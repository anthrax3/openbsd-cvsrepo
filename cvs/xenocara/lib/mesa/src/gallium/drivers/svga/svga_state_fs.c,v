head	1.2;
access;
symbols
	mesa-17_1_6:1.1.1.4
	OPENBSD_6_1:1.1.1.3.0.2
	OPENBSD_6_1_BASE:1.1.1.3
	mesa-13_0_6:1.1.1.3
	mesa-13_0_5:1.1.1.3
	mesa-13_0_3:1.1.1.3
	mesa-13_0_2:1.1.1.3
	OPENBSD_6_0:1.1.1.2.0.4
	OPENBSD_6_0_BASE:1.1.1.2
	mesa-11_2_2:1.1.1.2
	OPENBSD_5_9:1.1.1.1.0.2
	OPENBSD_5_9_BASE:1.1.1.1
	mesa-11_0_9:1.1.1.1
	mesa-11_0_8:1.1.1.1
	mesa-11_0_6:1.1.1.1
	mesa:1.1.1;
locks; strict;
comment	@ * @;


1.2
date	2017.08.26.16.59.27;	author jsg;	state Exp;
branches;
next	1.1;
commitid	D0k2io1oY8gcsQ2S;

1.1
date	2015.11.22.02.45.25;	author jsg;	state Exp;
branches
	1.1.1.1;
next	;
commitid	bJUptkbooQfJPk5r;

1.1.1.1
date	2015.11.22.02.45.25;	author jsg;	state Exp;
branches;
next	1.1.1.2;
commitid	bJUptkbooQfJPk5r;

1.1.1.2
date	2016.05.29.10.21.09;	author jsg;	state Exp;
branches;
next	1.1.1.3;
commitid	OwGfrJACrYJkCVJ4;

1.1.1.3
date	2016.12.11.08.29.41;	author jsg;	state Exp;
branches;
next	1.1.1.4;
commitid	uuv5VTS15jglEDZU;

1.1.1.4
date	2017.08.14.09.34.10;	author jsg;	state Exp;
branches;
next	;
commitid	enNyoMGkcgwM3Ww6;


desc
@@


1.2
log
@Revert to Mesa 13.0.6 to hopefully address rendering issues a handful of
people have reported with xpdf/fvwm on ivy bridge with modesetting driver.
@
text
@/**********************************************************
 * Copyright 2008-2009 VMware, Inc.  All rights reserved.
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 *
 **********************************************************/

#include "util/u_inlines.h"
#include "pipe/p_defines.h"
#include "util/u_math.h"
#include "util/u_memory.h"
#include "util/u_bitmask.h"
#include "tgsi/tgsi_ureg.h"

#include "svga_context.h"
#include "svga_state.h"
#include "svga_cmd.h"
#include "svga_shader.h"
#include "svga_resource_texture.h"
#include "svga_tgsi.h"
#include "svga_format.h"

#include "svga_hw_reg.h"



/**
 * If we fail to compile a fragment shader (because it uses too many
 * registers, for example) we'll use a dummy/fallback shader that
 * simply emits a constant color (red for debug, black for release).
 * We hit this with the Unigine/Heaven demo when Shaders = High.
 * With black, the demo still looks good.
 */
static const struct tgsi_token *
get_dummy_fragment_shader(void)
{
#ifdef DEBUG
   static const float color[4] = { 1.0, 0.0, 0.0, 0.0 }; /* red */
#else
   static const float color[4] = { 0.0, 0.0, 0.0, 0.0 }; /* black */
#endif
   struct ureg_program *ureg;
   const struct tgsi_token *tokens;
   struct ureg_src src;
   struct ureg_dst dst;
   unsigned num_tokens;

   ureg = ureg_create(PIPE_SHADER_FRAGMENT);
   if (!ureg)
      return NULL;

   dst = ureg_DECL_output(ureg, TGSI_SEMANTIC_COLOR, 0);
   src = ureg_DECL_immediate(ureg, color, 4);
   ureg_MOV(ureg, dst, src);
   ureg_END(ureg);

   tokens = ureg_get_tokens(ureg, &num_tokens);

   ureg_destroy(ureg);

   return tokens;
}


static struct svga_shader_variant *
translate_fragment_program(struct svga_context *svga,
                           const struct svga_fragment_shader *fs,
                           const struct svga_compile_key *key)
{
   if (svga_have_vgpu10(svga)) {
      return svga_tgsi_vgpu10_translate(svga, &fs->base, key,
                                        PIPE_SHADER_FRAGMENT);
   }
   else {
      return svga_tgsi_vgpu9_translate(svga, &fs->base, key,
                                       PIPE_SHADER_FRAGMENT);
   }
}


/**
 * Replace the given shader's instruction with a simple constant-color
 * shader.  We use this when normal shader translation fails.
 */
static struct svga_shader_variant *
get_compiled_dummy_shader(struct svga_context *svga,
                          struct svga_fragment_shader *fs,
                          const struct svga_compile_key *key)
{
   const struct tgsi_token *dummy = get_dummy_fragment_shader();
   struct svga_shader_variant *variant;

   if (!dummy) {
      return NULL;
   }

   FREE((void *) fs->base.tokens);
   fs->base.tokens = dummy;

   variant = translate_fragment_program(svga, fs, key);
   return variant;
}


/**
 * Translate TGSI shader into an svga shader variant.
 */
static enum pipe_error
compile_fs(struct svga_context *svga,
           struct svga_fragment_shader *fs,
           const struct svga_compile_key *key,
           struct svga_shader_variant **out_variant)
{
   struct svga_shader_variant *variant;
   enum pipe_error ret = PIPE_ERROR;

   variant = translate_fragment_program(svga, fs, key);
   if (variant == NULL) {
      debug_printf("Failed to compile fragment shader,"
                   " using dummy shader instead.\n");
      variant = get_compiled_dummy_shader(svga, fs, key);
   }
   else if (svga_shader_too_large(svga, variant)) {
      /* too big, use dummy shader */
      debug_printf("Shader too large (%u bytes),"
                   " using dummy shader instead.\n",
                   (unsigned) (variant->nr_tokens
                               * sizeof(variant->tokens[0])));
      /* Free the too-large variant */
      svga_destroy_shader_variant(svga, SVGA3D_SHADERTYPE_PS, variant);
      /* Use simple pass-through shader instead */
      variant = get_compiled_dummy_shader(svga, fs, key);
   }

   if (!variant) {
      return PIPE_ERROR;
   }

   ret = svga_define_shader(svga, SVGA3D_SHADERTYPE_PS, variant);
   if (ret != PIPE_OK) {
      svga_destroy_shader_variant(svga, SVGA3D_SHADERTYPE_PS, variant);
      return ret;
   }

   *out_variant = variant;

   /* insert variant at head of linked list */
   variant->next = fs->base.variants;
   fs->base.variants = variant;

   return PIPE_OK;
}


/* SVGA_NEW_TEXTURE_BINDING
 * SVGA_NEW_RAST
 * SVGA_NEW_NEED_SWTNL
 * SVGA_NEW_SAMPLER
 */
static enum pipe_error
make_fs_key(const struct svga_context *svga,
            struct svga_fragment_shader *fs,
            struct svga_compile_key *key)
{
   const enum pipe_shader_type shader = PIPE_SHADER_FRAGMENT;
   unsigned i;

   memset(key, 0, sizeof *key);

   memcpy(key->generic_remap_table, fs->generic_remap_table,
          sizeof(fs->generic_remap_table));

   /* SVGA_NEW_GS, SVGA_NEW_VS
    */
   if (svga->curr.gs) {
      key->fs.gs_generic_outputs = svga->curr.gs->generic_outputs;
   } else {
      key->fs.vs_generic_outputs = svga->curr.vs->generic_outputs;
   }

   /* Only need fragment shader fixup for twoside lighting if doing
    * hwtnl.  Otherwise the draw module does the whole job for us.
    *
    * SVGA_NEW_SWTNL
    */
   if (!svga->state.sw.need_swtnl) {
      /* SVGA_NEW_RAST, SVGA_NEW_REDUCED_PRIMITIVE
       */
      key->fs.light_twoside = svga->curr.rast->templ.light_twoside;
      key->fs.front_ccw = svga->curr.rast->templ.front_ccw;
      key->fs.pstipple = (svga->curr.rast->templ.poly_stipple_enable &&
                          svga->curr.reduced_prim == PIPE_PRIM_TRIANGLES);
      key->fs.aa_point = (svga->curr.rast->templ.point_smooth &&
                          svga->curr.reduced_prim == PIPE_PRIM_POINTS &&
                          (svga->curr.rast->pointsize > 1.0 ||
                           svga->curr.vs->base.info.writes_psize));
      if (key->fs.aa_point) {
         assert(svga->curr.gs != NULL);
         assert(svga->curr.gs->aa_point_coord_index != -1);
         key->fs.aa_point_coord_index = svga->curr.gs->aa_point_coord_index;
      }
   }

   /* The blend workaround for simulating logicop xor behaviour
    * requires that the incoming fragment color be white.  This change
    * achieves that by creating a variant of the current fragment
    * shader that overrides all output colors with 1,1,1,1
    *   
    * This will work for most shaders, including those containing
    * TEXKIL and/or depth-write.  However, it will break on the
    * combination of xor-logicop plus alphatest.
    *
    * Ultimately, we could implement alphatest in the shader using
    * texkil prior to overriding the outgoing fragment color.
    *   
    * SVGA_NEW_BLEND
    */
   if (svga->curr.blend->need_white_fragments) {
      key->fs.white_fragments = 1;
   }

#ifdef DEBUG
   /*
    * We expect a consistent set of samplers and sampler views.
    * Do some debug checks/warnings here.
    */
   {
      static boolean warned = FALSE;
      unsigned i, n = MAX2(svga->curr.num_sampler_views[shader],
                           svga->curr.num_samplers[shader]);
      /* Only warn once to prevent too much debug output */
      if (!warned) {
         if (svga->curr.num_sampler_views[shader] !=
             svga->curr.num_samplers[shader]) {
            debug_printf("svga: mismatched number of sampler views (%u) "
                         "vs. samplers (%u)\n",
                         svga->curr.num_sampler_views[shader],
                         svga->curr.num_samplers[shader]);
         }
         for (i = 0; i < n; i++) {
            if ((svga->curr.sampler_views[shader][i] == NULL) !=
                (svga->curr.sampler[shader][i] == NULL))
               debug_printf("sampler_view[%u] = %p but sampler[%u] = %p\n",
                            i, svga->curr.sampler_views[shader][i],
                            i, svga->curr.sampler[shader][i]);
         }
         warned = TRUE;
      }
   }
#endif

   /* XXX: want to limit this to the textures that the shader actually
    * refers to.
    *
    * SVGA_NEW_TEXTURE_BINDING | SVGA_NEW_SAMPLER
    */
   svga_init_shader_key_common(svga, shader, key);

   for (i = 0; i < svga->curr.num_samplers[shader]; ++i) {
      struct pipe_sampler_view *view = svga->curr.sampler_views[shader][i];
      const struct svga_sampler_state *sampler = svga->curr.sampler[shader][i];
      if (view) {
         struct pipe_resource *tex = view->texture;
         if (tex->target != PIPE_BUFFER) {
            struct svga_texture *stex = svga_texture(tex);
            SVGA3dSurfaceFormat format = stex->key.format;

            if (!svga_have_vgpu10(svga) &&
                (format == SVGA3D_Z_D16 ||
                 format == SVGA3D_Z_D24X8 ||
                 format == SVGA3D_Z_D24S8)) {
               /* If we're sampling from a SVGA3D_Z_D16, SVGA3D_Z_D24X8,
                * or SVGA3D_Z_D24S8 surface, we'll automatically get
                * shadow comparison.  But we only get LEQUAL mode.
                * Set TEX_COMPARE_NONE here so we don't emit the extra FS
                * code for shadow comparison.
                */
               key->tex[i].compare_mode = PIPE_TEX_COMPARE_NONE;
               key->tex[i].compare_func = PIPE_FUNC_NEVER;
               /* These depth formats _only_ support comparison mode and
                * not ordinary sampling so warn if the later is expected.
                */
               if (sampler->compare_mode != PIPE_TEX_COMPARE_R_TO_TEXTURE) {
                  debug_warn_once("Unsupported shadow compare mode");
               }
               /* The shader translation code can emit code to
                * handle ALWAYS and NEVER compare functions
                */
               else if (sampler->compare_func == PIPE_FUNC_ALWAYS ||
                        sampler->compare_func == PIPE_FUNC_NEVER) {
                  key->tex[i].compare_mode = sampler->compare_mode;
                  key->tex[i].compare_func = sampler->compare_func;
               }
               else if (sampler->compare_func != PIPE_FUNC_LEQUAL) {
                  debug_warn_once("Unsupported shadow compare function");
               }
            }
            else {
               /* For other texture formats, just use the compare func/mode
                * as-is.  Should be no-ops for color textures.  For depth
                * textures, we do not get automatic depth compare.  We have
                * to do it ourselves in the shader.  And we don't get PCF.
                */
               key->tex[i].compare_mode = sampler->compare_mode;
               key->tex[i].compare_func = sampler->compare_func;
            }
         }
      }
   }

   /* sprite coord gen state */
   for (i = 0; i < svga->curr.num_samplers[shader]; ++i) {
      key->tex[i].sprite_texgen =
         svga->curr.rast->templ.sprite_coord_enable & (1 << i);
   }

   key->sprite_origin_lower_left = (svga->curr.rast->templ.sprite_coord_mode
                                    == PIPE_SPRITE_COORD_LOWER_LEFT);

   key->fs.flatshade = svga->curr.rast->templ.flatshade;

   /* SVGA_NEW_DEPTH_STENCIL_ALPHA */
   if (svga_have_vgpu10(svga)) {
      /* Alpha testing is not supported in integer-valued render targets. */
      if (svga_has_any_integer_cbufs(svga)) {
         key->fs.alpha_func = SVGA3D_CMP_ALWAYS;
         key->fs.alpha_ref = 0;
      }
      else {
         key->fs.alpha_func = svga->curr.depth->alphafunc;
         key->fs.alpha_ref = svga->curr.depth->alpharef;
      }
   }

   /* SVGA_NEW_FRAME_BUFFER */
   if (fs->base.info.properties[TGSI_PROPERTY_FS_COLOR0_WRITES_ALL_CBUFS]) {
      /* Replicate color0 output to N colorbuffers */
      key->fs.write_color0_to_n_cbufs = svga->curr.framebuffer.nr_cbufs;
   }

   return PIPE_OK;
}


/**
 * svga_reemit_fs_bindings - Reemit the fragment shader bindings
 */
enum pipe_error
svga_reemit_fs_bindings(struct svga_context *svga)
{
   enum pipe_error ret;

   assert(svga->rebind.flags.fs);
   assert(svga_have_gb_objects(svga));

   if (!svga->state.hw_draw.fs)
      return PIPE_OK;

   if (!svga_need_to_rebind_resources(svga)) {
      ret =  svga->swc->resource_rebind(svga->swc, NULL,
                                        svga->state.hw_draw.fs->gb_shader,
                                        SVGA_RELOC_READ);
      goto out;
   }

   if (svga_have_vgpu10(svga))
      ret = SVGA3D_vgpu10_SetShader(svga->swc, SVGA3D_SHADERTYPE_PS,
                                    svga->state.hw_draw.fs->gb_shader,
                                    svga->state.hw_draw.fs->id);
   else
      ret = SVGA3D_SetGBShader(svga->swc, SVGA3D_SHADERTYPE_PS,
                               svga->state.hw_draw.fs->gb_shader);

 out:
   if (ret != PIPE_OK)
      return ret;

   svga->rebind.flags.fs = FALSE;
   return PIPE_OK;
}



static enum pipe_error
emit_hw_fs(struct svga_context *svga, unsigned dirty)
{
   struct svga_shader_variant *variant = NULL;
   enum pipe_error ret = PIPE_OK;
   struct svga_fragment_shader *fs = svga->curr.fs;
   struct svga_compile_key key;

   SVGA_STATS_TIME_PUSH(svga_sws(svga), SVGA_STATS_TIME_EMITFS);

   /* SVGA_NEW_BLEND
    * SVGA_NEW_TEXTURE_BINDING
    * SVGA_NEW_RAST
    * SVGA_NEW_NEED_SWTNL
    * SVGA_NEW_SAMPLER
    * SVGA_NEW_FRAME_BUFFER
    * SVGA_NEW_DEPTH_STENCIL_ALPHA
    * SVGA_NEW_VS
    */
   ret = make_fs_key(svga, fs, &key);
   if (ret != PIPE_OK)
      goto done;

   variant = svga_search_shader_key(&fs->base, &key);
   if (!variant) {
      ret = compile_fs(svga, fs, &key, &variant);
      if (ret != PIPE_OK)
         goto done;
   }

   assert(variant);

   if (variant != svga->state.hw_draw.fs) {
      ret = svga_set_shader(svga, SVGA3D_SHADERTYPE_PS, variant);
      if (ret != PIPE_OK)
         goto done;

      svga->rebind.flags.fs = FALSE;

      svga->dirty |= SVGA_NEW_FS_VARIANT;
      svga->state.hw_draw.fs = variant;
   }

done:
   SVGA_STATS_TIME_POP(svga_sws(svga));
   return ret;
}

struct svga_tracked_state svga_hw_fs = 
{
   "fragment shader (hwtnl)",
   (SVGA_NEW_FS |
    SVGA_NEW_GS |
    SVGA_NEW_VS |
    SVGA_NEW_TEXTURE_BINDING |
    SVGA_NEW_NEED_SWTNL |
    SVGA_NEW_RAST |
    SVGA_NEW_STIPPLE |
    SVGA_NEW_REDUCED_PRIMITIVE |
    SVGA_NEW_SAMPLER |
    SVGA_NEW_FRAME_BUFFER |
    SVGA_NEW_DEPTH_STENCIL_ALPHA |
    SVGA_NEW_BLEND),
   emit_hw_fs
};



@


1.1
log
@Initial revision
@
text
@d39 1
a44 32
static inline int
compare_fs_keys(const struct svga_fs_compile_key *a,
                const struct svga_fs_compile_key *b)
{
   unsigned keysize_a = svga_fs_key_size( a );
   unsigned keysize_b = svga_fs_key_size( b );

   if (keysize_a != keysize_b) {
      return (int)(keysize_a - keysize_b);
   }
   return memcmp( a, b, keysize_a );
}


/** Search for a fragment shader variant */
static struct svga_shader_variant *
search_fs_key(const struct svga_fragment_shader *fs,
              const struct svga_fs_compile_key *key)
{
   struct svga_shader_variant *variant = fs->base.variants;

   assert(key);

   for ( ; variant; variant = variant->next) {
      if (compare_fs_keys( key, &variant->key.fkey ) == 0)
         return variant;
   }
   
   return NULL;
}


d66 1
a66 1
   ureg = ureg_create(TGSI_PROCESSOR_FRAGMENT);
d83 16
d104 3
a106 2
get_compiled_dummy_shader(struct svga_fragment_shader *fs,
                          const struct svga_fs_compile_key *key)
d118 1
a118 1
   variant = svga_translate_fragment_program(fs, key);
d129 1
a129 1
           const struct svga_fs_compile_key *key,
d135 1
a135 1
   variant = svga_translate_fragment_program( fs, key );
d139 1
a139 5
      variant = get_compiled_dummy_shader(fs, key);
      if (!variant) {
         ret = PIPE_ERROR;
         goto fail;
      }
d141 1
a141 2

   if (svga_shader_too_large(svga, variant)) {
d143 1
a143 1
      debug_printf("Shader too large (%lu bytes),"
d145 10
a154 6
                   (unsigned long ) variant->nr_tokens * sizeof(variant->tokens[0]));
      variant = get_compiled_dummy_shader(fs, key);
      if (!variant) {
         ret = PIPE_ERROR;
         goto fail;
      }
d158 4
a161 2
   if (ret != PIPE_OK)
      goto fail;
d165 1
a165 1
   /* insert variants at head of linked list */
a169 6

fail:
   if (variant) {
      svga_destroy_shader_variant(svga, SVGA3D_SHADERTYPE_PS, variant);
   }
   return ret;
d181 1
a181 1
            struct svga_fs_compile_key *key)
d183 1
a184 1
   int idx = 0;
d188 11
d205 1
a205 1
      /* SVGA_NEW_RAST
d207 13
a219 2
      key->light_twoside = svga->curr.rast->templ.light_twoside;
      key->front_ccw = svga->curr.rast->templ.front_ccw;
d237 1
a237 1
      key->white_fragments = 1;
d247 2
a248 2
      unsigned i, n = MAX2(svga->curr.num_sampler_views,
                           svga->curr.num_samplers);
d251 2
a252 1
         if (svga->curr.num_sampler_views != svga->curr.num_samplers) {
d255 2
a256 2
                         svga->curr.num_sampler_views,
                         svga->curr.num_samplers);
d259 2
a260 2
            if ((svga->curr.sampler_views[i] == NULL) !=
                (svga->curr.sampler[i] == NULL))
d262 2
a263 2
                            i, svga->curr.sampler_views[i],
                            i, svga->curr.sampler[i]);
d275 1
a275 9
   for (i = 0; i < svga->curr.num_sampler_views; i++) {
      if (svga->curr.sampler_views[i] && svga->curr.sampler[i]) {
         assert(svga->curr.sampler_views[i]->texture);
         key->tex[i].texture_target = svga->curr.sampler_views[i]->texture->target;
         if (!svga->curr.sampler[i]->normalized_coords) {
            key->tex[i].width_height_idx = idx++;
            key->tex[i].unnormalized = TRUE;
            ++key->num_unnormalized_coords;
         }
d277 47
a323 36
         key->tex[i].swizzle_r = svga->curr.sampler_views[i]->swizzle_r;
         key->tex[i].swizzle_g = svga->curr.sampler_views[i]->swizzle_g;
         key->tex[i].swizzle_b = svga->curr.sampler_views[i]->swizzle_b;
         key->tex[i].swizzle_a = svga->curr.sampler_views[i]->swizzle_a;
      }
   }
   key->num_textures = svga->curr.num_sampler_views;

   idx = 0;
   for (i = 0; i < svga->curr.num_samplers; ++i) {
      if (svga->curr.sampler_views[i] && svga->curr.sampler[i]) {
         struct pipe_resource *tex = svga->curr.sampler_views[i]->texture;
         struct svga_texture *stex = svga_texture(tex);
         SVGA3dSurfaceFormat format = stex->key.format;

         if (format == SVGA3D_Z_D16 ||
             format == SVGA3D_Z_D24X8 ||
             format == SVGA3D_Z_D24S8) {
            /* If we're sampling from a SVGA3D_Z_D16, SVGA3D_Z_D24X8,
             * or SVGA3D_Z_D24S8 surface, we'll automatically get
             * shadow comparison.  But we only get LEQUAL mode.
             * Set TEX_COMPARE_NONE here so we don't emit the extra FS
             * code for shadow comparison.
             */
            key->tex[i].compare_mode = PIPE_TEX_COMPARE_NONE;
            key->tex[i].compare_func = PIPE_FUNC_NEVER;
            /* These depth formats _only_ support comparison mode and
             * not ordinary sampling so warn if the later is expected.
             */
            if (svga->curr.sampler[i]->compare_mode !=
                PIPE_TEX_COMPARE_R_TO_TEXTURE) {
               debug_warn_once("Unsupported shadow compare mode");
            }                   
            /* The only supported comparison mode is LEQUAL */
            if (svga->curr.sampler[i]->compare_func != PIPE_FUNC_LEQUAL) {
               debug_warn_once("Unsupported shadow compare function");
a325 9
         else {
            /* For other texture formats, just use the compare func/mode
             * as-is.  Should be no-ops for color textures.  For depth
             * textures, we do not get automatic depth compare.  We have
             * to do it ourselves in the shader.  And we don't get PCF.
             */
            key->tex[i].compare_mode = svga->curr.sampler[i]->compare_mode;
            key->tex[i].compare_func = svga->curr.sampler[i]->compare_func;
         }
d330 1
a330 1
   for (i = 0; i < svga->curr.num_samplers; ++i) {
d338 15
d356 1
a356 1
      key->write_color0_to_n_cbufs = svga->curr.framebuffer.nr_cbufs;
d371 1
a371 1
   assert(svga->rebind.fs);
d377 16
a392 2
   ret = SVGA3D_SetGBShader(svga->swc, SVGA3D_SHADERTYPE_PS,
                            svga->state.hw_draw.fs->gb_shader);
d396 1
a396 1
   svga->rebind.fs = FALSE;
d408 3
a410 1
   struct svga_fs_compile_key key;
d418 2
d421 1
a421 1
   ret = make_fs_key( svga, fs, &key );
d423 1
a423 1
      return ret;
d425 1
a425 1
   variant = search_fs_key( fs, &key );
d427 1
a427 1
      ret = compile_fs( svga, fs, &key, &variant );
d429 1
a429 1
         return ret;
d435 3
a437 5
      if (svga_have_gb_objects(svga)) {
         ret = SVGA3D_SetGBShader(svga->swc, SVGA3D_SHADERTYPE_PS,
                                  variant->gb_shader);
         if (ret != PIPE_OK)
            return ret;
d439 1
a439 7
         svga->rebind.fs = FALSE;
      }
      else {
         ret = SVGA3D_SetShader(svga->swc, SVGA3D_SHADERTYPE_PS, variant->id);
         if (ret != PIPE_OK)
            return ret;
      }
d442 1
a442 1
      svga->state.hw_draw.fs = variant;      
d445 3
a447 1
   return PIPE_OK;
d454 2
d459 2
d463 1
@


1.1.1.1
log
@import Mesa 11.0.6
@
text
@@


1.1.1.2
log
@Import Mesa 11.2.2
@
text
@a38 1
#include "svga_format.h"
d44 32
a113 16
static struct svga_shader_variant *
translate_fragment_program(struct svga_context *svga,
                           const struct svga_fragment_shader *fs,
                           const struct svga_compile_key *key)
{
   if (svga_have_vgpu10(svga)) {
      return svga_tgsi_vgpu10_translate(svga, &fs->base, key,
                                        PIPE_SHADER_FRAGMENT);
   }
   else {
      return svga_tgsi_vgpu9_translate(svga, &fs->base, key,
                                       PIPE_SHADER_FRAGMENT);
   }
}


d119 2
a120 3
get_compiled_dummy_shader(struct svga_context *svga,
                          struct svga_fragment_shader *fs,
                          const struct svga_compile_key *key)
d132 1
a132 1
   variant = translate_fragment_program(svga, fs, key);
d143 1
a143 1
           const struct svga_compile_key *key,
d149 1
a149 1
   variant = translate_fragment_program(svga, fs, key);
d153 5
a157 1
      variant = get_compiled_dummy_shader(svga, fs, key);
d159 2
a160 1
   else if (svga_shader_too_large(svga, variant)) {
d162 1
a162 1
      debug_printf("Shader too large (%u bytes),"
d164 6
a169 10
                   (unsigned) (variant->nr_tokens
                               * sizeof(variant->tokens[0])));
      /* Free the too-large variant */
      svga_destroy_shader_variant(svga, SVGA3D_SHADERTYPE_PS, variant);
      /* Use simple pass-through shader instead */
      variant = get_compiled_dummy_shader(svga, fs, key);
   }

   if (!variant) {
      return PIPE_ERROR;
d173 2
a174 4
   if (ret != PIPE_OK) {
      svga_destroy_shader_variant(svga, SVGA3D_SHADERTYPE_PS, variant);
      return ret;
   }
d178 1
a178 1
   /* insert variant at head of linked list */
d183 6
d200 1
a200 1
            struct svga_compile_key *key)
a201 1
   const unsigned shader = PIPE_SHADER_FRAGMENT;
d203 1
a206 11
   memcpy(key->generic_remap_table, fs->generic_remap_table,
          sizeof(fs->generic_remap_table));

   /* SVGA_NEW_GS, SVGA_NEW_VS
    */
   if (svga->curr.gs) {
      key->fs.gs_generic_outputs = svga->curr.gs->generic_outputs;
   } else {
      key->fs.vs_generic_outputs = svga->curr.vs->generic_outputs;
   }

d213 1
a213 1
      /* SVGA_NEW_RAST, SVGA_NEW_REDUCED_PRIMITIVE
d215 2
a216 13
      key->fs.light_twoside = svga->curr.rast->templ.light_twoside;
      key->fs.front_ccw = svga->curr.rast->templ.front_ccw;
      key->fs.pstipple = (svga->curr.rast->templ.poly_stipple_enable &&
                          svga->curr.reduced_prim == PIPE_PRIM_TRIANGLES);
      key->fs.aa_point = (svga->curr.rast->templ.point_smooth &&
                          svga->curr.reduced_prim == PIPE_PRIM_POINTS &&
                          (svga->curr.rast->pointsize > 1.0 ||
                           svga->curr.vs->base.info.writes_psize));
      if (key->fs.aa_point) {
         assert(svga->curr.gs != NULL);
         assert(svga->curr.gs->aa_point_coord_index != -1);
         key->fs.aa_point_coord_index = svga->curr.gs->aa_point_coord_index;
      }
d234 1
a234 1
      key->fs.white_fragments = 1;
d244 2
a245 2
      unsigned i, n = MAX2(svga->curr.num_sampler_views[shader],
                           svga->curr.num_samplers[shader]);
d248 1
a248 2
         if (svga->curr.num_sampler_views[shader] !=
             svga->curr.num_samplers[shader]) {
d251 2
a252 2
                         svga->curr.num_sampler_views[shader],
                         svga->curr.num_samplers[shader]);
d255 2
a256 2
            if ((svga->curr.sampler_views[shader][i] == NULL) !=
                (svga->curr.sampler[shader][i] == NULL))
d258 2
a259 2
                            i, svga->curr.sampler_views[shader][i],
                            i, svga->curr.sampler[shader][i]);
d271 17
a287 1
   svga_init_shader_key_common(svga, shader, key);
d289 28
a316 47
   for (i = 0; i < svga->curr.num_samplers[shader]; ++i) {
      struct pipe_sampler_view *view = svga->curr.sampler_views[shader][i];
      const struct svga_sampler_state *sampler = svga->curr.sampler[shader][i];
      if (view) {
         struct pipe_resource *tex = view->texture;
         if (tex->target != PIPE_BUFFER) {
            struct svga_texture *stex = svga_texture(tex);
            SVGA3dSurfaceFormat format = stex->key.format;

            if (!svga_have_vgpu10(svga) &&
                (format == SVGA3D_Z_D16 ||
                 format == SVGA3D_Z_D24X8 ||
                 format == SVGA3D_Z_D24S8)) {
               /* If we're sampling from a SVGA3D_Z_D16, SVGA3D_Z_D24X8,
                * or SVGA3D_Z_D24S8 surface, we'll automatically get
                * shadow comparison.  But we only get LEQUAL mode.
                * Set TEX_COMPARE_NONE here so we don't emit the extra FS
                * code for shadow comparison.
                */
               key->tex[i].compare_mode = PIPE_TEX_COMPARE_NONE;
               key->tex[i].compare_func = PIPE_FUNC_NEVER;
               /* These depth formats _only_ support comparison mode and
                * not ordinary sampling so warn if the later is expected.
                */
               if (sampler->compare_mode != PIPE_TEX_COMPARE_R_TO_TEXTURE) {
                  debug_warn_once("Unsupported shadow compare mode");
               }
               /* The shader translation code can emit code to
                * handle ALWAYS and NEVER compare functions
                */
               else if (sampler->compare_func == PIPE_FUNC_ALWAYS ||
                        sampler->compare_func == PIPE_FUNC_NEVER) {
                  key->tex[i].compare_mode = sampler->compare_mode;
                  key->tex[i].compare_func = sampler->compare_func;
               }
               else if (sampler->compare_func != PIPE_FUNC_LEQUAL) {
                  debug_warn_once("Unsupported shadow compare function");
               }
            }
            else {
               /* For other texture formats, just use the compare func/mode
                * as-is.  Should be no-ops for color textures.  For depth
                * textures, we do not get automatic depth compare.  We have
                * to do it ourselves in the shader.  And we don't get PCF.
                */
               key->tex[i].compare_mode = sampler->compare_mode;
               key->tex[i].compare_func = sampler->compare_func;
d318 9
d332 1
a332 1
   for (i = 0; i < svga->curr.num_samplers[shader]; ++i) {
a339 15
   key->fs.flatshade = svga->curr.rast->templ.flatshade;

   /* SVGA_NEW_DEPTH_STENCIL_ALPHA */
   if (svga_have_vgpu10(svga)) {
      /* Alpha testing is not supported in integer-valued render targets. */
      if (svga_has_any_integer_cbufs(svga)) {
         key->fs.alpha_func = SVGA3D_CMP_ALWAYS;
         key->fs.alpha_ref = 0;
      }
      else {
         key->fs.alpha_func = svga->curr.depth->alphafunc;
         key->fs.alpha_ref = svga->curr.depth->alpharef;
      }
   }

d343 1
a343 1
      key->fs.write_color0_to_n_cbufs = svga->curr.framebuffer.nr_cbufs;
d358 1
a358 1
   assert(svga->rebind.flags.fs);
d364 2
a365 16
   if (!svga_need_to_rebind_resources(svga)) {
      ret =  svga->swc->resource_rebind(svga->swc, NULL,
                                        svga->state.hw_draw.fs->gb_shader,
                                        SVGA_RELOC_READ);
      goto out;
   }

   if (svga_have_vgpu10(svga))
      ret = SVGA3D_vgpu10_SetShader(svga->swc, SVGA3D_SHADERTYPE_PS,
                                    svga->state.hw_draw.fs->gb_shader,
                                    svga->state.hw_draw.fs->id);
   else
      ret = SVGA3D_SetGBShader(svga->swc, SVGA3D_SHADERTYPE_PS,
                               svga->state.hw_draw.fs->gb_shader);

 out:
d369 1
a369 1
   svga->rebind.flags.fs = FALSE;
d381 1
a381 1
   struct svga_compile_key key;
a388 2
    * SVGA_NEW_DEPTH_STENCIL_ALPHA
    * SVGA_NEW_VS
d390 1
a390 1
   ret = make_fs_key(svga, fs, &key);
d394 1
a394 1
   variant = svga_search_shader_key(&fs->base, &key);
d396 1
a396 1
      ret = compile_fs(svga, fs, &key, &variant);
d404 5
a408 3
      ret = svga_set_shader(svga, SVGA3D_SHADERTYPE_PS, variant);
      if (ret != PIPE_OK)
         return ret;
d410 7
a416 1
      svga->rebind.flags.fs = FALSE;
d419 1
a419 1
      svga->state.hw_draw.fs = variant;
a428 2
    SVGA_NEW_GS |
    SVGA_NEW_VS |
a431 2
    SVGA_NEW_STIPPLE |
    SVGA_NEW_REDUCED_PRIMITIVE |
a433 1
    SVGA_NEW_DEPTH_STENCIL_ALPHA |
@


1.1.1.3
log
@Import Mesa 13.0.2
@
text
@d66 1
a66 1
   ureg = ureg_create(PIPE_SHADER_FRAGMENT);
d183 1
a183 1
   const enum pipe_shader_type shader = PIPE_SHADER_FRAGMENT;
a409 2
   SVGA_STATS_TIME_PUSH(svga_sws(svga), SVGA_STATS_TIME_EMITFS);

d421 1
a421 1
      goto done;
d427 1
a427 1
         goto done;
d435 1
a435 1
         goto done;
d443 1
a443 3
done:
   SVGA_STATS_TIME_POP(svga_sws(svga));
   return ret;
@


1.1.1.4
log
@Import Mesa 17.1.6
@
text
@d64 1
d75 1
a75 1
   tokens = ureg_get_tokens(ureg, NULL);
a410 21

   /* Disable rasterization if rasterizer_discard flag is set or
    * vs/gs does not output position.
    */
   svga->disable_rasterizer =
      svga->curr.rast->templ.rasterizer_discard ||
      (svga->curr.gs && !svga->curr.gs->base.info.writes_position) ||
      (!svga->curr.gs && !svga->curr.vs->base.info.writes_position);

   /* Set FS to NULL when rasterization is to be disabled */
   if (svga->disable_rasterizer) {
      /* Set FS to NULL if it has not been done */
      if (svga->state.hw_draw.fs) {
         ret = svga_set_shader(svga, SVGA3D_SHADERTYPE_PS, NULL);
         if (ret != PIPE_OK)
            goto done;
      }
      svga->rebind.flags.fs = FALSE;
      svga->state.hw_draw.fs = NULL;
      goto done;
   }
@


