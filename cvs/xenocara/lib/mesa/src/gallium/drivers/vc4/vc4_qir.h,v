head	1.2;
access;
symbols
	mesa-17_1_6:1.1.1.5
	OPENBSD_6_1:1.1.1.4.0.2
	OPENBSD_6_1_BASE:1.1.1.4
	mesa-13_0_6:1.1.1.4
	mesa-13_0_5:1.1.1.4
	mesa-13_0_3:1.1.1.3
	mesa-13_0_2:1.1.1.3
	OPENBSD_6_0:1.1.1.2.0.4
	OPENBSD_6_0_BASE:1.1.1.2
	mesa-11_2_2:1.1.1.2
	OPENBSD_5_9:1.1.1.1.0.2
	OPENBSD_5_9_BASE:1.1.1.1
	mesa-11_0_9:1.1.1.1
	mesa-11_0_8:1.1.1.1
	mesa-11_0_6:1.1.1.1
	mesa:1.1.1;
locks; strict;
comment	@ * @;


1.2
date	2017.08.26.16.59.29;	author jsg;	state Exp;
branches;
next	1.1;
commitid	D0k2io1oY8gcsQ2S;

1.1
date	2015.11.22.02.44.23;	author jsg;	state Exp;
branches
	1.1.1.1;
next	;
commitid	bJUptkbooQfJPk5r;

1.1.1.1
date	2015.11.22.02.44.23;	author jsg;	state Exp;
branches;
next	1.1.1.2;
commitid	bJUptkbooQfJPk5r;

1.1.1.2
date	2016.05.29.10.19.58;	author jsg;	state Exp;
branches;
next	1.1.1.3;
commitid	OwGfrJACrYJkCVJ4;

1.1.1.3
date	2016.12.11.08.27.35;	author jsg;	state Exp;
branches;
next	1.1.1.4;
commitid	uuv5VTS15jglEDZU;

1.1.1.4
date	2017.02.26.12.08.08;	author jsg;	state Exp;
branches;
next	1.1.1.5;
commitid	xZcdklZavddTKAf1;

1.1.1.5
date	2017.08.14.09.32.16;	author jsg;	state Exp;
branches;
next	;
commitid	enNyoMGkcgwM3Ww6;


desc
@@


1.2
log
@Revert to Mesa 13.0.6 to hopefully address rendering issues a handful of
people have reported with xpdf/fvwm on ivy bridge with modesetting driver.
@
text
@/*
 * Copyright Â© 2014 Broadcom
 *
 * Permission is hereby granted, free of charge, to any person obtaining a
 * copy of this software and associated documentation files (the "Software"),
 * to deal in the Software without restriction, including without limitation
 * the rights to use, copy, modify, merge, publish, distribute, sublicense,
 * and/or sell copies of the Software, and to permit persons to whom the
 * Software is furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice (including the next
 * paragraph) shall be included in all copies or substantial portions of the
 * Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
 * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
 * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
 * IN THE SOFTWARE.
 */

#ifndef VC4_QIR_H
#define VC4_QIR_H

#include <assert.h>
#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>
#include <stdint.h>
#include <string.h>

#include "util/macros.h"
#include "compiler/nir/nir.h"
#include "util/list.h"
#include "util/u_math.h"

#include "vc4_screen.h"
#include "vc4_qpu_defines.h"
#include "vc4_qpu.h"
#include "kernel/vc4_packet.h"
#include "pipe/p_state.h"

struct nir_builder;

enum qfile {
        QFILE_NULL,
        QFILE_TEMP,
        QFILE_VARY,
        QFILE_UNIF,
        QFILE_VPM,
        QFILE_TLB_COLOR_WRITE,
        QFILE_TLB_COLOR_WRITE_MS,
        QFILE_TLB_Z_WRITE,
        QFILE_TLB_STENCIL_SETUP,

        /* Payload registers that aren't in the physical register file, so we
         * can just use the corresponding qpu_reg at qpu_emit time.
         */
        QFILE_FRAG_X,
        QFILE_FRAG_Y,
        QFILE_FRAG_REV_FLAG,
        QFILE_QPU_ELEMENT,

        /**
         * Stores an immediate value in the index field that will be used
         * directly by qpu_load_imm().
         */
        QFILE_LOAD_IMM,

        /**
         * Stores an immediate value in the index field that can be turned
         * into a small immediate field by qpu_encode_small_immediate().
         */
        QFILE_SMALL_IMM,
};

struct qreg {
        enum qfile file;
        uint32_t index;
        int pack;
};

static inline struct qreg qir_reg(enum qfile file, uint32_t index)
{
        return (struct qreg){file, index};
}

enum qop {
        QOP_UNDEF,
        QOP_MOV,
        QOP_FMOV,
        QOP_MMOV,
        QOP_FADD,
        QOP_FSUB,
        QOP_FMUL,
        QOP_V8MULD,
        QOP_V8MIN,
        QOP_V8MAX,
        QOP_V8ADDS,
        QOP_V8SUBS,
        QOP_MUL24,
        QOP_FMIN,
        QOP_FMAX,
        QOP_FMINABS,
        QOP_FMAXABS,
        QOP_ADD,
        QOP_SUB,
        QOP_SHL,
        QOP_SHR,
        QOP_ASR,
        QOP_MIN,
        QOP_MIN_NOIMM,
        QOP_MAX,
        QOP_AND,
        QOP_OR,
        QOP_XOR,
        QOP_NOT,

        QOP_FTOI,
        QOP_ITOF,
        QOP_RCP,
        QOP_RSQ,
        QOP_EXP2,
        QOP_LOG2,
        QOP_VW_SETUP,
        QOP_VR_SETUP,
        QOP_TLB_COLOR_READ,
        QOP_MS_MASK,
        QOP_VARY_ADD_C,

        QOP_FRAG_Z,
        QOP_FRAG_W,

        /** Texture x coordinate parameter write */
        QOP_TEX_S,
        /** Texture y coordinate parameter write */
        QOP_TEX_T,
        /** Texture border color parameter or cube map z coordinate write */
        QOP_TEX_R,
        /** Texture LOD bias parameter write */
        QOP_TEX_B,

        /**
         * Texture-unit 4-byte read with address provided direct in S
         * cooordinate.
         *
         * The first operand is the offset from the start of the UBO, and the
         * second is the uniform that has the UBO's base pointer.
         */
        QOP_TEX_DIRECT,

        /**
         * Signal of texture read being necessary and then reading r4 into
         * the destination
         */
        QOP_TEX_RESULT,

        /* 32-bit immediate loaded to each SIMD channel */
        QOP_LOAD_IMM,

        /* 32-bit immediate divided into 16 2-bit unsigned int values and
         * loaded to each corresponding SIMD channel.
         */
        QOP_LOAD_IMM_U2,
        /* 32-bit immediate divided into 16 2-bit signed int values and
         * loaded to each corresponding SIMD channel.
         */
        QOP_LOAD_IMM_I2,

        QOP_ROT_MUL,

        /* Jumps to block->successor[0] if the qinst->cond (as a
         * QPU_COND_BRANCH_*) passes, or block->successor[1] if not.  Note
         * that block->successor[1] may be unset if the condition is ALWAYS.
         */
        QOP_BRANCH,

        /* Emits an ADD from src[0] to src[1], where src[0] must be a
         * QOP_LOAD_IMM result and src[1] is a QUNIFORM_UNIFORMS_ADDRESS,
         * required by the kernel as part of its branch validation.
         */
        QOP_UNIFORMS_RESET,
};

struct queued_qpu_inst {
        struct list_head link;
        uint64_t inst;
};

struct qinst {
        struct list_head link;

        enum qop op;
        struct qreg dst;
        struct qreg *src;
        bool sf;
        bool cond_is_exec_mask;
        uint8_t cond;
};

enum qstage {
        /**
         * Coordinate shader, runs during binning, before the VS, and just
         * outputs position.
         */
        QSTAGE_COORD,
        QSTAGE_VERT,
        QSTAGE_FRAG,
};

enum quniform_contents {
        /**
         * Indicates that a constant 32-bit value is copied from the program's
         * uniform contents.
         */
        QUNIFORM_CONSTANT,
        /**
         * Indicates that the program's uniform contents are used as an index
         * into the GL uniform storage.
         */
        QUNIFORM_UNIFORM,

        /** @@{
         * Scaling factors from clip coordinates to relative to the viewport
         * center.
         *
         * This is used by the coordinate and vertex shaders to produce the
         * 32-bit entry consisting of 2 16-bit fields with 12.4 signed fixed
         * point offsets from the viewport ccenter.
         */
        QUNIFORM_VIEWPORT_X_SCALE,
        QUNIFORM_VIEWPORT_Y_SCALE,
        /** @@} */

        QUNIFORM_VIEWPORT_Z_OFFSET,
        QUNIFORM_VIEWPORT_Z_SCALE,

        QUNIFORM_USER_CLIP_PLANE,

        /**
         * A reference to a texture config parameter 0 uniform.
         *
         * This is a uniform implicitly loaded with a QPU_W_TMU* write, which
         * defines texture type, miplevels, and such.  It will be found as a
         * parameter to the first QOP_TEX_[STRB] instruction in a sequence.
         */
        QUNIFORM_TEXTURE_CONFIG_P0,

        /**
         * A reference to a texture config parameter 1 uniform.
         *
         * This is a uniform implicitly loaded with a QPU_W_TMU* write, which
         * defines texture width, height, filters, and wrap modes.  It will be
         * found as a parameter to the second QOP_TEX_[STRB] instruction in a
         * sequence.
         */
        QUNIFORM_TEXTURE_CONFIG_P1,

        /** A reference to a texture config parameter 2 cubemap stride uniform */
        QUNIFORM_TEXTURE_CONFIG_P2,

        QUNIFORM_TEXTURE_FIRST_LEVEL,

        QUNIFORM_TEXTURE_MSAA_ADDR,

        QUNIFORM_UBO_ADDR,

        QUNIFORM_TEXRECT_SCALE_X,
        QUNIFORM_TEXRECT_SCALE_Y,

        QUNIFORM_TEXTURE_BORDER_COLOR,

        QUNIFORM_BLEND_CONST_COLOR_X,
        QUNIFORM_BLEND_CONST_COLOR_Y,
        QUNIFORM_BLEND_CONST_COLOR_Z,
        QUNIFORM_BLEND_CONST_COLOR_W,
        QUNIFORM_BLEND_CONST_COLOR_RGBA,
        QUNIFORM_BLEND_CONST_COLOR_AAAA,

        QUNIFORM_STENCIL,

        QUNIFORM_ALPHA_REF,
        QUNIFORM_SAMPLE_MASK,

        /* Placeholder uniform that will be updated by the kernel when used by
         * an instruction writing to QPU_W_UNIFORMS_ADDRESS.
         */
        QUNIFORM_UNIFORMS_ADDRESS,
};

struct vc4_varying_slot {
        uint8_t slot;
        uint8_t swizzle;
};

struct vc4_compiler_ubo_range {
        /**
         * offset in bytes from the start of the ubo where this range is
         * uploaded.
         *
         * Only set once used is set.
         */
        uint32_t dst_offset;

        /**
         * offset in bytes from the start of the gallium uniforms where the
         * data comes from.
         */
        uint32_t src_offset;

        /** size in bytes of this ubo range */
        uint32_t size;

        /**
         * Set if this range is used by the shader for indirect uniforms
         * access.
         */
        bool used;
};

struct vc4_key {
        struct vc4_uncompiled_shader *shader_state;
        struct {
                enum pipe_format format;
                uint8_t swizzle[4];
                union {
                        struct {
                                unsigned compare_mode:1;
                                unsigned compare_func:3;
                                unsigned wrap_s:3;
                                unsigned wrap_t:3;
                                bool force_first_level:1;
                        };
                        struct {
                                uint16_t msaa_width, msaa_height;
                        };
                };
        } tex[VC4_MAX_TEXTURE_SAMPLERS];
        uint8_t ucp_enables;
};

struct vc4_fs_key {
        struct vc4_key base;
        enum pipe_format color_format;
        bool depth_enabled;
        bool stencil_enabled;
        bool stencil_twoside;
        bool stencil_full_writemasks;
        bool is_points;
        bool is_lines;
        bool alpha_test;
        bool point_coord_upper_left;
        bool light_twoside;
        bool msaa;
        bool sample_coverage;
        bool sample_alpha_to_coverage;
        bool sample_alpha_to_one;
        uint8_t alpha_test_func;
        uint8_t logicop_func;
        uint32_t point_sprite_mask;

        struct pipe_rt_blend_state blend;
};

struct vc4_vs_key {
        struct vc4_key base;

        const struct vc4_fs_inputs *fs_inputs;
        enum pipe_format attr_formats[8];
        bool is_coord;
        bool per_vertex_point_size;
        bool clamp_color;
};

/** A basic block of QIR intructions. */
struct qblock {
        struct list_head link;

        struct list_head instructions;
        struct list_head qpu_inst_list;

        struct set *predecessors;
        struct qblock *successors[2];

        int index;

        /* Instruction IPs for the first and last instruction of the block.
         * Set by vc4_qpu_schedule.c.
         */
        uint32_t start_qpu_ip;
        uint32_t end_qpu_ip;

        /* Instruction IP for the branch instruction of the block.  Set by
         * vc4_qpu_schedule.c.
         */
        uint32_t branch_qpu_ip;

        /** @@{ used by vc4_qir_live_variables.c */
        BITSET_WORD *def;
        BITSET_WORD *use;
        BITSET_WORD *live_in;
        BITSET_WORD *live_out;
        int start_ip, end_ip;
        /** @@} */
};

struct vc4_compile {
        struct vc4_context *vc4;
        nir_shader *s;
        nir_function_impl *impl;
        struct exec_list *cf_node_list;

        /**
         * Mapping from nir_register * or nir_ssa_def * to array of struct
         * qreg for the values.
         */
        struct hash_table *def_ht;

        /* For each temp, the instruction generating its value. */
        struct qinst **defs;
        uint32_t defs_array_size;

        /**
         * Inputs to the shader, arranged by TGSI declaration order.
         *
         * Not all fragment shader QFILE_VARY reads are present in this array.
         */
        struct qreg *inputs;
        struct qreg *outputs;
        bool msaa_per_sample_output;
        struct qreg color_reads[VC4_MAX_SAMPLES];
        struct qreg sample_colors[VC4_MAX_SAMPLES];
        uint32_t inputs_array_size;
        uint32_t outputs_array_size;
        uint32_t uniforms_array_size;

        struct vc4_compiler_ubo_range *ubo_ranges;
        uint32_t ubo_ranges_array_size;
        /** Number of uniform areas declared in ubo_ranges. */
        uint32_t num_uniform_ranges;
        /** Number of uniform areas used for indirect addressed loads. */
        uint32_t num_ubo_ranges;
        uint32_t next_ubo_dst_offset;

        /* State for whether we're executing on each channel currently.  0 if
         * yes, otherwise a block number + 1 that the channel jumped to.
         */
        struct qreg execute;

        struct qreg line_x, point_x, point_y;
        /** boolean (~0 -> true) if the fragment has been discarded. */
        struct qreg discard;
        struct qreg payload_FRAG_Z;
        struct qreg payload_FRAG_W;

        uint8_t vattr_sizes[8];

        /**
         * Array of the VARYING_SLOT_* of all FS QFILE_VARY reads.
         *
         * This includes those that aren't part of the VPM varyings, like
         * point/line coordinates.
         */
        struct vc4_varying_slot *input_slots;
        uint32_t num_input_slots;
        uint32_t input_slots_array_size;

        /**
         * An entry per outputs[] in the VS indicating what the VARYING_SLOT_*
         * of the output is.  Used to emit from the VS in the order that the
         * FS needs.
         */
        struct vc4_varying_slot *output_slots;

        struct pipe_shader_state *shader_state;
        struct vc4_key *key;
        struct vc4_fs_key *fs_key;
        struct vc4_vs_key *vs_key;

        /* Live ranges of temps. */
        int *temp_start, *temp_end;

        uint32_t *uniform_data;
        enum quniform_contents *uniform_contents;
        uint32_t uniform_array_size;
        uint32_t num_uniforms;
        uint32_t num_outputs;
        uint32_t num_texture_samples;
        uint32_t output_position_index;
        uint32_t output_color_index;
        uint32_t output_point_size_index;
        uint32_t output_sample_mask_index;

        struct qreg undef;
        enum qstage stage;
        uint32_t num_temps;

        struct list_head blocks;
        int next_block_index;
        struct qblock *cur_block;
        struct qblock *loop_cont_block;
        struct qblock *loop_break_block;

        struct list_head qpu_inst_list;

        uint64_t *qpu_insts;
        uint32_t qpu_inst_count;
        uint32_t qpu_inst_size;
        uint32_t num_inputs;

        /**
         * Number of inputs from num_inputs remaining to be queued to the read
         * FIFO in the VS/CS.
         */
        uint32_t num_inputs_remaining;

        /* Number of inputs currently in the read FIFO for the VS/CS */
        uint32_t num_inputs_in_fifo;

        /** Next offset in the VPM to read from in the VS/CS */
        uint32_t vpm_read_offset;

        uint32_t program_id;
        uint32_t variant_id;
        bool failed;
};

/* Special nir_load_input intrinsic index for loading the current TLB
 * destination color.
 */
#define VC4_NIR_TLB_COLOR_READ_INPUT		2000000000

#define VC4_NIR_MS_MASK_OUTPUT			2000000000

struct vc4_compile *qir_compile_init(void);
void qir_compile_destroy(struct vc4_compile *c);
struct qblock *qir_new_block(struct vc4_compile *c);
void qir_set_emit_block(struct vc4_compile *c, struct qblock *block);
void qir_link_blocks(struct qblock *predecessor, struct qblock *successor);
struct qblock *qir_entry_block(struct vc4_compile *c);
struct qblock *qir_exit_block(struct vc4_compile *c);
struct qinst *qir_inst(enum qop op, struct qreg dst,
                       struct qreg src0, struct qreg src1);
struct qinst *qir_inst4(enum qop op, struct qreg dst,
                        struct qreg a,
                        struct qreg b,
                        struct qreg c,
                        struct qreg d);
void qir_remove_instruction(struct vc4_compile *c, struct qinst *qinst);
struct qreg qir_uniform(struct vc4_compile *c,
                        enum quniform_contents contents,
                        uint32_t data);
void qir_schedule_instructions(struct vc4_compile *c);
void qir_reorder_uniforms(struct vc4_compile *c);
void qir_emit_uniform_stream_resets(struct vc4_compile *c);

struct qreg qir_emit_def(struct vc4_compile *c, struct qinst *inst);
struct qinst *qir_emit_nondef(struct vc4_compile *c, struct qinst *inst);

struct qreg qir_get_temp(struct vc4_compile *c);
void qir_calculate_live_intervals(struct vc4_compile *c);
int qir_get_op_nsrc(enum qop qop);
bool qir_reg_equals(struct qreg a, struct qreg b);
bool qir_has_side_effects(struct vc4_compile *c, struct qinst *inst);
bool qir_has_side_effect_reads(struct vc4_compile *c, struct qinst *inst);
bool qir_is_mul(struct qinst *inst);
bool qir_is_raw_mov(struct qinst *inst);
bool qir_is_tex(struct qinst *inst);
bool qir_is_float_input(struct qinst *inst);
bool qir_depends_on_flags(struct qinst *inst);
bool qir_writes_r4(struct qinst *inst);
struct qreg qir_follow_movs(struct vc4_compile *c, struct qreg reg);
uint8_t qir_channels_written(struct qinst *inst);

void qir_dump(struct vc4_compile *c);
void qir_dump_inst(struct vc4_compile *c, struct qinst *inst);
const char *qir_get_stage_name(enum qstage stage);

void qir_validate(struct vc4_compile *c);

void qir_optimize(struct vc4_compile *c);
bool qir_opt_algebraic(struct vc4_compile *c);
bool qir_opt_constant_folding(struct vc4_compile *c);
bool qir_opt_copy_propagation(struct vc4_compile *c);
bool qir_opt_dead_code(struct vc4_compile *c);
bool qir_opt_peephole_sf(struct vc4_compile *c);
bool qir_opt_small_immediates(struct vc4_compile *c);
bool qir_opt_vpm(struct vc4_compile *c);
void vc4_nir_lower_blend(nir_shader *s, struct vc4_compile *c);
void vc4_nir_lower_io(nir_shader *s, struct vc4_compile *c);
nir_ssa_def *vc4_nir_get_swizzled_channel(struct nir_builder *b,
                                          nir_ssa_def **srcs, int swiz);
void vc4_nir_lower_txf_ms(nir_shader *s, struct vc4_compile *c);
void qir_lower_uniforms(struct vc4_compile *c);

uint32_t qpu_schedule_instructions(struct vc4_compile *c);

void qir_SF(struct vc4_compile *c, struct qreg src);

static inline struct qreg
qir_uniform_ui(struct vc4_compile *c, uint32_t ui)
{
        return qir_uniform(c, QUNIFORM_CONSTANT, ui);
}

static inline struct qreg
qir_uniform_f(struct vc4_compile *c, float f)
{
        return qir_uniform(c, QUNIFORM_CONSTANT, fui(f));
}

#define QIR_ALU0(name)                                                   \
static inline struct qreg                                                \
qir_##name(struct vc4_compile *c)                                        \
{                                                                        \
        return qir_emit_def(c, qir_inst(QOP_##name, c->undef,            \
                                        c->undef, c->undef));            \
}                                                                        \
static inline struct qinst *                                             \
qir_##name##_dest(struct vc4_compile *c, struct qreg dest)               \
{                                                                        \
        return qir_emit_nondef(c, qir_inst(QOP_##name, dest,             \
                                           c->undef, c->undef));         \
}

#define QIR_ALU1(name)                                                   \
static inline struct qreg                                                \
qir_##name(struct vc4_compile *c, struct qreg a)                         \
{                                                                        \
        return qir_emit_def(c, qir_inst(QOP_##name, c->undef,            \
                                        a, c->undef));                   \
}                                                                        \
static inline struct qinst *                                             \
qir_##name##_dest(struct vc4_compile *c, struct qreg dest,               \
                  struct qreg a)                                         \
{                                                                        \
        return qir_emit_nondef(c, qir_inst(QOP_##name, dest, a,          \
                                           c->undef));                   \
}

#define QIR_ALU2(name)                                                   \
static inline struct qreg                                                \
qir_##name(struct vc4_compile *c, struct qreg a, struct qreg b)          \
{                                                                        \
        return qir_emit_def(c, qir_inst(QOP_##name, c->undef, a, b));    \
}                                                                        \
static inline struct qinst *                                             \
qir_##name##_dest(struct vc4_compile *c, struct qreg dest,               \
                  struct qreg a, struct qreg b)                          \
{                                                                        \
        return qir_emit_nondef(c, qir_inst(QOP_##name, dest, a, b));     \
}

#define QIR_NODST_1(name)                                               \
static inline struct qinst *                                            \
qir_##name(struct vc4_compile *c, struct qreg a)                        \
{                                                                       \
        return qir_emit_nondef(c, qir_inst(QOP_##name, c->undef,        \
                                           a, c->undef));               \
}

#define QIR_NODST_2(name)                                               \
static inline struct qinst *                                            \
qir_##name(struct vc4_compile *c, struct qreg a, struct qreg b)         \
{                                                                       \
        return qir_emit_nondef(c, qir_inst(QOP_##name, c->undef,        \
                                           a, b));                      \
}

#define QIR_PAYLOAD(name)                                                \
static inline struct qreg                                                \
qir_##name(struct vc4_compile *c)                                        \
{                                                                        \
        struct qreg *payload = &c->payload_##name;                       \
        if (payload->file != QFILE_NULL)                                 \
                return *payload;                                         \
        *payload = qir_get_temp(c);                                      \
        struct qinst *inst = qir_inst(QOP_##name, *payload,              \
                                      c->undef, c->undef);               \
        struct qblock *entry = qir_entry_block(c);                       \
        list_add(&inst->link, &entry->instructions);                     \
        c->defs[payload->index] = inst;                                  \
        return *payload;                                                 \
}

QIR_ALU1(MOV)
QIR_ALU1(FMOV)
QIR_ALU1(MMOV)
QIR_ALU2(FADD)
QIR_ALU2(FSUB)
QIR_ALU2(FMUL)
QIR_ALU2(V8MULD)
QIR_ALU2(V8MIN)
QIR_ALU2(V8MAX)
QIR_ALU2(V8ADDS)
QIR_ALU2(V8SUBS)
QIR_ALU2(MUL24)
QIR_ALU2(FMIN)
QIR_ALU2(FMAX)
QIR_ALU2(FMINABS)
QIR_ALU2(FMAXABS)
QIR_ALU1(FTOI)
QIR_ALU1(ITOF)

QIR_ALU2(ADD)
QIR_ALU2(SUB)
QIR_ALU2(SHL)
QIR_ALU2(SHR)
QIR_ALU2(ASR)
QIR_ALU2(MIN)
QIR_ALU2(MIN_NOIMM)
QIR_ALU2(MAX)
QIR_ALU2(AND)
QIR_ALU2(OR)
QIR_ALU2(XOR)
QIR_ALU1(NOT)

QIR_ALU1(RCP)
QIR_ALU1(RSQ)
QIR_ALU1(EXP2)
QIR_ALU1(LOG2)
QIR_ALU1(VARY_ADD_C)
QIR_NODST_2(TEX_S)
QIR_NODST_2(TEX_T)
QIR_NODST_2(TEX_R)
QIR_NODST_2(TEX_B)
QIR_NODST_2(TEX_DIRECT)
QIR_PAYLOAD(FRAG_Z)
QIR_PAYLOAD(FRAG_W)
QIR_ALU0(TEX_RESULT)
QIR_ALU0(TLB_COLOR_READ)
QIR_NODST_1(MS_MASK)

static inline struct qreg
qir_SEL(struct vc4_compile *c, uint8_t cond, struct qreg src0, struct qreg src1)
{
        struct qreg t = qir_get_temp(c);
        struct qinst *a = qir_MOV_dest(c, t, src0);
        struct qinst *b = qir_MOV_dest(c, t, src1);
        a->cond = cond;
        b->cond = qpu_cond_complement(cond);
        return t;
}

static inline struct qreg
qir_UNPACK_8_F(struct vc4_compile *c, struct qreg src, int i)
{
        struct qreg t = qir_FMOV(c, src);
        c->defs[t.index]->src[0].pack = QPU_UNPACK_8A + i;
        return t;
}

static inline struct qreg
qir_UNPACK_8_I(struct vc4_compile *c, struct qreg src, int i)
{
        struct qreg t = qir_MOV(c, src);
        c->defs[t.index]->src[0].pack = QPU_UNPACK_8A + i;
        return t;
}

static inline struct qreg
qir_UNPACK_16_F(struct vc4_compile *c, struct qreg src, int i)
{
        struct qreg t = qir_FMOV(c, src);
        c->defs[t.index]->src[0].pack = QPU_UNPACK_16A + i;
        return t;
}

static inline struct qreg
qir_UNPACK_16_I(struct vc4_compile *c, struct qreg src, int i)
{
        struct qreg t = qir_MOV(c, src);
        c->defs[t.index]->src[0].pack = QPU_UNPACK_16A + i;
        return t;
}

static inline void
qir_PACK_8_F(struct vc4_compile *c, struct qreg dest, struct qreg val, int chan)
{
        assert(!dest.pack);
        dest.pack = QPU_PACK_MUL_8A + chan;
        qir_emit_nondef(c, qir_inst(QOP_MMOV, dest, val, c->undef));
}

static inline struct qreg
qir_PACK_8888_F(struct vc4_compile *c, struct qreg val)
{
        struct qreg dest = qir_MMOV(c, val);
        c->defs[dest.index]->dst.pack = QPU_PACK_MUL_8888;
        return dest;
}

static inline struct qreg
qir_POW(struct vc4_compile *c, struct qreg x, struct qreg y)
{
        return qir_EXP2(c, qir_FMUL(c,
                                    y,
                                    qir_LOG2(c, x)));
}

static inline void
qir_VPM_WRITE(struct vc4_compile *c, struct qreg val)
{
        qir_MOV_dest(c, qir_reg(QFILE_VPM, 0), val);
}

static inline struct qreg
qir_LOAD_IMM(struct vc4_compile *c, uint32_t val)
{
        return qir_emit_def(c, qir_inst(QOP_LOAD_IMM, c->undef,
                                        qir_reg(QFILE_LOAD_IMM, val), c->undef));
}

static inline struct qreg
qir_LOAD_IMM_U2(struct vc4_compile *c, uint32_t val)
{
        return qir_emit_def(c, qir_inst(QOP_LOAD_IMM_U2, c->undef,
                                        qir_reg(QFILE_LOAD_IMM, val),
                                        c->undef));
}

static inline struct qreg
qir_LOAD_IMM_I2(struct vc4_compile *c, uint32_t val)
{
        return qir_emit_def(c, qir_inst(QOP_LOAD_IMM_I2, c->undef,
                                        qir_reg(QFILE_LOAD_IMM, val),
                                        c->undef));
}

/** Shifts the multiply output to the right by rot channels */
static inline struct qreg
qir_ROT_MUL(struct vc4_compile *c, struct qreg val, uint32_t rot)
{
        return qir_emit_def(c, qir_inst(QOP_ROT_MUL, c->undef,
                                        val,
                                        qir_reg(QFILE_LOAD_IMM,
                                                QPU_SMALL_IMM_MUL_ROT + rot)));
}

static inline struct qinst *
qir_MOV_cond(struct vc4_compile *c, uint8_t cond,
             struct qreg dest, struct qreg src)
{
        struct qinst *mov = qir_MOV_dest(c, dest, src);
        mov->cond = cond;
        return mov;
}

static inline struct qinst *
qir_BRANCH(struct vc4_compile *c, uint8_t cond)
{
        struct qinst *inst = qir_inst(QOP_BRANCH, c->undef, c->undef, c->undef);
        inst->cond = cond;
        qir_emit_nondef(c, inst);
        return inst;
}

#define qir_for_each_block(block, c)                                    \
        list_for_each_entry(struct qblock, block, &c->blocks, link)

#define qir_for_each_block_rev(block, c)                                \
        list_for_each_entry_rev(struct qblock, block, &c->blocks, link)

/* Loop over the non-NULL members of the successors array. */
#define qir_for_each_successor(succ, block)                             \
        for (struct qblock *succ = block->successors[0];                \
             succ != NULL;                                              \
             succ = (succ == block->successors[1] ? NULL :              \
                     block->successors[1]))

#define qir_for_each_inst(inst, block)                                  \
        list_for_each_entry(struct qinst, inst, &block->instructions, link)

#define qir_for_each_inst_rev(inst, block)                                  \
        list_for_each_entry_rev(struct qinst, inst, &block->instructions, link)

#define qir_for_each_inst_safe(inst, block)                             \
        list_for_each_entry_safe(struct qinst, inst, &block->instructions, link)

#define qir_for_each_inst_inorder(inst, c)                              \
        qir_for_each_block(_block, c)                                   \
                qir_for_each_inst(inst, _block)

#endif /* VC4_QIR_H */
@


1.1
log
@Initial revision
@
text
@d35 1
a35 1
#include "glsl/nir/nir.h"
d40 3
d53 18
d85 5
d93 2
d98 5
d114 1
a120 17
        /* Note: Orderings of these compares must be the same as in
         * qpu_defines.h.  Selects the src[0] if the ns flag bit is set,
         * otherwise 0. */
        QOP_SEL_X_0_ZS,
        QOP_SEL_X_0_ZC,
        QOP_SEL_X_0_NS,
        QOP_SEL_X_0_NC,
        QOP_SEL_X_0_CS,
        QOP_SEL_X_0_CC,
        /* Selects the src[0] if the ns flag bit is set, otherwise src[1]. */
        QOP_SEL_X_Y_ZS,
        QOP_SEL_X_Y_ZC,
        QOP_SEL_X_Y_NS,
        QOP_SEL_X_Y_NC,
        QOP_SEL_X_Y_CS,
        QOP_SEL_X_Y_CC,

a128 9
        QOP_PACK_8888_F,
        QOP_PACK_8A_F,
        QOP_PACK_8B_F,
        QOP_PACK_8C_F,
        QOP_PACK_8D_F,
        QOP_TLB_DISCARD_SETUP,
        QOP_TLB_STENCIL_SETUP,
        QOP_TLB_Z_WRITE,
        QOP_TLB_COLOR_WRITE,
d130 1
a132 2
        QOP_FRAG_X,
        QOP_FRAG_Y,
a134 15
        QOP_FRAG_REV_FLAG,

        QOP_UNPACK_8A_F,
        QOP_UNPACK_8B_F,
        QOP_UNPACK_8C_F,
        QOP_UNPACK_8D_F,
        QOP_UNPACK_16A_F,
        QOP_UNPACK_16B_F,

        QOP_UNPACK_8A_I,
        QOP_UNPACK_8B_I,
        QOP_UNPACK_8C_I,
        QOP_UNPACK_8D_I,
        QOP_UNPACK_16A_I,
        QOP_UNPACK_16B_I,
d159 26
d199 2
d264 4
d279 2
d285 6
d293 2
a294 3
struct vc4_varying_semantic {
        uint8_t semantic;
        uint8_t index;
a326 4
                unsigned compare_mode:1;
                unsigned compare_func:3;
                unsigned wrap_s:3;
                unsigned wrap_t:3;
d328 12
d356 4
d370 1
a370 6
        /**
         * This is a proxy for the array of FS input semantics, which is
         * larger than we would want to put in the key.
         */
        uint64_t compiled_fs_id;

d374 33
d432 3
d447 5
d453 1
d455 2
d461 1
a461 1
         * Array of the TGSI semantics of all FS QFILE_VARY reads.
d466 3
a468 3
        struct vc4_varying_semantic *input_semantics;
        uint32_t num_input_semantics;
        uint32_t input_semantics_array_size;
d471 3
a473 3
         * An entry per outputs[] in the VS indicating what the semantic of
         * the output is.  Used to emit from the VS in the order that the FS
         * needs.
d475 1
a475 1
        struct vc4_varying_semantic *output_semantics;
d482 3
a491 1
        uint32_t output_clipvertex_index;
d494 1
d499 6
a504 2
        struct list_head instructions;
        uint32_t immediates[1024];
d507 1
d513 12
d527 1
d535 1
a535 4
/* Special offset for nir_load_uniform values to get a QUNIFORM_*
 * state-dependent value.
 */
#define VC4_NIR_STATE_UNIFORM_OFFSET		2000000000
d539 5
d555 1
d557 1
d559 2
a560 5
void qir_emit(struct vc4_compile *c, struct qinst *inst);
static inline void qir_emit_nodef(struct vc4_compile *c, struct qinst *inst)
{
        list_addtail(&inst->link, &c->instructions);
}
d563 1
a567 1
bool qir_is_multi_instruction(struct qinst *inst);
d569 1
d571 1
a573 1
bool qir_src_needs_a_file(struct qinst *inst);
d575 1
d581 2
a586 1
bool qir_opt_cse(struct vc4_compile *c);
d588 1
d590 3
a592 5
bool qir_opt_vpm_writes(struct vc4_compile *c);
void vc4_nir_lower_blend(struct vc4_compile *c);
void vc4_nir_lower_io(struct vc4_compile *c);
nir_ssa_def *vc4_nir_get_state_uniform(struct nir_builder *b,
                                       enum quniform_contents contents);
d595 1
d598 1
a598 1
void qpu_schedule_instructions(struct vc4_compile *c);
d618 8
a625 3
        struct qreg t = qir_get_temp(c);                                 \
        qir_emit(c, qir_inst(QOP_##name, t, c->undef, c->undef));        \
        return t;                                                        \
d632 2
a633 3
        struct qreg t = qir_get_temp(c);                                 \
        qir_emit(c, qir_inst(QOP_##name, t, a, c->undef));               \
        return t;                                                        \
d635 1
a635 1
static inline void                                                       \
d639 2
a640 1
        qir_emit_nodef(c, qir_inst(QOP_##name, dest, a, c->undef));      \
d647 1
a647 3
        struct qreg t = qir_get_temp(c);                                 \
        qir_emit(c, qir_inst(QOP_##name, t, a, b));                      \
        return t;                                                        \
d649 1
a649 1
static inline void                                                       \
d653 1
a653 1
        qir_emit_nodef(c, qir_inst(QOP_##name, dest, a, b));             \
d657 1
a657 1
static inline void                                                      \
d660 2
a661 1
        qir_emit(c, qir_inst(QOP_##name, c->undef, a, c->undef));       \
d665 1
a665 1
static inline void                                                      \
d668 2
a669 1
        qir_emit(c, qir_inst(QOP_##name, c->undef, a, b));       \
d672 1
a672 1
#define QIR_PACK(name)                                                   \
d674 1
a674 1
qir_##name(struct vc4_compile *c, struct qreg dest, struct qreg a)       \
d676 10
a685 2
        qir_emit_nodef(c, qir_inst(QOP_##name, dest, a, c->undef));      \
        return dest;                                                     \
d689 2
d694 5
a699 12
QIR_ALU1(SEL_X_0_ZS)
QIR_ALU1(SEL_X_0_ZC)
QIR_ALU1(SEL_X_0_NS)
QIR_ALU1(SEL_X_0_NC)
QIR_ALU1(SEL_X_0_CS)
QIR_ALU1(SEL_X_0_CC)
QIR_ALU2(SEL_X_Y_ZS)
QIR_ALU2(SEL_X_Y_ZC)
QIR_ALU2(SEL_X_Y_NS)
QIR_ALU2(SEL_X_Y_NC)
QIR_ALU2(SEL_X_Y_CS)
QIR_ALU2(SEL_X_Y_CC)
d713 1
a723 5
QIR_ALU1(PACK_8888_F)
QIR_PACK(PACK_8A_F)
QIR_PACK(PACK_8B_F)
QIR_PACK(PACK_8C_F)
QIR_PACK(PACK_8D_F)
d730 2
a731 5
QIR_ALU0(FRAG_X)
QIR_ALU0(FRAG_Y)
QIR_ALU0(FRAG_Z)
QIR_ALU0(FRAG_W)
QIR_ALU0(FRAG_REV_FLAG)
d734 12
a745 4
QIR_NODST_1(TLB_COLOR_WRITE)
QIR_NODST_1(TLB_Z_WRITE)
QIR_NODST_1(TLB_DISCARD_SETUP)
QIR_NODST_1(TLB_STENCIL_SETUP)
d750 2
a751 2
        struct qreg t = qir_get_temp(c);
        qir_emit(c, qir_inst(QOP_UNPACK_8A_F + i, t, src, c->undef));
d758 2
a759 2
        struct qreg t = qir_get_temp(c);
        qir_emit(c, qir_inst(QOP_UNPACK_8A_I + i, t, src, c->undef));
d766 2
a767 2
        struct qreg t = qir_get_temp(c);
        qir_emit(c, qir_inst(QOP_UNPACK_16A_F + i, t, src, c->undef));
d774 2
a775 2
        struct qreg t = qir_get_temp(c);
        qir_emit(c, qir_inst(QOP_UNPACK_16A_I + i, t, src, c->undef));
d779 8
d788 1
a788 1
qir_PACK_8_F(struct vc4_compile *c, struct qreg dest, struct qreg val, int chan)
d790 2
a791 3
        qir_emit(c, qir_inst(QOP_PACK_8A_F + chan, dest, val, c->undef));
        if (dest.file == QFILE_TEMP)
                c->defs[dest.index] = NULL;
d806 8
a813 2
        static const struct qreg vpm = { QFILE_VPM, 0 };
        qir_emit(c, qir_inst(QOP_MOV, vpm, val, c->undef));
d815 70
@


1.1.1.1
log
@import Mesa 11.0.6
@
text
@@


1.1.1.2
log
@Import Mesa 11.2.2
@
text
@d35 1
a35 1
#include "compiler/nir/nir.h"
a39 2
#include "vc4_qpu_defines.h"
#include "kernel/vc4_packet.h"
a66 2
        QOP_FMOV,
        QOP_MMOV,
a69 5
        QOP_V8MULD,
        QOP_V8MIN,
        QOP_V8MAX,
        QOP_V8ADDS,
        QOP_V8SUBS,
d87 17
d112 5
a120 1
        QOP_TLB_COLOR_WRITE_MS,
a121 1
        QOP_MS_MASK,
d130 14
a180 1
        uint8_t cond;
a243 2
        QUNIFORM_TEXTURE_MSAA_ADDR,

a254 2
        QUNIFORM_BLEND_CONST_COLOR_RGBA,
        QUNIFORM_BLEND_CONST_COLOR_AAAA,
a258 1
        QUNIFORM_SAMPLE_MASK,
d261 3
a263 2
struct vc4_varying_slot {
        uint8_t slot;
d296 4
a300 11
                union {
                        struct {
                                unsigned compare_mode:1;
                                unsigned compare_func:3;
                                unsigned wrap_s:3;
                                unsigned wrap_t:3;
                        };
                        struct {
                                uint16_t msaa_width, msaa_height;
                        };
                };
a316 4
        bool msaa;
        bool sample_coverage;
        bool sample_alpha_to_coverage;
        bool sample_alpha_to_one;
a360 3
        bool msaa_per_sample_output;
        struct qreg color_reads[VC4_MAX_SAMPLES];
        struct qreg sample_colors[VC4_MAX_SAMPLES];
a377 5
        /* Bitfield for whether a given channel of a sampler needs sRGB
         * decode.
         */
        uint8_t tex_srgb_decode[VC4_MAX_TEXTURE_SAMPLERS];

d379 1
a379 1
         * Array of the VARYING_SLOT_* of all FS QFILE_VARY reads.
d384 3
a386 3
        struct vc4_varying_slot *input_slots;
        uint32_t num_input_slots;
        uint32_t input_slots_array_size;
d389 3
a391 3
         * An entry per outputs[] in the VS indicating what the VARYING_SLOT_*
         * of the output is.  Used to emit from the VS in the order that the
         * FS needs.
d393 1
a393 1
        struct vc4_varying_slot *output_slots;
d407 1
a409 1
        uint32_t output_sample_mask_index;
a431 2
#define VC4_NIR_MS_MASK_OUTPUT			2000000000

d435 1
a435 1
#define VC4_NIR_STATE_UNIFORM_OFFSET		1000000000
a449 1
void qir_schedule_instructions(struct vc4_compile *c);
d453 1
a453 2
static inline struct qinst *
qir_emit_nodef(struct vc4_compile *c, struct qinst *inst)
a455 1
        return inst;
a464 1
bool qir_is_raw_mov(struct qinst *inst);
a465 1
bool qir_is_float_input(struct qinst *inst);
d468 1
a488 1
void vc4_nir_lower_txf_ms(struct vc4_compile *c);
d491 1
a491 1
uint32_t qpu_schedule_instructions(struct vc4_compile *c);
d524 1
a524 1
static inline struct qinst *                                             \
d528 1
a528 2
        return qir_emit_nodef(c, qir_inst(QOP_##name, dest, a,           \
                                          c->undef));                    \
a568 2
QIR_ALU1(FMOV)
QIR_ALU1(MMOV)
a571 5
QIR_ALU2(V8MULD)
QIR_ALU2(V8MIN)
QIR_ALU2(V8MAX)
QIR_ALU2(V8ADDS)
QIR_ALU2(V8SUBS)
d573 12
d608 5
a626 1
QIR_NODST_1(TLB_COLOR_WRITE_MS)
a629 1
QIR_NODST_1(MS_MASK)
d632 1
a632 1
qir_SEL(struct vc4_compile *c, uint8_t cond, struct qreg src0, struct qreg src1)
d635 1
a635 12
        struct qinst *a = qir_MOV_dest(c, t, src0);
        struct qinst *b = qir_MOV_dest(c, t, src1);
        a->cond = cond;
        b->cond = cond ^ 1;
        return t;
}

static inline struct qreg
qir_UNPACK_8_F(struct vc4_compile *c, struct qreg src, int i)
{
        struct qreg t = qir_FMOV(c, src);
        c->defs[t.index]->src[0].pack = QPU_UNPACK_8A + i;
d642 2
a643 2
        struct qreg t = qir_MOV(c, src);
        c->defs[t.index]->src[0].pack = QPU_UNPACK_8A + i;
d650 2
a651 2
        struct qreg t = qir_FMOV(c, src);
        c->defs[t.index]->src[0].pack = QPU_UNPACK_16A + i;
d658 2
a659 2
        struct qreg t = qir_MOV(c, src);
        c->defs[t.index]->src[0].pack = QPU_UNPACK_16A + i;
d663 1
a663 1
static inline void
d666 1
a666 3
        assert(!dest.pack);
        dest.pack = QPU_PACK_MUL_8A + chan;
        qir_emit(c, qir_inst(QOP_MMOV, dest, val, c->undef));
a668 7
}

static inline struct qreg
qir_PACK_8888_F(struct vc4_compile *c, struct qreg val)
{
        struct qreg dest = qir_MMOV(c, val);
        c->defs[dest.index]->dst.pack = QPU_PACK_MUL_8888;
@


1.1.1.3
log
@Import Mesa 13.0.2
@
text
@a40 1
#include "vc4_qpu.h"
a51 18
        QFILE_TLB_COLOR_WRITE,
        QFILE_TLB_COLOR_WRITE_MS,
        QFILE_TLB_Z_WRITE,
        QFILE_TLB_STENCIL_SETUP,

        /* Payload registers that aren't in the physical register file, so we
         * can just use the corresponding qpu_reg at qpu_emit time.
         */
        QFILE_FRAG_X,
        QFILE_FRAG_Y,
        QFILE_FRAG_REV_FLAG,
        QFILE_QPU_ELEMENT,

        /**
         * Stores an immediate value in the index field that will be used
         * directly by qpu_load_imm().
         */
        QFILE_LOAD_IMM,
a65 5
static inline struct qreg qir_reg(enum qfile file, uint32_t index)
{
        return (struct qreg){file, index};
}

d104 5
d113 2
d117 1
a141 26

        /* 32-bit immediate loaded to each SIMD channel */
        QOP_LOAD_IMM,

        /* 32-bit immediate divided into 16 2-bit unsigned int values and
         * loaded to each corresponding SIMD channel.
         */
        QOP_LOAD_IMM_U2,
        /* 32-bit immediate divided into 16 2-bit signed int values and
         * loaded to each corresponding SIMD channel.
         */
        QOP_LOAD_IMM_I2,

        QOP_ROT_MUL,

        /* Jumps to block->successor[0] if the qinst->cond (as a
         * QPU_COND_BRANCH_*) passes, or block->successor[1] if not.  Note
         * that block->successor[1] may be unset if the condition is ALWAYS.
         */
        QOP_BRANCH,

        /* Emits an ADD from src[0] to src[1], where src[0] must be a
         * QOP_LOAD_IMM result and src[1] is a QUNIFORM_UNIFORMS_ADDRESS,
         * required by the kernel as part of its branch validation.
         */
        QOP_UNIFORMS_RESET,
a155 1
        bool cond_is_exec_mask;
a219 2
        QUNIFORM_TEXTURE_FIRST_LEVEL,

a239 5

        /* Placeholder uniform that will be updated by the kernel when used by
         * an instruction writing to QPU_W_UNIFORMS_ADDRESS.
         */
        QUNIFORM_UNIFORMS_ADDRESS,
a282 1
                                bool force_first_level:1;
d318 6
a323 1
        const struct vc4_fs_inputs *fs_inputs;
a326 33
        bool clamp_color;
};

/** A basic block of QIR intructions. */
struct qblock {
        struct list_head link;

        struct list_head instructions;
        struct list_head qpu_inst_list;

        struct set *predecessors;
        struct qblock *successors[2];

        int index;

        /* Instruction IPs for the first and last instruction of the block.
         * Set by vc4_qpu_schedule.c.
         */
        uint32_t start_qpu_ip;
        uint32_t end_qpu_ip;

        /* Instruction IP for the branch instruction of the block.  Set by
         * vc4_qpu_schedule.c.
         */
        uint32_t branch_qpu_ip;

        /** @@{ used by vc4_qir_live_variables.c */
        BITSET_WORD *def;
        BITSET_WORD *use;
        BITSET_WORD *live_in;
        BITSET_WORD *live_out;
        int start_ip, end_ip;
        /** @@} */
a366 5
        /* State for whether we're executing on each channel currently.  0 if
         * yes, otherwise a block number + 1 that the channel jumped to.
         */
        struct qreg execute;

a367 1
        /** boolean (~0 -> true) if the fragment has been discarded. */
a368 2
        struct qreg payload_FRAG_Z;
        struct qreg payload_FRAG_W;
d372 5
a398 3
        /* Live ranges of temps. */
        int *temp_start, *temp_end;

d413 2
a414 6

        struct list_head blocks;
        int next_block_index;
        struct qblock *cur_block;
        struct qblock *loop_cont_block;
        struct qblock *loop_break_block;
a416 1

a421 12
        /**
         * Number of inputs from num_inputs remaining to be queued to the read
         * FIFO in the VS/CS.
         */
        uint32_t num_inputs_remaining;

        /* Number of inputs currently in the read FIFO for the VS/CS */
        uint32_t num_inputs_in_fifo;

        /** Next offset in the VPM to read from in the VS/CS */
        uint32_t vpm_read_offset;

a423 1
        bool failed;
d433 5
a439 5
struct qblock *qir_new_block(struct vc4_compile *c);
void qir_set_emit_block(struct vc4_compile *c, struct qblock *block);
void qir_link_blocks(struct qblock *predecessor, struct qblock *successor);
struct qblock *qir_entry_block(struct vc4_compile *c);
struct qblock *qir_exit_block(struct vc4_compile *c);
a452 1
void qir_emit_uniform_stream_resets(struct vc4_compile *c);
d454 7
a460 2
struct qreg qir_emit_def(struct vc4_compile *c, struct qinst *inst);
struct qinst *qir_emit_nondef(struct vc4_compile *c, struct qinst *inst);
a462 1
void qir_calculate_live_intervals(struct vc4_compile *c);
d467 1
a474 1
uint8_t qir_channels_written(struct qinst *inst);
a479 2
void qir_validate(struct vc4_compile *c);

d484 1
a485 1
bool qir_opt_peephole_sf(struct vc4_compile *c);
d487 5
a491 3
bool qir_opt_vpm(struct vc4_compile *c);
void vc4_nir_lower_blend(nir_shader *s, struct vc4_compile *c);
void vc4_nir_lower_io(nir_shader *s, struct vc4_compile *c);
d494 1
a494 1
void vc4_nir_lower_txf_ms(nir_shader *s, struct vc4_compile *c);
d517 3
a519 8
        return qir_emit_def(c, qir_inst(QOP_##name, c->undef,            \
                                        c->undef, c->undef));            \
}                                                                        \
static inline struct qinst *                                             \
qir_##name##_dest(struct vc4_compile *c, struct qreg dest)               \
{                                                                        \
        return qir_emit_nondef(c, qir_inst(QOP_##name, dest,             \
                                           c->undef, c->undef));         \
d526 3
a528 2
        return qir_emit_def(c, qir_inst(QOP_##name, c->undef,            \
                                        a, c->undef));                   \
d534 2
a535 2
        return qir_emit_nondef(c, qir_inst(QOP_##name, dest, a,          \
                                           c->undef));                   \
d542 3
a544 1
        return qir_emit_def(c, qir_inst(QOP_##name, c->undef, a, b));    \
d546 1
a546 1
static inline struct qinst *                                             \
d550 1
a550 1
        return qir_emit_nondef(c, qir_inst(QOP_##name, dest, a, b));     \
d554 1
a554 1
static inline struct qinst *                                            \
d557 1
a557 2
        return qir_emit_nondef(c, qir_inst(QOP_##name, c->undef,        \
                                           a, c->undef));               \
d561 1
a561 1
static inline struct qinst *                                            \
d564 1
a564 2
        return qir_emit_nondef(c, qir_inst(QOP_##name, c->undef,        \
                                           a, b));                      \
d567 1
a567 1
#define QIR_PAYLOAD(name)                                                \
d569 1
a569 1
qir_##name(struct vc4_compile *c)                                        \
d571 2
a572 10
        struct qreg *payload = &c->payload_##name;                       \
        if (payload->file != QFILE_NULL)                                 \
                return *payload;                                         \
        *payload = qir_get_temp(c);                                      \
        struct qinst *inst = qir_inst(QOP_##name, *payload,              \
                                      c->undef, c->undef);               \
        struct qblock *entry = qir_entry_block(c);                       \
        list_add(&inst->link, &entry->instructions);                     \
        c->defs[payload->index] = inst;                                  \
        return *payload;                                                 \
d616 5
a620 2
QIR_PAYLOAD(FRAG_Z)
QIR_PAYLOAD(FRAG_W)
d623 5
d637 1
a637 1
        b->cond = qpu_cond_complement(cond);
d678 3
a680 1
        qir_emit_nondef(c, qir_inst(QOP_MMOV, dest, val, c->undef));
d702 2
a703 1
        qir_MOV_dest(c, qir_reg(QFILE_VPM, 0), val);
a704 77

static inline struct qreg
qir_LOAD_IMM(struct vc4_compile *c, uint32_t val)
{
        return qir_emit_def(c, qir_inst(QOP_LOAD_IMM, c->undef,
                                        qir_reg(QFILE_LOAD_IMM, val), c->undef));
}

static inline struct qreg
qir_LOAD_IMM_U2(struct vc4_compile *c, uint32_t val)
{
        return qir_emit_def(c, qir_inst(QOP_LOAD_IMM_U2, c->undef,
                                        qir_reg(QFILE_LOAD_IMM, val),
                                        c->undef));
}

static inline struct qreg
qir_LOAD_IMM_I2(struct vc4_compile *c, uint32_t val)
{
        return qir_emit_def(c, qir_inst(QOP_LOAD_IMM_I2, c->undef,
                                        qir_reg(QFILE_LOAD_IMM, val),
                                        c->undef));
}

/** Shifts the multiply output to the right by rot channels */
static inline struct qreg
qir_ROT_MUL(struct vc4_compile *c, struct qreg val, uint32_t rot)
{
        return qir_emit_def(c, qir_inst(QOP_ROT_MUL, c->undef,
                                        val,
                                        qir_reg(QFILE_LOAD_IMM,
                                                QPU_SMALL_IMM_MUL_ROT + rot)));
}

static inline struct qinst *
qir_MOV_cond(struct vc4_compile *c, uint8_t cond,
             struct qreg dest, struct qreg src)
{
        struct qinst *mov = qir_MOV_dest(c, dest, src);
        mov->cond = cond;
        return mov;
}

static inline struct qinst *
qir_BRANCH(struct vc4_compile *c, uint8_t cond)
{
        struct qinst *inst = qir_inst(QOP_BRANCH, c->undef, c->undef, c->undef);
        inst->cond = cond;
        qir_emit_nondef(c, inst);
        return inst;
}

#define qir_for_each_block(block, c)                                    \
        list_for_each_entry(struct qblock, block, &c->blocks, link)

#define qir_for_each_block_rev(block, c)                                \
        list_for_each_entry_rev(struct qblock, block, &c->blocks, link)

/* Loop over the non-NULL members of the successors array. */
#define qir_for_each_successor(succ, block)                             \
        for (struct qblock *succ = block->successors[0];                \
             succ != NULL;                                              \
             succ = (succ == block->successors[1] ? NULL :              \
                     block->successors[1]))

#define qir_for_each_inst(inst, block)                                  \
        list_for_each_entry(struct qinst, inst, &block->instructions, link)

#define qir_for_each_inst_rev(inst, block)                                  \
        list_for_each_entry_rev(struct qinst, inst, &block->instructions, link)

#define qir_for_each_inst_safe(inst, block)                             \
        list_for_each_entry_safe(struct qinst, inst, &block->instructions, link)

#define qir_for_each_inst_inorder(inst, c)                              \
        qir_for_each_block(_block, c)                                   \
                qir_for_each_inst(inst, _block)
@


1.1.1.4
log
@Import Mesa 13.0.5
@
text
@a113 1
        QOP_MIN_NOIMM,
a711 1
QIR_ALU2(MIN_NOIMM)
@


1.1.1.5
log
@Import Mesa 17.1.6
@
text
@a57 12
        /* If tex_s is written on its own without preceding t/r/b setup, it's
         * a direct memory access using the input value, without the sideband
         * uniform load.  We represent these in QIR as a separate write
         * destination so we can tell if the sideband uniform is present.
         */
        QFILE_TEX_S_DIRECT,

        QFILE_TEX_S,
        QFILE_TEX_T,
        QFILE_TEX_R,
        QFILE_TEX_B,

d136 18
a159 10
        /**
         * Insert the signal for switching threads in a threaded fragment
         * shader.  No value can be live in an accumulator across a thrsw.
         *
         * At the QPU level, this will have several delay slots before the
         * switch happens.  Those slots are the responsibility of the
         * scheduler.
         */
        QOP_THRSW,

d197 1
a197 1
        struct qreg src[3];
a504 1
        struct qblock *last_top_block;
a507 3
        /* Pre-QPU-scheduled instruction containing the last THRSW */
        uint64_t *last_thrsw;

a526 9

        /* Set to compile program in threaded FS mode, where SIG_THREAD_SWITCH
         * is used to hide texturing latency at the cost of limiting ourselves
         * to the bottom half of physical reg space.
         */
        bool fs_threaded;

        bool last_thrsw_at_top_level;

d546 5
d564 1
a564 3
int qir_get_nsrc(struct qinst *inst);
int qir_get_non_sideband_nsrc(struct qinst *inst);
int qir_get_tex_uniform_src(struct qinst *inst);
a567 1
bool qir_has_uniform_read(struct qinst *inst);
a570 1
bool qir_has_implicit_tex_uniform(struct qinst *inst);
a584 1
bool qir_opt_coalesce_ff_writes(struct vc4_compile *c);
d725 5
d740 4
a743 2
        qir_MOV_dest(c, t, src1);
        qir_MOV_dest(c, t, src0)->cond = cond;
d884 1
a884 1
                qir_for_each_inst_safe(inst, _block)
@


