head	1.2;
access;
symbols
	OPENBSD_6_2:1.2.0.2
	OPENBSD_6_2_BASE:1.2
	mesa-17_1_6:1.1.1.5
	OPENBSD_6_1:1.1.1.4.0.2
	OPENBSD_6_1_BASE:1.1.1.4
	mesa-13_0_6:1.1.1.4
	mesa-13_0_5:1.1.1.4
	mesa-13_0_3:1.1.1.3
	mesa-13_0_2:1.1.1.3
	OPENBSD_6_0:1.1.1.2.0.4
	OPENBSD_6_0_BASE:1.1.1.2
	mesa-11_2_2:1.1.1.2
	OPENBSD_5_9:1.1.1.1.0.2
	OPENBSD_5_9_BASE:1.1.1.1
	mesa-11_0_9:1.1.1.1
	mesa-11_0_8:1.1.1.1
	mesa-11_0_6:1.1.1.1
	mesa:1.1.1;
locks; strict;
comment	@ * @;


1.2
date	2017.08.26.16.59.30;	author jsg;	state Exp;
branches;
next	1.1;
commitid	D0k2io1oY8gcsQ2S;

1.1
date	2015.11.22.02.41.56;	author jsg;	state Exp;
branches
	1.1.1.1;
next	;
commitid	bJUptkbooQfJPk5r;

1.1.1.1
date	2015.11.22.02.41.56;	author jsg;	state Exp;
branches;
next	1.1.1.2;
commitid	bJUptkbooQfJPk5r;

1.1.1.2
date	2016.05.29.10.17.24;	author jsg;	state Exp;
branches;
next	1.1.1.3;
commitid	OwGfrJACrYJkCVJ4;

1.1.1.3
date	2016.12.11.08.30.59;	author jsg;	state Exp;
branches;
next	1.1.1.4;
commitid	uuv5VTS15jglEDZU;

1.1.1.4
date	2017.02.26.12.11.32;	author jsg;	state Exp;
branches;
next	1.1.1.5;
commitid	xZcdklZavddTKAf1;

1.1.1.5
date	2017.08.14.09.35.38;	author jsg;	state Exp;
branches;
next	;
commitid	enNyoMGkcgwM3Ww6;


desc
@@


1.2
log
@Revert to Mesa 13.0.6 to hopefully address rendering issues a handful of
people have reported with xpdf/fvwm on ivy bridge with modesetting driver.
@
text
@/**************************************************************************
 *
 * Copyright 2010 Thomas Balling SÃ¸rensen & Orasanu Lucian.
 * Copyright 2014 Advanced Micro Devices, Inc.
 * All Rights Reserved.
 *
 * Permission is hereby granted, free of charge, to any person obtaining a
 * copy of this software and associated documentation files (the
 * "Software"), to deal in the Software without restriction, including
 * without limitation the rights to use, copy, modify, merge, publish,
 * distribute, sub license, and/or sell copies of the Software, and to
 * permit persons to whom the Software is furnished to do so, subject to
 * the following conditions:
 *
 * The above copyright notice and this permission notice (including the
 * next paragraph) shall be included in all copies or substantial portions
 * of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
 * OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT.
 * IN NO EVENT SHALL THE COPYRIGHT HOLDER(S) OR AUTHOR(S) BE LIABLE FOR
 * ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
 * SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 *
 **************************************************************************/

#include "pipe/p_video_codec.h"

#include "util/u_handle_table.h"
#include "util/u_video.h"

#include "vl/vl_vlc.h"
#include "vl/vl_winsys.h"

#include "va_private.h"

VAStatus
vlVaBeginPicture(VADriverContextP ctx, VAContextID context_id, VASurfaceID render_target)
{
   vlVaDriver *drv;
   vlVaContext *context;
   vlVaSurface *surf;

   if (!ctx)
      return VA_STATUS_ERROR_INVALID_CONTEXT;

   drv = VL_VA_DRIVER(ctx);
   if (!drv)
      return VA_STATUS_ERROR_INVALID_CONTEXT;

   pipe_mutex_lock(drv->mutex);
   context = handle_table_get(drv->htab, context_id);
   if (!context) {
      pipe_mutex_unlock(drv->mutex);
      return VA_STATUS_ERROR_INVALID_CONTEXT;
   }

   surf = handle_table_get(drv->htab, render_target);
   pipe_mutex_unlock(drv->mutex);
   if (!surf || !surf->buffer)
      return VA_STATUS_ERROR_INVALID_SURFACE;

   context->target_id = render_target;
   surf->ctx = context_id;
   context->target = surf->buffer;

   if (!context->decoder) {

      /* VPP */
      if (context->templat.profile == PIPE_VIDEO_PROFILE_UNKNOWN &&
          context->target->buffer_format != PIPE_FORMAT_B8G8R8A8_UNORM &&
          context->target->buffer_format != PIPE_FORMAT_R8G8B8A8_UNORM &&
          context->target->buffer_format != PIPE_FORMAT_B8G8R8X8_UNORM &&
          context->target->buffer_format != PIPE_FORMAT_R8G8B8X8_UNORM &&
          context->target->buffer_format != PIPE_FORMAT_NV12)
         return VA_STATUS_ERROR_UNIMPLEMENTED;

      return VA_STATUS_SUCCESS;
   }

   if (context->decoder->entrypoint != PIPE_VIDEO_ENTRYPOINT_ENCODE)
      context->needs_begin_frame = true;

   return VA_STATUS_SUCCESS;
}

void
vlVaGetReferenceFrame(vlVaDriver *drv, VASurfaceID surface_id,
                      struct pipe_video_buffer **ref_frame)
{
   vlVaSurface *surf = handle_table_get(drv->htab, surface_id);
   if (surf)
      *ref_frame = surf->buffer;
   else
      *ref_frame = NULL;
}

static void
getEncParamPreset(vlVaContext *context)
{
   //motion estimation preset
   context->desc.h264enc.motion_est.motion_est_quarter_pixel = 0x00000001;
   context->desc.h264enc.motion_est.lsmvert = 0x00000002;
   context->desc.h264enc.motion_est.enc_disable_sub_mode = 0x00000078;
   context->desc.h264enc.motion_est.enc_en_ime_overw_dis_subm = 0x00000001;
   context->desc.h264enc.motion_est.enc_ime_overw_dis_subm_no = 0x00000001;
   context->desc.h264enc.motion_est.enc_ime2_search_range_x = 0x00000004;
   context->desc.h264enc.motion_est.enc_ime2_search_range_y = 0x00000004;

   //pic control preset
   context->desc.h264enc.pic_ctrl.enc_cabac_enable = 0x00000001;
   context->desc.h264enc.pic_ctrl.enc_constraint_set_flags = 0x00000040;

   //rate control
   context->desc.h264enc.rate_ctrl.vbv_buffer_size = 20000000;
   context->desc.h264enc.rate_ctrl.vbv_buf_lv = 48;
   context->desc.h264enc.rate_ctrl.fill_data_enable = 1;
   context->desc.h264enc.rate_ctrl.enforce_hrd = 1;
   context->desc.h264enc.enable_vui = false;
   if (context->desc.h264enc.rate_ctrl.frame_rate_num == 0)
      context->desc.h264enc.rate_ctrl.frame_rate_num = 30;
   context->desc.h264enc.rate_ctrl.target_bits_picture =
      context->desc.h264enc.rate_ctrl.target_bitrate / context->desc.h264enc.rate_ctrl.frame_rate_num;
   context->desc.h264enc.rate_ctrl.peak_bits_picture_integer =
      context->desc.h264enc.rate_ctrl.peak_bitrate / context->desc.h264enc.rate_ctrl.frame_rate_num;
   context->desc.h264enc.rate_ctrl.peak_bits_picture_fraction = 0;

   context->desc.h264enc.ref_pic_mode = 0x00000201;
}

static VAStatus
handlePictureParameterBuffer(vlVaDriver *drv, vlVaContext *context, vlVaBuffer *buf)
{
   VAStatus vaStatus = VA_STATUS_SUCCESS;

   switch (u_reduce_video_profile(context->templat.profile)) {
   case PIPE_VIDEO_FORMAT_MPEG12:
      vlVaHandlePictureParameterBufferMPEG12(drv, context, buf);
      break;

   case PIPE_VIDEO_FORMAT_MPEG4_AVC:
      vlVaHandlePictureParameterBufferH264(drv, context, buf);
      break;

   case PIPE_VIDEO_FORMAT_VC1:
      vlVaHandlePictureParameterBufferVC1(drv, context, buf);
      break;

   case PIPE_VIDEO_FORMAT_MPEG4:
      vlVaHandlePictureParameterBufferMPEG4(drv, context, buf);
      break;

  case PIPE_VIDEO_FORMAT_HEVC:
      vlVaHandlePictureParameterBufferHEVC(drv, context, buf);
      break;

   default:
      break;
   }

   /* Create the decoder once max_references is known. */
   if (!context->decoder) {
      if (!context->target)
         return VA_STATUS_ERROR_INVALID_CONTEXT;

      if (context->templat.max_references == 0)
         return VA_STATUS_ERROR_INVALID_BUFFER;

      if (u_reduce_video_profile(context->templat.profile) ==
          PIPE_VIDEO_FORMAT_MPEG4_AVC)
         context->templat.level = u_get_h264_level(context->templat.width,
            context->templat.height, &context->templat.max_references);

      context->decoder = drv->pipe->create_video_codec(drv->pipe,
         &context->templat);

      if (!context->decoder)
         return VA_STATUS_ERROR_ALLOCATION_FAILED;

      context->needs_begin_frame = true;
   }

   return vaStatus;
}

static void
handleIQMatrixBuffer(vlVaContext *context, vlVaBuffer *buf)
{
   switch (u_reduce_video_profile(context->templat.profile)) {
   case PIPE_VIDEO_FORMAT_MPEG12:
      vlVaHandleIQMatrixBufferMPEG12(context, buf);
      break;

   case PIPE_VIDEO_FORMAT_MPEG4_AVC:
      vlVaHandleIQMatrixBufferH264(context, buf);
      break;

   case PIPE_VIDEO_FORMAT_MPEG4:
      vlVaHandleIQMatrixBufferMPEG4(context, buf);
      break;

   case PIPE_VIDEO_FORMAT_HEVC:
      vlVaHandleIQMatrixBufferHEVC(context, buf);
      break;

   default:
      break;
   }
}

static void
handleSliceParameterBuffer(vlVaContext *context, vlVaBuffer *buf)
{
   switch (u_reduce_video_profile(context->templat.profile)) {
   case PIPE_VIDEO_FORMAT_MPEG12:
      vlVaHandleSliceParameterBufferMPEG12(context, buf);
      break;

   case PIPE_VIDEO_FORMAT_VC1:
      vlVaHandleSliceParameterBufferVC1(context, buf);
      break;

   case PIPE_VIDEO_FORMAT_MPEG4_AVC:
      vlVaHandleSliceParameterBufferH264(context, buf);
      break;

   case PIPE_VIDEO_FORMAT_MPEG4:
      vlVaHandleSliceParameterBufferMPEG4(context, buf);
      break;

   case PIPE_VIDEO_FORMAT_HEVC:
      vlVaHandleSliceParameterBufferHEVC(context, buf);
      break;

   default:
      break;
   }
}

static unsigned int
bufHasStartcode(vlVaBuffer *buf, unsigned int code, unsigned int bits)
{
   struct vl_vlc vlc = {0};
   int i;

   /* search the first 64 bytes for a startcode */
   vl_vlc_init(&vlc, 1, (const void * const*)&buf->data, &buf->size);
   for (i = 0; i < 64 && vl_vlc_bits_left(&vlc) >= bits; ++i) {
      if (vl_vlc_peekbits(&vlc, bits) == code)
         return 1;
      vl_vlc_eatbits(&vlc, 8);
      vl_vlc_fillbits(&vlc);
   }

   return 0;
}

static void
handleVASliceDataBufferType(vlVaContext *context, vlVaBuffer *buf)
{
   enum pipe_video_format format;
   unsigned num_buffers = 0;
   void * const *buffers[2];
   unsigned sizes[2];
   static const uint8_t start_code_h264[] = { 0x00, 0x00, 0x01 };
   static const uint8_t start_code_h265[] = { 0x00, 0x00, 0x01 };
   static const uint8_t start_code_vc1[] = { 0x00, 0x00, 0x01, 0x0d };

   format = u_reduce_video_profile(context->templat.profile);
   switch (format) {
   case PIPE_VIDEO_FORMAT_MPEG4_AVC:
      if (bufHasStartcode(buf, 0x000001, 24))
         break;

      buffers[num_buffers] = (void *const)&start_code_h264;
      sizes[num_buffers++] = sizeof(start_code_h264);
      break;
   case PIPE_VIDEO_FORMAT_HEVC:
      if (bufHasStartcode(buf, 0x000001, 24))
         break;

      buffers[num_buffers] = (void *const)&start_code_h265;
      sizes[num_buffers++] = sizeof(start_code_h265);
      break;
   case PIPE_VIDEO_FORMAT_VC1:
      if (bufHasStartcode(buf, 0x0000010d, 32) ||
          bufHasStartcode(buf, 0x0000010c, 32) ||
          bufHasStartcode(buf, 0x0000010b, 32))
         break;

      if (context->decoder->profile == PIPE_VIDEO_PROFILE_VC1_ADVANCED) {
         buffers[num_buffers] = (void *const)&start_code_vc1;
         sizes[num_buffers++] = sizeof(start_code_vc1);
      }
      break;
   case PIPE_VIDEO_FORMAT_MPEG4:
      if (bufHasStartcode(buf, 0x000001, 24))
         break;

      vlVaDecoderFixMPEG4Startcode(context);
      buffers[num_buffers] = (void *)context->mpeg4.start_code;
      sizes[num_buffers++] = context->mpeg4.start_code_size;
   default:
      break;
   }

   buffers[num_buffers] = buf->data;
   sizes[num_buffers] = buf->size;
   ++num_buffers;

   if (context->needs_begin_frame) {
      context->decoder->begin_frame(context->decoder, context->target,
         &context->desc.base);
      context->needs_begin_frame = false;
   }
   context->decoder->decode_bitstream(context->decoder, context->target, &context->desc.base,
      num_buffers, (const void * const*)buffers, sizes);
}

static VAStatus
handleVAEncMiscParameterTypeRateControl(vlVaContext *context, VAEncMiscParameterBuffer *misc)
{
   VAEncMiscParameterRateControl *rc = (VAEncMiscParameterRateControl *)misc->data;
   if (context->desc.h264enc.rate_ctrl.rate_ctrl_method ==
       PIPE_H264_ENC_RATE_CONTROL_METHOD_CONSTANT)
      context->desc.h264enc.rate_ctrl.target_bitrate = rc->bits_per_second;
   else
      context->desc.h264enc.rate_ctrl.target_bitrate = rc->bits_per_second * (rc->target_percentage / 100.0);
   context->desc.h264enc.rate_ctrl.peak_bitrate = rc->bits_per_second;
   if (context->desc.h264enc.rate_ctrl.target_bitrate < 2000000)
      context->desc.h264enc.rate_ctrl.vbv_buffer_size = MIN2((context->desc.h264enc.rate_ctrl.target_bitrate * 2.75), 2000000);
   else
      context->desc.h264enc.rate_ctrl.vbv_buffer_size = context->desc.h264enc.rate_ctrl.target_bitrate;

   return VA_STATUS_SUCCESS;
}

static VAStatus
handleVAEncMiscParameterTypeFrameRate(vlVaContext *context, VAEncMiscParameterBuffer *misc)
{
   VAEncMiscParameterFrameRate *fr = (VAEncMiscParameterFrameRate *)misc->data;
   context->desc.h264enc.rate_ctrl.frame_rate_num = fr->framerate;
   return VA_STATUS_SUCCESS;
}

static VAStatus
handleVAEncSequenceParameterBufferType(vlVaDriver *drv, vlVaContext *context, vlVaBuffer *buf)
{
   VAEncSequenceParameterBufferH264 *h264 = (VAEncSequenceParameterBufferH264 *)buf->data;
   if (!context->decoder) {
      context->templat.max_references = h264->max_num_ref_frames;
      context->templat.level = h264->level_idc;
      context->decoder = drv->pipe->create_video_codec(drv->pipe, &context->templat);
      if (!context->decoder)
         return VA_STATUS_ERROR_ALLOCATION_FAILED;
   }
   context->desc.h264enc.gop_size = h264->intra_idr_period;
   context->desc.h264enc.rate_ctrl.frame_rate_num = h264->time_scale / 2;
   context->desc.h264enc.rate_ctrl.frame_rate_den = 1;
   return VA_STATUS_SUCCESS;
}

static VAStatus
handleVAEncMiscParameterBufferType(vlVaContext *context, vlVaBuffer *buf)
{
   VAStatus vaStatus = VA_STATUS_SUCCESS;
   VAEncMiscParameterBuffer *misc;
   misc = buf->data;

   switch (misc->type) {
   case VAEncMiscParameterTypeRateControl:
      vaStatus = handleVAEncMiscParameterTypeRateControl(context, misc);
      break;

   case VAEncMiscParameterTypeFrameRate:
      vaStatus = handleVAEncMiscParameterTypeFrameRate(context, misc);
      break;

   default:
      break;
   }

   return vaStatus;
}

static VAStatus
handleVAEncPictureParameterBufferType(vlVaDriver *drv, vlVaContext *context, vlVaBuffer *buf)
{
   VAEncPictureParameterBufferH264 *h264;
   vlVaBuffer *coded_buf;

   h264 = buf->data;
   context->desc.h264enc.frame_num = h264->frame_num;
   context->desc.h264enc.not_referenced = false;
   context->desc.h264enc.is_idr = (h264->pic_fields.bits.idr_pic_flag == 1);
   context->desc.h264enc.pic_order_cnt = h264->CurrPic.TopFieldOrderCnt;
   if (context->desc.h264enc.is_idr)
      context->desc.h264enc.i_remain = 1;
   else
      context->desc.h264enc.i_remain = 0;

   context->desc.h264enc.p_remain = context->desc.h264enc.gop_size - context->desc.h264enc.gop_cnt - context->desc.h264enc.i_remain;

   coded_buf = handle_table_get(drv->htab, h264->coded_buf);
   if (!coded_buf->derived_surface.resource)
      coded_buf->derived_surface.resource = pipe_buffer_create(drv->pipe->screen, PIPE_BIND_VERTEX_BUFFER,
                                            PIPE_USAGE_STREAM, coded_buf->size);
   context->coded_buf = coded_buf;

   context->desc.h264enc.frame_idx[h264->CurrPic.picture_id] = h264->frame_num;
   if (context->desc.h264enc.is_idr)
      context->desc.h264enc.picture_type = PIPE_H264_ENC_PICTURE_TYPE_IDR;
   else
      context->desc.h264enc.picture_type = PIPE_H264_ENC_PICTURE_TYPE_P;

   context->desc.h264enc.quant_i_frames = h264->pic_init_qp;
   context->desc.h264enc.quant_b_frames = h264->pic_init_qp;
   context->desc.h264enc.quant_p_frames = h264->pic_init_qp;
   context->desc.h264enc.frame_num_cnt++;
   context->desc.h264enc.gop_cnt++;
   if (context->desc.h264enc.gop_cnt == context->desc.h264enc.gop_size)
      context->desc.h264enc.gop_cnt = 0;

   return VA_STATUS_SUCCESS;
}

static VAStatus
handleVAEncSliceParameterBufferType(vlVaDriver *drv, vlVaContext *context, vlVaBuffer *buf)
{
   VAEncSliceParameterBufferH264 *h264;

   h264 = buf->data;
   context->desc.h264enc.ref_idx_l0 = VA_INVALID_ID;
   context->desc.h264enc.ref_idx_l1 = VA_INVALID_ID;

   for (int i = 0; i < 32; i++) {
      if (h264->RefPicList0[i].picture_id != VA_INVALID_ID) {
         if (context->desc.h264enc.ref_idx_l0 == VA_INVALID_ID)
            context->desc.h264enc.ref_idx_l0 = context->desc.h264enc.frame_idx[h264->RefPicList0[i].picture_id];
      }
      if (h264->RefPicList1[i].picture_id != VA_INVALID_ID && h264->slice_type == 1) {
         if (context->desc.h264enc.ref_idx_l1 == VA_INVALID_ID)
            context->desc.h264enc.ref_idx_l1 = context->desc.h264enc.frame_idx[h264->RefPicList1[i].picture_id];
      }
   }

   if (h264->slice_type == 1)
      context->desc.h264enc.picture_type = PIPE_H264_ENC_PICTURE_TYPE_B;
   else if (h264->slice_type == 0)
      context->desc.h264enc.picture_type = PIPE_H264_ENC_PICTURE_TYPE_P;
   else if (h264->slice_type == 2) {
      if (context->desc.h264enc.is_idr){
         context->desc.h264enc.picture_type = PIPE_H264_ENC_PICTURE_TYPE_IDR;
         context->desc.h264enc.idr_pic_id++;
	   } else
         context->desc.h264enc.picture_type = PIPE_H264_ENC_PICTURE_TYPE_I;
   } else
      context->desc.h264enc.picture_type = PIPE_H264_ENC_PICTURE_TYPE_SKIP;

   return VA_STATUS_SUCCESS;
}

VAStatus
vlVaRenderPicture(VADriverContextP ctx, VAContextID context_id, VABufferID *buffers, int num_buffers)
{
   vlVaDriver *drv;
   vlVaContext *context;
   VAStatus vaStatus = VA_STATUS_SUCCESS;

   unsigned i;

   if (!ctx)
      return VA_STATUS_ERROR_INVALID_CONTEXT;

   drv = VL_VA_DRIVER(ctx);
   if (!drv)
      return VA_STATUS_ERROR_INVALID_CONTEXT;

   pipe_mutex_lock(drv->mutex);
   context = handle_table_get(drv->htab, context_id);
   if (!context) {
      pipe_mutex_unlock(drv->mutex);
      return VA_STATUS_ERROR_INVALID_CONTEXT;
   }

   for (i = 0; i < num_buffers; ++i) {
      vlVaBuffer *buf = handle_table_get(drv->htab, buffers[i]);
      if (!buf) {
         pipe_mutex_unlock(drv->mutex);
         return VA_STATUS_ERROR_INVALID_BUFFER;
      }

      switch (buf->type) {
      case VAPictureParameterBufferType:
         vaStatus = handlePictureParameterBuffer(drv, context, buf);
         break;

      case VAIQMatrixBufferType:
         handleIQMatrixBuffer(context, buf);
         break;

      case VASliceParameterBufferType:
         handleSliceParameterBuffer(context, buf);
         break;

      case VASliceDataBufferType:
         handleVASliceDataBufferType(context, buf);
         break;
      case VAProcPipelineParameterBufferType:
         vaStatus = vlVaHandleVAProcPipelineParameterBufferType(drv, context, buf);
         break;

      case VAEncSequenceParameterBufferType:
         vaStatus = handleVAEncSequenceParameterBufferType(drv, context, buf);
         break;

      case VAEncMiscParameterBufferType:
         vaStatus = handleVAEncMiscParameterBufferType(context, buf);
         break;

      case VAEncPictureParameterBufferType:
         vaStatus = handleVAEncPictureParameterBufferType(drv, context, buf);
         break;

      case VAEncSliceParameterBufferType:
         vaStatus = handleVAEncSliceParameterBufferType(drv, context, buf);
         break;

      default:
         break;
      }
   }
   pipe_mutex_unlock(drv->mutex);

   return vaStatus;
}

VAStatus
vlVaEndPicture(VADriverContextP ctx, VAContextID context_id)
{
   vlVaDriver *drv;
   vlVaContext *context;
   vlVaBuffer *coded_buf;
   vlVaSurface *surf;
   void *feedback;

   if (!ctx)
      return VA_STATUS_ERROR_INVALID_CONTEXT;

   drv = VL_VA_DRIVER(ctx);
   if (!drv)
      return VA_STATUS_ERROR_INVALID_CONTEXT;

   pipe_mutex_lock(drv->mutex);
   context = handle_table_get(drv->htab, context_id);
   pipe_mutex_unlock(drv->mutex);
   if (!context)
      return VA_STATUS_ERROR_INVALID_CONTEXT;

   if (!context->decoder) {
      if (context->templat.profile != PIPE_VIDEO_PROFILE_UNKNOWN)
         return VA_STATUS_ERROR_INVALID_CONTEXT;

      /* VPP */
      return VA_STATUS_SUCCESS;
   }

   pipe_mutex_lock(drv->mutex);
   surf = handle_table_get(drv->htab, context->target_id);
   context->mpeg4.frame_num++;

   if (context->decoder->entrypoint == PIPE_VIDEO_ENTRYPOINT_ENCODE) {
      coded_buf = context->coded_buf;
      getEncParamPreset(context);
      context->decoder->begin_frame(context->decoder, context->target, &context->desc.base);
      context->decoder->encode_bitstream(context->decoder, context->target,
                                         coded_buf->derived_surface.resource, &feedback);
      surf->frame_num_cnt = context->desc.h264enc.frame_num_cnt;
      surf->feedback = feedback;
      surf->coded_buf = coded_buf;
   }

   context->decoder->end_frame(context->decoder, context->target, &context->desc.base);
   if (context->decoder->entrypoint == PIPE_VIDEO_ENTRYPOINT_ENCODE &&
       context->desc.h264enc.p_remain == 1)
      context->decoder->flush(context->decoder);
   pipe_mutex_unlock(drv->mutex);
   return VA_STATUS_SUCCESS;
}
@


1.1
log
@Initial revision
@
text
@d35 1
d53 1
d55 2
a56 1
   if (!context)
d58 1
d61 1
d65 2
d68 17
a84 1
   context->decoder->begin_frame(context->decoder, context->target, &context->desc.base);
d89 3
a91 3
static void
getReferenceFrame(vlVaDriver *drv, VASurfaceID surface_id,
                  struct pipe_video_buffer **ref_frame)
d101 33
d136 1
a136 9
   VAPictureParameterBufferMPEG2 *mpeg2;
   VAPictureParameterBufferH264 *h264;
   VAPictureParameterBufferVC1 * vc1;
   VAPictureParameterBufferMPEG4 *mpeg4;
   vlVaSurface *surf_forward;
   vlVaSurface *surf_backward;
   unsigned int i;
   static const uint8_t default_intra_quant_matrix[64] = { 0 };
   static const uint8_t default_non_intra_quant_matrix[64] = { 0 };
d138 1
a138 1
   switch (u_reduce_video_profile(context->decoder->profile)) {
d140 1
a140 30
      assert(buf->size >= sizeof(VAPictureParameterBufferMPEG2) && buf->num_elements == 1);
      mpeg2 = buf->data;
      /*horizontal_size;*/
      /*vertical_size;*/
      getReferenceFrame(drv, mpeg2->forward_reference_picture, &context->desc.mpeg12.ref[0]);
      getReferenceFrame(drv, mpeg2->backward_reference_picture, &context->desc.mpeg12.ref[1]);
      context->desc.mpeg12.picture_coding_type = mpeg2->picture_coding_type;
      context->desc.mpeg12.f_code[0][0] = ((mpeg2->f_code >> 12) & 0xf) - 1;
      context->desc.mpeg12.f_code[0][1] = ((mpeg2->f_code >> 8) & 0xf) - 1;
      context->desc.mpeg12.f_code[1][0] = ((mpeg2->f_code >> 4) & 0xf) - 1;
      context->desc.mpeg12.f_code[1][1] = (mpeg2->f_code & 0xf) - 1;
      context->desc.mpeg12.intra_dc_precision =
         mpeg2->picture_coding_extension.bits.intra_dc_precision;
      context->desc.mpeg12.picture_structure =
         mpeg2->picture_coding_extension.bits.picture_structure;
      context->desc.mpeg12.top_field_first =
         mpeg2->picture_coding_extension.bits.top_field_first;
      context->desc.mpeg12.frame_pred_frame_dct =
         mpeg2->picture_coding_extension.bits.frame_pred_frame_dct;
      context->desc.mpeg12.concealment_motion_vectors =
         mpeg2->picture_coding_extension.bits.concealment_motion_vectors;
      context->desc.mpeg12.q_scale_type =
         mpeg2->picture_coding_extension.bits.q_scale_type;
      context->desc.mpeg12.intra_vlc_format =
         mpeg2->picture_coding_extension.bits.intra_vlc_format;
      context->desc.mpeg12.alternate_scan =
         mpeg2->picture_coding_extension.bits.alternate_scan;
      /*repeat_first_field*/
      /*progressive_frame*/
      /*is_first_field*/
d144 1
a144 59
      assert(buf->size >= sizeof(VAPictureParameterBufferH264) && buf->num_elements == 1);
      h264 = buf->data;
      /*CurrPic*/
      context->desc.h264.field_order_cnt[0] = h264->CurrPic.TopFieldOrderCnt;
      context->desc.h264.field_order_cnt[1] = h264->CurrPic.BottomFieldOrderCnt;
      /*ReferenceFrames[16]*/
      /*picture_width_in_mbs_minus1*/
      /*picture_height_in_mbs_minus1*/
      /*bit_depth_luma_minus8*/
      /*bit_depth_chroma_minus8*/
      context->desc.h264.num_ref_frames = h264->num_ref_frames;
      /*chroma_format_idc*/
      /*residual_colour_transform_flag*/
      /*gaps_in_frame_num_value_allowed_flag*/
      context->desc.h264.pps->sps->frame_mbs_only_flag =
         h264->seq_fields.bits.frame_mbs_only_flag;
      context->desc.h264.pps->sps->mb_adaptive_frame_field_flag =
         h264->seq_fields.bits.mb_adaptive_frame_field_flag;
      context->desc.h264.pps->sps->direct_8x8_inference_flag =
         h264->seq_fields.bits.direct_8x8_inference_flag;
      /*MinLumaBiPredSize8x8*/
      context->desc.h264.pps->sps->log2_max_frame_num_minus4 =
         h264->seq_fields.bits.log2_max_frame_num_minus4;
      context->desc.h264.pps->sps->pic_order_cnt_type =
         h264->seq_fields.bits.pic_order_cnt_type;
      context->desc.h264.pps->sps->log2_max_pic_order_cnt_lsb_minus4 =
         h264->seq_fields.bits.log2_max_pic_order_cnt_lsb_minus4;
      context->desc.h264.pps->sps->delta_pic_order_always_zero_flag =
         h264->seq_fields.bits.delta_pic_order_always_zero_flag;
      /*num_slice_groups_minus1*/
      /*slice_group_map_type*/
      /*slice_group_change_rate_minus1*/
      context->desc.h264.pps->pic_init_qp_minus26 =
         h264->pic_init_qp_minus26;
      /*pic_init_qs_minus26*/
      context->desc.h264.pps->chroma_qp_index_offset =
         h264->chroma_qp_index_offset;
      context->desc.h264.pps->second_chroma_qp_index_offset =
         h264->second_chroma_qp_index_offset;
      context->desc.h264.pps->entropy_coding_mode_flag =
         h264->pic_fields.bits.entropy_coding_mode_flag;
      context->desc.h264.pps->weighted_pred_flag =
         h264->pic_fields.bits.weighted_pred_flag;
      context->desc.h264.pps->weighted_bipred_idc =
         h264->pic_fields.bits.weighted_bipred_idc;
      context->desc.h264.pps->transform_8x8_mode_flag =
         h264->pic_fields.bits.transform_8x8_mode_flag;
      context->desc.h264.field_pic_flag =
         h264->pic_fields.bits.field_pic_flag;
      context->desc.h264.pps->constrained_intra_pred_flag =
         h264->pic_fields.bits.constrained_intra_pred_flag;
      context->desc.h264.pps->bottom_field_pic_order_in_frame_present_flag =
         h264->pic_fields.bits.pic_order_present_flag;
      context->desc.h264.pps->deblocking_filter_control_present_flag =
         h264->pic_fields.bits.deblocking_filter_control_present_flag;
      context->desc.h264.pps->redundant_pic_cnt_present_flag =
         h264->pic_fields.bits.redundant_pic_cnt_present_flag;
      /*reference_pic_flag*/
      context->desc.h264.frame_num = h264->frame_num;
d148 1
a148 34
      assert(buf->size >= sizeof(VAPictureParameterBufferVC1) && buf->num_elements == 1);
      vc1 = buf->data;
      getReferenceFrame(drv, vc1->forward_reference_picture, &context->desc.vc1.ref[0]);
      getReferenceFrame(drv, vc1->backward_reference_picture, &context->desc.vc1.ref[1]);
      context->desc.vc1.picture_type = vc1->picture_fields.bits.picture_type;
      context->desc.vc1.frame_coding_mode = vc1->picture_fields.bits.frame_coding_mode;
      context->desc.vc1.postprocflag = vc1->post_processing != 0;
      context->desc.vc1.pulldown = vc1->sequence_fields.bits.pulldown;
      context->desc.vc1.interlace = vc1->sequence_fields.bits.interlace;
      context->desc.vc1.tfcntrflag = vc1->sequence_fields.bits.tfcntrflag;
      context->desc.vc1.finterpflag = vc1->sequence_fields.bits.finterpflag;
      context->desc.vc1.psf = vc1->sequence_fields.bits.psf;
      context->desc.vc1.dquant = vc1->pic_quantizer_fields.bits.dquant;
      context->desc.vc1.panscan_flag = vc1->entrypoint_fields.bits.panscan_flag;
      context->desc.vc1.refdist_flag =
         vc1->reference_fields.bits.reference_distance_flag;
      context->desc.vc1.quantizer = vc1->pic_quantizer_fields.bits.quantizer;
      context->desc.vc1.extended_mv = vc1->mv_fields.bits.extended_mv_flag;
      context->desc.vc1.extended_dmv = vc1->mv_fields.bits.extended_dmv_flag;
      context->desc.vc1.overlap = vc1->sequence_fields.bits.overlap;
      context->desc.vc1.vstransform =
         vc1->transform_fields.bits.variable_sized_transform_flag;
      context->desc.vc1.loopfilter = vc1->entrypoint_fields.bits.loopfilter;
      context->desc.vc1.fastuvmc = vc1->fast_uvmc_flag;
      context->desc.vc1.range_mapy_flag = vc1->range_mapping_fields.bits.luma_flag;
      context->desc.vc1.range_mapy = vc1->range_mapping_fields.bits.luma;
      context->desc.vc1.range_mapuv_flag = vc1->range_mapping_fields.bits.chroma_flag;
      context->desc.vc1.range_mapuv = vc1->range_mapping_fields.bits.chroma;
      context->desc.vc1.multires = vc1->sequence_fields.bits.multires;
      context->desc.vc1.syncmarker = vc1->sequence_fields.bits.syncmarker;
      context->desc.vc1.rangered = vc1->sequence_fields.bits.rangered;
      context->desc.vc1.maxbframes = vc1->sequence_fields.bits.max_b_frames;
      context->desc.vc1.deblockEnable = vc1->post_processing != 0;
      context->desc.vc1.pquant = vc1->pic_quantizer_fields.bits.pic_quantizer_scale;
d152 2
a153 62
      assert(buf->size >= sizeof(VAPictureParameterBufferMPEG4) && buf->num_elements == 1);
      mpeg4 = buf->data;

      context->mpeg4.pps = *mpeg4;

      /* vop_width */
      /* vop_height */
      /* forward_reference_picture */
      /* backward_reference_picture */
      context->desc.mpeg4.short_video_header =
            mpeg4->vol_fields.bits.short_video_header;
      /* chroma_format */
      context->desc.mpeg4.interlaced = mpeg4->vol_fields.bits.interlaced;
      /* obmc_disable */
      /* sprite_enable */
      /* sprite_warping_accuracy */
      context->desc.mpeg4.quant_type = mpeg4->vol_fields.bits.quant_type;
      context->desc.mpeg4.quarter_sample = mpeg4->vol_fields.bits.quarter_sample;
      /* data_partitioned */
      /* reversible_vlc */
      context->desc.mpeg4.resync_marker_disable =
            mpeg4->vol_fields.bits.resync_marker_disable;
      /* no_of_sprite_warping_points */
      /* sprite_trajectory_du */
      /* sprite_trajectory_dv */
      /* quant_precision */
      context->desc.mpeg4.vop_coding_type = mpeg4->vop_fields.bits.vop_coding_type;
      /* backward_reference_vop_coding_type */
      /* vop_rounding_type */
      /* intra_dc_vlc_thr */
      context->desc.mpeg4.top_field_first =
            mpeg4->vop_fields.bits.top_field_first;
      context->desc.mpeg4.alternate_vertical_scan_flag =
            mpeg4->vop_fields.bits.alternate_vertical_scan_flag;
      context->desc.mpeg4.vop_fcode_forward = mpeg4->vop_fcode_forward;
      context->desc.mpeg4.vop_fcode_backward = mpeg4->vop_fcode_backward;
      context->desc.mpeg4.vop_time_increment_resolution =
            mpeg4->vop_time_increment_resolution;
      /* num_gobs_in_vop */
      /* num_macroblocks_in_gob */
      context->desc.mpeg4.trb[0] = mpeg4->TRB;
      context->desc.mpeg4.trb[1] = mpeg4->TRB;
      context->desc.mpeg4.trd[0] = mpeg4->TRD;
      context->desc.mpeg4.trd[1] = mpeg4->TRD;

      /* default [non-]intra quant matrix because mpv does not set these
         matrices */
      if (!context->desc.mpeg4.intra_matrix)
         context->desc.mpeg4.intra_matrix = default_intra_quant_matrix;
      if (!context->desc.mpeg4.non_intra_matrix)
         context->desc.mpeg4.non_intra_matrix = default_non_intra_quant_matrix;

      surf_forward = handle_table_get(drv->htab, mpeg4->forward_reference_picture);
      if (surf_forward)
         context->desc.mpeg4.ref[0] = surf_forward->buffer;
      surf_backward = handle_table_get(drv->htab, mpeg4->backward_reference_picture);
      if (surf_backward)
         context->desc.mpeg4.ref[1] = surf_backward->buffer;

      context->mpeg4.vti_bits = 0;
      for (i = context->desc.mpeg4.vop_time_increment_resolution; i > 0; i /= 2)
         ++context->mpeg4.vti_bits;
d155 2
d162 24
d191 1
a191 5
   VAIQMatrixBufferMPEG2 *mpeg2;
   VAIQMatrixBufferH264 *h264;
   VAIQMatrixBufferMPEG4 *mpeg4;

   switch (u_reduce_video_profile(context->decoder->profile)) {
d193 1
a193 11
      assert(buf->size >= sizeof(VAIQMatrixBufferMPEG2) && buf->num_elements == 1);
      mpeg2 = buf->data;
      if (mpeg2->load_intra_quantiser_matrix)
         context->desc.mpeg12.intra_matrix = mpeg2->intra_quantiser_matrix;
      else
         context->desc.mpeg12.intra_matrix = NULL;

      if (mpeg2->load_non_intra_quantiser_matrix)
         context->desc.mpeg12.non_intra_matrix = mpeg2->non_intra_quantiser_matrix;
      else
         context->desc.mpeg12.non_intra_matrix = NULL;
d197 1
a197 4
      assert(buf->size >= sizeof(VAIQMatrixBufferH264) && buf->num_elements == 1);
      h264 = buf->data;
      memcpy(&context->desc.h264.pps->ScalingList4x4, h264->ScalingList4x4, 6 * 16);
      memcpy(&context->desc.h264.pps->ScalingList8x8, h264->ScalingList8x8, 2 * 64);
d201 2
a202 2
      assert(buf->size >= sizeof(VAIQMatrixBufferMPEG4) && buf->num_elements == 1);
      mpeg4 = buf->data;
d204 2
a205 9
      if (mpeg4->load_intra_quant_mat)
         context->desc.mpeg4.intra_matrix = mpeg4->intra_quant_mat;
      else
         context->desc.mpeg4.intra_matrix = NULL;

      if (mpeg4->load_non_intra_quant_mat)
         context->desc.mpeg4.non_intra_matrix = mpeg4->non_intra_quant_mat;
      else
         context->desc.mpeg4.non_intra_matrix = NULL;
d216 8
a223 2
   VASliceParameterBufferH264 *h264;
   VASliceParameterBufferMPEG4 *mpeg4;
a224 1
   switch (u_reduce_video_profile(context->decoder->profile)) {
d226 1
a226 6
      assert(buf->size >= sizeof(VASliceParameterBufferH264) && buf->num_elements == 1);
      h264 = buf->data;
      context->desc.h264.num_ref_idx_l0_active_minus1 =
         h264->num_ref_idx_l0_active_minus1;
      context->desc.h264.num_ref_idx_l1_active_minus1 =
         h264->num_ref_idx_l1_active_minus1;
d228 1
d230 2
a231 2
      assert(buf->size >= sizeof(VASliceParameterBufferMPEG4) && buf->num_elements == 1);
      mpeg4 = buf->data;
d233 2
a234 1
      context->mpeg4.quant_scale = mpeg4->quant_scale;
d236 1
a241 91
struct bit_stream
{
   uint8_t *data;
   unsigned int length; /* bits */
   unsigned int pos;    /* bits */
};

static inline void
write_bit(struct bit_stream *writer, unsigned int bit)
{
   assert(writer->length > (writer)->pos);
   writer->data[writer->pos>>3] |= ((bit & 1)<<(7 - (writer->pos & 7)));
   writer->pos++;
}

static inline void
write_bits(struct bit_stream *writer, unsigned int bits, unsigned int len)
{
   int i;
   assert(len <= sizeof(bits)*8);
   for (i = len - 1; i >= 0; i--)
      write_bit(writer, bits>>i);
}

static void
vlVaDecoderFixMPEG4Startcode(vlVaContext *context)
{
   uint8_t vop[] = { 0x00, 0x00, 0x01, 0xb6, 0x00, 0x00, 0x00, 0x00, 0x00 };
   struct bit_stream bs_vop = {vop, sizeof(vop)*8, 32};
   unsigned int vop_time_inc;
   int mod_time;
   unsigned int vop_size;
   unsigned int vop_coding_type = context->desc.mpeg4.vop_coding_type;

   context->mpeg4.start_code_size = 0;
   memset(context->mpeg4.start_code, 0, sizeof(context->mpeg4.start_code));
   if (vop_coding_type+1 == PIPE_MPEG12_PICTURE_CODING_TYPE_I) {
      unsigned int vop_time = context->mpeg4.frame_num/
            context->desc.mpeg4.vop_time_increment_resolution;
      unsigned int vop_hour = vop_time / 3600;
      unsigned int vop_minute = (vop_time / 60) % 60;
      unsigned int vop_second = vop_time % 60;
      uint8_t group_of_vop[] = { 0x00, 0x00, 0x01, 0xb3, 0x00, 0x00, 0x00 };
      struct bit_stream bs_gvop = {group_of_vop, sizeof(group_of_vop)*8, 32};

      write_bits(&bs_gvop, vop_hour, 5);
      write_bits(&bs_gvop, vop_minute, 6);
      write_bit(&bs_gvop, 1); /* marker_bit */
      write_bits(&bs_gvop, vop_second, 6);
      write_bit(&bs_gvop, 0); /* closed_gov */ /* TODO replace magic */
      write_bit(&bs_gvop, 0); /* broken_link */
      write_bit(&bs_gvop, 0); /* padding */
      write_bits(&bs_gvop, 7, 3); /* padding */

      memcpy(context->mpeg4.start_code, group_of_vop, sizeof(group_of_vop));
      context->mpeg4.start_code_size += sizeof(group_of_vop);
   }

   write_bits(&bs_vop, vop_coding_type, 2);
   mod_time = context->mpeg4.frame_num %
         context->desc.mpeg4.vop_time_increment_resolution == 0 &&
         vop_coding_type+1 != PIPE_MPEG12_PICTURE_CODING_TYPE_I;
   while (mod_time--)
      write_bit(&bs_vop, 1); /* modulo_time_base */
   write_bit(&bs_vop, 0); /* modulo_time_base */

   write_bit(&bs_vop, 1); /* marker_bit */
   vop_time_inc = context->mpeg4.frame_num %
         context->desc.mpeg4.vop_time_increment_resolution;
   write_bits(&bs_vop, vop_time_inc, context->mpeg4.vti_bits);
   write_bit(&bs_vop, 1); /* marker_bit */
   write_bit(&bs_vop, 1); /* vop_coded */
   if (vop_coding_type+1 == PIPE_MPEG12_PICTURE_CODING_TYPE_P)
      write_bit(&bs_vop, context->mpeg4.pps.vop_fields.bits.vop_rounding_type);
   write_bits(&bs_vop, context->mpeg4.pps.vop_fields.bits.intra_dc_vlc_thr, 3);
   if (context->mpeg4.pps.vol_fields.bits.interlaced) {
      write_bit(&bs_vop, context->mpeg4.pps.vop_fields.bits.top_field_first);
      write_bit(&bs_vop, context->mpeg4.pps.vop_fields.bits.alternate_vertical_scan_flag);
   }

   write_bits(&bs_vop, context->mpeg4.quant_scale, context->mpeg4.pps.quant_precision);
   if (vop_coding_type+1 != PIPE_MPEG12_PICTURE_CODING_TYPE_I)
      write_bits(&bs_vop, context->desc.mpeg4.vop_fcode_forward, 3);
   if (vop_coding_type+1 == PIPE_MPEG12_PICTURE_CODING_TYPE_B)
      write_bits(&bs_vop, context->desc.mpeg4.vop_fcode_backward, 3);

   vop_size = bs_vop.pos/8;
   memcpy(context->mpeg4.start_code + context->mpeg4.start_code_size, vop, vop_size);
   context->mpeg4.start_code_size += vop_size;
}

d268 1
d271 1
a271 1
   format = u_reduce_video_profile(context->decoder->profile);
d274 9
a282 2
         if (bufHasStartcode(buf, 0x000001, 24))
            break;
d284 2
a285 2
         buffers[num_buffers] = (void *const)&start_code_h264;
         sizes[num_buffers++] = sizeof(start_code_h264);
d312 6
d322 143
d470 1
d481 1
d483 2
a484 1
   if (!context)
d486 1
d490 2
a491 1
      if (!buf)
d493 1
d497 1
a497 1
         handlePictureParameterBuffer(drv, context, buf);
d511 19
d535 1
d537 1
a537 1
   return VA_STATUS_SUCCESS;
d545 3
d556 1
d558 1
d562 10
d573 12
d586 4
a589 1

@


1.1.1.1
log
@import Mesa 11.0.6
@
text
@@


1.1.1.2
log
@Import Mesa 11.2.2
@
text
@a34 1
#include "vl/vl_winsys.h"
a51 1
   pipe_mutex_lock(drv->mutex);
d53 1
a53 2
   if (!context) {
      pipe_mutex_unlock(drv->mutex);
a54 1
   }
a56 1
   pipe_mutex_unlock(drv->mutex);
a60 15

   if (!context->decoder) {

      /* VPP */
      if (context->templat.profile == PIPE_VIDEO_PROFILE_UNKNOWN &&
          context->target->buffer_format != PIPE_FORMAT_B8G8R8A8_UNORM &&
          context->target->buffer_format != PIPE_FORMAT_R8G8B8A8_UNORM &&
          context->target->buffer_format != PIPE_FORMAT_B8G8R8X8_UNORM &&
          context->target->buffer_format != PIPE_FORMAT_R8G8B8X8_UNORM &&
          context->target->buffer_format != PIPE_FORMAT_NV12)
         return VA_STATUS_ERROR_UNIMPLEMENTED;

      return VA_STATUS_SUCCESS;
   }

d66 3
a68 3
void
vlVaGetReferenceFrame(vlVaDriver *drv, VASurfaceID surface_id,
                      struct pipe_video_buffer **ref_frame)
d77 1
a77 1
static VAStatus
d80 9
a88 1
   VAStatus vaStatus = VA_STATUS_SUCCESS;
d90 1
a90 1
   switch (u_reduce_video_profile(context->templat.profile)) {
d92 30
a121 1
      vlVaHandlePictureParameterBufferMPEG12(drv, context, buf);
d125 59
a183 1
      vlVaHandlePictureParameterBufferH264(drv, context, buf);
d187 34
a220 1
      vlVaHandlePictureParameterBufferVC1(drv, context, buf);
d224 62
a285 2
      vlVaHandlePictureParameterBufferMPEG4(drv, context, buf);
      break;
a286 2
  case PIPE_VIDEO_FORMAT_HEVC:
      vlVaHandlePictureParameterBufferHEVC(drv, context, buf);
a291 25

   /* Create the decoder once max_references is known. */
   if (!context->decoder) {
      if (!context->target)
         return VA_STATUS_ERROR_INVALID_CONTEXT;

      if (context->templat.max_references == 0)
         return VA_STATUS_ERROR_INVALID_BUFFER;

      if (u_reduce_video_profile(context->templat.profile) ==
          PIPE_VIDEO_FORMAT_MPEG4_AVC)
         context->templat.level = u_get_h264_level(context->templat.width,
            context->templat.height, &context->templat.max_references);

      context->decoder = drv->pipe->create_video_codec(drv->pipe,
         &context->templat);

      if (!context->decoder)
         return VA_STATUS_ERROR_ALLOCATION_FAILED;

      context->decoder->begin_frame(context->decoder, context->target,
         &context->desc.base);
   }

   return vaStatus;
d297 5
a301 1
   switch (u_reduce_video_profile(context->templat.profile)) {
d303 11
a313 1
      vlVaHandleIQMatrixBufferMPEG12(context, buf);
d317 4
a320 1
      vlVaHandleIQMatrixBufferH264(context, buf);
d324 2
a325 2
      vlVaHandleIQMatrixBufferMPEG4(context, buf);
      break;
d327 9
a335 2
   case PIPE_VIDEO_FORMAT_HEVC:
      vlVaHandleIQMatrixBufferHEVC(context, buf);
d346 2
a347 8
   switch (u_reduce_video_profile(context->templat.profile)) {
   case PIPE_VIDEO_FORMAT_MPEG12:
      vlVaHandleSliceParameterBufferMPEG12(context, buf);
      break;

   case PIPE_VIDEO_FORMAT_VC1:
      vlVaHandleSliceParameterBufferVC1(context, buf);
      break;
d349 1
d351 6
a356 1
      vlVaHandleSliceParameterBufferH264(context, buf);
a357 1

d359 2
a360 2
      vlVaHandleSliceParameterBufferMPEG4(context, buf);
      break;
d362 1
a362 2
   case PIPE_VIDEO_FORMAT_HEVC:
      vlVaHandleSliceParameterBufferHEVC(context, buf);
a363 1

d369 91
a485 1
   static const uint8_t start_code_h265[] = { 0x00, 0x00, 0x01 };
d488 1
a488 1
   format = u_reduce_video_profile(context->templat.profile);
d491 2
a492 2
      if (bufHasStartcode(buf, 0x000001, 24))
         break;
d494 2
a495 9
      buffers[num_buffers] = (void *const)&start_code_h264;
      sizes[num_buffers++] = sizeof(start_code_h264);
      break;
   case PIPE_VIDEO_FORMAT_HEVC:
      if (bufHasStartcode(buf, 0x000001, 24))
         break;

      buffers[num_buffers] = (void *const)&start_code_h265;
      sizes[num_buffers++] = sizeof(start_code_h265);
a530 1
   VAStatus vaStatus = VA_STATUS_SUCCESS;
a540 1
   pipe_mutex_lock(drv->mutex);
d542 1
a542 2
   if (!context) {
      pipe_mutex_unlock(drv->mutex);
a543 1
   }
d547 1
a547 2
      if (!buf) {
         pipe_mutex_unlock(drv->mutex);
a548 1
      }
d552 1
a552 1
         vaStatus = handlePictureParameterBuffer(drv, context, buf);
a565 3
      case VAProcPipelineParameterBufferType:
         vaStatus = vlVaHandleVAProcPipelineParameterBufferType(drv, context, buf);
         break;
a570 1
   pipe_mutex_unlock(drv->mutex);
d572 1
a572 1
   return vaStatus;
a587 1
   pipe_mutex_lock(drv->mutex);
a588 1
   pipe_mutex_unlock(drv->mutex);
a590 8

   if (!context->decoder) {
      if (context->templat.profile != PIPE_VIDEO_PROFILE_UNKNOWN)
         return VA_STATUS_ERROR_INVALID_CONTEXT;

      /* VPP */
      return VA_STATUS_SUCCESS;
   }
@


1.1.1.3
log
@Import Mesa 13.0.2
@
text
@a64 2
   context->target_id = render_target;
   surf->ctx = context_id;
d81 1
a81 2
   if (context->decoder->entrypoint != PIPE_VIDEO_ENTRYPOINT_ENCODE)
      context->decoder->begin_frame(context->decoder, context->target, &context->desc.base);
a96 33
static void
getEncParamPreset(vlVaContext *context)
{
   //motion estimation preset
   context->desc.h264enc.motion_est.motion_est_quarter_pixel = 0x00000001;
   context->desc.h264enc.motion_est.lsmvert = 0x00000002;
   context->desc.h264enc.motion_est.enc_disable_sub_mode = 0x00000078;
   context->desc.h264enc.motion_est.enc_en_ime_overw_dis_subm = 0x00000001;
   context->desc.h264enc.motion_est.enc_ime_overw_dis_subm_no = 0x00000001;
   context->desc.h264enc.motion_est.enc_ime2_search_range_x = 0x00000004;
   context->desc.h264enc.motion_est.enc_ime2_search_range_y = 0x00000004;

   //pic control preset
   context->desc.h264enc.pic_ctrl.enc_cabac_enable = 0x00000001;
   context->desc.h264enc.pic_ctrl.enc_constraint_set_flags = 0x00000040;

   //rate control
   context->desc.h264enc.rate_ctrl.vbv_buffer_size = 20000000;
   context->desc.h264enc.rate_ctrl.vbv_buf_lv = 48;
   context->desc.h264enc.rate_ctrl.fill_data_enable = 1;
   context->desc.h264enc.rate_ctrl.enforce_hrd = 1;
   context->desc.h264enc.enable_vui = false;
   if (context->desc.h264enc.rate_ctrl.frame_rate_num == 0)
      context->desc.h264enc.rate_ctrl.frame_rate_num = 30;
   context->desc.h264enc.rate_ctrl.target_bits_picture =
      context->desc.h264enc.rate_ctrl.target_bitrate / context->desc.h264enc.rate_ctrl.frame_rate_num;
   context->desc.h264enc.rate_ctrl.peak_bits_picture_integer =
      context->desc.h264enc.rate_ctrl.peak_bitrate / context->desc.h264enc.rate_ctrl.frame_rate_num;
   context->desc.h264enc.rate_ctrl.peak_bits_picture_fraction = 0;

   context->desc.h264enc.ref_pic_mode = 0x00000201;
}

a280 143
static VAStatus
handleVAEncMiscParameterTypeRateControl(vlVaContext *context, VAEncMiscParameterBuffer *misc)
{
   VAEncMiscParameterRateControl *rc = (VAEncMiscParameterRateControl *)misc->data;
   if (context->desc.h264enc.rate_ctrl.rate_ctrl_method ==
       PIPE_H264_ENC_RATE_CONTROL_METHOD_CONSTANT)
      context->desc.h264enc.rate_ctrl.target_bitrate = rc->bits_per_second;
   else
      context->desc.h264enc.rate_ctrl.target_bitrate = rc->bits_per_second * (rc->target_percentage / 100.0);
   context->desc.h264enc.rate_ctrl.peak_bitrate = rc->bits_per_second;
   if (context->desc.h264enc.rate_ctrl.target_bitrate < 2000000)
      context->desc.h264enc.rate_ctrl.vbv_buffer_size = MIN2((context->desc.h264enc.rate_ctrl.target_bitrate * 2.75), 2000000);
   else
      context->desc.h264enc.rate_ctrl.vbv_buffer_size = context->desc.h264enc.rate_ctrl.target_bitrate;

   return VA_STATUS_SUCCESS;
}

static VAStatus
handleVAEncMiscParameterTypeFrameRate(vlVaContext *context, VAEncMiscParameterBuffer *misc)
{
   VAEncMiscParameterFrameRate *fr = (VAEncMiscParameterFrameRate *)misc->data;
   context->desc.h264enc.rate_ctrl.frame_rate_num = fr->framerate;
   return VA_STATUS_SUCCESS;
}

static VAStatus
handleVAEncSequenceParameterBufferType(vlVaDriver *drv, vlVaContext *context, vlVaBuffer *buf)
{
   VAEncSequenceParameterBufferH264 *h264 = (VAEncSequenceParameterBufferH264 *)buf->data;
   if (!context->decoder) {
      context->templat.max_references = h264->max_num_ref_frames;
      context->templat.level = h264->level_idc;
      context->decoder = drv->pipe->create_video_codec(drv->pipe, &context->templat);
      if (!context->decoder)
         return VA_STATUS_ERROR_ALLOCATION_FAILED;
   }
   context->desc.h264enc.gop_size = h264->intra_idr_period;
   context->desc.h264enc.rate_ctrl.frame_rate_num = h264->time_scale / 2;
   context->desc.h264enc.rate_ctrl.frame_rate_den = 1;
   return VA_STATUS_SUCCESS;
}

static VAStatus
handleVAEncMiscParameterBufferType(vlVaContext *context, vlVaBuffer *buf)
{
   VAStatus vaStatus = VA_STATUS_SUCCESS;
   VAEncMiscParameterBuffer *misc;
   misc = buf->data;

   switch (misc->type) {
   case VAEncMiscParameterTypeRateControl:
      vaStatus = handleVAEncMiscParameterTypeRateControl(context, misc);
      break;

   case VAEncMiscParameterTypeFrameRate:
      vaStatus = handleVAEncMiscParameterTypeFrameRate(context, misc);
      break;

   default:
      break;
   }

   return vaStatus;
}

static VAStatus
handleVAEncPictureParameterBufferType(vlVaDriver *drv, vlVaContext *context, vlVaBuffer *buf)
{
   VAEncPictureParameterBufferH264 *h264;
   vlVaBuffer *coded_buf;

   h264 = buf->data;
   context->desc.h264enc.frame_num = h264->frame_num;
   context->desc.h264enc.not_referenced = false;
   context->desc.h264enc.is_idr = (h264->pic_fields.bits.idr_pic_flag == 1);
   context->desc.h264enc.pic_order_cnt = h264->CurrPic.TopFieldOrderCnt;
   if (context->desc.h264enc.is_idr)
      context->desc.h264enc.i_remain = 1;
   else
      context->desc.h264enc.i_remain = 0;

   context->desc.h264enc.p_remain = context->desc.h264enc.gop_size - context->desc.h264enc.gop_cnt - context->desc.h264enc.i_remain;

   coded_buf = handle_table_get(drv->htab, h264->coded_buf);
   if (!coded_buf->derived_surface.resource)
      coded_buf->derived_surface.resource = pipe_buffer_create(drv->pipe->screen, PIPE_BIND_VERTEX_BUFFER,
                                            PIPE_USAGE_STREAM, coded_buf->size);
   context->coded_buf = coded_buf;

   context->desc.h264enc.frame_idx[h264->CurrPic.picture_id] = h264->frame_num;
   if (context->desc.h264enc.is_idr)
      context->desc.h264enc.picture_type = PIPE_H264_ENC_PICTURE_TYPE_IDR;
   else
      context->desc.h264enc.picture_type = PIPE_H264_ENC_PICTURE_TYPE_P;

   context->desc.h264enc.quant_i_frames = h264->pic_init_qp;
   context->desc.h264enc.quant_b_frames = h264->pic_init_qp;
   context->desc.h264enc.quant_p_frames = h264->pic_init_qp;
   context->desc.h264enc.frame_num_cnt++;
   context->desc.h264enc.gop_cnt++;
   if (context->desc.h264enc.gop_cnt == context->desc.h264enc.gop_size)
      context->desc.h264enc.gop_cnt = 0;

   return VA_STATUS_SUCCESS;
}

static VAStatus
handleVAEncSliceParameterBufferType(vlVaDriver *drv, vlVaContext *context, vlVaBuffer *buf)
{
   VAEncSliceParameterBufferH264 *h264;

   h264 = buf->data;
   context->desc.h264enc.ref_idx_l0 = VA_INVALID_ID;
   context->desc.h264enc.ref_idx_l1 = VA_INVALID_ID;

   for (int i = 0; i < 32; i++) {
      if (h264->RefPicList0[i].picture_id != VA_INVALID_ID) {
         if (context->desc.h264enc.ref_idx_l0 == VA_INVALID_ID)
            context->desc.h264enc.ref_idx_l0 = context->desc.h264enc.frame_idx[h264->RefPicList0[i].picture_id];
      }
      if (h264->RefPicList1[i].picture_id != VA_INVALID_ID && h264->slice_type == 1) {
         if (context->desc.h264enc.ref_idx_l1 == VA_INVALID_ID)
            context->desc.h264enc.ref_idx_l1 = context->desc.h264enc.frame_idx[h264->RefPicList1[i].picture_id];
      }
   }

   if (h264->slice_type == 1)
      context->desc.h264enc.picture_type = PIPE_H264_ENC_PICTURE_TYPE_B;
   else if (h264->slice_type == 0)
      context->desc.h264enc.picture_type = PIPE_H264_ENC_PICTURE_TYPE_P;
   else if (h264->slice_type == 2) {
      if (context->desc.h264enc.is_idr){
         context->desc.h264enc.picture_type = PIPE_H264_ENC_PICTURE_TYPE_IDR;
         context->desc.h264enc.idr_pic_id++;
	   } else
         context->desc.h264enc.picture_type = PIPE_H264_ENC_PICTURE_TYPE_I;
   } else
      context->desc.h264enc.picture_type = PIPE_H264_ENC_PICTURE_TYPE_SKIP;

   return VA_STATUS_SUCCESS;
}

a330 16
      case VAEncSequenceParameterBufferType:
         vaStatus = handleVAEncSequenceParameterBufferType(drv, context, buf);
         break;

      case VAEncMiscParameterBufferType:
         vaStatus = handleVAEncMiscParameterBufferType(context, buf);
         break;

      case VAEncPictureParameterBufferType:
         vaStatus = handleVAEncPictureParameterBufferType(drv, context, buf);
         break;

      case VAEncSliceParameterBufferType:
         vaStatus = handleVAEncSliceParameterBufferType(drv, context, buf);
         break;

a344 3
   vlVaBuffer *coded_buf;
   vlVaSurface *surf;
   void *feedback;
a366 2
   pipe_mutex_lock(drv->mutex);
   surf = handle_table_get(drv->htab, context->target_id);
d368 1
a369 16
   if (context->decoder->entrypoint == PIPE_VIDEO_ENTRYPOINT_ENCODE) {
      coded_buf = context->coded_buf;
      getEncParamPreset(context);
      context->decoder->begin_frame(context->decoder, context->target, &context->desc.base);
      context->decoder->encode_bitstream(context->decoder, context->target,
                                         coded_buf->derived_surface.resource, &feedback);
      surf->frame_num_cnt = context->desc.h264enc.frame_num_cnt;
      surf->feedback = feedback;
      surf->coded_buf = coded_buf;
   }

   context->decoder->end_frame(context->decoder, context->target, &context->desc.base);
   if (context->decoder->entrypoint == PIPE_VIDEO_ENTRYPOINT_ENCODE &&
       context->desc.h264enc.p_remain == 1)
      context->decoder->flush(context->decoder);
   pipe_mutex_unlock(drv->mutex);
@


1.1.1.4
log
@Import Mesa 13.0.5
@
text
@d84 1
a84 1
      context->needs_begin_frame = true;
d182 2
a183 1
      context->needs_begin_frame = true;
a312 6

   if (context->needs_begin_frame) {
      context->decoder->begin_frame(context->decoder, context->target,
         &context->desc.base);
      context->needs_begin_frame = false;
   }
@


1.1.1.5
log
@Import Mesa 17.1.6
@
text
@d53 1
a53 1
   mtx_lock(&drv->mutex);
d56 1
a56 1
      mtx_unlock(&drv->mutex);
d61 1
a61 1
   mtx_unlock(&drv->mutex);
d77 1
a77 2
          context->target->buffer_format != PIPE_FORMAT_NV12 &&
          context->target->buffer_format != PIPE_FORMAT_P016)
d122 2
a123 5
   if (context->desc.h264enc.rate_ctrl.frame_rate_num == 0 ||
       context->desc.h264enc.rate_ctrl.frame_rate_den == 0) {
         context->desc.h264enc.rate_ctrl.frame_rate_num = 30;
         context->desc.h264enc.rate_ctrl.frame_rate_den = 1;
   }
d125 1
a125 3
      context->desc.h264enc.rate_ctrl.target_bitrate *
      ((float)context->desc.h264enc.rate_ctrl.frame_rate_den /
      context->desc.h264enc.rate_ctrl.frame_rate_num);
d127 2
a128 3
      context->desc.h264enc.rate_ctrl.peak_bitrate *
      ((float)context->desc.h264enc.rate_ctrl.frame_rate_den /
      context->desc.h264enc.rate_ctrl.frame_rate_num);
a129 1
   context->desc.h264enc.rate_ctrl.peak_bits_picture_fraction = 0;
d344 1
a344 7
   if (fr->framerate & 0xffff0000) {
      context->desc.h264enc.rate_ctrl.frame_rate_num = fr->framerate       & 0xffff;
      context->desc.h264enc.rate_ctrl.frame_rate_den = fr->framerate >> 16 & 0xffff;
   } else {
      context->desc.h264enc.rate_ctrl.frame_rate_num = fr->framerate;
      context->desc.h264enc.rate_ctrl.frame_rate_den = 1;
   }
d359 1
a359 5

   context->gop_coeff = ((1024 + h264->intra_idr_period - 1) / h264->intra_idr_period + 1) / 2 * 2;
   if (context->gop_coeff > VL_VA_ENC_GOP_COEFF)
      context->gop_coeff = VL_VA_ENC_GOP_COEFF;
   context->desc.h264enc.gop_size = h264->intra_idr_period * context->gop_coeff;
d361 1
a361 1
   context->desc.h264enc.rate_ctrl.frame_rate_den = h264->num_units_in_tick;
d399 4
a402 4
   if (context->desc.h264enc.gop_cnt == 0)
      context->desc.h264enc.i_remain = context->gop_coeff;
   else if (context->desc.h264enc.frame_num == 1)
      context->desc.h264enc.i_remain--;
d421 1
d481 1
a481 1
   mtx_lock(&drv->mutex);
d484 1
a484 1
      mtx_unlock(&drv->mutex);
d491 1
a491 1
         mtx_unlock(&drv->mutex);
d535 1
a535 1
   mtx_unlock(&drv->mutex);
d556 1
a556 1
   mtx_lock(&drv->mutex);
d558 1
a558 1
   mtx_unlock(&drv->mutex);
d570 1
a570 1
   mtx_lock(&drv->mutex);
a576 1
      context->desc.h264enc.frame_num_cnt++;
d580 1
d586 4
a589 21
   if (context->decoder->entrypoint == PIPE_VIDEO_ENTRYPOINT_ENCODE) {
      int idr_period = context->desc.h264enc.gop_size / context->gop_coeff;
      int p_remain_in_idr = idr_period - context->desc.h264enc.frame_num;
      surf->frame_num_cnt = context->desc.h264enc.frame_num_cnt;
      surf->force_flushed = false;
      if (context->first_single_submitted) {
         context->decoder->flush(context->decoder);
         context->first_single_submitted = false;
         surf->force_flushed = true;
      }
      if (p_remain_in_idr == 1) {
         if ((context->desc.h264enc.frame_num_cnt % 2) != 0) {
            context->decoder->flush(context->decoder);
            context->first_single_submitted = true;
         }
         else
            context->first_single_submitted = false;
         surf->force_flushed = true;
      }
   }
   mtx_unlock(&drv->mutex);
@


