head	1.2;
access;
symbols
	mesa-17_1_6:1.1.1.3
	OPENBSD_6_1:1.1.1.2.0.2
	OPENBSD_6_1_BASE:1.1.1.2
	mesa-13_0_6:1.1.1.2
	mesa-13_0_5:1.1.1.2
	mesa-13_0_3:1.1.1.2
	mesa-13_0_2:1.1.1.2
	OPENBSD_6_0:1.1.1.2.0.4
	OPENBSD_6_0_BASE:1.1.1.2
	mesa-11_2_2:1.1.1.2
	OPENBSD_5_9:1.1.1.1.0.2
	OPENBSD_5_9_BASE:1.1.1.1
	mesa-11_0_9:1.1.1.1
	mesa-11_0_8:1.1.1.1
	mesa-11_0_6:1.1.1.1
	mesa:1.1.1;
locks; strict;
comment	@ * @;


1.2
date	2017.08.26.16.59.40;	author jsg;	state Exp;
branches;
next	1.1;
commitid	D0k2io1oY8gcsQ2S;

1.1
date	2015.11.22.02.38.17;	author jsg;	state Exp;
branches
	1.1.1.1;
next	;
commitid	bJUptkbooQfJPk5r;

1.1.1.1
date	2015.11.22.02.38.17;	author jsg;	state Exp;
branches;
next	1.1.1.2;
commitid	bJUptkbooQfJPk5r;

1.1.1.2
date	2016.05.29.10.13.26;	author jsg;	state Exp;
branches;
next	1.1.1.3;
commitid	OwGfrJACrYJkCVJ4;

1.1.1.3
date	2017.08.14.09.43.37;	author jsg;	state Exp;
branches;
next	;
commitid	enNyoMGkcgwM3Ww6;


desc
@@


1.2
log
@Revert to Mesa 13.0.6 to hopefully address rendering issues a handful of
people have reported with xpdf/fvwm on ivy bridge with modesetting driver.
@
text
@/*
 * Copyright (C) 2013 Christoph Bumiller
 * Copyright (C) 2015 Samuel Pitoiset
 *
 * Permission is hereby granted, free of charge, to any person obtaining a
 * copy of this software and associated documentation files (the "Software"),
 * to deal in the Software without restriction, including without limitation
 * the rights to use, copy, modify, merge, publish, distribute, sublicense,
 * and/or sell copies of the Software, and to permit persons to whom the
 * Software is furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included in
 * all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
 * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
 * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
 * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
 * OTHER DEALINGS IN THE SOFTWARE.
 */

/**
 * Performance monitoring counters interface to gallium.
 */

#include "st_debug.h"
#include "st_context.h"
#include "st_cb_bitmap.h"
#include "st_cb_perfmon.h"

#include "util/bitset.h"

#include "pipe/p_context.h"
#include "pipe/p_screen.h"
#include "util/u_memory.h"

static bool
init_perf_monitor(struct gl_context *ctx, struct gl_perf_monitor_object *m)
{
   struct st_context *st = st_context(ctx);
   struct st_perf_monitor_object *stm = st_perf_monitor_object(m);
   struct pipe_context *pipe = st->pipe;
   unsigned *batch = NULL;
   unsigned num_active_counters = 0;
   unsigned max_batch_counters = 0;
   unsigned num_batch_counters = 0;
   int gid, cid;

   st_flush_bitmap_cache(st);

   /* Determine the number of active counters. */
   for (gid = 0; gid < ctx->PerfMonitor.NumGroups; gid++) {
      const struct gl_perf_monitor_group *g = &ctx->PerfMonitor.Groups[gid];
      const struct st_perf_monitor_group *stg = &st->perfmon[gid];

      if (m->ActiveGroups[gid] > g->MaxActiveCounters) {
         /* Maximum number of counters reached. Cannot start the session. */
         if (ST_DEBUG & DEBUG_MESA) {
            debug_printf("Maximum number of counters reached. "
                         "Cannot start the session!\n");
         }
         return false;
      }

      num_active_counters += m->ActiveGroups[gid];
      if (stg->has_batch)
         max_batch_counters += m->ActiveGroups[gid];
   }

   if (!num_active_counters)
      return true;

   stm->active_counters = CALLOC(num_active_counters,
                                 sizeof(*stm->active_counters));
   if (!stm->active_counters)
      return false;

   if (max_batch_counters) {
      batch = CALLOC(max_batch_counters, sizeof(*batch));
      if (!batch)
         return false;
   }

   /* Create a query for each active counter. */
   for (gid = 0; gid < ctx->PerfMonitor.NumGroups; gid++) {
      const struct gl_perf_monitor_group *g = &ctx->PerfMonitor.Groups[gid];
      const struct st_perf_monitor_group *stg = &st->perfmon[gid];
      BITSET_WORD tmp;

      BITSET_FOREACH_SET(cid, tmp, m->ActiveCounters[gid], g->NumCounters) {
         const struct st_perf_monitor_counter *stc = &stg->counters[cid];
         struct st_perf_counter_object *cntr =
            &stm->active_counters[stm->num_active_counters];

         cntr->id       = cid;
         cntr->group_id = gid;
         if (stc->flags & PIPE_DRIVER_QUERY_FLAG_BATCH) {
            cntr->batch_index = num_batch_counters;
            batch[num_batch_counters++] = stc->query_type;
         } else {
            cntr->query = pipe->create_query(pipe, stc->query_type, 0);
            if (!cntr->query)
               goto fail;
         }
         ++stm->num_active_counters;
      }
   }

   /* Create the batch query. */
   if (num_batch_counters) {
      stm->batch_query = pipe->create_batch_query(pipe, num_batch_counters,
                                                  batch);
      stm->batch_result = CALLOC(num_batch_counters, sizeof(stm->batch_result->batch[0]));
      if (!stm->batch_query || !stm->batch_result)
         goto fail;
   }

   FREE(batch);
   return true;

fail:
   FREE(batch);
   return false;
}

static void
reset_perf_monitor(struct st_perf_monitor_object *stm,
                   struct pipe_context *pipe)
{
   unsigned i;

   for (i = 0; i < stm->num_active_counters; ++i) {
      struct pipe_query *query = stm->active_counters[i].query;
      if (query)
         pipe->destroy_query(pipe, query);
   }
   FREE(stm->active_counters);
   stm->active_counters = NULL;
   stm->num_active_counters = 0;

   if (stm->batch_query) {
      pipe->destroy_query(pipe, stm->batch_query);
      stm->batch_query = NULL;
   }
   FREE(stm->batch_result);
   stm->batch_result = NULL;
}

static struct gl_perf_monitor_object *
st_NewPerfMonitor(struct gl_context *ctx)
{
   struct st_perf_monitor_object *stq = ST_CALLOC_STRUCT(st_perf_monitor_object);
   if (stq)
      return &stq->base;
   return NULL;
}

static void
st_DeletePerfMonitor(struct gl_context *ctx, struct gl_perf_monitor_object *m)
{
   struct st_perf_monitor_object *stm = st_perf_monitor_object(m);
   struct pipe_context *pipe = st_context(ctx)->pipe;

   reset_perf_monitor(stm, pipe);
   FREE(stm);
}

static GLboolean
st_BeginPerfMonitor(struct gl_context *ctx, struct gl_perf_monitor_object *m)
{
   struct st_perf_monitor_object *stm = st_perf_monitor_object(m);
   struct pipe_context *pipe = st_context(ctx)->pipe;
   unsigned i;

   if (!stm->num_active_counters) {
      /* Create a query for each active counter before starting
       * a new monitoring session. */
      if (!init_perf_monitor(ctx, m))
         goto fail;
   }

   /* Start the query for each active counter. */
   for (i = 0; i < stm->num_active_counters; ++i) {
      struct pipe_query *query = stm->active_counters[i].query;
      if (query && !pipe->begin_query(pipe, query))
          goto fail;
   }

   if (stm->batch_query && !pipe->begin_query(pipe, stm->batch_query))
      goto fail;

   return true;

fail:
   /* Failed to start the monitoring session. */
   reset_perf_monitor(stm, pipe);
   return false;
}

static void
st_EndPerfMonitor(struct gl_context *ctx, struct gl_perf_monitor_object *m)
{
   struct st_perf_monitor_object *stm = st_perf_monitor_object(m);
   struct pipe_context *pipe = st_context(ctx)->pipe;
   unsigned i;

   /* Stop the query for each active counter. */
   for (i = 0; i < stm->num_active_counters; ++i) {
      struct pipe_query *query = stm->active_counters[i].query;
      if (query)
         pipe->end_query(pipe, query);
   }

   if (stm->batch_query)
      pipe->end_query(pipe, stm->batch_query);
}

static void
st_ResetPerfMonitor(struct gl_context *ctx, struct gl_perf_monitor_object *m)
{
   struct st_perf_monitor_object *stm = st_perf_monitor_object(m);
   struct pipe_context *pipe = st_context(ctx)->pipe;

   if (!m->Ended)
      st_EndPerfMonitor(ctx, m);

   reset_perf_monitor(stm, pipe);

   if (m->Active)
      st_BeginPerfMonitor(ctx, m);
}

static GLboolean
st_IsPerfMonitorResultAvailable(struct gl_context *ctx,
                                struct gl_perf_monitor_object *m)
{
   struct st_perf_monitor_object *stm = st_perf_monitor_object(m);
   struct pipe_context *pipe = st_context(ctx)->pipe;
   unsigned i;

   if (!stm->num_active_counters)
      return false;

   /* The result of a monitoring session is only available if the query of
    * each active counter is idle. */
   for (i = 0; i < stm->num_active_counters; ++i) {
      struct pipe_query *query = stm->active_counters[i].query;
      union pipe_query_result result;
      if (query && !pipe->get_query_result(pipe, query, FALSE, &result)) {
         /* The query is busy. */
         return false;
      }
   }

   if (stm->batch_query &&
       !pipe->get_query_result(pipe, stm->batch_query, FALSE, stm->batch_result))
      return false;

   return true;
}

static void
st_GetPerfMonitorResult(struct gl_context *ctx,
                        struct gl_perf_monitor_object *m,
                        GLsizei dataSize,
                        GLuint *data,
                        GLint *bytesWritten)
{
   struct st_perf_monitor_object *stm = st_perf_monitor_object(m);
   struct pipe_context *pipe = st_context(ctx)->pipe;
   unsigned i;

   /* Copy data to the supplied array (data).
    *
    * The output data format is: <group ID, counter ID, value> for each
    * active counter. The API allows counters to appear in any order.
    */
   GLsizei offset = 0;
   bool have_batch_query = false;

   if (stm->batch_query)
      have_batch_query = pipe->get_query_result(pipe, stm->batch_query, TRUE,
                                                stm->batch_result);

   /* Read query results for each active counter. */
   for (i = 0; i < stm->num_active_counters; ++i) {
      struct st_perf_counter_object *cntr = &stm->active_counters[i];
      union pipe_query_result result = { 0 };
      int gid, cid;
      GLenum type;

      cid  = cntr->id;
      gid  = cntr->group_id;
      type = ctx->PerfMonitor.Groups[gid].Counters[cid].Type;

      if (cntr->query) {
         if (!pipe->get_query_result(pipe, cntr->query, TRUE, &result))
            continue;
      } else {
         if (!have_batch_query)
            continue;
         result.batch[0] = stm->batch_result->batch[cntr->batch_index];
      }

      data[offset++] = gid;
      data[offset++] = cid;
      switch (type) {
      case GL_UNSIGNED_INT64_AMD:
         *(uint64_t *)&data[offset] = result.u64;
         offset += sizeof(uint64_t) / sizeof(GLuint);
         break;
      case GL_UNSIGNED_INT:
         *(uint32_t *)&data[offset] = result.u32;
         offset += sizeof(uint32_t) / sizeof(GLuint);
         break;
      case GL_FLOAT:
      case GL_PERCENTAGE_AMD:
         *(GLfloat *)&data[offset] = result.f;
         offset += sizeof(GLfloat) / sizeof(GLuint);
         break;
      }
   }

   if (bytesWritten)
      *bytesWritten = offset * sizeof(GLuint);
}


bool
st_have_perfmon(struct st_context *st)
{
   struct pipe_screen *screen = st->pipe->screen;

   if (!screen->get_driver_query_info || !screen->get_driver_query_group_info)
      return false;

   return screen->get_driver_query_group_info(screen, 0, NULL) != 0;
}

static void
st_InitPerfMonitorGroups(struct gl_context *ctx)
{
   struct st_context *st = st_context(ctx);
   struct gl_perf_monitor_state *perfmon = &st->ctx->PerfMonitor;
   struct pipe_screen *screen = st->pipe->screen;
   struct gl_perf_monitor_group *groups = NULL;
   struct st_perf_monitor_group *stgroups = NULL;
   int num_counters, num_groups;
   int gid, cid;

   /* Get the number of available queries. */
   num_counters = screen->get_driver_query_info(screen, 0, NULL);

   /* Get the number of available groups. */
   num_groups = screen->get_driver_query_group_info(screen, 0, NULL);
   groups = CALLOC(num_groups, sizeof(*groups));
   if (!groups)
      return;

   stgroups = CALLOC(num_groups, sizeof(*stgroups));
   if (!stgroups)
      goto fail_only_groups;

   for (gid = 0; gid < num_groups; gid++) {
      struct gl_perf_monitor_group *g = &groups[perfmon->NumGroups];
      struct st_perf_monitor_group *stg = &stgroups[perfmon->NumGroups];
      struct pipe_driver_query_group_info group_info;
      struct gl_perf_monitor_counter *counters = NULL;
      struct st_perf_monitor_counter *stcounters = NULL;

      if (!screen->get_driver_query_group_info(screen, gid, &group_info))
         continue;

      g->Name = group_info.name;
      g->MaxActiveCounters = group_info.max_active_queries;

      if (group_info.num_queries)
         counters = CALLOC(group_info.num_queries, sizeof(*counters));
      if (!counters)
         goto fail;
      g->Counters = counters;

      stcounters = CALLOC(group_info.num_queries, sizeof(*stcounters));
      if (!stcounters)
         goto fail;
      stg->counters = stcounters;

      for (cid = 0; cid < num_counters; cid++) {
         struct gl_perf_monitor_counter *c = &counters[g->NumCounters];
         struct st_perf_monitor_counter *stc = &stcounters[g->NumCounters];
         struct pipe_driver_query_info info;

         if (!screen->get_driver_query_info(screen, cid, &info))
            continue;
         if (info.group_id != gid)
            continue;

         c->Name = info.name;
         switch (info.type) {
            case PIPE_DRIVER_QUERY_TYPE_UINT64:
            case PIPE_DRIVER_QUERY_TYPE_BYTES:
            case PIPE_DRIVER_QUERY_TYPE_MICROSECONDS:
            case PIPE_DRIVER_QUERY_TYPE_HZ:
               c->Minimum.u64 = 0;
               c->Maximum.u64 = info.max_value.u64 ? info.max_value.u64 : -1;
               c->Type = GL_UNSIGNED_INT64_AMD;
               break;
            case PIPE_DRIVER_QUERY_TYPE_UINT:
               c->Minimum.u32 = 0;
               c->Maximum.u32 = info.max_value.u32 ? info.max_value.u32 : -1;
               c->Type = GL_UNSIGNED_INT;
               break;
            case PIPE_DRIVER_QUERY_TYPE_FLOAT:
               c->Minimum.f = 0.0;
               c->Maximum.f = info.max_value.f ? info.max_value.f : -1;
               c->Type = GL_FLOAT;
               break;
            case PIPE_DRIVER_QUERY_TYPE_PERCENTAGE:
               c->Minimum.f = 0.0f;
               c->Maximum.f = 100.0f;
               c->Type = GL_PERCENTAGE_AMD;
               break;
            default:
               unreachable("Invalid driver query type!");
         }

         stc->query_type = info.query_type;
         stc->flags = info.flags;
         if (stc->flags & PIPE_DRIVER_QUERY_FLAG_BATCH)
            stg->has_batch = true;

         g->NumCounters++;
      }
      perfmon->NumGroups++;
   }
   perfmon->Groups = groups;
   st->perfmon = stgroups;

   return;

fail:
   for (gid = 0; gid < num_groups; gid++) {
      FREE(stgroups[gid].counters);
      FREE((void *)groups[gid].Counters);
   }
   FREE(stgroups);
fail_only_groups:
   FREE(groups);
}

void
st_destroy_perfmon(struct st_context *st)
{
   struct gl_perf_monitor_state *perfmon = &st->ctx->PerfMonitor;
   int gid;

   for (gid = 0; gid < perfmon->NumGroups; gid++) {
      FREE(st->perfmon[gid].counters);
      FREE((void *)perfmon->Groups[gid].Counters);
   }
   FREE(st->perfmon);
   FREE((void *)perfmon->Groups);
}

void st_init_perfmon_functions(struct dd_function_table *functions)
{
   functions->InitPerfMonitorGroups = st_InitPerfMonitorGroups;
   functions->NewPerfMonitor = st_NewPerfMonitor;
   functions->DeletePerfMonitor = st_DeletePerfMonitor;
   functions->BeginPerfMonitor = st_BeginPerfMonitor;
   functions->EndPerfMonitor = st_EndPerfMonitor;
   functions->ResetPerfMonitor = st_ResetPerfMonitor;
   functions->IsPerfMonitorResultAvailable = st_IsPerfMonitorResultAvailable;
   functions->GetPerfMonitorResult = st_GetPerfMonitorResult;
}
@


1.1
log
@Initial revision
@
text
@a38 50
/**
 * Return a PIPE_QUERY_x type >= PIPE_QUERY_DRIVER_SPECIFIC, or -1 if
 * the driver-specific query doesn't exist.
 */
static int
find_query_type(struct pipe_screen *screen, const char *name)
{
   int num_queries;
   int type = -1;
   int i;

   num_queries = screen->get_driver_query_info(screen, 0, NULL);
   if (!num_queries)
      return type;

   for (i = 0; i < num_queries; i++) {
      struct pipe_driver_query_info info;

      if (!screen->get_driver_query_info(screen, i, &info))
         continue;

      if (!strncmp(info.name, name, strlen(name))) {
         type = info.query_type;
         break;
      }
   }
   return type;
}

/**
 * Return TRUE if the underlying driver expose GPU counters.
 */
static bool
has_gpu_counters(struct pipe_screen *screen)
{
   int num_groups, gid;

   num_groups = screen->get_driver_query_group_info(screen, 0, NULL);
   for (gid = 0; gid < num_groups; gid++) {
      struct pipe_driver_query_group_info group_info;

      if (!screen->get_driver_query_group_info(screen, gid, &group_info))
         continue;

      if (group_info.type == PIPE_DRIVER_QUERY_GROUP_TYPE_GPU)
         return true;
   }
   return false;
}

d42 1
d44 5
a48 2
   struct pipe_screen *screen = st_context(ctx)->pipe->screen;
   struct pipe_context *pipe = st_context(ctx)->pipe;
d51 1
a51 1
   st_flush_bitmap_cache(st_context(ctx));
d53 1
a53 1
   /* Create a query for each active counter. */
d56 1
d67 7
a73 4
      for (cid = 0; cid < g->NumCounters; cid++) {
         const struct gl_perf_monitor_counter *c = &g->Counters[cid];
         struct st_perf_counter_object *cntr;
         int query_type;
d75 10
a84 2
         if (!BITSET_TEST(m->ActiveCounters[gid], cid))
            continue;
d86 5
a90 2
         query_type = find_query_type(screen, c->Name);
         assert(query_type != -1);
d92 4
a95 3
         cntr = CALLOC_STRUCT(st_perf_counter_object);
         if (!cntr)
            return false;
a96 1
         cntr->query    = pipe->create_query(pipe, query_type, 0);
d99 11
d111 7
a117 2
         list_addtail(&cntr->list, &stm->active_counters);
      }
d119 2
d122 4
d132 1
a132 1
   struct st_perf_counter_object *cntr, *tmp;
d134 12
a145 5
   LIST_FOR_EACH_ENTRY_SAFE(cntr, tmp, &stm->active_counters, list) {
      if (cntr->query)
         pipe->destroy_query(pipe, cntr->query);
      list_del(&cntr->list);
      free(cntr);
d147 2
d155 1
a155 2
   if (stq) {
      list_inithead(&stq->active_counters);
a156 1
   }
d175 1
a175 1
   struct st_perf_counter_object *cntr;
d177 1
a177 1
   if (LIST_IS_EMPTY(&stm->active_counters)) {
d185 3
a187 2
   LIST_FOR_EACH_ENTRY(cntr, &stm->active_counters, list) {
      if (!pipe->begin_query(pipe, cntr->query))
d190 4
d207 1
a207 1
   struct st_perf_counter_object *cntr;
d210 8
a217 2
   LIST_FOR_EACH_ENTRY(cntr, &stm->active_counters, list)
      pipe->end_query(pipe, cntr->query);
d241 1
a241 1
   struct st_perf_counter_object *cntr;
d243 1
a243 1
   if (LIST_IS_EMPTY(&stm->active_counters))
d248 2
a249 1
   LIST_FOR_EACH_ENTRY(cntr, &stm->active_counters, list) {
d251 1
a251 1
      if (!pipe->get_query_result(pipe, cntr->query, FALSE, &result)) {
d256 5
d273 1
a273 1
   struct st_perf_counter_object *cntr;
d281 5
d288 2
a289 1
   LIST_FOR_EACH_ENTRY(cntr, &stm->active_counters, list) {
d298 8
a305 2
      if (!pipe->get_query_result(pipe, cntr->query, TRUE, &result))
         continue;
d332 12
a343 1
st_init_perfmon(struct st_context *st)
d345 1
d349 1
a352 9
   if (!screen->get_driver_query_info || !screen->get_driver_query_group_info)
      return false;

   if (!has_gpu_counters(screen)) {
      /* According to the spec, GL_AMD_performance_monitor must only
       * expose GPU counters. */
      return false;
   }

a354 2
   if (!num_counters)
      return false;
d358 1
a358 2
   if (num_groups)
      groups = CALLOC(num_groups, sizeof(*groups));
d360 5
a364 1
      return false;
d368 1
d371 1
a375 3
      if (group_info.type != PIPE_DRIVER_QUERY_GROUP_TYPE_GPU)
         continue;

a377 2
      g->NumCounters = 0;
      g->Counters = NULL;
d383 6
d392 1
d403 3
d428 6
a435 1
      g->Counters = counters;
d439 1
d441 1
a441 1
   return true;
d444 2
a445 1
   for (gid = 0; gid < num_groups; gid++)
d447 3
a450 1
   return false;
d459 2
a460 1
   for (gid = 0; gid < perfmon->NumGroups; gid++)
d462 2
d469 1
@


1.1.1.1
log
@import Mesa 11.0.6
@
text
@@


1.1.1.2
log
@Import Mesa 11.2.2
@
text
@d39 50
a91 1
   struct st_context *st = st_context(ctx);
d93 2
a94 5
   struct pipe_context *pipe = st->pipe;
   unsigned *batch = NULL;
   unsigned num_active_counters = 0;
   unsigned max_batch_counters = 0;
   unsigned num_batch_counters = 0;
d97 1
a97 1
   st_flush_bitmap_cache(st);
d99 1
a99 1
   /* Determine the number of active counters. */
a101 1
      const struct st_perf_monitor_group *stg = &st->perfmon[gid];
d112 4
a115 4
      num_active_counters += m->ActiveGroups[gid];
      if (stg->has_batch)
         max_batch_counters += m->ActiveGroups[gid];
   }
d117 2
a118 2
   if (!num_active_counters)
      return true;
d120 2
a121 16
   stm->active_counters = CALLOC(num_active_counters,
                                 sizeof(*stm->active_counters));
   if (!stm->active_counters)
      return false;

   if (max_batch_counters) {
      batch = CALLOC(max_batch_counters, sizeof(*batch));
      if (!batch)
         return false;
   }

   /* Create a query for each active counter. */
   for (gid = 0; gid < ctx->PerfMonitor.NumGroups; gid++) {
      const struct gl_perf_monitor_group *g = &ctx->PerfMonitor.Groups[gid];
      const struct st_perf_monitor_group *stg = &st->perfmon[gid];
      BITSET_WORD tmp;
d123 3
a125 4
      BITSET_FOREACH_SET(cid, tmp, m->ActiveCounters[gid], g->NumCounters) {
         const struct st_perf_monitor_counter *stc = &stg->counters[cid];
         struct st_perf_counter_object *cntr =
            &stm->active_counters[stm->num_active_counters];
d127 1
d130 2
a131 9
         if (stc->flags & PIPE_DRIVER_QUERY_FLAG_BATCH) {
            cntr->batch_index = num_batch_counters;
            batch[num_batch_counters++] = stc->query_type;
         } else {
            cntr->query = pipe->create_query(pipe, stc->query_type, 0);
            if (!cntr->query)
               goto fail;
         }
         ++stm->num_active_counters;
a133 11

   /* Create the batch query. */
   if (num_batch_counters) {
      stm->batch_query = pipe->create_batch_query(pipe, num_batch_counters,
                                                  batch);
      stm->batch_result = CALLOC(num_batch_counters, sizeof(stm->batch_result->batch[0]));
      if (!stm->batch_query || !stm->batch_result)
         goto fail;
   }

   FREE(batch);
a134 4

fail:
   FREE(batch);
   return false;
d141 1
a141 1
   unsigned i;
d143 5
a147 12
   for (i = 0; i < stm->num_active_counters; ++i) {
      struct pipe_query *query = stm->active_counters[i].query;
      if (query)
         pipe->destroy_query(pipe, query);
   }
   FREE(stm->active_counters);
   stm->active_counters = NULL;
   stm->num_active_counters = 0;

   if (stm->batch_query) {
      pipe->destroy_query(pipe, stm->batch_query);
      stm->batch_query = NULL;
a148 2
   FREE(stm->batch_result);
   stm->batch_result = NULL;
d155 2
a156 1
   if (stq)
d158 1
d177 1
a177 1
   unsigned i;
d179 1
a179 1
   if (!stm->num_active_counters) {
d187 2
a188 3
   for (i = 0; i < stm->num_active_counters; ++i) {
      struct pipe_query *query = stm->active_counters[i].query;
      if (query && !pipe->begin_query(pipe, query))
a190 4

   if (stm->batch_query && !pipe->begin_query(pipe, stm->batch_query))
      goto fail;

d204 1
a204 1
   unsigned i;
d207 2
a208 8
   for (i = 0; i < stm->num_active_counters; ++i) {
      struct pipe_query *query = stm->active_counters[i].query;
      if (query)
         pipe->end_query(pipe, query);
   }

   if (stm->batch_query)
      pipe->end_query(pipe, stm->batch_query);
d232 1
a232 1
   unsigned i;
d234 1
a234 1
   if (!stm->num_active_counters)
d239 1
a239 2
   for (i = 0; i < stm->num_active_counters; ++i) {
      struct pipe_query *query = stm->active_counters[i].query;
d241 1
a241 1
      if (query && !pipe->get_query_result(pipe, query, FALSE, &result)) {
a245 5

   if (stm->batch_query &&
       !pipe->get_query_result(pipe, stm->batch_query, FALSE, stm->batch_result))
      return false;

d258 1
a258 1
   unsigned i;
a265 5
   bool have_batch_query = false;

   if (stm->batch_query)
      have_batch_query = pipe->get_query_result(pipe, stm->batch_query, TRUE,
                                                stm->batch_result);
d268 1
a268 2
   for (i = 0; i < stm->num_active_counters; ++i) {
      struct st_perf_counter_object *cntr = &stm->active_counters[i];
d277 2
a278 8
      if (cntr->query) {
         if (!pipe->get_query_result(pipe, cntr->query, TRUE, &result))
            continue;
      } else {
         if (!have_batch_query)
            continue;
         result.batch[0] = stm->batch_result->batch[cntr->batch_index];
      }
d305 1
a305 1
st_have_perfmon(struct st_context *st)
d307 1
d309 3
d316 5
a320 13
   return screen->get_driver_query_group_info(screen, 0, NULL) != 0;
}

static void
st_InitPerfMonitorGroups(struct gl_context *ctx)
{
   struct st_context *st = st_context(ctx);
   struct gl_perf_monitor_state *perfmon = &st->ctx->PerfMonitor;
   struct pipe_screen *screen = st->pipe->screen;
   struct gl_perf_monitor_group *groups = NULL;
   struct st_perf_monitor_group *stgroups = NULL;
   int num_counters, num_groups;
   int gid, cid;
d324 2
d329 2
a330 1
   groups = CALLOC(num_groups, sizeof(*groups));
d332 1
a332 5
      return;

   stgroups = CALLOC(num_groups, sizeof(*stgroups));
   if (!stgroups)
      goto fail_only_groups;
a335 1
      struct st_perf_monitor_group *stg = &stgroups[perfmon->NumGroups];
a337 1
      struct st_perf_monitor_counter *stcounters = NULL;
d342 3
d347 2
a353 6
      g->Counters = counters;

      stcounters = CALLOC(group_info.num_queries, sizeof(*stcounters));
      if (!stcounters)
         goto fail;
      stg->counters = stcounters;
a356 1
         struct st_perf_monitor_counter *stc = &stcounters[g->NumCounters];
a366 3
            case PIPE_DRIVER_QUERY_TYPE_BYTES:
            case PIPE_DRIVER_QUERY_TYPE_MICROSECONDS:
            case PIPE_DRIVER_QUERY_TYPE_HZ:
a388 6

         stc->query_type = info.query_type;
         stc->flags = info.flags;
         if (stc->flags & PIPE_DRIVER_QUERY_FLAG_BATCH)
            stg->has_batch = true;

d391 1
a394 1
   st->perfmon = stgroups;
d396 1
a396 1
   return;
d399 1
a399 2
   for (gid = 0; gid < num_groups; gid++) {
      FREE(stgroups[gid].counters);
a400 3
   }
   FREE(stgroups);
fail_only_groups:
d402 1
d411 1
a411 2
   for (gid = 0; gid < perfmon->NumGroups; gid++) {
      FREE(st->perfmon[gid].counters);
a412 2
   }
   FREE(st->perfmon);
a417 1
   functions->InitPerfMonitorGroups = st_InitPerfMonitorGroups;
@


1.1.1.3
log
@Import Mesa 17.1.6
@
text
@d311 1
a311 1
         memcpy(&data[offset], &result.u64, sizeof(uint64_t));
d315 1
a315 1
         memcpy(&data[offset], &result.u32, sizeof(uint32_t));
d320 1
a320 1
         memcpy(&data[offset], &result.f, sizeof(GLfloat));
@


