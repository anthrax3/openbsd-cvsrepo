head	1.2;
access;
symbols
	OPENBSD_6_2:1.2.0.2
	OPENBSD_6_2_BASE:1.2
	mesa-17_1_6:1.1.1.4
	OPENBSD_6_1:1.1.1.3.0.2
	OPENBSD_6_1_BASE:1.1.1.3
	mesa-13_0_6:1.1.1.3
	mesa-13_0_5:1.1.1.2
	mesa-13_0_3:1.1.1.2
	mesa-13_0_2:1.1.1.2
	OPENBSD_6_0:1.1.1.1.0.4
	OPENBSD_6_0_BASE:1.1.1.1
	mesa-11_2_2:1.1.1.1
	mesa:1.1.1;
locks; strict;
comment	@ * @;
expand	@o@;


1.2
date	2017.08.26.16.59.20;	author jsg;	state Exp;
branches;
next	1.1;
commitid	D0k2io1oY8gcsQ2S;

1.1
date	2016.05.29.10.16.38;	author jsg;	state Exp;
branches
	1.1.1.1;
next	;
commitid	OwGfrJACrYJkCVJ4;

1.1.1.1
date	2016.05.29.10.16.38;	author jsg;	state Exp;
branches;
next	1.1.1.2;
commitid	OwGfrJACrYJkCVJ4;

1.1.1.2
date	2016.12.11.08.33.22;	author jsg;	state Exp;
branches;
next	1.1.1.3;
commitid	uuv5VTS15jglEDZU;

1.1.1.3
date	2017.03.25.00.12.55;	author jsg;	state Exp;
branches;
next	1.1.1.4;
commitid	YgkKuQ9hssScckR1;

1.1.1.4
date	2017.08.14.09.38.05;	author jsg;	state Exp;
branches;
next	;
commitid	enNyoMGkcgwM3Ww6;


desc
@@


1.2
log
@Revert to Mesa 13.0.6 to hopefully address rendering issues a handful of
people have reported with xpdf/fvwm on ivy bridge with modesetting driver.
@
text
@/*
 * Copyright Â© 2010 Intel Corporation
 *
 * Permission is hereby granted, free of charge, to any person obtaining a
 * copy of this software and associated documentation files (the "Software"),
 * to deal in the Software without restriction, including without limitation
 * the rights to use, copy, modify, merge, publish, distribute, sublicense,
 * and/or sell copies of the Software, and to permit persons to whom the
 * Software is furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice (including the next
 * paragraph) shall be included in all copies or substantial portions of the
 * Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
 * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
 * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
 * DEALINGS IN THE SOFTWARE.
 */


/**
 * \file ir_optimization.h
 *
 * Prototypes for optimization passes to be called by the compiler and drivers.
 */

/* Operations for lower_instructions() */
#define SUB_TO_ADD_NEG     0x01
#define FDIV_TO_MUL_RCP    0x02
#define EXP_TO_EXP2        0x04
#define POW_TO_EXP2        0x08
#define LOG_TO_LOG2        0x10
#define MOD_TO_FLOOR       0x20
#define INT_DIV_TO_MUL_RCP 0x40
#define LDEXP_TO_ARITH     0x80
#define CARRY_TO_ARITH     0x100
#define BORROW_TO_ARITH    0x200
#define SAT_TO_CLAMP       0x400
#define DOPS_TO_DFRAC      0x800
#define DFREXP_DLDEXP_TO_ARITH    0x1000
#define BIT_COUNT_TO_MATH         0x02000
#define EXTRACT_TO_SHIFTS         0x04000
#define INSERT_TO_SHIFTS          0x08000
#define REVERSE_TO_SHIFTS         0x10000
#define FIND_LSB_TO_FLOAT_CAST    0x20000
#define FIND_MSB_TO_FLOAT_CAST    0x40000
#define IMUL_HIGH_TO_MUL          0x80000
#define DDIV_TO_MUL_RCP           0x100000
#define DIV_TO_MUL_RCP            (FDIV_TO_MUL_RCP | DDIV_TO_MUL_RCP)

/**
 * \see class lower_packing_builtins_visitor
 */
enum lower_packing_builtins_op {
   LOWER_PACK_UNPACK_NONE               = 0x0000,

   LOWER_PACK_SNORM_2x16                = 0x0001,
   LOWER_UNPACK_SNORM_2x16              = 0x0002,

   LOWER_PACK_UNORM_2x16                = 0x0004,
   LOWER_UNPACK_UNORM_2x16              = 0x0008,

   LOWER_PACK_HALF_2x16                 = 0x0010,
   LOWER_UNPACK_HALF_2x16               = 0x0020,

   LOWER_PACK_SNORM_4x8                 = 0x0040,
   LOWER_UNPACK_SNORM_4x8               = 0x0080,

   LOWER_PACK_UNORM_4x8                 = 0x0100,
   LOWER_UNPACK_UNORM_4x8               = 0x0200,

   LOWER_PACK_USE_BFI                   = 0x0400,
   LOWER_PACK_USE_BFE                   = 0x0800,
};

bool do_common_optimization(exec_list *ir, bool linked,
			    bool uniform_locations_assigned,
                            const struct gl_shader_compiler_options *options,
                            bool native_integers);

bool ir_constant_fold(ir_rvalue **rvalue);

bool do_rebalance_tree(exec_list *instructions);
bool do_algebraic(exec_list *instructions, bool native_integers,
                  const struct gl_shader_compiler_options *options);
bool opt_conditional_discard(exec_list *instructions);
bool do_constant_folding(exec_list *instructions);
bool do_constant_variable(exec_list *instructions);
bool do_constant_variable_unlinked(exec_list *instructions);
bool do_copy_propagation(exec_list *instructions);
bool do_copy_propagation_elements(exec_list *instructions);
bool do_constant_propagation(exec_list *instructions);
void do_dead_builtin_varyings(struct gl_context *ctx,
                              gl_linked_shader *producer,
                              gl_linked_shader *consumer,
                              unsigned num_tfeedback_decls,
                              class tfeedback_decl *tfeedback_decls);
bool do_dead_code(exec_list *instructions, bool uniform_locations_assigned);
bool do_dead_code_local(exec_list *instructions);
bool do_dead_code_unlinked(exec_list *instructions);
bool do_dead_functions(exec_list *instructions);
bool opt_flip_matrices(exec_list *instructions);
bool do_function_inlining(exec_list *instructions);
bool do_lower_jumps(exec_list *instructions, bool pull_out_jumps = true, bool lower_sub_return = true, bool lower_main_return = false, bool lower_continue = false, bool lower_break = false);
bool do_lower_texture_projection(exec_list *instructions);
bool do_if_simplification(exec_list *instructions);
bool opt_flatten_nested_if_blocks(exec_list *instructions);
bool do_discard_simplification(exec_list *instructions);
bool lower_if_to_cond_assign(exec_list *instructions, unsigned max_depth = 0);
bool do_mat_op_to_vec(exec_list *instructions);
bool do_minmax_prune(exec_list *instructions);
bool do_noop_swizzle(exec_list *instructions);
bool do_structure_splitting(exec_list *instructions);
bool do_swizzle_swizzle(exec_list *instructions);
bool do_vectorize(exec_list *instructions);
bool do_tree_grafting(exec_list *instructions);
bool do_vec_index_to_cond_assign(exec_list *instructions);
bool do_vec_index_to_swizzle(exec_list *instructions);
bool lower_discard(exec_list *instructions);
void lower_discard_flow(exec_list *instructions);
bool lower_instructions(exec_list *instructions, unsigned what_to_lower);
bool lower_noise(exec_list *instructions);
bool lower_variable_index_to_cond_assign(gl_shader_stage stage,
    exec_list *instructions, bool lower_input, bool lower_output,
    bool lower_temp, bool lower_uniform);
bool lower_quadop_vector(exec_list *instructions, bool dont_lower_swz);
bool lower_const_arrays_to_uniforms(exec_list *instructions, unsigned stage);
bool lower_clip_cull_distance(struct gl_shader_program *prog,
                              gl_linked_shader *shader);
void lower_output_reads(unsigned stage, exec_list *instructions);
bool lower_packing_builtins(exec_list *instructions, int op_mask);
void lower_shared_reference(struct gl_linked_shader *shader,
                            unsigned *shared_size);
void lower_ubo_reference(struct gl_linked_shader *shader,
                         bool clamp_block_indices);
void lower_packed_varyings(void *mem_ctx,
                           unsigned locations_used, ir_variable_mode mode,
                           unsigned gs_input_vertices,
                           gl_linked_shader *shader,
                           bool disable_varying_packing, bool xfb_enabled);
bool lower_vector_insert(exec_list *instructions, bool lower_nonconstant_index);
bool lower_vector_derefs(gl_linked_shader *shader);
void lower_named_interface_blocks(void *mem_ctx, gl_linked_shader *shader);
bool optimize_redundant_jumps(exec_list *instructions);
bool optimize_split_arrays(exec_list *instructions, bool linked);
bool lower_offset_arrays(exec_list *instructions);
void optimize_dead_builtin_variables(exec_list *instructions,
                                     enum ir_variable_mode other);
bool lower_tess_level(gl_linked_shader *shader);

bool lower_vertex_id(gl_linked_shader *shader);
bool lower_blend_equation_advanced(gl_linked_shader *shader);

bool lower_subroutine(exec_list *instructions, struct _mesa_glsl_parse_state *state);
void propagate_invariance(exec_list *instructions);

ir_rvalue *
compare_index_block(exec_list *instructions, ir_variable *index,
		    unsigned base, unsigned components, void *mem_ctx);
@


1.1
log
@Initial revision
@
text
@d33 1
a33 1
#define DIV_TO_MUL_RCP     0x02
d45 9
d85 2
d98 2
a99 1
                              gl_shader *producer, gl_shader *consumer,
d131 3
a133 2
bool lower_const_arrays_to_uniforms(exec_list *instructions);
bool lower_clip_distance(gl_shader *shader);
d136 4
a139 2
void lower_shared_reference(struct gl_shader *shader, unsigned *shared_size);
void lower_ubo_reference(struct gl_shader *shader);
d142 3
a144 1
                           unsigned gs_input_vertices, gl_shader *shader);
d146 2
a147 2
bool lower_vector_derefs(gl_shader *shader);
void lower_named_interface_blocks(void *mem_ctx, gl_shader *shader);
d153 1
a153 1
bool lower_tess_level(gl_shader *shader);
d155 2
a156 1
bool lower_vertex_id(gl_shader *shader);
d159 1
@


1.1.1.1
log
@Import Mesa 11.2.2
@
text
@@


1.1.1.2
log
@Import Mesa 13.0.2
@
text
@a44 7
#define BIT_COUNT_TO_MATH         0x02000
#define EXTRACT_TO_SHIFTS         0x04000
#define INSERT_TO_SHIFTS          0x08000
#define REVERSE_TO_SHIFTS         0x10000
#define FIND_LSB_TO_FLOAT_CAST    0x20000
#define FIND_MSB_TO_FLOAT_CAST    0x40000
#define IMUL_HIGH_TO_MUL          0x80000
a75 2
bool ir_constant_fold(ir_rvalue **rvalue);

d87 1
a87 2
                              gl_linked_shader *producer,
                              gl_linked_shader *consumer,
d119 2
a120 3
bool lower_const_arrays_to_uniforms(exec_list *instructions, unsigned stage);
bool lower_clip_cull_distance(struct gl_shader_program *prog,
                              gl_linked_shader *shader);
d123 2
a124 4
void lower_shared_reference(struct gl_linked_shader *shader,
                            unsigned *shared_size);
void lower_ubo_reference(struct gl_linked_shader *shader,
                         bool clamp_block_indices);
d127 1
a127 3
                           unsigned gs_input_vertices,
                           gl_linked_shader *shader,
                           bool disable_varying_packing, bool xfb_enabled);
d129 2
a130 2
bool lower_vector_derefs(gl_linked_shader *shader);
void lower_named_interface_blocks(void *mem_ctx, gl_linked_shader *shader);
d136 1
a136 1
bool lower_tess_level(gl_linked_shader *shader);
d138 1
a138 2
bool lower_vertex_id(gl_linked_shader *shader);
bool lower_blend_equation_advanced(gl_linked_shader *shader);
a140 1
void propagate_invariance(exec_list *instructions);
@


1.1.1.3
log
@Import Mesa 13.0.6
@
text
@d33 1
a33 1
#define FDIV_TO_MUL_RCP    0x02
a51 2
#define DDIV_TO_MUL_RCP           0x100000
#define DIV_TO_MUL_RCP            (FDIV_TO_MUL_RCP | DDIV_TO_MUL_RCP)
@


1.1.1.4
log
@Import Mesa 17.1.6
@
text
@d24 1
a30 3
#ifndef GLSL_IR_OPTIMIZATION_H
#define GLSL_IR_OPTIMIZATION_H

a53 7
#define SQRT_TO_ABS_SQRT          0x200000

/* Opertaions for lower_64bit_integer_instructions() */
#define MUL64                     (1U << 0)
#define SIGN64                    (1U << 1)
#define DIV64                     (1U << 2)
#define MOD64                     (1U << 3)
d113 1
a113 2
bool lower_if_to_cond_assign(gl_shader_stage stage, exec_list *instructions,
                             unsigned max_depth = 0, unsigned min_branch_cost = 0);
d141 1
a141 3
                           unsigned locations_used,
                           const uint8_t *components,
                           ir_variable_mode mode,
a163 5

bool lower_64bit_integer_instructions(exec_list *instructions,
                                      unsigned what_to_lower);

#endif /* GLSL_IR_OPTIMIZATION_H */
@


