head	1.1;
branch	1.1.1;
access;
symbols
	mesa-17_1_6:1.1.1.3
	OPENBSD_6_1:1.1.1.2.0.2
	OPENBSD_6_1_BASE:1.1.1.2
	mesa-13_0_6:1.1.1.2
	mesa-13_0_5:1.1.1.2
	mesa-13_0_3:1.1.1.2
	mesa-13_0_2:1.1.1.2
	OPENBSD_6_0:1.1.1.1.0.4
	OPENBSD_6_0_BASE:1.1.1.1
	mesa-11_2_2:1.1.1.1
	mesa:1.1.1;
locks; strict;
comment	@ * @;
expand	@o@;


1.1
date	2016.05.29.10.16.29;	author jsg;	state Exp;
branches
	1.1.1.1;
next	;
commitid	OwGfrJACrYJkCVJ4;

1.1.1.1
date	2016.05.29.10.16.29;	author jsg;	state Exp;
branches;
next	1.1.1.2;
commitid	OwGfrJACrYJkCVJ4;

1.1.1.2
date	2016.12.11.08.33.42;	author jsg;	state Exp;
branches;
next	1.1.1.3;
commitid	uuv5VTS15jglEDZU;

1.1.1.3
date	2017.08.14.09.38.27;	author jsg;	state Exp;
branches;
next	;
commitid	enNyoMGkcgwM3Ww6;


desc
@@


1.1
log
@Initial revision
@
text
@/*
 * Copyright Â© 2014 Intel Corporation
 *
 * Permission is hereby granted, free of charge, to any person obtaining a
 * copy of this software and associated documentation files (the "Software"),
 * to deal in the Software without restriction, including without limitation
 * the rights to use, copy, modify, merge, publish, distribute, sublicense,
 * and/or sell copies of the Software, and to permit persons to whom the
 * Software is furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice (including the next
 * paragraph) shall be included in all copies or substantial portions of the
 * Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
 * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
 * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
 * IN THE SOFTWARE.
 *
 * Authors:
 *    Connor Abbott (cwabbott0@@gmail.com)
 *
 */

#include "compiler/glsl/ir_uniform.h"
#include "nir.h"
#include "main/config.h"
#include <assert.h>

typedef struct {
   const struct gl_shader_program *shader_program;
   nir_shader   *shader;
} lower_atomic_state;

/*
 * replace atomic counter intrinsics that use a variable with intrinsics
 * that directly store the buffer index and byte offset
 */

static void
lower_instr(nir_intrinsic_instr *instr,
            lower_atomic_state *state)
{
   nir_intrinsic_op op;
   switch (instr->intrinsic) {
   case nir_intrinsic_atomic_counter_read_var:
      op = nir_intrinsic_atomic_counter_read;
      break;

   case nir_intrinsic_atomic_counter_inc_var:
      op = nir_intrinsic_atomic_counter_inc;
      break;

   case nir_intrinsic_atomic_counter_dec_var:
      op = nir_intrinsic_atomic_counter_dec;
      break;

   default:
      return;
   }

   if (instr->variables[0]->var->data.mode != nir_var_uniform &&
       instr->variables[0]->var->data.mode != nir_var_shader_storage)
      return; /* atomics passed as function arguments can't be lowered */

   void *mem_ctx = ralloc_parent(instr);
   unsigned uniform_loc = instr->variables[0]->var->data.location;

   nir_intrinsic_instr *new_instr = nir_intrinsic_instr_create(mem_ctx, op);
   nir_intrinsic_set_base(new_instr,
      state->shader_program->UniformStorage[uniform_loc].opaque[state->shader->stage].index);

   nir_load_const_instr *offset_const = nir_load_const_instr_create(mem_ctx, 1);
   offset_const->value.u[0] = instr->variables[0]->var->data.offset;

   nir_instr_insert_before(&instr->instr, &offset_const->instr);

   nir_ssa_def *offset_def = &offset_const->def;

   nir_deref *tail = &instr->variables[0]->deref;
   while (tail->child != NULL) {
      assert(tail->child->deref_type == nir_deref_type_array);
      nir_deref_array *deref_array = nir_deref_as_array(tail->child);
      tail = tail->child;

      unsigned child_array_elements = tail->child != NULL ?
         glsl_get_aoa_size(tail->type) : 1;

      offset_const->value.u[0] += deref_array->base_offset *
         child_array_elements * ATOMIC_COUNTER_SIZE;

      if (deref_array->deref_array_type == nir_deref_array_type_indirect) {
         nir_load_const_instr *atomic_counter_size =
               nir_load_const_instr_create(mem_ctx, 1);
         atomic_counter_size->value.u[0] = child_array_elements * ATOMIC_COUNTER_SIZE;
         nir_instr_insert_before(&instr->instr, &atomic_counter_size->instr);

         nir_alu_instr *mul = nir_alu_instr_create(mem_ctx, nir_op_imul);
         nir_ssa_dest_init(&mul->instr, &mul->dest.dest, 1, NULL);
         mul->dest.write_mask = 0x1;
         nir_src_copy(&mul->src[0].src, &deref_array->indirect, mul);
         mul->src[1].src.is_ssa = true;
         mul->src[1].src.ssa = &atomic_counter_size->def;
         nir_instr_insert_before(&instr->instr, &mul->instr);

         nir_alu_instr *add = nir_alu_instr_create(mem_ctx, nir_op_iadd);
         nir_ssa_dest_init(&add->instr, &add->dest.dest, 1, NULL);
         add->dest.write_mask = 0x1;
         add->src[0].src.is_ssa = true;
         add->src[0].src.ssa = &mul->dest.dest.ssa;
         add->src[1].src.is_ssa = true;
         add->src[1].src.ssa = offset_def;
         nir_instr_insert_before(&instr->instr, &add->instr);

         offset_def = &add->dest.dest.ssa;
      }
   }

   new_instr->src[0].is_ssa = true;
   new_instr->src[0].ssa = offset_def;

   if (instr->dest.is_ssa) {
      nir_ssa_dest_init(&new_instr->instr, &new_instr->dest,
                        instr->dest.ssa.num_components, NULL);
      nir_ssa_def_rewrite_uses(&instr->dest.ssa,
                               nir_src_for_ssa(&new_instr->dest.ssa));
   } else {
      nir_dest_copy(&new_instr->dest, &instr->dest, mem_ctx);
   }

   nir_instr_insert_before(&instr->instr, &new_instr->instr);
   nir_instr_remove(&instr->instr);
}

static bool
lower_block(nir_block *block, void *state)
{
   nir_foreach_instr_safe(block, instr) {
      if (instr->type == nir_instr_type_intrinsic)
         lower_instr(nir_instr_as_intrinsic(instr),
                     (lower_atomic_state *) state);
   }

   return true;
}

void
nir_lower_atomics(nir_shader *shader,
                  const struct gl_shader_program *shader_program)
{
   lower_atomic_state state = {
      .shader = shader,
      .shader_program = shader_program,
   };

   nir_foreach_function(shader, function) {
      if (function->impl) {
         nir_foreach_block(function->impl, lower_block, (void *) &state);
         nir_metadata_preserve(function->impl, nir_metadata_block_index |
                                               nir_metadata_dominance);
      }
   }
}
@


1.1.1.1
log
@Import Mesa 11.2.2
@
text
@@


1.1.1.2
log
@Import Mesa 13.0.2
@
text
@d33 5
d45 1
a45 2
            const struct gl_shader_program *shader_program,
            nir_shader *shader)
a60 32
   case nir_intrinsic_atomic_counter_add_var:
      op = nir_intrinsic_atomic_counter_add;
      break;

   case nir_intrinsic_atomic_counter_min_var:
      op = nir_intrinsic_atomic_counter_min;
      break;

   case nir_intrinsic_atomic_counter_max_var:
      op = nir_intrinsic_atomic_counter_max;
      break;

   case nir_intrinsic_atomic_counter_and_var:
      op = nir_intrinsic_atomic_counter_and;
      break;

   case nir_intrinsic_atomic_counter_or_var:
      op = nir_intrinsic_atomic_counter_or;
      break;

   case nir_intrinsic_atomic_counter_xor_var:
      op = nir_intrinsic_atomic_counter_xor;
      break;

   case nir_intrinsic_atomic_counter_exchange_var:
      op = nir_intrinsic_atomic_counter_exchange;
      break;

   case nir_intrinsic_atomic_counter_comp_swap_var:
      op = nir_intrinsic_atomic_counter_comp_swap;
      break;

d66 1
a66 2
       instr->variables[0]->var->data.mode != nir_var_shader_storage &&
       instr->variables[0]->var->data.mode != nir_var_shared)
d74 1
a74 1
      shader_program->UniformStorage[uniform_loc].opaque[shader->stage].index);
d76 2
a77 3
   nir_load_const_instr *offset_const =
      nir_load_const_instr_create(mem_ctx, 1, 32);
   offset_const->value.u32[0] = instr->variables[0]->var->data.offset;
d85 1
d92 1
a92 1
      offset_const->value.u32[0] += deref_array->base_offset *
d97 2
a98 2
            nir_load_const_instr_create(mem_ctx, 1, 32);
         atomic_counter_size->value.u32[0] = child_array_elements * ATOMIC_COUNTER_SIZE;
d102 1
a102 1
         nir_ssa_dest_init(&mul->instr, &mul->dest.dest, 1, 32, NULL);
d110 1
a110 1
         nir_ssa_dest_init(&add->instr, &add->dest.dest, 1, 32, NULL);
a124 6
   /* Copy the other sources, if any, from the original instruction to the new
    * instruction.
    */
   for (unsigned i = 0; i < nir_intrinsic_infos[instr->intrinsic].num_srcs; i++)
      new_instr->src[i + 1] = instr->src[i];

d127 1
a127 1
                        instr->dest.ssa.num_components, 32, NULL);
d138 12
d154 6
a159 1
   nir_foreach_function(function, shader) {
d161 1
a161 8
         nir_foreach_block(block, function->impl) {
            nir_foreach_instr_safe(instr, block) {
               if (instr->type == nir_instr_type_intrinsic)
                  lower_instr(nir_instr_as_intrinsic(instr),
                              shader_program, shader);
            }
         }

@


1.1.1.3
log
@Import Mesa 17.1.6
@
text
@d38 1
a38 1
static bool
d90 1
a90 1
      return false;
d96 1
a96 1
      return false; /* atomics passed as function arguments can't be lowered */
d103 1
a103 1
      shader_program->data->UniformStorage[uniform_loc].opaque[shader->stage].index);
d158 1
a158 1
      nir_src_copy(&new_instr->src[i + 1], &instr->src[i], new_instr);
a170 2

   return true;
d173 1
a173 1
bool
a176 2
   bool progress = false;

d182 2
a183 2
                  progress |= lower_instr(nir_instr_as_intrinsic(instr),
                                          shader_program, shader);
a190 2

   return progress;
@


