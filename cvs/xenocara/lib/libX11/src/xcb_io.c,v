head	1.11;
access;
symbols
	OPENBSD_6_1_BASE:1.11
	OPENBSD_6_0:1.10.0.6
	OPENBSD_6_0_BASE:1.10
	OPENBSD_5_9:1.10.0.4
	OPENBSD_5_9_BASE:1.10
	OPENBSD_5_8:1.10.0.2
	OPENBSD_5_8_BASE:1.10
	OPENBSD_5_7:1.9.0.8
	OPENBSD_5_7_BASE:1.9
	OPENBSD_5_6:1.9.0.6
	OPENBSD_5_6_BASE:1.9
	OPENBSD_5_5:1.9.0.4
	OPENBSD_5_5_BASE:1.9
	OPENBSD_5_4:1.9.0.2
	OPENBSD_5_4_BASE:1.9
	OPENBSD_5_3:1.8.0.4
	OPENBSD_5_3_BASE:1.8
	OPENBSD_5_2:1.8.0.2
	OPENBSD_5_2_BASE:1.8
	OPENBSD_5_1_BASE:1.7
	OPENBSD_5_1:1.7.0.2
	OPENBSD_5_0:1.6.0.2
	OPENBSD_5_0_BASE:1.6
	OPENBSD_4_9:1.5.0.2
	OPENBSD_4_9_BASE:1.5
	OPENBSD_4_8:1.4.0.4
	OPENBSD_4_8_BASE:1.4
	OPENBSD_4_7:1.3.0.4
	OPENBSD_4_7_BASE:1.3
	OPENBSD_4_6:1.3.0.2
	OPENBSD_4_6_BASE:1.3
	OPENBSD_4_5:1.2.0.4
	OPENBSD_4_5_BASE:1.2
	OPENBSD_4_4:1.2.0.2
	OPENBSD_4_4_BASE:1.2
	OPENBSD_4_3_BASE:1.1.1.3
	OPENBSD_4_3:1.1.1.3.0.2
	v1_1_3:1.1.1.3
	OPENBSD_4_2:1.1.1.2.0.2
	OPENBSD_4_2_BASE:1.1.1.2
	v1_1_1:1.1.1.2
	v1_0_99_2:1.1.1.1
	xorg:1.1.1;
locks; strict;
comment	@ * @;


1.11
date	2016.11.03.10.21.31;	author matthieu;	state Exp;
branches;
next	1.10;
commitid	EvOPnI31yB1tDGgg;

1.10
date	2015.04.06.20.57.59;	author matthieu;	state Exp;
branches;
next	1.9;
commitid	L5f7tv2EiGjtzoSu;

1.9
date	2013.05.23.22.42.07;	author matthieu;	state Exp;
branches;
next	1.8;

1.8
date	2012.03.27.19.19.38;	author matthieu;	state Exp;
branches;
next	1.7;

1.7
date	2011.08.27.15.34.15;	author matthieu;	state Exp;
branches;
next	1.6;

1.6
date	2011.05.30.19.19.38;	author matthieu;	state Exp;
branches;
next	1.5;

1.5
date	2010.09.04.10.33.18;	author matthieu;	state Exp;
branches;
next	1.4;

1.4
date	2010.05.18.19.37.35;	author matthieu;	state Exp;
branches;
next	1.3;

1.3
date	2009.05.03.12.59.11;	author matthieu;	state Exp;
branches;
next	1.2;

1.2
date	2008.06.11.20.55.44;	author matthieu;	state Exp;
branches;
next	1.1;

1.1
date	2006.11.25.16.37.30;	author matthieu;	state Exp;
branches
	1.1.1.1;
next	;

1.1.1.1
date	2006.11.25.16.37.30;	author matthieu;	state Exp;
branches;
next	1.1.1.2;

1.1.1.2
date	2006.12.16.16.41.14;	author matthieu;	state Exp;
branches;
next	1.1.1.3;

1.1.1.3
date	2007.09.30.10.13.03;	author matthieu;	state Exp;
branches;
next	;


desc
@@


1.11
log
@Update to libX11 1.6.4
@
text
@/* Copyright (C) 2003-2006 Jamey Sharp, Josh Triplett
 * This file is licensed under the MIT license. See the file COPYING. */

#ifdef HAVE_CONFIG_H
#include <config.h>
#endif

#include "Xlibint.h"
#include "locking.h"
#include "Xprivate.h"
#include "Xxcbint.h"
#include <xcb/xcbext.h>

#include <assert.h>
#ifdef HAVE_INTTYPES_H
#include <inttypes.h>
#endif
#include <stdio.h>
#include <stdint.h>
#include <stdlib.h>
#include <string.h>
#include <limits.h>
#ifdef HAVE_SYS_SELECT_H
#include <sys/select.h>
#endif

#define xcb_fail_assert(_message, _var) { \
	unsigned int _var = 1; \
	fprintf(stderr, "[xcb] Aborting, sorry about that.\n"); \
	assert(!_var); \
}

#define throw_thread_fail_assert(_message, _var) { \
	fprintf(stderr, "[xcb] " _message "\n"); \
	fprintf(stderr, "[xcb] Most likely this is a multi-threaded client " \
	                "and XInitThreads has not been called\n"); \
	xcb_fail_assert(_message, _var); \
}

/* XXX: It would probably be most useful if we stored the last-processed
 *      request, so we could find the offender from the message. */
#define throw_extlib_fail_assert(_message, _var) { \
	fprintf(stderr, "[xcb] " _message "\n"); \
	fprintf(stderr, "[xcb] This is most likely caused by a broken X " \
	                "extension library\n"); \
	xcb_fail_assert(_message, _var); \
}

static void return_socket(void *closure)
{
	Display *dpy = closure;
	InternalLockDisplay(dpy, /* don't skip user locks */ 0);
	_XSend(dpy, NULL, 0);
	dpy->bufmax = dpy->buffer;
	UnlockDisplay(dpy);
}

static void require_socket(Display *dpy)
{
	if(dpy->bufmax == dpy->buffer)
	{
		uint64_t sent;
		int flags = 0;
		/* if we don't own the event queue, we have to ask XCB
		 * to set our errors aside for us. */
		if(dpy->xcb->event_owner != XlibOwnsEventQueue)
			flags = XCB_REQUEST_CHECKED;
		if(!xcb_take_socket(dpy->xcb->connection, return_socket, dpy,
		                    flags, &sent))
			_XIOError(dpy);
		dpy->xcb->last_flushed = sent;
		X_DPY_SET_REQUEST(dpy, sent);
		dpy->bufmax = dpy->xcb->real_bufmax;
	}
}

/* Call internal connection callbacks for any fds that are currently
 * ready to read. This function will not block unless one of the
 * callbacks blocks.
 *
 * This code borrowed from _XWaitForReadable. Inverse call tree:
 * _XRead
 *  _XWaitForWritable
 *   _XFlush
 *   _XSend
 *  _XEventsQueued
 *  _XReadEvents
 *  _XRead[0-9]+
 *   _XAllocIDs
 *  _XReply
 *  _XEatData
 * _XReadPad
 */
static void check_internal_connections(Display *dpy)
{
	struct _XConnectionInfo *ilist;
	fd_set r_mask;
	struct timeval tv;
	int result;
	int highest_fd = -1;

	if(dpy->flags & XlibDisplayProcConni || !dpy->im_fd_info)
		return;

	FD_ZERO(&r_mask);
	for(ilist = dpy->im_fd_info; ilist; ilist = ilist->next)
	{
		assert(ilist->fd >= 0);
		FD_SET(ilist->fd, &r_mask);
		if(ilist->fd > highest_fd)
			highest_fd = ilist->fd;
	}
	assert(highest_fd >= 0);

	tv.tv_sec = 0;
	tv.tv_usec = 0;
	result = select(highest_fd + 1, &r_mask, NULL, NULL, &tv);

	if(result == -1)
	{
		if(errno == EINTR)
			return;
		_XIOError(dpy);
	}

	for(ilist = dpy->im_fd_info; result && ilist; ilist = ilist->next)
		if(FD_ISSET(ilist->fd, &r_mask))
		{
			_XProcessInternalConnection(dpy, ilist);
			--result;
		}
}

static PendingRequest *append_pending_request(Display *dpy, uint64_t sequence)
{
	PendingRequest *node = malloc(sizeof(PendingRequest));
	assert(node);
	node->next = NULL;
	node->sequence = sequence;
	node->reply_waiter = 0;
	if(dpy->xcb->pending_requests_tail)
	{
		if (XLIB_SEQUENCE_COMPARE(dpy->xcb->pending_requests_tail->sequence,
		                          >=, node->sequence))
			throw_thread_fail_assert("Unknown sequence number "
			                         "while appending request",
			                         xcb_xlib_unknown_seq_number);
		if (dpy->xcb->pending_requests_tail->next != NULL)
			throw_thread_fail_assert("Unknown request in queue "
			                         "while appending request",
			                         xcb_xlib_unknown_req_pending);
		dpy->xcb->pending_requests_tail->next = node;
	}
	else
		dpy->xcb->pending_requests = node;
	dpy->xcb->pending_requests_tail = node;
	return node;
}

static void dequeue_pending_request(Display *dpy, PendingRequest *req)
{
	if (req != dpy->xcb->pending_requests)
		throw_thread_fail_assert("Unknown request in queue while "
		                         "dequeuing",
		                         xcb_xlib_unknown_req_in_deq);

	dpy->xcb->pending_requests = req->next;
	if(!dpy->xcb->pending_requests)
	{
		if (req != dpy->xcb->pending_requests_tail)
			throw_thread_fail_assert("Unknown request in queue "
			                         "while dequeuing",
			                         xcb_xlib_unknown_req_in_deq);
		dpy->xcb->pending_requests_tail = NULL;
	}
	else if (XLIB_SEQUENCE_COMPARE(req->sequence, >=,
	                               dpy->xcb->pending_requests->sequence))
		throw_thread_fail_assert("Unknown sequence number while "
		                         "dequeuing request",
		                         xcb_xlib_threads_sequence_lost);

	free(req);
}

static int handle_error(Display *dpy, xError *err, Bool in_XReply)
{
	_XExtension *ext;
	int ret_code;
	/* Oddly, Xlib only allows extensions to suppress errors when
	 * those errors were seen by _XReply. */
	if(in_XReply)
		/*
		 * we better see if there is an extension who may
		 * want to suppress the error.
		 */
		for(ext = dpy->ext_procs; ext; ext = ext->next)
			if(ext->error && (*ext->error)(dpy, err, &ext->codes, &ret_code))
				return ret_code;
	_XError(dpy, err);
	return 0;
}

/* Widen a 32-bit sequence number into a 64bit (uint64_t) sequence number.
 * Treating the comparison as a 1 and shifting it avoids a conditional branch.
 */
static void widen(uint64_t *wide, unsigned int narrow)
{
	uint64_t new = (*wide & ~((uint64_t)0xFFFFFFFFUL)) | narrow;
	*wide = new + (((uint64_t)(new < *wide)) << 32);
}

/* Thread-safety rules:
 *
 * At most one thread can be reading from XCB's event queue at a time.
 * If you are not the current event-reading thread and you need to find
 * out if an event is available, you must wait.
 *
 * The same rule applies for reading replies.
 *
 * A single thread cannot be both the the event-reading and the
 * reply-reading thread at the same time.
 *
 * We always look at both the current event and the first pending reply
 * to decide which to process next.
 *
 * We always process all responses in sequence-number order, which may
 * mean waiting for another thread (either the event_waiter or the
 * reply_waiter) to handle an earlier response before we can process or
 * return a later one. If so, we wait on the corresponding condition
 * variable for that thread to process the response and wake us up.
 */

static xcb_generic_reply_t *poll_for_event(Display *dpy)
{
	/* Make sure the Display's sequence numbers are valid */
	require_socket(dpy);

	/* Precondition: This thread can safely get events from XCB. */
	assert(dpy->xcb->event_owner == XlibOwnsEventQueue && !dpy->xcb->event_waiter);

	if(!dpy->xcb->next_event)
		dpy->xcb->next_event = xcb_poll_for_event(dpy->xcb->connection);

	if(dpy->xcb->next_event)
	{
		PendingRequest *req = dpy->xcb->pending_requests;
		xcb_generic_event_t *event = dpy->xcb->next_event;
		uint64_t event_sequence = X_DPY_GET_LAST_REQUEST_READ(dpy);
		widen(&event_sequence, event->full_sequence);
		if(!req || XLIB_SEQUENCE_COMPARE(event_sequence, <, req->sequence)
		        || (event->response_type != X_Error && event_sequence == req->sequence))
		{
			uint64_t request = X_DPY_GET_REQUEST(dpy);
			if (XLIB_SEQUENCE_COMPARE(event_sequence, >, request))
			{
				throw_thread_fail_assert("Unknown sequence "
				                         "number while "
							 "processing queue",
				                xcb_xlib_threads_sequence_lost);
			}
			X_DPY_SET_LAST_REQUEST_READ(dpy, event_sequence);
			dpy->xcb->next_event = NULL;
			return (xcb_generic_reply_t *) event;
		}
	}
	return NULL;
}

static xcb_generic_reply_t *poll_for_response(Display *dpy)
{
	void *response;
	xcb_generic_error_t *error;
	PendingRequest *req;
	while(!(response = poll_for_event(dpy)) &&
	      (req = dpy->xcb->pending_requests) &&
	      !req->reply_waiter &&
	      xcb_poll_for_reply64(dpy->xcb->connection, req->sequence, &response, &error))
	{
		uint64_t request = X_DPY_GET_REQUEST(dpy);
		if(XLIB_SEQUENCE_COMPARE(req->sequence, >, request))
		{
			throw_thread_fail_assert("Unknown sequence number "
			                         "while awaiting reply",
			                        xcb_xlib_threads_sequence_lost);
		}
		X_DPY_SET_LAST_REQUEST_READ(dpy, req->sequence);
		if(response)
			break;
		dequeue_pending_request(dpy, req);
		if(error)
			return (xcb_generic_reply_t *) error;
	}
	return response;
}

static void handle_response(Display *dpy, xcb_generic_reply_t *response, Bool in_XReply)
{
	_XAsyncHandler *async, *next;
	switch(response->response_type)
	{
	case X_Reply:
		for(async = dpy->async_handlers; async; async = next)
		{
			next = async->next;
			if(async->handler(dpy, (xReply *) response, (char *) response, sizeof(xReply) + (response->length << 2), async->data))
				break;
		}
		break;

	case X_Error:
		handle_error(dpy, (xError *) response, in_XReply);
		break;

	default: /* event */
		/* GenericEvents may be > 32 bytes. In this case, the
		 * event struct is trailed by the additional bytes. the
		 * xcb_generic_event_t struct uses 4 bytes for internal
		 * numbering, so we need to shift the trailing data to
		 * be after the first 32 bytes. */
		if(response->response_type == GenericEvent && ((xcb_ge_event_t *) response)->length)
		{
			xcb_ge_event_t *event = (xcb_ge_event_t *) response;
			memmove(&event->full_sequence, &event[1], event->length * 4);
		}
		_XEnq(dpy, (xEvent *) response);
		break;
	}
	free(response);
}

int _XEventsQueued(Display *dpy, int mode)
{
	xcb_generic_reply_t *response;
	if(dpy->flags & XlibDisplayIOError)
		return 0;
	if(dpy->xcb->event_owner != XlibOwnsEventQueue)
		return 0;

	if(mode == QueuedAfterFlush)
		_XSend(dpy, NULL, 0);
	else
		check_internal_connections(dpy);

	/* If another thread is blocked waiting for events, then we must
	 * let that thread pick up the next event. Since it blocked, we
	 * can reasonably claim there are no new events right now. */
	if(!dpy->xcb->event_waiter)
	{
		while((response = poll_for_response(dpy)))
			handle_response(dpy, response, False);
		if(xcb_connection_has_error(dpy->xcb->connection))
			_XIOError(dpy);
	}
	return dpy->qlen;
}

/* _XReadEvents - Flush the output queue,
 * then read as many events as possible (but at least 1) and enqueue them
 */
void _XReadEvents(Display *dpy)
{
	xcb_generic_reply_t *response;
	unsigned long serial;

	if(dpy->flags & XlibDisplayIOError)
		return;
	_XSend(dpy, NULL, 0);
	if(dpy->xcb->event_owner != XlibOwnsEventQueue)
		return;
	check_internal_connections(dpy);

	serial = dpy->next_event_serial_num;
	while(serial == dpy->next_event_serial_num || dpy->qlen == 0)
	{
		if(dpy->xcb->event_waiter)
		{
			ConditionWait(dpy, dpy->xcb->event_notify);
			/* Maybe the other thread got us an event. */
			continue;
		}

		if(!dpy->xcb->next_event)
		{
			xcb_generic_event_t *event;
			dpy->xcb->event_waiter = 1;
			UnlockDisplay(dpy);
			event = xcb_wait_for_event(dpy->xcb->connection);
			/* It appears that classic Xlib respected user
			 * locks when waking up after waiting for
			 * events. However, if this thread did not have
			 * any user locks, and another thread takes a
			 * user lock and tries to read events, then we'd
			 * deadlock. So we'll choose to let the thread
			 * that got in first consume events, despite the
			 * later thread's user locks. */
			InternalLockDisplay(dpy, /* ignore user locks */ 1);
			dpy->xcb->event_waiter = 0;
			ConditionBroadcast(dpy, dpy->xcb->event_notify);
			if(!event)
				_XIOError(dpy);
			dpy->xcb->next_event = event;
		}

		/* We've established most of the conditions for
		 * poll_for_response to return non-NULL. The exceptions
		 * are connection shutdown, and finding that another
		 * thread is waiting for the next reply we'd like to
		 * process. */

		response = poll_for_response(dpy);
		if(response)
			handle_response(dpy, response, False);
		else if(dpy->xcb->pending_requests->reply_waiter)
		{ /* need braces around ConditionWait */
			ConditionWait(dpy, dpy->xcb->reply_notify);
		}
		else
			_XIOError(dpy);
	}

	/* The preceding loop established that there is no
	 * event_waiter--unless we just called ConditionWait because of
	 * a reply_waiter, in which case another thread may have become
	 * the event_waiter while we slept unlocked. */
	if(!dpy->xcb->event_waiter)
		while((response = poll_for_response(dpy)))
			handle_response(dpy, response, False);
	if(xcb_connection_has_error(dpy->xcb->connection))
		_XIOError(dpy);
}

/*
 * _XSend - Flush the buffer and send the client data. 32 bit word aligned
 * transmission is used, if size is not 0 mod 4, extra bytes are transmitted.
 *
 * Note that the connection must not be read from once the data currently
 * in the buffer has been written.
 */
void _XSend(Display *dpy, const char *data, long size)
{
	static const xReq dummy_request;
	static char const pad[3];
	struct iovec vec[3];
	uint64_t requests;
	uint64_t dpy_request;
	_XExtension *ext;
	xcb_connection_t *c = dpy->xcb->connection;
	if(dpy->flags & XlibDisplayIOError)
		return;

	if(dpy->bufptr == dpy->buffer && !size)
		return;

	/* append_pending_request does not alter the dpy request number
	 * therefore we can get it outside of the loop and the if
	 */
	dpy_request = X_DPY_GET_REQUEST(dpy);
	/* iff we asked XCB to set aside errors, we must pick those up
	 * eventually. iff there are async handlers, we may have just
	 * issued requests that will generate replies. in either case,
	 * we need to remember to check later. */
	if(dpy->xcb->event_owner != XlibOwnsEventQueue || dpy->async_handlers)
	{
		uint64_t sequence;
		for(sequence = dpy->xcb->last_flushed + 1; sequence <= dpy_request; ++sequence)
			append_pending_request(dpy, sequence);
	}
	requests = dpy_request - dpy->xcb->last_flushed;
	dpy->xcb->last_flushed = dpy_request;

	vec[0].iov_base = dpy->buffer;
	vec[0].iov_len = dpy->bufptr - dpy->buffer;
	vec[1].iov_base = (char *)data;
	vec[1].iov_len = size;
	vec[2].iov_base = (char *)pad;
	vec[2].iov_len = -size & 3;

	for(ext = dpy->flushes; ext; ext = ext->next_flush)
	{
		int i;
		for(i = 0; i < 3; ++i)
			if(vec[i].iov_len)
				ext->before_flush(dpy, &ext->codes, vec[i].iov_base, vec[i].iov_len);
	}

	if(xcb_writev(c, vec, 3, requests) < 0)
		_XIOError(dpy);
	dpy->bufptr = dpy->buffer;
	dpy->last_req = (char *) &dummy_request;

	check_internal_connections(dpy);

	_XSetSeqSyncFunction(dpy);
}

/*
 * _XFlush - Flush the X request buffer.  If the buffer is empty, no
 * action is taken.
 */
void _XFlush(Display *dpy)
{
	require_socket(dpy);
	_XSend(dpy, NULL, 0);

	_XEventsQueued(dpy, QueuedAfterReading);
}

static const XID inval_id = ~0UL;

void _XIDHandler(Display *dpy)
{
	if (dpy->xcb->next_xid == inval_id)
		_XAllocIDs(dpy, &dpy->xcb->next_xid, 1);
}

/* _XAllocID - resource ID allocation routine. */
XID _XAllocID(Display *dpy)
{
	XID ret = dpy->xcb->next_xid;
	assert (ret != inval_id);
	dpy->xcb->next_xid = inval_id;
	_XSetPrivSyncFunction(dpy);
	return ret;
}

/* _XAllocIDs - multiple resource ID allocation routine. */
void _XAllocIDs(Display *dpy, XID *ids, int count)
{
	int i;
#ifdef XTHREADS
	if (dpy->lock)
		(*dpy->lock->user_lock_display)(dpy);
	UnlockDisplay(dpy);
#endif
	for (i = 0; i < count; i++)
		ids[i] = xcb_generate_id(dpy->xcb->connection);
#ifdef XTHREADS
	InternalLockDisplay(dpy, /* don't skip user locks */ 0);
	if (dpy->lock)
		(*dpy->lock->user_unlock_display)(dpy);
#endif
}

static void _XFreeReplyData(Display *dpy, Bool force)
{
	if(!force && dpy->xcb->reply_consumed < dpy->xcb->reply_length)
		return;
	free(dpy->xcb->reply_data);
	dpy->xcb->reply_data = NULL;
}

/*
 * _XReply - Wait for a reply packet and copy its contents into the
 * specified rep.
 * extra: number of 32-bit words expected after the reply
 * discard: should I discard data following "extra" words?
 */
Status _XReply(Display *dpy, xReply *rep, int extra, Bool discard)
{
	xcb_generic_error_t *error;
	xcb_connection_t *c = dpy->xcb->connection;
	char *reply;
	PendingRequest *current;
	uint64_t dpy_request;

	if (dpy->xcb->reply_data)
		throw_extlib_fail_assert("Extra reply data still left in queue",
		                         xcb_xlib_extra_reply_data_left);

	if(dpy->flags & XlibDisplayIOError)
		return 0;

	_XSend(dpy, NULL, 0);
	dpy_request = X_DPY_GET_REQUEST(dpy);
	if(dpy->xcb->pending_requests_tail
	   && dpy->xcb->pending_requests_tail->sequence == dpy_request)
		current = dpy->xcb->pending_requests_tail;
	else
		current = append_pending_request(dpy, dpy_request);
	/* Don't let any other thread get this reply. */
	current->reply_waiter = 1;

	while(1)
	{
		PendingRequest *req = dpy->xcb->pending_requests;
		xcb_generic_reply_t *response;

		if(req != current && req->reply_waiter)
		{
			ConditionWait(dpy, dpy->xcb->reply_notify);
			/* Another thread got this reply. */
			continue;
		}
		req->reply_waiter = 1;
		UnlockDisplay(dpy);
		response = xcb_wait_for_reply64(c, req->sequence, &error);
		/* Any user locks on another thread must have been taken
		 * while we slept in xcb_wait_for_reply64. Classic Xlib
		 * ignored those user locks in this case, so we do too. */
		InternalLockDisplay(dpy, /* ignore user locks */ 1);

		/* We have the response we're looking for. Now, before
		 * letting anyone else process this sequence number, we
		 * need to process any events that should have come
		 * earlier. */

		if(dpy->xcb->event_owner == XlibOwnsEventQueue)
		{
			xcb_generic_reply_t *event;
			/* If some thread is already waiting for events,
			 * it will get the first one. That thread must
			 * process that event before we can continue. */
			/* FIXME: That event might be after this reply,
			 * and might never even come--or there might be
			 * multiple threads trying to get events. */
			while(dpy->xcb->event_waiter)
			{ /* need braces around ConditionWait */
				ConditionWait(dpy, dpy->xcb->event_notify);
			}
			while((event = poll_for_event(dpy)))
				handle_response(dpy, event, True);
		}

		req->reply_waiter = 0;
		ConditionBroadcast(dpy, dpy->xcb->reply_notify);
		dpy_request = X_DPY_GET_REQUEST(dpy);
		if(XLIB_SEQUENCE_COMPARE(req->sequence, >, dpy_request)) {
			throw_thread_fail_assert("Unknown sequence number "
			                         "while processing reply",
			                        xcb_xlib_threads_sequence_lost);
		}
		X_DPY_SET_LAST_REQUEST_READ(dpy, req->sequence);
		if(!response)
			dequeue_pending_request(dpy, req);

		if(req == current)
		{
			reply = (char *) response;
			break;
		}

		if(error)
			handle_response(dpy, (xcb_generic_reply_t *) error, True);
		else if(response)
			handle_response(dpy, response, True);
	}
	check_internal_connections(dpy);

	if(dpy->xcb->next_event && dpy->xcb->next_event->response_type == X_Error)
	{
		xcb_generic_event_t *event = dpy->xcb->next_event;
		uint64_t last_request_read = X_DPY_GET_LAST_REQUEST_READ(dpy);
		uint64_t event_sequence = last_request_read;
		widen(&event_sequence, event->full_sequence);
		if(event_sequence == last_request_read)
		{
			error = (xcb_generic_error_t *) event;
			dpy->xcb->next_event = NULL;
		}
	}

	if(error)
	{
		int ret_code;

		/* Xlib is evil and assumes that even errors will be
		 * copied into rep. */
		memcpy(rep, error, 32);

		/* do not die on "no such font", "can't allocate",
		   "can't grab" failures */
		switch(error->error_code)
		{
			case BadName:
				switch(error->major_code)
				{
					case X_LookupColor:
					case X_AllocNamedColor:
						free(error);
						return 0;
				}
				break;
			case BadFont:
				if(error->major_code == X_QueryFont) {
					free(error);
					return 0;
				}
				break;
			case BadAlloc:
			case BadAccess:
				free(error);
				return 0;
		}

		ret_code = handle_error(dpy, (xError *) error, True);
		free(error);
		return ret_code;
	}

	/* it's not an error, but we don't have a reply, so it's an I/O
	 * error. */
	if(!reply)
	{
		_XIOError(dpy);
		return 0;
	}

	/* there's no error and we have a reply. */
	dpy->xcb->reply_data = reply;
	dpy->xcb->reply_consumed = sizeof(xReply) + (extra * 4);
	dpy->xcb->reply_length = sizeof(xReply);
	if(dpy->xcb->reply_data[0] == 1)
		dpy->xcb->reply_length += (((xcb_generic_reply_t *) dpy->xcb->reply_data)->length * 4);

	/* error: Xlib asks too much. give them what we can anyway. */
	if(dpy->xcb->reply_length < dpy->xcb->reply_consumed)
		dpy->xcb->reply_consumed = dpy->xcb->reply_length;

	memcpy(rep, dpy->xcb->reply_data, dpy->xcb->reply_consumed);
	_XFreeReplyData(dpy, discard);
	return 1;
}

int _XRead(Display *dpy, char *data, long size)
{
	assert(size >= 0);
	if(size == 0)
		return 0;
	if(dpy->xcb->reply_data == NULL ||
	   dpy->xcb->reply_consumed + size > dpy->xcb->reply_length)
		throw_extlib_fail_assert("Too much data requested from _XRead",
		                         xcb_xlib_too_much_data_requested);
	memcpy(data, dpy->xcb->reply_data + dpy->xcb->reply_consumed, size);
	dpy->xcb->reply_consumed += size;
	_XFreeReplyData(dpy, False);
	return 0;
}

/*
 * _XReadPad - Read bytes from the socket taking into account incomplete
 * reads.  If the number of bytes is not 0 mod 4, read additional pad
 * bytes.
 */
void _XReadPad(Display *dpy, char *data, long size)
{
	_XRead(dpy, data, size);
	dpy->xcb->reply_consumed += -size & 3;
	_XFreeReplyData(dpy, False);
}

/* Read and discard "n" 8-bit bytes of data */
void _XEatData(Display *dpy, unsigned long n)
{
	dpy->xcb->reply_consumed += n;
	_XFreeReplyData(dpy, False);
}

/*
 * Read and discard "n" 32-bit words of data
 * Matches the units of the length field in X protocol replies, and provides
 * a single implementation of overflow checking to avoid having to replicate
 * those checks in every caller.
 */
void _XEatDataWords(Display *dpy, unsigned long n)
{
	if (n < ((INT_MAX - dpy->xcb->reply_consumed) >> 2))
		dpy->xcb->reply_consumed += (n << 2);
	else
		/* Overflow would happen, so just eat the rest of the reply */
		dpy->xcb->reply_consumed = dpy->xcb->reply_length;
	_XFreeReplyData(dpy, False);
}

unsigned long
_XNextRequest(Display *dpy)
{
    /* This will update dpy->request. The assumption is that the next thing
     * that the application will do is make a request so there's little
     * overhead.
     */
    require_socket(dpy);
    return NextRequest(dpy);
}
@


1.10
log
@update to libX11 1.6.3
@
text
@d71 2
a72 16
		/* Xlib uses unsigned long for sequence numbers.  XCB
		 * uses 64-bit internally, but currently exposes an
		 * unsigned int API.  If these differ, Xlib cannot track
		 * the full 64-bit sequence number if 32-bit wrap
		 * happens while Xlib does not own the socket.  A
		 * complete fix would be to make XCB's public API use
		 * 64-bit sequence numbers. */
		if (sizeof(unsigned long) > sizeof(unsigned int) &&
		    dpy->xcb->event_owner == XlibOwnsEventQueue &&
		    (sent - dpy->last_request_read >= (UINT64_C(1) << 32))) {
			throw_thread_fail_assert("Sequence number wrapped "
			                         "beyond 32 bits while Xlib "
						 "did not own the socket",
			                         xcb_xlib_seq_number_wrapped);
		}
		dpy->xcb->last_flushed = dpy->request = sent;
d134 1
a134 1
static PendingRequest *append_pending_request(Display *dpy, unsigned long sequence)
d203 4
a206 5
/* Widen a 32-bit sequence number into a native-word-size (unsigned long)
 * sequence number.  Treating the comparison as a 1 and shifting it avoids a
 * conditional branch, and shifting by 16 twice avoids a compiler warning when
 * sizeof(unsigned long) == 4. */
static void widen(unsigned long *wide, unsigned int narrow)
d208 2
a209 2
	unsigned long new = (*wide & ~0xFFFFFFFFUL) | narrow;
	*wide = new + ((unsigned long) (new < *wide) << 16 << 16);
d248 1
a248 1
		unsigned long event_sequence = dpy->last_request_read;
d253 2
a254 2
			if (XLIB_SEQUENCE_COMPARE(event_sequence, >,
			                          dpy->request))
d261 1
a261 1
			dpy->last_request_read = event_sequence;
d277 1
a277 1
	      xcb_poll_for_reply(dpy->xcb->connection, req->sequence, &response, &error))
d279 2
a280 1
		if(XLIB_SEQUENCE_COMPARE(req->sequence, >, dpy->request))
d286 1
a286 1
		dpy->last_request_read = req->sequence;
d445 1
d454 4
d465 1
a465 1
		for(sequence = dpy->xcb->last_flushed + 1; sequence <= dpy->request; ++sequence)
d468 2
a469 2
	requests = dpy->request - dpy->xcb->last_flushed;
	dpy->xcb->last_flushed = dpy->request;
d564 1
d574 3
a576 1
	if(dpy->xcb->pending_requests_tail && dpy->xcb->pending_requests_tail->sequence == dpy->request)
d579 1
a579 1
		current = append_pending_request(dpy, dpy->request);
d596 1
a596 1
		response = xcb_wait_for_reply(c, req->sequence, &error);
d598 1
a598 1
		 * while we slept in xcb_wait_for_reply. Classic Xlib
d626 2
a627 1
		if(XLIB_SEQUENCE_COMPARE(req->sequence, >, dpy->request)) {
d632 1
a632 1
		dpy->last_request_read = req->sequence;
d652 2
a653 1
		unsigned long event_sequence = dpy->last_request_read;
d655 1
a655 1
		if(event_sequence == dpy->last_request_read)
@


1.9
log
@Merge upstream fixes for several X libs vulnerabilities
discovered by Ilja van Sprundel.

CVE-2013-1981 X.org libX11 1.5.99.901 (1.6 RC1) integer overflows
CVE-2013-1982 X.org libXext 1.3.1 integer overflows
CVE-2013-1983 X.org libXfixes 5.0 integer overflows
CVE-2013-1984 X.org libXi 1.7.1 integer overflows
CVE-2013-1985 X.org libXinerama 1.1.2 integer overflows
CVE-2013-1986 X.org libXrandr 1.4.0 integer overflows
CVE-2013-1987 X.org libXrender 0.9.7 integer overflows
CVE-2013-1988 X.org libXRes 1.0.6 integer overflows
CVE-2013-1989 X.org libXv 1.0.7 integer overflows
CVE-2013-1990 X.org libXvMC 1.0.7 integer overflows
CVE-2013-1991 X.org libXxf86dga 1.1.3 integer overflows
CVE-2013-1992 X.org libdmx 1.1.2 integer overflows
CVE-2013-1994 X.org libchromeXvMC & libchromeXvMCPro in openChrome
0.3.2 integer overflows
CVE-2013-1995 X.org libXi 1.7.1 sign extension issues
CVE-2013-1996 X.org libFS 1.0.4 sign extension issues
CVE-2013-1997 X.org libX11 1.5.99.901 (1.6 RC1) buffer overflows
CVE-2013-1998 X.org libXi 1.7.1 buffer overflows
CVE-2013-1999 X.org libXvMC 1.0.7 buffer overflows
CVE-2013-2000 X.org libXxf86dga 1.1.3 buffer overflows
CVE-2013-2001 X.org libXxf86vm 1.1.2 buffer overflows
CVE-2013-2002 X.org libXt 1.1.3 buffer overflows
CVE-2013-2003 X.org libXcursor 1.1.13 integer overflows
CVE-2013-2004 X.org libX11 1.5.99.901 (1.6 RC1) unbounded recursion
CVE-2013-2005 X.org libXt 1.1.3 memory corruption
CVE-2013-2066 X.org libXv 1.0.7 buffer overflows
@
text
@d777 11
@


1.8
log
@Upate to libX11 1.5rc1. Tested by krw@@, mpi@@, shadchin@@.
@
text
@d22 1
d759 16
@


1.7
log
@Update to libX11 1.4.4. Tested by ajacoutot@@, shadchin@@.
@
text
@d481 1
a481 1
	vec[1].iov_base = (caddr_t) data;
d483 1
a483 1
	vec[2].iov_base = (caddr_t) pad;
@


1.6
log
@Update to libx11 1.4.2. Tested by ajacoutot@@, jasper@@ krw@@, landry@@,
shadchin@@ on various architectures.
Bump major.
@
text
@d18 1
d26 22
d77 8
a84 3
		assert(!(sizeof(unsigned long) > sizeof(unsigned int)
		         && dpy->xcb->event_owner == XlibOwnsEventQueue
		         && (sent - dpy->last_request_read >= (UINT64_C(1) << 32))));
d156 9
a164 2
		assert(XLIB_SEQUENCE_COMPARE(dpy->xcb->pending_requests_tail->sequence, <, node->sequence));
		assert(dpy->xcb->pending_requests_tail->next == NULL);
d175 5
a179 1
	assert(req == dpy->xcb->pending_requests);
d183 4
a186 1
		assert(req == dpy->xcb->pending_requests_tail);
d189 6
a194 2
	else
		assert(XLIB_SEQUENCE_COMPARE(req->sequence, <, dpy->xcb->pending_requests->sequence));
d267 8
a274 1
			assert(XLIB_SEQUENCE_COMPARE(event_sequence, <=, dpy->request));
d293 6
a298 1
		assert(XLIB_SEQUENCE_COMPARE(req->sequence, <=, dpy->request));
d573 3
a575 1
	assert(!dpy->xcb->reply_data);
d631 5
a635 1
		assert(XLIB_SEQUENCE_COMPARE(req->sequence, <=, dpy->request));
d732 4
a735 2
	assert(dpy->xcb->reply_data != NULL);
	assert(dpy->xcb->reply_consumed + size <= dpy->xcb->reply_length);
@


1.5
log
@Update to libX11 1.3.5
@
text
@d242 3
a244 2
		if(!response)
			dequeue_pending_request(dpy, req);
d343 9
a351 1
			InternalLockDisplay(dpy, /* don't skip user locks */ 0);
d542 4
a545 1
		InternalLockDisplay(dpy, /* don't skip user locks */ 0);
@


1.4
log
@Update to libX11 1.3.3. Tested on a bulk ports build by naddy@@.
@
text
@d15 1
d17 1
d28 1
a28 1
	LockDisplay(dpy);
d119 1
a119 1
static void call_handlers(Display *dpy, xcb_generic_reply_t *buf)
d121 10
a130 6
	_XAsyncHandler *async, *next;
	for(async = dpy->async_handlers; async; async = next)
	{
		next = async->next;
		if(async->handler(dpy, (xReply *) buf, (char *) buf, sizeof(xReply) + (buf->length << 2), async->data))
			return;
d132 4
a135 2
	if(buf->response_type == 0) /* unhandled error */
	    _XError(dpy, (xError *) buf);
d138 1
a138 1
static xcb_generic_event_t * wait_or_poll_for_event(Display *dpy, int wait)
d140 3
a142 3
	xcb_connection_t *c = dpy->xcb->connection;
	xcb_generic_event_t *event;
	if(wait)
d144 2
a145 14
		if(dpy->xcb->event_waiter)
		{
			ConditionWait(dpy, dpy->xcb->event_notify);
			event = xcb_poll_for_event(c);
		}
		else
		{
			dpy->xcb->event_waiter = 1;
			UnlockDisplay(dpy);
			event = xcb_wait_for_event(c);
			LockDisplay(dpy);
			dpy->xcb->event_waiter = 0;
			ConditionBroadcast(dpy, dpy->xcb->event_notify);
		}
d148 20
a167 2
		event = xcb_poll_for_event(c);
	return event;
d180 22
a201 1
static void process_responses(Display *dpy, int wait_for_first_event, xcb_generic_error_t **current_error, unsigned long current_request)
d203 5
a207 6
	void *reply;
	xcb_generic_event_t *event = dpy->xcb->next_event;
	xcb_generic_error_t *error;
	xcb_connection_t *c = dpy->xcb->connection;
	if(!event && dpy->xcb->event_owner == XlibOwnsEventQueue)
		event = wait_or_poll_for_event(dpy, wait_for_first_event);
d209 2
a210 1
	require_socket(dpy);
d212 1
a212 1
	while(1)
d215 1
d217 3
a219 4
		if(event)
			widen(&event_sequence, event->full_sequence);
		assert(!(req && current_request && !XLIB_SEQUENCE_COMPARE(req->sequence, <=, current_request)));
		if(event && (!req || XLIB_SEQUENCE_COMPARE(event_sequence, <=, req->sequence)))
d221 1
d223 2
a224 30
			if(event->response_type != X_Error)
			{
				/* GenericEvents may be > 32 bytes. In this
				 * case, the event struct is trailed by the
				 * additional bytes. the xcb_generic_event_t
				 * struct uses 4 bytes for internal numbering,
				 * so we need to shift the trailing data to be
				 * after the first 32 bytes.  */
                                if (event->response_type == GenericEvent &&
                                        ((xcb_ge_event_t*)event)->length)
				{
					memmove(&event->full_sequence,
                                                &event[1],
						((xcb_ge_event_t*)event)->length * 4);
				}
				_XEnq(dpy, (xEvent *) event);
				wait_for_first_event = 0;
			}
			else if(current_error && event_sequence == current_request)
			{
				/* This can only occur when called from
				 * _XReply, which doesn't need a new event. */
				*current_error = (xcb_generic_error_t *) event;
				event = NULL;
				break;
			}
			else
				_XError(dpy, (xError *) event);
			free(event);
			event = wait_or_poll_for_event(dpy, wait_for_first_event);
d226 31
a256 1
		else if(req && req->sequence == current_request)
d258 3
a260 1
			break;
d262 13
a274 1
		else if(req && xcb_poll_for_reply(dpy->xcb->connection, req->sequence, &reply, &error))
d276 2
a277 15
			uint64_t sequence = req->sequence;
			if(!reply)
			{
				dpy->xcb->pending_requests = req->next;
				if(!dpy->xcb->pending_requests)
					dpy->xcb->pending_requests_tail = &dpy->xcb->pending_requests;
				free(req);
				reply = error;
			}
			if(reply)
			{
				dpy->last_request_read = sequence;
				call_handlers(dpy, reply);
				free(reply);
			}
d279 2
a280 2
		else
			break;
d282 1
a282 7

	dpy->xcb->next_event = event;

	if(xcb_connection_has_error(c))
		_XIOError(dpy);

	assert(XLIB_SEQUENCE_COMPARE(dpy->last_request_read, <=, dpy->request));
d287 1
d297 11
a307 1
	process_responses(dpy, 0, NULL, 0);
d316 3
d325 51
a375 3
	do {
		process_responses(dpy, 1, NULL, 0);
	} while (dpy->qlen == 0);
d406 2
a407 9
		for(sequence = dpy->xcb->last_flushed; sequence < dpy->request; ++sequence)
		{
			PendingRequest *req = malloc(sizeof(PendingRequest));
			assert(req);
			req->next = NULL;
			req->sequence = sequence;
			*dpy->xcb->pending_requests_tail = req;
			dpy->xcb->pending_requests_tail = &req->next;
		}
d451 1
a451 1
int _XIDHandler(Display *dpy)
d453 2
a454 14
	XID next;

	if (dpy->xcb->next_xid != inval_id)
	    return 0;

	next = xcb_generate_id(dpy->xcb->connection);
	LockDisplay(dpy);
	dpy->xcb->next_xid = next;
#ifdef XTHREADS
	if (dpy->lock)
		(*dpy->lock->user_unlock_display)(dpy);
#endif
	UnlockDisplay(dpy);
	return 0;
a461 4
#ifdef XTHREADS
	if (dpy->lock)
		(*dpy->lock->user_lock_display)(dpy);
#endif
d479 1
a479 1
	LockDisplay(dpy);
a492 18
static PendingRequest * insert_pending_request(Display *dpy)
{
	PendingRequest **cur = &dpy->xcb->pending_requests;
	while(*cur && XLIB_SEQUENCE_COMPARE((*cur)->sequence, <, dpy->request))
		cur = &((*cur)->next);
	if(!*cur || (*cur)->sequence != dpy->request)
	{
		PendingRequest *node = malloc(sizeof(PendingRequest));
		assert(node);
		node->next = *cur;
		node->sequence = dpy->request;
		if(cur == dpy->xcb->pending_requests_tail)
			dpy->xcb->pending_requests_tail = &(node->next);
		*cur = node;
	}
	return *cur;
}

d512 44
a555 4
	current = insert_pending_request(dpy);
	/* FIXME: drop the Display lock while waiting?
	 * Complicates process_responses. */
	reply = xcb_wait_for_reply(c, current->sequence, &error);
d557 18
d576 12
a587 1
	process_responses(dpy, 0, &error, current->sequence);
a590 2
		_XExtension *ext;
		xError *err = (xError *) error;
a592 2
		dpy->last_request_read = error->full_sequence;

d599 1
a599 1
		switch(err->errorCode)
d602 1
a602 1
				switch(err->majorCode)
d611 1
a611 1
				if(err->majorCode == X_QueryFont) {
d622 1
a622 11
		/*
		 * we better see if there is an extension who may
		 * want to suppress the error.
		 */
		for(ext = dpy->ext_procs; ext; ext = ext->next)
			if(ext->error && ext->error(dpy, err, &ext->codes, &ret_code)) {
				free(error);
				return ret_code;
			}

		_XError(dpy, err);
d624 1
a624 1
		return 0;
a633 2

	dpy->last_request_read = current->sequence;
@


1.3
log
@update to libX11 1.2.1
@
text
@d4 4
d19 3
@


1.2
log
@Update to libX11 1.1.4. I've carefully checked that there's no API/ABI
change in this version. Only small bug fixes, manual page fixes and
some more data in the i18n tables.
@
text
@d6 1
a8 1
#include <xcb/xcbxlib.h>
d11 2
d16 37
d72 1
a72 1
	struct _XConnectionInfo *ilist;  
a109 9
static void condition_wait(Display *dpy, xcondition_t cv)
{
	_XPutXCBBuffer(dpy);
	xcb_xlib_unlock(dpy->xcb->connection);
	ConditionWait(dpy, cv);
	xcb_xlib_lock(dpy->xcb->connection);
	_XGetXCBBuffer(dpy);
}

d129 14
a142 3
		UnlockDisplay(dpy);
		event = xcb_wait_for_event(c);
		LockDisplay(dpy);
d149 11
a159 1
static void process_responses(Display *dpy, int wait_for_first_event, xcb_generic_error_t **current_error, unsigned int current_request)
d168 2
d173 5
a177 2
		assert(!(req && current_request && !XCB_SEQUENCE_COMPARE(req->sequence, <=, current_request)));
		if(event && (!req || XCB_SEQUENCE_COMPARE(event->full_sequence, <=, req->sequence)))
d179 1
a179 1
			dpy->last_request_read = event->full_sequence;
d182 13
d198 1
a198 1
			else if(current_error && event->full_sequence == current_request)
d203 1
a203 1
				event = 0;
d211 1
a211 1
		else if(req && req->waiters != -1)
d213 1
a213 10
			if(req->sequence == current_request)
				break;
			if(!current_request && !wait_for_first_event)
				break;
			dpy->xcb->next_event = event;
			req->waiters++;
			assert(req->waiters > 0);
			condition_wait(dpy, &req->condition);
			--req->waiters;
			event = dpy->xcb->next_event;
d217 1
a217 1
			unsigned int sequence = req->sequence;
d242 1
a242 2
	assert_sequence_less(dpy->last_request_read, dpy->request);
	assert(!wait_for_first_event);
d253 1
a253 1
		_XSend(dpy, 0, 0);
d256 1
a256 1
	process_responses(dpy, 0, 0, 0);
d267 1
a267 1
	_XSend(dpy, 0, 0);
d271 3
a273 1
	process_responses(dpy, 1, 0, 0);
d285 5
d294 2
a295 3
	assert(!dpy->xcb->request_extra);
	dpy->xcb->request_extra = data;
	dpy->xcb->request_extra_size = size;
d297 34
a330 2
	/* give dpy->buffer to XCB */
	_XPutXCBBuffer(dpy);
d332 1
a332 1
	if(xcb_flush(c) <= 0)
d334 2
a335 3

	/* get a new dpy->buffer */
	_XGetXCBBuffer(dpy);
d339 1
a339 7
	/* A straight port of XlibInt.c would call _XSetSeqSyncFunction
	 * here. However that does no good: unlike traditional Xlib,
	 * Xlib/XCB almost never calls _XFlush because _XPutXCBBuffer
	 * automatically pushes requests down into XCB, so Xlib's buffer
	 * is empty most of the time. Since setting a synchandler has no
	 * effect until after UnlockDisplay returns, we may as well do
	 * the check in _XUnlockDisplay. */
d348 2
a349 1
	_XSend(dpy, 0, 0);
d354 3
a356 2
static int
_XIDHandler(Display *dpy)
d358 6
a363 1
	XID next = xcb_generate_id(dpy->xcb->connection);
d366 4
a369 5
	if(dpy->flags & XlibDisplayPrivSync)
	{
		dpy->synchandler = dpy->savedsynchandler;
		dpy->flags &= ~XlibDisplayPrivSync;
	}
a370 1
	SyncHandle();
d378 7
a384 8
	dpy->xcb->next_xid = 0;

	if(!(dpy->flags & XlibDisplayPrivSync))
	{
		dpy->savedsynchandler = dpy->synchandler;
		dpy->flags |= XlibDisplayPrivSync;
	}
	dpy->synchandler = _XIDHandler;
d392 5
a396 1
	_XPutXCBBuffer(dpy);
d399 5
a403 1
	_XGetXCBBuffer(dpy);
d411 1
a411 1
	dpy->xcb->reply_data = 0;
d417 1
a417 1
	while(*cur && XCB_SEQUENCE_COMPARE((*cur)->sequence, <, dpy->request))
d419 1
a419 8
	if(*cur && (*cur)->sequence == dpy->request)
	{
		/* Replacing an existing PendingRequest should only happen once,
		   when calling _XReply, and the replaced PendingRequest must
		   not have a condition set. */
		assert((*cur)->waiters == -1);
	}
	else
a428 2
	(*cur)->waiters = 0;
	xcondition_init(&((*cur)->condition));
d450 1
a450 4
	/* Internals of UnlockDisplay done by hand here, so that we can
	   insert_pending_request *after* we _XPutXCBBuffer, but before we
	   unlock the display. */
	_XPutXCBBuffer(dpy);
d452 2
a453 4
	if(!dpy->lock || dpy->lock->locking_level == 0)
		xcb_xlib_unlock(dpy->xcb->connection);
	if(dpy->xcb->lock_fns.unlock_display)
		dpy->xcb->lock_fns.unlock_display(dpy);
a454 1
	LockDisplay(dpy);
a458 6
	if(current->waiters)
	{ /* The ConditionBroadcast macro contains an if; braces needed here. */
		ConditionBroadcast(dpy, &current->condition);
	}
	--current->waiters;

d480 1
d485 2
a486 1
				if(err->majorCode == X_QueryFont)
d488 1
d492 1
d496 1
a496 1
		/* 
d501 2
a502 1
			if(ext->error && ext->error(dpy, err, &ext->codes, &ret_code))
d504 1
d506 2
a507 1
		_XError(dpy, (xError *) error);
d542 1
a542 1
	assert(dpy->xcb->reply_data != 0);
@


1.1
log
@Initial revision
@
text
@d5 1
d71 1
a71 1
static void handle_event(Display *dpy, xcb_generic_event_t *e)
d73 5
a77 8
	if(!e)
		_XIOError(dpy);
	dpy->last_request_read = e->full_sequence;
	if(e->response_type == X_Error)
		_XError(dpy, (xError *) e);
	else
		_XEnq(dpy, (xEvent *) e);
	free(e);
d93 16
a108 1
static void process_responses(Display *dpy, int wait_for_first_event, xcb_generic_error_t **current_error, unsigned long current_request)
a112 1
	PendingRequest *req;
d115 1
a115 10
	{
		if(wait_for_first_event)
		{
			UnlockDisplay(dpy);
			event = xcb_wait_for_event(c);
			LockDisplay(dpy);
		}
		else
			event = xcb_poll_for_event(c);
	}
d119 3
a121 3
		req = dpy->xcb->pending_requests;
		if(event && XCB_SEQUENCE_COMPARE(event->full_sequence, <=, current_request)
		         && (!req || XCB_SEQUENCE_COMPARE(event->full_sequence, <=, req->sequence)))
d123 2
a124 1
			if(current_error && event->response_type == 0 && event->full_sequence == current_request)
d126 7
d137 17
a153 2
			handle_event(dpy, event);
			event = xcb_poll_for_event(c);
d155 1
a155 2
		else if(req && XCB_SEQUENCE_COMPARE(req->sequence, <, current_request)
		            && xcb_poll_for_reply(dpy->xcb->connection, req->sequence, &reply, &error))
d157 1
a157 1
			dpy->xcb->pending_requests = req->next;
d159 5
d165 1
d168 1
a168 1
				dpy->last_request_read = req->sequence;
d170 1
a171 2
			free(req);
			free(reply);
a175 2
	if(!dpy->xcb->pending_requests)
		dpy->xcb->pending_requests_tail = &dpy->xcb->pending_requests;
d183 1
d188 2
d197 1
a197 1
	process_responses(dpy, 0, 0, dpy->request);
d206 2
d212 1
a212 1
	process_responses(dpy, 1, 0, dpy->request);
d225 2
d285 5
a289 3
	assert(!(dpy->flags & XlibDisplayPrivSync));
	dpy->savedsynchandler = dpy->synchandler;
	dpy->flags |= XlibDisplayPrivSync;
d312 27
a348 1
	unsigned long request = dpy->request;
d350 1
d354 13
a366 2
	UnlockDisplay(dpy);
	reply = xcb_wait_for_reply(c, request, &error);
d370 7
a376 1
	process_responses(dpy, 0, &error, request);
d431 1
a431 1
	dpy->last_request_read = request;
@


1.1.1.1
log
@import from X.Org 7.2RC2
@
text
@@


1.1.1.2
log
@Import libX11 1.1.1 from X.Org 7.2RC3
@
text
@a4 1
#include "locking.h"
a69 9
static void condition_wait(Display *dpy, xcondition_t cv)
{
	_XPutXCBBuffer(dpy);
	xcb_xlib_unlock(dpy->xcb->connection);
	ConditionWait(dpy, cv);
	xcb_xlib_lock(dpy->xcb->connection);
	_XGetXCBBuffer(dpy);
}

d95 1
a95 16
static xcb_generic_event_t * wait_or_poll_for_event(Display *dpy, int wait)
{
	xcb_connection_t *c = dpy->xcb->connection;
	xcb_generic_event_t *event;
	if(wait && !dpy->head)
	{
		UnlockDisplay(dpy);
		event = xcb_wait_for_event(c);
		LockDisplay(dpy);
	}
	else
		event = xcb_poll_for_event(c);
	return event;
}

static void process_responses(Display *dpy, int wait_for_first_event, xcb_generic_error_t **current_error, unsigned int current_request)
d103 10
a112 1
		event = wait_or_poll_for_event(dpy, wait_for_first_event);
d117 2
a118 2
		assert(!(req && current_request && !XCB_SEQUENCE_COMPARE(req->sequence, <=, current_request)));
		if(event && (!req || XCB_SEQUENCE_COMPARE(event->full_sequence, <=, req->sequence)))
d127 1
a127 1
			event = wait_or_poll_for_event(dpy, wait_for_first_event);
d129 2
a130 15
		else if(req && req->waiters != -1)
		{
			if(req->sequence == current_request)
				break;
			if(!current_request && !(wait_for_first_event && !dpy->head))
				break;
			dpy->xcb->next_event = event;
			req->waiters++;
			assert(req->waiters > 0);
			condition_wait(dpy, &req->condition);
			if(--req->waiters == 0)
				free(req);
			event = dpy->xcb->next_event;
		}
		else if(req && xcb_poll_for_reply(dpy->xcb->connection, req->sequence, &reply, &error))
a132 2
			if(!dpy->xcb->pending_requests)
				dpy->xcb->pending_requests_tail = &dpy->xcb->pending_requests;
d146 2
a154 1
	assert(!wait_for_first_event || dpy->head);
d166 1
a166 1
	process_responses(dpy, 0, 0, 0);
d179 1
a179 1
	process_responses(dpy, 1, 0, 0);
a274 38
static PendingRequest * insert_pending_request(Display *dpy)
{
	PendingRequest **cur = &dpy->xcb->pending_requests;
	while(*cur && XCB_SEQUENCE_COMPARE((*cur)->sequence, <, dpy->request))
		cur = &((*cur)->next);
	if(*cur && (*cur)->sequence == dpy->request)
	{
		/* Replacing an existing PendingRequest should only happen once,
		   when calling _XReply, and the replaced PendingRequest must
		   not have a condition set. */
		assert((*cur)->waiters == -1);
	}
	else
	{
		PendingRequest *node = malloc(sizeof(PendingRequest));
		assert(node);
		node->next = *cur;
		node->sequence = dpy->request;
		if(cur == dpy->xcb->pending_requests_tail)
			dpy->xcb->pending_requests_tail = &(node->next);
		*cur = node;
	}
	(*cur)->waiters = 0;
	xcondition_init(&((*cur)->condition));
	return *cur;
}

static void remove_pending_request(Display *dpy, PendingRequest *node)
{
	PendingRequest **cur = &dpy->xcb->pending_requests;
	while(*cur && *cur != node)
		cur = &((*cur)->next);
	if(*cur == node)
		*cur = node->next;
	if(!dpy->xcb->pending_requests)
		dpy->xcb->pending_requests_tail = &dpy->xcb->pending_requests;
}

d285 1
a286 2
	PendingRequest *current;
	unsigned int current_sequence;
d290 2
a291 9
	/* Internals of UnlockDisplay done by hand here, so that we can
	   insert_pending_request *after* we _XPutXCBBuffer, but before we
	   unlock the display. */
	_XPutXCBBuffer(dpy);
	current = insert_pending_request(dpy);
	xcb_xlib_unlock(dpy->xcb->connection);
	if(dpy->xcb->lock_fns.unlock_display)
		dpy->xcb->lock_fns.unlock_display(dpy);
	reply = xcb_wait_for_reply(c, current->sequence, &error);
d295 1
a295 14
	process_responses(dpy, 0, &error, current->sequence);

	current_sequence = current->sequence;

	remove_pending_request(dpy, current);
	if(current->waiters)
	{ /* The ConditionBroadcast macro contains an if; braces needed here. */
		ConditionBroadcast(dpy, &current->condition);
	}
	else
	{
		free(current);
		current = NULL;
	}
d350 1
a350 1
	dpy->last_request_read = current_sequence;
@


1.1.1.3
log
@libX11 1.1.3
@
text
@d80 12
d109 1
a109 1
	if(wait)
d125 1
d132 1
a132 1
		PendingRequest *req = dpy->xcb->pending_requests;
d136 1
a136 7
			dpy->last_request_read = event->full_sequence;
			if(event->response_type != X_Error)
			{
				_XEnq(dpy, (xEvent *) event);
				wait_for_first_event = 0;
			}
			else if(current_error && event->full_sequence == current_request)
a137 2
				/* This can only occur when called from
				 * _XReply, which doesn't need a new event. */
d142 1
a142 3
			else
				_XError(dpy, (xError *) event);
			free(event);
d149 1
a149 1
			if(!current_request && !wait_for_first_event)
d155 2
a156 1
			--req->waiters;
d161 3
a163 1
			unsigned int sequence = req->sequence;
a164 5
			{
				dpy->xcb->pending_requests = req->next;
				if(!dpy->xcb->pending_requests)
					dpy->xcb->pending_requests_tail = &dpy->xcb->pending_requests;
				free(req);
a165 1
			}
d168 1
a168 1
				dpy->last_request_read = sequence;
a169 1
				free(reply);
d171 2
d184 1
a184 1
	assert(!wait_for_first_event);
a188 2
	if(dpy->flags & XlibDisplayIOError)
		return 0;
a204 2
	if(dpy->flags & XlibDisplayIOError)
		return;
a221 2
	if(dpy->flags & XlibDisplayIOError)
		return;
d332 11
d355 1
a358 3
	if(dpy->flags & XlibDisplayIOError)
		return 0;

d364 1
a364 2
	if(!dpy->lock || dpy->lock->locking_level == 0)
		xcb_xlib_unlock(dpy->xcb->connection);
d373 3
d380 5
a384 1
	--current->waiters;
d439 1
a439 1
	dpy->last_request_read = current->sequence;
@


