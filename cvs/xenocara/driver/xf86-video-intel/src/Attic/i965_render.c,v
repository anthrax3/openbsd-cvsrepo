head	1.11;
access;
symbols
	OPENBSD_5_4:1.10.0.2
	OPENBSD_5_4_BASE:1.10
	OPENBSD_5_3:1.9.0.2
	OPENBSD_5_3_BASE:1.9
	OPENBSD_5_2:1.8.0.4
	OPENBSD_5_2_BASE:1.8
	OPENBSD_5_1_BASE:1.8
	OPENBSD_5_1:1.8.0.2
	OPENBSD_5_0:1.7.0.4
	OPENBSD_5_0_BASE:1.7
	OPENBSD_4_9:1.7.0.2
	OPENBSD_4_9_BASE:1.7
	OPENBSD_4_8:1.6.0.4
	OPENBSD_4_8_BASE:1.6
	OPENBSD_4_7:1.4.0.4
	OPENBSD_4_7_BASE:1.4
	OPENBSD_4_6:1.4.0.2
	OPENBSD_4_6_BASE:1.4
	OPENBSD_4_5:1.3.0.2
	OPENBSD_4_5_BASE:1.3
	OPENBSD_4_4:1.2.0.2
	OPENBSD_4_4_BASE:1.2
	OPENBSD_4_3_BASE:1.1.1.2
	OPENBSD_4_3:1.1.1.2.0.2
	v2_2_0_90:1.1.1.2
	v2_2_0:1.1.1.1
	xorg:1.1.1;
locks; strict;
comment	@ * @;


1.11
date	2014.02.03.15.54.51;	author matthieu;	state dead;
branches;
next	1.10;

1.10
date	2013.03.18.18.38.20;	author matthieu;	state Exp;
branches;
next	1.9;

1.9
date	2012.10.06.03.51.23;	author jsg;	state Exp;
branches;
next	1.8;

1.8
date	2011.11.29.12.39.03;	author oga;	state Exp;
branches;
next	1.7;

1.7
date	2011.02.11.21.01.55;	author matthieu;	state Exp;
branches;
next	1.6;

1.6
date	2010.07.18.14.47.47;	author oga;	state Exp;
branches;
next	1.5;

1.5
date	2010.05.10.22.32.29;	author oga;	state Exp;
branches;
next	1.4;

1.4
date	2009.06.25.20.16.43;	author matthieu;	state Exp;
branches;
next	1.3;

1.3
date	2008.10.12.15.20.50;	author matthieu;	state Exp;
branches;
next	1.2;

1.2
date	2008.05.21.20.19.52;	author matthieu;	state Exp;
branches;
next	1.1;

1.1
date	2007.11.24.19.44.46;	author matthieu;	state Exp;
branches
	1.1.1.1;
next	;

1.1.1.1
date	2007.11.24.19.44.46;	author matthieu;	state Exp;
branches;
next	1.1.1.2;

1.1.1.2
date	2008.02.11.20.10.09;	author matthieu;	state Exp;
branches;
next	;


desc
@@


1.11
log
@Update to xf86-video-intel 2.99.909
Tested by jsg@@, kettenis@@ and myself on a wide range of intel cards.
@
text
@/*
 * Copyright © 2006,2008 Intel Corporation
 * Copyright © 2007 Red Hat, Inc.
 *
 * Permission is hereby granted, free of charge, to any person obtaining a
 * copy of this software and associated documentation files (the "Software"),
 * to deal in the Software without restriction, including without limitation
 * the rights to use, copy, modify, merge, publish, distribute, sublicense,
 * and/or sell copies of the Software, and to permit persons to whom the
 * Software is furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice (including the next
 * paragraph) shall be included in all copies or substantial portions of the
 * Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
 * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 *
 * Authors:
 *    Wang Zhenyu <zhenyu.z.wang@@intel.com>
 *    Eric Anholt <eric@@anholt.net>
 *    Carl Worth <cworth@@redhat.com>
 *    Keith Packard <keithp@@keithp.com>
 *
 */

#ifdef HAVE_CONFIG_H
#include "config.h"
#endif

#include <assert.h>
#include "xf86.h"
#include "intel.h"
#include "i830_reg.h"
#include "i965_reg.h"

/* bring in brw structs */
#include "brw_defines.h"
#include "brw_structs.h"

// refer vol2, 3d rasterization 3.8.1

/* defined in brw_defines.h */
static const struct blendinfo {
	Bool dst_alpha;
	Bool src_alpha;
	uint32_t src_blend;
	uint32_t dst_blend;
} i965_blend_op[] = {
	/* Clear */
	{0, 0, BRW_BLENDFACTOR_ZERO, BRW_BLENDFACTOR_ZERO},
	/* Src */
	{0, 0, BRW_BLENDFACTOR_ONE, BRW_BLENDFACTOR_ZERO},
	/* Dst */
	{0, 0, BRW_BLENDFACTOR_ZERO, BRW_BLENDFACTOR_ONE},
	/* Over */
	{0, 1, BRW_BLENDFACTOR_ONE, BRW_BLENDFACTOR_INV_SRC_ALPHA},
	/* OverReverse */
	{1, 0, BRW_BLENDFACTOR_INV_DST_ALPHA, BRW_BLENDFACTOR_ONE},
	/* In */
	{1, 0, BRW_BLENDFACTOR_DST_ALPHA, BRW_BLENDFACTOR_ZERO},
	/* InReverse */
	{0, 1, BRW_BLENDFACTOR_ZERO, BRW_BLENDFACTOR_SRC_ALPHA},
	/* Out */
	{1, 0, BRW_BLENDFACTOR_INV_DST_ALPHA, BRW_BLENDFACTOR_ZERO},
	/* OutReverse */
	{0, 1, BRW_BLENDFACTOR_ZERO, BRW_BLENDFACTOR_INV_SRC_ALPHA},
	/* Atop */
	{1, 1, BRW_BLENDFACTOR_DST_ALPHA, BRW_BLENDFACTOR_INV_SRC_ALPHA},
	/* AtopReverse */
	{1, 1, BRW_BLENDFACTOR_INV_DST_ALPHA, BRW_BLENDFACTOR_SRC_ALPHA},
	/* Xor */
	{1, 1, BRW_BLENDFACTOR_INV_DST_ALPHA, BRW_BLENDFACTOR_INV_SRC_ALPHA},
	/* Add */
	{0, 0, BRW_BLENDFACTOR_ONE, BRW_BLENDFACTOR_ONE},
};

/**
 * Highest-valued BLENDFACTOR used in i965_blend_op.
 *
 * This leaves out BRW_BLENDFACTOR_INV_DST_COLOR,
 * BRW_BLENDFACTOR_INV_CONST_{COLOR,ALPHA},
 * BRW_BLENDFACTOR_INV_SRC1_{COLOR,ALPHA}
 */
#define BRW_BLENDFACTOR_COUNT (BRW_BLENDFACTOR_INV_DST_ALPHA + 1)

/* FIXME: surface format defined in brw_defines.h, shared Sampling engine
 * 1.7.2
 */
static const struct formatinfo {
	int fmt;
	uint32_t card_fmt;
} i965_tex_formats[] = {
	{PICT_a8, BRW_SURFACEFORMAT_A8_UNORM},
	{PICT_a8r8g8b8, BRW_SURFACEFORMAT_B8G8R8A8_UNORM},
	{PICT_x8r8g8b8, BRW_SURFACEFORMAT_B8G8R8X8_UNORM},
	{PICT_a8b8g8r8, BRW_SURFACEFORMAT_R8G8B8A8_UNORM},
	{PICT_x8b8g8r8, BRW_SURFACEFORMAT_R8G8B8X8_UNORM},
	{PICT_r8g8b8, BRW_SURFACEFORMAT_R8G8B8_UNORM},
	{PICT_r5g6b5, BRW_SURFACEFORMAT_B5G6R5_UNORM},
	{PICT_a1r5g5b5, BRW_SURFACEFORMAT_B5G5R5A1_UNORM},
#if XORG_VERSION_CURRENT >= 10699900
	{PICT_a2r10g10b10, BRW_SURFACEFORMAT_B10G10R10A2_UNORM},
	{PICT_x2r10g10b10, BRW_SURFACEFORMAT_B10G10R10X2_UNORM},
	{PICT_a2b10g10r10, BRW_SURFACEFORMAT_R10G10B10A2_UNORM},
	{PICT_x2r10g10b10, BRW_SURFACEFORMAT_B10G10R10X2_UNORM},
#endif
	{PICT_a4r4g4b4, BRW_SURFACEFORMAT_B4G4R4A4_UNORM},
};

static void i965_get_blend_cntl(int op, PicturePtr mask, uint32_t dst_format,
				uint32_t * sblend, uint32_t * dblend)
{

	*sblend = i965_blend_op[op].src_blend;
	*dblend = i965_blend_op[op].dst_blend;

	/* If there's no dst alpha channel, adjust the blend op so that we'll treat
	 * it as always 1.
	 */
	if (PICT_FORMAT_A(dst_format) == 0 && i965_blend_op[op].dst_alpha) {
		if (*sblend == BRW_BLENDFACTOR_DST_ALPHA)
			*sblend = BRW_BLENDFACTOR_ONE;
		else if (*sblend == BRW_BLENDFACTOR_INV_DST_ALPHA)
			*sblend = BRW_BLENDFACTOR_ZERO;
	}

	/* If the source alpha is being used, then we should only be in a case where
	 * the source blend factor is 0, and the source blend value is the mask
	 * channels multiplied by the source picture's alpha.
	 */
	if (mask && mask->componentAlpha && PICT_FORMAT_RGB(mask->format)
	    && i965_blend_op[op].src_alpha) {
		if (*dblend == BRW_BLENDFACTOR_SRC_ALPHA) {
			*dblend = BRW_BLENDFACTOR_SRC_COLOR;
		} else if (*dblend == BRW_BLENDFACTOR_INV_SRC_ALPHA) {
			*dblend = BRW_BLENDFACTOR_INV_SRC_COLOR;
		}
	}

}

static uint32_t i965_get_dest_format(PicturePtr dest_picture)
{
	switch (dest_picture->format) {
	case PICT_a8r8g8b8:
	case PICT_x8r8g8b8:
		return BRW_SURFACEFORMAT_B8G8R8A8_UNORM;
	case PICT_a8b8g8r8:
	case PICT_x8b8g8r8:
		return BRW_SURFACEFORMAT_R8G8B8A8_UNORM;
#if XORG_VERSION_CURRENT >= 10699900
	case PICT_a2r10g10b10:
	case PICT_x2r10g10b10:
		return BRW_SURFACEFORMAT_B10G10R10A2_UNORM;
#endif
	case PICT_r5g6b5:
		return BRW_SURFACEFORMAT_B5G6R5_UNORM;
	case PICT_x1r5g5b5:
	case PICT_a1r5g5b5:
		return BRW_SURFACEFORMAT_B5G5R5A1_UNORM;
	case PICT_a8:
		return BRW_SURFACEFORMAT_A8_UNORM;
	case PICT_a4r4g4b4:
	case PICT_x4r4g4b4:
		return BRW_SURFACEFORMAT_B4G4R4A4_UNORM;
	default:
		return -1;
	}
}

Bool
i965_check_composite(int op,
		     PicturePtr source_picture,
		     PicturePtr mask_picture,
		     PicturePtr dest_picture,
		     int width, int height)
{
	ScrnInfoPtr scrn = xf86ScreenToScrn(dest_picture->pDrawable->pScreen);

	/* Check for unsupported compositing operations. */
	if (op >= sizeof(i965_blend_op) / sizeof(i965_blend_op[0])) {
		intel_debug_fallback(scrn,
				     "Unsupported Composite op 0x%x\n", op);
		return FALSE;
	}

	if (mask_picture && mask_picture->componentAlpha &&
	    PICT_FORMAT_RGB(mask_picture->format)) {
		/* Check if it's component alpha that relies on a source alpha and on
		 * the source value.  We can only get one of those into the single
		 * source value that we get to blend with.
		 */
		if (i965_blend_op[op].src_alpha &&
		    (i965_blend_op[op].src_blend != BRW_BLENDFACTOR_ZERO)) {
			intel_debug_fallback(scrn,
					     "Component alpha not supported "
					     "with source alpha and source "
					     "value blending.\n");
			return FALSE;
		}
	}

	if (i965_get_dest_format(dest_picture) == -1) {
		intel_debug_fallback(scrn, "Usupported Color buffer format 0x%x\n",
				     (int)dest_picture->format);
		return FALSE;
	}

	return TRUE;
}

Bool
i965_check_composite_texture(ScreenPtr screen, PicturePtr picture)
{
	if (picture->repeatType > RepeatReflect) {
		ScrnInfoPtr scrn = xf86ScreenToScrn(screen);
		intel_debug_fallback(scrn,
				     "extended repeat (%d) not supported\n",
				     picture->repeatType);
		return FALSE;
	}

	if (picture->filter != PictFilterNearest &&
	    picture->filter != PictFilterBilinear) {
		ScrnInfoPtr scrn = xf86ScreenToScrn(screen);
		intel_debug_fallback(scrn, "Unsupported filter 0x%x\n",
				     picture->filter);
		return FALSE;
	}

	if (picture->pDrawable) {
		int w, h, i;

		w = picture->pDrawable->width;
		h = picture->pDrawable->height;
		if ((w > 8192) || (h > 8192)) {
			ScrnInfoPtr scrn = xf86ScreenToScrn(screen);
			intel_debug_fallback(scrn,
					     "Picture w/h too large (%dx%d)\n",
					     w, h);
			return FALSE;
		}

		for (i = 0;
		     i < sizeof(i965_tex_formats) / sizeof(i965_tex_formats[0]);
		     i++) {
			if (i965_tex_formats[i].fmt == picture->format)
				break;
		}
		if (i == sizeof(i965_tex_formats) / sizeof(i965_tex_formats[0]))
		{
			ScrnInfoPtr scrn = xf86ScreenToScrn(screen);
			intel_debug_fallback(scrn,
					     "Unsupported picture format "
					     "0x%x\n",
					     (int)picture->format);
			return FALSE;
		}

		return TRUE;
	}

	return FALSE;
}


#define BRW_GRF_BLOCKS(nreg)    ((nreg + 15) / 16 - 1)

/* Set up a default static partitioning of the URB, which is supposed to
 * allow anything we would want to do, at potentially lower performance.
 */
#define URB_CS_ENTRY_SIZE     0
#define URB_CS_ENTRIES	      0

#define URB_VS_ENTRY_SIZE     1	// each 512-bit row
#define URB_VS_ENTRIES	      8	// we needs at least 8 entries

#define URB_GS_ENTRY_SIZE     0
#define URB_GS_ENTRIES	      0

#define URB_CLIP_ENTRY_SIZE   0
#define URB_CLIP_ENTRIES      0

#define URB_SF_ENTRY_SIZE     2
#define URB_SF_ENTRIES	      1

/*
 * this program computes dA/dx and dA/dy for the texture coordinates along
 * with the base texture coordinate. It was extracted from the Mesa driver
 */

#define SF_KERNEL_NUM_GRF  16
#define SF_MAX_THREADS	   2

static const uint32_t sf_kernel_static[][4] = {
#include "exa_sf.g4b"
};

static const uint32_t sf_kernel_mask_static[][4] = {
#include "exa_sf_mask.g4b"
};

/* ps kernels */
#define PS_KERNEL_NUM_GRF   32
#define PS_MAX_THREADS	    48

static const uint32_t ps_kernel_nomask_affine_static[][4] = {
#include "exa_wm_xy.g4b"
#include "exa_wm_src_affine.g4b"
#include "exa_wm_src_sample_argb.g4b"
#include "exa_wm_write.g4b"
};

static const uint32_t ps_kernel_nomask_projective_static[][4] = {
#include "exa_wm_xy.g4b"
#include "exa_wm_src_projective.g4b"
#include "exa_wm_src_sample_argb.g4b"
#include "exa_wm_write.g4b"
};

static const uint32_t ps_kernel_maskca_affine_static[][4] = {
#include "exa_wm_xy.g4b"
#include "exa_wm_src_affine.g4b"
#include "exa_wm_src_sample_argb.g4b"
#include "exa_wm_mask_affine.g4b"
#include "exa_wm_mask_sample_argb.g4b"
#include "exa_wm_ca.g4b"
#include "exa_wm_write.g4b"
};

static const uint32_t ps_kernel_maskca_projective_static[][4] = {
#include "exa_wm_xy.g4b"
#include "exa_wm_src_projective.g4b"
#include "exa_wm_src_sample_argb.g4b"
#include "exa_wm_mask_projective.g4b"
#include "exa_wm_mask_sample_argb.g4b"
#include "exa_wm_ca.g4b"
#include "exa_wm_write.g4b"
};

static const uint32_t ps_kernel_maskca_srcalpha_affine_static[][4] = {
#include "exa_wm_xy.g4b"
#include "exa_wm_src_affine.g4b"
#include "exa_wm_src_sample_a.g4b"
#include "exa_wm_mask_affine.g4b"
#include "exa_wm_mask_sample_argb.g4b"
#include "exa_wm_ca_srcalpha.g4b"
#include "exa_wm_write.g4b"
};

static const uint32_t ps_kernel_maskca_srcalpha_projective_static[][4] = {
#include "exa_wm_xy.g4b"
#include "exa_wm_src_projective.g4b"
#include "exa_wm_src_sample_a.g4b"
#include "exa_wm_mask_projective.g4b"
#include "exa_wm_mask_sample_argb.g4b"
#include "exa_wm_ca_srcalpha.g4b"
#include "exa_wm_write.g4b"
};

static const uint32_t ps_kernel_masknoca_affine_static[][4] = {
#include "exa_wm_xy.g4b"
#include "exa_wm_src_affine.g4b"
#include "exa_wm_src_sample_argb.g4b"
#include "exa_wm_mask_affine.g4b"
#include "exa_wm_mask_sample_a.g4b"
#include "exa_wm_noca.g4b"
#include "exa_wm_write.g4b"
};

static const uint32_t ps_kernel_masknoca_projective_static[][4] = {
#include "exa_wm_xy.g4b"
#include "exa_wm_src_projective.g4b"
#include "exa_wm_src_sample_argb.g4b"
#include "exa_wm_mask_projective.g4b"
#include "exa_wm_mask_sample_a.g4b"
#include "exa_wm_noca.g4b"
#include "exa_wm_write.g4b"
};

/* new programs for Ironlake */
static const uint32_t sf_kernel_static_gen5[][4] = {
#include "exa_sf.g4b.gen5"
};

static const uint32_t sf_kernel_mask_static_gen5[][4] = {
#include "exa_sf_mask.g4b.gen5"
};

static const uint32_t ps_kernel_nomask_affine_static_gen5[][4] = {
#include "exa_wm_xy.g4b.gen5"
#include "exa_wm_src_affine.g4b.gen5"
#include "exa_wm_src_sample_argb.g4b.gen5"
#include "exa_wm_write.g4b.gen5"
};

static const uint32_t ps_kernel_nomask_projective_static_gen5[][4] = {
#include "exa_wm_xy.g4b.gen5"
#include "exa_wm_src_projective.g4b.gen5"
#include "exa_wm_src_sample_argb.g4b.gen5"
#include "exa_wm_write.g4b.gen5"
};

static const uint32_t ps_kernel_maskca_affine_static_gen5[][4] = {
#include "exa_wm_xy.g4b.gen5"
#include "exa_wm_src_affine.g4b.gen5"
#include "exa_wm_src_sample_argb.g4b.gen5"
#include "exa_wm_mask_affine.g4b.gen5"
#include "exa_wm_mask_sample_argb.g4b.gen5"
#include "exa_wm_ca.g4b.gen5"
#include "exa_wm_write.g4b.gen5"
};

static const uint32_t ps_kernel_maskca_projective_static_gen5[][4] = {
#include "exa_wm_xy.g4b.gen5"
#include "exa_wm_src_projective.g4b.gen5"
#include "exa_wm_src_sample_argb.g4b.gen5"
#include "exa_wm_mask_projective.g4b.gen5"
#include "exa_wm_mask_sample_argb.g4b.gen5"
#include "exa_wm_ca.g4b.gen5"
#include "exa_wm_write.g4b.gen5"
};

static const uint32_t ps_kernel_maskca_srcalpha_affine_static_gen5[][4] = {
#include "exa_wm_xy.g4b.gen5"
#include "exa_wm_src_affine.g4b.gen5"
#include "exa_wm_src_sample_a.g4b.gen5"
#include "exa_wm_mask_affine.g4b.gen5"
#include "exa_wm_mask_sample_argb.g4b.gen5"
#include "exa_wm_ca_srcalpha.g4b.gen5"
#include "exa_wm_write.g4b.gen5"
};

static const uint32_t ps_kernel_maskca_srcalpha_projective_static_gen5[][4] = {
#include "exa_wm_xy.g4b.gen5"
#include "exa_wm_src_projective.g4b.gen5"
#include "exa_wm_src_sample_a.g4b.gen5"
#include "exa_wm_mask_projective.g4b.gen5"
#include "exa_wm_mask_sample_argb.g4b.gen5"
#include "exa_wm_ca_srcalpha.g4b.gen5"
#include "exa_wm_write.g4b.gen5"
};

static const uint32_t ps_kernel_masknoca_affine_static_gen5[][4] = {
#include "exa_wm_xy.g4b.gen5"
#include "exa_wm_src_affine.g4b.gen5"
#include "exa_wm_src_sample_argb.g4b.gen5"
#include "exa_wm_mask_affine.g4b.gen5"
#include "exa_wm_mask_sample_a.g4b.gen5"
#include "exa_wm_noca.g4b.gen5"
#include "exa_wm_write.g4b.gen5"
};

static const uint32_t ps_kernel_masknoca_projective_static_gen5[][4] = {
#include "exa_wm_xy.g4b.gen5"
#include "exa_wm_src_projective.g4b.gen5"
#include "exa_wm_src_sample_argb.g4b.gen5"
#include "exa_wm_mask_projective.g4b.gen5"
#include "exa_wm_mask_sample_a.g4b.gen5"
#include "exa_wm_noca.g4b.gen5"
#include "exa_wm_write.g4b.gen5"
};

/* programs for GEN6 */
static const uint32_t ps_kernel_nomask_affine_static_gen6[][4] = {
#include "exa_wm_src_affine.g6b"
#include "exa_wm_src_sample_argb.g6b"
#include "exa_wm_write.g6b"
};

static const uint32_t ps_kernel_nomask_projective_static_gen6[][4] = {
#include "exa_wm_src_projective.g6b"
#include "exa_wm_src_sample_argb.g6b"
#include "exa_wm_write.g6b"
};

static const uint32_t ps_kernel_maskca_affine_static_gen6[][4] = {
#include "exa_wm_src_affine.g6b"
#include "exa_wm_src_sample_argb.g6b"
#include "exa_wm_mask_affine.g6b"
#include "exa_wm_mask_sample_argb.g6b"
#include "exa_wm_ca.g6b"
#include "exa_wm_write.g6b"
};

static const uint32_t ps_kernel_maskca_projective_static_gen6[][4] = {
#include "exa_wm_src_projective.g6b"
#include "exa_wm_src_sample_argb.g6b"
#include "exa_wm_mask_projective.g6b"
#include "exa_wm_mask_sample_argb.g6b"
#include "exa_wm_ca.g4b.gen5"
#include "exa_wm_write.g6b"
};

static const uint32_t ps_kernel_maskca_srcalpha_affine_static_gen6[][4] = {
#include "exa_wm_src_affine.g6b"
#include "exa_wm_src_sample_a.g6b"
#include "exa_wm_mask_affine.g6b"
#include "exa_wm_mask_sample_argb.g6b"
#include "exa_wm_ca_srcalpha.g6b"
#include "exa_wm_write.g6b"
};

static const uint32_t ps_kernel_maskca_srcalpha_projective_static_gen6[][4] = {
#include "exa_wm_src_projective.g6b"
#include "exa_wm_src_sample_a.g6b"
#include "exa_wm_mask_projective.g6b"
#include "exa_wm_mask_sample_argb.g6b"
#include "exa_wm_ca_srcalpha.g6b"
#include "exa_wm_write.g6b"
};

static const uint32_t ps_kernel_masknoca_affine_static_gen6[][4] = {
#include "exa_wm_src_affine.g6b"
#include "exa_wm_src_sample_argb.g6b"
#include "exa_wm_mask_affine.g6b"
#include "exa_wm_mask_sample_a.g6b"
#include "exa_wm_noca.g6b"
#include "exa_wm_write.g6b"
};

static const uint32_t ps_kernel_masknoca_projective_static_gen6[][4] = {
#include "exa_wm_src_projective.g6b"
#include "exa_wm_src_sample_argb.g6b"
#include "exa_wm_mask_projective.g6b"
#include "exa_wm_mask_sample_a.g6b"
#include "exa_wm_noca.g6b"
#include "exa_wm_write.g6b"
};

/* programs for GEN7 */
static const uint32_t ps_kernel_nomask_affine_static_gen7[][4] = {
#include "exa_wm_src_affine.g7b"
#include "exa_wm_src_sample_argb.g7b"
#include "exa_wm_write.g7b"
};

static const uint32_t ps_kernel_nomask_projective_static_gen7[][4] = {
#include "exa_wm_src_projective.g7b"
#include "exa_wm_src_sample_argb.g7b"
#include "exa_wm_write.g7b"
};

static const uint32_t ps_kernel_maskca_affine_static_gen7[][4] = {
#include "exa_wm_src_affine.g7b"
#include "exa_wm_src_sample_argb.g7b"
#include "exa_wm_mask_affine.g7b"
#include "exa_wm_mask_sample_argb.g7b"
#include "exa_wm_ca.g6b"
#include "exa_wm_write.g7b"
};

static const uint32_t ps_kernel_maskca_projective_static_gen7[][4] = {
#include "exa_wm_src_projective.g7b"
#include "exa_wm_src_sample_argb.g7b"
#include "exa_wm_mask_projective.g7b"
#include "exa_wm_mask_sample_argb.g7b"
#include "exa_wm_ca.g4b.gen5"
#include "exa_wm_write.g7b"
};

static const uint32_t ps_kernel_maskca_srcalpha_affine_static_gen7[][4] = {
#include "exa_wm_src_affine.g7b"
#include "exa_wm_src_sample_a.g7b"
#include "exa_wm_mask_affine.g7b"
#include "exa_wm_mask_sample_argb.g7b"
#include "exa_wm_ca_srcalpha.g6b"
#include "exa_wm_write.g7b"
};

static const uint32_t ps_kernel_maskca_srcalpha_projective_static_gen7[][4] = {
#include "exa_wm_src_projective.g7b"
#include "exa_wm_src_sample_a.g7b"
#include "exa_wm_mask_projective.g7b"
#include "exa_wm_mask_sample_argb.g7b"
#include "exa_wm_ca_srcalpha.g6b"
#include "exa_wm_write.g7b"
};

static const uint32_t ps_kernel_masknoca_affine_static_gen7[][4] = {
#include "exa_wm_src_affine.g7b"
#include "exa_wm_src_sample_argb.g7b"
#include "exa_wm_mask_affine.g7b"
#include "exa_wm_mask_sample_a.g7b"
#include "exa_wm_noca.g6b"
#include "exa_wm_write.g7b"
};

static const uint32_t ps_kernel_masknoca_projective_static_gen7[][4] = {
#include "exa_wm_src_projective.g7b"
#include "exa_wm_src_sample_argb.g7b"
#include "exa_wm_mask_projective.g7b"
#include "exa_wm_mask_sample_a.g7b"
#include "exa_wm_noca.g6b"
#include "exa_wm_write.g7b"
};


typedef enum {
	SS_INVALID_FILTER = -1,
	SS_FILTER_NEAREST,
	SS_FILTER_BILINEAR,
	FILTER_COUNT,
} sampler_state_filter_t;

typedef enum {
	SS_INVALID_EXTEND = -1,
	SS_EXTEND_NONE,
	SS_EXTEND_REPEAT,
	SS_EXTEND_PAD,
	SS_EXTEND_REFLECT,
	EXTEND_COUNT,
} sampler_state_extend_t;

typedef enum {
	WM_KERNEL_NOMASK_AFFINE,
	WM_KERNEL_NOMASK_PROJECTIVE,
	WM_KERNEL_MASKCA_AFFINE,
	WM_KERNEL_MASKCA_PROJECTIVE,
	WM_KERNEL_MASKCA_SRCALPHA_AFFINE,
	WM_KERNEL_MASKCA_SRCALPHA_PROJECTIVE,
	WM_KERNEL_MASKNOCA_AFFINE,
	WM_KERNEL_MASKNOCA_PROJECTIVE,
	KERNEL_COUNT
} wm_kernel_t;

#define KERNEL(kernel_enum, kernel, masked) \
    [kernel_enum] = {&kernel, sizeof(kernel), masked}
struct wm_kernel_info {
	const void *data;
	unsigned int size;
	Bool has_mask;
};

static const struct wm_kernel_info wm_kernels_gen4[] = {
	KERNEL(WM_KERNEL_NOMASK_AFFINE,
	       ps_kernel_nomask_affine_static, FALSE),
	KERNEL(WM_KERNEL_NOMASK_PROJECTIVE,
	       ps_kernel_nomask_projective_static, FALSE),
	KERNEL(WM_KERNEL_MASKCA_AFFINE,
	       ps_kernel_maskca_affine_static, TRUE),
	KERNEL(WM_KERNEL_MASKCA_PROJECTIVE,
	       ps_kernel_maskca_projective_static, TRUE),
	KERNEL(WM_KERNEL_MASKCA_SRCALPHA_AFFINE,
	       ps_kernel_maskca_srcalpha_affine_static, TRUE),
	KERNEL(WM_KERNEL_MASKCA_SRCALPHA_PROJECTIVE,
	       ps_kernel_maskca_srcalpha_projective_static, TRUE),
	KERNEL(WM_KERNEL_MASKNOCA_AFFINE,
	       ps_kernel_masknoca_affine_static, TRUE),
	KERNEL(WM_KERNEL_MASKNOCA_PROJECTIVE,
	       ps_kernel_masknoca_projective_static, TRUE),
};

static const struct wm_kernel_info wm_kernels_gen5[] = {
	KERNEL(WM_KERNEL_NOMASK_AFFINE,
	       ps_kernel_nomask_affine_static_gen5, FALSE),
	KERNEL(WM_KERNEL_NOMASK_PROJECTIVE,
	       ps_kernel_nomask_projective_static_gen5, FALSE),
	KERNEL(WM_KERNEL_MASKCA_AFFINE,
	       ps_kernel_maskca_affine_static_gen5, TRUE),
	KERNEL(WM_KERNEL_MASKCA_PROJECTIVE,
	       ps_kernel_maskca_projective_static_gen5, TRUE),
	KERNEL(WM_KERNEL_MASKCA_SRCALPHA_AFFINE,
	       ps_kernel_maskca_srcalpha_affine_static_gen5, TRUE),
	KERNEL(WM_KERNEL_MASKCA_SRCALPHA_PROJECTIVE,
	       ps_kernel_maskca_srcalpha_projective_static_gen5, TRUE),
	KERNEL(WM_KERNEL_MASKNOCA_AFFINE,
	       ps_kernel_masknoca_affine_static_gen5, TRUE),
	KERNEL(WM_KERNEL_MASKNOCA_PROJECTIVE,
	       ps_kernel_masknoca_projective_static_gen5, TRUE),
};

static const struct wm_kernel_info wm_kernels_gen6[] = {
	KERNEL(WM_KERNEL_NOMASK_AFFINE,
	       ps_kernel_nomask_affine_static_gen6, FALSE),
	KERNEL(WM_KERNEL_NOMASK_PROJECTIVE,
	       ps_kernel_nomask_projective_static_gen6, FALSE),
	KERNEL(WM_KERNEL_MASKCA_AFFINE,
	       ps_kernel_maskca_affine_static_gen6, TRUE),
	KERNEL(WM_KERNEL_MASKCA_PROJECTIVE,
	       ps_kernel_maskca_projective_static_gen6, TRUE),
	KERNEL(WM_KERNEL_MASKCA_SRCALPHA_AFFINE,
	       ps_kernel_maskca_srcalpha_affine_static_gen6, TRUE),
	KERNEL(WM_KERNEL_MASKCA_SRCALPHA_PROJECTIVE,
	       ps_kernel_maskca_srcalpha_projective_static_gen6, TRUE),
	KERNEL(WM_KERNEL_MASKNOCA_AFFINE,
	       ps_kernel_masknoca_affine_static_gen6, TRUE),
	KERNEL(WM_KERNEL_MASKNOCA_PROJECTIVE,
	       ps_kernel_masknoca_projective_static_gen6, TRUE),
};

static const struct wm_kernel_info wm_kernels_gen7[] = {
	KERNEL(WM_KERNEL_NOMASK_AFFINE,
	       ps_kernel_nomask_affine_static_gen7, FALSE),
	KERNEL(WM_KERNEL_NOMASK_PROJECTIVE,
	       ps_kernel_nomask_projective_static_gen7, FALSE),
	KERNEL(WM_KERNEL_MASKCA_AFFINE,
	       ps_kernel_maskca_affine_static_gen7, TRUE),
	KERNEL(WM_KERNEL_MASKCA_PROJECTIVE,
	       ps_kernel_maskca_projective_static_gen7, TRUE),
	KERNEL(WM_KERNEL_MASKCA_SRCALPHA_AFFINE,
	       ps_kernel_maskca_srcalpha_affine_static_gen7, TRUE),
	KERNEL(WM_KERNEL_MASKCA_SRCALPHA_PROJECTIVE,
	       ps_kernel_maskca_srcalpha_projective_static_gen7, TRUE),
	KERNEL(WM_KERNEL_MASKNOCA_AFFINE,
	       ps_kernel_masknoca_affine_static_gen7, TRUE),
	KERNEL(WM_KERNEL_MASKNOCA_PROJECTIVE,
	       ps_kernel_masknoca_projective_static_gen7, TRUE),
};

#undef KERNEL

typedef struct _brw_cc_unit_state_padded {
	struct brw_cc_unit_state state;
	char pad[64 - sizeof(struct brw_cc_unit_state)];
} brw_cc_unit_state_padded;

#ifndef MAX
#define MAX(a, b) ((a) > (b) ? (a) : (b))
#endif
#define SURFACE_STATE_PADDED_SIZE ALIGN(MAX(sizeof(struct brw_surface_state), sizeof(struct gen7_surface_state)), 32)

struct gen4_cc_unit_state {
	/* Index by [src_blend][dst_blend] */
	brw_cc_unit_state_padded cc_state[BRW_BLENDFACTOR_COUNT][BRW_BLENDFACTOR_COUNT];
};

typedef struct gen4_composite_op {
	int op;
	sampler_state_filter_t src_filter;
	sampler_state_filter_t mask_filter;
	sampler_state_extend_t src_extend;
	sampler_state_extend_t mask_extend;
	Bool is_affine;
	wm_kernel_t wm_kernel;
	int vertex_id;
} gen4_composite_op;

/** Private data for gen4 render accel implementation. */
struct gen4_render_state {
	drm_intel_bo *vs_state_bo;
	drm_intel_bo *sf_state_bo;
	drm_intel_bo *sf_mask_state_bo;
	drm_intel_bo *cc_state_bo;
	drm_intel_bo *wm_state_bo[KERNEL_COUNT]
	    [FILTER_COUNT] [EXTEND_COUNT]
	    [FILTER_COUNT] [EXTEND_COUNT];
	drm_intel_bo *wm_kernel_bo[KERNEL_COUNT];

	drm_intel_bo *cc_vp_bo;
	drm_intel_bo *gen6_blend_bo;
	drm_intel_bo *gen6_depth_stencil_bo;
	drm_intel_bo *ps_sampler_state_bo[FILTER_COUNT]
	    [EXTEND_COUNT]
	    [FILTER_COUNT]
	    [EXTEND_COUNT];
	gen4_composite_op composite_op;
};

static void gen6_emit_composite_state(struct intel_screen_private *intel);
static void gen6_render_state_init(ScrnInfoPtr scrn);

/**
 * Sets up the SF state pointing at an SF kernel.
 *
 * The SF kernel does coord interp: for each attribute,
 * calculate dA/dx and dA/dy.  Hand these interpolation coefficients
 * back to SF which then hands pixels off to WM.
 */
static drm_intel_bo *gen4_create_sf_state(intel_screen_private *intel,
					  drm_intel_bo * kernel_bo)
{
	struct brw_sf_unit_state *sf_state;
	drm_intel_bo *sf_state_bo;
	int ret;

	sf_state_bo = drm_intel_bo_alloc(intel->bufmgr, "gen4 SF state",
					 sizeof(*sf_state), 4096);
	assert(sf_state_bo);

	ret = drm_intel_bo_map(sf_state_bo, TRUE);
	assert(ret == 0);

	sf_state = memset(sf_state_bo->virtual, 0, sizeof(*sf_state));
	sf_state->thread0.grf_reg_count = BRW_GRF_BLOCKS(SF_KERNEL_NUM_GRF);
	sf_state->thread0.kernel_start_pointer =
	    intel_emit_reloc(sf_state_bo,
			     offsetof(struct brw_sf_unit_state, thread0),
			     kernel_bo, sf_state->thread0.grf_reg_count << 1,
			     I915_GEM_DOMAIN_INSTRUCTION, 0) >> 6;
	sf_state->sf1.single_program_flow = 1;
	sf_state->sf1.binding_table_entry_count = 0;
	sf_state->sf1.thread_priority = 0;
	sf_state->sf1.floating_point_mode = 0;	/* Mesa does this */
	sf_state->sf1.illegal_op_exception_enable = 1;
	sf_state->sf1.mask_stack_exception_enable = 1;
	sf_state->sf1.sw_exception_enable = 1;
	sf_state->thread2.per_thread_scratch_space = 0;
	/* scratch space is not used in our kernel */
	sf_state->thread2.scratch_space_base_pointer = 0;
	sf_state->thread3.const_urb_entry_read_length = 0;	/* no const URBs */
	sf_state->thread3.const_urb_entry_read_offset = 0;	/* no const URBs */
	sf_state->thread3.urb_entry_read_length = 1;	/* 1 URB per vertex */
	/* don't smash vertex header, read start from dw8 */
	sf_state->thread3.urb_entry_read_offset = 1;
	sf_state->thread3.dispatch_grf_start_reg = 3;
	sf_state->thread4.max_threads = SF_MAX_THREADS - 1;
	sf_state->thread4.urb_entry_allocation_size = URB_SF_ENTRY_SIZE - 1;
	sf_state->thread4.nr_urb_entries = URB_SF_ENTRIES;
	sf_state->sf5.viewport_transform = FALSE;	/* skip viewport */
	sf_state->sf6.cull_mode = BRW_CULLMODE_NONE;
	sf_state->sf6.scissor = 0;
	sf_state->sf7.trifan_pv = 2;
	sf_state->sf6.dest_org_vbias = 0x8;
	sf_state->sf6.dest_org_hbias = 0x8;

	drm_intel_bo_unmap(sf_state_bo);

	return sf_state_bo;
	(void)ret;
}

static drm_intel_bo *sampler_border_color_create(intel_screen_private *intel)
{
	struct brw_sampler_legacy_border_color sampler_border_color;

	/* Set up the sampler border color (always transparent black) */
	memset(&sampler_border_color, 0, sizeof(sampler_border_color));
	sampler_border_color.color[0] = 0;	/* R */
	sampler_border_color.color[1] = 0;	/* G */
	sampler_border_color.color[2] = 0;	/* B */
	sampler_border_color.color[3] = 0;	/* A */

	return intel_bo_alloc_for_data(intel,
				       &sampler_border_color,
				       sizeof(sampler_border_color),
				       "gen4 render sampler border color");
}

static void
gen4_sampler_state_init(drm_intel_bo * sampler_state_bo,
		   struct brw_sampler_state *sampler_state,
		   sampler_state_filter_t filter,
		   sampler_state_extend_t extend,
		   drm_intel_bo * border_color_bo)
{
	uint32_t sampler_state_offset;

	sampler_state_offset = (char *)sampler_state -
	    (char *)sampler_state_bo->virtual;

	/* PS kernel use this sampler */
	memset(sampler_state, 0, sizeof(*sampler_state));

	sampler_state->ss0.lod_preclamp = 1;	/* GL mode */

	/* We use the legacy mode to get the semantics specified by
	 * the Render extension. */
	sampler_state->ss0.border_color_mode = BRW_BORDER_COLOR_MODE_LEGACY;

	switch (filter) {
	default:
	case SS_FILTER_NEAREST:
		sampler_state->ss0.min_filter = BRW_MAPFILTER_NEAREST;
		sampler_state->ss0.mag_filter = BRW_MAPFILTER_NEAREST;
		break;
	case SS_FILTER_BILINEAR:
		sampler_state->ss0.min_filter = BRW_MAPFILTER_LINEAR;
		sampler_state->ss0.mag_filter = BRW_MAPFILTER_LINEAR;
		break;
	}

	switch (extend) {
	default:
	case SS_EXTEND_NONE:
		sampler_state->ss1.r_wrap_mode = BRW_TEXCOORDMODE_CLAMP_BORDER;
		sampler_state->ss1.s_wrap_mode = BRW_TEXCOORDMODE_CLAMP_BORDER;
		sampler_state->ss1.t_wrap_mode = BRW_TEXCOORDMODE_CLAMP_BORDER;
		break;
	case SS_EXTEND_REPEAT:
		sampler_state->ss1.r_wrap_mode = BRW_TEXCOORDMODE_WRAP;
		sampler_state->ss1.s_wrap_mode = BRW_TEXCOORDMODE_WRAP;
		sampler_state->ss1.t_wrap_mode = BRW_TEXCOORDMODE_WRAP;
		break;
	case SS_EXTEND_PAD:
		sampler_state->ss1.r_wrap_mode = BRW_TEXCOORDMODE_CLAMP;
		sampler_state->ss1.s_wrap_mode = BRW_TEXCOORDMODE_CLAMP;
		sampler_state->ss1.t_wrap_mode = BRW_TEXCOORDMODE_CLAMP;
		break;
	case SS_EXTEND_REFLECT:
		sampler_state->ss1.r_wrap_mode = BRW_TEXCOORDMODE_MIRROR;
		sampler_state->ss1.s_wrap_mode = BRW_TEXCOORDMODE_MIRROR;
		sampler_state->ss1.t_wrap_mode = BRW_TEXCOORDMODE_MIRROR;
		break;
	}

	sampler_state->ss2.border_color_pointer =
	    intel_emit_reloc(sampler_state_bo, sampler_state_offset +
			     offsetof(struct brw_sampler_state, ss2),
			     border_color_bo, 0,
			     I915_GEM_DOMAIN_SAMPLER, 0) >> 5;

	sampler_state->ss3.chroma_key_enable = 0;	/* disable chromakey */
}

static void
gen7_sampler_state_init(drm_intel_bo * sampler_state_bo,
		   struct gen7_sampler_state *sampler_state,
		   sampler_state_filter_t filter,
		   sampler_state_extend_t extend,
		   drm_intel_bo * border_color_bo)
{
	uint32_t sampler_state_offset;

	sampler_state_offset = (char *)sampler_state -
	    (char *)sampler_state_bo->virtual;

	/* PS kernel use this sampler */
	memset(sampler_state, 0, sizeof(*sampler_state));

	sampler_state->ss0.lod_preclamp = 1;	/* GL mode */

	/* We use the legacy mode to get the semantics specified by
	 * the Render extension. */
	sampler_state->ss0.default_color_mode = BRW_BORDER_COLOR_MODE_LEGACY;

	switch (filter) {
	default:
	case SS_FILTER_NEAREST:
		sampler_state->ss0.min_filter = BRW_MAPFILTER_NEAREST;
		sampler_state->ss0.mag_filter = BRW_MAPFILTER_NEAREST;
		break;
	case SS_FILTER_BILINEAR:
		sampler_state->ss0.min_filter = BRW_MAPFILTER_LINEAR;
		sampler_state->ss0.mag_filter = BRW_MAPFILTER_LINEAR;
		break;
	}

	switch (extend) {
	default:
	case SS_EXTEND_NONE:
		sampler_state->ss3.r_wrap_mode = BRW_TEXCOORDMODE_CLAMP_BORDER;
		sampler_state->ss3.s_wrap_mode = BRW_TEXCOORDMODE_CLAMP_BORDER;
		sampler_state->ss3.t_wrap_mode = BRW_TEXCOORDMODE_CLAMP_BORDER;
		break;
	case SS_EXTEND_REPEAT:
		sampler_state->ss3.r_wrap_mode = BRW_TEXCOORDMODE_WRAP;
		sampler_state->ss3.s_wrap_mode = BRW_TEXCOORDMODE_WRAP;
		sampler_state->ss3.t_wrap_mode = BRW_TEXCOORDMODE_WRAP;
		break;
	case SS_EXTEND_PAD:
		sampler_state->ss3.r_wrap_mode = BRW_TEXCOORDMODE_CLAMP;
		sampler_state->ss3.s_wrap_mode = BRW_TEXCOORDMODE_CLAMP;
		sampler_state->ss3.t_wrap_mode = BRW_TEXCOORDMODE_CLAMP;
		break;
	case SS_EXTEND_REFLECT:
		sampler_state->ss3.r_wrap_mode = BRW_TEXCOORDMODE_MIRROR;
		sampler_state->ss3.s_wrap_mode = BRW_TEXCOORDMODE_MIRROR;
		sampler_state->ss3.t_wrap_mode = BRW_TEXCOORDMODE_MIRROR;
		break;
	}

	sampler_state->ss2.default_color_pointer =
	    intel_emit_reloc(sampler_state_bo, sampler_state_offset +
			     offsetof(struct gen7_sampler_state, ss2),
			     border_color_bo, 0,
			     I915_GEM_DOMAIN_SAMPLER, 0) >> 5;

	sampler_state->ss3.chroma_key_enable = 0;	/* disable chromakey */
}



static drm_intel_bo *gen4_create_sampler_state(intel_screen_private *intel,
					       sampler_state_filter_t src_filter,
					       sampler_state_extend_t src_extend,
					       sampler_state_filter_t mask_filter,
					       sampler_state_extend_t mask_extend,
					       drm_intel_bo * border_color_bo)
{
	drm_intel_bo *sampler_state_bo;
	struct brw_sampler_state *sampler_state;
	int ret;

	sampler_state_bo =
	    drm_intel_bo_alloc(intel->bufmgr, "gen4 sampler state",
			       sizeof(struct brw_sampler_state) * 2, 4096);
	assert(sampler_state_bo);

	ret = drm_intel_bo_map(sampler_state_bo, TRUE);
	assert(ret == 0);

	sampler_state = sampler_state_bo->virtual;

	gen4_sampler_state_init(sampler_state_bo,
				&sampler_state[0],
				src_filter, src_extend, border_color_bo);
	gen4_sampler_state_init(sampler_state_bo,
				&sampler_state[1],
				mask_filter, mask_extend, border_color_bo);

	drm_intel_bo_unmap(sampler_state_bo);

	return sampler_state_bo;
	(void)ret;
}

static drm_intel_bo *
gen7_create_sampler_state(intel_screen_private *intel,
			  sampler_state_filter_t src_filter,
			  sampler_state_extend_t src_extend,
			  sampler_state_filter_t mask_filter,
			  sampler_state_extend_t mask_extend,
			  drm_intel_bo * border_color_bo)
{
	drm_intel_bo *sampler_state_bo;
	struct gen7_sampler_state *sampler_state;
	int ret;

	sampler_state_bo =
	    drm_intel_bo_alloc(intel->bufmgr, "gen7 sampler state",
			       sizeof(struct gen7_sampler_state) * 2, 4096);
	assert(sampler_state_bo);

	ret = drm_intel_bo_map(sampler_state_bo, TRUE);
	assert(ret == 0);

	sampler_state = sampler_state_bo->virtual;

	gen7_sampler_state_init(sampler_state_bo,
				&sampler_state[0],
				src_filter, src_extend, border_color_bo);
	gen7_sampler_state_init(sampler_state_bo,
				&sampler_state[1],
				mask_filter, mask_extend, border_color_bo);

	drm_intel_bo_unmap(sampler_state_bo);

	return sampler_state_bo;
	(void)ret;
}

static inline drm_intel_bo *
i965_create_sampler_state(intel_screen_private *intel,
			  sampler_state_filter_t src_filter,
			  sampler_state_extend_t src_extend,
			  sampler_state_filter_t mask_filter,
			  sampler_state_extend_t mask_extend,
			  drm_intel_bo * border_color_bo)
{
	if (INTEL_INFO(intel)->gen < 070)
		return gen4_create_sampler_state(intel, src_filter, src_extend,
						 mask_filter, mask_extend,
						 border_color_bo);
	return gen7_create_sampler_state(intel, src_filter, src_extend,
					 mask_filter, mask_extend,
					 border_color_bo);
}


static void
cc_state_init(drm_intel_bo * cc_state_bo,
	      uint32_t cc_state_offset,
	      int src_blend, int dst_blend, drm_intel_bo * cc_vp_bo)
{
	struct brw_cc_unit_state *cc_state;

	cc_state = (struct brw_cc_unit_state *)((char *)cc_state_bo->virtual +
						cc_state_offset);

	memset(cc_state, 0, sizeof(*cc_state));
	cc_state->cc0.stencil_enable = 0;	/* disable stencil */
	cc_state->cc2.depth_test = 0;	/* disable depth test */
	cc_state->cc2.logicop_enable = 0;	/* disable logic op */
	cc_state->cc3.ia_blend_enable = 0;	/* blend alpha same as colors */
	cc_state->cc3.blend_enable = 1;	/* enable color blend */
	cc_state->cc3.alpha_test = 0;	/* disable alpha test */

	cc_state->cc4.cc_viewport_state_offset =
	    intel_emit_reloc(cc_state_bo, cc_state_offset +
			     offsetof(struct brw_cc_unit_state, cc4),
			     cc_vp_bo, 0, I915_GEM_DOMAIN_INSTRUCTION, 0) >> 5;

	cc_state->cc5.dither_enable = 0;	/* disable dither */
	cc_state->cc5.logicop_func = 0xc;	/* COPY */
	cc_state->cc5.statistics_enable = 1;
	cc_state->cc5.ia_blend_function = BRW_BLENDFUNCTION_ADD;

	/* Fill in alpha blend factors same as color, for the future. */
	cc_state->cc5.ia_src_blend_factor = src_blend;
	cc_state->cc5.ia_dest_blend_factor = dst_blend;

	cc_state->cc6.blend_function = BRW_BLENDFUNCTION_ADD;
	cc_state->cc6.clamp_post_alpha_blend = 1;
	cc_state->cc6.clamp_pre_alpha_blend = 1;
	cc_state->cc6.clamp_range = 0;	/* clamp range [0,1] */

	cc_state->cc6.src_blend_factor = src_blend;
	cc_state->cc6.dest_blend_factor = dst_blend;
}

static drm_intel_bo *gen4_create_wm_state(intel_screen_private *intel,
					  Bool has_mask,
					  drm_intel_bo * kernel_bo,
					  drm_intel_bo * sampler_bo)
{
	struct brw_wm_unit_state *state;
	drm_intel_bo *wm_state_bo;
	int ret;

	wm_state_bo = drm_intel_bo_alloc(intel->bufmgr, "gen4 WM state",
					 sizeof(*state), 4096);
	assert(wm_state_bo);

	ret = drm_intel_bo_map(wm_state_bo, TRUE);
	assert(ret == 0);

	state = memset(wm_state_bo->virtual, 0, sizeof(*state));
	state->thread0.grf_reg_count = BRW_GRF_BLOCKS(PS_KERNEL_NUM_GRF);
	state->thread0.kernel_start_pointer =
	    intel_emit_reloc(wm_state_bo,
			     offsetof(struct brw_wm_unit_state, thread0),
			     kernel_bo, state->thread0.grf_reg_count << 1,
			     I915_GEM_DOMAIN_INSTRUCTION, 0) >> 6;

	state->thread1.single_program_flow = 0;

	/* scratch space is not used in our kernel */
	state->thread2.scratch_space_base_pointer = 0;
	state->thread2.per_thread_scratch_space = 0;

	state->thread3.const_urb_entry_read_length = 0;
	state->thread3.const_urb_entry_read_offset = 0;

	state->thread3.urb_entry_read_offset = 0;
	/* wm kernel use urb from 3, see wm_program in compiler module */
	state->thread3.dispatch_grf_start_reg = 3;	/* must match kernel */

	if (IS_GEN5(intel))
		state->wm4.sampler_count = 0;	/* hardware requirement */
	else
		state->wm4.sampler_count = 1;	/* 1-4 samplers used */

	state->wm4.sampler_state_pointer =
	    intel_emit_reloc(wm_state_bo,
			     offsetof(struct brw_wm_unit_state, wm4),
			     sampler_bo,
			     state->wm4.sampler_count << 2,
			     I915_GEM_DOMAIN_INSTRUCTION, 0) >> 5;
	state->wm5.max_threads = PS_MAX_THREADS - 1;
	state->wm5.transposed_urb_read = 0;
	state->wm5.thread_dispatch_enable = 1;
	/* just use 16-pixel dispatch (4 subspans), don't need to change kernel
	 * start point
	 */
	state->wm5.enable_16_pix = 1;
	state->wm5.enable_8_pix = 0;
	state->wm5.early_depth_test = 1;

	/* Each pair of attributes (src/mask coords) is two URB entries */
	if (has_mask) {
		state->thread1.binding_table_entry_count = 3;	/* 2 tex and fb */
		state->thread3.urb_entry_read_length = 4;
	} else {
		state->thread1.binding_table_entry_count = 2;	/* 1 tex and fb */
		state->thread3.urb_entry_read_length = 2;
	}

	/* binding table entry count is only used for prefetching, and it has to
	 * be set 0 for Ironlake
	 */
	if (IS_GEN5(intel))
		state->thread1.binding_table_entry_count = 0;

	drm_intel_bo_unmap(wm_state_bo);

	return wm_state_bo;
	(void)ret;
}

static drm_intel_bo *gen4_create_cc_viewport(intel_screen_private *intel)
{
	drm_intel_bo *bo;
	struct brw_cc_viewport vp;
	int ret;

	vp.min_depth = -1.e35;
	vp.max_depth = 1.e35;

	bo = drm_intel_bo_alloc(intel->bufmgr, "gen4 render unit state",
				sizeof(vp), 4096);
	assert(bo);

	ret = drm_intel_bo_subdata(bo, 0, sizeof(vp), &vp);
	assert(ret == 0);

	return bo;
	(void)ret;
}

static drm_intel_bo *gen4_create_vs_unit_state(intel_screen_private *intel)
{
	struct brw_vs_unit_state vs_state;
	memset(&vs_state, 0, sizeof(vs_state));

	/* Set up the vertex shader to be disabled (passthrough) */
	if (IS_GEN5(intel))
		vs_state.thread4.nr_urb_entries = URB_VS_ENTRIES >> 2;	/* hardware requirement */
	else
		vs_state.thread4.nr_urb_entries = URB_VS_ENTRIES;
	vs_state.thread4.urb_entry_allocation_size = URB_VS_ENTRY_SIZE - 1;
	vs_state.vs6.vs_enable = 0;
	vs_state.vs6.vert_cache_disable = 1;

	return intel_bo_alloc_for_data(intel, &vs_state, sizeof(vs_state),
				       "gen4 render VS state");
}

/**
 * Set up all combinations of cc state: each blendfactor for source and
 * dest.
 */
static drm_intel_bo *gen4_create_cc_unit_state(intel_screen_private *intel)
{
	drm_intel_bo *cc_state_bo, *cc_vp_bo;
	int i, j, ret;

	cc_vp_bo = gen4_create_cc_viewport(intel);

	cc_state_bo = drm_intel_bo_alloc(intel->bufmgr, "gen4 CC state",
					 sizeof(struct gen4_cc_unit_state),
					 4096);
	assert(cc_state_bo);

	ret = drm_intel_bo_map(cc_state_bo, TRUE);
	assert(ret == 0);

	for (i = 0; i < BRW_BLENDFACTOR_COUNT; i++) {
		for (j = 0; j < BRW_BLENDFACTOR_COUNT; j++) {
			cc_state_init(cc_state_bo,
				      offsetof(struct gen4_cc_unit_state,
					       cc_state[i][j].state),
				      i, j, cc_vp_bo);
		}
	}
	drm_intel_bo_unmap(cc_state_bo);

	drm_intel_bo_unreference(cc_vp_bo);

	return cc_state_bo;
	(void)ret;
}

static uint32_t i965_get_card_format(PicturePtr picture)
{
	int i;

	for (i = 0; i < sizeof(i965_tex_formats) / sizeof(i965_tex_formats[0]);
	     i++) {
		if (i965_tex_formats[i].fmt == picture->format)
			break;
	}
	assert(i != sizeof(i965_tex_formats) / sizeof(i965_tex_formats[0]));

	return i965_tex_formats[i].card_fmt;
}

static sampler_state_filter_t sampler_state_filter_from_picture(int filter)
{
	switch (filter) {
	case PictFilterNearest:
		return SS_FILTER_NEAREST;
	case PictFilterBilinear:
		return SS_FILTER_BILINEAR;
	default:
		return SS_INVALID_FILTER;
	}
}

static sampler_state_extend_t sampler_state_extend_from_picture(int repeat_type)
{
	switch (repeat_type) {
	case RepeatNone:
		return SS_EXTEND_NONE;
	case RepeatNormal:
		return SS_EXTEND_REPEAT;
	case RepeatPad:
		return SS_EXTEND_PAD;
	case RepeatReflect:
		return SS_EXTEND_REFLECT;
	default:
		return SS_INVALID_EXTEND;
	}
}

/**
 * Sets up the common fields for a surface state buffer for the given
 * picture in the given surface state buffer.
 */
static int
gen4_set_picture_surface_state(intel_screen_private *intel,
			       PicturePtr picture, PixmapPtr pixmap,
			       Bool is_dst)
{
	struct intel_pixmap *priv = intel_get_pixmap_private(pixmap);
	struct brw_surface_state *ss;
	uint32_t write_domain, read_domains;
	int offset;

	if (is_dst) {
		write_domain = I915_GEM_DOMAIN_RENDER;
		read_domains = I915_GEM_DOMAIN_RENDER;
	} else {
		write_domain = 0;
		read_domains = I915_GEM_DOMAIN_SAMPLER;
	}
	intel_batch_mark_pixmap_domains(intel, priv,
					read_domains, write_domain);
	ss = (struct brw_surface_state *)
		(intel->surface_data + intel->surface_used);

	memset(ss, 0, sizeof(*ss));
	ss->ss0.surface_type = BRW_SURFACE_2D;
	if (is_dst)
		ss->ss0.surface_format = i965_get_dest_format(picture);
	else
		ss->ss0.surface_format = i965_get_card_format(picture);

	ss->ss0.data_return_format = BRW_SURFACERETURNFORMAT_FLOAT32;
	ss->ss0.color_blend = 1;
	ss->ss1.base_addr = priv->bo->offset;

	ss->ss2.height = pixmap->drawable.height - 1;
	ss->ss2.width = pixmap->drawable.width - 1;
	ss->ss3.pitch = intel_pixmap_pitch(pixmap) - 1;
	ss->ss3.tile_walk = 0;	/* Tiled X */
	ss->ss3.tiled_surface = intel_pixmap_tiled(pixmap) ? 1 : 0;

	dri_bo_emit_reloc(intel->surface_bo,
			  read_domains, write_domain,
			  0,
			  intel->surface_used +
			  offsetof(struct brw_surface_state, ss1),
			  priv->bo);

	offset = intel->surface_used;
	intel->surface_used += SURFACE_STATE_PADDED_SIZE;

	return offset;
}

static int
gen7_set_picture_surface_state(intel_screen_private *intel,
			       PicturePtr picture, PixmapPtr pixmap,
			       Bool is_dst)
{
	struct intel_pixmap *priv = intel_get_pixmap_private(pixmap);
	struct gen7_surface_state *ss;
	uint32_t write_domain, read_domains;
	int offset;

	if (is_dst) {
		write_domain = I915_GEM_DOMAIN_RENDER;
		read_domains = I915_GEM_DOMAIN_RENDER;
	} else {
		write_domain = 0;
		read_domains = I915_GEM_DOMAIN_SAMPLER;
	}
	intel_batch_mark_pixmap_domains(intel, priv,
					read_domains, write_domain);
	ss = (struct gen7_surface_state *)
		(intel->surface_data + intel->surface_used);

	memset(ss, 0, sizeof(*ss));
	ss->ss0.surface_type = BRW_SURFACE_2D;
	if (is_dst)
		ss->ss0.surface_format = i965_get_dest_format(picture);
	else
		ss->ss0.surface_format = i965_get_card_format(picture);

	ss->ss0.tile_walk = 0;	/* Tiled X */
	ss->ss0.tiled_surface = intel_pixmap_tiled(pixmap) ? 1 : 0;
	ss->ss1.base_addr = priv->bo->offset;

	ss->ss2.height = pixmap->drawable.height - 1;
	ss->ss2.width = pixmap->drawable.width - 1;
	ss->ss3.pitch = intel_pixmap_pitch(pixmap) - 1;

	if (IS_HSW(intel)) {
		ss->ss7.shader_chanel_select_r = HSW_SCS_RED;
		ss->ss7.shader_chanel_select_g = HSW_SCS_GREEN;
		ss->ss7.shader_chanel_select_b = HSW_SCS_BLUE;
		ss->ss7.shader_chanel_select_a = HSW_SCS_ALPHA;
	}

	dri_bo_emit_reloc(intel->surface_bo,
			  read_domains, write_domain,
			  0,
			  intel->surface_used +
			  offsetof(struct gen7_surface_state, ss1),
			  priv->bo);

	offset = intel->surface_used;
	intel->surface_used += SURFACE_STATE_PADDED_SIZE;

	return offset;
}

static inline int
i965_set_picture_surface_state(intel_screen_private *intel,
			       PicturePtr picture, PixmapPtr pixmap,
			       Bool is_dst)
{
    if (INTEL_INFO(intel)->gen < 070)
        return gen4_set_picture_surface_state(intel, picture, pixmap, is_dst);
    return gen7_set_picture_surface_state(intel, picture, pixmap, is_dst);
}

static void gen4_composite_vertex_elements(struct intel_screen_private *intel)
{
	struct gen4_render_state *render_state = intel->gen4_render_state;
	gen4_composite_op *composite_op = &render_state->composite_op;
	Bool has_mask = intel->render_mask != NULL;
	Bool is_affine = composite_op->is_affine;
	/*
	 * number of extra parameters per vertex
	 */
	int nelem = has_mask ? 2 : 1;
	/*
	 * size of extra parameters:
	 *  3 for homogenous (xyzw)
	 *  2 for cartesian (xy)
	 */
	int selem = is_affine ? 2 : 3;
	uint32_t w_component;
	uint32_t src_format;
	int id;

	id = has_mask << 1 | is_affine;

	if (composite_op->vertex_id == id)
		return;

	composite_op->vertex_id = id;

	if (is_affine) {
		src_format = BRW_SURFACEFORMAT_R32G32_FLOAT;
		w_component = BRW_VFCOMPONENT_STORE_1_FLT;
	} else {
		src_format = BRW_SURFACEFORMAT_R32G32B32_FLOAT;
		w_component = BRW_VFCOMPONENT_STORE_SRC;
	}

	if (IS_GEN5(intel)) {
		/*
		 * The reason to add this extra vertex element in the header is that
		 * Ironlake has different vertex header definition and origin method to
		 * set destination element offset doesn't exist anymore, which means
		 * hardware requires a predefined vertex element layout.
		 *
		 * haihao proposed this approach to fill the first vertex element, so
		 * origin layout for Gen4 doesn't need to change, and origin shader
		 * programs behavior is also kept.
		 *
		 * I think this is not bad. - zhenyu
		 */

		OUT_BATCH(BRW_3DSTATE_VERTEX_ELEMENTS |
			  ((2 * (2 + nelem)) - 1));
		OUT_BATCH((id << VE0_VERTEX_BUFFER_INDEX_SHIFT) | VE0_VALID |
			  (BRW_SURFACEFORMAT_R32G32_FLOAT << VE0_FORMAT_SHIFT) |
			  (0 << VE0_OFFSET_SHIFT));

		OUT_BATCH((BRW_VFCOMPONENT_STORE_0 << VE1_VFCOMPONENT_0_SHIFT) |
			  (BRW_VFCOMPONENT_STORE_0 << VE1_VFCOMPONENT_1_SHIFT) |
			  (BRW_VFCOMPONENT_STORE_0 << VE1_VFCOMPONENT_2_SHIFT) |
			  (BRW_VFCOMPONENT_STORE_0 << VE1_VFCOMPONENT_3_SHIFT));
	} else {
		/* Set up our vertex elements, sourced from the single vertex buffer.
		 * that will be set up later.
		 */
		OUT_BATCH(BRW_3DSTATE_VERTEX_ELEMENTS |
			  ((2 * (1 + nelem)) - 1));
	}

	/* x,y */
	OUT_BATCH((id << VE0_VERTEX_BUFFER_INDEX_SHIFT) | VE0_VALID |
		  (BRW_SURFACEFORMAT_R32G32_FLOAT << VE0_FORMAT_SHIFT) |
		  (0 << VE0_OFFSET_SHIFT));

	if (IS_GEN5(intel))
		OUT_BATCH((BRW_VFCOMPONENT_STORE_SRC << VE1_VFCOMPONENT_0_SHIFT) |
			  (BRW_VFCOMPONENT_STORE_SRC << VE1_VFCOMPONENT_1_SHIFT) |
			  (BRW_VFCOMPONENT_STORE_1_FLT << VE1_VFCOMPONENT_2_SHIFT) |
			  (BRW_VFCOMPONENT_STORE_1_FLT << VE1_VFCOMPONENT_3_SHIFT));
	else
		OUT_BATCH((BRW_VFCOMPONENT_STORE_SRC << VE1_VFCOMPONENT_0_SHIFT) |
			  (BRW_VFCOMPONENT_STORE_SRC << VE1_VFCOMPONENT_1_SHIFT) |
			  (BRW_VFCOMPONENT_STORE_1_FLT << VE1_VFCOMPONENT_2_SHIFT) |
			  (BRW_VFCOMPONENT_STORE_1_FLT << VE1_VFCOMPONENT_3_SHIFT) |
			  (4 << VE1_DESTINATION_ELEMENT_OFFSET_SHIFT));
	/* u0, v0, w0 */
	OUT_BATCH((id << VE0_VERTEX_BUFFER_INDEX_SHIFT) | VE0_VALID |
		  (src_format << VE0_FORMAT_SHIFT) |
		  ((2 * 4) << VE0_OFFSET_SHIFT));	/* offset vb in bytes */

	if (IS_GEN5(intel))
		OUT_BATCH((BRW_VFCOMPONENT_STORE_SRC << VE1_VFCOMPONENT_0_SHIFT) |
			  (BRW_VFCOMPONENT_STORE_SRC << VE1_VFCOMPONENT_1_SHIFT) |
			  (w_component << VE1_VFCOMPONENT_2_SHIFT) |
			  (BRW_VFCOMPONENT_STORE_1_FLT << VE1_VFCOMPONENT_3_SHIFT));
	else
		OUT_BATCH((BRW_VFCOMPONENT_STORE_SRC << VE1_VFCOMPONENT_0_SHIFT) |
			  (BRW_VFCOMPONENT_STORE_SRC << VE1_VFCOMPONENT_1_SHIFT) |
			  (w_component << VE1_VFCOMPONENT_2_SHIFT) |
			  (BRW_VFCOMPONENT_STORE_1_FLT << VE1_VFCOMPONENT_3_SHIFT) |
			  ((4 + 4) << VE1_DESTINATION_ELEMENT_OFFSET_SHIFT));	/* VUE offset in dwords */
	/* u1, v1, w1 */
	if (has_mask) {
		OUT_BATCH((id << VE0_VERTEX_BUFFER_INDEX_SHIFT) | VE0_VALID |
			  (src_format << VE0_FORMAT_SHIFT) |
			  (((2 + selem) * 4) << VE0_OFFSET_SHIFT));	/* vb offset in bytes */

		if (IS_GEN5(intel))
			OUT_BATCH((BRW_VFCOMPONENT_STORE_SRC << VE1_VFCOMPONENT_0_SHIFT) |
				  (BRW_VFCOMPONENT_STORE_SRC << VE1_VFCOMPONENT_1_SHIFT) |
				  (w_component << VE1_VFCOMPONENT_2_SHIFT) |
				  (BRW_VFCOMPONENT_STORE_1_FLT << VE1_VFCOMPONENT_3_SHIFT));
		else
			OUT_BATCH((BRW_VFCOMPONENT_STORE_SRC << VE1_VFCOMPONENT_0_SHIFT) |
				  (BRW_VFCOMPONENT_STORE_SRC << VE1_VFCOMPONENT_1_SHIFT) |
				  (w_component << VE1_VFCOMPONENT_2_SHIFT) |
				  (BRW_VFCOMPONENT_STORE_1_FLT << VE1_VFCOMPONENT_3_SHIFT) |
				  ((4 + 4 + 4) << VE1_DESTINATION_ELEMENT_OFFSET_SHIFT));	/* VUE offset in dwords */
	}
}

static void i965_emit_composite_state(struct intel_screen_private *intel)
{
	struct gen4_render_state *render_state = intel->gen4_render_state;
	gen4_composite_op *composite_op = &render_state->composite_op;
	int op = composite_op->op;
	PicturePtr mask_picture = intel->render_mask_picture;
	PicturePtr dest_picture = intel->render_dest_picture;
	PixmapPtr mask = intel->render_mask;
	PixmapPtr dest = intel->render_dest;
	sampler_state_filter_t src_filter = composite_op->src_filter;
	sampler_state_filter_t mask_filter = composite_op->mask_filter;
	sampler_state_extend_t src_extend = composite_op->src_extend;
	sampler_state_extend_t mask_extend = composite_op->mask_extend;
	uint32_t src_blend, dst_blend;

	intel->needs_render_state_emit = FALSE;

	/* Begin the long sequence of commands needed to set up the 3D
	 * rendering pipe
	 */

	if (intel->needs_3d_invariant) {
		if (IS_GEN5(intel)) {
			/* Ironlake errata workaround: Before disabling the clipper,
			 * you have to MI_FLUSH to get the pipeline idle.
			 */
			OUT_BATCH(MI_FLUSH | MI_INHIBIT_RENDER_CACHE_FLUSH);
		}

		/* Match Mesa driver setup */
		if (INTEL_INFO(intel)->gen >= 045)
			OUT_BATCH(NEW_PIPELINE_SELECT | PIPELINE_SELECT_3D);
		else
			OUT_BATCH(BRW_PIPELINE_SELECT | PIPELINE_SELECT_3D);

		/* Set system instruction pointer */
		OUT_BATCH(BRW_STATE_SIP | 0);
		OUT_BATCH(0);

		intel->needs_3d_invariant = FALSE;
	}

	if (intel->surface_reloc == 0) {
		/* Zero out the two base address registers so all offsets are
		 * absolute.
		 */
		if (IS_GEN5(intel)) {
			OUT_BATCH(BRW_STATE_BASE_ADDRESS | 6);
			OUT_BATCH(0 | BASE_ADDRESS_MODIFY);	/* Generate state base address */
			intel->surface_reloc = intel->batch_used;
			intel_batch_emit_dword(intel,
					       intel->surface_bo->offset | BASE_ADDRESS_MODIFY);
			OUT_BATCH(0 | BASE_ADDRESS_MODIFY);	/* media base addr, don't care */
			OUT_BATCH(0 | BASE_ADDRESS_MODIFY);	/* Instruction base address */
			/* general state max addr, disabled */
			OUT_BATCH(0 | BASE_ADDRESS_MODIFY);
			/* media object state max addr, disabled */
			OUT_BATCH(0 | BASE_ADDRESS_MODIFY);
			/* Instruction max addr, disabled */
			OUT_BATCH(0 | BASE_ADDRESS_MODIFY);
		} else {
			OUT_BATCH(BRW_STATE_BASE_ADDRESS | 4);
			OUT_BATCH(0 | BASE_ADDRESS_MODIFY);	/* Generate state base address */
			intel->surface_reloc = intel->batch_used;
			intel_batch_emit_dword(intel,
					       intel->surface_bo->offset | BASE_ADDRESS_MODIFY);
			OUT_BATCH(0 | BASE_ADDRESS_MODIFY);	/* media base addr, don't care */
			/* general state max addr, disabled */
			OUT_BATCH(0 | BASE_ADDRESS_MODIFY);
			/* media object state max addr, disabled */
			OUT_BATCH(0 | BASE_ADDRESS_MODIFY);
		}
	}

	i965_get_blend_cntl(op, mask_picture, dest_picture->format,
			    &src_blend, &dst_blend);

	/* Binding table pointers */
	OUT_BATCH(BRW_3DSTATE_BINDING_TABLE_POINTERS | 4);
	OUT_BATCH(0);	/* vs */
	OUT_BATCH(0);	/* gs */
	OUT_BATCH(0);	/* clip */
	OUT_BATCH(0);	/* sf */
	/* Only the PS uses the binding table */
	OUT_BATCH(intel->surface_table);

	/* The drawing rectangle clipping is always on.  Set it to values that
	 * shouldn't do any clipping.
	 */
	OUT_BATCH(BRW_3DSTATE_DRAWING_RECTANGLE | 2);
	OUT_BATCH(0x00000000);	/* ymin, xmin */
	OUT_BATCH(DRAW_YMAX(dest->drawable.height - 1) |
		  DRAW_XMAX(dest->drawable.width - 1));	/* ymax, xmax */
	OUT_BATCH(0x00000000);	/* yorigin, xorigin */

	/* skip the depth buffer */
	/* skip the polygon stipple */
	/* skip the polygon stipple offset */
	/* skip the line stipple */

	/* Set the pointers to the 3d pipeline state */
	OUT_BATCH(BRW_3DSTATE_PIPELINED_POINTERS | 5);
	OUT_RELOC(render_state->vs_state_bo,
		  I915_GEM_DOMAIN_INSTRUCTION, 0, 0);
	OUT_BATCH(BRW_GS_DISABLE);	/* disable GS, resulting in passthrough */
	OUT_BATCH(BRW_CLIP_DISABLE);	/* disable CLIP, resulting in passthrough */
	if (mask) {
		OUT_RELOC(render_state->sf_mask_state_bo,
			  I915_GEM_DOMAIN_INSTRUCTION, 0, 0);
	} else {
		OUT_RELOC(render_state->sf_state_bo,
			  I915_GEM_DOMAIN_INSTRUCTION, 0, 0);
	}

	OUT_RELOC(render_state->wm_state_bo[composite_op->wm_kernel]
		  [src_filter][src_extend]
		  [mask_filter][mask_extend],
		  I915_GEM_DOMAIN_INSTRUCTION, 0, 0);

	OUT_RELOC(render_state->cc_state_bo,
		  I915_GEM_DOMAIN_INSTRUCTION, 0,
		  offsetof(struct gen4_cc_unit_state,
			   cc_state[src_blend][dst_blend]));

	{
		int urb_vs_start, urb_vs_size;
		int urb_gs_start, urb_gs_size;
		int urb_clip_start, urb_clip_size;
		int urb_sf_start, urb_sf_size;
		int urb_cs_start, urb_cs_size;

		urb_vs_start = 0;
		urb_vs_size = URB_VS_ENTRIES * URB_VS_ENTRY_SIZE;
		urb_gs_start = urb_vs_start + urb_vs_size;
		urb_gs_size = URB_GS_ENTRIES * URB_GS_ENTRY_SIZE;
		urb_clip_start = urb_gs_start + urb_gs_size;
		urb_clip_size = URB_CLIP_ENTRIES * URB_CLIP_ENTRY_SIZE;
		urb_sf_start = urb_clip_start + urb_clip_size;
		urb_sf_size = URB_SF_ENTRIES * URB_SF_ENTRY_SIZE;
		urb_cs_start = urb_sf_start + urb_sf_size;
		urb_cs_size = URB_CS_ENTRIES * URB_CS_ENTRY_SIZE;

		/* Erratum (Vol 1a, p32):
		 *   URB_FENCE must not cross a cache-line (64 bytes).
		 */
		if ((intel->batch_used & 15) > (16 - 3)) {
			int cnt = 16 - (intel->batch_used & 15);
			while (cnt--)
				OUT_BATCH(MI_NOOP);
		}

		OUT_BATCH(BRW_URB_FENCE |
			  UF0_CS_REALLOC |
			  UF0_SF_REALLOC |
			  UF0_CLIP_REALLOC |
			  UF0_GS_REALLOC |
			  UF0_VS_REALLOC |
			  1);
		OUT_BATCH(((urb_clip_start + urb_clip_size) << UF1_CLIP_FENCE_SHIFT) |
			  ((urb_gs_start + urb_gs_size) << UF1_GS_FENCE_SHIFT) |
			  ((urb_vs_start + urb_vs_size) << UF1_VS_FENCE_SHIFT));
		OUT_BATCH(((urb_cs_start + urb_cs_size) << UF2_CS_FENCE_SHIFT) |
			  ((urb_sf_start + urb_sf_size) << UF2_SF_FENCE_SHIFT));

		/* Constant buffer state */
		OUT_BATCH(BRW_CS_URB_STATE | 0);
		OUT_BATCH(((URB_CS_ENTRY_SIZE - 1) << 4) |
			  (URB_CS_ENTRIES << 0));
	}

	gen4_composite_vertex_elements(intel);
}

/**
 * Returns whether the current set of composite state plus vertex buffer is
 * expected to fit in the aperture.
 */
static Bool i965_composite_check_aperture(intel_screen_private *intel)
{
	struct gen4_render_state *render_state = intel->gen4_render_state;
	gen4_composite_op *composite_op = &render_state->composite_op;
	drm_intel_bo *bo_table[] = {
		intel->batch_bo,
		intel->vertex_bo,
		intel->surface_bo,
		render_state->vs_state_bo,
		render_state->sf_state_bo,
		render_state->sf_mask_state_bo,
		render_state->wm_state_bo[composite_op->wm_kernel]
		    [composite_op->src_filter]
		    [composite_op->src_extend]
		    [composite_op->mask_filter]
		    [composite_op->mask_extend],
		render_state->cc_state_bo,
	};
	drm_intel_bo *gen6_bo_table[] = {
		intel->batch_bo,
		intel->vertex_bo,
		intel->surface_bo,
		render_state->wm_kernel_bo[composite_op->wm_kernel],
		render_state->ps_sampler_state_bo[composite_op->src_filter]
		    [composite_op->src_extend]
		    [composite_op->mask_filter]
		    [composite_op->mask_extend],
		render_state->cc_vp_bo,
		render_state->cc_state_bo,
		render_state->gen6_blend_bo,
		render_state->gen6_depth_stencil_bo,
	};

	if (INTEL_INFO(intel)->gen >= 060)
		return drm_intel_bufmgr_check_aperture_space(gen6_bo_table,
							ARRAY_SIZE(gen6_bo_table)) == 0;
	else
		return drm_intel_bufmgr_check_aperture_space(bo_table,
							ARRAY_SIZE(bo_table)) == 0;
}

static void i965_surface_flush(struct intel_screen_private *intel)
{
	int ret;

	ret = drm_intel_bo_subdata(intel->surface_bo,
				   0, intel->surface_used,
				   intel->surface_data);
	assert(ret == 0);
	intel->surface_used = 0;

	assert (intel->surface_reloc != 0);
	drm_intel_bo_emit_reloc(intel->batch_bo,
				intel->surface_reloc * 4,
				intel->surface_bo, BASE_ADDRESS_MODIFY,
				I915_GEM_DOMAIN_INSTRUCTION, 0);
	intel->surface_reloc = 0;

	drm_intel_bo_unreference(intel->surface_bo);
	intel->surface_bo =
		drm_intel_bo_alloc(intel->bufmgr, "surface data",
				   sizeof(intel->surface_data), 4096);
	assert(intel->surface_bo);

	return;
	(void)ret;
}

static void
i965_emit_composite_primitive_identity_source(intel_screen_private *intel,
					      int srcX, int srcY,
					      int maskX, int maskY,
					      int dstX, int dstY,
					      int w, int h)
{
	OUT_VERTEX(dstX + w);
	OUT_VERTEX(dstY + h);
	OUT_VERTEX((srcX + w) * intel->scale_units[0][0]);
	OUT_VERTEX((srcY + h) * intel->scale_units[0][1]);

	OUT_VERTEX(dstX);
	OUT_VERTEX(dstY + h);
	OUT_VERTEX(srcX * intel->scale_units[0][0]);
	OUT_VERTEX((srcY + h) * intel->scale_units[0][1]);

	OUT_VERTEX(dstX);
	OUT_VERTEX(dstY);
	OUT_VERTEX(srcX * intel->scale_units[0][0]);
	OUT_VERTEX(srcY * intel->scale_units[0][1]);
}

static void
i965_emit_composite_primitive_affine_source(intel_screen_private *intel,
					    int srcX, int srcY,
					    int maskX, int maskY,
					    int dstX, int dstY,
					    int w, int h)
{
	float src_x[3], src_y[3];

	if (!intel_get_transformed_coordinates(srcX, srcY,
					      intel->transform[0],
					      &src_x[0],
					      &src_y[0]))
		return;

	if (!intel_get_transformed_coordinates(srcX, srcY + h,
					      intel->transform[0],
					      &src_x[1],
					      &src_y[1]))
		return;

	if (!intel_get_transformed_coordinates(srcX + w, srcY + h,
					      intel->transform[0],
					      &src_x[2],
					      &src_y[2]))
		return;

	OUT_VERTEX(dstX + w);
	OUT_VERTEX(dstY + h);
	OUT_VERTEX(src_x[2] * intel->scale_units[0][0]);
	OUT_VERTEX(src_y[2] * intel->scale_units[0][1]);

	OUT_VERTEX(dstX);
	OUT_VERTEX(dstY + h);
	OUT_VERTEX(src_x[1] * intel->scale_units[0][0]);
	OUT_VERTEX(src_y[1] * intel->scale_units[0][1]);

	OUT_VERTEX(dstX);
	OUT_VERTEX(dstY);
	OUT_VERTEX(src_x[0] * intel->scale_units[0][0]);
	OUT_VERTEX(src_y[0] * intel->scale_units[0][1]);
}

static void
i965_emit_composite_primitive_identity_source_mask(intel_screen_private *intel,
						   int srcX, int srcY,
						   int maskX, int maskY,
						   int dstX, int dstY,
						   int w, int h)
{
	OUT_VERTEX(dstX + w);
	OUT_VERTEX(dstY + h);
	OUT_VERTEX((srcX + w) * intel->scale_units[0][0]);
	OUT_VERTEX((srcY + h) * intel->scale_units[0][1]);
	OUT_VERTEX((maskX + w) * intel->scale_units[1][0]);
	OUT_VERTEX((maskY + h) * intel->scale_units[1][1]);

	OUT_VERTEX(dstX);
	OUT_VERTEX(dstY + h);
	OUT_VERTEX(srcX * intel->scale_units[0][0]);
	OUT_VERTEX((srcY + h) * intel->scale_units[0][1]);
	OUT_VERTEX(maskX * intel->scale_units[1][0]);
	OUT_VERTEX((maskY + h) * intel->scale_units[1][1]);

	OUT_VERTEX(dstX);
	OUT_VERTEX(dstY);
	OUT_VERTEX(srcX * intel->scale_units[0][0]);
	OUT_VERTEX(srcY * intel->scale_units[0][1]);
	OUT_VERTEX(maskX * intel->scale_units[1][0]);
	OUT_VERTEX(maskY * intel->scale_units[1][1]);
}

static void
i965_emit_composite_primitive(intel_screen_private *intel,
			      int srcX, int srcY,
			      int maskX, int maskY,
			      int dstX, int dstY,
			      int w, int h)
{
	float src_x[3], src_y[3], src_w[3], mask_x[3], mask_y[3], mask_w[3];
	Bool is_affine = intel->gen4_render_state->composite_op.is_affine;

	if (is_affine) {
		if (!intel_get_transformed_coordinates(srcX, srcY,
						       intel->transform[0],
						       &src_x[0],
						       &src_y[0]))
			return;

		if (!intel_get_transformed_coordinates(srcX, srcY + h,
						       intel->transform[0],
						       &src_x[1],
						       &src_y[1]))
			return;

		if (!intel_get_transformed_coordinates(srcX + w, srcY + h,
						       intel->transform[0],
						       &src_x[2],
						       &src_y[2]))
			return;
	} else {
		if (!intel_get_transformed_coordinates_3d(srcX, srcY,
							  intel->transform[0],
							  &src_x[0],
							  &src_y[0],
							  &src_w[0]))
			return;

		if (!intel_get_transformed_coordinates_3d(srcX, srcY + h,
							  intel->transform[0],
							  &src_x[1],
							  &src_y[1],
							  &src_w[1]))
			return;

		if (!intel_get_transformed_coordinates_3d(srcX + w, srcY + h,
							  intel->transform[0],
							  &src_x[2],
							  &src_y[2],
							  &src_w[2]))
			return;
	}

	if (intel->render_mask) {
		if (is_affine) {
			if (!intel_get_transformed_coordinates(maskX, maskY,
							      intel->transform[1],
							      &mask_x[0],
							      &mask_y[0]))
				return;

			if (!intel_get_transformed_coordinates(maskX, maskY + h,
							      intel->transform[1],
							      &mask_x[1],
							      &mask_y[1]))
				return;

			if (!intel_get_transformed_coordinates(maskX + w, maskY + h,
							      intel->transform[1],
							      &mask_x[2],
							      &mask_y[2]))
				return;
		} else {
			if (!intel_get_transformed_coordinates_3d(maskX, maskY,
								 intel->transform[1],
								 &mask_x[0],
								 &mask_y[0],
								 &mask_w[0]))
				return;

			if (!intel_get_transformed_coordinates_3d(maskX, maskY + h,
								 intel->transform[1],
								 &mask_x[1],
								 &mask_y[1],
								 &mask_w[1]))
				return;

			if (!intel_get_transformed_coordinates_3d(maskX + w, maskY + h,
								 intel->transform[1],
								 &mask_x[2],
								 &mask_y[2],
								 &mask_w[2]))
				return;
		}
	}

	OUT_VERTEX(dstX + w);
	OUT_VERTEX(dstY + h);
	OUT_VERTEX(src_x[2] * intel->scale_units[0][0]);
	OUT_VERTEX(src_y[2] * intel->scale_units[0][1]);
	if (!is_affine)
		OUT_VERTEX(src_w[2]);
	if (intel->render_mask) {
		OUT_VERTEX(mask_x[2] * intel->scale_units[1][0]);
		OUT_VERTEX(mask_y[2] * intel->scale_units[1][1]);
		if (!is_affine)
			OUT_VERTEX(mask_w[2]);
	}

	OUT_VERTEX(dstX);
	OUT_VERTEX(dstY + h);
	OUT_VERTEX(src_x[1] * intel->scale_units[0][0]);
	OUT_VERTEX(src_y[1] * intel->scale_units[0][1]);
	if (!is_affine)
		OUT_VERTEX(src_w[1]);
	if (intel->render_mask) {
		OUT_VERTEX(mask_x[1] * intel->scale_units[1][0]);
		OUT_VERTEX(mask_y[1] * intel->scale_units[1][1]);
		if (!is_affine)
			OUT_VERTEX(mask_w[1]);
	}

	OUT_VERTEX(dstX);
	OUT_VERTEX(dstY);
	OUT_VERTEX(src_x[0] * intel->scale_units[0][0]);
	OUT_VERTEX(src_y[0] * intel->scale_units[0][1]);
	if (!is_affine)
		OUT_VERTEX(src_w[0]);
	if (intel->render_mask) {
		OUT_VERTEX(mask_x[0] * intel->scale_units[1][0]);
		OUT_VERTEX(mask_y[0] * intel->scale_units[1][1]);
		if (!is_affine)
			OUT_VERTEX(mask_w[0]);
	}
}

Bool
i965_prepare_composite(int op, PicturePtr source_picture,
		       PicturePtr mask_picture, PicturePtr dest_picture,
		       PixmapPtr source, PixmapPtr mask, PixmapPtr dest)
{
	ScrnInfoPtr scrn = xf86ScreenToScrn(dest_picture->pDrawable->pScreen);
	intel_screen_private *intel = intel_get_screen_private(scrn);
	struct gen4_render_state *render_state = intel->gen4_render_state;
	gen4_composite_op *composite_op = &render_state->composite_op;

	composite_op->src_filter =
	    sampler_state_filter_from_picture(source_picture->filter);
	if (composite_op->src_filter == SS_INVALID_FILTER) {
		intel_debug_fallback(scrn, "Bad src filter 0x%x\n",
				     source_picture->filter);
		return FALSE;
	}
	composite_op->src_extend =
	    sampler_state_extend_from_picture(source_picture->repeatType);
	if (composite_op->src_extend == SS_INVALID_EXTEND) {
		intel_debug_fallback(scrn, "Bad src repeat 0x%x\n",
				     source_picture->repeatType);
		return FALSE;
	}

	if (mask_picture) {
		if (mask_picture->componentAlpha &&
		    PICT_FORMAT_RGB(mask_picture->format)) {
			/* Check if it's component alpha that relies on a source alpha and on
			 * the source value.  We can only get one of those into the single
			 * source value that we get to blend with.
			 */
			if (i965_blend_op[op].src_alpha &&
			    (i965_blend_op[op].src_blend != BRW_BLENDFACTOR_ZERO)) {
				intel_debug_fallback(scrn,
						     "Component alpha not supported "
						     "with source alpha and source "
						     "value blending.\n");
				return FALSE;
			}
		}

		composite_op->mask_filter =
		    sampler_state_filter_from_picture(mask_picture->filter);
		if (composite_op->mask_filter == SS_INVALID_FILTER) {
			intel_debug_fallback(scrn, "Bad mask filter 0x%x\n",
					     mask_picture->filter);
			return FALSE;
		}
		composite_op->mask_extend =
		    sampler_state_extend_from_picture(mask_picture->repeatType);
		if (composite_op->mask_extend == SS_INVALID_EXTEND) {
			intel_debug_fallback(scrn, "Bad mask repeat 0x%x\n",
					     mask_picture->repeatType);
			return FALSE;
		}
	} else {
		composite_op->mask_filter = SS_FILTER_NEAREST;
		composite_op->mask_extend = SS_EXTEND_NONE;
	}

	/* Flush any pending writes prior to relocating the textures. */
	if (intel_pixmap_is_dirty(source) || intel_pixmap_is_dirty(mask))
		intel_batch_emit_flush(scrn);

	composite_op->op = op;
	intel->render_source_picture = source_picture;
	intel->render_mask_picture = mask_picture;
	intel->render_dest_picture = dest_picture;
	intel->render_source = source;
	intel->render_mask = mask;
	intel->render_dest = dest;

	intel->scale_units[0][0] = 1. / source->drawable.width;
	intel->scale_units[0][1] = 1. / source->drawable.height;

	intel->transform[0] = source_picture->transform;
	composite_op->is_affine = intel_transform_is_affine(intel->transform[0]);

	if (mask_picture == NULL) {
		intel->transform[1] = NULL;
		intel->scale_units[1][0] = -1;
		intel->scale_units[1][1] = -1;
	} else {
		assert(mask != NULL);
		intel->transform[1] = mask_picture->transform;
		intel->scale_units[1][0] = 1. / mask->drawable.width;
		intel->scale_units[1][1] = 1. / mask->drawable.height;
		composite_op->is_affine &=
		    intel_transform_is_affine(intel->transform[1]);
	}

	if (mask) {
		if (mask_picture->componentAlpha &&
		    PICT_FORMAT_RGB(mask_picture->format)) {
			if (i965_blend_op[op].src_alpha) {
				if (composite_op->is_affine)
					composite_op->wm_kernel =
					    WM_KERNEL_MASKCA_SRCALPHA_AFFINE;
				else
					composite_op->wm_kernel =
					    WM_KERNEL_MASKCA_SRCALPHA_PROJECTIVE;
			} else {
				if (composite_op->is_affine)
					composite_op->wm_kernel =
					    WM_KERNEL_MASKCA_AFFINE;
				else
					composite_op->wm_kernel =
					    WM_KERNEL_MASKCA_PROJECTIVE;
			}
		} else {
			if (composite_op->is_affine)
				composite_op->wm_kernel =
				    WM_KERNEL_MASKNOCA_AFFINE;
			else
				composite_op->wm_kernel =
				    WM_KERNEL_MASKNOCA_PROJECTIVE;
		}
	} else {
		if (composite_op->is_affine)
			composite_op->wm_kernel = WM_KERNEL_NOMASK_AFFINE;
		else
			composite_op->wm_kernel = WM_KERNEL_NOMASK_PROJECTIVE;
	}

	intel->prim_emit = i965_emit_composite_primitive;
	if (!mask) {
		if (intel->transform[0] == NULL)
			intel->prim_emit = i965_emit_composite_primitive_identity_source;
		else if (composite_op->is_affine)
			intel->prim_emit = i965_emit_composite_primitive_affine_source;
	} else {
		if (intel->transform[0] == NULL && intel->transform[1] == NULL)
			intel->prim_emit = i965_emit_composite_primitive_identity_source_mask;
	}

	intel->floats_per_vertex =
		2 + (mask ? 2 : 1) * (composite_op->is_affine ? 2: 3);

	if (!i965_composite_check_aperture(intel)) {
		intel_batch_submit(scrn);
		if (!i965_composite_check_aperture(intel)) {
			intel_debug_fallback(scrn,
					     "Couldn't fit render operation "
					     "in aperture\n");
			return FALSE;
		}
	}

	if (sizeof(intel->surface_data) - intel->surface_used <
	    4 * SURFACE_STATE_PADDED_SIZE)
		i965_surface_flush(intel);

	intel->needs_render_state_emit = TRUE;

	return TRUE;
}

static void i965_select_vertex_buffer(struct intel_screen_private *intel)
{
	int id = intel->gen4_render_state->composite_op.vertex_id;
	int modifyenable = 0;

	if (intel->vertex_id & (1 << id))
		return;

	if (INTEL_INFO(intel)->gen >= 070)
		modifyenable = GEN7_VB0_ADDRESS_MODIFYENABLE;

	/* Set up the pointer to our (single) vertex buffer */
	OUT_BATCH(BRW_3DSTATE_VERTEX_BUFFERS | 3);

	/* XXX could use multiple vbo to reduce relocations if
	 * frequently switching between vertex sizes, like rgb10text.
	 */
	if (INTEL_INFO(intel)->gen >= 060) {
		OUT_BATCH((id << GEN6_VB0_BUFFER_INDEX_SHIFT) |
			  GEN6_VB0_VERTEXDATA |
			  modifyenable |
			  (4*intel->floats_per_vertex << VB0_BUFFER_PITCH_SHIFT));
	} else {
		OUT_BATCH((id << VB0_BUFFER_INDEX_SHIFT) |
			  VB0_VERTEXDATA |
			  (4*intel->floats_per_vertex << VB0_BUFFER_PITCH_SHIFT));
	}
	OUT_RELOC(intel->vertex_bo, I915_GEM_DOMAIN_VERTEX, 0, 0);
	if (INTEL_INFO(intel)->gen >= 050)
		OUT_RELOC(intel->vertex_bo,
			  I915_GEM_DOMAIN_VERTEX, 0,
			  sizeof(intel->vertex_ptr) - 1);
	else
		OUT_BATCH(0);
	OUT_BATCH(0);		// ignore for VERTEXDATA, but still there

	intel->vertex_id |= 1 << id;
}

static void i965_bind_surfaces(struct intel_screen_private *intel)
{
	uint32_t *binding_table;

	assert(intel->surface_used + 4 * SURFACE_STATE_PADDED_SIZE <= sizeof(intel->surface_data));

	binding_table = (uint32_t*) (intel->surface_data + intel->surface_used);
	intel->surface_table = intel->surface_used;
	intel->surface_used += SURFACE_STATE_PADDED_SIZE;

	binding_table[0] =
		i965_set_picture_surface_state(intel,
					       intel->render_dest_picture,
					       intel->render_dest,
					       TRUE);
	binding_table[1] =
		i965_set_picture_surface_state(intel,
					       intel->render_source_picture,
					       intel->render_source,
					       FALSE);
	if (intel->render_mask) {
		binding_table[2] =
			i965_set_picture_surface_state(intel,
						       intel->render_mask_picture,
						       intel->render_mask,
						       FALSE);
	}
}

void
i965_composite(PixmapPtr dest, int srcX, int srcY, int maskX, int maskY,
	       int dstX, int dstY, int w, int h)
{
	ScrnInfoPtr scrn = xf86ScreenToScrn(dest->drawable.pScreen);
	intel_screen_private *intel = intel_get_screen_private(scrn);

	intel_batch_start_atomic(scrn, 200);
	if (intel->needs_render_state_emit) {
		i965_bind_surfaces(intel);

		if (INTEL_INFO(intel)->gen >= 060)
			gen6_emit_composite_state(intel);
		else
			i965_emit_composite_state(intel);
	}

	if (intel->floats_per_vertex != intel->last_floats_per_vertex) {
		intel->vertex_index = (intel->vertex_used + intel->floats_per_vertex - 1) / intel->floats_per_vertex;
		intel->vertex_used = intel->vertex_index * intel->floats_per_vertex;
		intel->last_floats_per_vertex = intel->floats_per_vertex;
	}
	if (intel_vertex_space(intel) < 3*4*intel->floats_per_vertex) {
		i965_vertex_flush(intel);
		intel_next_vertex(intel);
		intel->vertex_index = 0;
	}
	i965_select_vertex_buffer(intel);

	if (intel->vertex_offset == 0) {
		if (INTEL_INFO(intel)->gen >= 070) {
			OUT_BATCH(BRW_3DPRIMITIVE | (7 - 2));
			OUT_BATCH(BRW_3DPRIMITIVE_VERTEX_SEQUENTIAL |
				  _3DPRIM_RECTLIST);
		} else {
			OUT_BATCH(BRW_3DPRIMITIVE |
				  BRW_3DPRIMITIVE_VERTEX_SEQUENTIAL |
				  (_3DPRIM_RECTLIST << BRW_3DPRIMITIVE_TOPOLOGY_SHIFT) |
				  (0 << 9) |
				  4);
		}
		intel->vertex_offset = intel->batch_used;
		OUT_BATCH(0);	/* vertex count, to be filled in later */
		OUT_BATCH(intel->vertex_index);
		OUT_BATCH(1);	/* single instance */
		OUT_BATCH(0);	/* start instance location */
		OUT_BATCH(0);	/* index buffer offset, ignored */
		intel->vertex_count = intel->vertex_index;
	}

	intel->prim_emit(intel,
			 srcX, srcY,
			 maskX, maskY,
			 dstX, dstY,
			 w, h);
	intel->vertex_index += 3;

	if (INTEL_INFO(intel)->gen < 050) {
	    /* XXX OMG! */
	    i965_vertex_flush(intel);
	    OUT_BATCH(MI_FLUSH | MI_INHIBIT_RENDER_CACHE_FLUSH);
	}

	intel_batch_end_atomic(scrn);
}

void i965_batch_commit_notify(intel_screen_private *intel)
{
	intel->needs_render_state_emit = TRUE;
	intel->needs_3d_invariant = TRUE;
	intel->last_floats_per_vertex = 0;
	intel->vertex_index = 0;

	intel->gen4_render_state->composite_op.vertex_id = -1;

	intel->gen6_render_state.num_sf_outputs = 0;
	intel->gen6_render_state.samplers = NULL;
	intel->gen6_render_state.blend = -1;
	intel->gen6_render_state.kernel = NULL;
	intel->gen6_render_state.drawrect = -1;

	assert(intel->surface_reloc == 0);
}

/**
 * Called at EnterVT so we can set up our offsets into the state buffer.
 */
void gen4_render_state_init(ScrnInfoPtr scrn)
{
	intel_screen_private *intel = intel_get_screen_private(scrn);
	struct gen4_render_state *render;
	const struct wm_kernel_info *wm_kernels;
	sampler_state_filter_t src_filter;
	sampler_state_extend_t src_extend;
	sampler_state_filter_t mask_filter;
	sampler_state_extend_t mask_extend;
	drm_intel_bo *sf_kernel_bo, *sf_kernel_mask_bo;
	drm_intel_bo *border_color_bo;
	int m;

	intel->needs_3d_invariant = TRUE;

	intel->surface_bo =
		drm_intel_bo_alloc(intel->bufmgr, "surface data",
				   sizeof(intel->surface_data), 4096);
	assert(intel->surface_bo);

	intel->surface_used = 0;

	if (intel->gen4_render_state == NULL) {
		intel->gen4_render_state = calloc(1, sizeof(*render));
		assert(intel->gen4_render_state != NULL);
	}

	if (INTEL_INFO(intel)->gen >= 060)
		return gen6_render_state_init(scrn);

	render = intel->gen4_render_state;
	render->composite_op.vertex_id = -1;

	render->vs_state_bo = gen4_create_vs_unit_state(intel);

	/* Set up the two SF states (one for blending with a mask, one without) */
	if (IS_GEN5(intel)) {
		sf_kernel_bo = intel_bo_alloc_for_data(intel,
						       sf_kernel_static_gen5,
						       sizeof
						       (sf_kernel_static_gen5),
						       "sf kernel gen5");
		sf_kernel_mask_bo =
		    intel_bo_alloc_for_data(intel, sf_kernel_mask_static_gen5,
					    sizeof(sf_kernel_mask_static_gen5),
					    "sf mask kernel");
	} else {
		sf_kernel_bo = intel_bo_alloc_for_data(intel,
						       sf_kernel_static,
						       sizeof(sf_kernel_static),
						       "sf kernel");
		sf_kernel_mask_bo = intel_bo_alloc_for_data(intel,
							    sf_kernel_mask_static,
							    sizeof
							    (sf_kernel_mask_static),
							    "sf mask kernel");
	}
	render->sf_state_bo = gen4_create_sf_state(intel, sf_kernel_bo);
	render->sf_mask_state_bo = gen4_create_sf_state(intel, sf_kernel_mask_bo);
	drm_intel_bo_unreference(sf_kernel_bo);
	drm_intel_bo_unreference(sf_kernel_mask_bo);

	wm_kernels = IS_GEN5(intel) ? wm_kernels_gen5 : wm_kernels_gen4;
	for (m = 0; m < KERNEL_COUNT; m++) {
		render->wm_kernel_bo[m] =
			intel_bo_alloc_for_data(intel,
					wm_kernels[m].data,
					wm_kernels[m].size,
					"WM kernel");
	}

	/* Set up the WM states: each filter/extend type for source and mask, per
	 * kernel.
	 */
	border_color_bo = sampler_border_color_create(intel);
	for (src_filter = 0; src_filter < FILTER_COUNT; src_filter++) {
		for (src_extend = 0; src_extend < EXTEND_COUNT; src_extend++) {
			for (mask_filter = 0; mask_filter < FILTER_COUNT; mask_filter++) {
				for (mask_extend = 0; mask_extend < EXTEND_COUNT; mask_extend++) {
					drm_intel_bo *sampler_state_bo;

					sampler_state_bo =
					    i965_create_sampler_state(intel,
								      src_filter, src_extend,
								      mask_filter, mask_extend,
								      border_color_bo);

					for (m = 0; m < KERNEL_COUNT; m++) {
						render->wm_state_bo[m][src_filter][src_extend][mask_filter][mask_extend] =
							gen4_create_wm_state
							(intel,
							 wm_kernels[m]. has_mask,
							 render->wm_kernel_bo[m],
							 sampler_state_bo);
					}
					drm_intel_bo_unreference(sampler_state_bo);
				}
			}
		}
	}
	drm_intel_bo_unreference(border_color_bo);

	render->cc_state_bo = gen4_create_cc_unit_state(intel);
}

/**
 * Called at LeaveVT.
 */
void gen4_render_state_cleanup(ScrnInfoPtr scrn)
{
	intel_screen_private *intel = intel_get_screen_private(scrn);
	struct gen4_render_state *render_state = intel->gen4_render_state;
	int i, j, k, l, m;

	drm_intel_bo_unreference(intel->surface_bo);
	drm_intel_bo_unreference(render_state->vs_state_bo);
	drm_intel_bo_unreference(render_state->sf_state_bo);
	drm_intel_bo_unreference(render_state->sf_mask_state_bo);

	for (i = 0; i < KERNEL_COUNT; i++)
		drm_intel_bo_unreference(render_state->wm_kernel_bo[i]);

	for (i = 0; i < FILTER_COUNT; i++)
		for (j = 0; j < EXTEND_COUNT; j++)
			for (k = 0; k < FILTER_COUNT; k++)
				for (l = 0; l < EXTEND_COUNT; l++)
					for (m = 0; m < KERNEL_COUNT; m++)
						drm_intel_bo_unreference
						    (render_state->
						     wm_state_bo[m][i][j][k]
						     [l]);

	for (i = 0; i < FILTER_COUNT; i++)
		for (j = 0; j < EXTEND_COUNT; j++)
			for (k = 0; k < FILTER_COUNT; k++)
				for (l = 0; l < EXTEND_COUNT; l++)
					drm_intel_bo_unreference(render_state->ps_sampler_state_bo[i][j][k][l]);

	drm_intel_bo_unreference(render_state->cc_state_bo);

	drm_intel_bo_unreference(render_state->cc_vp_bo);
	drm_intel_bo_unreference(render_state->gen6_blend_bo);
	drm_intel_bo_unreference(render_state->gen6_depth_stencil_bo);

	free(intel->gen4_render_state);
	intel->gen4_render_state = NULL;
}

/*
 * for GEN6+
 */
#define GEN6_BLEND_STATE_PADDED_SIZE	ALIGN(sizeof(struct gen6_blend_state), 64)

static drm_intel_bo *
gen6_composite_create_cc_state(intel_screen_private *intel)
{
	struct gen6_color_calc_state *state;
	drm_intel_bo *cc_bo;
	int ret;

	cc_bo = drm_intel_bo_alloc(intel->bufmgr,
				"gen6 CC state",
				sizeof(*state),
				4096);
	assert(cc_bo);

	ret = drm_intel_bo_map(cc_bo, TRUE);
	assert(ret == 0);

	state = memset(cc_bo->virtual, 0, sizeof(*state));
	state->constant_r = 1.0;
	state->constant_g = 0.0;
	state->constant_b = 1.0;
	state->constant_a = 1.0;
	drm_intel_bo_unmap(cc_bo);

	return cc_bo;
	(void)ret;
}

static drm_intel_bo *
gen6_composite_create_blend_state(intel_screen_private *intel)
{
	drm_intel_bo *blend_bo;
	int src, dst, ret;

	blend_bo = drm_intel_bo_alloc(intel->bufmgr,
				"gen6 BLEND state",
				BRW_BLENDFACTOR_COUNT * BRW_BLENDFACTOR_COUNT * GEN6_BLEND_STATE_PADDED_SIZE,
				4096);
	assert(blend_bo);

	ret = drm_intel_bo_map(blend_bo, TRUE);
	assert(ret == 0);

	memset(blend_bo->virtual, 0, blend_bo->size);
	for (src = 0; src < BRW_BLENDFACTOR_COUNT; src++) {
		for (dst = 0; dst < BRW_BLENDFACTOR_COUNT; dst++) {
			uint32_t blend_state_offset = (src * BRW_BLENDFACTOR_COUNT + dst) * GEN6_BLEND_STATE_PADDED_SIZE;
			struct gen6_blend_state *blend;

			blend = (struct gen6_blend_state *)((char *)blend_bo->virtual + blend_state_offset);
			blend->blend0.dest_blend_factor = dst;
			blend->blend0.source_blend_factor = src;
			blend->blend0.blend_func = BRW_BLENDFUNCTION_ADD;
			blend->blend0.blend_enable = 1;

			blend->blend1.post_blend_clamp_enable = 1;
			blend->blend1.pre_blend_clamp_enable = 1;
		}
	}

	drm_intel_bo_unmap(blend_bo);
	return blend_bo;
	(void)ret;
}

static drm_intel_bo *
gen6_composite_create_depth_stencil_state(intel_screen_private *intel)
{
	drm_intel_bo *depth_stencil_bo;
	int ret;

	depth_stencil_bo =
		drm_intel_bo_alloc(intel->bufmgr,
				   "gen6 DEPTH_STENCIL state",
				   sizeof(struct gen6_depth_stencil_state),
				   4096);
	assert(depth_stencil_bo);

	ret = drm_intel_bo_map(depth_stencil_bo, TRUE);
	assert(ret == 0);

	memset(depth_stencil_bo->virtual, 0,
	       sizeof(struct gen6_depth_stencil_state));
	drm_intel_bo_unmap(depth_stencil_bo);

	return depth_stencil_bo;
	(void)ret;
}

static void
gen6_composite_state_base_address(intel_screen_private *intel)
{
	OUT_BATCH(BRW_STATE_BASE_ADDRESS | (10 - 2));
	OUT_BATCH(BASE_ADDRESS_MODIFY); /* General state base address */
	intel->surface_reloc = intel->batch_used;
	intel_batch_emit_dword(intel,
			       intel->surface_bo->offset | BASE_ADDRESS_MODIFY);
	OUT_BATCH(BASE_ADDRESS_MODIFY); /* Dynamic state base address */
	OUT_BATCH(BASE_ADDRESS_MODIFY); /* Indirect object base address */
	OUT_BATCH(BASE_ADDRESS_MODIFY); /* Instruction base address */
	OUT_BATCH(BASE_ADDRESS_MODIFY); /* General state upper bound */
	OUT_BATCH(BASE_ADDRESS_MODIFY); /* Dynamic state upper bound */
	OUT_BATCH(BASE_ADDRESS_MODIFY); /* Indirect object upper bound */
	OUT_BATCH(BASE_ADDRESS_MODIFY); /* Instruction access upper bound */
}

static void
gen6_composite_cc_state_pointers(intel_screen_private *intel,
				 uint32_t blend_offset)
{
	struct gen4_render_state *render_state = intel->gen4_render_state;
	drm_intel_bo *cc_bo = NULL;
	drm_intel_bo *depth_stencil_bo = NULL;

	if (intel->gen6_render_state.blend == blend_offset)
		return;

	if (intel->gen6_render_state.blend == -1) {
		cc_bo = render_state->cc_state_bo;
		depth_stencil_bo = render_state->gen6_depth_stencil_bo;
	}
	if (INTEL_INFO(intel)->gen >= 070) {
		gen7_upload_cc_state_pointers(intel, render_state->gen6_blend_bo, cc_bo, depth_stencil_bo, blend_offset);
	} else {
		gen6_upload_cc_state_pointers(intel, render_state->gen6_blend_bo, cc_bo, depth_stencil_bo, blend_offset);
	}

	intel->gen6_render_state.blend = blend_offset;
}

static void
gen6_composite_sampler_state_pointers(intel_screen_private *intel,
				      drm_intel_bo *bo)
{
	if (intel->gen6_render_state.samplers == bo)
		return;

	intel->gen6_render_state.samplers = bo;

	if (INTEL_INFO(intel)->gen >= 070)
		gen7_upload_sampler_state_pointers(intel, bo);
	else
		gen6_upload_sampler_state_pointers(intel, bo);
}

static void
gen6_composite_wm_constants(intel_screen_private *intel)
{
	Bool ivb = INTEL_INFO(intel)->gen >= 070;
	/* disable WM constant buffer */
	OUT_BATCH(GEN6_3DSTATE_CONSTANT_PS | ((ivb ? 7 : 5) - 2));
	OUT_BATCH(0);
	OUT_BATCH(0);
	OUT_BATCH(0);
	OUT_BATCH(0);
	if (ivb) {
		OUT_BATCH(0);
		OUT_BATCH(0);
	}
}

static void
gen6_composite_sf_state(intel_screen_private *intel,
			Bool has_mask)
{
	int num_sf_outputs = has_mask ? 2 : 1;

	if (intel->gen6_render_state.num_sf_outputs == num_sf_outputs)
		return;

	intel->gen6_render_state.num_sf_outputs = num_sf_outputs;

	if (INTEL_INFO(intel)->gen >= 070)
		gen7_upload_sf_state(intel, num_sf_outputs, 1);
	else
		gen6_upload_sf_state(intel, num_sf_outputs, 1);
}

static void
gen6_composite_wm_state(intel_screen_private *intel,
			Bool has_mask,
			drm_intel_bo *bo)
{
	int num_surfaces = has_mask ? 3 : 2;
	int num_sf_outputs = has_mask ? 2 : 1;

	if (intel->gen6_render_state.kernel == bo)
		return;

	intel->gen6_render_state.kernel = bo;

	OUT_BATCH(GEN6_3DSTATE_WM | (9 - 2));
	OUT_RELOC(bo,
		I915_GEM_DOMAIN_INSTRUCTION, 0,
		0);
	OUT_BATCH((1 << GEN6_3DSTATE_WM_SAMPLER_COUNT_SHITF) |
		  (num_surfaces << GEN6_3DSTATE_WM_BINDING_TABLE_ENTRY_COUNT_SHIFT));
	OUT_BATCH(0);
	OUT_BATCH((6 << GEN6_3DSTATE_WM_DISPATCH_START_GRF_0_SHIFT)); /* DW4 */
	OUT_BATCH(((40 - 1) << GEN6_3DSTATE_WM_MAX_THREADS_SHIFT) |
		  GEN6_3DSTATE_WM_DISPATCH_ENABLE |
		  GEN6_3DSTATE_WM_16_DISPATCH_ENABLE);
	OUT_BATCH((num_sf_outputs << GEN6_3DSTATE_WM_NUM_SF_OUTPUTS_SHIFT) |
		  GEN6_3DSTATE_WM_PERSPECTIVE_PIXEL_BARYCENTRIC);
	OUT_BATCH(0);
	OUT_BATCH(0);
}

static void
gen7_composite_wm_state(intel_screen_private *intel,
			Bool has_mask,
			drm_intel_bo *bo)
{
	int num_surfaces = has_mask ? 3 : 2;
	unsigned int max_threads_shift = GEN7_PS_MAX_THREADS_SHIFT_IVB;
	unsigned int num_samples = 0;

	if (IS_HSW(intel)) {
		max_threads_shift = GEN7_PS_MAX_THREADS_SHIFT_HSW;
		num_samples = 1 << GEN7_PS_SAMPLE_MASK_SHIFT_HSW;
	}

	if (intel->gen6_render_state.kernel == bo)
		return;

	intel->gen6_render_state.kernel = bo;

	OUT_BATCH(GEN6_3DSTATE_WM | (3 - 2));
	OUT_BATCH(GEN7_WM_DISPATCH_ENABLE |
		  GEN7_WM_PERSPECTIVE_PIXEL_BARYCENTRIC);
	OUT_BATCH(0);

	OUT_BATCH(GEN7_3DSTATE_PS | (8 - 2));
	OUT_RELOC(bo, I915_GEM_DOMAIN_INSTRUCTION, 0, 0);
	OUT_BATCH((1 << GEN7_PS_SAMPLER_COUNT_SHIFT) |
		  (num_surfaces << GEN7_PS_BINDING_TABLE_ENTRY_COUNT_SHIFT));
	OUT_BATCH(0); /* scratch space base offset */
	OUT_BATCH(((48 - 1) << max_threads_shift) | num_samples |
		  GEN7_PS_ATTRIBUTE_ENABLE |
		  GEN7_PS_16_DISPATCH_ENABLE);
	OUT_BATCH((6 << GEN7_PS_DISPATCH_START_GRF_SHIFT_0));
	OUT_BATCH(0); /* kernel 1 pointer */
	OUT_BATCH(0); /* kernel 2 pointer */
}


static void
gen6_composite_drawing_rectangle(intel_screen_private *intel,
				 PixmapPtr dest)
{
	uint32_t dw =
		DRAW_YMAX(dest->drawable.height - 1) |
		DRAW_XMAX(dest->drawable.width - 1);

	/* XXX cacomposite depends upon the implicit non-pipelined flush */
	if (0 && intel->gen6_render_state.drawrect == dw)
		return;
	intel->gen6_render_state.drawrect = dw;

	OUT_BATCH(BRW_3DSTATE_DRAWING_RECTANGLE | (4 - 2));
	OUT_BATCH(0x00000000);	/* ymin, xmin */
	OUT_BATCH(dw);	/* ymax, xmax */
	OUT_BATCH(0x00000000);	/* yorigin, xorigin */
}

static void
gen6_composite_vertex_element_state(intel_screen_private *intel,
				    Bool has_mask,
				    Bool is_affine)
{
	/*
	 * vertex data in vertex buffer
	 *    position: (x, y)
	 *    texture coordinate 0: (u0, v0) if (is_affine is TRUE) else (u0, v0, w0)
	 *    texture coordinate 1 if (has_mask is TRUE): same as above
	 */
	gen4_composite_op *composite_op = &intel->gen4_render_state->composite_op;
	int nelem = has_mask ? 2 : 1;
	int selem = is_affine ? 2 : 3;
	uint32_t w_component;
	uint32_t src_format;
	int id;

	id = has_mask << 1 | is_affine;

	if (composite_op->vertex_id == id)
		return;

	composite_op->vertex_id = id;

	if (is_affine) {
		src_format = BRW_SURFACEFORMAT_R32G32_FLOAT;
		w_component = BRW_VFCOMPONENT_STORE_1_FLT;
	} else {
		src_format = BRW_SURFACEFORMAT_R32G32B32_FLOAT;
		w_component = BRW_VFCOMPONENT_STORE_SRC;
	}

	/* The VUE layout
	 *    dword 0-3: pad (0.0, 0.0, 0.0. 0.0)
	 *    dword 4-7: position (x, y, 1.0, 1.0),
	 *    dword 8-11: texture coordinate 0 (u0, v0, w0, 1.0)
	 *    dword 12-15: texture coordinate 1 (u1, v1, w1, 1.0)
	 *
	 * dword 4-15 are fetched from vertex buffer
	 */
	OUT_BATCH(BRW_3DSTATE_VERTEX_ELEMENTS |
		((2 * (2 + nelem)) + 1 - 2));

	OUT_BATCH((id << GEN6_VE0_VERTEX_BUFFER_INDEX_SHIFT) | GEN6_VE0_VALID |
		  (BRW_SURFACEFORMAT_R32G32_FLOAT << VE0_FORMAT_SHIFT) |
		  (0 << VE0_OFFSET_SHIFT));
	OUT_BATCH((BRW_VFCOMPONENT_STORE_0 << VE1_VFCOMPONENT_0_SHIFT) |
		  (BRW_VFCOMPONENT_STORE_0 << VE1_VFCOMPONENT_1_SHIFT) |
		  (BRW_VFCOMPONENT_STORE_0 << VE1_VFCOMPONENT_2_SHIFT) |
		  (BRW_VFCOMPONENT_STORE_0 << VE1_VFCOMPONENT_3_SHIFT));

	/* x,y */
	OUT_BATCH((id << GEN6_VE0_VERTEX_BUFFER_INDEX_SHIFT) | GEN6_VE0_VALID |
		  (BRW_SURFACEFORMAT_R32G32_FLOAT << VE0_FORMAT_SHIFT) |
		  (0 << VE0_OFFSET_SHIFT)); /* offsets vb in bytes */
	OUT_BATCH((BRW_VFCOMPONENT_STORE_SRC << VE1_VFCOMPONENT_0_SHIFT) |
		  (BRW_VFCOMPONENT_STORE_SRC << VE1_VFCOMPONENT_1_SHIFT) |
		  (BRW_VFCOMPONENT_STORE_1_FLT << VE1_VFCOMPONENT_2_SHIFT) |
		  (BRW_VFCOMPONENT_STORE_1_FLT << VE1_VFCOMPONENT_3_SHIFT));

	/* u0, v0, w0 */
	OUT_BATCH((id << GEN6_VE0_VERTEX_BUFFER_INDEX_SHIFT) | GEN6_VE0_VALID |
		  (src_format << VE0_FORMAT_SHIFT) |
		  ((2 * 4) << VE0_OFFSET_SHIFT));	/* offset vb in bytes */
	OUT_BATCH((BRW_VFCOMPONENT_STORE_SRC << VE1_VFCOMPONENT_0_SHIFT) |
		  (BRW_VFCOMPONENT_STORE_SRC << VE1_VFCOMPONENT_1_SHIFT) |
		  (w_component << VE1_VFCOMPONENT_2_SHIFT) |
		  (BRW_VFCOMPONENT_STORE_1_FLT << VE1_VFCOMPONENT_3_SHIFT));

	/* u1, v1, w1 */
	if (has_mask) {
		OUT_BATCH((id << GEN6_VE0_VERTEX_BUFFER_INDEX_SHIFT) |
			  GEN6_VE0_VALID |
			  (src_format << VE0_FORMAT_SHIFT) |
			  (((2 + selem) * 4) << VE0_OFFSET_SHIFT)); /* vb offset in bytes */
		OUT_BATCH((BRW_VFCOMPONENT_STORE_SRC << VE1_VFCOMPONENT_0_SHIFT) |
			  (BRW_VFCOMPONENT_STORE_SRC << VE1_VFCOMPONENT_1_SHIFT) |
			  (w_component << VE1_VFCOMPONENT_2_SHIFT) |
			  (BRW_VFCOMPONENT_STORE_1_FLT << VE1_VFCOMPONENT_3_SHIFT));
	}
}

static void
gen6_emit_composite_state(struct intel_screen_private *intel)
{
	struct gen4_render_state *render = intel->gen4_render_state;
	gen4_composite_op *composite_op = &render->composite_op;
	sampler_state_filter_t src_filter = composite_op->src_filter;
	sampler_state_filter_t mask_filter = composite_op->mask_filter;
	sampler_state_extend_t src_extend = composite_op->src_extend;
	sampler_state_extend_t mask_extend = composite_op->mask_extend;
	Bool is_affine = composite_op->is_affine;
	Bool has_mask = intel->render_mask != NULL;
	Bool ivb = INTEL_INFO(intel)->gen >= 070;
	uint32_t src, dst;
	drm_intel_bo *ps_sampler_state_bo = render->ps_sampler_state_bo[src_filter][src_extend][mask_filter][mask_extend];

	intel->needs_render_state_emit = FALSE;
	if (intel->needs_3d_invariant) {
		gen6_upload_invariant_states(intel);

		if (ivb) {
			gen7_upload_viewport_state_pointers(intel, render->cc_vp_bo);
			gen7_upload_urb(intel);
			gen7_upload_bypass_states(intel);
			gen7_upload_depth_buffer_state(intel);
		} else {
			gen6_upload_invariant_states(intel);
			gen6_upload_viewport_state_pointers(intel, render->cc_vp_bo);
			gen6_upload_urb(intel);

			gen6_upload_gs_state(intel);
			gen6_upload_depth_buffer_state(intel);
		}
		gen6_composite_wm_constants(intel);
		gen6_upload_vs_state(intel);
		gen6_upload_clip_state(intel);

		intel->needs_3d_invariant = FALSE;
	}

	i965_get_blend_cntl(composite_op->op,
			    intel->render_mask_picture,
			    intel->render_dest_picture->format,
			    &src, &dst);

	if (intel->surface_reloc == 0)
		gen6_composite_state_base_address(intel);

	gen6_composite_cc_state_pointers(intel,
					(src * BRW_BLENDFACTOR_COUNT + dst) * GEN6_BLEND_STATE_PADDED_SIZE);
	gen6_composite_sampler_state_pointers(intel, ps_sampler_state_bo);
	gen6_composite_sf_state(intel, has_mask);
	if (ivb) {
		gen7_composite_wm_state(intel, has_mask,
					render->wm_kernel_bo[composite_op->wm_kernel]);
		gen7_upload_binding_table(intel, intel->surface_table);
	} else {
		gen6_composite_wm_state(intel, has_mask,
					render->wm_kernel_bo[composite_op->wm_kernel]);
		gen6_upload_binding_table(intel, intel->surface_table);
	}
	gen6_composite_drawing_rectangle(intel, intel->render_dest);
	gen6_composite_vertex_element_state(intel, has_mask, is_affine);
}

static void
gen6_render_state_init(ScrnInfoPtr scrn)
{
	intel_screen_private *intel = intel_get_screen_private(scrn);
	struct gen4_render_state *render;
	sampler_state_filter_t src_filter;
	sampler_state_filter_t mask_filter;
	sampler_state_extend_t src_extend;
	sampler_state_extend_t mask_extend;
	int m;
	drm_intel_bo *border_color_bo;
	const struct wm_kernel_info *wm_kernels;

	render= intel->gen4_render_state;
	render->composite_op.vertex_id = -1;

	intel->gen6_render_state.num_sf_outputs = 0;
	intel->gen6_render_state.samplers = NULL;
	intel->gen6_render_state.blend = -1;
	intel->gen6_render_state.kernel = NULL;
	intel->gen6_render_state.drawrect = -1;

	wm_kernels = IS_GEN7(intel) ? wm_kernels_gen7 : wm_kernels_gen6;
	for (m = 0; m < KERNEL_COUNT; m++) {
		render->wm_kernel_bo[m] =
			intel_bo_alloc_for_data(intel,
					wm_kernels[m].data,
					wm_kernels[m].size,
					"WM kernel gen6/7");
	}

	border_color_bo = sampler_border_color_create(intel);

	for (src_filter = 0; src_filter < FILTER_COUNT; src_filter++) {
		for (src_extend = 0; src_extend < EXTEND_COUNT; src_extend++) {
			for (mask_filter = 0; mask_filter < FILTER_COUNT; mask_filter++) {
				for (mask_extend = 0; mask_extend < EXTEND_COUNT; mask_extend++) {
					render->ps_sampler_state_bo[src_filter][src_extend][mask_filter][mask_extend] =
						i965_create_sampler_state(intel,
									  src_filter, src_extend,
									  mask_filter, mask_extend,
								border_color_bo);
				}
			}
		}
	}

	drm_intel_bo_unreference(border_color_bo);
	render->cc_vp_bo = gen4_create_cc_viewport(intel);
	render->cc_state_bo = gen6_composite_create_cc_state(intel);
	render->gen6_blend_bo = gen6_composite_create_blend_state(intel);
	render->gen6_depth_stencil_bo = gen6_composite_create_depth_stencil_state(intel);
}

void i965_vertex_flush(struct intel_screen_private *intel)
{
	if (intel->vertex_offset) {
		intel->batch_ptr[intel->vertex_offset] =
			intel->vertex_index - intel->vertex_count;
		intel->vertex_offset = 0;
	}
}

void i965_batch_flush(struct intel_screen_private *intel)
{
	if (intel->surface_used)
		i965_surface_flush(intel);
}
@


1.10
log
@Update to xf86-video-intel 2.20.19.

A recent kernel with kernel modesetting support is required.
Thanks to jsg@@ and kettenis@@ for their work.
@
text
@@


1.9
log
@Add basic support for ivy bridge and fix several cases of register
access not being adjusted for the pch split, one of which prevented
multiple display pipes from working.  The third pipe on ivy bridge
remains disabled for now.

ok kettenis@@ thanks to everyone who tested
@
text
@d107 1
d112 1
d157 1
a157 1
		break;
d161 1
a161 1
		break;
d184 1
a184 2
	ScrnInfoPtr scrn = xf86Screens[dest_picture->pDrawable->pScreen->myNum];
	intel_screen_private *intel = intel_get_screen_private(scrn);
d222 1
a222 1
		ScrnInfoPtr scrn = xf86Screens[screen->myNum];
d231 1
a231 1
		ScrnInfoPtr scrn = xf86Screens[screen->myNum];
d243 1
a243 1
			ScrnInfoPtr scrn = xf86Screens[screen->myNum];
d258 1
a258 1
			ScrnInfoPtr scrn = xf86Screens[screen->myNum];
d387 1
a387 1
/* new programs for IGDNG */
d781 1
d785 4
a788 2
	drm_intel_bo_map(sf_state_bo, TRUE);
	sf_state = sf_state_bo->virtual;
d790 1
a790 1
	memset(sf_state, 0, sizeof(*sf_state));
d826 1
d989 1
d994 5
a998 1
	drm_intel_bo_map(sampler_state_bo, TRUE);
d1011 1
d1024 1
d1029 5
a1033 1
	drm_intel_bo_map(sampler_state_bo, TRUE);
d1046 1
d1057 1
a1057 1
	if (INTEL_INFO(intel)->gen < 70)
d1115 1
d1119 4
a1122 2
	drm_intel_bo_map(wm_state_bo, TRUE);
	state = wm_state_bo->virtual;
d1124 1
a1124 1
	memset(state, 0, sizeof(*state));
d1176 1
a1176 1
	 * be set 0 for IGDNG
d1184 1
d1191 1
d1198 4
a1201 1
	drm_intel_bo_subdata(bo, 0, sizeof(vp), &vp);
d1204 1
d1232 1
a1232 1
	int i, j;
d1239 5
a1243 1
	drm_intel_bo_map(cc_state_bo, TRUE);
d1257 1
d1395 7
d1420 1
a1420 1
    if (INTEL_INFO(intel)->gen < 70)
d1574 1
a1574 1
		if (INTEL_INFO(intel)->gen >= 45)
d1754 1
a1754 1
	if (INTEL_INFO(intel)->gen >= 60)
d1764 6
a1769 3
	drm_intel_bo_subdata(intel->surface_bo,
			     0, intel->surface_used,
			     intel->surface_data);
d1783 4
d1894 39
a1932 41
	if (! intel->render_source_is_solid) {
		if (is_affine) {
			if (!intel_get_transformed_coordinates(srcX, srcY,
							      intel->transform[0],
							      &src_x[0],
							      &src_y[0]))
				return;

			if (!intel_get_transformed_coordinates(srcX, srcY + h,
							      intel->transform[0],
							      &src_x[1],
							      &src_y[1]))
				return;

			if (!intel_get_transformed_coordinates(srcX + w, srcY + h,
							      intel->transform[0],
							      &src_x[2],
							      &src_y[2]))
				return;
		} else {
			if (!intel_get_transformed_coordinates_3d(srcX, srcY,
								 intel->transform[0],
								 &src_x[0],
								 &src_y[0],
								 &src_w[0]))
				return;

			if (!intel_get_transformed_coordinates_3d(srcX, srcY + h,
								 intel->transform[0],
								 &src_x[1],
								 &src_y[1],
								 &src_w[1]))
				return;

			if (!intel_get_transformed_coordinates_3d(srcX + w, srcY + h,
								 intel->transform[0],
								 &src_x[2],
								 &src_y[2],
								 &src_w[2]))
				return;
		}
d2023 1
a2023 1
	ScrnInfoPtr scrn = xf86Screens[dest_picture->pDrawable->pScreen->myNum];
d2080 1
a2080 2
	if (intel_pixmap_is_dirty(source) ||
	    (mask && intel_pixmap_is_dirty(mask)))
d2097 1
a2097 1
	if (!mask) {
d2102 1
d2184 1
a2184 1
	if (INTEL_INFO(intel)->gen >= 70)
d2193 1
a2193 1
	if (INTEL_INFO(intel)->gen >= 60) {
d2204 1
a2204 1
	if (INTEL_INFO(intel)->gen >= 50)
d2248 1
a2248 1
	ScrnInfoPtr scrn = xf86Screens[dest->drawable.pScreen->myNum];
d2255 1
a2255 1
		if (INTEL_INFO(intel)->gen >= 60)
d2274 1
a2274 1
		if (INTEL_INFO(intel)->gen >= 70) {
d2301 1
a2301 1
	if (INTEL_INFO(intel)->gen < 50) {
d2336 4
a2339 1
	int i, j, k, l, m;
d2342 1
d2349 2
d2353 4
a2356 2
	if (intel->gen4_render_state == NULL)
		intel->gen4_render_state = calloc(sizeof(*render), 1);
d2358 1
a2358 1
	if (INTEL_INFO(intel)->gen >= 60)
d2406 4
a2409 4
	for (i = 0; i < FILTER_COUNT; i++) {
		for (j = 0; j < EXTEND_COUNT; j++) {
			for (k = 0; k < FILTER_COUNT; k++) {
				for (l = 0; l < EXTEND_COUNT; l++) {
d2414 2
a2415 2
								      i, j,
								      k, l,
d2419 1
a2419 1
						render->wm_state_bo[m][i][j][k][l] =
d2489 1
d2495 6
a2500 3
	drm_intel_bo_map(cc_bo, TRUE);
	state = cc_bo->virtual;
	memset(state, 0, sizeof(*state));
d2508 1
d2515 1
a2515 1
	int src, dst;
d2521 5
a2525 1
	drm_intel_bo_map(blend_bo, TRUE);
a2526 1

d2545 1
a2550 1
	struct gen6_depth_stencil_state *state;
d2552 1
d2554 12
a2565 7
	depth_stencil_bo = drm_intel_bo_alloc(intel->bufmgr,
					"gen6 DEPTH_STENCIL state",
					sizeof(*state),
					4096);
	drm_intel_bo_map(depth_stencil_bo, TRUE);
	state = depth_stencil_bo->virtual;
	memset(state, 0, sizeof(*state));
d2569 1
d2604 1
a2604 1
	if (INTEL_INFO(intel)->gen >= 70) {
d2622 1
a2622 1
	if (INTEL_INFO(intel)->gen >= 70)
d2631 1
a2631 1
	Bool ivb = INTEL_INFO(intel)->gen >= 70;
d2655 1
a2655 1
	if (INTEL_INFO(intel)->gen >= 70)
d2697 7
d2720 1
a2720 1
	OUT_BATCH(((48 - 1) << GEN7_PS_MAX_THREADS_SHIFT) |
d2842 1
a2842 1
	Bool ivb = INTEL_INFO(intel)->gen >= 70;
d2900 5
a2904 1
	int i, j, k, l, m;
d2928 5
a2932 5
	for (i = 0; i < FILTER_COUNT; i++) {
		for (j = 0; j < EXTEND_COUNT; j++) {
			for (k = 0; k < FILTER_COUNT; k++) {
				for (l = 0; l < EXTEND_COUNT; l++) {
					render->ps_sampler_state_bo[i][j][k][l] =
d2934 2
a2935 2
								i, j,
								k, l,
@


1.8
log
@Update the intel driver to a more recent version based on more recent
upsteam code.

Backporting keeping UMS changes by me, some bugfixes from kettenis@@.

Has been in snapshots for a while, committed on request so we can be
sure what people are running. This is a prerequesite for sandybridge
support but has those chipsets disabled for now until the correct code
has been added.
@
text
@d2647 1
a2647 1
	OUT_BATCH(((86 - 1) << GEN7_PS_MAX_THREADS_SHIFT) |
@


1.7
log
@Avoid dereferencing a NULL pointer during VT switches when composite
is active.

Fix confirmed to fix observed crash by dcoppa@@ canacar@@. ok marco@@.
@
text
@d38 3
a40 2
#include "i830.h"
#include "i915_reg.h"
d46 1
a46 8
/* 24 = 4 vertices/composite * 3 texcoords/vertex * 2 floats/texcoord
 *
 * This is an upper-bound based on the case of a non-affine
 * transformation and with a mask, but useful for sizing all cases for
 * simplicity.
 */
#define VERTEX_FLOATS_PER_COMPOSITE	24
#define VERTEX_BUFFER_SIZE		(256 * VERTEX_FLOATS_PER_COMPOSITE)
d48 2
a49 1
struct blendinfo {
d54 1
a54 11
};

struct formatinfo {
	int fmt;
	uint32_t card_fmt;
};

// refer vol2, 3d rasterization 3.8.1

/* defined in brw_defines.h */
static struct blendinfo i965_blend_op[] = {
d95 5
a99 1
static struct formatinfo i965_tex_formats[] = {
d104 1
d107 5
a111 1
	{PICT_a8, BRW_SURFACEFORMAT_A8_UNORM},
d146 1
a146 1
static Bool i965_get_dest_format(PicturePtr dest_picture, uint32_t * dst_format)
a147 2
	ScrnInfoPtr scrn = xf86Screens[dest_picture->pDrawable->pScreen->myNum];

d151 8
a158 1
		*dst_format = BRW_SURFACEFORMAT_B8G8R8A8_UNORM;
d161 2
a162 2
		*dst_format = BRW_SURFACEFORMAT_B5G6R5_UNORM;
		break;
d164 1
a164 5
		*dst_format = BRW_SURFACEFORMAT_B5G5R5A1_UNORM;
		break;
	case PICT_x1r5g5b5:
		*dst_format = BRW_SURFACEFORMAT_B5G5R5X1_UNORM;
		break;
d166 1
a166 2
		*dst_format = BRW_SURFACEFORMAT_A8_UNORM;
		break;
d169 1
a169 2
		*dst_format = BRW_SURFACEFORMAT_B4G4R4A4_UNORM;
		break;
d171 1
a171 3
		intel_debug_fallback(scrn, "Unsupported dest format 0x%x\n",
				     (int)dest_picture->format);
		return FALSE;
a172 2

	return TRUE;
d183 1
a183 1
	uint32_t tmp1;
d208 3
a210 2
	if (!i965_get_dest_format(dest_picture, &tmp1)) {
		intel_debug_fallback(scrn, "Get Color buffer format\n");
a291 23
static const uint32_t sip_kernel_static[][4] = {
/*    wait (1) a0<1>UW a145<0,1,0>UW { align1 +  } */
	{0x00000030, 0x20000108, 0x00001220, 0x00000000},
/*    nop (4) g0<1>UD { align1 +  } */
	{0x0040007e, 0x20000c21, 0x00690000, 0x00000000},
/*    nop (4) g0<1>UD { align1 +  } */
	{0x0040007e, 0x20000c21, 0x00690000, 0x00000000},
/*    nop (4) g0<1>UD { align1 +  } */
	{0x0040007e, 0x20000c21, 0x00690000, 0x00000000},
/*    nop (4) g0<1>UD { align1 +  } */
	{0x0040007e, 0x20000c21, 0x00690000, 0x00000000},
/*    nop (4) g0<1>UD { align1 +  } */
	{0x0040007e, 0x20000c21, 0x00690000, 0x00000000},
/*    nop (4) g0<1>UD { align1 +  } */
	{0x0040007e, 0x20000c21, 0x00690000, 0x00000000},
/*    nop (4) g0<1>UD { align1 +  } */
	{0x0040007e, 0x20000c21, 0x00690000, 0x00000000},
/*    nop (4) g0<1>UD { align1 +  } */
	{0x0040007e, 0x20000c21, 0x00690000, 0x00000000},
/*    nop (4) g0<1>UD { align1 +  } */
	{0x0040007e, 0x20000c21, 0x00690000, 0x00000000},
};

d469 134
a602 12
#define WM_STATE_DECL(kernel) \
    struct brw_wm_unit_state wm_state_ ## kernel[SAMPLER_STATE_FILTER_COUNT] \
						[SAMPLER_STATE_EXTEND_COUNT] \
						[SAMPLER_STATE_FILTER_COUNT] \
						[SAMPLER_STATE_EXTEND_COUNT]

/* Many of the fields in the state structure must be aligned to a
 * 64-byte boundary, (or a 32-byte boundary, but 64 is good enough for
 * those too).
 */
#define PAD64_MULTI(previous, idx, factor) char previous ## _pad ## idx [(64 - (sizeof(struct previous) * (factor)) % 64) % 64]
#define PAD64(previous, idx) PAD64_MULTI(previous, idx, 1)
d605 4
a608 3
	SAMPLER_STATE_FILTER_NEAREST,
	SAMPLER_STATE_FILTER_BILINEAR,
	SAMPLER_STATE_FILTER_COUNT
d612 6
a617 5
	SAMPLER_STATE_EXTEND_NONE,
	SAMPLER_STATE_EXTEND_REPEAT,
	SAMPLER_STATE_EXTEND_PAD,
	SAMPLER_STATE_EXTEND_REFLECT,
	SAMPLER_STATE_EXTEND_COUNT
d629 1
a629 1
	WM_KERNEL_COUNT
d635 1
a635 1
	void *data;
d640 1
a640 1
static struct wm_kernel_info wm_kernels[] = {
d659 1
a659 1
static struct wm_kernel_info wm_kernels_gen5[] = {
d678 38
d723 4
a726 4
typedef struct brw_surface_state_padded {
	struct brw_surface_state state;
	char pad[32 - sizeof(struct brw_surface_state)];
} brw_surface_state_padded;
d730 1
a730 2
	brw_cc_unit_state_padded cc_state[BRW_BLENDFACTOR_COUNT]
	    [BRW_BLENDFACTOR_COUNT];
a732 2
typedef float gen4_vertex_buffer[VERTEX_BUFFER_SIZE];

a734 1
	drm_intel_bo *binding_table_bo;
d741 1
d750 12
a761 10
	drm_intel_bo *wm_state_bo[WM_KERNEL_COUNT]
	    [SAMPLER_STATE_FILTER_COUNT]
	    [SAMPLER_STATE_EXTEND_COUNT]
	    [SAMPLER_STATE_FILTER_COUNT]
	    [SAMPLER_STATE_EXTEND_COUNT];
	drm_intel_bo *wm_kernel_bo[WM_KERNEL_COUNT];

	drm_intel_bo *sip_kernel_bo;
	dri_bo *vertex_buffer_bo;

d763 1
d765 2
a766 3
	int vb_offset;
	int vertex_size;
};
d775 1
a775 1
static drm_intel_bo *gen4_create_sf_state(ScrnInfoPtr scrn,
a777 1
	intel_screen_private *intel = intel_get_screen_private(scrn);
a811 1
	sf_state->thread4.stats_enable = 1;
d824 1
a824 1
static drm_intel_bo *sampler_border_color_create(ScrnInfoPtr scrn)
d835 1
a835 1
	return intel_bo_alloc_for_data(scrn,
d842 1
a842 1
sampler_state_init(drm_intel_bo * sampler_state_bo,
d864 1
a864 1
	case SAMPLER_STATE_FILTER_NEAREST:
d868 1
a868 1
	case SAMPLER_STATE_FILTER_BILINEAR:
d876 1
a876 1
	case SAMPLER_STATE_EXTEND_NONE:
d881 1
a881 1
	case SAMPLER_STATE_EXTEND_REPEAT:
d886 1
a886 1
	case SAMPLER_STATE_EXTEND_PAD:
d891 1
a891 1
	case SAMPLER_STATE_EXTEND_REFLECT:
d907 73
a979 9
static drm_intel_bo *gen4_create_sampler_state(ScrnInfoPtr scrn,
					       sampler_state_filter_t
					       src_filter,
					       sampler_state_extend_t
					       src_extend,
					       sampler_state_filter_t
					       mask_filter,
					       sampler_state_extend_t
					       mask_extend,
a981 1
	intel_screen_private *intel = intel_get_screen_private(scrn);
d991 35
a1025 6
	sampler_state_init(sampler_state_bo,
			   &sampler_state[0],
			   src_filter, src_extend, border_color_bo);
	sampler_state_init(sampler_state_bo,
			   &sampler_state[1],
			   mask_filter, mask_extend, border_color_bo);
d1032 18
d1091 1
a1091 1
static drm_intel_bo *gen4_create_wm_state(ScrnInfoPtr scrn,
d1096 1
a1096 2
	intel_screen_private *intel = intel_get_screen_private(scrn);
	struct brw_wm_unit_state *wm_state;
d1100 1
a1100 1
					 sizeof(*wm_state), 4096);
d1102 1
a1102 1
	wm_state = wm_state_bo->virtual;
d1104 3
a1106 3
	memset(wm_state, 0, sizeof(*wm_state));
	wm_state->thread0.grf_reg_count = BRW_GRF_BLOCKS(PS_KERNEL_NUM_GRF);
	wm_state->thread0.kernel_start_pointer =
d1109 1
a1109 1
			     kernel_bo, wm_state->thread0.grf_reg_count << 1,
d1112 1
a1112 1
	wm_state->thread1.single_program_flow = 0;
d1115 2
a1116 2
	wm_state->thread2.scratch_space_base_pointer = 0;
	wm_state->thread2.per_thread_scratch_space = 0;
d1118 2
a1119 2
	wm_state->thread3.const_urb_entry_read_length = 0;
	wm_state->thread3.const_urb_entry_read_offset = 0;
d1121 1
a1121 1
	wm_state->thread3.urb_entry_read_offset = 0;
d1123 1
a1123 1
	wm_state->thread3.dispatch_grf_start_reg = 3;	/* must match kernel */
d1125 2
a1126 4
	wm_state->wm4.stats_enable = 1;	/* statistic */

	if (IS_IGDNG(intel))
		wm_state->wm4.sampler_count = 0;	/* hardware requirement */
d1128 1
a1128 1
		wm_state->wm4.sampler_count = 1;	/* 1-4 samplers used */
d1130 1
a1130 1
	wm_state->wm4.sampler_state_pointer =
d1134 1
a1134 2
			     wm_state->wm4.stats_enable +
			     (wm_state->wm4.sampler_count << 2),
d1136 3
a1138 3
	wm_state->wm5.max_threads = PS_MAX_THREADS - 1;
	wm_state->wm5.transposed_urb_read = 0;
	wm_state->wm5.thread_dispatch_enable = 1;
d1142 3
a1144 3
	wm_state->wm5.enable_16_pix = 1;
	wm_state->wm5.enable_8_pix = 0;
	wm_state->wm5.early_depth_test = 1;
d1148 2
a1149 2
		wm_state->thread1.binding_table_entry_count = 3;	/* 2 tex and fb */
		wm_state->thread3.urb_entry_read_length = 4;
d1151 2
a1152 2
		wm_state->thread1.binding_table_entry_count = 2;	/* 1 tex and fb */
		wm_state->thread3.urb_entry_read_length = 2;
d1158 2
a1159 2
	if (IS_IGDNG(intel))
		wm_state->thread1.binding_table_entry_count = 0;
d1166 1
a1166 1
static drm_intel_bo *gen4_create_cc_viewport(ScrnInfoPtr scrn)
a1167 1
	intel_screen_private *intel = intel_get_screen_private(scrn);
d1169 1
a1169 1
	struct brw_cc_viewport cc_viewport;
d1171 2
a1172 2
	cc_viewport.min_depth = -1.e35;
	cc_viewport.max_depth = 1.e35;
d1175 2
a1176 2
				sizeof(cc_viewport), 4096);
	drm_intel_bo_subdata(bo, 0, sizeof(cc_viewport), &cc_viewport);
d1181 1
a1181 1
static drm_intel_bo *gen4_create_vs_unit_state(ScrnInfoPtr scrn)
a1182 1
	intel_screen_private *intel = intel_get_screen_private(scrn);
d1187 1
a1187 1
	if (IS_IGDNG(intel))
d1195 1
a1195 1
	return intel_bo_alloc_for_data(scrn, &vs_state, sizeof(vs_state),
d1203 1
a1203 1
static drm_intel_bo *gen4_create_cc_unit_state(ScrnInfoPtr scrn)
a1204 2
	intel_screen_private *intel = intel_get_screen_private(scrn);
	struct gen4_cc_unit_state *cc_state;
d1208 1
a1208 1
	cc_vp_bo = gen4_create_cc_viewport(scrn);
d1211 2
a1212 1
					 sizeof(*cc_state), 4096);
a1213 1
	cc_state = cc_state_bo->virtual;
d1247 1
a1247 1
		return SAMPLER_STATE_FILTER_NEAREST;
d1249 1
a1249 1
		return SAMPLER_STATE_FILTER_BILINEAR;
d1251 1
a1251 1
		return -1;
d1259 1
a1259 1
		return SAMPLER_STATE_EXTEND_NONE;
d1261 1
a1261 1
		return SAMPLER_STATE_EXTEND_REPEAT;
d1263 1
a1263 1
		return SAMPLER_STATE_EXTEND_PAD;
d1265 1
a1265 1
		return SAMPLER_STATE_EXTEND_REFLECT;
d1267 1
a1267 1
		return -1;
d1275 103
a1377 1
static void
a1378 1
			       dri_bo * ss_bo, int ss_index,
d1382 26
a1407 3
	struct brw_surface_state_padded *ss;
	struct brw_surface_state local_ss;
	struct intel_pixmap *priv = i830_get_pixmap_intel(pixmap);
d1409 2
a1410 1
	ss = (struct brw_surface_state_padded *)ss_bo->virtual + ss_index;
d1412 1
a1412 8
	/* Since ss is a pointer to WC memory, do all of our bit operations
	 * into a local temporary first.
	 */
	memset(&local_ss, 0, sizeof(local_ss));
	local_ss.ss0.surface_type = BRW_SURFACE_2D;
	if (is_dst) {
		uint32_t dst_format = 0;
		Bool ret = TRUE;
d1414 3
a1416 3
		ret = i965_get_dest_format(picture, &dst_format);
		assert(ret == TRUE);
		local_ss.ss0.surface_format = dst_format;
d1418 2
a1419 1
		local_ss.ss0.surface_format = i965_get_card_format(picture);
d1422 31
a1452 32
	local_ss.ss0.data_return_format = BRW_SURFACERETURNFORMAT_FLOAT32;
	local_ss.ss0.writedisable_alpha = 0;
	local_ss.ss0.writedisable_red = 0;
	local_ss.ss0.writedisable_green = 0;
	local_ss.ss0.writedisable_blue = 0;
	local_ss.ss0.color_blend = 1;
	local_ss.ss0.vert_line_stride = 0;
	local_ss.ss0.vert_line_stride_ofs = 0;
	local_ss.ss0.mipmap_layout_mode = 0;
	local_ss.ss0.render_cache_read_mode = 0;
	local_ss.ss1.base_addr = priv->bo->offset;

	local_ss.ss2.mip_count = 0;
	local_ss.ss2.render_target_rotation = 0;
	local_ss.ss2.height = pixmap->drawable.height - 1;
	local_ss.ss2.width = pixmap->drawable.width - 1;
	local_ss.ss3.pitch = intel_get_pixmap_pitch(pixmap) - 1;
	local_ss.ss3.tile_walk = 0;	/* Tiled X */
	local_ss.ss3.tiled_surface = i830_pixmap_tiled(pixmap) ? 1 : 0;

	memcpy(ss, &local_ss, sizeof(local_ss));

	if (priv->bo != NULL) {
		uint32_t write_domain, read_domains;

		if (is_dst) {
			write_domain = I915_GEM_DOMAIN_RENDER;
			read_domains = I915_GEM_DOMAIN_RENDER;
		} else {
			write_domain = 0;
			read_domains = I915_GEM_DOMAIN_SAMPLER;
		}
d1454 49
a1502 6
		intel_batch_mark_pixmap_domains(intel, priv, read_domains, write_domain);
		dri_bo_emit_reloc(ss_bo, read_domains, write_domain,
				  0,
				  ss_index * sizeof(*ss) +
				  offsetof(struct brw_surface_state, ss1),
				  priv->bo);
d1506 1
a1506 1
static void i965_emit_composite_state(ScrnInfoPtr scrn)
a1507 1
	intel_screen_private *intel = intel_get_screen_private(scrn);
a1518 6
	Bool is_affine = composite_op->is_affine;
	int urb_vs_start, urb_vs_size;
	int urb_gs_start, urb_gs_size;
	int urb_clip_start, urb_clip_size;
	int urb_sf_start, urb_sf_size;
	int urb_cs_start, urb_cs_size;
a1519 1
	dri_bo *binding_table_bo = composite_op->binding_table_bo;
a1522 23
	IntelEmitInvarientState(scrn);
	intel->last_3d = LAST_3D_RENDER;

	/* Mark the destination dirty within this batch */
	intel_batch_mark_pixmap_domains(intel,
					i830_get_pixmap_intel(dest),
					I915_GEM_DOMAIN_RENDER,
					I915_GEM_DOMAIN_RENDER);

	urb_vs_start = 0;
	urb_vs_size = URB_VS_ENTRIES * URB_VS_ENTRY_SIZE;
	urb_gs_start = urb_vs_start + urb_vs_size;
	urb_gs_size = URB_GS_ENTRIES * URB_GS_ENTRY_SIZE;
	urb_clip_start = urb_gs_start + urb_gs_size;
	urb_clip_size = URB_CLIP_ENTRIES * URB_CLIP_ENTRY_SIZE;
	urb_sf_start = urb_clip_start + urb_clip_size;
	urb_sf_size = URB_SF_ENTRIES * URB_SF_ENTRY_SIZE;
	urb_cs_start = urb_sf_start + urb_sf_size;
	urb_cs_size = URB_CS_ENTRIES * URB_CS_ENTRY_SIZE;

	i965_get_blend_cntl(op, mask_picture, dest_picture->format,
			    &src_blend, &dst_blend);

d1527 7
a1533 5
	/* URB fence. Erratum (Vol 1a, p32): URB_FENCE must not cross a
	 * cache-line (64 bytes). Start by aligning this sequence of ops to
	 * a cache-line...
	 */
	ALIGN_BATCH(64);
a1534 2
	assert(intel->in_batch_atomic);
	{
d1536 1
a1536 4
		OUT_BATCH(MI_FLUSH |
			  MI_STATE_INSTRUCTION_CACHE_FLUSH |
			  BRW_MI_GLOBAL_SNAPSHOT_RESET);
		if (IS_G4X(intel) || IS_IGDNG(intel))
d1541 6
a1546 3
		OUT_BATCH(BRW_CS_URB_STATE | 0);
		OUT_BATCH((0 << 4) |	/* URB Entry Allocation Size */
			  (0 << 0));	/* Number of URB Entries */
d1548 1
d1552 1
a1552 1
		if (IS_IGDNG(intel)) {
d1555 3
a1557 1
			OUT_BATCH(0 | BASE_ADDRESS_MODIFY);	/* Surface state base address */
d1561 1
a1561 1
			OUT_BATCH(0x10000000 | BASE_ADDRESS_MODIFY);
d1563 1
a1563 1
			OUT_BATCH(0x10000000 | BASE_ADDRESS_MODIFY);
d1565 1
a1565 1
			OUT_BATCH(0x10000000 | BASE_ADDRESS_MODIFY);
d1569 3
a1571 1
			OUT_BATCH(0 | BASE_ADDRESS_MODIFY);	/* Surface state base address */
d1574 1
a1574 1
			OUT_BATCH(0x10000000 | BASE_ADDRESS_MODIFY);
d1576 1
a1576 1
			OUT_BATCH(0x10000000 | BASE_ADDRESS_MODIFY);
d1578 39
a1616 3
		/* Set system instruction pointer */
		OUT_BATCH(BRW_STATE_SIP | 0);
		OUT_RELOC(render_state->sip_kernel_bo,
d1620 9
a1628 6
	if (IS_IGDNG(intel)) {
		/* Ironlake errata workaround: Before disabling the clipper,
		 * you have to MI_FLUSH to get the pipeline idle.
		 */
		OUT_BATCH(MI_FLUSH);
	}
d1631 16
a1646 23
		int pipe_ctrl;
		/* Pipe control */

		if (IS_IGDNG(intel))
			pipe_ctrl = BRW_PIPE_CONTROL_NOWRITE;
		else
			pipe_ctrl =
			    BRW_PIPE_CONTROL_NOWRITE |
			    BRW_PIPE_CONTROL_IS_FLUSH;

		OUT_BATCH(BRW_PIPE_CONTROL | pipe_ctrl | 2);
		OUT_BATCH(0);	/* Destination address */
		OUT_BATCH(0);	/* Immediate data low DW */
		OUT_BATCH(0);	/* Immediate data high DW */

		/* Binding table pointers */
		OUT_BATCH(BRW_3DSTATE_BINDING_TABLE_POINTERS | 4);
		OUT_BATCH(0);	/* vs */
		OUT_BATCH(0);	/* gs */
		OUT_BATCH(0);	/* clip */
		OUT_BATCH(0);	/* sf */
		/* Only the PS uses the binding table */
		OUT_RELOC(binding_table_bo, I915_GEM_DOMAIN_SAMPLER, 0, 0);
d1648 2
a1649 2
		/* The drawing rectangle clipping is always on.  Set it to values that
		 * shouldn't do any clipping.
d1651 4
a1654 22
		OUT_BATCH(BRW_3DSTATE_DRAWING_RECTANGLE | 2);
		OUT_BATCH(0x00000000);	/* ymin, xmin */
		OUT_BATCH(DRAW_YMAX(dest->drawable.height - 1) | DRAW_XMAX(dest->drawable.width - 1));	/* ymax, xmax */
		OUT_BATCH(0x00000000);	/* yorigin, xorigin */

		/* skip the depth buffer */
		/* skip the polygon stipple */
		/* skip the polygon stipple offset */
		/* skip the line stipple */

		/* Set the pointers to the 3d pipeline state */
		OUT_BATCH(BRW_3DSTATE_PIPELINED_POINTERS | 5);
		OUT_RELOC(render_state->vs_state_bo,
			  I915_GEM_DOMAIN_INSTRUCTION, 0, 0);
		OUT_BATCH(BRW_GS_DISABLE);	/* disable GS, resulting in passthrough */
		OUT_BATCH(BRW_CLIP_DISABLE);	/* disable CLIP, resulting in passthrough */
		if (mask) {
			OUT_RELOC(render_state->sf_mask_state_bo,
				  I915_GEM_DOMAIN_INSTRUCTION, 0, 0);
		} else {
			OUT_RELOC(render_state->sf_state_bo,
				  I915_GEM_DOMAIN_INSTRUCTION, 0, 0);
a1656 20
		OUT_RELOC(render_state->wm_state_bo[composite_op->wm_kernel]
			  [src_filter][src_extend]
			  [mask_filter][mask_extend],
			  I915_GEM_DOMAIN_INSTRUCTION, 0, 0);

		OUT_RELOC(render_state->cc_state_bo,
			  I915_GEM_DOMAIN_INSTRUCTION, 0,
			  offsetof(struct gen4_cc_unit_state,
				   cc_state[src_blend][dst_blend]));

		/* URB fence. Erratum (Vol 1a, p32): URB_FENCE must not cross a
		 * cache-line (64 bytes).
		 *
		 * 21 preceding dwords since start of section: 84 bytes.
		 * 12 bytes for URB_FENCE, implies that the end-of-instruction
		 * does not cross the cache-line boundary...
		 *
		 * A total of 33 or 35 dwords since alignment: 132, 140 bytes.
		 * Again, the URB_FENCE will not cross a cache-line.
		 */
d1661 8
a1668 15
			  UF0_GS_REALLOC | UF0_VS_REALLOC | 1);
		OUT_BATCH(((urb_clip_start +
			    urb_clip_size) << UF1_CLIP_FENCE_SHIFT) |
			  ((urb_gs_start +
			    urb_gs_size) << UF1_GS_FENCE_SHIFT) | ((urb_vs_start
								    +
								    urb_vs_size)
								   <<
								   UF1_VS_FENCE_SHIFT));
		OUT_BATCH(((urb_cs_start +
			    urb_cs_size) << UF2_CS_FENCE_SHIFT) | ((urb_sf_start
								    +
								    urb_sf_size)
								   <<
								   UF2_SF_FENCE_SHIFT));
a1674 13
	{
		/*
		 * number of extra parameters per vertex
		 */
		int nelem = mask ? 2 : 1;
		/*
		 * size of extra parameters:
		 *  3 for homogenous (xyzw)
		 *  2 for cartesian (xy)
		 */
		int selem = is_affine ? 2 : 3;
		uint32_t w_component;
		uint32_t src_format;
d1676 2
a1677 1
		render_state->vertex_size = 4 * (2 + nelem * selem);
d1679 171
d1851 17
a1867 2
			src_format = BRW_SURFACEFORMAT_R32G32_FLOAT;
			w_component = BRW_VFCOMPONENT_STORE_1_FLT;
d1869 20
a1888 2
			src_format = BRW_SURFACEFORMAT_R32G32B32_FLOAT;
			w_component = BRW_VFCOMPONENT_STORE_SRC;
d1890 9
d1900 5
a1904 13
		if (IS_IGDNG(intel)) {
			/*
			 * The reason to add this extra vertex element in the header is that
			 * IGDNG has different vertex header definition and origin method to
			 * set destination element offset doesn't exist anymore, which means
			 * hardware requires a predefined vertex element layout.
			 *
			 * haihao proposed this approach to fill the first vertex element, so
			 * origin layout for Gen4 doesn't need to change, and origin shader
			 * programs behavior is also kept.
			 *
			 * I think this is not bad. - zhenyu
			 */
d1906 5
a1910 15
			OUT_BATCH(BRW_3DSTATE_VERTEX_ELEMENTS |
				  ((2 * (2 + nelem)) - 1));
			OUT_BATCH((0 << VE0_VERTEX_BUFFER_INDEX_SHIFT) |
				  VE0_VALID | (BRW_SURFACEFORMAT_R32G32_FLOAT <<
					       VE0_FORMAT_SHIFT) | (0 <<
								    VE0_OFFSET_SHIFT));

			OUT_BATCH((BRW_VFCOMPONENT_STORE_0 <<
				   VE1_VFCOMPONENT_0_SHIFT) |
				  (BRW_VFCOMPONENT_STORE_0 <<
				   VE1_VFCOMPONENT_1_SHIFT) |
				  (BRW_VFCOMPONENT_STORE_0 <<
				   VE1_VFCOMPONENT_2_SHIFT) |
				  (BRW_VFCOMPONENT_STORE_0 <<
				   VE1_VFCOMPONENT_3_SHIFT));
d1912 6
a1917 6
			/* Set up our vertex elements, sourced from the single vertex buffer.
			 * that will be set up later.
			 */
			OUT_BATCH(BRW_3DSTATE_VERTEX_ELEMENTS |
				  ((2 * (1 + nelem)) - 1));
		}
d1919 6
a1924 5
		/* x,y */
		OUT_BATCH((0 << VE0_VERTEX_BUFFER_INDEX_SHIFT) |
			  VE0_VALID |
			  (BRW_SURFACEFORMAT_R32G32_FLOAT << VE0_FORMAT_SHIFT) |
			  (0 << VE0_OFFSET_SHIFT));
d1926 6
a1931 47
		if (IS_IGDNG(intel))
			OUT_BATCH((BRW_VFCOMPONENT_STORE_SRC <<
				   VE1_VFCOMPONENT_0_SHIFT) |
				  (BRW_VFCOMPONENT_STORE_SRC <<
				   VE1_VFCOMPONENT_1_SHIFT) |
				  (BRW_VFCOMPONENT_STORE_1_FLT <<
				   VE1_VFCOMPONENT_2_SHIFT) |
				  (BRW_VFCOMPONENT_STORE_1_FLT <<
				   VE1_VFCOMPONENT_3_SHIFT));
		else
			OUT_BATCH((BRW_VFCOMPONENT_STORE_SRC <<
				   VE1_VFCOMPONENT_0_SHIFT) |
				  (BRW_VFCOMPONENT_STORE_SRC <<
				   VE1_VFCOMPONENT_1_SHIFT) |
				  (BRW_VFCOMPONENT_STORE_1_FLT <<
				   VE1_VFCOMPONENT_2_SHIFT) |
				  (BRW_VFCOMPONENT_STORE_1_FLT <<
				   VE1_VFCOMPONENT_3_SHIFT) | (4 <<
							       VE1_DESTINATION_ELEMENT_OFFSET_SHIFT));
		/* u0, v0, w0 */
		OUT_BATCH((0 << VE0_VERTEX_BUFFER_INDEX_SHIFT) | VE0_VALID | (src_format << VE0_FORMAT_SHIFT) | ((2 * 4) << VE0_OFFSET_SHIFT));	/* offset vb in bytes */

		if (IS_IGDNG(intel))
			OUT_BATCH((BRW_VFCOMPONENT_STORE_SRC <<
				   VE1_VFCOMPONENT_0_SHIFT) |
				  (BRW_VFCOMPONENT_STORE_SRC <<
				   VE1_VFCOMPONENT_1_SHIFT) | (w_component <<
							       VE1_VFCOMPONENT_2_SHIFT)
				  | (BRW_VFCOMPONENT_STORE_1_FLT <<
				     VE1_VFCOMPONENT_3_SHIFT));
		else
			OUT_BATCH((BRW_VFCOMPONENT_STORE_SRC << VE1_VFCOMPONENT_0_SHIFT) | (BRW_VFCOMPONENT_STORE_SRC << VE1_VFCOMPONENT_1_SHIFT) | (w_component << VE1_VFCOMPONENT_2_SHIFT) | (BRW_VFCOMPONENT_STORE_1_FLT << VE1_VFCOMPONENT_3_SHIFT) | ((4 + 4) << VE1_DESTINATION_ELEMENT_OFFSET_SHIFT));	/* VUE offset in dwords */
		/* u1, v1, w1 */
		if (mask) {
			OUT_BATCH((0 << VE0_VERTEX_BUFFER_INDEX_SHIFT) | VE0_VALID | (src_format << VE0_FORMAT_SHIFT) | (((2 + selem) * 4) << VE0_OFFSET_SHIFT));	/* vb offset in bytes */

			if (IS_IGDNG(intel))
				OUT_BATCH((BRW_VFCOMPONENT_STORE_SRC <<
					   VE1_VFCOMPONENT_0_SHIFT) |
					  (BRW_VFCOMPONENT_STORE_SRC <<
					   VE1_VFCOMPONENT_1_SHIFT) |
					  (w_component <<
					   VE1_VFCOMPONENT_2_SHIFT) |
					  (BRW_VFCOMPONENT_STORE_1_FLT <<
					   VE1_VFCOMPONENT_3_SHIFT));
			else
				OUT_BATCH((BRW_VFCOMPONENT_STORE_SRC << VE1_VFCOMPONENT_0_SHIFT) | (BRW_VFCOMPONENT_STORE_SRC << VE1_VFCOMPONENT_1_SHIFT) | (w_component << VE1_VFCOMPONENT_2_SHIFT) | (BRW_VFCOMPONENT_STORE_1_FLT << VE1_VFCOMPONENT_3_SHIFT) | ((4 + 4 + 4) << VE1_DESTINATION_ELEMENT_OFFSET_SHIFT));	/* VUE offset in dwords */
a1933 1
}
d1935 25
a1959 24
/**
 * Returns whether the current set of composite state plus vertex buffer is
 * expected to fit in the aperture.
 */
static Bool i965_composite_check_aperture(ScrnInfoPtr scrn)
{
	intel_screen_private *intel = intel_get_screen_private(scrn);
	struct gen4_render_state *render_state = intel->gen4_render_state;
	gen4_composite_op *composite_op = &render_state->composite_op;
	drm_intel_bo *bo_table[] = {
		intel->batch_bo,
		composite_op->binding_table_bo,
		render_state->vertex_buffer_bo,
		render_state->vs_state_bo,
		render_state->sf_state_bo,
		render_state->sf_mask_state_bo,
		render_state->wm_state_bo[composite_op->wm_kernel]
		    [composite_op->src_filter]
		    [composite_op->src_extend]
		    [composite_op->mask_filter]
		    [composite_op->mask_extend],
		render_state->cc_state_bo,
		render_state->sip_kernel_bo,
	};
d1961 12
a1972 2
	return drm_intel_bufmgr_check_aperture_space(bo_table,
						     ARRAY_SIZE(bo_table)) == 0;
d1983 1
a1983 8
	gen4_composite_op *composite_op;
	uint32_t *binding_table;
	drm_intel_bo *binding_table_bo, *surface_state_bo;

	if (render_state == NULL) 
		return FALSE;

	composite_op = &render_state->composite_op;
d1987 1
a1987 1
	if (composite_op->src_filter < 0) {
d1994 1
a1994 1
	if (composite_op->src_extend < 0) {
d2019 1
a2019 1
		if (composite_op->mask_filter < 0) {
d2026 1
a2026 1
		if (composite_op->mask_extend < 0) {
d2032 2
a2033 2
		composite_op->mask_filter = SAMPLER_STATE_FILTER_NEAREST;
		composite_op->mask_extend = SAMPLER_STATE_EXTEND_NONE;
d2037 2
a2038 2
	if(i830_uxa_pixmap_is_dirty(source) ||
	   (mask && i830_uxa_pixmap_is_dirty(mask)))
a2040 62

	/* Set up the surface states. */
	surface_state_bo = dri_bo_alloc(intel->bufmgr, "surface_state",
					3 * sizeof(brw_surface_state_padded),
					4096);
	if (dri_bo_map(surface_state_bo, 1) != 0) {
		dri_bo_unreference(surface_state_bo);
		return FALSE;
	}
	/* Set up the state buffer for the destination surface */
	i965_set_picture_surface_state(intel, surface_state_bo, 0,
				       dest_picture, dest, TRUE);
	/* Set up the source surface state buffer */
	i965_set_picture_surface_state(intel, surface_state_bo, 1,
				       source_picture, source, FALSE);
	if (mask) {
		/* Set up the mask surface state buffer */
		i965_set_picture_surface_state(intel, surface_state_bo, 2,
					       mask_picture, mask, FALSE);
	}
	dri_bo_unmap(surface_state_bo);

	/* Set up the binding table of surface indices to surface state. */
	binding_table_bo = dri_bo_alloc(intel->bufmgr, "binding_table",
					3 * sizeof(uint32_t), 4096);
	if (dri_bo_map(binding_table_bo, 1) != 0) {
		dri_bo_unreference(binding_table_bo);
		dri_bo_unreference(surface_state_bo);
		return FALSE;
	}

	binding_table = binding_table_bo->virtual;
	binding_table[0] = intel_emit_reloc(binding_table_bo,
					    0 * sizeof(uint32_t),
					    surface_state_bo,
					    0 *
					    sizeof(brw_surface_state_padded),
					    I915_GEM_DOMAIN_INSTRUCTION, 0);

	binding_table[1] = intel_emit_reloc(binding_table_bo,
					    1 * sizeof(uint32_t),
					    surface_state_bo,
					    1 *
					    sizeof(brw_surface_state_padded),
					    I915_GEM_DOMAIN_INSTRUCTION, 0);

	if (mask) {
		binding_table[2] = intel_emit_reloc(binding_table_bo,
						    2 * sizeof(uint32_t),
						    surface_state_bo,
						    2 *
						    sizeof
						    (brw_surface_state_padded),
						    I915_GEM_DOMAIN_INSTRUCTION,
						    0);
	} else {
		binding_table[2] = 0;
	}
	dri_bo_unmap(binding_table_bo);
	/* All refs to surface_state are now contained in binding_table_bo. */
	drm_intel_bo_unreference(surface_state_bo);

a2047 2
	drm_intel_bo_unreference(composite_op->binding_table_bo);
	composite_op->binding_table_bo = binding_table_bo;
d2049 2
a2050 2
	intel->scale_units[0][0] = source->drawable.width;
	intel->scale_units[0][1] = source->drawable.height;
d2053 1
a2053 1
	composite_op->is_affine = i830_transform_is_affine(intel->transform[0]);
d2061 2
a2062 2
		intel->scale_units[1][0] = mask->drawable.width;
		intel->scale_units[1][1] = mask->drawable.height;
d2064 1
a2064 1
		    i830_transform_is_affine(intel->transform[1]);
d2100 17
a2116 3
	if (!i965_composite_check_aperture(scrn)) {
		intel_batch_submit(scrn, FALSE);
		if (!i965_composite_check_aperture(scrn)) {
d2124 4
d2133 1
a2133 1
static drm_intel_bo *i965_get_vb_space(ScrnInfoPtr scrn)
d2135 11
a2145 2
	intel_screen_private *intel = intel_get_screen_private(scrn);
	struct gen4_render_state *render_state = intel->gen4_render_state;
d2147 2
a2148 2
	/* If the vertex buffer is too full, then we free the old and a new one
	 * gets made.
d2150 48
a2197 12
	if (render_state->vb_offset + VERTEX_FLOATS_PER_COMPOSITE >
	    VERTEX_BUFFER_SIZE) {
		drm_intel_bo_unreference(render_state->vertex_buffer_bo);
		render_state->vertex_buffer_bo = NULL;
	}

	/* Alloc a new vertex buffer if necessary. */
	if (render_state->vertex_buffer_bo == NULL) {
		render_state->vertex_buffer_bo =
		    drm_intel_bo_alloc(intel->bufmgr, "vb",
				       sizeof(gen4_vertex_buffer), 4096);
		render_state->vb_offset = 0;
a2198 3

	drm_intel_bo_reference(render_state->vertex_buffer_bo);
	return render_state->vertex_buffer_bo;
a2206 7
	struct gen4_render_state *render_state = intel->gen4_render_state;
	Bool has_mask;
	float src_x[3], src_y[3], src_w[3], mask_x[3], mask_y[3], mask_w[3];
	int i;
	drm_intel_bo *vb_bo;
	float vb[24]; /* 3 * (2 dst + 3 src + 3 mask) */
	Bool is_affine = render_state->composite_op.is_affine;
d2208 8
a2215 29
	if (is_affine) {
		if (!i830_get_transformed_coordinates(srcX, srcY,
						      intel->transform[0],
						      &src_x[0], &src_y[0]))
			return;
		if (!i830_get_transformed_coordinates(srcX, srcY + h,
						      intel->transform[0],
						      &src_x[1], &src_y[1]))
			return;
		if (!i830_get_transformed_coordinates(srcX + w, srcY + h,
						      intel->transform[0],
						      &src_x[2], &src_y[2]))
			return;
	} else {
		if (!i830_get_transformed_coordinates_3d(srcX, srcY,
							 intel->transform[0],
							 &src_x[0], &src_y[0],
							 &src_w[0]))
			return;
		if (!i830_get_transformed_coordinates_3d(srcX, srcY + h,
							 intel->transform[0],
							 &src_x[1], &src_y[1],
							 &src_w[1]))
			return;
		if (!i830_get_transformed_coordinates_3d(srcX + w, srcY + h,
							 intel->transform[0],
							 &src_x[2], &src_y[2],
							 &src_w[2]))
			return;
d2218 17
a2234 21
	if (intel->scale_units[1][0] == -1 || intel->scale_units[1][1] == -1) {
		has_mask = FALSE;
	} else {
		has_mask = TRUE;
		if (is_affine) {
			if (!i830_get_transformed_coordinates(maskX, maskY,
							      intel->
							      transform[1],
							      &mask_x[0],
							      &mask_y[0]))
				return;
			if (!i830_get_transformed_coordinates(maskX, maskY + h,
							      intel->
							      transform[1],
							      &mask_x[1],
							      &mask_y[1]))
				return;
			if (!i830_get_transformed_coordinates
			    (maskX + w, maskY + h, intel->transform[1],
			     &mask_x[2], &mask_y[2]))
				return;
d2236 5
a2240 15
			if (!i830_get_transformed_coordinates_3d(maskX, maskY,
								 intel->
								 transform[1],
								 &mask_x[0],
								 &mask_y[0],
								 &mask_w[0]))
				return;
			if (!i830_get_transformed_coordinates_3d
			    (maskX, maskY + h, intel->transform[1], &mask_x[1],
			     &mask_y[1], &mask_w[1]))
				return;
			if (!i830_get_transformed_coordinates_3d
			    (maskX + w, maskY + h, intel->transform[1],
			     &mask_x[2], &mask_y[2], &mask_w[2]))
				return;
d2242 20
a2263 82
	vb_bo = i965_get_vb_space(scrn);
	if (vb_bo == NULL)
		return;
	i = 0;
	/* rect (x2,y2) */
	vb[i++] = (float)(dstX + w);
	vb[i++] = (float)(dstY + h);
	vb[i++] = src_x[2] / intel->scale_units[0][0];
	vb[i++] = src_y[2] / intel->scale_units[0][1];
	if (!is_affine)
		vb[i++] = src_w[2];
	if (has_mask) {
		vb[i++] = mask_x[2] / intel->scale_units[1][0];
		vb[i++] = mask_y[2] / intel->scale_units[1][1];
		if (!is_affine)
			vb[i++] = mask_w[2];
	}

	/* rect (x1,y2) */
	vb[i++] = (float)dstX;
	vb[i++] = (float)(dstY + h);
	vb[i++] = src_x[1] / intel->scale_units[0][0];
	vb[i++] = src_y[1] / intel->scale_units[0][1];
	if (!is_affine)
		vb[i++] = src_w[1];
	if (has_mask) {
		vb[i++] = mask_x[1] / intel->scale_units[1][0];
		vb[i++] = mask_y[1] / intel->scale_units[1][1];
		if (!is_affine)
			vb[i++] = mask_w[1];
	}

	/* rect (x1,y1) */
	vb[i++] = (float)dstX;
	vb[i++] = (float)dstY;
	vb[i++] = src_x[0] / intel->scale_units[0][0];
	vb[i++] = src_y[0] / intel->scale_units[0][1];
	if (!is_affine)
		vb[i++] = src_w[0];
	if (has_mask) {
		vb[i++] = mask_x[0] / intel->scale_units[1][0];
		vb[i++] = mask_y[0] / intel->scale_units[1][1];
		if (!is_affine)
			vb[i++] = mask_w[0];
	}
	drm_intel_bo_subdata(vb_bo, render_state->vb_offset * 4, i * 4, vb);

	if (!i965_composite_check_aperture(scrn))
		intel_batch_submit(scrn, FALSE);

	intel_batch_start_atomic(scrn, 200);
	if (intel->needs_render_state_emit)
		i965_emit_composite_state(scrn);

	OUT_BATCH(MI_FLUSH);
	/* Set up the pointer to our (single) vertex buffer */
	OUT_BATCH(BRW_3DSTATE_VERTEX_BUFFERS | 3);
	OUT_BATCH((0 << VB0_BUFFER_INDEX_SHIFT) |
		  VB0_VERTEXDATA |
		  (render_state->vertex_size << VB0_BUFFER_PITCH_SHIFT));
	OUT_RELOC(vb_bo, I915_GEM_DOMAIN_VERTEX, 0,
		  render_state->vb_offset * 4);

	if (IS_IGDNG(intel))
		OUT_RELOC(vb_bo, I915_GEM_DOMAIN_VERTEX, 0,
			  render_state->vb_offset * 4 + i * 4);
	else
		OUT_BATCH(3);

	OUT_BATCH(0);		// ignore for VERTEXDATA, but still there

	OUT_BATCH(BRW_3DPRIMITIVE | BRW_3DPRIMITIVE_VERTEX_SEQUENTIAL | (_3DPRIM_RECTLIST << BRW_3DPRIMITIVE_TOPOLOGY_SHIFT) | (0 << 9) |	/* CTG - indirect vertex count */
		  4);
	OUT_BATCH(3);		/* vertex count per instance */
	OUT_BATCH(0);		/* start vertex offset */
	OUT_BATCH(1);		/* single instance */
	OUT_BATCH(0);		/* start instance location */
	OUT_BATCH(0);		/* index buffer offset, ignored */

	render_state->vb_offset += i;
	drm_intel_bo_unreference(vb_bo);

d2267 1
a2267 1
void i965_batch_flush_notify(ScrnInfoPtr scrn)
d2269 12
a2280 2
	intel_screen_private *intel = intel_get_screen_private(scrn);
	struct gen4_render_state *render_state = intel->gen4_render_state;
d2282 1
a2282 9
	/* Once a batch is emitted, we never want to map again any buffer
	 * object being referenced by that batch, (which would be very
	 * expensive). */
	if (render_state->vertex_buffer_bo) {
		dri_bo_unreference(render_state->vertex_buffer_bo);
		render_state->vertex_buffer_bo = NULL;
	}

	intel->needs_render_state_emit = TRUE;
d2291 2
a2292 1
	struct gen4_render_state *render_state;
d2297 7
d2305 1
a2305 1
		intel->gen4_render_state = calloc(sizeof(*render_state), 1);
d2307 2
a2308 2
	render_state = intel->gen4_render_state;
	render_state->vb_offset = 0;
d2310 4
a2313 1
	render_state->vs_state_bo = gen4_create_vs_unit_state(scrn);
d2316 2
a2317 2
	if (IS_IGDNG(intel)) {
		sf_kernel_bo = intel_bo_alloc_for_data(scrn,
d2323 1
a2323 1
		    intel_bo_alloc_for_data(scrn, sf_kernel_mask_static_gen5,
d2327 1
a2327 1
		sf_kernel_bo = intel_bo_alloc_for_data(scrn,
d2331 1
a2331 1
		sf_kernel_mask_bo = intel_bo_alloc_for_data(scrn,
d2337 2
a2338 3
	render_state->sf_state_bo = gen4_create_sf_state(scrn, sf_kernel_bo);
	render_state->sf_mask_state_bo = gen4_create_sf_state(scrn,
							      sf_kernel_mask_bo);
d2342 7
a2348 13
	for (m = 0; m < WM_KERNEL_COUNT; m++) {
		if (IS_IGDNG(intel))
			render_state->wm_kernel_bo[m] =
			    intel_bo_alloc_for_data(scrn,
						    wm_kernels_gen5[m].data,
						    wm_kernels_gen5[m].size,
						    "WM kernel gen5");
		else
			render_state->wm_kernel_bo[m] =
			    intel_bo_alloc_for_data(scrn,
						    wm_kernels[m].data,
						    wm_kernels[m].size,
						    "WM kernel");
d2354 5
a2358 5
	border_color_bo = sampler_border_color_create(scrn);
	for (i = 0; i < SAMPLER_STATE_FILTER_COUNT; i++) {
		for (j = 0; j < SAMPLER_STATE_EXTEND_COUNT; j++) {
			for (k = 0; k < SAMPLER_STATE_FILTER_COUNT; k++) {
				for (l = 0; l < SAMPLER_STATE_EXTEND_COUNT; l++) {
d2362 1
a2362 1
					    gen4_create_sampler_state(scrn,
d2367 7
a2373 23
					for (m = 0; m < WM_KERNEL_COUNT; m++) {
						if (IS_IGDNG(intel))
							render_state->
							    wm_state_bo[m][i][j]
							    [k][l] =
							    gen4_create_wm_state
							    (scrn,
							     wm_kernels_gen5[m].
							     has_mask,
							     render_state->
							     wm_kernel_bo[m],
							     sampler_state_bo);
						else
							render_state->
							    wm_state_bo[m][i][j]
							    [k][l] =
							    gen4_create_wm_state
							    (scrn,
							     wm_kernels[m].
							     has_mask,
							     render_state->
							     wm_kernel_bo[m],
							     sampler_state_bo);
d2375 1
a2375 2
					drm_intel_bo_unreference
					    (sampler_state_bo);
d2382 1
a2382 6
	render_state->cc_state_bo = gen4_create_cc_unit_state(scrn);
	render_state->sip_kernel_bo = intel_bo_alloc_for_data(scrn,
							      sip_kernel_static,
							      sizeof
							      (sip_kernel_static),
							      "sip kernel");
a2392 4
	gen4_composite_op *composite_op = &render_state->composite_op;

	drm_intel_bo_unreference(composite_op->binding_table_bo);
	drm_intel_bo_unreference(render_state->vertex_buffer_bo);
d2394 1
d2399 1
a2399 1
	for (i = 0; i < WM_KERNEL_COUNT; i++)
d2402 5
a2406 5
	for (i = 0; i < SAMPLER_STATE_FILTER_COUNT; i++)
		for (j = 0; j < SAMPLER_STATE_EXTEND_COUNT; j++)
			for (k = 0; k < SAMPLER_STATE_FILTER_COUNT; k++)
				for (l = 0; l < SAMPLER_STATE_EXTEND_COUNT; l++)
					for (m = 0; m < WM_KERNEL_COUNT; m++)
d2412 6
d2419 4
a2422 1
	drm_intel_bo_unreference(render_state->sip_kernel_bo);
d2426 459
@


1.6
log
@Update the intel driver to (mostly) a backport of 2.12.

It is missing a few commits that I have yet to verify (ones that try and
continue if we lock the gpu rendering engine and can't reset it, for
example) taht will be verified and sent out for extra testing soon.

Should contain a bunch of speedups and some correctness improvements
(though rendercheck still gives some errors that I am looking into).

This has been in snaps since the first day of c2k10, any known issues
with just this driver have (to my knowledge) been fixed since. A problem
with macbooks pointed out by otto happens with both this and the in-tree
driver and thus doesn't stop this moving forward.

As well as the 2.12 improvements, this driver also has a backport
(partially aided by the backports in RHEL 5 kindly provided by Dave
Airlie) from the kms code of modesetting support for ironlake (arrandale
and clarkdale: the IGDs build into intel nehalem cpu dies) which has
been tested on a number of chipsets. Note that Display port and eDP
displays have not yet been worked on (and probably won't until I can
find a displayport monitor), but VGA and lvds at least are known to
work, sure beats vesa.

"no objection on my side" matthieu@@, prodding (as always) from princess
marco.
@
text
@d1480 1
a1480 1
	gen4_composite_op *composite_op = &render_state->composite_op;
d1483 5
@


1.5
log
@Update the intel driver to 2.9.1 plus backports.

2.9.1 is the last version of the intel DDX that supports UMS (User
modesetting), with 2.10 onwards being purely KMS only. As such, this
driver contains backports of almost every correctness or performance
related fix to the rendering layer in later intel drivers. This driver
*REQUIRES* a GEM enabled kernel. it claims to support non-gem mode but
this is essentially unmaintained and due to the way the abstraciton
works is slow, if it works at all (it often does not). You have been
warned.

tested by many many people on tech over the last few weeks.
@
text
@d186 43
a228 2
static Bool i965_check_composite_texture(ScrnInfoPtr scrn, PicturePtr picture,
					 int unit)
d231 1
d240 1
d252 1
d267 1
d274 2
d278 1
a278 1
	return TRUE;
a280 48
Bool
i965_check_composite(int op, PicturePtr source_picture, PicturePtr mask_picture,
		     PicturePtr dest_picture)
{
	ScrnInfoPtr scrn = xf86Screens[dest_picture->pDrawable->pScreen->myNum];
	uint32_t tmp1;

	/* Check for unsupported compositing operations. */
	if (op >= sizeof(i965_blend_op) / sizeof(i965_blend_op[0])) {
		intel_debug_fallback(scrn,
				     "Unsupported Composite op 0x%x\n", op);
		return FALSE;
	}

	if (mask_picture && mask_picture->componentAlpha &&
	    PICT_FORMAT_RGB(mask_picture->format)) {
		/* Check if it's component alpha that relies on a source alpha and on
		 * the source value.  We can only get one of those into the single
		 * source value that we get to blend with.
		 */
		if (i965_blend_op[op].src_alpha &&
		    (i965_blend_op[op].src_blend != BRW_BLENDFACTOR_ZERO)) {
			intel_debug_fallback(scrn,
					     "Component alpha not supported "
					     "with source alpha and source "
					     "value blending.\n");
			return FALSE;
		}
	}

	if (!i965_check_composite_texture(scrn, source_picture, 0)) {
		intel_debug_fallback(scrn, "Check Src picture texture\n");
		return FALSE;
	}
	if (mask_picture != NULL
	    && !i965_check_composite_texture(scrn, mask_picture, 1)) {
		intel_debug_fallback(scrn, "Check Mask picture texture\n");
		return FALSE;
	}

	if (!i965_get_dest_format(dest_picture, &tmp1)) {
		intel_debug_fallback(scrn, "Get Color buffer format\n");
		return FALSE;
	}

	return TRUE;

}
d1145 6
d1175 1
a1176 5
		if (IS_IGDNG(intel))
			ATOMIC_BATCH(14);
		else
			ATOMIC_BATCH(12);

d1219 7
a1225 1
		ADVANCE_BATCH();
a1229 1
		ATOMIC_BATCH(26);
a1323 1
		ADVANCE_BATCH();
a1349 1
			ATOMIC_BATCH(mask ? 9 : 7);
a1378 1
			ATOMIC_BATCH(mask ? 7 : 5);
a1439 2

		ADVANCE_BATCH();
d1500 16
d1535 6
d1664 1
a1664 1
		intel_batch_submit(scrn);
a1672 4
	if(i830_uxa_pixmap_is_dirty(source) ||
	   (mask && i830_uxa_pixmap_is_dirty(mask)))
		intel_batch_emit_flush(scrn);

d1837 1
a1837 1
		intel_batch_submit(scrn);
a1842 1
	ATOMIC_BATCH(12);
a1866 1
	ADVANCE_BATCH();
@


1.4
log
@update to xf86-video-intel 2.7.1. Tested by many.
@
text
@d55 4
a58 4
    Bool dst_alpha;
    Bool src_alpha;
    uint32_t src_blend;
    uint32_t dst_blend;
d62 2
a63 2
    int fmt;
    uint32_t card_fmt;
d70 26
a95 26
    /* Clear */
    {0, 0, BRW_BLENDFACTOR_ZERO,          BRW_BLENDFACTOR_ZERO},
    /* Src */
    {0, 0, BRW_BLENDFACTOR_ONE,           BRW_BLENDFACTOR_ZERO},
    /* Dst */
    {0, 0, BRW_BLENDFACTOR_ZERO,          BRW_BLENDFACTOR_ONE},
    /* Over */
    {0, 1, BRW_BLENDFACTOR_ONE,           BRW_BLENDFACTOR_INV_SRC_ALPHA},
    /* OverReverse */
    {1, 0, BRW_BLENDFACTOR_INV_DST_ALPHA, BRW_BLENDFACTOR_ONE},
    /* In */
    {1, 0, BRW_BLENDFACTOR_DST_ALPHA,     BRW_BLENDFACTOR_ZERO},
    /* InReverse */
    {0, 1, BRW_BLENDFACTOR_ZERO,          BRW_BLENDFACTOR_SRC_ALPHA},
    /* Out */
    {1, 0, BRW_BLENDFACTOR_INV_DST_ALPHA, BRW_BLENDFACTOR_ZERO},
    /* OutReverse */
    {0, 1, BRW_BLENDFACTOR_ZERO,          BRW_BLENDFACTOR_INV_SRC_ALPHA},
    /* Atop */
    {1, 1, BRW_BLENDFACTOR_DST_ALPHA,     BRW_BLENDFACTOR_INV_SRC_ALPHA},
    /* AtopReverse */
    {1, 1, BRW_BLENDFACTOR_INV_DST_ALPHA, BRW_BLENDFACTOR_SRC_ALPHA},
    /* Xor */
    {1, 1, BRW_BLENDFACTOR_INV_DST_ALPHA, BRW_BLENDFACTOR_INV_SRC_ALPHA},
    /* Add */
    {0, 0, BRW_BLENDFACTOR_ONE,           BRW_BLENDFACTOR_ONE},
d97 1
d111 103
a213 103
    {PICT_a8r8g8b8, BRW_SURFACEFORMAT_B8G8R8A8_UNORM },
    {PICT_x8r8g8b8, BRW_SURFACEFORMAT_B8G8R8X8_UNORM },
    {PICT_a8b8g8r8, BRW_SURFACEFORMAT_R8G8B8A8_UNORM },
    {PICT_x8b8g8r8, BRW_SURFACEFORMAT_R8G8B8X8_UNORM },
    {PICT_r5g6b5,   BRW_SURFACEFORMAT_B5G6R5_UNORM   },
    {PICT_a1r5g5b5, BRW_SURFACEFORMAT_B5G5R5A1_UNORM },
    {PICT_a8,       BRW_SURFACEFORMAT_A8_UNORM	 },
};

static void i965_get_blend_cntl(int op, PicturePtr pMask, uint32_t dst_format,
				uint32_t *sblend, uint32_t *dblend)
{

    *sblend = i965_blend_op[op].src_blend;
    *dblend = i965_blend_op[op].dst_blend;

    /* If there's no dst alpha channel, adjust the blend op so that we'll treat
     * it as always 1.
     */
    if (PICT_FORMAT_A(dst_format) == 0 && i965_blend_op[op].dst_alpha) {
        if (*sblend == BRW_BLENDFACTOR_DST_ALPHA)
            *sblend = BRW_BLENDFACTOR_ONE;
        else if (*sblend == BRW_BLENDFACTOR_INV_DST_ALPHA)
            *sblend = BRW_BLENDFACTOR_ZERO;
    }

    /* If the source alpha is being used, then we should only be in a case where
     * the source blend factor is 0, and the source blend value is the mask
     * channels multiplied by the source picture's alpha.
     */
    if (pMask && pMask->componentAlpha && PICT_FORMAT_RGB(pMask->format)
            && i965_blend_op[op].src_alpha) {
        if (*dblend == BRW_BLENDFACTOR_SRC_ALPHA) {
	    *dblend = BRW_BLENDFACTOR_SRC_COLOR;
        } else if (*dblend == BRW_BLENDFACTOR_INV_SRC_ALPHA) {
	    *dblend = BRW_BLENDFACTOR_INV_SRC_COLOR;
        }
    }

}

static Bool i965_get_dest_format(PicturePtr pDstPicture, uint32_t *dst_format)
{
    ScrnInfoPtr pScrn = xf86Screens[pDstPicture->pDrawable->pScreen->myNum];

    switch (pDstPicture->format) {
    case PICT_a8r8g8b8:
    case PICT_x8r8g8b8:
        *dst_format = BRW_SURFACEFORMAT_B8G8R8A8_UNORM;
        break;
    case PICT_r5g6b5:
        *dst_format = BRW_SURFACEFORMAT_B5G6R5_UNORM;
        break;
    case PICT_a1r5g5b5:
    	*dst_format = BRW_SURFACEFORMAT_B5G5R5A1_UNORM;
	break;
    case PICT_x1r5g5b5:
        *dst_format = BRW_SURFACEFORMAT_B5G5R5X1_UNORM;
        break;
    case PICT_a8:
        *dst_format = BRW_SURFACEFORMAT_A8_UNORM;
        break;
    case PICT_a4r4g4b4:
    case PICT_x4r4g4b4:
	*dst_format = BRW_SURFACEFORMAT_B4G4R4A4_UNORM;
	break;
    default:
        I830FALLBACK("Unsupported dest format 0x%x\n",
		     (int)pDstPicture->format);
    }

    return TRUE;
}

static Bool i965_check_composite_texture(PicturePtr pPict, int unit)
{
    ScrnInfoPtr pScrn = xf86Screens[pPict->pDrawable->pScreen->myNum];
    int w = pPict->pDrawable->width;
    int h = pPict->pDrawable->height;
    int i;

    if ((w > 8192) || (h > 8192))
        I830FALLBACK("Picture w/h too large (%dx%d)\n", w, h);

    for (i = 0; i < sizeof(i965_tex_formats) / sizeof(i965_tex_formats[0]);
	 i++)
    {
        if (i965_tex_formats[i].fmt == pPict->format)
            break;
    }
    if (i == sizeof(i965_tex_formats) / sizeof(i965_tex_formats[0]))
        I830FALLBACK("Unsupported picture format 0x%x\n",
		     (int)pPict->format);

    if (pPict->repeatType > RepeatReflect)
	I830FALLBACK("extended repeat (%d) not supported\n",
		     pPict->repeatType);

    if (pPict->filter != PictFilterNearest &&
        pPict->filter != PictFilterBilinear)
    {
        I830FALLBACK("Unsupported filter 0x%x\n", pPict->filter);
    }
d215 17
a231 1
    return TRUE;
d235 2
a236 2
i965_check_composite(int op, PicturePtr pSrcPicture, PicturePtr pMaskPicture,
		     PicturePtr pDstPicture)
d238 9
a246 2
    ScrnInfoPtr pScrn = xf86Screens[pDstPicture->pDrawable->pScreen->myNum];
    uint32_t tmp1;
d248 14
a261 15
    /* Check for unsupported compositing operations. */
    if (op >= sizeof(i965_blend_op) / sizeof(i965_blend_op[0]))
        I830FALLBACK("Unsupported Composite op 0x%x\n", op);

    if (pMaskPicture && pMaskPicture->componentAlpha &&
            PICT_FORMAT_RGB(pMaskPicture->format)) {
        /* Check if it's component alpha that relies on a source alpha and on
         * the source value.  We can only get one of those into the single
         * source value that we get to blend with.
         */
        if (i965_blend_op[op].src_alpha &&
            (i965_blend_op[op].src_blend != BRW_BLENDFACTOR_ZERO))
	{
	    I830FALLBACK("Component alpha not supported with source "
			 "alpha and source value blending.\n");
a262 1
    } 
d264 9
a272 4
    if (!i965_check_composite_texture(pSrcPicture, 0))
        I830FALLBACK("Check Src picture texture\n");
    if (pMaskPicture != NULL && !i965_check_composite_texture(pMaskPicture, 1))
        I830FALLBACK("Check Mask picture texture\n");
d274 4
a277 2
    if (!i965_get_dest_format(pDstPicture, &tmp1))
	I830FALLBACK("Get Color buffer format\n");
d279 1
a279 1
    return TRUE;
a282 2
#define ALIGN(i,m)    (((i) + (m) - 1) & ~((m) - 1))
#define MIN(a,b) ((a) < (b) ? (a) : (b))
d291 2
a292 2
#define URB_VS_ENTRY_SIZE     1	  // each 512-bit row
#define URB_VS_ENTRIES	      8	  // we needs at least 8 entries
d305 1
a305 1
    { 0x00000030, 0x20000108, 0x00001220, 0x00000000 },
d307 1
a307 1
    { 0x0040007e, 0x20000c21, 0x00690000, 0x00000000 },
d309 1
a309 1
    { 0x0040007e, 0x20000c21, 0x00690000, 0x00000000 },
d311 1
a311 1
    { 0x0040007e, 0x20000c21, 0x00690000, 0x00000000 },
d313 1
a313 1
    { 0x0040007e, 0x20000c21, 0x00690000, 0x00000000 },
d315 1
a315 1
    { 0x0040007e, 0x20000c21, 0x00690000, 0x00000000 },
d317 1
a317 1
    { 0x0040007e, 0x20000c21, 0x00690000, 0x00000000 },
d319 1
a319 1
    { 0x0040007e, 0x20000c21, 0x00690000, 0x00000000 },
d321 1
a321 1
    { 0x0040007e, 0x20000c21, 0x00690000, 0x00000000 },
d323 1
a323 1
    { 0x0040007e, 0x20000c21, 0x00690000, 0x00000000 },
d346 1
a346 1
static const uint32_t ps_kernel_nomask_affine_static [][4] = {
d353 1
a353 1
static const uint32_t ps_kernel_nomask_projective_static [][4] = {
d360 1
a360 1
static const uint32_t ps_kernel_maskca_affine_static [][4] = {
d370 1
a370 1
static const uint32_t ps_kernel_maskca_projective_static [][4] = {
d380 1
a380 1
static const uint32_t ps_kernel_maskca_srcalpha_affine_static [][4] = {
d390 1
a390 1
static const uint32_t ps_kernel_maskca_srcalpha_projective_static [][4] = {
d400 1
a400 1
static const uint32_t ps_kernel_masknoca_affine_static [][4] = {
d410 1
a410 1
static const uint32_t ps_kernel_masknoca_projective_static [][4] = {
d420 83
d517 3
a519 3
    SAMPLER_STATE_FILTER_NEAREST,
    SAMPLER_STATE_FILTER_BILINEAR,
    SAMPLER_STATE_FILTER_COUNT
d523 5
a527 5
    SAMPLER_STATE_EXTEND_NONE,
    SAMPLER_STATE_EXTEND_REPEAT,
    SAMPLER_STATE_EXTEND_PAD,
    SAMPLER_STATE_EXTEND_REFLECT,
    SAMPLER_STATE_EXTEND_COUNT
d531 9
a539 9
    WM_KERNEL_NOMASK_AFFINE,
    WM_KERNEL_NOMASK_PROJECTIVE,
    WM_KERNEL_MASKCA_AFFINE,
    WM_KERNEL_MASKCA_PROJECTIVE,
    WM_KERNEL_MASKCA_SRCALPHA_AFFINE,
    WM_KERNEL_MASKCA_SRCALPHA_PROJECTIVE,
    WM_KERNEL_MASKNOCA_AFFINE,
    WM_KERNEL_MASKNOCA_PROJECTIVE,
    WM_KERNEL_COUNT
d545 22
a566 20
    void *data;
    unsigned int size;
    Bool has_mask;
} wm_kernels[] = {
    KERNEL(WM_KERNEL_NOMASK_AFFINE,
	   ps_kernel_nomask_affine_static, FALSE),
    KERNEL(WM_KERNEL_NOMASK_PROJECTIVE,
	   ps_kernel_nomask_projective_static, FALSE),
    KERNEL(WM_KERNEL_MASKCA_AFFINE,
	   ps_kernel_maskca_affine_static, TRUE),
    KERNEL(WM_KERNEL_MASKCA_PROJECTIVE,
	   ps_kernel_maskca_projective_static, TRUE),
    KERNEL(WM_KERNEL_MASKCA_SRCALPHA_AFFINE,
	   ps_kernel_maskca_srcalpha_affine_static, TRUE),
    KERNEL(WM_KERNEL_MASKCA_SRCALPHA_PROJECTIVE,
	   ps_kernel_maskca_srcalpha_projective_static, TRUE),
    KERNEL(WM_KERNEL_MASKNOCA_AFFINE,
	   ps_kernel_masknoca_affine_static, TRUE),
    KERNEL(WM_KERNEL_MASKNOCA_PROJECTIVE,
	   ps_kernel_masknoca_projective_static, TRUE),
d568 20
d591 2
a592 2
    struct brw_cc_unit_state state;
    char pad[64 - sizeof (struct brw_cc_unit_state)];
d596 2
a597 2
    struct brw_surface_state state;
    char pad[32 - sizeof (struct brw_surface_state)];
d601 3
a603 3
    /* Index by [src_blend][dst_blend] */
    brw_cc_unit_state_padded cc_state[BRW_BLENDFACTOR_COUNT]
				     [BRW_BLENDFACTOR_COUNT];
d609 8
a616 14
    int		op;
    PicturePtr	source_picture;
    PicturePtr	mask_picture;
    PicturePtr	dest_picture;
    PixmapPtr	source;
    PixmapPtr	mask;
    PixmapPtr	dest;
    drm_intel_bo *binding_table_bo;
    sampler_state_filter_t src_filter;
    sampler_state_filter_t mask_filter;
    sampler_state_extend_t src_extend;
    sampler_state_extend_t mask_extend;
    Bool is_affine;
    wm_kernel_t wm_kernel;
d621 10
a630 13
    drm_intel_bo *vs_state_bo;
    drm_intel_bo *sf_state_bo;
    drm_intel_bo *sf_mask_state_bo;
    drm_intel_bo *cc_state_bo;
    drm_intel_bo *wm_state_bo[WM_KERNEL_COUNT]
			     [SAMPLER_STATE_FILTER_COUNT]
			     [SAMPLER_STATE_EXTEND_COUNT]
			     [SAMPLER_STATE_FILTER_COUNT]
			     [SAMPLER_STATE_EXTEND_COUNT];
    drm_intel_bo *wm_kernel_bo[WM_KERNEL_COUNT];

    drm_intel_bo *sip_kernel_bo;
    dri_bo* vertex_buffer_bo;
d632 2
a633 1
    gen4_composite_op composite_op;
d635 1
a635 2
    int vb_offset;
    int vertex_size;
d637 2
a638 1
    Bool needs_state_emit;
d648 2
a649 2
static drm_intel_bo *
gen4_create_sf_state(ScrnInfoPtr scrn, drm_intel_bo *kernel_bo)
d651 63
a713 64
    I830Ptr pI830 = I830PTR(scrn);
    struct brw_sf_unit_state *sf_state;
    drm_intel_bo *sf_state_bo;

    sf_state_bo = drm_intel_bo_alloc(pI830->bufmgr, "gen4 SF state",
				     sizeof(*sf_state), 4096);
    drm_intel_bo_map(sf_state_bo, TRUE);
    sf_state = sf_state_bo->virtual;

    memset(sf_state, 0, sizeof(*sf_state));
    sf_state->thread0.grf_reg_count = BRW_GRF_BLOCKS(SF_KERNEL_NUM_GRF);
    sf_state->thread0.kernel_start_pointer =
	intel_emit_reloc(sf_state_bo,
			 offsetof(struct brw_sf_unit_state, thread0),
			 kernel_bo, sf_state->thread0.grf_reg_count << 1,
			 I915_GEM_DOMAIN_INSTRUCTION, 0) >> 6;
    sf_state->sf1.single_program_flow = 1;
    sf_state->sf1.binding_table_entry_count = 0;
    sf_state->sf1.thread_priority = 0;
    sf_state->sf1.floating_point_mode = 0; /* Mesa does this */
    sf_state->sf1.illegal_op_exception_enable = 1;
    sf_state->sf1.mask_stack_exception_enable = 1;
    sf_state->sf1.sw_exception_enable = 1;
    sf_state->thread2.per_thread_scratch_space = 0;
    /* scratch space is not used in our kernel */
    sf_state->thread2.scratch_space_base_pointer = 0;
    sf_state->thread3.const_urb_entry_read_length = 0; /* no const URBs */
    sf_state->thread3.const_urb_entry_read_offset = 0; /* no const URBs */
    sf_state->thread3.urb_entry_read_length = 1; /* 1 URB per vertex */
    /* don't smash vertex header, read start from dw8 */
    sf_state->thread3.urb_entry_read_offset = 1;
    sf_state->thread3.dispatch_grf_start_reg = 3;
    sf_state->thread4.max_threads = SF_MAX_THREADS - 1;
    sf_state->thread4.urb_entry_allocation_size = URB_SF_ENTRY_SIZE - 1;
    sf_state->thread4.nr_urb_entries = URB_SF_ENTRIES;
    sf_state->thread4.stats_enable = 1;
    sf_state->sf5.viewport_transform = FALSE; /* skip viewport */
    sf_state->sf6.cull_mode = BRW_CULLMODE_NONE;
    sf_state->sf6.scissor = 0;
    sf_state->sf7.trifan_pv = 2;
    sf_state->sf6.dest_org_vbias = 0x8;
    sf_state->sf6.dest_org_hbias = 0x8;

    drm_intel_bo_unmap(sf_state_bo);

    return sf_state_bo;
}

static drm_intel_bo *
sampler_border_color_create(ScrnInfoPtr scrn)
{
    struct brw_sampler_legacy_border_color sampler_border_color;

    /* Set up the sampler border color (always transparent black) */
    memset(&sampler_border_color, 0, sizeof(sampler_border_color));
    sampler_border_color.color[0] = 0; /* R */
    sampler_border_color.color[1] = 0; /* G */
    sampler_border_color.color[2] = 0; /* B */
    sampler_border_color.color[3] = 0; /* A */

    return intel_bo_alloc_for_data(scrn,
				   &sampler_border_color,
				   sizeof(sampler_border_color),
				   "gen4 render sampler border color");
d717 92
a808 91
sampler_state_init (drm_intel_bo *sampler_state_bo,
		    struct brw_sampler_state *sampler_state,
		    sampler_state_filter_t filter,
		    sampler_state_extend_t extend,
		    drm_intel_bo *border_color_bo)
{
    uint32_t sampler_state_offset;

    sampler_state_offset = (char *)sampler_state -
	(char *)sampler_state_bo->virtual;

    /* PS kernel use this sampler */
    memset(sampler_state, 0, sizeof(*sampler_state));

    sampler_state->ss0.lod_preclamp = 1; /* GL mode */

    /* We use the legacy mode to get the semantics specified by
     * the Render extension. */
    sampler_state->ss0.border_color_mode = BRW_BORDER_COLOR_MODE_LEGACY;

    switch(filter) {
    default:
    case SAMPLER_STATE_FILTER_NEAREST:
	sampler_state->ss0.min_filter = BRW_MAPFILTER_NEAREST;
	sampler_state->ss0.mag_filter = BRW_MAPFILTER_NEAREST;
	break;
    case SAMPLER_STATE_FILTER_BILINEAR:
	sampler_state->ss0.min_filter = BRW_MAPFILTER_LINEAR;
	sampler_state->ss0.mag_filter = BRW_MAPFILTER_LINEAR;
	break;
    }

    switch (extend) {
    default:
    case SAMPLER_STATE_EXTEND_NONE:
	sampler_state->ss1.r_wrap_mode = BRW_TEXCOORDMODE_CLAMP_BORDER;
	sampler_state->ss1.s_wrap_mode = BRW_TEXCOORDMODE_CLAMP_BORDER;
	sampler_state->ss1.t_wrap_mode = BRW_TEXCOORDMODE_CLAMP_BORDER;
	break;
    case SAMPLER_STATE_EXTEND_REPEAT:
	sampler_state->ss1.r_wrap_mode = BRW_TEXCOORDMODE_WRAP;
	sampler_state->ss1.s_wrap_mode = BRW_TEXCOORDMODE_WRAP;
	sampler_state->ss1.t_wrap_mode = BRW_TEXCOORDMODE_WRAP;
	break;
    case SAMPLER_STATE_EXTEND_PAD:
	sampler_state->ss1.r_wrap_mode = BRW_TEXCOORDMODE_CLAMP;
	sampler_state->ss1.s_wrap_mode = BRW_TEXCOORDMODE_CLAMP;
	sampler_state->ss1.t_wrap_mode = BRW_TEXCOORDMODE_CLAMP;
	break;
    case SAMPLER_STATE_EXTEND_REFLECT:
	sampler_state->ss1.r_wrap_mode = BRW_TEXCOORDMODE_MIRROR;
	sampler_state->ss1.s_wrap_mode = BRW_TEXCOORDMODE_MIRROR;
	sampler_state->ss1.t_wrap_mode = BRW_TEXCOORDMODE_MIRROR;
	break;
    }

    sampler_state->ss2.border_color_pointer =
	intel_emit_reloc(sampler_state_bo, sampler_state_offset +
			 offsetof(struct brw_sampler_state, ss2),
			 border_color_bo, 0,
			 I915_GEM_DOMAIN_SAMPLER, 0) >> 5;

    sampler_state->ss3.chroma_key_enable = 0; /* disable chromakey */
}

static drm_intel_bo *
gen4_create_sampler_state(ScrnInfoPtr scrn,
			  sampler_state_filter_t src_filter,
			  sampler_state_extend_t src_extend,
			  sampler_state_filter_t mask_filter,
			  sampler_state_extend_t mask_extend,
			  drm_intel_bo *border_color_bo)
{
    I830Ptr pI830 = I830PTR(scrn);
    drm_intel_bo *sampler_state_bo;
    struct brw_sampler_state *sampler_state;

    sampler_state_bo = drm_intel_bo_alloc(pI830->bufmgr, "gen4 sampler state",
					  sizeof(struct brw_sampler_state) * 2,
					  4096);
    drm_intel_bo_map(sampler_state_bo, TRUE);
    sampler_state = sampler_state_bo->virtual;

    sampler_state_init(sampler_state_bo,
		       &sampler_state[0],
		       src_filter, src_extend,
		       border_color_bo);
    sampler_state_init(sampler_state_bo,
		       &sampler_state[1],
		       mask_filter, mask_extend,
		       border_color_bo);
d810 1
a810 1
    drm_intel_bo_unmap(sampler_state_bo);
d812 1
a812 1
    return sampler_state_bo;
d816 140
a955 138
cc_state_init (drm_intel_bo *cc_state_bo,
	       uint32_t cc_state_offset,
	       int src_blend,
	       int dst_blend,
	       drm_intel_bo *cc_vp_bo)
{
    struct brw_cc_unit_state *cc_state;

    cc_state = (struct brw_cc_unit_state *)((char *)cc_state_bo->virtual +
					    cc_state_offset);

    memset(cc_state, 0, sizeof(*cc_state));
    cc_state->cc0.stencil_enable = 0;   /* disable stencil */
    cc_state->cc2.depth_test = 0;       /* disable depth test */
    cc_state->cc2.logicop_enable = 0;   /* disable logic op */
    cc_state->cc3.ia_blend_enable = 0;  /* blend alpha same as colors */
    cc_state->cc3.blend_enable = 1;     /* enable color blend */
    cc_state->cc3.alpha_test = 0;       /* disable alpha test */

    cc_state->cc4.cc_viewport_state_offset =
	intel_emit_reloc(cc_state_bo, cc_state_offset +
			 offsetof(struct brw_cc_unit_state, cc4),
			 cc_vp_bo, 0,
			 I915_GEM_DOMAIN_INSTRUCTION, 0) >> 5;

    cc_state->cc5.dither_enable = 0;    /* disable dither */
    cc_state->cc5.logicop_func = 0xc;   /* COPY */
    cc_state->cc5.statistics_enable = 1;
    cc_state->cc5.ia_blend_function = BRW_BLENDFUNCTION_ADD;

    /* Fill in alpha blend factors same as color, for the future. */
    cc_state->cc5.ia_src_blend_factor = src_blend;
    cc_state->cc5.ia_dest_blend_factor = dst_blend;

    cc_state->cc6.blend_function = BRW_BLENDFUNCTION_ADD;
    cc_state->cc6.clamp_post_alpha_blend = 1;
    cc_state->cc6.clamp_pre_alpha_blend = 1;
    cc_state->cc6.clamp_range = 0;  /* clamp range [0,1] */

    cc_state->cc6.src_blend_factor = src_blend;
    cc_state->cc6.dest_blend_factor = dst_blend;
}

static drm_intel_bo *
gen4_create_wm_state(ScrnInfoPtr scrn,
		     Bool has_mask, drm_intel_bo *kernel_bo,
		     drm_intel_bo *sampler_bo)
{
    I830Ptr pI830 = I830PTR(scrn);
    struct brw_wm_unit_state *wm_state;
    drm_intel_bo *wm_state_bo;

    wm_state_bo = drm_intel_bo_alloc(pI830->bufmgr, "gen4 WM state",
				     sizeof(*wm_state), 4096);
    drm_intel_bo_map(wm_state_bo, TRUE);
    wm_state = wm_state_bo->virtual;

    memset(wm_state, 0, sizeof (*wm_state));
    wm_state->thread0.grf_reg_count = BRW_GRF_BLOCKS(PS_KERNEL_NUM_GRF);
    wm_state->thread0.kernel_start_pointer =
	intel_emit_reloc(wm_state_bo,
			 offsetof(struct brw_wm_unit_state, thread0),
                         kernel_bo, wm_state->thread0.grf_reg_count << 1,
                         I915_GEM_DOMAIN_INSTRUCTION, 0) >> 6;

    wm_state->thread1.single_program_flow = 0;

    /* scratch space is not used in our kernel */
    wm_state->thread2.scratch_space_base_pointer = 0;
    wm_state->thread2.per_thread_scratch_space = 0;

    wm_state->thread3.const_urb_entry_read_length = 0;
    wm_state->thread3.const_urb_entry_read_offset = 0;

    wm_state->thread3.urb_entry_read_offset = 0;
    /* wm kernel use urb from 3, see wm_program in compiler module */
    wm_state->thread3.dispatch_grf_start_reg = 3; /* must match kernel */

    wm_state->wm4.stats_enable = 1;  /* statistic */
    wm_state->wm4.sampler_count = 1; /* 1-4 samplers used */
    wm_state->wm4.sampler_state_pointer =
	intel_emit_reloc(wm_state_bo, offsetof(struct brw_wm_unit_state, wm4),
			 sampler_bo,
			 wm_state->wm4.stats_enable +
			 (wm_state->wm4.sampler_count << 2),
			 I915_GEM_DOMAIN_INSTRUCTION, 0) >> 5;
    wm_state->wm5.max_threads = PS_MAX_THREADS - 1;
    wm_state->wm5.transposed_urb_read = 0;
    wm_state->wm5.thread_dispatch_enable = 1;
    /* just use 16-pixel dispatch (4 subspans), don't need to change kernel
     * start point
     */
    wm_state->wm5.enable_16_pix = 1;
    wm_state->wm5.enable_8_pix = 0;
    wm_state->wm5.early_depth_test = 1;

    /* Each pair of attributes (src/mask coords) is two URB entries */
    if (has_mask) {
	wm_state->thread1.binding_table_entry_count = 3; /* 2 tex and fb */
	wm_state->thread3.urb_entry_read_length = 4;
    } else {
	wm_state->thread1.binding_table_entry_count = 2; /* 1 tex and fb */
	wm_state->thread3.urb_entry_read_length = 2;
    }

    drm_intel_bo_unmap(wm_state_bo);

    return wm_state_bo;
}

static drm_intel_bo *
gen4_create_cc_viewport(ScrnInfoPtr scrn)
{
    I830Ptr pI830 = I830PTR(scrn);
    drm_intel_bo *bo;
    struct brw_cc_viewport cc_viewport;

    cc_viewport.min_depth = -1.e35;
    cc_viewport.max_depth = 1.e35;

    bo = drm_intel_bo_alloc(pI830->bufmgr, "gen4 render unit state",
			    sizeof(cc_viewport), 4096);
    drm_intel_bo_subdata(bo, 0, sizeof(cc_viewport), &cc_viewport);

    return bo;
}

static drm_intel_bo *
gen4_create_vs_unit_state(ScrnInfoPtr scrn)
{
    struct brw_vs_unit_state vs_state;
    memset(&vs_state, 0, sizeof(vs_state));

    /* Set up the vertex shader to be disabled (passthrough) */
    vs_state.thread4.nr_urb_entries = URB_VS_ENTRIES;
    vs_state.thread4.urb_entry_allocation_size = URB_VS_ENTRY_SIZE - 1;
    vs_state.vs6.vs_enable = 0;
    vs_state.vs6.vert_cache_disable = 1;
d957 11
a967 2
    return intel_bo_alloc_for_data(scrn, &vs_state, sizeof(vs_state),
				   "gen4 render VS state");
d974 1
a974 2
static drm_intel_bo *
gen4_create_cc_unit_state(ScrnInfoPtr scrn)
d976 18
a993 17
    I830Ptr pI830 = I830PTR(scrn);
    struct gen4_cc_unit_state *cc_state;
    drm_intel_bo *cc_state_bo, *cc_vp_bo;
    int i, j;

    cc_vp_bo = gen4_create_cc_viewport(scrn);

    cc_state_bo = drm_intel_bo_alloc(pI830->bufmgr, "gen4 CC state",
				     sizeof(*cc_state), 4096);
    drm_intel_bo_map(cc_state_bo, TRUE);
    cc_state = cc_state_bo->virtual;
    for (i = 0; i < BRW_BLENDFACTOR_COUNT; i++) {
	for (j = 0; j < BRW_BLENDFACTOR_COUNT; j++) {
	    cc_state_init(cc_state_bo,
			  offsetof(struct gen4_cc_unit_state,
				   cc_state[i][j].state),
			  i, j, cc_vp_bo);
d995 1
a995 2
    }
    drm_intel_bo_unmap(cc_state_bo);
d997 1
a997 1
    drm_intel_bo_unreference(cc_vp_bo);
d999 1
a999 1
    return cc_state_bo;
d1002 1
a1002 2
static uint32_t 
i965_get_card_format(PicturePtr pPict)
d1004 1
a1004 1
    int i;
d1006 6
a1011 7
    for (i = 0; i < sizeof(i965_tex_formats) / sizeof(i965_tex_formats[0]);
	 i++)
    {
	if (i965_tex_formats[i].fmt == pPict->format)
	    break;
    }
    assert(i != sizeof(i965_tex_formats) / sizeof(i965_tex_formats[0]));
d1013 1
a1013 1
    return i965_tex_formats[i].card_fmt;
d1016 1
a1016 2
static sampler_state_filter_t
sampler_state_filter_from_picture (int filter)
d1018 8
a1025 8
    switch (filter) {
    case PictFilterNearest:
	return SAMPLER_STATE_FILTER_NEAREST;
    case PictFilterBilinear:
	return SAMPLER_STATE_FILTER_BILINEAR;
    default:
	return -1;
    }
d1028 1
a1028 2
static sampler_state_extend_t
sampler_state_extend_from_picture (int repeat_type)
d1030 12
a1041 12
    switch (repeat_type) {
    case RepeatNone:
	return SAMPLER_STATE_EXTEND_NONE;
    case RepeatNormal:
	return SAMPLER_STATE_EXTEND_REPEAT;
    case RepeatPad:
	return SAMPLER_STATE_EXTEND_PAD;
    case RepeatReflect:
	return SAMPLER_STATE_EXTEND_REFLECT;
    default:
	return -1;
    }
d1049 3
a1051 2
i965_set_picture_surface_state(dri_bo *ss_bo, int ss_index,
			       PicturePtr pPicture, PixmapPtr pPixmap,
d1054 3
a1056 44
    struct brw_surface_state_padded *ss;
    struct brw_surface_state local_ss;
    dri_bo *pixmap_bo = i830_get_pixmap_bo(pPixmap);

    ss = (struct brw_surface_state_padded *)ss_bo->virtual + ss_index;

    /* Since ss is a pointer to WC memory, do all of our bit operations
     * into a local temporary first.
     */
    memset(&local_ss, 0, sizeof(local_ss));
    local_ss.ss0.surface_type = BRW_SURFACE_2D;
    if (is_dst) {
	uint32_t dst_format = 0;
	Bool ret = TRUE;

	ret = i965_get_dest_format(pPicture, &dst_format);
	assert(ret == TRUE);
	local_ss.ss0.surface_format = dst_format;
    } else {
	local_ss.ss0.surface_format = i965_get_card_format(pPicture);
    }

    local_ss.ss0.data_return_format = BRW_SURFACERETURNFORMAT_FLOAT32;
    local_ss.ss0.writedisable_alpha = 0;
    local_ss.ss0.writedisable_red = 0;
    local_ss.ss0.writedisable_green = 0;
    local_ss.ss0.writedisable_blue = 0;
    local_ss.ss0.color_blend = 1;
    local_ss.ss0.vert_line_stride = 0;
    local_ss.ss0.vert_line_stride_ofs = 0;
    local_ss.ss0.mipmap_layout_mode = 0;
    local_ss.ss0.render_cache_read_mode = 0;
    if (pixmap_bo != NULL)
	local_ss.ss1.base_addr = pixmap_bo->offset;
    else
	local_ss.ss1.base_addr = intel_get_pixmap_offset(pPixmap);

    local_ss.ss2.mip_count = 0;
    local_ss.ss2.render_target_rotation = 0;
    local_ss.ss2.height = pPixmap->drawable.height - 1;
    local_ss.ss2.width = pPixmap->drawable.width - 1;
    local_ss.ss3.pitch = intel_get_pixmap_pitch(pPixmap) - 1;
    local_ss.ss3.tile_walk = 0; /* Tiled X */
    local_ss.ss3.tiled_surface = i830_pixmap_tiled(pPixmap) ? 1 : 0;
d1058 1
a1058 1
    memcpy(ss, &local_ss, sizeof(local_ss));
d1060 8
a1067 2
    if (pixmap_bo != NULL) {
	uint32_t write_domain, read_domains;
d1069 3
a1071 3
	if (is_dst) {
	    write_domain = I915_GEM_DOMAIN_RENDER;
	    read_domains = I915_GEM_DOMAIN_RENDER;
d1073 42
a1114 2
	    write_domain = 0;
	    read_domains = I915_GEM_DOMAIN_SAMPLER;
a1115 6
	dri_bo_emit_reloc(ss_bo, read_domains, write_domain,
			  0,
			  ss_index * sizeof(*ss) +
			  offsetof(struct brw_surface_state, ss1),
			  pixmap_bo);
    }
d1118 1
a1118 2
static void
i965_emit_composite_state(ScrnInfoPtr pScrn)
d1120 36
a1155 59
    I830Ptr pI830 = I830PTR(pScrn);
    struct gen4_render_state *render_state= pI830->gen4_render_state;
    gen4_composite_op *composite_op = &render_state->composite_op;
    int op = composite_op->op;
    PicturePtr pMaskPicture = composite_op->mask_picture;
    PicturePtr pDstPicture = composite_op->dest_picture;
    PixmapPtr pMask = composite_op->mask;
    PixmapPtr pDst = composite_op->dest;
    sampler_state_filter_t src_filter = composite_op->src_filter;
    sampler_state_filter_t mask_filter = composite_op->mask_filter;
    sampler_state_extend_t src_extend = composite_op->src_extend;
    sampler_state_extend_t mask_extend = composite_op->mask_extend;
    Bool is_affine = composite_op->is_affine;
    int urb_vs_start, urb_vs_size;
    int urb_gs_start, urb_gs_size;
    int urb_clip_start, urb_clip_size;
    int urb_sf_start, urb_sf_size;
    int urb_cs_start, urb_cs_size;
    uint32_t src_blend, dst_blend;
    dri_bo *binding_table_bo = composite_op->binding_table_bo;

    render_state->needs_state_emit = FALSE;

    IntelEmitInvarientState(pScrn);
    pI830->last_3d = LAST_3D_RENDER;

    urb_vs_start = 0;
    urb_vs_size = URB_VS_ENTRIES * URB_VS_ENTRY_SIZE;
    urb_gs_start = urb_vs_start + urb_vs_size;
    urb_gs_size = URB_GS_ENTRIES * URB_GS_ENTRY_SIZE;
    urb_clip_start = urb_gs_start + urb_gs_size;
    urb_clip_size = URB_CLIP_ENTRIES * URB_CLIP_ENTRY_SIZE;
    urb_sf_start = urb_clip_start + urb_clip_size;
    urb_sf_size = URB_SF_ENTRIES * URB_SF_ENTRY_SIZE;
    urb_cs_start = urb_sf_start + urb_sf_size;
    urb_cs_size = URB_CS_ENTRIES * URB_CS_ENTRY_SIZE;

    i965_get_blend_cntl(op, pMaskPicture, pDstPicture->format,
			&src_blend, &dst_blend);

    /* Begin the long sequence of commands needed to set up the 3D
     * rendering pipe
     */
    {
	BEGIN_BATCH(2);
	OUT_BATCH(MI_FLUSH |
		  MI_STATE_INSTRUCTION_CACHE_FLUSH |
		  BRW_MI_GLOBAL_SNAPSHOT_RESET);
	OUT_BATCH(MI_NOOP);
	ADVANCE_BATCH();
    }
    {
        BEGIN_BATCH(12);

        /* Match Mesa driver setup */
	if (IS_G4X(pI830))
	    OUT_BATCH(NEW_PIPELINE_SELECT | PIPELINE_SELECT_3D);
	else
	    OUT_BATCH(BRW_PIPELINE_SELECT | PIPELINE_SELECT_3D);
d1157 2
a1158 3
	OUT_BATCH(BRW_CS_URB_STATE | 0);
	OUT_BATCH((0 << 4) |  /* URB Entry Allocation Size */
		  (0 << 0));  /* Number of URB Entries */
d1160 2
a1161 2
	/* Zero out the two base address registers so all offsets are
	 * absolute.
a1162 35
	OUT_BATCH(BRW_STATE_BASE_ADDRESS | 4);
	OUT_BATCH(0 | BASE_ADDRESS_MODIFY);  /* Generate state base address */
	OUT_BATCH(0 | BASE_ADDRESS_MODIFY);  /* Surface state base address */
	OUT_BATCH(0 | BASE_ADDRESS_MODIFY);  /* media base addr, don't care */
	/* general state max addr, disabled */
	OUT_BATCH(0x10000000 | BASE_ADDRESS_MODIFY);
	/* media object state max addr, disabled */
	OUT_BATCH(0x10000000 | BASE_ADDRESS_MODIFY);

	/* Set system instruction pointer */
	OUT_BATCH(BRW_STATE_SIP | 0);
	OUT_RELOC(render_state->sip_kernel_bo,
		  I915_GEM_DOMAIN_INSTRUCTION, 0, 0);
	OUT_BATCH(MI_NOOP);
	ADVANCE_BATCH();
    }
    {
	BEGIN_BATCH(26);
	/* Pipe control */
	OUT_BATCH(BRW_PIPE_CONTROL |
		  BRW_PIPE_CONTROL_NOWRITE |
		  BRW_PIPE_CONTROL_IS_FLUSH |
		  2);
	OUT_BATCH(0);			       /* Destination address */
	OUT_BATCH(0);			       /* Immediate data low DW */
	OUT_BATCH(0);			       /* Immediate data high DW */

	/* Binding table pointers */
	OUT_BATCH(BRW_3DSTATE_BINDING_TABLE_POINTERS | 4);
	OUT_BATCH(0); /* vs */
	OUT_BATCH(0); /* gs */
	OUT_BATCH(0); /* clip */
	OUT_BATCH(0); /* sf */
	/* Only the PS uses the binding table */
	OUT_RELOC(binding_table_bo, I915_GEM_DOMAIN_SAMPLER, 0, 0);
d1164 3
a1166 2
	/* The drawing rectangle clipping is always on.  Set it to values that
	 * shouldn't do any clipping.
d1168 51
a1218 22
	OUT_BATCH(BRW_3DSTATE_DRAWING_RECTANGLE | 2); /* XXX 3 for BLC or CTG */
	OUT_BATCH(0x00000000);	/* ymin, xmin */
	OUT_BATCH(DRAW_YMAX(pDst->drawable.height - 1) |
		  DRAW_XMAX(pDst->drawable.width - 1)); /* ymax, xmax */
	OUT_BATCH(0x00000000);	/* yorigin, xorigin */

	/* skip the depth buffer */
	/* skip the polygon stipple */
	/* skip the polygon stipple offset */
	/* skip the line stipple */

	/* Set the pointers to the 3d pipeline state */
	OUT_BATCH(BRW_3DSTATE_PIPELINED_POINTERS | 5);
	OUT_RELOC(render_state->vs_state_bo, I915_GEM_DOMAIN_INSTRUCTION, 0, 0);
	OUT_BATCH(BRW_GS_DISABLE);   /* disable GS, resulting in passthrough */
	OUT_BATCH(BRW_CLIP_DISABLE); /* disable CLIP, resulting in passthrough */
	if (pMask) {
	    OUT_RELOC(render_state->sf_mask_state_bo,
		      I915_GEM_DOMAIN_INSTRUCTION, 0, 0);
	} else {
	    OUT_RELOC(render_state->sf_state_bo,
		      I915_GEM_DOMAIN_INSTRUCTION, 0, 0);
a1220 47
	OUT_RELOC(render_state->wm_state_bo[composite_op->wm_kernel]
		  [src_filter][src_extend]
		  [mask_filter][mask_extend],
		  I915_GEM_DOMAIN_INSTRUCTION, 0, 0);

	OUT_RELOC(render_state->cc_state_bo,
		  I915_GEM_DOMAIN_INSTRUCTION, 0,
		  offsetof(struct gen4_cc_unit_state,
			   cc_state[src_blend][dst_blend]));

	/* URB fence */
	OUT_BATCH(BRW_URB_FENCE |
		  UF0_CS_REALLOC |
		  UF0_SF_REALLOC |
		  UF0_CLIP_REALLOC |
		  UF0_GS_REALLOC |
		  UF0_VS_REALLOC |
		  1);
	OUT_BATCH(((urb_clip_start + urb_clip_size) << UF1_CLIP_FENCE_SHIFT) |
		  ((urb_gs_start + urb_gs_size) << UF1_GS_FENCE_SHIFT) |
		  ((urb_vs_start + urb_vs_size) << UF1_VS_FENCE_SHIFT));
	OUT_BATCH(((urb_cs_start + urb_cs_size) << UF2_CS_FENCE_SHIFT) |
		  ((urb_sf_start + urb_sf_size) << UF2_SF_FENCE_SHIFT));

	/* Constant buffer state */
	OUT_BATCH(BRW_CS_URB_STATE | 0);
	OUT_BATCH(((URB_CS_ENTRY_SIZE - 1) << 4) |
		  (URB_CS_ENTRIES << 0));
	ADVANCE_BATCH();
    }
    {
	/* 
	 * number of extra parameters per vertex
	 */
        int nelem = pMask ? 2: 1;
	/* 
	 * size of extra parameters:
	 *  3 for homogenous (xyzw)
	 *  2 for cartesian (xy)
	 */
	int selem = is_affine ? 2 : 3;
	uint32_t    w_component;
	uint32_t    src_format;

	render_state->vertex_size = 4 * (2 + nelem * selem);
	
	if (is_affine)
d1222 97
a1318 2
	    src_format = BRW_SURFACEFORMAT_R32G32_FLOAT;
	    w_component = BRW_VFCOMPONENT_STORE_1_FLT;
a1319 1
	else
d1321 61
a1381 42
	    src_format = BRW_SURFACEFORMAT_R32G32B32_FLOAT;
	    w_component = BRW_VFCOMPONENT_STORE_SRC;
	}
	BEGIN_BATCH(pMask?7:5);
	/* Set up our vertex elements, sourced from the single vertex buffer.
	 * that will be set up later.
	 */
	
	OUT_BATCH(BRW_3DSTATE_VERTEX_ELEMENTS | ((2 * (1 + nelem)) - 1));
	/* x,y */
	OUT_BATCH((0 << VE0_VERTEX_BUFFER_INDEX_SHIFT) |
		  VE0_VALID |
		  (BRW_SURFACEFORMAT_R32G32_FLOAT << VE0_FORMAT_SHIFT) |
		  (0				<< VE0_OFFSET_SHIFT));
	OUT_BATCH((BRW_VFCOMPONENT_STORE_SRC	<< VE1_VFCOMPONENT_0_SHIFT) |
		  (BRW_VFCOMPONENT_STORE_SRC	<< VE1_VFCOMPONENT_1_SHIFT) |
		  (BRW_VFCOMPONENT_STORE_1_FLT	<< VE1_VFCOMPONENT_2_SHIFT) |
		  (BRW_VFCOMPONENT_STORE_1_FLT	<< VE1_VFCOMPONENT_3_SHIFT) |
		  (4				<< VE1_DESTINATION_ELEMENT_OFFSET_SHIFT));
	/* u0, v0, w0 */
	OUT_BATCH((0				<< VE0_VERTEX_BUFFER_INDEX_SHIFT) |
		  VE0_VALID					     |
		  (src_format			<< VE0_FORMAT_SHIFT) |
		  ((2 * 4)			<< VE0_OFFSET_SHIFT)); /* offset vb in bytes */
	OUT_BATCH((BRW_VFCOMPONENT_STORE_SRC	<< VE1_VFCOMPONENT_0_SHIFT) |
		  (BRW_VFCOMPONENT_STORE_SRC	<< VE1_VFCOMPONENT_1_SHIFT) |
		  (w_component			<< VE1_VFCOMPONENT_2_SHIFT) |
		  (BRW_VFCOMPONENT_STORE_1_FLT	<< VE1_VFCOMPONENT_3_SHIFT) |
		  ((4 + 4)			<< VE1_DESTINATION_ELEMENT_OFFSET_SHIFT)); /* VUE offset in dwords */
	/* u1, v1, w1 */
   	if (pMask) {
	    OUT_BATCH((0			    << VE0_VERTEX_BUFFER_INDEX_SHIFT) |
		      VE0_VALID							    |
		      (src_format		    << VE0_FORMAT_SHIFT) |
		      (((2 + selem) * 4)    	    << VE0_OFFSET_SHIFT));  /* vb offset in bytes */
	    
	    OUT_BATCH((BRW_VFCOMPONENT_STORE_SRC    << VE1_VFCOMPONENT_0_SHIFT) |
		      (BRW_VFCOMPONENT_STORE_SRC    << VE1_VFCOMPONENT_1_SHIFT) |
		      (w_component		    << VE1_VFCOMPONENT_2_SHIFT) |
		      (BRW_VFCOMPONENT_STORE_1_FLT  << VE1_VFCOMPONENT_3_SHIFT) |
		      ((4 + 4 + 4)		    << VE1_DESTINATION_ELEMENT_OFFSET_SHIFT)); /* VUE offset in dwords */
   	}
d1383 54
a1436 2
	ADVANCE_BATCH();
    }
d1438 2
a1439 4
#ifdef I830DEBUG
    ErrorF("try to sync to show any errors...\n");
    I830Sync(pScrn);
#endif
d1446 1
a1446 2
static Bool
i965_composite_check_aperture(ScrnInfoPtr pScrn)
d1448 18
a1465 18
    I830Ptr pI830 = I830PTR(pScrn);
    struct gen4_render_state *render_state= pI830->gen4_render_state;
    gen4_composite_op *composite_op = &render_state->composite_op;
    drm_intel_bo *bo_table[] = {
	pI830->batch_bo,
	composite_op->binding_table_bo,
	render_state->vertex_buffer_bo,
	render_state->vs_state_bo,
	render_state->sf_state_bo,
	render_state->sf_mask_state_bo,
	render_state->wm_state_bo[composite_op->wm_kernel]
				 [composite_op->src_filter]
				 [composite_op->src_extend]
				 [composite_op->mask_filter]
				 [composite_op->mask_extend],
	render_state->cc_state_bo,
	render_state->sip_kernel_bo,
    };
d1467 2
a1468 2
    return drm_intel_bufmgr_check_aperture_space(bo_table,
						 ARRAY_SIZE(bo_table)) == 0;
d1472 79
a1550 76
i965_prepare_composite(int op, PicturePtr pSrcPicture,
		       PicturePtr pMaskPicture, PicturePtr pDstPicture,
		       PixmapPtr pSrc, PixmapPtr pMask, PixmapPtr pDst)
{
    ScrnInfoPtr pScrn = xf86Screens[pSrcPicture->pDrawable->pScreen->myNum];
    I830Ptr pI830 = I830PTR(pScrn);
    struct gen4_render_state *render_state= pI830->gen4_render_state;
    gen4_composite_op *composite_op = &render_state->composite_op;
    uint32_t *binding_table;
    drm_intel_bo *binding_table_bo, *surface_state_bo;

    if (composite_op->src_filter < 0)
	I830FALLBACK("Bad src filter 0x%x\n", pSrcPicture->filter);
    composite_op->src_extend =
	sampler_state_extend_from_picture(pSrcPicture->repeatType);
    if (composite_op->src_extend < 0)
	I830FALLBACK("Bad src repeat 0x%x\n", pSrcPicture->repeatType);

    if (pMaskPicture) {
	composite_op->mask_filter =
	    sampler_state_filter_from_picture(pMaskPicture->filter);
	if (composite_op->mask_filter < 0)
	    I830FALLBACK("Bad mask filter 0x%x\n", pMaskPicture->filter);
	composite_op->mask_extend =
	    sampler_state_extend_from_picture(pMaskPicture->repeatType);
	if (composite_op->mask_extend < 0)
	    I830FALLBACK("Bad mask repeat 0x%x\n", pMaskPicture->repeatType);
    } else {
	composite_op->mask_filter = SAMPLER_STATE_FILTER_NEAREST;
	composite_op->mask_extend = SAMPLER_STATE_EXTEND_NONE;
    }

    /* Set up the surface states. */
    surface_state_bo = dri_bo_alloc(pI830->bufmgr, "surface_state",
				    3 * sizeof (brw_surface_state_padded),
				    4096);
    if (dri_bo_map(surface_state_bo, 1) != 0)
	return FALSE;
    /* Set up the state buffer for the destination surface */
    i965_set_picture_surface_state(surface_state_bo, 0,
				   pDstPicture, pDst, TRUE);
    /* Set up the source surface state buffer */
    i965_set_picture_surface_state(surface_state_bo, 1,
				   pSrcPicture, pSrc, FALSE);
    if (pMask) {
	/* Set up the mask surface state buffer */
	i965_set_picture_surface_state(surface_state_bo, 2,
				       pMaskPicture, pMask,
				       FALSE);
    }
    dri_bo_unmap(surface_state_bo);

    /* Set up the binding table of surface indices to surface state. */
    binding_table_bo = dri_bo_alloc(pI830->bufmgr, "binding_table",
				    3 * sizeof(uint32_t), 4096);
    if (dri_bo_map (binding_table_bo, 1) != 0) {
	dri_bo_unreference(surface_state_bo);
	return FALSE;
    }

    binding_table = binding_table_bo->virtual;
    binding_table[0] = intel_emit_reloc(binding_table_bo,
					0 * sizeof(uint32_t),
					surface_state_bo,
					0 * sizeof(brw_surface_state_padded),
					I915_GEM_DOMAIN_INSTRUCTION, 0);

    binding_table[1] = intel_emit_reloc(binding_table_bo,
					1 * sizeof(uint32_t),
					surface_state_bo,
					1 * sizeof(brw_surface_state_padded),
					I915_GEM_DOMAIN_INSTRUCTION, 0);

    if (pMask) {
	binding_table[2] = intel_emit_reloc(binding_table_bo,
					    2 * sizeof(uint32_t),
d1552 2
a1553 1
					    2 * sizeof(brw_surface_state_padded),
d1555 79
a1633 44
    } else {
	binding_table[2] = 0;
    }
    dri_bo_unmap(binding_table_bo);
    /* All refs to surface_state are now contained in binding_table_bo. */
    drm_intel_bo_unreference(surface_state_bo);

    composite_op->op = op;
    composite_op->source_picture = pSrcPicture;
    composite_op->mask_picture = pMaskPicture;
    composite_op->dest_picture = pDstPicture;
    composite_op->source = pSrc;
    composite_op->mask = pMask;
    composite_op->dest = pDst;
    drm_intel_bo_unreference(composite_op->binding_table_bo);
    composite_op->binding_table_bo = binding_table_bo;
    composite_op->src_filter =
	sampler_state_filter_from_picture(pSrcPicture->filter);

    pI830->scale_units[0][0] = pSrc->drawable.width;
    pI830->scale_units[0][1] = pSrc->drawable.height;

    pI830->transform[0] = pSrcPicture->transform;
    composite_op->is_affine =
	i830_transform_is_affine(pI830->transform[0]);

    if (!pMask) {
	pI830->transform[1] = NULL;
	pI830->scale_units[1][0] = -1;
	pI830->scale_units[1][1] = -1;
    } else {
	pI830->transform[1] = pMaskPicture->transform;
	pI830->scale_units[1][0] = pMask->drawable.width;
	pI830->scale_units[1][1] = pMask->drawable.height;
	composite_op->is_affine |=
	    i830_transform_is_affine(pI830->transform[1]);
    }


    if (pMask) {
	if (pMaskPicture->componentAlpha &&
	    PICT_FORMAT_RGB(pMaskPicture->format))
	{
	    if (i965_blend_op[op].src_alpha) {
d1635 1
a1635 1
		    composite_op->wm_kernel = WM_KERNEL_MASKCA_SRCALPHA_AFFINE;
d1637 12
a1648 19
		    composite_op->wm_kernel = WM_KERNEL_MASKCA_SRCALPHA_PROJECTIVE;
	    } else {
		if (composite_op->is_affine)
		    composite_op->wm_kernel = WM_KERNEL_MASKCA_AFFINE;
		else
		    composite_op->wm_kernel = WM_KERNEL_MASKCA_PROJECTIVE;
	    }
	} else {
	    if (composite_op->is_affine)
		composite_op->wm_kernel = WM_KERNEL_MASKNOCA_AFFINE;
	    else
		composite_op->wm_kernel = WM_KERNEL_MASKNOCA_PROJECTIVE;
	}
    } else {
	if (composite_op->is_affine)
	    composite_op->wm_kernel = WM_KERNEL_NOMASK_AFFINE;
	else
	    composite_op->wm_kernel = WM_KERNEL_NOMASK_PROJECTIVE;
    }
d1650 3
a1652 5
    if (!i965_composite_check_aperture(pScrn)) {
	intel_batch_flush(pScrn, FALSE);
	if (!i965_composite_check_aperture(pScrn))
	    I830FALLBACK("Couldn't fit render operation in aperture\n");
    }
d1654 1
a1654 1
    render_state->needs_state_emit = TRUE;
d1656 1
a1656 1
    return TRUE;
d1659 1
a1659 2
static drm_intel_bo *
i965_get_vb_space(ScrnInfoPtr pScrn)
d1661 2
a1662 2
    I830Ptr pI830 = I830PTR(pScrn);
    struct gen4_render_state *render_state = pI830->gen4_render_state;
d1664 8
a1671 8
    /* If the vertex buffer is too full, then we free the old and a new one
     * gets made.
     */
    if (render_state->vb_offset + VERTEX_FLOATS_PER_COMPOSITE >
	VERTEX_BUFFER_SIZE) {
	drm_intel_bo_unreference(render_state->vertex_buffer_bo);
	render_state->vertex_buffer_bo = NULL;
    }
d1673 7
a1679 7
    /* Alloc a new vertex buffer if necessary. */
    if (render_state->vertex_buffer_bo == NULL) {
	render_state->vertex_buffer_bo = drm_intel_bo_alloc(pI830->bufmgr, "vb",
							    sizeof(gen4_vertex_buffer),
							    4096);
	render_state->vb_offset = 0;
    }
d1681 2
a1682 2
    drm_intel_bo_reference(render_state->vertex_buffer_bo);
    return render_state->vertex_buffer_bo;
d1686 1
a1686 1
i965_composite(PixmapPtr pDst, int srcX, int srcY, int maskX, int maskY,
d1689 10
a1698 48
    ScrnInfoPtr pScrn = xf86Screens[pDst->drawable.pScreen->myNum];
    I830Ptr pI830 = I830PTR(pScrn);
    struct gen4_render_state *render_state = pI830->gen4_render_state;
    Bool has_mask;
    float src_x[3], src_y[3], src_w[3], mask_x[3], mask_y[3], mask_w[3];
    int i;
    drm_intel_bo *vb_bo;
    float vb[18];
    Bool is_affine = render_state->composite_op.is_affine;

    if (is_affine)
    {
	if (!i830_get_transformed_coordinates(srcX, srcY,
					      pI830->transform[0],
					      &src_x[0], &src_y[0]))
	    return;
	if (!i830_get_transformed_coordinates(srcX, srcY + h,
					      pI830->transform[0],
					      &src_x[1], &src_y[1]))
	    return;
	if (!i830_get_transformed_coordinates(srcX + w, srcY + h,
					      pI830->transform[0],
					      &src_x[2], &src_y[2]))
	    return;
    }
    else
    {
	if (!i830_get_transformed_coordinates_3d(srcX, srcY,
						 pI830->transform[0],
						 &src_x[0], &src_y[0],
						 &src_w[0]))
	    return;
	if (!i830_get_transformed_coordinates_3d(srcX, srcY + h,
						 pI830->transform[0],
						 &src_x[1], &src_y[1],
						 &src_w[1]))
	    return;
	if (!i830_get_transformed_coordinates_3d(srcX + w, srcY + h,
						 pI830->transform[0],
						 &src_x[2], &src_y[2],
						 &src_w[2]))
	    return;
    }

    if (pI830->scale_units[1][0] == -1 || pI830->scale_units[1][1] == -1) {
	has_mask = FALSE;
    } else {
	has_mask = TRUE;
d1700 32
a1731 12
	    if (!i830_get_transformed_coordinates(maskX, maskY,
						  pI830->transform[1],
						  &mask_x[0], &mask_y[0]))
		return;
	    if (!i830_get_transformed_coordinates(maskX, maskY + h,
						  pI830->transform[1],
						  &mask_x[1], &mask_y[1]))
		return;
	    if (!i830_get_transformed_coordinates(maskX + w, maskY + h,
						  pI830->transform[1],
						  &mask_x[2], &mask_y[2]))
		return;
d1733 39
a1771 14
	    if (!i830_get_transformed_coordinates_3d(maskX, maskY,
						     pI830->transform[1],
						     &mask_x[0], &mask_y[0],
						     &mask_w[0]))
		return;
	    if (!i830_get_transformed_coordinates_3d(maskX, maskY + h,
						     pI830->transform[1],
						     &mask_x[1], &mask_y[1],
						     &mask_w[1]))
		return;
	    if (!i830_get_transformed_coordinates_3d(maskX + w, maskY + h,
						     pI830->transform[1],
						     &mask_x[2], &mask_y[2],
						     &mask_w[2]))
d1773 13
a1786 1
    }
d1788 5
a1792 14
    vb_bo = i965_get_vb_space(pScrn);
    if (vb_bo == NULL)
	return;
    i = 0;
    /* rect (x2,y2) */
    vb[i++] = (float)(dstX + w);
    vb[i++] = (float)(dstY + h);
    vb[i++] = src_x[2] / pI830->scale_units[0][0];
    vb[i++] = src_y[2] / pI830->scale_units[0][1];
    if (!is_affine)
	vb[i++] = src_w[2];
    if (has_mask) {
        vb[i++] = mask_x[2] / pI830->scale_units[1][0];
        vb[i++] = mask_y[2] / pI830->scale_units[1][1];
d1794 7
a1800 2
	    vb[i++] = mask_w[2];
    }
d1802 5
a1806 10
    /* rect (x1,y2) */
    vb[i++] = (float)dstX;
    vb[i++] = (float)(dstY + h);
    vb[i++] = src_x[1] / pI830->scale_units[0][0];
    vb[i++] = src_y[1] / pI830->scale_units[0][1];
    if (!is_affine)
	vb[i++] = src_w[1];
    if (has_mask) {
        vb[i++] = mask_x[1] / pI830->scale_units[1][0];
        vb[i++] = mask_y[1] / pI830->scale_units[1][1];
d1808 11
a1818 2
	    vb[i++] = mask_w[1];
    }
d1820 35
a1854 55
    /* rect (x1,y1) */
    vb[i++] = (float)dstX;
    vb[i++] = (float)dstY;
    vb[i++] = src_x[0] / pI830->scale_units[0][0];
    vb[i++] = src_y[0] / pI830->scale_units[0][1];
    if (!is_affine)
	vb[i++] = src_w[0];
    if (has_mask) {
        vb[i++] = mask_x[0] / pI830->scale_units[1][0];
        vb[i++] = mask_y[0] / pI830->scale_units[1][1];
	if (!is_affine)
	    vb[i++] = mask_w[0];
    }
    assert (i <= VERTEX_BUFFER_SIZE);
    drm_intel_bo_subdata(vb_bo, render_state->vb_offset * 4, i * 4, vb);

    if (!i965_composite_check_aperture(pScrn))
	intel_batch_flush(pScrn, FALSE);

    intel_batch_start_atomic(pScrn, 200);
    if (render_state->needs_state_emit)
	i965_emit_composite_state(pScrn);

    BEGIN_BATCH(12);
    OUT_BATCH(MI_FLUSH);
    /* Set up the pointer to our (single) vertex buffer */
    OUT_BATCH(BRW_3DSTATE_VERTEX_BUFFERS | 3);
    OUT_BATCH((0 << VB0_BUFFER_INDEX_SHIFT) |
	      VB0_VERTEXDATA |
	      (render_state->vertex_size << VB0_BUFFER_PITCH_SHIFT));
    OUT_RELOC(vb_bo, I915_GEM_DOMAIN_VERTEX, 0, render_state->vb_offset * 4);
    OUT_BATCH(3);
    OUT_BATCH(0); // ignore for VERTEXDATA, but still there

    OUT_BATCH(BRW_3DPRIMITIVE |
	      BRW_3DPRIMITIVE_VERTEX_SEQUENTIAL |
	      (_3DPRIM_RECTLIST << BRW_3DPRIMITIVE_TOPOLOGY_SHIFT) |
	      (0 << 9) |  /* CTG - indirect vertex count */
	      4);
    OUT_BATCH(3);  /* vertex count per instance */
    OUT_BATCH(0); /* start vertex offset */
    OUT_BATCH(1); /* single instance */
    OUT_BATCH(0); /* start instance location */
    OUT_BATCH(0); /* index buffer offset, ignored */
    ADVANCE_BATCH();

    render_state->vb_offset += i;
    drm_intel_bo_unreference(vb_bo);

    intel_batch_end_atomic(pScrn);

#ifdef I830DEBUG
    ErrorF("sync after 3dprimitive\n");
    I830Sync(pScrn);
#endif
d1857 1
a1857 2
void
i965_batch_flush_notify(ScrnInfoPtr pScrn)
d1859 2
a1860 2
    I830Ptr pI830 = I830PTR(pScrn);
    struct gen4_render_state *render_state = pI830->gen4_render_state;
d1862 7
a1868 7
    /* Once a batch is emitted, we never want to map again any buffer
     * object being referenced by that batch, (which would be very
     * expensive). */
    if (render_state->vertex_buffer_bo) {
	dri_bo_unreference (render_state->vertex_buffer_bo);
	render_state->vertex_buffer_bo = NULL;
    }
d1870 1
a1870 1
    render_state->needs_state_emit = TRUE;
d1876 1
a1876 2
void
gen4_render_state_init(ScrnInfoPtr pScrn)
d1878 101
a1978 60
    I830Ptr pI830 = I830PTR(pScrn);
    struct gen4_render_state *render_state;
    int i, j, k, l, m;
    drm_intel_bo *sf_kernel_bo, *sf_kernel_mask_bo;
    drm_intel_bo *border_color_bo;

    if (pI830->gen4_render_state == NULL)
	pI830->gen4_render_state = calloc(sizeof(*render_state), 1);

    render_state = pI830->gen4_render_state;
    render_state->vb_offset = 0;

    render_state->vs_state_bo = gen4_create_vs_unit_state(pScrn);

    /* Set up the two SF states (one for blending with a mask, one without) */
    sf_kernel_bo = intel_bo_alloc_for_data(pScrn,
					   sf_kernel_static,
					   sizeof(sf_kernel_static),
					   "sf kernel");
    sf_kernel_mask_bo = intel_bo_alloc_for_data(pScrn,
						sf_kernel_mask_static,
						sizeof(sf_kernel_mask_static),
						"sf mask kernel");
    render_state->sf_state_bo = gen4_create_sf_state(pScrn, sf_kernel_bo);
    render_state->sf_mask_state_bo = gen4_create_sf_state(pScrn,
							  sf_kernel_mask_bo);
    drm_intel_bo_unreference(sf_kernel_bo);
    drm_intel_bo_unreference(sf_kernel_mask_bo);

    for (m = 0; m < WM_KERNEL_COUNT; m++) {
	render_state->wm_kernel_bo[m] =
	    intel_bo_alloc_for_data(pScrn,
				    wm_kernels[m].data, wm_kernels[m].size,
				    "WM kernel");
    }

    /* Set up the WM states: each filter/extend type for source and mask, per
     * kernel.
     */
    border_color_bo = sampler_border_color_create(pScrn);
    for (i = 0; i < SAMPLER_STATE_FILTER_COUNT; i++) {
	for (j = 0; j < SAMPLER_STATE_EXTEND_COUNT; j++) {
	    for (k = 0; k < SAMPLER_STATE_FILTER_COUNT; k++) {
		for (l = 0; l < SAMPLER_STATE_EXTEND_COUNT; l++) {
		    drm_intel_bo *sampler_state_bo;

		    sampler_state_bo =
			gen4_create_sampler_state(pScrn,
						  i, j,
						  k, l,
						  border_color_bo);

		    for (m = 0; m < WM_KERNEL_COUNT; m++) {
			render_state->wm_state_bo[m][i][j][k][l] =
			    gen4_create_wm_state(pScrn,
						 wm_kernels[m].has_mask,
						 render_state->wm_kernel_bo[m],
						 sampler_state_bo);
		    }
		    drm_intel_bo_unreference(sampler_state_bo);
a1979 1
	    }
d1981 1
a1981 2
    }
    drm_intel_bo_unreference(border_color_bo);
d1983 6
a1988 5
    render_state->cc_state_bo = gen4_create_cc_unit_state(pScrn);
    render_state->sip_kernel_bo = intel_bo_alloc_for_data(pScrn,
							  sip_kernel_static,
							  sizeof(sip_kernel_static),
							  "sip kernel");
d1994 1
a1994 2
void
gen4_render_state_cleanup(ScrnInfoPtr pScrn)
d1996 30
a2025 34
    I830Ptr pI830 = I830PTR(pScrn);
    struct gen4_render_state *render_state= pI830->gen4_render_state;
    int i, j, k, l, m;

    if (render_state->vertex_buffer_bo) {
	dri_bo_unreference (render_state->vertex_buffer_bo);
	render_state->vertex_buffer_bo = NULL;
    }

    drm_intel_bo_unreference(render_state->vs_state_bo);
    render_state->vs_state_bo = NULL;
    drm_intel_bo_unreference(render_state->sf_state_bo);
    render_state->sf_state_bo = NULL;
    drm_intel_bo_unreference(render_state->sf_mask_state_bo);
    render_state->sf_mask_state_bo = NULL;

    for (i = 0; i < WM_KERNEL_COUNT; i++) {
	drm_intel_bo_unreference(render_state->wm_kernel_bo[i]);
	render_state->wm_kernel_bo[i] = NULL;
    }

    for (i = 0; i < SAMPLER_STATE_FILTER_COUNT; i++)
	for (j = 0; j < SAMPLER_STATE_EXTEND_COUNT; j++)
	    for (k = 0; k < SAMPLER_STATE_FILTER_COUNT; k++)
		for (l = 0; l < SAMPLER_STATE_EXTEND_COUNT; l++)
		    for (m = 0; m < WM_KERNEL_COUNT; m++) {
			drm_intel_bo_unreference(render_state->wm_state_bo[m][i][j][k][l]);
			render_state->wm_state_bo[m][i][j][k][l] = NULL;
		    }

    drm_intel_bo_unreference(render_state->cc_state_bo);
    render_state->cc_state_bo = NULL;
    drm_intel_bo_unreference(render_state->sip_kernel_bo);
    render_state->sip_kernel_bo = NULL;
@


1.3
log
@xf86-video-intel 2.4.2. Has been in snapshots for weeks. Ok oga@@.
@
text
@d45 8
a52 19
#ifdef I830DEBUG
#define DEBUG_I830FALLBACK 1
#endif

#ifdef DEBUG_I830FALLBACK
#define I830FALLBACK(s, arg...)				\
do {							\
	DPRINTF(PFX, "EXA fallback: " s "\n", ##arg); 	\
	return FALSE;					\
} while(0)
#else
#define I830FALLBACK(s, arg...) 			\
do { 							\
	return FALSE;					\
} while(0)
#endif

#define MAX_VERTEX_PER_COMPOSITE    24
#define MAX_VERTEX_BUFFERS	    256
d153 2
d186 1
d204 1
a204 1
    if (pPict->repeat && pPict->repeatType != RepeatNormal)
d221 1
a317 2
#define PS_SCRATCH_SPACE    1024
#define PS_SCRATCH_SPACE_LOG	0   /* log2 (PS_SCRATCH_SPACE) - 10  (1024 is 0, 2048 is 1) */
a392 6
/**
 * Storage for the static kernel data with template name, rounded to 64 bytes.
 */
#define KERNEL_DECL(template) \
    uint32_t template [((sizeof (template ## _static) + 63) & ~63) / 16][4];

d415 2
d420 38
d468 1
a468 57
/**
 * Gen4 rendering state buffer structure.
 *
 * Ideally this structure would contain static data for all of the
 * combinations of state that we use for Render acceleration, and another
 * buffer would be the use-and-throw-away surface and vertex data.  See the
 * intel-batchbuffer branch for an implementation of that.  For now, it
 * has the static program data, and then a changing buffer containing all
 * the rest.
 */
typedef struct _gen4_state {
    uint8_t wm_scratch[128 * PS_MAX_THREADS];

    KERNEL_DECL (sip_kernel);
    KERNEL_DECL (sf_kernel);
    KERNEL_DECL (sf_kernel_mask);
    KERNEL_DECL (ps_kernel_nomask_affine);
    KERNEL_DECL (ps_kernel_nomask_projective);
    KERNEL_DECL (ps_kernel_maskca_affine);
    KERNEL_DECL (ps_kernel_maskca_projective);
    KERNEL_DECL (ps_kernel_maskca_srcalpha_affine);
    KERNEL_DECL (ps_kernel_maskca_srcalpha_projective);
    KERNEL_DECL (ps_kernel_masknoca_affine);
    KERNEL_DECL (ps_kernel_masknoca_projective);

    struct brw_vs_unit_state vs_state;
    PAD64 (brw_vs_unit_state, 0);

    struct brw_sf_unit_state sf_state;
    PAD64 (brw_sf_unit_state, 0);
    struct brw_sf_unit_state sf_state_mask;
    PAD64 (brw_sf_unit_state, 1);

    WM_STATE_DECL (nomask_affine);
    WM_STATE_DECL (nomask_projective);
    WM_STATE_DECL (maskca_affine);
    WM_STATE_DECL (maskca_projective);
    WM_STATE_DECL (maskca_srcalpha_affine);
    WM_STATE_DECL (maskca_srcalpha_projective);
    WM_STATE_DECL (masknoca_affine);
    WM_STATE_DECL (masknoca_projective);

    uint32_t binding_table[128];

    struct brw_surface_state_padded surface_state[32];

    /* Index by [src_filter][src_extend][mask_filter][mask_extend].  Two of
     * the structs happen to add to 32 bytes.
     */
    struct brw_sampler_state sampler_state[SAMPLER_STATE_FILTER_COUNT]
					  [SAMPLER_STATE_EXTEND_COUNT]
					  [SAMPLER_STATE_FILTER_COUNT]
					  [SAMPLER_STATE_EXTEND_COUNT][2];

    struct brw_sampler_default_color sampler_default_color;
    PAD64 (brw_sampler_default_color, 0);

d472 3
a474 2
    struct brw_cc_viewport cc_viewport;
    PAD64 (brw_cc_viewport, 0);
d476 16
a491 2
    float vb[MAX_VERTEX_PER_COMPOSITE * MAX_VERTEX_BUFFERS];
} gen4_state_t;
d495 15
a509 2
    gen4_state_t *card_state;
    uint32_t card_state_offset;
a510 2
    int binding_table_index;
    int surface_state_index;
d513 2
d524 2
a525 2
static void
sf_state_init (struct brw_sf_unit_state *sf_state, int kernel_offset)
d527 9
d538 5
d570 21
a590 2
    assert((kernel_offset & 63) == 0);
    sf_state->thread0.kernel_start_pointer = kernel_offset >> 6;
d594 2
a595 1
sampler_state_init (struct brw_sampler_state *sampler_state,
d598 1
a598 1
		    int default_color_offset)
d600 5
d609 4
a612 1
    sampler_state->ss0.default_color_mode = 0; /* GL mode */
d638 10
d650 5
a654 2
    assert((default_color_offset & 31) == 0);
    sampler_state->ss2.default_color_pointer = default_color_offset >> 5;
d659 32
d692 2
a693 1
cc_state_init (struct brw_cc_unit_state *cc_state,
d696 1
a696 1
	       int cc_viewport_offset)
d698 5
d711 5
a715 2
    assert((cc_viewport_offset & 31) == 0);
    cc_state->cc4.cc_viewport_state_offset = cc_viewport_offset >> 5;
d735 4
a738 6
static void
wm_state_init (struct brw_wm_unit_state *wm_state,
	       Bool has_mask,
	       int scratch_offset,
	       int kernel_offset,
	       int sampler_state_offset)
d740 9
d751 6
d759 3
a761 2
    assert((scratch_offset & 1023) == 0);
    wm_state->thread2.scratch_space_base_pointer = scratch_offset >> 10;
a762 1
    wm_state->thread2.per_thread_scratch_space = PS_SCRATCH_SPACE_LOG;
a770 2
    assert((sampler_state_offset & 31) == 0);
    wm_state->wm4.sampler_state_pointer = sampler_state_offset >> 5;
d772 6
a787 3
    assert((kernel_offset & 63) == 0);
    wm_state->thread0.kernel_start_pointer = kernel_offset >> 6;

d796 21
d819 2
a820 5
/**
 * Called at EnterVT to fill in our state buffer with any static information.
 */
static void
gen4_state_init (struct gen4_render_state *render_state)
d822 2
a823 19
    int i, j, k, l;
    gen4_state_t *card_state = render_state->card_state;
    uint32_t state_base_offset = render_state->card_state_offset;

#define KERNEL_COPY(kernel) \
    memcpy(card_state->kernel, kernel ## _static, sizeof(kernel ## _static))

    KERNEL_COPY (sip_kernel);
    KERNEL_COPY (sf_kernel);
    KERNEL_COPY (sf_kernel_mask);
    KERNEL_COPY (ps_kernel_nomask_affine);
    KERNEL_COPY (ps_kernel_nomask_projective);
    KERNEL_COPY (ps_kernel_maskca_affine);
    KERNEL_COPY (ps_kernel_maskca_projective);
    KERNEL_COPY (ps_kernel_maskca_srcalpha_affine);
    KERNEL_COPY (ps_kernel_maskca_srcalpha_projective);
    KERNEL_COPY (ps_kernel_masknoca_affine);
    KERNEL_COPY (ps_kernel_masknoca_projective);
#undef KERNEL_COPY
d826 4
a829 43
    memset(&card_state->vs_state, 0, sizeof(card_state->vs_state));
    card_state->vs_state.thread4.nr_urb_entries = URB_VS_ENTRIES;
    card_state->vs_state.thread4.urb_entry_allocation_size =
	URB_VS_ENTRY_SIZE - 1;
    card_state->vs_state.vs6.vs_enable = 0;
    card_state->vs_state.vs6.vert_cache_disable = 1;

    /* Set up the sampler default color (always transparent black) */
    memset(&card_state->sampler_default_color, 0,
	   sizeof(card_state->sampler_default_color));
    card_state->sampler_default_color.color[0] = 0.0; /* R */
    card_state->sampler_default_color.color[1] = 0.0; /* G */
    card_state->sampler_default_color.color[2] = 0.0; /* B */
    card_state->sampler_default_color.color[3] = 0.0; /* A */

    card_state->cc_viewport.min_depth = -1.e35;
    card_state->cc_viewport.max_depth = 1.e35;

    sf_state_init (&card_state->sf_state,
		   state_base_offset +
		   offsetof (gen4_state_t, sf_kernel));
    sf_state_init (&card_state->sf_state_mask,
		   state_base_offset +
		   offsetof (gen4_state_t, sf_kernel_mask));

    for (i = 0; i < SAMPLER_STATE_FILTER_COUNT; i++) {
	for (j = 0; j < SAMPLER_STATE_EXTEND_COUNT; j++) {
	    for (k = 0; k < SAMPLER_STATE_FILTER_COUNT; k++) {
		for (l = 0; l < SAMPLER_STATE_EXTEND_COUNT; l++) {
		    sampler_state_init (&card_state->sampler_state[i][j][k][l][0],
					i, j,
					state_base_offset +
					offsetof (gen4_state_t,
						  sampler_default_color));
		    sampler_state_init (&card_state->sampler_state[i][j][k][l][1],
					k, l,
					state_base_offset +
					offsetof (gen4_state_t,
						  sampler_default_color));
		}
	    }
	}
    }
d831 3
d835 18
d855 4
a858 3
	    cc_state_init (&card_state->cc_state[i][j].state, i, j,
			   state_base_offset +
			   offsetof (gen4_state_t, cc_viewport));
d861 1
d863 1
a863 9
#define SETUP_WM_STATE(kernel, has_mask)				\
    wm_state_init(&card_state->wm_state_ ## kernel [i][j][k][l],	\
		  has_mask,						\
		  state_base_offset + offsetof(gen4_state_t,		\
					       wm_scratch),		\
		  state_base_offset + offsetof(gen4_state_t,		\
					       ps_kernel_ ## kernel),	\
		  state_base_offset + offsetof(gen4_state_t,		\
					       sampler_state[i][j][k][l]));
d865 1
a865 18

    for (i = 0; i < SAMPLER_STATE_FILTER_COUNT; i++) {
	for (j = 0; j < SAMPLER_STATE_EXTEND_COUNT; j++) {
	    for (k = 0; k < SAMPLER_STATE_FILTER_COUNT; k++) {
		for (l = 0; l < SAMPLER_STATE_EXTEND_COUNT; l++) {
		    SETUP_WM_STATE (nomask_affine, FALSE);
		    SETUP_WM_STATE (nomask_projective, FALSE);
		    SETUP_WM_STATE (maskca_affine, TRUE);
		    SETUP_WM_STATE (maskca_projective, TRUE);
		    SETUP_WM_STATE (maskca_srcalpha_affine, TRUE);
		    SETUP_WM_STATE (maskca_srcalpha_projective, TRUE);
		    SETUP_WM_STATE (masknoca_affine, TRUE);
		    SETUP_WM_STATE (masknoca_projective, TRUE);
		}
	    }
	}
    }
#undef SETUP_WM_STATE
d898 1
a898 1
sampler_state_extend_from_picture (int repeat)
d900 1
a900 1
    switch (repeat) {
d905 4
d915 2
a916 3
 * Sets up the common fields for a surface state buffer for the given picture
 * in the surface state buffer at index, and returns the offset within the
 * state buffer for this entry.
d918 2
a919 2
static unsigned int
i965_set_picture_surface_state(ScrnInfoPtr pScrn, struct brw_surface_state *ss,
d923 1
a923 3
    I830Ptr pI830 = I830PTR(pScrn);
    struct gen4_render_state *render_state= pI830->gen4_render_state;
    gen4_state_t *card_state = render_state->card_state;
d925 3
a927 1
    uint32_t offset;
d955 4
a958 1
    local_ss.ss1.base_addr = intel_get_pixmap_offset(pPixmap);
d970 2
a971 2
    offset = (char *)ss - (char *)card_state;
    assert((offset & 31) == 0);
d973 13
a985 1
    return offset;
d988 2
a989 4
Bool
i965_prepare_composite(int op, PicturePtr pSrcPicture,
		       PicturePtr pMaskPicture, PicturePtr pDstPicture,
		       PixmapPtr pSrc, PixmapPtr pMask, PixmapPtr pDst)
a990 1
    ScrnInfoPtr pScrn = xf86Screens[pSrcPicture->pDrawable->pScreen->myNum];
d993 11
a1003 6
    gen4_state_t *card_state = render_state->card_state;
    struct brw_surface_state_padded *ss;
    uint32_t sf_state_offset;
    sampler_state_filter_t src_filter, mask_filter;
    sampler_state_extend_t src_extend, mask_extend;
    Bool is_affine_src, is_affine_mask, is_affine;
a1008 2
    char *state_base;
    int state_base_offset;
d1010 3
a1012 1
    uint32_t *binding_table;
d1015 1
a1015 25
    *pI830->last_3d = LAST_3D_RENDER;

    pI830->scale_units[0][0] = pSrc->drawable.width;
    pI830->scale_units[0][1] = pSrc->drawable.height;

    pI830->transform[0] = pSrcPicture->transform;
    is_affine_src = i830_transform_is_affine (pI830->transform[0]);

    if (!pMask) {
	pI830->transform[1] = NULL;
	pI830->scale_units[1][0] = -1;
	pI830->scale_units[1][1] = -1;
	is_affine_mask = TRUE;
    } else {
	pI830->transform[1] = pMaskPicture->transform;
	pI830->scale_units[1][0] = pMask->drawable.width;
	pI830->scale_units[1][1] = pMask->drawable.height;
	is_affine_mask = i830_transform_is_affine (pI830->transform[1]);
    }

    is_affine = is_affine_src && is_affine_mask;

    state_base_offset = pI830->gen4_render_state_mem->offset;
    assert((state_base_offset & 63) == 0);
    state_base = (char *)(pI830->FbBase + state_base_offset);
a1030 61
    if ((render_state->binding_table_index + 3 >=
	 ARRAY_SIZE(card_state->binding_table)) ||
	(render_state->surface_state_index + 3 >=
	 ARRAY_SIZE(card_state->surface_state)))
    {
	i830WaitSync(pScrn);
	render_state->binding_table_index = 0;
	render_state->surface_state_index = 0;
	render_state->vb_offset = 0;
    }

    binding_table = card_state->binding_table +
	render_state->binding_table_index;
    ss = card_state->surface_state + render_state->surface_state_index;
    /* We only use 2 or 3 entries, but the table has to be 32-byte
     * aligned.
     */
    render_state->binding_table_index += 8;
    render_state->surface_state_index += (pMask != NULL) ? 3 : 2;

    /* Set up and bind the state buffer for the destination surface */
    binding_table[0] = state_base_offset +
	i965_set_picture_surface_state(pScrn,
				       &ss[0].state,
				       pDstPicture, pDst, TRUE);

    /* Set up and bind the source surface state buffer */
    binding_table[1] = state_base_offset +
	i965_set_picture_surface_state(pScrn,
				       &ss[1].state,
				       pSrcPicture, pSrc, FALSE);
    if (pMask) {
	/* Set up and bind the mask surface state buffer */
	binding_table[2] = state_base_offset +
	    i965_set_picture_surface_state(pScrn,
					   &ss[2].state,
					   pMaskPicture, pMask,
					   FALSE);
    } else {
	binding_table[2] = 0;
    }

    src_filter = sampler_state_filter_from_picture (pSrcPicture->filter);
    if (src_filter < 0)
	I830FALLBACK ("Bad src filter 0x%x\n", pSrcPicture->filter);
    src_extend = sampler_state_extend_from_picture (pSrcPicture->repeat);
    if (src_extend < 0)
	I830FALLBACK ("Bad src repeat 0x%x\n", pSrcPicture->repeat);

    if (pMaskPicture) {
	mask_filter = sampler_state_filter_from_picture (pMaskPicture->filter);
	if (mask_filter < 0)
	    I830FALLBACK ("Bad mask filter 0x%x\n", pMaskPicture->filter);
	mask_extend = sampler_state_extend_from_picture (pMaskPicture->repeat);
	if (mask_extend < 0)
	    I830FALLBACK ("Bad mask repeat 0x%x\n", pMaskPicture->repeat);
    } else {
	mask_filter = SAMPLER_STATE_FILTER_NEAREST;
	mask_extend = SAMPLER_STATE_EXTEND_NONE;
    }

d1046 1
a1046 1
	if (IS_GM45(pI830) || IS_G4X(pI830))
d1069 2
a1070 1
	OUT_BATCH(state_base_offset + offsetof(gen4_state_t, sip_kernel));
d1092 1
a1092 2
	assert((((unsigned char *)binding_table - pI830->FbBase) & 31) == 0);
	OUT_BATCH((unsigned char *)binding_table - pI830->FbBase);
d1110 1
a1110 2
	assert((offsetof(gen4_state_t, vs_state) & 31) == 0);
	OUT_BATCH(state_base_offset + offsetof(gen4_state_t, vs_state));
a1112 24

	if (pMask) {
	    sf_state_offset = state_base_offset +
		offsetof(gen4_state_t, sf_state_mask);
	} else {
	    sf_state_offset = state_base_offset +
		offsetof(gen4_state_t, sf_state);
	}
	assert((sf_state_offset & 31) == 0);
	OUT_BATCH(sf_state_offset);

	/* Shorthand for long array lookup */
#define OUT_WM_KERNEL(kernel) do {					\
    uint32_t offset = state_base_offset +				\
	offsetof(gen4_state_t,						\
		 wm_state_ ## kernel					\
		 [src_filter]						\
		 [src_extend]						\
		 [mask_filter]						\
		 [mask_extend]);					\
    assert((offset & 31) == 0);						\
    OUT_BATCH(offset);							\
} while (0)

d1114 2
a1115 20
	    if (pMaskPicture->componentAlpha &&
		PICT_FORMAT_RGB(pMaskPicture->format))
	    {
		if (i965_blend_op[op].src_alpha) {
		    if (is_affine)
			OUT_WM_KERNEL(maskca_srcalpha_affine);
		    else
			OUT_WM_KERNEL(maskca_srcalpha_projective);
		} else {
		    if (is_affine)
			OUT_WM_KERNEL(maskca_affine);
		    else
			OUT_WM_KERNEL(maskca_projective);
		}
	    } else {
		if (is_affine)
		    OUT_WM_KERNEL(masknoca_affine);
		else
		    OUT_WM_KERNEL(masknoca_projective);
	    }
d1117 2
a1118 4
	    if (is_affine)
		OUT_WM_KERNEL(nomask_affine);
	    else
		OUT_WM_KERNEL(nomask_projective);
a1119 1
#undef OUT_WM_KERNEL
d1121 9
a1129 5
	/* 64 byte aligned */
	assert((offsetof(gen4_state_t,
			 cc_state[src_blend][dst_blend]) & 63) == 0);
	OUT_BATCH(state_base_offset +
		  offsetof(gen4_state_t, cc_state[src_blend][dst_blend]));
d1224 187
d1414 27
a1446 1
    gen4_state_t *card_state = pI830->gen4_render_state->card_state;
a1448 1
    Bool is_affine_src, is_affine_mask, is_affine;
a1449 1
    float *vb = card_state->vb;
d1451 3
a1454 4
    is_affine_src = i830_transform_is_affine (pI830->transform[0]);
    is_affine_mask = i830_transform_is_affine (pI830->transform[1]);
    is_affine = is_affine_src && is_affine_mask;
    
d1525 4
a1528 6
    if (render_state->vb_offset + MAX_VERTEX_PER_COMPOSITE >= ARRAY_SIZE(card_state->vb)) {
	i830WaitSync(pScrn);
	render_state->vb_offset = 0;
    }

    i = render_state->vb_offset;
d1570 9
a1578 1
    assert (i * 4 <= sizeof(card_state->vb));
d1587 1
a1587 2
    OUT_BATCH(render_state->card_state_offset + offsetof(gen4_state_t, vb) +
	      render_state->vb_offset * 4);
d1603 4
a1606 1
    render_state->vb_offset = i;
d1612 14
a1625 14
    /* we must be sure that the pipeline is flushed before next exa draw,
       because that will be new state, binding state and instructions*/
    {
	BEGIN_BATCH(4);
	OUT_BATCH(BRW_PIPE_CONTROL |
		  BRW_PIPE_CONTROL_NOWRITE |
		  BRW_PIPE_CONTROL_WC_FLUSH |
		  BRW_PIPE_CONTROL_IS_FLUSH |
		  (1 << 10) |  /* XXX texture cache flush for BLC/CTG */
		  2);
	OUT_BATCH(0); /* Destination address */
	OUT_BATCH(0); /* Immediate data low DW */
	OUT_BATCH(0); /* Immediate data high DW */
	ADVANCE_BATCH();
d1628 1
a1628 4
    /* Mark sync so we can wait for it before setting up the VB on the next
     * rectangle.
     */
    i830MarkSync(pScrn);
d1639 3
d1647 1
d1649 1
a1649 3
    render_state->card_state_offset = pI830->gen4_render_state_mem->offset;
    render_state->card_state = (gen4_state_t *)
	(pI830->FbBase + render_state->card_state_offset);
d1651 57
a1707 1
    gen4_state_init(render_state);
d1717 2
d1720 30
a1749 7
    pI830->gen4_render_state->card_state = NULL;
}

unsigned int
gen4_render_state_size(ScrnInfoPtr pScrn)
{
    return sizeof(gen4_state_t);
@


1.2
log
@Update to xf86-video-intel 2.3.1. Tested by many.
@
text
@d2 2
a3 1
 * Copyright © 2006 Intel Corporation
d27 2
d62 3
d108 8
d265 14
a278 38
static int urb_vs_start, urb_vs_size;
static int urb_gs_start, urb_gs_size;
static int urb_clip_start, urb_clip_size;
static int urb_sf_start, urb_sf_size;
static int urb_cs_start, urb_cs_size;

static struct brw_surface_state *dest_surf_state, dest_surf_state_local;
static struct brw_surface_state *src_surf_state, src_surf_state_local;
static struct brw_surface_state *mask_surf_state, mask_surf_state_local;
static struct brw_sampler_state *src_sampler_state, src_sampler_state_local;
static struct brw_sampler_state *mask_sampler_state, mask_sampler_state_local;
static struct brw_sampler_default_color *default_color_state;

static struct brw_vs_unit_state *vs_state, vs_state_local;
static struct brw_sf_unit_state *sf_state, sf_state_local;
static struct brw_wm_unit_state *wm_state, wm_state_local;
static struct brw_cc_unit_state *cc_state, cc_state_local;
static struct brw_cc_viewport *cc_viewport;

static struct brw_instruction *sf_kernel;
static struct brw_instruction *ps_kernel;
static struct brw_instruction *sip_kernel;

static uint32_t *binding_table;
static int binding_table_entries;

static int dest_surf_offset, src_surf_offset, mask_surf_offset;
static int src_sampler_offset, mask_sampler_offset,vs_offset;
static int sf_offset, wm_offset, cc_offset, vb_offset, cc_viewport_offset;
static int sf_kernel_offset, ps_kernel_offset, sip_kernel_offset;
static int wm_scratch_offset;
static int binding_table_offset;
static int default_color_offset;
static int next_offset, total_state_size;
static char *state_base;
static int state_base_offset;
static float *vb;
static int vb_size = (2 + 3 + 3) * 3 * 4;   /* (dst, src, mask) 3 vertices, 4 bytes */
d280 2
a281 1
static uint32_t src_blend, dst_blend;
d318 1
a318 1
static const uint32_t sf_kernel_static_mask[][4] = {
d328 1
a328 1
static const uint32_t ps_kernel_static_nomask_affine [][4] = {
d335 1
a335 1
static const uint32_t ps_kernel_static_nomask_projective [][4] = {
d342 1
a342 1
static const uint32_t ps_kernel_static_maskca_affine [][4] = {
d352 1
a352 1
static const uint32_t ps_kernel_static_maskca_projective [][4] = {
d362 1
a362 1
static const uint32_t ps_kernel_static_maskca_srcalpha_affine [][4] = {
d372 1
a372 1
static const uint32_t ps_kernel_static_maskca_srcalpha_projective [][4] = {
d382 1
a382 1
static const uint32_t ps_kernel_static_masknoca_affine [][4] = {
d392 1
a392 1
static const uint32_t ps_kernel_static_masknoca_projective [][4] = {
d402 399
d812 2
d817 86
d910 6
a915 5
    uint32_t src_offset, src_pitch, src_tile_format = 0, src_tiled = 0;
    uint32_t mask_offset = 0, mask_pitch = 0, mask_tile_format = 0,
	mask_tiled = 0;
    uint32_t dst_format, dst_offset, dst_pitch, dst_tile_format = 0,
	dst_tiled = 0;
d917 9
a929 20
    src_offset = intel_get_pixmap_offset(pSrc);
    src_pitch = intel_get_pixmap_pitch(pSrc);
    if (i830_pixmap_tiled(pSrc)) {
	src_tiled = 1;
	src_tile_format = 0; /* Tiled X */
    }
    dst_offset = intel_get_pixmap_offset(pDst);
    dst_pitch = intel_get_pixmap_pitch(pDst);
    if (i830_pixmap_tiled(pDst)) {
	dst_tiled = 1;
	dst_tile_format = 0; /* Tiled X */
    }
    if (pMask) {
	mask_offset = intel_get_pixmap_offset(pMask);
	mask_pitch = intel_get_pixmap_pitch(pMask);
	if (i830_pixmap_tiled(pMask)) {
	    mask_tiled = 1;
	    mask_tile_format = 0; /* Tiled X */
	}
    }
d950 2
a951 101
    /* setup 3d pipeline state */

    binding_table_entries = 2; /* default no mask */

    /* Set up our layout of state in framebuffer.  First the general state: */
    next_offset = 0;
    vs_offset = ALIGN(next_offset, 64);
    next_offset = vs_offset + sizeof(*vs_state);

    sf_offset = ALIGN(next_offset, 32);
    next_offset = sf_offset + sizeof(*sf_state);

    wm_offset = ALIGN(next_offset, 32);
    next_offset = wm_offset + sizeof(*wm_state);

    wm_scratch_offset = ALIGN(next_offset, 1024);
    next_offset = wm_scratch_offset + PS_SCRATCH_SPACE * PS_MAX_THREADS;

    cc_offset = ALIGN(next_offset, 32);
    next_offset = cc_offset + sizeof(*cc_state);

    /* keep current sf_kernel, which will send one setup urb entry to
     * PS kernel
     */
    sf_kernel_offset = ALIGN(next_offset, 64);
    if (pMask)
	next_offset = sf_kernel_offset + sizeof (sf_kernel_static_mask);
    else 
	next_offset = sf_kernel_offset + sizeof (sf_kernel_static);

    ps_kernel_offset = ALIGN(next_offset, 64);
    if (pMask) {
	if (pMaskPicture->componentAlpha && 
                PICT_FORMAT_RGB(pMaskPicture->format)) {
            if (i965_blend_op[op].src_alpha) {
		if (is_affine)
		    next_offset = ps_kernel_offset + sizeof(ps_kernel_static_maskca_srcalpha_affine);
		else
		    next_offset = ps_kernel_offset + sizeof(ps_kernel_static_maskca_srcalpha_projective);
            } else {
		if (is_affine)
		    next_offset = ps_kernel_offset + sizeof(ps_kernel_static_maskca_affine);
		else
		    next_offset = ps_kernel_offset + sizeof(ps_kernel_static_maskca_projective);
            }
        } else {
	    if (is_affine)
		next_offset = ps_kernel_offset + sizeof(ps_kernel_static_masknoca_affine);
	    else
		next_offset = ps_kernel_offset + sizeof(ps_kernel_static_masknoca_projective);
	}
    } else {
	if (is_affine)
	    next_offset = ps_kernel_offset + sizeof (ps_kernel_static_nomask_affine);
	else
	    next_offset = ps_kernel_offset + sizeof (ps_kernel_static_nomask_projective);
    }

    sip_kernel_offset = ALIGN(next_offset, 64);
    next_offset = sip_kernel_offset + sizeof (sip_kernel_static);

    /* needed? */
    cc_viewport_offset = ALIGN(next_offset, 32);
    next_offset = cc_viewport_offset + sizeof(*cc_viewport);

    /* for texture sampler */
    src_sampler_offset = ALIGN(next_offset, 32);
    next_offset = src_sampler_offset + sizeof(*src_sampler_state);

    if (pMask) {
   	mask_sampler_offset = ALIGN(next_offset, 32);
   	next_offset = mask_sampler_offset + sizeof(*mask_sampler_state);
    }
    /* Align VB to native size of elements, for safety */
    vb_offset = ALIGN(next_offset, 32);
    next_offset = vb_offset + vb_size;

    /* And then the general state: */
    dest_surf_offset = ALIGN(next_offset, 32);
    next_offset = dest_surf_offset + sizeof(*dest_surf_state);

    src_surf_offset = ALIGN(next_offset, 32);
    next_offset = src_surf_offset + sizeof(*src_surf_state);

    if (pMask) {
   	mask_surf_offset = ALIGN(next_offset, 32);
   	next_offset = mask_surf_offset + sizeof(*mask_surf_state);
	binding_table_entries = 3;
    }

    binding_table_offset = ALIGN(next_offset, 32);
    next_offset = binding_table_offset + (binding_table_entries * 4);

    default_color_offset = ALIGN(next_offset, 32);
    next_offset = default_color_offset + sizeof(*default_color_state);

    total_state_size = next_offset;
    assert(total_state_size < pI830->exa_965_state->size);

    state_base_offset = pI830->exa_965_state->offset;
    state_base_offset = ALIGN(state_base_offset, 64);
a953 30
    sf_kernel = (void *)(state_base + sf_kernel_offset);
    ps_kernel = (void *)(state_base + ps_kernel_offset);
    sip_kernel = (void *)(state_base + sip_kernel_offset);

    cc_viewport = (void *)(state_base + cc_viewport_offset);

    binding_table = (void *)(state_base + binding_table_offset);

    vb = (void *)(state_base + vb_offset);

    default_color_state = (void*)(state_base + default_color_offset);

    /* Set up a default static partitioning of the URB, which is supposed to
     * allow anything we would want to do, at potentially lower performance.
     */
#define URB_CS_ENTRY_SIZE     0
#define URB_CS_ENTRIES	      0

#define URB_VS_ENTRY_SIZE     1	  // each 512-bit row
#define URB_VS_ENTRIES	      8	  // we needs at least 8 entries

#define URB_GS_ENTRY_SIZE     0
#define URB_GS_ENTRIES	      0

#define URB_CLIP_ENTRY_SIZE   0
#define URB_CLIP_ENTRIES      0

#define URB_SF_ENTRY_SIZE     2
#define URB_SF_ENTRIES	      1

a964 24
    /* Because we only have a single static buffer for our state currently,
     * we have to sync before updating it every time.
     */
    i830WaitSync(pScrn);

    memset (cc_viewport, 0, sizeof (*cc_viewport));
    cc_viewport->min_depth = -1.e35;
    cc_viewport->max_depth = 1.e35;

    /* Color calculator state */
    cc_state = &cc_state_local;
    memset(cc_state, 0, sizeof(*cc_state));
    cc_state->cc0.stencil_enable = 0;   /* disable stencil */
    cc_state->cc2.depth_test = 0;       /* disable depth test */
    cc_state->cc2.logicop_enable = 0;   /* disable logic op */
    cc_state->cc3.ia_blend_enable = 1;  /* blend alpha just like colors */
    cc_state->cc3.blend_enable = 1;     /* enable color blend */
    cc_state->cc3.alpha_test = 0;       /* disable alpha test */
    cc_state->cc4.cc_viewport_state_offset = (state_base_offset +
					      cc_viewport_offset) >> 5;
    cc_state->cc5.dither_enable = 0;    /* disable dither */
    cc_state->cc5.logicop_func = 0xc;   /* COPY */
    cc_state->cc5.statistics_enable = 1;
    cc_state->cc5.ia_blend_function = BRW_BLENDFUNCTION_ADD;
a966 11
    /* XXX: alpha blend factor should be same as color, but check
     * for CA case in future
     */
    cc_state->cc5.ia_src_blend_factor = src_blend;
    cc_state->cc5.ia_dest_blend_factor = dst_blend;
    cc_state->cc6.blend_function = BRW_BLENDFUNCTION_ADD;
    cc_state->cc6.src_blend_factor = src_blend;
    cc_state->cc6.dest_blend_factor = dst_blend;
    cc_state->cc6.clamp_post_alpha_blend = 1;
    cc_state->cc6.clamp_pre_alpha_blend = 1;
    cc_state->cc6.clamp_range = 0;  /* clamp range [0,1] */
d968 10
a977 2
    cc_state = (void *)(state_base + cc_offset);
    memcpy (cc_state, &cc_state_local, sizeof (cc_state_local));
d979 8
a986 61
    /* Upload system kernel */
    memcpy (sip_kernel, sip_kernel_static, sizeof (sip_kernel_static));

    /* Set up the state buffer for the destination surface */
    dest_surf_state = &dest_surf_state_local;
    memset(dest_surf_state, 0, sizeof(*dest_surf_state));
    dest_surf_state->ss0.surface_type = BRW_SURFACE_2D;
    dest_surf_state->ss0.data_return_format = BRW_SURFACERETURNFORMAT_FLOAT32;
    if (!i965_get_dest_format(pDstPicture, &dst_format))
	return FALSE;
    dest_surf_state->ss0.surface_format = dst_format;

    dest_surf_state->ss0.writedisable_alpha = 0;
    dest_surf_state->ss0.writedisable_red = 0;
    dest_surf_state->ss0.writedisable_green = 0;
    dest_surf_state->ss0.writedisable_blue = 0;
    dest_surf_state->ss0.color_blend = 1;
    dest_surf_state->ss0.vert_line_stride = 0;
    dest_surf_state->ss0.vert_line_stride_ofs = 0;
    dest_surf_state->ss0.mipmap_layout_mode = 0;
    dest_surf_state->ss0.render_cache_read_mode = 0;

    dest_surf_state->ss1.base_addr = dst_offset;
    dest_surf_state->ss2.height = pDst->drawable.height - 1;
    dest_surf_state->ss2.width = pDst->drawable.width - 1;
    dest_surf_state->ss2.mip_count = 0;
    dest_surf_state->ss2.render_target_rotation = 0;
    dest_surf_state->ss3.pitch = dst_pitch - 1;
    dest_surf_state->ss3.tile_walk = dst_tile_format;
    dest_surf_state->ss3.tiled_surface = dst_tiled;

    dest_surf_state = (void *)(state_base + dest_surf_offset);
    memcpy (dest_surf_state, &dest_surf_state_local, sizeof (dest_surf_state_local));

    /* Set up the source surface state buffer */
    src_surf_state = &src_surf_state_local;
    memset(src_surf_state, 0, sizeof(*src_surf_state));
    src_surf_state->ss0.surface_type = BRW_SURFACE_2D;
    src_surf_state->ss0.surface_format = i965_get_card_format(pSrcPicture);

    src_surf_state->ss0.writedisable_alpha = 0;
    src_surf_state->ss0.writedisable_red = 0;
    src_surf_state->ss0.writedisable_green = 0;
    src_surf_state->ss0.writedisable_blue = 0;
    src_surf_state->ss0.color_blend = 1;
    src_surf_state->ss0.vert_line_stride = 0;
    src_surf_state->ss0.vert_line_stride_ofs = 0;
    src_surf_state->ss0.mipmap_layout_mode = 0;
    src_surf_state->ss0.render_cache_read_mode = 0;

    src_surf_state->ss1.base_addr = src_offset;
    src_surf_state->ss2.width = pSrc->drawable.width - 1;
    src_surf_state->ss2.height = pSrc->drawable.height - 1;
    src_surf_state->ss2.mip_count = 0;
    src_surf_state->ss2.render_target_rotation = 0;
    src_surf_state->ss3.pitch = src_pitch - 1;
    src_surf_state->ss3.tile_walk = src_tile_format;
    src_surf_state->ss3.tiled_surface = src_tiled;

    src_surf_state = (void *)(state_base + src_surf_offset);
    memcpy (src_surf_state, &src_surf_state_local, sizeof (src_surf_state_local));
d988 11
a998 1
    /* setup mask surface */
d1000 6
a1005 66
	mask_surf_state = &mask_surf_state_local;
   	memset(mask_surf_state, 0, sizeof(*mask_surf_state));
	mask_surf_state->ss0.surface_type = BRW_SURFACE_2D;
   	mask_surf_state->ss0.surface_format =
	    i965_get_card_format(pMaskPicture);

   	mask_surf_state->ss0.writedisable_alpha = 0;
   	mask_surf_state->ss0.writedisable_red = 0;
   	mask_surf_state->ss0.writedisable_green = 0;
   	mask_surf_state->ss0.writedisable_blue = 0;
   	mask_surf_state->ss0.color_blend = 1;
   	mask_surf_state->ss0.vert_line_stride = 0;
   	mask_surf_state->ss0.vert_line_stride_ofs = 0;
   	mask_surf_state->ss0.mipmap_layout_mode = 0;
   	mask_surf_state->ss0.render_cache_read_mode = 0;

   	mask_surf_state->ss1.base_addr = mask_offset;
   	mask_surf_state->ss2.width = pMask->drawable.width - 1;
   	mask_surf_state->ss2.height = pMask->drawable.height - 1;
   	mask_surf_state->ss2.mip_count = 0;
   	mask_surf_state->ss2.render_target_rotation = 0;
   	mask_surf_state->ss3.pitch = mask_pitch - 1;
	mask_surf_state->ss3.tile_walk = mask_tile_format;
	mask_surf_state->ss3.tiled_surface = mask_tiled;

	mask_surf_state = (void *)(state_base + mask_surf_offset);
	memcpy (mask_surf_state, &mask_surf_state_local, sizeof (mask_surf_state_local));
    }

    /* Set up a binding table for our surfaces.  Only the PS will use it */
    binding_table[0] = state_base_offset + dest_surf_offset;
    binding_table[1] = state_base_offset + src_surf_offset;
    if (pMask)
   	binding_table[2] = state_base_offset + mask_surf_offset;

    /* PS kernel use this sampler */
    src_sampler_state = &src_sampler_state_local;
    memset(src_sampler_state, 0, sizeof(*src_sampler_state));
    src_sampler_state->ss0.lod_preclamp = 1; /* GL mode */
    switch(pSrcPicture->filter) {
    case PictFilterNearest:
   	src_sampler_state->ss0.min_filter = BRW_MAPFILTER_NEAREST;
   	src_sampler_state->ss0.mag_filter = BRW_MAPFILTER_NEAREST;
	break;
    case PictFilterBilinear:
	src_sampler_state->ss0.min_filter = BRW_MAPFILTER_LINEAR;
   	src_sampler_state->ss0.mag_filter = BRW_MAPFILTER_LINEAR;
	break;
    default:
	I830FALLBACK("Bad filter 0x%x\n", pSrcPicture->filter);
    }

    memset(default_color_state, 0, sizeof(*default_color_state));
    default_color_state->color[0] = 0.0; /* R */
    default_color_state->color[1] = 0.0; /* G */
    default_color_state->color[2] = 0.0; /* B */
    default_color_state->color[3] = 0.0; /* A */

    src_sampler_state->ss0.default_color_mode = 0; /* GL mode */

    if (!pSrcPicture->repeat) {
   	src_sampler_state->ss1.r_wrap_mode = BRW_TEXCOORDMODE_CLAMP_BORDER;
   	src_sampler_state->ss1.s_wrap_mode = BRW_TEXCOORDMODE_CLAMP_BORDER;
   	src_sampler_state->ss1.t_wrap_mode = BRW_TEXCOORDMODE_CLAMP_BORDER;
	src_sampler_state->ss2.default_color_pointer =
	    (state_base_offset + default_color_offset) >> 5;
d1007 1
a1007 3
   	src_sampler_state->ss1.r_wrap_mode = BRW_TEXCOORDMODE_WRAP;
   	src_sampler_state->ss1.s_wrap_mode = BRW_TEXCOORDMODE_WRAP;
   	src_sampler_state->ss1.t_wrap_mode = BRW_TEXCOORDMODE_WRAP;
a1008 95
    src_sampler_state->ss3.chroma_key_enable = 0; /* disable chromakey */

    src_sampler_state = (void *)(state_base + src_sampler_offset);
    memcpy (src_sampler_state, &src_sampler_state_local, sizeof (src_sampler_state_local));

    if (pMask) {
	mask_sampler_state = &mask_sampler_state_local;
   	memset(mask_sampler_state, 0, sizeof(*mask_sampler_state));
   	mask_sampler_state->ss0.lod_preclamp = 1; /* GL mode */
   	switch(pMaskPicture->filter) {
   	case PictFilterNearest:
   	    mask_sampler_state->ss0.min_filter = BRW_MAPFILTER_NEAREST;
   	    mask_sampler_state->ss0.mag_filter = BRW_MAPFILTER_NEAREST;
	    break;
   	case PictFilterBilinear:
   	    mask_sampler_state->ss0.min_filter = BRW_MAPFILTER_LINEAR;
   	    mask_sampler_state->ss0.mag_filter = BRW_MAPFILTER_LINEAR;
	    break;
   	default:
	    I830FALLBACK("Bad filter 0x%x\n", pMaskPicture->filter);
   	}

	mask_sampler_state->ss0.default_color_mode = 0; /* GL mode */
   	if (!pMaskPicture->repeat) {
   	    mask_sampler_state->ss1.r_wrap_mode =
		BRW_TEXCOORDMODE_CLAMP_BORDER;
   	    mask_sampler_state->ss1.s_wrap_mode =
		BRW_TEXCOORDMODE_CLAMP_BORDER;
   	    mask_sampler_state->ss1.t_wrap_mode =
		BRW_TEXCOORDMODE_CLAMP_BORDER;
            mask_sampler_state->ss2.default_color_pointer =
		(state_base_offset + default_color_offset)>>5;
   	} else {
   	    mask_sampler_state->ss1.r_wrap_mode = BRW_TEXCOORDMODE_WRAP;
   	    mask_sampler_state->ss1.s_wrap_mode = BRW_TEXCOORDMODE_WRAP;
   	    mask_sampler_state->ss1.t_wrap_mode = BRW_TEXCOORDMODE_WRAP;
    	}
   	mask_sampler_state->ss3.chroma_key_enable = 0; /* disable chromakey */

	mask_sampler_state = (void *)(state_base + mask_sampler_offset);
	memcpy (mask_sampler_state, &mask_sampler_state_local, sizeof (mask_sampler_state_local));
    }

    /* Set up the vertex shader to be disabled (passthrough) */
    vs_state = &vs_state_local;
    memset(vs_state, 0, sizeof(*vs_state));
    vs_state->thread4.nr_urb_entries = URB_VS_ENTRIES;
    vs_state->thread4.urb_entry_allocation_size = URB_VS_ENTRY_SIZE - 1;
    vs_state->vs6.vs_enable = 0;
    vs_state->vs6.vert_cache_disable = 1;

    vs_state = (void *)(state_base + vs_offset);
    memcpy (vs_state, &vs_state_local, sizeof (vs_state_local));

    /* Set up the SF kernel to do coord interp: for each attribute,
     * calculate dA/dx and dA/dy.  Hand these interpolation coefficients
     * back to SF which then hands pixels off to WM.
     */
    if (pMask)
	memcpy(sf_kernel, sf_kernel_static_mask,
		sizeof (sf_kernel_static_mask));
    else
	memcpy(sf_kernel, sf_kernel_static, sizeof (sf_kernel_static));

    sf_state = &sf_state_local;
    memset(sf_state, 0, sizeof(*sf_state));
    sf_state->thread0.kernel_start_pointer =
	(state_base_offset + sf_kernel_offset) >> 6;
    sf_state->thread0.grf_reg_count = BRW_GRF_BLOCKS(SF_KERNEL_NUM_GRF);
    sf_state->sf1.single_program_flow = 1;
    sf_state->sf1.binding_table_entry_count = 0;
    sf_state->sf1.thread_priority = 0;
    sf_state->sf1.floating_point_mode = 0; /* Mesa does this */
    sf_state->sf1.illegal_op_exception_enable = 1;
    sf_state->sf1.mask_stack_exception_enable = 1;
    sf_state->sf1.sw_exception_enable = 1;
    sf_state->thread2.per_thread_scratch_space = 0;
    /* scratch space is not used in our kernel */
    sf_state->thread2.scratch_space_base_pointer = 0;
    sf_state->thread3.const_urb_entry_read_length = 0; /* no const URBs */
    sf_state->thread3.const_urb_entry_read_offset = 0; /* no const URBs */
    sf_state->thread3.urb_entry_read_length = 1; /* 1 URB per vertex */
    /* don't smash vertex header, read start from dw8 */
    sf_state->thread3.urb_entry_read_offset = 1;
    sf_state->thread3.dispatch_grf_start_reg = 3;
    sf_state->thread4.max_threads = SF_MAX_THREADS - 1;
    sf_state->thread4.urb_entry_allocation_size = URB_SF_ENTRY_SIZE - 1;
    sf_state->thread4.nr_urb_entries = URB_SF_ENTRIES;
    sf_state->thread4.stats_enable = 1;
    sf_state->sf5.viewport_transform = FALSE; /* skip viewport */
    sf_state->sf6.cull_mode = BRW_CULLMODE_NONE;
    sf_state->sf6.scissor = 0;
    sf_state->sf7.trifan_pv = 2;
    sf_state->sf6.dest_org_vbias = 0x8;
    sf_state->sf6.dest_org_hbias = 0x8;
d1010 14
a1023 24
    sf_state = (void *)(state_base + sf_offset);
    memcpy (sf_state, &sf_state_local, sizeof (sf_state_local));

   /* Set up the PS kernel (dispatched by WM) */
    if (pMask) {
	if (pMaskPicture->componentAlpha && 
                PICT_FORMAT_RGB(pMaskPicture->format)) {
            if (i965_blend_op[op].src_alpha) {
		if (is_affine)
		    memcpy(ps_kernel, ps_kernel_static_maskca_srcalpha_affine, sizeof (ps_kernel_static_maskca_srcalpha_affine));
		else
                    memcpy(ps_kernel, ps_kernel_static_maskca_srcalpha_projective, sizeof (ps_kernel_static_maskca_srcalpha_projective));
            } else {
		if (is_affine)
		    memcpy(ps_kernel, ps_kernel_static_maskca_affine, sizeof (ps_kernel_static_maskca_affine));
		else
		    memcpy(ps_kernel, ps_kernel_static_maskca_projective, sizeof (ps_kernel_static_maskca_projective));
	    }
        } else {
	    if (is_affine)
		memcpy(ps_kernel, ps_kernel_static_masknoca_affine, sizeof (ps_kernel_static_masknoca_affine));
	    else
		memcpy(ps_kernel, ps_kernel_static_masknoca_projective, sizeof (ps_kernel_static_masknoca_projective));
	}
d1025 2
a1026 4
	if (is_affine)
	    memcpy(ps_kernel, ps_kernel_static_nomask_affine, sizeof (ps_kernel_static_nomask_affine));
	else
	    memcpy(ps_kernel, ps_kernel_static_nomask_projective, sizeof (ps_kernel_static_nomask_projective));
a1028 42
    wm_state = &wm_state_local;
    memset(wm_state, 0, sizeof (*wm_state));
    wm_state->thread0.kernel_start_pointer =
	(state_base_offset + ps_kernel_offset) >> 6;
    wm_state->thread0.grf_reg_count = BRW_GRF_BLOCKS(PS_KERNEL_NUM_GRF);
    wm_state->thread1.single_program_flow = 0;
    if (!pMask)
	wm_state->thread1.binding_table_entry_count = 2; /* 1 tex and fb */
    else
	wm_state->thread1.binding_table_entry_count = 3; /* 2 tex and fb */

    wm_state->thread2.scratch_space_base_pointer = (state_base_offset +
						    wm_scratch_offset)>>10;
    wm_state->thread2.per_thread_scratch_space = PS_SCRATCH_SPACE_LOG; 
    wm_state->thread3.const_urb_entry_read_length = 0;
    wm_state->thread3.const_urb_entry_read_offset = 0;
    /* Each pair of attributes (src/mask coords) is one URB entry */
    if (pMask)
	wm_state->thread3.urb_entry_read_length = 4;
    else
	wm_state->thread3.urb_entry_read_length = 2;
    wm_state->thread3.urb_entry_read_offset = 0;
    /* wm kernel use urb from 3, see wm_program in compiler module */
    wm_state->thread3.dispatch_grf_start_reg = 3; /* must match kernel */

    wm_state->wm4.stats_enable = 1;  /* statistic */
    wm_state->wm4.sampler_state_pointer = (state_base_offset +
					   src_sampler_offset) >> 5;
    wm_state->wm4.sampler_count = 1; /* 1-4 samplers used */
    wm_state->wm5.max_threads = PS_MAX_THREADS - 1;
    wm_state->wm5.transposed_urb_read = 0;
    wm_state->wm5.thread_dispatch_enable = 1;
    /* just use 16-pixel dispatch (4 subspans), don't need to change kernel
     * start point
     */
    wm_state->wm5.enable_16_pix = 1;
    wm_state->wm5.enable_8_pix = 0;
    wm_state->wm5.early_depth_test = 1;

    wm_state = (void *)(state_base + wm_offset);
    memcpy (wm_state, &wm_state_local, sizeof (wm_state_local));

d1044 1
a1044 1
	if (IS_IGD_GM(pI830))
d1067 1
a1067 1
	OUT_BATCH(state_base_offset + sip_kernel_offset);
d1089 2
a1090 1
	OUT_BATCH(state_base_offset + binding_table_offset); /* ps */
d1108 2
a1109 1
	OUT_BATCH(state_base_offset + vs_offset);  /* 32 byte aligned */
d1112 58
a1169 3
	OUT_BATCH(state_base_offset + sf_offset);  /* 32 byte aligned */
	OUT_BATCH(state_base_offset + wm_offset);  /* 32 byte aligned */
	OUT_BATCH(state_base_offset + cc_offset);  /* 64 byte aligned */
d1204 2
d1217 1
a1217 10
	BEGIN_BATCH(pMask?12:10);
	/* Set up the pointer to our (single) vertex buffer */
	OUT_BATCH(BRW_3DSTATE_VERTEX_BUFFERS | 3);
	OUT_BATCH((0 << VB0_BUFFER_INDEX_SHIFT) |
		  VB0_VERTEXDATA |
		  ((4 * (2 + nelem * selem)) << VB0_BUFFER_PITCH_SHIFT));
	OUT_BATCH(state_base_offset + vb_offset);
        OUT_BATCH(3);
	OUT_BATCH(0); // ignore for VERTEXDATA, but still there

d1219 1
d1273 2
d1278 1
d1355 4
a1358 4
    /* Wait for any existing composite rectangles to land before we overwrite
     * the VB with the next one.
     */
    i830WaitSync(pScrn);
d1360 1
a1360 1
    i = 0;
d1402 27
a1428 1
    assert (i * 4 <= vb_size);
a1429 14
    {
      BEGIN_BATCH(6);
      OUT_BATCH(BRW_3DPRIMITIVE |
		BRW_3DPRIMITIVE_VERTEX_SEQUENTIAL |
		(_3DPRIM_RECTLIST << BRW_3DPRIMITIVE_TOPOLOGY_SHIFT) |
		(0 << 9) |  /* CTG - indirect vertex count */
		4);
      OUT_BATCH(3);  /* vertex count per instance */
      OUT_BATCH(0); /* start vertex offset */
      OUT_BATCH(1); /* single instance */
      OUT_BATCH(0); /* start instance location */
      OUT_BATCH(0); /* index buffer offset, ignored */
      ADVANCE_BATCH();
    }
d1454 38
@


1.1
log
@Initial revision
@
text
@d62 2
a63 2
    CARD32 src_blend;
    CARD32 dst_blend;
d68 1
a68 1
    CARD32 card_fmt;
d116 2
a117 2
static void i965_get_blend_cntl(int op, PicturePtr pMask, CARD32 dst_format,
				CARD32 *sblend, CARD32 *dblend)
d148 1
a148 1
static Bool i965_get_dest_format(PicturePtr pDstPicture, CARD32 *dst_format)
d185 1
a185 1
    if ((w > 0x7ff) || (h > 0x7ff))
d215 1
a215 1
    CARD32 tmp1;
d274 1
a274 1
static CARD32 *binding_table;
d288 1
a288 1
static int vb_size = (6 * 4) * 4 ; /* 6 DWORDS per vertex - and mask*/
d290 1
a290 1
static CARD32 src_blend, dst_blend;
d292 1
a292 1
static const CARD32 sip_kernel_static[][4] = {
d321 1
a321 1
#define SF_MAX_THREADS	   1
d323 2
a324 2
static const CARD32 sf_kernel_static[][4] = {
#include "exa_sf_prog.h"
d327 2
a328 2
static const CARD32 sf_kernel_static_mask[][4] = {
#include "exa_sf_mask_prog.h"
d331 11
a341 2
static const CARD32 sf_kernel_static_rotation[][4] = {
#include "exa_sf_rotation_prog.h"
d344 16
a359 3
/* ps kernels */
#define PS_KERNEL_NUM_GRF   32
#define PS_MAX_THREADS	   32
d361 8
a368 2
static const CARD32 ps_kernel_static_nomask [][4] = {
#include "exa_wm_nomask_prog.h"
d371 8
a378 2
static const CARD32 ps_kernel_static_maskca [][4] = {
#include "exa_wm_maskca_prog.h"
d381 8
a388 2
static const CARD32 ps_kernel_static_maskca_srcalpha [][4] = {
#include "exa_wm_maskca_srcalpha_prog.h"
d391 8
a398 2
static const CARD32 ps_kernel_static_masknoca [][4] = {
#include "exa_wm_masknoca_prog.h"
d401 8
a408 2
static const CARD32 ps_kernel_static_rotation [][4] = {
#include "exa_wm_rotation_prog.h"
d411 1
a411 1
static CARD32 
a424 15
static Bool
i965_check_rotation_transform(PictTransformPtr t)
{
    /* XXX this is arbitrary */
    int a, b;
    a = xFixedToInt(t->matrix[0][1]);
    b = xFixedToInt(t->matrix[1][0]);
    if (a == -1 && b == 1)
	return TRUE;
    else if (a == 1 && b == -1)
	return TRUE;
    else
	return FALSE;
}

d432 2
a433 2
    CARD32 src_offset, src_pitch, src_tile_format = 0, src_tiled = 0;
    CARD32 mask_offset = 0, mask_pitch = 0, mask_tile_format = 0,
d435 1
a435 1
    CARD32 dst_format, dst_offset, dst_pitch, dst_tile_format = 0,
d437 1
a437 1
    Bool rotation_program = FALSE;
d466 1
d472 1
a472 3
	if (pI830->transform[0] && 
		i965_check_rotation_transform(pI830->transform[0]))
	    rotation_program = TRUE;
a474 2
	if (pI830->transform[1])
	    I830FALLBACK("i965 mask transform not implemented!\n");
d477 1
d480 2
d498 1
a498 1
    next_offset = wm_scratch_offset + 1024 * PS_MAX_THREADS;
a508 2
    else if (rotation_program)
	next_offset = sf_kernel_offset + sizeof (sf_kernel_static_rotation);
d517 4
a520 2
                next_offset = ps_kernel_offset + 
                    sizeof(ps_kernel_static_maskca_srcalpha);
d522 4
a525 2
                next_offset = ps_kernel_offset + 
                    sizeof(ps_kernel_static_maskca);
d527 6
a532 5
        } else
	    next_offset = ps_kernel_offset + 
                          sizeof(ps_kernel_static_masknoca);
    } else if (rotation_program) {
   	next_offset = ps_kernel_offset + sizeof (ps_kernel_static_rotation);
d534 4
a537 1
   	next_offset = ps_kernel_offset + sizeof (ps_kernel_static_nomask);
d675 2
a676 1
    i965_get_dest_format(pDstPicture, &dst_format);
d824 1
a862 3
    else if (rotation_program)
	memcpy(sf_kernel, sf_kernel_static_rotation, 
		sizeof (sf_kernel_static_rotation));
d905 17
a921 12
            if (i965_blend_op[op].src_alpha) 
                memcpy(ps_kernel, ps_kernel_static_maskca_srcalpha,
                        sizeof (ps_kernel_static_maskca_srcalpha));
            else
                memcpy(ps_kernel, ps_kernel_static_maskca,
                        sizeof (ps_kernel_static_maskca));
        } else
   	    memcpy(ps_kernel, ps_kernel_static_masknoca,
		   sizeof (ps_kernel_static_masknoca));
    } else if (rotation_program) {
   	memcpy(ps_kernel, ps_kernel_static_rotation,
	       sizeof (ps_kernel_static_rotation));
d923 4
a926 2
   	memcpy(ps_kernel, ps_kernel_static_nomask,
	       sizeof (ps_kernel_static_nomask));
d934 1
a934 1
    wm_state->thread1.single_program_flow = 1;
d942 1
a942 1
    wm_state->thread2.per_thread_scratch_space = 0;
d947 2
a949 2
    else
	wm_state->thread3.urb_entry_read_length = 1;
d959 1
d975 6
a980 6
	BEGIN_LP_RING(2);
   	OUT_RING(MI_FLUSH |
		 MI_STATE_INSTRUCTION_CACHE_FLUSH |
		 BRW_MI_GLOBAL_SNAPSHOT_RESET);
	OUT_RING(MI_NOOP);
	ADVANCE_LP_RING();
d983 1
a983 1
        BEGIN_LP_RING(12);
d986 8
a993 5
        OUT_RING(BRW_PIPELINE_SELECT | PIPELINE_SELECT_3D);

   	OUT_RING(BRW_CS_URB_STATE | 0);
   	OUT_RING((0 << 4) |  /* URB Entry Allocation Size */
		 (0 << 0));  /* Number of URB Entries */
d998 4
a1001 4
   	OUT_RING(BRW_STATE_BASE_ADDRESS | 4);
   	OUT_RING(0 | BASE_ADDRESS_MODIFY);  /* Generate state base address */
   	OUT_RING(0 | BASE_ADDRESS_MODIFY);  /* Surface state base address */
   	OUT_RING(0 | BASE_ADDRESS_MODIFY);  /* media base addr, don't care */
d1003 1
a1003 1
   	OUT_RING(0x10000000 | BASE_ADDRESS_MODIFY);
d1005 1
a1005 1
   	OUT_RING(0x10000000 | BASE_ADDRESS_MODIFY);
d1008 4
a1011 4
   	OUT_RING(BRW_STATE_SIP | 0);
   	OUT_RING(state_base_offset + sip_kernel_offset);
	OUT_RING(MI_NOOP);
	ADVANCE_LP_RING();
d1014 1
a1014 1
	BEGIN_LP_RING(26);
d1016 7
a1022 7
   	OUT_RING(BRW_PIPE_CONTROL |
		 BRW_PIPE_CONTROL_NOWRITE |
		 BRW_PIPE_CONTROL_IS_FLUSH |
		 2);
   	OUT_RING(0);			       /* Destination address */
   	OUT_RING(0);			       /* Immediate data low DW */
   	OUT_RING(0);			       /* Immediate data high DW */
d1025 5
a1029 5
   	OUT_RING(BRW_3DSTATE_BINDING_TABLE_POINTERS | 4);
   	OUT_RING(0); /* vs */
   	OUT_RING(0); /* gs */
   	OUT_RING(0); /* clip */
   	OUT_RING(0); /* sf */
d1031 1
a1031 1
   	OUT_RING(state_base_offset + binding_table_offset); /* ps */
d1036 5
a1040 5
   	OUT_RING(BRW_3DSTATE_DRAWING_RECTANGLE | 2); /* XXX 3 for BLC or CTG */
   	OUT_RING(0x00000000);	/* ymin, xmin */
	OUT_RING(DRAW_YMAX(pDst->drawable.height - 1) |
		 DRAW_XMAX(pDst->drawable.width - 1)); /* ymax, xmax */
   	OUT_RING(0x00000000);	/* yorigin, xorigin */
d1048 7
a1054 7
   	OUT_RING(BRW_3DSTATE_PIPELINED_POINTERS | 5);
   	OUT_RING(state_base_offset + vs_offset);  /* 32 byte aligned */
   	OUT_RING(BRW_GS_DISABLE);   /* disable GS, resulting in passthrough */
   	OUT_RING(BRW_CLIP_DISABLE); /* disable CLIP, resulting in passthrough */
   	OUT_RING(state_base_offset + sf_offset);  /* 32 byte aligned */
   	OUT_RING(state_base_offset + wm_offset);  /* 32 byte aligned */
   	OUT_RING(state_base_offset + cc_offset);  /* 64 byte aligned */
d1057 12
a1068 12
   	OUT_RING(BRW_URB_FENCE |
        	 UF0_CS_REALLOC |
	    	 UF0_SF_REALLOC |
	    	 UF0_CLIP_REALLOC |
	         UF0_GS_REALLOC |
	         UF0_VS_REALLOC |
	    	 1);
   	OUT_RING(((urb_clip_start + urb_clip_size) << UF1_CLIP_FENCE_SHIFT) |
	    	 ((urb_gs_start + urb_gs_size) << UF1_GS_FENCE_SHIFT) |
	    	 ((urb_vs_start + urb_vs_size) << UF1_VS_FENCE_SHIFT));
   	OUT_RING(((urb_cs_start + urb_cs_size) << UF2_CS_FENCE_SHIFT) |
	     	 ((urb_sf_start + urb_sf_size) << UF2_SF_FENCE_SHIFT));
d1071 4
a1074 4
   	OUT_RING(BRW_CS_URB_STATE | 0);
   	OUT_RING(((URB_CS_ENTRY_SIZE - 1) << 4) |
	    	 (URB_CS_ENTRIES << 0));
	ADVANCE_LP_RING();
d1077 32
a1108 10
        int nelem = pMask ? 3: 2;
   	BEGIN_LP_RING(pMask?12:10);
	/* Set up the pointer to our vertex buffer */
   	OUT_RING(BRW_3DSTATE_VERTEX_BUFFERS | 3);
   	OUT_RING((0 << VB0_BUFFER_INDEX_SHIFT) |
	    	 VB0_VERTEXDATA |
	    	 ((4 * 2 * nelem) << VB0_BUFFER_PITCH_SHIFT));
   	OUT_RING(state_base_offset + vb_offset);
        OUT_RING(3);
   	OUT_RING(0); // ignore for VERTEXDATA, but still there
d1112 23
a1134 22
   	OUT_RING(BRW_3DSTATE_VERTEX_ELEMENTS | ((2 * nelem) - 1));
	/* vertex coordinates */
   	OUT_RING((0 << VE0_VERTEX_BUFFER_INDEX_SHIFT) |
	    	 VE0_VALID |
	    	 (BRW_SURFACEFORMAT_R32G32_FLOAT << VE0_FORMAT_SHIFT) |
	    	 (0 << VE0_OFFSET_SHIFT));
   	OUT_RING((BRW_VFCOMPONENT_STORE_SRC << VE1_VFCOMPONENT_0_SHIFT) |
	    	 (BRW_VFCOMPONENT_STORE_SRC << VE1_VFCOMPONENT_1_SHIFT) |
	     	 (BRW_VFCOMPONENT_STORE_1_FLT << VE1_VFCOMPONENT_2_SHIFT) |
	    	 (BRW_VFCOMPONENT_STORE_1_FLT << VE1_VFCOMPONENT_3_SHIFT) |
	    	 (4 << VE1_DESTINATION_ELEMENT_OFFSET_SHIFT));
	/* u0, v0 */
   	OUT_RING((0 << VE0_VERTEX_BUFFER_INDEX_SHIFT) |
	    	 VE0_VALID |
	    	 (BRW_SURFACEFORMAT_R32G32_FLOAT << VE0_FORMAT_SHIFT) |
	    	 (8 << VE0_OFFSET_SHIFT)); /* offset vb in bytes */
   	OUT_RING((BRW_VFCOMPONENT_STORE_SRC << VE1_VFCOMPONENT_0_SHIFT) |
	    	 (BRW_VFCOMPONENT_STORE_SRC << VE1_VFCOMPONENT_1_SHIFT) |
	    	 (BRW_VFCOMPONENT_NOSTORE << VE1_VFCOMPONENT_2_SHIFT) |
	    	 (BRW_VFCOMPONENT_NOSTORE << VE1_VFCOMPONENT_3_SHIFT) |
	    	 (8 << VE1_DESTINATION_ELEMENT_OFFSET_SHIFT)); /* VUE offset in dwords */
	/* u1, v1 */
d1136 10
a1145 9
	    OUT_RING((0 << VE0_VERTEX_BUFFER_INDEX_SHIFT) |
		     VE0_VALID |
		     (BRW_SURFACEFORMAT_R32G32_FLOAT << VE0_FORMAT_SHIFT) |
		     (16 << VE0_OFFSET_SHIFT));
	    OUT_RING((BRW_VFCOMPONENT_STORE_SRC << VE1_VFCOMPONENT_0_SHIFT) |
		     (BRW_VFCOMPONENT_STORE_SRC << VE1_VFCOMPONENT_1_SHIFT) |
		     (BRW_VFCOMPONENT_NOSTORE << VE1_VFCOMPONENT_2_SHIFT) |
		     (BRW_VFCOMPONENT_NOSTORE << VE1_VFCOMPONENT_3_SHIFT) |
		     (10 << VE1_DESTINATION_ELEMENT_OFFSET_SHIFT));
d1148 1
a1148 1
   	ADVANCE_LP_RING();
d1152 1
a1152 1
    ErrorF("try to sync to show any errors...");
d1165 2
a1166 1
    float src_x[3], src_y[3], mask_x[3], mask_y[3];
d1169 37
a1205 9
    i830_get_transformed_coordinates(srcX, srcY,
				     pI830->transform[0],
				     &src_x[0], &src_y[0]);
    i830_get_transformed_coordinates(srcX, srcY + h,
				     pI830->transform[0],
				     &src_x[1], &src_y[1]);
    i830_get_transformed_coordinates(srcX + w, srcY + h,
				     pI830->transform[0],
				     &src_x[2], &src_y[2]);
d1211 30
a1240 9
	i830_get_transformed_coordinates(maskX, maskY,
					 pI830->transform[1],
					 &mask_x[0], &mask_y[0]);
	i830_get_transformed_coordinates(maskX, maskY + h,
					 pI830->transform[1],
					 &mask_x[1], &mask_y[1]);
	i830_get_transformed_coordinates(maskX + w, maskY + h,
					 pI830->transform[1],
					 &mask_x[2], &mask_y[2]);
d1254 2
d1259 2
d1268 2
d1273 2
d1282 2
d1287 2
d1290 1
d1293 12
a1304 12
      BEGIN_LP_RING(6);
      OUT_RING(BRW_3DPRIMITIVE |
	       BRW_3DPRIMITIVE_VERTEX_SEQUENTIAL |
	       (_3DPRIM_RECTLIST << BRW_3DPRIMITIVE_TOPOLOGY_SHIFT) |
	       (0 << 9) |  /* CTG - indirect vertex count */
	       4);
      OUT_RING(3);  /* vertex count per instance */
      OUT_RING(0); /* start vertex offset */
      OUT_RING(1); /* single instance */
      OUT_RING(0); /* start instance location */
      OUT_RING(0); /* index buffer offset, ignored */
      ADVANCE_LP_RING();
d1307 1
a1307 1
    ErrorF("sync after 3dprimitive");
d1313 11
a1323 11
	BEGIN_LP_RING(4);
   	OUT_RING(BRW_PIPE_CONTROL |
	    BRW_PIPE_CONTROL_NOWRITE |
	    BRW_PIPE_CONTROL_WC_FLUSH |
	    BRW_PIPE_CONTROL_IS_FLUSH |
	    (1 << 10) |  /* XXX texture cache flush for BLC/CTG */
	    2);
   	OUT_RING(0); /* Destination address */
   	OUT_RING(0); /* Immediate data low DW */
   	OUT_RING(0); /* Immediate data high DW */
	ADVANCE_LP_RING();
@


1.1.1.1
log
@xf86-video-intel 2.2.0
@
text
@@


1.1.1.2
log
@Import intel driver v 2.2.0.90. tested by many, including krw@@ kettenis@@,
jakemsr@@, landry@@, beck@@ and oga@@. Thanks.
@
text
@a909 1
    wm_state->wm5.transposed_urb_read = 0;
d936 1
a936 4
	if (IS_IGD_GM(pI830))
	    OUT_RING(NEW_PIPELINE_SELECT | PIPELINE_SELECT_3D);
	else
	    OUT_RING(BRW_PIPELINE_SELECT | PIPELINE_SELECT_3D);
@

