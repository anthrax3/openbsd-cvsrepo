head	1.11;
access;
symbols
	OPENBSD_6_1_BASE:1.11
	OPENBSD_6_0:1.11.0.4
	OPENBSD_6_0_BASE:1.11
	OPENBSD_5_9:1.11.0.2
	OPENBSD_5_9_BASE:1.11
	OPENBSD_5_8:1.10.0.4
	OPENBSD_5_8_BASE:1.10
	OPENBSD_5_7:1.10.0.2
	OPENBSD_5_7_BASE:1.10
	OPENBSD_5_6:1.9.0.2
	OPENBSD_5_6_BASE:1.9
	OPENBSD_5_5:1.8.0.4
	OPENBSD_5_5_BASE:1.8
	OPENBSD_5_4:1.8.0.2
	OPENBSD_5_4_BASE:1.8
	OPENBSD_5_3:1.7.0.2
	OPENBSD_5_3_BASE:1.7
	OPENBSD_5_2:1.6.0.2
	OPENBSD_5_2_BASE:1.6
	OPENBSD_5_1_BASE:1.5
	OPENBSD_5_1:1.5.0.6
	OPENBSD_5_0:1.5.0.4
	OPENBSD_5_0_BASE:1.5
	OPENBSD_4_9:1.5.0.2
	OPENBSD_4_9_BASE:1.5
	OPENBSD_4_8:1.3.0.4
	OPENBSD_4_8_BASE:1.3
	OPENBSD_4_7:1.2.0.4
	OPENBSD_4_7_BASE:1.2
	OPENBSD_4_6:1.2.0.2
	OPENBSD_4_6_BASE:1.2
	v1_2:1.1.1.1
	XCB:1.1.1;
locks; strict;
comment	@ * @;


1.11
date	2015.09.30.09.13.41;	author dcoppa;	state Exp;
branches;
next	1.10;
commitid	ulTopuJyOQ6kVNOJ;

1.10
date	2015.01.26.21.32.11;	author matthieu;	state Exp;
branches;
next	1.9;
commitid	01TEvO4uNHLqFv7N;

1.9
date	2014.04.14.19.02.17;	author matthieu;	state Exp;
branches;
next	1.8;

1.8
date	2013.05.23.22.42.14;	author matthieu;	state Exp;
branches;
next	1.7;

1.7
date	2012.11.22.20.31.32;	author matthieu;	state Exp;
branches;
next	1.6;

1.6
date	2012.03.27.19.14.21;	author matthieu;	state Exp;
branches;
next	1.5;

1.5
date	2010.10.06.07.50.06;	author dcoppa;	state Exp;
branches;
next	1.4;

1.4
date	2010.09.04.10.00.59;	author matthieu;	state Exp;
branches;
next	1.3;

1.3
date	2010.04.18.20.06.18;	author matthieu;	state Exp;
branches;
next	1.2;

1.2
date	2009.05.31.16.44.43;	author matthieu;	state Exp;
branches;
next	1.1;

1.1
date	2009.05.22.15.56.12;	author matthieu;	state Exp;
branches
	1.1.1.1;
next	;

1.1.1.1
date	2009.05.22.15.56.12;	author matthieu;	state Exp;
branches;
next	;


desc
@@


1.11
log
@
Update to libxcb-1.11.1

ok matthieu@@
@
text
@/* Copyright (C) 2001-2004 Bart Massey and Jamey Sharp.
 *
 * Permission is hereby granted, free of charge, to any person obtaining a
 * copy of this software and associated documentation files (the "Software"),
 * to deal in the Software without restriction, including without limitation
 * the rights to use, copy, modify, merge, publish, distribute, sublicense,
 * and/or sell copies of the Software, and to permit persons to whom the
 * Software is furnished to do so, subject to the following conditions:
 * 
 * The above copyright notice and this permission notice shall be included in
 * all copies or substantial portions of the Software.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 * Except as contained in this notice, the names of the authors or their
 * institutions shall not be used in advertising or otherwise to promote the
 * sale, use or other dealings in this Software without prior written
 * authorization from the authors.
 */

/* Stuff that reads stuff from the server. */

#ifdef HAVE_CONFIG_H
#include "config.h"
#endif

#include <assert.h>
#include <string.h>
#include <stdlib.h>
#include <unistd.h>
#include <stdio.h>
#include <errno.h>

#if USE_POLL
#include <poll.h>
#endif
#ifndef _WIN32
#include <sys/select.h>
#include <sys/socket.h>
#endif

#ifdef _WIN32
#include "xcb_windefs.h"
#endif /* _WIN32 */

#include "xcb.h"
#include "xcbext.h"
#include "xcbint.h"

#define XCB_ERROR 0
#define XCB_REPLY 1
#define XCB_XGE_EVENT 35

struct event_list {
    xcb_generic_event_t *event;
    struct event_list *next;
};

struct xcb_special_event {

    struct xcb_special_event *next;

    /* Match XGE events for the specific extension and event ID (the
     * first 32 bit word after evtype)
     */
    uint8_t     extension;
    uint32_t    eid;
    uint32_t    *stamp;

    struct event_list   *events;
    struct event_list   **events_tail;

    pthread_cond_t special_event_cond;
};

struct reply_list {
    void *reply;
    struct reply_list *next;
};

typedef struct pending_reply {
    uint64_t first_request;
    uint64_t last_request;
    enum workarounds workaround;
    int flags;
    struct pending_reply *next;
} pending_reply;

typedef struct reader_list {
    uint64_t request;
    pthread_cond_t *data;
    struct reader_list *next;
} reader_list;

typedef struct special_list {
    xcb_special_event_t *se;
    struct special_list *next;
} special_list;

static void remove_finished_readers(reader_list **prev_reader, uint64_t completed)
{
    while(*prev_reader && XCB_SEQUENCE_COMPARE((*prev_reader)->request, <=, completed))
    {
        /* If you don't have what you're looking for now, you never
         * will. Wake up and leave me alone. */
        pthread_cond_signal((*prev_reader)->data);
        *prev_reader = (*prev_reader)->next;
    }
}

#if HAVE_SENDMSG
static int read_fds(xcb_connection_t *c, int *fds, int nfd)
{
    int *ifds = &c->in.in_fd.fd[c->in.in_fd.ifd];
    int infd = c->in.in_fd.nfd - c->in.in_fd.ifd;

    if (nfd > infd)
        return 0;
    memcpy(fds, ifds, nfd * sizeof (int));
    c->in.in_fd.ifd += nfd;
    return 1;
}
#endif

typedef struct xcb_ge_special_event_t {
    uint8_t  response_type; /**<  */
    uint8_t  extension; /**<  */
    uint16_t sequence; /**<  */
    uint32_t length; /**<  */
    uint16_t evtype; /**<  */
    uint8_t  pad0[2]; /**< */
    uint32_t eid; /**< */
    uint8_t  pad1[16]; /**<  */
} xcb_ge_special_event_t;

static int event_special(xcb_connection_t *c,
                         struct event_list *event)
{
    struct xcb_special_event *special_event;
    struct xcb_ge_special_event_t *ges = (void *) event->event;

    /* Special events are always XGE events */
    if ((ges->response_type & 0x7f) != XCB_XGE_EVENT)
        return 0;

    for (special_event = c->in.special_events;
         special_event;
         special_event = special_event->next)
    {
        if (ges->extension == special_event->extension &&
            ges->eid == special_event->eid)
        {
            *special_event->events_tail = event;
            special_event->events_tail = &event->next;
            if (special_event->stamp)
                ++(*special_event->stamp);
            pthread_cond_signal(&special_event->special_event_cond);
            return 1;
        }
    }

    return 0;
}

static int read_packet(xcb_connection_t *c)
{
    xcb_generic_reply_t genrep;
    uint64_t length = 32;
    uint64_t eventlength = 0; /* length after first 32 bytes for GenericEvents */
    int nfd = 0;         /* Number of file descriptors attached to the reply */
    uint64_t bufsize;
    void *buf;
    pending_reply *pend = 0;
    struct event_list *event;

    /* Wait for there to be enough data for us to read a whole packet */
    if(c->in.queue_len < length)
        return 0;

    /* Get the response type, length, and sequence number. */
    memcpy(&genrep, c->in.queue, sizeof(genrep));

    /* Compute 32-bit sequence number of this packet. */
    if((genrep.response_type & 0x7f) != XCB_KEYMAP_NOTIFY)
    {
        uint64_t lastread = c->in.request_read;
        c->in.request_read = (lastread & UINT64_C(0xffffffffffff0000)) | genrep.sequence;
        if(XCB_SEQUENCE_COMPARE(c->in.request_read, <, lastread))
            c->in.request_read += 0x10000;
        if(XCB_SEQUENCE_COMPARE(c->in.request_read, >, c->in.request_expected))
            c->in.request_expected = c->in.request_read;

        if(c->in.request_read != lastread)
        {
            if(c->in.current_reply)
            {
                _xcb_map_put(c->in.replies, lastread, c->in.current_reply);
                c->in.current_reply = 0;
                c->in.current_reply_tail = &c->in.current_reply;
            }
            c->in.request_completed = c->in.request_read - 1;
        }

        while(c->in.pending_replies &&
              c->in.pending_replies->workaround != WORKAROUND_EXTERNAL_SOCKET_OWNER &&
              XCB_SEQUENCE_COMPARE (c->in.pending_replies->last_request, <=, c->in.request_completed))
        {
            pending_reply *oldpend = c->in.pending_replies;
            c->in.pending_replies = oldpend->next;
            if(!oldpend->next)
                c->in.pending_replies_tail = &c->in.pending_replies;
            free(oldpend);
        }

        if(genrep.response_type == XCB_ERROR)
            c->in.request_completed = c->in.request_read;

        remove_finished_readers(&c->in.readers, c->in.request_completed);
    }

    if(genrep.response_type == XCB_ERROR || genrep.response_type == XCB_REPLY)
    {
        pend = c->in.pending_replies;
        if(pend &&
           !(XCB_SEQUENCE_COMPARE(pend->first_request, <=, c->in.request_read) &&
             (pend->workaround == WORKAROUND_EXTERNAL_SOCKET_OWNER ||
              XCB_SEQUENCE_COMPARE(c->in.request_read, <=, pend->last_request))))
            pend = 0;
    }

    /* For reply packets, check that the entire packet is available. */
    if(genrep.response_type == XCB_REPLY)
    {
        if(pend && pend->workaround == WORKAROUND_GLX_GET_FB_CONFIGS_BUG)
        {
            uint32_t *p = (uint32_t *) c->in.queue;
            genrep.length = p[2] * p[3] * 2;
        }
        length += genrep.length * 4;

        /* XXX a bit of a hack -- we "know" that all FD replys place
         * the number of fds in the pad0 byte */
        if (pend && pend->flags & XCB_REQUEST_REPLY_FDS)
            nfd = genrep.pad0;
    }

    /* XGE events may have sizes > 32 */
    if ((genrep.response_type & 0x7f) == XCB_XGE_EVENT)
        eventlength = genrep.length * 4;

    bufsize = length + eventlength + nfd * sizeof(int)  +
        (genrep.response_type == XCB_REPLY ? 0 : sizeof(uint32_t));
    if (bufsize < INT32_MAX)
        buf = malloc((size_t) bufsize);
    else
        buf = NULL;
    if(!buf)
    {
        _xcb_conn_shutdown(c, XCB_CONN_CLOSED_MEM_INSUFFICIENT);
        return 0;
    }

    if(_xcb_in_read_block(c, buf, length) <= 0)
    {
        free(buf);
        return 0;
    }

    /* pull in XGE event data if available, append after event struct */
    if (eventlength)
    {
        if(_xcb_in_read_block(c, &((xcb_generic_event_t*)buf)[1], eventlength) <= 0)
        {
            free(buf);
            return 0;
        }
    }

#if HAVE_SENDMSG
    if (nfd)
    {
        if (!read_fds(c, (int *) &((char *) buf)[length], nfd))
        {
            free(buf);
            return 0;
        }
    }
#endif

    if(pend && (pend->flags & XCB_REQUEST_DISCARD_REPLY))
    {
        free(buf);
        return 1;
    }

    if(genrep.response_type != XCB_REPLY)
        ((xcb_generic_event_t *) buf)->full_sequence = c->in.request_read;

    /* reply, or checked error */
    if( genrep.response_type == XCB_REPLY ||
       (genrep.response_type == XCB_ERROR && pend && (pend->flags & XCB_REQUEST_CHECKED)))
    {
        struct reply_list *cur = malloc(sizeof(struct reply_list));
        if(!cur)
        {
            _xcb_conn_shutdown(c, XCB_CONN_CLOSED_MEM_INSUFFICIENT);
            free(buf);
            return 0;
        }
        cur->reply = buf;
        cur->next = 0;
        *c->in.current_reply_tail = cur;
        c->in.current_reply_tail = &cur->next;
        if(c->in.readers && c->in.readers->request == c->in.request_read)
            pthread_cond_signal(c->in.readers->data);
        return 1;
    }

    /* event, or unchecked error */
    event = malloc(sizeof(struct event_list));
    if(!event)
    {
        _xcb_conn_shutdown(c, XCB_CONN_CLOSED_MEM_INSUFFICIENT);
        free(buf);
        return 0;
    }
    event->event = buf;
    event->next = 0;

    if (!event_special(c, event)) {
        *c->in.events_tail = event;
        c->in.events_tail = &event->next;
        pthread_cond_signal(&c->in.event_cond);
    }
    return 1; /* I have something for you... */
}

static xcb_generic_event_t *get_event(xcb_connection_t *c)
{
    struct event_list *cur = c->in.events;
    xcb_generic_event_t *ret;
    if(!c->in.events)
        return 0;
    ret = cur->event;
    c->in.events = cur->next;
    if(!cur->next)
        c->in.events_tail = &c->in.events;
    free(cur);
    return ret;
}

static void free_reply_list(struct reply_list *head)
{
    while(head)
    {
        struct reply_list *cur = head;
        head = cur->next;
        free(cur->reply);
        free(cur);
    }
}

static int read_block(const int fd, void *buf, const ssize_t len)
{
    int done = 0;
    while(done < len)
    {
        int ret = recv(fd, ((char *) buf) + done, len - done, 0);
        if(ret > 0)
            done += ret;
#ifndef _WIN32
        if(ret < 0 && errno == EAGAIN)
#else
        if(ret == SOCKET_ERROR && WSAGetLastError() == WSAEWOULDBLOCK)
#endif /* !_Win32 */
        {
#if USE_POLL
            struct pollfd pfd;
            pfd.fd = fd;
            pfd.events = POLLIN;
            pfd.revents = 0;
            do {
                ret = poll(&pfd, 1, -1);
            } while (ret == -1 && errno == EINTR);
#else
            fd_set fds;
            FD_ZERO(&fds);
            FD_SET(fd, &fds);

            /* Initializing errno here makes sure that for Win32 this loop will execute only once */
            errno = 0;
            do {
                ret = select(fd + 1, &fds, 0, 0, 0);
            } while (ret == -1 && errno == EINTR);
#endif /* USE_POLL */
        }
        if(ret <= 0)
            return ret;
    }
    return len;
}

static int poll_for_reply(xcb_connection_t *c, uint64_t request, void **reply, xcb_generic_error_t **error)
{
    struct reply_list *head;

    /* If an error occurred when issuing the request, fail immediately. */
    if(!request)
        head = 0;
    /* We've read requests past the one we want, so if it has replies we have
     * them all and they're in the replies map. */
    else if(XCB_SEQUENCE_COMPARE(request, <, c->in.request_read))
    {
        head = _xcb_map_remove(c->in.replies, request);
        if(head && head->next)
            _xcb_map_put(c->in.replies, request, head->next);
    }
    /* We're currently processing the responses to the request we want, and we
     * have a reply ready to return. So just return it without blocking. */
    else if(request == c->in.request_read && c->in.current_reply)
    {
        head = c->in.current_reply;
        c->in.current_reply = head->next;
        if(!head->next)
            c->in.current_reply_tail = &c->in.current_reply;
    }
    /* We know this request can't have any more replies, and we've already
     * established it doesn't have a reply now. Don't bother blocking. */
    else if(request == c->in.request_completed)
        head = 0;
    /* We may have more replies on the way for this request: block until we're
     * sure. */
    else
        return 0;

    if(error)
        *error = 0;
    *reply = 0;

    if(head)
    {
        if(((xcb_generic_reply_t *) head->reply)->response_type == XCB_ERROR)
        {
            if(error)
                *error = head->reply;
            else
                free(head->reply);
        }
        else
            *reply = head->reply;

        free(head);
    }

    return 1;
}

static void insert_reader(reader_list **prev_reader, reader_list *reader, uint64_t request, pthread_cond_t *cond)
{
    while(*prev_reader && XCB_SEQUENCE_COMPARE((*prev_reader)->request, <=, request))
        prev_reader = &(*prev_reader)->next;
    reader->request = request;
    reader->data = cond;
    reader->next = *prev_reader;
    *prev_reader = reader;
}

static void remove_reader(reader_list **prev_reader, reader_list *reader)
{
    while(*prev_reader && XCB_SEQUENCE_COMPARE((*prev_reader)->request, <=, reader->request))
        if(*prev_reader == reader)
        {
            *prev_reader = (*prev_reader)->next;
            break;
        }
}

static void insert_special(special_list **prev_special, special_list *special, xcb_special_event_t *se)
{
    special->se = se;
    special->next = *prev_special;
    *prev_special = special;
}

static void remove_special(special_list **prev_special, special_list *special)
{
    while(*prev_special)
    {
        if(*prev_special == special)
        {
            *prev_special = (*prev_special)->next;
            break;
        }
        prev_special = &(*prev_special)->next;
    }
}

static void *wait_for_reply(xcb_connection_t *c, uint64_t request, xcb_generic_error_t **e)
{
    void *ret = 0;

    /* If this request has not been written yet, write it. */
    if(c->out.return_socket || _xcb_out_flush_to(c, request))
    {
        pthread_cond_t cond = PTHREAD_COND_INITIALIZER;
        reader_list reader;

        insert_reader(&c->in.readers, &reader, request, &cond);

        while(!poll_for_reply(c, request, &ret, e))
            if(!_xcb_conn_wait(c, &cond, 0, 0))
                break;

        remove_reader(&c->in.readers, &reader);
        pthread_cond_destroy(&cond);
    }

    _xcb_in_wake_up_next_reader(c);
    return ret;
}

static uint64_t widen(xcb_connection_t *c, unsigned int request)
{
    uint64_t widened_request = (c->out.request & UINT64_C(0xffffffff00000000)) | request;
    if(widened_request > c->out.request)
        widened_request -= UINT64_C(1) << 32;
    return widened_request;
}

/* Public interface */

void *xcb_wait_for_reply(xcb_connection_t *c, unsigned int request, xcb_generic_error_t **e)
{
    void *ret;
    if(e)
        *e = 0;
    if(c->has_error)
        return 0;

    pthread_mutex_lock(&c->iolock);
    ret = wait_for_reply(c, widen(c, request), e);
    pthread_mutex_unlock(&c->iolock);
    return ret;
}

void *xcb_wait_for_reply64(xcb_connection_t *c, uint64_t request, xcb_generic_error_t **e)
{
    void *ret;
    if(e)
        *e = 0;
    if(c->has_error)
        return 0;

    pthread_mutex_lock(&c->iolock);
    ret = wait_for_reply(c, request, e);
    pthread_mutex_unlock(&c->iolock);
    return ret;
}

int *xcb_get_reply_fds(xcb_connection_t *c, void *reply, size_t reply_size)
{
    return (int *) (&((char *) reply)[reply_size]);
}

static void insert_pending_discard(xcb_connection_t *c, pending_reply **prev_next, uint64_t seq)
{
    pending_reply *pend;
    pend = malloc(sizeof(*pend));
    if(!pend)
    {
        _xcb_conn_shutdown(c, XCB_CONN_CLOSED_MEM_INSUFFICIENT);
        return;
    }

    pend->first_request = seq;
    pend->last_request = seq;
    pend->workaround = 0;
    pend->flags = XCB_REQUEST_DISCARD_REPLY;
    pend->next = *prev_next;
    *prev_next = pend;

    if(!pend->next)
        c->in.pending_replies_tail = &pend->next;
}

static void discard_reply(xcb_connection_t *c, uint64_t request)
{
    void *reply;
    pending_reply **prev_pend;

    /* Free any replies or errors that we've already read. Stop if
     * xcb_wait_for_reply would block or we've run out of replies. */
    while(poll_for_reply(c, request, &reply, 0) && reply)
        free(reply);

    /* If we've proven there are no more responses coming, we're done. */
    if(XCB_SEQUENCE_COMPARE(request, <=, c->in.request_completed))
        return;

    /* Walk the list of pending requests. Mark the first match for deletion. */
    for(prev_pend = &c->in.pending_replies; *prev_pend; prev_pend = &(*prev_pend)->next)
    {
        if(XCB_SEQUENCE_COMPARE((*prev_pend)->first_request, >, request))
            break;

        if((*prev_pend)->first_request == request)
        {
            /* Pending reply found. Mark for discard: */
            (*prev_pend)->flags |= XCB_REQUEST_DISCARD_REPLY;
            return;
        }
    }

    /* Pending reply not found (likely due to _unchecked request). Create one: */
    insert_pending_discard(c, prev_pend, request);
}

void xcb_discard_reply(xcb_connection_t *c, unsigned int sequence)
{
    if(c->has_error)
        return;

    /* If an error occurred when issuing the request, fail immediately. */
    if(!sequence)
        return;

    pthread_mutex_lock(&c->iolock);
    discard_reply(c, widen(c, sequence));
    pthread_mutex_unlock(&c->iolock);
}

void xcb_discard_reply64(xcb_connection_t *c, uint64_t sequence)
{
    if(c->has_error)
        return;

    /* If an error occurred when issuing the request, fail immediately. */
    if(!sequence)
        return;

    pthread_mutex_lock(&c->iolock);
    discard_reply(c, sequence);
    pthread_mutex_unlock(&c->iolock);
}

int xcb_poll_for_reply(xcb_connection_t *c, unsigned int request, void **reply, xcb_generic_error_t **error)
{
    int ret;
    if(c->has_error)
    {
        *reply = 0;
        if(error)
            *error = 0;
        return 1; /* would not block */
    }
    assert(reply != 0);
    pthread_mutex_lock(&c->iolock);
    ret = poll_for_reply(c, widen(c, request), reply, error);
    pthread_mutex_unlock(&c->iolock);
    return ret;
}

int xcb_poll_for_reply64(xcb_connection_t *c, uint64_t request, void **reply, xcb_generic_error_t **error)
{
    int ret;
    if(c->has_error)
    {
        *reply = 0;
        if(error)
            *error = 0;
        return 1; /* would not block */
    }
    assert(reply != 0);
    pthread_mutex_lock(&c->iolock);
    ret = poll_for_reply(c, request, reply, error);
    pthread_mutex_unlock(&c->iolock);
    return ret;
}

xcb_generic_event_t *xcb_wait_for_event(xcb_connection_t *c)
{
    xcb_generic_event_t *ret;
    if(c->has_error)
        return 0;
    pthread_mutex_lock(&c->iolock);
    /* get_event returns 0 on empty list. */
    while(!(ret = get_event(c)))
        if(!_xcb_conn_wait(c, &c->in.event_cond, 0, 0))
            break;

    _xcb_in_wake_up_next_reader(c);
    pthread_mutex_unlock(&c->iolock);
    return ret;
}

static xcb_generic_event_t *poll_for_next_event(xcb_connection_t *c, int queued)
{
    xcb_generic_event_t *ret = 0;
    if(!c->has_error)
    {
        pthread_mutex_lock(&c->iolock);
        /* FIXME: follow X meets Z architecture changes. */
        ret = get_event(c);
        if(!ret && !queued && c->in.reading == 0 && _xcb_in_read(c)) /* _xcb_in_read shuts down the connection on error */
            ret = get_event(c);
        pthread_mutex_unlock(&c->iolock);
    }
    return ret;
}

xcb_generic_event_t *xcb_poll_for_event(xcb_connection_t *c)
{
    return poll_for_next_event(c, 0);
}

xcb_generic_event_t *xcb_poll_for_queued_event(xcb_connection_t *c)
{
    return poll_for_next_event(c, 1);
}

xcb_generic_error_t *xcb_request_check(xcb_connection_t *c, xcb_void_cookie_t cookie)
{
    uint64_t request;
    xcb_generic_error_t *ret = 0;
    void *reply;
    if(c->has_error)
        return 0;
    pthread_mutex_lock(&c->iolock);
    request = widen(c, cookie.sequence);
    if(XCB_SEQUENCE_COMPARE(request, >=, c->in.request_expected)
       && XCB_SEQUENCE_COMPARE(request, >, c->in.request_completed))
    {
        _xcb_out_send_sync(c);
        _xcb_out_flush_to(c, c->out.request);
    }
    reply = wait_for_reply(c, request, &ret);
    assert(!reply);
    pthread_mutex_unlock(&c->iolock);
    return ret;
}

static xcb_generic_event_t *get_special_event(xcb_connection_t *c,
                                              xcb_special_event_t *se)
{
    xcb_generic_event_t *event = NULL;
    struct event_list *events;

    if ((events = se->events) != NULL) {
        event = events->event;
        if (!(se->events = events->next))
            se->events_tail = &se->events;
        free (events);
    }
    return event;
}

xcb_generic_event_t *xcb_poll_for_special_event(xcb_connection_t *c,
                                                xcb_special_event_t *se)
{
    xcb_generic_event_t *event;

    if(c->has_error)
        return 0;
    pthread_mutex_lock(&c->iolock);
    event = get_special_event(c, se);
    pthread_mutex_unlock(&c->iolock);
    return event;
}

xcb_generic_event_t *xcb_wait_for_special_event(xcb_connection_t *c,
                                                xcb_special_event_t *se)
{
    special_list special;
    xcb_generic_event_t *event;

    if(c->has_error)
        return 0;
    pthread_mutex_lock(&c->iolock);

    insert_special(&c->in.special_waiters, &special, se);

    /* get_special_event returns 0 on empty list. */
    while(!(event = get_special_event(c, se)))
        if(!_xcb_conn_wait(c, &se->special_event_cond, 0, 0))
            break;

    remove_special(&c->in.special_waiters, &special);

    _xcb_in_wake_up_next_reader(c);
    pthread_mutex_unlock(&c->iolock);
    return event;
}

xcb_special_event_t *
xcb_register_for_special_xge(xcb_connection_t *c,
                             xcb_extension_t *ext,
                             uint32_t eid,
                             uint32_t *stamp)
{
    xcb_special_event_t *se;
    const xcb_query_extension_reply_t   *ext_reply;

    if(c->has_error)
        return NULL;
    ext_reply = xcb_get_extension_data(c, ext);
    if (!ext_reply)
        return NULL;
    pthread_mutex_lock(&c->iolock);
    for (se = c->in.special_events; se; se = se->next) {
        if (se->extension == ext_reply->major_opcode &&
            se->eid == eid) {
            pthread_mutex_unlock(&c->iolock);
            return NULL;
        }
    }
    se = calloc(1, sizeof(xcb_special_event_t));
    if (!se) {
        pthread_mutex_unlock(&c->iolock);
        return NULL;
    }

    se->extension = ext_reply->major_opcode;
    se->eid = eid;

    se->events = NULL;
    se->events_tail = &se->events;
    se->stamp = stamp;

    pthread_cond_init(&se->special_event_cond, 0);

    se->next = c->in.special_events;
    c->in.special_events = se;
    pthread_mutex_unlock(&c->iolock);
    return se;
}

void
xcb_unregister_for_special_event(xcb_connection_t *c,
                                 xcb_special_event_t *se)
{
    xcb_special_event_t *s, **prev;
    struct event_list   *events, *next;

    if (!se)
        return;

    if (c->has_error)
        return;

    pthread_mutex_lock(&c->iolock);

    for (prev = &c->in.special_events; (s = *prev) != NULL; prev = &(s->next)) {
        if (s == se) {
            *prev = se->next;
            for (events = se->events; events; events = next) {
                next = events->next;
                free (events->event);
                free (events);
            }
            pthread_cond_destroy(&se->special_event_cond);
            free (se);
            break;
        }
    }
    pthread_mutex_unlock(&c->iolock);
}

/* Private interface */

int _xcb_in_init(_xcb_in *in)
{
    if(pthread_cond_init(&in->event_cond, 0))
        return 0;
    in->reading = 0;

    in->queue_len = 0;

    in->request_read = 0;
    in->request_completed = 0;

    in->replies = _xcb_map_new();
    if(!in->replies)
        return 0;

    in->current_reply_tail = &in->current_reply;
    in->events_tail = &in->events;
    in->pending_replies_tail = &in->pending_replies;

    return 1;
}

void _xcb_in_destroy(_xcb_in *in)
{
    pthread_cond_destroy(&in->event_cond);
    free_reply_list(in->current_reply);
    _xcb_map_delete(in->replies, (void (*)(void *)) free_reply_list);
    while(in->events)
    {
        struct event_list *e = in->events;
        in->events = e->next;
        free(e->event);
        free(e);
    }
    while(in->pending_replies)
    {
        pending_reply *pend = in->pending_replies;
        in->pending_replies = pend->next;
        free(pend);
    }
}

void _xcb_in_wake_up_next_reader(xcb_connection_t *c)
{
    int pthreadret;
    if(c->in.readers)
        pthreadret = pthread_cond_signal(c->in.readers->data);
    else if(c->in.special_waiters)
        pthreadret = pthread_cond_signal(&c->in.special_waiters->se->special_event_cond);
    else
        pthreadret = pthread_cond_signal(&c->in.event_cond);
    assert(pthreadret == 0);
}

int _xcb_in_expect_reply(xcb_connection_t *c, uint64_t request, enum workarounds workaround, int flags)
{
    pending_reply *pend = malloc(sizeof(pending_reply));
    assert(workaround != WORKAROUND_NONE || flags != 0);
    if(!pend)
    {
        _xcb_conn_shutdown(c, XCB_CONN_CLOSED_MEM_INSUFFICIENT);
        return 0;
    }
    pend->first_request = pend->last_request = request;
    pend->workaround = workaround;
    pend->flags = flags;
    pend->next = 0;
    *c->in.pending_replies_tail = pend;
    c->in.pending_replies_tail = &pend->next;
    return 1;
}

void _xcb_in_replies_done(xcb_connection_t *c)
{
    struct pending_reply *pend;
    if (c->in.pending_replies_tail != &c->in.pending_replies)
    {
        pend = container_of(c->in.pending_replies_tail, struct pending_reply, next);
        if(pend->workaround == WORKAROUND_EXTERNAL_SOCKET_OWNER)
        {
            pend->last_request = c->out.request;
            pend->workaround = WORKAROUND_NONE;
        }
    }
}

int _xcb_in_read(xcb_connection_t *c)
{
    int n;

#if HAVE_SENDMSG
    struct iovec    iov = {
        .iov_base = c->in.queue + c->in.queue_len,
        .iov_len = sizeof(c->in.queue) - c->in.queue_len,
    };
    union {
        struct cmsghdr cmsghdr;
        char buf[CMSG_SPACE(XCB_MAX_PASS_FD * sizeof(int))];
    } cmsgbuf;
    struct msghdr msg = {
        .msg_name = NULL,
        .msg_namelen = 0,
        .msg_iov = &iov,
        .msg_iovlen = 1,
        .msg_control = cmsgbuf.buf,
        .msg_controllen = CMSG_SPACE(sizeof(int) * (XCB_MAX_PASS_FD - c->in.in_fd.nfd)),
    };
    n = recvmsg(c->fd, &msg, 0);

    /* Check for truncation errors. Only MSG_CTRUNC is
     * probably possible here, which would indicate that
     * the sender tried to transmit more than XCB_MAX_PASS_FD
     * file descriptors.
     */
    if (msg.msg_flags & (MSG_TRUNC|MSG_CTRUNC)) {
        _xcb_conn_shutdown(c, XCB_CONN_CLOSED_FDPASSING_FAILED);
        return 0;
    }
#else
    n = recv(c->fd, c->in.queue + c->in.queue_len, sizeof(c->in.queue) - c->in.queue_len, 0);
#endif
    if(n > 0) {
#if HAVE_SENDMSG
        struct cmsghdr *hdr;

        if (msg.msg_controllen >= sizeof (struct cmsghdr)) {
            for (hdr = CMSG_FIRSTHDR(&msg); hdr; hdr = CMSG_NXTHDR(&msg, hdr)) {
                if (hdr->cmsg_level == SOL_SOCKET && hdr->cmsg_type == SCM_RIGHTS) {
                    int nfd = (hdr->cmsg_len - CMSG_LEN(0)) / sizeof (int);
                    memcpy(&c->in.in_fd.fd[c->in.in_fd.nfd], CMSG_DATA(hdr), nfd * sizeof (int));
                    c->in.in_fd.nfd += nfd;
                }
            }
        }
#endif
        c->in.queue_len += n;
    }
    while(read_packet(c))
        /* empty */;
#if HAVE_SENDMSG
    if (c->in.in_fd.nfd) {
        c->in.in_fd.nfd -= c->in.in_fd.ifd;
        memmove(&c->in.in_fd.fd[0],
                &c->in.in_fd.fd[c->in.in_fd.ifd],
                c->in.in_fd.nfd * sizeof (int));
        c->in.in_fd.ifd = 0;

        /* If we have any left-over file descriptors after emptying
         * the input buffer, then the server sent some that we weren't
         * expecting.  Close them and mark the connection as broken;
         */
        if (c->in.queue_len == 0 && c->in.in_fd.nfd != 0) {
            int i;
            for (i = 0; i < c->in.in_fd.nfd; i++)
                close(c->in.in_fd.fd[i]);
            _xcb_conn_shutdown(c, XCB_CONN_CLOSED_FDPASSING_FAILED);
            return 0;
        }
    }
#endif
#ifndef _WIN32
    if((n > 0) || (n < 0 && errno == EAGAIN))
#else
    if((n > 0) || (n < 0 && WSAGetLastError() == WSAEWOULDBLOCK))
#endif /* !_WIN32 */
        return 1;
    _xcb_conn_shutdown(c, XCB_CONN_ERROR);
    return 0;
}

int _xcb_in_read_block(xcb_connection_t *c, void *buf, int len)
{
    int done = c->in.queue_len;
    if(len < done)
        done = len;

    memcpy(buf, c->in.queue, done);
    c->in.queue_len -= done;
    memmove(c->in.queue, c->in.queue + done, c->in.queue_len);

    if(len > done)
    {
        int ret = read_block(c->fd, (char *) buf + done, len - done);
        if(ret <= 0)
        {
            _xcb_conn_shutdown(c, XCB_CONN_ERROR);
            return ret;
        }
    }

    return len;
}
@


1.10
log
@Update to libxcb and xcb-proto 1.11.
Tested on a bulk ports build by naddy@@.
Lots of churn due to white-space and comments changes in generated code.
@
text
@d100 5
d483 20
d551 14
d637 14
d668 17
d778 1
d785 2
d792 3
d922 2
@


1.9
log
@Update libxcb to version 1.10. Tested by naddy@@ and shadchin@@.
@
text
@a38 3
#include "xcb.h"
#include "xcbext.h"
#include "xcbint.h"
d51 4
d204 1
a204 1
        while(c->in.pending_replies && 
d206 1
a206 1
	      XCB_SEQUENCE_COMPARE (c->in.pending_replies->last_request, <=, c->in.request_completed))
d390 5
a394 5
	    /* Initializing errno here makes sure that for Win32 this loop will execute only once */
	    errno = 0;  
	    do {
		ret = select(fd + 1, &fds, 0, 0, 0);
	    } while (ret == -1 && errno == EINTR);
d750 1
a750 1
            
@


1.8
log
@Merge upstream fixes for several X libs vulnerabilities
discovered by Ilja van Sprundel.

CVE-2013-1981 X.org libX11 1.5.99.901 (1.6 RC1) integer overflows
CVE-2013-1982 X.org libXext 1.3.1 integer overflows
CVE-2013-1983 X.org libXfixes 5.0 integer overflows
CVE-2013-1984 X.org libXi 1.7.1 integer overflows
CVE-2013-1985 X.org libXinerama 1.1.2 integer overflows
CVE-2013-1986 X.org libXrandr 1.4.0 integer overflows
CVE-2013-1987 X.org libXrender 0.9.7 integer overflows
CVE-2013-1988 X.org libXRes 1.0.6 integer overflows
CVE-2013-1989 X.org libXv 1.0.7 integer overflows
CVE-2013-1990 X.org libXvMC 1.0.7 integer overflows
CVE-2013-1991 X.org libXxf86dga 1.1.3 integer overflows
CVE-2013-1992 X.org libdmx 1.1.2 integer overflows
CVE-2013-1994 X.org libchromeXvMC & libchromeXvMCPro in openChrome
0.3.2 integer overflows
CVE-2013-1995 X.org libXi 1.7.1 sign extension issues
CVE-2013-1996 X.org libFS 1.0.4 sign extension issues
CVE-2013-1997 X.org libX11 1.5.99.901 (1.6 RC1) buffer overflows
CVE-2013-1998 X.org libXi 1.7.1 buffer overflows
CVE-2013-1999 X.org libXvMC 1.0.7 buffer overflows
CVE-2013-2000 X.org libXxf86dga 1.1.3 buffer overflows
CVE-2013-2001 X.org libXxf86vm 1.1.2 buffer overflows
CVE-2013-2002 X.org libXt 1.1.3 buffer overflows
CVE-2013-2003 X.org libXcursor 1.1.13 integer overflows
CVE-2013-2004 X.org libX11 1.5.99.901 (1.6 RC1) unbounded recursion
CVE-2013-2005 X.org libXt 1.1.3 memory corruption
CVE-2013-2066 X.org libXv 1.0.7 buffer overflows
@
text
@d63 17
d110 54
d169 1
d239 5
d250 1
a250 1
    bufsize = length + eventlength +
d278 11
d328 6
a333 3
    *c->in.events_tail = event;
    c->in.events_tail = &event->next;
    pthread_cond_signal(&c->in.event_cond);
d525 5
d676 120
d884 47
a930 2
    int n = recv(c->fd, c->in.queue + c->in.queue_len, sizeof(c->in.queue) - c->in.queue_len, 0);
    if(n > 0)
d932 1
d935 21
@


1.7
log
@Update to libxcb 1.9.0.
tested by ajacoutot@@ and naddy@@ on a full ports build
@
text
@d96 3
a98 2
    int length = 32;
    int eventlength = 0; /* length after first 32 bytes for GenericEvents */
d173 6
a178 2
    buf = malloc(length + eventlength +
            (genrep.response_type == XCB_REPLY ? 0 : sizeof(uint32_t)));
@


1.6
log
@Update to libxcb 1.8.1. Tested by krw@@, mpi@@, shadchin@@
@
text
@d28 4
@


1.5
log
@Bugfixes from upstream.
Minor tweaks (shutdown(2) related bits) by me.

OK matthieu@@
@
text
@d40 2
a41 1
#else
d43 1
d46 4
d73 1
a73 1
    unsigned int request;
d78 11
d139 2
d165 1
a165 1
    if (genrep.response_type == XCB_XGE_EVENT)
d172 1
a172 1
        _xcb_conn_shutdown(c);
a204 1
        reader_list *reader;
d208 1
a208 1
            _xcb_conn_shutdown(c);
d216 2
a217 11
        for(reader = c->in.readers; 
	    reader && 
	    XCB_SEQUENCE_COMPARE_32(reader->request, <=, c->in.request_read);
	    reader = reader->next)
	{
            if(XCB_SEQUENCE_COMPARE_32(reader->request, ==, c->in.request_read))
            {
                pthread_cond_signal(reader->data);
                break;
            }
	}
d225 1
a225 1
        _xcb_conn_shutdown(c);
d267 1
a267 1
        int ret = read(fd, ((char *) buf) + done, len - done);
d270 1
d272 3
d288 3
d294 1
a294 1
#endif
d302 1
a302 1
static int poll_for_reply(xcb_connection_t *c, unsigned int request, void **reply, xcb_generic_error_t **error)
d311 1
a311 1
    else if(XCB_SEQUENCE_COMPARE_32(request, <, c->in.request_read))
d319 1
a319 1
    else if(XCB_SEQUENCE_COMPARE_32(request, ==, c->in.request_read) && c->in.current_reply)
d328 1
a328 1
    else if(XCB_SEQUENCE_COMPARE_32(request, ==, c->in.request_completed))
d357 19
a375 1
/* Public interface */
d377 1
a377 1
void *xcb_wait_for_reply(xcb_connection_t *c, unsigned int request, xcb_generic_error_t **e)
a378 1
    uint64_t widened_request;
a379 10
    if(e)
        *e = 0;
    if(c->has_error)
        return 0;

    pthread_mutex_lock(&c->iolock);

    widened_request = (c->out.request & UINT64_C(0xffffffff00000000)) | request;
    if(widened_request > c->out.request)
        widened_request -= UINT64_C(1) << 32;
d382 1
a382 1
    if(c->out.return_socket || _xcb_out_flush_to(c, widened_request))
a385 1
        reader_list **prev_reader;
d387 1
a387 11
        for(prev_reader = &c->in.readers; 
	    *prev_reader && 
	    XCB_SEQUENCE_COMPARE_32((*prev_reader)->request, <=, request);
	    prev_reader = &(*prev_reader)->next)
	{
            /* empty */;
	}
        reader.request = request;
        reader.data = &cond;
        reader.next = *prev_reader;
        *prev_reader = &reader;
d393 1
a393 11
        for(prev_reader = &c->in.readers;
	    *prev_reader && 
	    XCB_SEQUENCE_COMPARE_32((*prev_reader)->request, <=, request);
	    prev_reader = &(*prev_reader)->next)
	{
            if(*prev_reader == &reader)
            {
                *prev_reader = (*prev_reader)->next;
                break;
            }
	}
d398 23
d431 1
a431 1
        _xcb_conn_shutdown(c);
d446 1
a446 1
static void discard_reply(xcb_connection_t *c, unsigned int request)
d448 1
a448 1
    pending_reply *pend = 0;
a449 34
    uint64_t widened_request;

    /* We've read requests past the one we want, so if it has replies we have
     * them all and they're in the replies map. */
    if(XCB_SEQUENCE_COMPARE_32(request, <, c->in.request_read))
    {
        struct reply_list *head;
        head = _xcb_map_remove(c->in.replies, request);
        while (head)
        {
            struct reply_list *next = head->next;
            free(head->reply);
            free(head);
            head = next;
        }
        return;
    }

    /* We're currently processing the responses to the request we want, and we
     * have a reply ready to return. Free it, and mark the pend to free any further
     * replies. */
    if(XCB_SEQUENCE_COMPARE_32(request, ==, c->in.request_read) && c->in.current_reply)
    {
        struct reply_list *head;
        head = c->in.current_reply;
        c->in.current_reply = NULL;
        c->in.current_reply_tail = &c->in.current_reply;
        while (head)
        {
            struct reply_list *next = head->next;
            free(head->reply);
            free(head);
            head = next;
        }
d451 4
a454 10
        pend = c->in.pending_replies;
        if(pend &&
            !(XCB_SEQUENCE_COMPARE(pend->first_request, <=, c->in.request_read) &&
             (pend->workaround == WORKAROUND_EXTERNAL_SOCKET_OWNER ||
              XCB_SEQUENCE_COMPARE(c->in.request_read, <=, pend->last_request))))
            pend = 0;
        if(pend)
            pend->flags |= XCB_REQUEST_DISCARD_REPLY;
        else
            insert_pending_discard(c, &c->in.pending_replies, c->in.request_read);
d456 2
a458 1
    }
d463 1
a463 1
        if(XCB_SEQUENCE_COMPARE_32((*prev_pend)->first_request, >, request))
d466 1
a466 1
        if(XCB_SEQUENCE_COMPARE_32((*prev_pend)->first_request, ==, request))
d475 1
a475 5
    widened_request = (c->out.request & UINT64_C(0xffffffff00000000)) | request;
    if(widened_request > c->out.request)
        widened_request -= UINT64_C(1) << 32;

    insert_pending_discard(c, prev_pend, widened_request);
d488 1
a488 1
    discard_reply(c, sequence);
d504 1
a504 1
    ret = poll_for_reply(c, request, reply, error);
d525 1
a525 1
xcb_generic_event_t *xcb_poll_for_event(xcb_connection_t *c)
d533 1
a533 1
        if(!ret && _xcb_in_read(c)) /* _xcb_in_read shuts down the connection on error */
d540 10
d552 2
a553 4
    /* FIXME: this could hold the lock to avoid syncing unnecessarily, but
     * that would require factoring the locking out of xcb_get_input_focus,
     * xcb_get_input_focus_reply, and xcb_wait_for_reply. */
    xcb_generic_error_t *ret;
d557 4
a560 2
    if(XCB_SEQUENCE_COMPARE_32(cookie.sequence,>=,c->in.request_expected)
       && XCB_SEQUENCE_COMPARE_32(cookie.sequence,>,c->in.request_completed))
d562 2
a563 2
        free(xcb_get_input_focus_reply(c, xcb_get_input_focus(c), &ret));
        assert(!ret);
d565 1
a565 1
    reply = xcb_wait_for_reply(c, cookie.sequence, &ret);
d567 1
d631 1
a631 1
        _xcb_conn_shutdown(c);
d659 1
a659 1
    int n = read(c->fd, c->in.queue + c->in.queue_len, sizeof(c->in.queue) - c->in.queue_len);
d664 1
d666 3
d670 1
a670 1
    _xcb_conn_shutdown(c);
d689 1
a689 1
            _xcb_conn_shutdown(c);
@


1.4
log
@Update to libxcb 1.7
@
text
@d567 1
a567 1
    if(XCB_SEQUENCE_COMPARE_32(cookie.sequence,>,c->in.request_expected)
@


1.3
log
@Update to libxcb 1.6. Mostly for new dri2 helper lib, requested by oga@@.
@
text
@a71 10
static void wake_up_next_reader(xcb_connection_t *c)
{
    int pthreadret;
    if(c->in.readers)
        pthreadret = pthread_cond_signal(c->in.readers->data);
    else
        pthreadret = pthread_cond_signal(&c->in.event_cond);
    assert(pthreadret == 0);
}

d147 1
a147 3
    {
        eventlength = ((xcb_ge_event_t*)&genrep)->length * 4;
    }
d395 1
a395 1
    wake_up_next_reader(c);
d538 1
a538 1
    wake_up_next_reader(c);
d620 10
@


1.2
log
@update to libxcb 1.3
@
text
@d412 110
@


1.1
log
@Initial revision
@
text
@a32 1
#include <sys/select.h>
d38 5
d275 9
d290 1
@


1.1.1.1
log
@import libxcb 1.2
@
text
@@
