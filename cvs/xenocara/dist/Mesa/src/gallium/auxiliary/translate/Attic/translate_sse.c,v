head	1.6;
access;
symbols
	OPENBSD_5_8:1.5.0.6
	OPENBSD_5_8_BASE:1.5
	OPENBSD_5_7:1.5.0.4
	OPENBSD_5_7_BASE:1.5
	v10_2_9:1.1.1.3
	v10_4_3:1.1.1.3
	v10_2_7:1.1.1.3
	OPENBSD_5_6:1.5.0.2
	OPENBSD_5_6_BASE:1.5
	v10_2_3:1.1.1.3
	OPENBSD_5_5:1.4.0.2
	OPENBSD_5_5_BASE:1.4
	v9_2_5:1.1.1.2
	v9_2_3:1.1.1.2
	v9_2_2:1.1.1.2
	v9_2_1:1.1.1.2
	v9_2_0:1.1.1.2
	OPENBSD_5_4:1.3.0.4
	OPENBSD_5_4_BASE:1.3
	OPENBSD_5_3:1.3.0.2
	OPENBSD_5_3_BASE:1.3
	OPENBSD_5_2:1.2.0.4
	OPENBSD_5_2_BASE:1.2
	OPENBSD_5_1_BASE:1.2
	OPENBSD_5_1:1.2.0.2
	v7_10_3:1.1.1.1
	mesa:1.1.1
	OPENBSD_5_0:1.1.0.6
	OPENBSD_5_0_BASE:1.1
	OPENBSD_4_9:1.1.0.2
	OPENBSD_4_9_BASE:1.1
	OPENBSD_4_8:1.1.0.4
	OPENBSD_4_8_BASE:1.1;
locks; strict;
comment	@ * @;


1.6
date	2015.12.23.05.17.27;	author jsg;	state dead;
branches;
next	1.5;
commitid	TnlogFl9nOv2eaRf;

1.5
date	2014.07.09.21.08.52;	author jsg;	state Exp;
branches;
next	1.4;
commitid	WPD6rgPryPkvXOr9;

1.4
date	2013.09.05.13.59.46;	author jsg;	state Exp;
branches;
next	1.3;

1.3
date	2012.08.17.13.58.03;	author mpi;	state Exp;
branches;
next	1.2;

1.2
date	2011.10.23.13.37.32;	author matthieu;	state Exp;
branches;
next	1.1;

1.1
date	2010.05.22.20.06.04;	author matthieu;	state Exp;
branches
	1.1.1.1;
next	;

1.1.1.1
date	2011.10.23.13.29.25;	author matthieu;	state Exp;
branches;
next	1.1.1.2;

1.1.1.2
date	2013.09.05.13.10.43;	author jsg;	state Exp;
branches;
next	1.1.1.3;

1.1.1.3
date	2014.07.09.20.33.46;	author jsg;	state Exp;
branches;
next	;
commitid	3JhLfwcuBALP0ZR7;


desc
@@


1.6
log
@remove the now unused Mesa 10.2.9 code
@
text
@/*
 * Copyright 2003 VMware, Inc.
 * All Rights Reserved.
 *
 * Permission is hereby granted, free of charge, to any person obtaining a
 * copy of this software and associated documentation files (the "Software"),
 * to deal in the Software without restriction, including without limitation
 * on the rights to use, copy, modify, merge, publish, distribute, sub
 * license, and/or sell copies of the Software, and to permit persons to whom
 * the Software is furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice (including the next
 * paragraph) shall be included in all copies or substantial portions of the
 * Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT.  IN NO EVENT SHALL
 * VMWARE AND/OR THEIR SUPPLIERS BE LIABLE FOR ANY CLAIM,
 * DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
 * OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
 * USE OR OTHER DEALINGS IN THE SOFTWARE.
 *
 * Authors:
 *    Keith Whitwell <keithw@@vmware.com>
 */


#include "pipe/p_config.h"
#include "pipe/p_compiler.h"
#include "util/u_memory.h"
#include "util/u_math.h"
#include "util/u_format.h"

#include "translate.h"


#if (defined(PIPE_ARCH_X86) || (defined(PIPE_ARCH_X86_64) && !defined(__MINGW32__))) && !defined(PIPE_SUBSYSTEM_EMBEDDED)

#include "rtasm/rtasm_cpu.h"
#include "rtasm/rtasm_x86sse.h"


#define X    0
#define Y    1
#define Z    2
#define W    3


struct translate_buffer
{
   const void *base_ptr;
   uintptr_t stride;
   unsigned max_index;
};

struct translate_buffer_variant
{
   unsigned buffer_index;
   unsigned instance_divisor;
   void *ptr;                   /* updated either per vertex or per instance */
};


#define ELEMENT_BUFFER_INSTANCE_ID  1001

#define NUM_CONSTS 7

enum
{
   CONST_IDENTITY,
   CONST_INV_127,
   CONST_INV_255,
   CONST_INV_32767,
   CONST_INV_65535,
   CONST_INV_2147483647,
   CONST_255
};

#define C(v) {(float)(v), (float)(v), (float)(v), (float)(v)}
static float consts[NUM_CONSTS][4] = {
   {0, 0, 0, 1},
   C(1.0 / 127.0),
   C(1.0 / 255.0),
   C(1.0 / 32767.0),
   C(1.0 / 65535.0),
   C(1.0 / 2147483647.0),
   C(255.0)
};

#undef C

struct translate_sse
{
   struct translate translate;

   struct x86_function linear_func;
   struct x86_function elt_func;
   struct x86_function elt16_func;
   struct x86_function elt8_func;
   struct x86_function *func;

     PIPE_ALIGN_VAR(16) float consts[NUM_CONSTS][4];
   int8_t reg_to_const[16];
   int8_t const_to_reg[NUM_CONSTS];

   struct translate_buffer buffer[TRANSLATE_MAX_ATTRIBS];
   unsigned nr_buffers;

   /* Multiple buffer variants can map to a single buffer. */
   struct translate_buffer_variant buffer_variant[TRANSLATE_MAX_ATTRIBS];
   unsigned nr_buffer_variants;

   /* Multiple elements can map to a single buffer variant. */
   unsigned element_to_buffer_variant[TRANSLATE_MAX_ATTRIBS];

   boolean use_instancing;
   unsigned instance_id;
   unsigned start_instance;

   /* these are actually known values, but putting them in a struct
    * like this is helpful to keep them in sync across the file.
    */
   struct x86_reg tmp_EAX;
   struct x86_reg tmp2_EDX;
   struct x86_reg src_ECX;
   struct x86_reg idx_ESI;      /* either start+i or &elt[i] */
   struct x86_reg machine_EDI;
   struct x86_reg outbuf_EBX;
   struct x86_reg count_EBP;    /* decrements to zero */
};


static int
get_offset(const void *a, const void *b)
{
   return (const char *) b - (const char *) a;
}


static struct x86_reg
get_const(struct translate_sse *p, unsigned id)
{
   struct x86_reg reg;
   unsigned i;

   if (p->const_to_reg[id] >= 0)
      return x86_make_reg(file_XMM, p->const_to_reg[id]);

   for (i = 2; i < 8; ++i) {
      if (p->reg_to_const[i] < 0)
         break;
   }

   /* TODO: be smarter here */
   if (i == 8)
      --i;

   reg = x86_make_reg(file_XMM, i);

   if (p->reg_to_const[i] >= 0)
      p->const_to_reg[p->reg_to_const[i]] = -1;

   p->reg_to_const[i] = id;
   p->const_to_reg[id] = i;

   /* TODO: this should happen outside the loop, if possible */
   sse_movaps(p->func, reg,
              x86_make_disp(p->machine_EDI,
                            get_offset(p, &p->consts[id][0])));

   return reg;
}


/* load the data in a SSE2 register, padding with zeros */
static boolean
emit_load_sse2(struct translate_sse *p,
               struct x86_reg data, struct x86_reg src, unsigned size)
{
   struct x86_reg tmpXMM = x86_make_reg(file_XMM, 1);
   struct x86_reg tmp = p->tmp_EAX;
   switch (size) {
   case 1:
      x86_movzx8(p->func, tmp, src);
      sse2_movd(p->func, data, tmp);
      break;
   case 2:
      x86_movzx16(p->func, tmp, src);
      sse2_movd(p->func, data, tmp);
      break;
   case 3:
      x86_movzx8(p->func, tmp, x86_make_disp(src, 2));
      x86_shl_imm(p->func, tmp, 16);
      x86_mov16(p->func, tmp, src);
      sse2_movd(p->func, data, tmp);
      break;
   case 4:
      sse2_movd(p->func, data, src);
      break;
   case 6:
      sse2_movd(p->func, data, src);
      x86_movzx16(p->func, tmp, x86_make_disp(src, 4));
      sse2_movd(p->func, tmpXMM, tmp);
      sse2_punpckldq(p->func, data, tmpXMM);
      break;
   case 8:
      sse2_movq(p->func, data, src);
      break;
   case 12:
      sse2_movq(p->func, data, src);
      sse2_movd(p->func, tmpXMM, x86_make_disp(src, 8));
      sse2_punpcklqdq(p->func, data, tmpXMM);
      break;
   case 16:
      sse2_movdqu(p->func, data, src);
      break;
   default:
      return FALSE;
   }
   return TRUE;
}


/* this value can be passed for the out_chans argument */
#define CHANNELS_0001 5


/* this function will load #chans float values, and will
 * pad the register with zeroes at least up to out_chans.
 *
 * If out_chans is set to CHANNELS_0001, then the fourth
 * value will be padded with 1. Only pass this value if
 * chans < 4 or results are undefined.
 */
static void
emit_load_float32(struct translate_sse *p, struct x86_reg data,
                  struct x86_reg arg0, unsigned out_chans, unsigned chans)
{
   switch (chans) {
   case 1:
      /* a 0 0 0
       * a 0 0 1
       */
      sse_movss(p->func, data, arg0);
      if (out_chans == CHANNELS_0001)
         sse_orps(p->func, data, get_const(p, CONST_IDENTITY));
      break;
   case 2:
      /* 0 0 0 1
       * a b 0 1
       */
      if (out_chans == CHANNELS_0001)
         sse_shufps(p->func, data, get_const(p, CONST_IDENTITY),
                    SHUF(X, Y, Z, W));
      else if (out_chans > 2)
         sse_movlhps(p->func, data, get_const(p, CONST_IDENTITY));
      sse_movlps(p->func, data, arg0);
      break;
   case 3:
      /* Have to jump through some hoops:
       *
       * c 0 0 0
       * c 0 0 1 if out_chans == CHANNELS_0001
       * 0 0 c 0/1
       * a b c 0/1
       */
      sse_movss(p->func, data, x86_make_disp(arg0, 8));
      if (out_chans == CHANNELS_0001)
         sse_shufps(p->func, data, get_const(p, CONST_IDENTITY),
                    SHUF(X, Y, Z, W));
      sse_shufps(p->func, data, data, SHUF(Y, Z, X, W));
      sse_movlps(p->func, data, arg0);
      break;
   case 4:
      sse_movups(p->func, data, arg0);
      break;
   }
}

/* this function behaves like emit_load_float32, but loads
   64-bit floating point numbers, converting them to 32-bit
  ones */
static void
emit_load_float64to32(struct translate_sse *p, struct x86_reg data,
                      struct x86_reg arg0, unsigned out_chans, unsigned chans)
{
   struct x86_reg tmpXMM = x86_make_reg(file_XMM, 1);
   switch (chans) {
   case 1:
      sse2_movsd(p->func, data, arg0);
      if (out_chans > 1)
         sse2_cvtpd2ps(p->func, data, data);
      else
         sse2_cvtsd2ss(p->func, data, data);
      if (out_chans == CHANNELS_0001)
         sse_shufps(p->func, data, get_const(p, CONST_IDENTITY),
                    SHUF(X, Y, Z, W));
      break;
   case 2:
      sse2_movupd(p->func, data, arg0);
      sse2_cvtpd2ps(p->func, data, data);
      if (out_chans == CHANNELS_0001)
         sse_shufps(p->func, data, get_const(p, CONST_IDENTITY),
                    SHUF(X, Y, Z, W));
      else if (out_chans > 2)
         sse_movlhps(p->func, data, get_const(p, CONST_IDENTITY));
      break;
   case 3:
      sse2_movupd(p->func, data, arg0);
      sse2_cvtpd2ps(p->func, data, data);
      sse2_movsd(p->func, tmpXMM, x86_make_disp(arg0, 16));
      if (out_chans > 3)
         sse2_cvtpd2ps(p->func, tmpXMM, tmpXMM);
      else
         sse2_cvtsd2ss(p->func, tmpXMM, tmpXMM);
      sse_movlhps(p->func, data, tmpXMM);
      if (out_chans == CHANNELS_0001)
         sse_orps(p->func, data, get_const(p, CONST_IDENTITY));
      break;
   case 4:
      sse2_movupd(p->func, data, arg0);
      sse2_cvtpd2ps(p->func, data, data);
      sse2_movupd(p->func, tmpXMM, x86_make_disp(arg0, 16));
      sse2_cvtpd2ps(p->func, tmpXMM, tmpXMM);
      sse_movlhps(p->func, data, tmpXMM);
      break;
   }
}


static void
emit_mov64(struct translate_sse *p, struct x86_reg dst_gpr,
           struct x86_reg dst_xmm, struct x86_reg src_gpr,
           struct x86_reg src_xmm)
{
   if (x86_target(p->func) != X86_32)
      x64_mov64(p->func, dst_gpr, src_gpr);
   else {
      /* TODO: when/on which CPUs is SSE2 actually better than SSE? */
      if (x86_target_caps(p->func) & X86_SSE2)
         sse2_movq(p->func, dst_xmm, src_xmm);
      else
         sse_movlps(p->func, dst_xmm, src_xmm);
   }
}


static void
emit_load64(struct translate_sse *p, struct x86_reg dst_gpr,
            struct x86_reg dst_xmm, struct x86_reg src)
{
   emit_mov64(p, dst_gpr, dst_xmm, src, src);
}


static void
emit_store64(struct translate_sse *p, struct x86_reg dst,
             struct x86_reg src_gpr, struct x86_reg src_xmm)
{
   emit_mov64(p, dst, dst, src_gpr, src_xmm);
}


static void
emit_mov128(struct translate_sse *p, struct x86_reg dst, struct x86_reg src)
{
   if (x86_target_caps(p->func) & X86_SSE2)
      sse2_movdqu(p->func, dst, src);
   else
      sse_movups(p->func, dst, src);
}


/* TODO: this uses unaligned accesses liberally, which is great on Nehalem,
 * but may or may not be good on older processors
 * TODO: may perhaps want to use non-temporal stores here if possible
 */
static void
emit_memcpy(struct translate_sse *p, struct x86_reg dst, struct x86_reg src,
            unsigned size)
{
   struct x86_reg dataXMM = x86_make_reg(file_XMM, 0);
   struct x86_reg dataXMM2 = x86_make_reg(file_XMM, 1);
   struct x86_reg dataGPR = p->tmp_EAX;
   struct x86_reg dataGPR2 = p->tmp2_EDX;

   if (size < 8) {
      switch (size) {
      case 1:
         x86_mov8(p->func, dataGPR, src);
         x86_mov8(p->func, dst, dataGPR);
         break;
      case 2:
         x86_mov16(p->func, dataGPR, src);
         x86_mov16(p->func, dst, dataGPR);
         break;
      case 3:
         x86_mov16(p->func, dataGPR, src);
         x86_mov8(p->func, dataGPR2, x86_make_disp(src, 2));
         x86_mov16(p->func, dst, dataGPR);
         x86_mov8(p->func, x86_make_disp(dst, 2), dataGPR2);
         break;
      case 4:
         x86_mov(p->func, dataGPR, src);
         x86_mov(p->func, dst, dataGPR);
         break;
      case 6:
         x86_mov(p->func, dataGPR, src);
         x86_mov16(p->func, dataGPR2, x86_make_disp(src, 4));
         x86_mov(p->func, dst, dataGPR);
         x86_mov16(p->func, x86_make_disp(dst, 4), dataGPR2);
         break;
      }
   }
   else if (!(x86_target_caps(p->func) & X86_SSE)) {
      unsigned i = 0;
      assert((size & 3) == 0);
      for (i = 0; i < size; i += 4) {
         x86_mov(p->func, dataGPR, x86_make_disp(src, i));
         x86_mov(p->func, x86_make_disp(dst, i), dataGPR);
      }
   }
   else {
      switch (size) {
      case 8:
         emit_load64(p, dataGPR, dataXMM, src);
         emit_store64(p, dst, dataGPR, dataXMM);
         break;
      case 12:
         emit_load64(p, dataGPR2, dataXMM, src);
         x86_mov(p->func, dataGPR, x86_make_disp(src, 8));
         emit_store64(p, dst, dataGPR2, dataXMM);
         x86_mov(p->func, x86_make_disp(dst, 8), dataGPR);
         break;
      case 16:
         emit_mov128(p, dataXMM, src);
         emit_mov128(p, dst, dataXMM);
         break;
      case 24:
         emit_mov128(p, dataXMM, src);
         emit_load64(p, dataGPR, dataXMM2, x86_make_disp(src, 16));
         emit_mov128(p, dst, dataXMM);
         emit_store64(p, x86_make_disp(dst, 16), dataGPR, dataXMM2);
         break;
      case 32:
         emit_mov128(p, dataXMM, src);
         emit_mov128(p, dataXMM2, x86_make_disp(src, 16));
         emit_mov128(p, dst, dataXMM);
         emit_mov128(p, x86_make_disp(dst, 16), dataXMM2);
         break;
      default:
         assert(0);
      }
   }
}

static boolean
translate_attr_convert(struct translate_sse *p,
                       const struct translate_element *a,
                       struct x86_reg src, struct x86_reg dst)
{
   const struct util_format_description *input_desc =
      util_format_description(a->input_format);
   const struct util_format_description *output_desc =
      util_format_description(a->output_format);
   unsigned i;
   boolean id_swizzle = TRUE;
   unsigned swizzle[4] =
      { UTIL_FORMAT_SWIZZLE_NONE, UTIL_FORMAT_SWIZZLE_NONE,
        UTIL_FORMAT_SWIZZLE_NONE, UTIL_FORMAT_SWIZZLE_NONE };
   unsigned needed_chans = 0;
   unsigned imms[2] = { 0, 0x3f800000 };

   if (a->output_format == PIPE_FORMAT_NONE
       || a->input_format == PIPE_FORMAT_NONE)
      return FALSE;

   if (input_desc->channel[0].size & 7)
      return FALSE;

   if (input_desc->colorspace != output_desc->colorspace)
      return FALSE;

   for (i = 1; i < input_desc->nr_channels; ++i) {
      if (memcmp
          (&input_desc->channel[i], &input_desc->channel[0],
           sizeof(input_desc->channel[0])))
         return FALSE;
   }

   for (i = 1; i < output_desc->nr_channels; ++i) {
      if (memcmp
          (&output_desc->channel[i], &output_desc->channel[0],
           sizeof(output_desc->channel[0]))) {
         return FALSE;
      }
   }

   for (i = 0; i < output_desc->nr_channels; ++i) {
      if (output_desc->swizzle[i] < 4)
         swizzle[output_desc->swizzle[i]] = input_desc->swizzle[i];
   }

   if ((x86_target_caps(p->func) & X86_SSE) &&
       (0 || a->output_format == PIPE_FORMAT_R32_FLOAT
        || a->output_format == PIPE_FORMAT_R32G32_FLOAT
        || a->output_format == PIPE_FORMAT_R32G32B32_FLOAT
        || a->output_format == PIPE_FORMAT_R32G32B32A32_FLOAT)) {
      struct x86_reg dataXMM = x86_make_reg(file_XMM, 0);

      for (i = 0; i < output_desc->nr_channels; ++i) {
         if (swizzle[i] == UTIL_FORMAT_SWIZZLE_0
             && i >= input_desc->nr_channels)
            swizzle[i] = i;
      }

      for (i = 0; i < output_desc->nr_channels; ++i) {
         if (swizzle[i] < 4)
            needed_chans = MAX2(needed_chans, swizzle[i] + 1);
         if (swizzle[i] < UTIL_FORMAT_SWIZZLE_0 && swizzle[i] != i)
            id_swizzle = FALSE;
      }

      if (needed_chans > 0) {
         switch (input_desc->channel[0].type) {
         case UTIL_FORMAT_TYPE_UNSIGNED:
            if (!(x86_target_caps(p->func) & X86_SSE2))
               return FALSE;
            emit_load_sse2(p, dataXMM, src,
                           input_desc->channel[0].size *
                           input_desc->nr_channels >> 3);

            /* TODO: add support for SSE4.1 pmovzx */
            switch (input_desc->channel[0].size) {
            case 8:
               /* TODO: this may be inefficient due to get_identity() being
                *  used both as a float and integer register.
                */
               sse2_punpcklbw(p->func, dataXMM, get_const(p, CONST_IDENTITY));
               sse2_punpcklbw(p->func, dataXMM, get_const(p, CONST_IDENTITY));
               break;
            case 16:
               sse2_punpcklwd(p->func, dataXMM, get_const(p, CONST_IDENTITY));
               break;
            case 32:           /* we lose precision here */
               sse2_psrld_imm(p->func, dataXMM, 1);
               break;
            default:
               return FALSE;
            }
            sse2_cvtdq2ps(p->func, dataXMM, dataXMM);
            if (input_desc->channel[0].normalized) {
               struct x86_reg factor;
               switch (input_desc->channel[0].size) {
               case 8:
                  factor = get_const(p, CONST_INV_255);
                  break;
               case 16:
                  factor = get_const(p, CONST_INV_65535);
                  break;
               case 32:
                  factor = get_const(p, CONST_INV_2147483647);
                  break;
               default:
                  assert(0);
                  factor.disp = 0;
                  factor.file = 0;
                  factor.idx = 0;
                  factor.mod = 0;
                  break;
               }
               sse_mulps(p->func, dataXMM, factor);
            }
            else if (input_desc->channel[0].size == 32)
               /* compensate for the bit we threw away to fit u32 into s32 */
               sse_addps(p->func, dataXMM, dataXMM);
            break;
         case UTIL_FORMAT_TYPE_SIGNED:
            if (!(x86_target_caps(p->func) & X86_SSE2))
               return FALSE;
            emit_load_sse2(p, dataXMM, src,
                           input_desc->channel[0].size *
                           input_desc->nr_channels >> 3);

            /* TODO: add support for SSE4.1 pmovsx */
            switch (input_desc->channel[0].size) {
            case 8:
               sse2_punpcklbw(p->func, dataXMM, dataXMM);
               sse2_punpcklbw(p->func, dataXMM, dataXMM);
               sse2_psrad_imm(p->func, dataXMM, 24);
               break;
            case 16:
               sse2_punpcklwd(p->func, dataXMM, dataXMM);
               sse2_psrad_imm(p->func, dataXMM, 16);
               break;
            case 32:           /* we lose precision here */
               break;
            default:
               return FALSE;
            }
            sse2_cvtdq2ps(p->func, dataXMM, dataXMM);
            if (input_desc->channel[0].normalized) {
               struct x86_reg factor;
               switch (input_desc->channel[0].size) {
               case 8:
                  factor = get_const(p, CONST_INV_127);
                  break;
               case 16:
                  factor = get_const(p, CONST_INV_32767);
                  break;
               case 32:
                  factor = get_const(p, CONST_INV_2147483647);
                  break;
               default:
                  assert(0);
                  factor.disp = 0;
                  factor.file = 0;
                  factor.idx = 0;
                  factor.mod = 0;
                  break;
               }
               sse_mulps(p->func, dataXMM, factor);
            }
            break;

            break;
         case UTIL_FORMAT_TYPE_FLOAT:
            if (input_desc->channel[0].size != 32
                && input_desc->channel[0].size != 64) {
               return FALSE;
            }
            if (swizzle[3] == UTIL_FORMAT_SWIZZLE_1
                && input_desc->nr_channels <= 3) {
               swizzle[3] = UTIL_FORMAT_SWIZZLE_W;
               needed_chans = CHANNELS_0001;
            }
            switch (input_desc->channel[0].size) {
            case 32:
               emit_load_float32(p, dataXMM, src, needed_chans,
                                 input_desc->nr_channels);
               break;
            case 64:           /* we lose precision here */
               if (!(x86_target_caps(p->func) & X86_SSE2))
                  return FALSE;
               emit_load_float64to32(p, dataXMM, src, needed_chans,
                                     input_desc->nr_channels);
               break;
            default:
               return FALSE;
            }
            break;
         default:
            return FALSE;
         }

         if (!id_swizzle) {
            sse_shufps(p->func, dataXMM, dataXMM,
                       SHUF(swizzle[0], swizzle[1], swizzle[2], swizzle[3]));
         }
      }

      if (output_desc->nr_channels >= 4
          && swizzle[0] < UTIL_FORMAT_SWIZZLE_0
          && swizzle[1] < UTIL_FORMAT_SWIZZLE_0
          && swizzle[2] < UTIL_FORMAT_SWIZZLE_0
          && swizzle[3] < UTIL_FORMAT_SWIZZLE_0) {
         sse_movups(p->func, dst, dataXMM);
      }
      else {
         if (output_desc->nr_channels >= 2
             && swizzle[0] < UTIL_FORMAT_SWIZZLE_0
             && swizzle[1] < UTIL_FORMAT_SWIZZLE_0) {
            sse_movlps(p->func, dst, dataXMM);
         }
         else {
            if (swizzle[0] < UTIL_FORMAT_SWIZZLE_0) {
               sse_movss(p->func, dst, dataXMM);
            }
            else {
               x86_mov_imm(p->func, dst,
                           imms[swizzle[0] - UTIL_FORMAT_SWIZZLE_0]);
            }

            if (output_desc->nr_channels >= 2) {
               if (swizzle[1] < UTIL_FORMAT_SWIZZLE_0) {
                  sse_shufps(p->func, dataXMM, dataXMM, SHUF(1, 1, 2, 3));
                  sse_movss(p->func, x86_make_disp(dst, 4), dataXMM);
               }
               else {
                  x86_mov_imm(p->func, x86_make_disp(dst, 4),
                              imms[swizzle[1] - UTIL_FORMAT_SWIZZLE_0]);
               }
            }
         }

         if (output_desc->nr_channels >= 3) {
            if (output_desc->nr_channels >= 4
                && swizzle[2] < UTIL_FORMAT_SWIZZLE_0
                && swizzle[3] < UTIL_FORMAT_SWIZZLE_0) {
               sse_movhps(p->func, x86_make_disp(dst, 8), dataXMM);
            }
            else {
               if (swizzle[2] < UTIL_FORMAT_SWIZZLE_0) {
                  sse_shufps(p->func, dataXMM, dataXMM, SHUF(2, 2, 2, 3));
                  sse_movss(p->func, x86_make_disp(dst, 8), dataXMM);
               }
               else {
                  x86_mov_imm(p->func, x86_make_disp(dst, 8),
                              imms[swizzle[2] - UTIL_FORMAT_SWIZZLE_0]);
               }

               if (output_desc->nr_channels >= 4) {
                  if (swizzle[3] < UTIL_FORMAT_SWIZZLE_0) {
                     sse_shufps(p->func, dataXMM, dataXMM, SHUF(3, 3, 3, 3));
                     sse_movss(p->func, x86_make_disp(dst, 12), dataXMM);
                  }
                  else {
                     x86_mov_imm(p->func, x86_make_disp(dst, 12),
                                 imms[swizzle[3] - UTIL_FORMAT_SWIZZLE_0]);
                  }
               }
            }
         }
      }
      return TRUE;
   }
   else if ((x86_target_caps(p->func) & X86_SSE2)
            && input_desc->channel[0].size == 8
            && output_desc->channel[0].size == 16
            && output_desc->channel[0].normalized ==
            input_desc->channel[0].normalized &&
            (0 || (input_desc->channel[0].type == UTIL_FORMAT_TYPE_UNSIGNED
                   && output_desc->channel[0].type == UTIL_FORMAT_TYPE_UNSIGNED)
             || (input_desc->channel[0].type == UTIL_FORMAT_TYPE_UNSIGNED
                 && output_desc->channel[0].type == UTIL_FORMAT_TYPE_SIGNED)
             || (input_desc->channel[0].type == UTIL_FORMAT_TYPE_SIGNED
                 && output_desc->channel[0].type == UTIL_FORMAT_TYPE_SIGNED))) {
      struct x86_reg dataXMM = x86_make_reg(file_XMM, 0);
      struct x86_reg tmpXMM = x86_make_reg(file_XMM, 1);
      struct x86_reg tmp = p->tmp_EAX;
      unsigned imms[2] = { 0, 1 };

      for (i = 0; i < output_desc->nr_channels; ++i) {
         if (swizzle[i] == UTIL_FORMAT_SWIZZLE_0
             && i >= input_desc->nr_channels) {
            swizzle[i] = i;
         }
      }

      for (i = 0; i < output_desc->nr_channels; ++i) {
         if (swizzle[i] < 4)
            needed_chans = MAX2(needed_chans, swizzle[i] + 1);
         if (swizzle[i] < UTIL_FORMAT_SWIZZLE_0 && swizzle[i] != i)
            id_swizzle = FALSE;
      }

      if (needed_chans > 0) {
         emit_load_sse2(p, dataXMM, src,
                        input_desc->channel[0].size *
                        input_desc->nr_channels >> 3);

         switch (input_desc->channel[0].type) {
         case UTIL_FORMAT_TYPE_UNSIGNED:
            if (input_desc->channel[0].normalized) {
               sse2_punpcklbw(p->func, dataXMM, dataXMM);
               if (output_desc->channel[0].type == UTIL_FORMAT_TYPE_SIGNED)
                  sse2_psrlw_imm(p->func, dataXMM, 1);
            }
            else
               sse2_punpcklbw(p->func, dataXMM, get_const(p, CONST_IDENTITY));
            break;
         case UTIL_FORMAT_TYPE_SIGNED:
            if (input_desc->channel[0].normalized) {
               sse2_movq(p->func, tmpXMM, get_const(p, CONST_IDENTITY));
               sse2_punpcklbw(p->func, tmpXMM, dataXMM);
               sse2_psllw_imm(p->func, dataXMM, 9);
               sse2_psrlw_imm(p->func, dataXMM, 8);
               sse2_por(p->func, tmpXMM, dataXMM);
               sse2_psrlw_imm(p->func, dataXMM, 7);
               sse2_por(p->func, tmpXMM, dataXMM);
               {
                  struct x86_reg t = dataXMM;
                  dataXMM = tmpXMM;
                  tmpXMM = t;
               }
            }
            else {
               sse2_punpcklbw(p->func, dataXMM, dataXMM);
               sse2_psraw_imm(p->func, dataXMM, 8);
            }
            break;
         default:
            assert(0);
         }

         if (output_desc->channel[0].normalized)
            imms[1] =
               (output_desc->channel[0].type ==
                UTIL_FORMAT_TYPE_UNSIGNED) ? 0xffff : 0x7ffff;

         if (!id_swizzle)
            sse2_pshuflw(p->func, dataXMM, dataXMM,
                         (swizzle[0] & 3) | ((swizzle[1] & 3) << 2) |
                         ((swizzle[2] & 3) << 4) | ((swizzle[3] & 3) << 6));
      }

      if (output_desc->nr_channels >= 4
          && swizzle[0] < UTIL_FORMAT_SWIZZLE_0
          && swizzle[1] < UTIL_FORMAT_SWIZZLE_0
          && swizzle[2] < UTIL_FORMAT_SWIZZLE_0
          && swizzle[3] < UTIL_FORMAT_SWIZZLE_0) {
         sse2_movq(p->func, dst, dataXMM);
      }
      else {
         if (swizzle[0] < UTIL_FORMAT_SWIZZLE_0) {
            if (output_desc->nr_channels >= 2
                && swizzle[1] < UTIL_FORMAT_SWIZZLE_0) {
               sse2_movd(p->func, dst, dataXMM);
            }
            else {
               sse2_movd(p->func, tmp, dataXMM);
               x86_mov16(p->func, dst, tmp);
               if (output_desc->nr_channels >= 2)
                  x86_mov16_imm(p->func, x86_make_disp(dst, 2),
                                imms[swizzle[1] - UTIL_FORMAT_SWIZZLE_0]);
            }
         }
         else {
            if (output_desc->nr_channels >= 2
                && swizzle[1] >= UTIL_FORMAT_SWIZZLE_0) {
               x86_mov_imm(p->func, dst,
                           (imms[swizzle[1] - UTIL_FORMAT_SWIZZLE_0] << 16) |
                           imms[swizzle[0] - UTIL_FORMAT_SWIZZLE_0]);
            }
            else {
               x86_mov16_imm(p->func, dst,
                             imms[swizzle[0] - UTIL_FORMAT_SWIZZLE_0]);
               if (output_desc->nr_channels >= 2) {
                  sse2_movd(p->func, tmp, dataXMM);
                  x86_shr_imm(p->func, tmp, 16);
                  x86_mov16(p->func, x86_make_disp(dst, 2), tmp);
               }
            }
         }

         if (output_desc->nr_channels >= 3) {
            if (swizzle[2] < UTIL_FORMAT_SWIZZLE_0) {
               if (output_desc->nr_channels >= 4
                   && swizzle[3] < UTIL_FORMAT_SWIZZLE_0) {
                  sse2_psrlq_imm(p->func, dataXMM, 32);
                  sse2_movd(p->func, x86_make_disp(dst, 4), dataXMM);
               }
               else {
                  sse2_psrlq_imm(p->func, dataXMM, 32);
                  sse2_movd(p->func, tmp, dataXMM);
                  x86_mov16(p->func, x86_make_disp(dst, 4), tmp);
                  if (output_desc->nr_channels >= 4) {
                     x86_mov16_imm(p->func, x86_make_disp(dst, 6),
                                   imms[swizzle[3] - UTIL_FORMAT_SWIZZLE_0]);
                  }
               }
            }
            else {
               if (output_desc->nr_channels >= 4
                   && swizzle[3] >= UTIL_FORMAT_SWIZZLE_0) {
                  x86_mov_imm(p->func, x86_make_disp(dst, 4),
                              (imms[swizzle[3] - UTIL_FORMAT_SWIZZLE_0] << 16)
                              | imms[swizzle[2] - UTIL_FORMAT_SWIZZLE_0]);
               }
               else {
                  x86_mov16_imm(p->func, x86_make_disp(dst, 4),
                                imms[swizzle[2] - UTIL_FORMAT_SWIZZLE_0]);

                  if (output_desc->nr_channels >= 4) {
                     sse2_psrlq_imm(p->func, dataXMM, 48);
                     sse2_movd(p->func, tmp, dataXMM);
                     x86_mov16(p->func, x86_make_disp(dst, 6), tmp);
                  }
               }
            }
         }
      }
      return TRUE;
   }
   else if (!memcmp(&output_desc->channel[0], &input_desc->channel[0],
                    sizeof(output_desc->channel[0]))) {
      struct x86_reg tmp = p->tmp_EAX;
      unsigned i;

      if (input_desc->channel[0].size == 8 && input_desc->nr_channels == 4
          && output_desc->nr_channels == 4
          && swizzle[0] == UTIL_FORMAT_SWIZZLE_W
          && swizzle[1] == UTIL_FORMAT_SWIZZLE_Z
          && swizzle[2] == UTIL_FORMAT_SWIZZLE_Y
          && swizzle[3] == UTIL_FORMAT_SWIZZLE_X) {
         /* TODO: support movbe */
         x86_mov(p->func, tmp, src);
         x86_bswap(p->func, tmp);
         x86_mov(p->func, dst, tmp);
         return TRUE;
      }

      for (i = 0; i < output_desc->nr_channels; ++i) {
         switch (output_desc->channel[0].size) {
         case 8:
            if (swizzle[i] >= UTIL_FORMAT_SWIZZLE_0) {
               unsigned v = 0;
               if (swizzle[i] == UTIL_FORMAT_SWIZZLE_1) {
                  switch (output_desc->channel[0].type) {
                  case UTIL_FORMAT_TYPE_UNSIGNED:
                     v = output_desc->channel[0].normalized ? 0xff : 1;
                     break;
                  case UTIL_FORMAT_TYPE_SIGNED:
                     v = output_desc->channel[0].normalized ? 0x7f : 1;
                     break;
                  default:
                     return FALSE;
                  }
               }
               x86_mov8_imm(p->func, x86_make_disp(dst, i * 1), v);
            }
            else {
               x86_mov8(p->func, tmp, x86_make_disp(src, swizzle[i] * 1));
               x86_mov8(p->func, x86_make_disp(dst, i * 1), tmp);
            }
            break;
         case 16:
            if (swizzle[i] >= UTIL_FORMAT_SWIZZLE_0) {
               unsigned v = 0;
               if (swizzle[i] == UTIL_FORMAT_SWIZZLE_1) {
                  switch (output_desc->channel[1].type) {
                  case UTIL_FORMAT_TYPE_UNSIGNED:
                     v = output_desc->channel[1].normalized ? 0xffff : 1;
                     break;
                  case UTIL_FORMAT_TYPE_SIGNED:
                     v = output_desc->channel[1].normalized ? 0x7fff : 1;
                     break;
                  case UTIL_FORMAT_TYPE_FLOAT:
                     v = 0x3c00;
                     break;
                  default:
                     return FALSE;
                  }
               }
               x86_mov16_imm(p->func, x86_make_disp(dst, i * 2), v);
            }
            else if (swizzle[i] == UTIL_FORMAT_SWIZZLE_0) {
               x86_mov16_imm(p->func, x86_make_disp(dst, i * 2), 0);
            }
            else {
               x86_mov16(p->func, tmp, x86_make_disp(src, swizzle[i] * 2));
               x86_mov16(p->func, x86_make_disp(dst, i * 2), tmp);
            }
            break;
         case 32:
            if (swizzle[i] >= UTIL_FORMAT_SWIZZLE_0) {
               unsigned v = 0;
               if (swizzle[i] == UTIL_FORMAT_SWIZZLE_1) {
                  switch (output_desc->channel[1].type) {
                  case UTIL_FORMAT_TYPE_UNSIGNED:
                     v = output_desc->channel[1].normalized ? 0xffffffff : 1;
                     break;
                  case UTIL_FORMAT_TYPE_SIGNED:
                     v = output_desc->channel[1].normalized ? 0x7fffffff : 1;
                     break;
                  case UTIL_FORMAT_TYPE_FLOAT:
                     v = 0x3f800000;
                     break;
                  default:
                     return FALSE;
                  }
               }
               x86_mov_imm(p->func, x86_make_disp(dst, i * 4), v);
            }
            else {
               x86_mov(p->func, tmp, x86_make_disp(src, swizzle[i] * 4));
               x86_mov(p->func, x86_make_disp(dst, i * 4), tmp);
            }
            break;
         case 64:
            if (swizzle[i] >= UTIL_FORMAT_SWIZZLE_0) {
               unsigned l = 0;
               unsigned h = 0;
               if (swizzle[i] == UTIL_FORMAT_SWIZZLE_1) {
                  switch (output_desc->channel[1].type) {
                  case UTIL_FORMAT_TYPE_UNSIGNED:
                     h = output_desc->channel[1].normalized ? 0xffffffff : 0;
                     l = output_desc->channel[1].normalized ? 0xffffffff : 1;
                     break;
                  case UTIL_FORMAT_TYPE_SIGNED:
                     h = output_desc->channel[1].normalized ? 0x7fffffff : 0;
                     l = output_desc->channel[1].normalized ? 0xffffffff : 1;
                     break;
                  case UTIL_FORMAT_TYPE_FLOAT:
                     h = 0x3ff00000;
                     l = 0;
                     break;
                  default:
                     return FALSE;
                  }
               }
               x86_mov_imm(p->func, x86_make_disp(dst, i * 8), l);
               x86_mov_imm(p->func, x86_make_disp(dst, i * 8 + 4), h);
            }
            else {
               if (x86_target_caps(p->func) & X86_SSE) {
                  struct x86_reg tmpXMM = x86_make_reg(file_XMM, 0);
                  emit_load64(p, tmp, tmpXMM,
                              x86_make_disp(src, swizzle[i] * 8));
                  emit_store64(p, x86_make_disp(dst, i * 8), tmp, tmpXMM);
               }
               else {
                  x86_mov(p->func, tmp, x86_make_disp(src, swizzle[i] * 8));
                  x86_mov(p->func, x86_make_disp(dst, i * 8), tmp);
                  x86_mov(p->func, tmp,
                          x86_make_disp(src, swizzle[i] * 8 + 4));
                  x86_mov(p->func, x86_make_disp(dst, i * 8 + 4), tmp);
               }
            }
            break;
         default:
            return FALSE;
         }
      }
      return TRUE;
   }
   /* special case for draw's EMIT_4UB (RGBA) and EMIT_4UB_BGRA */
   else if ((x86_target_caps(p->func) & X86_SSE2) &&
            a->input_format == PIPE_FORMAT_R32G32B32A32_FLOAT &&
            (0 || a->output_format == PIPE_FORMAT_B8G8R8A8_UNORM
             || a-> output_format == PIPE_FORMAT_R8G8B8A8_UNORM)) {
      struct x86_reg dataXMM = x86_make_reg(file_XMM, 0);

      /* load */
      sse_movups(p->func, dataXMM, src);

      if (a->output_format == PIPE_FORMAT_B8G8R8A8_UNORM) {
         sse_shufps(p->func, dataXMM, dataXMM, SHUF(2, 1, 0, 3));
      }

      /* scale by 255.0 */
      sse_mulps(p->func, dataXMM, get_const(p, CONST_255));

      /* pack and emit */
      sse2_cvtps2dq(p->func, dataXMM, dataXMM);
      sse2_packssdw(p->func, dataXMM, dataXMM);
      sse2_packuswb(p->func, dataXMM, dataXMM);
      sse2_movd(p->func, dst, dataXMM);

      return TRUE;
   }

   return FALSE;
}


static boolean
translate_attr(struct translate_sse *p,
               const struct translate_element *a,
               struct x86_reg src, struct x86_reg dst)
{
   if (a->input_format == a->output_format) {
      emit_memcpy(p, dst, src, util_format_get_stride(a->input_format, 1));
      return TRUE;
   }

   return translate_attr_convert(p, a, src, dst);
}


static boolean
init_inputs(struct translate_sse *p, unsigned index_size)
{
   unsigned i;
   struct x86_reg instance_id =
      x86_make_disp(p->machine_EDI, get_offset(p, &p->instance_id));
   struct x86_reg start_instance =
      x86_make_disp(p->machine_EDI, get_offset(p, &p->start_instance));

   for (i = 0; i < p->nr_buffer_variants; i++) {
      struct translate_buffer_variant *variant = &p->buffer_variant[i];
      struct translate_buffer *buffer = &p->buffer[variant->buffer_index];

      if (!index_size || variant->instance_divisor) {
         struct x86_reg buf_max_index =
            x86_make_disp(p->machine_EDI, get_offset(p, &buffer->max_index));
         struct x86_reg buf_stride =
            x86_make_disp(p->machine_EDI, get_offset(p, &buffer->stride));
         struct x86_reg buf_ptr =
            x86_make_disp(p->machine_EDI, get_offset(p, &variant->ptr));
         struct x86_reg buf_base_ptr =
            x86_make_disp(p->machine_EDI, get_offset(p, &buffer->base_ptr));
         struct x86_reg elt = p->idx_ESI;
         struct x86_reg tmp_EAX = p->tmp_EAX;

         /* Calculate pointer to first attrib:
          *   base_ptr + stride * index, where index depends on instance divisor
          */
         if (variant->instance_divisor) {
            /* Start with instance = instance_id
             * which is true if divisor is 1.
             */
            x86_mov(p->func, tmp_EAX, instance_id);

            if (variant->instance_divisor != 1) {
               struct x86_reg tmp_EDX = p->tmp2_EDX;
               struct x86_reg tmp_ECX = p->src_ECX;

               /* TODO: Add x86_shr() to rtasm and use it whenever
                *       instance divisor is power of two.
                */
               x86_xor(p->func, tmp_EDX, tmp_EDX);
               x86_mov_reg_imm(p->func, tmp_ECX, variant->instance_divisor);
               x86_div(p->func, tmp_ECX);       /* EAX = EDX:EAX / ECX */

               /* instance = (instance_id - start_instance) / divisor + 
                *             start_instance 
                */
               x86_mov(p->func, tmp_EDX, start_instance);
               x86_add(p->func, tmp_EAX, tmp_EDX);
            }

            /* XXX we need to clamp the index here too, but to a
             * per-array max value, not the draw->pt.max_index value
             * that's being given to us via translate->set_buffer().
             */
         }
         else {
            x86_mov(p->func, tmp_EAX, elt);

            /* Clamp to max_index
             */
            x86_cmp(p->func, tmp_EAX, buf_max_index);
            x86_cmovcc(p->func, tmp_EAX, buf_max_index, cc_AE);
         }

         x86_mov(p->func, p->tmp2_EDX, buf_stride);
         x64_rexw(p->func);
         x86_imul(p->func, tmp_EAX, p->tmp2_EDX);
         x64_rexw(p->func);
         x86_add(p->func, tmp_EAX, buf_base_ptr);

         x86_cmp(p->func, p->count_EBP, p->tmp_EAX);

         /* In the linear case, keep the buffer pointer instead of the
          * index number.
          */
         if (!index_size && p->nr_buffer_variants == 1) {
            x64_rexw(p->func);
            x86_mov(p->func, elt, tmp_EAX);
         }
         else {
            x64_rexw(p->func);
            x86_mov(p->func, buf_ptr, tmp_EAX);
         }
      }
   }

   return TRUE;
}


static struct x86_reg
get_buffer_ptr(struct translate_sse *p,
               unsigned index_size, unsigned var_idx, struct x86_reg elt)
{
   if (var_idx == ELEMENT_BUFFER_INSTANCE_ID) {
      return x86_make_disp(p->machine_EDI, get_offset(p, &p->instance_id));
   }
   if (!index_size && p->nr_buffer_variants == 1) {
      return p->idx_ESI;
   }
   else if (!index_size || p->buffer_variant[var_idx].instance_divisor) {
      struct x86_reg ptr = p->src_ECX;
      struct x86_reg buf_ptr =
         x86_make_disp(p->machine_EDI,
                       get_offset(p, &p->buffer_variant[var_idx].ptr));

      x64_rexw(p->func);
      x86_mov(p->func, ptr, buf_ptr);
      return ptr;
   }
   else {
      struct x86_reg ptr = p->src_ECX;
      const struct translate_buffer_variant *variant =
         &p->buffer_variant[var_idx];
      struct x86_reg buf_stride =
         x86_make_disp(p->machine_EDI,
                       get_offset(p, &p->buffer[variant->buffer_index].stride));
      struct x86_reg buf_base_ptr =
         x86_make_disp(p->machine_EDI,
                  get_offset(p, &p->buffer[variant->buffer_index].base_ptr));
      struct x86_reg buf_max_index =
         x86_make_disp(p->machine_EDI,
                  get_offset(p, &p->buffer[variant->buffer_index].max_index));

      /* Calculate pointer to current attrib:
       */
      switch (index_size) {
      case 1:
         x86_movzx8(p->func, ptr, elt);
         break;
      case 2:
         x86_movzx16(p->func, ptr, elt);
         break;
      case 4:
         x86_mov(p->func, ptr, elt);
         break;
      }

      /* Clamp to max_index
       */
      x86_cmp(p->func, ptr, buf_max_index);
      x86_cmovcc(p->func, ptr, buf_max_index, cc_AE);

      x86_mov(p->func, p->tmp2_EDX, buf_stride);
      x64_rexw(p->func);
      x86_imul(p->func, ptr, p->tmp2_EDX);
      x64_rexw(p->func);
      x86_add(p->func, ptr, buf_base_ptr);
      return ptr;
   }
}


static boolean
incr_inputs(struct translate_sse *p, unsigned index_size)
{
   if (!index_size && p->nr_buffer_variants == 1) {
      const unsigned buffer_index = p->buffer_variant[0].buffer_index;
      struct x86_reg stride =
         x86_make_disp(p->machine_EDI,
                       get_offset(p, &p->buffer[buffer_index].stride));

      if (p->buffer_variant[0].instance_divisor == 0) {
         x64_rexw(p->func);
         x86_add(p->func, p->idx_ESI, stride);
         sse_prefetchnta(p->func, x86_make_disp(p->idx_ESI, 192));
      }
   }
   else if (!index_size) {
      unsigned i;

      /* Is this worthwhile??
       */
      for (i = 0; i < p->nr_buffer_variants; i++) {
         struct translate_buffer_variant *variant = &p->buffer_variant[i];
         struct x86_reg buf_ptr = x86_make_disp(p->machine_EDI,
                                                get_offset(p, &variant->ptr));
      struct x86_reg buf_stride =
         x86_make_disp(p->machine_EDI,
                       get_offset(p, &p->buffer[variant->buffer_index].stride));

         if (variant->instance_divisor == 0) {
            x86_mov(p->func, p->tmp_EAX, buf_stride);
            x64_rexw(p->func);
            x86_add(p->func, p->tmp_EAX, buf_ptr);
            if (i == 0)
               sse_prefetchnta(p->func, x86_make_disp(p->tmp_EAX, 192));
            x64_rexw(p->func);
            x86_mov(p->func, buf_ptr, p->tmp_EAX);
         }
      }
   }
   else {
      x64_rexw(p->func);
      x86_lea(p->func, p->idx_ESI, x86_make_disp(p->idx_ESI, index_size));
   }

   return TRUE;
}


/* Build run( struct translate *machine,
 *            unsigned start,
 *            unsigned count,
 *            void *output_buffer )
 * or
 *  run_elts( struct translate *machine,
 *            unsigned *elts,
 *            unsigned count,
 *            void *output_buffer )
 *
 *  Lots of hardcoding
 *
 * EAX -- pointer to current output vertex
 * ECX -- pointer to current attribute 
 * 
 */
static boolean
build_vertex_emit(struct translate_sse *p,
                  struct x86_function *func, unsigned index_size)
{
   int fixup, label;
   unsigned j;

   memset(p->reg_to_const, 0xff, sizeof(p->reg_to_const));
   memset(p->const_to_reg, 0xff, sizeof(p->const_to_reg));

   p->tmp_EAX = x86_make_reg(file_REG32, reg_AX);
   p->idx_ESI = x86_make_reg(file_REG32, reg_SI);
   p->outbuf_EBX = x86_make_reg(file_REG32, reg_BX);
   p->machine_EDI = x86_make_reg(file_REG32, reg_DI);
   p->count_EBP = x86_make_reg(file_REG32, reg_BP);
   p->tmp2_EDX = x86_make_reg(file_REG32, reg_DX);
   p->src_ECX = x86_make_reg(file_REG32, reg_CX);

   p->func = func;

   x86_init_func(p->func);

   if (x86_target(p->func) == X86_64_WIN64_ABI) {
      /* the ABI guarantees a 16-byte aligned 32-byte "shadow space"
       * above the return address
       */
      sse2_movdqa(p->func, x86_make_disp(x86_make_reg(file_REG32, reg_SP), 8),
                  x86_make_reg(file_XMM, 6));
      sse2_movdqa(p->func,
                  x86_make_disp(x86_make_reg(file_REG32, reg_SP), 24),
                  x86_make_reg(file_XMM, 7));
   }

   x86_push(p->func, p->outbuf_EBX);
   x86_push(p->func, p->count_EBP);

   /* on non-Win64 x86-64, these are already in the right registers */
   if (x86_target(p->func) != X86_64_STD_ABI) {
      x86_push(p->func, p->machine_EDI);
      x86_push(p->func, p->idx_ESI);

      if (x86_target(p->func) != X86_32) {
         x64_mov64(p->func, p->machine_EDI, x86_fn_arg(p->func, 1));
         x64_mov64(p->func, p->idx_ESI, x86_fn_arg(p->func, 2));
      }
      else {
         x86_mov(p->func, p->machine_EDI, x86_fn_arg(p->func, 1));
         x86_mov(p->func, p->idx_ESI, x86_fn_arg(p->func, 2));
      }
   }

   x86_mov(p->func, p->count_EBP, x86_fn_arg(p->func, 3));

   if (x86_target(p->func) != X86_32)
      x64_mov64(p->func, p->outbuf_EBX, x86_fn_arg(p->func, 6));
   else
      x86_mov(p->func, p->outbuf_EBX, x86_fn_arg(p->func, 6));

   /* Load instance ID.
    */
   if (p->use_instancing) {
      x86_mov(p->func, p->tmp2_EDX, x86_fn_arg(p->func, 4));
      x86_mov(p->func,
              x86_make_disp(p->machine_EDI,
                            get_offset(p, &p->start_instance)), p->tmp2_EDX);

      x86_mov(p->func, p->tmp_EAX, x86_fn_arg(p->func, 5));
      x86_mov(p->func,
              x86_make_disp(p->machine_EDI, get_offset(p, &p->instance_id)),
              p->tmp_EAX);
   }

   /* Get vertex count, compare to zero
    */
   x86_xor(p->func, p->tmp_EAX, p->tmp_EAX);
   x86_cmp(p->func, p->count_EBP, p->tmp_EAX);
   fixup = x86_jcc_forward(p->func, cc_E);

   /* always load, needed or not:
    */
   init_inputs(p, index_size);

   /* Note address for loop jump
    */
   label = x86_get_label(p->func);
   {
      struct x86_reg elt = !index_size ? p->idx_ESI : x86_deref(p->idx_ESI);
      int last_variant = -1;
      struct x86_reg vb;

      for (j = 0; j < p->translate.key.nr_elements; j++) {
         const struct translate_element *a = &p->translate.key.element[j];
         unsigned variant = p->element_to_buffer_variant[j];

         /* Figure out source pointer address:
          */
         if (variant != last_variant) {
            last_variant = variant;
            vb = get_buffer_ptr(p, index_size, variant, elt);
         }

         if (!translate_attr(p, a,
                             x86_make_disp(vb, a->input_offset),
                             x86_make_disp(p->outbuf_EBX, a->output_offset)))
            return FALSE;
      }

      /* Next output vertex:
       */
      x64_rexw(p->func);
      x86_lea(p->func, p->outbuf_EBX,
              x86_make_disp(p->outbuf_EBX, p->translate.key.output_stride));

      /* Incr index
       */
      incr_inputs(p, index_size);
   }

   /* decr count, loop if not zero
    */
   x86_dec(p->func, p->count_EBP);
   x86_jcc(p->func, cc_NZ, label);

   /* Exit mmx state?
    */
   if (p->func->need_emms)
      mmx_emms(p->func);

   /* Land forward jump here:
    */
   x86_fixup_fwd_jump(p->func, fixup);

   /* Pop regs and return
    */
   if (x86_target(p->func) != X86_64_STD_ABI) {
      x86_pop(p->func, p->idx_ESI);
      x86_pop(p->func, p->machine_EDI);
   }

   x86_pop(p->func, p->count_EBP);
   x86_pop(p->func, p->outbuf_EBX);

   if (x86_target(p->func) == X86_64_WIN64_ABI) {
      sse2_movdqa(p->func, x86_make_reg(file_XMM, 6),
                  x86_make_disp(x86_make_reg(file_REG32, reg_SP), 8));
      sse2_movdqa(p->func, x86_make_reg(file_XMM, 7),
                  x86_make_disp(x86_make_reg(file_REG32, reg_SP), 24));
   }
   x86_ret(p->func);

   return TRUE;
}


static void
translate_sse_set_buffer(struct translate *translate,
                         unsigned buf,
                         const void *ptr, unsigned stride, unsigned max_index)
{
   struct translate_sse *p = (struct translate_sse *) translate;

   if (buf < p->nr_buffers) {
      p->buffer[buf].base_ptr = (char *) ptr;
      p->buffer[buf].stride = stride;
      p->buffer[buf].max_index = max_index;
   }

   if (0)
      debug_printf("%s %d/%d: %p %d\n",
                   __FUNCTION__, buf, p->nr_buffers, ptr, stride);
}


static void
translate_sse_release(struct translate *translate)
{
   struct translate_sse *p = (struct translate_sse *) translate;

   x86_release_func(&p->elt8_func);
   x86_release_func(&p->elt16_func);
   x86_release_func(&p->elt_func);
   x86_release_func(&p->linear_func);

   os_free_aligned(p);
}


struct translate *
translate_sse2_create(const struct translate_key *key)
{
   struct translate_sse *p = NULL;
   unsigned i;

   /* this is misnamed, it actually refers to whether rtasm is enabled or not */
   if (!rtasm_cpu_has_sse())
      goto fail;

   p = os_malloc_aligned(sizeof(struct translate_sse), 16);
   if (p == NULL)
      goto fail;

   memset(p, 0, sizeof(*p));
   memcpy(p->consts, consts, sizeof(consts));

   p->translate.key = *key;
   p->translate.release = translate_sse_release;
   p->translate.set_buffer = translate_sse_set_buffer;

   assert(key->nr_elements <= TRANSLATE_MAX_ATTRIBS);

   for (i = 0; i < key->nr_elements; i++) {
      if (key->element[i].type == TRANSLATE_ELEMENT_NORMAL) {
         unsigned j;

         p->nr_buffers =
            MAX2(p->nr_buffers, key->element[i].input_buffer + 1);

         if (key->element[i].instance_divisor) {
            p->use_instancing = TRUE;
         }

         /*
          * Map vertex element to vertex buffer variant.
          */
         for (j = 0; j < p->nr_buffer_variants; j++) {
            if (p->buffer_variant[j].buffer_index ==
                key->element[i].input_buffer
                && p->buffer_variant[j].instance_divisor ==
                key->element[i].instance_divisor) {
               break;
            }
         }
         if (j == p->nr_buffer_variants) {
            p->buffer_variant[j].buffer_index = key->element[i].input_buffer;
            p->buffer_variant[j].instance_divisor =
               key->element[i].instance_divisor;
            p->nr_buffer_variants++;
         }
         p->element_to_buffer_variant[i] = j;
      }
      else {
         assert(key->element[i].type == TRANSLATE_ELEMENT_INSTANCE_ID);

         p->element_to_buffer_variant[i] = ELEMENT_BUFFER_INSTANCE_ID;
      }
   }

   if (0)
      debug_printf("nr_buffers: %d\n", p->nr_buffers);

   if (!build_vertex_emit(p, &p->linear_func, 0))
      goto fail;

   if (!build_vertex_emit(p, &p->elt_func, 4))
      goto fail;

   if (!build_vertex_emit(p, &p->elt16_func, 2))
      goto fail;

   if (!build_vertex_emit(p, &p->elt8_func, 1))
      goto fail;

   p->translate.run = (run_func) x86_get_func(&p->linear_func);
   if (p->translate.run == NULL)
      goto fail;

   p->translate.run_elts = (run_elts_func) x86_get_func(&p->elt_func);
   if (p->translate.run_elts == NULL)
      goto fail;

   p->translate.run_elts16 = (run_elts16_func) x86_get_func(&p->elt16_func);
   if (p->translate.run_elts16 == NULL)
      goto fail;

   p->translate.run_elts8 = (run_elts8_func) x86_get_func(&p->elt8_func);
   if (p->translate.run_elts8 == NULL)
      goto fail;

   return &p->translate;

 fail:
   if (p)
      translate_sse_release(&p->translate);

   return NULL;
}


#else

struct translate *
translate_sse2_create(const struct translate_key *key)
{
   return NULL;
}

#endif
@


1.5
log
@Merge Mesa 10.2.3
tested by matthieu@@ kettenis@@ mpi@@ brett@@ and myself across a
diverse range of hardware
@
text
@@


1.4
log
@Merge Mesa 9.2.0
@
text
@d2 1
a2 1
 * Copyright 2003 Tungsten Graphics, inc.
d19 1
a19 1
 * TUNGSTEN GRAPHICS AND/OR THEIR SUPPLIERS BE LIABLE FOR ANY CLAIM,
d25 1
a25 1
 *    Keith Whitwell <keithw@@tungstengraphics.com>
d50 2
a51 1
struct translate_buffer {
d57 2
a58 1
struct translate_buffer_variant {
d61 1
a61 1
   void *ptr;                    /* updated either per vertex or per instance */
d82 7
a88 7
      {0, 0, 0, 1},
      C(1.0 / 127.0),
      C(1.0 / 255.0),
      C(1.0 / 32767.0),
      C(1.0 / 65535.0),
      C(1.0 / 2147483647.0),
      C(255.0)
d90 1
d93 2
a94 1
struct translate_sse {
d103 1
a103 1
   PIPE_ALIGN_VAR(16) float consts[NUM_CONSTS][4];
d107 1
a107 1
   struct translate_buffer buffer[PIPE_MAX_ATTRIBS];
d111 1
a111 1
   struct translate_buffer_variant buffer_variant[PIPE_MAX_ATTRIBS];
d115 1
a115 1
   unsigned element_to_buffer_variant[PIPE_MAX_ATTRIBS];
d127 1
a127 1
   struct x86_reg idx_ESI;     /* either start+i or &elt[i] */
d133 3
a135 1
static int get_offset( const void *a, const void *b )
d137 1
a137 1
   return (const char *)b - (const char *)a;
d140 3
a142 1
static struct x86_reg get_const( struct translate_sse *p, unsigned id)
d147 1
a147 1
   if(p->const_to_reg[id] >= 0)
d150 2
a151 3
   for(i = 2; i < 8; ++i)
   {
      if(p->reg_to_const[i] < 0)
d156 1
a156 1
   if(i == 8)
d161 1
a161 1
   if(p->reg_to_const[i] >= 0)
d169 2
a170 2
         x86_make_disp(p->machine_EDI,
               get_offset(p, &p->consts[id][0])));
d175 1
d177 3
a179 4
static boolean emit_load_sse2( struct translate_sse *p,
				       struct x86_reg data,
				       struct x86_reg src,
				       unsigned size)
d183 1
a183 2
   switch(size)
   {
d224 1
d228 1
d236 3
a238 5
static void emit_load_float32( struct translate_sse *p,
                                       struct x86_reg data,
                                       struct x86_reg arg0,
                                       unsigned out_chans,
                                       unsigned chans)
d240 1
a240 2
   switch(chans)
   {
d246 2
a247 2
      if(out_chans == CHANNELS_0001)
         sse_orps(p->func, data, get_const(p, CONST_IDENTITY) );
d253 5
a257 4
      if(out_chans == CHANNELS_0001)
         sse_shufps(p->func, data, get_const(p, CONST_IDENTITY), SHUF(X, Y, Z, W) );
      else if(out_chans > 2)
         sse_movlhps(p->func, data, get_const(p, CONST_IDENTITY) );
d269 4
a272 3
      if(out_chans == CHANNELS_0001)
         sse_shufps(p->func, data, get_const(p, CONST_IDENTITY), SHUF(X,Y,Z,W) );
      sse_shufps(p->func, data, data, SHUF(Y,Z,X,W) );
d284 3
a286 5
static void emit_load_float64to32( struct translate_sse *p,
                                       struct x86_reg data,
                                       struct x86_reg arg0,
                                       unsigned out_chans,
                                       unsigned chans)
d289 1
a289 2
   switch(chans)
   {
d292 1
a292 1
      if(out_chans > 1)
d296 3
a298 2
      if(out_chans == CHANNELS_0001)
         sse_shufps(p->func, data, get_const(p, CONST_IDENTITY), SHUF(X, Y, Z, W)  );
d303 6
a308 5
      if(out_chans == CHANNELS_0001)
         sse_shufps(p->func, data, get_const(p, CONST_IDENTITY), SHUF(X, Y, Z, W) );
      else if(out_chans > 2)
         sse_movlhps(p->func, data, get_const(p, CONST_IDENTITY) );
       break;
d313 1
a313 1
      if(out_chans > 3)
d318 2
a319 2
      if(out_chans == CHANNELS_0001)
         sse_orps(p->func, data, get_const(p, CONST_IDENTITY) );
d331 5
a335 1
static void emit_mov64(struct translate_sse *p, struct x86_reg dst_gpr, struct x86_reg dst_xmm, struct x86_reg src_gpr,  struct x86_reg src_xmm)
d337 1
a337 1
   if(x86_target(p->func) != X86_32)
d339 1
a339 2
   else
   {
d341 1
a341 1
      if(x86_target_caps(p->func) & X86_SSE2)
d348 4
a351 1
static void emit_load64(struct translate_sse *p, struct x86_reg dst_gpr, struct x86_reg dst_xmm, struct x86_reg src)
d356 4
a359 1
static void emit_store64(struct translate_sse *p, struct x86_reg dst, struct x86_reg src_gpr, struct x86_reg src_xmm)
d364 3
a366 1
static void emit_mov128(struct translate_sse *p, struct x86_reg dst, struct x86_reg src)
d368 1
a368 1
   if(x86_target_caps(p->func) & X86_SSE2)
d374 1
d379 3
a381 1
static void emit_memcpy(struct translate_sse *p, struct x86_reg dst, struct x86_reg src, unsigned size)
d388 2
a389 4
   if(size < 8)
   {
      switch (size)
      {
d416 1
a416 2
   else if(!(x86_target_caps(p->func) & X86_SSE))
   {
d419 1
a419 2
      for(i = 0; i < size; i += 4)
      {
d424 2
a425 4
   else
   {
      switch(size)
      {
d458 4
a461 5
static boolean translate_attr_convert( struct translate_sse *p,
                               const struct translate_element *a,
                               struct x86_reg src,
                               struct x86_reg dst)

d463 4
a466 2
   const struct util_format_description* input_desc = util_format_description(a->input_format);
   const struct util_format_description* output_desc = util_format_description(a->output_format);
d469 3
a471 1
   unsigned swizzle[4] = {UTIL_FORMAT_SWIZZLE_NONE, UTIL_FORMAT_SWIZZLE_NONE, UTIL_FORMAT_SWIZZLE_NONE, UTIL_FORMAT_SWIZZLE_NONE};
d473 1
a473 1
   unsigned imms[2] = {0, 0x3f800000};
d475 2
a476 1
   if(a->output_format == PIPE_FORMAT_NONE || a->input_format == PIPE_FORMAT_NONE)
d479 1
a479 1
   if(input_desc->channel[0].size & 7)
d482 1
a482 1
   if(input_desc->colorspace != output_desc->colorspace)
d485 4
a488 3
   for(i = 1; i < input_desc->nr_channels; ++i)
   {
      if(memcmp(&input_desc->channel[i], &input_desc->channel[0], sizeof(input_desc->channel[0])))
d492 4
a495 3
   for(i = 1; i < output_desc->nr_channels; ++i)
   {
      if(memcmp(&output_desc->channel[i], &output_desc->channel[0], sizeof(output_desc->channel[0])))
d497 1
d500 2
a501 3
   for(i = 0; i < output_desc->nr_channels; ++i)
   {
      if(output_desc->swizzle[i] < 4)
d505 5
a509 6
   if((x86_target_caps(p->func) & X86_SSE) && (0
         || a->output_format == PIPE_FORMAT_R32_FLOAT
         || a->output_format == PIPE_FORMAT_R32G32_FLOAT
         || a->output_format == PIPE_FORMAT_R32G32B32_FLOAT
         || a->output_format == PIPE_FORMAT_R32G32B32A32_FLOAT))
   {
d512 3
a514 3
      for(i = 0; i < output_desc->nr_channels; ++i)
      {
         if(swizzle[i] == UTIL_FORMAT_SWIZZLE_0 && i >= input_desc->nr_channels)
d518 2
a519 3
      for(i = 0; i < output_desc->nr_channels; ++i)
      {
         if(swizzle[i] < 4)
d521 1
a521 1
         if(swizzle[i] < UTIL_FORMAT_SWIZZLE_0 && swizzle[i] != i)
d525 2
a526 4
      if(needed_chans > 0)
      {
         switch(input_desc->channel[0].type)
         {
d528 1
a528 1
            if(!(x86_target_caps(p->func) & X86_SSE2))
d530 3
a532 1
            emit_load_sse2(p, dataXMM, src, input_desc->channel[0].size * input_desc->nr_channels >> 3);
d535 1
a535 2
            switch(input_desc->channel[0].size)
            {
d537 3
a539 1
               /* TODO: this may be inefficient due to get_identity() being used both as a float and integer register */
d546 1
a546 1
            case 32: /* we lose precision here */
d553 1
a553 2
            if(input_desc->channel[0].normalized)
            {
d555 1
a555 2
               switch(input_desc->channel[0].size)
               {
d575 3
a577 2
            else if(input_desc->channel[0].size == 32)
               sse_addps(p->func, dataXMM, dataXMM); /* compensate for the bit we threw away to fit u32 into s32 */
d580 1
a580 1
            if(!(x86_target_caps(p->func) & X86_SSE2))
d582 3
a584 1
            emit_load_sse2(p, dataXMM, src, input_desc->channel[0].size * input_desc->nr_channels >> 3);
d587 1
a587 2
            switch(input_desc->channel[0].size)
            {
d597 1
a597 1
            case 32: /* we lose precision here */
d603 1
a603 2
            if(input_desc->channel[0].normalized)
            {
d605 1
a605 2
               switch(input_desc->channel[0].size)
               {
d629 2
a630 1
            if(input_desc->channel[0].size != 32 && input_desc->channel[0].size != 64)
d632 3
a634 2
            if(swizzle[3] == UTIL_FORMAT_SWIZZLE_1 && input_desc->nr_channels <= 3)
            {
d638 1
a638 2
            switch(input_desc->channel[0].size)
            {
d640 2
a641 1
               emit_load_float32(p, dataXMM, src, needed_chans, input_desc->nr_channels);
d643 2
a644 2
            case 64: /* we lose precision here */
               if(!(x86_target_caps(p->func) & X86_SSE2))
d646 2
a647 1
               emit_load_float64to32(p, dataXMM, src, needed_chans, input_desc->nr_channels);
d657 4
a660 2
         if(!id_swizzle)
            sse_shufps(p->func, dataXMM, dataXMM, SHUF(swizzle[0], swizzle[1], swizzle[2], swizzle[3]) );
d663 5
a667 6
      if(output_desc->nr_channels >= 4
            && swizzle[0] < UTIL_FORMAT_SWIZZLE_0
            && swizzle[1] < UTIL_FORMAT_SWIZZLE_0
            && swizzle[2] < UTIL_FORMAT_SWIZZLE_0
            && swizzle[3] < UTIL_FORMAT_SWIZZLE_0
            )
d669 5
a673 5
      else
      {
         if(output_desc->nr_channels >= 2
               && swizzle[0] < UTIL_FORMAT_SWIZZLE_0
               && swizzle[1] < UTIL_FORMAT_SWIZZLE_0)
d675 3
a677 3
         else
         {
            if(swizzle[0] < UTIL_FORMAT_SWIZZLE_0)
d679 5
a683 2
            else
               x86_mov_imm(p->func, dst, imms[swizzle[0] - UTIL_FORMAT_SWIZZLE_0]);
d685 2
a686 4
            if(output_desc->nr_channels >= 2)
            {
               if(swizzle[1] < UTIL_FORMAT_SWIZZLE_0)
               {
d690 4
a693 2
               else
                  x86_mov_imm(p->func, x86_make_disp(dst, 4), imms[swizzle[1] - UTIL_FORMAT_SWIZZLE_0]);
d697 4
a700 5
         if(output_desc->nr_channels >= 3)
         {
            if(output_desc->nr_channels >= 4
                  && swizzle[2] < UTIL_FORMAT_SWIZZLE_0
                  && swizzle[3] < UTIL_FORMAT_SWIZZLE_0)
d702 3
a704 4
            else
            {
               if(swizzle[2] < UTIL_FORMAT_SWIZZLE_0)
               {
d708 4
a711 2
               else
                  x86_mov_imm(p->func, x86_make_disp(dst, 8), imms[swizzle[2] - UTIL_FORMAT_SWIZZLE_0]);
d713 2
a714 4
               if(output_desc->nr_channels >= 4)
               {
                  if(swizzle[3] < UTIL_FORMAT_SWIZZLE_0)
                  {
d718 4
a721 2
                  else
                     x86_mov_imm(p->func, x86_make_disp(dst, 12), imms[swizzle[3] - UTIL_FORMAT_SWIZZLE_0]);
d728 11
a738 8
   else if((x86_target_caps(p->func) & X86_SSE2) && input_desc->channel[0].size == 8 && output_desc->channel[0].size == 16
         && output_desc->channel[0].normalized == input_desc->channel[0].normalized
         && (0
               || (input_desc->channel[0].type == UTIL_FORMAT_TYPE_UNSIGNED && output_desc->channel[0].type == UTIL_FORMAT_TYPE_UNSIGNED)
               || (input_desc->channel[0].type == UTIL_FORMAT_TYPE_UNSIGNED && output_desc->channel[0].type == UTIL_FORMAT_TYPE_SIGNED)
               || (input_desc->channel[0].type == UTIL_FORMAT_TYPE_SIGNED && output_desc->channel[0].type == UTIL_FORMAT_TYPE_SIGNED)
               ))
   {
d742 1
a742 1
      unsigned imms[2] = {0, 1};
d744 3
a746 3
      for(i = 0; i < output_desc->nr_channels; ++i)
      {
         if(swizzle[i] == UTIL_FORMAT_SWIZZLE_0 && i >= input_desc->nr_channels)
d748 1
d751 2
a752 3
      for(i = 0; i < output_desc->nr_channels; ++i)
      {
         if(swizzle[i] < 4)
d754 1
a754 1
         if(swizzle[i] < UTIL_FORMAT_SWIZZLE_0 && swizzle[i] != i)
d758 4
a761 3
      if(needed_chans > 0)
      {
         emit_load_sse2(p, dataXMM, src, input_desc->channel[0].size * input_desc->nr_channels >> 3);
d763 1
a763 2
         switch(input_desc->channel[0].type)
         {
d765 1
a765 2
            if(input_desc->channel[0].normalized)
            {
d767 2
a768 2
               if(output_desc->channel[0].type == UTIL_FORMAT_TYPE_SIGNED)
        	       sse2_psrlw_imm(p->func, dataXMM, 1);
d774 1
a774 2
            if(input_desc->channel[0].normalized)
            {
d788 1
a788 2
            else
            {
d797 9
a805 5
         if(output_desc->channel[0].normalized)
            imms[1] = (output_desc->channel[0].type == UTIL_FORMAT_TYPE_UNSIGNED) ? 0xffff : 0x7ffff;

         if(!id_swizzle)
            sse2_pshuflw(p->func, dataXMM, dataXMM, (swizzle[0] & 3) | ((swizzle[1] & 3) << 2) | ((swizzle[2] & 3) << 4) | ((swizzle[3] & 3) << 6));
d808 5
a812 6
      if(output_desc->nr_channels >= 4
            && swizzle[0] < UTIL_FORMAT_SWIZZLE_0
            && swizzle[1] < UTIL_FORMAT_SWIZZLE_0
            && swizzle[2] < UTIL_FORMAT_SWIZZLE_0
            && swizzle[3] < UTIL_FORMAT_SWIZZLE_0
            )
d814 5
a818 5
      else
      {
         if(swizzle[0] < UTIL_FORMAT_SWIZZLE_0)
         {
            if(output_desc->nr_channels >= 2 && swizzle[1] < UTIL_FORMAT_SWIZZLE_0)
d820 2
a821 2
            else
            {
d824 3
a826 2
               if(output_desc->nr_channels >= 2)
                  x86_mov16_imm(p->func, x86_make_disp(dst, 2), imms[swizzle[1] - UTIL_FORMAT_SWIZZLE_0]);
d829 11
a839 9
         else
         {
            if(output_desc->nr_channels >= 2 && swizzle[1] >= UTIL_FORMAT_SWIZZLE_0)
               x86_mov_imm(p->func, dst, (imms[swizzle[1] - UTIL_FORMAT_SWIZZLE_0] << 16) | imms[swizzle[0] - UTIL_FORMAT_SWIZZLE_0]);
            else
            {
               x86_mov16_imm(p->func, dst, imms[swizzle[0] - UTIL_FORMAT_SWIZZLE_0]);
               if(output_desc->nr_channels >= 2)
               {
d847 4
a850 6
         if(output_desc->nr_channels >= 3)
         {
            if(swizzle[2] < UTIL_FORMAT_SWIZZLE_0)
            {
               if(output_desc->nr_channels >= 4 && swizzle[3] < UTIL_FORMAT_SWIZZLE_0)
               {
d854 1
a854 2
               else
               {
d858 3
a860 3
                  if(output_desc->nr_channels >= 4)
                  {
                     x86_mov16_imm(p->func, x86_make_disp(dst, 6), imms[swizzle[3] - UTIL_FORMAT_SWIZZLE_0]);
d864 10
a873 7
            else
            {
               if(output_desc->nr_channels >= 4 && swizzle[3] >= UTIL_FORMAT_SWIZZLE_0)
                  x86_mov_imm(p->func, x86_make_disp(dst, 4), (imms[swizzle[3] - UTIL_FORMAT_SWIZZLE_0] << 16) | imms[swizzle[2] - UTIL_FORMAT_SWIZZLE_0]);
               else
               {
                  x86_mov16_imm(p->func, x86_make_disp(dst, 4), imms[swizzle[2] - UTIL_FORMAT_SWIZZLE_0]);
d875 1
a875 2
                  if(output_desc->nr_channels >= 4)
                  {
d886 2
a887 2
   else if(!memcmp(&output_desc->channel[0], &input_desc->channel[0], sizeof(output_desc->channel[0])))
   {
d890 7
a896 6
      if(input_desc->channel[0].size == 8 && input_desc->nr_channels == 4 && output_desc->nr_channels == 4
                     && swizzle[0] == UTIL_FORMAT_SWIZZLE_W
                     && swizzle[1] == UTIL_FORMAT_SWIZZLE_Z
                     && swizzle[2] == UTIL_FORMAT_SWIZZLE_Y
                     && swizzle[3] == UTIL_FORMAT_SWIZZLE_X)
      {
d904 2
a905 4
      for(i = 0; i < output_desc->nr_channels; ++i)
      {
         switch(output_desc->channel[0].size)
         {
d907 1
a907 2
            if(swizzle[i] >= UTIL_FORMAT_SWIZZLE_0)
            {
d909 2
a910 4
               if(swizzle[i] == UTIL_FORMAT_SWIZZLE_1)
               {
                  switch(output_desc->channel[0].type)
                  {
d923 1
a923 2
            else
            {
d929 1
a929 2
            if(swizzle[i] >= UTIL_FORMAT_SWIZZLE_0)
            {
d931 2
a932 4
               if(swizzle[i] == UTIL_FORMAT_SWIZZLE_1)
               {
                  switch(output_desc->channel[1].type)
                  {
d948 1
a948 1
            else if(swizzle[i] == UTIL_FORMAT_SWIZZLE_0)
d950 2
a951 2
            else
            {
d957 1
a957 2
            if(swizzle[i] >= UTIL_FORMAT_SWIZZLE_0)
            {
d959 2
a960 4
               if(swizzle[i] == UTIL_FORMAT_SWIZZLE_1)
               {
                  switch(output_desc->channel[1].type)
                  {
d976 1
a976 2
            else
            {
d982 1
a982 2
            if(swizzle[i] >= UTIL_FORMAT_SWIZZLE_0)
            {
d985 2
a986 4
               if(swizzle[i] == UTIL_FORMAT_SWIZZLE_1)
               {
                  switch(output_desc->channel[1].type)
                  {
d1006 2
a1007 4
            else
            {
               if(x86_target_caps(p->func) & X86_SSE)
               {
d1009 2
a1010 1
                  emit_load64(p, tmp, tmpXMM, x86_make_disp(src, swizzle[i] * 8));
d1013 1
a1013 2
               else
               {
d1016 2
a1017 1
                  x86_mov(p->func, tmp, x86_make_disp(src, swizzle[i] * 8 + 4));
d1029 4
a1032 6
   else if((x86_target_caps(p->func) & X86_SSE2) &&
         a->input_format == PIPE_FORMAT_R32G32B32A32_FLOAT && (0
               || a->output_format == PIPE_FORMAT_B8G8R8A8_UNORM
               || a->output_format == PIPE_FORMAT_R8G8B8A8_UNORM
         ))
   {
d1038 3
a1040 2
      if (a->output_format == PIPE_FORMAT_B8G8R8A8_UNORM)
         sse_shufps(p->func, dataXMM, dataXMM, SHUF(2,1,0,3));
d1057 5
a1061 4
static boolean translate_attr( struct translate_sse *p,
			       const struct translate_element *a,
			       struct x86_reg src,
			       struct x86_reg dst)
d1063 1
a1063 2
   if(a->input_format == a->output_format)
   {
d1071 3
a1073 2
static boolean init_inputs( struct translate_sse *p,
                            unsigned index_size )
d1076 4
a1079 4
   struct x86_reg instance_id = x86_make_disp(p->machine_EDI,
                                              get_offset(p, &p->instance_id));
   struct x86_reg start_instance = x86_make_disp(p->machine_EDI,
                                                 get_offset(p, &p->start_instance));
d1086 8
a1093 8
         struct x86_reg buf_max_index = x86_make_disp(p->machine_EDI,
                                                     get_offset(p, &buffer->max_index));
         struct x86_reg buf_stride   = x86_make_disp(p->machine_EDI,
                                                     get_offset(p, &buffer->stride));
         struct x86_reg buf_ptr      = x86_make_disp(p->machine_EDI,
                                                     get_offset(p, &variant->ptr));
         struct x86_reg buf_base_ptr = x86_make_disp(p->machine_EDI,
                                                     get_offset(p, &buffer->base_ptr));
a1109 4
               /* instance_num = instance_id - start_instance */
               x86_mov(p->func, tmp_EDX, start_instance);
               x86_sub(p->func, tmp_EAX, tmp_EDX);

d1115 1
a1115 1
               x86_div(p->func, tmp_ECX);    /* EAX = EDX:EAX / ECX */
d1128 2
a1129 1
         } else {
d1138 3
a1140 1
         x86_imul(p->func, tmp_EAX, buf_stride);
d1149 1
a1149 2
         if (!index_size && p->nr_buffer_variants == 1)
         {
d1153 1
a1153 2
         else
         {
d1164 3
a1166 4
static struct x86_reg get_buffer_ptr( struct translate_sse *p,
                                      unsigned index_size,
                                      unsigned var_idx,
                                      struct x86_reg elt )
d1169 1
a1169 2
      return x86_make_disp(p->machine_EDI,
                           get_offset(p, &p->instance_id));
d1176 1
a1176 1
      struct x86_reg buf_ptr = 
d1179 1
a1179 1
      
d1186 3
a1188 3
      const struct translate_buffer_variant *variant = &p->buffer_variant[var_idx];

      struct x86_reg buf_stride = 
d1191 1
a1191 2

      struct x86_reg buf_base_ptr = 
d1193 1
a1193 2
                       get_offset(p, &p->buffer[variant->buffer_index].base_ptr));

d1196 1
a1196 3
                       get_offset(p, &p->buffer[variant->buffer_index].max_index));


d1200 1
a1200 2
      switch(index_size)
      {
d1217 3
a1219 1
      x86_imul(p->func, ptr, buf_stride);
d1227 2
a1228 3

static boolean incr_inputs( struct translate_sse *p, 
                            unsigned index_size )
d1231 4
a1234 2
      struct x86_reg stride = x86_make_disp(p->machine_EDI,
                                            get_offset(p, &p->buffer[0].stride));
d1251 3
a1253 2
         struct x86_reg buf_stride = x86_make_disp(p->machine_EDI,
                                                   get_offset(p, &p->buffer[variant->buffer_index].stride));
d1259 2
a1260 1
            if (i == 0) sse_prefetchnta(p->func, x86_make_disp(p->tmp_EAX, 192));
d1265 1
a1265 1
   } 
d1270 1
a1270 1
   
d1291 3
a1293 3
static boolean build_vertex_emit( struct translate_sse *p,
				  struct x86_function *func,
				  unsigned index_size )
d1301 7
a1307 7
   p->tmp_EAX       = x86_make_reg(file_REG32, reg_AX);
   p->idx_ESI       = x86_make_reg(file_REG32, reg_SI);
   p->outbuf_EBX    = x86_make_reg(file_REG32, reg_BX);
   p->machine_EDI   = x86_make_reg(file_REG32, reg_DI);
   p->count_EBP     = x86_make_reg(file_REG32, reg_BP);
   p->tmp2_EDX     = x86_make_reg(file_REG32, reg_DX);
   p->src_ECX     = x86_make_reg(file_REG32, reg_CX);
d1313 9
a1321 5
   if(x86_target(p->func) == X86_64_WIN64_ABI)
   {
	   /* the ABI guarantees a 16-byte aligned 32-byte "shadow space" above the return address */
	   sse2_movdqa(p->func, x86_make_disp(x86_make_reg(file_REG32, reg_SP), 8), x86_make_reg(file_XMM, 6));
	   sse2_movdqa(p->func, x86_make_disp(x86_make_reg(file_REG32, reg_SP), 24), x86_make_reg(file_XMM, 7));
d1327 2
a1328 3
/* on non-Win64 x86-64, these are already in the right registers */
   if(x86_target(p->func) != X86_64_STD_ABI)
   {
d1332 8
a1339 2
      x86_mov(p->func, p->machine_EDI, x86_fn_arg(p->func, 1));
      x86_mov(p->func, p->idx_ESI, x86_fn_arg(p->func, 2));
d1344 1
a1344 1
   if(x86_target(p->func) != X86_32)
d1351 2
a1352 4
   if (p->use_instancing) {      
      x86_mov(p->func,
              p->tmp2_EDX,
              x86_fn_arg(p->func, 4));
d1354 2
a1355 2
              x86_make_disp(p->machine_EDI, get_offset(p, &p->start_instance)),
              p->tmp2_EDX);
d1357 1
a1357 3
      x86_mov(p->func,
              p->tmp_EAX,
              x86_fn_arg(p->func, 5));
d1391 4
a1394 4
         
         if (!translate_attr( p, a, 
                              x86_make_disp(vb, a->input_offset), 
                              x86_make_disp(p->outbuf_EBX, a->output_offset)))
d1401 2
a1402 4
      x86_lea(p->func, 
              p->outbuf_EBX,
              x86_make_disp(p->outbuf_EBX,
                            p->translate.key.output_stride));
d1405 2
a1406 2
       */ 
      incr_inputs( p, index_size );
d1425 1
a1425 3
   
   if(x86_target(p->func) != X86_64_STD_ABI)
   {
d1433 5
a1437 4
   if(x86_target(p->func) == X86_64_WIN64_ABI)
   {
	   sse2_movdqa(p->func, x86_make_reg(file_XMM, 6), x86_make_disp(x86_make_reg(file_REG32, reg_SP), 8));
	   sse2_movdqa(p->func, x86_make_reg(file_XMM, 7), x86_make_disp(x86_make_reg(file_REG32, reg_SP), 24));
d1445 4
a1448 10




			       
static void translate_sse_set_buffer( struct translate *translate,
				unsigned buf,
				const void *ptr,
				unsigned stride,
				unsigned max_index )
d1450 1
a1450 1
   struct translate_sse *p = (struct translate_sse *)translate;
d1453 1
a1453 1
      p->buffer[buf].base_ptr = (char *)ptr;
d1458 3
a1460 4
   if (0) debug_printf("%s %d/%d: %p %d\n", 
                       __FUNCTION__, buf, 
                       p->nr_buffers, 
                       ptr, stride);
d1464 2
a1465 1
static void translate_sse_release( struct translate *translate )
d1467 1
a1467 1
   struct translate_sse *p = (struct translate_sse *)translate;
d1469 4
a1472 4
   x86_release_func( &p->elt8_func );
   x86_release_func( &p->elt16_func );
   x86_release_func( &p->elt_func );
   x86_release_func( &p->linear_func );
d1478 2
a1479 1
struct translate *translate_sse2_create( const struct translate_key *key )
d1489 1
a1489 1
   if (p == NULL) 
d1491 1
d1499 2
d1505 2
a1506 1
         p->nr_buffers = MAX2(p->nr_buffers, key->element[i].input_buffer + 1);
d1516 4
a1519 2
            if (p->buffer_variant[j].buffer_index == key->element[i].input_buffer &&
                p->buffer_variant[j].instance_divisor == key->element[i].instance_divisor) {
d1525 2
a1526 1
            p->buffer_variant[j].instance_divisor = key->element[i].instance_divisor;
d1530 2
a1531 1
      } else {
d1538 2
a1539 1
   if (0) debug_printf("nr_buffers: %d\n", p->nr_buffers);
d1573 1
a1573 1
      translate_sse_release( &p->translate );
a1578 1

d1581 2
a1582 1
struct translate *translate_sse2_create( const struct translate_key *key )
@


1.3
log
@Upate to libGL 7.11.2

Tested by jsg@@, matthieu@@ and ajacoutot@@, ok mattieu@@
@
text
@d38 1
a38 1
#if defined(PIPE_ARCH_X86) || defined(PIPE_ARCH_X86_64)
d115 1
d1065 2
d1088 2
a1089 1
            /* Our index is instance ID divided by instance divisor.
d1097 4
a1103 1

d1107 6
d1328 1
a1328 1
      x64_mov64(p->func, p->outbuf_EBX, x86_fn_arg(p->func, 5));
d1330 1
a1330 1
      x86_mov(p->func, p->outbuf_EBX, x86_fn_arg(p->func, 5));
d1334 8
a1341 1
   if (p->use_instancing) {
d1344 1
a1344 1
              x86_fn_arg(p->func, 4));
d1465 3
a1468 1
   x86_release_func( &p->elt_func );
@


1.2
log
@Merge Mesa 7.10.3
@
text
@d56 1
a56 1
struct translate_buffer_varient {
d106 3
a108 3
   /* Multiple buffer varients can map to a single buffer. */
   struct translate_buffer_varient buffer_varient[PIPE_MAX_ATTRIBS];
   unsigned nr_buffer_varients;
d110 2
a111 2
   /* Multiple elements can map to a single buffer varient. */
   unsigned element_to_buffer_varient[PIPE_MAX_ATTRIBS];
d1065 7
a1071 5
   for (i = 0; i < p->nr_buffer_varients; i++) {
      struct translate_buffer_varient *varient = &p->buffer_varient[i];
      struct translate_buffer *buffer = &p->buffer[varient->buffer_index];

      if (!index_size || varient->instance_divisor) {
d1075 1
a1075 1
                                                     get_offset(p, &varient->ptr));
d1084 1
a1084 1
         if (varient->instance_divisor) {
d1089 1
a1089 1
            if (varient->instance_divisor != 1) {
d1098 1
a1098 1
               x86_mov_reg_imm(p->func, tmp_ECX, varient->instance_divisor);
d1101 5
d1108 5
a1114 4
         /*
          * TODO: Respect translate_buffer::max_index.
          */

d1119 1
d1124 1
a1124 1
         if (!index_size && p->nr_buffer_varients == 1)
d1150 1
a1150 1
   if (!index_size && p->nr_buffer_varients == 1) {
d1153 1
a1153 1
   else if (!index_size || p->buffer_varient[var_idx].instance_divisor) {
d1157 1
a1157 1
                       get_offset(p, &p->buffer_varient[var_idx].ptr));
d1165 1
a1165 1
      const struct translate_buffer_varient *varient = &p->buffer_varient[var_idx];
d1169 1
a1169 1
                       get_offset(p, &p->buffer[varient->buffer_index].stride));
d1173 5
a1177 1
                       get_offset(p, &p->buffer[varient->buffer_index].base_ptr));
d1195 6
d1213 1
a1213 1
   if (!index_size && p->nr_buffer_varients == 1) {
d1217 1
a1217 1
      if (p->buffer_varient[0].instance_divisor == 0) {
d1228 2
a1229 2
      for (i = 0; i < p->nr_buffer_varients; i++) {
         struct translate_buffer_varient *varient = &p->buffer_varient[i];
d1231 1
a1231 1
                                                get_offset(p, &varient->ptr));
d1233 1
a1233 1
                                                   get_offset(p, &p->buffer[varient->buffer_index].stride));
d1235 1
a1235 1
         if (varient->instance_divisor == 0) {
d1345 1
a1345 1
      int last_varient = -1;
d1350 1
a1350 1
         unsigned varient = p->element_to_buffer_varient[j];
d1354 3
a1356 3
         if (varient != last_varient) {
            last_varient = varient;
            vb = get_buffer_ptr(p, index_size, varient, elt);
d1482 1
a1482 1
          * Map vertex element to vertex buffer varient.
d1484 3
a1486 3
         for (j = 0; j < p->nr_buffer_varients; j++) {
            if (p->buffer_varient[j].buffer_index == key->element[i].input_buffer &&
                p->buffer_varient[j].instance_divisor == key->element[i].instance_divisor) {
d1490 4
a1493 4
         if (j == p->nr_buffer_varients) {
            p->buffer_varient[j].buffer_index = key->element[i].input_buffer;
            p->buffer_varient[j].instance_divisor = key->element[i].instance_divisor;
            p->nr_buffer_varients++;
d1495 1
a1495 1
         p->element_to_buffer_varient[i] = j;
d1499 1
a1499 1
         p->element_to_buffer_varient[i] = ELEMENT_BUFFER_INSTANCE_ID;
@


1.1
log
@Update to Mesa 7.8.1. Tested on a bulk ports build by naddy@@, ok oga@@.
@
text
@d33 1
d38 1
a38 1
#if defined(PIPE_ARCH_X86)
a49 12
typedef void (PIPE_CDECL *run_func)( struct translate *translate,
                                     unsigned start,
                                     unsigned count,
                                     unsigned instance_id,
                                     void *output_buffer);

typedef void (PIPE_CDECL *run_elts_func)( struct translate *translate,
                                          const unsigned *elts,
                                          unsigned count,
                                          unsigned instance_id,
                                          void *output_buffer);

d52 2
a53 1
   unsigned stride;
d65 24
d95 2
d99 3
a101 7
   boolean loaded_identity;
   boolean loaded_255;
   boolean loaded_inv_255;

   float identity[4];
   float float_255[4];
   float inv_255[4];
a115 3
   run_func      gen_run;
   run_elts_func gen_run_elts;

d120 6
a125 4
   struct x86_reg idx_EBX;     /* either start+i or &elt[i] */
   struct x86_reg outbuf_ECX;
   struct x86_reg machine_EDX;
   struct x86_reg count_ESI;    /* decrements to zero */
d133 4
d138 2
d141 5
a145 3
static struct x86_reg get_identity( struct translate_sse *p )
{
   struct x86_reg reg = x86_make_reg(file_XMM, 6);
d147 16
a162 11
   if (!p->loaded_identity) {
      p->loaded_identity = TRUE;
      p->identity[0] = 0;
      p->identity[1] = 0;
      p->identity[2] = 0;
      p->identity[3] = 1;

      sse_movups(p->func, reg, 
		 x86_make_disp(p->machine_EDX, 
			       get_offset(p, &p->identity[0])));
   }
d167 5
a171 1
static struct x86_reg get_255( struct translate_sse *p )
d173 46
a218 1
   struct x86_reg reg = x86_make_reg(file_XMM, 7);
d220 50
a269 10
   if (!p->loaded_255) {
      p->loaded_255 = TRUE;
      p->float_255[0] =
	 p->float_255[1] =
	 p->float_255[2] =
	 p->float_255[3] = 255.0f;

      sse_movups(p->func, reg, 
		 x86_make_disp(p->machine_EDX, 
			       get_offset(p, &p->float_255[0])));
d271 1
d273 49
a321 1
   return reg;
d324 1
a324 1
static struct x86_reg get_inv_255( struct translate_sse *p )
d326 9
a334 12
   struct x86_reg reg = x86_make_reg(file_XMM, 5);

   if (!p->loaded_inv_255) {
      p->loaded_inv_255 = TRUE;
      p->inv_255[0] =
	 p->inv_255[1] =
	 p->inv_255[2] =
	 p->inv_255[3] = 1.0f / 255.0f;

      sse_movups(p->func, reg, 
		 x86_make_disp(p->machine_EDX, 
			       get_offset(p, &p->inv_255[0])));
d336 1
d338 3
a340 1
   return reg;
d343 4
d348 6
a353 22
static void emit_load_R32G32B32A32( struct translate_sse *p, 			   
				    struct x86_reg data,
				    struct x86_reg arg0 )
{
   sse_movups(p->func, data, arg0);
}

static void emit_load_R32G32B32( struct translate_sse *p, 			   
				 struct x86_reg data,
				 struct x86_reg arg0 )
{
   /* Have to jump through some hoops:
    *
    * c 0 0 0
    * c 0 0 1
    * 0 0 c 1
    * a b c 1
    */
   sse_movss(p->func, data, x86_make_disp(arg0, 8));
   sse_shufps(p->func, data, get_identity(p), SHUF(X,Y,Z,W) );
   sse_shufps(p->func, data, data, SHUF(Y,Z,X,W) );
   sse_movlps(p->func, data, arg0);
d356 5
a360 3
static void emit_load_R32G32( struct translate_sse *p, 
			   struct x86_reg data,
			   struct x86_reg arg0 )
d362 79
a440 5
   /* 0 0 0 1
    * a b 0 1
    */
   sse_movups(p->func, data, get_identity(p) );
   sse_movlps(p->func, data, arg0);
d443 4
a447 3
static void emit_load_R32( struct translate_sse *p, 
			   struct x86_reg data,
			   struct x86_reg arg0 )
d449 16
a464 6
   /* a 0 0 0
    * a 0 0 1
    */
   sse_movss(p->func, data, arg0);
   sse_orps(p->func, data, get_identity(p) );
}
d466 5
d472 11
a482 4
static void emit_load_R8G8B8A8_UNORM( struct translate_sse *p,
				       struct x86_reg data,
				       struct x86_reg src )
{
d484 7
a490 5
   /* Load and unpack twice:
    */
   sse_movss(p->func, data, src);
   sse2_punpcklbw(p->func, data, get_identity(p));
   sse2_punpcklbw(p->func, data, get_identity(p));
d492 5
a496 3
   /* Convert to float:
    */
   sse2_cvtdq2ps(p->func, data, data);
d498 7
d506 102
a607 4
   /* Scale by 1/255.0
    */
   sse_mulps(p->func, data, get_inv_255(p));
}
d609 26
d636 3
d640 31
d672 49
a720 6
static void emit_store_R32G32B32A32( struct translate_sse *p, 			   
				     struct x86_reg dest,
				     struct x86_reg dataXMM )
{
   sse_movups(p->func, dest, dataXMM);
}
d722 7
a728 10
static void emit_store_R32G32B32( struct translate_sse *p, 
				  struct x86_reg dest,
				  struct x86_reg dataXMM )
{
   /* Emit two, shuffle, emit one.
    */
   sse_movlps(p->func, dest, dataXMM);
   sse_shufps(p->func, dataXMM, dataXMM, SHUF(Z,Z,Z,Z) ); /* NOTE! destructive */
   sse_movss(p->func, x86_make_disp(dest,8), dataXMM);
}
d730 41
a770 6
static void emit_store_R32G32( struct translate_sse *p, 
			       struct x86_reg dest,
			       struct x86_reg dataXMM )
{
   sse_movlps(p->func, dest, dataXMM);
}
d772 2
a773 6
static void emit_store_R32( struct translate_sse *p, 
			    struct x86_reg dest,
			    struct x86_reg dataXMM )
{
   sse_movss(p->func, dest, dataXMM);
}
d775 3
d779 36
d816 206
a1021 7
static void emit_store_R8G8B8A8_UNORM( struct translate_sse *p,
				       struct x86_reg dest,
				       struct x86_reg dataXMM )
{
   /* Scale by 255.0
    */
   sse_mulps(p->func, dataXMM, get_255(p));
d1023 2
a1024 7
   /* Pack and emit:
    */
   sse2_cvtps2dq(p->func, dataXMM, dataXMM);
   sse2_packssdw(p->func, dataXMM, dataXMM);
   sse2_packuswb(p->func, dataXMM, dataXMM);
   sse_movss(p->func, dest, dataXMM);
}
d1026 2
d1029 2
d1032 5
d1038 2
d1041 1
a1041 8
/* Extended swizzles?  Maybe later.
 */  
static void emit_swizzle( struct translate_sse *p,
			  struct x86_reg dest,
			  struct x86_reg src,
			  unsigned char shuffle )
{
   sse_shufps(p->func, dest, src, shuffle);
a1043 1

d1046 2
a1047 2
			       struct x86_reg srcECX,
			       struct x86_reg dstEAX)
d1049 4
a1052 24
   struct x86_reg dataXMM = x86_make_reg(file_XMM, 0);

   switch (a->input_format) {
   case PIPE_FORMAT_R32_FLOAT:
      emit_load_R32(p, dataXMM, srcECX);
      break;
   case PIPE_FORMAT_R32G32_FLOAT:
      emit_load_R32G32(p, dataXMM, srcECX);
      break;
   case PIPE_FORMAT_R32G32B32_FLOAT:
      emit_load_R32G32B32(p, dataXMM, srcECX);
      break;
   case PIPE_FORMAT_R32G32B32A32_FLOAT:
      emit_load_R32G32B32A32(p, dataXMM, srcECX);
      break;
   case PIPE_FORMAT_A8R8G8B8_UNORM:
      emit_load_R8G8B8A8_UNORM(p, dataXMM, srcECX);
      emit_swizzle(p, dataXMM, dataXMM, SHUF(Z,Y,X,W));
      break;
   case PIPE_FORMAT_R8G8B8A8_UNORM:
      emit_load_R8G8B8A8_UNORM(p, dataXMM, srcECX);
      break;
   default:
      return FALSE;
d1055 1
a1055 25
   switch (a->output_format) {
   case PIPE_FORMAT_R32_FLOAT:
      emit_store_R32(p, dstEAX, dataXMM);
      break;
   case PIPE_FORMAT_R32G32_FLOAT:
      emit_store_R32G32(p, dstEAX, dataXMM);
      break;
   case PIPE_FORMAT_R32G32B32_FLOAT:
      emit_store_R32G32B32(p, dstEAX, dataXMM);
      break;
   case PIPE_FORMAT_R32G32B32A32_FLOAT:
      emit_store_R32G32B32A32(p, dstEAX, dataXMM);
      break;
   case PIPE_FORMAT_A8R8G8B8_UNORM:
      emit_swizzle(p, dataXMM, dataXMM, SHUF(Z,Y,X,W));
      emit_store_R8G8B8A8_UNORM(p, dstEAX, dataXMM);
      break;
   case PIPE_FORMAT_R8G8B8A8_UNORM:
      emit_store_R8G8B8A8_UNORM(p, dstEAX, dataXMM);
      break;
   default:
      return FALSE;
   }

   return TRUE;
a1057 1

d1059 1
a1059 1
                            boolean linear )
d1062 1
a1062 1
   struct x86_reg instance_id = x86_make_disp(p->machine_EDX,
d1069 2
a1070 2
      if (linear || varient->instance_divisor) {
         struct x86_reg buf_stride   = x86_make_disp(p->machine_EDX,
d1072 1
a1072 1
         struct x86_reg buf_ptr      = x86_make_disp(p->machine_EDX,
d1074 1
a1074 1
         struct x86_reg buf_base_ptr = x86_make_disp(p->machine_EDX,
d1076 1
a1076 1
         struct x86_reg elt = p->idx_EBX;
d1088 2
a1089 2
               struct x86_reg tmp_EDX = p->machine_EDX;
               struct x86_reg tmp_ECX = p->outbuf_ECX;
a1094 2
               x86_push(p->func, tmp_EDX);
               x86_push(p->func, tmp_ECX);
a1097 2
               x86_pop(p->func, tmp_ECX);
               x86_pop(p->func, tmp_EDX);
d1102 5
d1108 1
d1115 3
a1117 1
         if (linear && p->nr_buffer_varients == 1)
d1119 1
d1121 2
d1124 1
d1133 1
a1133 1
                                      boolean linear,
d1138 1
a1138 1
      return x86_make_disp(p->machine_EDX,
d1141 2
a1142 2
   if (linear && p->nr_buffer_varients == 1) {
      return p->idx_EBX;
d1144 2
a1145 2
   else if (linear || p->buffer_varient[var_idx].instance_divisor) {
      struct x86_reg ptr = p->tmp_EAX;
d1147 1
a1147 1
         x86_make_disp(p->machine_EDX, 
d1150 1
d1155 1
a1155 1
      struct x86_reg ptr = p->tmp_EAX;
d1159 1
a1159 1
         x86_make_disp(p->machine_EDX, 
d1163 1
a1163 1
         x86_make_disp(p->machine_EDX, 
d1170 14
a1183 2
      x86_mov(p->func, ptr, buf_stride);
      x86_imul(p->func, ptr, elt);
d1192 1
a1192 1
                            boolean linear )
d1194 2
a1195 2
   if (linear && p->nr_buffer_varients == 1) {
      struct x86_reg stride = x86_make_disp(p->machine_EDX,
d1199 3
a1201 2
         x86_add(p->func, p->idx_EBX, stride);
         sse_prefetchnta(p->func, x86_make_disp(p->idx_EBX, 192));
d1204 1
a1204 1
   else if (linear) {
d1211 1
a1211 1
         struct x86_reg buf_ptr = x86_make_disp(p->machine_EDX,
d1213 1
a1213 1
         struct x86_reg buf_stride = x86_make_disp(p->machine_EDX,
d1217 3
a1219 2
            x86_mov(p->func, p->tmp_EAX, buf_ptr);
            x86_add(p->func, p->tmp_EAX, buf_stride);
d1221 1
d1227 2
a1228 1
      x86_lea(p->func, p->idx_EBX, x86_make_disp(p->idx_EBX, 4));
d1253 1
a1253 1
				  boolean linear )
d1258 3
d1262 6
a1267 4
   p->idx_EBX       = x86_make_reg(file_REG32, reg_BX);
   p->outbuf_ECX    = x86_make_reg(file_REG32, reg_CX);
   p->machine_EDX   = x86_make_reg(file_REG32, reg_DX);
   p->count_ESI     = x86_make_reg(file_REG32, reg_SI);
a1269 3
   p->loaded_inv_255 = FALSE;
   p->loaded_255 = FALSE;
   p->loaded_identity = FALSE;
d1273 21
a1293 4
   /* Push a few regs?
    */
   x86_push(p->func, p->idx_EBX);
   x86_push(p->func, p->count_ESI);
d1295 4
a1298 6
   /* Load arguments into regs:
    */
   x86_mov(p->func, p->machine_EDX, x86_fn_arg(p->func, 1));
   x86_mov(p->func, p->idx_EBX, x86_fn_arg(p->func, 2));
   x86_mov(p->func, p->count_ESI, x86_fn_arg(p->func, 3));
   x86_mov(p->func, p->outbuf_ECX, x86_fn_arg(p->func, 5));
d1307 1
a1307 1
              x86_make_disp(p->machine_EDX, get_offset(p, &p->instance_id)),
d1314 1
a1314 1
   x86_cmp(p->func, p->count_ESI, p->tmp_EAX);
d1319 1
a1319 1
   init_inputs(p, linear);
d1325 1
a1325 1
      struct x86_reg elt = linear ? p->idx_EBX : x86_deref(p->idx_EBX);
d1337 1
a1337 1
            vb = get_buffer_ptr(p, linear, varient, elt);
d1342 1
a1342 1
                              x86_make_disp(p->outbuf_ECX, a->output_offset)))
d1348 1
d1350 2
a1351 2
              p->outbuf_ECX, 
              x86_make_disp(p->outbuf_ECX, 
d1356 1
a1356 1
      incr_inputs( p, linear );
d1361 1
a1361 1
   x86_dec(p->func, p->count_ESI);
d1376 14
a1389 2
   x86_pop(p->func, p->count_ESI);
   x86_pop(p->func, p->idx_EBX);
d1404 2
a1405 1
				unsigned stride )
d1412 1
d1429 1
a1429 31
   FREE(p);
}

static void PIPE_CDECL translate_sse_run_elts( struct translate *translate,
			      const unsigned *elts,
			      unsigned count,
                              unsigned instance_id,
			      void *output_buffer )
{
   struct translate_sse *p = (struct translate_sse *)translate;

   p->gen_run_elts( translate,
		    elts,
		    count,
                    instance_id,
                    output_buffer);
}

static void PIPE_CDECL translate_sse_run( struct translate *translate,
			 unsigned start,
			 unsigned count,
                         unsigned instance_id,
			 void *output_buffer )
{
   struct translate_sse *p = (struct translate_sse *)translate;

   p->gen_run( translate,
	       start,
	       count,
               instance_id,
               output_buffer);
d1438 2
a1439 1
   if (!rtasm_cpu_has_sse() || !rtasm_cpu_has_sse2())
d1442 1
a1442 1
   p = CALLOC_STRUCT( translate_sse );
d1445 2
a1450 2
   p->translate.run_elts = translate_sse_run_elts;
   p->translate.run = translate_sse_run;
d1486 14
a1499 1
   if (!build_vertex_emit(p, &p->linear_func, TRUE))
d1502 2
a1503 1
   if (!build_vertex_emit(p, &p->elt_func, FALSE))
d1506 2
a1507 2
   p->gen_run = (run_func)x86_get_func(&p->linear_func);
   if (p->gen_run == NULL)
d1510 2
a1511 2
   p->gen_run_elts = (run_elts_func)x86_get_func(&p->elt_func);
   if (p->gen_run_elts == NULL)
@


1.1.1.1
log
@Import Mesa 7.10.3
@
text
@a32 1
#include "util/u_format.h"
d37 1
a37 1
#if defined(PIPE_ARCH_X86) || defined(PIPE_ARCH_X86_64)
d49 12
d63 1
a63 2
   uintptr_t stride;
   unsigned max_index;
a74 24
#define NUM_CONSTS 7

enum
{
   CONST_IDENTITY,
   CONST_INV_127,
   CONST_INV_255,
   CONST_INV_32767,
   CONST_INV_65535,
   CONST_INV_2147483647,
   CONST_255
};

#define C(v) {(float)(v), (float)(v), (float)(v), (float)(v)}
static float consts[NUM_CONSTS][4] = {
      {0, 0, 0, 1},
      C(1.0 / 127.0),
      C(1.0 / 255.0),
      C(1.0 / 32767.0),
      C(1.0 / 65535.0),
      C(1.0 / 2147483647.0),
      C(255.0)
};
#undef C
a80 2
   struct x86_function elt16_func;
   struct x86_function elt8_func;
d83 7
a89 3
   PIPE_ALIGN_VAR(16) float consts[NUM_CONSTS][4];
   int8_t reg_to_const[16];
   int8_t const_to_reg[NUM_CONSTS];
d104 3
d111 4
a114 6
   struct x86_reg tmp2_EDX;
   struct x86_reg src_ECX;
   struct x86_reg idx_ESI;     /* either start+i or &elt[i] */
   struct x86_reg machine_EDI;
   struct x86_reg outbuf_EBX;
   struct x86_reg count_EBP;    /* decrements to zero */
d122 3
a124 1
static struct x86_reg get_const( struct translate_sse *p, unsigned id)
d126 1
a126 2
   struct x86_reg reg;
   unsigned i;
d128 10
a137 7
   if(p->const_to_reg[id] >= 0)
      return x86_make_reg(file_XMM, p->const_to_reg[id]);

   for(i = 2; i < 8; ++i)
   {
      if(p->reg_to_const[i] < 0)
         break;
a139 17
   /* TODO: be smarter here */
   if(i == 8)
      --i;

   reg = x86_make_reg(file_XMM, i);

   if(p->reg_to_const[i] >= 0)
      p->const_to_reg[p->reg_to_const[i]] = -1;

   p->reg_to_const[i] = id;
   p->const_to_reg[id] = i;

   /* TODO: this should happen outside the loop, if possible */
   sse_movaps(p->func, reg,
         x86_make_disp(p->machine_EDI,
               get_offset(p, &p->consts[id][0])));

d143 1
a143 5
/* load the data in a SSE2 register, padding with zeros */
static boolean emit_load_sse2( struct translate_sse *p,
				       struct x86_reg data,
				       struct x86_reg src,
				       unsigned size)
d145 12
a156 40
   struct x86_reg tmpXMM = x86_make_reg(file_XMM, 1);
   struct x86_reg tmp = p->tmp_EAX;
   switch(size)
   {
   case 1:
      x86_movzx8(p->func, tmp, src);
      sse2_movd(p->func, data, tmp);
      break;
   case 2:
      x86_movzx16(p->func, tmp, src);
      sse2_movd(p->func, data, tmp);
      break;
   case 3:
      x86_movzx8(p->func, tmp, x86_make_disp(src, 2));
      x86_shl_imm(p->func, tmp, 16);
      x86_mov16(p->func, tmp, src);
      sse2_movd(p->func, data, tmp);
      break;
   case 4:
      sse2_movd(p->func, data, src);
      break;
   case 6:
      sse2_movd(p->func, data, src);
      x86_movzx16(p->func, tmp, x86_make_disp(src, 4));
      sse2_movd(p->func, tmpXMM, tmp);
      sse2_punpckldq(p->func, data, tmpXMM);
      break;
   case 8:
      sse2_movq(p->func, data, src);
      break;
   case 12:
      sse2_movq(p->func, data, src);
      sse2_movd(p->func, tmpXMM, x86_make_disp(src, 8));
      sse2_punpcklqdq(p->func, data, tmpXMM);
      break;
   case 16:
      sse2_movdqu(p->func, data, src);
      break;
   default:
      return FALSE;
d158 2
a159 1
   return TRUE;
d162 3
a164 2
/* this value can be passed for the out_chans argument */
#define CHANNELS_0001 5
d166 10
a175 50
/* this function will load #chans float values, and will
 * pad the register with zeroes at least up to out_chans.
 *
 * If out_chans is set to CHANNELS_0001, then the fourth
 * value will be padded with 1. Only pass this value if
 * chans < 4 or results are undefined.
 */
static void emit_load_float32( struct translate_sse *p,
                                       struct x86_reg data,
                                       struct x86_reg arg0,
                                       unsigned out_chans,
                                       unsigned chans)
{
   switch(chans)
   {
   case 1:
      /* a 0 0 0
       * a 0 0 1
       */
      sse_movss(p->func, data, arg0);
      if(out_chans == CHANNELS_0001)
         sse_orps(p->func, data, get_const(p, CONST_IDENTITY) );
      break;
   case 2:
      /* 0 0 0 1
       * a b 0 1
       */
      if(out_chans == CHANNELS_0001)
         sse_shufps(p->func, data, get_const(p, CONST_IDENTITY), SHUF(X, Y, Z, W) );
      else if(out_chans > 2)
         sse_movlhps(p->func, data, get_const(p, CONST_IDENTITY) );
      sse_movlps(p->func, data, arg0);
      break;
   case 3:
      /* Have to jump through some hoops:
       *
       * c 0 0 0
       * c 0 0 1 if out_chans == CHANNELS_0001
       * 0 0 c 0/1
       * a b c 0/1
       */
      sse_movss(p->func, data, x86_make_disp(arg0, 8));
      if(out_chans == CHANNELS_0001)
         sse_shufps(p->func, data, get_const(p, CONST_IDENTITY), SHUF(X,Y,Z,W) );
      sse_shufps(p->func, data, data, SHUF(Y,Z,X,W) );
      sse_movlps(p->func, data, arg0);
      break;
   case 4:
      sse_movups(p->func, data, arg0);
      break;
a176 1
}
d178 1
a178 49
/* this function behaves like emit_load_float32, but loads
   64-bit floating point numbers, converting them to 32-bit
  ones */
static void emit_load_float64to32( struct translate_sse *p,
                                       struct x86_reg data,
                                       struct x86_reg arg0,
                                       unsigned out_chans,
                                       unsigned chans)
{
   struct x86_reg tmpXMM = x86_make_reg(file_XMM, 1);
   switch(chans)
   {
   case 1:
      sse2_movsd(p->func, data, arg0);
      if(out_chans > 1)
         sse2_cvtpd2ps(p->func, data, data);
      else
         sse2_cvtsd2ss(p->func, data, data);
      if(out_chans == CHANNELS_0001)
         sse_shufps(p->func, data, get_const(p, CONST_IDENTITY), SHUF(X, Y, Z, W)  );
      break;
   case 2:
      sse2_movupd(p->func, data, arg0);
      sse2_cvtpd2ps(p->func, data, data);
      if(out_chans == CHANNELS_0001)
         sse_shufps(p->func, data, get_const(p, CONST_IDENTITY), SHUF(X, Y, Z, W) );
      else if(out_chans > 2)
         sse_movlhps(p->func, data, get_const(p, CONST_IDENTITY) );
       break;
   case 3:
      sse2_movupd(p->func, data, arg0);
      sse2_cvtpd2ps(p->func, data, data);
      sse2_movsd(p->func, tmpXMM, x86_make_disp(arg0, 16));
      if(out_chans > 3)
         sse2_cvtpd2ps(p->func, tmpXMM, tmpXMM);
      else
         sse2_cvtsd2ss(p->func, tmpXMM, tmpXMM);
      sse_movlhps(p->func, data, tmpXMM);
      if(out_chans == CHANNELS_0001)
         sse_orps(p->func, data, get_const(p, CONST_IDENTITY) );
      break;
   case 4:
      sse2_movupd(p->func, data, arg0);
      sse2_cvtpd2ps(p->func, data, data);
      sse2_movupd(p->func, tmpXMM, x86_make_disp(arg0, 16));
      sse2_cvtpd2ps(p->func, tmpXMM, tmpXMM);
      sse_movlhps(p->func, data, tmpXMM);
      break;
   }
a180 13
static void emit_mov64(struct translate_sse *p, struct x86_reg dst_gpr, struct x86_reg dst_xmm, struct x86_reg src_gpr,  struct x86_reg src_xmm)
{
   if(x86_target(p->func) != X86_32)
      x64_mov64(p->func, dst_gpr, src_gpr);
   else
   {
      /* TODO: when/on which CPUs is SSE2 actually better than SSE? */
      if(x86_target_caps(p->func) & X86_SSE2)
         sse2_movq(p->func, dst_xmm, src_xmm);
      else
         sse_movlps(p->func, dst_xmm, src_xmm);
   }
}
d182 22
a203 3
static void emit_load64(struct translate_sse *p, struct x86_reg dst_gpr, struct x86_reg dst_xmm, struct x86_reg src)
{
   emit_mov64(p, dst_gpr, dst_xmm, src, src);
d206 3
a208 1
static void emit_store64(struct translate_sse *p, struct x86_reg dst, struct x86_reg src_gpr, struct x86_reg src_xmm)
d210 5
a214 1
   emit_mov64(p, dst, dst, src_gpr, src_xmm);
a216 7
static void emit_mov128(struct translate_sse *p, struct x86_reg dst, struct x86_reg src)
{
   if(x86_target_caps(p->func) & X86_SSE2)
      sse2_movdqu(p->func, dst, src);
   else
      sse_movups(p->func, dst, src);
}
d218 3
a220 5
/* TODO: this uses unaligned accesses liberally, which is great on Nehalem,
 * but may or may not be good on older processors
 * TODO: may perhaps want to use non-temporal stores here if possible
 */
static void emit_memcpy(struct translate_sse *p, struct x86_reg dst, struct x86_reg src, unsigned size)
d222 5
a226 79
   struct x86_reg dataXMM = x86_make_reg(file_XMM, 0);
   struct x86_reg dataXMM2 = x86_make_reg(file_XMM, 1);
   struct x86_reg dataGPR = p->tmp_EAX;
   struct x86_reg dataGPR2 = p->tmp2_EDX;

   if(size < 8)
   {
      switch (size)
      {
      case 1:
         x86_mov8(p->func, dataGPR, src);
         x86_mov8(p->func, dst, dataGPR);
         break;
      case 2:
         x86_mov16(p->func, dataGPR, src);
         x86_mov16(p->func, dst, dataGPR);
         break;
      case 3:
         x86_mov16(p->func, dataGPR, src);
         x86_mov8(p->func, dataGPR2, x86_make_disp(src, 2));
         x86_mov16(p->func, dst, dataGPR);
         x86_mov8(p->func, x86_make_disp(dst, 2), dataGPR2);
         break;
      case 4:
         x86_mov(p->func, dataGPR, src);
         x86_mov(p->func, dst, dataGPR);
         break;
      case 6:
         x86_mov(p->func, dataGPR, src);
         x86_mov16(p->func, dataGPR2, x86_make_disp(src, 4));
         x86_mov(p->func, dst, dataGPR);
         x86_mov16(p->func, x86_make_disp(dst, 4), dataGPR2);
         break;
      }
   }
   else if(!(x86_target_caps(p->func) & X86_SSE))
   {
      unsigned i = 0;
      assert((size & 3) == 0);
      for(i = 0; i < size; i += 4)
      {
         x86_mov(p->func, dataGPR, x86_make_disp(src, i));
         x86_mov(p->func, x86_make_disp(dst, i), dataGPR);
      }
   }
   else
   {
      switch(size)
      {
      case 8:
         emit_load64(p, dataGPR, dataXMM, src);
         emit_store64(p, dst, dataGPR, dataXMM);
         break;
      case 12:
         emit_load64(p, dataGPR2, dataXMM, src);
         x86_mov(p->func, dataGPR, x86_make_disp(src, 8));
         emit_store64(p, dst, dataGPR2, dataXMM);
         x86_mov(p->func, x86_make_disp(dst, 8), dataGPR);
         break;
      case 16:
         emit_mov128(p, dataXMM, src);
         emit_mov128(p, dst, dataXMM);
         break;
      case 24:
         emit_mov128(p, dataXMM, src);
         emit_load64(p, dataGPR, dataXMM2, x86_make_disp(src, 16));
         emit_mov128(p, dst, dataXMM);
         emit_store64(p, x86_make_disp(dst, 16), dataGPR, dataXMM2);
         break;
      case 32:
         emit_mov128(p, dataXMM, src);
         emit_mov128(p, dataXMM2, x86_make_disp(src, 16));
         emit_mov128(p, dst, dataXMM);
         emit_mov128(p, x86_make_disp(dst, 16), dataXMM2);
         break;
      default:
         assert(0);
      }
   }
a228 4
static boolean translate_attr_convert( struct translate_sse *p,
                               const struct translate_element *a,
                               struct x86_reg src,
                               struct x86_reg dst)
d230 3
a233 7
   const struct util_format_description* input_desc = util_format_description(a->input_format);
   const struct util_format_description* output_desc = util_format_description(a->output_format);
   unsigned i;
   boolean id_swizzle = TRUE;
   unsigned swizzle[4] = {UTIL_FORMAT_SWIZZLE_NONE, UTIL_FORMAT_SWIZZLE_NONE, UTIL_FORMAT_SWIZZLE_NONE, UTIL_FORMAT_SWIZZLE_NONE};
   unsigned needed_chans = 0;
   unsigned imms[2] = {0, 0x3f800000};
d235 5
a239 2
   if(a->output_format == PIPE_FORMAT_NONE || a->input_format == PIPE_FORMAT_NONE)
      return FALSE;
d241 3
a243 2
   if(input_desc->channel[0].size & 7)
      return FALSE;
a244 2
   if(input_desc->colorspace != output_desc->colorspace)
      return FALSE;
d246 4
a249 5
   for(i = 1; i < input_desc->nr_channels; ++i)
   {
      if(memcmp(&input_desc->channel[i], &input_desc->channel[0], sizeof(input_desc->channel[0])))
         return FALSE;
   }
a250 5
   for(i = 1; i < output_desc->nr_channels; ++i)
   {
      if(memcmp(&output_desc->channel[i], &output_desc->channel[0], sizeof(output_desc->channel[0])))
         return FALSE;
   }
a251 5
   for(i = 0; i < output_desc->nr_channels; ++i)
   {
      if(output_desc->swizzle[i] < 4)
         swizzle[output_desc->swizzle[i]] = input_desc->swizzle[i];
   }
a252 7
   if((x86_target_caps(p->func) & X86_SSE) && (0
         || a->output_format == PIPE_FORMAT_R32_FLOAT
         || a->output_format == PIPE_FORMAT_R32G32_FLOAT
         || a->output_format == PIPE_FORMAT_R32G32B32_FLOAT
         || a->output_format == PIPE_FORMAT_R32G32B32A32_FLOAT))
   {
      struct x86_reg dataXMM = x86_make_reg(file_XMM, 0);
d254 6
a259 5
      for(i = 0; i < output_desc->nr_channels; ++i)
      {
         if(swizzle[i] == UTIL_FORMAT_SWIZZLE_0 && i >= input_desc->nr_channels)
            swizzle[i] = i;
      }
d261 10
a270 7
      for(i = 0; i < output_desc->nr_channels; ++i)
      {
         if(swizzle[i] < 4)
            needed_chans = MAX2(needed_chans, swizzle[i] + 1);
         if(swizzle[i] < UTIL_FORMAT_SWIZZLE_0 && swizzle[i] != i)
            id_swizzle = FALSE;
      }
d272 6
a277 102
      if(needed_chans > 0)
      {
         switch(input_desc->channel[0].type)
         {
         case UTIL_FORMAT_TYPE_UNSIGNED:
            if(!(x86_target_caps(p->func) & X86_SSE2))
               return FALSE;
            emit_load_sse2(p, dataXMM, src, input_desc->channel[0].size * input_desc->nr_channels >> 3);

            /* TODO: add support for SSE4.1 pmovzx */
            switch(input_desc->channel[0].size)
            {
            case 8:
               /* TODO: this may be inefficient due to get_identity() being used both as a float and integer register */
               sse2_punpcklbw(p->func, dataXMM, get_const(p, CONST_IDENTITY));
               sse2_punpcklbw(p->func, dataXMM, get_const(p, CONST_IDENTITY));
               break;
            case 16:
               sse2_punpcklwd(p->func, dataXMM, get_const(p, CONST_IDENTITY));
               break;
            case 32: /* we lose precision here */
               sse2_psrld_imm(p->func, dataXMM, 1);
               break;
            default:
               return FALSE;
            }
            sse2_cvtdq2ps(p->func, dataXMM, dataXMM);
            if(input_desc->channel[0].normalized)
            {
               struct x86_reg factor;
               switch(input_desc->channel[0].size)
               {
               case 8:
                  factor = get_const(p, CONST_INV_255);
                  break;
               case 16:
                  factor = get_const(p, CONST_INV_65535);
                  break;
               case 32:
                  factor = get_const(p, CONST_INV_2147483647);
                  break;
               default:
                  assert(0);
                  factor.disp = 0;
                  factor.file = 0;
                  factor.idx = 0;
                  factor.mod = 0;
                  break;
               }
               sse_mulps(p->func, dataXMM, factor);
            }
            else if(input_desc->channel[0].size == 32)
               sse_addps(p->func, dataXMM, dataXMM); /* compensate for the bit we threw away to fit u32 into s32 */
            break;
         case UTIL_FORMAT_TYPE_SIGNED:
            if(!(x86_target_caps(p->func) & X86_SSE2))
               return FALSE;
            emit_load_sse2(p, dataXMM, src, input_desc->channel[0].size * input_desc->nr_channels >> 3);

            /* TODO: add support for SSE4.1 pmovsx */
            switch(input_desc->channel[0].size)
            {
            case 8:
               sse2_punpcklbw(p->func, dataXMM, dataXMM);
               sse2_punpcklbw(p->func, dataXMM, dataXMM);
               sse2_psrad_imm(p->func, dataXMM, 24);
               break;
            case 16:
               sse2_punpcklwd(p->func, dataXMM, dataXMM);
               sse2_psrad_imm(p->func, dataXMM, 16);
               break;
            case 32: /* we lose precision here */
               break;
            default:
               return FALSE;
            }
            sse2_cvtdq2ps(p->func, dataXMM, dataXMM);
            if(input_desc->channel[0].normalized)
            {
               struct x86_reg factor;
               switch(input_desc->channel[0].size)
               {
               case 8:
                  factor = get_const(p, CONST_INV_127);
                  break;
               case 16:
                  factor = get_const(p, CONST_INV_32767);
                  break;
               case 32:
                  factor = get_const(p, CONST_INV_2147483647);
                  break;
               default:
                  assert(0);
                  factor.disp = 0;
                  factor.file = 0;
                  factor.idx = 0;
                  factor.mod = 0;
                  break;
               }
               sse_mulps(p->func, dataXMM, factor);
            }
            break;
d279 6
a284 26
            break;
         case UTIL_FORMAT_TYPE_FLOAT:
            if(input_desc->channel[0].size != 32 && input_desc->channel[0].size != 64)
               return FALSE;
            if(swizzle[3] == UTIL_FORMAT_SWIZZLE_1 && input_desc->nr_channels <= 3)
            {
               swizzle[3] = UTIL_FORMAT_SWIZZLE_W;
               needed_chans = CHANNELS_0001;
            }
            switch(input_desc->channel[0].size)
            {
            case 32:
               emit_load_float32(p, dataXMM, src, needed_chans, input_desc->nr_channels);
               break;
            case 64: /* we lose precision here */
               if(!(x86_target_caps(p->func) & X86_SSE2))
                  return FALSE;
               emit_load_float64to32(p, dataXMM, src, needed_chans, input_desc->nr_channels);
               break;
            default:
               return FALSE;
            }
            break;
         default:
            return FALSE;
         }
a285 3
         if(!id_swizzle)
            sse_shufps(p->func, dataXMM, dataXMM, SHUF(swizzle[0], swizzle[1], swizzle[2], swizzle[3]) );
      }
a286 31
      if(output_desc->nr_channels >= 4
            && swizzle[0] < UTIL_FORMAT_SWIZZLE_0
            && swizzle[1] < UTIL_FORMAT_SWIZZLE_0
            && swizzle[2] < UTIL_FORMAT_SWIZZLE_0
            && swizzle[3] < UTIL_FORMAT_SWIZZLE_0
            )
         sse_movups(p->func, dst, dataXMM);
      else
      {
         if(output_desc->nr_channels >= 2
               && swizzle[0] < UTIL_FORMAT_SWIZZLE_0
               && swizzle[1] < UTIL_FORMAT_SWIZZLE_0)
            sse_movlps(p->func, dst, dataXMM);
         else
         {
            if(swizzle[0] < UTIL_FORMAT_SWIZZLE_0)
               sse_movss(p->func, dst, dataXMM);
            else
               x86_mov_imm(p->func, dst, imms[swizzle[0] - UTIL_FORMAT_SWIZZLE_0]);

            if(output_desc->nr_channels >= 2)
            {
               if(swizzle[1] < UTIL_FORMAT_SWIZZLE_0)
               {
                  sse_shufps(p->func, dataXMM, dataXMM, SHUF(1, 1, 2, 3));
                  sse_movss(p->func, x86_make_disp(dst, 4), dataXMM);
               }
               else
                  x86_mov_imm(p->func, x86_make_disp(dst, 4), imms[swizzle[1] - UTIL_FORMAT_SWIZZLE_0]);
            }
         }
d288 7
a294 49
         if(output_desc->nr_channels >= 3)
         {
            if(output_desc->nr_channels >= 4
                  && swizzle[2] < UTIL_FORMAT_SWIZZLE_0
                  && swizzle[3] < UTIL_FORMAT_SWIZZLE_0)
               sse_movhps(p->func, x86_make_disp(dst, 8), dataXMM);
            else
            {
               if(swizzle[2] < UTIL_FORMAT_SWIZZLE_0)
               {
                  sse_shufps(p->func, dataXMM, dataXMM, SHUF(2, 2, 2, 3));
                  sse_movss(p->func, x86_make_disp(dst, 8), dataXMM);
               }
               else
                  x86_mov_imm(p->func, x86_make_disp(dst, 8), imms[swizzle[2] - UTIL_FORMAT_SWIZZLE_0]);

               if(output_desc->nr_channels >= 4)
               {
                  if(swizzle[3] < UTIL_FORMAT_SWIZZLE_0)
                  {
                     sse_shufps(p->func, dataXMM, dataXMM, SHUF(3, 3, 3, 3));
                     sse_movss(p->func, x86_make_disp(dst, 12), dataXMM);
                  }
                  else
                     x86_mov_imm(p->func, x86_make_disp(dst, 12), imms[swizzle[3] - UTIL_FORMAT_SWIZZLE_0]);
               }
            }
         }
      }
      return TRUE;
   }
   else if((x86_target_caps(p->func) & X86_SSE2) && input_desc->channel[0].size == 8 && output_desc->channel[0].size == 16
         && output_desc->channel[0].normalized == input_desc->channel[0].normalized
         && (0
               || (input_desc->channel[0].type == UTIL_FORMAT_TYPE_UNSIGNED && output_desc->channel[0].type == UTIL_FORMAT_TYPE_UNSIGNED)
               || (input_desc->channel[0].type == UTIL_FORMAT_TYPE_UNSIGNED && output_desc->channel[0].type == UTIL_FORMAT_TYPE_SIGNED)
               || (input_desc->channel[0].type == UTIL_FORMAT_TYPE_SIGNED && output_desc->channel[0].type == UTIL_FORMAT_TYPE_SIGNED)
               ))
   {
      struct x86_reg dataXMM = x86_make_reg(file_XMM, 0);
      struct x86_reg tmpXMM = x86_make_reg(file_XMM, 1);
      struct x86_reg tmp = p->tmp_EAX;
      unsigned imms[2] = {0, 1};

      for(i = 0; i < output_desc->nr_channels; ++i)
      {
         if(swizzle[i] == UTIL_FORMAT_SWIZZLE_0 && i >= input_desc->nr_channels)
            swizzle[i] = i;
      }
d296 7
a302 7
      for(i = 0; i < output_desc->nr_channels; ++i)
      {
         if(swizzle[i] < 4)
            needed_chans = MAX2(needed_chans, swizzle[i] + 1);
         if(swizzle[i] < UTIL_FORMAT_SWIZZLE_0 && swizzle[i] != i)
            id_swizzle = FALSE;
      }
a303 41
      if(needed_chans > 0)
      {
         emit_load_sse2(p, dataXMM, src, input_desc->channel[0].size * input_desc->nr_channels >> 3);

         switch(input_desc->channel[0].type)
         {
         case UTIL_FORMAT_TYPE_UNSIGNED:
            if(input_desc->channel[0].normalized)
            {
               sse2_punpcklbw(p->func, dataXMM, dataXMM);
               if(output_desc->channel[0].type == UTIL_FORMAT_TYPE_SIGNED)
        	       sse2_psrlw_imm(p->func, dataXMM, 1);
            }
            else
               sse2_punpcklbw(p->func, dataXMM, get_const(p, CONST_IDENTITY));
            break;
         case UTIL_FORMAT_TYPE_SIGNED:
            if(input_desc->channel[0].normalized)
            {
               sse2_movq(p->func, tmpXMM, get_const(p, CONST_IDENTITY));
               sse2_punpcklbw(p->func, tmpXMM, dataXMM);
               sse2_psllw_imm(p->func, dataXMM, 9);
               sse2_psrlw_imm(p->func, dataXMM, 8);
               sse2_por(p->func, tmpXMM, dataXMM);
               sse2_psrlw_imm(p->func, dataXMM, 7);
               sse2_por(p->func, tmpXMM, dataXMM);
               {
                  struct x86_reg t = dataXMM;
                  dataXMM = tmpXMM;
                  tmpXMM = t;
               }
            }
            else
            {
               sse2_punpcklbw(p->func, dataXMM, dataXMM);
               sse2_psraw_imm(p->func, dataXMM, 8);
            }
            break;
         default:
            assert(0);
         }
a304 2
         if(output_desc->channel[0].normalized)
            imms[1] = (output_desc->channel[0].type == UTIL_FORMAT_TYPE_UNSIGNED) ? 0xffff : 0x7ffff;
a305 3
         if(!id_swizzle)
            sse2_pshuflw(p->func, dataXMM, dataXMM, (swizzle[0] & 3) | ((swizzle[1] & 3) << 2) | ((swizzle[2] & 3) << 4) | ((swizzle[3] & 3) << 6));
      }
a306 36
      if(output_desc->nr_channels >= 4
            && swizzle[0] < UTIL_FORMAT_SWIZZLE_0
            && swizzle[1] < UTIL_FORMAT_SWIZZLE_0
            && swizzle[2] < UTIL_FORMAT_SWIZZLE_0
            && swizzle[3] < UTIL_FORMAT_SWIZZLE_0
            )
         sse2_movq(p->func, dst, dataXMM);
      else
      {
         if(swizzle[0] < UTIL_FORMAT_SWIZZLE_0)
         {
            if(output_desc->nr_channels >= 2 && swizzle[1] < UTIL_FORMAT_SWIZZLE_0)
               sse2_movd(p->func, dst, dataXMM);
            else
            {
               sse2_movd(p->func, tmp, dataXMM);
               x86_mov16(p->func, dst, tmp);
               if(output_desc->nr_channels >= 2)
                  x86_mov16_imm(p->func, x86_make_disp(dst, 2), imms[swizzle[1] - UTIL_FORMAT_SWIZZLE_0]);
            }
         }
         else
         {
            if(output_desc->nr_channels >= 2 && swizzle[1] >= UTIL_FORMAT_SWIZZLE_0)
               x86_mov_imm(p->func, dst, (imms[swizzle[1] - UTIL_FORMAT_SWIZZLE_0] << 16) | imms[swizzle[0] - UTIL_FORMAT_SWIZZLE_0]);
            else
            {
               x86_mov16_imm(p->func, dst, imms[swizzle[0] - UTIL_FORMAT_SWIZZLE_0]);
               if(output_desc->nr_channels >= 2)
               {
                  sse2_movd(p->func, tmp, dataXMM);
                  x86_shr_imm(p->func, tmp, 16);
                  x86_mov16(p->func, x86_make_disp(dst, 2), tmp);
               }
            }
         }
d308 9
a316 56
         if(output_desc->nr_channels >= 3)
         {
            if(swizzle[2] < UTIL_FORMAT_SWIZZLE_0)
            {
               if(output_desc->nr_channels >= 4 && swizzle[3] < UTIL_FORMAT_SWIZZLE_0)
               {
                  sse2_psrlq_imm(p->func, dataXMM, 32);
                  sse2_movd(p->func, x86_make_disp(dst, 4), dataXMM);
               }
               else
               {
                  sse2_psrlq_imm(p->func, dataXMM, 32);
                  sse2_movd(p->func, tmp, dataXMM);
                  x86_mov16(p->func, x86_make_disp(dst, 4), tmp);
                  if(output_desc->nr_channels >= 4)
                  {
                     x86_mov16_imm(p->func, x86_make_disp(dst, 6), imms[swizzle[3] - UTIL_FORMAT_SWIZZLE_0]);
                  }
               }
            }
            else
            {
               if(output_desc->nr_channels >= 4 && swizzle[3] >= UTIL_FORMAT_SWIZZLE_0)
                  x86_mov_imm(p->func, x86_make_disp(dst, 4), (imms[swizzle[3] - UTIL_FORMAT_SWIZZLE_0] << 16) | imms[swizzle[2] - UTIL_FORMAT_SWIZZLE_0]);
               else
               {
                  x86_mov16_imm(p->func, x86_make_disp(dst, 4), imms[swizzle[2] - UTIL_FORMAT_SWIZZLE_0]);

                  if(output_desc->nr_channels >= 4)
                  {
                     sse2_psrlq_imm(p->func, dataXMM, 48);
                     sse2_movd(p->func, tmp, dataXMM);
                     x86_mov16(p->func, x86_make_disp(dst, 6), tmp);
                  }
               }
            }
         }
      }
      return TRUE;
   }
   else if(!memcmp(&output_desc->channel[0], &input_desc->channel[0], sizeof(output_desc->channel[0])))
   {
      struct x86_reg tmp = p->tmp_EAX;
      unsigned i;
      if(input_desc->channel[0].size == 8 && input_desc->nr_channels == 4 && output_desc->nr_channels == 4
                     && swizzle[0] == UTIL_FORMAT_SWIZZLE_W
                     && swizzle[1] == UTIL_FORMAT_SWIZZLE_Z
                     && swizzle[2] == UTIL_FORMAT_SWIZZLE_Y
                     && swizzle[3] == UTIL_FORMAT_SWIZZLE_X)
      {
         /* TODO: support movbe */
         x86_mov(p->func, tmp, src);
         x86_bswap(p->func, tmp);
         x86_mov(p->func, dst, tmp);
         return TRUE;
      }
a317 149
      for(i = 0; i < output_desc->nr_channels; ++i)
      {
         switch(output_desc->channel[0].size)
         {
         case 8:
            if(swizzle[i] >= UTIL_FORMAT_SWIZZLE_0)
            {
               unsigned v = 0;
               if(swizzle[i] == UTIL_FORMAT_SWIZZLE_1)
               {
                  switch(output_desc->channel[0].type)
                  {
                  case UTIL_FORMAT_TYPE_UNSIGNED:
                     v = output_desc->channel[0].normalized ? 0xff : 1;
                     break;
                  case UTIL_FORMAT_TYPE_SIGNED:
                     v = output_desc->channel[0].normalized ? 0x7f : 1;
                     break;
                  default:
                     return FALSE;
                  }
               }
               x86_mov8_imm(p->func, x86_make_disp(dst, i * 1), v);
            }
            else
            {
               x86_mov8(p->func, tmp, x86_make_disp(src, swizzle[i] * 1));
               x86_mov8(p->func, x86_make_disp(dst, i * 1), tmp);
            }
            break;
         case 16:
            if(swizzle[i] >= UTIL_FORMAT_SWIZZLE_0)
            {
               unsigned v = 0;
               if(swizzle[i] == UTIL_FORMAT_SWIZZLE_1)
               {
                  switch(output_desc->channel[1].type)
                  {
                  case UTIL_FORMAT_TYPE_UNSIGNED:
                     v = output_desc->channel[1].normalized ? 0xffff : 1;
                     break;
                  case UTIL_FORMAT_TYPE_SIGNED:
                     v = output_desc->channel[1].normalized ? 0x7fff : 1;
                     break;
                  case UTIL_FORMAT_TYPE_FLOAT:
                     v = 0x3c00;
                     break;
                  default:
                     return FALSE;
                  }
               }
               x86_mov16_imm(p->func, x86_make_disp(dst, i * 2), v);
            }
            else if(swizzle[i] == UTIL_FORMAT_SWIZZLE_0)
               x86_mov16_imm(p->func, x86_make_disp(dst, i * 2), 0);
            else
            {
               x86_mov16(p->func, tmp, x86_make_disp(src, swizzle[i] * 2));
               x86_mov16(p->func, x86_make_disp(dst, i * 2), tmp);
            }
            break;
         case 32:
            if(swizzle[i] >= UTIL_FORMAT_SWIZZLE_0)
            {
               unsigned v = 0;
               if(swizzle[i] == UTIL_FORMAT_SWIZZLE_1)
               {
                  switch(output_desc->channel[1].type)
                  {
                  case UTIL_FORMAT_TYPE_UNSIGNED:
                     v = output_desc->channel[1].normalized ? 0xffffffff : 1;
                     break;
                  case UTIL_FORMAT_TYPE_SIGNED:
                     v = output_desc->channel[1].normalized ? 0x7fffffff : 1;
                     break;
                  case UTIL_FORMAT_TYPE_FLOAT:
                     v = 0x3f800000;
                     break;
                  default:
                     return FALSE;
                  }
               }
               x86_mov_imm(p->func, x86_make_disp(dst, i * 4), v);
            }
            else
            {
               x86_mov(p->func, tmp, x86_make_disp(src, swizzle[i] * 4));
               x86_mov(p->func, x86_make_disp(dst, i * 4), tmp);
            }
            break;
         case 64:
            if(swizzle[i] >= UTIL_FORMAT_SWIZZLE_0)
            {
               unsigned l = 0;
               unsigned h = 0;
               if(swizzle[i] == UTIL_FORMAT_SWIZZLE_1)
               {
                  switch(output_desc->channel[1].type)
                  {
                  case UTIL_FORMAT_TYPE_UNSIGNED:
                     h = output_desc->channel[1].normalized ? 0xffffffff : 0;
                     l = output_desc->channel[1].normalized ? 0xffffffff : 1;
                     break;
                  case UTIL_FORMAT_TYPE_SIGNED:
                     h = output_desc->channel[1].normalized ? 0x7fffffff : 0;
                     l = output_desc->channel[1].normalized ? 0xffffffff : 1;
                     break;
                  case UTIL_FORMAT_TYPE_FLOAT:
                     h = 0x3ff00000;
                     l = 0;
                     break;
                  default:
                     return FALSE;
                  }
               }
               x86_mov_imm(p->func, x86_make_disp(dst, i * 8), l);
               x86_mov_imm(p->func, x86_make_disp(dst, i * 8 + 4), h);
            }
            else
            {
               if(x86_target_caps(p->func) & X86_SSE)
               {
                  struct x86_reg tmpXMM = x86_make_reg(file_XMM, 0);
                  emit_load64(p, tmp, tmpXMM, x86_make_disp(src, swizzle[i] * 8));
                  emit_store64(p, x86_make_disp(dst, i * 8), tmp, tmpXMM);
               }
               else
               {
                  x86_mov(p->func, tmp, x86_make_disp(src, swizzle[i] * 8));
                  x86_mov(p->func, x86_make_disp(dst, i * 8), tmp);
                  x86_mov(p->func, tmp, x86_make_disp(src, swizzle[i] * 8 + 4));
                  x86_mov(p->func, x86_make_disp(dst, i * 8 + 4), tmp);
               }
            }
            break;
         default:
            return FALSE;
         }
      }
      return TRUE;
   }
   /* special case for draw's EMIT_4UB (RGBA) and EMIT_4UB_BGRA */
   else if((x86_target_caps(p->func) & X86_SSE2) &&
         a->input_format == PIPE_FORMAT_R32G32B32A32_FLOAT && (0
               || a->output_format == PIPE_FORMAT_B8G8R8A8_UNORM
               || a->output_format == PIPE_FORMAT_R8G8B8A8_UNORM
         ))
   {
      struct x86_reg dataXMM = x86_make_reg(file_XMM, 0);
d319 6
a324 2
      /* load */
      sse_movups(p->func, dataXMM, src);
d326 23
a348 2
      if (a->output_format == PIPE_FORMAT_B8G8R8A8_UNORM)
         sse_shufps(p->func, dataXMM, dataXMM, SHUF(2,1,0,3));
d350 22
a371 10
      /* scale by 255.0 */
      sse_mulps(p->func, dataXMM, get_const(p, CONST_255));

      /* pack and emit */
      sse2_cvtps2dq(p->func, dataXMM, dataXMM);
      sse2_packssdw(p->func, dataXMM, dataXMM);
      sse2_packuswb(p->func, dataXMM, dataXMM);
      sse2_movd(p->func, dst, dataXMM);

      return TRUE;
d374 1
a374 1
   return FALSE;
a376 13
static boolean translate_attr( struct translate_sse *p,
			       const struct translate_element *a,
			       struct x86_reg src,
			       struct x86_reg dst)
{
   if(a->input_format == a->output_format)
   {
      emit_memcpy(p, dst, src, util_format_get_stride(a->input_format, 1));
      return TRUE;
   }

   return translate_attr_convert(p, a, src, dst);
}
d379 1
a379 1
                            unsigned index_size )
d382 1
a382 1
   struct x86_reg instance_id = x86_make_disp(p->machine_EDI,
d389 2
a390 2
      if (!index_size || varient->instance_divisor) {
         struct x86_reg buf_stride   = x86_make_disp(p->machine_EDI,
d392 1
a392 1
         struct x86_reg buf_ptr      = x86_make_disp(p->machine_EDI,
d394 1
a394 1
         struct x86_reg buf_base_ptr = x86_make_disp(p->machine_EDI,
d396 1
a396 1
         struct x86_reg elt = p->idx_ESI;
d408 2
a409 2
               struct x86_reg tmp_EDX = p->tmp2_EDX;
               struct x86_reg tmp_ECX = p->src_ECX;
d415 2
d420 2
a425 5

         /*
          * TODO: Respect translate_buffer::max_index.
          */

a426 1
         x64_rexw(p->func);
d433 1
a433 3
         if (!index_size && p->nr_buffer_varients == 1)
         {
            x64_rexw(p->func);
a434 1
         }
a435 2
         {
            x64_rexw(p->func);
a436 1
         }
d445 1
a445 1
                                      unsigned index_size,
d450 1
a450 1
      return x86_make_disp(p->machine_EDI,
d453 2
a454 2
   if (!index_size && p->nr_buffer_varients == 1) {
      return p->idx_ESI;
d456 2
a457 2
   else if (!index_size || p->buffer_varient[var_idx].instance_divisor) {
      struct x86_reg ptr = p->src_ECX;
d459 1
a459 1
         x86_make_disp(p->machine_EDI,
a461 1
      x64_rexw(p->func);
d466 1
a466 1
      struct x86_reg ptr = p->src_ECX;
d470 1
a470 1
         x86_make_disp(p->machine_EDI,
d474 1
a474 1
         x86_make_disp(p->machine_EDI,
d481 2
a482 14
      switch(index_size)
      {
      case 1:
         x86_movzx8(p->func, ptr, elt);
         break;
      case 2:
         x86_movzx16(p->func, ptr, elt);
         break;
      case 4:
         x86_mov(p->func, ptr, elt);
         break;
      }
      x86_imul(p->func, ptr, buf_stride);
      x64_rexw(p->func);
d491 1
a491 1
                            unsigned index_size )
d493 2
a494 2
   if (!index_size && p->nr_buffer_varients == 1) {
      struct x86_reg stride = x86_make_disp(p->machine_EDI,
d498 2
a499 3
         x64_rexw(p->func);
         x86_add(p->func, p->idx_ESI, stride);
         sse_prefetchnta(p->func, x86_make_disp(p->idx_ESI, 192));
d502 1
a502 1
   else if (!index_size) {
d509 1
a509 1
         struct x86_reg buf_ptr = x86_make_disp(p->machine_EDI,
d511 1
a511 1
         struct x86_reg buf_stride = x86_make_disp(p->machine_EDI,
d515 2
a516 3
            x86_mov(p->func, p->tmp_EAX, buf_stride);
            x64_rexw(p->func);
            x86_add(p->func, p->tmp_EAX, buf_ptr);
a517 1
            x64_rexw(p->func);
d523 1
a523 2
      x64_rexw(p->func);
      x86_lea(p->func, p->idx_ESI, x86_make_disp(p->idx_ESI, index_size));
d548 1
a548 1
				  unsigned index_size )
a552 3
   memset(p->reg_to_const, 0xff, sizeof(p->reg_to_const));
   memset(p->const_to_reg, 0xff, sizeof(p->const_to_reg));

d554 4
a557 6
   p->idx_ESI       = x86_make_reg(file_REG32, reg_SI);
   p->outbuf_EBX    = x86_make_reg(file_REG32, reg_BX);
   p->machine_EDI   = x86_make_reg(file_REG32, reg_DI);
   p->count_EBP     = x86_make_reg(file_REG32, reg_BP);
   p->tmp2_EDX     = x86_make_reg(file_REG32, reg_DX);
   p->src_ECX     = x86_make_reg(file_REG32, reg_CX);
d560 3
d566 4
a569 6
   if(x86_target(p->func) == X86_64_WIN64_ABI)
   {
	   /* the ABI guarantees a 16-byte aligned 32-byte "shadow space" above the return address */
	   sse2_movdqa(p->func, x86_make_disp(x86_make_reg(file_REG32, reg_SP), 8), x86_make_reg(file_XMM, 6));
	   sse2_movdqa(p->func, x86_make_disp(x86_make_reg(file_REG32, reg_SP), 24), x86_make_reg(file_XMM, 7));
   }
d571 6
a576 19
   x86_push(p->func, p->outbuf_EBX);
   x86_push(p->func, p->count_EBP);

/* on non-Win64 x86-64, these are already in the right registers */
   if(x86_target(p->func) != X86_64_STD_ABI)
   {
      x86_push(p->func, p->machine_EDI);
      x86_push(p->func, p->idx_ESI);

      x86_mov(p->func, p->machine_EDI, x86_fn_arg(p->func, 1));
      x86_mov(p->func, p->idx_ESI, x86_fn_arg(p->func, 2));
   }

   x86_mov(p->func, p->count_EBP, x86_fn_arg(p->func, 3));

   if(x86_target(p->func) != X86_32)
      x64_mov64(p->func, p->outbuf_EBX, x86_fn_arg(p->func, 5));
   else
      x86_mov(p->func, p->outbuf_EBX, x86_fn_arg(p->func, 5));
d585 1
a585 1
              x86_make_disp(p->machine_EDI, get_offset(p, &p->instance_id)),
d592 1
a592 1
   x86_cmp(p->func, p->count_EBP, p->tmp_EAX);
d597 1
a597 1
   init_inputs(p, index_size);
d603 1
a603 1
      struct x86_reg elt = !index_size ? p->idx_ESI : x86_deref(p->idx_ESI);
d615 1
a615 1
            vb = get_buffer_ptr(p, index_size, varient, elt);
d620 1
a620 1
                              x86_make_disp(p->outbuf_EBX, a->output_offset)))
a625 1
      x64_rexw(p->func);
d627 2
a628 2
              p->outbuf_EBX,
              x86_make_disp(p->outbuf_EBX,
d633 1
a633 1
      incr_inputs( p, index_size );
d638 1
a638 1
   x86_dec(p->func, p->count_EBP);
d653 2
a654 14
   if(x86_target(p->func) != X86_64_STD_ABI)
   {
      x86_pop(p->func, p->idx_ESI);
      x86_pop(p->func, p->machine_EDI);
   }

   x86_pop(p->func, p->count_EBP);
   x86_pop(p->func, p->outbuf_EBX);

   if(x86_target(p->func) == X86_64_WIN64_ABI)
   {
	   sse2_movdqa(p->func, x86_make_reg(file_XMM, 6), x86_make_disp(x86_make_reg(file_REG32, reg_SP), 8));
	   sse2_movdqa(p->func, x86_make_reg(file_XMM, 7), x86_make_disp(x86_make_reg(file_REG32, reg_SP), 24));
   }
d669 1
a669 2
				unsigned stride,
				unsigned max_index )
a675 1
      p->buffer[buf].max_index = max_index;
d692 31
a722 1
   os_free_aligned(p);
d731 1
a731 2
   /* this is misnamed, it actually refers to whether rtasm is enabled or not */
   if (!rtasm_cpu_has_sse())
d734 1
a734 1
   p = os_malloc_aligned(sizeof(struct translate_sse), 16);
a736 2
   memset(p, 0, sizeof(*p));
   memcpy(p->consts, consts, sizeof(consts));
d741 2
d778 1
a778 14
   if (!build_vertex_emit(p, &p->linear_func, 0))
      goto fail;

   if (!build_vertex_emit(p, &p->elt_func, 4))
      goto fail;

   if (!build_vertex_emit(p, &p->elt16_func, 2))
      goto fail;

   if (!build_vertex_emit(p, &p->elt8_func, 1))
      goto fail;

   p->translate.run = (run_func) x86_get_func(&p->linear_func);
   if (p->translate.run == NULL)
d781 1
a781 2
   p->translate.run_elts = (run_elts_func) x86_get_func(&p->elt_func);
   if (p->translate.run_elts == NULL)
d784 2
a785 2
   p->translate.run_elts16 = (run_elts16_func) x86_get_func(&p->elt16_func);
   if (p->translate.run_elts16 == NULL)
d788 2
a789 2
   p->translate.run_elts8 = (run_elts8_func) x86_get_func(&p->elt8_func);
   if (p->translate.run_elts8 == NULL)
@


1.1.1.2
log
@Import Mesa 9.2.0
@
text
@d38 1
a38 1
#if (defined(PIPE_ARCH_X86) || (defined(PIPE_ARCH_X86_64) && !defined(__MINGW32__))) && !defined(PIPE_SUBSYSTEM_EMBEDDED)
d56 1
a56 1
struct translate_buffer_variant {
d106 3
a108 3
   /* Multiple buffer variants can map to a single buffer. */
   struct translate_buffer_variant buffer_variant[PIPE_MAX_ATTRIBS];
   unsigned nr_buffer_variants;
d110 2
a111 2
   /* Multiple elements can map to a single buffer variant. */
   unsigned element_to_buffer_variant[PIPE_MAX_ATTRIBS];
a114 1
   unsigned start_instance;
a1063 2
   struct x86_reg start_instance = x86_make_disp(p->machine_EDI,
                                                 get_offset(p, &p->start_instance));
d1065 5
a1069 7
   for (i = 0; i < p->nr_buffer_variants; i++) {
      struct translate_buffer_variant *variant = &p->buffer_variant[i];
      struct translate_buffer *buffer = &p->buffer[variant->buffer_index];

      if (!index_size || variant->instance_divisor) {
         struct x86_reg buf_max_index = x86_make_disp(p->machine_EDI,
                                                     get_offset(p, &buffer->max_index));
d1073 1
a1073 1
                                                     get_offset(p, &variant->ptr));
d1082 2
a1083 3
         if (variant->instance_divisor) {
            /* Start with instance = instance_id
             * which is true if divisor is 1.
d1087 1
a1087 1
            if (variant->instance_divisor != 1) {
a1090 4
               /* instance_num = instance_id - start_instance */
               x86_mov(p->func, tmp_EDX, start_instance);
               x86_sub(p->func, tmp_EAX, tmp_EDX);

d1094 1
d1096 1
a1096 1
               x86_mov_reg_imm(p->func, tmp_ECX, variant->instance_divisor);
a1097 6

               /* instance = (instance_id - start_instance) / divisor + 
                *             start_instance 
                */
               x86_mov(p->func, tmp_EDX, start_instance);
               x86_add(p->func, tmp_EAX, tmp_EDX);
a1098 5

            /* XXX we need to clamp the index here too, but to a
             * per-array max value, not the draw->pt.max_index value
             * that's being given to us via translate->set_buffer().
             */
d1101 1
d1103 3
a1105 5
            /* Clamp to max_index
             */
            x86_cmp(p->func, tmp_EAX, buf_max_index);
            x86_cmovcc(p->func, tmp_EAX, buf_max_index, cc_AE);
         }
a1110 1
         x86_cmp(p->func, p->count_EBP, p->tmp_EAX);
d1115 1
a1115 1
         if (!index_size && p->nr_buffer_variants == 1)
d1141 1
a1141 1
   if (!index_size && p->nr_buffer_variants == 1) {
d1144 1
a1144 1
   else if (!index_size || p->buffer_variant[var_idx].instance_divisor) {
d1148 1
a1148 1
                       get_offset(p, &p->buffer_variant[var_idx].ptr));
d1156 1
a1156 1
      const struct translate_buffer_variant *variant = &p->buffer_variant[var_idx];
d1160 1
a1160 1
                       get_offset(p, &p->buffer[variant->buffer_index].stride));
d1164 1
a1164 5
                       get_offset(p, &p->buffer[variant->buffer_index].base_ptr));

      struct x86_reg buf_max_index =
         x86_make_disp(p->machine_EDI,
                       get_offset(p, &p->buffer[variant->buffer_index].max_index));
a1181 6

      /* Clamp to max_index
       */
      x86_cmp(p->func, ptr, buf_max_index);
      x86_cmovcc(p->func, ptr, buf_max_index, cc_AE);

d1194 1
a1194 1
   if (!index_size && p->nr_buffer_variants == 1) {
d1198 1
a1198 1
      if (p->buffer_variant[0].instance_divisor == 0) {
d1209 2
a1210 2
      for (i = 0; i < p->nr_buffer_variants; i++) {
         struct translate_buffer_variant *variant = &p->buffer_variant[i];
d1212 1
a1212 1
                                                get_offset(p, &variant->ptr));
d1214 1
a1214 1
                                                   get_offset(p, &p->buffer[variant->buffer_index].stride));
d1216 1
a1216 1
         if (variant->instance_divisor == 0) {
d1296 1
a1296 1
      x64_mov64(p->func, p->outbuf_EBX, x86_fn_arg(p->func, 6));
d1298 1
a1298 1
      x86_mov(p->func, p->outbuf_EBX, x86_fn_arg(p->func, 6));
d1302 1
a1302 1
   if (p->use_instancing) {      
d1304 1
a1304 1
              p->tmp2_EDX,
a1306 7
              x86_make_disp(p->machine_EDI, get_offset(p, &p->start_instance)),
              p->tmp2_EDX);

      x86_mov(p->func,
              p->tmp_EAX,
              x86_fn_arg(p->func, 5));
      x86_mov(p->func,
d1326 1
a1326 1
      int last_variant = -1;
d1331 1
a1331 1
         unsigned variant = p->element_to_buffer_variant[j];
d1335 3
a1337 3
         if (variant != last_variant) {
            last_variant = variant;
            vb = get_buffer_ptr(p, index_size, variant, elt);
d1426 1
a1426 2
   x86_release_func( &p->elt8_func );
   x86_release_func( &p->elt16_func );
a1427 1
   x86_release_func( &p->linear_func );
d1463 1
a1463 1
          * Map vertex element to vertex buffer variant.
d1465 3
a1467 3
         for (j = 0; j < p->nr_buffer_variants; j++) {
            if (p->buffer_variant[j].buffer_index == key->element[i].input_buffer &&
                p->buffer_variant[j].instance_divisor == key->element[i].instance_divisor) {
d1471 4
a1474 4
         if (j == p->nr_buffer_variants) {
            p->buffer_variant[j].buffer_index = key->element[i].input_buffer;
            p->buffer_variant[j].instance_divisor = key->element[i].instance_divisor;
            p->nr_buffer_variants++;
d1476 1
a1476 1
         p->element_to_buffer_variant[i] = j;
d1480 1
a1480 1
         p->element_to_buffer_variant[i] = ELEMENT_BUFFER_INSTANCE_ID;
@


1.1.1.3
log
@Import Mesa 10.2.3
@
text
@d2 1
a2 1
 * Copyright 2003 VMware, Inc.
d19 1
a19 1
 * VMWARE AND/OR THEIR SUPPLIERS BE LIABLE FOR ANY CLAIM,
d25 1
a25 1
 *    Keith Whitwell <keithw@@vmware.com>
d50 1
a50 2
struct translate_buffer
{
d56 1
a56 2
struct translate_buffer_variant
{
d59 1
a59 1
   void *ptr;                   /* updated either per vertex or per instance */
d80 7
a86 7
   {0, 0, 0, 1},
   C(1.0 / 127.0),
   C(1.0 / 255.0),
   C(1.0 / 32767.0),
   C(1.0 / 65535.0),
   C(1.0 / 2147483647.0),
   C(255.0)
a87 1

d90 1
a90 2
struct translate_sse
{
d99 1
a99 1
     PIPE_ALIGN_VAR(16) float consts[NUM_CONSTS][4];
d103 1
a103 1
   struct translate_buffer buffer[TRANSLATE_MAX_ATTRIBS];
d107 1
a107 1
   struct translate_buffer_variant buffer_variant[TRANSLATE_MAX_ATTRIBS];
d111 1
a111 1
   unsigned element_to_buffer_variant[TRANSLATE_MAX_ATTRIBS];
d123 1
a123 1
   struct x86_reg idx_ESI;      /* either start+i or &elt[i] */
d129 1
a129 3

static int
get_offset(const void *a, const void *b)
d131 1
a131 1
   return (const char *) b - (const char *) a;
d134 1
a134 3

static struct x86_reg
get_const(struct translate_sse *p, unsigned id)
d139 1
a139 1
   if (p->const_to_reg[id] >= 0)
d142 3
a144 2
   for (i = 2; i < 8; ++i) {
      if (p->reg_to_const[i] < 0)
d149 1
a149 1
   if (i == 8)
d154 1
a154 1
   if (p->reg_to_const[i] >= 0)
d162 2
a163 2
              x86_make_disp(p->machine_EDI,
                            get_offset(p, &p->consts[id][0])));
a167 1

d169 4
a172 3
static boolean
emit_load_sse2(struct translate_sse *p,
               struct x86_reg data, struct x86_reg src, unsigned size)
d176 2
a177 1
   switch (size) {
a217 1

a220 1

d228 5
a232 3
static void
emit_load_float32(struct translate_sse *p, struct x86_reg data,
                  struct x86_reg arg0, unsigned out_chans, unsigned chans)
d234 2
a235 1
   switch (chans) {
d241 2
a242 2
      if (out_chans == CHANNELS_0001)
         sse_orps(p->func, data, get_const(p, CONST_IDENTITY));
d248 4
a251 5
      if (out_chans == CHANNELS_0001)
         sse_shufps(p->func, data, get_const(p, CONST_IDENTITY),
                    SHUF(X, Y, Z, W));
      else if (out_chans > 2)
         sse_movlhps(p->func, data, get_const(p, CONST_IDENTITY));
d263 3
a265 4
      if (out_chans == CHANNELS_0001)
         sse_shufps(p->func, data, get_const(p, CONST_IDENTITY),
                    SHUF(X, Y, Z, W));
      sse_shufps(p->func, data, data, SHUF(Y, Z, X, W));
d277 5
a281 3
static void
emit_load_float64to32(struct translate_sse *p, struct x86_reg data,
                      struct x86_reg arg0, unsigned out_chans, unsigned chans)
d284 2
a285 1
   switch (chans) {
d288 1
a288 1
      if (out_chans > 1)
d292 2
a293 3
      if (out_chans == CHANNELS_0001)
         sse_shufps(p->func, data, get_const(p, CONST_IDENTITY),
                    SHUF(X, Y, Z, W));
d298 5
a302 6
      if (out_chans == CHANNELS_0001)
         sse_shufps(p->func, data, get_const(p, CONST_IDENTITY),
                    SHUF(X, Y, Z, W));
      else if (out_chans > 2)
         sse_movlhps(p->func, data, get_const(p, CONST_IDENTITY));
      break;
d307 1
a307 1
      if (out_chans > 3)
d312 2
a313 2
      if (out_chans == CHANNELS_0001)
         sse_orps(p->func, data, get_const(p, CONST_IDENTITY));
d325 1
a325 5

static void
emit_mov64(struct translate_sse *p, struct x86_reg dst_gpr,
           struct x86_reg dst_xmm, struct x86_reg src_gpr,
           struct x86_reg src_xmm)
d327 1
a327 1
   if (x86_target(p->func) != X86_32)
d329 2
a330 1
   else {
d332 1
a332 1
      if (x86_target_caps(p->func) & X86_SSE2)
d339 1
a339 4

static void
emit_load64(struct translate_sse *p, struct x86_reg dst_gpr,
            struct x86_reg dst_xmm, struct x86_reg src)
d344 1
a344 4

static void
emit_store64(struct translate_sse *p, struct x86_reg dst,
             struct x86_reg src_gpr, struct x86_reg src_xmm)
d349 1
a349 3

static void
emit_mov128(struct translate_sse *p, struct x86_reg dst, struct x86_reg src)
d351 1
a351 1
   if (x86_target_caps(p->func) & X86_SSE2)
a356 1

d361 1
a361 3
static void
emit_memcpy(struct translate_sse *p, struct x86_reg dst, struct x86_reg src,
            unsigned size)
d368 4
a371 2
   if (size < 8) {
      switch (size) {
d398 2
a399 1
   else if (!(x86_target_caps(p->func) & X86_SSE)) {
d402 2
a403 1
      for (i = 0; i < size; i += 4) {
d408 4
a411 2
   else {
      switch (size) {
d444 5
a448 4
static boolean
translate_attr_convert(struct translate_sse *p,
                       const struct translate_element *a,
                       struct x86_reg src, struct x86_reg dst)
d450 2
a451 4
   const struct util_format_description *input_desc =
      util_format_description(a->input_format);
   const struct util_format_description *output_desc =
      util_format_description(a->output_format);
d454 1
a454 3
   unsigned swizzle[4] =
      { UTIL_FORMAT_SWIZZLE_NONE, UTIL_FORMAT_SWIZZLE_NONE,
        UTIL_FORMAT_SWIZZLE_NONE, UTIL_FORMAT_SWIZZLE_NONE };
d456 1
a456 1
   unsigned imms[2] = { 0, 0x3f800000 };
d458 1
a458 2
   if (a->output_format == PIPE_FORMAT_NONE
       || a->input_format == PIPE_FORMAT_NONE)
d461 1
a461 1
   if (input_desc->channel[0].size & 7)
d464 1
a464 1
   if (input_desc->colorspace != output_desc->colorspace)
d467 3
a469 4
   for (i = 1; i < input_desc->nr_channels; ++i) {
      if (memcmp
          (&input_desc->channel[i], &input_desc->channel[0],
           sizeof(input_desc->channel[0])))
d473 3
a475 4
   for (i = 1; i < output_desc->nr_channels; ++i) {
      if (memcmp
          (&output_desc->channel[i], &output_desc->channel[0],
           sizeof(output_desc->channel[0]))) {
a476 1
      }
d479 3
a481 2
   for (i = 0; i < output_desc->nr_channels; ++i) {
      if (output_desc->swizzle[i] < 4)
d485 6
a490 5
   if ((x86_target_caps(p->func) & X86_SSE) &&
       (0 || a->output_format == PIPE_FORMAT_R32_FLOAT
        || a->output_format == PIPE_FORMAT_R32G32_FLOAT
        || a->output_format == PIPE_FORMAT_R32G32B32_FLOAT
        || a->output_format == PIPE_FORMAT_R32G32B32A32_FLOAT)) {
d493 3
a495 3
      for (i = 0; i < output_desc->nr_channels; ++i) {
         if (swizzle[i] == UTIL_FORMAT_SWIZZLE_0
             && i >= input_desc->nr_channels)
d499 3
a501 2
      for (i = 0; i < output_desc->nr_channels; ++i) {
         if (swizzle[i] < 4)
d503 1
a503 1
         if (swizzle[i] < UTIL_FORMAT_SWIZZLE_0 && swizzle[i] != i)
d507 4
a510 2
      if (needed_chans > 0) {
         switch (input_desc->channel[0].type) {
d512 1
a512 1
            if (!(x86_target_caps(p->func) & X86_SSE2))
d514 1
a514 3
            emit_load_sse2(p, dataXMM, src,
                           input_desc->channel[0].size *
                           input_desc->nr_channels >> 3);
d517 2
a518 1
            switch (input_desc->channel[0].size) {
d520 1
a520 3
               /* TODO: this may be inefficient due to get_identity() being
                *  used both as a float and integer register.
                */
d527 1
a527 1
            case 32:           /* we lose precision here */
d534 2
a535 1
            if (input_desc->channel[0].normalized) {
d537 2
a538 1
               switch (input_desc->channel[0].size) {
d558 2
a559 3
            else if (input_desc->channel[0].size == 32)
               /* compensate for the bit we threw away to fit u32 into s32 */
               sse_addps(p->func, dataXMM, dataXMM);
d562 1
a562 1
            if (!(x86_target_caps(p->func) & X86_SSE2))
d564 1
a564 3
            emit_load_sse2(p, dataXMM, src,
                           input_desc->channel[0].size *
                           input_desc->nr_channels >> 3);
d567 2
a568 1
            switch (input_desc->channel[0].size) {
d578 1
a578 1
            case 32:           /* we lose precision here */
d584 2
a585 1
            if (input_desc->channel[0].normalized) {
d587 2
a588 1
               switch (input_desc->channel[0].size) {
d612 1
a612 2
            if (input_desc->channel[0].size != 32
                && input_desc->channel[0].size != 64) {
d614 2
a615 3
            }
            if (swizzle[3] == UTIL_FORMAT_SWIZZLE_1
                && input_desc->nr_channels <= 3) {
d619 2
a620 1
            switch (input_desc->channel[0].size) {
d622 1
a622 2
               emit_load_float32(p, dataXMM, src, needed_chans,
                                 input_desc->nr_channels);
d624 2
a625 2
            case 64:           /* we lose precision here */
               if (!(x86_target_caps(p->func) & X86_SSE2))
d627 1
a627 2
               emit_load_float64to32(p, dataXMM, src, needed_chans,
                                     input_desc->nr_channels);
d637 2
a638 4
         if (!id_swizzle) {
            sse_shufps(p->func, dataXMM, dataXMM,
                       SHUF(swizzle[0], swizzle[1], swizzle[2], swizzle[3]));
         }
d641 6
a646 5
      if (output_desc->nr_channels >= 4
          && swizzle[0] < UTIL_FORMAT_SWIZZLE_0
          && swizzle[1] < UTIL_FORMAT_SWIZZLE_0
          && swizzle[2] < UTIL_FORMAT_SWIZZLE_0
          && swizzle[3] < UTIL_FORMAT_SWIZZLE_0) {
d648 5
a652 5
      }
      else {
         if (output_desc->nr_channels >= 2
             && swizzle[0] < UTIL_FORMAT_SWIZZLE_0
             && swizzle[1] < UTIL_FORMAT_SWIZZLE_0) {
d654 3
a656 3
         }
         else {
            if (swizzle[0] < UTIL_FORMAT_SWIZZLE_0) {
d658 2
a659 5
            }
            else {
               x86_mov_imm(p->func, dst,
                           imms[swizzle[0] - UTIL_FORMAT_SWIZZLE_0]);
            }
d661 4
a664 2
            if (output_desc->nr_channels >= 2) {
               if (swizzle[1] < UTIL_FORMAT_SWIZZLE_0) {
d668 2
a669 4
               else {
                  x86_mov_imm(p->func, x86_make_disp(dst, 4),
                              imms[swizzle[1] - UTIL_FORMAT_SWIZZLE_0]);
               }
d673 5
a677 4
         if (output_desc->nr_channels >= 3) {
            if (output_desc->nr_channels >= 4
                && swizzle[2] < UTIL_FORMAT_SWIZZLE_0
                && swizzle[3] < UTIL_FORMAT_SWIZZLE_0) {
d679 4
a682 3
            }
            else {
               if (swizzle[2] < UTIL_FORMAT_SWIZZLE_0) {
d686 2
a687 4
               else {
                  x86_mov_imm(p->func, x86_make_disp(dst, 8),
                              imms[swizzle[2] - UTIL_FORMAT_SWIZZLE_0]);
               }
d689 4
a692 2
               if (output_desc->nr_channels >= 4) {
                  if (swizzle[3] < UTIL_FORMAT_SWIZZLE_0) {
d696 2
a697 4
                  else {
                     x86_mov_imm(p->func, x86_make_disp(dst, 12),
                                 imms[swizzle[3] - UTIL_FORMAT_SWIZZLE_0]);
                  }
d704 8
a711 11
   else if ((x86_target_caps(p->func) & X86_SSE2)
            && input_desc->channel[0].size == 8
            && output_desc->channel[0].size == 16
            && output_desc->channel[0].normalized ==
            input_desc->channel[0].normalized &&
            (0 || (input_desc->channel[0].type == UTIL_FORMAT_TYPE_UNSIGNED
                   && output_desc->channel[0].type == UTIL_FORMAT_TYPE_UNSIGNED)
             || (input_desc->channel[0].type == UTIL_FORMAT_TYPE_UNSIGNED
                 && output_desc->channel[0].type == UTIL_FORMAT_TYPE_SIGNED)
             || (input_desc->channel[0].type == UTIL_FORMAT_TYPE_SIGNED
                 && output_desc->channel[0].type == UTIL_FORMAT_TYPE_SIGNED))) {
d715 1
a715 1
      unsigned imms[2] = { 0, 1 };
d717 3
a719 3
      for (i = 0; i < output_desc->nr_channels; ++i) {
         if (swizzle[i] == UTIL_FORMAT_SWIZZLE_0
             && i >= input_desc->nr_channels) {
a720 1
         }
d723 3
a725 2
      for (i = 0; i < output_desc->nr_channels; ++i) {
         if (swizzle[i] < 4)
d727 1
a727 1
         if (swizzle[i] < UTIL_FORMAT_SWIZZLE_0 && swizzle[i] != i)
d731 3
a733 4
      if (needed_chans > 0) {
         emit_load_sse2(p, dataXMM, src,
                        input_desc->channel[0].size *
                        input_desc->nr_channels >> 3);
d735 2
a736 1
         switch (input_desc->channel[0].type) {
d738 2
a739 1
            if (input_desc->channel[0].normalized) {
d741 2
a742 2
               if (output_desc->channel[0].type == UTIL_FORMAT_TYPE_SIGNED)
                  sse2_psrlw_imm(p->func, dataXMM, 1);
d748 2
a749 1
            if (input_desc->channel[0].normalized) {
d763 2
a764 1
            else {
d773 5
a777 9
         if (output_desc->channel[0].normalized)
            imms[1] =
               (output_desc->channel[0].type ==
                UTIL_FORMAT_TYPE_UNSIGNED) ? 0xffff : 0x7ffff;

         if (!id_swizzle)
            sse2_pshuflw(p->func, dataXMM, dataXMM,
                         (swizzle[0] & 3) | ((swizzle[1] & 3) << 2) |
                         ((swizzle[2] & 3) << 4) | ((swizzle[3] & 3) << 6));
d780 6
a785 5
      if (output_desc->nr_channels >= 4
          && swizzle[0] < UTIL_FORMAT_SWIZZLE_0
          && swizzle[1] < UTIL_FORMAT_SWIZZLE_0
          && swizzle[2] < UTIL_FORMAT_SWIZZLE_0
          && swizzle[3] < UTIL_FORMAT_SWIZZLE_0) {
d787 5
a791 5
      }
      else {
         if (swizzle[0] < UTIL_FORMAT_SWIZZLE_0) {
            if (output_desc->nr_channels >= 2
                && swizzle[1] < UTIL_FORMAT_SWIZZLE_0) {
d793 2
a794 2
            }
            else {
d797 2
a798 3
               if (output_desc->nr_channels >= 2)
                  x86_mov16_imm(p->func, x86_make_disp(dst, 2),
                                imms[swizzle[1] - UTIL_FORMAT_SWIZZLE_0]);
d801 9
a809 11
         else {
            if (output_desc->nr_channels >= 2
                && swizzle[1] >= UTIL_FORMAT_SWIZZLE_0) {
               x86_mov_imm(p->func, dst,
                           (imms[swizzle[1] - UTIL_FORMAT_SWIZZLE_0] << 16) |
                           imms[swizzle[0] - UTIL_FORMAT_SWIZZLE_0]);
            }
            else {
               x86_mov16_imm(p->func, dst,
                             imms[swizzle[0] - UTIL_FORMAT_SWIZZLE_0]);
               if (output_desc->nr_channels >= 2) {
d817 6
a822 4
         if (output_desc->nr_channels >= 3) {
            if (swizzle[2] < UTIL_FORMAT_SWIZZLE_0) {
               if (output_desc->nr_channels >= 4
                   && swizzle[3] < UTIL_FORMAT_SWIZZLE_0) {
d826 2
a827 1
               else {
d831 3
a833 3
                  if (output_desc->nr_channels >= 4) {
                     x86_mov16_imm(p->func, x86_make_disp(dst, 6),
                                   imms[swizzle[3] - UTIL_FORMAT_SWIZZLE_0]);
d837 7
a843 10
            else {
               if (output_desc->nr_channels >= 4
                   && swizzle[3] >= UTIL_FORMAT_SWIZZLE_0) {
                  x86_mov_imm(p->func, x86_make_disp(dst, 4),
                              (imms[swizzle[3] - UTIL_FORMAT_SWIZZLE_0] << 16)
                              | imms[swizzle[2] - UTIL_FORMAT_SWIZZLE_0]);
               }
               else {
                  x86_mov16_imm(p->func, x86_make_disp(dst, 4),
                                imms[swizzle[2] - UTIL_FORMAT_SWIZZLE_0]);
d845 2
a846 1
                  if (output_desc->nr_channels >= 4) {
d857 2
a858 2
   else if (!memcmp(&output_desc->channel[0], &input_desc->channel[0],
                    sizeof(output_desc->channel[0]))) {
d861 6
a866 7

      if (input_desc->channel[0].size == 8 && input_desc->nr_channels == 4
          && output_desc->nr_channels == 4
          && swizzle[0] == UTIL_FORMAT_SWIZZLE_W
          && swizzle[1] == UTIL_FORMAT_SWIZZLE_Z
          && swizzle[2] == UTIL_FORMAT_SWIZZLE_Y
          && swizzle[3] == UTIL_FORMAT_SWIZZLE_X) {
d874 4
a877 2
      for (i = 0; i < output_desc->nr_channels; ++i) {
         switch (output_desc->channel[0].size) {
d879 2
a880 1
            if (swizzle[i] >= UTIL_FORMAT_SWIZZLE_0) {
d882 4
a885 2
               if (swizzle[i] == UTIL_FORMAT_SWIZZLE_1) {
                  switch (output_desc->channel[0].type) {
d898 2
a899 1
            else {
d905 2
a906 1
            if (swizzle[i] >= UTIL_FORMAT_SWIZZLE_0) {
d908 4
a911 2
               if (swizzle[i] == UTIL_FORMAT_SWIZZLE_1) {
                  switch (output_desc->channel[1].type) {
d927 1
a927 1
            else if (swizzle[i] == UTIL_FORMAT_SWIZZLE_0) {
d929 2
a930 2
            }
            else {
d936 2
a937 1
            if (swizzle[i] >= UTIL_FORMAT_SWIZZLE_0) {
d939 4
a942 2
               if (swizzle[i] == UTIL_FORMAT_SWIZZLE_1) {
                  switch (output_desc->channel[1].type) {
d958 2
a959 1
            else {
d965 2
a966 1
            if (swizzle[i] >= UTIL_FORMAT_SWIZZLE_0) {
d969 4
a972 2
               if (swizzle[i] == UTIL_FORMAT_SWIZZLE_1) {
                  switch (output_desc->channel[1].type) {
d992 4
a995 2
            else {
               if (x86_target_caps(p->func) & X86_SSE) {
d997 1
a997 2
                  emit_load64(p, tmp, tmpXMM,
                              x86_make_disp(src, swizzle[i] * 8));
d1000 2
a1001 1
               else {
d1004 1
a1004 2
                  x86_mov(p->func, tmp,
                          x86_make_disp(src, swizzle[i] * 8 + 4));
d1016 6
a1021 4
   else if ((x86_target_caps(p->func) & X86_SSE2) &&
            a->input_format == PIPE_FORMAT_R32G32B32A32_FLOAT &&
            (0 || a->output_format == PIPE_FORMAT_B8G8R8A8_UNORM
             || a-> output_format == PIPE_FORMAT_R8G8B8A8_UNORM)) {
d1027 2
a1028 3
      if (a->output_format == PIPE_FORMAT_B8G8R8A8_UNORM) {
         sse_shufps(p->func, dataXMM, dataXMM, SHUF(2, 1, 0, 3));
      }
d1045 4
a1048 5

static boolean
translate_attr(struct translate_sse *p,
               const struct translate_element *a,
               struct x86_reg src, struct x86_reg dst)
d1050 2
a1051 1
   if (a->input_format == a->output_format) {
d1059 2
a1060 3

static boolean
init_inputs(struct translate_sse *p, unsigned index_size)
d1063 4
a1066 4
   struct x86_reg instance_id =
      x86_make_disp(p->machine_EDI, get_offset(p, &p->instance_id));
   struct x86_reg start_instance =
      x86_make_disp(p->machine_EDI, get_offset(p, &p->start_instance));
d1073 8
a1080 8
         struct x86_reg buf_max_index =
            x86_make_disp(p->machine_EDI, get_offset(p, &buffer->max_index));
         struct x86_reg buf_stride =
            x86_make_disp(p->machine_EDI, get_offset(p, &buffer->stride));
         struct x86_reg buf_ptr =
            x86_make_disp(p->machine_EDI, get_offset(p, &variant->ptr));
         struct x86_reg buf_base_ptr =
            x86_make_disp(p->machine_EDI, get_offset(p, &buffer->base_ptr));
d1097 4
d1106 1
a1106 1
               x86_div(p->func, tmp_ECX);       /* EAX = EDX:EAX / ECX */
d1119 1
a1119 2
         }
         else {
d1128 1
a1128 3
         x86_mov(p->func, p->tmp2_EDX, buf_stride);
         x64_rexw(p->func);
         x86_imul(p->func, tmp_EAX, p->tmp2_EDX);
d1137 2
a1138 1
         if (!index_size && p->nr_buffer_variants == 1) {
d1142 2
a1143 1
         else {
d1154 4
a1157 3
static struct x86_reg
get_buffer_ptr(struct translate_sse *p,
               unsigned index_size, unsigned var_idx, struct x86_reg elt)
d1160 2
a1161 1
      return x86_make_disp(p->machine_EDI, get_offset(p, &p->instance_id));
d1168 1
a1168 1
      struct x86_reg buf_ptr =
d1171 1
a1171 1

d1178 3
a1180 3
      const struct translate_buffer_variant *variant =
         &p->buffer_variant[var_idx];
      struct x86_reg buf_stride =
d1183 2
a1184 1
      struct x86_reg buf_base_ptr =
d1186 2
a1187 1
                  get_offset(p, &p->buffer[variant->buffer_index].base_ptr));
d1190 3
a1192 1
                  get_offset(p, &p->buffer[variant->buffer_index].max_index));
d1196 2
a1197 1
      switch (index_size) {
d1214 1
a1214 3
      x86_mov(p->func, p->tmp2_EDX, buf_stride);
      x64_rexw(p->func);
      x86_imul(p->func, ptr, p->tmp2_EDX);
d1222 3
a1224 2
static boolean
incr_inputs(struct translate_sse *p, unsigned index_size)
d1227 2
a1228 4
      const unsigned buffer_index = p->buffer_variant[0].buffer_index;
      struct x86_reg stride =
         x86_make_disp(p->machine_EDI,
                       get_offset(p, &p->buffer[buffer_index].stride));
d1245 2
a1246 3
      struct x86_reg buf_stride =
         x86_make_disp(p->machine_EDI,
                       get_offset(p, &p->buffer[variant->buffer_index].stride));
d1252 1
a1252 2
            if (i == 0)
               sse_prefetchnta(p->func, x86_make_disp(p->tmp_EAX, 192));
d1257 1
a1257 1
   }
d1262 1
a1262 1

d1283 3
a1285 3
static boolean
build_vertex_emit(struct translate_sse *p,
                  struct x86_function *func, unsigned index_size)
d1293 7
a1299 7
   p->tmp_EAX = x86_make_reg(file_REG32, reg_AX);
   p->idx_ESI = x86_make_reg(file_REG32, reg_SI);
   p->outbuf_EBX = x86_make_reg(file_REG32, reg_BX);
   p->machine_EDI = x86_make_reg(file_REG32, reg_DI);
   p->count_EBP = x86_make_reg(file_REG32, reg_BP);
   p->tmp2_EDX = x86_make_reg(file_REG32, reg_DX);
   p->src_ECX = x86_make_reg(file_REG32, reg_CX);
d1305 5
a1309 9
   if (x86_target(p->func) == X86_64_WIN64_ABI) {
      /* the ABI guarantees a 16-byte aligned 32-byte "shadow space"
       * above the return address
       */
      sse2_movdqa(p->func, x86_make_disp(x86_make_reg(file_REG32, reg_SP), 8),
                  x86_make_reg(file_XMM, 6));
      sse2_movdqa(p->func,
                  x86_make_disp(x86_make_reg(file_REG32, reg_SP), 24),
                  x86_make_reg(file_XMM, 7));
d1315 3
a1317 2
   /* on non-Win64 x86-64, these are already in the right registers */
   if (x86_target(p->func) != X86_64_STD_ABI) {
d1321 2
a1322 8
      if (x86_target(p->func) != X86_32) {
         x64_mov64(p->func, p->machine_EDI, x86_fn_arg(p->func, 1));
         x64_mov64(p->func, p->idx_ESI, x86_fn_arg(p->func, 2));
      }
      else {
         x86_mov(p->func, p->machine_EDI, x86_fn_arg(p->func, 1));
         x86_mov(p->func, p->idx_ESI, x86_fn_arg(p->func, 2));
      }
d1327 1
a1327 1
   if (x86_target(p->func) != X86_32)
d1334 4
a1337 2
   if (p->use_instancing) {
      x86_mov(p->func, p->tmp2_EDX, x86_fn_arg(p->func, 4));
d1339 2
a1340 2
              x86_make_disp(p->machine_EDI,
                            get_offset(p, &p->start_instance)), p->tmp2_EDX);
d1342 3
a1344 1
      x86_mov(p->func, p->tmp_EAX, x86_fn_arg(p->func, 5));
d1378 4
a1381 4

         if (!translate_attr(p, a,
                             x86_make_disp(vb, a->input_offset),
                             x86_make_disp(p->outbuf_EBX, a->output_offset)))
d1388 4
a1391 2
      x86_lea(p->func, p->outbuf_EBX,
              x86_make_disp(p->outbuf_EBX, p->translate.key.output_stride));
d1394 2
a1395 2
       */
      incr_inputs(p, index_size);
d1414 3
a1416 1
   if (x86_target(p->func) != X86_64_STD_ABI) {
d1424 4
a1427 5
   if (x86_target(p->func) == X86_64_WIN64_ABI) {
      sse2_movdqa(p->func, x86_make_reg(file_XMM, 6),
                  x86_make_disp(x86_make_reg(file_REG32, reg_SP), 8));
      sse2_movdqa(p->func, x86_make_reg(file_XMM, 7),
                  x86_make_disp(x86_make_reg(file_REG32, reg_SP), 24));
d1435 10
a1444 4
static void
translate_sse_set_buffer(struct translate *translate,
                         unsigned buf,
                         const void *ptr, unsigned stride, unsigned max_index)
d1446 1
a1446 1
   struct translate_sse *p = (struct translate_sse *) translate;
d1449 1
a1449 1
      p->buffer[buf].base_ptr = (char *) ptr;
d1454 4
a1457 3
   if (0)
      debug_printf("%s %d/%d: %p %d\n",
                   __FUNCTION__, buf, p->nr_buffers, ptr, stride);
d1461 1
a1461 2
static void
translate_sse_release(struct translate *translate)
d1463 1
a1463 1
   struct translate_sse *p = (struct translate_sse *) translate;
d1465 4
a1468 4
   x86_release_func(&p->elt8_func);
   x86_release_func(&p->elt16_func);
   x86_release_func(&p->elt_func);
   x86_release_func(&p->linear_func);
d1474 1
a1474 2
struct translate *
translate_sse2_create(const struct translate_key *key)
d1484 1
a1484 1
   if (p == NULL)
a1485 1

a1492 2
   assert(key->nr_elements <= TRANSLATE_MAX_ATTRIBS);

d1497 1
a1497 2
         p->nr_buffers =
            MAX2(p->nr_buffers, key->element[i].input_buffer + 1);
d1507 2
a1508 4
            if (p->buffer_variant[j].buffer_index ==
                key->element[i].input_buffer
                && p->buffer_variant[j].instance_divisor ==
                key->element[i].instance_divisor) {
d1514 1
a1514 2
            p->buffer_variant[j].instance_divisor =
               key->element[i].instance_divisor;
d1518 1
a1518 2
      }
      else {
d1525 1
a1525 2
   if (0)
      debug_printf("nr_buffers: %d\n", p->nr_buffers);
d1559 1
a1559 1
      translate_sse_release(&p->translate);
d1565 1
d1568 1
a1568 2
struct translate *
translate_sse2_create(const struct translate_key *key)
@


