head	1.8;
access;
symbols
	OPENBSD_5_8:1.7.0.4
	OPENBSD_5_8_BASE:1.7
	OPENBSD_5_7:1.7.0.2
	OPENBSD_5_7_BASE:1.7
	v10_2_9:1.1.1.5
	v10_4_3:1.1.1.4
	v10_2_7:1.1.1.3
	OPENBSD_5_6:1.5.0.2
	OPENBSD_5_6_BASE:1.5
	v10_2_3:1.1.1.3
	OPENBSD_5_5:1.4.0.2
	OPENBSD_5_5_BASE:1.4
	v9_2_5:1.1.1.2
	v9_2_3:1.1.1.2
	v9_2_2:1.1.1.2
	v9_2_1:1.1.1.2
	v9_2_0:1.1.1.2
	OPENBSD_5_4:1.3.0.4
	OPENBSD_5_4_BASE:1.3
	OPENBSD_5_3:1.3.0.2
	OPENBSD_5_3_BASE:1.3
	OPENBSD_5_2:1.2.0.4
	OPENBSD_5_2_BASE:1.2
	OPENBSD_5_1_BASE:1.2
	OPENBSD_5_1:1.2.0.2
	v7_10_3:1.1.1.1
	mesa:1.1.1
	OPENBSD_5_0:1.1.0.6
	OPENBSD_5_0_BASE:1.1
	OPENBSD_4_9:1.1.0.2
	OPENBSD_4_9_BASE:1.1
	OPENBSD_4_8:1.1.0.4
	OPENBSD_4_8_BASE:1.1;
locks; strict;
comment	@ * @;


1.8
date	2015.12.23.05.17.26;	author jsg;	state dead;
branches;
next	1.7;
commitid	TnlogFl9nOv2eaRf;

1.7
date	2015.02.20.23.09.51;	author jsg;	state Exp;
branches;
next	1.6;
commitid	4ry2gvZGMXkCUD2n;

1.6
date	2015.01.25.14.41.15;	author jsg;	state Exp;
branches;
next	1.5;
commitid	mcxB0JvoI9gTDYXU;

1.5
date	2014.07.09.21.08.52;	author jsg;	state Exp;
branches;
next	1.4;
commitid	WPD6rgPryPkvXOr9;

1.4
date	2013.09.05.13.59.37;	author jsg;	state Exp;
branches;
next	1.3;

1.3
date	2012.08.17.13.58.03;	author mpi;	state Exp;
branches;
next	1.2;

1.2
date	2011.10.23.13.37.32;	author matthieu;	state Exp;
branches;
next	1.1;

1.1
date	2010.05.22.20.06.04;	author matthieu;	state Exp;
branches
	1.1.1.1;
next	;

1.1.1.1
date	2011.10.23.13.29.24;	author matthieu;	state Exp;
branches;
next	1.1.1.2;

1.1.1.2
date	2013.09.05.13.10.14;	author jsg;	state Exp;
branches;
next	1.1.1.3;

1.1.1.3
date	2014.07.09.20.33.44;	author jsg;	state Exp;
branches;
next	1.1.1.4;
commitid	3JhLfwcuBALP0ZR7;

1.1.1.4
date	2015.01.25.14.06.23;	author jsg;	state Exp;
branches;
next	1.1.1.5;
commitid	ce2W5rH5aF7VS9gi;

1.1.1.5
date	2015.02.20.22.43.30;	author jsg;	state Exp;
branches;
next	;
commitid	F54a1i0WXHMxq7kE;


desc
@@


1.8
log
@remove the now unused Mesa 10.2.9 code
@
text
@/**************************************************************************
 * 
 * Copyright 2009 VMware, Inc.
 * Copyright 2007-2008 VMware, Inc.
 * All Rights Reserved.
 * 
 * Permission is hereby granted, free of charge, to any person obtaining a
 * copy of this software and associated documentation files (the
 * "Software"), to deal in the Software without restriction, including
 * without limitation the rights to use, copy, modify, merge, publish,
 * distribute, sub license, and/or sell copies of the Software, and to
 * permit persons to whom the Software is furnished to do so, subject to
 * the following conditions:
 * 
 * The above copyright notice and this permission notice (including the
 * next paragraph) shall be included in all copies or substantial portions
 * of the Software.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
 * OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT.
 * IN NO EVENT SHALL VMWARE AND/OR ITS SUPPLIERS BE LIABLE FOR
 * ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
 * SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 **************************************************************************/

/**
 * @@file
 * TGSI to LLVM IR translation -- SoA.
 *
 * @@author Jose Fonseca <jfonseca@@vmware.com>
 *
 * Based on tgsi_sse2.c code written by Michal Krol, Keith Whitwell,
 * Brian Paul, and others.
 */

#include "pipe/p_config.h"
#include "pipe/p_shader_tokens.h"
#include "util/u_debug.h"
#include "util/u_math.h"
#include "util/u_memory.h"
#include "tgsi/tgsi_dump.h"
#include "tgsi/tgsi_exec.h"
#include "tgsi/tgsi_info.h"
#include "tgsi/tgsi_parse.h"
#include "tgsi/tgsi_util.h"
#include "tgsi/tgsi_scan.h"
#include "tgsi/tgsi_strings.h"
#include "lp_bld_tgsi_action.h"
#include "lp_bld_type.h"
#include "lp_bld_const.h"
#include "lp_bld_arit.h"
#include "lp_bld_bitarit.h"
#include "lp_bld_gather.h"
#include "lp_bld_init.h"
#include "lp_bld_logic.h"
#include "lp_bld_swizzle.h"
#include "lp_bld_flow.h"
#include "lp_bld_quad.h"
#include "lp_bld_tgsi.h"
#include "lp_bld_limits.h"
#include "lp_bld_debug.h"
#include "lp_bld_printf.h"
#include "lp_bld_sample.h"
#include "lp_bld_struct.h"

/* SM 4.0 says that subroutines can nest 32 deep and 
 * we need one more for our main function */
#define LP_MAX_NUM_FUNCS 33

#define DUMP_GS_EMITS 0

/*
 * If non-zero, the generated LLVM IR will print intermediate results on every TGSI
 * instruction.
 *
 * TODO:
 * - take execution masks in consideration
 * - debug control-flow instructions
 */
#define DEBUG_EXECUTION 0


/*
 * Emit code to print a register value.
 */
static void
emit_dump_reg(struct gallivm_state *gallivm,
              unsigned file,
              unsigned index,
              unsigned chan,
              LLVMValueRef value)
{
   char buf[32];

   util_snprintf(buf, sizeof buf, "    %s[%u].%c = ",
                 tgsi_file_name(file),
                 index, "xyzw"[chan]);

   lp_build_print_value(gallivm, buf, value);
}

/*
 * Return the context for the current function.
 * (always 'main', if shader doesn't do any function calls)
 */
static INLINE struct function_ctx *
func_ctx(struct lp_exec_mask *mask)
{
   assert(mask->function_stack_size > 0);
   assert(mask->function_stack_size <= LP_MAX_NUM_FUNCS);
   return &mask->function_stack[mask->function_stack_size - 1];
}

/*
 * Returns true if we're in a loop.
 * It's global, meaning that it returns true even if there's
 * no loop inside the current function, but we were inside
 * a loop inside another function, from which this one was called.
 */
static INLINE boolean
mask_has_loop(struct lp_exec_mask *mask)
{
   int i;
   for (i = mask->function_stack_size - 1; i >= 0; --i) {
      const struct function_ctx *ctx = &mask->function_stack[i];
      if (ctx->loop_stack_size > 0)
         return TRUE;
   }
   return FALSE;
}

/*
 * Returns true if we're inside a switch statement.
 * It's global, meaning that it returns true even if there's
 * no switch in the current function, but we were inside
 * a switch inside another function, from which this one was called.
 */
static INLINE boolean
mask_has_switch(struct lp_exec_mask *mask)
{
   int i;
   for (i = mask->function_stack_size - 1; i >= 0; --i) {
      const struct function_ctx *ctx = &mask->function_stack[i];
      if (ctx->switch_stack_size > 0)
         return TRUE;
   }
   return FALSE;
}

/*
 * Returns true if we're inside a conditional.
 * It's global, meaning that it returns true even if there's
 * no conditional in the current function, but we were inside
 * a conditional inside another function, from which this one was called.
 */
static INLINE boolean
mask_has_cond(struct lp_exec_mask *mask)
{
   int i;
   for (i = mask->function_stack_size - 1; i >= 0; --i) {
      const struct function_ctx *ctx = &mask->function_stack[i];
      if (ctx->cond_stack_size > 0)
         return TRUE;
   }
   return FALSE;
}


/*
 * Initialize a function context at the specified index.
 */
static void
lp_exec_mask_function_init(struct lp_exec_mask *mask, int function_idx)
{
   LLVMTypeRef int_type = LLVMInt32TypeInContext(mask->bld->gallivm->context);
   LLVMBuilderRef builder = mask->bld->gallivm->builder;
   struct function_ctx *ctx =  &mask->function_stack[function_idx];

   ctx->cond_stack_size = 0;
   ctx->loop_stack_size = 0;
   ctx->switch_stack_size = 0;

   if (function_idx == 0) {
      ctx->ret_mask = mask->ret_mask;
   }

   ctx->loop_limiter = lp_build_alloca(mask->bld->gallivm,
                                       int_type, "looplimiter");
   LLVMBuildStore(
      builder,
      LLVMConstInt(int_type, LP_MAX_TGSI_LOOP_ITERATIONS, false),
      ctx->loop_limiter);
}

static void lp_exec_mask_init(struct lp_exec_mask *mask, struct lp_build_context *bld)
{
   mask->bld = bld;
   mask->has_mask = FALSE;
   mask->ret_in_main = FALSE;
   /* For the main function */
   mask->function_stack_size = 1;

   mask->int_vec_type = lp_build_int_vec_type(bld->gallivm, mask->bld->type);
   mask->exec_mask = mask->ret_mask = mask->break_mask = mask->cont_mask =
         mask->cond_mask = mask->switch_mask =
         LLVMConstAllOnes(mask->int_vec_type);

   mask->function_stack = CALLOC(LP_MAX_NUM_FUNCS,
                                 sizeof(mask->function_stack[0]));
   lp_exec_mask_function_init(mask, 0);
}

static void
lp_exec_mask_fini(struct lp_exec_mask *mask)
{
   FREE(mask->function_stack);
}

static void lp_exec_mask_update(struct lp_exec_mask *mask)
{
   LLVMBuilderRef builder = mask->bld->gallivm->builder;
   boolean has_loop_mask = mask_has_loop(mask);
   boolean has_cond_mask = mask_has_cond(mask);
   boolean has_switch_mask = mask_has_switch(mask);
   boolean has_ret_mask = mask->function_stack_size > 1 ||
         mask->ret_in_main;

   if (has_loop_mask) {
      /*for loops we need to update the entire mask at runtime */
      LLVMValueRef tmp;
      assert(mask->break_mask);
      tmp = LLVMBuildAnd(builder,
                         mask->cont_mask,
                         mask->break_mask,
                         "maskcb");
      mask->exec_mask = LLVMBuildAnd(builder,
                                     mask->cond_mask,
                                     tmp,
                                     "maskfull");
   } else
      mask->exec_mask = mask->cond_mask;

   if (has_switch_mask) {
      mask->exec_mask = LLVMBuildAnd(builder,
                                     mask->exec_mask,
                                     mask->switch_mask,
                                     "switchmask");
   }

   if (has_ret_mask) {
      mask->exec_mask = LLVMBuildAnd(builder,
                                     mask->exec_mask,
                                     mask->ret_mask,
                                     "callmask");
   }

   mask->has_mask = (has_cond_mask ||
                     has_loop_mask ||
                     has_switch_mask ||
                     has_ret_mask);
}

static void lp_exec_mask_cond_push(struct lp_exec_mask *mask,
                                   LLVMValueRef val)
{
   LLVMBuilderRef builder = mask->bld->gallivm->builder;
   struct function_ctx *ctx = func_ctx(mask);

   if (ctx->cond_stack_size >= LP_MAX_TGSI_NESTING) {
      ctx->cond_stack_size++;
      return;
   }
   if (ctx->cond_stack_size == 0 && mask->function_stack_size == 1) {
      assert(mask->cond_mask == LLVMConstAllOnes(mask->int_vec_type));
   }
   ctx->cond_stack[ctx->cond_stack_size++] = mask->cond_mask;
   assert(LLVMTypeOf(val) == mask->int_vec_type);
   mask->cond_mask = LLVMBuildAnd(builder,
                                  mask->cond_mask,
                                  val,
                                  "");
   lp_exec_mask_update(mask);
}

static void lp_exec_mask_cond_invert(struct lp_exec_mask *mask)
{
   LLVMBuilderRef builder = mask->bld->gallivm->builder;
   struct function_ctx *ctx = func_ctx(mask);
   LLVMValueRef prev_mask;
   LLVMValueRef inv_mask;

   assert(ctx->cond_stack_size);
   if (ctx->cond_stack_size >= LP_MAX_TGSI_NESTING)
      return;
   prev_mask = ctx->cond_stack[ctx->cond_stack_size - 1];
   if (ctx->cond_stack_size == 1 && mask->function_stack_size == 1) {
      assert(prev_mask == LLVMConstAllOnes(mask->int_vec_type));
   }

   inv_mask = LLVMBuildNot(builder, mask->cond_mask, "");

   mask->cond_mask = LLVMBuildAnd(builder,
                                  inv_mask,
                                  prev_mask, "");
   lp_exec_mask_update(mask);
}

static void lp_exec_mask_cond_pop(struct lp_exec_mask *mask)
{
   struct function_ctx *ctx = func_ctx(mask);
   assert(ctx->cond_stack_size);
   --ctx->cond_stack_size;
   if (ctx->cond_stack_size >= LP_MAX_TGSI_NESTING)
      return;
   mask->cond_mask = ctx->cond_stack[ctx->cond_stack_size];
   lp_exec_mask_update(mask);
}

static void lp_exec_bgnloop(struct lp_exec_mask *mask)
{
   LLVMBuilderRef builder = mask->bld->gallivm->builder;
   struct function_ctx *ctx = func_ctx(mask);

   if (ctx->loop_stack_size >= LP_MAX_TGSI_NESTING) {
      ++ctx->loop_stack_size;
      return;
   }

   ctx->break_type_stack[ctx->loop_stack_size + ctx->switch_stack_size] =
      ctx->break_type;
   ctx->break_type = LP_EXEC_MASK_BREAK_TYPE_LOOP;

   ctx->loop_stack[ctx->loop_stack_size].loop_block = ctx->loop_block;
   ctx->loop_stack[ctx->loop_stack_size].cont_mask = mask->cont_mask;
   ctx->loop_stack[ctx->loop_stack_size].break_mask = mask->break_mask;
   ctx->loop_stack[ctx->loop_stack_size].break_var = ctx->break_var;
   ++ctx->loop_stack_size;

   ctx->break_var = lp_build_alloca(mask->bld->gallivm, mask->int_vec_type, "");
   LLVMBuildStore(builder, mask->break_mask, ctx->break_var);

   ctx->loop_block = lp_build_insert_new_block(mask->bld->gallivm, "bgnloop");

   LLVMBuildBr(builder, ctx->loop_block);
   LLVMPositionBuilderAtEnd(builder, ctx->loop_block);

   mask->break_mask = LLVMBuildLoad(builder, ctx->break_var, "");

   lp_exec_mask_update(mask);
}

static void lp_exec_break(struct lp_exec_mask *mask,
                          struct lp_build_tgsi_context * bld_base)
{
   LLVMBuilderRef builder = mask->bld->gallivm->builder;
   struct function_ctx *ctx = func_ctx(mask);

   if (ctx->break_type == LP_EXEC_MASK_BREAK_TYPE_LOOP) {
      LLVMValueRef exec_mask = LLVMBuildNot(builder,
                                            mask->exec_mask,
                                            "break");

      mask->break_mask = LLVMBuildAnd(builder,
                                      mask->break_mask,
                                      exec_mask, "break_full");
   }
   else {
      unsigned opcode = bld_base->instructions[bld_base->pc + 1].Instruction.Opcode;
      boolean break_always = (opcode == TGSI_OPCODE_ENDSWITCH ||
                              opcode == TGSI_OPCODE_CASE);


      if (ctx->switch_in_default) {
         /*
          * stop default execution but only if this is an unconditional switch.
          * (The condition here is not perfect since dead code after break is
          * allowed but should be sufficient since false negatives are just
          * unoptimized - so we don't have to pre-evaluate that).
          */
         if(break_always && ctx->switch_pc) {
            bld_base->pc = ctx->switch_pc;
            return;
         }
      }

      if (break_always) {
         mask->switch_mask = LLVMConstNull(mask->bld->int_vec_type);
      }
      else {
         LLVMValueRef exec_mask = LLVMBuildNot(builder,
                                               mask->exec_mask,
                                               "break");
         mask->switch_mask = LLVMBuildAnd(builder,
                                          mask->switch_mask,
                                          exec_mask, "break_switch");
      }
   }

   lp_exec_mask_update(mask);
}

static void lp_exec_break_condition(struct lp_exec_mask *mask,
                                    LLVMValueRef cond)
{
   LLVMBuilderRef builder = mask->bld->gallivm->builder;
   struct function_ctx *ctx = func_ctx(mask);
   LLVMValueRef cond_mask = LLVMBuildAnd(builder,
                                         mask->exec_mask,
                                         cond, "cond_mask");
   cond_mask = LLVMBuildNot(builder, cond_mask, "break_cond");

   if (ctx->break_type == LP_EXEC_MASK_BREAK_TYPE_LOOP) {
      mask->break_mask = LLVMBuildAnd(builder,
                                      mask->break_mask,
                                      cond_mask, "breakc_full");
   }
   else {
      mask->switch_mask = LLVMBuildAnd(builder,
                                       mask->switch_mask,
                                       cond_mask, "breakc_switch");
   }

   lp_exec_mask_update(mask);
}

static void lp_exec_continue(struct lp_exec_mask *mask)
{
   LLVMBuilderRef builder = mask->bld->gallivm->builder;
   LLVMValueRef exec_mask = LLVMBuildNot(builder,
                                         mask->exec_mask,
                                         "");

   mask->cont_mask = LLVMBuildAnd(builder,
                                  mask->cont_mask,
                                  exec_mask, "");

   lp_exec_mask_update(mask);
}


static void lp_exec_endloop(struct gallivm_state *gallivm,
                            struct lp_exec_mask *mask)
{
   LLVMBuilderRef builder = mask->bld->gallivm->builder;
   struct function_ctx *ctx = func_ctx(mask);
   LLVMBasicBlockRef endloop;
   LLVMTypeRef int_type = LLVMInt32TypeInContext(mask->bld->gallivm->context);
   LLVMTypeRef reg_type = LLVMIntTypeInContext(gallivm->context,
                                               mask->bld->type.width *
                                               mask->bld->type.length);
   LLVMValueRef i1cond, i2cond, icond, limiter;

   assert(mask->break_mask);

   
   assert(ctx->loop_stack_size);
   if (ctx->loop_stack_size > LP_MAX_TGSI_NESTING) {
      --ctx->loop_stack_size;
      return;
   }

   /*
    * Restore the cont_mask, but don't pop
    */
   mask->cont_mask = ctx->loop_stack[ctx->loop_stack_size - 1].cont_mask;
   lp_exec_mask_update(mask);

   /*
    * Unlike the continue mask, the break_mask must be preserved across loop
    * iterations
    */
   LLVMBuildStore(builder, mask->break_mask, ctx->break_var);

   /* Decrement the loop limiter */
   limiter = LLVMBuildLoad(builder, ctx->loop_limiter, "");

   limiter = LLVMBuildSub(
      builder,
      limiter,
      LLVMConstInt(int_type, 1, false),
      "");

   LLVMBuildStore(builder, limiter, ctx->loop_limiter);

   /* i1cond = (mask != 0) */
   i1cond = LLVMBuildICmp(
      builder,
      LLVMIntNE,
      LLVMBuildBitCast(builder, mask->exec_mask, reg_type, ""),
      LLVMConstNull(reg_type), "i1cond");

   /* i2cond = (looplimiter > 0) */
   i2cond = LLVMBuildICmp(
      builder,
      LLVMIntSGT,
      limiter,
      LLVMConstNull(int_type), "i2cond");

   /* if( i1cond && i2cond ) */
   icond = LLVMBuildAnd(builder, i1cond, i2cond, "");

   endloop = lp_build_insert_new_block(mask->bld->gallivm, "endloop");

   LLVMBuildCondBr(builder,
                   icond, ctx->loop_block, endloop);

   LLVMPositionBuilderAtEnd(builder, endloop);

   assert(ctx->loop_stack_size);
   --ctx->loop_stack_size;
   mask->cont_mask = ctx->loop_stack[ctx->loop_stack_size].cont_mask;
   mask->break_mask = ctx->loop_stack[ctx->loop_stack_size].break_mask;
   ctx->loop_block = ctx->loop_stack[ctx->loop_stack_size].loop_block;
   ctx->break_var = ctx->loop_stack[ctx->loop_stack_size].break_var;
   ctx->break_type = ctx->break_type_stack[ctx->loop_stack_size +
         ctx->switch_stack_size];

   lp_exec_mask_update(mask);
}

static void lp_exec_switch(struct lp_exec_mask *mask,
                           LLVMValueRef switchval)
{
   struct function_ctx *ctx = func_ctx(mask);

   if (ctx->switch_stack_size >= LP_MAX_TGSI_NESTING ||
       ctx->loop_stack_size > LP_MAX_TGSI_NESTING) {
      ctx->switch_stack_size++;
      return;
   }

   ctx->break_type_stack[ctx->loop_stack_size + ctx->switch_stack_size] =
      ctx->break_type;
   ctx->break_type = LP_EXEC_MASK_BREAK_TYPE_SWITCH;

   ctx->switch_stack[ctx->switch_stack_size].switch_mask = mask->switch_mask;
   ctx->switch_stack[ctx->switch_stack_size].switch_val = ctx->switch_val;
   ctx->switch_stack[ctx->switch_stack_size].switch_mask_default = ctx->switch_mask_default;
   ctx->switch_stack[ctx->switch_stack_size].switch_in_default = ctx->switch_in_default;
   ctx->switch_stack[ctx->switch_stack_size].switch_pc = ctx->switch_pc;
   ctx->switch_stack_size++;

   mask->switch_mask = LLVMConstNull(mask->int_vec_type);
   ctx->switch_val = switchval;
   ctx->switch_mask_default = LLVMConstNull(mask->int_vec_type);
   ctx->switch_in_default = false;
   ctx->switch_pc = 0;

   lp_exec_mask_update(mask);
}

static void lp_exec_endswitch(struct lp_exec_mask *mask,
                              struct lp_build_tgsi_context * bld_base)
{
   LLVMBuilderRef builder = mask->bld->gallivm->builder;
   struct function_ctx *ctx = func_ctx(mask);

   if (ctx->switch_stack_size > LP_MAX_TGSI_NESTING) {
      ctx->switch_stack_size--;
      return;
   }

   /* check if there's deferred default if so do it now */
   if (ctx->switch_pc && !ctx->switch_in_default) {
      LLVMValueRef prevmask, defaultmask;
      unsigned tmp_pc;
      prevmask = ctx->switch_stack[ctx->switch_stack_size - 1].switch_mask;
      defaultmask = LLVMBuildNot(builder, ctx->switch_mask_default, "sw_default_mask");
      mask->switch_mask = LLVMBuildAnd(builder, prevmask, defaultmask, "sw_mask");
      ctx->switch_in_default = true;

      lp_exec_mask_update(mask);

      assert(bld_base->instructions[ctx->switch_pc - 1].Instruction.Opcode ==
             TGSI_OPCODE_DEFAULT);

      tmp_pc = bld_base->pc;
      bld_base->pc = ctx->switch_pc;
      /*
       * re-purpose switch_pc to point to here again, since we stop execution of
       * the deferred default after next break.
       */
      ctx->switch_pc = tmp_pc - 1;

      return;
   }

   else if (ctx->switch_pc && ctx->switch_in_default) {
      assert(bld_base->pc == ctx->switch_pc + 1);
   }

   ctx->switch_stack_size--;
   mask->switch_mask = ctx->switch_stack[ctx->switch_stack_size].switch_mask;
   ctx->switch_val = ctx->switch_stack[ctx->switch_stack_size].switch_val;
   ctx->switch_mask_default = ctx->switch_stack[ctx->switch_stack_size].switch_mask_default;
   ctx->switch_in_default = ctx->switch_stack[ctx->switch_stack_size].switch_in_default;
   ctx->switch_pc = ctx->switch_stack[ctx->switch_stack_size].switch_pc;

   ctx->break_type = ctx->break_type_stack[ctx->loop_stack_size + ctx->switch_stack_size];

   lp_exec_mask_update(mask);
}

static void lp_exec_case(struct lp_exec_mask *mask,
                         LLVMValueRef caseval)
{
   LLVMBuilderRef builder = mask->bld->gallivm->builder;
   struct function_ctx *ctx = func_ctx(mask);

   LLVMValueRef casemask, prevmask;

   if (ctx->switch_stack_size > LP_MAX_TGSI_NESTING) {
      return;
   }

   /* skipping case mask evaluation here is NOT optional (not in all cases anyway). */
   if (!ctx->switch_in_default) {
      prevmask = ctx->switch_stack[ctx->switch_stack_size - 1].switch_mask;
      casemask = lp_build_cmp(mask->bld, PIPE_FUNC_EQUAL, caseval, ctx->switch_val);
      ctx->switch_mask_default = LLVMBuildOr(builder, casemask,
                                             ctx->switch_mask_default, "sw_default_mask");
      casemask = LLVMBuildOr(builder, casemask, mask->switch_mask, "");
      mask->switch_mask = LLVMBuildAnd(builder, casemask, prevmask, "sw_mask");

      lp_exec_mask_update(mask);
   }
}

/*
 * Analyse default statement in a switch.
 * \return true if default is last statement, false otherwise
 * \param default_pc_start contains pc of instruction to jump to
 *                         if default wasn't last but there's no
 *                         fallthrough into default.
 */
static boolean default_analyse_is_last(struct lp_exec_mask *mask,
                                       struct lp_build_tgsi_context * bld_base,
                                       int *default_pc_start)
{
   unsigned pc = bld_base->pc;
   struct function_ctx *ctx = func_ctx(mask);
   unsigned curr_switch_stack = ctx->switch_stack_size;

   if (ctx->switch_stack_size > LP_MAX_TGSI_NESTING) {
      return false;
   }

   /* skip over case statements which are together with default */
   while (bld_base->instructions[pc].Instruction.Opcode == TGSI_OPCODE_CASE) {
      pc++;
   }

   while (pc != -1 && pc < bld_base->num_instructions) {
      unsigned opcode = bld_base->instructions[pc].Instruction.Opcode;
      switch (opcode) {
      case TGSI_OPCODE_CASE:
         if (curr_switch_stack == ctx->switch_stack_size) {
            *default_pc_start = pc - 1;
            return false;
         }
         break;
      case TGSI_OPCODE_SWITCH:
         curr_switch_stack++;
         break;
      case TGSI_OPCODE_ENDSWITCH:
         if (curr_switch_stack == ctx->switch_stack_size) {
            *default_pc_start = pc - 1;
            return true;
         }
         curr_switch_stack--;
         break;
      }
      pc++;
   }
   /* should never arrive here */
   assert(0);
   return true;
}

static void lp_exec_default(struct lp_exec_mask *mask,
                            struct lp_build_tgsi_context * bld_base)
{
   LLVMBuilderRef builder = mask->bld->gallivm->builder;
   struct function_ctx *ctx = func_ctx(mask);

   int default_exec_pc;
   boolean default_is_last;

   if (ctx->switch_stack_size > LP_MAX_TGSI_NESTING) {
      return;
   }

   /*
    * This is a messy opcode, because it may not be always at the end and
    * there can be fallthrough in and out of it.
    */

   default_is_last = default_analyse_is_last(mask, bld_base, &default_exec_pc);
   /*
    * If it is last statement in switch (note that case statements appearing
    * "at the same time" as default don't change that) everything is just fine,
    * update switch mask and go on. This means we can handle default with
    * fallthrough INTO it without overhead, if it is last.
    */
   if (default_is_last) {
      LLVMValueRef prevmask, defaultmask;
      prevmask = ctx->switch_stack[ctx->switch_stack_size - 1].switch_mask;
      defaultmask = LLVMBuildNot(builder, ctx->switch_mask_default, "sw_default_mask");
      defaultmask = LLVMBuildOr(builder, defaultmask, mask->switch_mask, "");
      mask->switch_mask = LLVMBuildAnd(builder, prevmask, defaultmask, "sw_mask");
      ctx->switch_in_default = true;

      lp_exec_mask_update(mask);
   }
   else {
      /*
       * Technically, "case" immediately before default isn't really a
       * fallthrough, however we still have to count them as such as we
       * already have updated the masks.
       * If that happens in practice could add a switch optimizer pass
       * which just gets rid of all case statements appearing together with
       * default (or could do switch analysis at switch start time instead).
       */
      unsigned opcode = bld_base->instructions[bld_base->pc - 1].Instruction.Opcode;
      boolean ft_into = (opcode != TGSI_OPCODE_BRK &&
                         opcode != TGSI_OPCODE_SWITCH);
      /*
       * If it is not last statement and there was no fallthrough into it,
       * we record the PC and continue execution at next case (again, those
       * case encountered at the same time don't count). At endswitch
       * time, we update switchmask, and go back executing the code we skipped
       * until the next break (possibly re-executing some code with changed mask
       * if there was a fallthrough out of default).
       * Finally, if it is not last statement and there was a fallthrough into it,
       * do the same as with the former case, except instead of skipping the code
       * just execute it without updating the mask, then go back and re-execute.
       */
      ctx->switch_pc = bld_base->pc;
      if (!ft_into) {
         bld_base->pc = default_exec_pc;
      }
   }
}


/* stores val into an address pointed to by dst_ptr.
 * mask->exec_mask is used to figure out which bits of val
 * should be stored into the address
 * (0 means don't store this bit, 1 means do store).
 */
static void lp_exec_mask_store(struct lp_exec_mask *mask,
                               struct lp_build_context *bld_store,
                               LLVMValueRef pred,
                               LLVMValueRef val,
                               LLVMValueRef dst_ptr)
{
   LLVMBuilderRef builder = mask->bld->gallivm->builder;

   assert(lp_check_value(bld_store->type, val));
   assert(LLVMGetTypeKind(LLVMTypeOf(dst_ptr)) == LLVMPointerTypeKind);
   assert(LLVMGetElementType(LLVMTypeOf(dst_ptr)) == LLVMTypeOf(val));

   /* Mix the predicate and execution mask */
   if (mask->has_mask) {
      if (pred) {
         pred = LLVMBuildAnd(builder, pred, mask->exec_mask, "");
      } else {
         pred = mask->exec_mask;
      }
   }

   if (pred) {
      LLVMValueRef res, dst;

      dst = LLVMBuildLoad(builder, dst_ptr, "");
      res = lp_build_select(bld_store, pred, val, dst);
      LLVMBuildStore(builder, res, dst_ptr);
   } else
      LLVMBuildStore(builder, val, dst_ptr);
}

static void lp_exec_mask_call(struct lp_exec_mask *mask,
                              int func,
                              int *pc)
{
   if (mask->function_stack_size >= LP_MAX_NUM_FUNCS) {
      return;
   }

   lp_exec_mask_function_init(mask, mask->function_stack_size);
   mask->function_stack[mask->function_stack_size].pc = *pc;
   mask->function_stack[mask->function_stack_size].ret_mask = mask->ret_mask;
   mask->function_stack_size++;
   *pc = func;
}

static void lp_exec_mask_ret(struct lp_exec_mask *mask, int *pc)
{
   LLVMBuilderRef builder = mask->bld->gallivm->builder;
   struct function_ctx *ctx = func_ctx(mask);
   LLVMValueRef exec_mask;

   if (ctx->cond_stack_size == 0 &&
       ctx->loop_stack_size == 0 &&
       ctx->switch_stack_size == 0 &&
       mask->function_stack_size == 1) {
      /* returning from main() */
      *pc = -1;
      return;
   }

   if (mask->function_stack_size == 1) {
      /*
       * This requires special handling since we need to ensure
       * we don't drop the mask even if we have no call stack
       * (e.g. after a ret in a if clause after the endif)
       */
      mask->ret_in_main = TRUE;
   }

   exec_mask = LLVMBuildNot(builder,
                            mask->exec_mask,
                            "ret");

   mask->ret_mask = LLVMBuildAnd(builder,
                                 mask->ret_mask,
                                 exec_mask, "ret_full");

   lp_exec_mask_update(mask);
}

static void lp_exec_mask_bgnsub(struct lp_exec_mask *mask)
{
}

static void lp_exec_mask_endsub(struct lp_exec_mask *mask, int *pc)
{
   struct function_ctx *ctx;

   assert(mask->function_stack_size > 1);
   assert(mask->function_stack_size <= LP_MAX_NUM_FUNCS);

   ctx = func_ctx(mask);
   mask->function_stack_size--;

   *pc = ctx->pc;
   mask->ret_mask = ctx->ret_mask;

   lp_exec_mask_update(mask);
}


static LLVMValueRef
get_file_ptr(struct lp_build_tgsi_soa_context *bld,
             unsigned file,
             unsigned index,
             unsigned chan)
{
   LLVMBuilderRef builder = bld->bld_base.base.gallivm->builder;
   LLVMValueRef (*array_of_vars)[TGSI_NUM_CHANNELS];
   LLVMValueRef var_of_array;

   switch (file) {
   case TGSI_FILE_TEMPORARY:
      array_of_vars = bld->temps;
      var_of_array = bld->temps_array;
      break;
   case TGSI_FILE_OUTPUT:
      array_of_vars = bld->outputs;
      var_of_array = bld->outputs_array;
      break;
   default:
      assert(0);
      return NULL;
   }

   assert(chan < 4);

   if (bld->indirect_files & (1 << file)) {
      LLVMValueRef lindex = lp_build_const_int32(bld->bld_base.base.gallivm, index * 4 + chan);
      return LLVMBuildGEP(builder, var_of_array, &lindex, 1, "");
   }
   else {
      assert(index <= bld->bld_base.info->file_max[file]);
      return array_of_vars[index][chan];
   }
}


/**
 * Return pointer to a temporary register channel (src or dest).
 * Note that indirect addressing cannot be handled here.
 * \param index  which temporary register
 * \param chan  which channel of the temp register.
 */
LLVMValueRef
lp_get_temp_ptr_soa(struct lp_build_tgsi_soa_context *bld,
             unsigned index,
             unsigned chan)
{
   return get_file_ptr(bld, TGSI_FILE_TEMPORARY, index, chan);
}

/**
 * Return pointer to a output register channel (src or dest).
 * Note that indirect addressing cannot be handled here.
 * \param index  which output register
 * \param chan  which channel of the output register.
 */
LLVMValueRef
lp_get_output_ptr(struct lp_build_tgsi_soa_context *bld,
               unsigned index,
               unsigned chan)
{
   return get_file_ptr(bld, TGSI_FILE_OUTPUT, index, chan);
}

/*
 * If we have indirect addressing in outputs copy our alloca array
 * to the outputs slots specified by the caller to make sure
 * our outputs are delivered consistently via the same interface.
 */
static void
gather_outputs(struct lp_build_tgsi_soa_context * bld)
{
   if ((bld->indirect_files & (1 << TGSI_FILE_OUTPUT))) {
      unsigned index, chan;
      assert(bld->bld_base.info->num_outputs <=
             bld->bld_base.info->file_max[TGSI_FILE_OUTPUT] + 1);
      for (index = 0; index < bld->bld_base.info->num_outputs; ++index) {
         for (chan = 0; chan < TGSI_NUM_CHANNELS; ++chan) {
            bld->outputs[index][chan] = lp_get_output_ptr(bld, index, chan);
         }
      }
   }
}

/**
 * Gather vector.
 * XXX the lp_build_gather() function should be capable of doing this
 * with a little work.
 */
static LLVMValueRef
build_gather(struct lp_build_context *bld,
             LLVMValueRef base_ptr,
             LLVMValueRef indexes,
             LLVMValueRef *overflow_mask)
{
   LLVMBuilderRef builder = bld->gallivm->builder;
   LLVMValueRef res = bld->undef;
   unsigned i;
   LLVMValueRef temp_ptr;

   if (overflow_mask) {
      temp_ptr = lp_build_alloca(
         bld->gallivm,
         lp_build_vec_type(bld->gallivm, bld->type), "");
   }

   /*
    * Loop over elements of index_vec, load scalar value, insert it into 'res'.
    */
   for (i = 0; i < bld->type.length; i++) {
      LLVMValueRef ii = lp_build_const_int32(bld->gallivm, i);
      LLVMValueRef index = LLVMBuildExtractElement(builder,
                                                   indexes, ii, "");
      LLVMValueRef scalar_ptr, scalar;
      LLVMValueRef overflow;
      struct lp_build_if_state if_ctx;

      /*
       * overflow_mask is a boolean vector telling us which channels
       * in the vector overflowed. We use the overflow behavior for
       * constant buffers which is defined as:
       * Out of bounds access to constant buffer returns 0 in all
       * componenets. Out of bounds behavior is always with respect
       * to the size of the buffer bound at that slot.
       */
      if (overflow_mask) {
         overflow = LLVMBuildExtractElement(builder, *overflow_mask,
                                            ii, "");
         lp_build_if(&if_ctx, bld->gallivm, overflow);
         {
            LLVMValueRef val = LLVMBuildLoad(builder, temp_ptr, "");
            val = LLVMBuildInsertElement(
               builder, val,
               LLVMConstNull(LLVMFloatTypeInContext(bld->gallivm->context)),
               ii, "");
            LLVMBuildStore(builder, val, temp_ptr);
         }
         lp_build_else(&if_ctx);
         {
            LLVMValueRef val = LLVMBuildLoad(builder, temp_ptr, "");

            scalar_ptr = LLVMBuildGEP(builder, base_ptr,
                                      &index, 1, "gather_ptr");
            scalar = LLVMBuildLoad(builder, scalar_ptr, "");

            val = LLVMBuildInsertElement(builder, val, scalar, ii, "");

            LLVMBuildStore(builder, val, temp_ptr);
         }
         lp_build_endif(&if_ctx);
      } else {
         scalar_ptr = LLVMBuildGEP(builder, base_ptr,
                                   &index, 1, "gather_ptr");
         scalar = LLVMBuildLoad(builder, scalar_ptr, "");

         res = LLVMBuildInsertElement(builder, res, scalar, ii, "");
      }
   }

   if (overflow_mask) {
      res = LLVMBuildLoad(builder, temp_ptr, "gather_val");
   }

   return res;
}


/**
 * Scatter/store vector.
 */
static void
emit_mask_scatter(struct lp_build_tgsi_soa_context *bld,
                  LLVMValueRef base_ptr,
                  LLVMValueRef indexes,
                  LLVMValueRef values,
                  struct lp_exec_mask *mask,
                  LLVMValueRef pred)
{
   struct gallivm_state *gallivm = bld->bld_base.base.gallivm;
   LLVMBuilderRef builder = gallivm->builder;
   unsigned i;

   /* Mix the predicate and execution mask */
   if (mask->has_mask) {
      if (pred) {
         pred = LLVMBuildAnd(builder, pred, mask->exec_mask, "");
      }
      else {
         pred = mask->exec_mask;
      }
   }

   /*
    * Loop over elements of index_vec, store scalar value.
    */
   for (i = 0; i < bld->bld_base.base.type.length; i++) {
      LLVMValueRef ii = lp_build_const_int32(gallivm, i);
      LLVMValueRef index = LLVMBuildExtractElement(builder, indexes, ii, "");
      LLVMValueRef scalar_ptr = LLVMBuildGEP(builder, base_ptr, &index, 1, "scatter_ptr");
      LLVMValueRef val = LLVMBuildExtractElement(builder, values, ii, "scatter_val");
      LLVMValueRef scalar_pred = pred ?
         LLVMBuildExtractElement(builder, pred, ii, "scatter_pred") : NULL;

      if (0)
         lp_build_printf(gallivm, "scatter %d: val %f at %d %p\n",
                         ii, val, index, scalar_ptr);

      if (scalar_pred) {
         LLVMValueRef real_val, dst_val;
         dst_val = LLVMBuildLoad(builder, scalar_ptr, "");
         real_val = lp_build_select(&bld->elem_bld, scalar_pred, val, dst_val);
         LLVMBuildStore(builder, real_val, scalar_ptr);
      }
      else {
         LLVMBuildStore(builder, val, scalar_ptr);
      }
   }
}


/**
 * Read the current value of the ADDR register, convert the floats to
 * ints, add the base index and return the vector of offsets.
 * The offsets will be used to index into the constant buffer or
 * temporary register file.
 */
static LLVMValueRef
get_indirect_index(struct lp_build_tgsi_soa_context *bld,
                   unsigned reg_file, unsigned reg_index,
                   const struct tgsi_ind_register *indirect_reg)
{
   LLVMBuilderRef builder = bld->bld_base.base.gallivm->builder;
   struct lp_build_context *uint_bld = &bld->bld_base.uint_bld;
   /* always use X component of address register */
   unsigned swizzle = indirect_reg->Swizzle;
   LLVMValueRef base;
   LLVMValueRef rel;
   LLVMValueRef max_index;
   LLVMValueRef index;

   assert(bld->indirect_files & (1 << reg_file));

   base = lp_build_const_int_vec(bld->bld_base.base.gallivm, uint_bld->type, reg_index);

   assert(swizzle < 4);
   switch (indirect_reg->File) {
   case TGSI_FILE_ADDRESS:
      rel = LLVMBuildLoad(builder,
                          bld->addr[indirect_reg->Index][swizzle],
                          "load addr reg");
      /* ADDR LLVM values already have LLVM integer type. */
      break;
   case TGSI_FILE_TEMPORARY:
      rel = lp_get_temp_ptr_soa(bld, indirect_reg->Index, swizzle);
      rel = LLVMBuildLoad(builder, rel, "load temp reg");
      /* TEMP LLVM values always have LLVM float type, but for indirection, the
       * value actually stored is expected to be an integer */
      rel = LLVMBuildBitCast(builder, rel, uint_bld->vec_type, "");
      break;
   default:
      assert(0);
      rel = uint_bld->zero;
   }

   index = lp_build_add(uint_bld, base, rel);

   /*
    * emit_fetch_constant handles constant buffer overflow so this code
    * is pointless for them.
    * Furthermore the D3D10 spec in section 6.5 says:
    * If the constant buffer bound to a slot is larger than the size
    * declared in the shader for that slot, implementations are allowed
    * to return incorrect data (not necessarily 0) for indices that are
    * larger than the declared size but smaller than the buffer size.
    */
   if (reg_file != TGSI_FILE_CONSTANT) {
      max_index = lp_build_const_int_vec(bld->bld_base.base.gallivm,
                                         uint_bld->type,
                                         bld->bld_base.info->file_max[reg_file]);

      assert(!uint_bld->type.sign);
      index = lp_build_min(uint_bld, index, max_index);
   }

   return index;
}

static struct lp_build_context *
stype_to_fetch(struct lp_build_tgsi_context * bld_base,
	       enum tgsi_opcode_type stype)
{
   struct lp_build_context *bld_fetch;

   switch (stype) {
   case TGSI_TYPE_FLOAT:
   case TGSI_TYPE_UNTYPED:
      bld_fetch = &bld_base->base;
      break;
   case TGSI_TYPE_UNSIGNED:
      bld_fetch = &bld_base->uint_bld;
      break;
   case TGSI_TYPE_SIGNED:
      bld_fetch = &bld_base->int_bld;
      break;
   case TGSI_TYPE_VOID:
   case TGSI_TYPE_DOUBLE:
   default:
      assert(0);
      bld_fetch = NULL;
      break;
   }
   return bld_fetch;
}

static LLVMValueRef
get_soa_array_offsets(struct lp_build_context *uint_bld,
                      LLVMValueRef indirect_index,
                      unsigned chan_index,
                      boolean need_perelement_offset)
{
   struct gallivm_state *gallivm = uint_bld->gallivm;
   LLVMValueRef chan_vec =
      lp_build_const_int_vec(uint_bld->gallivm, uint_bld->type, chan_index);
   LLVMValueRef length_vec =
      lp_build_const_int_vec(gallivm, uint_bld->type, uint_bld->type.length);
   LLVMValueRef index_vec;

   /* index_vec = (indirect_index * 4 + chan_index) * length + offsets */
   index_vec = lp_build_shl_imm(uint_bld, indirect_index, 2);
   index_vec = lp_build_add(uint_bld, index_vec, chan_vec);
   index_vec = lp_build_mul(uint_bld, index_vec, length_vec);

   if (need_perelement_offset) {
      LLVMValueRef pixel_offsets;
      int i;
     /* build pixel offset vector: {0, 1, 2, 3, ...} */
      pixel_offsets = uint_bld->undef;
      for (i = 0; i < uint_bld->type.length; i++) {
         LLVMValueRef ii = lp_build_const_int32(gallivm, i);
         pixel_offsets = LLVMBuildInsertElement(gallivm->builder, pixel_offsets,
                                                ii, ii, "");
      }
      index_vec = lp_build_add(uint_bld, index_vec, pixel_offsets);
   }
   return index_vec;
}

static LLVMValueRef
emit_fetch_constant(
   struct lp_build_tgsi_context * bld_base,
   const struct tgsi_full_src_register * reg,
   enum tgsi_opcode_type stype,
   unsigned swizzle)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
   struct gallivm_state *gallivm = bld_base->base.gallivm;
   LLVMBuilderRef builder = gallivm->builder;
   struct lp_build_context *uint_bld = &bld_base->uint_bld;
   unsigned dimension = 0;
   LLVMValueRef dimension_index;
   LLVMValueRef consts_ptr;
   LLVMValueRef num_consts;
   LLVMValueRef res;

   /* XXX: Handle fetching xyzw components as a vector */
   assert(swizzle != ~0);

   if (reg->Register.Dimension) {
      assert(!reg->Dimension.Indirect);
      dimension = reg->Dimension.Index;
      assert(dimension < LP_MAX_TGSI_CONST_BUFFERS);
   }

   dimension_index = lp_build_const_int32(gallivm, dimension);
   consts_ptr =
      lp_build_array_get(gallivm, bld->consts_ptr, dimension_index);
   num_consts =
      lp_build_array_get(gallivm, bld->const_sizes_ptr, dimension_index);

   if (reg->Register.Indirect) {
      LLVMValueRef indirect_index;
      LLVMValueRef swizzle_vec =
         lp_build_const_int_vec(gallivm, uint_bld->type, swizzle);
      LLVMValueRef index_vec;  /* index into the const buffer */
      LLVMValueRef overflow_mask;

      indirect_index = get_indirect_index(bld,
                                          reg->Register.File,
                                          reg->Register.Index,
                                          &reg->Indirect);

      /* All fetches are from the same constant buffer, so
       * we need to propagate the size to a vector to do a
       * vector comparison */
      num_consts = lp_build_broadcast_scalar(uint_bld, num_consts);
      /* Construct a boolean vector telling us which channels
       * overflow the bound constant buffer */
      overflow_mask = LLVMBuildICmp(builder, LLVMIntUGE,
                                    indirect_index,
                                    num_consts, "");

      /* index_vec = indirect_index * 4 + swizzle */
      index_vec = lp_build_shl_imm(uint_bld, indirect_index, 2);
      index_vec = lp_build_add(uint_bld, index_vec, swizzle_vec);

      /* Gather values from the constant buffer */
      res = build_gather(&bld_base->base, consts_ptr, index_vec,
                         &overflow_mask);
   }
   else {
      LLVMValueRef index;  /* index into the const buffer */
      LLVMValueRef scalar, scalar_ptr;

      index = lp_build_const_int32(gallivm, reg->Register.Index * 4 + swizzle);

      scalar_ptr = LLVMBuildGEP(builder, consts_ptr,
                                &index, 1, "");
      scalar = LLVMBuildLoad(builder, scalar_ptr, "");
      res = lp_build_broadcast_scalar(&bld_base->base, scalar);
   }

   if (stype == TGSI_TYPE_SIGNED || stype == TGSI_TYPE_UNSIGNED) {
      struct lp_build_context *bld_fetch = stype_to_fetch(bld_base, stype);
      res = LLVMBuildBitCast(builder, res, bld_fetch->vec_type, "");
   }

   return res;
}

static LLVMValueRef
emit_fetch_immediate(
   struct lp_build_tgsi_context * bld_base,
   const struct tgsi_full_src_register * reg,
   enum tgsi_opcode_type stype,
   unsigned swizzle)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
   struct gallivm_state *gallivm = bld->bld_base.base.gallivm;
   LLVMBuilderRef builder = gallivm->builder;
   LLVMValueRef res = NULL;

   if (bld->use_immediates_array || reg->Register.Indirect) {
      LLVMValueRef imms_array;
      LLVMTypeRef fptr_type;

      /* cast imms_array pointer to float* */
      fptr_type = LLVMPointerType(LLVMFloatTypeInContext(gallivm->context), 0);
      imms_array = LLVMBuildBitCast(builder, bld->imms_array, fptr_type, "");

      if (reg->Register.Indirect) {
         LLVMValueRef indirect_index;
         LLVMValueRef index_vec;  /* index into the immediate register array */

         indirect_index = get_indirect_index(bld,
                                             reg->Register.File,
                                             reg->Register.Index,
                                             &reg->Indirect);
         /*
          * Unlike for other reg classes, adding pixel offsets is unnecessary -
          * immediates are stored as full vectors (FIXME??? - might be better
          * to store them the same as constants) but all elements are the same
          * in any case.
          */
         index_vec = get_soa_array_offsets(&bld_base->uint_bld,
                                           indirect_index,
                                           swizzle,
                                           FALSE);

         /* Gather values from the immediate register array */
         res = build_gather(&bld_base->base, imms_array, index_vec, NULL);
      } else {
         LLVMValueRef lindex = lp_build_const_int32(gallivm,
                                        reg->Register.Index * 4 + swizzle);
         LLVMValueRef imms_ptr =  LLVMBuildGEP(builder,
                                                bld->imms_array, &lindex, 1, "");
         res = LLVMBuildLoad(builder, imms_ptr, "");
      }
   }
   else {
      res = bld->immediates[reg->Register.Index][swizzle];
   }

   if (stype == TGSI_TYPE_UNSIGNED) {
      res = LLVMBuildBitCast(builder, res, bld_base->uint_bld.vec_type, "");
   } else if (stype == TGSI_TYPE_SIGNED) {
      res = LLVMBuildBitCast(builder, res, bld_base->int_bld.vec_type, "");
   }
   return res;
}

static LLVMValueRef
emit_fetch_input(
   struct lp_build_tgsi_context * bld_base,
   const struct tgsi_full_src_register * reg,
   enum tgsi_opcode_type stype,
   unsigned swizzle)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
   struct gallivm_state *gallivm = bld->bld_base.base.gallivm;
   LLVMBuilderRef builder = gallivm->builder;
   LLVMValueRef res;

   if (reg->Register.Indirect) {
      LLVMValueRef indirect_index;
      LLVMValueRef index_vec;  /* index into the input reg array */
      LLVMValueRef inputs_array;
      LLVMTypeRef fptr_type;

      indirect_index = get_indirect_index(bld,
                                          reg->Register.File,
                                          reg->Register.Index,
                                          &reg->Indirect);

      index_vec = get_soa_array_offsets(&bld_base->uint_bld,
                                        indirect_index,
                                        swizzle,
                                        TRUE);

      /* cast inputs_array pointer to float* */
      fptr_type = LLVMPointerType(LLVMFloatTypeInContext(gallivm->context), 0);
      inputs_array = LLVMBuildBitCast(builder, bld->inputs_array, fptr_type, "");

      /* Gather values from the input register array */
      res = build_gather(&bld_base->base, inputs_array, index_vec, NULL);
   } else {
      if (bld->indirect_files & (1 << TGSI_FILE_INPUT)) {
         LLVMValueRef lindex = lp_build_const_int32(gallivm,
                                        reg->Register.Index * 4 + swizzle);
         LLVMValueRef input_ptr =  LLVMBuildGEP(builder,
                                                bld->inputs_array, &lindex, 1, "");
         res = LLVMBuildLoad(builder, input_ptr, "");
      }
      else {
         res = bld->inputs[reg->Register.Index][swizzle];
      }
   }

   assert(res);

   if (stype == TGSI_TYPE_UNSIGNED) {
      res = LLVMBuildBitCast(builder, res, bld_base->uint_bld.vec_type, "");
   } else if (stype == TGSI_TYPE_SIGNED) {
      res = LLVMBuildBitCast(builder, res, bld_base->int_bld.vec_type, "");
   }

   return res;
}


static LLVMValueRef
emit_fetch_gs_input(
   struct lp_build_tgsi_context * bld_base,
   const struct tgsi_full_src_register * reg,
   enum tgsi_opcode_type stype,
   unsigned swizzle)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
   struct gallivm_state *gallivm = bld->bld_base.base.gallivm;
   LLVMBuilderRef builder = gallivm->builder;
   LLVMValueRef attrib_index = NULL;
   LLVMValueRef vertex_index = NULL;
   LLVMValueRef swizzle_index = lp_build_const_int32(gallivm, swizzle);
   LLVMValueRef res;

   if (reg->Register.Indirect) {
      attrib_index = get_indirect_index(bld,
                                        reg->Register.File,
                                        reg->Register.Index,
                                        &reg->Indirect);
   } else {
      attrib_index = lp_build_const_int32(gallivm, reg->Register.Index);
   }
   
   if (reg->Dimension.Indirect) {
      vertex_index = get_indirect_index(bld,
                                        reg->Register.File,
                                        reg->Dimension.Index,
                                        &reg->DimIndirect);
   } else {
      vertex_index = lp_build_const_int32(gallivm, reg->Dimension.Index);
   }

   res = bld->gs_iface->fetch_input(bld->gs_iface, bld_base,
                                    reg->Dimension.Indirect,
                                    vertex_index,
                                    reg->Register.Indirect,
                                    attrib_index,
                                    swizzle_index);

   assert(res);

   if (stype == TGSI_TYPE_UNSIGNED) {
      res = LLVMBuildBitCast(builder, res, bld_base->uint_bld.vec_type, "");
   } else if (stype == TGSI_TYPE_SIGNED) {
      res = LLVMBuildBitCast(builder, res, bld_base->int_bld.vec_type, "");
   }

   return res;
}

static LLVMValueRef
emit_fetch_temporary(
   struct lp_build_tgsi_context * bld_base,
   const struct tgsi_full_src_register * reg,
   enum tgsi_opcode_type stype,
   unsigned swizzle)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
   struct gallivm_state *gallivm = bld->bld_base.base.gallivm;
   LLVMBuilderRef builder = gallivm->builder;
   LLVMValueRef res;

   if (reg->Register.Indirect) {
      LLVMValueRef indirect_index;
      LLVMValueRef index_vec;  /* index into the temp reg array */
      LLVMValueRef temps_array;
      LLVMTypeRef fptr_type;

      indirect_index = get_indirect_index(bld,
                                          reg->Register.File,
                                          reg->Register.Index,
                                          &reg->Indirect);

      index_vec = get_soa_array_offsets(&bld_base->uint_bld,
                                        indirect_index,
                                        swizzle,
                                        TRUE);

      /* cast temps_array pointer to float* */
      fptr_type = LLVMPointerType(LLVMFloatTypeInContext(gallivm->context), 0);
      temps_array = LLVMBuildBitCast(builder, bld->temps_array, fptr_type, "");

      /* Gather values from the temporary register array */
      res = build_gather(&bld_base->base, temps_array, index_vec, NULL);
   }
   else {
      LLVMValueRef temp_ptr;
      temp_ptr = lp_get_temp_ptr_soa(bld, reg->Register.Index, swizzle);
      res = LLVMBuildLoad(builder, temp_ptr, "");
   }

   if (stype == TGSI_TYPE_SIGNED || stype == TGSI_TYPE_UNSIGNED) {
      struct lp_build_context *bld_fetch = stype_to_fetch(bld_base, stype);
      res = LLVMBuildBitCast(builder, res, bld_fetch->vec_type, "");
   }

   return res;
}

static LLVMValueRef
emit_fetch_system_value(
   struct lp_build_tgsi_context * bld_base,
   const struct tgsi_full_src_register * reg,
   enum tgsi_opcode_type stype,
   unsigned swizzle)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
   struct gallivm_state *gallivm = bld->bld_base.base.gallivm;
   const struct tgsi_shader_info *info = bld->bld_base.info;
   LLVMBuilderRef builder = gallivm->builder;
   LLVMValueRef res;
   enum tgsi_opcode_type atype; // Actual type of the value

   assert(!reg->Register.Indirect);

   switch (info->system_value_semantic_name[reg->Register.Index]) {
   case TGSI_SEMANTIC_INSTANCEID:
      res = lp_build_broadcast_scalar(&bld_base->uint_bld, bld->system_values.instance_id);
      atype = TGSI_TYPE_UNSIGNED;
      break;

   case TGSI_SEMANTIC_VERTEXID:
      res = bld->system_values.vertex_id;
      atype = TGSI_TYPE_UNSIGNED;
      break;

   case TGSI_SEMANTIC_PRIMID:
      res = bld->system_values.prim_id;
      atype = TGSI_TYPE_UNSIGNED;
      break;

   default:
      assert(!"unexpected semantic in emit_fetch_system_value");
      res = bld_base->base.zero;
      atype = TGSI_TYPE_FLOAT;
      break;
   }

   if (atype != stype) {
      if (stype == TGSI_TYPE_FLOAT) {
         res = LLVMBuildBitCast(builder, res, bld_base->base.vec_type, "");
      } else if (stype == TGSI_TYPE_UNSIGNED) {
         res = LLVMBuildBitCast(builder, res, bld_base->uint_bld.vec_type, "");
      } else if (stype == TGSI_TYPE_SIGNED) {
         res = LLVMBuildBitCast(builder, res, bld_base->int_bld.vec_type, "");
      }
   }

   return res;
}

/**
 * Register fetch with derivatives.
 */
static void
emit_fetch_deriv(
   struct lp_build_tgsi_soa_context *bld,
   LLVMValueRef src,
   LLVMValueRef *res,
   LLVMValueRef *ddx,
   LLVMValueRef *ddy)
{
   if(res)
      *res = src;

   /* TODO: use interpolation coeffs for inputs */

   if(ddx)
      *ddx = lp_build_ddx(&bld->bld_base.base, src);

   if(ddy)
      *ddy = lp_build_ddy(&bld->bld_base.base, src);
}


/**
 * Predicate.
 */
static void
emit_fetch_predicate(
   struct lp_build_tgsi_soa_context *bld,
   const struct tgsi_full_instruction *inst,
   LLVMValueRef *pred)
{
   LLVMBuilderRef builder = bld->bld_base.base.gallivm->builder;
   unsigned index;
   unsigned char swizzles[4];
   LLVMValueRef unswizzled[4] = {NULL, NULL, NULL, NULL};
   LLVMValueRef value;
   unsigned chan;

   if (!inst->Instruction.Predicate) {
      TGSI_FOR_EACH_CHANNEL( chan ) {
         pred[chan] = NULL;
      }
      return;
   }

   swizzles[0] = inst->Predicate.SwizzleX;
   swizzles[1] = inst->Predicate.SwizzleY;
   swizzles[2] = inst->Predicate.SwizzleZ;
   swizzles[3] = inst->Predicate.SwizzleW;

   index = inst->Predicate.Index;
   assert(index < LP_MAX_TGSI_PREDS);

   TGSI_FOR_EACH_CHANNEL( chan ) {
      unsigned swizzle = swizzles[chan];

      /*
       * Only fetch the predicate register channels that are actually listed
       * in the swizzles
       */
      if (!unswizzled[swizzle]) {
         value = LLVMBuildLoad(builder,
                               bld->preds[index][swizzle], "");

         /*
          * Convert the value to an integer mask.
          *
          * TODO: Short-circuit this comparison -- a D3D setp_xx instructions
          * is needlessly causing two comparisons due to storing the intermediate
          * result as float vector instead of an integer mask vector.
          */
         value = lp_build_compare(bld->bld_base.base.gallivm,
                                  bld->bld_base.base.type,
                                  PIPE_FUNC_NOTEQUAL,
                                  value,
                                  bld->bld_base.base.zero);
         if (inst->Predicate.Negate) {
            value = LLVMBuildNot(builder, value, "");
         }

         unswizzled[swizzle] = value;
      } else {
         value = unswizzled[swizzle];
      }

      pred[chan] = value;
   }
}


/**
 * Register store.
 */
static void
emit_store_chan(
   struct lp_build_tgsi_context *bld_base,
   const struct tgsi_full_instruction *inst,
   unsigned index,
   unsigned chan_index,
   LLVMValueRef pred,
   LLVMValueRef value)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
   struct gallivm_state *gallivm = bld_base->base.gallivm;
   LLVMBuilderRef builder = gallivm->builder;
   const struct tgsi_full_dst_register *reg = &inst->Dst[index];
   struct lp_build_context *float_bld = &bld_base->base;
   struct lp_build_context *int_bld = &bld_base->int_bld;
   LLVMValueRef indirect_index = NULL;
   enum tgsi_opcode_type dtype = tgsi_opcode_infer_dst_type(inst->Instruction.Opcode);

   /*
    * Apply saturation.
    *
    * It is always assumed to be float.
    */
   switch( inst->Instruction.Saturate ) {
   case TGSI_SAT_NONE:
      break;

   case TGSI_SAT_ZERO_ONE:
      assert(dtype == TGSI_TYPE_FLOAT ||
             dtype == TGSI_TYPE_UNTYPED);
      value = LLVMBuildBitCast(builder, value, float_bld->vec_type, "");
      value = lp_build_clamp_zero_one_nanzero(float_bld, value);
      break;

   case TGSI_SAT_MINUS_PLUS_ONE:
      assert(dtype == TGSI_TYPE_FLOAT ||
             dtype == TGSI_TYPE_UNTYPED);
      value = LLVMBuildBitCast(builder, value, float_bld->vec_type, "");
      /* This will give -1.0 for NaN which is probably not what we want. */
      value = lp_build_max_ext(float_bld, value,
                               lp_build_const_vec(gallivm, float_bld->type, -1.0),
                               GALLIVM_NAN_RETURN_OTHER_SECOND_NONNAN);
      value = lp_build_min(float_bld, value, float_bld->one);
      break;

   default:
      assert(0);
   }

   if (reg->Register.Indirect) {
      indirect_index = get_indirect_index(bld,
                                          reg->Register.File,
                                          reg->Register.Index,
                                          &reg->Indirect);
   } else {
      assert(reg->Register.Index <=
                             bld_base->info->file_max[reg->Register.File]);
   }

   if (DEBUG_EXECUTION) {
      emit_dump_reg(gallivm, reg->Register.File, reg->Register.Index, chan_index, value);
   }

   switch( reg->Register.File ) {
   case TGSI_FILE_OUTPUT:
      /* Outputs are always stored as floats */
      value = LLVMBuildBitCast(builder, value, float_bld->vec_type, "");

      if (reg->Register.Indirect) {
         LLVMValueRef index_vec;  /* indexes into the output registers */
         LLVMValueRef outputs_array;
         LLVMTypeRef fptr_type;

         index_vec = get_soa_array_offsets(&bld_base->uint_bld,
                                           indirect_index,
                                           chan_index,
                                           TRUE);

         fptr_type = LLVMPointerType(LLVMFloatTypeInContext(gallivm->context), 0);
         outputs_array = LLVMBuildBitCast(builder, bld->outputs_array, fptr_type, "");

         /* Scatter store values into output registers */
         emit_mask_scatter(bld, outputs_array, index_vec, value,
                           &bld->exec_mask, pred);
      }
      else {
         LLVMValueRef out_ptr = lp_get_output_ptr(bld, reg->Register.Index,
                                                  chan_index);
         lp_exec_mask_store(&bld->exec_mask, float_bld, pred, value, out_ptr);
      }
      break;

   case TGSI_FILE_TEMPORARY:
      /* Temporaries are always stored as floats */
      value = LLVMBuildBitCast(builder, value, float_bld->vec_type, "");

      if (reg->Register.Indirect) {
         LLVMValueRef index_vec;  /* indexes into the temp registers */
         LLVMValueRef temps_array;
         LLVMTypeRef fptr_type;

         index_vec = get_soa_array_offsets(&bld_base->uint_bld,
                                           indirect_index,
                                           chan_index,
                                           TRUE);

         fptr_type = LLVMPointerType(LLVMFloatTypeInContext(gallivm->context), 0);
         temps_array = LLVMBuildBitCast(builder, bld->temps_array, fptr_type, "");

         /* Scatter store values into temp registers */
         emit_mask_scatter(bld, temps_array, index_vec, value,
                           &bld->exec_mask, pred);
      }
      else {
         LLVMValueRef temp_ptr;
         temp_ptr = lp_get_temp_ptr_soa(bld, reg->Register.Index, chan_index);
         lp_exec_mask_store(&bld->exec_mask, float_bld, pred, value, temp_ptr);
      }
      break;

   case TGSI_FILE_ADDRESS:
      assert(dtype == TGSI_TYPE_SIGNED);
      assert(LLVMTypeOf(value) == int_bld->vec_type);
      value = LLVMBuildBitCast(builder, value, int_bld->vec_type, "");
      lp_exec_mask_store(&bld->exec_mask, int_bld, pred, value,
                         bld->addr[reg->Register.Index][chan_index]);
      break;

   case TGSI_FILE_PREDICATE:
      assert(LLVMTypeOf(value) == float_bld->vec_type);
      value = LLVMBuildBitCast(builder, value, float_bld->vec_type, "");
      lp_exec_mask_store(&bld->exec_mask, float_bld, pred, value,
                         bld->preds[reg->Register.Index][chan_index]);
      break;

   default:
      assert( 0 );
   }

   (void)dtype;
}

/*
 * Called at the beginning of the translation of each TGSI instruction, to
 * emit some debug code.
 */
static void
emit_debug(
   struct lp_build_tgsi_context * bld_base,
   const struct tgsi_full_instruction * inst,
   const struct tgsi_opcode_info * info)

{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);

   if (DEBUG_EXECUTION) {
      /*
       * Dump the TGSI instruction.
       */

      struct gallivm_state *gallivm = bld_base->base.gallivm;
      char buf[512];
      buf[0] = '$';
      buf[1] = ' ';
      tgsi_dump_instruction_str(inst, bld_base->pc, &buf[2], sizeof buf - 2);
      lp_build_printf(gallivm, buf);

      /* Dump the execution mask.
       */
      if (bld->exec_mask.has_mask) {
         lp_build_print_value(gallivm, "    mask = ", bld->exec_mask.exec_mask);
      }
   }
}

static void
emit_store(
   struct lp_build_tgsi_context * bld_base,
   const struct tgsi_full_instruction * inst,
   const struct tgsi_opcode_info * info,
   LLVMValueRef dst[4])

{
   unsigned chan_index;
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);

   if(info->num_dst) {
      LLVMValueRef pred[TGSI_NUM_CHANNELS];

      emit_fetch_predicate( bld, inst, pred );

      TGSI_FOR_EACH_DST0_ENABLED_CHANNEL( inst, chan_index ) {
         emit_store_chan(bld_base, inst, 0, chan_index, pred[chan_index], dst[chan_index]);
      }
   }
}

static unsigned
tgsi_to_pipe_tex_target(unsigned tgsi_target)
{
   switch (tgsi_target) {
   case TGSI_TEXTURE_BUFFER:
      return PIPE_BUFFER;
   case TGSI_TEXTURE_1D:
   case TGSI_TEXTURE_SHADOW1D:
      return PIPE_TEXTURE_1D;
   case TGSI_TEXTURE_2D:
   case TGSI_TEXTURE_SHADOW2D:
   case TGSI_TEXTURE_2D_MSAA:
      return PIPE_TEXTURE_2D;
   case TGSI_TEXTURE_3D:
      return PIPE_TEXTURE_3D;
   case TGSI_TEXTURE_CUBE:
   case TGSI_TEXTURE_SHADOWCUBE:
      return PIPE_TEXTURE_CUBE;
   case TGSI_TEXTURE_RECT:
   case TGSI_TEXTURE_SHADOWRECT:
      return PIPE_TEXTURE_RECT;
   case TGSI_TEXTURE_1D_ARRAY:
   case TGSI_TEXTURE_SHADOW1D_ARRAY:
      return PIPE_TEXTURE_1D_ARRAY;
   case TGSI_TEXTURE_2D_ARRAY:
   case TGSI_TEXTURE_SHADOW2D_ARRAY:
   case TGSI_TEXTURE_2D_ARRAY_MSAA:
      return PIPE_TEXTURE_2D_ARRAY;
   case TGSI_TEXTURE_CUBE_ARRAY:
   case TGSI_TEXTURE_SHADOWCUBE_ARRAY:
      return PIPE_TEXTURE_CUBE_ARRAY;
   default:
      assert(0);
      return PIPE_BUFFER;
   }
}


static enum lp_sampler_lod_property
lp_build_lod_property(
   struct lp_build_tgsi_context *bld_base,
   const struct tgsi_full_instruction *inst,
   unsigned src_op)
{
   const struct tgsi_full_src_register *reg = &inst->Src[src_op];
   enum lp_sampler_lod_property lod_property;

   /*
    * Not much we can do here. We could try catching inputs declared
    * with constant interpolation but not sure it's worth it - since for
    * TEX opcodes as well as FETCH/LD the lod comes from same reg as
    * the coords, so it could only work for SAMPLE/TXQ/SVIEWINFO), just
    * like the constant/immediate recognition below.
    * What seems to be of more value would be to recognize temps holding
    * broadcasted scalars but no way we can do it.
    * Tried asking llvm but without any success (using LLVMIsConstant
    * even though this isn't exactly what we'd need), even as simple as
    * IMM[0] UINT32 (0,-1,0,0)
    * MOV TEMP[0] IMM[0].yyyy
    * SVIEWINFO TEMP[1], TEMP[0].xxxx, SVIEWINFO[0]
    * doesn't work.
    * This means there's ZERO chance this will ever catch a scalar lod
    * with traditional tex opcodes as well as texel fetches, since the lod
    * comes from the same reg as coords (except some test shaders using
    * constant coords maybe).
    * There's at least hope for sample opcodes as well as size queries.
    */
   if (reg->Register.File == TGSI_FILE_CONSTANT ||
       reg->Register.File == TGSI_FILE_IMMEDIATE) {
      lod_property = LP_SAMPLER_LOD_SCALAR;
   }
   else if (bld_base->info->processor == TGSI_PROCESSOR_FRAGMENT) {
      if (gallivm_debug & GALLIVM_DEBUG_NO_QUAD_LOD) {
         lod_property = LP_SAMPLER_LOD_PER_ELEMENT;
      }
      else {
         lod_property = LP_SAMPLER_LOD_PER_QUAD;
      }
   }
   else {
      /* never use scalar (per-quad) lod the results are just too wrong. */
      lod_property = LP_SAMPLER_LOD_PER_ELEMENT;
   }
   return lod_property;
}


/**
 * High-level instruction translators.
 */

static void
emit_tex( struct lp_build_tgsi_soa_context *bld,
          const struct tgsi_full_instruction *inst,
          enum lp_build_tex_modifier modifier,
          LLVMValueRef *texel)
{
   unsigned unit;
   LLVMValueRef lod_bias, explicit_lod;
   LLVMValueRef oow = NULL;
   LLVMValueRef coords[5];
   LLVMValueRef offsets[3] = { NULL };
   struct lp_derivatives derivs;
   struct lp_derivatives *deriv_ptr = NULL;
   enum lp_sampler_lod_property lod_property = LP_SAMPLER_LOD_SCALAR;
   unsigned num_derivs, num_offsets, i;
   unsigned shadow_coord = 0;
   unsigned layer_coord = 0;

   if (!bld->sampler) {
      _debug_printf("warning: found texture instruction but no sampler generator supplied\n");
      for (i = 0; i < 4; i++) {
         texel[i] = bld->bld_base.base.undef;
      }
      return;
   }

   switch (inst->Texture.Texture) {
   case TGSI_TEXTURE_1D_ARRAY:
      layer_coord = 1;
      /* fallthrough */
   case TGSI_TEXTURE_1D:
      num_offsets = 1;
      num_derivs = 1;
      break;
   case TGSI_TEXTURE_2D_ARRAY:
      layer_coord = 2;
      /* fallthrough */
   case TGSI_TEXTURE_2D:
   case TGSI_TEXTURE_RECT:
      num_offsets = 2;
      num_derivs = 2;
      break;
   case TGSI_TEXTURE_SHADOW1D_ARRAY:
      layer_coord = 1;
      /* fallthrough */
   case TGSI_TEXTURE_SHADOW1D:
      shadow_coord = 2;
      num_offsets = 1;
      num_derivs = 1;
      break;
   case TGSI_TEXTURE_SHADOW2D_ARRAY:
      layer_coord = 2;
      shadow_coord = 3;
      num_offsets = 2;
      num_derivs = 2;
      break;
   case TGSI_TEXTURE_SHADOW2D:
   case TGSI_TEXTURE_SHADOWRECT:
      shadow_coord = 2;
      num_offsets = 2;
      num_derivs = 2;
      break;
   case TGSI_TEXTURE_CUBE:
      num_offsets = 2;
      num_derivs = 3;
      break;
   case TGSI_TEXTURE_3D:
      num_offsets = 3;
      num_derivs = 3;
      break;
   case TGSI_TEXTURE_SHADOWCUBE:
      shadow_coord = 3;
      num_offsets = 2;
      num_derivs = 3;
      break;
   case TGSI_TEXTURE_CUBE_ARRAY:
   case TGSI_TEXTURE_SHADOWCUBE_ARRAY:
   case TGSI_TEXTURE_2D_MSAA:
   case TGSI_TEXTURE_2D_ARRAY_MSAA:
   default:
      assert(0);
      return;
   }

   /* Note lod and especially projected are illegal in a LOT of cases */
   if (modifier == LP_BLD_TEX_MODIFIER_LOD_BIAS ||
       modifier == LP_BLD_TEX_MODIFIER_EXPLICIT_LOD) {
      LLVMValueRef lod = lp_build_emit_fetch(&bld->bld_base, inst, 0, 3);
      if (modifier == LP_BLD_TEX_MODIFIER_LOD_BIAS) {
         lod_bias = lod;
         explicit_lod = NULL;
      }
      else if (modifier == LP_BLD_TEX_MODIFIER_EXPLICIT_LOD) {
         lod_bias = NULL;
         explicit_lod = lod;
      }
      lod_property = lp_build_lod_property(&bld->bld_base, inst, 0);
   }
   else {
      lod_bias = NULL;
      explicit_lod = NULL;
   }

   if (modifier == LP_BLD_TEX_MODIFIER_PROJECTED) {
      oow = lp_build_emit_fetch(&bld->bld_base, inst, 0, 3);
      oow = lp_build_rcp(&bld->bld_base.base, oow);
   }

   for (i = 0; i < num_derivs; i++) {
      coords[i] = lp_build_emit_fetch(&bld->bld_base, inst, 0, i);
      if (modifier == LP_BLD_TEX_MODIFIER_PROJECTED)
         coords[i] = lp_build_mul(&bld->bld_base.base, coords[i], oow);
   }
   for (i = num_derivs; i < 5; i++) {
      coords[i] = bld->bld_base.base.undef;
   }

   /* Layer coord always goes into 3rd slot, except for cube map arrays */
   if (layer_coord) {
      coords[2] = lp_build_emit_fetch(&bld->bld_base, inst, 0, layer_coord);
      if (modifier == LP_BLD_TEX_MODIFIER_PROJECTED)
         coords[2] = lp_build_mul(&bld->bld_base.base, coords[2], oow);
   }
   /* Shadow coord occupies always 5th slot. */
   if (shadow_coord) {
      coords[4] = lp_build_emit_fetch(&bld->bld_base, inst, 0, shadow_coord);
      if (modifier == LP_BLD_TEX_MODIFIER_PROJECTED)
         coords[4] = lp_build_mul(&bld->bld_base.base, coords[4], oow);
   }

   if (modifier == LP_BLD_TEX_MODIFIER_EXPLICIT_DERIV) {
      unsigned dim;
      for (dim = 0; dim < num_derivs; ++dim) {
         derivs.ddx[dim] = lp_build_emit_fetch(&bld->bld_base, inst, 1, dim);
         derivs.ddy[dim] = lp_build_emit_fetch(&bld->bld_base, inst, 2, dim);
      }
      deriv_ptr = &derivs;
      unit = inst->Src[3].Register.Index;
      /*
       * could also check all src regs if constant but I doubt such
       * cases exist in practice.
       */
      if (bld->bld_base.info->processor == TGSI_PROCESSOR_FRAGMENT) {
         if (gallivm_debug & GALLIVM_DEBUG_NO_QUAD_LOD) {
            lod_property = LP_SAMPLER_LOD_PER_ELEMENT;
         }
         else {
            lod_property = LP_SAMPLER_LOD_PER_QUAD;
         }
      }
      else {
         lod_property = LP_SAMPLER_LOD_PER_ELEMENT;
      }
   } else {
      unit = inst->Src[1].Register.Index;
   }

   /* some advanced gather instructions (txgo) would require 4 offsets */
   if (inst->Texture.NumOffsets == 1) {
      unsigned dim;
      for (dim = 0; dim < num_offsets; dim++) {
         offsets[dim] = lp_build_emit_fetch_texoffset(&bld->bld_base, inst, 0, dim);
      }
   }

   bld->sampler->emit_fetch_texel(bld->sampler,
                                  bld->bld_base.base.gallivm,
                                  bld->bld_base.base.type,
                                  FALSE,
                                  unit, unit,
                                  coords,
                                  offsets,
                                  deriv_ptr,
                                  lod_bias, explicit_lod, lod_property,
                                  texel);
}

static void
emit_sample(struct lp_build_tgsi_soa_context *bld,
            const struct tgsi_full_instruction *inst,
            enum lp_build_tex_modifier modifier,
            boolean compare,
            LLVMValueRef *texel)
{
   struct gallivm_state *gallivm = bld->bld_base.base.gallivm;
   unsigned texture_unit, sampler_unit;
   LLVMValueRef lod_bias, explicit_lod;
   LLVMValueRef coords[5];
   LLVMValueRef offsets[3] = { NULL };
   struct lp_derivatives derivs;
   struct lp_derivatives *deriv_ptr = NULL;
   enum lp_sampler_lod_property lod_property = LP_SAMPLER_LOD_SCALAR;

   unsigned num_offsets, num_derivs, i;
   unsigned layer_coord = 0;

   if (!bld->sampler) {
      _debug_printf("warning: found texture instruction but no sampler generator supplied\n");
      for (i = 0; i < 4; i++) {
         texel[i] = bld->bld_base.base.undef;
      }
      return;
   }

   /*
    * unlike old-style tex opcodes the texture/sampler indices
    * always come from src1 and src2 respectively.
    */
   texture_unit = inst->Src[1].Register.Index;
   sampler_unit = inst->Src[2].Register.Index;

   /*
    * Note inst->Texture.Texture will contain the number of offsets,
    * however the target information is NOT there and comes from the
    * declared sampler views instead.
    */
   switch (bld->sv[texture_unit].Resource) {
   case TGSI_TEXTURE_1D:
      num_offsets = 1;
      num_derivs = 1;
      break;
   case TGSI_TEXTURE_1D_ARRAY:
      layer_coord = 1;
      num_offsets = 1;
      num_derivs = 1;
      break;
   case TGSI_TEXTURE_2D:
   case TGSI_TEXTURE_RECT:
      num_offsets = 2;
      num_derivs = 2;
      break;
   case TGSI_TEXTURE_2D_ARRAY:
      layer_coord = 2;
      num_offsets = 2;
      num_derivs = 2;
      break;
   case TGSI_TEXTURE_CUBE:
      num_offsets = 2;
      num_derivs = 3;
      break;
   case TGSI_TEXTURE_3D:
      num_offsets = 3;
      num_derivs = 3;
      break;
   case TGSI_TEXTURE_CUBE_ARRAY:
      layer_coord = 3;
      num_offsets = 2;
      num_derivs = 3;
      break;
   default:
      assert(0);
      return;
   }

   if (modifier == LP_BLD_TEX_MODIFIER_LOD_BIAS ||
       modifier == LP_BLD_TEX_MODIFIER_EXPLICIT_LOD) {
      LLVMValueRef lod = lp_build_emit_fetch(&bld->bld_base, inst, 3, 0);
      if (modifier == LP_BLD_TEX_MODIFIER_LOD_BIAS) {
         lod_bias = lod;
         explicit_lod = NULL;
      }
      else if (modifier == LP_BLD_TEX_MODIFIER_EXPLICIT_LOD) {
         lod_bias = NULL;
         explicit_lod = lod;
      }
      lod_property = lp_build_lod_property(&bld->bld_base, inst, 0);
   }
   else if (modifier == LP_BLD_TEX_MODIFIER_LOD_ZERO) {
      lod_bias = NULL;
      /* XXX might be better to explicitly pass the level zero information */
      explicit_lod = lp_build_const_vec(gallivm, bld->bld_base.base.type, 0.0F);
   }
   else {
      lod_bias = NULL;
      explicit_lod = NULL;
   }

   for (i = 0; i < num_derivs; i++) {
      coords[i] = lp_build_emit_fetch(&bld->bld_base, inst, 0, i);
   }
   for (i = num_derivs; i < 5; i++) {
      coords[i] = bld->bld_base.base.undef;
   }

   /* Layer coord always goes into 3rd slot, except for cube map arrays */
   if (layer_coord) {
      if (layer_coord == 3)
         coords[3] = lp_build_emit_fetch(&bld->bld_base, inst, 0, layer_coord);
      else
         coords[2] = lp_build_emit_fetch(&bld->bld_base, inst, 0, layer_coord);
   }
   /* Shadow coord occupies always 5th slot. */
   if (compare) {
      coords[4] = lp_build_emit_fetch(&bld->bld_base, inst, 3, 0);
   }

   if (modifier == LP_BLD_TEX_MODIFIER_EXPLICIT_DERIV) {
      unsigned dim;
      for (dim = 0; dim < num_derivs; ++dim) {
         derivs.ddx[dim] = lp_build_emit_fetch(&bld->bld_base, inst, 3, dim);
         derivs.ddy[dim] = lp_build_emit_fetch(&bld->bld_base, inst, 4, dim);
      }
      deriv_ptr = &derivs;
      /*
       * could also check all src regs if constant but I doubt such
       * cases exist in practice.
       */
      if (bld->bld_base.info->processor == TGSI_PROCESSOR_FRAGMENT) {
         if (gallivm_debug & GALLIVM_DEBUG_NO_QUAD_LOD) {
            lod_property = LP_SAMPLER_LOD_PER_ELEMENT;
         }
         else {
            lod_property = LP_SAMPLER_LOD_PER_QUAD;
         }
      }
      else {
         lod_property = LP_SAMPLER_LOD_PER_ELEMENT;
      }
   }

   /* some advanced gather instructions (txgo) would require 4 offsets */
   if (inst->Texture.NumOffsets == 1) {
      unsigned dim;
      for (dim = 0; dim < num_offsets; dim++) {
         offsets[dim] = lp_build_emit_fetch_texoffset(&bld->bld_base, inst, 0, dim);
      }
   }

   bld->sampler->emit_fetch_texel(bld->sampler,
                                  bld->bld_base.base.gallivm,
                                  bld->bld_base.base.type,
                                  FALSE,
                                  texture_unit, sampler_unit,
                                  coords,
                                  offsets,
                                  deriv_ptr,
                                  lod_bias, explicit_lod, lod_property,
                                  texel);

   if (inst->Src[1].Register.SwizzleX != PIPE_SWIZZLE_RED ||
       inst->Src[1].Register.SwizzleY != PIPE_SWIZZLE_GREEN ||
       inst->Src[1].Register.SwizzleZ != PIPE_SWIZZLE_BLUE ||
       inst->Src[1].Register.SwizzleW != PIPE_SWIZZLE_ALPHA) {
      unsigned char swizzles[4];
      swizzles[0] = inst->Src[1].Register.SwizzleX;
      swizzles[1] = inst->Src[1].Register.SwizzleY;
      swizzles[2] = inst->Src[1].Register.SwizzleZ;
      swizzles[3] = inst->Src[1].Register.SwizzleW;

      lp_build_swizzle_soa_inplace(&bld->bld_base.base, texel, swizzles);
   }
}

static void
emit_fetch_texels( struct lp_build_tgsi_soa_context *bld,
                   const struct tgsi_full_instruction *inst,
                   LLVMValueRef *texel,
                   boolean is_samplei)
{
   unsigned unit, target;
   LLVMValueRef coord_undef = LLVMGetUndef(bld->bld_base.base.int_vec_type);
   LLVMValueRef explicit_lod = NULL;
   LLVMValueRef coords[3];
   LLVMValueRef offsets[3] = { NULL };
   enum lp_sampler_lod_property lod_property = LP_SAMPLER_LOD_SCALAR;
   unsigned dims, i;
   unsigned layer_coord = 0;

   if (!bld->sampler) {
      _debug_printf("warning: found texture instruction but no sampler generator supplied\n");
      for (i = 0; i < 4; i++) {
         texel[i] = coord_undef;
      }
      return;
   }

   unit = inst->Src[1].Register.Index;

   if (is_samplei) {
      target = bld->sv[unit].Resource;
   }
   else {
      target = inst->Texture.Texture;
   }

   switch (target) {
   case TGSI_TEXTURE_1D:
   case TGSI_TEXTURE_BUFFER:
      dims = 1;
      break;
   case TGSI_TEXTURE_1D_ARRAY:
      layer_coord = 1;
      dims = 1;
      break;
   case TGSI_TEXTURE_2D:
   case TGSI_TEXTURE_RECT:
      dims = 2;
      break;
   case TGSI_TEXTURE_2D_ARRAY:
      layer_coord = 2;
      dims = 2;
      break;
   case TGSI_TEXTURE_3D:
      dims = 3;
      break;
   default:
      assert(0);
      return;
   }

   /* always have lod except for buffers ? */
   if (target != TGSI_TEXTURE_BUFFER) {
      explicit_lod = lp_build_emit_fetch(&bld->bld_base, inst, 0, 3);
      lod_property = lp_build_lod_property(&bld->bld_base, inst, 0);
   }

   for (i = 0; i < dims; i++) {
      coords[i] = lp_build_emit_fetch(&bld->bld_base, inst, 0, i);
   }
   for (i = dims; i < 3; i++) {
      coords[i] = coord_undef;
   }
   if (layer_coord)
      coords[2] = lp_build_emit_fetch(&bld->bld_base, inst, 0, layer_coord);

   if (inst->Texture.NumOffsets == 1) {
      unsigned dim;
      for (dim = 0; dim < dims; dim++) {
         offsets[dim] = lp_build_emit_fetch_texoffset(&bld->bld_base, inst, 0, dim);
      }
   }

   bld->sampler->emit_fetch_texel(bld->sampler,
                                  bld->bld_base.base.gallivm,
                                  bld->bld_base.base.type,
                                  TRUE,
                                  unit, unit,
                                  coords,
                                  offsets,
                                  NULL,
                                  NULL, explicit_lod, lod_property,
                                  texel);

   if (is_samplei &&
       (inst->Src[1].Register.SwizzleX != PIPE_SWIZZLE_RED ||
        inst->Src[1].Register.SwizzleY != PIPE_SWIZZLE_GREEN ||
        inst->Src[1].Register.SwizzleZ != PIPE_SWIZZLE_BLUE ||
        inst->Src[1].Register.SwizzleW != PIPE_SWIZZLE_ALPHA)) {
      unsigned char swizzles[4];
      swizzles[0] = inst->Src[1].Register.SwizzleX;
      swizzles[1] = inst->Src[1].Register.SwizzleY;
      swizzles[2] = inst->Src[1].Register.SwizzleZ;
      swizzles[3] = inst->Src[1].Register.SwizzleW;

      lp_build_swizzle_soa_inplace(&bld->bld_base.base, texel, swizzles);
   }
}

static void
emit_size_query( struct lp_build_tgsi_soa_context *bld,
                 const struct tgsi_full_instruction *inst,
                 LLVMValueRef *sizes_out,
                 boolean is_sviewinfo)
{
   LLVMValueRef explicit_lod;
   enum lp_sampler_lod_property lod_property;
   unsigned has_lod;
   unsigned i;
   unsigned unit = inst->Src[1].Register.Index;
   unsigned target, pipe_target;

   if (is_sviewinfo) {
      target = bld->sv[unit].Resource;
   }
   else {
      target = inst->Texture.Texture;
   }
   switch (target) {
   case TGSI_TEXTURE_BUFFER:
   case TGSI_TEXTURE_RECT:
   case TGSI_TEXTURE_SHADOWRECT:
      has_lod = 0;
      break;
   default:
      has_lod = 1;
      break;
   }

   if (!bld->sampler) {
      _debug_printf("warning: found texture query instruction but no sampler generator supplied\n");
      for (i = 0; i < 4; i++)
         sizes_out[i] = bld->bld_base.int_bld.undef;
      return;
   }

   if (has_lod) {
      explicit_lod = lp_build_emit_fetch(&bld->bld_base, inst, 0, 0);
      lod_property = lp_build_lod_property(&bld->bld_base, inst, 0);
   }
   else {
      explicit_lod = NULL;
      lod_property = LP_SAMPLER_LOD_SCALAR;
   }


   pipe_target = tgsi_to_pipe_tex_target(target);

   bld->sampler->emit_size_query(bld->sampler,
                                 bld->bld_base.base.gallivm,
                                 bld->bld_base.int_bld.type,
                                 unit, pipe_target,
                                 is_sviewinfo,
                                 lod_property,
                                 explicit_lod,
                                 sizes_out);
}

static boolean
near_end_of_shader(struct lp_build_tgsi_soa_context *bld,
		   int pc)
{
   int i;

   for (i = 0; i < 5; i++) {
      unsigned opcode;

      if (pc + i >= bld->bld_base.info->num_instructions)
	 return TRUE;

      opcode = bld->bld_base.instructions[pc + i].Instruction.Opcode;

      if (opcode == TGSI_OPCODE_END)
	 return TRUE;

      if (opcode == TGSI_OPCODE_TEX ||
	  opcode == TGSI_OPCODE_TXP ||
	  opcode == TGSI_OPCODE_TXD ||
	  opcode == TGSI_OPCODE_TXB ||
	  opcode == TGSI_OPCODE_TXL ||
	  opcode == TGSI_OPCODE_TXF ||
	  opcode == TGSI_OPCODE_TXQ ||
	  opcode == TGSI_OPCODE_CAL ||
	  opcode == TGSI_OPCODE_CALLNZ ||
	  opcode == TGSI_OPCODE_IF ||
          opcode == TGSI_OPCODE_UIF ||
	  opcode == TGSI_OPCODE_BGNLOOP ||
	  opcode == TGSI_OPCODE_SWITCH)
	 return FALSE;
   }

   return TRUE;
}



/**
 * Kill fragment if any of the src register values are negative.
 */
static void
emit_kill_if(
   struct lp_build_tgsi_soa_context *bld,
   const struct tgsi_full_instruction *inst,
   int pc)
{
   LLVMBuilderRef builder = bld->bld_base.base.gallivm->builder;
   const struct tgsi_full_src_register *reg = &inst->Src[0];
   LLVMValueRef terms[TGSI_NUM_CHANNELS];
   LLVMValueRef mask;
   unsigned chan_index;

   memset(&terms, 0, sizeof terms);

   TGSI_FOR_EACH_CHANNEL( chan_index ) {
      unsigned swizzle;

      /* Unswizzle channel */
      swizzle = tgsi_util_get_full_src_register_swizzle( reg, chan_index );

      /* Check if the component has not been already tested. */
      assert(swizzle < TGSI_NUM_CHANNELS);
      if( !terms[swizzle] )
         /* TODO: change the comparison operator instead of setting the sign */
         terms[swizzle] =  lp_build_emit_fetch(&bld->bld_base, inst, 0, chan_index );
   }

   mask = NULL;
   TGSI_FOR_EACH_CHANNEL( chan_index ) {
      if(terms[chan_index]) {
         LLVMValueRef chan_mask;

         /*
          * If term < 0 then mask = 0 else mask = ~0.
          */
         chan_mask = lp_build_cmp(&bld->bld_base.base, PIPE_FUNC_GEQUAL, terms[chan_index], bld->bld_base.base.zero);

         if(mask)
            mask = LLVMBuildAnd(builder, mask, chan_mask, "");
         else
            mask = chan_mask;
      }
   }

   if (bld->exec_mask.has_mask) {
      LLVMValueRef invmask;
      invmask = LLVMBuildNot(builder, bld->exec_mask.exec_mask, "kilp");
      mask = LLVMBuildOr(builder, mask, invmask, "");
   }

   lp_build_mask_update(bld->mask, mask);
   if (!near_end_of_shader(bld, pc))
      lp_build_mask_check(bld->mask);
}


/**
 * Unconditional fragment kill.
 * The only predication is the execution mask which will apply if
 * we're inside a loop or conditional.
 */
static void
emit_kill(struct lp_build_tgsi_soa_context *bld,
          int pc)
{
   LLVMBuilderRef builder = bld->bld_base.base.gallivm->builder;
   LLVMValueRef mask;

   /* For those channels which are "alive", disable fragment shader
    * execution.
    */
   if (bld->exec_mask.has_mask) {
      mask = LLVMBuildNot(builder, bld->exec_mask.exec_mask, "kilp");
   }
   else {
      LLVMValueRef zero = LLVMConstNull(bld->bld_base.base.int_vec_type);
      mask = zero;
   }

   lp_build_mask_update(bld->mask, mask);

   if (!near_end_of_shader(bld, pc))
      lp_build_mask_check(bld->mask);
}


/**
 * Emit code which will dump the value of all the temporary registers
 * to stdout.
 */
static void
emit_dump_file(struct lp_build_tgsi_soa_context *bld,
               unsigned file)
{
   const struct tgsi_shader_info *info = bld->bld_base.info;
   struct gallivm_state *gallivm = bld->bld_base.base.gallivm;
   LLVMBuilderRef builder = gallivm->builder;
   LLVMValueRef reg_ptr;
   int index;
   int max_index = info->file_max[file];

   /*
    * Some register files, particularly constants, can be very large,
    * and dumping everything could make this unusably slow.
    */
   max_index = MIN2(max_index, 32);

   for (index = 0; index <= max_index; index++) {
      LLVMValueRef res;
      unsigned mask;
      int chan;

      if (index < 8 * sizeof(unsigned) &&
          (info->file_mask[file] & (1 << index)) == 0)  {
         /* This was not declared.*/
         continue;
      }

      if (file == TGSI_FILE_INPUT) {
         mask = info->input_usage_mask[index];
      } else {
         mask = TGSI_WRITEMASK_XYZW;
      }

      for (chan = 0; chan < 4; chan++) {
         if ((mask & (1 << chan)) == 0) {
            /* This channel is not used.*/
            continue;
         }

         if (file == TGSI_FILE_CONSTANT) {
            struct tgsi_full_src_register reg;
            memset(&reg, 0, sizeof reg);
            reg.Register.File = file;
            reg.Register.Index = index;
            reg.Register.SwizzleX = 0;
            reg.Register.SwizzleY = 1;
            reg.Register.SwizzleZ = 2;
            reg.Register.SwizzleW = 3;

            res = bld->bld_base.emit_fetch_funcs[file](&bld->bld_base, &reg, TGSI_TYPE_FLOAT, chan);
            if (!res) {
               continue;
            }
         } else if (file == TGSI_FILE_INPUT) {
            res = bld->inputs[index][chan];
            if (!res) {
               continue;
            }
         } else if (file == TGSI_FILE_TEMPORARY) {
            reg_ptr = lp_get_temp_ptr_soa(bld, index, chan);
            assert(reg_ptr);
            res = LLVMBuildLoad(builder, reg_ptr, "");
         } else if (file == TGSI_FILE_OUTPUT) {
            reg_ptr = lp_get_output_ptr(bld, index, chan);
            assert(reg_ptr);
            res = LLVMBuildLoad(builder, reg_ptr, "");
         } else {
            assert(0);
            continue;
         }

         emit_dump_reg(gallivm, file, index, chan, res);
      }
   }
}



void
lp_emit_declaration_soa(
   struct lp_build_tgsi_context *bld_base,
   const struct tgsi_full_declaration *decl)
{
   struct lp_build_tgsi_soa_context *bld = lp_soa_context(bld_base);
   struct gallivm_state *gallivm = bld->bld_base.base.gallivm;
   LLVMTypeRef vec_type = bld->bld_base.base.vec_type;
   const unsigned first = decl->Range.First;
   const unsigned last = decl->Range.Last;
   unsigned idx, i;

   for (idx = first; idx <= last; ++idx) {
      assert(last <= bld->bld_base.info->file_max[decl->Declaration.File]);
      switch (decl->Declaration.File) {
      case TGSI_FILE_TEMPORARY:
         if (!(bld->indirect_files & (1 << TGSI_FILE_TEMPORARY))) {
            assert(idx < LP_MAX_INLINED_TEMPS);
            for (i = 0; i < TGSI_NUM_CHANNELS; i++)
               bld->temps[idx][i] = lp_build_alloca(gallivm, vec_type, "temp");
         }
         break;

      case TGSI_FILE_OUTPUT:
         if (!(bld->indirect_files & (1 << TGSI_FILE_OUTPUT))) {
            for (i = 0; i < TGSI_NUM_CHANNELS; i++)
               bld->outputs[idx][i] = lp_build_alloca(gallivm,
                                                      vec_type, "output");
         }
         break;

      case TGSI_FILE_ADDRESS:
	 /* ADDR registers are only allocated with an integer LLVM IR type,
	  * as they are guaranteed to always have integers.
	  * XXX: Not sure if this exception is worthwhile (or the whole idea of
	  * an ADDR register for that matter).
	  */
         assert(idx < LP_MAX_TGSI_ADDRS);
         for (i = 0; i < TGSI_NUM_CHANNELS; i++)
            bld->addr[idx][i] = lp_build_alloca(gallivm, bld_base->base.int_vec_type, "addr");
         break;

      case TGSI_FILE_PREDICATE:
         assert(idx < LP_MAX_TGSI_PREDS);
         for (i = 0; i < TGSI_NUM_CHANNELS; i++)
            bld->preds[idx][i] = lp_build_alloca(gallivm, vec_type,
                                                 "predicate");
         break;

      case TGSI_FILE_SAMPLER_VIEW:
         /*
          * The target stored here MUST match whatever there actually
          * is in the set sampler views (what about return type?).
          */
         assert(idx < PIPE_MAX_SHADER_SAMPLER_VIEWS);
         bld->sv[idx] = decl->SamplerView;
         break;

      default:
         /* don't need to declare other vars */
         break;
      }
   }
}


void lp_emit_immediate_soa(
   struct lp_build_tgsi_context *bld_base,
   const struct tgsi_full_immediate *imm)
{
   struct lp_build_tgsi_soa_context *bld = lp_soa_context(bld_base);
   struct gallivm_state * gallivm = bld_base->base.gallivm;
   LLVMValueRef imms[4];
   unsigned i;
   const uint size = imm->Immediate.NrTokens - 1;
   assert(size <= 4);
   switch (imm->Immediate.DataType) {
   case TGSI_IMM_FLOAT32:
      for( i = 0; i < size; ++i )
         imms[i] =
               lp_build_const_vec(gallivm, bld_base->base.type, imm->u[i].Float);

      break;
   case TGSI_IMM_UINT32:
      for( i = 0; i < size; ++i ) {
         LLVMValueRef tmp = lp_build_const_vec(gallivm, bld_base->uint_bld.type, imm->u[i].Uint);
         imms[i] = LLVMConstBitCast(tmp, bld_base->base.vec_type);
      }

      break;
   case TGSI_IMM_INT32:
      for( i = 0; i < size; ++i ) {
         LLVMValueRef tmp = lp_build_const_vec(gallivm, bld_base->int_bld.type, imm->u[i].Int);
         imms[i] = LLVMConstBitCast(tmp, bld_base->base.vec_type);
      }

      break;
   }
   for( i = size; i < 4; ++i )
      imms[i] = bld_base->base.undef;

   if (bld->use_immediates_array) {
      unsigned index = bld->num_immediates;
      struct gallivm_state *gallivm = bld->bld_base.base.gallivm;
      LLVMBuilderRef builder = gallivm->builder;

      assert(bld->indirect_files & (1 << TGSI_FILE_IMMEDIATE));
      for (i = 0; i < 4; ++i ) {
         LLVMValueRef lindex = lp_build_const_int32(
                  bld->bld_base.base.gallivm, index * 4 + i);
         LLVMValueRef imm_ptr = LLVMBuildGEP(builder,
                                             bld->imms_array, &lindex, 1, "");
         LLVMBuildStore(builder, imms[i], imm_ptr);
      }
   } else {
      /* simply copy the immediate values into the next immediates[] slot */
      unsigned i;
      const uint size = imm->Immediate.NrTokens - 1;
      assert(size <= 4);
      assert(bld->num_immediates < LP_MAX_INLINED_IMMEDIATES);

      for(i = 0; i < 4; ++i )
         bld->immediates[bld->num_immediates][i] = imms[i];

      if (bld->indirect_files & (1 << TGSI_FILE_IMMEDIATE)) {
         unsigned index = bld->num_immediates;
         struct gallivm_state *gallivm = bld->bld_base.base.gallivm;
         LLVMBuilderRef builder = gallivm->builder;
         for (i = 0; i < 4; ++i ) {
            LLVMValueRef lindex = lp_build_const_int32(
                     bld->bld_base.base.gallivm, index * 4 + i);
            LLVMValueRef imm_ptr = LLVMBuildGEP(builder,
                                                bld->imms_array, &lindex, 1, "");
            LLVMBuildStore(builder,
                           bld->immediates[index][i],
                           imm_ptr);
         }
      }
   }

   bld->num_immediates++;
}

static void
ddx_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);

   emit_fetch_deriv(bld, emit_data->args[0], NULL,
                    &emit_data->output[emit_data->chan], NULL);
}

static void
ddy_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);

   emit_fetch_deriv(bld, emit_data->args[0], NULL, NULL,
                    &emit_data->output[emit_data->chan]);
}

static void
kill_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);

   emit_kill(bld, bld_base->pc - 1);
}

static void
kill_if_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);

   emit_kill_if(bld, emit_data->inst, bld_base->pc - 1);
}

static void
tex_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);

   emit_tex(bld, emit_data->inst, LP_BLD_TEX_MODIFIER_NONE, emit_data->output);
}

static void
txb_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);

   emit_tex(bld, emit_data->inst, LP_BLD_TEX_MODIFIER_LOD_BIAS,
            emit_data->output);
}

static void
txd_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);

   emit_tex(bld, emit_data->inst, LP_BLD_TEX_MODIFIER_EXPLICIT_DERIV,
            emit_data->output);
}

static void
txl_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);

   emit_tex(bld, emit_data->inst, LP_BLD_TEX_MODIFIER_EXPLICIT_LOD,
            emit_data->output);
}

static void
txp_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);

   emit_tex(bld, emit_data->inst, LP_BLD_TEX_MODIFIER_PROJECTED,
            emit_data->output);
}

static void
txq_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);

   emit_size_query(bld, emit_data->inst, emit_data->output, FALSE);
}

static void
txf_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);

   emit_fetch_texels(bld, emit_data->inst, emit_data->output, FALSE);
}

static void
sample_i_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);

   emit_fetch_texels(bld, emit_data->inst, emit_data->output, TRUE);
}

static void
sample_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);

   emit_sample(bld, emit_data->inst, LP_BLD_TEX_MODIFIER_NONE,
               FALSE, emit_data->output);
}

static void
sample_b_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);

   emit_sample(bld, emit_data->inst, LP_BLD_TEX_MODIFIER_LOD_BIAS,
               FALSE, emit_data->output);
}

static void
sample_c_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);

   emit_sample(bld, emit_data->inst, LP_BLD_TEX_MODIFIER_NONE,
               TRUE, emit_data->output);
}

static void
sample_c_lz_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);

   emit_sample(bld, emit_data->inst, LP_BLD_TEX_MODIFIER_LOD_ZERO,
               TRUE, emit_data->output);
}

static void
sample_d_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);

   emit_sample(bld, emit_data->inst, LP_BLD_TEX_MODIFIER_EXPLICIT_DERIV,
               FALSE, emit_data->output);
}

static void
sample_l_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);

   emit_sample(bld, emit_data->inst, LP_BLD_TEX_MODIFIER_EXPLICIT_LOD,
               FALSE, emit_data->output);
}

static void
sviewinfo_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);

   emit_size_query(bld, emit_data->inst, emit_data->output, TRUE);
}

static LLVMValueRef
mask_vec(struct lp_build_tgsi_context *bld_base)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
   LLVMBuilderRef builder = bld->bld_base.base.gallivm->builder;
   struct lp_exec_mask *exec_mask = &bld->exec_mask;

   if (!exec_mask->has_mask) {
      return lp_build_mask_value(bld->mask);
   }
   return LLVMBuildAnd(builder, lp_build_mask_value(bld->mask),
                       exec_mask->exec_mask, "");
}

static void
increment_vec_ptr_by_mask(struct lp_build_tgsi_context * bld_base,
                          LLVMValueRef ptr,
                          LLVMValueRef mask)
{
   LLVMBuilderRef builder = bld_base->base.gallivm->builder;
   LLVMValueRef current_vec = LLVMBuildLoad(builder, ptr, "");

   current_vec = LLVMBuildSub(builder, current_vec, mask, "");

   LLVMBuildStore(builder, current_vec, ptr);
}

static void
clear_uint_vec_ptr_from_mask(struct lp_build_tgsi_context * bld_base,
                             LLVMValueRef ptr,
                             LLVMValueRef mask)
{
   LLVMBuilderRef builder = bld_base->base.gallivm->builder;
   LLVMValueRef current_vec = LLVMBuildLoad(builder, ptr, "");

   current_vec = lp_build_select(&bld_base->uint_bld,
                                 mask,
                                 bld_base->uint_bld.zero,
                                 current_vec);

   LLVMBuildStore(builder, current_vec, ptr);
}

static LLVMValueRef
clamp_mask_to_max_output_vertices(struct lp_build_tgsi_soa_context * bld,
                                  LLVMValueRef current_mask_vec,
                                  LLVMValueRef total_emitted_vertices_vec)
{
   LLVMBuilderRef builder = bld->bld_base.base.gallivm->builder;
   struct lp_build_context *int_bld = &bld->bld_base.int_bld;
   LLVMValueRef max_mask = lp_build_cmp(int_bld, PIPE_FUNC_LESS,
                                        total_emitted_vertices_vec,
                                        bld->max_output_vertices_vec);

   return LLVMBuildAnd(builder, current_mask_vec, max_mask, "");
}

static void
emit_vertex(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
   LLVMBuilderRef builder = bld->bld_base.base.gallivm->builder;

   if (bld->gs_iface->emit_vertex) {
      LLVMValueRef mask = mask_vec(bld_base);
      LLVMValueRef total_emitted_vertices_vec =
         LLVMBuildLoad(builder, bld->total_emitted_vertices_vec_ptr, "");
      mask = clamp_mask_to_max_output_vertices(bld, mask,
                                               total_emitted_vertices_vec);
      gather_outputs(bld);
      bld->gs_iface->emit_vertex(bld->gs_iface, &bld->bld_base,
                                 bld->outputs,
                                 total_emitted_vertices_vec);
      increment_vec_ptr_by_mask(bld_base, bld->emitted_vertices_vec_ptr,
                                mask);
      increment_vec_ptr_by_mask(bld_base, bld->total_emitted_vertices_vec_ptr,
                                mask);
#if DUMP_GS_EMITS
      lp_build_print_value(bld->bld_base.base.gallivm,
                           " +++ emit vertex masked ones = ",
                           mask);
      lp_build_print_value(bld->bld_base.base.gallivm,
                           " +++ emit vertex emitted = ",
                           total_emitted_vertices_vec);
#endif
   }
}


static void
end_primitive_masked(struct lp_build_tgsi_context * bld_base,
                     LLVMValueRef mask)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
   LLVMBuilderRef builder = bld->bld_base.base.gallivm->builder;

   if (bld->gs_iface->end_primitive) {
      struct lp_build_context *uint_bld = &bld_base->uint_bld;
      LLVMValueRef emitted_vertices_vec =
         LLVMBuildLoad(builder, bld->emitted_vertices_vec_ptr, "");
      LLVMValueRef emitted_prims_vec =
         LLVMBuildLoad(builder, bld->emitted_prims_vec_ptr, "");

      LLVMValueRef emitted_mask = lp_build_cmp(uint_bld, PIPE_FUNC_NOTEQUAL,
                                               emitted_vertices_vec,
                                               uint_bld->zero);
      /* We need to combine the current execution mask with the mask
         telling us which, if any, execution slots actually have
         unemitted primitives, this way we make sure that end_primitives
         executes only on the paths that have unflushed vertices */
      mask = LLVMBuildAnd(builder, mask, emitted_mask, "");

      bld->gs_iface->end_primitive(bld->gs_iface, &bld->bld_base,
                                   emitted_vertices_vec,
                                   emitted_prims_vec);

#if DUMP_GS_EMITS
      lp_build_print_value(bld->bld_base.base.gallivm,
                           " +++ end prim masked ones = ",
                           mask);
      lp_build_print_value(bld->bld_base.base.gallivm,
                           " +++ end prim emitted verts1 = ",
                           emitted_vertices_vec);
      lp_build_print_value(bld->bld_base.base.gallivm,
                           " +++ end prim emitted prims1 = ",
                           LLVMBuildLoad(builder,
                                         bld->emitted_prims_vec_ptr, ""));
#endif
      increment_vec_ptr_by_mask(bld_base, bld->emitted_prims_vec_ptr,
                                mask);
      clear_uint_vec_ptr_from_mask(bld_base, bld->emitted_vertices_vec_ptr,
                                   mask);
#if DUMP_GS_EMITS
      lp_build_print_value(bld->bld_base.base.gallivm,
                           " +++ end prim emitted verts2 = ",
                           LLVMBuildLoad(builder,
                                         bld->emitted_vertices_vec_ptr, ""));
#endif
   }

}

static void
end_primitive(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);

   if (bld->gs_iface->end_primitive) {
      LLVMValueRef mask = mask_vec(bld_base);
      end_primitive_masked(bld_base, mask);
   }
}

static void
cal_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);

   lp_exec_mask_call(&bld->exec_mask, emit_data->inst->Label.Label,
                     &bld_base->pc);
}

static void
ret_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);

   lp_exec_mask_ret(&bld->exec_mask, &bld_base->pc);
}

static void
brk_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);

   lp_exec_break(&bld->exec_mask, bld_base);
}

static void
breakc_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
   LLVMBuilderRef builder = bld_base->base.gallivm->builder;
   struct lp_build_context *uint_bld = &bld_base->uint_bld;
   LLVMValueRef unsigned_cond = 
      LLVMBuildBitCast(builder, emit_data->args[0], uint_bld->vec_type, "");
   LLVMValueRef cond = lp_build_cmp(uint_bld, PIPE_FUNC_NOTEQUAL,
                                    unsigned_cond,
                                    uint_bld->zero);

   lp_exec_break_condition(&bld->exec_mask, cond);
}

static void
if_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   LLVMValueRef tmp;
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);

   tmp = lp_build_cmp(&bld_base->base, PIPE_FUNC_NOTEQUAL,
                      emit_data->args[0], bld->bld_base.base.zero);
   lp_exec_mask_cond_push(&bld->exec_mask, tmp);
}

static void
uif_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   LLVMValueRef tmp;
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
   struct lp_build_context *uint_bld = &bld_base->uint_bld;

   tmp = lp_build_cmp(uint_bld, PIPE_FUNC_NOTEQUAL,
                      emit_data->args[0], uint_bld->zero);
   lp_exec_mask_cond_push(&bld->exec_mask, tmp);
}

static void
case_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);

   lp_exec_case(&bld->exec_mask, emit_data->args[0]);
}

static void
default_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);

   lp_exec_default(&bld->exec_mask, bld_base);
}

static void
switch_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);

   lp_exec_switch(&bld->exec_mask, emit_data->args[0]);
}

static void
endswitch_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);

   lp_exec_endswitch(&bld->exec_mask, bld_base);
}

static void
bgnloop_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);

   lp_exec_bgnloop(&bld->exec_mask);
}

static void
bgnsub_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);

   lp_exec_mask_bgnsub(&bld->exec_mask);
}

static void
else_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);

   lp_exec_mask_cond_invert(&bld->exec_mask);
}

static void
endif_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);

   lp_exec_mask_cond_pop(&bld->exec_mask);
}

static void
endloop_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);

   lp_exec_endloop(bld_base->base.gallivm, &bld->exec_mask);
}

static void
endsub_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);

   lp_exec_mask_endsub(&bld->exec_mask, &bld_base->pc);
}

static void
cont_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);

   lp_exec_continue(&bld->exec_mask);
}

/* XXX: Refactor and move it to lp_bld_tgsi_action.c
 *
 * XXX: What do the comments about xmm registers mean?  Maybe they are left over
 * from old code, but there is no garauntee that LLVM will use those registers
 * for this code.
 *
 * XXX: There should be no calls to lp_build_emit_fetch in this function.  This
 * should be handled by the emit_data->fetch_args function. */
static void
nrm_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   LLVMValueRef tmp0, tmp1;
   LLVMValueRef tmp4 = NULL;
   LLVMValueRef tmp5 = NULL;
   LLVMValueRef tmp6 = NULL;
   LLVMValueRef tmp7 = NULL;
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);

   uint dims = (emit_data->inst->Instruction.Opcode == TGSI_OPCODE_NRM) ? 3 : 4;

  if (TGSI_IS_DST0_CHANNEL_ENABLED(emit_data->inst, TGSI_CHAN_X) ||
      TGSI_IS_DST0_CHANNEL_ENABLED(emit_data->inst, TGSI_CHAN_Y) ||
      TGSI_IS_DST0_CHANNEL_ENABLED(emit_data->inst, TGSI_CHAN_Z) ||
      (TGSI_IS_DST0_CHANNEL_ENABLED(emit_data->inst, TGSI_CHAN_W) && dims == 4)) {

      /* NOTE: Cannot use xmm regs 2/3 here (see emit_rsqrt() above). */

      /* xmm4 = src.x */
      /* xmm0 = src.x * src.x */
      tmp0 = lp_build_emit_fetch(&bld->bld_base, emit_data->inst, 0, TGSI_CHAN_X);
      if (TGSI_IS_DST0_CHANNEL_ENABLED(emit_data->inst, TGSI_CHAN_X)) {
         tmp4 = tmp0;
      }
      tmp0 = lp_build_mul( &bld->bld_base.base, tmp0, tmp0);

      /* xmm5 = src.y */
      /* xmm0 = xmm0 + src.y * src.y */
      tmp1 = lp_build_emit_fetch(&bld->bld_base, emit_data->inst, 0, TGSI_CHAN_Y);
      if (TGSI_IS_DST0_CHANNEL_ENABLED(emit_data->inst, TGSI_CHAN_Y)) {
         tmp5 = tmp1;
      }
      tmp1 = lp_build_mul( &bld->bld_base.base, tmp1, tmp1);
      tmp0 = lp_build_add( &bld->bld_base.base, tmp0, tmp1);

      /* xmm6 = src.z */
      /* xmm0 = xmm0 + src.z * src.z */
      tmp1 = lp_build_emit_fetch(&bld->bld_base, emit_data->inst, 0, TGSI_CHAN_Z);
      if (TGSI_IS_DST0_CHANNEL_ENABLED(emit_data->inst, TGSI_CHAN_Z)) {
         tmp6 = tmp1;
      }
      tmp1 = lp_build_mul( &bld->bld_base.base, tmp1, tmp1);
      tmp0 = lp_build_add( &bld->bld_base.base, tmp0, tmp1);

      if (dims == 4) {
         /* xmm7 = src.w */
         /* xmm0 = xmm0 + src.w * src.w */
         tmp1 = lp_build_emit_fetch(&bld->bld_base, emit_data->inst, 0, TGSI_CHAN_W);
         if (TGSI_IS_DST0_CHANNEL_ENABLED(emit_data->inst, TGSI_CHAN_W)) {
            tmp7 = tmp1;
         }
         tmp1 = lp_build_mul( &bld->bld_base.base, tmp1, tmp1);
         tmp0 = lp_build_add( &bld->bld_base.base, tmp0, tmp1);
      }
      /* xmm1 = 1 / sqrt(xmm0) */
      tmp1 = lp_build_rsqrt( &bld->bld_base.base, tmp0);
       /* dst.x = xmm1 * src.x */
      if (TGSI_IS_DST0_CHANNEL_ENABLED(emit_data->inst, TGSI_CHAN_X)) {
         emit_data->output[TGSI_CHAN_X] = lp_build_mul( &bld->bld_base.base, tmp4, tmp1);
      }
      /* dst.y = xmm1 * src.y */
      if (TGSI_IS_DST0_CHANNEL_ENABLED(emit_data->inst, TGSI_CHAN_Y)) {
         emit_data->output[TGSI_CHAN_Y] = lp_build_mul( &bld->bld_base.base, tmp5, tmp1);
      }

      /* dst.z = xmm1 * src.z */
      if (TGSI_IS_DST0_CHANNEL_ENABLED(emit_data->inst, TGSI_CHAN_Z)) {
         emit_data->output[TGSI_CHAN_Z] = lp_build_mul( &bld->bld_base.base, tmp6, tmp1);
      }
      /* dst.w = xmm1 * src.w */
      if (TGSI_IS_DST0_CHANNEL_ENABLED(emit_data->inst, TGSI_CHAN_X) && dims == 4) {
         emit_data->output[TGSI_CHAN_W] = lp_build_mul( &bld->bld_base.base, tmp7, tmp1);
      }
   }

   /* dst.w = 1.0 */
   if (TGSI_IS_DST0_CHANNEL_ENABLED(emit_data->inst, TGSI_CHAN_W) && dims == 3) {
       emit_data->output[TGSI_CHAN_W] = bld->bld_base.base.one;
   }
}

static void emit_prologue(struct lp_build_tgsi_context * bld_base)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
   struct gallivm_state * gallivm = bld_base->base.gallivm;

   if (bld->indirect_files & (1 << TGSI_FILE_TEMPORARY)) {
      LLVMValueRef array_size =
         lp_build_const_int32(gallivm,
                         bld_base->info->file_max[TGSI_FILE_TEMPORARY] * 4 + 4);
      bld->temps_array = lp_build_array_alloca(gallivm,
                                              bld_base->base.vec_type, array_size,
                                              "temp_array");
   }

   if (bld->indirect_files & (1 << TGSI_FILE_OUTPUT)) {
      LLVMValueRef array_size =
         lp_build_const_int32(gallivm,
                            bld_base->info->file_max[TGSI_FILE_OUTPUT] * 4 + 4);
      bld->outputs_array = lp_build_array_alloca(gallivm,
                                                bld_base->base.vec_type, array_size,
                                                "output_array");
   }

   if (bld->indirect_files & (1 << TGSI_FILE_IMMEDIATE)) {
      LLVMValueRef array_size =
         lp_build_const_int32(gallivm,
                         bld_base->info->file_max[TGSI_FILE_IMMEDIATE] * 4 + 4);
      bld->imms_array = lp_build_array_alloca(gallivm,
                                              bld_base->base.vec_type, array_size,
                                              "imms_array");
   }

   /* If we have indirect addressing in inputs we need to copy them into
    * our alloca array to be able to iterate over them */
   if (bld->indirect_files & (1 << TGSI_FILE_INPUT) && !bld->gs_iface) {
      unsigned index, chan;
      LLVMTypeRef vec_type = bld_base->base.vec_type;
      LLVMValueRef array_size = lp_build_const_int32(gallivm,
            bld_base->info->file_max[TGSI_FILE_INPUT]*4 + 4);
      bld->inputs_array = lp_build_array_alloca(gallivm,
                                               vec_type, array_size,
                                               "input_array");

      assert(bld_base->info->num_inputs
                        <= bld_base->info->file_max[TGSI_FILE_INPUT] + 1);

      for (index = 0; index < bld_base->info->num_inputs; ++index) {
         for (chan = 0; chan < TGSI_NUM_CHANNELS; ++chan) {
            LLVMValueRef lindex =
               lp_build_const_int32(gallivm, index * 4 + chan);
            LLVMValueRef input_ptr =
               LLVMBuildGEP(gallivm->builder, bld->inputs_array,
                            &lindex, 1, "");
            LLVMValueRef value = bld->inputs[index][chan];
            if (value)
               LLVMBuildStore(gallivm->builder, value, input_ptr);
         }
      }
   }

   if (bld->gs_iface) {
      struct lp_build_context *uint_bld = &bld->bld_base.uint_bld;
      bld->emitted_prims_vec_ptr =
         lp_build_alloca(gallivm,
                         uint_bld->vec_type,
                         "emitted_prims_ptr");
      bld->emitted_vertices_vec_ptr =
         lp_build_alloca(gallivm,
                         uint_bld->vec_type,
                         "emitted_vertices_ptr");
      bld->total_emitted_vertices_vec_ptr =
         lp_build_alloca(gallivm,
                         uint_bld->vec_type,
                         "total_emitted_vertices_ptr");

      LLVMBuildStore(gallivm->builder, uint_bld->zero,
                     bld->emitted_prims_vec_ptr);
      LLVMBuildStore(gallivm->builder, uint_bld->zero,
                     bld->emitted_vertices_vec_ptr);
      LLVMBuildStore(gallivm->builder, uint_bld->zero,
                     bld->total_emitted_vertices_vec_ptr);
   }

   if (DEBUG_EXECUTION) {
      lp_build_printf(gallivm, "\n");
      emit_dump_file(bld, TGSI_FILE_CONSTANT);
      if (!bld->gs_iface)
         emit_dump_file(bld, TGSI_FILE_INPUT);
   }
}

static void emit_epilogue(struct lp_build_tgsi_context * bld_base)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
   LLVMBuilderRef builder = bld_base->base.gallivm->builder;

   if (DEBUG_EXECUTION) {
      /* for debugging */
      if (0) {
         emit_dump_file(bld, TGSI_FILE_TEMPORARY);
      }
      emit_dump_file(bld, TGSI_FILE_OUTPUT);
      lp_build_printf(bld_base->base.gallivm, "\n");
   }

   /* If we have indirect addressing in outputs we need to copy our alloca array
    * to the outputs slots specified by the caller */
   if (bld->gs_iface) {
      LLVMValueRef total_emitted_vertices_vec;
      LLVMValueRef emitted_prims_vec;
      /* implicit end_primitives, needed in case there are any unflushed
         vertices in the cache. Note must not call end_primitive here
         since the exec_mask is not valid at this point. */
      end_primitive_masked(bld_base, lp_build_mask_value(bld->mask));
      
      total_emitted_vertices_vec =
         LLVMBuildLoad(builder, bld->total_emitted_vertices_vec_ptr, "");
      emitted_prims_vec =
         LLVMBuildLoad(builder, bld->emitted_prims_vec_ptr, "");

      bld->gs_iface->gs_epilogue(bld->gs_iface,
                                 &bld->bld_base,
                                 total_emitted_vertices_vec,
                                 emitted_prims_vec);
   } else {
      gather_outputs(bld);
   }
}

void
lp_build_tgsi_soa(struct gallivm_state *gallivm,
                  const struct tgsi_token *tokens,
                  struct lp_type type,
                  struct lp_build_mask_context *mask,
                  LLVMValueRef consts_ptr,
                  LLVMValueRef const_sizes_ptr,
                  const struct lp_bld_tgsi_system_values *system_values,
                  const LLVMValueRef (*inputs)[TGSI_NUM_CHANNELS],
                  LLVMValueRef (*outputs)[TGSI_NUM_CHANNELS],
                  struct lp_build_sampler_soa *sampler,
                  const struct tgsi_shader_info *info,
                  const struct lp_build_tgsi_gs_iface *gs_iface)
{
   struct lp_build_tgsi_soa_context bld;

   struct lp_type res_type;

   assert(type.length <= LP_MAX_VECTOR_LENGTH);
   memset(&res_type, 0, sizeof res_type);
   res_type.width = type.width;
   res_type.length = type.length;
   res_type.sign = 1;

   /* Setup build context */
   memset(&bld, 0, sizeof bld);
   lp_build_context_init(&bld.bld_base.base, gallivm, type);
   lp_build_context_init(&bld.bld_base.uint_bld, gallivm, lp_uint_type(type));
   lp_build_context_init(&bld.bld_base.int_bld, gallivm, lp_int_type(type));
   lp_build_context_init(&bld.elem_bld, gallivm, lp_elem_type(type));
   bld.mask = mask;
   bld.inputs = inputs;
   bld.outputs = outputs;
   bld.consts_ptr = consts_ptr;
   bld.const_sizes_ptr = const_sizes_ptr;
   bld.sampler = sampler;
   bld.bld_base.info = info;
   bld.indirect_files = info->indirect_files;

   /*
    * If the number of temporaries is rather large then we just
    * allocate them as an array right from the start and treat
    * like indirect temporaries.
    */
   if (info->file_max[TGSI_FILE_TEMPORARY] >= LP_MAX_INLINED_TEMPS) {
      bld.indirect_files |= (1 << TGSI_FILE_TEMPORARY);
   }
   /*
    * For performance reason immediates are always backed in a static
    * array, but if their number is too great, we have to use just
    * a dynamically allocated array.
    */
   bld.use_immediates_array =
         (info->file_max[TGSI_FILE_IMMEDIATE] >= LP_MAX_INLINED_IMMEDIATES);
   if (bld.use_immediates_array) {
      bld.indirect_files |= (1 << TGSI_FILE_IMMEDIATE);
   }


   bld.bld_base.soa = TRUE;
   bld.bld_base.emit_debug = emit_debug;
   bld.bld_base.emit_fetch_funcs[TGSI_FILE_CONSTANT] = emit_fetch_constant;
   bld.bld_base.emit_fetch_funcs[TGSI_FILE_IMMEDIATE] = emit_fetch_immediate;
   bld.bld_base.emit_fetch_funcs[TGSI_FILE_INPUT] = emit_fetch_input;
   bld.bld_base.emit_fetch_funcs[TGSI_FILE_TEMPORARY] = emit_fetch_temporary;
   bld.bld_base.emit_fetch_funcs[TGSI_FILE_SYSTEM_VALUE] = emit_fetch_system_value;
   bld.bld_base.emit_store = emit_store;

   bld.bld_base.emit_declaration = lp_emit_declaration_soa;
   bld.bld_base.emit_immediate = lp_emit_immediate_soa;

   bld.bld_base.emit_prologue = emit_prologue;
   bld.bld_base.emit_epilogue = emit_epilogue;

   /* Set opcode actions */
   lp_set_default_actions_cpu(&bld.bld_base);

   bld.bld_base.op_actions[TGSI_OPCODE_BGNLOOP].emit = bgnloop_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_BGNSUB].emit = bgnsub_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_BRK].emit = brk_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_BREAKC].emit = breakc_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_CAL].emit = cal_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_CASE].emit = case_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_CONT].emit = cont_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_DDX].emit = ddx_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_DDY].emit = ddy_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_DEFAULT].emit = default_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_ELSE].emit = else_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_ENDIF].emit = endif_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_ENDLOOP].emit = endloop_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_ENDSUB].emit = endsub_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_ENDSWITCH].emit = endswitch_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_IF].emit = if_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_UIF].emit = uif_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_KILL_IF].emit = kill_if_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_KILL].emit = kill_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_NRM].emit = nrm_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_NRM4].emit = nrm_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_RET].emit = ret_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_SWITCH].emit = switch_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_TEX].emit = tex_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_TXB].emit = txb_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_TXD].emit = txd_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_TXL].emit = txl_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_TXP].emit = txp_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_TXQ].emit = txq_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_TXF].emit = txf_emit;
   /* DX10 sampling ops */
   bld.bld_base.op_actions[TGSI_OPCODE_SAMPLE].emit = sample_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_SAMPLE_B].emit = sample_b_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_SAMPLE_C].emit = sample_c_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_SAMPLE_C_LZ].emit = sample_c_lz_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_SAMPLE_D].emit = sample_d_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_SAMPLE_I].emit = sample_i_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_SAMPLE_L].emit = sample_l_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_SVIEWINFO].emit = sviewinfo_emit;

   if (gs_iface) {
      /* There's no specific value for this because it should always
       * be set, but apps using ext_geometry_shader4 quite often
       * were forgetting so we're using MAX_VERTEX_VARYING from
       * that spec even though we could debug_assert if it's not
       * set, but that's a lot uglier. */
      uint max_output_vertices = 32;
      uint i = 0;
      /* inputs are always indirect with gs */
      bld.indirect_files |= (1 << TGSI_FILE_INPUT);
      bld.gs_iface = gs_iface;
      bld.bld_base.emit_fetch_funcs[TGSI_FILE_INPUT] = emit_fetch_gs_input;
      bld.bld_base.op_actions[TGSI_OPCODE_EMIT].emit = emit_vertex;
      bld.bld_base.op_actions[TGSI_OPCODE_ENDPRIM].emit = end_primitive;

      for (i = 0; i < info->num_properties; ++i) {
         if (info->properties[i].name ==
             TGSI_PROPERTY_GS_MAX_OUTPUT_VERTICES) {
            max_output_vertices = info->properties[i].data[0];
         }
      }
      bld.max_output_vertices_vec =
         lp_build_const_int_vec(gallivm, bld.bld_base.int_bld.type,
                                max_output_vertices);
   }

   lp_exec_mask_init(&bld.exec_mask, &bld.bld_base.int_bld);

   bld.system_values = *system_values;

   lp_build_tgsi_llvm(&bld.bld_base, tokens);

   if (0) {
      LLVMBasicBlockRef block = LLVMGetInsertBlock(gallivm->builder);
      LLVMValueRef function = LLVMGetBasicBlockParent(block);
      debug_printf("11111111111111111111111111111 \n");
      tgsi_dump(tokens, 0);
      lp_debug_dump_value(function);
      debug_printf("2222222222222222222222222222 \n");
   }

   if (0) {
      LLVMModuleRef module = LLVMGetGlobalParent(
         LLVMGetBasicBlockParent(LLVMGetInsertBlock(gallivm->builder)));
      LLVMDumpModule(module);

   }
   lp_exec_mask_fini(&bld.exec_mask);
}
@


1.7
log
@Merge Mesa 10.2.9
@
text
@@


1.6
log
@Merge Mesa 10.4.3
Tested by matthieu@@ mpi@@ and myself.  landry@@ ran a ports bulk build.
kettenis@@ tracked down the cause of an alignment fault on archs
that require strict eight byte pointer alignment.
@
text
@d1216 1
d1230 5
a1234 2
   consts_ptr = bld->consts[dimension];
   num_consts = bld->consts_sizes[dimension];
a1414 1
   const struct tgsi_shader_info *info = bld->bld_base.info;
a1420 11
   if (info->input_semantic_name[reg->Register.Index] == TGSI_SEMANTIC_PRIMID) {
      /* This is really a system value not a regular input */
      assert(!reg->Register.Indirect);
      assert(!reg->Dimension.Indirect);
      res = bld->system_values.prim_id;
      if (stype != TGSI_TYPE_UNSIGNED && stype != TGSI_TYPE_SIGNED) {
         res = LLVMBuildBitCast(builder, res, bld_base->base.vec_type, "");
      }
      return res;
   }

d1945 1
a1945 2
          LLVMValueRef *texel,
          unsigned sampler_reg)
d1947 1
a1947 1
   unsigned unit = inst->Src[sampler_reg].Register.Index;
a2016 4
      num_offsets = 2;
      num_derivs = 3;
      layer_coord = 3;
      break;
a2017 5
      num_offsets = 2;
      num_derivs = 3;
      layer_coord = 3;
      shadow_coord = 4; /* shadow coord special different reg */
      break;
d2028 1
a2028 9
      LLVMValueRef lod;
      if (inst->Texture.Texture == TGSI_TEXTURE_SHADOWCUBE ||
          inst->Texture.Texture == TGSI_TEXTURE_CUBE_ARRAY) {
         /* note that shadow cube array with bias/explicit lod does not exist */
         lod = lp_build_emit_fetch(&bld->bld_base, inst, 1, 0);
      }
      else {
         lod = lp_build_emit_fetch(&bld->bld_base, inst, 0, 3);
      }
d2060 1
a2060 6
      if (layer_coord == 3) {
         coords[3] = lp_build_emit_fetch(&bld->bld_base, inst, 0, layer_coord);
      }
      else {
         coords[2] = lp_build_emit_fetch(&bld->bld_base, inst, 0, layer_coord);
      }
d2066 1
a2066 6
      if (shadow_coord == 4) {
         coords[4] = lp_build_emit_fetch(&bld->bld_base, inst, 1, 0);
      }
      else {
         coords[4] = lp_build_emit_fetch(&bld->bld_base, inst, 0, shadow_coord);
      }
d2078 1
d2094 2
d2303 1
a2303 1
   LLVMValueRef coords[5];
a2336 1
   case TGSI_TEXTURE_2D_MSAA:
a2339 1
   case TGSI_TEXTURE_2D_ARRAY_MSAA:
d2351 2
a2352 4
   /* always have lod except for buffers and msaa targets ? */
   if (target != TGSI_TEXTURE_BUFFER &&
       target != TGSI_TEXTURE_2D_MSAA &&
       target != TGSI_TEXTURE_2D_ARRAY_MSAA) {
a2355 1
   /* XXX: for real msaa support, the w component would be the sample index. */
d2360 1
a2360 2
   /* never use more than 3 coords here but emit_fetch_texel copies all 5 anyway */
   for (i = dims; i < 5; i++) {
d2452 1
a2452 1
                                 TRUE,
d2460 1
a2460 1
                   int pc)
d2468 1
a2468 1
         return TRUE;
d2473 1
a2473 1
         return TRUE;
d2476 13
a2488 24
         opcode == TGSI_OPCODE_TXP ||
         opcode == TGSI_OPCODE_TXD ||
         opcode == TGSI_OPCODE_TXB ||
         opcode == TGSI_OPCODE_TXL ||
         opcode == TGSI_OPCODE_TXF ||
         opcode == TGSI_OPCODE_TXQ ||
         opcode == TGSI_OPCODE_TEX2 ||
         opcode == TGSI_OPCODE_TXB2 ||
         opcode == TGSI_OPCODE_TXL2 ||
         opcode == TGSI_OPCODE_SAMPLE ||
         opcode == TGSI_OPCODE_SAMPLE_B ||
         opcode == TGSI_OPCODE_SAMPLE_C ||
         opcode == TGSI_OPCODE_SAMPLE_C_LZ ||
         opcode == TGSI_OPCODE_SAMPLE_D ||
         opcode == TGSI_OPCODE_SAMPLE_I ||
         opcode == TGSI_OPCODE_SAMPLE_L ||
         opcode == TGSI_OPCODE_SVIEWINFO ||
         opcode == TGSI_OPCODE_CAL ||
         opcode == TGSI_OPCODE_CALLNZ ||
         opcode == TGSI_OPCODE_IF ||
         opcode == TGSI_OPCODE_UIF ||
         opcode == TGSI_OPCODE_BGNLOOP ||
         opcode == TGSI_OPCODE_SWITCH)
         return FALSE;
d2680 6
a2685 7
   assert(last <= bld->bld_base.info->file_max[decl->Declaration.File]);

   switch (decl->Declaration.File) {
   case TGSI_FILE_TEMPORARY:
      if (!(bld->indirect_files & (1 << TGSI_FILE_TEMPORARY))) {
         assert(last < LP_MAX_INLINED_TEMPS);
         for (idx = first; idx <= last; ++idx) {
d2689 1
a2689 2
      }
      break;
d2691 2
a2692 3
   case TGSI_FILE_OUTPUT:
      if (!(bld->indirect_files & (1 << TGSI_FILE_OUTPUT))) {
         for (idx = first; idx <= last; ++idx) {
d2697 1
a2697 2
      }
      break;
d2699 6
a2704 8
   case TGSI_FILE_ADDRESS:
      /* ADDR registers are only allocated with an integer LLVM IR type,
       * as they are guaranteed to always have integers.
       * XXX: Not sure if this exception is worthwhile (or the whole idea of
       * an ADDR register for that matter).
       */
      assert(last < LP_MAX_TGSI_ADDRS);
      for (idx = first; idx <= last; ++idx) {
d2708 1
a2708 2
      }
      break;
d2710 2
a2711 3
   case TGSI_FILE_PREDICATE:
      assert(last < LP_MAX_TGSI_PREDS);
      for (idx = first; idx <= last; ++idx) {
d2715 1
a2715 2
      }
      break;
d2717 6
a2722 7
   case TGSI_FILE_SAMPLER_VIEW:
      /*
       * The target stored here MUST match whatever there actually
       * is in the set sampler views (what about return type?).
       */
      assert(last < PIPE_MAX_SHADER_SAMPLER_VIEWS);
      for (idx = first; idx <= last; ++idx) {
d2724 5
a2729 25
      break;

   case TGSI_FILE_CONSTANT:
   {
      /*
       * We could trivially fetch the per-buffer pointer when fetching the
       * constant, relying on llvm to figure out it's always the same pointer
       * anyway. However, doing so results in a huge (more than factor of 10)
       * slowdown in llvm compilation times for some (but not all) shaders
       * (more specifically, the IR optimization spends way more time in
       * DominatorTree::dominates). At least with llvm versions 3.1, 3.3.
       */
      unsigned idx2D = decl->Dim.Index2D;
      LLVMValueRef index2D = lp_build_const_int32(gallivm, idx2D);
      assert(idx2D < LP_MAX_TGSI_CONST_BUFFERS);
      bld->consts[idx2D] =
         lp_build_array_get(gallivm, bld->consts_ptr, index2D);
      bld->consts_sizes[idx2D] =
         lp_build_array_get(gallivm, bld->const_sizes_ptr, index2D);
   }
      break;

   default:
      /* don't need to declare other vars */
      break;
d2865 1
a2865 14
   emit_tex(bld, emit_data->inst, LP_BLD_TEX_MODIFIER_NONE,
            emit_data->output, 1);
}

static void
tex2_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);

   emit_tex(bld, emit_data->inst, LP_BLD_TEX_MODIFIER_NONE,
            emit_data->output, 2);
d2877 1
a2877 13
            emit_data->output, 1);
}

static void
txb2_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);

   emit_tex(bld, emit_data->inst, LP_BLD_TEX_MODIFIER_LOD_BIAS,
            emit_data->output, 2);
d2889 1
a2889 1
            emit_data->output, 3);
d2901 1
a2901 13
            emit_data->output, 1);
}

static void
txl2_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);

   emit_tex(bld, emit_data->inst, LP_BLD_TEX_MODIFIER_EXPLICIT_LOD,
            emit_data->output, 2);
d2913 1
a2913 1
            emit_data->output, 1);
a3721 3
   bld.bld_base.op_actions[TGSI_OPCODE_TEX2].emit = tex2_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_TXB2].emit = txb2_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_TXL2].emit = txl2_emit;
d3738 2
a3739 2
      uint max_output_vertices;

d3747 6
a3752 5
      max_output_vertices =
            info->properties[TGSI_PROPERTY_GS_MAX_OUTPUT_VERTICES];
      if (!max_output_vertices)
         max_output_vertices = 32;

@


1.5
log
@Merge Mesa 10.2.3
tested by matthieu@@ kettenis@@ mpi@@ brett@@ and myself across a
diverse range of hardware
@
text
@a1215 1
   LLVMValueRef dimension_index;
d1229 2
a1230 5
   dimension_index = lp_build_const_int32(gallivm, dimension);
   consts_ptr =
      lp_build_array_get(gallivm, bld->consts_ptr, dimension_index);
   num_consts =
      lp_build_array_get(gallivm, bld->const_sizes_ptr, dimension_index);
d1411 1
d1418 11
d1953 2
a1954 1
          LLVMValueRef *texel)
d1956 1
a1956 1
   unsigned unit;
d2026 4
d2031 5
d2046 9
a2054 1
      LLVMValueRef lod = lp_build_emit_fetch(&bld->bld_base, inst, 0, 3);
d2086 6
a2091 1
      coords[2] = lp_build_emit_fetch(&bld->bld_base, inst, 0, layer_coord);
d2097 6
a2102 1
      coords[4] = lp_build_emit_fetch(&bld->bld_base, inst, 0, shadow_coord);
a2113 1
      unit = inst->Src[3].Register.Index;
a2128 2
   } else {
      unit = inst->Src[1].Register.Index;
d2336 1
a2336 1
   LLVMValueRef coords[3];
d2370 1
d2374 1
d2386 4
a2389 2
   /* always have lod except for buffers ? */
   if (target != TGSI_TEXTURE_BUFFER) {
d2393 1
d2398 2
a2399 1
   for (i = dims; i < 3; i++) {
d2491 1
a2491 1
                                 is_sviewinfo,
d2499 1
a2499 1
		   int pc)
d2507 1
a2507 1
	 return TRUE;
d2512 1
a2512 1
	 return TRUE;
d2515 24
a2538 13
	  opcode == TGSI_OPCODE_TXP ||
	  opcode == TGSI_OPCODE_TXD ||
	  opcode == TGSI_OPCODE_TXB ||
	  opcode == TGSI_OPCODE_TXL ||
	  opcode == TGSI_OPCODE_TXF ||
	  opcode == TGSI_OPCODE_TXQ ||
	  opcode == TGSI_OPCODE_CAL ||
	  opcode == TGSI_OPCODE_CALLNZ ||
	  opcode == TGSI_OPCODE_IF ||
          opcode == TGSI_OPCODE_UIF ||
	  opcode == TGSI_OPCODE_BGNLOOP ||
	  opcode == TGSI_OPCODE_SWITCH)
	 return FALSE;
d2730 7
a2736 6
   for (idx = first; idx <= last; ++idx) {
      assert(last <= bld->bld_base.info->file_max[decl->Declaration.File]);
      switch (decl->Declaration.File) {
      case TGSI_FILE_TEMPORARY:
         if (!(bld->indirect_files & (1 << TGSI_FILE_TEMPORARY))) {
            assert(idx < LP_MAX_INLINED_TEMPS);
d2740 2
a2741 1
         break;
d2743 3
a2745 2
      case TGSI_FILE_OUTPUT:
         if (!(bld->indirect_files & (1 << TGSI_FILE_OUTPUT))) {
d2750 2
a2751 1
         break;
d2753 8
a2760 6
      case TGSI_FILE_ADDRESS:
	 /* ADDR registers are only allocated with an integer LLVM IR type,
	  * as they are guaranteed to always have integers.
	  * XXX: Not sure if this exception is worthwhile (or the whole idea of
	  * an ADDR register for that matter).
	  */
d2764 2
a2765 1
         break;
d2767 3
a2769 2
      case TGSI_FILE_PREDICATE:
         assert(idx < LP_MAX_TGSI_PREDS);
d2773 2
a2774 1
         break;
d2776 7
a2782 6
      case TGSI_FILE_SAMPLER_VIEW:
         /*
          * The target stored here MUST match whatever there actually
          * is in the set sampler views (what about return type?).
          */
         assert(idx < PIPE_MAX_SHADER_SAMPLER_VIEWS);
d2784 22
a2805 1
         break;
d2807 3
a2809 4
      default:
         /* don't need to declare other vars */
         break;
      }
d2945 14
a2958 1
   emit_tex(bld, emit_data->inst, LP_BLD_TEX_MODIFIER_NONE, emit_data->output);
d2970 13
a2982 1
            emit_data->output);
d2994 1
a2994 1
            emit_data->output);
d3006 13
a3018 1
            emit_data->output);
d3030 1
a3030 1
            emit_data->output);
d3839 3
d3858 2
a3859 2
      uint max_output_vertices = 32;
      uint i = 0;
d3867 5
a3871 6
      for (i = 0; i < info->num_properties; ++i) {
         if (info->properties[i].name ==
             TGSI_PROPERTY_GS_MAX_OUTPUT_VERTICES) {
            max_output_vertices = info->properties[i].data[0];
         }
      }
@


1.4
log
@Merge Mesa 9.2.0
@
text
@d4 1
a4 1
 * Copyright 2007-2008 Tungsten Graphics, Inc., Cedar Park, Texas.
d22 1
a22 1
 * IN NO EVENT SHALL TUNGSTEN GRAPHICS AND/OR ITS SUPPLIERS BE LIABLE FOR
d50 1
d69 4
d75 123
a199 3
   LLVMTypeRef int_type = LLVMInt32TypeInContext(bld->gallivm->context);
   LLVMBuilderRef builder = bld->gallivm->builder;

d203 2
a204 4
   mask->cond_stack_size = 0;
   mask->loop_stack_size = 0;
   mask->call_stack_size = 0;
   mask->switch_stack_size = 0;
d211 4
a214 1
   mask->loop_limiter = lp_build_alloca(bld->gallivm, int_type, "looplimiter");
d216 4
a219 4
   LLVMBuildStore(
      builder,
      LLVMConstInt(int_type, LP_MAX_TGSI_LOOP_ITERATIONS, false),
      mask->loop_limiter);
d225 5
d231 1
a231 1
   if (mask->loop_stack_size) {
d246 1
a246 1
   if (mask->switch_stack_size) {
d253 1
a253 1
   if (mask->call_stack_size || mask->ret_in_main) {
d260 4
a263 5
   mask->has_mask = (mask->cond_stack_size > 0 ||
                     mask->loop_stack_size > 0 ||
                     mask->call_stack_size > 0 ||
                     mask->switch_stack_size > 0 ||
                     mask->ret_in_main);
d270 1
d272 5
a276 2
   assert(mask->cond_stack_size < LP_MAX_TGSI_NESTING);
   if (mask->cond_stack_size == 0) {
d279 1
a279 1
   mask->cond_stack[mask->cond_stack_size++] = mask->cond_mask;
d291 1
d295 5
a299 3
   assert(mask->cond_stack_size);
   prev_mask = mask->cond_stack[mask->cond_stack_size - 1];
   if (mask->cond_stack_size == 1) {
d313 6
a318 2
   assert(mask->cond_stack_size);
   mask->cond_mask = mask->cond_stack[--mask->cond_stack_size];
d325 1
d327 3
a329 5
   if (mask->loop_stack_size == 0) {
      assert(mask->loop_block == NULL);
      assert(mask->cont_mask == LLVMConstAllOnes(mask->int_vec_type));
      assert(mask->break_mask == LLVMConstAllOnes(mask->int_vec_type));
      assert(mask->break_var == NULL);
d332 3
a334 5
   assert(mask->loop_stack_size < LP_MAX_TGSI_NESTING);

   mask->break_type_stack[mask->loop_stack_size + mask->switch_stack_size] =
      mask->break_type;
   mask->break_type = LP_EXEC_MASK_BREAK_TYPE_LOOP;
d336 5
a340 5
   mask->loop_stack[mask->loop_stack_size].loop_block = mask->loop_block;
   mask->loop_stack[mask->loop_stack_size].cont_mask = mask->cont_mask;
   mask->loop_stack[mask->loop_stack_size].break_mask = mask->break_mask;
   mask->loop_stack[mask->loop_stack_size].break_var = mask->break_var;
   ++mask->loop_stack_size;
d342 2
a343 2
   mask->break_var = lp_build_alloca(mask->bld->gallivm, mask->int_vec_type, "");
   LLVMBuildStore(builder, mask->break_mask, mask->break_var);
d345 1
a345 1
   mask->loop_block = lp_build_insert_new_block(mask->bld->gallivm, "bgnloop");
d347 2
a348 2
   LLVMBuildBr(builder, mask->loop_block);
   LLVMPositionBuilderAtEnd(builder, mask->loop_block);
d350 1
a350 1
   mask->break_mask = LLVMBuildLoad(builder, mask->break_var, "");
d359 1
d361 1
a361 1
   if (mask->break_type == LP_EXEC_MASK_BREAK_TYPE_LOOP) {
d376 1
a376 1
      if (mask->switch_in_default) {
d383 2
a384 2
         if(break_always && mask->switch_pc) {
            bld_base->pc = mask->switch_pc;
d409 1
d415 1
a415 1
   if (mask->break_type == LP_EXEC_MASK_BREAK_TYPE_LOOP) {
d448 1
d458 7
d468 1
a468 2
   assert(mask->loop_stack_size);
   mask->cont_mask = mask->loop_stack[mask->loop_stack_size - 1].cont_mask;
d475 1
a475 1
   LLVMBuildStore(builder, mask->break_mask, mask->break_var);
d478 1
a478 1
   limiter = LLVMBuildLoad(builder, mask->loop_limiter, "");
d486 1
a486 1
   LLVMBuildStore(builder, limiter, mask->loop_limiter);
d508 1
a508 1
                   icond, mask->loop_block, endloop);
d512 8
a519 7
   assert(mask->loop_stack_size);
   --mask->loop_stack_size;
   mask->loop_block = mask->loop_stack[mask->loop_stack_size].loop_block;
   mask->cont_mask = mask->loop_stack[mask->loop_stack_size].cont_mask;
   mask->break_mask = mask->loop_stack[mask->loop_stack_size].break_mask;
   mask->break_var = mask->loop_stack[mask->loop_stack_size].break_var;
   mask->break_type = mask->break_type_stack[mask->loop_stack_size + mask->switch_stack_size];
d527 18
a544 10
   mask->break_type_stack[mask->loop_stack_size + mask->switch_stack_size] =
      mask->break_type;
   mask->break_type = LP_EXEC_MASK_BREAK_TYPE_SWITCH;

   mask->switch_stack[mask->switch_stack_size].switch_val = mask->switch_val;
   mask->switch_stack[mask->switch_stack_size].switch_mask = mask->switch_mask;
   mask->switch_stack[mask->switch_stack_size].switch_mask_default = mask->switch_mask_default;
   mask->switch_stack[mask->switch_stack_size].switch_in_default = mask->switch_in_default;
   mask->switch_stack[mask->switch_stack_size].switch_pc = mask->switch_pc;
   mask->switch_stack_size++;
a545 1
   mask->switch_val = switchval;
d547 4
a550 3
   mask->switch_mask_default = LLVMConstNull(mask->int_vec_type);
   mask->switch_in_default = false;
   mask->switch_pc = 0;
d559 6
d567 1
a567 1
   if (mask->switch_pc && !mask->switch_in_default) {
d570 2
a571 2
      prevmask = mask->switch_stack[mask->switch_stack_size - 1].switch_mask;
      defaultmask = LLVMBuildNot(builder, mask->switch_mask_default, "sw_default_mask");
d573 1
a573 1
      mask->switch_in_default = true;
d577 1
a577 1
      assert(bld_base->instructions[mask->switch_pc - 1].Instruction.Opcode ==
d581 1
a581 1
      bld_base->pc = mask->switch_pc;
d586 1
a586 1
      mask->switch_pc = tmp_pc - 1;
d591 2
a592 2
   else if (mask->switch_pc && mask->switch_in_default) {
      assert(bld_base->pc == mask->switch_pc + 1);
d595 6
a600 6
   mask->switch_stack_size--;
   mask->switch_val = mask->switch_stack[mask->switch_stack_size].switch_val;
   mask->switch_mask = mask->switch_stack[mask->switch_stack_size].switch_mask;
   mask->switch_mask_default = mask->switch_stack[mask->switch_stack_size].switch_mask_default;
   mask->switch_in_default = mask->switch_stack[mask->switch_stack_size].switch_in_default;
   mask->switch_pc = mask->switch_stack[mask->switch_stack_size].switch_pc;
d602 1
a602 1
   mask->break_type = mask->break_type_stack[mask->loop_stack_size + mask->switch_stack_size];
d611 1
d615 4
d620 5
a624 5
   if (!mask->switch_in_default) {
      prevmask = mask->switch_stack[mask->switch_stack_size - 1].switch_mask;
      casemask = lp_build_cmp(mask->bld, PIPE_FUNC_EQUAL, caseval, mask->switch_val);
      mask->switch_mask_default = LLVMBuildOr(builder, casemask,
                                              mask->switch_mask_default, "sw_default_mask");
d644 6
a649 1
   unsigned curr_switch_stack = mask->switch_stack_size;
d660 1
a660 1
         if (curr_switch_stack == mask->switch_stack_size) {
d669 1
a669 1
         if (curr_switch_stack == mask->switch_stack_size) {
d687 1
d692 4
d710 2
a711 2
      prevmask = mask->switch_stack[mask->switch_stack_size - 1].switch_mask;
      defaultmask = LLVMBuildNot(builder, mask->switch_mask_default, "sw_default_mask");
d714 1
a714 1
      mask->switch_in_default = true;
d728 1
a728 1
      boolean ft_into = (opcode != TGSI_OPCODE_BRK ||
d741 1
a741 1
      mask->switch_pc = bld_base->pc;
d789 8
a796 4
   assert(mask->call_stack_size < LP_MAX_TGSI_NESTING);
   mask->call_stack[mask->call_stack_size].pc = *pc;
   mask->call_stack[mask->call_stack_size].ret_mask = mask->ret_mask;
   mask->call_stack_size++;
d803 1
d806 4
a809 4
   if (mask->cond_stack_size == 0 &&
       mask->loop_stack_size == 0 &&
       mask->switch_stack_size == 0 &&
       mask->call_stack_size == 0) {
d815 1
a815 1
   if (mask->call_stack_size == 0) {
d841 11
a851 4
   assert(mask->call_stack_size);
   mask->call_stack_size--;
   *pc = mask->call_stack[mask->call_stack_size].pc;
   mask->ret_mask = mask->call_stack[mask->call_stack_size].ret_mask;
d856 37
d904 1
a904 9
   LLVMBuilderRef builder = bld->bld_base.base.gallivm->builder;
   assert(chan < 4);
   if (bld->indirect_files & (1 << TGSI_FILE_TEMPORARY)) {
      LLVMValueRef lindex = lp_build_const_int32(bld->bld_base.base.gallivm, index * 4 + chan);
      return LLVMBuildGEP(builder, bld->temps_array, &lindex, 1, "");
   }
   else {
      return bld->temps[index][chan];
   }
d918 1
a918 10
   LLVMBuilderRef builder = bld->bld_base.base.gallivm->builder;
   assert(chan < 4);
   if (bld->indirect_files & (1 << TGSI_FILE_OUTPUT)) {
      LLVMValueRef lindex = lp_build_const_int32(bld->bld_base.base.gallivm,
                                                 index * 4 + chan);
      return LLVMBuildGEP(builder, bld->outputs_array, &lindex, 1, "");
   }
   else {
      return bld->outputs[index][chan];
   }
d949 2
a950 1
             LLVMValueRef indexes)
d955 7
d970 41
a1010 3
      LLVMValueRef scalar_ptr = LLVMBuildGEP(builder, base_ptr,
                                             &index, 1, "gather_ptr");
      LLVMValueRef scalar = LLVMBuildLoad(builder, scalar_ptr, "");
d1012 6
a1017 1
      res = LLVMBuildInsertElement(builder, res, scalar, ii, "");
d1123 13
a1135 3
   max_index = lp_build_const_int_vec(bld->bld_base.base.gallivm,
                                      uint_bld->type,
                                      bld->bld_base.info->file_max[reg_file]);
d1137 3
a1139 2
   assert(!uint_bld->type.sign);
   index = lp_build_min(uint_bld, index, max_index);
d1172 33
a1214 1
   LLVMValueRef indirect_index = NULL;
d1218 1
d1231 4
a1234 1
   consts_ptr = lp_build_array_get(gallivm, bld->consts_ptr, dimension_index);
d1237 6
a1246 1
   }
d1248 9
a1256 4
   if (reg->Register.Indirect) {
      LLVMValueRef swizzle_vec =
         lp_build_const_int_vec(bld->bld_base.base.gallivm, uint_bld->type, swizzle);
      LLVMValueRef index_vec;  /* index into the const buffer */
d1263 2
a1264 1
      res = build_gather(&bld_base->base, consts_ptr, index_vec);
d1270 1
a1270 1
      index = lp_build_const_int32(gallivm, reg->Register.Index*4 + swizzle);
d1282 1
a1295 2
   struct lp_build_context *uint_bld = &bld_base->uint_bld;
   struct lp_build_context *float_bld = &bld_base->base;
a1296 1
   LLVMValueRef indirect_index = NULL;
d1298 1
a1298 15
   if (reg->Register.Indirect) {
      indirect_index = get_indirect_index(bld,
                                          reg->Register.File,
                                          reg->Register.Index,
                                          &reg->Indirect);
   }

   if (reg->Register.Indirect) {
      LLVMValueRef swizzle_vec =
         lp_build_const_int_vec(bld->bld_base.base.gallivm,
                                uint_bld->type, swizzle);
      LLVMValueRef length_vec =
         lp_build_const_int_vec(bld->bld_base.base.gallivm, uint_bld->type,
                                bld->bld_base.base.type.length);
      LLVMValueRef index_vec;  /* index into the const buffer */
d1300 1
a1300 4
      LLVMValueRef pixel_offsets;
      LLVMValueRef offsets[LP_MAX_VECTOR_LENGTH];
      LLVMTypeRef float4_ptr_type;
      int i;
d1302 3
a1304 5
      /* build pixel offset vector: {0, 1, 2, 3, ...} */
      for (i = 0; i < float_bld->type.length; i++) {
         offsets[i] = lp_build_const_int32(gallivm, i);
      }
      pixel_offsets = LLVMConstVector(offsets, float_bld->type.length);
d1306 3
a1308 5
      /* index_vec = (indirect_index * 4 + swizzle) * length */
      index_vec = lp_build_shl_imm(uint_bld, indirect_index, 2);
      index_vec = lp_build_add(uint_bld, index_vec, swizzle_vec);
      index_vec = lp_build_mul(uint_bld, index_vec, length_vec);
      index_vec = lp_build_add(uint_bld, index_vec, pixel_offsets);
d1310 14
a1323 5
      /* cast imms_array pointer to float* */
      float4_ptr_type = LLVMPointerType(
         LLVMFloatTypeInContext(bld->bld_base.base.gallivm->context), 0);
      imms_array = LLVMBuildBitCast(builder, bld->imms_array,
                                    float4_ptr_type, "");
d1325 9
a1333 2
      /* Gather values from the temporary register array */
      res = build_gather(&bld_base->base, imms_array, index_vec);
a1356 2
   struct lp_build_context *uint_bld = &bld_base->uint_bld;
   LLVMValueRef indirect_index = NULL;
d1360 5
a1368 1
   }
d1370 4
a1373 13
   if (reg->Register.Indirect) {
      LLVMValueRef swizzle_vec =
         lp_build_const_int_vec(gallivm, uint_bld->type, swizzle);
      LLVMValueRef length_vec =
         lp_build_const_int_vec(gallivm, uint_bld->type, bld->bld_base.base.type.length);
      LLVMValueRef index_vec;  /* index into the const buffer */
      LLVMValueRef inputs_array;
      LLVMTypeRef float4_ptr_type;

      /* index_vec = (indirect_index * 4 + swizzle) * length */
      index_vec = lp_build_shl_imm(uint_bld, indirect_index, 2);
      index_vec = lp_build_add(uint_bld, index_vec, swizzle_vec);
      index_vec = lp_build_mul(uint_bld, index_vec, length_vec);
d1376 2
a1377 3
      float4_ptr_type = LLVMPointerType(LLVMFloatTypeInContext(gallivm->context), 0);
      inputs_array = LLVMBuildBitCast(builder, bld->inputs_array,
                                         float4_ptr_type, "");
d1379 2
a1380 2
      /* Gather values from the temporary register array */
      res = build_gather(&bld_base->base, inputs_array, index_vec);
d1423 3
a1425 3
                                          reg->Register.File,
                                          reg->Register.Index,
                                          &reg->Indirect);
d1441 3
a1443 1
                                    vertex_index, attrib_index,
a1466 3
   struct lp_build_context *uint_bld = &bld_base->uint_bld;
   struct lp_build_context *float_bld = &bld_base->base;
   LLVMValueRef indirect_index = NULL;
d1470 5
a1478 14
   }

   if (reg->Register.Indirect) {
      LLVMValueRef swizzle_vec =
         lp_build_const_int_vec(bld->bld_base.base.gallivm, uint_bld->type, swizzle);
      LLVMValueRef length_vec =
         lp_build_const_int_vec(bld->bld_base.base.gallivm, uint_bld->type,
                                bld->bld_base.base.type.length);
      LLVMValueRef index_vec;  /* index into the const buffer */
      LLVMValueRef temps_array;
      LLVMValueRef pixel_offsets;
      LLVMValueRef offsets[LP_MAX_VECTOR_LENGTH];
      LLVMTypeRef float4_ptr_type;
      int i;
d1480 4
a1483 11
      /* build pixel offset vector: {0, 1, 2, 3, ...} */
      for (i = 0; i < float_bld->type.length; i++) {
         offsets[i] = lp_build_const_int32(gallivm, i);
      }
      pixel_offsets = LLVMConstVector(offsets, float_bld->type.length);

      /* index_vec = (indirect_index * 4 + swizzle) * length */
      index_vec = lp_build_shl_imm(uint_bld, indirect_index, 2);
      index_vec = lp_build_add(uint_bld, index_vec, swizzle_vec);
      index_vec = lp_build_mul(uint_bld, index_vec, length_vec);
      index_vec = lp_build_add(uint_bld, index_vec, pixel_offsets);
d1486 2
a1487 3
      float4_ptr_type = LLVMPointerType(LLVMFloatTypeInContext(bld->bld_base.base.gallivm->context), 0);
      temps_array = LLVMBuildBitCast(builder, bld->temps_array,
                                     float4_ptr_type, "");
d1490 1
a1490 1
      res = build_gather(&bld_base->base, temps_array, index_vec);
d1649 1
a1667 1
   struct lp_build_context *uint_bld = &bld_base->uint_bld;
d1684 1
a1684 2
      value = lp_build_max(float_bld, value, float_bld->zero);
      value = lp_build_min(float_bld, value, float_bld->one);
d1691 4
a1694 1
      value = lp_build_max(float_bld, value, lp_build_const_vec(gallivm, float_bld->type, -1.0));
d1712 4
d1722 1
a1722 5
         LLVMValueRef chan_vec =
            lp_build_const_int_vec(gallivm, uint_bld->type, chan_index);
         LLVMValueRef length_vec =
            lp_build_const_int_vec(gallivm, uint_bld->type, float_bld->type.length);
         LLVMValueRef index_vec;  /* indexes into the temp registers */
d1724 6
a1729 11
         LLVMValueRef pixel_offsets;
         LLVMTypeRef float_ptr_type;
         int i;

         /* build pixel offset vector: {0, 1, 2, 3, ...} */
         pixel_offsets = uint_bld->undef;
         for (i = 0; i < float_bld->type.length; i++) {
            LLVMValueRef ii = lp_build_const_int32(gallivm, i);
            pixel_offsets = LLVMBuildInsertElement(builder, pixel_offsets,
                                                   ii, ii, "");
         }
d1731 2
a1732 10
         /* index_vec = (indirect_index * 4 + chan_index) * length + offsets */
         index_vec = lp_build_shl_imm(uint_bld, indirect_index, 2);
         index_vec = lp_build_add(uint_bld, index_vec, chan_vec);
         index_vec = lp_build_mul(uint_bld, index_vec, length_vec);
         index_vec = lp_build_add(uint_bld, index_vec, pixel_offsets);

         float_ptr_type =
            LLVMPointerType(LLVMFloatTypeInContext(gallivm->context), 0);
         outputs_array = LLVMBuildBitCast(builder, bld->outputs_array,
                                          float_ptr_type, "");
d1734 1
a1734 1
         /* Scatter store values into temp registers */
a1749 5
         LLVMValueRef chan_vec =
            lp_build_const_int_vec(gallivm, uint_bld->type, chan_index);
         LLVMValueRef length_vec =
            lp_build_const_int_vec(gallivm, uint_bld->type,
                                   float_bld->type.length);
d1752 6
a1757 11
         LLVMValueRef pixel_offsets;
         LLVMTypeRef float_ptr_type;
         int i;

         /* build pixel offset vector: {0, 1, 2, 3, ...} */
         pixel_offsets = uint_bld->undef; 
         for (i = 0; i < float_bld->type.length; i++) {
            LLVMValueRef ii = lp_build_const_int32(gallivm, i);
            pixel_offsets = LLVMBuildInsertElement(builder, pixel_offsets,
                                                   ii, ii, "");
         }
d1759 2
a1760 10
         /* index_vec = (indirect_index * 4 + chan_index) * length + offsets */
         index_vec = lp_build_shl_imm(uint_bld, indirect_index, 2);
         index_vec = lp_build_add(uint_bld, index_vec, chan_vec);
         index_vec = lp_build_mul(uint_bld, index_vec, length_vec);
         index_vec = lp_build_add(uint_bld, index_vec, pixel_offsets);

         float_ptr_type =
            LLVMPointerType(LLVMFloatTypeInContext(gallivm->context), 0);
         temps_array = LLVMBuildBitCast(builder, bld->temps_array,
                                        float_ptr_type, "");
d1768 1
a1768 2
         temp_ptr = lp_get_temp_ptr_soa(bld, reg->Register.Index,
                                        chan_index);
d1795 33
d1850 87
d1950 1
a1950 1
   LLVMValueRef coords[4];
d1954 4
a1957 3
   boolean scalar_lod;
   unsigned num_coords, num_derivs, num_offsets;
   unsigned i;
d1968 3
a1971 6
      num_coords = 1;
      num_offsets = 1;
      num_derivs = 1;
      break;
   case TGSI_TEXTURE_1D_ARRAY:
      num_coords = 2;
d1975 3
a1979 1
      num_coords = 2;
d1983 3
d1987 1
a1987 2
   case TGSI_TEXTURE_SHADOW1D_ARRAY:
      num_coords = 3;
d1991 6
d1999 1
a1999 2
   case TGSI_TEXTURE_2D_ARRAY:
      num_coords = 3;
a2003 1
      num_coords = 3;
a2007 1
      num_coords = 3;
a2010 5
   case TGSI_TEXTURE_SHADOW2D_ARRAY:
      num_coords = 4;
      num_offsets = 2;
      num_derivs = 2;
      break;
d2012 1
a2012 1
      num_coords = 4;
d2016 4
d2026 12
a2037 9
   if (modifier == LP_BLD_TEX_MODIFIER_LOD_BIAS) {
      assert(num_coords < 4);
      lod_bias = lp_build_emit_fetch( &bld->bld_base, inst, 0, 3 );
      explicit_lod = NULL;
   }
   else if (modifier == LP_BLD_TEX_MODIFIER_EXPLICIT_LOD) {
      assert(num_coords < 4);
      lod_bias = NULL;
      explicit_lod = lp_build_emit_fetch( &bld->bld_base, inst, 0, 3 );
d2045 1
a2045 2
      assert(num_coords < 4);
      oow = lp_build_emit_fetch( &bld->bld_base, inst, 0, 3 );
d2049 2
a2050 2
   for (i = 0; i < num_coords; i++) {
      coords[i] = lp_build_emit_fetch( &bld->bld_base, inst, 0, i );
d2054 1
a2054 1
   for (i = num_coords; i < 4; i++) {
d2058 13
d2074 2
a2075 2
         derivs.ddx[dim] = lp_build_emit_fetch( &bld->bld_base, inst, 1, dim );
         derivs.ddy[dim] = lp_build_emit_fetch( &bld->bld_base, inst, 2, dim );
d2079 15
d2102 1
a2102 1
         offsets[dim] = lp_build_emit_fetch_texoffset(&bld->bld_base, inst, 0, dim );
a2105 3
   /* TODO: use scalar lod if explicit_lod, lod_bias or derivs are broadcasted scalars */
   scalar_lod = bld->bld_base.info->processor == TGSI_PROCESSOR_FRAGMENT;

d2114 1
a2114 1
                                  lod_bias, explicit_lod, scalar_lod,
d2128 1
a2128 1
   LLVMValueRef coords[4];
d2132 4
a2135 3
   boolean scalar_lod;
   unsigned num_coords, num_offsets, num_derivs;
   unsigned i;
a2158 1
      num_coords = 1;
d2163 1
a2163 1
      num_coords = 2;
a2168 1
      num_coords = 2;
d2173 1
a2173 1
      num_coords = 3;
a2177 1
      num_coords = 3;
a2181 1
      num_coords = 3;
d2186 1
a2186 1
      num_coords = 4;
d2195 12
a2206 7
   if (modifier == LP_BLD_TEX_MODIFIER_LOD_BIAS) {
      lod_bias = lp_build_emit_fetch( &bld->bld_base, inst, 3, 0 );
      explicit_lod = NULL;
   }
   else if (modifier == LP_BLD_TEX_MODIFIER_EXPLICIT_LOD) {
      lod_bias = NULL;
      explicit_lod = lp_build_emit_fetch( &bld->bld_base, inst, 3, 0 );
d2218 2
a2219 2
   for (i = 0; i < num_coords; i++) {
      coords[i] = lp_build_emit_fetch( &bld->bld_base, inst, 0, i );
d2221 1
a2221 1
   for (i = num_coords; i < 4; i++) {
d2224 9
a2232 5
   /*
    * XXX: whack shadow comparison value into place.
    * Should probably fix the interface for separate value
    * (it will not work for cube arrays if it is part of coords).
    */
d2234 1
a2234 3
      unsigned c_coord = num_coords > 2 ? 3 : 2;
      assert(num_coords < 4);
      coords[c_coord] = lp_build_emit_fetch( &bld->bld_base, inst, 3, 0 );
d2240 2
a2241 2
         derivs.ddx[dim] = lp_build_emit_fetch( &bld->bld_base, inst, 3, dim );
         derivs.ddy[dim] = lp_build_emit_fetch( &bld->bld_base, inst, 4, dim );
d2244 15
d2265 1
a2265 1
         offsets[dim] = lp_build_emit_fetch_texoffset(&bld->bld_base, inst, 0, dim );
a2268 3
   /* TODO: use scalar lod if explicit_lod, lod_bias or derivs are broadcasted scalars */
   scalar_lod = bld->bld_base.info->processor == TGSI_PROCESSOR_FRAGMENT;

d2277 1
a2277 1
                                  lod_bias, explicit_lod, scalar_lod,
d2279 13
d2305 3
a2307 4
   boolean scalar_lod;
   unsigned num_coords;
   unsigned dims;
   unsigned i;
a2328 1
      num_coords = 1;
d2332 1
a2332 1
      num_coords = 2;
a2336 1
      num_coords = 2;
d2340 1
a2340 1
      num_coords = 3;
a2343 1
      num_coords = 3;
d2353 2
a2354 1
      explicit_lod = lp_build_emit_fetch( &bld->bld_base, inst, 0, 3 );
d2357 2
a2358 2
   for (i = 0; i < num_coords; i++) {
      coords[i] = lp_build_emit_fetch( &bld->bld_base, inst, 0, i );
d2360 1
a2360 1
   for (i = num_coords; i < 3; i++) {
d2363 2
d2369 1
a2369 1
         offsets[dim] = lp_build_emit_fetch_texoffset(&bld->bld_base, inst, 0, dim );
a2372 3
   /* TODO: use scalar lod if explicit_lod is broadcasted scalar */
   scalar_lod = bld->bld_base.info->processor == TGSI_PROCESSOR_FRAGMENT;

d2381 1
a2381 1
                                  NULL, explicit_lod, scalar_lod,
d2383 14
d2406 1
d2410 1
a2410 1
   unsigned target;
d2436 5
a2440 3
   if (has_lod)
      explicit_lod = lp_build_emit_fetch( &bld->bld_base, inst, 0, 0 );
   else
d2442 5
d2451 1
a2451 1
                                 unit,
d2453 1
d2543 5
a2547 2
   if(mask) {
      lp_build_mask_update(bld->mask, mask);
d2549 3
a2551 3
      if (!near_end_of_shader(bld, pc))
	 lp_build_mask_check(bld->mask);
   }
d2590 2
a2591 1
emit_dump_temps(struct lp_build_tgsi_soa_context *bld)
d2593 1
d2596 1
a2596 5
   LLVMValueRef temp_ptr;
   LLVMValueRef i0 = lp_build_const_int32(gallivm, 0);
   LLVMValueRef i1 = lp_build_const_int32(gallivm, 1);
   LLVMValueRef i2 = lp_build_const_int32(gallivm, 2);
   LLVMValueRef i3 = lp_build_const_int32(gallivm, 3);
d2598 7
a2604 1
   int n = bld->bld_base.info->file_max[TGSI_FILE_TEMPORARY];
d2606 3
a2608 3
   for (index = 0; index < n; index++) {
      LLVMValueRef idx = lp_build_const_int32(gallivm, index);
      LLVMValueRef v[4][4], res;
d2611 11
a2621 1
      lp_build_printf(gallivm, "TEMP[%d]:\n", idx);
d2624 39
a2662 16
         temp_ptr = lp_get_temp_ptr_soa(bld, index, chan);
         res = LLVMBuildLoad(builder, temp_ptr, "");
         v[chan][0] = LLVMBuildExtractElement(builder, res, i0, "");
         v[chan][1] = LLVMBuildExtractElement(builder, res, i1, "");
         v[chan][2] = LLVMBuildExtractElement(builder, res, i2, "");
         v[chan][3] = LLVMBuildExtractElement(builder, res, i3, "");
      }

      lp_build_printf(gallivm, "  X: %f %f %f %f\n",
                      v[0][0], v[0][1], v[0][2], v[0][3]);
      lp_build_printf(gallivm, "  Y: %f %f %f %f\n",
                      v[1][0], v[1][1], v[1][2], v[1][3]);
      lp_build_printf(gallivm, "  Z: %f %f %f %f\n",
                      v[2][0], v[2][1], v[2][2], v[2][3]);
      lp_build_printf(gallivm, "  W: %f %f %f %f\n",
                      v[3][0], v[3][1], v[3][2], v[3][3]);
a2683 1
         assert(idx < LP_MAX_TGSI_TEMPS);
d2685 1
d2740 1
a2740 2

   /* simply copy the immediate values into the next immediates[] slot */
a2743 1
   assert(bld->num_immediates < LP_MAX_TGSI_IMMEDIATES);
d2747 2
a2748 2
         bld->immediates[bld->num_immediates][i] =
            lp_build_const_vec(gallivm, bld_base->base.type, imm->u[i].Float);
d2754 1
a2754 2
         bld->immediates[bld->num_immediates][i] =
            LLVMConstBitCast(tmp, bld_base->base.vec_type);
d2761 1
a2761 2
         bld->immediates[bld->num_immediates][i] =
            LLVMConstBitCast(tmp, bld_base->base.vec_type);
d2763 1
a2763 1
            
d2767 1
a2767 1
      bld->immediates[bld->num_immediates][i] = bld_base->base.undef;
d2769 1
a2769 1
   if (bld->indirect_files & (1 << TGSI_FILE_IMMEDIATE)) {
d2773 2
d2777 1
a2777 1
            bld->bld_base.base.gallivm, index * 4 + i);
d2780 25
a2804 3
         LLVMBuildStore(builder, 
                        bld->immediates[index][i],
                        imm_ptr);
d3033 1
a3033 1
mask_to_one_vec(struct lp_build_tgsi_context *bld_base)
a3036 1
   LLVMValueRef one_vec = bld_base->int_bld.one;
d3039 2
a3040 2
   if (exec_mask->has_mask) {
      one_vec = LLVMBuildAnd(builder, one_vec, exec_mask->exec_mask, "");
d3042 2
a3043 3
   one_vec = LLVMBuildAnd(builder, one_vec,
                          lp_build_mask_value(bld->mask), "");
   return one_vec;
d3052 3
a3055 4
   LLVMValueRef current_vec = LLVMBuildLoad(builder, ptr, "");
   
   current_vec = LLVMBuildAdd(builder, current_vec, mask, "");
   
a3064 1

a3065 4
   LLVMValueRef full_mask = lp_build_cmp(&bld_base->uint_bld,
                                         PIPE_FUNC_NOTEQUAL,
                                         mask,
                                         bld_base->uint_bld.zero);
d3068 1
a3068 1
                                 full_mask,
d3071 1
a3071 1
   
d3081 2
a3082 2
   struct lp_build_context *uint_bld = &bld->bld_base.uint_bld;
   LLVMValueRef max_mask = lp_build_cmp(uint_bld, PIPE_FUNC_LESS,
d3099 1
a3099 1
      LLVMValueRef masked_ones = mask_to_one_vec(bld_base);
d3102 2
a3103 2
      masked_ones = clamp_mask_to_max_output_vertices(bld, masked_ones,
                                                      total_emitted_vertices_vec);
d3109 1
a3109 1
                                masked_ones);
d3111 1
a3111 1
                                masked_ones);
d3115 1
a3115 1
                           masked_ones);
d3126 1
a3126 1
                     LLVMValueRef masked_ones)
d3132 1
d3137 10
a3146 1
      
d3154 1
a3154 1
                           masked_ones);
d3164 1
a3164 1
                                masked_ones);
d3166 1
a3166 1
                                   masked_ones);
d3186 2
a3187 15
      LLVMBuilderRef builder = bld_base->base.gallivm->builder;
      LLVMValueRef masked_ones = mask_to_one_vec(bld_base);
      struct lp_build_context *uint_bld = &bld_base->uint_bld;
      LLVMValueRef emitted_verts = LLVMBuildLoad(
         builder, bld->emitted_vertices_vec_ptr, "");
      LLVMValueRef emitted_mask = lp_build_cmp(uint_bld, PIPE_FUNC_NOTEQUAL,
                                               emitted_verts,
                                               uint_bld->zero);
      /* We need to combine the current execution mask with the mask
         telling us which, if any, execution slots actually have
         unemitted primitives, this way we make sure that end_primitives
         executes only on the paths that have unflushed vertices */
      masked_ones = LLVMBuildAnd(builder, masked_ones, emitted_mask, "");
      
      end_primitive_masked(bld_base, masked_ones);
d3568 7
d3582 1
a3582 1
   if (0) {
d3584 5
a3588 1
      emit_dump_temps(bld);
d3597 3
a3599 2
         vertices in the cache */
      end_primitive(NULL, bld_base, NULL);
d3621 1
d3649 1
d3654 20
d3675 1
d3754 1
a3754 1
         lp_build_const_int_vec(gallivm, bld.bld_base.uint_bld.type,
d3779 1
@


1.3
log
@Upate to libGL 7.11.2

Tested by jsg@@, matthieu@@ and ajacoutot@@, ok mattieu@@
@
text
@d45 1
d50 1
d65 2
d68 1
d70 1
a70 56
#define FOR_EACH_CHANNEL( CHAN )\
   for (CHAN = 0; CHAN < NUM_CHANNELS; CHAN++)

#define IS_DST0_CHANNEL_ENABLED( INST, CHAN )\
   ((INST)->Dst[0].Register.WriteMask & (1 << (CHAN)))

#define IF_IS_DST0_CHANNEL_ENABLED( INST, CHAN )\
   if (IS_DST0_CHANNEL_ENABLED( INST, CHAN ))

#define FOR_EACH_DST0_ENABLED_CHANNEL( INST, CHAN )\
   FOR_EACH_CHANNEL( CHAN )\
      IF_IS_DST0_CHANNEL_ENABLED( INST, CHAN )

#define CHAN_X 0
#define CHAN_Y 1
#define CHAN_Z 2
#define CHAN_W 3
#define NUM_CHANNELS 4

#define LP_MAX_INSTRUCTIONS 256


struct lp_exec_mask {
   struct lp_build_context *bld;

   boolean has_mask;

   LLVMTypeRef int_vec_type;

   LLVMValueRef cond_stack[LP_MAX_TGSI_NESTING];
   int cond_stack_size;
   LLVMValueRef cond_mask;

   LLVMBasicBlockRef loop_block;
   LLVMValueRef cont_mask;
   LLVMValueRef break_mask;
   LLVMValueRef break_var;
   struct {
      LLVMBasicBlockRef loop_block;
      LLVMValueRef cont_mask;
      LLVMValueRef break_mask;
      LLVMValueRef break_var;
   } loop_stack[LP_MAX_TGSI_NESTING];
   int loop_stack_size;

   LLVMValueRef ret_mask;
   struct {
      int pc;
      LLVMValueRef ret_mask;
   } call_stack[LP_MAX_TGSI_NESTING];
   int call_stack_size;

   LLVMValueRef exec_mask;
};

struct lp_build_tgsi_soa_context
d72 2
a73 37
   struct lp_build_context base;

   /* Builder for vector integer masks and indices */
   struct lp_build_context uint_bld;

   /* Builder for scalar elements of shader's data type (float) */
   struct lp_build_context elem_bld;

   LLVMValueRef consts_ptr;
   const LLVMValueRef *pos;
   const LLVMValueRef (*inputs)[NUM_CHANNELS];
   LLVMValueRef (*outputs)[NUM_CHANNELS];

   const struct lp_build_sampler_soa *sampler;

   LLVMValueRef immediates[LP_MAX_TGSI_IMMEDIATES][NUM_CHANNELS];
   LLVMValueRef temps[LP_MAX_TGSI_TEMPS][NUM_CHANNELS];
   LLVMValueRef addr[LP_MAX_TGSI_ADDRS][NUM_CHANNELS];
   LLVMValueRef preds[LP_MAX_TGSI_PREDS][NUM_CHANNELS];

   /* We allocate/use this array of temps if (1 << TGSI_FILE_TEMPORARY) is
    * set in the indirect_files field.
    * The temps[] array above is unused then.
    */
   LLVMValueRef temps_array;

   /* We allocate/use this array of output if (1 << TGSI_FILE_OUTPUT) is
    * set in the indirect_files field.
    * The outputs[] array above is unused then.
    */
   LLVMValueRef outputs_array;

   /* We allocate/use this array of inputs if (1 << TGSI_FILE_INPUT) is
    * set in the indirect_files field.
    * The inputs[] array above is unused then.
    */
   LLVMValueRef inputs_array;
a74 15
   LLVMValueRef system_values_array;

   const struct tgsi_shader_info *info;
   /** bitmask indicating which register files are accessed indirectly */
   unsigned indirect_files;

   struct lp_build_mask_context *mask;
   struct lp_exec_mask exec_mask;

   struct tgsi_full_instruction *instructions;
   uint max_instructions;
};

static void lp_exec_mask_init(struct lp_exec_mask *mask, struct lp_build_context *bld)
{
d77 1
d81 1
d84 2
a85 1
   mask->exec_mask = mask->ret_mask = mask->break_mask = mask->cont_mask = mask->cond_mask =
d87 7
d115 8
a122 1
   if (mask->call_stack_size) {
d131 3
a133 1
                     mask->call_stack_size > 0);
d194 4
d208 1
d217 51
a267 1
static void lp_exec_break(struct lp_exec_mask *mask)
d270 1
a270 1
   LLVMValueRef exec_mask = LLVMBuildNot(builder,
d272 2
a273 1
                                         "break");
d275 10
a284 3
   mask->break_mask = LLVMBuildAnd(builder,
                                   mask->break_mask,
                                   exec_mask, "break_full");
d309 1
d313 1
a313 1
   LLVMValueRef i1cond;
d330 12
a341 1
   /* i1cond = (mask == 0) */
d346 11
a356 1
      LLVMConstNull(reg_type), "");
d361 1
a361 1
                   i1cond, mask->loop_block, endloop);
d371 70
d445 128
a572 1
/* stores val into an address pointed to by dst.
d578 1
d581 1
a581 1
                               LLVMValueRef dst)
d585 4
d599 1
a599 6
      LLVMValueRef real_val, dst_val;

      dst_val = LLVMBuildLoad(builder, dst, "");
      real_val = lp_build_select(mask->bld,
                                 pred,
                                 val, dst_val);
d601 3
a603 1
      LLVMBuildStore(builder, real_val, dst);
d605 1
a605 1
      LLVMBuildStore(builder, val, dst);
d624 4
a627 1
   if (mask->call_stack_size == 0) {
d632 10
d673 2
a674 2
static LLVMValueRef
get_temp_ptr(struct lp_build_tgsi_soa_context *bld,
d678 1
a678 1
   LLVMBuilderRef builder = bld->base.gallivm->builder;
d681 1
a681 1
      LLVMValueRef lindex = lp_build_const_int32(bld->base.gallivm, index * 4 + chan);
d695 2
a696 2
static LLVMValueRef
get_output_ptr(struct lp_build_tgsi_soa_context *bld,
d700 1
a700 1
   LLVMBuilderRef builder = bld->base.gallivm->builder;
d703 1
a703 1
      LLVMValueRef lindex = lp_build_const_int32(bld->base.gallivm,
d712 20
d738 1
a738 1
build_gather(struct lp_build_tgsi_soa_context *bld,
d742 2
a743 2
   LLVMBuilderRef builder = bld->base.gallivm->builder;
   LLVMValueRef res = bld->base.undef;
d749 2
a750 2
   for (i = 0; i < bld->base.type.length; i++) {
      LLVMValueRef ii = lp_build_const_int32(bld->base.gallivm, i);
d775 1
a775 1
   struct gallivm_state *gallivm = bld->base.gallivm;
d792 1
a792 1
   for (i = 0; i < bld->base.type.length; i++) {
d826 1
a826 1
                   const struct tgsi_src_register *indirect_reg)
d828 2
a829 2
   LLVMBuilderRef builder = bld->base.gallivm->builder;
   struct lp_build_context *uint_bld = &bld->uint_bld;
d831 1
a831 1
   unsigned swizzle = indirect_reg->SwizzleX;
d839 1
a839 1
   base = lp_build_const_int_vec(bld->base.gallivm, uint_bld->type, reg_index);
d842 18
a859 8
   rel = LLVMBuildLoad(builder,
                        bld->addr[indirect_reg->Index][swizzle],
                        "load addr reg");

   /* for indexing we want integers */
   rel = LLVMBuildFPToSI(builder,
                         rel,
                         uint_bld->vec_type, "");
d863 1
a863 1
   max_index = lp_build_const_int_vec(bld->base.gallivm,
d865 1
a865 1
                                      bld->info->file_max[reg_file]);
d873 26
a899 3
/**
 * Register fetch.
 */
d901 5
a905 5
emit_fetch(
   struct lp_build_tgsi_soa_context *bld,
   const struct tgsi_full_instruction *inst,
   unsigned src_op,
   const unsigned chan_index )
d907 2
a908 1
   struct gallivm_state *gallivm = bld->base.gallivm;
d910 5
a914 4
   struct lp_build_context *uint_bld = &bld->uint_bld;
   const struct tgsi_full_src_register *reg = &inst->Src[src_op];
   const unsigned swizzle =
      tgsi_util_get_full_src_register_swizzle(reg, chan_index);
a915 1
   LLVMValueRef indirect_index = NULL;
d917 7
a923 3
   if (swizzle > 3) {
      assert(0 && "invalid swizzle in emit_fetch()");
      return bld->base.undef;
d926 3
a933 2
   } else {
      assert(reg->Register.Index <= bld->info->file_max[reg->Register.File]);
d936 8
a943 6
   switch (reg->Register.File) {
   case TGSI_FILE_CONSTANT:
      if (reg->Register.Indirect) {
         LLVMValueRef swizzle_vec =
            lp_build_const_int_vec(bld->base.gallivm, uint_bld->type, swizzle);
         LLVMValueRef index_vec;  /* index into the const buffer */
d945 6
a950 3
         /* index_vec = indirect_index * 4 + swizzle */
         index_vec = lp_build_shl_imm(uint_bld, indirect_index, 2);
         index_vec = lp_build_add(uint_bld, index_vec, swizzle_vec);
d952 1
a952 6
         /* Gather values from the constant buffer */
         res = build_gather(bld, bld->consts_ptr, index_vec);
      }
      else {
         LLVMValueRef index;  /* index into the const buffer */
         LLVMValueRef scalar, scalar_ptr;
d954 5
a958 1
         index = lp_build_const_int32(gallivm, reg->Register.Index*4 + swizzle);
d960 6
a965 3
         scalar_ptr = LLVMBuildGEP(builder, bld->consts_ptr,
                                   &index, 1, "");
         scalar = LLVMBuildLoad(builder, scalar_ptr, "");
d967 14
a980 3
         res = lp_build_broadcast_scalar(&bld->base, scalar);
      }
      break;
d982 6
a987 4
   case TGSI_FILE_IMMEDIATE:
      res = bld->immediates[reg->Register.Index][swizzle];
      assert(res);
      break;
d989 31
a1019 9
   case TGSI_FILE_INPUT:
      if (reg->Register.Indirect) {
         LLVMValueRef swizzle_vec =
            lp_build_const_int_vec(gallivm, uint_bld->type, swizzle);
         LLVMValueRef length_vec =
            lp_build_const_int_vec(gallivm, uint_bld->type, bld->base.type.length);
         LLVMValueRef index_vec;  /* index into the const buffer */
         LLVMValueRef inputs_array;
         LLVMTypeRef float4_ptr_type;
d1021 6
a1026 4
         /* index_vec = (indirect_index * 4 + swizzle) * length */
         index_vec = lp_build_shl_imm(uint_bld, indirect_index, 2);
         index_vec = lp_build_add(uint_bld, index_vec, swizzle_vec);
         index_vec = lp_build_mul(uint_bld, index_vec, length_vec);
d1028 7
a1034 4
         /* cast inputs_array pointer to float* */
         float4_ptr_type = LLVMPointerType(LLVMFloatTypeInContext(gallivm->context), 0);
         inputs_array = LLVMBuildBitCast(builder, bld->inputs_array,
                                         float4_ptr_type, "");
d1036 13
a1048 16
         /* Gather values from the temporary register array */
         res = build_gather(bld, inputs_array, index_vec);
      } else {
         if (bld->indirect_files & (1 << TGSI_FILE_INPUT)) {
            LLVMValueRef lindex = lp_build_const_int32(gallivm,
                                           reg->Register.Index * 4 + swizzle);
            LLVMValueRef input_ptr =  LLVMBuildGEP(builder,
                                                   bld->inputs_array, &lindex, 1, "");
            res = LLVMBuildLoad(builder, input_ptr, "");
         }
         else {
            res = bld->inputs[reg->Register.Index][swizzle];
         }
      }
      assert(res);
      break;
d1050 6
a1055 10
   case TGSI_FILE_TEMPORARY:
      if (reg->Register.Indirect) {
         LLVMValueRef swizzle_vec =
            lp_build_const_int_vec(bld->base.gallivm, uint_bld->type, swizzle);
         LLVMValueRef length_vec =
            lp_build_const_int_vec(bld->base.gallivm, uint_bld->type,
                                   bld->base.type.length);
         LLVMValueRef index_vec;  /* index into the const buffer */
         LLVMValueRef temps_array;
         LLVMTypeRef float4_ptr_type;
d1057 18
a1074 4
         /* index_vec = (indirect_index * 4 + swizzle) * length */
         index_vec = lp_build_shl_imm(uint_bld, indirect_index, 2);
         index_vec = lp_build_add(uint_bld, index_vec, swizzle_vec);
         index_vec = lp_build_mul(uint_bld, index_vec, length_vec);
d1076 9
a1084 7
         /* cast temps_array pointer to float* */
         float4_ptr_type = LLVMPointerType(LLVMFloatTypeInContext(bld->base.gallivm->context), 0);
         temps_array = LLVMBuildBitCast(builder, bld->temps_array,
                                        float4_ptr_type, "");

         /* Gather values from the temporary register array */
         res = build_gather(bld, temps_array, index_vec);
d1087 1
a1087 5
         LLVMValueRef temp_ptr;
         temp_ptr = get_temp_ptr(bld, reg->Register.Index, swizzle);
         res = LLVMBuildLoad(builder, temp_ptr, "");
         if (!res)
            return bld->base.undef;
a1088 22
      break;

   case TGSI_FILE_SYSTEM_VALUE:
      assert(!reg->Register.Indirect);
      {
         LLVMValueRef index;  /* index into the system value array */
         LLVMValueRef scalar, scalar_ptr;

         index = lp_build_const_int32(gallivm,
                                      reg->Register.Index * 4 + swizzle);

         scalar_ptr = LLVMBuildGEP(builder, bld->system_values_array,
                                   &index, 1, "");
         scalar = LLVMBuildLoad(builder, scalar_ptr, "");

         res = lp_build_broadcast_scalar(&bld->base, scalar);
      }
      break;

   default:
      assert(0 && "invalid src register in emit_fetch()");
      return bld->base.undef;
d1091 1
a1091 11
   switch( tgsi_util_get_full_src_register_sign_mode( reg, chan_index ) ) {
   case TGSI_UTIL_SIGN_CLEAR:
      res = lp_build_abs( &bld->base, res );
      break;

   case TGSI_UTIL_SIGN_SET:
      res = lp_build_abs( &bld->base, res );
      /* fall through */
   case TGSI_UTIL_SIGN_TOGGLE:
      res = lp_build_negate( &bld->base, res );
      break;
d1093 4
a1096 2
   case TGSI_UTIL_SIGN_KEEP:
      break;
d1103 170
d1279 1
a1279 3
   const struct tgsi_full_instruction *inst,
   unsigned index,
   const unsigned chan_index,
a1283 4
   LLVMValueRef src;

   src = emit_fetch(bld, inst, index, chan_index);

d1290 1
a1290 1
      *ddx = lp_build_ddx(&bld->base, src);
d1293 1
a1293 1
      *ddy = lp_build_ddy(&bld->base, src);
d1306 1
a1306 1
   LLVMBuilderRef builder = bld->base.gallivm->builder;
d1314 1
a1314 1
      FOR_EACH_CHANNEL( chan ) {
d1328 1
a1328 1
   FOR_EACH_CHANNEL( chan ) {
d1346 2
a1347 2
         value = lp_build_compare(bld->base.gallivm,
                                  bld->base.type,
d1350 1
a1350 1
                                  bld->base.zero);
a1363 1

d1368 2
a1369 2
emit_store(
   struct lp_build_tgsi_soa_context *bld,
d1376 2
a1377 1
   struct gallivm_state *gallivm = bld->base.gallivm;
d1380 3
a1382 1
   struct lp_build_context *uint_bld = &bld->uint_bld;
d1384 1
d1386 5
d1396 5
a1400 2
      value = lp_build_max(&bld->base, value, bld->base.zero);
      value = lp_build_min(&bld->base, value, bld->base.one);
d1404 5
a1408 2
      value = lp_build_max(&bld->base, value, lp_build_const_vec(bld->base.gallivm, bld->base.type, -1.0));
      value = lp_build_min(&bld->base, value, bld->base.one);
d1421 2
a1422 1
      assert(reg->Register.Index <= bld->info->file_max[reg->Register.File]);
d1427 3
d1434 1
a1434 1
            lp_build_const_int_vec(gallivm, uint_bld->type, bld->base.type.length);
d1443 1
a1443 1
         for (i = 0; i < bld->base.type.length; i++) {
d1465 3
a1467 3
         LLVMValueRef out_ptr = get_output_ptr(bld, reg->Register.Index,
                                               chan_index);
         lp_exec_mask_store(&bld->exec_mask, pred, value, out_ptr);
d1472 3
d1480 1
a1480 1
                                   bld->base.type.length);
d1489 1
a1489 1
         for (i = 0; i < bld->base.type.length; i++) {
d1511 4
a1514 3
         LLVMValueRef temp_ptr = get_temp_ptr(bld, reg->Register.Index,
                                              chan_index);
         lp_exec_mask_store(&bld->exec_mask, pred, value, temp_ptr);
d1519 4
a1522 1
      lp_exec_mask_store(&bld->exec_mask, pred, value,
d1527 3
a1529 1
      lp_exec_mask_store(&bld->exec_mask, pred, value,
d1536 2
d1540 21
a1571 1
   LLVMBuilderRef builder = bld->base.gallivm->builder;
d1575 6
a1580 4
   LLVMValueRef coords[3];
   LLVMValueRef ddx[3];
   LLVMValueRef ddy[3];
   unsigned num_coords;
d1586 1
a1586 1
         texel[i] = bld->base.undef;
d1594 7
d1605 2
d1609 5
d1616 10
a1626 1
   case TGSI_TEXTURE_CUBE:
d1628 12
d1646 1
d1648 2
a1649 1
      lod_bias = emit_fetch( bld, inst, 0, 3 );
d1653 1
d1655 1
a1655 1
      explicit_lod = emit_fetch( bld, inst, 0, 3 );
d1663 3
a1665 2
      oow = emit_fetch( bld, inst, 0, 3 );
      oow = lp_build_rcp(&bld->base, oow);
d1669 1
a1669 1
      coords[i] = emit_fetch( bld, inst, 0, i );
d1671 1
a1671 1
         coords[i] = lp_build_mul(&bld->base, coords[i], oow);
d1673 2
a1674 2
   for (i = num_coords; i < 3; i++) {
      coords[i] = bld->base.undef;
d1678 4
a1681 6
      LLVMValueRef index0 = lp_build_const_int32(bld->base.gallivm, 0);
      for (i = 0; i < num_coords; i++) {
         LLVMValueRef src1 = emit_fetch( bld, inst, 1, i );
         LLVMValueRef src2 = emit_fetch( bld, inst, 2, i );
         ddx[i] = LLVMBuildExtractElement(builder, src1, index0, "");
         ddy[i] = LLVMBuildExtractElement(builder, src2, index0, "");
d1683 1
d1685 194
a1878 4
   }  else {
      for (i = 0; i < num_coords; i++) {
         ddx[i] = lp_build_scalar_ddx( &bld->base, coords[i] );
         ddy[i] = lp_build_scalar_ddy( &bld->base, coords[i] );
d1880 47
a1926 1
      unit = inst->Src[1].Register.Index;
d1929 1
a1929 2
      ddx[i] = LLVMGetUndef(bld->base.elem_type);
      ddy[i] = LLVMGetUndef(bld->base.elem_type);
d1932 10
d1943 8
a1950 5
                                  bld->base.gallivm,
                                  bld->base.type,
                                  unit, num_coords, coords,
                                  ddx, ddy,
                                  lod_bias, explicit_lod,
d1954 50
d2013 1
a2013 1
      if (pc + i >= bld->info->num_instructions)
d2016 1
a2016 1
      opcode = bld->instructions[pc + i].Instruction.Opcode;
d2031 1
a2031 1
	  opcode == TGSI_OPCODE_IFC ||
d2046 1
a2046 1
emit_kil(
d2051 1
a2051 1
   LLVMBuilderRef builder = bld->base.gallivm->builder;
d2053 1
a2053 1
   LLVMValueRef terms[NUM_CHANNELS];
d2059 1
a2059 1
   FOR_EACH_CHANNEL( chan_index ) {
d2066 1
a2066 1
      assert(swizzle < NUM_CHANNELS);
d2069 1
a2069 1
         terms[swizzle] =  emit_fetch(bld, inst, 0, chan_index );
d2073 1
a2073 1
   FOR_EACH_CHANNEL( chan_index ) {
d2080 1
a2080 1
         chan_mask = lp_build_cmp(&bld->base, PIPE_FUNC_GEQUAL, terms[chan_index], bld->base.zero);
d2099 1
a2099 2
 * Predicated fragment kill.
 * XXX Actually, we do an unconditional kill (as in tgsi_exec.c).
d2104 2
a2105 3
emit_kilp(struct lp_build_tgsi_soa_context *bld,
          const struct tgsi_full_instruction *inst,
	  int pc)
d2107 1
a2107 1
   LLVMBuilderRef builder = bld->base.gallivm->builder;
d2117 1
a2117 1
      LLVMValueRef zero = LLVMConstNull(bld->base.int_vec_type);
d2135 1
a2135 1
   struct gallivm_state *gallivm = bld->base.gallivm;
d2143 1
a2143 1
   int n = bld->info->file_max[TGSI_FILE_TEMPORARY];
d2153 1
a2153 1
         temp_ptr = get_temp_ptr(bld, index, chan);
d2174 3
a2176 3
static void
emit_declaration(
   struct lp_build_tgsi_soa_context *bld,
d2179 3
a2181 2
   struct gallivm_state *gallivm = bld->base.gallivm;
   LLVMTypeRef vec_type = bld->base.vec_type;
d2187 1
a2187 1
      assert(last <= bld->info->file_max[decl->Declaration.File]);
d2192 1
a2192 1
            for (i = 0; i < NUM_CHANNELS; i++)
d2199 1
a2199 1
            for (i = 0; i < NUM_CHANNELS; i++)
d2206 5
d2212 2
a2213 2
         for (i = 0; i < NUM_CHANNELS; i++)
            bld->addr[idx][i] = lp_build_alloca(gallivm, vec_type, "addr");
d2218 1
a2218 1
         for (i = 0; i < NUM_CHANNELS; i++)
d2223 9
d2240 3
a2242 10
/**
 * Emit LLVM for one TGSI instruction.
 * \param return TRUE for success, FALSE otherwise
 */
static boolean
emit_instruction(
   struct lp_build_tgsi_soa_context *bld,
   const struct tgsi_full_instruction *inst,
   const struct tgsi_opcode_info *info,
   int *pc)
d2244 2
a2245 10
   unsigned chan_index;
   LLVMValueRef src0, src1, src2;
   LLVMValueRef tmp0, tmp1, tmp2;
   LLVMValueRef tmp3 = NULL;
   LLVMValueRef tmp4 = NULL;
   LLVMValueRef tmp5 = NULL;
   LLVMValueRef tmp6 = NULL;
   LLVMValueRef tmp7 = NULL;
   LLVMValueRef res;
   LLVMValueRef dst0[NUM_CHANNELS];
d2247 10
a2256 10
   /*
    * Stores and write masks are handled in a general fashion after the long
    * instruction opcode switch statement.
    *
    * Although not stricitly necessary, we avoid generating instructions for
    * channels which won't be stored, in cases where's that easy. For some
    * complex instructions, like texture sampling, it is more convenient to
    * assume a full writemask and then let LLVM optimization passes eliminate
    * redundant code.
    */
a2257 16
   (*pc)++;

   assert(info->num_dst <= 1);
   if (info->num_dst) {
      FOR_EACH_DST0_ENABLED_CHANNEL( inst, chan_index ) {
         dst0[chan_index] = bld->base.undef;
      }
   }

   switch (inst->Instruction.Opcode) {
   case TGSI_OPCODE_ARL:
      FOR_EACH_DST0_ENABLED_CHANNEL( inst, chan_index ) {
         tmp0 = emit_fetch( bld, inst, 0, chan_index );
         tmp0 = lp_build_floor(&bld->base, tmp0);
         dst0[chan_index] = tmp0;
      }
d2259 5
a2263 4

   case TGSI_OPCODE_MOV:
      FOR_EACH_DST0_ENABLED_CHANNEL( inst, chan_index ) {
         dst0[chan_index] = emit_fetch( bld, inst, 0, chan_index );
a2264 1
      break;
a2265 23
   case TGSI_OPCODE_LIT:
      if( IS_DST0_CHANNEL_ENABLED( inst, CHAN_X ) ) {
         dst0[CHAN_X] = bld->base.one;
      }
      if( IS_DST0_CHANNEL_ENABLED( inst, CHAN_Y ) ) {
         src0 = emit_fetch( bld, inst, 0, CHAN_X );
         dst0[CHAN_Y] = lp_build_max( &bld->base, src0, bld->base.zero);
      }
      if( IS_DST0_CHANNEL_ENABLED( inst, CHAN_Z ) ) {
         /* XMM[1] = SrcReg[0].yyyy */
         tmp1 = emit_fetch( bld, inst, 0, CHAN_Y );
         /* XMM[1] = max(XMM[1], 0) */
         tmp1 = lp_build_max( &bld->base, tmp1, bld->base.zero);
         /* XMM[2] = SrcReg[0].wwww */
         tmp2 = emit_fetch( bld, inst, 0, CHAN_W );
         tmp1 = lp_build_pow( &bld->base, tmp1, tmp2);
         tmp0 = emit_fetch( bld, inst, 0, CHAN_X );
         tmp2 = lp_build_cmp(&bld->base, PIPE_FUNC_GREATER, tmp0, bld->base.zero);
         dst0[CHAN_Z] = lp_build_select(&bld->base, tmp2, tmp1, bld->base.zero);
      }
      if( IS_DST0_CHANNEL_ENABLED( inst, CHAN_W ) ) {
         dst0[CHAN_W] = bld->base.one;
      }
d2267 5
a2271 7

   case TGSI_OPCODE_RCP:
   /* TGSI_OPCODE_RECIP */
      src0 = emit_fetch( bld, inst, 0, CHAN_X );
      res = lp_build_rcp(&bld->base, src0);
      FOR_EACH_DST0_ENABLED_CHANNEL( inst, chan_index ) {
         dst0[chan_index] = res;
d2273 1
d2275 3
d2279 12
a2290 7
   case TGSI_OPCODE_RSQ:
   /* TGSI_OPCODE_RECIPSQRT */
      src0 = emit_fetch( bld, inst, 0, CHAN_X );
      src0 = lp_build_abs(&bld->base, src0);
      res = lp_build_rsqrt(&bld->base, src0);
      FOR_EACH_DST0_ENABLED_CHANNEL( inst, chan_index ) {
         dst0[chan_index] = res;
d2292 1
a2292 1
      break;
d2294 2
a2295 7
   case TGSI_OPCODE_EXP:
      if (IS_DST0_CHANNEL_ENABLED( inst, CHAN_X ) ||
          IS_DST0_CHANNEL_ENABLED( inst, CHAN_Y ) ||
          IS_DST0_CHANNEL_ENABLED( inst, CHAN_Z )) {
         LLVMValueRef *p_exp2_int_part = NULL;
         LLVMValueRef *p_frac_part = NULL;
         LLVMValueRef *p_exp2 = NULL;
d2297 7
a2303 1
         src0 = emit_fetch( bld, inst, 0, CHAN_X );
d2305 3
a2307 6
         if (IS_DST0_CHANNEL_ENABLED( inst, CHAN_X ))
            p_exp2_int_part = &tmp0;
         if (IS_DST0_CHANNEL_ENABLED( inst, CHAN_Y ))
            p_frac_part = &tmp1;
         if (IS_DST0_CHANNEL_ENABLED( inst, CHAN_Z ))
            p_exp2 = &tmp2;
d2309 7
a2315 1
         lp_build_exp2_approx(&bld->base, src0, p_exp2_int_part, p_frac_part, p_exp2);
d2317 3
a2319 12
         if (IS_DST0_CHANNEL_ENABLED( inst, CHAN_X ))
            dst0[CHAN_X] = tmp0;
         if (IS_DST0_CHANNEL_ENABLED( inst, CHAN_Y ))
            dst0[CHAN_Y] = tmp1;
         if (IS_DST0_CHANNEL_ENABLED( inst, CHAN_Z ))
            dst0[CHAN_Z] = tmp2;
      }
      /* dst.w = 1.0 */
      if (IS_DST0_CHANNEL_ENABLED( inst, CHAN_W )) {
         dst0[CHAN_W] = bld->base.one;
      }
      break;
d2321 7
a2327 7
   case TGSI_OPCODE_LOG:
      if (IS_DST0_CHANNEL_ENABLED( inst, CHAN_X ) ||
          IS_DST0_CHANNEL_ENABLED( inst, CHAN_Y ) ||
          IS_DST0_CHANNEL_ENABLED( inst, CHAN_Z )) {
         LLVMValueRef *p_floor_log2 = NULL;
         LLVMValueRef *p_exp = NULL;
         LLVMValueRef *p_log2 = NULL;
d2329 2
a2330 2
         src0 = emit_fetch( bld, inst, 0, CHAN_X );
         src0 = lp_build_abs( &bld->base, src0 );
d2332 7
a2338 6
         if (IS_DST0_CHANNEL_ENABLED( inst, CHAN_X ))
            p_floor_log2 = &tmp0;
         if (IS_DST0_CHANNEL_ENABLED( inst, CHAN_Y ))
            p_exp = &tmp1;
         if (IS_DST0_CHANNEL_ENABLED( inst, CHAN_Z ))
            p_log2 = &tmp2;
d2340 2
a2341 1
         lp_build_log2_approx(&bld->base, src0, p_exp, p_floor_log2, p_log2);
d2343 7
a2349 16
         /* dst.x = floor(lg2(abs(src.x))) */
         if (IS_DST0_CHANNEL_ENABLED( inst, CHAN_X ))
            dst0[CHAN_X] = tmp0;
         /* dst.y = abs(src)/ex2(floor(lg2(abs(src.x)))) */
         if (IS_DST0_CHANNEL_ENABLED( inst, CHAN_Y )) {
            dst0[CHAN_Y] = lp_build_div( &bld->base, src0, tmp1);
         }
         /* dst.z = lg2(abs(src.x)) */
         if (IS_DST0_CHANNEL_ENABLED( inst, CHAN_Z ))
            dst0[CHAN_Z] = tmp2;
      }
      /* dst.w = 1.0 */
      if (IS_DST0_CHANNEL_ENABLED( inst, CHAN_W )) {
         dst0[CHAN_W] = bld->base.one;
      }
      break;
d2351 2
a2352 7
   case TGSI_OPCODE_MUL:
      FOR_EACH_DST0_ENABLED_CHANNEL( inst, chan_index ) {
         src0 = emit_fetch( bld, inst, 0, chan_index );
         src1 = emit_fetch( bld, inst, 1, chan_index );
         dst0[chan_index] = lp_build_mul(&bld->base, src0, src1);
      }
      break;
d2354 7
a2360 7
   case TGSI_OPCODE_ADD:
      FOR_EACH_DST0_ENABLED_CHANNEL( inst, chan_index ) {
         src0 = emit_fetch( bld, inst, 0, chan_index );
         src1 = emit_fetch( bld, inst, 1, chan_index );
         dst0[chan_index] = lp_build_add(&bld->base, src0, src1);
      }
      break;
d2362 3
a2364 17
   case TGSI_OPCODE_DP3:
   /* TGSI_OPCODE_DOT3 */
      tmp0 = emit_fetch( bld, inst, 0, CHAN_X );
      tmp1 = emit_fetch( bld, inst, 1, CHAN_X );
      tmp0 = lp_build_mul( &bld->base, tmp0, tmp1);
      tmp1 = emit_fetch( bld, inst, 0, CHAN_Y );
      tmp2 = emit_fetch( bld, inst, 1, CHAN_Y );
      tmp1 = lp_build_mul( &bld->base, tmp1, tmp2);
      tmp0 = lp_build_add( &bld->base, tmp0, tmp1);
      tmp1 = emit_fetch( bld, inst, 0, CHAN_Z );
      tmp2 = emit_fetch( bld, inst, 1, CHAN_Z );
      tmp1 = lp_build_mul( &bld->base, tmp1, tmp2);
      tmp0 = lp_build_add( &bld->base, tmp0, tmp1);
      FOR_EACH_DST0_ENABLED_CHANNEL( inst, chan_index ) {
         dst0[chan_index] = tmp0;
      }
      break;
d2366 7
a2372 21
   case TGSI_OPCODE_DP4:
   /* TGSI_OPCODE_DOT4 */
      tmp0 = emit_fetch( bld, inst, 0, CHAN_X );
      tmp1 = emit_fetch( bld, inst, 1, CHAN_X );
      tmp0 = lp_build_mul( &bld->base, tmp0, tmp1);
      tmp1 = emit_fetch( bld, inst, 0, CHAN_Y );
      tmp2 = emit_fetch( bld, inst, 1, CHAN_Y );
      tmp1 = lp_build_mul( &bld->base, tmp1, tmp2);
      tmp0 = lp_build_add( &bld->base, tmp0, tmp1);
      tmp1 = emit_fetch( bld, inst, 0, CHAN_Z );
      tmp2 = emit_fetch( bld, inst, 1, CHAN_Z );
      tmp1 = lp_build_mul( &bld->base, tmp1, tmp2);
      tmp0 = lp_build_add( &bld->base, tmp0, tmp1);
      tmp1 = emit_fetch( bld, inst, 0, CHAN_W );
      tmp2 = emit_fetch( bld, inst, 1, CHAN_W );
      tmp1 = lp_build_mul( &bld->base, tmp1, tmp2);
      tmp0 = lp_build_add( &bld->base, tmp0, tmp1);
      FOR_EACH_DST0_ENABLED_CHANNEL( inst, chan_index ) {
         dst0[chan_index] = tmp0;
      }
      break;
d2374 3
a2376 16
   case TGSI_OPCODE_DST:
      IF_IS_DST0_CHANNEL_ENABLED( inst, CHAN_X ) {
         dst0[CHAN_X] = bld->base.one;
      }
      IF_IS_DST0_CHANNEL_ENABLED( inst, CHAN_Y ) {
         tmp0 = emit_fetch( bld, inst, 0, CHAN_Y );
         tmp1 = emit_fetch( bld, inst, 1, CHAN_Y );
         dst0[CHAN_Y] = lp_build_mul( &bld->base, tmp0, tmp1);
      }
      IF_IS_DST0_CHANNEL_ENABLED( inst, CHAN_Z ) {
         dst0[CHAN_Z] = emit_fetch( bld, inst, 0, CHAN_Z );
      }
      IF_IS_DST0_CHANNEL_ENABLED( inst, CHAN_W ) {
         dst0[CHAN_W] = emit_fetch( bld, inst, 1, CHAN_W );
      }
      break;
d2378 7
a2384 7
   case TGSI_OPCODE_MIN:
      FOR_EACH_DST0_ENABLED_CHANNEL( inst, chan_index ) {
         src0 = emit_fetch( bld, inst, 0, chan_index );
         src1 = emit_fetch( bld, inst, 1, chan_index );
         dst0[chan_index] = lp_build_min( &bld->base, src0, src1 );
      }
      break;
d2386 3
a2388 7
   case TGSI_OPCODE_MAX:
      FOR_EACH_DST0_ENABLED_CHANNEL( inst, chan_index ) {
         src0 = emit_fetch( bld, inst, 0, chan_index );
         src1 = emit_fetch( bld, inst, 1, chan_index );
         dst0[chan_index] = lp_build_max( &bld->base, src0, src1 );
      }
      break;
d2390 7
a2396 9
   case TGSI_OPCODE_SLT:
   /* TGSI_OPCODE_SETLT */
      FOR_EACH_DST0_ENABLED_CHANNEL( inst, chan_index ) {
         src0 = emit_fetch( bld, inst, 0, chan_index );
         src1 = emit_fetch( bld, inst, 1, chan_index );
         tmp0 = lp_build_cmp( &bld->base, PIPE_FUNC_LESS, src0, src1 );
         dst0[chan_index] = lp_build_select( &bld->base, tmp0, bld->base.one, bld->base.zero );
      }
      break;
d2398 3
a2400 9
   case TGSI_OPCODE_SGE:
   /* TGSI_OPCODE_SETGE */
      FOR_EACH_DST0_ENABLED_CHANNEL( inst, chan_index ) {
         src0 = emit_fetch( bld, inst, 0, chan_index );
         src1 = emit_fetch( bld, inst, 1, chan_index );
         tmp0 = lp_build_cmp( &bld->base, PIPE_FUNC_GEQUAL, src0, src1 );
         dst0[chan_index] = lp_build_select( &bld->base, tmp0, bld->base.one, bld->base.zero );
      }
      break;
d2402 7
a2408 11
   case TGSI_OPCODE_MAD:
   /* TGSI_OPCODE_MADD */
      FOR_EACH_DST0_ENABLED_CHANNEL( inst, chan_index ) {
         tmp0 = emit_fetch( bld, inst, 0, chan_index );
         tmp1 = emit_fetch( bld, inst, 1, chan_index );
         tmp2 = emit_fetch( bld, inst, 2, chan_index );
         tmp0 = lp_build_mul( &bld->base, tmp0, tmp1);
         tmp0 = lp_build_add( &bld->base, tmp0, tmp2);
         dst0[chan_index] = tmp0;
      }
      break;
d2410 2
a2411 7
   case TGSI_OPCODE_SUB:
      FOR_EACH_DST0_ENABLED_CHANNEL( inst, chan_index ) {
         tmp0 = emit_fetch( bld, inst, 0, chan_index );
         tmp1 = emit_fetch( bld, inst, 1, chan_index );
         dst0[chan_index] = lp_build_sub( &bld->base, tmp0, tmp1);
      }
      break;
d2413 7
a2419 10
   case TGSI_OPCODE_LRP:
      FOR_EACH_DST0_ENABLED_CHANNEL( inst, chan_index ) {
         src0 = emit_fetch( bld, inst, 0, chan_index );
         src1 = emit_fetch( bld, inst, 1, chan_index );
         src2 = emit_fetch( bld, inst, 2, chan_index );
         tmp0 = lp_build_sub( &bld->base, src1, src2 );
         tmp0 = lp_build_mul( &bld->base, src0, tmp0 );
         dst0[chan_index] = lp_build_add( &bld->base, tmp0, src2 );
      }
      break;
d2421 2
a2422 10
   case TGSI_OPCODE_CND:
      FOR_EACH_DST0_ENABLED_CHANNEL( inst, chan_index ) {
         src0 = emit_fetch( bld, inst, 0, chan_index );
         src1 = emit_fetch( bld, inst, 1, chan_index );
         src2 = emit_fetch( bld, inst, 2, chan_index );
         tmp1 = lp_build_const_vec(bld->base.gallivm, bld->base.type, 0.5);
         tmp0 = lp_build_cmp( &bld->base, PIPE_FUNC_GREATER, src2, tmp1);
         dst0[chan_index] = lp_build_select( &bld->base, tmp0, src0, src1 );
      }
      break;
d2424 7
a2430 14
   case TGSI_OPCODE_DP2A:
      tmp0 = emit_fetch( bld, inst, 0, CHAN_X );  /* xmm0 = src[0].x */
      tmp1 = emit_fetch( bld, inst, 1, CHAN_X );  /* xmm1 = src[1].x */
      tmp0 = lp_build_mul( &bld->base, tmp0, tmp1);              /* xmm0 = xmm0 * xmm1 */
      tmp1 = emit_fetch( bld, inst, 0, CHAN_Y );  /* xmm1 = src[0].y */
      tmp2 = emit_fetch( bld, inst, 1, CHAN_Y );  /* xmm2 = src[1].y */
      tmp1 = lp_build_mul( &bld->base, tmp1, tmp2);              /* xmm1 = xmm1 * xmm2 */
      tmp0 = lp_build_add( &bld->base, tmp0, tmp1);              /* xmm0 = xmm0 + xmm1 */
      tmp1 = emit_fetch( bld, inst, 2, CHAN_X );  /* xmm1 = src[2].x */
      tmp0 = lp_build_add( &bld->base, tmp0, tmp1);              /* xmm0 = xmm0 + xmm1 */
      FOR_EACH_DST0_ENABLED_CHANNEL( inst, chan_index ) {
         dst0[chan_index] = tmp0;  /* dest[ch] = xmm0 */
      }
      break;
d2432 2
a2433 8
   case TGSI_OPCODE_FRC:
      FOR_EACH_DST0_ENABLED_CHANNEL( inst, chan_index ) {
         src0 = emit_fetch( bld, inst, 0, chan_index );
         tmp0 = lp_build_floor(&bld->base, src0);
         tmp0 = lp_build_sub(&bld->base, src0, tmp0);
         dst0[chan_index] = tmp0;
      }
      break;
d2435 7
a2441 10
   case TGSI_OPCODE_CLAMP:
      FOR_EACH_DST0_ENABLED_CHANNEL( inst, chan_index ) {
         tmp0 = emit_fetch( bld, inst, 0, chan_index );
         src1 = emit_fetch( bld, inst, 1, chan_index );
         src2 = emit_fetch( bld, inst, 2, chan_index );
         tmp0 = lp_build_max(&bld->base, tmp0, src1);
         tmp0 = lp_build_min(&bld->base, tmp0, src2);
         dst0[chan_index] = tmp0;
      }
      break;
d2443 3
a2445 6
   case TGSI_OPCODE_FLR:
      FOR_EACH_DST0_ENABLED_CHANNEL( inst, chan_index ) {
         tmp0 = emit_fetch( bld, inst, 0, chan_index );
         dst0[chan_index] = lp_build_floor(&bld->base, tmp0);
      }
      break;
d2447 7
a2453 6
   case TGSI_OPCODE_ROUND:
      FOR_EACH_DST0_ENABLED_CHANNEL( inst, chan_index ) {
         tmp0 = emit_fetch( bld, inst, 0, chan_index );
         dst0[chan_index] = lp_build_round(&bld->base, tmp0);
      }
      break;
d2455 3
a2457 8
   case TGSI_OPCODE_EX2: {
      tmp0 = emit_fetch( bld, inst, 0, CHAN_X );
      tmp0 = lp_build_exp2( &bld->base, tmp0);
      FOR_EACH_DST0_ENABLED_CHANNEL( inst, chan_index ) {
         dst0[chan_index] = tmp0;
      }
      break;
   }
d2459 7
a2465 7
   case TGSI_OPCODE_LG2:
      tmp0 = emit_fetch( bld, inst, 0, CHAN_X );
      tmp0 = lp_build_log2( &bld->base, tmp0);
      FOR_EACH_DST0_ENABLED_CHANNEL( inst, chan_index ) {
         dst0[chan_index] = tmp0;
      }
      break;
d2467 3
a2469 8
   case TGSI_OPCODE_POW:
      src0 = emit_fetch( bld, inst, 0, CHAN_X );
      src1 = emit_fetch( bld, inst, 1, CHAN_X );
      res = lp_build_pow( &bld->base, src0, src1 );
      FOR_EACH_DST0_ENABLED_CHANNEL( inst, chan_index ) {
         dst0[chan_index] = res;
      }
      break;
d2471 7
a2477 40
   case TGSI_OPCODE_XPD:
      if( IS_DST0_CHANNEL_ENABLED( inst, CHAN_X ) ||
          IS_DST0_CHANNEL_ENABLED( inst, CHAN_Y ) ) {
         tmp1 = emit_fetch( bld, inst, 1, CHAN_Z );
         tmp3 = emit_fetch( bld, inst, 0, CHAN_Z );
      }
      if( IS_DST0_CHANNEL_ENABLED( inst, CHAN_X ) ||
          IS_DST0_CHANNEL_ENABLED( inst, CHAN_Z ) ) {
         tmp0 = emit_fetch( bld, inst, 0, CHAN_Y );
         tmp4 = emit_fetch( bld, inst, 1, CHAN_Y );
      }
      IF_IS_DST0_CHANNEL_ENABLED( inst, CHAN_X ) {
         tmp2 = tmp0;
         tmp2 = lp_build_mul( &bld->base, tmp2, tmp1);
         tmp5 = tmp3;
         tmp5 = lp_build_mul( &bld->base, tmp5, tmp4);
         tmp2 = lp_build_sub( &bld->base, tmp2, tmp5);
         dst0[CHAN_X] = tmp2;
      }
      if( IS_DST0_CHANNEL_ENABLED( inst, CHAN_Y ) ||
          IS_DST0_CHANNEL_ENABLED( inst, CHAN_Z ) ) {
         tmp2 = emit_fetch( bld, inst, 1, CHAN_X );
         tmp5 = emit_fetch( bld, inst, 0, CHAN_X );
      }
      IF_IS_DST0_CHANNEL_ENABLED( inst, CHAN_Y ) {
         tmp3 = lp_build_mul( &bld->base, tmp3, tmp2);
         tmp1 = lp_build_mul( &bld->base, tmp1, tmp5);
         tmp3 = lp_build_sub( &bld->base, tmp3, tmp1);
         dst0[CHAN_Y] = tmp3;
      }
      IF_IS_DST0_CHANNEL_ENABLED( inst, CHAN_Z ) {
         tmp5 = lp_build_mul( &bld->base, tmp5, tmp4);
         tmp0 = lp_build_mul( &bld->base, tmp0, tmp2);
         tmp5 = lp_build_sub( &bld->base, tmp5, tmp0);
         dst0[CHAN_Z] = tmp5;
      }
      IF_IS_DST0_CHANNEL_ENABLED( inst, CHAN_W ) {
         dst0[CHAN_W] = bld->base.one;
      }
      break;
d2479 3
a2481 6
   case TGSI_OPCODE_ABS:
      FOR_EACH_DST0_ENABLED_CHANNEL( inst, chan_index ) {
         tmp0 = emit_fetch( bld, inst, 0, chan_index );
         dst0[chan_index] = lp_build_abs( &bld->base, tmp0 );
      }
      break;
d2483 7
a2489 4
   case TGSI_OPCODE_RCC:
      /* deprecated? */
      assert(0);
      return FALSE;
d2491 3
a2493 18
   case TGSI_OPCODE_DPH:
      tmp0 = emit_fetch( bld, inst, 0, CHAN_X );
      tmp1 = emit_fetch( bld, inst, 1, CHAN_X );
      tmp0 = lp_build_mul( &bld->base, tmp0, tmp1);
      tmp1 = emit_fetch( bld, inst, 0, CHAN_Y );
      tmp2 = emit_fetch( bld, inst, 1, CHAN_Y );
      tmp1 = lp_build_mul( &bld->base, tmp1, tmp2);
      tmp0 = lp_build_add( &bld->base, tmp0, tmp1);
      tmp1 = emit_fetch( bld, inst, 0, CHAN_Z );
      tmp2 = emit_fetch( bld, inst, 1, CHAN_Z );
      tmp1 = lp_build_mul( &bld->base, tmp1, tmp2);
      tmp0 = lp_build_add( &bld->base, tmp0, tmp1);
      tmp1 = emit_fetch( bld, inst, 1, CHAN_W );
      tmp0 = lp_build_add( &bld->base, tmp0, tmp1);
      FOR_EACH_DST0_ENABLED_CHANNEL( inst, chan_index ) {
         dst0[chan_index] = tmp0;
      }
      break;
d2495 7
a2501 7
   case TGSI_OPCODE_COS:
      tmp0 = emit_fetch( bld, inst, 0, CHAN_X );
      tmp0 = lp_build_cos( &bld->base, tmp0 );
      FOR_EACH_DST0_ENABLED_CHANNEL( inst, chan_index ) {
         dst0[chan_index] = tmp0;
      }
      break;
d2503 3
a2505 5
   case TGSI_OPCODE_DDX:
      FOR_EACH_DST0_ENABLED_CHANNEL( inst, chan_index ) {
         emit_fetch_deriv( bld, inst, 0, chan_index, NULL, &dst0[chan_index], NULL);
      }
      break;
d2507 7
a2513 5
   case TGSI_OPCODE_DDY:
      FOR_EACH_DST0_ENABLED_CHANNEL( inst, chan_index ) {
         emit_fetch_deriv( bld, inst, 0, chan_index, NULL, NULL, &dst0[chan_index]);
      }
      break;
d2515 2
a2516 4
   case TGSI_OPCODE_KILP:
      /* predicated kill */
      emit_kilp( bld, inst, (*pc)-1 );
      break;
d2518 15
a2532 4
   case TGSI_OPCODE_KIL:
      /* conditional kill */
      emit_kil( bld, inst, (*pc)-1 );
      break;
d2534 6
a2539 3
   case TGSI_OPCODE_PK2H:
      return FALSE;
      break;
d2541 6
a2546 3
   case TGSI_OPCODE_PK2US:
      return FALSE;
      break;
d2548 20
a2567 3
   case TGSI_OPCODE_PK4B:
      return FALSE;
      break;
d2569 10
a2578 3
   case TGSI_OPCODE_PK4UB:
      return FALSE;
      break;
d2580 2
a2581 3
   case TGSI_OPCODE_RFL:
      return FALSE;
      break;
d2583 33
a2615 8
   case TGSI_OPCODE_SEQ:
      FOR_EACH_DST0_ENABLED_CHANNEL( inst, chan_index ) {
         src0 = emit_fetch( bld, inst, 0, chan_index );
         src1 = emit_fetch( bld, inst, 1, chan_index );
         tmp0 = lp_build_cmp( &bld->base, PIPE_FUNC_EQUAL, src0, src1 );
         dst0[chan_index] = lp_build_select( &bld->base, tmp0, bld->base.one, bld->base.zero );
      }
      break;
a2616 5
   case TGSI_OPCODE_SFL:
      FOR_EACH_DST0_ENABLED_CHANNEL( inst, chan_index ) {
         dst0[chan_index] = bld->base.zero;
      }
      break;
d2618 6
a2623 8
   case TGSI_OPCODE_SGT:
      FOR_EACH_DST0_ENABLED_CHANNEL( inst, chan_index ) {
         src0 = emit_fetch( bld, inst, 0, chan_index );
         src1 = emit_fetch( bld, inst, 1, chan_index );
         tmp0 = lp_build_cmp( &bld->base, PIPE_FUNC_GREATER, src0, src1 );
         dst0[chan_index] = lp_build_select( &bld->base, tmp0, bld->base.one, bld->base.zero );
      }
      break;
d2625 33
a2657 7
   case TGSI_OPCODE_SIN:
      tmp0 = emit_fetch( bld, inst, 0, CHAN_X );
      tmp0 = lp_build_sin( &bld->base, tmp0 );
      FOR_EACH_DST0_ENABLED_CHANNEL( inst, chan_index ) {
         dst0[chan_index] = tmp0;
      }
      break;
d2659 1
a2659 8
   case TGSI_OPCODE_SLE:
      FOR_EACH_DST0_ENABLED_CHANNEL( inst, chan_index ) {
         src0 = emit_fetch( bld, inst, 0, chan_index );
         src1 = emit_fetch( bld, inst, 1, chan_index );
         tmp0 = lp_build_cmp( &bld->base, PIPE_FUNC_LEQUAL, src0, src1 );
         dst0[chan_index] = lp_build_select( &bld->base, tmp0, bld->base.one, bld->base.zero );
      }
      break;
d2661 26
a2686 8
   case TGSI_OPCODE_SNE:
      FOR_EACH_DST0_ENABLED_CHANNEL( inst, chan_index ) {
         src0 = emit_fetch( bld, inst, 0, chan_index );
         src1 = emit_fetch( bld, inst, 1, chan_index );
         tmp0 = lp_build_cmp( &bld->base, PIPE_FUNC_NOTEQUAL, src0, src1 );
         dst0[chan_index] = lp_build_select( &bld->base, tmp0, bld->base.one, bld->base.zero );
      }
      break;
d2688 7
a2694 5
   case TGSI_OPCODE_STR:
      FOR_EACH_DST0_ENABLED_CHANNEL( inst, chan_index ) {
         dst0[chan_index] = bld->base.one;
      }
      break;
d2696 3
a2698 3
   case TGSI_OPCODE_TEX:
      emit_tex( bld, inst, LP_BLD_TEX_MODIFIER_NONE, dst0 );
      break;
d2700 7
a2706 3
   case TGSI_OPCODE_TXD:
      emit_tex( bld, inst, LP_BLD_TEX_MODIFIER_EXPLICIT_DERIV, dst0 );
      break;
d2708 2
a2709 5
   case TGSI_OPCODE_UP2H:
      /* deprecated */
      assert (0);
      return FALSE;
      break;
d2711 7
a2717 5
   case TGSI_OPCODE_UP2US:
      /* deprecated */
      assert(0);
      return FALSE;
      break;
d2719 2
a2720 5
   case TGSI_OPCODE_UP4B:
      /* deprecated */
      assert(0);
      return FALSE;
      break;
d2722 14
a2735 5
   case TGSI_OPCODE_UP4UB:
      /* deprecated */
      assert(0);
      return FALSE;
      break;
d2737 2
a2738 5
   case TGSI_OPCODE_X2D:
      /* deprecated? */
      assert(0);
      return FALSE;
      break;
d2740 13
a2752 5
   case TGSI_OPCODE_ARA:
      /* deprecated */
      assert(0);
      return FALSE;
      break;
d2754 14
a2767 7
   case TGSI_OPCODE_ARR:
      FOR_EACH_DST0_ENABLED_CHANNEL( inst, chan_index ) {
         tmp0 = emit_fetch( bld, inst, 0, chan_index );
         tmp0 = lp_build_round(&bld->base, tmp0);
         dst0[chan_index] = tmp0;
      }
      break;
d2769 7
a2775 5
   case TGSI_OPCODE_BRA:
      /* deprecated */
      assert(0);
      return FALSE;
      break;
d2777 2
a2778 4
   case TGSI_OPCODE_CAL:
      lp_exec_mask_call(&bld->exec_mask,
                        inst->Label.Label,
                        pc);
d2780 7
a2786 1
      break;
d2788 2
a2789 3
   case TGSI_OPCODE_RET:
      lp_exec_mask_ret(&bld->exec_mask, pc);
      break;
d2791 7
a2797 7
   case TGSI_OPCODE_END:
      if (0) {
         /* for debugging */
         emit_dump_temps(bld);
      }
      *pc = -1;
      break;
d2799 2
a2800 113
   case TGSI_OPCODE_SSG:
   /* TGSI_OPCODE_SGN */
      FOR_EACH_DST0_ENABLED_CHANNEL( inst, chan_index ) {
         tmp0 = emit_fetch( bld, inst, 0, chan_index );
         dst0[chan_index] = lp_build_sgn( &bld->base, tmp0 );
      }
      break;

   case TGSI_OPCODE_CMP:
      FOR_EACH_DST0_ENABLED_CHANNEL( inst, chan_index ) {
         src0 = emit_fetch( bld, inst, 0, chan_index );
         src1 = emit_fetch( bld, inst, 1, chan_index );
         src2 = emit_fetch( bld, inst, 2, chan_index );
         tmp0 = lp_build_cmp( &bld->base, PIPE_FUNC_LESS, src0, bld->base.zero );
         dst0[chan_index] = lp_build_select( &bld->base, tmp0, src1, src2);
      }
      break;

   case TGSI_OPCODE_SCS:
      IF_IS_DST0_CHANNEL_ENABLED( inst, CHAN_X ) {
         tmp0 = emit_fetch( bld, inst, 0, CHAN_X );
         dst0[CHAN_X] = lp_build_cos( &bld->base, tmp0 );
      }
      IF_IS_DST0_CHANNEL_ENABLED( inst, CHAN_Y ) {
         tmp0 = emit_fetch( bld, inst, 0, CHAN_X );
         dst0[CHAN_Y] = lp_build_sin( &bld->base, tmp0 );
      }
      IF_IS_DST0_CHANNEL_ENABLED( inst, CHAN_Z ) {
         dst0[CHAN_Z] = bld->base.zero;
      }
      IF_IS_DST0_CHANNEL_ENABLED( inst, CHAN_W ) {
         dst0[CHAN_W] = bld->base.one;
      }
      break;

   case TGSI_OPCODE_TXB:
      emit_tex( bld, inst, LP_BLD_TEX_MODIFIER_LOD_BIAS, dst0 );
      break;

   case TGSI_OPCODE_NRM:
      /* fall-through */
   case TGSI_OPCODE_NRM4:
      /* 3 or 4-component normalization */
      {
         uint dims = (inst->Instruction.Opcode == TGSI_OPCODE_NRM) ? 3 : 4;

         if (IS_DST0_CHANNEL_ENABLED(inst, CHAN_X) ||
             IS_DST0_CHANNEL_ENABLED(inst, CHAN_Y) ||
             IS_DST0_CHANNEL_ENABLED(inst, CHAN_Z) ||
             (IS_DST0_CHANNEL_ENABLED(inst, CHAN_W) && dims == 4)) {

            /* NOTE: Cannot use xmm regs 2/3 here (see emit_rsqrt() above). */

            /* xmm4 = src.x */
            /* xmm0 = src.x * src.x */
            tmp0 = emit_fetch(bld, inst, 0, CHAN_X);
            if (IS_DST0_CHANNEL_ENABLED(inst, CHAN_X)) {
               tmp4 = tmp0;
            }
            tmp0 = lp_build_mul( &bld->base, tmp0, tmp0);

            /* xmm5 = src.y */
            /* xmm0 = xmm0 + src.y * src.y */
            tmp1 = emit_fetch(bld, inst, 0, CHAN_Y);
            if (IS_DST0_CHANNEL_ENABLED(inst, CHAN_Y)) {
               tmp5 = tmp1;
            }
            tmp1 = lp_build_mul( &bld->base, tmp1, tmp1);
            tmp0 = lp_build_add( &bld->base, tmp0, tmp1);

            /* xmm6 = src.z */
            /* xmm0 = xmm0 + src.z * src.z */
            tmp1 = emit_fetch(bld, inst, 0, CHAN_Z);
            if (IS_DST0_CHANNEL_ENABLED(inst, CHAN_Z)) {
               tmp6 = tmp1;
            }
            tmp1 = lp_build_mul( &bld->base, tmp1, tmp1);
            tmp0 = lp_build_add( &bld->base, tmp0, tmp1);

            if (dims == 4) {
               /* xmm7 = src.w */
               /* xmm0 = xmm0 + src.w * src.w */
               tmp1 = emit_fetch(bld, inst, 0, CHAN_W);
               if (IS_DST0_CHANNEL_ENABLED(inst, CHAN_W)) {
                  tmp7 = tmp1;
               }
               tmp1 = lp_build_mul( &bld->base, tmp1, tmp1);
               tmp0 = lp_build_add( &bld->base, tmp0, tmp1);
            }

            /* xmm1 = 1 / sqrt(xmm0) */
            tmp1 = lp_build_rsqrt( &bld->base, tmp0);

            /* dst.x = xmm1 * src.x */
            if (IS_DST0_CHANNEL_ENABLED(inst, CHAN_X)) {
               dst0[CHAN_X] = lp_build_mul( &bld->base, tmp4, tmp1);
            }

            /* dst.y = xmm1 * src.y */
            if (IS_DST0_CHANNEL_ENABLED(inst, CHAN_Y)) {
               dst0[CHAN_Y] = lp_build_mul( &bld->base, tmp5, tmp1);
            }

            /* dst.z = xmm1 * src.z */
            if (IS_DST0_CHANNEL_ENABLED(inst, CHAN_Z)) {
               dst0[CHAN_Z] = lp_build_mul( &bld->base, tmp6, tmp1);
            }

            /* dst.w = xmm1 * src.w */
            if (IS_DST0_CHANNEL_ENABLED(inst, CHAN_X) && dims == 4) {
               dst0[CHAN_W] = lp_build_mul( &bld->base, tmp7, tmp1);
            }
         }
d2802 7
a2808 6
         /* dst.w = 1.0 */
         if (IS_DST0_CHANNEL_ENABLED(inst, CHAN_W) && dims == 3) {
            dst0[CHAN_W] = bld->base.one;
         }
      }
      break;
d2810 2
a2811 5
   case TGSI_OPCODE_DIV:
      /* deprecated */
      assert( 0 );
      return FALSE;
      break;
d2813 7
a2819 12
   case TGSI_OPCODE_DP2:
      tmp0 = emit_fetch( bld, inst, 0, CHAN_X );  /* xmm0 = src[0].x */
      tmp1 = emit_fetch( bld, inst, 1, CHAN_X );  /* xmm1 = src[1].x */
      tmp0 = lp_build_mul( &bld->base, tmp0, tmp1);              /* xmm0 = xmm0 * xmm1 */
      tmp1 = emit_fetch( bld, inst, 0, CHAN_Y );  /* xmm1 = src[0].y */
      tmp2 = emit_fetch( bld, inst, 1, CHAN_Y );  /* xmm2 = src[1].y */
      tmp1 = lp_build_mul( &bld->base, tmp1, tmp2);              /* xmm1 = xmm1 * xmm2 */
      tmp0 = lp_build_add( &bld->base, tmp0, tmp1);              /* xmm0 = xmm0 + xmm1 */
      FOR_EACH_DST0_ENABLED_CHANNEL( inst, chan_index ) {
         dst0[chan_index] = tmp0;  /* dest[ch] = xmm0 */
      }
      break;
d2821 2
a2822 3
   case TGSI_OPCODE_TXL:
      emit_tex( bld, inst, LP_BLD_TEX_MODIFIER_EXPLICIT_LOD, dst0 );
      break;
d2824 7
a2830 3
   case TGSI_OPCODE_TXP:
      emit_tex( bld, inst, LP_BLD_TEX_MODIFIER_PROJECTED, dst0 );
      break;
d2832 2
a2833 3
   case TGSI_OPCODE_BRK:
      lp_exec_break(&bld->exec_mask);
      break;
d2835 7
a2841 6
   case TGSI_OPCODE_IF:
      tmp0 = emit_fetch(bld, inst, 0, CHAN_X);
      tmp0 = lp_build_cmp(&bld->base, PIPE_FUNC_NOTEQUAL,
                          tmp0, bld->base.zero);
      lp_exec_mask_cond_push(&bld->exec_mask, tmp0);
      break;
d2843 2
a2844 3
   case TGSI_OPCODE_BGNLOOP:
      lp_exec_bgnloop(&bld->exec_mask);
      break;
d2846 7
a2852 3
   case TGSI_OPCODE_BGNSUB:
      lp_exec_mask_bgnsub(&bld->exec_mask);
      break;
d2854 2
a2855 3
   case TGSI_OPCODE_ELSE:
      lp_exec_mask_cond_invert(&bld->exec_mask);
      break;
d2857 7
a2863 3
   case TGSI_OPCODE_ENDIF:
      lp_exec_mask_cond_pop(&bld->exec_mask);
      break;
d2865 2
a2866 3
   case TGSI_OPCODE_ENDLOOP:
      lp_exec_endloop(bld->base.gallivm, &bld->exec_mask);
      break;
d2868 7
a2874 3
   case TGSI_OPCODE_ENDSUB:
      lp_exec_mask_endsub(&bld->exec_mask, pc);
      break;
d2876 2
a2877 5
   case TGSI_OPCODE_PUSHA:
      /* deprecated? */
      assert(0);
      return FALSE;
      break;
d2879 7
a2885 5
   case TGSI_OPCODE_POPA:
      /* deprecated? */
      assert(0);
      return FALSE;
      break;
d2887 2
a2888 6
   case TGSI_OPCODE_CEIL:
      FOR_EACH_DST0_ENABLED_CHANNEL( inst, chan_index ) {
         tmp0 = emit_fetch( bld, inst, 0, chan_index );
         dst0[chan_index] = lp_build_ceil(&bld->base, tmp0);
      }
      break;
d2890 20
a2909 5
   case TGSI_OPCODE_I2F:
      /* deprecated? */
      assert(0);
      return FALSE;
      break;
d2911 1
a2911 5
   case TGSI_OPCODE_NOT:
      /* deprecated? */
      assert(0);
      return FALSE;
      break;
d2913 52
a2964 4
   case TGSI_OPCODE_TRUNC:
      FOR_EACH_DST0_ENABLED_CHANNEL( inst, chan_index ) {
         tmp0 = emit_fetch( bld, inst, 0, chan_index );
         dst0[chan_index] = lp_build_trunc(&bld->base, tmp0);
a2965 1
      break;
d2967 9
a2975 5
   case TGSI_OPCODE_SHL:
      /* deprecated? */
      assert(0);
      return FALSE;
      break;
d2977 5
a2981 5
   case TGSI_OPCODE_ISHR:
      /* deprecated? */
      assert(0);
      return FALSE;
      break;
d2983 4
a2986 5
   case TGSI_OPCODE_AND:
      /* deprecated? */
      assert(0);
      return FALSE;
      break;
d2988 8
a2995 5
   case TGSI_OPCODE_OR:
      /* deprecated? */
      assert(0);
      return FALSE;
      break;
d2997 8
a3004 5
   case TGSI_OPCODE_MOD:
      /* deprecated? */
      assert(0);
      return FALSE;
      break;
d3006 8
a3013 5
   case TGSI_OPCODE_XOR:
      /* deprecated? */
      assert(0);
      return FALSE;
      break;
d3015 10
a3024 5
   case TGSI_OPCODE_SAD:
      /* deprecated? */
      assert(0);
      return FALSE;
      break;
d3026 2
a3027 5
   case TGSI_OPCODE_TXF:
      /* deprecated? */
      assert(0);
      return FALSE;
      break;
d3029 13
a3041 5
   case TGSI_OPCODE_TXQ:
      /* deprecated? */
      assert(0);
      return FALSE;
      break;
d3043 23
a3065 3
   case TGSI_OPCODE_CONT:
      lp_exec_continue(&bld->exec_mask);
      break;
d3067 4
a3070 3
   case TGSI_OPCODE_EMIT:
      return FALSE;
      break;
d3072 3
a3074 9
   case TGSI_OPCODE_ENDPRIM:
      return FALSE;
      break;

   case TGSI_OPCODE_NOP:
      break;

   default:
      return FALSE;
a3075 3
   
   if(info->num_dst) {
      LLVMValueRef pred[NUM_CHANNELS];
d3077 20
a3096 5
      emit_fetch_predicate( bld, inst, pred );

      FOR_EACH_DST0_ENABLED_CHANNEL( inst, chan_index ) {
         emit_store( bld, inst, 0, chan_index, pred[chan_index], dst0[chan_index]);
      }
a3097 2

   return TRUE;
a3099 1

d3106 3
a3108 4
                  LLVMValueRef system_values_array,
                  const LLVMValueRef *pos,
                  const LLVMValueRef (*inputs)[NUM_CHANNELS],
                  LLVMValueRef (*outputs)[NUM_CHANNELS],
d3110 2
a3111 1
                  const struct tgsi_shader_info *info)
a3113 5
   struct tgsi_parse_context parse;
   uint num_immediates = 0;
   uint num_instructions = 0;
   unsigned i;
   int pc = 0;
d3125 3
a3127 2
   lp_build_context_init(&bld.base, gallivm, type);
   lp_build_context_init(&bld.uint_bld, gallivm, lp_uint_type(type));
a3129 1
   bld.pos = pos;
d3134 1
a3134 1
   bld.info = info;
a3135 27
   bld.instructions = (struct tgsi_full_instruction *)
                      MALLOC( LP_MAX_INSTRUCTIONS * sizeof(struct tgsi_full_instruction) );
   bld.max_instructions = LP_MAX_INSTRUCTIONS;

   if (!bld.instructions) {
      return;
   }

   lp_exec_mask_init(&bld.exec_mask, &bld.base);

   if (bld.indirect_files & (1 << TGSI_FILE_TEMPORARY)) {
      LLVMValueRef array_size =
         lp_build_const_int32(gallivm,
                              info->file_max[TGSI_FILE_TEMPORARY] * 4 + 4);
      bld.temps_array = lp_build_array_alloca(gallivm,
                                              bld.base.vec_type, array_size,
                                              "temp_array");
   }

   if (bld.indirect_files & (1 << TGSI_FILE_OUTPUT)) {
      LLVMValueRef array_size =
         lp_build_const_int32(gallivm,
                              info->file_max[TGSI_FILE_OUTPUT] * 4 + 4);
      bld.outputs_array = lp_build_array_alloca(gallivm,
                                                bld.base.vec_type, array_size,
                                                "output_array");
   }
d3137 76
a3212 23
   /* If we have indirect addressing in inputs we need to copy them into
    * our alloca array to be able to iterate over them */
   if (bld.indirect_files & (1 << TGSI_FILE_INPUT)) {
      unsigned index, chan;
      LLVMTypeRef vec_type = bld.base.vec_type;
      LLVMValueRef array_size =
         lp_build_const_int32(gallivm, info->file_max[TGSI_FILE_INPUT]*4 + 4);
      bld.inputs_array = lp_build_array_alloca(gallivm,
                                               vec_type, array_size,
                                               "input_array");

      assert(info->num_inputs <= info->file_max[TGSI_FILE_INPUT] + 1);

      for (index = 0; index < info->num_inputs; ++index) {
         for (chan = 0; chan < NUM_CHANNELS; ++chan) {
            LLVMValueRef lindex =
               lp_build_const_int32(gallivm, index * 4 + chan);
            LLVMValueRef input_ptr =
               LLVMBuildGEP(gallivm->builder, bld.inputs_array,
                            &lindex, 1, "");
            LLVMValueRef value = bld.inputs[index][chan];
            if (value)
               LLVMBuildStore(gallivm->builder, value, input_ptr);
d3215 3
d3220 1
a3220 56
   bld.system_values_array = system_values_array;

   tgsi_parse_init( &parse, tokens );

   while( !tgsi_parse_end_of_tokens( &parse ) ) {
      tgsi_parse_token( &parse );

      switch( parse.FullToken.Token.Type ) {
      case TGSI_TOKEN_TYPE_DECLARATION:
         /* Inputs already interpolated */
         emit_declaration( &bld, &parse.FullToken.FullDeclaration );
         break;

      case TGSI_TOKEN_TYPE_INSTRUCTION:
         {
            /* save expanded instruction */
            if (num_instructions == bld.max_instructions) {
               struct tgsi_full_instruction *instructions;
               instructions = REALLOC(bld.instructions,
                                      bld.max_instructions
                                      * sizeof(struct tgsi_full_instruction),
                                      (bld.max_instructions + LP_MAX_INSTRUCTIONS)
                                      * sizeof(struct tgsi_full_instruction));
               if (!instructions) {
                  break;
               }
               bld.instructions = instructions;
               bld.max_instructions += LP_MAX_INSTRUCTIONS;
            }

            memcpy(bld.instructions + num_instructions,
                   &parse.FullToken.FullInstruction,
                   sizeof(bld.instructions[0]));

            num_instructions++;
         }

         break;

      case TGSI_TOKEN_TYPE_IMMEDIATE:
         /* simply copy the immediate values into the next immediates[] slot */
         {
            const uint size = parse.FullToken.FullImmediate.Immediate.NrTokens - 1;
            assert(size <= 4);
            assert(num_immediates < LP_MAX_TGSI_IMMEDIATES);
            for( i = 0; i < size; ++i )
               bld.immediates[num_immediates][i] =
                  lp_build_const_vec(gallivm, type, parse.FullToken.FullImmediate.u[i].Float);
            for( i = size; i < 4; ++i )
               bld.immediates[num_immediates][i] = bld.base.undef;
            num_immediates++;
         }
         break;

      case TGSI_TOKEN_TYPE_PROPERTY:
         break;
d3222 1
a3222 4
      default:
         assert( 0 );
      }
   }
d3224 1
a3224 20
   while (pc != -1) {
      struct tgsi_full_instruction *instr = bld.instructions + pc;
      const struct tgsi_opcode_info *opcode_info =
         tgsi_get_opcode_info(instr->Instruction.Opcode);
      if (!emit_instruction( &bld, instr, opcode_info, &pc ))
         _debug_printf("warning: failed to translate tgsi opcode %s to LLVM\n",
                       opcode_info->mnemonic);
   }

   /* If we have indirect addressing in outputs we need to copy our alloca array
    * to the outputs slots specified by the called */
   if (bld.indirect_files & (1 << TGSI_FILE_OUTPUT)) {
      unsigned index, chan;
      assert(info->num_outputs <= info->file_max[TGSI_FILE_OUTPUT] + 1);
      for (index = 0; index < info->num_outputs; ++index) {
         for (chan = 0; chan < NUM_CHANNELS; ++chan) {
            bld.outputs[index][chan] = get_output_ptr(&bld, index, chan);
         }
      }
   }
a3233 1
   tgsi_parse_free( &parse );
a3240 54

   FREE( bld.instructions );
}


/**
 * Build up the system values array out of individual values such as
 * the instance ID, front-face, primitive ID, etc.  The shader info is
 * used to determine which system values are needed and where to put
 * them in the system values array.
 *
 * XXX only instance ID is implemented at this time.
 *
 * The system values register file is similar to the constants buffer.
 * Example declaration:
 *    DCL SV[0], INSTANCEID
 * Example instruction:
 *    MOVE foo, SV[0].xxxx;
 *
 * \return  LLVM float array (interpreted as float [][4])
 */
LLVMValueRef
lp_build_system_values_array(struct gallivm_state *gallivm,
                             const struct tgsi_shader_info *info,
                             LLVMValueRef instance_id,
                             LLVMValueRef facing)
{
   LLVMValueRef size = lp_build_const_int32(gallivm, 4 * info->num_system_values);
   LLVMTypeRef float_t = LLVMFloatTypeInContext(gallivm->context);
   LLVMValueRef array = lp_build_array_alloca(gallivm, float_t,
                                              size, "sysvals_array");
   unsigned i;

   for (i = 0; i < info->num_system_values; i++) {
      LLVMValueRef index = lp_build_const_int32(gallivm, i * 4);
      LLVMValueRef ptr, value = 0;

      switch (info->system_value_semantic_name[i]) {
      case TGSI_SEMANTIC_INSTANCEID:
         /* convert instance ID from int to float */
         value = LLVMBuildSIToFP(gallivm->builder, instance_id, float_t,
                                 "sysval_instanceid");
         break;
      case TGSI_SEMANTIC_FACE:
         /* fall-through */
      default:
         assert(0 && "unexpected semantic in build_system_values_array()");
      }

      ptr = LLVMBuildGEP(gallivm->builder, array, &index, 1, "");
      LLVMBuildStore(gallivm->builder, value, ptr);
   }
      
   return array;
@


1.2
log
@Merge Mesa 7.10.3
@
text
@d160 2
d764 17
d2344 1
d2434 2
d2537 51
@


1.1
log
@Update to Mesa 7.8.1. Tested on a bulk ports build by naddy@@, ok oga@@.
@
text
@d44 1
d48 1
a48 1
#include "tgsi/tgsi_exec.h"
d52 3
d58 1
d60 1
d62 1
a62 4


#define LP_MAX_TEMPS 256
#define LP_MAX_IMMEDIATES 256
d82 1
d84 1
a84 4
#define QUAD_TOP_LEFT     0
#define QUAD_TOP_RIGHT    1
#define QUAD_BOTTOM_LEFT  2
#define QUAD_BOTTOM_RIGHT 3
a85 1
#define LP_TGSI_MAX_NESTING 16
d94 1
a94 1
   LLVMValueRef cond_stack[LP_TGSI_MAX_NESTING];
d98 19
d124 6
d135 1
a135 1
   struct lp_build_sampler_soa *sampler;
d137 26
a162 2
   LLVMValueRef immediates[LP_MAX_IMMEDIATES][NUM_CHANNELS];
   LLVMValueRef temps[LP_MAX_TEMPS][NUM_CHANNELS];
a165 13
};

static const unsigned char
swizzle_left[4] = {
   QUAD_TOP_LEFT,     QUAD_TOP_LEFT,
   QUAD_BOTTOM_LEFT,  QUAD_BOTTOM_LEFT
};

static const unsigned char
swizzle_right[4] = {
   QUAD_TOP_RIGHT,    QUAD_TOP_RIGHT,
   QUAD_BOTTOM_RIGHT, QUAD_BOTTOM_RIGHT
};
d167 2
a168 10
static const unsigned char
swizzle_top[4] = {
   QUAD_TOP_LEFT,     QUAD_TOP_RIGHT,
   QUAD_TOP_LEFT,     QUAD_TOP_RIGHT
};

static const unsigned char
swizzle_bottom[4] = {
   QUAD_BOTTOM_LEFT,  QUAD_BOTTOM_RIGHT,
   QUAD_BOTTOM_LEFT,  QUAD_BOTTOM_RIGHT
d176 2
d179 3
a181 1
   mask->int_vec_type = lp_build_int_vec_type(mask->bld->type);
d186 27
a212 3
   mask->exec_mask = mask->cond_mask;
   if (mask->cond_stack_size > 0)
      mask->has_mask = TRUE;
d218 6
d225 5
a229 3
   mask->cond_mask = LLVMBuildBitCast(mask->bld->builder, val,
                                      mask->int_vec_type, "");

d235 9
a243 3
   LLVMValueRef prev_mask = mask->cond_stack[mask->cond_stack_size - 1];
   LLVMValueRef inv_mask = LLVMBuildNot(mask->bld->builder,
                                        mask->cond_mask, "");
d245 1
a245 5
   /* means that we didn't have any mask before and that
    * we were fully enabled */
   if (mask->cond_stack_size <= 1) {
      prev_mask = LLVMConstAllOnes(mask->int_vec_type);
   }
d247 1
a247 1
   mask->cond_mask = LLVMBuildAnd(mask->bld->builder,
d255 1
d260 114
d375 1
d379 3
d383 8
d393 1
a393 1
      dst_val = LLVMBuildLoad(mask->bld->builder, dst, "");
d395 1
a395 1
                                 mask->exec_mask,
d398 1
a398 1
      LLVMBuildStore(mask->bld->builder, real_val, dst);
d400 69
a468 1
      LLVMBuildStore(mask->bld->builder, val, dst);
d471 22
d494 5
d500 36
a535 2
emit_ddx(struct lp_build_tgsi_soa_context *bld,
         LLVMValueRef src)
d537 39
a575 3
   LLVMValueRef src_left  = lp_build_swizzle1_aos(&bld->base, src, swizzle_left);
   LLVMValueRef src_right = lp_build_swizzle1_aos(&bld->base, src, swizzle_right);
   return lp_build_sub(&bld->base, src_right, src_left);
d579 6
d586 3
a588 2
emit_ddy(struct lp_build_tgsi_soa_context *bld,
         LLVMValueRef src)
d590 33
a622 3
   LLVMValueRef src_top    = lp_build_swizzle1_aos(&bld->base, src, swizzle_top);
   LLVMValueRef src_bottom = lp_build_swizzle1_aos(&bld->base, src, swizzle_bottom);
   return lp_build_sub(&bld->base, src_top, src_bottom);
d633 1
a633 1
   unsigned index,
d636 6
a641 2
   const struct tgsi_full_src_register *reg = &inst->Src[index];
   unsigned swizzle = tgsi_util_get_full_src_register_swizzle( reg, chan_index );
d643 39
a682 11
   switch (swizzle) {
   case TGSI_SWIZZLE_X:
   case TGSI_SWIZZLE_Y:
   case TGSI_SWIZZLE_Z:
   case TGSI_SWIZZLE_W:

      switch (reg->Register.File) {
      case TGSI_FILE_CONSTANT: {
         LLVMValueRef index = LLVMConstInt(LLVMInt32Type(), reg->Register.Index*4 + swizzle, 0);
         LLVMValueRef scalar_ptr = LLVMBuildGEP(bld->base.builder, bld->consts_ptr, &index, 1, "");
         LLVMValueRef scalar = LLVMBuildLoad(bld->base.builder, scalar_ptr, "");
a683 1
         break;
d685 1
d687 41
a727 4
      case TGSI_FILE_IMMEDIATE:
         res = bld->immediates[reg->Register.Index][swizzle];
         assert(res);
         break;
d729 29
a757 8
      case TGSI_FILE_INPUT:
         res = bld->inputs[reg->Register.Index][swizzle];
         assert(res);
         break;

      case TGSI_FILE_TEMPORARY:
         res = LLVMBuildLoad(bld->base.builder, bld->temps[reg->Register.Index][swizzle], "");
         if(!res)
a758 5
         break;

      default:
         assert( 0 );
         return bld->base.undef;
d763 1
a763 1
      assert( 0 );
a772 1
      /* TODO: Use bitwese OR for floating point */
d774 1
a774 3
      res = LLVMBuildNeg( bld->base.builder, res, "" );
      break;

d776 1
a776 1
      res = LLVMBuildNeg( bld->base.builder, res, "" );
d810 1
a810 1
      *ddx = emit_ddx(bld, src);
d813 69
a881 1
      *ddy = emit_ddy(bld, src);
d894 1
d897 2
d900 2
d913 1
a913 1
      value = lp_build_max(&bld->base, value, lp_build_const_scalar(bld->base.type, -1.0));
d921 9
d932 39
a970 2
      lp_exec_mask_store(&bld->exec_mask, value,
                         bld->outputs[reg->Register.Index][chan_index]);
d974 40
a1013 2
      lp_exec_mask_store(&bld->exec_mask, value,
                         bld->temps[reg->Register.Index][chan_index]);
d1017 7
a1023 2
      /* FIXME */
      assert(0);
a1035 1

d1039 1
a1039 2
          boolean apply_lodbias,
          boolean projected,
d1042 3
a1044 2
   const uint unit = inst->Src[1].Register.Index;
   LLVMValueRef lodbias;
d1047 2
d1052 8
d1080 12
a1091 4
   if(apply_lodbias)
      lodbias = emit_fetch( bld, inst, 0, 3 );
   else
      lodbias = bld->base.zero;
d1093 1
a1093 1
   if (projected) {
d1100 1
a1100 1
      if (projected)
d1107 21
d1129 1
a1129 1
                                  bld->base.builder,
d1131 3
a1133 1
                                  unit, num_coords, coords, lodbias,
d1137 37
d1175 3
d1181 2
a1182 1
   const struct tgsi_full_instruction *inst )
d1184 1
d1210 3
d1216 1
a1216 1
            mask = LLVMBuildAnd(bld->base.builder, mask, chan_mask, "");
d1222 1
a1222 1
   if(mask)
d1224 4
d1232 4
a1235 2
 * Check if inst src/dest regs use indirect addressing into temporary
 * register file.
d1237 4
a1240 2
static boolean
indirect_temp_reference(const struct tgsi_full_instruction *inst)
d1242 8
a1249 6
   uint i;
   for (i = 0; i < inst->Instruction.NumSrcRegs; i++) {
      const struct tgsi_full_src_register *reg = &inst->Src[i];
      if (reg->Register.File == TGSI_FILE_TEMPORARY &&
          reg->Register.Indirect)
         return TRUE;
d1251 53
a1303 5
   for (i = 0; i < inst->Instruction.NumDstRegs; i++) {
      const struct tgsi_full_dst_register *reg = &inst->Dst[i];
      if (reg->Register.File == TGSI_FILE_TEMPORARY &&
          reg->Register.Indirect)
         return TRUE;
a1304 1
   return FALSE;
d1307 3
a1309 1
static int
d1314 4
a1317 2
   unsigned first = decl->Range.First;
   unsigned last = decl->Range.Last;
d1321 1
a1321 2
      boolean ok;

d1324 17
d1342 1
a1342 2
            bld->temps[idx][i] = lp_build_alloca(&bld->base);
         ok = TRUE;
d1345 2
a1346 1
      case TGSI_FILE_OUTPUT:
d1348 2
a1349 2
            bld->outputs[idx][i] = lp_build_alloca(&bld->base);
         ok = TRUE;
d1354 1
a1354 1
         ok = TRUE;
a1355 3

      if (!ok)
         return FALSE;
d1357 1
a1358 2
   return TRUE;
}
d1360 5
a1364 1
static int
d1368 2
a1369 1
   const struct tgsi_opcode_info *info)
d1382 12
a1393 3
   /* we can't handle indirect addressing into temp register file yet */
   if (indirect_temp_reference(inst))
      return FALSE;
d1396 1
a1396 1
   if(info->num_dst) {
a1402 1
#if 0
a1403 1
      /* FIXME */
d1406 1
a1406 2
         emit_flr(bld, 0, 0);
         emit_f2it( bld, 0 );
a1409 1
#endif
d1675 1
a1675 1
         tmp1 = lp_build_const_scalar(bld->base.type, 0.5);
d1807 1
a1807 1
      return 0;
d1850 1
a1850 2
      /* FIXME */
      return 0;
d1855 1
a1855 1
      emit_kil( bld, inst );
d1859 1
a1859 1
      return 0;
d1863 1
a1863 1
      return 0;
d1867 1
a1867 1
      return 0;
d1871 1
a1871 1
      return 0;
d1875 1
a1875 1
      return 0;
d1935 1
a1935 2
      /* XXX what about dst0 writemask? */
      emit_tex( bld, inst, FALSE, FALSE, dst0 );
d1939 1
a1939 2
      /* FIXME */
      return 0;
d1945 1
a1945 1
      return 0;
d1951 1
a1951 1
      return 0;
d1957 1
a1957 1
      return 0;
d1963 1
a1963 1
      return 0;
d1969 1
a1969 1
      return 0;
d1975 1
a1975 1
      return 0;
a1977 1
#if 0
a1978 1
      /* FIXME */
d1981 1
a1981 2
         emit_rnd( bld, 0, 0 );
         emit_f2it( bld, 0 );
a1984 1
#endif
d1989 1
a1989 1
      return 0;
d1993 4
a1996 2
      /* FIXME */
      return 0;
d2000 1
a2000 2
      /* FIXME */
      return 0;
d2004 5
d2047 1
a2047 1
      emit_tex( bld, inst, TRUE, FALSE, dst0 );
d2135 1
a2135 1
      return 0;
d2152 1
a2152 1
      emit_tex( bld, inst, TRUE, FALSE, dst0 );
d2156 1
a2156 1
      emit_tex( bld, inst, FALSE, TRUE, dst0 );
d2158 1
a2158 1
      
d2160 1
a2160 2
      /* FIXME */
      return 0;
d2165 2
d2170 2
a2171 4
   case TGSI_OPCODE_BGNFOR:
      /* deprecated */
      assert(0);
      return 0;
d2174 2
a2175 4
   case TGSI_OPCODE_REP:
      /* deprecated */
      assert(0);
      return 0;
d2186 2
a2187 4
   case TGSI_OPCODE_ENDFOR:
      /* deprecated */
      assert(0);
      return 0;
d2190 2
a2191 4
   case TGSI_OPCODE_ENDREP:
      /* deprecated */
      assert(0);
      return 0;
d2197 1
a2197 1
      return 0;
d2203 1
a2203 1
      return 0;
d2216 1
a2216 1
      return 0;
d2222 1
a2222 1
      return 0;
d2235 1
a2235 1
      return 0;
d2241 1
a2241 1
      return 0;
d2247 1
a2247 1
      return 0;
d2253 1
a2253 1
      return 0;
d2259 1
a2259 1
      return 0;
d2265 1
a2265 1
      return 0;
d2271 1
a2271 1
      return 0;
d2277 1
a2277 1
      return 0;
d2283 1
a2283 1
      return 0;
d2287 1
a2287 2
      /* FIXME */
      return 0;
d2291 1
a2291 1
      return 0;
d2295 1
a2295 1
      return 0;
d2302 1
a2302 1
      return 0;
d2306 4
d2311 1
a2311 1
         emit_store( bld, inst, 0, chan_index, dst0[chan_index]);
d2315 1
a2315 1
   return 1;
d2320 1
a2320 1
lp_build_tgsi_soa(LLVMBuilderRef builder,
d2328 2
a2329 1
                  struct lp_build_sampler_soa *sampler)
d2334 1
d2336 9
d2348 3
a2350 1
   lp_build_context_init(&bld.base, builder, type);
d2357 9
d2369 45
d2422 1
a2422 4
         {
            if (!emit_declaration( &bld, &parse.FullToken.FullDeclaration ))
               _debug_printf("warning: failed to define LLVM variable\n");
         }
d2427 20
a2446 5
            unsigned opcode = parse.FullToken.FullInstruction.Instruction.Opcode;
            const struct tgsi_opcode_info *info = tgsi_get_opcode_info(opcode);
            if (!emit_instruction( &bld, &parse.FullToken.FullInstruction, info ))
               _debug_printf("warning: failed to translate tgsi opcode %s to LLVM\n",
                             info ? info->mnemonic : "<invalid>");
d2456 1
a2456 1
            assert(num_immediates < LP_MAX_IMMEDIATES);
d2459 1
a2459 1
                  lp_build_const_scalar(type, parse.FullToken.FullImmediate.u[i].Float);
d2474 29
d2504 9
@


1.1.1.1
log
@Import Mesa 7.10.3
@
text
@a43 1
#include "tgsi/tgsi_dump.h"
d47 1
a47 1
#include "tgsi/tgsi_scan.h"
a50 3
#include "lp_bld_bitarit.h"
#include "lp_bld_gather.h"
#include "lp_bld_init.h"
a53 1
#include "lp_bld_quad.h"
a54 1
#include "lp_bld_limits.h"
d56 4
a59 1
#include "lp_bld_printf.h"
a78 1
#define NUM_CHANNELS 4
d80 4
a83 1
#define LP_MAX_INSTRUCTIONS 256
d85 1
d94 1
a94 1
   LLVMValueRef cond_stack[LP_MAX_TGSI_NESTING];
a97 19
   LLVMBasicBlockRef loop_block;
   LLVMValueRef cont_mask;
   LLVMValueRef break_mask;
   LLVMValueRef break_var;
   struct {
      LLVMBasicBlockRef loop_block;
      LLVMValueRef cont_mask;
      LLVMValueRef break_mask;
      LLVMValueRef break_var;
   } loop_stack[LP_MAX_TGSI_NESTING];
   int loop_stack_size;

   LLVMValueRef ret_mask;
   struct {
      int pc;
      LLVMValueRef ret_mask;
   } call_stack[LP_MAX_TGSI_NESTING];
   int call_stack_size;

a104 6
   /* Builder for vector integer masks and indices */
   struct lp_build_context uint_bld;

   /* Builder for scalar elements of shader's data type (float) */
   struct lp_build_context elem_bld;

d110 1
a110 1
   const struct lp_build_sampler_soa *sampler;
d112 2
a113 26
   LLVMValueRef immediates[LP_MAX_TGSI_IMMEDIATES][NUM_CHANNELS];
   LLVMValueRef temps[LP_MAX_TGSI_TEMPS][NUM_CHANNELS];
   LLVMValueRef addr[LP_MAX_TGSI_ADDRS][NUM_CHANNELS];
   LLVMValueRef preds[LP_MAX_TGSI_PREDS][NUM_CHANNELS];

   /* We allocate/use this array of temps if (1 << TGSI_FILE_TEMPORARY) is
    * set in the indirect_files field.
    * The temps[] array above is unused then.
    */
   LLVMValueRef temps_array;

   /* We allocate/use this array of output if (1 << TGSI_FILE_OUTPUT) is
    * set in the indirect_files field.
    * The outputs[] array above is unused then.
    */
   LLVMValueRef outputs_array;

   /* We allocate/use this array of inputs if (1 << TGSI_FILE_INPUT) is
    * set in the indirect_files field.
    * The inputs[] array above is unused then.
    */
   LLVMValueRef inputs_array;

   const struct tgsi_shader_info *info;
   /** bitmask indicating which register files are accessed indirectly */
   unsigned indirect_files;
d117 13
d131 10
a140 2
   struct tgsi_full_instruction *instructions;
   uint max_instructions;
a147 2
   mask->loop_stack_size = 0;
   mask->call_stack_size = 0;
d149 1
a149 3
   mask->int_vec_type = lp_build_int_vec_type(bld->gallivm, mask->bld->type);
   mask->exec_mask = mask->ret_mask = mask->break_mask = mask->cont_mask = mask->cond_mask =
         LLVMConstAllOnes(mask->int_vec_type);
d154 3
a156 27
   LLVMBuilderRef builder = mask->bld->gallivm->builder;

   if (mask->loop_stack_size) {
      /*for loops we need to update the entire mask at runtime */
      LLVMValueRef tmp;
      assert(mask->break_mask);
      tmp = LLVMBuildAnd(builder,
                         mask->cont_mask,
                         mask->break_mask,
                         "maskcb");
      mask->exec_mask = LLVMBuildAnd(builder,
                                     mask->cond_mask,
                                     tmp,
                                     "maskfull");
   } else
      mask->exec_mask = mask->cond_mask;

   if (mask->call_stack_size) {
      mask->exec_mask = LLVMBuildAnd(builder,
                                     mask->exec_mask,
                                     mask->ret_mask,
                                     "callmask");
   }

   mask->has_mask = (mask->cond_stack_size > 0 ||
                     mask->loop_stack_size > 0 ||
                     mask->call_stack_size > 0);
d162 3
a164 1
   LLVMBuilderRef builder = mask->bld->gallivm->builder;
a165 10
   assert(mask->cond_stack_size < LP_MAX_TGSI_NESTING);
   if (mask->cond_stack_size == 0) {
      assert(mask->cond_mask == LLVMConstAllOnes(mask->int_vec_type));
   }
   mask->cond_stack[mask->cond_stack_size++] = mask->cond_mask;
   assert(LLVMTypeOf(val) == mask->int_vec_type);
   mask->cond_mask = LLVMBuildAnd(builder,
                                  mask->cond_mask,
                                  val,
                                  "");
d171 8
a178 8
   LLVMBuilderRef builder = mask->bld->gallivm->builder;
   LLVMValueRef prev_mask;
   LLVMValueRef inv_mask;

   assert(mask->cond_stack_size);
   prev_mask = mask->cond_stack[mask->cond_stack_size - 1];
   if (mask->cond_stack_size == 1) {
      assert(prev_mask == LLVMConstAllOnes(mask->int_vec_type));
d181 1
a181 3
   inv_mask = LLVMBuildNot(builder, mask->cond_mask, "");

   mask->cond_mask = LLVMBuildAnd(builder,
a188 1
   assert(mask->cond_stack_size);
a192 114
static void lp_exec_bgnloop(struct lp_exec_mask *mask)
{
   LLVMBuilderRef builder = mask->bld->gallivm->builder;

   if (mask->loop_stack_size == 0) {
      assert(mask->loop_block == NULL);
      assert(mask->cont_mask == LLVMConstAllOnes(mask->int_vec_type));
      assert(mask->break_mask == LLVMConstAllOnes(mask->int_vec_type));
      assert(mask->break_var == NULL);
   }

   assert(mask->loop_stack_size < LP_MAX_TGSI_NESTING);

   mask->loop_stack[mask->loop_stack_size].loop_block = mask->loop_block;
   mask->loop_stack[mask->loop_stack_size].cont_mask = mask->cont_mask;
   mask->loop_stack[mask->loop_stack_size].break_mask = mask->break_mask;
   mask->loop_stack[mask->loop_stack_size].break_var = mask->break_var;
   ++mask->loop_stack_size;

   mask->break_var = lp_build_alloca(mask->bld->gallivm, mask->int_vec_type, "");
   LLVMBuildStore(builder, mask->break_mask, mask->break_var);

   mask->loop_block = lp_build_insert_new_block(mask->bld->gallivm, "bgnloop");
   LLVMBuildBr(builder, mask->loop_block);
   LLVMPositionBuilderAtEnd(builder, mask->loop_block);

   mask->break_mask = LLVMBuildLoad(builder, mask->break_var, "");

   lp_exec_mask_update(mask);
}

static void lp_exec_break(struct lp_exec_mask *mask)
{
   LLVMBuilderRef builder = mask->bld->gallivm->builder;
   LLVMValueRef exec_mask = LLVMBuildNot(builder,
                                         mask->exec_mask,
                                         "break");

   mask->break_mask = LLVMBuildAnd(builder,
                                   mask->break_mask,
                                   exec_mask, "break_full");

   lp_exec_mask_update(mask);
}

static void lp_exec_continue(struct lp_exec_mask *mask)
{
   LLVMBuilderRef builder = mask->bld->gallivm->builder;
   LLVMValueRef exec_mask = LLVMBuildNot(builder,
                                         mask->exec_mask,
                                         "");

   mask->cont_mask = LLVMBuildAnd(builder,
                                  mask->cont_mask,
                                  exec_mask, "");

   lp_exec_mask_update(mask);
}


static void lp_exec_endloop(struct gallivm_state *gallivm,
                            struct lp_exec_mask *mask)
{
   LLVMBuilderRef builder = mask->bld->gallivm->builder;
   LLVMBasicBlockRef endloop;
   LLVMTypeRef reg_type = LLVMIntTypeInContext(gallivm->context,
                                               mask->bld->type.width *
                                               mask->bld->type.length);
   LLVMValueRef i1cond;

   assert(mask->break_mask);

   /*
    * Restore the cont_mask, but don't pop
    */
   assert(mask->loop_stack_size);
   mask->cont_mask = mask->loop_stack[mask->loop_stack_size - 1].cont_mask;
   lp_exec_mask_update(mask);

   /*
    * Unlike the continue mask, the break_mask must be preserved across loop
    * iterations
    */
   LLVMBuildStore(builder, mask->break_mask, mask->break_var);

   /* i1cond = (mask == 0) */
   i1cond = LLVMBuildICmp(
      builder,
      LLVMIntNE,
      LLVMBuildBitCast(builder, mask->exec_mask, reg_type, ""),
      LLVMConstNull(reg_type), "");

   endloop = lp_build_insert_new_block(mask->bld->gallivm, "endloop");

   LLVMBuildCondBr(builder,
                   i1cond, mask->loop_block, endloop);

   LLVMPositionBuilderAtEnd(builder, endloop);

   assert(mask->loop_stack_size);
   --mask->loop_stack_size;
   mask->loop_block = mask->loop_stack[mask->loop_stack_size].loop_block;
   mask->cont_mask = mask->loop_stack[mask->loop_stack_size].cont_mask;
   mask->break_mask = mask->loop_stack[mask->loop_stack_size].break_mask;
   mask->break_var = mask->loop_stack[mask->loop_stack_size].break_var;

   lp_exec_mask_update(mask);
}

/* stores val into an address pointed to by dst.
 * mask->exec_mask is used to figure out which bits of val
 * should be stored into the address
 * (0 means don't store this bit, 1 means do store).
 */
a193 1
                               LLVMValueRef pred,
a196 3
   LLVMBuilderRef builder = mask->bld->gallivm->builder;

   /* Mix the predicate and execution mask */
a197 8
      if (pred) {
         pred = LLVMBuildAnd(builder, pred, mask->exec_mask, "");
      } else {
         pred = mask->exec_mask;
      }
   }

   if (pred) {
d200 1
a200 1
      dst_val = LLVMBuildLoad(builder, dst, "");
d202 1
a202 1
                                 pred,
d205 1
a205 1
      LLVMBuildStore(builder, real_val, dst);
d207 1
a207 69
      LLVMBuildStore(builder, val, dst);
}

static void lp_exec_mask_call(struct lp_exec_mask *mask,
                              int func,
                              int *pc)
{
   assert(mask->call_stack_size < LP_MAX_TGSI_NESTING);
   mask->call_stack[mask->call_stack_size].pc = *pc;
   mask->call_stack[mask->call_stack_size].ret_mask = mask->ret_mask;
   mask->call_stack_size++;
   *pc = func;
}

static void lp_exec_mask_ret(struct lp_exec_mask *mask, int *pc)
{
   LLVMBuilderRef builder = mask->bld->gallivm->builder;
   LLVMValueRef exec_mask;

   if (mask->call_stack_size == 0) {
      /* returning from main() */
      *pc = -1;
      return;
   }
   exec_mask = LLVMBuildNot(builder,
                            mask->exec_mask,
                            "ret");

   mask->ret_mask = LLVMBuildAnd(builder,
                                 mask->ret_mask,
                                 exec_mask, "ret_full");

   lp_exec_mask_update(mask);
}

static void lp_exec_mask_bgnsub(struct lp_exec_mask *mask)
{
}

static void lp_exec_mask_endsub(struct lp_exec_mask *mask, int *pc)
{
   assert(mask->call_stack_size);
   mask->call_stack_size--;
   *pc = mask->call_stack[mask->call_stack_size].pc;
   mask->ret_mask = mask->call_stack[mask->call_stack_size].ret_mask;
   lp_exec_mask_update(mask);
}


/**
 * Return pointer to a temporary register channel (src or dest).
 * Note that indirect addressing cannot be handled here.
 * \param index  which temporary register
 * \param chan  which channel of the temp register.
 */
static LLVMValueRef
get_temp_ptr(struct lp_build_tgsi_soa_context *bld,
             unsigned index,
             unsigned chan)
{
   LLVMBuilderRef builder = bld->base.gallivm->builder;
   assert(chan < 4);
   if (bld->indirect_files & (1 << TGSI_FILE_TEMPORARY)) {
      LLVMValueRef lindex = lp_build_const_int32(bld->base.gallivm, index * 4 + chan);
      return LLVMBuildGEP(builder, bld->temps_array, &lindex, 1, "");
   }
   else {
      return bld->temps[index][chan];
   }
a209 22
/**
 * Return pointer to a output register channel (src or dest).
 * Note that indirect addressing cannot be handled here.
 * \param index  which output register
 * \param chan  which channel of the output register.
 */
static LLVMValueRef
get_output_ptr(struct lp_build_tgsi_soa_context *bld,
               unsigned index,
               unsigned chan)
{
   LLVMBuilderRef builder = bld->base.gallivm->builder;
   assert(chan < 4);
   if (bld->indirect_files & (1 << TGSI_FILE_OUTPUT)) {
      LLVMValueRef lindex = lp_build_const_int32(bld->base.gallivm,
                                                 index * 4 + chan);
      return LLVMBuildGEP(builder, bld->outputs_array, &lindex, 1, "");
   }
   else {
      return bld->outputs[index][chan];
   }
}
a210 5
/**
 * Gather vector.
 * XXX the lp_build_gather() function should be capable of doing this
 * with a little work.
 */
d212 2
a213 36
build_gather(struct lp_build_tgsi_soa_context *bld,
             LLVMValueRef base_ptr,
             LLVMValueRef indexes)
{
   LLVMBuilderRef builder = bld->base.gallivm->builder;
   LLVMValueRef res = bld->base.undef;
   unsigned i;

   /*
    * Loop over elements of index_vec, load scalar value, insert it into 'res'.
    */
   for (i = 0; i < bld->base.type.length; i++) {
      LLVMValueRef ii = lp_build_const_int32(bld->base.gallivm, i);
      LLVMValueRef index = LLVMBuildExtractElement(builder,
                                                   indexes, ii, "");
      LLVMValueRef scalar_ptr = LLVMBuildGEP(builder, base_ptr,
                                             &index, 1, "gather_ptr");
      LLVMValueRef scalar = LLVMBuildLoad(builder, scalar_ptr, "");

      res = LLVMBuildInsertElement(builder, res, scalar, ii, "");
   }

   return res;
}


/**
 * Scatter/store vector.
 */
static void
emit_mask_scatter(struct lp_build_tgsi_soa_context *bld,
                  LLVMValueRef base_ptr,
                  LLVMValueRef indexes,
                  LLVMValueRef values,
                  struct lp_exec_mask *mask,
                  LLVMValueRef pred)
d215 3
a217 39
   struct gallivm_state *gallivm = bld->base.gallivm;
   LLVMBuilderRef builder = gallivm->builder;
   unsigned i;

   /* Mix the predicate and execution mask */
   if (mask->has_mask) {
      if (pred) {
         pred = LLVMBuildAnd(builder, pred, mask->exec_mask, "");
      }
      else {
         pred = mask->exec_mask;
      }
   }

   /*
    * Loop over elements of index_vec, store scalar value.
    */
   for (i = 0; i < bld->base.type.length; i++) {
      LLVMValueRef ii = lp_build_const_int32(gallivm, i);
      LLVMValueRef index = LLVMBuildExtractElement(builder, indexes, ii, "");
      LLVMValueRef scalar_ptr = LLVMBuildGEP(builder, base_ptr, &index, 1, "scatter_ptr");
      LLVMValueRef val = LLVMBuildExtractElement(builder, values, ii, "scatter_val");
      LLVMValueRef scalar_pred = pred ?
         LLVMBuildExtractElement(builder, pred, ii, "scatter_pred") : NULL;

      if (0)
         lp_build_printf(gallivm, "scatter %d: val %f at %d %p\n",
                         ii, val, index, scalar_ptr);

      if (scalar_pred) {
         LLVMValueRef real_val, dst_val;
         dst_val = LLVMBuildLoad(builder, scalar_ptr, "");
         real_val = lp_build_select(&bld->elem_bld, scalar_pred, val, dst_val);
         LLVMBuildStore(builder, real_val, scalar_ptr);
      }
      else {
         LLVMBuildStore(builder, val, scalar_ptr);
      }
   }
a220 6
/**
 * Read the current value of the ADDR register, convert the floats to
 * ints, add the base index and return the vector of offsets.
 * The offsets will be used to index into the constant buffer or
 * temporary register file.
 */
d222 2
a223 3
get_indirect_index(struct lp_build_tgsi_soa_context *bld,
                   unsigned reg_file, unsigned reg_index,
                   const struct tgsi_src_register *indirect_reg)
d225 3
a227 33
   LLVMBuilderRef builder = bld->base.gallivm->builder;
   struct lp_build_context *uint_bld = &bld->uint_bld;
   /* always use X component of address register */
   unsigned swizzle = indirect_reg->SwizzleX;
   LLVMValueRef base;
   LLVMValueRef rel;
   LLVMValueRef max_index;
   LLVMValueRef index;

   assert(bld->indirect_files & (1 << reg_file));

   base = lp_build_const_int_vec(bld->base.gallivm, uint_bld->type, reg_index);

   assert(swizzle < 4);
   rel = LLVMBuildLoad(builder,
                        bld->addr[indirect_reg->Index][swizzle],
                        "load addr reg");

   /* for indexing we want integers */
   rel = LLVMBuildFPToSI(builder,
                         rel,
                         uint_bld->vec_type, "");

   index = lp_build_add(uint_bld, base, rel);

   max_index = lp_build_const_int_vec(bld->base.gallivm,
                                      uint_bld->type,
                                      bld->info->file_max[reg_file]);

   assert(!uint_bld->type.sign);
   index = lp_build_min(uint_bld, index, max_index);

   return index;
d238 1
a238 1
   unsigned src_op,
d241 2
a242 6
   struct gallivm_state *gallivm = bld->base.gallivm;
   LLVMBuilderRef builder = gallivm->builder;
   struct lp_build_context *uint_bld = &bld->uint_bld;
   const struct tgsi_full_src_register *reg = &inst->Src[src_op];
   const unsigned swizzle =
      tgsi_util_get_full_src_register_swizzle(reg, chan_index);
a243 39
   LLVMValueRef indirect_index = NULL;

   if (swizzle > 3) {
      assert(0 && "invalid swizzle in emit_fetch()");
      return bld->base.undef;
   }

   if (reg->Register.Indirect) {
      indirect_index = get_indirect_index(bld,
                                          reg->Register.File,
                                          reg->Register.Index,
                                          &reg->Indirect);
   } else {
      assert(reg->Register.Index <= bld->info->file_max[reg->Register.File]);
   }

   switch (reg->Register.File) {
   case TGSI_FILE_CONSTANT:
      if (reg->Register.Indirect) {
         LLVMValueRef swizzle_vec =
            lp_build_const_int_vec(bld->base.gallivm, uint_bld->type, swizzle);
         LLVMValueRef index_vec;  /* index into the const buffer */

         /* index_vec = indirect_index * 4 + swizzle */
         index_vec = lp_build_shl_imm(uint_bld, indirect_index, 2);
         index_vec = lp_build_add(uint_bld, index_vec, swizzle_vec);

         /* Gather values from the constant buffer */
         res = build_gather(bld, bld->consts_ptr, index_vec);
      }
      else {
         LLVMValueRef index;  /* index into the const buffer */
         LLVMValueRef scalar, scalar_ptr;

         index = lp_build_const_int32(gallivm, reg->Register.Index*4 + swizzle);

         scalar_ptr = LLVMBuildGEP(builder, bld->consts_ptr,
                                   &index, 1, "");
         scalar = LLVMBuildLoad(builder, scalar_ptr, "");
d245 11
d257 1
a258 1
      break;
d260 9
a268 41
   case TGSI_FILE_IMMEDIATE:
      res = bld->immediates[reg->Register.Index][swizzle];
      assert(res);
      break;

   case TGSI_FILE_INPUT:
      if (reg->Register.Indirect) {
         LLVMValueRef swizzle_vec =
            lp_build_const_int_vec(gallivm, uint_bld->type, swizzle);
         LLVMValueRef length_vec =
            lp_build_const_int_vec(gallivm, uint_bld->type, bld->base.type.length);
         LLVMValueRef index_vec;  /* index into the const buffer */
         LLVMValueRef inputs_array;
         LLVMTypeRef float4_ptr_type;

         /* index_vec = (indirect_index * 4 + swizzle) * length */
         index_vec = lp_build_shl_imm(uint_bld, indirect_index, 2);
         index_vec = lp_build_add(uint_bld, index_vec, swizzle_vec);
         index_vec = lp_build_mul(uint_bld, index_vec, length_vec);

         /* cast inputs_array pointer to float* */
         float4_ptr_type = LLVMPointerType(LLVMFloatTypeInContext(gallivm->context), 0);
         inputs_array = LLVMBuildBitCast(builder, bld->inputs_array,
                                         float4_ptr_type, "");

         /* Gather values from the temporary register array */
         res = build_gather(bld, inputs_array, index_vec);
      } else {
         if (bld->indirect_files & (1 << TGSI_FILE_INPUT)) {
            LLVMValueRef lindex = lp_build_const_int32(gallivm,
                                           reg->Register.Index * 4 + swizzle);
            LLVMValueRef input_ptr =  LLVMBuildGEP(builder,
                                                   bld->inputs_array, &lindex, 1, "");
            res = LLVMBuildLoad(builder, input_ptr, "");
         }
         else {
            res = bld->inputs[reg->Register.Index][swizzle];
         }
      }
      assert(res);
      break;
d270 3
a272 29
   case TGSI_FILE_TEMPORARY:
      if (reg->Register.Indirect) {
         LLVMValueRef swizzle_vec =
            lp_build_const_int_vec(bld->base.gallivm, uint_bld->type, swizzle);
         LLVMValueRef length_vec =
            lp_build_const_int_vec(bld->base.gallivm, uint_bld->type,
                                   bld->base.type.length);
         LLVMValueRef index_vec;  /* index into the const buffer */
         LLVMValueRef temps_array;
         LLVMTypeRef float4_ptr_type;

         /* index_vec = (indirect_index * 4 + swizzle) * length */
         index_vec = lp_build_shl_imm(uint_bld, indirect_index, 2);
         index_vec = lp_build_add(uint_bld, index_vec, swizzle_vec);
         index_vec = lp_build_mul(uint_bld, index_vec, length_vec);

         /* cast temps_array pointer to float* */
         float4_ptr_type = LLVMPointerType(LLVMFloatTypeInContext(bld->base.gallivm->context), 0);
         temps_array = LLVMBuildBitCast(builder, bld->temps_array,
                                        float4_ptr_type, "");

         /* Gather values from the temporary register array */
         res = build_gather(bld, temps_array, index_vec);
      }
      else {
         LLVMValueRef temp_ptr;
         temp_ptr = get_temp_ptr(bld, reg->Register.Index, swizzle);
         res = LLVMBuildLoad(builder, temp_ptr, "");
         if (!res)
d274 5
d283 1
a283 1
      assert(0 && "invalid src register in emit_fetch()");
d293 1
d295 3
a297 1
      /* fall through */
d299 1
a299 1
      res = lp_build_negate( &bld->base, res );
d333 1
a333 1
      *ddx = lp_build_ddx(&bld->base, src);
d336 1
a336 69
      *ddy = lp_build_ddy(&bld->base, src);
}


/**
 * Predicate.
 */
static void
emit_fetch_predicate(
   struct lp_build_tgsi_soa_context *bld,
   const struct tgsi_full_instruction *inst,
   LLVMValueRef *pred)
{
   LLVMBuilderRef builder = bld->base.gallivm->builder;
   unsigned index;
   unsigned char swizzles[4];
   LLVMValueRef unswizzled[4] = {NULL, NULL, NULL, NULL};
   LLVMValueRef value;
   unsigned chan;

   if (!inst->Instruction.Predicate) {
      FOR_EACH_CHANNEL( chan ) {
         pred[chan] = NULL;
      }
      return;
   }

   swizzles[0] = inst->Predicate.SwizzleX;
   swizzles[1] = inst->Predicate.SwizzleY;
   swizzles[2] = inst->Predicate.SwizzleZ;
   swizzles[3] = inst->Predicate.SwizzleW;

   index = inst->Predicate.Index;
   assert(index < LP_MAX_TGSI_PREDS);

   FOR_EACH_CHANNEL( chan ) {
      unsigned swizzle = swizzles[chan];

      /*
       * Only fetch the predicate register channels that are actually listed
       * in the swizzles
       */
      if (!unswizzled[swizzle]) {
         value = LLVMBuildLoad(builder,
                               bld->preds[index][swizzle], "");

         /*
          * Convert the value to an integer mask.
          *
          * TODO: Short-circuit this comparison -- a D3D setp_xx instructions
          * is needlessly causing two comparisons due to storing the intermediate
          * result as float vector instead of an integer mask vector.
          */
         value = lp_build_compare(bld->base.gallivm,
                                  bld->base.type,
                                  PIPE_FUNC_NOTEQUAL,
                                  value,
                                  bld->base.zero);
         if (inst->Predicate.Negate) {
            value = LLVMBuildNot(builder, value, "");
         }

         unswizzled[swizzle] = value;
      } else {
         value = unswizzled[swizzle];
      }

      pred[chan] = value;
   }
a348 1
   LLVMValueRef pred,
a350 2
   struct gallivm_state *gallivm = bld->base.gallivm;
   LLVMBuilderRef builder = gallivm->builder;
a351 2
   struct lp_build_context *uint_bld = &bld->uint_bld;
   LLVMValueRef indirect_index = NULL;
d363 1
a363 1
      value = lp_build_max(&bld->base, value, lp_build_const_vec(bld->base.gallivm, bld->base.type, -1.0));
a370 9
   if (reg->Register.Indirect) {
      indirect_index = get_indirect_index(bld,
                                          reg->Register.File,
                                          reg->Register.Index,
                                          &reg->Indirect);
   } else {
      assert(reg->Register.Index <= bld->info->file_max[reg->Register.File]);
   }

d373 2
a374 39
      if (reg->Register.Indirect) {
         LLVMValueRef chan_vec =
            lp_build_const_int_vec(gallivm, uint_bld->type, chan_index);
         LLVMValueRef length_vec =
            lp_build_const_int_vec(gallivm, uint_bld->type, bld->base.type.length);
         LLVMValueRef index_vec;  /* indexes into the temp registers */
         LLVMValueRef outputs_array;
         LLVMValueRef pixel_offsets;
         LLVMTypeRef float_ptr_type;
         int i;

         /* build pixel offset vector: {0, 1, 2, 3, ...} */
         pixel_offsets = uint_bld->undef;
         for (i = 0; i < bld->base.type.length; i++) {
            LLVMValueRef ii = lp_build_const_int32(gallivm, i);
            pixel_offsets = LLVMBuildInsertElement(builder, pixel_offsets,
                                                   ii, ii, "");
         }

         /* index_vec = (indirect_index * 4 + chan_index) * length + offsets */
         index_vec = lp_build_shl_imm(uint_bld, indirect_index, 2);
         index_vec = lp_build_add(uint_bld, index_vec, chan_vec);
         index_vec = lp_build_mul(uint_bld, index_vec, length_vec);
         index_vec = lp_build_add(uint_bld, index_vec, pixel_offsets);

         float_ptr_type =
            LLVMPointerType(LLVMFloatTypeInContext(gallivm->context), 0);
         outputs_array = LLVMBuildBitCast(builder, bld->outputs_array,
                                          float_ptr_type, "");

         /* Scatter store values into temp registers */
         emit_mask_scatter(bld, outputs_array, index_vec, value,
                           &bld->exec_mask, pred);
      }
      else {
         LLVMValueRef out_ptr = get_output_ptr(bld, reg->Register.Index,
                                               chan_index);
         lp_exec_mask_store(&bld->exec_mask, pred, value, out_ptr);
      }
d378 2
a379 40
      if (reg->Register.Indirect) {
         LLVMValueRef chan_vec =
            lp_build_const_int_vec(gallivm, uint_bld->type, chan_index);
         LLVMValueRef length_vec =
            lp_build_const_int_vec(gallivm, uint_bld->type,
                                   bld->base.type.length);
         LLVMValueRef index_vec;  /* indexes into the temp registers */
         LLVMValueRef temps_array;
         LLVMValueRef pixel_offsets;
         LLVMTypeRef float_ptr_type;
         int i;

         /* build pixel offset vector: {0, 1, 2, 3, ...} */
         pixel_offsets = uint_bld->undef; 
         for (i = 0; i < bld->base.type.length; i++) {
            LLVMValueRef ii = lp_build_const_int32(gallivm, i);
            pixel_offsets = LLVMBuildInsertElement(builder, pixel_offsets,
                                                   ii, ii, "");
         }

         /* index_vec = (indirect_index * 4 + chan_index) * length + offsets */
         index_vec = lp_build_shl_imm(uint_bld, indirect_index, 2);
         index_vec = lp_build_add(uint_bld, index_vec, chan_vec);
         index_vec = lp_build_mul(uint_bld, index_vec, length_vec);
         index_vec = lp_build_add(uint_bld, index_vec, pixel_offsets);

         float_ptr_type =
            LLVMPointerType(LLVMFloatTypeInContext(gallivm->context), 0);
         temps_array = LLVMBuildBitCast(builder, bld->temps_array,
                                        float_ptr_type, "");

         /* Scatter store values into temp registers */
         emit_mask_scatter(bld, temps_array, index_vec, value,
                           &bld->exec_mask, pred);
      }
      else {
         LLVMValueRef temp_ptr = get_temp_ptr(bld, reg->Register.Index,
                                              chan_index);
         lp_exec_mask_store(&bld->exec_mask, pred, value, temp_ptr);
      }
d383 2
a384 7
      lp_exec_mask_store(&bld->exec_mask, pred, value,
                         bld->addr[reg->Register.Index][chan_index]);
      break;

   case TGSI_FILE_PREDICATE:
      lp_exec_mask_store(&bld->exec_mask, pred, value,
                         bld->preds[reg->Register.Index][chan_index]);
d397 1
d401 2
a402 1
          enum lp_build_tex_modifier modifier,
d405 2
a406 3
   LLVMBuilderRef builder = bld->base.gallivm->builder;
   unsigned unit;
   LLVMValueRef lod_bias, explicit_lod;
a408 2
   LLVMValueRef ddx[3];
   LLVMValueRef ddy[3];
a411 8
   if (!bld->sampler) {
      _debug_printf("warning: found texture instruction but no sampler generator supplied\n");
      for (i = 0; i < 4; i++) {
         texel[i] = bld->base.undef;
      }
      return;
   }

d432 4
a435 12
   if (modifier == LP_BLD_TEX_MODIFIER_LOD_BIAS) {
      lod_bias = emit_fetch( bld, inst, 0, 3 );
      explicit_lod = NULL;
   }
   else if (modifier == LP_BLD_TEX_MODIFIER_EXPLICIT_LOD) {
      lod_bias = NULL;
      explicit_lod = emit_fetch( bld, inst, 0, 3 );
   }
   else {
      lod_bias = NULL;
      explicit_lod = NULL;
   }
d437 1
a437 1
   if (modifier == LP_BLD_TEX_MODIFIER_PROJECTED) {
d444 1
a444 1
      if (modifier == LP_BLD_TEX_MODIFIER_PROJECTED)
a450 21
   if (modifier == LP_BLD_TEX_MODIFIER_EXPLICIT_DERIV) {
      LLVMValueRef index0 = lp_build_const_int32(bld->base.gallivm, 0);
      for (i = 0; i < num_coords; i++) {
         LLVMValueRef src1 = emit_fetch( bld, inst, 1, i );
         LLVMValueRef src2 = emit_fetch( bld, inst, 2, i );
         ddx[i] = LLVMBuildExtractElement(builder, src1, index0, "");
         ddy[i] = LLVMBuildExtractElement(builder, src2, index0, "");
      }
      unit = inst->Src[3].Register.Index;
   }  else {
      for (i = 0; i < num_coords; i++) {
         ddx[i] = lp_build_scalar_ddx( &bld->base, coords[i] );
         ddy[i] = lp_build_scalar_ddy( &bld->base, coords[i] );
      }
      unit = inst->Src[1].Register.Index;
   }
   for (i = num_coords; i < 3; i++) {
      ddx[i] = LLVMGetUndef(bld->base.elem_type);
      ddy[i] = LLVMGetUndef(bld->base.elem_type);
   }

d452 1
a452 1
                                  bld->base.gallivm,
d454 1
a454 3
                                  unit, num_coords, coords,
                                  ddx, ddy,
                                  lod_bias, explicit_lod,
a457 37
static boolean
near_end_of_shader(struct lp_build_tgsi_soa_context *bld,
		   int pc)
{
   int i;

   for (i = 0; i < 5; i++) {
      unsigned opcode;

      if (pc + i >= bld->info->num_instructions)
	 return TRUE;

      opcode = bld->instructions[pc + i].Instruction.Opcode;

      if (opcode == TGSI_OPCODE_END)
	 return TRUE;

      if (opcode == TGSI_OPCODE_TEX ||
	  opcode == TGSI_OPCODE_TXP ||
	  opcode == TGSI_OPCODE_TXD ||
	  opcode == TGSI_OPCODE_TXB ||
	  opcode == TGSI_OPCODE_TXL ||
	  opcode == TGSI_OPCODE_TXF ||
	  opcode == TGSI_OPCODE_TXQ ||
	  opcode == TGSI_OPCODE_CAL ||
	  opcode == TGSI_OPCODE_CALLNZ ||
	  opcode == TGSI_OPCODE_IF ||
	  opcode == TGSI_OPCODE_IFC ||
	  opcode == TGSI_OPCODE_BGNLOOP ||
	  opcode == TGSI_OPCODE_SWITCH)
	 return FALSE;
   }

   return TRUE;
}


a458 3
/**
 * Kill fragment if any of the src register values are negative.
 */
d462 1
a462 2
   const struct tgsi_full_instruction *inst,
   int pc)
a463 1
   LLVMBuilderRef builder = bld->base.gallivm->builder;
a488 3
         /*
          * If term < 0 then mask = 0 else mask = ~0.
          */
d492 1
a492 1
            mask = LLVMBuildAnd(builder, mask, chan_mask, "");
d498 1
a498 1
   if(mask) {
a499 4

      if (!near_end_of_shader(bld, pc))
	 lp_build_mask_check(bld->mask);
   }
d504 2
a505 4
 * Predicated fragment kill.
 * XXX Actually, we do an unconditional kill (as in tgsi_exec.c).
 * The only predication is the execution mask which will apply if
 * we're inside a loop or conditional.
d507 2
a508 4
static void
emit_kilp(struct lp_build_tgsi_soa_context *bld,
          const struct tgsi_full_instruction *inst,
	  int pc)
d510 6
a515 8
   LLVMBuilderRef builder = bld->base.gallivm->builder;
   LLVMValueRef mask;

   /* For those channels which are "alive", disable fragment shader
    * execution.
    */
   if (bld->exec_mask.has_mask) {
      mask = LLVMBuildNot(builder, bld->exec_mask.exec_mask, "kilp");
d517 5
a521 53
   else {
      LLVMValueRef zero = LLVMConstNull(bld->base.int_vec_type);
      mask = zero;
   }

   lp_build_mask_update(bld->mask, mask);

   if (!near_end_of_shader(bld, pc))
      lp_build_mask_check(bld->mask);
}


/**
 * Emit code which will dump the value of all the temporary registers
 * to stdout.
 */
static void
emit_dump_temps(struct lp_build_tgsi_soa_context *bld)
{
   struct gallivm_state *gallivm = bld->base.gallivm;
   LLVMBuilderRef builder = gallivm->builder;
   LLVMValueRef temp_ptr;
   LLVMValueRef i0 = lp_build_const_int32(gallivm, 0);
   LLVMValueRef i1 = lp_build_const_int32(gallivm, 1);
   LLVMValueRef i2 = lp_build_const_int32(gallivm, 2);
   LLVMValueRef i3 = lp_build_const_int32(gallivm, 3);
   int index;
   int n = bld->info->file_max[TGSI_FILE_TEMPORARY];

   for (index = 0; index < n; index++) {
      LLVMValueRef idx = lp_build_const_int32(gallivm, index);
      LLVMValueRef v[4][4], res;
      int chan;

      lp_build_printf(gallivm, "TEMP[%d]:\n", idx);

      for (chan = 0; chan < 4; chan++) {
         temp_ptr = get_temp_ptr(bld, index, chan);
         res = LLVMBuildLoad(builder, temp_ptr, "");
         v[chan][0] = LLVMBuildExtractElement(builder, res, i0, "");
         v[chan][1] = LLVMBuildExtractElement(builder, res, i1, "");
         v[chan][2] = LLVMBuildExtractElement(builder, res, i2, "");
         v[chan][3] = LLVMBuildExtractElement(builder, res, i3, "");
      }

      lp_build_printf(gallivm, "  X: %f %f %f %f\n",
                      v[0][0], v[0][1], v[0][2], v[0][3]);
      lp_build_printf(gallivm, "  Y: %f %f %f %f\n",
                      v[1][0], v[1][1], v[1][2], v[1][3]);
      lp_build_printf(gallivm, "  Z: %f %f %f %f\n",
                      v[2][0], v[2][1], v[2][2], v[2][3]);
      lp_build_printf(gallivm, "  W: %f %f %f %f\n",
                      v[3][0], v[3][1], v[3][2], v[3][3]);
d523 1
d526 1
a526 3


static void
d531 2
a532 4
   struct gallivm_state *gallivm = bld->base.gallivm;
   LLVMTypeRef vec_type = bld->base.vec_type;
   const unsigned first = decl->Range.First;
   const unsigned last = decl->Range.Last;
d536 2
a537 1
      assert(last <= bld->info->file_max[decl->Declaration.File]);
d540 3
a542 5
         assert(idx < LP_MAX_TGSI_TEMPS);
         if (!(bld->indirect_files & (1 << TGSI_FILE_TEMPORARY))) {
            for (i = 0; i < NUM_CHANNELS; i++)
               bld->temps[idx][i] = lp_build_alloca(gallivm, vec_type, "temp");
         }
a545 9
         if (!(bld->indirect_files & (1 << TGSI_FILE_OUTPUT))) {
            for (i = 0; i < NUM_CHANNELS; i++)
               bld->outputs[idx][i] = lp_build_alloca(gallivm,
                                                      vec_type, "output");
         }
         break;

      case TGSI_FILE_ADDRESS:
         assert(idx < LP_MAX_TGSI_ADDRS);
d547 2
a548 8
            bld->addr[idx][i] = lp_build_alloca(gallivm, vec_type, "addr");
         break;

      case TGSI_FILE_PREDICATE:
         assert(idx < LP_MAX_TGSI_PREDS);
         for (i = 0; i < NUM_CHANNELS; i++)
            bld->preds[idx][i] = lp_build_alloca(gallivm, vec_type,
                                                 "predicate");
d553 1
a553 1
         break;
d555 3
d559 2
d563 1
a563 6

/**
 * Emit LLVM for one TGSI instruction.
 * \param return TRUE for success, FALSE otherwise
 */
static boolean
d567 1
a567 2
   const struct tgsi_opcode_info *info,
   int *pc)
d580 3
a582 12
   /*
    * Stores and write masks are handled in a general fashion after the long
    * instruction opcode switch statement.
    *
    * Although not stricitly necessary, we avoid generating instructions for
    * channels which won't be stored, in cases where's that easy. For some
    * complex instructions, like texture sampling, it is more convenient to
    * assume a full writemask and then let LLVM optimization passes eliminate
    * redundant code.
    */

   (*pc)++;
d585 1
a585 1
   if (info->num_dst) {
d592 1
d594 1
d597 2
a598 1
         tmp0 = lp_build_floor(&bld->base, tmp0);
d602 1
d868 1
a868 1
         tmp1 = lp_build_const_vec(bld->base.gallivm, bld->base.type, 0.5);
d1000 1
a1000 1
      return FALSE;
d1043 2
a1044 1
      emit_kilp( bld, inst, (*pc)-1 );
d1049 1
a1049 1
      emit_kil( bld, inst, (*pc)-1 );
d1053 1
a1053 1
      return FALSE;
d1057 1
a1057 1
      return FALSE;
d1061 1
a1061 1
      return FALSE;
d1065 1
a1065 1
      return FALSE;
d1069 1
a1069 1
      return FALSE;
d1129 2
a1130 1
      emit_tex( bld, inst, LP_BLD_TEX_MODIFIER_NONE, dst0 );
d1134 2
a1135 1
      emit_tex( bld, inst, LP_BLD_TEX_MODIFIER_EXPLICIT_DERIV, dst0 );
d1141 1
a1141 1
      return FALSE;
d1147 1
a1147 1
      return FALSE;
d1153 1
a1153 1
      return FALSE;
d1159 1
a1159 1
      return FALSE;
d1165 1
a1165 1
      return FALSE;
d1171 1
a1171 1
      return FALSE;
d1174 1
d1176 1
d1179 2
a1180 1
         tmp0 = lp_build_round(&bld->base, tmp0);
d1184 1
d1189 1
a1189 1
      return FALSE;
d1193 2
a1194 4
      lp_exec_mask_call(&bld->exec_mask,
                        inst->Label.Label,
                        pc);

d1198 2
a1199 1
      lp_exec_mask_ret(&bld->exec_mask, pc);
a1202 5
      if (0) {
         /* for debugging */
         emit_dump_temps(bld);
      }
      *pc = -1;
d1241 1
a1241 1
      emit_tex( bld, inst, LP_BLD_TEX_MODIFIER_LOD_BIAS, dst0 );
d1329 1
a1329 1
      return FALSE;
d1346 1
a1346 1
      emit_tex( bld, inst, LP_BLD_TEX_MODIFIER_EXPLICIT_LOD, dst0 );
d1350 1
a1350 1
      emit_tex( bld, inst, LP_BLD_TEX_MODIFIER_PROJECTED, dst0 );
d1352 1
a1352 1

d1354 2
a1355 1
      lp_exec_break(&bld->exec_mask);
a1359 2
      tmp0 = lp_build_cmp(&bld->base, PIPE_FUNC_NOTEQUAL,
                          tmp0, bld->base.zero);
d1363 4
a1366 2
   case TGSI_OPCODE_BGNLOOP:
      lp_exec_bgnloop(&bld->exec_mask);
d1369 4
a1372 2
   case TGSI_OPCODE_BGNSUB:
      lp_exec_mask_bgnsub(&bld->exec_mask);
d1383 4
a1386 2
   case TGSI_OPCODE_ENDLOOP:
      lp_exec_endloop(bld->base.gallivm, &bld->exec_mask);
d1389 4
a1392 2
   case TGSI_OPCODE_ENDSUB:
      lp_exec_mask_endsub(&bld->exec_mask, pc);
d1398 1
a1398 1
      return FALSE;
d1404 1
a1404 1
      return FALSE;
d1417 1
a1417 1
      return FALSE;
d1423 1
a1423 1
      return FALSE;
d1436 1
a1436 1
      return FALSE;
d1442 1
a1442 1
      return FALSE;
d1448 1
a1448 1
      return FALSE;
d1454 1
a1454 1
      return FALSE;
d1460 1
a1460 1
      return FALSE;
d1466 1
a1466 1
      return FALSE;
d1472 1
a1472 1
      return FALSE;
d1478 1
a1478 1
      return FALSE;
d1484 1
a1484 1
      return FALSE;
d1488 2
a1489 1
      lp_exec_continue(&bld->exec_mask);
d1493 1
a1493 1
      return FALSE;
d1497 1
a1497 1
      return FALSE;
d1504 1
a1504 1
      return FALSE;
a1507 4
      LLVMValueRef pred[NUM_CHANNELS];

      emit_fetch_predicate( bld, inst, pred );

d1509 1
a1509 1
         emit_store( bld, inst, 0, chan_index, pred[chan_index], dst0[chan_index]);
d1513 1
a1513 1
   return TRUE;
d1518 1
a1518 1
lp_build_tgsi_soa(struct gallivm_state *gallivm,
d1526 1
a1526 2
                  struct lp_build_sampler_soa *sampler,
                  const struct tgsi_shader_info *info)
a1530 1
   uint num_instructions = 0;
a1531 9
   int pc = 0;

   struct lp_type res_type;

   assert(type.length <= LP_MAX_VECTOR_LENGTH);
   memset(&res_type, 0, sizeof res_type);
   res_type.width = type.width;
   res_type.length = type.length;
   res_type.sign = 1;
d1535 1
a1535 3
   lp_build_context_init(&bld.base, gallivm, type);
   lp_build_context_init(&bld.uint_bld, gallivm, lp_uint_type(type));
   lp_build_context_init(&bld.elem_bld, gallivm, lp_elem_type(type));
a1541 9
   bld.info = info;
   bld.indirect_files = info->indirect_files;
   bld.instructions = (struct tgsi_full_instruction *)
                      MALLOC( LP_MAX_INSTRUCTIONS * sizeof(struct tgsi_full_instruction) );
   bld.max_instructions = LP_MAX_INSTRUCTIONS;

   if (!bld.instructions) {
      return;
   }
a1544 45
   if (bld.indirect_files & (1 << TGSI_FILE_TEMPORARY)) {
      LLVMValueRef array_size =
         lp_build_const_int32(gallivm,
                              info->file_max[TGSI_FILE_TEMPORARY] * 4 + 4);
      bld.temps_array = lp_build_array_alloca(gallivm,
                                              bld.base.vec_type, array_size,
                                              "temp_array");
   }

   if (bld.indirect_files & (1 << TGSI_FILE_OUTPUT)) {
      LLVMValueRef array_size =
         lp_build_const_int32(gallivm,
                              info->file_max[TGSI_FILE_OUTPUT] * 4 + 4);
      bld.outputs_array = lp_build_array_alloca(gallivm,
                                                bld.base.vec_type, array_size,
                                                "output_array");
   }

   /* If we have indirect addressing in inputs we need to copy them into
    * our alloca array to be able to iterate over them */
   if (bld.indirect_files & (1 << TGSI_FILE_INPUT)) {
      unsigned index, chan;
      LLVMTypeRef vec_type = bld.base.vec_type;
      LLVMValueRef array_size =
         lp_build_const_int32(gallivm, info->file_max[TGSI_FILE_INPUT]*4 + 4);
      bld.inputs_array = lp_build_array_alloca(gallivm,
                                               vec_type, array_size,
                                               "input_array");

      assert(info->num_inputs <= info->file_max[TGSI_FILE_INPUT] + 1);

      for (index = 0; index < info->num_inputs; ++index) {
         for (chan = 0; chan < NUM_CHANNELS; ++chan) {
            LLVMValueRef lindex =
               lp_build_const_int32(gallivm, index * 4 + chan);
            LLVMValueRef input_ptr =
               LLVMBuildGEP(gallivm->builder, bld.inputs_array,
                            &lindex, 1, "");
            LLVMValueRef value = bld.inputs[index][chan];
            if (value)
               LLVMBuildStore(gallivm->builder, value, input_ptr);
         }
      }
   }

d1553 4
a1556 1
         emit_declaration( &bld, &parse.FullToken.FullDeclaration );
d1561 5
a1565 20
            /* save expanded instruction */
            if (num_instructions == bld.max_instructions) {
               struct tgsi_full_instruction *instructions;
               instructions = REALLOC(bld.instructions,
                                      bld.max_instructions
                                      * sizeof(struct tgsi_full_instruction),
                                      (bld.max_instructions + LP_MAX_INSTRUCTIONS)
                                      * sizeof(struct tgsi_full_instruction));
               if (!instructions) {
                  break;
               }
               bld.instructions = instructions;
               bld.max_instructions += LP_MAX_INSTRUCTIONS;
            }

            memcpy(bld.instructions + num_instructions,
                   &parse.FullToken.FullInstruction,
                   sizeof(bld.instructions[0]));

            num_instructions++;
d1575 1
a1575 1
            assert(num_immediates < LP_MAX_TGSI_IMMEDIATES);
d1578 1
a1578 1
                  lp_build_const_vec(gallivm, type, parse.FullToken.FullImmediate.u[i].Float);
a1592 29
   while (pc != -1) {
      struct tgsi_full_instruction *instr = bld.instructions + pc;
      const struct tgsi_opcode_info *opcode_info =
         tgsi_get_opcode_info(instr->Instruction.Opcode);
      if (!emit_instruction( &bld, instr, opcode_info, &pc ))
         _debug_printf("warning: failed to translate tgsi opcode %s to LLVM\n",
                       opcode_info->mnemonic);
   }

   /* If we have indirect addressing in outputs we need to copy our alloca array
    * to the outputs slots specified by the called */
   if (bld.indirect_files & (1 << TGSI_FILE_OUTPUT)) {
      unsigned index, chan;
      assert(info->num_outputs <= info->file_max[TGSI_FILE_OUTPUT] + 1);
      for (index = 0; index < info->num_outputs; ++index) {
         for (chan = 0; chan < NUM_CHANNELS; ++chan) {
            bld.outputs[index][chan] = get_output_ptr(&bld, index, chan);
         }
      }
   }

   if (0) {
      LLVMBasicBlockRef block = LLVMGetInsertBlock(gallivm->builder);
      LLVMValueRef function = LLVMGetBasicBlockParent(block);
      debug_printf("11111111111111111111111111111 \n");
      tgsi_dump(tokens, 0);
      lp_debug_dump_value(function);
      debug_printf("2222222222222222222222222222 \n");
   }
a1593 9

   if (0) {
      LLVMModuleRef module = LLVMGetGlobalParent(
         LLVMGetBasicBlockParent(LLVMGetInsertBlock(gallivm->builder)));
      LLVMDumpModule(module);

   }

   FREE( bld.instructions );
@


1.1.1.2
log
@Import Mesa 9.2.0
@
text
@a44 1
#include "tgsi/tgsi_exec.h"
a48 1
#include "lp_bld_tgsi_action.h"
a62 2
#include "lp_bld_sample.h"
#include "lp_bld_struct.h"
d64 106
a169 1
#define DUMP_GS_EMITS 0
a172 3
   LLVMTypeRef int_type = LLVMInt32TypeInContext(bld->gallivm->context);
   LLVMBuilderRef builder = bld->gallivm->builder;

a174 1
   mask->ret_in_main = FALSE;
a177 1
   mask->switch_stack_size = 0;
d180 1
a180 2
   mask->exec_mask = mask->ret_mask = mask->break_mask = mask->cont_mask =
         mask->cond_mask = mask->switch_mask =
a181 7

   mask->loop_limiter = lp_build_alloca(bld->gallivm, int_type, "looplimiter");

   LLVMBuildStore(
      builder,
      LLVMConstInt(int_type, LP_MAX_TGSI_LOOP_ITERATIONS, false),
      mask->loop_limiter);
d203 1
a203 8
   if (mask->switch_stack_size) {
      mask->exec_mask = LLVMBuildAnd(builder,
                                     mask->exec_mask,
                                     mask->switch_mask,
                                     "switchmask");
   }

   if (mask->call_stack_size || mask->ret_in_main) {
d212 1
a212 3
                     mask->call_stack_size > 0 ||
                     mask->switch_stack_size > 0 ||
                     mask->ret_in_main);
a272 4
   mask->break_type_stack[mask->loop_stack_size + mask->switch_stack_size] =
      mask->break_type;
   mask->break_type = LP_EXEC_MASK_BREAK_TYPE_LOOP;

a282 1

d291 1
a291 2
static void lp_exec_break(struct lp_exec_mask *mask,
                          struct lp_build_tgsi_context * bld_base)
d294 1
a294 50

   if (mask->break_type == LP_EXEC_MASK_BREAK_TYPE_LOOP) {
      LLVMValueRef exec_mask = LLVMBuildNot(builder,
                                            mask->exec_mask,
                                            "break");

      mask->break_mask = LLVMBuildAnd(builder,
                                      mask->break_mask,
                                      exec_mask, "break_full");
   }
   else {
      unsigned opcode = bld_base->instructions[bld_base->pc + 1].Instruction.Opcode;
      boolean break_always = (opcode == TGSI_OPCODE_ENDSWITCH ||
                              opcode == TGSI_OPCODE_CASE);


      if (mask->switch_in_default) {
         /*
          * stop default execution but only if this is an unconditional switch.
          * (The condition here is not perfect since dead code after break is
          * allowed but should be sufficient since false negatives are just
          * unoptimized - so we don't have to pre-evaluate that).
          */
         if(break_always && mask->switch_pc) {
            bld_base->pc = mask->switch_pc;
            return;
         }
      }

      if (break_always) {
         mask->switch_mask = LLVMConstNull(mask->bld->int_vec_type);
      }
      else {
         LLVMValueRef exec_mask = LLVMBuildNot(builder,
                                               mask->exec_mask,
                                               "break");
         mask->switch_mask = LLVMBuildAnd(builder,
                                          mask->switch_mask,
                                          exec_mask, "break_switch");
      }
   }

   lp_exec_mask_update(mask);
}

static void lp_exec_break_condition(struct lp_exec_mask *mask,
                                    LLVMValueRef cond)
{
   LLVMBuilderRef builder = mask->bld->gallivm->builder;
   LLVMValueRef cond_mask = LLVMBuildAnd(builder,
d296 1
a296 2
                                         cond, "cond_mask");
   cond_mask = LLVMBuildNot(builder, cond_mask, "break_cond");
d298 3
a300 10
   if (mask->break_type == LP_EXEC_MASK_BREAK_TYPE_LOOP) {
      mask->break_mask = LLVMBuildAnd(builder,
                                      mask->break_mask,
                                      cond_mask, "breakc_full");
   }
   else {
      mask->switch_mask = LLVMBuildAnd(builder,
                                       mask->switch_mask,
                                       cond_mask, "breakc_switch");
   }
a324 1
   LLVMTypeRef int_type = LLVMInt32TypeInContext(mask->bld->gallivm->context);
d328 1
a328 1
   LLVMValueRef i1cond, i2cond, icond, limiter;
d345 1
a345 12
   /* Decrement the loop limiter */
   limiter = LLVMBuildLoad(builder, mask->loop_limiter, "");

   limiter = LLVMBuildSub(
      builder,
      limiter,
      LLVMConstInt(int_type, 1, false),
      "");

   LLVMBuildStore(builder, limiter, mask->loop_limiter);

   /* i1cond = (mask != 0) */
d350 1
a350 11
      LLVMConstNull(reg_type), "i1cond");

   /* i2cond = (looplimiter > 0) */
   i2cond = LLVMBuildICmp(
      builder,
      LLVMIntSGT,
      limiter,
      LLVMConstNull(int_type), "i2cond");

   /* if( i1cond && i2cond ) */
   icond = LLVMBuildAnd(builder, i1cond, i2cond, "");
d355 1
a355 1
                   icond, mask->loop_block, endloop);
a364 24
   mask->break_type = mask->break_type_stack[mask->loop_stack_size + mask->switch_stack_size];

   lp_exec_mask_update(mask);
}

static void lp_exec_switch(struct lp_exec_mask *mask,
                           LLVMValueRef switchval)
{
   mask->break_type_stack[mask->loop_stack_size + mask->switch_stack_size] =
      mask->break_type;
   mask->break_type = LP_EXEC_MASK_BREAK_TYPE_SWITCH;

   mask->switch_stack[mask->switch_stack_size].switch_val = mask->switch_val;
   mask->switch_stack[mask->switch_stack_size].switch_mask = mask->switch_mask;
   mask->switch_stack[mask->switch_stack_size].switch_mask_default = mask->switch_mask_default;
   mask->switch_stack[mask->switch_stack_size].switch_in_default = mask->switch_in_default;
   mask->switch_stack[mask->switch_stack_size].switch_pc = mask->switch_pc;
   mask->switch_stack_size++;

   mask->switch_val = switchval;
   mask->switch_mask = LLVMConstNull(mask->int_vec_type);
   mask->switch_mask_default = LLVMConstNull(mask->int_vec_type);
   mask->switch_in_default = false;
   mask->switch_pc = 0;
d369 1
a369 174
static void lp_exec_endswitch(struct lp_exec_mask *mask,
                              struct lp_build_tgsi_context * bld_base)
{
   LLVMBuilderRef builder = mask->bld->gallivm->builder;

   /* check if there's deferred default if so do it now */
   if (mask->switch_pc && !mask->switch_in_default) {
      LLVMValueRef prevmask, defaultmask;
      unsigned tmp_pc;
      prevmask = mask->switch_stack[mask->switch_stack_size - 1].switch_mask;
      defaultmask = LLVMBuildNot(builder, mask->switch_mask_default, "sw_default_mask");
      mask->switch_mask = LLVMBuildAnd(builder, prevmask, defaultmask, "sw_mask");
      mask->switch_in_default = true;

      lp_exec_mask_update(mask);

      assert(bld_base->instructions[mask->switch_pc - 1].Instruction.Opcode ==
             TGSI_OPCODE_DEFAULT);

      tmp_pc = bld_base->pc;
      bld_base->pc = mask->switch_pc;
      /*
       * re-purpose switch_pc to point to here again, since we stop execution of
       * the deferred default after next break.
       */
      mask->switch_pc = tmp_pc - 1;

      return;
   }

   else if (mask->switch_pc && mask->switch_in_default) {
      assert(bld_base->pc == mask->switch_pc + 1);
   }

   mask->switch_stack_size--;
   mask->switch_val = mask->switch_stack[mask->switch_stack_size].switch_val;
   mask->switch_mask = mask->switch_stack[mask->switch_stack_size].switch_mask;
   mask->switch_mask_default = mask->switch_stack[mask->switch_stack_size].switch_mask_default;
   mask->switch_in_default = mask->switch_stack[mask->switch_stack_size].switch_in_default;
   mask->switch_pc = mask->switch_stack[mask->switch_stack_size].switch_pc;

   mask->break_type = mask->break_type_stack[mask->loop_stack_size + mask->switch_stack_size];

   lp_exec_mask_update(mask);
}

static void lp_exec_case(struct lp_exec_mask *mask,
                         LLVMValueRef caseval)
{
   LLVMBuilderRef builder = mask->bld->gallivm->builder;

   LLVMValueRef casemask, prevmask;

   /* skipping case mask evaluation here is NOT optional (not in all cases anyway). */
   if (!mask->switch_in_default) {
      prevmask = mask->switch_stack[mask->switch_stack_size - 1].switch_mask;
      casemask = lp_build_cmp(mask->bld, PIPE_FUNC_EQUAL, caseval, mask->switch_val);
      mask->switch_mask_default = LLVMBuildOr(builder, casemask,
                                              mask->switch_mask_default, "sw_default_mask");
      casemask = LLVMBuildOr(builder, casemask, mask->switch_mask, "");
      mask->switch_mask = LLVMBuildAnd(builder, casemask, prevmask, "sw_mask");

      lp_exec_mask_update(mask);
   }
}

/*
 * Analyse default statement in a switch.
 * \return true if default is last statement, false otherwise
 * \param default_pc_start contains pc of instruction to jump to
 *                         if default wasn't last but there's no
 *                         fallthrough into default.
 */
static boolean default_analyse_is_last(struct lp_exec_mask *mask,
                                       struct lp_build_tgsi_context * bld_base,
                                       int *default_pc_start)
{
   unsigned pc = bld_base->pc;
   unsigned curr_switch_stack = mask->switch_stack_size;

   /* skip over case statements which are together with default */
   while (bld_base->instructions[pc].Instruction.Opcode == TGSI_OPCODE_CASE) {
      pc++;
   }

   while (pc != -1 && pc < bld_base->num_instructions) {
      unsigned opcode = bld_base->instructions[pc].Instruction.Opcode;
      switch (opcode) {
      case TGSI_OPCODE_CASE:
         if (curr_switch_stack == mask->switch_stack_size) {
            *default_pc_start = pc - 1;
            return false;
         }
         break;
      case TGSI_OPCODE_SWITCH:
         curr_switch_stack++;
         break;
      case TGSI_OPCODE_ENDSWITCH:
         if (curr_switch_stack == mask->switch_stack_size) {
            *default_pc_start = pc - 1;
            return true;
         }
         curr_switch_stack--;
         break;
      }
      pc++;
   }
   /* should never arrive here */
   assert(0);
   return true;
}

static void lp_exec_default(struct lp_exec_mask *mask,
                            struct lp_build_tgsi_context * bld_base)
{
   LLVMBuilderRef builder = mask->bld->gallivm->builder;

   int default_exec_pc;
   boolean default_is_last;

   /*
    * This is a messy opcode, because it may not be always at the end and
    * there can be fallthrough in and out of it.
    */

   default_is_last = default_analyse_is_last(mask, bld_base, &default_exec_pc);
   /*
    * If it is last statement in switch (note that case statements appearing
    * "at the same time" as default don't change that) everything is just fine,
    * update switch mask and go on. This means we can handle default with
    * fallthrough INTO it without overhead, if it is last.
    */
   if (default_is_last) {
      LLVMValueRef prevmask, defaultmask;
      prevmask = mask->switch_stack[mask->switch_stack_size - 1].switch_mask;
      defaultmask = LLVMBuildNot(builder, mask->switch_mask_default, "sw_default_mask");
      defaultmask = LLVMBuildOr(builder, defaultmask, mask->switch_mask, "");
      mask->switch_mask = LLVMBuildAnd(builder, prevmask, defaultmask, "sw_mask");
      mask->switch_in_default = true;

      lp_exec_mask_update(mask);
   }
   else {
      /*
       * Technically, "case" immediately before default isn't really a
       * fallthrough, however we still have to count them as such as we
       * already have updated the masks.
       * If that happens in practice could add a switch optimizer pass
       * which just gets rid of all case statements appearing together with
       * default (or could do switch analysis at switch start time instead).
       */
      unsigned opcode = bld_base->instructions[bld_base->pc - 1].Instruction.Opcode;
      boolean ft_into = (opcode != TGSI_OPCODE_BRK ||
                         opcode != TGSI_OPCODE_SWITCH);
      /*
       * If it is not last statement and there was no fallthrough into it,
       * we record the PC and continue execution at next case (again, those
       * case encountered at the same time don't count). At endswitch
       * time, we update switchmask, and go back executing the code we skipped
       * until the next break (possibly re-executing some code with changed mask
       * if there was a fallthrough out of default).
       * Finally, if it is not last statement and there was a fallthrough into it,
       * do the same as with the former case, except instead of skipping the code
       * just execute it without updating the mask, then go back and re-execute.
       */
      mask->switch_pc = bld_base->pc;
      if (!ft_into) {
         bld_base->pc = default_exec_pc;
      }
   }
}


/* stores val into an address pointed to by dst_ptr.
a374 1
                               struct lp_build_context *bld_store,
d377 1
a377 1
                               LLVMValueRef dst_ptr)
a380 4
   assert(lp_check_value(bld_store->type, val));
   assert(LLVMGetTypeKind(LLVMTypeOf(dst_ptr)) == LLVMPointerTypeKind);
   assert(LLVMGetElementType(LLVMTypeOf(dst_ptr)) == LLVMTypeOf(val));

d391 1
a391 1
      LLVMValueRef res, dst;
d393 6
a398 3
      dst = LLVMBuildLoad(builder, dst_ptr, "");
      res = lp_build_select(bld_store, pred, val, dst);
      LLVMBuildStore(builder, res, dst_ptr);
d400 1
a400 1
      LLVMBuildStore(builder, val, dst_ptr);
d419 1
a419 4
   if (mask->cond_stack_size == 0 &&
       mask->loop_stack_size == 0 &&
       mask->switch_stack_size == 0 &&
       mask->call_stack_size == 0) {
a423 10

   if (mask->call_stack_size == 0) {
      /*
       * This requires special handling since we need to ensure
       * we don't drop the mask even if we have no call stack
       * (e.g. after a ret in a if clause after the endif)
       */
      mask->ret_in_main = TRUE;
   }

d455 2
a456 2
LLVMValueRef
lp_get_temp_ptr_soa(struct lp_build_tgsi_soa_context *bld,
d460 1
a460 1
   LLVMBuilderRef builder = bld->bld_base.base.gallivm->builder;
d463 1
a463 1
      LLVMValueRef lindex = lp_build_const_int32(bld->bld_base.base.gallivm, index * 4 + chan);
d477 2
a478 2
LLVMValueRef
lp_get_output_ptr(struct lp_build_tgsi_soa_context *bld,
d482 1
a482 1
   LLVMBuilderRef builder = bld->bld_base.base.gallivm->builder;
d485 1
a485 1
      LLVMValueRef lindex = lp_build_const_int32(bld->bld_base.base.gallivm,
a493 20
/*
 * If we have indirect addressing in outputs copy our alloca array
 * to the outputs slots specified by the caller to make sure
 * our outputs are delivered consistently via the same interface.
 */
static void
gather_outputs(struct lp_build_tgsi_soa_context * bld)
{
   if ((bld->indirect_files & (1 << TGSI_FILE_OUTPUT))) {
      unsigned index, chan;
      assert(bld->bld_base.info->num_outputs <=
             bld->bld_base.info->file_max[TGSI_FILE_OUTPUT] + 1);
      for (index = 0; index < bld->bld_base.info->num_outputs; ++index) {
         for (chan = 0; chan < TGSI_NUM_CHANNELS; ++chan) {
            bld->outputs[index][chan] = lp_get_output_ptr(bld, index, chan);
         }
      }
   }
}

d500 1
a500 1
build_gather(struct lp_build_context *bld,
d504 2
a505 2
   LLVMBuilderRef builder = bld->gallivm->builder;
   LLVMValueRef res = bld->undef;
d511 2
a512 2
   for (i = 0; i < bld->type.length; i++) {
      LLVMValueRef ii = lp_build_const_int32(bld->gallivm, i);
d537 1
a537 1
   struct gallivm_state *gallivm = bld->bld_base.base.gallivm;
d554 1
a554 1
   for (i = 0; i < bld->bld_base.base.type.length; i++) {
d588 1
a588 1
                   const struct tgsi_ind_register *indirect_reg)
d590 2
a591 2
   LLVMBuilderRef builder = bld->bld_base.base.gallivm->builder;
   struct lp_build_context *uint_bld = &bld->bld_base.uint_bld;
d593 1
a593 1
   unsigned swizzle = indirect_reg->Swizzle;
d601 1
a601 1
   base = lp_build_const_int_vec(bld->bld_base.base.gallivm, uint_bld->type, reg_index);
d604 8
a611 18
   switch (indirect_reg->File) {
   case TGSI_FILE_ADDRESS:
      rel = LLVMBuildLoad(builder,
                          bld->addr[indirect_reg->Index][swizzle],
                          "load addr reg");
      /* ADDR LLVM values already have LLVM integer type. */
      break;
   case TGSI_FILE_TEMPORARY:
      rel = lp_get_temp_ptr_soa(bld, indirect_reg->Index, swizzle);
      rel = LLVMBuildLoad(builder, rel, "load temp reg");
      /* TEMP LLVM values always have LLVM float type, but for indirection, the
       * value actually stored is expected to be an integer */
      rel = LLVMBuildBitCast(builder, rel, uint_bld->vec_type, "");
      break;
   default:
      assert(0);
      rel = uint_bld->zero;
   }
d615 1
a615 1
   max_index = lp_build_const_int_vec(bld->bld_base.base.gallivm,
d617 1
a617 1
                                      bld->bld_base.info->file_max[reg_file]);
a624 26
static struct lp_build_context *
stype_to_fetch(struct lp_build_tgsi_context * bld_base,
	       enum tgsi_opcode_type stype)
{
   struct lp_build_context *bld_fetch;

   switch (stype) {
   case TGSI_TYPE_FLOAT:
   case TGSI_TYPE_UNTYPED:
      bld_fetch = &bld_base->base;
      break;
   case TGSI_TYPE_UNSIGNED:
      bld_fetch = &bld_base->uint_bld;
      break;
   case TGSI_TYPE_SIGNED:
      bld_fetch = &bld_base->int_bld;
      break;
   case TGSI_TYPE_VOID:
   case TGSI_TYPE_DOUBLE:
   default:
      assert(0);
      bld_fetch = NULL;
      break;
   }
   return bld_fetch;
}
d626 3
d630 5
a634 5
emit_fetch_constant(
   struct lp_build_tgsi_context * bld_base,
   const struct tgsi_full_src_register * reg,
   enum tgsi_opcode_type stype,
   unsigned swizzle)
d636 1
a636 2
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
   struct gallivm_state *gallivm = bld_base->base.gallivm;
d638 5
a642 1
   struct lp_build_context *uint_bld = &bld_base->uint_bld;
a643 7
   unsigned dimension = 0;
   LLVMValueRef dimension_index;
   LLVMValueRef consts_ptr;
   LLVMValueRef res;

   /* XXX: Handle fetching xyzw components as a vector */
   assert(swizzle != ~0);
d645 3
a647 4
   if (reg->Register.Dimension) {
      assert(!reg->Dimension.Indirect);
      dimension = reg->Dimension.Index;
      assert(dimension < LP_MAX_TGSI_CONST_BUFFERS);
a649 3
   dimension_index = lp_build_const_int32(gallivm, dimension);
   consts_ptr = lp_build_array_get(gallivm, bld->consts_ptr, dimension_index);

d655 2
d659 10
a668 8
   if (reg->Register.Indirect) {
      LLVMValueRef swizzle_vec =
         lp_build_const_int_vec(bld->bld_base.base.gallivm, uint_bld->type, swizzle);
      LLVMValueRef index_vec;  /* index into the const buffer */

      /* index_vec = indirect_index * 4 + swizzle */
      index_vec = lp_build_shl_imm(uint_bld, indirect_index, 2);
      index_vec = lp_build_add(uint_bld, index_vec, swizzle_vec);
d670 6
a675 6
      /* Gather values from the constant buffer */
      res = build_gather(&bld_base->base, consts_ptr, index_vec);
   }
   else {
      LLVMValueRef index;  /* index into the const buffer */
      LLVMValueRef scalar, scalar_ptr;
d677 1
a677 1
      index = lp_build_const_int32(gallivm, reg->Register.Index*4 + swizzle);
d679 3
a681 5
      scalar_ptr = LLVMBuildGEP(builder, consts_ptr,
                                &index, 1, "");
      scalar = LLVMBuildLoad(builder, scalar_ptr, "");
      res = lp_build_broadcast_scalar(&bld_base->base, scalar);
   }
d683 3
a685 6
   if (stype == TGSI_TYPE_SIGNED || stype == TGSI_TYPE_UNSIGNED) {
      struct lp_build_context *bld_fetch = stype_to_fetch(bld_base, stype);
      res = LLVMBuildBitCast(builder, res, bld_fetch->vec_type, "");
   }
   return res;
}
d687 4
a690 14
static LLVMValueRef
emit_fetch_immediate(
   struct lp_build_tgsi_context * bld_base,
   const struct tgsi_full_src_register * reg,
   enum tgsi_opcode_type stype,
   unsigned swizzle)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
   struct gallivm_state *gallivm = bld->bld_base.base.gallivm;
   LLVMBuilderRef builder = gallivm->builder;
   struct lp_build_context *uint_bld = &bld_base->uint_bld;
   struct lp_build_context *float_bld = &bld_base->base;
   LLVMValueRef res = NULL;
   LLVMValueRef indirect_index = NULL;
d692 9
a700 6
   if (reg->Register.Indirect) {
      indirect_index = get_indirect_index(bld,
                                          reg->Register.File,
                                          reg->Register.Index,
                                          &reg->Indirect);
   }
d702 4
a705 31
   if (reg->Register.Indirect) {
      LLVMValueRef swizzle_vec =
         lp_build_const_int_vec(bld->bld_base.base.gallivm,
                                uint_bld->type, swizzle);
      LLVMValueRef length_vec =
         lp_build_const_int_vec(bld->bld_base.base.gallivm, uint_bld->type,
                                bld->bld_base.base.type.length);
      LLVMValueRef index_vec;  /* index into the const buffer */
      LLVMValueRef imms_array;
      LLVMValueRef pixel_offsets;
      LLVMValueRef offsets[LP_MAX_VECTOR_LENGTH];
      LLVMTypeRef float4_ptr_type;
      int i;

      /* build pixel offset vector: {0, 1, 2, 3, ...} */
      for (i = 0; i < float_bld->type.length; i++) {
         offsets[i] = lp_build_const_int32(gallivm, i);
      }
      pixel_offsets = LLVMConstVector(offsets, float_bld->type.length);

      /* index_vec = (indirect_index * 4 + swizzle) * length */
      index_vec = lp_build_shl_imm(uint_bld, indirect_index, 2);
      index_vec = lp_build_add(uint_bld, index_vec, swizzle_vec);
      index_vec = lp_build_mul(uint_bld, index_vec, length_vec);
      index_vec = lp_build_add(uint_bld, index_vec, pixel_offsets);

      /* cast imms_array pointer to float* */
      float4_ptr_type = LLVMPointerType(
         LLVMFloatTypeInContext(bld->bld_base.base.gallivm->context), 0);
      imms_array = LLVMBuildBitCast(builder, bld->imms_array,
                                    float4_ptr_type, "");
d707 4
a710 6
      /* Gather values from the temporary register array */
      res = build_gather(&bld_base->base, imms_array, index_vec);
   }
   else {
      res = bld->immediates[reg->Register.Index][swizzle];
   }
d712 16
a727 7
   if (stype == TGSI_TYPE_UNSIGNED) {
      res = LLVMBuildBitCast(builder, res, bld_base->uint_bld.vec_type, "");
   } else if (stype == TGSI_TYPE_SIGNED) {
      res = LLVMBuildBitCast(builder, res, bld_base->int_bld.vec_type, "");
   }
   return res;
}
d729 10
a738 13
static LLVMValueRef
emit_fetch_input(
   struct lp_build_tgsi_context * bld_base,
   const struct tgsi_full_src_register * reg,
   enum tgsi_opcode_type stype,
   unsigned swizzle)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
   struct gallivm_state *gallivm = bld->bld_base.base.gallivm;
   LLVMBuilderRef builder = gallivm->builder;
   struct lp_build_context *uint_bld = &bld_base->uint_bld;
   LLVMValueRef indirect_index = NULL;
   LLVMValueRef res;
d740 4
a743 6
   if (reg->Register.Indirect) {
      indirect_index = get_indirect_index(bld,
                                          reg->Register.File,
                                          reg->Register.Index,
                                          &reg->Indirect);
   }
d745 4
a748 18
   if (reg->Register.Indirect) {
      LLVMValueRef swizzle_vec =
         lp_build_const_int_vec(gallivm, uint_bld->type, swizzle);
      LLVMValueRef length_vec =
         lp_build_const_int_vec(gallivm, uint_bld->type, bld->bld_base.base.type.length);
      LLVMValueRef index_vec;  /* index into the const buffer */
      LLVMValueRef inputs_array;
      LLVMTypeRef float4_ptr_type;

      /* index_vec = (indirect_index * 4 + swizzle) * length */
      index_vec = lp_build_shl_imm(uint_bld, indirect_index, 2);
      index_vec = lp_build_add(uint_bld, index_vec, swizzle_vec);
      index_vec = lp_build_mul(uint_bld, index_vec, length_vec);

      /* cast inputs_array pointer to float* */
      float4_ptr_type = LLVMPointerType(LLVMFloatTypeInContext(gallivm->context), 0);
      inputs_array = LLVMBuildBitCast(builder, bld->inputs_array,
                                         float4_ptr_type, "");
d750 2
a751 9
      /* Gather values from the temporary register array */
      res = build_gather(&bld_base->base, inputs_array, index_vec);
   } else {
      if (bld->indirect_files & (1 << TGSI_FILE_INPUT)) {
         LLVMValueRef lindex = lp_build_const_int32(gallivm,
                                        reg->Register.Index * 4 + swizzle);
         LLVMValueRef input_ptr =  LLVMBuildGEP(builder,
                                                bld->inputs_array, &lindex, 1, "");
         res = LLVMBuildLoad(builder, input_ptr, "");
d754 5
a758 1
         res = bld->inputs[reg->Register.Index][swizzle];
d760 5
d767 11
a777 1
   assert(res);
d779 2
a780 4
   if (stype == TGSI_TYPE_UNSIGNED) {
      res = LLVMBuildBitCast(builder, res, bld_base->uint_bld.vec_type, "");
   } else if (stype == TGSI_TYPE_SIGNED) {
      res = LLVMBuildBitCast(builder, res, bld_base->int_bld.vec_type, "");
d787 12
a798 6
static LLVMValueRef
emit_fetch_gs_input(
   struct lp_build_tgsi_context * bld_base,
   const struct tgsi_full_src_register * reg,
   enum tgsi_opcode_type stype,
   unsigned swizzle)
d800 1
a800 7
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
   struct gallivm_state *gallivm = bld->bld_base.base.gallivm;
   LLVMBuilderRef builder = gallivm->builder;
   LLVMValueRef attrib_index = NULL;
   LLVMValueRef vertex_index = NULL;
   LLVMValueRef swizzle_index = lp_build_const_int32(gallivm, swizzle);
   LLVMValueRef res;
d802 1
a802 154
   if (reg->Register.Indirect) {
      attrib_index = get_indirect_index(bld,
                                          reg->Register.File,
                                          reg->Register.Index,
                                          &reg->Indirect);
   } else {
      attrib_index = lp_build_const_int32(gallivm, reg->Register.Index);
   }
   
   if (reg->Dimension.Indirect) {
      vertex_index = get_indirect_index(bld,
                                        reg->Register.File,
                                        reg->Dimension.Index,
                                        &reg->DimIndirect);
   } else {
      vertex_index = lp_build_const_int32(gallivm, reg->Dimension.Index);
   }

   res = bld->gs_iface->fetch_input(bld->gs_iface, bld_base,
                                    reg->Dimension.Indirect,
                                    vertex_index, attrib_index,
                                    swizzle_index);

   assert(res);

   if (stype == TGSI_TYPE_UNSIGNED) {
      res = LLVMBuildBitCast(builder, res, bld_base->uint_bld.vec_type, "");
   } else if (stype == TGSI_TYPE_SIGNED) {
      res = LLVMBuildBitCast(builder, res, bld_base->int_bld.vec_type, "");
   }

   return res;
}

static LLVMValueRef
emit_fetch_temporary(
   struct lp_build_tgsi_context * bld_base,
   const struct tgsi_full_src_register * reg,
   enum tgsi_opcode_type stype,
   unsigned swizzle)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
   struct gallivm_state *gallivm = bld->bld_base.base.gallivm;
   LLVMBuilderRef builder = gallivm->builder;
   struct lp_build_context *uint_bld = &bld_base->uint_bld;
   struct lp_build_context *float_bld = &bld_base->base;
   LLVMValueRef indirect_index = NULL;
   LLVMValueRef res;

   if (reg->Register.Indirect) {
      indirect_index = get_indirect_index(bld,
                                          reg->Register.File,
                                          reg->Register.Index,
                                          &reg->Indirect);
   }

   if (reg->Register.Indirect) {
      LLVMValueRef swizzle_vec =
         lp_build_const_int_vec(bld->bld_base.base.gallivm, uint_bld->type, swizzle);
      LLVMValueRef length_vec =
         lp_build_const_int_vec(bld->bld_base.base.gallivm, uint_bld->type,
                                bld->bld_base.base.type.length);
      LLVMValueRef index_vec;  /* index into the const buffer */
      LLVMValueRef temps_array;
      LLVMValueRef pixel_offsets;
      LLVMValueRef offsets[LP_MAX_VECTOR_LENGTH];
      LLVMTypeRef float4_ptr_type;
      int i;

      /* build pixel offset vector: {0, 1, 2, 3, ...} */
      for (i = 0; i < float_bld->type.length; i++) {
         offsets[i] = lp_build_const_int32(gallivm, i);
      }
      pixel_offsets = LLVMConstVector(offsets, float_bld->type.length);

      /* index_vec = (indirect_index * 4 + swizzle) * length */
      index_vec = lp_build_shl_imm(uint_bld, indirect_index, 2);
      index_vec = lp_build_add(uint_bld, index_vec, swizzle_vec);
      index_vec = lp_build_mul(uint_bld, index_vec, length_vec);
      index_vec = lp_build_add(uint_bld, index_vec, pixel_offsets);

      /* cast temps_array pointer to float* */
      float4_ptr_type = LLVMPointerType(LLVMFloatTypeInContext(bld->bld_base.base.gallivm->context), 0);
      temps_array = LLVMBuildBitCast(builder, bld->temps_array,
                                     float4_ptr_type, "");

      /* Gather values from the temporary register array */
      res = build_gather(&bld_base->base, temps_array, index_vec);
   }
   else {
      LLVMValueRef temp_ptr;
      temp_ptr = lp_get_temp_ptr_soa(bld, reg->Register.Index, swizzle);
      res = LLVMBuildLoad(builder, temp_ptr, "");
   }

   if (stype == TGSI_TYPE_SIGNED || stype == TGSI_TYPE_UNSIGNED) {
      struct lp_build_context *bld_fetch = stype_to_fetch(bld_base, stype);
      res = LLVMBuildBitCast(builder, res, bld_fetch->vec_type, "");
   }

   return res;
}

static LLVMValueRef
emit_fetch_system_value(
   struct lp_build_tgsi_context * bld_base,
   const struct tgsi_full_src_register * reg,
   enum tgsi_opcode_type stype,
   unsigned swizzle)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
   struct gallivm_state *gallivm = bld->bld_base.base.gallivm;
   const struct tgsi_shader_info *info = bld->bld_base.info;
   LLVMBuilderRef builder = gallivm->builder;
   LLVMValueRef res;
   enum tgsi_opcode_type atype; // Actual type of the value

   assert(!reg->Register.Indirect);

   switch (info->system_value_semantic_name[reg->Register.Index]) {
   case TGSI_SEMANTIC_INSTANCEID:
      res = lp_build_broadcast_scalar(&bld_base->uint_bld, bld->system_values.instance_id);
      atype = TGSI_TYPE_UNSIGNED;
      break;

   case TGSI_SEMANTIC_VERTEXID:
      res = bld->system_values.vertex_id;
      atype = TGSI_TYPE_UNSIGNED;
      break;

   case TGSI_SEMANTIC_PRIMID:
      res = bld->system_values.prim_id;
      atype = TGSI_TYPE_UNSIGNED;
      break;

   default:
      assert(!"unexpected semantic in emit_fetch_system_value");
      res = bld_base->base.zero;
      atype = TGSI_TYPE_FLOAT;
      break;
   }

   if (atype != stype) {
      if (stype == TGSI_TYPE_FLOAT) {
         res = LLVMBuildBitCast(builder, res, bld_base->base.vec_type, "");
      } else if (stype == TGSI_TYPE_UNSIGNED) {
         res = LLVMBuildBitCast(builder, res, bld_base->uint_bld.vec_type, "");
      } else if (stype == TGSI_TYPE_SIGNED) {
         res = LLVMBuildBitCast(builder, res, bld_base->int_bld.vec_type, "");
      }
   }

   return res;
}
a803 11
/**
 * Register fetch with derivatives.
 */
static void
emit_fetch_deriv(
   struct lp_build_tgsi_soa_context *bld,
   LLVMValueRef src,
   LLVMValueRef *res,
   LLVMValueRef *ddx,
   LLVMValueRef *ddy)
{
d810 1
a810 1
      *ddx = lp_build_ddx(&bld->bld_base.base, src);
d813 1
a813 1
      *ddy = lp_build_ddy(&bld->bld_base.base, src);
d826 1
a826 1
   LLVMBuilderRef builder = bld->bld_base.base.gallivm->builder;
d834 1
a834 1
      TGSI_FOR_EACH_CHANNEL( chan ) {
d848 1
a848 1
   TGSI_FOR_EACH_CHANNEL( chan ) {
d866 2
a867 2
         value = lp_build_compare(bld->bld_base.base.gallivm,
                                  bld->bld_base.base.type,
d870 1
a870 1
                                  bld->bld_base.base.zero);
d884 1
d889 2
a890 2
emit_store_chan(
   struct lp_build_tgsi_context *bld_base,
d897 1
a897 2
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
   struct gallivm_state *gallivm = bld_base->base.gallivm;
d900 1
a900 3
   struct lp_build_context *float_bld = &bld_base->base;
   struct lp_build_context *int_bld = &bld_base->int_bld;
   struct lp_build_context *uint_bld = &bld_base->uint_bld;
a901 1
   enum tgsi_opcode_type dtype = tgsi_opcode_infer_dst_type(inst->Instruction.Opcode);
a902 5
   /*
    * Apply saturation.
    *
    * It is always assumed to be float.
    */
d908 2
a909 5
      assert(dtype == TGSI_TYPE_FLOAT ||
             dtype == TGSI_TYPE_UNTYPED);
      value = LLVMBuildBitCast(builder, value, float_bld->vec_type, "");
      value = lp_build_max(float_bld, value, float_bld->zero);
      value = lp_build_min(float_bld, value, float_bld->one);
d913 2
a914 5
      assert(dtype == TGSI_TYPE_FLOAT ||
             dtype == TGSI_TYPE_UNTYPED);
      value = LLVMBuildBitCast(builder, value, float_bld->vec_type, "");
      value = lp_build_max(float_bld, value, lp_build_const_vec(gallivm, float_bld->type, -1.0));
      value = lp_build_min(float_bld, value, float_bld->one);
d927 1
a927 2
      assert(reg->Register.Index <=
                             bld_base->info->file_max[reg->Register.File]);
a931 3
      /* Outputs are always stored as floats */
      value = LLVMBuildBitCast(builder, value, float_bld->vec_type, "");

d936 1
a936 1
            lp_build_const_int_vec(gallivm, uint_bld->type, float_bld->type.length);
d945 1
a945 1
         for (i = 0; i < float_bld->type.length; i++) {
d967 3
a969 3
         LLVMValueRef out_ptr = lp_get_output_ptr(bld, reg->Register.Index,
                                                  chan_index);
         lp_exec_mask_store(&bld->exec_mask, float_bld, pred, value, out_ptr);
a973 3
      /* Temporaries are always stored as floats */
      value = LLVMBuildBitCast(builder, value, float_bld->vec_type, "");

d979 1
a979 1
                                   float_bld->type.length);
d988 1
a988 1
         for (i = 0; i < float_bld->type.length; i++) {
d1010 3
a1012 4
         LLVMValueRef temp_ptr;
         temp_ptr = lp_get_temp_ptr_soa(bld, reg->Register.Index,
                                        chan_index);
         lp_exec_mask_store(&bld->exec_mask, float_bld, pred, value, temp_ptr);
d1017 1
a1017 4
      assert(dtype == TGSI_TYPE_SIGNED);
      assert(LLVMTypeOf(value) == int_bld->vec_type);
      value = LLVMBuildBitCast(builder, value, int_bld->vec_type, "");
      lp_exec_mask_store(&bld->exec_mask, int_bld, pred, value,
d1022 1
a1022 3
      assert(LLVMTypeOf(value) == float_bld->vec_type);
      value = LLVMBuildBitCast(builder, value, float_bld->vec_type, "");
      lp_exec_mask_store(&bld->exec_mask, float_bld, pred, value,
a1028 2

   (void)dtype;
a1030 21
static void
emit_store(
   struct lp_build_tgsi_context * bld_base,
   const struct tgsi_full_instruction * inst,
   const struct tgsi_opcode_info * info,
   LLVMValueRef dst[4])

{
   unsigned chan_index;
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);

   if(info->num_dst) {
      LLVMValueRef pred[TGSI_NUM_CHANNELS];

      emit_fetch_predicate( bld, inst, pred );

      TGSI_FOR_EACH_DST0_ENABLED_CHANNEL( inst, chan_index ) {
         emit_store_chan(bld_base, inst, 0, chan_index, pred[chan_index], dst[chan_index]);
      }
   }
}
d1042 1
d1046 4
a1049 6
   LLVMValueRef coords[4];
   LLVMValueRef offsets[3] = { NULL };
   struct lp_derivatives derivs;
   struct lp_derivatives *deriv_ptr = NULL;
   boolean scalar_lod;
   unsigned num_coords, num_derivs, num_offsets;
d1055 1
a1055 1
         texel[i] = bld->bld_base.base.undef;
a1062 7
      num_offsets = 1;
      num_derivs = 1;
      break;
   case TGSI_TEXTURE_1D_ARRAY:
      num_coords = 2;
      num_offsets = 1;
      num_derivs = 1;
a1066 2
      num_offsets = 2;
      num_derivs = 2;
a1068 5
   case TGSI_TEXTURE_SHADOW1D_ARRAY:
      num_coords = 3;
      num_offsets = 1;
      num_derivs = 1;
      break;
d1071 1
a1071 5
   case TGSI_TEXTURE_2D_ARRAY:
      num_coords = 3;
      num_offsets = 2;
      num_derivs = 2;
      break;
a1073 17
      num_offsets = 2;
      num_derivs = 3;
      break;
   case TGSI_TEXTURE_3D:
      num_coords = 3;
      num_offsets = 3;
      num_derivs = 3;
      break;
   case TGSI_TEXTURE_SHADOW2D_ARRAY:
      num_coords = 4;
      num_offsets = 2;
      num_derivs = 2;
      break;
   case TGSI_TEXTURE_SHADOWCUBE:
      num_coords = 4;
      num_offsets = 2;
      num_derivs = 3;
a1079 1
   /* Note lod and especially projected are illegal in a LOT of cases */
d1081 1
a1081 2
      assert(num_coords < 4);
      lod_bias = lp_build_emit_fetch( &bld->bld_base, inst, 0, 3 );
a1084 1
      assert(num_coords < 4);
d1086 1
a1086 1
      explicit_lod = lp_build_emit_fetch( &bld->bld_base, inst, 0, 3 );
d1094 2
a1095 3
      assert(num_coords < 4);
      oow = lp_build_emit_fetch( &bld->bld_base, inst, 0, 3 );
      oow = lp_build_rcp(&bld->bld_base.base, oow);
d1099 1
a1099 1
      coords[i] = lp_build_emit_fetch( &bld->bld_base, inst, 0, i );
d1101 1
a1101 1
         coords[i] = lp_build_mul(&bld->bld_base.base, coords[i], oow);
d1103 2
a1104 2
   for (i = num_coords; i < 4; i++) {
      coords[i] = bld->bld_base.base.undef;
d1108 6
a1113 4
      unsigned dim;
      for (dim = 0; dim < num_derivs; ++dim) {
         derivs.ddx[dim] = lp_build_emit_fetch( &bld->bld_base, inst, 1, dim );
         derivs.ddy[dim] = lp_build_emit_fetch( &bld->bld_base, inst, 2, dim );
a1114 1
      deriv_ptr = &derivs;
d1116 5
a1120 1
   } else {
d1123 3
a1125 7

   /* some advanced gather instructions (txgo) would require 4 offsets */
   if (inst->Texture.NumOffsets == 1) {
      unsigned dim;
      for (dim = 0; dim < num_offsets; dim++) {
         offsets[dim] = lp_build_emit_fetch_texoffset(&bld->bld_base, inst, 0, dim );
      }
a1127 3
   /* TODO: use scalar lod if explicit_lod, lod_bias or derivs are broadcasted scalars */
   scalar_lod = bld->bld_base.info->processor == TGSI_PROCESSOR_FRAGMENT;

d1129 5
a1133 8
                                  bld->bld_base.base.gallivm,
                                  bld->bld_base.base.type,
                                  FALSE,
                                  unit, unit,
                                  coords,
                                  offsets,
                                  deriv_ptr,
                                  lod_bias, explicit_lod, scalar_lod,
d1137 3
a1139 6
static void
emit_sample(struct lp_build_tgsi_soa_context *bld,
            const struct tgsi_full_instruction *inst,
            enum lp_build_tex_modifier modifier,
            boolean compare,
            LLVMValueRef *texel)
d1141 1
a1141 10
   struct gallivm_state *gallivm = bld->bld_base.base.gallivm;
   unsigned texture_unit, sampler_unit;
   LLVMValueRef lod_bias, explicit_lod;
   LLVMValueRef coords[4];
   LLVMValueRef offsets[3] = { NULL };
   struct lp_derivatives derivs;
   struct lp_derivatives *deriv_ptr = NULL;
   boolean scalar_lod;
   unsigned num_coords, num_offsets, num_derivs;
   unsigned i;
d1143 2
a1144 7
   if (!bld->sampler) {
      _debug_printf("warning: found texture instruction but no sampler generator supplied\n");
      for (i = 0; i < 4; i++) {
         texel[i] = bld->bld_base.base.undef;
      }
      return;
   }
d1146 2
a1147 6
   /*
    * unlike old-style tex opcodes the texture/sampler indices
    * always come from src1 and src2 respectively.
    */
   texture_unit = inst->Src[1].Register.Index;
   sampler_unit = inst->Src[2].Register.Index;
d1149 1
a1149 46
   /*
    * Note inst->Texture.Texture will contain the number of offsets,
    * however the target information is NOT there and comes from the
    * declared sampler views instead.
    */
   switch (bld->sv[texture_unit].Resource) {
   case TGSI_TEXTURE_1D:
      num_coords = 1;
      num_offsets = 1;
      num_derivs = 1;
      break;
   case TGSI_TEXTURE_1D_ARRAY:
      num_coords = 2;
      num_offsets = 1;
      num_derivs = 1;
      break;
   case TGSI_TEXTURE_2D:
   case TGSI_TEXTURE_RECT:
      num_coords = 2;
      num_offsets = 2;
      num_derivs = 2;
      break;
   case TGSI_TEXTURE_2D_ARRAY:
      num_coords = 3;
      num_offsets = 2;
      num_derivs = 2;
      break;
   case TGSI_TEXTURE_CUBE:
      num_coords = 3;
      num_offsets = 2;
      num_derivs = 3;
      break;
   case TGSI_TEXTURE_3D:
      num_coords = 3;
      num_offsets = 3;
      num_derivs = 3;
      break;
   case TGSI_TEXTURE_CUBE_ARRAY:
      num_coords = 4;
      num_offsets = 2;
      num_derivs = 3;
      break;
   default:
      assert(0);
      return;
   }
d1151 2
a1152 17
   if (modifier == LP_BLD_TEX_MODIFIER_LOD_BIAS) {
      lod_bias = lp_build_emit_fetch( &bld->bld_base, inst, 3, 0 );
      explicit_lod = NULL;
   }
   else if (modifier == LP_BLD_TEX_MODIFIER_EXPLICIT_LOD) {
      lod_bias = NULL;
      explicit_lod = lp_build_emit_fetch( &bld->bld_base, inst, 3, 0 );
   }
   else if (modifier == LP_BLD_TEX_MODIFIER_LOD_ZERO) {
      lod_bias = NULL;
      /* XXX might be better to explicitly pass the level zero information */
      explicit_lod = lp_build_const_vec(gallivm, bld->bld_base.base.type, 0.0F);
   }
   else {
      lod_bias = NULL;
      explicit_lod = NULL;
   }
d1154 14
a1167 15
   for (i = 0; i < num_coords; i++) {
      coords[i] = lp_build_emit_fetch( &bld->bld_base, inst, 0, i );
   }
   for (i = num_coords; i < 4; i++) {
      coords[i] = bld->bld_base.base.undef;
   }
   /*
    * XXX: whack shadow comparison value into place.
    * Should probably fix the interface for separate value
    * (it will not work for cube arrays if it is part of coords).
    */
   if (compare) {
      unsigned c_coord = num_coords > 2 ? 3 : 2;
      assert(num_coords < 4);
      coords[c_coord] = lp_build_emit_fetch( &bld->bld_base, inst, 3, 0 );
d1170 2
a1171 8
   if (modifier == LP_BLD_TEX_MODIFIER_EXPLICIT_DERIV) {
      unsigned dim;
      for (dim = 0; dim < num_derivs; ++dim) {
         derivs.ddx[dim] = lp_build_emit_fetch( &bld->bld_base, inst, 3, dim );
         derivs.ddy[dim] = lp_build_emit_fetch( &bld->bld_base, inst, 4, dim );
      }
      deriv_ptr = &derivs;
   }
a1172 7
   /* some advanced gather instructions (txgo) would require 4 offsets */
   if (inst->Texture.NumOffsets == 1) {
      unsigned dim;
      for (dim = 0; dim < num_offsets; dim++) {
         offsets[dim] = lp_build_emit_fetch_texoffset(&bld->bld_base, inst, 0, dim );
      }
   }
a1173 14
   /* TODO: use scalar lod if explicit_lod, lod_bias or derivs are broadcasted scalars */
   scalar_lod = bld->bld_base.info->processor == TGSI_PROCESSOR_FRAGMENT;

   bld->sampler->emit_fetch_texel(bld->sampler,
                                  bld->bld_base.base.gallivm,
                                  bld->bld_base.base.type,
                                  FALSE,
                                  texture_unit, sampler_unit,
                                  coords,
                                  offsets,
                                  deriv_ptr,
                                  lod_bias, explicit_lod, scalar_lod,
                                  texel);
}
d1175 3
d1179 10
a1188 14
emit_fetch_texels( struct lp_build_tgsi_soa_context *bld,
                   const struct tgsi_full_instruction *inst,
                   LLVMValueRef *texel,
                   boolean is_samplei)
{
   unsigned unit, target;
   LLVMValueRef coord_undef = LLVMGetUndef(bld->bld_base.base.int_vec_type);
   LLVMValueRef explicit_lod = NULL;
   LLVMValueRef coords[3];
   LLVMValueRef offsets[3] = { NULL };
   boolean scalar_lod;
   unsigned num_coords;
   unsigned dims;
   unsigned i;
d1190 1
a1190 7
   if (!bld->sampler) {
      _debug_printf("warning: found texture instruction but no sampler generator supplied\n");
      for (i = 0; i < 4; i++) {
         texel[i] = coord_undef;
      }
      return;
   }
d1192 2
a1193 1
   unit = inst->Src[1].Register.Index;
d1195 2
a1196 6
   if (is_samplei) {
      target = bld->sv[unit].Resource;
   }
   else {
      target = inst->Texture.Texture;
   }
d1198 5
a1202 26
   switch (target) {
   case TGSI_TEXTURE_1D:
   case TGSI_TEXTURE_BUFFER:
      num_coords = 1;
      dims = 1;
      break;
   case TGSI_TEXTURE_1D_ARRAY:
      num_coords = 2;
      dims = 1;
      break;
   case TGSI_TEXTURE_2D:
   case TGSI_TEXTURE_RECT:
      num_coords = 2;
      dims = 2;
      break;
   case TGSI_TEXTURE_2D_ARRAY:
      num_coords = 3;
      dims = 2;
      break;
   case TGSI_TEXTURE_3D:
      num_coords = 3;
      dims = 3;
      break;
   default:
      assert(0);
      return;
d1205 4
a1208 4
   /* always have lod except for buffers ? */
   if (target != TGSI_TEXTURE_BUFFER) {
      explicit_lod = lp_build_emit_fetch( &bld->bld_base, inst, 0, 3 );
   }
d1210 4
a1213 156
   for (i = 0; i < num_coords; i++) {
      coords[i] = lp_build_emit_fetch( &bld->bld_base, inst, 0, i );
   }
   for (i = num_coords; i < 3; i++) {
      coords[i] = coord_undef;
   }

   if (inst->Texture.NumOffsets == 1) {
      unsigned dim;
      for (dim = 0; dim < dims; dim++) {
         offsets[dim] = lp_build_emit_fetch_texoffset(&bld->bld_base, inst, 0, dim );
      }
   }

   /* TODO: use scalar lod if explicit_lod is broadcasted scalar */
   scalar_lod = bld->bld_base.info->processor == TGSI_PROCESSOR_FRAGMENT;

   bld->sampler->emit_fetch_texel(bld->sampler,
                                  bld->bld_base.base.gallivm,
                                  bld->bld_base.base.type,
                                  TRUE,
                                  unit, unit,
                                  coords,
                                  offsets,
                                  NULL,
                                  NULL, explicit_lod, scalar_lod,
                                  texel);
}

static void
emit_size_query( struct lp_build_tgsi_soa_context *bld,
                 const struct tgsi_full_instruction *inst,
                 LLVMValueRef *sizes_out,
                 boolean is_sviewinfo)
{
   LLVMValueRef explicit_lod;
   unsigned has_lod;
   unsigned i;
   unsigned unit = inst->Src[1].Register.Index;
   unsigned target;

   if (is_sviewinfo) {
      target = bld->sv[unit].Resource;
   }
   else {
      target = inst->Texture.Texture;
   }
   switch (target) {
   case TGSI_TEXTURE_BUFFER:
   case TGSI_TEXTURE_RECT:
   case TGSI_TEXTURE_SHADOWRECT:
      has_lod = 0;
      break;
   default:
      has_lod = 1;
      break;
   }

   if (!bld->sampler) {
      _debug_printf("warning: found texture query instruction but no sampler generator supplied\n");
      for (i = 0; i < 4; i++)
         sizes_out[i] = bld->bld_base.int_bld.undef;
      return;
   }

   if (has_lod)
      explicit_lod = lp_build_emit_fetch( &bld->bld_base, inst, 0, 0 );
   else
      explicit_lod = NULL;

   bld->sampler->emit_size_query(bld->sampler,
                                 bld->bld_base.base.gallivm,
                                 bld->bld_base.int_bld.type,
                                 unit,
                                 is_sviewinfo,
                                 explicit_lod,
                                 sizes_out);
}

static boolean
near_end_of_shader(struct lp_build_tgsi_soa_context *bld,
		   int pc)
{
   int i;

   for (i = 0; i < 5; i++) {
      unsigned opcode;

      if (pc + i >= bld->bld_base.info->num_instructions)
	 return TRUE;

      opcode = bld->bld_base.instructions[pc + i].Instruction.Opcode;

      if (opcode == TGSI_OPCODE_END)
	 return TRUE;

      if (opcode == TGSI_OPCODE_TEX ||
	  opcode == TGSI_OPCODE_TXP ||
	  opcode == TGSI_OPCODE_TXD ||
	  opcode == TGSI_OPCODE_TXB ||
	  opcode == TGSI_OPCODE_TXL ||
	  opcode == TGSI_OPCODE_TXF ||
	  opcode == TGSI_OPCODE_TXQ ||
	  opcode == TGSI_OPCODE_CAL ||
	  opcode == TGSI_OPCODE_CALLNZ ||
	  opcode == TGSI_OPCODE_IF ||
          opcode == TGSI_OPCODE_UIF ||
	  opcode == TGSI_OPCODE_BGNLOOP ||
	  opcode == TGSI_OPCODE_SWITCH)
	 return FALSE;
   }

   return TRUE;
}



/**
 * Kill fragment if any of the src register values are negative.
 */
static void
emit_kill_if(
   struct lp_build_tgsi_soa_context *bld,
   const struct tgsi_full_instruction *inst,
   int pc)
{
   LLVMBuilderRef builder = bld->bld_base.base.gallivm->builder;
   const struct tgsi_full_src_register *reg = &inst->Src[0];
   LLVMValueRef terms[TGSI_NUM_CHANNELS];
   LLVMValueRef mask;
   unsigned chan_index;

   memset(&terms, 0, sizeof terms);

   TGSI_FOR_EACH_CHANNEL( chan_index ) {
      unsigned swizzle;

      /* Unswizzle channel */
      swizzle = tgsi_util_get_full_src_register_swizzle( reg, chan_index );

      /* Check if the component has not been already tested. */
      assert(swizzle < TGSI_NUM_CHANNELS);
      if( !terms[swizzle] )
         /* TODO: change the comparison operator instead of setting the sign */
         terms[swizzle] =  lp_build_emit_fetch(&bld->bld_base, inst, 0, chan_index );
   }

   mask = NULL;
   TGSI_FOR_EACH_CHANNEL( chan_index ) {
      if(terms[chan_index]) {
         LLVMValueRef chan_mask;

         /*
          * If term < 0 then mask = 0 else mask = ~0.
          */
         chan_mask = lp_build_cmp(&bld->bld_base.base, PIPE_FUNC_GEQUAL, terms[chan_index], bld->bld_base.base.zero);
d1232 2
a1233 1
 * Unconditional fragment kill.
d1238 3
a1240 2
emit_kill(struct lp_build_tgsi_soa_context *bld,
          int pc)
d1242 1
a1242 1
   LLVMBuilderRef builder = bld->bld_base.base.gallivm->builder;
d1252 1
a1252 1
      LLVMValueRef zero = LLVMConstNull(bld->bld_base.base.int_vec_type);
d1270 1
a1270 1
   struct gallivm_state *gallivm = bld->bld_base.base.gallivm;
d1278 1
a1278 1
   int n = bld->bld_base.info->file_max[TGSI_FILE_TEMPORARY];
d1288 1
a1288 1
         temp_ptr = lp_get_temp_ptr_soa(bld, index, chan);
d1309 3
a1311 3
void
lp_emit_declaration_soa(
   struct lp_build_tgsi_context *bld_base,
d1314 2
a1315 3
   struct lp_build_tgsi_soa_context *bld = lp_soa_context(bld_base);
   struct gallivm_state *gallivm = bld->bld_base.base.gallivm;
   LLVMTypeRef vec_type = bld->bld_base.base.vec_type;
d1321 1
a1321 1
      assert(last <= bld->bld_base.info->file_max[decl->Declaration.File]);
d1326 1
a1326 1
            for (i = 0; i < TGSI_NUM_CHANNELS; i++)
d1333 1
a1333 1
            for (i = 0; i < TGSI_NUM_CHANNELS; i++)
a1339 5
	 /* ADDR registers are only allocated with an integer LLVM IR type,
	  * as they are guaranteed to always have integers.
	  * XXX: Not sure if this exception is worthwhile (or the whole idea of
	  * an ADDR register for that matter).
	  */
d1341 2
a1342 2
         for (i = 0; i < TGSI_NUM_CHANNELS; i++)
            bld->addr[idx][i] = lp_build_alloca(gallivm, bld_base->base.int_vec_type, "addr");
d1347 1
a1347 1
         for (i = 0; i < TGSI_NUM_CHANNELS; i++)
a1351 9
      case TGSI_FILE_SAMPLER_VIEW:
         /*
          * The target stored here MUST match whatever there actually
          * is in the set sampler views (what about return type?).
          */
         assert(idx < PIPE_MAX_SHADER_SAMPLER_VIEWS);
         bld->sv[idx] = decl->SamplerView;
         break;

d1360 10
a1369 3
void lp_emit_immediate_soa(
   struct lp_build_tgsi_context *bld_base,
   const struct tgsi_full_immediate *imm)
d1371 21
a1391 2
   struct lp_build_tgsi_soa_context *bld = lp_soa_context(bld_base);
   struct gallivm_state * gallivm = bld_base->base.gallivm;
d1393 1
a1393 10
   /* simply copy the immediate values into the next immediates[] slot */
   unsigned i;
   const uint size = imm->Immediate.NrTokens - 1;
   assert(size <= 4);
   assert(bld->num_immediates < LP_MAX_TGSI_IMMEDIATES);
   switch (imm->Immediate.DataType) {
   case TGSI_IMM_FLOAT32:
      for( i = 0; i < size; ++i )
         bld->immediates[bld->num_immediates][i] =
            lp_build_const_vec(gallivm, bld_base->base.type, imm->u[i].Float);
d1395 4
a1398 6
      break;
   case TGSI_IMM_UINT32:
      for( i = 0; i < size; ++i ) {
         LLVMValueRef tmp = lp_build_const_vec(gallivm, bld_base->uint_bld.type, imm->u[i].Uint);
         bld->immediates[bld->num_immediates][i] =
            LLVMConstBitCast(tmp, bld_base->base.vec_type);
d1400 1
d1402 7
d1410 4
a1413 5
   case TGSI_IMM_INT32:
      for( i = 0; i < size; ++i ) {
         LLVMValueRef tmp = lp_build_const_vec(gallivm, bld_base->int_bld.type, imm->u[i].Int);
         bld->immediates[bld->num_immediates][i] =
            LLVMConstBitCast(tmp, bld_base->base.vec_type);
a1414 1
            
a1415 3
   }
   for( i = size; i < 4; ++i )
      bld->immediates[bld->num_immediates][i] = bld_base->base.undef;
d1417 19
a1435 12
   if (bld->indirect_files & (1 << TGSI_FILE_IMMEDIATE)) {
      unsigned index = bld->num_immediates;
      struct gallivm_state *gallivm = bld->bld_base.base.gallivm;
      LLVMBuilderRef builder = gallivm->builder;
      for (i = 0; i < 4; ++i ) {
         LLVMValueRef lindex = lp_build_const_int32(
            bld->bld_base.base.gallivm, index * 4 + i);
         LLVMValueRef imm_ptr = LLVMBuildGEP(builder,
                                             bld->imms_array, &lindex, 1, "");
         LLVMBuildStore(builder, 
                        bld->immediates[index][i],
                        imm_ptr);
d1437 4
a1440 1
   }
d1442 8
a1449 2
   bld->num_immediates++;
}
d1451 9
a1459 7
static void
ddx_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
d1461 7
a1467 3
   emit_fetch_deriv(bld, emit_data->args[0], NULL,
                    &emit_data->output[emit_data->chan], NULL);
}
d1469 1
a1469 7
static void
ddy_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
d1471 6
a1476 3
   emit_fetch_deriv(bld, emit_data->args[0], NULL, NULL,
                    &emit_data->output[emit_data->chan]);
}
d1478 1
a1478 7
static void
kill_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
d1480 12
a1491 2
   emit_kill(bld, bld_base->pc - 1);
}
d1493 7
a1499 7
static void
kill_if_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
d1501 2
a1502 2
   emit_kill_if(bld, emit_data->inst, bld_base->pc - 1);
}
d1504 6
a1509 7
static void
tex_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
d1511 1
a1511 2
   emit_tex(bld, emit_data->inst, LP_BLD_TEX_MODIFIER_NONE, emit_data->output);
}
d1513 16
a1528 7
static void
txb_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
d1530 7
a1536 3
   emit_tex(bld, emit_data->inst, LP_BLD_TEX_MODIFIER_LOD_BIAS,
            emit_data->output);
}
d1538 7
a1544 7
static void
txd_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
d1546 17
a1562 3
   emit_tex(bld, emit_data->inst, LP_BLD_TEX_MODIFIER_EXPLICIT_DERIV,
            emit_data->output);
}
d1564 21
a1584 7
static void
txl_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
d1586 16
a1601 3
   emit_tex(bld, emit_data->inst, LP_BLD_TEX_MODIFIER_EXPLICIT_LOD,
            emit_data->output);
}
d1603 7
a1609 7
static void
txp_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
d1611 7
a1617 3
   emit_tex(bld, emit_data->inst, LP_BLD_TEX_MODIFIER_PROJECTED,
            emit_data->output);
}
d1619 9
a1627 7
static void
txq_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
d1629 9
a1637 2
   emit_size_query(bld, emit_data->inst, emit_data->output, FALSE);
}
d1639 11
a1649 7
static void
txf_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
d1651 7
a1657 2
   emit_fetch_texels(bld, emit_data->inst, emit_data->output, FALSE);
}
d1659 10
a1668 7
static void
sample_i_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
d1670 10
a1679 2
   emit_fetch_texels(bld, emit_data->inst, emit_data->output, TRUE);
}
d1681 14
a1694 7
static void
sample_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
d1696 8
a1703 3
   emit_sample(bld, emit_data->inst, LP_BLD_TEX_MODIFIER_NONE,
               FALSE, emit_data->output);
}
d1705 10
a1714 7
static void
sample_b_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
d1716 6
a1721 3
   emit_sample(bld, emit_data->inst, LP_BLD_TEX_MODIFIER_LOD_BIAS,
               FALSE, emit_data->output);
}
d1723 6
a1728 7
static void
sample_c_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
d1730 8
a1737 3
   emit_sample(bld, emit_data->inst, LP_BLD_TEX_MODIFIER_NONE,
               TRUE, emit_data->output);
}
d1739 7
a1745 7
static void
sample_c_lz_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
d1747 8
a1754 3
   emit_sample(bld, emit_data->inst, LP_BLD_TEX_MODIFIER_LOD_ZERO,
               TRUE, emit_data->output);
}
d1756 40
a1795 7
static void
sample_d_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
d1797 6
a1802 3
   emit_sample(bld, emit_data->inst, LP_BLD_TEX_MODIFIER_EXPLICIT_DERIV,
               FALSE, emit_data->output);
}
d1804 4
a1807 7
static void
sample_l_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
d1809 18
a1826 3
   emit_sample(bld, emit_data->inst, LP_BLD_TEX_MODIFIER_EXPLICIT_LOD,
               FALSE, emit_data->output);
}
d1828 13
a1840 7
static void
sviewinfo_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
d1842 5
a1846 2
   emit_size_query(bld, emit_data->inst, emit_data->output, TRUE);
}
d1848 4
a1851 15
static LLVMValueRef
mask_to_one_vec(struct lp_build_tgsi_context *bld_base)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
   LLVMBuilderRef builder = bld->bld_base.base.gallivm->builder;
   LLVMValueRef one_vec = bld_base->int_bld.one;
   struct lp_exec_mask *exec_mask = &bld->exec_mask;

   if (exec_mask->has_mask) {
      one_vec = LLVMBuildAnd(builder, one_vec, exec_mask->exec_mask, "");
   }
   one_vec = LLVMBuildAnd(builder, one_vec,
                          lp_build_mask_value(bld->mask), "");
   return one_vec;
}
d1853 4
a1856 6
static void
increment_vec_ptr_by_mask(struct lp_build_tgsi_context * bld_base,
                          LLVMValueRef ptr,
                          LLVMValueRef mask)
{
   LLVMBuilderRef builder = bld_base->base.gallivm->builder;
d1858 3
a1860 6
   LLVMValueRef current_vec = LLVMBuildLoad(builder, ptr, "");
   
   current_vec = LLVMBuildAdd(builder, current_vec, mask, "");
   
   LLVMBuildStore(builder, current_vec, ptr);
}
d1862 3
a1864 20
static void
clear_uint_vec_ptr_from_mask(struct lp_build_tgsi_context * bld_base,
                             LLVMValueRef ptr,
                             LLVMValueRef mask)
{
   LLVMBuilderRef builder = bld_base->base.gallivm->builder;

   LLVMValueRef current_vec = LLVMBuildLoad(builder, ptr, "");
   LLVMValueRef full_mask = lp_build_cmp(&bld_base->uint_bld,
                                         PIPE_FUNC_NOTEQUAL,
                                         mask,
                                         bld_base->uint_bld.zero);

   current_vec = lp_build_select(&bld_base->uint_bld,
                                 full_mask,
                                 bld_base->uint_bld.zero,
                                 current_vec);
   
   LLVMBuildStore(builder, current_vec, ptr);
}
d1866 3
a1868 10
static LLVMValueRef
clamp_mask_to_max_output_vertices(struct lp_build_tgsi_soa_context * bld,
                                  LLVMValueRef current_mask_vec,
                                  LLVMValueRef total_emitted_vertices_vec)
{
   LLVMBuilderRef builder = bld->bld_base.base.gallivm->builder;
   struct lp_build_context *uint_bld = &bld->bld_base.uint_bld;
   LLVMValueRef max_mask = lp_build_cmp(uint_bld, PIPE_FUNC_LESS,
                                        total_emitted_vertices_vec,
                                        bld->max_output_vertices_vec);
d1870 3
a1872 2
   return LLVMBuildAnd(builder, current_mask_vec, max_mask, "");
}
d1874 3
a1876 33
static void
emit_vertex(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
   LLVMBuilderRef builder = bld->bld_base.base.gallivm->builder;

   if (bld->gs_iface->emit_vertex) {
      LLVMValueRef masked_ones = mask_to_one_vec(bld_base);
      LLVMValueRef total_emitted_vertices_vec =
         LLVMBuildLoad(builder, bld->total_emitted_vertices_vec_ptr, "");
      masked_ones = clamp_mask_to_max_output_vertices(bld, masked_ones,
                                                      total_emitted_vertices_vec);
      gather_outputs(bld);
      bld->gs_iface->emit_vertex(bld->gs_iface, &bld->bld_base,
                                 bld->outputs,
                                 total_emitted_vertices_vec);
      increment_vec_ptr_by_mask(bld_base, bld->emitted_vertices_vec_ptr,
                                masked_ones);
      increment_vec_ptr_by_mask(bld_base, bld->total_emitted_vertices_vec_ptr,
                                masked_ones);
#if DUMP_GS_EMITS
      lp_build_print_value(bld->bld_base.base.gallivm,
                           " +++ emit vertex masked ones = ",
                           masked_ones);
      lp_build_print_value(bld->bld_base.base.gallivm,
                           " +++ emit vertex emitted = ",
                           total_emitted_vertices_vec);
#endif
   }
}
d1878 8
d1887 5
a1891 6
static void
end_primitive_masked(struct lp_build_tgsi_context * bld_base,
                     LLVMValueRef masked_ones)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
   LLVMBuilderRef builder = bld->bld_base.base.gallivm->builder;
d1893 8
a1900 33
   if (bld->gs_iface->end_primitive) {
      LLVMValueRef emitted_vertices_vec =
         LLVMBuildLoad(builder, bld->emitted_vertices_vec_ptr, "");
      LLVMValueRef emitted_prims_vec =
         LLVMBuildLoad(builder, bld->emitted_prims_vec_ptr, "");
      
      bld->gs_iface->end_primitive(bld->gs_iface, &bld->bld_base,
                                   emitted_vertices_vec,
                                   emitted_prims_vec);

#if DUMP_GS_EMITS
      lp_build_print_value(bld->bld_base.base.gallivm,
                           " +++ end prim masked ones = ",
                           masked_ones);
      lp_build_print_value(bld->bld_base.base.gallivm,
                           " +++ end prim emitted verts1 = ",
                           emitted_vertices_vec);
      lp_build_print_value(bld->bld_base.base.gallivm,
                           " +++ end prim emitted prims1 = ",
                           LLVMBuildLoad(builder,
                                         bld->emitted_prims_vec_ptr, ""));
#endif
      increment_vec_ptr_by_mask(bld_base, bld->emitted_prims_vec_ptr,
                                masked_ones);
      clear_uint_vec_ptr_from_mask(bld_base, bld->emitted_vertices_vec_ptr,
                                   masked_ones);
#if DUMP_GS_EMITS
      lp_build_print_value(bld->bld_base.base.gallivm,
                           " +++ end prim emitted verts2 = ",
                           LLVMBuildLoad(builder,
                                         bld->emitted_vertices_vec_ptr, ""));
#endif
   }
d1902 7
a1908 1
}
d1910 8
a1917 26
static void
end_primitive(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);

   if (bld->gs_iface->end_primitive) {
      LLVMBuilderRef builder = bld_base->base.gallivm->builder;
      LLVMValueRef masked_ones = mask_to_one_vec(bld_base);
      struct lp_build_context *uint_bld = &bld_base->uint_bld;
      LLVMValueRef emitted_verts = LLVMBuildLoad(
         builder, bld->emitted_vertices_vec_ptr, "");
      LLVMValueRef emitted_mask = lp_build_cmp(uint_bld, PIPE_FUNC_NOTEQUAL,
                                               emitted_verts,
                                               uint_bld->zero);
      /* We need to combine the current execution mask with the mask
         telling us which, if any, execution slots actually have
         unemitted primitives, this way we make sure that end_primitives
         executes only on the paths that have unflushed vertices */
      masked_ones = LLVMBuildAnd(builder, masked_ones, emitted_mask, "");
      
      end_primitive_masked(bld_base, masked_ones);
   }
}
d1919 8
a1926 7
static void
cal_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
d1928 5
a1932 3
   lp_exec_mask_call(&bld->exec_mask, emit_data->inst->Label.Label,
                     &bld_base->pc);
}
d1934 3
a1936 7
static void
ret_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
d1938 3
a1940 2
   lp_exec_mask_ret(&bld->exec_mask, &bld_base->pc);
}
d1942 5
a1946 7
static void
brk_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
d1948 5
a1952 2
   lp_exec_break(&bld->exec_mask, bld_base);
}
d1954 5
a1958 14
static void
breakc_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
   LLVMBuilderRef builder = bld_base->base.gallivm->builder;
   struct lp_build_context *uint_bld = &bld_base->uint_bld;
   LLVMValueRef unsigned_cond = 
      LLVMBuildBitCast(builder, emit_data->args[0], uint_bld->vec_type, "");
   LLVMValueRef cond = lp_build_cmp(uint_bld, PIPE_FUNC_NOTEQUAL,
                                    unsigned_cond,
                                    uint_bld->zero);
d1960 5
a1964 2
   lp_exec_break_condition(&bld->exec_mask, cond);
}
d1966 5
a1970 13
static void
if_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   LLVMValueRef tmp;
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);

   tmp = lp_build_cmp(&bld_base->base, PIPE_FUNC_NOTEQUAL,
                      emit_data->args[0], bld->bld_base.base.zero);
   lp_exec_mask_cond_push(&bld->exec_mask, tmp);
}
d1972 5
a1976 14
static void
uif_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   LLVMValueRef tmp;
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
   struct lp_build_context *uint_bld = &bld_base->uint_bld;

   tmp = lp_build_cmp(uint_bld, PIPE_FUNC_NOTEQUAL,
                      emit_data->args[0], uint_bld->zero);
   lp_exec_mask_cond_push(&bld->exec_mask, tmp);
}
d1978 7
a1984 7
static void
case_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
d1986 5
a1990 2
   lp_exec_case(&bld->exec_mask, emit_data->args[0]);
}
d1992 4
a1995 7
static void
default_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
d1997 1
a1997 2
   lp_exec_default(&bld->exec_mask, bld_base);
}
d1999 3
a2001 7
static void
switch_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
d2003 7
a2009 2
   lp_exec_switch(&bld->exec_mask, emit_data->args[0]);
}
d2011 113
a2123 7
static void
endswitch_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
d2125 6
a2130 2
   lp_exec_endswitch(&bld->exec_mask, bld_base);
}
d2132 5
a2136 7
static void
bgnloop_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
d2138 12
a2149 2
   lp_exec_bgnloop(&bld->exec_mask);
}
d2151 3
a2153 7
static void
bgnsub_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
d2155 3
a2157 2
   lp_exec_mask_bgnsub(&bld->exec_mask);
}
d2159 3
a2161 7
static void
else_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
d2163 6
a2168 2
   lp_exec_mask_cond_invert(&bld->exec_mask);
}
d2170 3
a2172 7
static void
endif_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
d2174 3
a2176 2
   lp_exec_mask_cond_pop(&bld->exec_mask);
}
d2178 3
a2180 7
static void
endloop_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
d2182 3
a2184 2
   lp_exec_endloop(bld_base->base.gallivm, &bld->exec_mask);
}
d2186 3
a2188 7
static void
endsub_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
d2190 3
a2192 2
   lp_exec_mask_endsub(&bld->exec_mask, &bld_base->pc);
}
d2194 5
a2198 31
static void
cont_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);

   lp_exec_continue(&bld->exec_mask);
}

/* XXX: Refactor and move it to lp_bld_tgsi_action.c
 *
 * XXX: What do the comments about xmm registers mean?  Maybe they are left over
 * from old code, but there is no garauntee that LLVM will use those registers
 * for this code.
 *
 * XXX: There should be no calls to lp_build_emit_fetch in this function.  This
 * should be handled by the emit_data->fetch_args function. */
static void
nrm_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   LLVMValueRef tmp0, tmp1;
   LLVMValueRef tmp4 = NULL;
   LLVMValueRef tmp5 = NULL;
   LLVMValueRef tmp6 = NULL;
   LLVMValueRef tmp7 = NULL;
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
d2200 5
a2204 1
   uint dims = (emit_data->inst->Instruction.Opcode == TGSI_OPCODE_NRM) ? 3 : 4;
d2206 4
a2209 42
  if (TGSI_IS_DST0_CHANNEL_ENABLED(emit_data->inst, TGSI_CHAN_X) ||
      TGSI_IS_DST0_CHANNEL_ENABLED(emit_data->inst, TGSI_CHAN_Y) ||
      TGSI_IS_DST0_CHANNEL_ENABLED(emit_data->inst, TGSI_CHAN_Z) ||
      (TGSI_IS_DST0_CHANNEL_ENABLED(emit_data->inst, TGSI_CHAN_W) && dims == 4)) {

      /* NOTE: Cannot use xmm regs 2/3 here (see emit_rsqrt() above). */

      /* xmm4 = src.x */
      /* xmm0 = src.x * src.x */
      tmp0 = lp_build_emit_fetch(&bld->bld_base, emit_data->inst, 0, TGSI_CHAN_X);
      if (TGSI_IS_DST0_CHANNEL_ENABLED(emit_data->inst, TGSI_CHAN_X)) {
         tmp4 = tmp0;
      }
      tmp0 = lp_build_mul( &bld->bld_base.base, tmp0, tmp0);

      /* xmm5 = src.y */
      /* xmm0 = xmm0 + src.y * src.y */
      tmp1 = lp_build_emit_fetch(&bld->bld_base, emit_data->inst, 0, TGSI_CHAN_Y);
      if (TGSI_IS_DST0_CHANNEL_ENABLED(emit_data->inst, TGSI_CHAN_Y)) {
         tmp5 = tmp1;
      }
      tmp1 = lp_build_mul( &bld->bld_base.base, tmp1, tmp1);
      tmp0 = lp_build_add( &bld->bld_base.base, tmp0, tmp1);

      /* xmm6 = src.z */
      /* xmm0 = xmm0 + src.z * src.z */
      tmp1 = lp_build_emit_fetch(&bld->bld_base, emit_data->inst, 0, TGSI_CHAN_Z);
      if (TGSI_IS_DST0_CHANNEL_ENABLED(emit_data->inst, TGSI_CHAN_Z)) {
         tmp6 = tmp1;
      }
      tmp1 = lp_build_mul( &bld->bld_base.base, tmp1, tmp1);
      tmp0 = lp_build_add( &bld->bld_base.base, tmp0, tmp1);

      if (dims == 4) {
         /* xmm7 = src.w */
         /* xmm0 = xmm0 + src.w * src.w */
         tmp1 = lp_build_emit_fetch(&bld->bld_base, emit_data->inst, 0, TGSI_CHAN_W);
         if (TGSI_IS_DST0_CHANNEL_ENABLED(emit_data->inst, TGSI_CHAN_W)) {
            tmp7 = tmp1;
         }
         tmp1 = lp_build_mul( &bld->bld_base.base, tmp1, tmp1);
         tmp0 = lp_build_add( &bld->bld_base.base, tmp0, tmp1);
d2211 18
a2228 9
      /* xmm1 = 1 / sqrt(xmm0) */
      tmp1 = lp_build_rsqrt( &bld->bld_base.base, tmp0);
       /* dst.x = xmm1 * src.x */
      if (TGSI_IS_DST0_CHANNEL_ENABLED(emit_data->inst, TGSI_CHAN_X)) {
         emit_data->output[TGSI_CHAN_X] = lp_build_mul( &bld->bld_base.base, tmp4, tmp1);
      }
      /* dst.y = xmm1 * src.y */
      if (TGSI_IS_DST0_CHANNEL_ENABLED(emit_data->inst, TGSI_CHAN_Y)) {
         emit_data->output[TGSI_CHAN_Y] = lp_build_mul( &bld->bld_base.base, tmp5, tmp1);
d2230 25
d2256 5
a2260 9
      /* dst.z = xmm1 * src.z */
      if (TGSI_IS_DST0_CHANNEL_ENABLED(emit_data->inst, TGSI_CHAN_Z)) {
         emit_data->output[TGSI_CHAN_Z] = lp_build_mul( &bld->bld_base.base, tmp6, tmp1);
      }
      /* dst.w = xmm1 * src.w */
      if (TGSI_IS_DST0_CHANNEL_ENABLED(emit_data->inst, TGSI_CHAN_X) && dims == 4) {
         emit_data->output[TGSI_CHAN_W] = lp_build_mul( &bld->bld_base.base, tmp7, tmp1);
      }
   }
d2262 5
a2266 5
   /* dst.w = 1.0 */
   if (TGSI_IS_DST0_CHANNEL_ENABLED(emit_data->inst, TGSI_CHAN_W) && dims == 3) {
       emit_data->output[TGSI_CHAN_W] = bld->bld_base.base.one;
   }
}
d2268 5
a2272 4
static void emit_prologue(struct lp_build_tgsi_context * bld_base)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
   struct gallivm_state * gallivm = bld_base->base.gallivm;
d2274 5
a2278 8
   if (bld->indirect_files & (1 << TGSI_FILE_TEMPORARY)) {
      LLVMValueRef array_size =
         lp_build_const_int32(gallivm,
                         bld_base->info->file_max[TGSI_FILE_TEMPORARY] * 4 + 4);
      bld->temps_array = lp_build_array_alloca(gallivm,
                                              bld_base->base.vec_type, array_size,
                                              "temp_array");
   }
d2280 5
a2284 8
   if (bld->indirect_files & (1 << TGSI_FILE_OUTPUT)) {
      LLVMValueRef array_size =
         lp_build_const_int32(gallivm,
                            bld_base->info->file_max[TGSI_FILE_OUTPUT] * 4 + 4);
      bld->outputs_array = lp_build_array_alloca(gallivm,
                                                bld_base->base.vec_type, array_size,
                                                "output_array");
   }
d2286 3
a2288 8
   if (bld->indirect_files & (1 << TGSI_FILE_IMMEDIATE)) {
      LLVMValueRef array_size =
         lp_build_const_int32(gallivm,
                         bld_base->info->file_max[TGSI_FILE_IMMEDIATE] * 4 + 4);
      bld->imms_array = lp_build_array_alloca(gallivm,
                                              bld_base->base.vec_type, array_size,
                                              "imms_array");
   }
d2290 3
a2292 10
   /* If we have indirect addressing in inputs we need to copy them into
    * our alloca array to be able to iterate over them */
   if (bld->indirect_files & (1 << TGSI_FILE_INPUT) && !bld->gs_iface) {
      unsigned index, chan;
      LLVMTypeRef vec_type = bld_base->base.vec_type;
      LLVMValueRef array_size = lp_build_const_int32(gallivm,
            bld_base->info->file_max[TGSI_FILE_INPUT]*4 + 4);
      bld->inputs_array = lp_build_array_alloca(gallivm,
                                               vec_type, array_size,
                                               "input_array");
d2294 3
a2296 2
      assert(bld_base->info->num_inputs
                        <= bld_base->info->file_max[TGSI_FILE_INPUT] + 1);
d2298 2
a2299 13
      for (index = 0; index < bld_base->info->num_inputs; ++index) {
         for (chan = 0; chan < TGSI_NUM_CHANNELS; ++chan) {
            LLVMValueRef lindex =
               lp_build_const_int32(gallivm, index * 4 + chan);
            LLVMValueRef input_ptr =
               LLVMBuildGEP(gallivm->builder, bld->inputs_array,
                            &lindex, 1, "");
            LLVMValueRef value = bld->inputs[index][chan];
            if (value)
               LLVMBuildStore(gallivm->builder, value, input_ptr);
         }
      }
   }
d2301 2
a2302 21
   if (bld->gs_iface) {
      struct lp_build_context *uint_bld = &bld->bld_base.uint_bld;
      bld->emitted_prims_vec_ptr =
         lp_build_alloca(gallivm,
                         uint_bld->vec_type,
                         "emitted_prims_ptr");
      bld->emitted_vertices_vec_ptr =
         lp_build_alloca(gallivm,
                         uint_bld->vec_type,
                         "emitted_vertices_ptr");
      bld->total_emitted_vertices_vec_ptr =
         lp_build_alloca(gallivm,
                         uint_bld->vec_type,
                         "total_emitted_vertices_ptr");

      LLVMBuildStore(gallivm->builder, uint_bld->zero,
                     bld->emitted_prims_vec_ptr);
      LLVMBuildStore(gallivm->builder, uint_bld->zero,
                     bld->emitted_vertices_vec_ptr);
      LLVMBuildStore(gallivm->builder, uint_bld->zero,
                     bld->total_emitted_vertices_vec_ptr);
d2304 3
a2306 1
}
d2308 1
a2308 4
static void emit_epilogue(struct lp_build_tgsi_context * bld_base)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);
   LLVMBuilderRef builder = bld_base->base.gallivm->builder;
d2310 3
a2312 3
   if (0) {
      /* for debugging */
      emit_dump_temps(bld);
d2315 1
a2315 21
   /* If we have indirect addressing in outputs we need to copy our alloca array
    * to the outputs slots specified by the caller */
   if (bld->gs_iface) {
      LLVMValueRef total_emitted_vertices_vec;
      LLVMValueRef emitted_prims_vec;
      /* implicit end_primitives, needed in case there are any unflushed
         vertices in the cache */
      end_primitive(NULL, bld_base, NULL);
      
      total_emitted_vertices_vec =
         LLVMBuildLoad(builder, bld->total_emitted_vertices_vec_ptr, "");
      emitted_prims_vec =
         LLVMBuildLoad(builder, bld->emitted_prims_vec_ptr, "");

      bld->gs_iface->gs_epilogue(bld->gs_iface,
                                 &bld->bld_base,
                                 total_emitted_vertices_vec,
                                 emitted_prims_vec);
   } else {
      gather_outputs(bld);
   }
d2318 1
d2325 3
a2327 3
                  const struct lp_bld_tgsi_system_values *system_values,
                  const LLVMValueRef (*inputs)[TGSI_NUM_CHANNELS],
                  LLVMValueRef (*outputs)[TGSI_NUM_CHANNELS],
d2329 1
a2329 2
                  const struct tgsi_shader_info *info,
                  const struct lp_build_tgsi_gs_iface *gs_iface)
d2332 5
d2348 2
a2349 3
   lp_build_context_init(&bld.bld_base.base, gallivm, type);
   lp_build_context_init(&bld.bld_base.uint_bld, gallivm, lp_uint_type(type));
   lp_build_context_init(&bld.bld_base.int_bld, gallivm, lp_int_type(type));
d2352 1
d2357 1
a2357 1
   bld.bld_base.info = info;
d2359 3
d2363 47
a2409 76
   bld.bld_base.soa = TRUE;
   bld.bld_base.emit_fetch_funcs[TGSI_FILE_CONSTANT] = emit_fetch_constant;
   bld.bld_base.emit_fetch_funcs[TGSI_FILE_IMMEDIATE] = emit_fetch_immediate;
   bld.bld_base.emit_fetch_funcs[TGSI_FILE_INPUT] = emit_fetch_input;
   bld.bld_base.emit_fetch_funcs[TGSI_FILE_TEMPORARY] = emit_fetch_temporary;
   bld.bld_base.emit_fetch_funcs[TGSI_FILE_SYSTEM_VALUE] = emit_fetch_system_value;
   bld.bld_base.emit_store = emit_store;

   bld.bld_base.emit_declaration = lp_emit_declaration_soa;
   bld.bld_base.emit_immediate = lp_emit_immediate_soa;

   bld.bld_base.emit_prologue = emit_prologue;
   bld.bld_base.emit_epilogue = emit_epilogue;

   /* Set opcode actions */
   lp_set_default_actions_cpu(&bld.bld_base);

   bld.bld_base.op_actions[TGSI_OPCODE_BGNLOOP].emit = bgnloop_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_BGNSUB].emit = bgnsub_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_BRK].emit = brk_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_BREAKC].emit = breakc_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_CAL].emit = cal_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_CASE].emit = case_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_CONT].emit = cont_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_DDX].emit = ddx_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_DDY].emit = ddy_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_DEFAULT].emit = default_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_ELSE].emit = else_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_ENDIF].emit = endif_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_ENDLOOP].emit = endloop_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_ENDSUB].emit = endsub_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_ENDSWITCH].emit = endswitch_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_IF].emit = if_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_UIF].emit = uif_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_KILL_IF].emit = kill_if_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_KILL].emit = kill_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_NRM].emit = nrm_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_NRM4].emit = nrm_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_RET].emit = ret_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_SWITCH].emit = switch_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_TEX].emit = tex_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_TXB].emit = txb_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_TXD].emit = txd_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_TXL].emit = txl_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_TXP].emit = txp_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_TXQ].emit = txq_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_TXF].emit = txf_emit;
   /* DX10 sampling ops */
   bld.bld_base.op_actions[TGSI_OPCODE_SAMPLE].emit = sample_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_SAMPLE_B].emit = sample_b_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_SAMPLE_C].emit = sample_c_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_SAMPLE_C_LZ].emit = sample_c_lz_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_SAMPLE_D].emit = sample_d_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_SAMPLE_I].emit = sample_i_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_SAMPLE_L].emit = sample_l_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_SVIEWINFO].emit = sviewinfo_emit;

   if (gs_iface) {
      /* There's no specific value for this because it should always
       * be set, but apps using ext_geometry_shader4 quite often
       * were forgetting so we're using MAX_VERTEX_VARYING from
       * that spec even though we could debug_assert if it's not
       * set, but that's a lot uglier. */
      uint max_output_vertices = 32;
      uint i = 0;
      /* inputs are always indirect with gs */
      bld.indirect_files |= (1 << TGSI_FILE_INPUT);
      bld.gs_iface = gs_iface;
      bld.bld_base.emit_fetch_funcs[TGSI_FILE_INPUT] = emit_fetch_gs_input;
      bld.bld_base.op_actions[TGSI_OPCODE_EMIT].emit = emit_vertex;
      bld.bld_base.op_actions[TGSI_OPCODE_ENDPRIM].emit = end_primitive;

      for (i = 0; i < info->num_properties; ++i) {
         if (info->properties[i].name ==
             TGSI_PROPERTY_GS_MAX_OUTPUT_VERTICES) {
            max_output_vertices = info->properties[i].data[0];
a2411 3
      bld.max_output_vertices_vec =
         lp_build_const_int_vec(gallivm, bld.bld_base.uint_bld.type,
                                max_output_vertices);
d2414 4
a2417 1
   lp_exec_mask_init(&bld.exec_mask, &bld.bld_base.int_bld);
d2419 5
a2423 1
   bld.system_values = *system_values;
d2425 69
a2493 1
   lp_build_tgsi_llvm(&bld.bld_base, tokens);
d2503 1
d2511 2
d2514 1
@


1.1.1.3
log
@Import Mesa 10.2.3
@
text
@d4 1
a4 1
 * Copyright 2007-2008 VMware, Inc.
d22 1
a22 1
 * IN NO EVENT SHALL VMWARE AND/OR ITS SUPPLIERS BE LIABLE FOR
a49 1
#include "tgsi/tgsi_strings.h"
a67 4
/* SM 4.0 says that subroutines can nest 32 deep and 
 * we need one more for our main function */
#define LP_MAX_NUM_FUNCS 33

d70 1
a70 36
/*
 * If non-zero, the generated LLVM IR will print intermediate results on every TGSI
 * instruction.
 *
 * TODO:
 * - take execution masks in consideration
 * - debug control-flow instructions
 */
#define DEBUG_EXECUTION 0


/*
 * Emit code to print a register value.
 */
static void
emit_dump_reg(struct gallivm_state *gallivm,
              unsigned file,
              unsigned index,
              unsigned chan,
              LLVMValueRef value)
{
   char buf[32];

   util_snprintf(buf, sizeof buf, "    %s[%u].%c = ",
                 tgsi_file_name(file),
                 index, "xyzw"[chan]);

   lp_build_print_value(gallivm, buf, value);
}

/*
 * Return the context for the current function.
 * (always 'main', if shader doesn't do any function calls)
 */
static INLINE struct function_ctx *
func_ctx(struct lp_exec_mask *mask)
d72 2
a73 85
   assert(mask->function_stack_size > 0);
   assert(mask->function_stack_size <= LP_MAX_NUM_FUNCS);
   return &mask->function_stack[mask->function_stack_size - 1];
}

/*
 * Returns true if we're in a loop.
 * It's global, meaning that it returns true even if there's
 * no loop inside the current function, but we were inside
 * a loop inside another function, from which this one was called.
 */
static INLINE boolean
mask_has_loop(struct lp_exec_mask *mask)
{
   int i;
   for (i = mask->function_stack_size - 1; i >= 0; --i) {
      const struct function_ctx *ctx = &mask->function_stack[i];
      if (ctx->loop_stack_size > 0)
         return TRUE;
   }
   return FALSE;
}

/*
 * Returns true if we're inside a switch statement.
 * It's global, meaning that it returns true even if there's
 * no switch in the current function, but we were inside
 * a switch inside another function, from which this one was called.
 */
static INLINE boolean
mask_has_switch(struct lp_exec_mask *mask)
{
   int i;
   for (i = mask->function_stack_size - 1; i >= 0; --i) {
      const struct function_ctx *ctx = &mask->function_stack[i];
      if (ctx->switch_stack_size > 0)
         return TRUE;
   }
   return FALSE;
}

/*
 * Returns true if we're inside a conditional.
 * It's global, meaning that it returns true even if there's
 * no conditional in the current function, but we were inside
 * a conditional inside another function, from which this one was called.
 */
static INLINE boolean
mask_has_cond(struct lp_exec_mask *mask)
{
   int i;
   for (i = mask->function_stack_size - 1; i >= 0; --i) {
      const struct function_ctx *ctx = &mask->function_stack[i];
      if (ctx->cond_stack_size > 0)
         return TRUE;
   }
   return FALSE;
}


/*
 * Initialize a function context at the specified index.
 */
static void
lp_exec_mask_function_init(struct lp_exec_mask *mask, int function_idx)
{
   LLVMTypeRef int_type = LLVMInt32TypeInContext(mask->bld->gallivm->context);
   LLVMBuilderRef builder = mask->bld->gallivm->builder;
   struct function_ctx *ctx =  &mask->function_stack[function_idx];

   ctx->cond_stack_size = 0;
   ctx->loop_stack_size = 0;
   ctx->switch_stack_size = 0;

   if (function_idx == 0) {
      ctx->ret_mask = mask->ret_mask;
   }

   ctx->loop_limiter = lp_build_alloca(mask->bld->gallivm,
                                       int_type, "looplimiter");
   LLVMBuildStore(
      builder,
      LLVMConstInt(int_type, LP_MAX_TGSI_LOOP_ITERATIONS, false),
      ctx->loop_limiter);
}
a74 2
static void lp_exec_mask_init(struct lp_exec_mask *mask, struct lp_build_context *bld)
{
d78 4
a81 2
   /* For the main function */
   mask->function_stack_size = 1;
d88 1
a88 4
   mask->function_stack = CALLOC(LP_MAX_NUM_FUNCS,
                                 sizeof(mask->function_stack[0]));
   lp_exec_mask_function_init(mask, 0);
}
d90 4
a93 4
static void
lp_exec_mask_fini(struct lp_exec_mask *mask)
{
   FREE(mask->function_stack);
a98 5
   boolean has_loop_mask = mask_has_loop(mask);
   boolean has_cond_mask = mask_has_cond(mask);
   boolean has_switch_mask = mask_has_switch(mask);
   boolean has_ret_mask = mask->function_stack_size > 1 ||
         mask->ret_in_main;
d100 1
a100 1
   if (has_loop_mask) {
d115 1
a115 1
   if (has_switch_mask) {
d122 1
a122 1
   if (has_ret_mask) {
d129 5
a133 4
   mask->has_mask = (has_cond_mask ||
                     has_loop_mask ||
                     has_switch_mask ||
                     has_ret_mask);
a139 1
   struct function_ctx *ctx = func_ctx(mask);
d141 2
a142 5
   if (ctx->cond_stack_size >= LP_MAX_TGSI_NESTING) {
      ctx->cond_stack_size++;
      return;
   }
   if (ctx->cond_stack_size == 0 && mask->function_stack_size == 1) {
d145 1
a145 1
   ctx->cond_stack[ctx->cond_stack_size++] = mask->cond_mask;
a156 1
   struct function_ctx *ctx = func_ctx(mask);
d160 3
a162 5
   assert(ctx->cond_stack_size);
   if (ctx->cond_stack_size >= LP_MAX_TGSI_NESTING)
      return;
   prev_mask = ctx->cond_stack[ctx->cond_stack_size - 1];
   if (ctx->cond_stack_size == 1 && mask->function_stack_size == 1) {
d176 2
a177 6
   struct function_ctx *ctx = func_ctx(mask);
   assert(ctx->cond_stack_size);
   --ctx->cond_stack_size;
   if (ctx->cond_stack_size >= LP_MAX_TGSI_NESTING)
      return;
   mask->cond_mask = ctx->cond_stack[ctx->cond_stack_size];
a183 1
   struct function_ctx *ctx = func_ctx(mask);
d185 5
a189 3
   if (ctx->loop_stack_size >= LP_MAX_TGSI_NESTING) {
      ++ctx->loop_stack_size;
      return;
d192 5
a196 3
   ctx->break_type_stack[ctx->loop_stack_size + ctx->switch_stack_size] =
      ctx->break_type;
   ctx->break_type = LP_EXEC_MASK_BREAK_TYPE_LOOP;
d198 5
a202 5
   ctx->loop_stack[ctx->loop_stack_size].loop_block = ctx->loop_block;
   ctx->loop_stack[ctx->loop_stack_size].cont_mask = mask->cont_mask;
   ctx->loop_stack[ctx->loop_stack_size].break_mask = mask->break_mask;
   ctx->loop_stack[ctx->loop_stack_size].break_var = ctx->break_var;
   ++ctx->loop_stack_size;
d204 2
a205 2
   ctx->break_var = lp_build_alloca(mask->bld->gallivm, mask->int_vec_type, "");
   LLVMBuildStore(builder, mask->break_mask, ctx->break_var);
d207 1
a207 1
   ctx->loop_block = lp_build_insert_new_block(mask->bld->gallivm, "bgnloop");
d209 2
a210 2
   LLVMBuildBr(builder, ctx->loop_block);
   LLVMPositionBuilderAtEnd(builder, ctx->loop_block);
d212 1
a212 1
   mask->break_mask = LLVMBuildLoad(builder, ctx->break_var, "");
a220 1
   struct function_ctx *ctx = func_ctx(mask);
d222 1
a222 1
   if (ctx->break_type == LP_EXEC_MASK_BREAK_TYPE_LOOP) {
d237 1
a237 1
      if (ctx->switch_in_default) {
d244 2
a245 2
         if(break_always && ctx->switch_pc) {
            bld_base->pc = ctx->switch_pc;
a269 1
   struct function_ctx *ctx = func_ctx(mask);
d275 1
a275 1
   if (ctx->break_type == LP_EXEC_MASK_BREAK_TYPE_LOOP) {
a307 1
   struct function_ctx *ctx = func_ctx(mask);
a316 7
   
   assert(ctx->loop_stack_size);
   if (ctx->loop_stack_size > LP_MAX_TGSI_NESTING) {
      --ctx->loop_stack_size;
      return;
   }

d320 2
a321 1
   mask->cont_mask = ctx->loop_stack[ctx->loop_stack_size - 1].cont_mask;
d328 1
a328 1
   LLVMBuildStore(builder, mask->break_mask, ctx->break_var);
d331 1
a331 1
   limiter = LLVMBuildLoad(builder, ctx->loop_limiter, "");
d339 1
a339 1
   LLVMBuildStore(builder, limiter, ctx->loop_limiter);
d361 1
a361 1
                   icond, ctx->loop_block, endloop);
d365 7
a371 8
   assert(ctx->loop_stack_size);
   --ctx->loop_stack_size;
   mask->cont_mask = ctx->loop_stack[ctx->loop_stack_size].cont_mask;
   mask->break_mask = ctx->loop_stack[ctx->loop_stack_size].break_mask;
   ctx->loop_block = ctx->loop_stack[ctx->loop_stack_size].loop_block;
   ctx->break_var = ctx->loop_stack[ctx->loop_stack_size].break_var;
   ctx->break_type = ctx->break_type_stack[ctx->loop_stack_size +
         ctx->switch_stack_size];
d379 10
a388 18
   struct function_ctx *ctx = func_ctx(mask);

   if (ctx->switch_stack_size >= LP_MAX_TGSI_NESTING ||
       ctx->loop_stack_size > LP_MAX_TGSI_NESTING) {
      ctx->switch_stack_size++;
      return;
   }

   ctx->break_type_stack[ctx->loop_stack_size + ctx->switch_stack_size] =
      ctx->break_type;
   ctx->break_type = LP_EXEC_MASK_BREAK_TYPE_SWITCH;

   ctx->switch_stack[ctx->switch_stack_size].switch_mask = mask->switch_mask;
   ctx->switch_stack[ctx->switch_stack_size].switch_val = ctx->switch_val;
   ctx->switch_stack[ctx->switch_stack_size].switch_mask_default = ctx->switch_mask_default;
   ctx->switch_stack[ctx->switch_stack_size].switch_in_default = ctx->switch_in_default;
   ctx->switch_stack[ctx->switch_stack_size].switch_pc = ctx->switch_pc;
   ctx->switch_stack_size++;
d390 1
d392 3
a394 4
   ctx->switch_val = switchval;
   ctx->switch_mask_default = LLVMConstNull(mask->int_vec_type);
   ctx->switch_in_default = false;
   ctx->switch_pc = 0;
a402 6
   struct function_ctx *ctx = func_ctx(mask);

   if (ctx->switch_stack_size > LP_MAX_TGSI_NESTING) {
      ctx->switch_stack_size--;
      return;
   }
d405 1
a405 1
   if (ctx->switch_pc && !ctx->switch_in_default) {
d408 2
a409 2
      prevmask = ctx->switch_stack[ctx->switch_stack_size - 1].switch_mask;
      defaultmask = LLVMBuildNot(builder, ctx->switch_mask_default, "sw_default_mask");
d411 1
a411 1
      ctx->switch_in_default = true;
d415 1
a415 1
      assert(bld_base->instructions[ctx->switch_pc - 1].Instruction.Opcode ==
d419 1
a419 1
      bld_base->pc = ctx->switch_pc;
d424 1
a424 1
      ctx->switch_pc = tmp_pc - 1;
d429 2
a430 2
   else if (ctx->switch_pc && ctx->switch_in_default) {
      assert(bld_base->pc == ctx->switch_pc + 1);
d433 6
a438 6
   ctx->switch_stack_size--;
   mask->switch_mask = ctx->switch_stack[ctx->switch_stack_size].switch_mask;
   ctx->switch_val = ctx->switch_stack[ctx->switch_stack_size].switch_val;
   ctx->switch_mask_default = ctx->switch_stack[ctx->switch_stack_size].switch_mask_default;
   ctx->switch_in_default = ctx->switch_stack[ctx->switch_stack_size].switch_in_default;
   ctx->switch_pc = ctx->switch_stack[ctx->switch_stack_size].switch_pc;
d440 1
a440 1
   ctx->break_type = ctx->break_type_stack[ctx->loop_stack_size + ctx->switch_stack_size];
a448 1
   struct function_ctx *ctx = func_ctx(mask);
a451 4
   if (ctx->switch_stack_size > LP_MAX_TGSI_NESTING) {
      return;
   }

d453 5
a457 5
   if (!ctx->switch_in_default) {
      prevmask = ctx->switch_stack[ctx->switch_stack_size - 1].switch_mask;
      casemask = lp_build_cmp(mask->bld, PIPE_FUNC_EQUAL, caseval, ctx->switch_val);
      ctx->switch_mask_default = LLVMBuildOr(builder, casemask,
                                             ctx->switch_mask_default, "sw_default_mask");
d477 1
a477 6
   struct function_ctx *ctx = func_ctx(mask);
   unsigned curr_switch_stack = ctx->switch_stack_size;

   if (ctx->switch_stack_size > LP_MAX_TGSI_NESTING) {
      return false;
   }
d488 1
a488 1
         if (curr_switch_stack == ctx->switch_stack_size) {
d497 1
a497 1
         if (curr_switch_stack == ctx->switch_stack_size) {
a514 1
   struct function_ctx *ctx = func_ctx(mask);
a518 4
   if (ctx->switch_stack_size > LP_MAX_TGSI_NESTING) {
      return;
   }

d533 2
a534 2
      prevmask = ctx->switch_stack[ctx->switch_stack_size - 1].switch_mask;
      defaultmask = LLVMBuildNot(builder, ctx->switch_mask_default, "sw_default_mask");
d537 1
a537 1
      ctx->switch_in_default = true;
d551 1
a551 1
      boolean ft_into = (opcode != TGSI_OPCODE_BRK &&
d564 1
a564 1
      ctx->switch_pc = bld_base->pc;
d612 4
a615 8
   if (mask->function_stack_size >= LP_MAX_NUM_FUNCS) {
      return;
   }

   lp_exec_mask_function_init(mask, mask->function_stack_size);
   mask->function_stack[mask->function_stack_size].pc = *pc;
   mask->function_stack[mask->function_stack_size].ret_mask = mask->ret_mask;
   mask->function_stack_size++;
a621 1
   struct function_ctx *ctx = func_ctx(mask);
d624 4
a627 4
   if (ctx->cond_stack_size == 0 &&
       ctx->loop_stack_size == 0 &&
       ctx->switch_stack_size == 0 &&
       mask->function_stack_size == 1) {
d633 1
a633 1
   if (mask->function_stack_size == 1) {
d659 4
a662 11
   struct function_ctx *ctx;

   assert(mask->function_stack_size > 1);
   assert(mask->function_stack_size <= LP_MAX_NUM_FUNCS);

   ctx = func_ctx(mask);
   mask->function_stack_size--;

   *pc = ctx->pc;
   mask->ret_mask = ctx->ret_mask;

a666 37
static LLVMValueRef
get_file_ptr(struct lp_build_tgsi_soa_context *bld,
             unsigned file,
             unsigned index,
             unsigned chan)
{
   LLVMBuilderRef builder = bld->bld_base.base.gallivm->builder;
   LLVMValueRef (*array_of_vars)[TGSI_NUM_CHANNELS];
   LLVMValueRef var_of_array;

   switch (file) {
   case TGSI_FILE_TEMPORARY:
      array_of_vars = bld->temps;
      var_of_array = bld->temps_array;
      break;
   case TGSI_FILE_OUTPUT:
      array_of_vars = bld->outputs;
      var_of_array = bld->outputs_array;
      break;
   default:
      assert(0);
      return NULL;
   }

   assert(chan < 4);

   if (bld->indirect_files & (1 << file)) {
      LLVMValueRef lindex = lp_build_const_int32(bld->bld_base.base.gallivm, index * 4 + chan);
      return LLVMBuildGEP(builder, var_of_array, &lindex, 1, "");
   }
   else {
      assert(index <= bld->bld_base.info->file_max[file]);
      return array_of_vars[index][chan];
   }
}


d678 9
a686 1
   return get_file_ptr(bld, TGSI_FILE_TEMPORARY, index, chan);
d700 10
a709 1
   return get_file_ptr(bld, TGSI_FILE_OUTPUT, index, chan);
d740 1
a740 2
             LLVMValueRef indexes,
             LLVMValueRef *overflow_mask)
a744 7
   LLVMValueRef temp_ptr;

   if (overflow_mask) {
      temp_ptr = lp_build_alloca(
         bld->gallivm,
         lp_build_vec_type(bld->gallivm, bld->type), "");
   }
d753 3
a755 41
      LLVMValueRef scalar_ptr, scalar;
      LLVMValueRef overflow;
      struct lp_build_if_state if_ctx;

      /*
       * overflow_mask is a boolean vector telling us which channels
       * in the vector overflowed. We use the overflow behavior for
       * constant buffers which is defined as:
       * Out of bounds access to constant buffer returns 0 in all
       * componenets. Out of bounds behavior is always with respect
       * to the size of the buffer bound at that slot.
       */
      if (overflow_mask) {
         overflow = LLVMBuildExtractElement(builder, *overflow_mask,
                                            ii, "");
         lp_build_if(&if_ctx, bld->gallivm, overflow);
         {
            LLVMValueRef val = LLVMBuildLoad(builder, temp_ptr, "");
            val = LLVMBuildInsertElement(
               builder, val,
               LLVMConstNull(LLVMFloatTypeInContext(bld->gallivm->context)),
               ii, "");
            LLVMBuildStore(builder, val, temp_ptr);
         }
         lp_build_else(&if_ctx);
         {
            LLVMValueRef val = LLVMBuildLoad(builder, temp_ptr, "");

            scalar_ptr = LLVMBuildGEP(builder, base_ptr,
                                      &index, 1, "gather_ptr");
            scalar = LLVMBuildLoad(builder, scalar_ptr, "");

            val = LLVMBuildInsertElement(builder, val, scalar, ii, "");

            LLVMBuildStore(builder, val, temp_ptr);
         }
         lp_build_endif(&if_ctx);
      } else {
         scalar_ptr = LLVMBuildGEP(builder, base_ptr,
                                   &index, 1, "gather_ptr");
         scalar = LLVMBuildLoad(builder, scalar_ptr, "");
d757 1
a757 6
         res = LLVMBuildInsertElement(builder, res, scalar, ii, "");
      }
   }

   if (overflow_mask) {
      res = LLVMBuildLoad(builder, temp_ptr, "gather_val");
d863 3
a865 13
   /*
    * emit_fetch_constant handles constant buffer overflow so this code
    * is pointless for them.
    * Furthermore the D3D10 spec in section 6.5 says:
    * If the constant buffer bound to a slot is larger than the size
    * declared in the shader for that slot, implementations are allowed
    * to return incorrect data (not necessarily 0) for indices that are
    * larger than the declared size but smaller than the buffer size.
    */
   if (reg_file != TGSI_FILE_CONSTANT) {
      max_index = lp_build_const_int_vec(bld->bld_base.base.gallivm,
                                         uint_bld->type,
                                         bld->bld_base.info->file_max[reg_file]);
d867 2
a868 3
      assert(!uint_bld->type.sign);
      index = lp_build_min(uint_bld, index, max_index);
   }
a900 33
get_soa_array_offsets(struct lp_build_context *uint_bld,
                      LLVMValueRef indirect_index,
                      unsigned chan_index,
                      boolean need_perelement_offset)
{
   struct gallivm_state *gallivm = uint_bld->gallivm;
   LLVMValueRef chan_vec =
      lp_build_const_int_vec(uint_bld->gallivm, uint_bld->type, chan_index);
   LLVMValueRef length_vec =
      lp_build_const_int_vec(gallivm, uint_bld->type, uint_bld->type.length);
   LLVMValueRef index_vec;

   /* index_vec = (indirect_index * 4 + chan_index) * length + offsets */
   index_vec = lp_build_shl_imm(uint_bld, indirect_index, 2);
   index_vec = lp_build_add(uint_bld, index_vec, chan_vec);
   index_vec = lp_build_mul(uint_bld, index_vec, length_vec);

   if (need_perelement_offset) {
      LLVMValueRef pixel_offsets;
      int i;
     /* build pixel offset vector: {0, 1, 2, 3, ...} */
      pixel_offsets = uint_bld->undef;
      for (i = 0; i < uint_bld->type.length; i++) {
         LLVMValueRef ii = lp_build_const_int32(gallivm, i);
         pixel_offsets = LLVMBuildInsertElement(gallivm->builder, pixel_offsets,
                                                ii, ii, "");
      }
      index_vec = lp_build_add(uint_bld, index_vec, pixel_offsets);
   }
   return index_vec;
}

static LLVMValueRef
d911 1
a914 1
   LLVMValueRef num_consts;
d927 1
a927 4
   consts_ptr =
      lp_build_array_get(gallivm, bld->consts_ptr, dimension_index);
   num_consts =
      lp_build_array_get(gallivm, bld->const_sizes_ptr, dimension_index);
a929 6
      LLVMValueRef indirect_index;
      LLVMValueRef swizzle_vec =
         lp_build_const_int_vec(gallivm, uint_bld->type, swizzle);
      LLVMValueRef index_vec;  /* index into the const buffer */
      LLVMValueRef overflow_mask;

d934 1
d936 4
a939 9
      /* All fetches are from the same constant buffer, so
       * we need to propagate the size to a vector to do a
       * vector comparison */
      num_consts = lp_build_broadcast_scalar(uint_bld, num_consts);
      /* Construct a boolean vector telling us which channels
       * overflow the bound constant buffer */
      overflow_mask = LLVMBuildICmp(builder, LLVMIntUGE,
                                    indirect_index,
                                    num_consts, "");
d946 1
a946 2
      res = build_gather(&bld_base->base, consts_ptr, index_vec,
                         &overflow_mask);
d952 1
a952 1
      index = lp_build_const_int32(gallivm, reg->Register.Index * 4 + swizzle);
a963 1

d977 2
d980 1
d982 15
a996 1
   if (bld->use_immediates_array || reg->Register.Indirect) {
d998 4
a1001 1
      LLVMTypeRef fptr_type;
d1003 5
a1007 3
      /* cast imms_array pointer to float* */
      fptr_type = LLVMPointerType(LLVMFloatTypeInContext(gallivm->context), 0);
      imms_array = LLVMBuildBitCast(builder, bld->imms_array, fptr_type, "");
d1009 5
a1013 3
      if (reg->Register.Indirect) {
         LLVMValueRef indirect_index;
         LLVMValueRef index_vec;  /* index into the immediate register array */
d1015 5
a1019 14
         indirect_index = get_indirect_index(bld,
                                             reg->Register.File,
                                             reg->Register.Index,
                                             &reg->Indirect);
         /*
          * Unlike for other reg classes, adding pixel offsets is unnecessary -
          * immediates are stored as full vectors (FIXME??? - might be better
          * to store them the same as constants) but all elements are the same
          * in any case.
          */
         index_vec = get_soa_array_offsets(&bld_base->uint_bld,
                                           indirect_index,
                                           swizzle,
                                           FALSE);
d1021 2
a1022 9
         /* Gather values from the immediate register array */
         res = build_gather(&bld_base->base, imms_array, index_vec, NULL);
      } else {
         LLVMValueRef lindex = lp_build_const_int32(gallivm,
                                        reg->Register.Index * 4 + swizzle);
         LLVMValueRef imms_ptr =  LLVMBuildGEP(builder,
                                                bld->imms_array, &lindex, 1, "");
         res = LLVMBuildLoad(builder, imms_ptr, "");
      }
d1046 2
a1050 5
      LLVMValueRef indirect_index;
      LLVMValueRef index_vec;  /* index into the input reg array */
      LLVMValueRef inputs_array;
      LLVMTypeRef fptr_type;

d1055 1
d1057 13
a1069 4
      index_vec = get_soa_array_offsets(&bld_base->uint_bld,
                                        indirect_index,
                                        swizzle,
                                        TRUE);
d1072 3
a1074 2
      fptr_type = LLVMPointerType(LLVMFloatTypeInContext(gallivm->context), 0);
      inputs_array = LLVMBuildBitCast(builder, bld->inputs_array, fptr_type, "");
d1076 2
a1077 2
      /* Gather values from the input register array */
      res = build_gather(&bld_base->base, inputs_array, index_vec, NULL);
d1120 3
a1122 3
                                        reg->Register.File,
                                        reg->Register.Index,
                                        &reg->Indirect);
d1138 1
a1138 3
                                    vertex_index,
                                    reg->Register.Indirect,
                                    attrib_index,
d1162 3
a1167 5
      LLVMValueRef indirect_index;
      LLVMValueRef index_vec;  /* index into the temp reg array */
      LLVMValueRef temps_array;
      LLVMTypeRef fptr_type;

d1172 14
d1187 11
a1197 4
      index_vec = get_soa_array_offsets(&bld_base->uint_bld,
                                        indirect_index,
                                        swizzle,
                                        TRUE);
d1200 3
a1202 2
      fptr_type = LLVMPointerType(LLVMFloatTypeInContext(gallivm->context), 0);
      temps_array = LLVMBuildBitCast(builder, bld->temps_array, fptr_type, "");
d1205 1
a1205 1
      res = build_gather(&bld_base->base, temps_array, index_vec, NULL);
a1363 1

d1382 1
d1399 2
a1400 1
      value = lp_build_clamp_zero_one_nanzero(float_bld, value);
d1407 1
a1407 4
      /* This will give -1.0 for NaN which is probably not what we want. */
      value = lp_build_max_ext(float_bld, value,
                               lp_build_const_vec(gallivm, float_bld->type, -1.0),
                               GALLIVM_NAN_RETURN_OTHER_SECOND_NONNAN);
a1424 4
   if (DEBUG_EXECUTION) {
      emit_dump_reg(gallivm, reg->Register.File, reg->Register.Index, chan_index, value);
   }

d1431 5
a1435 1
         LLVMValueRef index_vec;  /* indexes into the output registers */
d1437 11
a1447 1
         LLVMTypeRef fptr_type;
d1449 10
a1458 4
         index_vec = get_soa_array_offsets(&bld_base->uint_bld,
                                           indirect_index,
                                           chan_index,
                                           TRUE);
d1460 1
a1460 4
         fptr_type = LLVMPointerType(LLVMFloatTypeInContext(gallivm->context), 0);
         outputs_array = LLVMBuildBitCast(builder, bld->outputs_array, fptr_type, "");

         /* Scatter store values into output registers */
d1476 5
d1483 11
a1493 6
         LLVMTypeRef fptr_type;

         index_vec = get_soa_array_offsets(&bld_base->uint_bld,
                                           indirect_index,
                                           chan_index,
                                           TRUE);
d1495 10
a1504 2
         fptr_type = LLVMPointerType(LLVMFloatTypeInContext(gallivm->context), 0);
         temps_array = LLVMBuildBitCast(builder, bld->temps_array, fptr_type, "");
d1512 2
a1513 1
         temp_ptr = lp_get_temp_ptr_soa(bld, reg->Register.Index, chan_index);
a1539 33
/*
 * Called at the beginning of the translation of each TGSI instruction, to
 * emit some debug code.
 */
static void
emit_debug(
   struct lp_build_tgsi_context * bld_base,
   const struct tgsi_full_instruction * inst,
   const struct tgsi_opcode_info * info)

{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);

   if (DEBUG_EXECUTION) {
      /*
       * Dump the TGSI instruction.
       */

      struct gallivm_state *gallivm = bld_base->base.gallivm;
      char buf[512];
      buf[0] = '$';
      buf[1] = ' ';
      tgsi_dump_instruction_str(inst, bld_base->pc, &buf[2], sizeof buf - 2);
      lp_build_printf(gallivm, buf);

      /* Dump the execution mask.
       */
      if (bld->exec_mask.has_mask) {
         lp_build_print_value(gallivm, "    mask = ", bld->exec_mask.exec_mask);
      }
   }
}

a1561 87
static unsigned
tgsi_to_pipe_tex_target(unsigned tgsi_target)
{
   switch (tgsi_target) {
   case TGSI_TEXTURE_BUFFER:
      return PIPE_BUFFER;
   case TGSI_TEXTURE_1D:
   case TGSI_TEXTURE_SHADOW1D:
      return PIPE_TEXTURE_1D;
   case TGSI_TEXTURE_2D:
   case TGSI_TEXTURE_SHADOW2D:
   case TGSI_TEXTURE_2D_MSAA:
      return PIPE_TEXTURE_2D;
   case TGSI_TEXTURE_3D:
      return PIPE_TEXTURE_3D;
   case TGSI_TEXTURE_CUBE:
   case TGSI_TEXTURE_SHADOWCUBE:
      return PIPE_TEXTURE_CUBE;
   case TGSI_TEXTURE_RECT:
   case TGSI_TEXTURE_SHADOWRECT:
      return PIPE_TEXTURE_RECT;
   case TGSI_TEXTURE_1D_ARRAY:
   case TGSI_TEXTURE_SHADOW1D_ARRAY:
      return PIPE_TEXTURE_1D_ARRAY;
   case TGSI_TEXTURE_2D_ARRAY:
   case TGSI_TEXTURE_SHADOW2D_ARRAY:
   case TGSI_TEXTURE_2D_ARRAY_MSAA:
      return PIPE_TEXTURE_2D_ARRAY;
   case TGSI_TEXTURE_CUBE_ARRAY:
   case TGSI_TEXTURE_SHADOWCUBE_ARRAY:
      return PIPE_TEXTURE_CUBE_ARRAY;
   default:
      assert(0);
      return PIPE_BUFFER;
   }
}


static enum lp_sampler_lod_property
lp_build_lod_property(
   struct lp_build_tgsi_context *bld_base,
   const struct tgsi_full_instruction *inst,
   unsigned src_op)
{
   const struct tgsi_full_src_register *reg = &inst->Src[src_op];
   enum lp_sampler_lod_property lod_property;

   /*
    * Not much we can do here. We could try catching inputs declared
    * with constant interpolation but not sure it's worth it - since for
    * TEX opcodes as well as FETCH/LD the lod comes from same reg as
    * the coords, so it could only work for SAMPLE/TXQ/SVIEWINFO), just
    * like the constant/immediate recognition below.
    * What seems to be of more value would be to recognize temps holding
    * broadcasted scalars but no way we can do it.
    * Tried asking llvm but without any success (using LLVMIsConstant
    * even though this isn't exactly what we'd need), even as simple as
    * IMM[0] UINT32 (0,-1,0,0)
    * MOV TEMP[0] IMM[0].yyyy
    * SVIEWINFO TEMP[1], TEMP[0].xxxx, SVIEWINFO[0]
    * doesn't work.
    * This means there's ZERO chance this will ever catch a scalar lod
    * with traditional tex opcodes as well as texel fetches, since the lod
    * comes from the same reg as coords (except some test shaders using
    * constant coords maybe).
    * There's at least hope for sample opcodes as well as size queries.
    */
   if (reg->Register.File == TGSI_FILE_CONSTANT ||
       reg->Register.File == TGSI_FILE_IMMEDIATE) {
      lod_property = LP_SAMPLER_LOD_SCALAR;
   }
   else if (bld_base->info->processor == TGSI_PROCESSOR_FRAGMENT) {
      if (gallivm_debug & GALLIVM_DEBUG_NO_QUAD_LOD) {
         lod_property = LP_SAMPLER_LOD_PER_ELEMENT;
      }
      else {
         lod_property = LP_SAMPLER_LOD_PER_QUAD;
      }
   }
   else {
      /* never use scalar (per-quad) lod the results are just too wrong. */
      lod_property = LP_SAMPLER_LOD_PER_ELEMENT;
   }
   return lod_property;
}


d1575 1
a1575 1
   LLVMValueRef coords[5];
d1579 3
a1581 4
   enum lp_sampler_lod_property lod_property = LP_SAMPLER_LOD_SCALAR;
   unsigned num_derivs, num_offsets, i;
   unsigned shadow_coord = 0;
   unsigned layer_coord = 0;
d1592 5
d1598 1
a1598 3
      layer_coord = 1;
      /* fallthrough */
   case TGSI_TEXTURE_1D:
a1601 3
   case TGSI_TEXTURE_2D_ARRAY:
      layer_coord = 2;
      /* fallthrough */
d1604 1
d1608 1
d1610 1
a1610 4
      layer_coord = 1;
      /* fallthrough */
   case TGSI_TEXTURE_SHADOW1D:
      shadow_coord = 2;
a1613 6
   case TGSI_TEXTURE_SHADOW2D_ARRAY:
      layer_coord = 2;
      shadow_coord = 3;
      num_offsets = 2;
      num_derivs = 2;
      break;
d1616 2
a1617 1
      shadow_coord = 2;
d1622 1
d1627 1
d1631 5
d1637 1
a1637 1
      shadow_coord = 3;
a1640 4
   case TGSI_TEXTURE_CUBE_ARRAY:
   case TGSI_TEXTURE_SHADOWCUBE_ARRAY:
   case TGSI_TEXTURE_2D_MSAA:
   case TGSI_TEXTURE_2D_ARRAY_MSAA:
d1647 9
a1655 12
   if (modifier == LP_BLD_TEX_MODIFIER_LOD_BIAS ||
       modifier == LP_BLD_TEX_MODIFIER_EXPLICIT_LOD) {
      LLVMValueRef lod = lp_build_emit_fetch(&bld->bld_base, inst, 0, 3);
      if (modifier == LP_BLD_TEX_MODIFIER_LOD_BIAS) {
         lod_bias = lod;
         explicit_lod = NULL;
      }
      else if (modifier == LP_BLD_TEX_MODIFIER_EXPLICIT_LOD) {
         lod_bias = NULL;
         explicit_lod = lod;
      }
      lod_property = lp_build_lod_property(&bld->bld_base, inst, 0);
d1663 2
a1664 1
      oow = lp_build_emit_fetch(&bld->bld_base, inst, 0, 3);
d1668 2
a1669 2
   for (i = 0; i < num_derivs; i++) {
      coords[i] = lp_build_emit_fetch(&bld->bld_base, inst, 0, i);
d1673 1
a1673 1
   for (i = num_derivs; i < 5; i++) {
a1676 13
   /* Layer coord always goes into 3rd slot, except for cube map arrays */
   if (layer_coord) {
      coords[2] = lp_build_emit_fetch(&bld->bld_base, inst, 0, layer_coord);
      if (modifier == LP_BLD_TEX_MODIFIER_PROJECTED)
         coords[2] = lp_build_mul(&bld->bld_base.base, coords[2], oow);
   }
   /* Shadow coord occupies always 5th slot. */
   if (shadow_coord) {
      coords[4] = lp_build_emit_fetch(&bld->bld_base, inst, 0, shadow_coord);
      if (modifier == LP_BLD_TEX_MODIFIER_PROJECTED)
         coords[4] = lp_build_mul(&bld->bld_base.base, coords[4], oow);
   }

d1680 2
a1681 2
         derivs.ddx[dim] = lp_build_emit_fetch(&bld->bld_base, inst, 1, dim);
         derivs.ddy[dim] = lp_build_emit_fetch(&bld->bld_base, inst, 2, dim);
a1684 15
      /*
       * could also check all src regs if constant but I doubt such
       * cases exist in practice.
       */
      if (bld->bld_base.info->processor == TGSI_PROCESSOR_FRAGMENT) {
         if (gallivm_debug & GALLIVM_DEBUG_NO_QUAD_LOD) {
            lod_property = LP_SAMPLER_LOD_PER_ELEMENT;
         }
         else {
            lod_property = LP_SAMPLER_LOD_PER_QUAD;
         }
      }
      else {
         lod_property = LP_SAMPLER_LOD_PER_ELEMENT;
      }
d1693 1
a1693 1
         offsets[dim] = lp_build_emit_fetch_texoffset(&bld->bld_base, inst, 0, dim);
d1697 3
d1708 1
a1708 1
                                  lod_bias, explicit_lod, lod_property,
d1722 1
a1722 1
   LLVMValueRef coords[5];
d1726 3
a1728 4
   enum lp_sampler_lod_property lod_property = LP_SAMPLER_LOD_SCALAR;

   unsigned num_offsets, num_derivs, i;
   unsigned layer_coord = 0;
d1752 1
d1757 1
a1757 1
      layer_coord = 1;
d1763 1
d1768 1
a1768 1
      layer_coord = 2;
d1773 1
d1778 1
d1783 1
a1783 1
      layer_coord = 3;
d1792 7
a1798 12
   if (modifier == LP_BLD_TEX_MODIFIER_LOD_BIAS ||
       modifier == LP_BLD_TEX_MODIFIER_EXPLICIT_LOD) {
      LLVMValueRef lod = lp_build_emit_fetch(&bld->bld_base, inst, 3, 0);
      if (modifier == LP_BLD_TEX_MODIFIER_LOD_BIAS) {
         lod_bias = lod;
         explicit_lod = NULL;
      }
      else if (modifier == LP_BLD_TEX_MODIFIER_EXPLICIT_LOD) {
         lod_bias = NULL;
         explicit_lod = lod;
      }
      lod_property = lp_build_lod_property(&bld->bld_base, inst, 0);
d1810 2
a1811 2
   for (i = 0; i < num_derivs; i++) {
      coords[i] = lp_build_emit_fetch(&bld->bld_base, inst, 0, i);
d1813 1
a1813 1
   for (i = num_derivs; i < 5; i++) {
d1816 5
a1820 9

   /* Layer coord always goes into 3rd slot, except for cube map arrays */
   if (layer_coord) {
      if (layer_coord == 3)
         coords[3] = lp_build_emit_fetch(&bld->bld_base, inst, 0, layer_coord);
      else
         coords[2] = lp_build_emit_fetch(&bld->bld_base, inst, 0, layer_coord);
   }
   /* Shadow coord occupies always 5th slot. */
d1822 3
a1824 1
      coords[4] = lp_build_emit_fetch(&bld->bld_base, inst, 3, 0);
d1830 2
a1831 2
         derivs.ddx[dim] = lp_build_emit_fetch(&bld->bld_base, inst, 3, dim);
         derivs.ddy[dim] = lp_build_emit_fetch(&bld->bld_base, inst, 4, dim);
a1833 15
      /*
       * could also check all src regs if constant but I doubt such
       * cases exist in practice.
       */
      if (bld->bld_base.info->processor == TGSI_PROCESSOR_FRAGMENT) {
         if (gallivm_debug & GALLIVM_DEBUG_NO_QUAD_LOD) {
            lod_property = LP_SAMPLER_LOD_PER_ELEMENT;
         }
         else {
            lod_property = LP_SAMPLER_LOD_PER_QUAD;
         }
      }
      else {
         lod_property = LP_SAMPLER_LOD_PER_ELEMENT;
      }
d1840 1
a1840 1
         offsets[dim] = lp_build_emit_fetch_texoffset(&bld->bld_base, inst, 0, dim);
d1844 3
d1855 1
a1855 1
                                  lod_bias, explicit_lod, lod_property,
a1856 13

   if (inst->Src[1].Register.SwizzleX != PIPE_SWIZZLE_RED ||
       inst->Src[1].Register.SwizzleY != PIPE_SWIZZLE_GREEN ||
       inst->Src[1].Register.SwizzleZ != PIPE_SWIZZLE_BLUE ||
       inst->Src[1].Register.SwizzleW != PIPE_SWIZZLE_ALPHA) {
      unsigned char swizzles[4];
      swizzles[0] = inst->Src[1].Register.SwizzleX;
      swizzles[1] = inst->Src[1].Register.SwizzleY;
      swizzles[2] = inst->Src[1].Register.SwizzleZ;
      swizzles[3] = inst->Src[1].Register.SwizzleW;

      lp_build_swizzle_soa_inplace(&bld->bld_base.base, texel, swizzles);
   }
d1870 4
a1873 3
   enum lp_sampler_lod_property lod_property = LP_SAMPLER_LOD_SCALAR;
   unsigned dims, i;
   unsigned layer_coord = 0;
d1895 1
d1899 1
a1899 1
      layer_coord = 1;
d1904 1
d1908 1
a1908 1
      layer_coord = 2;
d1912 1
d1922 1
a1922 2
      explicit_lod = lp_build_emit_fetch(&bld->bld_base, inst, 0, 3);
      lod_property = lp_build_lod_property(&bld->bld_base, inst, 0);
d1925 2
a1926 2
   for (i = 0; i < dims; i++) {
      coords[i] = lp_build_emit_fetch(&bld->bld_base, inst, 0, i);
d1928 1
a1928 1
   for (i = dims; i < 3; i++) {
a1930 2
   if (layer_coord)
      coords[2] = lp_build_emit_fetch(&bld->bld_base, inst, 0, layer_coord);
d1935 1
a1935 1
         offsets[dim] = lp_build_emit_fetch_texoffset(&bld->bld_base, inst, 0, dim);
d1939 3
d1950 1
a1950 1
                                  NULL, explicit_lod, lod_property,
a1951 14

   if (is_samplei &&
       (inst->Src[1].Register.SwizzleX != PIPE_SWIZZLE_RED ||
        inst->Src[1].Register.SwizzleY != PIPE_SWIZZLE_GREEN ||
        inst->Src[1].Register.SwizzleZ != PIPE_SWIZZLE_BLUE ||
        inst->Src[1].Register.SwizzleW != PIPE_SWIZZLE_ALPHA)) {
      unsigned char swizzles[4];
      swizzles[0] = inst->Src[1].Register.SwizzleX;
      swizzles[1] = inst->Src[1].Register.SwizzleY;
      swizzles[2] = inst->Src[1].Register.SwizzleZ;
      swizzles[3] = inst->Src[1].Register.SwizzleW;

      lp_build_swizzle_soa_inplace(&bld->bld_base.base, texel, swizzles);
   }
a1960 1
   enum lp_sampler_lod_property lod_property;
d1964 1
a1964 1
   unsigned target, pipe_target;
d1990 3
a1992 5
   if (has_lod) {
      explicit_lod = lp_build_emit_fetch(&bld->bld_base, inst, 0, 0);
      lod_property = lp_build_lod_property(&bld->bld_base, inst, 0);
   }
   else {
a1993 5
      lod_property = LP_SAMPLER_LOD_SCALAR;
   }


   pipe_target = tgsi_to_pipe_tex_target(target);
d1998 1
a1998 1
                                 unit, pipe_target,
a1999 1
                                 lod_property,
d2089 5
a2093 4
   if (bld->exec_mask.has_mask) {
      LLVMValueRef invmask;
      invmask = LLVMBuildNot(builder, bld->exec_mask.exec_mask, "kilp");
      mask = LLVMBuildOr(builder, mask, invmask, "");
a2094 4

   lp_build_mask_update(bld->mask, mask);
   if (!near_end_of_shader(bld, pc))
      lp_build_mask_check(bld->mask);
d2133 1
a2133 2
emit_dump_file(struct lp_build_tgsi_soa_context *bld,
               unsigned file)
a2134 1
   const struct tgsi_shader_info *info = bld->bld_base.info;
d2137 5
a2141 1
   LLVMValueRef reg_ptr;
d2143 1
a2143 7
   int max_index = info->file_max[file];

   /*
    * Some register files, particularly constants, can be very large,
    * and dumping everything could make this unusably slow.
    */
   max_index = MIN2(max_index, 32);
d2145 3
a2147 3
   for (index = 0; index <= max_index; index++) {
      LLVMValueRef res;
      unsigned mask;
d2150 1
a2150 11
      if (index < 8 * sizeof(unsigned) &&
          (info->file_mask[file] & (1 << index)) == 0)  {
         /* This was not declared.*/
         continue;
      }

      if (file == TGSI_FILE_INPUT) {
         mask = info->input_usage_mask[index];
      } else {
         mask = TGSI_WRITEMASK_XYZW;
      }
d2153 16
a2168 39
         if ((mask & (1 << chan)) == 0) {
            /* This channel is not used.*/
            continue;
         }

         if (file == TGSI_FILE_CONSTANT) {
            struct tgsi_full_src_register reg;
            memset(&reg, 0, sizeof reg);
            reg.Register.File = file;
            reg.Register.Index = index;
            reg.Register.SwizzleX = 0;
            reg.Register.SwizzleY = 1;
            reg.Register.SwizzleZ = 2;
            reg.Register.SwizzleW = 3;

            res = bld->bld_base.emit_fetch_funcs[file](&bld->bld_base, &reg, TGSI_TYPE_FLOAT, chan);
            if (!res) {
               continue;
            }
         } else if (file == TGSI_FILE_INPUT) {
            res = bld->inputs[index][chan];
            if (!res) {
               continue;
            }
         } else if (file == TGSI_FILE_TEMPORARY) {
            reg_ptr = lp_get_temp_ptr_soa(bld, index, chan);
            assert(reg_ptr);
            res = LLVMBuildLoad(builder, reg_ptr, "");
         } else if (file == TGSI_FILE_OUTPUT) {
            reg_ptr = lp_get_output_ptr(bld, index, chan);
            assert(reg_ptr);
            res = LLVMBuildLoad(builder, reg_ptr, "");
         } else {
            assert(0);
            continue;
         }

         emit_dump_reg(gallivm, file, index, chan, res);
      }
d2190 1
a2191 1
            assert(idx < LP_MAX_INLINED_TEMPS);
d2246 2
a2247 1
   LLVMValueRef imms[4];
d2251 1
d2255 2
a2256 2
         imms[i] =
               lp_build_const_vec(gallivm, bld_base->base.type, imm->u[i].Float);
d2262 2
a2263 1
         imms[i] = LLVMConstBitCast(tmp, bld_base->base.vec_type);
d2270 2
a2271 1
         imms[i] = LLVMConstBitCast(tmp, bld_base->base.vec_type);
d2273 1
a2273 1

d2277 1
a2277 1
      imms[i] = bld_base->base.undef;
d2279 1
a2279 1
   if (bld->use_immediates_array) {
a2282 2

      assert(bld->indirect_files & (1 << TGSI_FILE_IMMEDIATE));
d2285 1
a2285 1
                  bld->bld_base.base.gallivm, index * 4 + i);
d2288 3
a2290 25
         LLVMBuildStore(builder, imms[i], imm_ptr);
      }
   } else {
      /* simply copy the immediate values into the next immediates[] slot */
      unsigned i;
      const uint size = imm->Immediate.NrTokens - 1;
      assert(size <= 4);
      assert(bld->num_immediates < LP_MAX_INLINED_IMMEDIATES);

      for(i = 0; i < 4; ++i )
         bld->immediates[bld->num_immediates][i] = imms[i];

      if (bld->indirect_files & (1 << TGSI_FILE_IMMEDIATE)) {
         unsigned index = bld->num_immediates;
         struct gallivm_state *gallivm = bld->bld_base.base.gallivm;
         LLVMBuilderRef builder = gallivm->builder;
         for (i = 0; i < 4; ++i ) {
            LLVMValueRef lindex = lp_build_const_int32(
                     bld->bld_base.base.gallivm, index * 4 + i);
            LLVMValueRef imm_ptr = LLVMBuildGEP(builder,
                                                bld->imms_array, &lindex, 1, "");
            LLVMBuildStore(builder,
                           bld->immediates[index][i],
                           imm_ptr);
         }
d2519 1
a2519 1
mask_vec(struct lp_build_tgsi_context *bld_base)
d2523 1
d2526 2
a2527 2
   if (!exec_mask->has_mask) {
      return lp_build_mask_value(bld->mask);
d2529 3
a2531 2
   return LLVMBuildAnd(builder, lp_build_mask_value(bld->mask),
                       exec_mask->exec_mask, "");
d2540 1
d2542 3
a2544 3

   current_vec = LLVMBuildSub(builder, current_vec, mask, "");

d2554 1
d2556 4
d2562 1
a2562 1
                                 mask,
d2565 1
a2565 1

d2575 2
a2576 2
   struct lp_build_context *int_bld = &bld->bld_base.int_bld;
   LLVMValueRef max_mask = lp_build_cmp(int_bld, PIPE_FUNC_LESS,
d2593 1
a2593 1
      LLVMValueRef mask = mask_vec(bld_base);
d2596 2
a2597 2
      mask = clamp_mask_to_max_output_vertices(bld, mask,
                                               total_emitted_vertices_vec);
d2603 1
a2603 1
                                mask);
d2605 1
a2605 1
                                mask);
d2609 1
a2609 1
                           mask);
d2620 1
a2620 1
                     LLVMValueRef mask)
a2625 1
      struct lp_build_context *uint_bld = &bld_base->uint_bld;
d2630 1
a2630 10

      LLVMValueRef emitted_mask = lp_build_cmp(uint_bld, PIPE_FUNC_NOTEQUAL,
                                               emitted_vertices_vec,
                                               uint_bld->zero);
      /* We need to combine the current execution mask with the mask
         telling us which, if any, execution slots actually have
         unemitted primitives, this way we make sure that end_primitives
         executes only on the paths that have unflushed vertices */
      mask = LLVMBuildAnd(builder, mask, emitted_mask, "");

d2638 1
a2638 1
                           mask);
d2648 1
a2648 1
                                mask);
d2650 1
a2650 1
                                   mask);
d2670 15
a2684 2
      LLVMValueRef mask = mask_vec(bld_base);
      end_primitive_masked(bld_base, mask);
a3064 7

   if (DEBUG_EXECUTION) {
      lp_build_printf(gallivm, "\n");
      emit_dump_file(bld, TGSI_FILE_CONSTANT);
      if (!bld->gs_iface)
         emit_dump_file(bld, TGSI_FILE_INPUT);
   }
d3072 1
a3072 1
   if (DEBUG_EXECUTION) {
d3074 1
a3074 5
      if (0) {
         emit_dump_file(bld, TGSI_FILE_TEMPORARY);
      }
      emit_dump_file(bld, TGSI_FILE_OUTPUT);
      lp_build_printf(bld_base->base.gallivm, "\n");
d3083 2
a3084 3
         vertices in the cache. Note must not call end_primitive here
         since the exec_mask is not valid at this point. */
      end_primitive_masked(bld_base, lp_build_mask_value(bld->mask));
a3105 1
                  LLVMValueRef const_sizes_ptr,
a3132 1
   bld.const_sizes_ptr = const_sizes_ptr;
a3136 20
   /*
    * If the number of temporaries is rather large then we just
    * allocate them as an array right from the start and treat
    * like indirect temporaries.
    */
   if (info->file_max[TGSI_FILE_TEMPORARY] >= LP_MAX_INLINED_TEMPS) {
      bld.indirect_files |= (1 << TGSI_FILE_TEMPORARY);
   }
   /*
    * For performance reason immediates are always backed in a static
    * array, but if their number is too great, we have to use just
    * a dynamically allocated array.
    */
   bld.use_immediates_array =
         (info->file_max[TGSI_FILE_IMMEDIATE] >= LP_MAX_INLINED_IMMEDIATES);
   if (bld.use_immediates_array) {
      bld.indirect_files |= (1 << TGSI_FILE_IMMEDIATE);
   }


a3137 1
   bld.bld_base.emit_debug = emit_debug;
d3216 1
a3216 1
         lp_build_const_int_vec(gallivm, bld.bld_base.int_bld.type,
a3240 1
   lp_exec_mask_fini(&bld.exec_mask);
@


1.1.1.4
log
@Import Mesa 10.4.3
@
text
@d1216 1
d1230 5
a1234 2
   consts_ptr = bld->consts[dimension];
   num_consts = bld->consts_sizes[dimension];
a1414 1
   const struct tgsi_shader_info *info = bld->bld_base.info;
a1420 11
   if (info->input_semantic_name[reg->Register.Index] == TGSI_SEMANTIC_PRIMID) {
      /* This is really a system value not a regular input */
      assert(!reg->Register.Indirect);
      assert(!reg->Dimension.Indirect);
      res = bld->system_values.prim_id;
      if (stype != TGSI_TYPE_UNSIGNED && stype != TGSI_TYPE_SIGNED) {
         res = LLVMBuildBitCast(builder, res, bld_base->base.vec_type, "");
      }
      return res;
   }

d1945 1
a1945 2
          LLVMValueRef *texel,
          unsigned sampler_reg)
d1947 1
a1947 1
   unsigned unit = inst->Src[sampler_reg].Register.Index;
a2016 4
      num_offsets = 2;
      num_derivs = 3;
      layer_coord = 3;
      break;
a2017 5
      num_offsets = 2;
      num_derivs = 3;
      layer_coord = 3;
      shadow_coord = 4; /* shadow coord special different reg */
      break;
d2028 1
a2028 9
      LLVMValueRef lod;
      if (inst->Texture.Texture == TGSI_TEXTURE_SHADOWCUBE ||
          inst->Texture.Texture == TGSI_TEXTURE_CUBE_ARRAY) {
         /* note that shadow cube array with bias/explicit lod does not exist */
         lod = lp_build_emit_fetch(&bld->bld_base, inst, 1, 0);
      }
      else {
         lod = lp_build_emit_fetch(&bld->bld_base, inst, 0, 3);
      }
d2060 1
a2060 6
      if (layer_coord == 3) {
         coords[3] = lp_build_emit_fetch(&bld->bld_base, inst, 0, layer_coord);
      }
      else {
         coords[2] = lp_build_emit_fetch(&bld->bld_base, inst, 0, layer_coord);
      }
d2066 1
a2066 6
      if (shadow_coord == 4) {
         coords[4] = lp_build_emit_fetch(&bld->bld_base, inst, 1, 0);
      }
      else {
         coords[4] = lp_build_emit_fetch(&bld->bld_base, inst, 0, shadow_coord);
      }
d2078 1
d2094 2
d2303 1
a2303 1
   LLVMValueRef coords[5];
a2336 1
   case TGSI_TEXTURE_2D_MSAA:
a2339 1
   case TGSI_TEXTURE_2D_ARRAY_MSAA:
d2351 2
a2352 4
   /* always have lod except for buffers and msaa targets ? */
   if (target != TGSI_TEXTURE_BUFFER &&
       target != TGSI_TEXTURE_2D_MSAA &&
       target != TGSI_TEXTURE_2D_ARRAY_MSAA) {
a2355 1
   /* XXX: for real msaa support, the w component would be the sample index. */
d2360 1
a2360 2
   /* never use more than 3 coords here but emit_fetch_texel copies all 5 anyway */
   for (i = dims; i < 5; i++) {
d2452 1
a2452 1
                                 TRUE,
d2460 1
a2460 1
                   int pc)
d2468 1
a2468 1
         return TRUE;
d2473 1
a2473 1
         return TRUE;
d2476 13
a2488 24
         opcode == TGSI_OPCODE_TXP ||
         opcode == TGSI_OPCODE_TXD ||
         opcode == TGSI_OPCODE_TXB ||
         opcode == TGSI_OPCODE_TXL ||
         opcode == TGSI_OPCODE_TXF ||
         opcode == TGSI_OPCODE_TXQ ||
         opcode == TGSI_OPCODE_TEX2 ||
         opcode == TGSI_OPCODE_TXB2 ||
         opcode == TGSI_OPCODE_TXL2 ||
         opcode == TGSI_OPCODE_SAMPLE ||
         opcode == TGSI_OPCODE_SAMPLE_B ||
         opcode == TGSI_OPCODE_SAMPLE_C ||
         opcode == TGSI_OPCODE_SAMPLE_C_LZ ||
         opcode == TGSI_OPCODE_SAMPLE_D ||
         opcode == TGSI_OPCODE_SAMPLE_I ||
         opcode == TGSI_OPCODE_SAMPLE_L ||
         opcode == TGSI_OPCODE_SVIEWINFO ||
         opcode == TGSI_OPCODE_CAL ||
         opcode == TGSI_OPCODE_CALLNZ ||
         opcode == TGSI_OPCODE_IF ||
         opcode == TGSI_OPCODE_UIF ||
         opcode == TGSI_OPCODE_BGNLOOP ||
         opcode == TGSI_OPCODE_SWITCH)
         return FALSE;
d2680 6
a2685 7
   assert(last <= bld->bld_base.info->file_max[decl->Declaration.File]);

   switch (decl->Declaration.File) {
   case TGSI_FILE_TEMPORARY:
      if (!(bld->indirect_files & (1 << TGSI_FILE_TEMPORARY))) {
         assert(last < LP_MAX_INLINED_TEMPS);
         for (idx = first; idx <= last; ++idx) {
d2689 1
a2689 2
      }
      break;
d2691 2
a2692 3
   case TGSI_FILE_OUTPUT:
      if (!(bld->indirect_files & (1 << TGSI_FILE_OUTPUT))) {
         for (idx = first; idx <= last; ++idx) {
d2697 1
a2697 2
      }
      break;
d2699 6
a2704 8
   case TGSI_FILE_ADDRESS:
      /* ADDR registers are only allocated with an integer LLVM IR type,
       * as they are guaranteed to always have integers.
       * XXX: Not sure if this exception is worthwhile (or the whole idea of
       * an ADDR register for that matter).
       */
      assert(last < LP_MAX_TGSI_ADDRS);
      for (idx = first; idx <= last; ++idx) {
d2708 1
a2708 2
      }
      break;
d2710 2
a2711 3
   case TGSI_FILE_PREDICATE:
      assert(last < LP_MAX_TGSI_PREDS);
      for (idx = first; idx <= last; ++idx) {
d2715 1
a2715 2
      }
      break;
d2717 6
a2722 7
   case TGSI_FILE_SAMPLER_VIEW:
      /*
       * The target stored here MUST match whatever there actually
       * is in the set sampler views (what about return type?).
       */
      assert(last < PIPE_MAX_SHADER_SAMPLER_VIEWS);
      for (idx = first; idx <= last; ++idx) {
d2724 5
a2729 25
      break;

   case TGSI_FILE_CONSTANT:
   {
      /*
       * We could trivially fetch the per-buffer pointer when fetching the
       * constant, relying on llvm to figure out it's always the same pointer
       * anyway. However, doing so results in a huge (more than factor of 10)
       * slowdown in llvm compilation times for some (but not all) shaders
       * (more specifically, the IR optimization spends way more time in
       * DominatorTree::dominates). At least with llvm versions 3.1, 3.3.
       */
      unsigned idx2D = decl->Dim.Index2D;
      LLVMValueRef index2D = lp_build_const_int32(gallivm, idx2D);
      assert(idx2D < LP_MAX_TGSI_CONST_BUFFERS);
      bld->consts[idx2D] =
         lp_build_array_get(gallivm, bld->consts_ptr, index2D);
      bld->consts_sizes[idx2D] =
         lp_build_array_get(gallivm, bld->const_sizes_ptr, index2D);
   }
      break;

   default:
      /* don't need to declare other vars */
      break;
d2865 1
a2865 14
   emit_tex(bld, emit_data->inst, LP_BLD_TEX_MODIFIER_NONE,
            emit_data->output, 1);
}

static void
tex2_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);

   emit_tex(bld, emit_data->inst, LP_BLD_TEX_MODIFIER_NONE,
            emit_data->output, 2);
d2877 1
a2877 13
            emit_data->output, 1);
}

static void
txb2_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);

   emit_tex(bld, emit_data->inst, LP_BLD_TEX_MODIFIER_LOD_BIAS,
            emit_data->output, 2);
d2889 1
a2889 1
            emit_data->output, 3);
d2901 1
a2901 13
            emit_data->output, 1);
}

static void
txl2_emit(
   const struct lp_build_tgsi_action * action,
   struct lp_build_tgsi_context * bld_base,
   struct lp_build_emit_data * emit_data)
{
   struct lp_build_tgsi_soa_context * bld = lp_soa_context(bld_base);

   emit_tex(bld, emit_data->inst, LP_BLD_TEX_MODIFIER_EXPLICIT_LOD,
            emit_data->output, 2);
d2913 1
a2913 1
            emit_data->output, 1);
a3721 3
   bld.bld_base.op_actions[TGSI_OPCODE_TEX2].emit = tex2_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_TXB2].emit = txb2_emit;
   bld.bld_base.op_actions[TGSI_OPCODE_TXL2].emit = txl2_emit;
d3738 2
a3739 2
      uint max_output_vertices;

d3747 6
a3752 5
      max_output_vertices =
            info->properties[TGSI_PROPERTY_GS_MAX_OUTPUT_VERTICES];
      if (!max_output_vertices)
         max_output_vertices = 32;

@


1.1.1.5
log
@Import Mesa 10.2.9
@
text
@a1215 1
   LLVMValueRef dimension_index;
d1229 2
a1230 5
   dimension_index = lp_build_const_int32(gallivm, dimension);
   consts_ptr =
      lp_build_array_get(gallivm, bld->consts_ptr, dimension_index);
   num_consts =
      lp_build_array_get(gallivm, bld->const_sizes_ptr, dimension_index);
d1411 1
d1418 11
d1953 2
a1954 1
          LLVMValueRef *texel)
d1956 1
a1956 1
   unsigned unit;
d2026 4
d2031 5
d2046 9
a2054 1
      LLVMValueRef lod = lp_build_emit_fetch(&bld->bld_base, inst, 0, 3);
d2086 6
a2091 1
      coords[2] = lp_build_emit_fetch(&bld->bld_base, inst, 0, layer_coord);
d2097 6
a2102 1
      coords[4] = lp_build_emit_fetch(&bld->bld_base, inst, 0, shadow_coord);
a2113 1
      unit = inst->Src[3].Register.Index;
a2128 2
   } else {
      unit = inst->Src[1].Register.Index;
d2336 1
a2336 1
   LLVMValueRef coords[3];
d2370 1
d2374 1
d2386 4
a2389 2
   /* always have lod except for buffers ? */
   if (target != TGSI_TEXTURE_BUFFER) {
d2393 1
d2398 2
a2399 1
   for (i = dims; i < 3; i++) {
d2491 1
a2491 1
                                 is_sviewinfo,
d2499 1
a2499 1
		   int pc)
d2507 1
a2507 1
	 return TRUE;
d2512 1
a2512 1
	 return TRUE;
d2515 24
a2538 13
	  opcode == TGSI_OPCODE_TXP ||
	  opcode == TGSI_OPCODE_TXD ||
	  opcode == TGSI_OPCODE_TXB ||
	  opcode == TGSI_OPCODE_TXL ||
	  opcode == TGSI_OPCODE_TXF ||
	  opcode == TGSI_OPCODE_TXQ ||
	  opcode == TGSI_OPCODE_CAL ||
	  opcode == TGSI_OPCODE_CALLNZ ||
	  opcode == TGSI_OPCODE_IF ||
          opcode == TGSI_OPCODE_UIF ||
	  opcode == TGSI_OPCODE_BGNLOOP ||
	  opcode == TGSI_OPCODE_SWITCH)
	 return FALSE;
d2730 7
a2736 6
   for (idx = first; idx <= last; ++idx) {
      assert(last <= bld->bld_base.info->file_max[decl->Declaration.File]);
      switch (decl->Declaration.File) {
      case TGSI_FILE_TEMPORARY:
         if (!(bld->indirect_files & (1 << TGSI_FILE_TEMPORARY))) {
            assert(idx < LP_MAX_INLINED_TEMPS);
d2740 2
a2741 1
         break;
d2743 3
a2745 2
      case TGSI_FILE_OUTPUT:
         if (!(bld->indirect_files & (1 << TGSI_FILE_OUTPUT))) {
d2750 2
a2751 1
         break;
d2753 8
a2760 6
      case TGSI_FILE_ADDRESS:
	 /* ADDR registers are only allocated with an integer LLVM IR type,
	  * as they are guaranteed to always have integers.
	  * XXX: Not sure if this exception is worthwhile (or the whole idea of
	  * an ADDR register for that matter).
	  */
d2764 2
a2765 1
         break;
d2767 3
a2769 2
      case TGSI_FILE_PREDICATE:
         assert(idx < LP_MAX_TGSI_PREDS);
d2773 2
a2774 1
         break;
d2776 7
a2782 6
      case TGSI_FILE_SAMPLER_VIEW:
         /*
          * The target stored here MUST match whatever there actually
          * is in the set sampler views (what about return type?).
          */
         assert(idx < PIPE_MAX_SHADER_SAMPLER_VIEWS);
d2784 22
a2805 1
         break;
d2807 3
a2809 4
      default:
         /* don't need to declare other vars */
         break;
      }
d2945 14
a2958 1
   emit_tex(bld, emit_data->inst, LP_BLD_TEX_MODIFIER_NONE, emit_data->output);
d2970 13
a2982 1
            emit_data->output);
d2994 1
a2994 1
            emit_data->output);
d3006 13
a3018 1
            emit_data->output);
d3030 1
a3030 1
            emit_data->output);
d3839 3
d3858 2
a3859 2
      uint max_output_vertices = 32;
      uint i = 0;
d3867 5
a3871 6
      for (i = 0; i < info->num_properties; ++i) {
         if (info->properties[i].name ==
             TGSI_PROPERTY_GS_MAX_OUTPUT_VERTICES) {
            max_output_vertices = info->properties[i].data[0];
         }
      }
@


