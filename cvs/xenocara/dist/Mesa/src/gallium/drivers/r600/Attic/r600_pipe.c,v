head	1.8;
access;
symbols
	OPENBSD_5_8:1.7.0.4
	OPENBSD_5_8_BASE:1.7
	OPENBSD_5_7:1.7.0.2
	OPENBSD_5_7_BASE:1.7
	v10_2_9:1.1.1.5
	v10_4_3:1.1.1.4
	v10_2_7:1.1.1.3
	OPENBSD_5_6:1.4.0.2
	OPENBSD_5_6_BASE:1.4
	v10_2_3:1.1.1.3
	OPENBSD_5_5:1.3.0.2
	OPENBSD_5_5_BASE:1.3
	v9_2_5:1.1.1.2
	v9_2_3:1.1.1.2
	v9_2_2:1.1.1.2
	v9_2_1:1.1.1.2
	v9_2_0:1.1.1.2
	OPENBSD_5_4:1.2.0.4
	OPENBSD_5_4_BASE:1.2
	OPENBSD_5_3:1.2.0.2
	OPENBSD_5_3_BASE:1.2
	OPENBSD_5_2:1.1.1.1.0.4
	OPENBSD_5_2_BASE:1.1.1.1
	OPENBSD_5_1_BASE:1.1.1.1
	OPENBSD_5_1:1.1.1.1.0.2
	v7_10_3:1.1.1.1
	mesa:1.1.1;
locks; strict;
comment	@ * @;


1.8
date	2015.12.23.05.17.33;	author jsg;	state dead;
branches;
next	1.7;
commitid	TnlogFl9nOv2eaRf;

1.7
date	2015.02.22.09.30.34;	author jsg;	state Exp;
branches;
next	1.6;
commitid	yhStanAcs6cSYmBc;

1.6
date	2015.02.20.23.09.53;	author jsg;	state Exp;
branches;
next	1.5;
commitid	4ry2gvZGMXkCUD2n;

1.5
date	2015.01.25.14.41.16;	author jsg;	state Exp;
branches;
next	1.4;
commitid	mcxB0JvoI9gTDYXU;

1.4
date	2014.07.09.21.08.54;	author jsg;	state Exp;
branches;
next	1.3;
commitid	WPD6rgPryPkvXOr9;

1.3
date	2013.09.05.14.01.01;	author jsg;	state Exp;
branches;
next	1.2;

1.2
date	2012.08.17.13.58.06;	author mpi;	state Exp;
branches;
next	1.1;

1.1
date	2011.10.23.13.29.28;	author matthieu;	state Exp;
branches
	1.1.1.1;
next	;

1.1.1.1
date	2011.10.23.13.29.28;	author matthieu;	state Exp;
branches;
next	1.1.1.2;

1.1.1.2
date	2013.09.05.13.12.22;	author jsg;	state Exp;
branches;
next	1.1.1.3;

1.1.1.3
date	2014.07.09.20.34.10;	author jsg;	state Exp;
branches;
next	1.1.1.4;
commitid	3JhLfwcuBALP0ZR7;

1.1.1.4
date	2015.01.25.14.08.18;	author jsg;	state Exp;
branches;
next	1.1.1.5;
commitid	ce2W5rH5aF7VS9gi;

1.1.1.5
date	2015.02.20.22.45.30;	author jsg;	state Exp;
branches;
next	;
commitid	F54a1i0WXHMxq7kE;


desc
@@


1.8
log
@remove the now unused Mesa 10.2.9 code
@
text
@/*
 * Copyright 2010 Jerome Glisse <glisse@@freedesktop.org>
 *
 * Permission is hereby granted, free of charge, to any person obtaining a
 * copy of this software and associated documentation files (the "Software"),
 * to deal in the Software without restriction, including without limitation
 * on the rights to use, copy, modify, merge, publish, distribute, sub
 * license, and/or sell copies of the Software, and to permit persons to whom
 * the Software is furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice (including the next
 * paragraph) shall be included in all copies or substantial portions of the
 * Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL
 * THE AUTHOR(S) AND/OR THEIR SUPPLIERS BE LIABLE FOR ANY CLAIM,
 * DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
 * OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
 * USE OR OTHER DEALINGS IN THE SOFTWARE.
 */
#include "r600_pipe.h"
#include "r600_public.h"
#include "r600_isa.h"
#include "evergreen_compute.h"
#include "r600d.h"

#include "sb/sb_public.h"

#include <errno.h>
#include "pipe/p_shader_tokens.h"
#include "util/u_blitter.h"
#include "util/u_debug.h"
#include "util/u_memory.h"
#include "util/u_simple_shaders.h"
#include "util/u_upload_mgr.h"
#include "util/u_math.h"
#include "vl/vl_decoder.h"
#include "vl/vl_video_buffer.h"
#include "radeon/radeon_video.h"
#include "radeon/radeon_uvd.h"
#include "os/os_time.h"

static const struct debug_named_value r600_debug_options[] = {
	/* features */
#if defined(R600_USE_LLVM)
	{ "llvm", DBG_LLVM, "Enable the LLVM shader compiler" },
#endif
	{ "nocpdma", DBG_NO_CP_DMA, "Disable CP DMA" },

	/* shader backend */
	{ "nosb", DBG_NO_SB, "Disable sb backend for graphics shaders" },
	{ "sbcl", DBG_SB_CS, "Enable sb backend for compute shaders" },
	{ "sbdry", DBG_SB_DRY_RUN, "Don't use optimized bytecode (just print the dumps)" },
	{ "sbstat", DBG_SB_STAT, "Print optimization statistics for shaders" },
	{ "sbdump", DBG_SB_DUMP, "Print IR dumps after some optimization passes" },
	{ "sbnofallback", DBG_SB_NO_FALLBACK, "Abort on errors instead of fallback" },
	{ "sbdisasm", DBG_SB_DISASM, "Use sb disassembler for shader dumps" },
	{ "sbsafemath", DBG_SB_SAFEMATH, "Disable unsafe math optimizations" },

	DEBUG_NAMED_VALUE_END /* must be last */
};

/*
 * pipe_context
 */

static void r600_destroy_context(struct pipe_context *context)
{
	struct r600_context *rctx = (struct r600_context *)context;

	r600_isa_destroy(rctx->isa);

	r600_sb_context_destroy(rctx->sb_context);

	pipe_resource_reference((struct pipe_resource**)&rctx->dummy_cmask, NULL);
	pipe_resource_reference((struct pipe_resource**)&rctx->dummy_fmask, NULL);

	if (rctx->dummy_pixel_shader) {
		rctx->b.b.delete_fs_state(&rctx->b.b, rctx->dummy_pixel_shader);
	}
	if (rctx->custom_dsa_flush) {
		rctx->b.b.delete_depth_stencil_alpha_state(&rctx->b.b, rctx->custom_dsa_flush);
	}
	if (rctx->custom_blend_resolve) {
		rctx->b.b.delete_blend_state(&rctx->b.b, rctx->custom_blend_resolve);
	}
	if (rctx->custom_blend_decompress) {
		rctx->b.b.delete_blend_state(&rctx->b.b, rctx->custom_blend_decompress);
	}
	if (rctx->custom_blend_fastclear) {
		rctx->b.b.delete_blend_state(&rctx->b.b, rctx->custom_blend_fastclear);
	}
	util_unreference_framebuffer_state(&rctx->framebuffer.state);

	if (rctx->blitter) {
		util_blitter_destroy(rctx->blitter);
	}
	if (rctx->allocator_fetch_shader) {
		u_suballocator_destroy(rctx->allocator_fetch_shader);
	}

	r600_release_command_buffer(&rctx->start_cs_cmd);

	FREE(rctx->start_compute_cs_cmd.buf);

	r600_common_context_cleanup(&rctx->b);
	FREE(rctx);
}

static struct pipe_context *r600_create_context(struct pipe_screen *screen, void *priv)
{
	struct r600_context *rctx = CALLOC_STRUCT(r600_context);
	struct r600_screen* rscreen = (struct r600_screen *)screen;
	struct radeon_winsys *ws = rscreen->b.ws;

	if (rctx == NULL)
		return NULL;

	rctx->b.b.screen = screen;
	rctx->b.b.priv = priv;
	rctx->b.b.destroy = r600_destroy_context;

	if (!r600_common_context_init(&rctx->b, &rscreen->b))
		goto fail;

	rctx->screen = rscreen;
	rctx->keep_tiling_flags = rscreen->b.info.drm_minor >= 12;

	r600_init_blit_functions(rctx);

	if (rscreen->b.info.has_uvd) {
		rctx->b.b.create_video_codec = r600_uvd_create_decoder;
		rctx->b.b.create_video_buffer = r600_video_buffer_create;
	} else {
		rctx->b.b.create_video_codec = vl_create_decoder;
		rctx->b.b.create_video_buffer = vl_video_buffer_create;
	}

	r600_init_common_state_functions(rctx);

	switch (rctx->b.chip_class) {
	case R600:
	case R700:
		r600_init_state_functions(rctx);
		r600_init_atom_start_cs(rctx);
		rctx->custom_dsa_flush = r600_create_db_flush_dsa(rctx);
		rctx->custom_blend_resolve = rctx->b.chip_class == R700 ? r700_create_resolve_blend(rctx)
								      : r600_create_resolve_blend(rctx);
		rctx->custom_blend_decompress = r600_create_decompress_blend(rctx);
		rctx->has_vertex_cache = !(rctx->b.family == CHIP_RV610 ||
					   rctx->b.family == CHIP_RV620 ||
					   rctx->b.family == CHIP_RS780 ||
					   rctx->b.family == CHIP_RS880 ||
					   rctx->b.family == CHIP_RV710);
		break;
	case EVERGREEN:
	case CAYMAN:
		evergreen_init_state_functions(rctx);
		evergreen_init_atom_start_cs(rctx);
		evergreen_init_atom_start_compute_cs(rctx);
		rctx->custom_dsa_flush = evergreen_create_db_flush_dsa(rctx);
		rctx->custom_blend_resolve = evergreen_create_resolve_blend(rctx);
		rctx->custom_blend_decompress = evergreen_create_decompress_blend(rctx);
		rctx->custom_blend_fastclear = evergreen_create_fastclear_blend(rctx);
		rctx->has_vertex_cache = !(rctx->b.family == CHIP_CEDAR ||
					   rctx->b.family == CHIP_PALM ||
					   rctx->b.family == CHIP_SUMO ||
					   rctx->b.family == CHIP_SUMO2 ||
					   rctx->b.family == CHIP_CAICOS ||
					   rctx->b.family == CHIP_CAYMAN ||
					   rctx->b.family == CHIP_ARUBA);
		break;
	default:
		R600_ERR("Unsupported chip class %d.\n", rctx->b.chip_class);
		goto fail;
	}

	rctx->b.rings.gfx.cs = ws->cs_create(ws, RING_GFX,
					     r600_context_gfx_flush, rctx,
					     rscreen->b.trace_bo ?
						     rscreen->b.trace_bo->cs_buf : NULL);
	rctx->b.rings.gfx.flush = r600_context_gfx_flush;

	rctx->allocator_fetch_shader = u_suballocator_create(&rctx->b.b, 64 * 1024, 256,
							     0, PIPE_USAGE_DEFAULT, FALSE);
	if (!rctx->allocator_fetch_shader)
		goto fail;

	rctx->isa = calloc(1, sizeof(struct r600_isa));
	if (!rctx->isa || r600_isa_init(rctx, rctx->isa))
		goto fail;

	rctx->blitter = util_blitter_create(&rctx->b.b);
	if (rctx->blitter == NULL)
		goto fail;
	util_blitter_set_texture_multisample(rctx->blitter, rscreen->has_msaa);
	rctx->blitter->draw_rectangle = r600_draw_rectangle;

	r600_begin_new_cs(rctx);
	r600_query_init_backend_mask(&rctx->b); /* this emits commands and must be last */

	rctx->dummy_pixel_shader =
		util_make_fragment_cloneinput_shader(&rctx->b.b, 0,
						     TGSI_SEMANTIC_GENERIC,
						     TGSI_INTERPOLATE_CONSTANT);
	rctx->b.b.bind_fs_state(&rctx->b.b, rctx->dummy_pixel_shader);

	return &rctx->b.b;

fail:
	r600_destroy_context(&rctx->b.b);
	return NULL;
}

/*
 * pipe_screen
 */

static int r600_get_param(struct pipe_screen* pscreen, enum pipe_cap param)
{
	struct r600_screen *rscreen = (struct r600_screen *)pscreen;
	enum radeon_family family = rscreen->b.family;

	switch (param) {
	/* Supported features (boolean caps). */
	case PIPE_CAP_NPOT_TEXTURES:
	case PIPE_CAP_MIXED_FRAMEBUFFER_SIZES:
	case PIPE_CAP_TWO_SIDED_STENCIL:
	case PIPE_CAP_ANISOTROPIC_FILTER:
	case PIPE_CAP_POINT_SPRITE:
	case PIPE_CAP_OCCLUSION_QUERY:
	case PIPE_CAP_TEXTURE_SHADOW_MAP:
	case PIPE_CAP_TEXTURE_MIRROR_CLAMP:
	case PIPE_CAP_BLEND_EQUATION_SEPARATE:
	case PIPE_CAP_TEXTURE_SWIZZLE:
	case PIPE_CAP_DEPTH_CLIP_DISABLE:
	case PIPE_CAP_SHADER_STENCIL_EXPORT:
	case PIPE_CAP_VERTEX_ELEMENT_INSTANCE_DIVISOR:
	case PIPE_CAP_MIXED_COLORBUFFER_FORMATS:
	case PIPE_CAP_TGSI_FS_COORD_ORIGIN_UPPER_LEFT:
	case PIPE_CAP_TGSI_FS_COORD_PIXEL_CENTER_HALF_INTEGER:
	case PIPE_CAP_SM3:
	case PIPE_CAP_SEAMLESS_CUBE_MAP:
	case PIPE_CAP_PRIMITIVE_RESTART:
	case PIPE_CAP_CONDITIONAL_RENDER:
	case PIPE_CAP_TEXTURE_BARRIER:
	case PIPE_CAP_VERTEX_COLOR_UNCLAMPED:
	case PIPE_CAP_QUADS_FOLLOW_PROVOKING_VERTEX_CONVENTION:
	case PIPE_CAP_TGSI_INSTANCEID:
	case PIPE_CAP_VERTEX_BUFFER_OFFSET_4BYTE_ALIGNED_ONLY:
	case PIPE_CAP_VERTEX_BUFFER_STRIDE_4BYTE_ALIGNED_ONLY:
	case PIPE_CAP_VERTEX_ELEMENT_SRC_OFFSET_4BYTE_ALIGNED_ONLY:
	case PIPE_CAP_USER_INDEX_BUFFERS:
	case PIPE_CAP_USER_CONSTANT_BUFFERS:
	case PIPE_CAP_START_INSTANCE:
	case PIPE_CAP_MAX_DUAL_SOURCE_RENDER_TARGETS:
	case PIPE_CAP_TEXTURE_BUFFER_OBJECTS:
        case PIPE_CAP_PREFER_BLIT_BASED_TEXTURE_TRANSFER:
	case PIPE_CAP_QUERY_PIPELINE_STATISTICS:
	case PIPE_CAP_TEXTURE_MULTISAMPLE:
        case PIPE_CAP_BUFFER_MAP_PERSISTENT_COHERENT:
		return 1;

	case PIPE_CAP_COMPUTE:
		return rscreen->b.chip_class > R700;

	case PIPE_CAP_TGSI_TEXCOORD:
		return 0;

	case PIPE_CAP_FAKE_SW_MSAA:
		return 0;

	case PIPE_CAP_MAX_TEXTURE_BUFFER_SIZE:
		return MIN2(rscreen->b.info.vram_size, 0xFFFFFFFF);

        case PIPE_CAP_MIN_MAP_BUFFER_ALIGNMENT:
                return R600_MAP_BUFFER_ALIGNMENT;

	case PIPE_CAP_CONSTANT_BUFFER_OFFSET_ALIGNMENT:
		return 256;

	case PIPE_CAP_TEXTURE_BUFFER_OFFSET_ALIGNMENT:
		return 1;

	case PIPE_CAP_GLSL_FEATURE_LEVEL:
		if (family >= CHIP_CEDAR)
		   return 330;
		/* pre-evergreen geom shaders need newer kernel */
		if (rscreen->b.info.drm_minor >= 37)
		   return 330;
		return 140;

	/* Supported except the original R600. */
	case PIPE_CAP_INDEP_BLEND_ENABLE:
	case PIPE_CAP_INDEP_BLEND_FUNC:
		/* R600 doesn't support per-MRT blends */
		return family == CHIP_R600 ? 0 : 1;

	/* Supported on Evergreen. */
	case PIPE_CAP_SEAMLESS_CUBE_MAP_PER_TEXTURE:
	case PIPE_CAP_CUBE_MAP_ARRAY:
	case PIPE_CAP_TGSI_VS_LAYER:
		return family >= CHIP_CEDAR ? 1 : 0;

	/* Unsupported features. */
	case PIPE_CAP_TGSI_FS_COORD_ORIGIN_LOWER_LEFT:
	case PIPE_CAP_TGSI_FS_COORD_PIXEL_CENTER_INTEGER:
	case PIPE_CAP_TGSI_CAN_COMPACT_CONSTANTS:
	case PIPE_CAP_FRAGMENT_COLOR_CLAMPED:
	case PIPE_CAP_VERTEX_COLOR_CLAMPED:
	case PIPE_CAP_USER_VERTEX_BUFFERS:
	case PIPE_CAP_MAX_TEXTURE_GATHER_COMPONENTS:
	case PIPE_CAP_TEXTURE_GATHER_SM5:
	case PIPE_CAP_TEXTURE_QUERY_LOD:
        case PIPE_CAP_SAMPLE_SHADING:
		return 0;

	/* Stream output. */
	case PIPE_CAP_MAX_STREAM_OUTPUT_BUFFERS:
		return rscreen->b.has_streamout ? 4 : 0;
	case PIPE_CAP_STREAM_OUTPUT_PAUSE_RESUME:
		return rscreen->b.has_streamout ? 1 : 0;
	case PIPE_CAP_MAX_STREAM_OUTPUT_SEPARATE_COMPONENTS:
	case PIPE_CAP_MAX_STREAM_OUTPUT_INTERLEAVED_COMPONENTS:
		return 32*4;

	/* Geometry shader output. */
	case PIPE_CAP_MAX_GEOMETRY_OUTPUT_VERTICES:
		return 1024;
	case PIPE_CAP_MAX_GEOMETRY_TOTAL_OUTPUT_COMPONENTS:
		return 16384;

	/* Texturing. */
	case PIPE_CAP_MAX_TEXTURE_2D_LEVELS:
	case PIPE_CAP_MAX_TEXTURE_CUBE_LEVELS:
		if (family >= CHIP_CEDAR)
			return 15;
		else
			return 14;
	case PIPE_CAP_MAX_TEXTURE_3D_LEVELS:
		/* textures support 8192, but layered rendering supports 2048 */
		return 12;
	case PIPE_CAP_MAX_TEXTURE_ARRAY_LAYERS:
		/* textures support 8192, but layered rendering supports 2048 */
		return rscreen->b.info.drm_minor >= 9 ? 2048 : 0;

	/* Render targets. */
	case PIPE_CAP_MAX_RENDER_TARGETS:
		/* XXX some r6xx are buggy and can only do 4 */
		return 8;

	case PIPE_CAP_MAX_VIEWPORTS:
		return 16;

	/* Timer queries, present when the clock frequency is non zero. */
	case PIPE_CAP_QUERY_TIME_ELAPSED:
		return rscreen->b.info.r600_clock_crystal_freq != 0;
	case PIPE_CAP_QUERY_TIMESTAMP:
		return rscreen->b.info.drm_minor >= 20 &&
		       rscreen->b.info.r600_clock_crystal_freq != 0;

	case PIPE_CAP_MIN_TEXTURE_GATHER_OFFSET:
	case PIPE_CAP_MIN_TEXEL_OFFSET:
		return -8;

	case PIPE_CAP_MAX_TEXTURE_GATHER_OFFSET:
	case PIPE_CAP_MAX_TEXEL_OFFSET:
		return 7;

	case PIPE_CAP_TEXTURE_BORDER_COLOR_QUIRK:
		return PIPE_QUIRK_TEXTURE_BORDER_COLOR_SWIZZLE_R600;
	case PIPE_CAP_ENDIANNESS:
		return PIPE_ENDIAN_LITTLE;

	case PIPE_CAP_VENDOR_ID:
		return 0x1002;
	case PIPE_CAP_DEVICE_ID:
		return rscreen->b.info.pci_id;
	case PIPE_CAP_ACCELERATED:
		return 1;
	case PIPE_CAP_VIDEO_MEMORY:
		return rscreen->b.info.vram_size >> 20;
	case PIPE_CAP_UMA:
		return 0;
	}
	return 0;
}

static int r600_get_shader_param(struct pipe_screen* pscreen, unsigned shader, enum pipe_shader_cap param)
{
	struct r600_screen *rscreen = (struct r600_screen *)pscreen;

	switch(shader)
	{
	case PIPE_SHADER_FRAGMENT:
	case PIPE_SHADER_VERTEX:
	case PIPE_SHADER_COMPUTE:
		break;
	case PIPE_SHADER_GEOMETRY:
		if (rscreen->b.family >= CHIP_CEDAR)
			break;
		/* pre-evergreen geom shaders need newer kernel */
		if (rscreen->b.info.drm_minor >= 37)
			break;
		return 0;
	default:
		/* XXX: support tessellation on Evergreen */
		return 0;
	}

	switch (param) {
	case PIPE_SHADER_CAP_MAX_INSTRUCTIONS:
	case PIPE_SHADER_CAP_MAX_ALU_INSTRUCTIONS:
	case PIPE_SHADER_CAP_MAX_TEX_INSTRUCTIONS:
	case PIPE_SHADER_CAP_MAX_TEX_INDIRECTIONS:
		return 16384;
	case PIPE_SHADER_CAP_MAX_CONTROL_FLOW_DEPTH:
		return 32;
	case PIPE_SHADER_CAP_MAX_INPUTS:
		return 32;
	case PIPE_SHADER_CAP_MAX_TEMPS:
		return 256; /* Max native temporaries. */
	case PIPE_SHADER_CAP_MAX_ADDRS:
		/* XXX Isn't this equal to TEMPS? */
		return 1; /* Max native address registers */
	case PIPE_SHADER_CAP_MAX_CONSTS:
		return R600_MAX_CONST_BUFFER_SIZE;
	case PIPE_SHADER_CAP_MAX_CONST_BUFFERS:
		return R600_MAX_USER_CONST_BUFFERS;
	case PIPE_SHADER_CAP_MAX_PREDS:
		return 0; /* nothing uses this */
	case PIPE_SHADER_CAP_TGSI_CONT_SUPPORTED:
		return 1;
	case PIPE_SHADER_CAP_TGSI_SQRT_SUPPORTED:
		return 0;
	case PIPE_SHADER_CAP_INDIRECT_INPUT_ADDR:
	case PIPE_SHADER_CAP_INDIRECT_OUTPUT_ADDR:
	case PIPE_SHADER_CAP_INDIRECT_TEMP_ADDR:
	case PIPE_SHADER_CAP_INDIRECT_CONST_ADDR:
		return 1;
	case PIPE_SHADER_CAP_SUBROUTINES:
		return 0;
	case PIPE_SHADER_CAP_INTEGERS:
		return 1;
	case PIPE_SHADER_CAP_MAX_TEXTURE_SAMPLERS:
	case PIPE_SHADER_CAP_MAX_SAMPLER_VIEWS:
		return 16;
        case PIPE_SHADER_CAP_PREFERRED_IR:
		if (shader == PIPE_SHADER_COMPUTE) {
			return PIPE_SHADER_IR_LLVM;
		} else {
			return PIPE_SHADER_IR_TGSI;
		}
	}
	return 0;
}

static void r600_destroy_screen(struct pipe_screen* pscreen)
{
	struct r600_screen *rscreen = (struct r600_screen *)pscreen;

	if (rscreen == NULL)
		return;

	if (!rscreen->b.ws->unref(rscreen->b.ws))
		return;

	if (rscreen->global_pool) {
		compute_memory_pool_delete(rscreen->global_pool);
	}

	r600_destroy_common_screen(&rscreen->b);
}

static struct pipe_resource *r600_resource_create(struct pipe_screen *screen,
						  const struct pipe_resource *templ)
{
	if (templ->target == PIPE_BUFFER &&
	    (templ->bind & PIPE_BIND_GLOBAL))
		return r600_compute_global_buffer_create(screen, templ);

	return r600_resource_create_common(screen, templ);
}

struct pipe_screen *r600_screen_create(struct radeon_winsys *ws)
{
	struct r600_screen *rscreen = CALLOC_STRUCT(r600_screen);

	if (rscreen == NULL) {
		return NULL;
	}

	/* Set functions first. */
	rscreen->b.b.context_create = r600_create_context;
	rscreen->b.b.destroy = r600_destroy_screen;
	rscreen->b.b.get_param = r600_get_param;
	rscreen->b.b.get_shader_param = r600_get_shader_param;
	rscreen->b.b.resource_create = r600_resource_create;

	if (!r600_common_screen_init(&rscreen->b, ws)) {
		FREE(rscreen);
		return NULL;
	}

	if (rscreen->b.info.chip_class >= EVERGREEN) {
		rscreen->b.b.is_format_supported = evergreen_is_format_supported;
	} else {
		rscreen->b.b.is_format_supported = r600_is_format_supported;
	}

	rscreen->b.debug_flags |= debug_get_flags_option("R600_DEBUG", r600_debug_options, 0);
	if (debug_get_bool_option("R600_DEBUG_COMPUTE", FALSE))
		rscreen->b.debug_flags |= DBG_COMPUTE;
	if (debug_get_bool_option("R600_DUMP_SHADERS", FALSE))
		rscreen->b.debug_flags |= DBG_FS | DBG_VS | DBG_GS | DBG_PS | DBG_CS;
	if (debug_get_bool_option("R600_HYPERZ", FALSE))
		rscreen->b.debug_flags |= DBG_HYPERZ;
	if (debug_get_bool_option("R600_LLVM", FALSE))
		rscreen->b.debug_flags |= DBG_LLVM;

	if (rscreen->b.family == CHIP_UNKNOWN) {
		fprintf(stderr, "r600: Unknown chipset 0x%04X\n", rscreen->b.info.pci_id);
		FREE(rscreen);
		return NULL;
	}

	/* Figure out streamout kernel support. */
	switch (rscreen->b.chip_class) {
	case R600:
		if (rscreen->b.family < CHIP_RS780) {
			rscreen->b.has_streamout = rscreen->b.info.drm_minor >= 14;
		} else {
			rscreen->b.has_streamout = rscreen->b.info.drm_minor >= 23;
		}
		break;
	case R700:
		rscreen->b.has_streamout = rscreen->b.info.drm_minor >= 17;
		break;
	case EVERGREEN:
	case CAYMAN:
		rscreen->b.has_streamout = rscreen->b.info.drm_minor >= 14;
		break;
	default:
		rscreen->b.has_streamout = FALSE;
		break;
	}

	/* MSAA support. */
	switch (rscreen->b.chip_class) {
	case R600:
	case R700:
		rscreen->has_msaa = rscreen->b.info.drm_minor >= 22;
		rscreen->has_compressed_msaa_texturing = false;
		break;
	case EVERGREEN:
		rscreen->has_msaa = rscreen->b.info.drm_minor >= 19;
		rscreen->has_compressed_msaa_texturing = rscreen->b.info.drm_minor >= 24;
		break;
	case CAYMAN:
		rscreen->has_msaa = rscreen->b.info.drm_minor >= 19;
		rscreen->has_compressed_msaa_texturing = true;
		break;
	default:
		rscreen->has_msaa = FALSE;
		rscreen->has_compressed_msaa_texturing = false;
	}

	rscreen->b.has_cp_dma = rscreen->b.info.drm_minor >= 27 &&
			      !(rscreen->b.debug_flags & DBG_NO_CP_DMA);

	rscreen->global_pool = compute_memory_pool_new(rscreen);

	/* Create the auxiliary context. This must be done last. */
	rscreen->b.aux_context = rscreen->b.b.context_create(&rscreen->b.b, NULL);

#if 0 /* This is for testing whether aux_context and buffer clearing work correctly. */
	struct pipe_resource templ = {};

	templ.width0 = 4;
	templ.height0 = 2048;
	templ.depth0 = 1;
	templ.array_size = 1;
	templ.target = PIPE_TEXTURE_2D;
	templ.format = PIPE_FORMAT_R8G8B8A8_UNORM;
	templ.usage = PIPE_USAGE_DEFAULT;

	struct r600_resource *res = r600_resource(rscreen->screen.resource_create(&rscreen->screen, &templ));
	unsigned char *map = ws->buffer_map(res->cs_buf, NULL, PIPE_TRANSFER_WRITE);

	memset(map, 0, 256);

	r600_screen_clear_buffer(rscreen, &res->b.b, 4, 4, 0xCC);
	r600_screen_clear_buffer(rscreen, &res->b.b, 8, 4, 0xDD);
	r600_screen_clear_buffer(rscreen, &res->b.b, 12, 4, 0xEE);
	r600_screen_clear_buffer(rscreen, &res->b.b, 20, 4, 0xFF);
	r600_screen_clear_buffer(rscreen, &res->b.b, 32, 20, 0x87);

	ws->buffer_wait(res->buf, RADEON_USAGE_WRITE);

	int i;
	for (i = 0; i < 256; i++) {
		printf("%02X", map[i]);
		if (i % 16 == 15)
			printf("\n");
	}
#endif

	return &rscreen->b.b;
}
@


1.7
log
@Backport support for GLX_MESA_query_renderer for non Intel drivers.
This is desirable as the chromium port now uses this extension to
obtain pci vendor/device ids for use in feature/extension blacklists.

Prompted by a mail from byrnet@@, tested on r600g by krw@@

The newly added os_get_total_physical_memory() was passing the length of
a pointer rather than the type which made the sysctl call fail on
non 64 bit archs.  And it was passing the wrong pointer for the result.
Fixes for these problems have been submitted back upstream.
@
text
@@


1.6
log
@Merge Mesa 10.2.9
@
text
@d376 11
@


1.5
log
@Merge Mesa 10.4.3
Tested by matthieu@@ mpi@@ and myself.  landry@@ ran a ports bulk build.
kettenis@@ tracked down the cause of an alignment fault on archs
that require strict eight byte pointer alignment.
@
text
@d33 1
a194 3
	if (rscreen->b.debug_flags & DBG_FORCE_DMA)
		rctx->b.b.resource_copy_region = rctx->b.dma_copy;

d263 1
a263 5
	case PIPE_CAP_BUFFER_MAP_PERSISTENT_COHERENT:
	case PIPE_CAP_TGSI_VS_WINDOW_SPACE_POSITION:
	case PIPE_CAP_TGSI_VS_LAYER_VIEWPORT:
	case PIPE_CAP_SAMPLE_SHADING:
	case PIPE_CAP_CLIP_HALFZ:
d304 1
a304 3
	case PIPE_CAP_TEXTURE_GATHER_SM5:
	case PIPE_CAP_TEXTURE_QUERY_LOD:
	case PIPE_CAP_TGSI_FS_FINE_DERIVATIVE:
a305 2
	case PIPE_CAP_MAX_TEXTURE_GATHER_COMPONENTS:
		return family >= CHIP_CEDAR ? 4 : 0;
d314 4
a317 4
	case PIPE_CAP_TEXTURE_GATHER_OFFSETS:
	case PIPE_CAP_DRAW_INDIRECT:
	case PIPE_CAP_CONDITIONAL_RENDER_INVERTED:
	case PIPE_CAP_SAMPLER_VIEW_TARGET:
a333 5
	case PIPE_CAP_MAX_VERTEX_STREAMS:
		return 1;

	case PIPE_CAP_MAX_VERTEX_ATTRIB_STRIDE:
		return 2047;
a375 11

	case PIPE_CAP_VENDOR_ID:
		return 0x1002;
	case PIPE_CAP_DEVICE_ID:
		return rscreen->b.info.pci_id;
	case PIPE_CAP_ACCELERATED:
		return 1;
	case PIPE_CAP_VIDEO_MEMORY:
		return rscreen->b.info.vram_size >> 20;
	case PIPE_CAP_UMA:
		return 0;
d411 1
a411 3
		return shader == PIPE_SHADER_VERTEX ? 16 : 32;
	case PIPE_SHADER_CAP_MAX_OUTPUTS:
		return shader == PIPE_SHADER_FRAGMENT ? 8 : 32;
d414 5
a418 11
	case PIPE_SHADER_CAP_MAX_CONST_BUFFER_SIZE:
		if (shader == PIPE_SHADER_COMPUTE) {
			uint64_t max_const_buffer_size;
			pscreen->get_compute_param(pscreen,
				PIPE_COMPUTE_CAP_MAX_MEM_ALLOC_SIZE,
				&max_const_buffer_size);
			return max_const_buffer_size;

		} else {
			return R600_MAX_CONST_BUFFER_SIZE;
		}
d426 1
a426 1
		return 1;
a440 1
#if HAVE_LLVM < 0x0306
a441 3
#else
			return PIPE_SHADER_IR_NATIVE;
#endif
a444 2
	case PIPE_SHADER_CAP_DOUBLES:
		return 0;
d507 2
a508 2
	if (!debug_get_bool_option("R600_HYPERZ", TRUE))
		rscreen->b.debug_flags |= DBG_NO_HYPERZ;
@


1.4
log
@Merge Mesa 10.2.3
tested by matthieu@@ kettenis@@ mpi@@ brett@@ and myself across a
diverse range of hardware
@
text
@a32 1
#include "util/u_blitter.h"
d194 3
d265 5
a269 1
        case PIPE_CAP_BUFFER_MAP_PERSISTENT_COHERENT:
d310 3
a312 1
	case PIPE_CAP_TGSI_VS_LAYER:
d314 2
d324 4
a327 4
	case PIPE_CAP_MAX_TEXTURE_GATHER_COMPONENTS:
	case PIPE_CAP_TEXTURE_GATHER_SM5:
	case PIPE_CAP_TEXTURE_QUERY_LOD:
        case PIPE_CAP_SAMPLE_SHADING:
d344 5
d391 11
d437 3
a439 1
		return 32;
d442 11
a452 5
	case PIPE_SHADER_CAP_MAX_ADDRS:
		/* XXX Isn't this equal to TEMPS? */
		return 1; /* Max native address registers */
	case PIPE_SHADER_CAP_MAX_CONSTS:
		return R600_MAX_CONST_BUFFER_SIZE;
d460 1
a460 1
		return 0;
d475 1
d477 3
d483 2
d547 2
a548 2
	if (debug_get_bool_option("R600_HYPERZ", FALSE))
		rscreen->b.debug_flags |= DBG_HYPERZ;
@


1.3
log
@Merge Mesa 9.2.0
@
text
@a34 1
#include "util/u_format_s3tc.h"
d41 1
d45 1
a45 14
static const struct debug_named_value debug_options[] = {
	/* logging */
	{ "texdepth", DBG_TEX_DEPTH, "Print texture depth info" },
	{ "compute", DBG_COMPUTE, "Print compute info" },
	{ "vm", DBG_VM, "Print virtual addresses when creating resources" },
	{ "trace_cs", DBG_TRACE_CS, "Trace cs and write rlockup_<csid>.c file with faulty cs" },

	/* shaders */
	{ "fs", DBG_FS, "Print fetch shaders" },
	{ "vs", DBG_VS, "Print vertex shaders" },
	{ "gs", DBG_GS, "Print geometry shaders" },
	{ "ps", DBG_PS, "Print pixel shaders" },
	{ "cs", DBG_CS, "Print compute shaders" },

a46 1
	{ "nohyperz", DBG_NO_HYPERZ, "Disable Hyper-Z" },
d48 1
a48 1
	{ "nollvm", DBG_NO_LLVM, "Disable the LLVM shader compiler" },
a50 3
	{ "nodma", DBG_NO_ASYNC_DMA, "Disable asynchronous DMA" },
	/* GL uses the word INVALIDATE, gallium uses the word DISCARD */
	{ "noinvalrange", DBG_NO_DISCARD_RANGE, "Disable handling of INVALIDATE_RANGE map flags" },
d53 2
a54 2
	{ "sb", DBG_SB, "Enable optimization of graphics shaders" },
	{ "sbcl", DBG_SB_CS, "Enable optimization of compute shaders" },
a67 234
static struct r600_fence *r600_create_fence(struct r600_context *rctx)
{
	struct r600_screen *rscreen = rctx->screen;
	struct r600_fence *fence = NULL;

	pipe_mutex_lock(rscreen->fences.mutex);

	if (!rscreen->fences.bo) {
		/* Create the shared buffer object */
		rscreen->fences.bo = (struct r600_resource*)
			pipe_buffer_create(&rscreen->screen, PIPE_BIND_CUSTOM,
					   PIPE_USAGE_STAGING, 4096);
		if (!rscreen->fences.bo) {
			R600_ERR("r600: failed to create bo for fence objects\n");
			goto out;
		}
		rscreen->fences.data = r600_buffer_mmap_sync_with_rings(rctx, rscreen->fences.bo, PIPE_TRANSFER_READ_WRITE);
	}

	if (!LIST_IS_EMPTY(&rscreen->fences.pool)) {
		struct r600_fence *entry;

		/* Try to find a freed fence that has been signalled */
		LIST_FOR_EACH_ENTRY(entry, &rscreen->fences.pool, head) {
			if (rscreen->fences.data[entry->index] != 0) {
				LIST_DELINIT(&entry->head);
				fence = entry;
				break;
			}
		}
	}

	if (!fence) {
		/* Allocate a new fence */
		struct r600_fence_block *block;
		unsigned index;

		if ((rscreen->fences.next_index + 1) >= 1024) {
			R600_ERR("r600: too many concurrent fences\n");
			goto out;
		}

		index = rscreen->fences.next_index++;

		if (!(index % FENCE_BLOCK_SIZE)) {
			/* Allocate a new block */
			block = CALLOC_STRUCT(r600_fence_block);
			if (block == NULL)
				goto out;

			LIST_ADD(&block->head, &rscreen->fences.blocks);
		} else {
			block = LIST_ENTRY(struct r600_fence_block, rscreen->fences.blocks.next, head);
		}

		fence = &block->fences[index % FENCE_BLOCK_SIZE];
		fence->index = index;
	}

	pipe_reference_init(&fence->reference, 1);

	rscreen->fences.data[fence->index] = 0;
	r600_context_emit_fence(rctx, rscreen->fences.bo, fence->index, 1);

	/* Create a dummy BO so that fence_finish without a timeout can sleep waiting for completion */
	fence->sleep_bo = (struct r600_resource*)
			pipe_buffer_create(&rctx->screen->screen, PIPE_BIND_CUSTOM,
					   PIPE_USAGE_STAGING, 1);
	/* Add the fence as a dummy relocation. */
	r600_context_bo_reloc(rctx, &rctx->rings.gfx, fence->sleep_bo, RADEON_USAGE_READWRITE);

out:
	pipe_mutex_unlock(rscreen->fences.mutex);
	return fence;
}

static void r600_flush(struct pipe_context *ctx, unsigned flags)
{
	struct r600_context *rctx = (struct r600_context *)ctx;
	struct pipe_query *render_cond = NULL;
	unsigned render_cond_mode = 0;
	boolean render_cond_cond = FALSE;

	if (rctx->rings.gfx.cs->cdw == rctx->initial_gfx_cs_size)
		return;

	rctx->rings.gfx.flushing = true;
	/* Disable render condition. */
	if (rctx->current_render_cond) {
		render_cond = rctx->current_render_cond;
		render_cond_cond = rctx->current_render_cond_cond;
		render_cond_mode = rctx->current_render_cond_mode;
		ctx->render_condition(ctx, NULL, FALSE, 0);
	}

	r600_context_flush(rctx, flags);
	rctx->rings.gfx.flushing = false;
	r600_begin_new_cs(rctx);

	/* Re-enable render condition. */
	if (render_cond) {
		ctx->render_condition(ctx, render_cond, render_cond_cond, render_cond_mode);
	}

	rctx->initial_gfx_cs_size = rctx->rings.gfx.cs->cdw;
}

static void r600_flush_from_st(struct pipe_context *ctx,
			       struct pipe_fence_handle **fence,
			       unsigned flags)
{
	struct r600_context *rctx = (struct r600_context *)ctx;
	struct r600_fence **rfence = (struct r600_fence**)fence;
	unsigned fflags;

	fflags = flags & PIPE_FLUSH_END_OF_FRAME ? RADEON_FLUSH_END_OF_FRAME : 0;
	if (rfence) {
		*rfence = r600_create_fence(rctx);
	}
	/* flush gfx & dma ring, order does not matter as only one can be live */
	if (rctx->rings.dma.cs) {
		rctx->rings.dma.flush(rctx, fflags);
	}
	rctx->rings.gfx.flush(rctx, fflags);
}

static void r600_flush_gfx_ring(void *ctx, unsigned flags)
{
	r600_flush((struct pipe_context*)ctx, flags);
}

static void r600_flush_dma_ring(void *ctx, unsigned flags)
{
	struct r600_context *rctx = (struct r600_context *)ctx;
	struct radeon_winsys_cs *cs = rctx->rings.dma.cs;
	unsigned padding_dw, i;

	if (!cs->cdw) {
		return;
	}

	/* Pad the DMA CS to a multiple of 8 dwords. */
	padding_dw = 8 - cs->cdw % 8;
	if (padding_dw < 8) {
		for (i = 0; i < padding_dw; i++) {
			cs->buf[cs->cdw++] = DMA_PACKET(DMA_PACKET_NOP, 0, 0, 0);
		}
	}

	rctx->rings.dma.flushing = true;
	rctx->ws->cs_flush(cs, flags, 0);
	rctx->rings.dma.flushing = false;
}

boolean r600_rings_is_buffer_referenced(struct r600_context *ctx,
					struct radeon_winsys_cs_handle *buf,
					enum radeon_bo_usage usage)
{
	if (ctx->ws->cs_is_buffer_referenced(ctx->rings.gfx.cs, buf, usage)) {
		return TRUE;
	}
	if (ctx->rings.dma.cs) {
		if (ctx->ws->cs_is_buffer_referenced(ctx->rings.dma.cs, buf, usage)) {
			return TRUE;
		}
	}
	return FALSE;
}

void *r600_buffer_mmap_sync_with_rings(struct r600_context *ctx,
					struct r600_resource *resource,
					unsigned usage)
{
	enum radeon_bo_usage rusage = RADEON_USAGE_READWRITE;
	unsigned flags = 0;
	bool sync_flush = TRUE;

	if (usage & PIPE_TRANSFER_UNSYNCHRONIZED) {
		return ctx->ws->buffer_map(resource->cs_buf, NULL, usage);
	}

	if (!(usage & PIPE_TRANSFER_WRITE)) {
		/* have to wait for pending read */
		rusage = RADEON_USAGE_WRITE;
	}
	if (usage & PIPE_TRANSFER_DONTBLOCK) {
		flags |= RADEON_FLUSH_ASYNC;
	}

	if (ctx->ws->cs_is_buffer_referenced(ctx->rings.gfx.cs, resource->cs_buf, rusage) && ctx->rings.gfx.cs->cdw) {
		ctx->rings.gfx.flush(ctx, flags);
		if (usage & PIPE_TRANSFER_DONTBLOCK) {
			return NULL;
		}
	}
	if (ctx->rings.dma.cs) {
		if (ctx->ws->cs_is_buffer_referenced(ctx->rings.dma.cs, resource->cs_buf, rusage) && ctx->rings.dma.cs->cdw) {
			ctx->rings.dma.flush(ctx, flags);
			if (usage & PIPE_TRANSFER_DONTBLOCK) {
				return NULL;
			}
		}
	}

	if (usage & PIPE_TRANSFER_DONTBLOCK) {
		if (ctx->ws->buffer_is_busy(resource->buf, rusage)) {
			return NULL;
		}
	}
	if (sync_flush) {
		/* Try to avoid busy-waiting in radeon_bo_wait. */
		ctx->ws->cs_sync_flush(ctx->rings.gfx.cs);
		if (ctx->rings.dma.cs) {
			ctx->ws->cs_sync_flush(ctx->rings.dma.cs);
		}
	}

	/* at this point everything is synchronized */
	return ctx->ws->buffer_map(resource->cs_buf, NULL, usage);
}

static void r600_flush_from_winsys(void *ctx, unsigned flags)
{
	struct r600_context *rctx = (struct r600_context *)ctx;

	rctx->rings.gfx.flush(rctx, flags);
}

static void r600_flush_dma_from_winsys(void *ctx, unsigned flags)
{
	struct r600_context *rctx = (struct r600_context *)ctx;

	rctx->rings.dma.flush(rctx, flags);
}
d81 1
a81 1
		rctx->context.delete_fs_state(&rctx->context, rctx->dummy_pixel_shader);
d84 1
a84 1
		rctx->context.delete_depth_stencil_alpha_state(&rctx->context, rctx->custom_dsa_flush);
d87 1
a87 1
		rctx->context.delete_blend_state(&rctx->context, rctx->custom_blend_resolve);
d90 4
a93 1
		rctx->context.delete_blend_state(&rctx->context, rctx->custom_blend_decompress);
a99 6
	if (rctx->uploader) {
		u_upload_destroy(rctx->uploader);
	}
	if (rctx->allocator_so_filled_size) {
		u_suballocator_destroy(rctx->allocator_so_filled_size);
	}
a102 1
	util_slab_destroy(&rctx->pool_transfers);
d106 1
a106 6
	if (rctx->rings.gfx.cs) {
		rctx->ws->cs_destroy(rctx->rings.gfx.cs);
	}
	if (rctx->rings.dma.cs) {
		rctx->ws->cs_destroy(rctx->rings.dma.cs);
	}
d108 1
d116 1
d121 6
a126 8
	util_slab_create(&rctx->pool_transfers,
			 sizeof(struct r600_transfer), 64,
			 UTIL_SLAB_SINGLETHREADED);

	rctx->context.screen = screen;
	rctx->context.priv = priv;
	rctx->context.destroy = r600_destroy_context;
	rctx->context.flush = r600_flush_from_st;
a127 1
	/* Easy accessing of screen/winsys. */
d129 1
a129 4
	rctx->ws = rscreen->ws;
	rctx->family = rscreen->family;
	rctx->chip_class = rscreen->chip_class;
	rctx->keep_tiling_flags = rscreen->info.drm_minor >= 12;
d131 1
a131 1
	LIST_INITHEAD(&rctx->active_nontimer_queries);
d133 3
a135 8
	r600_init_blit_functions(rctx);
	r600_init_query_functions(rctx);
	r600_init_context_resource_functions(rctx);
	r600_init_surface_functions(rctx);

	if (rscreen->info.has_uvd) {
		rctx->context.create_video_decoder = r600_uvd_create_decoder;
		rctx->context.create_video_buffer = r600_video_buffer_create;
d137 2
a138 2
		rctx->context.create_video_decoder = vl_create_decoder;
		rctx->context.create_video_buffer = vl_video_buffer_create;
d143 1
a143 1
	switch (rctx->chip_class) {
a147 1
		rctx->max_db = 4;
d149 1
a149 1
		rctx->custom_blend_resolve = rctx->chip_class == R700 ? r700_create_resolve_blend(rctx)
d152 5
a156 5
		rctx->has_vertex_cache = !(rctx->family == CHIP_RV610 ||
					   rctx->family == CHIP_RV620 ||
					   rctx->family == CHIP_RS780 ||
					   rctx->family == CHIP_RS880 ||
					   rctx->family == CHIP_RV710);
a162 1
		rctx->max_db = 8;
d166 8
a173 7
		rctx->has_vertex_cache = !(rctx->family == CHIP_CEDAR ||
					   rctx->family == CHIP_PALM ||
					   rctx->family == CHIP_SUMO ||
					   rctx->family == CHIP_SUMO2 ||
					   rctx->family == CHIP_CAICOS ||
					   rctx->family == CHIP_CAYMAN ||
					   rctx->family == CHIP_ARUBA);
d176 1
a176 1
		R600_ERR("Unsupported chip class %d.\n", rctx->chip_class);
d180 5
a184 22
	if (rscreen->trace_bo) {
		rctx->rings.gfx.cs = rctx->ws->cs_create(rctx->ws, RING_GFX, rscreen->trace_bo->cs_buf);
	} else {
		rctx->rings.gfx.cs = rctx->ws->cs_create(rctx->ws, RING_GFX, NULL);
	}
	rctx->rings.gfx.flush = r600_flush_gfx_ring;
	rctx->ws->cs_set_flush_callback(rctx->rings.gfx.cs, r600_flush_from_winsys, rctx);
	rctx->rings.gfx.flushing = false;

	rctx->rings.dma.cs = NULL;
	if (rscreen->info.r600_has_dma && !(rscreen->debug_flags & DBG_NO_ASYNC_DMA)) {
		rctx->rings.dma.cs = rctx->ws->cs_create(rctx->ws, RING_DMA, NULL);
		rctx->rings.dma.flush = r600_flush_dma_ring;
		rctx->ws->cs_set_flush_callback(rctx->rings.dma.cs, r600_flush_dma_from_winsys, rctx);
		rctx->rings.dma.flushing = false;
	}

	rctx->uploader = u_upload_create(&rctx->context, 1024 * 1024, 256,
					PIPE_BIND_INDEX_BUFFER |
					PIPE_BIND_CONSTANT_BUFFER);
	if (!rctx->uploader)
		goto fail;
d186 2
a187 2
	rctx->allocator_fetch_shader = u_suballocator_create(&rctx->context, 64 * 1024, 256,
							     0, PIPE_USAGE_STATIC, FALSE);
a190 5
	rctx->allocator_so_filled_size = u_suballocator_create(&rctx->context, 4096, 4,
								0, PIPE_USAGE_STATIC, TRUE);
	if (!rctx->allocator_so_filled_size)
		goto fail;

d195 1
a195 1
	rctx->blitter = util_blitter_create(&rctx->context);
d202 1
a202 1
	r600_get_backend_mask(rctx); /* this emits commands and must be last */
d205 1
a205 1
		util_make_fragment_cloneinput_shader(&rctx->context, 0,
d208 1
a208 1
	rctx->context.bind_fs_state(&rctx->context, rctx->dummy_pixel_shader);
d210 1
a210 1
	return &rctx->context;
d213 1
a213 1
	r600_destroy_context(&rctx->context);
a219 43
static const char* r600_get_vendor(struct pipe_screen* pscreen)
{
	return "X.Org";
}

static const char *r600_get_family_name(enum radeon_family family)
{
	switch(family) {
	case CHIP_R600: return "AMD R600";
	case CHIP_RV610: return "AMD RV610";
	case CHIP_RV630: return "AMD RV630";
	case CHIP_RV670: return "AMD RV670";
	case CHIP_RV620: return "AMD RV620";
	case CHIP_RV635: return "AMD RV635";
	case CHIP_RS780: return "AMD RS780";
	case CHIP_RS880: return "AMD RS880";
	case CHIP_RV770: return "AMD RV770";
	case CHIP_RV730: return "AMD RV730";
	case CHIP_RV710: return "AMD RV710";
	case CHIP_RV740: return "AMD RV740";
	case CHIP_CEDAR: return "AMD CEDAR";
	case CHIP_REDWOOD: return "AMD REDWOOD";
	case CHIP_JUNIPER: return "AMD JUNIPER";
	case CHIP_CYPRESS: return "AMD CYPRESS";
	case CHIP_HEMLOCK: return "AMD HEMLOCK";
	case CHIP_PALM: return "AMD PALM";
	case CHIP_SUMO: return "AMD SUMO";
	case CHIP_SUMO2: return "AMD SUMO2";
	case CHIP_BARTS: return "AMD BARTS";
	case CHIP_TURKS: return "AMD TURKS";
	case CHIP_CAICOS: return "AMD CAICOS";
	case CHIP_CAYMAN: return "AMD CAYMAN";
	case CHIP_ARUBA: return "AMD ARUBA";
	default: return "AMD unknown";
	}
}

static const char* r600_get_name(struct pipe_screen* pscreen)
{
	struct r600_screen *rscreen = (struct r600_screen *)pscreen;

	return r600_get_family_name(rscreen->family);
}
d224 1
a224 1
	enum radeon_family family = rscreen->family;
d229 1
a256 1
	case PIPE_CAP_COMPUTE:
d263 1
d266 3
d272 3
d276 1
a276 1
		return MIN2(rscreen->info.vram_size, 0xFFFFFFFF);
d288 5
d304 1
a309 1
	case PIPE_CAP_SCALED_RESOLVE:
d314 4
d322 1
a322 1
		return rscreen->has_streamout ? 4 : 0;
d324 1
a324 1
		return rscreen->has_streamout ? 1 : 0;
d329 6
a336 1
	case PIPE_CAP_MAX_TEXTURE_3D_LEVELS:
d342 3
d346 2
a347 4
		return rscreen->info.drm_minor >= 9 ?
			(family >= CHIP_CEDAR ? 16384 : 8192) : 0;
	case PIPE_CAP_MAX_COMBINED_SAMPLERS:
		return 32;
d354 3
d359 1
a359 1
		return rscreen->info.r600_clock_crystal_freq != 0;
d361 2
a362 2
		return rscreen->info.drm_minor >= 20 &&
		       rscreen->info.r600_clock_crystal_freq != 0;
d364 1
d368 1
d380 1
a380 2
static float r600_get_paramf(struct pipe_screen* pscreen,
			     enum pipe_capf param)
a382 1
	enum radeon_family family = rscreen->family;
a383 24
	switch (param) {
	case PIPE_CAPF_MAX_LINE_WIDTH:
	case PIPE_CAPF_MAX_LINE_WIDTH_AA:
	case PIPE_CAPF_MAX_POINT_WIDTH:
	case PIPE_CAPF_MAX_POINT_WIDTH_AA:
		if (family >= CHIP_CEDAR)
			return 16384.0f;
		else
			return 8192.0f;
	case PIPE_CAPF_MAX_TEXTURE_ANISOTROPY:
		return 16.0f;
	case PIPE_CAPF_MAX_TEXTURE_LOD_BIAS:
		return 16.0f;
	case PIPE_CAPF_GUARD_BAND_LEFT:
	case PIPE_CAPF_GUARD_BAND_TOP:
	case PIPE_CAPF_GUARD_BAND_RIGHT:
	case PIPE_CAPF_GUARD_BAND_BOTTOM:
		return 0.0f;
	}
	return 0.0f;
}

static int r600_get_shader_param(struct pipe_screen* pscreen, unsigned shader, enum pipe_shader_cap param)
{
d388 1
a388 1
        case PIPE_SHADER_COMPUTE:
d391 5
a395 1
		/* XXX: support and enable geometry programs */
d437 1
a448 186
static int r600_get_video_param(struct pipe_screen *screen,
				enum pipe_video_profile profile,
				enum pipe_video_cap param)
{
	switch (param) {
	case PIPE_VIDEO_CAP_SUPPORTED:
		return vl_profile_supported(screen, profile);
	case PIPE_VIDEO_CAP_NPOT_TEXTURES:
		return 1;
	case PIPE_VIDEO_CAP_MAX_WIDTH:
	case PIPE_VIDEO_CAP_MAX_HEIGHT:
		return vl_video_buffer_max_size(screen);
	case PIPE_VIDEO_CAP_PREFERED_FORMAT:
		return PIPE_FORMAT_NV12;
	case PIPE_VIDEO_CAP_PREFERS_INTERLACED:
		return false;
	case PIPE_VIDEO_CAP_SUPPORTS_INTERLACED:
		return false;
	case PIPE_VIDEO_CAP_SUPPORTS_PROGRESSIVE:
		return true;
	default:
		return 0;
	}
}

const char * r600_llvm_gpu_string(enum radeon_family family)
{
	const char * gpu_family;

	switch (family) {
	case CHIP_R600:
	case CHIP_RV630:
	case CHIP_RV635:
	case CHIP_RV670:
		gpu_family = "r600";
		break;
	case CHIP_RV610:
	case CHIP_RV620:
	case CHIP_RS780:
	case CHIP_RS880:
		gpu_family = "rs880";
		break;
	case CHIP_RV710:
		gpu_family = "rv710";
		break;
	case CHIP_RV730:
		gpu_family = "rv730";
		break;
	case CHIP_RV740:
	case CHIP_RV770:
		gpu_family = "rv770";
		break;
	case CHIP_PALM:
	case CHIP_CEDAR:
		gpu_family = "cedar";
		break;
	case CHIP_SUMO:
	case CHIP_SUMO2:
		gpu_family = "sumo";
		break;
	case CHIP_REDWOOD:
		gpu_family = "redwood";
		break;
	case CHIP_JUNIPER:
		gpu_family = "juniper";
		break;
	case CHIP_HEMLOCK:
	case CHIP_CYPRESS:
		gpu_family = "cypress";
		break;
	case CHIP_BARTS:
		gpu_family = "barts";
		break;
	case CHIP_TURKS:
		gpu_family = "turks";
		break;
	case CHIP_CAICOS:
		gpu_family = "caicos";
		break;
	case CHIP_CAYMAN:
        case CHIP_ARUBA:
		gpu_family = "cayman";
		break;
	default:
		gpu_family = "";
		fprintf(stderr, "Chip not supported by r600 llvm "
			"backend, please file a bug at " PACKAGE_BUGREPORT "\n");
		break;
	}
	return gpu_family;
}


static int r600_get_compute_param(struct pipe_screen *screen,
        enum pipe_compute_cap param,
        void *ret)
{
	struct r600_screen *rscreen = (struct r600_screen *)screen;
	//TODO: select these params by asic
	switch (param) {
	case PIPE_COMPUTE_CAP_IR_TARGET: {
		const char *gpu = r600_llvm_gpu_string(rscreen->family);
		if (ret) {
			sprintf(ret, "%s-r600--", gpu);
		}
		return (8 + strlen(gpu)) * sizeof(char);
	}
	case PIPE_COMPUTE_CAP_GRID_DIMENSION:
		if (ret) {
			uint64_t * grid_dimension = ret;
			grid_dimension[0] = 3;
		}
		return 1 * sizeof(uint64_t);

	case PIPE_COMPUTE_CAP_MAX_GRID_SIZE:
		if (ret) {
			uint64_t * grid_size = ret;
			grid_size[0] = 65535;
			grid_size[1] = 65535;
			grid_size[2] = 1;
		}
		return 3 * sizeof(uint64_t) ;

	case PIPE_COMPUTE_CAP_MAX_BLOCK_SIZE:
		if (ret) {
			uint64_t * block_size = ret;
			block_size[0] = 256;
			block_size[1] = 256;
			block_size[2] = 256;
		}
		return 3 * sizeof(uint64_t);

	case PIPE_COMPUTE_CAP_MAX_THREADS_PER_BLOCK:
		if (ret) {
			uint64_t * max_threads_per_block = ret;
			*max_threads_per_block = 256;
		}
		return sizeof(uint64_t);

	case PIPE_COMPUTE_CAP_MAX_GLOBAL_SIZE:
		if (ret) {
			uint64_t * max_global_size = ret;
			/* XXX: This is what the proprietary driver reports, we
			 * may want to use a different value. */
			*max_global_size = 201326592;
		}
		return sizeof(uint64_t);

	case PIPE_COMPUTE_CAP_MAX_INPUT_SIZE:
		if (ret) {
			uint64_t * max_input_size = ret;
			*max_input_size = 1024;
		}
		return sizeof(uint64_t);

	case PIPE_COMPUTE_CAP_MAX_LOCAL_SIZE:
		if (ret) {
			uint64_t * max_local_size = ret;
			/* XXX: This is what the proprietary driver reports, we
			 * may want to use a different value. */
			*max_local_size = 32768;
		}
		return sizeof(uint64_t);

	case PIPE_COMPUTE_CAP_MAX_MEM_ALLOC_SIZE:
		if (ret) {
			uint64_t max_global_size;
			uint64_t * max_mem_alloc_size = ret;
			r600_get_compute_param(screen,
					PIPE_COMPUTE_CAP_MAX_GLOBAL_SIZE,
					&max_global_size);
			/* OpenCL requres this value be at least
			 * max(MAX_GLOBAL_SIZE / 4, 128 * 1024 *1024)
			 * I'm really not sure what value to report here, but
			 * MAX_GLOBAL_SIZE / 4 seems resonable.
			 */
			*max_mem_alloc_size = max_global_size / 4;
		}
		return sizeof(uint64_t);

	default:
		fprintf(stderr, "unknown PIPE_COMPUTE_CAP %d\n", param);
		return 0;
	}
}

d456 2
a457 2
	pipe_mutex_destroy(rscreen->aux_context_lock);
	rscreen->aux_context->destroy(rscreen->aux_context);
d463 1
a463 19
	if (rscreen->fences.bo) {
		struct r600_fence_block *entry, *tmp;

		LIST_FOR_EACH_ENTRY_SAFE(entry, tmp, &rscreen->fences.blocks, head) {
			LIST_DEL(&entry->head);
			FREE(entry);
		}

		rscreen->ws->buffer_unmap(rscreen->fences.bo->cs_buf);
		pipe_resource_reference((struct pipe_resource**)&rscreen->fences.bo, NULL);
	}
	if (rscreen->trace_bo) {
		rscreen->ws->buffer_unmap(rscreen->trace_bo->cs_buf);
		pipe_resource_reference((struct pipe_resource**)&rscreen->trace_bo, NULL);
	}
	pipe_mutex_destroy(rscreen->fences.mutex);

	rscreen->ws->destroy(rscreen->ws);
	FREE(rscreen);
d466 2
a467 3
static void r600_fence_reference(struct pipe_screen *pscreen,
                                 struct pipe_fence_handle **ptr,
                                 struct pipe_fence_handle *fence)
d469 3
a471 10
	struct r600_fence **oldf = (struct r600_fence**)ptr;
	struct r600_fence *newf = (struct r600_fence*)fence;

	if (pipe_reference(&(*oldf)->reference, &newf->reference)) {
		struct r600_screen *rscreen = (struct r600_screen *)pscreen;
		pipe_mutex_lock(rscreen->fences.mutex);
		pipe_resource_reference((struct pipe_resource**)&(*oldf)->sleep_bo, NULL);
		LIST_ADDTAIL(&(*oldf)->head, &rscreen->fences.pool);
		pipe_mutex_unlock(rscreen->fences.mutex);
	}
d473 1
a473 1
	*ptr = fence;
d476 1
a476 2
static boolean r600_fence_signalled(struct pipe_screen *pscreen,
                                    struct pipe_fence_handle *fence)
d478 1
a478 2
	struct r600_screen *rscreen = (struct r600_screen *)pscreen;
	struct r600_fence *rfence = (struct r600_fence*)fence;
d480 2
a481 17
	return rscreen->fences.data[rfence->index] != 0;
}

static boolean r600_fence_finish(struct pipe_screen *pscreen,
                                 struct pipe_fence_handle *fence,
                                 uint64_t timeout)
{
	struct r600_screen *rscreen = (struct r600_screen *)pscreen;
	struct r600_fence *rfence = (struct r600_fence*)fence;
	int64_t start_time = 0;
	unsigned spins = 0;

	if (timeout != PIPE_TIMEOUT_INFINITE) {
		start_time = os_time_get();

		/* Convert to microseconds. */
		timeout /= 1000;
d484 6
a489 6
	while (rscreen->fences.data[rfence->index] == 0) {
		/* Special-case infinite timeout - wait for the dummy BO to become idle */
		if (timeout == PIPE_TIMEOUT_INFINITE) {
			rscreen->ws->buffer_wait(rfence->sleep_bo->buf, RADEON_USAGE_READWRITE);
			break;
		}
d491 3
a493 38
		/* The dummy BO will be busy until the CS including the fence has completed, or
		 * the GPU is reset. Don't bother continuing to spin when the BO is idle. */
		if (!rscreen->ws->buffer_is_busy(rfence->sleep_bo->buf, RADEON_USAGE_READWRITE))
			break;

		if (++spins % 256)
			continue;
#ifdef PIPE_OS_UNIX
		sched_yield();
#else
		os_time_sleep(10);
#endif
		if (timeout != PIPE_TIMEOUT_INFINITE &&
		    os_time_get() - start_time >= timeout) {
			break;
		}
	}

	return rscreen->fences.data[rfence->index] != 0;
}

static int r600_interpret_tiling(struct r600_screen *rscreen, uint32_t tiling_config)
{
	switch ((tiling_config & 0xe) >> 1) {
	case 0:
		rscreen->tiling_info.num_channels = 1;
		break;
	case 1:
		rscreen->tiling_info.num_channels = 2;
		break;
	case 2:
		rscreen->tiling_info.num_channels = 4;
		break;
	case 3:
		rscreen->tiling_info.num_channels = 8;
		break;
	default:
		return -EINVAL;
d496 2
a497 86
	switch ((tiling_config & 0x30) >> 4) {
	case 0:
		rscreen->tiling_info.num_banks = 4;
		break;
	case 1:
		rscreen->tiling_info.num_banks = 8;
		break;
	default:
		return -EINVAL;

	}
	switch ((tiling_config & 0xc0) >> 6) {
	case 0:
		rscreen->tiling_info.group_bytes = 256;
		break;
	case 1:
		rscreen->tiling_info.group_bytes = 512;
		break;
	default:
		return -EINVAL;
	}
	return 0;
}

static int evergreen_interpret_tiling(struct r600_screen *rscreen, uint32_t tiling_config)
{
	switch (tiling_config & 0xf) {
	case 0:
		rscreen->tiling_info.num_channels = 1;
		break;
	case 1:
		rscreen->tiling_info.num_channels = 2;
		break;
	case 2:
		rscreen->tiling_info.num_channels = 4;
		break;
	case 3:
		rscreen->tiling_info.num_channels = 8;
		break;
	default:
		return -EINVAL;
	}

	switch ((tiling_config & 0xf0) >> 4) {
	case 0:
		rscreen->tiling_info.num_banks = 4;
		break;
	case 1:
		rscreen->tiling_info.num_banks = 8;
		break;
	case 2:
		rscreen->tiling_info.num_banks = 16;
		break;
	default:
		return -EINVAL;
	}

	switch ((tiling_config & 0xf00) >> 8) {
	case 0:
		rscreen->tiling_info.group_bytes = 256;
		break;
	case 1:
		rscreen->tiling_info.group_bytes = 512;
		break;
	default:
		return -EINVAL;
	}
	return 0;
}

static int r600_init_tiling(struct r600_screen *rscreen)
{
	uint32_t tiling_config = rscreen->info.r600_tiling_config;

	/* set default group bytes, overridden by tiling info ioctl */
	if (rscreen->chip_class <= R700) {
		rscreen->tiling_info.group_bytes = 256;
	} else {
		rscreen->tiling_info.group_bytes = 512;
	}

	if (!tiling_config)
		return 0;

	if (rscreen->chip_class <= R700) {
		return r600_interpret_tiling(rscreen, tiling_config);
d499 1
a499 40
		return evergreen_interpret_tiling(rscreen, tiling_config);
	}
}

static uint64_t r600_get_timestamp(struct pipe_screen *screen)
{
	struct r600_screen *rscreen = (struct r600_screen*)screen;

	return 1000000 * rscreen->ws->query_value(rscreen->ws, RADEON_TIMESTAMP) /
			rscreen->info.r600_clock_crystal_freq;
}

static int r600_get_driver_query_info(struct pipe_screen *screen,
				      unsigned index,
				      struct pipe_driver_query_info *info)
{
	struct r600_screen *rscreen = (struct r600_screen*)screen;
	struct pipe_driver_query_info list[] = {
		{"draw-calls", R600_QUERY_DRAW_CALLS, 0},
		{"requested-VRAM", R600_QUERY_REQUESTED_VRAM, rscreen->info.vram_size, TRUE},
		{"requested-GTT", R600_QUERY_REQUESTED_GTT, rscreen->info.gart_size, TRUE},
		{"buffer-wait-time", R600_QUERY_BUFFER_WAIT_TIME, 0, FALSE}
	};

	if (!info)
		return Elements(list);

	if (index >= Elements(list))
		return 0;

	*info = list[index];
	return 1;
}

struct pipe_screen *r600_screen_create(struct radeon_winsys *ws)
{
	struct r600_screen *rscreen = CALLOC_STRUCT(r600_screen);

	if (rscreen == NULL) {
		return NULL;
d502 1
a502 4
	rscreen->ws = ws;
	ws->query_info(ws, &rscreen->info);

	rscreen->debug_flags = debug_get_flags_option("R600_DEBUG", debug_options, 0);
d504 1
a504 1
		rscreen->debug_flags |= DBG_COMPUTE;
d506 5
a510 9
		rscreen->debug_flags |= DBG_FS | DBG_VS | DBG_GS | DBG_PS | DBG_CS;
	if (!debug_get_bool_option("R600_HYPERZ", TRUE))
		rscreen->debug_flags |= DBG_NO_HYPERZ;
	if (!debug_get_bool_option("R600_LLVM", TRUE))
		rscreen->debug_flags |= DBG_NO_LLVM;
	if (debug_get_bool_option("R600_PRINT_TEXDEPTH", FALSE))
		rscreen->debug_flags |= DBG_TEX_DEPTH;
	rscreen->family = rscreen->info.family;
	rscreen->chip_class = rscreen->info.chip_class;
d512 2
a513 2
	if (rscreen->family == CHIP_UNKNOWN) {
		fprintf(stderr, "r600: Unknown chipset 0x%04X\n", rscreen->info.pci_id);
d519 1
a519 1
	switch (rscreen->chip_class) {
d521 2
a522 2
		if (rscreen->family < CHIP_RS780) {
			rscreen->has_streamout = rscreen->info.drm_minor >= 14;
d524 1
a524 1
			rscreen->has_streamout = rscreen->info.drm_minor >= 23;
d528 1
a528 1
		rscreen->has_streamout = rscreen->info.drm_minor >= 17;
d532 1
a532 1
		rscreen->has_streamout = rscreen->info.drm_minor >= 14;
d535 1
a535 1
		rscreen->has_streamout = FALSE;
d540 1
a540 1
	switch (rscreen->chip_class) {
d543 1
a543 1
		rscreen->has_msaa = rscreen->info.drm_minor >= 22;
d547 2
a548 2
		rscreen->has_msaa = rscreen->info.drm_minor >= 19;
		rscreen->has_compressed_msaa_texturing = rscreen->info.drm_minor >= 24;
d551 1
a551 1
		rscreen->has_msaa = rscreen->info.drm_minor >= 19;
d559 2
a560 48
	rscreen->has_cp_dma = rscreen->info.drm_minor >= 27 &&
			      !(rscreen->debug_flags & DBG_NO_CP_DMA);

	if (r600_init_tiling(rscreen)) {
		FREE(rscreen);
		return NULL;
	}

	rscreen->screen.destroy = r600_destroy_screen;
	rscreen->screen.get_name = r600_get_name;
	rscreen->screen.get_vendor = r600_get_vendor;
	rscreen->screen.get_param = r600_get_param;
	rscreen->screen.get_shader_param = r600_get_shader_param;
	rscreen->screen.get_paramf = r600_get_paramf;
	rscreen->screen.get_compute_param = r600_get_compute_param;
	rscreen->screen.get_timestamp = r600_get_timestamp;

	if (rscreen->chip_class >= EVERGREEN) {
		rscreen->screen.is_format_supported = evergreen_is_format_supported;
		rscreen->dma_blit = &evergreen_dma_blit;
	} else {
		rscreen->screen.is_format_supported = r600_is_format_supported;
		rscreen->dma_blit = &r600_dma_blit;
	}
	rscreen->screen.context_create = r600_create_context;
	rscreen->screen.fence_reference = r600_fence_reference;
	rscreen->screen.fence_signalled = r600_fence_signalled;
	rscreen->screen.fence_finish = r600_fence_finish;
	rscreen->screen.get_driver_query_info = r600_get_driver_query_info;

	if (rscreen->info.has_uvd) {
		rscreen->screen.get_video_param = r600_uvd_get_video_param;
		rscreen->screen.is_video_format_supported = ruvd_is_format_supported;
	} else {
		rscreen->screen.get_video_param = r600_get_video_param;
		rscreen->screen.is_video_format_supported = vl_video_buffer_is_format_supported;
	}

	r600_init_screen_resource_functions(&rscreen->screen);

	util_format_s3tc_init();

	rscreen->fences.bo = NULL;
	rscreen->fences.data = NULL;
	rscreen->fences.next_index = 0;
	LIST_INITHEAD(&rscreen->fences.pool);
	LIST_INITHEAD(&rscreen->fences.blocks);
	pipe_mutex_init(rscreen->fences.mutex);
d564 2
a565 15
	rscreen->cs_count = 0;
	if (rscreen->info.drm_minor >= 28 && (rscreen->debug_flags & DBG_TRACE_CS)) {
		rscreen->trace_bo = (struct r600_resource*)pipe_buffer_create(&rscreen->screen,
										PIPE_BIND_CUSTOM,
										PIPE_USAGE_STAGING,
										4096);
		if (rscreen->trace_bo) {
			rscreen->trace_ptr = rscreen->ws->buffer_map(rscreen->trace_bo->cs_buf, NULL,
									PIPE_TRANSFER_UNSYNCHRONIZED);
		}
	}

	/* Create the auxiliary context. */
	pipe_mutex_init(rscreen->aux_context_lock);
	rscreen->aux_context = rscreen->screen.context_create(&rscreen->screen, NULL);
d576 1
a576 1
	templ.usage = PIPE_USAGE_STATIC;
d599 1
a599 1
	return &rscreen->screen;
@


1.2
log
@Upate to libGL 7.11.2

Tested by jsg@@, matthieu@@ and ajacoutot@@, ok mattieu@@
@
text
@d23 8
a30 1
#include <stdio.h>
d32 6
a37 15
#include <pipe/p_defines.h>
#include <pipe/p_state.h>
#include <pipe/p_context.h>
#include <tgsi/tgsi_scan.h>
#include <tgsi/tgsi_parse.h>
#include <tgsi/tgsi_util.h>
#include <util/u_blitter.h>
#include <util/u_double_list.h>
#include "util/u_format.h"
#include <util/u_format_s3tc.h>
#include <util/u_transfer.h>
#include <util/u_surface.h>
#include <util/u_pack_color.h>
#include <util/u_memory.h>
#include <util/u_inlines.h>
d39 4
d44 37
a80 7
#include <pipebuffer/pb_buffer.h>
#include "r600.h"
#include "r600d.h"
#include "r600_resource.h"
#include "r600_shader.h"
#include "r600_pipe.h"
#include "r600_state_inlines.h"
d85 1
a85 1
static struct r600_fence *r600_create_fence(struct r600_pipe_context *ctx)
d87 1
d90 3
a92 1
	if (!ctx->fences.bo) {
d94 4
a97 2
		ctx->fences.bo = r600_bo(ctx->radeon, 4096, 0, 0, 0);
		if (!ctx->fences.bo) {
d99 1
a99 1
			return NULL;
d101 1
a101 1
		ctx->fences.data = r600_bo_map(ctx->radeon, ctx->fences.bo, PB_USAGE_UNSYNCHRONIZED, NULL);
d104 1
a104 1
	if (!LIST_IS_EMPTY(&ctx->fences.pool)) {
d108 2
a109 2
		LIST_FOR_EACH_ENTRY(entry, &ctx->fences.pool, head) {
			if (ctx->fences.data[entry->index] != 0) {
d122 1
a122 1
		if ((ctx->fences.next_index + 1) >= 1024) {
d124 1
a124 1
			return NULL;
d127 1
a127 1
		index = ctx->fences.next_index++;
d133 1
a133 1
				return NULL;
d135 1
a135 1
			LIST_ADD(&block->head, &ctx->fences.blocks);
d137 1
a137 1
			block = LIST_ENTRY(struct r600_fence_block, ctx->fences.blocks.next, head);
a140 1
		fence->ctx = ctx;
d146 12
a157 2
	ctx->fences.data[fence->index] = 0;
	r600_context_emit_fence(&ctx->ctx, ctx->fences.bo, fence->index, 1);
d161 1
a161 2
static void r600_flush(struct pipe_context *ctx,
			struct pipe_fence_handle **fence)
d163 34
a196 1
	struct r600_pipe_context *rctx = (struct r600_pipe_context *)ctx;
d198 1
d200 33
a232 4
#if 0
	static int dc = 0;
	char dname[256];
#endif
d234 4
a237 2
	if (rfence)
		*rfence = r600_create_fence(rctx);
d239 11
a249 5
#if 0
	sprintf(dname, "gallium-%08d.bof", dc);
	if (dc < 20) {
		r600_context_dump_bof(&rctx->ctx, dname);
		R600_ERR("dumped %s\n", dname);
d251 1
a251 3
	dc++;
#endif
	r600_context_flush(&rctx->ctx);
d254 3
a256 1
static void r600_update_num_contexts(struct r600_screen *rscreen, int diff)
d258 3
a260 3
	pipe_mutex_lock(rscreen->mutex_num_contexts);
	if (diff > 0) {
		rscreen->num_contexts++;
d262 26
a287 5
		if (rscreen->num_contexts > 1)
			util_slab_set_thread_safety(&rscreen->pool_buffers,
						    UTIL_SLAB_MULTITHREADED);
	} else {
		rscreen->num_contexts--;
d289 11
a299 3
		if (rscreen->num_contexts <= 1)
			util_slab_set_thread_safety(&rscreen->pool_buffers,
						    UTIL_SLAB_SINGLETHREADED);
d301 17
a317 1
	pipe_mutex_unlock(rscreen->mutex_num_contexts);
d322 1
a322 1
	struct r600_pipe_context *rctx = (struct r600_pipe_context *)context;
d324 1
a324 2
	rctx->context.delete_depth_stencil_alpha_state(&rctx->context, rctx->custom_dsa_flush);
	util_unreference_framebuffer_state(&rctx->framebuffer);
d326 1
a326 1
	r600_context_fini(&rctx->ctx);
d328 2
a329 1
	util_blitter_destroy(rctx->blitter);
d331 5
a335 2
	for (int i = 0; i < R600_PIPE_NSTATES; i++) {
		free(rctx->states[i]);
d337 7
d345 12
a356 1
	u_vbuf_destroy(rctx->vbuf_mgr);
d359 1
a359 2
	if (rctx->fences.bo) {
		struct r600_fence_block *entry, *tmp;
d361 5
a365 7
		LIST_FOR_EACH_ENTRY_SAFE(entry, tmp, &rctx->fences.blocks, head) {
			LIST_DEL(&entry->head);
			FREE(entry);
		}

		r600_bo_unmap(rctx->radeon, rctx->fences.bo);
		r600_bo_reference(rctx->radeon, &rctx->fences.bo, NULL);
a367 2
	r600_update_num_contexts(rctx->screen, -1);

d373 1
a373 1
	struct r600_pipe_context *rctx = CALLOC_STRUCT(r600_pipe_context);
a374 1
	enum chip_class class;
d379 3
a381 1
	r600_update_num_contexts(rscreen, 1);
a382 1
	rctx->context.winsys = rscreen->screen.winsys;
d386 1
a386 1
	rctx->context.flush = r600_flush;
d390 4
a393 2
	rctx->radeon = rscreen->radeon;
	rctx->family = r600_get_family(rctx->radeon);
d395 1
a395 5
	rctx->fences.bo = NULL;
	rctx->fences.data = NULL;
	rctx->fences.next_index = 0;
	LIST_INITHEAD(&rctx->fences.pool);
	LIST_INITHEAD(&rctx->fences.blocks);
a400 1
	rctx->context.draw_vbo = r600_draw_vbo;
d402 13
a414 13
	switch (r600_get_family(rctx->radeon)) {
	case CHIP_R600:
	case CHIP_RV610:
	case CHIP_RV630:
	case CHIP_RV670:
	case CHIP_RV620:
	case CHIP_RV635:
	case CHIP_RS780:
	case CHIP_RS880:
	case CHIP_RV770:
	case CHIP_RV730:
	case CHIP_RV710:
	case CHIP_RV740:
d416 11
a426 5
		if (r600_context_init(&rctx->ctx, rctx->radeon)) {
			r600_destroy_context(&rctx->context);
			return NULL;
		}
		r600_init_config(rctx);
d428 2
a429 12
	case CHIP_CEDAR:
	case CHIP_REDWOOD:
	case CHIP_JUNIPER:
	case CHIP_CYPRESS:
	case CHIP_HEMLOCK:
	case CHIP_PALM:
	case CHIP_SUMO:
	case CHIP_SUMO2:
	case CHIP_BARTS:
	case CHIP_TURKS:
	case CHIP_CAICOS:
	case CHIP_CAYMAN:
d431 13
a443 5
		if (evergreen_context_init(&rctx->ctx, rctx->radeon)) {
			r600_destroy_context(&rctx->context);
			return NULL;
		}
		evergreen_init_config(rctx);
d446 2
a447 3
		R600_ERR("unsupported family %d\n", r600_get_family(rctx->radeon));
		r600_destroy_context(&rctx->context);
		return NULL;
d450 4
a453 12
	util_slab_create(&rctx->pool_transfers,
			 sizeof(struct pipe_transfer), 64,
			 UTIL_SLAB_SINGLETHREADED);

	rctx->vbuf_mgr = u_vbuf_create(&rctx->context, 1024 * 1024, 256,
					   PIPE_BIND_VERTEX_BUFFER |
					   PIPE_BIND_INDEX_BUFFER |
					   PIPE_BIND_CONSTANT_BUFFER,
					   U_VERTEX_FETCH_DWORD_ALIGNED);
	if (!rctx->vbuf_mgr) {
		r600_destroy_context(&rctx->context);
		return NULL;
d455 31
d488 13
a500 4
	if (rctx->blitter == NULL) {
		r600_destroy_context(&rctx->context);
		return NULL;
	}
d502 1
a502 5
	class = r600_get_family_class(rctx->radeon);
	if (class == R600 || class == R700)
		rctx->custom_dsa_flush = r600_create_db_flush_dsa(rctx);
	else
		rctx->custom_dsa_flush = evergreen_create_db_flush_dsa(rctx);
d504 3
a506 1
	return &rctx->context;
d544 1
a551 1
	enum radeon_family family = r600_get_family(rscreen->radeon);
d553 1
a553 1
	return r600_get_family_name(family);
d559 1
a559 1
	enum radeon_family family = r600_get_family(rscreen->radeon);
a564 2
	case PIPE_CAP_GLSL:
	case PIPE_CAP_DUAL_SOURCE_BLEND:
a569 1
	case PIPE_CAP_TEXTURE_MIRROR_REPEAT:
d572 1
a572 2
	case PIPE_CAP_DEPTHSTENCIL_CLEAR_SEPARATE:
	case PIPE_CAP_DEPTH_CLAMP:
d580 18
a597 1
	case PIPE_CAP_FRAGMENT_COLOR_CLAMP_CONTROL:
d600 18
d626 1
a629 3
	case PIPE_CAP_STREAM_OUTPUT:
	case PIPE_CAP_PRIMITIVE_RESTART:
	case PIPE_CAP_TGSI_INSTANCEID:
d632 5
d639 8
a646 3
	case PIPE_CAP_ARRAY_TEXTURES:
		/* fix once the CS checker upstream is fixed */
		return debug_get_bool_option("R600_ARRAY_TEXTURE", FALSE);
d656 3
a658 3
	case PIPE_CAP_MAX_VERTEX_TEXTURE_UNITS:
	case PIPE_CAP_MAX_TEXTURE_IMAGE_UNITS:
		return 16;
d664 1
a664 1
		/* FIXME some r6xx are buggy and can only do 4 */
d668 16
a683 6
	case PIPE_CAP_TIMER_QUERY:
		return r600_get_clock_crystal_freq(rscreen->radeon) != 0;

	default:
		R600_ERR("r600: unknown param %d\n", param);
		return 0;
d685 1
d688 2
a689 1
static float r600_get_paramf(struct pipe_screen* pscreen, enum pipe_cap param)
d692 1
a692 1
	enum radeon_family family = r600_get_family(rscreen->radeon);
d695 4
a698 4
	case PIPE_CAP_MAX_LINE_WIDTH:
	case PIPE_CAP_MAX_LINE_WIDTH_AA:
	case PIPE_CAP_MAX_POINT_WIDTH:
	case PIPE_CAP_MAX_POINT_WIDTH_AA:
d703 1
a703 1
	case PIPE_CAP_MAX_TEXTURE_ANISOTROPY:
d705 1
a705 1
	case PIPE_CAP_MAX_TEXTURE_LOD_BIAS:
d707 4
a710 2
	default:
		R600_ERR("r600: unsupported paramf %d\n", param);
d713 1
d722 1
d725 1
a725 1
		/* TODO: support and enable geometry programs */
d728 1
a728 1
		/* TODO: support tessellation on Evergreen */
a731 1
	/* TODO: all these should be fixed, since r600 surely supports much more! */
d739 1
a739 1
		return 8; /* FIXME */
d741 1
a741 4
		if(shader == PIPE_SHADER_FRAGMENT)
			return 34;
		else
			return 32;
d745 1
a745 1
		/* FIXME Isn't this equal to TEMPS? */
d750 1
a750 1
		return R600_MAX_CONST_BUFFERS;
d752 1
a752 1
		return 0; /* FIXME */
d755 2
d764 34
d803 1
a803 5
static boolean r600_is_format_supported(struct pipe_screen* screen,
					enum pipe_format format,
					enum pipe_texture_target target,
					unsigned sample_count,
                                        unsigned usage)
d805 61
a865 4
	unsigned retval = 0;
	if (target >= PIPE_MAX_TEXTURE_TYPES) {
		R600_ERR("r600: unsupported texture type %d\n", target);
		return FALSE;
d867 2
a869 2
        if (!util_format_is_supported(format, usage))
                return FALSE;
d871 20
a890 3
	/* Multisample */
	if (sample_count > 1)
		return FALSE;
d892 8
a899 4
	if ((usage & PIPE_BIND_SAMPLER_VIEW) &&
	    r600_is_sampler_format_supported(screen, format)) {
		retval |= PIPE_BIND_SAMPLER_VIEW;
	}
d901 8
a908 11
	if ((usage & (PIPE_BIND_RENDER_TARGET |
			PIPE_BIND_DISPLAY_TARGET |
			PIPE_BIND_SCANOUT |
			PIPE_BIND_SHARED)) &&
			r600_is_colorbuffer_format_supported(format)) {
		retval |= usage &
			(PIPE_BIND_RENDER_TARGET |
			 PIPE_BIND_DISPLAY_TARGET |
			 PIPE_BIND_SCANOUT |
			 PIPE_BIND_SHARED);
	}
d910 6
a915 4
	if ((usage & PIPE_BIND_DEPTH_STENCIL) &&
	    r600_is_zs_format_supported(format)) {
		retval |= PIPE_BIND_DEPTH_STENCIL;
	}
d917 8
a924 3
	if (usage & PIPE_BIND_VERTEX_BUFFER) {
		struct r600_screen *rscreen = (struct r600_screen *)screen;
		enum radeon_family family = r600_get_family(rscreen->radeon);
d926 4
a929 2
		if (r600_is_vertex_format_supported(format, family)) {
			retval |= PIPE_BIND_VERTEX_BUFFER;
d931 1
a931 1
	}
d933 8
a940 4
	if (usage & PIPE_BIND_TRANSFER_READ)
		retval |= PIPE_BIND_TRANSFER_READ;
	if (usage & PIPE_BIND_TRANSFER_WRITE)
		retval |= PIPE_BIND_TRANSFER_WRITE;
d942 20
a961 1
	return retval == usage;
d971 23
a993 1
	radeon_decref(rscreen->radeon);
d995 1
a995 2
	util_slab_destroy(&rscreen->pool_buffers);
	pipe_mutex_destroy(rscreen->mutex_num_contexts);
d1007 5
a1011 2
		struct r600_pipe_context *ctx = (*oldf)->ctx;
		LIST_ADDTAIL(&(*oldf)->head, &ctx->fences.pool);
d1020 1
a1021 1
	struct r600_pipe_context *ctx = rfence->ctx;
d1023 1
a1023 1
	return ctx->fences.data[rfence->index];
d1030 1
a1031 1
	struct r600_pipe_context *ctx = rfence->ctx;
d1042 12
a1053 1
	while (ctx->fences.data[rfence->index] == 0) {
d1063 1
a1063 1
			return FALSE;
d1067 119
a1185 1
	return TRUE;
d1188 3
a1190 1
struct pipe_screen *r600_screen_create(struct radeon *radeon)
d1192 21
a1212 1
	struct r600_screen *rscreen;
a1213 1
	rscreen = CALLOC_STRUCT(r600_screen);
d1218 72
a1289 2
	rscreen->radeon = radeon;
	rscreen->screen.winsys = (struct pipe_winsys*)radeon;
d1296 10
a1305 1
	rscreen->screen.is_format_supported = r600_is_format_supported;
d1310 10
a1321 1
	rscreen->tiling_info = r600_get_tiling_info(radeon);
d1324 20
a1343 3
	util_slab_create(&rscreen->pool_buffers,
			 sizeof(struct r600_resource_buffer), 64,
			 UTIL_SLAB_SINGLETHREADED);
d1345 35
a1379 1
	pipe_mutex_init(rscreen->mutex_num_contexts);
@


1.1
log
@Initial revision
@
text
@d33 2
d40 2
d53 63
a115 1
static void r600_flush(struct pipe_context *ctx, unsigned flags,
d119 2
d126 2
a127 2
	if (!rctx->ctx.pm4_cdwords)
		return;
d138 1
d140 17
a156 1
	r600_upload_flush(rctx->rupload_vb);
d164 1
a164 2

	r600_end_vertex_translate(rctx);
d174 14
a187 1
	r600_upload_destroy(rctx->rupload_vb);
d189 1
a189 2
	if (rctx->tran.translate_cache)
		translate_cache_destroy(rctx->tran.translate_cache);
a190 2
	FREE(rctx->ps_resource);
	FREE(rctx->vs_resource);
d202 3
d216 6
d226 1
a240 1
		rctx->context.draw_vbo = r600_draw_vbo;
d254 2
d259 1
a259 1
		rctx->context.draw_vbo = evergreen_draw;
d273 10
a282 2
	rctx->rupload_vb = r600_upload_create(rctx, 128 * 1024, 16);
	if (rctx->rupload_vb == NULL) {
d289 1
a289 19
		FREE(rctx);
		return NULL;
	}

	rctx->tran.translate_cache = translate_cache_create();
	if (rctx->tran.translate_cache == NULL) {
		FREE(rctx);
		return NULL;
	}

	rctx->vs_resource = CALLOC(R600_RESOURCE_ARRAY_SIZE, sizeof(struct r600_pipe_state));
	if (!rctx->vs_resource) {
		FREE(rctx);
		return NULL;
	}

	rctx->ps_resource = CALLOC(R600_RESOURCE_ARRAY_SIZE, sizeof(struct r600_pipe_state));
	if (!rctx->ps_resource) {
		FREE(rctx);
a298 2
	r600_blit_uncompress_depth_ptr = r600_blit_uncompress_depth;

d331 2
d336 1
a366 1
	case PIPE_CAP_SM3:
a367 1
	case PIPE_CAP_INDEP_BLEND_ENABLE:
d371 7
d380 11
a390 2
	/* Unsupported features (boolean caps). */
	case PIPE_CAP_TIMER_QUERY:
d393 3
a395 1
	case PIPE_CAP_INDEP_BLEND_FUNC: /* FIXME allow this */
d398 4
d411 1
a411 1
		/* FIXME allow this once infrastructure is there */
a412 1
	case PIPE_CAP_MAX_TEXTURE_IMAGE_UNITS:
d414 1
a414 1
		return 16;
d421 3
a423 7
	/* Fragment coordinate conventions. */
	case PIPE_CAP_TGSI_FS_COORD_ORIGIN_UPPER_LEFT:
	case PIPE_CAP_TGSI_FS_COORD_PIXEL_CENTER_HALF_INTEGER:
		return 1;
	case PIPE_CAP_TGSI_FS_COORD_ORIGIN_LOWER_LEFT:
	case PIPE_CAP_TGSI_FS_COORD_PIXEL_CENTER_INTEGER:
		return 0;
d485 1
a485 1
		return 256; //max native temporaries
d487 2
a488 1
		return 1; //max native address registers/* FIXME Isn't this equal to TEMPS? */
d490 1
a490 1
		return 256; //max native parameters
d492 1
a492 1
		return 1;
d513 1
a513 2
					unsigned usage,
					unsigned geom_flags)
d521 3
d529 1
a529 1
	    r600_is_sampler_format_supported(format)) {
d550 8
a557 3
	if ((usage & PIPE_BIND_VERTEX_BUFFER) &&
	    r600_is_vertex_format_supported(format))
		retval |= PIPE_BIND_VERTEX_BUFFER;
d576 2
d581 56
d657 3
d663 7
@


1.1.1.1
log
@Import Mesa 7.10.3
@
text
@@


1.1.1.2
log
@Import Mesa 9.2.0
@
text
@d23 20
d44 1
a44 57
#include "r600_public.h"
#include "r600_isa.h"
#include "evergreen_compute.h"
#include "r600d.h"

#include "sb/sb_public.h"

#include <errno.h>
#include "pipe/p_shader_tokens.h"
#include "util/u_blitter.h"
#include "util/u_debug.h"
#include "util/u_format_s3tc.h"
#include "util/u_memory.h"
#include "util/u_simple_shaders.h"
#include "util/u_upload_mgr.h"
#include "util/u_math.h"
#include "vl/vl_decoder.h"
#include "vl/vl_video_buffer.h"
#include "radeon/radeon_uvd.h"
#include "os/os_time.h"

static const struct debug_named_value debug_options[] = {
	/* logging */
	{ "texdepth", DBG_TEX_DEPTH, "Print texture depth info" },
	{ "compute", DBG_COMPUTE, "Print compute info" },
	{ "vm", DBG_VM, "Print virtual addresses when creating resources" },
	{ "trace_cs", DBG_TRACE_CS, "Trace cs and write rlockup_<csid>.c file with faulty cs" },

	/* shaders */
	{ "fs", DBG_FS, "Print fetch shaders" },
	{ "vs", DBG_VS, "Print vertex shaders" },
	{ "gs", DBG_GS, "Print geometry shaders" },
	{ "ps", DBG_PS, "Print pixel shaders" },
	{ "cs", DBG_CS, "Print compute shaders" },

	/* features */
	{ "nohyperz", DBG_NO_HYPERZ, "Disable Hyper-Z" },
#if defined(R600_USE_LLVM)
	{ "nollvm", DBG_NO_LLVM, "Disable the LLVM shader compiler" },
#endif
	{ "nocpdma", DBG_NO_CP_DMA, "Disable CP DMA" },
	{ "nodma", DBG_NO_ASYNC_DMA, "Disable asynchronous DMA" },
	/* GL uses the word INVALIDATE, gallium uses the word DISCARD */
	{ "noinvalrange", DBG_NO_DISCARD_RANGE, "Disable handling of INVALIDATE_RANGE map flags" },

	/* shader backend */
	{ "sb", DBG_SB, "Enable optimization of graphics shaders" },
	{ "sbcl", DBG_SB_CS, "Enable optimization of compute shaders" },
	{ "sbdry", DBG_SB_DRY_RUN, "Don't use optimized bytecode (just print the dumps)" },
	{ "sbstat", DBG_SB_STAT, "Print optimization statistics for shaders" },
	{ "sbdump", DBG_SB_DUMP, "Print IR dumps after some optimization passes" },
	{ "sbnofallback", DBG_SB_NO_FALLBACK, "Abort on errors instead of fallback" },
	{ "sbdisasm", DBG_SB_DISASM, "Use sb disassembler for shader dumps" },
	{ "sbsafemath", DBG_SB_SAFEMATH, "Disable unsafe math optimizations" },

	DEBUG_NAMED_VALUE_END /* must be last */
};
d49 2
a50 1
static struct r600_fence *r600_create_fence(struct r600_context *rctx)
d52 5
a56 56
	struct r600_screen *rscreen = rctx->screen;
	struct r600_fence *fence = NULL;

	pipe_mutex_lock(rscreen->fences.mutex);

	if (!rscreen->fences.bo) {
		/* Create the shared buffer object */
		rscreen->fences.bo = (struct r600_resource*)
			pipe_buffer_create(&rscreen->screen, PIPE_BIND_CUSTOM,
					   PIPE_USAGE_STAGING, 4096);
		if (!rscreen->fences.bo) {
			R600_ERR("r600: failed to create bo for fence objects\n");
			goto out;
		}
		rscreen->fences.data = r600_buffer_mmap_sync_with_rings(rctx, rscreen->fences.bo, PIPE_TRANSFER_READ_WRITE);
	}

	if (!LIST_IS_EMPTY(&rscreen->fences.pool)) {
		struct r600_fence *entry;

		/* Try to find a freed fence that has been signalled */
		LIST_FOR_EACH_ENTRY(entry, &rscreen->fences.pool, head) {
			if (rscreen->fences.data[entry->index] != 0) {
				LIST_DELINIT(&entry->head);
				fence = entry;
				break;
			}
		}
	}

	if (!fence) {
		/* Allocate a new fence */
		struct r600_fence_block *block;
		unsigned index;

		if ((rscreen->fences.next_index + 1) >= 1024) {
			R600_ERR("r600: too many concurrent fences\n");
			goto out;
		}

		index = rscreen->fences.next_index++;

		if (!(index % FENCE_BLOCK_SIZE)) {
			/* Allocate a new block */
			block = CALLOC_STRUCT(r600_fence_block);
			if (block == NULL)
				goto out;

			LIST_ADD(&block->head, &rscreen->fences.blocks);
		} else {
			block = LIST_ENTRY(struct r600_fence_block, rscreen->fences.blocks.next, head);
		}

		fence = &block->fences[index % FENCE_BLOCK_SIZE];
		fence->index = index;
	}
d58 1
a58 25
	pipe_reference_init(&fence->reference, 1);

	rscreen->fences.data[fence->index] = 0;
	r600_context_emit_fence(rctx, rscreen->fences.bo, fence->index, 1);

	/* Create a dummy BO so that fence_finish without a timeout can sleep waiting for completion */
	fence->sleep_bo = (struct r600_resource*)
			pipe_buffer_create(&rctx->screen->screen, PIPE_BIND_CUSTOM,
					   PIPE_USAGE_STAGING, 1);
	/* Add the fence as a dummy relocation. */
	r600_context_bo_reloc(rctx, &rctx->rings.gfx, fence->sleep_bo, RADEON_USAGE_READWRITE);

out:
	pipe_mutex_unlock(rscreen->fences.mutex);
	return fence;
}

static void r600_flush(struct pipe_context *ctx, unsigned flags)
{
	struct r600_context *rctx = (struct r600_context *)ctx;
	struct pipe_query *render_cond = NULL;
	unsigned render_cond_mode = 0;
	boolean render_cond_cond = FALSE;

	if (rctx->rings.gfx.cs->cdw == rctx->initial_gfx_cs_size)
d61 5
a65 7
	rctx->rings.gfx.flushing = true;
	/* Disable render condition. */
	if (rctx->current_render_cond) {
		render_cond = rctx->current_render_cond;
		render_cond_cond = rctx->current_render_cond_cond;
		render_cond_mode = rctx->current_render_cond_mode;
		ctx->render_condition(ctx, NULL, FALSE, 0);
d67 3
d71 1
a71 138
	r600_context_flush(rctx, flags);
	rctx->rings.gfx.flushing = false;
	r600_begin_new_cs(rctx);

	/* Re-enable render condition. */
	if (render_cond) {
		ctx->render_condition(ctx, render_cond, render_cond_cond, render_cond_mode);
	}

	rctx->initial_gfx_cs_size = rctx->rings.gfx.cs->cdw;
}

static void r600_flush_from_st(struct pipe_context *ctx,
			       struct pipe_fence_handle **fence,
			       unsigned flags)
{
	struct r600_context *rctx = (struct r600_context *)ctx;
	struct r600_fence **rfence = (struct r600_fence**)fence;
	unsigned fflags;

	fflags = flags & PIPE_FLUSH_END_OF_FRAME ? RADEON_FLUSH_END_OF_FRAME : 0;
	if (rfence) {
		*rfence = r600_create_fence(rctx);
	}
	/* flush gfx & dma ring, order does not matter as only one can be live */
	if (rctx->rings.dma.cs) {
		rctx->rings.dma.flush(rctx, fflags);
	}
	rctx->rings.gfx.flush(rctx, fflags);
}

static void r600_flush_gfx_ring(void *ctx, unsigned flags)
{
	r600_flush((struct pipe_context*)ctx, flags);
}

static void r600_flush_dma_ring(void *ctx, unsigned flags)
{
	struct r600_context *rctx = (struct r600_context *)ctx;
	struct radeon_winsys_cs *cs = rctx->rings.dma.cs;
	unsigned padding_dw, i;

	if (!cs->cdw) {
		return;
	}

	/* Pad the DMA CS to a multiple of 8 dwords. */
	padding_dw = 8 - cs->cdw % 8;
	if (padding_dw < 8) {
		for (i = 0; i < padding_dw; i++) {
			cs->buf[cs->cdw++] = DMA_PACKET(DMA_PACKET_NOP, 0, 0, 0);
		}
	}

	rctx->rings.dma.flushing = true;
	rctx->ws->cs_flush(cs, flags, 0);
	rctx->rings.dma.flushing = false;
}

boolean r600_rings_is_buffer_referenced(struct r600_context *ctx,
					struct radeon_winsys_cs_handle *buf,
					enum radeon_bo_usage usage)
{
	if (ctx->ws->cs_is_buffer_referenced(ctx->rings.gfx.cs, buf, usage)) {
		return TRUE;
	}
	if (ctx->rings.dma.cs) {
		if (ctx->ws->cs_is_buffer_referenced(ctx->rings.dma.cs, buf, usage)) {
			return TRUE;
		}
	}
	return FALSE;
}

void *r600_buffer_mmap_sync_with_rings(struct r600_context *ctx,
					struct r600_resource *resource,
					unsigned usage)
{
	enum radeon_bo_usage rusage = RADEON_USAGE_READWRITE;
	unsigned flags = 0;
	bool sync_flush = TRUE;

	if (usage & PIPE_TRANSFER_UNSYNCHRONIZED) {
		return ctx->ws->buffer_map(resource->cs_buf, NULL, usage);
	}

	if (!(usage & PIPE_TRANSFER_WRITE)) {
		/* have to wait for pending read */
		rusage = RADEON_USAGE_WRITE;
	}
	if (usage & PIPE_TRANSFER_DONTBLOCK) {
		flags |= RADEON_FLUSH_ASYNC;
	}

	if (ctx->ws->cs_is_buffer_referenced(ctx->rings.gfx.cs, resource->cs_buf, rusage) && ctx->rings.gfx.cs->cdw) {
		ctx->rings.gfx.flush(ctx, flags);
		if (usage & PIPE_TRANSFER_DONTBLOCK) {
			return NULL;
		}
	}
	if (ctx->rings.dma.cs) {
		if (ctx->ws->cs_is_buffer_referenced(ctx->rings.dma.cs, resource->cs_buf, rusage) && ctx->rings.dma.cs->cdw) {
			ctx->rings.dma.flush(ctx, flags);
			if (usage & PIPE_TRANSFER_DONTBLOCK) {
				return NULL;
			}
		}
	}

	if (usage & PIPE_TRANSFER_DONTBLOCK) {
		if (ctx->ws->buffer_is_busy(resource->buf, rusage)) {
			return NULL;
		}
	}
	if (sync_flush) {
		/* Try to avoid busy-waiting in radeon_bo_wait. */
		ctx->ws->cs_sync_flush(ctx->rings.gfx.cs);
		if (ctx->rings.dma.cs) {
			ctx->ws->cs_sync_flush(ctx->rings.dma.cs);
		}
	}

	/* at this point everything is synchronized */
	return ctx->ws->buffer_map(resource->cs_buf, NULL, usage);
}

static void r600_flush_from_winsys(void *ctx, unsigned flags)
{
	struct r600_context *rctx = (struct r600_context *)ctx;

	rctx->rings.gfx.flush(rctx, flags);
}

static void r600_flush_dma_from_winsys(void *ctx, unsigned flags)
{
	struct r600_context *rctx = (struct r600_context *)ctx;

	rctx->rings.dma.flush(rctx, flags);
d76 1
a76 1
	struct r600_context *rctx = (struct r600_context *)context;
d78 1
a78 1
	r600_isa_destroy(rctx->isa);
d80 1
a80 1
	r600_sb_context_destroy(rctx->sb_context);
d82 1
a82 2
	pipe_resource_reference((struct pipe_resource**)&rctx->dummy_cmask, NULL);
	pipe_resource_reference((struct pipe_resource**)&rctx->dummy_fmask, NULL);
d84 1
a84 13
	if (rctx->dummy_pixel_shader) {
		rctx->context.delete_fs_state(&rctx->context, rctx->dummy_pixel_shader);
	}
	if (rctx->custom_dsa_flush) {
		rctx->context.delete_depth_stencil_alpha_state(&rctx->context, rctx->custom_dsa_flush);
	}
	if (rctx->custom_blend_resolve) {
		rctx->context.delete_blend_state(&rctx->context, rctx->custom_blend_resolve);
	}
	if (rctx->custom_blend_decompress) {
		rctx->context.delete_blend_state(&rctx->context, rctx->custom_blend_decompress);
	}
	util_unreference_framebuffer_state(&rctx->framebuffer.state);
d86 2
a87 2
	if (rctx->blitter) {
		util_blitter_destroy(rctx->blitter);
a88 10
	if (rctx->uploader) {
		u_upload_destroy(rctx->uploader);
	}
	if (rctx->allocator_so_filled_size) {
		u_suballocator_destroy(rctx->allocator_so_filled_size);
	}
	if (rctx->allocator_fetch_shader) {
		u_suballocator_destroy(rctx->allocator_fetch_shader);
	}
	util_slab_destroy(&rctx->pool_transfers);
d90 1
a90 1
	r600_release_command_buffer(&rctx->start_cs_cmd);
d92 2
a93 6
	if (rctx->rings.gfx.cs) {
		rctx->ws->cs_destroy(rctx->rings.gfx.cs);
	}
	if (rctx->rings.dma.cs) {
		rctx->ws->cs_destroy(rctx->rings.dma.cs);
	}
d95 2
d102 1
a102 1
	struct r600_context *rctx = CALLOC_STRUCT(r600_context);
d104 1
d108 1
a108 5

	util_slab_create(&rctx->pool_transfers,
			 sizeof(struct r600_transfer), 64,
			 UTIL_SLAB_SINGLETHREADED);

d112 1
a112 1
	rctx->context.flush = r600_flush_from_st;
d116 2
a117 6
	rctx->ws = rscreen->ws;
	rctx->family = rscreen->family;
	rctx->chip_class = rscreen->chip_class;
	rctx->keep_tiling_flags = rscreen->info.drm_minor >= 12;

	LIST_INITHEAD(&rctx->active_nontimer_queries);
d124 14
a137 13
	if (rscreen->info.has_uvd) {
		rctx->context.create_video_decoder = r600_uvd_create_decoder;
		rctx->context.create_video_buffer = r600_video_buffer_create;
	} else {
		rctx->context.create_video_decoder = vl_create_decoder;
		rctx->context.create_video_buffer = vl_video_buffer_create;
	}

	r600_init_common_state_functions(rctx);

	switch (rctx->chip_class) {
	case R600:
	case R700:
d139 5
a143 11
		r600_init_atom_start_cs(rctx);
		rctx->max_db = 4;
		rctx->custom_dsa_flush = r600_create_db_flush_dsa(rctx);
		rctx->custom_blend_resolve = rctx->chip_class == R700 ? r700_create_resolve_blend(rctx)
								      : r600_create_resolve_blend(rctx);
		rctx->custom_blend_decompress = r600_create_decompress_blend(rctx);
		rctx->has_vertex_cache = !(rctx->family == CHIP_RV610 ||
					   rctx->family == CHIP_RV620 ||
					   rctx->family == CHIP_RS780 ||
					   rctx->family == CHIP_RS880 ||
					   rctx->family == CHIP_RV710);
d145 10
a154 2
	case EVERGREEN:
	case CAYMAN:
d156 5
a160 13
		evergreen_init_atom_start_cs(rctx);
		evergreen_init_atom_start_compute_cs(rctx);
		rctx->max_db = 8;
		rctx->custom_dsa_flush = evergreen_create_db_flush_dsa(rctx);
		rctx->custom_blend_resolve = evergreen_create_resolve_blend(rctx);
		rctx->custom_blend_decompress = evergreen_create_decompress_blend(rctx);
		rctx->has_vertex_cache = !(rctx->family == CHIP_CEDAR ||
					   rctx->family == CHIP_PALM ||
					   rctx->family == CHIP_SUMO ||
					   rctx->family == CHIP_SUMO2 ||
					   rctx->family == CHIP_CAICOS ||
					   rctx->family == CHIP_CAYMAN ||
					   rctx->family == CHIP_ARUBA);
d163 3
a165 2
		R600_ERR("Unsupported chip class %d.\n", rctx->chip_class);
		goto fail;
d168 4
a171 4
	if (rscreen->trace_bo) {
		rctx->rings.gfx.cs = rctx->ws->cs_create(rctx->ws, RING_GFX, rscreen->trace_bo->cs_buf);
	} else {
		rctx->rings.gfx.cs = rctx->ws->cs_create(rctx->ws, RING_GFX, NULL);
d173 23
a195 10
	rctx->rings.gfx.flush = r600_flush_gfx_ring;
	rctx->ws->cs_set_flush_callback(rctx->rings.gfx.cs, r600_flush_from_winsys, rctx);
	rctx->rings.gfx.flushing = false;

	rctx->rings.dma.cs = NULL;
	if (rscreen->info.r600_has_dma && !(rscreen->debug_flags & DBG_NO_ASYNC_DMA)) {
		rctx->rings.dma.cs = rctx->ws->cs_create(rctx->ws, RING_DMA, NULL);
		rctx->rings.dma.flush = r600_flush_dma_ring;
		rctx->ws->cs_set_flush_callback(rctx->rings.dma.cs, r600_flush_dma_from_winsys, rctx);
		rctx->rings.dma.flushing = false;
d198 5
a202 19
	rctx->uploader = u_upload_create(&rctx->context, 1024 * 1024, 256,
					PIPE_BIND_INDEX_BUFFER |
					PIPE_BIND_CONSTANT_BUFFER);
	if (!rctx->uploader)
		goto fail;

	rctx->allocator_fetch_shader = u_suballocator_create(&rctx->context, 64 * 1024, 256,
							     0, PIPE_USAGE_STATIC, FALSE);
	if (!rctx->allocator_fetch_shader)
		goto fail;

	rctx->allocator_so_filled_size = u_suballocator_create(&rctx->context, 4096, 4,
								0, PIPE_USAGE_STATIC, TRUE);
	if (!rctx->allocator_so_filled_size)
		goto fail;

	rctx->isa = calloc(1, sizeof(struct r600_isa));
	if (!rctx->isa || r600_isa_init(rctx, rctx->isa))
		goto fail;
d204 1
a204 14
	rctx->blitter = util_blitter_create(&rctx->context);
	if (rctx->blitter == NULL)
		goto fail;
	util_blitter_set_texture_multisample(rctx->blitter, rscreen->has_msaa);
	rctx->blitter->draw_rectangle = r600_draw_rectangle;

	r600_begin_new_cs(rctx);
	r600_get_backend_mask(rctx); /* this emits commands and must be last */

	rctx->dummy_pixel_shader =
		util_make_fragment_cloneinput_shader(&rctx->context, 0,
						     TGSI_SEMANTIC_GENERIC,
						     TGSI_INTERPOLATE_CONSTANT);
	rctx->context.bind_fs_state(&rctx->context, rctx->dummy_pixel_shader);
a206 4

fail:
	r600_destroy_context(&rctx->context);
	return NULL;
a237 2
	case CHIP_SUMO: return "AMD SUMO";
	case CHIP_SUMO2: return "AMD SUMO2";
a240 2
	case CHIP_CAYMAN: return "AMD CAYMAN";
	case CHIP_ARUBA: return "AMD ARUBA";
d248 1
d250 1
a250 1
	return r600_get_family_name(rscreen->family);
d256 1
a256 1
	enum radeon_family family = rscreen->family;
d262 2
d269 1
d271 1
d273 3
a275 1
	case PIPE_CAP_DEPTH_CLIP_DISABLE:
a276 24
	case PIPE_CAP_VERTEX_ELEMENT_INSTANCE_DIVISOR:
	case PIPE_CAP_MIXED_COLORBUFFER_FORMATS:
	case PIPE_CAP_TGSI_FS_COORD_ORIGIN_UPPER_LEFT:
	case PIPE_CAP_TGSI_FS_COORD_PIXEL_CENTER_HALF_INTEGER:
	case PIPE_CAP_SM3:
	case PIPE_CAP_SEAMLESS_CUBE_MAP:
	case PIPE_CAP_PRIMITIVE_RESTART:
	case PIPE_CAP_CONDITIONAL_RENDER:
	case PIPE_CAP_TEXTURE_BARRIER:
	case PIPE_CAP_VERTEX_COLOR_UNCLAMPED:
	case PIPE_CAP_QUADS_FOLLOW_PROVOKING_VERTEX_CONVENTION:
	case PIPE_CAP_TGSI_INSTANCEID:
	case PIPE_CAP_VERTEX_BUFFER_OFFSET_4BYTE_ALIGNED_ONLY:
	case PIPE_CAP_VERTEX_BUFFER_STRIDE_4BYTE_ALIGNED_ONLY:
	case PIPE_CAP_VERTEX_ELEMENT_SRC_OFFSET_4BYTE_ALIGNED_ONLY:
	case PIPE_CAP_USER_INDEX_BUFFERS:
	case PIPE_CAP_USER_CONSTANT_BUFFERS:
	case PIPE_CAP_COMPUTE:
	case PIPE_CAP_START_INSTANCE:
	case PIPE_CAP_MAX_DUAL_SOURCE_RENDER_TARGETS:
	case PIPE_CAP_TEXTURE_BUFFER_OBJECTS:
        case PIPE_CAP_PREFER_BLIT_BASED_TEXTURE_TRANSFER:
	case PIPE_CAP_QUERY_PIPELINE_STATISTICS:
	case PIPE_CAP_TEXTURE_MULTISAMPLE:
d279 5
a283 37
	case PIPE_CAP_TGSI_TEXCOORD:
		return 0;

	case PIPE_CAP_MAX_TEXTURE_BUFFER_SIZE:
		return MIN2(rscreen->info.vram_size, 0xFFFFFFFF);

        case PIPE_CAP_MIN_MAP_BUFFER_ALIGNMENT:
                return R600_MAP_BUFFER_ALIGNMENT;

	case PIPE_CAP_CONSTANT_BUFFER_OFFSET_ALIGNMENT:
		return 256;

	case PIPE_CAP_TEXTURE_BUFFER_OFFSET_ALIGNMENT:
		return 1;

	case PIPE_CAP_GLSL_FEATURE_LEVEL:
		return 140;

	/* Supported except the original R600. */
	case PIPE_CAP_INDEP_BLEND_ENABLE:
	case PIPE_CAP_INDEP_BLEND_FUNC:
		/* R600 doesn't support per-MRT blends */
		return family == CHIP_R600 ? 0 : 1;

	/* Supported on Evergreen. */
	case PIPE_CAP_SEAMLESS_CUBE_MAP_PER_TEXTURE:
	case PIPE_CAP_CUBE_MAP_ARRAY:
		return family >= CHIP_CEDAR ? 1 : 0;

	/* Unsupported features. */
	case PIPE_CAP_TGSI_FS_COORD_ORIGIN_LOWER_LEFT:
	case PIPE_CAP_TGSI_FS_COORD_PIXEL_CENTER_INTEGER:
	case PIPE_CAP_SCALED_RESOLVE:
	case PIPE_CAP_TGSI_CAN_COMPACT_CONSTANTS:
	case PIPE_CAP_FRAGMENT_COLOR_CLAMPED:
	case PIPE_CAP_VERTEX_COLOR_CLAMPED:
	case PIPE_CAP_USER_VERTEX_BUFFERS:
a285 9
	/* Stream output. */
	case PIPE_CAP_MAX_STREAM_OUTPUT_BUFFERS:
		return rscreen->has_streamout ? 4 : 0;
	case PIPE_CAP_STREAM_OUTPUT_PAUSE_RESUME:
		return rscreen->has_streamout ? 1 : 0;
	case PIPE_CAP_MAX_STREAM_OUTPUT_SEPARATE_COMPONENTS:
	case PIPE_CAP_MAX_STREAM_OUTPUT_INTERLEAVED_COMPONENTS:
		return 32*4;

d294 4
a297 3
	case PIPE_CAP_MAX_TEXTURE_ARRAY_LAYERS:
		return rscreen->info.drm_minor >= 9 ?
			(family >= CHIP_CEDAR ? 16384 : 8192) : 0;
d299 1
a299 1
		return 32;
d303 1
a303 1
		/* XXX some r6xx are buggy and can only do 4 */
d306 11
a316 17
	/* Timer queries, present when the clock frequency is non zero. */
	case PIPE_CAP_QUERY_TIME_ELAPSED:
		return rscreen->info.r600_clock_crystal_freq != 0;
	case PIPE_CAP_QUERY_TIMESTAMP:
		return rscreen->info.drm_minor >= 20 &&
		       rscreen->info.r600_clock_crystal_freq != 0;

	case PIPE_CAP_MIN_TEXEL_OFFSET:
		return -8;

	case PIPE_CAP_MAX_TEXEL_OFFSET:
		return 7;

	case PIPE_CAP_TEXTURE_BORDER_COLOR_QUIRK:
		return PIPE_QUIRK_TEXTURE_BORDER_COLOR_SWIZZLE_R600;
	case PIPE_CAP_ENDIANNESS:
		return PIPE_ENDIAN_LITTLE;
a317 1
	return 0;
d320 1
a320 2
static float r600_get_paramf(struct pipe_screen* pscreen,
			     enum pipe_capf param)
d323 1
a323 1
	enum radeon_family family = rscreen->family;
d326 4
a329 4
	case PIPE_CAPF_MAX_LINE_WIDTH:
	case PIPE_CAPF_MAX_LINE_WIDTH_AA:
	case PIPE_CAPF_MAX_POINT_WIDTH:
	case PIPE_CAPF_MAX_POINT_WIDTH_AA:
d334 1
a334 1
	case PIPE_CAPF_MAX_TEXTURE_ANISOTROPY:
d336 1
a336 1
	case PIPE_CAPF_MAX_TEXTURE_LOD_BIAS:
d338 2
a339 4
	case PIPE_CAPF_GUARD_BAND_LEFT:
	case PIPE_CAPF_GUARD_BAND_TOP:
	case PIPE_CAPF_GUARD_BAND_RIGHT:
	case PIPE_CAPF_GUARD_BAND_BOTTOM:
a341 1
	return 0.0f;
a349 1
        case PIPE_SHADER_COMPUTE:
d352 1
a352 1
		/* XXX: support and enable geometry programs */
d355 1
a355 1
		/* XXX: support tessellation on Evergreen */
d359 1
d367 1
a367 1
		return 32;
d369 4
a372 1
		return 32;
d374 1
a374 1
		return 256; /* Max native temporaries. */
d376 1
a376 2
		/* XXX Isn't this equal to TEMPS? */
		return 1; /* Max native address registers */
d378 1
a378 1
		return R600_MAX_CONST_BUFFER_SIZE;
d380 1
a380 1
		return R600_MAX_USER_CONST_BUFFERS;
d382 1
a382 1
		return 0; /* nothing uses this */
a384 2
	case PIPE_SHADER_CAP_TGSI_SQRT_SUPPORTED:
		return 0;
a391 34
	case PIPE_SHADER_CAP_INTEGERS:
		return 1;
	case PIPE_SHADER_CAP_MAX_TEXTURE_SAMPLERS:
		return 16;
        case PIPE_SHADER_CAP_PREFERRED_IR:
		if (shader == PIPE_SHADER_COMPUTE) {
			return PIPE_SHADER_IR_LLVM;
		} else {
			return PIPE_SHADER_IR_TGSI;
		}
	}
	return 0;
}

static int r600_get_video_param(struct pipe_screen *screen,
				enum pipe_video_profile profile,
				enum pipe_video_cap param)
{
	switch (param) {
	case PIPE_VIDEO_CAP_SUPPORTED:
		return vl_profile_supported(screen, profile);
	case PIPE_VIDEO_CAP_NPOT_TEXTURES:
		return 1;
	case PIPE_VIDEO_CAP_MAX_WIDTH:
	case PIPE_VIDEO_CAP_MAX_HEIGHT:
		return vl_video_buffer_max_size(screen);
	case PIPE_VIDEO_CAP_PREFERED_FORMAT:
		return PIPE_FORMAT_NV12;
	case PIPE_VIDEO_CAP_PREFERS_INTERLACED:
		return false;
	case PIPE_VIDEO_CAP_SUPPORTS_INTERLACED:
		return false;
	case PIPE_VIDEO_CAP_SUPPORTS_PROGRESSIVE:
		return true;
d397 47
a443 3
const char * r600_llvm_gpu_string(enum radeon_family family)
{
	const char * gpu_family;
d445 1
a445 155
	switch (family) {
	case CHIP_R600:
	case CHIP_RV630:
	case CHIP_RV635:
	case CHIP_RV670:
		gpu_family = "r600";
		break;
	case CHIP_RV610:
	case CHIP_RV620:
	case CHIP_RS780:
	case CHIP_RS880:
		gpu_family = "rs880";
		break;
	case CHIP_RV710:
		gpu_family = "rv710";
		break;
	case CHIP_RV730:
		gpu_family = "rv730";
		break;
	case CHIP_RV740:
	case CHIP_RV770:
		gpu_family = "rv770";
		break;
	case CHIP_PALM:
	case CHIP_CEDAR:
		gpu_family = "cedar";
		break;
	case CHIP_SUMO:
	case CHIP_SUMO2:
		gpu_family = "sumo";
		break;
	case CHIP_REDWOOD:
		gpu_family = "redwood";
		break;
	case CHIP_JUNIPER:
		gpu_family = "juniper";
		break;
	case CHIP_HEMLOCK:
	case CHIP_CYPRESS:
		gpu_family = "cypress";
		break;
	case CHIP_BARTS:
		gpu_family = "barts";
		break;
	case CHIP_TURKS:
		gpu_family = "turks";
		break;
	case CHIP_CAICOS:
		gpu_family = "caicos";
		break;
	case CHIP_CAYMAN:
        case CHIP_ARUBA:
		gpu_family = "cayman";
		break;
	default:
		gpu_family = "";
		fprintf(stderr, "Chip not supported by r600 llvm "
			"backend, please file a bug at " PACKAGE_BUGREPORT "\n");
		break;
	}
	return gpu_family;
}


static int r600_get_compute_param(struct pipe_screen *screen,
        enum pipe_compute_cap param,
        void *ret)
{
	struct r600_screen *rscreen = (struct r600_screen *)screen;
	//TODO: select these params by asic
	switch (param) {
	case PIPE_COMPUTE_CAP_IR_TARGET: {
		const char *gpu = r600_llvm_gpu_string(rscreen->family);
		if (ret) {
			sprintf(ret, "%s-r600--", gpu);
		}
		return (8 + strlen(gpu)) * sizeof(char);
	}
	case PIPE_COMPUTE_CAP_GRID_DIMENSION:
		if (ret) {
			uint64_t * grid_dimension = ret;
			grid_dimension[0] = 3;
		}
		return 1 * sizeof(uint64_t);

	case PIPE_COMPUTE_CAP_MAX_GRID_SIZE:
		if (ret) {
			uint64_t * grid_size = ret;
			grid_size[0] = 65535;
			grid_size[1] = 65535;
			grid_size[2] = 1;
		}
		return 3 * sizeof(uint64_t) ;

	case PIPE_COMPUTE_CAP_MAX_BLOCK_SIZE:
		if (ret) {
			uint64_t * block_size = ret;
			block_size[0] = 256;
			block_size[1] = 256;
			block_size[2] = 256;
		}
		return 3 * sizeof(uint64_t);

	case PIPE_COMPUTE_CAP_MAX_THREADS_PER_BLOCK:
		if (ret) {
			uint64_t * max_threads_per_block = ret;
			*max_threads_per_block = 256;
		}
		return sizeof(uint64_t);

	case PIPE_COMPUTE_CAP_MAX_GLOBAL_SIZE:
		if (ret) {
			uint64_t * max_global_size = ret;
			/* XXX: This is what the proprietary driver reports, we
			 * may want to use a different value. */
			*max_global_size = 201326592;
		}
		return sizeof(uint64_t);

	case PIPE_COMPUTE_CAP_MAX_INPUT_SIZE:
		if (ret) {
			uint64_t * max_input_size = ret;
			*max_input_size = 1024;
		}
		return sizeof(uint64_t);

	case PIPE_COMPUTE_CAP_MAX_LOCAL_SIZE:
		if (ret) {
			uint64_t * max_local_size = ret;
			/* XXX: This is what the proprietary driver reports, we
			 * may want to use a different value. */
			*max_local_size = 32768;
		}
		return sizeof(uint64_t);

	case PIPE_COMPUTE_CAP_MAX_MEM_ALLOC_SIZE:
		if (ret) {
			uint64_t max_global_size;
			uint64_t * max_mem_alloc_size = ret;
			r600_get_compute_param(screen,
					PIPE_COMPUTE_CAP_MAX_GLOBAL_SIZE,
					&max_global_size);
			/* OpenCL requres this value be at least
			 * max(MAX_GLOBAL_SIZE / 4, 128 * 1024 *1024)
			 * I'm really not sure what value to report here, but
			 * MAX_GLOBAL_SIZE / 4 seems resonable.
			 */
			*max_mem_alloc_size = max_global_size / 4;
		}
		return sizeof(uint64_t);

	default:
		fprintf(stderr, "unknown PIPE_COMPUTE_CAP %d\n", param);
		return 0;
	}
d455 1
a455 2
	pipe_mutex_destroy(rscreen->aux_context_lock);
	rscreen->aux_context->destroy(rscreen->aux_context);
a456 22
	if (rscreen->global_pool) {
		compute_memory_pool_delete(rscreen->global_pool);
	}

	if (rscreen->fences.bo) {
		struct r600_fence_block *entry, *tmp;

		LIST_FOR_EACH_ENTRY_SAFE(entry, tmp, &rscreen->fences.blocks, head) {
			LIST_DEL(&entry->head);
			FREE(entry);
		}

		rscreen->ws->buffer_unmap(rscreen->fences.bo->cs_buf);
		pipe_resource_reference((struct pipe_resource**)&rscreen->fences.bo, NULL);
	}
	if (rscreen->trace_bo) {
		rscreen->ws->buffer_unmap(rscreen->trace_bo->cs_buf);
		pipe_resource_reference((struct pipe_resource**)&rscreen->trace_bo, NULL);
	}
	pipe_mutex_destroy(rscreen->fences.mutex);

	rscreen->ws->destroy(rscreen->ws);
a459 17
static void r600_fence_reference(struct pipe_screen *pscreen,
                                 struct pipe_fence_handle **ptr,
                                 struct pipe_fence_handle *fence)
{
	struct r600_fence **oldf = (struct r600_fence**)ptr;
	struct r600_fence *newf = (struct r600_fence*)fence;

	if (pipe_reference(&(*oldf)->reference, &newf->reference)) {
		struct r600_screen *rscreen = (struct r600_screen *)pscreen;
		pipe_mutex_lock(rscreen->fences.mutex);
		pipe_resource_reference((struct pipe_resource**)&(*oldf)->sleep_bo, NULL);
		LIST_ADDTAIL(&(*oldf)->head, &rscreen->fences.pool);
		pipe_mutex_unlock(rscreen->fences.mutex);
	}

	*ptr = fence;
}
d461 1
a461 2
static boolean r600_fence_signalled(struct pipe_screen *pscreen,
                                    struct pipe_fence_handle *fence)
d463 1
a463 193
	struct r600_screen *rscreen = (struct r600_screen *)pscreen;
	struct r600_fence *rfence = (struct r600_fence*)fence;

	return rscreen->fences.data[rfence->index] != 0;
}

static boolean r600_fence_finish(struct pipe_screen *pscreen,
                                 struct pipe_fence_handle *fence,
                                 uint64_t timeout)
{
	struct r600_screen *rscreen = (struct r600_screen *)pscreen;
	struct r600_fence *rfence = (struct r600_fence*)fence;
	int64_t start_time = 0;
	unsigned spins = 0;

	if (timeout != PIPE_TIMEOUT_INFINITE) {
		start_time = os_time_get();

		/* Convert to microseconds. */
		timeout /= 1000;
	}

	while (rscreen->fences.data[rfence->index] == 0) {
		/* Special-case infinite timeout - wait for the dummy BO to become idle */
		if (timeout == PIPE_TIMEOUT_INFINITE) {
			rscreen->ws->buffer_wait(rfence->sleep_bo->buf, RADEON_USAGE_READWRITE);
			break;
		}

		/* The dummy BO will be busy until the CS including the fence has completed, or
		 * the GPU is reset. Don't bother continuing to spin when the BO is idle. */
		if (!rscreen->ws->buffer_is_busy(rfence->sleep_bo->buf, RADEON_USAGE_READWRITE))
			break;

		if (++spins % 256)
			continue;
#ifdef PIPE_OS_UNIX
		sched_yield();
#else
		os_time_sleep(10);
#endif
		if (timeout != PIPE_TIMEOUT_INFINITE &&
		    os_time_get() - start_time >= timeout) {
			break;
		}
	}

	return rscreen->fences.data[rfence->index] != 0;
}

static int r600_interpret_tiling(struct r600_screen *rscreen, uint32_t tiling_config)
{
	switch ((tiling_config & 0xe) >> 1) {
	case 0:
		rscreen->tiling_info.num_channels = 1;
		break;
	case 1:
		rscreen->tiling_info.num_channels = 2;
		break;
	case 2:
		rscreen->tiling_info.num_channels = 4;
		break;
	case 3:
		rscreen->tiling_info.num_channels = 8;
		break;
	default:
		return -EINVAL;
	}

	switch ((tiling_config & 0x30) >> 4) {
	case 0:
		rscreen->tiling_info.num_banks = 4;
		break;
	case 1:
		rscreen->tiling_info.num_banks = 8;
		break;
	default:
		return -EINVAL;

	}
	switch ((tiling_config & 0xc0) >> 6) {
	case 0:
		rscreen->tiling_info.group_bytes = 256;
		break;
	case 1:
		rscreen->tiling_info.group_bytes = 512;
		break;
	default:
		return -EINVAL;
	}
	return 0;
}

static int evergreen_interpret_tiling(struct r600_screen *rscreen, uint32_t tiling_config)
{
	switch (tiling_config & 0xf) {
	case 0:
		rscreen->tiling_info.num_channels = 1;
		break;
	case 1:
		rscreen->tiling_info.num_channels = 2;
		break;
	case 2:
		rscreen->tiling_info.num_channels = 4;
		break;
	case 3:
		rscreen->tiling_info.num_channels = 8;
		break;
	default:
		return -EINVAL;
	}

	switch ((tiling_config & 0xf0) >> 4) {
	case 0:
		rscreen->tiling_info.num_banks = 4;
		break;
	case 1:
		rscreen->tiling_info.num_banks = 8;
		break;
	case 2:
		rscreen->tiling_info.num_banks = 16;
		break;
	default:
		return -EINVAL;
	}

	switch ((tiling_config & 0xf00) >> 8) {
	case 0:
		rscreen->tiling_info.group_bytes = 256;
		break;
	case 1:
		rscreen->tiling_info.group_bytes = 512;
		break;
	default:
		return -EINVAL;
	}
	return 0;
}

static int r600_init_tiling(struct r600_screen *rscreen)
{
	uint32_t tiling_config = rscreen->info.r600_tiling_config;

	/* set default group bytes, overridden by tiling info ioctl */
	if (rscreen->chip_class <= R700) {
		rscreen->tiling_info.group_bytes = 256;
	} else {
		rscreen->tiling_info.group_bytes = 512;
	}

	if (!tiling_config)
		return 0;

	if (rscreen->chip_class <= R700) {
		return r600_interpret_tiling(rscreen, tiling_config);
	} else {
		return evergreen_interpret_tiling(rscreen, tiling_config);
	}
}

static uint64_t r600_get_timestamp(struct pipe_screen *screen)
{
	struct r600_screen *rscreen = (struct r600_screen*)screen;

	return 1000000 * rscreen->ws->query_value(rscreen->ws, RADEON_TIMESTAMP) /
			rscreen->info.r600_clock_crystal_freq;
}

static int r600_get_driver_query_info(struct pipe_screen *screen,
				      unsigned index,
				      struct pipe_driver_query_info *info)
{
	struct r600_screen *rscreen = (struct r600_screen*)screen;
	struct pipe_driver_query_info list[] = {
		{"draw-calls", R600_QUERY_DRAW_CALLS, 0},
		{"requested-VRAM", R600_QUERY_REQUESTED_VRAM, rscreen->info.vram_size, TRUE},
		{"requested-GTT", R600_QUERY_REQUESTED_GTT, rscreen->info.gart_size, TRUE},
		{"buffer-wait-time", R600_QUERY_BUFFER_WAIT_TIME, 0, FALSE}
	};

	if (!info)
		return Elements(list);

	if (index >= Elements(list))
		return 0;

	*info = list[index];
	return 1;
}

struct pipe_screen *r600_screen_create(struct radeon_winsys *ws)
{
	struct r600_screen *rscreen = CALLOC_STRUCT(r600_screen);
d465 1
d470 2
a471 72
	rscreen->ws = ws;
	ws->query_info(ws, &rscreen->info);

	rscreen->debug_flags = debug_get_flags_option("R600_DEBUG", debug_options, 0);
	if (debug_get_bool_option("R600_DEBUG_COMPUTE", FALSE))
		rscreen->debug_flags |= DBG_COMPUTE;
	if (debug_get_bool_option("R600_DUMP_SHADERS", FALSE))
		rscreen->debug_flags |= DBG_FS | DBG_VS | DBG_GS | DBG_PS | DBG_CS;
	if (!debug_get_bool_option("R600_HYPERZ", TRUE))
		rscreen->debug_flags |= DBG_NO_HYPERZ;
	if (!debug_get_bool_option("R600_LLVM", TRUE))
		rscreen->debug_flags |= DBG_NO_LLVM;
	if (debug_get_bool_option("R600_PRINT_TEXDEPTH", FALSE))
		rscreen->debug_flags |= DBG_TEX_DEPTH;
	rscreen->family = rscreen->info.family;
	rscreen->chip_class = rscreen->info.chip_class;

	if (rscreen->family == CHIP_UNKNOWN) {
		fprintf(stderr, "r600: Unknown chipset 0x%04X\n", rscreen->info.pci_id);
		FREE(rscreen);
		return NULL;
	}

	/* Figure out streamout kernel support. */
	switch (rscreen->chip_class) {
	case R600:
		if (rscreen->family < CHIP_RS780) {
			rscreen->has_streamout = rscreen->info.drm_minor >= 14;
		} else {
			rscreen->has_streamout = rscreen->info.drm_minor >= 23;
		}
		break;
	case R700:
		rscreen->has_streamout = rscreen->info.drm_minor >= 17;
		break;
	case EVERGREEN:
	case CAYMAN:
		rscreen->has_streamout = rscreen->info.drm_minor >= 14;
		break;
	default:
		rscreen->has_streamout = FALSE;
		break;
	}

	/* MSAA support. */
	switch (rscreen->chip_class) {
	case R600:
	case R700:
		rscreen->has_msaa = rscreen->info.drm_minor >= 22;
		rscreen->has_compressed_msaa_texturing = false;
		break;
	case EVERGREEN:
		rscreen->has_msaa = rscreen->info.drm_minor >= 19;
		rscreen->has_compressed_msaa_texturing = rscreen->info.drm_minor >= 24;
		break;
	case CAYMAN:
		rscreen->has_msaa = rscreen->info.drm_minor >= 19;
		rscreen->has_compressed_msaa_texturing = true;
		break;
	default:
		rscreen->has_msaa = FALSE;
		rscreen->has_compressed_msaa_texturing = false;
	}

	rscreen->has_cp_dma = rscreen->info.drm_minor >= 27 &&
			      !(rscreen->debug_flags & DBG_NO_CP_DMA);

	if (r600_init_tiling(rscreen)) {
		FREE(rscreen);
		return NULL;
	}

d478 1
a478 10
	rscreen->screen.get_compute_param = r600_get_compute_param;
	rscreen->screen.get_timestamp = r600_get_timestamp;

	if (rscreen->chip_class >= EVERGREEN) {
		rscreen->screen.is_format_supported = evergreen_is_format_supported;
		rscreen->dma_blit = &evergreen_dma_blit;
	} else {
		rscreen->screen.is_format_supported = r600_is_format_supported;
		rscreen->dma_blit = &r600_dma_blit;
	}
a479 13
	rscreen->screen.fence_reference = r600_fence_reference;
	rscreen->screen.fence_signalled = r600_fence_signalled;
	rscreen->screen.fence_finish = r600_fence_finish;
	rscreen->screen.get_driver_query_info = r600_get_driver_query_info;

	if (rscreen->info.has_uvd) {
		rscreen->screen.get_video_param = r600_uvd_get_video_param;
		rscreen->screen.is_video_format_supported = ruvd_is_format_supported;
	} else {
		rscreen->screen.get_video_param = r600_get_video_param;
		rscreen->screen.is_video_format_supported = vl_video_buffer_is_format_supported;
	}

d482 1
a482 58
	util_format_s3tc_init();

	rscreen->fences.bo = NULL;
	rscreen->fences.data = NULL;
	rscreen->fences.next_index = 0;
	LIST_INITHEAD(&rscreen->fences.pool);
	LIST_INITHEAD(&rscreen->fences.blocks);
	pipe_mutex_init(rscreen->fences.mutex);

	rscreen->global_pool = compute_memory_pool_new(rscreen);

	rscreen->cs_count = 0;
	if (rscreen->info.drm_minor >= 28 && (rscreen->debug_flags & DBG_TRACE_CS)) {
		rscreen->trace_bo = (struct r600_resource*)pipe_buffer_create(&rscreen->screen,
										PIPE_BIND_CUSTOM,
										PIPE_USAGE_STAGING,
										4096);
		if (rscreen->trace_bo) {
			rscreen->trace_ptr = rscreen->ws->buffer_map(rscreen->trace_bo->cs_buf, NULL,
									PIPE_TRANSFER_UNSYNCHRONIZED);
		}
	}

	/* Create the auxiliary context. */
	pipe_mutex_init(rscreen->aux_context_lock);
	rscreen->aux_context = rscreen->screen.context_create(&rscreen->screen, NULL);

#if 0 /* This is for testing whether aux_context and buffer clearing work correctly. */
	struct pipe_resource templ = {};

	templ.width0 = 4;
	templ.height0 = 2048;
	templ.depth0 = 1;
	templ.array_size = 1;
	templ.target = PIPE_TEXTURE_2D;
	templ.format = PIPE_FORMAT_R8G8B8A8_UNORM;
	templ.usage = PIPE_USAGE_STATIC;

	struct r600_resource *res = r600_resource(rscreen->screen.resource_create(&rscreen->screen, &templ));
	unsigned char *map = ws->buffer_map(res->cs_buf, NULL, PIPE_TRANSFER_WRITE);

	memset(map, 0, 256);

	r600_screen_clear_buffer(rscreen, &res->b.b, 4, 4, 0xCC);
	r600_screen_clear_buffer(rscreen, &res->b.b, 8, 4, 0xDD);
	r600_screen_clear_buffer(rscreen, &res->b.b, 12, 4, 0xEE);
	r600_screen_clear_buffer(rscreen, &res->b.b, 20, 4, 0xFF);
	r600_screen_clear_buffer(rscreen, &res->b.b, 32, 20, 0x87);

	ws->buffer_wait(res->buf, RADEON_USAGE_WRITE);

	int i;
	for (i = 0; i < 256; i++) {
		printf("%02X", map[i]);
		if (i % 16 == 15)
			printf("\n");
	}
#endif
@


1.1.1.3
log
@Import Mesa 10.2.3
@
text
@d35 1
a41 1
#include "radeon/radeon_video.h"
d45 14
a58 1
static const struct debug_named_value r600_debug_options[] = {
d60 1
d62 1
a62 1
	{ "llvm", DBG_LLVM, "Enable the LLVM shader compiler" },
d65 3
d70 2
a71 2
	{ "nosb", DBG_NO_SB, "Disable sb backend for graphics shaders" },
	{ "sbcl", DBG_SB_CS, "Enable sb backend for compute shaders" },
d85 234
d332 1
a332 1
		rctx->b.b.delete_fs_state(&rctx->b.b, rctx->dummy_pixel_shader);
d335 1
a335 1
		rctx->b.b.delete_depth_stencil_alpha_state(&rctx->b.b, rctx->custom_dsa_flush);
d338 1
a338 1
		rctx->b.b.delete_blend_state(&rctx->b.b, rctx->custom_blend_resolve);
d341 1
a341 4
		rctx->b.b.delete_blend_state(&rctx->b.b, rctx->custom_blend_decompress);
	}
	if (rctx->custom_blend_fastclear) {
		rctx->b.b.delete_blend_state(&rctx->b.b, rctx->custom_blend_fastclear);
d348 6
d357 1
d361 6
a366 1
	FREE(rctx->start_compute_cs_cmd.buf);
a367 1
	r600_common_context_cleanup(&rctx->b);
a374 1
	struct radeon_winsys *ws = rscreen->b.ws;
d379 8
a386 3
	rctx->b.b.screen = screen;
	rctx->b.b.priv = priv;
	rctx->b.b.destroy = r600_destroy_context;
d388 6
a393 2
	if (!r600_common_context_init(&rctx->b, &rscreen->b))
		goto fail;
d395 1
a395 2
	rctx->screen = rscreen;
	rctx->keep_tiling_flags = rscreen->b.info.drm_minor >= 12;
d398 7
a404 4

	if (rscreen->b.info.has_uvd) {
		rctx->b.b.create_video_codec = r600_uvd_create_decoder;
		rctx->b.b.create_video_buffer = r600_video_buffer_create;
d406 2
a407 2
		rctx->b.b.create_video_codec = vl_create_decoder;
		rctx->b.b.create_video_buffer = vl_video_buffer_create;
d412 1
a412 1
	switch (rctx->b.chip_class) {
d417 1
d419 1
a419 1
		rctx->custom_blend_resolve = rctx->b.chip_class == R700 ? r700_create_resolve_blend(rctx)
d422 5
a426 5
		rctx->has_vertex_cache = !(rctx->b.family == CHIP_RV610 ||
					   rctx->b.family == CHIP_RV620 ||
					   rctx->b.family == CHIP_RS780 ||
					   rctx->b.family == CHIP_RS880 ||
					   rctx->b.family == CHIP_RV710);
d433 1
d437 7
a443 8
		rctx->custom_blend_fastclear = evergreen_create_fastclear_blend(rctx);
		rctx->has_vertex_cache = !(rctx->b.family == CHIP_CEDAR ||
					   rctx->b.family == CHIP_PALM ||
					   rctx->b.family == CHIP_SUMO ||
					   rctx->b.family == CHIP_SUMO2 ||
					   rctx->b.family == CHIP_CAICOS ||
					   rctx->b.family == CHIP_CAYMAN ||
					   rctx->b.family == CHIP_ARUBA);
d446 1
a446 1
		R600_ERR("Unsupported chip class %d.\n", rctx->b.chip_class);
d450 22
a471 5
	rctx->b.rings.gfx.cs = ws->cs_create(ws, RING_GFX,
					     r600_context_gfx_flush, rctx,
					     rscreen->b.trace_bo ?
						     rscreen->b.trace_bo->cs_buf : NULL);
	rctx->b.rings.gfx.flush = r600_context_gfx_flush;
d473 2
a474 2
	rctx->allocator_fetch_shader = u_suballocator_create(&rctx->b.b, 64 * 1024, 256,
							     0, PIPE_USAGE_DEFAULT, FALSE);
d478 5
d487 1
a487 1
	rctx->blitter = util_blitter_create(&rctx->b.b);
d494 1
a494 1
	r600_query_init_backend_mask(&rctx->b); /* this emits commands and must be last */
d497 1
a497 1
		util_make_fragment_cloneinput_shader(&rctx->b.b, 0,
d500 1
a500 1
	rctx->b.b.bind_fs_state(&rctx->b.b, rctx->dummy_pixel_shader);
d502 1
a502 1
	return &rctx->b.b;
d505 1
a505 1
	r600_destroy_context(&rctx->b.b);
d512 43
d559 1
a559 1
	enum radeon_family family = rscreen->b.family;
a563 1
	case PIPE_CAP_MIXED_FRAMEBUFFER_SIZES:
d591 1
a597 1
        case PIPE_CAP_BUFFER_MAP_PERSISTENT_COHERENT:
a599 3
	case PIPE_CAP_COMPUTE:
		return rscreen->b.chip_class > R700;

a602 3
	case PIPE_CAP_FAKE_SW_MSAA:
		return 0;

d604 1
a604 1
		return MIN2(rscreen->b.info.vram_size, 0xFFFFFFFF);
a615 5
		if (family >= CHIP_CEDAR)
		   return 330;
		/* pre-evergreen geom shaders need newer kernel */
		if (rscreen->b.info.drm_minor >= 37)
		   return 330;
a626 1
	case PIPE_CAP_TGSI_VS_LAYER:
d632 1
a636 4
	case PIPE_CAP_MAX_TEXTURE_GATHER_COMPONENTS:
	case PIPE_CAP_TEXTURE_GATHER_SM5:
	case PIPE_CAP_TEXTURE_QUERY_LOD:
        case PIPE_CAP_SAMPLE_SHADING:
d641 1
a641 1
		return rscreen->b.has_streamout ? 4 : 0;
d643 1
a643 1
		return rscreen->b.has_streamout ? 1 : 0;
a647 6
	/* Geometry shader output. */
	case PIPE_CAP_MAX_GEOMETRY_OUTPUT_VERTICES:
		return 1024;
	case PIPE_CAP_MAX_GEOMETRY_TOTAL_OUTPUT_COMPONENTS:
		return 16384;

d650 1
a655 3
	case PIPE_CAP_MAX_TEXTURE_3D_LEVELS:
		/* textures support 8192, but layered rendering supports 2048 */
		return 12;
d657 4
a660 2
		/* textures support 8192, but layered rendering supports 2048 */
		return rscreen->b.info.drm_minor >= 9 ? 2048 : 0;
a666 3
	case PIPE_CAP_MAX_VIEWPORTS:
		return 16;

d669 1
a669 1
		return rscreen->b.info.r600_clock_crystal_freq != 0;
d671 2
a672 2
		return rscreen->b.info.drm_minor >= 20 &&
		       rscreen->b.info.r600_clock_crystal_freq != 0;
a673 1
	case PIPE_CAP_MIN_TEXTURE_GATHER_OFFSET:
a676 1
	case PIPE_CAP_MAX_TEXTURE_GATHER_OFFSET:
d688 2
a689 1
static int r600_get_shader_param(struct pipe_screen* pscreen, unsigned shader, enum pipe_shader_cap param)
d692 1
d694 24
d722 1
a722 1
	case PIPE_SHADER_COMPUTE:
d725 1
a725 5
		if (rscreen->b.family >= CHIP_CEDAR)
			break;
		/* pre-evergreen geom shaders need newer kernel */
		if (rscreen->b.info.drm_minor >= 37)
			break;
a766 1
	case PIPE_SHADER_CAP_MAX_SAMPLER_VIEWS:
d778 186
d971 2
a972 2
	if (!rscreen->b.ws->unref(rscreen->b.ws))
		return;
d978 19
a996 1
	r600_destroy_common_screen(&rscreen->b);
d999 3
a1001 2
static struct pipe_resource *r600_resource_create(struct pipe_screen *screen,
						  const struct pipe_resource *templ)
d1003 34
a1036 3
	if (templ->target == PIPE_BUFFER &&
	    (templ->bind & PIPE_BIND_GLOBAL))
		return r600_compute_global_buffer_create(screen, templ);
d1038 30
a1067 1
	return r600_resource_create_common(screen, templ);
d1070 44
a1113 1
struct pipe_screen *r600_screen_create(struct radeon_winsys *ws)
d1115 30
a1144 1
	struct r600_screen *rscreen = CALLOC_STRUCT(r600_screen);
d1146 9
a1154 2
	if (rscreen == NULL) {
		return NULL;
d1156 2
d1159 3
a1161 6
	/* Set functions first. */
	rscreen->b.b.context_create = r600_create_context;
	rscreen->b.b.destroy = r600_destroy_screen;
	rscreen->b.b.get_param = r600_get_param;
	rscreen->b.b.get_shader_param = r600_get_shader_param;
	rscreen->b.b.resource_create = r600_resource_create;
d1163 5
a1167 3
	if (!r600_common_screen_init(&rscreen->b, ws)) {
		FREE(rscreen);
		return NULL;
d1170 5
a1174 2
	if (rscreen->b.info.chip_class >= EVERGREEN) {
		rscreen->b.b.is_format_supported = evergreen_is_format_supported;
d1176 40
a1215 1
		rscreen->b.b.is_format_supported = r600_is_format_supported;
d1218 4
a1221 1
	rscreen->b.debug_flags |= debug_get_flags_option("R600_DEBUG", r600_debug_options, 0);
d1223 1
a1223 1
		rscreen->b.debug_flags |= DBG_COMPUTE;
d1225 9
a1233 5
		rscreen->b.debug_flags |= DBG_FS | DBG_VS | DBG_GS | DBG_PS | DBG_CS;
	if (debug_get_bool_option("R600_HYPERZ", FALSE))
		rscreen->b.debug_flags |= DBG_HYPERZ;
	if (debug_get_bool_option("R600_LLVM", FALSE))
		rscreen->b.debug_flags |= DBG_LLVM;
d1235 2
a1236 2
	if (rscreen->b.family == CHIP_UNKNOWN) {
		fprintf(stderr, "r600: Unknown chipset 0x%04X\n", rscreen->b.info.pci_id);
d1242 1
a1242 1
	switch (rscreen->b.chip_class) {
d1244 2
a1245 2
		if (rscreen->b.family < CHIP_RS780) {
			rscreen->b.has_streamout = rscreen->b.info.drm_minor >= 14;
d1247 1
a1247 1
			rscreen->b.has_streamout = rscreen->b.info.drm_minor >= 23;
d1251 1
a1251 1
		rscreen->b.has_streamout = rscreen->b.info.drm_minor >= 17;
d1255 1
a1255 1
		rscreen->b.has_streamout = rscreen->b.info.drm_minor >= 14;
d1258 1
a1258 1
		rscreen->b.has_streamout = FALSE;
d1263 1
a1263 1
	switch (rscreen->b.chip_class) {
d1266 1
a1266 1
		rscreen->has_msaa = rscreen->b.info.drm_minor >= 22;
d1270 2
a1271 2
		rscreen->has_msaa = rscreen->b.info.drm_minor >= 19;
		rscreen->has_compressed_msaa_texturing = rscreen->b.info.drm_minor >= 24;
d1274 1
a1274 1
		rscreen->has_msaa = rscreen->b.info.drm_minor >= 19;
d1282 48
a1329 2
	rscreen->b.has_cp_dma = rscreen->b.info.drm_minor >= 27 &&
			      !(rscreen->b.debug_flags & DBG_NO_CP_DMA);
d1333 15
a1347 2
	/* Create the auxiliary context. This must be done last. */
	rscreen->b.aux_context = rscreen->b.b.context_create(&rscreen->b.b, NULL);
d1358 1
a1358 1
	templ.usage = PIPE_USAGE_DEFAULT;
d1381 1
a1381 1
	return &rscreen->b.b;
@


1.1.1.4
log
@Import Mesa 10.4.3
@
text
@d33 1
a194 3
	if (rscreen->b.debug_flags & DBG_FORCE_DMA)
		rctx->b.b.resource_copy_region = rctx->b.dma_copy;

d263 1
a263 5
	case PIPE_CAP_BUFFER_MAP_PERSISTENT_COHERENT:
	case PIPE_CAP_TGSI_VS_WINDOW_SPACE_POSITION:
	case PIPE_CAP_TGSI_VS_LAYER_VIEWPORT:
	case PIPE_CAP_SAMPLE_SHADING:
	case PIPE_CAP_CLIP_HALFZ:
d304 1
a304 3
	case PIPE_CAP_TEXTURE_GATHER_SM5:
	case PIPE_CAP_TEXTURE_QUERY_LOD:
	case PIPE_CAP_TGSI_FS_FINE_DERIVATIVE:
a305 2
	case PIPE_CAP_MAX_TEXTURE_GATHER_COMPONENTS:
		return family >= CHIP_CEDAR ? 4 : 0;
d314 4
a317 4
	case PIPE_CAP_TEXTURE_GATHER_OFFSETS:
	case PIPE_CAP_DRAW_INDIRECT:
	case PIPE_CAP_CONDITIONAL_RENDER_INVERTED:
	case PIPE_CAP_SAMPLER_VIEW_TARGET:
a333 5
	case PIPE_CAP_MAX_VERTEX_STREAMS:
		return 1;

	case PIPE_CAP_MAX_VERTEX_ATTRIB_STRIDE:
		return 2047;
a375 11

	case PIPE_CAP_VENDOR_ID:
		return 0x1002;
	case PIPE_CAP_DEVICE_ID:
		return rscreen->b.info.pci_id;
	case PIPE_CAP_ACCELERATED:
		return 1;
	case PIPE_CAP_VIDEO_MEMORY:
		return rscreen->b.info.vram_size >> 20;
	case PIPE_CAP_UMA:
		return 0;
d411 1
a411 3
		return shader == PIPE_SHADER_VERTEX ? 16 : 32;
	case PIPE_SHADER_CAP_MAX_OUTPUTS:
		return shader == PIPE_SHADER_FRAGMENT ? 8 : 32;
d414 5
a418 11
	case PIPE_SHADER_CAP_MAX_CONST_BUFFER_SIZE:
		if (shader == PIPE_SHADER_COMPUTE) {
			uint64_t max_const_buffer_size;
			pscreen->get_compute_param(pscreen,
				PIPE_COMPUTE_CAP_MAX_MEM_ALLOC_SIZE,
				&max_const_buffer_size);
			return max_const_buffer_size;

		} else {
			return R600_MAX_CONST_BUFFER_SIZE;
		}
d426 1
a426 1
		return 1;
a440 1
#if HAVE_LLVM < 0x0306
a441 3
#else
			return PIPE_SHADER_IR_NATIVE;
#endif
a444 2
	case PIPE_SHADER_CAP_DOUBLES:
		return 0;
d507 2
a508 2
	if (!debug_get_bool_option("R600_HYPERZ", TRUE))
		rscreen->b.debug_flags |= DBG_NO_HYPERZ;
@


1.1.1.5
log
@Import Mesa 10.2.9
@
text
@a32 1
#include "util/u_blitter.h"
d194 3
d265 5
a269 1
        case PIPE_CAP_BUFFER_MAP_PERSISTENT_COHERENT:
d310 3
a312 1
	case PIPE_CAP_TGSI_VS_LAYER:
d314 2
d324 4
a327 4
	case PIPE_CAP_MAX_TEXTURE_GATHER_COMPONENTS:
	case PIPE_CAP_TEXTURE_GATHER_SM5:
	case PIPE_CAP_TEXTURE_QUERY_LOD:
        case PIPE_CAP_SAMPLE_SHADING:
d344 5
d391 11
d437 3
a439 1
		return 32;
d442 11
a452 5
	case PIPE_SHADER_CAP_MAX_ADDRS:
		/* XXX Isn't this equal to TEMPS? */
		return 1; /* Max native address registers */
	case PIPE_SHADER_CAP_MAX_CONSTS:
		return R600_MAX_CONST_BUFFER_SIZE;
d460 1
a460 1
		return 0;
d475 1
d477 3
d483 2
d547 2
a548 2
	if (debug_get_bool_option("R600_HYPERZ", FALSE))
		rscreen->b.debug_flags |= DBG_HYPERZ;
@


