head	1.2;
access;
symbols
	OPENBSD_5_8:1.1.1.5.0.4
	OPENBSD_5_8_BASE:1.1.1.5
	OPENBSD_5_7:1.1.1.5.0.2
	OPENBSD_5_7_BASE:1.1.1.5
	v10_2_9:1.1.1.5
	v10_4_3:1.1.1.4
	v10_2_7:1.1.1.3
	OPENBSD_5_6:1.1.1.3.0.2
	OPENBSD_5_6_BASE:1.1.1.3
	v10_2_3:1.1.1.3
	OPENBSD_5_5:1.1.1.2.0.2
	OPENBSD_5_5_BASE:1.1.1.2
	v9_2_5:1.1.1.2
	v9_2_3:1.1.1.1
	v9_2_2:1.1.1.1
	v9_2_1:1.1.1.1
	v9_2_0:1.1.1.1
	mesa:1.1.1;
locks; strict;
comment	@ * @;
expand	@o@;


1.2
date	2015.12.23.05.17.29;	author jsg;	state dead;
branches;
next	1.1;
commitid	TnlogFl9nOv2eaRf;

1.1
date	2013.09.05.13.11.05;	author jsg;	state Exp;
branches
	1.1.1.1;
next	;

1.1.1.1
date	2013.09.05.13.11.05;	author jsg;	state Exp;
branches;
next	1.1.1.2;

1.1.1.2
date	2014.01.19.03.03.39;	author jsg;	state Exp;
branches;
next	1.1.1.3;

1.1.1.3
date	2014.07.09.20.33.51;	author jsg;	state Exp;
branches;
next	1.1.1.4;
commitid	3JhLfwcuBALP0ZR7;

1.1.1.4
date	2015.01.25.14.07.00;	author jsg;	state Exp;
branches;
next	1.1.1.5;
commitid	ce2W5rH5aF7VS9gi;

1.1.1.5
date	2015.02.20.22.44.09;	author jsg;	state Exp;
branches;
next	;
commitid	F54a1i0WXHMxq7kE;


desc
@@


1.2
log
@remove the now unused Mesa 10.2.9 code
@
text
@/* -*- mode: C; c-file-style: "k&r"; tab-width 4; indent-tabs-mode: t; -*- */

/*
 * Copyright (C) 2013 Rob Clark <robclark@@freedesktop.org>
 *
 * Permission is hereby granted, free of charge, to any person obtaining a
 * copy of this software and associated documentation files (the "Software"),
 * to deal in the Software without restriction, including without limitation
 * the rights to use, copy, modify, merge, publish, distribute, sublicense,
 * and/or sell copies of the Software, and to permit persons to whom the
 * Software is furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice (including the next
 * paragraph) shall be included in all copies or substantial portions of the
 * Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
 * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 *
 * Authors:
 *    Rob Clark <robclark@@freedesktop.org>
 */

#include "pipe/p_state.h"
#include "util/u_string.h"
#include "util/u_memory.h"
#include "util/u_inlines.h"
#include "util/u_format.h"
#include "tgsi/tgsi_dump.h"
#include "tgsi/tgsi_parse.h"

#include "fd3_program.h"
#include "fd3_compiler.h"
#include "fd3_texture.h"
#include "fd3_util.h"

static void
delete_shader(struct fd3_shader_stateobj *so)
{
	ir3_shader_destroy(so->ir);
	fd_bo_del(so->bo);
	free(so);
}

static void
assemble_shader(struct pipe_context *pctx, struct fd3_shader_stateobj *so)
{
	struct fd_context *ctx = fd_context(pctx);
	uint32_t sz, *bin;

	bin = ir3_shader_assemble(so->ir, &so->info);
	sz = so->info.sizedwords * 4;

	so->bo = fd_bo_new(ctx->screen->dev, sz,
			DRM_FREEDRENO_GEM_CACHE_WCOMBINE |
			DRM_FREEDRENO_GEM_TYPE_KMEM);

	memcpy(fd_bo_map(so->bo), bin, sz);

	free(bin);

	so->instrlen = so->info.sizedwords / 8;
	so->constlen = so->info.max_const + 1;
}

/* for vertex shader, the inputs are loaded into registers before the shader
 * is executed, so max_regs from the shader instructions might not properly
 * reflect the # of registers actually used:
 */
static void
fixup_vp_regfootprint(struct fd3_shader_stateobj *so)
{
	unsigned i;
	for (i = 0; i < so->inputs_count; i++) {
		so->info.max_reg = MAX2(so->info.max_reg, so->inputs[i].regid >> 2);
	}
}

static struct fd3_shader_stateobj *
create_shader(struct pipe_context *pctx, const struct pipe_shader_state *cso,
		enum shader_t type)
{
	struct fd3_shader_stateobj *so = CALLOC_STRUCT(fd3_shader_stateobj);
	int ret;

	if (!so)
		return NULL;

	so->type = type;

	if (fd_mesa_debug & FD_DBG_DISASM) {
		DBG("dump tgsi: type=%d", so->type);
		tgsi_dump(cso->tokens, 0);
	}

	if (type == SHADER_FRAGMENT) {
		/* we seem to get wrong colors (maybe swap/endianess or hw issue?)
		 * with full precision color reg.  And blob driver only seems to
		 * use half precision register for color output (that I can find
		 * so far), even with highp precision.  So for force half precision
		 * for frag shader:
		 */
		so->half_precision = true;
	}

	ret = fd3_compile_shader(so, cso->tokens);
	if (ret) {
		debug_error("compile failed!");
		goto fail;
	}

	assemble_shader(pctx, so);
	if (!so->bo) {
		debug_error("assemble failed!");
		goto fail;
	}

	if (type == SHADER_VERTEX)
		fixup_vp_regfootprint(so);

	if (fd_mesa_debug & FD_DBG_DISASM) {
		DBG("disassemble: type=%d", so->type);
		disasm_a3xx(fd_bo_map(so->bo), so->info.sizedwords, 0, so->type);
	}

	return so;

fail:
	delete_shader(so);
	return NULL;
}

static void *
fd3_fp_state_create(struct pipe_context *pctx,
		const struct pipe_shader_state *cso)
{
	return create_shader(pctx, cso, SHADER_FRAGMENT);
}

static void
fd3_fp_state_delete(struct pipe_context *pctx, void *hwcso)
{
	struct fd3_shader_stateobj *so = hwcso;
	delete_shader(so);
}

static void
fd3_fp_state_bind(struct pipe_context *pctx, void *hwcso)
{
	struct fd_context *ctx = fd_context(pctx);
	ctx->prog.fp = hwcso;
	ctx->prog.dirty |= FD_SHADER_DIRTY_FP;
	ctx->dirty |= FD_DIRTY_PROG;
}

static void *
fd3_vp_state_create(struct pipe_context *pctx,
		const struct pipe_shader_state *cso)
{
	return create_shader(pctx, cso, SHADER_VERTEX);
}

static void
fd3_vp_state_delete(struct pipe_context *pctx, void *hwcso)
{
	struct fd3_shader_stateobj *so = hwcso;
	delete_shader(so);
}

static void
fd3_vp_state_bind(struct pipe_context *pctx, void *hwcso)
{
	struct fd_context *ctx = fd_context(pctx);
	ctx->prog.vp = hwcso;
	ctx->prog.dirty |= FD_SHADER_DIRTY_VP;
	ctx->dirty |= FD_DIRTY_PROG;
}

static void
emit_shader(struct fd_ringbuffer *ring, struct fd3_shader_stateobj *so)
{
	struct ir3_shader_info *si = &so->info;
	enum adreno_state_block sb;
	uint32_t i, *bin;

	if (so->type == SHADER_VERTEX) {
		sb = SB_VERT_SHADER;
	} else {
		sb = SB_FRAG_SHADER;
	}

	// XXX use SS_INDIRECT
	bin = fd_bo_map(so->bo);
	OUT_PKT3(ring, CP_LOAD_STATE, 2 + si->sizedwords);
	OUT_RING(ring, CP_LOAD_STATE_0_DST_OFF(0) |
			CP_LOAD_STATE_0_STATE_SRC(SS_DIRECT) |
			CP_LOAD_STATE_0_STATE_BLOCK(sb) |
			CP_LOAD_STATE_0_NUM_UNIT(so->instrlen));
	OUT_RING(ring, CP_LOAD_STATE_1_STATE_TYPE(ST_SHADER) |
			CP_LOAD_STATE_1_EXT_SRC_ADDR(0));
	for (i = 0; i < si->sizedwords; i++)
		OUT_RING(ring, bin[i]);
}

void
fd3_program_emit(struct fd_ringbuffer *ring,
		struct fd_program_stateobj *prog)
{
	struct fd3_shader_stateobj *vp = prog->vp;
	struct fd3_shader_stateobj *fp = prog->fp;
	struct ir3_shader_info *vsi = &vp->info;
	struct ir3_shader_info *fsi = &fp->info;
	int i;

	/* we could probably divide this up into things that need to be
	 * emitted if frag-prog is dirty vs if vert-prog is dirty..
	 */

	OUT_PKT0(ring, REG_A3XX_HLSQ_CONTROL_0_REG, 6);
	OUT_RING(ring, A3XX_HLSQ_CONTROL_0_REG_FSTHREADSIZE(FOUR_QUADS) |
			A3XX_HLSQ_CONTROL_0_REG_SPSHADERRESTART |
			A3XX_HLSQ_CONTROL_0_REG_SPCONSTFULLUPDATE);
	OUT_RING(ring, A3XX_HLSQ_CONTROL_1_REG_VSTHREADSIZE(TWO_QUADS) |
			A3XX_HLSQ_CONTROL_1_REG_VSSUPERTHREADENABLE);
	OUT_RING(ring, A3XX_HLSQ_CONTROL_2_REG_PRIMALLOCTHRESHOLD(31));
	OUT_RING(ring, 0x00000000);        /* HLSQ_CONTROL_3_REG */
	OUT_RING(ring, A3XX_HLSQ_VS_CONTROL_REG_CONSTLENGTH(vp->constlen) |
			A3XX_HLSQ_VS_CONTROL_REG_CONSTSTARTOFFSET(0) |
			A3XX_HLSQ_VS_CONTROL_REG_INSTRLENGTH(vp->instrlen));
	OUT_RING(ring, A3XX_HLSQ_FS_CONTROL_REG_CONSTLENGTH(fp->constlen) |
			A3XX_HLSQ_FS_CONTROL_REG_CONSTSTARTOFFSET(128) |
			A3XX_HLSQ_FS_CONTROL_REG_INSTRLENGTH(fp->instrlen));

	OUT_PKT0(ring, REG_A3XX_SP_SP_CTRL_REG, 1);
	OUT_RING(ring, A3XX_SP_SP_CTRL_REG_CONSTMODE(0) |
			A3XX_SP_SP_CTRL_REG_SLEEPMODE(1) |
			// XXX "resolve" (?) bit set on gmem->mem pass..
//			COND(!uniforms, A3XX_SP_SP_CTRL_REG_RESOLVE) |
			// XXX sometimes 0, sometimes 1:
			A3XX_SP_SP_CTRL_REG_LOMODE(1));

	/* emit unknown sequence of perfcounter disables that the blob
	 * emits as part of the program state..
	 */
	for (i = 0; i < 6; i++) {
		OUT_PKT0(ring, REG_A3XX_SP_PERFCOUNTER0_SELECT, 1);
		OUT_RING(ring, 0x00000000);    /* SP_PERFCOUNTER4_SELECT */

		OUT_PKT0(ring, REG_A3XX_SP_PERFCOUNTER4_SELECT, 1);
		OUT_RING(ring, 0x00000000);    /* SP_PERFCOUNTER4_SELECT */
	}

	OUT_PKT0(ring, REG_A3XX_SP_VS_LENGTH_REG, 1);
	OUT_RING(ring, A3XX_SP_VS_LENGTH_REG_SHADERLENGTH(vp->instrlen));

	OUT_PKT0(ring, REG_A3XX_SP_VS_CTRL_REG0, 3);
	OUT_RING(ring, A3XX_SP_VS_CTRL_REG0_THREADMODE(MULTI) |
			A3XX_SP_VS_CTRL_REG0_INSTRBUFFERMODE(BUFFER) |
			A3XX_SP_VS_CTRL_REG0_HALFREGFOOTPRINT(vsi->max_half_reg + 1) |
			A3XX_SP_VS_CTRL_REG0_FULLREGFOOTPRINT(vsi->max_reg + 1) |
			A3XX_SP_VS_CTRL_REG0_INOUTREGOVERLAP(0) |
			A3XX_SP_VS_CTRL_REG0_THREADSIZE(TWO_QUADS) |
			A3XX_SP_VS_CTRL_REG0_SUPERTHREADMODE |
			COND(vp->samplers_count > 0, A3XX_SP_VS_CTRL_REG0_PIXLODENABLE) |
			A3XX_SP_VS_CTRL_REG0_LENGTH(vp->instrlen));
	OUT_RING(ring, A3XX_SP_VS_CTRL_REG1_CONSTLENGTH(vp->constlen) |
			A3XX_SP_VS_CTRL_REG1_INITIALOUTSTANDING(vp->total_in) |
			A3XX_SP_VS_CTRL_REG1_CONSTFOOTPRINT(MAX2(vsi->max_const, 0)));
	OUT_RING(ring, A3XX_SP_VS_PARAM_REG_POSREGID(vp->pos_regid) |
			A3XX_SP_VS_PARAM_REG_PSIZEREGID(vp->psize_regid) |
			A3XX_SP_VS_PARAM_REG_TOTALVSOUTVAR(vp->outputs_count));

	assert(vp->outputs_count >= fp->inputs_count);

	for (i = 0; i < fp->inputs_count; ) {
		uint32_t reg = 0;

		OUT_PKT0(ring, REG_A3XX_SP_VS_OUT_REG(i/2), 1);

		reg |= A3XX_SP_VS_OUT_REG_A_REGID(vp->outputs[i].regid);
		reg |= A3XX_SP_VS_OUT_REG_A_COMPMASK(fp->inputs[i].compmask);
		i++;

		reg |= A3XX_SP_VS_OUT_REG_B_REGID(vp->outputs[i].regid);
		reg |= A3XX_SP_VS_OUT_REG_B_COMPMASK(fp->inputs[i].compmask);
		i++;

		OUT_RING(ring, reg);
	}

	for (i = 0; i < fp->inputs_count; ) {
		uint32_t reg = 0;

		OUT_PKT0(ring, REG_A3XX_SP_VS_VPC_DST_REG(i/4), 1);

		reg |= A3XX_SP_VS_VPC_DST_REG_OUTLOC0(fp->inputs[i++].inloc);
		reg |= A3XX_SP_VS_VPC_DST_REG_OUTLOC1(fp->inputs[i++].inloc);
		reg |= A3XX_SP_VS_VPC_DST_REG_OUTLOC2(fp->inputs[i++].inloc);
		reg |= A3XX_SP_VS_VPC_DST_REG_OUTLOC3(fp->inputs[i++].inloc);

		OUT_RING(ring, reg);
	}

#if 0
	/* for some reason, when I write SP_{VS,FS}_OBJ_START_REG I get:
[  666.663665] kgsl kgsl-3d0: |a3xx_err_callback| RBBM | AHB bus error | READ | addr=201 | ports=1:3
[  666.664001] kgsl kgsl-3d0: |a3xx_err_callback| ringbuffer AHB error interrupt
[  670.680909] kgsl kgsl-3d0: |adreno_idle| spun too long waiting for RB to idle
[  670.681062] kgsl kgsl-3d0: |kgsl-3d0| Dump Started
[  670.681123] kgsl kgsl-3d0: POWER: FLAGS = 00000007 | ACTIVE POWERLEVEL = 00000001
[  670.681214] kgsl kgsl-3d0: POWER: INTERVAL TIMEOUT = 0000000A
[  670.681367] kgsl kgsl-3d0: GRP_CLK = 325000000
[  670.681489] kgsl kgsl-3d0: BUS CLK = 0
	 */
	OUT_PKT0(ring, REG_A3XX_SP_VS_OBJ_OFFSET_REG, 2);
	OUT_RING(ring, A3XX_SP_VS_OBJ_OFFSET_REG_CONSTOBJECTOFFSET(0) |
			A3XX_SP_VS_OBJ_OFFSET_REG_SHADEROBJOFFSET(0));
	OUT_RELOC(ring, vp->bo, 0, 0);    /* SP_VS_OBJ_START_REG */
#endif

	OUT_PKT0(ring, REG_A3XX_SP_FS_LENGTH_REG, 1);
	OUT_RING(ring, A3XX_SP_FS_LENGTH_REG_SHADERLENGTH(fp->instrlen));

	OUT_PKT0(ring, REG_A3XX_SP_FS_CTRL_REG0, 2);
	OUT_RING(ring, A3XX_SP_FS_CTRL_REG0_THREADMODE(MULTI) |
			A3XX_SP_FS_CTRL_REG0_INSTRBUFFERMODE(BUFFER) |
			A3XX_SP_FS_CTRL_REG0_HALFREGFOOTPRINT(fsi->max_half_reg + 1) |
			A3XX_SP_FS_CTRL_REG0_FULLREGFOOTPRINT(fsi->max_reg + 1) |
			A3XX_SP_FS_CTRL_REG0_INOUTREGOVERLAP(1) |
			A3XX_SP_FS_CTRL_REG0_THREADSIZE(FOUR_QUADS) |
			A3XX_SP_FS_CTRL_REG0_SUPERTHREADMODE |
			COND(fp->samplers_count > 0, A3XX_SP_FS_CTRL_REG0_PIXLODENABLE) |
			A3XX_SP_FS_CTRL_REG0_LENGTH(fp->instrlen));
	OUT_RING(ring, A3XX_SP_FS_CTRL_REG1_CONSTLENGTH(fp->constlen) |
			A3XX_SP_FS_CTRL_REG1_INITIALOUTSTANDING(fp->total_in) |
			A3XX_SP_FS_CTRL_REG1_CONSTFOOTPRINT(MAX2(fsi->max_const, 0)) |
			A3XX_SP_FS_CTRL_REG1_HALFPRECVAROFFSET(63));

#if 0
	OUT_PKT0(ring, REG_A3XX_SP_FS_OBJ_OFFSET_REG, 2);
	OUT_RING(ring, A3XX_SP_FS_OBJ_OFFSET_REG_CONSTOBJECTOFFSET(128) |
			A3XX_SP_FS_OBJ_OFFSET_REG_SHADEROBJOFFSET(128 - fp->instrlen));
	OUT_RELOC(ring, fp->bo, 0, 0);    /* SP_FS_OBJ_START_REG */
#endif

	OUT_PKT0(ring, REG_A3XX_SP_FS_FLAT_SHAD_MODE_REG_0, 2);
	OUT_RING(ring, 0x00000000);        /* SP_FS_FLAT_SHAD_MODE_REG_0 */
	OUT_RING(ring, 0x00000000);        /* SP_FS_FLAT_SHAD_MODE_REG_1 */

	OUT_PKT0(ring, REG_A3XX_SP_FS_OUTPUT_REG, 1);
	OUT_RING(ring, 0x00000000);        /* SP_FS_OUTPUT_REG */

	OUT_PKT0(ring, REG_A3XX_SP_FS_MRT_REG(0), 4);
	OUT_RING(ring, A3XX_SP_FS_MRT_REG_REGID(fp->color_regid) |
			COND(fp->half_precision, A3XX_SP_FS_MRT_REG_HALF_PRECISION));
	OUT_RING(ring, A3XX_SP_FS_MRT_REG_REGID(0));
	OUT_RING(ring, A3XX_SP_FS_MRT_REG_REGID(0));
	OUT_RING(ring, A3XX_SP_FS_MRT_REG_REGID(0));

	OUT_PKT0(ring, REG_A3XX_VPC_ATTR, 2);
	OUT_RING(ring, A3XX_VPC_ATTR_TOTALATTR(fp->total_in) |
			A3XX_VPC_ATTR_THRDASSIGN(1) |
			A3XX_VPC_ATTR_LMSIZE(1));
	OUT_RING(ring, A3XX_VPC_PACK_NUMFPNONPOSVAR(fp->total_in) |
			A3XX_VPC_PACK_NUMNONPOSVSVAR(fp->total_in));

	OUT_PKT0(ring, REG_A3XX_VPC_VARYING_INTERP_MODE(0), 4);
	OUT_RING(ring, fp->vinterp[0]);    /* VPC_VARYING_INTERP[0].MODE */
	OUT_RING(ring, fp->vinterp[1]);    /* VPC_VARYING_INTERP[1].MODE */
	OUT_RING(ring, fp->vinterp[2]);    /* VPC_VARYING_INTERP[2].MODE */
	OUT_RING(ring, fp->vinterp[3]);    /* VPC_VARYING_INTERP[3].MODE */

	OUT_PKT0(ring, REG_A3XX_VPC_VARYING_PS_REPL_MODE(0), 4);
	OUT_RING(ring, fp->vpsrepl[0]);    /* VPC_VARYING_PS_REPL[0].MODE */
	OUT_RING(ring, fp->vpsrepl[1]);    /* VPC_VARYING_PS_REPL[1].MODE */
	OUT_RING(ring, fp->vpsrepl[2]);    /* VPC_VARYING_PS_REPL[2].MODE */
	OUT_RING(ring, fp->vpsrepl[3]);    /* VPC_VARYING_PS_REPL[3].MODE */

	OUT_PKT0(ring, REG_A3XX_VFD_VS_THREADING_THRESHOLD, 1);
	OUT_RING(ring, A3XX_VFD_VS_THREADING_THRESHOLD_REGID_THRESHOLD(15) |
			A3XX_VFD_VS_THREADING_THRESHOLD_REGID_VTXCNT(252));

	emit_shader(ring, vp);

	OUT_PKT0(ring, REG_A3XX_VFD_PERFCOUNTER0_SELECT, 1);
	OUT_RING(ring, 0x00000000);        /* VFD_PERFCOUNTER0_SELECT */

	emit_shader(ring, fp);

	OUT_PKT0(ring, REG_A3XX_VFD_PERFCOUNTER0_SELECT, 1);
	OUT_RING(ring, 0x00000000);        /* VFD_PERFCOUNTER0_SELECT */

	OUT_PKT0(ring, REG_A3XX_VFD_CONTROL_0, 2);
	OUT_RING(ring, A3XX_VFD_CONTROL_0_TOTALATTRTOVS(vp->total_in) |
			A3XX_VFD_CONTROL_0_PACKETSIZE(2) |
			A3XX_VFD_CONTROL_0_STRMDECINSTRCNT(vp->inputs_count) |
			A3XX_VFD_CONTROL_0_STRMFETCHINSTRCNT(vp->inputs_count));
	OUT_RING(ring, A3XX_VFD_CONTROL_1_MAXSTORAGE(1) | // XXX
			A3XX_VFD_CONTROL_1_REGID4VTX(regid(63,0)) |
			A3XX_VFD_CONTROL_1_REGID4INST(regid(63,0)));
}

/* once the compiler is good enough, we should construct TGSI in the
 * core freedreno driver, and then let the a2xx/a3xx parts compile
 * the internal shaders from TGSI the same as regular shaders.  This
 * would be the first step towards handling most of clear (and the
 * gmem<->mem blits) from the core via normal state changes and shader
 * state objects.
 *
 * (Well, there would still be some special bits, because there are
 * some registers that don't get set for normal draw, but this should
 * be relatively small and could be handled via callbacks from core
 * into a2xx/a3xx..)
 */
static struct fd3_shader_stateobj *
create_internal_shader(struct pipe_context *pctx, enum shader_t type,
		struct ir3_shader *ir)
{
	struct fd3_shader_stateobj *so = CALLOC_STRUCT(fd3_shader_stateobj);

	if (!so) {
		ir3_shader_destroy(ir);
		return NULL;
	}

	so->type = type;
	so->ir = ir;

	assemble_shader(pctx, so);
	assert(so->bo);

	return so;
}

/* Creates shader:
 *    (sy)(ss)(rpt1)bary.f (ei)r0.z, (r)0, r0.x
 *    (rpt5)nop
 *    sam (f32)(xyzw)r0.x, r0.z, s#0, t#0
 *    (sy)(rpt3)cov.f32f16 hr0.x, (r)r0.x
 *    end
 */
static struct fd3_shader_stateobj *
create_blit_fp(struct pipe_context *pctx)
{
	struct fd3_shader_stateobj *so;
	struct ir3_shader *ir = ir3_shader_create();
	struct ir3_instruction *instr;

	/* (sy)(ss)(rpt1)bary.f (ei)r0.z, (r)0, r0.x */
	instr = ir3_instr_create(ir, 2, OPC_BARY_F);
	instr->flags = IR3_INSTR_SY | IR3_INSTR_SS;
	instr->repeat = 1;

	ir3_reg_create(instr, regid(0,2), IR3_REG_EI);    /* (ei)r0.z */
	ir3_reg_create(instr, 0, IR3_REG_R |              /* (r)0 */
			IR3_REG_IMMED)->iim_val = 0;
	ir3_reg_create(instr, regid(0,0), 0);             /* r0.x */

	/* (rpt5)nop */
	instr = ir3_instr_create(ir, 0, OPC_NOP);
	instr->repeat = 5;

	/* sam (f32)(xyzw)r0.x, r0.z, s#0, t#0 */
	instr = ir3_instr_create(ir, 5, OPC_SAM);
	instr->cat5.samp = 0;
	instr->cat5.tex  = 0;
	instr->cat5.type = TYPE_F32;

	ir3_reg_create(instr, regid(0,0),                 /* (xyzw)r0.x */
			0)->wrmask = 0xf;
	ir3_reg_create(instr, regid(0,2), 0);             /* r0.z */

	/* (sy)(rpt3)cov.f32f16 hr0.x, (r)r0.x */
	instr = ir3_instr_create(ir, 1, 0);  /* mov/cov instructions have no opc */
	instr->flags = IR3_INSTR_SY;
	instr->repeat = 3;
	instr->cat1.src_type = TYPE_F32;
	instr->cat1.dst_type = TYPE_F16;

	ir3_reg_create(instr, regid(0,0), IR3_REG_HALF);  /* hr0.x */
	ir3_reg_create(instr, regid(0,0), IR3_REG_R);     /* (r)r0.x */

	/* end */
	instr = ir3_instr_create(ir, 0, OPC_END);

	so = create_internal_shader(pctx, SHADER_FRAGMENT, ir);
	if (!so)
		return NULL;

	so->color_regid = regid(0,0);
	so->half_precision = true;
	so->inputs_count = 1;
	so->inputs[0].inloc = 8;
	so->inputs[0].compmask = 0x3;
	so->total_in = 2;
	so->samplers_count = 1;

	so->vpsrepl[0] = 0x99999999;
	so->vpsrepl[1] = 0x99999999;
	so->vpsrepl[2] = 0x99999999;
	so->vpsrepl[3] = 0x99999999;

	return so;
}

/* Creates shader:
 *    (sy)(ss)end
 */
static struct fd3_shader_stateobj *
create_blit_vp(struct pipe_context *pctx)
{
	struct fd3_shader_stateobj *so;
	struct ir3_shader *ir = ir3_shader_create();
	struct ir3_instruction *instr;

	/* (sy)(ss)end */
	instr = ir3_instr_create(ir, 0, OPC_END);
	instr->flags = IR3_INSTR_SY | IR3_INSTR_SS;

	so = create_internal_shader(pctx, SHADER_VERTEX, ir);
	if (!so)
		return NULL;

	so->pos_regid = regid(1,0);
	so->psize_regid = regid(63,0);
	so->inputs_count = 2;
	so->inputs[0].regid = regid(0,0);
	so->inputs[0].compmask = 0xf;
	so->inputs[1].regid = regid(1,0);
	so->inputs[1].compmask = 0xf;
	so->total_in = 8;
	so->outputs_count = 1;
	so->outputs[0].regid = regid(0,0);

	fixup_vp_regfootprint(so);

	return so;
}

/* Creates shader:
 *    (sy)(ss)(rpt3)mov.f16f16 hr0.x, (r)hc0.x
 *    end
 */
static struct fd3_shader_stateobj *
create_solid_fp(struct pipe_context *pctx)
{
	struct fd3_shader_stateobj *so;
	struct ir3_shader *ir = ir3_shader_create();
	struct ir3_instruction *instr;

	/* (sy)(ss)(rpt3)mov.f16f16 hr0.x, (r)hc0.x */
	instr = ir3_instr_create(ir, 1, 0);  /* mov/cov instructions have no opc */
	instr->flags = IR3_INSTR_SY | IR3_INSTR_SS;
	instr->repeat = 3;
	instr->cat1.src_type = TYPE_F16;
	instr->cat1.dst_type = TYPE_F16;

	ir3_reg_create(instr, regid(0,0), IR3_REG_HALF);  /* hr0.x */
	ir3_reg_create(instr, regid(0,0), IR3_REG_HALF |  /* (r)hc0.x */
			IR3_REG_CONST | IR3_REG_R);

	/* end */
	instr = ir3_instr_create(ir, 0, OPC_END);

	so = create_internal_shader(pctx, SHADER_FRAGMENT, ir);
	if (!so)
		return NULL;

	so->color_regid = regid(0,0);
	so->half_precision = true;
	so->inputs_count = 0;
	so->total_in = 0;

	return so;
}

/* Creates shader:
 *    (sy)(ss)end
 */
static struct fd3_shader_stateobj *
create_solid_vp(struct pipe_context *pctx)
{
	struct fd3_shader_stateobj *so;
	struct ir3_shader *ir = ir3_shader_create();
	struct ir3_instruction *instr;

	/* (sy)(ss)end */
	instr = ir3_instr_create(ir, 0, OPC_END);
	instr->flags = IR3_INSTR_SY | IR3_INSTR_SS;


	so = create_internal_shader(pctx, SHADER_VERTEX, ir);
	if (!so)
		return NULL;

	so->pos_regid = regid(0,0);
	so->psize_regid = regid(63,0);
	so->inputs_count = 1;
	so->inputs[0].regid = regid(0,0);
	so->inputs[0].compmask = 0xf;
	so->total_in = 4;
	so->outputs_count = 0;

	fixup_vp_regfootprint(so);

	return so;
}

void
fd3_prog_init(struct pipe_context *pctx)
{
	struct fd_context *ctx = fd_context(pctx);

	pctx->create_fs_state = fd3_fp_state_create;
	pctx->bind_fs_state = fd3_fp_state_bind;
	pctx->delete_fs_state = fd3_fp_state_delete;

	pctx->create_vs_state = fd3_vp_state_create;
	pctx->bind_vs_state = fd3_vp_state_bind;
	pctx->delete_vs_state = fd3_vp_state_delete;

	ctx->solid_prog.fp = create_solid_fp(pctx);
	ctx->solid_prog.vp = create_solid_vp(pctx);
	ctx->blit_prog.fp = create_blit_fp(pctx);
	ctx->blit_prog.vp = create_blit_vp(pctx);
}

void
fd3_prog_fini(struct pipe_context *pctx)
{
	struct fd_context *ctx = fd_context(pctx);

	delete_shader(ctx->solid_prog.vp);
	delete_shader(ctx->solid_prog.fp);
	delete_shader(ctx->blit_prog.vp);
	delete_shader(ctx->blit_prog.fp);
}
@


1.1
log
@Initial revision
@
text
@@


1.1.1.1
log
@Import Mesa 9.2.0
@
text
@@


1.1.1.2
log
@Import Mesa 9.2.5
@
text
@d252 1
a252 1
		OUT_RING(ring, 0x00000000);    /* SP_PERFCOUNTER0_SELECT */
d323 1
a323 1
	OUT_RELOC(ring, vp->bo, 0, 0, 0);  /* SP_VS_OBJ_START_REG */
d348 1
a348 1
	OUT_RELOC(ring, fp->bo, 0, 0, 0);  /* SP_FS_OBJ_START_REG */
@


1.1.1.3
log
@Import Mesa 10.2.3
@
text
@a36 3
#include "freedreno_lowering.h"
#include "freedreno_program.h"

a38 1
#include "fd3_emit.h"
d43 1
a43 1
delete_variant(struct fd3_shader_variant *v)
d45 3
a47 3
	ir3_shader_destroy(v->ir);
	fd_bo_del(v->bo);
	free(v);
d51 1
a51 1
assemble_variant(struct fd3_shader_variant *so)
d53 1
a53 1
	struct fd_context *ctx = fd_context(so->so->pctx);
d59 1
a59 1
	so->bo = fd_bo_new(ctx->dev, sz,
d76 1
a76 1
fixup_vp_regfootprint(struct fd3_shader_variant *so)
d80 1
a80 8
		if (so->inputs[i].compmask) {
			uint32_t regid = (so->inputs[i].regid + 3) >> 2;
			so->info.max_reg = MAX2(so->info.max_reg, regid);
		}
	}
	for (i = 0; i < so->outputs_count; i++) {
		uint32_t regid = (so->outputs[i].regid + 3) >> 2;
		so->info.max_reg = MAX2(so->info.max_reg, regid);
d84 3
a86 2
static struct fd3_shader_variant *
create_variant(struct fd3_shader_stateobj *so, struct fd3_shader_key key)
d88 1
a88 2
	struct fd3_shader_variant *v = CALLOC_STRUCT(fd3_shader_variant);
	const struct tgsi_token *tokens = so->tokens;
d91 1
a91 1
	if (!v)
d94 1
a94 3
	v->so = so;
	v->key = key;
	v->type = so->type;
d97 2
a98 18
		DBG("dump tgsi: type=%d, k={bp=%u,cts=%u,hp=%u}", so->type,
			key.binning_pass, key.color_two_side, key.half_precision);
		tgsi_dump(tokens, 0);
	}

	if (!(fd_mesa_debug & FD_DBG_NOOPT)) {
		ret = fd3_compile_shader(v, tokens, key);
		if (ret) {
			debug_error("new compiler failed, trying fallback!");

			v->inputs_count = 0;
			v->outputs_count = 0;
			v->total_in = 0;
			v->has_samp = false;
			v->immediates_count = 0;
		}
	} else {
		ret = -1;  /* force fallback to old compiler */
d101 9
a109 2
	if (ret)
		ret = fd3_compile_shader_old(v, tokens, key);
d111 1
d117 2
a118 2
	assemble_variant(v);
	if (!v->bo) {
d123 2
a124 2
	if (so->type == SHADER_VERTEX)
		fixup_vp_regfootprint(v);
d127 2
a128 3
		DBG("disassemble: type=%d, k={bp=%u,cts=%u,hp=%u}", v->type,
			key.binning_pass, key.color_two_side, key.half_precision);
		disasm_a3xx(fd_bo_map(v->bo), v->info.sizedwords, 0, v->type);
d131 1
a131 1
	return v;
d134 1
a134 1
	delete_variant(v);
a137 54
struct fd3_shader_variant *
fd3_shader_variant(struct fd3_shader_stateobj *so, struct fd3_shader_key key)
{
	struct fd3_shader_variant *v;

	/* some shader key values only apply to vertex or frag shader,
	 * so normalize the key to avoid constructing multiple identical
	 * variants:
	 */
	if (so->type == SHADER_FRAGMENT) {
		key.binning_pass = false;
	}
	if (so->type == SHADER_VERTEX) {
		key.color_two_side = false;
		key.half_precision = false;
	}

	for (v = so->variants; v; v = v->next)
		if (!memcmp(&key, &v->key, sizeof(key)))
			return v;

	/* compile new variant if it doesn't exist already: */
	v = create_variant(so, key);
	v->next = so->variants;
	so->variants = v;

	return v;
}


static void
delete_shader(struct fd3_shader_stateobj *so)
{
	struct fd3_shader_variant *v, *t;
	for (v = so->variants; v; ) {
		t = v;
		v = v->next;
		delete_variant(t);
	}
	free((void *)so->tokens);
	free(so);
}

static struct fd3_shader_stateobj *
create_shader(struct pipe_context *pctx, const struct pipe_shader_state *cso,
		enum shader_t type)
{
	struct fd3_shader_stateobj *so = CALLOC_STRUCT(fd3_shader_stateobj);
	so->pctx = pctx;
	so->type = type;
	so->tokens = tgsi_dup_tokens(cso->tokens);
	return so;
}

d152 9
d176 10
a185 1
emit_shader(struct fd_ringbuffer *ring, const struct fd3_shader_variant *so)
d187 1
a187 1
	const struct ir3_shader_info *si = &so->info;
d189 1
a189 2
	enum adreno_state_src src;
	uint32_t i, sz, *bin;
d197 3
a199 11
	if (fd_mesa_debug & FD_DBG_DIRECT) {
		sz = si->sizedwords;
		src = SS_DIRECT;
		bin = fd_bo_map(so->bo);
	} else {
		sz = 0;
		src = SS_INDIRECT;
		bin = NULL;
	}

	OUT_PKT3(ring, CP_LOAD_STATE, 2 + sz);
d201 1
a201 1
			CP_LOAD_STATE_0_STATE_SRC(src) |
d204 3
a206 8
	if (bin) {
		OUT_RING(ring, CP_LOAD_STATE_1_EXT_SRC_ADDR(0) |
				CP_LOAD_STATE_1_STATE_TYPE(ST_SHADER));
	} else {
		OUT_RELOC(ring, so->bo, 0,
				CP_LOAD_STATE_1_STATE_TYPE(ST_SHADER), 0);
	}
	for (i = 0; i < sz; i++) {
a207 45
	}
}

static int
find_output(const struct fd3_shader_variant *so, fd3_semantic semantic)
{
	int j;

	for (j = 0; j < so->outputs_count; j++)
		if (so->outputs[j].semantic == semantic)
			return j;

	/* it seems optional to have a OUT.BCOLOR[n] for each OUT.COLOR[n]
	 * in the vertex shader.. but the fragment shader doesn't know this
	 * so  it will always have both IN.COLOR[n] and IN.BCOLOR[n].  So
	 * at link time if there is no matching OUT.BCOLOR[n], we must map
	 * OUT.COLOR[n] to IN.BCOLOR[n].
	 */
	if (sem2name(semantic) == TGSI_SEMANTIC_BCOLOR) {
		unsigned idx = sem2idx(semantic);
		return find_output(so, fd3_semantic_name(TGSI_SEMANTIC_COLOR, idx));
	}

	debug_assert(0);

	return 0;
}

static int
next_varying(const struct fd3_shader_variant *so, int i)
{
	while (++i < so->inputs_count)
		if (so->inputs[i].compmask && so->inputs[i].bary)
			break;
	return i;
}

static uint32_t
find_output_regid(const struct fd3_shader_variant *so, fd3_semantic semantic)
{
	int j;
	for (j = 0; j < so->outputs_count; j++)
		if (so->outputs[j].semantic == semantic)
			return so->outputs[j].regid;
	return regid(63, 0);
d212 1
a212 1
		struct fd_program_stateobj *prog, struct fd3_shader_key key)
d214 5
a218 26
	const struct fd3_shader_variant *vp, *fp;
	const struct ir3_shader_info *vsi, *fsi;
	uint32_t pos_regid, posz_regid, psize_regid, color_regid;
	int i, j, k;

	vp = fd3_shader_variant(prog->vp, key);

	if (key.binning_pass) {
		/* use dummy stateobj to simplify binning vs non-binning: */
		static const struct fd3_shader_variant binning_fp = {};
		fp = &binning_fp;
	} else {
		fp = fd3_shader_variant(prog->fp, key);
	}

	vsi = &vp->info;
	fsi = &fp->info;

	pos_regid = find_output_regid(vp,
		fd3_semantic_name(TGSI_SEMANTIC_POSITION, 0));
	posz_regid = find_output_regid(fp,
		fd3_semantic_name(TGSI_SEMANTIC_POSITION, 0));
	psize_regid = find_output_regid(vp,
		fd3_semantic_name(TGSI_SEMANTIC_PSIZE, 0));
	color_regid = find_output_regid(fp,
		fd3_semantic_name(TGSI_SEMANTIC_COLOR, 0));
a225 4
			/* NOTE:  I guess SHADERRESTART and CONSTFULLUPDATE maybe
			 * flush some caches? I think we only need to set those
			 * bits if we have updated const or shader..
			 */
d229 1
a229 2
			A3XX_HLSQ_CONTROL_1_REG_VSSUPERTHREADENABLE |
			COND(fp->frag_coord, A3XX_HLSQ_CONTROL_1_REG_ZWCOORD));
d231 1
a231 1
	OUT_RING(ring, A3XX_HLSQ_CONTROL_3_REG_REGID(fp->pos_regid));
a240 1
			COND(key.binning_pass, A3XX_SP_SP_CTRL_REG_BINNING) |
d242 15
a256 1
			A3XX_SP_SP_CTRL_REG_L0MODE(0));
a263 1
			A3XX_SP_VS_CTRL_REG0_CACHEINVALID |
d269 1
a269 1
			COND(vp->has_samp, A3XX_SP_VS_CTRL_REG0_PIXLODENABLE) |
d274 5
a278 3
	OUT_RING(ring, A3XX_SP_VS_PARAM_REG_POSREGID(pos_regid) |
			A3XX_SP_VS_PARAM_REG_PSIZEREGID(psize_regid) |
			A3XX_SP_VS_PARAM_REG_TOTALVSOUTVAR(align(fp->total_in, 4) / 4));
d280 1
a280 1
	for (i = 0, j = -1; (i < 8) && (j < (int)fp->inputs_count); i++) {
d283 1
a283 1
		OUT_PKT0(ring, REG_A3XX_SP_VS_OUT_REG(i), 1);
d285 7
a291 13
		j = next_varying(fp, j);
		if (j < fp->inputs_count) {
			k = find_output(vp, fp->inputs[j].semantic);
			reg |= A3XX_SP_VS_OUT_REG_A_REGID(vp->outputs[k].regid);
			reg |= A3XX_SP_VS_OUT_REG_A_COMPMASK(fp->inputs[j].compmask);
		}

		j = next_varying(fp, j);
		if (j < fp->inputs_count) {
			k = find_output(vp, fp->inputs[j].semantic);
			reg |= A3XX_SP_VS_OUT_REG_B_REGID(vp->outputs[k].regid);
			reg |= A3XX_SP_VS_OUT_REG_B_COMPMASK(fp->inputs[j].compmask);
		}
d296 1
a296 1
	for (i = 0, j = -1; (i < 4) && (j < (int)fp->inputs_count); i++) {
d299 1
a299 1
		OUT_PKT0(ring, REG_A3XX_SP_VS_VPC_DST_REG(i), 1);
d301 4
a304 12
		j = next_varying(fp, j);
		if (j < fp->inputs_count)
			reg |= A3XX_SP_VS_VPC_DST_REG_OUTLOC0(fp->inputs[j].inloc);
		j = next_varying(fp, j);
		if (j < fp->inputs_count)
			reg |= A3XX_SP_VS_VPC_DST_REG_OUTLOC1(fp->inputs[j].inloc);
		j = next_varying(fp, j);
		if (j < fp->inputs_count)
			reg |= A3XX_SP_VS_VPC_DST_REG_OUTLOC2(fp->inputs[j].inloc);
		j = next_varying(fp, j);
		if (j < fp->inputs_count)
			reg |= A3XX_SP_VS_VPC_DST_REG_OUTLOC3(fp->inputs[j].inloc);
d309 11
d324 1
d326 2
a327 11
	if (key.binning_pass) {
		OUT_PKT0(ring, REG_A3XX_SP_FS_LENGTH_REG, 1);
		OUT_RING(ring, 0x00000000);

		OUT_PKT0(ring, REG_A3XX_SP_FS_CTRL_REG0, 2);
		OUT_RING(ring, A3XX_SP_FS_CTRL_REG0_THREADMODE(MULTI) |
				A3XX_SP_FS_CTRL_REG0_INSTRBUFFERMODE(BUFFER));
		OUT_RING(ring, 0x00000000);
	} else {
		OUT_PKT0(ring, REG_A3XX_SP_FS_LENGTH_REG, 1);
		OUT_RING(ring, A3XX_SP_FS_LENGTH_REG_SHADERLENGTH(fp->instrlen));
d329 21
a349 20
		OUT_PKT0(ring, REG_A3XX_SP_FS_CTRL_REG0, 2);
		OUT_RING(ring, A3XX_SP_FS_CTRL_REG0_THREADMODE(MULTI) |
				A3XX_SP_FS_CTRL_REG0_INSTRBUFFERMODE(BUFFER) |
				A3XX_SP_FS_CTRL_REG0_CACHEINVALID |
				A3XX_SP_FS_CTRL_REG0_HALFREGFOOTPRINT(fsi->max_half_reg + 1) |
				A3XX_SP_FS_CTRL_REG0_FULLREGFOOTPRINT(fsi->max_reg + 1) |
				A3XX_SP_FS_CTRL_REG0_INOUTREGOVERLAP(1) |
				A3XX_SP_FS_CTRL_REG0_THREADSIZE(FOUR_QUADS) |
				A3XX_SP_FS_CTRL_REG0_SUPERTHREADMODE |
				COND(fp->has_samp > 0, A3XX_SP_FS_CTRL_REG0_PIXLODENABLE) |
				A3XX_SP_FS_CTRL_REG0_LENGTH(fp->instrlen));
		OUT_RING(ring, A3XX_SP_FS_CTRL_REG1_CONSTLENGTH(fp->constlen) |
				A3XX_SP_FS_CTRL_REG1_INITIALOUTSTANDING(fp->total_in) |
				A3XX_SP_FS_CTRL_REG1_CONSTFOOTPRINT(MAX2(fsi->max_const, 0)) |
				A3XX_SP_FS_CTRL_REG1_HALFPRECVAROFFSET(63));
		OUT_PKT0(ring, REG_A3XX_SP_FS_OBJ_OFFSET_REG, 2);
		OUT_RING(ring, A3XX_SP_FS_OBJ_OFFSET_REG_CONSTOBJECTOFFSET(128) |
				A3XX_SP_FS_OBJ_OFFSET_REG_SHADEROBJOFFSET(0));
		OUT_RELOC(ring, fp->bo, 0, 0, 0);  /* SP_FS_OBJ_START_REG */
	}
d356 1
a356 6
	if (fp->writes_pos) {
		OUT_RING(ring, A3XX_SP_FS_OUTPUT_REG_DEPTH_ENABLE |
				A3XX_SP_FS_OUTPUT_REG_DEPTH_REGID(posz_regid));
	} else {
		OUT_RING(ring, 0x00000000);
	}
d359 2
a360 2
	OUT_RING(ring, A3XX_SP_FS_MRT_REG_REGID(color_regid) |
			COND(fp->key.half_precision, A3XX_SP_FS_MRT_REG_HALF_PRECISION));
d365 18
a382 27
	if (key.binning_pass) {
		OUT_PKT0(ring, REG_A3XX_VPC_ATTR, 2);
		OUT_RING(ring, A3XX_VPC_ATTR_THRDASSIGN(1) |
				A3XX_VPC_ATTR_LMSIZE(1) |
				COND(vp->writes_psize, A3XX_VPC_ATTR_PSIZE));
		OUT_RING(ring, 0x00000000);
	} else {
		OUT_PKT0(ring, REG_A3XX_VPC_ATTR, 2);
		OUT_RING(ring, A3XX_VPC_ATTR_TOTALATTR(fp->total_in) |
				A3XX_VPC_ATTR_THRDASSIGN(1) |
				A3XX_VPC_ATTR_LMSIZE(1) |
				COND(vp->writes_psize, A3XX_VPC_ATTR_PSIZE));
		OUT_RING(ring, A3XX_VPC_PACK_NUMFPNONPOSVAR(fp->total_in) |
				A3XX_VPC_PACK_NUMNONPOSVSVAR(fp->total_in));

		OUT_PKT0(ring, REG_A3XX_VPC_VARYING_INTERP_MODE(0), 4);
		OUT_RING(ring, fp->so->vinterp[0]);    /* VPC_VARYING_INTERP[0].MODE */
		OUT_RING(ring, fp->so->vinterp[1]);    /* VPC_VARYING_INTERP[1].MODE */
		OUT_RING(ring, fp->so->vinterp[2]);    /* VPC_VARYING_INTERP[2].MODE */
		OUT_RING(ring, fp->so->vinterp[3]);    /* VPC_VARYING_INTERP[3].MODE */

		OUT_PKT0(ring, REG_A3XX_VPC_VARYING_PS_REPL_MODE(0), 4);
		OUT_RING(ring, fp->so->vpsrepl[0]);    /* VPC_VARYING_PS_REPL[0].MODE */
		OUT_RING(ring, fp->so->vpsrepl[1]);    /* VPC_VARYING_PS_REPL[1].MODE */
		OUT_RING(ring, fp->so->vpsrepl[2]);    /* VPC_VARYING_PS_REPL[2].MODE */
		OUT_RING(ring, fp->so->vpsrepl[3]);    /* VPC_VARYING_PS_REPL[3].MODE */
	}
d393 1
a393 2
	if (!key.binning_pass) {
		emit_shader(ring, fp);
d395 34
a428 2
		OUT_PKT0(ring, REG_A3XX_VFD_PERFCOUNTER0_SELECT, 1);
		OUT_RING(ring, 0x00000000);        /* VFD_PERFCOUNTER0_SELECT */
d430 8
d440 9
a448 3
/* hack.. until we figure out how to deal w/ vpsrepl properly.. */
static void
fix_blit_fp(struct pipe_context *pctx)
d450 52
a501 2
	struct fd_context *ctx = fd_context(pctx);
	struct fd3_shader_stateobj *so = ctx->blit_prog.fp;
d507 105
d617 2
d620 1
d624 1
d627 10
a636 1
	fd_prog_init(pctx);
d638 4
a641 1
	fix_blit_fp(pctx);
@


1.1.1.4
log
@Import Mesa 10.4.3
@
text
@d37 1
d41 1
d47 1
a47 1
delete_shader_stateobj(struct fd3_shader_stateobj *so)
d49 151
a199 1
	ir3_shader_destroy(so->shader);
d204 1
a204 1
create_shader_stateobj(struct pipe_context *pctx, const struct pipe_shader_state *cso,
d208 3
a210 1
	so->shader = ir3_shader_create(pctx, cso->tokens, type);
d218 1
a218 1
	return create_shader_stateobj(pctx, cso, SHADER_FRAGMENT);
d225 1
a225 1
	delete_shader_stateobj(so);
d232 1
a232 1
	return create_shader_stateobj(pctx, cso, SHADER_VERTEX);
d239 1
a239 1
	delete_shader_stateobj(so);
d243 1
a243 1
emit_shader(struct fd_ringbuffer *ring, const struct ir3_shader_variant *so)
d245 1
a245 1
	const struct ir3_info *si = &so->info;
d283 44
d328 2
a329 1
fd3_program_emit(struct fd_ringbuffer *ring, struct fd3_emit *emit)
d331 2
a332 4
	const struct ir3_shader_variant *vp, *fp;
	const struct ir3_info *vsi, *fsi;
	enum a3xx_instrbuffermode fpbuffer, vpbuffer;
	uint32_t fpbuffersz, vpbuffersz, fsoff;
a333 1
	int constmode;
d336 1
a336 1
	vp = fd3_emit_get_vp(emit);
d338 1
a338 1
	if (emit->key.binning_pass) {
d340 1
a340 1
		static const struct ir3_shader_variant binning_fp = {};
d343 1
a343 1
		fp = fd3_emit_get_fp(emit);
d349 8
a356 51
	fpbuffer = BUFFER;
	vpbuffer = BUFFER;
	fpbuffersz = fp->instrlen;
	vpbuffersz = vp->instrlen;

	/*
	 * Decide whether to use BUFFER or CACHE mode for VS and FS.  It
	 * appears like 256 is the hard limit, but when the combined size
	 * exceeds 128 then blob will try to keep FS in BUFFER mode and
	 * switch to CACHE for VS until VS is too large.  The blob seems
	 * to switch FS out of BUFFER mode at slightly under 128.  But
	 * a bit fuzzy on the decision tree, so use slightly conservative
	 * limits.
	 *
	 * TODO check if these thresholds for BUFFER vs CACHE mode are the
	 *      same for all a3xx or whether we need to consider the gpuid
	 */

	if ((fpbuffersz + vpbuffersz) > 128) {
		if (fpbuffersz < 112) {
			/* FP:BUFFER   VP:CACHE  */
			vpbuffer = CACHE;
			vpbuffersz = 256 - fpbuffersz;
		} else if (vpbuffersz < 112) {
			/* FP:CACHE    VP:BUFFER */
			fpbuffer = CACHE;
			fpbuffersz = 256 - vpbuffersz;
		} else {
			/* FP:CACHE    VP:CACHE  */
			vpbuffer = fpbuffer = CACHE;
			vpbuffersz = fpbuffersz = 192;
		}
	}

	if (fpbuffer == BUFFER) {
		fsoff = 128 - fpbuffersz;
	} else {
		fsoff = 256 - fpbuffersz;
	}

	/* seems like vs->constlen + fs->constlen > 256, then CONSTMODE=1 */
	constmode = ((vp->constlen + fp->constlen) > 256) ? 1 : 0;

	pos_regid = ir3_find_output_regid(vp,
		ir3_semantic_name(TGSI_SEMANTIC_POSITION, 0));
	posz_regid = ir3_find_output_regid(fp,
		ir3_semantic_name(TGSI_SEMANTIC_POSITION, 0));
	psize_regid = ir3_find_output_regid(vp,
		ir3_semantic_name(TGSI_SEMANTIC_PSIZE, 0));
	color_regid = ir3_find_output_regid(fp,
		ir3_semantic_name(TGSI_SEMANTIC_COLOR, 0));
a363 1
			A3XX_HLSQ_CONTROL_0_REG_CONSTMODE(constmode) |
d377 1
a377 1
			A3XX_HLSQ_VS_CONTROL_REG_INSTRLENGTH(vpbuffersz));
d380 1
a380 1
			A3XX_HLSQ_FS_CONTROL_REG_INSTRLENGTH(fpbuffersz));
d383 2
a384 2
	OUT_RING(ring, A3XX_SP_SP_CTRL_REG_CONSTMODE(constmode) |
			COND(emit->key.binning_pass, A3XX_SP_SP_CTRL_REG_BINNING) |
d393 2
a394 2
			A3XX_SP_VS_CTRL_REG0_INSTRBUFFERMODE(vpbuffer) |
			COND(vpbuffer == CACHE, A3XX_SP_VS_CTRL_REG0_CACHEINVALID) |
d401 1
a401 1
			A3XX_SP_VS_CTRL_REG0_LENGTH(vpbuffersz));
d404 1
a404 1
			A3XX_SP_VS_CTRL_REG1_CONSTFOOTPRINT(MAX2(vp->constlen + 1, 0)));
d414 1
a414 1
		j = ir3_next_varying(fp, j);
d416 1
a416 1
			k = ir3_find_output(vp, fp->inputs[j].semantic);
d421 1
a421 1
		j = ir3_next_varying(fp, j);
d423 1
a423 1
			k = ir3_find_output(vp, fp->inputs[j].semantic);
d436 1
a436 1
		j = ir3_next_varying(fp, j);
d439 1
a439 1
		j = ir3_next_varying(fp, j);
d442 1
a442 1
		j = ir3_next_varying(fp, j);
d445 1
a445 1
		j = ir3_next_varying(fp, j);
d457 1
a457 1
	if (emit->key.binning_pass) {
a464 4

		OUT_PKT0(ring, REG_A3XX_SP_FS_OBJ_OFFSET_REG, 1);
		OUT_RING(ring, A3XX_SP_FS_OBJ_OFFSET_REG_CONSTOBJECTOFFSET(128) |
				A3XX_SP_FS_OBJ_OFFSET_REG_SHADEROBJOFFSET(0));
d471 2
a472 2
				A3XX_SP_FS_CTRL_REG0_INSTRBUFFERMODE(fpbuffer) |
				COND(fpbuffer == CACHE, A3XX_SP_FS_CTRL_REG0_CACHEINVALID) |
d479 1
a479 1
				A3XX_SP_FS_CTRL_REG0_LENGTH(fpbuffersz));
d482 1
a482 1
				A3XX_SP_FS_CTRL_REG1_CONSTFOOTPRINT(MAX2(fp->constlen + 1, 0)) |
a483 1

d485 2
a486 3
		OUT_RING(ring, A3XX_SP_FS_OBJ_OFFSET_REG_CONSTOBJECTOFFSET(
					MAX2(128, vp->constlen)) |
				A3XX_SP_FS_OBJ_OFFSET_REG_SHADEROBJOFFSET(fsoff));
d490 4
d509 1
a509 1
	if (emit->key.binning_pass) {
a515 24
		uint32_t vinterp[4] = {0}, flatshade[2] = {0};

		/* figure out VARYING_INTERP / FLAT_SHAD register values: */
		for (j = -1; (j = ir3_next_varying(fp, j)) < (int)fp->inputs_count; ) {
			uint32_t interp = fp->inputs[j].interpolate;
			if ((interp == TGSI_INTERPOLATE_CONSTANT) ||
					((interp == TGSI_INTERPOLATE_COLOR) && emit->rasterflat)) {
				/* TODO might be cleaner to just +8 in SP_VS_VPC_DST_REG
				 * instead.. rather than -8 everywhere else..
				 */
				uint32_t loc = fp->inputs[j].inloc - 8;

				/* currently assuming varyings aligned to 4 (not
				 * packed):
				 */
				debug_assert((loc % 4) == 0);

				for (i = 0; i < 4; i++, loc++) {
					vinterp[loc / 16] |= FLAT << ((loc % 16) * 2);
					flatshade[loc / 32] |= 1 << (loc % 32);
				}
			}
		}

d525 4
a528 4
		OUT_RING(ring, vinterp[0]);    /* VPC_VARYING_INTERP[0].MODE */
		OUT_RING(ring, vinterp[1]);    /* VPC_VARYING_INTERP[1].MODE */
		OUT_RING(ring, vinterp[2]);    /* VPC_VARYING_INTERP[2].MODE */
		OUT_RING(ring, vinterp[3]);    /* VPC_VARYING_INTERP[3].MODE */
d531 4
a534 8
		OUT_RING(ring, fp->shader->vpsrepl[0]);    /* VPC_VARYING_PS_REPL[0].MODE */
		OUT_RING(ring, fp->shader->vpsrepl[1]);    /* VPC_VARYING_PS_REPL[1].MODE */
		OUT_RING(ring, fp->shader->vpsrepl[2]);    /* VPC_VARYING_PS_REPL[2].MODE */
		OUT_RING(ring, fp->shader->vpsrepl[3]);    /* VPC_VARYING_PS_REPL[3].MODE */

		OUT_PKT0(ring, REG_A3XX_SP_FS_FLAT_SHAD_MODE_REG_0, 2);
		OUT_RING(ring, flatshade[0]);        /* SP_FS_FLAT_SHAD_MODE_REG_0 */
		OUT_RING(ring, flatshade[1]);        /* SP_FS_FLAT_SHAD_MODE_REG_1 */
d541 1
a541 2
	if (vpbuffer == BUFFER)
		emit_shader(ring, vp);
d546 2
a547 3
	if (!emit->key.binning_pass) {
		if (fpbuffer == BUFFER)
			emit_shader(ring, fp);
d561 4
a564 4
	so->shader->vpsrepl[0] = 0x99999999;
	so->shader->vpsrepl[1] = 0x99999999;
	so->shader->vpsrepl[2] = 0x99999999;
	so->shader->vpsrepl[3] = 0x99999999;
@


1.1.1.5
log
@Import Mesa 10.2.9
@
text
@a36 1
#include "freedreno_lowering.h"
a39 1
#include "fd3_compiler.h"
d45 1
a45 1
delete_variant(struct fd3_shader_variant *v)
d47 1
a47 151
	ir3_shader_destroy(v->ir);
	fd_bo_del(v->bo);
	free(v);
}

static void
assemble_variant(struct fd3_shader_variant *so)
{
	struct fd_context *ctx = fd_context(so->so->pctx);
	uint32_t sz, *bin;

	bin = ir3_shader_assemble(so->ir, &so->info);
	sz = so->info.sizedwords * 4;

	so->bo = fd_bo_new(ctx->dev, sz,
			DRM_FREEDRENO_GEM_CACHE_WCOMBINE |
			DRM_FREEDRENO_GEM_TYPE_KMEM);

	memcpy(fd_bo_map(so->bo), bin, sz);

	free(bin);

	so->instrlen = so->info.sizedwords / 8;
	so->constlen = so->info.max_const + 1;
}

/* for vertex shader, the inputs are loaded into registers before the shader
 * is executed, so max_regs from the shader instructions might not properly
 * reflect the # of registers actually used:
 */
static void
fixup_vp_regfootprint(struct fd3_shader_variant *so)
{
	unsigned i;
	for (i = 0; i < so->inputs_count; i++) {
		if (so->inputs[i].compmask) {
			uint32_t regid = (so->inputs[i].regid + 3) >> 2;
			so->info.max_reg = MAX2(so->info.max_reg, regid);
		}
	}
	for (i = 0; i < so->outputs_count; i++) {
		uint32_t regid = (so->outputs[i].regid + 3) >> 2;
		so->info.max_reg = MAX2(so->info.max_reg, regid);
	}
}

static struct fd3_shader_variant *
create_variant(struct fd3_shader_stateobj *so, struct fd3_shader_key key)
{
	struct fd3_shader_variant *v = CALLOC_STRUCT(fd3_shader_variant);
	const struct tgsi_token *tokens = so->tokens;
	int ret;

	if (!v)
		return NULL;

	v->so = so;
	v->key = key;
	v->type = so->type;

	if (fd_mesa_debug & FD_DBG_DISASM) {
		DBG("dump tgsi: type=%d, k={bp=%u,cts=%u,hp=%u}", so->type,
			key.binning_pass, key.color_two_side, key.half_precision);
		tgsi_dump(tokens, 0);
	}

	if (!(fd_mesa_debug & FD_DBG_NOOPT)) {
		ret = fd3_compile_shader(v, tokens, key);
		if (ret) {
			debug_error("new compiler failed, trying fallback!");

			v->inputs_count = 0;
			v->outputs_count = 0;
			v->total_in = 0;
			v->has_samp = false;
			v->immediates_count = 0;
		}
	} else {
		ret = -1;  /* force fallback to old compiler */
	}

	if (ret)
		ret = fd3_compile_shader_old(v, tokens, key);

	if (ret) {
		debug_error("compile failed!");
		goto fail;
	}

	assemble_variant(v);
	if (!v->bo) {
		debug_error("assemble failed!");
		goto fail;
	}

	if (so->type == SHADER_VERTEX)
		fixup_vp_regfootprint(v);

	if (fd_mesa_debug & FD_DBG_DISASM) {
		DBG("disassemble: type=%d, k={bp=%u,cts=%u,hp=%u}", v->type,
			key.binning_pass, key.color_two_side, key.half_precision);
		disasm_a3xx(fd_bo_map(v->bo), v->info.sizedwords, 0, v->type);
	}

	return v;

fail:
	delete_variant(v);
	return NULL;
}

struct fd3_shader_variant *
fd3_shader_variant(struct fd3_shader_stateobj *so, struct fd3_shader_key key)
{
	struct fd3_shader_variant *v;

	/* some shader key values only apply to vertex or frag shader,
	 * so normalize the key to avoid constructing multiple identical
	 * variants:
	 */
	if (so->type == SHADER_FRAGMENT) {
		key.binning_pass = false;
	}
	if (so->type == SHADER_VERTEX) {
		key.color_two_side = false;
		key.half_precision = false;
	}

	for (v = so->variants; v; v = v->next)
		if (!memcmp(&key, &v->key, sizeof(key)))
			return v;

	/* compile new variant if it doesn't exist already: */
	v = create_variant(so, key);
	v->next = so->variants;
	so->variants = v;

	return v;
}


static void
delete_shader(struct fd3_shader_stateobj *so)
{
	struct fd3_shader_variant *v, *t;
	for (v = so->variants; v; ) {
		t = v;
		v = v->next;
		delete_variant(t);
	}
	free((void *)so->tokens);
d52 1
a52 1
create_shader(struct pipe_context *pctx, const struct pipe_shader_state *cso,
d56 1
a56 3
	so->pctx = pctx;
	so->type = type;
	so->tokens = tgsi_dup_tokens(cso->tokens);
d64 1
a64 1
	return create_shader(pctx, cso, SHADER_FRAGMENT);
d71 1
a71 1
	delete_shader(so);
d78 1
a78 1
	return create_shader(pctx, cso, SHADER_VERTEX);
d85 1
a85 1
	delete_shader(so);
d89 1
a89 1
emit_shader(struct fd_ringbuffer *ring, const struct fd3_shader_variant *so)
d91 1
a91 1
	const struct ir3_shader_info *si = &so->info;
a128 44
static int
find_output(const struct fd3_shader_variant *so, fd3_semantic semantic)
{
	int j;

	for (j = 0; j < so->outputs_count; j++)
		if (so->outputs[j].semantic == semantic)
			return j;

	/* it seems optional to have a OUT.BCOLOR[n] for each OUT.COLOR[n]
	 * in the vertex shader.. but the fragment shader doesn't know this
	 * so  it will always have both IN.COLOR[n] and IN.BCOLOR[n].  So
	 * at link time if there is no matching OUT.BCOLOR[n], we must map
	 * OUT.COLOR[n] to IN.BCOLOR[n].
	 */
	if (sem2name(semantic) == TGSI_SEMANTIC_BCOLOR) {
		unsigned idx = sem2idx(semantic);
		return find_output(so, fd3_semantic_name(TGSI_SEMANTIC_COLOR, idx));
	}

	debug_assert(0);

	return 0;
}

static int
next_varying(const struct fd3_shader_variant *so, int i)
{
	while (++i < so->inputs_count)
		if (so->inputs[i].compmask && so->inputs[i].bary)
			break;
	return i;
}

static uint32_t
find_output_regid(const struct fd3_shader_variant *so, fd3_semantic semantic)
{
	int j;
	for (j = 0; j < so->outputs_count; j++)
		if (so->outputs[j].semantic == semantic)
			return so->outputs[j].regid;
	return regid(63, 0);
}

d130 1
a130 2
fd3_program_emit(struct fd_ringbuffer *ring,
		struct fd_program_stateobj *prog, struct fd3_shader_key key)
d132 4
a135 2
	const struct fd3_shader_variant *vp, *fp;
	const struct ir3_shader_info *vsi, *fsi;
d137 1
d140 1
a140 1
	vp = fd3_shader_variant(prog->vp, key);
d142 1
a142 1
	if (key.binning_pass) {
d144 1
a144 1
		static const struct fd3_shader_variant binning_fp = {};
d147 1
a147 1
		fp = fd3_shader_variant(prog->fp, key);
d153 51
a203 8
	pos_regid = find_output_regid(vp,
		fd3_semantic_name(TGSI_SEMANTIC_POSITION, 0));
	posz_regid = find_output_regid(fp,
		fd3_semantic_name(TGSI_SEMANTIC_POSITION, 0));
	psize_regid = find_output_regid(vp,
		fd3_semantic_name(TGSI_SEMANTIC_PSIZE, 0));
	color_regid = find_output_regid(fp,
		fd3_semantic_name(TGSI_SEMANTIC_COLOR, 0));
d211 1
d225 1
a225 1
			A3XX_HLSQ_VS_CONTROL_REG_INSTRLENGTH(vp->instrlen));
d228 1
a228 1
			A3XX_HLSQ_FS_CONTROL_REG_INSTRLENGTH(fp->instrlen));
d231 2
a232 2
	OUT_RING(ring, A3XX_SP_SP_CTRL_REG_CONSTMODE(0) |
			COND(key.binning_pass, A3XX_SP_SP_CTRL_REG_BINNING) |
d241 2
a242 2
			A3XX_SP_VS_CTRL_REG0_INSTRBUFFERMODE(BUFFER) |
			A3XX_SP_VS_CTRL_REG0_CACHEINVALID |
d249 1
a249 1
			A3XX_SP_VS_CTRL_REG0_LENGTH(vp->instrlen));
d252 1
a252 1
			A3XX_SP_VS_CTRL_REG1_CONSTFOOTPRINT(MAX2(vsi->max_const, 0)));
d262 1
a262 1
		j = next_varying(fp, j);
d264 1
a264 1
			k = find_output(vp, fp->inputs[j].semantic);
d269 1
a269 1
		j = next_varying(fp, j);
d271 1
a271 1
			k = find_output(vp, fp->inputs[j].semantic);
d284 1
a284 1
		j = next_varying(fp, j);
d287 1
a287 1
		j = next_varying(fp, j);
d290 1
a290 1
		j = next_varying(fp, j);
d293 1
a293 1
		j = next_varying(fp, j);
d305 1
a305 1
	if (key.binning_pass) {
d313 4
d323 2
a324 2
				A3XX_SP_FS_CTRL_REG0_INSTRBUFFERMODE(BUFFER) |
				A3XX_SP_FS_CTRL_REG0_CACHEINVALID |
d331 1
a331 1
				A3XX_SP_FS_CTRL_REG0_LENGTH(fp->instrlen));
d334 1
a334 1
				A3XX_SP_FS_CTRL_REG1_CONSTFOOTPRINT(MAX2(fsi->max_const, 0)) |
d336 1
d338 3
a340 2
		OUT_RING(ring, A3XX_SP_FS_OBJ_OFFSET_REG_CONSTOBJECTOFFSET(128) |
				A3XX_SP_FS_OBJ_OFFSET_REG_SHADEROBJOFFSET(0));
a343 4
	OUT_PKT0(ring, REG_A3XX_SP_FS_FLAT_SHAD_MODE_REG_0, 2);
	OUT_RING(ring, 0x00000000);        /* SP_FS_FLAT_SHAD_MODE_REG_0 */
	OUT_RING(ring, 0x00000000);        /* SP_FS_FLAT_SHAD_MODE_REG_1 */

d359 1
a359 1
	if (key.binning_pass) {
d366 24
d399 4
a402 4
		OUT_RING(ring, fp->so->vinterp[0]);    /* VPC_VARYING_INTERP[0].MODE */
		OUT_RING(ring, fp->so->vinterp[1]);    /* VPC_VARYING_INTERP[1].MODE */
		OUT_RING(ring, fp->so->vinterp[2]);    /* VPC_VARYING_INTERP[2].MODE */
		OUT_RING(ring, fp->so->vinterp[3]);    /* VPC_VARYING_INTERP[3].MODE */
d405 8
a412 4
		OUT_RING(ring, fp->so->vpsrepl[0]);    /* VPC_VARYING_PS_REPL[0].MODE */
		OUT_RING(ring, fp->so->vpsrepl[1]);    /* VPC_VARYING_PS_REPL[1].MODE */
		OUT_RING(ring, fp->so->vpsrepl[2]);    /* VPC_VARYING_PS_REPL[2].MODE */
		OUT_RING(ring, fp->so->vpsrepl[3]);    /* VPC_VARYING_PS_REPL[3].MODE */
d419 2
a420 1
	emit_shader(ring, vp);
d425 3
a427 2
	if (!key.binning_pass) {
		emit_shader(ring, fp);
d441 4
a444 4
	so->vpsrepl[0] = 0x99999999;
	so->vpsrepl[1] = 0x99999999;
	so->vpsrepl[2] = 0x99999999;
	so->vpsrepl[3] = 0x99999999;
@


