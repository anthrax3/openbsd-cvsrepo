head	1.7;
access;
symbols
	OPENBSD_5_8:1.6.0.4
	OPENBSD_5_8_BASE:1.6
	OPENBSD_5_7:1.6.0.2
	OPENBSD_5_7_BASE:1.6
	v10_2_9:1.1.1.5
	v10_4_3:1.1.1.4
	v10_2_7:1.1.1.3
	OPENBSD_5_6:1.4.0.2
	OPENBSD_5_6_BASE:1.4
	v10_2_3:1.1.1.3
	OPENBSD_5_5:1.3.0.2
	OPENBSD_5_5_BASE:1.3
	v9_2_5:1.1.1.2
	v9_2_3:1.1.1.2
	v9_2_2:1.1.1.2
	v9_2_1:1.1.1.2
	v9_2_0:1.1.1.2
	OPENBSD_5_4:1.2.0.4
	OPENBSD_5_4_BASE:1.2
	OPENBSD_5_3:1.2.0.2
	OPENBSD_5_3_BASE:1.2
	OPENBSD_5_2:1.1.1.1.0.4
	OPENBSD_5_2_BASE:1.1.1.1
	OPENBSD_5_1_BASE:1.1.1.1
	OPENBSD_5_1:1.1.1.1.0.2
	v7_10_3:1.1.1.1
	mesa:1.1.1;
locks; strict;
comment	@ * @;


1.7
date	2015.12.23.05.17.35;	author jsg;	state dead;
branches;
next	1.6;
commitid	TnlogFl9nOv2eaRf;

1.6
date	2015.02.20.23.09.53;	author jsg;	state Exp;
branches;
next	1.5;
commitid	4ry2gvZGMXkCUD2n;

1.5
date	2015.01.25.14.41.16;	author jsg;	state Exp;
branches;
next	1.4;
commitid	mcxB0JvoI9gTDYXU;

1.4
date	2014.07.09.21.08.55;	author jsg;	state Exp;
branches;
next	1.3;
commitid	WPD6rgPryPkvXOr9;

1.3
date	2013.09.05.14.01.10;	author jsg;	state Exp;
branches;
next	1.2;

1.2
date	2012.08.17.13.58.06;	author mpi;	state Exp;
branches;
next	1.1;

1.1
date	2011.10.23.13.29.29;	author matthieu;	state Exp;
branches
	1.1.1.1;
next	;

1.1.1.1
date	2011.10.23.13.29.29;	author matthieu;	state Exp;
branches;
next	1.1.1.2;

1.1.1.2
date	2013.09.05.13.12.59;	author jsg;	state Exp;
branches;
next	1.1.1.3;

1.1.1.3
date	2014.07.09.20.34.16;	author jsg;	state Exp;
branches;
next	1.1.1.4;
commitid	3JhLfwcuBALP0ZR7;

1.1.1.4
date	2015.01.25.14.08.53;	author jsg;	state Exp;
branches;
next	1.1.1.5;
commitid	ce2W5rH5aF7VS9gi;

1.1.1.5
date	2015.02.20.22.46.08;	author jsg;	state Exp;
branches;
next	;
commitid	F54a1i0WXHMxq7kE;


desc
@@


1.7
log
@remove the now unused Mesa 10.2.9 code
@
text
@/**********************************************************
 * Copyright 2008-2009 VMware, Inc.  All rights reserved.
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 *
 **********************************************************/

#include "svga3d_reg.h"
#include "svga3d_surfacedefs.h"

#include "pipe/p_state.h"
#include "pipe/p_defines.h"
#include "os/os_thread.h"
#include "util/u_format.h"
#include "util/u_inlines.h"
#include "util/u_math.h"
#include "util/u_memory.h"
#include "util/u_resource.h"

#include "svga_cmd.h"
#include "svga_format.h"
#include "svga_screen.h"
#include "svga_context.h"
#include "svga_resource_texture.h"
#include "svga_resource_buffer.h"
#include "svga_sampler_view.h"
#include "svga_winsys.h"
#include "svga_debug.h"


/* XXX: This isn't a real hardware flag, but just a hack for kernel to
 * know about primary surfaces. Find a better way to accomplish this.
 */
#define SVGA3D_SURFACE_HINT_SCANOUT (1 << 9)


static INLINE void
svga_transfer_dma_band(struct svga_context *svga,
                       struct svga_transfer *st,
                       SVGA3dTransferType transfer,
                       unsigned y, unsigned h, unsigned srcy,
                       SVGA3dSurfaceDMAFlags flags)
{
   struct svga_texture *texture = svga_texture(st->base.resource); 
   SVGA3dCopyBox box;
   enum pipe_error ret;
 
   assert(!st->use_direct_map);

   box.x = st->base.box.x;
   box.y = y;
   box.z = st->base.box.z;
   box.w = st->base.box.width;
   box.h = h;
   box.d = 1;
   box.srcx = 0;
   box.srcy = srcy;
   box.srcz = 0;

   if (st->base.resource->target == PIPE_TEXTURE_CUBE) {
      st->face = st->base.box.z;
      box.z = 0;
   }
   else
      st->face = 0;

   SVGA_DBG(DEBUG_DMA, "dma %s sid %p, face %u, (%u, %u, %u) - (%u, %u, %u), %ubpp\n",
                transfer == SVGA3D_WRITE_HOST_VRAM ? "to" : "from", 
                texture->handle,
                st->face,
                st->base.box.x,
                y,
                box.z,
                st->base.box.x + st->base.box.width,
                y + h,
                box.z + 1,
                util_format_get_blocksize(texture->b.b.format) * 8 /
                (util_format_get_blockwidth(texture->b.b.format)*util_format_get_blockheight(texture->b.b.format)));

   ret = SVGA3D_SurfaceDMA(svga->swc, st, transfer, &box, 1, flags);
   if(ret != PIPE_OK) {
      svga_context_flush(svga, NULL);
      ret = SVGA3D_SurfaceDMA(svga->swc, st, transfer, &box, 1, flags);
      assert(ret == PIPE_OK);
   }
}


static INLINE void
svga_transfer_dma(struct svga_context *svga,
                  struct svga_transfer *st,
                  SVGA3dTransferType transfer,
                  SVGA3dSurfaceDMAFlags flags)
{
   struct svga_texture *texture = svga_texture(st->base.resource); 
   struct svga_screen *screen = svga_screen(texture->b.b.screen);
   struct svga_winsys_screen *sws = screen->sws;
   struct pipe_fence_handle *fence = NULL;

   assert(!st->use_direct_map);

   if (transfer == SVGA3D_READ_HOST_VRAM) {
      SVGA_DBG(DEBUG_PERF, "%s: readback transfer\n", __FUNCTION__);
   }

   /* Ensure any pending operations on host surfaces are queued on the command
    * buffer first.
    */
   svga_surfaces_flush( svga );

   if(!st->swbuf) {
      /* Do the DMA transfer in a single go */

      svga_transfer_dma_band(svga, st, transfer,
                             st->base.box.y, st->base.box.height, 0,
                             flags);

      if(transfer == SVGA3D_READ_HOST_VRAM) {
         svga_context_flush(svga, &fence);
         sws->fence_finish(sws, fence, 0);
         sws->fence_reference(sws, &fence, NULL);
      }
   }
   else {
      int y, h, srcy;
      unsigned blockheight = util_format_get_blockheight(st->base.resource->format);
      h = st->hw_nblocksy * blockheight;
      srcy = 0;
      for(y = 0; y < st->base.box.height; y += h) {
         unsigned offset, length;
         void *hw, *sw;

         if (y + h > st->base.box.height)
            h = st->base.box.height - y;

         /* Transfer band must be aligned to pixel block boundaries */
         assert(y % blockheight == 0);
         assert(h % blockheight == 0);

         offset = y * st->base.stride / blockheight;
         length = h * st->base.stride / blockheight;

         sw = (uint8_t *)st->swbuf + offset;

         if (transfer == SVGA3D_WRITE_HOST_VRAM) {
            unsigned usage = PIPE_TRANSFER_WRITE;

            /* Wait for the previous DMAs to complete */
            /* TODO: keep one DMA (at half the size) in the background */
            if (y) {
               svga_context_flush(svga, NULL);
               usage |= PIPE_TRANSFER_DISCARD_WHOLE_RESOURCE;
            }

            hw = sws->buffer_map(sws, st->hwbuf, usage);
            assert(hw);
            if (hw) {
               memcpy(hw, sw, length);
               sws->buffer_unmap(sws, st->hwbuf);
            }
         }

         svga_transfer_dma_band(svga, st, transfer, y, h, srcy, flags);

         /*
          * Prevent the texture contents to be discarded on the next band
          * upload.
          */

         flags.discard = FALSE;

         if(transfer == SVGA3D_READ_HOST_VRAM) {
            svga_context_flush(svga, &fence);
            sws->fence_finish(sws, fence, 0);

            hw = sws->buffer_map(sws, st->hwbuf, PIPE_TRANSFER_READ);
            assert(hw);
            if(hw) {
               memcpy(sw, hw, length);
               sws->buffer_unmap(sws, st->hwbuf);
            }
         }
      }
   }
}


static boolean 
svga_texture_get_handle(struct pipe_screen *screen,
                               struct pipe_resource *texture,
                               struct winsys_handle *whandle)
{
   struct svga_winsys_screen *sws = svga_winsys_screen(texture->screen);
   unsigned stride;

   assert(svga_texture(texture)->key.cachable == 0);
   svga_texture(texture)->key.cachable = 0;
   stride = util_format_get_nblocksx(texture->format, texture->width0) *
            util_format_get_blocksize(texture->format);
   return sws->surface_get_handle(sws, svga_texture(texture)->handle, stride, whandle);
}


static void
svga_texture_destroy(struct pipe_screen *screen,
		     struct pipe_resource *pt)
{
   struct svga_screen *ss = svga_screen(screen);
   struct svga_texture *tex = svga_texture(pt);

   ss->texture_timestamp++;

   svga_sampler_view_reference(&tex->cached_view, NULL);

   /*
     DBG("%s deleting %p\n", __FUNCTION__, (void *) tex);
   */
   SVGA_DBG(DEBUG_DMA, "unref sid %p (texture)\n", tex->handle);
   svga_screen_surface_destroy(ss, &tex->key, &tex->handle);

   ss->total_resource_bytes -= tex->size;

   FREE(tex->rendered_to);
   FREE(tex);
}


/**
 * Determine if we need to read back a texture image before mapping it.
 */
static boolean
need_tex_readback(struct pipe_transfer *transfer)
{
   struct svga_texture *t = svga_texture(transfer->resource);

   if (transfer->usage & PIPE_TRANSFER_READ)
      return TRUE;

   if ((transfer->usage & PIPE_TRANSFER_WRITE) &&
       ((transfer->usage & PIPE_TRANSFER_DISCARD_WHOLE_RESOURCE) == 0)) {
      unsigned face;

      if (transfer->resource->target == PIPE_TEXTURE_CUBE) {
         assert(transfer->box.depth == 1);
         face = transfer->box.z;
      }
      else {
         face = 0;
      }
      if (svga_was_texture_rendered_to(t, face, transfer->level)) {
         return TRUE;
      }
   }

   return FALSE;
}



/* XXX: Still implementing this as if it was a screen function, but
 * can now modify it to queue transfers on the context.
 */
static void *
svga_texture_transfer_map(struct pipe_context *pipe,
                          struct pipe_resource *texture,
                          unsigned level,
                          unsigned usage,
                          const struct pipe_box *box,
                          struct pipe_transfer **ptransfer)
{
   struct svga_context *svga = svga_context(pipe);
   struct svga_screen *ss = svga_screen(pipe->screen);
   struct svga_winsys_screen *sws = ss->sws;
   struct svga_transfer *st;
   unsigned nblocksx, nblocksy;
   boolean use_direct_map = svga_have_gb_objects(svga) &&
      !svga_have_gb_dma(svga);
   unsigned d;

   /* We can't map texture storage directly unless we have GB objects */
   if (usage & PIPE_TRANSFER_MAP_DIRECTLY) {
      if (svga_have_gb_objects(svga))
         use_direct_map = TRUE;
      else
         return NULL;
   }

   st = CALLOC_STRUCT(svga_transfer);
   if (!st)
      return NULL;

   {
      unsigned w, h;
      if (use_direct_map) {
         /* we'll directly access the guest-backed surface */
         w = u_minify(texture->width0, level);
         h = u_minify(texture->height0, level);
         d = u_minify(texture->depth0, level);
      }
      else {
         /* we'll put the data into a tightly packed buffer */
         w = box->width;
         h = box->height;
         d = box->depth;
      }
      nblocksx = util_format_get_nblocksx(texture->format, w);
      nblocksy = util_format_get_nblocksy(texture->format, h);
   }

   pipe_resource_reference(&st->base.resource, texture);
   st->base.level = level;
   st->base.usage = usage;
   st->base.box = *box;
   st->base.stride = nblocksx*util_format_get_blocksize(texture->format);
   st->base.layer_stride = st->base.stride * nblocksy;

   if (!use_direct_map) {
      /* Use a DMA buffer */
      st->hw_nblocksy = nblocksy;

      st->hwbuf = svga_winsys_buffer_create(svga,
                                            1, 
                                            0,
                                            st->hw_nblocksy * st->base.stride * d);
      while(!st->hwbuf && (st->hw_nblocksy /= 2)) {
         st->hwbuf = svga_winsys_buffer_create(svga,
                                               1, 
                                               0,
                                               st->hw_nblocksy * st->base.stride * d);
      }

      if (!st->hwbuf) {
         FREE(st);
         return NULL;
      }

      if(st->hw_nblocksy < nblocksy) {
         /* We couldn't allocate a hardware buffer big enough for the transfer, 
          * so allocate regular malloc memory instead */
         if (0) {
            debug_printf("%s: failed to allocate %u KB of DMA, "
                         "splitting into %u x %u KB DMA transfers\n",
                         __FUNCTION__,
                         (nblocksy*st->base.stride + 1023)/1024,
                         (nblocksy + st->hw_nblocksy - 1)/st->hw_nblocksy,
                         (st->hw_nblocksy*st->base.stride + 1023)/1024);
         }

         st->swbuf = MALLOC(nblocksy * st->base.stride * d);
         if (!st->swbuf) {
            sws->buffer_destroy(sws, st->hwbuf);
            FREE(st);
            return NULL;
         }
      }

      if (usage & PIPE_TRANSFER_READ) {
         SVGA3dSurfaceDMAFlags flags;
         memset(&flags, 0, sizeof flags);
         svga_transfer_dma(svga, st, SVGA3D_READ_HOST_VRAM, flags);
      }
   } else {
      struct pipe_transfer *transfer = &st->base;
      struct svga_texture *tex = svga_texture(transfer->resource);
      struct svga_winsys_surface *surf = tex->handle;
      unsigned face;

      assert(surf);

      if (tex->b.b.target == PIPE_TEXTURE_CUBE) {
	 face = transfer->box.z;
      } else {
	 face = 0;
      }

      if (need_tex_readback(transfer)) {
	 SVGA3dBox box;
	 enum pipe_error ret;

	 box.x = transfer->box.x;
	 box.y = transfer->box.y;
	 box.w = transfer->box.width;
	 box.h = transfer->box.height;
	 box.d = transfer->box.depth;
	 if (tex->b.b.target == PIPE_TEXTURE_CUBE) {
	    box.z = 0;
	 }
	 else {
	    box.z = transfer->box.z;
	 }

         (void) box;  /* not used at this time */

         svga_surfaces_flush(svga);

	 ret = SVGA3D_ReadbackGBImage(svga->swc, surf, face, transfer->level);

	 if (ret != PIPE_OK) {
	    svga_context_flush(svga, NULL);
	    ret = SVGA3D_ReadbackGBImage(svga->swc, surf, face, transfer->level);
	    assert(ret == PIPE_OK);
	 }

	 svga_context_flush(svga, NULL);

         /*
          * Note: if PIPE_TRANSFER_DISCARD_WHOLE_RESOURCE were specified
          * we could potentially clear the flag for all faces/layers/mips.
          */
         svga_clear_texture_rendered_to(tex, face, transfer->level);
      }
      else {
	 assert(transfer->usage & PIPE_TRANSFER_WRITE);
	 if ((transfer->usage & PIPE_TRANSFER_UNSYNCHRONIZED) == 0) {
            svga_surfaces_flush(svga);
            if (!sws->surface_is_flushed(sws, surf))
               svga_context_flush(svga, NULL);
	 }
      }
   }

   st->use_direct_map = use_direct_map;

   *ptransfer = &st->base;

   /*
    * Begin mapping code
    */
   if (st->swbuf) {
      return st->swbuf;
   }
   else if (!st->use_direct_map) {
      return sws->buffer_map(sws, st->hwbuf, usage);
   }
   else {
      struct svga_screen *screen = svga_screen(svga->pipe.screen);
      SVGA3dSurfaceFormat format;
      SVGA3dSize baseLevelSize;
      struct svga_texture *tex = svga_texture(texture);
      struct svga_winsys_surface *surf = tex->handle;
      uint8_t *map;
      boolean retry;
      unsigned face, offset, mip_width, mip_height;
      unsigned xoffset = box->x;
      unsigned yoffset = box->y;
      unsigned zoffset = box->z;

      map = svga->swc->surface_map(svga->swc, surf, usage, &retry);
      if (map == NULL && retry) {
         /*
          * At this point, the svga_surfaces_flush() should already have
          * called in svga_texture_get_transfer().
          */
         svga_context_flush(svga, NULL);
         map = svga->swc->surface_map(svga->swc, surf, usage, &retry);
      }

      /*
       * Make sure whe return NULL if the map fails
       */
      if (map == NULL) {
         FREE(st);
         return map;
      }

      /**
       * Compute the offset to the specific texture slice in the buffer.
       */
      if (tex->b.b.target == PIPE_TEXTURE_CUBE) {
         face = zoffset;
         zoffset = 0;
      } else {
         face = 0;
      }

      format = svga_translate_format(screen, tex->b.b.format, 0);
      baseLevelSize.width = tex->b.b.width0;
      baseLevelSize.height = tex->b.b.height0;
      baseLevelSize.depth = tex->b.b.depth0;

      offset = svga3dsurface_get_image_offset(format, baseLevelSize,
                                              tex->b.b.last_level + 1, /* numMips */
                                              face, level);
      if (level > 0) {
         assert(offset > 0);
      }

      mip_width = u_minify(tex->b.b.width0, level);
      mip_height = u_minify(tex->b.b.height0, level);

      offset += svga3dsurface_get_pixel_offset(format, mip_width, mip_height,
                                               xoffset, yoffset, zoffset);

      return (void *) (map + offset);
   }
}


/**
 * Unmap a GB texture surface.
 */
static void
svga_texture_surface_unmap(struct svga_context *svga,
                           struct pipe_transfer *transfer)
{
   struct svga_winsys_surface *surf = svga_texture(transfer->resource)->handle;
   struct svga_winsys_context *swc = svga->swc;
   boolean rebind;

   assert(surf);

   swc->surface_unmap(swc, surf, &rebind);
   if (rebind) {
      enum pipe_error ret;
      ret = SVGA3D_BindGBSurface(swc, surf);
      if (ret != PIPE_OK) {
         /* flush and retry */
         svga_context_flush(svga, NULL);
         ret = SVGA3D_BindGBSurface(swc, surf);
         assert(ret == PIPE_OK);
      }
   }
}


/* XXX: Still implementing this as if it was a screen function, but
 * can now modify it to queue transfers on the context.
 */
static void
svga_texture_transfer_unmap(struct pipe_context *pipe,
			    struct pipe_transfer *transfer)
{
   struct svga_context *svga = svga_context(pipe);
   struct svga_screen *ss = svga_screen(pipe->screen);
   struct svga_winsys_screen *sws = ss->sws;
   struct svga_transfer *st = svga_transfer(transfer);
   struct svga_texture *tex = svga_texture(transfer->resource);

   if (!st->swbuf) {
      if (st->use_direct_map) {
         svga_texture_surface_unmap(svga, transfer);
      }
      else {
         sws->buffer_unmap(sws, st->hwbuf);
      }
   }

   if (!st->use_direct_map && (st->base.usage & PIPE_TRANSFER_WRITE)) {
      /* Use DMA to transfer texture data */
      SVGA3dSurfaceDMAFlags flags;

      memset(&flags, 0, sizeof flags);
      if (transfer->usage & PIPE_TRANSFER_DISCARD_WHOLE_RESOURCE) {
         flags.discard = TRUE;
      }
      if (transfer->usage & PIPE_TRANSFER_UNSYNCHRONIZED) {
         flags.unsynchronized = TRUE;
      }

      svga_transfer_dma(svga, st, SVGA3D_WRITE_HOST_VRAM, flags);
   } else if (transfer->usage & PIPE_TRANSFER_WRITE) {
      struct svga_winsys_surface *surf =
	 svga_texture(transfer->resource)->handle;
      unsigned face;
      SVGA3dBox box;
      enum pipe_error ret;

      assert(svga_have_gb_objects(svga));

      /* update the effected region */
      if (tex->b.b.target == PIPE_TEXTURE_CUBE) {
	 face = transfer->box.z;
      } else {
	 face = 0;
      }

      box.x = transfer->box.x;
      box.y = transfer->box.y;
      if (tex->b.b.target == PIPE_TEXTURE_CUBE) {
         box.z = 0;
      }
      else {
         box.z = transfer->box.z;
      }
      box.w = transfer->box.width;
      box.h = transfer->box.height;
      box.d = transfer->box.depth;

      if (0)
         debug_printf("%s %d, %d, %d  %d x %d x %d\n",
                      __FUNCTION__,
                      box.x, box.y, box.z,
                      box.w, box.h, box.d);

      ret = SVGA3D_UpdateGBImage(svga->swc, surf, &box, face, transfer->level);
      if (ret != PIPE_OK) {
         svga_context_flush(svga, NULL);
         ret = SVGA3D_UpdateGBImage(svga->swc, surf, &box, face, transfer->level);
         assert(ret == PIPE_OK);
      }
   }

   ss->texture_timestamp++;
   svga_age_texture_view(tex, transfer->level);
   if (transfer->resource->target == PIPE_TEXTURE_CUBE)
      svga_define_texture_level(tex, transfer->box.z, transfer->level);
   else
      svga_define_texture_level(tex, 0, transfer->level);

   pipe_resource_reference(&st->base.resource, NULL);

   FREE(st->swbuf);
   if (!st->use_direct_map) {
      sws->buffer_destroy(sws, st->hwbuf);
   }
   FREE(st);
}


struct u_resource_vtbl svga_texture_vtbl = 
{
   svga_texture_get_handle,	      /* get_handle */
   svga_texture_destroy,	      /* resource_destroy */
   svga_texture_transfer_map,	      /* transfer_map */
   u_default_transfer_flush_region,   /* transfer_flush_region */
   svga_texture_transfer_unmap,	      /* transfer_unmap */
   u_default_transfer_inline_write    /* transfer_inline_write */
};


struct pipe_resource *
svga_texture_create(struct pipe_screen *screen,
                    const struct pipe_resource *template)
{
   struct svga_screen *svgascreen = svga_screen(screen);
   struct svga_texture *tex = CALLOC_STRUCT(svga_texture);

   if (!tex)
      goto error1;

   tex->b.b = *template;
   tex->b.vtbl = &svga_texture_vtbl;
   pipe_reference_init(&tex->b.b.reference, 1);
   tex->b.b.screen = screen;

   assert(template->last_level < SVGA_MAX_TEXTURE_LEVELS);
   if(template->last_level >= SVGA_MAX_TEXTURE_LEVELS)
      goto error2;
   
   tex->key.flags = 0;
   tex->key.size.width = template->width0;
   tex->key.size.height = template->height0;
   tex->key.size.depth = template->depth0;

   if(template->target == PIPE_TEXTURE_CUBE) {
      tex->key.flags |= SVGA3D_SURFACE_CUBEMAP;
      tex->key.numFaces = 6;
   }
   else {
      tex->key.numFaces = 1;
   }

   if (template->target == PIPE_TEXTURE_3D) {
      tex->key.flags |= SVGA3D_SURFACE_VOLUME;
   }

   tex->key.cachable = 1;

   if (template->bind & PIPE_BIND_SAMPLER_VIEW)
      tex->key.flags |= SVGA3D_SURFACE_HINT_TEXTURE;

   if (template->bind & PIPE_BIND_DISPLAY_TARGET) {
      tex->key.cachable = 0;
   }

   if (template->bind & PIPE_BIND_SHARED) {
      tex->key.cachable = 0;
   }

   if (template->bind & (PIPE_BIND_SCANOUT |
                         PIPE_BIND_CURSOR)) {
      tex->key.flags |= SVGA3D_SURFACE_HINT_SCANOUT;
      tex->key.cachable = 0;
   }

   /* 
    * Note: Previously we never passed the
    * SVGA3D_SURFACE_HINT_RENDERTARGET hint. Mesa cannot
    * know beforehand whether a texture will be used as a rendertarget or not
    * and it always requests PIPE_BIND_RENDER_TARGET, therefore
    * passing the SVGA3D_SURFACE_HINT_RENDERTARGET here defeats its purpose.
    *
    * However, this was changed since other state trackers
    * (XA for example) uses it accurately and certain device versions
    * relies on it in certain situations to render correctly.
    */
   if((template->bind & PIPE_BIND_RENDER_TARGET) &&
      !util_format_is_s3tc(template->format))
      tex->key.flags |= SVGA3D_SURFACE_HINT_RENDERTARGET;
   
   if(template->bind & PIPE_BIND_DEPTH_STENCIL)
      tex->key.flags |= SVGA3D_SURFACE_HINT_DEPTHSTENCIL;
   
   tex->key.numMipLevels = template->last_level + 1;
   
   tex->key.format = svga_translate_format(svgascreen, template->format, template->bind);
   if(tex->key.format == SVGA3D_FORMAT_INVALID)
      goto error2;

   SVGA_DBG(DEBUG_DMA, "surface_create for texture\n", tex->handle);
   tex->handle = svga_screen_surface_create(svgascreen, &tex->key);
   if (tex->handle)
      SVGA_DBG(DEBUG_DMA, "  --> got sid %p (texture)\n", tex->handle);

   debug_reference(&tex->b.b.reference,
                   (debug_reference_descriptor)debug_describe_resource, 0);

   tex->size = util_resource_size(template);
   svgascreen->total_resource_bytes += tex->size;

   tex->rendered_to = CALLOC(template->depth0 * template->array_size,
                             sizeof(tex->rendered_to[0]));
   if (!tex->rendered_to)
      goto error2;

   return &tex->b.b;

error2:
   FREE(tex->rendered_to);
   FREE(tex);
error1:
   return NULL;
}


struct pipe_resource *
svga_texture_from_handle(struct pipe_screen *screen,
			 const struct pipe_resource *template,
			 struct winsys_handle *whandle)
{
   struct svga_winsys_screen *sws = svga_winsys_screen(screen);
   struct svga_winsys_surface *srf;
   struct svga_texture *tex;
   enum SVGA3dSurfaceFormat format = 0;
   assert(screen);

   /* Only supports one type */
   if ((template->target != PIPE_TEXTURE_2D &&
       template->target != PIPE_TEXTURE_RECT) ||
       template->last_level != 0 ||
       template->depth0 != 1) {
      return NULL;
   }

   srf = sws->surface_from_handle(sws, whandle, &format);

   if (!srf)
      return NULL;

   if (svga_translate_format(svga_screen(screen), template->format, template->bind) != format) {
      unsigned f1 = svga_translate_format(svga_screen(screen), template->format, template->bind);
      unsigned f2 = format;

      /* It's okay for XRGB and ARGB or depth with/out stencil to get mixed up */
      if ( !( (f1 == SVGA3D_X8R8G8B8 && f2 == SVGA3D_A8R8G8B8) ||
              (f1 == SVGA3D_A8R8G8B8 && f2 == SVGA3D_X8R8G8B8) ||
              (f1 == SVGA3D_Z_D24X8 && f2 == SVGA3D_Z_D24S8) ||
              (f1 == SVGA3D_Z_DF24 && f2 == SVGA3D_Z_D24S8_INT) ) ) {
         debug_printf("%s wrong format %u != %u\n", __FUNCTION__, f1, f2);
         return NULL;
      }
   }

   tex = CALLOC_STRUCT(svga_texture);
   if (!tex)
      return NULL;

   tex->b.b = *template;
   tex->b.vtbl = &svga_texture_vtbl;
   pipe_reference_init(&tex->b.b.reference, 1);
   tex->b.b.screen = screen;

   SVGA_DBG(DEBUG_DMA, "wrap surface sid %p\n", srf);

   tex->key.cachable = 0;
   tex->handle = srf;

   tex->rendered_to = CALLOC(1, sizeof(tex->rendered_to[0]));

   return &tex->b.b;
}
@


1.6
log
@Merge Mesa 10.2.9
@
text
@@


1.5
log
@Merge Mesa 10.4.3
Tested by matthieu@@ mpi@@ and myself.  landry@@ ran a ports bulk build.
kettenis@@ tracked down the cause of an alignment fault on archs
that require strict eight byte pointer alignment.
@
text
@d55 1
a55 1
static void
d107 1
a107 1
static void
d730 2
a731 4
   if (!tex->handle)
       goto error2;

   SVGA_DBG(DEBUG_DMA, "  --> got sid %p (texture)\n", tex->handle);
@


1.4
log
@Merge Mesa 10.2.3
tested by matthieu@@ kettenis@@ mpi@@ brett@@ and myself across a
diverse range of hardware
@
text
@d55 1
a55 1
static INLINE void
d107 1
a107 1
static INLINE void
d730 4
a733 2
   if (tex->handle)
      SVGA_DBG(DEBUG_DMA, "  --> got sid %p (texture)\n", tex->handle);
@


1.3
log
@Merge Mesa 9.2.0
@
text
@d26 2
a27 1
#include "svga_cmd.h"
a30 1
#include "util/u_inlines.h"
d33 1
d38 1
d66 2
d118 2
d241 1
d246 32
d293 12
a304 6
   unsigned nblocksx = util_format_get_nblocksx(texture->format, box->width);
   unsigned nblocksy = util_format_get_nblocksy(texture->format, box->height);

   /* We can't map texture storage directly */
   if (usage & PIPE_TRANSFER_MAP_DIRECTLY)
      return NULL;
d310 19
a328 1
   st->base.resource = texture;
d335 3
a337 1
   st->hw_nblocksy = nblocksy;
a338 5
   st->hwbuf = svga_winsys_buffer_create(svga,
                                         1, 
                                         0,
                                         st->hw_nblocksy * st->base.stride * box->depth);
   while(!st->hwbuf && (st->hw_nblocksy /= 2)) {
d342 24
a365 2
                                            st->hw_nblocksy * st->base.stride * box->depth);
   }
d367 7
a373 2
   if(!st->hwbuf)
      goto no_hwbuf;
d375 17
a391 10
   if(st->hw_nblocksy < nblocksy) {
      /* We couldn't allocate a hardware buffer big enough for the transfer, 
       * so allocate regular malloc memory instead */
      if (0) {
         debug_printf("%s: failed to allocate %u KB of DMA, "
                      "splitting into %u x %u KB DMA transfers\n",
                      __FUNCTION__,
                      (nblocksy*st->base.stride + 1023)/1024,
                      (nblocksy + st->hw_nblocksy - 1)/st->hw_nblocksy,
                      (st->hw_nblocksy*st->base.stride + 1023)/1024);
d394 44
a437 3
      st->swbuf = MALLOC(nblocksy*st->base.stride);
      if(!st->swbuf)
         goto no_swbuf;
d440 3
a442 5
   if (usage & PIPE_TRANSFER_READ) {
      SVGA3dSurfaceDMAFlags flags;
      memset(&flags, 0, sizeof flags);
      svga_transfer_dma(svga, st, SVGA3D_READ_HOST_VRAM, flags);
   }
d444 3
a447 1
      *ptransfer = &st->base;
d449 62
a510 6
   } else {
      /* The wait for read transfers already happened when svga_transfer_dma
       * was called. */
      void *map = sws->buffer_map(sws, st->hwbuf, usage);
      if (!map)
         goto fail;
d512 1
a512 2
      *ptransfer = &st->base;
      return map;
d514 2
d517 24
a540 7
fail:
   FREE(st->swbuf);
no_swbuf:
   sws->buffer_destroy(sws, st->hwbuf);
no_hwbuf:
   FREE(st);
   return NULL;
d557 8
a564 2
   if(!st->swbuf)
      sws->buffer_unmap(sws, st->hwbuf);
d566 2
a567 1
   if (st->base.usage & PIPE_TRANSFER_WRITE) {
d579 40
a618 6
      ss->texture_timestamp++;
      svga_age_texture_view(tex, transfer->level);
      if (transfer->resource->target == PIPE_TEXTURE_CUBE)
         svga_define_texture_level(tex, transfer->box.z, transfer->level);
      else
         svga_define_texture_level(tex, 0, transfer->level);
d621 9
d631 3
a633 1
   sws->buffer_destroy(sws, st->hwbuf);
d682 1
a682 1
      tex->key.flags |= SVGA3D_SURFACE_HINT_VOLUME;
d739 5
d747 1
d805 2
@


1.2
log
@Upate to libGL 7.11.2

Tested by jsg@@, matthieu@@ and ajacoutot@@, ok mattieu@@
@
text
@d35 1
d37 1
a52 79
/*
 * Helper function and arrays
 */

SVGA3dSurfaceFormat
svga_translate_format(enum pipe_format format)
{
   switch(format) {
   
   case PIPE_FORMAT_B8G8R8A8_UNORM:
      return SVGA3D_A8R8G8B8;
   case PIPE_FORMAT_B8G8R8X8_UNORM:
      return SVGA3D_X8R8G8B8;

      /* Required for GL2.1:
       */
   case PIPE_FORMAT_B8G8R8A8_SRGB:
      return SVGA3D_A8R8G8B8;

   case PIPE_FORMAT_B5G6R5_UNORM:
      return SVGA3D_R5G6B5;
   case PIPE_FORMAT_B5G5R5A1_UNORM:
      return SVGA3D_A1R5G5B5;
   case PIPE_FORMAT_B4G4R4A4_UNORM:
      return SVGA3D_A4R4G4B4;

      
   /* XXX: Doesn't seem to work properly.
   case PIPE_FORMAT_Z32_UNORM:
      return SVGA3D_Z_D32;
    */
   case PIPE_FORMAT_Z16_UNORM:
      return SVGA3D_Z_D16;
   case PIPE_FORMAT_S8_USCALED_Z24_UNORM:
      return SVGA3D_Z_D24S8;
   case PIPE_FORMAT_X8Z24_UNORM:
      return SVGA3D_Z_D24X8;

   case PIPE_FORMAT_A8_UNORM:
      return SVGA3D_ALPHA8;
   case PIPE_FORMAT_L8_UNORM:
      return SVGA3D_LUMINANCE8;

   case PIPE_FORMAT_DXT1_RGB:
   case PIPE_FORMAT_DXT1_RGBA:
      return SVGA3D_DXT1;
   case PIPE_FORMAT_DXT3_RGBA:
      return SVGA3D_DXT3;
   case PIPE_FORMAT_DXT5_RGBA:
      return SVGA3D_DXT5;

   default:
      return SVGA3D_FORMAT_INVALID;
   }
}


SVGA3dSurfaceFormat
svga_translate_format_render(enum pipe_format format)
{
   switch(format) { 
   case PIPE_FORMAT_B8G8R8A8_UNORM:
   case PIPE_FORMAT_B8G8R8X8_UNORM:
   case PIPE_FORMAT_B5G5R5A1_UNORM:
   case PIPE_FORMAT_B4G4R4A4_UNORM:
   case PIPE_FORMAT_B5G6R5_UNORM:
   case PIPE_FORMAT_S8_USCALED_Z24_UNORM:
   case PIPE_FORMAT_X8Z24_UNORM:
   case PIPE_FORMAT_Z32_UNORM:
   case PIPE_FORMAT_Z16_UNORM:
   case PIPE_FORMAT_L8_UNORM:
      return svga_translate_format(format);

   default:
      return SVGA3D_FORMAT_INVALID;
   }
}


d137 1
a137 1
      unsigned y, h, srcy;
a199 3



d221 1
a221 1
   struct svga_texture *tex = (struct svga_texture *)pt;
d233 2
a238 5





d242 2
a243 2
static struct pipe_transfer *
svga_texture_get_transfer(struct pipe_context *pipe,
d247 2
a248 1
                          const struct pipe_box *box)
a260 1
   assert(box->depth == 1);
d265 1
a265 1
   pipe_resource_reference(&st->base.resource, texture);
d270 1
a270 1
   st->base.layer_stride = 0;
d277 1
a277 1
                                         st->hw_nblocksy*st->base.stride);
d282 1
a282 1
                                            st->hw_nblocksy*st->base.stride);
d311 13
a323 1
   return &st->base;
d325 2
a337 20
static void *
svga_texture_transfer_map( struct pipe_context *pipe,
			   struct pipe_transfer *transfer )
{
   struct svga_screen *ss = svga_screen(pipe->screen);
   struct svga_winsys_screen *sws = ss->sws;
   struct svga_transfer *st = svga_transfer(transfer);

   if(st->swbuf)
      return st->swbuf;
   else
      /* The wait for read transfers already happened when svga_transfer_dma
       * was called. */
      return sws->buffer_map(sws, st->hwbuf, transfer->usage);
}


/* XXX: Still implementing this as if it was a screen function, but
 * can now modify it to queue transfers on the context.
 */
d342 1
d346 2
a347 1
   
a349 12
}


static void
svga_texture_transfer_destroy(struct pipe_context *pipe,
			      struct pipe_transfer *transfer)
{
   struct svga_context *svga = svga_context(pipe);
   struct svga_texture *tex = svga_texture(transfer->resource);
   struct svga_screen *ss = svga_screen(pipe->screen);
   struct svga_winsys_screen *sws = ss->sws;
   struct svga_transfer *st = svga_transfer(transfer);
d364 1
a364 1
      tex->view_age[transfer->level] = ++(tex->age);
d366 1
a366 1
         tex->defined[transfer->box.z][transfer->level] = TRUE;
d368 1
a368 1
         tex->defined[0][transfer->level] = TRUE;
a370 1
   pipe_resource_reference(&st->base.resource, NULL);
a376 3



a380 2
   svga_texture_get_transfer,	      /* get_transfer */
   svga_texture_transfer_destroy,     /* transfer_destroy */
a387 2


d420 5
a424 2
   /* XXX: Disabled for now */
   tex->key.cachable = 0;
d437 2
a438 1
   if (template->bind & PIPE_BIND_SCANOUT) {
d442 1
a442 1
   
d444 2
a445 1
    * XXX: Never pass the SVGA3D_SURFACE_HINT_RENDERTARGET hint. Mesa cannot
d449 4
a453 1
#if 0
a456 1
#endif
d463 1
a463 1
   tex->key.format = svga_translate_format(template->format);
d475 3
a486 2


d511 2
a512 2
   if (svga_translate_format(template->format) != format) {
      unsigned f1 = svga_translate_format(template->format);
d518 2
a519 1
              (f1 == SVGA3D_Z_D24X8 && f2 == SVGA3D_Z_D24S8) ) ) {
a533 8
   if (format == SVGA3D_X8R8G8B8)
      tex->b.b.format = PIPE_FORMAT_B8G8R8X8_UNORM;
   else if (format == SVGA3D_A8R8G8B8)
      tex->b.b.format = PIPE_FORMAT_B8G8R8A8_UNORM;
   else {
      /* ?? */
   }

a540 1

@


1.1
log
@Initial revision
@
text
@a50 25
static unsigned int
svga_texture_is_referenced( struct pipe_context *pipe,
                            struct pipe_resource *texture,
                            unsigned level, int layer)
{
   struct svga_texture *tex = svga_texture(texture);
   struct svga_screen *ss = svga_screen(pipe->screen);

   /**
    * The screen does not cache texture writes.
    */

   if (!tex->handle || ss->sws->surface_is_flushed(ss->sws, tex->handle))
      return PIPE_UNREFERENCED;

   /**
    * sws->surface_is_flushed() does not distinguish between read references
    * and write references. So assume a reference is both.
    */

   return PIPE_REFERENCED_FOR_READ | PIPE_REFERENCED_FOR_WRITE;
}



a123 10
#if 1
   /* For on host conversion */
   case PIPE_FORMAT_DXT1_RGB:
      return SVGA3D_X8R8G8B8;
   case PIPE_FORMAT_DXT1_RGBA:
   case PIPE_FORMAT_DXT3_RGBA:
   case PIPE_FORMAT_DXT5_RGBA:
      return SVGA3D_A8R8G8B8;
#endif

d134 2
a135 1
                       unsigned y, unsigned h, unsigned srcy)
d171 1
a171 1
   ret = SVGA3D_SurfaceDMA(svga->swc, st, transfer, &box, 1);
d173 2
a174 2
      svga->swc->flush(svga->swc, NULL);
      ret = SVGA3D_SurfaceDMA(svga->swc, st, transfer, &box, 1);
d183 2
a184 1
                  SVGA3dTransferType transfer)
d195 4
d203 3
a205 1
      svga_transfer_dma_band(svga, st, transfer, st->base.box.y, st->base.box.height, 0);
d234 3
a236 1
         if(transfer == SVGA3D_WRITE_HOST_VRAM) {
d239 3
a241 4
            if(y) {
               svga_context_flush(svga, &fence);
               sws->fence_finish(sws, fence, 0);
               sws->fence_reference(sws, &fence, NULL);
d244 1
a244 1
            hw = sws->buffer_map(sws, st->hwbuf, PIPE_TRANSFER_WRITE);
d246 1
a246 1
            if(hw) {
d252 8
a259 1
         svga_transfer_dma_band(svga, st, transfer, y, h, srcy);
d374 9
a382 5
      debug_printf("%s: failed to allocate %u KB of DMA, splitting into %u x %u KB DMA transfers\n",
                   __FUNCTION__,
                   (nblocksy*st->base.stride + 1023)/1024,
                   (nblocksy + st->hw_nblocksy - 1)/st->hw_nblocksy,
                   (st->hw_nblocksy*st->base.stride + 1023)/1024);
d388 5
a392 2
   if (usage & PIPE_TRANSFER_READ)
      svga_transfer_dma(svga, st, SVGA3D_READ_HOST_VRAM);
d451 11
a461 1
      svga_transfer_dma(svga, st, SVGA3D_WRITE_HOST_VRAM);
a483 1
   svga_texture_is_referenced,	      /* is_resource_referenced */
d527 2
a528 1
   tex->key.cachable = 1;
d571 3
@


1.1.1.1
log
@Import Mesa 7.10.3
@
text
@@


1.1.1.2
log
@Import Mesa 9.2.0
@
text
@a34 1
#include "util/u_resource.h"
a35 1
#include "svga_format.h"
d51 114
d169 1
a169 2
                       unsigned y, unsigned h, unsigned srcy,
                       SVGA3dSurfaceDMAFlags flags)
d205 1
a205 1
   ret = SVGA3D_SurfaceDMA(svga->swc, st, transfer, &box, 1, flags);
d207 2
a208 2
      svga_context_flush(svga, NULL);
      ret = SVGA3D_SurfaceDMA(svga->swc, st, transfer, &box, 1, flags);
d217 1
a217 2
                  SVGA3dTransferType transfer,
                  SVGA3dSurfaceDMAFlags flags)
a227 4
   /* Ensure any pending operations on host surfaces are queued on the command
    * buffer first.
    */
   svga_surfaces_flush( svga );
d232 1
a232 3
      svga_transfer_dma_band(svga, st, transfer,
                             st->base.box.y, st->base.box.height, 0,
                             flags);
d241 1
a241 1
      int y, h, srcy;
d261 1
a261 3
         if (transfer == SVGA3D_WRITE_HOST_VRAM) {
            unsigned usage = PIPE_TRANSFER_WRITE;

d264 4
a267 3
            if (y) {
               svga_context_flush(svga, NULL);
               usage |= PIPE_TRANSFER_DISCARD_WHOLE_RESOURCE;
d270 1
a270 1
            hw = sws->buffer_map(sws, st->hwbuf, usage);
d272 1
a272 1
            if (hw) {
d278 1
a278 8
         svga_transfer_dma_band(svga, st, transfer, y, h, srcy, flags);

         /*
          * Prevent the texture contents to be discarded on the next band
          * upload.
          */

         flags.discard = FALSE;
d296 3
d320 1
a320 1
   struct svga_texture *tex = svga_texture(pt);
a331 2
   ss->total_resource_bytes -= tex->size;

d336 5
d344 2
a345 2
static void *
svga_texture_transfer_map(struct pipe_context *pipe,
d349 1
a349 2
                          const struct pipe_box *box,
                          struct pipe_transfer **ptransfer)
d362 1
d367 1
a367 1
   st->base.resource = texture;
d372 1
a372 1
   st->base.layer_stride = st->base.stride * nblocksy;
d379 1
a379 1
                                         st->hw_nblocksy * st->base.stride * box->depth);
d384 1
a384 1
                                            st->hw_nblocksy * st->base.stride * box->depth);
d393 5
a397 9
      if (0) {
         debug_printf("%s: failed to allocate %u KB of DMA, "
                      "splitting into %u x %u KB DMA transfers\n",
                      __FUNCTION__,
                      (nblocksy*st->base.stride + 1023)/1024,
                      (nblocksy + st->hw_nblocksy - 1)/st->hw_nblocksy,
                      (st->hw_nblocksy*st->base.stride + 1023)/1024);
      }

d403 2
a404 15
   if (usage & PIPE_TRANSFER_READ) {
      SVGA3dSurfaceDMAFlags flags;
      memset(&flags, 0, sizeof flags);
      svga_transfer_dma(svga, st, SVGA3D_READ_HOST_VRAM, flags);
   }

   if (st->swbuf) {
      *ptransfer = &st->base;
      return st->swbuf;
   } else {
      /* The wait for read transfers already happened when svga_transfer_dma
       * was called. */
      void *map = sws->buffer_map(sws, st->hwbuf, usage);
      if (!map)
         goto fail;
d406 1
a406 3
      *ptransfer = &st->base;
      return map;
   }
a407 2
fail:
   FREE(st->swbuf);
d419 20
a442 1
   struct svga_context *svga = svga_context(pipe);
d446 1
a446 2
   struct svga_texture *tex = svga_texture(transfer->resource);

d449 1
a450 2
   if (st->base.usage & PIPE_TRANSFER_WRITE) {
      SVGA3dSurfaceDMAFlags flags;
d452 9
a460 7
      memset(&flags, 0, sizeof flags);
      if (transfer->usage & PIPE_TRANSFER_DISCARD_WHOLE_RESOURCE) {
         flags.discard = TRUE;
      }
      if (transfer->usage & PIPE_TRANSFER_UNSYNCHRONIZED) {
         flags.unsynchronized = TRUE;
      }
d462 2
a463 1
      svga_transfer_dma(svga, st, SVGA3D_WRITE_HOST_VRAM, flags);
d465 1
a465 1
      svga_age_texture_view(tex, transfer->level);
d467 1
a467 1
         svga_define_texture_level(tex, transfer->box.z, transfer->level);
d469 1
a469 1
         svga_define_texture_level(tex, 0, transfer->level);
d472 1
d479 3
d486 3
d496 2
a529 4
   if (template->target == PIPE_TEXTURE_3D) {
      tex->key.flags |= SVGA3D_SURFACE_HINT_VOLUME;
   }

d543 1
a543 2
   if (template->bind & (PIPE_BIND_SCANOUT |
                         PIPE_BIND_CURSOR)) {
d547 1
a547 1

d549 1
a549 2
    * Note: Previously we never passed the
    * SVGA3D_SURFACE_HINT_RENDERTARGET hint. Mesa cannot
a552 4
    *
    * However, this was changed since other state trackers
    * (XA for example) uses it accurately and certain device versions
    * relies on it in certain situations to render correctly.
d554 1
d558 1
d565 1
a565 1
   tex->key.format = svga_translate_format(svgascreen, template->format, template->bind);
a573 6
   debug_reference(&tex->b.b.reference,
                   (debug_reference_descriptor)debug_describe_resource, 0);

   tex->size = util_resource_size(template);
   svgascreen->total_resource_bytes += tex->size;

d583 2
d609 2
a610 2
   if (svga_translate_format(svga_screen(screen), template->format, template->bind) != format) {
      unsigned f1 = svga_translate_format(svga_screen(screen), template->format, template->bind);
d616 1
a616 2
              (f1 == SVGA3D_Z_D24X8 && f2 == SVGA3D_Z_D24S8) ||
              (f1 == SVGA3D_Z_DF24 && f2 == SVGA3D_Z_D24S8_INT) ) ) {
d631 8
d646 1
@


1.1.1.3
log
@Import Mesa 10.2.3
@
text
@d26 1
a26 2
#include "svga3d_reg.h"
#include "svga3d_surfacedefs.h"
d30 1
a32 1
#include "util/u_inlines.h"
a36 1
#include "svga_cmd.h"
a63 2
   assert(!st->use_direct_map);

a113 2
   assert(!st->use_direct_map);

a234 1
   FREE(tex->rendered_to);
a238 32
/**
 * Determine if we need to read back a texture image before mapping it.
 */
static boolean
need_tex_readback(struct pipe_transfer *transfer)
{
   struct svga_texture *t = svga_texture(transfer->resource);

   if (transfer->usage & PIPE_TRANSFER_READ)
      return TRUE;

   if ((transfer->usage & PIPE_TRANSFER_WRITE) &&
       ((transfer->usage & PIPE_TRANSFER_DISCARD_WHOLE_RESOURCE) == 0)) {
      unsigned face;

      if (transfer->resource->target == PIPE_TEXTURE_CUBE) {
         assert(transfer->box.depth == 1);
         face = transfer->box.z;
      }
      else {
         face = 0;
      }
      if (svga_was_texture_rendered_to(t, face, transfer->level)) {
         return TRUE;
      }
   }

   return FALSE;
}



d254 6
a259 12
   unsigned nblocksx, nblocksy;
   boolean use_direct_map = svga_have_gb_objects(svga) &&
      !svga_have_gb_dma(svga);
   unsigned d;

   /* We can't map texture storage directly unless we have GB objects */
   if (usage & PIPE_TRANSFER_MAP_DIRECTLY) {
      if (svga_have_gb_objects(svga))
         use_direct_map = TRUE;
      else
         return NULL;
   }
d265 1
a265 19
   {
      unsigned w, h;
      if (use_direct_map) {
         /* we'll directly access the guest-backed surface */
         w = u_minify(texture->width0, level);
         h = u_minify(texture->height0, level);
         d = u_minify(texture->depth0, level);
      }
      else {
         /* we'll put the data into a tightly packed buffer */
         w = box->width;
         h = box->height;
         d = box->depth;
      }
      nblocksx = util_format_get_nblocksx(texture->format, w);
      nblocksy = util_format_get_nblocksy(texture->format, h);
   }

   pipe_resource_reference(&st->base.resource, texture);
d272 1
a272 3
   if (!use_direct_map) {
      /* Use a DMA buffer */
      st->hw_nblocksy = nblocksy;
d274 5
d282 2
a283 7
                                            st->hw_nblocksy * st->base.stride * d);
      while(!st->hwbuf && (st->hw_nblocksy /= 2)) {
         st->hwbuf = svga_winsys_buffer_create(svga,
                                               1, 
                                               0,
                                               st->hw_nblocksy * st->base.stride * d);
      }
d285 2
a286 4
      if (!st->hwbuf) {
         FREE(st);
         return NULL;
      }
d288 10
a297 18
      if(st->hw_nblocksy < nblocksy) {
         /* We couldn't allocate a hardware buffer big enough for the transfer, 
          * so allocate regular malloc memory instead */
         if (0) {
            debug_printf("%s: failed to allocate %u KB of DMA, "
                         "splitting into %u x %u KB DMA transfers\n",
                         __FUNCTION__,
                         (nblocksy*st->base.stride + 1023)/1024,
                         (nblocksy + st->hw_nblocksy - 1)/st->hw_nblocksy,
                         (st->hw_nblocksy*st->base.stride + 1023)/1024);
         }

         st->swbuf = MALLOC(nblocksy * st->base.stride * d);
         if (!st->swbuf) {
            sws->buffer_destroy(sws, st->hwbuf);
            FREE(st);
            return NULL;
         }
d300 4
a303 18
      if (usage & PIPE_TRANSFER_READ) {
         SVGA3dSurfaceDMAFlags flags;
         memset(&flags, 0, sizeof flags);
         svga_transfer_dma(svga, st, SVGA3D_READ_HOST_VRAM, flags);
      }
   } else {
      struct pipe_transfer *transfer = &st->base;
      struct svga_texture *tex = svga_texture(transfer->resource);
      struct svga_winsys_surface *surf = tex->handle;
      unsigned face;

      assert(surf);

      if (tex->b.b.target == PIPE_TEXTURE_CUBE) {
	 face = transfer->box.z;
      } else {
	 face = 0;
      }
d305 4
a308 44
      if (need_tex_readback(transfer)) {
	 SVGA3dBox box;
	 enum pipe_error ret;

	 box.x = transfer->box.x;
	 box.y = transfer->box.y;
	 box.w = transfer->box.width;
	 box.h = transfer->box.height;
	 box.d = transfer->box.depth;
	 if (tex->b.b.target == PIPE_TEXTURE_CUBE) {
	    box.z = 0;
	 }
	 else {
	    box.z = transfer->box.z;
	 }

         (void) box;  /* not used at this time */

         svga_surfaces_flush(svga);

	 ret = SVGA3D_ReadbackGBImage(svga->swc, surf, face, transfer->level);

	 if (ret != PIPE_OK) {
	    svga_context_flush(svga, NULL);
	    ret = SVGA3D_ReadbackGBImage(svga->swc, surf, face, transfer->level);
	    assert(ret == PIPE_OK);
	 }

	 svga_context_flush(svga, NULL);

         /*
          * Note: if PIPE_TRANSFER_DISCARD_WHOLE_RESOURCE were specified
          * we could potentially clear the flag for all faces/layers/mips.
          */
         svga_clear_texture_rendered_to(tex, face, transfer->level);
      }
      else {
	 assert(transfer->usage & PIPE_TRANSFER_WRITE);
	 if ((transfer->usage & PIPE_TRANSFER_UNSYNCHRONIZED) == 0) {
            svga_surfaces_flush(svga);
            if (!sws->surface_is_flushed(sws, surf))
               svga_context_flush(svga, NULL);
	 }
      }
a310 7
   st->use_direct_map = use_direct_map;

   *ptransfer = &st->base;

   /*
    * Begin mapping code
    */
d312 1
d314 6
a319 34
   }
   else if (!st->use_direct_map) {
      return sws->buffer_map(sws, st->hwbuf, usage);
   }
   else {
      struct svga_screen *screen = svga_screen(svga->pipe.screen);
      SVGA3dSurfaceFormat format;
      SVGA3dSize baseLevelSize;
      struct svga_texture *tex = svga_texture(texture);
      struct svga_winsys_surface *surf = tex->handle;
      uint8_t *map;
      boolean retry;
      unsigned face, offset, mip_width, mip_height;
      unsigned xoffset = box->x;
      unsigned yoffset = box->y;
      unsigned zoffset = box->z;

      map = svga->swc->surface_map(svga->swc, surf, usage, &retry);
      if (map == NULL && retry) {
         /*
          * At this point, the svga_surfaces_flush() should already have
          * called in svga_texture_get_transfer().
          */
         svga_context_flush(svga, NULL);
         map = svga->swc->surface_map(svga->swc, surf, usage, &retry);
      }

      /*
       * Make sure whe return NULL if the map fails
       */
      if (map == NULL) {
         FREE(st);
         return map;
      }
d321 2
a322 29
      /**
       * Compute the offset to the specific texture slice in the buffer.
       */
      if (tex->b.b.target == PIPE_TEXTURE_CUBE) {
         face = zoffset;
         zoffset = 0;
      } else {
         face = 0;
      }

      format = svga_translate_format(screen, tex->b.b.format, 0);
      baseLevelSize.width = tex->b.b.width0;
      baseLevelSize.height = tex->b.b.height0;
      baseLevelSize.depth = tex->b.b.depth0;

      offset = svga3dsurface_get_image_offset(format, baseLevelSize,
                                              tex->b.b.last_level + 1, /* numMips */
                                              face, level);
      if (level > 0) {
         assert(offset > 0);
      }

      mip_width = u_minify(tex->b.b.width0, level);
      mip_height = u_minify(tex->b.b.height0, level);

      offset += svga3dsurface_get_pixel_offset(format, mip_width, mip_height,
                                               xoffset, yoffset, zoffset);

      return (void *) (map + offset);
a323 1
}
d325 7
a331 25

/**
 * Unmap a GB texture surface.
 */
static void
svga_texture_surface_unmap(struct svga_context *svga,
                           struct pipe_transfer *transfer)
{
   struct svga_winsys_surface *surf = svga_texture(transfer->resource)->handle;
   struct svga_winsys_context *swc = svga->swc;
   boolean rebind;

   assert(surf);

   swc->surface_unmap(swc, surf, &rebind);
   if (rebind) {
      enum pipe_error ret;
      ret = SVGA3D_BindGBSurface(swc, surf);
      if (ret != PIPE_OK) {
         /* flush and retry */
         svga_context_flush(svga, NULL);
         ret = SVGA3D_BindGBSurface(swc, surf);
         assert(ret == PIPE_OK);
      }
   }
d348 2
a349 8
   if (!st->swbuf) {
      if (st->use_direct_map) {
         svga_texture_surface_unmap(svga, transfer);
      }
      else {
         sws->buffer_unmap(sws, st->hwbuf);
      }
   }
d351 1
a351 2
   if (!st->use_direct_map && (st->base.usage & PIPE_TRANSFER_WRITE)) {
      /* Use DMA to transfer texture data */
d363 6
a368 40
   } else if (transfer->usage & PIPE_TRANSFER_WRITE) {
      struct svga_winsys_surface *surf =
	 svga_texture(transfer->resource)->handle;
      unsigned face;
      SVGA3dBox box;
      enum pipe_error ret;

      assert(svga_have_gb_objects(svga));

      /* update the effected region */
      if (tex->b.b.target == PIPE_TEXTURE_CUBE) {
	 face = transfer->box.z;
      } else {
	 face = 0;
      }

      box.x = transfer->box.x;
      box.y = transfer->box.y;
      if (tex->b.b.target == PIPE_TEXTURE_CUBE) {
         box.z = 0;
      }
      else {
         box.z = transfer->box.z;
      }
      box.w = transfer->box.width;
      box.h = transfer->box.height;
      box.d = transfer->box.depth;

      if (0)
         debug_printf("%s %d, %d, %d  %d x %d x %d\n",
                      __FUNCTION__,
                      box.x, box.y, box.z,
                      box.w, box.h, box.d);

      ret = SVGA3D_UpdateGBImage(svga->swc, surf, &box, face, transfer->level);
      if (ret != PIPE_OK) {
         svga_context_flush(svga, NULL);
         ret = SVGA3D_UpdateGBImage(svga->swc, surf, &box, face, transfer->level);
         assert(ret == PIPE_OK);
      }
a370 9
   ss->texture_timestamp++;
   svga_age_texture_view(tex, transfer->level);
   if (transfer->resource->target == PIPE_TEXTURE_CUBE)
      svga_define_texture_level(tex, transfer->box.z, transfer->level);
   else
      svga_define_texture_level(tex, 0, transfer->level);

   pipe_resource_reference(&st->base.resource, NULL);

d372 1
a372 3
   if (!st->use_direct_map) {
      sws->buffer_destroy(sws, st->hwbuf);
   }
d421 1
a421 1
      tex->key.flags |= SVGA3D_SURFACE_VOLUME;
a477 5
   tex->rendered_to = CALLOC(template->depth0 * template->array_size,
                             sizeof(tex->rendered_to[0]));
   if (!tex->rendered_to)
      goto error2;

a480 1
   FREE(tex->rendered_to);
a537 2

   tex->rendered_to = CALLOC(1, sizeof(tex->rendered_to[0]));
@


1.1.1.4
log
@Import Mesa 10.4.3
@
text
@d55 1
a55 1
static void
d107 1
a107 1
static void
d730 2
a731 4
   if (!tex->handle)
       goto error2;

   SVGA_DBG(DEBUG_DMA, "  --> got sid %p (texture)\n", tex->handle);
@


1.1.1.5
log
@Import Mesa 10.2.9
@
text
@d55 1
a55 1
static INLINE void
d107 1
a107 1
static INLINE void
d730 4
a733 2
   if (tex->handle)
      SVGA_DBG(DEBUG_DMA, "  --> got sid %p (texture)\n", tex->handle);
@


