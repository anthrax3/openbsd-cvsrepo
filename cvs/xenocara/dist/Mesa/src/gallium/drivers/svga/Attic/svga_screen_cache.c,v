head	1.6;
access;
symbols
	OPENBSD_5_8:1.5.0.4
	OPENBSD_5_8_BASE:1.5
	OPENBSD_5_7:1.5.0.2
	OPENBSD_5_7_BASE:1.5
	v10_2_9:1.1.1.5
	v10_4_3:1.1.1.4
	v10_2_7:1.1.1.3
	OPENBSD_5_6:1.3.0.2
	OPENBSD_5_6_BASE:1.3
	v10_2_3:1.1.1.3
	OPENBSD_5_5:1.2.0.2
	OPENBSD_5_5_BASE:1.2
	v9_2_5:1.1.1.2
	v9_2_3:1.1.1.2
	v9_2_2:1.1.1.2
	v9_2_1:1.1.1.2
	v9_2_0:1.1.1.2
	OPENBSD_5_4:1.1.0.14
	OPENBSD_5_4_BASE:1.1
	OPENBSD_5_3:1.1.0.12
	OPENBSD_5_3_BASE:1.1
	OPENBSD_5_2:1.1.0.10
	OPENBSD_5_2_BASE:1.1
	OPENBSD_5_1_BASE:1.1
	OPENBSD_5_1:1.1.0.8
	v7_10_3:1.1.1.1
	mesa:1.1.1
	OPENBSD_5_0:1.1.0.6
	OPENBSD_5_0_BASE:1.1
	OPENBSD_4_9:1.1.0.2
	OPENBSD_4_9_BASE:1.1
	OPENBSD_4_8:1.1.0.4
	OPENBSD_4_8_BASE:1.1;
locks; strict;
comment	@ * @;


1.6
date	2015.12.23.05.17.35;	author jsg;	state dead;
branches;
next	1.5;
commitid	TnlogFl9nOv2eaRf;

1.5
date	2015.02.20.23.09.53;	author jsg;	state Exp;
branches;
next	1.4;
commitid	4ry2gvZGMXkCUD2n;

1.4
date	2015.01.25.14.41.16;	author jsg;	state Exp;
branches;
next	1.3;
commitid	mcxB0JvoI9gTDYXU;

1.3
date	2014.07.09.21.08.55;	author jsg;	state Exp;
branches;
next	1.2;
commitid	WPD6rgPryPkvXOr9;

1.2
date	2013.09.05.14.01.10;	author jsg;	state Exp;
branches;
next	1.1;

1.1
date	2010.05.22.20.06.07;	author matthieu;	state Exp;
branches
	1.1.1.1;
next	;

1.1.1.1
date	2011.10.23.13.29.29;	author matthieu;	state Exp;
branches;
next	1.1.1.2;

1.1.1.2
date	2013.09.05.13.12.59;	author jsg;	state Exp;
branches;
next	1.1.1.3;

1.1.1.3
date	2014.07.09.20.34.16;	author jsg;	state Exp;
branches;
next	1.1.1.4;
commitid	3JhLfwcuBALP0ZR7;

1.1.1.4
date	2015.01.25.14.08.53;	author jsg;	state Exp;
branches;
next	1.1.1.5;
commitid	ce2W5rH5aF7VS9gi;

1.1.1.5
date	2015.02.20.22.46.08;	author jsg;	state Exp;
branches;
next	;
commitid	F54a1i0WXHMxq7kE;


desc
@@


1.6
log
@remove the now unused Mesa 10.2.9 code
@
text
@/**********************************************************
 * Copyright 2008-2009 VMware, Inc.  All rights reserved.
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 *
 **********************************************************/

#include "util/u_math.h"
#include "util/u_memory.h"
#include "util/u_hash.h"

#include "svga_debug.h"
#include "svga_format.h"
#include "svga_winsys.h"
#include "svga_screen.h"
#include "svga_screen_cache.h"


#define SVGA_SURFACE_CACHE_ENABLED 1


/**
 * Return the size of the surface described by the key (in bytes).
 */
static unsigned
surface_size(const struct svga_host_surface_cache_key *key)
{
   unsigned bw, bh, bpb, total_size, i;

   assert(key->numMipLevels > 0);
   assert(key->numFaces > 0);

   if (key->format == SVGA3D_BUFFER) {
      /* Special case: we don't want to count vertex/index buffers
       * against the cache size limit, so view them as zero-sized.
       */
      return 0;
   }

   svga_format_size(key->format, &bw, &bh, &bpb);

   total_size = 0;

   for (i = 0; i < key->numMipLevels; i++) {
      unsigned w = u_minify(key->size.width, i);
      unsigned h = u_minify(key->size.height, i);
      unsigned d = u_minify(key->size.depth, i);
      unsigned img_size = ((w + bw - 1) / bw) * ((h + bh - 1) / bh) * d * bpb;
      total_size += img_size;
   }

   total_size *= key->numFaces;

   return total_size;
}


/**
 * Compute the bucket for this key.
 */
static INLINE unsigned
svga_screen_cache_bucket(const struct svga_host_surface_cache_key *key)
{
   return util_hash_crc32(key, sizeof *key) % SVGA_HOST_SURFACE_CACHE_BUCKETS;
}


/**
 * Search the cache for a surface that matches the key.  If a match is
 * found, remove it from the cache and return the surface pointer.
 * Return NULL otherwise.
 */
static INLINE struct svga_winsys_surface *
svga_screen_cache_lookup(struct svga_screen *svgascreen,
                         const struct svga_host_surface_cache_key *key)
{
   struct svga_host_surface_cache *cache = &svgascreen->cache;
   struct svga_winsys_screen *sws = svgascreen->sws;
   struct svga_host_surface_cache_entry *entry;
   struct svga_winsys_surface *handle = NULL;
   struct list_head *curr, *next;
   unsigned bucket;
   unsigned tries = 0;

   assert(key->cachable);

   bucket = svga_screen_cache_bucket(key);

   pipe_mutex_lock(cache->mutex);

   curr = cache->bucket[bucket].next;
   next = curr->next;
   while (curr != &cache->bucket[bucket]) {
      ++tries;

      entry = LIST_ENTRY(struct svga_host_surface_cache_entry, curr, bucket_head);

      assert(entry->handle);

      if (memcmp(&entry->key, key, sizeof *key) == 0 &&
         sws->fence_signalled(sws, entry->fence, 0) == 0) {
         unsigned surf_size;

         assert(sws->surface_is_flushed(sws, entry->handle));

         handle = entry->handle; /* Reference is transfered here. */
         entry->handle = NULL;

         LIST_DEL(&entry->bucket_head);

         LIST_DEL(&entry->head);

         LIST_ADD(&entry->head, &cache->empty);

         /* update the cache size */
         surf_size = surface_size(&entry->key);
         assert(surf_size <= cache->total_size);
         if (surf_size > cache->total_size)
            cache->total_size = 0; /* should never happen, but be safe */
         else
            cache->total_size -= surf_size;

         break;
      }

      curr = next;
      next = curr->next;
   }

   pipe_mutex_unlock(cache->mutex);

   if (SVGA_DEBUG & DEBUG_DMA)
      debug_printf("%s: cache %s after %u tries (bucket %d)\n", __FUNCTION__,
                   handle ? "hit" : "miss", tries, bucket);

   return handle;
}


/**
 * Free the least recently used entries in the surface cache until the
 * cache size is <= the target size OR there are no unused entries left
 * to discard.  We don't do any flushing to try to free up additional
 * surfaces.
 */
static void
svga_screen_cache_shrink(struct svga_screen *svgascreen,
                         unsigned target_size)
{
   struct svga_host_surface_cache *cache = &svgascreen->cache;
   struct svga_winsys_screen *sws = svgascreen->sws;
   struct svga_host_surface_cache_entry *entry = NULL, *next_entry;

   /* Walk over the list of unused buffers in reverse order: from oldest
    * to newest.
    */
   LIST_FOR_EACH_ENTRY_SAFE_REV(entry, next_entry, &cache->unused, head) {
      if (entry->key.format != SVGA3D_BUFFER) {
         /* we don't want to discard vertex/index buffers */

         cache->total_size -= surface_size(&entry->key);

         assert(entry->handle);
         sws->surface_reference(sws, &entry->handle, NULL);

         LIST_DEL(&entry->bucket_head);
         LIST_DEL(&entry->head);
         LIST_ADD(&entry->head, &cache->empty);

         if (cache->total_size <= target_size) {
            /* all done */
            break;
         }
      }
   }
}


/**
 * Transfers a handle reference.
 */
static INLINE void
svga_screen_cache_add(struct svga_screen *svgascreen,
                      const struct svga_host_surface_cache_key *key,
                      struct svga_winsys_surface **p_handle)
{
   struct svga_host_surface_cache *cache = &svgascreen->cache;
   struct svga_winsys_screen *sws = svgascreen->sws;
   struct svga_host_surface_cache_entry *entry = NULL;
   struct svga_winsys_surface *handle = *p_handle;
   unsigned surf_size;
   
   assert(key->cachable);

   if (!handle)
      return;
   
   surf_size = surface_size(key);

   *p_handle = NULL;
   pipe_mutex_lock(cache->mutex);
   
   if (surf_size >= SVGA_HOST_SURFACE_CACHE_BYTES) {
      /* this surface is too large to cache, just free it */
      sws->surface_reference(sws, &handle, NULL);
      pipe_mutex_unlock(cache->mutex);
      return;
   }

   if (cache->total_size + surf_size > SVGA_HOST_SURFACE_CACHE_BYTES) {
      /* Adding this surface would exceed the cache size.
       * Try to discard least recently used entries until we hit the
       * new target cache size.
       */
      unsigned target_size = SVGA_HOST_SURFACE_CACHE_BYTES - surf_size;

      svga_screen_cache_shrink(svgascreen, target_size);

      if (cache->total_size > target_size) {
         /* we weren't able to shrink the cache as much as we wanted so
          * just discard this surface.
          */
         sws->surface_reference(sws, &handle, NULL);
         pipe_mutex_unlock(cache->mutex);
         return;
      }
   }

   if (!LIST_IS_EMPTY(&cache->empty)) {
      /* use the first empty entry */
      entry = LIST_ENTRY(struct svga_host_surface_cache_entry,
                         cache->empty.next, head);

      LIST_DEL(&entry->head);
   }
   else if (!LIST_IS_EMPTY(&cache->unused)) {
      /* free the last used buffer and reuse its entry */
      entry = LIST_ENTRY(struct svga_host_surface_cache_entry,
                         cache->unused.prev, head);
      SVGA_DBG(DEBUG_CACHE|DEBUG_DMA,
               "unref sid %p (make space)\n", entry->handle);

      cache->total_size -= surface_size(&entry->key);

      sws->surface_reference(sws, &entry->handle, NULL);

      LIST_DEL(&entry->bucket_head);

      LIST_DEL(&entry->head);
   }

   if (entry) {
      entry->handle = handle;
      memcpy(&entry->key, key, sizeof entry->key);

      SVGA_DBG(DEBUG_CACHE|DEBUG_DMA,
               "cache sid %p\n", entry->handle);
      LIST_ADD(&entry->head, &cache->validated);

      cache->total_size += surf_size;
   }
   else {
      /* Couldn't cache the buffer -- this really shouldn't happen */
      SVGA_DBG(DEBUG_CACHE|DEBUG_DMA,
               "unref sid %p (couldn't find space)\n", handle);
      sws->surface_reference(sws, &handle, NULL);
   }

   pipe_mutex_unlock(cache->mutex);
}


/**
 * Called during the screen flush to move all buffers not in a validate list
 * into the unused list.
 */
void
svga_screen_cache_flush(struct svga_screen *svgascreen,
                        struct pipe_fence_handle *fence)
{
   struct svga_host_surface_cache *cache = &svgascreen->cache;
   struct svga_winsys_screen *sws = svgascreen->sws;
   struct svga_host_surface_cache_entry *entry;
   struct list_head *curr, *next;
   unsigned bucket;

   pipe_mutex_lock(cache->mutex);

   curr = cache->validated.next;
   next = curr->next;
   while (curr != &cache->validated) {
      entry = LIST_ENTRY(struct svga_host_surface_cache_entry, curr, head);

      assert(entry->handle);

      if (sws->surface_is_flushed(sws, entry->handle)) {
         LIST_DEL(&entry->head);

         svgascreen->sws->fence_reference(svgascreen->sws, &entry->fence, fence);

         LIST_ADD(&entry->head, &cache->unused);

         bucket = svga_screen_cache_bucket(&entry->key);
         LIST_ADD(&entry->bucket_head, &cache->bucket[bucket]);
      }

      curr = next;
      next = curr->next;
   }

   pipe_mutex_unlock(cache->mutex);
}


/**
 * Free all the surfaces in the cache.
 * Called when destroying the svga screen object.
 */
void
svga_screen_cache_cleanup(struct svga_screen *svgascreen)
{
   struct svga_host_surface_cache *cache = &svgascreen->cache;
   struct svga_winsys_screen *sws = svgascreen->sws;
   unsigned i;

   for (i = 0; i < SVGA_HOST_SURFACE_CACHE_SIZE; ++i) {
      if (cache->entries[i].handle) {
	 SVGA_DBG(DEBUG_CACHE|DEBUG_DMA,
                  "unref sid %p (shutdown)\n", cache->entries[i].handle);
	 sws->surface_reference(sws, &cache->entries[i].handle, NULL);

         cache->total_size -= surface_size(&cache->entries[i].key);
      }

      if (cache->entries[i].fence)
         svgascreen->sws->fence_reference(svgascreen->sws,
                                          &cache->entries[i].fence, NULL);
   }

   pipe_mutex_destroy(cache->mutex);
}


enum pipe_error
svga_screen_cache_init(struct svga_screen *svgascreen)
{
   struct svga_host_surface_cache *cache = &svgascreen->cache;
   unsigned i;

   assert(cache->total_size == 0);

   pipe_mutex_init(cache->mutex);

   for (i = 0; i < SVGA_HOST_SURFACE_CACHE_BUCKETS; ++i)
      LIST_INITHEAD(&cache->bucket[i]);

   LIST_INITHEAD(&cache->unused);

   LIST_INITHEAD(&cache->validated);

   LIST_INITHEAD(&cache->empty);
   for (i = 0; i < SVGA_HOST_SURFACE_CACHE_SIZE; ++i)
      LIST_ADDTAIL(&cache->entries[i].head, &cache->empty);

   return PIPE_OK;
}


/**
 * Allocate a new host-side surface.  If the surface is marked as cachable,
 * first try re-using a surface in the cache of freed surfaces.  Otherwise,
 * allocate a new surface.
 */
struct svga_winsys_surface *
svga_screen_surface_create(struct svga_screen *svgascreen,
                           struct svga_host_surface_cache_key *key)
{
   struct svga_winsys_screen *sws = svgascreen->sws;
   struct svga_winsys_surface *handle = NULL;
   boolean cachable = SVGA_SURFACE_CACHE_ENABLED && key->cachable;

   SVGA_DBG(DEBUG_CACHE|DEBUG_DMA,
            "%s sz %dx%dx%d mips %d faces %d cachable %d\n",
            __FUNCTION__,
            key->size.width,
            key->size.height,
            key->size.depth,
            key->numMipLevels,
            key->numFaces,
            key->cachable);

   if (cachable) {
      if (key->format == SVGA3D_BUFFER) {
         /* For buffers, round the buffer size up to the nearest power
          * of two to increase the probability of cache hits.  Keep
          * texture surface dimensions unchanged.
          */
         uint32_t size = 1;
         while (size < key->size.width)
            size <<= 1;
         key->size.width = size;
	 /* Since we're reusing buffers we're effectively transforming all
	  * of them into dynamic buffers.
	  *
	  * It would be nice to not cache long lived static buffers. But there
	  * is no way to detect the long lived from short lived ones yet. A
	  * good heuristic would be buffer size.
	  */
	 key->flags &= ~SVGA3D_SURFACE_HINT_STATIC;
	 key->flags |= SVGA3D_SURFACE_HINT_DYNAMIC;
      }

      handle = svga_screen_cache_lookup(svgascreen, key);
      if (handle) {
         if (key->format == SVGA3D_BUFFER)
            SVGA_DBG(DEBUG_CACHE|DEBUG_DMA,
                     "reuse sid %p sz %d (buffer)\n", handle,
                     key->size.width);
         else
            SVGA_DBG(DEBUG_CACHE|DEBUG_DMA,
                     "reuse sid %p sz %dx%dx%d mips %d faces %d\n", handle,
                     key->size.width,
                     key->size.height,
                     key->size.depth,
                     key->numMipLevels,
                     key->numFaces);
      }
   }

   if (!handle) {
      handle = sws->surface_create(sws,
                                   key->flags,
                                   key->format,
                                   key->cachable ?
                                   0 : SVGA_SURFACE_USAGE_SHARED,
                                   key->size,
                                   key->numFaces,
                                   key->numMipLevels);
      if (handle)
         SVGA_DBG(DEBUG_CACHE|DEBUG_DMA,
                  "  CREATE sid %p sz %dx%dx%d\n",
                  handle,
                  key->size.width,
                  key->size.height,
                  key->size.depth);
   }

   return handle;
}


/**
 * Release a surface.  We don't actually free the surface- we put
 * it into the cache of freed surfaces (if it's cachable).
 */
void
svga_screen_surface_destroy(struct svga_screen *svgascreen,
                            const struct svga_host_surface_cache_key *key,
                            struct svga_winsys_surface **p_handle)
{
   struct svga_winsys_screen *sws = svgascreen->sws;

   /* We only set the cachable flag for surfaces of which we are the
    * exclusive owner.  So just hold onto our existing reference in
    * that case.
    */
   if (SVGA_SURFACE_CACHE_ENABLED && key->cachable) {
      svga_screen_cache_add(svgascreen, key, p_handle);
   }
   else {
      SVGA_DBG(DEBUG_DMA,
               "unref sid %p (uncachable)\n", *p_handle);
      sws->surface_reference(sws, p_handle, NULL);
   }
}


/**
 * Print/dump the contents of the screen cache.  For debugging.
 */
void
svga_screen_cache_dump(const struct svga_screen *svgascreen)
{
   const struct svga_host_surface_cache *cache = &svgascreen->cache;
   unsigned bucket;
   unsigned count = 0;

   debug_printf("svga3d surface cache:\n");
   for (bucket = 0; bucket < SVGA_HOST_SURFACE_CACHE_BUCKETS; bucket++) {
      struct list_head *curr;
      curr = cache->bucket[bucket].next;
      while (curr && curr != &cache->bucket[bucket]) {
         struct svga_host_surface_cache_entry *entry =
            LIST_ENTRY(struct svga_host_surface_cache_entry,
                       curr, bucket_head);
         if (entry->key.format != 37) {
            debug_printf("  %u x %u x %u format %u\n",
                         entry->key.size.width,
                         entry->key.size.height,
                         entry->key.size.depth,
                         entry->key.format);
         }
         curr = curr->next;
         count++;
      }
   }

   debug_printf("%u surfaces, %u bytes\n", count, cache->total_size);
}
@


1.5
log
@Merge Mesa 10.2.9
@
text
@@


1.4
log
@Merge Mesa 10.4.3
Tested by matthieu@@ mpi@@ and myself.  landry@@ ran a ports bulk build.
kettenis@@ tracked down the cause of an alignment fault on archs
that require strict eight byte pointer alignment.
@
text
@d91 1
a91 1
static struct svga_winsys_surface *
d200 1
a200 1
static void
@


1.3
log
@Merge Mesa 10.2.3
tested by matthieu@@ kettenis@@ mpi@@ brett@@ and myself across a
diverse range of hardware
@
text
@d91 1
a91 1
static INLINE struct svga_winsys_surface *
d200 1
a200 1
static INLINE void
@


1.2
log
@Merge Mesa 9.2.0
@
text
@a212 1
   assert(handle);
d452 2
@


1.1
log
@Update to Mesa 7.8.1. Tested on a bulk ports build by naddy@@, ok oga@@.
@
text
@d26 1
d31 1
d40 38
a77 2
/** 
 * Compute the bucket for this key. 
d82 1
a82 1
   return util_hash_crc32( key, sizeof *key ) % SVGA_HOST_SURFACE_CACHE_BUCKETS;
d86 5
d111 1
a111 1
   while(curr != &cache->bucket[bucket]) {
d113 1
a113 1
      
d117 5
a121 3
      
      if(memcmp(&entry->key, key, sizeof *key) == 0 &&
         sws->fence_signalled( sws, entry->fence, 0 ) == 0) {
d123 2
a124 2
         
         handle = entry->handle; // Reference is transfered here.
d126 1
a126 1
         
d130 1
a130 1
         
d133 8
d144 1
a144 1
      curr = next; 
d149 1
a149 1
   
d151 1
a151 1
      debug_printf("%s: cache %s after %u tries (bucket %d)\n", __FUNCTION__, 
d153 1
a153 1
   
d158 40
a197 1
/*
a199 1
                           
d202 1
a202 1
                      const struct svga_host_surface_cache_key *key, 
d209 1
d214 1
a214 1
   if(!handle)
d217 2
d222 27
a248 1
   if(!LIST_IS_EMPTY(&cache->empty)) {
d250 3
a252 2
      entry = LIST_ENTRY(struct svga_host_surface_cache_entry, cache->empty.next, head);
        
d255 1
a255 1
   else if(!LIST_IS_EMPTY(&cache->unused)) {
d257 2
a258 1
      entry = LIST_ENTRY(struct svga_host_surface_cache_entry, cache->unused.prev, head);
d261 3
d271 1
a271 1
   if(entry) {
d274 1
a274 1
   
d278 2
d287 1
a287 1
   
d310 1
a310 1
   while(curr != &cache->validated) {
d315 1
a315 1
      if(sws->surface_is_flushed(sws, entry->handle)) {
d317 1
a317 1
         
d326 1
a326 1
      curr = next; 
d334 4
d344 3
a346 3
   
   for(i = 0; i < SVGA_HOST_SURFACE_CACHE_SIZE; ++i) {
      if(cache->entries[i].handle) {
d350 2
d354 3
a356 2
      if(cache->entries[i].fence)
         svgascreen->sws->fence_reference(svgascreen->sws, &cache->entries[i].fence, NULL);
d358 1
a358 1
   
d369 2
d372 2
a373 2
   
   for(i = 0; i < SVGA_HOST_SURFACE_CACHE_BUCKETS; ++i)
d377 1
a377 1
   
d379 1
a379 1
   
d381 1
a381 1
   for(i = 0; i < SVGA_HOST_SURFACE_CACHE_SIZE; ++i)
d387 6
a392 1
                           
d402 1
a402 1
            "%s sz %dx%dx%d mips %d faces %d cachable %d\n", 
d418 1
a418 1
         while(size < key->size.width)
d436 1
a436 1
                     "reuse sid %p sz %d (buffer)\n", handle, 
d440 1
a440 1
                     "reuse sid %p sz %dx%dx%d mips %d faces %d\n", handle, 
d453 2
a454 2
                                   key->size, 
                                   key->numFaces, 
d458 2
a459 2
                  "  CREATE sid %p sz %dx%dx%d\n", 
                  handle, 
d469 4
d479 1
a479 1
   
d484 1
a484 1
   if(SVGA_SURFACE_CACHE_ENABLED && key->cachable) {
d492 34
@


1.1.1.1
log
@Import Mesa 7.10.3
@
text
@@


1.1.1.2
log
@Import Mesa 9.2.0
@
text
@a25 1
#include "util/u_math.h"
a29 1
#include "svga_format.h"
d38 2
a39 38
/**
 * Return the size of the surface described by the key (in bytes).
 */
static unsigned
surface_size(const struct svga_host_surface_cache_key *key)
{
   unsigned bw, bh, bpb, total_size, i;

   assert(key->numMipLevels > 0);
   assert(key->numFaces > 0);

   if (key->format == SVGA3D_BUFFER) {
      /* Special case: we don't want to count vertex/index buffers
       * against the cache size limit, so view them as zero-sized.
       */
      return 0;
   }

   svga_format_size(key->format, &bw, &bh, &bpb);

   total_size = 0;

   for (i = 0; i < key->numMipLevels; i++) {
      unsigned w = u_minify(key->size.width, i);
      unsigned h = u_minify(key->size.height, i);
      unsigned d = u_minify(key->size.depth, i);
      unsigned img_size = ((w + bw - 1) / bw) * ((h + bh - 1) / bh) * d * bpb;
      total_size += img_size;
   }

   total_size *= key->numFaces;

   return total_size;
}


/**
 * Compute the bucket for this key.
d44 1
a44 1
   return util_hash_crc32(key, sizeof *key) % SVGA_HOST_SURFACE_CACHE_BUCKETS;
a47 5
/**
 * Search the cache for a surface that matches the key.  If a match is
 * found, remove it from the cache and return the surface pointer.
 * Return NULL otherwise.
 */
d68 1
a68 1
   while (curr != &cache->bucket[bucket]) {
d70 1
a70 1

d74 3
a76 5

      if (memcmp(&entry->key, key, sizeof *key) == 0 &&
         sws->fence_signalled(sws, entry->fence, 0) == 0) {
         unsigned surf_size;

d78 2
a79 2

         handle = entry->handle; /* Reference is transfered here. */
d81 1
a81 1

d85 1
a85 1

a87 8
         /* update the cache size */
         surf_size = surface_size(&entry->key);
         assert(surf_size <= cache->total_size);
         if (surf_size > cache->total_size)
            cache->total_size = 0; /* should never happen, but be safe */
         else
            cache->total_size -= surf_size;

d91 1
a91 1
      curr = next;
d96 1
a96 1

d98 1
a98 1
      debug_printf("%s: cache %s after %u tries (bucket %d)\n", __FUNCTION__,
d100 1
a100 1

d105 1
a105 40
/**
 * Free the least recently used entries in the surface cache until the
 * cache size is <= the target size OR there are no unused entries left
 * to discard.  We don't do any flushing to try to free up additional
 * surfaces.
 */
static void
svga_screen_cache_shrink(struct svga_screen *svgascreen,
                         unsigned target_size)
{
   struct svga_host_surface_cache *cache = &svgascreen->cache;
   struct svga_winsys_screen *sws = svgascreen->sws;
   struct svga_host_surface_cache_entry *entry = NULL, *next_entry;

   /* Walk over the list of unused buffers in reverse order: from oldest
    * to newest.
    */
   LIST_FOR_EACH_ENTRY_SAFE_REV(entry, next_entry, &cache->unused, head) {
      if (entry->key.format != SVGA3D_BUFFER) {
         /* we don't want to discard vertex/index buffers */

         cache->total_size -= surface_size(&entry->key);

         assert(entry->handle);
         sws->surface_reference(sws, &entry->handle, NULL);

         LIST_DEL(&entry->bucket_head);
         LIST_DEL(&entry->head);
         LIST_ADD(&entry->head, &cache->empty);

         if (cache->total_size <= target_size) {
            /* all done */
            break;
         }
      }
   }
}


/**
d108 1
d111 1
a111 1
                      const struct svga_host_surface_cache_key *key,
a117 1
   unsigned surf_size;
d122 1
a122 1
   if (!handle)
a124 2
   surf_size = surface_size(key);

d128 1
a128 27
   if (surf_size >= SVGA_HOST_SURFACE_CACHE_BYTES) {
      /* this surface is too large to cache, just free it */
      sws->surface_reference(sws, &handle, NULL);
      pipe_mutex_unlock(cache->mutex);
      return;
   }

   if (cache->total_size + surf_size > SVGA_HOST_SURFACE_CACHE_BYTES) {
      /* Adding this surface would exceed the cache size.
       * Try to discard least recently used entries until we hit the
       * new target cache size.
       */
      unsigned target_size = SVGA_HOST_SURFACE_CACHE_BYTES - surf_size;

      svga_screen_cache_shrink(svgascreen, target_size);

      if (cache->total_size > target_size) {
         /* we weren't able to shrink the cache as much as we wanted so
          * just discard this surface.
          */
         sws->surface_reference(sws, &handle, NULL);
         pipe_mutex_unlock(cache->mutex);
         return;
      }
   }

   if (!LIST_IS_EMPTY(&cache->empty)) {
d130 2
a131 3
      entry = LIST_ENTRY(struct svga_host_surface_cache_entry,
                         cache->empty.next, head);

d134 1
a134 1
   else if (!LIST_IS_EMPTY(&cache->unused)) {
d136 1
a136 2
      entry = LIST_ENTRY(struct svga_host_surface_cache_entry,
                         cache->unused.prev, head);
a138 3

      cache->total_size -= surface_size(&entry->key);

d146 1
a146 1
   if (entry) {
d149 1
a149 1

a152 2

      cache->total_size += surf_size;
d160 1
a160 1

d183 1
a183 1
   while (curr != &cache->validated) {
d188 1
a188 1
      if (sws->surface_is_flushed(sws, entry->handle)) {
d190 1
a190 1

d199 1
a199 1
      curr = next;
a206 4
/**
 * Free all the surfaces in the cache.
 * Called when destroying the svga screen object.
 */
d213 3
a215 3

   for (i = 0; i < SVGA_HOST_SURFACE_CACHE_SIZE; ++i) {
      if (cache->entries[i].handle) {
a218 2

         cache->total_size -= surface_size(&cache->entries[i].key);
d221 2
a222 3
      if (cache->entries[i].fence)
         svgascreen->sws->fence_reference(svgascreen->sws,
                                          &cache->entries[i].fence, NULL);
d224 1
a224 1

a234 2
   assert(cache->total_size == 0);

d236 2
a237 2

   for (i = 0; i < SVGA_HOST_SURFACE_CACHE_BUCKETS; ++i)
d241 1
a241 1

d243 1
a243 1

d245 1
a245 1
   for (i = 0; i < SVGA_HOST_SURFACE_CACHE_SIZE; ++i)
d251 1
a251 6

/**
 * Allocate a new host-side surface.  If the surface is marked as cachable,
 * first try re-using a surface in the cache of freed surfaces.  Otherwise,
 * allocate a new surface.
 */
d261 1
a261 1
            "%s sz %dx%dx%d mips %d faces %d cachable %d\n",
d277 1
a277 1
         while (size < key->size.width)
d295 1
a295 1
                     "reuse sid %p sz %d (buffer)\n", handle,
d299 1
a299 1
                     "reuse sid %p sz %dx%dx%d mips %d faces %d\n", handle,
d312 2
a313 2
                                   key->size,
                                   key->numFaces,
d317 2
a318 2
                  "  CREATE sid %p sz %dx%dx%d\n",
                  handle,
a327 4
/**
 * Release a surface.  We don't actually free the surface- we put
 * it into the cache of freed surfaces (if it's cachable).
 */
d334 1
a334 1

d339 1
a339 1
   if (SVGA_SURFACE_CACHE_ENABLED && key->cachable) {
a346 34
}


/**
 * Print/dump the contents of the screen cache.  For debugging.
 */
void
svga_screen_cache_dump(const struct svga_screen *svgascreen)
{
   const struct svga_host_surface_cache *cache = &svgascreen->cache;
   unsigned bucket;
   unsigned count = 0;

   debug_printf("svga3d surface cache:\n");
   for (bucket = 0; bucket < SVGA_HOST_SURFACE_CACHE_BUCKETS; bucket++) {
      struct list_head *curr;
      curr = cache->bucket[bucket].next;
      while (curr && curr != &cache->bucket[bucket]) {
         struct svga_host_surface_cache_entry *entry =
            LIST_ENTRY(struct svga_host_surface_cache_entry,
                       curr, bucket_head);
         if (entry->key.format != 37) {
            debug_printf("  %u x %u x %u format %u\n",
                         entry->key.size.width,
                         entry->key.size.height,
                         entry->key.size.depth,
                         entry->key.format);
         }
         curr = curr->next;
         count++;
      }
   }

   debug_printf("%u surfaces, %u bytes\n", count, cache->total_size);
@


1.1.1.3
log
@Import Mesa 10.2.3
@
text
@d213 1
a452 2
                                   key->cachable ?
                                   0 : SVGA_SURFACE_USAGE_SHARED,
@


1.1.1.4
log
@Import Mesa 10.4.3
@
text
@d91 1
a91 1
static struct svga_winsys_surface *
d200 1
a200 1
static void
@


1.1.1.5
log
@Import Mesa 10.2.9
@
text
@d91 1
a91 1
static INLINE struct svga_winsys_surface *
d200 1
a200 1
static INLINE void
@


