head	1.6;
access;
symbols
	OPENBSD_5_8:1.5.0.4
	OPENBSD_5_8_BASE:1.5
	OPENBSD_5_7:1.5.0.2
	OPENBSD_5_7_BASE:1.5
	v10_2_9:1.1.1.4
	v10_4_3:1.1.1.3
	v10_2_7:1.1.1.2
	OPENBSD_5_6:1.3.0.4
	OPENBSD_5_6_BASE:1.3
	v10_2_3:1.1.1.2
	OPENBSD_5_5:1.3.0.2
	OPENBSD_5_5_BASE:1.3
	v9_2_5:1.1.1.2
	v9_2_3:1.1.1.2
	v9_2_2:1.1.1.2
	v9_2_1:1.1.1.2
	v9_2_0:1.1.1.2
	OPENBSD_5_4:1.2.0.4
	OPENBSD_5_4_BASE:1.2
	OPENBSD_5_3:1.2.0.2
	OPENBSD_5_3_BASE:1.2
	OPENBSD_5_2:1.1.1.1.0.4
	OPENBSD_5_2_BASE:1.1.1.1
	OPENBSD_5_1_BASE:1.1.1.1
	OPENBSD_5_1:1.1.1.1.0.2
	v7_10_3:1.1.1.1
	mesa:1.1.1;
locks; strict;
comment	@ * @;


1.6
date	2015.12.23.05.17.32;	author jsg;	state dead;
branches;
next	1.5;
commitid	TnlogFl9nOv2eaRf;

1.5
date	2015.02.20.23.09.52;	author jsg;	state Exp;
branches;
next	1.4;
commitid	4ry2gvZGMXkCUD2n;

1.4
date	2015.01.25.14.41.16;	author jsg;	state Exp;
branches;
next	1.3;
commitid	mcxB0JvoI9gTDYXU;

1.3
date	2013.09.05.14.00.58;	author jsg;	state Exp;
branches;
next	1.2;

1.2
date	2012.08.17.13.58.06;	author mpi;	state Exp;
branches;
next	1.1;

1.1
date	2011.10.23.13.29.28;	author matthieu;	state Exp;
branches
	1.1.1.1;
next	;

1.1.1.1
date	2011.10.23.13.29.28;	author matthieu;	state Exp;
branches;
next	1.1.1.2;

1.1.1.2
date	2013.09.05.13.12.02;	author jsg;	state Exp;
branches;
next	1.1.1.3;

1.1.1.3
date	2015.01.25.14.08.04;	author jsg;	state Exp;
branches;
next	1.1.1.4;
commitid	ce2W5rH5aF7VS9gi;

1.1.1.4
date	2015.02.20.22.45.14;	author jsg;	state Exp;
branches;
next	;
commitid	F54a1i0WXHMxq7kE;


desc
@@


1.6
log
@remove the now unused Mesa 10.2.9 code
@
text
@/*
 * Copyright 2010 Red Hat Inc.
 *
 * Permission is hereby granted, free of charge, to any person obtaining a
 * copy of this software and associated documentation files (the "Software"),
 * to deal in the Software without restriction, including without limitation
 * on the rights to use, copy, modify, merge, publish, distribute, sub
 * license, and/or sell copies of the Software, and to permit persons to whom
 * the Software is furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice (including the next
 * paragraph) shall be included in all copies or substantial portions of the
 * Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL
 * THE AUTHOR(S) AND/OR THEIR SUPPLIERS BE LIABLE FOR ANY CLAIM,
 * DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
 * OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
 * USE OR OTHER DEALINGS IN THE SOFTWARE.
 *
 * Authors: Dave Airlie
 */

#include <stdio.h>

#include "util/u_inlines.h"
#include "util/u_memory.h"
#include "util/u_upload_mgr.h"
#include "util/u_math.h"

#include "r300_screen_buffer.h"

void r300_upload_index_buffer(struct r300_context *r300,
			      struct pipe_resource **index_buffer,
			      unsigned index_size, unsigned *start,
			      unsigned count, const uint8_t *ptr)
{
    unsigned index_offset;

    *index_buffer = NULL;

    u_upload_data(r300->uploader,
                  0, count * index_size,
                  ptr + (*start * index_size),
                  &index_offset,
                  index_buffer);

    *start = index_offset / index_size;
}

static void r300_buffer_destroy(struct pipe_screen *screen,
				struct pipe_resource *buf)
{
    struct r300_resource *rbuf = r300_resource(buf);

    align_free(rbuf->malloced_buffer);

    if (rbuf->buf)
        pb_reference(&rbuf->buf, NULL);

    FREE(rbuf);
}

static void *
r300_buffer_transfer_map( struct pipe_context *context,
                          struct pipe_resource *resource,
                          unsigned level,
                          unsigned usage,
                          const struct pipe_box *box,
                          struct pipe_transfer **ptransfer )
{
    struct r300_context *r300 = r300_context(context);
    struct radeon_winsys *rws = r300->screen->rws;
    struct r300_resource *rbuf = r300_resource(resource);
    struct pipe_transfer *transfer;
    uint8_t *map;

    transfer = util_slab_alloc(&r300->pool_transfers);
    transfer->resource = resource;
    transfer->level = level;
    transfer->usage = usage;
    transfer->box = *box;
    transfer->stride = 0;
    transfer->layer_stride = 0;

    if (rbuf->malloced_buffer) {
        *ptransfer = transfer;
        return rbuf->malloced_buffer + box->x;
    }

    if (usage & PIPE_TRANSFER_DISCARD_WHOLE_RESOURCE &&
        !(usage & PIPE_TRANSFER_UNSYNCHRONIZED)) {
        assert(usage & PIPE_TRANSFER_WRITE);

        /* Check if mapping this buffer would cause waiting for the GPU. */
        if (r300->rws->cs_is_buffer_referenced(r300->cs, rbuf->cs_buf, RADEON_USAGE_READWRITE) ||
            r300->rws->buffer_is_busy(rbuf->buf, RADEON_USAGE_READWRITE)) {
            unsigned i;
            struct pb_buffer *new_buf;

            /* Create a new one in the same pipe_resource. */
            new_buf = r300->rws->buffer_create(r300->rws, rbuf->b.b.width0,
                                               R300_BUFFER_ALIGNMENT, TRUE,
                                               rbuf->domain);
            if (new_buf) {
                /* Discard the old buffer. */
                pb_reference(&rbuf->buf, NULL);
                rbuf->buf = new_buf;
                rbuf->cs_buf = r300->rws->buffer_get_cs_handle(rbuf->buf);

                /* We changed the buffer, now we need to bind it where the old one was bound. */
                for (i = 0; i < r300->nr_vertex_buffers; i++) {
                    if (r300->vertex_buffer[i].buffer == &rbuf->b.b) {
                        r300->vertex_arrays_dirty = TRUE;
                        break;
                    }
                }
            }
        }
    }

    /* Buffers are never used for write, therefore mapping for read can be
     * unsynchronized. */
    if (!(usage & PIPE_TRANSFER_WRITE)) {
       usage |= PIPE_TRANSFER_UNSYNCHRONIZED;
    }

    map = rws->buffer_map(rbuf->cs_buf, r300->cs, usage);

    if (map == NULL) {
        util_slab_free(&r300->pool_transfers, transfer);
        return NULL;
    }

    *ptransfer = transfer;
    return map + box->x;
}

static void r300_buffer_transfer_unmap( struct pipe_context *pipe,
                                        struct pipe_transfer *transfer )
{
    struct r300_context *r300 = r300_context(pipe);

    util_slab_free(&r300->pool_transfers, transfer);
}

static const struct u_resource_vtbl r300_buffer_vtbl =
{
   NULL,                               /* get_handle */
   r300_buffer_destroy,                /* resource_destroy */
   r300_buffer_transfer_map,           /* transfer_map */
   NULL,                               /* transfer_flush_region */
   r300_buffer_transfer_unmap,         /* transfer_unmap */
   NULL   /* transfer_inline_write */
};

struct pipe_resource *r300_buffer_create(struct pipe_screen *screen,
					 const struct pipe_resource *templ)
{
    struct r300_screen *r300screen = r300_screen(screen);
    struct r300_resource *rbuf;

    rbuf = MALLOC_STRUCT(r300_resource);

    rbuf->b.b = *templ;
    rbuf->b.vtbl = &r300_buffer_vtbl;
    pipe_reference_init(&rbuf->b.b.reference, 1);
    rbuf->b.b.screen = screen;
    rbuf->domain = RADEON_DOMAIN_GTT;
    rbuf->buf = NULL;
    rbuf->malloced_buffer = NULL;

    /* Allocate constant buffers and SWTCL vertex and index buffers in RAM.
     * Note that uploaded index buffers use the flag PIPE_BIND_CUSTOM, so that
     * we can distinguish them from user-created buffers.
     */
    if (templ->bind & PIPE_BIND_CONSTANT_BUFFER ||
        (!r300screen->caps.has_tcl && !(templ->bind & PIPE_BIND_CUSTOM))) {
        rbuf->malloced_buffer = align_malloc(templ->width0, 64);
        return &rbuf->b.b;
    }

    rbuf->buf =
        r300screen->rws->buffer_create(r300screen->rws, rbuf->b.b.width0,
                                       R300_BUFFER_ALIGNMENT, TRUE,
                                       rbuf->domain);
    if (!rbuf->buf) {
        FREE(rbuf);
        return NULL;
    }

    rbuf->cs_buf =
        r300screen->rws->buffer_get_cs_handle(rbuf->buf);

    return &rbuf->b.b;
}
@


1.5
log
@Merge Mesa 10.2.9
@
text
@@


1.4
log
@Merge Mesa 10.4.3
Tested by matthieu@@ mpi@@ and myself.  landry@@ ran a ports bulk build.
kettenis@@ tracked down the cause of an alignment fault on archs
that require strict eight byte pointer alignment.
@
text
@d106 1
a106 1
                                               rbuf->domain, 0);
d188 1
a188 1
                                       rbuf->domain, 0);
@


1.3
log
@Merge Mesa 9.2.0
@
text
@d106 1
a106 1
                                               rbuf->domain);
d188 1
a188 1
                                       rbuf->domain);
@


1.2
log
@Upate to libGL 7.11.2

Tested by jsg@@, matthieu@@ and ajacoutot@@, ok mattieu@@
@
text
@d38 1
a38 1
			      unsigned count, uint8_t *ptr)
a40 1
    boolean flushed;
d44 1
a44 1
    u_upload_data(r300->vbuf_mgr->uploader,
d48 1
a48 1
                  index_buffer, &flushed);
a55 1
    struct r300_screen *r300screen = r300_screen(screen);
d58 1
a58 2
    if (rbuf->constant_buffer)
        FREE(rbuf->constant_buffer);
d63 1
a63 33
    util_slab_free(&r300screen->pool_buffers, rbuf);
}

static struct pipe_transfer*
r300_buffer_get_transfer(struct pipe_context *context,
                         struct pipe_resource *resource,
                         unsigned level,
                         unsigned usage,
                         const struct pipe_box *box)
{
   struct r300_context *r300 = r300_context(context);
   struct pipe_transfer *transfer =
         util_slab_alloc(&r300->pool_transfers);

   transfer->resource = resource;
   transfer->level = level;
   transfer->usage = usage;
   transfer->box = *box;
   transfer->stride = 0;
   transfer->layer_stride = 0;
   transfer->data = NULL;

   /* Note strides are zero, this is ok for buffers, but not for
    * textures 2d & higher at least.
    */
   return transfer;
}

static void r300_buffer_transfer_destroy(struct pipe_context *pipe,
                                         struct pipe_transfer *transfer)
{
   struct r300_context *r300 = r300_context(pipe);
   util_slab_free(&r300->pool_transfers, transfer);
d67 6
a72 2
r300_buffer_transfer_map( struct pipe_context *pipe,
			  struct pipe_transfer *transfer )
d74 4
a77 4
    struct r300_context *r300 = r300_context(pipe);
    struct r300_screen *r300screen = r300_screen(pipe->screen);
    struct radeon_winsys *rws = r300screen->rws;
    struct r300_resource *rbuf = r300_resource(transfer->resource);
d80 49
a128 4
    if (rbuf->b.user_ptr)
        return (uint8_t *) rbuf->b.user_ptr + transfer->box.x;
    if (rbuf->constant_buffer)
        return (uint8_t *) rbuf->constant_buffer + transfer->box.x;
d130 1
a130 1
    map = rws->buffer_map(rbuf->buf, r300->cs, transfer->usage);
d132 2
a133 1
    if (map == NULL)
d135 1
d137 2
a138 1
    return map + transfer->box.x;
d142 1
a142 19
			    struct pipe_transfer *transfer )
{
    struct r300_screen *r300screen = r300_screen(pipe->screen);
    struct radeon_winsys *rws = r300screen->rws;
    struct r300_resource *rbuf = r300_resource(transfer->resource);

    if (rbuf->buf) {
        rws->buffer_unmap(rbuf->buf);
    }
}

static void r300_buffer_transfer_inline_write(struct pipe_context *pipe,
                                              struct pipe_resource *resource,
                                              unsigned level,
                                              unsigned usage,
                                              const struct pipe_box *box,
                                              const void *data,
                                              unsigned stride,
                                              unsigned layer_stride)
a144 3
    struct radeon_winsys *rws = r300->screen->rws;
    struct r300_resource *rbuf = r300_resource(resource);
    uint8_t *map = NULL;
d146 1
a146 12
    if (rbuf->constant_buffer) {
        memcpy(rbuf->constant_buffer + box->x, data, box->width);
        return;
    }
    assert(rbuf->b.user_ptr == NULL);

    map = rws->buffer_map(rbuf->buf, r300->cs,
                          PIPE_TRANSFER_WRITE | PIPE_TRANSFER_DISCARD | usage);

    memcpy(map + box->x, data, box->width);

    rws->buffer_unmap(rbuf->buf);
a152 2
   r300_buffer_get_transfer,           /* get_transfer */
   r300_buffer_transfer_destroy,       /* transfer_destroy */
d156 1
a156 1
   r300_buffer_transfer_inline_write   /* transfer_inline_write */
a163 1
    unsigned alignment = 16;
d165 1
a165 1
    rbuf = util_slab_alloc(&r300screen->pool_buffers);
d167 4
a170 5
    rbuf->b.b.b = *templ;
    rbuf->b.b.vtbl = &r300_buffer_vtbl;
    pipe_reference_init(&rbuf->b.b.b.reference, 1);
    rbuf->b.b.b.screen = screen;
    rbuf->b.user_ptr = NULL;
d173 1
a173 2
    rbuf->buf_size = templ->width0;
    rbuf->constant_buffer = NULL;
d175 8
a182 4
    /* Alloc constant buffers in RAM. */
    if (templ->bind & PIPE_BIND_CONSTANT_BUFFER) {
        rbuf->constant_buffer = MALLOC(templ->width0);
        return &rbuf->b.b.b;
d186 2
a187 3
        r300screen->rws->buffer_create(r300screen->rws,
                                       rbuf->b.b.b.width0, alignment,
                                       rbuf->b.b.b.bind, rbuf->b.b.b.usage,
d190 1
a190 1
        util_slab_free(&r300screen->pool_buffers, rbuf);
d197 1
a197 30
    return &rbuf->b.b.b;
}

struct pipe_resource *r300_user_buffer_create(struct pipe_screen *screen,
					      void *ptr, unsigned size,
					      unsigned bind)
{
    struct r300_screen *r300screen = r300_screen(screen);
    struct r300_resource *rbuf;

    rbuf = util_slab_alloc(&r300screen->pool_buffers);

    pipe_reference_init(&rbuf->b.b.b.reference, 1);
    rbuf->b.b.b.screen = screen;
    rbuf->b.b.b.target = PIPE_BUFFER;
    rbuf->b.b.b.format = PIPE_FORMAT_R8_UNORM;
    rbuf->b.b.b.usage = PIPE_USAGE_IMMUTABLE;
    rbuf->b.b.b.bind = bind;
    rbuf->b.b.b.width0 = ~0;
    rbuf->b.b.b.height0 = 1;
    rbuf->b.b.b.depth0 = 1;
    rbuf->b.b.b.array_size = 1;
    rbuf->b.b.b.flags = 0;
    rbuf->b.b.vtbl = &r300_buffer_vtbl;
    rbuf->b.user_ptr = ptr;
    rbuf->domain = RADEON_DOMAIN_GTT;
    rbuf->buf = NULL;
    rbuf->buf_size = size;
    rbuf->constant_buffer = NULL;
    return &rbuf->b.b.b;
@


1.1
log
@Initial revision
@
text
@a33 1
#include "r300_winsys.h"
d35 15
a49 15
unsigned r300_buffer_is_referenced(struct pipe_context *context,
				   struct pipe_resource *buf,
                                   enum r300_reference_domain domain)
{
    struct r300_context *r300 = r300_context(context);
    struct r300_buffer *rbuf = r300_buffer(buf);

    if (r300_buffer_is_user_buffer(buf))
 	return PIPE_UNREFERENCED;

    if (r300->rws->cs_is_buffer_referenced(r300->cs, rbuf->cs_buf, domain))
        return PIPE_REFERENCED_FOR_READ | PIPE_REFERENCED_FOR_WRITE;

    return PIPE_UNREFERENCED;
}
d51 1
a51 74
static unsigned r300_buffer_is_referenced_by_cs(struct pipe_context *context,
                                                struct pipe_resource *buf,
                                                unsigned level, int layer)
{
    return r300_buffer_is_referenced(context, buf, R300_REF_CS);
}

/* External helper, not required to implent u_resource_vtbl:
 */
int r300_upload_index_buffer(struct r300_context *r300,
			     struct pipe_resource **index_buffer,
			     unsigned index_size,
			     unsigned start,
			     unsigned count,
			     unsigned *out_offset)
{
   struct pipe_resource *upload_buffer = NULL;
   unsigned index_offset = start * index_size;
   int ret = 0;

    if (r300_buffer_is_user_buffer(*index_buffer)) {
	ret = u_upload_buffer(r300->upload_ib,
			      index_offset,
			      count * index_size,
			      *index_buffer,
			      &index_offset,
			      &upload_buffer);
	if (ret) {
	    goto done;
	}
	*index_buffer = upload_buffer;
	*out_offset = index_offset / index_size;
    } else
        *out_offset = start;

 done:
    //    if (upload_buffer)
    //	pipe_resource_reference(&upload_buffer, NULL);
    return ret;
}

/* External helper, not required to implement u_resource_vtbl:
 */
int r300_upload_user_buffers(struct r300_context *r300)
{
    enum pipe_error ret = PIPE_OK;
    int i, nr;

    nr = r300->velems->count;

    for (i = 0; i < nr; i++) {
        struct pipe_vertex_buffer *vb =
            &r300->vertex_buffer[r300->velems->velem[i].vertex_buffer_index];

        if (r300_buffer_is_user_buffer(vb->buffer)) {
            struct pipe_resource *upload_buffer = NULL;
            unsigned offset = 0; /*vb->buffer_offset * 4;*/
            unsigned size = vb->buffer->width0;
            unsigned upload_offset;
            ret = u_upload_buffer(r300->upload_vb,
                                  offset, size,
                                  vb->buffer,
                                  &upload_offset, &upload_buffer);
            if (ret)
                return ret;

            pipe_resource_reference(&vb->buffer, NULL);
            vb->buffer = upload_buffer;
            vb->buffer_offset = upload_offset;
            r300->validate_buffers = TRUE;
            r300->aos_dirty = TRUE;
        }
    }
    return ret;
d58 1
a58 2
    struct r300_buffer *rbuf = r300_buffer(buf);
    struct r300_winsys_screen *rws = r300screen->rws;
d64 1
a64 1
        rws->buffer_reference(rws, &rbuf->buf, NULL);
d107 2
a108 2
    struct r300_winsys_screen *rws = r300screen->rws;
    struct r300_buffer *rbuf = r300_buffer(transfer->resource);
a109 2
    boolean flush = FALSE;
    unsigned i;
d111 2
a112 2
    if (rbuf->user_buffer)
        return (uint8_t *) rbuf->user_buffer + transfer->box.x;
d116 1
a116 27
    /* check if the mapping is to a range we already flushed */
    if (transfer->usage & PIPE_TRANSFER_DISCARD) {
	for (i = 0; i < rbuf->num_ranges; i++) {
	    if ((transfer->box.x >= rbuf->ranges[i].start) &&
		(transfer->box.x < rbuf->ranges[i].end))
		flush = TRUE;

	    if (flush) {
		/* unreference this hw buffer and allocate a new one */
		rws->buffer_reference(rws, &rbuf->buf, NULL);

		rbuf->num_ranges = 0;
                rbuf->buf =
                    r300screen->rws->buffer_create(r300screen->rws,
                                                   rbuf->b.b.width0, 16,
                                                   rbuf->b.b.bind,
                                                   rbuf->b.b.usage,
                                                   rbuf->domain);
                rbuf->cs_buf =
                    r300screen->rws->buffer_get_cs_handle(r300screen->rws,
                                                          rbuf->buf);
		break;
	    }
	}
    }

    map = rws->buffer_map(rws, rbuf->buf, r300->cs, transfer->usage);
a120 4
    /* map_buffer() returned a pointer to the beginning of the buffer,
     * but transfers are expected to return a pointer to just the
     * region specified in the box.
     */
a123 30
static void r300_buffer_transfer_flush_region( struct pipe_context *pipe,
					       struct pipe_transfer *transfer,
					       const struct pipe_box *box)
{
    struct r300_buffer *rbuf = r300_buffer(transfer->resource);
    unsigned i;
    unsigned offset = transfer->box.x + box->x;
    unsigned length = box->width;

    assert(box->x + box->width <= transfer->box.width);

    if (rbuf->user_buffer)
	return;
    if (rbuf->constant_buffer)
        return;

    /* mark the range as used */
    for(i = 0; i < rbuf->num_ranges; ++i) {
	if(offset <= rbuf->ranges[i].end && rbuf->ranges[i].start <= (offset+box->width)) {
	    rbuf->ranges[i].start = MIN2(rbuf->ranges[i].start, offset);
	    rbuf->ranges[i].end   = MAX2(rbuf->ranges[i].end, (offset+length));
	    return;
	}
    }

    rbuf->ranges[rbuf->num_ranges].start = offset;
    rbuf->ranges[rbuf->num_ranges].end = offset+length;
    rbuf->num_ranges++;
}

d128 2
a129 2
    struct r300_winsys_screen *rws = r300screen->rws;
    struct r300_buffer *rbuf = r300_buffer(transfer->resource);
d132 1
a132 1
        rws->buffer_unmap(rws, rbuf->buf);
d145 3
a147 2
    struct r300_buffer *rbuf = r300_buffer(resource);
    struct pipe_transfer *transfer = NULL;
d154 1
d156 2
a157 3
    transfer = r300_buffer_get_transfer(pipe, resource, 0,
                        PIPE_TRANSFER_WRITE | PIPE_TRANSFER_DISCARD, box);
    map = r300_buffer_transfer_map(pipe, transfer);
d159 1
a159 1
    memcpy(map, data, box->width);
d161 1
a161 2
    r300_buffer_transfer_unmap(pipe, transfer);
    r300_buffer_transfer_destroy(pipe, transfer);
d164 1
a164 1
struct u_resource_vtbl r300_buffer_vtbl = 
d166 1
a166 1
   u_default_resource_get_handle,      /* get_handle */
a167 1
   r300_buffer_is_referenced_by_cs,    /* is_buffer_referenced */
d171 1
a171 1
   r300_buffer_transfer_flush_region,  /* transfer_flush_region */
d180 1
a180 1
    struct r300_buffer *rbuf;
d185 6
a190 8
    rbuf->magic = R300_BUFFER_MAGIC;

    rbuf->b.b = *templ;
    rbuf->b.vtbl = &r300_buffer_vtbl;
    pipe_reference_init(&rbuf->b.b.reference, 1);
    rbuf->b.b.screen = screen;
    rbuf->domain = R300_DOMAIN_GTT;
    rbuf->num_ranges = 0;
d192 1
a193 1
    rbuf->user_buffer = NULL;
d198 1
a198 1
        return &rbuf->b.b;
d203 2
a204 2
                                       rbuf->b.b.width0, alignment,
                                       rbuf->b.b.bind, rbuf->b.b.usage,
a205 3
    rbuf->cs_buf =
        r300screen->rws->buffer_get_cs_handle(r300screen->rws, rbuf->buf);

d211 4
a214 1
    return &rbuf->b.b;
d218 1
a218 2
					      void *ptr,
					      unsigned bytes,
d222 1
a222 1
    struct r300_buffer *rbuf;
d226 14
a239 16
    rbuf->magic = R300_BUFFER_MAGIC;

    pipe_reference_init(&rbuf->b.b.reference, 1);
    rbuf->b.vtbl = &r300_buffer_vtbl;
    rbuf->b.b.screen = screen;
    rbuf->b.b.target = PIPE_BUFFER;
    rbuf->b.b.format = PIPE_FORMAT_R8_UNORM;
    rbuf->b.b.usage = PIPE_USAGE_IMMUTABLE;
    rbuf->b.b.bind = bind;
    rbuf->b.b.width0 = bytes;
    rbuf->b.b.height0 = 1;
    rbuf->b.b.depth0 = 1;
    rbuf->b.b.array_size = 1;
    rbuf->b.b.flags = 0;
    rbuf->domain = R300_DOMAIN_GTT;
    rbuf->num_ranges = 0;
d241 1
d243 1
a243 2
    rbuf->user_buffer = ptr;
    return &rbuf->b.b;
@


1.1.1.1
log
@Import Mesa 7.10.3
@
text
@@


1.1.1.2
log
@Import Mesa 9.2.0
@
text
@d34 1
d36 12
a47 14
void r300_upload_index_buffer(struct r300_context *r300,
			      struct pipe_resource **index_buffer,
			      unsigned index_size, unsigned *start,
			      unsigned count, const uint8_t *ptr)
{
    unsigned index_offset;

    *index_buffer = NULL;

    u_upload_data(r300->uploader,
                  0, count * index_size,
                  ptr + (*start * index_size),
                  &index_offset,
                  index_buffer);
d49 77
a125 1
    *start = index_offset / index_size;
d131 3
a133 1
    struct r300_resource *rbuf = r300_resource(buf);
d135 2
a136 1
    align_free(rbuf->malloced_buffer);
d139 29
a167 1
        pb_reference(&rbuf->buf, NULL);
d169 5
a173 1
    FREE(rbuf);
d177 2
a178 6
r300_buffer_transfer_map( struct pipe_context *context,
                          struct pipe_resource *resource,
                          unsigned level,
                          unsigned usage,
                          const struct pipe_box *box,
                          struct pipe_transfer **ptransfer )
d180 4
a183 4
    struct r300_context *r300 = r300_context(context);
    struct radeon_winsys *rws = r300->screen->rws;
    struct r300_resource *rbuf = r300_resource(resource);
    struct pipe_transfer *transfer;
d185 2
d188 29
a216 42
    transfer = util_slab_alloc(&r300->pool_transfers);
    transfer->resource = resource;
    transfer->level = level;
    transfer->usage = usage;
    transfer->box = *box;
    transfer->stride = 0;
    transfer->layer_stride = 0;

    if (rbuf->malloced_buffer) {
        *ptransfer = transfer;
        return rbuf->malloced_buffer + box->x;
    }

    if (usage & PIPE_TRANSFER_DISCARD_WHOLE_RESOURCE &&
        !(usage & PIPE_TRANSFER_UNSYNCHRONIZED)) {
        assert(usage & PIPE_TRANSFER_WRITE);

        /* Check if mapping this buffer would cause waiting for the GPU. */
        if (r300->rws->cs_is_buffer_referenced(r300->cs, rbuf->cs_buf, RADEON_USAGE_READWRITE) ||
            r300->rws->buffer_is_busy(rbuf->buf, RADEON_USAGE_READWRITE)) {
            unsigned i;
            struct pb_buffer *new_buf;

            /* Create a new one in the same pipe_resource. */
            new_buf = r300->rws->buffer_create(r300->rws, rbuf->b.b.width0,
                                               R300_BUFFER_ALIGNMENT, TRUE,
                                               rbuf->domain);
            if (new_buf) {
                /* Discard the old buffer. */
                pb_reference(&rbuf->buf, NULL);
                rbuf->buf = new_buf;
                rbuf->cs_buf = r300->rws->buffer_get_cs_handle(rbuf->buf);

                /* We changed the buffer, now we need to bind it where the old one was bound. */
                for (i = 0; i < r300->nr_vertex_buffers; i++) {
                    if (r300->vertex_buffer[i].buffer == &rbuf->b.b) {
                        r300->vertex_arrays_dirty = TRUE;
                        break;
                    }
                }
            }
        }
d219 4
a222 5
    /* Buffers are never used for write, therefore mapping for read can be
     * unsynchronized. */
    if (!(usage & PIPE_TRANSFER_WRITE)) {
       usage |= PIPE_TRANSFER_UNSYNCHRONIZED;
    }
d224 6
a229 1
    map = rws->buffer_map(rbuf->cs_buf, r300->cs, usage);
d231 23
a253 3
    if (map == NULL) {
        util_slab_free(&r300->pool_transfers, transfer);
        return NULL;
d256 3
a258 2
    *ptransfer = transfer;
    return map + box->x;
d262 1
a262 1
                                        struct pipe_transfer *transfer )
d264 32
a295 1
    struct r300_context *r300 = r300_context(pipe);
d297 2
a298 1
    util_slab_free(&r300->pool_transfers, transfer);
d301 1
a301 1
static const struct u_resource_vtbl r300_buffer_vtbl =
d303 1
a303 1
   NULL,                               /* get_handle */
d305 3
d309 1
a309 1
   NULL,                               /* transfer_flush_region */
d311 1
a311 1
   NULL   /* transfer_inline_write */
d318 4
a321 1
    struct r300_resource *rbuf;
d323 1
a323 1
    rbuf = MALLOC_STRUCT(r300_resource);
d329 2
a330 1
    rbuf->domain = RADEON_DOMAIN_GTT;
d332 2
a333 1
    rbuf->malloced_buffer = NULL;
d335 3
a337 7
    /* Allocate constant buffers and SWTCL vertex and index buffers in RAM.
     * Note that uploaded index buffers use the flag PIPE_BIND_CUSTOM, so that
     * we can distinguish them from user-created buffers.
     */
    if (templ->bind & PIPE_BIND_CONSTANT_BUFFER ||
        (!r300screen->caps.has_tcl && !(templ->bind & PIPE_BIND_CUSTOM))) {
        rbuf->malloced_buffer = align_malloc(templ->width0, 64);
d342 3
a344 2
        r300screen->rws->buffer_create(r300screen->rws, rbuf->b.b.width0,
                                       R300_BUFFER_ALIGNMENT, TRUE,
d346 3
d350 1
a350 1
        FREE(rbuf);
d354 14
a367 2
    rbuf->cs_buf =
        r300screen->rws->buffer_get_cs_handle(rbuf->buf);
d369 17
@


1.1.1.3
log
@Import Mesa 10.4.3
@
text
@d106 1
a106 1
                                               rbuf->domain, 0);
d188 1
a188 1
                                       rbuf->domain, 0);
@


1.1.1.4
log
@Import Mesa 10.2.9
@
text
@d106 1
a106 1
                                               rbuf->domain);
d188 1
a188 1
                                       rbuf->domain);
@


