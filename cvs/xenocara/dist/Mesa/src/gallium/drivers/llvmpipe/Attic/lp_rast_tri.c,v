head	1.5;
access;
symbols
	OPENBSD_5_8:1.4.0.6
	OPENBSD_5_8_BASE:1.4
	OPENBSD_5_7:1.4.0.4
	OPENBSD_5_7_BASE:1.4
	v10_2_9:1.1.1.3
	v10_4_3:1.1.1.3
	v10_2_7:1.1.1.3
	OPENBSD_5_6:1.4.0.2
	OPENBSD_5_6_BASE:1.4
	v10_2_3:1.1.1.3
	OPENBSD_5_5:1.3.0.2
	OPENBSD_5_5_BASE:1.3
	v9_2_5:1.1.1.2
	v9_2_3:1.1.1.2
	v9_2_2:1.1.1.2
	v9_2_1:1.1.1.2
	v9_2_0:1.1.1.2
	OPENBSD_5_4:1.2.0.8
	OPENBSD_5_4_BASE:1.2
	OPENBSD_5_3:1.2.0.6
	OPENBSD_5_3_BASE:1.2
	OPENBSD_5_2:1.2.0.4
	OPENBSD_5_2_BASE:1.2
	OPENBSD_5_1_BASE:1.2
	OPENBSD_5_1:1.2.0.2
	v7_10_3:1.1.1.1
	mesa:1.1.1
	OPENBSD_5_0:1.1.0.6
	OPENBSD_5_0_BASE:1.1
	OPENBSD_4_9:1.1.0.2
	OPENBSD_4_9_BASE:1.1
	OPENBSD_4_8:1.1.0.4
	OPENBSD_4_8_BASE:1.1;
locks; strict;
comment	@ * @;


1.5
date	2015.12.23.05.17.31;	author jsg;	state dead;
branches;
next	1.4;
commitid	TnlogFl9nOv2eaRf;

1.4
date	2014.07.09.21.08.53;	author jsg;	state Exp;
branches;
next	1.3;
commitid	WPD6rgPryPkvXOr9;

1.3
date	2013.09.05.14.00.33;	author jsg;	state Exp;
branches;
next	1.2;

1.2
date	2011.10.23.13.37.33;	author matthieu;	state Exp;
branches;
next	1.1;

1.1
date	2010.05.22.20.06.06;	author matthieu;	state Exp;
branches
	1.1.1.1;
next	;

1.1.1.1
date	2011.10.23.13.29.27;	author matthieu;	state Exp;
branches;
next	1.1.1.2;

1.1.1.2
date	2013.09.05.13.11.26;	author jsg;	state Exp;
branches;
next	1.1.1.3;

1.1.1.3
date	2014.07.09.20.33.57;	author jsg;	state Exp;
branches;
next	;
commitid	3JhLfwcuBALP0ZR7;


desc
@@


1.5
log
@remove the now unused Mesa 10.2.9 code
@
text
@/**************************************************************************
 *
 * Copyright 2007-2009 VMware, Inc.
 * All Rights Reserved.
 *
 * Permission is hereby granted, free of charge, to any person obtaining a
 * copy of this software and associated documentation files (the
 * "Software"), to deal in the Software without restriction, including
 * without limitation the rights to use, copy, modify, merge, publish,
 * distribute, sub license, and/or sell copies of the Software, and to
 * permit persons to whom the Software is furnished to do so, subject to
 * the following conditions:
 *
 * The above copyright notice and this permission notice (including the
 * next paragraph) shall be included in all copies or substantial portions
 * of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
 * OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT.
 * IN NO EVENT SHALL VMWARE AND/OR ITS SUPPLIERS BE LIABLE FOR
 * ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
 * SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 *
 **************************************************************************/

/*
 * Rasterization for binned triangles within a tile
 */

#include <limits.h>
#include "util/u_math.h"
#include "lp_debug.h"
#include "lp_perf.h"
#include "lp_rast_priv.h"

/**
 * Shade all pixels in a 4x4 block.
 */
static void
block_full_4(struct lp_rasterizer_task *task,
             const struct lp_rast_triangle *tri,
             int x, int y)
{
   lp_rast_shade_quads_all(task, &tri->inputs, x, y);
}


/**
 * Shade all pixels in a 16x16 block.
 */
static void
block_full_16(struct lp_rasterizer_task *task,
              const struct lp_rast_triangle *tri,
              int x, int y)
{
   unsigned ix, iy;
   assert(x % 16 == 0);
   assert(y % 16 == 0);
   for (iy = 0; iy < 16; iy += 4)
      for (ix = 0; ix < 16; ix += 4)
	 block_full_4(task, tri, x + ix, y + iy);
}

static INLINE unsigned
build_mask_linear(int64_t c, int64_t dcdx, int64_t dcdy)
{
   unsigned mask = 0;

   int64_t c0 = c;
   int64_t c1 = c0 + dcdy;
   int64_t c2 = c1 + dcdy;
   int64_t c3 = c2 + dcdy;

   mask |= ((c0 + 0 * dcdx) >> FIXED_SHIFT) & (1 << 0);
   mask |= ((c0 + 1 * dcdx) >> FIXED_SHIFT) & (1 << 1);
   mask |= ((c0 + 2 * dcdx) >> FIXED_SHIFT) & (1 << 2);
   mask |= ((c0 + 3 * dcdx) >> FIXED_SHIFT) & (1 << 3);
   mask |= ((c1 + 0 * dcdx) >> FIXED_SHIFT) & (1 << 4);
   mask |= ((c1 + 1 * dcdx) >> FIXED_SHIFT) & (1 << 5);
   mask |= ((c1 + 2 * dcdx) >> FIXED_SHIFT) & (1 << 6);
   mask |= ((c1 + 3 * dcdx) >> FIXED_SHIFT) & (1 << 7);
   mask |= ((c2 + 0 * dcdx) >> FIXED_SHIFT) & (1 << 8);
   mask |= ((c2 + 1 * dcdx) >> FIXED_SHIFT) & (1 << 9);
   mask |= ((c2 + 2 * dcdx) >> FIXED_SHIFT) & (1 << 10);
   mask |= ((c2 + 3 * dcdx) >> FIXED_SHIFT) & (1 << 11);
   mask |= ((c3 + 0 * dcdx) >> FIXED_SHIFT) & (1 << 12);
   mask |= ((c3 + 1 * dcdx) >> FIXED_SHIFT) & (1 << 13);
   mask |= ((c3 + 2 * dcdx) >> FIXED_SHIFT) & (1 << 14);
   mask |= ((c3 + 3 * dcdx) >> FIXED_SHIFT) & (1 << 15);
  
   return mask;
}


static INLINE void
build_masks(int64_t c,
            int64_t cdiff,
            int64_t dcdx,
            int64_t dcdy,
	    unsigned *outmask,
	    unsigned *partmask)
{
   *outmask |= build_mask_linear(c, dcdx, dcdy);
   *partmask |= build_mask_linear(c + cdiff, dcdx, dcdy);
}

void
lp_rast_triangle_3_16(struct lp_rasterizer_task *task,
                      const union lp_rast_cmd_arg arg)
{
   union lp_rast_cmd_arg arg2;
   arg2.triangle.tri = arg.triangle.tri;
   arg2.triangle.plane_mask = (1<<3)-1;
   lp_rast_triangle_3(task, arg2);
}

void
lp_rast_triangle_3_4(struct lp_rasterizer_task *task,
                      const union lp_rast_cmd_arg arg)
{
   lp_rast_triangle_3_16(task, arg);
}

void
lp_rast_triangle_4_16(struct lp_rasterizer_task *task,
                      const union lp_rast_cmd_arg arg)
{
   union lp_rast_cmd_arg arg2;
   arg2.triangle.tri = arg.triangle.tri;
   arg2.triangle.plane_mask = (1<<4)-1;
   lp_rast_triangle_4(task, arg2);
}

#if !defined(PIPE_ARCH_SSE)

void
lp_rast_triangle_32_3_16(struct lp_rasterizer_task *task,
                         const union lp_rast_cmd_arg arg)
{
   union lp_rast_cmd_arg arg2;
   arg2.triangle.tri = arg.triangle.tri;
   arg2.triangle.plane_mask = (1<<3)-1;
   lp_rast_triangle_32_3(task, arg2);
}

void
lp_rast_triangle_32_4_16(struct lp_rasterizer_task *task,
                         const union lp_rast_cmd_arg arg)
{
   union lp_rast_cmd_arg arg2;
   arg2.triangle.tri = arg.triangle.tri;
   arg2.triangle.plane_mask = (1<<4)-1;
   lp_rast_triangle_32_4(task, arg2);
}

void
lp_rast_triangle_32_3_4(struct lp_rasterizer_task *task,
                      const union lp_rast_cmd_arg arg)
{
   lp_rast_triangle_32_3_16(task, arg);
}

#else
#include <emmintrin.h>
#include "util/u_sse.h"


static INLINE void
build_masks_32(int c, 
               int cdiff,
               int dcdx,
               int dcdy,
               unsigned *outmask,
               unsigned *partmask)
{
   __m128i cstep0 = _mm_setr_epi32(c, c+dcdx, c+dcdx*2, c+dcdx*3);
   __m128i xdcdy = _mm_set1_epi32(dcdy);

   /* Get values across the quad
    */
   __m128i cstep1 = _mm_add_epi32(cstep0, xdcdy);
   __m128i cstep2 = _mm_add_epi32(cstep1, xdcdy);
   __m128i cstep3 = _mm_add_epi32(cstep2, xdcdy);

   {
      __m128i cstep01, cstep23, result;

      cstep01 = _mm_packs_epi32(cstep0, cstep1);
      cstep23 = _mm_packs_epi32(cstep2, cstep3);
      result = _mm_packs_epi16(cstep01, cstep23);

      *outmask |= _mm_movemask_epi8(result);
   }


   {
      __m128i cio4 = _mm_set1_epi32(cdiff);
      __m128i cstep01, cstep23, result;

      cstep0 = _mm_add_epi32(cstep0, cio4);
      cstep1 = _mm_add_epi32(cstep1, cio4);
      cstep2 = _mm_add_epi32(cstep2, cio4);
      cstep3 = _mm_add_epi32(cstep3, cio4);

      cstep01 = _mm_packs_epi32(cstep0, cstep1);
      cstep23 = _mm_packs_epi32(cstep2, cstep3);
      result = _mm_packs_epi16(cstep01, cstep23);

      *partmask |= _mm_movemask_epi8(result);
   }
}


static INLINE unsigned
build_mask_linear_32(int c, int dcdx, int dcdy)
{
   __m128i cstep0 = _mm_setr_epi32(c, c+dcdx, c+dcdx*2, c+dcdx*3);
   __m128i xdcdy = _mm_set1_epi32(dcdy);

   /* Get values across the quad
    */
   __m128i cstep1 = _mm_add_epi32(cstep0, xdcdy);
   __m128i cstep2 = _mm_add_epi32(cstep1, xdcdy);
   __m128i cstep3 = _mm_add_epi32(cstep2, xdcdy);

   /* pack pairs of results into epi16
    */
   __m128i cstep01 = _mm_packs_epi32(cstep0, cstep1);
   __m128i cstep23 = _mm_packs_epi32(cstep2, cstep3);

   /* pack into epi8, preserving sign bits
    */
   __m128i result = _mm_packs_epi16(cstep01, cstep23);

   /* extract sign bits to create mask
    */
   return _mm_movemask_epi8(result);
}

static INLINE unsigned
sign_bits4(const __m128i *cstep, int cdiff)
{

   /* Adjust the step values
    */
   __m128i cio4 = _mm_set1_epi32(cdiff);
   __m128i cstep0 = _mm_add_epi32(cstep[0], cio4);
   __m128i cstep1 = _mm_add_epi32(cstep[1], cio4);
   __m128i cstep2 = _mm_add_epi32(cstep[2], cio4);
   __m128i cstep3 = _mm_add_epi32(cstep[3], cio4);

   /* Pack down to epi8
    */
   __m128i cstep01 = _mm_packs_epi32(cstep0, cstep1);
   __m128i cstep23 = _mm_packs_epi32(cstep2, cstep3);
   __m128i result = _mm_packs_epi16(cstep01, cstep23);

   /* Extract the sign bits
    */
   return _mm_movemask_epi8(result);
}


#define NR_PLANES 3







void
lp_rast_triangle_32_3_16(struct lp_rasterizer_task *task,
                      const union lp_rast_cmd_arg arg)
{
   const struct lp_rast_triangle *tri = arg.triangle.tri;
   const struct lp_rast_plane *plane = GET_PLANES(tri);
   int x = (arg.triangle.plane_mask & 0xff) + task->x;
   int y = (arg.triangle.plane_mask >> 8) + task->y;
   unsigned i, j;

   struct { unsigned mask:16; unsigned i:8; unsigned j:8; } out[16];
   unsigned nr = 0;

   __m128i p0 = lp_plane_to_m128i(&plane[0]); /* c, dcdx, dcdy, eo */
   __m128i p1 = lp_plane_to_m128i(&plane[1]); /* c, dcdx, dcdy, eo */
   __m128i p2 = lp_plane_to_m128i(&plane[2]); /* c, dcdx, dcdy, eo */
   __m128i zero = _mm_setzero_si128();

   __m128i c;
   __m128i dcdx;
   __m128i dcdy;
   __m128i rej4;

   __m128i dcdx2;
   __m128i dcdx3;
   
   __m128i span_0;                /* 0,dcdx,2dcdx,3dcdx for plane 0 */
   __m128i span_1;                /* 0,dcdx,2dcdx,3dcdx for plane 1 */
   __m128i span_2;                /* 0,dcdx,2dcdx,3dcdx for plane 2 */
   __m128i unused;
   
   transpose4_epi32(&p0, &p1, &p2, &zero,
                    &c, &dcdx, &dcdy, &rej4);

   /* Adjust dcdx;
    */
   dcdx = _mm_sub_epi32(zero, dcdx);

   c = _mm_add_epi32(c, mm_mullo_epi32(dcdx, _mm_set1_epi32(x)));
   c = _mm_add_epi32(c, mm_mullo_epi32(dcdy, _mm_set1_epi32(y)));
   rej4 = _mm_slli_epi32(rej4, 2);

   /* Adjust so we can just check the sign bit (< 0 comparison), instead of having to do a less efficient <= 0 comparison */
   c = _mm_sub_epi32(c, _mm_set1_epi32(1));
   rej4 = _mm_add_epi32(rej4, _mm_set1_epi32(1));

   dcdx2 = _mm_add_epi32(dcdx, dcdx);
   dcdx3 = _mm_add_epi32(dcdx2, dcdx);

   transpose4_epi32(&zero, &dcdx, &dcdx2, &dcdx3,
                    &span_0, &span_1, &span_2, &unused);

   for (i = 0; i < 4; i++) {
      __m128i cx = c;

      for (j = 0; j < 4; j++) {
         __m128i c4rej = _mm_add_epi32(cx, rej4);
         __m128i rej_masks = _mm_srai_epi32(c4rej, 31);

         /* if (is_zero(rej_masks)) */
         if (_mm_movemask_epi8(rej_masks) == 0) {
            __m128i c0_0 = _mm_add_epi32(SCALAR_EPI32(cx, 0), span_0);
            __m128i c1_0 = _mm_add_epi32(SCALAR_EPI32(cx, 1), span_1);
            __m128i c2_0 = _mm_add_epi32(SCALAR_EPI32(cx, 2), span_2);

            __m128i c_0 = _mm_or_si128(_mm_or_si128(c0_0, c1_0), c2_0);

            __m128i c0_1 = _mm_add_epi32(c0_0, SCALAR_EPI32(dcdy, 0));
            __m128i c1_1 = _mm_add_epi32(c1_0, SCALAR_EPI32(dcdy, 1));
            __m128i c2_1 = _mm_add_epi32(c2_0, SCALAR_EPI32(dcdy, 2));

            __m128i c_1 = _mm_or_si128(_mm_or_si128(c0_1, c1_1), c2_1);
            __m128i c_01 = _mm_packs_epi32(c_0, c_1);

            __m128i c0_2 = _mm_add_epi32(c0_1, SCALAR_EPI32(dcdy, 0));
            __m128i c1_2 = _mm_add_epi32(c1_1, SCALAR_EPI32(dcdy, 1));
            __m128i c2_2 = _mm_add_epi32(c2_1, SCALAR_EPI32(dcdy, 2));

            __m128i c_2 = _mm_or_si128(_mm_or_si128(c0_2, c1_2), c2_2);

            __m128i c0_3 = _mm_add_epi32(c0_2, SCALAR_EPI32(dcdy, 0));
            __m128i c1_3 = _mm_add_epi32(c1_2, SCALAR_EPI32(dcdy, 1));
            __m128i c2_3 = _mm_add_epi32(c2_2, SCALAR_EPI32(dcdy, 2));

            __m128i c_3 = _mm_or_si128(_mm_or_si128(c0_3, c1_3), c2_3);
            __m128i c_23 = _mm_packs_epi32(c_2, c_3);
            __m128i c_0123 = _mm_packs_epi16(c_01, c_23);

            unsigned mask = _mm_movemask_epi8(c_0123);

            out[nr].i = i;
            out[nr].j = j;
            out[nr].mask = mask;
            if (mask != 0xffff)
               nr++;
         }
         cx = _mm_add_epi32(cx, _mm_slli_epi32(dcdx, 2));
      }

      c = _mm_add_epi32(c, _mm_slli_epi32(dcdy, 2));
   }

   for (i = 0; i < nr; i++)
      lp_rast_shade_quads_mask(task,
                               &tri->inputs,
                               x + 4 * out[i].j,
                               y + 4 * out[i].i,
                               0xffff & ~out[i].mask);
}





void
lp_rast_triangle_32_3_4(struct lp_rasterizer_task *task,
                     const union lp_rast_cmd_arg arg)
{
   const struct lp_rast_triangle *tri = arg.triangle.tri;
   const struct lp_rast_plane *plane = GET_PLANES(tri);
   unsigned x = (arg.triangle.plane_mask & 0xff) + task->x;
   unsigned y = (arg.triangle.plane_mask >> 8) + task->y;

   __m128i p0 = lp_plane_to_m128i(&plane[0]); /* c, dcdx, dcdy, eo */
   __m128i p1 = lp_plane_to_m128i(&plane[1]); /* c, dcdx, dcdy, eo */
   __m128i p2 = lp_plane_to_m128i(&plane[2]); /* c, dcdx, dcdy, eo */
   __m128i zero = _mm_setzero_si128();

   __m128i c;
   __m128i dcdx;
   __m128i dcdy;

   __m128i dcdx2;
   __m128i dcdx3;
   
   __m128i span_0;                /* 0,dcdx,2dcdx,3dcdx for plane 0 */
   __m128i span_1;                /* 0,dcdx,2dcdx,3dcdx for plane 1 */
   __m128i span_2;                /* 0,dcdx,2dcdx,3dcdx for plane 2 */
   __m128i unused;

   transpose4_epi32(&p0, &p1, &p2, &zero,
                    &c, &dcdx, &dcdy, &unused);

   /* Adjust dcdx;
    */
   dcdx = _mm_sub_epi32(zero, dcdx);

   c = _mm_add_epi32(c, mm_mullo_epi32(dcdx, _mm_set1_epi32(x)));
   c = _mm_add_epi32(c, mm_mullo_epi32(dcdy, _mm_set1_epi32(y)));

   /* Adjust so we can just check the sign bit (< 0 comparison), instead of having to do a less efficient <= 0 comparison */
   c = _mm_sub_epi32(c, _mm_set1_epi32(1));

   dcdx2 = _mm_add_epi32(dcdx, dcdx);
   dcdx3 = _mm_add_epi32(dcdx2, dcdx);

   transpose4_epi32(&zero, &dcdx, &dcdx2, &dcdx3,
                    &span_0, &span_1, &span_2, &unused);


   {
      __m128i c0_0 = _mm_add_epi32(SCALAR_EPI32(c, 0), span_0);
      __m128i c1_0 = _mm_add_epi32(SCALAR_EPI32(c, 1), span_1);
      __m128i c2_0 = _mm_add_epi32(SCALAR_EPI32(c, 2), span_2);
      
      __m128i c_0 = _mm_or_si128(_mm_or_si128(c0_0, c1_0), c2_0);

      __m128i c0_1 = _mm_add_epi32(c0_0, SCALAR_EPI32(dcdy, 0));
      __m128i c1_1 = _mm_add_epi32(c1_0, SCALAR_EPI32(dcdy, 1));
      __m128i c2_1 = _mm_add_epi32(c2_0, SCALAR_EPI32(dcdy, 2));

      __m128i c_1 = _mm_or_si128(_mm_or_si128(c0_1, c1_1), c2_1);
      __m128i c_01 = _mm_packs_epi32(c_0, c_1);

      __m128i c0_2 = _mm_add_epi32(c0_1, SCALAR_EPI32(dcdy, 0));
      __m128i c1_2 = _mm_add_epi32(c1_1, SCALAR_EPI32(dcdy, 1));
      __m128i c2_2 = _mm_add_epi32(c2_1, SCALAR_EPI32(dcdy, 2));

      __m128i c_2 = _mm_or_si128(_mm_or_si128(c0_2, c1_2), c2_2);

      __m128i c0_3 = _mm_add_epi32(c0_2, SCALAR_EPI32(dcdy, 0));
      __m128i c1_3 = _mm_add_epi32(c1_2, SCALAR_EPI32(dcdy, 1));
      __m128i c2_3 = _mm_add_epi32(c2_2, SCALAR_EPI32(dcdy, 2));

      __m128i c_3 = _mm_or_si128(_mm_or_si128(c0_3, c1_3), c2_3);
      __m128i c_23 = _mm_packs_epi32(c_2, c_3);
      __m128i c_0123 = _mm_packs_epi16(c_01, c_23);

      unsigned mask = _mm_movemask_epi8(c_0123);

      if (mask != 0xffff)
         lp_rast_shade_quads_mask(task,
                                  &tri->inputs,
                                  x,
                                  y,
                                  0xffff & ~mask);
   }
}

#undef NR_PLANES
#endif


#define BUILD_MASKS(c, cdiff, dcdx, dcdy, omask, pmask) build_masks(c, cdiff, dcdx, dcdy, omask, pmask)
#define BUILD_MASK_LINEAR(c, dcdx, dcdy) build_mask_linear(c, dcdx, dcdy)

#define TAG(x) x##_1
#define NR_PLANES 1
#include "lp_rast_tri_tmp.h"

#define TAG(x) x##_2
#define NR_PLANES 2
#include "lp_rast_tri_tmp.h"

#define TAG(x) x##_3
#define NR_PLANES 3
/*#define TRI_4 lp_rast_triangle_3_4*/
/*#define TRI_16 lp_rast_triangle_3_16*/
#include "lp_rast_tri_tmp.h"

#define TAG(x) x##_4
#define NR_PLANES 4
/*#define TRI_16 lp_rast_triangle_4_16*/
#include "lp_rast_tri_tmp.h"

#define TAG(x) x##_5
#define NR_PLANES 5
#include "lp_rast_tri_tmp.h"

#define TAG(x) x##_6
#define NR_PLANES 6
#include "lp_rast_tri_tmp.h"

#define TAG(x) x##_7
#define NR_PLANES 7
#include "lp_rast_tri_tmp.h"

#define TAG(x) x##_8
#define NR_PLANES 8
#include "lp_rast_tri_tmp.h"

#ifdef PIPE_ARCH_SSE
#undef BUILD_MASKS
#undef BUILD_MASK_LINEAR
#define BUILD_MASKS(c, cdiff, dcdx, dcdy, omask, pmask) build_masks_32((int)c, (int)cdiff, dcdx, dcdy, omask, pmask)
#define BUILD_MASK_LINEAR(c, dcdx, dcdy) build_mask_linear_32((int)c, dcdx, dcdy)
#endif

#define TAG(x) x##_32_1
#define NR_PLANES 1
#include "lp_rast_tri_tmp.h"

#define TAG(x) x##_32_2
#define NR_PLANES 2
#include "lp_rast_tri_tmp.h"

#define TAG(x) x##_32_3
#define NR_PLANES 3
/*#define TRI_4 lp_rast_triangle_3_4*/
/*#define TRI_16 lp_rast_triangle_3_16*/
#include "lp_rast_tri_tmp.h"

#define TAG(x) x##_32_4
#define NR_PLANES 4
#ifdef PIPE_ARCH_SSE
#define TRI_16 lp_rast_triangle_32_4_16
#endif
#include "lp_rast_tri_tmp.h"

#define TAG(x) x##_32_5
#define NR_PLANES 5
#include "lp_rast_tri_tmp.h"

#define TAG(x) x##_32_6
#define NR_PLANES 6
#include "lp_rast_tri_tmp.h"

#define TAG(x) x##_32_7
#define NR_PLANES 7
#include "lp_rast_tri_tmp.h"

#define TAG(x) x##_32_8
#define NR_PLANES 8
#include "lp_rast_tri_tmp.h"

@


1.4
log
@Merge Mesa 10.2.3
tested by matthieu@@ kettenis@@ mpi@@ brett@@ and myself across a
diverse range of hardware
@
text
@@


1.3
log
@Merge Mesa 9.2.0
@
text
@a37 3



a65 2
#if !defined(PIPE_ARCH_SSE)

d67 1
a67 1
build_mask_linear(int c, int dcdx, int dcdy)
d69 1
a69 1
   int mask = 0;
d71 21
a91 21
   int c0 = c;
   int c1 = c0 + dcdy;
   int c2 = c1 + dcdy;
   int c3 = c2 + dcdy;

   mask |= ((c0 + 0 * dcdx) >> 31) & (1 << 0);
   mask |= ((c0 + 1 * dcdx) >> 31) & (1 << 1);
   mask |= ((c0 + 2 * dcdx) >> 31) & (1 << 2);
   mask |= ((c0 + 3 * dcdx) >> 31) & (1 << 3);
   mask |= ((c1 + 0 * dcdx) >> 31) & (1 << 4);
   mask |= ((c1 + 1 * dcdx) >> 31) & (1 << 5);
   mask |= ((c1 + 2 * dcdx) >> 31) & (1 << 6);
   mask |= ((c1 + 3 * dcdx) >> 31) & (1 << 7); 
   mask |= ((c2 + 0 * dcdx) >> 31) & (1 << 8);
   mask |= ((c2 + 1 * dcdx) >> 31) & (1 << 9);
   mask |= ((c2 + 2 * dcdx) >> 31) & (1 << 10);
   mask |= ((c2 + 3 * dcdx) >> 31) & (1 << 11);
   mask |= ((c3 + 0 * dcdx) >> 31) & (1 << 12);
   mask |= ((c3 + 1 * dcdx) >> 31) & (1 << 13);
   mask |= ((c3 + 2 * dcdx) >> 31) & (1 << 14);
   mask |= ((c3 + 3 * dcdx) >> 31) & (1 << 15);
d98 4
a101 4
build_masks(int c, 
	    int cdiff,
	    int dcdx,
	    int dcdy,
d120 7
d136 22
d159 1
a159 1
lp_rast_triangle_3_4(struct lp_rasterizer_task *task,
d162 1
a162 1
   lp_rast_triangle_3_16(task, arg);
d171 6
a176 6
build_masks(int c, 
	    int cdiff,
	    int dcdx,
	    int dcdy,
	    unsigned *outmask,
	    unsigned *partmask)
d217 1
a217 1
build_mask_linear(int c, int dcdx, int dcdy)
d275 1
a275 1
lp_rast_triangle_3_16(struct lp_rasterizer_task *task,
d287 3
a289 3
   __m128i p0 = _mm_load_si128((__m128i *)&plane[0]); /* c, dcdx, dcdy, eo */
   __m128i p1 = _mm_load_si128((__m128i *)&plane[1]); /* c, dcdx, dcdy, eo */
   __m128i p2 = _mm_load_si128((__m128i *)&plane[2]); /* c, dcdx, dcdy, eo */
d389 1
a389 1
lp_rast_triangle_3_4(struct lp_rasterizer_task *task,
d397 3
a399 3
   __m128i p0 = _mm_load_si128((__m128i *)&plane[0]); /* c, dcdx, dcdy, eo */
   __m128i p1 = _mm_load_si128((__m128i *)&plane[1]); /* c, dcdx, dcdy, eo */
   __m128i p2 = _mm_load_si128((__m128i *)&plane[2]); /* c, dcdx, dcdy, eo */
d477 2
a478 1

d496 1
a496 1
#define TRI_16 lp_rast_triangle_4_16
d512 44
@


1.2
log
@Merge Mesa 7.10.3
@
text
@a36 1
#include "lp_tile_soa.h"
d131 1
a131 1
   lp_rast_triangle_3(task, arg2);
d292 4
d370 2
a371 2
   int x = (arg.triangle.plane_mask & 0xff) + task->x;
   int y = (arg.triangle.plane_mask >> 8) + task->y;
d389 1
a389 1
   
d399 3
@


1.1
log
@Update to Mesa 7.8.1. Tested on a bulk ports build by naddy@@, ok oga@@.
@
text
@a39 46
/**
 * Map an index in [0,15] to an x,y position, multiplied by 4.
 * This is used to get the position of each subtile in a 4x4
 * grid of edge step values.
 * Note: we can use some bit twiddling to compute these values instead
 * of using a look-up table, but there's no measurable performance
 * difference.
 */
static const int pos_table4[16][2] = {
   { 0, 0 },
   { 4, 0 },
   { 0, 4 },
   { 4, 4 },
   { 8, 0 },
   { 12, 0 },
   { 8, 4 },
   { 12, 4 },
   { 0, 8 },
   { 4, 8 },
   { 0, 12 },
   { 4, 12 },
   { 8, 8 },
   { 12, 8 },
   { 8, 12 },
   { 12, 12 }
};


static const int pos_table16[16][2] = {
   { 0, 0 },
   { 16, 0 },
   { 0, 16 },
   { 16, 16 },
   { 32, 0 },
   { 48, 0 },
   { 32, 16 },
   { 48, 16 },
   { 0, 32 },
   { 16, 32 },
   { 0, 48 },
   { 16, 48 },
   { 32, 32 },
   { 48, 32 },
   { 32, 48 },
   { 48, 48 }
};
d70 54
d125 3
a127 10
/**
 * Pass the 4x4 pixel block to the shader function.
 * Determination of which of the 16 pixels lies inside the triangle
 * will be done as part of the fragment shader.
 */
static void
do_block_4(struct lp_rasterizer_task *task,
           const struct lp_rast_triangle *tri,
           int x, int y,
           int c1, int c2, int c3)
d129 5
a133 2
   assert(x >= 0);
   assert(y >= 0);
d135 5
a139 1
   lp_rast_shade_quads(task, &tri->inputs, x, y, -c1, -c2, -c3);
d142 3
a145 14
/**
 * Evaluate a 16x16 block of pixels to determine which 4x4 subblocks are in/out
 * of the triangle's bounds.
 */
static void
do_block_16(struct lp_rasterizer_task *task,
            const struct lp_rast_triangle *tri,
            int x, int y,
            int c0, int c1, int c2)
{
   unsigned mask = 0;
   int eo[3];
   int c[3];
   int i, j;
d147 23
a169 4
   assert(x >= 0);
   assert(y >= 0);
   assert(x % 16 == 0);
   assert(y % 16 == 0);
d171 1
a171 18
   eo[0] = tri->eo1 * 4;
   eo[1] = tri->eo2 * 4;
   eo[2] = tri->eo3 * 4;

   c[0] = c0;
   c[1] = c1;
   c[2] = c2;

   for (j = 0; j < 3; j++) {
      const int *step = tri->inputs.step[j];
      const int cx = c[j] + eo[j];

      /* Mask has bits set whenever we are outside any of the edges.
       */
      for (i = 0; i < 16; i++) {
         int out = cx + step[i] * 4;
         mask |= (out >> 31) & (1 << i);
      }
d174 15
a188 16
   mask = ~mask & 0xffff;
   while (mask) {
      int i = ffs(mask) - 1;
      int px = x + pos_table4[i][0];
      int py = y + pos_table4[i][1];
      int cx1 = c0 + tri->inputs.step[0][i] * 4;
      int cx2 = c1 + tri->inputs.step[1][i] * 4;
      int cx3 = c2 + tri->inputs.step[2][i] * 4;

      mask &= ~(1 << i);

      /* Don't bother testing if the 4x4 block is entirely in/out of
       * the triangle.  It's a little faster to do it in the jit code.
       */
      LP_COUNT(nr_non_empty_4);
      do_block_4(task, tri, px, py, cx1, cx2, cx3);
d193 58
a250 4
/**
 * Scan the tile in chunks and figure out which pixels to rasterize
 * for this triangle.
 */
d252 2
a253 2
lp_rast_triangle(struct lp_rasterizer_task *task,
                 const union lp_rast_cmd_arg arg)
d255 4
a258 4
   const struct lp_rast_triangle *tri = arg.triangle;
   const int x = task->x, y = task->y;
   int ei[3], eo[3], c[3];
   unsigned outmask, inmask, partial_mask;
d261 83
a343 30
   c[0] = tri->c1 + tri->dx12 * y - tri->dy12 * x;
   c[1] = tri->c2 + tri->dx23 * y - tri->dy23 * x;
   c[2] = tri->c3 + tri->dx31 * y - tri->dy31 * x;

   eo[0] = tri->eo1 * 16;
   eo[1] = tri->eo2 * 16;
   eo[2] = tri->eo3 * 16;

   ei[0] = tri->ei1 * 16;
   ei[1] = tri->ei2 * 16;
   ei[2] = tri->ei3 * 16;

   outmask = 0;
   inmask = 0xffff;

   for (j = 0; j < 3; j++) {
      const int *step = tri->inputs.step[j];
      const int cox = c[j] + eo[j];
      const int cio = ei[j]- eo[j];

      /* Outmask has bits set whenever we are outside any of the
       * edges.
       */
      /* Inmask has bits set whenever we are inside all of the edges.
       */
      for (i = 0; i < 16; i++) {
         int out = cox + step[i] * 16;
         int in = out + cio;
         outmask |= (out >> 31) & (1 << i);
         inmask &= ~((in >> 31) & (1 << i));
d345 2
d349 9
a357 1
   assert((outmask & inmask) == 0);
a358 2
   if (outmask == 0xffff)
      return;
d360 31
a390 2
   /* Invert mask, so that bits are set whenever we are at least
    * partially inside all of the edges:
d392 10
a401 1
   partial_mask = ~inmask & ~outmask & 0xffff;
a402 9
   /* Iterate over partials:
    */
   while (partial_mask) {
      int i = ffs(partial_mask) - 1;
      int px = x + pos_table16[i][0];
      int py = y + pos_table16[i][1];
      int cx1 = c[0] + tri->inputs.step[0][i] * 16;
      int cx2 = c[1] + tri->inputs.step[1][i] * 16;
      int cx3 = c[2] + tri->inputs.step[2][i] * 16;
d404 19
a422 1
      partial_mask &= ~(1 << i);
d424 3
a426 3
      LP_COUNT(nr_partially_covered_16);
      do_block_16(task, tri, px, py, cx1, cx2, cx3);
   }
d428 3
a430 6
   /* Iterate over fulls: 
    */
   while (inmask) {
      int i = ffs(inmask) - 1;
      int px = x + pos_table16[i][0];
      int py = y + pos_table16[i][1];
d432 1
a432 1
      inmask &= ~(1 << i);
d434 6
a439 2
      LP_COUNT(nr_fully_covered_16);
      block_full_16(task, tri, px, py);
d442 42
@


1.1.1.1
log
@Import Mesa 7.10.3
@
text
@d40 46
a115 1
#if !defined(PIPE_ARCH_SSE)
d117 10
a126 2
static INLINE unsigned
build_mask_linear(int c, int dcdx, int dcdy)
d128 2
a129 1
   int mask = 0;
d131 1
a131 23
   int c0 = c;
   int c1 = c0 + dcdy;
   int c2 = c1 + dcdy;
   int c3 = c2 + dcdy;

   mask |= ((c0 + 0 * dcdx) >> 31) & (1 << 0);
   mask |= ((c0 + 1 * dcdx) >> 31) & (1 << 1);
   mask |= ((c0 + 2 * dcdx) >> 31) & (1 << 2);
   mask |= ((c0 + 3 * dcdx) >> 31) & (1 << 3);
   mask |= ((c1 + 0 * dcdx) >> 31) & (1 << 4);
   mask |= ((c1 + 1 * dcdx) >> 31) & (1 << 5);
   mask |= ((c1 + 2 * dcdx) >> 31) & (1 << 6);
   mask |= ((c1 + 3 * dcdx) >> 31) & (1 << 7); 
   mask |= ((c2 + 0 * dcdx) >> 31) & (1 << 8);
   mask |= ((c2 + 1 * dcdx) >> 31) & (1 << 9);
   mask |= ((c2 + 2 * dcdx) >> 31) & (1 << 10);
   mask |= ((c2 + 3 * dcdx) >> 31) & (1 << 11);
   mask |= ((c3 + 0 * dcdx) >> 31) & (1 << 12);
   mask |= ((c3 + 1 * dcdx) >> 31) & (1 << 13);
   mask |= ((c3 + 2 * dcdx) >> 31) & (1 << 14);
   mask |= ((c3 + 3 * dcdx) >> 31) & (1 << 15);
  
   return mask;
d135 14
a148 11
static INLINE void
build_masks(int c, 
	    int cdiff,
	    int dcdx,
	    int dcdy,
	    unsigned *outmask,
	    unsigned *partmask)
{
   *outmask |= build_mask_linear(c, dcdx, dcdy);
   *partmask |= build_mask_linear(c + cdiff, dcdx, dcdy);
}
d150 4
a153 9
void
lp_rast_triangle_3_16(struct lp_rasterizer_task *task,
                      const union lp_rast_cmd_arg arg)
{
   union lp_rast_cmd_arg arg2;
   arg2.triangle.tri = arg.triangle.tri;
   arg2.triangle.plane_mask = (1<<3)-1;
   lp_rast_triangle_3(task, arg2);
}
d155 18
a172 47
void
lp_rast_triangle_4_16(struct lp_rasterizer_task *task,
                      const union lp_rast_cmd_arg arg)
{
   union lp_rast_cmd_arg arg2;
   arg2.triangle.tri = arg.triangle.tri;
   arg2.triangle.plane_mask = (1<<4)-1;
   lp_rast_triangle_3(task, arg2);
}

void
lp_rast_triangle_3_4(struct lp_rasterizer_task *task,
                      const union lp_rast_cmd_arg arg)
{
   lp_rast_triangle_3_16(task, arg);
}

#else
#include <emmintrin.h>
#include "util/u_sse.h"


static INLINE void
build_masks(int c, 
	    int cdiff,
	    int dcdx,
	    int dcdy,
	    unsigned *outmask,
	    unsigned *partmask)
{
   __m128i cstep0 = _mm_setr_epi32(c, c+dcdx, c+dcdx*2, c+dcdx*3);
   __m128i xdcdy = _mm_set1_epi32(dcdy);

   /* Get values across the quad
    */
   __m128i cstep1 = _mm_add_epi32(cstep0, xdcdy);
   __m128i cstep2 = _mm_add_epi32(cstep1, xdcdy);
   __m128i cstep3 = _mm_add_epi32(cstep2, xdcdy);

   {
      __m128i cstep01, cstep23, result;

      cstep01 = _mm_packs_epi32(cstep0, cstep1);
      cstep23 = _mm_packs_epi32(cstep2, cstep3);
      result = _mm_packs_epi16(cstep01, cstep23);

      *outmask |= _mm_movemask_epi8(result);
d175 16
a190 15

   {
      __m128i cio4 = _mm_set1_epi32(cdiff);
      __m128i cstep01, cstep23, result;

      cstep0 = _mm_add_epi32(cstep0, cio4);
      cstep1 = _mm_add_epi32(cstep1, cio4);
      cstep2 = _mm_add_epi32(cstep2, cio4);
      cstep3 = _mm_add_epi32(cstep3, cio4);

      cstep01 = _mm_packs_epi32(cstep0, cstep1);
      cstep23 = _mm_packs_epi32(cstep2, cstep3);
      result = _mm_packs_epi16(cstep01, cstep23);

      *partmask |= _mm_movemask_epi8(result);
d195 4
a198 58
static INLINE unsigned
build_mask_linear(int c, int dcdx, int dcdy)
{
   __m128i cstep0 = _mm_setr_epi32(c, c+dcdx, c+dcdx*2, c+dcdx*3);
   __m128i xdcdy = _mm_set1_epi32(dcdy);

   /* Get values across the quad
    */
   __m128i cstep1 = _mm_add_epi32(cstep0, xdcdy);
   __m128i cstep2 = _mm_add_epi32(cstep1, xdcdy);
   __m128i cstep3 = _mm_add_epi32(cstep2, xdcdy);

   /* pack pairs of results into epi16
    */
   __m128i cstep01 = _mm_packs_epi32(cstep0, cstep1);
   __m128i cstep23 = _mm_packs_epi32(cstep2, cstep3);

   /* pack into epi8, preserving sign bits
    */
   __m128i result = _mm_packs_epi16(cstep01, cstep23);

   /* extract sign bits to create mask
    */
   return _mm_movemask_epi8(result);
}

static INLINE unsigned
sign_bits4(const __m128i *cstep, int cdiff)
{

   /* Adjust the step values
    */
   __m128i cio4 = _mm_set1_epi32(cdiff);
   __m128i cstep0 = _mm_add_epi32(cstep[0], cio4);
   __m128i cstep1 = _mm_add_epi32(cstep[1], cio4);
   __m128i cstep2 = _mm_add_epi32(cstep[2], cio4);
   __m128i cstep3 = _mm_add_epi32(cstep[3], cio4);

   /* Pack down to epi8
    */
   __m128i cstep01 = _mm_packs_epi32(cstep0, cstep1);
   __m128i cstep23 = _mm_packs_epi32(cstep2, cstep3);
   __m128i result = _mm_packs_epi16(cstep01, cstep23);

   /* Extract the sign bits
    */
   return _mm_movemask_epi8(result);
}


#define NR_PLANES 3







d200 2
a201 2
lp_rast_triangle_3_16(struct lp_rasterizer_task *task,
                      const union lp_rast_cmd_arg arg)
d203 4
a206 4
   const struct lp_rast_triangle *tri = arg.triangle.tri;
   const struct lp_rast_plane *plane = GET_PLANES(tri);
   int x = (arg.triangle.plane_mask & 0xff) + task->x;
   int y = (arg.triangle.plane_mask >> 8) + task->y;
d209 30
a238 83
   struct { unsigned mask:16; unsigned i:8; unsigned j:8; } out[16];
   unsigned nr = 0;

   __m128i p0 = _mm_load_si128((__m128i *)&plane[0]); /* c, dcdx, dcdy, eo */
   __m128i p1 = _mm_load_si128((__m128i *)&plane[1]); /* c, dcdx, dcdy, eo */
   __m128i p2 = _mm_load_si128((__m128i *)&plane[2]); /* c, dcdx, dcdy, eo */
   __m128i zero = _mm_setzero_si128();

   __m128i c;
   __m128i dcdx;
   __m128i dcdy;
   __m128i rej4;

   __m128i dcdx2;
   __m128i dcdx3;
   
   __m128i span_0;                /* 0,dcdx,2dcdx,3dcdx for plane 0 */
   __m128i span_1;                /* 0,dcdx,2dcdx,3dcdx for plane 1 */
   __m128i span_2;                /* 0,dcdx,2dcdx,3dcdx for plane 2 */
   __m128i unused;
   
   transpose4_epi32(&p0, &p1, &p2, &zero,
                    &c, &dcdx, &dcdy, &rej4);

   /* Adjust dcdx;
    */
   dcdx = _mm_sub_epi32(zero, dcdx);

   c = _mm_add_epi32(c, mm_mullo_epi32(dcdx, _mm_set1_epi32(x)));
   c = _mm_add_epi32(c, mm_mullo_epi32(dcdy, _mm_set1_epi32(y)));
   rej4 = _mm_slli_epi32(rej4, 2);

   dcdx2 = _mm_add_epi32(dcdx, dcdx);
   dcdx3 = _mm_add_epi32(dcdx2, dcdx);

   transpose4_epi32(&zero, &dcdx, &dcdx2, &dcdx3,
                    &span_0, &span_1, &span_2, &unused);

   for (i = 0; i < 4; i++) {
      __m128i cx = c;

      for (j = 0; j < 4; j++) {
         __m128i c4rej = _mm_add_epi32(cx, rej4);
         __m128i rej_masks = _mm_srai_epi32(c4rej, 31);

         /* if (is_zero(rej_masks)) */
         if (_mm_movemask_epi8(rej_masks) == 0) {
            __m128i c0_0 = _mm_add_epi32(SCALAR_EPI32(cx, 0), span_0);
            __m128i c1_0 = _mm_add_epi32(SCALAR_EPI32(cx, 1), span_1);
            __m128i c2_0 = _mm_add_epi32(SCALAR_EPI32(cx, 2), span_2);

            __m128i c_0 = _mm_or_si128(_mm_or_si128(c0_0, c1_0), c2_0);

            __m128i c0_1 = _mm_add_epi32(c0_0, SCALAR_EPI32(dcdy, 0));
            __m128i c1_1 = _mm_add_epi32(c1_0, SCALAR_EPI32(dcdy, 1));
            __m128i c2_1 = _mm_add_epi32(c2_0, SCALAR_EPI32(dcdy, 2));

            __m128i c_1 = _mm_or_si128(_mm_or_si128(c0_1, c1_1), c2_1);
            __m128i c_01 = _mm_packs_epi32(c_0, c_1);

            __m128i c0_2 = _mm_add_epi32(c0_1, SCALAR_EPI32(dcdy, 0));
            __m128i c1_2 = _mm_add_epi32(c1_1, SCALAR_EPI32(dcdy, 1));
            __m128i c2_2 = _mm_add_epi32(c2_1, SCALAR_EPI32(dcdy, 2));

            __m128i c_2 = _mm_or_si128(_mm_or_si128(c0_2, c1_2), c2_2);

            __m128i c0_3 = _mm_add_epi32(c0_2, SCALAR_EPI32(dcdy, 0));
            __m128i c1_3 = _mm_add_epi32(c1_2, SCALAR_EPI32(dcdy, 1));
            __m128i c2_3 = _mm_add_epi32(c2_2, SCALAR_EPI32(dcdy, 2));

            __m128i c_3 = _mm_or_si128(_mm_or_si128(c0_3, c1_3), c2_3);
            __m128i c_23 = _mm_packs_epi32(c_2, c_3);
            __m128i c_0123 = _mm_packs_epi16(c_01, c_23);

            unsigned mask = _mm_movemask_epi8(c_0123);

            out[nr].i = i;
            out[nr].j = j;
            out[nr].mask = mask;
            if (mask != 0xffff)
               nr++;
         }
         cx = _mm_add_epi32(cx, _mm_slli_epi32(dcdx, 2));
a239 2

      c = _mm_add_epi32(c, _mm_slli_epi32(dcdy, 2));
d242 1
a242 7
   for (i = 0; i < nr; i++)
      lp_rast_shade_quads_mask(task,
                               &tri->inputs,
                               x + 4 * out[i].j,
                               y + 4 * out[i].i,
                               0xffff & ~out[i].mask);
}
d244 2
d247 4
d252 9
d262 1
d264 3
a266 28
void
lp_rast_triangle_3_4(struct lp_rasterizer_task *task,
                     const union lp_rast_cmd_arg arg)
{
   const struct lp_rast_triangle *tri = arg.triangle.tri;
   const struct lp_rast_plane *plane = GET_PLANES(tri);
   int x = (arg.triangle.plane_mask & 0xff) + task->x;
   int y = (arg.triangle.plane_mask >> 8) + task->y;

   __m128i p0 = _mm_load_si128((__m128i *)&plane[0]); /* c, dcdx, dcdy, eo */
   __m128i p1 = _mm_load_si128((__m128i *)&plane[1]); /* c, dcdx, dcdy, eo */
   __m128i p2 = _mm_load_si128((__m128i *)&plane[2]); /* c, dcdx, dcdy, eo */
   __m128i zero = _mm_setzero_si128();

   __m128i c;
   __m128i dcdx;
   __m128i dcdy;

   __m128i dcdx2;
   __m128i dcdx3;
   
   __m128i span_0;                /* 0,dcdx,2dcdx,3dcdx for plane 0 */
   __m128i span_1;                /* 0,dcdx,2dcdx,3dcdx for plane 1 */
   __m128i span_2;                /* 0,dcdx,2dcdx,3dcdx for plane 2 */
   __m128i unused;
   
   transpose4_epi32(&p0, &p1, &p2, &zero,
                    &c, &dcdx, &dcdy, &unused);
d268 1
a268 1
   /* Adjust dcdx;
d270 4
a273 39
   dcdx = _mm_sub_epi32(zero, dcdx);

   c = _mm_add_epi32(c, mm_mullo_epi32(dcdx, _mm_set1_epi32(x)));
   c = _mm_add_epi32(c, mm_mullo_epi32(dcdy, _mm_set1_epi32(y)));

   dcdx2 = _mm_add_epi32(dcdx, dcdx);
   dcdx3 = _mm_add_epi32(dcdx2, dcdx);

   transpose4_epi32(&zero, &dcdx, &dcdx2, &dcdx3,
                    &span_0, &span_1, &span_2, &unused);


   {
      __m128i c0_0 = _mm_add_epi32(SCALAR_EPI32(c, 0), span_0);
      __m128i c1_0 = _mm_add_epi32(SCALAR_EPI32(c, 1), span_1);
      __m128i c2_0 = _mm_add_epi32(SCALAR_EPI32(c, 2), span_2);
      
      __m128i c_0 = _mm_or_si128(_mm_or_si128(c0_0, c1_0), c2_0);

      __m128i c0_1 = _mm_add_epi32(c0_0, SCALAR_EPI32(dcdy, 0));
      __m128i c1_1 = _mm_add_epi32(c1_0, SCALAR_EPI32(dcdy, 1));
      __m128i c2_1 = _mm_add_epi32(c2_0, SCALAR_EPI32(dcdy, 2));

      __m128i c_1 = _mm_or_si128(_mm_or_si128(c0_1, c1_1), c2_1);
      __m128i c_01 = _mm_packs_epi32(c_0, c_1);

      __m128i c0_2 = _mm_add_epi32(c0_1, SCALAR_EPI32(dcdy, 0));
      __m128i c1_2 = _mm_add_epi32(c1_1, SCALAR_EPI32(dcdy, 1));
      __m128i c2_2 = _mm_add_epi32(c2_1, SCALAR_EPI32(dcdy, 2));

      __m128i c_2 = _mm_or_si128(_mm_or_si128(c0_2, c1_2), c2_2);

      __m128i c0_3 = _mm_add_epi32(c0_2, SCALAR_EPI32(dcdy, 0));
      __m128i c1_3 = _mm_add_epi32(c1_2, SCALAR_EPI32(dcdy, 1));
      __m128i c2_3 = _mm_add_epi32(c2_2, SCALAR_EPI32(dcdy, 2));

      __m128i c_3 = _mm_or_si128(_mm_or_si128(c0_3, c1_3), c2_3);
      __m128i c_23 = _mm_packs_epi32(c_2, c_3);
      __m128i c_0123 = _mm_packs_epi16(c_01, c_23);
d275 1
a275 1
      unsigned mask = _mm_movemask_epi8(c_0123);
d277 2
a278 6
      if (mask != 0xffff)
         lp_rast_shade_quads_mask(task,
                                  &tri->inputs,
                                  x,
                                  y,
                                  0xffff & ~mask);
a280 42

#undef NR_PLANES
#endif




#define TAG(x) x##_1
#define NR_PLANES 1
#include "lp_rast_tri_tmp.h"

#define TAG(x) x##_2
#define NR_PLANES 2
#include "lp_rast_tri_tmp.h"

#define TAG(x) x##_3
#define NR_PLANES 3
/*#define TRI_4 lp_rast_triangle_3_4*/
/*#define TRI_16 lp_rast_triangle_3_16*/
#include "lp_rast_tri_tmp.h"

#define TAG(x) x##_4
#define NR_PLANES 4
#define TRI_16 lp_rast_triangle_4_16
#include "lp_rast_tri_tmp.h"

#define TAG(x) x##_5
#define NR_PLANES 5
#include "lp_rast_tri_tmp.h"

#define TAG(x) x##_6
#define NR_PLANES 6
#include "lp_rast_tri_tmp.h"

#define TAG(x) x##_7
#define NR_PLANES 7
#include "lp_rast_tri_tmp.h"

#define TAG(x) x##_8
#define NR_PLANES 8
#include "lp_rast_tri_tmp.h"

@


1.1.1.2
log
@Import Mesa 9.2.0
@
text
@d37 1
d132 1
a132 1
   lp_rast_triangle_4(task, arg2);
a292 4
   /* Adjust so we can just check the sign bit (< 0 comparison), instead of having to do a less efficient <= 0 comparison */
   c = _mm_sub_epi32(c, _mm_set1_epi32(1));
   rej4 = _mm_add_epi32(rej4, _mm_set1_epi32(1));

d367 2
a368 2
   unsigned x = (arg.triangle.plane_mask & 0xff) + task->x;
   unsigned y = (arg.triangle.plane_mask >> 8) + task->y;
d386 1
a386 1

a395 3

   /* Adjust so we can just check the sign bit (< 0 comparison), instead of having to do a less efficient <= 0 comparison */
   c = _mm_sub_epi32(c, _mm_set1_epi32(1));
@


1.1.1.3
log
@Import Mesa 10.2.3
@
text
@d38 3
d69 2
d72 1
a72 1
build_mask_linear(int64_t c, int64_t dcdx, int64_t dcdy)
d74 1
a74 1
   unsigned mask = 0;
d76 21
a96 21
   int64_t c0 = c;
   int64_t c1 = c0 + dcdy;
   int64_t c2 = c1 + dcdy;
   int64_t c3 = c2 + dcdy;

   mask |= ((c0 + 0 * dcdx) >> FIXED_SHIFT) & (1 << 0);
   mask |= ((c0 + 1 * dcdx) >> FIXED_SHIFT) & (1 << 1);
   mask |= ((c0 + 2 * dcdx) >> FIXED_SHIFT) & (1 << 2);
   mask |= ((c0 + 3 * dcdx) >> FIXED_SHIFT) & (1 << 3);
   mask |= ((c1 + 0 * dcdx) >> FIXED_SHIFT) & (1 << 4);
   mask |= ((c1 + 1 * dcdx) >> FIXED_SHIFT) & (1 << 5);
   mask |= ((c1 + 2 * dcdx) >> FIXED_SHIFT) & (1 << 6);
   mask |= ((c1 + 3 * dcdx) >> FIXED_SHIFT) & (1 << 7);
   mask |= ((c2 + 0 * dcdx) >> FIXED_SHIFT) & (1 << 8);
   mask |= ((c2 + 1 * dcdx) >> FIXED_SHIFT) & (1 << 9);
   mask |= ((c2 + 2 * dcdx) >> FIXED_SHIFT) & (1 << 10);
   mask |= ((c2 + 3 * dcdx) >> FIXED_SHIFT) & (1 << 11);
   mask |= ((c3 + 0 * dcdx) >> FIXED_SHIFT) & (1 << 12);
   mask |= ((c3 + 1 * dcdx) >> FIXED_SHIFT) & (1 << 13);
   mask |= ((c3 + 2 * dcdx) >> FIXED_SHIFT) & (1 << 14);
   mask |= ((c3 + 3 * dcdx) >> FIXED_SHIFT) & (1 << 15);
d103 4
a106 4
build_masks(int64_t c,
            int64_t cdiff,
            int64_t dcdx,
            int64_t dcdy,
a124 7
lp_rast_triangle_3_4(struct lp_rasterizer_task *task,
                      const union lp_rast_cmd_arg arg)
{
   lp_rast_triangle_3_16(task, arg);
}

void
a133 2
#if !defined(PIPE_ARCH_SSE)

d135 1
a135 21
lp_rast_triangle_32_3_16(struct lp_rasterizer_task *task,
                         const union lp_rast_cmd_arg arg)
{
   union lp_rast_cmd_arg arg2;
   arg2.triangle.tri = arg.triangle.tri;
   arg2.triangle.plane_mask = (1<<3)-1;
   lp_rast_triangle_32_3(task, arg2);
}

void
lp_rast_triangle_32_4_16(struct lp_rasterizer_task *task,
                         const union lp_rast_cmd_arg arg)
{
   union lp_rast_cmd_arg arg2;
   arg2.triangle.tri = arg.triangle.tri;
   arg2.triangle.plane_mask = (1<<4)-1;
   lp_rast_triangle_32_4(task, arg2);
}

void
lp_rast_triangle_32_3_4(struct lp_rasterizer_task *task,
d138 1
a138 1
   lp_rast_triangle_32_3_16(task, arg);
d147 6
a152 6
build_masks_32(int c, 
               int cdiff,
               int dcdx,
               int dcdy,
               unsigned *outmask,
               unsigned *partmask)
d193 1
a193 1
build_mask_linear_32(int c, int dcdx, int dcdy)
d251 1
a251 1
lp_rast_triangle_32_3_16(struct lp_rasterizer_task *task,
d263 3
a265 3
   __m128i p0 = lp_plane_to_m128i(&plane[0]); /* c, dcdx, dcdy, eo */
   __m128i p1 = lp_plane_to_m128i(&plane[1]); /* c, dcdx, dcdy, eo */
   __m128i p2 = lp_plane_to_m128i(&plane[2]); /* c, dcdx, dcdy, eo */
d365 1
a365 1
lp_rast_triangle_32_3_4(struct lp_rasterizer_task *task,
d373 3
a375 3
   __m128i p0 = lp_plane_to_m128i(&plane[0]); /* c, dcdx, dcdy, eo */
   __m128i p1 = lp_plane_to_m128i(&plane[1]); /* c, dcdx, dcdy, eo */
   __m128i p2 = lp_plane_to_m128i(&plane[2]); /* c, dcdx, dcdy, eo */
d453 1
a453 2
#define BUILD_MASKS(c, cdiff, dcdx, dcdy, omask, pmask) build_masks(c, cdiff, dcdx, dcdy, omask, pmask)
#define BUILD_MASK_LINEAR(c, dcdx, dcdy) build_mask_linear(c, dcdx, dcdy)
d471 1
a471 1
/*#define TRI_16 lp_rast_triangle_4_16*/
a486 44
#define NR_PLANES 8
#include "lp_rast_tri_tmp.h"

#ifdef PIPE_ARCH_SSE
#undef BUILD_MASKS
#undef BUILD_MASK_LINEAR
#define BUILD_MASKS(c, cdiff, dcdx, dcdy, omask, pmask) build_masks_32((int)c, (int)cdiff, dcdx, dcdy, omask, pmask)
#define BUILD_MASK_LINEAR(c, dcdx, dcdy) build_mask_linear_32((int)c, dcdx, dcdy)
#endif

#define TAG(x) x##_32_1
#define NR_PLANES 1
#include "lp_rast_tri_tmp.h"

#define TAG(x) x##_32_2
#define NR_PLANES 2
#include "lp_rast_tri_tmp.h"

#define TAG(x) x##_32_3
#define NR_PLANES 3
/*#define TRI_4 lp_rast_triangle_3_4*/
/*#define TRI_16 lp_rast_triangle_3_16*/
#include "lp_rast_tri_tmp.h"

#define TAG(x) x##_32_4
#define NR_PLANES 4
#ifdef PIPE_ARCH_SSE
#define TRI_16 lp_rast_triangle_32_4_16
#endif
#include "lp_rast_tri_tmp.h"

#define TAG(x) x##_32_5
#define NR_PLANES 5
#include "lp_rast_tri_tmp.h"

#define TAG(x) x##_32_6
#define NR_PLANES 6
#include "lp_rast_tri_tmp.h"

#define TAG(x) x##_32_7
#define NR_PLANES 7
#include "lp_rast_tri_tmp.h"

#define TAG(x) x##_32_8
@


