head	1.4;
access;
symbols
	OPENBSD_5_8:1.3.0.6
	OPENBSD_5_8_BASE:1.3
	OPENBSD_5_7:1.3.0.4
	OPENBSD_5_7_BASE:1.3
	v10_2_9:1.1.1.2
	v10_4_3:1.1.1.2
	v10_2_7:1.1.1.2
	OPENBSD_5_6:1.3.0.2
	OPENBSD_5_6_BASE:1.3
	v10_2_3:1.1.1.2
	OPENBSD_5_5:1.2.0.2
	OPENBSD_5_5_BASE:1.2
	v9_2_5:1.1.1.1
	v9_2_3:1.1.1.1
	v9_2_2:1.1.1.1
	v9_2_1:1.1.1.1
	v9_2_0:1.1.1.1
	mesa:1.1.1
	OPENBSD_5_4:1.1.0.4
	OPENBSD_5_4_BASE:1.1
	OPENBSD_5_3:1.1.0.2
	OPENBSD_5_3_BASE:1.1;
locks; strict;
comment	@ * @;


1.4
date	2015.12.23.05.17.31;	author jsg;	state dead;
branches;
next	1.3;
commitid	TnlogFl9nOv2eaRf;

1.3
date	2014.07.09.21.08.53;	author jsg;	state Exp;
branches;
next	1.2;
commitid	WPD6rgPryPkvXOr9;

1.2
date	2013.09.05.14.00.38;	author jsg;	state Exp;
branches;
next	1.1;

1.1
date	2012.08.17.13.58.05;	author mpi;	state Exp;
branches
	1.1.1.1;
next	;

1.1.1.1
date	2013.09.05.13.11.32;	author jsg;	state Exp;
branches;
next	1.1.1.2;

1.1.1.2
date	2014.07.09.20.34.00;	author jsg;	state Exp;
branches;
next	;
commitid	3JhLfwcuBALP0ZR7;


desc
@@


1.4
log
@remove the now unused Mesa 10.2.9 code
@
text
@
#include <inttypes.h>

#include "util/u_inlines.h"
#include "util/u_memory.h"
#include "util/u_double_list.h"

#include "nouveau_winsys.h"
#include "nouveau_screen.h"
#include "nouveau_mm.h"

/* TODO: Higher orders can waste a lot of space for npot size buffers, should
 * add an extra cache for such buffer objects.
 *
 * HACK: Max order == 21 to accommodate TF2's 1.5 MiB, frequently reallocated
 * vertex buffer (VM flush (?) decreases performance dramatically).
 */

#define MM_MIN_ORDER 7 /* >= 6 to not violate ARB_map_buffer_alignment */
#define MM_MAX_ORDER 21

#define MM_NUM_BUCKETS (MM_MAX_ORDER - MM_MIN_ORDER + 1)

#define MM_MIN_SIZE (1 << MM_MIN_ORDER)
#define MM_MAX_SIZE (1 << MM_MAX_ORDER)

struct mm_bucket {
   struct list_head free;
   struct list_head used;
   struct list_head full;
   int num_free;
};

struct nouveau_mman {
   struct nouveau_device *dev;
   struct mm_bucket bucket[MM_NUM_BUCKETS];
   uint32_t domain;
   union nouveau_bo_config config;
   uint64_t allocated;
};

struct mm_slab {
   struct list_head head;
   struct nouveau_bo *bo;
   struct nouveau_mman *cache;
   int order;
   int count;
   int free;
   uint32_t bits[0];
};

static int
mm_slab_alloc(struct mm_slab *slab)
{
   int i, n, b;

   if (slab->free == 0)
      return -1;

   for (i = 0; i < (slab->count + 31) / 32; ++i) {
      b = ffs(slab->bits[i]) - 1;
      if (b >= 0) {
         n = i * 32 + b;
         assert(n < slab->count);
         slab->free--;
         slab->bits[i] &= ~(1 << b);
         return n;
      }
   }
   return -1;
}

static INLINE void
mm_slab_free(struct mm_slab *slab, int i)
{
   assert(i < slab->count);
   slab->bits[i / 32] |= 1 << (i % 32);
   slab->free++;
   assert(slab->free <= slab->count);
}

static INLINE int
mm_get_order(uint32_t size)
{
   int s = __builtin_clz(size) ^ 31;

   if (size > (1 << s))
      s += 1;
   return s;
}

static struct mm_bucket *
mm_bucket_by_order(struct nouveau_mman *cache, int order)
{
   if (order > MM_MAX_ORDER)
      return NULL;
   return &cache->bucket[MAX2(order, MM_MIN_ORDER) - MM_MIN_ORDER];
}

static struct mm_bucket *
mm_bucket_by_size(struct nouveau_mman *cache, unsigned size)
{
   return mm_bucket_by_order(cache, mm_get_order(size));
}

/* size of bo allocation for slab with chunks of (1 << chunk_order) bytes */
static INLINE uint32_t
mm_default_slab_size(unsigned chunk_order)
{
   static const int8_t slab_order[MM_MAX_ORDER - MM_MIN_ORDER + 1] =
   {
      12, 12, 13, 14, 14, 17, 17, 17, 17, 19, 19, 20, 21, 22, 22
   };

   assert(chunk_order <= MM_MAX_ORDER && chunk_order >= MM_MIN_ORDER);

   return 1 << slab_order[chunk_order - MM_MIN_ORDER];
}

static int
mm_slab_new(struct nouveau_mman *cache, int chunk_order)
{
   struct mm_slab *slab;
   int words, ret;
   const uint32_t size = mm_default_slab_size(chunk_order);

   words = ((size >> chunk_order) + 31) / 32;
   assert(words);

   slab = MALLOC(sizeof(struct mm_slab) + words * 4);
   if (!slab)
      return PIPE_ERROR_OUT_OF_MEMORY;

   memset(&slab->bits[0], ~0, words * 4);

   slab->bo = NULL;

   ret = nouveau_bo_new(cache->dev, cache->domain, 0, size, &cache->config,
                        &slab->bo);
   if (ret) {
      FREE(slab);
      return PIPE_ERROR_OUT_OF_MEMORY;
   }

   LIST_INITHEAD(&slab->head);

   slab->cache = cache;
   slab->order = chunk_order;
   slab->count = slab->free = size >> chunk_order;

   LIST_ADD(&slab->head, &mm_bucket_by_order(cache, chunk_order)->free);

   cache->allocated += size;

   if (nouveau_mesa_debug)
      debug_printf("MM: new slab, total memory = %"PRIu64" KiB\n",
                   cache->allocated / 1024);

   return PIPE_OK;
}

/* @@return token to identify slab or NULL if we just allocated a new bo */
struct nouveau_mm_allocation *
nouveau_mm_allocate(struct nouveau_mman *cache,
                    uint32_t size, struct nouveau_bo **bo, uint32_t *offset)
{
   struct mm_bucket *bucket;
   struct mm_slab *slab;
   struct nouveau_mm_allocation *alloc;
   int ret;

   bucket = mm_bucket_by_size(cache, size);
   if (!bucket) {
      ret = nouveau_bo_new(cache->dev, cache->domain, 0, size, &cache->config,
                           bo);
      if (ret)
         debug_printf("bo_new(%x, %x): %i\n",
                      size, cache->config.nv50.memtype, ret);

      *offset = 0;
      return NULL;
   }

   if (!LIST_IS_EMPTY(&bucket->used)) {
      slab = LIST_ENTRY(struct mm_slab, bucket->used.next, head);
   } else {
      if (LIST_IS_EMPTY(&bucket->free)) {
         mm_slab_new(cache, MAX2(mm_get_order(size), MM_MIN_ORDER));
      }
      slab = LIST_ENTRY(struct mm_slab, bucket->free.next, head);

      LIST_DEL(&slab->head);
      LIST_ADD(&slab->head, &bucket->used);
   }

   *offset = mm_slab_alloc(slab) << slab->order;

   alloc = MALLOC_STRUCT(nouveau_mm_allocation);
   if (!alloc)
      return NULL;

   nouveau_bo_ref(slab->bo, bo);

   if (slab->free == 0) {
      LIST_DEL(&slab->head);
      LIST_ADD(&slab->head, &bucket->full);
   }

   alloc->next = NULL;
   alloc->offset = *offset;
   alloc->priv = (void *)slab;

   return alloc;
}

void
nouveau_mm_free(struct nouveau_mm_allocation *alloc)
{
   struct mm_slab *slab = (struct mm_slab *)alloc->priv;
   struct mm_bucket *bucket = mm_bucket_by_order(slab->cache, slab->order);

   mm_slab_free(slab, alloc->offset >> slab->order);

   if (slab->free == slab->count) {
      LIST_DEL(&slab->head);
      LIST_ADDTAIL(&slab->head, &bucket->free);
   } else
   if (slab->free == 1) {
      LIST_DEL(&slab->head);
      LIST_ADDTAIL(&slab->head, &bucket->used);
   }

   FREE(alloc);
}

void
nouveau_mm_free_work(void *data)
{
   nouveau_mm_free(data);
}

struct nouveau_mman *
nouveau_mm_create(struct nouveau_device *dev, uint32_t domain,
                  union nouveau_bo_config *config)
{
   struct nouveau_mman *cache = MALLOC_STRUCT(nouveau_mman);
   int i;

   if (!cache)
      return NULL;

   cache->dev = dev;
   cache->domain = domain;
   cache->config = *config;
   cache->allocated = 0;

   for (i = 0; i < MM_NUM_BUCKETS; ++i) {
      LIST_INITHEAD(&cache->bucket[i].free);
      LIST_INITHEAD(&cache->bucket[i].used);
      LIST_INITHEAD(&cache->bucket[i].full);
   }

   return cache;
}

static INLINE void
nouveau_mm_free_slabs(struct list_head *head)
{
   struct mm_slab *slab, *next;

   LIST_FOR_EACH_ENTRY_SAFE(slab, next, head, head) {
      LIST_DEL(&slab->head);
      nouveau_bo_ref(NULL, &slab->bo);
      FREE(slab);
   }
}

void
nouveau_mm_destroy(struct nouveau_mman *cache)
{
   int i;

   if (!cache)
      return;

   for (i = 0; i < MM_NUM_BUCKETS; ++i) {
      if (!LIST_IS_EMPTY(&cache->bucket[i].used) ||
          !LIST_IS_EMPTY(&cache->bucket[i].full))
         debug_printf("WARNING: destroying GPU memory cache "
                      "with some buffers still in use\n");

      nouveau_mm_free_slabs(&cache->bucket[i].free);
      nouveau_mm_free_slabs(&cache->bucket[i].used);
      nouveau_mm_free_slabs(&cache->bucket[i].full);
   }

   FREE(cache);
}
@


1.3
log
@Merge Mesa 10.2.3
tested by matthieu@@ kettenis@@ mpi@@ brett@@ and myself across a
diverse range of hardware
@
text
@@


1.2
log
@Merge Mesa 9.2.0
@
text
@a298 1

@


1.1
log
@Upate to libGL 7.11.2

Tested by jsg@@, matthieu@@ and ajacoutot@@, ok mattieu@@
@
text
@d2 2
d8 1
d12 6
a17 1
#include "nouveau/nouveau_bo.h"
d19 2
a20 2
#define MM_MIN_ORDER 7
#define MM_MAX_ORDER 20
a36 1
   uint32_t storage_type;
d38 1
d112 1
a112 1
      12, 12, 13, 14, 14, 17, 17, 17, 17, 19, 19, 20, 21, 22
d137 3
a139 2
   ret = nouveau_bo_new_tile(cache->dev, cache->domain, 0, size,
                             0, cache->storage_type, &slab->bo);
d155 3
a157 2
   debug_printf("MM: new slab, total memory = %llu KiB\n",
                cache->allocated / 1024);
d165 1
a165 1
                 uint32_t size, struct nouveau_bo **bo, uint32_t *offset)
d174 2
a175 2
      ret = nouveau_bo_new_tile(cache->dev, cache->domain, 0, size,
                                0, cache->storage_type, bo);
d177 2
a178 1
         debug_printf("bo_new(%x, %x): %i\n", size, cache->storage_type, ret);
d224 4
d230 1
a230 5

      if (slab->count > 1)
         LIST_ADDTAIL(&slab->head, &bucket->used);
      else
         LIST_ADDTAIL(&slab->head, &bucket->free);
d244 1
a244 1
               uint32_t storage_type)
d254 1
a254 1
   cache->storage_type = storage_type;
@


1.1.1.1
log
@Import Mesa 9.2.0
@
text
@a1 2
#include <inttypes.h>

a5 1
#include "nouveau_winsys.h"
d9 1
a9 6
/* TODO: Higher orders can waste a lot of space for npot size buffers, should
 * add an extra cache for such buffer objects.
 *
 * HACK: Max order == 21 to accommodate TF2's 1.5 MiB, frequently reallocated
 * vertex buffer (VM flush (?) decreases performance dramatically).
 */
d11 2
a12 2
#define MM_MIN_ORDER 7 /* >= 6 to not violate ARB_map_buffer_alignment */
#define MM_MAX_ORDER 21
d29 1
a30 1
   union nouveau_bo_config config;
d104 1
a104 1
      12, 12, 13, 14, 14, 17, 17, 17, 17, 19, 19, 20, 21, 22, 22
d129 2
a130 3

   ret = nouveau_bo_new(cache->dev, cache->domain, 0, size, &cache->config,
                        &slab->bo);
d146 2
a147 3
   if (nouveau_mesa_debug)
      debug_printf("MM: new slab, total memory = %"PRIu64" KiB\n",
                   cache->allocated / 1024);
d155 1
a155 1
                    uint32_t size, struct nouveau_bo **bo, uint32_t *offset)
d164 2
a165 2
      ret = nouveau_bo_new(cache->dev, cache->domain, 0, size, &cache->config,
                           bo);
d167 1
a167 2
         debug_printf("bo_new(%x, %x): %i\n",
                      size, cache->config.nv50.memtype, ret);
a212 4
   if (slab->free == slab->count) {
      LIST_DEL(&slab->head);
      LIST_ADDTAIL(&slab->head, &bucket->free);
   } else
d215 5
a219 1
      LIST_ADDTAIL(&slab->head, &bucket->used);
d233 1
a233 1
                  union nouveau_bo_config *config)
d243 1
a243 1
   cache->config = *config;
@


1.1.1.2
log
@Import Mesa 10.2.3
@
text
@d299 1
@


