head	1.7;
access;
symbols
	OPENBSD_5_8:1.6.0.4
	OPENBSD_5_8_BASE:1.6
	OPENBSD_5_7:1.6.0.2
	OPENBSD_5_7_BASE:1.6
	v10_2_9:1.1.1.5
	v10_4_3:1.1.1.4
	v10_2_7:1.1.1.3
	OPENBSD_5_6:1.3.0.2
	OPENBSD_5_6_BASE:1.3
	v10_2_3:1.1.1.2
	OPENBSD_5_5:1.2.0.2
	OPENBSD_5_5_BASE:1.2
	v9_2_5:1.1.1.1
	v9_2_3:1.1.1.1
	v9_2_2:1.1.1.1
	v9_2_1:1.1.1.1
	v9_2_0:1.1.1.1
	mesa:1.1.1
	OPENBSD_5_4:1.1.0.4
	OPENBSD_5_4_BASE:1.1
	OPENBSD_5_3:1.1.0.2
	OPENBSD_5_3_BASE:1.1;
locks; strict;
comment	@ * @;


1.7
date	2015.12.23.05.17.42;	author jsg;	state dead;
branches;
next	1.6;
commitid	TnlogFl9nOv2eaRf;

1.6
date	2015.02.20.23.09.56;	author jsg;	state Exp;
branches;
next	1.5;
commitid	4ry2gvZGMXkCUD2n;

1.5
date	2015.01.25.14.41.19;	author jsg;	state Exp;
branches;
next	1.4;
commitid	mcxB0JvoI9gTDYXU;

1.4
date	2014.09.07.15.20.07;	author jsg;	state Exp;
branches;
next	1.3;
commitid	7kimTMT4YlQauAIU;

1.3
date	2014.07.09.21.08.57;	author jsg;	state Exp;
branches;
next	1.2;
commitid	WPD6rgPryPkvXOr9;

1.2
date	2013.09.05.14.02.16;	author jsg;	state Exp;
branches;
next	1.1;

1.1
date	2012.08.17.13.58.09;	author mpi;	state Exp;
branches
	1.1.1.1;
next	;

1.1.1.1
date	2013.09.05.13.13.54;	author jsg;	state Exp;
branches;
next	1.1.1.2;

1.1.1.2
date	2014.07.09.20.34.23;	author jsg;	state Exp;
branches;
next	1.1.1.3;
commitid	3JhLfwcuBALP0ZR7;

1.1.1.3
date	2014.09.07.15.04.19;	author jsg;	state Exp;
branches;
next	1.1.1.4;
commitid	dm8VnQHhowGHmemJ;

1.1.1.4
date	2015.01.25.14.09.54;	author jsg;	state Exp;
branches;
next	1.1.1.5;
commitid	ce2W5rH5aF7VS9gi;

1.1.1.5
date	2015.02.20.22.47.01;	author jsg;	state Exp;
branches;
next	;
commitid	F54a1i0WXHMxq7kE;


desc
@@


1.7
log
@remove the now unused Mesa 10.2.9 code
@
text
@/*
 * Copyright © 2009 Corbin Simpson
 * Copyright © 2011 Marek Olšák <maraeo@@gmail.com>
 * All Rights Reserved.
 *
 * Permission is hereby granted, free of charge, to any person obtaining
 * a copy of this software and associated documentation files (the
 * "Software"), to deal in the Software without restriction, including
 * without limitation the rights to use, copy, modify, merge, publish,
 * distribute, sub license, and/or sell copies of the Software, and to
 * permit persons to whom the Software is furnished to do so, subject to
 * the following conditions:
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES
 * OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NON-INFRINGEMENT. IN NO EVENT SHALL THE COPYRIGHT HOLDERS, AUTHORS
 * AND/OR ITS SUPPLIERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
 * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
 * USE OR OTHER DEALINGS IN THE SOFTWARE.
 *
 * The above copyright notice and this permission notice (including the
 * next paragraph) shall be included in all copies or substantial portions
 * of the Software.
 */
/*
 * Authors:
 *      Corbin Simpson <MostAwesomeDude@@gmail.com>
 *      Joakim Sindholt <opensource@@zhasha.com>
 *      Marek Olšák <maraeo@@gmail.com>
 */

#include "radeon_drm_bo.h"
#include "radeon_drm_cs.h"
#include "radeon_drm_public.h"

#include "pipebuffer/pb_bufmgr.h"
#include "util/u_memory.h"
#include "util/u_hash_table.h"

#include <xf86drm.h>
#include <stdio.h>
#include <sys/types.h>
#include <sys/stat.h>
#include <unistd.h>

static struct util_hash_table *fd_tab = NULL;
pipe_static_mutex(fd_tab_mutex);

/* Enable/disable feature access for one command stream.
 * If enable == TRUE, return TRUE on success.
 * Otherwise, return FALSE.
 *
 * We basically do the same thing kernel does, because we have to deal
 * with multiple contexts (here command streams) backed by one winsys. */
static boolean radeon_set_fd_access(struct radeon_drm_cs *applier,
                                    struct radeon_drm_cs **owner,
                                    pipe_mutex *mutex,
                                    unsigned request, const char *request_name,
                                    boolean enable)
{
    struct drm_radeon_info info;
    unsigned value = enable ? 1 : 0;

    memset(&info, 0, sizeof(info));

    pipe_mutex_lock(*mutex);

    /* Early exit if we are sure the request will fail. */
    if (enable) {
        if (*owner) {
            pipe_mutex_unlock(*mutex);
            return FALSE;
        }
    } else {
        if (*owner != applier) {
            pipe_mutex_unlock(*mutex);
            return FALSE;
        }
    }

    /* Pass through the request to the kernel. */
    info.value = (unsigned long)&value;
    info.request = request;
    if (drmCommandWriteRead(applier->ws->fd, DRM_RADEON_INFO,
                            &info, sizeof(info)) != 0) {
        pipe_mutex_unlock(*mutex);
        return FALSE;
    }

    /* Update the rights in the winsys. */
    if (enable) {
        if (value) {
            *owner = applier;
            printf("radeon: Acquired access to %s.\n", request_name);
            pipe_mutex_unlock(*mutex);
            return TRUE;
        }
    } else {
        *owner = NULL;
        printf("radeon: Released access to %s.\n", request_name);
    }

    pipe_mutex_unlock(*mutex);
    return FALSE;
}

static boolean radeon_get_drm_value(int fd, unsigned request,
                                    const char *errname, uint32_t *out)
{
    struct drm_radeon_info info;
    int retval;

    memset(&info, 0, sizeof(info));

    info.value = (unsigned long)out;
    info.request = request;

    retval = drmCommandWriteRead(fd, DRM_RADEON_INFO, &info, sizeof(info));
    if (retval) {
        if (errname) {
            fprintf(stderr, "radeon: Failed to get %s, error number %d\n",
                    errname, retval);
        }
        return FALSE;
    }
    return TRUE;
}

/* Helper function to do the ioctls needed for setup and init. */
static boolean do_winsys_init(struct radeon_drm_winsys *ws)
{
    struct drm_radeon_gem_info gem_info;
    int retval;
    drmVersionPtr version;

    memset(&gem_info, 0, sizeof(gem_info));

    /* We do things in a specific order here.
     *
     * DRM version first. We need to be sure we're running on a KMS chipset.
     * This is also for some features.
     *
     * Then, the PCI ID. This is essential and should return usable numbers
     * for all Radeons. If this fails, we probably got handed an FD for some
     * non-Radeon card.
     *
     * The GEM info is actually bogus on the kernel side, as well as our side
     * (see radeon_gem_info_ioctl in radeon_gem.c) but that's alright because
     * we don't actually use the info for anything yet.
     *
     * The GB and Z pipe requests should always succeed, but they might not
     * return sensical values for all chipsets, but that's alright because
     * the pipe drivers already know that.
     */

    /* Get DRM version. */
    version = drmGetVersion(ws->fd);
    if (version->version_major != 2 ||
        version->version_minor < 3) {
        fprintf(stderr, "%s: DRM version is %d.%d.%d but this driver is "
                "only compatible with 2.3.x (kernel 2.6.34) or later.\n",
                __FUNCTION__,
                version->version_major,
                version->version_minor,
                version->version_patchlevel);
        drmFreeVersion(version);
        return FALSE;
    }

    ws->info.drm_major = version->version_major;
    ws->info.drm_minor = version->version_minor;
    ws->info.drm_patchlevel = version->version_patchlevel;
    drmFreeVersion(version);

    /* Get PCI ID. */
    if (!radeon_get_drm_value(ws->fd, RADEON_INFO_DEVICE_ID, "PCI ID",
                              &ws->info.pci_id))
        return FALSE;

    /* Check PCI ID. */
    switch (ws->info.pci_id) {
#define CHIPSET(pci_id, name, cfamily) case pci_id: ws->info.family = CHIP_##cfamily; ws->gen = DRV_R300; break;
#include "pci_ids/r300_pci_ids.h"
#undef CHIPSET

#define CHIPSET(pci_id, name, cfamily) case pci_id: ws->info.family = CHIP_##cfamily; ws->gen = DRV_R600; break;
#include "pci_ids/r600_pci_ids.h"
#undef CHIPSET

#define CHIPSET(pci_id, name, cfamily) case pci_id: ws->info.family = CHIP_##cfamily; ws->gen = DRV_SI; break;
#include "pci_ids/radeonsi_pci_ids.h"
#undef CHIPSET

    default:
        fprintf(stderr, "radeon: Invalid PCI ID.\n");
        return FALSE;
    }

    switch (ws->info.family) {
    default:
    case CHIP_UNKNOWN:
        fprintf(stderr, "radeon: Unknown family.\n");
        return FALSE;
    case CHIP_R300:
    case CHIP_R350:
    case CHIP_RV350:
    case CHIP_RV370:
    case CHIP_RV380:
    case CHIP_RS400:
    case CHIP_RC410:
    case CHIP_RS480:
        ws->info.chip_class = R300;
        break;
    case CHIP_R420:     /* R4xx-based cores. */
    case CHIP_R423:
    case CHIP_R430:
    case CHIP_R480:
    case CHIP_R481:
    case CHIP_RV410:
    case CHIP_RS600:
    case CHIP_RS690:
    case CHIP_RS740:
        ws->info.chip_class = R400;
        break;
    case CHIP_RV515:    /* R5xx-based cores. */
    case CHIP_R520:
    case CHIP_RV530:
    case CHIP_R580:
    case CHIP_RV560:
    case CHIP_RV570:
        ws->info.chip_class = R500;
        break;
    case CHIP_R600:
    case CHIP_RV610:
    case CHIP_RV630:
    case CHIP_RV670:
    case CHIP_RV620:
    case CHIP_RV635:
    case CHIP_RS780:
    case CHIP_RS880:
        ws->info.chip_class = R600;
        break;
    case CHIP_RV770:
    case CHIP_RV730:
    case CHIP_RV710:
    case CHIP_RV740:
        ws->info.chip_class = R700;
        break;
    case CHIP_CEDAR:
    case CHIP_REDWOOD:
    case CHIP_JUNIPER:
    case CHIP_CYPRESS:
    case CHIP_HEMLOCK:
    case CHIP_PALM:
    case CHIP_SUMO:
    case CHIP_SUMO2:
    case CHIP_BARTS:
    case CHIP_TURKS:
    case CHIP_CAICOS:
        ws->info.chip_class = EVERGREEN;
        break;
    case CHIP_CAYMAN:
    case CHIP_ARUBA:
        ws->info.chip_class = CAYMAN;
        break;
    case CHIP_TAHITI:
    case CHIP_PITCAIRN:
    case CHIP_VERDE:
    case CHIP_OLAND:
    case CHIP_HAINAN:
        ws->info.chip_class = SI;
        break;
    case CHIP_BONAIRE:
    case CHIP_KAVERI:
    case CHIP_KABINI:
    case CHIP_HAWAII:
    case CHIP_MULLINS:
        ws->info.chip_class = CIK;
        break;
    }

    /* Check for dma */
    ws->info.r600_has_dma = FALSE;
    /* DMA is disabled on R700. There is IB corruption and hangs. */
    if (ws->info.chip_class >= EVERGREEN && ws->info.drm_minor >= 27) {
        ws->info.r600_has_dma = TRUE;
    }

    /* Check for UVD and VCE */
    ws->info.has_uvd = FALSE;
    ws->info.vce_fw_version = 0x00000000;
    if (ws->info.drm_minor >= 32) {
	uint32_t value = RADEON_CS_RING_UVD;
        if (radeon_get_drm_value(ws->fd, RADEON_INFO_RING_WORKING,
                                 "UVD Ring working", &value))
            ws->info.has_uvd = value;

        value = RADEON_CS_RING_VCE;
        if (radeon_get_drm_value(ws->fd, RADEON_INFO_RING_WORKING,
                                 NULL, &value) && value) {

            if (radeon_get_drm_value(ws->fd, RADEON_INFO_VCE_FW_VERSION,
                                     "VCE FW version", &value))
                ws->info.vce_fw_version = value;
	}
    }

    /* Get GEM info. */
    retval = drmCommandWriteRead(ws->fd, DRM_RADEON_GEM_INFO,
            &gem_info, sizeof(gem_info));
    if (retval) {
        fprintf(stderr, "radeon: Failed to get MM info, error number %d\n",
                retval);
        return FALSE;
    }
    ws->info.gart_size = gem_info.gart_size;
    ws->info.vram_size = gem_info.vram_size;

    /* Get max clock frequency info and convert it to MHz */
    radeon_get_drm_value(ws->fd, RADEON_INFO_MAX_SCLK, NULL,
                         &ws->info.max_sclk);
    ws->info.max_sclk /= 1000;

    ws->num_cpus = sysconf(_SC_NPROCESSORS_ONLN);

    /* Generation-specific queries. */
    if (ws->gen == DRV_R300) {
        if (!radeon_get_drm_value(ws->fd, RADEON_INFO_NUM_GB_PIPES,
                                  "GB pipe count",
                                  &ws->info.r300_num_gb_pipes))
            return FALSE;

        if (!radeon_get_drm_value(ws->fd, RADEON_INFO_NUM_Z_PIPES,
                                  "Z pipe count",
                                  &ws->info.r300_num_z_pipes))
            return FALSE;
    }
    else if (ws->gen >= DRV_R600) {
        if (ws->info.drm_minor >= 9 &&
            !radeon_get_drm_value(ws->fd, RADEON_INFO_NUM_BACKENDS,
                                  "num backends",
                                  &ws->info.r600_num_backends))
            return FALSE;

        /* get the GPU counter frequency, failure is not fatal */
        radeon_get_drm_value(ws->fd, RADEON_INFO_CLOCK_CRYSTAL_FREQ, NULL,
                             &ws->info.r600_clock_crystal_freq);

        radeon_get_drm_value(ws->fd, RADEON_INFO_TILING_CONFIG, NULL,
                             &ws->info.r600_tiling_config);

        if (ws->info.drm_minor >= 11) {
            radeon_get_drm_value(ws->fd, RADEON_INFO_NUM_TILE_PIPES, NULL,
                                 &ws->info.r600_num_tile_pipes);

            if (radeon_get_drm_value(ws->fd, RADEON_INFO_BACKEND_MAP, NULL,
                                      &ws->info.r600_backend_map))
                ws->info.r600_backend_map_valid = TRUE;
        }

        ws->info.r600_virtual_address = FALSE;
        if (ws->info.drm_minor >= 13) {
            uint32_t ib_vm_max_size;

            ws->info.r600_virtual_address = TRUE;
            if (!radeon_get_drm_value(ws->fd, RADEON_INFO_VA_START, NULL,
                                      &ws->va_start))
                ws->info.r600_virtual_address = FALSE;
            if (!radeon_get_drm_value(ws->fd, RADEON_INFO_IB_VM_MAX_SIZE, NULL,
                                      &ib_vm_max_size))
                ws->info.r600_virtual_address = FALSE;
        }
	if (ws->gen == DRV_R600 && !debug_get_bool_option("RADEON_VA", FALSE))
		ws->info.r600_virtual_address = FALSE;
    }

    /* Get max pipes, this is only needed for compute shaders.  All evergreen+
     * chips have at least 2 pipes, so we use 2 as a default. */
    ws->info.r600_max_pipes = 2;
    radeon_get_drm_value(ws->fd, RADEON_INFO_MAX_PIPES, NULL,
                         &ws->info.r600_max_pipes);

    radeon_get_drm_value(ws->fd, RADEON_INFO_ACCEL_WORKING2, NULL,
                         &ws->accel_working2);
    if (ws->info.family == CHIP_HAWAII && ws->accel_working2 < 2) {
        fprintf(stderr, "radeon: GPU acceleration for Hawaii disabled, "
                "returned accel_working2 value %u is smaller than 2. "
                "Please install a newer kernel.\n",
                ws->accel_working2);
        return FALSE;
    }

    if (radeon_get_drm_value(ws->fd, RADEON_INFO_SI_TILE_MODE_ARRAY, NULL,
                             ws->info.si_tile_mode_array)) {
        ws->info.si_tile_mode_array_valid = TRUE;
    }

    if (radeon_get_drm_value(ws->fd, RADEON_INFO_CIK_MACROTILE_MODE_ARRAY, NULL,
                             ws->info.cik_macrotile_mode_array)) {
        ws->info.cik_macrotile_mode_array_valid = TRUE;
    }

    return TRUE;
}

static void radeon_winsys_destroy(struct radeon_winsys *rws)
{
    struct radeon_drm_winsys *ws = (struct radeon_drm_winsys*)rws;

    if (ws->thread) {
        ws->kill_thread = 1;
        pipe_semaphore_signal(&ws->cs_queued);
        pipe_thread_wait(ws->thread);
    }
    pipe_semaphore_destroy(&ws->cs_queued);

    pipe_mutex_destroy(ws->hyperz_owner_mutex);
    pipe_mutex_destroy(ws->cmask_owner_mutex);
    pipe_mutex_destroy(ws->cs_stack_lock);

    ws->cman->destroy(ws->cman);
    ws->kman->destroy(ws->kman);
    if (ws->gen >= DRV_R600) {
        radeon_surface_manager_free(ws->surf_man);
    }
    FREE(rws);
}

static void radeon_query_info(struct radeon_winsys *rws,
                              struct radeon_info *info)
{
    *info = ((struct radeon_drm_winsys *)rws)->info;
}

static boolean radeon_cs_request_feature(struct radeon_winsys_cs *rcs,
                                         enum radeon_feature_id fid,
                                         boolean enable)
{
    struct radeon_drm_cs *cs = radeon_drm_cs(rcs);

    switch (fid) {
    case RADEON_FID_R300_HYPERZ_ACCESS:
        return radeon_set_fd_access(cs, &cs->ws->hyperz_owner,
                                    &cs->ws->hyperz_owner_mutex,
                                    RADEON_INFO_WANT_HYPERZ, "Hyper-Z",
                                    enable);

    case RADEON_FID_R300_CMASK_ACCESS:
        return radeon_set_fd_access(cs, &cs->ws->cmask_owner,
                                    &cs->ws->cmask_owner_mutex,
                                    RADEON_INFO_WANT_CMASK, "AA optimizations",
                                    enable);
    }
    return FALSE;
}

static int radeon_drm_winsys_surface_init(struct radeon_winsys *rws,
                                          struct radeon_surface *surf)
{
    struct radeon_drm_winsys *ws = (struct radeon_drm_winsys*)rws;

    return radeon_surface_init(ws->surf_man, surf);
}

static int radeon_drm_winsys_surface_best(struct radeon_winsys *rws,
                                          struct radeon_surface *surf)
{
    struct radeon_drm_winsys *ws = (struct radeon_drm_winsys*)rws;

    return radeon_surface_best(ws->surf_man, surf);
}

static uint64_t radeon_query_value(struct radeon_winsys *rws,
                                   enum radeon_value_id value)
{
    struct radeon_drm_winsys *ws = (struct radeon_drm_winsys*)rws;
    uint64_t retval = 0;

    switch (value) {
    case RADEON_REQUESTED_VRAM_MEMORY:
        return ws->allocated_vram;
    case RADEON_REQUESTED_GTT_MEMORY:
        return ws->allocated_gtt;
    case RADEON_BUFFER_WAIT_TIME_NS:
        return ws->buffer_wait_time;
    case RADEON_TIMESTAMP:
        if (ws->info.drm_minor < 20 || ws->gen < DRV_R600) {
            assert(0);
            return 0;
        }

        radeon_get_drm_value(ws->fd, RADEON_INFO_TIMESTAMP, "timestamp",
                             (uint32_t*)&retval);
        return retval;
    case RADEON_NUM_CS_FLUSHES:
        return ws->num_cs_flushes;
    case RADEON_NUM_BYTES_MOVED:
        radeon_get_drm_value(ws->fd, RADEON_INFO_NUM_BYTES_MOVED,
                             "num-bytes-moved", (uint32_t*)&retval);
        return retval;
    case RADEON_VRAM_USAGE:
        radeon_get_drm_value(ws->fd, RADEON_INFO_VRAM_USAGE,
                             "vram-usage", (uint32_t*)&retval);
        return retval;
    case RADEON_GTT_USAGE:
        radeon_get_drm_value(ws->fd, RADEON_INFO_GTT_USAGE,
                             "gtt-usage", (uint32_t*)&retval);
        return retval;
    }
    return 0;
}

static unsigned hash_fd(void *key)
{
    int fd = pointer_to_intptr(key);
    struct stat stat;
    fstat(fd, &stat);

    return stat.st_dev ^ stat.st_ino ^ stat.st_rdev;
}

static int compare_fd(void *key1, void *key2)
{
    int fd1 = pointer_to_intptr(key1);
    int fd2 = pointer_to_intptr(key2);
    struct stat stat1, stat2;
    fstat(fd1, &stat1);
    fstat(fd2, &stat2);

    return stat1.st_dev != stat2.st_dev ||
           stat1.st_ino != stat2.st_ino ||
           stat1.st_rdev != stat2.st_rdev;
}

void radeon_drm_ws_queue_cs(struct radeon_drm_winsys *ws, struct radeon_drm_cs *cs)
{
retry:
    pipe_mutex_lock(ws->cs_stack_lock);
    if (ws->ncs >= RING_LAST) {
        /* no room left for a flush */
        pipe_mutex_unlock(ws->cs_stack_lock);
        goto retry;
    }
    ws->cs_stack[ws->ncs++] = cs;
    pipe_mutex_unlock(ws->cs_stack_lock);
    pipe_semaphore_signal(&ws->cs_queued);
}

static PIPE_THREAD_ROUTINE(radeon_drm_cs_emit_ioctl, param)
{
    struct radeon_drm_winsys *ws = (struct radeon_drm_winsys *)param;
    struct radeon_drm_cs *cs;
    unsigned i;

    while (1) {
        pipe_semaphore_wait(&ws->cs_queued);
        if (ws->kill_thread)
            break;

        pipe_mutex_lock(ws->cs_stack_lock);
        cs = ws->cs_stack[0];
        for (i = 1; i < ws->ncs; i++)
            ws->cs_stack[i - 1] = ws->cs_stack[i];
        ws->cs_stack[--ws->ncs] = NULL;
        pipe_mutex_unlock(ws->cs_stack_lock);

        if (cs) {
            radeon_drm_cs_emit_ioctl_oneshot(cs, cs->cst);
            pipe_semaphore_signal(&cs->flush_completed);
        }
    }
    pipe_mutex_lock(ws->cs_stack_lock);
    for (i = 0; i < ws->ncs; i++) {
        pipe_semaphore_signal(&ws->cs_stack[i]->flush_completed);
        ws->cs_stack[i] = NULL;
    }
    ws->ncs = 0;
    pipe_mutex_unlock(ws->cs_stack_lock);
    return 0;
}

DEBUG_GET_ONCE_BOOL_OPTION(thread, "RADEON_THREAD", TRUE)
static PIPE_THREAD_ROUTINE(radeon_drm_cs_emit_ioctl, param);

static bool radeon_winsys_unref(struct radeon_winsys *ws)
{
    struct radeon_drm_winsys *rws = (struct radeon_drm_winsys*)ws;
    bool destroy;

    /* When the reference counter drops to zero, remove the fd from the table.
     * This must happen while the mutex is locked, so that
     * radeon_drm_winsys_create in another thread doesn't get the winsys
     * from the table when the counter drops to 0. */
    pipe_mutex_lock(fd_tab_mutex);

    destroy = pipe_reference(&rws->reference, NULL);
    if (destroy && fd_tab)
        util_hash_table_remove(fd_tab, intptr_to_pointer(rws->fd));

    pipe_mutex_unlock(fd_tab_mutex);
    return destroy;
}

PUBLIC struct radeon_winsys *
radeon_drm_winsys_create(int fd, radeon_screen_create_t screen_create)
{
    struct radeon_drm_winsys *ws;

    pipe_mutex_lock(fd_tab_mutex);
    if (!fd_tab) {
        fd_tab = util_hash_table_create(hash_fd, compare_fd);
    }

    ws = util_hash_table_get(fd_tab, intptr_to_pointer(fd));
    if (ws) {
        pipe_reference(NULL, &ws->reference);
        pipe_mutex_unlock(fd_tab_mutex);
        return &ws->base;
    }

    ws = CALLOC_STRUCT(radeon_drm_winsys);
    if (!ws) {
        pipe_mutex_unlock(fd_tab_mutex);
        return NULL;
    }

    ws->fd = fd;

    if (!do_winsys_init(ws))
        goto fail;

    /* Create managers. */
    ws->kman = radeon_bomgr_create(ws);
    if (!ws->kman)
        goto fail;
    ws->cman = pb_cache_manager_create(ws->kman, 1000000, 2.0f, 0);
    if (!ws->cman)
        goto fail;

    if (ws->gen >= DRV_R600) {
        ws->surf_man = radeon_surface_manager_new(fd);
        if (!ws->surf_man)
            goto fail;
    }

    /* init reference */
    pipe_reference_init(&ws->reference, 1);

    /* Set functions. */
    ws->base.unref = radeon_winsys_unref;
    ws->base.destroy = radeon_winsys_destroy;
    ws->base.query_info = radeon_query_info;
    ws->base.cs_request_feature = radeon_cs_request_feature;
    ws->base.surface_init = radeon_drm_winsys_surface_init;
    ws->base.surface_best = radeon_drm_winsys_surface_best;
    ws->base.query_value = radeon_query_value;

    radeon_bomgr_init_functions(ws);
    radeon_drm_cs_init_functions(ws);

    pipe_mutex_init(ws->hyperz_owner_mutex);
    pipe_mutex_init(ws->cmask_owner_mutex);
    pipe_mutex_init(ws->cs_stack_lock);

    ws->ncs = 0;
    pipe_semaphore_init(&ws->cs_queued, 0);
    if (ws->num_cpus > 1 && debug_get_option_thread())
        ws->thread = pipe_thread_create(radeon_drm_cs_emit_ioctl, ws);

    /* Create the screen at the end. The winsys must be initialized
     * completely.
     *
     * Alternatively, we could create the screen based on "ws->gen"
     * and link all drivers into one binary blob. */
    ws->base.screen = screen_create(&ws->base);
    if (!ws->base.screen) {
        radeon_winsys_destroy(&ws->base);
        pipe_mutex_unlock(fd_tab_mutex);
        return NULL;
    }

    util_hash_table_set(fd_tab, intptr_to_pointer(fd), ws);

    /* We must unlock the mutex once the winsys is fully initialized, so that
     * other threads attempting to create the winsys from the same fd will
     * get a fully initialized winsys and not just half-way initialized. */
    pipe_mutex_unlock(fd_tab_mutex);

    return &ws->base;

fail:
    pipe_mutex_unlock(fd_tab_mutex);
    if (ws->cman)
        ws->cman->destroy(ws->cman);
    if (ws->kman)
        ws->kman->destroy(ws->kman);
    if (ws->surf_man)
        radeon_surface_manager_free(ws->surf_man);
    FREE(ws);
    return NULL;
}
@


1.6
log
@Merge Mesa 10.2.9
@
text
@@


1.5
log
@Merge Mesa 10.4.3
Tested by matthieu@@ mpi@@ and myself.  landry@@ ran a ports bulk build.
kettenis@@ tracked down the cause of an alignment fault on archs
that require strict eight byte pointer alignment.
@
text
@a47 4
#ifndef RADEON_INFO_ACTIVE_CU_COUNT
#define RADEON_INFO_ACTIVE_CU_COUNT 0x20
#endif

d96 1
d102 1
a325 3
    radeon_get_drm_value(ws->fd, RADEON_INFO_SI_BACKEND_ENABLED_MASK, NULL,
                         &ws->info.si_backend_enabled_mask);

a384 29
    radeon_get_drm_value(ws->fd, RADEON_INFO_ACTIVE_CU_COUNT, NULL,
                         &ws->info.max_compute_units);

    radeon_get_drm_value(ws->fd, RADEON_INFO_MAX_SE, NULL,
                         &ws->info.max_se);

    if (!ws->info.max_se) {
        switch (ws->info.family) {
        default:
            ws->info.max_se = 1;
            break;
        case CHIP_CYPRESS:
        case CHIP_HEMLOCK:
        case CHIP_BARTS:
        case CHIP_CAYMAN:
        case CHIP_TAHITI:
        case CHIP_PITCAIRN:
        case CHIP_BONAIRE:
            ws->info.max_se = 2;
            break;
        case CHIP_HAWAII:
            ws->info.max_se = 4;
            break;
        }
    }

    radeon_get_drm_value(ws->fd, RADEON_INFO_MAX_SH_PER_SE, NULL,
                         &ws->info.max_sh_per_se);

d638 1
a638 3

    ws->cman = pb_cache_manager_create(ws->kman, 1000000, 2.0f, 0,
                                       (ws->info.vram_size + ws->info.gart_size) / 8);
@


1.4
log
@Merge Mesa 10.2.7
@
text
@d48 4
a99 1
            printf("radeon: Acquired access to %s.\n", request_name);
a104 1
        printf("radeon: Released access to %s.\n", request_name);
d328 3
d390 29
d672 3
a674 1
    ws->cman = pb_cache_manager_create(ws->kman, 1000000, 2.0f, 0);
@


1.3
log
@Merge Mesa 10.2.3
tested by matthieu@@ kettenis@@ mpi@@ brett@@ and myself across a
diverse range of hardware
@
text
@d385 10
@


1.2
log
@Merge Mesa 9.2.0
@
text
@d44 3
a46 56

/*
 * this are copy from radeon_drm, once an updated libdrm is released
 * we should bump configure.ac requirement for it and remove the following
 * field
 */
#ifndef RADEON_INFO_TILING_CONFIG
#define RADEON_INFO_TILING_CONFIG 6
#endif

#ifndef RADEON_INFO_WANT_HYPERZ
#define RADEON_INFO_WANT_HYPERZ 7
#endif

#ifndef RADEON_INFO_WANT_CMASK
#define RADEON_INFO_WANT_CMASK 8
#endif

#ifndef RADEON_INFO_CLOCK_CRYSTAL_FREQ
#define RADEON_INFO_CLOCK_CRYSTAL_FREQ 9
#endif

#ifndef RADEON_INFO_NUM_BACKENDS
#define RADEON_INFO_NUM_BACKENDS 0xa
#endif

#ifndef RADEON_INFO_NUM_TILE_PIPES
#define RADEON_INFO_NUM_TILE_PIPES 0xb
#endif

#ifndef RADEON_INFO_BACKEND_MAP
#define RADEON_INFO_BACKEND_MAP 0xd
#endif

#ifndef RADEON_INFO_VA_START
/* virtual address start, va < start are reserved by the kernel */
#define RADEON_INFO_VA_START        0x0e
/* maximum size of ib using the virtual memory cs */
#define RADEON_INFO_IB_VM_MAX_SIZE  0x0f
#endif

#ifndef RADEON_INFO_MAX_PIPES
#define RADEON_INFO_MAX_PIPES 0x10
#endif

#ifndef RADEON_INFO_TIMESTAMP
#define RADEON_INFO_TIMESTAMP 0x11
#endif

#ifndef RADEON_INFO_RING_WORKING
#define RADEON_INFO_RING_WORKING 0x15
#endif

#ifndef RADEON_CS_RING_UVD
#define RADEON_CS_RING_UVD	3
#endif
d49 1
d278 2
d286 2
a287 1
    if (ws->info.chip_class >= R700 && ws->info.drm_minor >= 27) {
d291 1
a291 1
    /* Check for UVD */
d293 1
d299 9
d321 5
d365 2
d369 1
a369 1
                                      &ws->info.r600_va_start))
d372 1
a372 1
                                      &ws->info.r600_ib_vm_max_size))
d385 10
a407 5
    pipe_condvar_destroy(ws->cs_queue_empty);

    if (!pipe_reference(&ws->base.reference, NULL)) {
        return;
    }
a417 3
    if (fd_tab) {
        util_hash_table_remove(fd_tab, intptr_to_pointer(ws->fd));
    }
d469 1
a469 1
    uint64_t ts = 0;
d485 16
a500 2
                             (uint32_t*)&ts);
        return ts;
d507 5
a511 1
    return pointer_to_intptr(key);
d516 9
a524 1
    return pointer_to_intptr(key1) != pointer_to_intptr(key2);
d531 1
a531 1
    if (p_atomic_read(&ws->ncs) >= RING_LAST) {
d536 1
a536 2
    ws->cs_stack[p_atomic_read(&ws->ncs)] = cs;
    p_atomic_inc(&ws->ncs);
d545 1
a545 1
    unsigned i, empty_stack;
d551 1
a551 1
next:
d554 3
a560 12

            pipe_mutex_lock(ws->cs_stack_lock);
            for (i = 1; i < p_atomic_read(&ws->ncs); i++) {
                ws->cs_stack[i - 1] = ws->cs_stack[i];
            }
            ws->cs_stack[p_atomic_read(&ws->ncs) - 1] = NULL;
            empty_stack = p_atomic_dec_zero(&ws->ncs);
            if (empty_stack) {
                pipe_condvar_signal(ws->cs_queue_empty);
            }
            pipe_mutex_unlock(ws->cs_stack_lock);

a561 4

            if (!empty_stack) {
                goto next;
            }
d565 1
a565 1
    for (i = 0; i < p_atomic_read(&ws->ncs); i++) {
d569 1
a569 2
    p_atomic_set(&ws->ncs, 0);
    pipe_condvar_signal(ws->cs_queue_empty);
d571 1
a571 1
    return NULL;
d577 21
a597 1
struct radeon_winsys *radeon_drm_winsys_create(int fd)
d601 1
d608 2
a609 1
        pipe_reference(NULL, &ws->base.reference);
d615 1
d618 1
a619 1
    util_hash_table_set(fd_tab, intptr_to_pointer(fd), ws);
d628 1
a628 1
    ws->cman = pb_cache_manager_create(ws->kman, 1000000);
d639 1
a639 1
    pipe_reference_init(&ws->base.reference, 1);
d642 1
d657 1
a657 1
    p_atomic_set(&ws->ncs, 0);
a658 1
    pipe_condvar_init(ws->cs_queue_empty);
d662 19
d684 1
@


1.1
log
@Upate to libGL 7.11.2

Tested by jsg@@, matthieu@@ and ajacoutot@@, ok mattieu@@
@
text
@d40 1
d45 9
d57 1
d62 41
d112 2
a113 1
                                    unsigned request, boolean enable)
d115 1
a115 1
    struct drm_radeon_info info = {0};
d118 2
d148 1
a148 1
            fprintf(stderr, "radeon: Acquired Hyper-Z.\n");
d154 1
a154 1
        fprintf(stderr, "radeon: Released Hyper-Z.\n");
d161 22
d184 1
a184 1
static void do_ioctls(struct radeon_drm_winsys *winsys)
d186 1
a186 3
    struct drm_radeon_gem_info gem_info = {0};
    struct drm_radeon_info info = {0};
    int target = 0;
d190 1
a190 1
    info.value = (unsigned long)&target;
d201 4
d208 1
a208 4
     *
     * The GEM info is actually bogus on the kernel side, as well as our side
     * (see radeon_gem_info_ioctl in radeon_gem.c) but that's alright because
     * we don't actually use the info for anything yet. */
d210 2
a211 1
    version = drmGetVersion(winsys->fd);
d215 1
a215 1
                "only compatible with 2.3.x (kernel 2.6.34) and later.\n",
d221 1
a221 1
        exit(1);
d224 19
a242 3
    winsys->drm_major = version->version_major;
    winsys->drm_minor = version->version_minor;
    winsys->drm_patchlevel = version->version_patchlevel;
d244 7
a250 6
    info.request = RADEON_INFO_DEVICE_ID;
    retval = drmCommandWriteRead(winsys->fd, DRM_RADEON_INFO, &info, sizeof(info));
    if (retval) {
        fprintf(stderr, "%s: Failed to get PCI ID, "
                "error number %d\n", __FUNCTION__, retval);
        exit(1);
a251 1
    winsys->pci_id = target;
d253 94
a346 6
    info.request = RADEON_INFO_NUM_GB_PIPES;
    retval = drmCommandWriteRead(winsys->fd, DRM_RADEON_INFO, &info, sizeof(info));
    if (retval) {
        fprintf(stderr, "%s: Failed to get GB pipe count, "
                "error number %d\n", __FUNCTION__, retval);
        exit(1);
a347 1
    winsys->gb_pipes = target;
d349 3
a351 2
    info.request = RADEON_INFO_NUM_Z_PIPES;
    retval = drmCommandWriteRead(winsys->fd, DRM_RADEON_INFO, &info, sizeof(info));
d353 3
a355 3
        fprintf(stderr, "%s: Failed to get Z pipe count, "
                "error number %d\n", __FUNCTION__, retval);
        exit(1);
d357 11
a367 1
    winsys->z_pipes = target;
d369 40
a408 6
    retval = drmCommandWriteRead(winsys->fd, DRM_RADEON_GEM_INFO,
            &gem_info, sizeof(gem_info));
    if (retval) {
        fprintf(stderr, "%s: Failed to get MM info, error number %d\n",
                __FUNCTION__, retval);
        exit(1);
a409 2
    winsys->gart_size = gem_info.gart_size;
    winsys->vram_size = gem_info.vram_size;
d411 5
a415 1
    drmFreeVersion(version);
d417 1
a417 1
    winsys->num_cpus = sysconf(_SC_NPROCESSORS_ONLN);
d424 12
d438 1
d442 6
d451 2
a452 2
static uint32_t radeon_get_value(struct radeon_winsys *rws,
                                 enum radeon_value_id id)
d454 1
a454 25
    struct radeon_drm_winsys *ws = (struct radeon_drm_winsys *)rws;

    switch(id) {
    case RADEON_VID_PCI_ID:
	return ws->pci_id;
    case RADEON_VID_R300_GB_PIPES:
	return ws->gb_pipes;
    case RADEON_VID_R300_Z_PIPES:
	return ws->z_pipes;
    case RADEON_VID_GART_SIZE:
        return ws->gart_size;
    case RADEON_VID_VRAM_SIZE:
        return ws->vram_size;
    case RADEON_VID_DRM_MAJOR:
        return ws->drm_major;
    case RADEON_VID_DRM_MINOR:
        return ws->drm_minor;
    case RADEON_VID_DRM_PATCHLEVEL:
        return ws->drm_patchlevel;
    case RADEON_VID_DRM_2_6_0:
        return ws->drm_major*100 + ws->drm_minor >= 206;
    case RADEON_VID_DRM_2_8_0:
        return ws->drm_major*100 + ws->drm_minor >= 208;
    }
    return 0;
d464 48
a511 7
    case RADEON_FID_HYPERZ_RAM_ACCESS:
        if (debug_get_bool_option("RADEON_HYPERZ", FALSE)) {
            return radeon_set_fd_access(cs, &cs->ws->hyperz_owner,
                                        &cs->ws->hyperz_owner_mutex,
                                        RADEON_INFO_WANT_HYPERZ, enable);
        } else {
            return FALSE;
d514 66
a579 7
    case RADEON_FID_CMASK_RAM_ACCESS:
        if (debug_get_bool_option("RADEON_CMASK", FALSE)) {
            return radeon_set_fd_access(cs, &cs->ws->cmask_owner,
                                        &cs->ws->cmask_owner_mutex,
                                        RADEON_INFO_WANT_CMASK, enable);
        } else {
            return FALSE;
d582 9
a590 1
    return FALSE;
d593 3
d598 13
a610 1
    struct radeon_drm_winsys *ws = CALLOC_STRUCT(radeon_drm_winsys);
a613 1

d615 1
a615 1
    do_ioctls(ws);
d617 2
a618 8
    switch (ws->pci_id) {
#define CHIPSET(pci_id, name, family) case pci_id:
#include "pci_ids/r300_pci_ids.h"
#undef CHIPSET
       break;
    default:
       goto fail;
    }
d623 1
a623 1
	goto fail;
d626 10
a635 1
	goto fail;
d639 1
a639 1
    ws->base.get_value = radeon_get_value;
d641 3
d650 7
d662 1
a662 1
	ws->cman->destroy(ws->cman);
d664 3
a666 1
	ws->kman->destroy(ws->kman);
@


1.1.1.1
log
@Import Mesa 9.2.0
@
text
@a39 1
#include "util/u_hash_table.h"
a43 9
/*
 * this are copy from radeon_drm, once an updated libdrm is released
 * we should bump configure.ac requirement for it and remove the following
 * field
 */
#ifndef RADEON_INFO_TILING_CONFIG
#define RADEON_INFO_TILING_CONFIG 6
#endif

a46 1

a50 41
#ifndef RADEON_INFO_CLOCK_CRYSTAL_FREQ
#define RADEON_INFO_CLOCK_CRYSTAL_FREQ 9
#endif

#ifndef RADEON_INFO_NUM_BACKENDS
#define RADEON_INFO_NUM_BACKENDS 0xa
#endif

#ifndef RADEON_INFO_NUM_TILE_PIPES
#define RADEON_INFO_NUM_TILE_PIPES 0xb
#endif

#ifndef RADEON_INFO_BACKEND_MAP
#define RADEON_INFO_BACKEND_MAP 0xd
#endif

#ifndef RADEON_INFO_VA_START
/* virtual address start, va < start are reserved by the kernel */
#define RADEON_INFO_VA_START        0x0e
/* maximum size of ib using the virtual memory cs */
#define RADEON_INFO_IB_VM_MAX_SIZE  0x0f
#endif

#ifndef RADEON_INFO_MAX_PIPES
#define RADEON_INFO_MAX_PIPES 0x10
#endif

#ifndef RADEON_INFO_TIMESTAMP
#define RADEON_INFO_TIMESTAMP 0x11
#endif

#ifndef RADEON_INFO_RING_WORKING
#define RADEON_INFO_RING_WORKING 0x15
#endif

#ifndef RADEON_CS_RING_UVD
#define RADEON_CS_RING_UVD	3
#endif

static struct util_hash_table *fd_tab = NULL;

d60 1
a60 2
                                    unsigned request, const char *request_name,
                                    boolean enable)
d62 1
a62 1
    struct drm_radeon_info info;
a64 2
    memset(&info, 0, sizeof(info));

d93 1
a93 1
            printf("radeon: Acquired access to %s.\n", request_name);
d99 1
a99 1
        printf("radeon: Released access to %s.\n", request_name);
a105 22
static boolean radeon_get_drm_value(int fd, unsigned request,
                                    const char *errname, uint32_t *out)
{
    struct drm_radeon_info info;
    int retval;

    memset(&info, 0, sizeof(info));

    info.value = (unsigned long)out;
    info.request = request;

    retval = drmCommandWriteRead(fd, DRM_RADEON_INFO, &info, sizeof(info));
    if (retval) {
        if (errname) {
            fprintf(stderr, "radeon: Failed to get %s, error number %d\n",
                    errname, retval);
        }
        return FALSE;
    }
    return TRUE;
}

d107 1
a107 1
static boolean do_winsys_init(struct radeon_drm_winsys *ws)
d109 3
a111 1
    struct drm_radeon_gem_info gem_info;
d115 1
a115 1
    memset(&gem_info, 0, sizeof(gem_info));
a125 4
     * The GEM info is actually bogus on the kernel side, as well as our side
     * (see radeon_gem_info_ioctl in radeon_gem.c) but that's alright because
     * we don't actually use the info for anything yet.
     *
d129 4
a132 1
     */
d134 1
a134 2
    /* Get DRM version. */
    version = drmGetVersion(ws->fd);
d138 1
a138 1
                "only compatible with 2.3.x (kernel 2.6.34) or later.\n",
d144 1
a144 1
        return FALSE;
d147 3
a149 4
    ws->info.drm_major = version->version_major;
    ws->info.drm_minor = version->version_minor;
    ws->info.drm_patchlevel = version->version_patchlevel;
    drmFreeVersion(version);
d151 8
a158 4
    /* Get PCI ID. */
    if (!radeon_get_drm_value(ws->fd, RADEON_INFO_DEVICE_ID, "PCI ID",
                              &ws->info.pci_id))
        return FALSE;
d160 6
a165 17
    /* Check PCI ID. */
    switch (ws->info.pci_id) {
#define CHIPSET(pci_id, name, cfamily) case pci_id: ws->info.family = CHIP_##cfamily; ws->gen = DRV_R300; break;
#include "pci_ids/r300_pci_ids.h"
#undef CHIPSET

#define CHIPSET(pci_id, name, cfamily) case pci_id: ws->info.family = CHIP_##cfamily; ws->gen = DRV_R600; break;
#include "pci_ids/r600_pci_ids.h"
#undef CHIPSET

#define CHIPSET(pci_id, name, cfamily) case pci_id: ws->info.family = CHIP_##cfamily; ws->gen = DRV_SI; break;
#include "pci_ids/radeonsi_pci_ids.h"
#undef CHIPSET

    default:
        fprintf(stderr, "radeon: Invalid PCI ID.\n");
        return FALSE;
d167 1
d169 6
a174 94
    switch (ws->info.family) {
    default:
    case CHIP_UNKNOWN:
        fprintf(stderr, "radeon: Unknown family.\n");
        return FALSE;
    case CHIP_R300:
    case CHIP_R350:
    case CHIP_RV350:
    case CHIP_RV370:
    case CHIP_RV380:
    case CHIP_RS400:
    case CHIP_RC410:
    case CHIP_RS480:
        ws->info.chip_class = R300;
        break;
    case CHIP_R420:     /* R4xx-based cores. */
    case CHIP_R423:
    case CHIP_R430:
    case CHIP_R480:
    case CHIP_R481:
    case CHIP_RV410:
    case CHIP_RS600:
    case CHIP_RS690:
    case CHIP_RS740:
        ws->info.chip_class = R400;
        break;
    case CHIP_RV515:    /* R5xx-based cores. */
    case CHIP_R520:
    case CHIP_RV530:
    case CHIP_R580:
    case CHIP_RV560:
    case CHIP_RV570:
        ws->info.chip_class = R500;
        break;
    case CHIP_R600:
    case CHIP_RV610:
    case CHIP_RV630:
    case CHIP_RV670:
    case CHIP_RV620:
    case CHIP_RV635:
    case CHIP_RS780:
    case CHIP_RS880:
        ws->info.chip_class = R600;
        break;
    case CHIP_RV770:
    case CHIP_RV730:
    case CHIP_RV710:
    case CHIP_RV740:
        ws->info.chip_class = R700;
        break;
    case CHIP_CEDAR:
    case CHIP_REDWOOD:
    case CHIP_JUNIPER:
    case CHIP_CYPRESS:
    case CHIP_HEMLOCK:
    case CHIP_PALM:
    case CHIP_SUMO:
    case CHIP_SUMO2:
    case CHIP_BARTS:
    case CHIP_TURKS:
    case CHIP_CAICOS:
        ws->info.chip_class = EVERGREEN;
        break;
    case CHIP_CAYMAN:
    case CHIP_ARUBA:
        ws->info.chip_class = CAYMAN;
        break;
    case CHIP_TAHITI:
    case CHIP_PITCAIRN:
    case CHIP_VERDE:
    case CHIP_OLAND:
    case CHIP_HAINAN:
        ws->info.chip_class = SI;
        break;
    case CHIP_BONAIRE:
    case CHIP_KAVERI:
    case CHIP_KABINI:
        ws->info.chip_class = CIK;
        break;
    }

    /* Check for dma */
    ws->info.r600_has_dma = FALSE;
    if (ws->info.chip_class >= R700 && ws->info.drm_minor >= 27) {
        ws->info.r600_has_dma = TRUE;
    }

    /* Check for UVD */
    ws->info.has_uvd = FALSE;
    if (ws->info.drm_minor >= 32) {
	uint32_t value = RADEON_CS_RING_UVD;
        if (radeon_get_drm_value(ws->fd, RADEON_INFO_RING_WORKING,
                                 "UVD Ring working", &value))
            ws->info.has_uvd = value;
d176 1
d178 1
a178 2
    /* Get GEM info. */
    retval = drmCommandWriteRead(ws->fd, DRM_RADEON_GEM_INFO,
d181 3
a183 3
        fprintf(stderr, "radeon: Failed to get MM info, error number %d\n",
                retval);
        return FALSE;
d185 2
a186 2
    ws->info.gart_size = gem_info.gart_size;
    ws->info.vram_size = gem_info.vram_size;
d188 1
a188 8
    ws->num_cpus = sysconf(_SC_NPROCESSORS_ONLN);

    /* Generation-specific queries. */
    if (ws->gen == DRV_R300) {
        if (!radeon_get_drm_value(ws->fd, RADEON_INFO_NUM_GB_PIPES,
                                  "GB pipe count",
                                  &ws->info.r300_num_gb_pipes))
            return FALSE;
d190 1
a190 49
        if (!radeon_get_drm_value(ws->fd, RADEON_INFO_NUM_Z_PIPES,
                                  "Z pipe count",
                                  &ws->info.r300_num_z_pipes))
            return FALSE;
    }
    else if (ws->gen >= DRV_R600) {
        if (ws->info.drm_minor >= 9 &&
            !radeon_get_drm_value(ws->fd, RADEON_INFO_NUM_BACKENDS,
                                  "num backends",
                                  &ws->info.r600_num_backends))
            return FALSE;

        /* get the GPU counter frequency, failure is not fatal */
        radeon_get_drm_value(ws->fd, RADEON_INFO_CLOCK_CRYSTAL_FREQ, NULL,
                             &ws->info.r600_clock_crystal_freq);

        radeon_get_drm_value(ws->fd, RADEON_INFO_TILING_CONFIG, NULL,
                             &ws->info.r600_tiling_config);

        if (ws->info.drm_minor >= 11) {
            radeon_get_drm_value(ws->fd, RADEON_INFO_NUM_TILE_PIPES, NULL,
                                 &ws->info.r600_num_tile_pipes);

            if (radeon_get_drm_value(ws->fd, RADEON_INFO_BACKEND_MAP, NULL,
                                      &ws->info.r600_backend_map))
                ws->info.r600_backend_map_valid = TRUE;
        }

        ws->info.r600_virtual_address = FALSE;
        if (ws->info.drm_minor >= 13) {
            ws->info.r600_virtual_address = TRUE;
            if (!radeon_get_drm_value(ws->fd, RADEON_INFO_VA_START, NULL,
                                      &ws->info.r600_va_start))
                ws->info.r600_virtual_address = FALSE;
            if (!radeon_get_drm_value(ws->fd, RADEON_INFO_IB_VM_MAX_SIZE, NULL,
                                      &ws->info.r600_ib_vm_max_size))
                ws->info.r600_virtual_address = FALSE;
        }
	if (ws->gen == DRV_R600 && !debug_get_bool_option("RADEON_VA", FALSE))
		ws->info.r600_virtual_address = FALSE;
    }

    /* Get max pipes, this is only needed for compute shaders.  All evergreen+
     * chips have at least 2 pipes, so we use 2 as a default. */
    ws->info.r600_max_pipes = 2;
    radeon_get_drm_value(ws->fd, RADEON_INFO_MAX_PIPES, NULL,
                         &ws->info.r600_max_pipes);

    return TRUE;
a196 12
    if (ws->thread) {
        ws->kill_thread = 1;
        pipe_semaphore_signal(&ws->cs_queued);
        pipe_thread_wait(ws->thread);
    }
    pipe_semaphore_destroy(&ws->cs_queued);
    pipe_condvar_destroy(ws->cs_queue_empty);

    if (!pipe_reference(&ws->base.reference, NULL)) {
        return;
    }

a198 1
    pipe_mutex_destroy(ws->cs_stack_lock);
a201 6
    if (ws->gen >= DRV_R600) {
        radeon_surface_manager_free(ws->surf_man);
    }
    if (fd_tab) {
        util_hash_table_remove(fd_tab, intptr_to_pointer(ws->fd));
    }
d205 2
a206 2
static void radeon_query_info(struct radeon_winsys *rws,
                              struct radeon_info *info)
d208 25
a232 1
    *info = ((struct radeon_drm_winsys *)rws)->info;
d242 7
a248 48
    case RADEON_FID_R300_HYPERZ_ACCESS:
        return radeon_set_fd_access(cs, &cs->ws->hyperz_owner,
                                    &cs->ws->hyperz_owner_mutex,
                                    RADEON_INFO_WANT_HYPERZ, "Hyper-Z",
                                    enable);

    case RADEON_FID_R300_CMASK_ACCESS:
        return radeon_set_fd_access(cs, &cs->ws->cmask_owner,
                                    &cs->ws->cmask_owner_mutex,
                                    RADEON_INFO_WANT_CMASK, "AA optimizations",
                                    enable);
    }
    return FALSE;
}

static int radeon_drm_winsys_surface_init(struct radeon_winsys *rws,
                                          struct radeon_surface *surf)
{
    struct radeon_drm_winsys *ws = (struct radeon_drm_winsys*)rws;

    return radeon_surface_init(ws->surf_man, surf);
}

static int radeon_drm_winsys_surface_best(struct radeon_winsys *rws,
                                          struct radeon_surface *surf)
{
    struct radeon_drm_winsys *ws = (struct radeon_drm_winsys*)rws;

    return radeon_surface_best(ws->surf_man, surf);
}

static uint64_t radeon_query_value(struct radeon_winsys *rws,
                                   enum radeon_value_id value)
{
    struct radeon_drm_winsys *ws = (struct radeon_drm_winsys*)rws;
    uint64_t ts = 0;

    switch (value) {
    case RADEON_REQUESTED_VRAM_MEMORY:
        return ws->allocated_vram;
    case RADEON_REQUESTED_GTT_MEMORY:
        return ws->allocated_gtt;
    case RADEON_BUFFER_WAIT_TIME_NS:
        return ws->buffer_wait_time;
    case RADEON_TIMESTAMP:
        if (ws->info.drm_minor < 20 || ws->gen < DRV_R600) {
            assert(0);
            return 0;
d251 7
a257 66
        radeon_get_drm_value(ws->fd, RADEON_INFO_TIMESTAMP, "timestamp",
                             (uint32_t*)&ts);
        return ts;
    }
    return 0;
}

static unsigned hash_fd(void *key)
{
    return pointer_to_intptr(key);
}

static int compare_fd(void *key1, void *key2)
{
    return pointer_to_intptr(key1) != pointer_to_intptr(key2);
}

void radeon_drm_ws_queue_cs(struct radeon_drm_winsys *ws, struct radeon_drm_cs *cs)
{
retry:
    pipe_mutex_lock(ws->cs_stack_lock);
    if (p_atomic_read(&ws->ncs) >= RING_LAST) {
        /* no room left for a flush */
        pipe_mutex_unlock(ws->cs_stack_lock);
        goto retry;
    }
    ws->cs_stack[p_atomic_read(&ws->ncs)] = cs;
    p_atomic_inc(&ws->ncs);
    pipe_mutex_unlock(ws->cs_stack_lock);
    pipe_semaphore_signal(&ws->cs_queued);
}

static PIPE_THREAD_ROUTINE(radeon_drm_cs_emit_ioctl, param)
{
    struct radeon_drm_winsys *ws = (struct radeon_drm_winsys *)param;
    struct radeon_drm_cs *cs;
    unsigned i, empty_stack;

    while (1) {
        pipe_semaphore_wait(&ws->cs_queued);
        if (ws->kill_thread)
            break;
next:
        pipe_mutex_lock(ws->cs_stack_lock);
        cs = ws->cs_stack[0];
        pipe_mutex_unlock(ws->cs_stack_lock);

        if (cs) {
            radeon_drm_cs_emit_ioctl_oneshot(cs, cs->cst);

            pipe_mutex_lock(ws->cs_stack_lock);
            for (i = 1; i < p_atomic_read(&ws->ncs); i++) {
                ws->cs_stack[i - 1] = ws->cs_stack[i];
            }
            ws->cs_stack[p_atomic_read(&ws->ncs) - 1] = NULL;
            empty_stack = p_atomic_dec_zero(&ws->ncs);
            if (empty_stack) {
                pipe_condvar_signal(ws->cs_queue_empty);
            }
            pipe_mutex_unlock(ws->cs_stack_lock);

            pipe_semaphore_signal(&cs->flush_completed);

            if (!empty_stack) {
                goto next;
            }
d260 1
a260 9
    pipe_mutex_lock(ws->cs_stack_lock);
    for (i = 0; i < p_atomic_read(&ws->ncs); i++) {
        pipe_semaphore_signal(&ws->cs_stack[i]->flush_completed);
        ws->cs_stack[i] = NULL;
    }
    p_atomic_set(&ws->ncs, 0);
    pipe_condvar_signal(ws->cs_queue_empty);
    pipe_mutex_unlock(ws->cs_stack_lock);
    return NULL;
a262 3
DEBUG_GET_ONCE_BOOL_OPTION(thread, "RADEON_THREAD", TRUE)
static PIPE_THREAD_ROUTINE(radeon_drm_cs_emit_ioctl, param);

d265 1
a265 13
    struct radeon_drm_winsys *ws;

    if (!fd_tab) {
        fd_tab = util_hash_table_create(hash_fd, compare_fd);
    }

    ws = util_hash_table_get(fd_tab, intptr_to_pointer(fd));
    if (ws) {
        pipe_reference(NULL, &ws->base.reference);
        return &ws->base;
    }

    ws = CALLOC_STRUCT(radeon_drm_winsys);
d269 1
d271 1
a271 1
    util_hash_table_set(fd_tab, intptr_to_pointer(fd), ws);
d273 8
a280 2
    if (!do_winsys_init(ws))
        goto fail;
d285 1
a285 1
        goto fail;
d288 1
a288 10
        goto fail;

    if (ws->gen >= DRV_R600) {
        ws->surf_man = radeon_surface_manager_new(fd);
        if (!ws->surf_man)
            goto fail;
    }

    /* init reference */
    pipe_reference_init(&ws->base.reference, 1);
d292 1
a292 1
    ws->base.query_info = radeon_query_info;
a293 3
    ws->base.surface_init = radeon_drm_winsys_surface_init;
    ws->base.surface_best = radeon_drm_winsys_surface_best;
    ws->base.query_value = radeon_query_value;
a299 7
    pipe_mutex_init(ws->cs_stack_lock);

    p_atomic_set(&ws->ncs, 0);
    pipe_semaphore_init(&ws->cs_queued, 0);
    pipe_condvar_init(ws->cs_queue_empty);
    if (ws->num_cpus > 1 && debug_get_option_thread())
        ws->thread = pipe_thread_create(radeon_drm_cs_emit_ioctl, ws);
d305 1
a305 1
        ws->cman->destroy(ws->cman);
d307 1
a307 3
        ws->kman->destroy(ws->kman);
    if (ws->surf_man)
        radeon_surface_manager_free(ws->surf_man);
@


1.1.1.2
log
@Import Mesa 10.2.3
@
text
@d44 56
a99 3
#include <sys/types.h>
#include <sys/stat.h>
#include <unistd.h>
a101 1
pipe_static_mutex(fd_tab_mutex);
a329 2
    case CHIP_HAWAII:
    case CHIP_MULLINS:
d336 1
a336 2
    /* DMA is disabled on R700. There is IB corruption and hangs. */
    if (ws->info.chip_class >= EVERGREEN && ws->info.drm_minor >= 27) {
d340 1
a340 1
    /* Check for UVD and VCE */
a341 1
    ws->info.vce_fw_version = 0x00000000;
a346 9

        value = RADEON_CS_RING_VCE;
        if (radeon_get_drm_value(ws->fd, RADEON_INFO_RING_WORKING,
                                 NULL, &value) && value) {

            if (radeon_get_drm_value(ws->fd, RADEON_INFO_VCE_FW_VERSION,
                                     "VCE FW version", &value))
                ws->info.vce_fw_version = value;
	}
a359 5
    /* Get max clock frequency info and convert it to MHz */
    radeon_get_drm_value(ws->fd, RADEON_INFO_MAX_SCLK, NULL,
                         &ws->info.max_sclk);
    ws->info.max_sclk /= 1000;

a398 2
            uint32_t ib_vm_max_size;

d401 1
a401 1
                                      &ws->va_start))
d404 1
a404 1
                                      &ib_vm_max_size))
a416 10
    if (radeon_get_drm_value(ws->fd, RADEON_INFO_SI_TILE_MODE_ARRAY, NULL,
                             ws->info.si_tile_mode_array)) {
        ws->info.si_tile_mode_array_valid = TRUE;
    }

    if (radeon_get_drm_value(ws->fd, RADEON_INFO_CIK_MACROTILE_MODE_ARRAY, NULL,
                             ws->info.cik_macrotile_mode_array)) {
        ws->info.cik_macrotile_mode_array_valid = TRUE;
    }

d430 5
d445 3
d499 1
a499 1
    uint64_t retval = 0;
d515 2
a516 16
                             (uint32_t*)&retval);
        return retval;
    case RADEON_NUM_CS_FLUSHES:
        return ws->num_cs_flushes;
    case RADEON_NUM_BYTES_MOVED:
        radeon_get_drm_value(ws->fd, RADEON_INFO_NUM_BYTES_MOVED,
                             "num-bytes-moved", (uint32_t*)&retval);
        return retval;
    case RADEON_VRAM_USAGE:
        radeon_get_drm_value(ws->fd, RADEON_INFO_VRAM_USAGE,
                             "vram-usage", (uint32_t*)&retval);
        return retval;
    case RADEON_GTT_USAGE:
        radeon_get_drm_value(ws->fd, RADEON_INFO_GTT_USAGE,
                             "gtt-usage", (uint32_t*)&retval);
        return retval;
d523 1
a523 5
    int fd = pointer_to_intptr(key);
    struct stat stat;
    fstat(fd, &stat);

    return stat.st_dev ^ stat.st_ino ^ stat.st_rdev;
d528 1
a528 9
    int fd1 = pointer_to_intptr(key1);
    int fd2 = pointer_to_intptr(key2);
    struct stat stat1, stat2;
    fstat(fd1, &stat1);
    fstat(fd2, &stat2);

    return stat1.st_dev != stat2.st_dev ||
           stat1.st_ino != stat2.st_ino ||
           stat1.st_rdev != stat2.st_rdev;
d535 1
a535 1
    if (ws->ncs >= RING_LAST) {
d540 2
a541 1
    ws->cs_stack[ws->ncs++] = cs;
d550 1
a550 1
    unsigned i;
d556 1
a556 1

a558 3
        for (i = 1; i < ws->ncs; i++)
            ws->cs_stack[i - 1] = ws->cs_stack[i];
        ws->cs_stack[--ws->ncs] = NULL;
d563 12
d576 4
d583 1
a583 1
    for (i = 0; i < ws->ncs; i++) {
d587 2
a588 1
    ws->ncs = 0;
d590 1
a590 1
    return 0;
d596 1
a596 21
static bool radeon_winsys_unref(struct radeon_winsys *ws)
{
    struct radeon_drm_winsys *rws = (struct radeon_drm_winsys*)ws;
    bool destroy;

    /* When the reference counter drops to zero, remove the fd from the table.
     * This must happen while the mutex is locked, so that
     * radeon_drm_winsys_create in another thread doesn't get the winsys
     * from the table when the counter drops to 0. */
    pipe_mutex_lock(fd_tab_mutex);

    destroy = pipe_reference(&rws->reference, NULL);
    if (destroy && fd_tab)
        util_hash_table_remove(fd_tab, intptr_to_pointer(rws->fd));

    pipe_mutex_unlock(fd_tab_mutex);
    return destroy;
}

PUBLIC struct radeon_winsys *
radeon_drm_winsys_create(int fd, radeon_screen_create_t screen_create)
a599 1
    pipe_mutex_lock(fd_tab_mutex);
d606 1
a606 2
        pipe_reference(NULL, &ws->reference);
        pipe_mutex_unlock(fd_tab_mutex);
a611 1
        pipe_mutex_unlock(fd_tab_mutex);
a613 1

d615 1
d624 1
a624 1
    ws->cman = pb_cache_manager_create(ws->kman, 1000000, 2.0f, 0);
d635 1
a635 1
    pipe_reference_init(&ws->reference, 1);
a637 1
    ws->base.unref = radeon_winsys_unref;
d652 1
a652 1
    ws->ncs = 0;
d654 1
a657 19
    /* Create the screen at the end. The winsys must be initialized
     * completely.
     *
     * Alternatively, we could create the screen based on "ws->gen"
     * and link all drivers into one binary blob. */
    ws->base.screen = screen_create(&ws->base);
    if (!ws->base.screen) {
        radeon_winsys_destroy(&ws->base);
        pipe_mutex_unlock(fd_tab_mutex);
        return NULL;
    }

    util_hash_table_set(fd_tab, intptr_to_pointer(fd), ws);

    /* We must unlock the mutex once the winsys is fully initialized, so that
     * other threads attempting to create the winsys from the same fd will
     * get a fully initialized winsys and not just half-way initialized. */
    pipe_mutex_unlock(fd_tab_mutex);

a660 1
    pipe_mutex_unlock(fd_tab_mutex);
@


1.1.1.3
log
@Import Mesa 10.2.7
@
text
@a384 10
    radeon_get_drm_value(ws->fd, RADEON_INFO_ACCEL_WORKING2, NULL,
                         &ws->accel_working2);
    if (ws->info.family == CHIP_HAWAII && ws->accel_working2 < 2) {
        fprintf(stderr, "radeon: GPU acceleration for Hawaii disabled, "
                "returned accel_working2 value %u is smaller than 2. "
                "Please install a newer kernel.\n",
                ws->accel_working2);
        return FALSE;
    }

@


1.1.1.4
log
@Import Mesa 10.4.3
@
text
@a47 4
#ifndef RADEON_INFO_ACTIVE_CU_COUNT
#define RADEON_INFO_ACTIVE_CU_COUNT 0x20
#endif

d96 1
d102 1
a325 3
    radeon_get_drm_value(ws->fd, RADEON_INFO_SI_BACKEND_ENABLED_MASK, NULL,
                         &ws->info.si_backend_enabled_mask);

a384 29
    radeon_get_drm_value(ws->fd, RADEON_INFO_ACTIVE_CU_COUNT, NULL,
                         &ws->info.max_compute_units);

    radeon_get_drm_value(ws->fd, RADEON_INFO_MAX_SE, NULL,
                         &ws->info.max_se);

    if (!ws->info.max_se) {
        switch (ws->info.family) {
        default:
            ws->info.max_se = 1;
            break;
        case CHIP_CYPRESS:
        case CHIP_HEMLOCK:
        case CHIP_BARTS:
        case CHIP_CAYMAN:
        case CHIP_TAHITI:
        case CHIP_PITCAIRN:
        case CHIP_BONAIRE:
            ws->info.max_se = 2;
            break;
        case CHIP_HAWAII:
            ws->info.max_se = 4;
            break;
        }
    }

    radeon_get_drm_value(ws->fd, RADEON_INFO_MAX_SH_PER_SE, NULL,
                         &ws->info.max_sh_per_se);

d638 1
a638 3

    ws->cman = pb_cache_manager_create(ws->kman, 1000000, 2.0f, 0,
                                       (ws->info.vram_size + ws->info.gart_size) / 8);
@


1.1.1.5
log
@Import Mesa 10.2.9
@
text
@d48 4
a99 1
            printf("radeon: Acquired access to %s.\n", request_name);
a104 1
        printf("radeon: Released access to %s.\n", request_name);
d328 3
d390 29
d672 3
a674 1
    ws->cman = pb_cache_manager_create(ws->kman, 1000000, 2.0f, 0);
@


