head	1.4;
access;
symbols
	OPENBSD_5_8:1.3.0.4
	OPENBSD_5_8_BASE:1.3
	OPENBSD_5_7:1.3.0.2
	OPENBSD_5_7_BASE:1.3
	v10_2_9:1.1.1.2
	v10_2_7:1.1.1.2
	OPENBSD_5_6:1.1.1.2.0.2
	OPENBSD_5_6_BASE:1.1.1.2
	v10_2_3:1.1.1.2
	OPENBSD_5_5:1.1.1.1.0.2
	OPENBSD_5_5_BASE:1.1.1.1
	v9_2_5:1.1.1.1
	v9_2_3:1.1.1.1
	v9_2_2:1.1.1.1
	v9_2_1:1.1.1.1
	v9_2_0:1.1.1.1
	mesa:1.1.1;
locks; strict;
comment	@ * @;
expand	@o@;


1.4
date	2015.12.23.05.17.41;	author jsg;	state dead;
branches;
next	1.3;
commitid	TnlogFl9nOv2eaRf;

1.3
date	2015.02.20.23.09.56;	author jsg;	state Exp;
branches;
next	1.2;
commitid	4ry2gvZGMXkCUD2n;

1.2
date	2015.01.25.14.41.18;	author jsg;	state dead;
branches;
next	1.1;
commitid	mcxB0JvoI9gTDYXU;

1.1
date	2013.09.05.13.13.53;	author jsg;	state Exp;
branches
	1.1.1.1;
next	;

1.1.1.1
date	2013.09.05.13.13.53;	author jsg;	state Exp;
branches;
next	1.1.1.2;

1.1.1.2
date	2014.07.09.20.34.23;	author jsg;	state Exp;
branches;
next	;
commitid	3JhLfwcuBALP0ZR7;


desc
@@


1.4
log
@remove the now unused Mesa 10.2.9 code
@
text
@/*
 * Mesa 3-D graphics library
 *
 * Copyright (C) 2012-2014 LunarG, Inc.
 *
 * Permission is hereby granted, free of charge, to any person obtaining a
 * copy of this software and associated documentation files (the "Software"),
 * to deal in the Software without restriction, including without limitation
 * the rights to use, copy, modify, merge, publish, distribute, sublicense,
 * and/or sell copies of the Software, and to permit persons to whom the
 * Software is furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included
 * in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
 * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
 * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
 * DEALINGS IN THE SOFTWARE.
 *
 * Authors:
 *    Chia-I Wu <olv@@lunarg.com>
 */

#ifndef INTEL_WINSYS_H
#define INTEL_WINSYS_H

#include "pipe/p_compiler.h"

/* this is compatible with i915_drm.h's definitions */
enum intel_ring_type {
   INTEL_RING_RENDER    = 1,
   INTEL_RING_BSD       = 2,
   INTEL_RING_BLT       = 3,
   INTEL_RING_VEBOX     = 4,
};

/* this is compatible with i915_drm.h's definitions */
enum intel_exec_flag {
   INTEL_EXEC_GEN7_SOL_RESET  = 1 << 8,
};

/* this is compatible with i915_drm.h's definitions */
enum intel_domain_flag {
   INTEL_DOMAIN_CPU           = 0x00000001,
   INTEL_DOMAIN_RENDER        = 0x00000002,
   INTEL_DOMAIN_SAMPLER       = 0x00000004,
   INTEL_DOMAIN_COMMAND	      = 0x00000008,
   INTEL_DOMAIN_INSTRUCTION   = 0x00000010,
   INTEL_DOMAIN_VERTEX        = 0x00000020,
   INTEL_DOMAIN_GTT           = 0x00000040,
};

/* this is compatible with i915_drm.h's definitions */
enum intel_tiling_mode {
   INTEL_TILING_NONE = 0,
   INTEL_TILING_X    = 1,
   INTEL_TILING_Y    = 2,
};

struct winsys_handle;
struct intel_winsys;
struct intel_context;
struct intel_bo;

struct intel_winsys_info {
   int devid;

   int max_batch_size;
   bool has_llc;
   bool has_address_swizzling;
   bool has_logical_context;
   bool has_ppgtt;

   /* valid registers for intel_winsys_read_reg() */
   bool has_timestamp;

   /* valid flags for intel_winsys_submit_bo() */
   bool has_gen7_sol_reset;
};

struct intel_winsys *
intel_winsys_create_for_fd(int fd);

void
intel_winsys_destroy(struct intel_winsys *winsys);

const struct intel_winsys_info *
intel_winsys_get_info(const struct intel_winsys *winsys);

/**
 * Create a logical context for use with the render ring.
 */
struct intel_context *
intel_winsys_create_context(struct intel_winsys *winsys);

/**
 * Destroy a logical context.
 */
void
intel_winsys_destroy_context(struct intel_winsys *winsys,
                             struct intel_context *ctx);

/**
 * Read a register.  Only registers that are considered safe, such as
 *
 *   TIMESTAMP (0x2358)
 *
 * can be read.
 */
int
intel_winsys_read_reg(struct intel_winsys *winsys,
                      uint32_t reg, uint64_t *val);

/**
 * Allocate a linear buffer object.
 *
 * \param name             Informative description of the bo.
 * \param size             Size of the bo.
 * \param initial_domain   Initial (write) domain.
 */
struct intel_bo *
intel_winsys_alloc_buffer(struct intel_winsys *winsys,
                          const char *name,
                          unsigned long size,
                          uint32_t initial_domain);

/**
 * Allocate a 2-dimentional buffer object.
 *
 * \param name             Informative description of the bo.
 * \param width            Width of the bo.
 * \param height           Height of the bo.
 * \param cpp              Bytes per texel.
 * \param tiling           Tiling mode.
 * \param initial_domain   Initial (write) domain.
 * \param pitch            Pitch of the bo.
 */
struct intel_bo *
intel_winsys_alloc_texture(struct intel_winsys *winsys,
                           const char *name,
                           int width, int height, int cpp,
                           enum intel_tiling_mode tiling,
                           uint32_t initial_domain,
                           unsigned long *pitch);

/**
 * Create a bo from a winsys handle.
 */
struct intel_bo *
intel_winsys_import_handle(struct intel_winsys *winsys,
                           const char *name,
                           const struct winsys_handle *handle,
                           int width, int height, int cpp,
                           enum intel_tiling_mode *tiling,
                           unsigned long *pitch);

/**
 * Export \p bo as a winsys handle for inter-process sharing.
 */
int
intel_winsys_export_handle(struct intel_winsys *winsys,
                           struct intel_bo *bo,
                           enum intel_tiling_mode tiling,
                           unsigned long pitch,
                           struct winsys_handle *handle);

/**
 * Return true when buffer objects directly specified in \p bo_array, and
 * those indirectly referenced by them, can fit in the aperture space.
 */
bool
intel_winsys_can_submit_bo(struct intel_winsys *winsys,
                           struct intel_bo **bo_array,
                           int count);

/**
 * Submit \p bo for execution.
 *
 * \p bo and all bos referenced by \p bo will be considered busy until all
 * commands are parsed and executed.  \p ctx is ignored when the bo is not
 * submitted to the render ring.
 */
int
intel_winsys_submit_bo(struct intel_winsys *winsys,
                       enum intel_ring_type ring,
                       struct intel_bo *bo, int used,
                       struct intel_context *ctx,
                       unsigned long flags);

/**
 * Decode the commands contained in \p bo.  For debugging.
 *
 * \param bo      Batch buffer to decode.
 * \param used    Size of the commands in bytes.
 */
void
intel_winsys_decode_bo(struct intel_winsys *winsys,
                       struct intel_bo *bo, int used);

/**
 * Increase the reference count of \p bo.
 */
void
intel_bo_reference(struct intel_bo *bo);

/**
 * Decrease the reference count of \p bo.  When the reference count reaches
 * zero, \p bo is destroyed.
 */
void
intel_bo_unreference(struct intel_bo *bo);

/**
 * Map \p bo for CPU access.  Recursive mapping is allowed.
 *
 * map() maps the backing store into CPU address space, cached.  It will block
 * if the bo is busy.  This variant allows fastest random reads and writes,
 * but the caller needs to handle tiling or swizzling manually if the bo is
 * tiled or swizzled.  If write is enabled and there is no shared last-level
 * cache (LLC), the CPU cache will be flushed, which is expensive.
 *
 * map_gtt() maps the bo for MMIO access, uncached but write-combined.  It
 * will block if the bo is busy.  This variant promises a reasonable speed for
 * sequential writes, but reads would be very slow.  Callers always have a
 * linear view of the bo.
 *
 * map_unsynchronized() is similar to map_gtt(), except that it does not
 * block.
 */
void *
intel_bo_map(struct intel_bo *bo, bool write_enable);

void *
intel_bo_map_gtt(struct intel_bo *bo);

void *
intel_bo_map_unsynchronized(struct intel_bo *bo);

/**
 * Unmap \p bo.
 */
void
intel_bo_unmap(struct intel_bo *bo);

/**
 * Write data to \p bo.
 */
int
intel_bo_pwrite(struct intel_bo *bo, unsigned long offset,
                unsigned long size, const void *data);

/**
 * Read data from the bo.
 */
int
intel_bo_pread(struct intel_bo *bo, unsigned long offset,
               unsigned long size, void *data);

/**
 * Add \p target_bo to the relocation list.
 *
 * When \p bo is submitted for execution, and if \p target_bo has moved,
 * the kernel will patch \p bo at \p offset to \p target_bo->offset plus
 * \p target_offset.
 *
 * \p presumed_offset should be written to \p bo at \p offset.
 */
int
intel_bo_add_reloc(struct intel_bo *bo, uint32_t offset,
                   struct intel_bo *target_bo, uint32_t target_offset,
                   uint32_t read_domains, uint32_t write_domain,
                   uint64_t *presumed_offset);

/**
 * Return the current number of relocations.
 */
int
intel_bo_get_reloc_count(struct intel_bo *bo);

/**
 * Truncate all relocations except the first \p start ones.
 *
 * Combined with \p intel_bo_get_reloc_count(), they can be used to undo the
 * \p intel_bo_add_reloc() calls that were just made.
 */
void
intel_bo_truncate_relocs(struct intel_bo *bo, int start);

/**
 * Return true if \p target_bo is on the relocation list of \p bo, or on
 * the relocation list of some bo that is referenced by \p bo.
 */
bool
intel_bo_has_reloc(struct intel_bo *bo, struct intel_bo *target_bo);

/**
 * Wait until \bo is idle, or \p timeout nanoseconds have passed.  A
 * negative timeout means to wait indefinitely.
 *
 * \return 0 only when \p bo is idle
 */
int
intel_bo_wait(struct intel_bo *bo, int64_t timeout);

/**
 * Return true if \p bo is busy.
 */
static inline bool
intel_bo_is_busy(struct intel_bo *bo)
{
   return (intel_bo_wait(bo, 0) != 0);
}

#endif /* INTEL_WINSYS_H */
@


1.3
log
@Merge Mesa 10.2.9
@
text
@@


1.2
log
@Merge Mesa 10.4.3
Tested by matthieu@@ mpi@@ and myself.  landry@@ ran a ports bulk build.
kettenis@@ tracked down the cause of an alignment fault on archs
that require strict eight byte pointer alignment.
@
text
@d4 1
a4 1
 * Copyright (C) 2012-2013 LunarG, Inc.
d34 8
a42 9
   /* bits[2:0]: ring type */
   INTEL_EXEC_DEFAULT         = 0 << 0,
   INTEL_EXEC_RENDER          = 1 << 0,
   INTEL_EXEC_BSD             = 2 << 0,
   INTEL_EXEC_BLT             = 3 << 0,

   /* bits[7:6]: constant buffer addressing mode */

   /* bits[8]: reset SO write offset register on GEN7+ */
a63 5
/* this is compatible with intel_bufmgr.h's definitions */
enum intel_alloc_flag {
   INTEL_ALLOC_FOR_RENDER     = 1 << 0,
};

d71 2
d74 8
a82 1
   bool has_address_swizzling;
d94 3
a96 3
void
intel_winsys_enable_reuse(struct intel_winsys *winsys);

d100 3
d107 7
d118 7
d129 1
a129 1
                          unsigned long flags);
d131 11
d147 1
a147 1
                           unsigned long flags,
d150 3
d162 1
a162 1
 * Export a handle for inter-process sharing.
d171 16
d188 5
a192 3
intel_winsys_check_aperture_space(struct intel_winsys *winsys,
                                  struct intel_bo **bo_array,
                                  int count);
d194 6
d201 2
a202 2
intel_winsys_decode_commands(struct intel_winsys *winsys,
                             struct intel_bo *bo, int used);
d204 3
d210 4
a216 9
unsigned long
intel_bo_get_size(const struct intel_bo *bo);

unsigned long
intel_bo_get_offset(const struct intel_bo *bo);

void *
intel_bo_get_virtual(const struct intel_bo *bo);

d218 1
a218 1
 * Map/unmap \p bo for CPU access.
d220 5
a224 5
 * map() maps the backing store into CPU address space, cached.  This
 * variant allows for fast random reads and writes.  But the caller needs
 * handle tiling or swizzling manually if the bo is tiled or swizzled.  If
 * write is enabled and there is no shared last-level cache (LLC), unmap()
 * needs to flush the cache, which is rather expensive.
d226 4
a229 3
 * map_gtt() maps the bo for MMIO access, uncached but write-combined.
 * This variant promises a reasonable speed for sequential writes, but
 * reads would be very slow.  Callers always have a linear view of the bo.
d232 1
a232 1
 * wait until the bo is idle.
d234 1
a234 1
int
d237 1
a237 1
int
d240 1
a240 1
int
d243 3
d250 1
a250 1
 * Move data in to or out of the bo.
d255 4
d269 2
d273 4
a276 3
intel_bo_emit_reloc(struct intel_bo *bo, uint32_t offset,
                    struct intel_bo *target_bo, uint32_t target_offset,
                    uint32_t read_domains, uint32_t write_domain);
d285 1
a285 1
 * Discard all relocations except the first \p start ones.
d287 2
a288 2
 * Combined with \p get_reloc_count(), they can be used to undo
 * the \p emit_reloc() calls that were just made.
d291 1
a291 1
intel_bo_clear_relocs(struct intel_bo *bo, int start);
d298 1
a298 11
intel_bo_references(struct intel_bo *bo, struct intel_bo *target_bo);

/**
 * Submit \p bo for execution.
 *
 * \p bo and all bos referenced by \p bo will be considered busy until all
 * commands are parsed and executed.
 */
int
intel_bo_exec(struct intel_bo *bo, int used,
              struct intel_context *ctx, unsigned long flags);
@


1.1
log
@Initial revision
@
text
@@


1.1.1.1
log
@Import Mesa 9.2.0
@
text
@@


1.1.1.2
log
@Import Mesa 10.2.3
@
text
@d4 1
a4 1
 * Copyright (C) 2012-2014 LunarG, Inc.
d34 8
a41 6
enum intel_ring_type {
   INTEL_RING_RENDER    = 1,
   INTEL_RING_BSD       = 2,
   INTEL_RING_BLT       = 3,
   INTEL_RING_VEBOX     = 4,
};
d43 1
a43 2
/* this is compatible with i915_drm.h's definitions */
enum intel_exec_flag {
d65 5
a76 2

   int max_batch_size;
d78 1
a79 8
   bool has_logical_context;
   bool has_ppgtt;

   /* valid registers for intel_winsys_read_reg() */
   bool has_timestamp;

   /* valid flags for intel_winsys_submit_bo() */
   bool has_gen7_sol_reset;
d91 3
a93 3
/**
 * Create a logical context for use with the render ring.
 */
a96 3
/**
 * Destroy a logical context.
 */
a100 7
/**
 * Read a register.  Only registers that are considered safe, such as
 *
 *   TIMESTAMP (0x2358)
 *
 * can be read.
 */
a104 7
/**
 * Allocate a linear buffer object.
 *
 * \param name             Informative description of the bo.
 * \param size             Size of the bo.
 * \param initial_domain   Initial (write) domain.
 */
d109 1
a109 1
                          uint32_t initial_domain);
a110 11
/**
 * Allocate a 2-dimentional buffer object.
 *
 * \param name             Informative description of the bo.
 * \param width            Width of the bo.
 * \param height           Height of the bo.
 * \param cpp              Bytes per texel.
 * \param tiling           Tiling mode.
 * \param initial_domain   Initial (write) domain.
 * \param pitch            Pitch of the bo.
 */
d116 1
a116 1
                           uint32_t initial_domain,
a118 3
/**
 * Create a bo from a winsys handle.
 */
d128 1
a128 1
 * Export \p bo as a winsys handle for inter-process sharing.
a136 16
/**
 * Return true when buffer objects directly specified in \p bo_array, and
 * those indirectly referenced by them, can fit in the aperture space.
 */
bool
intel_winsys_can_submit_bo(struct intel_winsys *winsys,
                           struct intel_bo **bo_array,
                           int count);

/**
 * Submit \p bo for execution.
 *
 * \p bo and all bos referenced by \p bo will be considered busy until all
 * commands are parsed and executed.  \p ctx is ignored when the bo is not
 * submitted to the render ring.
 */
d138 3
a140 5
intel_winsys_submit_bo(struct intel_winsys *winsys,
                       enum intel_ring_type ring,
                       struct intel_bo *bo, int used,
                       struct intel_context *ctx,
                       unsigned long flags);
a141 6
/**
 * Decode the commands contained in \p bo.  For debugging.
 *
 * \param bo      Batch buffer to decode.
 * \param used    Size of the commands in bytes.
 */
d143 2
a144 2
intel_winsys_decode_bo(struct intel_winsys *winsys,
                       struct intel_bo *bo, int used);
a145 3
/**
 * Increase the reference count of \p bo.
 */
a148 4
/**
 * Decrease the reference count of \p bo.  When the reference count reaches
 * zero, \p bo is destroyed.
 */
d152 9
d162 1
a162 1
 * Map \p bo for CPU access.  Recursive mapping is allowed.
d164 5
a168 5
 * map() maps the backing store into CPU address space, cached.  It will block
 * if the bo is busy.  This variant allows fastest random reads and writes,
 * but the caller needs to handle tiling or swizzling manually if the bo is
 * tiled or swizzled.  If write is enabled and there is no shared last-level
 * cache (LLC), the CPU cache will be flushed, which is expensive.
d170 3
a172 4
 * map_gtt() maps the bo for MMIO access, uncached but write-combined.  It
 * will block if the bo is busy.  This variant promises a reasonable speed for
 * sequential writes, but reads would be very slow.  Callers always have a
 * linear view of the bo.
d175 1
a175 1
 * block.
d177 1
a177 1
void *
d180 1
a180 1
void *
d183 1
a183 1
void *
a185 3
/**
 * Unmap \p bo.
 */
d190 1
a190 1
 * Write data to \p bo.
a194 4

/**
 * Read data from the bo.
 */
a204 2
 *
 * \p presumed_offset should be written to \p bo at \p offset.
d207 3
a209 4
intel_bo_add_reloc(struct intel_bo *bo, uint32_t offset,
                   struct intel_bo *target_bo, uint32_t target_offset,
                   uint32_t read_domains, uint32_t write_domain,
                   uint64_t *presumed_offset);
d218 1
a218 1
 * Truncate all relocations except the first \p start ones.
d220 2
a221 2
 * Combined with \p intel_bo_get_reloc_count(), they can be used to undo the
 * \p intel_bo_add_reloc() calls that were just made.
d224 1
a224 1
intel_bo_truncate_relocs(struct intel_bo *bo, int start);
d231 11
a241 1
intel_bo_has_reloc(struct intel_bo *bo, struct intel_bo *target_bo);
@

