head	1.2;
access;
symbols
	OPENBSD_5_8:1.1.1.4.0.4
	OPENBSD_5_8_BASE:1.1.1.4
	OPENBSD_5_7:1.1.1.4.0.2
	OPENBSD_5_7_BASE:1.1.1.4
	v10_2_9:1.1.1.4
	v10_4_3:1.1.1.3
	v10_2_7:1.1.1.2
	OPENBSD_5_6:1.1.1.2.0.2
	OPENBSD_5_6_BASE:1.1.1.2
	v10_2_3:1.1.1.2
	OPENBSD_5_5:1.1.1.1.0.2
	OPENBSD_5_5_BASE:1.1.1.1
	v9_2_5:1.1.1.1
	v9_2_3:1.1.1.1
	v9_2_2:1.1.1.1
	v9_2_1:1.1.1.1
	v9_2_0:1.1.1.1
	mesa:1.1.1;
locks; strict;
comment	@ * @;
expand	@o@;


1.2
date	2015.12.23.05.17.42;	author jsg;	state dead;
branches;
next	1.1;
commitid	TnlogFl9nOv2eaRf;

1.1
date	2013.09.05.13.13.53;	author jsg;	state Exp;
branches
	1.1.1.1;
next	;

1.1.1.1
date	2013.09.05.13.13.53;	author jsg;	state Exp;
branches;
next	1.1.1.2;

1.1.1.2
date	2014.07.09.20.34.23;	author jsg;	state Exp;
branches;
next	1.1.1.3;
commitid	3JhLfwcuBALP0ZR7;

1.1.1.3
date	2015.01.25.14.09.53;	author jsg;	state Exp;
branches;
next	1.1.1.4;
commitid	ce2W5rH5aF7VS9gi;

1.1.1.4
date	2015.02.20.22.47.00;	author jsg;	state Exp;
branches;
next	;
commitid	F54a1i0WXHMxq7kE;


desc
@@


1.2
log
@remove the now unused Mesa 10.2.9 code
@
text
@/*
 * Mesa 3-D graphics library
 *
 * Copyright (C) 2012-2013 LunarG, Inc.
 *
 * Permission is hereby granted, free of charge, to any person obtaining a
 * copy of this software and associated documentation files (the "Software"),
 * to deal in the Software without restriction, including without limitation
 * the rights to use, copy, modify, merge, publish, distribute, sublicense,
 * and/or sell copies of the Software, and to permit persons to whom the
 * Software is furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included
 * in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
 * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
 * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
 * DEALINGS IN THE SOFTWARE.
 *
 * Authors:
 *    Chia-I Wu <olv@@lunarg.com>
 */

#include <string.h>
#include <errno.h>
#ifndef ETIME
#define ETIME ETIMEDOUT
#endif

#include <xf86drm.h>
#include <i915_drm.h>
#include <intel_bufmgr.h>

#include "state_tracker/drm_driver.h"
#include "pipe/p_state.h"
#include "util/u_inlines.h"
#include "util/u_memory.h"
#include "util/u_debug.h"
#include "../intel_winsys.h"

#define BATCH_SZ (8192 * sizeof(uint32_t))

struct intel_winsys {
   int fd;
   drm_intel_bufmgr *bufmgr;
   struct intel_winsys_info info;

   struct drm_intel_decode *decode;
};

static bool
get_param(struct intel_winsys *winsys, int param, int *value)
{
   struct drm_i915_getparam gp;
   int err;

   *value = 0;

   memset(&gp, 0, sizeof(gp));
   gp.param = param;
   gp.value = value;

   err = drmCommandWriteRead(winsys->fd, DRM_I915_GETPARAM, &gp, sizeof(gp));
   if (err) {
      *value = 0;
      return false;
   }

   return true;
}

static bool
test_address_swizzling(struct intel_winsys *winsys)
{
   drm_intel_bo *bo;
   uint32_t tiling = I915_TILING_X, swizzle;
   unsigned long pitch;

   bo = drm_intel_bo_alloc_tiled(winsys->bufmgr,
         "address swizzling test", 64, 64, 4, &tiling, &pitch, 0);
   if (bo) {
      drm_intel_bo_get_tiling(bo, &tiling, &swizzle);
      drm_intel_bo_unreference(bo);
   }
   else {
      swizzle = I915_BIT_6_SWIZZLE_NONE;
   }

   return (swizzle != I915_BIT_6_SWIZZLE_NONE);
}

static bool
init_info(struct intel_winsys *winsys)
{
   struct intel_winsys_info *info = &winsys->info;
   int val;

   /* follow the classic driver here */
   get_param(winsys, I915_PARAM_HAS_RELAXED_DELTA, &val);
   if (!val) {
      debug_error("kernel 2.6.39 required");
      return false;
   }

   info->devid = drm_intel_bufmgr_gem_get_devid(winsys->bufmgr);

   get_param(winsys, I915_PARAM_HAS_LLC, &val);
   info->has_llc = val;

   get_param(winsys, I915_PARAM_HAS_GEN7_SOL_RESET, &val);
   info->has_gen7_sol_reset = val;

   info->has_address_swizzling = test_address_swizzling(winsys);

   return true;
}

struct intel_winsys *
intel_winsys_create_for_fd(int fd)
{
   struct intel_winsys *winsys;

   winsys = CALLOC_STRUCT(intel_winsys);
   if (!winsys)
      return NULL;

   winsys->fd = fd;

   winsys->bufmgr = drm_intel_bufmgr_gem_init(winsys->fd, BATCH_SZ);
   if (!winsys->bufmgr) {
      debug_error("failed to create GEM buffer manager");
      FREE(winsys);
      return NULL;
   }

   if (!init_info(winsys)) {
      drm_intel_bufmgr_destroy(winsys->bufmgr);
      FREE(winsys);
      return NULL;
   }

   drm_intel_bufmgr_gem_enable_fenced_relocs(winsys->bufmgr);

   return winsys;
}

void
intel_winsys_destroy(struct intel_winsys *winsys)
{
   if (winsys->decode)
      drm_intel_decode_context_free(winsys->decode);

   drm_intel_bufmgr_destroy(winsys->bufmgr);
   FREE(winsys);
}

const struct intel_winsys_info *
intel_winsys_get_info(const struct intel_winsys *winsys)
{
   return &winsys->info;
}

void
intel_winsys_enable_reuse(struct intel_winsys *winsys)
{
   drm_intel_bufmgr_gem_enable_reuse(winsys->bufmgr);
}

struct intel_context *
intel_winsys_create_context(struct intel_winsys *winsys)
{
   return (struct intel_context *)
      drm_intel_gem_context_create(winsys->bufmgr);
}

void
intel_winsys_destroy_context(struct intel_winsys *winsys,
                             struct intel_context *ctx)
{
   drm_intel_gem_context_destroy((drm_intel_context *) ctx);
}

int
intel_winsys_read_reg(struct intel_winsys *winsys,
                      uint32_t reg, uint64_t *val)
{
   return drm_intel_reg_read(winsys->bufmgr, reg, val);
}

struct intel_bo *
intel_winsys_alloc_buffer(struct intel_winsys *winsys,
                          const char *name,
                          unsigned long size,
                          unsigned long flags)
{
   const int alignment = 4096; /* always page-aligned */
   drm_intel_bo *bo;

   if (flags == INTEL_ALLOC_FOR_RENDER) {
      bo = drm_intel_bo_alloc_for_render(winsys->bufmgr,
            name, size, alignment);
   }
   else {
      assert(!flags);
      bo = drm_intel_bo_alloc(winsys->bufmgr, name, size, alignment);
   }

   return (struct intel_bo *) bo;
}

struct intel_bo *
intel_winsys_alloc_texture(struct intel_winsys *winsys,
                           const char *name,
                           int width, int height, int cpp,
                           enum intel_tiling_mode tiling,
                           unsigned long flags,
                           unsigned long *pitch)
{
   uint32_t real_tiling = tiling;
   drm_intel_bo *bo;

   bo = drm_intel_bo_alloc_tiled(winsys->bufmgr, name,
         width, height, cpp, &real_tiling, pitch, flags);
   if (!bo)
      return NULL;

   if (real_tiling != tiling) {
      assert(!"tiling mismatch");
      drm_intel_bo_unreference(bo);
      return NULL;
   }

   return (struct intel_bo *) bo;
}

struct intel_bo *
intel_winsys_import_handle(struct intel_winsys *winsys,
                           const char *name,
                           const struct winsys_handle *handle,
                           int width, int height, int cpp,
                           enum intel_tiling_mode *tiling,
                           unsigned long *pitch)
{
   uint32_t real_tiling, swizzle;
   drm_intel_bo *bo;
   int err;

   switch (handle->type) {
   case DRM_API_HANDLE_TYPE_SHARED:
      {
         const uint32_t gem_name = handle->handle;
         bo = drm_intel_bo_gem_create_from_name(winsys->bufmgr,
               name, gem_name);
      }
      break;
#if 0
   case DRM_API_HANDLE_TYPE_FD:
      {
         const int fd = (int) handle->handle;
         bo = drm_intel_bo_gem_create_from_prime(winsys->bufmgr,
               fd, height * handle->stride);
      }
      break;
#endif
   default:
      bo = NULL;
      break;
   }

   if (!bo)
      return NULL;

   err = drm_intel_bo_get_tiling(bo, &real_tiling, &swizzle);
   if (err) {
      drm_intel_bo_unreference(bo);
      return NULL;
   }

   *tiling = real_tiling;
   *pitch = handle->stride;

   return (struct intel_bo *) bo;
}

int
intel_winsys_export_handle(struct intel_winsys *winsys,
                           struct intel_bo *bo,
                           enum intel_tiling_mode tiling,
                           unsigned long pitch,
                           struct winsys_handle *handle)
{
   int err = 0;

   switch (handle->type) {
   case DRM_API_HANDLE_TYPE_SHARED:
      {
         uint32_t name;

         err = drm_intel_bo_flink((drm_intel_bo *) bo, &name);
         if (!err)
            handle->handle = name;
      }
      break;
   case DRM_API_HANDLE_TYPE_KMS:
      handle->handle = ((drm_intel_bo *) bo)->handle;
      break;
#if 0
   case DRM_API_HANDLE_TYPE_FD:
      {
         int fd;

         err = drm_intel_bo_gem_export_to_prime((drm_intel_bo *) bo, &fd);
         if (!err)
            handle->handle = fd;
      }
      break;
#endif
   default:
      err = -EINVAL;
      break;
   }

   if (err)
      return err;

   handle->stride = pitch;

   return 0;
}

int
intel_winsys_check_aperture_space(struct intel_winsys *winsys,
                                  struct intel_bo **bo_array,
                                  int count)
{
   return drm_intel_bufmgr_check_aperture_space((drm_intel_bo **) bo_array,
                                                count);
}

void
intel_winsys_decode_commands(struct intel_winsys *winsys,
                             struct intel_bo *bo, int used)
{
   int err;

   if (!winsys->decode) {
      winsys->decode = drm_intel_decode_context_alloc(winsys->info.devid);
      if (!winsys->decode)
         return;

      /* debug_printf()/debug_error() uses stderr by default */
      drm_intel_decode_set_output_file(winsys->decode, stderr);
   }

   err = intel_bo_map(bo, false);
   if (err) {
      debug_printf("failed to map buffer for decoding\n");
      return;
   }

   /* in dwords */
   used /= 4;

   drm_intel_decode_set_batch_pointer(winsys->decode,
         intel_bo_get_virtual(bo), intel_bo_get_offset(bo), used);

   drm_intel_decode(winsys->decode);

   intel_bo_unmap(bo);
}

void
intel_bo_reference(struct intel_bo *bo)
{
   drm_intel_bo_reference((drm_intel_bo *) bo);
}

void
intel_bo_unreference(struct intel_bo *bo)
{
   drm_intel_bo_unreference((drm_intel_bo *) bo);
}

unsigned long
intel_bo_get_size(const struct intel_bo *bo)
{
   return ((drm_intel_bo *) bo)->size;
}

unsigned long
intel_bo_get_offset(const struct intel_bo *bo)
{
   return ((drm_intel_bo *) bo)->offset;
}

void *
intel_bo_get_virtual(const struct intel_bo *bo)
{
   return ((drm_intel_bo *) bo)->virtual;
}

int
intel_bo_map(struct intel_bo *bo, bool write_enable)
{
   return drm_intel_bo_map((drm_intel_bo *) bo, write_enable);
}

int
intel_bo_map_gtt(struct intel_bo *bo)
{
   return drm_intel_gem_bo_map_gtt((drm_intel_bo *) bo);
}

int
intel_bo_map_unsynchronized(struct intel_bo *bo)
{
   return drm_intel_gem_bo_map_unsynchronized((drm_intel_bo *) bo);
}

void
intel_bo_unmap(struct intel_bo *bo)
{
   int err;

   err = drm_intel_bo_unmap((drm_intel_bo *) bo);
   assert(!err);
}

int
intel_bo_pwrite(struct intel_bo *bo, unsigned long offset,
                unsigned long size, const void *data)
{
   return drm_intel_bo_subdata((drm_intel_bo *) bo, offset, size, data);
}

int
intel_bo_pread(struct intel_bo *bo, unsigned long offset,
               unsigned long size, void *data)
{
   return drm_intel_bo_get_subdata((drm_intel_bo *) bo, offset, size, data);
}

int
intel_bo_emit_reloc(struct intel_bo *bo, uint32_t offset,
                    struct intel_bo *target_bo, uint32_t target_offset,
                    uint32_t read_domains, uint32_t write_domain)
{
   return drm_intel_bo_emit_reloc((drm_intel_bo *) bo, offset,
         (drm_intel_bo *) target_bo, target_offset,
         read_domains, write_domain);
}

int
intel_bo_get_reloc_count(struct intel_bo *bo)
{
   return drm_intel_gem_bo_get_reloc_count((drm_intel_bo *) bo);
}

void
intel_bo_clear_relocs(struct intel_bo *bo, int start)
{
   return drm_intel_gem_bo_clear_relocs((drm_intel_bo *) bo, start);
}

bool
intel_bo_references(struct intel_bo *bo, struct intel_bo *target_bo)
{
   return drm_intel_bo_references((drm_intel_bo *) bo,
         (drm_intel_bo *) target_bo);
}

int
intel_bo_exec(struct intel_bo *bo, int used,
              struct intel_context *ctx, unsigned long flags)
{
   if (ctx) {
      return drm_intel_gem_bo_context_exec((drm_intel_bo *) bo,
            (drm_intel_context *) ctx, used, flags);
   }
   else {
      return drm_intel_bo_mrb_exec((drm_intel_bo *) bo,
            used, NULL, 0, 0, flags);
   }
}

int
intel_bo_wait(struct intel_bo *bo, int64_t timeout)
{
   int err;

   err = drm_intel_gem_bo_wait((drm_intel_bo *) bo, timeout);
   /* consider the bo idle on errors */
   if (err && err != -ETIME)
      err = 0;

   return err;
}
@


1.1
log
@Initial revision
@
text
@@


1.1.1.1
log
@Import Mesa 9.2.0
@
text
@@


1.1.1.2
log
@Import Mesa 10.2.3
@
text
@d4 1
a4 1
 * Copyright (C) 2012-2014 LunarG, Inc.
a37 1
#include "os/os_thread.h"
a51 3
   /* these are protected by the mutex */
   pipe_mutex mutex;
   drm_intel_context *first_gem_ctx;
a54 6
static drm_intel_bo *
gem_bo(const struct intel_bo *bo)
{
   return (drm_intel_bo *) bo;
}

d97 1
a97 9
test_reg_read(struct intel_winsys *winsys, uint32_t reg)
{
   uint64_t dummy;

   return !drm_intel_reg_read(winsys->bufmgr, reg, &dummy);
}

static bool
probe_winsys(struct intel_winsys *winsys)
d102 1
a102 14
   /*
    * When we need the Nth vertex from a user vertex buffer, and the vertex is
    * uploaded to, say, the beginning of a bo, we want the first vertex in the
    * bo to be fetched.  One way to do this is to set the base address of the
    * vertex buffer to
    *
    *   bo->offset64 + (vb->buffer_offset - vb->stride * N).
    *
    * The second term may be negative, and we need kernel support to do that.
    *
    * This check is taken from the classic driver.  u_vbuf_upload_buffers()
    * guarantees the term is never negative, but it is good to require a
    * recent kernel.
    */
a110 2
   info->max_batch_size = BATCH_SZ;

a112 10
   info->has_address_swizzling = test_address_swizzling(winsys);

   winsys->first_gem_ctx = drm_intel_gem_context_create(winsys->bufmgr);
   info->has_logical_context = (winsys->first_gem_ctx != NULL);

   get_param(winsys, I915_PARAM_HAS_ALIASING_PPGTT, &val);
   info->has_ppgtt = val;

   /* test TIMESTAMP read */
   info->has_timestamp = test_reg_read(winsys, 0x2358);
d117 2
d140 1
a140 3
   pipe_mutex_init(winsys->mutex);

   if (!probe_winsys(winsys)) {
a145 9
   /*
    * No need to implicitly set up a fence register for each non-linear reloc
    * entry.  When a fence register is needed for a reloc entry,
    * drm_intel_bo_emit_reloc_fence() will be called explicitly.
    *
    * intel_bo_add_reloc() currently lacks "bool fenced" for this to work.
    * But we never need a fence register on GEN4+ so we do not need to worry
    * about it yet.
    */
a147 2
   drm_intel_bufmgr_gem_enable_reuse(winsys->bufmgr);

a156 4
   if (winsys->first_gem_ctx)
      drm_intel_gem_context_destroy(winsys->first_gem_ctx);

   pipe_mutex_destroy(winsys->mutex);
d167 6
d176 2
a177 12
   drm_intel_context *gem_ctx;

   /* try the preallocated context first */
   pipe_mutex_lock(winsys->mutex);
   gem_ctx = winsys->first_gem_ctx;
   winsys->first_gem_ctx = NULL;
   pipe_mutex_unlock(winsys->mutex);

   if (!gem_ctx)
      gem_ctx = drm_intel_gem_context_create(winsys->bufmgr);

   return (struct intel_context *) gem_ctx;
d198 1
a198 1
                          uint32_t initial_domain)
a199 2
   const bool for_render =
      (initial_domain & (INTEL_DOMAIN_RENDER | INTEL_DOMAIN_INSTRUCTION));
d203 1
a203 1
   if (for_render) {
d208 1
d220 1
a220 1
                           uint32_t initial_domain,
a222 3
   const unsigned long flags =
      (initial_domain & (INTEL_DOMAIN_RENDER | INTEL_DOMAIN_INSTRUCTION)) ?
      BO_ALLOC_FOR_RENDER : 0;
d260 1
d268 1
d303 1
a303 1
         err = drm_intel_bo_flink(gem_bo(bo), &name);
d309 1
a309 1
      handle->handle = gem_bo(bo)->handle;
d311 1
d316 1
a316 1
         err = drm_intel_bo_gem_export_to_prime(gem_bo(bo), &fd);
d321 1
a334 9
bool
intel_winsys_can_submit_bo(struct intel_winsys *winsys,
                           struct intel_bo **bo_array,
                           int count)
{
   return !drm_intel_bufmgr_check_aperture_space((drm_intel_bo **) bo_array,
                                                 count);
}

d336 3
a338 5
intel_winsys_submit_bo(struct intel_winsys *winsys,
                       enum intel_ring_type ring,
                       struct intel_bo *bo, int used,
                       struct intel_context *ctx,
                       unsigned long flags)
d340 2
a341 14
   const unsigned long exec_flags = (unsigned long) ring | flags;

   /* logical contexts are only available for the render ring */
   if (ring != INTEL_RING_RENDER)
      ctx = NULL;

   if (ctx) {
      return drm_intel_gem_bo_context_exec(gem_bo(bo),
            (drm_intel_context *) ctx, used, exec_flags);
   }
   else {
      return drm_intel_bo_mrb_exec(gem_bo(bo),
            used, NULL, 0, 0, exec_flags);
   }
d345 2
a346 2
intel_winsys_decode_bo(struct intel_winsys *winsys,
                       struct intel_bo *bo, int used)
d348 1
a348 9
   void *ptr;

   ptr = intel_bo_map(bo, false);
   if (!ptr) {
      debug_printf("failed to map buffer for decoding\n");
      return;
   }

   pipe_mutex_lock(winsys->mutex);
d352 1
a352 3
      if (!winsys->decode) {
         pipe_mutex_unlock(winsys->mutex);
         intel_bo_unmap(bo);
a353 1
      }
d359 6
d369 1
a369 1
         ptr, gem_bo(bo)->offset64, used);
a372 2
   pipe_mutex_unlock(winsys->mutex);

d379 1
a379 1
   drm_intel_bo_reference(gem_bo(bo));
d385 1
a385 1
   drm_intel_bo_unreference(gem_bo(bo));
d388 2
a389 2
void *
intel_bo_map(struct intel_bo *bo, bool write_enable)
d391 2
a392 1
   int err;
d394 4
a397 7
   err = drm_intel_bo_map(gem_bo(bo), write_enable);
   if (err) {
      debug_error("failed to map bo");
      return NULL;
   }

   return gem_bo(bo)->virtual;
d401 1
a401 1
intel_bo_map_gtt(struct intel_bo *bo)
d403 2
a404 1
   int err;
d406 5
a410 5
   err = drm_intel_gem_bo_map_gtt(gem_bo(bo));
   if (err) {
      debug_error("failed to map bo");
      return NULL;
   }
d412 4
a415 1
   return gem_bo(bo)->virtual;
d418 1
a418 1
void *
d421 1
a421 9
   int err;

   err = drm_intel_gem_bo_map_unsynchronized(gem_bo(bo));
   if (err) {
      debug_error("failed to map bo");
      return NULL;
   }

   return gem_bo(bo)->virtual;
d429 1
a429 1
   err = drm_intel_bo_unmap(gem_bo(bo));
d437 1
a437 1
   return drm_intel_bo_subdata(gem_bo(bo), offset, size, data);
d444 1
a444 1
   return drm_intel_bo_get_subdata(gem_bo(bo), offset, size, data);
d448 3
a450 4
intel_bo_add_reloc(struct intel_bo *bo, uint32_t offset,
                   struct intel_bo *target_bo, uint32_t target_offset,
                   uint32_t read_domains, uint32_t write_domain,
                   uint64_t *presumed_offset)
d452 2
a453 4
   int err;

   err = drm_intel_bo_emit_reloc(gem_bo(bo), offset,
         gem_bo(target_bo), target_offset,
a454 4

   *presumed_offset = gem_bo(target_bo)->offset64 + target_offset;

   return err;
d460 1
a460 1
   return drm_intel_gem_bo_get_reloc_count(gem_bo(bo));
d464 1
a464 1
intel_bo_truncate_relocs(struct intel_bo *bo, int start)
d466 1
a466 1
   drm_intel_gem_bo_clear_relocs(gem_bo(bo), start);
d470 1
a470 1
intel_bo_has_reloc(struct intel_bo *bo, struct intel_bo *target_bo)
d472 16
a487 1
   return drm_intel_bo_references(gem_bo(bo), gem_bo(target_bo));
d495 1
a495 1
   err = drm_intel_gem_bo_wait(gem_bo(bo), timeout);
@


1.1.1.3
log
@Import Mesa 10.4.3
@
text
@d44 3
a46 2
#include "ilo/intel_winsys.h"
#include "intel_drm_public.h"
d142 1
a142 5
   if (drm_intel_get_aperture_sizes(winsys->fd,
         &info->aperture_mappable, &info->aperture_total)) {
      debug_error("failed to query aperture sizes");
      return false;
   }
a165 2
   /* so that we can have enough (up to 4094) relocs per bo */
   const int batch_size = sizeof(uint32_t) * 8192;
d174 1
a174 1
   winsys->bufmgr = drm_intel_bufmgr_gem_init(winsys->fd, batch_size);
a183 1
      pipe_mutex_destroy(winsys->mutex);
d191 6
a196 1
    * entry.  INTEL_RELOC_FENCE will be set on reloc entries that need them.
d257 8
a264 9
intel_winsys_alloc_bo(struct intel_winsys *winsys,
                      const char *name,
                      enum intel_tiling_mode tiling,
                      unsigned long pitch,
                      unsigned long height,
                      bool cpu_init)
{
   const unsigned int alignment = 4096; /* always page-aligned */
   unsigned long size;
d267 6
a272 11
   switch (tiling) {
   case INTEL_TILING_X:
      if (pitch % 512)
         return NULL;
      break;
   case INTEL_TILING_Y:
      if (pitch % 128)
         return NULL;
      break;
   default:
      break;
d275 2
a276 2
   if (pitch > ULONG_MAX / height)
      return NULL;
d278 13
a290 1
   size = pitch * height;
d292 4
a295 7
   if (cpu_init) {
      bo = drm_intel_bo_alloc(winsys->bufmgr, name, size, alignment);
   }
   else {
      bo = drm_intel_bo_alloc_for_render(winsys->bufmgr,
            name, size, alignment);
   }
d297 4
a300 10
   if (bo && tiling != INTEL_TILING_NONE) {
      uint32_t real_tiling = tiling;
      int err;

      err = drm_intel_bo_set_tiling(bo, &real_tiling, pitch);
      if (err || real_tiling != tiling) {
         assert(!"tiling mismatch");
         drm_intel_bo_unreference(bo);
         return NULL;
      }
d310 1
a310 1
                           unsigned long height,
a357 1
                           unsigned long height,
d509 1
a509 1
intel_bo_map_gtt_async(struct intel_bo *bo)
d548 2
a549 1
                   uint32_t flags, uint64_t *presumed_offset)
a550 1
   uint32_t read_domains, write_domain;
d553 3
a555 26
   if (flags & INTEL_RELOC_WRITE) {
      /*
       * Because of the translation to domains, INTEL_RELOC_GGTT should only
       * be set on GEN6 when the bo is written by MI_* or PIPE_CONTROL.  The
       * kernel will translate it back to INTEL_RELOC_GGTT.
       */
      write_domain = (flags & INTEL_RELOC_GGTT) ?
         I915_GEM_DOMAIN_INSTRUCTION : I915_GEM_DOMAIN_RENDER;
      read_domains = write_domain;
   } else {
      write_domain = 0;
      read_domains = I915_GEM_DOMAIN_RENDER |
                     I915_GEM_DOMAIN_SAMPLER |
                     I915_GEM_DOMAIN_INSTRUCTION |
                     I915_GEM_DOMAIN_VERTEX;
   }

   if (flags & INTEL_RELOC_FENCE) {
      err = drm_intel_bo_emit_reloc_fence(gem_bo(bo), offset,
            gem_bo(target_bo), target_offset,
            read_domains, write_domain);
   } else {
      err = drm_intel_bo_emit_reloc(gem_bo(bo), offset,
            gem_bo(target_bo), target_offset,
            read_domains, write_domain);
   }
d585 1
a585 7
   if (timeout >= 0) {
      err = drm_intel_gem_bo_wait(gem_bo(bo), timeout);
   } else {
      drm_intel_bo_wait_rendering(gem_bo(bo));
      err = 0;
   }

@


1.1.1.4
log
@Import Mesa 10.2.9
@
text
@d44 2
a45 3
#include "../intel_winsys.h"

#define BATCH_SZ (8192 * sizeof(uint32_t))
d141 5
a145 1
   info->max_batch_size = BATCH_SZ;
d169 2
d179 1
a179 1
   winsys->bufmgr = drm_intel_bufmgr_gem_init(winsys->fd, BATCH_SZ);
d189 1
d197 1
a197 6
    * entry.  When a fence register is needed for a reloc entry,
    * drm_intel_bo_emit_reloc_fence() will be called explicitly.
    *
    * intel_bo_add_reloc() currently lacks "bool fenced" for this to work.
    * But we never need a fence register on GEN4+ so we do not need to worry
    * about it yet.
d258 9
a266 8
intel_winsys_alloc_buffer(struct intel_winsys *winsys,
                          const char *name,
                          unsigned long size,
                          uint32_t initial_domain)
{
   const bool for_render =
      (initial_domain & (INTEL_DOMAIN_RENDER | INTEL_DOMAIN_INSTRUCTION));
   const int alignment = 4096; /* always page-aligned */
d269 11
a279 6
   if (for_render) {
      bo = drm_intel_bo_alloc_for_render(winsys->bufmgr,
            name, size, alignment);
   }
   else {
      bo = drm_intel_bo_alloc(winsys->bufmgr, name, size, alignment);
d282 2
a283 2
   return (struct intel_bo *) bo;
}
d285 1
a285 13
struct intel_bo *
intel_winsys_alloc_texture(struct intel_winsys *winsys,
                           const char *name,
                           int width, int height, int cpp,
                           enum intel_tiling_mode tiling,
                           uint32_t initial_domain,
                           unsigned long *pitch)
{
   const unsigned long flags =
      (initial_domain & (INTEL_DOMAIN_RENDER | INTEL_DOMAIN_INSTRUCTION)) ?
      BO_ALLOC_FOR_RENDER : 0;
   uint32_t real_tiling = tiling;
   drm_intel_bo *bo;
d287 7
a293 4
   bo = drm_intel_bo_alloc_tiled(winsys->bufmgr, name,
         width, height, cpp, &real_tiling, pitch, flags);
   if (!bo)
      return NULL;
d295 10
a304 4
   if (real_tiling != tiling) {
      assert(!"tiling mismatch");
      drm_intel_bo_unreference(bo);
      return NULL;
d314 1
a314 1
                           int width, int height, int cpp,
d362 1
d514 1
a514 1
intel_bo_map_unsynchronized(struct intel_bo *bo)
d553 1
a553 2
                   uint32_t read_domains, uint32_t write_domain,
                   uint64_t *presumed_offset)
d555 1
d558 26
a583 3
   err = drm_intel_bo_emit_reloc(gem_bo(bo), offset,
         gem_bo(target_bo), target_offset,
         read_domains, write_domain);
d613 7
a619 1
   err = drm_intel_gem_bo_wait(gem_bo(bo), timeout);
@


