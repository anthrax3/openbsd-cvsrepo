head	1.6;
access;
symbols
	OPENBSD_5_4:1.5.0.8
	OPENBSD_5_4_BASE:1.5
	OPENBSD_5_3:1.5.0.6
	OPENBSD_5_3_BASE:1.5
	OPENBSD_5_2:1.5.0.4
	OPENBSD_5_2_BASE:1.5
	OPENBSD_5_1_BASE:1.5
	OPENBSD_5_1:1.5.0.2
	v7_10_3:1.1.1.3
	OPENBSD_5_0:1.4.0.6
	OPENBSD_5_0_BASE:1.4
	OPENBSD_4_9:1.4.0.2
	OPENBSD_4_9_BASE:1.4
	OPENBSD_4_8:1.4.0.4
	OPENBSD_4_8_BASE:1.4
	OPENBSD_4_7:1.3.0.4
	OPENBSD_4_7_BASE:1.3
	OPENBSD_4_6:1.3.0.2
	OPENBSD_4_6_BASE:1.3
	OPENBSD_4_5:1.2.0.2
	OPENBSD_4_5_BASE:1.2
	OPENBSD_4_4:1.1.1.2.0.4
	OPENBSD_4_4_BASE:1.1.1.2
	OPENBSD_4_3_BASE:1.1.1.2
	OPENBSD_4_3:1.1.1.2.0.2
	v7_0_1:1.1.1.2
	OPENBSD_4_2:1.1.1.1.0.2
	OPENBSD_4_2_BASE:1.1.1.1
	v6_5_2:1.1.1.1
	v6_5_1:1.1.1.1
	mesa:1.1.1;
locks; strict;
comment	@ * @;


1.6
date	2013.09.05.14.05.02;	author jsg;	state dead;
branches;
next	1.5;

1.5
date	2011.10.23.13.37.40;	author matthieu;	state Exp;
branches;
next	1.4;

1.4
date	2010.05.22.20.06.23;	author matthieu;	state Exp;
branches;
next	1.3;

1.3
date	2009.05.17.20.26.40;	author matthieu;	state Exp;
branches;
next	1.2;

1.2
date	2008.11.02.14.58.17;	author matthieu;	state Exp;
branches;
next	1.1;

1.1
date	2006.11.25.18.53.31;	author matthieu;	state Exp;
branches
	1.1.1.1;
next	;

1.1.1.1
date	2006.11.25.18.53.31;	author matthieu;	state Exp;
branches;
next	1.1.1.2;

1.1.1.2
date	2007.11.24.17.29.26;	author matthieu;	state Exp;
branches;
next	1.1.1.3;

1.1.1.3
date	2011.10.23.13.29.40;	author matthieu;	state Exp;
branches;
next	;


desc
@@


1.6
log
@Merge Mesa 9.2.0
@
text
@/**************************************************************************

Copyright (C) 2004 Nicolai Haehnle.

All Rights Reserved.

Permission is hereby granted, free of charge, to any person obtaining a
copy of this software and associated documentation files (the "Software"),
to deal in the Software without restriction, including without limitation
on the rights to use, copy, modify, merge, publish, distribute, sub
license, and/or sell copies of the Software, and to permit persons to whom
the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice (including the next
paragraph) shall be included in all copies or substantial portions of the
Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL
ATI, VA LINUX SYSTEMS AND/OR THEIR SUPPLIERS BE LIABLE FOR ANY CLAIM,
DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
USE OR OTHER DEALINGS IN THE SOFTWARE.

**************************************************************************/

/**
 * \file
 *
 * \brief R300 Render (Vertex Buffer Implementation)
 *
 * The immediate implementation has been removed from CVS in favor of the vertex
 * buffer implementation.
 *
 * The render functions are called by the pipeline manager to render a batch of
 * primitives. They return TRUE to pass on to the next stage (i.e. software
 * rasterization) or FALSE to indicate that the pipeline has finished after
 * rendering something.
 *
 * When falling back to software TCL still attempt to use hardware
 * rasterization.
 *
 * I am not sure that the cache related registers are setup correctly, but
 * obviously this does work... Further investigation is needed.
 *
 * \author Nicolai Haehnle <prefect_@@gmx.net>
 *
 * \todo Add immediate implementation back? Perhaps this is useful if there are
 * no bugs...
 */

#include "r300_render.h"

#include "main/glheader.h"
#include "main/imports.h"
#include "main/enums.h"
#include "main/macros.h"
#include "main/context.h"
#include "main/dd.h"
#include "main/simple_list.h"
#include "main/api_arrayelt.h"
#include "swrast/swrast.h"
#include "swrast_setup/swrast_setup.h"
#include "vbo/vbo.h"
#include "vbo/vbo_split.h"
#include "r300_context.h"
#include "r300_state.h"
#include "r300_reg.h"
#include "r300_emit.h"
#include "r300_swtcl.h"

/**
 * \brief Convert a OpenGL primitive type into a R300 primitive type.
 */
int r300PrimitiveType(r300ContextPtr rmesa, int prim)
{
	switch (prim & PRIM_MODE_MASK) {
	case GL_POINTS:
		return R300_VAP_VF_CNTL__PRIM_POINTS;
		break;
	case GL_LINES:
		return R300_VAP_VF_CNTL__PRIM_LINES;
		break;
	case GL_LINE_STRIP:
		return R300_VAP_VF_CNTL__PRIM_LINE_STRIP;
		break;
	case GL_LINE_LOOP:
		return R300_VAP_VF_CNTL__PRIM_LINE_LOOP;
		break;
	case GL_TRIANGLES:
		return R300_VAP_VF_CNTL__PRIM_TRIANGLES;
		break;
	case GL_TRIANGLE_STRIP:
		return R300_VAP_VF_CNTL__PRIM_TRIANGLE_STRIP;
		break;
	case GL_TRIANGLE_FAN:
		return R300_VAP_VF_CNTL__PRIM_TRIANGLE_FAN;
		break;
	case GL_QUADS:
		return R300_VAP_VF_CNTL__PRIM_QUADS;
		break;
	case GL_QUAD_STRIP:
		return R300_VAP_VF_CNTL__PRIM_QUAD_STRIP;
		break;
	case GL_POLYGON:
		return R300_VAP_VF_CNTL__PRIM_POLYGON;
		break;
	default:
		assert(0);
		return -1;
		break;
	}
}

int r300NumVerts(r300ContextPtr rmesa, int num_verts, int prim)
{
	int verts_off = 0;

	switch (prim & PRIM_MODE_MASK) {
	case GL_POINTS:
		verts_off = 0;
		break;
	case GL_LINES:
		verts_off = num_verts % 2;
		break;
	case GL_LINE_STRIP:
		if (num_verts < 2)
			verts_off = num_verts;
		break;
	case GL_LINE_LOOP:
		if (num_verts < 2)
			verts_off = num_verts;
		break;
	case GL_TRIANGLES:
		verts_off = num_verts % 3;
		break;
	case GL_TRIANGLE_STRIP:
		if (num_verts < 3)
			verts_off = num_verts;
		break;
	case GL_TRIANGLE_FAN:
		if (num_verts < 3)
			verts_off = num_verts;
		break;
	case GL_QUADS:
		verts_off = num_verts % 4;
		break;
	case GL_QUAD_STRIP:
		if (num_verts < 4)
			verts_off = num_verts;
		else
			verts_off = num_verts % 2;
		break;
	case GL_POLYGON:
		if (num_verts < 3)
			verts_off = num_verts;
		break;
	default:
		assert(0);
		return -1;
		break;
	}

	return num_verts - verts_off;
}

static void r300FireEB(r300ContextPtr rmesa, int vertex_count, int type, int offset)
{
	BATCH_LOCALS(&rmesa->radeon);
	int size;

	/* offset is in indices */
	BEGIN_BATCH(10);
	OUT_BATCH_PACKET3(R300_PACKET3_3D_DRAW_INDX_2, 0);
	if (rmesa->ind_buf.is_32bit) {
		/* convert to bytes */
		offset *= 4;
		size = vertex_count;
		OUT_BATCH(R300_VAP_VF_CNTL__PRIM_WALK_INDICES |
		  (vertex_count << 16) | type |
		  R300_VAP_VF_CNTL__INDEX_SIZE_32bit);
	} else {
		/* convert to bytes */
		offset *= 2;
		size = (vertex_count + 1) >> 1;
		OUT_BATCH(R300_VAP_VF_CNTL__PRIM_WALK_INDICES |
		   (vertex_count << 16) | type);
	}

	if (!rmesa->radeon.radeonScreen->kernel_mm) {
		OUT_BATCH_PACKET3(R300_PACKET3_INDX_BUFFER, 2);
		OUT_BATCH(R300_INDX_BUFFER_ONE_REG_WR | (0 << R300_INDX_BUFFER_SKIP_SHIFT) |
				 (R300_VAP_PORT_IDX0 >> 2));
		OUT_BATCH_RELOC(0, rmesa->ind_buf.bo, rmesa->ind_buf.bo_offset + offset, RADEON_GEM_DOMAIN_GTT, 0, 0);
		OUT_BATCH(size);
	} else {
		OUT_BATCH_PACKET3(R300_PACKET3_INDX_BUFFER, 2);
		OUT_BATCH(R300_INDX_BUFFER_ONE_REG_WR | (0 << R300_INDX_BUFFER_SKIP_SHIFT) |
				 (R300_VAP_PORT_IDX0 >> 2));
		OUT_BATCH(rmesa->ind_buf.bo_offset + offset);
		OUT_BATCH(size);
		radeon_cs_write_reloc(rmesa->radeon.cmdbuf.cs,
				      rmesa->ind_buf.bo, RADEON_GEM_DOMAIN_GTT, 0, 0);
	}
	END_BATCH();
}

static void r300EmitAOS(r300ContextPtr rmesa, GLuint nr, GLuint offset)
{
	BATCH_LOCALS(&rmesa->radeon);
	uint32_t voffset;
	int sz = 1 + (nr >> 1) * 3 + (nr & 1) * 2;
	int i;

	if (RADEON_DEBUG & RADEON_VERTS)
		fprintf(stderr, "%s: nr=%d, ofs=0x%08x\n", __FUNCTION__, nr,
			offset);

	if (!rmesa->radeon.radeonScreen->kernel_mm) {
		BEGIN_BATCH(sz+2+(nr * 2));
		OUT_BATCH_PACKET3(R300_PACKET3_3D_LOAD_VBPNTR, sz - 1);
		OUT_BATCH(nr);

		for (i = 0; i + 1 < nr; i += 2) {
			OUT_BATCH((rmesa->radeon.tcl.aos[i].components << 0) |
				  (rmesa->radeon.tcl.aos[i].stride << 8) |
				  (rmesa->radeon.tcl.aos[i + 1].components << 16) |
				  (rmesa->radeon.tcl.aos[i + 1].stride << 24));

			voffset =  rmesa->radeon.tcl.aos[i + 0].offset +
				offset * 4 * rmesa->radeon.tcl.aos[i + 0].stride;
			OUT_BATCH_RELOC(voffset,
					rmesa->radeon.tcl.aos[i].bo,
					voffset,
					RADEON_GEM_DOMAIN_GTT,
					0, 0);
			voffset =  rmesa->radeon.tcl.aos[i + 1].offset +
			  offset * 4 * rmesa->radeon.tcl.aos[i + 1].stride;
			OUT_BATCH_RELOC(voffset,
					rmesa->radeon.tcl.aos[i+1].bo,
					voffset,
					RADEON_GEM_DOMAIN_GTT,
					0, 0);
		}

		if (nr & 1) {
			OUT_BATCH((rmesa->radeon.tcl.aos[nr - 1].components << 0) |
				  (rmesa->radeon.tcl.aos[nr - 1].stride << 8));
			voffset =  rmesa->radeon.tcl.aos[nr - 1].offset +
				offset * 4 * rmesa->radeon.tcl.aos[nr - 1].stride;
			OUT_BATCH_RELOC(voffset,
					rmesa->radeon.tcl.aos[nr - 1].bo,
					voffset,
					RADEON_GEM_DOMAIN_GTT,
					0, 0);
		}
		END_BATCH();
	} else {

		BEGIN_BATCH(sz+2+(nr * 2));
		OUT_BATCH_PACKET3(R300_PACKET3_3D_LOAD_VBPNTR, sz - 1);
		OUT_BATCH(nr);

		for (i = 0; i + 1 < nr; i += 2) {
			OUT_BATCH((rmesa->radeon.tcl.aos[i].components << 0) |
				  (rmesa->radeon.tcl.aos[i].stride << 8) |
				  (rmesa->radeon.tcl.aos[i + 1].components << 16) |
				  (rmesa->radeon.tcl.aos[i + 1].stride << 24));

			voffset =  rmesa->radeon.tcl.aos[i + 0].offset +
				offset * 4 * rmesa->radeon.tcl.aos[i + 0].stride;
			OUT_BATCH(voffset);
			voffset =  rmesa->radeon.tcl.aos[i + 1].offset +
				offset * 4 * rmesa->radeon.tcl.aos[i + 1].stride;
			OUT_BATCH(voffset);
		}

		if (nr & 1) {
			OUT_BATCH((rmesa->radeon.tcl.aos[nr - 1].components << 0) |
			  (rmesa->radeon.tcl.aos[nr - 1].stride << 8));
			voffset =  rmesa->radeon.tcl.aos[nr - 1].offset +
				offset * 4 * rmesa->radeon.tcl.aos[nr - 1].stride;
			OUT_BATCH(voffset);
		}
		for (i = 0; i + 1 < nr; i += 2) {
			voffset =  rmesa->radeon.tcl.aos[i + 0].offset +
				offset * 4 * rmesa->radeon.tcl.aos[i + 0].stride;
			radeon_cs_write_reloc(rmesa->radeon.cmdbuf.cs,
					      rmesa->radeon.tcl.aos[i+0].bo,
					      RADEON_GEM_DOMAIN_GTT,
					      0, 0);
			voffset =  rmesa->radeon.tcl.aos[i + 1].offset +
				offset * 4 * rmesa->radeon.tcl.aos[i + 1].stride;
			radeon_cs_write_reloc(rmesa->radeon.cmdbuf.cs,
					      rmesa->radeon.tcl.aos[i+1].bo,
					      RADEON_GEM_DOMAIN_GTT,
					      0, 0);
		}
		if (nr & 1) {
			voffset =  rmesa->radeon.tcl.aos[nr - 1].offset +
				offset * 4 * rmesa->radeon.tcl.aos[nr - 1].stride;
			radeon_cs_write_reloc(rmesa->radeon.cmdbuf.cs,
					      rmesa->radeon.tcl.aos[nr-1].bo,
					      RADEON_GEM_DOMAIN_GTT,
					      0, 0);
		}
		END_BATCH();
	}

}

static void r300FireAOS(r300ContextPtr rmesa, int vertex_count, int type)
{
	BATCH_LOCALS(&rmesa->radeon);

        r300_emit_scissor(rmesa->radeon.glCtx);
	BEGIN_BATCH(3);
	OUT_BATCH_PACKET3(R300_PACKET3_3D_DRAW_VBUF_2, 0);
	OUT_BATCH(R300_VAP_VF_CNTL__PRIM_WALK_VERTEX_LIST | (vertex_count << 16) | type);
	END_BATCH();
}

void r300RunRenderPrimitive(struct gl_context * ctx, int start, int end, int prim)
{
	r300ContextPtr rmesa = R300_CONTEXT(ctx);
	BATCH_LOCALS(&rmesa->radeon);
	int type, num_verts;

	type = r300PrimitiveType(rmesa, prim);
	num_verts = r300NumVerts(rmesa, end - start, prim);

	if (type < 0 || num_verts <= 0)
		return;

	if (rmesa->ind_buf.bo) {
		GLuint first, incr, offset = 0;

		if (!split_prim_inplace(prim & PRIM_MODE_MASK, &first, &incr) &&
			num_verts > 65500) {
			WARN_ONCE("Fixme: can't handle spliting prim %d\n", prim);
			return;
		}


		r300EmitAOS(rmesa, rmesa->radeon.tcl.aos_count, 0);
		if (rmesa->radeon.radeonScreen->kernel_mm) {
			BEGIN_BATCH_NO_AUTOSTATE(2);
			OUT_BATCH_REGSEQ(R300_VAP_VF_MAX_VTX_INDX, 1);
			OUT_BATCH(rmesa->radeon.tcl.aos[0].count);
			END_BATCH();
		}

		r300_emit_scissor(rmesa->radeon.glCtx);
		while (num_verts > 0) {
			int nr;
			int align;

			nr = MIN2(num_verts, 65535);
			nr -= (nr - first) % incr;

			/* get alignment for IB correct */
			if (nr != num_verts) {
				do {
				    align = nr * (rmesa->ind_buf.is_32bit ? 4 : 2);
				    if (align % 4)
					nr -= incr;
				} while(align % 4);
				if (nr <= 0) {
					WARN_ONCE("did the impossible happen? we never aligned nr to dword\n");
					return;
				}
					
			}
			r300FireEB(rmesa, nr, type, offset);

			num_verts -= nr;
			offset += nr;
		}

	} else {
		GLuint first, incr, offset = 0;

		if (!split_prim_inplace(prim & PRIM_MODE_MASK, &first, &incr) &&
			num_verts > 65535) {
			WARN_ONCE("Fixme: can't handle spliting prim %d\n", prim);
			return;
		}

		if (rmesa->radeon.radeonScreen->kernel_mm) {
			BEGIN_BATCH_NO_AUTOSTATE(2);
			OUT_BATCH_REGSEQ(R300_VAP_VF_MAX_VTX_INDX, 1);
			OUT_BATCH(rmesa->radeon.tcl.aos[0].count);
			END_BATCH();
		}

		r300_emit_scissor(rmesa->radeon.glCtx);
		while (num_verts > 0) {
			int nr;
			nr = MIN2(num_verts, 65535);
			nr -= (nr - first) % incr;
			r300EmitAOS(rmesa, rmesa->radeon.tcl.aos_count, start + offset);
			r300FireAOS(rmesa, nr, type);
			num_verts -= nr;
			offset += nr;
		}
	}
	COMMIT_BATCH();
}

static const char *getFallbackString(r300ContextPtr rmesa, uint32_t bit)
{
	static char common_fallback_str[32];
	switch (bit) {
		case R300_FALLBACK_VERTEX_PROGRAM :
			return "vertex program";
		case R300_FALLBACK_LINE_SMOOTH:
			return "smooth lines";
		case R300_FALLBACK_POINT_SMOOTH:
			return "smooth points";
		case R300_FALLBACK_POLYGON_SMOOTH:
			return "smooth polygons";
		case R300_FALLBACK_LINE_STIPPLE:
			return "line stipple";
		case R300_FALLBACK_POLYGON_STIPPLE:
			return "polygon stipple";
		case R300_FALLBACK_STENCIL_TWOSIDE:
			return "two-sided stencil";
		case R300_FALLBACK_RENDER_MODE:
			return "render mode != GL_RENDER";
		case R300_FALLBACK_FRAGMENT_PROGRAM:
			return "fragment program";
		case R300_FALLBACK_RADEON_COMMON:
			snprintf(common_fallback_str, 32, "radeon common 0x%08x", rmesa->radeon.Fallback);
			return common_fallback_str;
		case R300_FALLBACK_AOS_LIMIT:
			return "aos limit";
		case R300_FALLBACK_INVALID_BUFFERS:
			return "invalid buffers";
		default:
			return "unknown";
	}
}

void r300SwitchFallback(struct gl_context *ctx, uint32_t bit, GLboolean mode)
{
	TNLcontext *tnl = TNL_CONTEXT(ctx);
	r300ContextPtr rmesa = R300_CONTEXT(ctx);
	uint32_t old_fallback = rmesa->fallback;
	static uint32_t fallback_warn = 0;

	if (mode) {
		if ((fallback_warn & bit) == 0) {
			if (RADEON_DEBUG & RADEON_FALLBACKS)
				fprintf(stderr, "WARNING! Falling back to software for %s\n", getFallbackString(rmesa, bit));
			fallback_warn |= bit;
		}
		rmesa->fallback |= bit;

		/* update only if we change from no tcl fallbacks to some tcl fallbacks */
		if (rmesa->options.hw_tcl_enabled) {
			if (((old_fallback & R300_TCL_FALLBACK_MASK) == 0) &&
				((bit & R300_TCL_FALLBACK_MASK) > 0)) {
				R300_STATECHANGE(rmesa, vap_cntl_status);
				rmesa->hw.vap_cntl_status.cmd[1] |= R300_VAP_TCL_BYPASS;
			}
		}

		/* update only if we change from no raster fallbacks to some raster fallbacks */
		if (((old_fallback & R300_RASTER_FALLBACK_MASK) == 0) &&
			((bit & R300_RASTER_FALLBACK_MASK) > 0)) {

			radeon_firevertices(&rmesa->radeon);
			rmesa->radeon.swtcl.RenderIndex = ~0;
			_swsetup_Wakeup( ctx );
		}
	} else {
		rmesa->fallback &= ~bit;

		/* update only if we have disabled all tcl fallbacks */
		if (rmesa->options.hw_tcl_enabled) {
			if ((old_fallback & R300_TCL_FALLBACK_MASK) == bit) {
				R300_STATECHANGE(rmesa, vap_cntl_status);
				rmesa->hw.vap_cntl_status.cmd[1] &= ~R300_VAP_TCL_BYPASS;
			}
		}

		/* update only if we have disabled all raster fallbacks */
		if ((old_fallback & R300_RASTER_FALLBACK_MASK) == bit) {
			_swrast_flush( ctx );

			tnl->Driver.Render.Start = r300RenderStart;
			tnl->Driver.Render.Finish = r300RenderFinish;
			tnl->Driver.Render.PrimitiveNotify = r300RenderPrimitive;
			tnl->Driver.Render.ResetLineStipple = r300ResetLineStipple;
			tnl->Driver.Render.BuildVertices = _tnl_build_vertices;
			tnl->Driver.Render.CopyPV = _tnl_copy_pv;
			tnl->Driver.Render.Interp = _tnl_interp;

			_tnl_invalidate_vertex_state( ctx, ~0 );
			_tnl_invalidate_vertices( ctx, ~0 );
		}
	}

}
@


1.5
log
@Merge Mesa 7.10.3
@
text
@@


1.4
log
@Update to Mesa 7.8.1. Tested on a bulk ports build by naddy@@, ok oga@@.
@
text
@d324 1
a324 1
void r300RunRenderPrimitive(GLcontext * ctx, int start, int end, int prim)
d445 1
a445 1
void r300SwitchFallback(GLcontext *ctx, uint32_t bit, GLboolean mode)
@


1.3
log
@Update to Mesa 7.4.2. Tested by oga@@, ckuethe@@ and naddy@@.
@
text
@d53 2
a55 1
#include "main/state.h"
d66 1
a66 6
#include "tnl/tnl.h"
#include "tnl/t_vp_build.h"
#include "radeon_reg.h"
#include "radeon_macros.h"
#include "radeon_ioctl.h"
#include "radeon_state.h"
a67 1
#include "r300_ioctl.h"
a69 1
#include "r300_tex.h"
d71 1
a71 2
#include "r300_fragprog.h"
extern int future_hw_tcl_on;
d168 1
a168 1
static void r300EmitElts(GLcontext * ctx, void *elts, unsigned long n_elts)
d170 2
a171 3
	r300ContextPtr rmesa = R300_CONTEXT(ctx);
	struct r300_dma_region *rvb = &rmesa->state.elt_dma;
	void *out;
d173 16
a188 10
	if (r300IsGartMemory(rmesa, elts, n_elts * 4)) {
		rvb->address = rmesa->radeon.radeonScreen->gartTextures.map;
		rvb->start = ((char *)elts) - rvb->address;
		rvb->aos_offset =
		    rmesa->radeon.radeonScreen->gart_texture_offset +
		    rvb->start;
		return;
	} else if (r300IsGartMemory(rmesa, elts, 1)) {
		WARN_ONCE("Pointer not within GART memory!\n");
		_mesa_exit(-1);
d191 16
a206 22
	r300AllocDmaRegion(rmesa, rvb, n_elts * 4, 4);
	rvb->aos_offset = GET_START(rvb);

	out = rvb->address + rvb->start;
	memcpy(out, elts, n_elts * 4);
}

static void r300FireEB(r300ContextPtr rmesa, unsigned long addr,
		       int vertex_count, int type)
{
	int cmd_reserved = 0;
	int cmd_written = 0;
	drm_radeon_cmd_header_t *cmd = NULL;

	start_packet3(CP_PACKET3(R300_PACKET3_3D_DRAW_INDX_2, 0), 0);
	e32(R300_VAP_VF_CNTL__PRIM_WALK_INDICES | (vertex_count << 16) | type | R300_VAP_VF_CNTL__INDEX_SIZE_32bit);

	start_packet3(CP_PACKET3(R300_PACKET3_INDX_BUFFER, 2), 2);
	e32(R300_INDX_BUFFER_ONE_REG_WR | (0 << R300_INDX_BUFFER_SKIP_SHIFT) |
	    (R300_VAP_PORT_IDX0 >> 2));
	e32(addr);
	e32(vertex_count);
d211 2
a214 3
	int cmd_reserved = 0;
	int cmd_written = 0;
	drm_radeon_cmd_header_t *cmd = NULL;
d216 1
a216 1
	if (RADEON_DEBUG & DEBUG_VERTS)
d220 26
a245 2
	start_packet3(CP_PACKET3(R300_PACKET3_3D_LOAD_VBPNTR, sz - 1), sz - 1);
	e32(nr);
d247 13
a259 5
	for (i = 0; i + 1 < nr; i += 2) {
		e32((rmesa->state.aos[i].aos_size << 0) |
		    (rmesa->state.aos[i].aos_stride << 8) |
		    (rmesa->state.aos[i + 1].aos_size << 16) |
		    (rmesa->state.aos[i + 1].aos_stride << 24));
d261 48
a308 2
		e32(rmesa->state.aos[i].aos_offset + offset * 4 * rmesa->state.aos[i].aos_stride);
		e32(rmesa->state.aos[i + 1].aos_offset + offset * 4 * rmesa->state.aos[i + 1].aos_stride);
a310 5
	if (nr & 1) {
		e32((rmesa->state.aos[nr - 1].aos_size << 0) |
		    (rmesa->state.aos[nr - 1].aos_stride << 8));
		e32(rmesa->state.aos[nr - 1].aos_offset + offset * 4 * rmesa->state.aos[nr - 1].aos_stride);
	}
d315 1
a315 3
	int cmd_reserved = 0;
	int cmd_written = 0;
	drm_radeon_cmd_header_t *cmd = NULL;
d317 5
a321 2
	start_packet3(CP_PACKET3(R300_PACKET3_3D_DRAW_VBUF_2, 0), 0);
	e32(R300_VAP_VF_CNTL__PRIM_WALK_VERTEX_LIST | (vertex_count << 16) | type);
d324 1
a324 2
static void r300RunRenderPrimitive(r300ContextPtr rmesa, GLcontext * ctx,
				   int start, int end, int prim)
d326 2
a328 2
	TNLcontext *tnl = TNL_CONTEXT(ctx);
	struct vertex_buffer *vb = &tnl->vb;
d336 6
a341 4
	if (vb->Elts) {
		if (num_verts > 65535) {
			/* not implemented yet */
			WARN_ONCE("Too many elts\n");
a343 19
		/* Note: The following is incorrect, but it's the best I can do
		 * without a major refactoring of how DMA memory is handled.
		 * The problem: Ensuring that both vertex arrays *and* index
		 * arrays are at the right position, and then ensuring that
		 * the LOAD_VBPNTR, DRAW_INDX and INDX_BUFFER packets are emitted
		 * at once.
		 *
		 * So why is the following incorrect? Well, it seems like
		 * allocating the index array might actually evict the vertex
		 * arrays. *sigh*
		 */
		r300EmitElts(ctx, vb->Elts, num_verts);
		r300EmitAOS(rmesa, rmesa->state.aos_count, start);
		r300FireEB(rmesa, rmesa->state.elt_dma.aos_offset, num_verts, type);
	} else {
		r300EmitAOS(rmesa, rmesa->state.aos_count, start);
		r300FireAOS(rmesa, num_verts, type);
	}
}
a344 7
static GLboolean r300RunRender(GLcontext * ctx,
			       struct tnl_pipeline_stage *stage)
{
	r300ContextPtr rmesa = R300_CONTEXT(ctx);
	int i;
	TNLcontext *tnl = TNL_CONTEXT(ctx);
	struct vertex_buffer *vb = &tnl->vb;
d346 7
d354 22
a375 2
	if (RADEON_DEBUG & DEBUG_PRIMS)
		fprintf(stderr, "%s\n", __FUNCTION__);
d377 3
a379 3
	r300UpdateShaders(rmesa);
	if (r300EmitArrays(ctx))
		return GL_TRUE;
d381 2
a382 1
	r300UpdateShaderStates(rmesa);
d384 5
a388 2
	r300EmitCacheFlush(rmesa);
	r300EmitState(rmesa);
d390 6
a395 32
	for (i = 0; i < vb->PrimitiveCount; i++) {
		GLuint prim = _tnl_translate_prim(&vb->Primitive[i]);
		GLuint start = vb->Primitive[i].start;
		GLuint end = vb->Primitive[i].start + vb->Primitive[i].count;
		r300RunRenderPrimitive(rmesa, ctx, start, end, prim);
	}

	r300EmitCacheFlush(rmesa);

#ifdef USER_BUFFERS
	r300UseArrays(ctx);
#endif

	r300ReleaseArrays(ctx);

	return GL_FALSE;
}

#define FALLBACK_IF(expr)						\
	do {								\
		if (expr) {						\
			if (1 || RADEON_DEBUG & DEBUG_FALLBACKS)	\
				WARN_ONCE("Software fallback:%s\n",	\
					  #expr);			\
			return R300_FALLBACK_RAST;			\
		}							\
	} while(0)

static int r300Fallback(GLcontext * ctx)
{
	r300ContextPtr r300 = R300_CONTEXT(ctx);
	const unsigned back = ctx->Stencil._BackFace;
d397 9
a405 19
	/* Do we need to use new-style shaders?
	 * Also is there a better way to do this? */
	if (r300->radeon.radeonScreen->chip_family >= CHIP_FAMILY_RV515) {
		struct r500_fragment_program *fp = (struct r500_fragment_program *)
	    (char *)ctx->FragmentProgram._Current;
		if (fp) {
			if (!fp->translated) {
				r500TranslateFragmentShader(r300, fp);
				FALLBACK_IF(!fp->translated);
			}
		}
	} else {
		struct r300_fragment_program *fp = (struct r300_fragment_program *)
	    (char *)ctx->FragmentProgram._Current;
		if (fp) {
			if (!fp->translated) {
				r300TranslateFragmentShader(r300, fp);
				FALLBACK_IF(!fp->translated);
			}
d408 1
a408 24

	FALLBACK_IF(ctx->RenderMode != GL_RENDER);

	/* If GL_EXT_stencil_two_side is disabled, this fallback check can
	 * be removed.
	 */
	FALLBACK_IF(ctx->Stencil.Ref[0] != ctx->Stencil.Ref[back]
		    || ctx->Stencil.ValueMask[0] !=
		    ctx->Stencil.ValueMask[back]
		    || ctx->Stencil.WriteMask[0] !=
		    ctx->Stencil.WriteMask[back]);

	if (ctx->Extensions.NV_point_sprite || ctx->Extensions.ARB_point_sprite)
		FALLBACK_IF(ctx->Point.PointSprite);

	if (!r300->disable_lowimpact_fallback) {
		FALLBACK_IF(ctx->Polygon.StippleFlag);
		FALLBACK_IF(ctx->Multisample._Enabled);
		FALLBACK_IF(ctx->Line.StippleFlag);
		FALLBACK_IF(ctx->Line.SmoothFlag);
		FALLBACK_IF(ctx->Point.SmoothFlag);
	}

	return R300_FALLBACK_NONE;
d411 1
a411 2
static GLboolean r300RunNonTCLRender(GLcontext * ctx,
				     struct tnl_pipeline_stage *stage)
d413 30
a442 12
	r300ContextPtr rmesa = R300_CONTEXT(ctx);

	if (RADEON_DEBUG & DEBUG_PRIMS)
		fprintf(stderr, "%s\n", __FUNCTION__);

	if (r300Fallback(ctx) >= R300_FALLBACK_RAST)
		return GL_TRUE;

	if (!(rmesa->radeon.radeonScreen->chip_flags & RADEON_CHIPSET_TCL))
 	        return GL_TRUE;

	return r300RunRender(ctx, stage);
d445 1
a445 2
static GLboolean r300RunTCLRender(GLcontext * ctx,
				  struct tnl_pipeline_stage *stage)
d447 1
d449 2
a450 1
	struct r300_vertex_program *vp;
d452 7
a458 1
	hw_tcl_on = future_hw_tcl_on;
d460 8
a467 2
	if (RADEON_DEBUG & DEBUG_PRIMS)
		fprintf(stderr, "%s\n", __FUNCTION__);
d469 10
a478 2
	if (hw_tcl_on == GL_FALSE)
		return GL_TRUE;
d480 7
a486 4
	if (r300Fallback(ctx) >= R300_FALLBACK_TCL) {
		hw_tcl_on = GL_FALSE;
		return GL_TRUE;
	}
d488 11
a498 1
	r300UpdateShaders(rmesa);
d500 3
a502 4
	vp = (struct r300_vertex_program *)CURRENT_VERTEX_SHADER(ctx);
	if (vp->native == GL_FALSE) {
		hw_tcl_on = GL_FALSE;
		return GL_TRUE;
a504 1
	return r300RunRender(ctx, stage);
a505 18

const struct tnl_pipeline_stage _r300_render_stage = {
	"r300 Hardware Rasterization",
	NULL,
	NULL,
	NULL,
	NULL,
	r300RunNonTCLRender
};

const struct tnl_pipeline_stage _r300_tcl_stage = {
	"r300 Hardware Transform, Clipping and Lighting",
	NULL,
	NULL,
	NULL,
	NULL,
	r300RunTCLRender
};
@


1.2
log
@Mesa 7.2, Tested by ckuethe@@, naddy@@, oga@@, and others.
@
text
@d53 9
a61 9
#include "glheader.h"
#include "state.h"
#include "imports.h"
#include "enums.h"
#include "macros.h"
#include "context.h"
#include "dd.h"
#include "simple_list.h"
#include "api_arrayelt.h"
d211 2
a212 1
	e32(R300_EB_UNK1 | (0 << 16) | R300_EB_UNK2);
d350 2
d376 8
a383 6
	FALLBACK_IF(ctx->Stencil._TestTwoSide
		    && (ctx->Stencil.Ref[0] != ctx->Stencil.Ref[1]
			|| ctx->Stencil.ValueMask[0] !=
			ctx->Stencil.ValueMask[1]
			|| ctx->Stencil.WriteMask[0] !=
			ctx->Stencil.WriteMask[1]));
@


1.1
log
@Initial revision
@
text
@d28 23
a50 3
/*
 * Authors:
 *   Nicolai Haehnle <prefect_@@gmx.net>
a60 1

d64 1
a64 1
#include "array_cache/acache.h"
a66 1

a74 1
#include "r300_program.h"
a75 1
#include "r300_maos.h"
d77 1
a77 1

d80 4
a83 8
/**********************************************************************
*                     Hardware rasterization
*
* When we fell back to software TCL, we still try to use the
* rasterization hardware for rendering.
**********************************************************************/

static int r300_get_primitive_type(r300ContextPtr rmesa, GLcontext *ctx, int prim)
a84 2
	int type=-1;

d87 2
a88 2
	        type=R300_VAP_VF_CNTL__PRIM_POINTS;
      		break;
d90 2
a91 2
	        type=R300_VAP_VF_CNTL__PRIM_LINES;
      		break;
d93 2
a94 2
	        type=R300_VAP_VF_CNTL__PRIM_LINE_STRIP;
      		break;
d96 11
a106 11
		type=R300_VAP_VF_CNTL__PRIM_LINE_LOOP;
      		break;
    	case GL_TRIANGLES:
	        type=R300_VAP_VF_CNTL__PRIM_TRIANGLES;
      		break;
   	case GL_TRIANGLE_STRIP:
	        type=R300_VAP_VF_CNTL__PRIM_TRIANGLE_STRIP;
      		break;
   	case GL_TRIANGLE_FAN:
	        type=R300_VAP_VF_CNTL__PRIM_TRIANGLE_FAN;
      		break;
d108 2
a109 2
	        type=R300_VAP_VF_CNTL__PRIM_QUADS;
      		break;
d111 2
a112 2
	        type=R300_VAP_VF_CNTL__PRIM_QUAD_STRIP;
      		break;
d114 1
a114 1
		type=R300_VAP_VF_CNTL__PRIM_POLYGON;
d116 2
a117 4
   	default:
 		fprintf(stderr, "%s:%s Do not know how to handle primitive %02x - help me !\n",
			__FILE__, __FUNCTION__,
			prim & PRIM_MODE_MASK);
d119 2
a120 3
         	break;
   	}
   return type;
d123 1
a123 1
int r300_get_num_verts(r300ContextPtr rmesa, int num_verts, int prim)
d125 1
a125 2
	int verts_off=0;
	char *name="UNKNOWN";
a128 1
   		name="P";
d130 1
a130 1
      		break;
a131 1
   		name="L";
d133 1
a133 1
      		break;
d135 1
a135 2
   		name="LS";
		if(num_verts < 2)
d137 1
a137 1
      		break;
d139 1
a139 2
   		name="LL";
		if(num_verts < 2)
d141 2
a142 3
      		break;
    	case GL_TRIANGLES:
   		name="T";
d144 3
a146 4
      		break;
   	case GL_TRIANGLE_STRIP:
   		name="TS";
		if(num_verts < 3)
d148 3
a150 4
      		break;
   	case GL_TRIANGLE_FAN:
   		name="TF";
		if(num_verts < 3)
d152 1
a152 1
      		break;
a153 1
   		name="Q";
d155 1
a155 1
      		break;
d157 1
a157 2
   		name="QS";
		if(num_verts < 4)
d161 1
a161 1
      		break;
d163 1
a163 2
		name="P";
		if(num_verts < 3)
d166 2
a167 4
   	default:
 		fprintf(stderr, "%s:%s Do not know how to handle primitive %02x - help me !\n",
			__FILE__, __FUNCTION__,
			prim & PRIM_MODE_MASK);
d169 1
a169 12
         	break;
   	}

	if (RADEON_DEBUG & DEBUG_VERTS) {
		if (num_verts - verts_off == 0) {
			WARN_ONCE("user error: Need more than %d vertices to draw primitive %s !\n", num_verts, name);
			return 0;
		}

		if (verts_off > 0) {
			WARN_ONCE("user error: %d is not a valid number of vertices for primitive %s !\n", num_verts, name);
		}
d175 17
a191 1
/* Immediate implementation has been removed from CVS. */
d193 2
a194 1
/* vertex buffer implementation */
d196 6
a201 1
static void inline fire_EB(r300ContextPtr rmesa, unsigned long addr, int vertex_count, int type, int elt_size)
a205 27
	unsigned long addr_a;
	unsigned long t_addr;
	unsigned long magic_1, magic_2;
	GLcontext *ctx;
	ctx = rmesa->radeon.glCtx; 
	
	assert(elt_size == 2 || elt_size == 4);
	
	if(addr & (elt_size-1)){
		WARN_ONCE("Badly aligned buffer\n");
		return ;
	}
#ifdef OPTIMIZE_ELTS
	addr_a = 0;
	
	magic_1 = (addr % 32) / 4;
	t_addr = addr & (~0x1d);
	magic_2 = (vertex_count + 1 + (t_addr & 0x2)) / 2 + magic_1;
	
	check_space(6);
	
	start_packet3(RADEON_CP_PACKET3_3D_DRAW_INDX_2, 0);
	if(elt_size == 4){
		e32(R300_VAP_VF_CNTL__PRIM_WALK_INDICES | (vertex_count<<16) | type | R300_VAP_VF_CNTL__INDEX_SIZE_32bit);
	} else {
		e32(R300_VAP_VF_CNTL__PRIM_WALK_INDICES | (vertex_count<<16) | type);
	}
d207 2
a208 34
	start_packet3(RADEON_CP_PACKET3_INDX_BUFFER, 2);
	if(elt_size == 4){
		e32(R300_EB_UNK1 | (0 << 16) | R300_EB_UNK2);
		e32(addr /*& 0xffffffe3*/);
	} else {
		e32(R300_EB_UNK1 | (magic_1 << 16) | R300_EB_UNK2);
		e32(t_addr);
	}
	
	if(elt_size == 4){
		e32(vertex_count /*+ addr_a/4*/); /* Total number of dwords needed? */
	} else {
		e32(magic_2); /* Total number of dwords needed? */
	}
	//cp_delay(rmesa, 1);
#if 0
	fprintf(stderr, "magic_1 %d\n", magic_1);
	fprintf(stderr, "t_addr %x\n", t_addr);
	fprintf(stderr, "magic_2 %d\n", magic_2);
	exit(1);
#endif
#else
	(void)magic_2, (void)magic_1, (void)t_addr;
	
	addr_a = 0;
	
	check_space(6);
	
	start_packet3(RADEON_CP_PACKET3_3D_DRAW_INDX_2, 0);
	if(elt_size == 4){
		e32(R300_VAP_VF_CNTL__PRIM_WALK_INDICES | (vertex_count<<16) | type | R300_VAP_VF_CNTL__INDEX_SIZE_32bit);
	} else {
		e32(R300_VAP_VF_CNTL__PRIM_WALK_INDICES | (vertex_count<<16) | type);
	}
d210 1
a210 1
	start_packet3(RADEON_CP_PACKET3_INDX_BUFFER, 2);
d212 2
a213 9
	e32(addr /*& 0xffffffe3*/);
	
	if(elt_size == 4){
		e32(vertex_count /*+ addr_a/4*/); /* Total number of dwords needed? */
	} else {
		e32((vertex_count+1)/2 /*+ addr_a/4*/); /* Total number of dwords needed? */
	}
	//cp_delay(rmesa, 1);
#endif	
d216 1
a216 5
static void r300_render_vb_primitive(r300ContextPtr rmesa,
	GLcontext *ctx,
	int start,
	int end,
	int prim)
d218 18
a235 1
   int type, num_verts;
d237 3
a239 2
   type=r300_get_primitive_type(rmesa, ctx, prim);
   num_verts=r300_get_num_verts(rmesa, end-start, prim);
d241 6
a246 1
   if(type<0 || num_verts <= 0)return;
d248 2
a249 3
   if(rmesa->state.VB.Elts){
	r300EmitAOS(rmesa, rmesa->state.aos_count, /*0*/start);
#if 0
d253 16
a268 8
	int i;
	start_index32_packet(num_verts, type);
	for(i=0; i < num_verts; i++)
		e32(((unsigned long *)rmesa->state.VB.Elts)[i]/*rmesa->state.Elts[start+i]*/); /* start ? */
#else
	if(num_verts == 1){
		//start_index32_packet(num_verts, type);
		//e32(rmesa->state.Elts[start]);
d270 24
a294 13
	
	if(num_verts > 65535){ /* not implemented yet */
		WARN_ONCE("Too many elts\n");
		return;
	}
	
	r300EmitElts(ctx, rmesa->state.VB.Elts, num_verts, rmesa->state.VB.elt_size);
	fire_EB(rmesa, rmesa->state.elt_dma.aos_offset, num_verts, type, rmesa->state.VB.elt_size);
#endif
   }else{
	   r300EmitAOS(rmesa, rmesa->state.aos_count, start);
	   fire_AOS(rmesa, num_verts, type);
   }
d297 2
a298 2
GLboolean r300_run_vb_render(GLcontext *ctx,
				 struct tnl_pipeline_stage *stage)
a300 1
	struct radeon_vertex_buffer *VB = &rmesa->state.VB;
d302 3
a304 3
	int cmd_reserved = 0;
	int cmd_written = 0;
	drm_radeon_cmd_header_t *cmd = NULL;
a305 1
   
a308 5
	if (stage) {
 		TNLcontext *tnl = TNL_CONTEXT(ctx);
		radeon_vb_to_rvb(rmesa, VB, &tnl->vb);
	}
	
d314 2
a315 7
	
	reg_start(R300_RB3D_DSTCACHE_CTLSTAT,0);
	e32(0x0000000a);

	reg_start(0x4f18,0);
	e32(0x00000003);
	
d317 6
a322 7
	
	for(i=0; i < VB->PrimitiveCount; i++){
		GLuint prim = VB->Primitive[i].mode;
		GLuint start = VB->Primitive[i].start;
		GLuint length = VB->Primitive[i].count;
		
		r300_render_vb_primitive(rmesa, ctx, start, start + length, prim);
d325 1
a325 5
	reg_start(R300_RB3D_DSTCACHE_CTLSTAT,0);
	e32(0x0000000a/*0x2*/);

	reg_start(0x4f18,0);
	e32(0x00000003/*0x1*/);
d330 1
d332 1
d346 1
a346 1
int r300Fallback(GLcontext *ctx)
d349 21
a369 1
	int i;
a370 3
	/* We do not do SELECT or FEEDBACK (yet ?)
	 * Is it worth doing them ?
	 */
d373 9
a381 14
#if 0
	/* These should work now.. */
	FALLBACK_IF(ctx->Color.DitherFlag);
	/* GL_ALPHA_TEST */
	FALLBACK_IF(ctx->Color.AlphaEnabled);
	/* GL_BLEND */
	FALLBACK_IF(ctx->Color.BlendEnabled);
	/* GL_POLYGON_OFFSET_FILL */
	FALLBACK_IF(ctx->Polygon.OffsetFill);
	/* FOG seems to trigger an unknown output
	 *  in vertex program.
	 */
	FALLBACK_IF(ctx->Fog.Enabled);
#endif
d383 1
a383 12
	if(!r300->disable_lowimpact_fallback){
		/* GL_POLYGON_OFFSET_POINT */
		FALLBACK_IF(ctx->Polygon.OffsetPoint);
		/* GL_POLYGON_OFFSET_LINE */
		FALLBACK_IF(ctx->Polygon.OffsetLine);
#if 0
		/* GL_STENCIL_TEST */
		FALLBACK_IF(ctx->Stencil.Enabled);
		/* GL_POLYGON_SMOOTH disabling to get blender going */
		FALLBACK_IF(ctx->Polygon.SmoothFlag);
#endif
		/* GL_POLYGON_STIPPLE */
d385 1
a385 3
		/* GL_MULTISAMPLE_ARB */
		FALLBACK_IF(ctx->Multisample.Enabled);
		/* blender ? */
a386 1
		/* GL_LINE_SMOOTH */
a387 1
		/* GL_POINT_SMOOTH */
a390 14
	/* Fallback for LOGICOP */
	FALLBACK_IF(ctx->Color.ColorLogicOpEnabled);

	/* Rest could be done with vertex fragments */
	if (ctx->Extensions.NV_point_sprite ||
	    ctx->Extensions.ARB_point_sprite)
		/* GL_POINT_SPRITE_NV */
		FALLBACK_IF(ctx->Point.PointSprite);

	/* Fallback for rectangular texture */
	for (i = 0; i < ctx->Const.MaxTextureUnits; i++)
		if (ctx->Texture.Unit[i]._ReallyEnabled & TEXTURE_RECT_BIT)
			return R300_FALLBACK_TCL;

d394 2
a395 8
/**
 * Called by the pipeline manager to render a batch of primitives.
 * We can return true to pass on to the next stage (i.e. software
 * rasterization) or false to indicate that the pipeline has finished
 * after we render something.
 */
static GLboolean r300_run_render(GLcontext *ctx,
				 struct tnl_pipeline_stage *stage)
d397 1
d405 4
a408 1
	return r300_run_vb_render(ctx, stage);
d411 2
a412 11
const struct tnl_pipeline_stage _r300_render_stage = {
	"r300 hw rasterize",
	NULL,
	NULL,
	NULL,
	NULL,
	r300_run_render		/* run */
};

static GLboolean r300_run_tcl_render(GLcontext *ctx,
				 struct tnl_pipeline_stage *stage)
d416 3
a418 3
   
   	hw_tcl_on=future_hw_tcl_on;
   
d421 2
a422 1
	if(hw_tcl_on == GL_FALSE)
d424 1
a424 1
	
d429 1
a429 1
	
a432 21
#if 0 /* Draw every second request with software arb vp */
	vp->native++;
	vp->native &= 1;
	//vp->native = GL_FALSE;
#endif

#if 0 /* You dont want to know what this does... */
	TNLcontext *tnl = TNL_CONTEXT(ctx);
	struct tnl_cache *cache;
	struct tnl_cache_item *c;
	
	cache = tnl->vp_cache;
	c = cache->items[0xc000cc0e % cache->size];
	
	if(c && c->data == vp)
		vp->native = GL_FALSE;
	
#endif
#if 0
	vp->native = GL_FALSE;
#endif
d437 2
a438 3
	//r300UpdateShaderStates(rmesa);
	
	return r300_run_vb_render(ctx, stage);
d441 2
a442 2
const struct tnl_pipeline_stage _r300_tcl_stage = {
	"r300 tcl",
d447 1
a447 1
	r300_run_tcl_render	/* run */
d450 7
a456 102
/* R300 texture rectangle expects coords in 0..1 range, not 0..dimension
 * as in the extension spec.  Need to translate here.
 *
 * Note that swrast expects 0..dimension, so if a fallback is active,
 * don't do anything.  (Maybe need to configure swrast to match hw)
 */
struct texrect_stage_data {
   GLvector4f texcoord[MAX_TEXTURE_UNITS];
};

#define TEXRECT_STAGE_DATA(stage) ((struct texrect_stage_data *)stage->privatePtr)


static GLboolean run_texrect_stage( GLcontext *ctx,
				    struct tnl_pipeline_stage *stage )
{
   struct texrect_stage_data *store = TEXRECT_STAGE_DATA(stage);
   r300ContextPtr rmesa = R300_CONTEXT(ctx);
   TNLcontext *tnl = TNL_CONTEXT(ctx);
   struct vertex_buffer *VB = &tnl->vb;
   GLuint i;

   if (rmesa->radeon.Fallback)
      return GL_TRUE;

   for (i = 0 ; i < ctx->Const.MaxTextureUnits ; i++) {
      if (ctx->Texture.Unit[i]._ReallyEnabled & TEXTURE_RECT_BIT) {
	 struct gl_texture_object *texObj = ctx->Texture.Unit[i].CurrentRect;
	 struct gl_texture_image *texImage = texObj->Image[0][texObj->BaseLevel];
	 const GLfloat iw = 1.0/texImage->Width;
	 const GLfloat ih = 1.0/texImage->Height;
	 GLfloat *in = (GLfloat *)VB->TexCoordPtr[i]->data;
	 GLint instride = VB->TexCoordPtr[i]->stride;
	 GLfloat (*out)[4] = store->texcoord[i].data;
	 GLint j;

	 store->texcoord[i].size = VB->TexCoordPtr[i]->size;
	 for (j = 0 ; j < VB->Count ; j++) {
	    switch (VB->TexCoordPtr[i]->size) {
	    case 4:
	       out[j][3] = in[3];
	    /* fallthrough */
	    case 3:
	       out[j][2] = in[2];
	    /* fallthrough */
	    default:
	       out[j][0] = in[0] * iw;
	       out[j][1] = in[1] * ih;
	    }
	    in = (GLfloat *)((GLubyte *)in + instride);
	 }

	 VB->AttribPtr[VERT_ATTRIB_TEX0+i] = VB->TexCoordPtr[i] = &store->texcoord[i];
      }
   }

   return GL_TRUE;
}


/* Called the first time stage->run() is invoked.
 */
static GLboolean alloc_texrect_data( GLcontext *ctx,
				     struct tnl_pipeline_stage *stage )
{
   struct vertex_buffer *VB = &TNL_CONTEXT(ctx)->vb;
   struct texrect_stage_data *store;
   GLuint i;

   stage->privatePtr = CALLOC(sizeof(*store));
   store = TEXRECT_STAGE_DATA(stage);
   if (!store)
      return GL_FALSE;

   for (i = 0 ; i < ctx->Const.MaxTextureUnits ; i++)
      _mesa_vector4f_alloc( &store->texcoord[i], 0, VB->Size, 32 );

   return GL_TRUE;
}

static void free_texrect_data( struct tnl_pipeline_stage *stage )
{
   struct texrect_stage_data *store = TEXRECT_STAGE_DATA(stage);
   GLuint i;

   if (store) {
      for (i = 0 ; i < MAX_TEXTURE_UNITS ; i++)
	 if (store->texcoord[i].data)
	    _mesa_vector4f_free( &store->texcoord[i] );
      FREE( store );
      stage->privatePtr = NULL;
   }
}

const struct tnl_pipeline_stage _r300_texrect_stage =
{
   "r300 texrect stage",			/* name */
   NULL,
   alloc_texrect_data,
   free_texrect_data,
   NULL,
   run_texrect_stage
a457 1

@


1.1.1.1
log
@Import MesaLibs 6.5.1. (in dist/ since its code is shared between lib 
and xserver)...
@
text
@@


1.1.1.2
log
@Mesa 7.0.1
@
text
@d28 3
a30 20
/**
 * \file
 *
 * \brief R300 Render (Vertex Buffer Implementation)
 *
 * The immediate implementation has been removed from CVS in favor of the vertex
 * buffer implementation.
 *
 * The render functions are called by the pipeline manager to render a batch of
 * primitives. They return TRUE to pass on to the next stage (i.e. software
 * rasterization) or FALSE to indicate that the pipeline has finished after
 * rendering something.
 *
 * When falling back to software TCL still attempt to use hardware
 * rasterization.
 *
 * I am not sure that the cache related registers are setup correctly, but
 * obviously this does work... Further investigation is needed.
 *
 * \author Nicolai Haehnle <prefect_@@gmx.net>
d41 1
d45 1
a45 1
#include "vbo/vbo.h"
d48 1
d57 1
d59 1
d61 1
d64 8
a71 4
/**
 * \brief Convert a OpenGL primitive type into a R300 primitive type.
 */
static int r300PrimitiveType(r300ContextPtr rmesa, GLcontext * ctx, int prim)
d73 2
d77 2
a78 2
		return R300_VAP_VF_CNTL__PRIM_POINTS;
		break;
d80 2
a81 2
		return R300_VAP_VF_CNTL__PRIM_LINES;
		break;
d83 2
a84 2
		return R300_VAP_VF_CNTL__PRIM_LINE_STRIP;
		break;
d86 11
a96 11
		return R300_VAP_VF_CNTL__PRIM_LINE_LOOP;
		break;
	case GL_TRIANGLES:
		return R300_VAP_VF_CNTL__PRIM_TRIANGLES;
		break;
	case GL_TRIANGLE_STRIP:
		return R300_VAP_VF_CNTL__PRIM_TRIANGLE_STRIP;
		break;
	case GL_TRIANGLE_FAN:
		return R300_VAP_VF_CNTL__PRIM_TRIANGLE_FAN;
		break;
d98 2
a99 2
		return R300_VAP_VF_CNTL__PRIM_QUADS;
		break;
d101 2
a102 2
		return R300_VAP_VF_CNTL__PRIM_QUAD_STRIP;
		break;
d104 1
a104 1
		return R300_VAP_VF_CNTL__PRIM_POLYGON;
d106 4
a109 2
	default:
		assert(0);
d111 3
a113 2
		break;
	}
d116 1
a116 1
static int r300NumVerts(r300ContextPtr rmesa, int num_verts, int prim)
d118 2
a119 1
	int verts_off = 0;
d123 1
d125 1
a125 1
		break;
d127 1
d129 1
a129 1
		break;
d131 2
a132 1
		if (num_verts < 2)
d134 1
a134 1
		break;
d136 2
a137 1
		if (num_verts < 2)
d139 3
a141 2
		break;
	case GL_TRIANGLES:
d143 4
a146 3
		break;
	case GL_TRIANGLE_STRIP:
		if (num_verts < 3)
d148 4
a151 3
		break;
	case GL_TRIANGLE_FAN:
		if (num_verts < 3)
d153 1
a153 1
		break;
d155 1
d157 1
a157 1
		break;
d159 2
a160 1
		if (num_verts < 4)
d164 1
a164 1
		break;
d166 2
a167 1
		if (num_verts < 3)
d170 4
a173 2
	default:
		assert(0);
d175 12
a186 1
		break;
d192 1
a192 8
static void r300EmitElts(GLcontext * ctx, void *elts, unsigned long n_elts,
			 int elt_size)
{
	r300ContextPtr rmesa = R300_CONTEXT(ctx);
	struct r300_dma_region *rvb = &rmesa->state.elt_dma;
	void *out;

	assert(elt_size == 2 || elt_size == 4);
d194 1
a194 11
	if (r300IsGartMemory(rmesa, elts, n_elts * elt_size)) {
		rvb->address = rmesa->radeon.radeonScreen->gartTextures.map;
		rvb->start = ((char *)elts) - rvb->address;
		rvb->aos_offset =
		    rmesa->radeon.radeonScreen->gart_texture_offset +
		    rvb->start;
		return;
	} else if (r300IsGartMemory(rmesa, elts, 1)) {
		WARN_ONCE("Pointer not within GART memory!\n");
		_mesa_exit(-1);
	}
d196 1
a196 9
	r300AllocDmaRegion(rmesa, rvb, n_elts * elt_size, elt_size);
	rvb->aos_offset = GET_START(rvb);

	out = rvb->address + rvb->start;
	memcpy(out, elts, n_elts * elt_size);
}

static void r300FireEB(r300ContextPtr rmesa, unsigned long addr,
		       int vertex_count, int type, int elt_size)
d201 1
d204 3
a206 1

d208 2
a209 2

	if (addr & (elt_size - 1)) {
d211 1
a211 1
		return;
d213 3
a215 1

d217 1
a217 1
	t_addr = addr & ~0x1d;
d219 3
a221 1

d223 2
a224 4
	if (elt_size == 4) {
		e32(R300_VAP_VF_CNTL__PRIM_WALK_INDICES |
		    (vertex_count << 16) | type |
		    R300_VAP_VF_CNTL__INDEX_SIZE_32bit);
d226 1
a226 2
		e32(R300_VAP_VF_CNTL__PRIM_WALK_INDICES |
		    (vertex_count << 16) | type);
d230 1
a230 2
#ifdef OPTIMIZE_ELTS
	if (elt_size == 4) {
d232 1
a232 1
		e32(addr);
d237 13
d251 14
d266 4
a269 5
	e32(addr);
#endif

	if (elt_size == 4) {
		e32(vertex_count);
d271 1
a271 5
#ifdef OPTIMIZE_ELTS
		e32(magic_2);
#else
		e32((vertex_count + 1) / 2);
#endif
d273 2
d277 5
a281 1
static void r300EmitAOS(r300ContextPtr rmesa, GLuint nr, GLuint offset)
d283 4
a286 5
	int sz = 1 + (nr >> 1) * 3 + (nr & 1) * 2;
	int i;
	int cmd_reserved = 0;
	int cmd_written = 0;
	drm_radeon_cmd_header_t *cmd = NULL;
d288 1
a288 26
	if (RADEON_DEBUG & DEBUG_VERTS)
		fprintf(stderr, "%s: nr=%d, ofs=0x%08x\n", __FUNCTION__, nr,
			offset);

	start_packet3(RADEON_CP_PACKET3_3D_LOAD_VBPNTR, sz - 1);
	e32(nr);
	for (i = 0; i + 1 < nr; i += 2) {
		e32((rmesa->state.aos[i].aos_size << 0)
		    | (rmesa->state.aos[i].aos_stride << 8)
		    | (rmesa->state.aos[i + 1].aos_size << 16)
		    | (rmesa->state.aos[i + 1].aos_stride << 24)
		    );
		e32(rmesa->state.aos[i].aos_offset +
		    offset * 4 * rmesa->state.aos[i].aos_stride);
		e32(rmesa->state.aos[i + 1].aos_offset +
		    offset * 4 * rmesa->state.aos[i + 1].aos_stride);
	}

	if (nr & 1) {
		e32((rmesa->state.aos[nr - 1].aos_size << 0)
		    | (rmesa->state.aos[nr - 1].aos_stride << 8)
		    );
		e32(rmesa->state.aos[nr - 1].aos_offset +
		    offset * 4 * rmesa->state.aos[nr - 1].aos_stride);
	}
}
d290 3
a292 2
static void r300FireAOS(r300ContextPtr rmesa, int vertex_count, int type)
{
d296 8
a303 15

	start_packet3(RADEON_CP_PACKET3_3D_DRAW_VBUF_2, 0);
	e32(R300_VAP_VF_CNTL__PRIM_WALK_VERTEX_LIST | (vertex_count << 16)
	    | type);
}

static void r300RunRenderPrimitive(r300ContextPtr rmesa, GLcontext * ctx,
				   int start, int end, int prim)
{
	int type, num_verts;

	type = r300PrimitiveType(rmesa, ctx, prim);
	num_verts = r300NumVerts(rmesa, end - start, prim);

	if (type < 0 || num_verts <= 0)
a304 15

	if (rmesa->state.VB.Elts) {
		r300EmitAOS(rmesa, rmesa->state.aos_count, start);
		if (num_verts > 65535) {
			/* not implemented yet */
			WARN_ONCE("Too many elts\n");
			return;
		}
		r300EmitElts(ctx, rmesa->state.VB.Elts, num_verts,
			     rmesa->state.VB.elt_size);
		r300FireEB(rmesa, rmesa->state.elt_dma.aos_offset,
			   num_verts, type, rmesa->state.VB.elt_size);
	} else {
		r300EmitAOS(rmesa, rmesa->state.aos_count, start);
		r300FireAOS(rmesa, num_verts, type);
d306 4
a309 29
}

#define CONV_VB(a, b) rvb->AttribPtr[(a)].size = vb->b->size, \
			rvb->AttribPtr[(a)].type = GL_FLOAT, \
			rvb->AttribPtr[(a)].stride = vb->b->stride, \
			rvb->AttribPtr[(a)].data = vb->b->data

static void radeon_vb_to_rvb(r300ContextPtr rmesa,
			     struct radeon_vertex_buffer *rvb,
			     struct vertex_buffer *vb)
{
	int i;
	GLcontext *ctx;
	ctx = rmesa->radeon.glCtx;

	memset(rvb, 0, sizeof(*rvb));

	rvb->Elts = vb->Elts;
	rvb->elt_size = 4;
	rvb->elt_min = 0;
	rvb->elt_max = vb->Count;

	rvb->Count = vb->Count;

	if (hw_tcl_on) {
		CONV_VB(VERT_ATTRIB_POS, ObjPtr);
	} else {
		assert(vb->ClipPtr);
		CONV_VB(VERT_ATTRIB_POS, ClipPtr);
d311 8
a318 17

	CONV_VB(VERT_ATTRIB_NORMAL, NormalPtr);
	CONV_VB(VERT_ATTRIB_COLOR0, ColorPtr[0]);
	CONV_VB(VERT_ATTRIB_COLOR1, SecondaryColorPtr[0]);
	CONV_VB(VERT_ATTRIB_FOG, FogCoordPtr);

	for (i = 0; i < ctx->Const.MaxTextureCoordUnits; i++)
		CONV_VB(VERT_ATTRIB_TEX0 + i, TexCoordPtr[i]);

	for (i = 0; i < MAX_VERTEX_PROGRAM_ATTRIBS; i++)
		CONV_VB(VERT_ATTRIB_GENERIC0 + i,
			AttribPtr[VERT_ATTRIB_GENERIC0 + i]);

	rvb->Primitive = vb->Primitive;
	rvb->PrimitiveCount = vb->PrimitiveCount;
	rvb->LockFirst = rvb->LockCount = 0;
	rvb->lock_uptodate = GL_FALSE;
d321 2
a322 2
static GLboolean r300RunRender(GLcontext * ctx,
			       struct tnl_pipeline_stage *stage)
d331 1
d336 1
a336 1
		TNLcontext *tnl = TNL_CONTEXT(ctx);
d339 1
a339 1

d345 7
a351 7

	reg_start(R300_RB3D_DSTCACHE_CTLSTAT, 0);
	e32(R300_RB3D_DSTCACHE_UNKNOWN_0A);

	reg_start(R300_RB3D_ZCACHE_CTLSTAT, 0);
	e32(R300_RB3D_ZCACHE_UNKNOWN_03);

d353 3
a355 3

	for (i = 0; i < VB->PrimitiveCount; i++) {
		GLuint prim = _tnl_translate_prim(&VB->Primitive[i]);
d357 3
a359 2
		GLuint end = VB->Primitive[i].start + VB->Primitive[i].count;
		r300RunRenderPrimitive(rmesa, ctx, start, end, prim);
d362 2
a363 2
	reg_start(R300_RB3D_DSTCACHE_CTLSTAT, 0);
	e32(R300_RB3D_DSTCACHE_UNKNOWN_0A);
d365 2
a366 2
	reg_start(R300_RB3D_ZCACHE_CTLSTAT, 0);
	e32(R300_RB3D_ZCACHE_UNKNOWN_03);
a370 1

a371 1

d385 1
a385 1
static int r300Fallback(GLcontext * ctx)
d388 1
a388 8
	struct r300_fragment_program *fp = (struct r300_fragment_program *)
	    (char *)ctx->FragmentProgram._Current;

	if (fp) {
		if (!fp->translated)
			r300TranslateFragmentShader(r300, fp);
		FALLBACK_IF(!fp->translated);
	}
d390 3
d395 14
a408 6
	FALLBACK_IF(ctx->Stencil._TestTwoSide
		    && (ctx->Stencil.Ref[0] != ctx->Stencil.Ref[1]
			|| ctx->Stencil.ValueMask[0] !=
			ctx->Stencil.ValueMask[1]
			|| ctx->Stencil.WriteMask[0] !=
			ctx->Stencil.WriteMask[1]));
d410 2
a411 6
	FALLBACK_IF(ctx->Color.ColorLogicOpEnabled);

	if (ctx->Extensions.NV_point_sprite || ctx->Extensions.ARB_point_sprite)
		FALLBACK_IF(ctx->Point.PointSprite);

	if (!r300->disable_lowimpact_fallback) {
d413 1
d415 7
d423 1
d425 1
d427 1
d429 1
d433 14
d450 8
a457 2
static GLboolean r300RunNonTCLRender(GLcontext * ctx,
				     struct tnl_pipeline_stage *stage)
d459 1
d466 1
a466 1
	return r300RunRender(ctx, stage);
d469 11
a479 2
static GLboolean r300RunTCLRender(GLcontext * ctx,
				  struct tnl_pipeline_stage *stage)
d483 3
a485 3

	hw_tcl_on = future_hw_tcl_on;

d488 1
a488 2

	if (hw_tcl_on == GL_FALSE)
d490 1
a490 1

d495 1
a495 1

d499 21
d524 3
a526 2

	return r300RunRender(ctx, stage);
d529 2
a530 2
const struct tnl_pipeline_stage _r300_render_stage = {
	"r300 Hardware Rasterization",
d535 1
a535 1
	r300RunNonTCLRender
d538 102
a639 7
const struct tnl_pipeline_stage _r300_tcl_stage = {
	"r300 Hardware Transform, Clipping and Lighting",
	NULL,
	NULL,
	NULL,
	NULL,
	r300RunTCLRender
d641 1
@


1.1.1.3
log
@Import Mesa 7.10.3
@
text
@a47 3
 *
 * \todo Add immediate implementation back? Perhaps this is useful if there are
 * no bugs...
d50 9
a58 10
#include "r300_render.h"

#include "main/glheader.h"
#include "main/imports.h"
#include "main/enums.h"
#include "main/macros.h"
#include "main/context.h"
#include "main/dd.h"
#include "main/simple_list.h"
#include "main/api_arrayelt.h"
d62 6
a67 1
#include "vbo/vbo_split.h"
d69 1
d72 1
d74 1
a74 1
#include "r300_swtcl.h"
d79 1
a79 1
int r300PrimitiveType(r300ContextPtr rmesa, int prim)
d119 1
a119 1
int r300NumVerts(r300ContextPtr rmesa, int num_verts, int prim)
d171 30
a200 1
static void r300FireEB(r300ContextPtr rmesa, int vertex_count, int type, int offset)
d202 12
a213 2
	BATCH_LOCALS(&rmesa->radeon);
	int size;
d215 9
a223 10
	/* offset is in indices */
	BEGIN_BATCH(10);
	OUT_BATCH_PACKET3(R300_PACKET3_3D_DRAW_INDX_2, 0);
	if (rmesa->ind_buf.is_32bit) {
		/* convert to bytes */
		offset *= 4;
		size = vertex_count;
		OUT_BATCH(R300_VAP_VF_CNTL__PRIM_WALK_INDICES |
		  (vertex_count << 16) | type |
		  R300_VAP_VF_CNTL__INDEX_SIZE_32bit);
d225 2
a226 5
		/* convert to bytes */
		offset *= 2;
		size = (vertex_count + 1) >> 1;
		OUT_BATCH(R300_VAP_VF_CNTL__PRIM_WALK_INDICES |
		   (vertex_count << 16) | type);
d229 5
a233 6
	if (!rmesa->radeon.radeonScreen->kernel_mm) {
		OUT_BATCH_PACKET3(R300_PACKET3_INDX_BUFFER, 2);
		OUT_BATCH(R300_INDX_BUFFER_ONE_REG_WR | (0 << R300_INDX_BUFFER_SKIP_SHIFT) |
				 (R300_VAP_PORT_IDX0 >> 2));
		OUT_BATCH_RELOC(0, rmesa->ind_buf.bo, rmesa->ind_buf.bo_offset + offset, RADEON_GEM_DOMAIN_GTT, 0, 0);
		OUT_BATCH(size);
d235 16
a250 7
		OUT_BATCH_PACKET3(R300_PACKET3_INDX_BUFFER, 2);
		OUT_BATCH(R300_INDX_BUFFER_ONE_REG_WR | (0 << R300_INDX_BUFFER_SKIP_SHIFT) |
				 (R300_VAP_PORT_IDX0 >> 2));
		OUT_BATCH(rmesa->ind_buf.bo_offset + offset);
		OUT_BATCH(size);
		radeon_cs_write_reloc(rmesa->radeon.cmdbuf.cs,
				      rmesa->ind_buf.bo, RADEON_GEM_DOMAIN_GTT, 0, 0);
a251 1
	END_BATCH();
a255 2
	BATCH_LOCALS(&rmesa->radeon);
	uint32_t voffset;
d258 3
d262 1
a262 1
	if (RADEON_DEBUG & RADEON_VERTS)
d266 13
a278 26
	if (!rmesa->radeon.radeonScreen->kernel_mm) {
		BEGIN_BATCH(sz+2+(nr * 2));
		OUT_BATCH_PACKET3(R300_PACKET3_3D_LOAD_VBPNTR, sz - 1);
		OUT_BATCH(nr);

		for (i = 0; i + 1 < nr; i += 2) {
			OUT_BATCH((rmesa->radeon.tcl.aos[i].components << 0) |
				  (rmesa->radeon.tcl.aos[i].stride << 8) |
				  (rmesa->radeon.tcl.aos[i + 1].components << 16) |
				  (rmesa->radeon.tcl.aos[i + 1].stride << 24));

			voffset =  rmesa->radeon.tcl.aos[i + 0].offset +
				offset * 4 * rmesa->radeon.tcl.aos[i + 0].stride;
			OUT_BATCH_RELOC(voffset,
					rmesa->radeon.tcl.aos[i].bo,
					voffset,
					RADEON_GEM_DOMAIN_GTT,
					0, 0);
			voffset =  rmesa->radeon.tcl.aos[i + 1].offset +
			  offset * 4 * rmesa->radeon.tcl.aos[i + 1].stride;
			OUT_BATCH_RELOC(voffset,
					rmesa->radeon.tcl.aos[i+1].bo,
					voffset,
					RADEON_GEM_DOMAIN_GTT,
					0, 0);
		}
d280 6
a285 62
		if (nr & 1) {
			OUT_BATCH((rmesa->radeon.tcl.aos[nr - 1].components << 0) |
				  (rmesa->radeon.tcl.aos[nr - 1].stride << 8));
			voffset =  rmesa->radeon.tcl.aos[nr - 1].offset +
				offset * 4 * rmesa->radeon.tcl.aos[nr - 1].stride;
			OUT_BATCH_RELOC(voffset,
					rmesa->radeon.tcl.aos[nr - 1].bo,
					voffset,
					RADEON_GEM_DOMAIN_GTT,
					0, 0);
		}
		END_BATCH();
	} else {

		BEGIN_BATCH(sz+2+(nr * 2));
		OUT_BATCH_PACKET3(R300_PACKET3_3D_LOAD_VBPNTR, sz - 1);
		OUT_BATCH(nr);

		for (i = 0; i + 1 < nr; i += 2) {
			OUT_BATCH((rmesa->radeon.tcl.aos[i].components << 0) |
				  (rmesa->radeon.tcl.aos[i].stride << 8) |
				  (rmesa->radeon.tcl.aos[i + 1].components << 16) |
				  (rmesa->radeon.tcl.aos[i + 1].stride << 24));

			voffset =  rmesa->radeon.tcl.aos[i + 0].offset +
				offset * 4 * rmesa->radeon.tcl.aos[i + 0].stride;
			OUT_BATCH(voffset);
			voffset =  rmesa->radeon.tcl.aos[i + 1].offset +
				offset * 4 * rmesa->radeon.tcl.aos[i + 1].stride;
			OUT_BATCH(voffset);
		}

		if (nr & 1) {
			OUT_BATCH((rmesa->radeon.tcl.aos[nr - 1].components << 0) |
			  (rmesa->radeon.tcl.aos[nr - 1].stride << 8));
			voffset =  rmesa->radeon.tcl.aos[nr - 1].offset +
				offset * 4 * rmesa->radeon.tcl.aos[nr - 1].stride;
			OUT_BATCH(voffset);
		}
		for (i = 0; i + 1 < nr; i += 2) {
			voffset =  rmesa->radeon.tcl.aos[i + 0].offset +
				offset * 4 * rmesa->radeon.tcl.aos[i + 0].stride;
			radeon_cs_write_reloc(rmesa->radeon.cmdbuf.cs,
					      rmesa->radeon.tcl.aos[i+0].bo,
					      RADEON_GEM_DOMAIN_GTT,
					      0, 0);
			voffset =  rmesa->radeon.tcl.aos[i + 1].offset +
				offset * 4 * rmesa->radeon.tcl.aos[i + 1].stride;
			radeon_cs_write_reloc(rmesa->radeon.cmdbuf.cs,
					      rmesa->radeon.tcl.aos[i+1].bo,
					      RADEON_GEM_DOMAIN_GTT,
					      0, 0);
		}
		if (nr & 1) {
			voffset =  rmesa->radeon.tcl.aos[nr - 1].offset +
				offset * 4 * rmesa->radeon.tcl.aos[nr - 1].stride;
			radeon_cs_write_reloc(rmesa->radeon.cmdbuf.cs,
					      rmesa->radeon.tcl.aos[nr-1].bo,
					      RADEON_GEM_DOMAIN_GTT,
					      0, 0);
		}
		END_BATCH();
a286 1

d291 7
a297 7
	BATCH_LOCALS(&rmesa->radeon);

        r300_emit_scissor(rmesa->radeon.glCtx);
	BEGIN_BATCH(3);
	OUT_BATCH_PACKET3(R300_PACKET3_3D_DRAW_VBUF_2, 0);
	OUT_BATCH(R300_VAP_VF_CNTL__PRIM_WALK_VERTEX_LIST | (vertex_count << 16) | type);
	END_BATCH();
d300 2
a301 1
void r300RunRenderPrimitive(struct gl_context * ctx, int start, int end, int prim)
a302 2
	r300ContextPtr rmesa = R300_CONTEXT(ctx);
	BATCH_LOCALS(&rmesa->radeon);
d305 1
a305 1
	type = r300PrimitiveType(rmesa, prim);
d311 5
a315 6
	if (rmesa->ind_buf.bo) {
		GLuint first, incr, offset = 0;

		if (!split_prim_inplace(prim & PRIM_MODE_MASK, &first, &incr) &&
			num_verts > 65500) {
			WARN_ONCE("Fixme: can't handle spliting prim %d\n", prim);
d318 9
d328 12
d341 1
a341 7
		r300EmitAOS(rmesa, rmesa->radeon.tcl.aos_count, 0);
		if (rmesa->radeon.radeonScreen->kernel_mm) {
			BEGIN_BATCH_NO_AUTOSTATE(2);
			OUT_BATCH_REGSEQ(R300_VAP_VF_MAX_VTX_INDX, 1);
			OUT_BATCH(rmesa->radeon.tcl.aos[0].count);
			END_BATCH();
		}
d343 4
a346 22
		r300_emit_scissor(rmesa->radeon.glCtx);
		while (num_verts > 0) {
			int nr;
			int align;

			nr = MIN2(num_verts, 65535);
			nr -= (nr - first) % incr;

			/* get alignment for IB correct */
			if (nr != num_verts) {
				do {
				    align = nr * (rmesa->ind_buf.is_32bit ? 4 : 2);
				    if (align % 4)
					nr -= incr;
				} while(align % 4);
				if (nr <= 0) {
					WARN_ONCE("did the impossible happen? we never aligned nr to dword\n");
					return;
				}
					
			}
			r300FireEB(rmesa, nr, type, offset);
d348 1
a348 3
			num_verts -= nr;
			offset += nr;
		}
d350 2
d353 45
a397 1
		GLuint first, incr, offset = 0;
d399 5
a403 5
		if (!split_prim_inplace(prim & PRIM_MODE_MASK, &first, &incr) &&
			num_verts > 65535) {
			WARN_ONCE("Fixme: can't handle spliting prim %d\n", prim);
			return;
		}
d405 1
a405 6
		if (rmesa->radeon.radeonScreen->kernel_mm) {
			BEGIN_BATCH_NO_AUTOSTATE(2);
			OUT_BATCH_REGSEQ(R300_VAP_VF_MAX_VTX_INDX, 1);
			OUT_BATCH(rmesa->radeon.tcl.aos[0].count);
			END_BATCH();
		}
d407 5
a411 10
		r300_emit_scissor(rmesa->radeon.glCtx);
		while (num_verts > 0) {
			int nr;
			nr = MIN2(num_verts, 65535);
			nr -= (nr - first) % incr;
			r300EmitAOS(rmesa, rmesa->radeon.tcl.aos_count, start + offset);
			r300FireAOS(rmesa, nr, type);
			num_verts -= nr;
			offset += nr;
		}
d413 14
a426 1
	COMMIT_BATCH();
d429 11
a439 1
static const char *getFallbackString(r300ContextPtr rmesa, uint32_t bit)
d441 32
a472 29
	static char common_fallback_str[32];
	switch (bit) {
		case R300_FALLBACK_VERTEX_PROGRAM :
			return "vertex program";
		case R300_FALLBACK_LINE_SMOOTH:
			return "smooth lines";
		case R300_FALLBACK_POINT_SMOOTH:
			return "smooth points";
		case R300_FALLBACK_POLYGON_SMOOTH:
			return "smooth polygons";
		case R300_FALLBACK_LINE_STIPPLE:
			return "line stipple";
		case R300_FALLBACK_POLYGON_STIPPLE:
			return "polygon stipple";
		case R300_FALLBACK_STENCIL_TWOSIDE:
			return "two-sided stencil";
		case R300_FALLBACK_RENDER_MODE:
			return "render mode != GL_RENDER";
		case R300_FALLBACK_FRAGMENT_PROGRAM:
			return "fragment program";
		case R300_FALLBACK_RADEON_COMMON:
			snprintf(common_fallback_str, 32, "radeon common 0x%08x", rmesa->radeon.Fallback);
			return common_fallback_str;
		case R300_FALLBACK_AOS_LIMIT:
			return "aos limit";
		case R300_FALLBACK_INVALID_BUFFERS:
			return "invalid buffers";
		default:
			return "unknown";
d474 2
d478 14
a491 1
void r300SwitchFallback(struct gl_context *ctx, uint32_t bit, GLboolean mode)
a492 1
	TNLcontext *tnl = TNL_CONTEXT(ctx);
d494 1
a494 2
	uint32_t old_fallback = rmesa->fallback;
	static uint32_t fallback_warn = 0;
d496 1
a496 7
	if (mode) {
		if ((fallback_warn & bit) == 0) {
			if (RADEON_DEBUG & RADEON_FALLBACKS)
				fprintf(stderr, "WARNING! Falling back to software for %s\n", getFallbackString(rmesa, bit));
			fallback_warn |= bit;
		}
		rmesa->fallback |= bit;
d498 2
a499 8
		/* update only if we change from no tcl fallbacks to some tcl fallbacks */
		if (rmesa->options.hw_tcl_enabled) {
			if (((old_fallback & R300_TCL_FALLBACK_MASK) == 0) &&
				((bit & R300_TCL_FALLBACK_MASK) > 0)) {
				R300_STATECHANGE(rmesa, vap_cntl_status);
				rmesa->hw.vap_cntl_status.cmd[1] |= R300_VAP_TCL_BYPASS;
			}
		}
d501 2
a502 10
		/* update only if we change from no raster fallbacks to some raster fallbacks */
		if (((old_fallback & R300_RASTER_FALLBACK_MASK) == 0) &&
			((bit & R300_RASTER_FALLBACK_MASK) > 0)) {

			radeon_firevertices(&rmesa->radeon);
			rmesa->radeon.swtcl.RenderIndex = ~0;
			_swsetup_Wakeup( ctx );
		}
	} else {
		rmesa->fallback &= ~bit;
d504 4
a507 7
		/* update only if we have disabled all tcl fallbacks */
		if (rmesa->options.hw_tcl_enabled) {
			if ((old_fallback & R300_TCL_FALLBACK_MASK) == bit) {
				R300_STATECHANGE(rmesa, vap_cntl_status);
				rmesa->hw.vap_cntl_status.cmd[1] &= ~R300_VAP_TCL_BYPASS;
			}
		}
d509 1
a509 11
		/* update only if we have disabled all raster fallbacks */
		if ((old_fallback & R300_RASTER_FALLBACK_MASK) == bit) {
			_swrast_flush( ctx );

			tnl->Driver.Render.Start = r300RenderStart;
			tnl->Driver.Render.Finish = r300RenderFinish;
			tnl->Driver.Render.PrimitiveNotify = r300RenderPrimitive;
			tnl->Driver.Render.ResetLineStipple = r300ResetLineStipple;
			tnl->Driver.Render.BuildVertices = _tnl_build_vertices;
			tnl->Driver.Render.CopyPV = _tnl_copy_pv;
			tnl->Driver.Render.Interp = _tnl_interp;
d511 4
a514 3
			_tnl_invalidate_vertex_state( ctx, ~0 );
			_tnl_invalidate_vertices( ctx, ~0 );
		}
d517 1
d519 18
@


