head	1.8;
access;
symbols
	OPENBSD_5_5:1.7.0.2
	OPENBSD_5_5_BASE:1.7
	v9_2_5:1.1.1.5
	v9_2_3:1.1.1.5
	v9_2_2:1.1.1.5
	v9_2_1:1.1.1.5
	v9_2_0:1.1.1.5
	OPENBSD_5_4:1.6.0.4
	OPENBSD_5_4_BASE:1.6
	OPENBSD_5_3:1.6.0.2
	OPENBSD_5_3_BASE:1.6
	OPENBSD_5_2:1.5.0.4
	OPENBSD_5_2_BASE:1.5
	OPENBSD_5_1_BASE:1.5
	OPENBSD_5_1:1.5.0.2
	v7_10_3:1.1.1.4
	OPENBSD_5_0:1.4.0.6
	OPENBSD_5_0_BASE:1.4
	OPENBSD_4_9:1.4.0.2
	OPENBSD_4_9_BASE:1.4
	OPENBSD_4_8:1.4.0.4
	OPENBSD_4_8_BASE:1.4
	OPENBSD_4_7:1.3.0.4
	OPENBSD_4_7_BASE:1.3
	OPENBSD_4_6:1.3.0.2
	OPENBSD_4_6_BASE:1.3
	OPENBSD_4_5:1.2.0.2
	OPENBSD_4_5_BASE:1.2
	OPENBSD_4_4:1.1.1.3.0.4
	OPENBSD_4_4_BASE:1.1.1.3
	OPENBSD_4_3_BASE:1.1.1.3
	OPENBSD_4_3:1.1.1.3.0.2
	v7_0_1:1.1.1.3
	OPENBSD_4_2:1.1.1.2.0.2
	OPENBSD_4_2_BASE:1.1.1.2
	v6_5_2:1.1.1.2
	v6_5_1:1.1.1.1
	mesa:1.1.1;
locks; strict;
comment	@ * @;


1.8
date	2014.07.09.21.08.59;	author jsg;	state dead;
branches;
next	1.7;
commitid	WPD6rgPryPkvXOr9;

1.7
date	2013.09.05.14.04.22;	author jsg;	state Exp;
branches;
next	1.6;

1.6
date	2012.08.17.13.58.15;	author mpi;	state Exp;
branches;
next	1.5;

1.5
date	2011.10.23.13.37.39;	author matthieu;	state Exp;
branches;
next	1.4;

1.4
date	2010.05.22.20.06.19;	author matthieu;	state Exp;
branches;
next	1.3;

1.3
date	2009.05.17.20.26.39;	author matthieu;	state Exp;
branches;
next	1.2;

1.2
date	2008.11.02.14.58.15;	author matthieu;	state Exp;
branches;
next	1.1;

1.1
date	2006.11.25.18.52.48;	author matthieu;	state Exp;
branches
	1.1.1.1;
next	;

1.1.1.1
date	2006.11.25.18.52.48;	author matthieu;	state Exp;
branches;
next	1.1.1.2;

1.1.1.2
date	2007.03.03.11.57.17;	author matthieu;	state Exp;
branches;
next	1.1.1.3;

1.1.1.3
date	2007.11.24.17.28.38;	author matthieu;	state Exp;
branches;
next	1.1.1.4;

1.1.1.4
date	2011.10.23.13.29.36;	author matthieu;	state Exp;
branches;
next	1.1.1.5;

1.1.1.5
date	2013.09.05.13.15.41;	author jsg;	state Exp;
branches;
next	;


desc
@@


1.8
log
@Merge Mesa 10.2.3
tested by matthieu@@ kettenis@@ mpi@@ brett@@ and myself across a
diverse range of hardware
@
text
@/*
 Copyright (C) Intel Corp.  2006.  All Rights Reserved.
 Intel funded Tungsten Graphics (http://www.tungstengraphics.com) to
 develop this 3D driver.
 
 Permission is hereby granted, free of charge, to any person obtaining
 a copy of this software and associated documentation files (the
 "Software"), to deal in the Software without restriction, including
 without limitation the rights to use, copy, modify, merge, publish,
 distribute, sublicense, and/or sell copies of the Software, and to
 permit persons to whom the Software is furnished to do so, subject to
 the following conditions:
 
 The above copyright notice and this permission notice (including the
 next paragraph) shall be included in all copies or substantial
 portions of the Software.
 
 THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
 IN NO EVENT SHALL THE COPYRIGHT OWNER(S) AND/OR ITS SUPPLIERS BE
 LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
 OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
 WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 
**********************************************************************/

/*
 * Authors:
 *   Keith Whitwell <keith@@tungstengraphics.com>
 */

#include "main/glheader.h"
#include "main/mtypes.h"
#include "main/imports.h"
#include "main/macros.h"
#include "main/colormac.h"
#include "main/renderbuffer.h"
#include "main/framebuffer.h"

#include "intel_batchbuffer.h" 
#include "intel_regions.h" 
#include "intel_fbo.h"

#include "brw_context.h"
#include "brw_program.h"
#include "brw_defines.h"
#include "brw_state.h"
#include "brw_draw.h"
#include "brw_vs.h"
#include "brw_wm.h"

#include "gen6_blorp.h"
#include "gen7_blorp.h"

#include "glsl/ralloc.h"

static void
dri_bo_release(drm_intel_bo **bo)
{
   drm_intel_bo_unreference(*bo);
   *bo = NULL;
}


/**
 * called from intelDestroyContext()
 */
static void
brw_destroy_context(struct brw_context *brw)
{
   if (INTEL_DEBUG & DEBUG_SHADER_TIME) {
      /* Force a report. */
      brw->shader_time.report_time = 0;

      brw_collect_and_report_shader_time(brw);
      brw_destroy_shader_time(brw);
   }

   brw_destroy_state(brw);
   brw_draw_destroy( brw );

   dri_bo_release(&brw->curbe.curbe_bo);
   dri_bo_release(&brw->vs.const_bo);
   dri_bo_release(&brw->wm.const_bo);

   free(brw->curbe.last_buf);
   free(brw->curbe.next_buf);

   drm_intel_gem_context_destroy(brw->hw_ctx);
}

/**
 * called from intel_batchbuffer_flush and children before sending a
 * batchbuffer off.
 *
 * Note that ALL state emitted here must fit in the reserved space
 * at the end of a batchbuffer.  If you add more GPU state, increase
 * the BATCH_RESERVED macro.
 */
static void
brw_finish_batch(struct brw_context *brw)
{
   brw_emit_query_end(brw);

   if (brw->curbe.curbe_bo) {
      drm_intel_gem_bo_unmap_gtt(brw->curbe.curbe_bo);
      drm_intel_bo_unreference(brw->curbe.curbe_bo);
      brw->curbe.curbe_bo = NULL;
   }
}


/**
 * called from intelFlushBatchLocked
 */
static void
brw_new_batch(struct brw_context *brw)
{
   /* If the kernel supports hardware contexts, then most hardware state is
    * preserved between batches; we only need to re-emit state that is required
    * to be in every batch.  Otherwise we need to re-emit all the state that
    * would otherwise be stored in the context (which for all intents and
    * purposes means everything).
    */
   if (brw->hw_ctx == NULL)
      brw->state.dirty.brw |= BRW_NEW_CONTEXT;

   brw->state.dirty.brw |= BRW_NEW_BATCH;

   /* Assume that the last command before the start of our batch was a
    * primitive, for safety.
    */
   brw->batch.need_workaround_flush = true;

   brw->state_batch_count = 0;

   brw->ib.type = -1;

   /* Mark that the current program cache BO has been used by the GPU.
    * It will be reallocated if we need to put new programs in for the
    * next batch.
    */
   brw->cache.bo_used_by_gpu = true;

   /* We need to periodically reap the shader time results, because rollover
    * happens every few seconds.  We also want to see results every once in a
    * while, because many programs won't cleanly destroy our context, so the
    * end-of-run printout may not happen.
    */
   if (INTEL_DEBUG & DEBUG_SHADER_TIME)
      brw_collect_and_report_shader_time(brw);
}

void brwInitVtbl( struct brw_context *brw )
{
   brw->vtbl.new_batch = brw_new_batch;
   brw->vtbl.finish_batch = brw_finish_batch;
   brw->vtbl.destroy = brw_destroy_context;

   assert(brw->gen >= 4);
   if (brw->gen >= 7) {
      gen7_init_vtable_surface_functions(brw);
      brw->vtbl.emit_depth_stencil_hiz = gen7_emit_depth_stencil_hiz;
   } else if (brw->gen >= 4) {
      gen4_init_vtable_surface_functions(brw);
      brw->vtbl.emit_depth_stencil_hiz = brw_emit_depth_stencil_hiz;
   }
}
@


1.7
log
@Merge Mesa 9.2.0
@
text
@@


1.6
log
@Upate to libGL 7.11.2

Tested by jsg@@, matthieu@@ and ajacoutot@@, ok mattieu@@
@
text
@d46 1
d53 4
a56 1
#include "../glsl/ralloc.h"
d69 2
a70 1
static void brw_destroy_context( struct intel_context *intel )
d72 7
a78 1
   struct brw_context *brw = brw_context(&intel->ctx);
a81 2
   brw_clear_validated_bos(brw);
   ralloc_free(brw->wm.compile_data);
a88 88
}

/**
 * Update the hardware state for drawing into a window or framebuffer object.
 *
 * Called by glDrawBuffer, glBindFramebufferEXT, MakeCurrent, and other
 * places within the driver.
 *
 * Basically, this needs to be called any time the current framebuffer
 * changes, the renderbuffers change, or we need to draw into different
 * color buffers.
 */
static void
brw_update_draw_buffer(struct intel_context *intel)
{
   struct gl_context *ctx = &intel->ctx;
   struct gl_framebuffer *fb = ctx->DrawBuffer;
   struct intel_renderbuffer *irbDepth = NULL, *irbStencil = NULL;
   bool fb_has_hiz = intel_framebuffer_has_hiz(fb);

   if (!fb) {
      /* this can happen during the initial context initialization */
      return;
   }

   /*
    * If intel_context is using separate stencil, but the depth attachment
    * (gl_framebuffer.Attachment[BUFFER_DEPTH]) has a packed depth/stencil
    * format, then we must install the real depth buffer at fb->_DepthBuffer
    * and set fb->_DepthBuffer->Wrapped before calling _mesa_update_framebuffer.
    * Otherwise, _mesa_update_framebuffer will create and install a swras
    * depth wrapper instead.
    *
    * Ditto for stencil.
    */
   irbDepth = intel_get_renderbuffer(fb, BUFFER_DEPTH);
   if (irbDepth && irbDepth->Base.Format == MESA_FORMAT_X8_Z24) {
      _mesa_reference_renderbuffer(&fb->_DepthBuffer, &irbDepth->Base);
      irbDepth->Base.Wrapped = fb->Attachment[BUFFER_DEPTH].Renderbuffer;
   }

   irbStencil = intel_get_renderbuffer(fb, BUFFER_STENCIL);
   if (irbStencil && irbStencil->Base.Format == MESA_FORMAT_S8) {
      _mesa_reference_renderbuffer(&fb->_StencilBuffer, &irbStencil->Base);
      irbStencil->Base.Wrapped = fb->Attachment[BUFFER_STENCIL].Renderbuffer;
   }

   /* Do this here, not core Mesa, since this function is called from
    * many places within the driver.
    */
   if (ctx->NewState & _NEW_BUFFERS) {
      /* this updates the DrawBuffer->_NumColorDrawBuffers fields, etc */
      _mesa_update_framebuffer(ctx);
      /* this updates the DrawBuffer's Width/Height if it's a FBO */
      _mesa_update_draw_buffer_bounds(ctx);
   }

   if (fb->_Status != GL_FRAMEBUFFER_COMPLETE_EXT) {
      /* this may occur when we're called by glBindFrameBuffer() during
       * the process of someone setting up renderbuffers, etc.
       */
      /*_mesa_debug(ctx, "DrawBuffer: incomplete user FBO\n");*/
      return;
   }

   /* Check some stencil invariants.  These should probably be in
    * emit_depthbuffer().
    */
   if (irbStencil && irbStencil->region) {
      if (!intel->has_separate_stencil)
	 assert(irbStencil->Base.Format == MESA_FORMAT_S8_Z24);
      if (fb_has_hiz || intel->must_use_separate_stencil)
	 assert(irbStencil->Base.Format == MESA_FORMAT_S8);
      if (irbStencil->Base.Format == MESA_FORMAT_S8)
	 assert(intel->has_separate_stencil);
   }

   /* Mesa's Stencil._Enabled field is updated when
    * _NEW_BUFFERS | _NEW_STENCIL, but i965 code assumes that the value
    * only changes with _NEW_STENCIL (which seems sensible).  So flag it
    * here since this is the _NEW_BUFFERS path.
    */
   intel->NewGLState |= (_NEW_DEPTH | _NEW_STENCIL);

   /* The driver uses this in places that need to look up
    * renderbuffers' buffer objects.
    */
   intel->NewGLState |= _NEW_BUFFERS;
d90 1
a90 7
   /* update viewport/scissor since it depends on window size */
   intel->NewGLState |= _NEW_VIEWPORT | _NEW_SCISSOR;

   /* Update culling direction which changes depending on the
    * orientation of the buffer:
    */
   intel->NewGLState |= _NEW_POLYGON;
d96 4
d101 2
a102 1
static void brw_finish_batch(struct intel_context *intel)
a103 1
   struct brw_context *brw = brw_context(&intel->ctx);
d117 2
a118 1
static void brw_new_batch( struct intel_context *intel )
d120 8
a127 1
   struct brw_context *brw = brw_context(&intel->ctx);
d129 1
a129 5
   /* Mark all context state as needing to be re-emitted.
    * This is probably not as severe as on 915, since almost all of our state
    * is just in referenced buffers.
    */
   brw->state.dirty.brw |= BRW_NEW_CONTEXT | BRW_NEW_BATCH;
d134 3
a136 1
   intel->batch.need_workaround_flush = true;
a137 1
   brw->vb.nr_current_buffers = 0;
a144 1
}
d146 7
a152 13
static void brw_invalidate_state( struct intel_context *intel, GLuint new_state )
{
   /* nothing */
}

/**
 * \see intel_context.vtbl.is_hiz_depth_format
 */
static bool brw_is_hiz_depth_format(struct intel_context *intel,
                                    gl_format format)
{
   /* In the future, this will support Z_FLOAT32. */
   return intel->has_hiz && (format == MESA_FORMAT_X8_Z24);
a154 1

d157 12
a168 14
   brw->intel.vtbl.check_vertex_size = 0;
   brw->intel.vtbl.emit_state = 0;
   brw->intel.vtbl.reduced_primitive_state = 0;
   brw->intel.vtbl.render_start = 0;
   brw->intel.vtbl.update_texture_state = 0;

   brw->intel.vtbl.invalidate_state = brw_invalidate_state;
   brw->intel.vtbl.new_batch = brw_new_batch;
   brw->intel.vtbl.finish_batch = brw_finish_batch;
   brw->intel.vtbl.destroy = brw_destroy_context;
   brw->intel.vtbl.update_draw_buffer = brw_update_draw_buffer;
   brw->intel.vtbl.debug_batch = brw_debug_batch;
   brw->intel.vtbl.render_target_supported = brw_render_target_supported;
   brw->intel.vtbl.is_hiz_depth_format = brw_is_hiz_depth_format;
@


1.5
log
@Merge Mesa 7.10.3
@
text
@d38 2
d43 1
d52 2
a67 1
   int i;
d72 1
a72 12
   if (brw->wm.compile_data) {
      free(brw->wm.compile_data->instruction);
      free(brw->wm.compile_data->vreg);
      free(brw->wm.compile_data->refs);
      free(brw->wm.compile_data->prog_instructions);
      free(brw->wm.compile_data);
   }

   for (i = 0; i < brw->state.nr_color_regions; i++)
      intel_region_release(&brw->state.color_regions[i]);
   brw->state.nr_color_regions = 0;
   intel_region_release(&brw->state.depth_region);
a74 3
   dri_bo_release(&brw->vs.prog_bo);
   dri_bo_release(&brw->vs.state_bo);
   dri_bo_release(&brw->vs.bind_bo);
a75 16
   dri_bo_release(&brw->gs.prog_bo);
   dri_bo_release(&brw->gs.state_bo);
   dri_bo_release(&brw->clip.prog_bo);
   dri_bo_release(&brw->clip.state_bo);
   dri_bo_release(&brw->clip.vp_bo);
   dri_bo_release(&brw->sf.prog_bo);
   dri_bo_release(&brw->sf.state_bo);
   dri_bo_release(&brw->sf.vp_bo);
   for (i = 0; i < BRW_MAX_TEX_UNIT; i++)
      dri_bo_release(&brw->wm.sdc_bo[i]);
   dri_bo_release(&brw->wm.bind_bo);
   for (i = 0; i < BRW_WM_MAX_SURF; i++)
      dri_bo_release(&brw->wm.surf_bo[i]);
   dri_bo_release(&brw->wm.sampler_bo);
   dri_bo_release(&brw->wm.prog_bo);
   dri_bo_release(&brw->wm.state_bo);
a76 7
   dri_bo_release(&brw->wm.push_const_bo);
   dri_bo_release(&brw->cc.prog_bo);
   dri_bo_release(&brw->cc.state_bo);
   dri_bo_release(&brw->cc.vp_bo);
   dri_bo_release(&brw->cc.blend_state_bo);
   dri_bo_release(&brw->cc.depth_stencil_state_bo);
   dri_bo_release(&brw->cc.color_calc_state_bo);
a81 1

d83 8
a90 1
 * called from intelDrawBuffer()
d92 2
a93 4
static void brw_set_draw_region( struct intel_context *intel, 
                                 struct intel_region *color_regions[],
                                 struct intel_region *depth_region,
                                 GLuint num_color_regions)
d95 76
a170 2
   struct brw_context *brw = brw_context(&intel->ctx);
   GLuint i;
d172 4
a175 12
   /* release old color/depth regions */
   if (brw->state.depth_region != depth_region)
      brw->state.dirty.brw |= BRW_NEW_DEPTH_BUFFER;
   for (i = 0; i < brw->state.nr_color_regions; i++)
       intel_region_release(&brw->state.color_regions[i]);
   intel_region_release(&brw->state.depth_region);

   /* reference new color/depth regions */
   for (i = 0; i < num_color_regions; i++)
       intel_region_reference(&brw->state.color_regions[i], color_regions[i]);
   intel_region_reference(&brw->state.depth_region, depth_region);
   brw->state.nr_color_regions = num_color_regions;
a177 1

d206 9
a214 1
   brw->state.dirty.brw |= BRW_NEW_CONTEXT;
d216 5
a220 12
   brw->state.dirty.mesa |= ~0;
   brw->state.dirty.brw |= ~0;
   brw->state.dirty.cache |= ~0;

   /* Move to the end of the current upload buffer so that we'll force choosing
    * a new buffer next time.
    */
   if (brw->vb.upload.bo != NULL) {
      drm_intel_bo_unreference(brw->vb.upload.bo);
      brw->vb.upload.bo = NULL;
      brw->vb.upload.offset = 0;
   }
d228 10
d251 1
a251 1
   brw->intel.vtbl.set_draw_region = brw_set_draw_region;
d253 2
@


1.4
log
@Update to Mesa 7.8.1. Tested on a bulk ports build by naddy@@, ok oga@@.
@
text
@a45 1
#include "brw_state.h"
d50 1
a50 1
dri_bo_release(dri_bo **bo)
d52 1
a52 1
   dri_bo_unreference(*bo);
d85 1
d102 2
d110 3
d180 1
a180 1
      dri_bo_unreference(brw->vb.upload.bo);
@


1.3
log
@Update to Mesa 7.4.2. Tested by oga@@, ckuethe@@ and naddy@@.
@
text
@d26 1
a26 7
 **********************************************************************/
 /*
  * Authors:
  *   Keith Whitwell <keith@@tungstengraphics.com>
  */
            

d28 4
a44 1

a46 1
#include "brw_fallback.h"
d48 1
a48 1
#include <stdarg.h>
d57 3
a59 1
/* called from intelDestroyContext()
d68 8
d77 3
a79 5
   brw_FrameBufferTexDestroy( brw );

   for (i = 0; i < brw->state.nr_draw_regions; i++)
       intel_region_release(&brw->state.draw_regions[i]);
   brw->state.nr_draw_regions = 0;
d85 1
d99 1
d105 3
d110 3
a112 1
/* called from intelDrawBuffer()
d115 3
a117 3
				  struct intel_region *draw_regions[],
				  struct intel_region *depth_region,
				GLuint num_regions)
d120 3
a122 1
   int i;
d125 2
a126 2
   for (i = 0; i < brw->state.nr_draw_regions; i++)
       intel_region_release(&brw->state.draw_regions[i]);
d128 4
a131 2
   for (i = 0; i < num_regions; i++)
       intel_region_reference(&brw->state.draw_regions[i], draw_regions[i]);
d133 1
a133 1
   brw->state.nr_draw_regions = num_regions;
d136 3
a138 1
/* called from intel_batchbuffer_flush and children before sending a
d144 1
d146 5
a150 1
   brw_emit_query_end(brw);
d153 3
a155 1
/* called from intelFlushBatchLocked
a160 5
   /* Check that we didn't just wrap our batchbuffer at a bad time. */
   assert(!brw->no_batch_wrap);

   brw->curbe.need_new_bo = GL_TRUE;

a180 46
static void brw_note_fence( struct intel_context *intel, 
			    GLuint fence )
{
   brw_context(&intel->ctx)->state.dirty.brw |= BRW_NEW_FENCE;
}
 
static void brw_note_unlock( struct intel_context *intel )
{
   struct brw_context *brw = brw_context(&intel->ctx);

   brw_state_cache_check_size(brw);
}


void brw_do_flush( struct brw_context *brw, 
		   GLuint flags )
{
   struct brw_mi_flush flush;
   memset(&flush, 0, sizeof(flush));      
   flush.opcode = CMD_MI_FLUSH;
   flush.flags = flags;
   BRW_BATCH_STRUCT(brw, &flush);
}


static void brw_emit_flush( struct intel_context *intel,
			GLuint unused )
{
   brw_do_flush(brw_context(&intel->ctx),
		BRW_FLUSH_STATE_CACHE|BRW_FLUSH_READ_CACHE);
}


/* called from intelWaitForIdle() and intelFlush()
 *
 * For now, just flush everything.  Could be smarter later.
 */
static GLuint brw_flush_cmd( void )
{
   struct brw_mi_flush flush;
   flush.opcode = CMD_MI_FLUSH;
   flush.pad = 0;
   flush.flags = BRW_FLUSH_READ_CACHE | BRW_FLUSH_STATE_CACHE;
   return *(GLuint *)&flush;
}

d190 2
a191 2
   brw->intel.vtbl.emit_state = 0; 
   brw->intel.vtbl.reduced_primitive_state = 0;	
d193 1
a193 1
   brw->intel.vtbl.update_texture_state = 0; 
d195 1
a195 3
   brw->intel.vtbl.invalidate_state = brw_invalidate_state; 
   brw->intel.vtbl.note_fence = brw_note_fence; 
   brw->intel.vtbl.note_unlock = brw_note_unlock; 
a199 2
   brw->intel.vtbl.flush_cmd = brw_flush_cmd;
   brw->intel.vtbl.emit_flush = brw_emit_flush;
a201 1

@


1.2
log
@Mesa 7.2, Tested by ckuethe@@, naddy@@, oga@@, and others.
@
text
@d35 5
a39 5
#include "glheader.h"
#include "mtypes.h"
#include "imports.h"
#include "macros.h"
#include "colormac.h"
d54 6
a64 1
   GLcontext *ctx = &intel->ctx;
d66 1
a67 1
   brw_destroy_metaops(brw);
a70 1
   brw_ProgramCacheDestroy( ctx );
d72 27
d121 9
d140 1
a140 2
   dri_bo_unreference(brw->curbe.curbe_bo);
   brw->curbe.curbe_bo = NULL;
a172 2

   brw_context(&intel->ctx)->state.dirty.brw |= BRW_NEW_LOCK;
d226 1
@


1.1
log
@Initial revision
@
text
@a48 2
#include "brw_exec.h"
#include "brw_save.h"
a49 1
#include "brw_aub.h"
d52 1
a52 1

a61 2
   brw_aub_destroy(brw);

a65 3
   brw_exec_destroy( ctx );
   brw_save_destroy( ctx );

d67 1
d73 3
a75 2
				  struct intel_region *draw_region,
				  struct intel_region *depth_region)
d78 8
a85 4

   intel_region_release(intel, &brw->state.draw_region);
   intel_region_release(intel, &brw->state.depth_region);
   intel_region_reference(&brw->state.draw_region, draw_region);
d87 1
d93 1
a93 1
static void brw_lost_hardware( struct intel_context *intel )
d97 9
a105 4
   /* Note that we effectively lose the context after this.
    * 
    * Setting this flag provokes a state buffer wrap and also flushes
    * the hardware caches.
a108 4
   /* Which means there shouldn't be any commands already queued:
    */
   assert(intel->batch->ptr == intel->batch->map + intel->batch->offset);

d112 9
d131 1
a131 1
  struct brw_context *brw = brw_context(&intel->ctx);
d133 1
a133 2
   brw_pool_check_wrap(brw, &brw->pool[BRW_GS_POOL]);
   brw_pool_check_wrap(brw, &brw->pool[BRW_SS_POOL]);
a170 3



d173 1
a173 4
   GLcontext *ctx = &intel->ctx;

   brw_exec_invalidate_state(ctx, new_state);
   brw_save_invalidate_state(ctx, new_state);
d188 1
a188 1
   brw->intel.vtbl.lost_hardware = brw_lost_hardware;
d193 1
@


1.1.1.1
log
@Import MesaLibs 6.5.1. (in dist/ since its code is shared between lib 
and xserver)...
@
text
@@


1.1.1.2
log
@import MesaLibs version 6.5.2
@
text
@a74 1
   brw_FrameBufferTexDestroy( brw );
@


1.1.1.3
log
@Mesa 7.0.1
@
text
@d49 2
d71 3
d169 4
a172 1
   /* nothing */
@


1.1.1.4
log
@Import Mesa 7.10.3
@
text
@d26 7
a32 1
**********************************************************************/
a33 4
/*
 * Authors:
 *   Keith Whitwell <keith@@tungstengraphics.com>
 */
d35 5
a39 5
#include "main/glheader.h"
#include "main/mtypes.h"
#include "main/imports.h"
#include "main/macros.h"
#include "main/colormac.h"
d47 1
d49 3
a52 1
#include "brw_wm.h"
a53 6
static void
dri_bo_release(drm_intel_bo **bo)
{
   drm_intel_bo_unreference(*bo);
   *bo = NULL;
}
d56 1
a56 2
/**
 * called from intelDestroyContext()
d60 1
a61 1
   int i;
d63 3
a67 43
   brw_clear_validated_bos(brw);
   if (brw->wm.compile_data) {
      free(brw->wm.compile_data->instruction);
      free(brw->wm.compile_data->vreg);
      free(brw->wm.compile_data->refs);
      free(brw->wm.compile_data->prog_instructions);
      free(brw->wm.compile_data);
   }

   for (i = 0; i < brw->state.nr_color_regions; i++)
      intel_region_release(&brw->state.color_regions[i]);
   brw->state.nr_color_regions = 0;
   intel_region_release(&brw->state.depth_region);

   dri_bo_release(&brw->curbe.curbe_bo);
   dri_bo_release(&brw->vs.prog_bo);
   dri_bo_release(&brw->vs.state_bo);
   dri_bo_release(&brw->vs.bind_bo);
   dri_bo_release(&brw->vs.const_bo);
   dri_bo_release(&brw->gs.prog_bo);
   dri_bo_release(&brw->gs.state_bo);
   dri_bo_release(&brw->clip.prog_bo);
   dri_bo_release(&brw->clip.state_bo);
   dri_bo_release(&brw->clip.vp_bo);
   dri_bo_release(&brw->sf.prog_bo);
   dri_bo_release(&brw->sf.state_bo);
   dri_bo_release(&brw->sf.vp_bo);
   for (i = 0; i < BRW_MAX_TEX_UNIT; i++)
      dri_bo_release(&brw->wm.sdc_bo[i]);
   dri_bo_release(&brw->wm.bind_bo);
   for (i = 0; i < BRW_WM_MAX_SURF; i++)
      dri_bo_release(&brw->wm.surf_bo[i]);
   dri_bo_release(&brw->wm.sampler_bo);
   dri_bo_release(&brw->wm.prog_bo);
   dri_bo_release(&brw->wm.state_bo);
   dri_bo_release(&brw->wm.const_bo);
   dri_bo_release(&brw->wm.push_const_bo);
   dri_bo_release(&brw->cc.prog_bo);
   dri_bo_release(&brw->cc.state_bo);
   dri_bo_release(&brw->cc.vp_bo);
   dri_bo_release(&brw->cc.blend_state_bo);
   dri_bo_release(&brw->cc.depth_stencil_state_bo);
   dri_bo_release(&brw->cc.color_calc_state_bo);
d69 2
a70 2
   free(brw->curbe.last_buf);
   free(brw->curbe.next_buf);
d73 1
a73 3

/**
 * called from intelDrawBuffer()
d76 2
a77 3
                                 struct intel_region *color_regions[],
                                 struct intel_region *depth_region,
                                 GLuint num_color_regions)
a79 1
   GLuint i;
d81 3
a83 10
   /* release old color/depth regions */
   if (brw->state.depth_region != depth_region)
      brw->state.dirty.brw |= BRW_NEW_DEPTH_BUFFER;
   for (i = 0; i < brw->state.nr_color_regions; i++)
       intel_region_release(&brw->state.color_regions[i]);
   intel_region_release(&brw->state.depth_region);

   /* reference new color/depth regions */
   for (i = 0; i < num_color_regions; i++)
       intel_region_reference(&brw->state.color_regions[i], color_regions[i]);
a84 1
   brw->state.nr_color_regions = num_color_regions;
d88 1
a88 3
/**
 * called from intel_batchbuffer_flush and children before sending a
 * batchbuffer off.
d90 1
a90 1
static void brw_finish_batch(struct intel_context *intel)
a92 1
   brw_emit_query_end(brw);
d94 14
a107 5
   if (brw->curbe.curbe_bo) {
      drm_intel_gem_bo_unmap_gtt(brw->curbe.curbe_bo);
      drm_intel_bo_unreference(brw->curbe.curbe_bo);
      brw->curbe.curbe_bo = NULL;
   }
d110 9
d120 29
a148 2
/**
 * called from intelFlushBatchLocked
d150 1
a150 1
static void brw_new_batch( struct intel_context *intel )
d152 6
a157 1
   struct brw_context *brw = brw_context(&intel->ctx);
a158 5
   /* Mark all context state as needing to be re-emitted.
    * This is probably not as severe as on 915, since almost all of our state
    * is just in referenced buffers.
    */
   brw->state.dirty.brw |= BRW_NEW_CONTEXT;
a159 3
   brw->state.dirty.mesa |= ~0;
   brw->state.dirty.brw |= ~0;
   brw->state.dirty.cache |= ~0;
a160 9
   /* Move to the end of the current upload buffer so that we'll force choosing
    * a new buffer next time.
    */
   if (brw->vb.upload.bo != NULL) {
      drm_intel_bo_unreference(brw->vb.upload.bo);
      brw->vb.upload.bo = NULL;
      brw->vb.upload.offset = 0;
   }
}
d171 2
a172 2
   brw->intel.vtbl.emit_state = 0;
   brw->intel.vtbl.reduced_primitive_state = 0;
d174 1
a174 1
   brw->intel.vtbl.update_texture_state = 0;
d176 4
a179 3
   brw->intel.vtbl.invalidate_state = brw_invalidate_state;
   brw->intel.vtbl.new_batch = brw_new_batch;
   brw->intel.vtbl.finish_batch = brw_finish_batch;
d182 2
a183 1
   brw->intel.vtbl.debug_batch = brw_debug_batch;
d185 1
@


1.1.1.5
log
@Import Mesa 9.2.0
@
text
@a37 2
#include "main/renderbuffer.h"
#include "main/framebuffer.h"
a40 1
#include "intel_fbo.h"
a42 1
#include "brw_program.h"
a48 5
#include "gen6_blorp.h"
#include "gen7_blorp.h"

#include "glsl/ralloc.h"

d60 1
a60 2
static void
brw_destroy_context(struct brw_context *brw)
d62 2
a63 3
   if (INTEL_DEBUG & DEBUG_SHADER_TIME) {
      /* Force a report. */
      brw->shader_time.report_time = 0;
d65 9
a73 2
      brw_collect_and_report_shader_time(brw);
      brw_destroy_shader_time(brw);
d76 4
a79 2
   brw_destroy_state(brw);
   brw_draw_destroy( brw );
d82 3
d86 16
d103 7
d113 13
d127 12
a138 1
   drm_intel_gem_context_destroy(brw->hw_ctx);
d141 1
a144 4
 *
 * Note that ALL state emitted here must fit in the reserved space
 * at the end of a batchbuffer.  If you add more GPU state, increase
 * the BATCH_RESERVED macro.
d146 1
a146 2
static void
brw_finish_batch(struct brw_context *brw)
d148 1
d162 1
a162 2
static void
brw_new_batch(struct brw_context *brw)
d164 1
a164 10
   /* If the kernel supports hardware contexts, then most hardware state is
    * preserved between batches; we only need to re-emit state that is required
    * to be in every batch.  Otherwise we need to re-emit all the state that
    * would otherwise be stored in the context (which for all intents and
    * purposes means everything).
    */
   if (brw->hw_ctx == NULL)
      brw->state.dirty.brw |= BRW_NEW_CONTEXT;

   brw->state.dirty.brw |= BRW_NEW_BATCH;
d166 3
a168 2
   /* Assume that the last command before the start of our batch was a
    * primitive, for safety.
d170 1
a170 3
   brw->batch.need_workaround_flush = true;

   brw->state_batch_count = 0;
d172 3
a174 1
   brw->ib.type = -1;
d176 2
a177 3
   /* Mark that the current program cache BO has been used by the GPU.
    * It will be reallocated if we need to put new programs in for the
    * next batch.
d179 6
a184 1
   brw->cache.bo_used_by_gpu = true;
d186 3
a188 7
   /* We need to periodically reap the shader time results, because rollover
    * happens every few seconds.  We also want to see results every once in a
    * while, because many programs won't cleanly destroy our context, so the
    * end-of-run printout may not happen.
    */
   if (INTEL_DEBUG & DEBUG_SHADER_TIME)
      brw_collect_and_report_shader_time(brw);
d191 1
d194 12
a205 12
   brw->vtbl.new_batch = brw_new_batch;
   brw->vtbl.finish_batch = brw_finish_batch;
   brw->vtbl.destroy = brw_destroy_context;

   assert(brw->gen >= 4);
   if (brw->gen >= 7) {
      gen7_init_vtable_surface_functions(brw);
      brw->vtbl.emit_depth_stencil_hiz = gen7_emit_depth_stencil_hiz;
   } else if (brw->gen >= 4) {
      gen4_init_vtable_surface_functions(brw);
      brw->vtbl.emit_depth_stencil_hiz = brw_emit_depth_stencil_hiz;
   }
@


