head	1.14;
access;
symbols
	OPENBSD_5_4:1.13.0.4
	OPENBSD_5_4_BASE:1.13
	OPENBSD_5_3:1.13.0.2
	OPENBSD_5_3_BASE:1.13
	OPENBSD_5_2:1.12.0.4
	OPENBSD_5_2_BASE:1.12
	OPENBSD_5_1_BASE:1.12
	OPENBSD_5_1:1.12.0.2
	v7_10_3:1.1.1.1
	mesa:1.1.1
	OPENBSD_5_0:1.11.0.6
	OPENBSD_5_0_BASE:1.11
	OPENBSD_4_9:1.11.0.2
	OPENBSD_4_9_BASE:1.11
	OPENBSD_4_8:1.11.0.4
	OPENBSD_4_8_BASE:1.11
	OPENBSD_4_7:1.8.0.2
	OPENBSD_4_7_BASE:1.8
	OPENBSD_4_6:1.6.0.2
	OPENBSD_4_6_BASE:1.6
	OPENBSD_4_5:1.5.0.2
	OPENBSD_4_5_BASE:1.5;
locks; strict;
comment	@ * @;


1.14
date	2013.09.05.14.04.30;	author jsg;	state dead;
branches;
next	1.13;

1.13
date	2012.08.17.13.58.15;	author mpi;	state Exp;
branches;
next	1.12;

1.12
date	2011.10.23.13.37.39;	author matthieu;	state Exp;
branches;
next	1.11;

1.11
date	2010.07.24.18.13.33;	author oga;	state Exp;
branches;
next	1.10;

1.10
date	2010.06.22.20.04.22;	author matthieu;	state Exp;
branches;
next	1.9;

1.9
date	2010.05.22.20.06.19;	author matthieu;	state Exp;
branches;
next	1.8;

1.8
date	2009.09.08.23.31.10;	author oga;	state Exp;
branches;
next	1.7;

1.7
date	2009.08.06.15.50.02;	author oga;	state Exp;
branches;
next	1.6;

1.6
date	2009.05.17.20.26.39;	author matthieu;	state Exp;
branches;
next	1.5;

1.5
date	2009.02.04.19.48.26;	author oga;	state Exp;
branches;
next	1.4;

1.4
date	2009.01.10.15.56.13;	author oga;	state Exp;
branches;
next	1.3;

1.3
date	2009.01.10.15.27.14;	author oga;	state Exp;
branches;
next	1.2;

1.2
date	2009.01.10.15.09.50;	author oga;	state Exp;
branches;
next	1.1;

1.1
date	2008.11.02.14.58.16;	author matthieu;	state Exp;
branches
	1.1.1.1;
next	;

1.1.1.1
date	2011.10.23.13.29.38;	author matthieu;	state Exp;
branches;
next	;


desc
@@


1.14
log
@Merge Mesa 9.2.0
@
text
@/**************************************************************************
 * 
 * Copyright 2003 Tungsten Graphics, Inc., Cedar Park, Texas.
 * All Rights Reserved.
 * 
 * Permission is hereby granted, free of charge, to any person obtaining a
 * copy of this software and associated documentation files (the
 * "Software"), to deal in the Software without restriction, including
 * without limitation the rights to use, copy, modify, merge, publish,
 * distribute, sub license, and/or sell copies of the Software, and to
 * permit persons to whom the Software is furnished to do so, subject to
 * the following conditions:
 * 
 * The above copyright notice and this permission notice (including the
 * next paragraph) shall be included in all copies or substantial portions
 * of the Software.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
 * OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT.
 * IN NO EVENT SHALL TUNGSTEN GRAPHICS AND/OR ITS SUPPLIERS BE LIABLE FOR
 * ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
 * SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 **************************************************************************/


#include "main/glheader.h"
#include "main/context.h"
#include "main/extensions.h"
#include "main/fbobject.h"
#include "main/framebuffer.h"
#include "main/imports.h"
#include "main/points.h"
#include "main/renderbuffer.h"

#include "swrast/swrast.h"
#include "swrast_setup/swrast_setup.h"
#include "tnl/tnl.h"
#include "drivers/common/driverfuncs.h"
#include "drivers/common/meta.h"

#include "intel_chipset.h"
#include "intel_buffers.h"
#include "intel_tex.h"
#include "intel_batchbuffer.h"
#include "intel_clear.h"
#include "intel_extensions.h"
#include "intel_pixel.h"
#include "intel_regions.h"
#include "intel_buffer_objects.h"
#include "intel_fbo.h"
#include "intel_bufmgr.h"
#include "intel_screen.h"

#include "drirenderbuffer.h"
#include "utils.h"


#ifndef INTEL_DEBUG
int INTEL_DEBUG = (0);
#endif


static const GLubyte *
intelGetString(struct gl_context * ctx, GLenum name)
{
   const struct intel_context *const intel = intel_context(ctx);
   const char *chipset;
   static char buffer[128];

   switch (name) {
   case GL_VENDOR:
      return (GLubyte *) "Tungsten Graphics, Inc";
      break;

   case GL_RENDERER:
      switch (intel->intelScreen->deviceID) {
      case PCI_CHIP_845_G:
         chipset = "Intel(R) 845G";
         break;
      case PCI_CHIP_I830_M:
         chipset = "Intel(R) 830M";
         break;
      case PCI_CHIP_I855_GM:
         chipset = "Intel(R) 852GM/855GM";
         break;
      case PCI_CHIP_I865_G:
         chipset = "Intel(R) 865G";
         break;
      case PCI_CHIP_I915_G:
         chipset = "Intel(R) 915G";
         break;
      case PCI_CHIP_E7221_G:
	 chipset = "Intel (R) E7221G (i915)";
	 break;
      case PCI_CHIP_I915_GM:
         chipset = "Intel(R) 915GM";
         break;
      case PCI_CHIP_I945_G:
         chipset = "Intel(R) 945G";
         break;
      case PCI_CHIP_I945_GM:
         chipset = "Intel(R) 945GM";
         break;
      case PCI_CHIP_I945_GME:
         chipset = "Intel(R) 945GME";
         break;
      case PCI_CHIP_G33_G:
	 chipset = "Intel(R) G33";
	 break;
      case PCI_CHIP_Q35_G:
	 chipset = "Intel(R) Q35";
	 break;
      case PCI_CHIP_Q33_G:
	 chipset = "Intel(R) Q33";
	 break;
      case PCI_CHIP_IGD_GM:
      case PCI_CHIP_IGD_G:
	 chipset = "Intel(R) IGD";
	 break;
      case PCI_CHIP_I965_Q:
	 chipset = "Intel(R) 965Q";
	 break;
      case PCI_CHIP_I965_G:
      case PCI_CHIP_I965_G_1:
	 chipset = "Intel(R) 965G";
	 break;
      case PCI_CHIP_I946_GZ:
	 chipset = "Intel(R) 946GZ";
	 break;
      case PCI_CHIP_I965_GM:
	 chipset = "Intel(R) 965GM";
	 break;
      case PCI_CHIP_I965_GME:
	 chipset = "Intel(R) 965GME/GLE";
	 break;
      case PCI_CHIP_GM45_GM:
	 chipset = "Mobile IntelÂ® GM45 Express Chipset";
	 break; 
      case PCI_CHIP_IGD_E_G:
	 chipset = "Intel(R) Integrated Graphics Device";
	 break;
      case PCI_CHIP_G45_G:
         chipset = "Intel(R) G45/G43";
         break;
      case PCI_CHIP_Q45_G:
         chipset = "Intel(R) Q45/Q43";
         break;
      case PCI_CHIP_G41_G:
         chipset = "Intel(R) G41";
         break;
      case PCI_CHIP_B43_G:
      case PCI_CHIP_B43_G1:
         chipset = "Intel(R) B43";
         break;
      case PCI_CHIP_ILD_G:
         chipset = "Intel(R) Ironlake Desktop";
         break;
      case PCI_CHIP_ILM_G:
         chipset = "Intel(R) Ironlake Mobile";
         break;
      case PCI_CHIP_SANDYBRIDGE_GT1:
      case PCI_CHIP_SANDYBRIDGE_GT2:
      case PCI_CHIP_SANDYBRIDGE_GT2_PLUS:
	 chipset = "Intel(R) Sandybridge Desktop";
	 break;
      case PCI_CHIP_SANDYBRIDGE_M_GT1:
      case PCI_CHIP_SANDYBRIDGE_M_GT2:
      case PCI_CHIP_SANDYBRIDGE_M_GT2_PLUS:
	 chipset = "Intel(R) Sandybridge Mobile";
	 break;
      case PCI_CHIP_SANDYBRIDGE_S:
	 chipset = "Intel(R) Sandybridge Server";
	 break;
      case PCI_CHIP_IVYBRIDGE_GT1:
      case PCI_CHIP_IVYBRIDGE_GT2:
	 chipset = "Intel(R) Ivybridge Desktop";
	 break;
      case PCI_CHIP_IVYBRIDGE_M_GT1:
      case PCI_CHIP_IVYBRIDGE_M_GT2:
	 chipset = "Intel(R) Ivybridge Mobile";
	 break;
      case PCI_CHIP_IVYBRIDGE_S_GT1:
	 chipset = "Intel(R) Ivybridge Server";
	 break;
      default:
         chipset = "Unknown Intel Chipset";
         break;
      }

      (void) driGetRendererString(buffer, chipset, 0);
      return (GLubyte *) buffer;

   default:
      return NULL;
   }
}

static void
intel_flush_front(struct gl_context *ctx)
{
   struct intel_context *intel = intel_context(ctx);
    __DRIcontext *driContext = intel->driContext;
    __DRIscreen *const screen = intel->intelScreen->driScrnPriv;

   if ((ctx->DrawBuffer->Name == 0) && intel->front_buffer_dirty) {
      if (screen->dri2.loader &&
          (screen->dri2.loader->base.version >= 2)
	  && (screen->dri2.loader->flushFrontBuffer != NULL) &&
          driContext->driDrawablePriv &&
	  driContext->driDrawablePriv->loaderPrivate) {
	 (*screen->dri2.loader->flushFrontBuffer)(driContext->driDrawablePriv,
						  driContext->driDrawablePriv->loaderPrivate);

	 /* We set the dirty bit in intel_prepare_render() if we're
	  * front buffer rendering once we get there.
	  */
	 intel->front_buffer_dirty = GL_FALSE;
      }
   }
}

static unsigned
intel_bits_per_pixel(const struct intel_renderbuffer *rb)
{
   return _mesa_get_format_bytes(rb->Base.Format) * 8;
}

static void
intel_query_dri2_buffers_no_separate_stencil(struct intel_context *intel,
					     __DRIdrawable *drawable,
					     __DRIbuffer **buffers,
					     int *count);

static void
intel_process_dri2_buffer_no_separate_stencil(struct intel_context *intel,
					      __DRIdrawable *drawable,
					      __DRIbuffer *buffer,
					      struct intel_renderbuffer *rb,
					      const char *buffer_name);

static void
intel_query_dri2_buffers_with_separate_stencil(struct intel_context *intel,
					       __DRIdrawable *drawable,
					       __DRIbuffer **buffers,
					       unsigned **attachments,
					       int *count);

static void
intel_process_dri2_buffer_with_separate_stencil(struct intel_context *intel,
						__DRIdrawable *drawable,
						__DRIbuffer *buffer,
						struct intel_renderbuffer *rb,
						const char *buffer_name);
static void
intel_verify_dri2_has_hiz(struct intel_context *intel,
			  __DRIdrawable *drawable,
			  __DRIbuffer **buffers,
			  unsigned **attachments,
			  int *count);

void
intel_update_renderbuffers(__DRIcontext *context, __DRIdrawable *drawable)
{
   struct gl_framebuffer *fb = drawable->driverPrivate;
   struct intel_renderbuffer *rb;
   struct intel_context *intel = context->driverPrivate;
   __DRIbuffer *buffers = NULL;
   unsigned *attachments = NULL;
   int i, count;
   const char *region_name;

   bool try_separate_stencil =
      intel->has_separate_stencil &&
      intel->intelScreen->dri2_has_hiz != INTEL_DRI2_HAS_HIZ_FALSE &&
      intel->intelScreen->driScrnPriv->dri2.loader != NULL &&
      intel->intelScreen->driScrnPriv->dri2.loader->base.version > 2 &&
      intel->intelScreen->driScrnPriv->dri2.loader->getBuffersWithFormat != NULL;

   assert(!intel->must_use_separate_stencil || try_separate_stencil);

   /* If we're rendering to the fake front buffer, make sure all the
    * pending drawing has landed on the real front buffer.  Otherwise
    * when we eventually get to DRI2GetBuffersWithFormat the stale
    * real front buffer contents will get copied to the new fake front
    * buffer.
    */
   if (intel->is_front_buffer_rendering) {
      intel_flush(&intel->ctx);
      intel_flush_front(&intel->ctx);
   }

   /* Set this up front, so that in case our buffers get invalidated
    * while we're getting new buffers, we don't clobber the stamp and
    * thus ignore the invalidate. */
   drawable->lastStamp = drawable->dri2.stamp;

   if (unlikely(INTEL_DEBUG & DEBUG_DRI))
      fprintf(stderr, "enter %s, drawable %p\n", __func__, drawable);

   if (try_separate_stencil) {
      intel_query_dri2_buffers_with_separate_stencil(intel, drawable, &buffers,
						     &attachments, &count);
   } else {
      intel_query_dri2_buffers_no_separate_stencil(intel, drawable, &buffers,
						   &count);
   }

   if (buffers == NULL)
      return;

   drawable->x = 0;
   drawable->y = 0;
   drawable->backX = 0;
   drawable->backY = 0;
   drawable->numClipRects = 1;
   drawable->pClipRects[0].x1 = 0;
   drawable->pClipRects[0].y1 = 0;
   drawable->pClipRects[0].x2 = drawable->w;
   drawable->pClipRects[0].y2 = drawable->h;
   drawable->numBackClipRects = 1;
   drawable->pBackClipRects[0].x1 = 0;
   drawable->pBackClipRects[0].y1 = 0;
   drawable->pBackClipRects[0].x2 = drawable->w;
   drawable->pBackClipRects[0].y2 = drawable->h;

   for (i = 0; i < count; i++) {
       switch (buffers[i].attachment) {
       case __DRI_BUFFER_FRONT_LEFT:
	   rb = intel_get_renderbuffer(fb, BUFFER_FRONT_LEFT);
	   region_name = "dri2 front buffer";
	   break;

       case __DRI_BUFFER_FAKE_FRONT_LEFT:
	   rb = intel_get_renderbuffer(fb, BUFFER_FRONT_LEFT);
	   region_name = "dri2 fake front buffer";
	   break;

       case __DRI_BUFFER_BACK_LEFT:
	   rb = intel_get_renderbuffer(fb, BUFFER_BACK_LEFT);
	   region_name = "dri2 back buffer";
	   break;

       case __DRI_BUFFER_DEPTH:
	   rb = intel_get_renderbuffer(fb, BUFFER_DEPTH);
	   region_name = "dri2 depth buffer";
	   break;

       case __DRI_BUFFER_HIZ:
	   /* The hiz region resides in the depth renderbuffer. */
	   rb = intel_get_renderbuffer(fb, BUFFER_DEPTH);
	   region_name = "dri2 hiz buffer";
	   break;

       case __DRI_BUFFER_DEPTH_STENCIL:
	   rb = intel_get_renderbuffer(fb, BUFFER_DEPTH);
	   region_name = "dri2 depth / stencil buffer";
	   break;

       case __DRI_BUFFER_STENCIL:
	   rb = intel_get_renderbuffer(fb, BUFFER_STENCIL);
	   region_name = "dri2 stencil buffer";
	   break;

       case __DRI_BUFFER_ACCUM:
       default:
	   fprintf(stderr,
		   "unhandled buffer attach event, attachment type %d\n",
		   buffers[i].attachment);
	   return;
       }

       if (try_separate_stencil) {
	 intel_process_dri2_buffer_with_separate_stencil(intel, drawable,
						         &buffers[i], rb,
						         region_name);
       } else {
	 intel_process_dri2_buffer_no_separate_stencil(intel, drawable,
						       &buffers[i], rb,
						       region_name);
       }
   }

   if (try_separate_stencil
       && intel->intelScreen->dri2_has_hiz == INTEL_DRI2_HAS_HIZ_UNKNOWN) {
      intel_verify_dri2_has_hiz(intel, drawable, &buffers, &attachments,
				&count);
   }

   if (attachments)
      free(attachments);

   driUpdateFramebufferSize(&intel->ctx, drawable);
}

/**
 * intel_prepare_render should be called anywhere that curent read/drawbuffer
 * state is required.
 */
void
intel_prepare_render(struct intel_context *intel)
{
   __DRIcontext *driContext = intel->driContext;
   __DRIdrawable *drawable;

   drawable = driContext->driDrawablePriv;
   if (drawable && drawable->dri2.stamp != driContext->dri2.draw_stamp) {
      if (drawable->lastStamp != drawable->dri2.stamp)
	 intel_update_renderbuffers(driContext, drawable);
      intel_draw_buffer(&intel->ctx, intel->ctx.DrawBuffer);
      driContext->dri2.draw_stamp = drawable->dri2.stamp;
   }

   drawable = driContext->driReadablePriv;
   if (drawable && drawable->dri2.stamp != driContext->dri2.read_stamp) {
      if (drawable->lastStamp != drawable->dri2.stamp)
	 intel_update_renderbuffers(driContext, drawable);
      driContext->dri2.read_stamp = drawable->dri2.stamp;
   }

   /* If we're currently rendering to the front buffer, the rendering
    * that will happen next will probably dirty the front buffer.  So
    * mark it as dirty here.
    */
   if (intel->is_front_buffer_rendering)
      intel->front_buffer_dirty = GL_TRUE;

   /* Wait for the swapbuffers before the one we just emitted, so we
    * don't get too many swaps outstanding for apps that are GPU-heavy
    * but not CPU-heavy.
    *
    * We're using intelDRI2Flush (called from the loader before
    * swapbuffer) and glFlush (for front buffer rendering) as the
    * indicator that a frame is done and then throttle when we get
    * here as we prepare to render the next frame.  At this point for
    * round trips for swap/copy and getting new buffers are done and
    * we'll spend less time waiting on the GPU.
    *
    * Unfortunately, we don't have a handle to the batch containing
    * the swap, and getting our hands on that doesn't seem worth it,
    * so we just us the first batch we emitted after the last swap.
    */
   if (intel->need_throttle && intel->first_post_swapbuffers_batch) {
      drm_intel_bo_wait_rendering(intel->first_post_swapbuffers_batch);
      drm_intel_bo_unreference(intel->first_post_swapbuffers_batch);
      intel->first_post_swapbuffers_batch = NULL;
      intel->need_throttle = GL_FALSE;
   }
}

static void
intel_viewport(struct gl_context *ctx, GLint x, GLint y, GLsizei w, GLsizei h)
{
    struct intel_context *intel = intel_context(ctx);
    __DRIcontext *driContext = intel->driContext;

    if (intel->saved_viewport)
	intel->saved_viewport(ctx, x, y, w, h);

    if (ctx->DrawBuffer->Name == 0) {
       dri2InvalidateDrawable(driContext->driDrawablePriv);
       dri2InvalidateDrawable(driContext->driReadablePriv);
    }
}

static const struct dri_debug_control debug_control[] = {
   { "tex",   DEBUG_TEXTURE},
   { "state", DEBUG_STATE},
   { "ioctl", DEBUG_IOCTL},
   { "blit",  DEBUG_BLIT},
   { "mip",   DEBUG_MIPTREE},
   { "fall",  DEBUG_FALLBACKS},
   { "verb",  DEBUG_VERBOSE},
   { "bat",   DEBUG_BATCH},
   { "pix",   DEBUG_PIXEL},
   { "buf",   DEBUG_BUFMGR},
   { "reg",   DEBUG_REGION},
   { "fbo",   DEBUG_FBO},
   { "gs",    DEBUG_GS},
   { "sync",  DEBUG_SYNC},
   { "prim",  DEBUG_PRIMS },
   { "vert",  DEBUG_VERTS },
   { "dri",   DEBUG_DRI },
   { "sf",    DEBUG_SF },
   { "san",   DEBUG_SANITY },
   { "sleep", DEBUG_SLEEP },
   { "stats", DEBUG_STATS },
   { "tile",  DEBUG_TILE },
   { "sing",  DEBUG_SINGLE_THREAD },
   { "thre",  DEBUG_SINGLE_THREAD },
   { "wm",    DEBUG_WM },
   { "urb",   DEBUG_URB },
   { "vs",    DEBUG_VS },
   { "clip",  DEBUG_CLIP },
   { NULL,    0 }
};


static void
intelInvalidateState(struct gl_context * ctx, GLuint new_state)
{
    struct intel_context *intel = intel_context(ctx);

   _swrast_InvalidateState(ctx, new_state);
   _vbo_InvalidateState(ctx, new_state);

   intel->NewGLState |= new_state;

   if (intel->vtbl.invalidate_state)
      intel->vtbl.invalidate_state( intel, new_state );
}

void
intel_flush(struct gl_context *ctx)
{
   struct intel_context *intel = intel_context(ctx);

   if (intel->Fallback)
      _swrast_flush(ctx);

   if (intel->gen < 4)
      INTEL_FIREVERTICES(intel);

   if (intel->batch.used)
      intel_batchbuffer_flush(intel);
}

static void
intel_glFlush(struct gl_context *ctx)
{
   struct intel_context *intel = intel_context(ctx);

   intel_flush(ctx);
   intel_flush_front(ctx);
   if (intel->is_front_buffer_rendering)
      intel->need_throttle = GL_TRUE;
}

void
intelFinish(struct gl_context * ctx)
{
   struct intel_context *intel = intel_context(ctx);

   intel_flush(ctx);
   intel_flush_front(ctx);

   if (intel->batch.last_bo)
      drm_intel_bo_wait_rendering(intel->batch.last_bo);
}

void
intelInitDriverFunctions(struct dd_function_table *functions)
{
   _mesa_init_driver_functions(functions);

   functions->Flush = intel_glFlush;
   functions->Finish = intelFinish;
   functions->GetString = intelGetString;
   functions->UpdateState = intelInvalidateState;

   intelInitTextureFuncs(functions);
   intelInitTextureImageFuncs(functions);
   intelInitTextureSubImageFuncs(functions);
   intelInitTextureCopyImageFuncs(functions);
   intelInitStateFuncs(functions);
   intelInitClearFuncs(functions);
   intelInitBufferFuncs(functions);
   intelInitPixelFuncs(functions);
   intelInitBufferObjectFuncs(functions);
   intel_init_syncobj_functions(functions);
}

GLboolean
intelInitContext(struct intel_context *intel,
		 int api,
                 const struct gl_config * mesaVis,
                 __DRIcontext * driContextPriv,
                 void *sharedContextPrivate,
                 struct dd_function_table *functions)
{
   struct gl_context *ctx = &intel->ctx;
   struct gl_context *shareCtx = (struct gl_context *) sharedContextPrivate;
   __DRIscreen *sPriv = driContextPriv->driScreenPriv;
   struct intel_screen *intelScreen = sPriv->private;
   int bo_reuse_mode;
   struct gl_config visual;

   /* we can't do anything without a connection to the device */
   if (intelScreen->bufmgr == NULL)
      return GL_FALSE;

   /* Can't rely on invalidate events, fall back to glViewport hack */
   if (!driContextPriv->driScreenPriv->dri2.useInvalidate) {
      intel->saved_viewport = functions->Viewport;
      functions->Viewport = intel_viewport;
   }

   if (mesaVis == NULL) {
      memset(&visual, 0, sizeof visual);
      mesaVis = &visual;
   }

   if (!_mesa_initialize_context(&intel->ctx, api, mesaVis, shareCtx,
                                 functions, (void *) intel)) {
      printf("%s: failed to init mesa context\n", __FUNCTION__);
      return GL_FALSE;
   }

   driContextPriv->driverPrivate = intel;
   intel->intelScreen = intelScreen;
   intel->driContext = driContextPriv;
   intel->driFd = sPriv->fd;

   intel->has_xrgb_textures = GL_TRUE;
   intel->gen = intelScreen->gen;
   if (IS_GEN7(intel->intelScreen->deviceID)) {
      intel->needs_ff_sync = GL_TRUE;
      intel->has_luminance_srgb = GL_TRUE;
   } else if (IS_GEN6(intel->intelScreen->deviceID)) {
      intel->needs_ff_sync = GL_TRUE;
      intel->has_luminance_srgb = GL_TRUE;
   } else if (IS_GEN5(intel->intelScreen->deviceID)) {
      intel->needs_ff_sync = GL_TRUE;
      intel->has_luminance_srgb = GL_TRUE;
   } else if (IS_965(intel->intelScreen->deviceID)) {
      if (IS_G4X(intel->intelScreen->deviceID)) {
	  intel->has_luminance_srgb = GL_TRUE;
	  intel->is_g4x = GL_TRUE;
      }
   } else if (IS_9XX(intel->intelScreen->deviceID)) {
      if (IS_945(intel->intelScreen->deviceID)) {
	 intel->is_945 = GL_TRUE;
      }
   } else {
      if (intel->intelScreen->deviceID == PCI_CHIP_I830_M ||
	  intel->intelScreen->deviceID == PCI_CHIP_845_G) {
	 intel->has_xrgb_textures = GL_FALSE;
      }
   }

   intel->has_separate_stencil = intel->intelScreen->hw_has_separate_stencil;
   intel->must_use_separate_stencil = intel->intelScreen->hw_must_use_separate_stencil;
   intel->has_hiz = intel->intelScreen->hw_has_hiz;

   memset(&ctx->TextureFormatSupported, 0,
	  sizeof(ctx->TextureFormatSupported));
   ctx->TextureFormatSupported[MESA_FORMAT_ARGB8888] = GL_TRUE;
   if (intel->has_xrgb_textures)
      ctx->TextureFormatSupported[MESA_FORMAT_XRGB8888] = GL_TRUE;
   ctx->TextureFormatSupported[MESA_FORMAT_ARGB4444] = GL_TRUE;
   ctx->TextureFormatSupported[MESA_FORMAT_ARGB1555] = GL_TRUE;
   ctx->TextureFormatSupported[MESA_FORMAT_RGB565] = GL_TRUE;
   ctx->TextureFormatSupported[MESA_FORMAT_L8] = GL_TRUE;
   ctx->TextureFormatSupported[MESA_FORMAT_A8] = GL_TRUE;
   ctx->TextureFormatSupported[MESA_FORMAT_I8] = GL_TRUE;
   ctx->TextureFormatSupported[MESA_FORMAT_AL88] = GL_TRUE;
   if (intel->gen >= 4)
      ctx->TextureFormatSupported[MESA_FORMAT_AL1616] = GL_TRUE;

   /* Depth and stencil */
   ctx->TextureFormatSupported[MESA_FORMAT_S8_Z24] = GL_TRUE;
   ctx->TextureFormatSupported[MESA_FORMAT_X8_Z24] = GL_TRUE;
   ctx->TextureFormatSupported[MESA_FORMAT_S8] = intel->has_separate_stencil;

   /*
    * This was disabled in initial FBO enabling to avoid combinations
    * of depth+stencil that wouldn't work together.  We since decided
    * that it was OK, since it's up to the app to come up with the
    * combo that actually works, so this can probably be re-enabled.
    */
   /*
   ctx->TextureFormatSupported[MESA_FORMAT_Z16] = GL_TRUE;
   ctx->TextureFormatSupported[MESA_FORMAT_Z24] = GL_TRUE;
   */

   /* ctx->Extensions.MESA_ycbcr_texture */
   ctx->TextureFormatSupported[MESA_FORMAT_YCBCR] = GL_TRUE;
   ctx->TextureFormatSupported[MESA_FORMAT_YCBCR_REV] = GL_TRUE;

   /* GL_3DFX_texture_compression_FXT1 */
   ctx->TextureFormatSupported[MESA_FORMAT_RGB_FXT1] = GL_TRUE;
   ctx->TextureFormatSupported[MESA_FORMAT_RGBA_FXT1] = GL_TRUE;

   /* GL_EXT_texture_compression_s3tc */
   ctx->TextureFormatSupported[MESA_FORMAT_RGB_DXT1] = GL_TRUE;
   ctx->TextureFormatSupported[MESA_FORMAT_RGBA_DXT1] = GL_TRUE;
   ctx->TextureFormatSupported[MESA_FORMAT_RGBA_DXT3] = GL_TRUE;
   ctx->TextureFormatSupported[MESA_FORMAT_RGBA_DXT5] = GL_TRUE;

#ifndef I915
   /* GL_ARB_texture_compression_rgtc */
   ctx->TextureFormatSupported[MESA_FORMAT_RED_RGTC1] = GL_TRUE;
   ctx->TextureFormatSupported[MESA_FORMAT_SIGNED_RED_RGTC1] = GL_TRUE;
   ctx->TextureFormatSupported[MESA_FORMAT_RG_RGTC2] = GL_TRUE;
   ctx->TextureFormatSupported[MESA_FORMAT_SIGNED_RG_RGTC2] = GL_TRUE;

   /* GL_ARB_texture_rg */
   ctx->TextureFormatSupported[MESA_FORMAT_R8] = GL_TRUE;
   ctx->TextureFormatSupported[MESA_FORMAT_R16] = GL_TRUE;
   ctx->TextureFormatSupported[MESA_FORMAT_RG88] = GL_TRUE;
   ctx->TextureFormatSupported[MESA_FORMAT_RG1616] = GL_TRUE;

   /* GL_MESA_texture_signed_rgba / GL_EXT_texture_snorm */
   ctx->TextureFormatSupported[MESA_FORMAT_DUDV8] = GL_TRUE;
   ctx->TextureFormatSupported[MESA_FORMAT_SIGNED_RGBA8888_REV] = GL_TRUE;
   ctx->TextureFormatSupported[MESA_FORMAT_SIGNED_R8] = GL_TRUE;
   ctx->TextureFormatSupported[MESA_FORMAT_SIGNED_RG88_REV] = GL_TRUE;
   ctx->TextureFormatSupported[MESA_FORMAT_SIGNED_R16] = GL_TRUE;
   ctx->TextureFormatSupported[MESA_FORMAT_SIGNED_GR1616] = GL_TRUE;

   /* GL_EXT_texture_sRGB */
   ctx->TextureFormatSupported[MESA_FORMAT_SARGB8] = GL_TRUE;
   if (intel->gen >= 5 || intel->is_g4x)
      ctx->TextureFormatSupported[MESA_FORMAT_SRGB_DXT1] = GL_TRUE;
   ctx->TextureFormatSupported[MESA_FORMAT_SRGBA_DXT1] = GL_TRUE;
   ctx->TextureFormatSupported[MESA_FORMAT_SRGBA_DXT3] = GL_TRUE;
   ctx->TextureFormatSupported[MESA_FORMAT_SRGBA_DXT5] = GL_TRUE;
   if (intel->has_luminance_srgb) {
      ctx->TextureFormatSupported[MESA_FORMAT_SL8] = GL_TRUE;
      ctx->TextureFormatSupported[MESA_FORMAT_SLA8] = GL_TRUE;
   }

#ifdef TEXTURE_FLOAT_ENABLED
   ctx->TextureFormatSupported[MESA_FORMAT_RGBA_FLOAT32] = GL_TRUE;
   ctx->TextureFormatSupported[MESA_FORMAT_RG_FLOAT32] = GL_TRUE;
   ctx->TextureFormatSupported[MESA_FORMAT_R_FLOAT32] = GL_TRUE;
   ctx->TextureFormatSupported[MESA_FORMAT_INTENSITY_FLOAT32] = GL_TRUE;
   ctx->TextureFormatSupported[MESA_FORMAT_LUMINANCE_FLOAT32] = GL_TRUE;
   ctx->TextureFormatSupported[MESA_FORMAT_ALPHA_FLOAT32] = GL_TRUE;
   ctx->TextureFormatSupported[MESA_FORMAT_LUMINANCE_ALPHA_FLOAT32] = GL_TRUE;
#endif

#endif /* !I915 */

   driParseConfigFiles(&intel->optionCache, &intelScreen->optionCache,
                       sPriv->myNum, (intel->gen >= 4) ? "i965" : "i915");
   if (intel->gen < 4)
      intel->maxBatchSize = 4096;
   else
      intel->maxBatchSize = sizeof(intel->batch.map);

   intel->bufmgr = intelScreen->bufmgr;

   bo_reuse_mode = driQueryOptioni(&intel->optionCache, "bo_reuse");
   switch (bo_reuse_mode) {
   case DRI_CONF_BO_REUSE_DISABLED:
      break;
   case DRI_CONF_BO_REUSE_ALL:
      intel_bufmgr_gem_enable_reuse(intel->bufmgr);
      break;
   }

   /* This doesn't yet catch all non-conformant rendering, but it's a
    * start.
    */
   if (getenv("INTEL_STRICT_CONFORMANCE")) {
      unsigned int value = atoi(getenv("INTEL_STRICT_CONFORMANCE"));
      if (value > 0) {
         intel->conformance_mode = value;
      }
      else {
         intel->conformance_mode = 1;
      }
   }

   if (intel->conformance_mode > 0) {
      ctx->Const.MinLineWidth = 1.0;
      ctx->Const.MinLineWidthAA = 1.0;
      ctx->Const.MaxLineWidth = 1.0;
      ctx->Const.MaxLineWidthAA = 1.0;
      ctx->Const.LineWidthGranularity = 1.0;
   }
   else {
      ctx->Const.MinLineWidth = 1.0;
      ctx->Const.MinLineWidthAA = 1.0;
      ctx->Const.MaxLineWidth = 5.0;
      ctx->Const.MaxLineWidthAA = 5.0;
      ctx->Const.LineWidthGranularity = 0.5;
   }

   ctx->Const.MinPointSize = 1.0;
   ctx->Const.MinPointSizeAA = 1.0;
   ctx->Const.MaxPointSize = 255.0;
   ctx->Const.MaxPointSizeAA = 3.0;
   ctx->Const.PointSizeGranularity = 1.0;

   ctx->Const.MaxSamples = 1.0;

   /* reinitialize the context point state.
    * It depend on constants in __struct gl_contextRec::Const
    */
   _mesa_init_point(ctx);

   if (intel->gen >= 4) {
      ctx->Const.sRGBCapable = GL_TRUE;
      if (MAX_WIDTH > 8192)
	 ctx->Const.MaxRenderbufferSize = 8192;
   } else {
      if (MAX_WIDTH > 2048)
	 ctx->Const.MaxRenderbufferSize = 2048;
   }

   /* Initialize the software rasterizer and helper modules. */
   _swrast_CreateContext(ctx);
   _vbo_CreateContext(ctx);
   _tnl_CreateContext(ctx);
   _swsetup_CreateContext(ctx);
 
   /* Configure swrast to match hardware characteristics: */
   _swrast_allow_pixel_fog(ctx, GL_FALSE);
   _swrast_allow_vertex_fog(ctx, GL_TRUE);

   _mesa_meta_init(ctx);

   intel->hw_stencil = mesaVis->stencilBits && mesaVis->depthBits == 24;
   intel->hw_stipple = 1;

   /* XXX FBO: this doesn't seem to be used anywhere */
   switch (mesaVis->depthBits) {
   case 0:                     /* what to do in this case? */
   case 16:
      intel->polygon_offset_scale = 1.0;
      break;
   case 24:
      intel->polygon_offset_scale = 2.0;     /* req'd to pass glean */
      break;
   default:
      assert(0);
      break;
   }

   if (intel->gen >= 4)
      intel->polygon_offset_scale /= 0xffff;

   intel->RenderIndex = ~0;

   switch (ctx->API) {
   case API_OPENGL:
      intelInitExtensions(ctx);
      break;
   case API_OPENGLES:
      intelInitExtensionsES1(ctx);
      break;
   case API_OPENGLES2:
      intelInitExtensionsES2(ctx);
      break;
   }

   INTEL_DEBUG = driParseDebugString(getenv("INTEL_DEBUG"), debug_control);
   if (INTEL_DEBUG & DEBUG_BUFMGR)
      dri_bufmgr_set_debug(intel->bufmgr, GL_TRUE);

   intel_batchbuffer_init(intel);

   intel_fbo_init(intel);

   if (intel->ctx.Mesa_DXTn) {
      _mesa_enable_extension(ctx, "GL_EXT_texture_compression_s3tc");
      _mesa_enable_extension(ctx, "GL_S3_s3tc");
   }
   else if (driQueryOptionb(&intel->optionCache, "force_s3tc_enable")) {
      _mesa_enable_extension(ctx, "GL_EXT_texture_compression_s3tc");
   }
   intel->use_texture_tiling = driQueryOptionb(&intel->optionCache,
					       "texture_tiling");
   intel->use_early_z = driQueryOptionb(&intel->optionCache, "early_z");

   intel->prim.primitive = ~0;

   /* Force all software fallbacks */
   if (driQueryOptionb(&intel->optionCache, "no_rast")) {
      fprintf(stderr, "disabling 3D rasterization\n");
      intel->no_rast = 1;
   }

   if (driQueryOptionb(&intel->optionCache, "always_flush_batch")) {
      fprintf(stderr, "flushing batchbuffer before/after each draw call\n");
      intel->always_flush_batch = 1;
   }

   if (driQueryOptionb(&intel->optionCache, "always_flush_cache")) {
      fprintf(stderr, "flushing GPU caches before/after each draw call\n");
      intel->always_flush_cache = 1;
   }

   return GL_TRUE;
}

void
intelDestroyContext(__DRIcontext * driContextPriv)
{
   struct intel_context *intel =
      (struct intel_context *) driContextPriv->driverPrivate;

   assert(intel);               /* should never be null */
   if (intel) {
      INTEL_FIREVERTICES(intel);

      _mesa_meta_free(&intel->ctx);

      intel->vtbl.destroy(intel);

      _swsetup_DestroyContext(&intel->ctx);
      _tnl_DestroyContext(&intel->ctx);
      _vbo_DestroyContext(&intel->ctx);

      _swrast_DestroyContext(&intel->ctx);
      intel->Fallback = 0x0;      /* don't call _swrast_Flush later */

      intel_batchbuffer_free(intel);

      free(intel->prim.vb);
      intel->prim.vb = NULL;
      drm_intel_bo_unreference(intel->prim.vb_bo);
      intel->prim.vb_bo = NULL;
      drm_intel_bo_unreference(intel->first_post_swapbuffers_batch);
      intel->first_post_swapbuffers_batch = NULL;

      driDestroyOptionCache(&intel->optionCache);

      /* free the Mesa context */
      _mesa_free_context_data(&intel->ctx);

      FREE(intel);
      driContextPriv->driverPrivate = NULL;
   }
}

GLboolean
intelUnbindContext(__DRIcontext * driContextPriv)
{
   /* Unset current context and dispath table */
   _mesa_make_current(NULL, NULL, NULL);

   return GL_TRUE;
}

GLboolean
intelMakeCurrent(__DRIcontext * driContextPriv,
                 __DRIdrawable * driDrawPriv,
                 __DRIdrawable * driReadPriv)
{
   struct intel_context *intel;
   GET_CURRENT_CONTEXT(curCtx);

   if (driContextPriv)
      intel = (struct intel_context *) driContextPriv->driverPrivate;
   else
      intel = NULL;

   /* According to the glXMakeCurrent() man page: "Pending commands to
    * the previous context, if any, are flushed before it is released."
    * But only flush if we're actually changing contexts.
    */
   if (intel_context(curCtx) && intel_context(curCtx) != intel) {
      _mesa_flush(curCtx);
   }

   if (driContextPriv) {
      struct gl_framebuffer *fb, *readFb;
      
      if (driDrawPriv == NULL && driReadPriv == NULL) {
	 fb = _mesa_get_incomplete_framebuffer();
	 readFb = _mesa_get_incomplete_framebuffer();
      } else {
	 fb = driDrawPriv->driverPrivate;
	 readFb = driReadPriv->driverPrivate;
	 driContextPriv->dri2.draw_stamp = driDrawPriv->dri2.stamp - 1;
	 driContextPriv->dri2.read_stamp = driReadPriv->dri2.stamp - 1;
      }

      intel_prepare_render(intel);
      _mesa_make_current(&intel->ctx, fb, readFb);
      
      /* We do this in intel_prepare_render() too, but intel->ctx.DrawBuffer
       * is NULL at that point.  We can't call _mesa_makecurrent()
       * first, since we need the buffer size for the initial
       * viewport.  So just call intel_draw_buffer() again here. */
      intel_draw_buffer(&intel->ctx, intel->ctx.DrawBuffer);
   }
   else {
      _mesa_make_current(NULL, NULL, NULL);
   }

   return GL_TRUE;
}

/**
 * \brief Query DRI2 to obtain a DRIdrawable's buffers.
 *
 * To determine which DRI buffers to request, examine the renderbuffers
 * attached to the drawable's framebuffer. Then request the buffers with
 * DRI2GetBuffers() or DRI2GetBuffersWithFormat().
 *
 * This is called from intel_update_renderbuffers(). It is used only if either
 * the hardware or the X driver lacks separate stencil support.
 *
 * \param drawable      Drawable whose buffers are queried.
 * \param buffers       [out] List of buffers returned by DRI2 query.
 * \param buffer_count  [out] Number of buffers returned.
 *
 * \see intel_update_renderbuffers()
 * \see DRI2GetBuffers()
 * \see DRI2GetBuffersWithFormat()
 */
static void
intel_query_dri2_buffers_no_separate_stencil(struct intel_context *intel,
					     __DRIdrawable *drawable,
					     __DRIbuffer **buffers,
					     int *buffer_count)
{
   assert(!intel->must_use_separate_stencil);

   __DRIscreen *screen = intel->intelScreen->driScrnPriv;
   struct gl_framebuffer *fb = drawable->driverPrivate;

   if (screen->dri2.loader
       && screen->dri2.loader->base.version > 2
       && screen->dri2.loader->getBuffersWithFormat != NULL) {

      int i = 0;
      const int max_attachments = 4;
      unsigned *attachments = calloc(2 * max_attachments, sizeof(unsigned));

      struct intel_renderbuffer *front_rb;
      struct intel_renderbuffer *back_rb;
      struct intel_renderbuffer *depth_rb;
      struct intel_renderbuffer *stencil_rb;

      front_rb = intel_get_renderbuffer(fb, BUFFER_FRONT_LEFT);
      back_rb = intel_get_renderbuffer(fb, BUFFER_BACK_LEFT);
      depth_rb = intel_get_renderbuffer(fb, BUFFER_DEPTH);
      stencil_rb = intel_get_renderbuffer(fb, BUFFER_STENCIL);

      if ((intel->is_front_buffer_rendering ||
	   intel->is_front_buffer_reading ||
	   !back_rb) && front_rb) {
	 attachments[i++] = __DRI_BUFFER_FRONT_LEFT;
	 attachments[i++] = intel_bits_per_pixel(front_rb);
      }

      if (back_rb) {
	 attachments[i++] = __DRI_BUFFER_BACK_LEFT;
	 attachments[i++] = intel_bits_per_pixel(back_rb);
      }

      if (depth_rb && stencil_rb) {
	 attachments[i++] = __DRI_BUFFER_DEPTH_STENCIL;
	 attachments[i++] = intel_bits_per_pixel(depth_rb);
      } else if (depth_rb) {
	 attachments[i++] = __DRI_BUFFER_DEPTH;
	 attachments[i++] = intel_bits_per_pixel(depth_rb);
      } else if (stencil_rb) {
	 attachments[i++] = __DRI_BUFFER_STENCIL;
	 attachments[i++] = intel_bits_per_pixel(stencil_rb);
      }

      assert(i <= 2 * max_attachments);

      *buffers = screen->dri2.loader->getBuffersWithFormat(drawable,
							   &drawable->w,
							   &drawable->h,
							   attachments, i / 2,
							   buffer_count,
							   drawable->loaderPrivate);
      free(attachments);

   } else if (screen->dri2.loader) {

      int i = 0;
      const int max_attachments = 4;
      unsigned *attachments = calloc(max_attachments, sizeof(unsigned));

      if (intel_get_renderbuffer(fb, BUFFER_FRONT_LEFT))
	 attachments[i++] = __DRI_BUFFER_FRONT_LEFT;
      if (intel_get_renderbuffer(fb, BUFFER_BACK_LEFT))
	 attachments[i++] = __DRI_BUFFER_BACK_LEFT;
      if (intel_get_renderbuffer(fb, BUFFER_DEPTH))
	 attachments[i++] = __DRI_BUFFER_DEPTH;
      if (intel_get_renderbuffer(fb, BUFFER_STENCIL))
	 attachments[i++] = __DRI_BUFFER_STENCIL;

      assert(i <= max_attachments);

      *buffers = screen->dri2.loader->getBuffersWithFormat(drawable,
							   &drawable->w,
							   &drawable->h,
							   attachments, i,
							   buffer_count,
							   drawable->loaderPrivate);
      free(attachments);

   } else {
      *buffers = NULL;
      *buffer_count = 0;
   }
}

/**
 * \brief Assign a DRI buffer's DRM region to a renderbuffer.
 *
 * This is called from intel_update_renderbuffers().  It is used only if
 * either the hardware or the X driver lacks separate stencil support.
 *
 * \par Note:
 *    DRI buffers whose attachment point is DRI2BufferStencil or
 *    DRI2BufferDepthStencil are handled as special cases.
 *
 * \param buffer_name is a human readable name, such as "dri2 front buffer",
 *        that is passed to intel_region_alloc_for_handle().
 *
 * \see intel_update_renderbuffers()
 * \see intel_region_alloc_for_handle()
 * \see intel_renderbuffer_set_region()
 */
static void
intel_process_dri2_buffer_no_separate_stencil(struct intel_context *intel,
					      __DRIdrawable *drawable,
					      __DRIbuffer *buffer,
					      struct intel_renderbuffer *rb,
					      const char *buffer_name)
{
   assert(!intel->must_use_separate_stencil);

   struct gl_framebuffer *fb = drawable->driverPrivate;
   struct intel_region *region = NULL;
   struct intel_renderbuffer *depth_rb = NULL;

   if (!rb)
      return;

   if (rb->region && rb->region->name == buffer->name)
      return;

   if (unlikely(INTEL_DEBUG & DEBUG_DRI)) {
      fprintf(stderr,
	      "attaching buffer %d, at %d, cpp %d, pitch %d\n",
	      buffer->name, buffer->attachment,
	      buffer->cpp, buffer->pitch);
   }

   bool identify_depth_and_stencil = false;
   if (buffer->attachment == __DRI_BUFFER_STENCIL) {
      struct intel_renderbuffer *depth_rb =
	 intel_get_renderbuffer(fb, BUFFER_DEPTH);
      identify_depth_and_stencil = depth_rb && depth_rb->region;
   }

   if (identify_depth_and_stencil) {
      if (unlikely(INTEL_DEBUG & DEBUG_DRI)) {
	 fprintf(stderr, "(reusing depth buffer as stencil)\n");
      }
      intel_region_reference(&region, depth_rb->region);
   } else {
      region = intel_region_alloc_for_handle(intel->intelScreen,
					     buffer->cpp,
					     drawable->w,
					     drawable->h,
					     buffer->pitch / buffer->cpp,
					     buffer->name,
					     buffer_name);
   }

   intel_renderbuffer_set_region(intel, rb, region);
   intel_region_release(&region);

   if (buffer->attachment == __DRI_BUFFER_DEPTH_STENCIL) {
      struct intel_renderbuffer *stencil_rb =
	 intel_get_renderbuffer(fb, BUFFER_STENCIL);

      if (!stencil_rb)
	 return;

      if (stencil_rb->region && stencil_rb->region->name == buffer->name)
	 return;

      intel_renderbuffer_set_region(intel, stencil_rb, region);
   }
}

/**
 * \brief Query DRI2 to obtain a DRIdrawable's buffers.
 *
 * To determine which DRI buffers to request, examine the renderbuffers
 * attached to the drawable's framebuffer. Then request the buffers with
 * DRI2GetBuffersWithFormat().
 *
 * This is called from intel_update_renderbuffers(). It is used when 1) the
 * hardware supports separate stencil and 2) the X driver's separate stencil
 * support has been verified to work or is still unknown.
 *
 * \param drawable      Drawable whose buffers are queried.
 * \param buffers       [out] List of buffers returned by DRI2 query.
 * \param buffer_count  [out] Number of buffers returned.
 * \param attachments   [out] List of pairs (attachment_point, bits_per_pixel)
 *                      that were submitted in the DRI2 query. Number of pairs
 *                      is same as buffer_count.
 *
 * \see intel_update_renderbuffers()
 * \see DRI2GetBuffersWithFormat()
 * \see enum intel_dri2_has_hiz
 */
static void
intel_query_dri2_buffers_with_separate_stencil(struct intel_context *intel,
					       __DRIdrawable *drawable,
					       __DRIbuffer **buffers,
					       unsigned **attachments,
					       int *count)
{
   assert(intel->has_separate_stencil);

   __DRIscreen *screen = intel->intelScreen->driScrnPriv;
   struct gl_framebuffer *fb = drawable->driverPrivate;

   const int max_attachments = 5;
   int i = 0;

   *attachments = calloc(2 * max_attachments, sizeof(unsigned));
   if (!*attachments) {
      *buffers = NULL;
      *count = 0;
      return;
   }

   struct intel_renderbuffer *front_rb;
   struct intel_renderbuffer *back_rb;
   struct intel_renderbuffer *depth_rb;
   struct intel_renderbuffer *stencil_rb;

   front_rb = intel_get_renderbuffer(fb, BUFFER_FRONT_LEFT);
   back_rb = intel_get_renderbuffer(fb, BUFFER_BACK_LEFT);
   depth_rb = intel_get_renderbuffer(fb, BUFFER_DEPTH);
   stencil_rb = intel_get_renderbuffer(fb, BUFFER_STENCIL);

   if ((intel->is_front_buffer_rendering ||
	intel->is_front_buffer_reading ||
	!back_rb) && front_rb) {
      (*attachments)[i++] = __DRI_BUFFER_FRONT_LEFT;
      (*attachments)[i++] = intel_bits_per_pixel(front_rb);
   }

   if (back_rb) {
      (*attachments)[i++] = __DRI_BUFFER_BACK_LEFT;
      (*attachments)[i++] = intel_bits_per_pixel(back_rb);
   }

   /*
    * We request a separate stencil buffer, and perhaps a hiz buffer too, even
    * if we do not yet know if the X driver supports it. See the comments for
    * 'enum intel_dri2_has_hiz'.
    */

   if (depth_rb) {
      (*attachments)[i++] = __DRI_BUFFER_DEPTH;
      (*attachments)[i++] = intel_bits_per_pixel(depth_rb);

      if (intel->vtbl.is_hiz_depth_format(intel, depth_rb->Base.Format)) {
	 /* Depth and hiz buffer have same bpp. */
	 (*attachments)[i++] = __DRI_BUFFER_HIZ;
	 (*attachments)[i++] = intel_bits_per_pixel(depth_rb);
      }
   }

   if (stencil_rb) {
      assert(stencil_rb->Base.Format == MESA_FORMAT_S8);
      (*attachments)[i++] = __DRI_BUFFER_STENCIL;
      (*attachments)[i++] = intel_bits_per_pixel(stencil_rb);
   }

   assert(i <= 2 * max_attachments);

   *buffers = screen->dri2.loader->getBuffersWithFormat(drawable,
							&drawable->w,
							&drawable->h,
							*attachments, i / 2,
							count,
							drawable->loaderPrivate);

   if (!*buffers) {
      free(*attachments);
      *attachments = NULL;
      *count = 0;
   }
}

/**
 * \brief Assign a DRI buffer's DRM region to a renderbuffer.
 *
 * This is called from intel_update_renderbuffers().  It is used when 1) the
 * hardware supports separate stencil and 2) the X driver's separate stencil
 * support has been verified to work or is still unknown.
 *
 * \par Note:
 *    DRI buffers whose attachment point is DRI2BufferStencil or DRI2BufferHiz
 *    are handled as special cases.
 *
 * \param buffer_name is a human readable name, such as "dri2 front buffer",
 *        that is passed to intel_region_alloc_for_handle().
 *
 * \see intel_update_renderbuffers()
 * \see intel_region_alloc_for_handle()
 * \see intel_renderbuffer_set_region()
 * \see enum intel_dri2_has_hiz
 */
static void
intel_process_dri2_buffer_with_separate_stencil(struct intel_context *intel,
						__DRIdrawable *drawable,
						__DRIbuffer *buffer,
						struct intel_renderbuffer *rb,
						const char *buffer_name)
{
   assert(intel->has_separate_stencil);
   assert(buffer->attachment != __DRI_BUFFER_DEPTH_STENCIL);

   if (!rb)
      return;

   /* If the renderbuffer's and DRIbuffer's regions match, then continue. */
   if ((buffer->attachment != __DRI_BUFFER_HIZ &&
	rb->region &&
	rb->region->name == buffer->name) ||
       (buffer->attachment == __DRI_BUFFER_HIZ &&
	rb->hiz_region &&
	rb->hiz_region->name == buffer->name)) {
      return;
   }

   if (unlikely(INTEL_DEBUG & DEBUG_DRI)) {
      fprintf(stderr,
	      "attaching buffer %d, at %d, cpp %d, pitch %d\n",
	      buffer->name, buffer->attachment,
	      buffer->cpp, buffer->pitch);
   }

   int buffer_width;
   int buffer_height;
   if (buffer->attachment == __DRI_BUFFER_STENCIL) {
      /* The stencil buffer has quirky pitch requirements.  From Section
       * 2.11.5.6.2.1 3DSTATE_STENCIL_BUFFER, field "Surface Pitch":
       *    The pitch must be set to 2x the value computed based on width, as
       *    the stencil buffer is stored with two rows interleaved.
       *
       * To satisfy the pitch requirement, the X driver allocated the region
       * with the following dimensions.
       */
       buffer_width = ALIGN(drawable->w, 64);
       buffer_height = ALIGN(ALIGN(drawable->h, 2) / 2, 64);
   } else {
       buffer_width = drawable->w;
       buffer_height = drawable->h;
   }

   struct intel_region *region =
      intel_region_alloc_for_handle(intel->intelScreen,
				    buffer->cpp,
				    buffer_width,
				    buffer_height,
				    buffer->pitch / buffer->cpp,
				    buffer->name,
				    buffer_name);

   if (buffer->attachment == __DRI_BUFFER_HIZ) {
      intel_renderbuffer_set_hiz_region(intel, rb, region);
   } else {
      intel_renderbuffer_set_region(intel, rb, region);
   }

   intel_region_release(&region);
}

/**
 * \brief Verify that the X driver supports hiz and separate stencil.
 *
 * This implements the cleanup stage of the handshake described in the
 * comments for 'enum intel_dri2_has_hiz'.
 *
 * This should be called from intel_update_renderbuffers() after 1) the
 * DRIdrawable has been queried for its buffers via DRI2GetBuffersWithFormat()
 * and 2) the DRM region of each returned DRIbuffer has been assigned to the
 * appropriate intel_renderbuffer. Furthermore, this should be called *only*
 * when 1) intel_update_renderbuffers() tried to used the X driver's separate
 * stencil functionality and 2) it has not yet been determined if the X driver
 * supports separate stencil.
 *
 * If we determine that the X driver does have support, then we set
 * intel_screen.dri2_has_hiz to true and return.
 *
 * If we determine that the X driver lacks support, and we requested
 * a DRI2BufferDepth and DRI2BufferStencil, then we must remedy the mistake by
 * taking the following actions:
 *    1. Discard the framebuffer's stencil and depth renderbuffers.
 *    2. Create a combined depth/stencil renderbuffer and attach
 *       it to the framebuffer's depth and stencil attachment points.
 *    3. Query the drawable for a new set of buffers, which consists of the
 *       originally requested set plus DRI2BufferDepthStencil.
 *    4. Assign the DRI2BufferDepthStencil's DRM region to the new
 *       depth/stencil renderbuffer.
 *
 * \pre intel->intelScreen->dri2_has_hiz == INTEL_DRI2_HAS_HIZ_UNKNOWN
 *
 * \param drawable      Drawable whose buffers were queried.
 *
 * \param buffers       [in/out] As input, the buffer list returned by the
 *                      original DRI2 query. As output, the current buffer
 *                      list, which may have been altered by a new DRI2 query.
 *
 * \param attachments   [in/out] As input, the attachment list submitted
 *                      in the original DRI2 query. As output, the attachment
 *                      list that was submitted in the DRI2 query that
 *                      obtained the current buffer list, as returned in the
 *                      output parameter \c buffers.  (Note: If no new query
 *                      was made, then the list remains unaltered).
 *
 * \param count         [out] Number of buffers in the current buffer list, as
 *                      returned in the output parameter \c buffers.
 *
 * \see enum intel_dri2_has_hiz
 * \see struct intel_screen::dri2_has_hiz
 * \see intel_update_renderbuffers
 */
static void
intel_verify_dri2_has_hiz(struct intel_context *intel,
			  __DRIdrawable *drawable,
			  __DRIbuffer **buffers,
			  unsigned **attachments,
			  int *count)
{
   assert(intel->intelScreen->dri2_has_hiz == INTEL_DRI2_HAS_HIZ_UNKNOWN);

   struct gl_framebuffer *fb = drawable->driverPrivate;
   struct intel_renderbuffer *stencil_rb =
      intel_get_renderbuffer(fb, BUFFER_STENCIL);

   if (stencil_rb) {
      /*
       * We requested a DRI2BufferStencil without knowing if the X driver
       * supports it. Now, check if X handled the request correctly and clean
       * up if it did not. (See comments for 'enum intel_dri2_has_hiz').
       */
      struct intel_renderbuffer *depth_rb =
	 intel_get_renderbuffer(fb, BUFFER_DEPTH);
      assert(stencil_rb->Base.Format == MESA_FORMAT_S8);
      assert(depth_rb && depth_rb->Base.Format == MESA_FORMAT_X8_Z24);

      if (stencil_rb->region->tiling == I915_TILING_NONE) {
	 /*
	  * The stencil buffer is actually W tiled. The region's tiling is
	  * I915_TILING_NONE, however, because the GTT is incapable of W
	  * fencing.
	  */
	 intel->intelScreen->dri2_has_hiz = INTEL_DRI2_HAS_HIZ_TRUE;
	 return;
      } else {
	 /*
	  * Oops... the screen doesn't support separate stencil. Discard the
	  * separate depth and stencil buffers and replace them with
	  * a combined depth/stencil buffer. Discard the hiz buffer too.
	  */
	 intel->intelScreen->dri2_has_hiz = INTEL_DRI2_HAS_HIZ_FALSE;

	 /* 1. Discard depth and stencil renderbuffers. */
	 _mesa_remove_renderbuffer(fb, BUFFER_DEPTH);
	 depth_rb = NULL;
	 _mesa_remove_renderbuffer(fb, BUFFER_STENCIL);
	 stencil_rb = NULL;

	 /* 2. Create new depth/stencil renderbuffer. */
	 struct intel_renderbuffer *depth_stencil_rb =
	    intel_create_renderbuffer(MESA_FORMAT_S8_Z24);
	 _mesa_add_renderbuffer(fb, BUFFER_DEPTH, &depth_stencil_rb->Base);
	 _mesa_add_renderbuffer(fb, BUFFER_STENCIL, &depth_stencil_rb->Base);

	 /* 3. Append DRI2BufferDepthStencil to attachment list. */
	 int old_count = *count;
	 unsigned int *old_attachments = *attachments;
	 *count = old_count + 1;
	 *attachments = malloc(2 * (*count) * sizeof(unsigned));
	 memcpy(*attachments, old_attachments, 2 * old_count * sizeof(unsigned));
	 free(old_attachments);
	 (*attachments)[2 * old_count + 0] = __DRI_BUFFER_DEPTH_STENCIL;
	 (*attachments)[2 * old_count + 1] = intel_bits_per_pixel(depth_stencil_rb);

	 /* 4. Request new set of DRI2 attachments. */
	 __DRIscreen *screen = intel->intelScreen->driScrnPriv;
	 *buffers = screen->dri2.loader->getBuffersWithFormat(drawable,
							      &drawable->w,
							      &drawable->h,
							      *attachments,
							      *count,
							      count,
							      drawable->loaderPrivate);
	 if (!*buffers)
	    return;

	 /*
	  * I don't know how to recover from the failure assertion below.
	  * Rather than fail gradually and unexpectedly, we should just die
	  * now.
	  */
	 assert(*count == old_count + 1);

	 /* 5. Assign the DRI buffer's DRM region to the its renderbuffers. */
	 __DRIbuffer *depth_stencil_buffer = NULL;
	 for (int i = 0; i < *count; ++i) {
	    if ((*buffers)[i].attachment == __DRI_BUFFER_DEPTH_STENCIL) {
	       depth_stencil_buffer = &(*buffers)[i];
	       break;
	    }
	 }
	 struct intel_region *region =
	    intel_region_alloc_for_handle(intel->intelScreen,
					  depth_stencil_buffer->cpp,
					  drawable->w,
					  drawable->h,
					  depth_stencil_buffer->pitch
					     / depth_stencil_buffer->cpp,
					  depth_stencil_buffer->name,
					  "dri2 depth / stencil buffer");
	 intel_renderbuffer_set_region(intel,
				       intel_get_renderbuffer(fb, BUFFER_DEPTH),
				       region);
	 intel_renderbuffer_set_region(intel,
				       intel_get_renderbuffer(fb, BUFFER_STENCIL),
				       region);
	 intel_region_release(&region);
      }
   }

   if (intel_framebuffer_has_hiz(fb)) {
      /*
       * In the future, the driver may advertise a GL config with hiz
       * compatible depth bits and 0 stencil bits (for example, when the
       * driver gains support for float32 depth buffers). When that day comes,
       * here we need to verify that the X driver does in fact support hiz and
       * clean up if it doesn't.
       *
       * Presently, however, no verification or clean up is necessary, and
       * execution should not reach here. If the framebuffer still has a hiz
       * region, then we have already set dri2_has_hiz to true after
       * confirming above that the stencil buffer is W tiled.
       */
      assert(0);
   }
}
@


1.13
log
@Upate to libGL 7.11.2

Tested by jsg@@, matthieu@@ and ajacoutot@@, ok mattieu@@
@
text
@@


1.12
log
@Merge Mesa 7.10.3
@
text
@d36 1
d177 11
d193 1
a193 1
      (void) driGetRendererString(buffer, chipset, "", 0);
d231 33
a268 1
   struct intel_region *region, *depth_region;
a269 1
   struct intel_renderbuffer *front_rb, *back_rb, *depth_rb, *stencil_rb;
d271 1
a271 1
   __DRIscreen *screen;
a272 1
   unsigned int attachments[10];
d275 9
d303 6
a308 59
   screen = intel->intelScreen->driScrnPriv;

   if (screen->dri2.loader
       && (screen->dri2.loader->base.version > 2)
       && (screen->dri2.loader->getBuffersWithFormat != NULL)) {

      front_rb = intel_get_renderbuffer(fb, BUFFER_FRONT_LEFT);
      back_rb = intel_get_renderbuffer(fb, BUFFER_BACK_LEFT);
      depth_rb = intel_get_renderbuffer(fb, BUFFER_DEPTH);
      stencil_rb = intel_get_renderbuffer(fb, BUFFER_STENCIL);

      i = 0;
      if ((intel->is_front_buffer_rendering ||
	   intel->is_front_buffer_reading ||
	   !back_rb) && front_rb) {
	 attachments[i++] = __DRI_BUFFER_FRONT_LEFT;
	 attachments[i++] = intel_bits_per_pixel(front_rb);
      }

      if (back_rb) {
	 attachments[i++] = __DRI_BUFFER_BACK_LEFT;
	 attachments[i++] = intel_bits_per_pixel(back_rb);
      }

      if ((depth_rb != NULL) && (stencil_rb != NULL)) {
	 attachments[i++] = __DRI_BUFFER_DEPTH_STENCIL;
	 attachments[i++] = intel_bits_per_pixel(depth_rb);
      } else if (depth_rb != NULL) {
	 attachments[i++] = __DRI_BUFFER_DEPTH;
	 attachments[i++] = intel_bits_per_pixel(depth_rb);
      } else if (stencil_rb != NULL) {
	 attachments[i++] = __DRI_BUFFER_STENCIL;
	 attachments[i++] = intel_bits_per_pixel(stencil_rb);
      }

      buffers =
	 (*screen->dri2.loader->getBuffersWithFormat)(drawable,
						      &drawable->w,
						      &drawable->h,
						      attachments, i / 2,
						      &count,
						      drawable->loaderPrivate);
   } else if (screen->dri2.loader) {
      i = 0;
      if (intel_get_renderbuffer(fb, BUFFER_FRONT_LEFT))
	 attachments[i++] = __DRI_BUFFER_FRONT_LEFT;
      if (intel_get_renderbuffer(fb, BUFFER_BACK_LEFT))
	 attachments[i++] = __DRI_BUFFER_BACK_LEFT;
      if (intel_get_renderbuffer(fb, BUFFER_DEPTH))
	 attachments[i++] = __DRI_BUFFER_DEPTH;
      if (intel_get_renderbuffer(fb, BUFFER_STENCIL))
	 attachments[i++] = __DRI_BUFFER_STENCIL;

      buffers = (*screen->dri2.loader->getBuffers)(drawable,
						   &drawable->w,
						   &drawable->h,
						   attachments, i,
						   &count,
						   drawable->loaderPrivate);
a328 1
   depth_region = NULL;
d351 6
d375 10
a384 2
       if (rb == NULL)
	  continue;
d386 5
a390 2
       if (rb->region && rb->region->name == buffers[i].name)
	     continue;
d392 2
a393 40
       if (unlikely(INTEL_DEBUG & DEBUG_DRI))
	  fprintf(stderr,
		  "attaching buffer %d, at %d, cpp %d, pitch %d\n",
		  buffers[i].name, buffers[i].attachment,
		  buffers[i].cpp, buffers[i].pitch);
       
       if (buffers[i].attachment == __DRI_BUFFER_STENCIL && depth_region) {
	  if (unlikely(INTEL_DEBUG & DEBUG_DRI))
	     fprintf(stderr, "(reusing depth buffer as stencil)\n");
	  intel_region_reference(&region, depth_region);
       }
       else
          region = intel_region_alloc_for_handle(intel->intelScreen,
						 buffers[i].cpp,
						 drawable->w,
						 drawable->h,
						 buffers[i].pitch / buffers[i].cpp,
						 buffers[i].name,
						 region_name);

       if (buffers[i].attachment == __DRI_BUFFER_DEPTH)
	  depth_region = region;

       intel_renderbuffer_set_region(intel, rb, region);
       intel_region_release(&region);

       if (buffers[i].attachment == __DRI_BUFFER_DEPTH_STENCIL) {
	  rb = intel_get_renderbuffer(fb, BUFFER_STENCIL);
	  if (rb != NULL) {
	     struct intel_region *stencil_region = NULL;

	     if (rb->region && rb->region->name == buffers[i].name)
		   continue;

	     intel_region_reference(&stencil_region, region);
	     intel_renderbuffer_set_region(intel, rb, stencil_region);
	     intel_region_release(&stencil_region);
	  }
       }
   }
d462 1
a462 1
    if (!intel->meta.internal_viewport_call && ctx->DrawBuffer->Name == 0) {
a506 1
   _swsetup_InvalidateState(ctx, new_state);
a507 2
   _tnl_InvalidateState(ctx, new_state);
   _tnl_invalidate_vertex_state(ctx, new_state);
d526 2
a527 2
   if (intel->batch->map != intel->batch->ptr)
      intel_batchbuffer_flush(intel->batch);
d544 1
a544 2
   struct gl_framebuffer *fb = ctx->DrawBuffer;
   int i;
d549 2
a550 11
   for (i = 0; i < fb->_NumColorDrawBuffers; i++) {
       struct intel_renderbuffer *irb;

       irb = intel_renderbuffer(fb->_ColorDrawBuffers[i]);

       if (irb && irb->region)
	  drm_intel_bo_wait_rendering(irb->region->buffer);
   }
   if (fb->_DepthBuffer) {
      /* XXX: Wait on buffer idle */
   }
a574 1

d605 2
a606 2
   if (!_mesa_initialize_context_for_api(&intel->ctx, api, mesaVis, shareCtx,
					 functions, (void *) intel)) {
d617 5
a621 2
   if (IS_GEN6(intel->intelScreen->deviceID)) {
      intel->gen = 6;
a624 1
      intel->gen = 5;
a627 1
      intel->gen = 4;
a632 1
      intel->gen = 3;
a636 1
      intel->gen = 2;
d643 94
d739 1
a739 1
   if (intelScreen->deviceID == PCI_CHIP_I865_G)
d742 1
a742 1
      intel->maxBatchSize = BATCH_SZ;
a795 1
   meta_init_metaops(ctx, &intel->meta);
d797 1
d844 1
d855 1
a855 1
   intel->batch = intel_batchbuffer_alloc(intel);
a902 2
      meta_destroy_metaops(&intel->meta);

d912 1
a912 2
      intel_batchbuffer_free(intel->batch);
      intel->batch = NULL;
d988 558
@


1.11
log
@This is a hack.

Since mesa changed some code, GL applications have been rather nasty to
the xserver, if they are unconstrained rendering wise they spam too many
requests at the xserver and make it slow as hell (even if the cpu is
fairly idle).

There is a throttling mechanism in the xserver (1.8 at least), but that
only really works if you are doing vblank syncing (which is turned off
in our intel driver right now for unrelated reasons), and even then an unsynced
client can cause the same problem.

While a proper fix is being worked on (I am in discussion with X
developers), comment out two conditionals in the intel mesa driver so
that even when using dri2 swapbuffers we wait on the swapbuffers before
last before rendeing more, this prevents almost DoSing the server.

Tested on ironlake, 855 and 965 by me (and my matthieu as well). ok
matthieu@@
@
text
@d32 1
a42 2
#include "i830_dri.h"

a64 4
#define DRIVER_DATE                     "20100328 2010Q1"
#define DRIVER_DATE_GEM                 "GEM " DRIVER_DATE


d66 1
a66 1
intelGetString(GLcontext * ctx, GLenum name)
d154 1
d163 13
d181 1
a181 1
      (void) driGetRendererString(buffer, chipset, DRIVER_DATE_GEM, 0);
d189 24
d239 4
a242 2
   if (intel->is_front_buffer_rendering)
      intel_flush(&intel->ctx, GL_FALSE);
d249 1
a249 1
   if (INTEL_DEBUG & DEBUG_DRI)
d367 1
a367 1
		   "unhandled buffer attach event, attacment type %d\n",
d378 1
a378 1
       if (INTEL_DEBUG & DEBUG_DRI)
d385 1
a385 1
	  if (INTEL_DEBUG & DEBUG_DRI)
d390 2
a391 1
          region = intel_region_alloc_for_handle(intel, buffers[i].cpp,
d422 4
d432 2
a433 2
   drawable = intel->driDrawable;
   if (drawable->dri2.stamp != driContext->dri2.draw_stamp) {
d440 2
a441 2
   drawable = intel->driReadDrawable;
   if (drawable->dri2.stamp != driContext->dri2.read_stamp) {
d446 29
d477 2
a478 2
void
intel_viewport(GLcontext *ctx, GLint x, GLint y, GLsizei w, GLsizei h)
d483 4
a486 2
    if (!intel->using_dri2_swapbuffers &&
	!intel->meta.internal_viewport_call && ctx->DrawBuffer->Name == 0) {
d505 1
a505 1
   { "lock",  DEBUG_LOCK},
d510 1
a510 1
   { "dma",   DEBUG_DMA },
d520 1
d526 1
a526 1
intelInvalidateState(GLcontext * ctx, GLuint new_state)
d543 1
a543 1
intel_flush(GLcontext *ctx, GLboolean needs_mi_flush)
a554 28

   if ((ctx->DrawBuffer->Name == 0) && intel->front_buffer_dirty) {
      __DRIscreen *const screen = intel->intelScreen->driScrnPriv;

      if (screen->dri2.loader &&
          (screen->dri2.loader->base.version >= 2)
	  && (screen->dri2.loader->flushFrontBuffer != NULL) &&
          intel->driDrawable && intel->driDrawable->loaderPrivate) {
	 (*screen->dri2.loader->flushFrontBuffer)(intel->driDrawable,
						  intel->driDrawable->loaderPrivate);

	 /* Only clear the dirty bit if front-buffer rendering is no longer
	  * enabled.  This is done so that the dirty bit can only be set in
	  * glDrawBuffer.  Otherwise the dirty bit would have to be set at
	  * each of N places that do rendering.  This has worse performances,
	  * but it is much easier to get correct.
	  */
	 if (!intel->is_front_buffer_rendering) {
	    intel->front_buffer_dirty = GL_FALSE;
	 }
      }
   }
}

void
intelFlush(GLcontext * ctx)
{
   intel_flush(ctx, GL_FALSE);
d558 1
a558 1
intel_glFlush(GLcontext *ctx)
d562 4
a565 20
   intel_flush(ctx, GL_TRUE);

   /* We're using glFlush as an indicator that a frame is done, which is
    * what DRI2 does before calling SwapBuffers (and means we should catch
    * people doing front-buffer rendering, as well)..
    *
    * Wait for the swapbuffers before the one we just emitted, so we don't
    * get too many swaps outstanding for apps that are GPU-heavy but not
    * CPU-heavy.
    *
    * Unfortunately, we don't have a handle to the batch containing the swap,
    * and getting our hands on that doesn't seem worth it, so we just us the
    * first batch we emitted after the last swap.
    */
   if (/* !intel->using_dri2_swapbuffers && */
       intel->first_post_swapbuffers_batch != NULL) {
      drm_intel_bo_wait_rendering(intel->first_post_swapbuffers_batch);
      drm_intel_bo_unreference(intel->first_post_swapbuffers_batch);
      intel->first_post_swapbuffers_batch = NULL;
   }
d569 1
a569 1
intelFinish(GLcontext * ctx)
d574 2
a575 1
   intelFlush(ctx);
d583 1
a583 1
	  dri_bo_wait_rendering(irb->region->buffer);
d615 2
a616 1
                 const __GLcontextModes * mesaVis,
d621 2
a622 2
   GLcontext *ctx = &intel->ctx;
   GLcontext *shareCtx = (GLcontext *) sharedContextPrivate;
d626 1
d632 13
a644 2
   if (!_mesa_initialize_context(&intel->ctx, mesaVis, shareCtx,
                                 functions, (void *) intel)) {
a650 1
   intel->driScreen = sPriv;
d683 1
a683 2
                       intel->driScreen->myNum,
		       (intel->gen >= 4) ? "i965" : "i915");
d734 2
d737 1
a737 1
    * It depend on constants in __GLcontextRec::Const
a741 1
   ctx->Const.MaxColorAttachments = 4;  /* XXX FBO: review this */
d784 10
a793 1
   intelInitExtensions(ctx);
a831 5
   /* Disable all hardware rendering (skip emitting batches and fences/waits
    * to the kernel)
    */
   intel->no_hw = getenv("INTEL_NO_HW") != NULL;

a842 2
      GLboolean release_texture_heaps;

a850 1
      release_texture_heaps = (intel->ctx.Shared->RefCount == 1);
d863 1
a863 1
      dri_bo_unreference(intel->prim.vb_bo);
d865 1
a865 1
      dri_bo_unreference(intel->first_post_swapbuffers_batch);
a867 12
      if (release_texture_heaps) {
         /* Nothing is currently done here to free texture heaps;
          * but we're not using the texture heap utilities, so I
          * rather think we shouldn't.  I've taken a look, and can't
          * find any private texture data hanging around anywhere, but
          * I'm not yet certain there isn't any at all...
          */
         /* if (INTEL_DEBUG & DEBUG_TEXTURE)
            fprintf(stderr, "do something to free texture heaps\n");
          */
      }

d881 2
a882 7
   struct intel_context *intel =
      (struct intel_context *) driContextPriv->driverPrivate;

   /* Deassociate the context with the drawables.
    */
   intel->driDrawable = NULL;
   intel->driReadDrawable = NULL;
d909 11
a919 2
      struct gl_framebuffer *fb = driDrawPriv->driverPrivate;
      struct gl_framebuffer *readFb = driReadPriv->driverPrivate;
a920 4
      intel->driReadDrawable = driReadPriv;
      intel->driDrawable = driDrawPriv;
      driContextPriv->dri2.draw_stamp = driDrawPriv->dri2.stamp - 1;
      driContextPriv->dri2.read_stamp = driReadPriv->dri2.stamp - 1;
d923 6
@


1.10
log
@Update to Mesa 7.8.2. Tested by johan@@. Thanks.
@
text
@d532 1
a532 1
   if (!intel->using_dri2_swapbuffers &&
@


1.9
log
@Update to Mesa 7.8.1. Tested on a bulk ports build by naddy@@, ok oga@@.
@
text
@d613 1
d635 4
@


1.8
log
@undo a bit of overzealous backporting from the DRI2 bits, this chunk
isn't strictly needed and it causes GL apps to segfault on exit on the
965 with dri1 and xserver 1.6.

ok matthieu@@
@
text
@d28 1
a30 2
#include "main/matrix.h"
#include "main/simple_list.h"
a31 1
#include "main/arrayobj.h"
a38 4

#include "tnl/t_pipeline.h"
#include "tnl/t_vertex.h"

d40 1
a40 2

#include "intel_screen.h"
a47 1
#include "intel_blit.h"
d49 1
a53 1
#include "intel_decode.h"
d55 1
a55 1
#include "intel_swapbuffers.h"
a57 1
#include "vblank.h"
d59 1
a59 1
#include "xmlpool.h"            /* for symbolic values of enum-type options */
a64 26
#define need_GL_ARB_multisample
#define need_GL_ARB_occlusion_query
#define need_GL_ARB_point_parameters
#define need_GL_ARB_shader_objects
#define need_GL_ARB_texture_compression
#define need_GL_ARB_vertex_buffer_object
#define need_GL_ARB_vertex_program
#define need_GL_ARB_vertex_shader
#define need_GL_ARB_window_pos
#define need_GL_EXT_blend_color
#define need_GL_EXT_blend_equation_separate
#define need_GL_EXT_blend_func_separate
#define need_GL_EXT_blend_minmax
#define need_GL_EXT_cull_vertex
#define need_GL_EXT_fog_coord
#define need_GL_EXT_framebuffer_object
#define need_GL_EXT_multi_draw_arrays
#define need_GL_EXT_point_parameters
#define need_GL_EXT_secondary_color
#define need_GL_ATI_separate_stencil
#define need_GL_NV_point_sprite
#define need_GL_NV_vertex_program
#define need_GL_VERSION_2_0
#define need_GL_VERSION_2_1

#include "extension_helper.h"
d66 1
a66 1
#define DRIVER_DATE                     "20090418 2009Q1"
a69 2
static void intel_flush(GLcontext *ctx, GLboolean needs_mi_flush);

d158 9
d172 1
a172 3
      (void) driGetRendererString(buffer, chipset, 
				  (intel->ttm) ? DRIVER_DATE_GEM : DRIVER_DATE,
				  0);
d183 1
a183 13
   switch (rb->Base._ActualFormat) {
   case GL_RGB5:
   case GL_DEPTH_COMPONENT16:
      return 16;
   case GL_RGB8:
   case GL_RGBA8:
   case GL_DEPTH_COMPONENT24:
   case GL_DEPTH24_STENCIL8_EXT:
   case GL_STENCIL_INDEX8_EXT:
      return 32;
   default:
      return 0;
   }
d189 1
a189 1
   struct intel_framebuffer *intel_fb = drawable->driverPrivate;
d193 1
a197 1
   uint32_t name;
d200 14
d222 5
a226 2
      struct intel_renderbuffer *depth_rb;
      struct intel_renderbuffer *stencil_rb;
d231 1
a231 2
	   !intel_fb->color_rb[1])
	   && intel_fb->color_rb[0]) {
d233 1
a233 1
	 attachments[i++] = intel_bits_per_pixel(intel_fb->color_rb[0]);
d236 1
a236 1
      if (intel_fb->color_rb[1]) {
d238 1
a238 1
	 attachments[i++] = intel_bits_per_pixel(intel_fb->color_rb[1]);
a240 3
      depth_rb = intel_get_renderbuffer(&intel_fb->Base, BUFFER_DEPTH);
      stencil_rb = intel_get_renderbuffer(&intel_fb->Base, BUFFER_STENCIL);

d261 1
a261 1
      if (intel_fb->color_rb[0])
d263 1
a263 1
      if (intel_fb->color_rb[1])
d265 1
a265 1
      if (intel_get_renderbuffer(&intel_fb->Base, BUFFER_DEPTH))
d267 1
a267 1
      if (intel_get_renderbuffer(&intel_fb->Base, BUFFER_STENCIL))
d300 1
a300 1
	   rb = intel_fb->color_rb[0];
d305 1
a305 1
	   rb = intel_fb->color_rb[0];
d310 1
a310 1
	   rb = intel_fb->color_rb[1];
d315 1
a315 1
	   rb = intel_get_renderbuffer(&intel_fb->Base, BUFFER_DEPTH);
d320 1
a320 1
	   rb = intel_get_renderbuffer(&intel_fb->Base, BUFFER_DEPTH);
d325 1
a325 1
	   rb = intel_get_renderbuffer(&intel_fb->Base, BUFFER_STENCIL);
d340 1
a340 3
       if (rb->region) {
	  dri_bo_flink(rb->region->buffer, &name);
	  if (name == buffers[i].name)
a341 1
       }
d365 1
a365 1
       intel_renderbuffer_set_region(rb, region);
d369 1
a369 1
	  rb = intel_get_renderbuffer(&intel_fb->Base, BUFFER_STENCIL);
d373 1
a373 3
	     if (rb->region) {
		dri_bo_flink(rb->region->buffer, &name);
		if (name == buffers[i].name)
a374 1
	     }
d377 1
a377 1
	     intel_renderbuffer_set_region(rb, stencil_region);
d387 1
a387 1
intel_viewport(GLcontext *ctx, GLint x, GLint y, GLsizei w, GLsizei h)
d389 2
a390 4
    struct intel_context *intel = intel_context(ctx);
    __DRIcontext *driContext = intel->driContext;
    void (*old_viewport)(GLcontext *ctx, GLint x, GLint y,
			 GLsizei w, GLsizei h);
d392 14
a405 13
    if (!driContext->driScreenPriv->dri2.enabled)
	return;

    intel_update_renderbuffers(driContext, driContext->driDrawablePriv);
    if (driContext->driDrawablePriv != driContext->driReadablePriv)
	intel_update_renderbuffers(driContext, driContext->driReadablePriv);

    old_viewport = ctx->Driver.Viewport;
    ctx->Driver.Viewport = NULL;
    intel->driDrawable = driContext->driDrawablePriv;
    intelWindowMoved(intel);
    intel_draw_buffer(ctx, intel->ctx.DrawBuffer);
    ctx->Driver.Viewport = old_viewport;
d408 2
a409 91
/**
 * Extension strings exported by the intel driver.
 *
 * Extensions supported by all chips supported by i830_dri, i915_dri, or
 * i965_dri.
 */
static const struct dri_extension card_extensions[] = {
   { "GL_ARB_multisample",                GL_ARB_multisample_functions },
   { "GL_ARB_multitexture",               NULL },
   { "GL_ARB_point_parameters",           GL_ARB_point_parameters_functions },
   { "GL_ARB_texture_border_clamp",       NULL },
   { "GL_ARB_texture_compression",        GL_ARB_texture_compression_functions },
   { "GL_ARB_texture_cube_map",           NULL },
   { "GL_ARB_texture_env_add",            NULL },
   { "GL_ARB_texture_env_combine",        NULL },
   { "GL_ARB_texture_env_crossbar",       NULL },
   { "GL_ARB_texture_env_dot3",           NULL },
   { "GL_ARB_texture_mirrored_repeat",    NULL },
   { "GL_ARB_texture_rectangle",          NULL },
   { "GL_ARB_vertex_buffer_object",       GL_ARB_vertex_buffer_object_functions },
   { "GL_ARB_vertex_program",             GL_ARB_vertex_program_functions },
   { "GL_ARB_window_pos",                 GL_ARB_window_pos_functions },
   { "GL_EXT_blend_color",                GL_EXT_blend_color_functions },
   { "GL_EXT_blend_equation_separate",    GL_EXT_blend_equation_separate_functions },
   { "GL_EXT_blend_func_separate",        GL_EXT_blend_func_separate_functions },
   { "GL_EXT_blend_minmax",               GL_EXT_blend_minmax_functions },
   { "GL_EXT_blend_logic_op",             NULL },
   { "GL_EXT_blend_subtract",             NULL },
   { "GL_EXT_cull_vertex",                GL_EXT_cull_vertex_functions },
   { "GL_EXT_fog_coord",                  GL_EXT_fog_coord_functions },
   { "GL_EXT_multi_draw_arrays",          GL_EXT_multi_draw_arrays_functions },
   { "GL_EXT_packed_depth_stencil",       NULL },
   { "GL_EXT_secondary_color",            GL_EXT_secondary_color_functions },
   { "GL_EXT_stencil_wrap",               NULL },
   { "GL_EXT_texture_edge_clamp",         NULL },
   { "GL_EXT_texture_env_combine",        NULL },
   { "GL_EXT_texture_env_dot3",           NULL },
   { "GL_EXT_texture_filter_anisotropic", NULL },
   { "GL_EXT_texture_lod_bias",           NULL },
   { "GL_3DFX_texture_compression_FXT1",  NULL },
   { "GL_APPLE_client_storage",           NULL },
   { "GL_MESA_pack_invert",               NULL },
   { "GL_MESA_ycbcr_texture",             NULL },
   { "GL_NV_blend_square",                NULL },
   { "GL_NV_point_sprite",                GL_NV_point_sprite_functions },
   { "GL_NV_vertex_program",              GL_NV_vertex_program_functions },
   { "GL_NV_vertex_program1_1",           NULL },
   { "GL_SGIS_generate_mipmap",           NULL },
   { NULL, NULL }
};

static const struct dri_extension brw_extensions[] = {
   { "GL_ARB_depth_texture",              NULL },
   { "GL_ARB_draw_buffers",               NULL },
   { "GL_ARB_fragment_program",           NULL },
   { "GL_ARB_fragment_program_shadow",    NULL },
   { "GL_ARB_fragment_shader",            NULL },
   { "GL_ARB_occlusion_query",            GL_ARB_occlusion_query_functions },
   { "GL_ARB_point_sprite", 		  NULL },
   { "GL_ARB_shader_objects",             GL_ARB_shader_objects_functions },
   { "GL_ARB_shading_language_100",       GL_VERSION_2_0_functions },
#if 0
   /* Support for GLSL 1.20 is currently broken in core Mesa.
    */
   { "GL_ARB_shading_language_120",       GL_VERSION_2_1_functions },
#endif
   { "GL_ARB_shadow",                     NULL },
   { "GL_ARB_texture_non_power_of_two",   NULL },
   { "GL_ARB_vertex_shader",              GL_ARB_vertex_shader_functions },
   { "GL_EXT_shadow_funcs",               NULL },
   { "GL_EXT_texture_sRGB",		  NULL },
   { "GL_ATI_separate_stencil",           GL_ATI_separate_stencil_functions },
   { "GL_ATI_texture_env_combine3",       NULL },
   { NULL,                                NULL }
};

static const struct dri_extension arb_oq_extensions[] = {
   { NULL, NULL }
};

static const struct dri_extension ttm_extensions[] = {
   { "GL_ARB_pixel_buffer_object",        NULL },
   { "GL_EXT_framebuffer_object",         GL_EXT_framebuffer_object_functions },
   { NULL, NULL }
};

/**
 * Initializes potential list of extensions if ctx == NULL, or actually enables
 * extensions for a context.
 */
void intelInitExtensions(GLcontext *ctx, GLboolean enable_imaging)
d411 2
a412 1
   struct intel_context *intel = ctx?intel_context(ctx):NULL;
d414 5
a418 11
   /* Disable imaging extension until convolution is working in teximage paths.
    */
   enable_imaging = GL_FALSE;

   driInitExtensions(ctx, card_extensions, enable_imaging);

   if (intel == NULL || intel->ttm)
      driInitExtensions(ctx, ttm_extensions, GL_FALSE);

   if (intel == NULL || IS_965(intel->intelScreen->deviceID))
      driInitExtensions(ctx, brw_extensions, GL_FALSE);
d470 1
a470 1
static void
d478 1
a478 1
   if (!IS_965(intel->intelScreen->deviceID))
a480 7
   /* Emit a flush so that any frontbuffer rendering that might have occurred
    * lands onscreen in a timely manner, even if the X Server doesn't trigger
    * a flush for us.
    */
   if (needs_mi_flush)
      intel_batchbuffer_emit_mi_flush(intel->batch);

d489 2
a490 1
	  && (screen->dri2.loader->flushFrontBuffer != NULL)) {
d500 1
a500 1
	 if (intel->is_front_buffer_rendering) {
d513 1
a513 1
void
d516 2
d519 19
a570 5
   functions->CopyColorTable = _swrast_CopyColorTable;
   functions->CopyColorSubTable = _swrast_CopyColorSubTable;
   functions->CopyConvolutionFilter1D = _swrast_CopyConvolutionFilter1D;
   functions->CopyConvolutionFilter2D = _swrast_CopyConvolutionFilter2D;

d572 3
d579 2
d587 1
a587 1
                 __DRIcontextPrivate * driContextPriv,
d593 7
a599 3
   __DRIscreenPrivate *sPriv = driContextPriv->driScreenPriv;
   intelScreenPrivate *intelScreen = (intelScreenPrivate *) sPriv->private;
   int fthrottle_mode;
d603 1
a603 1
      _mesa_printf("%s: failed to init mesa context\n", __FUNCTION__);
a609 1
   intel->sarea = intelScreen->sarea;
d611 1
d613 22
a634 4
   /* Dri stuff */
   intel->hHWContext = driContextPriv->hHWContext;
   intel->driFd = sPriv->fd;
   intel->driHwLock = sPriv->lock;
d638 1
a638 1
		       IS_965(intelScreen->deviceID) ? "i965" : "i915");
d645 8
a652 12
   intel->ttm = intelScreen->ttm;
   if (intel->ttm) {
      int bo_reuse_mode;

      bo_reuse_mode = driQueryOptioni(&intel->optionCache, "bo_reuse");
      switch (bo_reuse_mode) {
      case DRI_CONF_BO_REUSE_DISABLED:
	 break;
      case DRI_CONF_BO_REUSE_ALL:
	 intel_bufmgr_gem_enable_reuse(intel->bufmgr);
	 break;
      }
a654 2
   ctx->Const.MaxTextureMaxAnisotropy = 2.0;

d694 1
d696 1
a696 1
   if (IS_965(intelScreen->deviceID)) {
d714 2
d733 1
a733 1
   if (IS_965(intelScreen->deviceID))
d738 1
a738 16
   fthrottle_mode = driQueryOptioni(&intel->optionCache, "fthrottle_mode");
   intel->irqsEmitted = 0;

   intel->do_irqs = (intel->intelScreen->irq_active &&
                     fthrottle_mode == DRI_CONF_FTHROTTLE_IRQS);

   intel->do_usleeps = (fthrottle_mode == DRI_CONF_FTHROTTLE_USLEEPS);

   _math_matrix_ctr(&intel->ViewportMatrix);

   if (IS_965(intelScreen->deviceID) && !intel->intelScreen->irq_active) {
      _mesa_printf("IRQs not active.  Exiting\n");
      exit(1);
   }

   intelInitExtensions(ctx, GL_FALSE);
a743 3
   if (!sPriv->dri2.enabled)
      intel_recreate_static_regions(intel);

a745 1
   intel_bufferobj_init(intel);
d755 3
d767 10
d786 1
a786 1
intelDestroyContext(__DRIcontextPrivate * driContextPriv)
d797 4
d809 1
a809 1
      intel->Fallback = 0;      /* don't call _swrast_Flush later */
d818 2
a832 4
      intel_region_release(&intel->front_region);
      intel_region_release(&intel->back_region);
      intel_region_release(&intel->depth_region);

d837 3
d844 1
a844 1
intelUnbindContext(__DRIcontextPrivate * driContextPriv)
d846 8
d858 3
a860 3
intelMakeCurrent(__DRIcontextPrivate * driContextPriv,
                 __DRIdrawablePrivate * driDrawPriv,
                 __DRIdrawablePrivate * driReadPriv)
d862 2
a863 1
   __DRIscreenPrivate *psp = driDrawPriv->driScreenPriv;
d865 4
a868 35
   if (driContextPriv) {
      struct intel_context *intel =
         (struct intel_context *) driContextPriv->driverPrivate;
      struct intel_framebuffer *intel_fb =
	 (struct intel_framebuffer *) driDrawPriv->driverPrivate;
      GLframebuffer *readFb = (GLframebuffer *) driReadPriv->driverPrivate;
 
      if (driContextPriv->driScreenPriv->dri2.enabled) {     
          intel_update_renderbuffers(driContextPriv, driDrawPriv);
          if (driDrawPriv != driReadPriv)
              intel_update_renderbuffers(driContextPriv, driReadPriv);
      } else {
          /* XXX FBO temporary fix-ups! */
          /* if the renderbuffers don't have regions, init them from the context */
         struct intel_renderbuffer *irbDepth
            = intel_get_renderbuffer(&intel_fb->Base, BUFFER_DEPTH);
         struct intel_renderbuffer *irbStencil
            = intel_get_renderbuffer(&intel_fb->Base, BUFFER_STENCIL);

         if (intel_fb->color_rb[0]) {
	    intel_renderbuffer_set_region(intel_fb->color_rb[0],
					  intel->front_region);
         }
         if (intel_fb->color_rb[1]) {
	    intel_renderbuffer_set_region(intel_fb->color_rb[1],
					  intel->back_region);
         }

         if (irbDepth) {
	    intel_renderbuffer_set_region(irbDepth, intel->depth_region);
         }
         if (irbStencil) {
	    intel_renderbuffer_set_region(irbStencil, intel->depth_region);
         }
      }
d870 7
a876 2
      /* set GLframebuffer size to match window, if needed */
      driUpdateFramebufferSize(&intel->ctx, driDrawPriv);
d878 3
a880 5
      if (driReadPriv != driDrawPriv) {
	 driUpdateFramebufferSize(&intel->ctx, driReadPriv);
      }

      _mesa_make_current(&intel->ctx, &intel_fb->Base, readFb);
d882 6
a887 35
      /* The drawbuffer won't always be updated by _mesa_make_current: 
       */
      if (intel->ctx.DrawBuffer == &intel_fb->Base) {

	 if (intel->driReadDrawable != driReadPriv)
	    intel->driReadDrawable = driReadPriv;

	 if (intel->driDrawable != driDrawPriv) {
	    if (driDrawPriv->swap_interval == (unsigned)-1) {
	       int i;

	       driDrawPriv->vblFlags = (intel->intelScreen->irq_active != 0)
		  ? driGetDefaultVBlankFlags(&intel->optionCache)
		 : VBLANK_FLAG_NO_IRQ;

	       /* Prevent error printf if one crtc is disabled, this will
		* be properly calculated in intelWindowMoved() next.
		*/
		driDrawPriv->vblFlags = intelFixupVblank(intel, driDrawPriv);

	       (*psp->systemTime->getUST) (&intel_fb->swap_ust);
	       driDrawableInitVBlank(driDrawPriv);
	       intel_fb->vbl_waited = driDrawPriv->vblSeq;

	       for (i = 0; i < 2; i++) {
		  if (intel_fb->color_rb[i])
		     intel_fb->color_rb[i]->vbl_pending = driDrawPriv->vblSeq;
	       }
	    }
	    intel->driDrawable = driDrawPriv;
	    intelWindowMoved(intel);
	 }

	 intel_draw_buffer(&intel->ctx, &intel_fb->Base);
      }
a894 135

static void
intelContendedLock(struct intel_context *intel, GLuint flags)
{
   __DRIdrawablePrivate *dPriv = intel->driDrawable;
   __DRIscreenPrivate *sPriv = intel->driScreen;
   volatile drm_i915_sarea_t *sarea = intel->sarea;
   int me = intel->hHWContext;

   drmGetLock(intel->driFd, intel->hHWContext, flags);
   intel->locked = 1;

   if (INTEL_DEBUG & DEBUG_LOCK)
      _mesa_printf("%s - got contended lock\n", __progname);

   /* If the window moved, may need to set a new cliprect now.
    *
    * NOTE: This releases and regains the hw lock, so all state
    * checking must be done *after* this call:
    */
   if (dPriv)
       DRI_VALIDATE_DRAWABLE_INFO(sPriv, dPriv);

   if (sarea && sarea->ctxOwner != me) {
      if (INTEL_DEBUG & DEBUG_BUFMGR) {
	 fprintf(stderr, "Lost Context: sarea->ctxOwner %x me %x\n",
		 sarea->ctxOwner, me);
      }
      sarea->ctxOwner = me;
   }

   /* If the last consumer of the texture memory wasn't us, notify the fake
    * bufmgr and record the new owner.  We should have the memory shared
    * between contexts of a single fake bufmgr, but this will at least make
    * things correct for now.
    */
   if (!intel->ttm && sarea->texAge != intel->hHWContext) {
      sarea->texAge = intel->hHWContext;
      intel_bufmgr_fake_contended_lock_take(intel->bufmgr);
      if (INTEL_DEBUG & DEBUG_BATCH)
	 intel_decode_context_reset();
      if (INTEL_DEBUG & DEBUG_BUFMGR)
	 fprintf(stderr, "Lost Textures: sarea->texAge %x hw context %x\n",
		 sarea->ctxOwner, intel->hHWContext);
   }

   /* Drawable changed?
    */
   if (dPriv && intel->lastStamp != dPriv->lastStamp) {
       intelWindowMoved(intel);
       intel->lastStamp = dPriv->lastStamp;
   }
}


_glthread_DECLARE_STATIC_MUTEX(lockMutex);

/* Lock the hardware and validate our state.  
 */
void LOCK_HARDWARE( struct intel_context *intel )
{
    __DRIdrawable *dPriv = intel->driDrawable;
    __DRIscreen *sPriv = intel->driScreen;
    char __ret = 0;
    struct intel_framebuffer *intel_fb = NULL;
    struct intel_renderbuffer *intel_rb = NULL;

    _glthread_LOCK_MUTEX(lockMutex);
    assert(!intel->locked);
    intel->locked = 1;

    if (intel->driDrawable) {
       intel_fb = intel->driDrawable->driverPrivate;

       if (intel_fb)
	  intel_rb =
	     intel_get_renderbuffer(&intel_fb->Base,
				    intel_fb->Base._ColorDrawBufferIndexes[0]);
    }

    if (intel_rb && dPriv->vblFlags &&
	!(dPriv->vblFlags & VBLANK_FLAG_NO_IRQ) &&
	(intel_fb->vbl_waited - intel_rb->vbl_pending) > (1<<23)) {
	drmVBlank vbl;

	vbl.request.type = DRM_VBLANK_ABSOLUTE;

	if ( dPriv->vblFlags & VBLANK_FLAG_SECONDARY ) {
	    vbl.request.type |= DRM_VBLANK_SECONDARY;
	}

	vbl.request.sequence = intel_rb->vbl_pending;
	drmWaitVBlank(intel->driFd, &vbl);
	intel_fb->vbl_waited = vbl.reply.sequence;
    }

    if (!sPriv->dri2.enabled) {
	DRM_CAS(intel->driHwLock, intel->hHWContext,
		(DRM_LOCK_HELD|intel->hHWContext), __ret);

	if (__ret)
	    intelContendedLock( intel, 0 );
    }


    if (INTEL_DEBUG & DEBUG_LOCK)
      _mesa_printf("%s - locked\n", __progname);
}


/* Unlock the hardware using the global current context 
 */
void UNLOCK_HARDWARE( struct intel_context *intel )
{
    __DRIscreen *sPriv = intel->driScreen;

   intel->vtbl.note_unlock( intel );
   intel->locked = 0;

   if (!sPriv->dri2.enabled)
      DRM_UNLOCK(intel->driFd, intel->driHwLock, intel->hHWContext);

   _glthread_UNLOCK_MUTEX(lockMutex);

   if (INTEL_DEBUG & DEBUG_LOCK)
      _mesa_printf("%s - unlocked\n", __progname);

   /**
    * Nothing should be left in batch outside of LOCK/UNLOCK which references
    * cliprects.
    */
   if (intel->batch->cliprect_mode == REFERENCES_CLIPRECTS)
      intel_batchbuffer_flush(intel->batch);
}

@


1.7
log
@backport some code from mesa current (and 7.5) so that the dri2 protocol
is correctly handled. without fixes to mesa and the ddx, the so-called
backwards compat goop that was added just plain does not work and ends
up with rendering bullshit.
@
text
@a928 33
      /* XXX In intelMakeCurrent() below, the context's static regions are 
       * referenced inside the frame buffer; it's listed as a hack,
       * with a comment of "XXX FBO temporary fix-ups!", but
       * as long as it's there, we should release the regions here.
       * The do/while loop around the block is used to allow the
       * "continue" statements inside the block to exit the block,
       * to avoid many layers of "if" constructs.
       */
      do {
         __DRIdrawablePrivate * driDrawPriv = intel->driDrawable;
         struct intel_framebuffer *intel_fb;
         struct intel_renderbuffer *irbDepth, *irbStencil;
         if (!driDrawPriv) {
            /* We're already detached from the drawable; exit this block. */
            continue;
         }
         intel_fb = (struct intel_framebuffer *) driDrawPriv->driverPrivate;
         if (!intel_fb) {
            /* The frame buffer is already gone; exit this block. */
            continue;
         }
         irbDepth = intel_get_renderbuffer(&intel_fb->Base, BUFFER_DEPTH);
         irbStencil = intel_get_renderbuffer(&intel_fb->Base, BUFFER_STENCIL);

         /* Usually, the stencil buffer is the same as the depth buffer;
          * but they're handled separately in MakeCurrent, so we'll
          * handle them separately here.
          */
         if (irbStencil && irbStencil->region == intel->depth_region) {
	    intel_renderbuffer_set_region(irbStencil, NULL);
         }
      } while (0);

@


1.6
log
@Update to Mesa 7.4.2. Tested by oga@@, ckuethe@@ and naddy@@.
@
text
@a27 1

d33 1
d69 1
d104 3
d210 18
d235 1
a235 1
   __DRIbuffer *buffers;
d247 59
a305 16
   i = 0;
   if (intel_fb->color_rb[0])
      attachments[i++] = __DRI_BUFFER_FRONT_LEFT;
   if (intel_fb->color_rb[1])
      attachments[i++] = __DRI_BUFFER_BACK_LEFT;
   if (intel_get_renderbuffer(&intel_fb->Base, BUFFER_DEPTH))
      attachments[i++] = __DRI_BUFFER_DEPTH;
   if (intel_get_renderbuffer(&intel_fb->Base, BUFFER_STENCIL))
      attachments[i++] = __DRI_BUFFER_STENCIL;

   buffers = (*screen->dri2.loader->getBuffers)(drawable,
						&drawable->w,
						&drawable->h,
						attachments, i,
						&count,
						drawable->loaderPrivate);
d348 5
d399 17
d624 2
a625 2
      if (screen->dri2.loader
          && (screen->dri2.loader->base.version >= 2)
d668 1
a668 1
       if (irb->region)
d794 7
d918 5
a922 2
         /* This share group is about to go away, free our private
          * texture object data.
d924 1
a924 1
         if (INTEL_DEBUG & DEBUG_TEXTURE)
d926 1
d928 33
@


1.5
log
@Merge in two commits of mine from upstream mesa which mean that on
startup with and when we have only one pipe running we will always pick
the correct vblank pipe to sync to.

ok matthieu@@.
@
text
@d29 8
a36 8
#include "glheader.h"
#include "context.h"
#include "matrix.h"
#include "simple_list.h"
#include "extensions.h"
#include "framebuffer.h"
#include "imports.h"
#include "points.h"
a53 1
#include "intel_ioctl.h"
d56 1
d62 2
a72 1
#define need_GL_NV_point_sprite
d74 1
d76 1
d80 1
d90 1
d92 2
a94 2
#define need_GL_ATI_separate_stencil
#define need_GL_EXT_point_parameters
a96 2
#define need_GL_ARB_shader_objects
#define need_GL_ARB_vertex_shader
d100 2
a101 1
#define DRIVER_DATE                     "20061102"
d106 1
d116 1
a116 1
      switch (intel_context(ctx)->intelScreen->deviceID) {
d156 4
d196 3
a198 1
      (void) driGetRendererString(buffer, chipset, DRIVER_DATE, 0);
d206 151
d364 42
a405 50
   {"GL_ARB_multisample", GL_ARB_multisample_functions},
   {"GL_ARB_multitexture", NULL},
   {"GL_ARB_point_parameters", GL_ARB_point_parameters_functions},
   {"GL_NV_point_sprite", GL_NV_point_sprite_functions},
   {"GL_ARB_texture_border_clamp", NULL},
   {"GL_ARB_texture_compression", GL_ARB_texture_compression_functions},
   {"GL_ARB_texture_cube_map", NULL},
   {"GL_ARB_texture_env_add", NULL},
   {"GL_ARB_texture_env_combine", NULL},
   {"GL_ARB_texture_env_crossbar", NULL},
   {"GL_ARB_texture_env_dot3", NULL},
   {"GL_ARB_texture_mirrored_repeat", NULL},
   {"GL_ARB_texture_non_power_of_two",   NULL },
   {"GL_ARB_texture_rectangle", NULL},
   {"GL_NV_texture_rectangle", NULL},
   {"GL_EXT_texture_rectangle", NULL},
   {"GL_ARB_point_parameters", NULL}, 
   {"GL_ARB_vertex_buffer_object", GL_ARB_vertex_buffer_object_functions},
   {"GL_ARB_vertex_program", GL_ARB_vertex_program_functions},
   {"GL_ARB_window_pos", GL_ARB_window_pos_functions},
   {"GL_EXT_blend_color", GL_EXT_blend_color_functions},
   {"GL_EXT_blend_equation_separate",
    GL_EXT_blend_equation_separate_functions},
   {"GL_EXT_blend_func_separate", GL_EXT_blend_func_separate_functions},
   {"GL_EXT_blend_minmax", GL_EXT_blend_minmax_functions},
   {"GL_EXT_blend_logic_op", NULL},
   {"GL_EXT_blend_subtract", NULL},
   {"GL_EXT_cull_vertex", GL_EXT_cull_vertex_functions},
   {"GL_EXT_fog_coord", GL_EXT_fog_coord_functions},
   {"GL_EXT_multi_draw_arrays", GL_EXT_multi_draw_arrays_functions},
   {"GL_ATI_separate_stencil", GL_ATI_separate_stencil_functions},
#if 1                           /* XXX FBO temporary? */
   {"GL_EXT_packed_depth_stencil", NULL},
#endif
   {"GL_EXT_secondary_color", GL_EXT_secondary_color_functions},
   {"GL_EXT_stencil_wrap", NULL},
   {"GL_EXT_texture_edge_clamp", NULL},
   {"GL_EXT_texture_env_combine", NULL},
   {"GL_EXT_texture_env_dot3", NULL},
   {"GL_EXT_texture_filter_anisotropic", NULL},
   {"GL_EXT_texture_lod_bias", NULL},
   {"GL_3DFX_texture_compression_FXT1", NULL},
   {"GL_APPLE_client_storage", NULL},
   {"GL_MESA_pack_invert", NULL},
   {"GL_MESA_ycbcr_texture", NULL},
   {"GL_NV_blend_square", NULL},
   {"GL_NV_vertex_program", GL_NV_vertex_program_functions},
   {"GL_NV_vertex_program1_1", NULL},
   { "GL_SGIS_generate_mipmap", NULL },
   {NULL, NULL}
d409 1
a409 6
   { "GL_ARB_shading_language_100",       GL_VERSION_2_0_functions},
   { "GL_ARB_shading_language_120",       GL_VERSION_2_1_functions},
   { "GL_ARB_shader_objects",             GL_ARB_shader_objects_functions},
   { "GL_ARB_vertex_shader",              GL_ARB_vertex_shader_functions},
   { "GL_ARB_point_sprite", 		  NULL},
   { "GL_ARB_fragment_shader",            NULL },
a410 1
   { "GL_ARB_depth_texture",              NULL },
d412 11
d424 2
d427 3
a429 4
   { "GL_ARB_fragment_program_shadow",    NULL },
   /* ARB extn won't work if not enabled */
   { "GL_SGIX_depth_texture",             NULL },
   { "GL_EXT_texture_sRGB",		  NULL},
d433 10
d457 3
d513 2
a514 3

void
intelFlush(GLcontext * ctx)
d524 7
d534 20
a553 2
   /* XXX: Need to do an MI_FLUSH here.
    */
d557 1
a557 1
intelFinish(GLcontext * ctx)
d559 1
a559 7
   struct intel_context *intel = intel_context(ctx);
   intelFlush(ctx);
   if (intel->batch->last_fence) {
      dri_fence_wait(intel->batch->last_fence);
      dri_fence_unreference(intel->batch->last_fence);
      intel->batch->last_fence = NULL;
   }
d562 2
a563 3
/** Driver-specific fence emit implementation for the fake memory manager. */
static unsigned int
intel_fence_emit(void *private)
d565 1
a565 10
   struct intel_context *intel = (struct intel_context *)private;
   unsigned int fence;

   /* XXX: Need to emit a flush, if we haven't already (at least with the
    * current batchbuffer implementation, we have).
    */

   fence = intelEmitIrqLocked(intel);

   return fence;
d568 2
a569 3
/** Driver-specific fence wait implementation for the fake memory manager. */
static int
intel_fence_wait(void *private, unsigned int cookie)
d571 2
a572 1
   struct intel_context *intel = (struct intel_context *)private;
d574 1
a574 1
   intelWaitIrq(intel, cookie);
d576 2
a577 2
   return 0;
}
d579 1
a579 4
static GLboolean
intel_init_bufmgr(struct intel_context *intel)
{
   intelScreenPrivate *intelScreen = intel->intelScreen;
d581 5
a585 9
   /* If we've got a new enough DDX that's initializing TTM and giving us
    * object handles for the shared buffers, use that.
    */
   intel->ttm = GL_FALSE;

   if (intelScreen->tex.size == 0) {
      fprintf(stderr, "[%s:%u] Error initializing buffer manager.\n",
           __func__, __LINE__);
       return GL_FALSE;
a586 9

   intel->bufmgr = dri_bufmgr_fake_init(intelScreen->tex.offset,
					intelScreen->tex.map,
					intelScreen->tex.size,
					intel_fence_emit,
					intel_fence_wait,
					intel);

   return GL_TRUE;
d594 1
a594 1
   functions->Flush = intelFlush;
d606 1
a622 2
   volatile struct drm_i915_sarea *saPriv = (struct drm_i915_sarea *)
      (((GLubyte *) sPriv->pSAREA) + intelScreen->sarea_priv_offset);
d634 2
a635 1
   intel->sarea = saPriv;
a641 3
   intel->width = intelScreen->width;
   intel->height = intelScreen->height;

d650 14
a663 2
   if (!intel_init_bufmgr(intel))
      return GL_FALSE;
d671 7
a677 1
      intel->strict_conformance = 1;
d680 1
a680 1
   if (intel->strict_conformance) {
a764 2
   intel->last_swap_fence = NULL;
   intel->first_swap_fence = NULL;
a781 1
      FALLBACK(intel, INTEL_FALLBACK_USER, 1);
d816 1
d818 4
a821 10
      if (intel->last_swap_fence) {
	 dri_fence_wait(intel->last_swap_fence);
	 dri_fence_unreference(intel->last_swap_fence);
	 intel->last_swap_fence = NULL;
      }
      if (intel->first_swap_fence) {
	 dri_fence_wait(intel->first_swap_fence);
	 dri_fence_unreference(intel->first_swap_fence);
	 intel->first_swap_fence = NULL;
      }
d831 6
a838 2

      dri_bufmgr_destroy(intel->bufmgr);
d861 8
a868 5


      /* XXX FBO temporary fix-ups! */
      /* if the renderbuffers don't have regions, init them from the context */
      if (!driContextPriv->driScreenPriv->dri2.enabled) {
d882 1
d948 1
a948 1
   volatile struct drm_i915_sarea *sarea = intel->sarea;
d980 1
a980 1
      dri_bufmgr_fake_contended_lock_take(intel->bufmgr);
a987 32
   if (sarea->width != intel->width || sarea->height != intel->height) {
       int numClipRects = intel->numClipRects;

       /*
	* FIXME: Really only need to do this when drawing to a
	* common back- or front buffer.
	*/

       /*
	* This will essentially drop the outstanding batchbuffer on
	* the floor.
	*/
       intel->numClipRects = 0;

       if (intel->Fallback)
	   _swrast_flush(&intel->ctx);

       if (!IS_965(intel->intelScreen->deviceID))
	   INTEL_FIREVERTICES(intel);

       if (intel->batch->map != intel->batch->ptr)
	   intel_batchbuffer_flush(intel->batch);

       intel->numClipRects = numClipRects;

       /* force window update */
       intel->lastStamp = 0;

       intel->width = sarea->width;
       intel->height = sarea->height;
   }

d1038 3
a1040 2
    DRM_CAS(intel->driHwLock, intel->hHWContext,
        (DRM_LOCK_HELD|intel->hHWContext), __ret);
a1041 1
    if (sPriv->dri2.enabled) {
d1043 1
a1043 7
	    drmGetLock(intel->driFd, intel->hHWContext, 0);
	if (__driParseEvents(dPriv->driContextPriv, dPriv)) {
	    intelWindowMoved(intel);
	    intel_draw_buffer(&intel->ctx, intel->ctx.DrawBuffer);
	}
    } else if (__ret) {
        intelContendedLock( intel, 0 );
d1056 2
d1061 2
a1062 1
   DRM_UNLOCK(intel->driFd, intel->driHwLock, intel->hHWContext);
d1073 2
a1074 1
   assert(intel->batch->cliprect_mode != REFERENCES_CLIPRECTS);
@


1.4
log
@Remove ttm entrypoints. That memory manager interface isn't going to see the
light of day and has already been removed in mesa master (ages ago).

As a bonus, removes the annoying "falling back to classic" message on
launching a gl application.

ok matthieu@@.
@
text
@d735 5
@


1.3
log
@remove the triple buffering support from the intel driver, the support
from this was removed from the kernel and is very much deprecated.
Pageflipping is also probably broken and should not be used. Similar
change happened in mesa master a while back.

ok matthieu@@
@
text
@a61 1
#include "intel_bufmgr_ttm.h"
a272 6
static const struct dri_extension ttm_extensions[] = {
   {"GL_EXT_framebuffer_object", GL_EXT_framebuffer_object_functions},
   {"GL_ARB_pixel_buffer_object", NULL},
   {NULL, NULL}
};

a286 3
   if (intel == NULL || intel->ttm)
      driInitExtensions(ctx, ttm_extensions, GL_FALSE);

a401 2
   GLboolean ttm_disable = getenv("INTEL_NO_TTM") != NULL;
   GLboolean ttm_supported;
d407 5
a411 27
   if (intel->intelScreen->driScrnPriv->dri2.enabled)
       ttm_supported = GL_TRUE;
   else if (intel->intelScreen->driScrnPriv->ddx_version.minor >= 9 &&
	    intel->intelScreen->drmMinor >= 11 &&
	    intel->intelScreen->front.bo_handle != -1)
       ttm_supported = GL_TRUE;
   else
       ttm_supported = GL_FALSE;

   if (!ttm_disable && ttm_supported) {
      int bo_reuse_mode;
      intel->bufmgr = intel_bufmgr_ttm_init(intel->driFd,
					    DRM_FENCE_TYPE_EXE,
					    DRM_FENCE_TYPE_EXE |
					    DRM_I915_FENCE_TYPE_RW,
					    BATCH_SZ);
      if (intel->bufmgr != NULL)
	 intel->ttm = GL_TRUE;

      bo_reuse_mode = driQueryOptioni(&intel->optionCache, "bo_reuse");
      switch (bo_reuse_mode) {
      case DRI_CONF_BO_REUSE_DISABLED:
	 break;
      case DRI_CONF_BO_REUSE_ALL:
	 intel_ttm_enable_bo_reuse(intel->bufmgr);
	 break;
      }
a412 8
   /* Otherwise, use the classic buffer manager. */
   if (intel->bufmgr == NULL) {
      if (ttm_disable) {
	 fprintf(stderr, "TTM buffer manager disabled.  Using classic.\n");
      } else {
	 fprintf(stderr, "Failed to initialize TTM buffer manager.  "
		 "Falling back to classic.\n");
      }
d414 6
a419 13
      if (intelScreen->tex.size == 0) {
	 fprintf(stderr, "[%s:%u] Error initializing buffer manager.\n",
		 __func__, __LINE__);
	 return GL_FALSE;
      }

      intel->bufmgr = dri_bufmgr_fake_init(intelScreen->tex.offset,
					   intelScreen->tex.map,
					   intelScreen->tex.size,
					   intel_fence_emit,
					   intel_fence_wait,
					   intel);
   }
@


1.2
log
@Remove the ARB_occlusion_query support in the intel drivers. It was racy and
broken and the kernel ioctl doesn't exist anymore. GEM has a much better
solution for this.

ok matthieu (as part of a larger diff)
@
text
@a751 6
#if 0
         if (intel_fb->color_rb[2]) {
	    intel_renderbuffer_set_region(intel_fb->color_rb[2],
					  intel->third_region);
         }
#endif
d788 1
a788 1
	       for (i = 0; i < (intel->intelScreen->third.handle ? 3 : 2); i++) {
@


1.1
log
@Mesa 7.2, Tested by ckuethe@@, naddy@@, oga@@, and others.
@
text
@a78 1
#define need_GL_ARB_occlusion_query
a273 5
static const struct dri_extension arb_oc_extensions[] = {
   {"GL_ARB_occlusion_query",            GL_ARB_occlusion_query_functions},
   {NULL, NULL}
};

a296 5
   if (intel == NULL || 
       (IS_965(intel->intelScreen->deviceID) && 
	intel->intelScreen->drmMinor >= 8))
      driInitExtensions(ctx, arb_oc_extensions, GL_FALSE);

a380 31
static void
intelBeginQuery(GLcontext *ctx, GLenum target, struct gl_query_object *q)
{
	struct intel_context *intel = intel_context( ctx );
	struct drm_i915_mmio io = {
		.read_write = I915_MMIO_READ,
		.reg = MMIO_REGS_PS_DEPTH_COUNT,
		.data = &q->Result 
	};
	intel->stats_wm++;
	intelFinish(&intel->ctx);
	drmCommandWrite(intel->driFd, DRM_I915_MMIO, &io, sizeof(io));
}

static void
intelEndQuery(GLcontext *ctx, GLenum target, struct gl_query_object *q)
{
	struct intel_context *intel = intel_context( ctx );
	GLuint64EXT tmp;	
	struct drm_i915_mmio io = {
		.read_write = I915_MMIO_READ,
		.reg = MMIO_REGS_PS_DEPTH_COUNT,
		.data = &tmp
	};
	intelFinish(&intel->ctx);
	drmCommandWrite(intel->driFd, DRM_I915_MMIO, &io, sizeof(io));
	q->Result = tmp - q->Result;
	q->Ready = GL_TRUE;
	intel->stats_wm--;
}

a486 3

   functions->BeginQuery = intelBeginQuery;
   functions->EndQuery = intelEndQuery;
@


1.1.1.1
log
@Import Mesa 7.10.3
@
text
@d29 8
a36 7
#include "main/glheader.h"
#include "main/context.h"
#include "main/extensions.h"
#include "main/fbobject.h"
#include "main/framebuffer.h"
#include "main/imports.h"
#include "main/points.h"
d41 4
d46 4
a49 1
#include "drivers/common/meta.h"
d54 1
d56 1
a56 2
#include "intel_clear.h"
#include "intel_extensions.h"
d61 2
a62 2
#include "intel_bufmgr.h"
#include "intel_screen.h"
d65 1
d67 1
a67 2


d72 28
d102 1
a102 1
intelGetString(struct gl_context * ctx, GLenum name)
a103 1
   const struct intel_context *const intel = intel_context(ctx);
d113 1
a113 1
      switch (intel->intelScreen->deviceID) {
a152 4
      case PCI_CHIP_IGD_GM:
      case PCI_CHIP_IGD_G:
	 chipset = "Intel(R) IGD";
	 break;
a183 23
      case PCI_CHIP_B43_G:
      case PCI_CHIP_B43_G1:
         chipset = "Intel(R) B43";
         break;
      case PCI_CHIP_ILD_G:
         chipset = "Intel(R) Ironlake Desktop";
         break;
      case PCI_CHIP_ILM_G:
         chipset = "Intel(R) Ironlake Mobile";
         break;
      case PCI_CHIP_SANDYBRIDGE_GT1:
      case PCI_CHIP_SANDYBRIDGE_GT2:
      case PCI_CHIP_SANDYBRIDGE_GT2_PLUS:
	 chipset = "Intel(R) Sandybridge Desktop";
	 break;
      case PCI_CHIP_SANDYBRIDGE_M_GT1:
      case PCI_CHIP_SANDYBRIDGE_M_GT2:
      case PCI_CHIP_SANDYBRIDGE_M_GT2_PLUS:
	 chipset = "Intel(R) Sandybridge Mobile";
	 break;
      case PCI_CHIP_SANDYBRIDGE_S:
	 chipset = "Intel(R) Sandybridge Server";
	 break;
d189 1
a189 1
      (void) driGetRendererString(buffer, chipset, "", 0);
d197 58
a254 6
static void
intel_flush_front(struct gl_context *ctx)
{
   struct intel_context *intel = intel_context(ctx);
    __DRIcontext *driContext = intel->driContext;
    __DRIscreen *const screen = intel->intelScreen->driScrnPriv;
d256 18
a273 8
   if ((ctx->DrawBuffer->Name == 0) && intel->front_buffer_dirty) {
      if (screen->dri2.loader &&
          (screen->dri2.loader->base.version >= 2)
	  && (screen->dri2.loader->flushFrontBuffer != NULL) &&
          driContext->driDrawablePriv &&
	  driContext->driDrawablePriv->loaderPrivate) {
	 (*screen->dri2.loader->flushFrontBuffer)(driContext->driDrawablePriv,
						  driContext->driDrawablePriv->loaderPrivate);
d275 4
a278 7
	 /* We set the dirty bit in intel_prepare_render() if we're
	  * front buffer rendering once we get there.
	  */
	 intel->front_buffer_dirty = GL_FALSE;
      }
   }
}
d280 5
a284 208
static unsigned
intel_bits_per_pixel(const struct intel_renderbuffer *rb)
{
   return _mesa_get_format_bytes(rb->Base.Format) * 8;
}

void
intel_update_renderbuffers(__DRIcontext *context, __DRIdrawable *drawable)
{
   struct gl_framebuffer *fb = drawable->driverPrivate;
   struct intel_renderbuffer *rb;
   struct intel_region *region, *depth_region;
   struct intel_context *intel = context->driverPrivate;
   struct intel_renderbuffer *front_rb, *back_rb, *depth_rb, *stencil_rb;
   __DRIbuffer *buffers = NULL;
   __DRIscreen *screen;
   int i, count;
   unsigned int attachments[10];
   const char *region_name;

   /* If we're rendering to the fake front buffer, make sure all the
    * pending drawing has landed on the real front buffer.  Otherwise
    * when we eventually get to DRI2GetBuffersWithFormat the stale
    * real front buffer contents will get copied to the new fake front
    * buffer.
    */
   if (intel->is_front_buffer_rendering) {
      intel_flush(&intel->ctx);
      intel_flush_front(&intel->ctx);
   }

   /* Set this up front, so that in case our buffers get invalidated
    * while we're getting new buffers, we don't clobber the stamp and
    * thus ignore the invalidate. */
   drawable->lastStamp = drawable->dri2.stamp;

   if (unlikely(INTEL_DEBUG & DEBUG_DRI))
      fprintf(stderr, "enter %s, drawable %p\n", __func__, drawable);

   screen = intel->intelScreen->driScrnPriv;

   if (screen->dri2.loader
       && (screen->dri2.loader->base.version > 2)
       && (screen->dri2.loader->getBuffersWithFormat != NULL)) {

      front_rb = intel_get_renderbuffer(fb, BUFFER_FRONT_LEFT);
      back_rb = intel_get_renderbuffer(fb, BUFFER_BACK_LEFT);
      depth_rb = intel_get_renderbuffer(fb, BUFFER_DEPTH);
      stencil_rb = intel_get_renderbuffer(fb, BUFFER_STENCIL);

      i = 0;
      if ((intel->is_front_buffer_rendering ||
	   intel->is_front_buffer_reading ||
	   !back_rb) && front_rb) {
	 attachments[i++] = __DRI_BUFFER_FRONT_LEFT;
	 attachments[i++] = intel_bits_per_pixel(front_rb);
      }

      if (back_rb) {
	 attachments[i++] = __DRI_BUFFER_BACK_LEFT;
	 attachments[i++] = intel_bits_per_pixel(back_rb);
      }

      if ((depth_rb != NULL) && (stencil_rb != NULL)) {
	 attachments[i++] = __DRI_BUFFER_DEPTH_STENCIL;
	 attachments[i++] = intel_bits_per_pixel(depth_rb);
      } else if (depth_rb != NULL) {
	 attachments[i++] = __DRI_BUFFER_DEPTH;
	 attachments[i++] = intel_bits_per_pixel(depth_rb);
      } else if (stencil_rb != NULL) {
	 attachments[i++] = __DRI_BUFFER_STENCIL;
	 attachments[i++] = intel_bits_per_pixel(stencil_rb);
      }

      buffers =
	 (*screen->dri2.loader->getBuffersWithFormat)(drawable,
						      &drawable->w,
						      &drawable->h,
						      attachments, i / 2,
						      &count,
						      drawable->loaderPrivate);
   } else if (screen->dri2.loader) {
      i = 0;
      if (intel_get_renderbuffer(fb, BUFFER_FRONT_LEFT))
	 attachments[i++] = __DRI_BUFFER_FRONT_LEFT;
      if (intel_get_renderbuffer(fb, BUFFER_BACK_LEFT))
	 attachments[i++] = __DRI_BUFFER_BACK_LEFT;
      if (intel_get_renderbuffer(fb, BUFFER_DEPTH))
	 attachments[i++] = __DRI_BUFFER_DEPTH;
      if (intel_get_renderbuffer(fb, BUFFER_STENCIL))
	 attachments[i++] = __DRI_BUFFER_STENCIL;

      buffers = (*screen->dri2.loader->getBuffers)(drawable,
						   &drawable->w,
						   &drawable->h,
						   attachments, i,
						   &count,
						   drawable->loaderPrivate);
   }

   if (buffers == NULL)
      return;

   drawable->x = 0;
   drawable->y = 0;
   drawable->backX = 0;
   drawable->backY = 0;
   drawable->numClipRects = 1;
   drawable->pClipRects[0].x1 = 0;
   drawable->pClipRects[0].y1 = 0;
   drawable->pClipRects[0].x2 = drawable->w;
   drawable->pClipRects[0].y2 = drawable->h;
   drawable->numBackClipRects = 1;
   drawable->pBackClipRects[0].x1 = 0;
   drawable->pBackClipRects[0].y1 = 0;
   drawable->pBackClipRects[0].x2 = drawable->w;
   drawable->pBackClipRects[0].y2 = drawable->h;

   depth_region = NULL;
   for (i = 0; i < count; i++) {
       switch (buffers[i].attachment) {
       case __DRI_BUFFER_FRONT_LEFT:
	   rb = intel_get_renderbuffer(fb, BUFFER_FRONT_LEFT);
	   region_name = "dri2 front buffer";
	   break;

       case __DRI_BUFFER_FAKE_FRONT_LEFT:
	   rb = intel_get_renderbuffer(fb, BUFFER_FRONT_LEFT);
	   region_name = "dri2 fake front buffer";
	   break;

       case __DRI_BUFFER_BACK_LEFT:
	   rb = intel_get_renderbuffer(fb, BUFFER_BACK_LEFT);
	   region_name = "dri2 back buffer";
	   break;

       case __DRI_BUFFER_DEPTH:
	   rb = intel_get_renderbuffer(fb, BUFFER_DEPTH);
	   region_name = "dri2 depth buffer";
	   break;

       case __DRI_BUFFER_DEPTH_STENCIL:
	   rb = intel_get_renderbuffer(fb, BUFFER_DEPTH);
	   region_name = "dri2 depth / stencil buffer";
	   break;

       case __DRI_BUFFER_STENCIL:
	   rb = intel_get_renderbuffer(fb, BUFFER_STENCIL);
	   region_name = "dri2 stencil buffer";
	   break;

       case __DRI_BUFFER_ACCUM:
       default:
	   fprintf(stderr,
		   "unhandled buffer attach event, attachment type %d\n",
		   buffers[i].attachment);
	   return;
       }

       if (rb == NULL)
	  continue;

       if (rb->region && rb->region->name == buffers[i].name)
	     continue;

       if (unlikely(INTEL_DEBUG & DEBUG_DRI))
	  fprintf(stderr,
		  "attaching buffer %d, at %d, cpp %d, pitch %d\n",
		  buffers[i].name, buffers[i].attachment,
		  buffers[i].cpp, buffers[i].pitch);
       
       if (buffers[i].attachment == __DRI_BUFFER_STENCIL && depth_region) {
	  if (unlikely(INTEL_DEBUG & DEBUG_DRI))
	     fprintf(stderr, "(reusing depth buffer as stencil)\n");
	  intel_region_reference(&region, depth_region);
       }
       else
          region = intel_region_alloc_for_handle(intel->intelScreen,
						 buffers[i].cpp,
						 drawable->w,
						 drawable->h,
						 buffers[i].pitch / buffers[i].cpp,
						 buffers[i].name,
						 region_name);

       if (buffers[i].attachment == __DRI_BUFFER_DEPTH)
	  depth_region = region;

       intel_renderbuffer_set_region(intel, rb, region);
       intel_region_release(&region);

       if (buffers[i].attachment == __DRI_BUFFER_DEPTH_STENCIL) {
	  rb = intel_get_renderbuffer(fb, BUFFER_STENCIL);
	  if (rb != NULL) {
	     struct intel_region *stencil_region = NULL;

	     if (rb->region && rb->region->name == buffers[i].name)
		   continue;

	     intel_region_reference(&stencil_region, region);
	     intel_renderbuffer_set_region(intel, rb, stencil_region);
	     intel_region_release(&stencil_region);
	  }
       }
   }

   driUpdateFramebufferSize(&intel->ctx, drawable);
}
d287 2
a288 2
 * intel_prepare_render should be called anywhere that curent read/drawbuffer
 * state is required.
d290 1
a290 2
void
intel_prepare_render(struct intel_context *intel)
d292 1
a292 2
   __DRIcontext *driContext = intel->driContext;
   __DRIdrawable *drawable;
d294 1
a294 18
   drawable = driContext->driDrawablePriv;
   if (drawable && drawable->dri2.stamp != driContext->dri2.draw_stamp) {
      if (drawable->lastStamp != drawable->dri2.stamp)
	 intel_update_renderbuffers(driContext, drawable);
      intel_draw_buffer(&intel->ctx, intel->ctx.DrawBuffer);
      driContext->dri2.draw_stamp = drawable->dri2.stamp;
   }

   drawable = driContext->driReadablePriv;
   if (drawable && drawable->dri2.stamp != driContext->dri2.read_stamp) {
      if (drawable->lastStamp != drawable->dri2.stamp)
	 intel_update_renderbuffers(driContext, drawable);
      driContext->dri2.read_stamp = drawable->dri2.stamp;
   }

   /* If we're currently rendering to the front buffer, the rendering
    * that will happen next will probably dirty the front buffer.  So
    * mark it as dirty here.
d296 1
a296 2
   if (intel->is_front_buffer_rendering)
      intel->front_buffer_dirty = GL_TRUE;
d298 1
a298 22
   /* Wait for the swapbuffers before the one we just emitted, so we
    * don't get too many swaps outstanding for apps that are GPU-heavy
    * but not CPU-heavy.
    *
    * We're using intelDRI2Flush (called from the loader before
    * swapbuffer) and glFlush (for front buffer rendering) as the
    * indicator that a frame is done and then throttle when we get
    * here as we prepare to render the next frame.  At this point for
    * round trips for swap/copy and getting new buffers are done and
    * we'll spend less time waiting on the GPU.
    *
    * Unfortunately, we don't have a handle to the batch containing
    * the swap, and getting our hands on that doesn't seem worth it,
    * so we just us the first batch we emitted after the last swap.
    */
   if (intel->need_throttle && intel->first_post_swapbuffers_batch) {
      drm_intel_bo_wait_rendering(intel->first_post_swapbuffers_batch);
      drm_intel_bo_unreference(intel->first_post_swapbuffers_batch);
      intel->first_post_swapbuffers_batch = NULL;
      intel->need_throttle = GL_FALSE;
   }
}
d300 2
a301 5
static void
intel_viewport(struct gl_context *ctx, GLint x, GLint y, GLsizei w, GLsizei h)
{
    struct intel_context *intel = intel_context(ctx);
    __DRIcontext *driContext = intel->driContext;
d303 4
a306 2
    if (intel->saved_viewport)
	intel->saved_viewport(ctx, x, y, w, h);
d308 2
a309 4
    if (!intel->meta.internal_viewport_call && ctx->DrawBuffer->Name == 0) {
       dri2InvalidateDrawable(driContext->driDrawablePriv);
       dri2InvalidateDrawable(driContext->driReadablePriv);
    }
d325 1
a325 1
   { "gs",    DEBUG_GS},
d330 1
a330 1
   { "sf",    DEBUG_SF },
a339 1
   { "clip",  DEBUG_CLIP },
d345 1
a345 1
intelInvalidateState(struct gl_context * ctx, GLuint new_state)
d361 1
d363 1
a363 1
intel_flush(struct gl_context *ctx)
d370 1
a370 1
   if (intel->gen < 4)
d375 29
d407 19
a425 1
intel_glFlush(struct gl_context *ctx)
d427 8
a434 1
   struct intel_context *intel = intel_context(ctx);
d436 1
a436 4
   intel_flush(ctx);
   intel_flush_front(ctx);
   if (intel->is_front_buffer_rendering)
      intel->need_throttle = GL_TRUE;
d439 3
a441 2
void
intelFinish(struct gl_context * ctx)
d443 3
a445 2
   struct gl_framebuffer *fb = ctx->DrawBuffer;
   int i;
d447 2
a448 2
   intel_flush(ctx);
   intel_flush_front(ctx);
d450 6
a455 2
   for (i = 0; i < fb->_NumColorDrawBuffers; i++) {
       struct intel_renderbuffer *irb;
d457 12
a468 1
       irb = intel_renderbuffer(fb->_ColorDrawBuffers[i]);
d470 18
a487 2
       if (irb && irb->region)
	  drm_intel_bo_wait_rendering(irb->region->buffer);
d489 21
a509 2
   if (fb->_DepthBuffer) {
      /* XXX: Wait on buffer idle */
d511 2
d520 1
a520 1
   functions->Flush = intel_glFlush;
d525 8
a533 3
   intelInitTextureImageFuncs(functions);
   intelInitTextureSubImageFuncs(functions);
   intelInitTextureCopyImageFuncs(functions);
a534 1
   intelInitClearFuncs(functions);
a536 2
   intelInitBufferObjectFuncs(functions);
   intel_init_syncobj_functions(functions);
d542 2
a543 3
		 int api,
                 const struct gl_config * mesaVis,
                 __DRIcontext * driContextPriv,
d547 11
a557 25
   struct gl_context *ctx = &intel->ctx;
   struct gl_context *shareCtx = (struct gl_context *) sharedContextPrivate;
   __DRIscreen *sPriv = driContextPriv->driScreenPriv;
   struct intel_screen *intelScreen = sPriv->private;
   int bo_reuse_mode;
   struct gl_config visual;

   /* we can't do anything without a connection to the device */
   if (intelScreen->bufmgr == NULL)
      return GL_FALSE;

   /* Can't rely on invalidate events, fall back to glViewport hack */
   if (!driContextPriv->driScreenPriv->dri2.useInvalidate) {
      intel->saved_viewport = functions->Viewport;
      functions->Viewport = intel_viewport;
   }

   if (mesaVis == NULL) {
      memset(&visual, 0, sizeof visual);
      mesaVis = &visual;
   }

   if (!_mesa_initialize_context_for_api(&intel->ctx, api, mesaVis, shareCtx,
					 functions, (void *) intel)) {
      printf("%s: failed to init mesa context\n", __FUNCTION__);
d563 5
a567 1
   intel->driContext = driContextPriv;
d569 1
d571 2
a572 27
   intel->has_xrgb_textures = GL_TRUE;
   if (IS_GEN6(intel->intelScreen->deviceID)) {
      intel->gen = 6;
      intel->needs_ff_sync = GL_TRUE;
      intel->has_luminance_srgb = GL_TRUE;
   } else if (IS_GEN5(intel->intelScreen->deviceID)) {
      intel->gen = 5;
      intel->needs_ff_sync = GL_TRUE;
      intel->has_luminance_srgb = GL_TRUE;
   } else if (IS_965(intel->intelScreen->deviceID)) {
      intel->gen = 4;
      if (IS_G4X(intel->intelScreen->deviceID)) {
	  intel->has_luminance_srgb = GL_TRUE;
	  intel->is_g4x = GL_TRUE;
      }
   } else if (IS_9XX(intel->intelScreen->deviceID)) {
      intel->gen = 3;
      if (IS_945(intel->intelScreen->deviceID)) {
	 intel->is_945 = GL_TRUE;
      }
   } else {
      intel->gen = 2;
      if (intel->intelScreen->deviceID == PCI_CHIP_I830_M ||
	  intel->intelScreen->deviceID == PCI_CHIP_845_G) {
	 intel->has_xrgb_textures = GL_FALSE;
      }
   }
d575 2
a576 1
                       sPriv->myNum, (intel->gen >= 4) ? "i965" : "i915");
d582 2
a583 1
   intel->bufmgr = intelScreen->bufmgr;
d585 1
a585 8
   bo_reuse_mode = driQueryOptioni(&intel->optionCache, "bo_reuse");
   switch (bo_reuse_mode) {
   case DRI_CONF_BO_REUSE_DISABLED:
      break;
   case DRI_CONF_BO_REUSE_ALL:
      intel_bufmgr_gem_enable_reuse(intel->bufmgr);
      break;
   }
d591 1
a591 7
      unsigned int value = atoi(getenv("INTEL_STRICT_CONFORMANCE"));
      if (value > 0) {
         intel->conformance_mode = value;
      }
      else {
         intel->conformance_mode = 1;
      }
d594 1
a594 1
   if (intel->conformance_mode > 0) {
a614 2
   ctx->Const.MaxSamples = 1.0;

d616 1
a616 1
    * It depend on constants in __struct gl_contextRec::Const
d620 1
a620 8
   meta_init_metaops(ctx, &intel->meta);
   if (intel->gen >= 4) {
      if (MAX_WIDTH > 8192)
	 ctx->Const.MaxRenderbufferSize = 8192;
   } else {
      if (MAX_WIDTH > 2048)
	 ctx->Const.MaxRenderbufferSize = 2048;
   }
a631 2
   _mesa_meta_init(ctx);

d649 1
a649 1
   if (intel->gen >= 4)
d654 13
a666 9
   switch (ctx->API) {
   case API_OPENGL:
      intelInitExtensions(ctx);
      break;
   case API_OPENGLES:
      break;
   case API_OPENGLES2:
      intelInitExtensionsES2(ctx);
      break;
d669 2
d675 3
d679 2
d682 1
a691 3
   intel->use_texture_tiling = driQueryOptionb(&intel->optionCache,
					       "texture_tiling");
   intel->use_early_z = driQueryOptionb(&intel->optionCache, "early_z");
d698 1
d702 4
a705 9
   if (driQueryOptionb(&intel->optionCache, "always_flush_batch")) {
      fprintf(stderr, "flushing batchbuffer before/after each draw call\n");
      intel->always_flush_batch = 1;
   }

   if (driQueryOptionb(&intel->optionCache, "always_flush_cache")) {
      fprintf(stderr, "flushing GPU caches before/after each draw call\n");
      intel->always_flush_cache = 1;
   }
d711 1
a711 1
intelDestroyContext(__DRIcontext * driContextPriv)
d718 2
a721 4
      _mesa_meta_free(&intel->ctx);

      meta_destroy_metaops(&intel->meta);

d724 1
d730 1
a730 1
      intel->Fallback = 0x0;      /* don't call _swrast_Flush later */
a732 1
      intel->batch = NULL;
d734 18
a751 8
      free(intel->prim.vb);
      intel->prim.vb = NULL;
      drm_intel_bo_unreference(intel->prim.vb_bo);
      intel->prim.vb_bo = NULL;
      drm_intel_bo_unreference(intel->first_post_swapbuffers_batch);
      intel->first_post_swapbuffers_batch = NULL;

      driDestroyOptionCache(&intel->optionCache);
d756 1
a756 2
      FREE(intel);
      driContextPriv->driverPrivate = NULL;
d761 1
a761 1
intelUnbindContext(__DRIcontext * driContextPriv)
a762 3
   /* Unset current context and dispath table */
   _mesa_make_current(NULL, NULL, NULL);

d767 3
a769 3
intelMakeCurrent(__DRIcontext * driContextPriv,
                 __DRIdrawable * driDrawPriv,
                 __DRIdrawable * driReadPriv)
d771 1
a771 2
   struct intel_context *intel;
   GET_CURRENT_CONTEXT(curCtx);
d773 37
a809 4
   if (driContextPriv)
      intel = (struct intel_context *) driContextPriv->driverPrivate;
   else
      intel = NULL;
d811 2
a812 7
   /* According to the glXMakeCurrent() man page: "Pending commands to
    * the previous context, if any, are flushed before it is released."
    * But only flush if we're actually changing contexts.
    */
   if (intel_context(curCtx) && intel_context(curCtx) != intel) {
      _mesa_flush(curCtx);
   }
d814 2
a815 11
   if (driContextPriv) {
      struct gl_framebuffer *fb, *readFb;
      
      if (driDrawPriv == NULL && driReadPriv == NULL) {
	 fb = _mesa_get_incomplete_framebuffer();
	 readFb = _mesa_get_incomplete_framebuffer();
      } else {
	 fb = driDrawPriv->driverPrivate;
	 readFb = driReadPriv->driverPrivate;
	 driContextPriv->dri2.draw_stamp = driDrawPriv->dri2.stamp - 1;
	 driContextPriv->dri2.read_stamp = driReadPriv->dri2.stamp - 1;
d818 32
a849 8
      intel_prepare_render(intel);
      _mesa_make_current(&intel->ctx, fb, readFb);
      
      /* We do this in intel_prepare_render() too, but intel->ctx.DrawBuffer
       * is NULL at that point.  We can't call _mesa_makecurrent()
       * first, since we need the buffer size for the initial
       * viewport.  So just call intel_draw_buffer() again here. */
      intel_draw_buffer(&intel->ctx, intel->ctx.DrawBuffer);
d857 169
@


