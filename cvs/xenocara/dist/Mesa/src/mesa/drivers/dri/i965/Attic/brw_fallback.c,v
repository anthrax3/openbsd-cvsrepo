head	1.7;
access;
symbols
	OPENBSD_5_4:1.6.0.4
	OPENBSD_5_4_BASE:1.6
	OPENBSD_5_3:1.6.0.2
	OPENBSD_5_3_BASE:1.6
	OPENBSD_5_2:1.5.0.4
	OPENBSD_5_2_BASE:1.5
	OPENBSD_5_1_BASE:1.5
	OPENBSD_5_1:1.5.0.2
	v7_10_3:1.1.1.4
	OPENBSD_5_0:1.4.0.6
	OPENBSD_5_0_BASE:1.4
	OPENBSD_4_9:1.4.0.2
	OPENBSD_4_9_BASE:1.4
	OPENBSD_4_8:1.4.0.4
	OPENBSD_4_8_BASE:1.4
	OPENBSD_4_7:1.3.0.4
	OPENBSD_4_7_BASE:1.3
	OPENBSD_4_6:1.3.0.2
	OPENBSD_4_6_BASE:1.3
	OPENBSD_4_5:1.2.0.2
	OPENBSD_4_5_BASE:1.2
	OPENBSD_4_4:1.1.1.3.0.4
	OPENBSD_4_4_BASE:1.1.1.3
	OPENBSD_4_3_BASE:1.1.1.3
	OPENBSD_4_3:1.1.1.3.0.2
	v7_0_1:1.1.1.3
	OPENBSD_4_2:1.1.1.2.0.2
	OPENBSD_4_2_BASE:1.1.1.2
	v6_5_2:1.1.1.2
	v6_5_1:1.1.1.1
	mesa:1.1.1;
locks; strict;
comment	@ * @;


1.7
date	2013.09.05.14.04.18;	author jsg;	state dead;
branches;
next	1.6;

1.6
date	2012.08.17.13.58.15;	author mpi;	state Exp;
branches;
next	1.5;

1.5
date	2011.10.23.13.37.39;	author matthieu;	state Exp;
branches;
next	1.4;

1.4
date	2010.05.22.20.06.18;	author matthieu;	state Exp;
branches;
next	1.3;

1.3
date	2009.05.17.20.26.39;	author matthieu;	state Exp;
branches;
next	1.2;

1.2
date	2008.11.02.14.58.15;	author matthieu;	state Exp;
branches;
next	1.1;

1.1
date	2006.11.25.18.52.43;	author matthieu;	state Exp;
branches
	1.1.1.1;
next	;

1.1.1.1
date	2006.11.25.18.52.43;	author matthieu;	state Exp;
branches;
next	1.1.1.2;

1.1.1.2
date	2007.03.03.11.57.15;	author matthieu;	state Exp;
branches;
next	1.1.1.3;

1.1.1.3
date	2007.11.24.17.28.34;	author matthieu;	state Exp;
branches;
next	1.1.1.4;

1.1.1.4
date	2011.10.23.13.29.36;	author matthieu;	state Exp;
branches;
next	;


desc
@@


1.7
log
@Merge Mesa 9.2.0
@
text
@/**************************************************************************
 * 
 * Copyright 2005 Tungsten Graphics, Inc., Cedar Park, Texas.
 * All Rights Reserved.
 * 
 * Permission is hereby granted, free of charge, to any person obtaining a
 * copy of this software and associated documentation files (the
 * "Software"), to deal in the Software without restriction, including
 * without limitation the rights to use, copy, modify, merge, publish,
 * distribute, sub license, and/or sell copies of the Software, and to
 * permit persons to whom the Software is furnished to do so, subject to
 * the following conditions:
 * 
 * The above copyright notice and this permission notice (including the
 * next paragraph) shall be included in all copies or substantial portions
 * of the Software.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
 * OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT.
 * IN NO EVENT SHALL TUNGSTEN GRAPHICS AND/OR ITS SUPPLIERS BE LIABLE FOR
 * ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
 * SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 * 
 **************************************************************************/

#include "main/glheader.h"
#include "main/context.h"
#include "main/enums.h"
#include "main/imports.h"
#include "main/macros.h"
#include "main/mtypes.h"

#include "swrast_setup/swrast_setup.h"
#include "swrast/swrast.h"
#include "tnl/tnl.h"
#include "brw_context.h"

#define FILE_DEBUG_FLAG DEBUG_FALLBACKS

static GLboolean do_check_fallback(struct brw_context *brw)
{
   struct gl_context *ctx = &brw->intel.ctx;
   GLuint i;

   if (brw->intel.no_rast) {
      DBG("FALLBACK: rasterization disabled\n");
      return GL_TRUE;
   }

   /* _NEW_RENDERMODE
    */
   if (ctx->RenderMode != GL_RENDER) {
      DBG("FALLBACK: render mode\n");
      return GL_TRUE;
   }

   /* _NEW_TEXTURE:
    */
   for (i = 0; i < BRW_MAX_TEX_UNIT; i++) {
      struct gl_texture_unit *texUnit = &ctx->Texture.Unit[i];
      if (texUnit->_ReallyEnabled) {
	 struct gl_texture_object *tex_obj = texUnit->_Current;
	 struct gl_texture_image *texImage = tex_obj->Image[0][tex_obj->BaseLevel];
	 if (texImage->Border) {
	    DBG("FALLBACK: texture border\n");
	    return GL_TRUE;
	 }
      }
   }

   return GL_FALSE;
}

static void check_fallback(struct brw_context *brw)
{
   brw->intel.Fallback = do_check_fallback(brw);
}

const struct brw_tracked_state brw_check_fallback = {
   .dirty = {
      .mesa = _NEW_RENDERMODE | _NEW_TEXTURE | _NEW_STENCIL,
      .brw  = 0,
      .cache = 0
   },
   .prepare = check_fallback
};




/**
 * Called by the INTEL_FALLBACK() macro.
 * NOTE: this is a no-op for the i965 driver.  The brw->intel.Fallback
 * field is treated as a boolean, not a bitmask.  It's only set in a
 * couple of places.
 */
void intelFallback( struct intel_context *intel, GLuint bit, GLboolean mode )
{
}



@


1.6
log
@Upate to libGL 7.11.2

Tested by jsg@@, matthieu@@ and ajacoutot@@, ok mattieu@@
@
text
@@


1.5
log
@Merge Mesa 7.10.3
@
text
@a38 2
#include "intel_fbo.h"
#include "intel_regions.h"
d64 2
a65 2
	 struct intel_texture_object *intelObj = intel_texture_object(texUnit->_Current);
	 struct gl_texture_image *texImage = intelObj->base.Image[0][intelObj->firstLevel];
a71 35
   
   /* _NEW_STENCIL 
    */
   if (ctx->Stencil._Enabled &&
       (ctx->DrawBuffer->Name == 0 && !brw->intel.hw_stencil)) {
      DBG("FALLBACK: stencil\n");
      return GL_TRUE;
   }

   /* _NEW_BUFFERS */
   if (!brw->has_surface_tile_offset) {
      for (i = 0; i < ctx->DrawBuffer->_NumColorDrawBuffers; i++) {
	 struct gl_renderbuffer *rb = ctx->DrawBuffer->_ColorDrawBuffers[i];
	 struct intel_renderbuffer *irb = intel_renderbuffer(rb);

	 /* The original gen4 hardware couldn't set up WM surfaces pointing
	  * at an offset within a tile, which can happen when rendering to
	  * anything but the base level of a texture or the +X face/0 depth.
	  * This was fixed with the 4 Series hardware.
	  *
	  * For these original chips, you would have to make the depth and
	  * color destination surfaces include information on the texture
	  * type, LOD, face, and various limits to use them as a destination.
	  * I would have done this, but there's also a nasty requirement that
	  * the depth and the color surfaces all be of the same LOD, which
	  * may be a worse requirement than this alignment.  (Also, we may
	  * want to just demote the texture to untiled, instead).
	  */
	 if (irb->region && irb->region->tiling != I915_TILING_NONE &&
	     (irb->region->draw_offset & 4095)) {
	    DBG("FALLBACK: non-tile-aligned destination for tiled FBO\n");
	    return GL_TRUE;
	 }
      }
   }
d83 1
a83 1
      .mesa = _NEW_BUFFERS | _NEW_RENDERMODE | _NEW_TEXTURE | _NEW_STENCIL,
@


1.4
log
@Update to Mesa 7.8.1. Tested on a bulk ports build by naddy@@, ok oga@@.
@
text
@d46 1
a46 1
   GLcontext *ctx = &brw->intel.ctx;
@


1.3
log
@Update to Mesa 7.4.2. Tested by oga@@, ckuethe@@ and naddy@@.
@
text
@d39 2
a40 3
#include "brw_fallback.h"

#include "glapi/glapi.h"
d77 1
a77 1
   if (ctx->Stencil.Enabled &&
d83 26
d130 5
a134 1
/* Not used:
@


1.2
log
@Mesa 7.2, Tested by ckuethe@@, naddy@@, oga@@, and others.
@
text
@d28 7
a37 1
#include "context.h"
d41 1
a41 6
#include "glheader.h"
#include "enums.h"
#include "glapi.h"
#include "imports.h"
#include "macros.h"
#include "mtypes.h"
a49 5
   /* BRW_NEW_METAOPS
    */
   if (brw->metaops.active)
      return GL_FALSE;

a55 3
    *
    * XXX: need to save/restore RenderMode in metaops state, or
    * somehow move to a new attribs pointer:
d65 1
a65 1
      struct gl_texture_unit *texUnit = &brw->attribs.Texture->Unit[i];
d69 1
a69 4
	 if (texImage->Border ||
         ((texImage->_BaseFormat == GL_DEPTH_COMPONENT) &&
          ((texImage->TexObject->WrapS == GL_CLAMP_TO_BORDER) || 
           (texImage->TexObject->WrapT == GL_CLAMP_TO_BORDER)))) {
d78 2
a79 2
   if (brw->attribs.Stencil->Enabled && 
       !brw->intel.hw_stencil) {
d88 1
a88 1
static int check_fallback(struct brw_context *brw)
a90 1
   return 0;
d96 1
a96 1
      .brw  = BRW_NEW_METAOPS,
@


1.1
log
@Initial revision
@
text
@a32 2
#include "brw_exec.h"
#include "brw_save.h"
a40 293
#include "dispatch.h"


typedef void (*attr_func)( GLcontext *ctx, GLint target, const GLfloat * );


/* Wrapper functions in case glVertexAttrib*fvNV doesn't exist */
static void VertexAttrib1fvNV(GLcontext *ctx, GLint target, const GLfloat *v)
{
   CALL_VertexAttrib1fvNV(ctx->Exec, (target, v));
}

static void VertexAttrib2fvNV(GLcontext *ctx, GLint target, const GLfloat *v)
{
   CALL_VertexAttrib2fvNV(ctx->Exec, (target, v));
}

static void VertexAttrib3fvNV(GLcontext *ctx, GLint target, const GLfloat *v)
{
   CALL_VertexAttrib3fvNV(ctx->Exec, (target, v));
}

static void VertexAttrib4fvNV(GLcontext *ctx, GLint target, const GLfloat *v)
{
   CALL_VertexAttrib4fvNV(ctx->Exec, (target, v));
}

static attr_func vert_attrfunc[4] = {
   VertexAttrib1fvNV,
   VertexAttrib2fvNV,
   VertexAttrib3fvNV,
   VertexAttrib4fvNV
};

#if 0
static void VertexAttrib1fvARB(GLcontext *ctx, GLint target, const GLfloat *v)
{
   CALL_VertexAttrib1fvARB(ctx->Exec, (target, v));
}

static void VertexAttrib2fvARB(GLcontext *ctx, GLint target, const GLfloat *v)
{
   CALL_VertexAttrib2fvARB(ctx->Exec, (target, v));
}

static void VertexAttrib3fvARB(GLcontext *ctx, GLint target, const GLfloat *v)
{
   CALL_VertexAttrib3fvARB(ctx->Exec, (target, v));
}

static void VertexAttrib4fvARB(GLcontext *ctx, GLint target, const GLfloat *v)
{
   CALL_VertexAttrib4fvARB(ctx->Exec, (target, v));
}


static attr_func vert_attrfunc_arb[4] = {
   VertexAttrib1fvARB,
   VertexAttrib2fvARB,
   VertexAttrib3fvARB,
   VertexAttrib4fvARB
};
#endif






static void mat_attr1fv( GLcontext *ctx, GLint target, const GLfloat *v )
{
   switch (target) {
   case BRW_ATTRIB_MAT_FRONT_SHININESS:
      CALL_Materialfv(ctx->Exec, ( GL_FRONT, GL_SHININESS, v ));
      break;
   case BRW_ATTRIB_MAT_BACK_SHININESS:
      CALL_Materialfv(ctx->Exec, ( GL_BACK, GL_SHININESS, v ));
      break;
   }
}


static void mat_attr3fv( GLcontext *ctx, GLint target, const GLfloat *v )
{
   switch (target) {
   case BRW_ATTRIB_MAT_FRONT_INDEXES:
      CALL_Materialfv(ctx->Exec, ( GL_FRONT, GL_COLOR_INDEXES, v ));
      break;
   case BRW_ATTRIB_MAT_BACK_INDEXES:
      CALL_Materialfv(ctx->Exec, ( GL_BACK, GL_COLOR_INDEXES, v ));
      break;
   }
}


static void mat_attr4fv( GLcontext *ctx, GLint target, const GLfloat *v )
{
   switch (target) {
   case BRW_ATTRIB_MAT_FRONT_EMISSION:
      CALL_Materialfv(ctx->Exec, ( GL_FRONT, GL_EMISSION, v ));
      break;
   case BRW_ATTRIB_MAT_BACK_EMISSION:
      CALL_Materialfv(ctx->Exec, ( GL_BACK, GL_EMISSION, v ));
      break;
   case BRW_ATTRIB_MAT_FRONT_AMBIENT:
      CALL_Materialfv(ctx->Exec, ( GL_FRONT, GL_AMBIENT, v ));
      break;
   case BRW_ATTRIB_MAT_BACK_AMBIENT:
      CALL_Materialfv(ctx->Exec, ( GL_BACK, GL_AMBIENT, v ));
      break;
   case BRW_ATTRIB_MAT_FRONT_DIFFUSE:
      CALL_Materialfv(ctx->Exec, ( GL_FRONT, GL_DIFFUSE, v ));
      break;
   case BRW_ATTRIB_MAT_BACK_DIFFUSE:
      CALL_Materialfv(ctx->Exec, ( GL_BACK, GL_DIFFUSE, v ));
      break;
   case BRW_ATTRIB_MAT_FRONT_SPECULAR:
      CALL_Materialfv(ctx->Exec, ( GL_FRONT, GL_SPECULAR, v ));
      break;
   case BRW_ATTRIB_MAT_BACK_SPECULAR:
      CALL_Materialfv(ctx->Exec, ( GL_BACK, GL_SPECULAR, v ));
      break;
   }
}


static attr_func mat_attrfunc[4] = {
   mat_attr1fv,
   NULL,
   mat_attr3fv,
   mat_attr4fv
};


static void index_attr1fv(GLcontext *ctx, GLint target, const GLfloat *v)
{
   (void) target;
   CALL_Indexf(ctx->Exec, (v[0]));
}

static void edgeflag_attr1fv(GLcontext *ctx, GLint target, const GLfloat *v)
{
   (void) target;
   CALL_EdgeFlag(ctx->Exec, ((GLboolean)(v[0] == 1.0)));
}

struct loopback_attr {
   GLint target;
   GLint sz;
   attr_func func;
};

/* Don't emit ends and begins on wrapped primitives.  Don't replay
 * wrapped vertices.  If we get here, it's probably because the the
 * precalculated wrapping is wrong.
 */
static void loopback_prim( GLcontext *ctx,
			   const GLfloat *buffer,
			   const struct brw_draw_prim *prim,
			   GLuint wrap_count,
			   GLuint vertex_size,
			   const struct loopback_attr *la, GLuint nr )
{
   GLint start = prim->start;
   GLint end = start + prim->count;
   const GLfloat *data;
   GLint j;
   GLuint k;

   if (0)
      _mesa_printf("loopback prim %s(%s,%s) verts %d..%d\n",
		   _mesa_lookup_enum_by_nr(prim->mode),
		   prim->begin ? "begin" : "..",
		   prim->end ? "end" : "..",
		   start, 
		   end);

   if (prim->begin) {
      CALL_Begin(GET_DISPATCH(), ( prim->mode ));
   }
   else {
      assert(start == 0);
      start += wrap_count;
   }

   data = buffer + start * vertex_size;

   for (j = start ; j < end ; j++) {
      const GLfloat *tmp = data + la[0].sz;

      for (k = 1 ; k < nr ; k++) {
	 la[k].func( ctx, la[k].target, tmp );
	 tmp += la[k].sz;
      }
	 
      /* Fire the vertex
       */
      la[0].func( ctx, BRW_ATTRIB_POS, data );
      data = tmp;
   }

   if (prim->end) {
      CALL_End(GET_DISPATCH(), ());
   }
}

/* Primitives generated by DrawArrays/DrawElements/Rectf may be
 * caught here.  If there is no primitive in progress, execute them
 * normally, otherwise need to track and discard the generated
 * primitives.
 */
static void loopback_weak_prim( GLcontext *ctx,
				const struct brw_draw_prim *prim )
{
   /* Use the prim_weak flag to ensure that if this primitive
    * wraps, we don't mistake future vertex_lists for part of the
    * surrounding primitive.
    *
    * While this flag is set, we are simply disposing of data
    * generated by an operation now known to be a noop.
    */
   if (prim->begin)
      ctx->Driver.CurrentExecPrimitive |= BRW_SAVE_PRIM_WEAK;
   if (prim->end)
      ctx->Driver.CurrentExecPrimitive &= ~BRW_SAVE_PRIM_WEAK;
}


void brw_loopback_vertex_list( GLcontext *ctx,
			       const GLfloat *buffer,
			       const GLubyte *attrsz,
			       const struct brw_draw_prim *prim,
			       GLuint prim_count,
			       GLuint wrap_count,
			       GLuint vertex_size)
{
   struct loopback_attr la[BRW_ATTRIB_MAX];
   GLuint i, nr = 0;

   for (i = 0 ; i <= BRW_ATTRIB_TEX7 ; i++) {
      if (attrsz[i]) {
	 la[nr].target = i;
	 la[nr].sz = attrsz[i];
	 la[nr].func = vert_attrfunc[attrsz[i]-1];
	 nr++;
      }
   }

   for (i = BRW_ATTRIB_MAT_FRONT_AMBIENT ; 
	i <= BRW_ATTRIB_MAT_BACK_INDEXES ; 
	i++) {
      if (attrsz[i]) {
	 la[nr].target = i;
	 la[nr].sz = attrsz[i];
	 la[nr].func = mat_attrfunc[attrsz[i]-1];
	 nr++;
      }
   }

   if (attrsz[BRW_ATTRIB_EDGEFLAG]) {
      la[nr].target = BRW_ATTRIB_EDGEFLAG;
      la[nr].sz = attrsz[BRW_ATTRIB_EDGEFLAG];
      la[nr].func = edgeflag_attr1fv;
      nr++;
   }

   if (attrsz[BRW_ATTRIB_INDEX]) {
      la[nr].target = BRW_ATTRIB_INDEX;
      la[nr].sz = attrsz[BRW_ATTRIB_INDEX];
      la[nr].func = index_attr1fv;
      nr++;
   }

   /* XXX ARB vertex attribs */

   for (i = 0 ; i < prim_count ; i++) {
      if ((prim[i].mode & BRW_SAVE_PRIM_WEAK) &&
	  (ctx->Driver.CurrentExecPrimitive != PRIM_OUTSIDE_BEGIN_END))
      {
	 loopback_weak_prim( ctx, &prim[i] );
      }
      else
      {
	 loopback_prim( ctx, buffer, &prim[i], wrap_count, vertex_size, la, nr );
      }
   }
}






d42 1
d48 1
a48 1
   
d54 2
a55 7
   if (brw->intel.no_rast)
      return GL_TRUE;
   
   /* _NEW_BUFFERS
    */
   if (ctx->DrawBuffer->_ColorDrawBufferMask[0] != BUFFER_BIT_FRONT_LEFT &&
       ctx->DrawBuffer->_ColorDrawBufferMask[0] != BUFFER_BIT_BACK_LEFT)
d57 1
d64 2
a65 1
   if (ctx->RenderMode != GL_RENDER)
d67 1
d76 5
a80 1
	 if (texImage->Border)
d82 1
d90 1
d98 1
a98 1
static void check_fallback(struct brw_context *brw)
d101 1
d110 1
a110 1
   .update = check_fallback
a114 56

/* If there is a fallback, fallback to software rasterization and
 * transformation together.  There is never a requirement to have
 * software t&l but hardware rasterization.
 * 
 * Further, all fallbacks are based on GL state, not on eg. primitive
 * or vertex data.
 */

static void do_fallback( struct brw_context *brw,
			 GLboolean fallback )
{
   GLcontext *ctx = &brw->intel.ctx;

   /* flush:
    */
   ctx->Driver.Flush( ctx );

   if (fallback) {
      _swsetup_Wakeup( ctx );
      _tnl_wakeup_exec( ctx );	

      /* Need this because tnl_wakeup_exec does too much: 
       */
      brw_save_wakeup(ctx);
      brw_save_fallback(ctx, GL_TRUE);
   }
   else {
      /* Flush vertices and copy-to-current:
       */
      FLUSH_CURRENT(ctx, 0); 

      _swrast_flush( ctx );

      brw_exec_wakeup(ctx);

      /* Need this because tnl_wakeup_exec does too much: 
       */
      brw_save_wakeup(ctx);
      brw_save_fallback(ctx, GL_FALSE);	 
   }
}


void brw_fallback( GLcontext *ctx )
{
   struct brw_context *brw = brw_context(ctx);
   do_fallback(brw, 1);
}


void brw_unfallback( GLcontext *ctx )
{
   struct brw_context *brw = brw_context(ctx);
   do_fallback(brw, 0);
}
@


1.1.1.1
log
@Import MesaLibs 6.5.1. (in dist/ since its code is shared between lib 
and xserver)...
@
text
@@


1.1.1.2
log
@import MesaLibs version 6.5.2
@
text
@a282 3
      if (i == BRW_ATTRIB_INDEX || i == BRW_ATTRIB_EDGEFLAG)
                   continue;

@


1.1.1.3
log
@Mesa 7.0.1
@
text
@d33 2
d43 291
d407 56
@


1.1.1.4
log
@Import Mesa 7.10.3
@
text
@a27 7
#include "main/glheader.h"
#include "main/context.h"
#include "main/enums.h"
#include "main/imports.h"
#include "main/macros.h"
#include "main/mtypes.h"

d31 1
d33 13
a45 2
#include "intel_fbo.h"
#include "intel_regions.h"
a46 1
#define FILE_DEBUG_FLAG DEBUG_FALLBACKS
d50 1
a50 1
   struct gl_context *ctx = &brw->intel.ctx;
d52 5
d58 7
a64 2
   if (brw->intel.no_rast) {
      DBG("FALLBACK: rasterization disabled\n");
a65 1
   }
d68 3
d72 1
a72 2
   if (ctx->RenderMode != GL_RENDER) {
      DBG("FALLBACK: render mode\n");
a73 1
   }
d78 1
a78 1
      struct gl_texture_unit *texUnit = &ctx->Texture.Unit[i];
d82 1
a82 2
	 if (texImage->Border) {
	    DBG("FALLBACK: texture border\n");
a83 1
	 }
d89 2
a90 3
   if (ctx->Stencil._Enabled &&
       (ctx->DrawBuffer->Name == 0 && !brw->intel.hw_stencil)) {
      DBG("FALLBACK: stencil\n");
a93 26
   /* _NEW_BUFFERS */
   if (!brw->has_surface_tile_offset) {
      for (i = 0; i < ctx->DrawBuffer->_NumColorDrawBuffers; i++) {
	 struct gl_renderbuffer *rb = ctx->DrawBuffer->_ColorDrawBuffers[i];
	 struct intel_renderbuffer *irb = intel_renderbuffer(rb);

	 /* The original gen4 hardware couldn't set up WM surfaces pointing
	  * at an offset within a tile, which can happen when rendering to
	  * anything but the base level of a texture or the +X face/0 depth.
	  * This was fixed with the 4 Series hardware.
	  *
	  * For these original chips, you would have to make the depth and
	  * color destination surfaces include information on the texture
	  * type, LOD, face, and various limits to use them as a destination.
	  * I would have done this, but there's also a nasty requirement that
	  * the depth and the color surfaces all be of the same LOD, which
	  * may be a worse requirement than this alignment.  (Also, we may
	  * want to just demote the texture to untiled, instead).
	  */
	 if (irb->region && irb->region->tiling != I915_TILING_NONE &&
	     (irb->region->draw_offset & 4095)) {
	    DBG("FALLBACK: non-tile-aligned destination for tiled FBO\n");
	    return GL_TRUE;
	 }
      }
   }
d106 1
a106 1
      .brw  = 0,
d109 1
a109 1
   .prepare = check_fallback
d115 1
a115 5
/**
 * Called by the INTEL_FALLBACK() macro.
 * NOTE: this is a no-op for the i965 driver.  The brw->intel.Fallback
 * field is treated as a boolean, not a bitmask.  It's only set in a
 * couple of places.
@


