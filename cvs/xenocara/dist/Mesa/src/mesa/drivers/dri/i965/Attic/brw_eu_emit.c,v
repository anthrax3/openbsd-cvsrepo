head	1.12;
access;
symbols
	OPENBSD_5_8:1.11.0.4
	OPENBSD_5_8_BASE:1.11
	OPENBSD_5_7:1.11.0.2
	OPENBSD_5_7_BASE:1.11
	v10_2_9:1.1.1.7
	v10_4_3:1.1.1.6
	v10_2_7:1.1.1.5
	OPENBSD_5_6:1.9.0.2
	OPENBSD_5_6_BASE:1.9
	v10_2_3:1.1.1.5
	OPENBSD_5_5:1.8.0.2
	OPENBSD_5_5_BASE:1.8
	v9_2_5:1.1.1.4
	v9_2_3:1.1.1.4
	v9_2_2:1.1.1.4
	v9_2_1:1.1.1.4
	v9_2_0:1.1.1.4
	OPENBSD_5_4:1.7.0.4
	OPENBSD_5_4_BASE:1.7
	OPENBSD_5_3:1.7.0.2
	OPENBSD_5_3_BASE:1.7
	OPENBSD_5_2:1.6.0.4
	OPENBSD_5_2_BASE:1.6
	OPENBSD_5_1_BASE:1.6
	OPENBSD_5_1:1.6.0.2
	v7_10_3:1.1.1.3
	OPENBSD_5_0:1.5.0.6
	OPENBSD_5_0_BASE:1.5
	OPENBSD_4_9:1.5.0.2
	OPENBSD_4_9_BASE:1.5
	OPENBSD_4_8:1.5.0.4
	OPENBSD_4_8_BASE:1.5
	OPENBSD_4_7:1.4.0.4
	OPENBSD_4_7_BASE:1.4
	OPENBSD_4_6:1.4.0.2
	OPENBSD_4_6_BASE:1.4
	OPENBSD_4_5:1.3.0.2
	OPENBSD_4_5_BASE:1.3
	OPENBSD_4_4:1.2.0.2
	OPENBSD_4_4_BASE:1.2
	OPENBSD_4_3_BASE:1.1.1.2
	OPENBSD_4_3:1.1.1.2.0.2
	v7_0_1:1.1.1.2
	OPENBSD_4_2:1.1.1.1.0.2
	OPENBSD_4_2_BASE:1.1.1.1
	v6_5_2:1.1.1.1
	v6_5_1:1.1.1.1
	mesa:1.1.1;
locks; strict;
comment	@ * @;


1.12
date	2015.12.23.05.17.49;	author jsg;	state dead;
branches;
next	1.11;
commitid	TnlogFl9nOv2eaRf;

1.11
date	2015.02.20.23.09.58;	author jsg;	state Exp;
branches;
next	1.10;
commitid	4ry2gvZGMXkCUD2n;

1.10
date	2015.01.25.14.41.20;	author jsg;	state Exp;
branches;
next	1.9;
commitid	mcxB0JvoI9gTDYXU;

1.9
date	2014.07.09.21.08.59;	author jsg;	state Exp;
branches;
next	1.8;
commitid	WPD6rgPryPkvXOr9;

1.8
date	2013.09.05.14.04.18;	author jsg;	state Exp;
branches;
next	1.7;

1.7
date	2012.08.17.13.58.15;	author mpi;	state Exp;
branches;
next	1.6;

1.6
date	2011.10.23.13.37.39;	author matthieu;	state Exp;
branches;
next	1.5;

1.5
date	2010.05.22.20.06.18;	author matthieu;	state Exp;
branches;
next	1.4;

1.4
date	2009.05.17.20.26.39;	author matthieu;	state Exp;
branches;
next	1.3;

1.3
date	2008.11.02.14.58.15;	author matthieu;	state Exp;
branches;
next	1.2;

1.2
date	2008.05.31.16.36.48;	author matthieu;	state Exp;
branches;
next	1.1;

1.1
date	2006.11.25.18.52.42;	author matthieu;	state Exp;
branches
	1.1.1.1;
next	;

1.1.1.1
date	2006.11.25.18.52.42;	author matthieu;	state Exp;
branches;
next	1.1.1.2;

1.1.1.2
date	2007.11.24.17.28.34;	author matthieu;	state Exp;
branches;
next	1.1.1.3;

1.1.1.3
date	2011.10.23.13.29.36;	author matthieu;	state Exp;
branches;
next	1.1.1.4;

1.1.1.4
date	2013.09.05.13.15.31;	author jsg;	state Exp;
branches;
next	1.1.1.5;

1.1.1.5
date	2014.07.09.20.34.49;	author jsg;	state Exp;
branches;
next	1.1.1.6;
commitid	3JhLfwcuBALP0ZR7;

1.1.1.6
date	2015.01.25.14.11.35;	author jsg;	state Exp;
branches;
next	1.1.1.7;
commitid	ce2W5rH5aF7VS9gi;

1.1.1.7
date	2015.02.20.22.48.42;	author jsg;	state Exp;
branches;
next	;
commitid	F54a1i0WXHMxq7kE;


desc
@@


1.12
log
@remove the now unused Mesa 10.2.9 code
@
text
@/*
 Copyright (C) Intel Corp.  2006.  All Rights Reserved.
 Intel funded Tungsten Graphics to
 develop this 3D driver.

 Permission is hereby granted, free of charge, to any person obtaining
 a copy of this software and associated documentation files (the
 "Software"), to deal in the Software without restriction, including
 without limitation the rights to use, copy, modify, merge, publish,
 distribute, sublicense, and/or sell copies of the Software, and to
 permit persons to whom the Software is furnished to do so, subject to
 the following conditions:

 The above copyright notice and this permission notice (including the
 next paragraph) shall be included in all copies or substantial
 portions of the Software.

 THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
 IN NO EVENT SHALL THE COPYRIGHT OWNER(S) AND/OR ITS SUPPLIERS BE
 LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
 OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
 WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

 **********************************************************************/
 /*
  * Authors:
  *   Keith Whitwell <keithw@@vmware.com>
  */


#include "brw_context.h"
#include "brw_defines.h"
#include "brw_eu.h"

#include "glsl/ralloc.h"

/***********************************************************************
 * Internal helper for constructing instructions
 */

static void guess_execution_size(struct brw_compile *p,
				 struct brw_instruction *insn,
				 struct brw_reg reg)
{
   if (reg.width == BRW_WIDTH_8 && p->compressed)
      insn->header.execution_size = BRW_EXECUTE_16;
   else
      insn->header.execution_size = reg.width;	/* note - definitions are compatible */
}


/**
 * Prior to Sandybridge, the SEND instruction accepted non-MRF source
 * registers, implicitly moving the operand to a message register.
 *
 * On Sandybridge, this is no longer the case.  This function performs the
 * explicit move; it should be called before emitting a SEND instruction.
 */
void
gen6_resolve_implied_move(struct brw_compile *p,
			  struct brw_reg *src,
			  unsigned msg_reg_nr)
{
   struct brw_context *brw = p->brw;
   if (brw->gen < 6)
      return;

   if (src->file == BRW_MESSAGE_REGISTER_FILE)
      return;

   if (src->file != BRW_ARCHITECTURE_REGISTER_FILE || src->nr != BRW_ARF_NULL) {
      brw_push_insn_state(p);
      brw_set_mask_control(p, BRW_MASK_DISABLE);
      brw_set_compression_control(p, BRW_COMPRESSION_NONE);
      brw_MOV(p, retype(brw_message_reg(msg_reg_nr), BRW_REGISTER_TYPE_UD),
	      retype(*src, BRW_REGISTER_TYPE_UD));
      brw_pop_insn_state(p);
   }
   *src = brw_message_reg(msg_reg_nr);
}

static void
gen7_convert_mrf_to_grf(struct brw_compile *p, struct brw_reg *reg)
{
   /* From the Ivybridge PRM, Volume 4 Part 3, page 218 ("send"):
    * "The send with EOT should use register space R112-R127 for <src>. This is
    *  to enable loading of a new thread into the same slot while the message
    *  with EOT for current thread is pending dispatch."
    *
    * Since we're pretending to have 16 MRFs anyway, we may as well use the
    * registers required for messages with EOT.
    */
   struct brw_context *brw = p->brw;
   if (brw->gen == 7 && reg->file == BRW_MESSAGE_REGISTER_FILE) {
      reg->file = BRW_GENERAL_REGISTER_FILE;
      reg->nr += GEN7_MRF_HACK_START;
   }
}

/**
 * Convert a brw_reg_type enumeration value into the hardware representation.
 *
 * The hardware encoding may depend on whether the value is an immediate.
 */
unsigned
brw_reg_type_to_hw_type(const struct brw_context *brw,
                        enum brw_reg_type type, unsigned file)
{
   if (file == BRW_IMMEDIATE_VALUE) {
      const static int imm_hw_types[] = {
         [BRW_REGISTER_TYPE_UD] = BRW_HW_REG_TYPE_UD,
         [BRW_REGISTER_TYPE_D]  = BRW_HW_REG_TYPE_D,
         [BRW_REGISTER_TYPE_UW] = BRW_HW_REG_TYPE_UW,
         [BRW_REGISTER_TYPE_W]  = BRW_HW_REG_TYPE_W,
         [BRW_REGISTER_TYPE_F]  = BRW_HW_REG_TYPE_F,
         [BRW_REGISTER_TYPE_UB] = -1,
         [BRW_REGISTER_TYPE_B]  = -1,
         [BRW_REGISTER_TYPE_UV] = BRW_HW_REG_IMM_TYPE_UV,
         [BRW_REGISTER_TYPE_VF] = BRW_HW_REG_IMM_TYPE_VF,
         [BRW_REGISTER_TYPE_V]  = BRW_HW_REG_IMM_TYPE_V,
         [BRW_REGISTER_TYPE_DF] = GEN8_HW_REG_IMM_TYPE_DF,
         [BRW_REGISTER_TYPE_HF] = GEN8_HW_REG_IMM_TYPE_HF,
         [BRW_REGISTER_TYPE_UQ] = GEN8_HW_REG_TYPE_UQ,
         [BRW_REGISTER_TYPE_Q]  = GEN8_HW_REG_TYPE_Q,
      };
      assert(type < ARRAY_SIZE(imm_hw_types));
      assert(imm_hw_types[type] != -1);
      assert(brw->gen >= 8 || type < BRW_REGISTER_TYPE_DF);
      return imm_hw_types[type];
   } else {
      /* Non-immediate registers */
      const static int hw_types[] = {
         [BRW_REGISTER_TYPE_UD] = BRW_HW_REG_TYPE_UD,
         [BRW_REGISTER_TYPE_D]  = BRW_HW_REG_TYPE_D,
         [BRW_REGISTER_TYPE_UW] = BRW_HW_REG_TYPE_UW,
         [BRW_REGISTER_TYPE_W]  = BRW_HW_REG_TYPE_W,
         [BRW_REGISTER_TYPE_UB] = BRW_HW_REG_NON_IMM_TYPE_UB,
         [BRW_REGISTER_TYPE_B]  = BRW_HW_REG_NON_IMM_TYPE_B,
         [BRW_REGISTER_TYPE_F]  = BRW_HW_REG_TYPE_F,
         [BRW_REGISTER_TYPE_UV] = -1,
         [BRW_REGISTER_TYPE_VF] = -1,
         [BRW_REGISTER_TYPE_V]  = -1,
         [BRW_REGISTER_TYPE_DF] = GEN7_HW_REG_NON_IMM_TYPE_DF,
         [BRW_REGISTER_TYPE_HF] = GEN8_HW_REG_NON_IMM_TYPE_HF,
         [BRW_REGISTER_TYPE_UQ] = GEN8_HW_REG_TYPE_UQ,
         [BRW_REGISTER_TYPE_Q]  = GEN8_HW_REG_TYPE_Q,
      };
      assert(type < ARRAY_SIZE(hw_types));
      assert(hw_types[type] != -1);
      assert(brw->gen >= 7 || type < BRW_REGISTER_TYPE_DF);
      assert(brw->gen >= 8 || type < BRW_REGISTER_TYPE_HF);
      return hw_types[type];
   }
}

void
brw_set_dest(struct brw_compile *p, struct brw_instruction *insn,
	     struct brw_reg dest)
{
   if (dest.file != BRW_ARCHITECTURE_REGISTER_FILE &&
       dest.file != BRW_MESSAGE_REGISTER_FILE)
      assert(dest.nr < 128);

   gen7_convert_mrf_to_grf(p, &dest);

   insn->bits1.da1.dest_reg_file = dest.file;
   insn->bits1.da1.dest_reg_type =
      brw_reg_type_to_hw_type(p->brw, dest.type, dest.file);
   insn->bits1.da1.dest_address_mode = dest.address_mode;

   if (dest.address_mode == BRW_ADDRESS_DIRECT) {
      insn->bits1.da1.dest_reg_nr = dest.nr;

      if (insn->header.access_mode == BRW_ALIGN_1) {
	 insn->bits1.da1.dest_subreg_nr = dest.subnr;
	 if (dest.hstride == BRW_HORIZONTAL_STRIDE_0)
	    dest.hstride = BRW_HORIZONTAL_STRIDE_1;
	 insn->bits1.da1.dest_horiz_stride = dest.hstride;
      }
      else {
	 insn->bits1.da16.dest_subreg_nr = dest.subnr / 16;
	 insn->bits1.da16.dest_writemask = dest.dw1.bits.writemask;
         if (dest.file == BRW_GENERAL_REGISTER_FILE ||
             dest.file == BRW_MESSAGE_REGISTER_FILE) {
            assert(dest.dw1.bits.writemask != 0);
         }
	 /* From the Ivybridge PRM, Vol 4, Part 3, Section 5.2.4.1:
	  *    Although Dst.HorzStride is a don't care for Align16, HW needs
	  *    this to be programmed as "01".
	  */
	 insn->bits1.da16.dest_horiz_stride = 1;
      }
   }
   else {
      insn->bits1.ia1.dest_subreg_nr = dest.subnr;

      /* These are different sizes in align1 vs align16:
       */
      if (insn->header.access_mode == BRW_ALIGN_1) {
	 insn->bits1.ia1.dest_indirect_offset = dest.dw1.bits.indirect_offset;
	 if (dest.hstride == BRW_HORIZONTAL_STRIDE_0)
	    dest.hstride = BRW_HORIZONTAL_STRIDE_1;
	 insn->bits1.ia1.dest_horiz_stride = dest.hstride;
      }
      else {
	 insn->bits1.ia16.dest_indirect_offset = dest.dw1.bits.indirect_offset;
	 /* even ignored in da16, still need to set as '01' */
	 insn->bits1.ia16.dest_horiz_stride = 1;
      }
   }

   /* NEW: Set the execution size based on dest.width and
    * insn->compression_control:
    */
   guess_execution_size(p, insn, dest);
}

extern int reg_type_size[];

static void
validate_reg(struct brw_instruction *insn, struct brw_reg reg)
{
   int hstride_for_reg[] = {0, 1, 2, 4};
   int vstride_for_reg[] = {0, 1, 2, 4, 8, 16, 32, 64, 128, 256};
   int width_for_reg[] = {1, 2, 4, 8, 16};
   int execsize_for_reg[] = {1, 2, 4, 8, 16};
   int width, hstride, vstride, execsize;

   if (reg.file == BRW_IMMEDIATE_VALUE) {
      /* 3.3.6: Region Parameters.  Restriction: Immediate vectors
       * mean the destination has to be 128-bit aligned and the
       * destination horiz stride has to be a word.
       */
      if (reg.type == BRW_REGISTER_TYPE_V) {
	 assert(hstride_for_reg[insn->bits1.da1.dest_horiz_stride] *
		reg_type_size[insn->bits1.da1.dest_reg_type] == 2);
      }

      return;
   }

   if (reg.file == BRW_ARCHITECTURE_REGISTER_FILE &&
       reg.file == BRW_ARF_NULL)
      return;

   assert(reg.hstride >= 0 && reg.hstride < Elements(hstride_for_reg));
   hstride = hstride_for_reg[reg.hstride];

   if (reg.vstride == 0xf) {
      vstride = -1;
   } else {
      assert(reg.vstride >= 0 && reg.vstride < Elements(vstride_for_reg));
      vstride = vstride_for_reg[reg.vstride];
   }

   assert(reg.width >= 0 && reg.width < Elements(width_for_reg));
   width = width_for_reg[reg.width];

   assert(insn->header.execution_size >= 0 &&
	  insn->header.execution_size < Elements(execsize_for_reg));
   execsize = execsize_for_reg[insn->header.execution_size];

   /* Restrictions from 3.3.10: Register Region Restrictions. */
   /* 3. */
   assert(execsize >= width);

   /* 4. */
   if (execsize == width && hstride != 0) {
      assert(vstride == -1 || vstride == width * hstride);
   }

   /* 5. */
   if (execsize == width && hstride == 0) {
      /* no restriction on vstride. */
   }

   /* 6. */
   if (width == 1) {
      assert(hstride == 0);
   }

   /* 7. */
   if (execsize == 1 && width == 1) {
      assert(hstride == 0);
      assert(vstride == 0);
   }

   /* 8. */
   if (vstride == 0 && hstride == 0) {
      assert(width == 1);
   }

   /* 10. Check destination issues. */
}

void
brw_set_src0(struct brw_compile *p, struct brw_instruction *insn,
	     struct brw_reg reg)
{
   struct brw_context *brw = p->brw;

   if (reg.type != BRW_ARCHITECTURE_REGISTER_FILE)
      assert(reg.nr < 128);

   gen7_convert_mrf_to_grf(p, &reg);

   if (brw->gen >= 6 && (insn->header.opcode == BRW_OPCODE_SEND ||
                           insn->header.opcode == BRW_OPCODE_SENDC)) {
      /* Any source modifiers or regions will be ignored, since this just
       * identifies the MRF/GRF to start reading the message contents from.
       * Check for some likely failures.
       */
      assert(!reg.negate);
      assert(!reg.abs);
      assert(reg.address_mode == BRW_ADDRESS_DIRECT);
   }

   validate_reg(insn, reg);

   insn->bits1.da1.src0_reg_file = reg.file;
   insn->bits1.da1.src0_reg_type =
      brw_reg_type_to_hw_type(brw, reg.type, reg.file);
   insn->bits2.da1.src0_abs = reg.abs;
   insn->bits2.da1.src0_negate = reg.negate;
   insn->bits2.da1.src0_address_mode = reg.address_mode;

   if (reg.file == BRW_IMMEDIATE_VALUE) {
      insn->bits3.ud = reg.dw1.ud;

      /* Required to set some fields in src1 as well:
       */
      insn->bits1.da1.src1_reg_file = 0; /* arf */
      insn->bits1.da1.src1_reg_type = insn->bits1.da1.src0_reg_type;
   }
   else
   {
      if (reg.address_mode == BRW_ADDRESS_DIRECT) {
	 if (insn->header.access_mode == BRW_ALIGN_1) {
	    insn->bits2.da1.src0_subreg_nr = reg.subnr;
	    insn->bits2.da1.src0_reg_nr = reg.nr;
	 }
	 else {
	    insn->bits2.da16.src0_subreg_nr = reg.subnr / 16;
	    insn->bits2.da16.src0_reg_nr = reg.nr;
	 }
      }
      else {
	 insn->bits2.ia1.src0_subreg_nr = reg.subnr;

	 if (insn->header.access_mode == BRW_ALIGN_1) {
	    insn->bits2.ia1.src0_indirect_offset = reg.dw1.bits.indirect_offset;
	 }
	 else {
	    insn->bits2.ia16.src0_subreg_nr = reg.dw1.bits.indirect_offset;
	 }
      }

      if (insn->header.access_mode == BRW_ALIGN_1) {
	 if (reg.width == BRW_WIDTH_1 &&
	     insn->header.execution_size == BRW_EXECUTE_1) {
	    insn->bits2.da1.src0_horiz_stride = BRW_HORIZONTAL_STRIDE_0;
	    insn->bits2.da1.src0_width = BRW_WIDTH_1;
	    insn->bits2.da1.src0_vert_stride = BRW_VERTICAL_STRIDE_0;
	 }
	 else {
	    insn->bits2.da1.src0_horiz_stride = reg.hstride;
	    insn->bits2.da1.src0_width = reg.width;
	    insn->bits2.da1.src0_vert_stride = reg.vstride;
	 }
      }
      else {
	 insn->bits2.da16.src0_swz_x = BRW_GET_SWZ(reg.dw1.bits.swizzle, BRW_CHANNEL_X);
	 insn->bits2.da16.src0_swz_y = BRW_GET_SWZ(reg.dw1.bits.swizzle, BRW_CHANNEL_Y);
	 insn->bits2.da16.src0_swz_z = BRW_GET_SWZ(reg.dw1.bits.swizzle, BRW_CHANNEL_Z);
	 insn->bits2.da16.src0_swz_w = BRW_GET_SWZ(reg.dw1.bits.swizzle, BRW_CHANNEL_W);

	 /* This is an oddity of the fact we're using the same
	  * descriptions for registers in align_16 as align_1:
	  */
	 if (reg.vstride == BRW_VERTICAL_STRIDE_8)
	    insn->bits2.da16.src0_vert_stride = BRW_VERTICAL_STRIDE_4;
	 else
	    insn->bits2.da16.src0_vert_stride = reg.vstride;
      }
   }
}


void brw_set_src1(struct brw_compile *p,
		  struct brw_instruction *insn,
		  struct brw_reg reg)
{
   assert(reg.file != BRW_MESSAGE_REGISTER_FILE);

   if (reg.type != BRW_ARCHITECTURE_REGISTER_FILE)
      assert(reg.nr < 128);

   gen7_convert_mrf_to_grf(p, &reg);

   validate_reg(insn, reg);

   insn->bits1.da1.src1_reg_file = reg.file;
   insn->bits1.da1.src1_reg_type =
      brw_reg_type_to_hw_type(p->brw, reg.type, reg.file);
   insn->bits3.da1.src1_abs = reg.abs;
   insn->bits3.da1.src1_negate = reg.negate;

   /* Only src1 can be immediate in two-argument instructions.
    */
   assert(insn->bits1.da1.src0_reg_file != BRW_IMMEDIATE_VALUE);

   if (reg.file == BRW_IMMEDIATE_VALUE) {
      insn->bits3.ud = reg.dw1.ud;
   }
   else {
      /* This is a hardware restriction, which may or may not be lifted
       * in the future:
       */
      assert (reg.address_mode == BRW_ADDRESS_DIRECT);
      /* assert (reg.file == BRW_GENERAL_REGISTER_FILE); */

      if (insn->header.access_mode == BRW_ALIGN_1) {
	 insn->bits3.da1.src1_subreg_nr = reg.subnr;
	 insn->bits3.da1.src1_reg_nr = reg.nr;
      }
      else {
	 insn->bits3.da16.src1_subreg_nr = reg.subnr / 16;
	 insn->bits3.da16.src1_reg_nr = reg.nr;
      }

      if (insn->header.access_mode == BRW_ALIGN_1) {
	 if (reg.width == BRW_WIDTH_1 &&
	     insn->header.execution_size == BRW_EXECUTE_1) {
	    insn->bits3.da1.src1_horiz_stride = BRW_HORIZONTAL_STRIDE_0;
	    insn->bits3.da1.src1_width = BRW_WIDTH_1;
	    insn->bits3.da1.src1_vert_stride = BRW_VERTICAL_STRIDE_0;
	 }
	 else {
	    insn->bits3.da1.src1_horiz_stride = reg.hstride;
	    insn->bits3.da1.src1_width = reg.width;
	    insn->bits3.da1.src1_vert_stride = reg.vstride;
	 }
      }
      else {
	 insn->bits3.da16.src1_swz_x = BRW_GET_SWZ(reg.dw1.bits.swizzle, BRW_CHANNEL_X);
	 insn->bits3.da16.src1_swz_y = BRW_GET_SWZ(reg.dw1.bits.swizzle, BRW_CHANNEL_Y);
	 insn->bits3.da16.src1_swz_z = BRW_GET_SWZ(reg.dw1.bits.swizzle, BRW_CHANNEL_Z);
	 insn->bits3.da16.src1_swz_w = BRW_GET_SWZ(reg.dw1.bits.swizzle, BRW_CHANNEL_W);

	 /* This is an oddity of the fact we're using the same
	  * descriptions for registers in align_16 as align_1:
	  */
	 if (reg.vstride == BRW_VERTICAL_STRIDE_8)
	    insn->bits3.da16.src1_vert_stride = BRW_VERTICAL_STRIDE_4;
	 else
	    insn->bits3.da16.src1_vert_stride = reg.vstride;
      }
   }
}

/**
 * Set the Message Descriptor and Extended Message Descriptor fields
 * for SEND messages.
 *
 * \note This zeroes out the Function Control bits, so it must be called
 *       \b before filling out any message-specific data.  Callers can
 *       choose not to fill in irrelevant bits; they will be zero.
 */
static void
brw_set_message_descriptor(struct brw_compile *p,
			   struct brw_instruction *inst,
			   enum brw_message_target sfid,
			   unsigned msg_length,
			   unsigned response_length,
			   bool header_present,
			   bool end_of_thread)
{
   struct brw_context *brw = p->brw;

   brw_set_src1(p, inst, brw_imm_d(0));

   if (brw->gen >= 5) {
      inst->bits3.generic_gen5.header_present = header_present;
      inst->bits3.generic_gen5.response_length = response_length;
      inst->bits3.generic_gen5.msg_length = msg_length;
      inst->bits3.generic_gen5.end_of_thread = end_of_thread;

      if (brw->gen >= 6) {
	 /* On Gen6+ Message target/SFID goes in bits 27:24 of the header */
	 inst->header.destreg__conditionalmod = sfid;
      } else {
	 /* Set Extended Message Descriptor (ex_desc) */
	 inst->bits2.send_gen5.sfid = sfid;
	 inst->bits2.send_gen5.end_of_thread = end_of_thread;
      }
   } else {
      inst->bits3.generic.response_length = response_length;
      inst->bits3.generic.msg_length = msg_length;
      inst->bits3.generic.msg_target = sfid;
      inst->bits3.generic.end_of_thread = end_of_thread;
   }
}

static void brw_set_math_message( struct brw_compile *p,
				  struct brw_instruction *insn,
				  unsigned function,
				  unsigned integer_type,
				  bool low_precision,
				  unsigned dataType )
{
   struct brw_context *brw = p->brw;
   unsigned msg_length;
   unsigned response_length;

   /* Infer message length from the function */
   switch (function) {
   case BRW_MATH_FUNCTION_POW:
   case BRW_MATH_FUNCTION_INT_DIV_QUOTIENT:
   case BRW_MATH_FUNCTION_INT_DIV_REMAINDER:
   case BRW_MATH_FUNCTION_INT_DIV_QUOTIENT_AND_REMAINDER:
      msg_length = 2;
      break;
   default:
      msg_length = 1;
      break;
   }

   /* Infer response length from the function */
   switch (function) {
   case BRW_MATH_FUNCTION_SINCOS:
   case BRW_MATH_FUNCTION_INT_DIV_QUOTIENT_AND_REMAINDER:
      response_length = 2;
      break;
   default:
      response_length = 1;
      break;
   }


   brw_set_message_descriptor(p, insn, BRW_SFID_MATH,
			      msg_length, response_length, false, false);
   if (brw->gen == 5) {
      insn->bits3.math_gen5.function = function;
      insn->bits3.math_gen5.int_type = integer_type;
      insn->bits3.math_gen5.precision = low_precision;
      insn->bits3.math_gen5.saturate = insn->header.saturate;
      insn->bits3.math_gen5.data_type = dataType;
      insn->bits3.math_gen5.snapshot = 0;
   } else {
      insn->bits3.math.function = function;
      insn->bits3.math.int_type = integer_type;
      insn->bits3.math.precision = low_precision;
      insn->bits3.math.saturate = insn->header.saturate;
      insn->bits3.math.data_type = dataType;
   }
   insn->header.saturate = 0;
}


static void brw_set_ff_sync_message(struct brw_compile *p,
				    struct brw_instruction *insn,
				    bool allocate,
				    unsigned response_length,
				    bool end_of_thread)
{
   brw_set_message_descriptor(p, insn, BRW_SFID_URB,
			      1, response_length, true, end_of_thread);
   insn->bits3.urb_gen5.opcode = 1; /* FF_SYNC */
   insn->bits3.urb_gen5.offset = 0; /* Not used by FF_SYNC */
   insn->bits3.urb_gen5.swizzle_control = 0; /* Not used by FF_SYNC */
   insn->bits3.urb_gen5.allocate = allocate;
   insn->bits3.urb_gen5.used = 0; /* Not used by FF_SYNC */
   insn->bits3.urb_gen5.complete = 0; /* Not used by FF_SYNC */
}

static void brw_set_urb_message( struct brw_compile *p,
				 struct brw_instruction *insn,
                                 enum brw_urb_write_flags flags,
				 unsigned msg_length,
				 unsigned response_length,
				 unsigned offset,
				 unsigned swizzle_control )
{
   struct brw_context *brw = p->brw;

   brw_set_message_descriptor(p, insn, BRW_SFID_URB,
			      msg_length, response_length, true,
                              flags & BRW_URB_WRITE_EOT);
   if (brw->gen == 7) {
      if (flags & BRW_URB_WRITE_OWORD) {
         assert(msg_length == 2); /* header + one OWORD of data */
         insn->bits3.urb_gen7.opcode = BRW_URB_OPCODE_WRITE_OWORD;
      } else {
         insn->bits3.urb_gen7.opcode = BRW_URB_OPCODE_WRITE_HWORD;
      }
      insn->bits3.urb_gen7.offset = offset;
      assert(swizzle_control != BRW_URB_SWIZZLE_TRANSPOSE);
      insn->bits3.urb_gen7.swizzle_control = swizzle_control;
      insn->bits3.urb_gen7.per_slot_offset =
         flags & BRW_URB_WRITE_PER_SLOT_OFFSET ? 1 : 0;
      insn->bits3.urb_gen7.complete = flags & BRW_URB_WRITE_COMPLETE ? 1 : 0;
   } else if (brw->gen >= 5) {
      insn->bits3.urb_gen5.opcode = 0;	/* URB_WRITE */
      insn->bits3.urb_gen5.offset = offset;
      insn->bits3.urb_gen5.swizzle_control = swizzle_control;
      insn->bits3.urb_gen5.allocate = flags & BRW_URB_WRITE_ALLOCATE ? 1 : 0;
      insn->bits3.urb_gen5.used = flags & BRW_URB_WRITE_UNUSED ? 0 : 1;
      insn->bits3.urb_gen5.complete = flags & BRW_URB_WRITE_COMPLETE ? 1 : 0;
   } else {
      insn->bits3.urb.opcode = 0;	/* ? */
      insn->bits3.urb.offset = offset;
      insn->bits3.urb.swizzle_control = swizzle_control;
      insn->bits3.urb.allocate = flags & BRW_URB_WRITE_ALLOCATE ? 1 : 0;
      insn->bits3.urb.used = flags & BRW_URB_WRITE_UNUSED ? 0 : 1;
      insn->bits3.urb.complete = flags & BRW_URB_WRITE_COMPLETE ? 1 : 0;
   }
}

void
brw_set_dp_write_message(struct brw_compile *p,
			 struct brw_instruction *insn,
			 unsigned binding_table_index,
			 unsigned msg_control,
			 unsigned msg_type,
			 unsigned msg_length,
			 bool header_present,
			 unsigned last_render_target,
			 unsigned response_length,
			 unsigned end_of_thread,
			 unsigned send_commit_msg)
{
   struct brw_context *brw = p->brw;
   unsigned sfid;

   if (brw->gen >= 7) {
      /* Use the Render Cache for RT writes; otherwise use the Data Cache */
      if (msg_type == GEN6_DATAPORT_WRITE_MESSAGE_RENDER_TARGET_WRITE)
	 sfid = GEN6_SFID_DATAPORT_RENDER_CACHE;
      else
	 sfid = GEN7_SFID_DATAPORT_DATA_CACHE;
   } else if (brw->gen == 6) {
      /* Use the render cache for all write messages. */
      sfid = GEN6_SFID_DATAPORT_RENDER_CACHE;
   } else {
      sfid = BRW_SFID_DATAPORT_WRITE;
   }

   brw_set_message_descriptor(p, insn, sfid, msg_length, response_length,
			      header_present, end_of_thread);

   if (brw->gen >= 7) {
      insn->bits3.gen7_dp.binding_table_index = binding_table_index;
      insn->bits3.gen7_dp.msg_control = msg_control;
      insn->bits3.gen7_dp.last_render_target = last_render_target;
      insn->bits3.gen7_dp.msg_type = msg_type;
   } else if (brw->gen == 6) {
      insn->bits3.gen6_dp.binding_table_index = binding_table_index;
      insn->bits3.gen6_dp.msg_control = msg_control;
      insn->bits3.gen6_dp.last_render_target = last_render_target;
      insn->bits3.gen6_dp.msg_type = msg_type;
      insn->bits3.gen6_dp.send_commit_msg = send_commit_msg;
   } else if (brw->gen == 5) {
      insn->bits3.dp_write_gen5.binding_table_index = binding_table_index;
      insn->bits3.dp_write_gen5.msg_control = msg_control;
      insn->bits3.dp_write_gen5.last_render_target = last_render_target;
      insn->bits3.dp_write_gen5.msg_type = msg_type;
      insn->bits3.dp_write_gen5.send_commit_msg = send_commit_msg;
   } else {
      insn->bits3.dp_write.binding_table_index = binding_table_index;
      insn->bits3.dp_write.msg_control = msg_control;
      insn->bits3.dp_write.last_render_target = last_render_target;
      insn->bits3.dp_write.msg_type = msg_type;
      insn->bits3.dp_write.send_commit_msg = send_commit_msg;
   }
}

void
brw_set_dp_read_message(struct brw_compile *p,
			struct brw_instruction *insn,
			unsigned binding_table_index,
			unsigned msg_control,
			unsigned msg_type,
			unsigned target_cache,
			unsigned msg_length,
                        bool header_present,
			unsigned response_length)
{
   struct brw_context *brw = p->brw;
   unsigned sfid;

   if (brw->gen >= 7) {
      sfid = GEN7_SFID_DATAPORT_DATA_CACHE;
   } else if (brw->gen == 6) {
      if (target_cache == BRW_DATAPORT_READ_TARGET_RENDER_CACHE)
	 sfid = GEN6_SFID_DATAPORT_RENDER_CACHE;
      else
	 sfid = GEN6_SFID_DATAPORT_SAMPLER_CACHE;
   } else {
      sfid = BRW_SFID_DATAPORT_READ;
   }

   brw_set_message_descriptor(p, insn, sfid, msg_length, response_length,
			      header_present, false);

   if (brw->gen >= 7) {
      insn->bits3.gen7_dp.binding_table_index = binding_table_index;
      insn->bits3.gen7_dp.msg_control = msg_control;
      insn->bits3.gen7_dp.last_render_target = 0;
      insn->bits3.gen7_dp.msg_type = msg_type;
   } else if (brw->gen == 6) {
      insn->bits3.gen6_dp.binding_table_index = binding_table_index;
      insn->bits3.gen6_dp.msg_control = msg_control;
      insn->bits3.gen6_dp.last_render_target = 0;
      insn->bits3.gen6_dp.msg_type = msg_type;
      insn->bits3.gen6_dp.send_commit_msg = 0;
   } else if (brw->gen == 5) {
      insn->bits3.dp_read_gen5.binding_table_index = binding_table_index;
      insn->bits3.dp_read_gen5.msg_control = msg_control;
      insn->bits3.dp_read_gen5.msg_type = msg_type;
      insn->bits3.dp_read_gen5.target_cache = target_cache;
   } else if (brw->is_g4x) {
      insn->bits3.dp_read_g4x.binding_table_index = binding_table_index; /*0:7*/
      insn->bits3.dp_read_g4x.msg_control = msg_control;  /*8:10*/
      insn->bits3.dp_read_g4x.msg_type = msg_type;  /*11:13*/
      insn->bits3.dp_read_g4x.target_cache = target_cache;  /*14:15*/
   } else {
      insn->bits3.dp_read.binding_table_index = binding_table_index; /*0:7*/
      insn->bits3.dp_read.msg_control = msg_control;  /*8:11*/
      insn->bits3.dp_read.msg_type = msg_type;  /*12:13*/
      insn->bits3.dp_read.target_cache = target_cache;  /*14:15*/
   }
}

void
brw_set_sampler_message(struct brw_compile *p,
                        struct brw_instruction *insn,
                        unsigned binding_table_index,
                        unsigned sampler,
                        unsigned msg_type,
                        unsigned response_length,
                        unsigned msg_length,
                        unsigned header_present,
                        unsigned simd_mode,
                        unsigned return_format)
{
   struct brw_context *brw = p->brw;

   brw_set_message_descriptor(p, insn, BRW_SFID_SAMPLER, msg_length,
			      response_length, header_present, false);

   if (brw->gen >= 7) {
      insn->bits3.sampler_gen7.binding_table_index = binding_table_index;
      insn->bits3.sampler_gen7.sampler = sampler;
      insn->bits3.sampler_gen7.msg_type = msg_type;
      insn->bits3.sampler_gen7.simd_mode = simd_mode;
   } else if (brw->gen >= 5) {
      insn->bits3.sampler_gen5.binding_table_index = binding_table_index;
      insn->bits3.sampler_gen5.sampler = sampler;
      insn->bits3.sampler_gen5.msg_type = msg_type;
      insn->bits3.sampler_gen5.simd_mode = simd_mode;
   } else if (brw->is_g4x) {
      insn->bits3.sampler_g4x.binding_table_index = binding_table_index;
      insn->bits3.sampler_g4x.sampler = sampler;
      insn->bits3.sampler_g4x.msg_type = msg_type;
   } else {
      insn->bits3.sampler.binding_table_index = binding_table_index;
      insn->bits3.sampler.sampler = sampler;
      insn->bits3.sampler.msg_type = msg_type;
      insn->bits3.sampler.return_format = return_format;
   }
}


#define next_insn brw_next_insn
struct brw_instruction *
brw_next_insn(struct brw_compile *p, unsigned opcode)
{
   struct brw_instruction *insn;

   if (p->nr_insn + 1 > p->store_size) {
      if (0) {
         fprintf(stderr, "incresing the store size to %d\n",
                 p->store_size << 1);
      }
      p->store_size <<= 1;
      p->store = reralloc(p->mem_ctx, p->store,
                          struct brw_instruction, p->store_size);
      if (!p->store)
         assert(!"realloc eu store memeory failed");
   }

   p->next_insn_offset += 16;
   insn = &p->store[p->nr_insn++];
   memcpy(insn, p->current, sizeof(*insn));

   /* Reset this one-shot flag:
    */

   if (p->current->header.destreg__conditionalmod) {
      p->current->header.destreg__conditionalmod = 0;
      p->current->header.predicate_control = BRW_PREDICATE_NORMAL;
   }

   insn->header.opcode = opcode;
   return insn;
}

static struct brw_instruction *brw_alu1( struct brw_compile *p,
					 unsigned opcode,
					 struct brw_reg dest,
					 struct brw_reg src )
{
   struct brw_instruction *insn = next_insn(p, opcode);
   brw_set_dest(p, insn, dest);
   brw_set_src0(p, insn, src);
   return insn;
}

static struct brw_instruction *brw_alu2(struct brw_compile *p,
					unsigned opcode,
					struct brw_reg dest,
					struct brw_reg src0,
					struct brw_reg src1 )
{
   struct brw_instruction *insn = next_insn(p, opcode);
   brw_set_dest(p, insn, dest);
   brw_set_src0(p, insn, src0);
   brw_set_src1(p, insn, src1);
   return insn;
}

static int
get_3src_subreg_nr(struct brw_reg reg)
{
   if (reg.vstride == BRW_VERTICAL_STRIDE_0) {
      assert(brw_is_single_value_swizzle(reg.dw1.bits.swizzle));
      return reg.subnr / 4 + BRW_GET_SWZ(reg.dw1.bits.swizzle, 0);
   } else {
      return reg.subnr / 4;
   }
}

static struct brw_instruction *brw_alu3(struct brw_compile *p,
					unsigned opcode,
					struct brw_reg dest,
					struct brw_reg src0,
					struct brw_reg src1,
					struct brw_reg src2)
{
   struct brw_context *brw = p->brw;
   struct brw_instruction *insn = next_insn(p, opcode);

   gen7_convert_mrf_to_grf(p, &dest);

   assert(insn->header.access_mode == BRW_ALIGN_16);

   assert(dest.file == BRW_GENERAL_REGISTER_FILE ||
	  dest.file == BRW_MESSAGE_REGISTER_FILE);
   assert(dest.nr < 128);
   assert(dest.address_mode == BRW_ADDRESS_DIRECT);
   assert(dest.type == BRW_REGISTER_TYPE_F ||
          dest.type == BRW_REGISTER_TYPE_D ||
          dest.type == BRW_REGISTER_TYPE_UD);
   insn->bits1.da3src.dest_reg_file = (dest.file == BRW_MESSAGE_REGISTER_FILE);
   insn->bits1.da3src.dest_reg_nr = dest.nr;
   insn->bits1.da3src.dest_subreg_nr = dest.subnr / 16;
   insn->bits1.da3src.dest_writemask = dest.dw1.bits.writemask;
   guess_execution_size(p, insn, dest);

   assert(src0.file == BRW_GENERAL_REGISTER_FILE);
   assert(src0.address_mode == BRW_ADDRESS_DIRECT);
   assert(src0.nr < 128);
   insn->bits2.da3src.src0_swizzle = src0.dw1.bits.swizzle;
   insn->bits2.da3src.src0_subreg_nr = get_3src_subreg_nr(src0);
   insn->bits2.da3src.src0_reg_nr = src0.nr;
   insn->bits1.da3src.src0_abs = src0.abs;
   insn->bits1.da3src.src0_negate = src0.negate;
   insn->bits2.da3src.src0_rep_ctrl = src0.vstride == BRW_VERTICAL_STRIDE_0;

   assert(src1.file == BRW_GENERAL_REGISTER_FILE);
   assert(src1.address_mode == BRW_ADDRESS_DIRECT);
   assert(src1.nr < 128);
   insn->bits2.da3src.src1_swizzle = src1.dw1.bits.swizzle;
   insn->bits2.da3src.src1_subreg_nr_low = get_3src_subreg_nr(src1) & 0x3;
   insn->bits3.da3src.src1_subreg_nr_high = get_3src_subreg_nr(src1) >> 2;
   insn->bits2.da3src.src1_rep_ctrl = src1.vstride == BRW_VERTICAL_STRIDE_0;
   insn->bits3.da3src.src1_reg_nr = src1.nr;
   insn->bits1.da3src.src1_abs = src1.abs;
   insn->bits1.da3src.src1_negate = src1.negate;

   assert(src2.file == BRW_GENERAL_REGISTER_FILE);
   assert(src2.address_mode == BRW_ADDRESS_DIRECT);
   assert(src2.nr < 128);
   insn->bits3.da3src.src2_swizzle = src2.dw1.bits.swizzle;
   insn->bits3.da3src.src2_subreg_nr = get_3src_subreg_nr(src2);
   insn->bits3.da3src.src2_rep_ctrl = src2.vstride == BRW_VERTICAL_STRIDE_0;
   insn->bits3.da3src.src2_reg_nr = src2.nr;
   insn->bits1.da3src.src2_abs = src2.abs;
   insn->bits1.da3src.src2_negate = src2.negate;

   if (brw->gen >= 7) {
      /* Set both the source and destination types based on dest.type,
       * ignoring the source register types.  The MAD and LRP emitters ensure
       * that all four types are float.  The BFE and BFI2 emitters, however,
       * may send us mixed D and UD types and want us to ignore that and use
       * the destination type.
       */
      switch (dest.type) {
      case BRW_REGISTER_TYPE_F:
         insn->bits1.da3src.src_type = BRW_3SRC_TYPE_F;
         insn->bits1.da3src.dst_type = BRW_3SRC_TYPE_F;
         break;
      case BRW_REGISTER_TYPE_D:
         insn->bits1.da3src.src_type = BRW_3SRC_TYPE_D;
         insn->bits1.da3src.dst_type = BRW_3SRC_TYPE_D;
         break;
      case BRW_REGISTER_TYPE_UD:
         insn->bits1.da3src.src_type = BRW_3SRC_TYPE_UD;
         insn->bits1.da3src.dst_type = BRW_3SRC_TYPE_UD;
         break;
      }
   }

   return insn;
}


/***********************************************************************
 * Convenience routines.
 */
#define ALU1(OP)					\
struct brw_instruction *brw_##OP(struct brw_compile *p,	\
	      struct brw_reg dest,			\
	      struct brw_reg src0)   			\
{							\
   return brw_alu1(p, BRW_OPCODE_##OP, dest, src0);    	\
}

#define ALU2(OP)					\
struct brw_instruction *brw_##OP(struct brw_compile *p,	\
	      struct brw_reg dest,			\
	      struct brw_reg src0,			\
	      struct brw_reg src1)   			\
{							\
   return brw_alu2(p, BRW_OPCODE_##OP, dest, src0, src1);	\
}

#define ALU3(OP)					\
struct brw_instruction *brw_##OP(struct brw_compile *p,	\
	      struct brw_reg dest,			\
	      struct brw_reg src0,			\
	      struct brw_reg src1,			\
	      struct brw_reg src2)   			\
{							\
   return brw_alu3(p, BRW_OPCODE_##OP, dest, src0, src1, src2);	\
}

#define ALU3F(OP)                                               \
struct brw_instruction *brw_##OP(struct brw_compile *p,         \
                                 struct brw_reg dest,           \
                                 struct brw_reg src0,           \
                                 struct brw_reg src1,           \
                                 struct brw_reg src2)           \
{                                                               \
   assert(dest.type == BRW_REGISTER_TYPE_F);                    \
   assert(src0.type == BRW_REGISTER_TYPE_F);                    \
   assert(src1.type == BRW_REGISTER_TYPE_F);                    \
   assert(src2.type == BRW_REGISTER_TYPE_F);                    \
   return brw_alu3(p, BRW_OPCODE_##OP, dest, src0, src1, src2); \
}

/* Rounding operations (other than RNDD) require two instructions - the first
 * stores a rounded value (possibly the wrong way) in the dest register, but
 * also sets a per-channel "increment bit" in the flag register.  A predicated
 * add of 1.0 fixes dest to contain the desired result.
 *
 * Sandybridge and later appear to round correctly without an ADD.
 */
#define ROUND(OP)							      \
void brw_##OP(struct brw_compile *p,					      \
	      struct brw_reg dest,					      \
	      struct brw_reg src)					      \
{									      \
   struct brw_instruction *rnd, *add;					      \
   rnd = next_insn(p, BRW_OPCODE_##OP);					      \
   brw_set_dest(p, rnd, dest);						      \
   brw_set_src0(p, rnd, src);						      \
									      \
   if (p->brw->gen < 6) {						      \
      /* turn on round-increments */					      \
      rnd->header.destreg__conditionalmod = BRW_CONDITIONAL_R;		      \
      add = brw_ADD(p, dest, dest, brw_imm_f(1.0f));			      \
      add->header.predicate_control = BRW_PREDICATE_NORMAL;		      \
   }									      \
}


ALU1(MOV)
ALU2(SEL)
ALU1(NOT)
ALU2(AND)
ALU2(OR)
ALU2(XOR)
ALU2(SHR)
ALU2(SHL)
ALU2(ASR)
ALU1(F32TO16)
ALU1(F16TO32)
ALU1(FRC)
ALU1(RNDD)
ALU2(MAC)
ALU2(MACH)
ALU1(LZD)
ALU2(DP4)
ALU2(DPH)
ALU2(DP3)
ALU2(DP2)
ALU2(LINE)
ALU2(PLN)
ALU3F(MAD)
ALU3F(LRP)
ALU1(BFREV)
ALU3(BFE)
ALU2(BFI1)
ALU3(BFI2)
ALU1(FBH)
ALU1(FBL)
ALU1(CBIT)
ALU2(ADDC)
ALU2(SUBB)

ROUND(RNDZ)
ROUND(RNDE)


struct brw_instruction *brw_ADD(struct brw_compile *p,
				struct brw_reg dest,
				struct brw_reg src0,
				struct brw_reg src1)
{
   /* 6.2.2: add */
   if (src0.type == BRW_REGISTER_TYPE_F ||
       (src0.file == BRW_IMMEDIATE_VALUE &&
	src0.type == BRW_REGISTER_TYPE_VF)) {
      assert(src1.type != BRW_REGISTER_TYPE_UD);
      assert(src1.type != BRW_REGISTER_TYPE_D);
   }

   if (src1.type == BRW_REGISTER_TYPE_F ||
       (src1.file == BRW_IMMEDIATE_VALUE &&
	src1.type == BRW_REGISTER_TYPE_VF)) {
      assert(src0.type != BRW_REGISTER_TYPE_UD);
      assert(src0.type != BRW_REGISTER_TYPE_D);
   }

   return brw_alu2(p, BRW_OPCODE_ADD, dest, src0, src1);
}

struct brw_instruction *brw_AVG(struct brw_compile *p,
                                struct brw_reg dest,
                                struct brw_reg src0,
                                struct brw_reg src1)
{
   assert(dest.type == src0.type);
   assert(src0.type == src1.type);
   switch (src0.type) {
   case BRW_REGISTER_TYPE_B:
   case BRW_REGISTER_TYPE_UB:
   case BRW_REGISTER_TYPE_W:
   case BRW_REGISTER_TYPE_UW:
   case BRW_REGISTER_TYPE_D:
   case BRW_REGISTER_TYPE_UD:
      break;
   default:
      assert(!"Bad type for brw_AVG");
   }

   return brw_alu2(p, BRW_OPCODE_AVG, dest, src0, src1);
}

struct brw_instruction *brw_MUL(struct brw_compile *p,
				struct brw_reg dest,
				struct brw_reg src0,
				struct brw_reg src1)
{
   /* 6.32.38: mul */
   if (src0.type == BRW_REGISTER_TYPE_D ||
       src0.type == BRW_REGISTER_TYPE_UD ||
       src1.type == BRW_REGISTER_TYPE_D ||
       src1.type == BRW_REGISTER_TYPE_UD) {
      assert(dest.type != BRW_REGISTER_TYPE_F);
   }

   if (src0.type == BRW_REGISTER_TYPE_F ||
       (src0.file == BRW_IMMEDIATE_VALUE &&
	src0.type == BRW_REGISTER_TYPE_VF)) {
      assert(src1.type != BRW_REGISTER_TYPE_UD);
      assert(src1.type != BRW_REGISTER_TYPE_D);
   }

   if (src1.type == BRW_REGISTER_TYPE_F ||
       (src1.file == BRW_IMMEDIATE_VALUE &&
	src1.type == BRW_REGISTER_TYPE_VF)) {
      assert(src0.type != BRW_REGISTER_TYPE_UD);
      assert(src0.type != BRW_REGISTER_TYPE_D);
   }

   assert(src0.file != BRW_ARCHITECTURE_REGISTER_FILE ||
	  src0.nr != BRW_ARF_ACCUMULATOR);
   assert(src1.file != BRW_ARCHITECTURE_REGISTER_FILE ||
	  src1.nr != BRW_ARF_ACCUMULATOR);

   return brw_alu2(p, BRW_OPCODE_MUL, dest, src0, src1);
}


void brw_NOP(struct brw_compile *p)
{
   struct brw_instruction *insn = next_insn(p, BRW_OPCODE_NOP);
   brw_set_dest(p, insn, retype(brw_vec4_grf(0,0), BRW_REGISTER_TYPE_UD));
   brw_set_src0(p, insn, retype(brw_vec4_grf(0,0), BRW_REGISTER_TYPE_UD));
   brw_set_src1(p, insn, brw_imm_ud(0x0));
}





/***********************************************************************
 * Comparisons, if/else/endif
 */

struct brw_instruction *brw_JMPI(struct brw_compile *p,
                                 struct brw_reg dest,
                                 struct brw_reg src0,
                                 struct brw_reg src1)
{
   struct brw_instruction *insn = brw_alu2(p, BRW_OPCODE_JMPI, dest, src0, src1);

   insn->header.execution_size = 1;
   insn->header.compression_control = BRW_COMPRESSION_NONE;
   insn->header.mask_control = BRW_MASK_DISABLE;

   p->current->header.predicate_control = BRW_PREDICATE_NONE;

   return insn;
}

static void
push_if_stack(struct brw_compile *p, struct brw_instruction *inst)
{
   p->if_stack[p->if_stack_depth] = inst - p->store;

   p->if_stack_depth++;
   if (p->if_stack_array_size <= p->if_stack_depth) {
      p->if_stack_array_size *= 2;
      p->if_stack = reralloc(p->mem_ctx, p->if_stack, int,
			     p->if_stack_array_size);
   }
}

static struct brw_instruction *
pop_if_stack(struct brw_compile *p)
{
   p->if_stack_depth--;
   return &p->store[p->if_stack[p->if_stack_depth]];
}

static void
push_loop_stack(struct brw_compile *p, struct brw_instruction *inst)
{
   if (p->loop_stack_array_size < p->loop_stack_depth) {
      p->loop_stack_array_size *= 2;
      p->loop_stack = reralloc(p->mem_ctx, p->loop_stack, int,
			       p->loop_stack_array_size);
      p->if_depth_in_loop = reralloc(p->mem_ctx, p->if_depth_in_loop, int,
				     p->loop_stack_array_size);
   }

   p->loop_stack[p->loop_stack_depth] = inst - p->store;
   p->loop_stack_depth++;
   p->if_depth_in_loop[p->loop_stack_depth] = 0;
}

static struct brw_instruction *
get_inner_do_insn(struct brw_compile *p)
{
   return &p->store[p->loop_stack[p->loop_stack_depth - 1]];
}

/* EU takes the value from the flag register and pushes it onto some
 * sort of a stack (presumably merging with any flag value already on
 * the stack).  Within an if block, the flags at the top of the stack
 * control execution on each channel of the unit, eg. on each of the
 * 16 pixel values in our wm programs.
 *
 * When the matching 'else' instruction is reached (presumably by
 * countdown of the instruction count patched in by our ELSE/ENDIF
 * functions), the relevent flags are inverted.
 *
 * When the matching 'endif' instruction is reached, the flags are
 * popped off.  If the stack is now empty, normal execution resumes.
 */
struct brw_instruction *
brw_IF(struct brw_compile *p, unsigned execute_size)
{
   struct brw_context *brw = p->brw;
   struct brw_instruction *insn;

   insn = next_insn(p, BRW_OPCODE_IF);

   /* Override the defaults for this instruction:
    */
   if (brw->gen < 6) {
      brw_set_dest(p, insn, brw_ip_reg());
      brw_set_src0(p, insn, brw_ip_reg());
      brw_set_src1(p, insn, brw_imm_d(0x0));
   } else if (brw->gen == 6) {
      brw_set_dest(p, insn, brw_imm_w(0));
      insn->bits1.branch_gen6.jump_count = 0;
      brw_set_src0(p, insn, vec1(retype(brw_null_reg(), BRW_REGISTER_TYPE_D)));
      brw_set_src1(p, insn, vec1(retype(brw_null_reg(), BRW_REGISTER_TYPE_D)));
   } else {
      brw_set_dest(p, insn, vec1(retype(brw_null_reg(), BRW_REGISTER_TYPE_D)));
      brw_set_src0(p, insn, vec1(retype(brw_null_reg(), BRW_REGISTER_TYPE_D)));
      brw_set_src1(p, insn, brw_imm_ud(0));
      insn->bits3.break_cont.jip = 0;
      insn->bits3.break_cont.uip = 0;
   }

   insn->header.execution_size = execute_size;
   insn->header.compression_control = BRW_COMPRESSION_NONE;
   insn->header.predicate_control = BRW_PREDICATE_NORMAL;
   insn->header.mask_control = BRW_MASK_ENABLE;
   if (!p->single_program_flow)
      insn->header.thread_control = BRW_THREAD_SWITCH;

   p->current->header.predicate_control = BRW_PREDICATE_NONE;

   push_if_stack(p, insn);
   p->if_depth_in_loop[p->loop_stack_depth]++;
   return insn;
}

/* This function is only used for gen6-style IF instructions with an
 * embedded comparison (conditional modifier).  It is not used on gen7.
 */
struct brw_instruction *
gen6_IF(struct brw_compile *p, uint32_t conditional,
	struct brw_reg src0, struct brw_reg src1)
{
   struct brw_instruction *insn;

   insn = next_insn(p, BRW_OPCODE_IF);

   brw_set_dest(p, insn, brw_imm_w(0));
   if (p->compressed) {
      insn->header.execution_size = BRW_EXECUTE_16;
   } else {
      insn->header.execution_size = BRW_EXECUTE_8;
   }
   insn->bits1.branch_gen6.jump_count = 0;
   brw_set_src0(p, insn, src0);
   brw_set_src1(p, insn, src1);

   assert(insn->header.compression_control == BRW_COMPRESSION_NONE);
   assert(insn->header.predicate_control == BRW_PREDICATE_NONE);
   insn->header.destreg__conditionalmod = conditional;

   if (!p->single_program_flow)
      insn->header.thread_control = BRW_THREAD_SWITCH;

   push_if_stack(p, insn);
   return insn;
}

/**
 * In single-program-flow (SPF) mode, convert IF and ELSE into ADDs.
 */
static void
convert_IF_ELSE_to_ADD(struct brw_compile *p,
		       struct brw_instruction *if_inst,
		       struct brw_instruction *else_inst)
{
   /* The next instruction (where the ENDIF would be, if it existed) */
   struct brw_instruction *next_inst = &p->store[p->nr_insn];

   assert(p->single_program_flow);
   assert(if_inst != NULL && if_inst->header.opcode == BRW_OPCODE_IF);
   assert(else_inst == NULL || else_inst->header.opcode == BRW_OPCODE_ELSE);
   assert(if_inst->header.execution_size == BRW_EXECUTE_1);

   /* Convert IF to an ADD instruction that moves the instruction pointer
    * to the first instruction of the ELSE block.  If there is no ELSE
    * block, point to where ENDIF would be.  Reverse the predicate.
    *
    * There's no need to execute an ENDIF since we don't need to do any
    * stack operations, and if we're currently executing, we just want to
    * continue normally.
    */
   if_inst->header.opcode = BRW_OPCODE_ADD;
   if_inst->header.predicate_inverse = 1;

   if (else_inst != NULL) {
      /* Convert ELSE to an ADD instruction that points where the ENDIF
       * would be.
       */
      else_inst->header.opcode = BRW_OPCODE_ADD;

      if_inst->bits3.ud = (else_inst - if_inst + 1) * 16;
      else_inst->bits3.ud = (next_inst - else_inst) * 16;
   } else {
      if_inst->bits3.ud = (next_inst - if_inst) * 16;
   }
}

/**
 * Patch IF and ELSE instructions with appropriate jump targets.
 */
static void
patch_IF_ELSE(struct brw_compile *p,
	      struct brw_instruction *if_inst,
	      struct brw_instruction *else_inst,
	      struct brw_instruction *endif_inst)
{
   struct brw_context *brw = p->brw;

   /* We shouldn't be patching IF and ELSE instructions in single program flow
    * mode when gen < 6, because in single program flow mode on those
    * platforms, we convert flow control instructions to conditional ADDs that
    * operate on IP (see brw_ENDIF).
    *
    * However, on Gen6, writing to IP doesn't work in single program flow mode
    * (see the SandyBridge PRM, Volume 4 part 2, p79: "When SPF is ON, IP may
    * not be updated by non-flow control instructions.").  And on later
    * platforms, there is no significant benefit to converting control flow
    * instructions to conditional ADDs.  So we do patch IF and ELSE
    * instructions in single program flow mode on those platforms.
    */
   if (brw->gen < 6)
      assert(!p->single_program_flow);

   assert(if_inst != NULL && if_inst->header.opcode == BRW_OPCODE_IF);
   assert(endif_inst != NULL);
   assert(else_inst == NULL || else_inst->header.opcode == BRW_OPCODE_ELSE);

   unsigned br = 1;
   /* Jump count is for 64bit data chunk each, so one 128bit instruction
    * requires 2 chunks.
    */
   if (brw->gen >= 5)
      br = 2;

   assert(endif_inst->header.opcode == BRW_OPCODE_ENDIF);
   endif_inst->header.execution_size = if_inst->header.execution_size;

   if (else_inst == NULL) {
      /* Patch IF -> ENDIF */
      if (brw->gen < 6) {
	 /* Turn it into an IFF, which means no mask stack operations for
	  * all-false and jumping past the ENDIF.
	  */
	 if_inst->header.opcode = BRW_OPCODE_IFF;
	 if_inst->bits3.if_else.jump_count = br * (endif_inst - if_inst + 1);
	 if_inst->bits3.if_else.pop_count = 0;
	 if_inst->bits3.if_else.pad0 = 0;
      } else if (brw->gen == 6) {
	 /* As of gen6, there is no IFF and IF must point to the ENDIF. */
	 if_inst->bits1.branch_gen6.jump_count = br * (endif_inst - if_inst);
      } else {
	 if_inst->bits3.break_cont.uip = br * (endif_inst - if_inst);
	 if_inst->bits3.break_cont.jip = br * (endif_inst - if_inst);
      }
   } else {
      else_inst->header.execution_size = if_inst->header.execution_size;

      /* Patch IF -> ELSE */
      if (brw->gen < 6) {
	 if_inst->bits3.if_else.jump_count = br * (else_inst - if_inst);
	 if_inst->bits3.if_else.pop_count = 0;
	 if_inst->bits3.if_else.pad0 = 0;
      } else if (brw->gen == 6) {
	 if_inst->bits1.branch_gen6.jump_count = br * (else_inst - if_inst + 1);
      }

      /* Patch ELSE -> ENDIF */
      if (brw->gen < 6) {
	 /* BRW_OPCODE_ELSE pre-gen6 should point just past the
	  * matching ENDIF.
	  */
	 else_inst->bits3.if_else.jump_count = br*(endif_inst - else_inst + 1);
	 else_inst->bits3.if_else.pop_count = 1;
	 else_inst->bits3.if_else.pad0 = 0;
      } else if (brw->gen == 6) {
	 /* BRW_OPCODE_ELSE on gen6 should point to the matching ENDIF. */
	 else_inst->bits1.branch_gen6.jump_count = br*(endif_inst - else_inst);
      } else {
	 /* The IF instruction's JIP should point just past the ELSE */
	 if_inst->bits3.break_cont.jip = br * (else_inst - if_inst + 1);
	 /* The IF instruction's UIP and ELSE's JIP should point to ENDIF */
	 if_inst->bits3.break_cont.uip = br * (endif_inst - if_inst);
	 else_inst->bits3.break_cont.jip = br * (endif_inst - else_inst);
      }
   }
}

void
brw_ELSE(struct brw_compile *p)
{
   struct brw_context *brw = p->brw;
   struct brw_instruction *insn;

   insn = next_insn(p, BRW_OPCODE_ELSE);

   if (brw->gen < 6) {
      brw_set_dest(p, insn, brw_ip_reg());
      brw_set_src0(p, insn, brw_ip_reg());
      brw_set_src1(p, insn, brw_imm_d(0x0));
   } else if (brw->gen == 6) {
      brw_set_dest(p, insn, brw_imm_w(0));
      insn->bits1.branch_gen6.jump_count = 0;
      brw_set_src0(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
      brw_set_src1(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
   } else {
      brw_set_dest(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
      brw_set_src0(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
      brw_set_src1(p, insn, brw_imm_ud(0));
      insn->bits3.break_cont.jip = 0;
      insn->bits3.break_cont.uip = 0;
   }

   insn->header.compression_control = BRW_COMPRESSION_NONE;
   insn->header.mask_control = BRW_MASK_ENABLE;
   if (!p->single_program_flow)
      insn->header.thread_control = BRW_THREAD_SWITCH;

   push_if_stack(p, insn);
}

void
brw_ENDIF(struct brw_compile *p)
{
   struct brw_context *brw = p->brw;
   struct brw_instruction *insn = NULL;
   struct brw_instruction *else_inst = NULL;
   struct brw_instruction *if_inst = NULL;
   struct brw_instruction *tmp;
   bool emit_endif = true;

   /* In single program flow mode, we can express IF and ELSE instructions
    * equivalently as ADD instructions that operate on IP.  On platforms prior
    * to Gen6, flow control instructions cause an implied thread switch, so
    * this is a significant savings.
    *
    * However, on Gen6, writing to IP doesn't work in single program flow mode
    * (see the SandyBridge PRM, Volume 4 part 2, p79: "When SPF is ON, IP may
    * not be updated by non-flow control instructions.").  And on later
    * platforms, there is no significant benefit to converting control flow
    * instructions to conditional ADDs.  So we only do this trick on Gen4 and
    * Gen5.
    */
   if (brw->gen < 6 && p->single_program_flow)
      emit_endif = false;

   /*
    * A single next_insn() may change the base adress of instruction store
    * memory(p->store), so call it first before referencing the instruction
    * store pointer from an index
    */
   if (emit_endif)
      insn = next_insn(p, BRW_OPCODE_ENDIF);

   /* Pop the IF and (optional) ELSE instructions from the stack */
   p->if_depth_in_loop[p->loop_stack_depth]--;
   tmp = pop_if_stack(p);
   if (tmp->header.opcode == BRW_OPCODE_ELSE) {
      else_inst = tmp;
      tmp = pop_if_stack(p);
   }
   if_inst = tmp;

   if (!emit_endif) {
      /* ENDIF is useless; don't bother emitting it. */
      convert_IF_ELSE_to_ADD(p, if_inst, else_inst);
      return;
   }

   if (brw->gen < 6) {
      brw_set_dest(p, insn, retype(brw_vec4_grf(0,0), BRW_REGISTER_TYPE_UD));
      brw_set_src0(p, insn, retype(brw_vec4_grf(0,0), BRW_REGISTER_TYPE_UD));
      brw_set_src1(p, insn, brw_imm_d(0x0));
   } else if (brw->gen == 6) {
      brw_set_dest(p, insn, brw_imm_w(0));
      brw_set_src0(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
      brw_set_src1(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
   } else {
      brw_set_dest(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
      brw_set_src0(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
      brw_set_src1(p, insn, brw_imm_ud(0));
   }

   insn->header.compression_control = BRW_COMPRESSION_NONE;
   insn->header.mask_control = BRW_MASK_ENABLE;
   insn->header.thread_control = BRW_THREAD_SWITCH;

   /* Also pop item off the stack in the endif instruction: */
   if (brw->gen < 6) {
      insn->bits3.if_else.jump_count = 0;
      insn->bits3.if_else.pop_count = 1;
      insn->bits3.if_else.pad0 = 0;
   } else if (brw->gen == 6) {
      insn->bits1.branch_gen6.jump_count = 2;
   } else {
      insn->bits3.break_cont.jip = 2;
   }
   patch_IF_ELSE(p, if_inst, else_inst, insn);
}

struct brw_instruction *brw_BREAK(struct brw_compile *p)
{
   struct brw_context *brw = p->brw;
   struct brw_instruction *insn;

   insn = next_insn(p, BRW_OPCODE_BREAK);
   if (brw->gen >= 6) {
      brw_set_dest(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
      brw_set_src0(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
      brw_set_src1(p, insn, brw_imm_d(0x0));
   } else {
      brw_set_dest(p, insn, brw_ip_reg());
      brw_set_src0(p, insn, brw_ip_reg());
      brw_set_src1(p, insn, brw_imm_d(0x0));
      insn->bits3.if_else.pad0 = 0;
      insn->bits3.if_else.pop_count = p->if_depth_in_loop[p->loop_stack_depth];
   }
   insn->header.compression_control = BRW_COMPRESSION_NONE;
   insn->header.execution_size = BRW_EXECUTE_8;

   return insn;
}

struct brw_instruction *gen6_CONT(struct brw_compile *p)
{
   struct brw_instruction *insn;

   insn = next_insn(p, BRW_OPCODE_CONTINUE);
   brw_set_dest(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
   brw_set_src0(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
   brw_set_dest(p, insn, brw_ip_reg());
   brw_set_src0(p, insn, brw_ip_reg());
   brw_set_src1(p, insn, brw_imm_d(0x0));

   insn->header.compression_control = BRW_COMPRESSION_NONE;
   insn->header.execution_size = BRW_EXECUTE_8;
   return insn;
}

struct brw_instruction *brw_CONT(struct brw_compile *p)
{
   struct brw_instruction *insn;
   insn = next_insn(p, BRW_OPCODE_CONTINUE);
   brw_set_dest(p, insn, brw_ip_reg());
   brw_set_src0(p, insn, brw_ip_reg());
   brw_set_src1(p, insn, brw_imm_d(0x0));
   insn->header.compression_control = BRW_COMPRESSION_NONE;
   insn->header.execution_size = BRW_EXECUTE_8;
   /* insn->header.mask_control = BRW_MASK_DISABLE; */
   insn->bits3.if_else.pad0 = 0;
   insn->bits3.if_else.pop_count = p->if_depth_in_loop[p->loop_stack_depth];
   return insn;
}

struct brw_instruction *gen6_HALT(struct brw_compile *p)
{
   struct brw_instruction *insn;

   insn = next_insn(p, BRW_OPCODE_HALT);
   brw_set_dest(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
   brw_set_src0(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
   brw_set_src1(p, insn, brw_imm_d(0x0)); /* UIP and JIP, updated later. */

   if (p->compressed) {
      insn->header.execution_size = BRW_EXECUTE_16;
   } else {
      insn->header.compression_control = BRW_COMPRESSION_NONE;
      insn->header.execution_size = BRW_EXECUTE_8;
   }
   return insn;
}

/* DO/WHILE loop:
 *
 * The DO/WHILE is just an unterminated loop -- break or continue are
 * used for control within the loop.  We have a few ways they can be
 * done.
 *
 * For uniform control flow, the WHILE is just a jump, so ADD ip, ip,
 * jip and no DO instruction.
 *
 * For non-uniform control flow pre-gen6, there's a DO instruction to
 * push the mask, and a WHILE to jump back, and BREAK to get out and
 * pop the mask.
 *
 * For gen6, there's no more mask stack, so no need for DO.  WHILE
 * just points back to the first instruction of the loop.
 */
struct brw_instruction *brw_DO(struct brw_compile *p, unsigned execute_size)
{
   struct brw_context *brw = p->brw;

   if (brw->gen >= 6 || p->single_program_flow) {
      push_loop_stack(p, &p->store[p->nr_insn]);
      return &p->store[p->nr_insn];
   } else {
      struct brw_instruction *insn = next_insn(p, BRW_OPCODE_DO);

      push_loop_stack(p, insn);

      /* Override the defaults for this instruction:
       */
      brw_set_dest(p, insn, brw_null_reg());
      brw_set_src0(p, insn, brw_null_reg());
      brw_set_src1(p, insn, brw_null_reg());

      insn->header.compression_control = BRW_COMPRESSION_NONE;
      insn->header.execution_size = execute_size;
      insn->header.predicate_control = BRW_PREDICATE_NONE;
      /* insn->header.mask_control = BRW_MASK_ENABLE; */
      /* insn->header.mask_control = BRW_MASK_DISABLE; */

      return insn;
   }
}

/**
 * For pre-gen6, we patch BREAK/CONT instructions to point at the WHILE
 * instruction here.
 *
 * For gen6+, see brw_set_uip_jip(), which doesn't care so much about the loop
 * nesting, since it can always just point to the end of the block/current loop.
 */
static void
brw_patch_break_cont(struct brw_compile *p, struct brw_instruction *while_inst)
{
   struct brw_context *brw = p->brw;
   struct brw_instruction *do_inst = get_inner_do_insn(p);
   struct brw_instruction *inst;
   int br = (brw->gen == 5) ? 2 : 1;

   for (inst = while_inst - 1; inst != do_inst; inst--) {
      /* If the jump count is != 0, that means that this instruction has already
       * been patched because it's part of a loop inside of the one we're
       * patching.
       */
      if (inst->header.opcode == BRW_OPCODE_BREAK &&
	  inst->bits3.if_else.jump_count == 0) {
	 inst->bits3.if_else.jump_count = br * ((while_inst - inst) + 1);
      } else if (inst->header.opcode == BRW_OPCODE_CONTINUE &&
		 inst->bits3.if_else.jump_count == 0) {
	 inst->bits3.if_else.jump_count = br * (while_inst - inst);
      }
   }
}

struct brw_instruction *brw_WHILE(struct brw_compile *p)
{
   struct brw_context *brw = p->brw;
   struct brw_instruction *insn, *do_insn;
   unsigned br = 1;

   if (brw->gen >= 5)
      br = 2;

   if (brw->gen >= 7) {
      insn = next_insn(p, BRW_OPCODE_WHILE);
      do_insn = get_inner_do_insn(p);

      brw_set_dest(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
      brw_set_src0(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
      brw_set_src1(p, insn, brw_imm_ud(0));
      insn->bits3.break_cont.jip = br * (do_insn - insn);

      insn->header.execution_size = BRW_EXECUTE_8;
   } else if (brw->gen == 6) {
      insn = next_insn(p, BRW_OPCODE_WHILE);
      do_insn = get_inner_do_insn(p);

      brw_set_dest(p, insn, brw_imm_w(0));
      insn->bits1.branch_gen6.jump_count = br * (do_insn - insn);
      brw_set_src0(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
      brw_set_src1(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));

      insn->header.execution_size = BRW_EXECUTE_8;
   } else {
      if (p->single_program_flow) {
	 insn = next_insn(p, BRW_OPCODE_ADD);
         do_insn = get_inner_do_insn(p);

	 brw_set_dest(p, insn, brw_ip_reg());
	 brw_set_src0(p, insn, brw_ip_reg());
	 brw_set_src1(p, insn, brw_imm_d((do_insn - insn) * 16));
	 insn->header.execution_size = BRW_EXECUTE_1;
      } else {
	 insn = next_insn(p, BRW_OPCODE_WHILE);
         do_insn = get_inner_do_insn(p);

	 assert(do_insn->header.opcode == BRW_OPCODE_DO);

	 brw_set_dest(p, insn, brw_ip_reg());
	 brw_set_src0(p, insn, brw_ip_reg());
	 brw_set_src1(p, insn, brw_imm_d(0));

	 insn->header.execution_size = do_insn->header.execution_size;
	 insn->bits3.if_else.jump_count = br * (do_insn - insn + 1);
	 insn->bits3.if_else.pop_count = 0;
	 insn->bits3.if_else.pad0 = 0;

	 brw_patch_break_cont(p, insn);
      }
   }
   insn->header.compression_control = BRW_COMPRESSION_NONE;
   p->current->header.predicate_control = BRW_PREDICATE_NONE;

   p->loop_stack_depth--;

   return insn;
}


/* FORWARD JUMPS:
 */
void brw_land_fwd_jump(struct brw_compile *p, int jmp_insn_idx)
{
   struct brw_context *brw = p->brw;
   struct brw_instruction *jmp_insn = &p->store[jmp_insn_idx];
   unsigned jmpi = 1;

   if (brw->gen >= 5)
      jmpi = 2;

   assert(jmp_insn->header.opcode == BRW_OPCODE_JMPI);
   assert(jmp_insn->bits1.da1.src1_reg_file == BRW_IMMEDIATE_VALUE);

   jmp_insn->bits3.ud = jmpi * (p->nr_insn - jmp_insn_idx - 1);
}



/* To integrate with the above, it makes sense that the comparison
 * instruction should populate the flag register.  It might be simpler
 * just to use the flag reg for most WM tasks?
 */
void brw_CMP(struct brw_compile *p,
	     struct brw_reg dest,
	     unsigned conditional,
	     struct brw_reg src0,
	     struct brw_reg src1)
{
   struct brw_context *brw = p->brw;
   struct brw_instruction *insn = next_insn(p, BRW_OPCODE_CMP);

   insn->header.destreg__conditionalmod = conditional;
   brw_set_dest(p, insn, dest);
   brw_set_src0(p, insn, src0);
   brw_set_src1(p, insn, src1);

/*    guess_execution_size(insn, src0); */


   /* Make it so that future instructions will use the computed flag
    * value until brw_set_predicate_control_flag_value() is called
    * again.
    */
   if (dest.file == BRW_ARCHITECTURE_REGISTER_FILE &&
       dest.nr == 0) {
      p->current->header.predicate_control = BRW_PREDICATE_NORMAL;
      p->flag_value = 0xff;
   }

   /* Item WaCMPInstNullDstForcesThreadSwitch in the Haswell Bspec workarounds
    * page says:
    *    "Any CMP instruction with a null destination must use a {switch}."
    *
    * It also applies to other Gen7 platforms (IVB, BYT) even though it isn't
    * mentioned on their work-arounds pages.
    */
   if (brw->gen == 7) {
      if (dest.file == BRW_ARCHITECTURE_REGISTER_FILE &&
          dest.nr == BRW_ARF_NULL) {
         insn->header.thread_control = BRW_THREAD_SWITCH;
      }
   }
}

/* Issue 'wait' instruction for n1, host could program MMIO
   to wake up thread. */
void brw_WAIT (struct brw_compile *p)
{
   struct brw_instruction *insn = next_insn(p, BRW_OPCODE_WAIT);
   struct brw_reg src = brw_notification_1_reg();

   brw_set_dest(p, insn, src);
   brw_set_src0(p, insn, src);
   brw_set_src1(p, insn, brw_null_reg());
   insn->header.execution_size = 0; /* must */
   insn->header.predicate_control = 0;
   insn->header.compression_control = 0;
}


/***********************************************************************
 * Helpers for the various SEND message types:
 */

/** Extended math function, float[8].
 */
void brw_math( struct brw_compile *p,
	       struct brw_reg dest,
	       unsigned function,
	       unsigned msg_reg_nr,
	       struct brw_reg src,
	       unsigned data_type,
	       unsigned precision )
{
   struct brw_context *brw = p->brw;

   if (brw->gen >= 6) {
      struct brw_instruction *insn = next_insn(p, BRW_OPCODE_MATH);

      assert(dest.file == BRW_GENERAL_REGISTER_FILE ||
             (brw->gen >= 7 && dest.file == BRW_MESSAGE_REGISTER_FILE));
      assert(src.file == BRW_GENERAL_REGISTER_FILE);

      assert(dest.hstride == BRW_HORIZONTAL_STRIDE_1);
      if (brw->gen == 6)
	 assert(src.hstride == BRW_HORIZONTAL_STRIDE_1);

      /* Source modifiers are ignored for extended math instructions on Gen6. */
      if (brw->gen == 6) {
	 assert(!src.negate);
	 assert(!src.abs);
      }

      if (function == BRW_MATH_FUNCTION_INT_DIV_QUOTIENT ||
	  function == BRW_MATH_FUNCTION_INT_DIV_REMAINDER ||
	  function == BRW_MATH_FUNCTION_INT_DIV_QUOTIENT_AND_REMAINDER) {
	 assert(src.type != BRW_REGISTER_TYPE_F);
      } else {
	 assert(src.type == BRW_REGISTER_TYPE_F);
      }

      /* Math is the same ISA format as other opcodes, except that CondModifier
       * becomes FC[3:0] and ThreadCtrl becomes FC[5:4].
       */
      insn->header.destreg__conditionalmod = function;

      brw_set_dest(p, insn, dest);
      brw_set_src0(p, insn, src);
      brw_set_src1(p, insn, brw_null_reg());
   } else {
      struct brw_instruction *insn = next_insn(p, BRW_OPCODE_SEND);

      /* Example code doesn't set predicate_control for send
       * instructions.
       */
      insn->header.predicate_control = 0;
      insn->header.destreg__conditionalmod = msg_reg_nr;

      brw_set_dest(p, insn, dest);
      brw_set_src0(p, insn, src);
      brw_set_math_message(p,
			   insn,
			   function,
			   src.type == BRW_REGISTER_TYPE_D,
			   precision,
			   data_type);
   }
}

/** Extended math function, float[8].
 */
void brw_math2(struct brw_compile *p,
	       struct brw_reg dest,
	       unsigned function,
	       struct brw_reg src0,
	       struct brw_reg src1)
{
   struct brw_context *brw = p->brw;
   struct brw_instruction *insn = next_insn(p, BRW_OPCODE_MATH);

   assert(dest.file == BRW_GENERAL_REGISTER_FILE ||
          (brw->gen >= 7 && dest.file == BRW_MESSAGE_REGISTER_FILE));
   assert(src0.file == BRW_GENERAL_REGISTER_FILE);
   assert(src1.file == BRW_GENERAL_REGISTER_FILE);

   assert(dest.hstride == BRW_HORIZONTAL_STRIDE_1);
   if (brw->gen == 6) {
      assert(src0.hstride == BRW_HORIZONTAL_STRIDE_1);
      assert(src1.hstride == BRW_HORIZONTAL_STRIDE_1);
   }

   if (function == BRW_MATH_FUNCTION_INT_DIV_QUOTIENT ||
       function == BRW_MATH_FUNCTION_INT_DIV_REMAINDER ||
       function == BRW_MATH_FUNCTION_INT_DIV_QUOTIENT_AND_REMAINDER) {
      assert(src0.type != BRW_REGISTER_TYPE_F);
      assert(src1.type != BRW_REGISTER_TYPE_F);
   } else {
      assert(src0.type == BRW_REGISTER_TYPE_F);
      assert(src1.type == BRW_REGISTER_TYPE_F);
   }

   /* Source modifiers are ignored for extended math instructions on Gen6. */
   if (brw->gen == 6) {
      assert(!src0.negate);
      assert(!src0.abs);
      assert(!src1.negate);
      assert(!src1.abs);
   }

   /* Math is the same ISA format as other opcodes, except that CondModifier
    * becomes FC[3:0] and ThreadCtrl becomes FC[5:4].
    */
   insn->header.destreg__conditionalmod = function;

   brw_set_dest(p, insn, dest);
   brw_set_src0(p, insn, src0);
   brw_set_src1(p, insn, src1);
}


/**
 * Write a block of OWORDs (half a GRF each) from the scratch buffer,
 * using a constant offset per channel.
 *
 * The offset must be aligned to oword size (16 bytes).  Used for
 * register spilling.
 */
void brw_oword_block_write_scratch(struct brw_compile *p,
				   struct brw_reg mrf,
				   int num_regs,
				   unsigned offset)
{
   struct brw_context *brw = p->brw;
   uint32_t msg_control, msg_type;
   int mlen;

   if (brw->gen >= 6)
      offset /= 16;

   mrf = retype(mrf, BRW_REGISTER_TYPE_UD);

   if (num_regs == 1) {
      msg_control = BRW_DATAPORT_OWORD_BLOCK_2_OWORDS;
      mlen = 2;
   } else {
      msg_control = BRW_DATAPORT_OWORD_BLOCK_4_OWORDS;
      mlen = 3;
   }

   /* Set up the message header.  This is g0, with g0.2 filled with
    * the offset.  We don't want to leave our offset around in g0 or
    * it'll screw up texture samples, so set it up inside the message
    * reg.
    */
   {
      brw_push_insn_state(p);
      brw_set_mask_control(p, BRW_MASK_DISABLE);
      brw_set_compression_control(p, BRW_COMPRESSION_NONE);

      brw_MOV(p, mrf, retype(brw_vec8_grf(0, 0), BRW_REGISTER_TYPE_UD));

      /* set message header global offset field (reg 0, element 2) */
      brw_MOV(p,
	      retype(brw_vec1_reg(BRW_MESSAGE_REGISTER_FILE,
				  mrf.nr,
				  2), BRW_REGISTER_TYPE_UD),
	      brw_imm_ud(offset));

      brw_pop_insn_state(p);
   }

   {
      struct brw_reg dest;
      struct brw_instruction *insn = next_insn(p, BRW_OPCODE_SEND);
      int send_commit_msg;
      struct brw_reg src_header = retype(brw_vec8_grf(0, 0),
					 BRW_REGISTER_TYPE_UW);

      if (insn->header.compression_control != BRW_COMPRESSION_NONE) {
	 insn->header.compression_control = BRW_COMPRESSION_NONE;
	 src_header = vec16(src_header);
      }
      assert(insn->header.predicate_control == BRW_PREDICATE_NONE);
      insn->header.destreg__conditionalmod = mrf.nr;

      /* Until gen6, writes followed by reads from the same location
       * are not guaranteed to be ordered unless write_commit is set.
       * If set, then a no-op write is issued to the destination
       * register to set a dependency, and a read from the destination
       * can be used to ensure the ordering.
       *
       * For gen6, only writes between different threads need ordering
       * protection.  Our use of DP writes is all about register
       * spilling within a thread.
       */
      if (brw->gen >= 6) {
	 dest = retype(vec16(brw_null_reg()), BRW_REGISTER_TYPE_UW);
	 send_commit_msg = 0;
      } else {
	 dest = src_header;
	 send_commit_msg = 1;
      }

      brw_set_dest(p, insn, dest);
      if (brw->gen >= 6) {
	 brw_set_src0(p, insn, mrf);
      } else {
	 brw_set_src0(p, insn, brw_null_reg());
      }

      if (brw->gen >= 6)
	 msg_type = GEN6_DATAPORT_WRITE_MESSAGE_OWORD_BLOCK_WRITE;
      else
	 msg_type = BRW_DATAPORT_WRITE_MESSAGE_OWORD_BLOCK_WRITE;

      brw_set_dp_write_message(p,
			       insn,
			       255, /* binding table index (255=stateless) */
			       msg_control,
			       msg_type,
			       mlen,
			       true, /* header_present */
			       0, /* not a render target */
			       send_commit_msg, /* response_length */
			       0, /* eot */
			       send_commit_msg);
   }
}


/**
 * Read a block of owords (half a GRF each) from the scratch buffer
 * using a constant index per channel.
 *
 * Offset must be aligned to oword size (16 bytes).  Used for register
 * spilling.
 */
void
brw_oword_block_read_scratch(struct brw_compile *p,
			     struct brw_reg dest,
			     struct brw_reg mrf,
			     int num_regs,
			     unsigned offset)
{
   struct brw_context *brw = p->brw;
   uint32_t msg_control;
   int rlen;

   if (brw->gen >= 6)
      offset /= 16;

   mrf = retype(mrf, BRW_REGISTER_TYPE_UD);
   dest = retype(dest, BRW_REGISTER_TYPE_UW);

   if (num_regs == 1) {
      msg_control = BRW_DATAPORT_OWORD_BLOCK_2_OWORDS;
      rlen = 1;
   } else {
      msg_control = BRW_DATAPORT_OWORD_BLOCK_4_OWORDS;
      rlen = 2;
   }

   {
      brw_push_insn_state(p);
      brw_set_compression_control(p, BRW_COMPRESSION_NONE);
      brw_set_mask_control(p, BRW_MASK_DISABLE);

      brw_MOV(p, mrf, retype(brw_vec8_grf(0, 0), BRW_REGISTER_TYPE_UD));

      /* set message header global offset field (reg 0, element 2) */
      brw_MOV(p,
	      retype(brw_vec1_reg(BRW_MESSAGE_REGISTER_FILE,
				  mrf.nr,
				  2), BRW_REGISTER_TYPE_UD),
	      brw_imm_ud(offset));

      brw_pop_insn_state(p);
   }

   {
      struct brw_instruction *insn = next_insn(p, BRW_OPCODE_SEND);

      assert(insn->header.predicate_control == 0);
      insn->header.compression_control = BRW_COMPRESSION_NONE;
      insn->header.destreg__conditionalmod = mrf.nr;

      brw_set_dest(p, insn, dest);	/* UW? */
      if (brw->gen >= 6) {
	 brw_set_src0(p, insn, mrf);
      } else {
	 brw_set_src0(p, insn, brw_null_reg());
      }

      brw_set_dp_read_message(p,
			      insn,
			      255, /* binding table index (255=stateless) */
			      msg_control,
			      BRW_DATAPORT_READ_MESSAGE_OWORD_BLOCK_READ, /* msg_type */
			      BRW_DATAPORT_READ_TARGET_RENDER_CACHE,
			      1, /* msg_length */
                              true, /* header_present */
			      rlen);
   }
}

void
gen7_block_read_scratch(struct brw_compile *p,
                        struct brw_reg dest,
                        int num_regs,
                        unsigned offset)
{
   dest = retype(dest, BRW_REGISTER_TYPE_UW);

   struct brw_instruction *insn = next_insn(p, BRW_OPCODE_SEND);

   assert(insn->header.predicate_control == BRW_PREDICATE_NONE);
   insn->header.compression_control = BRW_COMPRESSION_NONE;

   brw_set_dest(p, insn, dest);

   /* The HW requires that the header is present; this is to get the g0.5
    * scratch offset.
    */
   bool header_present = true;
   brw_set_src0(p, insn, brw_vec8_grf(0, 0));

   brw_set_message_descriptor(p, insn,
                              GEN7_SFID_DATAPORT_DATA_CACHE,
                              1, /* mlen: just g0 */
                              num_regs,
                              header_present,
                              false);

   insn->bits3.ud |= GEN7_DATAPORT_SCRATCH_READ;

   assert(num_regs == 1 || num_regs == 2 || num_regs == 4);
   insn->bits3.ud |= (num_regs - 1) << GEN7_DATAPORT_SCRATCH_NUM_REGS_SHIFT;

   /* According to the docs, offset is "A 12-bit HWord offset into the memory
    * Immediate Memory buffer as specified by binding table 0xFF."  An HWORD
    * is 32 bytes, which happens to be the size of a register.
    */
   offset /= REG_SIZE;
   assert(offset < (1 << 12));
   insn->bits3.ud |= offset;
}

/**
 * Read a float[4] vector from the data port Data Cache (const buffer).
 * Location (in buffer) should be a multiple of 16.
 * Used for fetching shader constants.
 */
void brw_oword_block_read(struct brw_compile *p,
			  struct brw_reg dest,
			  struct brw_reg mrf,
			  uint32_t offset,
			  uint32_t bind_table_index)
{
   struct brw_context *brw = p->brw;

   /* On newer hardware, offset is in units of owords. */
   if (brw->gen >= 6)
      offset /= 16;

   mrf = retype(mrf, BRW_REGISTER_TYPE_UD);

   brw_push_insn_state(p);
   brw_set_predicate_control(p, BRW_PREDICATE_NONE);
   brw_set_compression_control(p, BRW_COMPRESSION_NONE);
   brw_set_mask_control(p, BRW_MASK_DISABLE);

   brw_MOV(p, mrf, retype(brw_vec8_grf(0, 0), BRW_REGISTER_TYPE_UD));

   /* set message header global offset field (reg 0, element 2) */
   brw_MOV(p,
	   retype(brw_vec1_reg(BRW_MESSAGE_REGISTER_FILE,
			       mrf.nr,
			       2), BRW_REGISTER_TYPE_UD),
	   brw_imm_ud(offset));

   struct brw_instruction *insn = next_insn(p, BRW_OPCODE_SEND);
   insn->header.destreg__conditionalmod = mrf.nr;

   /* cast dest to a uword[8] vector */
   dest = retype(vec8(dest), BRW_REGISTER_TYPE_UW);

   brw_set_dest(p, insn, dest);
   if (brw->gen >= 6) {
      brw_set_src0(p, insn, mrf);
   } else {
      brw_set_src0(p, insn, brw_null_reg());
   }

   brw_set_dp_read_message(p,
			   insn,
			   bind_table_index,
			   BRW_DATAPORT_OWORD_BLOCK_1_OWORDLOW,
			   BRW_DATAPORT_READ_MESSAGE_OWORD_BLOCK_READ,
			   BRW_DATAPORT_READ_TARGET_DATA_CACHE,
			   1, /* msg_length */
                           true, /* header_present */
			   1); /* response_length (1 reg, 2 owords!) */

   brw_pop_insn_state(p);
}


void brw_fb_WRITE(struct brw_compile *p,
		  int dispatch_width,
                  unsigned msg_reg_nr,
                  struct brw_reg src0,
                  unsigned msg_control,
                  unsigned binding_table_index,
                  unsigned msg_length,
                  unsigned response_length,
                  bool eot,
                  bool header_present)
{
   struct brw_context *brw = p->brw;
   struct brw_instruction *insn;
   unsigned msg_type;
   struct brw_reg dest;

   if (dispatch_width == 16)
      dest = retype(vec16(brw_null_reg()), BRW_REGISTER_TYPE_UW);
   else
      dest = retype(vec8(brw_null_reg()), BRW_REGISTER_TYPE_UW);

   if (brw->gen >= 6) {
      insn = next_insn(p, BRW_OPCODE_SENDC);
   } else {
      insn = next_insn(p, BRW_OPCODE_SEND);
   }
   insn->header.compression_control = BRW_COMPRESSION_NONE;

   if (brw->gen >= 6) {
      /* headerless version, just submit color payload */
      src0 = brw_message_reg(msg_reg_nr);

      msg_type = GEN6_DATAPORT_WRITE_MESSAGE_RENDER_TARGET_WRITE;
   } else {
      insn->header.destreg__conditionalmod = msg_reg_nr;

      msg_type = BRW_DATAPORT_WRITE_MESSAGE_RENDER_TARGET_WRITE;
   }

   brw_set_dest(p, insn, dest);
   brw_set_src0(p, insn, src0);
   brw_set_dp_write_message(p,
			    insn,
			    binding_table_index,
			    msg_control,
			    msg_type,
			    msg_length,
			    header_present,
			    eot, /* last render target write */
			    response_length,
			    eot,
			    0 /* send_commit_msg */);
}


/**
 * Texture sample instruction.
 * Note: the msg_type plus msg_length values determine exactly what kind
 * of sampling operation is performed.  See volume 4, page 161 of docs.
 */
void brw_SAMPLE(struct brw_compile *p,
		struct brw_reg dest,
		unsigned msg_reg_nr,
		struct brw_reg src0,
		unsigned binding_table_index,
		unsigned sampler,
		unsigned msg_type,
		unsigned response_length,
		unsigned msg_length,
		unsigned header_present,
		unsigned simd_mode,
		unsigned return_format)
{
   struct brw_context *brw = p->brw;
   struct brw_instruction *insn;

   if (msg_reg_nr != -1)
      gen6_resolve_implied_move(p, &src0, msg_reg_nr);

   insn = next_insn(p, BRW_OPCODE_SEND);
   insn->header.predicate_control = 0; /* XXX */

   /* From the 965 PRM (volume 4, part 1, section 14.2.41):
    *
    *    "Instruction compression is not allowed for this instruction (that
    *     is, send). The hardware behavior is undefined if this instruction is
    *     set as compressed. However, compress control can be set to "SecHalf"
    *     to affect the EMask generation."
    *
    * No similar wording is found in later PRMs, but there are examples
    * utilizing send with SecHalf.  More importantly, SIMD8 sampler messages
    * are allowed in SIMD16 mode and they could not work without SecHalf.  For
    * these reasons, we allow BRW_COMPRESSION_2NDHALF here.
    */
   if (insn->header.compression_control != BRW_COMPRESSION_2NDHALF)
      insn->header.compression_control = BRW_COMPRESSION_NONE;

   if (brw->gen < 6)
      insn->header.destreg__conditionalmod = msg_reg_nr;

   brw_set_dest(p, insn, dest);
   brw_set_src0(p, insn, src0);
   brw_set_sampler_message(p, insn,
                           binding_table_index,
                           sampler,
                           msg_type,
                           response_length,
                           msg_length,
                           header_present,
                           simd_mode,
                           return_format);
}

/* All these variables are pretty confusing - we might be better off
 * using bitmasks and macros for this, in the old style.  Or perhaps
 * just having the caller instantiate the fields in dword3 itself.
 */
void brw_urb_WRITE(struct brw_compile *p,
		   struct brw_reg dest,
		   unsigned msg_reg_nr,
		   struct brw_reg src0,
                   enum brw_urb_write_flags flags,
		   unsigned msg_length,
		   unsigned response_length,
		   unsigned offset,
		   unsigned swizzle)
{
   struct brw_context *brw = p->brw;
   struct brw_instruction *insn;

   gen6_resolve_implied_move(p, &src0, msg_reg_nr);

   if (brw->gen == 7 && !(flags & BRW_URB_WRITE_USE_CHANNEL_MASKS)) {
      /* Enable Channel Masks in the URB_WRITE_HWORD message header */
      brw_push_insn_state(p);
      brw_set_access_mode(p, BRW_ALIGN_1);
      brw_set_mask_control(p, BRW_MASK_DISABLE);
      brw_OR(p, retype(brw_vec1_reg(BRW_MESSAGE_REGISTER_FILE, msg_reg_nr, 5),
		       BRW_REGISTER_TYPE_UD),
	        retype(brw_vec1_grf(0, 5), BRW_REGISTER_TYPE_UD),
		brw_imm_ud(0xff00));
      brw_pop_insn_state(p);
   }

   insn = next_insn(p, BRW_OPCODE_SEND);

   assert(msg_length < BRW_MAX_MRF);

   brw_set_dest(p, insn, dest);
   brw_set_src0(p, insn, src0);
   brw_set_src1(p, insn, brw_imm_d(0));

   if (brw->gen < 6)
      insn->header.destreg__conditionalmod = msg_reg_nr;

   brw_set_urb_message(p,
		       insn,
		       flags,
		       msg_length,
		       response_length,
		       offset,
		       swizzle);
}

static int
next_ip(struct brw_compile *p, int ip)
{
   struct brw_instruction *insn = (void *)p->store + ip;

   if (insn->header.cmpt_control)
      return ip + 8;
   else
      return ip + 16;
}

static int
brw_find_next_block_end(struct brw_compile *p, int start)
{
   int ip;
   void *store = p->store;

   for (ip = next_ip(p, start); ip < p->next_insn_offset; ip = next_ip(p, ip)) {
      struct brw_instruction *insn = store + ip;

      switch (insn->header.opcode) {
      case BRW_OPCODE_ENDIF:
      case BRW_OPCODE_ELSE:
      case BRW_OPCODE_WHILE:
      case BRW_OPCODE_HALT:
	 return ip;
      }
   }

   return 0;
}

/* There is no DO instruction on gen6, so to find the end of the loop
 * we have to see if the loop is jumping back before our start
 * instruction.
 */
static int
brw_find_loop_end(struct brw_compile *p, int start)
{
   struct brw_context *brw = p->brw;
   int ip;
   int scale = 8;
   void *store = p->store;

   /* Always start after the instruction (such as a WHILE) we're trying to fix
    * up.
    */
   for (ip = next_ip(p, start); ip < p->next_insn_offset; ip = next_ip(p, ip)) {
      struct brw_instruction *insn = store + ip;

      if (insn->header.opcode == BRW_OPCODE_WHILE) {
	 int jip = brw->gen == 6 ? insn->bits1.branch_gen6.jump_count
				   : insn->bits3.break_cont.jip;
	 if (ip + jip * scale <= start)
	    return ip;
      }
   }
   assert(!"not reached");
   return start;
}

/* After program generation, go back and update the UIP and JIP of
 * BREAK, CONT, and HALT instructions to their correct locations.
 */
void
brw_set_uip_jip(struct brw_compile *p)
{
   struct brw_context *brw = p->brw;
   int ip;
   int scale = 8;
   void *store = p->store;

   if (brw->gen < 6)
      return;

   for (ip = 0; ip < p->next_insn_offset; ip = next_ip(p, ip)) {
      struct brw_instruction *insn = store + ip;

      if (insn->header.cmpt_control) {
	 /* Fixups for compacted BREAK/CONTINUE not supported yet. */
	 assert(insn->header.opcode != BRW_OPCODE_BREAK &&
		insn->header.opcode != BRW_OPCODE_CONTINUE &&
		insn->header.opcode != BRW_OPCODE_HALT);
	 continue;
      }

      int block_end_ip = brw_find_next_block_end(p, ip);
      switch (insn->header.opcode) {
      case BRW_OPCODE_BREAK:
         assert(block_end_ip != 0);
	 insn->bits3.break_cont.jip = (block_end_ip - ip) / scale;
	 /* Gen7 UIP points to WHILE; Gen6 points just after it */
	 insn->bits3.break_cont.uip =
	    (brw_find_loop_end(p, ip) - ip +
             (brw->gen == 6 ? 16 : 0)) / scale;
	 break;
      case BRW_OPCODE_CONTINUE:
         assert(block_end_ip != 0);
	 insn->bits3.break_cont.jip = (block_end_ip - ip) / scale;
	 insn->bits3.break_cont.uip =
            (brw_find_loop_end(p, ip) - ip) / scale;

	 assert(insn->bits3.break_cont.uip != 0);
	 assert(insn->bits3.break_cont.jip != 0);
	 break;

      case BRW_OPCODE_ENDIF:
         if (block_end_ip == 0)
            insn->bits3.break_cont.jip = 2;
         else
            insn->bits3.break_cont.jip = (block_end_ip - ip) / scale;
	 break;

      case BRW_OPCODE_HALT:
	 /* From the Sandy Bridge PRM (volume 4, part 2, section 8.3.19):
	  *
	  *    "In case of the halt instruction not inside any conditional
	  *     code block, the value of <JIP> and <UIP> should be the
	  *     same. In case of the halt instruction inside conditional code
	  *     block, the <UIP> should be the end of the program, and the
	  *     <JIP> should be end of the most inner conditional code block."
	  *
	  * The uip will have already been set by whoever set up the
	  * instruction.
	  */
	 if (block_end_ip == 0) {
	    insn->bits3.break_cont.jip = insn->bits3.break_cont.uip;
	 } else {
	    insn->bits3.break_cont.jip = (block_end_ip - ip) / scale;
	 }
	 assert(insn->bits3.break_cont.uip != 0);
	 assert(insn->bits3.break_cont.jip != 0);
	 break;
      }
   }
}

void brw_ff_sync(struct brw_compile *p,
		   struct brw_reg dest,
		   unsigned msg_reg_nr,
		   struct brw_reg src0,
		   bool allocate,
		   unsigned response_length,
		   bool eot)
{
   struct brw_context *brw = p->brw;
   struct brw_instruction *insn;

   gen6_resolve_implied_move(p, &src0, msg_reg_nr);

   insn = next_insn(p, BRW_OPCODE_SEND);
   brw_set_dest(p, insn, dest);
   brw_set_src0(p, insn, src0);
   brw_set_src1(p, insn, brw_imm_d(0));

   if (brw->gen < 6)
      insn->header.destreg__conditionalmod = msg_reg_nr;

   brw_set_ff_sync_message(p,
			   insn,
			   allocate,
			   response_length,
			   eot);
}

/**
 * Emit the SEND instruction necessary to generate stream output data on Gen6
 * (for transform feedback).
 *
 * If send_commit_msg is true, this is the last piece of stream output data
 * from this thread, so send the data as a committed write.  According to the
 * Sandy Bridge PRM (volume 2 part 1, section 4.5.1):
 *
 *   "Prior to End of Thread with a URB_WRITE, the kernel must ensure all
 *   writes are complete by sending the final write as a committed write."
 */
void
brw_svb_write(struct brw_compile *p,
              struct brw_reg dest,
              unsigned msg_reg_nr,
              struct brw_reg src0,
              unsigned binding_table_index,
              bool   send_commit_msg)
{
   struct brw_instruction *insn;

   gen6_resolve_implied_move(p, &src0, msg_reg_nr);

   insn = next_insn(p, BRW_OPCODE_SEND);
   brw_set_dest(p, insn, dest);
   brw_set_src0(p, insn, src0);
   brw_set_src1(p, insn, brw_imm_d(0));
   brw_set_dp_write_message(p, insn,
                            binding_table_index,
                            0, /* msg_control: ignored */
                            GEN6_DATAPORT_WRITE_MESSAGE_STREAMED_VB_WRITE,
                            1, /* msg_length */
                            true, /* header_present */
                            0, /* last_render_target: ignored */
                            send_commit_msg, /* response_length */
                            0, /* end_of_thread */
                            send_commit_msg); /* send_commit_msg */
}

static void
brw_set_dp_untyped_atomic_message(struct brw_compile *p,
                                  struct brw_instruction *insn,
                                  unsigned atomic_op,
                                  unsigned bind_table_index,
                                  unsigned msg_length,
                                  unsigned response_length,
                                  bool header_present)
{
   if (p->brw->is_haswell) {
      brw_set_message_descriptor(p, insn, HSW_SFID_DATAPORT_DATA_CACHE_1,
                                 msg_length, response_length,
                                 header_present, false);


      if (insn->header.access_mode == BRW_ALIGN_1) {
         if (insn->header.execution_size != BRW_EXECUTE_16)
            insn->bits3.ud |= 1 << 12; /* SIMD8 mode */

         insn->bits3.gen7_dp.msg_type =
            HSW_DATAPORT_DC_PORT1_UNTYPED_ATOMIC_OP;
      } else {
         insn->bits3.gen7_dp.msg_type =
            HSW_DATAPORT_DC_PORT1_UNTYPED_ATOMIC_OP_SIMD4X2;
      }

   } else {
      brw_set_message_descriptor(p, insn, GEN7_SFID_DATAPORT_DATA_CACHE,
                                 msg_length, response_length,
                                 header_present, false);

      insn->bits3.gen7_dp.msg_type = GEN7_DATAPORT_DC_UNTYPED_ATOMIC_OP;

      if (insn->header.execution_size != BRW_EXECUTE_16)
         insn->bits3.ud |= 1 << 12; /* SIMD8 mode */
   }

   if (response_length)
      insn->bits3.ud |= 1 << 13; /* Return data expected */

   insn->bits3.gen7_dp.binding_table_index = bind_table_index;
   insn->bits3.ud |= atomic_op << 8;
}

void
brw_untyped_atomic(struct brw_compile *p,
                   struct brw_reg dest,
                   struct brw_reg mrf,
                   unsigned atomic_op,
                   unsigned bind_table_index,
                   unsigned msg_length,
                   unsigned response_length) {
   struct brw_instruction *insn = brw_next_insn(p, BRW_OPCODE_SEND);

   brw_set_dest(p, insn, retype(dest, BRW_REGISTER_TYPE_UD));
   brw_set_src0(p, insn, retype(mrf, BRW_REGISTER_TYPE_UD));
   brw_set_src1(p, insn, brw_imm_d(0));
   brw_set_dp_untyped_atomic_message(
      p, insn, atomic_op, bind_table_index, msg_length, response_length,
      insn->header.access_mode == BRW_ALIGN_1);
}

static void
brw_set_dp_untyped_surface_read_message(struct brw_compile *p,
                                        struct brw_instruction *insn,
                                        unsigned bind_table_index,
                                        unsigned msg_length,
                                        unsigned response_length,
                                        bool header_present)
{
   const unsigned dispatch_width =
      (insn->header.execution_size == BRW_EXECUTE_16 ? 16 : 8);
   const unsigned num_channels = response_length / (dispatch_width / 8);

   if (p->brw->is_haswell) {
      brw_set_message_descriptor(p, insn, HSW_SFID_DATAPORT_DATA_CACHE_1,
                                 msg_length, response_length,
                                 header_present, false);

      insn->bits3.gen7_dp.msg_type = HSW_DATAPORT_DC_PORT1_UNTYPED_SURFACE_READ;
   } else {
      brw_set_message_descriptor(p, insn, GEN7_SFID_DATAPORT_DATA_CACHE,
                                 msg_length, response_length,
                                 header_present, false);

      insn->bits3.gen7_dp.msg_type = GEN7_DATAPORT_DC_UNTYPED_SURFACE_READ;
   }

   if (insn->header.access_mode == BRW_ALIGN_1) {
      if (dispatch_width == 16)
         insn->bits3.ud |= 1 << 12; /* SIMD16 mode */
      else
         insn->bits3.ud |= 2 << 12; /* SIMD8 mode */
   }

   insn->bits3.gen7_dp.binding_table_index = bind_table_index;

   /* Set mask of 32-bit channels to drop. */
   insn->bits3.ud |= (0xf & (0xf << num_channels)) << 8;
}

void
brw_untyped_surface_read(struct brw_compile *p,
                         struct brw_reg dest,
                         struct brw_reg mrf,
                         unsigned bind_table_index,
                         unsigned msg_length,
                         unsigned response_length)
{
   struct brw_instruction *insn = next_insn(p, BRW_OPCODE_SEND);

   brw_set_dest(p, insn, retype(dest, BRW_REGISTER_TYPE_UD));
   brw_set_src0(p, insn, retype(mrf, BRW_REGISTER_TYPE_UD));
   brw_set_dp_untyped_surface_read_message(
      p, insn, bind_table_index, msg_length, response_length,
      insn->header.access_mode == BRW_ALIGN_1);
}

/**
 * This instruction is generated as a single-channel align1 instruction by
 * both the VS and FS stages when using INTEL_DEBUG=shader_time.
 *
 * We can't use the typed atomic op in the FS because that has the execution
 * mask ANDed with the pixel mask, but we just want to write the one dword for
 * all the pixels.
 *
 * We don't use the SIMD4x2 atomic ops in the VS because want to just write
 * one u32.  So we use the same untyped atomic write message as the pixel
 * shader.
 *
 * The untyped atomic operation requires a BUFFER surface type with RAW
 * format, and is only accessible through the legacy DATA_CACHE dataport
 * messages.
 */
void brw_shader_time_add(struct brw_compile *p,
                         struct brw_reg payload,
                         uint32_t surf_index)
{
   struct brw_context *brw = p->brw;
   assert(brw->gen >= 7);

   brw_push_insn_state(p);
   brw_set_access_mode(p, BRW_ALIGN_1);
   brw_set_mask_control(p, BRW_MASK_DISABLE);
   struct brw_instruction *send = brw_next_insn(p, BRW_OPCODE_SEND);
   brw_pop_insn_state(p);

   /* We use brw_vec1_reg and unmasked because we want to increment the given
    * offset only once.
    */
   brw_set_dest(p, send, brw_vec1_reg(BRW_ARCHITECTURE_REGISTER_FILE,
                                      BRW_ARF_NULL, 0));
   brw_set_src0(p, send, brw_vec1_reg(payload.file,
                                      payload.nr, 0));
   brw_set_dp_untyped_atomic_message(p, send, BRW_AOP_ADD, surf_index,
                                     2 /* message length */,
                                     0 /* response length */,
                                     false /* header present */);
}
@


1.11
log
@Merge Mesa 10.2.9
@
text
@@


1.10
log
@Merge Mesa 10.4.3
Tested by matthieu@@ mpi@@ and myself.  landry@@ ran a ports bulk build.
kettenis@@ tracked down the cause of an alignment fault on archs
that require strict eight byte pointer alignment.
@
text
@d37 1
a37 1
#include "util/ralloc.h"
d44 1
a44 1
				 brw_inst *insn,
d47 4
a50 8
   const struct brw_context *brw = p->brw;

   if (reg.width == BRW_WIDTH_8 && p->compressed) {
      brw_inst_set_exec_size(brw, insn, BRW_EXECUTE_16);
   } else {
      /* Register width definitions are compatible with BRW_EXECUTE_* enums. */
      brw_inst_set_exec_size(brw, insn, reg.width);
   }
d75 2
a76 2
      brw_set_default_mask_control(p, BRW_MASK_DISABLE);
      brw_set_default_compression_control(p, BRW_COMPRESSION_NONE);
d96 1
a96 1
   if (brw->gen >= 7 && reg->file == BRW_MESSAGE_REGISTER_FILE) {
d159 2
a160 1
brw_set_dest(struct brw_compile *p, brw_inst *inst, struct brw_reg dest)
a161 2
   const struct brw_context *brw = p->brw;

d168 4
a171 4
   brw_inst_set_dst_reg_file(brw, inst, dest.file);
   brw_inst_set_dst_reg_type(brw, inst, brw_reg_type_to_hw_type(brw, dest.type,
                                                                dest.file));
   brw_inst_set_dst_address_mode(brw, inst, dest.address_mode);
d174 1
a174 1
      brw_inst_set_dst_da_reg_nr(brw, inst, dest.nr);
d176 2
a177 2
      if (brw_inst_access_mode(brw, inst) == BRW_ALIGN_1) {
         brw_inst_set_dst_da1_subreg_nr(brw, inst, dest.subnr);
d180 5
a184 4
         brw_inst_set_dst_hstride(brw, inst, dest.hstride);
      } else {
         brw_inst_set_dst_da16_subreg_nr(brw, inst, dest.subnr / 16);
         brw_inst_set_da16_writemask(brw, inst, dest.dw1.bits.writemask);
d193 1
a193 1
         brw_inst_set_dst_hstride(brw, inst, 1);
d195 3
a197 2
   } else {
      brw_inst_set_dst_ia_subreg_nr(brw, inst, dest.subnr);
d201 2
a202 3
      if (brw_inst_access_mode(brw, inst) == BRW_ALIGN_1) {
         brw_inst_set_dst_ia1_addr_imm(brw, inst,
                                       dest.dw1.bits.indirect_offset);
d205 4
a208 4
         brw_inst_set_dst_hstride(brw, inst, dest.hstride);
      } else {
         brw_inst_set_dst_ia16_addr_imm(brw, inst,
                                        dest.dw1.bits.indirect_offset);
d210 1
a210 1
         brw_inst_set_dst_hstride(brw, inst, 1);
d215 1
a215 1
    * inst->compression_control:
d217 1
a217 1
   guess_execution_size(p, inst, dest);
d223 1
a223 1
validate_reg(const struct brw_context *brw, brw_inst *inst, struct brw_reg reg)
d226 1
a226 1
   int vstride_for_reg[] = {0, 1, 2, 4, 8, 16, 32};
d237 2
a238 2
         assert(hstride_for_reg[brw_inst_dst_hstride(brw, inst)] *
                reg_type_size[brw_inst_dst_reg_type(brw, inst)] == 2);
d261 3
a263 3
   assert(brw_inst_exec_size(brw, inst) >= 0 &&
          brw_inst_exec_size(brw, inst) < Elements(execsize_for_reg));
   execsize = execsize_for_reg[brw_inst_exec_size(brw, inst)];
a297 10
static bool
is_compactable_immediate(unsigned imm)
{
   /* We get the low 12 bits as-is. */
   imm &= ~0xfff;

   /* We get one bit replicated through the top 20 bits. */
   return imm == 0 || imm == 0xfffff000;
}

d299 2
a300 1
brw_set_src0(struct brw_compile *p, brw_inst *inst, struct brw_reg reg)
d304 1
a304 1
   if (reg.file != BRW_ARCHITECTURE_REGISTER_FILE)
d309 2
a310 2
   if (brw->gen >= 6 && (brw_inst_opcode(brw, inst) == BRW_OPCODE_SEND ||
                         brw_inst_opcode(brw, inst) == BRW_OPCODE_SENDC)) {
d320 1
a320 1
   validate_reg(brw, inst, reg);
d322 6
a327 6
   brw_inst_set_src0_reg_file(brw, inst, reg.file);
   brw_inst_set_src0_reg_type(brw, inst,
                              brw_reg_type_to_hw_type(brw, reg.type, reg.file));
   brw_inst_set_src0_abs(brw, inst, reg.abs);
   brw_inst_set_src0_negate(brw, inst, reg.negate);
   brw_inst_set_src0_address_mode(brw, inst, reg.address_mode);
d330 1
a330 1
      brw_inst_set_imm_ud(brw, inst, reg.dw1.ud);
d332 1
a332 21
      /* The Bspec's section titled "Non-present Operands" claims that if src0
       * is an immediate that src1's type must be the same as that of src0.
       *
       * The SNB+ DataTypeIndex instruction compaction tables contain mappings
       * that do not follow this rule. E.g., from the IVB/HSW table:
       *
       *  DataTypeIndex   18-Bit Mapping       Mapped Meaning
       *        3         001000001011111101   r:f | i:vf | a:ud | <1> | dir |
       *
       * And from the SNB table:
       *
       *  DataTypeIndex   18-Bit Mapping       Mapped Meaning
       *        8         001000000111101100   a:w | i:w | a:ud | <1> | dir |
       *
       * Neither of these cause warnings from the simulator when used,
       * compacted or otherwise. In fact, all compaction mappings that have an
       * immediate in src0 use a:ud for src1.
       *
       * The GM45 instruction compaction tables do not contain mapped meanings
       * so it's not clear whether it has the restriction. We'll assume it was
       * lifted on SNB. (FINISHME: decode the GM45 tables and check.)
d334 14
a347 22
      brw_inst_set_src1_reg_file(brw, inst, BRW_ARCHITECTURE_REGISTER_FILE);
      if (brw->gen < 6) {
         brw_inst_set_src1_reg_type(brw, inst,
                                    brw_inst_src0_reg_type(brw, inst));
      } else {
         brw_inst_set_src1_reg_type(brw, inst, BRW_HW_REG_TYPE_UD);
      }

      /* Compacted instructions only have 12-bits (plus 1 for the other 20)
       * for immediate values. Presumably the hardware engineers realized
       * that the only useful floating-point value that could be represented
       * in this format is 0.0, which can also be represented as a VF-typed
       * immediate, so they gave us the previously mentioned mapping on IVB+.
       *
       * Strangely, we do have a mapping for imm:f in src1, so we don't need
       * to do this there.
       *
       * If we see a 0.0:F, change the type to VF so that it can be compacted.
       */
      if (brw_inst_imm_ud(brw, inst) == 0x0 &&
          brw_inst_src0_reg_type(brw, inst) == BRW_HW_REG_TYPE_F) {
         brw_inst_set_src0_reg_type(brw, inst, BRW_HW_REG_IMM_TYPE_VF);
d349 2
d352 2
a353 17
      /* There are no mappings for dst:d | i:d, so if the immediate is suitable
       * set the types to :UD so the instruction can be compacted.
       */
      if (is_compactable_immediate(brw_inst_imm_ud(brw, inst)) &&
          brw_inst_cond_modifier(brw, inst) == BRW_CONDITIONAL_NONE &&
          brw_inst_src0_reg_type(brw, inst) == BRW_HW_REG_TYPE_D &&
          brw_inst_dst_reg_type(brw, inst) == BRW_HW_REG_TYPE_D) {
         brw_inst_set_src0_reg_type(brw, inst, BRW_HW_REG_TYPE_UD);
         brw_inst_set_dst_reg_type(brw, inst, BRW_HW_REG_TYPE_UD);
      }
   } else {
      if (reg.address_mode == BRW_ADDRESS_DIRECT) {
         brw_inst_set_src0_da_reg_nr(brw, inst, reg.nr);
         if (brw_inst_access_mode(brw, inst) == BRW_ALIGN_1) {
             brw_inst_set_src0_da1_subreg_nr(brw, inst, reg.subnr);
	 } else {
            brw_inst_set_src0_da16_subreg_nr(brw, inst, reg.subnr / 16);
d355 2
a356 7
      } else {
         brw_inst_set_src0_ia_subreg_nr(brw, inst, reg.subnr);

         if (brw_inst_access_mode(brw, inst) == BRW_ALIGN_1) {
            brw_inst_set_src0_ia1_addr_imm(brw, inst, reg.dw1.bits.indirect_offset);
	 } else {
            brw_inst_set_src0_ia_subreg_nr(brw, inst, reg.dw1.bits.indirect_offset);
d360 1
a360 1
      if (brw_inst_access_mode(brw, inst) == BRW_ALIGN_1) {
d362 9
a370 8
             brw_inst_exec_size(brw, inst) == BRW_EXECUTE_1) {
            brw_inst_set_src0_hstride(brw, inst, BRW_HORIZONTAL_STRIDE_0);
            brw_inst_set_src0_width(brw, inst, BRW_WIDTH_1);
            brw_inst_set_src0_vstride(brw, inst, BRW_VERTICAL_STRIDE_0);
	 } else {
            brw_inst_set_src0_hstride(brw, inst, reg.hstride);
            brw_inst_set_src0_width(brw, inst, reg.width);
            brw_inst_set_src0_vstride(brw, inst, reg.vstride);
d372 6
a377 9
      } else {
         brw_inst_set_src0_da16_swiz_x(brw, inst,
            BRW_GET_SWZ(reg.dw1.bits.swizzle, BRW_CHANNEL_X));
         brw_inst_set_src0_da16_swiz_y(brw, inst,
            BRW_GET_SWZ(reg.dw1.bits.swizzle, BRW_CHANNEL_Y));
         brw_inst_set_src0_da16_swiz_z(brw, inst,
            BRW_GET_SWZ(reg.dw1.bits.swizzle, BRW_CHANNEL_Z));
         brw_inst_set_src0_da16_swiz_w(brw, inst,
            BRW_GET_SWZ(reg.dw1.bits.swizzle, BRW_CHANNEL_W));
d383 1
a383 1
            brw_inst_set_src0_vstride(brw, inst, BRW_VERTICAL_STRIDE_4);
d385 1
a385 1
            brw_inst_set_src0_vstride(brw, inst, reg.vstride);
d391 3
a393 2
void
brw_set_src1(struct brw_compile *p, brw_inst *inst, struct brw_reg reg)
a394 1
   const struct brw_context *brw = p->brw;
d397 1
a397 1
   if (reg.file != BRW_ARCHITECTURE_REGISTER_FILE)
d402 1
a402 1
   validate_reg(brw, inst, reg);
d404 5
a408 5
   brw_inst_set_src1_reg_file(brw, inst, reg.file);
   brw_inst_set_src1_reg_type(brw, inst,
                              brw_reg_type_to_hw_type(brw, reg.type, reg.file));
   brw_inst_set_src1_abs(brw, inst, reg.abs);
   brw_inst_set_src1_negate(brw, inst, reg.negate);
d412 1
a412 1
   assert(brw_inst_src0_reg_file(brw, inst) != BRW_IMMEDIATE_VALUE);
d415 3
a417 2
      brw_inst_set_imm_ud(brw, inst, reg.dw1.ud);
   } else {
d424 7
a430 5
      brw_inst_set_src1_da_reg_nr(brw, inst, reg.nr);
      if (brw_inst_access_mode(brw, inst) == BRW_ALIGN_1) {
         brw_inst_set_src1_da1_subreg_nr(brw, inst, reg.subnr);
      } else {
         brw_inst_set_src1_da16_subreg_nr(brw, inst, reg.subnr / 16);
d433 1
a433 1
      if (brw_inst_access_mode(brw, inst) == BRW_ALIGN_1) {
d435 9
a443 8
             brw_inst_exec_size(brw, inst) == BRW_EXECUTE_1) {
            brw_inst_set_src1_hstride(brw, inst, BRW_HORIZONTAL_STRIDE_0);
            brw_inst_set_src1_width(brw, inst, BRW_WIDTH_1);
            brw_inst_set_src1_vstride(brw, inst, BRW_VERTICAL_STRIDE_0);
	 } else {
            brw_inst_set_src1_hstride(brw, inst, reg.hstride);
            brw_inst_set_src1_width(brw, inst, reg.width);
            brw_inst_set_src1_vstride(brw, inst, reg.vstride);
d445 6
a450 9
      } else {
         brw_inst_set_src1_da16_swiz_x(brw, inst,
            BRW_GET_SWZ(reg.dw1.bits.swizzle, BRW_CHANNEL_X));
         brw_inst_set_src1_da16_swiz_y(brw, inst,
            BRW_GET_SWZ(reg.dw1.bits.swizzle, BRW_CHANNEL_Y));
         brw_inst_set_src1_da16_swiz_z(brw, inst,
            BRW_GET_SWZ(reg.dw1.bits.swizzle, BRW_CHANNEL_Z));
         brw_inst_set_src1_da16_swiz_w(brw, inst,
            BRW_GET_SWZ(reg.dw1.bits.swizzle, BRW_CHANNEL_W));
d456 1
a456 1
            brw_inst_set_src1_vstride(brw, inst, BRW_VERTICAL_STRIDE_4);
d458 1
a458 1
            brw_inst_set_src1_vstride(brw, inst, reg.vstride);
d473 1
a473 1
			   brw_inst *inst,
d484 5
a488 11
   /* For indirect sends, `inst` will not be the SEND/SENDC instruction
    * itself; instead, it will be a MOV/OR into the address register.
    *
    * In this case, we avoid setting the extended message descriptor bits,
    * since they go on the later SEND/SENDC instead and if set here would
    * instead clobber the conditionalmod bits.
    */
   unsigned opcode = brw_inst_opcode(brw, inst);
   if (opcode == BRW_OPCODE_SEND || opcode == BRW_OPCODE_SENDC) {
      brw_inst_set_sfid(brw, inst, sfid);
   }
d490 13
a502 6
   brw_inst_set_mlen(brw, inst, msg_length);
   brw_inst_set_rlen(brw, inst, response_length);
   brw_inst_set_eot(brw, inst, end_of_thread);

   if (brw->gen >= 5) {
      brw_inst_set_header_present(brw, inst, header_present);
d507 1
a507 1
				  brw_inst *inst,
d542 1
a542 1
   brw_set_message_descriptor(p, inst, BRW_SFID_MATH,
d544 15
a558 6
   brw_inst_set_math_msg_function(brw, inst, function);
   brw_inst_set_math_msg_signed_int(brw, inst, integer_type);
   brw_inst_set_math_msg_precision(brw, inst, low_precision);
   brw_inst_set_math_msg_saturate(brw, inst, brw_inst_saturate(brw, inst));
   brw_inst_set_math_msg_data_type(brw, inst, dataType);
   brw_inst_set_saturate(brw, inst, 0);
d563 1
a563 1
				    brw_inst *insn,
a567 2
   const struct brw_context *brw = p->brw;

d570 6
a575 7
   brw_inst_set_urb_opcode(brw, insn, 1); /* FF_SYNC */
   brw_inst_set_urb_allocate(brw, insn, allocate);
   /* The following fields are not used by FF_SYNC: */
   brw_inst_set_urb_global_offset(brw, insn, 0);
   brw_inst_set_urb_swizzle_control(brw, insn, 0);
   brw_inst_set_urb_used(brw, insn, 0);
   brw_inst_set_urb_complete(brw, insn, 0);
d579 1
a579 1
				 brw_inst *insn,
a587 4
   assert(brw->gen < 7 || swizzle_control != BRW_URB_SWIZZLE_TRANSPOSE);
   assert(brw->gen < 7 || !(flags & BRW_URB_WRITE_ALLOCATE));
   assert(brw->gen >= 7 || !(flags & BRW_URB_WRITE_PER_SLOT_OFFSET));

d591 27
a617 21

   if (flags & BRW_URB_WRITE_OWORD) {
      assert(msg_length == 2); /* header + one OWORD of data */
      brw_inst_set_urb_opcode(brw, insn, BRW_URB_OPCODE_WRITE_OWORD);
   } else {
      brw_inst_set_urb_opcode(brw, insn, BRW_URB_OPCODE_WRITE_HWORD);
   }

   brw_inst_set_urb_global_offset(brw, insn, offset);
   brw_inst_set_urb_swizzle_control(brw, insn, swizzle_control);

   if (brw->gen < 8) {
      brw_inst_set_urb_complete(brw, insn, !!(flags & BRW_URB_WRITE_COMPLETE));
   }

   if (brw->gen < 7) {
      brw_inst_set_urb_allocate(brw, insn, !!(flags & BRW_URB_WRITE_ALLOCATE));
      brw_inst_set_urb_used(brw, insn, !(flags & BRW_URB_WRITE_UNUSED));
   } else {
      brw_inst_set_urb_per_slot_offset(brw, insn,
         !!(flags & BRW_URB_WRITE_PER_SLOT_OFFSET));
d623 1
a623 1
			 brw_inst *insn,
d653 23
a675 6
   brw_inst_set_binding_table_index(brw, insn, binding_table_index);
   brw_inst_set_dp_write_msg_type(brw, insn, msg_type);
   brw_inst_set_dp_write_msg_control(brw, insn, msg_control);
   brw_inst_set_rt_last(brw, insn, last_render_target);
   if (brw->gen < 7) {
      brw_inst_set_dp_write_commit(brw, insn, send_commit_msg);
d681 1
a681 1
			brw_inst *insn,
d707 27
a733 5
   brw_inst_set_binding_table_index(brw, insn, binding_table_index);
   brw_inst_set_dp_read_msg_type(brw, insn, msg_type);
   brw_inst_set_dp_read_msg_control(brw, insn, msg_control);
   if (brw->gen < 6)
      brw_inst_set_dp_read_target_cache(brw, insn, target_cache);
d738 1
a738 1
                        brw_inst *inst,
d750 1
a750 1
   brw_set_message_descriptor(p, inst, BRW_SFID_SAMPLER, msg_length,
d753 19
a771 7
   brw_inst_set_binding_table_index(brw, inst, binding_table_index);
   brw_inst_set_sampler(brw, inst, sampler);
   brw_inst_set_sampler_msg_type(brw, inst, msg_type);
   if (brw->gen >= 5) {
      brw_inst_set_sampler_simd_mode(brw, inst, simd_mode);
   } else if (brw->gen == 4 && !brw->is_g4x) {
      brw_inst_set_sampler_return_format(brw, inst, return_format);
a774 39
void brw_set_indirect_send_descriptor(struct brw_compile *p,
                                      brw_inst *insn,
                                      unsigned sfid,
                                      struct brw_reg descriptor)
{
   /* Only a0.0 may be used as SEND's descriptor operand. */
   assert(descriptor.file == BRW_ARCHITECTURE_REGISTER_FILE);
   assert(descriptor.type == BRW_REGISTER_TYPE_UD);
   assert(descriptor.nr == BRW_ARF_ADDRESS);
   assert(descriptor.subnr == 0);

   brw_set_message_descriptor(p, insn, sfid, 0, 0, false, false);
   brw_set_src1(p, insn, descriptor);
}

static void
gen7_set_dp_scratch_message(struct brw_compile *p,
                            brw_inst *inst,
                            bool write,
                            bool dword,
                            bool invalidate_after_read,
                            unsigned num_regs,
                            unsigned addr_offset,
                            unsigned mlen,
                            unsigned rlen,
                            bool header_present)
{
   const struct brw_context *brw = p->brw;
   assert(num_regs == 1 || num_regs == 2 || num_regs == 4 ||
          (brw->gen >= 8 && num_regs == 8));
   brw_set_message_descriptor(p, inst, GEN7_SFID_DATAPORT_DATA_CACHE,
                              mlen, rlen, header_present, false);
   brw_inst_set_dp_category(brw, inst, 1); /* Scratch Block Read/Write msgs */
   brw_inst_set_scratch_read_write(brw, inst, write);
   brw_inst_set_scratch_type(brw, inst, dword);
   brw_inst_set_scratch_invalidate_after_read(brw, inst, invalidate_after_read);
   brw_inst_set_scratch_block_size(brw, inst, ffs(num_regs) - 1);
   brw_inst_set_scratch_addr_offset(brw, inst, addr_offset);
}
d777 1
a777 1
brw_inst *
d780 1
a780 2
   const struct brw_context *brw = p->brw;
   brw_inst *insn;
d783 4
d788 4
a791 1
      p->store = reralloc(p->mem_ctx, p->store, brw_inst, p->store_size);
d798 9
a806 1
   brw_inst_set_opcode(brw, insn, opcode);
d810 4
a813 3
static brw_inst *
brw_alu1(struct brw_compile *p, unsigned opcode,
         struct brw_reg dest, struct brw_reg src)
d815 1
a815 1
   brw_inst *insn = next_insn(p, opcode);
d821 5
a825 3
static brw_inst *
brw_alu2(struct brw_compile *p, unsigned opcode,
         struct brw_reg dest, struct brw_reg src0, struct brw_reg src1)
d827 1
a827 1
   brw_inst *insn = next_insn(p, opcode);
d845 6
a850 3
static brw_inst *
brw_alu3(struct brw_compile *p, unsigned opcode, struct brw_reg dest,
         struct brw_reg src0, struct brw_reg src1, struct brw_reg src2)
d853 1
a853 1
   brw_inst *inst = next_insn(p, opcode);
d857 1
a857 1
   assert(brw_inst_access_mode(brw, inst) == BRW_ALIGN_16);
d866 5
a870 8
   if (brw->gen == 6) {
      brw_inst_set_3src_dst_reg_file(brw, inst,
                                     dest.file == BRW_MESSAGE_REGISTER_FILE);
   }
   brw_inst_set_3src_dst_reg_nr(brw, inst, dest.nr);
   brw_inst_set_3src_dst_subreg_nr(brw, inst, dest.subnr / 16);
   brw_inst_set_3src_dst_writemask(brw, inst, dest.dw1.bits.writemask);
   guess_execution_size(p, inst, dest);
d875 6
a880 7
   brw_inst_set_3src_src0_swizzle(brw, inst, src0.dw1.bits.swizzle);
   brw_inst_set_3src_src0_subreg_nr(brw, inst, get_3src_subreg_nr(src0));
   brw_inst_set_3src_src0_reg_nr(brw, inst, src0.nr);
   brw_inst_set_3src_src0_abs(brw, inst, src0.abs);
   brw_inst_set_3src_src0_negate(brw, inst, src0.negate);
   brw_inst_set_3src_src0_rep_ctrl(brw, inst,
                                   src0.vstride == BRW_VERTICAL_STRIDE_0);
d885 7
a891 7
   brw_inst_set_3src_src1_swizzle(brw, inst, src1.dw1.bits.swizzle);
   brw_inst_set_3src_src1_subreg_nr(brw, inst, get_3src_subreg_nr(src1));
   brw_inst_set_3src_src1_reg_nr(brw, inst, src1.nr);
   brw_inst_set_3src_src1_abs(brw, inst, src1.abs);
   brw_inst_set_3src_src1_negate(brw, inst, src1.negate);
   brw_inst_set_3src_src1_rep_ctrl(brw, inst,
                                   src1.vstride == BRW_VERTICAL_STRIDE_0);
d896 6
a901 7
   brw_inst_set_3src_src2_swizzle(brw, inst, src2.dw1.bits.swizzle);
   brw_inst_set_3src_src2_subreg_nr(brw, inst, get_3src_subreg_nr(src2));
   brw_inst_set_3src_src2_reg_nr(brw, inst, src2.nr);
   brw_inst_set_3src_src2_abs(brw, inst, src2.abs);
   brw_inst_set_3src_src2_negate(brw, inst, src2.negate);
   brw_inst_set_3src_src2_rep_ctrl(brw, inst,
                                   src2.vstride == BRW_VERTICAL_STRIDE_0);
d912 2
a913 2
         brw_inst_set_3src_src_type(brw, inst, BRW_3SRC_TYPE_F);
         brw_inst_set_3src_dst_type(brw, inst, BRW_3SRC_TYPE_F);
d916 2
a917 2
         brw_inst_set_3src_src_type(brw, inst, BRW_3SRC_TYPE_D);
         brw_inst_set_3src_dst_type(brw, inst, BRW_3SRC_TYPE_D);
d920 2
a921 2
         brw_inst_set_3src_src_type(brw, inst, BRW_3SRC_TYPE_UD);
         brw_inst_set_3src_dst_type(brw, inst, BRW_3SRC_TYPE_UD);
d926 1
a926 1
   return inst;
d934 1
a934 1
brw_inst *brw_##OP(struct brw_compile *p,		\
d942 1
a942 1
brw_inst *brw_##OP(struct brw_compile *p,		\
d951 1
a951 1
brw_inst *brw_##OP(struct brw_compile *p,		\
d961 1
a961 1
brw_inst *brw_##OP(struct brw_compile *p,         \
d986 1
a986 2
   struct brw_context *brw = p->brw;					      \
   brw_inst *rnd, *add;							      \
d991 1
a991 1
   if (brw->gen < 6) {							      \
d993 1
a993 1
      brw_inst_set_cond_modifier(brw, rnd, BRW_CONDITIONAL_R);                \
d995 1
a995 1
      brw_inst_set_pred_control(brw, add, BRW_PREDICATE_NORMAL);              \
d1009 2
d1038 4
a1041 3
brw_inst *
brw_ADD(struct brw_compile *p, struct brw_reg dest,
        struct brw_reg src0, struct brw_reg src1)
d1061 4
a1064 3
brw_inst *
brw_AVG(struct brw_compile *p, struct brw_reg dest,
        struct brw_reg src0, struct brw_reg src1)
d1077 1
a1077 1
      unreachable("Bad type for brw_AVG");
d1083 4
a1086 3
brw_inst *
brw_MUL(struct brw_compile *p, struct brw_reg dest,
        struct brw_reg src0, struct brw_reg src1)
a1117 50
brw_inst *
brw_F32TO16(struct brw_compile *p, struct brw_reg dst, struct brw_reg src)
{
   const struct brw_context *brw = p->brw;
   bool align16 = brw_inst_access_mode(brw, p->current) == BRW_ALIGN_16;

   if (align16) {
      assert(dst.type == BRW_REGISTER_TYPE_UD);
   } else {
      assert(dst.type == BRW_REGISTER_TYPE_W ||
             dst.type == BRW_REGISTER_TYPE_UW ||
             dst.type == BRW_REGISTER_TYPE_HF);
   }

   if (brw->gen >= 8) {
      if (align16) {
         /* Emulate the Gen7 zeroing bug (see comments in vec4_visitor's
          * emit_pack_half_2x16 method.)
          */
         brw_MOV(p, retype(dst, BRW_REGISTER_TYPE_UD), brw_imm_ud(0u));
      }
      return brw_MOV(p, retype(dst, BRW_REGISTER_TYPE_HF), src);
   } else {
      assert(brw->gen == 7);
      return brw_alu1(p, BRW_OPCODE_F32TO16, dst, src);
   }
}

brw_inst *
brw_F16TO32(struct brw_compile *p, struct brw_reg dst, struct brw_reg src)
{
   const struct brw_context *brw = p->brw;
   bool align16 = brw_inst_access_mode(brw, p->current) == BRW_ALIGN_16;

   if (align16) {
      assert(src.type == BRW_REGISTER_TYPE_UD);
   } else {
      assert(src.type == BRW_REGISTER_TYPE_W ||
             src.type == BRW_REGISTER_TYPE_UW ||
             src.type == BRW_REGISTER_TYPE_HF);
   }

   if (brw->gen >= 8) {
      return brw_MOV(p, dst, retype(src, BRW_REGISTER_TYPE_HF));
   } else {
      assert(brw->gen == 7);
      return brw_alu1(p, BRW_OPCODE_F16TO32, dst, src);
   }
}

d1121 1
a1121 1
   brw_inst *insn = next_insn(p, BRW_OPCODE_NOP);
d1135 12
a1146 12
brw_inst *
brw_JMPI(struct brw_compile *p, struct brw_reg index,
         unsigned predicate_control)
{
   const struct brw_context *brw = p->brw;
   struct brw_reg ip = brw_ip_reg();
   brw_inst *inst = brw_alu2(p, BRW_OPCODE_JMPI, ip, ip, index);

   brw_inst_set_exec_size(brw, inst, BRW_EXECUTE_2);
   brw_inst_set_qtr_control(brw, inst, BRW_COMPRESSION_NONE);
   brw_inst_set_mask_control(brw, inst, BRW_MASK_DISABLE);
   brw_inst_set_pred_control(brw, inst, predicate_control);
d1148 1
a1148 1
   return inst;
d1152 1
a1152 1
push_if_stack(struct brw_compile *p, brw_inst *inst)
d1164 1
a1164 1
static brw_inst *
d1172 1
a1172 1
push_loop_stack(struct brw_compile *p, brw_inst *inst)
d1187 1
a1187 1
static brw_inst *
d1206 1
a1206 1
brw_inst *
d1210 1
a1210 1
   brw_inst *insn;
d1222 1
a1222 1
      brw_inst_set_gen6_jump_count(brw, insn, 0);
d1225 1
a1225 1
   } else if (brw->gen == 7) {
d1229 2
a1230 7
      brw_inst_set_jip(brw, insn, 0);
      brw_inst_set_uip(brw, insn, 0);
   } else {
      brw_set_dest(p, insn, vec1(retype(brw_null_reg(), BRW_REGISTER_TYPE_D)));
      brw_set_src0(p, insn, brw_imm_d(0));
      brw_inst_set_jip(brw, insn, 0);
      brw_inst_set_uip(brw, insn, 0);
d1233 8
a1240 6
   brw_inst_set_exec_size(brw, insn, execute_size);
   brw_inst_set_qtr_control(brw, insn, BRW_COMPRESSION_NONE);
   brw_inst_set_pred_control(brw, insn, BRW_PREDICATE_NORMAL);
   brw_inst_set_mask_control(brw, insn, BRW_MASK_ENABLE);
   if (!p->single_program_flow && brw->gen < 6)
      brw_inst_set_thread_control(brw, insn, BRW_THREAD_SWITCH);
d1250 2
a1251 2
brw_inst *
gen6_IF(struct brw_compile *p, enum brw_conditional_mod conditional,
d1254 1
a1254 2
   const struct brw_context *brw = p->brw;
   brw_inst *insn;
d1259 6
a1264 3
   brw_inst_set_exec_size(brw, insn, p->compressed ? BRW_EXECUTE_16
                                                   : BRW_EXECUTE_8);
   brw_inst_set_gen6_jump_count(brw, insn, 0);
d1268 6
a1273 3
   assert(brw_inst_qtr_control(brw, insn) == BRW_COMPRESSION_NONE);
   assert(brw_inst_pred_control(brw, insn) == BRW_PREDICATE_NONE);
   brw_inst_set_cond_modifier(brw, insn, conditional);
d1284 2
a1285 1
                       brw_inst *if_inst, brw_inst *else_inst)
a1286 2
   const struct brw_context *brw = p->brw;

d1288 1
a1288 1
   brw_inst *next_inst = &p->store[p->nr_insn];
d1291 3
a1293 3
   assert(if_inst != NULL && brw_inst_opcode(brw, if_inst) == BRW_OPCODE_IF);
   assert(else_inst == NULL || brw_inst_opcode(brw, else_inst) == BRW_OPCODE_ELSE);
   assert(brw_inst_exec_size(brw, if_inst) == BRW_EXECUTE_1);
d1303 2
a1304 2
   brw_inst_set_opcode(brw, if_inst, BRW_OPCODE_ADD);
   brw_inst_set_pred_inv(brw, if_inst, true);
d1310 1
a1310 1
      brw_inst_set_opcode(brw, else_inst, BRW_OPCODE_ADD);
d1312 2
a1313 2
      brw_inst_set_imm_ud(brw, if_inst, (else_inst - if_inst + 1) * 16);
      brw_inst_set_imm_ud(brw, else_inst, (next_inst - else_inst) * 16);
d1315 1
a1315 1
      brw_inst_set_imm_ud(brw, if_inst, (next_inst - if_inst) * 16);
d1324 3
a1326 1
              brw_inst *if_inst, brw_inst *else_inst, brw_inst *endif_inst)
d1345 1
a1345 1
   assert(if_inst != NULL && brw_inst_opcode(brw, if_inst) == BRW_OPCODE_IF);
d1347 1
a1347 1
   assert(else_inst == NULL || brw_inst_opcode(brw, else_inst) == BRW_OPCODE_ELSE);
d1349 6
a1354 1
   unsigned br = brw_jump_scale(brw);
d1356 2
a1357 2
   assert(brw_inst_opcode(brw, endif_inst) == BRW_OPCODE_ENDIF);
   brw_inst_set_exec_size(brw, endif_inst, brw_inst_exec_size(brw, if_inst));
d1365 4
a1368 4
         brw_inst_set_opcode(brw, if_inst, BRW_OPCODE_IFF);
         brw_inst_set_gen4_jump_count(brw, if_inst,
                                      br * (endif_inst - if_inst + 1));
         brw_inst_set_gen4_pop_count(brw, if_inst, 0);
d1371 1
a1371 1
         brw_inst_set_gen6_jump_count(brw, if_inst, br*(endif_inst - if_inst));
d1373 2
a1374 2
         brw_inst_set_uip(brw, if_inst, br * (endif_inst - if_inst));
         brw_inst_set_jip(brw, if_inst, br * (endif_inst - if_inst));
d1377 1
a1377 1
      brw_inst_set_exec_size(brw, else_inst, brw_inst_exec_size(brw, if_inst));
d1381 3
a1383 3
         brw_inst_set_gen4_jump_count(brw, if_inst,
                                      br * (else_inst - if_inst));
         brw_inst_set_gen4_pop_count(brw, if_inst, 0);
d1385 1
a1385 2
         brw_inst_set_gen6_jump_count(brw, if_inst,
                                      br * (else_inst - if_inst + 1));
d1393 3
a1395 3
         brw_inst_set_gen4_jump_count(brw, else_inst,
                                      br * (endif_inst - else_inst + 1));
         brw_inst_set_gen4_pop_count(brw, else_inst, 1);
d1398 1
a1398 2
         brw_inst_set_gen6_jump_count(brw, else_inst,
                                      br * (endif_inst - else_inst));
d1401 1
a1401 1
         brw_inst_set_jip(brw, if_inst, br * (else_inst - if_inst + 1));
d1403 2
a1404 8
         brw_inst_set_uip(brw, if_inst, br * (endif_inst - if_inst));
         brw_inst_set_jip(brw, else_inst, br * (endif_inst - else_inst));
         if (brw->gen >= 8) {
            /* Since we don't set branch_ctrl, the ELSE's JIP and UIP both
             * should point to ENDIF.
             */
            brw_inst_set_uip(brw, else_inst, br * (endif_inst - else_inst));
         }
d1413 1
a1413 1
   brw_inst *insn;
d1423 1
a1423 1
      brw_inst_set_gen6_jump_count(brw, insn, 0);
d1426 1
a1426 1
   } else if (brw->gen == 7) {
d1430 2
a1431 7
      brw_inst_set_jip(brw, insn, 0);
      brw_inst_set_uip(brw, insn, 0);
   } else {
      brw_set_dest(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
      brw_set_src0(p, insn, brw_imm_d(0));
      brw_inst_set_jip(brw, insn, 0);
      brw_inst_set_uip(brw, insn, 0);
d1434 4
a1437 4
   brw_inst_set_qtr_control(brw, insn, BRW_COMPRESSION_NONE);
   brw_inst_set_mask_control(brw, insn, BRW_MASK_ENABLE);
   if (!p->single_program_flow && brw->gen < 6)
      brw_inst_set_thread_control(brw, insn, BRW_THREAD_SWITCH);
d1446 4
a1449 4
   brw_inst *insn = NULL;
   brw_inst *else_inst = NULL;
   brw_inst *if_inst = NULL;
   brw_inst *tmp;
d1478 1
a1478 1
   if (brw_inst_opcode(brw, tmp) == BRW_OPCODE_ELSE) {
d1498 1
a1498 1
   } else if (brw->gen == 7) {
a1501 2
   } else {
      brw_set_src0(p, insn, brw_imm_d(0));
d1504 3
a1506 4
   brw_inst_set_qtr_control(brw, insn, BRW_COMPRESSION_NONE);
   brw_inst_set_mask_control(brw, insn, BRW_MASK_ENABLE);
   if (brw->gen < 6)
      brw_inst_set_thread_control(brw, insn, BRW_THREAD_SWITCH);
d1510 3
a1512 2
      brw_inst_set_gen4_jump_count(brw, insn, 0);
      brw_inst_set_gen4_pop_count(brw, insn, 1);
d1514 1
a1514 1
      brw_inst_set_gen6_jump_count(brw, insn, 2);
d1516 1
a1516 1
      brw_inst_set_jip(brw, insn, 2);
d1521 1
a1521 2
brw_inst *
brw_BREAK(struct brw_compile *p)
d1524 1
a1524 1
   brw_inst *insn;
d1527 1
a1527 4
   if (brw->gen >= 8) {
      brw_set_dest(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
      brw_set_src0(p, insn, brw_imm_d(0x0));
   } else if (brw->gen >= 6) {
d1535 2
a1536 2
      brw_inst_set_gen4_pop_count(brw, insn,
                                  p->if_depth_in_loop[p->loop_stack_depth]);
d1538 2
a1539 3
   brw_inst_set_qtr_control(brw, insn, BRW_COMPRESSION_NONE);
   brw_inst_set_exec_size(brw, insn, p->compressed ? BRW_EXECUTE_16
                                                   : BRW_EXECUTE_8);
d1544 1
a1544 2
brw_inst *
brw_CONT(struct brw_compile *p)
d1546 1
a1546 2
   const struct brw_context *brw = p->brw;
   brw_inst *insn;
d1549 2
d1552 7
a1558 6
   if (brw->gen >= 8) {
      brw_set_src0(p, insn, brw_imm_d(0x0));
   } else {
      brw_set_src0(p, insn, brw_ip_reg());
      brw_set_src1(p, insn, brw_imm_d(0x0));
   }
d1560 12
a1571 7
   if (brw->gen < 6) {
      brw_inst_set_gen4_pop_count(brw, insn,
                                  p->if_depth_in_loop[p->loop_stack_depth]);
   }
   brw_inst_set_qtr_control(brw, insn, BRW_COMPRESSION_NONE);
   brw_inst_set_exec_size(brw, insn, p->compressed ? BRW_EXECUTE_16
                                                   : BRW_EXECUTE_8);
d1575 1
a1575 2
brw_inst *
gen6_HALT(struct brw_compile *p)
d1577 1
a1577 2
   const struct brw_context *brw = p->brw;
   brw_inst *insn;
d1581 2
a1582 6
   if (brw->gen >= 8) {
      brw_set_src0(p, insn, brw_imm_d(0x0));
   } else {
      brw_set_src0(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
      brw_set_src1(p, insn, brw_imm_d(0x0)); /* UIP and JIP, updated later. */
   }
d1585 1
a1585 1
      brw_inst_set_exec_size(brw, insn, BRW_EXECUTE_16);
d1587 2
a1588 2
      brw_inst_set_qtr_control(brw, insn, BRW_COMPRESSION_NONE);
      brw_inst_set_exec_size(brw, insn, BRW_EXECUTE_8);
d1609 1
a1609 2
brw_inst *
brw_DO(struct brw_compile *p, unsigned execute_size)
d1617 1
a1617 1
      brw_inst *insn = next_insn(p, BRW_OPCODE_DO);
d1627 5
a1631 3
      brw_inst_set_qtr_control(brw, insn, BRW_COMPRESSION_NONE);
      brw_inst_set_exec_size(brw, insn, execute_size);
      brw_inst_set_pred_control(brw, insn, BRW_PREDICATE_NONE);
d1645 1
a1645 1
brw_patch_break_cont(struct brw_compile *p, brw_inst *while_inst)
d1648 3
a1650 5
   brw_inst *do_inst = get_inner_do_insn(p);
   brw_inst *inst;
   unsigned br = brw_jump_scale(brw);

   assert(brw->gen < 6);
d1657 6
a1662 6
      if (brw_inst_opcode(brw, inst) == BRW_OPCODE_BREAK &&
          brw_inst_gen4_jump_count(brw, inst) == 0) {
         brw_inst_set_gen4_jump_count(brw, inst, br*((while_inst - inst) + 1));
      } else if (brw_inst_opcode(brw, inst) == BRW_OPCODE_CONTINUE &&
                 brw_inst_gen4_jump_count(brw, inst) == 0) {
         brw_inst_set_gen4_jump_count(brw, inst, br * (while_inst - inst));
d1667 1
a1667 2
brw_inst *
brw_WHILE(struct brw_compile *p)
d1670 9
a1678 2
   brw_inst *insn, *do_insn;
   unsigned br = brw_jump_scale(brw);
d1680 7
a1686 1
   if (brw->gen >= 6) {
d1690 4
a1693 15
      if (brw->gen >= 8) {
         brw_set_dest(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
         brw_set_src0(p, insn, brw_imm_d(0));
         brw_inst_set_jip(brw, insn, br * (do_insn - insn));
      } else if (brw->gen == 7) {
         brw_set_dest(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
         brw_set_src0(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
         brw_set_src1(p, insn, brw_imm_ud(0));
         brw_inst_set_jip(brw, insn, br * (do_insn - insn));
      } else {
         brw_set_dest(p, insn, brw_imm_w(0));
         brw_inst_set_gen6_jump_count(brw, insn, br * (do_insn - insn));
         brw_set_src0(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
         brw_set_src1(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
      }
d1695 1
a1695 2
      brw_inst_set_exec_size(brw, insn, p->compressed ? BRW_EXECUTE_16
                                                      : BRW_EXECUTE_8);
d1704 1
a1704 1
         brw_inst_set_exec_size(brw, insn, BRW_EXECUTE_1);
d1709 1
a1709 1
         assert(brw_inst_opcode(brw, do_insn) == BRW_OPCODE_DO);
d1715 4
a1718 3
         brw_inst_set_exec_size(brw, insn, brw_inst_exec_size(brw, do_insn));
         brw_inst_set_gen4_jump_count(brw, insn, br * (do_insn - insn + 1));
         brw_inst_set_gen4_pop_count(brw, insn, 0);
d1723 2
a1724 1
   brw_inst_set_qtr_control(brw, insn, BRW_COMPRESSION_NONE);
d1731 1
d1737 1
a1737 1
   brw_inst *jmp_insn = &p->store[jmp_insn_idx];
d1743 2
a1744 2
   assert(brw_inst_opcode(brw, jmp_insn) == BRW_OPCODE_JMPI);
   assert(brw_inst_src1_reg_file(brw, jmp_insn) == BRW_IMMEDIATE_VALUE);
d1746 1
a1746 2
   brw_inst_set_gen4_jump_count(brw, jmp_insn,
                                jmpi * (p->nr_insn - jmp_insn_idx - 1));
d1749 2
d1762 1
a1762 9
   brw_inst *insn = next_insn(p, BRW_OPCODE_CMP);

   if (brw->gen >= 8) {
      /* The CMP instruction appears to behave erratically for floating point
       * sources unless the destination type is also float.  Overriding it to
       * match src0 makes it work in all cases.
       */
      dest.type = src0.type;
   }
d1764 1
a1764 1
   brw_inst_set_cond_modifier(brw, insn, conditional);
d1769 13
d1792 1
a1792 1
         brw_inst_set_thread_control(brw, insn, BRW_THREAD_SWITCH);
d1797 16
d1819 1
a1819 1
void gen4_math(struct brw_compile *p,
d1824 1
d1828 34
a1861 6
   brw_inst *insn = next_insn(p, BRW_OPCODE_SEND);
   unsigned data_type;
   if (src.vstride == BRW_VERTICAL_STRIDE_0 &&
       src.width == BRW_WIDTH_1 &&
       src.hstride == BRW_HORIZONTAL_STRIDE_0) {
      data_type = BRW_MATH_DATA_SCALAR;
d1863 1
a1863 2
      data_type = BRW_MATH_DATA_VECTOR;
   }
d1865 5
a1869 1
   assert(brw->gen < 6);
d1871 9
a1879 14
   /* Example code doesn't set predicate_control for send
    * instructions.
    */
   brw_inst_set_pred_control(brw, insn, 0);
   brw_inst_set_base_mrf(brw, insn, msg_reg_nr);

   brw_set_dest(p, insn, dest);
   brw_set_src0(p, insn, src);
   brw_set_math_message(p,
                        insn,
                        function,
                        src.type == BRW_REGISTER_TYPE_D,
                        precision,
                        data_type);
d1882 3
a1884 1
void gen6_math(struct brw_compile *p,
d1891 1
a1891 3
   brw_inst *insn = next_insn(p, BRW_OPCODE_MATH);

   assert(brw->gen >= 6);
d1895 2
a1896 2
   assert(src0.file == BRW_GENERAL_REGISTER_FILE ||
          (brw->gen >= 8 && src0.file == BRW_IMMEDIATE_VALUE));
a1908 2
      assert(src1.file == BRW_GENERAL_REGISTER_FILE ||
             (brw->gen >= 8 && src1.file == BRW_IMMEDIATE_VALUE));
a1911 7
      if (function == BRW_MATH_FUNCTION_POW) {
         assert(src1.file == BRW_GENERAL_REGISTER_FILE ||
                (brw->gen >= 8 && src1.file == BRW_IMMEDIATE_VALUE));
      } else {
         assert(src1.file == BRW_ARCHITECTURE_REGISTER_FILE &&
                src1.nr == BRW_ARF_NULL);
      }
d1922 4
a1925 1
   brw_inst_set_math_function(brw, insn, function);
d1969 2
a1970 2
      brw_set_default_mask_control(p, BRW_MASK_DISABLE);
      brw_set_default_compression_control(p, BRW_COMPRESSION_NONE);
d1986 1
a1986 1
      brw_inst *insn = next_insn(p, BRW_OPCODE_SEND);
d1991 2
a1992 2
      if (brw_inst_qtr_control(brw, insn) != BRW_COMPRESSION_NONE) {
         brw_inst_set_qtr_control(brw, insn, BRW_COMPRESSION_NONE);
d1995 2
a1996 3
      assert(brw_inst_pred_control(brw, insn) == BRW_PREDICATE_NONE);
      if (brw->gen < 6)
         brw_inst_set_base_mrf(brw, insn, mrf.nr);
d2064 1
a2064 12
   if (p->brw->gen >= 7) {
      /* On gen 7 and above, we no longer have message registers and we can
       * send from any register we want.  By using the destination register
       * for the message, we guarantee that the implied message write won't
       * accidentally overwrite anything.  This has been a problem because
       * the MRF registers and source for the final FB write are both fixed
       * and may overlap.
       */
      mrf = retype(dest, BRW_REGISTER_TYPE_UD);
   } else {
      mrf = retype(mrf, BRW_REGISTER_TYPE_UD);
   }
d2077 2
a2078 2
      brw_set_default_compression_control(p, BRW_COMPRESSION_NONE);
      brw_set_default_mask_control(p, BRW_MASK_DISABLE);
d2083 5
a2087 1
      brw_MOV(p, get_element_ud(mrf, 2), brw_imm_ud(offset));
d2093 1
a2093 1
      brw_inst *insn = next_insn(p, BRW_OPCODE_SEND);
d2095 3
a2097 2
      assert(brw_inst_pred_control(brw, insn) == 0);
      brw_inst_set_qtr_control(brw, insn, BRW_COMPRESSION_NONE);
a2103 1
         brw_inst_set_base_mrf(brw, insn, mrf.nr);
d2124 3
a2126 3
   const struct brw_context *brw = p->brw;
   brw_inst *insn = next_insn(p, BRW_OPCODE_SEND);
   assert(brw_inst_pred_control(brw, insn) == BRW_PREDICATE_NONE);
d2128 4
a2131 2
   brw_inst_set_qtr_control(brw, insn, BRW_COMPRESSION_NONE);
   brw_set_dest(p, insn, retype(dest, BRW_REGISTER_TYPE_UW));
d2136 1
d2139 12
d2157 1
a2157 10

   gen7_set_dp_scratch_message(p, insn,
                               false, /* scratch read */
                               false, /* OWords */
                               false, /* invalidate after read */
                               num_regs,
                               offset,
                               1,        /* mlen: just g0 */
                               num_regs, /* rlen */
                               true);    /* header present */
d2180 3
a2182 3
   brw_set_default_predicate_control(p, BRW_PREDICATE_NONE);
   brw_set_default_compression_control(p, BRW_COMPRESSION_NONE);
   brw_set_default_mask_control(p, BRW_MASK_DISABLE);
d2193 2
a2194 1
   brw_inst *insn = next_insn(p, BRW_OPCODE_SEND);
a2203 1
      brw_inst_set_base_mrf(brw, insn, mrf.nr);
d2222 2
a2223 2
                  struct brw_reg payload,
                  struct brw_reg implied_header,
d2232 1
a2232 1
   brw_inst *insn;
d2234 1
a2234 1
   struct brw_reg dest, src0;
d2246 1
a2246 1
   brw_inst_set_qtr_control(brw, insn, BRW_COMPRESSION_NONE);
d2250 1
a2250 1
      src0 = payload;
d2254 1
a2254 3
      assert(payload.file == BRW_MESSAGE_REGISTER_FILE);
      brw_inst_set_base_mrf(brw, insn, payload.nr);
      src0 = implied_header;
d2294 1
a2294 1
   brw_inst *insn;
d2300 1
a2300 1
   brw_inst_set_pred_control(brw, insn, BRW_PREDICATE_NONE); /* XXX */
d2314 2
a2315 2
   if (brw_inst_qtr_control(brw, insn) != BRW_COMPRESSION_2NDHALF)
      brw_inst_set_qtr_control(brw, insn, BRW_COMPRESSION_NONE);
d2318 1
a2318 1
      brw_inst_set_base_mrf(brw, insn, msg_reg_nr);
a2332 47
/* Adjust the message header's sampler state pointer to
 * select the correct group of 16 samplers.
 */
void brw_adjust_sampler_state_pointer(struct brw_compile *p,
                                      struct brw_reg header,
                                      struct brw_reg sampler_index,
                                      struct brw_reg scratch)
{
   /* The "Sampler Index" field can only store values between 0 and 15.
    * However, we can add an offset to the "Sampler State Pointer"
    * field, effectively selecting a different set of 16 samplers.
    *
    * The "Sampler State Pointer" needs to be aligned to a 32-byte
    * offset, and each sampler state is only 16-bytes, so we can't
    * exclusively use the offset - we have to use both.
    */

   struct brw_context *brw = p->brw;

   if (sampler_index.file == BRW_IMMEDIATE_VALUE) {
      const int sampler_state_size = 16; /* 16 bytes */
      uint32_t sampler = sampler_index.dw1.ud;

      if (sampler >= 16) {
         assert(brw->is_haswell || brw->gen >= 8);
         brw_ADD(p,
                 get_element_ud(header, 3),
                 get_element_ud(brw_vec8_grf(0, 0), 3),
                 brw_imm_ud(16 * (sampler / 16) * sampler_state_size));
      }
   } else {
      /* Non-const sampler array indexing case */
      if (brw->gen < 8 && !brw->is_haswell) {
         return;
      }

      struct brw_reg temp = vec1(retype(scratch, BRW_REGISTER_TYPE_UD));

      brw_AND(p, temp, get_element_ud(sampler_index, 0), brw_imm_ud(0x0f0));
      brw_SHL(p, temp, temp, brw_imm_ud(4));
      brw_ADD(p,
              get_element_ud(header, 3),
              get_element_ud(brw_vec8_grf(0, 0), 3),
              temp);
   }
}

d2348 1
a2348 1
   brw_inst *insn;
d2352 1
a2352 1
   if (brw->gen >= 7 && !(flags & BRW_URB_WRITE_USE_CHANNEL_MASKS)) {
d2355 2
a2356 2
      brw_set_default_access_mode(p, BRW_ALIGN_1);
      brw_set_default_mask_control(p, BRW_MASK_DISABLE);
d2373 1
a2373 1
      brw_inst_set_base_mrf(brw, insn, msg_reg_nr);
d2385 1
a2385 1
brw_find_next_block_end(struct brw_compile *p, int start_offset)
d2387 12
a2398 1
   int offset;
a2399 1
   const struct brw_context *brw = p->brw;
d2401 2
a2402 4
   for (offset = next_offset(brw, store, start_offset);
        offset < p->next_insn_offset;
        offset = next_offset(brw, store, offset)) {
      brw_inst *insn = store + offset;
d2404 1
a2404 1
      switch (brw_inst_opcode(brw, insn)) {
d2409 1
a2409 1
	 return offset;
d2421 1
a2421 1
brw_find_loop_end(struct brw_compile *p, int start_offset)
d2424 2
a2425 2
   int offset;
   int scale = 16 / brw_jump_scale(brw);
a2427 2
   assert(brw->gen >= 6);

d2431 8
a2438 10
   for (offset = next_offset(brw, store, start_offset);
        offset < p->next_insn_offset;
        offset = next_offset(brw, store, offset)) {
      brw_inst *insn = store + offset;

      if (brw_inst_opcode(brw, insn) == BRW_OPCODE_WHILE) {
         int jip = brw->gen == 6 ? brw_inst_gen6_jump_count(brw, insn)
                                 : brw_inst_jip(brw, insn);
	 if (offset + jip * scale <= start_offset)
	    return offset;
d2442 1
a2442 1
   return start_offset;
d2452 2
a2453 3
   int offset;
   int br = brw_jump_scale(brw);
   int scale = 16 / br;
d2459 2
a2460 3
   for (offset = 0; offset < p->next_insn_offset;
        offset = next_offset(brw, store, offset)) {
      brw_inst *insn = store + offset;
d2462 1
a2462 1
      if (brw_inst_cmpt_control(brw, insn)) {
d2464 3
a2466 3
         assert(brw_inst_opcode(brw, insn) != BRW_OPCODE_BREAK &&
                brw_inst_opcode(brw, insn) != BRW_OPCODE_CONTINUE &&
                brw_inst_opcode(brw, insn) != BRW_OPCODE_HALT);
d2470 2
a2471 2
      int block_end_offset = brw_find_next_block_end(p, offset);
      switch (brw_inst_opcode(brw, insn)) {
d2473 2
a2474 2
         assert(block_end_offset != 0);
         brw_inst_set_jip(brw, insn, (block_end_offset - offset) / scale);
d2476 3
a2478 3
         brw_inst_set_uip(brw, insn,
	    (brw_find_loop_end(p, offset) - offset +
             (brw->gen == 6 ? 16 : 0)) / scale);
d2481 4
a2484 4
         assert(block_end_offset != 0);
         brw_inst_set_jip(brw, insn, (block_end_offset - offset) / scale);
         brw_inst_set_uip(brw, insn,
            (brw_find_loop_end(p, offset) - offset) / scale);
d2486 2
a2487 2
         assert(brw_inst_uip(brw, insn) != 0);
         assert(brw_inst_jip(brw, insn) != 0);
d2490 3
a2492 5
      case BRW_OPCODE_ENDIF: {
         int32_t jump = (block_end_offset == 0) ?
                        1 * br : (block_end_offset - offset) / scale;
         if (brw->gen >= 7)
            brw_inst_set_jip(brw, insn, jump);
d2494 1
a2494 1
            brw_inst_set_gen6_jump_count(brw, insn, jump);
a2495 1
      }
d2509 2
a2510 2
	 if (block_end_offset == 0) {
            brw_inst_set_jip(brw, insn, brw_inst_uip(brw, insn));
d2512 1
a2512 1
            brw_inst_set_jip(brw, insn, (block_end_offset - offset) / scale);
d2514 2
a2515 2
         assert(brw_inst_uip(brw, insn) != 0);
         assert(brw_inst_jip(brw, insn) != 0);
d2530 1
a2530 1
   brw_inst *insn;
d2540 1
a2540 1
      brw_inst_set_base_mrf(brw, insn, msg_reg_nr);
d2568 1
a2568 1
   brw_inst *insn;
d2590 1
a2590 1
                                  brw_inst *insn,
d2597 1
a2597 7
   const struct brw_context *brw = p->brw;

   unsigned msg_control =
      atomic_op | /* Atomic Operation Type: BRW_AOP_* */
      (response_length ? 1 << 5 : 0); /* Return data expected */

   if (brw->gen >= 8 || brw->is_haswell) {
d2603 3
a2605 3
      if (brw_inst_access_mode(brw, insn) == BRW_ALIGN_1) {
         if (brw_inst_exec_size(brw, insn) != BRW_EXECUTE_16)
            msg_control |= 1 << 4; /* SIMD8 mode */
d2607 2
a2608 2
         brw_inst_set_dp_msg_type(brw, insn,
                                  HSW_DATAPORT_DC_PORT1_UNTYPED_ATOMIC_OP);
d2610 2
a2611 2
         brw_inst_set_dp_msg_type(brw, insn,
            HSW_DATAPORT_DC_PORT1_UNTYPED_ATOMIC_OP_SIMD4X2);
d2613 1
d2619 1
a2619 1
      brw_inst_set_dp_msg_type(brw, insn, GEN7_DATAPORT_DC_UNTYPED_ATOMIC_OP);
d2621 2
a2622 2
      if (brw_inst_exec_size(brw, insn) != BRW_EXECUTE_16)
         msg_control |= 1 << 4; /* SIMD8 mode */
d2625 5
a2629 2
   brw_inst_set_binding_table_index(brw, insn, bind_table_index);
   brw_inst_set_dp_msg_control(brw, insn, msg_control);
d2635 1
a2635 1
                   struct brw_reg payload,
d2640 1
a2640 2
   const struct brw_context *brw = p->brw;
   brw_inst *insn = brw_next_insn(p, BRW_OPCODE_SEND);
d2643 1
a2643 1
   brw_set_src0(p, insn, retype(payload, BRW_REGISTER_TYPE_UD));
d2647 1
a2647 1
      brw_inst_access_mode(brw, insn) == BRW_ALIGN_1);
d2652 1
a2652 1
                                        brw_inst *insn,
a2657 1
   const struct brw_context *brw = p->brw;
d2659 1
a2659 1
      (brw_inst_exec_size(brw, insn) == BRW_EXECUTE_16 ? 16 : 8);
d2662 1
a2662 1
   if (brw->gen >= 8 || brw->is_haswell) {
d2667 1
a2667 2
      brw_inst_set_dp_msg_type(brw, insn,
                               HSW_DATAPORT_DC_PORT1_UNTYPED_SURFACE_READ);
d2673 1
a2673 2
      brw_inst_set_dp_msg_type(brw, insn,
                               GEN7_DATAPORT_DC_UNTYPED_SURFACE_READ);
d2676 1
a2676 4
   /* Set mask of 32-bit channels to drop. */
   unsigned msg_control = (0xf & (0xf << num_channels));

   if (brw_inst_access_mode(brw, insn) == BRW_ALIGN_1) {
d2678 1
a2678 1
         msg_control |= 1 << 4; /* SIMD16 mode */
d2680 1
a2680 1
         msg_control |= 2 << 4; /* SIMD8 mode */
d2683 4
a2686 2
   brw_inst_set_binding_table_index(brw, insn, bind_table_index);
   brw_inst_set_dp_msg_control(brw, insn, msg_control);
d2697 1
a2697 2
   const struct brw_context *brw = p->brw;
   brw_inst *insn = next_insn(p, BRW_OPCODE_SEND);
d2703 1
a2703 29
      brw_inst_access_mode(brw, insn) == BRW_ALIGN_1);
}

void
brw_pixel_interpolator_query(struct brw_compile *p,
                             struct brw_reg dest,
                             struct brw_reg mrf,
                             bool noperspective,
                             unsigned mode,
                             unsigned data,
                             unsigned msg_length,
                             unsigned response_length)
{
   const struct brw_context *brw = p->brw;
   struct brw_inst *insn = next_insn(p, BRW_OPCODE_SEND);

   brw_set_dest(p, insn, dest);
   brw_set_src0(p, insn, mrf);
   brw_set_message_descriptor(p, insn, GEN7_SFID_PIXEL_INTERPOLATOR,
                              msg_length, response_length,
                              false /* header is never present for PI */,
                              false);

   brw_inst_set_pi_simd_mode(
         brw, insn, brw_inst_exec_size(brw, insn) == BRW_EXECUTE_16);
   brw_inst_set_pi_slot_group(brw, insn, 0); /* zero unless 32/64px dispatch */
   brw_inst_set_pi_nopersp(brw, insn, noperspective);
   brw_inst_set_pi_message_type(brw, insn, mode);
   brw_inst_set_pi_message_data(brw, insn, data);
d2726 2
a2727 1
   assert(p->brw->gen >= 7);
d2730 3
a2732 3
   brw_set_default_access_mode(p, BRW_ALIGN_1);
   brw_set_default_mask_control(p, BRW_MASK_DISABLE);
   brw_inst *send = brw_next_insn(p, BRW_OPCODE_SEND);
@


1.9
log
@Merge Mesa 10.2.3
tested by matthieu@@ kettenis@@ mpi@@ brett@@ and myself across a
diverse range of hardware
@
text
@d37 1
a37 1
#include "glsl/ralloc.h"
d44 1
a44 1
				 struct brw_instruction *insn,
d47 8
a54 4
   if (reg.width == BRW_WIDTH_8 && p->compressed)
      insn->header.execution_size = BRW_EXECUTE_16;
   else
      insn->header.execution_size = reg.width;	/* note - definitions are compatible */
d79 2
a80 2
      brw_set_mask_control(p, BRW_MASK_DISABLE);
      brw_set_compression_control(p, BRW_COMPRESSION_NONE);
d100 1
a100 1
   if (brw->gen == 7 && reg->file == BRW_MESSAGE_REGISTER_FILE) {
d163 1
a163 2
brw_set_dest(struct brw_compile *p, struct brw_instruction *insn,
	     struct brw_reg dest)
d165 2
d173 4
a176 4
   insn->bits1.da1.dest_reg_file = dest.file;
   insn->bits1.da1.dest_reg_type =
      brw_reg_type_to_hw_type(p->brw, dest.type, dest.file);
   insn->bits1.da1.dest_address_mode = dest.address_mode;
d179 1
a179 1
      insn->bits1.da1.dest_reg_nr = dest.nr;
d181 2
a182 2
      if (insn->header.access_mode == BRW_ALIGN_1) {
	 insn->bits1.da1.dest_subreg_nr = dest.subnr;
d185 4
a188 5
	 insn->bits1.da1.dest_horiz_stride = dest.hstride;
      }
      else {
	 insn->bits1.da16.dest_subreg_nr = dest.subnr / 16;
	 insn->bits1.da16.dest_writemask = dest.dw1.bits.writemask;
d197 1
a197 1
	 insn->bits1.da16.dest_horiz_stride = 1;
d199 2
a200 3
   }
   else {
      insn->bits1.ia1.dest_subreg_nr = dest.subnr;
d204 3
a206 2
      if (insn->header.access_mode == BRW_ALIGN_1) {
	 insn->bits1.ia1.dest_indirect_offset = dest.dw1.bits.indirect_offset;
d209 4
a212 4
	 insn->bits1.ia1.dest_horiz_stride = dest.hstride;
      }
      else {
	 insn->bits1.ia16.dest_indirect_offset = dest.dw1.bits.indirect_offset;
d214 1
a214 1
	 insn->bits1.ia16.dest_horiz_stride = 1;
d219 1
a219 1
    * insn->compression_control:
d221 1
a221 1
   guess_execution_size(p, insn, dest);
d227 1
a227 1
validate_reg(struct brw_instruction *insn, struct brw_reg reg)
d230 1
a230 1
   int vstride_for_reg[] = {0, 1, 2, 4, 8, 16, 32, 64, 128, 256};
d241 2
a242 2
	 assert(hstride_for_reg[insn->bits1.da1.dest_horiz_stride] *
		reg_type_size[insn->bits1.da1.dest_reg_type] == 2);
d265 3
a267 3
   assert(insn->header.execution_size >= 0 &&
	  insn->header.execution_size < Elements(execsize_for_reg));
   execsize = execsize_for_reg[insn->header.execution_size];
d302 10
d313 1
a313 2
brw_set_src0(struct brw_compile *p, struct brw_instruction *insn,
	     struct brw_reg reg)
d317 1
a317 1
   if (reg.type != BRW_ARCHITECTURE_REGISTER_FILE)
d322 2
a323 2
   if (brw->gen >= 6 && (insn->header.opcode == BRW_OPCODE_SEND ||
                           insn->header.opcode == BRW_OPCODE_SENDC)) {
d333 1
a333 1
   validate_reg(insn, reg);
d335 6
a340 6
   insn->bits1.da1.src0_reg_file = reg.file;
   insn->bits1.da1.src0_reg_type =
      brw_reg_type_to_hw_type(brw, reg.type, reg.file);
   insn->bits2.da1.src0_abs = reg.abs;
   insn->bits2.da1.src0_negate = reg.negate;
   insn->bits2.da1.src0_address_mode = reg.address_mode;
d343 1
a343 1
      insn->bits3.ud = reg.dw1.ud;
d345 21
a365 1
      /* Required to set some fields in src1 as well:
d367 35
a401 5
      insn->bits1.da1.src1_reg_file = 0; /* arf */
      insn->bits1.da1.src1_reg_type = insn->bits1.da1.src0_reg_type;
   }
   else
   {
d403 5
a407 3
	 if (insn->header.access_mode == BRW_ALIGN_1) {
	    insn->bits2.da1.src0_subreg_nr = reg.subnr;
	    insn->bits2.da1.src0_reg_nr = reg.nr;
d409 2
a410 7
	 else {
	    insn->bits2.da16.src0_subreg_nr = reg.subnr / 16;
	    insn->bits2.da16.src0_reg_nr = reg.nr;
	 }
      }
      else {
	 insn->bits2.ia1.src0_subreg_nr = reg.subnr;
d412 4
a415 5
	 if (insn->header.access_mode == BRW_ALIGN_1) {
	    insn->bits2.ia1.src0_indirect_offset = reg.dw1.bits.indirect_offset;
	 }
	 else {
	    insn->bits2.ia16.src0_subreg_nr = reg.dw1.bits.indirect_offset;
d419 1
a419 1
      if (insn->header.access_mode == BRW_ALIGN_1) {
d421 8
a428 4
	     insn->header.execution_size == BRW_EXECUTE_1) {
	    insn->bits2.da1.src0_horiz_stride = BRW_HORIZONTAL_STRIDE_0;
	    insn->bits2.da1.src0_width = BRW_WIDTH_1;
	    insn->bits2.da1.src0_vert_stride = BRW_VERTICAL_STRIDE_0;
d430 9
a438 11
	 else {
	    insn->bits2.da1.src0_horiz_stride = reg.hstride;
	    insn->bits2.da1.src0_width = reg.width;
	    insn->bits2.da1.src0_vert_stride = reg.vstride;
	 }
      }
      else {
	 insn->bits2.da16.src0_swz_x = BRW_GET_SWZ(reg.dw1.bits.swizzle, BRW_CHANNEL_X);
	 insn->bits2.da16.src0_swz_y = BRW_GET_SWZ(reg.dw1.bits.swizzle, BRW_CHANNEL_Y);
	 insn->bits2.da16.src0_swz_z = BRW_GET_SWZ(reg.dw1.bits.swizzle, BRW_CHANNEL_Z);
	 insn->bits2.da16.src0_swz_w = BRW_GET_SWZ(reg.dw1.bits.swizzle, BRW_CHANNEL_W);
d444 1
a444 1
	    insn->bits2.da16.src0_vert_stride = BRW_VERTICAL_STRIDE_4;
d446 1
a446 1
	    insn->bits2.da16.src0_vert_stride = reg.vstride;
d452 2
a453 3
void brw_set_src1(struct brw_compile *p,
		  struct brw_instruction *insn,
		  struct brw_reg reg)
d455 1
d458 1
a458 1
   if (reg.type != BRW_ARCHITECTURE_REGISTER_FILE)
d463 1
a463 1
   validate_reg(insn, reg);
d465 5
a469 5
   insn->bits1.da1.src1_reg_file = reg.file;
   insn->bits1.da1.src1_reg_type =
      brw_reg_type_to_hw_type(p->brw, reg.type, reg.file);
   insn->bits3.da1.src1_abs = reg.abs;
   insn->bits3.da1.src1_negate = reg.negate;
d473 1
a473 1
   assert(insn->bits1.da1.src0_reg_file != BRW_IMMEDIATE_VALUE);
d476 2
a477 3
      insn->bits3.ud = reg.dw1.ud;
   }
   else {
d484 5
a488 7
      if (insn->header.access_mode == BRW_ALIGN_1) {
	 insn->bits3.da1.src1_subreg_nr = reg.subnr;
	 insn->bits3.da1.src1_reg_nr = reg.nr;
      }
      else {
	 insn->bits3.da16.src1_subreg_nr = reg.subnr / 16;
	 insn->bits3.da16.src1_reg_nr = reg.nr;
d491 1
a491 1
      if (insn->header.access_mode == BRW_ALIGN_1) {
d493 8
a500 4
	     insn->header.execution_size == BRW_EXECUTE_1) {
	    insn->bits3.da1.src1_horiz_stride = BRW_HORIZONTAL_STRIDE_0;
	    insn->bits3.da1.src1_width = BRW_WIDTH_1;
	    insn->bits3.da1.src1_vert_stride = BRW_VERTICAL_STRIDE_0;
d502 9
a510 11
	 else {
	    insn->bits3.da1.src1_horiz_stride = reg.hstride;
	    insn->bits3.da1.src1_width = reg.width;
	    insn->bits3.da1.src1_vert_stride = reg.vstride;
	 }
      }
      else {
	 insn->bits3.da16.src1_swz_x = BRW_GET_SWZ(reg.dw1.bits.swizzle, BRW_CHANNEL_X);
	 insn->bits3.da16.src1_swz_y = BRW_GET_SWZ(reg.dw1.bits.swizzle, BRW_CHANNEL_Y);
	 insn->bits3.da16.src1_swz_z = BRW_GET_SWZ(reg.dw1.bits.swizzle, BRW_CHANNEL_Z);
	 insn->bits3.da16.src1_swz_w = BRW_GET_SWZ(reg.dw1.bits.swizzle, BRW_CHANNEL_W);
d516 1
a516 1
	    insn->bits3.da16.src1_vert_stride = BRW_VERTICAL_STRIDE_4;
d518 1
a518 1
	    insn->bits3.da16.src1_vert_stride = reg.vstride;
d533 1
a533 1
			   struct brw_instruction *inst,
d544 16
d561 1
a561 18
      inst->bits3.generic_gen5.header_present = header_present;
      inst->bits3.generic_gen5.response_length = response_length;
      inst->bits3.generic_gen5.msg_length = msg_length;
      inst->bits3.generic_gen5.end_of_thread = end_of_thread;

      if (brw->gen >= 6) {
	 /* On Gen6+ Message target/SFID goes in bits 27:24 of the header */
	 inst->header.destreg__conditionalmod = sfid;
      } else {
	 /* Set Extended Message Descriptor (ex_desc) */
	 inst->bits2.send_gen5.sfid = sfid;
	 inst->bits2.send_gen5.end_of_thread = end_of_thread;
      }
   } else {
      inst->bits3.generic.response_length = response_length;
      inst->bits3.generic.msg_length = msg_length;
      inst->bits3.generic.msg_target = sfid;
      inst->bits3.generic.end_of_thread = end_of_thread;
d566 1
a566 1
				  struct brw_instruction *insn,
d601 1
a601 1
   brw_set_message_descriptor(p, insn, BRW_SFID_MATH,
d603 6
a608 15
   if (brw->gen == 5) {
      insn->bits3.math_gen5.function = function;
      insn->bits3.math_gen5.int_type = integer_type;
      insn->bits3.math_gen5.precision = low_precision;
      insn->bits3.math_gen5.saturate = insn->header.saturate;
      insn->bits3.math_gen5.data_type = dataType;
      insn->bits3.math_gen5.snapshot = 0;
   } else {
      insn->bits3.math.function = function;
      insn->bits3.math.int_type = integer_type;
      insn->bits3.math.precision = low_precision;
      insn->bits3.math.saturate = insn->header.saturate;
      insn->bits3.math.data_type = dataType;
   }
   insn->header.saturate = 0;
d613 1
a613 1
				    struct brw_instruction *insn,
d618 2
d622 7
a628 6
   insn->bits3.urb_gen5.opcode = 1; /* FF_SYNC */
   insn->bits3.urb_gen5.offset = 0; /* Not used by FF_SYNC */
   insn->bits3.urb_gen5.swizzle_control = 0; /* Not used by FF_SYNC */
   insn->bits3.urb_gen5.allocate = allocate;
   insn->bits3.urb_gen5.used = 0; /* Not used by FF_SYNC */
   insn->bits3.urb_gen5.complete = 0; /* Not used by FF_SYNC */
d632 1
a632 1
				 struct brw_instruction *insn,
d641 4
d648 21
a668 27
   if (brw->gen == 7) {
      if (flags & BRW_URB_WRITE_OWORD) {
         assert(msg_length == 2); /* header + one OWORD of data */
         insn->bits3.urb_gen7.opcode = BRW_URB_OPCODE_WRITE_OWORD;
      } else {
         insn->bits3.urb_gen7.opcode = BRW_URB_OPCODE_WRITE_HWORD;
      }
      insn->bits3.urb_gen7.offset = offset;
      assert(swizzle_control != BRW_URB_SWIZZLE_TRANSPOSE);
      insn->bits3.urb_gen7.swizzle_control = swizzle_control;
      insn->bits3.urb_gen7.per_slot_offset =
         flags & BRW_URB_WRITE_PER_SLOT_OFFSET ? 1 : 0;
      insn->bits3.urb_gen7.complete = flags & BRW_URB_WRITE_COMPLETE ? 1 : 0;
   } else if (brw->gen >= 5) {
      insn->bits3.urb_gen5.opcode = 0;	/* URB_WRITE */
      insn->bits3.urb_gen5.offset = offset;
      insn->bits3.urb_gen5.swizzle_control = swizzle_control;
      insn->bits3.urb_gen5.allocate = flags & BRW_URB_WRITE_ALLOCATE ? 1 : 0;
      insn->bits3.urb_gen5.used = flags & BRW_URB_WRITE_UNUSED ? 0 : 1;
      insn->bits3.urb_gen5.complete = flags & BRW_URB_WRITE_COMPLETE ? 1 : 0;
   } else {
      insn->bits3.urb.opcode = 0;	/* ? */
      insn->bits3.urb.offset = offset;
      insn->bits3.urb.swizzle_control = swizzle_control;
      insn->bits3.urb.allocate = flags & BRW_URB_WRITE_ALLOCATE ? 1 : 0;
      insn->bits3.urb.used = flags & BRW_URB_WRITE_UNUSED ? 0 : 1;
      insn->bits3.urb.complete = flags & BRW_URB_WRITE_COMPLETE ? 1 : 0;
d674 1
a674 1
			 struct brw_instruction *insn,
d704 6
a709 23
   if (brw->gen >= 7) {
      insn->bits3.gen7_dp.binding_table_index = binding_table_index;
      insn->bits3.gen7_dp.msg_control = msg_control;
      insn->bits3.gen7_dp.last_render_target = last_render_target;
      insn->bits3.gen7_dp.msg_type = msg_type;
   } else if (brw->gen == 6) {
      insn->bits3.gen6_dp.binding_table_index = binding_table_index;
      insn->bits3.gen6_dp.msg_control = msg_control;
      insn->bits3.gen6_dp.last_render_target = last_render_target;
      insn->bits3.gen6_dp.msg_type = msg_type;
      insn->bits3.gen6_dp.send_commit_msg = send_commit_msg;
   } else if (brw->gen == 5) {
      insn->bits3.dp_write_gen5.binding_table_index = binding_table_index;
      insn->bits3.dp_write_gen5.msg_control = msg_control;
      insn->bits3.dp_write_gen5.last_render_target = last_render_target;
      insn->bits3.dp_write_gen5.msg_type = msg_type;
      insn->bits3.dp_write_gen5.send_commit_msg = send_commit_msg;
   } else {
      insn->bits3.dp_write.binding_table_index = binding_table_index;
      insn->bits3.dp_write.msg_control = msg_control;
      insn->bits3.dp_write.last_render_target = last_render_target;
      insn->bits3.dp_write.msg_type = msg_type;
      insn->bits3.dp_write.send_commit_msg = send_commit_msg;
d715 1
a715 1
			struct brw_instruction *insn,
d741 5
a745 27
   if (brw->gen >= 7) {
      insn->bits3.gen7_dp.binding_table_index = binding_table_index;
      insn->bits3.gen7_dp.msg_control = msg_control;
      insn->bits3.gen7_dp.last_render_target = 0;
      insn->bits3.gen7_dp.msg_type = msg_type;
   } else if (brw->gen == 6) {
      insn->bits3.gen6_dp.binding_table_index = binding_table_index;
      insn->bits3.gen6_dp.msg_control = msg_control;
      insn->bits3.gen6_dp.last_render_target = 0;
      insn->bits3.gen6_dp.msg_type = msg_type;
      insn->bits3.gen6_dp.send_commit_msg = 0;
   } else if (brw->gen == 5) {
      insn->bits3.dp_read_gen5.binding_table_index = binding_table_index;
      insn->bits3.dp_read_gen5.msg_control = msg_control;
      insn->bits3.dp_read_gen5.msg_type = msg_type;
      insn->bits3.dp_read_gen5.target_cache = target_cache;
   } else if (brw->is_g4x) {
      insn->bits3.dp_read_g4x.binding_table_index = binding_table_index; /*0:7*/
      insn->bits3.dp_read_g4x.msg_control = msg_control;  /*8:10*/
      insn->bits3.dp_read_g4x.msg_type = msg_type;  /*11:13*/
      insn->bits3.dp_read_g4x.target_cache = target_cache;  /*14:15*/
   } else {
      insn->bits3.dp_read.binding_table_index = binding_table_index; /*0:7*/
      insn->bits3.dp_read.msg_control = msg_control;  /*8:11*/
      insn->bits3.dp_read.msg_type = msg_type;  /*12:13*/
      insn->bits3.dp_read.target_cache = target_cache;  /*14:15*/
   }
d750 1
a750 1
                        struct brw_instruction *insn,
d762 1
a762 1
   brw_set_message_descriptor(p, insn, BRW_SFID_SAMPLER, msg_length,
d765 7
a771 19
   if (brw->gen >= 7) {
      insn->bits3.sampler_gen7.binding_table_index = binding_table_index;
      insn->bits3.sampler_gen7.sampler = sampler;
      insn->bits3.sampler_gen7.msg_type = msg_type;
      insn->bits3.sampler_gen7.simd_mode = simd_mode;
   } else if (brw->gen >= 5) {
      insn->bits3.sampler_gen5.binding_table_index = binding_table_index;
      insn->bits3.sampler_gen5.sampler = sampler;
      insn->bits3.sampler_gen5.msg_type = msg_type;
      insn->bits3.sampler_gen5.simd_mode = simd_mode;
   } else if (brw->is_g4x) {
      insn->bits3.sampler_g4x.binding_table_index = binding_table_index;
      insn->bits3.sampler_g4x.sampler = sampler;
      insn->bits3.sampler_g4x.msg_type = msg_type;
   } else {
      insn->bits3.sampler.binding_table_index = binding_table_index;
      insn->bits3.sampler.sampler = sampler;
      insn->bits3.sampler.msg_type = msg_type;
      insn->bits3.sampler.return_format = return_format;
d775 39
d816 1
a816 1
struct brw_instruction *
d819 2
a820 1
   struct brw_instruction *insn;
a822 4
      if (0) {
         fprintf(stderr, "incresing the store size to %d\n",
                 p->store_size << 1);
      }
d824 1
a824 4
      p->store = reralloc(p->mem_ctx, p->store,
                          struct brw_instruction, p->store_size);
      if (!p->store)
         assert(!"realloc eu store memeory failed");
d831 1
a831 9
   /* Reset this one-shot flag:
    */

   if (p->current->header.destreg__conditionalmod) {
      p->current->header.destreg__conditionalmod = 0;
      p->current->header.predicate_control = BRW_PREDICATE_NORMAL;
   }

   insn->header.opcode = opcode;
d835 3
a837 4
static struct brw_instruction *brw_alu1( struct brw_compile *p,
					 unsigned opcode,
					 struct brw_reg dest,
					 struct brw_reg src )
d839 1
a839 1
   struct brw_instruction *insn = next_insn(p, opcode);
d845 3
a847 5
static struct brw_instruction *brw_alu2(struct brw_compile *p,
					unsigned opcode,
					struct brw_reg dest,
					struct brw_reg src0,
					struct brw_reg src1 )
d849 1
a849 1
   struct brw_instruction *insn = next_insn(p, opcode);
d867 3
a869 6
static struct brw_instruction *brw_alu3(struct brw_compile *p,
					unsigned opcode,
					struct brw_reg dest,
					struct brw_reg src0,
					struct brw_reg src1,
					struct brw_reg src2)
d872 1
a872 1
   struct brw_instruction *insn = next_insn(p, opcode);
d876 1
a876 1
   assert(insn->header.access_mode == BRW_ALIGN_16);
d885 8
a892 5
   insn->bits1.da3src.dest_reg_file = (dest.file == BRW_MESSAGE_REGISTER_FILE);
   insn->bits1.da3src.dest_reg_nr = dest.nr;
   insn->bits1.da3src.dest_subreg_nr = dest.subnr / 16;
   insn->bits1.da3src.dest_writemask = dest.dw1.bits.writemask;
   guess_execution_size(p, insn, dest);
d897 7
a903 6
   insn->bits2.da3src.src0_swizzle = src0.dw1.bits.swizzle;
   insn->bits2.da3src.src0_subreg_nr = get_3src_subreg_nr(src0);
   insn->bits2.da3src.src0_reg_nr = src0.nr;
   insn->bits1.da3src.src0_abs = src0.abs;
   insn->bits1.da3src.src0_negate = src0.negate;
   insn->bits2.da3src.src0_rep_ctrl = src0.vstride == BRW_VERTICAL_STRIDE_0;
d908 7
a914 7
   insn->bits2.da3src.src1_swizzle = src1.dw1.bits.swizzle;
   insn->bits2.da3src.src1_subreg_nr_low = get_3src_subreg_nr(src1) & 0x3;
   insn->bits3.da3src.src1_subreg_nr_high = get_3src_subreg_nr(src1) >> 2;
   insn->bits2.da3src.src1_rep_ctrl = src1.vstride == BRW_VERTICAL_STRIDE_0;
   insn->bits3.da3src.src1_reg_nr = src1.nr;
   insn->bits1.da3src.src1_abs = src1.abs;
   insn->bits1.da3src.src1_negate = src1.negate;
d919 7
a925 6
   insn->bits3.da3src.src2_swizzle = src2.dw1.bits.swizzle;
   insn->bits3.da3src.src2_subreg_nr = get_3src_subreg_nr(src2);
   insn->bits3.da3src.src2_rep_ctrl = src2.vstride == BRW_VERTICAL_STRIDE_0;
   insn->bits3.da3src.src2_reg_nr = src2.nr;
   insn->bits1.da3src.src2_abs = src2.abs;
   insn->bits1.da3src.src2_negate = src2.negate;
d936 2
a937 2
         insn->bits1.da3src.src_type = BRW_3SRC_TYPE_F;
         insn->bits1.da3src.dst_type = BRW_3SRC_TYPE_F;
d940 2
a941 2
         insn->bits1.da3src.src_type = BRW_3SRC_TYPE_D;
         insn->bits1.da3src.dst_type = BRW_3SRC_TYPE_D;
d944 2
a945 2
         insn->bits1.da3src.src_type = BRW_3SRC_TYPE_UD;
         insn->bits1.da3src.dst_type = BRW_3SRC_TYPE_UD;
d950 1
a950 1
   return insn;
d958 1
a958 1
struct brw_instruction *brw_##OP(struct brw_compile *p,	\
d966 1
a966 1
struct brw_instruction *brw_##OP(struct brw_compile *p,	\
d975 1
a975 1
struct brw_instruction *brw_##OP(struct brw_compile *p,	\
d985 1
a985 1
struct brw_instruction *brw_##OP(struct brw_compile *p,         \
d1010 2
a1011 1
   struct brw_instruction *rnd, *add;					      \
d1016 1
a1016 1
   if (p->brw->gen < 6) {						      \
d1018 1
a1018 1
      rnd->header.destreg__conditionalmod = BRW_CONDITIONAL_R;		      \
d1020 1
a1020 1
      add->header.predicate_control = BRW_PREDICATE_NORMAL;		      \
a1033 2
ALU1(F32TO16)
ALU1(F16TO32)
d1061 3
a1063 4
struct brw_instruction *brw_ADD(struct brw_compile *p,
				struct brw_reg dest,
				struct brw_reg src0,
				struct brw_reg src1)
d1083 3
a1085 4
struct brw_instruction *brw_AVG(struct brw_compile *p,
                                struct brw_reg dest,
                                struct brw_reg src0,
                                struct brw_reg src1)
d1098 1
a1098 1
      assert(!"Bad type for brw_AVG");
d1104 3
a1106 4
struct brw_instruction *brw_MUL(struct brw_compile *p,
				struct brw_reg dest,
				struct brw_reg src0,
				struct brw_reg src1)
d1138 50
d1191 1
a1191 1
   struct brw_instruction *insn = next_insn(p, BRW_OPCODE_NOP);
d1205 12
a1216 12
struct brw_instruction *brw_JMPI(struct brw_compile *p,
                                 struct brw_reg dest,
                                 struct brw_reg src0,
                                 struct brw_reg src1)
{
   struct brw_instruction *insn = brw_alu2(p, BRW_OPCODE_JMPI, dest, src0, src1);

   insn->header.execution_size = 1;
   insn->header.compression_control = BRW_COMPRESSION_NONE;
   insn->header.mask_control = BRW_MASK_DISABLE;

   p->current->header.predicate_control = BRW_PREDICATE_NONE;
d1218 1
a1218 1
   return insn;
d1222 1
a1222 1
push_if_stack(struct brw_compile *p, struct brw_instruction *inst)
d1234 1
a1234 1
static struct brw_instruction *
d1242 1
a1242 1
push_loop_stack(struct brw_compile *p, struct brw_instruction *inst)
d1257 1
a1257 1
static struct brw_instruction *
d1276 1
a1276 1
struct brw_instruction *
d1280 1
a1280 1
   struct brw_instruction *insn;
d1292 1
a1292 1
      insn->bits1.branch_gen6.jump_count = 0;
d1295 1
a1295 1
   } else {
d1299 7
a1305 2
      insn->bits3.break_cont.jip = 0;
      insn->bits3.break_cont.uip = 0;
d1308 6
a1313 8
   insn->header.execution_size = execute_size;
   insn->header.compression_control = BRW_COMPRESSION_NONE;
   insn->header.predicate_control = BRW_PREDICATE_NORMAL;
   insn->header.mask_control = BRW_MASK_ENABLE;
   if (!p->single_program_flow)
      insn->header.thread_control = BRW_THREAD_SWITCH;

   p->current->header.predicate_control = BRW_PREDICATE_NONE;
d1323 2
a1324 2
struct brw_instruction *
gen6_IF(struct brw_compile *p, uint32_t conditional,
d1327 2
a1328 1
   struct brw_instruction *insn;
d1333 3
a1335 6
   if (p->compressed) {
      insn->header.execution_size = BRW_EXECUTE_16;
   } else {
      insn->header.execution_size = BRW_EXECUTE_8;
   }
   insn->bits1.branch_gen6.jump_count = 0;
d1339 3
a1341 6
   assert(insn->header.compression_control == BRW_COMPRESSION_NONE);
   assert(insn->header.predicate_control == BRW_PREDICATE_NONE);
   insn->header.destreg__conditionalmod = conditional;

   if (!p->single_program_flow)
      insn->header.thread_control = BRW_THREAD_SWITCH;
d1352 1
a1352 2
		       struct brw_instruction *if_inst,
		       struct brw_instruction *else_inst)
d1354 2
d1357 1
a1357 1
   struct brw_instruction *next_inst = &p->store[p->nr_insn];
d1360 3
a1362 3
   assert(if_inst != NULL && if_inst->header.opcode == BRW_OPCODE_IF);
   assert(else_inst == NULL || else_inst->header.opcode == BRW_OPCODE_ELSE);
   assert(if_inst->header.execution_size == BRW_EXECUTE_1);
d1372 2
a1373 2
   if_inst->header.opcode = BRW_OPCODE_ADD;
   if_inst->header.predicate_inverse = 1;
d1379 1
a1379 1
      else_inst->header.opcode = BRW_OPCODE_ADD;
d1381 2
a1382 2
      if_inst->bits3.ud = (else_inst - if_inst + 1) * 16;
      else_inst->bits3.ud = (next_inst - else_inst) * 16;
d1384 1
a1384 1
      if_inst->bits3.ud = (next_inst - if_inst) * 16;
d1393 1
a1393 3
	      struct brw_instruction *if_inst,
	      struct brw_instruction *else_inst,
	      struct brw_instruction *endif_inst)
d1412 1
a1412 1
   assert(if_inst != NULL && if_inst->header.opcode == BRW_OPCODE_IF);
d1414 1
a1414 1
   assert(else_inst == NULL || else_inst->header.opcode == BRW_OPCODE_ELSE);
d1416 1
a1416 6
   unsigned br = 1;
   /* Jump count is for 64bit data chunk each, so one 128bit instruction
    * requires 2 chunks.
    */
   if (brw->gen >= 5)
      br = 2;
d1418 2
a1419 2
   assert(endif_inst->header.opcode == BRW_OPCODE_ENDIF);
   endif_inst->header.execution_size = if_inst->header.execution_size;
d1427 4
a1430 4
	 if_inst->header.opcode = BRW_OPCODE_IFF;
	 if_inst->bits3.if_else.jump_count = br * (endif_inst - if_inst + 1);
	 if_inst->bits3.if_else.pop_count = 0;
	 if_inst->bits3.if_else.pad0 = 0;
d1433 1
a1433 1
	 if_inst->bits1.branch_gen6.jump_count = br * (endif_inst - if_inst);
d1435 2
a1436 2
	 if_inst->bits3.break_cont.uip = br * (endif_inst - if_inst);
	 if_inst->bits3.break_cont.jip = br * (endif_inst - if_inst);
d1439 1
a1439 1
      else_inst->header.execution_size = if_inst->header.execution_size;
d1443 3
a1445 3
	 if_inst->bits3.if_else.jump_count = br * (else_inst - if_inst);
	 if_inst->bits3.if_else.pop_count = 0;
	 if_inst->bits3.if_else.pad0 = 0;
d1447 2
a1448 1
	 if_inst->bits1.branch_gen6.jump_count = br * (else_inst - if_inst + 1);
d1456 3
a1458 3
	 else_inst->bits3.if_else.jump_count = br*(endif_inst - else_inst + 1);
	 else_inst->bits3.if_else.pop_count = 1;
	 else_inst->bits3.if_else.pad0 = 0;
d1461 2
a1462 1
	 else_inst->bits1.branch_gen6.jump_count = br*(endif_inst - else_inst);
d1465 1
a1465 1
	 if_inst->bits3.break_cont.jip = br * (else_inst - if_inst + 1);
d1467 8
a1474 2
	 if_inst->bits3.break_cont.uip = br * (endif_inst - if_inst);
	 else_inst->bits3.break_cont.jip = br * (endif_inst - else_inst);
d1483 1
a1483 1
   struct brw_instruction *insn;
d1493 1
a1493 1
      insn->bits1.branch_gen6.jump_count = 0;
d1496 1
a1496 1
   } else {
d1500 7
a1506 2
      insn->bits3.break_cont.jip = 0;
      insn->bits3.break_cont.uip = 0;
d1509 4
a1512 4
   insn->header.compression_control = BRW_COMPRESSION_NONE;
   insn->header.mask_control = BRW_MASK_ENABLE;
   if (!p->single_program_flow)
      insn->header.thread_control = BRW_THREAD_SWITCH;
d1521 4
a1524 4
   struct brw_instruction *insn = NULL;
   struct brw_instruction *else_inst = NULL;
   struct brw_instruction *if_inst = NULL;
   struct brw_instruction *tmp;
d1553 1
a1553 1
   if (tmp->header.opcode == BRW_OPCODE_ELSE) {
d1573 1
a1573 1
   } else {
d1577 2
d1581 4
a1584 3
   insn->header.compression_control = BRW_COMPRESSION_NONE;
   insn->header.mask_control = BRW_MASK_ENABLE;
   insn->header.thread_control = BRW_THREAD_SWITCH;
d1588 2
a1589 3
      insn->bits3.if_else.jump_count = 0;
      insn->bits3.if_else.pop_count = 1;
      insn->bits3.if_else.pad0 = 0;
d1591 1
a1591 1
      insn->bits1.branch_gen6.jump_count = 2;
d1593 1
a1593 1
      insn->bits3.break_cont.jip = 2;
d1598 2
a1599 1
struct brw_instruction *brw_BREAK(struct brw_compile *p)
d1602 1
a1602 1
   struct brw_instruction *insn;
d1605 4
a1608 1
   if (brw->gen >= 6) {
d1616 2
a1617 2
      insn->bits3.if_else.pad0 = 0;
      insn->bits3.if_else.pop_count = p->if_depth_in_loop[p->loop_stack_depth];
d1619 3
a1621 2
   insn->header.compression_control = BRW_COMPRESSION_NONE;
   insn->header.execution_size = BRW_EXECUTE_8;
d1626 2
a1627 1
struct brw_instruction *gen6_CONT(struct brw_compile *p)
d1629 2
a1630 1
   struct brw_instruction *insn;
a1632 2
   brw_set_dest(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
   brw_set_src0(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
d1634 6
a1639 2
   brw_set_src0(p, insn, brw_ip_reg());
   brw_set_src1(p, insn, brw_imm_d(0x0));
d1641 7
a1647 2
   insn->header.compression_control = BRW_COMPRESSION_NONE;
   insn->header.execution_size = BRW_EXECUTE_8;
d1651 2
a1652 1
struct brw_instruction *brw_CONT(struct brw_compile *p)
d1654 2
a1655 16
   struct brw_instruction *insn;
   insn = next_insn(p, BRW_OPCODE_CONTINUE);
   brw_set_dest(p, insn, brw_ip_reg());
   brw_set_src0(p, insn, brw_ip_reg());
   brw_set_src1(p, insn, brw_imm_d(0x0));
   insn->header.compression_control = BRW_COMPRESSION_NONE;
   insn->header.execution_size = BRW_EXECUTE_8;
   /* insn->header.mask_control = BRW_MASK_DISABLE; */
   insn->bits3.if_else.pad0 = 0;
   insn->bits3.if_else.pop_count = p->if_depth_in_loop[p->loop_stack_depth];
   return insn;
}

struct brw_instruction *gen6_HALT(struct brw_compile *p)
{
   struct brw_instruction *insn;
d1659 6
a1664 2
   brw_set_src0(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
   brw_set_src1(p, insn, brw_imm_d(0x0)); /* UIP and JIP, updated later. */
d1667 1
a1667 1
      insn->header.execution_size = BRW_EXECUTE_16;
d1669 2
a1670 2
      insn->header.compression_control = BRW_COMPRESSION_NONE;
      insn->header.execution_size = BRW_EXECUTE_8;
d1691 2
a1692 1
struct brw_instruction *brw_DO(struct brw_compile *p, unsigned execute_size)
d1700 1
a1700 1
      struct brw_instruction *insn = next_insn(p, BRW_OPCODE_DO);
d1710 3
a1712 5
      insn->header.compression_control = BRW_COMPRESSION_NONE;
      insn->header.execution_size = execute_size;
      insn->header.predicate_control = BRW_PREDICATE_NONE;
      /* insn->header.mask_control = BRW_MASK_ENABLE; */
      /* insn->header.mask_control = BRW_MASK_DISABLE; */
d1726 1
a1726 1
brw_patch_break_cont(struct brw_compile *p, struct brw_instruction *while_inst)
d1729 5
a1733 3
   struct brw_instruction *do_inst = get_inner_do_insn(p);
   struct brw_instruction *inst;
   int br = (brw->gen == 5) ? 2 : 1;
d1740 6
a1745 6
      if (inst->header.opcode == BRW_OPCODE_BREAK &&
	  inst->bits3.if_else.jump_count == 0) {
	 inst->bits3.if_else.jump_count = br * ((while_inst - inst) + 1);
      } else if (inst->header.opcode == BRW_OPCODE_CONTINUE &&
		 inst->bits3.if_else.jump_count == 0) {
	 inst->bits3.if_else.jump_count = br * (while_inst - inst);
d1750 2
a1751 1
struct brw_instruction *brw_WHILE(struct brw_compile *p)
d1754 2
a1755 2
   struct brw_instruction *insn, *do_insn;
   unsigned br = 1;
d1757 1
a1757 4
   if (brw->gen >= 5)
      br = 2;

   if (brw->gen >= 7) {
d1761 15
a1775 9
      brw_set_dest(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
      brw_set_src0(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
      brw_set_src1(p, insn, brw_imm_ud(0));
      insn->bits3.break_cont.jip = br * (do_insn - insn);

      insn->header.execution_size = BRW_EXECUTE_8;
   } else if (brw->gen == 6) {
      insn = next_insn(p, BRW_OPCODE_WHILE);
      do_insn = get_inner_do_insn(p);
d1777 2
a1778 6
      brw_set_dest(p, insn, brw_imm_w(0));
      insn->bits1.branch_gen6.jump_count = br * (do_insn - insn);
      brw_set_src0(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
      brw_set_src1(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));

      insn->header.execution_size = BRW_EXECUTE_8;
d1787 1
a1787 1
	 insn->header.execution_size = BRW_EXECUTE_1;
d1792 1
a1792 1
	 assert(do_insn->header.opcode == BRW_OPCODE_DO);
d1798 3
a1800 4
	 insn->header.execution_size = do_insn->header.execution_size;
	 insn->bits3.if_else.jump_count = br * (do_insn - insn + 1);
	 insn->bits3.if_else.pop_count = 0;
	 insn->bits3.if_else.pad0 = 0;
d1805 1
a1805 2
   insn->header.compression_control = BRW_COMPRESSION_NONE;
   p->current->header.predicate_control = BRW_PREDICATE_NONE;
a1811 1

d1817 1
a1817 1
   struct brw_instruction *jmp_insn = &p->store[jmp_insn_idx];
d1823 2
a1824 2
   assert(jmp_insn->header.opcode == BRW_OPCODE_JMPI);
   assert(jmp_insn->bits1.da1.src1_reg_file == BRW_IMMEDIATE_VALUE);
d1826 2
a1827 1
   jmp_insn->bits3.ud = jmpi * (p->nr_insn - jmp_insn_idx - 1);
a1829 2


d1841 9
a1849 1
   struct brw_instruction *insn = next_insn(p, BRW_OPCODE_CMP);
d1851 1
a1851 1
   insn->header.destreg__conditionalmod = conditional;
a1855 13
/*    guess_execution_size(insn, src0); */


   /* Make it so that future instructions will use the computed flag
    * value until brw_set_predicate_control_flag_value() is called
    * again.
    */
   if (dest.file == BRW_ARCHITECTURE_REGISTER_FILE &&
       dest.nr == 0) {
      p->current->header.predicate_control = BRW_PREDICATE_NORMAL;
      p->flag_value = 0xff;
   }

d1866 1
a1866 1
         insn->header.thread_control = BRW_THREAD_SWITCH;
a1870 16
/* Issue 'wait' instruction for n1, host could program MMIO
   to wake up thread. */
void brw_WAIT (struct brw_compile *p)
{
   struct brw_instruction *insn = next_insn(p, BRW_OPCODE_WAIT);
   struct brw_reg src = brw_notification_1_reg();

   brw_set_dest(p, insn, src);
   brw_set_src0(p, insn, src);
   brw_set_src1(p, insn, brw_null_reg());
   insn->header.execution_size = 0; /* must */
   insn->header.predicate_control = 0;
   insn->header.compression_control = 0;
}


d1877 1
a1877 1
void brw_math( struct brw_compile *p,
a1881 1
	       unsigned data_type,
d1885 9
d1895 1
a1895 2
   if (brw->gen >= 6) {
      struct brw_instruction *insn = next_insn(p, BRW_OPCODE_MATH);
d1897 5
a1901 21
      assert(dest.file == BRW_GENERAL_REGISTER_FILE ||
             (brw->gen >= 7 && dest.file == BRW_MESSAGE_REGISTER_FILE));
      assert(src.file == BRW_GENERAL_REGISTER_FILE);

      assert(dest.hstride == BRW_HORIZONTAL_STRIDE_1);
      if (brw->gen == 6)
	 assert(src.hstride == BRW_HORIZONTAL_STRIDE_1);

      /* Source modifiers are ignored for extended math instructions on Gen6. */
      if (brw->gen == 6) {
	 assert(!src.negate);
	 assert(!src.abs);
      }

      if (function == BRW_MATH_FUNCTION_INT_DIV_QUOTIENT ||
	  function == BRW_MATH_FUNCTION_INT_DIV_REMAINDER ||
	  function == BRW_MATH_FUNCTION_INT_DIV_QUOTIENT_AND_REMAINDER) {
	 assert(src.type != BRW_REGISTER_TYPE_F);
      } else {
	 assert(src.type == BRW_REGISTER_TYPE_F);
      }
d1903 8
a1910 26
      /* Math is the same ISA format as other opcodes, except that CondModifier
       * becomes FC[3:0] and ThreadCtrl becomes FC[5:4].
       */
      insn->header.destreg__conditionalmod = function;

      brw_set_dest(p, insn, dest);
      brw_set_src0(p, insn, src);
      brw_set_src1(p, insn, brw_null_reg());
   } else {
      struct brw_instruction *insn = next_insn(p, BRW_OPCODE_SEND);

      /* Example code doesn't set predicate_control for send
       * instructions.
       */
      insn->header.predicate_control = 0;
      insn->header.destreg__conditionalmod = msg_reg_nr;

      brw_set_dest(p, insn, dest);
      brw_set_src0(p, insn, src);
      brw_set_math_message(p,
			   insn,
			   function,
			   src.type == BRW_REGISTER_TYPE_D,
			   precision,
			   data_type);
   }
d1913 1
a1913 3
/** Extended math function, float[8].
 */
void brw_math2(struct brw_compile *p,
d1920 3
a1922 1
   struct brw_instruction *insn = next_insn(p, BRW_OPCODE_MATH);
d1926 2
a1927 2
   assert(src0.file == BRW_GENERAL_REGISTER_FILE);
   assert(src1.file == BRW_GENERAL_REGISTER_FILE);
d1940 2
d1945 7
d1962 1
a1962 4
   /* Math is the same ISA format as other opcodes, except that CondModifier
    * becomes FC[3:0] and ThreadCtrl becomes FC[5:4].
    */
   insn->header.destreg__conditionalmod = function;
d2006 2
a2007 2
      brw_set_mask_control(p, BRW_MASK_DISABLE);
      brw_set_compression_control(p, BRW_COMPRESSION_NONE);
d2023 1
a2023 1
      struct brw_instruction *insn = next_insn(p, BRW_OPCODE_SEND);
d2028 2
a2029 2
      if (insn->header.compression_control != BRW_COMPRESSION_NONE) {
	 insn->header.compression_control = BRW_COMPRESSION_NONE;
d2032 3
a2034 2
      assert(insn->header.predicate_control == BRW_PREDICATE_NONE);
      insn->header.destreg__conditionalmod = mrf.nr;
d2102 12
a2113 1
   mrf = retype(mrf, BRW_REGISTER_TYPE_UD);
d2126 2
a2127 2
      brw_set_compression_control(p, BRW_COMPRESSION_NONE);
      brw_set_mask_control(p, BRW_MASK_DISABLE);
d2132 1
a2132 5
      brw_MOV(p,
	      retype(brw_vec1_reg(BRW_MESSAGE_REGISTER_FILE,
				  mrf.nr,
				  2), BRW_REGISTER_TYPE_UD),
	      brw_imm_ud(offset));
d2138 1
a2138 1
      struct brw_instruction *insn = next_insn(p, BRW_OPCODE_SEND);
d2140 2
a2141 3
      assert(insn->header.predicate_control == 0);
      insn->header.compression_control = BRW_COMPRESSION_NONE;
      insn->header.destreg__conditionalmod = mrf.nr;
d2148 1
d2169 3
a2171 3
   dest = retype(dest, BRW_REGISTER_TYPE_UW);

   struct brw_instruction *insn = next_insn(p, BRW_OPCODE_SEND);
d2173 2
a2174 4
   assert(insn->header.predicate_control == BRW_PREDICATE_NONE);
   insn->header.compression_control = BRW_COMPRESSION_NONE;

   brw_set_dest(p, insn, dest);
a2178 1
   bool header_present = true;
a2180 12
   brw_set_message_descriptor(p, insn,
                              GEN7_SFID_DATAPORT_DATA_CACHE,
                              1, /* mlen: just g0 */
                              num_regs,
                              header_present,
                              false);

   insn->bits3.ud |= GEN7_DATAPORT_SCRATCH_READ;

   assert(num_regs == 1 || num_regs == 2 || num_regs == 4);
   insn->bits3.ud |= (num_regs - 1) << GEN7_DATAPORT_SCRATCH_NUM_REGS_SHIFT;

d2187 10
a2196 1
   insn->bits3.ud |= offset;
d2219 3
a2221 3
   brw_set_predicate_control(p, BRW_PREDICATE_NONE);
   brw_set_compression_control(p, BRW_COMPRESSION_NONE);
   brw_set_mask_control(p, BRW_MASK_DISABLE);
d2232 1
a2232 2
   struct brw_instruction *insn = next_insn(p, BRW_OPCODE_SEND);
   insn->header.destreg__conditionalmod = mrf.nr;
d2242 1
d2261 2
a2262 2
                  unsigned msg_reg_nr,
                  struct brw_reg src0,
d2271 1
a2271 1
   struct brw_instruction *insn;
d2273 1
a2273 1
   struct brw_reg dest;
d2285 1
a2285 1
   insn->header.compression_control = BRW_COMPRESSION_NONE;
d2289 1
a2289 1
      src0 = brw_message_reg(msg_reg_nr);
d2293 3
a2295 1
      insn->header.destreg__conditionalmod = msg_reg_nr;
d2335 1
a2335 1
   struct brw_instruction *insn;
d2341 1
a2341 1
   insn->header.predicate_control = 0; /* XXX */
d2355 2
a2356 2
   if (insn->header.compression_control != BRW_COMPRESSION_2NDHALF)
      insn->header.compression_control = BRW_COMPRESSION_NONE;
d2359 1
a2359 1
      insn->header.destreg__conditionalmod = msg_reg_nr;
d2374 47
d2436 1
a2436 1
   struct brw_instruction *insn;
d2440 1
a2440 1
   if (brw->gen == 7 && !(flags & BRW_URB_WRITE_USE_CHANNEL_MASKS)) {
d2443 2
a2444 2
      brw_set_access_mode(p, BRW_ALIGN_1);
      brw_set_mask_control(p, BRW_MASK_DISABLE);
d2461 1
a2461 1
      insn->header.destreg__conditionalmod = msg_reg_nr;
d2473 1
a2473 1
next_ip(struct brw_compile *p, int ip)
d2475 1
a2475 12
   struct brw_instruction *insn = (void *)p->store + ip;

   if (insn->header.cmpt_control)
      return ip + 8;
   else
      return ip + 16;
}

static int
brw_find_next_block_end(struct brw_compile *p, int start)
{
   int ip;
d2477 1
d2479 4
a2482 2
   for (ip = next_ip(p, start); ip < p->next_insn_offset; ip = next_ip(p, ip)) {
      struct brw_instruction *insn = store + ip;
d2484 1
a2484 1
      switch (insn->header.opcode) {
d2489 1
a2489 1
	 return ip;
d2501 1
a2501 1
brw_find_loop_end(struct brw_compile *p, int start)
d2504 2
a2505 2
   int ip;
   int scale = 8;
d2508 2
d2513 10
a2522 8
   for (ip = next_ip(p, start); ip < p->next_insn_offset; ip = next_ip(p, ip)) {
      struct brw_instruction *insn = store + ip;

      if (insn->header.opcode == BRW_OPCODE_WHILE) {
	 int jip = brw->gen == 6 ? insn->bits1.branch_gen6.jump_count
				   : insn->bits3.break_cont.jip;
	 if (ip + jip * scale <= start)
	    return ip;
d2526 1
a2526 1
   return start;
d2536 3
a2538 2
   int ip;
   int scale = 8;
d2544 3
a2546 2
   for (ip = 0; ip < p->next_insn_offset; ip = next_ip(p, ip)) {
      struct brw_instruction *insn = store + ip;
d2548 1
a2548 1
      if (insn->header.cmpt_control) {
d2550 3
a2552 3
	 assert(insn->header.opcode != BRW_OPCODE_BREAK &&
		insn->header.opcode != BRW_OPCODE_CONTINUE &&
		insn->header.opcode != BRW_OPCODE_HALT);
d2556 2
a2557 2
      int block_end_ip = brw_find_next_block_end(p, ip);
      switch (insn->header.opcode) {
d2559 2
a2560 2
         assert(block_end_ip != 0);
	 insn->bits3.break_cont.jip = (block_end_ip - ip) / scale;
d2562 3
a2564 3
	 insn->bits3.break_cont.uip =
	    (brw_find_loop_end(p, ip) - ip +
             (brw->gen == 6 ? 16 : 0)) / scale;
d2567 4
a2570 4
         assert(block_end_ip != 0);
	 insn->bits3.break_cont.jip = (block_end_ip - ip) / scale;
	 insn->bits3.break_cont.uip =
            (brw_find_loop_end(p, ip) - ip) / scale;
d2572 2
a2573 2
	 assert(insn->bits3.break_cont.uip != 0);
	 assert(insn->bits3.break_cont.jip != 0);
d2576 5
a2580 3
      case BRW_OPCODE_ENDIF:
         if (block_end_ip == 0)
            insn->bits3.break_cont.jip = 2;
d2582 1
a2582 1
            insn->bits3.break_cont.jip = (block_end_ip - ip) / scale;
d2584 1
d2598 2
a2599 2
	 if (block_end_ip == 0) {
	    insn->bits3.break_cont.jip = insn->bits3.break_cont.uip;
d2601 1
a2601 1
	    insn->bits3.break_cont.jip = (block_end_ip - ip) / scale;
d2603 2
a2604 2
	 assert(insn->bits3.break_cont.uip != 0);
	 assert(insn->bits3.break_cont.jip != 0);
d2619 1
a2619 1
   struct brw_instruction *insn;
d2629 1
a2629 1
      insn->header.destreg__conditionalmod = msg_reg_nr;
d2657 1
a2657 1
   struct brw_instruction *insn;
d2679 1
a2679 1
                                  struct brw_instruction *insn,
d2686 7
a2692 1
   if (p->brw->is_haswell) {
d2698 3
a2700 3
      if (insn->header.access_mode == BRW_ALIGN_1) {
         if (insn->header.execution_size != BRW_EXECUTE_16)
            insn->bits3.ud |= 1 << 12; /* SIMD8 mode */
d2702 2
a2703 2
         insn->bits3.gen7_dp.msg_type =
            HSW_DATAPORT_DC_PORT1_UNTYPED_ATOMIC_OP;
d2705 2
a2706 2
         insn->bits3.gen7_dp.msg_type =
            HSW_DATAPORT_DC_PORT1_UNTYPED_ATOMIC_OP_SIMD4X2;
a2707 1

d2713 1
a2713 1
      insn->bits3.gen7_dp.msg_type = GEN7_DATAPORT_DC_UNTYPED_ATOMIC_OP;
d2715 2
a2716 2
      if (insn->header.execution_size != BRW_EXECUTE_16)
         insn->bits3.ud |= 1 << 12; /* SIMD8 mode */
d2719 2
a2720 5
   if (response_length)
      insn->bits3.ud |= 1 << 13; /* Return data expected */

   insn->bits3.gen7_dp.binding_table_index = bind_table_index;
   insn->bits3.ud |= atomic_op << 8;
d2726 1
a2726 1
                   struct brw_reg mrf,
d2731 2
a2732 1
   struct brw_instruction *insn = brw_next_insn(p, BRW_OPCODE_SEND);
d2735 1
a2735 1
   brw_set_src0(p, insn, retype(mrf, BRW_REGISTER_TYPE_UD));
d2739 1
a2739 1
      insn->header.access_mode == BRW_ALIGN_1);
d2744 1
a2744 1
                                        struct brw_instruction *insn,
d2750 1
d2752 1
a2752 1
      (insn->header.execution_size == BRW_EXECUTE_16 ? 16 : 8);
d2755 1
a2755 1
   if (p->brw->is_haswell) {
d2760 2
a2761 1
      insn->bits3.gen7_dp.msg_type = HSW_DATAPORT_DC_PORT1_UNTYPED_SURFACE_READ;
d2767 2
a2768 1
      insn->bits3.gen7_dp.msg_type = GEN7_DATAPORT_DC_UNTYPED_SURFACE_READ;
d2771 4
a2774 1
   if (insn->header.access_mode == BRW_ALIGN_1) {
d2776 1
a2776 1
         insn->bits3.ud |= 1 << 12; /* SIMD16 mode */
d2778 1
a2778 1
         insn->bits3.ud |= 2 << 12; /* SIMD8 mode */
d2781 2
a2782 4
   insn->bits3.gen7_dp.binding_table_index = bind_table_index;

   /* Set mask of 32-bit channels to drop. */
   insn->bits3.ud |= (0xf & (0xf << num_channels)) << 8;
d2793 2
a2794 1
   struct brw_instruction *insn = next_insn(p, BRW_OPCODE_SEND);
d2800 29
a2828 1
      insn->header.access_mode == BRW_ALIGN_1);
d2851 1
a2851 2
   struct brw_context *brw = p->brw;
   assert(brw->gen >= 7);
d2854 3
a2856 3
   brw_set_access_mode(p, BRW_ALIGN_1);
   brw_set_mask_control(p, BRW_MASK_DISABLE);
   struct brw_instruction *send = brw_next_insn(p, BRW_OPCODE_SEND);
@


1.8
log
@Merge Mesa 9.2.0
@
text
@d3 1
a3 1
 Intel funded Tungsten Graphics (http://www.tungstengraphics.com) to
d5 1
a5 1
 
d13 1
a13 1
 
d17 1
a17 1
 
d25 1
a25 1
 
d29 1
a29 1
  *   Keith Whitwell <keith@@tungstengraphics.com>
d31 1
a31 1
     
d64 1
a64 1
			  GLuint msg_reg_nr)
d102 55
d169 2
a170 1
   insn->bits1.da1.dest_reg_type = dest.type;
d173 1
a173 1
   if (dest.address_mode == BRW_ADDRESS_DIRECT) {   
d185 4
d323 2
a324 1
   insn->bits1.da1.src0_reg_type = reg.type;
d331 1
a331 1
   
d335 1
a335 1
      insn->bits1.da1.src1_reg_type = reg.type;
d337 1
a337 1
   else 
d353 1
a353 1
	    insn->bits2.ia1.src0_indirect_offset = reg.dw1.bits.indirect_offset; 
d361 1
a361 1
	 if (reg.width == BRW_WIDTH_1 && 
d405 2
a406 1
   insn->bits1.da1.src1_reg_type = reg.type;
d434 1
a434 1
	 if (reg.width == BRW_WIDTH_1 && 
d508 2
a509 2
				  GLuint function,
				  GLuint integer_type,
d511 1
a511 1
				  GLuint dataType )
d565 1
a565 1
				    GLuint response_length,
d580 5
a584 8
				 bool allocate,
				 bool used,
				 GLuint msg_length,
				 GLuint response_length,
				 bool end_of_thread,
				 bool complete,
				 GLuint offset,
				 GLuint swizzle_control )
d589 2
a590 1
			      msg_length, response_length, true, end_of_thread);
d592 6
a597 1
      insn->bits3.urb_gen7.opcode = 0;	/* URB_WRITE_HWORD */
d601 3
a603 3
      /* per_slot_offset = 0 makes it ignore offsets in message header */
      insn->bits3.urb_gen7.per_slot_offset = 0;
      insn->bits3.urb_gen7.complete = complete;
d608 3
a610 3
      insn->bits3.urb_gen5.allocate = allocate;
      insn->bits3.urb_gen5.used = used;	/* ? */
      insn->bits3.urb_gen5.complete = complete;
d615 3
a617 3
      insn->bits3.urb.allocate = allocate;
      insn->bits3.urb.used = used;	/* ? */
      insn->bits3.urb.complete = complete;
d624 4
a627 4
			 GLuint binding_table_index,
			 GLuint msg_control,
			 GLuint msg_type,
			 GLuint msg_length,
d629 4
a632 4
			 GLuint last_render_target,
			 GLuint response_length,
			 GLuint end_of_thread,
			 GLuint send_commit_msg)
d682 5
a686 5
			GLuint binding_table_index,
			GLuint msg_control,
			GLuint msg_type,
			GLuint target_cache,
			GLuint msg_length,
d688 1
a688 1
			GLuint response_length)
d739 8
a746 8
                        GLuint binding_table_index,
                        GLuint sampler,
                        GLuint msg_type,
                        GLuint response_length,
                        GLuint msg_length,
                        GLuint header_present,
                        GLuint simd_mode,
                        GLuint return_format)
d778 1
a778 1
brw_next_insn(struct brw_compile *p, GLuint opcode)
d783 4
a786 2
      if (0)
         printf("incresing the store size to %d\n", p->store_size << 1);
d798 1
a798 1
   /* Reset this one-shot flag: 
d811 1
a811 1
					 GLuint opcode,
d822 1
a822 1
					GLuint opcode,
d827 1
a827 1
   struct brw_instruction *insn = next_insn(p, opcode);   
d846 1
a846 1
					GLuint opcode,
a1007 2
ALU2(RSR)
ALU2(RSL)
d1031 2
d1121 1
a1121 1
   struct brw_instruction *insn = next_insn(p, BRW_OPCODE_NOP);   
d1135 1
a1135 1
struct brw_instruction *brw_JMPI(struct brw_compile *p, 
d1207 1
a1207 1
brw_IF(struct brw_compile *p, GLuint execute_size)
d1609 1
a1609 1
struct brw_instruction *brw_DO(struct brw_compile *p, GLuint execute_size)
d1671 1
a1671 1
   GLuint br = 1;
d1738 1
a1738 1
   GLuint jmpi = 1;
d1757 1
a1757 1
	     GLuint conditional,
d1774 1
a1774 1
    * again.  
d1821 2
a1822 2
	       GLuint function,
	       GLuint msg_reg_nr,
d1824 2
a1825 2
	       GLuint data_type,
	       GLuint precision )
d1886 1
a1886 1
	       GLuint function,
d1943 1
a1943 1
				   GLuint offset)
d2055 1
a2055 1
			     GLuint offset)
d2118 42
d2222 1
a2222 1
                  GLuint msg_reg_nr,
d2224 4
a2227 4
                  GLuint msg_control,
                  GLuint binding_table_index,
                  GLuint msg_length,
                  GLuint response_length,
d2233 1
a2233 1
   GLuint msg_type;
a2245 2
   /* The execution mask is ignored for render target writes. */
   insn->header.predicate_control = 0;
d2282 1
a2282 1
		GLuint msg_reg_nr,
d2284 8
a2291 8
		GLuint binding_table_index,
		GLuint sampler,
		GLuint msg_type,
		GLuint response_length,
		GLuint msg_length,
		GLuint header_present,
		GLuint simd_mode,
		GLuint return_format)
d2296 2
a2297 1
   gen6_resolve_implied_move(p, &src0, msg_reg_nr);
d2301 16
a2316 1
   insn->header.compression_control = BRW_COMPRESSION_NONE;
d2339 1
a2339 1
		   GLuint msg_reg_nr,
d2341 5
a2345 8
		   bool allocate,
		   bool used,
		   GLuint msg_length,
		   GLuint response_length,
		   bool eot,
		   bool writes_complete,
		   GLuint offset,
		   GLuint swizzle)
d2352 1
a2352 1
   if (brw->gen == 7) {
d2377 1
a2377 2
		       allocate,
		       used,
d2379 1
a2379 3
		       response_length, 
		       eot, 
		       writes_complete, 
d2523 1
a2523 1
		   GLuint msg_reg_nr,
d2526 1
a2526 1
		   GLuint response_length,
d2563 1
a2563 1
              GLuint msg_reg_nr,
d2565 1
a2565 1
              GLuint binding_table_index,
d2588 118
d2742 4
a2745 21

   uint32_t sfid, msg_type;
   if (brw->is_haswell) {
      sfid = HSW_SFID_DATAPORT_DATA_CACHE_1;
      msg_type = HSW_DATAPORT_DC_PORT1_UNTYPED_ATOMIC_OP;
   } else {
      sfid = GEN7_SFID_DATAPORT_DATA_CACHE;
      msg_type = GEN7_DATAPORT_DC_UNTYPED_ATOMIC_OP;
   }

   bool header_present = false;
   bool eot = false;
   uint32_t mlen = 2; /* offset, value */
   uint32_t rlen = 0;
   brw_set_message_descriptor(p, send, sfid, mlen, rlen, header_present, eot);

   send->bits3.ud |= msg_type << 14;
   send->bits3.ud |= 0 << 13; /* no return data */
   send->bits3.ud |= 1 << 12; /* SIMD8 mode */
   send->bits3.ud |= BRW_AOP_ADD << 8;
   send->bits3.ud |= surf_index << 0;
@


1.7
log
@Upate to libGL 7.11.2

Tested by jsg@@, matthieu@@ and ajacoutot@@, ok mattieu@@
@
text
@d37 1
a37 1
#include "../glsl/ralloc.h"
d61 1
a61 1
static void
d66 5
a70 2
   struct intel_context *intel = &p->brw->intel;
   if (intel->gen < 6)
d87 10
a96 2
   struct intel_context *intel = &p->brw->intel;
   if (intel->gen == 7 && reg->file == BRW_MESSAGE_REGISTER_FILE) {
d98 1
a98 1
      reg->nr += 111;
d103 3
a105 3
static void brw_set_dest(struct brw_compile *p,
			 struct brw_instruction *insn,
			 struct brw_reg dest)
d129 4
a132 1
	 /* even ignored in da16, still need to set as '01' */
d238 3
a240 3
static void brw_set_src0(struct brw_compile *p,
			 struct brw_instruction *insn,
			 struct brw_reg reg)
d242 2
d249 11
d336 2
a337 1
   assert(reg.nr < 128);
d401 20
d422 21
a445 2
				  GLuint msg_length,
				  GLuint response_length,
d448 1
a448 2
				  GLboolean low_precision,
				  GLboolean saturate,
d452 27
a478 2
   struct intel_context *intel = &brw->intel;
   brw_set_src1(p, insn, brw_imm_d(0));
d480 3
a482 1
   if (intel->gen == 5) {
d486 1
a486 1
      insn->bits3.math_gen5.saturate = saturate;
a488 6
      insn->bits3.math_gen5.header_present = 0;
      insn->bits3.math_gen5.response_length = response_length;
      insn->bits3.math_gen5.msg_length = msg_length;
      insn->bits3.math_gen5.end_of_thread = 0;
      insn->bits2.send_gen5.sfid = BRW_MESSAGE_TARGET_MATH;
      insn->bits2.send_gen5.end_of_thread = 0;
d493 1
a493 1
      insn->bits3.math.saturate = saturate;
a494 4
      insn->bits3.math.response_length = response_length;
      insn->bits3.math.msg_length = msg_length;
      insn->bits3.math.msg_target = BRW_MESSAGE_TARGET_MATH;
      insn->bits3.math.end_of_thread = 0;
d496 1
d502 1
a502 1
				    GLboolean allocate,
d504 1
a504 1
				    GLboolean end_of_thread)
d506 2
a507 4
   struct brw_context *brw = p->brw;
   struct intel_context *intel = &brw->intel;
   brw_set_src1(p, insn, brw_imm_d(0));

a513 10
   insn->bits3.urb_gen5.header_present = 1;
   insn->bits3.urb_gen5.response_length = response_length; /* may be 1 or 0 */
   insn->bits3.urb_gen5.msg_length = 1;
   insn->bits3.urb_gen5.end_of_thread = end_of_thread;
   if (intel->gen >= 6) {
      insn->header.destreg__conditionalmod = BRW_MESSAGE_TARGET_URB;
   } else {
      insn->bits2.send_gen5.sfid = BRW_MESSAGE_TARGET_URB;
      insn->bits2.send_gen5.end_of_thread = end_of_thread;
   }
d518 2
a519 2
				 GLboolean allocate,
				 GLboolean used,
d522 2
a523 2
				 GLboolean end_of_thread,
				 GLboolean complete,
a527 2
   struct intel_context *intel = &brw->intel;
   brw_set_src1(p, insn, brw_imm_d(0));
d529 3
a531 1
   if (intel->gen == 7) {
d539 1
a539 6
      insn->bits3.urb_gen7.header_present = 1;
      insn->bits3.urb_gen7.response_length = response_length;
      insn->bits3.urb_gen7.msg_length = msg_length;
      insn->bits3.urb_gen7.end_of_thread = end_of_thread;
      insn->header.destreg__conditionalmod = BRW_MESSAGE_TARGET_URB;
   } else if (intel->gen >= 5) {
a545 14
      insn->bits3.urb_gen5.header_present = 1;
      insn->bits3.urb_gen5.response_length = response_length;
      insn->bits3.urb_gen5.msg_length = msg_length;
      insn->bits3.urb_gen5.end_of_thread = end_of_thread;
      if (intel->gen >= 6) {
	 /* For SNB, the SFID bits moved to the condmod bits, and
	  * EOT stayed in bits3 above.  Does the EOT bit setting
	  * below on Ironlake even do anything?
	  */
	 insn->header.destreg__conditionalmod = BRW_MESSAGE_TARGET_URB;
      } else {
	 insn->bits2.send_gen5.sfid = BRW_MESSAGE_TARGET_URB;
	 insn->bits2.send_gen5.end_of_thread = end_of_thread;
      }
a552 4
      insn->bits3.urb.response_length = response_length;
      insn->bits3.urb.msg_length = msg_length;
      insn->bits3.urb.msg_target = BRW_MESSAGE_TARGET_URB;
      insn->bits3.urb.end_of_thread = end_of_thread;
d556 12
a567 11
static void brw_set_dp_write_message( struct brw_compile *p,
				      struct brw_instruction *insn,
				      GLuint binding_table_index,
				      GLuint msg_control,
				      GLuint msg_type,
				      GLuint msg_length,
				      GLboolean header_present,
				      GLuint pixel_scoreboard_clear,
				      GLuint response_length,
				      GLuint end_of_thread,
				      GLuint send_commit_msg)
d570 1
a570 2
   struct intel_context *intel = &brw->intel;
   brw_set_src1(p, insn, brw_imm_ud(0));
d572 17
a588 1
   if (intel->gen >= 7) {
d591 1
a591 1
      insn->bits3.gen7_dp.pixel_scoreboard_clear = pixel_scoreboard_clear;
d593 1
a593 8
      insn->bits3.gen7_dp.header_present = header_present;
      insn->bits3.gen7_dp.response_length = response_length;
      insn->bits3.gen7_dp.msg_length = msg_length;
      insn->bits3.gen7_dp.end_of_thread = end_of_thread;

      /* We always use the render cache for write messages */
      insn->header.destreg__conditionalmod = GEN6_MESSAGE_TARGET_DP_RENDER_CACHE;
   } else if (intel->gen == 6) {
d596 1
a596 1
      insn->bits3.gen6_dp.pixel_scoreboard_clear = pixel_scoreboard_clear;
d599 1
a599 8
      insn->bits3.gen6_dp.header_present = header_present;
      insn->bits3.gen6_dp.response_length = response_length;
      insn->bits3.gen6_dp.msg_length = msg_length;
      insn->bits3.gen6_dp.end_of_thread = end_of_thread;

      /* We always use the render cache for write messages */
      insn->header.destreg__conditionalmod = GEN6_MESSAGE_TARGET_DP_RENDER_CACHE;
   } else if (intel->gen == 5) {
d602 1
a602 1
      insn->bits3.dp_write_gen5.pixel_scoreboard_clear = pixel_scoreboard_clear;
a604 6
      insn->bits3.dp_write_gen5.header_present = header_present;
      insn->bits3.dp_write_gen5.response_length = response_length;
      insn->bits3.dp_write_gen5.msg_length = msg_length;
      insn->bits3.dp_write_gen5.end_of_thread = end_of_thread;
      insn->bits2.send_gen5.sfid = BRW_MESSAGE_TARGET_DATAPORT_WRITE;
      insn->bits2.send_gen5.end_of_thread = end_of_thread;
d608 1
a608 1
      insn->bits3.dp_write.pixel_scoreboard_clear = pixel_scoreboard_clear;
a610 4
      insn->bits3.dp_write.response_length = response_length;
      insn->bits3.dp_write.msg_length = msg_length;
      insn->bits3.dp_write.msg_target = BRW_MESSAGE_TARGET_DATAPORT_WRITE;
      insn->bits3.dp_write.end_of_thread = end_of_thread;
d614 1
a614 1
static void
d622 1
d626 15
a640 2
   struct intel_context *intel = &brw->intel;
   brw_set_src1(p, insn, brw_imm_d(0));
d642 1
a642 1
   if (intel->gen >= 7) {
d645 1
a645 1
      insn->bits3.gen7_dp.pixel_scoreboard_clear = 0;
d647 1
a647 13
      insn->bits3.gen7_dp.header_present = 1;
      insn->bits3.gen7_dp.response_length = response_length;
      insn->bits3.gen7_dp.msg_length = msg_length;
      insn->bits3.gen7_dp.end_of_thread = 0;
      insn->header.destreg__conditionalmod = GEN6_MESSAGE_TARGET_DP_CONST_CACHE;
   } else if (intel->gen == 6) {
      uint32_t target_function;

      if (target_cache == BRW_DATAPORT_READ_TARGET_DATA_CACHE)
	 target_function = GEN6_MESSAGE_TARGET_DP_SAMPLER_CACHE;
      else
	 target_function = GEN6_MESSAGE_TARGET_DP_RENDER_CACHE;

d650 1
a650 1
      insn->bits3.gen6_dp.pixel_scoreboard_clear = 0;
d653 1
a653 6
      insn->bits3.gen6_dp.header_present = 1;
      insn->bits3.gen6_dp.response_length = response_length;
      insn->bits3.gen6_dp.msg_length = msg_length;
      insn->bits3.gen6_dp.end_of_thread = 0;
      insn->header.destreg__conditionalmod = target_function;
   } else if (intel->gen == 5) {
d658 1
a658 8
      insn->bits3.dp_read_gen5.header_present = 1;
      insn->bits3.dp_read_gen5.response_length = response_length;
      insn->bits3.dp_read_gen5.msg_length = msg_length;
      insn->bits3.dp_read_gen5.pad1 = 0;
      insn->bits3.dp_read_gen5.end_of_thread = 0;
      insn->bits2.send_gen5.sfid = BRW_MESSAGE_TARGET_DATAPORT_READ;
      insn->bits2.send_gen5.end_of_thread = 0;
   } else if (intel->is_g4x) {
a662 5
      insn->bits3.dp_read_g4x.response_length = response_length;  /*16:19*/
      insn->bits3.dp_read_g4x.msg_length = msg_length;  /*20:23*/
      insn->bits3.dp_read_g4x.msg_target = BRW_MESSAGE_TARGET_DATAPORT_READ; /*24:27*/
      insn->bits3.dp_read_g4x.pad1 = 0;
      insn->bits3.dp_read_g4x.end_of_thread = 0;
a667 5
      insn->bits3.dp_read.response_length = response_length;  /*16:19*/
      insn->bits3.dp_read.msg_length = msg_length;  /*20:23*/
      insn->bits3.dp_read.msg_target = BRW_MESSAGE_TARGET_DATAPORT_READ; /*24:27*/
      insn->bits3.dp_read.pad1 = 0;  /*28:30*/
      insn->bits3.dp_read.end_of_thread = 0;  /*31*/
d671 11
a681 10
static void brw_set_sampler_message(struct brw_compile *p,
                                    struct brw_instruction *insn,
                                    GLuint binding_table_index,
                                    GLuint sampler,
                                    GLuint msg_type,
                                    GLuint response_length,
                                    GLuint msg_length,
                                    GLboolean eot,
                                    GLuint header_present,
                                    GLuint simd_mode)
a683 3
   struct intel_context *intel = &brw->intel;
   assert(eot == 0);
   brw_set_src1(p, insn, brw_imm_d(0));
d685 4
a688 1
   if (intel->gen >= 7) {
d693 1
a693 6
      insn->bits3.sampler_gen7.header_present = header_present;
      insn->bits3.sampler_gen7.response_length = response_length;
      insn->bits3.sampler_gen7.msg_length = msg_length;
      insn->bits3.sampler_gen7.end_of_thread = eot;
      insn->header.destreg__conditionalmod = BRW_MESSAGE_TARGET_SAMPLER;
   } else if (intel->gen >= 5) {
d698 1
a698 11
      insn->bits3.sampler_gen5.header_present = header_present;
      insn->bits3.sampler_gen5.response_length = response_length;
      insn->bits3.sampler_gen5.msg_length = msg_length;
      insn->bits3.sampler_gen5.end_of_thread = eot;
      if (intel->gen >= 6)
	  insn->header.destreg__conditionalmod = BRW_MESSAGE_TARGET_SAMPLER;
      else {
	  insn->bits2.send_gen5.sfid = BRW_MESSAGE_TARGET_SAMPLER;
	  insn->bits2.send_gen5.end_of_thread = eot;
      }
   } else if (intel->is_g4x) {
a701 4
      insn->bits3.sampler_g4x.response_length = response_length;
      insn->bits3.sampler_g4x.msg_length = msg_length;
      insn->bits3.sampler_g4x.end_of_thread = eot;
      insn->bits3.sampler_g4x.msg_target = BRW_MESSAGE_TARGET_SAMPLER;
d706 1
a706 5
      insn->bits3.sampler.return_format = BRW_SAMPLER_RETURN_FORMAT_FLOAT32;
      insn->bits3.sampler.response_length = response_length;
      insn->bits3.sampler.msg_length = msg_length;
      insn->bits3.sampler.end_of_thread = eot;
      insn->bits3.sampler.msg_target = BRW_MESSAGE_TARGET_SAMPLER;
d711 3
a713 3

static struct brw_instruction *next_insn( struct brw_compile *p, 
					  GLuint opcode )
d717 9
a725 1
   assert(p->nr_insn + 1 < BRW_EU_MAX_INSN);
d727 1
a742 1

d767 95
d883 24
d924 1
a924 1
   if (p->brw->intel.gen < 6) {						      \
d944 2
d957 9
a965 1

d994 22
d1087 1
a1087 1
   p->if_stack[p->if_stack_depth] = inst;
d1092 1
a1092 1
      p->if_stack = reralloc(p->mem_ctx, p->if_stack, struct brw_instruction *,
d1097 29
d1142 1
a1142 1
   struct intel_context *intel = &p->brw->intel;
d1149 1
a1149 1
   if (intel->gen < 6) {
d1153 1
a1153 1
   } else if (intel->gen == 6) {
d1156 2
a1157 2
      brw_set_src0(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
      brw_set_src1(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
d1159 2
a1160 2
      brw_set_dest(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
      brw_set_src0(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
d1176 1
d1261 16
a1276 1
   struct intel_context *intel = &p->brw->intel;
a1277 1
   assert(!p->single_program_flow);
d1286 1
a1286 1
   if (intel->gen >= 5)
d1294 1
a1294 1
      if (intel->gen < 6) {
d1302 1
a1302 1
      } else if (intel->gen == 6) {
d1313 1
a1313 1
      if (intel->gen < 6) {
d1317 1
a1317 1
      } else if (intel->gen == 6) {
d1322 1
a1322 1
      if (intel->gen < 6) {
d1329 1
a1329 1
      } else if (intel->gen == 6) {
d1345 1
a1345 1
   struct intel_context *intel = &p->brw->intel;
d1350 1
a1350 1
   if (intel->gen < 6) {
d1354 1
a1354 1
   } else if (intel->gen == 6) {
d1378 2
a1379 2
   struct intel_context *intel = &p->brw->intel;
   struct brw_instruction *insn;
d1382 25
d1409 5
a1413 4
   p->if_stack_depth--;
   if (p->if_stack[p->if_stack_depth]->header.opcode == BRW_OPCODE_ELSE) {
      else_inst = p->if_stack[p->if_stack_depth];
      p->if_stack_depth--;
d1415 1
a1415 1
   if_inst = p->if_stack[p->if_stack_depth];
d1417 1
a1417 1
   if (p->single_program_flow) {
d1423 1
a1423 3
   insn = next_insn(p, BRW_OPCODE_ENDIF);

   if (intel->gen < 6) {
d1427 1
a1427 1
   } else if (intel->gen == 6) {
d1442 1
a1442 1
   if (intel->gen < 6) {
d1446 1
a1446 1
   } else if (intel->gen == 6) {
d1454 1
a1454 1
struct brw_instruction *brw_BREAK(struct brw_compile *p, int pop_count)
d1456 1
a1456 1
   struct intel_context *intel = &p->brw->intel;
d1460 1
a1460 1
   if (intel->gen >= 6) {
d1469 1
a1469 1
      insn->bits3.if_else.pop_count = pop_count;
d1477 1
a1477 2
struct brw_instruction *gen6_CONT(struct brw_compile *p,
				  struct brw_instruction *do_insn)
d1493 1
a1493 1
struct brw_instruction *brw_CONT(struct brw_compile *p, int pop_count)
d1504 19
a1522 1
   insn->bits3.if_else.pop_count = pop_count;
d1544 1
a1544 1
   struct intel_context *intel = &p->brw->intel;
d1546 2
a1547 1
   if (intel->gen >= 6 || p->single_program_flow) {
d1552 2
d1570 29
d1600 1
a1600 3

struct brw_instruction *brw_WHILE(struct brw_compile *p, 
                                  struct brw_instruction *do_insn)
d1602 2
a1603 2
   struct intel_context *intel = &p->brw->intel;
   struct brw_instruction *insn;
d1606 1
a1606 1
   if (intel->gen >= 5)
d1609 1
a1609 1
   if (intel->gen >= 7) {
d1611 1
d1618 2
a1619 3
      insn->header.execution_size = do_insn->header.execution_size;
      assert(insn->header.execution_size == BRW_EXECUTE_8);
   } else if (intel->gen == 6) {
d1621 1
d1628 1
a1628 2
      insn->header.execution_size = do_insn->header.execution_size;
      assert(insn->header.execution_size == BRW_EXECUTE_8);
d1632 1
d1640 1
d1652 2
d1659 2
d1667 1
a1667 2
void brw_land_fwd_jump(struct brw_compile *p, 
		       struct brw_instruction *jmp_insn)
d1669 2
a1670 2
   struct intel_context *intel = &p->brw->intel;
   struct brw_instruction *landing = &p->store[p->nr_insn];
d1673 1
a1673 1
   if (intel->gen >= 5)
d1679 1
a1679 1
   jmp_insn->bits3.ud = jmpi * ((landing - jmp_insn) - 1);
d1694 1
d1714 14
a1754 1
	       GLuint saturate,
d1760 1
a1760 1
   struct intel_context *intel = &p->brw->intel;
d1762 1
a1762 1
   if (intel->gen >= 6) {
d1765 2
a1766 1
      assert(dest.file == BRW_GENERAL_REGISTER_FILE);
d1770 2
a1771 1
      assert(src.hstride == BRW_HORIZONTAL_STRIDE_1);
d1773 5
a1777 3
      /* Source modifiers are ignored for extended math instructions. */
      assert(!src.negate);
      assert(!src.abs);
d1779 5
a1783 2
      if (function != BRW_MATH_FUNCTION_INT_DIV_QUOTIENT &&
	  function != BRW_MATH_FUNCTION_INT_DIV_QUOTIENT_AND_REMAINDER) {
a1790 1
      insn->header.saturate = saturate;
d1797 1
a1797 2
      GLuint msg_length = (function == BRW_MATH_FUNCTION_POW) ? 2 : 1;
      GLuint response_length = (function == BRW_MATH_FUNCTION_SINCOS) ? 2 : 1;
a1807 1
			   msg_length, response_length,
d1809 1
a1809 1
			   BRW_MATH_INTEGER_UNSIGNED,
a1810 1
			   saturate,
d1823 1
a1823 1
   struct intel_context *intel = &p->brw->intel;
d1826 2
a1827 5
   assert(intel->gen >= 6);
   (void) intel;


   assert(dest.file == BRW_GENERAL_REGISTER_FILE);
d1832 4
a1835 2
   assert(src0.hstride == BRW_HORIZONTAL_STRIDE_1);
   assert(src1.hstride == BRW_HORIZONTAL_STRIDE_1);
d1837 6
a1842 2
   if (function != BRW_MATH_FUNCTION_INT_DIV_QUOTIENT &&
       function != BRW_MATH_FUNCTION_INT_DIV_QUOTIENT_AND_REMAINDER) {
d1847 7
a1853 5
   /* Source modifiers are ignored for extended math instructions. */
   assert(!src0.negate);
   assert(!src0.abs);
   assert(!src1.negate);
   assert(!src1.abs);
a1864 76
/**
 * Extended math function, float[16].
 * Use 2 send instructions.
 */
void brw_math_16( struct brw_compile *p,
		  struct brw_reg dest,
		  GLuint function,
		  GLuint saturate,
		  GLuint msg_reg_nr,
		  struct brw_reg src,
		  GLuint precision )
{
   struct intel_context *intel = &p->brw->intel;
   struct brw_instruction *insn;
   GLuint msg_length = (function == BRW_MATH_FUNCTION_POW) ? 2 : 1; 
   GLuint response_length = (function == BRW_MATH_FUNCTION_SINCOS) ? 2 : 1; 

   if (intel->gen >= 6) {
      insn = next_insn(p, BRW_OPCODE_MATH);

      /* Math is the same ISA format as other opcodes, except that CondModifier
       * becomes FC[3:0] and ThreadCtrl becomes FC[5:4].
       */
      insn->header.destreg__conditionalmod = function;
      insn->header.saturate = saturate;

      /* Source modifiers are ignored for extended math instructions. */
      assert(!src.negate);
      assert(!src.abs);

      brw_set_dest(p, insn, dest);
      brw_set_src0(p, insn, src);
      brw_set_src1(p, insn, brw_null_reg());
      return;
   }

   /* First instruction:
    */
   brw_push_insn_state(p);
   brw_set_predicate_control_flag_value(p, 0xff);
   brw_set_compression_control(p, BRW_COMPRESSION_NONE);

   insn = next_insn(p, BRW_OPCODE_SEND);
   insn->header.destreg__conditionalmod = msg_reg_nr;

   brw_set_dest(p, insn, dest);
   brw_set_src0(p, insn, src);
   brw_set_math_message(p,
			insn, 
			msg_length, response_length, 
			function,
			BRW_MATH_INTEGER_UNSIGNED,
			precision,
			saturate,
			BRW_MATH_DATA_VECTOR);

   /* Second instruction:
    */
   insn = next_insn(p, BRW_OPCODE_SEND);
   insn->header.compression_control = BRW_COMPRESSION_2NDHALF;
   insn->header.destreg__conditionalmod = msg_reg_nr+1;

   brw_set_dest(p, insn, offset(dest,1));
   brw_set_src0(p, insn, src);
   brw_set_math_message(p, 
			insn, 
			msg_length, response_length, 
			function,
			BRW_MATH_INTEGER_UNSIGNED,
			precision,
			saturate,
			BRW_MATH_DATA_VECTOR);

   brw_pop_insn_state(p);
}

d1878 1
a1878 1
   struct intel_context *intel = &p->brw->intel;
d1882 1
a1882 1
   if (intel->gen >= 6)
d1941 1
a1941 1
      if (intel->gen >= 6) {
d1950 1
a1950 1
      if (intel->gen >= 6) {
d1956 1
a1956 1
      if (intel->gen >= 6)
d1967 2
a1968 2
			       GL_TRUE, /* header_present */
			       0, /* pixel scoreboard */
d1990 1
a1990 1
   struct intel_context *intel = &p->brw->intel;
d1994 1
a1994 1
   if (intel->gen >= 6)
d2033 1
a2033 1
      if (intel->gen >= 6) {
d2046 1
d2062 1
a2062 1
   struct intel_context *intel = &p->brw->intel;
d2065 1
a2065 1
   if (intel->gen >= 6)
d2091 1
a2091 1
   if (intel->gen >= 6) {
d2104 1
a2109 150
/**
 * Read a set of dwords from the data port Data Cache (const buffer).
 *
 * Location (in buffer) appears as UD offsets in the register after
 * the provided mrf header reg.
 */
void brw_dword_scattered_read(struct brw_compile *p,
			      struct brw_reg dest,
			      struct brw_reg mrf,
			      uint32_t bind_table_index)
{
   mrf = retype(mrf, BRW_REGISTER_TYPE_UD);

   brw_push_insn_state(p);
   brw_set_predicate_control(p, BRW_PREDICATE_NONE);
   brw_set_compression_control(p, BRW_COMPRESSION_NONE);
   brw_set_mask_control(p, BRW_MASK_DISABLE);
   brw_MOV(p, mrf, retype(brw_vec8_grf(0, 0), BRW_REGISTER_TYPE_UD));
   brw_pop_insn_state(p);

   struct brw_instruction *insn = next_insn(p, BRW_OPCODE_SEND);
   insn->header.destreg__conditionalmod = mrf.nr;

   /* cast dest to a uword[8] vector */
   dest = retype(vec8(dest), BRW_REGISTER_TYPE_UW);

   brw_set_dest(p, insn, dest);
   brw_set_src0(p, insn, brw_null_reg());

   brw_set_dp_read_message(p,
			   insn,
			   bind_table_index,
			   BRW_DATAPORT_DWORD_SCATTERED_BLOCK_8DWORDS,
			   BRW_DATAPORT_READ_MESSAGE_DWORD_SCATTERED_READ,
			   BRW_DATAPORT_READ_TARGET_DATA_CACHE,
			   2, /* msg_length */
			   1); /* response_length */
}



/**
 * Read float[4] constant(s) from VS constant buffer.
 * For relative addressing, two float[4] constants will be read into 'dest'.
 * Otherwise, one float[4] constant will be read into the lower half of 'dest'.
 */
void brw_dp_READ_4_vs(struct brw_compile *p,
                      struct brw_reg dest,
                      GLuint location,
                      GLuint bind_table_index)
{
   struct intel_context *intel = &p->brw->intel;
   struct brw_instruction *insn;
   GLuint msg_reg_nr = 1;

   if (intel->gen >= 6)
      location /= 16;

   /* Setup MRF[1] with location/offset into const buffer */
   brw_push_insn_state(p);
   brw_set_access_mode(p, BRW_ALIGN_1);
   brw_set_compression_control(p, BRW_COMPRESSION_NONE);
   brw_set_mask_control(p, BRW_MASK_DISABLE);
   brw_set_predicate_control(p, BRW_PREDICATE_NONE);
   brw_MOV(p, retype(brw_vec1_reg(BRW_MESSAGE_REGISTER_FILE, msg_reg_nr, 2),
		     BRW_REGISTER_TYPE_UD),
	   brw_imm_ud(location));
   brw_pop_insn_state(p);

   insn = next_insn(p, BRW_OPCODE_SEND);

   insn->header.predicate_control = BRW_PREDICATE_NONE;
   insn->header.compression_control = BRW_COMPRESSION_NONE;
   insn->header.destreg__conditionalmod = msg_reg_nr;
   insn->header.mask_control = BRW_MASK_DISABLE;

   brw_set_dest(p, insn, dest);
   if (intel->gen >= 6) {
      brw_set_src0(p, insn, brw_message_reg(msg_reg_nr));
   } else {
      brw_set_src0(p, insn, brw_null_reg());
   }

   brw_set_dp_read_message(p,
			   insn,
			   bind_table_index,
			   0,
			   BRW_DATAPORT_READ_MESSAGE_OWORD_BLOCK_READ, /* msg_type */
			   BRW_DATAPORT_READ_TARGET_DATA_CACHE,
			   1, /* msg_length */
			   1); /* response_length (1 Oword) */
}

/**
 * Read a float[4] constant per vertex from VS constant buffer, with
 * relative addressing.
 */
void brw_dp_READ_4_vs_relative(struct brw_compile *p,
			       struct brw_reg dest,
			       struct brw_reg addr_reg,
			       GLuint offset,
			       GLuint bind_table_index)
{
   struct intel_context *intel = &p->brw->intel;
   struct brw_reg src = brw_vec8_grf(0, 0);
   int msg_type;

   /* Setup MRF[1] with offset into const buffer */
   brw_push_insn_state(p);
   brw_set_access_mode(p, BRW_ALIGN_1);
   brw_set_compression_control(p, BRW_COMPRESSION_NONE);
   brw_set_mask_control(p, BRW_MASK_DISABLE);
   brw_set_predicate_control(p, BRW_PREDICATE_NONE);

   /* M1.0 is block offset 0, M1.4 is block offset 1, all other
    * fields ignored.
    */
   brw_ADD(p, retype(brw_message_reg(1), BRW_REGISTER_TYPE_D),
	   addr_reg, brw_imm_d(offset));
   brw_pop_insn_state(p);

   gen6_resolve_implied_move(p, &src, 0);
   struct brw_instruction *insn = next_insn(p, BRW_OPCODE_SEND);

   insn->header.predicate_control = BRW_PREDICATE_NONE;
   insn->header.compression_control = BRW_COMPRESSION_NONE;
   insn->header.destreg__conditionalmod = 0;
   insn->header.mask_control = BRW_MASK_DISABLE;

   brw_set_dest(p, insn, dest);
   brw_set_src0(p, insn, src);

   if (intel->gen >= 6)
      msg_type = GEN6_DATAPORT_READ_MESSAGE_OWORD_DUAL_BLOCK_READ;
   else if (intel->gen == 5 || intel->is_g4x)
      msg_type = G45_DATAPORT_READ_MESSAGE_OWORD_DUAL_BLOCK_READ;
   else
      msg_type = BRW_DATAPORT_READ_MESSAGE_OWORD_DUAL_BLOCK_READ;

   brw_set_dp_read_message(p,
			   insn,
			   bind_table_index,
			   BRW_DATAPORT_OWORD_DUAL_BLOCK_1OWORD,
			   msg_type,
			   BRW_DATAPORT_READ_TARGET_DATA_CACHE,
			   2, /* msg_length */
			   1); /* response_length */
}


d2115 1
d2119 2
a2120 2
                  GLboolean eot,
                  GLboolean header_present)
d2122 1
a2122 1
   struct intel_context *intel = &p->brw->intel;
d2124 1
a2124 1
   GLuint msg_control, msg_type;
d2132 1
a2132 1
   if (intel->gen >= 6 && binding_table_index == 0) {
d2141 1
a2141 1
   if (intel->gen >= 6) {
a2151 5
   if (dispatch_width == 16)
      msg_control = BRW_DATAPORT_RENDER_TARGET_WRITE_SIMD16_SINGLE_SOURCE;
   else
      msg_control = BRW_DATAPORT_RENDER_TARGET_WRITE_SIMD8_SINGLE_SOURCE_SUBSPAN01;

d2161 1
a2161 1
			    1,	/* pixel scoreboard */
a2178 1
		GLuint writemask,
a2181 1
		GLboolean eot,
d2183 2
a2184 1
		GLuint simd_mode)
d2186 2
a2187 2
   struct intel_context *intel = &p->brw->intel;
   GLboolean need_stall = 0;
d2189 1
a2189 37
   if (writemask == 0) {
      /*printf("%s: zero writemask??\n", __FUNCTION__); */
      return;
   }
   
   /* Hardware doesn't do destination dependency checking on send
    * instructions properly.  Add a workaround which generates the
    * dependency by other means.  In practice it seems like this bug
    * only crops up for texture samples, and only where registers are
    * written by the send and then written again later without being
    * read in between.  Luckily for us, we already track that
    * information and use it to modify the writemask for the
    * instruction, so that is a guide for whether a workaround is
    * needed.
    */
   if (writemask != WRITEMASK_XYZW) {
      GLuint dst_offset = 0;
      GLuint i, newmask = 0, len = 0;

      for (i = 0; i < 4; i++) {
	 if (writemask & (1<<i))
	    break;
	 dst_offset += 2;
      }
      for (; i < 4; i++) {
	 if (!(writemask & (1<<i)))
	    break;
	 newmask |= 1<<i;
	 len++;
      }

      if (newmask != writemask) {
	 need_stall = 1;
         /* printf("need stall %x %x\n", newmask , writemask); */
      }
      else {
	 GLboolean dispatch_16 = GL_FALSE;
d2191 5
a2195 66
	 struct brw_reg m1 = brw_message_reg(msg_reg_nr);

	 guess_execution_size(p, p->current, dest);
	 if (p->current->header.execution_size == BRW_EXECUTE_16)
	    dispatch_16 = GL_TRUE;

	 newmask = ~newmask & WRITEMASK_XYZW;

	 brw_push_insn_state(p);

	 brw_set_compression_control(p, BRW_COMPRESSION_NONE);
	 brw_set_mask_control(p, BRW_MASK_DISABLE);

	 brw_MOV(p, retype(m1, BRW_REGISTER_TYPE_UD),
		 retype(brw_vec8_grf(0,0), BRW_REGISTER_TYPE_UD));
  	 brw_MOV(p, get_element_ud(m1, 2), brw_imm_ud(newmask << 12)); 

	 brw_pop_insn_state(p);

  	 src0 = retype(brw_null_reg(), BRW_REGISTER_TYPE_UW); 
	 dest = offset(dest, dst_offset);

	 /* For 16-wide dispatch, masked channels are skipped in the
	  * response.  For 8-wide, masked channels still take up slots,
	  * and are just not written to.
	  */
	 if (dispatch_16)
	    response_length = len * 2;
      }
   }

   {
      struct brw_instruction *insn;
   
      gen6_resolve_implied_move(p, &src0, msg_reg_nr);

      insn = next_insn(p, BRW_OPCODE_SEND);
      insn->header.predicate_control = 0; /* XXX */
      insn->header.compression_control = BRW_COMPRESSION_NONE;
      if (intel->gen < 6)
	  insn->header.destreg__conditionalmod = msg_reg_nr;

      brw_set_dest(p, insn, dest);
      brw_set_src0(p, insn, src0);
      brw_set_sampler_message(p, insn,
			      binding_table_index,
			      sampler,
			      msg_type,
			      response_length, 
			      msg_length,
			      eot,
			      header_present,
			      simd_mode);
   }

   if (need_stall) {
      struct brw_reg reg = vec8(offset(dest, response_length-1));

      /*  mov (8) r9.0<1>:f    r9.0<8;8,1>:f    { Align1 }
       */
      brw_push_insn_state(p);
      brw_set_compression_control(p, BRW_COMPRESSION_NONE);
      brw_MOV(p, retype(reg, BRW_REGISTER_TYPE_UD),
	      retype(reg, BRW_REGISTER_TYPE_UD));
      brw_pop_insn_state(p);
   }
d2197 11
d2218 2
a2219 2
		   GLboolean allocate,
		   GLboolean used,
d2222 2
a2223 2
		   GLboolean eot,
		   GLboolean writes_complete,
d2227 1
a2227 1
   struct intel_context *intel = &p->brw->intel;
d2232 1
a2232 1
   if (intel->gen == 7) {
d2234 3
d2241 1
d2252 1
a2252 1
   if (intel->gen < 6)
d2268 11
d2282 1
d2284 2
a2285 2
   for (ip = start + 1; ip < p->nr_insn; ip++) {
      struct brw_instruction *insn = &p->store[ip];
d2291 1
d2295 2
a2296 2
   assert(!"not reached");
   return start + 1;
d2306 1
a2306 1
   struct intel_context *intel = &p->brw->intel;
d2308 2
a2309 1
   int br = 2;
d2311 5
a2315 2
   for (ip = start + 1; ip < p->nr_insn; ip++) {
      struct brw_instruction *insn = &p->store[ip];
d2318 1
a2318 1
	 int jip = intel->gen == 6 ? insn->bits1.branch_gen6.jump_count
d2320 1
a2320 1
	 if (ip + jip / br < start)
d2325 1
a2325 1
   return start + 1;
d2329 1
a2329 1
 * BREAK and CONT instructions to their correct locations.
d2334 1
a2334 1
   struct intel_context *intel = &p->brw->intel;
d2336 2
a2337 1
   int br = 2;
d2339 1
a2339 1
   if (intel->gen < 6)
d2342 10
a2351 2
   for (ip = 0; ip < p->nr_insn; ip++) {
      struct brw_instruction *insn = &p->store[ip];
d2353 1
d2356 2
a2357 1
	 insn->bits3.break_cont.jip = br * (brw_find_next_block_end(p, ip) - ip);
d2360 2
a2361 1
	    br * (brw_find_loop_end(p, ip) - ip + (intel->gen == 6 ? 1 : 0));
d2364 4
a2367 2
	 insn->bits3.break_cont.jip = br * (brw_find_next_block_end(p, ip) - ip);
	 insn->bits3.break_cont.uip = br * (brw_find_loop_end(p, ip) - ip);
d2372 28
d2408 1
a2408 1
		   GLboolean allocate,
d2410 1
a2410 1
		   GLboolean eot)
d2412 1
a2412 1
   struct intel_context *intel = &p->brw->intel;
d2422 1
a2422 1
   if (intel->gen < 6)
d2430 98
@


1.6
log
@Merge Mesa 7.10.3
@
text
@d37 1
a37 2


d67 1
a67 1
   if (intel->gen != 6)
d81 10
d100 2
d224 3
a226 2
static void brw_set_src0( struct brw_instruction *insn,
                          struct brw_reg reg )
d231 2
d303 3
a305 2
void brw_set_src1( struct brw_instruction *insn,
                   struct brw_reg reg )
d311 2
d375 1
a375 1
static void brw_set_math_message( struct brw_context *brw,
d385 1
d387 1
a387 1
   brw_set_src1(insn, brw_imm_d(0));
d390 22
a411 22
       insn->bits3.math_gen5.function = function;
       insn->bits3.math_gen5.int_type = integer_type;
       insn->bits3.math_gen5.precision = low_precision;
       insn->bits3.math_gen5.saturate = saturate;
       insn->bits3.math_gen5.data_type = dataType;
       insn->bits3.math_gen5.snapshot = 0;
       insn->bits3.math_gen5.header_present = 0;
       insn->bits3.math_gen5.response_length = response_length;
       insn->bits3.math_gen5.msg_length = msg_length;
       insn->bits3.math_gen5.end_of_thread = 0;
       insn->bits2.send_gen5.sfid = BRW_MESSAGE_TARGET_MATH;
       insn->bits2.send_gen5.end_of_thread = 0;
   } else {
       insn->bits3.math.function = function;
       insn->bits3.math.int_type = integer_type;
       insn->bits3.math.precision = low_precision;
       insn->bits3.math.saturate = saturate;
       insn->bits3.math.data_type = dataType;
       insn->bits3.math.response_length = response_length;
       insn->bits3.math.msg_length = msg_length;
       insn->bits3.math.msg_target = BRW_MESSAGE_TARGET_MATH;
       insn->bits3.math.end_of_thread = 0;
d416 1
a416 1
static void brw_set_ff_sync_message(struct brw_context *brw,
d422 3
a424 2
	struct intel_context *intel = &brw->intel;
	brw_set_src1(insn, brw_imm_d(0));
d426 16
a441 16
	insn->bits3.urb_gen5.opcode = 1; /* FF_SYNC */
	insn->bits3.urb_gen5.offset = 0; /* Not used by FF_SYNC */
	insn->bits3.urb_gen5.swizzle_control = 0; /* Not used by FF_SYNC */
	insn->bits3.urb_gen5.allocate = allocate;
	insn->bits3.urb_gen5.used = 0; /* Not used by FF_SYNC */
	insn->bits3.urb_gen5.complete = 0; /* Not used by FF_SYNC */
	insn->bits3.urb_gen5.header_present = 1;
	insn->bits3.urb_gen5.response_length = response_length; /* may be 1 or 0 */
	insn->bits3.urb_gen5.msg_length = 1;
	insn->bits3.urb_gen5.end_of_thread = end_of_thread;
	if (intel->gen >= 6) {
	   insn->header.destreg__conditionalmod = BRW_MESSAGE_TARGET_URB;
	} else {
	   insn->bits2.send_gen5.sfid = BRW_MESSAGE_TARGET_URB;
	   insn->bits2.send_gen5.end_of_thread = end_of_thread;
	}
d444 1
a444 1
static void brw_set_urb_message( struct brw_context *brw,
d455 3
a457 2
    struct intel_context *intel = &brw->intel;
    brw_set_src1(insn, brw_imm_d(0));
d459 46
a504 33
    if (intel->gen >= 5) {
        insn->bits3.urb_gen5.opcode = 0;	/* ? */
        insn->bits3.urb_gen5.offset = offset;
        insn->bits3.urb_gen5.swizzle_control = swizzle_control;
        insn->bits3.urb_gen5.allocate = allocate;
        insn->bits3.urb_gen5.used = used;	/* ? */
        insn->bits3.urb_gen5.complete = complete;
        insn->bits3.urb_gen5.header_present = 1;
        insn->bits3.urb_gen5.response_length = response_length;
        insn->bits3.urb_gen5.msg_length = msg_length;
        insn->bits3.urb_gen5.end_of_thread = end_of_thread;
	if (intel->gen >= 6) {
	   /* For SNB, the SFID bits moved to the condmod bits, and
	    * EOT stayed in bits3 above.  Does the EOT bit setting
	    * below on Ironlake even do anything?
	    */
	   insn->header.destreg__conditionalmod = BRW_MESSAGE_TARGET_URB;
	} else {
	   insn->bits2.send_gen5.sfid = BRW_MESSAGE_TARGET_URB;
	   insn->bits2.send_gen5.end_of_thread = end_of_thread;
	}
    } else {
        insn->bits3.urb.opcode = 0;	/* ? */
        insn->bits3.urb.offset = offset;
        insn->bits3.urb.swizzle_control = swizzle_control;
        insn->bits3.urb.allocate = allocate;
        insn->bits3.urb.used = used;	/* ? */
        insn->bits3.urb.complete = complete;
        insn->bits3.urb.response_length = response_length;
        insn->bits3.urb.msg_length = msg_length;
        insn->bits3.urb.msg_target = BRW_MESSAGE_TARGET_URB;
        insn->bits3.urb.end_of_thread = end_of_thread;
    }
d507 1
a507 1
static void brw_set_dp_write_message( struct brw_context *brw,
d519 1
d521 24
a544 1
   brw_set_src1(insn, brw_imm_ud(0));
d546 2
a547 14
   if (intel->gen >= 6) {
       insn->bits3.dp_render_cache.binding_table_index = binding_table_index;
       insn->bits3.dp_render_cache.msg_control = msg_control;
       insn->bits3.dp_render_cache.pixel_scoreboard_clear = pixel_scoreboard_clear;
       insn->bits3.dp_render_cache.msg_type = msg_type;
       insn->bits3.dp_render_cache.send_commit_msg = send_commit_msg;
       insn->bits3.dp_render_cache.header_present = header_present;
       insn->bits3.dp_render_cache.response_length = response_length;
       insn->bits3.dp_render_cache.msg_length = msg_length;
       insn->bits3.dp_render_cache.end_of_thread = end_of_thread;
       insn->header.destreg__conditionalmod = BRW_MESSAGE_TARGET_DATAPORT_WRITE;
	/* XXX really need below? */
       insn->bits2.send_gen5.sfid = BRW_MESSAGE_TARGET_DATAPORT_WRITE;
       insn->bits2.send_gen5.end_of_thread = end_of_thread;
d549 21
a569 21
       insn->bits3.dp_write_gen5.binding_table_index = binding_table_index;
       insn->bits3.dp_write_gen5.msg_control = msg_control;
       insn->bits3.dp_write_gen5.pixel_scoreboard_clear = pixel_scoreboard_clear;
       insn->bits3.dp_write_gen5.msg_type = msg_type;
       insn->bits3.dp_write_gen5.send_commit_msg = send_commit_msg;
       insn->bits3.dp_write_gen5.header_present = header_present;
       insn->bits3.dp_write_gen5.response_length = response_length;
       insn->bits3.dp_write_gen5.msg_length = msg_length;
       insn->bits3.dp_write_gen5.end_of_thread = end_of_thread;
       insn->bits2.send_gen5.sfid = BRW_MESSAGE_TARGET_DATAPORT_WRITE;
       insn->bits2.send_gen5.end_of_thread = end_of_thread;
   } else {
       insn->bits3.dp_write.binding_table_index = binding_table_index;
       insn->bits3.dp_write.msg_control = msg_control;
       insn->bits3.dp_write.pixel_scoreboard_clear = pixel_scoreboard_clear;
       insn->bits3.dp_write.msg_type = msg_type;
       insn->bits3.dp_write.send_commit_msg = send_commit_msg;
       insn->bits3.dp_write.response_length = response_length;
       insn->bits3.dp_write.msg_length = msg_length;
       insn->bits3.dp_write.msg_target = BRW_MESSAGE_TARGET_DATAPORT_WRITE;
       insn->bits3.dp_write.end_of_thread = end_of_thread;
d574 1
a574 1
brw_set_dp_read_message(struct brw_context *brw,
d583 1
d585 19
a603 1
   brw_set_src1(insn, brw_imm_d(0));
d605 10
a614 14
   if (intel->gen >= 6) {
       insn->bits3.dp_render_cache.binding_table_index = binding_table_index;
       insn->bits3.dp_render_cache.msg_control = msg_control;
       insn->bits3.dp_render_cache.pixel_scoreboard_clear = 0;
       insn->bits3.dp_render_cache.msg_type = msg_type;
       insn->bits3.dp_render_cache.send_commit_msg = 0;
       insn->bits3.dp_render_cache.header_present = 1;
       insn->bits3.dp_render_cache.response_length = response_length;
       insn->bits3.dp_render_cache.msg_length = msg_length;
       insn->bits3.dp_render_cache.end_of_thread = 0;
       insn->header.destreg__conditionalmod = BRW_MESSAGE_TARGET_DATAPORT_READ;
	/* XXX really need below? */
       insn->bits2.send_gen5.sfid = BRW_MESSAGE_TARGET_DATAPORT_READ;
       insn->bits2.send_gen5.end_of_thread = 0;
d616 11
a626 11
       insn->bits3.dp_read_gen5.binding_table_index = binding_table_index;
       insn->bits3.dp_read_gen5.msg_control = msg_control;
       insn->bits3.dp_read_gen5.msg_type = msg_type;
       insn->bits3.dp_read_gen5.target_cache = target_cache;
       insn->bits3.dp_read_gen5.header_present = 1;
       insn->bits3.dp_read_gen5.response_length = response_length;
       insn->bits3.dp_read_gen5.msg_length = msg_length;
       insn->bits3.dp_read_gen5.pad1 = 0;
       insn->bits3.dp_read_gen5.end_of_thread = 0;
       insn->bits2.send_gen5.sfid = BRW_MESSAGE_TARGET_DATAPORT_READ;
       insn->bits2.send_gen5.end_of_thread = 0;
d628 19
a646 19
       insn->bits3.dp_read_g4x.binding_table_index = binding_table_index; /*0:7*/
       insn->bits3.dp_read_g4x.msg_control = msg_control;  /*8:10*/
       insn->bits3.dp_read_g4x.msg_type = msg_type;  /*11:13*/
       insn->bits3.dp_read_g4x.target_cache = target_cache;  /*14:15*/
       insn->bits3.dp_read_g4x.response_length = response_length;  /*16:19*/
       insn->bits3.dp_read_g4x.msg_length = msg_length;  /*20:23*/
       insn->bits3.dp_read_g4x.msg_target = BRW_MESSAGE_TARGET_DATAPORT_READ; /*24:27*/
       insn->bits3.dp_read_g4x.pad1 = 0;
       insn->bits3.dp_read_g4x.end_of_thread = 0;
   } else {
       insn->bits3.dp_read.binding_table_index = binding_table_index; /*0:7*/
       insn->bits3.dp_read.msg_control = msg_control;  /*8:11*/
       insn->bits3.dp_read.msg_type = msg_type;  /*12:13*/
       insn->bits3.dp_read.target_cache = target_cache;  /*14:15*/
       insn->bits3.dp_read.response_length = response_length;  /*16:19*/
       insn->bits3.dp_read.msg_length = msg_length;  /*20:23*/
       insn->bits3.dp_read.msg_target = BRW_MESSAGE_TARGET_DATAPORT_READ; /*24:27*/
       insn->bits3.dp_read.pad1 = 0;  /*28:30*/
       insn->bits3.dp_read.end_of_thread = 0;  /*31*/
d650 1
a650 1
static void brw_set_sampler_message(struct brw_context *brw,
d661 1
d664 1
a664 1
   brw_set_src1(insn, brw_imm_d(0));
d666 11
a676 1
   if (intel->gen >= 5) {
d743 1
a743 1
   brw_set_src0(insn, src);   
d755 2
a756 2
   brw_set_src0(insn, src0);
   brw_set_src1(insn, src1);
d785 2
d796 1
a796 2
   brw_set_src0(rnd, src);						      \
   rnd->header.destreg__conditionalmod = 0x7; /* turn on round-increments */  \
d798 6
a803 2
   add = brw_ADD(p, dest, dest, brw_imm_f(1.0f));			      \
   add->header.predicate_control = BRW_PREDICATE_NORMAL;		      \
d898 2
a899 2
   brw_set_src0(insn, retype(brw_vec4_grf(0,0), BRW_REGISTER_TYPE_UD));
   brw_set_src1(insn, brw_imm_ud(0x0));
d926 13
a950 2
 *
 * No attempt is made to deal with stack overflow (14 elements?).
d952 2
a953 1
struct brw_instruction *brw_IF(struct brw_compile *p, GLuint execute_size)
d958 1
a958 8
   if (p->single_program_flow) {
      assert(execute_size == BRW_EXECUTE_1);

      insn = next_insn(p, BRW_OPCODE_ADD);
      insn->header.predicate_inverse = 1;
   } else {
      insn = next_insn(p, BRW_OPCODE_IF);
   }
d964 3
a966 3
      brw_set_src0(insn, brw_ip_reg());
      brw_set_src1(insn, brw_imm_d(0x0));
   } else {
d969 8
a976 2
      brw_set_src0(insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
      brw_set_src1(insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
d984 1
a984 1
       insn->header.thread_control = BRW_THREAD_SWITCH;
d988 1
d992 3
d996 2
a997 2
brw_IF_gen6(struct brw_compile *p, uint32_t conditional,
	    struct brw_reg src0, struct brw_reg src1)
d1004 5
a1008 1
   insn->header.execution_size = BRW_EXECUTE_8;
d1010 2
a1011 2
   brw_set_src0(insn, src0);
   brw_set_src1(insn, src1);
d1018 1
a1018 1
       insn->header.thread_control = BRW_THREAD_SWITCH;
d1020 1
d1024 48
a1071 2
struct brw_instruction *brw_ELSE(struct brw_compile *p, 
				 struct brw_instruction *if_insn)
a1073 2
   struct brw_instruction *insn;
   GLuint br = 1;
d1075 9
a1083 2
   /* jump count is for 64bit data chunk each, so one 128bit
      instruction requires 2 chunks. */
d1087 20
a1106 2
   if (p->single_program_flow) {
      insn = next_insn(p, BRW_OPCODE_ADD);
d1108 29
a1136 1
      insn = next_insn(p, BRW_OPCODE_ELSE);
d1138 9
d1150 3
a1152 3
      brw_set_src0(insn, brw_ip_reg());
      brw_set_src1(insn, brw_imm_d(0x0));
   } else {
d1155 8
a1162 2
      brw_set_src0(insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
      brw_set_src1(insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
a1165 1
   insn->header.execution_size = if_insn->header.execution_size;
d1168 1
a1168 10
       insn->header.thread_control = BRW_THREAD_SWITCH;

   /* Patch the if instruction to point at this instruction.
    */
   if (p->single_program_flow) {
      assert(if_insn->header.opcode == BRW_OPCODE_ADD);

      if_insn->bits3.ud = (insn - if_insn + 1) * 16;
   } else {
      assert(if_insn->header.opcode == BRW_OPCODE_IF);
d1170 1
a1170 10
      if (intel->gen < 6) {
	 if_insn->bits3.if_else.jump_count = br * (insn - if_insn);
	 if_insn->bits3.if_else.pop_count = 0;
	 if_insn->bits3.if_else.pad0 = 0;
      } else {
	 if_insn->bits1.branch_gen6.jump_count = br * (insn - if_insn + 1);
      }
   }

   return insn;
d1173 2
a1174 2
void brw_ENDIF(struct brw_compile *p, 
	       struct brw_instruction *patch_insn)
d1177 11
a1187 1
   GLuint br = 1;
a1188 3
   if (intel->gen >= 5)
      br = 2; 
 
d1190 4
a1193 5
      /* In single program flow mode, there's no need to execute an ENDIF,
       * since we don't need to do any stack operations, and if we're executing
       * currently, we want to just continue executing.
       */
      struct brw_instruction *next = &p->store[p->nr_insn];
d1195 1
a1195 1
      assert(patch_insn->header.opcode == BRW_OPCODE_ADD);
d1197 8
a1204 1
      patch_insn->bits3.ud = (next - patch_insn) * 16;
d1206 4
a1209 1
      struct brw_instruction *insn = next_insn(p, BRW_OPCODE_ENDIF);
d1211 3
a1213 9
      if (intel->gen < 6) {
	 brw_set_dest(p, insn, retype(brw_vec4_grf(0,0), BRW_REGISTER_TYPE_UD));
	 brw_set_src0(insn, retype(brw_vec4_grf(0,0), BRW_REGISTER_TYPE_UD));
	 brw_set_src1(insn, brw_imm_d(0x0));
      } else {
	 brw_set_dest(p, insn, brw_imm_w(0));
	 brw_set_src0(insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
	 brw_set_src1(insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
      }
d1215 9
a1223 50
      insn->header.compression_control = BRW_COMPRESSION_NONE;
      insn->header.execution_size = patch_insn->header.execution_size;
      insn->header.mask_control = BRW_MASK_ENABLE;
      insn->header.thread_control = BRW_THREAD_SWITCH;

      if (intel->gen < 6)
	 assert(patch_insn->bits3.if_else.jump_count == 0);
      else
	 assert(patch_insn->bits1.branch_gen6.jump_count == 0);

      /* Patch the if or else instructions to point at this or the next
       * instruction respectively.
       */
      if (patch_insn->header.opcode == BRW_OPCODE_IF) {
	 if (intel->gen < 6) {
	    /* Turn it into an IFF, which means no mask stack operations for
	     * all-false and jumping past the ENDIF.
	     */
	    patch_insn->header.opcode = BRW_OPCODE_IFF;
	    patch_insn->bits3.if_else.jump_count = br * (insn - patch_insn + 1);
	    patch_insn->bits3.if_else.pop_count = 0;
	    patch_insn->bits3.if_else.pad0 = 0;
	 } else {
	    /* As of gen6, there is no IFF and IF must point to the ENDIF. */
	    patch_insn->bits1.branch_gen6.jump_count = br * (insn - patch_insn);
	 }
      } else {
	 assert(patch_insn->header.opcode == BRW_OPCODE_ELSE);
	 if (intel->gen < 6) {
	    /* BRW_OPCODE_ELSE pre-gen6 should point just past the
	     * matching ENDIF.
	     */
	    patch_insn->bits3.if_else.jump_count = br * (insn - patch_insn + 1);
	    patch_insn->bits3.if_else.pop_count = 1;
	    patch_insn->bits3.if_else.pad0 = 0;
	 } else {
	    /* BRW_OPCODE_ELSE on gen6 should point to the matching ENDIF. */
	    patch_insn->bits1.branch_gen6.jump_count = br * (insn - patch_insn);
	 }
      }

      /* Also pop item off the stack in the endif instruction:
       */
      if (intel->gen < 6) {
	 insn->bits3.if_else.jump_count = 0;
	 insn->bits3.if_else.pop_count = 1;
	 insn->bits3.if_else.pad0 = 0;
      } else {
	 insn->bits1.branch_gen6.jump_count = 2;
      }
d1225 1
d1236 2
a1237 2
      brw_set_src0(insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
      brw_set_src1(insn, brw_imm_d(0x0));
d1240 2
a1241 2
      brw_set_src0(insn, brw_ip_reg());
      brw_set_src1(insn, brw_imm_d(0x0));
d1251 2
a1252 2
struct brw_instruction *brw_CONT_gen6(struct brw_compile *p,
				      struct brw_instruction *do_insn)
a1254 1
   int br = 2;
d1258 1
a1258 1
   brw_set_src0(insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
d1260 2
a1261 4
   brw_set_src0(insn, brw_ip_reg());
   brw_set_src1(insn, brw_imm_d(0x0));

   insn->bits3.break_cont.uip = br * (do_insn - insn);
d1273 2
a1274 2
   brw_set_src0(insn, brw_ip_reg());
   brw_set_src1(insn, brw_imm_d(0x0));
d1311 2
a1312 2
      brw_set_src0(insn, brw_null_reg());
      brw_set_src1(insn, brw_null_reg());
d1336 11
a1346 1
   if (intel->gen >= 6) {
d1351 2
a1352 2
      brw_set_src0(insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
      brw_set_src1(insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
d1361 2
a1362 2
	 brw_set_src0(insn, brw_ip_reg());
	 brw_set_src1(insn, brw_imm_d((do_insn - insn) * 16));
d1370 2
a1371 2
	 brw_set_src0(insn, brw_ip_reg());
	 brw_set_src1(insn, brw_imm_d(0));
d1396 1
a1396 1
       jmpi = 2;
d1420 2
a1421 2
   brw_set_src0(insn, src0);
   brw_set_src1(insn, src1);
d1445 2
a1446 2
   brw_set_src0(insn, src);
   brw_set_src1(insn, brw_null_reg());
d1495 2
a1496 2
      brw_set_src0(insn, src);
      brw_set_src1(insn, brw_null_reg());
d1508 2
a1509 2
      brw_set_src0(insn, src);
      brw_set_math_message(p->brw,
d1561 2
a1562 2
   brw_set_src0(insn, src0);
   brw_set_src1(insn, src1);
d1596 2
a1597 2
      brw_set_src0(insn, src);
      brw_set_src1(insn, brw_null_reg());
d1611 2
a1612 2
   brw_set_src0(insn, src);
   brw_set_math_message(p->brw,
d1628 2
a1629 2
   brw_set_src0(insn, src);
   brw_set_math_message(p->brw, 
d1655 1
a1655 1
   uint32_t msg_control;
d1658 3
d1726 10
a1735 1
      brw_set_src0(insn, brw_null_reg());
d1737 1
a1737 1
      brw_set_dp_write_message(p->brw,
d1741 1
a1741 1
			       BRW_DATAPORT_WRITE_MESSAGE_OWORD_BLOCK_WRITE, /* msg_type */
d1766 1
d1770 3
d1809 5
a1813 1
      brw_set_src0(insn, brw_null_reg());
d1815 1
a1815 1
      brw_set_dp_read_message(p->brw,
d1820 1
a1820 1
			      1, /* target cache (render/scratch) */
d1867 1
a1867 1
      brw_set_src0(insn, mrf);
d1869 1
a1869 1
      brw_set_src0(insn, brw_null_reg());
d1872 1
a1872 1
   brw_set_dp_read_message(p->brw,
d1877 1
a1877 1
			   0, /* source cache = data cache */
d1911 1
a1911 1
   brw_set_src0(insn, brw_null_reg());
d1913 1
a1913 1
   brw_set_dp_read_message(p->brw,
d1918 1
a1918 1
			   0, /* source cache = data cache */
d1962 1
a1962 1
      brw_set_src0(insn, brw_message_reg(msg_reg_nr));
d1964 1
a1964 1
      brw_set_src0(insn, brw_null_reg());
d1967 1
a1967 1
   brw_set_dp_read_message(p->brw,
d1972 1
a1972 1
			   0, /* source cache = data cache */
d2014 1
a2014 1
   brw_set_src0(insn, src);
d2016 1
a2016 1
   if (intel->gen == 6)
d2023 1
a2023 1
   brw_set_dp_read_message(p->brw,
d2028 1
a2028 1
			   0, /* source cache = data cache */
a2036 1
                  struct brw_reg dest,
d2048 6
d2065 2
a2066 2
       /* headerless version, just submit color payload */
       src0 = brw_message_reg(msg_reg_nr);
d2068 1
a2068 1
       msg_type = BRW_DATAPORT_WRITE_MESSAGE_RENDER_TARGET_WRITE_GEN6;
d2081 2
a2082 2
   brw_set_src0(insn, src0);
   brw_set_dp_write_message(p->brw,
d2199 2
a2200 2
      brw_set_src0(insn, src0);
      brw_set_sampler_message(p->brw, insn,
d2247 8
d2260 2
a2261 2
   brw_set_src0(insn, src0);
   brw_set_src1(insn, brw_imm_d(0));
d2266 1
a2266 1
   brw_set_urb_message(p->brw,
d2304 1
d2312 3
a2314 1
	 if (ip + insn->bits1.branch_gen6.jump_count / br < start)
d2341 3
a2343 1
	 insn->bits3.break_cont.uip = br * (brw_find_loop_end(p, ip) - ip + 1);
a2345 3
	 /* JIP is set at CONTINUE emit time, since that's when we
	  * know where the start of the loop is.
	  */
d2347 2
d2371 2
a2372 2
   brw_set_src0(insn, src0);
   brw_set_src1(insn, brw_imm_d(0));
d2375 1
a2375 1
       insn->header.destreg__conditionalmod = msg_reg_nr;
d2377 1
a2377 1
   brw_set_ff_sync_message(p->brw,
@


1.5
log
@Update to Mesa 7.8.1. Tested on a bulk ports build by naddy@@, ok oga@@.
@
text
@d44 3
a46 2
static void guess_execution_size( struct brw_instruction *insn,
				  struct brw_reg reg )
d48 1
a48 2
   if (reg.width == BRW_WIDTH_8 && 
       insn->header.compression_control == BRW_COMPRESSION_COMPRESSED) 
d55 31
a85 2
static void brw_set_dest( struct brw_instruction *insn,
			  struct brw_reg dest )
d107 2
d124 2
d132 79
a210 1
   guess_execution_size(insn, dest);
d219 2
d296 2
d398 5
a402 10
static void brw_set_ff_sync_message( struct brw_context *brw,
				 struct brw_instruction *insn,
				 GLboolean allocate,
				 GLboolean used,
				 GLuint msg_length,
				 GLuint response_length,
				 GLboolean end_of_thread,
				 GLboolean complete,
				 GLuint offset,
				 GLuint swizzle_control )
d404 1
d407 3
a409 3
	insn->bits3.urb_gen5.opcode = 1;
	insn->bits3.urb_gen5.offset = offset;
	insn->bits3.urb_gen5.swizzle_control = swizzle_control;
d411 2
a412 2
	insn->bits3.urb_gen5.used = used;
	insn->bits3.urb_gen5.complete = complete;
d414 2
a415 2
	insn->bits3.urb_gen5.response_length = response_length;
	insn->bits3.urb_gen5.msg_length = msg_length;
d417 6
a422 2
	insn->bits2.send_gen5.sfid = BRW_MESSAGE_TARGET_URB;
	insn->bits2.send_gen5.end_of_thread = end_of_thread;
d480 1
d483 2
a484 1
				      GLuint end_of_thread )
d487 1
a487 1
   brw_set_src1(insn, brw_imm_d(0));
d489 15
a503 1
   if (intel->gen == 5) {
d508 2
a509 2
       insn->bits3.dp_write_gen5.send_commit_msg = 0;
       insn->bits3.dp_write_gen5.header_present = 1;
d520 1
a520 1
       insn->bits3.dp_write.send_commit_msg = 0;
d528 9
a536 9
static void brw_set_dp_read_message( struct brw_context *brw,
				      struct brw_instruction *insn,
				      GLuint binding_table_index,
				      GLuint msg_control,
				      GLuint msg_type,
				      GLuint target_cache,
				      GLuint msg_length,
				      GLuint response_length,
				      GLuint end_of_thread )
d541 15
a555 1
   if (intel->gen == 5) {
d564 1
a564 1
       insn->bits3.dp_read_gen5.end_of_thread = end_of_thread;
d566 11
a576 1
       insn->bits2.send_gen5.end_of_thread = end_of_thread;
d586 1
a586 1
       insn->bits3.dp_read.end_of_thread = end_of_thread;  /*31*/
d605 1
a605 1
   if (intel->gen == 5) {
d614 6
a619 2
      insn->bits2.send_gen5.sfid = BRW_MESSAGE_TARGET_SAMPLER;
      insn->bits2.send_gen5.end_of_thread = eot;
d671 1
a671 1
   brw_set_dest(insn, dest);
d683 1
a683 1
   brw_set_dest(insn, dest);
d710 20
a741 2
ALU2(ADD)
ALU2(MUL)
a743 1
ALU1(RNDZ)
d752 42
d795 6
d802 14
d821 1
a821 1
   brw_set_dest(insn, retype(brw_vec4_grf(0,0), BRW_REGISTER_TYPE_UD));
d867 1
d881 10
a890 3
   brw_set_dest(insn, brw_ip_reg());
   brw_set_src0(insn, brw_ip_reg());
   brw_set_src1(insn, brw_imm_d(0x0));
d904 23
d935 3
a937 1
   if (intel->gen == 5)
d946 10
a955 3
   brw_set_dest(insn, brw_ip_reg());
   brw_set_src0(insn, brw_ip_reg());
   brw_set_src1(insn, brw_imm_d(0x0));
d972 7
a978 3
      if_insn->bits3.if_else.jump_count = br * (insn - if_insn);
      if_insn->bits3.if_else.pop_count = 0;
      if_insn->bits3.if_else.pad0 = 0;
d990 1
a990 1
   if (intel->gen == 5)
d1006 9
a1014 3
      brw_set_dest(insn, retype(brw_vec4_grf(0,0), BRW_REGISTER_TYPE_UD));
      brw_set_src0(insn, retype(brw_vec4_grf(0,0), BRW_REGISTER_TYPE_UD));
      brw_set_src1(insn, brw_imm_d(0x0));
d1021 4
a1024 1
      assert(patch_insn->bits3.if_else.jump_count == 0);
d1030 12
a1041 10
	 /* Automagically turn it into an IFF:
	  */
	 patch_insn->header.opcode = BRW_OPCODE_IFF;
	 patch_insn->bits3.if_else.jump_count = br * (insn - patch_insn + 1);
	 patch_insn->bits3.if_else.pop_count = 0;
	 patch_insn->bits3.if_else.pad0 = 0;
      } else if (patch_insn->header.opcode == BRW_OPCODE_ELSE) {
	 patch_insn->bits3.if_else.jump_count = br * (insn - patch_insn + 1);
	 patch_insn->bits3.if_else.pop_count = 1;
	 patch_insn->bits3.if_else.pad0 = 0;
d1043 12
a1054 1
	 assert(0);
d1059 24
a1082 2
      insn->bits3.if_else.jump_count = 0;
      insn->bits3.if_else.pop_count = 1;
d1084 1
d1086 4
d1092 2
a1093 1
struct brw_instruction *brw_BREAK(struct brw_compile *p)
d1096 6
a1101 2
   insn = next_insn(p, BRW_OPCODE_BREAK);
   brw_set_dest(insn, brw_ip_reg());
d1104 3
a1108 2
   /* insn->header.mask_control = BRW_MASK_DISABLE; */
   insn->bits3.if_else.pad0 = 0;
d1112 1
a1112 1
struct brw_instruction *brw_CONT(struct brw_compile *p)
d1116 1
a1116 1
   brw_set_dest(insn, brw_ip_reg());
d1123 1
d1128 14
d1145 3
a1147 1
   if (p->single_program_flow) {
d1154 1
a1154 1
      brw_set_dest(insn, brw_null_reg());
d1177 1
a1177 1
   if (intel->gen == 5)
d1180 1
a1180 3
   if (p->single_program_flow)
      insn = next_insn(p, BRW_OPCODE_ADD);
   else
d1183 4
a1186 3
   brw_set_dest(insn, brw_ip_reg());
   brw_set_src0(insn, brw_ip_reg());
   brw_set_src1(insn, brw_imm_d(0x0));
d1188 5
a1192 1
   insn->header.compression_control = BRW_COMPRESSION_NONE;
d1194 6
a1199 2
   if (p->single_program_flow) {
      insn->header.execution_size = BRW_EXECUTE_1;
d1201 1
a1201 3
      insn->bits3.d = (do_insn - insn) * 16;
   } else {
      insn->header.execution_size = do_insn->header.execution_size;
d1203 9
a1211 4
      assert(do_insn->header.opcode == BRW_OPCODE_DO);
      insn->bits3.if_else.jump_count = br * (do_insn - insn + 1);
      insn->bits3.if_else.pop_count = 0;
      insn->bits3.if_else.pad0 = 0;
d1213 2
a1215 4
/*    insn->header.mask_control = BRW_MASK_ENABLE; */

   /* insn->header.mask_control = BRW_MASK_DISABLE; */
   p->current->header.predicate_control = BRW_PREDICATE_NONE;   
d1229 1
a1229 1
   if (intel->gen == 5)
d1253 1
a1253 1
   brw_set_dest(insn, dest);
d1271 14
d1307 15
d1326 1
d1328 1
a1328 1
      brw_set_dest(insn, dest);
d1341 1
a1341 1
      brw_set_dest(insn, dest);
d1354 45
d1411 1
d1416 19
d1444 1
a1444 1
   brw_set_dest(insn, dest);
d1461 1
a1461 1
   brw_set_dest(insn, offset(dest,1));
d1477 10
a1486 7
 * Write block of 16 dwords/floats to the data port Render Cache scratch buffer.
 * Scratch offset should be a multiple of 64.
 * Used for register spilling.
 */
void brw_dp_WRITE_16( struct brw_compile *p,
		      struct brw_reg src,
		      GLuint scratch_offset )
d1488 19
a1506 1
   GLuint msg_reg_nr = 1;
d1512 2
d1516 4
a1519 2
	      retype(brw_vec1_grf(0, 2), BRW_REGISTER_TYPE_D),
	      brw_imm_d(scratch_offset));
d1525 1
a1525 2
      GLuint msg_length = 3;
      struct brw_reg dest = retype(brw_null_reg(), BRW_REGISTER_TYPE_UW);
d1527 31
a1557 7
   
      insn->header.predicate_control = 0; /* XXX */
      insn->header.compression_control = BRW_COMPRESSION_NONE; 
      insn->header.destreg__conditionalmod = msg_reg_nr;
  
      brw_set_dest(insn, dest);
      brw_set_src0(insn, src);
d1562 1
a1562 1
			       BRW_DATAPORT_OWORD_BLOCK_4_OWORDS, /* msg_control */
d1564 2
a1565 1
			       msg_length,
d1567 3
a1569 2
			       0, /* response_length */
			       0); /* eot */
d1575 27
a1601 9
 * Read block of 16 dwords/floats from the data port Render Cache scratch buffer.
 * Scratch offset should be a multiple of 64.
 * Used for register spilling.
 */
void brw_dp_READ_16( struct brw_compile *p,
		      struct brw_reg dest,
		      GLuint scratch_offset )
{
   GLuint msg_reg_nr = 1;
d1607 2
d1611 4
a1614 2
	      retype(brw_vec1_grf(0, 2), BRW_REGISTER_TYPE_D),
	      brw_imm_d(scratch_offset));
d1621 7
a1627 7
   
      insn->header.predicate_control = 0; /* XXX */
      insn->header.compression_control = BRW_COMPRESSION_NONE; 
      insn->header.destreg__conditionalmod = msg_reg_nr;
  
      brw_set_dest(insn, dest);	/* UW? */
      brw_set_src0(insn, retype(brw_vec8_grf(0, 0), BRW_REGISTER_TYPE_UW));
d1632 1
a1632 1
			      3,  /* msg_control (3 means 4 Owords) */
d1636 1
a1636 2
			      2, /* response_length */
			      0); /* eot */
a1639 1

a1643 1
 * If relAddr is true, we'll do an indirect fetch using the address register.
d1645 5
a1649 5
void brw_dp_READ_4( struct brw_compile *p,
                    struct brw_reg dest,
                    GLboolean relAddr,
                    GLuint location,
                    GLuint bind_table_index )
d1651 27
a1677 8
   /* XXX: relAddr not implemented */
   GLuint msg_reg_nr = 1;
   {
      struct brw_reg b;
      brw_push_insn_state(p);
      brw_set_predicate_control(p, BRW_PREDICATE_NONE);
      brw_set_compression_control(p, BRW_COMPRESSION_NONE);
      brw_set_mask_control(p, BRW_MASK_DISABLE);
d1679 5
a1683 8
   /* Setup MRF[1] with location/offset into const buffer */
      b = brw_message_reg(msg_reg_nr);
      b = retype(b, BRW_REGISTER_TYPE_UD);
      /* XXX I think we're setting all the dwords of MRF[1] to 'location'.
       * when the docs say only dword[2] should be set.  Hmmm.  But it works.
       */
      brw_MOV(p, b, brw_imm_ud(location));
      brw_pop_insn_state(p);
d1686 37
a1722 10
   {
      struct brw_instruction *insn = next_insn(p, BRW_OPCODE_SEND);
   
      insn->header.predicate_control = BRW_PREDICATE_NONE;
      insn->header.compression_control = BRW_COMPRESSION_NONE; 
      insn->header.destreg__conditionalmod = msg_reg_nr;
      insn->header.mask_control = BRW_MASK_DISABLE;
  
      /* cast dest to a uword[8] vector */
      dest = retype(vec8(dest), BRW_REGISTER_TYPE_UW);
d1724 2
a1725 2
      brw_set_dest(insn, dest);
      brw_set_src0(insn, brw_null_reg());
d1727 8
a1734 10
      brw_set_dp_read_message(p->brw,
			      insn,
			      bind_table_index,
			      0,  /* msg_control (0 means 1 Oword) */
			      BRW_DATAPORT_READ_MESSAGE_OWORD_BLOCK_READ, /* msg_type */
			      0, /* source cache = data cache */
			      1, /* msg_length */
			      1, /* response_length (1 Oword) */
			      0); /* eot */
   }
d1738 1
a1745 3
                      GLuint oword,
                      GLboolean relAddr,
                      struct brw_reg addrReg,
d1749 2
d1753 2
a1754 5
   assert(oword < 2);
   /*
   printf("vs const read msg, location %u, msg_reg_nr %d\n",
          location, msg_reg_nr);
   */
d1757 9
a1765 2
   {
      struct brw_reg b;
d1767 1
a1767 5
      brw_push_insn_state(p);
      brw_set_compression_control(p, BRW_COMPRESSION_NONE);
      brw_set_mask_control(p, BRW_MASK_DISABLE);
      brw_set_predicate_control(p, BRW_PREDICATE_NONE);
      /*brw_set_access_mode(p, BRW_ALIGN_16);*/
d1769 4
a1772 12
      /* XXX I think we're setting all the dwords of MRF[1] to 'location'.
       * when the docs say only dword[2] should be set.  Hmmm.  But it works.
       */
      b = brw_message_reg(msg_reg_nr);
      b = retype(b, BRW_REGISTER_TYPE_UD);
      /*b = get_element_ud(b, 2);*/
      if (relAddr) {
         brw_ADD(p, b, addrReg, brw_imm_ud(location));
      }
      else {
         brw_MOV(p, b, brw_imm_ud(location));
      }
d1774 5
a1778 1
      brw_pop_insn_state(p);
d1781 55
a1835 11
   {
      struct brw_instruction *insn = next_insn(p, BRW_OPCODE_SEND);
   
      insn->header.predicate_control = BRW_PREDICATE_NONE;
      insn->header.compression_control = BRW_COMPRESSION_NONE; 
      insn->header.destreg__conditionalmod = msg_reg_nr;
      insn->header.mask_control = BRW_MASK_DISABLE;
      /*insn->header.access_mode = BRW_ALIGN_16;*/
  
      brw_set_dest(insn, dest);
      brw_set_src0(insn, brw_null_reg());
d1837 8
a1844 10
      brw_set_dp_read_message(p->brw,
			      insn,
			      bind_table_index,
			      oword,  /* 0 = lower Oword, 1 = upper Oword */
			      BRW_DATAPORT_READ_MESSAGE_OWORD_BLOCK_READ, /* msg_type */
			      0, /* source cache = data cache */
			      1, /* msg_length */
			      1, /* response_length (1 Oword) */
			      0); /* eot */
   }
d1850 1
d1857 2
a1858 1
                  GLboolean eot)
d1860 30
a1889 7
   struct brw_instruction *insn = next_insn(p, BRW_OPCODE_SEND);
   
   insn->header.predicate_control = 0; /* XXX */
   insn->header.compression_control = BRW_COMPRESSION_NONE; 
   insn->header.destreg__conditionalmod = msg_reg_nr;
  
   brw_set_dest(insn, dest);
d1894 2
a1895 2
			    BRW_DATAPORT_RENDER_TARGET_WRITE_SIMD16_SINGLE_SOURCE, /* msg_control */
			    BRW_DATAPORT_WRITE_MESSAGE_RENDER_TARGET_WRITE, /* msg_type */
d1897 1
d1899 3
a1901 2
			    response_length, 
			    eot);
d1924 1
d1967 1
a1967 1
	 guess_execution_size(p->current, dest);
d1978 2
a1979 1
	 brw_MOV(p, m1, brw_vec8_grf(0,0));	 
d1997 1
a1997 1
      struct brw_instruction *insn = next_insn(p, BRW_OPCODE_SEND);
d1999 3
d2004 2
a2005 1
      insn->header.destreg__conditionalmod = msg_reg_nr;
d2007 1
a2007 1
      brw_set_dest(insn, dest);
d2027 2
a2028 1
      brw_MOV(p, reg, reg);	      
d2054 1
a2054 7
   /* Sandybridge doesn't have the implied move for SENDs,
    * and the first message register index comes from src0.
    */
   if (intel->gen >= 6) {
      brw_MOV(p, brw_message_reg(msg_reg_nr), src0);
      src0 = brw_message_reg(msg_reg_nr);
   }
d2060 1
a2060 1
   brw_set_dest(insn, dest);
d2079 74
a2157 2
		   GLboolean used,
		   GLuint msg_length,
d2159 1
a2159 4
		   GLboolean eot,
		   GLboolean writes_complete,
		   GLuint offset,
		   GLuint swizzle)
d2161 2
a2162 1
   struct brw_instruction *insn = next_insn(p, BRW_OPCODE_SEND);
d2164 1
a2164 1
   assert(msg_length < 16);
d2166 2
a2167 1
   brw_set_dest(insn, dest);
d2171 2
a2172 1
   insn->header.destreg__conditionalmod = msg_reg_nr;
d2175 4
a2178 9
		       insn,
		       allocate,
		       used,
		       msg_length,
		       response_length, 
		       eot, 
		       writes_complete, 
		       offset,
		       swizzle);
@


1.4
log
@Update to Mesa 7.4.2. Tested by oga@@, ckuethe@@ and naddy@@.
@
text
@d58 4
d103 1
a103 1
		      struct brw_reg reg )
d105 2
a106 1
   assert(reg.file != BRW_MESSAGE_REGISTER_FILE);
d177 1
a177 1
			  struct brw_reg reg )
d181 2
d200 1
a200 1
      //assert (reg.file == BRW_GENERAL_REGISTER_FILE);
d243 2
a244 1
static void brw_set_math_message( struct brw_instruction *insn,
d253 1
d256 52
a307 9
   insn->bits3.math.function = function;
   insn->bits3.math.int_type = integer_type;
   insn->bits3.math.precision = low_precision;
   insn->bits3.math.saturate = saturate;
   insn->bits3.math.data_type = dataType;
   insn->bits3.math.response_length = response_length;
   insn->bits3.math.msg_length = msg_length;
   insn->bits3.math.msg_target = BRW_MESSAGE_TARGET_MATH;
   insn->bits3.math.end_of_thread = 0;
d310 2
a311 1
static void brw_set_urb_message( struct brw_instruction *insn,
d321 2
a322 1
   brw_set_src1(insn, brw_imm_d(0));
d324 33
a356 10
   insn->bits3.urb.opcode = 0;	/* ? */
   insn->bits3.urb.offset = offset;
   insn->bits3.urb.swizzle_control = swizzle_control;
   insn->bits3.urb.allocate = allocate;
   insn->bits3.urb.used = used;	/* ? */
   insn->bits3.urb.complete = complete;
   insn->bits3.urb.response_length = response_length;
   insn->bits3.urb.msg_length = msg_length;
   insn->bits3.urb.msg_target = BRW_MESSAGE_TARGET_URB;
   insn->bits3.urb.end_of_thread = end_of_thread;
d359 2
a360 1
static void brw_set_dp_write_message( struct brw_instruction *insn,
d369 1
d372 23
a394 9
   insn->bits3.dp_write.binding_table_index = binding_table_index;
   insn->bits3.dp_write.msg_control = msg_control;
   insn->bits3.dp_write.pixel_scoreboard_clear = pixel_scoreboard_clear;
   insn->bits3.dp_write.msg_type = msg_type;
   insn->bits3.dp_write.send_commit_msg = 0;
   insn->bits3.dp_write.response_length = response_length;
   insn->bits3.dp_write.msg_length = msg_length;
   insn->bits3.dp_write.msg_target = BRW_MESSAGE_TARGET_DATAPORT_WRITE;
   insn->bits3.urb.end_of_thread = end_of_thread;
d397 2
a398 1
static void brw_set_dp_read_message( struct brw_instruction *insn,
d407 1
d410 23
a432 8
   insn->bits3.dp_read.binding_table_index = binding_table_index;
   insn->bits3.dp_read.msg_control = msg_control;
   insn->bits3.dp_read.msg_type = msg_type;
   insn->bits3.dp_read.target_cache = target_cache;
   insn->bits3.dp_read.response_length = response_length;
   insn->bits3.dp_read.msg_length = msg_length;
   insn->bits3.dp_read.msg_target = BRW_MESSAGE_TARGET_DATAPORT_READ;
   insn->bits3.dp_read.end_of_thread = end_of_thread;
d436 9
a444 7
                 struct brw_instruction *insn,
				     GLuint binding_table_index,
				     GLuint sampler,
				     GLuint msg_type,
				     GLuint response_length,
				     GLuint msg_length,
				     GLboolean eot)
d446 2
d450 12
a461 1
   if (BRW_IS_G4X(brw)) {
d496 2
a497 2
   if (p->current->header.destreg__conditonalmod) {
      p->current->header.destreg__conditonalmod = 0;   
d535 1
a535 1
struct brw_instruction *brw_##OP(struct brw_compile *p,			\
d543 1
a543 1
struct brw_instruction *brw_##OP(struct brw_compile *p,			\
d597 3
a599 3
	      struct brw_reg dest,
	      struct brw_reg src0,
	      struct brw_reg src1)
d603 4
d662 1
d664 4
d694 2
a695 2
      if_insn->bits3.if_else.jump_count = insn - if_insn;
      if_insn->bits3.if_else.pop_count = 1;
d705 6
d742 1
a742 1
	 patch_insn->bits3.if_else.jump_count = insn - patch_insn + 1;
d746 1
a746 1
	 patch_insn->bits3.if_else.jump_count = insn - patch_insn + 1;
d817 1
a817 1
	       struct brw_instruction *do_insn)
d819 1
d821 4
d845 1
a845 1
      insn->bits3.if_else.jump_count = do_insn - insn + 1;
d863 1
d865 4
d871 1
a871 1
   assert(jmp_insn->bits1.da1.src1_reg_file = BRW_IMMEDIATE_VALUE);
d873 1
a873 1
   jmp_insn->bits3.ud = (landing - jmp_insn) - 1; 
d890 1
a890 1
   insn->header.destreg__conditonalmod = conditional;
d915 1
a915 1
/* Invert 8 values
d926 9
a934 3
   struct brw_instruction *insn = next_insn(p, BRW_OPCODE_SEND);
   GLuint msg_length = (function == BRW_MATH_FUNCTION_POW) ? 2 : 1; 
   GLuint response_length = (function == BRW_MATH_FUNCTION_SINCOS) ? 2 : 1; 
d936 12
a947 5
   /* Example code doesn't set predicate_control for send
    * instructions.
    */
   insn->header.predicate_control = 0; 
   insn->header.destreg__conditonalmod = msg_reg_nr;
d949 11
a959 9
   brw_set_dest(insn, dest);
   brw_set_src0(insn, src);
   brw_set_math_message(insn, 
			msg_length, response_length, 
			function,
			BRW_MATH_INTEGER_UNSIGNED,
			precision,
			saturate,
			data_type);
d962 3
a964 1
/* Use 2 send instructions to invert 16 elements
d985 1
a985 1
   insn->header.destreg__conditonalmod = msg_reg_nr;
d989 2
a990 1
   brw_set_math_message(insn, 
d1002 1
a1002 1
   insn->header.destreg__conditonalmod = msg_reg_nr+1;
d1006 2
a1007 1
   brw_set_math_message(insn, 
d1019 5
a1023 2


a1025 1
		      GLuint msg_reg_nr,
d1028 1
d1034 1
d1038 1
a1038 1
			   
d1049 1
a1049 1
      insn->header.destreg__conditonalmod = msg_reg_nr;
d1054 3
a1056 2
      brw_set_dp_write_message(insn,
			       255, /* bti */
a1063 1

d1067 5
a1073 1
		      GLuint msg_reg_nr,
d1076 1
d1082 1
d1086 1
a1086 1
			   
d1095 1
a1095 1
      insn->header.destreg__conditonalmod = msg_reg_nr;
d1100 4
a1103 3
      brw_set_dp_read_message(insn,
			      255, /* bti */
			      3,  /* msg_control */
d1105 1
a1105 1
			      1, /* target cache */
d1113 131
d1245 7
a1251 7
		   struct brw_reg dest,
		   GLuint msg_reg_nr,
		   struct brw_reg src0,
		   GLuint binding_table_index,
		   GLuint msg_length,
		   GLuint response_length,
		   GLboolean eot)
d1257 1
a1257 1
   insn->header.destreg__conditonalmod = msg_reg_nr;
d1261 2
a1262 1
   brw_set_dp_write_message(insn,
d1273 5
a1277 1

d1288 3
a1290 1
		GLboolean eot)
d1293 3
a1295 3
   
   if(writemask == 0) {
/*       _mesa_printf("%s: zero writemask??\n", __FUNCTION__); */
d1327 1
a1327 1
/* 	 _mesa_printf("need stall %x %x\n", newmask , writemask); */
d1330 2
d1333 5
a1337 1
	 
d1352 7
a1358 1
	 response_length = len * 2;
d1367 1
a1367 1
      insn->header.destreg__conditonalmod = msg_reg_nr;
d1377 3
a1379 1
			      eot);
d1382 1
a1382 2
   if (need_stall)
   {
d1388 1
a1388 1
      brw_set_compression_control(p, GL_FALSE);
d1412 47
d1467 1
a1467 1
   insn->header.destreg__conditonalmod = msg_reg_nr;
d1469 2
a1470 1
   brw_set_urb_message(insn,
a1479 1

@


1.3
log
@Mesa 7.2, Tested by ckuethe@@, naddy@@, oga@@, and others.
@
text
@d67 3
a69 1
	 insn->bits1.da1.dest_horiz_stride = BRW_HORIZONTAL_STRIDE_1;
d83 3
a85 1
	 insn->bits1.ia1.dest_horiz_stride = BRW_HORIZONTAL_STRIDE_1;
d336 8
a343 8
   if (BRW_IS_GM45(brw) || BRW_IS_G4X(brw)) {
      insn->bits3.sampler_gm45_g4x.binding_table_index = binding_table_index;
      insn->bits3.sampler_gm45_g4x.sampler = sampler;
      insn->bits3.sampler_gm45_g4x.msg_type = msg_type;
      insn->bits3.sampler_gm45_g4x.response_length = response_length;
      insn->bits3.sampler_gm45_g4x.msg_length = msg_length;
      insn->bits3.sampler_gm45_g4x.end_of_thread = eot;
      insn->bits3.sampler_gm45_g4x.msg_target = BRW_MESSAGE_TARGET_SAMPLER;
d442 1
@


1.2
log
@Update to Mesa 7.0.3. tested my oga@@ and johan@@
@
text
@d167 1
a167 1
static void brw_set_src1( struct brw_instruction *insn,
d189 1
a189 1
      assert (reg.file == BRW_GENERAL_REGISTER_FILE);
d322 1
a322 1
				     struct brw_instruction *insn,
d332 8
a339 8
   if (BRW_IS_IGD(brw)) {
      insn->bits3.sampler_igd.binding_table_index = binding_table_index;
      insn->bits3.sampler_igd.sampler = sampler;
      insn->bits3.sampler_igd.msg_type = msg_type;
      insn->bits3.sampler_igd.response_length = response_length;
      insn->bits3.sampler_igd.msg_length = msg_length;
      insn->bits3.sampler_igd.end_of_thread = eot;
      insn->bits3.sampler_igd.msg_target = BRW_MESSAGE_TARGET_SAMPLER;
d516 2
d543 2
d586 1
d616 28
d655 3
a657 3
      brw_set_dest(insn, retype(brw_vec1_grf(0,0), BRW_REGISTER_TYPE_UD));
      brw_set_src0(insn, retype(brw_vec1_grf(0,0), BRW_REGISTER_TYPE_UD));
      brw_set_src1(insn, retype(brw_vec1_grf(0,0), BRW_REGISTER_TYPE_UD));
d661 1
d663 1
d671 1
a671 1
void brw_WHILE(struct brw_compile *p, 
d695 1
a695 1
      insn->bits3.if_else.jump_count = do_insn - insn;
d702 1
d704 1
@


1.1
log
@Initial revision
@
text
@d321 2
a322 1
static void brw_set_sampler_message( struct brw_instruction *insn,
d332 18
a349 8
   insn->bits3.sampler.binding_table_index = binding_table_index;
   insn->bits3.sampler.sampler = sampler;
   insn->bits3.sampler.msg_type = msg_type;
   insn->bits3.sampler.return_format = BRW_SAMPLER_RETURN_FORMAT_FLOAT32;
   insn->bits3.sampler.response_length = response_length;
   insn->bits3.sampler.msg_length = msg_length;
   insn->bits3.sampler.end_of_thread = eot;
   insn->bits3.sampler.msg_target = BRW_MESSAGE_TARGET_SAMPLER;
a477 1

d495 10
a504 1
   struct brw_instruction *insn = next_insn(p, BRW_OPCODE_IF);   
d526 7
a532 1
   struct brw_instruction *insn = next_insn(p, BRW_OPCODE_ELSE);   
d544 2
a545 1
   assert(if_insn->header.opcode == BRW_OPCODE_IF);
d547 8
a554 3
   if_insn->bits3.if_else.jump_count = insn - if_insn; 
   if_insn->bits3.if_else.pop_count = 1;
   if_insn->bits3.if_else.pad0 = 0;
d562 12
a573 1
   struct brw_instruction *insn = next_insn(p, BRW_OPCODE_ENDIF);   
d575 7
a581 3
   brw_set_dest(insn, retype(brw_vec4_grf(0,0), BRW_REGISTER_TYPE_UD));
   brw_set_src0(insn, retype(brw_vec4_grf(0,0), BRW_REGISTER_TYPE_UD));
   brw_set_src1(insn, brw_imm_d(0x0));
d583 1
a583 3
   insn->header.compression_control = BRW_COMPRESSION_NONE;
   insn->header.execution_size = patch_insn->header.execution_size;
   insn->header.mask_control = BRW_MASK_ENABLE;
d585 2
a586 7
   assert(patch_insn->bits3.if_else.jump_count == 0);
      
   /* Patch the if or else instructions to point at this or the next
    * instruction respectively.
    */
   if (patch_insn->header.opcode == BRW_OPCODE_IF) {
      /* Automagically turn it into an IFF:
d588 14
a601 4
      patch_insn->header.opcode = BRW_OPCODE_IFF;
      patch_insn->bits3.if_else.jump_count = insn - patch_insn + 1;
      patch_insn->bits3.if_else.pop_count = 0;
      patch_insn->bits3.if_else.pad0 = 0;
d603 5
a608 14
   else if (patch_insn->header.opcode == BRW_OPCODE_ELSE) {
      patch_insn->bits3.if_else.jump_count = insn - patch_insn + 1;
      patch_insn->bits3.if_else.pop_count = 1;
      patch_insn->bits3.if_else.pad0 = 0;
   }
   else {
      assert(0);
   }

   /* Also pop item off the stack in the endif instruction:
    */
   insn->bits3.if_else.jump_count = 0;
   insn->bits3.if_else.pop_count = 1; 
   insn->bits3.if_else.pad0 = 0;
d615 4
a618 1
   struct brw_instruction *insn = next_insn(p, BRW_OPCODE_DO);   
d620 5
a624 5
   /* Override the defaults for this instruction:
    */
   brw_set_dest(insn, retype(brw_vec1_grf(0,0), BRW_REGISTER_TYPE_UD));
   brw_set_src0(insn, retype(brw_vec1_grf(0,0), BRW_REGISTER_TYPE_UD));
   brw_set_src1(insn, retype(brw_vec1_grf(0,0), BRW_REGISTER_TYPE_UD));
d626 3
a628 3
   insn->header.compression_control = BRW_COMPRESSION_NONE;
   insn->header.execution_size = execute_size;
/*    insn->header.mask_control = BRW_MASK_ENABLE; */
d630 2
a631 1
   return insn;
d639 6
a644 1
   struct brw_instruction *insn = next_insn(p, BRW_OPCODE_WHILE);
a650 1
   insn->header.execution_size = do_insn->header.execution_size;
d652 12
a663 4
   assert(do_insn->header.opcode == BRW_OPCODE_DO);
   insn->bits3.if_else.jump_count = do_insn - insn;
   insn->bits3.if_else.pop_count = 0;
   insn->bits3.if_else.pad0 = 0;
d999 1
a999 1
      brw_set_sampler_message(insn,
@


1.1.1.1
log
@Import MesaLibs 6.5.1. (in dist/ since its code is shared between lib 
and xserver)...
@
text
@@


1.1.1.2
log
@Mesa 7.0.1
@
text
@d467 1
d485 1
a485 10
   struct brw_instruction *insn;

   if (p->single_program_flow) {
      assert(execute_size == BRW_EXECUTE_1);

      insn = next_insn(p, BRW_OPCODE_ADD);
      insn->header.predicate_inverse = 1;
   } else {
      insn = next_insn(p, BRW_OPCODE_IF);
   }
d507 1
a507 7
   struct brw_instruction *insn;

   if (p->single_program_flow) {
      insn = next_insn(p, BRW_OPCODE_ADD);
   } else {
      insn = next_insn(p, BRW_OPCODE_ELSE);
   }
d519 1
a519 2
   if (p->single_program_flow) {
      assert(if_insn->header.opcode == BRW_OPCODE_ADD);
d521 3
a523 8
      if_insn->bits3.ud = (insn - if_insn + 1) * 16;
   } else {
      assert(if_insn->header.opcode == BRW_OPCODE_IF);

      if_insn->bits3.if_else.jump_count = insn - if_insn;
      if_insn->bits3.if_else.pop_count = 1;
      if_insn->bits3.if_else.pad0 = 0;
   }
d531 1
a531 6
   if (p->single_program_flow) {
      /* In single program flow mode, there's no need to execute an ENDIF,
       * since we don't need to do any stack operations, and if we're executing
       * currently, we want to just continue executing.
       */
      struct brw_instruction *next = &p->store[p->nr_insn];
d533 3
a535 1
      assert(patch_insn->header.opcode == BRW_OPCODE_ADD);
d537 3
a539 3
      patch_insn->bits3.ud = (next - patch_insn) * 16;
   } else {
      struct brw_instruction *insn = next_insn(p, BRW_OPCODE_ENDIF);
d541 7
a547 12
      brw_set_dest(insn, retype(brw_vec4_grf(0,0), BRW_REGISTER_TYPE_UD));
      brw_set_src0(insn, retype(brw_vec4_grf(0,0), BRW_REGISTER_TYPE_UD));
      brw_set_src1(insn, brw_imm_d(0x0));

      insn->header.compression_control = BRW_COMPRESSION_NONE;
      insn->header.execution_size = patch_insn->header.execution_size;
      insn->header.mask_control = BRW_MASK_ENABLE;

      assert(patch_insn->bits3.if_else.jump_count == 0);

      /* Patch the if or else instructions to point at this or the next
       * instruction respectively.
d549 4
a552 14
      if (patch_insn->header.opcode == BRW_OPCODE_IF) {
	 /* Automagically turn it into an IFF:
	  */
	 patch_insn->header.opcode = BRW_OPCODE_IFF;
	 patch_insn->bits3.if_else.jump_count = insn - patch_insn + 1;
	 patch_insn->bits3.if_else.pop_count = 0;
	 patch_insn->bits3.if_else.pad0 = 0;
      } else if (patch_insn->header.opcode == BRW_OPCODE_ELSE) {
	 patch_insn->bits3.if_else.jump_count = insn - patch_insn + 1;
	 patch_insn->bits3.if_else.pop_count = 1;
	 patch_insn->bits3.if_else.pad0 = 0;
      } else {
	 assert(0);
      }
a553 5
      /* Also pop item off the stack in the endif instruction:
       */
      insn->bits3.if_else.jump_count = 0;
      insn->bits3.if_else.pop_count = 1;
      insn->bits3.if_else.pad0 = 0;
d555 14
d575 1
a575 4
   if (p->single_program_flow) {
      return &p->store[p->nr_insn];
   } else {
      struct brw_instruction *insn = next_insn(p, BRW_OPCODE_DO);
d577 9
a585 9
      /* Override the defaults for this instruction:
       */
      brw_set_dest(insn, retype(brw_vec1_grf(0,0), BRW_REGISTER_TYPE_UD));
      brw_set_src0(insn, retype(brw_vec1_grf(0,0), BRW_REGISTER_TYPE_UD));
      brw_set_src1(insn, retype(brw_vec1_grf(0,0), BRW_REGISTER_TYPE_UD));

      insn->header.compression_control = BRW_COMPRESSION_NONE;
      insn->header.execution_size = execute_size;
      /* insn->header.mask_control = BRW_MASK_ENABLE; */
d587 1
a587 2
      return insn;
   }
d595 1
a595 6
   struct brw_instruction *insn;

   if (p->single_program_flow)
      insn = next_insn(p, BRW_OPCODE_ADD);
   else
      insn = next_insn(p, BRW_OPCODE_WHILE);
d602 1
d604 4
a607 12
   if (p->single_program_flow) {
      insn->header.execution_size = BRW_EXECUTE_1;

      insn->bits3.d = (do_insn - insn) * 16;
   } else {
      insn->header.execution_size = do_insn->header.execution_size;

      assert(do_insn->header.opcode == BRW_OPCODE_DO);
      insn->bits3.if_else.jump_count = do_insn - insn;
      insn->bits3.if_else.pop_count = 0;
      insn->bits3.if_else.pad0 = 0;
   }
@


1.1.1.3
log
@Import Mesa 7.10.3
@
text
@d44 2
a45 3
static void guess_execution_size(struct brw_compile *p,
				 struct brw_instruction *insn,
				 struct brw_reg reg)
d47 2
a48 1
   if (reg.width == BRW_WIDTH_8 && p->compressed)
d55 2
a56 31
/**
 * Prior to Sandybridge, the SEND instruction accepted non-MRF source
 * registers, implicitly moving the operand to a message register.
 *
 * On Sandybridge, this is no longer the case.  This function performs the
 * explicit move; it should be called before emitting a SEND instruction.
 */
static void
gen6_resolve_implied_move(struct brw_compile *p,
			  struct brw_reg *src,
			  GLuint msg_reg_nr)
{
   struct intel_context *intel = &p->brw->intel;
   if (intel->gen != 6)
      return;

   if (src->file != BRW_ARCHITECTURE_REGISTER_FILE || src->nr != BRW_ARF_NULL) {
      brw_push_insn_state(p);
      brw_set_mask_control(p, BRW_MASK_DISABLE);
      brw_set_compression_control(p, BRW_COMPRESSION_NONE);
      brw_MOV(p, retype(brw_message_reg(msg_reg_nr), BRW_REGISTER_TYPE_UD),
	      retype(*src, BRW_REGISTER_TYPE_UD));
      brw_pop_insn_state(p);
   }
   *src = brw_message_reg(msg_reg_nr);
}


static void brw_set_dest(struct brw_compile *p,
			 struct brw_instruction *insn,
			 struct brw_reg dest)
a57 4
   if (dest.file != BRW_ARCHITECTURE_REGISTER_FILE &&
       dest.file != BRW_MESSAGE_REGISTER_FILE)
      assert(dest.nr < 128);

d67 1
a67 3
	 if (dest.hstride == BRW_HORIZONTAL_STRIDE_0)
	    dest.hstride = BRW_HORIZONTAL_STRIDE_1;
	 insn->bits1.da1.dest_horiz_stride = dest.hstride;
a71 2
	 /* even ignored in da16, still need to set as '01' */
	 insn->bits1.da16.dest_horiz_stride = 1;
d81 1
a81 3
	 if (dest.hstride == BRW_HORIZONTAL_STRIDE_0)
	    dest.hstride = BRW_HORIZONTAL_STRIDE_1;
	 insn->bits1.ia1.dest_horiz_stride = dest.hstride;
a84 2
	 /* even ignored in da16, still need to set as '01' */
	 insn->bits1.ia16.dest_horiz_stride = 1;
d91 1
a91 79
   guess_execution_size(p, insn, dest);
}

extern int reg_type_size[];

static void
validate_reg(struct brw_instruction *insn, struct brw_reg reg)
{
   int hstride_for_reg[] = {0, 1, 2, 4};
   int vstride_for_reg[] = {0, 1, 2, 4, 8, 16, 32, 64, 128, 256};
   int width_for_reg[] = {1, 2, 4, 8, 16};
   int execsize_for_reg[] = {1, 2, 4, 8, 16};
   int width, hstride, vstride, execsize;

   if (reg.file == BRW_IMMEDIATE_VALUE) {
      /* 3.3.6: Region Parameters.  Restriction: Immediate vectors
       * mean the destination has to be 128-bit aligned and the
       * destination horiz stride has to be a word.
       */
      if (reg.type == BRW_REGISTER_TYPE_V) {
	 assert(hstride_for_reg[insn->bits1.da1.dest_horiz_stride] *
		reg_type_size[insn->bits1.da1.dest_reg_type] == 2);
      }

      return;
   }

   if (reg.file == BRW_ARCHITECTURE_REGISTER_FILE &&
       reg.file == BRW_ARF_NULL)
      return;

   assert(reg.hstride >= 0 && reg.hstride < Elements(hstride_for_reg));
   hstride = hstride_for_reg[reg.hstride];

   if (reg.vstride == 0xf) {
      vstride = -1;
   } else {
      assert(reg.vstride >= 0 && reg.vstride < Elements(vstride_for_reg));
      vstride = vstride_for_reg[reg.vstride];
   }

   assert(reg.width >= 0 && reg.width < Elements(width_for_reg));
   width = width_for_reg[reg.width];

   assert(insn->header.execution_size >= 0 &&
	  insn->header.execution_size < Elements(execsize_for_reg));
   execsize = execsize_for_reg[insn->header.execution_size];

   /* Restrictions from 3.3.10: Register Region Restrictions. */
   /* 3. */
   assert(execsize >= width);

   /* 4. */
   if (execsize == width && hstride != 0) {
      assert(vstride == -1 || vstride == width * hstride);
   }

   /* 5. */
   if (execsize == width && hstride == 0) {
      /* no restriction on vstride. */
   }

   /* 6. */
   if (width == 1) {
      assert(hstride == 0);
   }

   /* 7. */
   if (execsize == 1 && width == 1) {
      assert(hstride == 0);
      assert(vstride == 0);
   }

   /* 8. */
   if (vstride == 0 && hstride == 0) {
      assert(width == 1);
   }

   /* 10. Check destination issues. */
d95 1
a95 1
                          struct brw_reg reg )
d97 1
a97 4
   if (reg.type != BRW_ARCHITECTURE_REGISTER_FILE)
      assert(reg.nr < 128);

   validate_reg(insn, reg);
d167 2
a168 2
void brw_set_src1( struct brw_instruction *insn,
                   struct brw_reg reg )
a171 4
   assert(reg.nr < 128);

   validate_reg(insn, reg);

d189 1
a189 1
      /* assert (reg.file == BRW_GENERAL_REGISTER_FILE); */
d232 1
a232 2
static void brw_set_math_message( struct brw_context *brw,
				  struct brw_instruction *insn,
a240 1
   struct intel_context *intel = &brw->intel;
d243 9
a251 24
   if (intel->gen == 5) {
       insn->bits3.math_gen5.function = function;
       insn->bits3.math_gen5.int_type = integer_type;
       insn->bits3.math_gen5.precision = low_precision;
       insn->bits3.math_gen5.saturate = saturate;
       insn->bits3.math_gen5.data_type = dataType;
       insn->bits3.math_gen5.snapshot = 0;
       insn->bits3.math_gen5.header_present = 0;
       insn->bits3.math_gen5.response_length = response_length;
       insn->bits3.math_gen5.msg_length = msg_length;
       insn->bits3.math_gen5.end_of_thread = 0;
       insn->bits2.send_gen5.sfid = BRW_MESSAGE_TARGET_MATH;
       insn->bits2.send_gen5.end_of_thread = 0;
   } else {
       insn->bits3.math.function = function;
       insn->bits3.math.int_type = integer_type;
       insn->bits3.math.precision = low_precision;
       insn->bits3.math.saturate = saturate;
       insn->bits3.math.data_type = dataType;
       insn->bits3.math.response_length = response_length;
       insn->bits3.math.msg_length = msg_length;
       insn->bits3.math.msg_target = BRW_MESSAGE_TARGET_MATH;
       insn->bits3.math.end_of_thread = 0;
   }
d254 1
a254 30

static void brw_set_ff_sync_message(struct brw_context *brw,
				    struct brw_instruction *insn,
				    GLboolean allocate,
				    GLuint response_length,
				    GLboolean end_of_thread)
{
	struct intel_context *intel = &brw->intel;
	brw_set_src1(insn, brw_imm_d(0));

	insn->bits3.urb_gen5.opcode = 1; /* FF_SYNC */
	insn->bits3.urb_gen5.offset = 0; /* Not used by FF_SYNC */
	insn->bits3.urb_gen5.swizzle_control = 0; /* Not used by FF_SYNC */
	insn->bits3.urb_gen5.allocate = allocate;
	insn->bits3.urb_gen5.used = 0; /* Not used by FF_SYNC */
	insn->bits3.urb_gen5.complete = 0; /* Not used by FF_SYNC */
	insn->bits3.urb_gen5.header_present = 1;
	insn->bits3.urb_gen5.response_length = response_length; /* may be 1 or 0 */
	insn->bits3.urb_gen5.msg_length = 1;
	insn->bits3.urb_gen5.end_of_thread = end_of_thread;
	if (intel->gen >= 6) {
	   insn->header.destreg__conditionalmod = BRW_MESSAGE_TARGET_URB;
	} else {
	   insn->bits2.send_gen5.sfid = BRW_MESSAGE_TARGET_URB;
	   insn->bits2.send_gen5.end_of_thread = end_of_thread;
	}
}

static void brw_set_urb_message( struct brw_context *brw,
				 struct brw_instruction *insn,
d264 1
a264 2
    struct intel_context *intel = &brw->intel;
    brw_set_src1(insn, brw_imm_d(0));
d266 10
a275 33
    if (intel->gen >= 5) {
        insn->bits3.urb_gen5.opcode = 0;	/* ? */
        insn->bits3.urb_gen5.offset = offset;
        insn->bits3.urb_gen5.swizzle_control = swizzle_control;
        insn->bits3.urb_gen5.allocate = allocate;
        insn->bits3.urb_gen5.used = used;	/* ? */
        insn->bits3.urb_gen5.complete = complete;
        insn->bits3.urb_gen5.header_present = 1;
        insn->bits3.urb_gen5.response_length = response_length;
        insn->bits3.urb_gen5.msg_length = msg_length;
        insn->bits3.urb_gen5.end_of_thread = end_of_thread;
	if (intel->gen >= 6) {
	   /* For SNB, the SFID bits moved to the condmod bits, and
	    * EOT stayed in bits3 above.  Does the EOT bit setting
	    * below on Ironlake even do anything?
	    */
	   insn->header.destreg__conditionalmod = BRW_MESSAGE_TARGET_URB;
	} else {
	   insn->bits2.send_gen5.sfid = BRW_MESSAGE_TARGET_URB;
	   insn->bits2.send_gen5.end_of_thread = end_of_thread;
	}
    } else {
        insn->bits3.urb.opcode = 0;	/* ? */
        insn->bits3.urb.offset = offset;
        insn->bits3.urb.swizzle_control = swizzle_control;
        insn->bits3.urb.allocate = allocate;
        insn->bits3.urb.used = used;	/* ? */
        insn->bits3.urb.complete = complete;
        insn->bits3.urb.response_length = response_length;
        insn->bits3.urb.msg_length = msg_length;
        insn->bits3.urb.msg_target = BRW_MESSAGE_TARGET_URB;
        insn->bits3.urb.end_of_thread = end_of_thread;
    }
d278 1
a278 2
static void brw_set_dp_write_message( struct brw_context *brw,
				      struct brw_instruction *insn,
a282 1
				      GLboolean header_present,
d285 1
a285 2
				      GLuint end_of_thread,
				      GLuint send_commit_msg)
d287 1
a287 2
   struct intel_context *intel = &brw->intel;
   brw_set_src1(insn, brw_imm_ud(0));
d289 9
a297 37
   if (intel->gen >= 6) {
       insn->bits3.dp_render_cache.binding_table_index = binding_table_index;
       insn->bits3.dp_render_cache.msg_control = msg_control;
       insn->bits3.dp_render_cache.pixel_scoreboard_clear = pixel_scoreboard_clear;
       insn->bits3.dp_render_cache.msg_type = msg_type;
       insn->bits3.dp_render_cache.send_commit_msg = send_commit_msg;
       insn->bits3.dp_render_cache.header_present = header_present;
       insn->bits3.dp_render_cache.response_length = response_length;
       insn->bits3.dp_render_cache.msg_length = msg_length;
       insn->bits3.dp_render_cache.end_of_thread = end_of_thread;
       insn->header.destreg__conditionalmod = BRW_MESSAGE_TARGET_DATAPORT_WRITE;
	/* XXX really need below? */
       insn->bits2.send_gen5.sfid = BRW_MESSAGE_TARGET_DATAPORT_WRITE;
       insn->bits2.send_gen5.end_of_thread = end_of_thread;
   } else if (intel->gen == 5) {
       insn->bits3.dp_write_gen5.binding_table_index = binding_table_index;
       insn->bits3.dp_write_gen5.msg_control = msg_control;
       insn->bits3.dp_write_gen5.pixel_scoreboard_clear = pixel_scoreboard_clear;
       insn->bits3.dp_write_gen5.msg_type = msg_type;
       insn->bits3.dp_write_gen5.send_commit_msg = send_commit_msg;
       insn->bits3.dp_write_gen5.header_present = header_present;
       insn->bits3.dp_write_gen5.response_length = response_length;
       insn->bits3.dp_write_gen5.msg_length = msg_length;
       insn->bits3.dp_write_gen5.end_of_thread = end_of_thread;
       insn->bits2.send_gen5.sfid = BRW_MESSAGE_TARGET_DATAPORT_WRITE;
       insn->bits2.send_gen5.end_of_thread = end_of_thread;
   } else {
       insn->bits3.dp_write.binding_table_index = binding_table_index;
       insn->bits3.dp_write.msg_control = msg_control;
       insn->bits3.dp_write.pixel_scoreboard_clear = pixel_scoreboard_clear;
       insn->bits3.dp_write.msg_type = msg_type;
       insn->bits3.dp_write.send_commit_msg = send_commit_msg;
       insn->bits3.dp_write.response_length = response_length;
       insn->bits3.dp_write.msg_length = msg_length;
       insn->bits3.dp_write.msg_target = BRW_MESSAGE_TARGET_DATAPORT_WRITE;
       insn->bits3.dp_write.end_of_thread = end_of_thread;
   }
d300 8
a307 9
static void
brw_set_dp_read_message(struct brw_context *brw,
			struct brw_instruction *insn,
			GLuint binding_table_index,
			GLuint msg_control,
			GLuint msg_type,
			GLuint target_cache,
			GLuint msg_length,
			GLuint response_length)
a308 1
   struct intel_context *intel = &brw->intel;
d311 17
a327 59
   if (intel->gen >= 6) {
       insn->bits3.dp_render_cache.binding_table_index = binding_table_index;
       insn->bits3.dp_render_cache.msg_control = msg_control;
       insn->bits3.dp_render_cache.pixel_scoreboard_clear = 0;
       insn->bits3.dp_render_cache.msg_type = msg_type;
       insn->bits3.dp_render_cache.send_commit_msg = 0;
       insn->bits3.dp_render_cache.header_present = 1;
       insn->bits3.dp_render_cache.response_length = response_length;
       insn->bits3.dp_render_cache.msg_length = msg_length;
       insn->bits3.dp_render_cache.end_of_thread = 0;
       insn->header.destreg__conditionalmod = BRW_MESSAGE_TARGET_DATAPORT_READ;
	/* XXX really need below? */
       insn->bits2.send_gen5.sfid = BRW_MESSAGE_TARGET_DATAPORT_READ;
       insn->bits2.send_gen5.end_of_thread = 0;
   } else if (intel->gen == 5) {
       insn->bits3.dp_read_gen5.binding_table_index = binding_table_index;
       insn->bits3.dp_read_gen5.msg_control = msg_control;
       insn->bits3.dp_read_gen5.msg_type = msg_type;
       insn->bits3.dp_read_gen5.target_cache = target_cache;
       insn->bits3.dp_read_gen5.header_present = 1;
       insn->bits3.dp_read_gen5.response_length = response_length;
       insn->bits3.dp_read_gen5.msg_length = msg_length;
       insn->bits3.dp_read_gen5.pad1 = 0;
       insn->bits3.dp_read_gen5.end_of_thread = 0;
       insn->bits2.send_gen5.sfid = BRW_MESSAGE_TARGET_DATAPORT_READ;
       insn->bits2.send_gen5.end_of_thread = 0;
   } else if (intel->is_g4x) {
       insn->bits3.dp_read_g4x.binding_table_index = binding_table_index; /*0:7*/
       insn->bits3.dp_read_g4x.msg_control = msg_control;  /*8:10*/
       insn->bits3.dp_read_g4x.msg_type = msg_type;  /*11:13*/
       insn->bits3.dp_read_g4x.target_cache = target_cache;  /*14:15*/
       insn->bits3.dp_read_g4x.response_length = response_length;  /*16:19*/
       insn->bits3.dp_read_g4x.msg_length = msg_length;  /*20:23*/
       insn->bits3.dp_read_g4x.msg_target = BRW_MESSAGE_TARGET_DATAPORT_READ; /*24:27*/
       insn->bits3.dp_read_g4x.pad1 = 0;
       insn->bits3.dp_read_g4x.end_of_thread = 0;
   } else {
       insn->bits3.dp_read.binding_table_index = binding_table_index; /*0:7*/
       insn->bits3.dp_read.msg_control = msg_control;  /*8:11*/
       insn->bits3.dp_read.msg_type = msg_type;  /*12:13*/
       insn->bits3.dp_read.target_cache = target_cache;  /*14:15*/
       insn->bits3.dp_read.response_length = response_length;  /*16:19*/
       insn->bits3.dp_read.msg_length = msg_length;  /*20:23*/
       insn->bits3.dp_read.msg_target = BRW_MESSAGE_TARGET_DATAPORT_READ; /*24:27*/
       insn->bits3.dp_read.pad1 = 0;  /*28:30*/
       insn->bits3.dp_read.end_of_thread = 0;  /*31*/
   }
}

static void brw_set_sampler_message(struct brw_context *brw,
                                    struct brw_instruction *insn,
                                    GLuint binding_table_index,
                                    GLuint sampler,
                                    GLuint msg_type,
                                    GLuint response_length,
                                    GLuint msg_length,
                                    GLboolean eot,
                                    GLuint header_present,
                                    GLuint simd_mode)
a328 2
   struct intel_context *intel = &brw->intel;
   assert(eot == 0);
d331 8
a338 33
   if (intel->gen >= 5) {
      insn->bits3.sampler_gen5.binding_table_index = binding_table_index;
      insn->bits3.sampler_gen5.sampler = sampler;
      insn->bits3.sampler_gen5.msg_type = msg_type;
      insn->bits3.sampler_gen5.simd_mode = simd_mode;
      insn->bits3.sampler_gen5.header_present = header_present;
      insn->bits3.sampler_gen5.response_length = response_length;
      insn->bits3.sampler_gen5.msg_length = msg_length;
      insn->bits3.sampler_gen5.end_of_thread = eot;
      if (intel->gen >= 6)
	  insn->header.destreg__conditionalmod = BRW_MESSAGE_TARGET_SAMPLER;
      else {
	  insn->bits2.send_gen5.sfid = BRW_MESSAGE_TARGET_SAMPLER;
	  insn->bits2.send_gen5.end_of_thread = eot;
      }
   } else if (intel->is_g4x) {
      insn->bits3.sampler_g4x.binding_table_index = binding_table_index;
      insn->bits3.sampler_g4x.sampler = sampler;
      insn->bits3.sampler_g4x.msg_type = msg_type;
      insn->bits3.sampler_g4x.response_length = response_length;
      insn->bits3.sampler_g4x.msg_length = msg_length;
      insn->bits3.sampler_g4x.end_of_thread = eot;
      insn->bits3.sampler_g4x.msg_target = BRW_MESSAGE_TARGET_SAMPLER;
   } else {
      insn->bits3.sampler.binding_table_index = binding_table_index;
      insn->bits3.sampler.sampler = sampler;
      insn->bits3.sampler.msg_type = msg_type;
      insn->bits3.sampler.return_format = BRW_SAMPLER_RETURN_FORMAT_FLOAT32;
      insn->bits3.sampler.response_length = response_length;
      insn->bits3.sampler.msg_length = msg_length;
      insn->bits3.sampler.end_of_thread = eot;
      insn->bits3.sampler.msg_target = BRW_MESSAGE_TARGET_SAMPLER;
   }
d356 2
a357 2
   if (p->current->header.destreg__conditionalmod) {
      p->current->header.destreg__conditionalmod = 0;
d372 1
a372 1
   brw_set_dest(p, insn, dest);
d384 1
a384 1
   brw_set_dest(p, insn, dest);
d395 1
a395 1
struct brw_instruction *brw_##OP(struct brw_compile *p,	\
d403 1
a403 1
struct brw_instruction *brw_##OP(struct brw_compile *p,	\
a410 20
/* Rounding operations (other than RNDD) require two instructions - the first
 * stores a rounded value (possibly the wrong way) in the dest register, but
 * also sets a per-channel "increment bit" in the flag register.  A predicated
 * add of 1.0 fixes dest to contain the desired result.
 */
#define ROUND(OP)							      \
void brw_##OP(struct brw_compile *p,					      \
	      struct brw_reg dest,					      \
	      struct brw_reg src)					      \
{									      \
   struct brw_instruction *rnd, *add;					      \
   rnd = next_insn(p, BRW_OPCODE_##OP);					      \
   brw_set_dest(p, rnd, dest);						      \
   brw_set_src0(rnd, src);						      \
   rnd->header.destreg__conditionalmod = 0x7; /* turn on round-increments */  \
									      \
   add = brw_ADD(p, dest, dest, brw_imm_f(1.0f));			      \
   add->header.predicate_control = BRW_PREDICATE_NORMAL;		      \
}

d423 2
a434 26
ALU2(PLN)


ROUND(RNDZ)
ROUND(RNDE)


struct brw_instruction *brw_ADD(struct brw_compile *p,
				struct brw_reg dest,
				struct brw_reg src0,
				struct brw_reg src1)
{
   /* 6.2.2: add */
   if (src0.type == BRW_REGISTER_TYPE_F ||
       (src0.file == BRW_IMMEDIATE_VALUE &&
	src0.type == BRW_REGISTER_TYPE_VF)) {
      assert(src1.type != BRW_REGISTER_TYPE_UD);
      assert(src1.type != BRW_REGISTER_TYPE_D);
   }

   if (src1.type == BRW_REGISTER_TYPE_F ||
       (src1.file == BRW_IMMEDIATE_VALUE &&
	src1.type == BRW_REGISTER_TYPE_VF)) {
      assert(src0.type != BRW_REGISTER_TYPE_UD);
      assert(src0.type != BRW_REGISTER_TYPE_D);
   }
a435 15
   return brw_alu2(p, BRW_OPCODE_ADD, dest, src0, src1);
}

struct brw_instruction *brw_MUL(struct brw_compile *p,
				struct brw_reg dest,
				struct brw_reg src0,
				struct brw_reg src1)
{
   /* 6.32.38: mul */
   if (src0.type == BRW_REGISTER_TYPE_D ||
       src0.type == BRW_REGISTER_TYPE_UD ||
       src1.type == BRW_REGISTER_TYPE_D ||
       src1.type == BRW_REGISTER_TYPE_UD) {
      assert(dest.type != BRW_REGISTER_TYPE_F);
   }
a436 21
   if (src0.type == BRW_REGISTER_TYPE_F ||
       (src0.file == BRW_IMMEDIATE_VALUE &&
	src0.type == BRW_REGISTER_TYPE_VF)) {
      assert(src1.type != BRW_REGISTER_TYPE_UD);
      assert(src1.type != BRW_REGISTER_TYPE_D);
   }

   if (src1.type == BRW_REGISTER_TYPE_F ||
       (src1.file == BRW_IMMEDIATE_VALUE &&
	src1.type == BRW_REGISTER_TYPE_VF)) {
      assert(src0.type != BRW_REGISTER_TYPE_UD);
      assert(src0.type != BRW_REGISTER_TYPE_D);
   }

   assert(src0.file != BRW_ARCHITECTURE_REGISTER_FILE ||
	  src0.nr != BRW_ARF_ACCUMULATOR);
   assert(src1.file != BRW_ARCHITECTURE_REGISTER_FILE ||
	  src1.nr != BRW_ARF_ACCUMULATOR);

   return brw_alu2(p, BRW_OPCODE_MUL, dest, src0, src1);
}
d442 1
a442 1
   brw_set_dest(p, insn, retype(brw_vec4_grf(0,0), BRW_REGISTER_TYPE_UD));
d456 3
a458 3
                                 struct brw_reg dest,
                                 struct brw_reg src0,
                                 struct brw_reg src1)
a461 4
   insn->header.execution_size = 1;
   insn->header.compression_control = BRW_COMPRESSION_NONE;
   insn->header.mask_control = BRW_MASK_DISABLE;

a483 1
   struct intel_context *intel = &p->brw->intel;
d497 3
a499 10
   if (intel->gen < 6) {
      brw_set_dest(p, insn, brw_ip_reg());
      brw_set_src0(insn, brw_ip_reg());
      brw_set_src1(insn, brw_imm_d(0x0));
   } else {
      brw_set_dest(p, insn, brw_imm_w(0));
      insn->bits1.branch_gen6.jump_count = 0;
      brw_set_src0(insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
      brw_set_src1(insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
   }
a504 2
   if (!p->single_program_flow)
       insn->header.thread_control = BRW_THREAD_SWITCH;
a510 23
struct brw_instruction *
brw_IF_gen6(struct brw_compile *p, uint32_t conditional,
	    struct brw_reg src0, struct brw_reg src1)
{
   struct brw_instruction *insn;

   insn = next_insn(p, BRW_OPCODE_IF);

   brw_set_dest(p, insn, brw_imm_w(0));
   insn->header.execution_size = BRW_EXECUTE_8;
   insn->bits1.branch_gen6.jump_count = 0;
   brw_set_src0(insn, src0);
   brw_set_src1(insn, src1);

   assert(insn->header.compression_control == BRW_COMPRESSION_NONE);
   assert(insn->header.predicate_control == BRW_PREDICATE_NONE);
   insn->header.destreg__conditionalmod = conditional;

   if (!p->single_program_flow)
       insn->header.thread_control = BRW_THREAD_SWITCH;

   return insn;
}
a514 1
   struct intel_context *intel = &p->brw->intel;
a515 6
   GLuint br = 1;

   /* jump count is for 64bit data chunk each, so one 128bit
      instruction requires 2 chunks. */
   if (intel->gen >= 5)
      br = 2;
d523 3
a525 10
   if (intel->gen < 6) {
      brw_set_dest(p, insn, brw_ip_reg());
      brw_set_src0(insn, brw_ip_reg());
      brw_set_src1(insn, brw_imm_d(0x0));
   } else {
      brw_set_dest(p, insn, brw_imm_w(0));
      insn->bits1.branch_gen6.jump_count = 0;
      brw_set_src0(insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
      brw_set_src1(insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
   }
a529 2
   if (!p->single_program_flow)
       insn->header.thread_control = BRW_THREAD_SWITCH;
d540 3
a542 7
      if (intel->gen < 6) {
	 if_insn->bits3.if_else.jump_count = br * (insn - if_insn);
	 if_insn->bits3.if_else.pop_count = 0;
	 if_insn->bits3.if_else.pad0 = 0;
      } else {
	 if_insn->bits1.branch_gen6.jump_count = br * (insn - if_insn + 1);
      }
a550 6
   struct intel_context *intel = &p->brw->intel;
   GLuint br = 1;

   if (intel->gen >= 5)
      br = 2; 
 
d564 3
a566 9
      if (intel->gen < 6) {
	 brw_set_dest(p, insn, retype(brw_vec4_grf(0,0), BRW_REGISTER_TYPE_UD));
	 brw_set_src0(insn, retype(brw_vec4_grf(0,0), BRW_REGISTER_TYPE_UD));
	 brw_set_src1(insn, brw_imm_d(0x0));
      } else {
	 brw_set_dest(p, insn, brw_imm_w(0));
	 brw_set_src0(insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
	 brw_set_src1(insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
      }
a570 1
      insn->header.thread_control = BRW_THREAD_SWITCH;
d572 1
a572 4
      if (intel->gen < 6)
	 assert(patch_insn->bits3.if_else.jump_count == 0);
      else
	 assert(patch_insn->bits1.branch_gen6.jump_count == 0);
d578 10
a587 12
	 if (intel->gen < 6) {
	    /* Turn it into an IFF, which means no mask stack operations for
	     * all-false and jumping past the ENDIF.
	     */
	    patch_insn->header.opcode = BRW_OPCODE_IFF;
	    patch_insn->bits3.if_else.jump_count = br * (insn - patch_insn + 1);
	    patch_insn->bits3.if_else.pop_count = 0;
	    patch_insn->bits3.if_else.pad0 = 0;
	 } else {
	    /* As of gen6, there is no IFF and IF must point to the ENDIF. */
	    patch_insn->bits1.branch_gen6.jump_count = br * (insn - patch_insn);
	 }
d589 1
a589 12
	 assert(patch_insn->header.opcode == BRW_OPCODE_ELSE);
	 if (intel->gen < 6) {
	    /* BRW_OPCODE_ELSE pre-gen6 should point just past the
	     * matching ENDIF.
	     */
	    patch_insn->bits3.if_else.jump_count = br * (insn - patch_insn + 1);
	    patch_insn->bits3.if_else.pop_count = 1;
	    patch_insn->bits3.if_else.pad0 = 0;
	 } else {
	    /* BRW_OPCODE_ELSE on gen6 should point to the matching ENDIF. */
	    patch_insn->bits1.branch_gen6.jump_count = br * (insn - patch_insn);
	 }
d594 2
a595 24
      if (intel->gen < 6) {
	 insn->bits3.if_else.jump_count = 0;
	 insn->bits3.if_else.pop_count = 1;
	 insn->bits3.if_else.pad0 = 0;
      } else {
	 insn->bits1.branch_gen6.jump_count = 2;
      }
   }
}

struct brw_instruction *brw_BREAK(struct brw_compile *p, int pop_count)
{
   struct intel_context *intel = &p->brw->intel;
   struct brw_instruction *insn;

   insn = next_insn(p, BRW_OPCODE_BREAK);
   if (intel->gen >= 6) {
      brw_set_dest(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
      brw_set_src0(insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
      brw_set_src1(insn, brw_imm_d(0x0));
   } else {
      brw_set_dest(p, insn, brw_ip_reg());
      brw_set_src0(insn, brw_ip_reg());
      brw_set_src1(insn, brw_imm_d(0x0));
a596 1
      insn->bits3.if_else.pop_count = pop_count;
a597 39
   insn->header.compression_control = BRW_COMPRESSION_NONE;
   insn->header.execution_size = BRW_EXECUTE_8;

   return insn;
}

struct brw_instruction *brw_CONT_gen6(struct brw_compile *p,
				      struct brw_instruction *do_insn)
{
   struct brw_instruction *insn;
   int br = 2;

   insn = next_insn(p, BRW_OPCODE_CONTINUE);
   brw_set_dest(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
   brw_set_src0(insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
   brw_set_dest(p, insn, brw_ip_reg());
   brw_set_src0(insn, brw_ip_reg());
   brw_set_src1(insn, brw_imm_d(0x0));

   insn->bits3.break_cont.uip = br * (do_insn - insn);

   insn->header.compression_control = BRW_COMPRESSION_NONE;
   insn->header.execution_size = BRW_EXECUTE_8;
   return insn;
}

struct brw_instruction *brw_CONT(struct brw_compile *p, int pop_count)
{
   struct brw_instruction *insn;
   insn = next_insn(p, BRW_OPCODE_CONTINUE);
   brw_set_dest(p, insn, brw_ip_reg());
   brw_set_src0(insn, brw_ip_reg());
   brw_set_src1(insn, brw_imm_d(0x0));
   insn->header.compression_control = BRW_COMPRESSION_NONE;
   insn->header.execution_size = BRW_EXECUTE_8;
   /* insn->header.mask_control = BRW_MASK_DISABLE; */
   insn->bits3.if_else.pad0 = 0;
   insn->bits3.if_else.pop_count = pop_count;
   return insn;
a600 14
 *
 * The DO/WHILE is just an unterminated loop -- break or continue are
 * used for control within the loop.  We have a few ways they can be
 * done.
 *
 * For uniform control flow, the WHILE is just a jump, so ADD ip, ip,
 * jip and no DO instruction.
 *
 * For non-uniform control flow pre-gen6, there's a DO instruction to
 * push the mask, and a WHILE to jump back, and BREAK to get out and
 * pop the mask.
 *
 * For gen6, there's no more mask stack, so no need for DO.  WHILE
 * just points back to the first instruction of the loop.
d604 1
a604 3
   struct intel_context *intel = &p->brw->intel;

   if (intel->gen >= 6 || p->single_program_flow) {
d611 3
a613 3
      brw_set_dest(p, insn, brw_null_reg());
      brw_set_src0(insn, brw_null_reg());
      brw_set_src1(insn, brw_null_reg());
a616 1
      insn->header.predicate_control = BRW_PREDICATE_NONE;
a617 1
      /* insn->header.mask_control = BRW_MASK_DISABLE; */
d625 2
a626 2
struct brw_instruction *brw_WHILE(struct brw_compile *p, 
                                  struct brw_instruction *do_insn)
a627 1
   struct intel_context *intel = &p->brw->intel;
a628 1
   GLuint br = 1;
d630 3
a632 4
   if (intel->gen >= 5)
      br = 2;

   if (intel->gen >= 6) {
d635 3
a637 4
      brw_set_dest(p, insn, brw_imm_w(0));
      insn->bits1.branch_gen6.jump_count = br * (do_insn - insn);
      brw_set_src0(insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
      brw_set_src1(insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
d639 1
a639 5
      insn->header.execution_size = do_insn->header.execution_size;
      assert(insn->header.execution_size == BRW_EXECUTE_8);
   } else {
      if (p->single_program_flow) {
	 insn = next_insn(p, BRW_OPCODE_ADD);
d641 2
a642 6
	 brw_set_dest(p, insn, brw_ip_reg());
	 brw_set_src0(insn, brw_ip_reg());
	 brw_set_src1(insn, brw_imm_d((do_insn - insn) * 16));
	 insn->header.execution_size = BRW_EXECUTE_1;
      } else {
	 insn = next_insn(p, BRW_OPCODE_WHILE);
d644 3
a646 1
	 assert(do_insn->header.opcode == BRW_OPCODE_DO);
d648 4
a651 9
	 brw_set_dest(p, insn, brw_ip_reg());
	 brw_set_src0(insn, brw_ip_reg());
	 brw_set_src1(insn, brw_imm_d(0));

	 insn->header.execution_size = do_insn->header.execution_size;
	 insn->bits3.if_else.jump_count = br * (do_insn - insn + 1);
	 insn->bits3.if_else.pop_count = 0;
	 insn->bits3.if_else.pad0 = 0;
      }
a652 2
   insn->header.compression_control = BRW_COMPRESSION_NONE;
   p->current->header.predicate_control = BRW_PREDICATE_NONE;
d654 3
a656 1
   return insn;
a664 1
   struct intel_context *intel = &p->brw->intel;
a665 4
   GLuint jmpi = 1;

   if (intel->gen >= 5)
       jmpi = 2;
d668 1
a668 1
   assert(jmp_insn->bits1.da1.src1_reg_file == BRW_IMMEDIATE_VALUE);
d670 1
a670 1
   jmp_insn->bits3.ud = jmpi * ((landing - jmp_insn) - 1);
d687 2
a688 2
   insn->header.destreg__conditionalmod = conditional;
   brw_set_dest(p, insn, dest);
a705 14
/* Issue 'wait' instruction for n1, host could program MMIO
   to wake up thread. */
void brw_WAIT (struct brw_compile *p)
{
   struct brw_instruction *insn = next_insn(p, BRW_OPCODE_WAIT);
   struct brw_reg src = brw_notification_1_reg();

   brw_set_dest(p, insn, src);
   brw_set_src0(insn, src);
   brw_set_src1(insn, brw_null_reg());
   insn->header.execution_size = 0; /* must */
   insn->header.predicate_control = 0;
   insn->header.compression_control = 0;
}
d712 1
a712 1
/** Extended math function, float[8].
d723 3
a725 74
   struct intel_context *intel = &p->brw->intel;

   if (intel->gen >= 6) {
      struct brw_instruction *insn = next_insn(p, BRW_OPCODE_MATH);

      assert(dest.file == BRW_GENERAL_REGISTER_FILE);
      assert(src.file == BRW_GENERAL_REGISTER_FILE);

      assert(dest.hstride == BRW_HORIZONTAL_STRIDE_1);
      assert(src.hstride == BRW_HORIZONTAL_STRIDE_1);

      /* Source modifiers are ignored for extended math instructions. */
      assert(!src.negate);
      assert(!src.abs);

      if (function != BRW_MATH_FUNCTION_INT_DIV_QUOTIENT &&
	  function != BRW_MATH_FUNCTION_INT_DIV_QUOTIENT_AND_REMAINDER) {
	 assert(src.type == BRW_REGISTER_TYPE_F);
      }

      /* Math is the same ISA format as other opcodes, except that CondModifier
       * becomes FC[3:0] and ThreadCtrl becomes FC[5:4].
       */
      insn->header.destreg__conditionalmod = function;
      insn->header.saturate = saturate;

      brw_set_dest(p, insn, dest);
      brw_set_src0(insn, src);
      brw_set_src1(insn, brw_null_reg());
   } else {
      struct brw_instruction *insn = next_insn(p, BRW_OPCODE_SEND);
      GLuint msg_length = (function == BRW_MATH_FUNCTION_POW) ? 2 : 1;
      GLuint response_length = (function == BRW_MATH_FUNCTION_SINCOS) ? 2 : 1;
      /* Example code doesn't set predicate_control for send
       * instructions.
       */
      insn->header.predicate_control = 0;
      insn->header.destreg__conditionalmod = msg_reg_nr;

      brw_set_dest(p, insn, dest);
      brw_set_src0(insn, src);
      brw_set_math_message(p->brw,
			   insn,
			   msg_length, response_length,
			   function,
			   BRW_MATH_INTEGER_UNSIGNED,
			   precision,
			   saturate,
			   data_type);
   }
}

/** Extended math function, float[8].
 */
void brw_math2(struct brw_compile *p,
	       struct brw_reg dest,
	       GLuint function,
	       struct brw_reg src0,
	       struct brw_reg src1)
{
   struct intel_context *intel = &p->brw->intel;
   struct brw_instruction *insn = next_insn(p, BRW_OPCODE_MATH);

   assert(intel->gen >= 6);
   (void) intel;


   assert(dest.file == BRW_GENERAL_REGISTER_FILE);
   assert(src0.file == BRW_GENERAL_REGISTER_FILE);
   assert(src1.file == BRW_GENERAL_REGISTER_FILE);

   assert(dest.hstride == BRW_HORIZONTAL_STRIDE_1);
   assert(src0.hstride == BRW_HORIZONTAL_STRIDE_1);
   assert(src1.hstride == BRW_HORIZONTAL_STRIDE_1);
d727 2
a728 14
   if (function != BRW_MATH_FUNCTION_INT_DIV_QUOTIENT &&
       function != BRW_MATH_FUNCTION_INT_DIV_QUOTIENT_AND_REMAINDER) {
      assert(src0.type == BRW_REGISTER_TYPE_F);
      assert(src1.type == BRW_REGISTER_TYPE_F);
   }

   /* Source modifiers are ignored for extended math instructions. */
   assert(!src0.negate);
   assert(!src0.abs);
   assert(!src1.negate);
   assert(!src1.abs);

   /* Math is the same ISA format as other opcodes, except that CondModifier
    * becomes FC[3:0] and ThreadCtrl becomes FC[5:4].
d730 2
a731 1
   insn->header.destreg__conditionalmod = function;
d733 9
a741 3
   brw_set_dest(p, insn, dest);
   brw_set_src0(insn, src0);
   brw_set_src1(insn, src1);
d744 1
a744 3
/**
 * Extended math function, float[16].
 * Use 2 send instructions.
a753 1
   struct intel_context *intel = &p->brw->intel;
a757 19
   if (intel->gen >= 6) {
      insn = next_insn(p, BRW_OPCODE_MATH);

      /* Math is the same ISA format as other opcodes, except that CondModifier
       * becomes FC[3:0] and ThreadCtrl becomes FC[5:4].
       */
      insn->header.destreg__conditionalmod = function;
      insn->header.saturate = saturate;

      /* Source modifiers are ignored for extended math instructions. */
      assert(!src.negate);
      assert(!src.abs);

      brw_set_dest(p, insn, dest);
      brw_set_src0(insn, src);
      brw_set_src1(insn, brw_null_reg());
      return;
   }

d765 1
a765 1
   insn->header.destreg__conditionalmod = msg_reg_nr;
d767 1
a767 1
   brw_set_dest(p, insn, dest);
d769 1
a769 2
   brw_set_math_message(p->brw,
			insn, 
d781 1
a781 1
   insn->header.destreg__conditionalmod = msg_reg_nr+1;
d783 1
a783 1
   brw_set_dest(p, insn, offset(dest,1));
d785 1
a785 2
   brw_set_math_message(p->brw, 
			insn, 
a796 25
/**
 * Write a block of OWORDs (half a GRF each) from the scratch buffer,
 * using a constant offset per channel.
 *
 * The offset must be aligned to oword size (16 bytes).  Used for
 * register spilling.
 */
void brw_oword_block_write_scratch(struct brw_compile *p,
				   struct brw_reg mrf,
				   int num_regs,
				   GLuint offset)
{
   struct intel_context *intel = &p->brw->intel;
   uint32_t msg_control;
   int mlen;

   mrf = retype(mrf, BRW_REGISTER_TYPE_UD);

   if (num_regs == 1) {
      msg_control = BRW_DATAPORT_OWORD_BLOCK_2_OWORDS;
      mlen = 2;
   } else {
      msg_control = BRW_DATAPORT_OWORD_BLOCK_4_OWORDS;
      mlen = 3;
   }
d798 6
a803 5
   /* Set up the message header.  This is g0, with g0.2 filled with
    * the offset.  We don't want to leave our offset around in g0 or
    * it'll screw up texture samples, so set it up inside the message
    * reg.
    */
a808 3
      brw_MOV(p, mrf, retype(brw_vec8_grf(0, 0), BRW_REGISTER_TYPE_UD));

      /* set message header global offset field (reg 0, element 2) */
d810 3
a812 5
	      retype(brw_vec1_reg(BRW_MESSAGE_REGISTER_FILE,
				  mrf.nr,
				  2), BRW_REGISTER_TYPE_UD),
	      brw_imm_ud(offset));

d817 2
a818 1
      struct brw_reg dest;
d820 7
a826 31
      int send_commit_msg;
      struct brw_reg src_header = retype(brw_vec8_grf(0, 0),
					 BRW_REGISTER_TYPE_UW);

      if (insn->header.compression_control != BRW_COMPRESSION_NONE) {
	 insn->header.compression_control = BRW_COMPRESSION_NONE;
	 src_header = vec16(src_header);
      }
      assert(insn->header.predicate_control == BRW_PREDICATE_NONE);
      insn->header.destreg__conditionalmod = mrf.nr;

      /* Until gen6, writes followed by reads from the same location
       * are not guaranteed to be ordered unless write_commit is set.
       * If set, then a no-op write is issued to the destination
       * register to set a dependency, and a read from the destination
       * can be used to ensure the ordering.
       *
       * For gen6, only writes between different threads need ordering
       * protection.  Our use of DP writes is all about register
       * spilling within a thread.
       */
      if (intel->gen >= 6) {
	 dest = retype(vec16(brw_null_reg()), BRW_REGISTER_TYPE_UW);
	 send_commit_msg = 0;
      } else {
	 dest = src_header;
	 send_commit_msg = 1;
      }

      brw_set_dest(p, insn, dest);
      brw_set_src0(insn, brw_null_reg());
d828 3
a830 4
      brw_set_dp_write_message(p->brw,
			       insn,
			       255, /* binding table index (255=stateless) */
			       msg_control,
d832 1
a832 2
			       mlen,
			       GL_TRUE, /* header_present */
d834 2
a835 3
			       send_commit_msg, /* response_length */
			       0, /* eot */
			       send_commit_msg);
d837 1
d841 5
a845 28
/**
 * Read a block of owords (half a GRF each) from the scratch buffer
 * using a constant index per channel.
 *
 * Offset must be aligned to oword size (16 bytes).  Used for register
 * spilling.
 */
void
brw_oword_block_read_scratch(struct brw_compile *p,
			     struct brw_reg dest,
			     struct brw_reg mrf,
			     int num_regs,
			     GLuint offset)
{
   uint32_t msg_control;
   int rlen;

   mrf = retype(mrf, BRW_REGISTER_TYPE_UD);
   dest = retype(dest, BRW_REGISTER_TYPE_UW);

   if (num_regs == 1) {
      msg_control = BRW_DATAPORT_OWORD_BLOCK_2_OWORDS;
      rlen = 1;
   } else {
      msg_control = BRW_DATAPORT_OWORD_BLOCK_4_OWORDS;
      rlen = 2;
   }

a850 3
      brw_MOV(p, mrf, retype(brw_vec8_grf(0, 0), BRW_REGISTER_TYPE_UD));

      /* set message header global offset field (reg 0, element 2) */
d852 3
a854 5
	      retype(brw_vec1_reg(BRW_MESSAGE_REGISTER_FILE,
				  mrf.nr,
				  2), BRW_REGISTER_TYPE_UD),
	      brw_imm_ud(offset));

d860 11
a870 12

      assert(insn->header.predicate_control == 0);
      insn->header.compression_control = BRW_COMPRESSION_NONE;
      insn->header.destreg__conditionalmod = mrf.nr;

      brw_set_dest(p, insn, dest);	/* UW? */
      brw_set_src0(insn, brw_null_reg());

      brw_set_dp_read_message(p->brw,
			      insn,
			      255, /* binding table index (255=stateless) */
			      msg_control,
d872 1
a872 1
			      1, /* target cache (render/scratch) */
d874 2
a875 1
			      rlen);
a878 16
/**
 * Read a float[4] vector from the data port Data Cache (const buffer).
 * Location (in buffer) should be a multiple of 16.
 * Used for fetching shader constants.
 */
void brw_oword_block_read(struct brw_compile *p,
			  struct brw_reg dest,
			  struct brw_reg mrf,
			  uint32_t offset,
			  uint32_t bind_table_index)
{
   struct intel_context *intel = &p->brw->intel;

   /* On newer hardware, offset is in units of owords. */
   if (intel->gen >= 6)
      offset /= 16;
d880 8
a887 51
   mrf = retype(mrf, BRW_REGISTER_TYPE_UD);

   brw_push_insn_state(p);
   brw_set_predicate_control(p, BRW_PREDICATE_NONE);
   brw_set_compression_control(p, BRW_COMPRESSION_NONE);
   brw_set_mask_control(p, BRW_MASK_DISABLE);

   brw_MOV(p, mrf, retype(brw_vec8_grf(0, 0), BRW_REGISTER_TYPE_UD));

   /* set message header global offset field (reg 0, element 2) */
   brw_MOV(p,
	   retype(brw_vec1_reg(BRW_MESSAGE_REGISTER_FILE,
			       mrf.nr,
			       2), BRW_REGISTER_TYPE_UD),
	   brw_imm_ud(offset));

   struct brw_instruction *insn = next_insn(p, BRW_OPCODE_SEND);
   insn->header.destreg__conditionalmod = mrf.nr;

   /* cast dest to a uword[8] vector */
   dest = retype(vec8(dest), BRW_REGISTER_TYPE_UW);

   brw_set_dest(p, insn, dest);
   if (intel->gen >= 6) {
      brw_set_src0(insn, mrf);
   } else {
      brw_set_src0(insn, brw_null_reg());
   }

   brw_set_dp_read_message(p->brw,
			   insn,
			   bind_table_index,
			   BRW_DATAPORT_OWORD_BLOCK_1_OWORDLOW,
			   BRW_DATAPORT_READ_MESSAGE_OWORD_BLOCK_READ,
			   0, /* source cache = data cache */
			   1, /* msg_length */
			   1); /* response_length (1 reg, 2 owords!) */

   brw_pop_insn_state(p);
}

/**
 * Read a set of dwords from the data port Data Cache (const buffer).
 *
 * Location (in buffer) appears as UD offsets in the register after
 * the provided mrf header reg.
 */
void brw_dword_scattered_read(struct brw_compile *p,
			      struct brw_reg dest,
			      struct brw_reg mrf,
			      uint32_t bind_table_index)
a888 9
   mrf = retype(mrf, BRW_REGISTER_TYPE_UD);

   brw_push_insn_state(p);
   brw_set_predicate_control(p, BRW_PREDICATE_NONE);
   brw_set_compression_control(p, BRW_COMPRESSION_NONE);
   brw_set_mask_control(p, BRW_MASK_DISABLE);
   brw_MOV(p, mrf, retype(brw_vec8_grf(0, 0), BRW_REGISTER_TYPE_UD));
   brw_pop_insn_state(p);

d890 6
a895 171
   insn->header.destreg__conditionalmod = mrf.nr;

   /* cast dest to a uword[8] vector */
   dest = retype(vec8(dest), BRW_REGISTER_TYPE_UW);

   brw_set_dest(p, insn, dest);
   brw_set_src0(insn, brw_null_reg());

   brw_set_dp_read_message(p->brw,
			   insn,
			   bind_table_index,
			   BRW_DATAPORT_DWORD_SCATTERED_BLOCK_8DWORDS,
			   BRW_DATAPORT_READ_MESSAGE_DWORD_SCATTERED_READ,
			   0, /* source cache = data cache */
			   2, /* msg_length */
			   1); /* response_length */
}



/**
 * Read float[4] constant(s) from VS constant buffer.
 * For relative addressing, two float[4] constants will be read into 'dest'.
 * Otherwise, one float[4] constant will be read into the lower half of 'dest'.
 */
void brw_dp_READ_4_vs(struct brw_compile *p,
                      struct brw_reg dest,
                      GLuint location,
                      GLuint bind_table_index)
{
   struct intel_context *intel = &p->brw->intel;
   struct brw_instruction *insn;
   GLuint msg_reg_nr = 1;

   if (intel->gen >= 6)
      location /= 16;

   /* Setup MRF[1] with location/offset into const buffer */
   brw_push_insn_state(p);
   brw_set_access_mode(p, BRW_ALIGN_1);
   brw_set_compression_control(p, BRW_COMPRESSION_NONE);
   brw_set_mask_control(p, BRW_MASK_DISABLE);
   brw_set_predicate_control(p, BRW_PREDICATE_NONE);
   brw_MOV(p, retype(brw_vec1_reg(BRW_MESSAGE_REGISTER_FILE, msg_reg_nr, 2),
		     BRW_REGISTER_TYPE_UD),
	   brw_imm_ud(location));
   brw_pop_insn_state(p);

   insn = next_insn(p, BRW_OPCODE_SEND);

   insn->header.predicate_control = BRW_PREDICATE_NONE;
   insn->header.compression_control = BRW_COMPRESSION_NONE;
   insn->header.destreg__conditionalmod = msg_reg_nr;
   insn->header.mask_control = BRW_MASK_DISABLE;

   brw_set_dest(p, insn, dest);
   if (intel->gen >= 6) {
      brw_set_src0(insn, brw_message_reg(msg_reg_nr));
   } else {
      brw_set_src0(insn, brw_null_reg());
   }

   brw_set_dp_read_message(p->brw,
			   insn,
			   bind_table_index,
			   0,
			   BRW_DATAPORT_READ_MESSAGE_OWORD_BLOCK_READ, /* msg_type */
			   0, /* source cache = data cache */
			   1, /* msg_length */
			   1); /* response_length (1 Oword) */
}

/**
 * Read a float[4] constant per vertex from VS constant buffer, with
 * relative addressing.
 */
void brw_dp_READ_4_vs_relative(struct brw_compile *p,
			       struct brw_reg dest,
			       struct brw_reg addr_reg,
			       GLuint offset,
			       GLuint bind_table_index)
{
   struct intel_context *intel = &p->brw->intel;
   struct brw_reg src = brw_vec8_grf(0, 0);
   int msg_type;

   /* Setup MRF[1] with offset into const buffer */
   brw_push_insn_state(p);
   brw_set_access_mode(p, BRW_ALIGN_1);
   brw_set_compression_control(p, BRW_COMPRESSION_NONE);
   brw_set_mask_control(p, BRW_MASK_DISABLE);
   brw_set_predicate_control(p, BRW_PREDICATE_NONE);

   /* M1.0 is block offset 0, M1.4 is block offset 1, all other
    * fields ignored.
    */
   brw_ADD(p, retype(brw_message_reg(1), BRW_REGISTER_TYPE_D),
	   addr_reg, brw_imm_d(offset));
   brw_pop_insn_state(p);

   gen6_resolve_implied_move(p, &src, 0);
   struct brw_instruction *insn = next_insn(p, BRW_OPCODE_SEND);

   insn->header.predicate_control = BRW_PREDICATE_NONE;
   insn->header.compression_control = BRW_COMPRESSION_NONE;
   insn->header.destreg__conditionalmod = 0;
   insn->header.mask_control = BRW_MASK_DISABLE;

   brw_set_dest(p, insn, dest);
   brw_set_src0(insn, src);

   if (intel->gen == 6)
      msg_type = GEN6_DATAPORT_READ_MESSAGE_OWORD_DUAL_BLOCK_READ;
   else if (intel->gen == 5 || intel->is_g4x)
      msg_type = G45_DATAPORT_READ_MESSAGE_OWORD_DUAL_BLOCK_READ;
   else
      msg_type = BRW_DATAPORT_READ_MESSAGE_OWORD_DUAL_BLOCK_READ;

   brw_set_dp_read_message(p->brw,
			   insn,
			   bind_table_index,
			   BRW_DATAPORT_OWORD_DUAL_BLOCK_1OWORD,
			   msg_type,
			   0, /* source cache = data cache */
			   2, /* msg_length */
			   1); /* response_length */
}



void brw_fb_WRITE(struct brw_compile *p,
		  int dispatch_width,
                  struct brw_reg dest,
                  GLuint msg_reg_nr,
                  struct brw_reg src0,
                  GLuint binding_table_index,
                  GLuint msg_length,
                  GLuint response_length,
                  GLboolean eot,
                  GLboolean header_present)
{
   struct intel_context *intel = &p->brw->intel;
   struct brw_instruction *insn;
   GLuint msg_control, msg_type;

   if (intel->gen >= 6 && binding_table_index == 0) {
      insn = next_insn(p, BRW_OPCODE_SENDC);
   } else {
      insn = next_insn(p, BRW_OPCODE_SEND);
   }
   /* The execution mask is ignored for render target writes. */
   insn->header.predicate_control = 0;
   insn->header.compression_control = BRW_COMPRESSION_NONE;

   if (intel->gen >= 6) {
       /* headerless version, just submit color payload */
       src0 = brw_message_reg(msg_reg_nr);

       msg_type = BRW_DATAPORT_WRITE_MESSAGE_RENDER_TARGET_WRITE_GEN6;
   } else {
      insn->header.destreg__conditionalmod = msg_reg_nr;

      msg_type = BRW_DATAPORT_WRITE_MESSAGE_RENDER_TARGET_WRITE;
   }

   if (dispatch_width == 16)
      msg_control = BRW_DATAPORT_RENDER_TARGET_WRITE_SIMD16_SINGLE_SOURCE;
   else
      msg_control = BRW_DATAPORT_RENDER_TARGET_WRITE_SIMD8_SINGLE_SOURCE_SUBSPAN01;

   brw_set_dest(p, insn, dest);
d897 1
a897 2
   brw_set_dp_write_message(p->brw,
			    insn,
d899 2
a900 2
			    msg_control,
			    msg_type,
a901 1
			    header_present,
d903 2
a904 3
			    response_length,
			    eot,
			    0 /* send_commit_msg */);
d908 1
a908 5
/**
 * Texture sample instruction.
 * Note: the msg_type plus msg_length values determine exactly what kind
 * of sampling operation is performed.  See volume 4, page 161 of docs.
 */
d919 1
a919 3
		GLboolean eot,
		GLuint header_present,
		GLuint simd_mode)
a920 1
   struct intel_context *intel = &p->brw->intel;
d922 3
a924 3

   if (writemask == 0) {
      /*printf("%s: zero writemask??\n", __FUNCTION__); */
d956 1
a956 1
         /* printf("need stall %x %x\n", newmask , writemask); */
a958 2
	 GLboolean dispatch_16 = GL_FALSE;

d960 1
a960 5

	 guess_execution_size(p, p->current, dest);
	 if (p->current->header.execution_size == BRW_EXECUTE_16)
	    dispatch_16 = GL_TRUE;

d968 1
a968 2
	 brw_MOV(p, retype(m1, BRW_REGISTER_TYPE_UD),
		 retype(brw_vec8_grf(0,0), BRW_REGISTER_TYPE_UD));
d975 1
a975 7

	 /* For 16-wide dispatch, masked channels are skipped in the
	  * response.  For 8-wide, masked channels still take up slots,
	  * and are just not written to.
	  */
	 if (dispatch_16)
	    response_length = len * 2;
d980 1
a980 1
      struct brw_instruction *insn;
a981 3
      gen6_resolve_implied_move(p, &src0, msg_reg_nr);

      insn = next_insn(p, BRW_OPCODE_SEND);
d984 1
a984 2
      if (intel->gen < 6)
	  insn->header.destreg__conditionalmod = msg_reg_nr;
d986 1
a986 1
      brw_set_dest(p, insn, dest);
d988 1
a988 1
      brw_set_sampler_message(p->brw, insn,
d994 1
a994 3
			      eot,
			      header_present,
			      simd_mode);
d997 2
a998 1
   if (need_stall) {
d1004 2
a1005 3
      brw_set_compression_control(p, BRW_COMPRESSION_NONE);
      brw_MOV(p, retype(reg, BRW_REGISTER_TYPE_UD),
	      retype(reg, BRW_REGISTER_TYPE_UD));
d1028 1
a1028 2
   struct intel_context *intel = &p->brw->intel;
   struct brw_instruction *insn;
d1030 1
a1030 1
   gen6_resolve_implied_move(p, &src0, msg_reg_nr);
d1032 1
a1032 5
   insn = next_insn(p, BRW_OPCODE_SEND);

   assert(msg_length < BRW_MAX_MRF);

   brw_set_dest(p, insn, dest);
d1036 1
a1036 2
   if (intel->gen < 6)
      insn->header.destreg__conditionalmod = msg_reg_nr;
d1038 1
a1038 2
   brw_set_urb_message(p->brw,
		       insn,
a1048 101
static int
brw_find_next_block_end(struct brw_compile *p, int start)
{
   int ip;

   for (ip = start + 1; ip < p->nr_insn; ip++) {
      struct brw_instruction *insn = &p->store[ip];

      switch (insn->header.opcode) {
      case BRW_OPCODE_ENDIF:
      case BRW_OPCODE_ELSE:
      case BRW_OPCODE_WHILE:
	 return ip;
      }
   }
   assert(!"not reached");
   return start + 1;
}

/* There is no DO instruction on gen6, so to find the end of the loop
 * we have to see if the loop is jumping back before our start
 * instruction.
 */
static int
brw_find_loop_end(struct brw_compile *p, int start)
{
   int ip;
   int br = 2;

   for (ip = start + 1; ip < p->nr_insn; ip++) {
      struct brw_instruction *insn = &p->store[ip];

      if (insn->header.opcode == BRW_OPCODE_WHILE) {
	 if (ip + insn->bits1.branch_gen6.jump_count / br < start)
	    return ip;
      }
   }
   assert(!"not reached");
   return start + 1;
}

/* After program generation, go back and update the UIP and JIP of
 * BREAK and CONT instructions to their correct locations.
 */
void
brw_set_uip_jip(struct brw_compile *p)
{
   struct intel_context *intel = &p->brw->intel;
   int ip;
   int br = 2;

   if (intel->gen < 6)
      return;

   for (ip = 0; ip < p->nr_insn; ip++) {
      struct brw_instruction *insn = &p->store[ip];

      switch (insn->header.opcode) {
      case BRW_OPCODE_BREAK:
	 insn->bits3.break_cont.jip = br * (brw_find_next_block_end(p, ip) - ip);
	 insn->bits3.break_cont.uip = br * (brw_find_loop_end(p, ip) - ip + 1);
	 break;
      case BRW_OPCODE_CONTINUE:
	 /* JIP is set at CONTINUE emit time, since that's when we
	  * know where the start of the loop is.
	  */
	 insn->bits3.break_cont.jip = br * (brw_find_next_block_end(p, ip) - ip);
	 assert(insn->bits3.break_cont.uip != 0);
	 assert(insn->bits3.break_cont.jip != 0);
	 break;
      }
   }
}

void brw_ff_sync(struct brw_compile *p,
		   struct brw_reg dest,
		   GLuint msg_reg_nr,
		   struct brw_reg src0,
		   GLboolean allocate,
		   GLuint response_length,
		   GLboolean eot)
{
   struct intel_context *intel = &p->brw->intel;
   struct brw_instruction *insn;

   gen6_resolve_implied_move(p, &src0, msg_reg_nr);

   insn = next_insn(p, BRW_OPCODE_SEND);
   brw_set_dest(p, insn, dest);
   brw_set_src0(insn, src0);
   brw_set_src1(insn, brw_imm_d(0));

   if (intel->gen < 6)
       insn->header.destreg__conditionalmod = msg_reg_nr;

   brw_set_ff_sync_message(p->brw,
			   insn,
			   allocate,
			   response_length,
			   eot);
}
@


1.1.1.4
log
@Import Mesa 9.2.0
@
text
@d37 2
a38 1
#include "glsl/ralloc.h"
d62 1
a62 1
void
d67 2
a68 5
   struct brw_context *brw = p->brw;
   if (brw->gen < 6)
      return;

   if (src->file == BRW_MESSAGE_REGISTER_FILE)
a81 17
static void
gen7_convert_mrf_to_grf(struct brw_compile *p, struct brw_reg *reg)
{
   /* From the Ivybridge PRM, Volume 4 Part 3, page 218 ("send"):
    * "The send with EOT should use register space R112-R127 for <src>. This is
    *  to enable loading of a new thread into the same slot while the message
    *  with EOT for current thread is pending dispatch."
    *
    * Since we're pretending to have 16 MRFs anyway, we may as well use the
    * registers required for messages with EOT.
    */
   struct brw_context *brw = p->brw;
   if (brw->gen == 7 && reg->file == BRW_MESSAGE_REGISTER_FILE) {
      reg->file = BRW_GENERAL_REGISTER_FILE;
      reg->nr += GEN7_MRF_HACK_START;
   }
}
d83 3
a85 4

void
brw_set_dest(struct brw_compile *p, struct brw_instruction *insn,
	     struct brw_reg dest)
a90 2
   gen7_convert_mrf_to_grf(p, &dest);

d107 1
a107 4
	 /* From the Ivybridge PRM, Vol 4, Part 3, Section 5.2.4.1:
	  *    Although Dst.HorzStride is a don't care for Align16, HW needs
	  *    this to be programmed as "01".
	  */
d213 2
a214 3
void
brw_set_src0(struct brw_compile *p, struct brw_instruction *insn,
	     struct brw_reg reg)
a215 2
   struct brw_context *brw = p->brw;

a218 13
   gen7_convert_mrf_to_grf(p, &reg);

   if (brw->gen >= 6 && (insn->header.opcode == BRW_OPCODE_SEND ||
                           insn->header.opcode == BRW_OPCODE_SENDC)) {
      /* Any source modifiers or regions will be ignored, since this just
       * identifies the MRF/GRF to start reading the message contents from.
       * Check for some likely failures.
       */
      assert(!reg.negate);
      assert(!reg.abs);
      assert(reg.address_mode == BRW_ADDRESS_DIRECT);
   }

d289 2
a290 3
void brw_set_src1(struct brw_compile *p,
		  struct brw_instruction *insn,
		  struct brw_reg reg)
d294 1
a294 4
   if (reg.type != BRW_ARCHITECTURE_REGISTER_FILE)
      assert(reg.nr < 128);

   gen7_convert_mrf_to_grf(p, &reg);
a355 42
/**
 * Set the Message Descriptor and Extended Message Descriptor fields
 * for SEND messages.
 *
 * \note This zeroes out the Function Control bits, so it must be called
 *       \b before filling out any message-specific data.  Callers can
 *       choose not to fill in irrelevant bits; they will be zero.
 */
static void
brw_set_message_descriptor(struct brw_compile *p,
			   struct brw_instruction *inst,
			   enum brw_message_target sfid,
			   unsigned msg_length,
			   unsigned response_length,
			   bool header_present,
			   bool end_of_thread)
{
   struct brw_context *brw = p->brw;

   brw_set_src1(p, inst, brw_imm_d(0));

   if (brw->gen >= 5) {
      inst->bits3.generic_gen5.header_present = header_present;
      inst->bits3.generic_gen5.response_length = response_length;
      inst->bits3.generic_gen5.msg_length = msg_length;
      inst->bits3.generic_gen5.end_of_thread = end_of_thread;

      if (brw->gen >= 6) {
	 /* On Gen6+ Message target/SFID goes in bits 27:24 of the header */
	 inst->header.destreg__conditionalmod = sfid;
      } else {
	 /* Set Extended Message Descriptor (ex_desc) */
	 inst->bits2.send_gen5.sfid = sfid;
	 inst->bits2.send_gen5.end_of_thread = end_of_thread;
      }
   } else {
      inst->bits3.generic.response_length = response_length;
      inst->bits3.generic.msg_length = msg_length;
      inst->bits3.generic.msg_target = sfid;
      inst->bits3.generic.end_of_thread = end_of_thread;
   }
}
d357 2
a358 1
static void brw_set_math_message( struct brw_compile *p,
d360 2
d364 2
a365 1
				  bool low_precision,
d368 2
a369 28
   struct brw_context *brw = p->brw;
   unsigned msg_length;
   unsigned response_length;

   /* Infer message length from the function */
   switch (function) {
   case BRW_MATH_FUNCTION_POW:
   case BRW_MATH_FUNCTION_INT_DIV_QUOTIENT:
   case BRW_MATH_FUNCTION_INT_DIV_REMAINDER:
   case BRW_MATH_FUNCTION_INT_DIV_QUOTIENT_AND_REMAINDER:
      msg_length = 2;
      break;
   default:
      msg_length = 1;
      break;
   }

   /* Infer response length from the function */
   switch (function) {
   case BRW_MATH_FUNCTION_SINCOS:
   case BRW_MATH_FUNCTION_INT_DIV_QUOTIENT_AND_REMAINDER:
      response_length = 2;
      break;
   default:
      response_length = 1;
      break;
   }

d371 23
a393 15
   brw_set_message_descriptor(p, insn, BRW_SFID_MATH,
			      msg_length, response_length, false, false);
   if (brw->gen == 5) {
      insn->bits3.math_gen5.function = function;
      insn->bits3.math_gen5.int_type = integer_type;
      insn->bits3.math_gen5.precision = low_precision;
      insn->bits3.math_gen5.saturate = insn->header.saturate;
      insn->bits3.math_gen5.data_type = dataType;
      insn->bits3.math_gen5.snapshot = 0;
   } else {
      insn->bits3.math.function = function;
      insn->bits3.math.int_type = integer_type;
      insn->bits3.math.precision = low_precision;
      insn->bits3.math.saturate = insn->header.saturate;
      insn->bits3.math.data_type = dataType;
a394 1
   insn->header.saturate = 0;
d398 1
a398 1
static void brw_set_ff_sync_message(struct brw_compile *p,
d400 1
a400 1
				    bool allocate,
d402 1
a402 1
				    bool end_of_thread)
d404 19
a422 8
   brw_set_message_descriptor(p, insn, BRW_SFID_URB,
			      1, response_length, true, end_of_thread);
   insn->bits3.urb_gen5.opcode = 1; /* FF_SYNC */
   insn->bits3.urb_gen5.offset = 0; /* Not used by FF_SYNC */
   insn->bits3.urb_gen5.swizzle_control = 0; /* Not used by FF_SYNC */
   insn->bits3.urb_gen5.allocate = allocate;
   insn->bits3.urb_gen5.used = 0; /* Not used by FF_SYNC */
   insn->bits3.urb_gen5.complete = 0; /* Not used by FF_SYNC */
d425 1
a425 1
static void brw_set_urb_message( struct brw_compile *p,
d427 2
a428 2
				 bool allocate,
				 bool used,
d431 2
a432 2
				 bool end_of_thread,
				 bool complete,
d436 2
a437 1
   struct brw_context *brw = p->brw;
d439 86
a524 24
   brw_set_message_descriptor(p, insn, BRW_SFID_URB,
			      msg_length, response_length, true, end_of_thread);
   if (brw->gen == 7) {
      insn->bits3.urb_gen7.opcode = 0;	/* URB_WRITE_HWORD */
      insn->bits3.urb_gen7.offset = offset;
      assert(swizzle_control != BRW_URB_SWIZZLE_TRANSPOSE);
      insn->bits3.urb_gen7.swizzle_control = swizzle_control;
      /* per_slot_offset = 0 makes it ignore offsets in message header */
      insn->bits3.urb_gen7.per_slot_offset = 0;
      insn->bits3.urb_gen7.complete = complete;
   } else if (brw->gen >= 5) {
      insn->bits3.urb_gen5.opcode = 0;	/* URB_WRITE */
      insn->bits3.urb_gen5.offset = offset;
      insn->bits3.urb_gen5.swizzle_control = swizzle_control;
      insn->bits3.urb_gen5.allocate = allocate;
      insn->bits3.urb_gen5.used = used;	/* ? */
      insn->bits3.urb_gen5.complete = complete;
   } else {
      insn->bits3.urb.opcode = 0;	/* ? */
      insn->bits3.urb.offset = offset;
      insn->bits3.urb.swizzle_control = swizzle_control;
      insn->bits3.urb.allocate = allocate;
      insn->bits3.urb.used = used;	/* ? */
      insn->bits3.urb.complete = complete;
d528 2
a529 60
void
brw_set_dp_write_message(struct brw_compile *p,
			 struct brw_instruction *insn,
			 GLuint binding_table_index,
			 GLuint msg_control,
			 GLuint msg_type,
			 GLuint msg_length,
			 bool header_present,
			 GLuint last_render_target,
			 GLuint response_length,
			 GLuint end_of_thread,
			 GLuint send_commit_msg)
{
   struct brw_context *brw = p->brw;
   unsigned sfid;

   if (brw->gen >= 7) {
      /* Use the Render Cache for RT writes; otherwise use the Data Cache */
      if (msg_type == GEN6_DATAPORT_WRITE_MESSAGE_RENDER_TARGET_WRITE)
	 sfid = GEN6_SFID_DATAPORT_RENDER_CACHE;
      else
	 sfid = GEN7_SFID_DATAPORT_DATA_CACHE;
   } else if (brw->gen == 6) {
      /* Use the render cache for all write messages. */
      sfid = GEN6_SFID_DATAPORT_RENDER_CACHE;
   } else {
      sfid = BRW_SFID_DATAPORT_WRITE;
   }

   brw_set_message_descriptor(p, insn, sfid, msg_length, response_length,
			      header_present, end_of_thread);

   if (brw->gen >= 7) {
      insn->bits3.gen7_dp.binding_table_index = binding_table_index;
      insn->bits3.gen7_dp.msg_control = msg_control;
      insn->bits3.gen7_dp.last_render_target = last_render_target;
      insn->bits3.gen7_dp.msg_type = msg_type;
   } else if (brw->gen == 6) {
      insn->bits3.gen6_dp.binding_table_index = binding_table_index;
      insn->bits3.gen6_dp.msg_control = msg_control;
      insn->bits3.gen6_dp.last_render_target = last_render_target;
      insn->bits3.gen6_dp.msg_type = msg_type;
      insn->bits3.gen6_dp.send_commit_msg = send_commit_msg;
   } else if (brw->gen == 5) {
      insn->bits3.dp_write_gen5.binding_table_index = binding_table_index;
      insn->bits3.dp_write_gen5.msg_control = msg_control;
      insn->bits3.dp_write_gen5.last_render_target = last_render_target;
      insn->bits3.dp_write_gen5.msg_type = msg_type;
      insn->bits3.dp_write_gen5.send_commit_msg = send_commit_msg;
   } else {
      insn->bits3.dp_write.binding_table_index = binding_table_index;
      insn->bits3.dp_write.msg_control = msg_control;
      insn->bits3.dp_write.last_render_target = last_render_target;
      insn->bits3.dp_write.msg_type = msg_type;
      insn->bits3.dp_write.send_commit_msg = send_commit_msg;
   }
}

void
brw_set_dp_read_message(struct brw_compile *p,
a535 1
                        bool header_present,
d538 2
a539 13
   struct brw_context *brw = p->brw;
   unsigned sfid;

   if (brw->gen >= 7) {
      sfid = GEN7_SFID_DATAPORT_DATA_CACHE;
   } else if (brw->gen == 6) {
      if (target_cache == BRW_DATAPORT_READ_TARGET_RENDER_CACHE)
	 sfid = GEN6_SFID_DATAPORT_RENDER_CACHE;
      else
	 sfid = GEN6_SFID_DATAPORT_SAMPLER_CACHE;
   } else {
      sfid = BRW_SFID_DATAPORT_READ;
   }
d541 63
a603 2
   brw_set_message_descriptor(p, insn, sfid, msg_length, response_length,
			      header_present, false);
d605 1
a605 52
   if (brw->gen >= 7) {
      insn->bits3.gen7_dp.binding_table_index = binding_table_index;
      insn->bits3.gen7_dp.msg_control = msg_control;
      insn->bits3.gen7_dp.last_render_target = 0;
      insn->bits3.gen7_dp.msg_type = msg_type;
   } else if (brw->gen == 6) {
      insn->bits3.gen6_dp.binding_table_index = binding_table_index;
      insn->bits3.gen6_dp.msg_control = msg_control;
      insn->bits3.gen6_dp.last_render_target = 0;
      insn->bits3.gen6_dp.msg_type = msg_type;
      insn->bits3.gen6_dp.send_commit_msg = 0;
   } else if (brw->gen == 5) {
      insn->bits3.dp_read_gen5.binding_table_index = binding_table_index;
      insn->bits3.dp_read_gen5.msg_control = msg_control;
      insn->bits3.dp_read_gen5.msg_type = msg_type;
      insn->bits3.dp_read_gen5.target_cache = target_cache;
   } else if (brw->is_g4x) {
      insn->bits3.dp_read_g4x.binding_table_index = binding_table_index; /*0:7*/
      insn->bits3.dp_read_g4x.msg_control = msg_control;  /*8:10*/
      insn->bits3.dp_read_g4x.msg_type = msg_type;  /*11:13*/
      insn->bits3.dp_read_g4x.target_cache = target_cache;  /*14:15*/
   } else {
      insn->bits3.dp_read.binding_table_index = binding_table_index; /*0:7*/
      insn->bits3.dp_read.msg_control = msg_control;  /*8:11*/
      insn->bits3.dp_read.msg_type = msg_type;  /*12:13*/
      insn->bits3.dp_read.target_cache = target_cache;  /*14:15*/
   }
}

void
brw_set_sampler_message(struct brw_compile *p,
                        struct brw_instruction *insn,
                        GLuint binding_table_index,
                        GLuint sampler,
                        GLuint msg_type,
                        GLuint response_length,
                        GLuint msg_length,
                        GLuint header_present,
                        GLuint simd_mode,
                        GLuint return_format)
{
   struct brw_context *brw = p->brw;

   brw_set_message_descriptor(p, insn, BRW_SFID_SAMPLER, msg_length,
			      response_length, header_present, false);

   if (brw->gen >= 7) {
      insn->bits3.sampler_gen7.binding_table_index = binding_table_index;
      insn->bits3.sampler_gen7.sampler = sampler;
      insn->bits3.sampler_gen7.msg_type = msg_type;
      insn->bits3.sampler_gen7.simd_mode = simd_mode;
   } else if (brw->gen >= 5) {
d610 11
a620 1
   } else if (brw->is_g4x) {
d624 4
d632 5
a636 1
      insn->bits3.sampler.return_format = return_format;
d641 3
a643 3
#define next_insn brw_next_insn
struct brw_instruction *
brw_next_insn(struct brw_compile *p, GLuint opcode)
d647 1
a647 9
   if (p->nr_insn + 1 > p->store_size) {
      if (0)
         printf("incresing the store size to %d\n", p->store_size << 1);
      p->store_size <<= 1;
      p->store = reralloc(p->mem_ctx, p->store,
                          struct brw_instruction, p->store_size);
      if (!p->store)
         assert(!"realloc eu store memeory failed");
   }
a648 1
   p->next_insn_offset += 16;
d664 1
d672 1
a672 1
   brw_set_src0(p, insn, src);
d684 2
a685 97
   brw_set_src0(p, insn, src0);
   brw_set_src1(p, insn, src1);
   return insn;
}

static int
get_3src_subreg_nr(struct brw_reg reg)
{
   if (reg.vstride == BRW_VERTICAL_STRIDE_0) {
      assert(brw_is_single_value_swizzle(reg.dw1.bits.swizzle));
      return reg.subnr / 4 + BRW_GET_SWZ(reg.dw1.bits.swizzle, 0);
   } else {
      return reg.subnr / 4;
   }
}

static struct brw_instruction *brw_alu3(struct brw_compile *p,
					GLuint opcode,
					struct brw_reg dest,
					struct brw_reg src0,
					struct brw_reg src1,
					struct brw_reg src2)
{
   struct brw_context *brw = p->brw;
   struct brw_instruction *insn = next_insn(p, opcode);

   gen7_convert_mrf_to_grf(p, &dest);

   assert(insn->header.access_mode == BRW_ALIGN_16);

   assert(dest.file == BRW_GENERAL_REGISTER_FILE ||
	  dest.file == BRW_MESSAGE_REGISTER_FILE);
   assert(dest.nr < 128);
   assert(dest.address_mode == BRW_ADDRESS_DIRECT);
   assert(dest.type == BRW_REGISTER_TYPE_F ||
          dest.type == BRW_REGISTER_TYPE_D ||
          dest.type == BRW_REGISTER_TYPE_UD);
   insn->bits1.da3src.dest_reg_file = (dest.file == BRW_MESSAGE_REGISTER_FILE);
   insn->bits1.da3src.dest_reg_nr = dest.nr;
   insn->bits1.da3src.dest_subreg_nr = dest.subnr / 16;
   insn->bits1.da3src.dest_writemask = dest.dw1.bits.writemask;
   guess_execution_size(p, insn, dest);

   assert(src0.file == BRW_GENERAL_REGISTER_FILE);
   assert(src0.address_mode == BRW_ADDRESS_DIRECT);
   assert(src0.nr < 128);
   insn->bits2.da3src.src0_swizzle = src0.dw1.bits.swizzle;
   insn->bits2.da3src.src0_subreg_nr = get_3src_subreg_nr(src0);
   insn->bits2.da3src.src0_reg_nr = src0.nr;
   insn->bits1.da3src.src0_abs = src0.abs;
   insn->bits1.da3src.src0_negate = src0.negate;
   insn->bits2.da3src.src0_rep_ctrl = src0.vstride == BRW_VERTICAL_STRIDE_0;

   assert(src1.file == BRW_GENERAL_REGISTER_FILE);
   assert(src1.address_mode == BRW_ADDRESS_DIRECT);
   assert(src1.nr < 128);
   insn->bits2.da3src.src1_swizzle = src1.dw1.bits.swizzle;
   insn->bits2.da3src.src1_subreg_nr_low = get_3src_subreg_nr(src1) & 0x3;
   insn->bits3.da3src.src1_subreg_nr_high = get_3src_subreg_nr(src1) >> 2;
   insn->bits2.da3src.src1_rep_ctrl = src1.vstride == BRW_VERTICAL_STRIDE_0;
   insn->bits3.da3src.src1_reg_nr = src1.nr;
   insn->bits1.da3src.src1_abs = src1.abs;
   insn->bits1.da3src.src1_negate = src1.negate;

   assert(src2.file == BRW_GENERAL_REGISTER_FILE);
   assert(src2.address_mode == BRW_ADDRESS_DIRECT);
   assert(src2.nr < 128);
   insn->bits3.da3src.src2_swizzle = src2.dw1.bits.swizzle;
   insn->bits3.da3src.src2_subreg_nr = get_3src_subreg_nr(src2);
   insn->bits3.da3src.src2_rep_ctrl = src2.vstride == BRW_VERTICAL_STRIDE_0;
   insn->bits3.da3src.src2_reg_nr = src2.nr;
   insn->bits1.da3src.src2_abs = src2.abs;
   insn->bits1.da3src.src2_negate = src2.negate;

   if (brw->gen >= 7) {
      /* Set both the source and destination types based on dest.type,
       * ignoring the source register types.  The MAD and LRP emitters ensure
       * that all four types are float.  The BFE and BFI2 emitters, however,
       * may send us mixed D and UD types and want us to ignore that and use
       * the destination type.
       */
      switch (dest.type) {
      case BRW_REGISTER_TYPE_F:
         insn->bits1.da3src.src_type = BRW_3SRC_TYPE_F;
         insn->bits1.da3src.dst_type = BRW_3SRC_TYPE_F;
         break;
      case BRW_REGISTER_TYPE_D:
         insn->bits1.da3src.src_type = BRW_3SRC_TYPE_D;
         insn->bits1.da3src.dst_type = BRW_3SRC_TYPE_D;
         break;
      case BRW_REGISTER_TYPE_UD:
         insn->bits1.da3src.src_type = BRW_3SRC_TYPE_UD;
         insn->bits1.da3src.dst_type = BRW_3SRC_TYPE_UD;
         break;
      }
   }

a709 24
#define ALU3(OP)					\
struct brw_instruction *brw_##OP(struct brw_compile *p,	\
	      struct brw_reg dest,			\
	      struct brw_reg src0,			\
	      struct brw_reg src1,			\
	      struct brw_reg src2)   			\
{							\
   return brw_alu3(p, BRW_OPCODE_##OP, dest, src0, src1, src2);	\
}

#define ALU3F(OP)                                               \
struct brw_instruction *brw_##OP(struct brw_compile *p,         \
                                 struct brw_reg dest,           \
                                 struct brw_reg src0,           \
                                 struct brw_reg src1,           \
                                 struct brw_reg src2)           \
{                                                               \
   assert(dest.type == BRW_REGISTER_TYPE_F);                    \
   assert(src0.type == BRW_REGISTER_TYPE_F);                    \
   assert(src1.type == BRW_REGISTER_TYPE_F);                    \
   assert(src2.type == BRW_REGISTER_TYPE_F);                    \
   return brw_alu3(p, BRW_OPCODE_##OP, dest, src0, src1, src2); \
}

a713 2
 *
 * Sandybridge and later appear to round correctly without an ADD.
d723 2
a724 1
   brw_set_src0(p, rnd, src);						      \
d726 2
a727 6
   if (p->brw->gen < 6) {						      \
      /* turn on round-increments */					      \
      rnd->header.destreg__conditionalmod = BRW_CONDITIONAL_R;		      \
      add = brw_ADD(p, dest, dest, brw_imm_f(1.0f));			      \
      add->header.predicate_control = BRW_PREDICATE_NORMAL;		      \
   }									      \
a741 2
ALU1(F32TO16)
ALU1(F16TO32)
d753 1
a753 9
ALU3F(MAD)
ALU3F(LRP)
ALU1(BFREV)
ALU3(BFE)
ALU2(BFI1)
ALU3(BFI2)
ALU1(FBH)
ALU1(FBL)
ALU1(CBIT)
a781 22
struct brw_instruction *brw_AVG(struct brw_compile *p,
                                struct brw_reg dest,
                                struct brw_reg src0,
                                struct brw_reg src1)
{
   assert(dest.type == src0.type);
   assert(src0.type == src1.type);
   switch (src0.type) {
   case BRW_REGISTER_TYPE_B:
   case BRW_REGISTER_TYPE_UB:
   case BRW_REGISTER_TYPE_W:
   case BRW_REGISTER_TYPE_UW:
   case BRW_REGISTER_TYPE_D:
   case BRW_REGISTER_TYPE_UD:
      break;
   default:
      assert(!"Bad type for brw_AVG");
   }

   return brw_alu2(p, BRW_OPCODE_AVG, dest, src0, src1);
}

d822 2
a823 2
   brw_set_src0(p, insn, retype(brw_vec4_grf(0,0), BRW_REGISTER_TYPE_UD));
   brw_set_src1(p, insn, brw_imm_ud(0x0));
a849 42
static void
push_if_stack(struct brw_compile *p, struct brw_instruction *inst)
{
   p->if_stack[p->if_stack_depth] = inst - p->store;

   p->if_stack_depth++;
   if (p->if_stack_array_size <= p->if_stack_depth) {
      p->if_stack_array_size *= 2;
      p->if_stack = reralloc(p->mem_ctx, p->if_stack, int,
			     p->if_stack_array_size);
   }
}

static struct brw_instruction *
pop_if_stack(struct brw_compile *p)
{
   p->if_stack_depth--;
   return &p->store[p->if_stack[p->if_stack_depth]];
}

static void
push_loop_stack(struct brw_compile *p, struct brw_instruction *inst)
{
   if (p->loop_stack_array_size < p->loop_stack_depth) {
      p->loop_stack_array_size *= 2;
      p->loop_stack = reralloc(p->mem_ctx, p->loop_stack, int,
			       p->loop_stack_array_size);
      p->if_depth_in_loop = reralloc(p->mem_ctx, p->if_depth_in_loop, int,
				     p->loop_stack_array_size);
   }

   p->loop_stack[p->loop_stack_depth] = inst - p->store;
   p->loop_stack_depth++;
   p->if_depth_in_loop[p->loop_stack_depth] = 0;
}

static struct brw_instruction *
get_inner_do_insn(struct brw_compile *p)
{
   return &p->store[p->loop_stack[p->loop_stack_depth - 1]];
}

d862 2
d865 1
a865 2
struct brw_instruction *
brw_IF(struct brw_compile *p, GLuint execute_size)
d867 1
a867 1
   struct brw_context *brw = p->brw;
d870 8
a877 1
   insn = next_insn(p, BRW_OPCODE_IF);
d881 1
a881 1
   if (brw->gen < 6) {
d883 3
a885 3
      brw_set_src0(p, insn, brw_ip_reg());
      brw_set_src1(p, insn, brw_imm_d(0x0));
   } else if (brw->gen == 6) {
d888 2
a889 8
      brw_set_src0(p, insn, vec1(retype(brw_null_reg(), BRW_REGISTER_TYPE_D)));
      brw_set_src1(p, insn, vec1(retype(brw_null_reg(), BRW_REGISTER_TYPE_D)));
   } else {
      brw_set_dest(p, insn, vec1(retype(brw_null_reg(), BRW_REGISTER_TYPE_D)));
      brw_set_src0(p, insn, vec1(retype(brw_null_reg(), BRW_REGISTER_TYPE_D)));
      brw_set_src1(p, insn, brw_imm_ud(0));
      insn->bits3.break_cont.jip = 0;
      insn->bits3.break_cont.uip = 0;
d897 1
a897 1
      insn->header.thread_control = BRW_THREAD_SWITCH;
a900 2
   push_if_stack(p, insn);
   p->if_depth_in_loop[p->loop_stack_depth]++;
a903 3
/* This function is only used for gen6-style IF instructions with an
 * embedded comparison (conditional modifier).  It is not used on gen7.
 */
d905 2
a906 2
gen6_IF(struct brw_compile *p, uint32_t conditional,
	struct brw_reg src0, struct brw_reg src1)
d913 1
a913 5
   if (p->compressed) {
      insn->header.execution_size = BRW_EXECUTE_16;
   } else {
      insn->header.execution_size = BRW_EXECUTE_8;
   }
d915 2
a916 2
   brw_set_src0(p, insn, src0);
   brw_set_src1(p, insn, src1);
d923 1
a923 1
      insn->header.thread_control = BRW_THREAD_SWITCH;
a924 1
   push_if_stack(p, insn);
d928 11
a938 26
/**
 * In single-program-flow (SPF) mode, convert IF and ELSE into ADDs.
 */
static void
convert_IF_ELSE_to_ADD(struct brw_compile *p,
		       struct brw_instruction *if_inst,
		       struct brw_instruction *else_inst)
{
   /* The next instruction (where the ENDIF would be, if it existed) */
   struct brw_instruction *next_inst = &p->store[p->nr_insn];

   assert(p->single_program_flow);
   assert(if_inst != NULL && if_inst->header.opcode == BRW_OPCODE_IF);
   assert(else_inst == NULL || else_inst->header.opcode == BRW_OPCODE_ELSE);
   assert(if_inst->header.execution_size == BRW_EXECUTE_1);

   /* Convert IF to an ADD instruction that moves the instruction pointer
    * to the first instruction of the ELSE block.  If there is no ELSE
    * block, point to where ENDIF would be.  Reverse the predicate.
    *
    * There's no need to execute an ENDIF since we don't need to do any
    * stack operations, and if we're currently executing, we just want to
    * continue normally.
    */
   if_inst->header.opcode = BRW_OPCODE_ADD;
   if_inst->header.predicate_inverse = 1;
d940 5
a944 5
   if (else_inst != NULL) {
      /* Convert ELSE to an ADD instruction that points where the ENDIF
       * would be.
       */
      else_inst->header.opcode = BRW_OPCODE_ADD;
d946 4
a949 2
      if_inst->bits3.ud = (else_inst - if_inst + 1) * 16;
      else_inst->bits3.ud = (next_inst - else_inst) * 16;
d951 4
a954 1
      if_inst->bits3.ud = (next_inst - if_inst) * 16;
a955 1
}
d957 5
a961 25
/**
 * Patch IF and ELSE instructions with appropriate jump targets.
 */
static void
patch_IF_ELSE(struct brw_compile *p,
	      struct brw_instruction *if_inst,
	      struct brw_instruction *else_inst,
	      struct brw_instruction *endif_inst)
{
   struct brw_context *brw = p->brw;

   /* We shouldn't be patching IF and ELSE instructions in single program flow
    * mode when gen < 6, because in single program flow mode on those
    * platforms, we convert flow control instructions to conditional ADDs that
    * operate on IP (see brw_ENDIF).
    *
    * However, on Gen6, writing to IP doesn't work in single program flow mode
    * (see the SandyBridge PRM, Volume 4 part 2, p79: "When SPF is ON, IP may
    * not be updated by non-flow control instructions.").  And on later
    * platforms, there is no significant benefit to converting control flow
    * instructions to conditional ADDs.  So we do patch IF and ELSE
    * instructions in single program flow mode on those platforms.
    */
   if (brw->gen < 6)
      assert(!p->single_program_flow);
d963 1
a963 7
   assert(if_inst != NULL && if_inst->header.opcode == BRW_OPCODE_IF);
   assert(endif_inst != NULL);
   assert(else_inst == NULL || else_inst->header.opcode == BRW_OPCODE_ELSE);

   unsigned br = 1;
   /* Jump count is for 64bit data chunk each, so one 128bit instruction
    * requires 2 chunks.
d965 2
a966 2
   if (brw->gen >= 5)
      br = 2;
d968 1
a968 20
   assert(endif_inst->header.opcode == BRW_OPCODE_ENDIF);
   endif_inst->header.execution_size = if_inst->header.execution_size;

   if (else_inst == NULL) {
      /* Patch IF -> ENDIF */
      if (brw->gen < 6) {
	 /* Turn it into an IFF, which means no mask stack operations for
	  * all-false and jumping past the ENDIF.
	  */
	 if_inst->header.opcode = BRW_OPCODE_IFF;
	 if_inst->bits3.if_else.jump_count = br * (endif_inst - if_inst + 1);
	 if_inst->bits3.if_else.pop_count = 0;
	 if_inst->bits3.if_else.pad0 = 0;
      } else if (brw->gen == 6) {
	 /* As of gen6, there is no IFF and IF must point to the ENDIF. */
	 if_inst->bits1.branch_gen6.jump_count = br * (endif_inst - if_inst);
      } else {
	 if_inst->bits3.break_cont.uip = br * (endif_inst - if_inst);
	 if_inst->bits3.break_cont.jip = br * (endif_inst - if_inst);
      }
d970 1
a970 1
      else_inst->header.execution_size = if_inst->header.execution_size;
d972 4
a975 20
      /* Patch IF -> ELSE */
      if (brw->gen < 6) {
	 if_inst->bits3.if_else.jump_count = br * (else_inst - if_inst);
	 if_inst->bits3.if_else.pop_count = 0;
	 if_inst->bits3.if_else.pad0 = 0;
      } else if (brw->gen == 6) {
	 if_inst->bits1.branch_gen6.jump_count = br * (else_inst - if_inst + 1);
      }

      /* Patch ELSE -> ENDIF */
      if (brw->gen < 6) {
	 /* BRW_OPCODE_ELSE pre-gen6 should point just past the
	  * matching ENDIF.
	  */
	 else_inst->bits3.if_else.jump_count = br*(endif_inst - else_inst + 1);
	 else_inst->bits3.if_else.pop_count = 1;
	 else_inst->bits3.if_else.pad0 = 0;
      } else if (brw->gen == 6) {
	 /* BRW_OPCODE_ELSE on gen6 should point to the matching ENDIF. */
	 else_inst->bits1.branch_gen6.jump_count = br*(endif_inst - else_inst);
d977 1
a977 5
	 /* The IF instruction's JIP should point just past the ELSE */
	 if_inst->bits3.break_cont.jip = br * (else_inst - if_inst + 1);
	 /* The IF instruction's UIP and ELSE's JIP should point to ENDIF */
	 if_inst->bits3.break_cont.uip = br * (endif_inst - if_inst);
	 else_inst->bits3.break_cont.jip = br * (endif_inst - else_inst);
d980 2
d984 2
a985 2
void
brw_ELSE(struct brw_compile *p)
d987 12
a998 2
   struct brw_context *brw = p->brw;
   struct brw_instruction *insn;
d1000 1
a1000 1
   insn = next_insn(p, BRW_OPCODE_ELSE);
d1002 1
a1002 9
   if (brw->gen < 6) {
      brw_set_dest(p, insn, brw_ip_reg());
      brw_set_src0(p, insn, brw_ip_reg());
      brw_set_src1(p, insn, brw_imm_d(0x0));
   } else if (brw->gen == 6) {
      brw_set_dest(p, insn, brw_imm_w(0));
      insn->bits1.branch_gen6.jump_count = 0;
      brw_set_src0(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
      brw_set_src1(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
d1004 11
a1014 6
      brw_set_dest(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
      brw_set_src0(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
      brw_set_src1(p, insn, brw_imm_ud(0));
      insn->bits3.break_cont.jip = 0;
      insn->bits3.break_cont.uip = 0;
   }
d1016 3
a1018 3
   insn->header.compression_control = BRW_COMPRESSION_NONE;
   insn->header.mask_control = BRW_MASK_ENABLE;
   if (!p->single_program_flow)
d1021 4
a1024 2
   push_if_stack(p, insn);
}
d1026 30
a1055 24
void
brw_ENDIF(struct brw_compile *p)
{
   struct brw_context *brw = p->brw;
   struct brw_instruction *insn = NULL;
   struct brw_instruction *else_inst = NULL;
   struct brw_instruction *if_inst = NULL;
   struct brw_instruction *tmp;
   bool emit_endif = true;

   /* In single program flow mode, we can express IF and ELSE instructions
    * equivalently as ADD instructions that operate on IP.  On platforms prior
    * to Gen6, flow control instructions cause an implied thread switch, so
    * this is a significant savings.
    *
    * However, on Gen6, writing to IP doesn't work in single program flow mode
    * (see the SandyBridge PRM, Volume 4 part 2, p79: "When SPF is ON, IP may
    * not be updated by non-flow control instructions.").  And on later
    * platforms, there is no significant benefit to converting control flow
    * instructions to conditional ADDs.  So we only do this trick on Gen4 and
    * Gen5.
    */
   if (brw->gen < 6 && p->single_program_flow)
      emit_endif = false;
d1057 9
a1065 50
   /*
    * A single next_insn() may change the base adress of instruction store
    * memory(p->store), so call it first before referencing the instruction
    * store pointer from an index
    */
   if (emit_endif)
      insn = next_insn(p, BRW_OPCODE_ENDIF);

   /* Pop the IF and (optional) ELSE instructions from the stack */
   p->if_depth_in_loop[p->loop_stack_depth]--;
   tmp = pop_if_stack(p);
   if (tmp->header.opcode == BRW_OPCODE_ELSE) {
      else_inst = tmp;
      tmp = pop_if_stack(p);
   }
   if_inst = tmp;

   if (!emit_endif) {
      /* ENDIF is useless; don't bother emitting it. */
      convert_IF_ELSE_to_ADD(p, if_inst, else_inst);
      return;
   }

   if (brw->gen < 6) {
      brw_set_dest(p, insn, retype(brw_vec4_grf(0,0), BRW_REGISTER_TYPE_UD));
      brw_set_src0(p, insn, retype(brw_vec4_grf(0,0), BRW_REGISTER_TYPE_UD));
      brw_set_src1(p, insn, brw_imm_d(0x0));
   } else if (brw->gen == 6) {
      brw_set_dest(p, insn, brw_imm_w(0));
      brw_set_src0(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
      brw_set_src1(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
   } else {
      brw_set_dest(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
      brw_set_src0(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
      brw_set_src1(p, insn, brw_imm_ud(0));
   }

   insn->header.compression_control = BRW_COMPRESSION_NONE;
   insn->header.mask_control = BRW_MASK_ENABLE;
   insn->header.thread_control = BRW_THREAD_SWITCH;

   /* Also pop item off the stack in the endif instruction: */
   if (brw->gen < 6) {
      insn->bits3.if_else.jump_count = 0;
      insn->bits3.if_else.pop_count = 1;
      insn->bits3.if_else.pad0 = 0;
   } else if (brw->gen == 6) {
      insn->bits1.branch_gen6.jump_count = 2;
   } else {
      insn->bits3.break_cont.jip = 2;
a1066 1
   patch_IF_ELSE(p, if_inst, else_inst, insn);
d1069 1
a1069 1
struct brw_instruction *brw_BREAK(struct brw_compile *p)
d1071 1
a1071 1
   struct brw_context *brw = p->brw;
d1075 1
a1075 1
   if (brw->gen >= 6) {
d1077 2
a1078 2
      brw_set_src0(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
      brw_set_src1(p, insn, brw_imm_d(0x0));
d1081 2
a1082 2
      brw_set_src0(p, insn, brw_ip_reg());
      brw_set_src1(p, insn, brw_imm_d(0x0));
d1084 1
a1084 1
      insn->bits3.if_else.pop_count = p->if_depth_in_loop[p->loop_stack_depth];
d1092 2
a1093 1
struct brw_instruction *gen6_CONT(struct brw_compile *p)
d1096 1
d1100 1
a1100 1
   brw_set_src0(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
d1102 4
a1105 2
   brw_set_src0(p, insn, brw_ip_reg());
   brw_set_src1(p, insn, brw_imm_d(0x0));
d1112 1
a1112 1
struct brw_instruction *brw_CONT(struct brw_compile *p)
d1117 2
a1118 2
   brw_set_src0(p, insn, brw_ip_reg());
   brw_set_src1(p, insn, brw_imm_d(0x0));
d1123 1
a1123 19
   insn->bits3.if_else.pop_count = p->if_depth_in_loop[p->loop_stack_depth];
   return insn;
}

struct brw_instruction *gen6_HALT(struct brw_compile *p)
{
   struct brw_instruction *insn;

   insn = next_insn(p, BRW_OPCODE_HALT);
   brw_set_dest(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
   brw_set_src0(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
   brw_set_src1(p, insn, brw_imm_d(0x0)); /* UIP and JIP, updated later. */

   if (p->compressed) {
      insn->header.execution_size = BRW_EXECUTE_16;
   } else {
      insn->header.compression_control = BRW_COMPRESSION_NONE;
      insn->header.execution_size = BRW_EXECUTE_8;
   }
d1145 1
a1145 1
   struct brw_context *brw = p->brw;
d1147 1
a1147 2
   if (brw->gen >= 6 || p->single_program_flow) {
      push_loop_stack(p, &p->store[p->nr_insn]);
a1151 2
      push_loop_stack(p, insn);

d1155 2
a1156 2
      brw_set_src0(p, insn, brw_null_reg());
      brw_set_src1(p, insn, brw_null_reg());
a1167 29
/**
 * For pre-gen6, we patch BREAK/CONT instructions to point at the WHILE
 * instruction here.
 *
 * For gen6+, see brw_set_uip_jip(), which doesn't care so much about the loop
 * nesting, since it can always just point to the end of the block/current loop.
 */
static void
brw_patch_break_cont(struct brw_compile *p, struct brw_instruction *while_inst)
{
   struct brw_context *brw = p->brw;
   struct brw_instruction *do_inst = get_inner_do_insn(p);
   struct brw_instruction *inst;
   int br = (brw->gen == 5) ? 2 : 1;

   for (inst = while_inst - 1; inst != do_inst; inst--) {
      /* If the jump count is != 0, that means that this instruction has already
       * been patched because it's part of a loop inside of the one we're
       * patching.
       */
      if (inst->header.opcode == BRW_OPCODE_BREAK &&
	  inst->bits3.if_else.jump_count == 0) {
	 inst->bits3.if_else.jump_count = br * ((while_inst - inst) + 1);
      } else if (inst->header.opcode == BRW_OPCODE_CONTINUE &&
		 inst->bits3.if_else.jump_count == 0) {
	 inst->bits3.if_else.jump_count = br * (while_inst - inst);
      }
   }
}
d1169 3
a1171 1
struct brw_instruction *brw_WHILE(struct brw_compile *p)
d1173 2
a1174 2
   struct brw_context *brw = p->brw;
   struct brw_instruction *insn, *do_insn;
d1177 1
a1177 1
   if (brw->gen >= 5)
d1180 1
a1180 1
   if (brw->gen >= 7) {
a1181 11
      do_insn = get_inner_do_insn(p);

      brw_set_dest(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
      brw_set_src0(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
      brw_set_src1(p, insn, brw_imm_ud(0));
      insn->bits3.break_cont.jip = br * (do_insn - insn);

      insn->header.execution_size = BRW_EXECUTE_8;
   } else if (brw->gen == 6) {
      insn = next_insn(p, BRW_OPCODE_WHILE);
      do_insn = get_inner_do_insn(p);
d1185 2
a1186 2
      brw_set_src0(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
      brw_set_src1(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
d1188 2
a1189 1
      insn->header.execution_size = BRW_EXECUTE_8;
a1192 1
         do_insn = get_inner_do_insn(p);
d1195 2
a1196 2
	 brw_set_src0(p, insn, brw_ip_reg());
	 brw_set_src1(p, insn, brw_imm_d((do_insn - insn) * 16));
a1199 1
         do_insn = get_inner_do_insn(p);
d1204 2
a1205 2
	 brw_set_src0(p, insn, brw_ip_reg());
	 brw_set_src1(p, insn, brw_imm_d(0));
a1210 2

	 brw_patch_break_cont(p, insn);
a1215 2
   p->loop_stack_depth--;

d1222 2
a1223 1
void brw_land_fwd_jump(struct brw_compile *p, int jmp_insn_idx)
d1225 2
a1226 2
   struct brw_context *brw = p->brw;
   struct brw_instruction *jmp_insn = &p->store[jmp_insn_idx];
d1229 2
a1230 2
   if (brw->gen >= 5)
      jmpi = 2;
d1235 1
a1235 1
   jmp_insn->bits3.ud = jmpi * (p->nr_insn - jmp_insn_idx - 1);
a1249 1
   struct brw_context *brw = p->brw;
d1254 2
a1255 2
   brw_set_src0(p, insn, src0);
   brw_set_src1(p, insn, src1);
a1268 14

   /* Item WaCMPInstNullDstForcesThreadSwitch in the Haswell Bspec workarounds
    * page says:
    *    "Any CMP instruction with a null destination must use a {switch}."
    *
    * It also applies to other Gen7 platforms (IVB, BYT) even though it isn't
    * mentioned on their work-arounds pages.
    */
   if (brw->gen == 7) {
      if (dest.file == BRW_ARCHITECTURE_REGISTER_FILE &&
          dest.nr == BRW_ARF_NULL) {
         insn->header.thread_control = BRW_THREAD_SWITCH;
      }
   }
d1279 2
a1280 2
   brw_set_src0(p, insn, src);
   brw_set_src1(p, insn, brw_null_reg());
d1296 1
d1302 1
a1302 1
   struct brw_context *brw = p->brw;
d1304 1
a1304 1
   if (brw->gen >= 6) {
d1307 1
a1307 2
      assert(dest.file == BRW_GENERAL_REGISTER_FILE ||
             (brw->gen >= 7 && dest.file == BRW_MESSAGE_REGISTER_FILE));
d1311 1
a1311 2
      if (brw->gen == 6)
	 assert(src.hstride == BRW_HORIZONTAL_STRIDE_1);
d1313 3
a1315 5
      /* Source modifiers are ignored for extended math instructions on Gen6. */
      if (brw->gen == 6) {
	 assert(!src.negate);
	 assert(!src.abs);
      }
d1317 2
a1318 5
      if (function == BRW_MATH_FUNCTION_INT_DIV_QUOTIENT ||
	  function == BRW_MATH_FUNCTION_INT_DIV_REMAINDER ||
	  function == BRW_MATH_FUNCTION_INT_DIV_QUOTIENT_AND_REMAINDER) {
	 assert(src.type != BRW_REGISTER_TYPE_F);
      } else {
d1326 1
d1329 2
a1330 2
      brw_set_src0(p, insn, src);
      brw_set_src1(p, insn, brw_null_reg());
d1333 2
a1334 1

d1342 2
a1343 2
      brw_set_src0(p, insn, src);
      brw_set_math_message(p,
d1345 1
d1347 1
a1347 1
			   src.type == BRW_REGISTER_TYPE_D,
d1349 1
d1362 1
a1362 1
   struct brw_context *brw = p->brw;
d1365 5
a1369 2
   assert(dest.file == BRW_GENERAL_REGISTER_FILE ||
          (brw->gen >= 7 && dest.file == BRW_MESSAGE_REGISTER_FILE));
d1374 2
a1375 4
   if (brw->gen == 6) {
      assert(src0.hstride == BRW_HORIZONTAL_STRIDE_1);
      assert(src1.hstride == BRW_HORIZONTAL_STRIDE_1);
   }
d1377 2
a1378 6
   if (function == BRW_MATH_FUNCTION_INT_DIV_QUOTIENT ||
       function == BRW_MATH_FUNCTION_INT_DIV_REMAINDER ||
       function == BRW_MATH_FUNCTION_INT_DIV_QUOTIENT_AND_REMAINDER) {
      assert(src0.type != BRW_REGISTER_TYPE_F);
      assert(src1.type != BRW_REGISTER_TYPE_F);
   } else {
d1383 5
a1387 7
   /* Source modifiers are ignored for extended math instructions on Gen6. */
   if (brw->gen == 6) {
      assert(!src0.negate);
      assert(!src0.abs);
      assert(!src1.negate);
      assert(!src1.abs);
   }
d1395 78
a1472 2
   brw_set_src0(p, insn, src0);
   brw_set_src1(p, insn, src1);
d1488 2
a1489 2
   struct brw_context *brw = p->brw;
   uint32_t msg_control, msg_type;
a1491 3
   if (brw->gen >= 6)
      offset /= 16;

d1548 1
a1548 1
      if (brw->gen >= 6) {
d1557 1
a1557 10
      if (brw->gen >= 6) {
	 brw_set_src0(p, insn, mrf);
      } else {
	 brw_set_src0(p, insn, brw_null_reg());
      }

      if (brw->gen >= 6)
	 msg_type = GEN6_DATAPORT_WRITE_MESSAGE_OWORD_BLOCK_WRITE;
      else
	 msg_type = BRW_DATAPORT_WRITE_MESSAGE_OWORD_BLOCK_WRITE;
d1559 1
a1559 1
      brw_set_dp_write_message(p,
d1563 1
a1563 1
			       msg_type,
d1565 2
a1566 2
			       true, /* header_present */
			       0, /* not a render target */
a1587 1
   struct brw_context *brw = p->brw;
a1590 3
   if (brw->gen >= 6)
      offset /= 16;

d1627 1
a1627 5
      if (brw->gen >= 6) {
	 brw_set_src0(p, insn, mrf);
      } else {
	 brw_set_src0(p, insn, brw_null_reg());
      }
d1629 1
a1629 1
      brw_set_dp_read_message(p,
d1634 1
a1634 1
			      BRW_DATAPORT_READ_TARGET_RENDER_CACHE,
a1635 1
                              true, /* header_present */
d1651 1
a1651 1
   struct brw_context *brw = p->brw;
d1654 1
a1654 1
   if (brw->gen >= 6)
d1680 2
a1681 2
   if (brw->gen >= 6) {
      brw_set_src0(p, insn, mrf);
d1683 1
a1683 1
      brw_set_src0(p, insn, brw_null_reg());
d1686 1
a1686 1
   brw_set_dp_read_message(p,
d1691 1
a1691 1
			   BRW_DATAPORT_READ_TARGET_DATA_CACHE,
a1692 1
                           true, /* header_present */
d1698 150
d1851 1
a1853 1
                  GLuint msg_control,
d1857 2
a1858 2
                  bool eot,
                  bool header_present)
d1860 1
a1860 1
   struct brw_context *brw = p->brw;
d1862 1
a1862 2
   GLuint msg_type;
   struct brw_reg dest;
d1864 1
a1864 6
   if (dispatch_width == 16)
      dest = retype(vec16(brw_null_reg()), BRW_REGISTER_TYPE_UW);
   else
      dest = retype(vec8(brw_null_reg()), BRW_REGISTER_TYPE_UW);

   if (brw->gen >= 6) {
d1873 3
a1875 3
   if (brw->gen >= 6) {
      /* headerless version, just submit color payload */
      src0 = brw_message_reg(msg_reg_nr);
d1877 1
a1877 1
      msg_type = GEN6_DATAPORT_WRITE_MESSAGE_RENDER_TARGET_WRITE;
d1884 5
d1890 2
a1891 2
   brw_set_src0(p, insn, src0);
   brw_set_dp_write_message(p,
d1898 1
a1898 1
			    eot, /* last render target write */
d1916 1
d1920 1
d1922 1
a1922 2
		GLuint simd_mode,
		GLuint return_format)
d1924 95
a2018 2
   struct brw_context *brw = p->brw;
   struct brw_instruction *insn;
d2020 2
a2021 1
   gen6_resolve_implied_move(p, &src0, msg_reg_nr);
d2023 8
a2030 5
   insn = next_insn(p, BRW_OPCODE_SEND);
   insn->header.predicate_control = 0; /* XXX */
   insn->header.compression_control = BRW_COMPRESSION_NONE;
   if (brw->gen < 6)
      insn->header.destreg__conditionalmod = msg_reg_nr;
a2031 11
   brw_set_dest(p, insn, dest);
   brw_set_src0(p, insn, src0);
   brw_set_sampler_message(p, insn,
                           binding_table_index,
                           sampler,
                           msg_type,
                           response_length,
                           msg_length,
                           header_present,
                           simd_mode,
                           return_format);
d2042 2
a2043 2
		   bool allocate,
		   bool used,
d2046 2
a2047 2
		   bool eot,
		   bool writes_complete,
d2051 1
a2051 1
   struct brw_context *brw = p->brw;
a2055 12
   if (brw->gen == 7) {
      /* Enable Channel Masks in the URB_WRITE_HWORD message header */
      brw_push_insn_state(p);
      brw_set_access_mode(p, BRW_ALIGN_1);
      brw_set_mask_control(p, BRW_MASK_DISABLE);
      brw_OR(p, retype(brw_vec1_reg(BRW_MESSAGE_REGISTER_FILE, msg_reg_nr, 5),
		       BRW_REGISTER_TYPE_UD),
	        retype(brw_vec1_grf(0, 5), BRW_REGISTER_TYPE_UD),
		brw_imm_ud(0xff00));
      brw_pop_insn_state(p);
   }

d2061 2
a2062 2
   brw_set_src0(p, insn, src0);
   brw_set_src1(p, insn, brw_imm_d(0));
d2064 1
a2064 1
   if (brw->gen < 6)
d2067 1
a2067 1
   brw_set_urb_message(p,
a2079 11
next_ip(struct brw_compile *p, int ip)
{
   struct brw_instruction *insn = (void *)p->store + ip;

   if (insn->header.cmpt_control)
      return ip + 8;
   else
      return ip + 16;
}

static int
a2082 1
   void *store = p->store;
d2084 2
a2085 2
   for (ip = next_ip(p, start); ip < p->next_insn_offset; ip = next_ip(p, ip)) {
      struct brw_instruction *insn = store + ip;
a2090 1
      case BRW_OPCODE_HALT:
d2094 2
a2095 2

   return 0;
a2104 1
   struct brw_context *brw = p->brw;
d2106 1
a2106 2
   int scale = 8;
   void *store = p->store;
d2108 2
a2109 5
   /* Always start after the instruction (such as a WHILE) we're trying to fix
    * up.
    */
   for (ip = next_ip(p, start); ip < p->next_insn_offset; ip = next_ip(p, ip)) {
      struct brw_instruction *insn = store + ip;
d2112 1
a2112 3
	 int jip = brw->gen == 6 ? insn->bits1.branch_gen6.jump_count
				   : insn->bits3.break_cont.jip;
	 if (ip + jip * scale <= start)
d2117 1
a2117 1
   return start;
d2121 1
a2121 1
 * BREAK, CONT, and HALT instructions to their correct locations.
d2126 1
a2126 1
   struct brw_context *brw = p->brw;
d2128 1
a2128 2
   int scale = 8;
   void *store = p->store;
d2130 1
a2130 1
   if (brw->gen < 6)
d2133 2
a2134 10
   for (ip = 0; ip < p->next_insn_offset; ip = next_ip(p, ip)) {
      struct brw_instruction *insn = store + ip;

      if (insn->header.cmpt_control) {
	 /* Fixups for compacted BREAK/CONTINUE not supported yet. */
	 assert(insn->header.opcode != BRW_OPCODE_BREAK &&
		insn->header.opcode != BRW_OPCODE_CONTINUE &&
		insn->header.opcode != BRW_OPCODE_HALT);
	 continue;
      }
a2135 1
      int block_end_ip = brw_find_next_block_end(p, ip);
d2138 2
a2139 6
         assert(block_end_ip != 0);
	 insn->bits3.break_cont.jip = (block_end_ip - ip) / scale;
	 /* Gen7 UIP points to WHILE; Gen6 points just after it */
	 insn->bits3.break_cont.uip =
	    (brw_find_loop_end(p, ip) - ip +
             (brw->gen == 6 ? 16 : 0)) / scale;
d2142 2
a2143 27
         assert(block_end_ip != 0);
	 insn->bits3.break_cont.jip = (block_end_ip - ip) / scale;
	 insn->bits3.break_cont.uip =
            (brw_find_loop_end(p, ip) - ip) / scale;

	 assert(insn->bits3.break_cont.uip != 0);
	 assert(insn->bits3.break_cont.jip != 0);
	 break;

      case BRW_OPCODE_ENDIF:
         if (block_end_ip == 0)
            insn->bits3.break_cont.jip = 2;
         else
            insn->bits3.break_cont.jip = (block_end_ip - ip) / scale;
	 break;

      case BRW_OPCODE_HALT:
	 /* From the Sandy Bridge PRM (volume 4, part 2, section 8.3.19):
	  *
	  *    "In case of the halt instruction not inside any conditional
	  *     code block, the value of <JIP> and <UIP> should be the
	  *     same. In case of the halt instruction inside conditional code
	  *     block, the <UIP> should be the end of the program, and the
	  *     <JIP> should be end of the most inner conditional code block."
	  *
	  * The uip will have already been set by whoever set up the
	  * instruction.
d2145 1
a2145 5
	 if (block_end_ip == 0) {
	    insn->bits3.break_cont.jip = insn->bits3.break_cont.uip;
	 } else {
	    insn->bits3.break_cont.jip = (block_end_ip - ip) / scale;
	 }
d2157 1
a2157 1
		   bool allocate,
d2159 1
a2159 1
		   bool eot)
d2161 1
a2161 1
   struct brw_context *brw = p->brw;
d2168 2
a2169 2
   brw_set_src0(p, insn, src0);
   brw_set_src1(p, insn, brw_imm_d(0));
d2171 2
a2172 2
   if (brw->gen < 6)
      insn->header.destreg__conditionalmod = msg_reg_nr;
d2174 1
a2174 1
   brw_set_ff_sync_message(p,
a2178 98
}

/**
 * Emit the SEND instruction necessary to generate stream output data on Gen6
 * (for transform feedback).
 *
 * If send_commit_msg is true, this is the last piece of stream output data
 * from this thread, so send the data as a committed write.  According to the
 * Sandy Bridge PRM (volume 2 part 1, section 4.5.1):
 *
 *   "Prior to End of Thread with a URB_WRITE, the kernel must ensure all
 *   writes are complete by sending the final write as a committed write."
 */
void
brw_svb_write(struct brw_compile *p,
              struct brw_reg dest,
              GLuint msg_reg_nr,
              struct brw_reg src0,
              GLuint binding_table_index,
              bool   send_commit_msg)
{
   struct brw_instruction *insn;

   gen6_resolve_implied_move(p, &src0, msg_reg_nr);

   insn = next_insn(p, BRW_OPCODE_SEND);
   brw_set_dest(p, insn, dest);
   brw_set_src0(p, insn, src0);
   brw_set_src1(p, insn, brw_imm_d(0));
   brw_set_dp_write_message(p, insn,
                            binding_table_index,
                            0, /* msg_control: ignored */
                            GEN6_DATAPORT_WRITE_MESSAGE_STREAMED_VB_WRITE,
                            1, /* msg_length */
                            true, /* header_present */
                            0, /* last_render_target: ignored */
                            send_commit_msg, /* response_length */
                            0, /* end_of_thread */
                            send_commit_msg); /* send_commit_msg */
}

/**
 * This instruction is generated as a single-channel align1 instruction by
 * both the VS and FS stages when using INTEL_DEBUG=shader_time.
 *
 * We can't use the typed atomic op in the FS because that has the execution
 * mask ANDed with the pixel mask, but we just want to write the one dword for
 * all the pixels.
 *
 * We don't use the SIMD4x2 atomic ops in the VS because want to just write
 * one u32.  So we use the same untyped atomic write message as the pixel
 * shader.
 *
 * The untyped atomic operation requires a BUFFER surface type with RAW
 * format, and is only accessible through the legacy DATA_CACHE dataport
 * messages.
 */
void brw_shader_time_add(struct brw_compile *p,
                         struct brw_reg payload,
                         uint32_t surf_index)
{
   struct brw_context *brw = p->brw;
   assert(brw->gen >= 7);

   brw_push_insn_state(p);
   brw_set_access_mode(p, BRW_ALIGN_1);
   brw_set_mask_control(p, BRW_MASK_DISABLE);
   struct brw_instruction *send = brw_next_insn(p, BRW_OPCODE_SEND);
   brw_pop_insn_state(p);

   /* We use brw_vec1_reg and unmasked because we want to increment the given
    * offset only once.
    */
   brw_set_dest(p, send, brw_vec1_reg(BRW_ARCHITECTURE_REGISTER_FILE,
                                      BRW_ARF_NULL, 0));
   brw_set_src0(p, send, brw_vec1_reg(payload.file,
                                      payload.nr, 0));

   uint32_t sfid, msg_type;
   if (brw->is_haswell) {
      sfid = HSW_SFID_DATAPORT_DATA_CACHE_1;
      msg_type = HSW_DATAPORT_DC_PORT1_UNTYPED_ATOMIC_OP;
   } else {
      sfid = GEN7_SFID_DATAPORT_DATA_CACHE;
      msg_type = GEN7_DATAPORT_DC_UNTYPED_ATOMIC_OP;
   }

   bool header_present = false;
   bool eot = false;
   uint32_t mlen = 2; /* offset, value */
   uint32_t rlen = 0;
   brw_set_message_descriptor(p, send, sfid, mlen, rlen, header_present, eot);

   send->bits3.ud |= msg_type << 14;
   send->bits3.ud |= 0 << 13; /* no return data */
   send->bits3.ud |= 1 << 12; /* SIMD8 mode */
   send->bits3.ud |= BRW_AOP_ADD << 8;
   send->bits3.ud |= surf_index << 0;
@


1.1.1.5
log
@Import Mesa 10.2.3
@
text
@d3 1
a3 1
 Intel funded Tungsten Graphics to
d5 1
a5 1

d13 1
a13 1

d17 1
a17 1

d25 1
a25 1

d29 1
a29 1
  *   Keith Whitwell <keithw@@vmware.com>
d31 1
a31 1

d64 1
a64 1
			  unsigned msg_reg_nr)
a101 55
/**
 * Convert a brw_reg_type enumeration value into the hardware representation.
 *
 * The hardware encoding may depend on whether the value is an immediate.
 */
unsigned
brw_reg_type_to_hw_type(const struct brw_context *brw,
                        enum brw_reg_type type, unsigned file)
{
   if (file == BRW_IMMEDIATE_VALUE) {
      const static int imm_hw_types[] = {
         [BRW_REGISTER_TYPE_UD] = BRW_HW_REG_TYPE_UD,
         [BRW_REGISTER_TYPE_D]  = BRW_HW_REG_TYPE_D,
         [BRW_REGISTER_TYPE_UW] = BRW_HW_REG_TYPE_UW,
         [BRW_REGISTER_TYPE_W]  = BRW_HW_REG_TYPE_W,
         [BRW_REGISTER_TYPE_F]  = BRW_HW_REG_TYPE_F,
         [BRW_REGISTER_TYPE_UB] = -1,
         [BRW_REGISTER_TYPE_B]  = -1,
         [BRW_REGISTER_TYPE_UV] = BRW_HW_REG_IMM_TYPE_UV,
         [BRW_REGISTER_TYPE_VF] = BRW_HW_REG_IMM_TYPE_VF,
         [BRW_REGISTER_TYPE_V]  = BRW_HW_REG_IMM_TYPE_V,
         [BRW_REGISTER_TYPE_DF] = GEN8_HW_REG_IMM_TYPE_DF,
         [BRW_REGISTER_TYPE_HF] = GEN8_HW_REG_IMM_TYPE_HF,
         [BRW_REGISTER_TYPE_UQ] = GEN8_HW_REG_TYPE_UQ,
         [BRW_REGISTER_TYPE_Q]  = GEN8_HW_REG_TYPE_Q,
      };
      assert(type < ARRAY_SIZE(imm_hw_types));
      assert(imm_hw_types[type] != -1);
      assert(brw->gen >= 8 || type < BRW_REGISTER_TYPE_DF);
      return imm_hw_types[type];
   } else {
      /* Non-immediate registers */
      const static int hw_types[] = {
         [BRW_REGISTER_TYPE_UD] = BRW_HW_REG_TYPE_UD,
         [BRW_REGISTER_TYPE_D]  = BRW_HW_REG_TYPE_D,
         [BRW_REGISTER_TYPE_UW] = BRW_HW_REG_TYPE_UW,
         [BRW_REGISTER_TYPE_W]  = BRW_HW_REG_TYPE_W,
         [BRW_REGISTER_TYPE_UB] = BRW_HW_REG_NON_IMM_TYPE_UB,
         [BRW_REGISTER_TYPE_B]  = BRW_HW_REG_NON_IMM_TYPE_B,
         [BRW_REGISTER_TYPE_F]  = BRW_HW_REG_TYPE_F,
         [BRW_REGISTER_TYPE_UV] = -1,
         [BRW_REGISTER_TYPE_VF] = -1,
         [BRW_REGISTER_TYPE_V]  = -1,
         [BRW_REGISTER_TYPE_DF] = GEN7_HW_REG_NON_IMM_TYPE_DF,
         [BRW_REGISTER_TYPE_HF] = GEN8_HW_REG_NON_IMM_TYPE_HF,
         [BRW_REGISTER_TYPE_UQ] = GEN8_HW_REG_TYPE_UQ,
         [BRW_REGISTER_TYPE_Q]  = GEN8_HW_REG_TYPE_Q,
      };
      assert(type < ARRAY_SIZE(hw_types));
      assert(hw_types[type] != -1);
      assert(brw->gen >= 7 || type < BRW_REGISTER_TYPE_DF);
      assert(brw->gen >= 8 || type < BRW_REGISTER_TYPE_HF);
      return hw_types[type];
   }
}
d114 1
a114 2
   insn->bits1.da1.dest_reg_type =
      brw_reg_type_to_hw_type(p->brw, dest.type, dest.file);
d117 1
a117 1
   if (dest.address_mode == BRW_ADDRESS_DIRECT) {
a128 4
         if (dest.file == BRW_GENERAL_REGISTER_FILE ||
             dest.file == BRW_MESSAGE_REGISTER_FILE) {
            assert(dest.dw1.bits.writemask != 0);
         }
d263 1
a263 2
   insn->bits1.da1.src0_reg_type =
      brw_reg_type_to_hw_type(brw, reg.type, reg.file);
d270 1
a270 1

d274 1
a274 1
      insn->bits1.da1.src1_reg_type = insn->bits1.da1.src0_reg_type;
d276 1
a276 1
   else
d292 1
a292 1
	    insn->bits2.ia1.src0_indirect_offset = reg.dw1.bits.indirect_offset;
d300 1
a300 1
	 if (reg.width == BRW_WIDTH_1 &&
d344 1
a344 2
   insn->bits1.da1.src1_reg_type =
      brw_reg_type_to_hw_type(p->brw, reg.type, reg.file);
d372 1
a372 1
	 if (reg.width == BRW_WIDTH_1 &&
d446 2
a447 2
				  unsigned function,
				  unsigned integer_type,
d449 1
a449 1
				  unsigned dataType )
d503 1
a503 1
				    unsigned response_length,
d518 8
a525 5
                                 enum brw_urb_write_flags flags,
				 unsigned msg_length,
				 unsigned response_length,
				 unsigned offset,
				 unsigned swizzle_control )
d530 1
a530 2
			      msg_length, response_length, true,
                              flags & BRW_URB_WRITE_EOT);
d532 1
a532 6
      if (flags & BRW_URB_WRITE_OWORD) {
         assert(msg_length == 2); /* header + one OWORD of data */
         insn->bits3.urb_gen7.opcode = BRW_URB_OPCODE_WRITE_OWORD;
      } else {
         insn->bits3.urb_gen7.opcode = BRW_URB_OPCODE_WRITE_HWORD;
      }
d536 3
a538 3
      insn->bits3.urb_gen7.per_slot_offset =
         flags & BRW_URB_WRITE_PER_SLOT_OFFSET ? 1 : 0;
      insn->bits3.urb_gen7.complete = flags & BRW_URB_WRITE_COMPLETE ? 1 : 0;
d543 3
a545 3
      insn->bits3.urb_gen5.allocate = flags & BRW_URB_WRITE_ALLOCATE ? 1 : 0;
      insn->bits3.urb_gen5.used = flags & BRW_URB_WRITE_UNUSED ? 0 : 1;
      insn->bits3.urb_gen5.complete = flags & BRW_URB_WRITE_COMPLETE ? 1 : 0;
d550 3
a552 3
      insn->bits3.urb.allocate = flags & BRW_URB_WRITE_ALLOCATE ? 1 : 0;
      insn->bits3.urb.used = flags & BRW_URB_WRITE_UNUSED ? 0 : 1;
      insn->bits3.urb.complete = flags & BRW_URB_WRITE_COMPLETE ? 1 : 0;
d559 4
a562 4
			 unsigned binding_table_index,
			 unsigned msg_control,
			 unsigned msg_type,
			 unsigned msg_length,
d564 4
a567 4
			 unsigned last_render_target,
			 unsigned response_length,
			 unsigned end_of_thread,
			 unsigned send_commit_msg)
d617 5
a621 5
			unsigned binding_table_index,
			unsigned msg_control,
			unsigned msg_type,
			unsigned target_cache,
			unsigned msg_length,
d623 1
a623 1
			unsigned response_length)
d674 8
a681 8
                        unsigned binding_table_index,
                        unsigned sampler,
                        unsigned msg_type,
                        unsigned response_length,
                        unsigned msg_length,
                        unsigned header_present,
                        unsigned simd_mode,
                        unsigned return_format)
d713 1
a713 1
brw_next_insn(struct brw_compile *p, unsigned opcode)
d718 2
a719 4
      if (0) {
         fprintf(stderr, "incresing the store size to %d\n",
                 p->store_size << 1);
      }
d731 1
a731 1
   /* Reset this one-shot flag:
d744 1
a744 1
					 unsigned opcode,
d755 1
a755 1
					unsigned opcode,
d760 1
a760 1
   struct brw_instruction *insn = next_insn(p, opcode);
d779 1
a779 1
					unsigned opcode,
d941 2
a965 2
ALU2(ADDC)
ALU2(SUBB)
d1054 1
a1054 1
   struct brw_instruction *insn = next_insn(p, BRW_OPCODE_NOP);
d1068 1
a1068 1
struct brw_instruction *brw_JMPI(struct brw_compile *p,
d1140 1
a1140 1
brw_IF(struct brw_compile *p, unsigned execute_size)
d1542 1
a1542 1
struct brw_instruction *brw_DO(struct brw_compile *p, unsigned execute_size)
d1604 1
a1604 1
   unsigned br = 1;
d1671 1
a1671 1
   unsigned jmpi = 1;
d1690 1
a1690 1
	     unsigned conditional,
d1707 1
a1707 1
    * again.
d1754 2
a1755 2
	       unsigned function,
	       unsigned msg_reg_nr,
d1757 2
a1758 2
	       unsigned data_type,
	       unsigned precision )
d1819 1
a1819 1
	       unsigned function,
d1876 1
a1876 1
				   unsigned offset)
d1988 1
a1988 1
			     unsigned offset)
a2050 42
void
gen7_block_read_scratch(struct brw_compile *p,
                        struct brw_reg dest,
                        int num_regs,
                        unsigned offset)
{
   dest = retype(dest, BRW_REGISTER_TYPE_UW);

   struct brw_instruction *insn = next_insn(p, BRW_OPCODE_SEND);

   assert(insn->header.predicate_control == BRW_PREDICATE_NONE);
   insn->header.compression_control = BRW_COMPRESSION_NONE;

   brw_set_dest(p, insn, dest);

   /* The HW requires that the header is present; this is to get the g0.5
    * scratch offset.
    */
   bool header_present = true;
   brw_set_src0(p, insn, brw_vec8_grf(0, 0));

   brw_set_message_descriptor(p, insn,
                              GEN7_SFID_DATAPORT_DATA_CACHE,
                              1, /* mlen: just g0 */
                              num_regs,
                              header_present,
                              false);

   insn->bits3.ud |= GEN7_DATAPORT_SCRATCH_READ;

   assert(num_regs == 1 || num_regs == 2 || num_regs == 4);
   insn->bits3.ud |= (num_regs - 1) << GEN7_DATAPORT_SCRATCH_NUM_REGS_SHIFT;

   /* According to the docs, offset is "A 12-bit HWord offset into the memory
    * Immediate Memory buffer as specified by binding table 0xFF."  An HWORD
    * is 32 bytes, which happens to be the size of a register.
    */
   offset /= REG_SIZE;
   assert(offset < (1 << 12));
   insn->bits3.ud |= offset;
}

d2113 1
a2113 1
                  unsigned msg_reg_nr,
d2115 4
a2118 4
                  unsigned msg_control,
                  unsigned binding_table_index,
                  unsigned msg_length,
                  unsigned response_length,
d2124 1
a2124 1
   unsigned msg_type;
d2137 2
d2175 1
a2175 1
		unsigned msg_reg_nr,
d2177 8
a2184 8
		unsigned binding_table_index,
		unsigned sampler,
		unsigned msg_type,
		unsigned response_length,
		unsigned msg_length,
		unsigned header_present,
		unsigned simd_mode,
		unsigned return_format)
d2189 1
a2189 2
   if (msg_reg_nr != -1)
      gen6_resolve_implied_move(p, &src0, msg_reg_nr);
d2193 1
a2193 16

   /* From the 965 PRM (volume 4, part 1, section 14.2.41):
    *
    *    "Instruction compression is not allowed for this instruction (that
    *     is, send). The hardware behavior is undefined if this instruction is
    *     set as compressed. However, compress control can be set to "SecHalf"
    *     to affect the EMask generation."
    *
    * No similar wording is found in later PRMs, but there are examples
    * utilizing send with SecHalf.  More importantly, SIMD8 sampler messages
    * are allowed in SIMD16 mode and they could not work without SecHalf.  For
    * these reasons, we allow BRW_COMPRESSION_2NDHALF here.
    */
   if (insn->header.compression_control != BRW_COMPRESSION_2NDHALF)
      insn->header.compression_control = BRW_COMPRESSION_NONE;

d2216 1
a2216 1
		   unsigned msg_reg_nr,
d2218 8
a2225 5
                   enum brw_urb_write_flags flags,
		   unsigned msg_length,
		   unsigned response_length,
		   unsigned offset,
		   unsigned swizzle)
d2232 1
a2232 1
   if (brw->gen == 7 && !(flags & BRW_URB_WRITE_USE_CHANNEL_MASKS)) {
d2257 2
a2258 1
		       flags,
d2260 3
a2262 1
		       response_length,
d2406 1
a2406 1
		   unsigned msg_reg_nr,
d2409 1
a2409 1
		   unsigned response_length,
d2446 1
a2446 1
              unsigned msg_reg_nr,
d2448 1
a2448 1
              unsigned binding_table_index,
a2470 118
static void
brw_set_dp_untyped_atomic_message(struct brw_compile *p,
                                  struct brw_instruction *insn,
                                  unsigned atomic_op,
                                  unsigned bind_table_index,
                                  unsigned msg_length,
                                  unsigned response_length,
                                  bool header_present)
{
   if (p->brw->is_haswell) {
      brw_set_message_descriptor(p, insn, HSW_SFID_DATAPORT_DATA_CACHE_1,
                                 msg_length, response_length,
                                 header_present, false);


      if (insn->header.access_mode == BRW_ALIGN_1) {
         if (insn->header.execution_size != BRW_EXECUTE_16)
            insn->bits3.ud |= 1 << 12; /* SIMD8 mode */

         insn->bits3.gen7_dp.msg_type =
            HSW_DATAPORT_DC_PORT1_UNTYPED_ATOMIC_OP;
      } else {
         insn->bits3.gen7_dp.msg_type =
            HSW_DATAPORT_DC_PORT1_UNTYPED_ATOMIC_OP_SIMD4X2;
      }

   } else {
      brw_set_message_descriptor(p, insn, GEN7_SFID_DATAPORT_DATA_CACHE,
                                 msg_length, response_length,
                                 header_present, false);

      insn->bits3.gen7_dp.msg_type = GEN7_DATAPORT_DC_UNTYPED_ATOMIC_OP;

      if (insn->header.execution_size != BRW_EXECUTE_16)
         insn->bits3.ud |= 1 << 12; /* SIMD8 mode */
   }

   if (response_length)
      insn->bits3.ud |= 1 << 13; /* Return data expected */

   insn->bits3.gen7_dp.binding_table_index = bind_table_index;
   insn->bits3.ud |= atomic_op << 8;
}

void
brw_untyped_atomic(struct brw_compile *p,
                   struct brw_reg dest,
                   struct brw_reg mrf,
                   unsigned atomic_op,
                   unsigned bind_table_index,
                   unsigned msg_length,
                   unsigned response_length) {
   struct brw_instruction *insn = brw_next_insn(p, BRW_OPCODE_SEND);

   brw_set_dest(p, insn, retype(dest, BRW_REGISTER_TYPE_UD));
   brw_set_src0(p, insn, retype(mrf, BRW_REGISTER_TYPE_UD));
   brw_set_src1(p, insn, brw_imm_d(0));
   brw_set_dp_untyped_atomic_message(
      p, insn, atomic_op, bind_table_index, msg_length, response_length,
      insn->header.access_mode == BRW_ALIGN_1);
}

static void
brw_set_dp_untyped_surface_read_message(struct brw_compile *p,
                                        struct brw_instruction *insn,
                                        unsigned bind_table_index,
                                        unsigned msg_length,
                                        unsigned response_length,
                                        bool header_present)
{
   const unsigned dispatch_width =
      (insn->header.execution_size == BRW_EXECUTE_16 ? 16 : 8);
   const unsigned num_channels = response_length / (dispatch_width / 8);

   if (p->brw->is_haswell) {
      brw_set_message_descriptor(p, insn, HSW_SFID_DATAPORT_DATA_CACHE_1,
                                 msg_length, response_length,
                                 header_present, false);

      insn->bits3.gen7_dp.msg_type = HSW_DATAPORT_DC_PORT1_UNTYPED_SURFACE_READ;
   } else {
      brw_set_message_descriptor(p, insn, GEN7_SFID_DATAPORT_DATA_CACHE,
                                 msg_length, response_length,
                                 header_present, false);

      insn->bits3.gen7_dp.msg_type = GEN7_DATAPORT_DC_UNTYPED_SURFACE_READ;
   }

   if (insn->header.access_mode == BRW_ALIGN_1) {
      if (dispatch_width == 16)
         insn->bits3.ud |= 1 << 12; /* SIMD16 mode */
      else
         insn->bits3.ud |= 2 << 12; /* SIMD8 mode */
   }

   insn->bits3.gen7_dp.binding_table_index = bind_table_index;

   /* Set mask of 32-bit channels to drop. */
   insn->bits3.ud |= (0xf & (0xf << num_channels)) << 8;
}

void
brw_untyped_surface_read(struct brw_compile *p,
                         struct brw_reg dest,
                         struct brw_reg mrf,
                         unsigned bind_table_index,
                         unsigned msg_length,
                         unsigned response_length)
{
   struct brw_instruction *insn = next_insn(p, BRW_OPCODE_SEND);

   brw_set_dest(p, insn, retype(dest, BRW_REGISTER_TYPE_UD));
   brw_set_src0(p, insn, retype(mrf, BRW_REGISTER_TYPE_UD));
   brw_set_dp_untyped_surface_read_message(
      p, insn, bind_table_index, msg_length, response_length,
      insn->header.access_mode == BRW_ALIGN_1);
}

d2507 21
a2527 4
   brw_set_dp_untyped_atomic_message(p, send, BRW_AOP_ADD, surf_index,
                                     2 /* message length */,
                                     0 /* response length */,
                                     false /* header present */);
@


1.1.1.6
log
@Import Mesa 10.4.3
@
text
@d37 1
a37 1
#include "util/ralloc.h"
d44 1
a44 1
				 brw_inst *insn,
d47 4
a50 8
   const struct brw_context *brw = p->brw;

   if (reg.width == BRW_WIDTH_8 && p->compressed) {
      brw_inst_set_exec_size(brw, insn, BRW_EXECUTE_16);
   } else {
      /* Register width definitions are compatible with BRW_EXECUTE_* enums. */
      brw_inst_set_exec_size(brw, insn, reg.width);
   }
d75 2
a76 2
      brw_set_default_mask_control(p, BRW_MASK_DISABLE);
      brw_set_default_compression_control(p, BRW_COMPRESSION_NONE);
d96 1
a96 1
   if (brw->gen >= 7 && reg->file == BRW_MESSAGE_REGISTER_FILE) {
d159 2
a160 1
brw_set_dest(struct brw_compile *p, brw_inst *inst, struct brw_reg dest)
a161 2
   const struct brw_context *brw = p->brw;

d168 4
a171 4
   brw_inst_set_dst_reg_file(brw, inst, dest.file);
   brw_inst_set_dst_reg_type(brw, inst, brw_reg_type_to_hw_type(brw, dest.type,
                                                                dest.file));
   brw_inst_set_dst_address_mode(brw, inst, dest.address_mode);
d174 1
a174 1
      brw_inst_set_dst_da_reg_nr(brw, inst, dest.nr);
d176 2
a177 2
      if (brw_inst_access_mode(brw, inst) == BRW_ALIGN_1) {
         brw_inst_set_dst_da1_subreg_nr(brw, inst, dest.subnr);
d180 5
a184 4
         brw_inst_set_dst_hstride(brw, inst, dest.hstride);
      } else {
         brw_inst_set_dst_da16_subreg_nr(brw, inst, dest.subnr / 16);
         brw_inst_set_da16_writemask(brw, inst, dest.dw1.bits.writemask);
d193 1
a193 1
         brw_inst_set_dst_hstride(brw, inst, 1);
d195 3
a197 2
   } else {
      brw_inst_set_dst_ia_subreg_nr(brw, inst, dest.subnr);
d201 2
a202 3
      if (brw_inst_access_mode(brw, inst) == BRW_ALIGN_1) {
         brw_inst_set_dst_ia1_addr_imm(brw, inst,
                                       dest.dw1.bits.indirect_offset);
d205 4
a208 4
         brw_inst_set_dst_hstride(brw, inst, dest.hstride);
      } else {
         brw_inst_set_dst_ia16_addr_imm(brw, inst,
                                        dest.dw1.bits.indirect_offset);
d210 1
a210 1
         brw_inst_set_dst_hstride(brw, inst, 1);
d215 1
a215 1
    * inst->compression_control:
d217 1
a217 1
   guess_execution_size(p, inst, dest);
d223 1
a223 1
validate_reg(const struct brw_context *brw, brw_inst *inst, struct brw_reg reg)
d226 1
a226 1
   int vstride_for_reg[] = {0, 1, 2, 4, 8, 16, 32};
d237 2
a238 2
         assert(hstride_for_reg[brw_inst_dst_hstride(brw, inst)] *
                reg_type_size[brw_inst_dst_reg_type(brw, inst)] == 2);
d261 3
a263 3
   assert(brw_inst_exec_size(brw, inst) >= 0 &&
          brw_inst_exec_size(brw, inst) < Elements(execsize_for_reg));
   execsize = execsize_for_reg[brw_inst_exec_size(brw, inst)];
a297 10
static bool
is_compactable_immediate(unsigned imm)
{
   /* We get the low 12 bits as-is. */
   imm &= ~0xfff;

   /* We get one bit replicated through the top 20 bits. */
   return imm == 0 || imm == 0xfffff000;
}

d299 2
a300 1
brw_set_src0(struct brw_compile *p, brw_inst *inst, struct brw_reg reg)
d304 1
a304 1
   if (reg.file != BRW_ARCHITECTURE_REGISTER_FILE)
d309 2
a310 2
   if (brw->gen >= 6 && (brw_inst_opcode(brw, inst) == BRW_OPCODE_SEND ||
                         brw_inst_opcode(brw, inst) == BRW_OPCODE_SENDC)) {
d320 1
a320 1
   validate_reg(brw, inst, reg);
d322 6
a327 6
   brw_inst_set_src0_reg_file(brw, inst, reg.file);
   brw_inst_set_src0_reg_type(brw, inst,
                              brw_reg_type_to_hw_type(brw, reg.type, reg.file));
   brw_inst_set_src0_abs(brw, inst, reg.abs);
   brw_inst_set_src0_negate(brw, inst, reg.negate);
   brw_inst_set_src0_address_mode(brw, inst, reg.address_mode);
d330 1
a330 1
      brw_inst_set_imm_ud(brw, inst, reg.dw1.ud);
d332 1
a332 21
      /* The Bspec's section titled "Non-present Operands" claims that if src0
       * is an immediate that src1's type must be the same as that of src0.
       *
       * The SNB+ DataTypeIndex instruction compaction tables contain mappings
       * that do not follow this rule. E.g., from the IVB/HSW table:
       *
       *  DataTypeIndex   18-Bit Mapping       Mapped Meaning
       *        3         001000001011111101   r:f | i:vf | a:ud | <1> | dir |
       *
       * And from the SNB table:
       *
       *  DataTypeIndex   18-Bit Mapping       Mapped Meaning
       *        8         001000000111101100   a:w | i:w | a:ud | <1> | dir |
       *
       * Neither of these cause warnings from the simulator when used,
       * compacted or otherwise. In fact, all compaction mappings that have an
       * immediate in src0 use a:ud for src1.
       *
       * The GM45 instruction compaction tables do not contain mapped meanings
       * so it's not clear whether it has the restriction. We'll assume it was
       * lifted on SNB. (FINISHME: decode the GM45 tables and check.)
d334 14
a347 22
      brw_inst_set_src1_reg_file(brw, inst, BRW_ARCHITECTURE_REGISTER_FILE);
      if (brw->gen < 6) {
         brw_inst_set_src1_reg_type(brw, inst,
                                    brw_inst_src0_reg_type(brw, inst));
      } else {
         brw_inst_set_src1_reg_type(brw, inst, BRW_HW_REG_TYPE_UD);
      }

      /* Compacted instructions only have 12-bits (plus 1 for the other 20)
       * for immediate values. Presumably the hardware engineers realized
       * that the only useful floating-point value that could be represented
       * in this format is 0.0, which can also be represented as a VF-typed
       * immediate, so they gave us the previously mentioned mapping on IVB+.
       *
       * Strangely, we do have a mapping for imm:f in src1, so we don't need
       * to do this there.
       *
       * If we see a 0.0:F, change the type to VF so that it can be compacted.
       */
      if (brw_inst_imm_ud(brw, inst) == 0x0 &&
          brw_inst_src0_reg_type(brw, inst) == BRW_HW_REG_TYPE_F) {
         brw_inst_set_src0_reg_type(brw, inst, BRW_HW_REG_IMM_TYPE_VF);
d349 2
d352 2
a353 17
      /* There are no mappings for dst:d | i:d, so if the immediate is suitable
       * set the types to :UD so the instruction can be compacted.
       */
      if (is_compactable_immediate(brw_inst_imm_ud(brw, inst)) &&
          brw_inst_cond_modifier(brw, inst) == BRW_CONDITIONAL_NONE &&
          brw_inst_src0_reg_type(brw, inst) == BRW_HW_REG_TYPE_D &&
          brw_inst_dst_reg_type(brw, inst) == BRW_HW_REG_TYPE_D) {
         brw_inst_set_src0_reg_type(brw, inst, BRW_HW_REG_TYPE_UD);
         brw_inst_set_dst_reg_type(brw, inst, BRW_HW_REG_TYPE_UD);
      }
   } else {
      if (reg.address_mode == BRW_ADDRESS_DIRECT) {
         brw_inst_set_src0_da_reg_nr(brw, inst, reg.nr);
         if (brw_inst_access_mode(brw, inst) == BRW_ALIGN_1) {
             brw_inst_set_src0_da1_subreg_nr(brw, inst, reg.subnr);
	 } else {
            brw_inst_set_src0_da16_subreg_nr(brw, inst, reg.subnr / 16);
d355 2
a356 7
      } else {
         brw_inst_set_src0_ia_subreg_nr(brw, inst, reg.subnr);

         if (brw_inst_access_mode(brw, inst) == BRW_ALIGN_1) {
            brw_inst_set_src0_ia1_addr_imm(brw, inst, reg.dw1.bits.indirect_offset);
	 } else {
            brw_inst_set_src0_ia_subreg_nr(brw, inst, reg.dw1.bits.indirect_offset);
d360 1
a360 1
      if (brw_inst_access_mode(brw, inst) == BRW_ALIGN_1) {
d362 9
a370 8
             brw_inst_exec_size(brw, inst) == BRW_EXECUTE_1) {
            brw_inst_set_src0_hstride(brw, inst, BRW_HORIZONTAL_STRIDE_0);
            brw_inst_set_src0_width(brw, inst, BRW_WIDTH_1);
            brw_inst_set_src0_vstride(brw, inst, BRW_VERTICAL_STRIDE_0);
	 } else {
            brw_inst_set_src0_hstride(brw, inst, reg.hstride);
            brw_inst_set_src0_width(brw, inst, reg.width);
            brw_inst_set_src0_vstride(brw, inst, reg.vstride);
d372 6
a377 9
      } else {
         brw_inst_set_src0_da16_swiz_x(brw, inst,
            BRW_GET_SWZ(reg.dw1.bits.swizzle, BRW_CHANNEL_X));
         brw_inst_set_src0_da16_swiz_y(brw, inst,
            BRW_GET_SWZ(reg.dw1.bits.swizzle, BRW_CHANNEL_Y));
         brw_inst_set_src0_da16_swiz_z(brw, inst,
            BRW_GET_SWZ(reg.dw1.bits.swizzle, BRW_CHANNEL_Z));
         brw_inst_set_src0_da16_swiz_w(brw, inst,
            BRW_GET_SWZ(reg.dw1.bits.swizzle, BRW_CHANNEL_W));
d383 1
a383 1
            brw_inst_set_src0_vstride(brw, inst, BRW_VERTICAL_STRIDE_4);
d385 1
a385 1
            brw_inst_set_src0_vstride(brw, inst, reg.vstride);
d391 3
a393 2
void
brw_set_src1(struct brw_compile *p, brw_inst *inst, struct brw_reg reg)
a394 1
   const struct brw_context *brw = p->brw;
d397 1
a397 1
   if (reg.file != BRW_ARCHITECTURE_REGISTER_FILE)
d402 1
a402 1
   validate_reg(brw, inst, reg);
d404 5
a408 5
   brw_inst_set_src1_reg_file(brw, inst, reg.file);
   brw_inst_set_src1_reg_type(brw, inst,
                              brw_reg_type_to_hw_type(brw, reg.type, reg.file));
   brw_inst_set_src1_abs(brw, inst, reg.abs);
   brw_inst_set_src1_negate(brw, inst, reg.negate);
d412 1
a412 1
   assert(brw_inst_src0_reg_file(brw, inst) != BRW_IMMEDIATE_VALUE);
d415 3
a417 2
      brw_inst_set_imm_ud(brw, inst, reg.dw1.ud);
   } else {
d424 7
a430 5
      brw_inst_set_src1_da_reg_nr(brw, inst, reg.nr);
      if (brw_inst_access_mode(brw, inst) == BRW_ALIGN_1) {
         brw_inst_set_src1_da1_subreg_nr(brw, inst, reg.subnr);
      } else {
         brw_inst_set_src1_da16_subreg_nr(brw, inst, reg.subnr / 16);
d433 1
a433 1
      if (brw_inst_access_mode(brw, inst) == BRW_ALIGN_1) {
d435 9
a443 8
             brw_inst_exec_size(brw, inst) == BRW_EXECUTE_1) {
            brw_inst_set_src1_hstride(brw, inst, BRW_HORIZONTAL_STRIDE_0);
            brw_inst_set_src1_width(brw, inst, BRW_WIDTH_1);
            brw_inst_set_src1_vstride(brw, inst, BRW_VERTICAL_STRIDE_0);
	 } else {
            brw_inst_set_src1_hstride(brw, inst, reg.hstride);
            brw_inst_set_src1_width(brw, inst, reg.width);
            brw_inst_set_src1_vstride(brw, inst, reg.vstride);
d445 6
a450 9
      } else {
         brw_inst_set_src1_da16_swiz_x(brw, inst,
            BRW_GET_SWZ(reg.dw1.bits.swizzle, BRW_CHANNEL_X));
         brw_inst_set_src1_da16_swiz_y(brw, inst,
            BRW_GET_SWZ(reg.dw1.bits.swizzle, BRW_CHANNEL_Y));
         brw_inst_set_src1_da16_swiz_z(brw, inst,
            BRW_GET_SWZ(reg.dw1.bits.swizzle, BRW_CHANNEL_Z));
         brw_inst_set_src1_da16_swiz_w(brw, inst,
            BRW_GET_SWZ(reg.dw1.bits.swizzle, BRW_CHANNEL_W));
d456 1
a456 1
            brw_inst_set_src1_vstride(brw, inst, BRW_VERTICAL_STRIDE_4);
d458 1
a458 1
            brw_inst_set_src1_vstride(brw, inst, reg.vstride);
d473 1
a473 1
			   brw_inst *inst,
d484 5
a488 11
   /* For indirect sends, `inst` will not be the SEND/SENDC instruction
    * itself; instead, it will be a MOV/OR into the address register.
    *
    * In this case, we avoid setting the extended message descriptor bits,
    * since they go on the later SEND/SENDC instead and if set here would
    * instead clobber the conditionalmod bits.
    */
   unsigned opcode = brw_inst_opcode(brw, inst);
   if (opcode == BRW_OPCODE_SEND || opcode == BRW_OPCODE_SENDC) {
      brw_inst_set_sfid(brw, inst, sfid);
   }
d490 13
a502 6
   brw_inst_set_mlen(brw, inst, msg_length);
   brw_inst_set_rlen(brw, inst, response_length);
   brw_inst_set_eot(brw, inst, end_of_thread);

   if (brw->gen >= 5) {
      brw_inst_set_header_present(brw, inst, header_present);
d507 1
a507 1
				  brw_inst *inst,
d542 1
a542 1
   brw_set_message_descriptor(p, inst, BRW_SFID_MATH,
d544 15
a558 6
   brw_inst_set_math_msg_function(brw, inst, function);
   brw_inst_set_math_msg_signed_int(brw, inst, integer_type);
   brw_inst_set_math_msg_precision(brw, inst, low_precision);
   brw_inst_set_math_msg_saturate(brw, inst, brw_inst_saturate(brw, inst));
   brw_inst_set_math_msg_data_type(brw, inst, dataType);
   brw_inst_set_saturate(brw, inst, 0);
d563 1
a563 1
				    brw_inst *insn,
a567 2
   const struct brw_context *brw = p->brw;

d570 6
a575 7
   brw_inst_set_urb_opcode(brw, insn, 1); /* FF_SYNC */
   brw_inst_set_urb_allocate(brw, insn, allocate);
   /* The following fields are not used by FF_SYNC: */
   brw_inst_set_urb_global_offset(brw, insn, 0);
   brw_inst_set_urb_swizzle_control(brw, insn, 0);
   brw_inst_set_urb_used(brw, insn, 0);
   brw_inst_set_urb_complete(brw, insn, 0);
d579 1
a579 1
				 brw_inst *insn,
a587 4
   assert(brw->gen < 7 || swizzle_control != BRW_URB_SWIZZLE_TRANSPOSE);
   assert(brw->gen < 7 || !(flags & BRW_URB_WRITE_ALLOCATE));
   assert(brw->gen >= 7 || !(flags & BRW_URB_WRITE_PER_SLOT_OFFSET));

d591 27
a617 21

   if (flags & BRW_URB_WRITE_OWORD) {
      assert(msg_length == 2); /* header + one OWORD of data */
      brw_inst_set_urb_opcode(brw, insn, BRW_URB_OPCODE_WRITE_OWORD);
   } else {
      brw_inst_set_urb_opcode(brw, insn, BRW_URB_OPCODE_WRITE_HWORD);
   }

   brw_inst_set_urb_global_offset(brw, insn, offset);
   brw_inst_set_urb_swizzle_control(brw, insn, swizzle_control);

   if (brw->gen < 8) {
      brw_inst_set_urb_complete(brw, insn, !!(flags & BRW_URB_WRITE_COMPLETE));
   }

   if (brw->gen < 7) {
      brw_inst_set_urb_allocate(brw, insn, !!(flags & BRW_URB_WRITE_ALLOCATE));
      brw_inst_set_urb_used(brw, insn, !(flags & BRW_URB_WRITE_UNUSED));
   } else {
      brw_inst_set_urb_per_slot_offset(brw, insn,
         !!(flags & BRW_URB_WRITE_PER_SLOT_OFFSET));
d623 1
a623 1
			 brw_inst *insn,
d653 23
a675 6
   brw_inst_set_binding_table_index(brw, insn, binding_table_index);
   brw_inst_set_dp_write_msg_type(brw, insn, msg_type);
   brw_inst_set_dp_write_msg_control(brw, insn, msg_control);
   brw_inst_set_rt_last(brw, insn, last_render_target);
   if (brw->gen < 7) {
      brw_inst_set_dp_write_commit(brw, insn, send_commit_msg);
d681 1
a681 1
			brw_inst *insn,
d707 27
a733 5
   brw_inst_set_binding_table_index(brw, insn, binding_table_index);
   brw_inst_set_dp_read_msg_type(brw, insn, msg_type);
   brw_inst_set_dp_read_msg_control(brw, insn, msg_control);
   if (brw->gen < 6)
      brw_inst_set_dp_read_target_cache(brw, insn, target_cache);
d738 1
a738 1
                        brw_inst *inst,
d750 1
a750 1
   brw_set_message_descriptor(p, inst, BRW_SFID_SAMPLER, msg_length,
d753 19
a771 7
   brw_inst_set_binding_table_index(brw, inst, binding_table_index);
   brw_inst_set_sampler(brw, inst, sampler);
   brw_inst_set_sampler_msg_type(brw, inst, msg_type);
   if (brw->gen >= 5) {
      brw_inst_set_sampler_simd_mode(brw, inst, simd_mode);
   } else if (brw->gen == 4 && !brw->is_g4x) {
      brw_inst_set_sampler_return_format(brw, inst, return_format);
a774 39
void brw_set_indirect_send_descriptor(struct brw_compile *p,
                                      brw_inst *insn,
                                      unsigned sfid,
                                      struct brw_reg descriptor)
{
   /* Only a0.0 may be used as SEND's descriptor operand. */
   assert(descriptor.file == BRW_ARCHITECTURE_REGISTER_FILE);
   assert(descriptor.type == BRW_REGISTER_TYPE_UD);
   assert(descriptor.nr == BRW_ARF_ADDRESS);
   assert(descriptor.subnr == 0);

   brw_set_message_descriptor(p, insn, sfid, 0, 0, false, false);
   brw_set_src1(p, insn, descriptor);
}

static void
gen7_set_dp_scratch_message(struct brw_compile *p,
                            brw_inst *inst,
                            bool write,
                            bool dword,
                            bool invalidate_after_read,
                            unsigned num_regs,
                            unsigned addr_offset,
                            unsigned mlen,
                            unsigned rlen,
                            bool header_present)
{
   const struct brw_context *brw = p->brw;
   assert(num_regs == 1 || num_regs == 2 || num_regs == 4 ||
          (brw->gen >= 8 && num_regs == 8));
   brw_set_message_descriptor(p, inst, GEN7_SFID_DATAPORT_DATA_CACHE,
                              mlen, rlen, header_present, false);
   brw_inst_set_dp_category(brw, inst, 1); /* Scratch Block Read/Write msgs */
   brw_inst_set_scratch_read_write(brw, inst, write);
   brw_inst_set_scratch_type(brw, inst, dword);
   brw_inst_set_scratch_invalidate_after_read(brw, inst, invalidate_after_read);
   brw_inst_set_scratch_block_size(brw, inst, ffs(num_regs) - 1);
   brw_inst_set_scratch_addr_offset(brw, inst, addr_offset);
}
d777 1
a777 1
brw_inst *
d780 1
a780 2
   const struct brw_context *brw = p->brw;
   brw_inst *insn;
d783 4
d788 4
a791 1
      p->store = reralloc(p->mem_ctx, p->store, brw_inst, p->store_size);
d798 9
a806 1
   brw_inst_set_opcode(brw, insn, opcode);
d810 4
a813 3
static brw_inst *
brw_alu1(struct brw_compile *p, unsigned opcode,
         struct brw_reg dest, struct brw_reg src)
d815 1
a815 1
   brw_inst *insn = next_insn(p, opcode);
d821 5
a825 3
static brw_inst *
brw_alu2(struct brw_compile *p, unsigned opcode,
         struct brw_reg dest, struct brw_reg src0, struct brw_reg src1)
d827 1
a827 1
   brw_inst *insn = next_insn(p, opcode);
d845 6
a850 3
static brw_inst *
brw_alu3(struct brw_compile *p, unsigned opcode, struct brw_reg dest,
         struct brw_reg src0, struct brw_reg src1, struct brw_reg src2)
d853 1
a853 1
   brw_inst *inst = next_insn(p, opcode);
d857 1
a857 1
   assert(brw_inst_access_mode(brw, inst) == BRW_ALIGN_16);
d866 5
a870 8
   if (brw->gen == 6) {
      brw_inst_set_3src_dst_reg_file(brw, inst,
                                     dest.file == BRW_MESSAGE_REGISTER_FILE);
   }
   brw_inst_set_3src_dst_reg_nr(brw, inst, dest.nr);
   brw_inst_set_3src_dst_subreg_nr(brw, inst, dest.subnr / 16);
   brw_inst_set_3src_dst_writemask(brw, inst, dest.dw1.bits.writemask);
   guess_execution_size(p, inst, dest);
d875 6
a880 7
   brw_inst_set_3src_src0_swizzle(brw, inst, src0.dw1.bits.swizzle);
   brw_inst_set_3src_src0_subreg_nr(brw, inst, get_3src_subreg_nr(src0));
   brw_inst_set_3src_src0_reg_nr(brw, inst, src0.nr);
   brw_inst_set_3src_src0_abs(brw, inst, src0.abs);
   brw_inst_set_3src_src0_negate(brw, inst, src0.negate);
   brw_inst_set_3src_src0_rep_ctrl(brw, inst,
                                   src0.vstride == BRW_VERTICAL_STRIDE_0);
d885 7
a891 7
   brw_inst_set_3src_src1_swizzle(brw, inst, src1.dw1.bits.swizzle);
   brw_inst_set_3src_src1_subreg_nr(brw, inst, get_3src_subreg_nr(src1));
   brw_inst_set_3src_src1_reg_nr(brw, inst, src1.nr);
   brw_inst_set_3src_src1_abs(brw, inst, src1.abs);
   brw_inst_set_3src_src1_negate(brw, inst, src1.negate);
   brw_inst_set_3src_src1_rep_ctrl(brw, inst,
                                   src1.vstride == BRW_VERTICAL_STRIDE_0);
d896 6
a901 7
   brw_inst_set_3src_src2_swizzle(brw, inst, src2.dw1.bits.swizzle);
   brw_inst_set_3src_src2_subreg_nr(brw, inst, get_3src_subreg_nr(src2));
   brw_inst_set_3src_src2_reg_nr(brw, inst, src2.nr);
   brw_inst_set_3src_src2_abs(brw, inst, src2.abs);
   brw_inst_set_3src_src2_negate(brw, inst, src2.negate);
   brw_inst_set_3src_src2_rep_ctrl(brw, inst,
                                   src2.vstride == BRW_VERTICAL_STRIDE_0);
d912 2
a913 2
         brw_inst_set_3src_src_type(brw, inst, BRW_3SRC_TYPE_F);
         brw_inst_set_3src_dst_type(brw, inst, BRW_3SRC_TYPE_F);
d916 2
a917 2
         brw_inst_set_3src_src_type(brw, inst, BRW_3SRC_TYPE_D);
         brw_inst_set_3src_dst_type(brw, inst, BRW_3SRC_TYPE_D);
d920 2
a921 2
         brw_inst_set_3src_src_type(brw, inst, BRW_3SRC_TYPE_UD);
         brw_inst_set_3src_dst_type(brw, inst, BRW_3SRC_TYPE_UD);
d926 1
a926 1
   return inst;
d934 1
a934 1
brw_inst *brw_##OP(struct brw_compile *p,		\
d942 1
a942 1
brw_inst *brw_##OP(struct brw_compile *p,		\
d951 1
a951 1
brw_inst *brw_##OP(struct brw_compile *p,		\
d961 1
a961 1
brw_inst *brw_##OP(struct brw_compile *p,         \
d986 1
a986 2
   struct brw_context *brw = p->brw;					      \
   brw_inst *rnd, *add;							      \
d991 1
a991 1
   if (brw->gen < 6) {							      \
d993 1
a993 1
      brw_inst_set_cond_modifier(brw, rnd, BRW_CONDITIONAL_R);                \
d995 1
a995 1
      brw_inst_set_pred_control(brw, add, BRW_PREDICATE_NORMAL);              \
d1009 2
d1038 4
a1041 3
brw_inst *
brw_ADD(struct brw_compile *p, struct brw_reg dest,
        struct brw_reg src0, struct brw_reg src1)
d1061 4
a1064 3
brw_inst *
brw_AVG(struct brw_compile *p, struct brw_reg dest,
        struct brw_reg src0, struct brw_reg src1)
d1077 1
a1077 1
      unreachable("Bad type for brw_AVG");
d1083 4
a1086 3
brw_inst *
brw_MUL(struct brw_compile *p, struct brw_reg dest,
        struct brw_reg src0, struct brw_reg src1)
a1117 50
brw_inst *
brw_F32TO16(struct brw_compile *p, struct brw_reg dst, struct brw_reg src)
{
   const struct brw_context *brw = p->brw;
   bool align16 = brw_inst_access_mode(brw, p->current) == BRW_ALIGN_16;

   if (align16) {
      assert(dst.type == BRW_REGISTER_TYPE_UD);
   } else {
      assert(dst.type == BRW_REGISTER_TYPE_W ||
             dst.type == BRW_REGISTER_TYPE_UW ||
             dst.type == BRW_REGISTER_TYPE_HF);
   }

   if (brw->gen >= 8) {
      if (align16) {
         /* Emulate the Gen7 zeroing bug (see comments in vec4_visitor's
          * emit_pack_half_2x16 method.)
          */
         brw_MOV(p, retype(dst, BRW_REGISTER_TYPE_UD), brw_imm_ud(0u));
      }
      return brw_MOV(p, retype(dst, BRW_REGISTER_TYPE_HF), src);
   } else {
      assert(brw->gen == 7);
      return brw_alu1(p, BRW_OPCODE_F32TO16, dst, src);
   }
}

brw_inst *
brw_F16TO32(struct brw_compile *p, struct brw_reg dst, struct brw_reg src)
{
   const struct brw_context *brw = p->brw;
   bool align16 = brw_inst_access_mode(brw, p->current) == BRW_ALIGN_16;

   if (align16) {
      assert(src.type == BRW_REGISTER_TYPE_UD);
   } else {
      assert(src.type == BRW_REGISTER_TYPE_W ||
             src.type == BRW_REGISTER_TYPE_UW ||
             src.type == BRW_REGISTER_TYPE_HF);
   }

   if (brw->gen >= 8) {
      return brw_MOV(p, dst, retype(src, BRW_REGISTER_TYPE_HF));
   } else {
      assert(brw->gen == 7);
      return brw_alu1(p, BRW_OPCODE_F16TO32, dst, src);
   }
}

d1121 1
a1121 1
   brw_inst *insn = next_insn(p, BRW_OPCODE_NOP);
d1135 12
a1146 12
brw_inst *
brw_JMPI(struct brw_compile *p, struct brw_reg index,
         unsigned predicate_control)
{
   const struct brw_context *brw = p->brw;
   struct brw_reg ip = brw_ip_reg();
   brw_inst *inst = brw_alu2(p, BRW_OPCODE_JMPI, ip, ip, index);

   brw_inst_set_exec_size(brw, inst, BRW_EXECUTE_2);
   brw_inst_set_qtr_control(brw, inst, BRW_COMPRESSION_NONE);
   brw_inst_set_mask_control(brw, inst, BRW_MASK_DISABLE);
   brw_inst_set_pred_control(brw, inst, predicate_control);
d1148 1
a1148 1
   return inst;
d1152 1
a1152 1
push_if_stack(struct brw_compile *p, brw_inst *inst)
d1164 1
a1164 1
static brw_inst *
d1172 1
a1172 1
push_loop_stack(struct brw_compile *p, brw_inst *inst)
d1187 1
a1187 1
static brw_inst *
d1206 1
a1206 1
brw_inst *
d1210 1
a1210 1
   brw_inst *insn;
d1222 1
a1222 1
      brw_inst_set_gen6_jump_count(brw, insn, 0);
d1225 1
a1225 1
   } else if (brw->gen == 7) {
d1229 2
a1230 7
      brw_inst_set_jip(brw, insn, 0);
      brw_inst_set_uip(brw, insn, 0);
   } else {
      brw_set_dest(p, insn, vec1(retype(brw_null_reg(), BRW_REGISTER_TYPE_D)));
      brw_set_src0(p, insn, brw_imm_d(0));
      brw_inst_set_jip(brw, insn, 0);
      brw_inst_set_uip(brw, insn, 0);
d1233 8
a1240 6
   brw_inst_set_exec_size(brw, insn, execute_size);
   brw_inst_set_qtr_control(brw, insn, BRW_COMPRESSION_NONE);
   brw_inst_set_pred_control(brw, insn, BRW_PREDICATE_NORMAL);
   brw_inst_set_mask_control(brw, insn, BRW_MASK_ENABLE);
   if (!p->single_program_flow && brw->gen < 6)
      brw_inst_set_thread_control(brw, insn, BRW_THREAD_SWITCH);
d1250 2
a1251 2
brw_inst *
gen6_IF(struct brw_compile *p, enum brw_conditional_mod conditional,
d1254 1
a1254 2
   const struct brw_context *brw = p->brw;
   brw_inst *insn;
d1259 6
a1264 3
   brw_inst_set_exec_size(brw, insn, p->compressed ? BRW_EXECUTE_16
                                                   : BRW_EXECUTE_8);
   brw_inst_set_gen6_jump_count(brw, insn, 0);
d1268 6
a1273 3
   assert(brw_inst_qtr_control(brw, insn) == BRW_COMPRESSION_NONE);
   assert(brw_inst_pred_control(brw, insn) == BRW_PREDICATE_NONE);
   brw_inst_set_cond_modifier(brw, insn, conditional);
d1284 2
a1285 1
                       brw_inst *if_inst, brw_inst *else_inst)
a1286 2
   const struct brw_context *brw = p->brw;

d1288 1
a1288 1
   brw_inst *next_inst = &p->store[p->nr_insn];
d1291 3
a1293 3
   assert(if_inst != NULL && brw_inst_opcode(brw, if_inst) == BRW_OPCODE_IF);
   assert(else_inst == NULL || brw_inst_opcode(brw, else_inst) == BRW_OPCODE_ELSE);
   assert(brw_inst_exec_size(brw, if_inst) == BRW_EXECUTE_1);
d1303 2
a1304 2
   brw_inst_set_opcode(brw, if_inst, BRW_OPCODE_ADD);
   brw_inst_set_pred_inv(brw, if_inst, true);
d1310 1
a1310 1
      brw_inst_set_opcode(brw, else_inst, BRW_OPCODE_ADD);
d1312 2
a1313 2
      brw_inst_set_imm_ud(brw, if_inst, (else_inst - if_inst + 1) * 16);
      brw_inst_set_imm_ud(brw, else_inst, (next_inst - else_inst) * 16);
d1315 1
a1315 1
      brw_inst_set_imm_ud(brw, if_inst, (next_inst - if_inst) * 16);
d1324 3
a1326 1
              brw_inst *if_inst, brw_inst *else_inst, brw_inst *endif_inst)
d1345 1
a1345 1
   assert(if_inst != NULL && brw_inst_opcode(brw, if_inst) == BRW_OPCODE_IF);
d1347 1
a1347 1
   assert(else_inst == NULL || brw_inst_opcode(brw, else_inst) == BRW_OPCODE_ELSE);
d1349 6
a1354 1
   unsigned br = brw_jump_scale(brw);
d1356 2
a1357 2
   assert(brw_inst_opcode(brw, endif_inst) == BRW_OPCODE_ENDIF);
   brw_inst_set_exec_size(brw, endif_inst, brw_inst_exec_size(brw, if_inst));
d1365 4
a1368 4
         brw_inst_set_opcode(brw, if_inst, BRW_OPCODE_IFF);
         brw_inst_set_gen4_jump_count(brw, if_inst,
                                      br * (endif_inst - if_inst + 1));
         brw_inst_set_gen4_pop_count(brw, if_inst, 0);
d1371 1
a1371 1
         brw_inst_set_gen6_jump_count(brw, if_inst, br*(endif_inst - if_inst));
d1373 2
a1374 2
         brw_inst_set_uip(brw, if_inst, br * (endif_inst - if_inst));
         brw_inst_set_jip(brw, if_inst, br * (endif_inst - if_inst));
d1377 1
a1377 1
      brw_inst_set_exec_size(brw, else_inst, brw_inst_exec_size(brw, if_inst));
d1381 3
a1383 3
         brw_inst_set_gen4_jump_count(brw, if_inst,
                                      br * (else_inst - if_inst));
         brw_inst_set_gen4_pop_count(brw, if_inst, 0);
d1385 1
a1385 2
         brw_inst_set_gen6_jump_count(brw, if_inst,
                                      br * (else_inst - if_inst + 1));
d1393 3
a1395 3
         brw_inst_set_gen4_jump_count(brw, else_inst,
                                      br * (endif_inst - else_inst + 1));
         brw_inst_set_gen4_pop_count(brw, else_inst, 1);
d1398 1
a1398 2
         brw_inst_set_gen6_jump_count(brw, else_inst,
                                      br * (endif_inst - else_inst));
d1401 1
a1401 1
         brw_inst_set_jip(brw, if_inst, br * (else_inst - if_inst + 1));
d1403 2
a1404 8
         brw_inst_set_uip(brw, if_inst, br * (endif_inst - if_inst));
         brw_inst_set_jip(brw, else_inst, br * (endif_inst - else_inst));
         if (brw->gen >= 8) {
            /* Since we don't set branch_ctrl, the ELSE's JIP and UIP both
             * should point to ENDIF.
             */
            brw_inst_set_uip(brw, else_inst, br * (endif_inst - else_inst));
         }
d1413 1
a1413 1
   brw_inst *insn;
d1423 1
a1423 1
      brw_inst_set_gen6_jump_count(brw, insn, 0);
d1426 1
a1426 1
   } else if (brw->gen == 7) {
d1430 2
a1431 7
      brw_inst_set_jip(brw, insn, 0);
      brw_inst_set_uip(brw, insn, 0);
   } else {
      brw_set_dest(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
      brw_set_src0(p, insn, brw_imm_d(0));
      brw_inst_set_jip(brw, insn, 0);
      brw_inst_set_uip(brw, insn, 0);
d1434 4
a1437 4
   brw_inst_set_qtr_control(brw, insn, BRW_COMPRESSION_NONE);
   brw_inst_set_mask_control(brw, insn, BRW_MASK_ENABLE);
   if (!p->single_program_flow && brw->gen < 6)
      brw_inst_set_thread_control(brw, insn, BRW_THREAD_SWITCH);
d1446 4
a1449 4
   brw_inst *insn = NULL;
   brw_inst *else_inst = NULL;
   brw_inst *if_inst = NULL;
   brw_inst *tmp;
d1478 1
a1478 1
   if (brw_inst_opcode(brw, tmp) == BRW_OPCODE_ELSE) {
d1498 1
a1498 1
   } else if (brw->gen == 7) {
a1501 2
   } else {
      brw_set_src0(p, insn, brw_imm_d(0));
d1504 3
a1506 4
   brw_inst_set_qtr_control(brw, insn, BRW_COMPRESSION_NONE);
   brw_inst_set_mask_control(brw, insn, BRW_MASK_ENABLE);
   if (brw->gen < 6)
      brw_inst_set_thread_control(brw, insn, BRW_THREAD_SWITCH);
d1510 3
a1512 2
      brw_inst_set_gen4_jump_count(brw, insn, 0);
      brw_inst_set_gen4_pop_count(brw, insn, 1);
d1514 1
a1514 1
      brw_inst_set_gen6_jump_count(brw, insn, 2);
d1516 1
a1516 1
      brw_inst_set_jip(brw, insn, 2);
d1521 1
a1521 2
brw_inst *
brw_BREAK(struct brw_compile *p)
d1524 1
a1524 1
   brw_inst *insn;
d1527 1
a1527 4
   if (brw->gen >= 8) {
      brw_set_dest(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
      brw_set_src0(p, insn, brw_imm_d(0x0));
   } else if (brw->gen >= 6) {
d1535 2
a1536 2
      brw_inst_set_gen4_pop_count(brw, insn,
                                  p->if_depth_in_loop[p->loop_stack_depth]);
d1538 2
a1539 3
   brw_inst_set_qtr_control(brw, insn, BRW_COMPRESSION_NONE);
   brw_inst_set_exec_size(brw, insn, p->compressed ? BRW_EXECUTE_16
                                                   : BRW_EXECUTE_8);
d1544 1
a1544 2
brw_inst *
brw_CONT(struct brw_compile *p)
d1546 1
a1546 2
   const struct brw_context *brw = p->brw;
   brw_inst *insn;
d1549 2
d1552 7
a1558 6
   if (brw->gen >= 8) {
      brw_set_src0(p, insn, brw_imm_d(0x0));
   } else {
      brw_set_src0(p, insn, brw_ip_reg());
      brw_set_src1(p, insn, brw_imm_d(0x0));
   }
d1560 12
a1571 7
   if (brw->gen < 6) {
      brw_inst_set_gen4_pop_count(brw, insn,
                                  p->if_depth_in_loop[p->loop_stack_depth]);
   }
   brw_inst_set_qtr_control(brw, insn, BRW_COMPRESSION_NONE);
   brw_inst_set_exec_size(brw, insn, p->compressed ? BRW_EXECUTE_16
                                                   : BRW_EXECUTE_8);
d1575 1
a1575 2
brw_inst *
gen6_HALT(struct brw_compile *p)
d1577 1
a1577 2
   const struct brw_context *brw = p->brw;
   brw_inst *insn;
d1581 2
a1582 6
   if (brw->gen >= 8) {
      brw_set_src0(p, insn, brw_imm_d(0x0));
   } else {
      brw_set_src0(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
      brw_set_src1(p, insn, brw_imm_d(0x0)); /* UIP and JIP, updated later. */
   }
d1585 1
a1585 1
      brw_inst_set_exec_size(brw, insn, BRW_EXECUTE_16);
d1587 2
a1588 2
      brw_inst_set_qtr_control(brw, insn, BRW_COMPRESSION_NONE);
      brw_inst_set_exec_size(brw, insn, BRW_EXECUTE_8);
d1609 1
a1609 2
brw_inst *
brw_DO(struct brw_compile *p, unsigned execute_size)
d1617 1
a1617 1
      brw_inst *insn = next_insn(p, BRW_OPCODE_DO);
d1627 5
a1631 3
      brw_inst_set_qtr_control(brw, insn, BRW_COMPRESSION_NONE);
      brw_inst_set_exec_size(brw, insn, execute_size);
      brw_inst_set_pred_control(brw, insn, BRW_PREDICATE_NONE);
d1645 1
a1645 1
brw_patch_break_cont(struct brw_compile *p, brw_inst *while_inst)
d1648 3
a1650 5
   brw_inst *do_inst = get_inner_do_insn(p);
   brw_inst *inst;
   unsigned br = brw_jump_scale(brw);

   assert(brw->gen < 6);
d1657 6
a1662 6
      if (brw_inst_opcode(brw, inst) == BRW_OPCODE_BREAK &&
          brw_inst_gen4_jump_count(brw, inst) == 0) {
         brw_inst_set_gen4_jump_count(brw, inst, br*((while_inst - inst) + 1));
      } else if (brw_inst_opcode(brw, inst) == BRW_OPCODE_CONTINUE &&
                 brw_inst_gen4_jump_count(brw, inst) == 0) {
         brw_inst_set_gen4_jump_count(brw, inst, br * (while_inst - inst));
d1667 1
a1667 2
brw_inst *
brw_WHILE(struct brw_compile *p)
d1670 9
a1678 2
   brw_inst *insn, *do_insn;
   unsigned br = brw_jump_scale(brw);
d1680 7
a1686 1
   if (brw->gen >= 6) {
d1690 4
a1693 15
      if (brw->gen >= 8) {
         brw_set_dest(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
         brw_set_src0(p, insn, brw_imm_d(0));
         brw_inst_set_jip(brw, insn, br * (do_insn - insn));
      } else if (brw->gen == 7) {
         brw_set_dest(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
         brw_set_src0(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
         brw_set_src1(p, insn, brw_imm_ud(0));
         brw_inst_set_jip(brw, insn, br * (do_insn - insn));
      } else {
         brw_set_dest(p, insn, brw_imm_w(0));
         brw_inst_set_gen6_jump_count(brw, insn, br * (do_insn - insn));
         brw_set_src0(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
         brw_set_src1(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
      }
d1695 1
a1695 2
      brw_inst_set_exec_size(brw, insn, p->compressed ? BRW_EXECUTE_16
                                                      : BRW_EXECUTE_8);
d1704 1
a1704 1
         brw_inst_set_exec_size(brw, insn, BRW_EXECUTE_1);
d1709 1
a1709 1
         assert(brw_inst_opcode(brw, do_insn) == BRW_OPCODE_DO);
d1715 4
a1718 3
         brw_inst_set_exec_size(brw, insn, brw_inst_exec_size(brw, do_insn));
         brw_inst_set_gen4_jump_count(brw, insn, br * (do_insn - insn + 1));
         brw_inst_set_gen4_pop_count(brw, insn, 0);
d1723 2
a1724 1
   brw_inst_set_qtr_control(brw, insn, BRW_COMPRESSION_NONE);
d1731 1
d1737 1
a1737 1
   brw_inst *jmp_insn = &p->store[jmp_insn_idx];
d1743 2
a1744 2
   assert(brw_inst_opcode(brw, jmp_insn) == BRW_OPCODE_JMPI);
   assert(brw_inst_src1_reg_file(brw, jmp_insn) == BRW_IMMEDIATE_VALUE);
d1746 1
a1746 2
   brw_inst_set_gen4_jump_count(brw, jmp_insn,
                                jmpi * (p->nr_insn - jmp_insn_idx - 1));
d1749 2
d1762 1
a1762 9
   brw_inst *insn = next_insn(p, BRW_OPCODE_CMP);

   if (brw->gen >= 8) {
      /* The CMP instruction appears to behave erratically for floating point
       * sources unless the destination type is also float.  Overriding it to
       * match src0 makes it work in all cases.
       */
      dest.type = src0.type;
   }
d1764 1
a1764 1
   brw_inst_set_cond_modifier(brw, insn, conditional);
d1769 13
d1792 1
a1792 1
         brw_inst_set_thread_control(brw, insn, BRW_THREAD_SWITCH);
d1797 16
d1819 1
a1819 1
void gen4_math(struct brw_compile *p,
d1824 1
d1828 34
a1861 6
   brw_inst *insn = next_insn(p, BRW_OPCODE_SEND);
   unsigned data_type;
   if (src.vstride == BRW_VERTICAL_STRIDE_0 &&
       src.width == BRW_WIDTH_1 &&
       src.hstride == BRW_HORIZONTAL_STRIDE_0) {
      data_type = BRW_MATH_DATA_SCALAR;
d1863 1
a1863 2
      data_type = BRW_MATH_DATA_VECTOR;
   }
d1865 5
a1869 1
   assert(brw->gen < 6);
d1871 9
a1879 14
   /* Example code doesn't set predicate_control for send
    * instructions.
    */
   brw_inst_set_pred_control(brw, insn, 0);
   brw_inst_set_base_mrf(brw, insn, msg_reg_nr);

   brw_set_dest(p, insn, dest);
   brw_set_src0(p, insn, src);
   brw_set_math_message(p,
                        insn,
                        function,
                        src.type == BRW_REGISTER_TYPE_D,
                        precision,
                        data_type);
d1882 3
a1884 1
void gen6_math(struct brw_compile *p,
d1891 1
a1891 3
   brw_inst *insn = next_insn(p, BRW_OPCODE_MATH);

   assert(brw->gen >= 6);
d1895 2
a1896 2
   assert(src0.file == BRW_GENERAL_REGISTER_FILE ||
          (brw->gen >= 8 && src0.file == BRW_IMMEDIATE_VALUE));
a1908 2
      assert(src1.file == BRW_GENERAL_REGISTER_FILE ||
             (brw->gen >= 8 && src1.file == BRW_IMMEDIATE_VALUE));
a1911 7
      if (function == BRW_MATH_FUNCTION_POW) {
         assert(src1.file == BRW_GENERAL_REGISTER_FILE ||
                (brw->gen >= 8 && src1.file == BRW_IMMEDIATE_VALUE));
      } else {
         assert(src1.file == BRW_ARCHITECTURE_REGISTER_FILE &&
                src1.nr == BRW_ARF_NULL);
      }
d1922 4
a1925 1
   brw_inst_set_math_function(brw, insn, function);
d1969 2
a1970 2
      brw_set_default_mask_control(p, BRW_MASK_DISABLE);
      brw_set_default_compression_control(p, BRW_COMPRESSION_NONE);
d1986 1
a1986 1
      brw_inst *insn = next_insn(p, BRW_OPCODE_SEND);
d1991 2
a1992 2
      if (brw_inst_qtr_control(brw, insn) != BRW_COMPRESSION_NONE) {
         brw_inst_set_qtr_control(brw, insn, BRW_COMPRESSION_NONE);
d1995 2
a1996 3
      assert(brw_inst_pred_control(brw, insn) == BRW_PREDICATE_NONE);
      if (brw->gen < 6)
         brw_inst_set_base_mrf(brw, insn, mrf.nr);
d2064 1
a2064 12
   if (p->brw->gen >= 7) {
      /* On gen 7 and above, we no longer have message registers and we can
       * send from any register we want.  By using the destination register
       * for the message, we guarantee that the implied message write won't
       * accidentally overwrite anything.  This has been a problem because
       * the MRF registers and source for the final FB write are both fixed
       * and may overlap.
       */
      mrf = retype(dest, BRW_REGISTER_TYPE_UD);
   } else {
      mrf = retype(mrf, BRW_REGISTER_TYPE_UD);
   }
d2077 2
a2078 2
      brw_set_default_compression_control(p, BRW_COMPRESSION_NONE);
      brw_set_default_mask_control(p, BRW_MASK_DISABLE);
d2083 5
a2087 1
      brw_MOV(p, get_element_ud(mrf, 2), brw_imm_ud(offset));
d2093 1
a2093 1
      brw_inst *insn = next_insn(p, BRW_OPCODE_SEND);
d2095 3
a2097 2
      assert(brw_inst_pred_control(brw, insn) == 0);
      brw_inst_set_qtr_control(brw, insn, BRW_COMPRESSION_NONE);
a2103 1
         brw_inst_set_base_mrf(brw, insn, mrf.nr);
d2124 3
a2126 3
   const struct brw_context *brw = p->brw;
   brw_inst *insn = next_insn(p, BRW_OPCODE_SEND);
   assert(brw_inst_pred_control(brw, insn) == BRW_PREDICATE_NONE);
d2128 4
a2131 2
   brw_inst_set_qtr_control(brw, insn, BRW_COMPRESSION_NONE);
   brw_set_dest(p, insn, retype(dest, BRW_REGISTER_TYPE_UW));
d2136 1
d2139 12
d2157 1
a2157 10

   gen7_set_dp_scratch_message(p, insn,
                               false, /* scratch read */
                               false, /* OWords */
                               false, /* invalidate after read */
                               num_regs,
                               offset,
                               1,        /* mlen: just g0 */
                               num_regs, /* rlen */
                               true);    /* header present */
d2180 3
a2182 3
   brw_set_default_predicate_control(p, BRW_PREDICATE_NONE);
   brw_set_default_compression_control(p, BRW_COMPRESSION_NONE);
   brw_set_default_mask_control(p, BRW_MASK_DISABLE);
d2193 2
a2194 1
   brw_inst *insn = next_insn(p, BRW_OPCODE_SEND);
a2203 1
      brw_inst_set_base_mrf(brw, insn, mrf.nr);
d2222 2
a2223 2
                  struct brw_reg payload,
                  struct brw_reg implied_header,
d2232 1
a2232 1
   brw_inst *insn;
d2234 1
a2234 1
   struct brw_reg dest, src0;
d2246 1
a2246 1
   brw_inst_set_qtr_control(brw, insn, BRW_COMPRESSION_NONE);
d2250 1
a2250 1
      src0 = payload;
d2254 1
a2254 3
      assert(payload.file == BRW_MESSAGE_REGISTER_FILE);
      brw_inst_set_base_mrf(brw, insn, payload.nr);
      src0 = implied_header;
d2294 1
a2294 1
   brw_inst *insn;
d2300 1
a2300 1
   brw_inst_set_pred_control(brw, insn, BRW_PREDICATE_NONE); /* XXX */
d2314 2
a2315 2
   if (brw_inst_qtr_control(brw, insn) != BRW_COMPRESSION_2NDHALF)
      brw_inst_set_qtr_control(brw, insn, BRW_COMPRESSION_NONE);
d2318 1
a2318 1
      brw_inst_set_base_mrf(brw, insn, msg_reg_nr);
a2332 47
/* Adjust the message header's sampler state pointer to
 * select the correct group of 16 samplers.
 */
void brw_adjust_sampler_state_pointer(struct brw_compile *p,
                                      struct brw_reg header,
                                      struct brw_reg sampler_index,
                                      struct brw_reg scratch)
{
   /* The "Sampler Index" field can only store values between 0 and 15.
    * However, we can add an offset to the "Sampler State Pointer"
    * field, effectively selecting a different set of 16 samplers.
    *
    * The "Sampler State Pointer" needs to be aligned to a 32-byte
    * offset, and each sampler state is only 16-bytes, so we can't
    * exclusively use the offset - we have to use both.
    */

   struct brw_context *brw = p->brw;

   if (sampler_index.file == BRW_IMMEDIATE_VALUE) {
      const int sampler_state_size = 16; /* 16 bytes */
      uint32_t sampler = sampler_index.dw1.ud;

      if (sampler >= 16) {
         assert(brw->is_haswell || brw->gen >= 8);
         brw_ADD(p,
                 get_element_ud(header, 3),
                 get_element_ud(brw_vec8_grf(0, 0), 3),
                 brw_imm_ud(16 * (sampler / 16) * sampler_state_size));
      }
   } else {
      /* Non-const sampler array indexing case */
      if (brw->gen < 8 && !brw->is_haswell) {
         return;
      }

      struct brw_reg temp = vec1(retype(scratch, BRW_REGISTER_TYPE_UD));

      brw_AND(p, temp, get_element_ud(sampler_index, 0), brw_imm_ud(0x0f0));
      brw_SHL(p, temp, temp, brw_imm_ud(4));
      brw_ADD(p,
              get_element_ud(header, 3),
              get_element_ud(brw_vec8_grf(0, 0), 3),
              temp);
   }
}

d2348 1
a2348 1
   brw_inst *insn;
d2352 1
a2352 1
   if (brw->gen >= 7 && !(flags & BRW_URB_WRITE_USE_CHANNEL_MASKS)) {
d2355 2
a2356 2
      brw_set_default_access_mode(p, BRW_ALIGN_1);
      brw_set_default_mask_control(p, BRW_MASK_DISABLE);
d2373 1
a2373 1
      brw_inst_set_base_mrf(brw, insn, msg_reg_nr);
d2385 1
a2385 1
brw_find_next_block_end(struct brw_compile *p, int start_offset)
d2387 12
a2398 1
   int offset;
a2399 1
   const struct brw_context *brw = p->brw;
d2401 2
a2402 4
   for (offset = next_offset(brw, store, start_offset);
        offset < p->next_insn_offset;
        offset = next_offset(brw, store, offset)) {
      brw_inst *insn = store + offset;
d2404 1
a2404 1
      switch (brw_inst_opcode(brw, insn)) {
d2409 1
a2409 1
	 return offset;
d2421 1
a2421 1
brw_find_loop_end(struct brw_compile *p, int start_offset)
d2424 2
a2425 2
   int offset;
   int scale = 16 / brw_jump_scale(brw);
a2427 2
   assert(brw->gen >= 6);

d2431 8
a2438 10
   for (offset = next_offset(brw, store, start_offset);
        offset < p->next_insn_offset;
        offset = next_offset(brw, store, offset)) {
      brw_inst *insn = store + offset;

      if (brw_inst_opcode(brw, insn) == BRW_OPCODE_WHILE) {
         int jip = brw->gen == 6 ? brw_inst_gen6_jump_count(brw, insn)
                                 : brw_inst_jip(brw, insn);
	 if (offset + jip * scale <= start_offset)
	    return offset;
d2442 1
a2442 1
   return start_offset;
d2452 2
a2453 3
   int offset;
   int br = brw_jump_scale(brw);
   int scale = 16 / br;
d2459 2
a2460 3
   for (offset = 0; offset < p->next_insn_offset;
        offset = next_offset(brw, store, offset)) {
      brw_inst *insn = store + offset;
d2462 1
a2462 1
      if (brw_inst_cmpt_control(brw, insn)) {
d2464 3
a2466 3
         assert(brw_inst_opcode(brw, insn) != BRW_OPCODE_BREAK &&
                brw_inst_opcode(brw, insn) != BRW_OPCODE_CONTINUE &&
                brw_inst_opcode(brw, insn) != BRW_OPCODE_HALT);
d2470 2
a2471 2
      int block_end_offset = brw_find_next_block_end(p, offset);
      switch (brw_inst_opcode(brw, insn)) {
d2473 2
a2474 2
         assert(block_end_offset != 0);
         brw_inst_set_jip(brw, insn, (block_end_offset - offset) / scale);
d2476 3
a2478 3
         brw_inst_set_uip(brw, insn,
	    (brw_find_loop_end(p, offset) - offset +
             (brw->gen == 6 ? 16 : 0)) / scale);
d2481 4
a2484 4
         assert(block_end_offset != 0);
         brw_inst_set_jip(brw, insn, (block_end_offset - offset) / scale);
         brw_inst_set_uip(brw, insn,
            (brw_find_loop_end(p, offset) - offset) / scale);
d2486 2
a2487 2
         assert(brw_inst_uip(brw, insn) != 0);
         assert(brw_inst_jip(brw, insn) != 0);
d2490 3
a2492 5
      case BRW_OPCODE_ENDIF: {
         int32_t jump = (block_end_offset == 0) ?
                        1 * br : (block_end_offset - offset) / scale;
         if (brw->gen >= 7)
            brw_inst_set_jip(brw, insn, jump);
d2494 1
a2494 1
            brw_inst_set_gen6_jump_count(brw, insn, jump);
a2495 1
      }
d2509 2
a2510 2
	 if (block_end_offset == 0) {
            brw_inst_set_jip(brw, insn, brw_inst_uip(brw, insn));
d2512 1
a2512 1
            brw_inst_set_jip(brw, insn, (block_end_offset - offset) / scale);
d2514 2
a2515 2
         assert(brw_inst_uip(brw, insn) != 0);
         assert(brw_inst_jip(brw, insn) != 0);
d2530 1
a2530 1
   brw_inst *insn;
d2540 1
a2540 1
      brw_inst_set_base_mrf(brw, insn, msg_reg_nr);
d2568 1
a2568 1
   brw_inst *insn;
d2590 1
a2590 1
                                  brw_inst *insn,
d2597 1
a2597 7
   const struct brw_context *brw = p->brw;

   unsigned msg_control =
      atomic_op | /* Atomic Operation Type: BRW_AOP_* */
      (response_length ? 1 << 5 : 0); /* Return data expected */

   if (brw->gen >= 8 || brw->is_haswell) {
d2603 3
a2605 3
      if (brw_inst_access_mode(brw, insn) == BRW_ALIGN_1) {
         if (brw_inst_exec_size(brw, insn) != BRW_EXECUTE_16)
            msg_control |= 1 << 4; /* SIMD8 mode */
d2607 2
a2608 2
         brw_inst_set_dp_msg_type(brw, insn,
                                  HSW_DATAPORT_DC_PORT1_UNTYPED_ATOMIC_OP);
d2610 2
a2611 2
         brw_inst_set_dp_msg_type(brw, insn,
            HSW_DATAPORT_DC_PORT1_UNTYPED_ATOMIC_OP_SIMD4X2);
d2613 1
d2619 1
a2619 1
      brw_inst_set_dp_msg_type(brw, insn, GEN7_DATAPORT_DC_UNTYPED_ATOMIC_OP);
d2621 2
a2622 2
      if (brw_inst_exec_size(brw, insn) != BRW_EXECUTE_16)
         msg_control |= 1 << 4; /* SIMD8 mode */
d2625 5
a2629 2
   brw_inst_set_binding_table_index(brw, insn, bind_table_index);
   brw_inst_set_dp_msg_control(brw, insn, msg_control);
d2635 1
a2635 1
                   struct brw_reg payload,
d2640 1
a2640 2
   const struct brw_context *brw = p->brw;
   brw_inst *insn = brw_next_insn(p, BRW_OPCODE_SEND);
d2643 1
a2643 1
   brw_set_src0(p, insn, retype(payload, BRW_REGISTER_TYPE_UD));
d2647 1
a2647 1
      brw_inst_access_mode(brw, insn) == BRW_ALIGN_1);
d2652 1
a2652 1
                                        brw_inst *insn,
a2657 1
   const struct brw_context *brw = p->brw;
d2659 1
a2659 1
      (brw_inst_exec_size(brw, insn) == BRW_EXECUTE_16 ? 16 : 8);
d2662 1
a2662 1
   if (brw->gen >= 8 || brw->is_haswell) {
d2667 1
a2667 2
      brw_inst_set_dp_msg_type(brw, insn,
                               HSW_DATAPORT_DC_PORT1_UNTYPED_SURFACE_READ);
d2673 1
a2673 2
      brw_inst_set_dp_msg_type(brw, insn,
                               GEN7_DATAPORT_DC_UNTYPED_SURFACE_READ);
d2676 1
a2676 4
   /* Set mask of 32-bit channels to drop. */
   unsigned msg_control = (0xf & (0xf << num_channels));

   if (brw_inst_access_mode(brw, insn) == BRW_ALIGN_1) {
d2678 1
a2678 1
         msg_control |= 1 << 4; /* SIMD16 mode */
d2680 1
a2680 1
         msg_control |= 2 << 4; /* SIMD8 mode */
d2683 4
a2686 2
   brw_inst_set_binding_table_index(brw, insn, bind_table_index);
   brw_inst_set_dp_msg_control(brw, insn, msg_control);
d2697 1
a2697 2
   const struct brw_context *brw = p->brw;
   brw_inst *insn = next_insn(p, BRW_OPCODE_SEND);
d2703 1
a2703 29
      brw_inst_access_mode(brw, insn) == BRW_ALIGN_1);
}

void
brw_pixel_interpolator_query(struct brw_compile *p,
                             struct brw_reg dest,
                             struct brw_reg mrf,
                             bool noperspective,
                             unsigned mode,
                             unsigned data,
                             unsigned msg_length,
                             unsigned response_length)
{
   const struct brw_context *brw = p->brw;
   struct brw_inst *insn = next_insn(p, BRW_OPCODE_SEND);

   brw_set_dest(p, insn, dest);
   brw_set_src0(p, insn, mrf);
   brw_set_message_descriptor(p, insn, GEN7_SFID_PIXEL_INTERPOLATOR,
                              msg_length, response_length,
                              false /* header is never present for PI */,
                              false);

   brw_inst_set_pi_simd_mode(
         brw, insn, brw_inst_exec_size(brw, insn) == BRW_EXECUTE_16);
   brw_inst_set_pi_slot_group(brw, insn, 0); /* zero unless 32/64px dispatch */
   brw_inst_set_pi_nopersp(brw, insn, noperspective);
   brw_inst_set_pi_message_type(brw, insn, mode);
   brw_inst_set_pi_message_data(brw, insn, data);
d2726 2
a2727 1
   assert(p->brw->gen >= 7);
d2730 3
a2732 3
   brw_set_default_access_mode(p, BRW_ALIGN_1);
   brw_set_default_mask_control(p, BRW_MASK_DISABLE);
   brw_inst *send = brw_next_insn(p, BRW_OPCODE_SEND);
@


1.1.1.7
log
@Import Mesa 10.2.9
@
text
@d37 1
a37 1
#include "glsl/ralloc.h"
d44 1
a44 1
				 struct brw_instruction *insn,
d47 8
a54 4
   if (reg.width == BRW_WIDTH_8 && p->compressed)
      insn->header.execution_size = BRW_EXECUTE_16;
   else
      insn->header.execution_size = reg.width;	/* note - definitions are compatible */
d79 2
a80 2
      brw_set_mask_control(p, BRW_MASK_DISABLE);
      brw_set_compression_control(p, BRW_COMPRESSION_NONE);
d100 1
a100 1
   if (brw->gen == 7 && reg->file == BRW_MESSAGE_REGISTER_FILE) {
d163 1
a163 2
brw_set_dest(struct brw_compile *p, struct brw_instruction *insn,
	     struct brw_reg dest)
d165 2
d173 4
a176 4
   insn->bits1.da1.dest_reg_file = dest.file;
   insn->bits1.da1.dest_reg_type =
      brw_reg_type_to_hw_type(p->brw, dest.type, dest.file);
   insn->bits1.da1.dest_address_mode = dest.address_mode;
d179 1
a179 1
      insn->bits1.da1.dest_reg_nr = dest.nr;
d181 2
a182 2
      if (insn->header.access_mode == BRW_ALIGN_1) {
	 insn->bits1.da1.dest_subreg_nr = dest.subnr;
d185 4
a188 5
	 insn->bits1.da1.dest_horiz_stride = dest.hstride;
      }
      else {
	 insn->bits1.da16.dest_subreg_nr = dest.subnr / 16;
	 insn->bits1.da16.dest_writemask = dest.dw1.bits.writemask;
d197 1
a197 1
	 insn->bits1.da16.dest_horiz_stride = 1;
d199 2
a200 3
   }
   else {
      insn->bits1.ia1.dest_subreg_nr = dest.subnr;
d204 3
a206 2
      if (insn->header.access_mode == BRW_ALIGN_1) {
	 insn->bits1.ia1.dest_indirect_offset = dest.dw1.bits.indirect_offset;
d209 4
a212 4
	 insn->bits1.ia1.dest_horiz_stride = dest.hstride;
      }
      else {
	 insn->bits1.ia16.dest_indirect_offset = dest.dw1.bits.indirect_offset;
d214 1
a214 1
	 insn->bits1.ia16.dest_horiz_stride = 1;
d219 1
a219 1
    * insn->compression_control:
d221 1
a221 1
   guess_execution_size(p, insn, dest);
d227 1
a227 1
validate_reg(struct brw_instruction *insn, struct brw_reg reg)
d230 1
a230 1
   int vstride_for_reg[] = {0, 1, 2, 4, 8, 16, 32, 64, 128, 256};
d241 2
a242 2
	 assert(hstride_for_reg[insn->bits1.da1.dest_horiz_stride] *
		reg_type_size[insn->bits1.da1.dest_reg_type] == 2);
d265 3
a267 3
   assert(insn->header.execution_size >= 0 &&
	  insn->header.execution_size < Elements(execsize_for_reg));
   execsize = execsize_for_reg[insn->header.execution_size];
d302 10
d313 1
a313 2
brw_set_src0(struct brw_compile *p, struct brw_instruction *insn,
	     struct brw_reg reg)
d317 1
a317 1
   if (reg.type != BRW_ARCHITECTURE_REGISTER_FILE)
d322 2
a323 2
   if (brw->gen >= 6 && (insn->header.opcode == BRW_OPCODE_SEND ||
                           insn->header.opcode == BRW_OPCODE_SENDC)) {
d333 1
a333 1
   validate_reg(insn, reg);
d335 6
a340 6
   insn->bits1.da1.src0_reg_file = reg.file;
   insn->bits1.da1.src0_reg_type =
      brw_reg_type_to_hw_type(brw, reg.type, reg.file);
   insn->bits2.da1.src0_abs = reg.abs;
   insn->bits2.da1.src0_negate = reg.negate;
   insn->bits2.da1.src0_address_mode = reg.address_mode;
d343 1
a343 1
      insn->bits3.ud = reg.dw1.ud;
d345 21
a365 1
      /* Required to set some fields in src1 as well:
d367 35
a401 5
      insn->bits1.da1.src1_reg_file = 0; /* arf */
      insn->bits1.da1.src1_reg_type = insn->bits1.da1.src0_reg_type;
   }
   else
   {
d403 5
a407 3
	 if (insn->header.access_mode == BRW_ALIGN_1) {
	    insn->bits2.da1.src0_subreg_nr = reg.subnr;
	    insn->bits2.da1.src0_reg_nr = reg.nr;
d409 2
a410 7
	 else {
	    insn->bits2.da16.src0_subreg_nr = reg.subnr / 16;
	    insn->bits2.da16.src0_reg_nr = reg.nr;
	 }
      }
      else {
	 insn->bits2.ia1.src0_subreg_nr = reg.subnr;
d412 4
a415 5
	 if (insn->header.access_mode == BRW_ALIGN_1) {
	    insn->bits2.ia1.src0_indirect_offset = reg.dw1.bits.indirect_offset;
	 }
	 else {
	    insn->bits2.ia16.src0_subreg_nr = reg.dw1.bits.indirect_offset;
d419 1
a419 1
      if (insn->header.access_mode == BRW_ALIGN_1) {
d421 8
a428 4
	     insn->header.execution_size == BRW_EXECUTE_1) {
	    insn->bits2.da1.src0_horiz_stride = BRW_HORIZONTAL_STRIDE_0;
	    insn->bits2.da1.src0_width = BRW_WIDTH_1;
	    insn->bits2.da1.src0_vert_stride = BRW_VERTICAL_STRIDE_0;
d430 9
a438 11
	 else {
	    insn->bits2.da1.src0_horiz_stride = reg.hstride;
	    insn->bits2.da1.src0_width = reg.width;
	    insn->bits2.da1.src0_vert_stride = reg.vstride;
	 }
      }
      else {
	 insn->bits2.da16.src0_swz_x = BRW_GET_SWZ(reg.dw1.bits.swizzle, BRW_CHANNEL_X);
	 insn->bits2.da16.src0_swz_y = BRW_GET_SWZ(reg.dw1.bits.swizzle, BRW_CHANNEL_Y);
	 insn->bits2.da16.src0_swz_z = BRW_GET_SWZ(reg.dw1.bits.swizzle, BRW_CHANNEL_Z);
	 insn->bits2.da16.src0_swz_w = BRW_GET_SWZ(reg.dw1.bits.swizzle, BRW_CHANNEL_W);
d444 1
a444 1
	    insn->bits2.da16.src0_vert_stride = BRW_VERTICAL_STRIDE_4;
d446 1
a446 1
	    insn->bits2.da16.src0_vert_stride = reg.vstride;
d452 2
a453 3
void brw_set_src1(struct brw_compile *p,
		  struct brw_instruction *insn,
		  struct brw_reg reg)
d455 1
d458 1
a458 1
   if (reg.type != BRW_ARCHITECTURE_REGISTER_FILE)
d463 1
a463 1
   validate_reg(insn, reg);
d465 5
a469 5
   insn->bits1.da1.src1_reg_file = reg.file;
   insn->bits1.da1.src1_reg_type =
      brw_reg_type_to_hw_type(p->brw, reg.type, reg.file);
   insn->bits3.da1.src1_abs = reg.abs;
   insn->bits3.da1.src1_negate = reg.negate;
d473 1
a473 1
   assert(insn->bits1.da1.src0_reg_file != BRW_IMMEDIATE_VALUE);
d476 2
a477 3
      insn->bits3.ud = reg.dw1.ud;
   }
   else {
d484 5
a488 7
      if (insn->header.access_mode == BRW_ALIGN_1) {
	 insn->bits3.da1.src1_subreg_nr = reg.subnr;
	 insn->bits3.da1.src1_reg_nr = reg.nr;
      }
      else {
	 insn->bits3.da16.src1_subreg_nr = reg.subnr / 16;
	 insn->bits3.da16.src1_reg_nr = reg.nr;
d491 1
a491 1
      if (insn->header.access_mode == BRW_ALIGN_1) {
d493 8
a500 4
	     insn->header.execution_size == BRW_EXECUTE_1) {
	    insn->bits3.da1.src1_horiz_stride = BRW_HORIZONTAL_STRIDE_0;
	    insn->bits3.da1.src1_width = BRW_WIDTH_1;
	    insn->bits3.da1.src1_vert_stride = BRW_VERTICAL_STRIDE_0;
d502 9
a510 11
	 else {
	    insn->bits3.da1.src1_horiz_stride = reg.hstride;
	    insn->bits3.da1.src1_width = reg.width;
	    insn->bits3.da1.src1_vert_stride = reg.vstride;
	 }
      }
      else {
	 insn->bits3.da16.src1_swz_x = BRW_GET_SWZ(reg.dw1.bits.swizzle, BRW_CHANNEL_X);
	 insn->bits3.da16.src1_swz_y = BRW_GET_SWZ(reg.dw1.bits.swizzle, BRW_CHANNEL_Y);
	 insn->bits3.da16.src1_swz_z = BRW_GET_SWZ(reg.dw1.bits.swizzle, BRW_CHANNEL_Z);
	 insn->bits3.da16.src1_swz_w = BRW_GET_SWZ(reg.dw1.bits.swizzle, BRW_CHANNEL_W);
d516 1
a516 1
	    insn->bits3.da16.src1_vert_stride = BRW_VERTICAL_STRIDE_4;
d518 1
a518 1
	    insn->bits3.da16.src1_vert_stride = reg.vstride;
d533 1
a533 1
			   struct brw_instruction *inst,
d544 16
d561 1
a561 18
      inst->bits3.generic_gen5.header_present = header_present;
      inst->bits3.generic_gen5.response_length = response_length;
      inst->bits3.generic_gen5.msg_length = msg_length;
      inst->bits3.generic_gen5.end_of_thread = end_of_thread;

      if (brw->gen >= 6) {
	 /* On Gen6+ Message target/SFID goes in bits 27:24 of the header */
	 inst->header.destreg__conditionalmod = sfid;
      } else {
	 /* Set Extended Message Descriptor (ex_desc) */
	 inst->bits2.send_gen5.sfid = sfid;
	 inst->bits2.send_gen5.end_of_thread = end_of_thread;
      }
   } else {
      inst->bits3.generic.response_length = response_length;
      inst->bits3.generic.msg_length = msg_length;
      inst->bits3.generic.msg_target = sfid;
      inst->bits3.generic.end_of_thread = end_of_thread;
d566 1
a566 1
				  struct brw_instruction *insn,
d601 1
a601 1
   brw_set_message_descriptor(p, insn, BRW_SFID_MATH,
d603 6
a608 15
   if (brw->gen == 5) {
      insn->bits3.math_gen5.function = function;
      insn->bits3.math_gen5.int_type = integer_type;
      insn->bits3.math_gen5.precision = low_precision;
      insn->bits3.math_gen5.saturate = insn->header.saturate;
      insn->bits3.math_gen5.data_type = dataType;
      insn->bits3.math_gen5.snapshot = 0;
   } else {
      insn->bits3.math.function = function;
      insn->bits3.math.int_type = integer_type;
      insn->bits3.math.precision = low_precision;
      insn->bits3.math.saturate = insn->header.saturate;
      insn->bits3.math.data_type = dataType;
   }
   insn->header.saturate = 0;
d613 1
a613 1
				    struct brw_instruction *insn,
d618 2
d622 7
a628 6
   insn->bits3.urb_gen5.opcode = 1; /* FF_SYNC */
   insn->bits3.urb_gen5.offset = 0; /* Not used by FF_SYNC */
   insn->bits3.urb_gen5.swizzle_control = 0; /* Not used by FF_SYNC */
   insn->bits3.urb_gen5.allocate = allocate;
   insn->bits3.urb_gen5.used = 0; /* Not used by FF_SYNC */
   insn->bits3.urb_gen5.complete = 0; /* Not used by FF_SYNC */
d632 1
a632 1
				 struct brw_instruction *insn,
d641 4
d648 21
a668 27
   if (brw->gen == 7) {
      if (flags & BRW_URB_WRITE_OWORD) {
         assert(msg_length == 2); /* header + one OWORD of data */
         insn->bits3.urb_gen7.opcode = BRW_URB_OPCODE_WRITE_OWORD;
      } else {
         insn->bits3.urb_gen7.opcode = BRW_URB_OPCODE_WRITE_HWORD;
      }
      insn->bits3.urb_gen7.offset = offset;
      assert(swizzle_control != BRW_URB_SWIZZLE_TRANSPOSE);
      insn->bits3.urb_gen7.swizzle_control = swizzle_control;
      insn->bits3.urb_gen7.per_slot_offset =
         flags & BRW_URB_WRITE_PER_SLOT_OFFSET ? 1 : 0;
      insn->bits3.urb_gen7.complete = flags & BRW_URB_WRITE_COMPLETE ? 1 : 0;
   } else if (brw->gen >= 5) {
      insn->bits3.urb_gen5.opcode = 0;	/* URB_WRITE */
      insn->bits3.urb_gen5.offset = offset;
      insn->bits3.urb_gen5.swizzle_control = swizzle_control;
      insn->bits3.urb_gen5.allocate = flags & BRW_URB_WRITE_ALLOCATE ? 1 : 0;
      insn->bits3.urb_gen5.used = flags & BRW_URB_WRITE_UNUSED ? 0 : 1;
      insn->bits3.urb_gen5.complete = flags & BRW_URB_WRITE_COMPLETE ? 1 : 0;
   } else {
      insn->bits3.urb.opcode = 0;	/* ? */
      insn->bits3.urb.offset = offset;
      insn->bits3.urb.swizzle_control = swizzle_control;
      insn->bits3.urb.allocate = flags & BRW_URB_WRITE_ALLOCATE ? 1 : 0;
      insn->bits3.urb.used = flags & BRW_URB_WRITE_UNUSED ? 0 : 1;
      insn->bits3.urb.complete = flags & BRW_URB_WRITE_COMPLETE ? 1 : 0;
d674 1
a674 1
			 struct brw_instruction *insn,
d704 6
a709 23
   if (brw->gen >= 7) {
      insn->bits3.gen7_dp.binding_table_index = binding_table_index;
      insn->bits3.gen7_dp.msg_control = msg_control;
      insn->bits3.gen7_dp.last_render_target = last_render_target;
      insn->bits3.gen7_dp.msg_type = msg_type;
   } else if (brw->gen == 6) {
      insn->bits3.gen6_dp.binding_table_index = binding_table_index;
      insn->bits3.gen6_dp.msg_control = msg_control;
      insn->bits3.gen6_dp.last_render_target = last_render_target;
      insn->bits3.gen6_dp.msg_type = msg_type;
      insn->bits3.gen6_dp.send_commit_msg = send_commit_msg;
   } else if (brw->gen == 5) {
      insn->bits3.dp_write_gen5.binding_table_index = binding_table_index;
      insn->bits3.dp_write_gen5.msg_control = msg_control;
      insn->bits3.dp_write_gen5.last_render_target = last_render_target;
      insn->bits3.dp_write_gen5.msg_type = msg_type;
      insn->bits3.dp_write_gen5.send_commit_msg = send_commit_msg;
   } else {
      insn->bits3.dp_write.binding_table_index = binding_table_index;
      insn->bits3.dp_write.msg_control = msg_control;
      insn->bits3.dp_write.last_render_target = last_render_target;
      insn->bits3.dp_write.msg_type = msg_type;
      insn->bits3.dp_write.send_commit_msg = send_commit_msg;
d715 1
a715 1
			struct brw_instruction *insn,
d741 5
a745 27
   if (brw->gen >= 7) {
      insn->bits3.gen7_dp.binding_table_index = binding_table_index;
      insn->bits3.gen7_dp.msg_control = msg_control;
      insn->bits3.gen7_dp.last_render_target = 0;
      insn->bits3.gen7_dp.msg_type = msg_type;
   } else if (brw->gen == 6) {
      insn->bits3.gen6_dp.binding_table_index = binding_table_index;
      insn->bits3.gen6_dp.msg_control = msg_control;
      insn->bits3.gen6_dp.last_render_target = 0;
      insn->bits3.gen6_dp.msg_type = msg_type;
      insn->bits3.gen6_dp.send_commit_msg = 0;
   } else if (brw->gen == 5) {
      insn->bits3.dp_read_gen5.binding_table_index = binding_table_index;
      insn->bits3.dp_read_gen5.msg_control = msg_control;
      insn->bits3.dp_read_gen5.msg_type = msg_type;
      insn->bits3.dp_read_gen5.target_cache = target_cache;
   } else if (brw->is_g4x) {
      insn->bits3.dp_read_g4x.binding_table_index = binding_table_index; /*0:7*/
      insn->bits3.dp_read_g4x.msg_control = msg_control;  /*8:10*/
      insn->bits3.dp_read_g4x.msg_type = msg_type;  /*11:13*/
      insn->bits3.dp_read_g4x.target_cache = target_cache;  /*14:15*/
   } else {
      insn->bits3.dp_read.binding_table_index = binding_table_index; /*0:7*/
      insn->bits3.dp_read.msg_control = msg_control;  /*8:11*/
      insn->bits3.dp_read.msg_type = msg_type;  /*12:13*/
      insn->bits3.dp_read.target_cache = target_cache;  /*14:15*/
   }
d750 1
a750 1
                        struct brw_instruction *insn,
d762 1
a762 1
   brw_set_message_descriptor(p, insn, BRW_SFID_SAMPLER, msg_length,
d765 7
a771 19
   if (brw->gen >= 7) {
      insn->bits3.sampler_gen7.binding_table_index = binding_table_index;
      insn->bits3.sampler_gen7.sampler = sampler;
      insn->bits3.sampler_gen7.msg_type = msg_type;
      insn->bits3.sampler_gen7.simd_mode = simd_mode;
   } else if (brw->gen >= 5) {
      insn->bits3.sampler_gen5.binding_table_index = binding_table_index;
      insn->bits3.sampler_gen5.sampler = sampler;
      insn->bits3.sampler_gen5.msg_type = msg_type;
      insn->bits3.sampler_gen5.simd_mode = simd_mode;
   } else if (brw->is_g4x) {
      insn->bits3.sampler_g4x.binding_table_index = binding_table_index;
      insn->bits3.sampler_g4x.sampler = sampler;
      insn->bits3.sampler_g4x.msg_type = msg_type;
   } else {
      insn->bits3.sampler.binding_table_index = binding_table_index;
      insn->bits3.sampler.sampler = sampler;
      insn->bits3.sampler.msg_type = msg_type;
      insn->bits3.sampler.return_format = return_format;
d775 39
d816 1
a816 1
struct brw_instruction *
d819 2
a820 1
   struct brw_instruction *insn;
a822 4
      if (0) {
         fprintf(stderr, "incresing the store size to %d\n",
                 p->store_size << 1);
      }
d824 1
a824 4
      p->store = reralloc(p->mem_ctx, p->store,
                          struct brw_instruction, p->store_size);
      if (!p->store)
         assert(!"realloc eu store memeory failed");
d831 1
a831 9
   /* Reset this one-shot flag:
    */

   if (p->current->header.destreg__conditionalmod) {
      p->current->header.destreg__conditionalmod = 0;
      p->current->header.predicate_control = BRW_PREDICATE_NORMAL;
   }

   insn->header.opcode = opcode;
d835 3
a837 4
static struct brw_instruction *brw_alu1( struct brw_compile *p,
					 unsigned opcode,
					 struct brw_reg dest,
					 struct brw_reg src )
d839 1
a839 1
   struct brw_instruction *insn = next_insn(p, opcode);
d845 3
a847 5
static struct brw_instruction *brw_alu2(struct brw_compile *p,
					unsigned opcode,
					struct brw_reg dest,
					struct brw_reg src0,
					struct brw_reg src1 )
d849 1
a849 1
   struct brw_instruction *insn = next_insn(p, opcode);
d867 3
a869 6
static struct brw_instruction *brw_alu3(struct brw_compile *p,
					unsigned opcode,
					struct brw_reg dest,
					struct brw_reg src0,
					struct brw_reg src1,
					struct brw_reg src2)
d872 1
a872 1
   struct brw_instruction *insn = next_insn(p, opcode);
d876 1
a876 1
   assert(insn->header.access_mode == BRW_ALIGN_16);
d885 8
a892 5
   insn->bits1.da3src.dest_reg_file = (dest.file == BRW_MESSAGE_REGISTER_FILE);
   insn->bits1.da3src.dest_reg_nr = dest.nr;
   insn->bits1.da3src.dest_subreg_nr = dest.subnr / 16;
   insn->bits1.da3src.dest_writemask = dest.dw1.bits.writemask;
   guess_execution_size(p, insn, dest);
d897 7
a903 6
   insn->bits2.da3src.src0_swizzle = src0.dw1.bits.swizzle;
   insn->bits2.da3src.src0_subreg_nr = get_3src_subreg_nr(src0);
   insn->bits2.da3src.src0_reg_nr = src0.nr;
   insn->bits1.da3src.src0_abs = src0.abs;
   insn->bits1.da3src.src0_negate = src0.negate;
   insn->bits2.da3src.src0_rep_ctrl = src0.vstride == BRW_VERTICAL_STRIDE_0;
d908 7
a914 7
   insn->bits2.da3src.src1_swizzle = src1.dw1.bits.swizzle;
   insn->bits2.da3src.src1_subreg_nr_low = get_3src_subreg_nr(src1) & 0x3;
   insn->bits3.da3src.src1_subreg_nr_high = get_3src_subreg_nr(src1) >> 2;
   insn->bits2.da3src.src1_rep_ctrl = src1.vstride == BRW_VERTICAL_STRIDE_0;
   insn->bits3.da3src.src1_reg_nr = src1.nr;
   insn->bits1.da3src.src1_abs = src1.abs;
   insn->bits1.da3src.src1_negate = src1.negate;
d919 7
a925 6
   insn->bits3.da3src.src2_swizzle = src2.dw1.bits.swizzle;
   insn->bits3.da3src.src2_subreg_nr = get_3src_subreg_nr(src2);
   insn->bits3.da3src.src2_rep_ctrl = src2.vstride == BRW_VERTICAL_STRIDE_0;
   insn->bits3.da3src.src2_reg_nr = src2.nr;
   insn->bits1.da3src.src2_abs = src2.abs;
   insn->bits1.da3src.src2_negate = src2.negate;
d936 2
a937 2
         insn->bits1.da3src.src_type = BRW_3SRC_TYPE_F;
         insn->bits1.da3src.dst_type = BRW_3SRC_TYPE_F;
d940 2
a941 2
         insn->bits1.da3src.src_type = BRW_3SRC_TYPE_D;
         insn->bits1.da3src.dst_type = BRW_3SRC_TYPE_D;
d944 2
a945 2
         insn->bits1.da3src.src_type = BRW_3SRC_TYPE_UD;
         insn->bits1.da3src.dst_type = BRW_3SRC_TYPE_UD;
d950 1
a950 1
   return insn;
d958 1
a958 1
struct brw_instruction *brw_##OP(struct brw_compile *p,	\
d966 1
a966 1
struct brw_instruction *brw_##OP(struct brw_compile *p,	\
d975 1
a975 1
struct brw_instruction *brw_##OP(struct brw_compile *p,	\
d985 1
a985 1
struct brw_instruction *brw_##OP(struct brw_compile *p,         \
d1010 2
a1011 1
   struct brw_instruction *rnd, *add;					      \
d1016 1
a1016 1
   if (p->brw->gen < 6) {						      \
d1018 1
a1018 1
      rnd->header.destreg__conditionalmod = BRW_CONDITIONAL_R;		      \
d1020 1
a1020 1
      add->header.predicate_control = BRW_PREDICATE_NORMAL;		      \
a1033 2
ALU1(F32TO16)
ALU1(F16TO32)
d1061 3
a1063 4
struct brw_instruction *brw_ADD(struct brw_compile *p,
				struct brw_reg dest,
				struct brw_reg src0,
				struct brw_reg src1)
d1083 3
a1085 4
struct brw_instruction *brw_AVG(struct brw_compile *p,
                                struct brw_reg dest,
                                struct brw_reg src0,
                                struct brw_reg src1)
d1098 1
a1098 1
      assert(!"Bad type for brw_AVG");
d1104 3
a1106 4
struct brw_instruction *brw_MUL(struct brw_compile *p,
				struct brw_reg dest,
				struct brw_reg src0,
				struct brw_reg src1)
d1138 50
d1191 1
a1191 1
   struct brw_instruction *insn = next_insn(p, BRW_OPCODE_NOP);
d1205 12
a1216 12
struct brw_instruction *brw_JMPI(struct brw_compile *p,
                                 struct brw_reg dest,
                                 struct brw_reg src0,
                                 struct brw_reg src1)
{
   struct brw_instruction *insn = brw_alu2(p, BRW_OPCODE_JMPI, dest, src0, src1);

   insn->header.execution_size = 1;
   insn->header.compression_control = BRW_COMPRESSION_NONE;
   insn->header.mask_control = BRW_MASK_DISABLE;

   p->current->header.predicate_control = BRW_PREDICATE_NONE;
d1218 1
a1218 1
   return insn;
d1222 1
a1222 1
push_if_stack(struct brw_compile *p, struct brw_instruction *inst)
d1234 1
a1234 1
static struct brw_instruction *
d1242 1
a1242 1
push_loop_stack(struct brw_compile *p, struct brw_instruction *inst)
d1257 1
a1257 1
static struct brw_instruction *
d1276 1
a1276 1
struct brw_instruction *
d1280 1
a1280 1
   struct brw_instruction *insn;
d1292 1
a1292 1
      insn->bits1.branch_gen6.jump_count = 0;
d1295 1
a1295 1
   } else {
d1299 7
a1305 2
      insn->bits3.break_cont.jip = 0;
      insn->bits3.break_cont.uip = 0;
d1308 6
a1313 8
   insn->header.execution_size = execute_size;
   insn->header.compression_control = BRW_COMPRESSION_NONE;
   insn->header.predicate_control = BRW_PREDICATE_NORMAL;
   insn->header.mask_control = BRW_MASK_ENABLE;
   if (!p->single_program_flow)
      insn->header.thread_control = BRW_THREAD_SWITCH;

   p->current->header.predicate_control = BRW_PREDICATE_NONE;
d1323 2
a1324 2
struct brw_instruction *
gen6_IF(struct brw_compile *p, uint32_t conditional,
d1327 2
a1328 1
   struct brw_instruction *insn;
d1333 3
a1335 6
   if (p->compressed) {
      insn->header.execution_size = BRW_EXECUTE_16;
   } else {
      insn->header.execution_size = BRW_EXECUTE_8;
   }
   insn->bits1.branch_gen6.jump_count = 0;
d1339 3
a1341 6
   assert(insn->header.compression_control == BRW_COMPRESSION_NONE);
   assert(insn->header.predicate_control == BRW_PREDICATE_NONE);
   insn->header.destreg__conditionalmod = conditional;

   if (!p->single_program_flow)
      insn->header.thread_control = BRW_THREAD_SWITCH;
d1352 1
a1352 2
		       struct brw_instruction *if_inst,
		       struct brw_instruction *else_inst)
d1354 2
d1357 1
a1357 1
   struct brw_instruction *next_inst = &p->store[p->nr_insn];
d1360 3
a1362 3
   assert(if_inst != NULL && if_inst->header.opcode == BRW_OPCODE_IF);
   assert(else_inst == NULL || else_inst->header.opcode == BRW_OPCODE_ELSE);
   assert(if_inst->header.execution_size == BRW_EXECUTE_1);
d1372 2
a1373 2
   if_inst->header.opcode = BRW_OPCODE_ADD;
   if_inst->header.predicate_inverse = 1;
d1379 1
a1379 1
      else_inst->header.opcode = BRW_OPCODE_ADD;
d1381 2
a1382 2
      if_inst->bits3.ud = (else_inst - if_inst + 1) * 16;
      else_inst->bits3.ud = (next_inst - else_inst) * 16;
d1384 1
a1384 1
      if_inst->bits3.ud = (next_inst - if_inst) * 16;
d1393 1
a1393 3
	      struct brw_instruction *if_inst,
	      struct brw_instruction *else_inst,
	      struct brw_instruction *endif_inst)
d1412 1
a1412 1
   assert(if_inst != NULL && if_inst->header.opcode == BRW_OPCODE_IF);
d1414 1
a1414 1
   assert(else_inst == NULL || else_inst->header.opcode == BRW_OPCODE_ELSE);
d1416 1
a1416 6
   unsigned br = 1;
   /* Jump count is for 64bit data chunk each, so one 128bit instruction
    * requires 2 chunks.
    */
   if (brw->gen >= 5)
      br = 2;
d1418 2
a1419 2
   assert(endif_inst->header.opcode == BRW_OPCODE_ENDIF);
   endif_inst->header.execution_size = if_inst->header.execution_size;
d1427 4
a1430 4
	 if_inst->header.opcode = BRW_OPCODE_IFF;
	 if_inst->bits3.if_else.jump_count = br * (endif_inst - if_inst + 1);
	 if_inst->bits3.if_else.pop_count = 0;
	 if_inst->bits3.if_else.pad0 = 0;
d1433 1
a1433 1
	 if_inst->bits1.branch_gen6.jump_count = br * (endif_inst - if_inst);
d1435 2
a1436 2
	 if_inst->bits3.break_cont.uip = br * (endif_inst - if_inst);
	 if_inst->bits3.break_cont.jip = br * (endif_inst - if_inst);
d1439 1
a1439 1
      else_inst->header.execution_size = if_inst->header.execution_size;
d1443 3
a1445 3
	 if_inst->bits3.if_else.jump_count = br * (else_inst - if_inst);
	 if_inst->bits3.if_else.pop_count = 0;
	 if_inst->bits3.if_else.pad0 = 0;
d1447 2
a1448 1
	 if_inst->bits1.branch_gen6.jump_count = br * (else_inst - if_inst + 1);
d1456 3
a1458 3
	 else_inst->bits3.if_else.jump_count = br*(endif_inst - else_inst + 1);
	 else_inst->bits3.if_else.pop_count = 1;
	 else_inst->bits3.if_else.pad0 = 0;
d1461 2
a1462 1
	 else_inst->bits1.branch_gen6.jump_count = br*(endif_inst - else_inst);
d1465 1
a1465 1
	 if_inst->bits3.break_cont.jip = br * (else_inst - if_inst + 1);
d1467 8
a1474 2
	 if_inst->bits3.break_cont.uip = br * (endif_inst - if_inst);
	 else_inst->bits3.break_cont.jip = br * (endif_inst - else_inst);
d1483 1
a1483 1
   struct brw_instruction *insn;
d1493 1
a1493 1
      insn->bits1.branch_gen6.jump_count = 0;
d1496 1
a1496 1
   } else {
d1500 7
a1506 2
      insn->bits3.break_cont.jip = 0;
      insn->bits3.break_cont.uip = 0;
d1509 4
a1512 4
   insn->header.compression_control = BRW_COMPRESSION_NONE;
   insn->header.mask_control = BRW_MASK_ENABLE;
   if (!p->single_program_flow)
      insn->header.thread_control = BRW_THREAD_SWITCH;
d1521 4
a1524 4
   struct brw_instruction *insn = NULL;
   struct brw_instruction *else_inst = NULL;
   struct brw_instruction *if_inst = NULL;
   struct brw_instruction *tmp;
d1553 1
a1553 1
   if (tmp->header.opcode == BRW_OPCODE_ELSE) {
d1573 1
a1573 1
   } else {
d1577 2
d1581 4
a1584 3
   insn->header.compression_control = BRW_COMPRESSION_NONE;
   insn->header.mask_control = BRW_MASK_ENABLE;
   insn->header.thread_control = BRW_THREAD_SWITCH;
d1588 2
a1589 3
      insn->bits3.if_else.jump_count = 0;
      insn->bits3.if_else.pop_count = 1;
      insn->bits3.if_else.pad0 = 0;
d1591 1
a1591 1
      insn->bits1.branch_gen6.jump_count = 2;
d1593 1
a1593 1
      insn->bits3.break_cont.jip = 2;
d1598 2
a1599 1
struct brw_instruction *brw_BREAK(struct brw_compile *p)
d1602 1
a1602 1
   struct brw_instruction *insn;
d1605 4
a1608 1
   if (brw->gen >= 6) {
d1616 2
a1617 2
      insn->bits3.if_else.pad0 = 0;
      insn->bits3.if_else.pop_count = p->if_depth_in_loop[p->loop_stack_depth];
d1619 3
a1621 2
   insn->header.compression_control = BRW_COMPRESSION_NONE;
   insn->header.execution_size = BRW_EXECUTE_8;
d1626 2
a1627 1
struct brw_instruction *gen6_CONT(struct brw_compile *p)
d1629 2
a1630 1
   struct brw_instruction *insn;
a1632 2
   brw_set_dest(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
   brw_set_src0(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
d1634 6
a1639 2
   brw_set_src0(p, insn, brw_ip_reg());
   brw_set_src1(p, insn, brw_imm_d(0x0));
d1641 7
a1647 2
   insn->header.compression_control = BRW_COMPRESSION_NONE;
   insn->header.execution_size = BRW_EXECUTE_8;
d1651 2
a1652 1
struct brw_instruction *brw_CONT(struct brw_compile *p)
d1654 2
a1655 16
   struct brw_instruction *insn;
   insn = next_insn(p, BRW_OPCODE_CONTINUE);
   brw_set_dest(p, insn, brw_ip_reg());
   brw_set_src0(p, insn, brw_ip_reg());
   brw_set_src1(p, insn, brw_imm_d(0x0));
   insn->header.compression_control = BRW_COMPRESSION_NONE;
   insn->header.execution_size = BRW_EXECUTE_8;
   /* insn->header.mask_control = BRW_MASK_DISABLE; */
   insn->bits3.if_else.pad0 = 0;
   insn->bits3.if_else.pop_count = p->if_depth_in_loop[p->loop_stack_depth];
   return insn;
}

struct brw_instruction *gen6_HALT(struct brw_compile *p)
{
   struct brw_instruction *insn;
d1659 6
a1664 2
   brw_set_src0(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
   brw_set_src1(p, insn, brw_imm_d(0x0)); /* UIP and JIP, updated later. */
d1667 1
a1667 1
      insn->header.execution_size = BRW_EXECUTE_16;
d1669 2
a1670 2
      insn->header.compression_control = BRW_COMPRESSION_NONE;
      insn->header.execution_size = BRW_EXECUTE_8;
d1691 2
a1692 1
struct brw_instruction *brw_DO(struct brw_compile *p, unsigned execute_size)
d1700 1
a1700 1
      struct brw_instruction *insn = next_insn(p, BRW_OPCODE_DO);
d1710 3
a1712 5
      insn->header.compression_control = BRW_COMPRESSION_NONE;
      insn->header.execution_size = execute_size;
      insn->header.predicate_control = BRW_PREDICATE_NONE;
      /* insn->header.mask_control = BRW_MASK_ENABLE; */
      /* insn->header.mask_control = BRW_MASK_DISABLE; */
d1726 1
a1726 1
brw_patch_break_cont(struct brw_compile *p, struct brw_instruction *while_inst)
d1729 5
a1733 3
   struct brw_instruction *do_inst = get_inner_do_insn(p);
   struct brw_instruction *inst;
   int br = (brw->gen == 5) ? 2 : 1;
d1740 6
a1745 6
      if (inst->header.opcode == BRW_OPCODE_BREAK &&
	  inst->bits3.if_else.jump_count == 0) {
	 inst->bits3.if_else.jump_count = br * ((while_inst - inst) + 1);
      } else if (inst->header.opcode == BRW_OPCODE_CONTINUE &&
		 inst->bits3.if_else.jump_count == 0) {
	 inst->bits3.if_else.jump_count = br * (while_inst - inst);
d1750 2
a1751 1
struct brw_instruction *brw_WHILE(struct brw_compile *p)
d1754 2
a1755 2
   struct brw_instruction *insn, *do_insn;
   unsigned br = 1;
d1757 1
a1757 4
   if (brw->gen >= 5)
      br = 2;

   if (brw->gen >= 7) {
d1761 15
a1775 9
      brw_set_dest(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
      brw_set_src0(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
      brw_set_src1(p, insn, brw_imm_ud(0));
      insn->bits3.break_cont.jip = br * (do_insn - insn);

      insn->header.execution_size = BRW_EXECUTE_8;
   } else if (brw->gen == 6) {
      insn = next_insn(p, BRW_OPCODE_WHILE);
      do_insn = get_inner_do_insn(p);
d1777 2
a1778 6
      brw_set_dest(p, insn, brw_imm_w(0));
      insn->bits1.branch_gen6.jump_count = br * (do_insn - insn);
      brw_set_src0(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));
      brw_set_src1(p, insn, retype(brw_null_reg(), BRW_REGISTER_TYPE_D));

      insn->header.execution_size = BRW_EXECUTE_8;
d1787 1
a1787 1
	 insn->header.execution_size = BRW_EXECUTE_1;
d1792 1
a1792 1
	 assert(do_insn->header.opcode == BRW_OPCODE_DO);
d1798 3
a1800 4
	 insn->header.execution_size = do_insn->header.execution_size;
	 insn->bits3.if_else.jump_count = br * (do_insn - insn + 1);
	 insn->bits3.if_else.pop_count = 0;
	 insn->bits3.if_else.pad0 = 0;
d1805 1
a1805 2
   insn->header.compression_control = BRW_COMPRESSION_NONE;
   p->current->header.predicate_control = BRW_PREDICATE_NONE;
a1811 1

d1817 1
a1817 1
   struct brw_instruction *jmp_insn = &p->store[jmp_insn_idx];
d1823 2
a1824 2
   assert(jmp_insn->header.opcode == BRW_OPCODE_JMPI);
   assert(jmp_insn->bits1.da1.src1_reg_file == BRW_IMMEDIATE_VALUE);
d1826 2
a1827 1
   jmp_insn->bits3.ud = jmpi * (p->nr_insn - jmp_insn_idx - 1);
a1829 2


d1841 9
a1849 1
   struct brw_instruction *insn = next_insn(p, BRW_OPCODE_CMP);
d1851 1
a1851 1
   insn->header.destreg__conditionalmod = conditional;
a1855 13
/*    guess_execution_size(insn, src0); */


   /* Make it so that future instructions will use the computed flag
    * value until brw_set_predicate_control_flag_value() is called
    * again.
    */
   if (dest.file == BRW_ARCHITECTURE_REGISTER_FILE &&
       dest.nr == 0) {
      p->current->header.predicate_control = BRW_PREDICATE_NORMAL;
      p->flag_value = 0xff;
   }

d1866 1
a1866 1
         insn->header.thread_control = BRW_THREAD_SWITCH;
a1870 16
/* Issue 'wait' instruction for n1, host could program MMIO
   to wake up thread. */
void brw_WAIT (struct brw_compile *p)
{
   struct brw_instruction *insn = next_insn(p, BRW_OPCODE_WAIT);
   struct brw_reg src = brw_notification_1_reg();

   brw_set_dest(p, insn, src);
   brw_set_src0(p, insn, src);
   brw_set_src1(p, insn, brw_null_reg());
   insn->header.execution_size = 0; /* must */
   insn->header.predicate_control = 0;
   insn->header.compression_control = 0;
}


d1877 1
a1877 1
void brw_math( struct brw_compile *p,
a1881 1
	       unsigned data_type,
d1885 9
d1895 1
a1895 2
   if (brw->gen >= 6) {
      struct brw_instruction *insn = next_insn(p, BRW_OPCODE_MATH);
d1897 5
a1901 21
      assert(dest.file == BRW_GENERAL_REGISTER_FILE ||
             (brw->gen >= 7 && dest.file == BRW_MESSAGE_REGISTER_FILE));
      assert(src.file == BRW_GENERAL_REGISTER_FILE);

      assert(dest.hstride == BRW_HORIZONTAL_STRIDE_1);
      if (brw->gen == 6)
	 assert(src.hstride == BRW_HORIZONTAL_STRIDE_1);

      /* Source modifiers are ignored for extended math instructions on Gen6. */
      if (brw->gen == 6) {
	 assert(!src.negate);
	 assert(!src.abs);
      }

      if (function == BRW_MATH_FUNCTION_INT_DIV_QUOTIENT ||
	  function == BRW_MATH_FUNCTION_INT_DIV_REMAINDER ||
	  function == BRW_MATH_FUNCTION_INT_DIV_QUOTIENT_AND_REMAINDER) {
	 assert(src.type != BRW_REGISTER_TYPE_F);
      } else {
	 assert(src.type == BRW_REGISTER_TYPE_F);
      }
d1903 8
a1910 26
      /* Math is the same ISA format as other opcodes, except that CondModifier
       * becomes FC[3:0] and ThreadCtrl becomes FC[5:4].
       */
      insn->header.destreg__conditionalmod = function;

      brw_set_dest(p, insn, dest);
      brw_set_src0(p, insn, src);
      brw_set_src1(p, insn, brw_null_reg());
   } else {
      struct brw_instruction *insn = next_insn(p, BRW_OPCODE_SEND);

      /* Example code doesn't set predicate_control for send
       * instructions.
       */
      insn->header.predicate_control = 0;
      insn->header.destreg__conditionalmod = msg_reg_nr;

      brw_set_dest(p, insn, dest);
      brw_set_src0(p, insn, src);
      brw_set_math_message(p,
			   insn,
			   function,
			   src.type == BRW_REGISTER_TYPE_D,
			   precision,
			   data_type);
   }
d1913 1
a1913 3
/** Extended math function, float[8].
 */
void brw_math2(struct brw_compile *p,
d1920 3
a1922 1
   struct brw_instruction *insn = next_insn(p, BRW_OPCODE_MATH);
d1926 2
a1927 2
   assert(src0.file == BRW_GENERAL_REGISTER_FILE);
   assert(src1.file == BRW_GENERAL_REGISTER_FILE);
d1940 2
d1945 7
d1962 1
a1962 4
   /* Math is the same ISA format as other opcodes, except that CondModifier
    * becomes FC[3:0] and ThreadCtrl becomes FC[5:4].
    */
   insn->header.destreg__conditionalmod = function;
d2006 2
a2007 2
      brw_set_mask_control(p, BRW_MASK_DISABLE);
      brw_set_compression_control(p, BRW_COMPRESSION_NONE);
d2023 1
a2023 1
      struct brw_instruction *insn = next_insn(p, BRW_OPCODE_SEND);
d2028 2
a2029 2
      if (insn->header.compression_control != BRW_COMPRESSION_NONE) {
	 insn->header.compression_control = BRW_COMPRESSION_NONE;
d2032 3
a2034 2
      assert(insn->header.predicate_control == BRW_PREDICATE_NONE);
      insn->header.destreg__conditionalmod = mrf.nr;
d2102 12
a2113 1
   mrf = retype(mrf, BRW_REGISTER_TYPE_UD);
d2126 2
a2127 2
      brw_set_compression_control(p, BRW_COMPRESSION_NONE);
      brw_set_mask_control(p, BRW_MASK_DISABLE);
d2132 1
a2132 5
      brw_MOV(p,
	      retype(brw_vec1_reg(BRW_MESSAGE_REGISTER_FILE,
				  mrf.nr,
				  2), BRW_REGISTER_TYPE_UD),
	      brw_imm_ud(offset));
d2138 1
a2138 1
      struct brw_instruction *insn = next_insn(p, BRW_OPCODE_SEND);
d2140 2
a2141 3
      assert(insn->header.predicate_control == 0);
      insn->header.compression_control = BRW_COMPRESSION_NONE;
      insn->header.destreg__conditionalmod = mrf.nr;
d2148 1
d2169 3
a2171 3
   dest = retype(dest, BRW_REGISTER_TYPE_UW);

   struct brw_instruction *insn = next_insn(p, BRW_OPCODE_SEND);
d2173 2
a2174 4
   assert(insn->header.predicate_control == BRW_PREDICATE_NONE);
   insn->header.compression_control = BRW_COMPRESSION_NONE;

   brw_set_dest(p, insn, dest);
a2178 1
   bool header_present = true;
a2180 12
   brw_set_message_descriptor(p, insn,
                              GEN7_SFID_DATAPORT_DATA_CACHE,
                              1, /* mlen: just g0 */
                              num_regs,
                              header_present,
                              false);

   insn->bits3.ud |= GEN7_DATAPORT_SCRATCH_READ;

   assert(num_regs == 1 || num_regs == 2 || num_regs == 4);
   insn->bits3.ud |= (num_regs - 1) << GEN7_DATAPORT_SCRATCH_NUM_REGS_SHIFT;

d2187 10
a2196 1
   insn->bits3.ud |= offset;
d2219 3
a2221 3
   brw_set_predicate_control(p, BRW_PREDICATE_NONE);
   brw_set_compression_control(p, BRW_COMPRESSION_NONE);
   brw_set_mask_control(p, BRW_MASK_DISABLE);
d2232 1
a2232 2
   struct brw_instruction *insn = next_insn(p, BRW_OPCODE_SEND);
   insn->header.destreg__conditionalmod = mrf.nr;
d2242 1
d2261 2
a2262 2
                  unsigned msg_reg_nr,
                  struct brw_reg src0,
d2271 1
a2271 1
   struct brw_instruction *insn;
d2273 1
a2273 1
   struct brw_reg dest;
d2285 1
a2285 1
   insn->header.compression_control = BRW_COMPRESSION_NONE;
d2289 1
a2289 1
      src0 = brw_message_reg(msg_reg_nr);
d2293 3
a2295 1
      insn->header.destreg__conditionalmod = msg_reg_nr;
d2335 1
a2335 1
   struct brw_instruction *insn;
d2341 1
a2341 1
   insn->header.predicate_control = 0; /* XXX */
d2355 2
a2356 2
   if (insn->header.compression_control != BRW_COMPRESSION_2NDHALF)
      insn->header.compression_control = BRW_COMPRESSION_NONE;
d2359 1
a2359 1
      insn->header.destreg__conditionalmod = msg_reg_nr;
d2374 47
d2436 1
a2436 1
   struct brw_instruction *insn;
d2440 1
a2440 1
   if (brw->gen == 7 && !(flags & BRW_URB_WRITE_USE_CHANNEL_MASKS)) {
d2443 2
a2444 2
      brw_set_access_mode(p, BRW_ALIGN_1);
      brw_set_mask_control(p, BRW_MASK_DISABLE);
d2461 1
a2461 1
      insn->header.destreg__conditionalmod = msg_reg_nr;
d2473 1
a2473 1
next_ip(struct brw_compile *p, int ip)
d2475 1
a2475 12
   struct brw_instruction *insn = (void *)p->store + ip;

   if (insn->header.cmpt_control)
      return ip + 8;
   else
      return ip + 16;
}

static int
brw_find_next_block_end(struct brw_compile *p, int start)
{
   int ip;
d2477 1
d2479 4
a2482 2
   for (ip = next_ip(p, start); ip < p->next_insn_offset; ip = next_ip(p, ip)) {
      struct brw_instruction *insn = store + ip;
d2484 1
a2484 1
      switch (insn->header.opcode) {
d2489 1
a2489 1
	 return ip;
d2501 1
a2501 1
brw_find_loop_end(struct brw_compile *p, int start)
d2504 2
a2505 2
   int ip;
   int scale = 8;
d2508 2
d2513 10
a2522 8
   for (ip = next_ip(p, start); ip < p->next_insn_offset; ip = next_ip(p, ip)) {
      struct brw_instruction *insn = store + ip;

      if (insn->header.opcode == BRW_OPCODE_WHILE) {
	 int jip = brw->gen == 6 ? insn->bits1.branch_gen6.jump_count
				   : insn->bits3.break_cont.jip;
	 if (ip + jip * scale <= start)
	    return ip;
d2526 1
a2526 1
   return start;
d2536 3
a2538 2
   int ip;
   int scale = 8;
d2544 3
a2546 2
   for (ip = 0; ip < p->next_insn_offset; ip = next_ip(p, ip)) {
      struct brw_instruction *insn = store + ip;
d2548 1
a2548 1
      if (insn->header.cmpt_control) {
d2550 3
a2552 3
	 assert(insn->header.opcode != BRW_OPCODE_BREAK &&
		insn->header.opcode != BRW_OPCODE_CONTINUE &&
		insn->header.opcode != BRW_OPCODE_HALT);
d2556 2
a2557 2
      int block_end_ip = brw_find_next_block_end(p, ip);
      switch (insn->header.opcode) {
d2559 2
a2560 2
         assert(block_end_ip != 0);
	 insn->bits3.break_cont.jip = (block_end_ip - ip) / scale;
d2562 3
a2564 3
	 insn->bits3.break_cont.uip =
	    (brw_find_loop_end(p, ip) - ip +
             (brw->gen == 6 ? 16 : 0)) / scale;
d2567 4
a2570 4
         assert(block_end_ip != 0);
	 insn->bits3.break_cont.jip = (block_end_ip - ip) / scale;
	 insn->bits3.break_cont.uip =
            (brw_find_loop_end(p, ip) - ip) / scale;
d2572 2
a2573 2
	 assert(insn->bits3.break_cont.uip != 0);
	 assert(insn->bits3.break_cont.jip != 0);
d2576 5
a2580 3
      case BRW_OPCODE_ENDIF:
         if (block_end_ip == 0)
            insn->bits3.break_cont.jip = 2;
d2582 1
a2582 1
            insn->bits3.break_cont.jip = (block_end_ip - ip) / scale;
d2584 1
d2598 2
a2599 2
	 if (block_end_ip == 0) {
	    insn->bits3.break_cont.jip = insn->bits3.break_cont.uip;
d2601 1
a2601 1
	    insn->bits3.break_cont.jip = (block_end_ip - ip) / scale;
d2603 2
a2604 2
	 assert(insn->bits3.break_cont.uip != 0);
	 assert(insn->bits3.break_cont.jip != 0);
d2619 1
a2619 1
   struct brw_instruction *insn;
d2629 1
a2629 1
      insn->header.destreg__conditionalmod = msg_reg_nr;
d2657 1
a2657 1
   struct brw_instruction *insn;
d2679 1
a2679 1
                                  struct brw_instruction *insn,
d2686 7
a2692 1
   if (p->brw->is_haswell) {
d2698 3
a2700 3
      if (insn->header.access_mode == BRW_ALIGN_1) {
         if (insn->header.execution_size != BRW_EXECUTE_16)
            insn->bits3.ud |= 1 << 12; /* SIMD8 mode */
d2702 2
a2703 2
         insn->bits3.gen7_dp.msg_type =
            HSW_DATAPORT_DC_PORT1_UNTYPED_ATOMIC_OP;
d2705 2
a2706 2
         insn->bits3.gen7_dp.msg_type =
            HSW_DATAPORT_DC_PORT1_UNTYPED_ATOMIC_OP_SIMD4X2;
a2707 1

d2713 1
a2713 1
      insn->bits3.gen7_dp.msg_type = GEN7_DATAPORT_DC_UNTYPED_ATOMIC_OP;
d2715 2
a2716 2
      if (insn->header.execution_size != BRW_EXECUTE_16)
         insn->bits3.ud |= 1 << 12; /* SIMD8 mode */
d2719 2
a2720 5
   if (response_length)
      insn->bits3.ud |= 1 << 13; /* Return data expected */

   insn->bits3.gen7_dp.binding_table_index = bind_table_index;
   insn->bits3.ud |= atomic_op << 8;
d2726 1
a2726 1
                   struct brw_reg mrf,
d2731 2
a2732 1
   struct brw_instruction *insn = brw_next_insn(p, BRW_OPCODE_SEND);
d2735 1
a2735 1
   brw_set_src0(p, insn, retype(mrf, BRW_REGISTER_TYPE_UD));
d2739 1
a2739 1
      insn->header.access_mode == BRW_ALIGN_1);
d2744 1
a2744 1
                                        struct brw_instruction *insn,
d2750 1
d2752 1
a2752 1
      (insn->header.execution_size == BRW_EXECUTE_16 ? 16 : 8);
d2755 1
a2755 1
   if (p->brw->is_haswell) {
d2760 2
a2761 1
      insn->bits3.gen7_dp.msg_type = HSW_DATAPORT_DC_PORT1_UNTYPED_SURFACE_READ;
d2767 2
a2768 1
      insn->bits3.gen7_dp.msg_type = GEN7_DATAPORT_DC_UNTYPED_SURFACE_READ;
d2771 4
a2774 1
   if (insn->header.access_mode == BRW_ALIGN_1) {
d2776 1
a2776 1
         insn->bits3.ud |= 1 << 12; /* SIMD16 mode */
d2778 1
a2778 1
         insn->bits3.ud |= 2 << 12; /* SIMD8 mode */
d2781 2
a2782 4
   insn->bits3.gen7_dp.binding_table_index = bind_table_index;

   /* Set mask of 32-bit channels to drop. */
   insn->bits3.ud |= (0xf & (0xf << num_channels)) << 8;
d2793 2
a2794 1
   struct brw_instruction *insn = next_insn(p, BRW_OPCODE_SEND);
d2800 29
a2828 1
      insn->header.access_mode == BRW_ALIGN_1);
d2851 1
a2851 2
   struct brw_context *brw = p->brw;
   assert(brw->gen >= 7);
d2854 3
a2856 3
   brw_set_access_mode(p, BRW_ALIGN_1);
   brw_set_mask_control(p, BRW_MASK_DISABLE);
   struct brw_instruction *send = brw_next_insn(p, BRW_OPCODE_SEND);
@


