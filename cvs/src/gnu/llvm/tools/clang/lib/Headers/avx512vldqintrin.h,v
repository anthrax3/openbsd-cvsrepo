head	1.1;
branch	1.1.1;
access;
symbols
	OPENBSD_6_2:1.1.1.3.0.6
	OPENBSD_6_2_BASE:1.1.1.3
	OPENBSD_6_1:1.1.1.3.0.4
	OPENBSD_6_1_BASE:1.1.1.3
	LLVM_4_0_0:1.1.1.3
	LLVM_4_0_0_RC1:1.1.1.3
	LLVM_3_9_1:1.1.1.2
	LLVM_3_8_1:1.1.1.1
	LLVM:1.1.1;
locks; strict;
comment	@ * @;


1.1
date	2016.09.03.22.46.57;	author pascal;	state Exp;
branches
	1.1.1.1;
next	;
commitid	piLU3CHugy63NlaI;

1.1.1.1
date	2016.09.03.22.46.57;	author pascal;	state Exp;
branches;
next	1.1.1.2;
commitid	piLU3CHugy63NlaI;

1.1.1.2
date	2017.01.14.19.55.50;	author patrick;	state Exp;
branches;
next	1.1.1.3;
commitid	qMUxATnKgqN83Oct;

1.1.1.3
date	2017.01.24.08.33.07;	author patrick;	state Exp;
branches;
next	;
commitid	so2WA7LCP6wbxtYl;


desc
@@


1.1
log
@Initial revision
@
text
@/*===---- avx512vldqintrin.h - AVX512VL and AVX512DQ intrinsics ------------===
 *
 * Permission is hereby granted, free of charge, to any person obtaining a copy
 * of this software and associated documentation files (the "Software"), to deal
 * in the Software without restriction, including without limitation the rights
 * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 * copies of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included in
 * all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
 * THE SOFTWARE.
 *
 *===-----------------------------------------------------------------------===
 */

#ifndef __IMMINTRIN_H
#error "Never use <avx512vldqintrin.h> directly; include <immintrin.h> instead."
#endif

#ifndef __AVX512VLDQINTRIN_H
#define __AVX512VLDQINTRIN_H

/* Define the default attributes for the functions in this file. */
#define __DEFAULT_FN_ATTRS __attribute__((__always_inline__, __nodebug__, __target__("avx512vl,avx512dq")))

static __inline__ __m256i __DEFAULT_FN_ATTRS
_mm256_mullo_epi64 (__m256i __A, __m256i __B) {
  return (__m256i) ((__v4di) __A * (__v4di) __B);
}

static __inline__ __m256i __DEFAULT_FN_ATTRS
_mm256_mask_mullo_epi64 (__m256i __W, __mmask8 __U, __m256i __A, __m256i __B) {
  return (__m256i) __builtin_ia32_pmullq256_mask ((__v4di) __A,
              (__v4di) __B,
              (__v4di) __W,
              (__mmask8) __U);
}

static __inline__ __m256i __DEFAULT_FN_ATTRS
_mm256_maskz_mullo_epi64 (__mmask8 __U, __m256i __A, __m256i __B) {
  return (__m256i) __builtin_ia32_pmullq256_mask ((__v4di) __A,
              (__v4di) __B,
              (__v4di)
              _mm256_setzero_si256 (),
              (__mmask8) __U);
}

static __inline__ __m128i __DEFAULT_FN_ATTRS
_mm_mullo_epi64 (__m128i __A, __m128i __B) {
  return (__m128i) ((__v2di) __A * (__v2di) __B);
}

static __inline__ __m128i __DEFAULT_FN_ATTRS
_mm_mask_mullo_epi64 (__m128i __W, __mmask8 __U, __m128i __A, __m128i __B) {
  return (__m128i) __builtin_ia32_pmullq128_mask ((__v2di) __A,
              (__v2di) __B,
              (__v2di) __W,
              (__mmask8) __U);
}

static __inline__ __m128i __DEFAULT_FN_ATTRS
_mm_maskz_mullo_epi64 (__mmask8 __U, __m128i __A, __m128i __B) {
  return (__m128i) __builtin_ia32_pmullq128_mask ((__v2di) __A,
              (__v2di) __B,
              (__v2di)
              _mm_setzero_si128 (),
              (__mmask8) __U);
}

static __inline__ __m256d __DEFAULT_FN_ATTRS
_mm256_mask_andnot_pd (__m256d __W, __mmask8 __U, __m256d __A, __m256d __B) {
  return (__m256d) __builtin_ia32_andnpd256_mask ((__v4df) __A,
              (__v4df) __B,
              (__v4df) __W,
              (__mmask8) __U);
}

static __inline__ __m256d __DEFAULT_FN_ATTRS
_mm256_maskz_andnot_pd (__mmask8 __U, __m256d __A, __m256d __B) {
  return (__m256d) __builtin_ia32_andnpd256_mask ((__v4df) __A,
              (__v4df) __B,
              (__v4df)
              _mm256_setzero_pd (),
              (__mmask8) __U);
}

static __inline__ __m128d __DEFAULT_FN_ATTRS
_mm_mask_andnot_pd (__m128d __W, __mmask8 __U, __m128d __A, __m128d __B) {
  return (__m128d) __builtin_ia32_andnpd128_mask ((__v2df) __A,
              (__v2df) __B,
              (__v2df) __W,
              (__mmask8) __U);
}

static __inline__ __m128d __DEFAULT_FN_ATTRS
_mm_maskz_andnot_pd (__mmask8 __U, __m128d __A, __m128d __B) {
  return (__m128d) __builtin_ia32_andnpd128_mask ((__v2df) __A,
              (__v2df) __B,
              (__v2df)
              _mm_setzero_pd (),
              (__mmask8) __U);
}

static __inline__ __m256 __DEFAULT_FN_ATTRS
_mm256_mask_andnot_ps (__m256 __W, __mmask8 __U, __m256 __A, __m256 __B) {
  return (__m256) __builtin_ia32_andnps256_mask ((__v8sf) __A,
             (__v8sf) __B,
             (__v8sf) __W,
             (__mmask8) __U);
}

static __inline__ __m256 __DEFAULT_FN_ATTRS
_mm256_maskz_andnot_ps (__mmask8 __U, __m256 __A, __m256 __B) {
  return (__m256) __builtin_ia32_andnps256_mask ((__v8sf) __A,
             (__v8sf) __B,
             (__v8sf)
             _mm256_setzero_ps (),
             (__mmask8) __U);
}

static __inline__ __m128 __DEFAULT_FN_ATTRS
_mm_mask_andnot_ps (__m128 __W, __mmask8 __U, __m128 __A, __m128 __B) {
  return (__m128) __builtin_ia32_andnps128_mask ((__v4sf) __A,
             (__v4sf) __B,
             (__v4sf) __W,
             (__mmask8) __U);
}

static __inline__ __m128 __DEFAULT_FN_ATTRS
_mm_maskz_andnot_ps (__mmask8 __U, __m128 __A, __m128 __B) {
  return (__m128) __builtin_ia32_andnps128_mask ((__v4sf) __A,
             (__v4sf) __B,
             (__v4sf)
             _mm_setzero_ps (),
             (__mmask8) __U);
}

static __inline__ __m256d __DEFAULT_FN_ATTRS
_mm256_mask_and_pd (__m256d __W, __mmask8 __U, __m256d __A, __m256d __B) {
  return (__m256d) __builtin_ia32_andpd256_mask ((__v4df) __A,
             (__v4df) __B,
             (__v4df) __W,
             (__mmask8) __U);
}

static __inline__ __m256d __DEFAULT_FN_ATTRS
_mm256_maskz_and_pd (__mmask8 __U, __m256d __A, __m256d __B) {
  return (__m256d) __builtin_ia32_andpd256_mask ((__v4df) __A,
             (__v4df) __B,
             (__v4df)
             _mm256_setzero_pd (),
             (__mmask8) __U);
}

static __inline__ __m128d __DEFAULT_FN_ATTRS
_mm_mask_and_pd (__m128d __W, __mmask8 __U, __m128d __A, __m128d __B) {
  return (__m128d) __builtin_ia32_andpd128_mask ((__v2df) __A,
             (__v2df) __B,
             (__v2df) __W,
             (__mmask8) __U);
}

static __inline__ __m128d __DEFAULT_FN_ATTRS
_mm_maskz_and_pd (__mmask8 __U, __m128d __A, __m128d __B) {
  return (__m128d) __builtin_ia32_andpd128_mask ((__v2df) __A,
             (__v2df) __B,
             (__v2df)
             _mm_setzero_pd (),
             (__mmask8) __U);
}

static __inline__ __m256 __DEFAULT_FN_ATTRS
_mm256_mask_and_ps (__m256 __W, __mmask8 __U, __m256 __A, __m256 __B) {
  return (__m256) __builtin_ia32_andps256_mask ((__v8sf) __A,
            (__v8sf) __B,
            (__v8sf) __W,
            (__mmask8) __U);
}

static __inline__ __m256 __DEFAULT_FN_ATTRS
_mm256_maskz_and_ps (__mmask8 __U, __m256 __A, __m256 __B) {
  return (__m256) __builtin_ia32_andps256_mask ((__v8sf) __A,
            (__v8sf) __B,
            (__v8sf)
            _mm256_setzero_ps (),
            (__mmask8) __U);
}

static __inline__ __m128 __DEFAULT_FN_ATTRS
_mm_mask_and_ps (__m128 __W, __mmask8 __U, __m128 __A, __m128 __B) {
  return (__m128) __builtin_ia32_andps128_mask ((__v4sf) __A,
            (__v4sf) __B,
            (__v4sf) __W,
            (__mmask8) __U);
}

static __inline__ __m128 __DEFAULT_FN_ATTRS
_mm_maskz_and_ps (__mmask8 __U, __m128 __A, __m128 __B) {
  return (__m128) __builtin_ia32_andps128_mask ((__v4sf) __A,
            (__v4sf) __B,
            (__v4sf)
            _mm_setzero_ps (),
            (__mmask8) __U);
}

static __inline__ __m256d __DEFAULT_FN_ATTRS
_mm256_mask_xor_pd (__m256d __W, __mmask8 __U, __m256d __A,
        __m256d __B) {
  return (__m256d) __builtin_ia32_xorpd256_mask ((__v4df) __A,
             (__v4df) __B,
             (__v4df) __W,
             (__mmask8) __U);
}

static __inline__ __m256d __DEFAULT_FN_ATTRS
_mm256_maskz_xor_pd (__mmask8 __U, __m256d __A, __m256d __B) {
  return (__m256d) __builtin_ia32_xorpd256_mask ((__v4df) __A,
             (__v4df) __B,
             (__v4df)
             _mm256_setzero_pd (),
             (__mmask8) __U);
}

static __inline__ __m128d __DEFAULT_FN_ATTRS
_mm_mask_xor_pd (__m128d __W, __mmask8 __U, __m128d __A, __m128d __B) {
  return (__m128d) __builtin_ia32_xorpd128_mask ((__v2df) __A,
             (__v2df) __B,
             (__v2df) __W,
             (__mmask8) __U);
}

static __inline__ __m128d __DEFAULT_FN_ATTRS
_mm_maskz_xor_pd (__mmask8 __U, __m128d __A, __m128d __B) {
  return (__m128d) __builtin_ia32_xorpd128_mask ((__v2df) __A,
             (__v2df) __B,
             (__v2df)
             _mm_setzero_pd (),
             (__mmask8) __U);
}

static __inline__ __m256 __DEFAULT_FN_ATTRS
_mm256_mask_xor_ps (__m256 __W, __mmask8 __U, __m256 __A, __m256 __B) {
  return (__m256) __builtin_ia32_xorps256_mask ((__v8sf) __A,
            (__v8sf) __B,
            (__v8sf) __W,
            (__mmask8) __U);
}

static __inline__ __m256 __DEFAULT_FN_ATTRS
_mm256_maskz_xor_ps (__mmask8 __U, __m256 __A, __m256 __B) {
  return (__m256) __builtin_ia32_xorps256_mask ((__v8sf) __A,
            (__v8sf) __B,
            (__v8sf)
            _mm256_setzero_ps (),
            (__mmask8) __U);
}

static __inline__ __m128 __DEFAULT_FN_ATTRS
_mm_mask_xor_ps (__m128 __W, __mmask8 __U, __m128 __A, __m128 __B) {
  return (__m128) __builtin_ia32_xorps128_mask ((__v4sf) __A,
            (__v4sf) __B,
            (__v4sf) __W,
            (__mmask8) __U);
}

static __inline__ __m128 __DEFAULT_FN_ATTRS
_mm_maskz_xor_ps (__mmask8 __U, __m128 __A, __m128 __B) {
  return (__m128) __builtin_ia32_xorps128_mask ((__v4sf) __A,
            (__v4sf) __B,
            (__v4sf)
            _mm_setzero_ps (),
            (__mmask8) __U);
}

static __inline__ __m256d __DEFAULT_FN_ATTRS
_mm256_mask_or_pd (__m256d __W, __mmask8 __U, __m256d __A, __m256d __B) {
  return (__m256d) __builtin_ia32_orpd256_mask ((__v4df) __A,
            (__v4df) __B,
            (__v4df) __W,
            (__mmask8) __U);
}

static __inline__ __m256d __DEFAULT_FN_ATTRS
_mm256_maskz_or_pd (__mmask8 __U, __m256d __A, __m256d __B) {
  return (__m256d) __builtin_ia32_orpd256_mask ((__v4df) __A,
            (__v4df) __B,
            (__v4df)
            _mm256_setzero_pd (),
            (__mmask8) __U);
}

static __inline__ __m128d __DEFAULT_FN_ATTRS
_mm_mask_or_pd (__m128d __W, __mmask8 __U, __m128d __A, __m128d __B) {
  return (__m128d) __builtin_ia32_orpd128_mask ((__v2df) __A,
            (__v2df) __B,
            (__v2df) __W,
            (__mmask8) __U);
}

static __inline__ __m128d __DEFAULT_FN_ATTRS
_mm_maskz_or_pd (__mmask8 __U, __m128d __A, __m128d __B) {
  return (__m128d) __builtin_ia32_orpd128_mask ((__v2df) __A,
            (__v2df) __B,
            (__v2df)
            _mm_setzero_pd (),
            (__mmask8) __U);
}

static __inline__ __m256 __DEFAULT_FN_ATTRS
_mm256_mask_or_ps (__m256 __W, __mmask8 __U, __m256 __A, __m256 __B) {
  return (__m256) __builtin_ia32_orps256_mask ((__v8sf) __A,
                 (__v8sf) __B,
                 (__v8sf) __W,
                 (__mmask8) __U);
}

static __inline__ __m256 __DEFAULT_FN_ATTRS
_mm256_maskz_or_ps (__mmask8 __U, __m256 __A, __m256 __B) {
  return (__m256) __builtin_ia32_orps256_mask ((__v8sf) __A,
                 (__v8sf) __B,
                 (__v8sf)
                 _mm256_setzero_ps (),
                 (__mmask8) __U);
}

static __inline__ __m128 __DEFAULT_FN_ATTRS
_mm_mask_or_ps (__m128 __W, __mmask8 __U, __m128 __A, __m128 __B) {
  return (__m128) __builtin_ia32_orps128_mask ((__v4sf) __A,
                 (__v4sf) __B,
                 (__v4sf) __W,
                 (__mmask8) __U);
}

static __inline__ __m128 __DEFAULT_FN_ATTRS
_mm_maskz_or_ps (__mmask8 __U, __m128 __A, __m128 __B) {
  return (__m128) __builtin_ia32_orps128_mask ((__v4sf) __A,
                 (__v4sf) __B,
                 (__v4sf)
                 _mm_setzero_ps (),
                 (__mmask8) __U);
}

static __inline__ __m128i __DEFAULT_FN_ATTRS
_mm_cvtpd_epi64 (__m128d __A) {
  return (__m128i) __builtin_ia32_cvtpd2qq128_mask ((__v2df) __A,
                (__v2di) _mm_setzero_si128(),
                (__mmask8) -1);
}

static __inline__ __m128i __DEFAULT_FN_ATTRS
_mm_mask_cvtpd_epi64 (__m128i __W, __mmask8 __U, __m128d __A) {
  return (__m128i) __builtin_ia32_cvtpd2qq128_mask ((__v2df) __A,
                (__v2di) __W,
                (__mmask8) __U);
}

static __inline__ __m128i __DEFAULT_FN_ATTRS
_mm_maskz_cvtpd_epi64 (__mmask8 __U, __m128d __A) {
  return (__m128i) __builtin_ia32_cvtpd2qq128_mask ((__v2df) __A,
                (__v2di) _mm_setzero_si128(),
                (__mmask8) __U);
}

static __inline__ __m256i __DEFAULT_FN_ATTRS
_mm256_cvtpd_epi64 (__m256d __A) {
  return (__m256i) __builtin_ia32_cvtpd2qq256_mask ((__v4df) __A,
                (__v4di) _mm256_setzero_si256(),
                (__mmask8) -1);
}

static __inline__ __m256i __DEFAULT_FN_ATTRS
_mm256_mask_cvtpd_epi64 (__m256i __W, __mmask8 __U, __m256d __A) {
  return (__m256i) __builtin_ia32_cvtpd2qq256_mask ((__v4df) __A,
                (__v4di) __W,
                (__mmask8) __U);
}

static __inline__ __m256i __DEFAULT_FN_ATTRS
_mm256_maskz_cvtpd_epi64 (__mmask8 __U, __m256d __A) {
  return (__m256i) __builtin_ia32_cvtpd2qq256_mask ((__v4df) __A,
                (__v4di) _mm256_setzero_si256(),
                (__mmask8) __U);
}

static __inline__ __m128i __DEFAULT_FN_ATTRS
_mm_cvtpd_epu64 (__m128d __A) {
  return (__m128i) __builtin_ia32_cvtpd2uqq128_mask ((__v2df) __A,
                (__v2di) _mm_setzero_si128(),
                (__mmask8) -1);
}

static __inline__ __m128i __DEFAULT_FN_ATTRS
_mm_mask_cvtpd_epu64 (__m128i __W, __mmask8 __U, __m128d __A) {
  return (__m128i) __builtin_ia32_cvtpd2uqq128_mask ((__v2df) __A,
                (__v2di) __W,
                (__mmask8) __U);
}

static __inline__ __m128i __DEFAULT_FN_ATTRS
_mm_maskz_cvtpd_epu64 (__mmask8 __U, __m128d __A) {
  return (__m128i) __builtin_ia32_cvtpd2uqq128_mask ((__v2df) __A,
                (__v2di) _mm_setzero_si128(),
                (__mmask8) __U);
}

static __inline__ __m256i __DEFAULT_FN_ATTRS
_mm256_cvtpd_epu64 (__m256d __A) {
  return (__m256i) __builtin_ia32_cvtpd2uqq256_mask ((__v4df) __A,
                (__v4di) _mm256_setzero_si256(),
                (__mmask8) -1);
}

static __inline__ __m256i __DEFAULT_FN_ATTRS
_mm256_mask_cvtpd_epu64 (__m256i __W, __mmask8 __U, __m256d __A) {
  return (__m256i) __builtin_ia32_cvtpd2uqq256_mask ((__v4df) __A,
                (__v4di) __W,
                (__mmask8) __U);
}

static __inline__ __m256i __DEFAULT_FN_ATTRS
_mm256_maskz_cvtpd_epu64 (__mmask8 __U, __m256d __A) {
  return (__m256i) __builtin_ia32_cvtpd2uqq256_mask ((__v4df) __A,
                (__v4di) _mm256_setzero_si256(),
                (__mmask8) __U);
}

static __inline__ __m128i __DEFAULT_FN_ATTRS
_mm_cvtps_epi64 (__m128 __A) {
  return (__m128i) __builtin_ia32_cvtps2qq128_mask ((__v4sf) __A,
                (__v2di) _mm_setzero_si128(),
                (__mmask8) -1);
}

static __inline__ __m128i __DEFAULT_FN_ATTRS
_mm_mask_cvtps_epi64 (__m128i __W, __mmask8 __U, __m128 __A) {
  return (__m128i) __builtin_ia32_cvtps2qq128_mask ((__v4sf) __A,
                (__v2di) __W,
                (__mmask8) __U);
}

static __inline__ __m128i __DEFAULT_FN_ATTRS
_mm_maskz_cvtps_epi64 (__mmask8 __U, __m128 __A) {
  return (__m128i) __builtin_ia32_cvtps2qq128_mask ((__v4sf) __A,
                (__v2di) _mm_setzero_si128(),
                (__mmask8) __U);
}

static __inline__ __m256i __DEFAULT_FN_ATTRS
_mm256_cvtps_epi64 (__m128 __A) {
  return (__m256i) __builtin_ia32_cvtps2qq256_mask ((__v4sf) __A,
                (__v4di) _mm256_setzero_si256(),
                (__mmask8) -1);
}

static __inline__ __m256i __DEFAULT_FN_ATTRS
_mm256_mask_cvtps_epi64 (__m256i __W, __mmask8 __U, __m128 __A) {
  return (__m256i) __builtin_ia32_cvtps2qq256_mask ((__v4sf) __A,
                (__v4di) __W,
                (__mmask8) __U);
}

static __inline__ __m256i __DEFAULT_FN_ATTRS
_mm256_maskz_cvtps_epi64 (__mmask8 __U, __m128 __A) {
  return (__m256i) __builtin_ia32_cvtps2qq256_mask ((__v4sf) __A,
                (__v4di) _mm256_setzero_si256(),
                (__mmask8) __U);
}

static __inline__ __m128i __DEFAULT_FN_ATTRS
_mm_cvtps_epu64 (__m128 __A) {
  return (__m128i) __builtin_ia32_cvtps2uqq128_mask ((__v4sf) __A,
                (__v2di) _mm_setzero_si128(),
                (__mmask8) -1);
}

static __inline__ __m128i __DEFAULT_FN_ATTRS
_mm_mask_cvtps_epu64 (__m128i __W, __mmask8 __U, __m128 __A) {
  return (__m128i) __builtin_ia32_cvtps2uqq128_mask ((__v4sf) __A,
                (__v2di) __W,
                (__mmask8) __U);
}

static __inline__ __m128i __DEFAULT_FN_ATTRS
_mm_maskz_cvtps_epu64 (__mmask8 __U, __m128 __A) {
  return (__m128i) __builtin_ia32_cvtps2uqq128_mask ((__v4sf) __A,
                (__v2di) _mm_setzero_si128(),
                (__mmask8) __U);
}

static __inline__ __m256i __DEFAULT_FN_ATTRS
_mm256_cvtps_epu64 (__m128 __A) {
  return (__m256i) __builtin_ia32_cvtps2uqq256_mask ((__v4sf) __A,
                (__v4di) _mm256_setzero_si256(),
                (__mmask8) -1);
}

static __inline__ __m256i __DEFAULT_FN_ATTRS
_mm256_mask_cvtps_epu64 (__m256i __W, __mmask8 __U, __m128 __A) {
  return (__m256i) __builtin_ia32_cvtps2uqq256_mask ((__v4sf) __A,
                (__v4di) __W,
                (__mmask8) __U);
}

static __inline__ __m256i __DEFAULT_FN_ATTRS
_mm256_maskz_cvtps_epu64 (__mmask8 __U, __m128 __A) {
  return (__m256i) __builtin_ia32_cvtps2uqq256_mask ((__v4sf) __A,
                (__v4di) _mm256_setzero_si256(),
                (__mmask8) __U);
}

static __inline__ __m128d __DEFAULT_FN_ATTRS
_mm_cvtepi64_pd (__m128i __A) {
  return (__m128d) __builtin_ia32_cvtqq2pd128_mask ((__v2di) __A,
                (__v2df) _mm_setzero_pd(),
                (__mmask8) -1);
}

static __inline__ __m128d __DEFAULT_FN_ATTRS
_mm_mask_cvtepi64_pd (__m128d __W, __mmask8 __U, __m128i __A) {
  return (__m128d) __builtin_ia32_cvtqq2pd128_mask ((__v2di) __A,
                (__v2df) __W,
                (__mmask8) __U);
}

static __inline__ __m128d __DEFAULT_FN_ATTRS
_mm_maskz_cvtepi64_pd (__mmask8 __U, __m128i __A) {
  return (__m128d) __builtin_ia32_cvtqq2pd128_mask ((__v2di) __A,
                (__v2df) _mm_setzero_pd(),
                (__mmask8) __U);
}

static __inline__ __m256d __DEFAULT_FN_ATTRS
_mm256_cvtepi64_pd (__m256i __A) {
  return (__m256d) __builtin_ia32_cvtqq2pd256_mask ((__v4di) __A,
                (__v4df) _mm256_setzero_pd(),
                (__mmask8) -1);
}

static __inline__ __m256d __DEFAULT_FN_ATTRS
_mm256_mask_cvtepi64_pd (__m256d __W, __mmask8 __U, __m256i __A) {
  return (__m256d) __builtin_ia32_cvtqq2pd256_mask ((__v4di) __A,
                (__v4df) __W,
                (__mmask8) __U);
}

static __inline__ __m256d __DEFAULT_FN_ATTRS
_mm256_maskz_cvtepi64_pd (__mmask8 __U, __m256i __A) {
  return (__m256d) __builtin_ia32_cvtqq2pd256_mask ((__v4di) __A,
                (__v4df) _mm256_setzero_pd(),
                (__mmask8) __U);
}

static __inline__ __m128 __DEFAULT_FN_ATTRS
_mm_cvtepi64_ps (__m128i __A) {
  return (__m128) __builtin_ia32_cvtqq2ps128_mask ((__v2di) __A,
                (__v4sf) _mm_setzero_ps(),
                (__mmask8) -1);
}

static __inline__ __m128 __DEFAULT_FN_ATTRS
_mm_mask_cvtepi64_ps (__m128 __W, __mmask8 __U, __m128i __A) {
  return (__m128) __builtin_ia32_cvtqq2ps128_mask ((__v2di) __A,
                (__v4sf) __W,
                (__mmask8) __U);
}

static __inline__ __m128 __DEFAULT_FN_ATTRS
_mm_maskz_cvtepi64_ps (__mmask8 __U, __m128i __A) {
  return (__m128) __builtin_ia32_cvtqq2ps128_mask ((__v2di) __A,
                (__v4sf) _mm_setzero_ps(),
                (__mmask8) __U);
}

static __inline__ __m128 __DEFAULT_FN_ATTRS
_mm256_cvtepi64_ps (__m256i __A) {
  return (__m128) __builtin_ia32_cvtqq2ps256_mask ((__v4di) __A,
                (__v4sf) _mm_setzero_ps(),
                (__mmask8) -1);
}

static __inline__ __m128 __DEFAULT_FN_ATTRS
_mm256_mask_cvtepi64_ps (__m128 __W, __mmask8 __U, __m256i __A) {
  return (__m128) __builtin_ia32_cvtqq2ps256_mask ((__v4di) __A,
                (__v4sf) __W,
                (__mmask8) __U);
}

static __inline__ __m128 __DEFAULT_FN_ATTRS
_mm256_maskz_cvtepi64_ps (__mmask8 __U, __m256i __A) {
  return (__m128) __builtin_ia32_cvtqq2ps256_mask ((__v4di) __A,
                (__v4sf) _mm_setzero_ps(),
                (__mmask8) __U);
}

static __inline__ __m128i __DEFAULT_FN_ATTRS
_mm_cvttpd_epi64 (__m128d __A) {
  return (__m128i) __builtin_ia32_cvttpd2qq128_mask ((__v2df) __A,
                (__v2di) _mm_setzero_si128(),
                (__mmask8) -1);
}

static __inline__ __m128i __DEFAULT_FN_ATTRS
_mm_mask_cvttpd_epi64 (__m128i __W, __mmask8 __U, __m128d __A) {
  return (__m128i) __builtin_ia32_cvttpd2qq128_mask ((__v2df) __A,
                (__v2di) __W,
                (__mmask8) __U);
}

static __inline__ __m128i __DEFAULT_FN_ATTRS
_mm_maskz_cvttpd_epi64 (__mmask8 __U, __m128d __A) {
  return (__m128i) __builtin_ia32_cvttpd2qq128_mask ((__v2df) __A,
                (__v2di) _mm_setzero_si128(),
                (__mmask8) __U);
}

static __inline__ __m256i __DEFAULT_FN_ATTRS
_mm256_cvttpd_epi64 (__m256d __A) {
  return (__m256i) __builtin_ia32_cvttpd2qq256_mask ((__v4df) __A,
                (__v4di) _mm256_setzero_si256(),
                (__mmask8) -1);
}

static __inline__ __m256i __DEFAULT_FN_ATTRS
_mm256_mask_cvttpd_epi64 (__m256i __W, __mmask8 __U, __m256d __A) {
  return (__m256i) __builtin_ia32_cvttpd2qq256_mask ((__v4df) __A,
                (__v4di) __W,
                (__mmask8) __U);
}

static __inline__ __m256i __DEFAULT_FN_ATTRS
_mm256_maskz_cvttpd_epi64 (__mmask8 __U, __m256d __A) {
  return (__m256i) __builtin_ia32_cvttpd2qq256_mask ((__v4df) __A,
                (__v4di) _mm256_setzero_si256(),
                (__mmask8) __U);
}

static __inline__ __m128i __DEFAULT_FN_ATTRS
_mm_cvttpd_epu64 (__m128d __A) {
  return (__m128i) __builtin_ia32_cvttpd2uqq128_mask ((__v2df) __A,
                (__v2di) _mm_setzero_si128(),
                (__mmask8) -1);
}

static __inline__ __m128i __DEFAULT_FN_ATTRS
_mm_mask_cvttpd_epu64 (__m128i __W, __mmask8 __U, __m128d __A) {
  return (__m128i) __builtin_ia32_cvttpd2uqq128_mask ((__v2df) __A,
                (__v2di) __W,
                (__mmask8) __U);
}

static __inline__ __m128i __DEFAULT_FN_ATTRS
_mm_maskz_cvttpd_epu64 (__mmask8 __U, __m128d __A) {
  return (__m128i) __builtin_ia32_cvttpd2uqq128_mask ((__v2df) __A,
                (__v2di) _mm_setzero_si128(),
                (__mmask8) __U);
}

static __inline__ __m256i __DEFAULT_FN_ATTRS
_mm256_cvttpd_epu64 (__m256d __A) {
  return (__m256i) __builtin_ia32_cvttpd2uqq256_mask ((__v4df) __A,
                (__v4di) _mm256_setzero_si256(),
                (__mmask8) -1);
}

static __inline__ __m256i __DEFAULT_FN_ATTRS
_mm256_mask_cvttpd_epu64 (__m256i __W, __mmask8 __U, __m256d __A) {
  return (__m256i) __builtin_ia32_cvttpd2uqq256_mask ((__v4df) __A,
                (__v4di) __W,
                (__mmask8) __U);
}

static __inline__ __m256i __DEFAULT_FN_ATTRS
_mm256_maskz_cvttpd_epu64 (__mmask8 __U, __m256d __A) {
  return (__m256i) __builtin_ia32_cvttpd2uqq256_mask ((__v4df) __A,
                (__v4di) _mm256_setzero_si256(),
                (__mmask8) __U);
}

static __inline__ __m128i __DEFAULT_FN_ATTRS
_mm_cvttps_epi64 (__m128 __A) {
  return (__m128i) __builtin_ia32_cvttps2qq128_mask ((__v4sf) __A,
                (__v2di) _mm_setzero_si128(),
                (__mmask8) -1);
}

static __inline__ __m128i __DEFAULT_FN_ATTRS
_mm_mask_cvttps_epi64 (__m128i __W, __mmask8 __U, __m128 __A) {
  return (__m128i) __builtin_ia32_cvttps2qq128_mask ((__v4sf) __A,
                (__v2di) __W,
                (__mmask8) __U);
}

static __inline__ __m128i __DEFAULT_FN_ATTRS
_mm_maskz_cvttps_epi64 (__mmask8 __U, __m128 __A) {
  return (__m128i) __builtin_ia32_cvttps2qq128_mask ((__v4sf) __A,
                (__v2di) _mm_setzero_si128(),
                (__mmask8) __U);
}

static __inline__ __m256i __DEFAULT_FN_ATTRS
_mm256_cvttps_epi64 (__m128 __A) {
  return (__m256i) __builtin_ia32_cvttps2qq256_mask ((__v4sf) __A,
                (__v4di) _mm256_setzero_si256(),
                (__mmask8) -1);
}

static __inline__ __m256i __DEFAULT_FN_ATTRS
_mm256_mask_cvttps_epi64 (__m256i __W, __mmask8 __U, __m128 __A) {
  return (__m256i) __builtin_ia32_cvttps2qq256_mask ((__v4sf) __A,
                (__v4di) __W,
                (__mmask8) __U);
}

static __inline__ __m256i __DEFAULT_FN_ATTRS
_mm256_maskz_cvttps_epi64 (__mmask8 __U, __m128 __A) {
  return (__m256i) __builtin_ia32_cvttps2qq256_mask ((__v4sf) __A,
                (__v4di) _mm256_setzero_si256(),
                (__mmask8) __U);
}

static __inline__ __m128i __DEFAULT_FN_ATTRS
_mm_cvttps_epu64 (__m128 __A) {
  return (__m128i) __builtin_ia32_cvttps2uqq128_mask ((__v4sf) __A,
                (__v2di) _mm_setzero_si128(),
                (__mmask8) -1);
}

static __inline__ __m128i __DEFAULT_FN_ATTRS
_mm_mask_cvttps_epu64 (__m128i __W, __mmask8 __U, __m128 __A) {
  return (__m128i) __builtin_ia32_cvttps2uqq128_mask ((__v4sf) __A,
                (__v2di) __W,
                (__mmask8) __U);
}

static __inline__ __m128i __DEFAULT_FN_ATTRS
_mm_maskz_cvttps_epu64 (__mmask8 __U, __m128 __A) {
  return (__m128i) __builtin_ia32_cvttps2uqq128_mask ((__v4sf) __A,
                (__v2di) _mm_setzero_si128(),
                (__mmask8) __U);
}

static __inline__ __m256i __DEFAULT_FN_ATTRS
_mm256_cvttps_epu64 (__m128 __A) {
  return (__m256i) __builtin_ia32_cvttps2uqq256_mask ((__v4sf) __A,
                (__v4di) _mm256_setzero_si256(),
                (__mmask8) -1);
}

static __inline__ __m256i __DEFAULT_FN_ATTRS
_mm256_mask_cvttps_epu64 (__m256i __W, __mmask8 __U, __m128 __A) {
  return (__m256i) __builtin_ia32_cvttps2uqq256_mask ((__v4sf) __A,
                (__v4di) __W,
                (__mmask8) __U);
}

static __inline__ __m256i __DEFAULT_FN_ATTRS
_mm256_maskz_cvttps_epu64 (__mmask8 __U, __m128 __A) {
  return (__m256i) __builtin_ia32_cvttps2uqq256_mask ((__v4sf) __A,
                (__v4di) _mm256_setzero_si256(),
                (__mmask8) __U);
}

static __inline__ __m128d __DEFAULT_FN_ATTRS
_mm_cvtepu64_pd (__m128i __A) {
  return (__m128d) __builtin_ia32_cvtuqq2pd128_mask ((__v2di) __A,
                (__v2df) _mm_setzero_pd(),
                (__mmask8) -1);
}

static __inline__ __m128d __DEFAULT_FN_ATTRS
_mm_mask_cvtepu64_pd (__m128d __W, __mmask8 __U, __m128i __A) {
  return (__m128d) __builtin_ia32_cvtuqq2pd128_mask ((__v2di) __A,
                (__v2df) __W,
                (__mmask8) __U);
}

static __inline__ __m128d __DEFAULT_FN_ATTRS
_mm_maskz_cvtepu64_pd (__mmask8 __U, __m128i __A) {
  return (__m128d) __builtin_ia32_cvtuqq2pd128_mask ((__v2di) __A,
                (__v2df) _mm_setzero_pd(),
                (__mmask8) __U);
}

static __inline__ __m256d __DEFAULT_FN_ATTRS
_mm256_cvtepu64_pd (__m256i __A) {
  return (__m256d) __builtin_ia32_cvtuqq2pd256_mask ((__v4di) __A,
                (__v4df) _mm256_setzero_pd(),
                (__mmask8) -1);
}

static __inline__ __m256d __DEFAULT_FN_ATTRS
_mm256_mask_cvtepu64_pd (__m256d __W, __mmask8 __U, __m256i __A) {
  return (__m256d) __builtin_ia32_cvtuqq2pd256_mask ((__v4di) __A,
                (__v4df) __W,
                (__mmask8) __U);
}

static __inline__ __m256d __DEFAULT_FN_ATTRS
_mm256_maskz_cvtepu64_pd (__mmask8 __U, __m256i __A) {
  return (__m256d) __builtin_ia32_cvtuqq2pd256_mask ((__v4di) __A,
                (__v4df) _mm256_setzero_pd(),
                (__mmask8) __U);
}

static __inline__ __m128 __DEFAULT_FN_ATTRS
_mm_cvtepu64_ps (__m128i __A) {
  return (__m128) __builtin_ia32_cvtuqq2ps128_mask ((__v2di) __A,
                (__v4sf) _mm_setzero_ps(),
                (__mmask8) -1);
}

static __inline__ __m128 __DEFAULT_FN_ATTRS
_mm_mask_cvtepu64_ps (__m128 __W, __mmask8 __U, __m128i __A) {
  return (__m128) __builtin_ia32_cvtuqq2ps128_mask ((__v2di) __A,
                (__v4sf) __W,
                (__mmask8) __U);
}

static __inline__ __m128 __DEFAULT_FN_ATTRS
_mm_maskz_cvtepu64_ps (__mmask8 __U, __m128i __A) {
  return (__m128) __builtin_ia32_cvtuqq2ps128_mask ((__v2di) __A,
                (__v4sf) _mm_setzero_ps(),
                (__mmask8) __U);
}

static __inline__ __m128 __DEFAULT_FN_ATTRS
_mm256_cvtepu64_ps (__m256i __A) {
  return (__m128) __builtin_ia32_cvtuqq2ps256_mask ((__v4di) __A,
                (__v4sf) _mm_setzero_ps(),
                (__mmask8) -1);
}

static __inline__ __m128 __DEFAULT_FN_ATTRS
_mm256_mask_cvtepu64_ps (__m128 __W, __mmask8 __U, __m256i __A) {
  return (__m128) __builtin_ia32_cvtuqq2ps256_mask ((__v4di) __A,
                (__v4sf) __W,
                (__mmask8) __U);
}

static __inline__ __m128 __DEFAULT_FN_ATTRS
_mm256_maskz_cvtepu64_ps (__mmask8 __U, __m256i __A) {
  return (__m128) __builtin_ia32_cvtuqq2ps256_mask ((__v4di) __A,
                (__v4sf) _mm_setzero_ps(),
                (__mmask8) __U);
}

#define _mm_range_pd(__A, __B, __C) __extension__ ({                         \
  (__m128d) __builtin_ia32_rangepd128_mask ((__v2df) __A, (__v2df) __B, __C, \
                (__v2df) _mm_setzero_pd(), (__mmask8) -1); })

#define _mm_mask_range_pd(__W, __U, __A, __B, __C) __extension__ ({          \
  (__m128d) __builtin_ia32_rangepd128_mask ((__v2df) __A, (__v2df) __B, __C, \
                (__v2df) __W, (__mmask8) __U); })

#define _mm_maskz_range_pd(__U, __A, __B, __C) __extension__ ({              \
  (__m128d) __builtin_ia32_rangepd128_mask ((__v2df) __A, (__v2df) __B, __C, \
                (__v2df) _mm_setzero_pd(), (__mmask8) __U); })

#define _mm256_range_pd(__A, __B, __C) __extension__ ({                      \
  (__m256d) __builtin_ia32_rangepd256_mask ((__v4df) __A, (__v4df) __B, __C, \
                (__v4df) _mm256_setzero_pd(), (__mmask8) -1); })

#define _mm256_mask_range_pd(__W, __U, __A, __B, __C) __extension__ ({       \
  (__m256d) __builtin_ia32_rangepd256_mask ((__v4df) __A, (__v4df) __B, __C, \
                (__v4df) __W, (__mmask8) __U); })

#define _mm256_maskz_range_pd(__U, __A, __B, __C) __extension__ ({           \
  (__m256d) __builtin_ia32_rangepd256_mask ((__v4df) __A, (__v4df) __B, __C, \
                (__v4df) _mm256_setzero_pd(), (__mmask8) __U); })

#define _mm_range_ps(__A, __B, __C) __extension__ ({                         \
  (__m128) __builtin_ia32_rangeps128_mask ((__v4sf) __A, (__v4sf) __B, __C,  \
                (__v4sf) _mm_setzero_ps(), (__mmask8) -1); })

#define _mm_mask_range_ps(__W, __U, __A, __B, __C) __extension__ ({          \
  (__m128) __builtin_ia32_rangeps128_mask ((__v4sf) __A, (__v4sf) __B, __C,  \
                (__v4sf) __W, (__mmask8) __U); })

#define _mm_maskz_range_ps(__U, __A, __B, __C) __extension__ ({              \
  (__m128) __builtin_ia32_rangeps128_mask ((__v4sf) __A, (__v4sf) __B, __C,  \
                (__v4sf) _mm_setzero_ps(), (__mmask8) __U); })

#define _mm256_range_ps(__A, __B, __C) __extension__ ({                      \
  (__m256) __builtin_ia32_rangeps256_mask ((__v8sf) __A, (__v8sf) __B, __C,  \
                (__v8sf) _mm256_setzero_ps(), (__mmask8) -1); })

#define _mm256_mask_range_ps(__W, __U, __A, __B, __C) __extension__ ({       \
  (__m256) __builtin_ia32_rangeps256_mask ((__v8sf) __A, (__v8sf) __B, __C,  \
                (__v8sf) __W, (__mmask8) __U); })

#define _mm256_maskz_range_ps(__U, __A, __B, __C) __extension__ ({           \
  (__m256) __builtin_ia32_rangeps256_mask ((__v8sf) __A, (__v8sf) __B, __C,  \
                (__v8sf) _mm256_setzero_ps(), (__mmask8) __U); })

#define _mm_reduce_pd(__A, __B) __extension__ ({                \
  (__m128d) __builtin_ia32_reducepd128_mask ((__v2df) __A, __B, \
                (__v2df) _mm_setzero_pd(), (__mmask8) -1); })

#define _mm_mask_reduce_pd(__W, __U, __A, __B) __extension__ ({ \
  (__m128d) __builtin_ia32_reducepd128_mask ((__v2df) __A, __B, \
                (__v2df) __W, (__mmask8) __U); })

#define _mm_maskz_reduce_pd(__U, __A, __B) __extension__ ({     \
  (__m128d) __builtin_ia32_reducepd128_mask ((__v2df) __A, __B, \
                (__v2df) _mm_setzero_pd(), (__mmask8) __U); })

#define _mm256_reduce_pd(__A, __B) __extension__ ({                \
  (__m256d) __builtin_ia32_reducepd256_mask ((__v4df) __A, __B,    \
                (__v4df) _mm256_setzero_pd(), (__mmask8) -1); })

#define _mm256_mask_reduce_pd(__W, __U, __A, __B) __extension__ ({ \
  (__m256d) __builtin_ia32_reducepd256_mask ((__v4df) __A, __B,    \
                (__v4df) __W, (__mmask8) __U); })

#define _mm256_maskz_reduce_pd(__U, __A, __B) __extension__ ({     \
  (__m256d) __builtin_ia32_reducepd256_mask ((__v4df) __A, __B,    \
                (__v4df) _mm256_setzero_pd(), (__mmask8) __U); })

#define _mm_reduce_ps(__A, __B) __extension__ ({                   \
  (__m128) __builtin_ia32_reduceps128_mask ((__v4sf) __A, __B,     \
                (__v4sf) _mm_setzero_ps(), (__mmask8) -1); })

#define _mm_mask_reduce_ps(__W, __U, __A, __B) __extension__ ({    \
  (__m128) __builtin_ia32_reduceps128_mask ((__v4sf) __A, __B,     \
                (__v4sf) __W, (__mmask8) __U); })

#define _mm_maskz_reduce_ps(__U, __A, __B) __extension__ ({        \
  (__m128) __builtin_ia32_reduceps128_mask ((__v4sf) __A, __B,     \
                (__v4sf) _mm_setzero_ps(), (__mmask8) __U); })

#define _mm256_reduce_ps(__A, __B) __extension__ ({                \
  (__m256) __builtin_ia32_reduceps256_mask ((__v8sf) __A, __B,     \
                (__v8sf) _mm256_setzero_ps(), (__mmask8) -1); })

#define _mm256_mask_reduce_ps(__W, __U, __A, __B) __extension__ ({ \
  (__m256) __builtin_ia32_reduceps256_mask ((__v8sf) __A, __B,     \
                (__v8sf) __W, (__mmask8) __U); })

#define _mm256_maskz_reduce_ps(__U, __A, __B) __extension__ ({     \
  (__m256) __builtin_ia32_reduceps256_mask ((__v8sf) __A, __B,     \
                (__v8sf) _mm256_setzero_ps(), (__mmask8) __U); })

#undef __DEFAULT_FN_ATTRS

#endif
@


1.1.1.1
log
@Use the space freed up by sparc and zaurus to import LLVM.

ok hackroom@@
@
text
@@


1.1.1.2
log
@Import LLVM 3.9.1 including clang and lld.
@
text
@d36 1
a36 1
  return (__m256i) ((__v4du) __A * (__v4du) __B);
d58 1
a58 1
  return (__m128i) ((__v2du) __A * (__v2du) __B);
d855 95
a949 407
#define _mm_range_pd(A, B, C) __extension__ ({                         \
  (__m128d)__builtin_ia32_rangepd128_mask((__v2df)(__m128d)(A), \
                                          (__v2df)(__m128d)(B), (int)(C), \
                                          (__v2df)_mm_setzero_pd(), \
                                          (__mmask8)-1); })

#define _mm_mask_range_pd(W, U, A, B, C) __extension__ ({          \
  (__m128d)__builtin_ia32_rangepd128_mask((__v2df)(__m128d)(A), \
                                          (__v2df)(__m128d)(B), (int)(C), \
                                          (__v2df)(__m128d)(W), \
                                          (__mmask8)(U)); })

#define _mm_maskz_range_pd(U, A, B, C) __extension__ ({              \
  (__m128d)__builtin_ia32_rangepd128_mask((__v2df)(__m128d)(A), \
                                          (__v2df)(__m128d)(B), (int)(C), \
                                          (__v2df)_mm_setzero_pd(), \
                                          (__mmask8)(U)); })

#define _mm256_range_pd(A, B, C) __extension__ ({                      \
  (__m256d)__builtin_ia32_rangepd256_mask((__v4df)(__m256d)(A), \
                                          (__v4df)(__m256d)(B), (int)(C), \
                                          (__v4df)_mm256_setzero_pd(), \
                                          (__mmask8)-1); })

#define _mm256_mask_range_pd(W, U, A, B, C) __extension__ ({       \
  (__m256d)__builtin_ia32_rangepd256_mask((__v4df)(__m256d)(A), \
                                          (__v4df)(__m256d)(B), (int)(C), \
                                          (__v4df)(__m256d)(W), \
                                          (__mmask8)(U)); })

#define _mm256_maskz_range_pd(U, A, B, C) __extension__ ({           \
  (__m256d)__builtin_ia32_rangepd256_mask((__v4df)(__m256d)(A), \
                                          (__v4df)(__m256d)(B), (int)(C), \
                                          (__v4df)_mm256_setzero_pd(), \
                                          (__mmask8)(U)); })

#define _mm_range_ps(A, B, C) __extension__ ({                         \
  (__m128)__builtin_ia32_rangeps128_mask((__v4sf)(__m128)(A), \
                                         (__v4sf)(__m128)(B), (int)(C), \
                                         (__v4sf)_mm_setzero_ps(), \
                                         (__mmask8)-1); })

#define _mm_mask_range_ps(W, U, A, B, C) __extension__ ({          \
  (__m128)__builtin_ia32_rangeps128_mask((__v4sf)(__m128)(A), \
                                         (__v4sf)(__m128)(B), (int)(C), \
                                         (__v4sf)(__m128)(W), (__mmask8)(U)); })

#define _mm_maskz_range_ps(U, A, B, C) __extension__ ({              \
  (__m128)__builtin_ia32_rangeps128_mask((__v4sf)(__m128)(A), \
                                         (__v4sf)(__m128)(B), (int)(C), \
                                         (__v4sf)_mm_setzero_ps(), \
                                         (__mmask8)(U)); })

#define _mm256_range_ps(A, B, C) __extension__ ({                      \
  (__m256)__builtin_ia32_rangeps256_mask((__v8sf)(__m256)(A), \
                                         (__v8sf)(__m256)(B), (int)(C), \
                                         (__v8sf)_mm256_setzero_ps(), \
                                         (__mmask8)-1); })

#define _mm256_mask_range_ps(W, U, A, B, C) __extension__ ({       \
  (__m256)__builtin_ia32_rangeps256_mask((__v8sf)(__m256)(A), \
                                         (__v8sf)(__m256)(B), (int)(C), \
                                         (__v8sf)(__m256)(W), (__mmask8)(U)); })

#define _mm256_maskz_range_ps(U, A, B, C) __extension__ ({           \
  (__m256)__builtin_ia32_rangeps256_mask((__v8sf)(__m256)(A), \
                                         (__v8sf)(__m256)(B), (int)(C), \
                                         (__v8sf)_mm256_setzero_ps(), \
                                         (__mmask8)(U)); })

#define _mm_reduce_pd(A, B) __extension__ ({                \
  (__m128d)__builtin_ia32_reducepd128_mask((__v2df)(__m128d)(A), (int)(B), \
                                           (__v2df)_mm_setzero_pd(), \
                                           (__mmask8)-1); })

#define _mm_mask_reduce_pd(W, U, A, B) __extension__ ({ \
  (__m128d)__builtin_ia32_reducepd128_mask((__v2df)(__m128d)(A), (int)(B), \
                                           (__v2df)(__m128d)(W), \
                                           (__mmask8)(U)); })

#define _mm_maskz_reduce_pd(U, A, B) __extension__ ({     \
  (__m128d)__builtin_ia32_reducepd128_mask((__v2df)(__m128d)(A), (int)(B), \
                                           (__v2df)_mm_setzero_pd(), \
                                           (__mmask8)(U)); })

#define _mm256_reduce_pd(A, B) __extension__ ({                \
  (__m256d)__builtin_ia32_reducepd256_mask((__v4df)(__m256d)(A), (int)(B), \
                                           (__v4df)_mm256_setzero_pd(), \
                                           (__mmask8)-1); })

#define _mm256_mask_reduce_pd(W, U, A, B) __extension__ ({ \
  (__m256d)__builtin_ia32_reducepd256_mask((__v4df)(__m256d)(A), (int)(B), \
                                           (__v4df)(__m256d)(W), \
                                           (__mmask8)(U)); })

#define _mm256_maskz_reduce_pd(U, A, B) __extension__ ({     \
  (__m256d)__builtin_ia32_reducepd256_mask((__v4df)(__m256d)(A), (int)(B), \
                                           (__v4df)_mm256_setzero_pd(), \
                                           (__mmask8)(U)); })

#define _mm_reduce_ps(A, B) __extension__ ({                   \
  (__m128)__builtin_ia32_reduceps128_mask((__v4sf)(__m128)(A), (int)(B), \
                                          (__v4sf)_mm_setzero_ps(), \
                                          (__mmask8)-1); })

#define _mm_mask_reduce_ps(W, U, A, B) __extension__ ({    \
  (__m128)__builtin_ia32_reduceps128_mask((__v4sf)(__m128)(A), (int)(B), \
                                          (__v4sf)(__m128)(W), \
                                          (__mmask8)(U)); })

#define _mm_maskz_reduce_ps(U, A, B) __extension__ ({        \
  (__m128)__builtin_ia32_reduceps128_mask((__v4sf)(__m128)(A), (int)(B), \
                                          (__v4sf)_mm_setzero_ps(), \
                                          (__mmask8)(U)); })

#define _mm256_reduce_ps(A, B) __extension__ ({                \
  (__m256)__builtin_ia32_reduceps256_mask((__v8sf)(__m256)(A), (int)(B), \
                                          (__v8sf)_mm256_setzero_ps(), \
                                          (__mmask8)-1); })

#define _mm256_mask_reduce_ps(W, U, A, B) __extension__ ({ \
  (__m256)__builtin_ia32_reduceps256_mask((__v8sf)(__m256)(A), (int)(B), \
                                          (__v8sf)(__m256)(W), \
                                          (__mmask8)(U)); })

#define _mm256_maskz_reduce_ps(U, A, B) __extension__ ({     \
  (__m256)__builtin_ia32_reduceps256_mask((__v8sf)(__m256)(A), (int)(B), \
                                          (__v8sf)_mm256_setzero_ps(), \
                                          (__mmask8)(U)); })

static __inline__ __mmask8 __DEFAULT_FN_ATTRS
_mm_movepi32_mask (__m128i __A)
{
  return (__mmask8) __builtin_ia32_cvtd2mask128 ((__v4si) __A);
}

static __inline__ __mmask8 __DEFAULT_FN_ATTRS
_mm256_movepi32_mask (__m256i __A)
{
  return (__mmask8) __builtin_ia32_cvtd2mask256 ((__v8si) __A);
}

static __inline__ __m128i __DEFAULT_FN_ATTRS
_mm_movm_epi32 (__mmask8 __A)
{
  return (__m128i) __builtin_ia32_cvtmask2d128 (__A);
}

static __inline__ __m256i __DEFAULT_FN_ATTRS
_mm256_movm_epi32 (__mmask8 __A)
{
  return (__m256i) __builtin_ia32_cvtmask2d256 (__A);
}

static __inline__ __m128i __DEFAULT_FN_ATTRS
_mm_movm_epi64 (__mmask8 __A)
{
  return (__m128i) __builtin_ia32_cvtmask2q128 (__A);
}

static __inline__ __m256i __DEFAULT_FN_ATTRS
_mm256_movm_epi64 (__mmask8 __A)
{
  return (__m256i) __builtin_ia32_cvtmask2q256 (__A);
}

static __inline__ __mmask8 __DEFAULT_FN_ATTRS
_mm_movepi64_mask (__m128i __A)
{
  return (__mmask8) __builtin_ia32_cvtq2mask128 ((__v2di) __A);
}

static __inline__ __mmask8 __DEFAULT_FN_ATTRS
_mm256_movepi64_mask (__m256i __A)
{
  return (__mmask8) __builtin_ia32_cvtq2mask256 ((__v4di) __A);
}

static __inline__ __m256 __DEFAULT_FN_ATTRS
_mm256_broadcast_f32x2 (__m128 __A)
{
  return (__m256) __builtin_ia32_broadcastf32x2_256_mask ((__v4sf) __A,
                (__v8sf)_mm256_undefined_ps(),
                (__mmask8) -1);
}

static __inline__ __m256 __DEFAULT_FN_ATTRS
_mm256_mask_broadcast_f32x2 (__m256 __O, __mmask8 __M, __m128 __A)
{
  return (__m256) __builtin_ia32_broadcastf32x2_256_mask ((__v4sf) __A,
                (__v8sf) __O,
                __M);
}

static __inline__ __m256 __DEFAULT_FN_ATTRS
_mm256_maskz_broadcast_f32x2 (__mmask8 __M, __m128 __A)
{
  return (__m256) __builtin_ia32_broadcastf32x2_256_mask ((__v4sf) __A,
                (__v8sf) _mm256_setzero_ps (),
                __M);
}

static __inline__ __m256d __DEFAULT_FN_ATTRS
_mm256_broadcast_f64x2 (__m128d __A)
{
  return (__m256d) __builtin_ia32_broadcastf64x2_256_mask ((__v2df) __A,
                 (__v4df)_mm256_undefined_pd(),
                 (__mmask8) -1);
}

static __inline__ __m256d __DEFAULT_FN_ATTRS
_mm256_mask_broadcast_f64x2 (__m256d __O, __mmask8 __M, __m128d __A)
{
  return (__m256d) __builtin_ia32_broadcastf64x2_256_mask ((__v2df) __A,
                 (__v4df) __O,
                 __M);
}

static __inline__ __m256d __DEFAULT_FN_ATTRS
_mm256_maskz_broadcast_f64x2 (__mmask8 __M, __m128d __A)
{
  return (__m256d) __builtin_ia32_broadcastf64x2_256_mask ((__v2df) __A,
                 (__v4df) _mm256_setzero_ps (),
                 __M);
}

static __inline__ __m128i __DEFAULT_FN_ATTRS
_mm_broadcast_i32x2 (__m128i __A)
{
  return (__m128i) __builtin_ia32_broadcasti32x2_128_mask ((__v4si) __A,
                 (__v4si)_mm_undefined_si128(),
                 (__mmask8) -1);
}

static __inline__ __m128i __DEFAULT_FN_ATTRS
_mm_mask_broadcast_i32x2 (__m128i __O, __mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_broadcasti32x2_128_mask ((__v4si) __A,
                 (__v4si) __O,
                 __M);
}

static __inline__ __m128i __DEFAULT_FN_ATTRS
_mm_maskz_broadcast_i32x2 (__mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_broadcasti32x2_128_mask ((__v4si) __A,
                 (__v4si) _mm_setzero_si128 (),
                 __M);
}

static __inline__ __m256i __DEFAULT_FN_ATTRS
_mm256_broadcast_i32x2 (__m128i __A)
{
  return (__m256i) __builtin_ia32_broadcasti32x2_256_mask ((__v4si) __A,
                 (__v8si)_mm256_undefined_si256(),
                 (__mmask8) -1);
}

static __inline__ __m256i __DEFAULT_FN_ATTRS
_mm256_mask_broadcast_i32x2 (__m256i __O, __mmask8 __M, __m128i __A)
{
  return (__m256i) __builtin_ia32_broadcasti32x2_256_mask ((__v4si) __A,
                 (__v8si) __O,
                 __M);
}

static __inline__ __m256i __DEFAULT_FN_ATTRS
_mm256_maskz_broadcast_i32x2 (__mmask8 __M, __m128i __A)
{
  return (__m256i) __builtin_ia32_broadcasti32x2_256_mask ((__v4si) __A,
                 (__v8si) _mm256_setzero_si256 (),
                 __M);
}

static __inline__ __m256i __DEFAULT_FN_ATTRS
_mm256_broadcast_i64x2 (__m128i __A)
{
  return (__m256i) __builtin_ia32_broadcasti64x2_256_mask ((__v2di) __A,
                 (__v4di)_mm256_undefined_si256(),
                 (__mmask8) -1);
}

static __inline__ __m256i __DEFAULT_FN_ATTRS
_mm256_mask_broadcast_i64x2 (__m256i __O, __mmask8 __M, __m128i __A)
{
  return (__m256i) __builtin_ia32_broadcasti64x2_256_mask ((__v2di) __A,
                 (__v4di) __O,
                 __M);
}

static __inline__ __m256i __DEFAULT_FN_ATTRS
_mm256_maskz_broadcast_i64x2 (__mmask8 __M, __m128i __A)
{
  return (__m256i) __builtin_ia32_broadcasti64x2_256_mask ((__v2di) __A,
                 (__v4di) _mm256_setzero_si256 (),
                 __M);
}

#define _mm256_extractf64x2_pd(A, imm) __extension__ ({ \
  (__m128d)__builtin_ia32_extractf64x2_256_mask((__v4df)(__m256d)(A), \
                                                (int)(imm), \
                                                (__v2df)_mm_setzero_pd(), \
                                                (__mmask8)-1); })

#define _mm256_mask_extractf64x2_pd(W, U, A, imm) __extension__ ({ \
  (__m128d)__builtin_ia32_extractf64x2_256_mask((__v4df)(__m256d)(A), \
                                                (int)(imm), \
                                                (__v2df)(__m128d)(W), \
                                                (__mmask8)(U)); })

#define _mm256_maskz_extractf64x2_pd(U, A, imm) __extension__ ({ \
  (__m128d)__builtin_ia32_extractf64x2_256_mask((__v4df)(__m256d)(A), \
                                                (int)(imm), \
                                                (__v2df)_mm_setzero_pd(), \
                                                (__mmask8)(U)); })

#define _mm256_extracti64x2_epi64(A, imm) __extension__ ({ \
  (__m128i)__builtin_ia32_extracti64x2_256_mask((__v4di)(__m256i)(A), \
                                                (int)(imm), \
                                                (__v2di)_mm_setzero_di(), \
                                                (__mmask8)-1); })

#define _mm256_mask_extracti64x2_epi64(W, U, A, imm) __extension__ ({ \
  (__m128i)__builtin_ia32_extracti64x2_256_mask((__v4di)(__m256i)(A), \
                                                (int)(imm), \
                                                (__v2di)(__m128i)(W), \
                                                (__mmask8)(U)); })

#define _mm256_maskz_extracti64x2_epi64(U, A, imm) __extension__ ({ \
  (__m128i)__builtin_ia32_extracti64x2_256_mask((__v4di)(__m256i)(A), \
                                                (int)(imm), \
                                                (__v2di)_mm_setzero_di(), \
                                                (__mmask8)(U)); })

#define _mm256_insertf64x2(A, B, imm) __extension__ ({ \
  (__m256d)__builtin_ia32_insertf64x2_256_mask((__v4df)(__m256d)(A), \
                                               (__v2df)(__m128d)(B), \
                                               (int)(imm), \
                                               (__v4df)_mm256_setzero_pd(), \
                                               (__mmask8)-1); })

#define _mm256_mask_insertf64x2(W, U, A, B, imm) __extension__ ({ \
  (__m256d)__builtin_ia32_insertf64x2_256_mask((__v4df)(__m256d)(A), \
                                               (__v2df)(__m128d)(B), \
                                               (int)(imm), \
                                               (__v4df)(__m256d)(W), \
                                               (__mmask8)(U)); })

#define _mm256_maskz_insertf64x2(U, A, B, imm) __extension__ ({ \
  (__m256d)__builtin_ia32_insertf64x2_256_mask((__v4df)(__m256d)(A), \
                                               (__v2df)(__m128d)(B), \
                                               (int)(imm), \
                                               (__v4df)_mm256_setzero_pd(), \
                                               (__mmask8)(U)); })

#define _mm256_inserti64x2(A, B, imm) __extension__ ({ \
  (__m256i)__builtin_ia32_inserti64x2_256_mask((__v4di)(__m256i)(A), \
                                               (__v2di)(__m128i)(B), \
                                               (int)(imm), \
                                               (__v4di)_mm256_setzero_si256(), \
                                               (__mmask8)-1); })

#define _mm256_mask_inserti64x2(W, U, A, B, imm) __extension__ ({ \
  (__m256i)__builtin_ia32_inserti64x2_256_mask((__v4di)(__m256i)(A), \
                                               (__v2di)(__m128i)(B), \
                                               (int)(imm), \
                                               (__v4di)(__m256i)(W), \
                                               (__mmask8)(U)); })

#define _mm256_maskz_inserti64x2(U, A, B, imm) __extension__ ({ \
  (__m256i)__builtin_ia32_inserti64x2_256_mask((__v4di)(__m256i)(A), \
                                               (__v2di)(__m128i)(B), \
                                               (int)(imm), \
                                               (__v4di)_mm256_setzero_si256(), \
                                               (__mmask8)(U)); })

#define _mm_mask_fpclass_pd_mask(U, A, imm) __extension__ ({ \
  (__mmask8)__builtin_ia32_fpclasspd128_mask((__v2df)(__m128d)(A), (int)(imm), \
                                             (__mmask8)(U)); })

#define _mm_fpclass_pd_mask(A, imm) __extension__ ({ \
  (__mmask8)__builtin_ia32_fpclasspd128_mask((__v2df)(__m128d)(A), (int)(imm), \
                                             (__mmask8)-1); })

#define _mm256_mask_fpclass_pd_mask(U, A, imm) __extension__ ({ \
  (__mmask8)__builtin_ia32_fpclasspd256_mask((__v4df)(__m256d)(A), (int)(imm), \
                                             (__mmask8)(U)); })

#define _mm256_fpclass_pd_mask(A, imm) __extension__ ({ \
  (__mmask8)__builtin_ia32_fpclasspd256_mask((__v4df)(__m256d)(A), (int)(imm), \
                                             (__mmask8)-1); })

#define _mm_mask_fpclass_ps_mask(U, A, imm) __extension__ ({ \
  (__mmask8)__builtin_ia32_fpclassps128_mask((__v4sf)(__m128)(A), (int)(imm), \
                                             (__mmask8)(U)); })

#define _mm_fpclass_ps_mask(A, imm) __extension__ ({ \
  (__mmask8)__builtin_ia32_fpclassps128_mask((__v4sf)(__m128)(A), (int)(imm), \
                                             (__mmask8)-1); })

#define _mm256_mask_fpclass_ps_mask(U, A, imm) __extension__ ({ \
  (__mmask8)__builtin_ia32_fpclassps256_mask((__v8sf)(__m256)(A), (int)(imm), \
                                             (__mmask8)(U)); })

#define _mm256_fpclass_ps_mask(A, imm) __extension__ ({ \
  (__mmask8)__builtin_ia32_fpclassps256_mask((__v8sf)(__m256)(A), (int)(imm), \
                                             (__mmask8)-1); })
@


1.1.1.3
log
@Import LLVM 4.0.0 rc1 including clang and lld to help the current
development effort on OpenBSD/arm64.
@
text
@d40 5
a44 4
_mm256_mask_mullo_epi64(__m256i __W, __mmask8 __U, __m256i __A, __m256i __B) {
  return (__m256i)__builtin_ia32_selectq_256((__mmask8)__U,
                                             (__v4di)_mm256_mullo_epi64(__A, __B),
                                             (__v4di)__W);
d48 6
a53 4
_mm256_maskz_mullo_epi64(__mmask8 __U, __m256i __A, __m256i __B) {
  return (__m256i)__builtin_ia32_selectq_256((__mmask8)__U,
                                             (__v4di)_mm256_mullo_epi64(__A, __B),
                                             (__v4di)_mm256_setzero_si256());
d62 5
a66 4
_mm_mask_mullo_epi64(__m128i __W, __mmask8 __U, __m128i __A, __m128i __B) {
  return (__m128i)__builtin_ia32_selectq_128((__mmask8)__U,
                                             (__v2di)_mm_mullo_epi64(__A, __B),
                                             (__v2di)__W);
d70 6
a75 4
_mm_maskz_mullo_epi64(__mmask8 __U, __m128i __A, __m128i __B) {
  return (__m128i)__builtin_ia32_selectq_128((__mmask8)__U,
                                             (__v2di)_mm_mullo_epi64(__A, __B),
                                             (__v2di)_mm_setzero_si128());
d79 5
a83 4
_mm256_mask_andnot_pd(__m256d __W, __mmask8 __U, __m256d __A, __m256d __B) {
  return (__m256d)__builtin_ia32_selectpd_256((__mmask8)__U,
                                              (__v4df)_mm256_andnot_pd(__A, __B),
                                              (__v4df)__W);
d87 6
a92 4
_mm256_maskz_andnot_pd(__mmask8 __U, __m256d __A, __m256d __B) {
  return (__m256d)__builtin_ia32_selectpd_256((__mmask8)__U,
                                              (__v4df)_mm256_andnot_pd(__A, __B),
                                              (__v4df)_mm256_setzero_pd());
d96 5
a100 4
_mm_mask_andnot_pd(__m128d __W, __mmask8 __U, __m128d __A, __m128d __B) {
  return (__m128d)__builtin_ia32_selectpd_128((__mmask8)__U,
                                              (__v2df)_mm_andnot_pd(__A, __B),
                                              (__v2df)__W);
d104 6
a109 4
_mm_maskz_andnot_pd(__mmask8 __U, __m128d __A, __m128d __B) {
  return (__m128d)__builtin_ia32_selectpd_128((__mmask8)__U,
                                              (__v2df)_mm_andnot_pd(__A, __B),
                                              (__v2df)_mm_setzero_pd());
d113 5
a117 4
_mm256_mask_andnot_ps(__m256 __W, __mmask8 __U, __m256 __A, __m256 __B) {
  return (__m256)__builtin_ia32_selectps_256((__mmask8)__U,
                                             (__v8sf)_mm256_andnot_ps(__A, __B),
                                             (__v8sf)__W);
d121 6
a126 4
_mm256_maskz_andnot_ps(__mmask8 __U, __m256 __A, __m256 __B) {
  return (__m256)__builtin_ia32_selectps_256((__mmask8)__U,
                                             (__v8sf)_mm256_andnot_ps(__A, __B),
                                             (__v8sf)_mm256_setzero_ps());
d130 5
a134 4
_mm_mask_andnot_ps(__m128 __W, __mmask8 __U, __m128 __A, __m128 __B) {
  return (__m128)__builtin_ia32_selectps_128((__mmask8)__U,
                                             (__v4sf)_mm_andnot_ps(__A, __B),
                                             (__v4sf)__W);
d138 6
a143 4
_mm_maskz_andnot_ps(__mmask8 __U, __m128 __A, __m128 __B) {
  return (__m128)__builtin_ia32_selectps_128((__mmask8)__U,
                                             (__v4sf)_mm_andnot_ps(__A, __B),
                                             (__v4sf)_mm_setzero_ps());
d147 5
a151 4
_mm256_mask_and_pd(__m256d __W, __mmask8 __U, __m256d __A, __m256d __B) {
  return (__m256d)__builtin_ia32_selectpd_256((__mmask8)__U,
                                              (__v4df)_mm256_and_pd(__A, __B),
                                              (__v4df)__W);
d155 6
a160 4
_mm256_maskz_and_pd(__mmask8 __U, __m256d __A, __m256d __B) {
  return (__m256d)__builtin_ia32_selectpd_256((__mmask8)__U,
                                              (__v4df)_mm256_and_pd(__A, __B),
                                              (__v4df)_mm256_setzero_pd());
d164 5
a168 4
_mm_mask_and_pd(__m128d __W, __mmask8 __U, __m128d __A, __m128d __B) {
  return (__m128d)__builtin_ia32_selectpd_128((__mmask8)__U,
                                              (__v2df)_mm_and_pd(__A, __B),
                                              (__v2df)__W);
d172 6
a177 4
_mm_maskz_and_pd(__mmask8 __U, __m128d __A, __m128d __B) {
  return (__m128d)__builtin_ia32_selectpd_128((__mmask8)__U,
                                              (__v2df)_mm_and_pd(__A, __B),
                                              (__v2df)_mm_setzero_pd());
d181 5
a185 4
_mm256_mask_and_ps(__m256 __W, __mmask8 __U, __m256 __A, __m256 __B) {
  return (__m256)__builtin_ia32_selectps_256((__mmask8)__U,
                                             (__v8sf)_mm256_and_ps(__A, __B),
                                             (__v8sf)__W);
d189 6
a194 4
_mm256_maskz_and_ps(__mmask8 __U, __m256 __A, __m256 __B) {
  return (__m256)__builtin_ia32_selectps_256((__mmask8)__U,
                                             (__v8sf)_mm256_and_ps(__A, __B),
                                             (__v8sf)_mm256_setzero_ps());
d198 5
a202 4
_mm_mask_and_ps(__m128 __W, __mmask8 __U, __m128 __A, __m128 __B) {
  return (__m128)__builtin_ia32_selectps_128((__mmask8)__U,
                                             (__v4sf)_mm_and_ps(__A, __B),
                                             (__v4sf)__W);
d206 6
a211 4
_mm_maskz_and_ps(__mmask8 __U, __m128 __A, __m128 __B) {
  return (__m128)__builtin_ia32_selectps_128((__mmask8)__U,
                                             (__v4sf)_mm_and_ps(__A, __B),
                                             (__v4sf)_mm_setzero_ps());
d215 6
a220 4
_mm256_mask_xor_pd(__m256d __W, __mmask8 __U, __m256d __A, __m256d __B) {
  return (__m256d)__builtin_ia32_selectpd_256((__mmask8)__U,
                                              (__v4df)_mm256_xor_pd(__A, __B),
                                              (__v4df)__W);
d224 6
a229 4
_mm256_maskz_xor_pd(__mmask8 __U, __m256d __A, __m256d __B) {
  return (__m256d)__builtin_ia32_selectpd_256((__mmask8)__U,
                                              (__v4df)_mm256_xor_pd(__A, __B),
                                              (__v4df)_mm256_setzero_pd());
d233 5
a237 4
_mm_mask_xor_pd(__m128d __W, __mmask8 __U, __m128d __A, __m128d __B) {
  return (__m128d)__builtin_ia32_selectpd_128((__mmask8)__U,
                                              (__v2df)_mm_xor_pd(__A, __B),
                                              (__v2df)__W);
d242 5
a246 3
  return (__m128d)__builtin_ia32_selectpd_128((__mmask8)__U,
                                              (__v2df)_mm_xor_pd(__A, __B),
                                              (__v2df)_mm_setzero_pd());
d250 5
a254 4
_mm256_mask_xor_ps(__m256 __W, __mmask8 __U, __m256 __A, __m256 __B) {
  return (__m256)__builtin_ia32_selectps_256((__mmask8)__U,
                                             (__v8sf)_mm256_xor_ps(__A, __B),
                                             (__v8sf)__W);
d258 6
a263 4
_mm256_maskz_xor_ps(__mmask8 __U, __m256 __A, __m256 __B) {
  return (__m256)__builtin_ia32_selectps_256((__mmask8)__U,
                                             (__v8sf)_mm256_xor_ps(__A, __B),
                                             (__v8sf)_mm256_setzero_ps());
d267 5
a271 4
_mm_mask_xor_ps(__m128 __W, __mmask8 __U, __m128 __A, __m128 __B) {
  return (__m128)__builtin_ia32_selectps_128((__mmask8)__U,
                                             (__v4sf)_mm_xor_ps(__A, __B),
                                             (__v4sf)__W);
d275 6
a280 4
_mm_maskz_xor_ps(__mmask8 __U, __m128 __A, __m128 __B) {
  return (__m128)__builtin_ia32_selectps_128((__mmask8)__U,
                                             (__v4sf)_mm_xor_ps(__A, __B),
                                             (__v4sf)_mm_setzero_ps());
d284 5
a288 4
_mm256_mask_or_pd(__m256d __W, __mmask8 __U, __m256d __A, __m256d __B) {
  return (__m256d)__builtin_ia32_selectpd_256((__mmask8)__U,
                                              (__v4df)_mm256_or_pd(__A, __B),
                                              (__v4df)__W);
d292 6
a297 4
_mm256_maskz_or_pd(__mmask8 __U, __m256d __A, __m256d __B) {
  return (__m256d)__builtin_ia32_selectpd_256((__mmask8)__U,
                                              (__v4df)_mm256_or_pd(__A, __B),
                                              (__v4df)_mm256_setzero_pd());
d301 5
a305 4
_mm_mask_or_pd(__m128d __W, __mmask8 __U, __m128d __A, __m128d __B) {
  return (__m128d)__builtin_ia32_selectpd_128((__mmask8)__U,
                                              (__v2df)_mm_or_pd(__A, __B),
                                              (__v2df)__W);
d309 6
a314 4
_mm_maskz_or_pd(__mmask8 __U, __m128d __A, __m128d __B) {
  return (__m128d)__builtin_ia32_selectpd_128((__mmask8)__U,
                                              (__v2df)_mm_or_pd(__A, __B),
                                              (__v2df)_mm_setzero_pd());
d318 5
a322 4
_mm256_mask_or_ps(__m256 __W, __mmask8 __U, __m256 __A, __m256 __B) {
  return (__m256)__builtin_ia32_selectps_256((__mmask8)__U,
                                             (__v8sf)_mm256_or_ps(__A, __B),
                                             (__v8sf)__W);
d326 6
a331 4
_mm256_maskz_or_ps(__mmask8 __U, __m256 __A, __m256 __B) {
  return (__m256)__builtin_ia32_selectps_256((__mmask8)__U,
                                             (__v8sf)_mm256_or_ps(__A, __B),
                                             (__v8sf)_mm256_setzero_ps());
d335 5
a339 4
_mm_mask_or_ps(__m128 __W, __mmask8 __U, __m128 __A, __m128 __B) {
  return (__m128)__builtin_ia32_selectps_128((__mmask8)__U,
                                             (__v4sf)_mm_or_ps(__A, __B),
                                             (__v4sf)__W);
d343 6
a348 4
_mm_maskz_or_ps(__mmask8 __U, __m128 __A, __m128 __B) {
  return (__m128)__builtin_ia32_selectps_128((__mmask8)__U,
                                             (__v4sf)_mm_or_ps(__A, __B),
                                             (__v4sf)_mm_setzero_ps());
d1154 4
a1157 4
  (__m128d)__builtin_shufflevector((__v4df)(__m256d)(A),           \
                                   (__v4df)_mm256_undefined_pd(), \
                                   ((imm) & 1) ? 2 : 0,           \
                                   ((imm) & 1) ? 3 : 1); })
d1160 4
a1163 3
  (__m128d)__builtin_ia32_selectpd_128((__mmask8)(U), \
                                   (__v2df)_mm256_extractf64x2_pd((A), (imm)), \
                                   (__v2df)(W)); })
d1166 4
a1169 3
  (__m128d)__builtin_ia32_selectpd_128((__mmask8)(U), \
                                   (__v2df)_mm256_extractf64x2_pd((A), (imm)), \
                                   (__v2df)_mm_setzero_pd()); })
d1172 4
a1175 4
  (__m128i)__builtin_shufflevector((__v4di)(__m256i)(A),             \
                                   (__v4di)_mm256_undefined_si256(), \
                                   ((imm) & 1) ? 2 : 0,              \
                                   ((imm) & 1) ? 3 : 1); })
d1178 4
a1181 3
  (__m128i)__builtin_ia32_selectq_128((__mmask8)(U), \
                                (__v2di)_mm256_extracti64x2_epi64((A), (imm)), \
                                (__v2di)(W)); })
d1184 4
a1187 3
  (__m128i)__builtin_ia32_selectq_128((__mmask8)(U), \
                                (__v2di)_mm256_extracti64x2_epi64((A), (imm)), \
                                (__v2di)_mm_setzero_di()); })
d1190 5
a1194 6
  (__m256d)__builtin_shufflevector((__v4df)(A), \
                                 (__v4df)_mm256_castpd128_pd256((__m128d)(B)), \
                                 ((imm) & 0x1) ? 0 : 4, \
                                 ((imm) & 0x1) ? 1 : 5, \
                                 ((imm) & 0x1) ? 4 : 2, \
                                 ((imm) & 0x1) ? 5 : 3); })
d1197 5
a1201 3
  (__m256d)__builtin_ia32_selectpd_256((__mmask8)(U), \
                                  (__v4df)_mm256_insertf64x2((A), (B), (imm)), \
                                  (__v4df)(W)); })
d1204 5
a1208 3
  (__m256d)__builtin_ia32_selectpd_256((__mmask8)(U), \
                                  (__v4df)_mm256_insertf64x2((A), (B), (imm)), \
                                  (__v4df)_mm256_setzero_pd()); })
d1211 5
a1215 6
  (__m256i)__builtin_shufflevector((__v4di)(A), \
                                 (__v4di)_mm256_castsi128_si256((__m128i)(B)), \
                                 ((imm) & 0x1) ? 0 : 4, \
                                 ((imm) & 0x1) ? 1 : 5, \
                                 ((imm) & 0x1) ? 4 : 2, \
                                 ((imm) & 0x1) ? 5 : 3); })
d1218 5
a1222 3
  (__m256i)__builtin_ia32_selectq_256((__mmask8)(U), \
                                  (__v4di)_mm256_inserti64x2((A), (B), (imm)), \
                                  (__v4di)(W)); })
d1225 5
a1229 3
  (__m256i)__builtin_ia32_selectq_256((__mmask8)(U), \
                                  (__v4di)_mm256_inserti64x2((A), (B), (imm)), \
                                  (__v4di)_mm256_setzero_si256()); })
@


