head	1.1;
branch	1.1.1;
access;
symbols
	LLVM_5_0_0:1.1.1.4
	OPENBSD_6_2:1.1.1.3.0.2
	OPENBSD_6_2_BASE:1.1.1.3
	OPENBSD_6_1:1.1.1.3.0.4
	OPENBSD_6_1_BASE:1.1.1.3
	LLVM_4_0_0:1.1.1.3
	LLVM_4_0_0_RC1:1.1.1.3
	LLVM_3_9_1:1.1.1.2
	LLVM_3_8_1:1.1.1.1
	LLVM:1.1.1;
locks; strict;
comment	@ * @;


1.1
date	2016.09.03.22.47.01;	author pascal;	state Exp;
branches
	1.1.1.1;
next	;
commitid	piLU3CHugy63NlaI;

1.1.1.1
date	2016.09.03.22.47.01;	author pascal;	state Exp;
branches;
next	1.1.1.2;
commitid	piLU3CHugy63NlaI;

1.1.1.2
date	2017.01.14.19.56.07;	author patrick;	state Exp;
branches;
next	1.1.1.3;
commitid	qMUxATnKgqN83Oct;

1.1.1.3
date	2017.01.24.08.33.27;	author patrick;	state Exp;
branches;
next	1.1.1.4;
commitid	so2WA7LCP6wbxtYl;

1.1.1.4
date	2017.10.04.20.28.01;	author patrick;	state Exp;
branches;
next	;
commitid	ufzi3t8MqoilCPqO;


desc
@@


1.1
log
@Initial revision
@
text
@//===-- ARMTargetTransformInfo.h - ARM specific TTI -------------*- C++ -*-===//
//
//                     The LLVM Compiler Infrastructure
//
// This file is distributed under the University of Illinois Open Source
// License. See LICENSE.TXT for details.
//
//===----------------------------------------------------------------------===//
/// \file
/// This file a TargetTransformInfo::Concept conforming object specific to the
/// ARM target machine. It uses the target's detailed information to
/// provide more precise answers to certain TTI queries, while letting the
/// target independent and default TTI implementations handle the rest.
///
//===----------------------------------------------------------------------===//

#ifndef LLVM_LIB_TARGET_ARM_ARMTARGETTRANSFORMINFO_H
#define LLVM_LIB_TARGET_ARM_ARMTARGETTRANSFORMINFO_H

#include "ARM.h"
#include "ARMTargetMachine.h"
#include "llvm/Analysis/TargetTransformInfo.h"
#include "llvm/CodeGen/BasicTTIImpl.h"
#include "llvm/Target/TargetLowering.h"

namespace llvm {

class ARMTTIImpl : public BasicTTIImplBase<ARMTTIImpl> {
  typedef BasicTTIImplBase<ARMTTIImpl> BaseT;
  typedef TargetTransformInfo TTI;
  friend BaseT;

  const ARMSubtarget *ST;
  const ARMTargetLowering *TLI;

  /// Estimate the overhead of scalarizing an instruction. Insert and Extract
  /// are set if the result needs to be inserted and/or extracted from vectors.
  unsigned getScalarizationOverhead(Type *Ty, bool Insert, bool Extract);

  const ARMSubtarget *getST() const { return ST; }
  const ARMTargetLowering *getTLI() const { return TLI; }

public:
  explicit ARMTTIImpl(const ARMBaseTargetMachine *TM, const Function &F)
      : BaseT(TM, F.getParent()->getDataLayout()), ST(TM->getSubtargetImpl(F)),
        TLI(ST->getTargetLowering()) {}

  // Provide value semantics. MSVC requires that we spell all of these out.
  ARMTTIImpl(const ARMTTIImpl &Arg)
      : BaseT(static_cast<const BaseT &>(Arg)), ST(Arg.ST), TLI(Arg.TLI) {}
  ARMTTIImpl(ARMTTIImpl &&Arg)
      : BaseT(std::move(static_cast<BaseT &>(Arg))), ST(std::move(Arg.ST)),
        TLI(std::move(Arg.TLI)) {}

  bool enableInterleavedAccessVectorization() { return true; }

  /// \name Scalar TTI Implementations
  /// @@{

  using BaseT::getIntImmCost;
  int getIntImmCost(const APInt &Imm, Type *Ty);

  /// @@}

  /// \name Vector TTI Implementations
  /// @@{

  unsigned getNumberOfRegisters(bool Vector) {
    if (Vector) {
      if (ST->hasNEON())
        return 16;
      return 0;
    }

    if (ST->isThumb1Only())
      return 8;
    return 13;
  }

  unsigned getRegisterBitWidth(bool Vector) {
    if (Vector) {
      if (ST->hasNEON())
        return 128;
      return 0;
    }

    return 32;
  }

  unsigned getMaxInterleaveFactor(unsigned VF) {
    // These are out of order CPUs:
    if (ST->isCortexA15() || ST->isSwift())
      return 2;
    return 1;
  }

  int getShuffleCost(TTI::ShuffleKind Kind, Type *Tp, int Index, Type *SubTp);

  int getCastInstrCost(unsigned Opcode, Type *Dst, Type *Src);

  int getCmpSelInstrCost(unsigned Opcode, Type *ValTy, Type *CondTy);

  int getVectorInstrCost(unsigned Opcode, Type *Val, unsigned Index);

  int getAddressComputationCost(Type *Val, bool IsComplex);

  int getFPOpCost(Type *Ty);

  int getArithmeticInstrCost(
      unsigned Opcode, Type *Ty,
      TTI::OperandValueKind Op1Info = TTI::OK_AnyValue,
      TTI::OperandValueKind Op2Info = TTI::OK_AnyValue,
      TTI::OperandValueProperties Opd1PropInfo = TTI::OP_None,
      TTI::OperandValueProperties Opd2PropInfo = TTI::OP_None);

  int getMemoryOpCost(unsigned Opcode, Type *Src, unsigned Alignment,
                      unsigned AddressSpace);

  int getInterleavedMemoryOpCost(unsigned Opcode, Type *VecTy, unsigned Factor,
                                 ArrayRef<unsigned> Indices, unsigned Alignment,
                                 unsigned AddressSpace);
  /// @@}
};

} // end namespace llvm

#endif
@


1.1.1.1
log
@Use the space freed up by sparc and zaurus to import LLVM.

ok hackroom@@
@
text
@@


1.1.1.2
log
@Import LLVM 3.9.1 including clang and lld.
@
text
@a56 7
  /// Floating-point computation using ARMv8 AArch32 Advanced
  /// SIMD instructions remains unchanged from ARMv7. Only AArch64 SIMD
  /// is IEEE-754 compliant, but it's not covered in this target.
  bool isFPVectorizationPotentiallyUnsafe() {
    return !ST->isTargetDarwin();
  }

a59 3
  int getIntImmCodeSizeCost(unsigned Opcode, unsigned Idx, const APInt &Imm,
                            Type *Ty);

a62 2
  int getIntImmCost(unsigned Opcode, unsigned Idx, const APInt &Imm, Type *Ty);

d91 4
a94 1
    return ST->getMaxInterleaveFactor();
@


1.1.1.3
log
@Import LLVM 4.0.0 rc1 including clang and lld to help the current
development effort on OpenBSD/arm64.
@
text
@d48 7
d114 1
a114 2
  int getAddressComputationCost(Type *Val, ScalarEvolution *SE, 
                                const SCEV *Ptr);
d123 1
a123 2
      TTI::OperandValueProperties Opd2PropInfo = TTI::OP_None,
      ArrayRef<const Value *> Args = ArrayRef<const Value *>());
a130 10

  bool shouldBuildLookupTablesForConstant(Constant *C) const {
    // In the ROPI and RWPI relocation models we can't have pointers to global
    // variables or functions in constant data, so don't convert switches to
    // lookup tables if any of the values would need relocation.
    if (ST->isROPI() || ST->isRWPI())
      return !C->needsRelocation();

    return true;
  }
@


1.1.1.4
log
@Import LLVM 5.0.0 release including clang, lld and lldb.
@
text
@d36 3
a38 32
  // Currently the following features are excluded from InlineFeatureWhitelist.
  // ModeThumb, FeatureNoARM, ModeSoftFloat, FeatureVFPOnlySP, FeatureD16
  // Depending on whether they are set or unset, different
  // instructions/registers are available. For example, inlining a callee with
  // -thumb-mode in a caller with +thumb-mode, may cause the assembler to
  // fail if the callee uses ARM only instructions, e.g. in inline asm.
  const FeatureBitset InlineFeatureWhitelist = {
      ARM::FeatureVFP2, ARM::FeatureVFP3, ARM::FeatureNEON, ARM::FeatureThumb2,
      ARM::FeatureFP16, ARM::FeatureVFP4, ARM::FeatureFPARMv8,
      ARM::FeatureFullFP16, ARM::FeatureHWDivThumb,
      ARM::FeatureHWDivARM, ARM::FeatureDB, ARM::FeatureV7Clrex,
      ARM::FeatureAcquireRelease, ARM::FeatureSlowFPBrcc,
      ARM::FeaturePerfMon, ARM::FeatureTrustZone, ARM::Feature8MSecExt,
      ARM::FeatureCrypto, ARM::FeatureCRC, ARM::FeatureRAS,
      ARM::FeatureFPAO, ARM::FeatureFuseAES, ARM::FeatureZCZeroing,
      ARM::FeatureProfUnpredicate, ARM::FeatureSlowVGETLNi32,
      ARM::FeatureSlowVDUP32, ARM::FeaturePreferVMOVSR,
      ARM::FeaturePrefISHSTBarrier, ARM::FeatureMuxedUnits,
      ARM::FeatureSlowOddRegister, ARM::FeatureSlowLoadDSubreg,
      ARM::FeatureDontWidenVMOVS, ARM::FeatureExpandMLx,
      ARM::FeatureHasVMLxHazards, ARM::FeatureNEONForFPMovs,
      ARM::FeatureNEONForFP, ARM::FeatureCheckVLDnAlign,
      ARM::FeatureHasSlowFPVMLx, ARM::FeatureVMLxForwarding,
      ARM::FeaturePref32BitThumb, ARM::FeatureAvoidPartialCPSR,
      ARM::FeatureCheapPredicableCPSR, ARM::FeatureAvoidMOVsShOp,
      ARM::FeatureHasRetAddrStack, ARM::FeatureHasNoBranchPredictor,
      ARM::FeatureDSP, ARM::FeatureMP, ARM::FeatureVirtualization,
      ARM::FeatureMClass, ARM::FeatureRClass, ARM::FeatureAClass,
      ARM::FeatureNaClTrap, ARM::FeatureStrictAlign, ARM::FeatureLongCalls,
      ARM::FeatureExecuteOnly, ARM::FeatureReserveR9, ARM::FeatureNoMovt,
      ARM::FeatureNoNegativeImmediates
  };
a47 3
  bool areInlineCompatible(const Function *Caller,
                           const Function *Callee) const;

d85 1
a85 1
  unsigned getRegisterBitWidth(bool Vector) const {
d101 1
a101 2
  int getCastInstrCost(unsigned Opcode, Type *Dst, Type *Src,
                       const Instruction *I = nullptr);
d103 1
a103 2
  int getCmpSelInstrCost(unsigned Opcode, Type *ValTy, Type *CondTy,
                         const Instruction *I = nullptr);
d121 1
a121 1
                      unsigned AddressSpace, const Instruction *I = nullptr);
@


