head	1.1;
branch	1.1.1;
access;
symbols
	LLVM_5_0_0:1.1.1.4
	OPENBSD_6_2:1.1.1.3.0.2
	OPENBSD_6_2_BASE:1.1.1.3
	OPENBSD_6_1:1.1.1.3.0.4
	OPENBSD_6_1_BASE:1.1.1.3
	LLVM_4_0_0:1.1.1.3
	LLVM_4_0_0_RC1:1.1.1.3
	LLVM_3_9_1:1.1.1.2
	LLVM_3_8_1:1.1.1.1
	LLVM:1.1.1;
locks; strict;
comment	@ * @;


1.1
date	2016.09.03.22.47.00;	author pascal;	state Exp;
branches
	1.1.1.1;
next	;
commitid	piLU3CHugy63NlaI;

1.1.1.1
date	2016.09.03.22.47.00;	author pascal;	state Exp;
branches;
next	1.1.1.2;
commitid	piLU3CHugy63NlaI;

1.1.1.2
date	2017.01.14.19.56.05;	author patrick;	state Exp;
branches;
next	1.1.1.3;
commitid	qMUxATnKgqN83Oct;

1.1.1.3
date	2017.01.24.08.33.33;	author patrick;	state Exp;
branches;
next	1.1.1.4;
commitid	so2WA7LCP6wbxtYl;

1.1.1.4
date	2017.10.04.20.28.07;	author patrick;	state Exp;
branches;
next	;
commitid	ufzi3t8MqoilCPqO;


desc
@@


1.1
log
@Initial revision
@
text
@//===-- AMDGPUBaseInfo.h - Top level definitions for AMDGPU -----*- C++ -*-===//
//
//                     The LLVM Compiler Infrastructure
//
// This file is distributed under the University of Illinois Open Source
// License. See LICENSE.TXT for details.
//
//===----------------------------------------------------------------------===//

#ifndef LLVM_LIB_TARGET_AMDGPU_UTILS_AMDGPUBASEINFO_H
#define LLVM_LIB_TARGET_AMDGPU_UTILS_AMDGPUBASEINFO_H

#include "AMDKernelCodeT.h"

namespace llvm {

class FeatureBitset;
class Function;
class GlobalValue;
class MCContext;
class MCSection;
class MCSubtargetInfo;

namespace AMDGPU {

struct IsaVersion {
  unsigned Major;
  unsigned Minor;
  unsigned Stepping;
};

IsaVersion getIsaVersion(const FeatureBitset &Features);
void initDefaultAMDKernelCodeT(amd_kernel_code_t &Header,
                               const FeatureBitset &Features);
MCSection *getHSATextSection(MCContext &Ctx);

MCSection *getHSADataGlobalAgentSection(MCContext &Ctx);

MCSection *getHSADataGlobalProgramSection(MCContext &Ctx);

MCSection *getHSARodataReadonlyAgentSection(MCContext &Ctx);

bool isGroupSegment(const GlobalValue *GV);
bool isGlobalSegment(const GlobalValue *GV);
bool isReadOnlySegment(const GlobalValue *GV);

unsigned getShaderType(const Function &F);
unsigned getInitialPSInputAddr(const Function &F);


bool isSI(const MCSubtargetInfo &STI);
bool isCI(const MCSubtargetInfo &STI);
bool isVI(const MCSubtargetInfo &STI);

/// If \p Reg is a pseudo reg, return the correct hardware register given
/// \p STI otherwise return \p Reg.
unsigned getMCReg(unsigned Reg, const MCSubtargetInfo &STI);

} // end namespace AMDGPU
} // end namespace llvm

#endif
@


1.1.1.1
log
@Use the space freed up by sparc and zaurus to import LLVM.

ok hackroom@@
@
text
@@


1.1.1.2
log
@Import LLVM 3.9.1 including clang and lld.
@
text
@a13 1
#include "llvm/IR/CallingConv.h"
d47 1
a47 3
int getIntegerAttribute(const Function &F, StringRef Name, int Default);

unsigned getMaximumWorkGroupSize(const Function &F);
a49 2
bool isShader(CallingConv::ID cc);
bool isCompute(CallingConv::ID cc);
@


1.1.1.3
log
@Import LLVM 4.0.0 rc1 including clang and lld to help the current
development effort on OpenBSD/arm64.
@
text
@a15 6
#include "SIDefines.h"

#define GET_INSTRINFO_OPERAND_ENUM
#include "AMDGPUGenInstrInfo.inc"
#undef GET_INSTRINFO_OPERAND_ENUM

a21 3
class MCInstrDesc;
class MCRegisterClass;
class MCRegisterInfo;
a26 3
LLVM_READONLY
int16_t getNamedOperandIdx(uint16_t Opcode, uint16_t NamedIdx);

a47 10
/// \returns True if constants should be emitted to .text section for given
/// target triple \p TT, false otherwise.
bool shouldEmitConstantsToTextSection(const Triple &TT);

/// \returns Integer value requested using \p F's \p Name attribute.
///
/// \returns \p Default if attribute is not present.
///
/// \returns \p Default and emits error if requested value cannot be converted
/// to integer.
d50 1
a50 68
/// \returns A pair of integer values requested using \p F's \p Name attribute
/// in "first[,second]" format ("second" is optional unless \p OnlyFirstRequired
/// is false).
///
/// \returns \p Default if attribute is not present.
///
/// \returns \p Default and emits error if one of the requested values cannot be
/// converted to integer, or \p OnlyFirstRequired is false and "second" value is
/// not present.
std::pair<int, int> getIntegerPairAttribute(const Function &F,
                                            StringRef Name,
                                            std::pair<int, int> Default,
                                            bool OnlyFirstRequired = false);

/// \returns Waitcnt bit mask for given isa \p Version.
unsigned getWaitcntBitMask(IsaVersion Version);

/// \returns Vmcnt bit mask for given isa \p Version.
unsigned getVmcntBitMask(IsaVersion Version);

/// \returns Expcnt bit mask for given isa \p Version.
unsigned getExpcntBitMask(IsaVersion Version);

/// \returns Lgkmcnt bit mask for given isa \p Version.
unsigned getLgkmcntBitMask(IsaVersion Version);

/// \returns Decoded Vmcnt from given \p Waitcnt for given isa \p Version.
unsigned decodeVmcnt(IsaVersion Version, unsigned Waitcnt);

/// \returns Decoded Expcnt from given \p Waitcnt for given isa \p Version.
unsigned decodeExpcnt(IsaVersion Version, unsigned Waitcnt);

/// \returns Decoded Lgkmcnt from given \p Waitcnt for given isa \p Version.
unsigned decodeLgkmcnt(IsaVersion Version, unsigned Waitcnt);

/// \brief Decodes Vmcnt, Expcnt and Lgkmcnt from given \p Waitcnt for given isa
/// \p Version, and writes decoded values into \p Vmcnt, \p Expcnt and
/// \p Lgkmcnt respectively.
///
/// \details \p Vmcnt, \p Expcnt and \p Lgkmcnt are decoded as follows:
///     \p Vmcnt = \p Waitcnt[3:0]
///     \p Expcnt = \p Waitcnt[6:4]
///     \p Lgkmcnt = \p Waitcnt[11:8]
void decodeWaitcnt(IsaVersion Version, unsigned Waitcnt,
                   unsigned &Vmcnt, unsigned &Expcnt, unsigned &Lgkmcnt);

/// \returns \p Waitcnt with encoded \p Vmcnt for given isa \p Version.
unsigned encodeVmcnt(IsaVersion Version, unsigned Waitcnt, unsigned Vmcnt);

/// \returns \p Waitcnt with encoded \p Expcnt for given isa \p Version.
unsigned encodeExpcnt(IsaVersion Version, unsigned Waitcnt, unsigned Expcnt);

/// \returns \p Waitcnt with encoded \p Lgkmcnt for given isa \p Version.
unsigned encodeLgkmcnt(IsaVersion Version, unsigned Waitcnt, unsigned Lgkmcnt);

/// \brief Encodes \p Vmcnt, \p Expcnt and \p Lgkmcnt into Waitcnt for given isa
/// \p Version.
///
/// \details \p Vmcnt, \p Expcnt and \p Lgkmcnt are encoded as follows:
///     Waitcnt[3:0]  = \p Vmcnt
///     Waitcnt[6:4]  = \p Expcnt
///     Waitcnt[11:8] = \p Lgkmcnt
///
/// \returns Waitcnt with encoded \p Vmcnt, \p Expcnt and \p Lgkmcnt for given
/// isa \p Version.
unsigned encodeWaitcnt(IsaVersion Version,
                       unsigned Vmcnt, unsigned Expcnt, unsigned Lgkmcnt);

a62 60

/// \brief Can this operand also contain immediate values?
bool isSISrcOperand(const MCInstrDesc &Desc, unsigned OpNo);

/// \brief Is this floating-point operand?
bool isSISrcFPOperand(const MCInstrDesc &Desc, unsigned OpNo);

/// \brief Does this opearnd support only inlinable literals?
bool isSISrcInlinableOperand(const MCInstrDesc &Desc, unsigned OpNo);

/// \brief Get the size in bits of a register from the register class \p RC.
unsigned getRegBitWidth(unsigned RCID);

/// \brief Get the size in bits of a register from the register class \p RC.
unsigned getRegBitWidth(const MCRegisterClass &RC);

/// \brief Get size of register operand
unsigned getRegOperandSize(const MCRegisterInfo *MRI, const MCInstrDesc &Desc,
                           unsigned OpNo);

LLVM_READNONE
inline unsigned getOperandSize(const MCOperandInfo &OpInfo) {
  switch (OpInfo.OperandType) {
  case AMDGPU::OPERAND_REG_IMM_INT32:
  case AMDGPU::OPERAND_REG_IMM_FP32:
  case AMDGPU::OPERAND_REG_INLINE_C_INT32:
  case AMDGPU::OPERAND_REG_INLINE_C_FP32:
    return 4;

  case AMDGPU::OPERAND_REG_IMM_INT64:
  case AMDGPU::OPERAND_REG_IMM_FP64:
  case AMDGPU::OPERAND_REG_INLINE_C_INT64:
  case AMDGPU::OPERAND_REG_INLINE_C_FP64:
    return 8;

  case AMDGPU::OPERAND_REG_IMM_INT16:
  case AMDGPU::OPERAND_REG_IMM_FP16:
  case AMDGPU::OPERAND_REG_INLINE_C_INT16:
  case AMDGPU::OPERAND_REG_INLINE_C_FP16:
    return 2;

  default:
    llvm_unreachable("unhandled operand type");
  }
}

LLVM_READNONE
inline unsigned getOperandSize(const MCInstrDesc &Desc, unsigned OpNo) {
  return getOperandSize(Desc.OpInfo[OpNo]);
}

/// \brief Is this literal inlinable
LLVM_READNONE
bool isInlinableLiteral64(int64_t Literal, bool HasInv2Pi);

LLVM_READNONE
bool isInlinableLiteral32(int32_t Literal, bool HasInv2Pi);

LLVM_READNONE
bool isInlinableLiteral16(int16_t Literal, bool HasInv2Pi);
@


1.1.1.4
log
@Import LLVM 5.0.0 release including clang, lld and lldb.
@
text
@d1 1
a1 1
//===- AMDGPUBaseInfo.h - Top level definitions for AMDGPU ------*- C++ -*-===//
a12 1
#include "AMDGPU.h"
d14 2
d17 4
a20 7
#include "llvm/ADT/StringRef.h"
#include "llvm/IR/CallingConv.h"
#include "llvm/MC/MCInstrDesc.h"
#include "llvm/Support/Compiler.h"
#include "llvm/Support/ErrorHandling.h"
#include <cstdint>
#include <utility>
a26 1
class MachineMemOperand;
d28 1
a32 1
class Triple;
a34 1
namespace IsaInfo {
d36 2
a37 5
enum {
  // The closed Vulkan driver sets 96, which limits the wave count to 8 but
  // doesn't spill SGPRs as much as when 80 is set.
  FIXED_NUM_SGPRS_FOR_INIT_BUG = 96
};
a38 1
/// \brief Instruction set architecture version.
a44 1
/// \returns Isa version for given subtarget \p Features.
d46 3
d50 1
a50 80
/// \returns Wavefront size for given subtarget \p Features.
unsigned getWavefrontSize(const FeatureBitset &Features);

/// \returns Local memory size in bytes for given subtarget \p Features.
unsigned getLocalMemorySize(const FeatureBitset &Features);

/// \returns Number of execution units per compute unit for given subtarget \p
/// Features.
unsigned getEUsPerCU(const FeatureBitset &Features);

/// \returns Maximum number of work groups per compute unit for given subtarget
/// \p Features and limited by given \p FlatWorkGroupSize.
unsigned getMaxWorkGroupsPerCU(const FeatureBitset &Features,
                               unsigned FlatWorkGroupSize);

/// \returns Maximum number of waves per compute unit for given subtarget \p
/// Features without any kind of limitation.
unsigned getMaxWavesPerCU(const FeatureBitset &Features);

/// \returns Maximum number of waves per compute unit for given subtarget \p
/// Features and limited by given \p FlatWorkGroupSize.
unsigned getMaxWavesPerCU(const FeatureBitset &Features,
                          unsigned FlatWorkGroupSize);

/// \returns Minimum number of waves per execution unit for given subtarget \p
/// Features.
unsigned getMinWavesPerEU(const FeatureBitset &Features);

/// \returns Maximum number of waves per execution unit for given subtarget \p
/// Features without any kind of limitation.
unsigned getMaxWavesPerEU(const FeatureBitset &Features);

/// \returns Maximum number of waves per execution unit for given subtarget \p
/// Features and limited by given \p FlatWorkGroupSize.
unsigned getMaxWavesPerEU(const FeatureBitset &Features,
                          unsigned FlatWorkGroupSize);

/// \returns Minimum flat work group size for given subtarget \p Features.
unsigned getMinFlatWorkGroupSize(const FeatureBitset &Features);

/// \returns Maximum flat work group size for given subtarget \p Features.
unsigned getMaxFlatWorkGroupSize(const FeatureBitset &Features);

/// \returns Number of waves per work group for given subtarget \p Features and
/// limited by given \p FlatWorkGroupSize.
unsigned getWavesPerWorkGroup(const FeatureBitset &Features,
                              unsigned FlatWorkGroupSize);

/// \returns SGPR allocation granularity for given subtarget \p Features.
unsigned getSGPRAllocGranule(const FeatureBitset &Features);

/// \returns SGPR encoding granularity for given subtarget \p Features.
unsigned getSGPREncodingGranule(const FeatureBitset &Features);

/// \returns Total number of SGPRs for given subtarget \p Features.
unsigned getTotalNumSGPRs(const FeatureBitset &Features);

/// \returns Addressable number of SGPRs for given subtarget \p Features.
unsigned getAddressableNumSGPRs(const FeatureBitset &Features);

/// \returns Minimum number of SGPRs that meets the given number of waves per
/// execution unit requirement for given subtarget \p Features.
unsigned getMinNumSGPRs(const FeatureBitset &Features, unsigned WavesPerEU);

/// \returns Maximum number of SGPRs that meets the given number of waves per
/// execution unit requirement for given subtarget \p Features.
unsigned getMaxNumSGPRs(const FeatureBitset &Features, unsigned WavesPerEU,
                        bool Addressable);

/// \returns VGPR allocation granularity for given subtarget \p Features.
unsigned getVGPRAllocGranule(const FeatureBitset &Features);

/// \returns VGPR encoding granularity for given subtarget \p Features.
unsigned getVGPREncodingGranule(const FeatureBitset &Features);

/// \returns Total number of VGPRs for given subtarget \p Features.
unsigned getTotalNumVGPRs(const FeatureBitset &Features);

/// \returns Addressable number of VGPRs for given subtarget \p Features.
unsigned getAddressableNumVGPRs(const FeatureBitset &Features);
d52 1
a52 3
/// \returns Minimum number of VGPRs that meets given number of waves per
/// execution unit requirement for given subtarget \p Features.
unsigned getMinNumVGPRs(const FeatureBitset &Features, unsigned WavesPerEU);
d54 1
a54 3
/// \returns Maximum number of VGPRs that meets given number of waves per
/// execution unit requirement for given subtarget \p Features.
unsigned getMaxNumVGPRs(const FeatureBitset &Features, unsigned WavesPerEU);
d56 3
a58 11
} // end namespace IsaInfo

LLVM_READONLY
int16_t getNamedOperandIdx(uint16_t Opcode, uint16_t NamedIdx);

void initDefaultAMDKernelCodeT(amd_kernel_code_t &Header,
                               const FeatureBitset &Features);

bool isGroupSegment(const GlobalValue *GV, AMDGPUAS AS);
bool isGlobalSegment(const GlobalValue *GV, AMDGPUAS AS);
bool isReadOnlySegment(const GlobalValue *GV, AMDGPUAS AS);
d86 3
d90 1
a90 1
unsigned getVmcntBitMask(const IsaInfo::IsaVersion &Version);
d93 1
a93 1
unsigned getExpcntBitMask(const IsaInfo::IsaVersion &Version);
d96 1
a96 4
unsigned getLgkmcntBitMask(const IsaInfo::IsaVersion &Version);

/// \returns Waitcnt bit mask for given isa \p Version.
unsigned getWaitcntBitMask(const IsaInfo::IsaVersion &Version);
d99 1
a99 1
unsigned decodeVmcnt(const IsaInfo::IsaVersion &Version, unsigned Waitcnt);
d102 1
a102 1
unsigned decodeExpcnt(const IsaInfo::IsaVersion &Version, unsigned Waitcnt);
d105 1
a105 1
unsigned decodeLgkmcnt(const IsaInfo::IsaVersion &Version, unsigned Waitcnt);
d112 1
a112 2
///     \p Vmcnt = \p Waitcnt[3:0]                      (pre-gfx9 only)
///     \p Vmcnt = \p Waitcnt[3:0] | \p Waitcnt[15:14]  (gfx9+ only)
d115 1
a115 1
void decodeWaitcnt(const IsaInfo::IsaVersion &Version, unsigned Waitcnt,
d119 1
a119 2
unsigned encodeVmcnt(const IsaInfo::IsaVersion &Version, unsigned Waitcnt,
                     unsigned Vmcnt);
d122 1
a122 2
unsigned encodeExpcnt(const IsaInfo::IsaVersion &Version, unsigned Waitcnt,
                      unsigned Expcnt);
d125 1
a125 2
unsigned encodeLgkmcnt(const IsaInfo::IsaVersion &Version, unsigned Waitcnt,
                       unsigned Lgkmcnt);
d131 3
a133 5
///     Waitcnt[3:0]   = \p Vmcnt       (pre-gfx9 only)
///     Waitcnt[3:0]   = \p Vmcnt[3:0]  (gfx9+ only)
///     Waitcnt[6:4]   = \p Expcnt
///     Waitcnt[11:8]  = \p Lgkmcnt
///     Waitcnt[15:14] = \p Vmcnt[5:4]  (gfx9+ only)
d137 1
a137 1
unsigned encodeWaitcnt(const IsaInfo::IsaVersion &Version,
d142 2
a143 20
LLVM_READNONE
bool isShader(CallingConv::ID CC);

LLVM_READNONE
bool isCompute(CallingConv::ID CC);

LLVM_READNONE
bool isEntryFunctionCC(CallingConv::ID CC);

// FIXME: Remove this when calling conventions cleaned up
LLVM_READNONE
inline bool isKernel(CallingConv::ID CC) {
  switch (CC) {
  case CallingConv::AMDGPU_KERNEL:
  case CallingConv::SPIR_KERNEL:
    return true;
  default:
    return false;
  }
}
a147 7
bool isGFX9(const MCSubtargetInfo &STI);

/// \brief Is Reg - scalar register
bool isSGPR(unsigned Reg, const MCRegisterInfo* TRI);

/// \brief Is there any intersection between registers
bool isRegIntersect(unsigned Reg0, unsigned Reg1, const MCRegisterInfo* TRI);
a152 4
/// \brief Convert hardware register \p Reg to a pseudo register
LLVM_READNONE
unsigned mc2PseudoReg(unsigned Reg);

a190 2
  case AMDGPU::OPERAND_REG_INLINE_C_V2INT16:
  case AMDGPU::OPERAND_REG_INLINE_C_V2FP16:
a212 14
LLVM_READNONE
bool isInlinableLiteralV216(int32_t Literal, bool HasInv2Pi);

bool isUniformMMO(const MachineMemOperand *MMO);

/// \returns The encoding that will be used for \p ByteOffset in the SMRD
/// offset field.
int64_t getSMRDEncodedOffset(const MCSubtargetInfo &ST, int64_t ByteOffset);

/// \returns true if this offset is small enough to fit in the SMRD
/// offset field.  \p ByteOffset should be the offset in bytes and
/// not the encoded offset.
bool isLegalSMRDImmOffset(const MCSubtargetInfo &ST, int64_t ByteOffset);

d216 1
a216 1
#endif // LLVM_LIB_TARGET_AMDGPU_UTILS_AMDGPUBASEINFO_H
@


