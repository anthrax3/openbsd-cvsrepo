head	1.16;
access;
symbols
	OPENBSD_6_2:1.16.0.6
	OPENBSD_6_2_BASE:1.16
	PERL_5_24_2:1.1.1.15
	OPENBSD_6_1:1.16.0.4
	OPENBSD_6_1_BASE:1.16
	OPENBSD_6_0:1.15.0.10
	OPENBSD_6_0_BASE:1.15
	OPENBSD_5_9:1.15.0.4
	OPENBSD_5_9_BASE:1.15
	OPENBSD_5_8:1.15.0.6
	OPENBSD_5_8_BASE:1.15
	PERL_5_20_2:1.1.1.14
	OPENBSD_5_7:1.15.0.2
	OPENBSD_5_7_BASE:1.15
	PERL_5_20_1:1.1.1.14
	OPENBSD_5_6:1.14.0.4
	OPENBSD_5_6_BASE:1.14
	PERL_5_18_2:1.1.1.13
	PERL:1.1.1
	OPENBSD_5_5:1.13.0.6
	OPENBSD_5_5_BASE:1.13
	OPENBSD_5_4:1.13.0.2
	OPENBSD_5_4_BASE:1.13
	PERL_5_16_3:1.1.1.12
	OPENBSD_5_3:1.12.0.10
	OPENBSD_5_3_BASE:1.12
	OPENBSD_5_2:1.12.0.8
	OPENBSD_5_2_BASE:1.12
	OPENBSD_5_1_BASE:1.12
	OPENBSD_5_1:1.12.0.6
	OPENBSD_5_0:1.12.0.4
	OPENBSD_5_0_BASE:1.12
	OPENBSD_4_9:1.12.0.2
	OPENBSD_4_9_BASE:1.12
	PERL_5_12_2:1.1.1.11
	OPENBSD_4_8:1.11.0.4
	OPENBSD_4_8_BASE:1.11
	OPENBSD_4_7:1.11.0.2
	OPENBSD_4_7_BASE:1.11
	PERL_5_10_1:1.1.1.10
	OPENBSD_4_6:1.10.0.6
	OPENBSD_4_6_BASE:1.10
	OPENBSD_4_5:1.10.0.2
	OPENBSD_4_5_BASE:1.10
	PERL_5_10_0:1.1.1.9
	OPENBSD_4_4:1.9.0.10
	OPENBSD_4_4_BASE:1.9
	OPENBSD_4_3:1.9.0.8
	OPENBSD_4_3_BASE:1.9
	OPENBSD_4_2:1.9.0.6
	OPENBSD_4_2_BASE:1.9
	OPENBSD_4_1:1.9.0.4
	OPENBSD_4_1_BASE:1.9
	OPENBSD_4_0:1.9.0.2
	OPENBSD_4_0_BASE:1.9
	PERL_5_8_8:1.1.1.8
	OPENBSD_3_9:1.8.0.6
	OPENBSD_3_9_BASE:1.8
	OPENBSD_3_8:1.8.0.4
	OPENBSD_3_8_BASE:1.8
	OPENBSD_3_7:1.8.0.2
	OPENBSD_3_7_BASE:1.8
	PERL_5_8_6:1.1.1.7
	OPENBSD_3_6:1.7.0.4
	OPENBSD_3_6_BASE:1.7
	PERL_5_8_5:1.1.1.6
	PERL_5_8_3:1.1.1.6
	OPENBSD_3_5:1.7.0.2
	OPENBSD_3_5_BASE:1.7
	PERL_5_8_2:1.1.1.6
	OPENBSD_3_4:1.6.0.4
	OPENBSD_3_4_BASE:1.6
	OPENBSD_3_3:1.6.0.2
	OPENBSD_3_3_BASE:1.6
	PERL_5_8_0:1.1.1.5
	OPENBSD_3_2:1.5.0.6
	OPENBSD_3_2_BASE:1.5
	OPENBSD_3_1:1.5.0.4
	OPENBSD_3_1_BASE:1.5
	OPENBSD_3_0:1.5.0.2
	OPENBSD_3_0_BASE:1.5
	PERL_5_6_1:1.1.1.4
	OPENBSD_2_9:1.4.0.6
	OPENBSD_2_9_BASE:1.4
	OPENBSD_2_8:1.4.0.4
	OPENBSD_2_8_BASE:1.4
	OPENBSD_2_7:1.4.0.2
	OPENBSD_2_7_BASE:1.4
	PERL_5_6_0:1.1.1.3
	OPENBSD_2_6:1.3.0.2
	OPENBSD_2_6_BASE:1.3
	PERL_500503:1.1.1.2
	CPAN:1.1.1
	OPENBSD_2_5:1.2.0.6
	OPENBSD_2_5_BASE:1.2
	OPENBSD_2_4:1.2.0.4
	OPENBSD_2_4_BASE:1.2
	OPENBSD_2_3:1.2.0.2
	OPENBSD_2_3_BASE:1.2
	OPENBSD_2_2:1.1.1.1.0.6
	OPENBSD_2_2_BASE:1.1.1.1
	OPENBSD_2_1:1.1.1.1.0.4
	OPENBSD_2_1_BASE:1.1.1.1
	OPENBSD_2_0:1.1.1.1.0.2
	OPENBSD_2_0_BASE:1.1.1.1
	perl5003:1.1.1.1
	lwall:1.1.1;
locks; strict;
comment	@ * @;
expand	@o@;


1.16
date	2017.02.05.00.31.52;	author afresh1;	state Exp;
branches;
next	1.15;
commitid	cxJ08BvJA9Pt2PTM;

1.15
date	2014.11.17.20.56.47;	author afresh1;	state Exp;
branches;
next	1.14;
commitid	QP75iYx42Uo7mMxO;

1.14
date	2014.03.24.15.05.13;	author afresh1;	state Exp;
branches;
next	1.13;

1.13
date	2013.03.25.20.40.44;	author sthen;	state Exp;
branches;
next	1.12;

1.12
date	2010.09.24.15.06.40;	author millert;	state Exp;
branches;
next	1.11;

1.11
date	2009.10.12.18.24.21;	author millert;	state Exp;
branches;
next	1.10;

1.10
date	2008.09.29.17.35.57;	author millert;	state Exp;
branches;
next	1.9;

1.9
date	2006.03.28.19.22.57;	author millert;	state Exp;
branches;
next	1.8;

1.8
date	2005.01.15.21.30.19;	author millert;	state Exp;
branches;
next	1.7;

1.7
date	2003.12.03.03.02.21;	author millert;	state Exp;
branches;
next	1.6;

1.6
date	2002.10.27.22.25.18;	author millert;	state Exp;
branches;
next	1.5;

1.5
date	2001.05.24.18.34.50;	author millert;	state Exp;
branches;
next	1.4;

1.4
date	2000.04.06.17.04.00;	author millert;	state Exp;
branches;
next	1.3;

1.3
date	99.04.29.22.51.01;	author millert;	state Exp;
branches;
next	1.2;

1.2
date	97.11.30.07.48.43;	author millert;	state Exp;
branches;
next	1.1;

1.1
date	96.08.19.10.11.41;	author downsj;	state Exp;
branches
	1.1.1.1;
next	;

1.1.1.1
date	96.08.19.10.11.41;	author downsj;	state Exp;
branches;
next	1.1.1.2;

1.1.1.2
date	99.04.29.22.37.24;	author millert;	state Exp;
branches;
next	1.1.1.3;

1.1.1.3
date	2000.04.06.16.08.38;	author millert;	state Exp;
branches;
next	1.1.1.4;

1.1.1.4
date	2001.05.24.18.22.06;	author millert;	state Exp;
branches;
next	1.1.1.5;

1.1.1.5
date	2002.10.27.22.14.47;	author millert;	state Exp;
branches;
next	1.1.1.6;

1.1.1.6
date	2003.12.03.02.43.30;	author millert;	state Exp;
branches;
next	1.1.1.7;

1.1.1.7
date	2005.01.15.21.16.26;	author millert;	state Exp;
branches;
next	1.1.1.8;

1.1.1.8
date	2006.03.28.18.47.29;	author millert;	state Exp;
branches;
next	1.1.1.9;

1.1.1.9
date	2008.09.29.17.18.06;	author millert;	state Exp;
branches;
next	1.1.1.10;

1.1.1.10
date	2009.10.12.18.10.34;	author millert;	state Exp;
branches;
next	1.1.1.11;

1.1.1.11
date	2010.09.24.14.48.25;	author millert;	state Exp;
branches;
next	1.1.1.12;

1.1.1.12
date	2013.03.25.20.06.26;	author sthen;	state Exp;
branches;
next	1.1.1.13;

1.1.1.13
date	2014.03.24.14.58.45;	author afresh1;	state Exp;
branches;
next	1.1.1.14;

1.1.1.14
date	2014.11.17.20.52.36;	author afresh1;	state Exp;
branches;
next	1.1.1.15;
commitid	B31cAbBIXiCqnL97;

1.1.1.15
date	2017.08.14.13.45.26;	author afresh1;	state Exp;
branches;
next	;
commitid	fAzrs78vdW2Yfc6A;


desc
@@


1.16
log
@Fix merge issues, remove excess files - match perl-5.24.1 dist
@
text
@/*    malloc.c
 *
 */

/*
 * 'The Chamber of Records,' said Gimli.  'I guess that is where we now stand.'
 *
 *     [p.321 of _The Lord of the Rings_, II/v: "The Bridge of Khazad-DÃ»m"]
 */

/* This file contains Perl's own implementation of the malloc library.
 * It is used if Configure decides that, on your platform, Perl's
 * version is better than the OS's, or if you give Configure the
 * -Dusemymalloc command-line option.
 */

/*
  Here are some notes on configuring Perl's malloc.

  There are two macros which serve as bulk disablers of advanced
  features of this malloc: NO_FANCY_MALLOC, PLAIN_MALLOC (undef by
  default).  Look in the list of default values below to understand
  their exact effect.  Defining NO_FANCY_MALLOC returns malloc.c to the
  state of the malloc in Perl 5.004.  Additionally defining PLAIN_MALLOC
  returns it to the state as of Perl 5.000.

  Note that some of the settings below may be ignored in the code based
  on values of other macros.  The PERL_CORE symbol is only defined when
  perl itself is being compiled (so malloc can make some assumptions
  about perl's facilities being available to it).

  Each config option has a short description, followed by its name,
  default value, and a comment about the default (if applicable).  Some
  options take a precise value, while the others are just boolean.
  The boolean ones are listed first.

    # Read configuration settings from malloc_cfg.h
    HAVE_MALLOC_CFG_H		undef

    # Enable code for an emergency memory pool in $^M.  See perlvar.pod
    # for a description of $^M.
    PERL_EMERGENCY_SBRK		!PLAIN_MALLOC

    # Enable code for printing memory statistics.
    DEBUGGING_MSTATS		!PLAIN_MALLOC

    # Move allocation info for small buckets into separate areas.
    # Memory optimization (especially for small allocations, of the
    # less than 64 bytes).  Since perl usually makes a large number
    # of small allocations, this is usually a win.
    PACK_MALLOC			(!PLAIN_MALLOC && !RCHECK)

    # Add one page to big powers of two when calculating bucket size.
    # This is targeted at big allocations, as are common in image
    # processing.
    TWO_POT_OPTIMIZE		!PLAIN_MALLOC
 
    # Use intermediate bucket sizes between powers-of-two.  This is
    # generally a memory optimization, and a (small) speed pessimization.
    BUCKETS_ROOT2		!NO_FANCY_MALLOC

    # Do not check small deallocations for bad free().  Memory
    # and speed optimization, error reporting pessimization.
    IGNORE_SMALL_BAD_FREE	(!NO_FANCY_MALLOC && !RCHECK)

    # Use table lookup to decide in which bucket a given allocation will go.
    SMALL_BUCKET_VIA_TABLE	!NO_FANCY_MALLOC

    # Use a perl-defined sbrk() instead of the (presumably broken or
    # missing) system-supplied sbrk().
    USE_PERL_SBRK		undef

    # Use system malloc() (or calloc() etc.) to emulate sbrk(). Normally
    # only used with broken sbrk()s.
    PERL_SBRK_VIA_MALLOC	undef

    # Which allocator to use if PERL_SBRK_VIA_MALLOC
    SYSTEM_ALLOC(a) 		malloc(a)

    # Minimal alignment (in bytes, should be a power of 2) of SYSTEM_ALLOC
    SYSTEM_ALLOC_ALIGNMENT	MEM_ALIGNBYTES

    # Disable memory overwrite checking with DEBUGGING.  Memory and speed
    # optimization, error reporting pessimization.
    NO_RCHECK			undef

    # Enable memory overwrite checking with DEBUGGING.  Memory and speed
    # pessimization, error reporting optimization
    RCHECK			(DEBUGGING && !NO_RCHECK)

    # Do not overwrite uninit areas with DEBUGGING.  Speed
    # optimization, error reporting pessimization
    NO_MFILL			undef

    # Overwrite uninit areas with DEBUGGING.  Speed
    # pessimization, error reporting optimization
    MALLOC_FILL			(DEBUGGING && !NO_RCHECK && !NO_MFILL)

    # Do not check overwritten uninit areas with DEBUGGING.  Speed
    # optimization, error reporting pessimization
    NO_FILL_CHECK		undef

    # Check overwritten uninit areas with DEBUGGING.  Speed
    # pessimization, error reporting optimization
    MALLOC_FILL_CHECK		(DEBUGGING && !NO_RCHECK && !NO_FILL_CHECK)

    # Failed allocations bigger than this size croak (if
    # PERL_EMERGENCY_SBRK is enabled) without touching $^M.  See
    # perlvar.pod for a description of $^M.
    BIG_SIZE			 (1<<16)	# 64K

    # Starting from this power of two, add an extra page to the
    # size of the bucket. This enables optimized allocations of sizes
    # close to powers of 2.  Note that the value is indexed at 0.
    FIRST_BIG_POW2 		15		# 32K, 16K is used too often

    # Estimate of minimal memory footprint.  malloc uses this value to
    # request the most reasonable largest blocks of memory from the system.
    FIRST_SBRK 			(48*1024)

    # Round up sbrk()s to multiples of this.
    MIN_SBRK 			2048

    # Round up sbrk()s to multiples of this percent of footprint.
    MIN_SBRK_FRAC 		3

    # Round up sbrk()s to multiples of this multiple of 1/1000 of footprint.
    MIN_SBRK_FRAC1000 		(10 * MIN_SBRK_FRAC)

    # Add this much memory to big powers of two to get the bucket size.
    PERL_PAGESIZE 		4096

    # This many sbrk() discontinuities should be tolerated even
    # from the start without deciding that sbrk() is usually
    # discontinuous.
    SBRK_ALLOW_FAILURES		3

    # This many continuous sbrk()s compensate for one discontinuous one.
    SBRK_FAILURE_PRICE		50

    # Some configurations may ask for 12-byte-or-so allocations which
    # require 8-byte alignment (?!).  In such situation one needs to
    # define this to disable 12-byte bucket (will increase memory footprint)
    STRICT_ALIGNMENT		undef

    # Do not allow configuration of runtime options at runtime
    NO_MALLOC_DYNAMIC_CFG	undef

    # Do not allow configuration of runtime options via $ENV{PERL_MALLOC_OPT}
    NO_PERL_MALLOC_ENV		undef

	[The variable consists of ;-separated parts of the form CODE=VALUE
	 with 1-character codes F, M, f, A, P, G, d, a, c for runtime
	 configuration of FIRST_SBRK, MIN_SBRK, MIN_SBRK_FRAC1000,
	 SBRK_ALLOW_FAILURES, SBRK_FAILURE_PRICE, sbrk_goodness,
	 filldead, fillalive, fillcheck.  The last 3 are for DEBUGGING
	 build, and allow switching the tests for free()ed memory read,
	 uninit memory reads, and free()ed memory write.]

  This implementation assumes that calling PerlIO_printf() does not
  result in any memory allocation calls (used during a panic).

 */


#ifdef HAVE_MALLOC_CFG_H
#  include "malloc_cfg.h"
#endif

#ifndef NO_FANCY_MALLOC
#  ifndef SMALL_BUCKET_VIA_TABLE
#    define SMALL_BUCKET_VIA_TABLE
#  endif 
#  ifndef BUCKETS_ROOT2
#    define BUCKETS_ROOT2
#  endif 
#  ifndef IGNORE_SMALL_BAD_FREE
#    define IGNORE_SMALL_BAD_FREE
#  endif 
#endif 

#ifndef PLAIN_MALLOC			/* Bulk enable features */
#  ifndef PACK_MALLOC
#      define PACK_MALLOC
#  endif 
#  ifndef TWO_POT_OPTIMIZE
#    define TWO_POT_OPTIMIZE
#  endif 
#  ifndef PERL_EMERGENCY_SBRK
#    define PERL_EMERGENCY_SBRK
#  endif 
#  ifndef DEBUGGING_MSTATS
#    define DEBUGGING_MSTATS
#  endif 
#endif

#define MIN_BUC_POW2 (sizeof(void*) > 4 ? 3 : 2) /* Allow for 4-byte arena. */
#define MIN_BUCKET (MIN_BUC_POW2 * BUCKETS_PER_POW2)

#define LOG_OF_MIN_ARENA 11

#if defined(DEBUGGING) && !defined(NO_RCHECK)
#  define RCHECK
#endif
#if defined(DEBUGGING) && !defined(NO_RCHECK) && !defined(NO_MFILL) && !defined(MALLOC_FILL)
#  define MALLOC_FILL
#endif
#if defined(DEBUGGING) && !defined(NO_RCHECK) && !defined(NO_FILL_CHECK) && !defined(MALLOC_FILL_CHECK)
#  define MALLOC_FILL_CHECK
#endif
#if defined(RCHECK) && defined(IGNORE_SMALL_BAD_FREE)
#  undef IGNORE_SMALL_BAD_FREE
#endif 
/*
 * malloc.c (Caltech) 2/21/82
 * Chris Kingsley, kingsley@@cit-20.
 *
 * This is a very fast storage allocator.  It allocates blocks of a small 
 * number of different sizes, and keeps free lists of each size.  Blocks that
 * don't exactly fit are passed up to the next larger size.  In this 
 * implementation, the available sizes are 2^n-4 (or 2^n-12) bytes long.
 * If PACK_MALLOC is defined, small blocks are 2^n bytes long.
 * This is designed for use in a program that uses vast quantities of memory,
 * but bombs when it runs out.
 * 
 * Modifications Copyright Ilya Zakharevich 1996-99.
 * 
 * Still very quick, but much more thrifty.  (Std config is 10% slower
 * than it was, and takes 67% of old heap size for typical usage.)
 *
 * Allocations of small blocks are now table-driven to many different
 * buckets.  Sizes of really big buckets are increased to accommodate
 * common size=power-of-2 blocks.  Running-out-of-memory is made into
 * an exception.  Deeply configurable and thread-safe.
 * 
 */

#include "EXTERN.h"
#define PERL_IN_MALLOC_C
#include "perl.h"
#if defined(PERL_IMPLICIT_CONTEXT)
#    define croak	Perl_croak_nocontext
#    define croak2	Perl_croak_nocontext
#    define warn	Perl_warn_nocontext
#    define warn2	Perl_warn_nocontext
#else
#    define croak2	croak
#    define warn2	warn
#endif
#ifdef USE_ITHREADS
#     define PERL_MAYBE_ALIVE	PL_thr_key
#else
#     define PERL_MAYBE_ALIVE	1
#endif

#ifndef MYMALLOC
#  error "MYMALLOC is not defined"
#endif

#ifndef MUTEX_LOCK
#  define MUTEX_LOCK(l)
#endif 

#ifndef MUTEX_UNLOCK
#  define MUTEX_UNLOCK(l)
#endif 

#ifndef MALLOC_LOCK
#  define MALLOC_LOCK		MUTEX_LOCK(&PL_malloc_mutex)
#endif 

#ifndef MALLOC_UNLOCK
#  define MALLOC_UNLOCK		MUTEX_UNLOCK(&PL_malloc_mutex)
#endif 

#  ifndef fatalcroak				/* make depend */
#    define fatalcroak(mess)	(write(2, (mess), strlen(mess)), exit(2))
#  endif 

#ifdef DEBUGGING
#  undef DEBUG_m
#  define DEBUG_m(a) 							\
    STMT_START {							\
	if (PERL_MAYBE_ALIVE && PERL_GET_THX) {						\
	    dTHX;							\
	    if (DEBUG_m_TEST) {						\
		PL_debug &= ~DEBUG_m_FLAG;				\
		a;							\
		PL_debug |= DEBUG_m_FLAG;				\
	    }								\
	}								\
    } STMT_END
#endif

#ifdef PERL_IMPLICIT_CONTEXT
#  define PERL_IS_ALIVE		aTHX
#else
#  define PERL_IS_ALIVE		TRUE
#endif
    

/*
 * Layout of memory:
 * ~~~~~~~~~~~~~~~~
 * The memory is broken into "blocks" which occupy multiples of 2K (and
 * generally speaking, have size "close" to a power of 2).  The addresses
 * of such *unused* blocks are kept in nextf[i] with big enough i.  (nextf
 * is an array of linked lists.)  (Addresses of used blocks are not known.)
 * 
 * Moreover, since the algorithm may try to "bite" smaller blocks out
 * of unused bigger ones, there are also regions of "irregular" size,
 * managed separately, by a linked list chunk_chain.
 * 
 * The third type of storage is the sbrk()ed-but-not-yet-used space, its
 * end and size are kept in last_sbrk_top and sbrked_remains.
 * 
 * Growing blocks "in place":
 * ~~~~~~~~~~~~~~~~~~~~~~~~~
 * The address of the block with the greatest address is kept in last_op
 * (if not known, last_op is 0).  If it is known that the memory above
 * last_op is not continuous, or contains a chunk from chunk_chain,
 * last_op is set to 0.
 * 
 * The chunk with address last_op may be grown by expanding into
 * sbrk()ed-but-not-yet-used space, or trying to sbrk() more continuous
 * memory.
 * 
 * Management of last_op:
 * ~~~~~~~~~~~~~~~~~~~~~
 * 
 * free() never changes the boundaries of blocks, so is not relevant.
 * 
 * The only way realloc() may change the boundaries of blocks is if it
 * grows a block "in place".  However, in the case of success such a
 * chunk is automatically last_op, and it remains last_op.  In the case
 * of failure getpages_adjacent() clears last_op.
 * 
 * malloc() may change blocks by calling morecore() only.
 * 
 * morecore() may create new blocks by:
 *   a) biting pieces from chunk_chain (cannot create one above last_op);
 *   b) biting a piece from an unused block (if block was last_op, this
 *      may create a chunk from chain above last_op, thus last_op is
 *      invalidated in such a case).
 *   c) biting of sbrk()ed-but-not-yet-used space.  This creates 
 *      a block which is last_op.
 *   d) Allocating new pages by calling getpages();
 * 
 * getpages() creates a new block.  It marks last_op at the bottom of
 * the chunk of memory it returns.
 * 
 * Active pages footprint:
 * ~~~~~~~~~~~~~~~~~~~~~~
 * Note that we do not need to traverse the lists in nextf[i], just take
 * the first element of this list.  However, we *need* to traverse the
 * list in chunk_chain, but most the time it should be a very short one,
 * so we do not step on a lot of pages we are not going to use.
 * 
 * Flaws:
 * ~~~~~
 * get_from_bigger_buckets(): forget to increment price => Quite
 * aggressive.
 */

/* I don't much care whether these are defined in sys/types.h--LAW */

#define u_char unsigned char
#define u_int unsigned int
/* 
 * I removed the definition of u_bigint which appeared to be u_bigint = UV
 * u_bigint was only used in TWOK_MASKED and TWOK_SHIFT 
 * where I have used PTR2UV.  RMB
 */
#define u_short unsigned short

#if defined(RCHECK) && defined(PACK_MALLOC)
#  undef PACK_MALLOC
#endif 

/*
 * The description below is applicable if PACK_MALLOC is not defined.
 *
 * The overhead on a block is at least 4 bytes.  When free, this space
 * contains a pointer to the next free block, and the bottom two bits must
 * be zero.  When in use, the first byte is set to MAGIC, and the second
 * byte is the size index.  The remaining bytes are for alignment.
 * If range checking is enabled and the size of the block fits
 * in two bytes, then the top two bytes hold the size of the requested block
 * plus the range checking words, and the header word MINUS ONE.
 */
union	overhead {
	union	overhead *ov_next;	/* when free */
#if MEM_ALIGNBYTES > 4
	double	strut;			/* alignment problems */
#  if MEM_ALIGNBYTES > 8
	char	sstrut[MEM_ALIGNBYTES]; /* for the sizing */
#  endif
#endif
	struct {
/*
 * Keep the ovu_index and ovu_magic in this order, having a char
 * field first gives alignment indigestion in some systems, such as
 * MachTen.
 */
		u_char	ovu_index;	/* bucket # */
		u_char	ovu_magic;	/* magic number */
#ifdef RCHECK
	    /* Subtract one to fit into u_short for an extra bucket */
		u_short	ovu_size;	/* block size (requested + overhead - 1) */
		u_int	ovu_rmagic;	/* range magic number */
#endif
	} ovu;
#define	ov_magic	ovu.ovu_magic
#define	ov_index	ovu.ovu_index
#define	ov_size		ovu.ovu_size
#define	ov_rmagic	ovu.ovu_rmagic
};

#define	MAGIC		0xff		/* magic # on accounting info */
#define RMAGIC		0x55555555	/* magic # on range info */
#define RMAGIC_C	0x55		/* magic # on range info */

#ifdef RCHECK
#  define	RMAGIC_SZ	sizeof (u_int) /* Overhead at end of bucket */
#  ifdef TWO_POT_OPTIMIZE
#    define MAX_SHORT_BUCKET (12 * BUCKETS_PER_POW2) /* size-1 fits in short */
#  else
#    define MAX_SHORT_BUCKET (13 * BUCKETS_PER_POW2)
#  endif 
#else
#  define	RMAGIC_SZ	0
#endif

#if !defined(PACK_MALLOC) && defined(BUCKETS_ROOT2)
#  undef BUCKETS_ROOT2
#endif 

#ifdef BUCKETS_ROOT2
#  define BUCKET_TABLE_SHIFT 2
#  define BUCKET_POW2_SHIFT 1
#  define BUCKETS_PER_POW2 2
#else
#  define BUCKET_TABLE_SHIFT MIN_BUC_POW2
#  define BUCKET_POW2_SHIFT 0
#  define BUCKETS_PER_POW2 1
#endif 

#if !defined(MEM_ALIGNBYTES) || ((MEM_ALIGNBYTES > 4) && !defined(STRICT_ALIGNMENT))
/* Figure out the alignment of void*. */
struct aligner {
  char c;
  void *p;
};
#  define ALIGN_SMALL ((IV)((caddr_t)&(((struct aligner*)0)->p)))
#else
#  define ALIGN_SMALL MEM_ALIGNBYTES
#endif

#define IF_ALIGN_8(yes,no)	((ALIGN_SMALL>4) ? (yes) : (no))

#ifdef BUCKETS_ROOT2
#  define MAX_BUCKET_BY_TABLE 13
static const u_short buck_size[MAX_BUCKET_BY_TABLE + 1] = 
  { 
      0, 0, 0, 0, 4, 4, 8, 12, 16, 24, 32, 48, 64, 80,
  };
#  define BUCKET_SIZE_NO_SURPLUS(i) ((i) % 2 ? buck_size[i] : (1 << ((i) >> BUCKET_POW2_SHIFT)))
#  define BUCKET_SIZE_REAL(i) ((i) <= MAX_BUCKET_BY_TABLE		\
			       ? buck_size[i] 				\
			       : ((1 << ((i) >> BUCKET_POW2_SHIFT))	\
				  - MEM_OVERHEAD(i)			\
				  + POW2_OPTIMIZE_SURPLUS(i)))
#else
#  define BUCKET_SIZE_NO_SURPLUS(i) (1 << ((i) >> BUCKET_POW2_SHIFT))
#  define BUCKET_SIZE(i) (BUCKET_SIZE_NO_SURPLUS(i) + POW2_OPTIMIZE_SURPLUS(i))
#  define BUCKET_SIZE_REAL(i) (BUCKET_SIZE(i) - MEM_OVERHEAD(i))
#endif 


#ifdef PACK_MALLOC
/* In this case there are several possible layout of arenas depending
 * on the size.  Arenas are of sizes multiple to 2K, 2K-aligned, and
 * have a size close to a power of 2.
 *
 * Arenas of the size >= 4K keep one chunk only.  Arenas of size 2K
 * may keep one chunk or multiple chunks.  Here are the possible
 * layouts of arenas:
 *
 *	# One chunk only, chunksize 2^k + SOMETHING - ALIGN, k >= 11
 *
 * INDEX MAGIC1 UNUSED CHUNK1
 *
 *	# Multichunk with sanity checking and chunksize 2^k-ALIGN, k>7
 *
 * INDEX MAGIC1 MAGIC2 MAGIC3 UNUSED CHUNK1 CHUNK2 CHUNK3 ...
 *
 *	# Multichunk with sanity checking and size 2^k-ALIGN, k=7
 *
 * INDEX MAGIC1 MAGIC2 MAGIC3 UNUSED CHUNK1 UNUSED CHUNK2 CHUNK3 ...
 *
 *	# Multichunk with sanity checking and size up to 80
 *
 * INDEX UNUSED MAGIC1 UNUSED MAGIC2 UNUSED ... CHUNK1 CHUNK2 CHUNK3 ...
 *
 *	# No sanity check (usually up to 48=byte-long buckets)
 * INDEX UNUSED CHUNK1 CHUNK2 ...
 *
 * Above INDEX and MAGIC are one-byte-long.  Sizes of UNUSED are
 * appropriate to keep algorithms simple and memory aligned.  INDEX
 * encodes the size of the chunk, while MAGICn encodes state (used,
 * free or non-managed-by-us-so-it-indicates-a-bug) of CHUNKn.  MAGIC
 * is used for sanity checking purposes only.  SOMETHING is 0 or 4K
 * (to make size of big CHUNK accommodate allocations for powers of two
 * better).
 *
 * [There is no need to alignment between chunks, since C rules ensure
 *  that structs which need 2^k alignment have sizeof which is
 *  divisible by 2^k.  Thus as far as the last chunk is aligned at the
 *  end of the arena, and 2K-alignment does not contradict things,
 *  everything is going to be OK for sizes of chunks 2^n and 2^n +
 *  2^k.  Say, 80-bit buckets will be 16-bit aligned, and as far as we
 *  put allocations for requests in 65..80 range, all is fine.
 *
 *  Note, however, that standard malloc() puts more strict
 *  requirements than the above C rules.  Moreover, our algorithms of
 *  realloc() may break this idyll, but we suppose that realloc() does
 *  need not change alignment.]
 *
 * Is very important to make calculation of the offset of MAGICm as
 * quick as possible, since it is done on each malloc()/free().  In
 * fact it is so quick that it has quite little effect on the speed of
 * doing malloc()/free().  [By default] We forego such calculations
 * for small chunks, but only to save extra 3% of memory, not because
 * of speed considerations.
 *
 * Here is the algorithm [which is the same for all the allocations
 * schemes above], see OV_MAGIC(block,bucket).  Let OFFSETm be the
 * offset of the CHUNKm from the start of ARENA.  Then offset of
 * MAGICm is (OFFSET1 >> SHIFT) + ADDOFFSET.  Here SHIFT and ADDOFFSET
 * are numbers which depend on the size of the chunks only.
 *
 * Let as check some sanity conditions.  Numbers OFFSETm>>SHIFT are
 * different for all the chunks in the arena if 2^SHIFT is not greater
 * than size of the chunks in the arena.  MAGIC1 will not overwrite
 * INDEX provided ADDOFFSET is >0 if OFFSET1 < 2^SHIFT.  MAGIClast
 * will not overwrite CHUNK1 if OFFSET1 > (OFFSETlast >> SHIFT) +
 * ADDOFFSET.
 * 
 * Make SHIFT the maximal possible (there is no point in making it
 * smaller).  Since OFFSETlast is 2K - CHUNKSIZE, above restrictions
 * give restrictions on OFFSET1 and on ADDOFFSET.
 * 
 * In particular, for chunks of size 2^k with k>=6 we can put
 * ADDOFFSET to be from 0 to 2^k - 2^(11-k), and have
 * OFFSET1==chunksize.  For chunks of size 80 OFFSET1 of 2K%80=48 is
 * large enough to have ADDOFFSET between 1 and 16 (similarly for 96,
 * when ADDOFFSET should be 1).  In particular, keeping MAGICs for
 * these sizes gives no additional size penalty.
 * 
 * However, for chunks of size 2^k with k<=5 this gives OFFSET1 >=
 * ADDOFSET + 2^(11-k).  Keeping ADDOFFSET 0 allows for 2^(11-k)-2^(11-2k)
 * chunks per arena.  This is smaller than 2^(11-k) - 1 which are
 * needed if no MAGIC is kept.  [In fact, having a negative ADDOFFSET
 * would allow for slightly more buckets per arena for k=2,3.]
 * 
 * Similarly, for chunks of size 3/2*2^k with k<=5 MAGICs would span
 * the area up to 2^(11-k)+ADDOFFSET.  For k=4 this give optimal
 * ADDOFFSET as -7..0.  For k=3 ADDOFFSET can go up to 4 (with tiny
 * savings for negative ADDOFFSET).  For k=5 ADDOFFSET can go -1..16
 * (with no savings for negative values).
 *
 * In particular, keeping ADDOFFSET 0 for sizes of chunks up to 2^6
 * leads to tiny pessimizations in case of sizes 4, 8, 12, 24, and
 * leads to no contradictions except for size=80 (or 96.)
 *
 * However, it also makes sense to keep no magic for sizes 48 or less.
 * This is what we do.  In this case one needs ADDOFFSET>=1 also for
 * chunksizes 12, 24, and 48, unless one gets one less chunk per
 * arena.
 *  
 * The algo of OV_MAGIC(block,bucket) keeps ADDOFFSET 0 until
 * chunksize of 64, then makes it 1. 
 *
 * This allows for an additional optimization: the above scheme leads
 * to giant overheads for sizes 128 or more (one whole chunk needs to
 * be sacrifised to keep INDEX).  Instead we use chunks not of size
 * 2^k, but of size 2^k-ALIGN.  If we pack these chunks at the end of
 * the arena, then the beginnings are still in different 2^k-long
 * sections of the arena if k>=7 for ALIGN==4, and k>=8 if ALIGN=8.
 * Thus for k>7 the above algo of calculating the offset of the magic
 * will still give different answers for different chunks.  And to
 * avoid the overrun of MAGIC1 into INDEX, one needs ADDOFFSET of >=1.
 * In the case k=7 we just move the first chunk an extra ALIGN
 * backward inside the ARENA (this is done once per arena lifetime,
 * thus is not a big overhead).  */
#  define MAX_PACKED_POW2 6
#  define MAX_PACKED (MAX_PACKED_POW2 * BUCKETS_PER_POW2 + BUCKET_POW2_SHIFT)
#  define MAX_POW2_ALGO ((1<<(MAX_PACKED_POW2 + 1)) - M_OVERHEAD)
#  define TWOK_MASK ((1<<LOG_OF_MIN_ARENA) - 1)
#  define TWOK_MASKED(x) (PTR2UV(x) & ~TWOK_MASK)
#  define TWOK_SHIFT(x) (PTR2UV(x) & TWOK_MASK)
#  define OV_INDEXp(block) (INT2PTR(u_char*,TWOK_MASKED(block)))
#  define OV_INDEX(block) (*OV_INDEXp(block))
#  define OV_MAGIC(block,bucket) (*(OV_INDEXp(block) +			\
				    (TWOK_SHIFT(block)>>		\
				     (bucket>>BUCKET_POW2_SHIFT)) +	\
				    (bucket >= MIN_NEEDS_SHIFT ? 1 : 0)))
    /* A bucket can have a shift smaller than it size, we need to
       shift its magic number so it will not overwrite index: */
#  ifdef BUCKETS_ROOT2
#    define MIN_NEEDS_SHIFT (7*BUCKETS_PER_POW2 - 1) /* Shift 80 greater than chunk 64. */
#  else
#    define MIN_NEEDS_SHIFT (7*BUCKETS_PER_POW2) /* Shift 128 greater than chunk 32. */
#  endif 
#  define CHUNK_SHIFT 0

/* Number of active buckets of given ordinal. */
#ifdef IGNORE_SMALL_BAD_FREE
#define FIRST_BUCKET_WITH_CHECK (6 * BUCKETS_PER_POW2) /* 64 */
#  define N_BLKS(bucket) ( (bucket) < FIRST_BUCKET_WITH_CHECK 		\
			 ? ((1<<LOG_OF_MIN_ARENA) - 1)/BUCKET_SIZE_NO_SURPLUS(bucket) \
			 : n_blks[bucket] )
#else
#  define N_BLKS(bucket) n_blks[bucket]
#endif 

static const u_short n_blks[LOG_OF_MIN_ARENA * BUCKETS_PER_POW2] =
  {
#  if BUCKETS_PER_POW2==1
      0, 0,
      (MIN_BUC_POW2==2 ? 384 : 0),
      224, 120, 62, 31, 16, 8, 4, 2
#  else
      0, 0, 0, 0,
      (MIN_BUC_POW2==2 ? 384 : 0), (MIN_BUC_POW2==2 ? 384 : 0),	/* 4, 4 */
      224, 149, 120, 80, 62, 41, 31, 25, 16, 16, 8, 8, 4, 4, 2, 2
#  endif
  };

/* Shift of the first bucket with the given ordinal inside 2K chunk. */
#ifdef IGNORE_SMALL_BAD_FREE
#  define BLK_SHIFT(bucket) ( (bucket) < FIRST_BUCKET_WITH_CHECK 	\
			      ? ((1<<LOG_OF_MIN_ARENA)			\
				 - BUCKET_SIZE_NO_SURPLUS(bucket) * N_BLKS(bucket)) \
			      : blk_shift[bucket])
#else
#  define BLK_SHIFT(bucket) blk_shift[bucket]
#endif 

static const u_short blk_shift[LOG_OF_MIN_ARENA * BUCKETS_PER_POW2] =
  { 
#  if BUCKETS_PER_POW2==1
      0, 0,
      (MIN_BUC_POW2==2 ? 512 : 0),
      256, 128, 64, 64,			/* 8 to 64 */
      16*sizeof(union overhead), 
      8*sizeof(union overhead), 
      4*sizeof(union overhead), 
      2*sizeof(union overhead), 
#  else
      0, 0, 0, 0,
      (MIN_BUC_POW2==2 ? 512 : 0), (MIN_BUC_POW2==2 ? 512 : 0),
      256, 260, 128, 128, 64, 80, 64, 48, /* 8 to 96 */
      16*sizeof(union overhead), 16*sizeof(union overhead), 
      8*sizeof(union overhead), 8*sizeof(union overhead), 
      4*sizeof(union overhead), 4*sizeof(union overhead), 
      2*sizeof(union overhead), 2*sizeof(union overhead), 
#  endif 
  };

#  define NEEDED_ALIGNMENT 0x800	/* 2k boundaries */
#  define WANTED_ALIGNMENT 0x800	/* 2k boundaries */

#else  /* !PACK_MALLOC */

#  define OV_MAGIC(block,bucket) (block)->ov_magic
#  define OV_INDEX(block) (block)->ov_index
#  define CHUNK_SHIFT 1
#  define MAX_PACKED -1
#  define NEEDED_ALIGNMENT MEM_ALIGNBYTES
#  define WANTED_ALIGNMENT 0x400	/* 1k boundaries */

#endif /* !PACK_MALLOC */

#define M_OVERHEAD (sizeof(union overhead) + RMAGIC_SZ) /* overhead at start+end */

#ifdef PACK_MALLOC
#  define MEM_OVERHEAD(bucket) \
  (bucket <= MAX_PACKED ? 0 : M_OVERHEAD)
#  ifdef SMALL_BUCKET_VIA_TABLE
#    define START_SHIFTS_BUCKET ((MAX_PACKED_POW2 + 1) * BUCKETS_PER_POW2)
#    define START_SHIFT MAX_PACKED_POW2
#    ifdef BUCKETS_ROOT2		/* Chunks of size 3*2^n. */
#      define SIZE_TABLE_MAX 80
#    else
#      define SIZE_TABLE_MAX 64
#    endif 
static const char bucket_of[] =
  {
#    ifdef BUCKETS_ROOT2		/* Chunks of size 3*2^n. */
      /* 0 to 15 in 4-byte increments. */
      (sizeof(void*) > 4 ? 6 : 5),	/* 4/8, 5-th bucket for better reports */
      6,				/* 8 */
      IF_ALIGN_8(8,7), 8,		/* 16/12, 16 */
      9, 9, 10, 10,			/* 24, 32 */
      11, 11, 11, 11,			/* 48 */
      12, 12, 12, 12,			/* 64 */
      13, 13, 13, 13,			/* 80 */
      13, 13, 13, 13			/* 80 */
#    else /* !BUCKETS_ROOT2 */
      /* 0 to 15 in 4-byte increments. */
      (sizeof(void*) > 4 ? 3 : 2),
      3, 
      4, 4, 
      5, 5, 5, 5,
      6, 6, 6, 6,
      6, 6, 6, 6
#    endif /* !BUCKETS_ROOT2 */
  };
#  else  /* !SMALL_BUCKET_VIA_TABLE */
#    define START_SHIFTS_BUCKET MIN_BUCKET
#    define START_SHIFT (MIN_BUC_POW2 - 1)
#  endif /* !SMALL_BUCKET_VIA_TABLE */
#else  /* !PACK_MALLOC */
#  define MEM_OVERHEAD(bucket) M_OVERHEAD
#  ifdef SMALL_BUCKET_VIA_TABLE
#    undef SMALL_BUCKET_VIA_TABLE
#  endif 
#  define START_SHIFTS_BUCKET MIN_BUCKET
#  define START_SHIFT (MIN_BUC_POW2 - 1)
#endif /* !PACK_MALLOC */

/*
 * Big allocations are often of the size 2^n bytes. To make them a
 * little bit better, make blocks of size 2^n+pagesize for big n.
 */

#ifdef TWO_POT_OPTIMIZE

#  ifndef PERL_PAGESIZE
#    define PERL_PAGESIZE 4096
#  endif 
#  ifndef FIRST_BIG_POW2
#    define FIRST_BIG_POW2 15	/* 32K, 16K is used too often. */
#  endif
#  define FIRST_BIG_BLOCK (1<<FIRST_BIG_POW2)
/* If this value or more, check against bigger blocks. */
#  define FIRST_BIG_BOUND (FIRST_BIG_BLOCK - M_OVERHEAD)
/* If less than this value, goes into 2^n-overhead-block. */
#  define LAST_SMALL_BOUND ((FIRST_BIG_BLOCK>>1) - M_OVERHEAD)

#  define POW2_OPTIMIZE_ADJUST(nbytes)				\
   ((nbytes >= FIRST_BIG_BOUND) ? nbytes -= PERL_PAGESIZE : 0)
#  define POW2_OPTIMIZE_SURPLUS(bucket)				\
   ((bucket >= FIRST_BIG_POW2 * BUCKETS_PER_POW2) ? PERL_PAGESIZE : 0)

#else  /* !TWO_POT_OPTIMIZE */
#  define POW2_OPTIMIZE_ADJUST(nbytes)
#  define POW2_OPTIMIZE_SURPLUS(bucket) 0
#endif /* !TWO_POT_OPTIMIZE */

#define BARK_64K_LIMIT(what,nbytes,size)

#ifndef MIN_SBRK
#  define MIN_SBRK 2048
#endif 

#ifndef FIRST_SBRK
#  define FIRST_SBRK (48*1024)
#endif 

/* Minimal sbrk in percents of what is already alloced. */
#ifndef MIN_SBRK_FRAC
#  define MIN_SBRK_FRAC 3
#endif 

#ifndef SBRK_ALLOW_FAILURES
#  define SBRK_ALLOW_FAILURES 3
#endif 

#ifndef SBRK_FAILURE_PRICE
#  define SBRK_FAILURE_PRICE 50
#endif 

static void	morecore	(int bucket);
#  if defined(DEBUGGING)
static void	botch		(const char *diag, const char *s, const char *file, int line);
#  endif
static void	add_to_chain	(void *p, MEM_SIZE size, MEM_SIZE chip);
static void*	get_from_chain	(MEM_SIZE size);
static void*	get_from_bigger_buckets(int bucket, MEM_SIZE size);
static union overhead *getpages	(MEM_SIZE needed, int *nblksp, int bucket);
static int	getpages_adjacent(MEM_SIZE require);

#ifdef I_MACH_CTHREADS
#  undef  MUTEX_LOCK
#  define MUTEX_LOCK(m)   STMT_START { if (*m) mutex_lock(*m);   } STMT_END
#  undef  MUTEX_UNLOCK
#  define MUTEX_UNLOCK(m) STMT_START { if (*m) mutex_unlock(*m); } STMT_END
#endif

#ifndef PTRSIZE
#  define PTRSIZE	sizeof(void*)
#endif

#ifndef BITS_IN_PTR
#  define BITS_IN_PTR (8*PTRSIZE)
#endif

/*
 * nextf[i] is the pointer to the next free block of size 2^i.  The
 * smallest allocatable block is 8 bytes.  The overhead information
 * precedes the data area returned to the user.
 */
#define	NBUCKETS (BITS_IN_PTR*BUCKETS_PER_POW2 + 1)
static	union overhead *nextf[NBUCKETS];

#if defined(PURIFY) && !defined(USE_PERL_SBRK)
#  define USE_PERL_SBRK
#endif

#ifdef USE_PERL_SBRK
# define sbrk(a) Perl_sbrk(a)
Malloc_t Perl_sbrk (int size);
#else
# ifndef HAS_SBRK_PROTO /* <unistd.h> usually takes care of this */
extern	Malloc_t sbrk(int);
# endif
#endif

#ifndef MIN_SBRK_FRAC1000	/* Backward compatibility */
#  define MIN_SBRK_FRAC1000	(MIN_SBRK_FRAC * 10)
#endif

#ifndef START_EXTERN_C
#  ifdef __cplusplus
#    define START_EXTERN_C	extern "C" {
#  else
#    define START_EXTERN_C
#  endif
#endif

#ifndef END_EXTERN_C
#  ifdef __cplusplus
#    define END_EXTERN_C		};
#  else
#    define END_EXTERN_C
#  endif
#endif

#include "malloc_ctl.h"

#ifndef NO_MALLOC_DYNAMIC_CFG
#  define PERL_MALLOC_OPT_CHARS "FMfAPGdac"

#  ifndef FILL_DEAD_DEFAULT
#    define FILL_DEAD_DEFAULT	1
#  endif
#  ifndef FILL_ALIVE_DEFAULT
#    define FILL_ALIVE_DEFAULT	1
#  endif
#  ifndef FILL_CHECK_DEFAULT
#    define FILL_CHECK_DEFAULT	1
#  endif

static IV MallocCfg[MallocCfg_last] = {
  FIRST_SBRK,
  MIN_SBRK,
  MIN_SBRK_FRAC,
  SBRK_ALLOW_FAILURES,
  SBRK_FAILURE_PRICE,
  SBRK_ALLOW_FAILURES * SBRK_FAILURE_PRICE,	/* sbrk_goodness */
  FILL_DEAD_DEFAULT,	/* FILL_DEAD */
  FILL_ALIVE_DEFAULT,	/* FILL_ALIVE */
  FILL_CHECK_DEFAULT,	/* FILL_CHECK */
  0,			/* MallocCfg_skip_cfg_env */
  0,			/* MallocCfg_cfg_env_read */
  0,			/* MallocCfg_emergency_buffer_size */
  0,			/* MallocCfg_emergency_buffer_prepared_size */
  0			/* MallocCfg_emergency_buffer_last_req */
};
IV *MallocCfg_ptr = MallocCfg;

static char* MallocCfgP[MallocCfg_last] = {
  0,			/* MallocCfgP_emergency_buffer */
  0,			/* MallocCfgP_emergency_buffer_prepared */
};
char **MallocCfgP_ptr = MallocCfgP;

#  undef MIN_SBRK
#  undef FIRST_SBRK
#  undef MIN_SBRK_FRAC1000
#  undef SBRK_ALLOW_FAILURES
#  undef SBRK_FAILURE_PRICE

#  define MIN_SBRK		MallocCfg[MallocCfg_MIN_SBRK]
#  define FIRST_SBRK		MallocCfg[MallocCfg_FIRST_SBRK]
#  define MIN_SBRK_FRAC1000	MallocCfg[MallocCfg_MIN_SBRK_FRAC1000]
#  define SBRK_ALLOW_FAILURES	MallocCfg[MallocCfg_SBRK_ALLOW_FAILURES]
#  define SBRK_FAILURE_PRICE	MallocCfg[MallocCfg_SBRK_FAILURE_PRICE]

#  define sbrk_goodness		MallocCfg[MallocCfg_sbrk_goodness]

#  define emergency_buffer_size	MallocCfg[MallocCfg_emergency_buffer_size]
#  define emergency_buffer_last_req	MallocCfg[MallocCfg_emergency_buffer_last_req]

#  define FILL_DEAD		MallocCfg[MallocCfg_filldead]
#  define FILL_ALIVE		MallocCfg[MallocCfg_fillalive]
#  define FILL_CHECK_CFG	MallocCfg[MallocCfg_fillcheck]
#  define FILL_CHECK		(FILL_DEAD && FILL_CHECK_CFG)

#  define emergency_buffer	MallocCfgP[MallocCfgP_emergency_buffer]
#  define emergency_buffer_prepared	MallocCfgP[MallocCfgP_emergency_buffer_prepared]

#else	/* defined(NO_MALLOC_DYNAMIC_CFG) */

#  define FILL_DEAD	1
#  define FILL_ALIVE	1
#  define FILL_CHECK	1
static int sbrk_goodness = SBRK_ALLOW_FAILURES * SBRK_FAILURE_PRICE;

#  define NO_PERL_MALLOC_ENV

#endif

#ifdef DEBUGGING_MSTATS
/*
 * nmalloc[i] is the difference between the number of mallocs and frees
 * for a given block size.
 */
static	u_int nmalloc[NBUCKETS];
static  u_int sbrk_slack;
static  u_int start_slack;
#else	/* !( defined DEBUGGING_MSTATS ) */
#  define sbrk_slack	0
#endif

static	u_int goodsbrk;

#ifdef PERL_EMERGENCY_SBRK

#  ifndef BIG_SIZE
#    define BIG_SIZE (1<<16)		/* 64K */
#  endif

#  ifdef NO_MALLOC_DYNAMIC_CFG
static MEM_SIZE emergency_buffer_size;
	/* 0 if the last request for more memory succeeded.
	   Otherwise the size of the failing request. */
static MEM_SIZE emergency_buffer_last_req;
static char *emergency_buffer;
static char *emergency_buffer_prepared;
#  endif

#  ifndef emergency_sbrk_croak
#    define emergency_sbrk_croak	croak2
#  endif

static char *
perl_get_emergency_buffer(IV *size)
{
    dTHX;
    /* First offense, give a possibility to recover by dieing. */
    /* No malloc involved here: */
    SV *sv;
    char *pv;
    GV **gvp = (GV**)hv_fetchs(PL_defstash, "^M", FALSE);

    if (!gvp) gvp = (GV**)hv_fetchs(PL_defstash, "\015", FALSE);
    if (!gvp || !(sv = GvSV(*gvp)) || !SvPOK(sv) 
        || (SvLEN(sv) < (1<<LOG_OF_MIN_ARENA) - M_OVERHEAD))
        return NULL;		/* Now die die die... */
    /* Got it, now detach SvPV: */
    pv = SvPV_nolen(sv);
    /* Check alignment: */
    if ((PTR2UV(pv) - sizeof(union overhead)) & (NEEDED_ALIGNMENT - 1)) {
        PerlIO_puts(PerlIO_stderr(),"Bad alignment of $^M!\n");
        return NULL;		/* die die die */
    }

    SvPOK_off(sv);
    SvPV_set(sv, NULL);
    SvCUR_set(sv, 0);
    SvLEN_set(sv, 0);
    *size = malloced_size(pv) + M_OVERHEAD;
    return pv - sizeof(union overhead);
}
#  define PERL_GET_EMERGENCY_BUFFER(p)	perl_get_emergency_buffer(p)

#  ifndef NO_MALLOC_DYNAMIC_CFG
static char *
get_emergency_buffer(IV *size)
{
    char *pv = emergency_buffer_prepared;

    *size = MallocCfg[MallocCfg_emergency_buffer_prepared_size];
    emergency_buffer_prepared = 0;
    MallocCfg[MallocCfg_emergency_buffer_prepared_size] = 0;
    return pv;
}

#    define GET_EMERGENCY_BUFFER(p)	get_emergency_buffer(p)
#  else		/* NO_MALLOC_DYNAMIC_CFG */
#    define GET_EMERGENCY_BUFFER(p)	NULL
#  endif

static Malloc_t
emergency_sbrk(MEM_SIZE size)
{
    MEM_SIZE rsize = (((size - 1)>>LOG_OF_MIN_ARENA) + 1)<<LOG_OF_MIN_ARENA;

    if (size >= BIG_SIZE
	&& (!emergency_buffer_last_req ||
	    (size < (MEM_SIZE)emergency_buffer_last_req))) {
	/* Give the possibility to recover, but avoid an infinite cycle. */
	MALLOC_UNLOCK;
	emergency_buffer_last_req = size;
	emergency_sbrk_croak("Out of memory during \"large\" request for %"UVuf" bytes, total sbrk() is %"UVuf" bytes", (UV)size, (UV)(goodsbrk + sbrk_slack));
    }

    if ((MEM_SIZE)emergency_buffer_size >= rsize) {
	char *old = emergency_buffer;
	
	emergency_buffer_size -= rsize;
	emergency_buffer += rsize;
	return old;
    } else {		
	/* First offense, give a possibility to recover by dieing. */
	/* No malloc involved here: */
	IV Size;
	char *pv = GET_EMERGENCY_BUFFER(&Size);
	int have = 0;

	if (emergency_buffer_size) {
	    add_to_chain(emergency_buffer, emergency_buffer_size, 0);
	    emergency_buffer_size = 0;
	    emergency_buffer = NULL;
	    have = 1;
	}

	if (!pv)
	    pv = PERL_GET_EMERGENCY_BUFFER(&Size);
	if (!pv) {
	    if (have)
		goto do_croak;
	    return (char *)-1;		/* Now die die die... */
	}

	/* Check alignment: */
	if (PTR2UV(pv) & (NEEDED_ALIGNMENT - 1)) {
	    dTHX;

	    PerlIO_puts(PerlIO_stderr(),"Bad alignment of $^M!\n");
	    return (char *)-1;		/* die die die */
	}

	emergency_buffer = pv;
	emergency_buffer_size = Size;
    }
  do_croak:
    MALLOC_UNLOCK;
    emergency_sbrk_croak("Out of memory during request for %"UVuf" bytes, total sbrk() is %"UVuf" bytes", (UV)size, (UV)(goodsbrk + sbrk_slack));
    NOT_REACHED; /* NOTREACHED */
    return NULL;
}

#else /*  !defined(PERL_EMERGENCY_SBRK) */
#  define emergency_sbrk(size)	-1
#endif	/* defined PERL_EMERGENCY_SBRK */

/* Don't use PerlIO buffered writes as they allocate memory. */
#define MYMALLOC_WRITE2STDERR(s) PERL_UNUSED_RESULT(PerlLIO_write(PerlIO_fileno(PerlIO_stderr()),s,strlen(s)))

#ifdef DEBUGGING
#undef ASSERT
#define	ASSERT(p,diag)   if (!(p)) botch(diag,STRINGIFY(p),__FILE__,__LINE__);

static void
botch(const char *diag, const char *s, const char *file, int line)
{
    dVAR;
    dTHX;
    if (!(PERL_MAYBE_ALIVE && PERL_GET_THX))
	goto do_write;
    else {
	if (PerlIO_printf(PerlIO_stderr(),
			  "assertion botched (%s?): %s %s:%d\n",
			  diag, s, file, line) != 0) {
	 do_write:		/* Can be initializing interpreter */
	    MYMALLOC_WRITE2STDERR("assertion botched (");
	    MYMALLOC_WRITE2STDERR(diag);
	    MYMALLOC_WRITE2STDERR("?): ");
	    MYMALLOC_WRITE2STDERR(s);
	    MYMALLOC_WRITE2STDERR(" (");
	    MYMALLOC_WRITE2STDERR(file);
	    MYMALLOC_WRITE2STDERR(":");
	    {
	      char linebuf[10];
	      char *s = linebuf + sizeof(linebuf) - 1;
	      int n = line;
	      *s = 0;
	      do {
		*--s = '0' + (n % 10);
	      } while (n /= 10);
	      MYMALLOC_WRITE2STDERR(s);
	    }
	    MYMALLOC_WRITE2STDERR(")\n");
	}
	PerlProc_abort();
    }
}
#else
#define	ASSERT(p, diag)
#endif

#ifdef MALLOC_FILL
/* Fill should be long enough to cover long */
static void
fill_pat_4bytes(unsigned char *s, size_t nbytes, const unsigned char *fill)
{
    unsigned char *e = s + nbytes;
    long *lp;
    const long lfill = *(long*)fill;

    if (PTR2UV(s) & (sizeof(long)-1)) {		/* Align the pattern */
	int shift = sizeof(long) - (PTR2UV(s) & (sizeof(long)-1));
	unsigned const char *f = fill + sizeof(long) - shift;
	unsigned char *e1 = s + shift;

	while (s < e1)
	    *s++ = *f++;
    }
    lp = (long*)s;
    while ((unsigned char*)(lp + 1) <= e)
	*lp++ = lfill;
    s = (unsigned char*)lp;
    while (s < e)
	*s++ = *fill++;
}
/* Just malloc()ed */
static const unsigned char fill_feedadad[] =
 {0xFE, 0xED, 0xAD, 0xAD, 0xFE, 0xED, 0xAD, 0xAD,
  0xFE, 0xED, 0xAD, 0xAD, 0xFE, 0xED, 0xAD, 0xAD};
/* Just free()ed */
static const unsigned char fill_deadbeef[] =
 {0xDE, 0xAD, 0xBE, 0xEF, 0xDE, 0xAD, 0xBE, 0xEF,
  0xDE, 0xAD, 0xBE, 0xEF, 0xDE, 0xAD, 0xBE, 0xEF};
#  define FILL_DEADBEEF(s, n)	\
	(void)(FILL_DEAD?  (fill_pat_4bytes((s), (n), fill_deadbeef), 0) : 0)
#  define FILL_FEEDADAD(s, n)	\
	(void)(FILL_ALIVE? (fill_pat_4bytes((s), (n), fill_feedadad), 0) : 0)
#else
#  define FILL_DEADBEEF(s, n)	((void)0)
#  define FILL_FEEDADAD(s, n)	((void)0)
#  undef MALLOC_FILL_CHECK
#endif

#ifdef MALLOC_FILL_CHECK
static int
cmp_pat_4bytes(unsigned char *s, size_t nbytes, const unsigned char *fill)
{
    unsigned char *e = s + nbytes;
    long *lp;
    const long lfill = *(long*)fill;

    if (PTR2UV(s) & (sizeof(long)-1)) {		/* Align the pattern */
	int shift = sizeof(long) - (PTR2UV(s) & (sizeof(long)-1));
	unsigned const char *f = fill + sizeof(long) - shift;
	unsigned char *e1 = s + shift;

	while (s < e1)
	    if (*s++ != *f++)
		return 1;
    }
    lp = (long*)s;
    while ((unsigned char*)(lp + 1) <= e)
	if (*lp++ != lfill)
	    return 1;
    s = (unsigned char*)lp;
    while (s < e)
	if (*s++ != *fill++)
	    return 1;
    return 0;
}
#  define FILLCHECK_DEADBEEF(s, n)					\
	ASSERT(!FILL_CHECK || !cmp_pat_4bytes(s, n, fill_deadbeef),	\
	       "free()ed/realloc()ed-away memory was overwritten")
#else
#  define FILLCHECK_DEADBEEF(s, n)	((void)0)
#endif

STATIC int
S_adjust_size_and_find_bucket(size_t *nbytes_p)
{
	MEM_SIZE shiftr;
	int bucket;
	size_t nbytes;

	PERL_ARGS_ASSERT_ADJUST_SIZE_AND_FIND_BUCKET;

	nbytes = *nbytes_p;

	/*
	 * Convert amount of memory requested into
	 * closest block size stored in hash buckets
	 * which satisfies request.  Account for
	 * space used per block for accounting.
	 */
#ifdef PACK_MALLOC
#  ifdef SMALL_BUCKET_VIA_TABLE
	if (nbytes == 0)
	    bucket = MIN_BUCKET;
	else if (nbytes <= SIZE_TABLE_MAX) {
	    bucket = bucket_of[(nbytes - 1) >> BUCKET_TABLE_SHIFT];
	} else
#  else
	if (nbytes == 0)
	    nbytes = 1;
	if (nbytes <= MAX_POW2_ALGO) goto do_shifts;
	else
#  endif
#endif 
	{
	    POW2_OPTIMIZE_ADJUST(nbytes);
	    nbytes += M_OVERHEAD;
	    nbytes = (nbytes + 3) &~ 3; 
#if defined(PACK_MALLOC) && !defined(SMALL_BUCKET_VIA_TABLE)
	  do_shifts:
#endif
	    shiftr = (nbytes - 1) >> START_SHIFT;
	    bucket = START_SHIFTS_BUCKET;
	    /* apart from this loop, this is O(1) */
	    while (shiftr >>= 1)
  		bucket += BUCKETS_PER_POW2;
	}
	*nbytes_p = nbytes;
	return bucket;
}

Malloc_t
Perl_malloc(size_t nbytes)
{
        dVAR;
  	union overhead *p;
  	int bucket;

#if defined(DEBUGGING) || defined(RCHECK)
	MEM_SIZE size = nbytes;
#endif

	BARK_64K_LIMIT("Allocation",nbytes,nbytes);
#ifdef DEBUGGING
	if ((long)nbytes < 0)
	    croak("%s", "panic: malloc");
#endif

	bucket = adjust_size_and_find_bucket(&nbytes);
	MALLOC_LOCK;
	/*
	 * If nothing in hash bucket right now,
	 * request more memory from the system.
	 */
  	if (nextf[bucket] == NULL)    
  		morecore(bucket);
  	if ((p = nextf[bucket]) == NULL) {
		MALLOC_UNLOCK;
		{
		    dTHX;
		    if (!PL_nomemok) {
#if defined(PLAIN_MALLOC) && defined(NO_FANCY_MALLOC)
		        MYMALLOC_WRITE2STDERR("Out of memory!\n");
#else
			char buff[80];
			char *eb = buff + sizeof(buff) - 1;
			char *s = eb;
			size_t n = nbytes;

			MYMALLOC_WRITE2STDERR("Out of memory during request for ");
#if defined(DEBUGGING) || defined(RCHECK)
			n = size;
#endif
			*s = 0;			
			do {
			    *--s = '0' + (n % 10);
			} while (n /= 10);
			MYMALLOC_WRITE2STDERR(s);
			MYMALLOC_WRITE2STDERR(" bytes, total sbrk() is ");
			s = eb;
			n = goodsbrk + sbrk_slack;
			do {
			    *--s = '0' + (n % 10);
			} while (n /= 10);
			MYMALLOC_WRITE2STDERR(s);
			MYMALLOC_WRITE2STDERR(" bytes!\n");
#endif /* defined(PLAIN_MALLOC) && defined(NO_FANCY_MALLOC) */
			my_exit(1);
		    }
		}
  		return (NULL);
	}

	/* remove from linked list */
#ifdef DEBUGGING
	if ( (PTR2UV(p) & (MEM_ALIGNBYTES - 1))
						/* Can't get this low */
	     || (p && PTR2UV(p) < (1<<LOG_OF_MIN_ARENA)) ) {
	    dTHX;
	    PerlIO_printf(PerlIO_stderr(),
			  "Unaligned pointer in the free chain 0x%"UVxf"\n",
			  PTR2UV(p));
	}
	if ( (PTR2UV(p->ov_next) & (MEM_ALIGNBYTES - 1))
	     || (p->ov_next && PTR2UV(p->ov_next) < (1<<LOG_OF_MIN_ARENA)) ) {
	    dTHX;
	    PerlIO_printf(PerlIO_stderr(),
			  "Unaligned \"next\" pointer in the free "
			  "chain 0x%"UVxf" at 0x%"UVxf"\n",
			  PTR2UV(p->ov_next), PTR2UV(p));
	}
#endif
  	nextf[bucket] = p->ov_next;

	MALLOC_UNLOCK;

	DEBUG_m(PerlIO_printf(Perl_debug_log,
			      "0x%"UVxf": (%05lu) malloc %ld bytes\n",
			      PTR2UV((Malloc_t)(p + CHUNK_SHIFT)), (unsigned long)(PL_an++),
			      (long)size));

	FILLCHECK_DEADBEEF((unsigned char*)(p + CHUNK_SHIFT),
			   BUCKET_SIZE_REAL(bucket) + RMAGIC_SZ);

#ifdef IGNORE_SMALL_BAD_FREE
	if (bucket >= FIRST_BUCKET_WITH_CHECK)
#endif 
	    OV_MAGIC(p, bucket) = MAGIC;
#ifndef PACK_MALLOC
	OV_INDEX(p) = bucket;
#endif
#ifdef RCHECK
	/*
	 * Record allocated size of block and
	 * bound space with magic numbers.
	 */
	p->ov_rmagic = RMAGIC;
	if (bucket <= MAX_SHORT_BUCKET) {
	    int i;
	    
	    nbytes = size + M_OVERHEAD; 
	    p->ov_size = nbytes - 1;
	    if ((i = nbytes & (RMAGIC_SZ-1))) {
		i = RMAGIC_SZ - i;
		while (i--) /* nbytes - RMAGIC_SZ is end of alloced area */
		    ((caddr_t)p + nbytes - RMAGIC_SZ)[i] = RMAGIC_C;
	    }
	    /* Same at RMAGIC_SZ-aligned RMAGIC */
	    nbytes = (nbytes + RMAGIC_SZ - 1) & ~(RMAGIC_SZ - 1);
	    ((u_int *)((caddr_t)p + nbytes))[-1] = RMAGIC;
	}
	FILL_FEEDADAD((unsigned char *)(p + CHUNK_SHIFT), size);
#endif
  	return ((Malloc_t)(p + CHUNK_SHIFT));
}

static char *last_sbrk_top;
static char *last_op;			/* This arena can be easily extended. */
static MEM_SIZE sbrked_remains;

#ifdef DEBUGGING_MSTATS
static int sbrks;
#endif 

struct chunk_chain_s {
    struct chunk_chain_s *next;
    MEM_SIZE size;
};
static struct chunk_chain_s *chunk_chain;
static int n_chunks;
static char max_bucket;

/* Cutoff a piece of one of the chunks in the chain.  Prefer smaller chunk. */
static void *
get_from_chain(MEM_SIZE size)
{
    struct chunk_chain_s *elt = chunk_chain, **oldp = &chunk_chain;
    struct chunk_chain_s **oldgoodp = NULL;
    long min_remain = LONG_MAX;

    while (elt) {
	if (elt->size >= size) {
	    long remains = elt->size - size;
	    if (remains >= 0 && remains < min_remain) {
		oldgoodp = oldp;
		min_remain = remains;
	    }
	    if (remains == 0) {
		break;
	    }
	}
	oldp = &( elt->next );
	elt = elt->next;
    }
    if (!oldgoodp) return NULL;
    if (min_remain) {
	void *ret = *oldgoodp;
	struct chunk_chain_s *next = (*oldgoodp)->next;
	
	*oldgoodp = (struct chunk_chain_s *)((char*)ret + size);
	(*oldgoodp)->size = min_remain;
	(*oldgoodp)->next = next;
	return ret;
    } else {
	void *ret = *oldgoodp;
	*oldgoodp = (*oldgoodp)->next;
	n_chunks--;
	return ret;
    }
}

static void
add_to_chain(void *p, MEM_SIZE size, MEM_SIZE chip)
{
    struct chunk_chain_s *next = chunk_chain;
    char *cp = (char*)p;
    
    cp += chip;
    chunk_chain = (struct chunk_chain_s *)cp;
    chunk_chain->size = size - chip;
    chunk_chain->next = next;
    n_chunks++;
}

static void *
get_from_bigger_buckets(int bucket, MEM_SIZE size)
{
    int price = 1;
    static int bucketprice[NBUCKETS];
    while (bucket <= max_bucket) {
	/* We postpone stealing from bigger buckets until we want it
	   often enough. */
	if (nextf[bucket] && bucketprice[bucket]++ >= price) {
	    /* Steal it! */
	    void *ret = (void*)(nextf[bucket] - 1 + CHUNK_SHIFT);
	    bucketprice[bucket] = 0;
	    if (((char*)nextf[bucket]) - M_OVERHEAD == last_op) {
		last_op = NULL;		/* Disable optimization */
	    }
	    nextf[bucket] = nextf[bucket]->ov_next;
#ifdef DEBUGGING_MSTATS
	    nmalloc[bucket]--;
	    start_slack -= M_OVERHEAD;
#endif 
	    add_to_chain(ret, (BUCKET_SIZE_NO_SURPLUS(bucket) +
			       POW2_OPTIMIZE_SURPLUS(bucket)), 
			 size);
	    return ret;
	}
	bucket++;
    }
    return NULL;
}

static union overhead *
getpages(MEM_SIZE needed, int *nblksp, int bucket)
{
    dVAR;
    /* Need to do (possibly expensive) system call. Try to
       optimize it for rare calling. */
    MEM_SIZE require = needed - sbrked_remains;
    char *cp;
    union overhead *ovp;
    MEM_SIZE slack = 0;

    if (sbrk_goodness > 0) {
	if (!last_sbrk_top && require < (MEM_SIZE)FIRST_SBRK) 
	    require = FIRST_SBRK;
	else if (require < (MEM_SIZE)MIN_SBRK) require = MIN_SBRK;

	if (require < (Size_t)(goodsbrk * MIN_SBRK_FRAC1000 / 1000))
	    require = goodsbrk * MIN_SBRK_FRAC1000 / 1000;
	require = ((require - 1 + MIN_SBRK) / MIN_SBRK) * MIN_SBRK;
    } else {
	require = needed;
	last_sbrk_top = 0;
	sbrked_remains = 0;
    }

    DEBUG_m(PerlIO_printf(Perl_debug_log, 
			  "sbrk(%ld) for %ld-byte-long arena\n",
			  (long)require, (long) needed));
    cp = (char *)sbrk(require);
#ifdef DEBUGGING_MSTATS
    sbrks++;
#endif 
    if (cp == last_sbrk_top) {
	/* Common case, anything is fine. */
	sbrk_goodness++;
	ovp = (union overhead *) (cp - sbrked_remains);
	last_op = cp - sbrked_remains;
	sbrked_remains = require - (needed - sbrked_remains);
    } else if (cp == (char *)-1) { /* no more room! */
	ovp = (union overhead *)emergency_sbrk(needed);
	if (ovp == (union overhead *)-1)
	    return 0;
	if (((char*)ovp) > last_op) {	/* Cannot happen with current emergency_sbrk() */
	    last_op = 0;
	}
	return ovp;
    } else {			/* Non-continuous or first sbrk(). */
	long add = sbrked_remains;
	char *newcp;

	if (sbrked_remains) {	/* Put rest into chain, we
				   cannot use it right now. */
	    add_to_chain((void*)(last_sbrk_top - sbrked_remains),
			 sbrked_remains, 0);
	}

	/* Second, check alignment. */
	slack = 0;

	/* WANTED_ALIGNMENT may be more than NEEDED_ALIGNMENT, but this may
	   improve performance of memory access. */
	if (PTR2UV(cp) & (WANTED_ALIGNMENT - 1)) { /* Not aligned. */
	    slack = WANTED_ALIGNMENT - (PTR2UV(cp) & (WANTED_ALIGNMENT - 1));
	    add += slack;
	}
		
	if (add) {
	    DEBUG_m(PerlIO_printf(Perl_debug_log, 
				  "sbrk(%ld) to fix non-continuous/off-page sbrk:\n\t%ld for alignment,\t%ld were assumed to come from the tail of the previous sbrk\n",
				  (long)add, (long) slack,
				  (long) sbrked_remains));
	    newcp = (char *)sbrk(add);
#if defined(DEBUGGING_MSTATS)
	    sbrks++;
	    sbrk_slack += add;
#endif
	    if (newcp != cp + require) {
		/* Too bad: even rounding sbrk() is not continuous.*/
		DEBUG_m(PerlIO_printf(Perl_debug_log, 
				      "failed to fix bad sbrk()\n"));
#ifdef PACK_MALLOC
		if (slack) {
		    MALLOC_UNLOCK;
		    fatalcroak("panic: Off-page sbrk\n");
		}
#endif
		if (sbrked_remains) {
		    /* Try again. */
#if defined(DEBUGGING_MSTATS)
		    sbrk_slack += require;
#endif
		    require = needed;
		    DEBUG_m(PerlIO_printf(Perl_debug_log, 
					  "straight sbrk(%ld)\n",
					  (long)require));
		    cp = (char *)sbrk(require);
#ifdef DEBUGGING_MSTATS
		    sbrks++;
#endif 
		    if (cp == (char *)-1)
			return 0;
		}
		sbrk_goodness = -1;	/* Disable optimization!
				   Continue with not-aligned... */
	    } else {
		cp += slack;
		require += sbrked_remains;
	    }
	}

	if (last_sbrk_top) {
	    sbrk_goodness -= SBRK_FAILURE_PRICE;
	}

	ovp = (union overhead *) cp;
	/*
	 * Round up to minimum allocation size boundary
	 * and deduct from block count to reflect.
	 */

#  if NEEDED_ALIGNMENT > MEM_ALIGNBYTES
	if (PTR2UV(ovp) & (NEEDED_ALIGNMENT - 1))
	    fatalcroak("Misalignment of sbrk()\n");
	else
#  endif
	if (PTR2UV(ovp) & (MEM_ALIGNBYTES - 1)) {
	    DEBUG_m(PerlIO_printf(Perl_debug_log, 
				  "fixing sbrk(): %d bytes off machine alignment\n",
				  (int)(PTR2UV(ovp) & (MEM_ALIGNBYTES - 1))));
	    ovp = INT2PTR(union overhead *,(PTR2UV(ovp) + MEM_ALIGNBYTES) &
				     (MEM_ALIGNBYTES - 1));
	    (*nblksp)--;
# if defined(DEBUGGING_MSTATS)
	    /* This is only approx. if TWO_POT_OPTIMIZE: */
	    sbrk_slack += (1 << (bucket >> BUCKET_POW2_SHIFT));
# endif
	}
	;				/* Finish "else" */
	sbrked_remains = require - needed;
	last_op = cp;
    }
#if !defined(PLAIN_MALLOC) && !defined(NO_FANCY_MALLOC)
    emergency_buffer_last_req = 0;
#endif
    last_sbrk_top = cp + require;
#ifdef DEBUGGING_MSTATS
    goodsbrk += require;
#endif	
    return ovp;
}

static int
getpages_adjacent(MEM_SIZE require)
{	    
    if (require <= sbrked_remains) {
	sbrked_remains -= require;
    } else {
	char *cp;

	require -= sbrked_remains;
	/* We do not try to optimize sbrks here, we go for place. */
	cp = (char*) sbrk(require);
#ifdef DEBUGGING_MSTATS
	sbrks++;
	goodsbrk += require;
#endif 
	if (cp == last_sbrk_top) {
	    sbrked_remains = 0;
	    last_sbrk_top = cp + require;
	} else {
	    if (cp == (char*)-1) {	/* Out of memory */
#ifdef DEBUGGING_MSTATS
		goodsbrk -= require;
#endif
		return 0;
	    }
	    /* Report the failure: */
	    if (sbrked_remains)
		add_to_chain((void*)(last_sbrk_top - sbrked_remains),
			     sbrked_remains, 0);
	    add_to_chain((void*)cp, require, 0);
	    sbrk_goodness -= SBRK_FAILURE_PRICE;
	    sbrked_remains = 0;
	    last_sbrk_top = 0;
	    last_op = 0;
	    return 0;
	}
    }
	    
    return 1;
}

/*
 * Allocate more memory to the indicated bucket.
 */
static void
morecore(int bucket)
{
        dVAR;
  	union overhead *ovp;
  	int rnu;       /* 2^rnu bytes will be requested */
  	int nblks;		/* become nblks blocks of the desired size */
	MEM_SIZE siz, needed;
	static int were_called = 0;

  	if (nextf[bucket])
  		return;
#ifndef NO_PERL_MALLOC_ENV
	if (!were_called) {
	    /* It's the our first time.  Initialize ourselves */
	    were_called = 1;	/* Avoid a loop */
	    if (!MallocCfg[MallocCfg_skip_cfg_env]) {
		char *s = getenv("PERL_MALLOC_OPT"), *t = s, *off;
		const char *opts = PERL_MALLOC_OPT_CHARS;
		int changed = 0;

		while ( t && t[0] && t[1] == '='
			&& ((off = strchr(opts, *t))) ) {
		    IV val = 0;

		    t += 2;
		    while (*t <= '9' && *t >= '0')
			val = 10*val + *t++ - '0';
		    if (!*t || *t == ';') {
			if (MallocCfg[off - opts] != val)
			    changed = 1;
			MallocCfg[off - opts] = val;
			if (*t)
			    t++;
		    }
		}
		if (t && *t) {
		    dTHX;
		    MYMALLOC_WRITE2STDERR("Unrecognized part of PERL_MALLOC_OPT: \"");
		    MYMALLOC_WRITE2STDERR(t);
		    MYMALLOC_WRITE2STDERR("\"\n");
		}
		if (changed)
		    MallocCfg[MallocCfg_cfg_env_read] = 1;
	    }
	}
#endif
	if (bucket == sizeof(MEM_SIZE)*8*BUCKETS_PER_POW2) {
	    MALLOC_UNLOCK;
	    croak("%s", "Out of memory during ridiculously large request");
	}
	if (bucket > max_bucket)
	    max_bucket = bucket;

  	rnu = ( (bucket <= (LOG_OF_MIN_ARENA << BUCKET_POW2_SHIFT)) 
		? LOG_OF_MIN_ARENA 
		: (bucket >> BUCKET_POW2_SHIFT) );
	/* This may be overwritten later: */
  	nblks = 1 << (rnu - (bucket >> BUCKET_POW2_SHIFT)); /* how many blocks to get */
	needed = ((MEM_SIZE)1 << rnu) + POW2_OPTIMIZE_SURPLUS(bucket);
	if (nextf[rnu << BUCKET_POW2_SHIFT]) { /* 2048b bucket. */
	    ovp = nextf[rnu << BUCKET_POW2_SHIFT] - 1 + CHUNK_SHIFT;
	    nextf[rnu << BUCKET_POW2_SHIFT]
		= nextf[rnu << BUCKET_POW2_SHIFT]->ov_next;
#ifdef DEBUGGING_MSTATS
	    nmalloc[rnu << BUCKET_POW2_SHIFT]--;
	    start_slack -= M_OVERHEAD;
#endif 
	    DEBUG_m(PerlIO_printf(Perl_debug_log, 
				  "stealing %ld bytes from %ld arena\n",
				  (long) needed, (long) rnu << BUCKET_POW2_SHIFT));
	} else if (chunk_chain 
		   && (ovp = (union overhead*) get_from_chain(needed))) {
	    DEBUG_m(PerlIO_printf(Perl_debug_log, 
				  "stealing %ld bytes from chain\n",
				  (long) needed));
	} else if ( (ovp = (union overhead*)
		     get_from_bigger_buckets((rnu << BUCKET_POW2_SHIFT) + 1,
					     needed)) ) {
	    DEBUG_m(PerlIO_printf(Perl_debug_log, 
				  "stealing %ld bytes from bigger buckets\n",
				  (long) needed));
	} else if (needed <= sbrked_remains) {
	    ovp = (union overhead *)(last_sbrk_top - sbrked_remains);
	    sbrked_remains -= needed;
	    last_op = (char*)ovp;
	} else 
	    ovp = getpages(needed, &nblks, bucket);

	if (!ovp)
	    return;
	FILL_DEADBEEF((unsigned char*)ovp, needed);

	/*
	 * Add new memory allocated to that on
	 * free list for this hash bucket.
	 */
  	siz = BUCKET_SIZE_NO_SURPLUS(bucket); /* No surplus if nblks > 1 */
#ifdef PACK_MALLOC
	*(u_char*)ovp = bucket;	/* Fill index. */
	if (bucket <= MAX_PACKED) {
	    ovp = (union overhead *) ((char*)ovp + BLK_SHIFT(bucket));
	    nblks = N_BLKS(bucket);
#  ifdef DEBUGGING_MSTATS
	    start_slack += BLK_SHIFT(bucket);
#  endif
	} else if (bucket < LOG_OF_MIN_ARENA * BUCKETS_PER_POW2) {
	    ovp = (union overhead *) ((char*)ovp + BLK_SHIFT(bucket));
	    siz -= sizeof(union overhead);
	} else ovp++;		/* One chunk per block. */
#endif /* PACK_MALLOC */
  	nextf[bucket] = ovp;
#ifdef DEBUGGING_MSTATS
	nmalloc[bucket] += nblks;
	if (bucket > MAX_PACKED) {
	    start_slack += M_OVERHEAD * nblks;
	}
#endif 

  	while (--nblks > 0) {
		ovp->ov_next = (union overhead *)((caddr_t)ovp + siz);
		ovp = (union overhead *)((caddr_t)ovp + siz);
  	}
	/* Not all sbrks return zeroed memory.*/
	ovp->ov_next = (union overhead *)NULL;
#ifdef PACK_MALLOC
	if (bucket == 7*BUCKETS_PER_POW2) { /* Special case, explanation is above. */
	    union overhead *n_op = nextf[7*BUCKETS_PER_POW2]->ov_next;
	    nextf[7*BUCKETS_PER_POW2] = 
		(union overhead *)((caddr_t)nextf[7*BUCKETS_PER_POW2] 
				   - sizeof(union overhead));
	    nextf[7*BUCKETS_PER_POW2]->ov_next = n_op;
	}
#endif /* !PACK_MALLOC */
}

Free_t
Perl_mfree(Malloc_t where)
{
        dVAR;
  	MEM_SIZE size;
	union overhead *ovp;
	char *cp = (char*)where;
#ifdef PACK_MALLOC
	u_char bucket;
#endif 

	DEBUG_m(PerlIO_printf(Perl_debug_log, 
			      "0x%"UVxf": (%05lu) free\n",
			      PTR2UV(cp), (unsigned long)(PL_an++)));

	if (cp == NULL)
		return;
#ifdef DEBUGGING
	if (PTR2UV(cp) & (MEM_ALIGNBYTES - 1))
	    croak("%s", "wrong alignment in free()");
#endif
	ovp = (union overhead *)((caddr_t)cp 
				- sizeof (union overhead) * CHUNK_SHIFT);
#ifdef PACK_MALLOC
	bucket = OV_INDEX(ovp);
#endif 
#ifdef IGNORE_SMALL_BAD_FREE
	if ((bucket >= FIRST_BUCKET_WITH_CHECK) 
	    && (OV_MAGIC(ovp, bucket) != MAGIC))
#else
	if (OV_MAGIC(ovp, bucket) != MAGIC)
#endif 
	    {
		static int bad_free_warn = -1;
		if (bad_free_warn == -1) {
		    dTHX;
		    char *pbf = PerlEnv_getenv("PERL_BADFREE");
		    bad_free_warn = (pbf) ? strNE("0", pbf) : 1;
		}
		if (!bad_free_warn)
		    return;
#ifdef RCHECK
		{
		    dTHX;
		    if (!PERL_IS_ALIVE || !PL_curcop)
			Perl_ck_warner_d(aTHX_ packWARN(WARN_MALLOC), "%s free() ignored (RMAGIC, PERL_CORE)",
					 ovp->ov_rmagic == RMAGIC - 1 ?
					 "Duplicate" : "Bad");
		}
#else
		{
		    dTHX;
		    if (!PERL_IS_ALIVE || !PL_curcop)
			Perl_ck_warner_d(aTHX_ packWARN(WARN_MALLOC), "%s", "Bad free() ignored (PERL_CORE)");
		}
#endif
		return;				/* sanity */
	    }
#ifdef RCHECK
  	ASSERT(ovp->ov_rmagic == RMAGIC, "chunk's head overwrite");
	if (OV_INDEX(ovp) <= MAX_SHORT_BUCKET) {
	    int i;
	    MEM_SIZE nbytes = ovp->ov_size + 1;

	    if ((i = nbytes & (RMAGIC_SZ-1))) {
		i = RMAGIC_SZ - i;
		while (i--) {	/* nbytes - RMAGIC_SZ is end of alloced area */
		    ASSERT(((caddr_t)ovp + nbytes - RMAGIC_SZ)[i] == RMAGIC_C,
			   "chunk's tail overwrite");
		}
	    }
	    /* Same at RMAGIC_SZ-aligned RMAGIC */
	    nbytes = (nbytes + (RMAGIC_SZ-1)) & ~(RMAGIC_SZ-1);
	    ASSERT(((u_int *)((caddr_t)ovp + nbytes))[-1] == RMAGIC,
		   "chunk's tail overwrite");	    
	    FILLCHECK_DEADBEEF((unsigned char*)((caddr_t)ovp + nbytes),
			       BUCKET_SIZE(OV_INDEX(ovp)) - nbytes);
	}
	FILL_DEADBEEF((unsigned char*)(ovp+CHUNK_SHIFT),
		      BUCKET_SIZE_REAL(OV_INDEX(ovp)) + RMAGIC_SZ);
	ovp->ov_rmagic = RMAGIC - 1;
#endif
  	ASSERT(OV_INDEX(ovp) < NBUCKETS, "chunk's head overwrite");
  	size = OV_INDEX(ovp);

	MALLOC_LOCK;
	ovp->ov_next = nextf[size];
  	nextf[size] = ovp;
	MALLOC_UNLOCK;
}

/* There is no need to do any locking in realloc (with an exception of
   trying to grow in place if we are at the end of the chain).
   If somebody calls us from a different thread with the same address,
   we are sole anyway.  */

Malloc_t
Perl_realloc(void *mp, size_t nbytes)
{
        dVAR;
  	MEM_SIZE onb;
	union overhead *ovp;
  	char *res;
	int prev_bucket;
	int bucket;
	int incr;		/* 1 if does not fit, -1 if "easily" fits in a
				   smaller bucket, otherwise 0.  */
	char *cp = (char*)mp;

#ifdef DEBUGGING
	MEM_SIZE size = nbytes;

	if ((long)nbytes < 0)
	    croak("%s", "panic: realloc");
#endif

	BARK_64K_LIMIT("Reallocation",nbytes,size);
	if (!cp)
		return Perl_malloc(nbytes);

	ovp = (union overhead *)((caddr_t)cp 
				- sizeof (union overhead) * CHUNK_SHIFT);
	bucket = OV_INDEX(ovp);

#ifdef IGNORE_SMALL_BAD_FREE
	if ((bucket >= FIRST_BUCKET_WITH_CHECK) 
	    && (OV_MAGIC(ovp, bucket) != MAGIC))
#else
	if (OV_MAGIC(ovp, bucket) != MAGIC)
#endif 
	    {
		static int bad_free_warn = -1;
		if (bad_free_warn == -1) {
		    dTHX;
		    char *pbf = PerlEnv_getenv("PERL_BADFREE");
		    bad_free_warn = (pbf) ? strNE("0", pbf) : 1;
		}
		if (!bad_free_warn)
		    return NULL;
#ifdef RCHECK
		{
		    dTHX;
		    if (!PERL_IS_ALIVE || !PL_curcop)
			Perl_ck_warner_d(aTHX_ packWARN(WARN_MALLOC), "%srealloc() %signored",
					 (ovp->ov_rmagic == RMAGIC - 1 ? "" : "Bad "),
					 ovp->ov_rmagic == RMAGIC - 1
					 ? "of freed memory " : "");
		}
#else
		{
		    dTHX;
		    if (!PERL_IS_ALIVE || !PL_curcop)
			Perl_ck_warner_d(aTHX_ packWARN(WARN_MALLOC), "%s",
					 "Bad realloc() ignored");
		}
#endif
		return NULL;			/* sanity */
	    }

	onb = BUCKET_SIZE_REAL(bucket);
	/* 
	 *  avoid the copy if same size block.
	 *  We are not aggressive with boundary cases. Note that it might
	 *  (for a small number of cases) give false negative if
	 *  both new size and old one are in the bucket for
	 *  FIRST_BIG_POW2, but the new one is near the lower end.
	 *
	 *  We do not try to go to 1.5 times smaller bucket so far.
	 */
	if (nbytes > onb) incr = 1;
	else {
#ifdef DO_NOT_TRY_HARDER_WHEN_SHRINKING
	    if ( /* This is a little bit pessimal if PACK_MALLOC: */
		nbytes > ( (onb >> 1) - M_OVERHEAD )
#  ifdef TWO_POT_OPTIMIZE
		|| (bucket == FIRST_BIG_POW2 && nbytes >= LAST_SMALL_BOUND )
#  endif	
		)
#else  /* !DO_NOT_TRY_HARDER_WHEN_SHRINKING */
		prev_bucket = ( (bucket > MAX_PACKED + 1) 
				? bucket - BUCKETS_PER_POW2
				: bucket - 1);
	     if (nbytes > BUCKET_SIZE_REAL(prev_bucket))
#endif /* !DO_NOT_TRY_HARDER_WHEN_SHRINKING */
		 incr = 0;
	     else incr = -1;
	}
#ifdef STRESS_REALLOC
	goto hard_way;
#endif
	if (incr == 0) {
	  inplace_label:
#ifdef RCHECK
		/*
		 * Record new allocated size of block and
		 * bound space with magic numbers.
		 */
		if (OV_INDEX(ovp) <= MAX_SHORT_BUCKET) {
		       int i, nb = ovp->ov_size + 1;

		       if ((i = nb & (RMAGIC_SZ-1))) {
			   i = RMAGIC_SZ - i;
			   while (i--) { /* nb - RMAGIC_SZ is end of alloced area */
			       ASSERT(((caddr_t)ovp + nb - RMAGIC_SZ)[i] == RMAGIC_C, "chunk's tail overwrite");
			   }
		       }
		       /* Same at RMAGIC_SZ-aligned RMAGIC */
		       nb = (nb + (RMAGIC_SZ-1)) & ~(RMAGIC_SZ-1);
		       ASSERT(((u_int *)((caddr_t)ovp + nb))[-1] == RMAGIC,
			      "chunk's tail overwrite");
		       FILLCHECK_DEADBEEF((unsigned char*)((caddr_t)ovp + nb),
					  BUCKET_SIZE(OV_INDEX(ovp)) - nb);
		       if (nbytes > ovp->ov_size + 1 - M_OVERHEAD)
			   FILL_FEEDADAD((unsigned char*)cp + ovp->ov_size + 1 - M_OVERHEAD,
				     nbytes - (ovp->ov_size + 1 - M_OVERHEAD));
		       else
			   FILL_DEADBEEF((unsigned char*)cp + nbytes,
					 nb - M_OVERHEAD + RMAGIC_SZ - nbytes);
			/*
			 * Convert amount of memory requested into
			 * closest block size stored in hash buckets
			 * which satisfies request.  Account for
			 * space used per block for accounting.
			 */
			nbytes += M_OVERHEAD;
			ovp->ov_size = nbytes - 1;
			if ((i = nbytes & (RMAGIC_SZ-1))) {
			    i = RMAGIC_SZ - i;
			    while (i--)	/* nbytes - RMAGIC_SZ is end of alloced area */
				((caddr_t)ovp + nbytes - RMAGIC_SZ)[i]
				    = RMAGIC_C;
			}
			/* Same at RMAGIC_SZ-aligned RMAGIC */
			nbytes = (nbytes + (RMAGIC_SZ-1)) & ~(RMAGIC_SZ - 1);
			((u_int *)((caddr_t)ovp + nbytes))[-1] = RMAGIC;
		}
#endif
		res = cp;
		DEBUG_m(PerlIO_printf(Perl_debug_log, 
			      "0x%"UVxf": (%05lu) realloc %ld bytes inplace\n",
			      PTR2UV(res),(unsigned long)(PL_an++),
			      (long)size));
	} else if (incr == 1 && (cp - M_OVERHEAD == last_op) 
		   && (onb > (1 << LOG_OF_MIN_ARENA))) {
	    MEM_SIZE require, newarena = nbytes, pow;
	    int shiftr;

	    POW2_OPTIMIZE_ADJUST(newarena);
	    newarena = newarena + M_OVERHEAD;
	    /* newarena = (newarena + 3) &~ 3; */
	    shiftr = (newarena - 1) >> LOG_OF_MIN_ARENA;
	    pow = LOG_OF_MIN_ARENA + 1;
	    /* apart from this loop, this is O(1) */
	    while (shiftr >>= 1)
  		pow++;
	    newarena = (1 << pow) + POW2_OPTIMIZE_SURPLUS(pow * BUCKETS_PER_POW2);
	    require = newarena - onb - M_OVERHEAD;
	    
	    MALLOC_LOCK;
	    if (cp - M_OVERHEAD == last_op /* We *still* are the last chunk */
		&& getpages_adjacent(require)) {
#ifdef DEBUGGING_MSTATS
		nmalloc[bucket]--;
		nmalloc[pow * BUCKETS_PER_POW2]++;
#endif 	    
		if (pow * BUCKETS_PER_POW2 > (MEM_SIZE)max_bucket)
		    max_bucket = pow * BUCKETS_PER_POW2;
		*(cp - M_OVERHEAD) = pow * BUCKETS_PER_POW2; /* Fill index. */
		MALLOC_UNLOCK;
		goto inplace_label;
	    } else {
		MALLOC_UNLOCK;		
		goto hard_way;
	    }
	} else {
	  hard_way:
	    DEBUG_m(PerlIO_printf(Perl_debug_log, 
			      "0x%"UVxf": (%05lu) realloc %ld bytes the hard way\n",
			      PTR2UV(cp),(unsigned long)(PL_an++),
			      (long)size));
	    if ((res = (char*)Perl_malloc(nbytes)) == NULL)
		return (NULL);
	    if (cp != res)			/* common optimization */
		Copy(cp, res, (MEM_SIZE)(nbytes<onb?nbytes:onb), char);
	    Perl_mfree(cp);
	}
  	return ((Malloc_t)res);
}

Malloc_t
Perl_calloc(size_t elements, size_t size)
{
    long sz = elements * size;
    Malloc_t p = Perl_malloc(sz);

    if (p) {
	memset((void*)p, 0, sz);
    }
    return p;
}

char *
Perl_strdup(const char *s)
{
    MEM_SIZE l = strlen(s);
    char *s1 = (char *)Perl_malloc(l+1);

    return (char *)CopyD(s, s1, (MEM_SIZE)(l+1), char);
}

int
Perl_putenv(char *a)
{
    /* Sometimes system's putenv conflicts with my_setenv() - this is system
       malloc vs Perl's free(). */
  dTHX;
  char *var;
  char *val = a;
  MEM_SIZE l;
  char buf[80];

  while (*val && *val != '=')
      val++;
  if (!*val)
      return -1;
  l = val - a;
  if (l < sizeof(buf))
      var = buf;
  else
      var = (char *)Perl_malloc(l + 1);
  Copy(a, var, l, char);
  var[l + 1] = 0;
  my_setenv(var, val+1);
  if (var != buf)
      Perl_mfree(var);
  return 0;
}

MEM_SIZE
Perl_malloced_size(void *p)
{
    union overhead * const ovp = (union overhead *)
	((caddr_t)p - sizeof (union overhead) * CHUNK_SHIFT);
    const int bucket = OV_INDEX(ovp);

    PERL_ARGS_ASSERT_MALLOCED_SIZE;

#ifdef RCHECK
    /* The caller wants to have a complete control over the chunk,
       disable the memory checking inside the chunk.  */
    if (bucket <= MAX_SHORT_BUCKET) {
	const MEM_SIZE size = BUCKET_SIZE_REAL(bucket);
	ovp->ov_size = size + M_OVERHEAD - 1;
	*((u_int *)((caddr_t)ovp + size + M_OVERHEAD - RMAGIC_SZ)) = RMAGIC;
    }
#endif
    return BUCKET_SIZE_REAL(bucket);
}


MEM_SIZE
Perl_malloc_good_size(size_t wanted)
{
    return BUCKET_SIZE_REAL(adjust_size_and_find_bucket(&wanted));
}

#  ifdef BUCKETS_ROOT2
#    define MIN_EVEN_REPORT 6
#  else
#    define MIN_EVEN_REPORT MIN_BUCKET
#  endif 

int
Perl_get_mstats(pTHX_ perl_mstats_t *buf, int buflen, int level)
{
#ifdef DEBUGGING_MSTATS
  	int i, j;
  	union overhead *p;
	struct chunk_chain_s* nextchain;

	PERL_ARGS_ASSERT_GET_MSTATS;

  	buf->topbucket = buf->topbucket_ev = buf->topbucket_odd 
	    = buf->totfree = buf->total = buf->total_chain = 0;

	buf->minbucket = MIN_BUCKET;
	MALLOC_LOCK;
  	for (i = MIN_BUCKET ; i < NBUCKETS; i++) {
  		for (j = 0, p = nextf[i]; p; p = p->ov_next, j++)
  			;
		if (i < buflen) {
		    buf->nfree[i] = j;
		    buf->ntotal[i] = nmalloc[i];
		}		
  		buf->totfree += j * BUCKET_SIZE_REAL(i);
  		buf->total += nmalloc[i] * BUCKET_SIZE_REAL(i);
		if (nmalloc[i]) {
		    i % 2 ? (buf->topbucket_odd = i) : (buf->topbucket_ev = i);
		    buf->topbucket = i;
		}
  	}
	nextchain = chunk_chain;
	while (nextchain) {
	    buf->total_chain += nextchain->size;
	    nextchain = nextchain->next;
	}
	buf->total_sbrk = goodsbrk + sbrk_slack;
	buf->sbrks = sbrks;
	buf->sbrk_good = sbrk_goodness;
	buf->sbrk_slack = sbrk_slack;
	buf->start_slack = start_slack;
	buf->sbrked_remains = sbrked_remains;
	MALLOC_UNLOCK;
	buf->nbuckets = NBUCKETS;
	if (level) {
	    for (i = MIN_BUCKET ; i < NBUCKETS; i++) {
		if (i >= buflen)
		    break;
		buf->bucket_mem_size[i] = BUCKET_SIZE_NO_SURPLUS(i);
		buf->bucket_available_size[i] = BUCKET_SIZE_REAL(i);
	    }
	}
#else /* defined DEBUGGING_MSTATS */
	PerlIO_printf(Perl_error_log, "perl not compiled with DEBUGGING_MSTATS\n");
#endif	/* defined DEBUGGING_MSTATS */
	return 0;		/* XXX unused */
}
/*
 * mstats - print out statistics about malloc
 * 
 * Prints two lines of numbers, one showing the length of the free list
 * for each size category, the second showing the number of mallocs -
 * frees for each size category.
 */
void
Perl_dump_mstats(pTHX_ const char *s)
{
#ifdef DEBUGGING_MSTATS
  	int i;
	perl_mstats_t buffer;
	UV nf[NBUCKETS];
	UV nt[NBUCKETS];

	PERL_ARGS_ASSERT_DUMP_MSTATS;

	buffer.nfree  = nf;
	buffer.ntotal = nt;
	get_mstats(&buffer, NBUCKETS, 0);

  	if (s)
	    PerlIO_printf(Perl_error_log,
			  "Memory allocation statistics %s (buckets %"IVdf"(%"IVdf")..%"IVdf"(%"IVdf")\n",
			  s, 
			  (IV)BUCKET_SIZE_REAL(MIN_BUCKET), 
			  (IV)BUCKET_SIZE_NO_SURPLUS(MIN_BUCKET),
			  (IV)BUCKET_SIZE_REAL(buffer.topbucket), 
			  (IV)BUCKET_SIZE_NO_SURPLUS(buffer.topbucket));
  	PerlIO_printf(Perl_error_log, "%8"IVdf" free:", buffer.totfree);
  	for (i = MIN_EVEN_REPORT; i <= buffer.topbucket; i += BUCKETS_PER_POW2) {
  		PerlIO_printf(Perl_error_log, 
			      ((i < 8*BUCKETS_PER_POW2 || i == 10*BUCKETS_PER_POW2)
			       ? " %5"UVuf 
			       : ((i < 12*BUCKETS_PER_POW2) ? " %3"UVuf : " %"UVuf)),
			      buffer.nfree[i]);
  	}
#ifdef BUCKETS_ROOT2
	PerlIO_printf(Perl_error_log, "\n\t   ");
  	for (i = MIN_BUCKET + 1; i <= buffer.topbucket_odd; i += BUCKETS_PER_POW2) {
  		PerlIO_printf(Perl_error_log, 
			      ((i < 8*BUCKETS_PER_POW2 || i == 10*BUCKETS_PER_POW2)
			       ? " %5"UVuf 
			       : ((i < 12*BUCKETS_PER_POW2) ? " %3"UVuf : " %"UVuf)),
			      buffer.nfree[i]);
  	}
#endif 
  	PerlIO_printf(Perl_error_log, "\n%8"IVdf" used:", buffer.total - buffer.totfree);
  	for (i = MIN_EVEN_REPORT; i <= buffer.topbucket; i += BUCKETS_PER_POW2) {
  		PerlIO_printf(Perl_error_log, 
			      ((i < 8*BUCKETS_PER_POW2 || i == 10*BUCKETS_PER_POW2)
			       ? " %5"IVdf
			       : ((i < 12*BUCKETS_PER_POW2) ? " %3"IVdf : " %"IVdf)), 
			      buffer.ntotal[i] - buffer.nfree[i]);
  	}
#ifdef BUCKETS_ROOT2
	PerlIO_printf(Perl_error_log, "\n\t   ");
  	for (i = MIN_BUCKET + 1; i <= buffer.topbucket_odd; i += BUCKETS_PER_POW2) {
  		PerlIO_printf(Perl_error_log, 
			      ((i < 8*BUCKETS_PER_POW2 || i == 10*BUCKETS_PER_POW2)
			       ? " %5"IVdf 
			       : ((i < 12*BUCKETS_PER_POW2) ? " %3"IVdf : " %"IVdf)),
			      buffer.ntotal[i] - buffer.nfree[i]);
  	}
#endif 
	PerlIO_printf(Perl_error_log, "\nTotal sbrk(): %"IVdf"/%"IVdf":%"IVdf". Odd ends: pad+heads+chain+tail: %"IVdf"+%"IVdf"+%"IVdf"+%"IVdf".\n",
		      buffer.total_sbrk, buffer.sbrks, buffer.sbrk_good,
		      buffer.sbrk_slack, buffer.start_slack,
		      buffer.total_chain, buffer.sbrked_remains);
#else /* DEBUGGING_MSTATS */
	PerlIO_printf(Perl_error_log, "%s: perl not compiled with DEBUGGING_MSTATS\n",s);
#endif /* DEBUGGING_MSTATS */
}

#ifdef USE_PERL_SBRK

#   if defined(PURIFY)
#      define PERL_SBRK_VIA_MALLOC
#   endif

#   ifdef PERL_SBRK_VIA_MALLOC

/* it may seem schizophrenic to use perl's malloc and let it call system */
/* malloc, the reason for that is only the 3.2 version of the OS that had */
/* frequent core dumps within nxzonefreenolock. This sbrk routine put an */
/* end to the cores */

#      ifndef SYSTEM_ALLOC
#         define SYSTEM_ALLOC(a) malloc(a)
#      endif
#      ifndef SYSTEM_ALLOC_ALIGNMENT
#         define SYSTEM_ALLOC_ALIGNMENT MEM_ALIGNBYTES
#      endif

#   endif  /* PERL_SBRK_VIA_MALLOC */

static IV Perl_sbrk_oldchunk;
static long Perl_sbrk_oldsize;

#   define PERLSBRK_32_K (1<<15)
#   define PERLSBRK_64_K (1<<16)

Malloc_t
Perl_sbrk(int size)
{
    IV got;
    int small, reqsize;

    if (!size) return 0;
    reqsize = size; /* just for the DEBUG_m statement */
#ifdef PACK_MALLOC
    size = (size + 0x7ff) & ~0x7ff;
#endif
    if (size <= Perl_sbrk_oldsize) {
	got = Perl_sbrk_oldchunk;
	Perl_sbrk_oldchunk += size;
	Perl_sbrk_oldsize -= size;
    } else {
      if (size >= PERLSBRK_32_K) {
	small = 0;
      } else {
	size = PERLSBRK_64_K;
	small = 1;
      }
#  if NEEDED_ALIGNMENT > SYSTEM_ALLOC_ALIGNMENT
      size += NEEDED_ALIGNMENT - SYSTEM_ALLOC_ALIGNMENT;
#  endif
      got = (IV)SYSTEM_ALLOC(size);
#  if NEEDED_ALIGNMENT > SYSTEM_ALLOC_ALIGNMENT
      got = (got + NEEDED_ALIGNMENT - 1) & ~(NEEDED_ALIGNMENT - 1);
#  endif
      if (small) {
	/* Chunk is small, register the rest for future allocs. */
	Perl_sbrk_oldchunk = got + reqsize;
	Perl_sbrk_oldsize = size - reqsize;
      }
    }

    DEBUG_m(PerlIO_printf(Perl_debug_log, "sbrk malloc size %ld (reqsize %ld), left size %ld, give addr 0x%"UVxf"\n",
		    size, reqsize, Perl_sbrk_oldsize, PTR2UV(got)));

    return (void *)got;
}

#endif /* ! defined USE_PERL_SBRK */

/*
 * ex: set ts=8 sts=4 sw=4 et:
 */
@


1.15
log
@Fix merge conflicts, remove extra files, match upstream perl-5.20.1

ok deraadt@@ sthen@@ espie@@ miod@@
@
text
@d256 4
a1001 13
/* Returns 0 on success, -1 on bad alignment, -2 if not implemented */
int
set_emergency_buffer(char *b, IV size)
{
    if (PTR2UV(b) & (NEEDED_ALIGNMENT - 1))
	return -1;
    if (MallocCfg[MallocCfg_emergency_buffer_prepared_size])
	add_to_chain((void*)emergency_buffer_prepared,
		     MallocCfg[MallocCfg_emergency_buffer_prepared_size], 0);
    emergency_buffer_prepared = b;
    MallocCfg[MallocCfg_emergency_buffer_prepared_size] = size;
    return 0;
}
a1004 5
int
set_emergency_buffer(char *b, IV size)
{
    return -1;
}
d1063 1
a1063 1
    assert(0); /* NOTREACHED */
d1072 1
a1072 1
#define MYMALLOC_WRITE2STDERR(s) PerlLIO_write(PerlIO_fileno(PerlIO_stderr()),s,strlen(s))
d1531 1
a1531 1
				  "sbrk(%ld) to fix non-continuous/off-page sbrk:\n\t%ld for alignement,\t%ld were assumed to come from the tail of the previous sbrk\n",
d1831 1
a1831 1
		    bad_free_warn = (pbf) ? atoi(pbf) : 1;
d1929 1
a1929 1
		    bad_free_warn = (pbf) ? atoi(pbf) : 1;
d2298 1
a2298 1
#   if defined(NeXT) || defined(__NeXT__) || defined(PURIFY)
a2368 6
 * Local variables:
 * c-indentation-style: bsd
 * c-basic-offset: 4
 * indent-tabs-mode: nil
 * End:
 *
@


1.14
log
@Merge perl-5.18.2 plus local patches, remove old files

OK espie@@ sthen@@ deraadt@@
@
text
@d758 1
a758 10
#ifdef HAS_64K_LIMIT
#  define BARK_64K_LIMIT(what,nbytes,size)				\
	if (nbytes > 0xffff) {						\
		PerlIO_printf(PerlIO_stderr(),				\
			      "%s too large: %lx\n", what, size);	\
		my_exit(1);						\
	}
#else /* !HAS_64K_LIMIT */
#  define BARK_64K_LIMIT(what,nbytes,size)
#endif /* !HAS_64K_LIMIT */
d1206 2
a1207 2
int
S_ajust_size_and_find_bucket(size_t *nbytes_p)
d1209 1
a1209 1
  	MEM_SIZE shiftr;
d1211 5
a1215 1
	size_t nbytes = *nbytes_p;
d1271 1
a1271 1
	bucket = S_ajust_size_and_find_bucket(&nbytes);
d2171 1
a2171 1
    return BUCKET_SIZE_REAL(S_ajust_size_and_find_bucket(&wanted));
@


1.13
log
@merge/resolve conflicts
(some more to do after this one)
@
text
@d200 1
a200 8
#if !(defined(I286) || defined(atarist))
	/* take 2k unless the block is bigger than that */
#  define LOG_OF_MIN_ARENA 11
#else
	/* take 16k unless the block is bigger than that 
	   (80286s like large segments!), probably good on the atari too */
#  define LOG_OF_MIN_ARENA 14
#endif
d372 1
a372 2
/* 286 and atarist like big chunks, which gives too much overhead. */
#if (defined(RCHECK) || defined(I286) || defined(atarist)) && defined(PACK_MALLOC)
d450 1
a450 1
#  define ALIGN_SMALL ((int)((caddr_t)&(((struct aligner*)0)->p)))
d790 1
a790 1
static void	morecore	(register int bucket);
d1086 1
a1086 1
    /* NOTREACHED */
d1094 2
a1095 5
static void
write2(const char *mess)
{
  write(2, mess, strlen(mess));
}
d1113 7
a1119 7
	    write2("assertion botched (");
	    write2(diag);
	    write2("?): ");
	    write2(s);
	    write2(" (");
	    write2(file);
	    write2(":");
d1128 1
a1128 1
	      write2(s);
d1130 1
a1130 1
	    write2(")\n");
d1263 2
a1264 2
  	register union overhead *p;
  	register int bucket;
d1290 1
a1290 1
		        PerlIO_puts(PerlIO_stderr(),"Out of memory!\n");
d1297 1
a1297 1
			PerlIO_puts(PerlIO_stderr(),"Out of memory during request for ");
d1305 2
a1306 2
			PerlIO_puts(PerlIO_stderr(),s);
			PerlIO_puts(PerlIO_stderr()," bytes, total sbrk() is ");
d1312 2
a1313 2
			PerlIO_puts(PerlIO_stderr(),s);
			PerlIO_puts(PerlIO_stderr()," bytes!\n");
d1498 1
a1498 1
	if (require < goodsbrk * MIN_SBRK_FRAC1000 / 1000)
a1540 2
#if !defined(atarist) /* on the atari we dont have to worry about this */
#  ifndef I286 	/* The sbrk(0) call on the I286 always returns the next segment */
a1546 2
#  endif
#endif /* !atarist */
a1606 1
#ifndef I286	/* Again, this should always be ok on an 80286 */
a1618 1
#endif
d1678 1
a1678 1
morecore(register int bucket)
d1681 2
a1682 2
  	register union overhead *ovp;
  	register int rnu;       /* 2^rnu bytes will be requested */
d1684 1
a1684 1
	register MEM_SIZE siz, needed;
d1714 4
a1717 3
		    write2("Unrecognized part of PERL_MALLOC_OPT: \"");
		    write2(t);
		    write2("\"\n");
d1817 2
a1818 2
  	register MEM_SIZE size;
	register union overhead *ovp;
d1913 1
a1913 1
  	register MEM_SIZE onb;
d1917 1
a1917 1
	register int bucket;
d2103 1
a2103 1
Perl_calloc(register size_t elements, register size_t size)
d2189 2
a2190 2
  	register int i, j;
  	register union overhead *p;
d2251 1
a2251 1
  	register int i;
d2391 1
a2391 1
 * indent-tabs-mode: t
d2394 1
a2394 1
 * ex: set ts=8 sts=4 sw=4 noet:
@


1.12
log
@merge in perl 5.12.2 plus local changes
@
text
@d8 1
a8 1
 *     [p.321 of _The Lord of the Rings_, II/v: "The Bridge of Khazad-Dûm"]
d18 2
a19 3
  Here are some notes on configuring Perl's malloc.  (For non-perl
  usage see below.)
 
d42 1
a42 1
    PERL_EMERGENCY_SBRK		(!PLAIN_MALLOC && (PERL_CORE || !NO_MALLOC_DYNAMIC_CFG))
d45 1
a45 1
    DEBUGGING_MSTATS		(!PLAIN_MALLOC && PERL_CORE)
a164 66
/*
   If used outside of Perl environment, it may be useful to redefine
   the following macros (listed below with defaults):

     # Type of address returned by allocation functions
     Malloc_t				void *

     # Type of size argument for allocation functions
     MEM_SIZE				unsigned long

     # size of void*
     PTRSIZE				4

     # Maximal value in LONG
     LONG_MAX				0x7FFFFFFF

     # Unsigned integer type big enough to keep a pointer
     UV					unsigned long

     # Signed integer of the same sizeof() as UV
     IV					long

     # Type of pointer with 1-byte granularity
     caddr_t				char *

     # Type returned by free()
     Free_t				void

     # Conversion of pointer to integer
     PTR2UV(ptr)			((UV)(ptr))

     # Conversion of integer to pointer
     INT2PTR(type, i)			((type)(i))

     # printf()-%-Conversion of UV to pointer
     UVuf				"lu"

     # printf()-%-Conversion of UV to hex pointer
     UVxf				"lx"

     # Alignment to use
     MEM_ALIGNBYTES			4

     # Very fatal condition reporting function (cannot call any )
     fatalcroak(arg)			write(2,arg,strlen(arg)) + exit(2)
  
     # Fatal error reporting function
     croak(format, arg)			warn(idem) + exit(1)
  
     # Fatal error reporting function
     croak2(format, arg1, arg2)		warn2(idem) + exit(1)
  
     # Error reporting function
     warn(format, arg)			fprintf(stderr, idem)

     # Error reporting function
     warn2(format, arg1, arg2)		fprintf(stderr, idem)

     # Locking/unlocking for MT operation
     MALLOC_LOCK			MUTEX_LOCK(&PL_malloc_mutex)
     MALLOC_UNLOCK			MUTEX_UNLOCK(&PL_malloc_mutex)

     # Locking/unlocking mutex for MT operation
     MUTEX_LOCK(l)			void
     MUTEX_UNLOCK(l)			void
 */
d189 1
a189 1
#  if (defined(PERL_CORE) || !defined(NO_MALLOC_DYNAMIC_CFG)) && !defined(PERL_EMERGENCY_SBRK)
d192 1
a192 1
#  if defined(PERL_CORE) && !defined(DEBUGGING_MSTATS)
d239 1
a239 1
 * buckets.  Sizes of really big buckets are increased to accomodata
d245 4
a248 5
#ifdef PERL_CORE
#  include "EXTERN.h"
#  define PERL_IN_MALLOC_C
#  include "perl.h"
#  if defined(PERL_IMPLICIT_CONTEXT)
d253 1
a253 1
#  else
d256 2
a257 2
#  endif
#  if defined(USE_5005THREADS) || defined(USE_ITHREADS)
d259 1
a259 1
#  else
d261 1
a261 108
#  endif
#else
#  ifdef PERL_FOR_X2P
#    include "../EXTERN.h"
#    include "../perl.h"
#  else
#    include <stdlib.h>
#    include <stdio.h>
#    include <memory.h>
#    ifdef OS2
#      include <io.h>
#    endif
#    include <string.h>
#    ifndef Malloc_t
#      define Malloc_t void *
#    endif
#    ifndef PTRSIZE
#      define PTRSIZE 4
#    endif
#    ifndef MEM_SIZE
#      define MEM_SIZE unsigned long
#    endif
#    ifndef LONG_MAX
#      define LONG_MAX 0x7FFFFFFF
#    endif
#    ifndef UV
#      define UV unsigned long
#    endif
#    ifndef IV
#      define IV long
#    endif
#    ifndef caddr_t
#      define caddr_t char *
#    endif
#    ifndef Free_t
#      define Free_t void
#    endif
#    define Copy(s,d,n,t) (void)memcpy((char*)(d),(char*)(s), (n) * sizeof(t))
#    define CopyD(s,d,n,t) memcpy((char*)(d),(char*)(s), (n) * sizeof(t))
#    define PerlEnv_getenv getenv
#    define PerlIO_printf fprintf
#    define PerlIO_stderr() stderr
#    define PerlIO_puts(f,s)		fputs(s,f)
#    ifndef INT2PTR
#      define INT2PTR(t,i)		((t)(i))
#    endif
#    ifndef PTR2UV
#      define PTR2UV(p)			((UV)(p))
#    endif
#    ifndef UVuf
#      define UVuf			"lu"
#    endif
#    ifndef UVxf
#      define UVxf			"lx"
#    endif
#    ifndef MEM_ALIGNBYTES
#      define MEM_ALIGNBYTES		4
#    endif
#  endif
#  ifndef croak				/* make depend */
#    define croak(mess, arg) (warn((mess), (arg)), exit(1))
#  endif 
#  ifndef croak2			/* make depend */
#    define croak2(mess, arg1, arg2) (warn2((mess), (arg1), (arg2)), exit(1))
#  endif 
#  ifndef warn
#    define warn(mess, arg) fprintf(stderr, (mess), (arg))
#  endif 
#  ifndef warn2
#    define warn2(mess, arg1, arg2) fprintf(stderr, (mess), (arg1), (arg2))
#  endif 
#  ifdef DEBUG_m
#    undef DEBUG_m
#  endif 
#  define DEBUG_m(a)
#  ifdef DEBUGGING
#     undef DEBUGGING
#  endif
#  ifndef pTHX
#     define pTHX		void
#     define pTHX_
#     ifdef HASATTRIBUTE_UNUSED
#        define dTHX		extern int Perl___notused PERL_UNUSED_DECL
#     else
#        define dTHX            extern int Perl___notused
#     endif
#     define WITH_THX(s)	s
#  endif
#  ifndef PERL_GET_INTERP
#     define PERL_GET_INTERP	PL_curinterp
#  endif
#  define PERL_MAYBE_ALIVE	1
#  ifndef Perl_malloc
#     define Perl_malloc malloc
#  endif
#  ifndef Perl_mfree
#     define Perl_mfree free
#  endif
#  ifndef Perl_realloc
#     define Perl_realloc realloc
#  endif
#  ifndef Perl_calloc
#     define Perl_calloc calloc
#  endif
#  ifndef Perl_strdup
#     define Perl_strdup strdup
#  endif
#endif	/* defined PERL_CORE */
d517 1
a517 1
 * (to make size of big CHUNK accomodate allocations for powers of two
d766 1
a766 1
#if defined(HAS_64K_LIMIT) && defined(PERL_CORE)
d773 1
a773 1
#else /* !HAS_64K_LIMIT || !PERL_CORE */
d775 1
a775 1
#endif /* !HAS_64K_LIMIT || !PERL_CORE */
a807 2
#ifdef PERL_CORE

a814 2
#endif	/* defined PERL_CORE */ 

a971 1
#  ifdef PERL_CORE
d1001 1
a1001 4
#    define PERL_GET_EMERGENCY_BUFFER(p)	perl_get_emergency_buffer(p)
#  else
#    define PERL_GET_EMERGENCY_BUFFER(p)	NULL
#  endif	/* defined PERL_CORE */
a1296 1
#ifdef PERL_CORE
a1328 1
#endif
d1625 1
a1625 1
				  "fixing sbrk(): %d bytes off machine alignement\n",
a1870 1
#ifdef PERL_CORE
a1878 5
		warn("%s free() ignored (RMAGIC)",
		    ovp->ov_rmagic == RMAGIC - 1 ? "Duplicate" : "Bad");
#endif		
#else
#ifdef PERL_CORE
a1883 3
#else
		warn("%s", "Bad free() ignored");
#endif
d1938 1
a1938 1
#if defined(DEBUGGING) || !defined(PERL_CORE)
a1968 1
#ifdef PERL_CORE
a1977 6
		warn2("%srealloc() %signored",
		      (ovp->ov_rmagic == RMAGIC - 1 ? "" : "Bad "),
		      ovp->ov_rmagic == RMAGIC - 1 ? "of freed memory " : "");
#endif
#else
#ifdef PERL_CORE
a1983 3
#else
		warn("%s", "Bad realloc() ignored");
#endif
d1991 1
a1991 1
	 *  We are not agressive with boundary cases. Note that it might
a2138 1
#ifdef PERL_CORE
a2165 1
#  endif
a2365 1
#ifdef PERL_CORE
a2366 1
#endif
@


1.11
log
@Merge in perl 5.10.1
@
text
@d267 1
a267 1
#if !(defined(I286) || defined(atarist) || defined(__MINT__))
d555 1
a555 1
#if (defined(RCHECK) || defined(I286) || defined(atarist) || defined(__MINT__)) && defined(PACK_MALLOC)
d1737 1
a1737 1
#if !defined(atarist) && !defined(__MINT__) /* on the atari we dont have to worry about this */
d1746 1
a1746 1
#endif /* !atarist && !MINT */
d2059 4
a2062 4
		    if (!PERL_IS_ALIVE || !PL_curcop || ckWARN_d(WARN_MALLOC))
			Perl_warner(aTHX_ packWARN(WARN_MALLOC), "%s free() ignored (RMAGIC, PERL_CORE)",
				    ovp->ov_rmagic == RMAGIC - 1 ?
				    "Duplicate" : "Bad");
d2072 2
a2073 2
		    if (!PERL_IS_ALIVE || !PL_curcop || ckWARN_d(WARN_MALLOC))
			Perl_warner(aTHX_ packWARN(WARN_MALLOC), "%s", "Bad free() ignored (PERL_CORE)");
d2166 5
a2170 5
		    if (!PERL_IS_ALIVE || !PL_curcop || ckWARN_d(WARN_MALLOC))
			Perl_warner(aTHX_ packWARN(WARN_MALLOC), "%srealloc() %signored",
				    (ovp->ov_rmagic == RMAGIC - 1 ? "" : "Bad "),
				    ovp->ov_rmagic == RMAGIC - 1
				    ? "of freed memory " : "");
d2181 3
a2183 3
		    if (!PERL_IS_ALIVE || !PL_curcop || ckWARN_d(WARN_MALLOC))
			Perl_warner(aTHX_ packWARN(WARN_MALLOC), "%s",
				    "Bad realloc() ignored");
d2470 1
a2470 1
Perl_dump_mstats(pTHX_ char *s)
d2539 1
a2539 1
#   if defined(__MACHTEN_PPC__) || defined(NeXT) || defined(__NeXT__) || defined(PURIFY)
@


1.10
log
@fix conflicts and merge in local changes to perl 5.10.0
@
text
@d6 3
a8 1
 * "'The Chamber of Records,' said Gimli. 'I guess that is where we now stand.'"
a383 3
#    ifndef Nullch
#      define Nullch			NULL
#    endif
d975 1
a975 1
static void	botch		(char *diag, char *s, char *file, int line);
d1286 1
a1286 1
write2(char *mess)
d1296 1
a1296 1
botch(char *diag, char *s, char *file, int line)
d1299 1
a1302 1
	dTHX;
d1409 2
a1410 2
Malloc_t
Perl_malloc(register size_t nbytes)
d1412 3
a1414 14
        dVAR;
  	register union overhead *p;
  	register int bucket;
  	register MEM_SIZE shiftr;

#if defined(DEBUGGING) || defined(RCHECK)
	MEM_SIZE size = nbytes;
#endif

	BARK_64K_LIMIT("Allocation",nbytes,nbytes);
#ifdef DEBUGGING
	if ((long)nbytes < 0)
	    croak("%s", "panic: malloc");
#endif
d1449 22
d2298 2
d2379 3
d2394 7
d2415 2
d2457 2
d2478 2
d2532 2
@


1.9
log
@merge in perl 5.8.8
@
text
@a1158 1
    GV **gvp = (GV**)hv_fetch(PL_defstash, "^M", 2, 0);
d1161 1
d1163 1
a1163 1
    if (!gvp) gvp = (GV**)hv_fetch(PL_defstash, "\015", 1, 0);
d1176 1
a1176 1
    SvPV_set(sv, Nullch);
d1252 1
a1252 1
	    emergency_buffer = Nullch;
d1279 1
a1279 1
    return Nullch;
d1294 2
a1295 1
#define	ASSERT(p,diag)   if (!(p)) botch(diag,STRINGIFY(p),__FILE__,__LINE__);  else
d1299 1
d1413 1
d1671 1
d1872 1
d2005 1
a2005 1
Perl_mfree(void *mp)
d2007 1
d2010 1
a2010 1
	char *cp = (char*)mp;
d2112 1
d2151 1
a2151 1
		    return Nullch;
d2179 1
a2179 1
		return Nullch;			/* sanity */
d2328 1
a2328 1
    return CopyD(s, s1, (MEM_SIZE)(l+1), char);
d2351 1
a2351 1
      var = Perl_malloc(l + 1);
@


1.8
log
@sync in-tree perl with 5.8.6
@
text
@d274 12
a285 13
#ifndef lint
#  if defined(DEBUGGING) && !defined(NO_RCHECK)
#    define RCHECK
#  endif
#  if defined(DEBUGGING) && !defined(NO_RCHECK) && !defined(NO_MFILL) && !defined(MALLOC_FILL)
#    define MALLOC_FILL
#  endif
#  if defined(DEBUGGING) && !defined(NO_RCHECK) && !defined(NO_FILL_CHECK) && !defined(MALLOC_FILL_CHECK)
#    define MALLOC_FILL_CHECK
#  endif
#  if defined(RCHECK) && defined(IGNORE_SMALL_BAD_FREE)
#    undef IGNORE_SMALL_BAD_FREE
#  endif 
d411 1
a411 1
#     ifdef HASATTRIBUTE
d643 1
a643 1
static u_short buck_size[MAX_BUCKET_BY_TABLE + 1] = 
d807 1
a807 1
static u_short n_blks[LOG_OF_MIN_ARENA * BUCKETS_PER_POW2] = 
d830 1
a830 1
static u_short blk_shift[LOG_OF_MIN_ARENA * BUCKETS_PER_POW2] = 
d878 1
a878 1
static char bucket_of[] =
a1161 1
    STRLEN n_a;
d1168 1
a1168 1
    pv = SvPV(sv, n_a);
d1176 3
a1178 2
    SvPVX(sv) = Nullch;
    SvCUR(sv) = SvLEN(sv) = 0;
d1228 2
a1229 1
	&& (!emergency_buffer_last_req || (size < emergency_buffer_last_req))) {
d1236 1
a1236 1
    if (emergency_buffer_size >= rsize) {
d1339 1
a1339 1
    long lfill = *(long*)fill;
d1380 1
a1380 1
    long lfill = *(long*)fill;
d1518 1
a1518 1
			  "Unaligned `next' pointer in the free "
d1676 1
a1676 1
	if (!last_sbrk_top && require < FIRST_SBRK) 
d1678 1
a1678 1
	else if (require < MIN_SBRK) require = MIN_SBRK;
d1807 1
a1807 1
	;				/* Finish `else' */
d1901 1
a1901 1
		    write2("Unrecognized part of PERL_MALLOC_OPT: `");
d1903 1
a1903 1
		    write2("'\n");
d2357 1
a2357 1
    union overhead *ovp = (union overhead *)
d2359 1
a2359 1
    int bucket = OV_INDEX(ovp);
d2364 1
a2364 1
	MEM_SIZE size = BUCKET_SIZE_REAL(bucket);
a2498 1
#endif /* lint */
d2573 10
@


1.7
log
@Resolve conflicts for perl 5.8.2, remove old files, and add OpenBSD-specific scaffolding
@
text
@d9 6
d366 1
d2321 1
a2321 2
    Copy(s, s1, (MEM_SIZE)(l+1), char);
    return s1;
@


1.6
log
@Resolve conflicts, remove old files, merge local changes
@
text
@d30 3
d35 1
a35 1
    PERL_EMERGENCY_SBRK		(!PLAIN_MALLOC && PERL_CORE)
d84 16
d120 3
d139 14
d177 3
d186 15
d225 4
d248 1
a248 1
#  if defined(PERL_CORE) && !defined(PERL_EMERGENCY_SBRK)
d272 6
d318 5
d331 4
d350 3
d363 19
d393 1
a393 1
#    define warn2(mess, arg1) fprintf(stderr, (mess), (arg1), (arg2))
d415 1
d431 1
a431 1
#endif
d457 1
a457 1
	if (PERL_GET_INTERP) {						\
d569 3
d582 2
a583 1
		u_short	ovu_size;	/* actual block size */
d598 1
a598 1
#  define	RSLOP		sizeof (u_int)
d600 1
a600 1
#    define MAX_SHORT_BUCKET (12 * BUCKETS_PER_POW2)
d605 1
a605 1
#  define	RSLOP		0
d641 1
a641 1
#  define BUCKET_SIZE(i) ((i) % 2 ? buck_size[i] : (1 << ((i) >> BUCKET_POW2_SHIFT)))
d648 3
a650 2
#  define BUCKET_SIZE(i) (1 << ((i) >> BUCKET_POW2_SHIFT))
#  define BUCKET_SIZE_REAL(i) (BUCKET_SIZE(i) - MEM_OVERHEAD(i) + POW2_OPTIMIZE_SURPLUS(i))
d795 1
a795 1
			 ? ((1<<LOG_OF_MIN_ARENA) - 1)/BUCKET_SIZE(bucket) \
d818 1
a818 1
				 - BUCKET_SIZE(bucket) * N_BLKS(bucket)) \
d859 1
a859 1
#define M_OVERHEAD (sizeof(union overhead) + RSLOP)
d970 1
a970 1
static void	botch		(char *diag, char *s);
d987 6
d1018 95
d1127 1
a1127 1
# ifdef PERL_EMERGENCY_SBRK
d1133 5
d1139 76
a1214 3
static MEM_SIZE emergency_buffer_size;
static MEM_SIZE no_mem;	/* 0 if the last request for more memory succeeded.
			   Otherwise the size of the failing request. */
d1221 2
a1222 1
    if (size >= BIG_SIZE && (!no_mem || (size < no_mem))) {
d1225 2
a1226 2
	no_mem = size;
	croak2("Out of memory during \"large\" request for %"UVuf" bytes, total sbrk() is %"UVuf" bytes", (UV)size, (UV)(goodsbrk + sbrk_slack));
a1235 1
	dTHX;
d1238 2
a1239 3
	GV **gvp = (GV**)hv_fetch(PL_defstash, "^M", 2, 0);
	SV *sv;
	char *pv;
a1240 1
	STRLEN n_a;
d1248 4
a1251 3
	if (!gvp) gvp = (GV**)hv_fetch(PL_defstash, "\015", 1, 0);
	if (!gvp || !(sv = GvSV(*gvp)) || !SvPOK(sv) 
	    || (SvLEN(sv) < (1<<LOG_OF_MIN_ARENA) - M_OVERHEAD)) {
d1256 1
a1256 2
	/* Got it, now detach SvPV: */
	pv = SvPV(sv, n_a);
d1258 3
a1260 1
	if ((PTR2UV(pv) - sizeof(union overhead)) & (NEEDED_ALIGNMENT - 1)) {
d1265 2
a1266 5
	emergency_buffer = pv - sizeof(union overhead);
	emergency_buffer_size = malloced_size(pv) + M_OVERHEAD;
	SvPOK_off(sv);
	SvPVX(sv) = Nullch;
	SvCUR(sv) = SvLEN(sv) = 0;
d1270 1
a1270 1
    croak("Out of memory during request for %"UVuf" bytes, total sbrk() is %"UVuf" bytes", (UV)size, (UV)(goodsbrk + sbrk_slack));
d1275 1
a1275 1
# else /*  !defined(PERL_EMERGENCY_SBRK) */
d1277 7
a1283 2
# endif
#endif /* ifdef PERL_CORE */
d1287 1
a1287 1
#define	ASSERT(p,diag)   if (!(p)) botch(diag,STRINGIFY(p));  else
d1289 1
a1289 1
botch(char *diag, char *s)
d1291 3
d1295 23
a1317 1
	PerlIO_printf(PerlIO_stderr(), "assertion botched (%s?): %s\n", diag, s);
d1319 1
d1325 76
d1498 4
a1501 2
#if defined(RCHECK)
	if ((PTR2UV(p)) & (MEM_ALIGNBYTES - 1)) {
d1507 2
a1508 1
	if ((PTR2UV(p->ov_next)) & (MEM_ALIGNBYTES - 1)) {
d1522 1
a1522 1
			      PTR2UV(p), (unsigned long)(PL_an++),
d1525 3
d1546 4
a1549 4
	    if ((i = nbytes & 3)) {
		i = 4 - i;
		while (i--)
		    *((char *)((caddr_t)p + nbytes - RSLOP + i)) = RMAGIC_C;
d1551 3
a1553 2
	    nbytes = (nbytes + 3) &~ 3; 
	    *((u_int *)((caddr_t)p + nbytes - RSLOP)) = RMAGIC;
d1555 1
a1562 1
static int sbrk_good = SBRK_ALLOW_FAILURES * SBRK_FAILURE_PRICE;
d1648 1
a1648 1
	    add_to_chain(ret, (BUCKET_SIZE(bucket) +
d1668 1
a1668 1
    if (sbrk_good > 0) {
d1673 2
a1674 2
	if (require < goodsbrk * MIN_SBRK_FRAC / 100)
	    require = goodsbrk * MIN_SBRK_FRAC / 100;
d1691 1
a1691 1
	sbrk_good++;
d1763 1
a1763 1
		sbrk_good = -1;	/* Disable optimization!
d1772 1
a1772 1
	    sbrk_good -= SBRK_FAILURE_PRICE;
d1805 1
a1805 1
    no_mem = 0;
d1844 1
a1844 1
	    sbrk_good -= SBRK_FAILURE_PRICE;
d1865 1
d1869 34
d1947 1
d1953 1
a1953 1
  	siz = BUCKET_SIZE(bucket);
d1974 1
d2008 4
d2064 5
a2068 5
	    if ((i = nbytes & 3)) {
		i = 4 - i;
		while (i--) {
		    ASSERT(*((char *)((caddr_t)ovp + nbytes - RSLOP + i))
			   == RMAGIC_C, "chunk's tail overwrite");
d2071 6
a2076 2
	    nbytes = (nbytes + 3) &~ 3; 
	    ASSERT(*(u_int *)((caddr_t)ovp + nbytes - RSLOP) == RMAGIC, "chunk's tail overwrite");	    
d2078 2
d2149 3
a2151 3
		warn("%srealloc() %signored",
		    (ovp->ov_rmagic == RMAGIC - 1 ? "" : "Bad "),
		     ovp->ov_rmagic == RMAGIC - 1 ? "of freed memory " : "");
d2209 4
a2212 4
		       if ((i = nb & 3)) {
			   i = 4 - i;
			   while (i--) {
			       ASSERT(*((char *)((caddr_t)ovp + nb - RSLOP + i)) == RMAGIC_C, "chunk's tail overwrite");
d2215 12
a2226 2
		       nb = (nb + 3) &~ 3; 
		       ASSERT(*(u_int *)((caddr_t)ovp + nb - RSLOP) == RMAGIC, "chunk's tail overwrite");
d2235 4
a2238 4
			if ((i = nbytes & 3)) {
			    i = 4 - i;
			    while (i--)
				*((char *)((caddr_t)ovp + nbytes - RSLOP + i))
d2241 3
a2243 2
			nbytes = (nbytes + 3) &~ 3; 
			*((u_int *)((caddr_t)ovp + nbytes - RSLOP)) = RMAGIC;
d2360 1
a2360 1
	*((u_int *)((caddr_t)ovp + size + M_OVERHEAD - RSLOP)) = RMAGIC;
d2406 1
a2406 1
	buf->sbrk_good = sbrk_good;
d2416 1
a2416 1
		buf->bucket_mem_size[i] = BUCKET_SIZE(i);
d2448 1
a2448 1
			  (IV)BUCKET_SIZE(MIN_BUCKET),
d2450 1
a2450 1
			  (IV)BUCKET_SIZE(buffer.topbucket));
@


1.5
log
@merge in perl 5.6.1 with our local changes
@
text
@d6 4
a261 1
#    define _(arg) arg
d310 5
a314 1
#     define dTHX		extern int Perl___notused
d359 1
a359 1
#  define DEBUG_m(a)  \
d361 8
a368 1
	if (PERL_GET_INTERP) { dTHX; if (PL_debug & 128) { a; } }	\
d906 1
a906 1
#ifndef HAS_SBRK_PROTO
d908 1
a908 1
#endif
d933 1
a933 1
static int no_mem;	/* 0 if the last request for more memory succeeded.
d1058 1
d1060 1
a1112 5
	DEBUG_m(PerlIO_printf(Perl_debug_log,
			      "0x%"UVxf": (%05lu) malloc %ld bytes\n",
			      PTR2UV(p), (unsigned long)(PL_an++),
			      (long)size));

d1133 5
d1170 1
a1170 1
static int sbrked_remains;
d1605 1
a1605 1
			Perl_warner(aTHX_ WARN_MALLOC, "%s free() ignored",
d1610 1
a1610 1
		warn("%s free() ignored",
d1618 1
a1618 1
			Perl_warner(aTHX_ WARN_MALLOC, "%s", "Bad free() ignored");
d1705 1
a1705 1
			Perl_warner(aTHX_ WARN_MALLOC, "%srealloc() %signored",
d1720 1
a1720 1
			Perl_warner(aTHX_ WARN_MALLOC, "%s",
@


1.4
log
@perl-5.6.0 + local changes
@
text
@d149 3
d155 3
d243 1
d245 4
d288 3
d294 3
d461 5
d863 1
a863 5
#if defined(PERL_EMERGENCY_SBRK) && defined(PERL_CORE)

#  ifndef BIG_SIZE
#    define BIG_SIZE (1<<16)		/* 64K */
#  endif 
d872 45
d919 2
d927 2
a928 2
    if (size >= BIG_SIZE) {
	/* Give the possibility to recover: */
d930 2
a931 1
	croak("Out of memory during \"large\" request for %i bytes", size);
d979 1
a979 1
    croak("Out of memory during request for %i bytes", size);
d984 1
a984 1
#else /* !(defined(PERL_EMERGENCY_SBRK) && defined(PERL_CORE)) */
d986 2
a987 42
#endif /* !(defined(PERL_EMERGENCY_SBRK) && defined(PERL_CORE)) */

#ifndef BITS_IN_PTR
#  define BITS_IN_PTR (8*PTRSIZE)
#endif

/*
 * nextf[i] is the pointer to the next free block of size 2^i.  The
 * smallest allocatable block is 8 bytes.  The overhead information
 * precedes the data area returned to the user.
 */
#define	NBUCKETS (BITS_IN_PTR*BUCKETS_PER_POW2 + 1)
static	union overhead *nextf[NBUCKETS];

#if defined(PURIFY) && !defined(USE_PERL_SBRK)
#  define USE_PERL_SBRK
#endif

#ifdef USE_PERL_SBRK
#define sbrk(a) Perl_sbrk(a)
Malloc_t Perl_sbrk (int size);
#else 
#ifdef DONT_DECLARE_STD
#ifdef I_UNISTD
#include <unistd.h>
#endif
#else
extern	Malloc_t sbrk(int);
#endif
#endif

#ifdef DEBUGGING_MSTATS
/*
 * nmalloc[i] is the difference between the number of mallocs and frees
 * for a given block size.
 */
static	u_int nmalloc[NBUCKETS];
static  u_int sbrk_slack;
static  u_int start_slack;
#endif

static	u_int goodsbrk;
d1064 26
a1089 1
			PerlIO_puts(PerlIO_stderr(),"Out of memory!\n");
d1099 1
a1099 1
			      PTR2UV(p+1), (unsigned long)(PL_an++),
d1114 1
a1114 1
			  "chain 0x"UVxf" at 0x%"UVxf"\n",
d1397 3
d1946 1
d1969 1
a1969 2
  	register int i, j;
  	register union overhead *p;
d1971 2
a1972 3
	unsigned long nf[NBUCKETS];
	unsigned long nt[NBUCKETS];
	struct chunk_chain_s* nextchain;
d1980 1
a1980 1
			  "Memory allocation statistics %s (buckets %ld(%ld)..%ld(%ld)\n",
d1982 5
a1986 5
			  (long)BUCKET_SIZE_REAL(MIN_BUCKET), 
			  (long)BUCKET_SIZE(MIN_BUCKET),
			  (long)BUCKET_SIZE_REAL(buffer.topbucket), 
			  (long)BUCKET_SIZE(buffer.topbucket));
  	PerlIO_printf(Perl_error_log, "%8ld free:", buffer.totfree);
d1990 2
a1991 2
			       ? " %5d" 
			       : ((i < 12*BUCKETS_PER_POW2) ? " %3d" : " %d")),
d1999 2
a2000 2
			       ? " %5d" 
			       : ((i < 12*BUCKETS_PER_POW2) ? " %3d" : " %d")),
d2004 1
a2004 1
  	PerlIO_printf(Perl_error_log, "\n%8ld used:", buffer.total - buffer.totfree);
d2008 2
a2009 2
			       ? " %5d" 
			       : ((i < 12*BUCKETS_PER_POW2) ? " %3d" : " %d")), 
d2017 2
a2018 2
			       ? " %5d" 
			       : ((i < 12*BUCKETS_PER_POW2) ? " %3d" : " %d")),
d2022 1
a2022 1
	PerlIO_printf(Perl_error_log, "\nTotal sbrk(): %ld/%ld:%ld. Odd ends: pad+heads+chain+tail: %ld+%ld+%ld+%ld.\n",
@


1.3
log
@perl5.005_03 (stock)
@
text
@d6 2
a7 1
  Here are some notes on configuring Perl's malloc.
d66 3
d118 43
d217 12
a228 1
 * but bombs when it runs out. 
d233 1
d235 4
d251 3
d275 1
a275 1
#    define croak(mess, arg) warn((mess), (arg)); exit(1);
d278 1
a278 1
#    define warn(mess, arg) fprintf(stderr, (mess), (arg));
d287 24
d321 12
d335 4
a338 1
#  define DEBUG_m(a)  if (PL_debug & 128)   a
d341 70
d415 5
a419 7

#ifdef HAS_QUAD
#  define u_bigint UV			/* Needs to eat *void. */
#else  /* needed? */
#  define u_bigint unsigned long	/* Needs to eat *void. */
#endif

d444 1
a445 1
		u_char	ovu_index;	/* bucket # */
a456 7
#ifdef DEBUGGING
static void botch _((char *diag, char *s));
#endif
static void morecore _((int bucket));
static int findbucket _((union overhead *freep, int srchlen));
static void add_to_chain(void *p, MEM_SIZE size, MEM_SIZE chip);

d518 115
a632 23
/* In this case it is assumed that if we do sbrk() in 2K units, we
 * will get 2K aligned arenas (at least after some initial
 * alignment). The bucket number of the given subblock is on the start
 * of 2K arena which contains the subblock.  Several following bytes
 * contain the magic numbers for the subblocks in the block.
 *
 * Sizes of chunks are powers of 2 for chunks in buckets <=
 * MAX_PACKED, after this they are (2^n - sizeof(union overhead)) (to
 * get alignment right).
 *
 * Consider an arena for 2^n with n>MAX_PACKED.  We suppose that
 * starts of all the chunks in a 2K arena are in different
 * 2^n-byte-long chunks.  If the top of the last chunk is aligned on a
 * boundary of 2K block, this means that sizeof(union
 * overhead)*"number of chunks" < 2^n, or sizeof(union overhead)*2K <
 * 4^n, or n > 6 + log2(sizeof()/2)/2, since a chunk of size 2^n -
 * overhead is used.  Since this rules out n = 7 for 8 byte alignment,
 * we specialcase allocation of the first of 16 128-byte-long chunks.
 *
 * Note that with the above assumption we automatically have enough
 * place for MAGIC at the start of 2K block.  Note also that we
 * overlay union overhead over the chunk, thus the start of small chunks
 * is immediately overwritten after freeing.  */
d637 3
a639 3
#  define TWOK_MASKED(x) ((u_bigint)(x) & ~TWOK_MASK)
#  define TWOK_SHIFT(x) ((u_bigint)(x) & TWOK_MASK)
#  define OV_INDEXp(block) ((u_char*)(TWOK_MASKED(block)))
d708 3
d717 3
d831 10
d847 5
a851 5
#ifdef MUTEX_INIT_CALLS_MALLOC
#  undef      MUTEX_LOCK
#  define MUTEX_LOCK(m)       STMT_START { if (*m) mutex_lock(*m); } STMT_END
#  undef      MUTEX_UNLOCK
#  define MUTEX_UNLOCK(m)     STMT_START { if (*m) mutex_unlock(*m); } STMT_END
a855 1
static Malloc_t emergency_sbrk(MEM_SIZE size);
d864 1
a864 1
	MUTEX_UNLOCK(&PL_malloc_mutex);
d875 1
a875 1
	dTHR;
d900 1
a900 1
	if (((UV)(pv - sizeof(union overhead))) & ((1<<LOG_OF_MIN_ARENA) - 1)) {
d912 1
a912 1
    MUTEX_UNLOCK(&PL_malloc_mutex);
d914 2
d922 4
d931 1
a931 1
#define	NBUCKETS (32*BUCKETS_PER_POW2 + 1)
d934 4
d940 1
a940 1
Malloc_t Perl_sbrk _((int size));
d969 1
d978 1
a978 1
malloc(register size_t nbytes)
d991 1
a991 1
		croak("%s", "panic: malloc");
a993 1
	MUTEX_LOCK(&PL_malloc_mutex);
d1025 1
d1033 1
a1033 1
		MUTEX_UNLOCK(&PL_malloc_mutex);
d1035 6
a1040 3
		if (!PL_nomemok) {
		    PerlIO_puts(PerlIO_stderr(),"Out of memory!\n");
		    my_exit(1);
d1042 1
a1042 1
#else
a1043 1
#endif
d1047 2
a1048 2
			      "0x%lx: (%05lu) malloc %ld bytes\n",
			      (unsigned long)(p+1), (unsigned long)(PL_an++),
d1053 13
a1065 3
	if (((UV)p) & (MEM_ALIGNBYTES - 1))
	    PerlIO_printf(PerlIO_stderr(), "Corrupt malloc ptr 0x%lx at 0x%lx\n",
		(unsigned long)*((int*)p),(unsigned long)p);
d1068 3
a1097 1
	MUTEX_UNLOCK(&PL_malloc_mutex);
d1201 1
a1201 1
getpages(int needed, int *nblksp, int bucket)
d1208 1
a1208 1
    int slack = 0;
d1235 1
d1241 3
d1260 4
a1263 5

	/* CHUNK_SHIFT is 1 for PACK_MALLOC, 0 otherwise. */
	if ((UV)cp & (0x7FF >> CHUNK_SHIFT)) { /* Not aligned. */
	    slack = (0x800 >> CHUNK_SHIFT)
		- ((UV)cp & (0x7FF >> CHUNK_SHIFT));
d1285 2
a1286 2
		    MUTEX_UNLOCK(&PL_malloc_mutex);
		    croak("%s", "panic: Off-page sbrk");
d1323 5
d1329 1
a1329 2
	if ((UV)ovp & 7) {
	    ovp = (union overhead *)(((UV)ovp + 8) & ~7);
d1332 3
a1334 1
				  (int)((UV)ovp & 7)));
d1338 1
a1338 1
	    sbrk_slack += (1 << bucket);
d1342 1
d1344 1
a1346 1
    last_op = (char*) cp;
d1354 1
a1354 1
getpages_adjacent(int require)
d1408 1
a1408 1
	    MUTEX_UNLOCK(&PL_malloc_mutex);
d1495 2
a1496 2
free(void *mp)
{   
d1505 2
a1506 2
			      "0x%lx: (%05lu) free\n",
			      (unsigned long)cp, (unsigned long)(PL_an++)));
d1524 1
d1531 9
d1542 8
d1553 1
a1555 1
	MUTEX_LOCK(&PL_malloc_mutex);
d1576 2
d1580 1
a1580 1
	MUTEX_UNLOCK(&PL_malloc_mutex);
d1583 4
a1586 12
/*
 * When a program attempts "storage compaction" as mentioned in the
 * old malloc man page, it realloc's an already freed block.  Usually
 * this is the last block it freed; occasionally it might be farther
 * back.  We have to search all the free lists for the block in order
 * to determine its bucket: 1st we make one pass thru the lists
 * checking only the first block in each; if that fails we search
 * ``reall_srchlen'' blocks in each list for a match (the variable
 * is extern so the caller can modify it).  If that fails we just copy
 * however many bytes was given to realloc() and hope it's not huge.
 */
int reall_srchlen = 4;  /* 4 should be plenty, -1 =>'s whole list */
d1589 2
a1590 2
realloc(void *mp, size_t nbytes)
{   
d1596 2
a1597 1
	int was_alloced = 0, incr;
d1604 1
a1604 1
		croak("%s", "panic: realloc");
d1609 1
a1609 1
		return malloc(nbytes);
a1610 1
	MUTEX_LOCK(&PL_malloc_mutex);
d1614 1
d1616 2
a1617 2
	if ((bucket < FIRST_BUCKET_WITH_CHECK) 
	    || (OV_MAGIC(ovp, bucket) == MAGIC))
d1619 1
a1619 1
	if (OV_MAGIC(ovp, bucket) == MAGIC) 
d1621 39
a1659 18
	{
		was_alloced = 1;
	} else {
		/*
		 * Already free, doing "compaction".
		 *
		 * Search for the old block of memory on the
		 * free list.  First, check the most common
		 * case (last element free'd), then (this failing)
		 * the last ``reall_srchlen'' items free'd.
		 * If all lookups fail, then assume the size of
		 * the memory block being realloc'd is the
		 * smallest possible.
		 */
		if ((bucket = findbucket(ovp, 1)) < 0 &&
		    (bucket = findbucket(ovp, reall_srchlen)) < 0)
			bucket = 0;
	}
a1687 1
	if (!was_alloced
d1689 1
a1689 1
	    || 1 /* always do it the hard way */
d1691 1
a1691 2
	    ) goto hard_way;
	else if (incr == 0) {
a1727 1
		MUTEX_UNLOCK(&PL_malloc_mutex);
d1729 2
a1730 2
			      "0x%lx: (%05lu) realloc %ld bytes inplace\n",
			      (unsigned long)res,(unsigned long)(PL_an++),
d1748 3
a1750 1
	    if (getpages_adjacent(require)) {
d1756 1
d1758 2
a1759 1
	    } else
d1761 1
a1763 1
	    MUTEX_UNLOCK(&PL_malloc_mutex);
d1765 2
a1766 2
			      "0x%lx: (%05lu) realloc %ld bytes the hard way\n",
			      (unsigned long)cp,(unsigned long)(PL_an++),
d1768 1
a1768 1
	    if ((res = (char*)malloc(nbytes)) == NULL)
d1772 1
a1772 2
	    if (was_alloced)
		free(cp);
a1776 22
/*
 * Search ``srchlen'' elements of each free list for a block whose
 * header starts at ``freep''.  If srchlen is -1 search the whole list.
 * Return bucket number, or -1 if not found.
 */
static int
findbucket(union overhead *freep, int srchlen)
{
	register union overhead *p;
	register int i, j;

	for (i = 0; i < NBUCKETS; i++) {
		j = 0;
		for (p = nextf[i]; p && j != srchlen; p = p->ov_next) {
			if (p == freep)
				return (i);
			j++;
		}
	}
	return (-1);
}

d1778 1
a1778 1
calloc(register size_t elements, register size_t size)
d1781 1
a1781 1
    Malloc_t p = malloc(sz);
d1789 40
d1830 1
a1830 1
malloced_size(void *p)
a1846 2
#ifdef DEBUGGING_MSTATS

d1852 51
d1911 1
a1911 1
dump_mstats(char *s)
d1913 1
d1916 8
a1923 4
  	int topbucket=0, topbucket_ev=0, topbucket_odd=0, totfree=0, total=0;
	u_int nfree[NBUCKETS];
	int total_chain = 0;
	struct chunk_chain_s* nextchain = chunk_chain;
a1924 11
  	for (i = MIN_BUCKET ; i < NBUCKETS; i++) {
  		for (j = 0, p = nextf[i]; p; p = p->ov_next, j++)
  			;
		nfree[i] = j;
  		totfree += nfree[i] * BUCKET_SIZE_REAL(i);
  		total += nmalloc[i] * BUCKET_SIZE_REAL(i);
		if (nmalloc[i]) {
		    i % 2 ? (topbucket_odd = i) : (topbucket_ev = i);
		    topbucket = i;
		}
  	}
d1926 1
a1926 1
	    PerlIO_printf(PerlIO_stderr(),
d1931 5
a1935 4
			  (long)BUCKET_SIZE_REAL(topbucket), (long)BUCKET_SIZE(topbucket));
  	PerlIO_printf(PerlIO_stderr(), "%8d free:", totfree);
  	for (i = MIN_EVEN_REPORT; i <= topbucket; i += BUCKETS_PER_POW2) {
  		PerlIO_printf(PerlIO_stderr(), 
d1939 1
a1939 1
			      nfree[i]);
d1942 3
a1944 3
	PerlIO_printf(PerlIO_stderr(), "\n\t   ");
  	for (i = MIN_BUCKET + 1; i <= topbucket_odd; i += BUCKETS_PER_POW2) {
  		PerlIO_printf(PerlIO_stderr(), 
d1948 1
a1948 1
			      nfree[i]);
d1951 3
a1953 3
  	PerlIO_printf(PerlIO_stderr(), "\n%8d used:", total - totfree);
  	for (i = MIN_EVEN_REPORT; i <= topbucket; i += BUCKETS_PER_POW2) {
  		PerlIO_printf(PerlIO_stderr(), 
d1957 1
a1957 1
			      nmalloc[i] - nfree[i]);
d1960 3
a1962 3
	PerlIO_printf(PerlIO_stderr(), "\n\t   ");
  	for (i = MIN_BUCKET + 1; i <= topbucket_odd; i += BUCKETS_PER_POW2) {
  		PerlIO_printf(PerlIO_stderr(), 
d1966 1
a1966 1
			      nmalloc[i] - nfree[i]);
d1969 5
a1973 7
	while (nextchain) {
	    total_chain += nextchain->size;
	    nextchain = nextchain->next;
	}
	PerlIO_printf(PerlIO_stderr(), "\nTotal sbrk(): %d/%d:%d. Odd ends: pad+heads+chain+tail: %d+%d+%d+%d.\n",
		      goodsbrk + sbrk_slack, sbrks, sbrk_good, sbrk_slack,
		      start_slack, total_chain, sbrked_remains);
a1974 6
#else
void
dump_mstats(char *s)
{
}
#endif
a1976 1

d1979 1
a1979 1
#   if defined(__MACHTEN_PPC__) || defined(__NeXT__)
a1980 11
/*
 * MachTen's malloc() returns a buffer aligned on a two-byte boundary.
 * While this is adequate, it may slow down access to longer data
 * types by forcing multiple memory accesses.  It also causes
 * complaints when RCHECK is in force.  So we allocate six bytes
 * more than we need to, and return an address rounded up to an
 * eight-byte boundary.
 *
 * 980701 Dominic Dunlop <domo@@computer.org>
 */
#      define SYSTEM_ALLOC(a) ((void *)(((unsigned)malloc((a)+6)+6)&~7))
a1983 8
#      if defined(HIDEMYMALLOC) || defined(EMBEDMYMALLOC)
#         undef malloc		/* Expose names that  */
#         undef calloc		/* HIDEMYMALLOC hides */
#         undef realloc
#         undef free
#      else
#         include "Error: -DPERL_SBRK_VIA_MALLOC needs -D(HIDE|EMBED)MYMALLOC"
#      endif
d1993 3
d2029 3
d2033 3
a2035 3
#ifdef PACK_MALLOC
      got = (got + 0x7ff) & ~0x7ff;
#endif
d2043 2
a2044 2
    DEBUG_m(PerlIO_printf(Perl_debug_log, "sbrk malloc size %ld (reqsize %ld), left size %ld, give addr 0x%lx\n",
		    size, reqsize, Perl_sbrk_oldsize, got));
@


1.2
log
@perl 5.004_04
@
text
@d5 119
a123 2
#if defined(PERL_CORE) && !defined(DEBUGGING_MSTATS)
#  define DEBUGGING_MSTATS
d126 27
d157 3
d173 57
a229 2
#include "EXTERN.h"
#include "perl.h"
d232 2
a233 2
#undef DEBUG_m
#define DEBUG_m(a)  if (debug & 128)   a
d240 7
d250 2
a251 2
#if (defined(RCHECK) || defined(I286) || defined(atarist)) && defined(PACK_MALLOC)
#undef PACK_MALLOC
a253 1

d285 1
a285 1
static void botch _((char *s));
d289 1
d293 2
d298 1
a298 1
#    define MAX_SHORT_BUCKET 12
d300 1
a300 1
#    define MAX_SHORT_BUCKET 13
d306 45
d352 5
a356 6
/*
 * In this case it is assumed that if we do sbrk() in 2K units, we
 * will get 2K aligned blocks. The bucket number of the given subblock is
 * on the boundary of 2K block which contains the subblock.
 * Several following bytes contain the magic numbers for the subblocks
 * in the block.
d362 8
a369 8
 * We suppose that starts of all the chunks in a 2K block are in
 * different 2^n-byte-long chunks.  If the top of the last chunk is
 * aligned on a boundary of 2K block, this means that
 * sizeof(union overhead)*"number of chunks" < 2^n, or
 * sizeof(union overhead)*2K < 4^n, or n > 6 + log2(sizeof()/2)/2, if a
 * chunk of size 2^n - overhead is used. Since this rules out n = 7
 * for 8 byte alignment, we specialcase allocation of the first of 16
 * 128-byte-long chunks.
d373 8
a380 8
 * overlay union overhead over the chunk, thus the start of the chunk
 * is immediately overwritten after freeing.
 */
#  define MAX_PACKED 6
#  define MAX_2_POT_ALGO ((1<<(MAX_PACKED + 1)) - M_OVERHEAD)
#  define TWOK_MASK ((1<<11) - 1)
#  define TWOK_MASKED(x) ((u_int)(x) & ~TWOK_MASK)
#  define TWOK_SHIFT(x) ((u_int)(x) & TWOK_MASK)
d384 10
a393 2
				    (TWOK_SHIFT(block)>>(bucket + 3)) + \
				    (bucket > MAX_NONSHIFT ? 1 : 0)))
d396 53
a448 8
static u_char n_blks[11 - 3]	 = {224, 120, 62, 31, 16, 8, 4, 2};
static u_short blk_shift[11 - 3] = {256, 128, 64, 32, 
				    16*sizeof(union overhead), 
				    8*sizeof(union overhead), 
				    4*sizeof(union overhead), 
				    2*sizeof(union overhead), 
#  define MAX_NONSHIFT 2	/* Shift 64 greater than chunk 32. */
};
d455 1
d458 47
a504 1
#  define M_OVERHEAD (sizeof(union overhead) + RSLOP)
d516 2
a517 2
#  ifndef FIRST_BIG_TWO_POT
#    define FIRST_BIG_TWO_POT 14	/* 16K */
d519 1
a519 1
#  define FIRST_BIG_BLOCK (1<<FIRST_BIG_TWO_POT) /* 16K */
d525 41
a565 1
#endif /* TWO_POT_OPTIMIZE */
d569 10
a578 3
#ifndef BIG_SIZE
#  define BIG_SIZE (1<<16)		/* 64K */
#endif 
d582 1
d584 2
a585 3
static char *
emergency_sbrk(size)
    MEM_SIZE size;
d587 2
d591 2
a592 2
	die("Out of memory during request for %i bytes", size);
	/* croak may eat too much memory. */
d595 8
a602 1
    if (!emergency_buffer) {		
d605 1
a605 1
	GV **gvp = (GV**)hv_fetch(defstash, "^M", 2, 0);
d608 2
d611 7
a617 1
	if (!gvp) gvp = (GV**)hv_fetch(defstash, "\015", 1, 0);
d619 3
a621 1
	    || (SvLEN(sv) < (1<<11) - M_OVERHEAD)) 
d623 1
a623 1

d625 1
a625 1
	pv = SvPV(sv, na);
d627 1
a627 1
	if (((u_int)(pv - M_OVERHEAD)) & ((1<<11) - 1)) {
d632 2
a633 2
	emergency_buffer = pv - M_OVERHEAD;
	emergency_buffer_size = SvLEN(sv) + M_OVERHEAD;
d635 2
a636 6
	SvREADONLY_on(sv);
	die("Out of memory!");		/* croak may eat too much memory. */
    }
    else if (emergency_buffer_size >= size) {
	emergency_buffer_size -= size;
	return emergency_buffer + emergency_buffer_size;
d638 3
a640 2
    
    return (char *)-1;			/* poor guy... */
d643 1
a643 1
#else /* !(defined(TWO_POT_OPTIMIZE) && defined(PERL_CORE)) */
d645 1
a645 1
#endif /* !(defined(TWO_POT_OPTIMIZE) && defined(PERL_CORE)) */
d648 1
a648 1
 * nextf[i] is the pointer to the next free block of size 2^(i+3).  The
d652 1
a652 1
#define	NBUCKETS 30
d657 6
a662 1
char *  Perl_sbrk _((int size));
d664 2
a665 1
extern	char *sbrk();
a673 1
static	u_int goodsbrk;
d678 2
d681 2
a682 1
#define	ASSERT(p)   if (!(p)) botch(STRINGIFY(p));  else
d684 1
a684 2
botch(s)
	char *s;
d686 2
a687 2
	PerlIO_printf(PerlIO_stderr(), "assertion botched: %s\n", s);
	abort();
d690 1
a690 1
#define	ASSERT(p)
d694 1
a694 2
malloc(nbytes)
	register MEM_SIZE nbytes;
d697 1
a697 1
  	register int bucket = 0;
d704 1
a704 8
#ifdef PERL_CORE
#ifdef HAS_64K_LIMIT
	if (nbytes > 0xffff) {
		PerlIO_printf(PerlIO_stderr(),
			      "Allocation too large: %lx\n", (long)nbytes);
		my_exit(1);
	}
#endif /* HAS_64K_LIMIT */
d707 1
a707 1
		croak("panic: malloc");
a708 1
#endif /* PERL_CORE */
d710 1
d718 7
d727 4
a730 2
	else if (nbytes > MAX_2_POT_ALGO)
#endif
d732 9
a740 6
#ifdef TWO_POT_OPTIMIZE
		if (nbytes >= FIRST_BIG_BOUND)
			nbytes -= PERL_PAGESIZE;
#endif 
		nbytes += M_OVERHEAD;
		nbytes = (nbytes + 3) &~ 3; 
a741 4
  	shiftr = (nbytes - 1) >> 2;
	/* apart from this loop, this is O(1) */
  	while (shiftr >>= 1)
  		bucket++;
d748 2
a749 1
  	if ((p = (union overhead *)nextf[bucket]) == NULL) {
d751 1
a751 1
		if (!nomemok) {
d760 4
a763 4
#ifdef PERL_CORE
    DEBUG_m(PerlIO_printf(Perl_debug_log, "0x%lx: (%05lu) malloc %ld bytes\n",
	(unsigned long)(p+1),(unsigned long)(an++),(long)size));
#endif /* PERL_CORE */
d766 2
a767 2
#ifdef RCHECK
	if (*((int*)p) & (sizeof(union overhead) - 1))
d772 4
a775 1
	OV_MAGIC(p, bucket) = MAGIC;
a783 3
	nbytes = (size + M_OVERHEAD + 3) &~ 3; 
  	if (nbytes <= 0x10000)
		p->ov_size = nbytes - 1;
d785 13
a797 1
  	*((u_int *)((caddr_t)p + nbytes - RSLOP)) = RMAGIC;
d799 1
d803 56
a858 3
/*
 * Allocate more memory to the indicated bucket.
 */
d860 44
a903 2
morecore(bucket)
	register int bucket;
d905 20
a924 5
  	register union overhead *op;
  	register int rnu;       /* 2^rnu bytes will be requested */
  	register int nblks;     /* become nblks blocks of the desired size */
	register MEM_SIZE siz, needed;
	int slack = 0;
d926 25
a950 4
  	if (nextf[bucket])
  		return;
	if (bucket == (sizeof(MEM_SIZE)*8 - 3)) {
	    croak("Allocation too large");
d952 12
a963 14
	/*
	 * Insure memory is allocated
	 * on a page boundary.  Should
	 * make getpageize call?
	 */
#ifndef atarist /* on the atari we dont have to worry about this */
  	op = (union overhead *)sbrk(0);
#  ifndef I286
  	if ((UV)op & (0x7FF >> CHUNK_SHIFT)) {
	    slack = (0x800 >> CHUNK_SHIFT) - ((UV)op & (0x7FF >> CHUNK_SHIFT));
	    (void)sbrk(slack);
#    if defined(DEBUGGING_MSTATS)
	    sbrk_slack += slack;
#    endif
a964 2
#  else
	/* The sbrk(0) call on the I286 always returns the next segment */
d966 21
a986 9
#endif /* atarist */

#if !(defined(I286) || defined(atarist))
	/* take 2k unless the block is bigger than that */
  	rnu = (bucket <= 8) ? 11 : bucket + 3;
#else
	/* take 16k unless the block is bigger than that 
	   (80286s like large segments!), probably good on the atari too */
  	rnu = (bucket <= 11) ? 14 : bucket + 3;
d988 12
a999 4
  	nblks = 1 << (rnu - (bucket + 3));  /* how many blocks to get */
	needed = (MEM_SIZE)1 << rnu;
#ifdef TWO_POT_OPTIMIZE
	needed += (bucket >= (FIRST_BIG_TWO_POT - 3) ? PERL_PAGESIZE : 0);
d1001 13
a1013 6
	op = (union overhead *)sbrk(needed);
	/* no more room! */
  	if (op == (union overhead *)-1) {
	    op = (union overhead *)emergency_sbrk(needed);
	    if (op == (union overhead *)-1)
  		return;
d1015 2
a1016 3
#ifdef DEBUGGING_MSTATS
	goodsbrk += needed;
#endif	
d1021 46
a1066 11
#ifndef I286
#  ifdef PACK_MALLOC
	if ((UV)op & 0x7FF)
		croak("panic: Off-page sbrk");
#  endif
  	if ((UV)op & 7) {
  		op = (union overhead *)(((UV)op + 8) & ~7);
  		nblks--;
  	}
#else
	/* Again, this should always be ok on an 80286 */
d1068 76
d1148 1
a1148 1
  	siz = 1 << (bucket + 3);
d1150 4
a1153 4
	*(u_char*)op = bucket;	/* Fill index. */
	if (bucket <= MAX_PACKED - 3) {
	    op = (union overhead *) ((char*)op + blk_shift[bucket]);
	    nblks = n_blks[bucket];
d1155 1
a1155 1
	    start_slack += blk_shift[bucket];
d1157 2
a1158 3
	} else if (bucket <= 11 - 1 - 3) {
	    op = (union overhead *) ((char*)op + blk_shift[bucket]);
	    /* nblks = n_blks[bucket]; */
d1160 3
a1162 3
	} else op++;		/* One chunk per block. */
#endif /* !PACK_MALLOC */
  	nextf[bucket] = op;
d1165 3
d1170 2
a1171 2
		op->ov_next = (union overhead *)((caddr_t)op + siz);
		op = (union overhead *)((caddr_t)op + siz);
d1174 1
a1174 1
	op->ov_next = (union overhead *)NULL;
d1176 6
a1181 5
	if (bucket == 7 - 3) {	/* Special case, explanation is above. */
	    union overhead *n_op = nextf[7 - 3]->ov_next;
	    nextf[7 - 3] = (union overhead *)((caddr_t)nextf[7 - 3] 
					      - sizeof(union overhead));
	    nextf[7 - 3]->ov_next = n_op;
d1187 1
a1187 2
free(mp)
	Malloc_t mp;
d1190 1
a1190 1
	register union overhead *op;
d1196 3
a1198 3
#ifdef PERL_CORE
    DEBUG_m(PerlIO_printf(Perl_debug_log, "0x%lx: (%05lu) free\n",(unsigned long)cp,(unsigned long)(an++)));
#endif /* PERL_CORE */
d1202 1
a1202 1
	op = (union overhead *)((caddr_t)cp 
d1205 1
a1205 1
	bucket = OV_INDEX(op);
d1207 7
a1213 1
	if (OV_MAGIC(op, bucket) != MAGIC) {
d1216 1
a1216 1
		    char *pbf = getenv("PERL_BADFREE");
d1223 1
a1223 1
		    op->ov_rmagic == RMAGIC - 1 ? "Duplicate" : "Bad");
d1225 1
a1225 1
		warn("Bad free() ignored");
d1228 17
d1246 7
a1252 10
#ifdef RCHECK
  	ASSERT(op->ov_rmagic == RMAGIC);
	if (OV_INDEX(op) <= MAX_SHORT_BUCKET)
		ASSERT(*(u_int *)((caddr_t)op + op->ov_size + 1 - RSLOP) == RMAGIC);
	op->ov_rmagic = RMAGIC - 1;
#endif
  	ASSERT(OV_INDEX(op) < NBUCKETS);
  	size = OV_INDEX(op);
	op->ov_next = nextf[size];
  	nextf[size] = op;
d1266 1
a1266 1
int reall_srchlen = 4;	/* 4 should be plenty, -1 =>'s whole list */
d1269 1
a1269 3
realloc(mp, nbytes)
	Malloc_t mp; 
	MEM_SIZE nbytes;
d1272 1
a1272 1
	union overhead *op;
d1274 3
a1276 2
	register int i;
	int was_alloced = 0;
d1279 1
a1279 1
#ifdef DEBUGGING
d1281 3
d1286 1
a1286 8
#ifdef PERL_CORE
#ifdef HAS_64K_LIMIT
	if (nbytes > 0xffff) {
		PerlIO_printf(PerlIO_stderr(),
			      "Reallocation too large: %lx\n", size);
		my_exit(1);
	}
#endif /* HAS_64K_LIMIT */
a1288 5
#ifdef DEBUGGING
	if ((long)nbytes < 0)
		croak("panic: realloc");
#endif
#endif /* PERL_CORE */
d1290 2
a1291 1
	op = (union overhead *)((caddr_t)cp 
d1293 8
a1300 2
	i = OV_INDEX(op);
	if (OV_MAGIC(op, i) == MAGIC) {
d1314 3
a1316 3
		if ((i = findbucket(op, 1)) < 0 &&
		    (i = findbucket(op, reall_srchlen)) < 0)
			i = 0;
d1318 1
a1318 10
	onb = (1L << (i + 3)) - 
#ifdef PACK_MALLOC
	    (i <= (MAX_PACKED - 3) ? 0 : M_OVERHEAD)
#else
	    M_OVERHEAD
#endif
#ifdef TWO_POT_OPTIMIZE
	    + (i >= (FIRST_BIG_TWO_POT - 3) ? PERL_PAGESIZE : 0)
#endif
	    ;
d1321 2
a1322 2
	 *  We are not agressive with boundary cases. Note that it is
	 *  possible for small number of cases give false negative if
d1324 3
a1326 1
	 *  FIRST_BIG_TWO_POT, but the new one is near the lower end.
d1328 25
a1352 7
	if (was_alloced &&
	    nbytes <= onb && (nbytes > ( (onb >> 1) - M_OVERHEAD )
#ifdef TWO_POT_OPTIMIZE
			      || (i == (FIRST_BIG_TWO_POT - 3) 
				  && nbytes >= LAST_SMALL_BOUND )
#endif	
		)) {
d1358 11
a1368 1
		if (OV_INDEX(op) <= MAX_SHORT_BUCKET) {
d1376 7
d1384 1
a1384 2
			op->ov_size = nbytes - 1;
			*((u_int *)((caddr_t)op + nbytes - RSLOP)) = RMAGIC;
d1388 43
a1431 18
	else {
		if ((res = (char*)malloc(nbytes)) == NULL)
			return (NULL);
		if (cp != res)			/* common optimization */
			Copy(cp, res, (MEM_SIZE)(nbytes<onb?nbytes:onb), char);
		if (was_alloced)
			free(cp);
	}

#ifdef PERL_CORE
#ifdef DEBUGGING
    if (debug & 128) {
	PerlIO_printf(Perl_debug_log, "0x%lx: (%05lu) rfree\n",(unsigned long)res,(unsigned long)(an++));
	PerlIO_printf(Perl_debug_log, "0x%lx: (%05lu) realloc %ld bytes\n",
	    (unsigned long)res,(unsigned long)(an++),(long)size);
    }
#endif
#endif /* PERL_CORE */
d1441 1
a1441 3
findbucket(freep, srchlen)
	union overhead *freep;
	int srchlen;
d1458 1
a1458 3
calloc(elements, size)
	register MEM_SIZE elements;
	register MEM_SIZE size;
d1469 18
d1488 6
d1502 1
a1502 2
dump_mstats(s)
	char *s;
d1506 1
a1506 1
  	int topbucket=0, totfree=0, total=0;
d1508 2
d1511 1
a1511 1
  	for (i=0; i < NBUCKETS; i++) {
d1515 6
a1520 4
  		totfree += nfree[i]   * (1 << (i + 3));
  		total += nmalloc[i] * (1 << (i + 3));
		if (nmalloc[i])
			topbucket = i;
d1523 6
a1528 2
		PerlIO_printf(PerlIO_stderr(), "Memory allocation statistics %s (buckets 8..%d)\n",
			s, (1 << (topbucket + 3)) );
d1530 15
a1544 2
  	for (i=0; i <= topbucket; i++) {
  		PerlIO_printf(PerlIO_stderr(), (i<5 || i==7)?" %5d": (i<9)?" %3d":" %d", nfree[i]);
d1546 1
d1548 15
a1562 2
  	for (i=0; i <= topbucket; i++) {
  		PerlIO_printf(PerlIO_stderr(), (i<5 || i==7)?" %5d": (i<9)?" %3d":" %d", nmalloc[i] - nfree[i]);
d1564 8
a1571 2
	PerlIO_printf(PerlIO_stderr(), "\nTotal sbrk(): %8d. Odd ends: sbrk(): %7d, malloc(): %7d bytes.\n",
		      goodsbrk + sbrk_slack, sbrk_slack, start_slack);
d1575 1
a1575 2
dump_mstats(s)
    char *s;
d1584 1
a1584 1
#   ifdef NeXT
d1586 11
d1601 4
a1604 1
#         undef malloc
d1614 3
a1616 1
#      define SYSTEM_ALLOC(a) malloc(a)
d1626 2
a1627 3
char *
Perl_sbrk(size)
int size;
a1646 3
#ifndef PERL_CORE
	reqsize = size;
#endif
a1660 1
#ifdef PERL_CORE
a1662 1
#endif
@


1.1
log
@Initial revision
@
text
@d5 4
d10 3
a12 3
#ifdef DEBUGGING
#define RCHECK
#endif
d21 1
d29 5
d40 6
d47 2
d76 1
a76 1
#ifdef debug
d85 6
a90 1
#define	RSLOP		sizeof (u_int)
d92 1
a92 1
#define	RSLOP		0
d95 134
d236 5
d242 1
d250 3
a252 1
#include <stdio.h>
d255 2
a256 2
#ifdef debug
#define	ASSERT(p)   if (!(p)) botch("p"); else
d261 1
a261 2

	printf("assertion botched: %s\n", s);
d276 1
a276 2
#ifdef safemalloc
#ifdef DEBUGGING
d280 2
a281 1
#ifdef MSDOS
d283 2
a284 1
		fprintf(stderr, "Allocation too large: %lx\n", (long)nbytes);
d287 1
a287 1
#endif /* MSDOS */
d290 1
a290 1
	    croak("panic: malloc");
d292 1
a292 1
#endif /* safemalloc */
d300 13
a312 2
  	nbytes += sizeof (union overhead) + RSLOP;
  	nbytes = (nbytes + 3) &~ 3; 
d324 1
a324 1
#ifdef safemalloc
d326 1
a326 1
		    fputs("Out of memory!\n", stderr);
d334 4
a337 4
#ifdef safemalloc
    DEBUG_m(fprintf(stderr,"0x%lx: (%05d) malloc %ld bytes\n",
	(unsigned long)(p+1),an++,(long)size));
#endif /* safemalloc */
d342 1
a342 1
	    fprintf(stderr,"Corrupt malloc ptr 0x%lx at 0x%lx\n",
d346 3
a348 4
	p->ov_magic = MAGIC;
	p->ov_index= bucket;
#ifdef DEBUGGING_MSTATS
  	nmalloc[bucket]++;
d355 1
d361 1
a361 1
  	return ((Malloc_t)(p + 1));
d374 2
a375 1
	register MEM_SIZE siz;
d379 3
d389 9
a397 4
#ifndef I286
  	if ((int)op & 0x3ff)
  		(void)sbrk(1024 - ((int)op & 0x3ff));
#else
d399 1
a399 1
#endif
d411 5
a415 3
  	if (rnu < bucket)
		rnu = bucket;
	op = (union overhead *)sbrk(1L << rnu);
d417 3
a419 1
  	if ((int)op == -1)
d421 4
d430 6
a435 2
  	if ((int)op & 7) {
  		op = (union overhead *)(((MEM_SIZE)op + 8) &~ 7);
d445 15
d461 3
a463 1
  	siz = 1 << (bucket + 3);
d468 10
d487 23
a509 12

#ifdef safemalloc
    DEBUG_m(fprintf(stderr,"0x%lx: (%05d) free\n",(unsigned long)cp,an++));
#endif /* safemalloc */

  	if (cp == NULL)
  		return;
	op = (union overhead *)((caddr_t)cp - sizeof (union overhead));
#ifdef debug
  	ASSERT(op->ov_magic == MAGIC);		/* make sure it was in use */
#else
	if (op->ov_magic != MAGIC) {
a517 1
#endif
d520 1
a520 1
	if (op->ov_index <= 13)
d524 2
a525 2
  	ASSERT(op->ov_index < NBUCKETS);
  	size = op->ov_index;
a527 3
#ifdef DEBUGGING_MSTATS
  	nmalloc[size]--;
#endif
a554 1
#ifdef safemalloc
d559 2
a560 1
#ifdef MSDOS
d562 2
a563 1
		fprintf(stderr, "Reallocation too large: %lx\n", size);
d566 1
a566 1
#endif /* MSDOS */
d573 1
a573 1
#endif /* safemalloc */
d575 5
a579 4
	op = (union overhead *)((caddr_t)cp - sizeof (union overhead));
	if (op->ov_magic == MAGIC) {
		was_alloced++;
		i = op->ov_index;
d596 17
a612 2
	onb = (1L << (i + 3)) - sizeof (*op) - RSLOP;
	/* avoid the copy if same size block */
d614 6
a619 1
	    nbytes <= onb && nbytes > (onb >> 1) - sizeof(*op) - RSLOP) {
d625 1
a625 1
		if (op->ov_index <= 13) {
d632 1
a632 1
			nbytes += sizeof (union overhead) + RSLOP;
d649 1
a649 1
#ifdef safemalloc
d652 3
a654 3
	fprintf(stderr,"0x%lx: (%05d) rfree\n",(unsigned long)res,an++);
	fprintf(stderr,"0x%lx: (%05d) realloc %ld bytes\n",
	    (unsigned long)res,an++,(long)size);
d657 1
a657 1
#endif /* safemalloc */
d685 14
d713 1
a713 1
  	int topbucket=0, totfree=0, totused=0;
d721 2
a722 2
  		totused += nmalloc[i] * (1 << (i + 3));
		if (nfree[i] || nmalloc[i])
d726 1
a726 1
		fprintf(stderr, "Memory allocation statistics %s (buckets 8..%d)\n",
d728 1
a728 1
  	fprintf(stderr, " %7d free: ", totfree);
d730 1
a730 1
  		fprintf(stderr, (i<5)?" %5d":" %3d", nfree[i]);
d732 1
a732 1
  	fprintf(stderr, "\n %7d used: ", totused);
d734 1
a734 1
  		fprintf(stderr, (i<5)?" %5d":" %3d", nmalloc[i]);
d736 2
a737 1
  	fprintf(stderr, "\n");
d747 78
@


1.1.1.1
log
@Import of Perl 5.003 into the tree.  Makefile.bsd-wrapper and
config.sh.OpenBSD are the only local changes.
@
text
@@


1.1.1.2
log
@perl5.005_03
@
text
@d5 3
a7 134
/*
  Here are some notes on configuring Perl's malloc.
 
  There are two macros which serve as bulk disablers of advanced
  features of this malloc: NO_FANCY_MALLOC, PLAIN_MALLOC (undef by
  default).  Look in the list of default values below to understand
  their exact effect.  Defining NO_FANCY_MALLOC returns malloc.c to the
  state of the malloc in Perl 5.004.  Additionally defining PLAIN_MALLOC
  returns it to the state as of Perl 5.000.

  Note that some of the settings below may be ignored in the code based
  on values of other macros.  The PERL_CORE symbol is only defined when
  perl itself is being compiled (so malloc can make some assumptions
  about perl's facilities being available to it).

  Each config option has a short description, followed by its name,
  default value, and a comment about the default (if applicable).  Some
  options take a precise value, while the others are just boolean.
  The boolean ones are listed first.

    # Enable code for an emergency memory pool in $^M.  See perlvar.pod
    # for a description of $^M.
    PERL_EMERGENCY_SBRK		(!PLAIN_MALLOC && PERL_CORE)

    # Enable code for printing memory statistics.
    DEBUGGING_MSTATS		(!PLAIN_MALLOC && PERL_CORE)

    # Move allocation info for small buckets into separate areas.
    # Memory optimization (especially for small allocations, of the
    # less than 64 bytes).  Since perl usually makes a large number
    # of small allocations, this is usually a win.
    PACK_MALLOC			(!PLAIN_MALLOC && !RCHECK)

    # Add one page to big powers of two when calculating bucket size.
    # This is targeted at big allocations, as are common in image
    # processing.
    TWO_POT_OPTIMIZE		!PLAIN_MALLOC
 
    # Use intermediate bucket sizes between powers-of-two.  This is
    # generally a memory optimization, and a (small) speed pessimization.
    BUCKETS_ROOT2		!NO_FANCY_MALLOC

    # Do not check small deallocations for bad free().  Memory
    # and speed optimization, error reporting pessimization.
    IGNORE_SMALL_BAD_FREE	(!NO_FANCY_MALLOC && !RCHECK)

    # Use table lookup to decide in which bucket a given allocation will go.
    SMALL_BUCKET_VIA_TABLE	!NO_FANCY_MALLOC

    # Use a perl-defined sbrk() instead of the (presumably broken or
    # missing) system-supplied sbrk().
    USE_PERL_SBRK		undef

    # Use system malloc() (or calloc() etc.) to emulate sbrk(). Normally
    # only used with broken sbrk()s.
    PERL_SBRK_VIA_MALLOC	undef

    # Which allocator to use if PERL_SBRK_VIA_MALLOC
    SYSTEM_ALLOC(a) 		malloc(a)

    # Disable memory overwrite checking with DEBUGGING.  Memory and speed
    # optimization, error reporting pessimization.
    NO_RCHECK			undef

    # Enable memory overwrite checking with DEBUGGING.  Memory and speed
    # pessimization, error reporting optimization
    RCHECK			(DEBUGGING && !NO_RCHECK)

    # Failed allocations bigger than this size croak (if
    # PERL_EMERGENCY_SBRK is enabled) without touching $^M.  See
    # perlvar.pod for a description of $^M.
    BIG_SIZE			 (1<<16)	# 64K

    # Starting from this power of two, add an extra page to the
    # size of the bucket. This enables optimized allocations of sizes
    # close to powers of 2.  Note that the value is indexed at 0.
    FIRST_BIG_POW2 		15		# 32K, 16K is used too often

    # Estimate of minimal memory footprint.  malloc uses this value to
    # request the most reasonable largest blocks of memory from the system.
    FIRST_SBRK 			(48*1024)

    # Round up sbrk()s to multiples of this.
    MIN_SBRK 			2048

    # Round up sbrk()s to multiples of this percent of footprint.
    MIN_SBRK_FRAC 		3

    # Add this much memory to big powers of two to get the bucket size.
    PERL_PAGESIZE 		4096

    # This many sbrk() discontinuities should be tolerated even
    # from the start without deciding that sbrk() is usually
    # discontinuous.
    SBRK_ALLOW_FAILURES		3

    # This many continuous sbrk()s compensate for one discontinuous one.
    SBRK_FAILURE_PRICE		50

    # Some configurations may ask for 12-byte-or-so allocations which
    # require 8-byte alignment (?!).  In such situation one needs to
    # define this to disable 12-byte bucket (will increase memory footprint)
    STRICT_ALIGNMENT		undef

  This implementation assumes that calling PerlIO_printf() does not
  result in any memory allocation calls (used during a panic).

 */

#ifndef NO_FANCY_MALLOC
#  ifndef SMALL_BUCKET_VIA_TABLE
#    define SMALL_BUCKET_VIA_TABLE
#  endif 
#  ifndef BUCKETS_ROOT2
#    define BUCKETS_ROOT2
#  endif 
#  ifndef IGNORE_SMALL_BAD_FREE
#    define IGNORE_SMALL_BAD_FREE
#  endif 
#endif 

#ifndef PLAIN_MALLOC			/* Bulk enable features */
#  ifndef PACK_MALLOC
#      define PACK_MALLOC
#  endif 
#  ifndef TWO_POT_OPTIMIZE
#    define TWO_POT_OPTIMIZE
#  endif 
#  if defined(PERL_CORE) && !defined(PERL_EMERGENCY_SBRK)
#    define PERL_EMERGENCY_SBRK
#  endif 
#  if defined(PERL_CORE) && !defined(DEBUGGING_MSTATS)
#    define DEBUGGING_MSTATS
#  endif 
a8 20

#define MIN_BUC_POW2 (sizeof(void*) > 4 ? 3 : 2) /* Allow for 4-byte arena. */
#define MIN_BUCKET (MIN_BUC_POW2 * BUCKETS_PER_POW2)

#if !(defined(I286) || defined(atarist) || defined(__MINT__))
	/* take 2k unless the block is bigger than that */
#  define LOG_OF_MIN_ARENA 11
#else
	/* take 16k unless the block is bigger than that 
	   (80286s like large segments!), probably good on the atari too */
#  define LOG_OF_MIN_ARENA 14
#endif

#ifndef lint
#  if defined(DEBUGGING) && !defined(NO_RCHECK)
#    define RCHECK
#  endif
#  if defined(RCHECK) && defined(IGNORE_SMALL_BAD_FREE)
#    undef IGNORE_SMALL_BAD_FREE
#  endif 
a16 1
 * If PACK_MALLOC is defined, small blocks are 2^n bytes long.
d21 2
a22 62
#ifdef PERL_CORE
#  include "EXTERN.h"
#  include "perl.h"
#else
#  ifdef PERL_FOR_X2P
#    include "../EXTERN.h"
#    include "../perl.h"
#  else
#    include <stdlib.h>
#    include <stdio.h>
#    include <memory.h>
#    define _(arg) arg
#    ifndef Malloc_t
#      define Malloc_t void *
#    endif
#    ifndef MEM_SIZE
#      define MEM_SIZE unsigned long
#    endif
#    ifndef LONG_MAX
#      define LONG_MAX 0x7FFFFFFF
#    endif
#    ifndef UV
#      define UV unsigned long
#    endif
#    ifndef caddr_t
#      define caddr_t char *
#    endif
#    ifndef Free_t
#      define Free_t void
#    endif
#    define Copy(s,d,n,t) (void)memcpy((char*)(d),(char*)(s), (n) * sizeof(t))
#    define PerlEnv_getenv getenv
#    define PerlIO_printf fprintf
#    define PerlIO_stderr() stderr
#  endif
#  ifndef croak				/* make depend */
#    define croak(mess, arg) warn((mess), (arg)); exit(1);
#  endif 
#  ifndef warn
#    define warn(mess, arg) fprintf(stderr, (mess), (arg));
#  endif 
#  ifdef DEBUG_m
#    undef DEBUG_m
#  endif 
#  define DEBUG_m(a)
#  ifdef DEBUGGING
#     undef DEBUGGING
#  endif
#endif

#ifndef MUTEX_LOCK
#  define MUTEX_LOCK(l)
#endif 

#ifndef MUTEX_UNLOCK
#  define MUTEX_UNLOCK(l)
#endif 

#ifdef DEBUGGING
#  undef DEBUG_m
#  define DEBUG_m(a)  if (PL_debug & 128)   a
#endif
a27 7

#ifdef HAS_QUAD
#  define u_bigint UV			/* Needs to eat *void. */
#else  /* needed? */
#  define u_bigint unsigned long	/* Needs to eat *void. */
#endif

a29 5
/* 286 and atarist like big chunks, which gives too much overhead. */
#if (defined(RCHECK) || defined(I286) || defined(atarist) || defined(__MINT__)) && defined(PACK_MALLOC)
#  undef PACK_MALLOC
#endif 

a30 2
 * The description below is applicable if PACK_MALLOC is not defined.
 *
d58 2
a59 2
#ifdef DEBUGGING
static void botch _((char *diag, char *s));
a62 1
static void add_to_chain(void *p, MEM_SIZE size, MEM_SIZE chip);
a65 2
#define RMAGIC_C	0x55		/* magic # on range info */

d67 1
a67 6
#  define	RSLOP		sizeof (u_int)
#  ifdef TWO_POT_OPTIMIZE
#    define MAX_SHORT_BUCKET (12 * BUCKETS_PER_POW2)
#  else
#    define MAX_SHORT_BUCKET (13 * BUCKETS_PER_POW2)
#  endif 
d69 1
a69 1
#  define	RSLOP		0
a71 200
#if !defined(PACK_MALLOC) && defined(BUCKETS_ROOT2)
#  undef BUCKETS_ROOT2
#endif 

#ifdef BUCKETS_ROOT2
#  define BUCKET_TABLE_SHIFT 2
#  define BUCKET_POW2_SHIFT 1
#  define BUCKETS_PER_POW2 2
#else
#  define BUCKET_TABLE_SHIFT MIN_BUC_POW2
#  define BUCKET_POW2_SHIFT 0
#  define BUCKETS_PER_POW2 1
#endif 

#if !defined(MEM_ALIGNBYTES) || ((MEM_ALIGNBYTES > 4) && !defined(STRICT_ALIGNMENT))
/* Figure out the alignment of void*. */
struct aligner {
  char c;
  void *p;
};
#  define ALIGN_SMALL ((int)((caddr_t)&(((struct aligner*)0)->p)))
#else
#  define ALIGN_SMALL MEM_ALIGNBYTES
#endif

#define IF_ALIGN_8(yes,no)	((ALIGN_SMALL>4) ? (yes) : (no))

#ifdef BUCKETS_ROOT2
#  define MAX_BUCKET_BY_TABLE 13
static u_short buck_size[MAX_BUCKET_BY_TABLE + 1] = 
  { 
      0, 0, 0, 0, 4, 4, 8, 12, 16, 24, 32, 48, 64, 80,
  };
#  define BUCKET_SIZE(i) ((i) % 2 ? buck_size[i] : (1 << ((i) >> BUCKET_POW2_SHIFT)))
#  define BUCKET_SIZE_REAL(i) ((i) <= MAX_BUCKET_BY_TABLE		\
			       ? buck_size[i] 				\
			       : ((1 << ((i) >> BUCKET_POW2_SHIFT))	\
				  - MEM_OVERHEAD(i)			\
				  + POW2_OPTIMIZE_SURPLUS(i)))
#else
#  define BUCKET_SIZE(i) (1 << ((i) >> BUCKET_POW2_SHIFT))
#  define BUCKET_SIZE_REAL(i) (BUCKET_SIZE(i) - MEM_OVERHEAD(i) + POW2_OPTIMIZE_SURPLUS(i))
#endif 


#ifdef PACK_MALLOC
/* In this case it is assumed that if we do sbrk() in 2K units, we
 * will get 2K aligned arenas (at least after some initial
 * alignment). The bucket number of the given subblock is on the start
 * of 2K arena which contains the subblock.  Several following bytes
 * contain the magic numbers for the subblocks in the block.
 *
 * Sizes of chunks are powers of 2 for chunks in buckets <=
 * MAX_PACKED, after this they are (2^n - sizeof(union overhead)) (to
 * get alignment right).
 *
 * Consider an arena for 2^n with n>MAX_PACKED.  We suppose that
 * starts of all the chunks in a 2K arena are in different
 * 2^n-byte-long chunks.  If the top of the last chunk is aligned on a
 * boundary of 2K block, this means that sizeof(union
 * overhead)*"number of chunks" < 2^n, or sizeof(union overhead)*2K <
 * 4^n, or n > 6 + log2(sizeof()/2)/2, since a chunk of size 2^n -
 * overhead is used.  Since this rules out n = 7 for 8 byte alignment,
 * we specialcase allocation of the first of 16 128-byte-long chunks.
 *
 * Note that with the above assumption we automatically have enough
 * place for MAGIC at the start of 2K block.  Note also that we
 * overlay union overhead over the chunk, thus the start of small chunks
 * is immediately overwritten after freeing.  */
#  define MAX_PACKED_POW2 6
#  define MAX_PACKED (MAX_PACKED_POW2 * BUCKETS_PER_POW2 + BUCKET_POW2_SHIFT)
#  define MAX_POW2_ALGO ((1<<(MAX_PACKED_POW2 + 1)) - M_OVERHEAD)
#  define TWOK_MASK ((1<<LOG_OF_MIN_ARENA) - 1)
#  define TWOK_MASKED(x) ((u_bigint)(x) & ~TWOK_MASK)
#  define TWOK_SHIFT(x) ((u_bigint)(x) & TWOK_MASK)
#  define OV_INDEXp(block) ((u_char*)(TWOK_MASKED(block)))
#  define OV_INDEX(block) (*OV_INDEXp(block))
#  define OV_MAGIC(block,bucket) (*(OV_INDEXp(block) +			\
				    (TWOK_SHIFT(block)>>		\
				     (bucket>>BUCKET_POW2_SHIFT)) +	\
				    (bucket >= MIN_NEEDS_SHIFT ? 1 : 0)))
    /* A bucket can have a shift smaller than it size, we need to
       shift its magic number so it will not overwrite index: */
#  ifdef BUCKETS_ROOT2
#    define MIN_NEEDS_SHIFT (7*BUCKETS_PER_POW2 - 1) /* Shift 80 greater than chunk 64. */
#  else
#    define MIN_NEEDS_SHIFT (7*BUCKETS_PER_POW2) /* Shift 128 greater than chunk 32. */
#  endif 
#  define CHUNK_SHIFT 0

/* Number of active buckets of given ordinal. */
#ifdef IGNORE_SMALL_BAD_FREE
#define FIRST_BUCKET_WITH_CHECK (6 * BUCKETS_PER_POW2) /* 64 */
#  define N_BLKS(bucket) ( (bucket) < FIRST_BUCKET_WITH_CHECK 		\
			 ? ((1<<LOG_OF_MIN_ARENA) - 1)/BUCKET_SIZE(bucket) \
			 : n_blks[bucket] )
#else
#  define N_BLKS(bucket) n_blks[bucket]
#endif 

static u_short n_blks[LOG_OF_MIN_ARENA * BUCKETS_PER_POW2] = 
  {
#  if BUCKETS_PER_POW2==1
      0, 0,
      (MIN_BUC_POW2==2 ? 384 : 0),
      224, 120, 62, 31, 16, 8, 4, 2
#  else
      0, 0, 0, 0,
      (MIN_BUC_POW2==2 ? 384 : 0), (MIN_BUC_POW2==2 ? 384 : 0),	/* 4, 4 */
      224, 149, 120, 80, 62, 41, 31, 25, 16, 16, 8, 8, 4, 4, 2, 2
#  endif
  };

/* Shift of the first bucket with the given ordinal inside 2K chunk. */
#ifdef IGNORE_SMALL_BAD_FREE
#  define BLK_SHIFT(bucket) ( (bucket) < FIRST_BUCKET_WITH_CHECK 	\
			      ? ((1<<LOG_OF_MIN_ARENA)			\
				 - BUCKET_SIZE(bucket) * N_BLKS(bucket)) \
			      : blk_shift[bucket])
#else
#  define BLK_SHIFT(bucket) blk_shift[bucket]
#endif 

static u_short blk_shift[LOG_OF_MIN_ARENA * BUCKETS_PER_POW2] = 
  { 
#  if BUCKETS_PER_POW2==1
      0, 0,
      (MIN_BUC_POW2==2 ? 512 : 0),
      256, 128, 64, 64,			/* 8 to 64 */
      16*sizeof(union overhead), 
      8*sizeof(union overhead), 
      4*sizeof(union overhead), 
      2*sizeof(union overhead), 
#  else
      0, 0, 0, 0,
      (MIN_BUC_POW2==2 ? 512 : 0), (MIN_BUC_POW2==2 ? 512 : 0),
      256, 260, 128, 128, 64, 80, 64, 48, /* 8 to 96 */
      16*sizeof(union overhead), 16*sizeof(union overhead), 
      8*sizeof(union overhead), 8*sizeof(union overhead), 
      4*sizeof(union overhead), 4*sizeof(union overhead), 
      2*sizeof(union overhead), 2*sizeof(union overhead), 
#  endif 
  };

#else  /* !PACK_MALLOC */

#  define OV_MAGIC(block,bucket) (block)->ov_magic
#  define OV_INDEX(block) (block)->ov_index
#  define CHUNK_SHIFT 1
#  define MAX_PACKED -1
#endif /* !PACK_MALLOC */

#define M_OVERHEAD (sizeof(union overhead) + RSLOP)

#ifdef PACK_MALLOC
#  define MEM_OVERHEAD(bucket) \
  (bucket <= MAX_PACKED ? 0 : M_OVERHEAD)
#  ifdef SMALL_BUCKET_VIA_TABLE
#    define START_SHIFTS_BUCKET ((MAX_PACKED_POW2 + 1) * BUCKETS_PER_POW2)
#    define START_SHIFT MAX_PACKED_POW2
#    ifdef BUCKETS_ROOT2		/* Chunks of size 3*2^n. */
#      define SIZE_TABLE_MAX 80
#    else
#      define SIZE_TABLE_MAX 64
#    endif 
static char bucket_of[] =
  {
#    ifdef BUCKETS_ROOT2		/* Chunks of size 3*2^n. */
      /* 0 to 15 in 4-byte increments. */
      (sizeof(void*) > 4 ? 6 : 5),	/* 4/8, 5-th bucket for better reports */
      6,				/* 8 */
      IF_ALIGN_8(8,7), 8,		/* 16/12, 16 */
      9, 9, 10, 10,			/* 24, 32 */
      11, 11, 11, 11,			/* 48 */
      12, 12, 12, 12,			/* 64 */
      13, 13, 13, 13,			/* 80 */
      13, 13, 13, 13			/* 80 */
#    else /* !BUCKETS_ROOT2 */
      /* 0 to 15 in 4-byte increments. */
      (sizeof(void*) > 4 ? 3 : 2),
      3, 
      4, 4, 
      5, 5, 5, 5,
      6, 6, 6, 6,
      6, 6, 6, 6
#    endif /* !BUCKETS_ROOT2 */
  };
#  else  /* !SMALL_BUCKET_VIA_TABLE */
#    define START_SHIFTS_BUCKET MIN_BUCKET
#    define START_SHIFT (MIN_BUC_POW2 - 1)
#  endif /* !SMALL_BUCKET_VIA_TABLE */
#else  /* !PACK_MALLOC */
#  define MEM_OVERHEAD(bucket) M_OVERHEAD
#  ifdef SMALL_BUCKET_VIA_TABLE
#    undef SMALL_BUCKET_VIA_TABLE
#  endif 
#  define START_SHIFTS_BUCKET MIN_BUCKET
#  define START_SHIFT (MIN_BUC_POW2 - 1)
#endif /* !PACK_MALLOC */

d73 1
a73 142
 * Big allocations are often of the size 2^n bytes. To make them a
 * little bit better, make blocks of size 2^n+pagesize for big n.
 */

#ifdef TWO_POT_OPTIMIZE

#  ifndef PERL_PAGESIZE
#    define PERL_PAGESIZE 4096
#  endif 
#  ifndef FIRST_BIG_POW2
#    define FIRST_BIG_POW2 15	/* 32K, 16K is used too often. */
#  endif
#  define FIRST_BIG_BLOCK (1<<FIRST_BIG_POW2)
/* If this value or more, check against bigger blocks. */
#  define FIRST_BIG_BOUND (FIRST_BIG_BLOCK - M_OVERHEAD)
/* If less than this value, goes into 2^n-overhead-block. */
#  define LAST_SMALL_BOUND ((FIRST_BIG_BLOCK>>1) - M_OVERHEAD)

#  define POW2_OPTIMIZE_ADJUST(nbytes)				\
   ((nbytes >= FIRST_BIG_BOUND) ? nbytes -= PERL_PAGESIZE : 0)
#  define POW2_OPTIMIZE_SURPLUS(bucket)				\
   ((bucket >= FIRST_BIG_POW2 * BUCKETS_PER_POW2) ? PERL_PAGESIZE : 0)

#else  /* !TWO_POT_OPTIMIZE */
#  define POW2_OPTIMIZE_ADJUST(nbytes)
#  define POW2_OPTIMIZE_SURPLUS(bucket) 0
#endif /* !TWO_POT_OPTIMIZE */

#if defined(HAS_64K_LIMIT) && defined(PERL_CORE)
#  define BARK_64K_LIMIT(what,nbytes,size)				\
	if (nbytes > 0xffff) {						\
		PerlIO_printf(PerlIO_stderr(),				\
			      "%s too large: %lx\n", what, size);	\
		my_exit(1);						\
	}
#else /* !HAS_64K_LIMIT || !PERL_CORE */
#  define BARK_64K_LIMIT(what,nbytes,size)
#endif /* !HAS_64K_LIMIT || !PERL_CORE */

#ifndef MIN_SBRK
#  define MIN_SBRK 2048
#endif 

#ifndef FIRST_SBRK
#  define FIRST_SBRK (48*1024)
#endif 

/* Minimal sbrk in percents of what is already alloced. */
#ifndef MIN_SBRK_FRAC
#  define MIN_SBRK_FRAC 3
#endif 

#ifndef SBRK_ALLOW_FAILURES
#  define SBRK_ALLOW_FAILURES 3
#endif 

#ifndef SBRK_FAILURE_PRICE
#  define SBRK_FAILURE_PRICE 50
#endif 

#if defined(PERL_EMERGENCY_SBRK) && defined(PERL_CORE)

#  ifndef BIG_SIZE
#    define BIG_SIZE (1<<16)		/* 64K */
#  endif 

#ifdef MUTEX_INIT_CALLS_MALLOC
#  undef      MUTEX_LOCK
#  define MUTEX_LOCK(m)       STMT_START { if (*m) mutex_lock(*m); } STMT_END
#  undef      MUTEX_UNLOCK
#  define MUTEX_UNLOCK(m)     STMT_START { if (*m) mutex_unlock(*m); } STMT_END
#endif

static char *emergency_buffer;
static MEM_SIZE emergency_buffer_size;
static Malloc_t emergency_sbrk(MEM_SIZE size);

static Malloc_t
emergency_sbrk(MEM_SIZE size)
{
    MEM_SIZE rsize = (((size - 1)>>LOG_OF_MIN_ARENA) + 1)<<LOG_OF_MIN_ARENA;

    if (size >= BIG_SIZE) {
	/* Give the possibility to recover: */
	MUTEX_UNLOCK(&PL_malloc_mutex);
	croak("Out of memory during \"large\" request for %i bytes", size);
    }

    if (emergency_buffer_size >= rsize) {
	char *old = emergency_buffer;
	
	emergency_buffer_size -= rsize;
	emergency_buffer += rsize;
	return old;
    } else {		
	dTHR;
	/* First offense, give a possibility to recover by dieing. */
	/* No malloc involved here: */
	GV **gvp = (GV**)hv_fetch(PL_defstash, "^M", 2, 0);
	SV *sv;
	char *pv;
	int have = 0;
	STRLEN n_a;

	if (emergency_buffer_size) {
	    add_to_chain(emergency_buffer, emergency_buffer_size, 0);
	    emergency_buffer_size = 0;
	    emergency_buffer = Nullch;
	    have = 1;
	}
	if (!gvp) gvp = (GV**)hv_fetch(PL_defstash, "\015", 1, 0);
	if (!gvp || !(sv = GvSV(*gvp)) || !SvPOK(sv) 
	    || (SvLEN(sv) < (1<<LOG_OF_MIN_ARENA) - M_OVERHEAD)) {
	    if (have)
		goto do_croak;
	    return (char *)-1;		/* Now die die die... */
	}
	/* Got it, now detach SvPV: */
	pv = SvPV(sv, n_a);
	/* Check alignment: */
	if (((UV)(pv - sizeof(union overhead))) & ((1<<LOG_OF_MIN_ARENA) - 1)) {
	    PerlIO_puts(PerlIO_stderr(),"Bad alignment of $^M!\n");
	    return (char *)-1;		/* die die die */
	}

	emergency_buffer = pv - sizeof(union overhead);
	emergency_buffer_size = malloced_size(pv) + M_OVERHEAD;
	SvPOK_off(sv);
	SvPVX(sv) = Nullch;
	SvCUR(sv) = SvLEN(sv) = 0;
    }
  do_croak:
    MUTEX_UNLOCK(&PL_malloc_mutex);
    croak("Out of memory during request for %i bytes", size);
}

#else /* !(defined(PERL_EMERGENCY_SBRK) && defined(PERL_CORE)) */
#  define emergency_sbrk(size)	-1
#endif /* !(defined(PERL_EMERGENCY_SBRK) && defined(PERL_CORE)) */

/*
 * nextf[i] is the pointer to the next free block of size 2^i.  The
d77 1
a77 1
#define	NBUCKETS (32*BUCKETS_PER_POW2 + 1)
d79 1
a79 13

#ifdef USE_PERL_SBRK
#define sbrk(a) Perl_sbrk(a)
Malloc_t Perl_sbrk _((int size));
#else 
#ifdef DONT_DECLARE_STD
#ifdef I_UNISTD
#include <unistd.h>
#endif
#else
extern	Malloc_t sbrk(int);
#endif
#endif
d87 1
a87 2
static  u_int sbrk_slack;
static  u_int start_slack;
d90 2
a91 5
static	u_int goodsbrk;

#ifdef DEBUGGING
#undef ASSERT
#define	ASSERT(p,diag)   if (!(p)) botch(diag,STRINGIFY(p));  else
d93 2
a94 1
botch(char *diag, char *s)
d96 3
a98 2
	PerlIO_printf(PerlIO_stderr(), "assertion botched (%s?): %s\n", diag, s);
	PerlProc_abort();
d101 1
a101 1
#define	ASSERT(p, diag)
d105 2
a106 1
malloc(register size_t nbytes)
d109 1
a109 1
  	register int bucket;
d112 2
a113 1
#if defined(DEBUGGING) || defined(RCHECK)
d117 6
a122 1
	BARK_64K_LIMIT("Allocation",nbytes,nbytes);
d125 1
a125 1
		croak("%s", "panic: malloc");
d127 1
a128 1
	MUTEX_LOCK(&PL_malloc_mutex);
d135 6
a140 25
#ifdef PACK_MALLOC
#  ifdef SMALL_BUCKET_VIA_TABLE
	if (nbytes == 0)
	    bucket = MIN_BUCKET;
	else if (nbytes <= SIZE_TABLE_MAX) {
	    bucket = bucket_of[(nbytes - 1) >> BUCKET_TABLE_SHIFT];
	} else
#  else
	if (nbytes == 0)
	    nbytes = 1;
	if (nbytes <= MAX_POW2_ALGO) goto do_shifts;
	else
#  endif
#endif 
	{
	    POW2_OPTIMIZE_ADJUST(nbytes);
	    nbytes += M_OVERHEAD;
	    nbytes = (nbytes + 3) &~ 3; 
	  do_shifts:
	    shiftr = (nbytes - 1) >> START_SHIFT;
	    bucket = START_SHIFTS_BUCKET;
	    /* apart from this loop, this is O(1) */
	    while (shiftr >>= 1)
  		bucket += BUCKETS_PER_POW2;
	}
d147 4
a150 5
  	if ((p = nextf[bucket]) == NULL) {
		MUTEX_UNLOCK(&PL_malloc_mutex);
#ifdef PERL_CORE
		if (!PL_nomemok) {
		    PerlIO_puts(PerlIO_stderr(),"Out of memory!\n");
d158 4
a161 4
	DEBUG_m(PerlIO_printf(Perl_debug_log,
			      "0x%lx: (%05lu) malloc %ld bytes\n",
			      (unsigned long)(p+1), (unsigned long)(PL_an++),
			      (long)size));
d164 3
a166 3
#if defined(RCHECK)
	if (((UV)p) & (MEM_ALIGNBYTES - 1))
	    PerlIO_printf(PerlIO_stderr(), "Corrupt malloc ptr 0x%lx at 0x%lx\n",
d170 4
a173 6
#ifdef IGNORE_SMALL_BAD_FREE
	if (bucket >= FIRST_BUCKET_WITH_CHECK)
#endif 
	    OV_MAGIC(p, bucket) = MAGIC;
#ifndef PACK_MALLOC
	OV_INDEX(p) = bucket;
d180 2
d183 1
a183 13
	if (bucket <= MAX_SHORT_BUCKET) {
	    int i;
	    
	    nbytes = size + M_OVERHEAD; 
	    p->ov_size = nbytes - 1;
	    if ((i = nbytes & 3)) {
		i = 4 - i;
		while (i--)
		    *((char *)((caddr_t)p + nbytes - RSLOP + i)) = RMAGIC_C;
	    }
	    nbytes = (nbytes + 3) &~ 3; 
	    *((u_int *)((caddr_t)p + nbytes - RSLOP)) = RMAGIC;
	}
d185 1
a185 58
	MUTEX_UNLOCK(&PL_malloc_mutex);
  	return ((Malloc_t)(p + CHUNK_SHIFT));
}

static char *last_sbrk_top;
static char *last_op;			/* This arena can be easily extended. */
static int sbrked_remains;
static int sbrk_good = SBRK_ALLOW_FAILURES * SBRK_FAILURE_PRICE;

#ifdef DEBUGGING_MSTATS
static int sbrks;
#endif 

struct chunk_chain_s {
    struct chunk_chain_s *next;
    MEM_SIZE size;
};
static struct chunk_chain_s *chunk_chain;
static int n_chunks;
static char max_bucket;

/* Cutoff a piece of one of the chunks in the chain.  Prefer smaller chunk. */
static void *
get_from_chain(MEM_SIZE size)
{
    struct chunk_chain_s *elt = chunk_chain, **oldp = &chunk_chain;
    struct chunk_chain_s **oldgoodp = NULL;
    long min_remain = LONG_MAX;

    while (elt) {
	if (elt->size >= size) {
	    long remains = elt->size - size;
	    if (remains >= 0 && remains < min_remain) {
		oldgoodp = oldp;
		min_remain = remains;
	    }
	    if (remains == 0) {
		break;
	    }
	}
	oldp = &( elt->next );
	elt = elt->next;
    }
    if (!oldgoodp) return NULL;
    if (min_remain) {
	void *ret = *oldgoodp;
	struct chunk_chain_s *next = (*oldgoodp)->next;
	
	*oldgoodp = (struct chunk_chain_s *)((char*)ret + size);
	(*oldgoodp)->size = min_remain;
	(*oldgoodp)->next = next;
	return ret;
    } else {
	void *ret = *oldgoodp;
	*oldgoodp = (*oldgoodp)->next;
	n_chunks--;
	return ret;
    }
d188 3
d192 2
a193 1
add_to_chain(void *p, MEM_SIZE size, MEM_SIZE chip)
d195 4
a198 9
    struct chunk_chain_s *next = chunk_chain;
    char *cp = (char*)p;
    
    cp += chip;
    chunk_chain = (struct chunk_chain_s *)cp;
    chunk_chain->size = size - chip;
    chunk_chain->next = next;
    n_chunks++;
}
d200 16
a215 29
static void *
get_from_bigger_buckets(int bucket, MEM_SIZE size)
{
    int price = 1;
    static int bucketprice[NBUCKETS];
    while (bucket <= max_bucket) {
	/* We postpone stealing from bigger buckets until we want it
	   often enough. */
	if (nextf[bucket] && bucketprice[bucket]++ >= price) {
	    /* Steal it! */
	    void *ret = (void*)(nextf[bucket] - 1 + CHUNK_SHIFT);
	    bucketprice[bucket] = 0;
	    if (((char*)nextf[bucket]) - M_OVERHEAD == last_op) {
		last_op = NULL;		/* Disable optimization */
	    }
	    nextf[bucket] = nextf[bucket]->ov_next;
#ifdef DEBUGGING_MSTATS
	    nmalloc[bucket]--;
	    start_slack -= M_OVERHEAD;
#endif 
	    add_to_chain(ret, (BUCKET_SIZE(bucket) +
			       POW2_OPTIMIZE_SURPLUS(bucket)), 
			 size);
	    return ret;
	}
	bucket++;
    }
    return NULL;
}
d217 7
a223 85
static union overhead *
getpages(int needed, int *nblksp, int bucket)
{
    /* Need to do (possibly expensive) system call. Try to
       optimize it for rare calling. */
    MEM_SIZE require = needed - sbrked_remains;
    char *cp;
    union overhead *ovp;
    int slack = 0;

    if (sbrk_good > 0) {
	if (!last_sbrk_top && require < FIRST_SBRK) 
	    require = FIRST_SBRK;
	else if (require < MIN_SBRK) require = MIN_SBRK;

	if (require < goodsbrk * MIN_SBRK_FRAC / 100)
	    require = goodsbrk * MIN_SBRK_FRAC / 100;
	require = ((require - 1 + MIN_SBRK) / MIN_SBRK) * MIN_SBRK;
    } else {
	require = needed;
	last_sbrk_top = 0;
	sbrked_remains = 0;
    }

    DEBUG_m(PerlIO_printf(Perl_debug_log, 
			  "sbrk(%ld) for %ld-byte-long arena\n",
			  (long)require, (long) needed));
    cp = (char *)sbrk(require);
#ifdef DEBUGGING_MSTATS
    sbrks++;
#endif 
    if (cp == last_sbrk_top) {
	/* Common case, anything is fine. */
	sbrk_good++;
	ovp = (union overhead *) (cp - sbrked_remains);
	sbrked_remains = require - (needed - sbrked_remains);
    } else if (cp == (char *)-1) { /* no more room! */
	ovp = (union overhead *)emergency_sbrk(needed);
	if (ovp == (union overhead *)-1)
	    return 0;
	return ovp;
    } else {			/* Non-continuous or first sbrk(). */
	long add = sbrked_remains;
	char *newcp;

	if (sbrked_remains) {	/* Put rest into chain, we
				   cannot use it right now. */
	    add_to_chain((void*)(last_sbrk_top - sbrked_remains),
			 sbrked_remains, 0);
	}

	/* Second, check alignment. */
	slack = 0;

#if !defined(atarist) && !defined(__MINT__) /* on the atari we dont have to worry about this */
#  ifndef I286 	/* The sbrk(0) call on the I286 always returns the next segment */

	/* CHUNK_SHIFT is 1 for PACK_MALLOC, 0 otherwise. */
	if ((UV)cp & (0x7FF >> CHUNK_SHIFT)) { /* Not aligned. */
	    slack = (0x800 >> CHUNK_SHIFT)
		- ((UV)cp & (0x7FF >> CHUNK_SHIFT));
	    add += slack;
	}
#  endif
#endif /* !atarist && !MINT */
		
	if (add) {
	    DEBUG_m(PerlIO_printf(Perl_debug_log, 
				  "sbrk(%ld) to fix non-continuous/off-page sbrk:\n\t%ld for alignement,\t%ld were assumed to come from the tail of the previous sbrk\n",
				  (long)add, (long) slack,
				  (long) sbrked_remains));
	    newcp = (char *)sbrk(add);
#if defined(DEBUGGING_MSTATS)
	    sbrks++;
	    sbrk_slack += add;
#endif
	    if (newcp != cp + require) {
		/* Too bad: even rounding sbrk() is not continuous.*/
		DEBUG_m(PerlIO_printf(Perl_debug_log, 
				      "failed to fix bad sbrk()\n"));
#ifdef PACK_MALLOC
		if (slack) {
		    MUTEX_UNLOCK(&PL_malloc_mutex);
		    croak("%s", "panic: Off-page sbrk");
		}
d225 7
a231 29
		if (sbrked_remains) {
		    /* Try again. */
#if defined(DEBUGGING_MSTATS)
		    sbrk_slack += require;
#endif
		    require = needed;
		    DEBUG_m(PerlIO_printf(Perl_debug_log, 
					  "straight sbrk(%ld)\n",
					  (long)require));
		    cp = (char *)sbrk(require);
#ifdef DEBUGGING_MSTATS
		    sbrks++;
#endif 
		    if (cp == (char *)-1)
			return 0;
		}
		sbrk_good = -1;	/* Disable optimization!
				   Continue with not-aligned... */
	    } else {
		cp += slack;
		require += sbrked_remains;
	    }
	}

	if (last_sbrk_top) {
	    sbrk_good -= SBRK_FAILURE_PRICE;
	}

	ovp = (union overhead *) cp;
d236 7
a242 46

#ifndef I286	/* Again, this should always be ok on an 80286 */
	if ((UV)ovp & 7) {
	    ovp = (union overhead *)(((UV)ovp + 8) & ~7);
	    DEBUG_m(PerlIO_printf(Perl_debug_log, 
				  "fixing sbrk(): %d bytes off machine alignement\n",
				  (int)((UV)ovp & 7)));
	    (*nblksp)--;
# if defined(DEBUGGING_MSTATS)
	    /* This is only approx. if TWO_POT_OPTIMIZE: */
	    sbrk_slack += (1 << bucket);
# endif
	}
#endif
	sbrked_remains = require - needed;
    }
    last_sbrk_top = cp + require;
    last_op = (char*) cp;
#ifdef DEBUGGING_MSTATS
    goodsbrk += require;
#endif	
    return ovp;
}

static int
getpages_adjacent(int require)
{	    
    if (require <= sbrked_remains) {
	sbrked_remains -= require;
    } else {
	char *cp;

	require -= sbrked_remains;
	/* We do not try to optimize sbrks here, we go for place. */
	cp = (char*) sbrk(require);
#ifdef DEBUGGING_MSTATS
	sbrks++;
	goodsbrk += require;
#endif 
	if (cp == last_sbrk_top) {
	    sbrked_remains = 0;
	    last_sbrk_top = cp + require;
	} else {
	    if (cp == (char*)-1) {	/* Out of memory */
#ifdef DEBUGGING_MSTATS
		goodsbrk -= require;
a243 76
		return 0;
	    }
	    /* Report the failure: */
	    if (sbrked_remains)
		add_to_chain((void*)(last_sbrk_top - sbrked_remains),
			     sbrked_remains, 0);
	    add_to_chain((void*)cp, require, 0);
	    sbrk_good -= SBRK_FAILURE_PRICE;
	    sbrked_remains = 0;
	    last_sbrk_top = 0;
	    last_op = 0;
	    return 0;
	}
    }
	    
    return 1;
}

/*
 * Allocate more memory to the indicated bucket.
 */
static void
morecore(register int bucket)
{
  	register union overhead *ovp;
  	register int rnu;       /* 2^rnu bytes will be requested */
  	int nblks;		/* become nblks blocks of the desired size */
	register MEM_SIZE siz, needed;

  	if (nextf[bucket])
  		return;
	if (bucket == sizeof(MEM_SIZE)*8*BUCKETS_PER_POW2) {
	    MUTEX_UNLOCK(&PL_malloc_mutex);
	    croak("%s", "Out of memory during ridiculously large request");
	}
	if (bucket > max_bucket)
	    max_bucket = bucket;

  	rnu = ( (bucket <= (LOG_OF_MIN_ARENA << BUCKET_POW2_SHIFT)) 
		? LOG_OF_MIN_ARENA 
		: (bucket >> BUCKET_POW2_SHIFT) );
	/* This may be overwritten later: */
  	nblks = 1 << (rnu - (bucket >> BUCKET_POW2_SHIFT)); /* how many blocks to get */
	needed = ((MEM_SIZE)1 << rnu) + POW2_OPTIMIZE_SURPLUS(bucket);
	if (nextf[rnu << BUCKET_POW2_SHIFT]) { /* 2048b bucket. */
	    ovp = nextf[rnu << BUCKET_POW2_SHIFT] - 1 + CHUNK_SHIFT;
	    nextf[rnu << BUCKET_POW2_SHIFT]
		= nextf[rnu << BUCKET_POW2_SHIFT]->ov_next;
#ifdef DEBUGGING_MSTATS
	    nmalloc[rnu << BUCKET_POW2_SHIFT]--;
	    start_slack -= M_OVERHEAD;
#endif 
	    DEBUG_m(PerlIO_printf(Perl_debug_log, 
				  "stealing %ld bytes from %ld arena\n",
				  (long) needed, (long) rnu << BUCKET_POW2_SHIFT));
	} else if (chunk_chain 
		   && (ovp = (union overhead*) get_from_chain(needed))) {
	    DEBUG_m(PerlIO_printf(Perl_debug_log, 
				  "stealing %ld bytes from chain\n",
				  (long) needed));
	} else if ( (ovp = (union overhead*)
		     get_from_bigger_buckets((rnu << BUCKET_POW2_SHIFT) + 1,
					     needed)) ) {
	    DEBUG_m(PerlIO_printf(Perl_debug_log, 
				  "stealing %ld bytes from bigger buckets\n",
				  (long) needed));
	} else if (needed <= sbrked_remains) {
	    ovp = (union overhead *)(last_sbrk_top - sbrked_remains);
	    sbrked_remains -= needed;
	    last_op = (char*)ovp;
	} else 
	    ovp = getpages(needed, &nblks, bucket);

	if (!ovp)
	    return;

d248 2
a249 21
  	siz = BUCKET_SIZE(bucket);
#ifdef PACK_MALLOC
	*(u_char*)ovp = bucket;	/* Fill index. */
	if (bucket <= MAX_PACKED) {
	    ovp = (union overhead *) ((char*)ovp + BLK_SHIFT(bucket));
	    nblks = N_BLKS(bucket);
#  ifdef DEBUGGING_MSTATS
	    start_slack += BLK_SHIFT(bucket);
#  endif
	} else if (bucket < LOG_OF_MIN_ARENA * BUCKETS_PER_POW2) {
	    ovp = (union overhead *) ((char*)ovp + BLK_SHIFT(bucket));
	    siz -= sizeof(union overhead);
	} else ovp++;		/* One chunk per block. */
#endif /* PACK_MALLOC */
  	nextf[bucket] = ovp;
#ifdef DEBUGGING_MSTATS
	nmalloc[bucket] += nblks;
	if (bucket > MAX_PACKED) {
	    start_slack += M_OVERHEAD * nblks;
	}
#endif 
d251 2
a252 2
		ovp->ov_next = (union overhead *)((caddr_t)ovp + siz);
		ovp = (union overhead *)((caddr_t)ovp + siz);
a253 11
	/* Not all sbrks return zeroed memory.*/
	ovp->ov_next = (union overhead *)NULL;
#ifdef PACK_MALLOC
	if (bucket == 7*BUCKETS_PER_POW2) { /* Special case, explanation is above. */
	    union overhead *n_op = nextf[7*BUCKETS_PER_POW2]->ov_next;
	    nextf[7*BUCKETS_PER_POW2] = 
		(union overhead *)((caddr_t)nextf[7*BUCKETS_PER_POW2] 
				   - sizeof(union overhead));
	    nextf[7*BUCKETS_PER_POW2]->ov_next = n_op;
	}
#endif /* !PACK_MALLOC */
d257 2
a258 1
free(void *mp)
d261 1
a261 1
	register union overhead *ovp;
d263 10
a272 18
#ifdef PACK_MALLOC
	u_char bucket;
#endif 

	DEBUG_m(PerlIO_printf(Perl_debug_log, 
			      "0x%lx: (%05lu) free\n",
			      (unsigned long)cp, (unsigned long)(PL_an++)));

	if (cp == NULL)
		return;
	ovp = (union overhead *)((caddr_t)cp 
				- sizeof (union overhead) * CHUNK_SHIFT);
#ifdef PACK_MALLOC
	bucket = OV_INDEX(ovp);
#endif 
#ifdef IGNORE_SMALL_BAD_FREE
	if ((bucket >= FIRST_BUCKET_WITH_CHECK) 
	    && (OV_MAGIC(ovp, bucket) != MAGIC))
d274 1
a274 10
	if (OV_MAGIC(ovp, bucket) != MAGIC)
#endif 
	    {
		static int bad_free_warn = -1;
		if (bad_free_warn == -1) {
		    char *pbf = PerlEnv_getenv("PERL_BADFREE");
		    bad_free_warn = (pbf) ? atoi(pbf) : 1;
		}
		if (!bad_free_warn)
		    return;
d277 1
a277 1
		    ovp->ov_rmagic == RMAGIC - 1 ? "Duplicate" : "Bad");
d279 1
a279 1
		warn("%s", "Bad free() ignored");
d282 2
a283 2
	    }
	MUTEX_LOCK(&PL_malloc_mutex);
d285 11
a295 16
  	ASSERT(ovp->ov_rmagic == RMAGIC, "chunk's head overwrite");
	if (OV_INDEX(ovp) <= MAX_SHORT_BUCKET) {
	    int i;
	    MEM_SIZE nbytes = ovp->ov_size + 1;

	    if ((i = nbytes & 3)) {
		i = 4 - i;
		while (i--) {
		    ASSERT(*((char *)((caddr_t)ovp + nbytes - RSLOP + i))
			   == RMAGIC_C, "chunk's tail overwrite");
		}
	    }
	    nbytes = (nbytes + 3) &~ 3; 
	    ASSERT(*(u_int *)((caddr_t)ovp + nbytes - RSLOP) == RMAGIC, "chunk's tail overwrite");	    
	}
	ovp->ov_rmagic = RMAGIC - 1;
a296 5
  	ASSERT(OV_INDEX(ovp) < NBUCKETS, "chunk's head overwrite");
  	size = OV_INDEX(ovp);
	ovp->ov_next = nextf[size];
  	nextf[size] = ovp;
	MUTEX_UNLOCK(&PL_malloc_mutex);
d310 1
a310 1
int reall_srchlen = 4;  /* 4 should be plenty, -1 =>'s whole list */
d313 3
a315 1
realloc(void *mp, size_t nbytes)
d318 1
a318 1
	union overhead *ovp;
d320 2
a321 3
	int prev_bucket;
	register int bucket;
	int was_alloced = 0, incr;
d324 2
a325 1
#if defined(DEBUGGING) || !defined(PERL_CORE)
a326 3

	if ((long)nbytes < 0)
		croak("%s", "panic: realloc");
d329 6
a334 1
	BARK_64K_LIMIT("Reallocation",nbytes,size);
d337 5
d343 4
a346 12
	MUTEX_LOCK(&PL_malloc_mutex);
	ovp = (union overhead *)((caddr_t)cp 
				- sizeof (union overhead) * CHUNK_SHIFT);
	bucket = OV_INDEX(ovp);
#ifdef IGNORE_SMALL_BAD_FREE
	if ((bucket < FIRST_BUCKET_WITH_CHECK) 
	    || (OV_MAGIC(ovp, bucket) == MAGIC))
#else
	if (OV_MAGIC(ovp, bucket) == MAGIC) 
#endif 
	{
		was_alloced = 1;
d359 8
a366 39
		if ((bucket = findbucket(ovp, 1)) < 0 &&
		    (bucket = findbucket(ovp, reall_srchlen)) < 0)
			bucket = 0;
	}
	onb = BUCKET_SIZE_REAL(bucket);
	/* 
	 *  avoid the copy if same size block.
	 *  We are not agressive with boundary cases. Note that it might
	 *  (for a small number of cases) give false negative if
	 *  both new size and old one are in the bucket for
	 *  FIRST_BIG_POW2, but the new one is near the lower end.
	 *
	 *  We do not try to go to 1.5 times smaller bucket so far.
	 */
	if (nbytes > onb) incr = 1;
	else {
#ifdef DO_NOT_TRY_HARDER_WHEN_SHRINKING
	    if ( /* This is a little bit pessimal if PACK_MALLOC: */
		nbytes > ( (onb >> 1) - M_OVERHEAD )
#  ifdef TWO_POT_OPTIMIZE
		|| (bucket == FIRST_BIG_POW2 && nbytes >= LAST_SMALL_BOUND )
#  endif	
		)
#else  /* !DO_NOT_TRY_HARDER_WHEN_SHRINKING */
		prev_bucket = ( (bucket > MAX_PACKED + 1) 
				? bucket - BUCKETS_PER_POW2
				: bucket - 1);
	     if (nbytes > BUCKET_SIZE_REAL(prev_bucket))
#endif /* !DO_NOT_TRY_HARDER_WHEN_SHRINKING */
		 incr = 0;
	     else incr = -1;
	}
	if (!was_alloced
#ifdef STRESS_REALLOC
	    || 1 /* always do it the hard way */
#endif
	    ) goto hard_way;
	else if (incr == 0) {
	  inplace_label:
d372 1
a372 11
		if (OV_INDEX(ovp) <= MAX_SHORT_BUCKET) {
		       int i, nb = ovp->ov_size + 1;

		       if ((i = nb & 3)) {
			   i = 4 - i;
			   while (i--) {
			       ASSERT(*((char *)((caddr_t)ovp + nb - RSLOP + i)) == RMAGIC_C, "chunk's tail overwrite");
			   }
		       }
		       nb = (nb + 3) &~ 3; 
		       ASSERT(*(u_int *)((caddr_t)ovp + nb - RSLOP) == RMAGIC, "chunk's tail overwrite");
d379 1
a379 8
			nbytes += M_OVERHEAD;
			ovp->ov_size = nbytes - 1;
			if ((i = nbytes & 3)) {
			    i = 4 - i;
			    while (i--)
				*((char *)((caddr_t)ovp + nbytes - RSLOP + i))
				    = RMAGIC_C;
			}
d381 2
a382 1
			*((u_int *)((caddr_t)ovp + nbytes - RSLOP)) = RMAGIC;
a385 43
		MUTEX_UNLOCK(&PL_malloc_mutex);
		DEBUG_m(PerlIO_printf(Perl_debug_log, 
			      "0x%lx: (%05lu) realloc %ld bytes inplace\n",
			      (unsigned long)res,(unsigned long)(PL_an++),
			      (long)size));
	} else if (incr == 1 && (cp - M_OVERHEAD == last_op) 
		   && (onb > (1 << LOG_OF_MIN_ARENA))) {
	    MEM_SIZE require, newarena = nbytes, pow;
	    int shiftr;

	    POW2_OPTIMIZE_ADJUST(newarena);
	    newarena = newarena + M_OVERHEAD;
	    /* newarena = (newarena + 3) &~ 3; */
	    shiftr = (newarena - 1) >> LOG_OF_MIN_ARENA;
	    pow = LOG_OF_MIN_ARENA + 1;
	    /* apart from this loop, this is O(1) */
	    while (shiftr >>= 1)
  		pow++;
	    newarena = (1 << pow) + POW2_OPTIMIZE_SURPLUS(pow * BUCKETS_PER_POW2);
	    require = newarena - onb - M_OVERHEAD;
	    
	    if (getpages_adjacent(require)) {
#ifdef DEBUGGING_MSTATS
		nmalloc[bucket]--;
		nmalloc[pow * BUCKETS_PER_POW2]++;
#endif 	    
		*(cp - M_OVERHEAD) = pow * BUCKETS_PER_POW2; /* Fill index. */
		goto inplace_label;
	    } else
		goto hard_way;
	} else {
	  hard_way:
	    MUTEX_UNLOCK(&PL_malloc_mutex);
	    DEBUG_m(PerlIO_printf(Perl_debug_log, 
			      "0x%lx: (%05lu) realloc %ld bytes the hard way\n",
			      (unsigned long)cp,(unsigned long)(PL_an++),
			      (long)size));
	    if ((res = (char*)malloc(nbytes)) == NULL)
		return (NULL);
	    if (cp != res)			/* common optimization */
		Copy(cp, res, (MEM_SIZE)(nbytes<onb?nbytes:onb), char);
	    if (was_alloced)
		free(cp);
d387 18
d414 3
a416 1
findbucket(union overhead *freep, int srchlen)
a431 30
Malloc_t
calloc(register size_t elements, register size_t size)
{
    long sz = elements * size;
    Malloc_t p = malloc(sz);

    if (p) {
	memset((void*)p, 0, sz);
    }
    return p;
}

MEM_SIZE
malloced_size(void *p)
{
    union overhead *ovp = (union overhead *)
	((caddr_t)p - sizeof (union overhead) * CHUNK_SHIFT);
    int bucket = OV_INDEX(ovp);
#ifdef RCHECK
    /* The caller wants to have a complete control over the chunk,
       disable the memory checking inside the chunk.  */
    if (bucket <= MAX_SHORT_BUCKET) {
	MEM_SIZE size = BUCKET_SIZE_REAL(bucket);
	ovp->ov_size = size + M_OVERHEAD - 1;
	*((u_int *)((caddr_t)ovp + size + M_OVERHEAD - RSLOP)) = RMAGIC;
    }
#endif
    return BUCKET_SIZE_REAL(bucket);
}

a432 6

#  ifdef BUCKETS_ROOT2
#    define MIN_EVEN_REPORT 6
#  else
#    define MIN_EVEN_REPORT MIN_BUCKET
#  endif 
d441 2
a442 1
dump_mstats(char *s)
d446 1
a446 1
  	int topbucket=0, topbucket_ev=0, topbucket_odd=0, totfree=0, total=0;
a447 2
	int total_chain = 0;
	struct chunk_chain_s* nextchain = chunk_chain;
d449 1
a449 1
  	for (i = MIN_BUCKET ; i < NBUCKETS; i++) {
d453 4
a456 6
  		totfree += nfree[i] * BUCKET_SIZE_REAL(i);
  		total += nmalloc[i] * BUCKET_SIZE_REAL(i);
		if (nmalloc[i]) {
		    i % 2 ? (topbucket_odd = i) : (topbucket_ev = i);
		    topbucket = i;
		}
d459 5
a463 22
	    PerlIO_printf(PerlIO_stderr(),
			  "Memory allocation statistics %s (buckets %ld(%ld)..%ld(%ld)\n",
			  s, 
			  (long)BUCKET_SIZE_REAL(MIN_BUCKET), 
			  (long)BUCKET_SIZE(MIN_BUCKET),
			  (long)BUCKET_SIZE_REAL(topbucket), (long)BUCKET_SIZE(topbucket));
  	PerlIO_printf(PerlIO_stderr(), "%8d free:", totfree);
  	for (i = MIN_EVEN_REPORT; i <= topbucket; i += BUCKETS_PER_POW2) {
  		PerlIO_printf(PerlIO_stderr(), 
			      ((i < 8*BUCKETS_PER_POW2 || i == 10*BUCKETS_PER_POW2)
			       ? " %5d" 
			       : ((i < 12*BUCKETS_PER_POW2) ? " %3d" : " %d")),
			      nfree[i]);
  	}
#ifdef BUCKETS_ROOT2
	PerlIO_printf(PerlIO_stderr(), "\n\t   ");
  	for (i = MIN_BUCKET + 1; i <= topbucket_odd; i += BUCKETS_PER_POW2) {
  		PerlIO_printf(PerlIO_stderr(), 
			      ((i < 8*BUCKETS_PER_POW2 || i == 10*BUCKETS_PER_POW2)
			       ? " %5d" 
			       : ((i < 12*BUCKETS_PER_POW2) ? " %3d" : " %d")),
			      nfree[i]);
d465 3
a467 8
#endif 
  	PerlIO_printf(PerlIO_stderr(), "\n%8d used:", total - totfree);
  	for (i = MIN_EVEN_REPORT; i <= topbucket; i += BUCKETS_PER_POW2) {
  		PerlIO_printf(PerlIO_stderr(), 
			      ((i < 8*BUCKETS_PER_POW2 || i == 10*BUCKETS_PER_POW2)
			       ? " %5d" 
			       : ((i < 12*BUCKETS_PER_POW2) ? " %3d" : " %d")), 
			      nmalloc[i] - nfree[i]);
d469 1
a469 17
#ifdef BUCKETS_ROOT2
	PerlIO_printf(PerlIO_stderr(), "\n\t   ");
  	for (i = MIN_BUCKET + 1; i <= topbucket_odd; i += BUCKETS_PER_POW2) {
  		PerlIO_printf(PerlIO_stderr(), 
			      ((i < 8*BUCKETS_PER_POW2 || i == 10*BUCKETS_PER_POW2)
			       ? " %5d" 
			       : ((i < 12*BUCKETS_PER_POW2) ? " %3d" : " %d")),
			      nmalloc[i] - nfree[i]);
  	}
#endif 
	while (nextchain) {
	    total_chain += nextchain->size;
	    nextchain = nextchain->next;
	}
	PerlIO_printf(PerlIO_stderr(), "\nTotal sbrk(): %d/%d:%d. Odd ends: pad+heads+chain+tail: %d+%d+%d+%d.\n",
		      goodsbrk + sbrk_slack, sbrks, sbrk_good, sbrk_slack,
		      start_slack, total_chain, sbrked_remains);
d473 2
a474 1
dump_mstats(char *s)
a478 88


#ifdef USE_PERL_SBRK

#   if defined(__MACHTEN_PPC__) || defined(__NeXT__)
#      define PERL_SBRK_VIA_MALLOC
/*
 * MachTen's malloc() returns a buffer aligned on a two-byte boundary.
 * While this is adequate, it may slow down access to longer data
 * types by forcing multiple memory accesses.  It also causes
 * complaints when RCHECK is in force.  So we allocate six bytes
 * more than we need to, and return an address rounded up to an
 * eight-byte boundary.
 *
 * 980701 Dominic Dunlop <domo@@computer.org>
 */
#      define SYSTEM_ALLOC(a) ((void *)(((unsigned)malloc((a)+6)+6)&~7))
#   endif

#   ifdef PERL_SBRK_VIA_MALLOC
#      if defined(HIDEMYMALLOC) || defined(EMBEDMYMALLOC)
#         undef malloc		/* Expose names that  */
#         undef calloc		/* HIDEMYMALLOC hides */
#         undef realloc
#         undef free
#      else
#         include "Error: -DPERL_SBRK_VIA_MALLOC needs -D(HIDE|EMBED)MYMALLOC"
#      endif

/* it may seem schizophrenic to use perl's malloc and let it call system */
/* malloc, the reason for that is only the 3.2 version of the OS that had */
/* frequent core dumps within nxzonefreenolock. This sbrk routine put an */
/* end to the cores */

#      ifndef SYSTEM_ALLOC
#         define SYSTEM_ALLOC(a) malloc(a)
#      endif

#   endif  /* PERL_SBRK_VIA_MALLOC */

static IV Perl_sbrk_oldchunk;
static long Perl_sbrk_oldsize;

#   define PERLSBRK_32_K (1<<15)
#   define PERLSBRK_64_K (1<<16)

Malloc_t
Perl_sbrk(int size)
{
    IV got;
    int small, reqsize;

    if (!size) return 0;
#ifdef PERL_CORE
    reqsize = size; /* just for the DEBUG_m statement */
#endif
#ifdef PACK_MALLOC
    size = (size + 0x7ff) & ~0x7ff;
#endif
    if (size <= Perl_sbrk_oldsize) {
	got = Perl_sbrk_oldchunk;
	Perl_sbrk_oldchunk += size;
	Perl_sbrk_oldsize -= size;
    } else {
      if (size >= PERLSBRK_32_K) {
	small = 0;
      } else {
	size = PERLSBRK_64_K;
	small = 1;
      }
      got = (IV)SYSTEM_ALLOC(size);
#ifdef PACK_MALLOC
      got = (got + 0x7ff) & ~0x7ff;
#endif
      if (small) {
	/* Chunk is small, register the rest for future allocs. */
	Perl_sbrk_oldchunk = got + reqsize;
	Perl_sbrk_oldsize = size - reqsize;
      }
    }

    DEBUG_m(PerlIO_printf(Perl_debug_log, "sbrk malloc size %ld (reqsize %ld), left size %ld, give addr 0x%lx\n",
		    size, reqsize, Perl_sbrk_oldsize, got));

    return (void *)got;
}

#endif /* ! defined USE_PERL_SBRK */
@


1.1.1.3
log
@virgin perl 5.6.0
@
text
@d6 1
a6 2
  Here are some notes on configuring Perl's malloc.  (For non-perl
  usage see below.)
a64 3
    # Minimal alignment (in bytes, should be a power of 2) of SYSTEM_ALLOC
    SYSTEM_ALLOC_ALIGNMENT	MEM_ALIGNBYTES

a113 43
/*
   If used outside of Perl environment, it may be useful to redefine
   the following macros (listed below with defaults):

     # Type of address returned by allocation functions
     Malloc_t				void *

     # Type of size argument for allocation functions
     MEM_SIZE				unsigned long

     # size of void*
     PTRSIZE				4

     # Maximal value in LONG
     LONG_MAX				0x7FFFFFFF

     # Unsigned integer type big enough to keep a pointer
     UV					unsigned long

     # Type of pointer with 1-byte granularity
     caddr_t				char *

     # Type returned by free()
     Free_t				void

     # Very fatal condition reporting function (cannot call any )
     fatalcroak(arg)			write(2,arg,strlen(arg)) + exit(2)
  
     # Fatal error reporting function
     croak(format, arg)			warn(idem) + exit(1)
  
     # Error reporting function
     warn(format, arg)			fprintf(stderr, idem)

     # Locking/unlocking for MT operation
     MALLOC_LOCK			MUTEX_LOCK(&PL_malloc_mutex)
     MALLOC_UNLOCK			MUTEX_UNLOCK(&PL_malloc_mutex)

     # Locking/unlocking mutex for MT operation
     MUTEX_LOCK(l)			void
     MUTEX_UNLOCK(l)			void
 */

d170 1
a170 12
 * but bombs when it runs out.
 * 
 * Modifications Copyright Ilya Zakharevich 1996-99.
 * 
 * Still very quick, but much more thrifty.  (Std config is 10% slower
 * than it was, and takes 67% of old heap size for typical usage.)
 *
 * Allocations of small blocks are now table-driven to many different
 * buckets.  Sizes of really big buckets are increased to accomodata
 * common size=power-of-2 blocks.  Running-out-of-memory is made into
 * an exception.  Deeply configurable and thread-safe.
 * 
a174 1
#  define PERL_IN_MALLOC_C
a175 4
#  if defined(PERL_IMPLICIT_CONTEXT)
#    define croak	Perl_croak_nocontext
#    define warn	Perl_warn_nocontext
#  endif
a187 3
#    ifndef PTRSIZE
#      define PTRSIZE 4
#    endif
d209 1
a209 1
#    define croak(mess, arg) (warn((mess), (arg)), exit(1))
d212 1
a212 1
#    define warn(mess, arg) fprintf(stderr, (mess), (arg))
a220 24
#  ifndef pTHX
#     define pTHX		void
#     define pTHX_
#     define dTHX		extern int Perl___notused
#     define WITH_THX(s)	s
#  endif
#  ifndef PERL_GET_INTERP
#     define PERL_GET_INTERP	PL_curinterp
#  endif
#  ifndef Perl_malloc
#     define Perl_malloc malloc
#  endif
#  ifndef Perl_mfree
#     define Perl_mfree free
#  endif
#  ifndef Perl_realloc
#     define Perl_realloc realloc
#  endif
#  ifndef Perl_calloc
#     define Perl_calloc calloc
#  endif
#  ifndef Perl_strdup
#     define Perl_strdup strdup
#  endif
a230 12
#ifndef MALLOC_LOCK
#  define MALLOC_LOCK		MUTEX_LOCK(&PL_malloc_mutex)
#endif 

#ifndef MALLOC_UNLOCK
#  define MALLOC_UNLOCK		MUTEX_UNLOCK(&PL_malloc_mutex)
#endif 

#  ifndef fatalcroak				/* make depend */
#    define fatalcroak(mess)	(write(2, (mess), strlen(mess)), exit(2))
#  endif 

d233 1
a233 4
#  define DEBUG_m(a)  \
    STMT_START {							\
	if (PERL_GET_INTERP) { dTHX; if (PL_debug & 128) { a; } }	\
    } STMT_END
a235 70
#ifdef PERL_IMPLICIT_CONTEXT
#  define PERL_IS_ALIVE		aTHX
#else
#  define PERL_IS_ALIVE		TRUE
#endif
    

/*
 * Layout of memory:
 * ~~~~~~~~~~~~~~~~
 * The memory is broken into "blocks" which occupy multiples of 2K (and
 * generally speaking, have size "close" to a power of 2).  The addresses
 * of such *unused* blocks are kept in nextf[i] with big enough i.  (nextf
 * is an array of linked lists.)  (Addresses of used blocks are not known.)
 * 
 * Moreover, since the algorithm may try to "bite" smaller blocks out
 * of unused bigger ones, there are also regions of "irregular" size,
 * managed separately, by a linked list chunk_chain.
 * 
 * The third type of storage is the sbrk()ed-but-not-yet-used space, its
 * end and size are kept in last_sbrk_top and sbrked_remains.
 * 
 * Growing blocks "in place":
 * ~~~~~~~~~~~~~~~~~~~~~~~~~
 * The address of the block with the greatest address is kept in last_op
 * (if not known, last_op is 0).  If it is known that the memory above
 * last_op is not continuous, or contains a chunk from chunk_chain,
 * last_op is set to 0.
 * 
 * The chunk with address last_op may be grown by expanding into
 * sbrk()ed-but-not-yet-used space, or trying to sbrk() more continuous
 * memory.
 * 
 * Management of last_op:
 * ~~~~~~~~~~~~~~~~~~~~~
 * 
 * free() never changes the boundaries of blocks, so is not relevant.
 * 
 * The only way realloc() may change the boundaries of blocks is if it
 * grows a block "in place".  However, in the case of success such a
 * chunk is automatically last_op, and it remains last_op.  In the case
 * of failure getpages_adjacent() clears last_op.
 * 
 * malloc() may change blocks by calling morecore() only.
 * 
 * morecore() may create new blocks by:
 *   a) biting pieces from chunk_chain (cannot create one above last_op);
 *   b) biting a piece from an unused block (if block was last_op, this
 *      may create a chunk from chain above last_op, thus last_op is
 *      invalidated in such a case).
 *   c) biting of sbrk()ed-but-not-yet-used space.  This creates 
 *      a block which is last_op.
 *   d) Allocating new pages by calling getpages();
 * 
 * getpages() creates a new block.  It marks last_op at the bottom of
 * the chunk of memory it returns.
 * 
 * Active pages footprint:
 * ~~~~~~~~~~~~~~~~~~~~~~
 * Note that we do not need to traverse the lists in nextf[i], just take
 * the first element of this list.  However, we *need* to traverse the
 * list in chunk_chain, but most the time it should be a very short one,
 * so we do not step on a lot of pages we are not going to use.
 * 
 * Flaws:
 * ~~~~~
 * get_from_bigger_buckets(): forget to increment price => Quite
 * aggressive.
 */

d240 7
a246 5
/* 
 * I removed the definition of u_bigint which appeared to be u_bigint = UV
 * u_bigint was only used in TWOK_MASKED and TWOK_SHIFT 
 * where I have used PTR2UV.  RMB
 */
d271 1
a272 1
		u_char	ovu_magic;	/* magic number */
d284 7
d352 23
a374 115
/* In this case there are several possible layout of arenas depending
 * on the size.  Arenas are of sizes multiple to 2K, 2K-aligned, and
 * have a size close to a power of 2.
 *
 * Arenas of the size >= 4K keep one chunk only.  Arenas of size 2K
 * may keep one chunk or multiple chunks.  Here are the possible
 * layouts of arenas:
 *
 *	# One chunk only, chunksize 2^k + SOMETHING - ALIGN, k >= 11
 *
 * INDEX MAGIC1 UNUSED CHUNK1
 *
 *	# Multichunk with sanity checking and chunksize 2^k-ALIGN, k>7
 *
 * INDEX MAGIC1 MAGIC2 MAGIC3 UNUSED CHUNK1 CHUNK2 CHUNK3 ...
 *
 *	# Multichunk with sanity checking and size 2^k-ALIGN, k=7
 *
 * INDEX MAGIC1 MAGIC2 MAGIC3 UNUSED CHUNK1 UNUSED CHUNK2 CHUNK3 ...
 *
 *	# Multichunk with sanity checking and size up to 80
 *
 * INDEX UNUSED MAGIC1 UNUSED MAGIC2 UNUSED ... CHUNK1 CHUNK2 CHUNK3 ...
 *
 *	# No sanity check (usually up to 48=byte-long buckets)
 * INDEX UNUSED CHUNK1 CHUNK2 ...
 *
 * Above INDEX and MAGIC are one-byte-long.  Sizes of UNUSED are
 * appropriate to keep algorithms simple and memory aligned.  INDEX
 * encodes the size of the chunk, while MAGICn encodes state (used,
 * free or non-managed-by-us-so-it-indicates-a-bug) of CHUNKn.  MAGIC
 * is used for sanity checking purposes only.  SOMETHING is 0 or 4K
 * (to make size of big CHUNK accomodate allocations for powers of two
 * better).
 *
 * [There is no need to alignment between chunks, since C rules ensure
 *  that structs which need 2^k alignment have sizeof which is
 *  divisible by 2^k.  Thus as far as the last chunk is aligned at the
 *  end of the arena, and 2K-alignment does not contradict things,
 *  everything is going to be OK for sizes of chunks 2^n and 2^n +
 *  2^k.  Say, 80-bit buckets will be 16-bit aligned, and as far as we
 *  put allocations for requests in 65..80 range, all is fine.
 *
 *  Note, however, that standard malloc() puts more strict
 *  requirements than the above C rules.  Moreover, our algorithms of
 *  realloc() may break this idyll, but we suppose that realloc() does
 *  need not change alignment.]
 *
 * Is very important to make calculation of the offset of MAGICm as
 * quick as possible, since it is done on each malloc()/free().  In
 * fact it is so quick that it has quite little effect on the speed of
 * doing malloc()/free().  [By default] We forego such calculations
 * for small chunks, but only to save extra 3% of memory, not because
 * of speed considerations.
 *
 * Here is the algorithm [which is the same for all the allocations
 * schemes above], see OV_MAGIC(block,bucket).  Let OFFSETm be the
 * offset of the CHUNKm from the start of ARENA.  Then offset of
 * MAGICm is (OFFSET1 >> SHIFT) + ADDOFFSET.  Here SHIFT and ADDOFFSET
 * are numbers which depend on the size of the chunks only.
 *
 * Let as check some sanity conditions.  Numbers OFFSETm>>SHIFT are
 * different for all the chunks in the arena if 2^SHIFT is not greater
 * than size of the chunks in the arena.  MAGIC1 will not overwrite
 * INDEX provided ADDOFFSET is >0 if OFFSET1 < 2^SHIFT.  MAGIClast
 * will not overwrite CHUNK1 if OFFSET1 > (OFFSETlast >> SHIFT) +
 * ADDOFFSET.
 * 
 * Make SHIFT the maximal possible (there is no point in making it
 * smaller).  Since OFFSETlast is 2K - CHUNKSIZE, above restrictions
 * give restrictions on OFFSET1 and on ADDOFFSET.
 * 
 * In particular, for chunks of size 2^k with k>=6 we can put
 * ADDOFFSET to be from 0 to 2^k - 2^(11-k), and have
 * OFFSET1==chunksize.  For chunks of size 80 OFFSET1 of 2K%80=48 is
 * large enough to have ADDOFFSET between 1 and 16 (similarly for 96,
 * when ADDOFFSET should be 1).  In particular, keeping MAGICs for
 * these sizes gives no additional size penalty.
 * 
 * However, for chunks of size 2^k with k<=5 this gives OFFSET1 >=
 * ADDOFSET + 2^(11-k).  Keeping ADDOFFSET 0 allows for 2^(11-k)-2^(11-2k)
 * chunks per arena.  This is smaller than 2^(11-k) - 1 which are
 * needed if no MAGIC is kept.  [In fact, having a negative ADDOFFSET
 * would allow for slightly more buckets per arena for k=2,3.]
 * 
 * Similarly, for chunks of size 3/2*2^k with k<=5 MAGICs would span
 * the area up to 2^(11-k)+ADDOFFSET.  For k=4 this give optimal
 * ADDOFFSET as -7..0.  For k=3 ADDOFFSET can go up to 4 (with tiny
 * savings for negative ADDOFFSET).  For k=5 ADDOFFSET can go -1..16
 * (with no savings for negative values).
 *
 * In particular, keeping ADDOFFSET 0 for sizes of chunks up to 2^6
 * leads to tiny pessimizations in case of sizes 4, 8, 12, 24, and
 * leads to no contradictions except for size=80 (or 96.)
 *
 * However, it also makes sense to keep no magic for sizes 48 or less.
 * This is what we do.  In this case one needs ADDOFFSET>=1 also for
 * chunksizes 12, 24, and 48, unless one gets one less chunk per
 * arena.
 *  
 * The algo of OV_MAGIC(block,bucket) keeps ADDOFFSET 0 until
 * chunksize of 64, then makes it 1. 
 *
 * This allows for an additional optimization: the above scheme leads
 * to giant overheads for sizes 128 or more (one whole chunk needs to
 * be sacrifised to keep INDEX).  Instead we use chunks not of size
 * 2^k, but of size 2^k-ALIGN.  If we pack these chunks at the end of
 * the arena, then the beginnings are still in different 2^k-long
 * sections of the arena if k>=7 for ALIGN==4, and k>=8 if ALIGN=8.
 * Thus for k>7 the above algo of calculating the offset of the magic
 * will still give different answers for different chunks.  And to
 * avoid the overrun of MAGIC1 into INDEX, one needs ADDOFFSET of >=1.
 * In the case k=7 we just move the first chunk an extra ALIGN
 * backward inside the ARENA (this is done once per arena lifetime,
 * thus is not a big overhead).  */
d379 3
a381 3
#  define TWOK_MASKED(x) (PTR2UV(x) & ~TWOK_MASK)
#  define TWOK_SHIFT(x) (PTR2UV(x) & TWOK_MASK)
#  define OV_INDEXp(block) (INT2PTR(u_char*,TWOK_MASKED(block)))
a449 3
#  define NEEDED_ALIGNMENT 0x800	/* 2k boundaries */
#  define WANTED_ALIGNMENT 0x800	/* 2k boundaries */

a455 3
#  define NEEDED_ALIGNMENT MEM_ALIGNBYTES
#  define WANTED_ALIGNMENT 0x400	/* 1k boundaries */

a566 10
static void	morecore	(register int bucket);
#  if defined(DEBUGGING)
static void	botch		(char *diag, char *s);
#  endif
static void	add_to_chain	(void *p, MEM_SIZE size, MEM_SIZE chip);
static void*	get_from_chain	(MEM_SIZE size);
static void*	get_from_bigger_buckets(int bucket, MEM_SIZE size);
static union overhead *getpages	(MEM_SIZE needed, int *nblksp, int bucket);
static int	getpages_adjacent(MEM_SIZE require);

d573 5
a577 5
#ifdef I_MACH_CTHREADS
#  undef  MUTEX_LOCK
#  define MUTEX_LOCK(m)   STMT_START { if (*m) mutex_lock(*m);   } STMT_END
#  undef  MUTEX_UNLOCK
#  define MUTEX_UNLOCK(m) STMT_START { if (*m) mutex_unlock(*m); } STMT_END
d582 1
d591 1
a591 1
	MALLOC_UNLOCK;
d602 1
a602 1
	dTHX;
d627 1
a627 1
	if ((PTR2UV(pv) - sizeof(union overhead)) & (NEEDED_ALIGNMENT - 1)) {
d639 1
a639 1
    MALLOC_UNLOCK;
a640 2
    /* NOTREACHED */
    return Nullch;
a646 4
#ifndef BITS_IN_PTR
#  define BITS_IN_PTR (8*PTRSIZE)
#endif

d652 1
a652 1
#define	NBUCKETS (BITS_IN_PTR*BUCKETS_PER_POW2 + 1)
a654 4
#if defined(PURIFY) && !defined(USE_PERL_SBRK)
#  define USE_PERL_SBRK
#endif

d657 1
a657 1
Malloc_t Perl_sbrk (int size);
a685 1
	dTHX;
d694 1
a694 1
Perl_malloc(register size_t nbytes)
d707 1
a707 1
	    croak("%s", "panic: malloc");
d710 1
a741 1
	MALLOC_LOCK;
d749 1
a749 1
		MALLOC_UNLOCK;
d751 3
a753 6
		{
		    dTHX;
		    if (!PL_nomemok) {
			PerlIO_puts(PerlIO_stderr(),"Out of memory!\n");
			my_exit(1);
		    }
d755 2
a757 1
  		return (NULL);
d761 2
a762 2
			      "0x%"UVxf": (%05lu) malloc %ld bytes\n",
			      PTR2UV(p+1), (unsigned long)(PL_an++),
d767 3
a769 13
	if ((PTR2UV(p)) & (MEM_ALIGNBYTES - 1)) {
	    dTHX;
	    PerlIO_printf(PerlIO_stderr(),
			  "Unaligned pointer in the free chain 0x%"UVxf"\n",
			  PTR2UV(p));
	}
	if ((PTR2UV(p->ov_next)) & (MEM_ALIGNBYTES - 1)) {
	    dTHX;
	    PerlIO_printf(PerlIO_stderr(),
			  "Unaligned `next' pointer in the free "
			  "chain 0x"UVxf" at 0x%"UVxf"\n",
			  PTR2UV(p->ov_next), PTR2UV(p));
	}
a771 3

	MALLOC_UNLOCK;

d799 1
d903 1
a903 1
getpages(MEM_SIZE needed, int *nblksp, int bucket)
d910 1
a910 1
    MEM_SIZE slack = 0;
a936 1
	last_op = cp - sbrked_remains;
a941 3
	if (((char*)ovp) > last_op) {	/* Cannot happen with current emergency_sbrk() */
	    last_op = 0;
	}
d958 5
a962 4
	/* WANTED_ALIGNMENT may be more than NEEDED_ALIGNMENT, but this may
	   improve performance of memory access. */
	if (PTR2UV(cp) & (WANTED_ALIGNMENT - 1)) { /* Not aligned. */
	    slack = WANTED_ALIGNMENT - (PTR2UV(cp) & (WANTED_ALIGNMENT - 1));
d984 2
a985 2
		    MALLOC_UNLOCK;
		    fatalcroak("panic: Off-page sbrk\n");
a1021 5
#  if NEEDED_ALIGNMENT > MEM_ALIGNBYTES
	if (PTR2UV(ovp) & (NEEDED_ALIGNMENT - 1))
	    fatalcroak("Misalignment of sbrk()\n");
	else
#  endif
d1023 2
a1024 1
	if (PTR2UV(ovp) & (MEM_ALIGNBYTES - 1)) {
d1027 1
a1027 3
				  (int)(PTR2UV(ovp) & (MEM_ALIGNBYTES - 1))));
	    ovp = INT2PTR(union overhead *,(PTR2UV(ovp) + MEM_ALIGNBYTES) &
				     (MEM_ALIGNBYTES - 1));
d1031 1
a1031 1
	    sbrk_slack += (1 << (bucket >> BUCKET_POW2_SHIFT));
a1034 1
	;				/* Finish `else' */
a1035 1
	last_op = cp;
d1038 1
d1046 1
a1046 1
getpages_adjacent(MEM_SIZE require)
d1100 1
a1100 1
	    MALLOC_UNLOCK;
d1187 2
a1188 2
Perl_mfree(void *mp)
{
d1197 2
a1198 2
			      "0x%"UVxf": (%05lu) free\n",
			      PTR2UV(cp), (unsigned long)(PL_an++)));
a1215 1
		    dTHX;
a1221 9
#ifdef PERL_CORE
		{
		    dTHX;
		    if (!PERL_IS_ALIVE || !PL_curcop || ckWARN_d(WARN_MALLOC))
			Perl_warner(aTHX_ WARN_MALLOC, "%s free() ignored",
				    ovp->ov_rmagic == RMAGIC - 1 ?
				    "Duplicate" : "Bad");
		}
#else
a1223 8
#endif		
#else
#ifdef PERL_CORE
		{
		    dTHX;
		    if (!PERL_IS_ALIVE || !PL_curcop || ckWARN_d(WARN_MALLOC))
			Perl_warner(aTHX_ WARN_MALLOC, "%s", "Bad free() ignored");
		}
a1226 1
#endif
d1229 1
a1249 2

	MALLOC_LOCK;
d1252 1
a1252 1
	MALLOC_UNLOCK;
d1255 12
a1266 4
/* There is no need to do any locking in realloc (with an exception of
   trying to grow in place if we are at the end of the chain).
   If somebody calls us from a different thread with the same address,
   we are sole anyway.  */
d1269 2
a1270 2
Perl_realloc(void *mp, size_t nbytes)
{
d1276 1
a1276 2
	int incr;		/* 1 if does not fit, -1 if "easily" fits in a
				   smaller bucket, otherwise 0.  */
d1283 1
a1283 1
	    croak("%s", "panic: realloc");
d1288 1
a1288 1
		return Perl_malloc(nbytes);
d1290 1
a1293 1

d1295 2
a1296 2
	if ((bucket >= FIRST_BUCKET_WITH_CHECK) 
	    && (OV_MAGIC(ovp, bucket) != MAGIC))
d1298 1
a1298 1
	if (OV_MAGIC(ovp, bucket) != MAGIC)
d1300 18
a1317 39
	    {
		static int bad_free_warn = -1;
		if (bad_free_warn == -1) {
		    dTHX;
		    char *pbf = PerlEnv_getenv("PERL_BADFREE");
		    bad_free_warn = (pbf) ? atoi(pbf) : 1;
		}
		if (!bad_free_warn)
		    return Nullch;
#ifdef RCHECK
#ifdef PERL_CORE
		{
		    dTHX;
		    if (!PERL_IS_ALIVE || !PL_curcop || ckWARN_d(WARN_MALLOC))
			Perl_warner(aTHX_ WARN_MALLOC, "%srealloc() %signored",
				    (ovp->ov_rmagic == RMAGIC - 1 ? "" : "Bad "),
				    ovp->ov_rmagic == RMAGIC - 1
				    ? "of freed memory " : "");
		}
#else
		warn("%srealloc() %signored",
		    (ovp->ov_rmagic == RMAGIC - 1 ? "" : "Bad "),
		     ovp->ov_rmagic == RMAGIC - 1 ? "of freed memory " : "");
#endif
#else
#ifdef PERL_CORE
		{
		    dTHX;
		    if (!PERL_IS_ALIVE || !PL_curcop || ckWARN_d(WARN_MALLOC))
			Perl_warner(aTHX_ WARN_MALLOC, "%s",
				    "Bad realloc() ignored");
		}
#else
		warn("%s", "Bad realloc() ignored");
#endif
#endif
		return Nullch;			/* sanity */
	    }

d1346 1
d1348 1
a1348 1
	goto hard_way;
d1350 2
a1351 1
	if (incr == 0) {
d1388 1
d1390 2
a1391 2
			      "0x%"UVxf": (%05lu) realloc %ld bytes inplace\n",
			      PTR2UV(res),(unsigned long)(PL_an++),
d1409 1
a1409 3
	    MALLOC_LOCK;
	    if (cp - M_OVERHEAD == last_op /* We *still* are the last chunk */
		&& getpages_adjacent(require)) {
a1414 1
		MALLOC_UNLOCK;
d1416 1
a1416 2
	    } else {
		MALLOC_UNLOCK;		
a1417 1
	    }
d1420 1
d1422 2
a1423 2
			      "0x%"UVxf": (%05lu) realloc %ld bytes the hard way\n",
			      PTR2UV(cp),(unsigned long)(PL_an++),
d1425 1
a1425 1
	    if ((res = (char*)Perl_malloc(nbytes)) == NULL)
d1429 2
a1430 1
	    Perl_mfree(cp);
d1435 22
d1458 1
a1458 1
Perl_calloc(register size_t elements, register size_t size)
d1461 1
a1461 1
    Malloc_t p = Perl_malloc(sz);
a1468 40
char *
Perl_strdup(const char *s)
{
    MEM_SIZE l = strlen(s);
    char *s1 = (char *)Perl_malloc(l+1);

    Copy(s, s1, (MEM_SIZE)(l+1), char);
    return s1;
}

#ifdef PERL_CORE
int
Perl_putenv(char *a)
{
    /* Sometimes system's putenv conflicts with my_setenv() - this is system
       malloc vs Perl's free(). */
  dTHX;
  char *var;
  char *val = a;
  MEM_SIZE l;
  char buf[80];

  while (*val && *val != '=')
      val++;
  if (!*val)
      return -1;
  l = val - a;
  if (l < sizeof(buf))
      var = buf;
  else
      var = Perl_malloc(l + 1);
  Copy(a, var, l, char);
  var[l + 1] = 0;
  my_setenv(var, val+1);
  if (var != buf)
      Perl_mfree(var);
  return 0;
}
#  endif

d1470 1
a1470 1
Perl_malloced_size(void *p)
d1487 2
a1493 51

int
Perl_get_mstats(pTHX_ perl_mstats_t *buf, int buflen, int level)
{
#ifdef DEBUGGING_MSTATS
  	register int i, j;
  	register union overhead *p;
	struct chunk_chain_s* nextchain;

  	buf->topbucket = buf->topbucket_ev = buf->topbucket_odd 
	    = buf->totfree = buf->total = buf->total_chain = 0;

	buf->minbucket = MIN_BUCKET;
	MALLOC_LOCK;
  	for (i = MIN_BUCKET ; i < NBUCKETS; i++) {
  		for (j = 0, p = nextf[i]; p; p = p->ov_next, j++)
  			;
		if (i < buflen) {
		    buf->nfree[i] = j;
		    buf->ntotal[i] = nmalloc[i];
		}		
  		buf->totfree += j * BUCKET_SIZE_REAL(i);
  		buf->total += nmalloc[i] * BUCKET_SIZE_REAL(i);
		if (nmalloc[i]) {
		    i % 2 ? (buf->topbucket_odd = i) : (buf->topbucket_ev = i);
		    buf->topbucket = i;
		}
  	}
	nextchain = chunk_chain;
	while (nextchain) {
	    buf->total_chain += nextchain->size;
	    nextchain = nextchain->next;
	}
	buf->total_sbrk = goodsbrk + sbrk_slack;
	buf->sbrks = sbrks;
	buf->sbrk_good = sbrk_good;
	buf->sbrk_slack = sbrk_slack;
	buf->start_slack = start_slack;
	buf->sbrked_remains = sbrked_remains;
	MALLOC_UNLOCK;
	if (level) {
	    for (i = MIN_BUCKET ; i < NBUCKETS; i++) {
		if (i >= buflen)
		    break;
		buf->bucket_mem_size[i] = BUCKET_SIZE(i);
		buf->bucket_available_size[i] = BUCKET_SIZE_REAL(i);
	    }
	}
#endif	/* defined DEBUGGING_MSTATS */
	return 0;		/* XXX unused */
}
d1502 1
a1502 1
Perl_dump_mstats(pTHX_ char *s)
a1503 1
#ifdef DEBUGGING_MSTATS
d1506 4
a1509 8
	perl_mstats_t buffer;
	unsigned long nf[NBUCKETS];
	unsigned long nt[NBUCKETS];
	struct chunk_chain_s* nextchain;

	buffer.nfree  = nf;
	buffer.ntotal = nt;
	get_mstats(&buffer, NBUCKETS, 0);
d1511 11
d1523 1
a1523 1
	    PerlIO_printf(Perl_error_log,
d1528 4
a1531 5
			  (long)BUCKET_SIZE_REAL(buffer.topbucket), 
			  (long)BUCKET_SIZE(buffer.topbucket));
  	PerlIO_printf(Perl_error_log, "%8ld free:", buffer.totfree);
  	for (i = MIN_EVEN_REPORT; i <= buffer.topbucket; i += BUCKETS_PER_POW2) {
  		PerlIO_printf(Perl_error_log, 
d1535 1
a1535 1
			      buffer.nfree[i]);
d1538 3
a1540 3
	PerlIO_printf(Perl_error_log, "\n\t   ");
  	for (i = MIN_BUCKET + 1; i <= buffer.topbucket_odd; i += BUCKETS_PER_POW2) {
  		PerlIO_printf(Perl_error_log, 
d1544 1
a1544 1
			      buffer.nfree[i]);
d1547 3
a1549 3
  	PerlIO_printf(Perl_error_log, "\n%8ld used:", buffer.total - buffer.totfree);
  	for (i = MIN_EVEN_REPORT; i <= buffer.topbucket; i += BUCKETS_PER_POW2) {
  		PerlIO_printf(Perl_error_log, 
d1553 1
a1553 1
			      buffer.ntotal[i] - buffer.nfree[i]);
d1556 3
a1558 3
	PerlIO_printf(Perl_error_log, "\n\t   ");
  	for (i = MIN_BUCKET + 1; i <= buffer.topbucket_odd; i += BUCKETS_PER_POW2) {
  		PerlIO_printf(Perl_error_log, 
d1562 1
a1562 1
			      buffer.ntotal[i] - buffer.nfree[i]);
d1565 7
a1571 5
	PerlIO_printf(Perl_error_log, "\nTotal sbrk(): %ld/%ld:%ld. Odd ends: pad+heads+chain+tail: %ld+%ld+%ld+%ld.\n",
		      buffer.total_sbrk, buffer.sbrks, buffer.sbrk_good,
		      buffer.sbrk_slack, buffer.start_slack,
		      buffer.total_chain, buffer.sbrked_remains);
#endif /* DEBUGGING_MSTATS */
d1573 6
d1581 1
d1584 1
a1584 1
#   if defined(__MACHTEN_PPC__) || defined(NeXT) || defined(__NeXT__) || defined(PURIFY)
d1586 11
d1600 8
a1616 3
#      ifndef SYSTEM_ALLOC_ALIGNMENT
#         define SYSTEM_ALLOC_ALIGNMENT MEM_ALIGNBYTES
#      endif
a1649 3
#  if NEEDED_ALIGNMENT > SYSTEM_ALLOC_ALIGNMENT
      size += NEEDED_ALIGNMENT - SYSTEM_ALLOC_ALIGNMENT;
#  endif
d1651 3
a1653 3
#  if NEEDED_ALIGNMENT > SYSTEM_ALLOC_ALIGNMENT
      got = (got + NEEDED_ALIGNMENT - 1) & ~(NEEDED_ALIGNMENT - 1);
#  endif
d1661 2
a1662 2
    DEBUG_m(PerlIO_printf(Perl_debug_log, "sbrk malloc size %ld (reqsize %ld), left size %ld, give addr 0x%"UVxf"\n",
		    size, reqsize, Perl_sbrk_oldsize, PTR2UV(got)));
@


1.1.1.4
log
@stock perl 5.6.1
@
text
@a148 3
     # Fatal error reporting function
     croak2(format, arg1, arg2)		warn2(idem) + exit(1)
  
a151 3
     # Error reporting function
     warn2(format, arg1, arg2)		fprintf(stderr, idem)

a236 1
#    define croak2	Perl_croak_nocontext
a237 4
#    define warn2	Perl_warn_nocontext
#  else
#    define croak2	croak
#    define warn2	warn
a276 3
#  ifndef croak2			/* make depend */
#    define croak2(mess, arg1, arg2) (warn2((mess), (arg1), (arg2)), exit(1))
#  endif 
a279 3
#  ifndef warn2
#    define warn2(mess, arg1) fprintf(stderr, (mess), (arg1), (arg2))
#  endif 
a443 5
/*
 * Keep the ovu_index and ovu_magic in this order, having a char
 * field first gives alignment indigestion in some systems, such as
 * MachTen.
 */
d841 5
a845 1
#ifdef PERL_CORE
a853 45
#ifndef BITS_IN_PTR
#  define BITS_IN_PTR (8*PTRSIZE)
#endif

/*
 * nextf[i] is the pointer to the next free block of size 2^i.  The
 * smallest allocatable block is 8 bytes.  The overhead information
 * precedes the data area returned to the user.
 */
#define	NBUCKETS (BITS_IN_PTR*BUCKETS_PER_POW2 + 1)
static	union overhead *nextf[NBUCKETS];

#if defined(PURIFY) && !defined(USE_PERL_SBRK)
#  define USE_PERL_SBRK
#endif

#ifdef USE_PERL_SBRK
# define sbrk(a) Perl_sbrk(a)
Malloc_t Perl_sbrk (int size);
#else
#ifndef HAS_SBRK_PROTO
extern	Malloc_t sbrk(int);
#endif
#endif

#ifdef DEBUGGING_MSTATS
/*
 * nmalloc[i] is the difference between the number of mallocs and frees
 * for a given block size.
 */
static	u_int nmalloc[NBUCKETS];
static  u_int sbrk_slack;
static  u_int start_slack;
#else	/* !( defined DEBUGGING_MSTATS ) */
#  define sbrk_slack	0
#endif

static	u_int goodsbrk;

# ifdef PERL_EMERGENCY_SBRK

#  ifndef BIG_SIZE
#    define BIG_SIZE (1<<16)		/* 64K */
#  endif

a855 2
static int no_mem;	/* 0 if the last request for more memory succeeded.
			   Otherwise the size of the failing request. */
d862 2
a863 2
    if (size >= BIG_SIZE && (!no_mem || (size < no_mem))) {
	/* Give the possibility to recover, but avoid an infinite cycle. */
d865 1
a865 2
	no_mem = size;
	croak2("Out of memory during \"large\" request for %"UVuf" bytes, total sbrk() is %"UVuf" bytes", (UV)size, (UV)(goodsbrk + sbrk_slack));
d913 1
a913 1
    croak("Out of memory during request for %"UVuf" bytes, total sbrk() is %"UVuf" bytes", (UV)size, (UV)(goodsbrk + sbrk_slack));
d918 1
a918 1
# else /*  !defined(PERL_EMERGENCY_SBRK) */
d920 42
a961 2
# endif
#endif /* ifdef PERL_CORE */
d1038 1
a1038 26
#if defined(PLAIN_MALLOC) && defined(NO_FANCY_MALLOC)
		        PerlIO_puts(PerlIO_stderr(),"Out of memory!\n");
#else
			char buff[80];
			char *eb = buff + sizeof(buff) - 1;
			char *s = eb;
			size_t n = nbytes;

			PerlIO_puts(PerlIO_stderr(),"Out of memory during request for ");
#if defined(DEBUGGING) || defined(RCHECK)
			n = size;
#endif
			*s = 0;			
			do {
			    *--s = '0' + (n % 10);
			} while (n /= 10);
			PerlIO_puts(PerlIO_stderr(),s);
			PerlIO_puts(PerlIO_stderr()," bytes, total sbrk() is ");
			s = eb;
			n = goodsbrk + sbrk_slack;
			do {
			    *--s = '0' + (n % 10);
			} while (n /= 10);
			PerlIO_puts(PerlIO_stderr(),s);
			PerlIO_puts(PerlIO_stderr()," bytes!\n");
#endif /* defined(PLAIN_MALLOC) && defined(NO_FANCY_MALLOC) */
d1048 1
a1048 1
			      PTR2UV(p), (unsigned long)(PL_an++),
d1063 1
a1063 1
			  "chain 0x%"UVxf" at 0x%"UVxf"\n",
a1345 3
#if !defined(PLAIN_MALLOC) && !defined(NO_FANCY_MALLOC)
    no_mem = 0;
#endif
a1891 1
	buf->nbuckets = NBUCKETS;
d1914 2
a1915 1
  	register int i;
d1917 3
a1919 2
	UV nf[NBUCKETS];
	UV nt[NBUCKETS];
d1927 1
a1927 1
			  "Memory allocation statistics %s (buckets %"IVdf"(%"IVdf")..%"IVdf"(%"IVdf")\n",
d1929 5
a1933 5
			  (IV)BUCKET_SIZE_REAL(MIN_BUCKET), 
			  (IV)BUCKET_SIZE(MIN_BUCKET),
			  (IV)BUCKET_SIZE_REAL(buffer.topbucket), 
			  (IV)BUCKET_SIZE(buffer.topbucket));
  	PerlIO_printf(Perl_error_log, "%8"IVdf" free:", buffer.totfree);
d1937 2
a1938 2
			       ? " %5"UVuf 
			       : ((i < 12*BUCKETS_PER_POW2) ? " %3"UVuf : " %"UVuf)),
d1946 2
a1947 2
			       ? " %5"UVuf 
			       : ((i < 12*BUCKETS_PER_POW2) ? " %3"UVuf : " %"UVuf)),
d1951 1
a1951 1
  	PerlIO_printf(Perl_error_log, "\n%8"IVdf" used:", buffer.total - buffer.totfree);
d1955 2
a1956 2
			       ? " %5"IVdf
			       : ((i < 12*BUCKETS_PER_POW2) ? " %3"IVdf : " %"IVdf)), 
d1964 2
a1965 2
			       ? " %5"IVdf 
			       : ((i < 12*BUCKETS_PER_POW2) ? " %3"IVdf : " %"IVdf)),
d1969 1
a1969 1
	PerlIO_printf(Perl_error_log, "\nTotal sbrk(): %"IVdf"/%"IVdf":%"IVdf". Odd ends: pad+heads+chain+tail: %"IVdf"+%"IVdf"+%"IVdf"+%"IVdf".\n",
@


1.1.1.5
log
@stock perl 5.8.0 from CPAN
@
text
@a5 4
 * "'The Chamber of Records,' said Gimli. 'I guess that is where we now stand.'"
 */

/*
d258 1
d307 1
a307 5
#     ifdef HASATTRIBUTE
#        define dTHX		extern int Perl___notused PERL_UNUSED_DECL
#     else
#        define dTHX            extern int Perl___notused
#     endif
d352 1
a352 1
#  define DEBUG_m(a) 							\
d354 1
a354 8
	if (PERL_GET_INTERP) {						\
	    dTHX;							\
	    if (DEBUG_m_TEST) {						\
		PL_debug &= ~DEBUG_m_FLAG;				\
		a;							\
		PL_debug |= DEBUG_m_FLAG;				\
	    }								\
	}								\
d892 1
a892 1
# ifndef HAS_SBRK_PROTO /* <unistd.h> usually takes care of this */
d894 1
a894 1
# endif
d919 1
a919 1
static MEM_SIZE no_mem;	/* 0 if the last request for more memory succeeded.
a1043 1
#if defined(PACK_MALLOC) && !defined(SMALL_BUCKET_VIA_TABLE)
a1044 1
#endif
d1097 5
a1121 5
	DEBUG_m(PerlIO_printf(Perl_debug_log,
			      "0x%"UVxf": (%05lu) malloc %ld bytes\n",
			      PTR2UV(p), (unsigned long)(PL_an++),
			      (long)size));

d1154 1
a1154 1
static MEM_SIZE sbrked_remains;
d1589 1
a1589 1
			Perl_warner(aTHX_ packWARN(WARN_MALLOC), "%s free() ignored (RMAGIC, PERL_CORE)",
d1594 1
a1594 1
		warn("%s free() ignored (RMAGIC)",
d1602 1
a1602 1
			Perl_warner(aTHX_ packWARN(WARN_MALLOC), "%s", "Bad free() ignored (PERL_CORE)");
d1689 1
a1689 1
			Perl_warner(aTHX_ packWARN(WARN_MALLOC), "%srealloc() %signored",
d1704 1
a1704 1
			Perl_warner(aTHX_ packWARN(WARN_MALLOC), "%s",
@


1.1.1.6
log
@perl 5.8.2 from CPAN
@
text
@a29 3
    # Read configuration settings from malloc_cfg.h
    HAVE_MALLOC_CFG_H		undef

d32 1
a32 1
    PERL_EMERGENCY_SBRK		(!PLAIN_MALLOC && (PERL_CORE || !NO_MALLOC_DYNAMIC_CFG))
a80 16
    # Do not overwrite uninit areas with DEBUGGING.  Speed
    # optimization, error reporting pessimization
    NO_MFILL			undef

    # Overwrite uninit areas with DEBUGGING.  Speed
    # pessimization, error reporting optimization
    MALLOC_FILL			(DEBUGGING && !NO_RCHECK && !NO_MFILL)

    # Do not check overwritten uninit areas with DEBUGGING.  Speed
    # optimization, error reporting pessimization
    NO_FILL_CHECK		undef

    # Check overwritten uninit areas with DEBUGGING.  Speed
    # pessimization, error reporting optimization
    MALLOC_FILL_CHECK		(DEBUGGING && !NO_RCHECK && !NO_FILL_CHECK)

a100 3
    # Round up sbrk()s to multiples of this multiple of 1/1000 of footprint.
    MIN_SBRK_FRAC1000 		(10 * MIN_SBRK_FRAC)

a116 14
    # Do not allow configuration of runtime options at runtime
    NO_MALLOC_DYNAMIC_CFG	undef

    # Do not allow configuration of runtime options via $ENV{PERL_MALLOC_OPT}
    NO_PERL_MALLOC_ENV		undef

	[The variable consists of ;-separated parts of the form CODE=VALUE
	 with 1-character codes F, M, f, A, P, G, d, a, c for runtime
	 configuration of FIRST_SBRK, MIN_SBRK, MIN_SBRK_FRAC1000,
	 SBRK_ALLOW_FAILURES, SBRK_FAILURE_PRICE, sbrk_goodness,
	 filldead, fillalive, fillcheck.  The last 3 are for DEBUGGING
	 build, and allow switching the tests for free()ed memory read,
	 uninit memory reads, and free()ed memory write.]

a140 3
     # Signed integer of the same sizeof() as UV
     IV					long

a146 15
     # Conversion of pointer to integer
     PTR2UV(ptr)			((UV)(ptr))

     # Conversion of integer to pointer
     INT2PTR(type, i)			((type)(i))

     # printf()-%-Conversion of UV to pointer
     UVuf				"lu"

     # printf()-%-Conversion of UV to hex pointer
     UVxf				"lx"

     # Alignment to use
     MEM_ALIGNBYTES			4

a170 4
#ifdef HAVE_MALLOC_CFG_H
#  include "malloc_cfg.h"
#endif

d190 1
a190 1
#  if (defined(PERL_CORE) || !defined(NO_MALLOC_DYNAMIC_CFG)) && !defined(PERL_EMERGENCY_SBRK)
a213 6
#  if defined(DEBUGGING) && !defined(NO_RCHECK) && !defined(NO_MFILL) && !defined(MALLOC_FILL)
#    define MALLOC_FILL
#  endif
#  if defined(DEBUGGING) && !defined(NO_RCHECK) && !defined(NO_FILL_CHECK) && !defined(MALLOC_FILL_CHECK)
#    define MALLOC_FILL_CHECK
#  endif
a253 5
#  if defined(USE_5005THREADS) || defined(USE_ITHREADS)
#     define PERL_MAYBE_ALIVE	PL_thr_key
#  else
#     define PERL_MAYBE_ALIVE	1
#  endif
a261 4
#    ifdef OS2
#      include <io.h>
#    endif
#    include <string.h>
a276 3
#    ifndef IV
#      define IV long
#    endif
a286 19
#    define PerlIO_puts(f,s)		fputs(s,f)
#    ifndef INT2PTR
#      define INT2PTR(t,i)		((t)(i))
#    endif
#    ifndef PTR2UV
#      define PTR2UV(p)			((UV)(p))
#    endif
#    ifndef UVuf
#      define UVuf			"lu"
#    endif
#    ifndef UVxf
#      define UVxf			"lx"
#    endif
#    ifndef Nullch
#      define Nullch			NULL
#    endif
#    ifndef MEM_ALIGNBYTES
#      define MEM_ALIGNBYTES		4
#    endif
d298 1
a298 1
#    define warn2(mess, arg1, arg2) fprintf(stderr, (mess), (arg1), (arg2))
a319 1
#  define PERL_MAYBE_ALIVE	1
d335 1
a335 1
#endif	/* defined PERL_CORE */
d361 1
a361 1
	if (PERL_MAYBE_ALIVE && PERL_GET_THX) {						\
a472 3
#  if MEM_ALIGNBYTES > 8
	char	sstrut[MEM_ALIGNBYTES]; /* for the sizing */
#  endif
d483 1
a483 2
	    /* Subtract one to fit into u_short for an extra bucket */
		u_short	ovu_size;	/* block size (requested + overhead - 1) */
d498 1
a498 1
#  define	RMAGIC_SZ	sizeof (u_int) /* Overhead at end of bucket */
d500 1
a500 1
#    define MAX_SHORT_BUCKET (12 * BUCKETS_PER_POW2) /* size-1 fits in short */
d505 1
a505 1
#  define	RMAGIC_SZ	0
d541 1
a541 1
#  define BUCKET_SIZE_NO_SURPLUS(i) ((i) % 2 ? buck_size[i] : (1 << ((i) >> BUCKET_POW2_SHIFT)))
d548 2
a549 3
#  define BUCKET_SIZE_NO_SURPLUS(i) (1 << ((i) >> BUCKET_POW2_SHIFT))
#  define BUCKET_SIZE(i) (BUCKET_SIZE_NO_SURPLUS(i) + POW2_OPTIMIZE_SURPLUS(i))
#  define BUCKET_SIZE_REAL(i) (BUCKET_SIZE(i) - MEM_OVERHEAD(i))
d694 1
a694 1
			 ? ((1<<LOG_OF_MIN_ARENA) - 1)/BUCKET_SIZE_NO_SURPLUS(bucket) \
d717 1
a717 1
				 - BUCKET_SIZE_NO_SURPLUS(bucket) * N_BLKS(bucket)) \
d758 1
a758 1
#define M_OVERHEAD (sizeof(union overhead) + RMAGIC_SZ) /* overhead at start+end */
d869 1
a869 1
static void	botch		(char *diag, char *s, char *file, int line);
a885 6
#endif	/* defined PERL_CORE */ 

#ifndef PTRSIZE
#  define PTRSIZE	sizeof(void*)
#endif

a910 95
#ifndef MIN_SBRK_FRAC1000	/* Backward compatibility */
#  define MIN_SBRK_FRAC1000	(MIN_SBRK_FRAC * 10)
#endif

#ifndef START_EXTERN_C
#  ifdef __cplusplus
#    define START_EXTERN_C	extern "C" {
#  else
#    define START_EXTERN_C
#  endif
#endif

#ifndef END_EXTERN_C
#  ifdef __cplusplus
#    define END_EXTERN_C		};
#  else
#    define END_EXTERN_C
#  endif
#endif

#include "malloc_ctl.h"

#ifndef NO_MALLOC_DYNAMIC_CFG
#  define PERL_MALLOC_OPT_CHARS "FMfAPGdac"

#  ifndef FILL_DEAD_DEFAULT
#    define FILL_DEAD_DEFAULT	1
#  endif
#  ifndef FILL_ALIVE_DEFAULT
#    define FILL_ALIVE_DEFAULT	1
#  endif
#  ifndef FILL_CHECK_DEFAULT
#    define FILL_CHECK_DEFAULT	1
#  endif

static IV MallocCfg[MallocCfg_last] = {
  FIRST_SBRK,
  MIN_SBRK,
  MIN_SBRK_FRAC,
  SBRK_ALLOW_FAILURES,
  SBRK_FAILURE_PRICE,
  SBRK_ALLOW_FAILURES * SBRK_FAILURE_PRICE,	/* sbrk_goodness */
  FILL_DEAD_DEFAULT,	/* FILL_DEAD */
  FILL_ALIVE_DEFAULT,	/* FILL_ALIVE */
  FILL_CHECK_DEFAULT,	/* FILL_CHECK */
  0,			/* MallocCfg_skip_cfg_env */
  0,			/* MallocCfg_cfg_env_read */
  0,			/* MallocCfg_emergency_buffer_size */
  0,			/* MallocCfg_emergency_buffer_prepared_size */
  0			/* MallocCfg_emergency_buffer_last_req */
};
IV *MallocCfg_ptr = MallocCfg;

static char* MallocCfgP[MallocCfg_last] = {
  0,			/* MallocCfgP_emergency_buffer */
  0,			/* MallocCfgP_emergency_buffer_prepared */
};
char **MallocCfgP_ptr = MallocCfgP;

#  undef MIN_SBRK
#  undef FIRST_SBRK
#  undef MIN_SBRK_FRAC1000
#  undef SBRK_ALLOW_FAILURES
#  undef SBRK_FAILURE_PRICE

#  define MIN_SBRK		MallocCfg[MallocCfg_MIN_SBRK]
#  define FIRST_SBRK		MallocCfg[MallocCfg_FIRST_SBRK]
#  define MIN_SBRK_FRAC1000	MallocCfg[MallocCfg_MIN_SBRK_FRAC1000]
#  define SBRK_ALLOW_FAILURES	MallocCfg[MallocCfg_SBRK_ALLOW_FAILURES]
#  define SBRK_FAILURE_PRICE	MallocCfg[MallocCfg_SBRK_FAILURE_PRICE]

#  define sbrk_goodness		MallocCfg[MallocCfg_sbrk_goodness]

#  define emergency_buffer_size	MallocCfg[MallocCfg_emergency_buffer_size]
#  define emergency_buffer_last_req	MallocCfg[MallocCfg_emergency_buffer_last_req]

#  define FILL_DEAD		MallocCfg[MallocCfg_filldead]
#  define FILL_ALIVE		MallocCfg[MallocCfg_fillalive]
#  define FILL_CHECK_CFG	MallocCfg[MallocCfg_fillcheck]
#  define FILL_CHECK		(FILL_DEAD && FILL_CHECK_CFG)

#  define emergency_buffer	MallocCfgP[MallocCfgP_emergency_buffer]
#  define emergency_buffer_prepared	MallocCfgP[MallocCfgP_emergency_buffer_prepared]

#else	/* defined(NO_MALLOC_DYNAMIC_CFG) */

#  define FILL_DEAD	1
#  define FILL_ALIVE	1
#  define FILL_CHECK	1
static int sbrk_goodness = SBRK_ALLOW_FAILURES * SBRK_FAILURE_PRICE;

#  define NO_PERL_MALLOC_ENV

#endif

d925 1
a925 1
#ifdef PERL_EMERGENCY_SBRK
d931 1
a931 1
#  ifdef NO_MALLOC_DYNAMIC_CFG
d933 2
a934 80
	/* 0 if the last request for more memory succeeded.
	   Otherwise the size of the failing request. */
static MEM_SIZE emergency_buffer_last_req;
static char *emergency_buffer;
static char *emergency_buffer_prepared;
#  endif

#  ifndef emergency_sbrk_croak
#    define emergency_sbrk_croak	croak2
#  endif

#  ifdef PERL_CORE
static char *
perl_get_emergency_buffer(IV *size)
{
    dTHX;
    /* First offense, give a possibility to recover by dieing. */
    /* No malloc involved here: */
    GV **gvp = (GV**)hv_fetch(PL_defstash, "^M", 2, 0);
    SV *sv;
    char *pv;
    STRLEN n_a;

    if (!gvp) gvp = (GV**)hv_fetch(PL_defstash, "\015", 1, 0);
    if (!gvp || !(sv = GvSV(*gvp)) || !SvPOK(sv) 
        || (SvLEN(sv) < (1<<LOG_OF_MIN_ARENA) - M_OVERHEAD))
        return NULL;		/* Now die die die... */
    /* Got it, now detach SvPV: */
    pv = SvPV(sv, n_a);
    /* Check alignment: */
    if ((PTR2UV(pv) - sizeof(union overhead)) & (NEEDED_ALIGNMENT - 1)) {
        PerlIO_puts(PerlIO_stderr(),"Bad alignment of $^M!\n");
        return NULL;		/* die die die */
    }

    SvPOK_off(sv);
    SvPVX(sv) = Nullch;
    SvCUR(sv) = SvLEN(sv) = 0;
    *size = malloced_size(pv) + M_OVERHEAD;
    return pv - sizeof(union overhead);
}
#    define PERL_GET_EMERGENCY_BUFFER(p)	perl_get_emergency_buffer(p)
#  else
#    define PERL_GET_EMERGENCY_BUFFER(p)	NULL
#  endif	/* defined PERL_CORE */

#  ifndef NO_MALLOC_DYNAMIC_CFG
static char *
get_emergency_buffer(IV *size)
{
    char *pv = emergency_buffer_prepared;

    *size = MallocCfg[MallocCfg_emergency_buffer_prepared_size];
    emergency_buffer_prepared = 0;
    MallocCfg[MallocCfg_emergency_buffer_prepared_size] = 0;
    return pv;
}

/* Returns 0 on success, -1 on bad alignment, -2 if not implemented */
int
set_emergency_buffer(char *b, IV size)
{
    if (PTR2UV(b) & (NEEDED_ALIGNMENT - 1))
	return -1;
    if (MallocCfg[MallocCfg_emergency_buffer_prepared_size])
	add_to_chain((void*)emergency_buffer_prepared,
		     MallocCfg[MallocCfg_emergency_buffer_prepared_size], 0);
    emergency_buffer_prepared = b;
    MallocCfg[MallocCfg_emergency_buffer_prepared_size] = size;
    return 0;
}
#    define GET_EMERGENCY_BUFFER(p)	get_emergency_buffer(p)
#  else		/* NO_MALLOC_DYNAMIC_CFG */
#    define GET_EMERGENCY_BUFFER(p)	NULL
int
set_emergency_buffer(char *b, IV size)
{
    return -1;
}
#  endif
d941 1
a941 2
    if (size >= BIG_SIZE
	&& (!emergency_buffer_last_req || (size < emergency_buffer_last_req))) {
d944 2
a945 2
	emergency_buffer_last_req = size;
	emergency_sbrk_croak("Out of memory during \"large\" request for %"UVuf" bytes, total sbrk() is %"UVuf" bytes", (UV)size, (UV)(goodsbrk + sbrk_slack));
d955 1
d958 3
a960 2
	IV Size;
	char *pv = GET_EMERGENCY_BUFFER(&Size);
d962 1
d970 3
a972 4

	if (!pv)
	    pv = PERL_GET_EMERGENCY_BUFFER(&Size);
	if (!pv) {
d977 2
a978 1

d980 1
a980 3
	if (PTR2UV(pv) & (NEEDED_ALIGNMENT - 1)) {
	    dTHX;

d985 5
a989 2
	emergency_buffer = pv;
	emergency_buffer_size = Size;
d993 1
a993 1
    emergency_sbrk_croak("Out of memory during request for %"UVuf" bytes, total sbrk() is %"UVuf" bytes", (UV)size, (UV)(goodsbrk + sbrk_slack));
d998 1
a998 1
#else /*  !defined(PERL_EMERGENCY_SBRK) */
d1000 2
a1001 7
#endif	/* defined PERL_EMERGENCY_SBRK */

static void
write2(char *mess)
{
  write(2, mess, strlen(mess));
}
d1005 1
a1005 1
#define	ASSERT(p,diag)   if (!(p)) botch(diag,STRINGIFY(p),__FILE__,__LINE__);  else
d1007 1
a1007 1
botch(char *diag, char *s, char *file, int line)
a1008 3
    if (!(PERL_MAYBE_ALIVE && PERL_GET_THX))
	goto do_write;
    else {
d1010 1
a1010 23
	if (PerlIO_printf(PerlIO_stderr(),
			  "assertion botched (%s?): %s %s:%d\n",
			  diag, s, file, line) != 0) {
	 do_write:		/* Can be initializing interpreter */
	    write2("assertion botched (");
	    write2(diag);
	    write2("?): ");
	    write2(s);
	    write2(" (");
	    write2(file);
	    write2(":");
	    {
	      char linebuf[10];
	      char *s = linebuf + sizeof(linebuf) - 1;
	      int n = line;
	      *s = 0;
	      do {
		*--s = '0' + (n % 10);
	      } while (n /= 10);
	      write2(s);
	    }
	    write2(")\n");
	}
a1011 1
    }
a1016 76
#ifdef MALLOC_FILL
/* Fill should be long enough to cover long */
static void
fill_pat_4bytes(unsigned char *s, size_t nbytes, const unsigned char *fill)
{
    unsigned char *e = s + nbytes;
    long *lp;
    long lfill = *(long*)fill;

    if (PTR2UV(s) & (sizeof(long)-1)) {		/* Align the pattern */
	int shift = sizeof(long) - (PTR2UV(s) & (sizeof(long)-1));
	unsigned const char *f = fill + sizeof(long) - shift;
	unsigned char *e1 = s + shift;

	while (s < e1)
	    *s++ = *f++;
    }
    lp = (long*)s;
    while ((unsigned char*)(lp + 1) <= e)
	*lp++ = lfill;
    s = (unsigned char*)lp;
    while (s < e)
	*s++ = *fill++;
}
/* Just malloc()ed */
static const unsigned char fill_feedadad[] =
 {0xFE, 0xED, 0xAD, 0xAD, 0xFE, 0xED, 0xAD, 0xAD,
  0xFE, 0xED, 0xAD, 0xAD, 0xFE, 0xED, 0xAD, 0xAD};
/* Just free()ed */
static const unsigned char fill_deadbeef[] =
 {0xDE, 0xAD, 0xBE, 0xEF, 0xDE, 0xAD, 0xBE, 0xEF,
  0xDE, 0xAD, 0xBE, 0xEF, 0xDE, 0xAD, 0xBE, 0xEF};
#  define FILL_DEADBEEF(s, n)	\
	(void)(FILL_DEAD?  (fill_pat_4bytes((s), (n), fill_deadbeef), 0) : 0)
#  define FILL_FEEDADAD(s, n)	\
	(void)(FILL_ALIVE? (fill_pat_4bytes((s), (n), fill_feedadad), 0) : 0)
#else
#  define FILL_DEADBEEF(s, n)	((void)0)
#  define FILL_FEEDADAD(s, n)	((void)0)
#  undef MALLOC_FILL_CHECK
#endif

#ifdef MALLOC_FILL_CHECK
static int
cmp_pat_4bytes(unsigned char *s, size_t nbytes, const unsigned char *fill)
{
    unsigned char *e = s + nbytes;
    long *lp;
    long lfill = *(long*)fill;

    if (PTR2UV(s) & (sizeof(long)-1)) {		/* Align the pattern */
	int shift = sizeof(long) - (PTR2UV(s) & (sizeof(long)-1));
	unsigned const char *f = fill + sizeof(long) - shift;
	unsigned char *e1 = s + shift;

	while (s < e1)
	    if (*s++ != *f++)
		return 1;
    }
    lp = (long*)s;
    while ((unsigned char*)(lp + 1) <= e)
	if (*lp++ != lfill)
	    return 1;
    s = (unsigned char*)lp;
    while (s < e)
	if (*s++ != *fill++)
	    return 1;
    return 0;
}
#  define FILLCHECK_DEADBEEF(s, n)					\
	ASSERT(!FILL_CHECK || !cmp_pat_4bytes(s, n, fill_deadbeef),	\
	       "free()ed/realloc()ed-away memory was overwritten")
#else
#  define FILLCHECK_DEADBEEF(s, n)	((void)0)
#endif

d1114 2
a1115 4
#ifdef DEBUGGING
	if ( (PTR2UV(p) & (MEM_ALIGNBYTES - 1))
						/* Can't get this low */
	     || (p && PTR2UV(p) < (1<<LOG_OF_MIN_ARENA)) ) {
d1121 1
a1121 2
	if ( (PTR2UV(p->ov_next) & (MEM_ALIGNBYTES - 1))
	     || (p->ov_next && PTR2UV(p->ov_next) < (1<<LOG_OF_MIN_ARENA)) ) {
d1135 1
a1135 1
			      PTR2UV((Malloc_t)(p + CHUNK_SHIFT)), (unsigned long)(PL_an++),
a1137 3
	FILLCHECK_DEADBEEF((unsigned char*)(p + CHUNK_SHIFT),
			   BUCKET_SIZE_REAL(bucket) + RMAGIC_SZ);

d1156 4
a1159 4
	    if ((i = nbytes & (RMAGIC_SZ-1))) {
		i = RMAGIC_SZ - i;
		while (i--) /* nbytes - RMAGIC_SZ is end of alloced area */
		    ((caddr_t)p + nbytes - RMAGIC_SZ)[i] = RMAGIC_C;
d1161 2
a1162 3
	    /* Same at RMAGIC_SZ-aligned RMAGIC */
	    nbytes = (nbytes + RMAGIC_SZ - 1) & ~(RMAGIC_SZ - 1);
	    ((u_int *)((caddr_t)p + nbytes))[-1] = RMAGIC;
a1163 1
	FILL_FEEDADAD((unsigned char *)(p + CHUNK_SHIFT), size);
d1171 1
d1257 1
a1257 1
	    add_to_chain(ret, (BUCKET_SIZE_NO_SURPLUS(bucket) +
d1277 1
a1277 1
    if (sbrk_goodness > 0) {
d1282 2
a1283 2
	if (require < goodsbrk * MIN_SBRK_FRAC1000 / 1000)
	    require = goodsbrk * MIN_SBRK_FRAC1000 / 1000;
d1300 1
a1300 1
	sbrk_goodness++;
d1372 1
a1372 1
		sbrk_goodness = -1;	/* Disable optimization!
d1381 1
a1381 1
	    sbrk_goodness -= SBRK_FAILURE_PRICE;
d1414 1
a1414 1
    emergency_buffer_last_req = 0;
d1453 1
a1453 1
	    sbrk_goodness -= SBRK_FAILURE_PRICE;
a1473 1
	static int were_called = 0;
a1476 34
#ifndef NO_PERL_MALLOC_ENV
	if (!were_called) {
	    /* It's the our first time.  Initialize ourselves */
	    were_called = 1;	/* Avoid a loop */
	    if (!MallocCfg[MallocCfg_skip_cfg_env]) {
		char *s = getenv("PERL_MALLOC_OPT"), *t = s, *off;
		const char *opts = PERL_MALLOC_OPT_CHARS;
		int changed = 0;

		while ( t && t[0] && t[1] == '='
			&& ((off = strchr(opts, *t))) ) {
		    IV val = 0;

		    t += 2;
		    while (*t <= '9' && *t >= '0')
			val = 10*val + *t++ - '0';
		    if (!*t || *t == ';') {
			if (MallocCfg[off - opts] != val)
			    changed = 1;
			MallocCfg[off - opts] = val;
			if (*t)
			    t++;
		    }
		}
		if (t && *t) {
		    write2("Unrecognized part of PERL_MALLOC_OPT: `");
		    write2(t);
		    write2("'\n");
		}
		if (changed)
		    MallocCfg[MallocCfg_cfg_env_read] = 1;
	    }
	}
#endif
a1520 1
	FILL_DEADBEEF((unsigned char*)ovp, needed);
d1526 1
a1526 1
  	siz = BUCKET_SIZE_NO_SURPLUS(bucket); /* No surplus if nblks > 1 */
a1546 1

a1579 4
#ifdef DEBUGGING
	if (PTR2UV(cp) & (MEM_ALIGNBYTES - 1))
	    croak("%s", "wrong alignment in free()");
#endif
d1632 5
a1636 5
	    if ((i = nbytes & (RMAGIC_SZ-1))) {
		i = RMAGIC_SZ - i;
		while (i--) {	/* nbytes - RMAGIC_SZ is end of alloced area */
		    ASSERT(((caddr_t)ovp + nbytes - RMAGIC_SZ)[i] == RMAGIC_C,
			   "chunk's tail overwrite");
d1639 2
a1640 6
	    /* Same at RMAGIC_SZ-aligned RMAGIC */
	    nbytes = (nbytes + (RMAGIC_SZ-1)) & ~(RMAGIC_SZ-1);
	    ASSERT(((u_int *)((caddr_t)ovp + nbytes))[-1] == RMAGIC,
		   "chunk's tail overwrite");	    
	    FILLCHECK_DEADBEEF((unsigned char*)((caddr_t)ovp + nbytes),
			       BUCKET_SIZE(OV_INDEX(ovp)) - nbytes);
a1641 2
	FILL_DEADBEEF((unsigned char*)(ovp+CHUNK_SHIFT),
		      BUCKET_SIZE_REAL(OV_INDEX(ovp)) + RMAGIC_SZ);
d1711 3
a1713 3
		warn2("%srealloc() %signored",
		      (ovp->ov_rmagic == RMAGIC - 1 ? "" : "Bad "),
		      ovp->ov_rmagic == RMAGIC - 1 ? "of freed memory " : "");
d1771 4
a1774 4
		       if ((i = nb & (RMAGIC_SZ-1))) {
			   i = RMAGIC_SZ - i;
			   while (i--) { /* nb - RMAGIC_SZ is end of alloced area */
			       ASSERT(((caddr_t)ovp + nb - RMAGIC_SZ)[i] == RMAGIC_C, "chunk's tail overwrite");
d1777 2
a1778 12
		       /* Same at RMAGIC_SZ-aligned RMAGIC */
		       nb = (nb + (RMAGIC_SZ-1)) & ~(RMAGIC_SZ-1);
		       ASSERT(((u_int *)((caddr_t)ovp + nb))[-1] == RMAGIC,
			      "chunk's tail overwrite");
		       FILLCHECK_DEADBEEF((unsigned char*)((caddr_t)ovp + nb),
					  BUCKET_SIZE(OV_INDEX(ovp)) - nb);
		       if (nbytes > ovp->ov_size + 1 - M_OVERHEAD)
			   FILL_FEEDADAD((unsigned char*)cp + ovp->ov_size + 1 - M_OVERHEAD,
				     nbytes - (ovp->ov_size + 1 - M_OVERHEAD));
		       else
			   FILL_DEADBEEF((unsigned char*)cp + nbytes,
					 nb - M_OVERHEAD + RMAGIC_SZ - nbytes);
d1787 4
a1790 4
			if ((i = nbytes & (RMAGIC_SZ-1))) {
			    i = RMAGIC_SZ - i;
			    while (i--)	/* nbytes - RMAGIC_SZ is end of alloced area */
				((caddr_t)ovp + nbytes - RMAGIC_SZ)[i]
d1793 2
a1794 3
			/* Same at RMAGIC_SZ-aligned RMAGIC */
			nbytes = (nbytes + (RMAGIC_SZ-1)) & ~(RMAGIC_SZ - 1);
			((u_int *)((caddr_t)ovp + nbytes))[-1] = RMAGIC;
d1911 1
a1911 1
	*((u_int *)((caddr_t)ovp + size + M_OVERHEAD - RMAGIC_SZ)) = RMAGIC;
d1957 1
a1957 1
	buf->sbrk_good = sbrk_goodness;
d1967 1
a1967 1
		buf->bucket_mem_size[i] = BUCKET_SIZE_NO_SURPLUS(i);
d1999 1
a1999 1
			  (IV)BUCKET_SIZE_NO_SURPLUS(MIN_BUCKET),
d2001 1
a2001 1
			  (IV)BUCKET_SIZE_NO_SURPLUS(buffer.topbucket));
@


1.1.1.7
log
@perl 5.8.6 from CPAN
@
text
@a8 6
/* This file contains Perl's own implementation of the malloc library.
 * It is used if Configure decides that, on your platform, Perl's
 * version is better than the OS's, or if you give Configure the
 * -Dusemymalloc command-line option.
 */

a359 1
#    define CopyD(s,d,n,t) memcpy((char*)(d),(char*)(s), (n) * sizeof(t))
d2314 2
a2315 1
    return CopyD(s, s1, (MEM_SIZE)(l+1), char);
@


1.1.1.8
log
@perl 5.8.8 import
@
text
@d274 13
a286 12
#if defined(DEBUGGING) && !defined(NO_RCHECK)
#  define RCHECK
#endif
#if defined(DEBUGGING) && !defined(NO_RCHECK) && !defined(NO_MFILL) && !defined(MALLOC_FILL)
#  define MALLOC_FILL
#endif
#if defined(DEBUGGING) && !defined(NO_RCHECK) && !defined(NO_FILL_CHECK) && !defined(MALLOC_FILL_CHECK)
#  define MALLOC_FILL_CHECK
#endif
#if defined(RCHECK) && defined(IGNORE_SMALL_BAD_FREE)
#  undef IGNORE_SMALL_BAD_FREE
#endif 
d412 1
a412 1
#     ifdef HASATTRIBUTE_UNUSED
d644 1
a644 1
static const u_short buck_size[MAX_BUCKET_BY_TABLE + 1] = 
d808 1
a808 1
static const u_short n_blks[LOG_OF_MIN_ARENA * BUCKETS_PER_POW2] =
d831 1
a831 1
static const u_short blk_shift[LOG_OF_MIN_ARENA * BUCKETS_PER_POW2] =
d879 1
a879 1
static const char bucket_of[] =
d1163 1
d1170 1
a1170 1
    pv = SvPV_nolen(sv);
d1178 2
a1179 3
    SvPV_set(sv, Nullch);
    SvCUR_set(sv, 0);
    SvLEN_set(sv, 0);
d1229 1
a1229 2
	&& (!emergency_buffer_last_req ||
	    (size < (MEM_SIZE)emergency_buffer_last_req))) {
d1236 1
a1236 1
    if ((MEM_SIZE)emergency_buffer_size >= rsize) {
d1339 1
a1339 1
    const long lfill = *(long*)fill;
d1380 1
a1380 1
    const long lfill = *(long*)fill;
d1518 1
a1518 1
			  "Unaligned \"next\" pointer in the free "
d1676 1
a1676 1
	if (!last_sbrk_top && require < (MEM_SIZE)FIRST_SBRK) 
d1678 1
a1678 1
	else if (require < (MEM_SIZE)MIN_SBRK) require = MIN_SBRK;
d1807 1
a1807 1
	;				/* Finish "else" */
d1901 1
a1901 1
		    write2("Unrecognized part of PERL_MALLOC_OPT: \"");
d1903 1
a1903 1
		    write2("\"\n");
d2357 1
a2357 1
    union overhead * const ovp = (union overhead *)
d2359 1
a2359 1
    const int bucket = OV_INDEX(ovp);
d2364 1
a2364 1
	const MEM_SIZE size = BUCKET_SIZE_REAL(bucket);
d2499 1
a2573 10

/*
 * Local variables:
 * c-indentation-style: bsd
 * c-basic-offset: 4
 * indent-tabs-mode: t
 * End:
 *
 * ex: set ts=8 sts=4 sw=4 noet:
 */
@


1.1.1.9
log
@import perl 5.10.0 from CPAN
@
text
@d1159 1
a1161 1
    GV **gvp = (GV**)hv_fetchs(PL_defstash, "^M", FALSE);
d1163 1
a1163 1
    if (!gvp) gvp = (GV**)hv_fetchs(PL_defstash, "\015", FALSE);
d1176 1
a1176 1
    SvPV_set(sv, NULL);
d1252 1
a1252 1
	    emergency_buffer = NULL;
d1279 1
a1279 1
    return NULL;
d1294 1
a1294 2
#define	ASSERT(p,diag)   if (!(p)) botch(diag,STRINGIFY(p),__FILE__,__LINE__);

a1297 1
    dVAR;
a1410 1
        dVAR;
a1667 1
    dVAR;
a1867 1
        dVAR;
d2000 1
a2000 1
Perl_mfree(Malloc_t where)
a2001 1
        dVAR;
d2004 1
a2004 1
	char *cp = (char*)where;
a2105 1
        dVAR;
d2144 1
a2144 1
		    return NULL;
d2172 1
a2172 1
		return NULL;			/* sanity */
d2321 1
a2321 1
    return (char *)CopyD(s, s1, (MEM_SIZE)(l+1), char);
d2344 1
a2344 1
      var = (char *)Perl_malloc(l + 1);
@


1.1.1.10
log
@import perl 5.10.1
@
text
@d6 1
a6 3
 * 'The Chamber of Records,' said Gimli.  'I guess that is where we now stand.'
 *
 *     [p.321 of _The Lord of the Rings_, II/v: "The Bridge of Khazad-Dûm"]
d382 3
d976 1
a976 1
static void	botch		(const char *diag, const char *s, const char *file, int line);
d1287 1
a1287 1
write2(const char *mess)
d1297 1
a1297 1
botch(const char *diag, const char *s, const char *file, int line)
a1299 1
    dTHX;
d1303 1
d1410 2
a1411 2
int
S_ajust_size_and_find_bucket(size_t *nbytes_p)
d1413 14
a1426 3
  	MEM_SIZE shiftr;
	int bucket;
	size_t nbytes = *nbytes_p;
a1460 22
	*nbytes_p = nbytes;
	return bucket;
}

Malloc_t
Perl_malloc(size_t nbytes)
{
        dVAR;
  	register union overhead *p;
  	register int bucket;

#if defined(DEBUGGING) || defined(RCHECK)
	MEM_SIZE size = nbytes;
#endif

	BARK_64K_LIMIT("Allocation",nbytes,nbytes);
#ifdef DEBUGGING
	if ((long)nbytes < 0)
	    croak("%s", "panic: malloc");
#endif

	bucket = S_ajust_size_and_find_bucket(&nbytes);
a2287 2
		if (pow * BUCKETS_PER_POW2 > (MEM_SIZE)max_bucket)
		    max_bucket = pow * BUCKETS_PER_POW2;
a2366 3

    PERL_ARGS_ASSERT_MALLOCED_SIZE;

a2378 7

MEM_SIZE
Perl_malloc_good_size(size_t wanted)
{
    return BUCKET_SIZE_REAL(S_ajust_size_and_find_bucket(&wanted));
}

a2392 2
	PERL_ARGS_ASSERT_GET_MSTATS;

a2432 2
#else /* defined DEBUGGING_MSTATS */
	PerlIO_printf(Perl_error_log, "perl not compiled with DEBUGGING_MSTATS\n");
a2451 2
	PERL_ARGS_ASSERT_DUMP_MSTATS;

a2503 2
#else /* DEBUGGING_MSTATS */
	PerlIO_printf(Perl_error_log, "%s: perl not compiled with DEBUGGING_MSTATS\n",s);
@


1.1.1.11
log
@Perl 5.12.2 from CPAN
@
text
@d267 1
a267 1
#if !(defined(I286) || defined(atarist))
d555 1
a555 1
#if (defined(RCHECK) || defined(I286) || defined(atarist)) && defined(PACK_MALLOC)
d1737 1
a1737 1
#if !defined(atarist) /* on the atari we dont have to worry about this */
d1746 1
a1746 1
#endif /* !atarist */
d2059 4
a2062 4
		    if (!PERL_IS_ALIVE || !PL_curcop)
			Perl_ck_warner_d(aTHX_ packWARN(WARN_MALLOC), "%s free() ignored (RMAGIC, PERL_CORE)",
					 ovp->ov_rmagic == RMAGIC - 1 ?
					 "Duplicate" : "Bad");
d2072 2
a2073 2
		    if (!PERL_IS_ALIVE || !PL_curcop)
			Perl_ck_warner_d(aTHX_ packWARN(WARN_MALLOC), "%s", "Bad free() ignored (PERL_CORE)");
d2166 5
a2170 5
		    if (!PERL_IS_ALIVE || !PL_curcop)
			Perl_ck_warner_d(aTHX_ packWARN(WARN_MALLOC), "%srealloc() %signored",
					 (ovp->ov_rmagic == RMAGIC - 1 ? "" : "Bad "),
					 ovp->ov_rmagic == RMAGIC - 1
					 ? "of freed memory " : "");
d2181 3
a2183 3
		    if (!PERL_IS_ALIVE || !PL_curcop)
			Perl_ck_warner_d(aTHX_ packWARN(WARN_MALLOC), "%s",
					 "Bad realloc() ignored");
d2470 1
a2470 1
Perl_dump_mstats(pTHX_ const char *s)
d2539 1
a2539 1
#   if defined(NeXT) || defined(__NeXT__) || defined(PURIFY)
@


1.1.1.12
log
@import perl 5.16.3 from CPAN - worked on by Andrew Fresh and myself
@
text
@d8 1
a8 1
 *     [p.321 of _The Lord of the Rings_, II/v: "The Bridge of Khazad-DÃ»m"]
d18 3
a20 2
  Here are some notes on configuring Perl's malloc.

d43 1
a43 1
    PERL_EMERGENCY_SBRK		!PLAIN_MALLOC
d46 1
a46 1
    DEBUGGING_MSTATS		!PLAIN_MALLOC
d166 66
d256 1
a256 1
#  ifndef PERL_EMERGENCY_SBRK
d259 1
a259 1
#  ifndef DEBUGGING_MSTATS
d306 1
a306 1
 * buckets.  Sizes of really big buckets are increased to accommodate
d312 5
a316 4
#include "EXTERN.h"
#define PERL_IN_MALLOC_C
#include "perl.h"
#if defined(PERL_IMPLICIT_CONTEXT)
d321 1
a321 1
#else
d324 2
a325 2
#endif
#ifdef USE_ITHREADS
d327 3
d331 106
a436 2
#     define PERL_MAYBE_ALIVE	1
#endif
d692 1
a692 1
 * (to make size of big CHUNK accommodate allocations for powers of two
d941 1
a941 1
#ifdef HAS_64K_LIMIT
d948 1
a948 1
#else /* !HAS_64K_LIMIT */
d950 1
a950 1
#endif /* !HAS_64K_LIMIT */
d983 2
d992 2
d1151 1
d1181 4
a1184 1
#  define PERL_GET_EMERGENCY_BUFFER(p)	perl_get_emergency_buffer(p)
d1480 1
d1513 1
d1810 1
a1810 1
				  "fixing sbrk(): %d bytes off machine alignment\n",
d2056 1
d2065 5
d2075 3
d2132 1
a2132 1
#ifdef DEBUGGING
d2163 1
d2173 6
d2185 3
d2195 1
a2195 1
	 *  We are not aggressive with boundary cases. Note that it might
d2343 1
d2371 1
d2572 1
d2574 1
@


1.1.1.13
log
@Import perl-5.18.2

OK espie@@ sthen@@ deraadt@@
@
text
@d200 8
a207 1
#define LOG_OF_MIN_ARENA 11
d379 2
a380 1
#if defined(RCHECK) && defined(PACK_MALLOC)
d458 1
a458 1
#  define ALIGN_SMALL ((IV)((caddr_t)&(((struct aligner*)0)->p)))
d798 1
a798 1
static void	morecore	(int bucket);
d1094 1
a1094 1
    assert(0); /* NOTREACHED */
d1102 5
a1106 2
/* Don't use PerlIO buffered writes as they allocate memory. */
#define MYMALLOC_WRITE2STDERR(s) PerlLIO_write(PerlIO_fileno(PerlIO_stderr()),s,strlen(s))
d1124 7
a1130 7
	    MYMALLOC_WRITE2STDERR("assertion botched (");
	    MYMALLOC_WRITE2STDERR(diag);
	    MYMALLOC_WRITE2STDERR("?): ");
	    MYMALLOC_WRITE2STDERR(s);
	    MYMALLOC_WRITE2STDERR(" (");
	    MYMALLOC_WRITE2STDERR(file);
	    MYMALLOC_WRITE2STDERR(":");
d1139 1
a1139 1
	      MYMALLOC_WRITE2STDERR(s);
d1141 1
a1141 1
	    MYMALLOC_WRITE2STDERR(")\n");
d1274 2
a1275 2
  	union overhead *p;
  	int bucket;
d1301 1
a1301 1
		        MYMALLOC_WRITE2STDERR("Out of memory!\n");
d1308 1
a1308 1
			MYMALLOC_WRITE2STDERR("Out of memory during request for ");
d1316 2
a1317 2
			MYMALLOC_WRITE2STDERR(s);
			MYMALLOC_WRITE2STDERR(" bytes, total sbrk() is ");
d1323 2
a1324 2
			MYMALLOC_WRITE2STDERR(s);
			MYMALLOC_WRITE2STDERR(" bytes!\n");
d1509 1
a1509 1
	if (require < (Size_t)(goodsbrk * MIN_SBRK_FRAC1000 / 1000))
d1552 2
d1560 2
d1622 1
d1635 1
d1695 1
a1695 1
morecore(int bucket)
d1698 2
a1699 2
  	union overhead *ovp;
  	int rnu;       /* 2^rnu bytes will be requested */
d1701 1
a1701 1
	MEM_SIZE siz, needed;
d1731 3
a1733 4
		    dTHX;
		    MYMALLOC_WRITE2STDERR("Unrecognized part of PERL_MALLOC_OPT: \"");
		    MYMALLOC_WRITE2STDERR(t);
		    MYMALLOC_WRITE2STDERR("\"\n");
d1833 2
a1834 2
  	MEM_SIZE size;
	union overhead *ovp;
d1929 1
a1929 1
  	MEM_SIZE onb;
d1933 1
a1933 1
	int bucket;
d2119 1
a2119 1
Perl_calloc(size_t elements, size_t size)
d2205 2
a2206 2
  	int i, j;
  	union overhead *p;
d2267 1
a2267 1
  	int i;
d2407 1
a2407 1
 * indent-tabs-mode: nil
d2410 1
a2410 1
 * ex: set ts=8 sts=4 sw=4 et:
@


1.1.1.14
log
@Import perl-5.20.1
@
text
@d758 10
a767 1
#define BARK_64K_LIMIT(what,nbytes,size)
d1215 2
a1216 2
STATIC int
S_adjust_size_and_find_bucket(size_t *nbytes_p)
d1218 1
a1218 1
	MEM_SIZE shiftr;
d1220 1
a1220 5
	size_t nbytes;

	PERL_ARGS_ASSERT_ADJUST_SIZE_AND_FIND_BUCKET;

	nbytes = *nbytes_p;
d1276 1
a1276 1
	bucket = adjust_size_and_find_bucket(&nbytes);
d2176 1
a2176 1
    return BUCKET_SIZE_REAL(adjust_size_and_find_bucket(&wanted));
@


1.1.1.15
log
@Import perl-5.24.2
@
text
@a255 4
#ifndef MYMALLOC
#  error "MYMALLOC is not defined"
#endif

d998 13
d1014 5
d1077 1
a1077 1
    NOT_REACHED; /* NOTREACHED */
d1086 1
a1086 1
#define MYMALLOC_WRITE2STDERR(s) PERL_UNUSED_RESULT(PerlLIO_write(PerlIO_fileno(PerlIO_stderr()),s,strlen(s)))
d1545 1
a1545 1
				  "sbrk(%ld) to fix non-continuous/off-page sbrk:\n\t%ld for alignment,\t%ld were assumed to come from the tail of the previous sbrk\n",
d1845 1
a1845 1
		    bad_free_warn = (pbf) ? strNE("0", pbf) : 1;
d1943 1
a1943 1
		    bad_free_warn = (pbf) ? strNE("0", pbf) : 1;
d2312 1
a2312 1
#   if defined(PURIFY)
d2383 6
@


