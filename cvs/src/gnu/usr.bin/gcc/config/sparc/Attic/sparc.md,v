head	1.3;
access;
symbols
	OPENBSD_2_5:1.2.0.6
	OPENBSD_2_5_BASE:1.2
	OPENBSD_2_4:1.2.0.4
	OPENBSD_2_4_BASE:1.2
	OPENBSD_2_3:1.2.0.2
	OPENBSD_2_3_BASE:1.2
	FSF_2_8_1:1.1.1.2
	FSF_2_8_0:1.1.1.2
	OPENBSD_2_2:1.1.1.1.0.6
	OPENBSD_2_2_BASE:1.1.1.1
	OPENBSD_2_1:1.1.1.1.0.4
	OPENBSD_2_1_BASE:1.1.1.1
	OPENBSD_2_0:1.1.1.1.0.2
	OPENBSD_2_0_BASE:1.1.1.1
	FSF_2_7_2:1.1.1.1
	FSF:1.1.1;
locks; strict;
comment	@# @;


1.3
date	99.05.26.16.27.28;	author espie;	state dead;
branches;
next	1.2;

1.2
date	98.03.03.21.33.02;	author niklas;	state Exp;
branches;
next	1.1;

1.1
date	95.12.20.01.05.44;	author niklas;	state Exp;
branches
	1.1.1.1;
next	;

1.1.1.1
date	95.12.20.01.05.44;	author niklas;	state Exp;
branches;
next	1.1.1.2;

1.1.1.2
date	98.02.14.19.23.34;	author niklas;	state Exp;
branches;
next	;


desc
@@


1.3
log
@So long, and thanks for all the bugs.
@
text
@;;- Machine description for SPARC chip for GNU C compiler
;;  Copyright (C) 1987, 88, 89, 92-96, 1997 Free Software Foundation, Inc.
;;  Contributed by Michael Tiemann (tiemann@@cygnus.com)
;;  64 bit SPARC V9 support by Michael Tiemann, Jim Wilson, and Doug Evans,
;;  at Cygnus Support.

;; This file is part of GNU CC.

;; GNU CC is free software; you can redistribute it and/or modify
;; it under the terms of the GNU General Public License as published by
;; the Free Software Foundation; either version 2, or (at your option)
;; any later version.

;; GNU CC is distributed in the hope that it will be useful,
;; but WITHOUT ANY WARRANTY; without even the implied warranty of
;; MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
;; GNU General Public License for more details.

;; You should have received a copy of the GNU General Public License
;; along with GNU CC; see the file COPYING.  If not, write to
;; the Free Software Foundation, 59 Temple Place - Suite 330,
;; Boston, MA 02111-1307, USA.

;;- See file "rtl.def" for documentation on define_insn, match_*, et. al.

;; The upper 32 fp regs on the v9 can't hold SFmode values.  To deal with this
;; a second register class, EXTRA_FP_REGS, exists for the v9 chip.  The name
;; is a bit of a misnomer as it covers all 64 fp regs.  The corresponding
;; constraint letter is 'e'.  To avoid any confusion, 'e' is used instead of
;; 'f' for all DF/TFmode values, including those that are specific to the v8.
;;
;; -mlive-g0 is *not* supported for TARGET_ARCH64, so we don't bother to
;; test TARGET_LIVE_G0 if we have TARGET_ARCH64.

;; Attribute for cpu type.
;; These must match the values for enum processor_type in sparc.h.
(define_attr "cpu" "v7,cypress,v8,supersparc,sparclite,f930,f934,sparclet,tsc701,v8plus,v9,ultrasparc"
  (const (symbol_ref "sparc_cpu_attr")))

;; Attribute for the instruction set.
;; At present we only need to distinguish v9/!v9, but for clarity we
;; test TARGET_V8 too.
(define_attr "isa" "v6,v8,v9,sparclet"
 (const
  (cond [(symbol_ref "TARGET_V9") (const_string "v9")
	 (symbol_ref "TARGET_V8") (const_string "v8")
	 (symbol_ref "TARGET_SPARCLET") (const_string "sparclet")]
	(const_string "v6"))))

;; Architecture size.
(define_attr "arch" "arch32bit,arch64bit"
 (const
  (cond [(symbol_ref "TARGET_ARCH64") (const_string "arch64bit")]
	(const_string "arch32bit"))))

;; Whether -mlive-g0 is in effect.
(define_attr "live_g0" "no,yes"
 (const
  (cond [(symbol_ref "TARGET_LIVE_G0") (const_string "yes")]
	(const_string "no"))))

;; Insn type.  Used to default other attribute values.

;; type "unary" insns have one input operand (1) and one output operand (0)
;; type "binary" insns have two input operands (1,2) and one output (0)
;; type "compare" insns have one or two input operands (0,1) and no output
;; type "call_no_delay_slot" is a call followed by an unimp instruction.

(define_attr "type"
  "move,unary,binary,compare,load,store,ialu,shift,uncond_branch,branch,call,call_no_delay_slot,address,imul,fpload,fpstore,fp,fpcmp,fpmul,fpdivs,fpdivd,fpsqrt,cmove,multi,misc"
  (const_string "binary"))

;; Set true if insn uses call-clobbered intermediate register.
(define_attr "use_clobbered" "false,true"
  (if_then_else (and (eq_attr "type" "address")
		     (match_operand 0 "clobbered_register" ""))
	 	(const_string "true")
		(const_string "false")))

;; Length (in # of insns).
(define_attr "length" ""
  (cond [(eq_attr "type" "load,fpload")
	 (if_then_else (match_operand 1 "symbolic_memory_operand" "")
		       (const_int 2) (const_int 1))

	 (eq_attr "type" "store,fpstore")
	 (if_then_else (match_operand 0 "symbolic_memory_operand" "")
		       (const_int 2) (const_int 1))

	 (eq_attr "type" "address") (const_int 2)

	 (eq_attr "type" "binary")
	 (if_then_else (ior (match_operand 2 "arith_operand" "")
			    (match_operand 2 "arith_double_operand" ""))
		       (const_int 1) (const_int 3))

	 (eq_attr "type" "multi") (const_int 2)

	 (eq_attr "type" "move,unary")
	 (if_then_else (ior (match_operand 1 "arith_operand" "")
			    (match_operand 1 "arith_double_operand" ""))
		       (const_int 1) (const_int 2))]

	(const_int 1)))

(define_asm_attributes
  [(set_attr "length" "1")
   (set_attr "type" "multi")])

;; Attributes for instruction and branch scheduling

(define_attr "in_call_delay" "false,true"
  (cond [(eq_attr "type" "uncond_branch,branch,call,call_no_delay_slot,multi")
	 	(const_string "false")
	 (eq_attr "type" "load,fpload,store,fpstore")
	 	(if_then_else (eq_attr "length" "1")
			      (const_string "true")
			      (const_string "false"))
	 (eq_attr "type" "address")
	 	(if_then_else (eq_attr "use_clobbered" "false")
			      (const_string "true")
			      (const_string "false"))]
	(if_then_else (eq_attr "length" "1")
		      (const_string "true")
		      (const_string "false"))))

(define_delay (eq_attr "type" "call")
  [(eq_attr "in_call_delay" "true") (nil) (nil)])

;; ??? Should implement the notion of predelay slots for floating point
;; branches.  This would allow us to remove the nop always inserted before
;; a floating point branch.

;; ??? It is OK for fill_simple_delay_slots to put load/store instructions
;; in a delay slot, but it is not OK for fill_eager_delay_slots to do so.
;; This is because doing so will add several pipeline stalls to the path
;; that the load/store did not come from.  Unfortunately, there is no way
;; to prevent fill_eager_delay_slots from using load/store without completely
;; disabling them.  For the SPEC benchmark set, this is a serious lose,
;; because it prevents us from moving back the final store of inner loops.

(define_attr "in_branch_delay" "false,true"
  (if_then_else (and (eq_attr "type" "!uncond_branch,branch,call,call_no_delay_slot,multi")
		     (eq_attr "length" "1"))
		(const_string "true")
		(const_string "false")))

(define_attr "in_uncond_branch_delay" "false,true"
  (if_then_else (and (eq_attr "type" "!uncond_branch,branch,call,call_no_delay_slot,multi")
		     (eq_attr "length" "1"))
		(const_string "true")
		(const_string "false")))

(define_attr "in_annul_branch_delay" "false,true"
  (if_then_else (and (eq_attr "type" "!uncond_branch,branch,call,call_no_delay_slot,multi")
		     (eq_attr "length" "1"))
		(const_string "true")
		(const_string "false")))

(define_delay (eq_attr "type" "branch")
  [(eq_attr "in_branch_delay" "true")
   (nil) (eq_attr "in_annul_branch_delay" "true")])

(define_delay (eq_attr "type" "uncond_branch")
  [(eq_attr "in_uncond_branch_delay" "true")
   (nil) (nil)])
   
;; Function units of the SPARC

;; (define_function_unit {name} {num-units} {n-users} {test}
;;                       {ready-delay} {issue-delay} [{conflict-list}])

;; The integer ALU.
;; (Noted only for documentation; units that take one cycle do not need to
;; be specified.)

;; On the sparclite, integer multiply takes 1, 3, or 5 cycles depending on
;; the inputs.

;; (define_function_unit "alu" 1 0
;;  (eq_attr "type" "unary,binary,move,address") 1 0)

;; ---- cypress CY7C602 scheduling:
;; Memory with load-delay of 1 (i.e., 2 cycle load).
(define_function_unit "memory" 1 0 
  (and (eq_attr "type" "load,fpload") (eq_attr "cpu" "cypress")) 2 2)

;; SPARC has two floating-point units: the FP ALU,
;; and the FP MUL/DIV/SQRT unit.
;; Instruction timings on the CY7C602 are as follows
;; FABSs	4
;; FADDs/d	5/5
;; FCMPs/d	4/4
;; FDIVs/d	23/37
;; FMOVs	4
;; FMULs/d	5/7
;; FNEGs	4
;; FSQRTs/d	34/63
;; FSUBs/d	5/5
;; FdTOi/s	5/5
;; FsTOi/d	5/5
;; FiTOs/d	9/5

;; The CY7C602 can only support 2 fp isnsn simultaneously.
;; More insns cause the chip to stall.

(define_function_unit "fp_alu" 1 0
  (and (eq_attr "type" "fp")            (eq_attr "cpu" "cypress")) 5 5)
(define_function_unit "fp_mds" 1 0
  (and (eq_attr "type" "fpmul")         (eq_attr "cpu" "cypress")) 7 7)
(define_function_unit "fp_mds" 1 0
  (and (eq_attr "type" "fpdivs,fpdivd") (eq_attr "cpu" "cypress")) 37 37)
(define_function_unit "fp_mds" 1 0
  (and (eq_attr "type" "fpsqrt")        (eq_attr "cpu" "cypress")) 63 63)

;; ----- The TMS390Z55 scheduling
;; The Supersparc can issue 1 - 3 insns per cycle; here we assume
;; three insns/cycle, and hence multiply all costs by three.
;; Combinations up to two integer, one ld/st, one fp.
;; Memory delivers its result in one cycle to IU, zero cycles to FP
(define_function_unit "memory" 1 0
  (and (eq_attr "type" "load")          (eq_attr "cpu" "supersparc")) 3 3)
(define_function_unit "memory" 1 0
  (and (eq_attr "type" "fpload")        (eq_attr "cpu" "supersparc")) 1 3)
;; at least one in three instructions can be a mem opt.
(define_function_unit "memory" 1 0
  (and (eq_attr "type" "store,fpstore") (eq_attr "cpu" "supersparc")) 1 3)
;; at least one in three instructions can be a shift op.
(define_function_unit "shift" 1 0
  (and (eq_attr "type" "shift")         (eq_attr "cpu" "supersparc")) 1 3)

;; There are only two write ports to the integer register file
;; A store also uses a write port
(define_function_unit "iwport" 2 0
  (and (eq_attr "type" "load,store,shift,ialu") (eq_attr "cpu" "supersparc")) 1 3)

;; Timings; throughput/latency
;; FADD     1/3    add/sub, format conv, compar, abs, neg
;; FMUL     1/3
;; FDIVs    4/6
;; FDIVd    7/9
;; FSQRTs   6/8
;; FSQRTd  10/12
;; IMUL     4/4

(define_function_unit "fp_alu" 1 0
  (and (eq_attr "type" "fp,fpcmp") (eq_attr "cpu" "supersparc")) 9 3)
(define_function_unit "fp_mds" 1 0
  (and (eq_attr "type" "fpmul")    (eq_attr "cpu" "supersparc")) 9 3)
(define_function_unit "fp_mds" 1 0
  (and (eq_attr "type" "fpdivs")   (eq_attr "cpu" "supersparc")) 18 12)
(define_function_unit "fp_mds" 1 0
  (and (eq_attr "type" "fpdivd")   (eq_attr "cpu" "supersparc")) 27 21)
(define_function_unit "fp_mds" 1 0
  (and (eq_attr "type" "fpsqrt")   (eq_attr "cpu" "supersparc")) 36 30)
(define_function_unit "fp_mds" 1 0
  (and (eq_attr "type" "imul")     (eq_attr "cpu" "supersparc")) 12 12)

;; ----- sparclet tsc701 scheduling
;; The tsc701 issues 1 insn per cycle.
;; Results may be written back out of order.

;; Loads take 2 extra cycles to complete and 4 can be buffered at a time.
(define_function_unit "tsc701_load" 4 1
  (and (eq_attr "type" "load")          (eq_attr "cpu" "tsc701")) 3 1)
;; Stores take 2(?) extra cycles to complete.
;; It is desirable to not have any memory operation in the following 2 cycles.
;; (??? or 2 memory ops in the case of std).
(define_function_unit "tsc701_store" 1 0
  (and (eq_attr "type" "store")		(eq_attr "cpu" "tsc701")) 3 3
  [(eq_attr "type" "load,store")])
;; The multiply unit has a latency of 5.
(define_function_unit "tsc701_mul" 1 0
  (and (eq_attr "type" "imul")		(eq_attr "cpu" "tsc701")) 5 5)

;; ----- The UltraSPARC-1 scheduling
;; The Ultrasparc can issue 1 - 4 insns per cycle; here we assume
;; four insns/cycle, and hence multiply all costs by four.

;; Memory delivers its result in three cycles to IU, three cycles to FP
(define_function_unit "memory" 1 0
  (and (eq_attr "type" "load,fpload")   (eq_attr "cpu" "ultrasparc")) 12 4)
(define_function_unit "memory" 1 0
  (and (eq_attr "type" "store,fpstore") (eq_attr "cpu" "ultrasparc"))  4 4)
(define_function_unit "ieu" 1 0
  (and (eq_attr "type" "ialu")          (eq_attr "cpu" "ultrasparc"))  1 2)
(define_function_unit "ieu" 1 0
  (and (eq_attr "type" "shift")         (eq_attr "cpu" "ultrasparc"))  1 4)
(define_function_unit "ieu" 1 0
  (and (eq_attr "type" "cmove")         (eq_attr "cpu" "ultrasparc"))  8 4)

;; Timings; throughput/latency
;; ?? FADD     1/3    add/sub, format conv, compar, abs, neg
;; ?? FMUL     1/3
;; ?? FDIVs    1/12
;; ?? FDIVd    1/22
;; ?? FSQRTs   1/12
;; ?? FSQRTd   1/22

(define_function_unit "fp" 1 0
  (and (eq_attr "type" "fp")       (eq_attr "cpu" "ultrasparc")) 12 2)
(define_function_unit "fp" 1 0
  (and (eq_attr "type" "fpcmp")    (eq_attr "cpu" "ultrasparc"))  8 2)
(define_function_unit "fp" 1 0
  (and (eq_attr "type" "fpmul")    (eq_attr "cpu" "ultrasparc")) 12 2)
(define_function_unit "fp" 1 0
  (and (eq_attr "type" "fpdivs")   (eq_attr "cpu" "ultrasparc")) 48 2)
(define_function_unit "fp" 1 0
  (and (eq_attr "type" "fpdivd")   (eq_attr "cpu" "ultrasparc")) 88 2)
(define_function_unit "fp" 1 0
  (and (eq_attr "type" "fpsqrt")   (eq_attr "cpu" "ultrasparc")) 48 2)

;; Compare instructions.
;; This controls RTL generation and register allocation.

;; We generate RTL for comparisons and branches by having the cmpxx 
;; patterns store away the operands.  Then, the scc and bcc patterns
;; emit RTL for both the compare and the branch.
;;
;; We do this because we want to generate different code for an sne and
;; seq insn.  In those cases, if the second operand of the compare is not
;; const0_rtx, we want to compute the xor of the two operands and test
;; it against zero.
;;
;; We start with the DEFINE_EXPANDs, then the DEFINE_INSNs to match
;; the patterns.  Finally, we have the DEFINE_SPLITs for some of the scc
;; insns that actually require more than one machine instruction.

;; Put cmpsi first among compare insns so it matches two CONST_INT operands.

(define_expand "cmpsi"
  [(set (reg:CC 100)
	(compare:CC (match_operand:SI 0 "register_operand" "")
		    (match_operand:SI 1 "arith_operand" "")))]
  ""
  "
{
  sparc_compare_op0 = operands[0];
  sparc_compare_op1 = operands[1];
  DONE;
}")

(define_expand "cmpdi"
  [(set (reg:CCX 100)
	(compare:CCX (match_operand:DI 0 "register_operand" "")
		     (match_operand:DI 1 "arith_double_operand" "")))]
  "TARGET_ARCH64"
  "
{
  sparc_compare_op0 = operands[0];
  sparc_compare_op1 = operands[1];
  DONE;
}")

(define_expand "cmpsf"
  ;; The 96 here isn't ever used by anyone.
  [(set (reg:CCFP 96)
	(compare:CCFP (match_operand:SF 0 "register_operand" "")
		      (match_operand:SF 1 "register_operand" "")))]
  "TARGET_FPU"
  "
{
  sparc_compare_op0 = operands[0];
  sparc_compare_op1 = operands[1];
  DONE;
}")

(define_expand "cmpdf"
  ;; The 96 here isn't ever used by anyone.
  [(set (reg:CCFP 96)
	(compare:CCFP (match_operand:DF 0 "register_operand" "")
		      (match_operand:DF 1 "register_operand" "")))]
  "TARGET_FPU"
  "
{
  sparc_compare_op0 = operands[0];
  sparc_compare_op1 = operands[1];
  DONE;
}")

(define_expand "cmptf"
  ;; The 96 here isn't ever used by anyone.
  [(set (reg:CCFP 96)
	(compare:CCFP (match_operand:TF 0 "register_operand" "")
		      (match_operand:TF 1 "register_operand" "")))]
  "TARGET_FPU"
  "
{
  sparc_compare_op0 = operands[0];
  sparc_compare_op1 = operands[1];
  DONE;
}")

;; Now the compare DEFINE_INSNs.

(define_insn "*cmpsi_insn"
  [(set (reg:CC 100)
	(compare:CC (match_operand:SI 0 "register_operand" "r")
		    (match_operand:SI 1 "arith_operand" "rI")))]
  ""
  "cmp %0,%1"
  [(set_attr "type" "compare")])

(define_insn "*cmpdi_sp64"
  [(set (reg:CCX 100)
	(compare:CCX (match_operand:DI 0 "register_operand" "r")
		     (match_operand:DI 1 "arith_double_operand" "rHI")))]
  "TARGET_ARCH64"
  "cmp %0,%1"
  [(set_attr "type" "compare")])

(define_insn "*cmpsf_fpe"
  [(set (match_operand:CCFPE 0 "fcc_reg_operand" "=c")
	(compare:CCFPE (match_operand:SF 1 "register_operand" "f")
		       (match_operand:SF 2 "register_operand" "f")))]
  "TARGET_FPU"
  "*
{
  if (TARGET_V9)
    return \"fcmpes %0,%1,%2\";
  return \"fcmpes %1,%2\";
}"
  [(set_attr "type" "fpcmp")])

(define_insn "*cmpdf_fpe"
  [(set (match_operand:CCFPE 0 "fcc_reg_operand" "=c")
	(compare:CCFPE (match_operand:DF 1 "register_operand" "e")
		       (match_operand:DF 2 "register_operand" "e")))]
  "TARGET_FPU"
  "*
{
  if (TARGET_V9)
    return \"fcmped %0,%1,%2\";
  return \"fcmped %1,%2\";
}"
  [(set_attr "type" "fpcmp")])

(define_insn "*cmptf_fpe"
  [(set (match_operand:CCFPE 0 "fcc_reg_operand" "=c")
	(compare:CCFPE (match_operand:TF 1 "register_operand" "e")
		       (match_operand:TF 2 "register_operand" "e")))]
  "TARGET_FPU && TARGET_HARD_QUAD"
  "*
{
  if (TARGET_V9)
    return \"fcmpeq %0,%1,%2\";
  return \"fcmpeq %1,%2\";
}"
  [(set_attr "type" "fpcmp")])

(define_insn "*cmpsf_fp"
  [(set (match_operand:CCFP 0 "fcc_reg_operand" "=c")
	(compare:CCFP (match_operand:SF 1 "register_operand" "f")
		      (match_operand:SF 2 "register_operand" "f")))]
  "TARGET_FPU"
  "*
{
  if (TARGET_V9)
    return \"fcmps %0,%1,%2\";
  return \"fcmps %1,%2\";
}"
  [(set_attr "type" "fpcmp")])

(define_insn "*cmpdf_fp"
  [(set (match_operand:CCFP 0 "fcc_reg_operand" "=c")
	(compare:CCFP (match_operand:DF 1 "register_operand" "e")
		      (match_operand:DF 2 "register_operand" "e")))]
  "TARGET_FPU"
  "*
{
  if (TARGET_V9)
    return \"fcmpd %0,%1,%2\";
  return \"fcmpd %1,%2\";
}"
  [(set_attr "type" "fpcmp")])

(define_insn "*cmptf_fp"
  [(set (match_operand:CCFP 0 "fcc_reg_operand" "=c")
	(compare:CCFP (match_operand:TF 1 "register_operand" "e")
		      (match_operand:TF 2 "register_operand" "e")))]
  "TARGET_FPU && TARGET_HARD_QUAD"
  "*
{
  if (TARGET_V9)
    return \"fcmpq %0,%1,%2\";
  return \"fcmpq %1,%2\";
}"
  [(set_attr "type" "fpcmp")])

;; Next come the scc insns.  For seq, sne, sgeu, and sltu, we can do this
;; without jumps using the addx/subx instructions.  For seq/sne on v9 we use
;; the same code as v8 (the addx/subx method has more applications).  The
;; exception to this is "reg != 0" which can be done in one instruction on v9
;; (so we do it).  For the rest, on v9 we use conditional moves; on v8, we do
;; branches.

;; Seq_special[_xxx] and sne_special[_xxx] clobber the CC reg, because they
;; generate addcc/subcc instructions.

(define_expand "seqsi_special"
  [(set (match_dup 3)
	(xor:SI (match_operand:SI 1 "register_operand" "")
		(match_operand:SI 2 "register_operand" "")))
   (parallel [(set (match_operand:SI 0 "register_operand" "")
		   (eq:SI (match_dup 3) (const_int 0)))
	      (clobber (reg:CC 100))])]
  "! TARGET_LIVE_G0"
  "{ operands[3] = gen_reg_rtx (SImode); }")

(define_expand "seqdi_special"
  [(set (match_dup 3)
	(xor:DI (match_operand:DI 1 "register_operand" "")
		(match_operand:DI 2 "register_operand" "")))
   (set (match_operand:DI 0 "register_operand" "")
	(eq:DI (match_dup 3) (const_int 0)))]
  "TARGET_ARCH64"
  "{ operands[3] = gen_reg_rtx (DImode); }")

(define_expand "snesi_special"
  [(set (match_dup 3)
	(xor:SI (match_operand:SI 1 "register_operand" "")
		(match_operand:SI 2 "register_operand" "")))
   (parallel [(set (match_operand:SI 0 "register_operand" "")
		   (ne:SI (match_dup 3) (const_int 0)))
	      (clobber (reg:CC 100))])]
  "! TARGET_LIVE_G0"
  "{ operands[3] = gen_reg_rtx (SImode); }")

(define_expand "snedi_special"
  [(set (match_dup 3)
	(xor:DI (match_operand:DI 1 "register_operand" "")
		(match_operand:DI 2 "register_operand" "")))
   (set (match_operand:DI 0 "register_operand" "")
	(ne:DI (match_dup 3) (const_int 0)))]
  "TARGET_ARCH64"
  "{ operands[3] = gen_reg_rtx (DImode); }")

(define_expand "seqdi_special_trunc"
  [(set (match_dup 3)
	(xor:DI (match_operand:DI 1 "register_operand" "")
		(match_operand:DI 2 "register_operand" "")))
   (set (match_operand:SI 0 "register_operand" "")
	(eq:DI (match_dup 3) (const_int 0)))]
  "TARGET_ARCH64"
  "{ operands[3] = gen_reg_rtx (DImode); }")

(define_expand "snedi_special_trunc"
  [(set (match_dup 3)
	(xor:DI (match_operand:DI 1 "register_operand" "")
		(match_operand:DI 2 "register_operand" "")))
   (set (match_operand:SI 0 "register_operand" "")
	(ne:DI (match_dup 3) (const_int 0)))]
  "TARGET_ARCH64"
  "{ operands[3] = gen_reg_rtx (DImode); }")

(define_expand "seqsi_special_extend"
  [(set (match_dup 3)
	(xor:SI (match_operand:SI 1 "register_operand" "")
		(match_operand:SI 2 "register_operand" "")))
   (parallel [(set (match_operand:DI 0 "register_operand" "")
		   (eq:SI (match_dup 3) (const_int 0)))
	      (clobber (reg:CC 100))])]
  "TARGET_ARCH64"
  "{ operands[3] = gen_reg_rtx (SImode); }")

(define_expand "snesi_special_extend"
  [(set (match_dup 3)
	(xor:SI (match_operand:SI 1 "register_operand" "")
		(match_operand:SI 2 "register_operand" "")))
   (parallel [(set (match_operand:DI 0 "register_operand" "")
		   (ne:SI (match_dup 3) (const_int 0)))
	      (clobber (reg:CC 100))])]
  "TARGET_ARCH64"
  "{ operands[3] = gen_reg_rtx (SImode); }")

;; ??? v9: Operand 0 needs a mode, so SImode was chosen.
;; However, the code handles both SImode and DImode.
(define_expand "seq"
  [(set (match_operand:SI 0 "intreg_operand" "")
	(eq:SI (match_dup 1) (const_int 0)))]
  "! TARGET_LIVE_G0"
  "
{
  if (GET_MODE (sparc_compare_op0) == SImode)
    {
      rtx pat;

      if (GET_MODE (operands[0]) == SImode)
	pat = gen_seqsi_special (operands[0], sparc_compare_op0,
				 sparc_compare_op1);
      else if (! TARGET_ARCH64)
	FAIL;
      else
	pat = gen_seqsi_special_extend (operands[0], sparc_compare_op0,
					sparc_compare_op1);
      emit_insn (pat);
      DONE;
    }
  else if (GET_MODE (sparc_compare_op0) == DImode)
    {
      rtx pat;

      if (! TARGET_ARCH64)
	FAIL;
      else if (GET_MODE (operands[0]) == SImode)
	pat = gen_seqdi_special_trunc (operands[0], sparc_compare_op0,
				       sparc_compare_op1);
      else
	pat = gen_seqdi_special (operands[0], sparc_compare_op0,
				 sparc_compare_op1);
      emit_insn (pat);
      DONE;
    }
  else if (GET_MODE (sparc_compare_op0) == TFmode && ! TARGET_HARD_QUAD)
    {
      emit_float_lib_cmp (sparc_compare_op0, sparc_compare_op1, EQ);
      emit_insn (gen_sne (operands[0]));
      DONE;
    }      
  else if (TARGET_V9)
    {
      if (gen_v9_scc (EQ, operands))
	DONE;
      /* fall through */
    }
  operands[1] = gen_compare_reg (EQ, sparc_compare_op0, sparc_compare_op1);
}")

;; ??? v9: Operand 0 needs a mode, so SImode was chosen.
;; However, the code handles both SImode and DImode.
(define_expand "sne"
  [(set (match_operand:SI 0 "intreg_operand" "")
	(ne:SI (match_dup 1) (const_int 0)))]
  "! TARGET_LIVE_G0"
  "
{
  if (GET_MODE (sparc_compare_op0) == SImode)
    {
      rtx pat;

      if (GET_MODE (operands[0]) == SImode)
	pat = gen_snesi_special (operands[0], sparc_compare_op0,
				 sparc_compare_op1);
      else if (! TARGET_ARCH64)
	FAIL;
      else
	pat = gen_snesi_special_extend (operands[0], sparc_compare_op0,
					sparc_compare_op1);
      emit_insn (pat);
      DONE;
    }
  else if (GET_MODE (sparc_compare_op0) == DImode)
    {
      rtx pat;

      if (! TARGET_ARCH64)
	FAIL;
      else if (GET_MODE (operands[0]) == SImode)
	pat = gen_snedi_special_trunc (operands[0], sparc_compare_op0,
				       sparc_compare_op1);
      else
	pat = gen_snedi_special (operands[0], sparc_compare_op0,
				 sparc_compare_op1);
      emit_insn (pat);
      DONE;
    }
  else if (GET_MODE (sparc_compare_op0) == TFmode && ! TARGET_HARD_QUAD)
    {
      emit_float_lib_cmp (sparc_compare_op0, sparc_compare_op1, NE);
      emit_insn (gen_sne (operands[0]));
      DONE;
    }      
  else if (TARGET_V9)
    {
      if (gen_v9_scc (NE, operands))
	DONE;
      /* fall through */
    }
  operands[1] = gen_compare_reg (NE, sparc_compare_op0, sparc_compare_op1);
}")

(define_expand "sgt"
  [(set (match_operand:SI 0 "intreg_operand" "")
	(gt:SI (match_dup 1) (const_int 0)))]
  "! TARGET_LIVE_G0"
  "
{
  if (GET_MODE (sparc_compare_op0) == TFmode && ! TARGET_HARD_QUAD)
    {
      emit_float_lib_cmp (sparc_compare_op0, sparc_compare_op1, GT);
      emit_insn (gen_sne (operands[0]));
      DONE;
    }
  else if (TARGET_V9)
    {
      if (gen_v9_scc (GT, operands))
	DONE;
      /* fall through */
    }
  operands[1] = gen_compare_reg (GT, sparc_compare_op0, sparc_compare_op1);
}")

(define_expand "slt"
  [(set (match_operand:SI 0 "intreg_operand" "")
	(lt:SI (match_dup 1) (const_int 0)))]
  "! TARGET_LIVE_G0"
  "
{
  if (GET_MODE (sparc_compare_op0) == TFmode && ! TARGET_HARD_QUAD)
    {
      emit_float_lib_cmp (sparc_compare_op0, sparc_compare_op1, LT);
      emit_insn (gen_sne (operands[0]));
      DONE;
    }
  else if (TARGET_V9)
    {
      if (gen_v9_scc (LT, operands))
	DONE;
      /* fall through */
    }
  operands[1] = gen_compare_reg (LT, sparc_compare_op0, sparc_compare_op1);
}")

(define_expand "sge"
  [(set (match_operand:SI 0 "intreg_operand" "")
	(ge:SI (match_dup 1) (const_int 0)))]
  "! TARGET_LIVE_G0"
  "
{
  if (GET_MODE (sparc_compare_op0) == TFmode && ! TARGET_HARD_QUAD)
    {
      emit_float_lib_cmp (sparc_compare_op0, sparc_compare_op1, GE);
      emit_insn (gen_sne (operands[0]));
      DONE;
    }
  else if (TARGET_V9)
    {
      if (gen_v9_scc (GE, operands))
	DONE;
      /* fall through */
    }
  operands[1] = gen_compare_reg (GE, sparc_compare_op0, sparc_compare_op1);
}")

(define_expand "sle"
  [(set (match_operand:SI 0 "intreg_operand" "")
	(le:SI (match_dup 1) (const_int 0)))]
  "! TARGET_LIVE_G0"
  "
{
  if (GET_MODE (sparc_compare_op0) == TFmode && ! TARGET_HARD_QUAD)
    {
      emit_float_lib_cmp (sparc_compare_op0, sparc_compare_op1, LE);
      emit_insn (gen_sne (operands[0]));
      DONE;
    }
  else if (TARGET_V9)
    {
      if (gen_v9_scc (LE, operands))
	DONE;
      /* fall through */
    }
  operands[1] = gen_compare_reg (LE, sparc_compare_op0, sparc_compare_op1);
}")

(define_expand "sgtu"
  [(set (match_operand:SI 0 "intreg_operand" "")
	(gtu:SI (match_dup 1) (const_int 0)))]
  "! TARGET_LIVE_G0"
  "
{
  if (! TARGET_V9)
    {
      rtx tem;

      /* We can do ltu easily, so if both operands are registers, swap them and
	 do a LTU.  */
      if ((GET_CODE (sparc_compare_op0) == REG
	   || GET_CODE (sparc_compare_op0) == SUBREG)
	  && (GET_CODE (sparc_compare_op1) == REG
	      || GET_CODE (sparc_compare_op1) == SUBREG))
	{
	  tem = sparc_compare_op0;
	  sparc_compare_op0 = sparc_compare_op1;
	  sparc_compare_op1 = tem;
	  emit_insn (gen_sltu (operands[0]));
	  DONE;
	}
    }
  else
    {
      if (gen_v9_scc (GTU, operands))
	DONE;
    }
  operands[1] = gen_compare_reg (GTU, sparc_compare_op0, sparc_compare_op1);
}")

(define_expand "sltu"
  [(set (match_operand:SI 0 "intreg_operand" "")
	(ltu:SI (match_dup 1) (const_int 0)))]
  "! TARGET_LIVE_G0"
  "
{
  if (TARGET_V9)
    {
      if (gen_v9_scc (LTU, operands))
	DONE;
    }
  operands[1] = gen_compare_reg (LTU, sparc_compare_op0, sparc_compare_op1);
}")

(define_expand "sgeu"
  [(set (match_operand:SI 0 "intreg_operand" "")
	(geu:SI (match_dup 1) (const_int 0)))]
  "! TARGET_LIVE_G0"
  "
{
  if (TARGET_V9)
    {
      if (gen_v9_scc (GEU, operands))
	DONE;
    }
  operands[1] = gen_compare_reg (GEU, sparc_compare_op0, sparc_compare_op1);
}")

(define_expand "sleu"
  [(set (match_operand:SI 0 "intreg_operand" "")
	(leu:SI (match_dup 1) (const_int 0)))]
  "! TARGET_LIVE_G0"
  "
{
  if (! TARGET_V9)
    {
      rtx tem;

      /* We can do geu easily, so if both operands are registers, swap them and
	 do a GEU.  */
      if ((GET_CODE (sparc_compare_op0) == REG
	   || GET_CODE (sparc_compare_op0) == SUBREG)
	  && (GET_CODE (sparc_compare_op1) == REG
	      || GET_CODE (sparc_compare_op1) == SUBREG))
	{
	  tem = sparc_compare_op0;
	  sparc_compare_op0 = sparc_compare_op1;
	  sparc_compare_op1 = tem;
	  emit_insn (gen_sgeu (operands[0]));
	  DONE;
	}
    }
  else
    {
      if (gen_v9_scc (LEU, operands))
	DONE;
    }
  operands[1] = gen_compare_reg (LEU, sparc_compare_op0, sparc_compare_op1);
}")

;; Now the DEFINE_INSNs for the scc cases.

;; The SEQ and SNE patterns are special because they can be done
;; without any branching and do not involve a COMPARE.

(define_insn "*snesi_zero"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(ne:SI (match_operand:SI 1 "register_operand" "r")
	       (const_int 0)))
   (clobber (reg:CC 100))]
  "! TARGET_LIVE_G0"
  "subcc %%g0,%1,%%g0\;addx %%g0,0,%0"
  [(set_attr "type" "unary")
   (set_attr "length" "2")])

(define_insn "*neg_snesi_zero"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(neg:SI (ne:SI (match_operand:SI 1 "register_operand" "r")
		       (const_int 0))))
   (clobber (reg:CC 100))]
  "! TARGET_LIVE_G0"
  "subcc %%g0,%1,%%g0\;subx %%g0,0,%0"
  [(set_attr "type" "unary")
   (set_attr "length" "2")])

(define_insn "*snesi_zero_extend"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(ne:SI (match_operand:SI 1 "register_operand" "r")
	       (const_int 0)))
   (clobber (reg:CC 100))]
  "TARGET_ARCH64"
  "subcc %%g0,%1,%%g0\;addx %%g0,0,%0"
  [(set_attr "type" "unary")
   (set_attr "length" "2")])

(define_insn "*snedi_zero"
  [(set (match_operand:DI 0 "register_operand" "=&r")
	(ne:DI (match_operand:DI 1 "register_operand" "r")
	       (const_int 0)))]
  "TARGET_ARCH64"
  "mov 0,%0\;movrnz %1,1,%0"
  [(set_attr "type" "unary")
   (set_attr "length" "2")])

(define_insn "*neg_snedi_zero"
  [(set (match_operand:DI 0 "register_operand" "=&r")
	(neg:DI (ne:DI (match_operand:DI 1 "register_operand" "r")
		       (const_int 0))))]
  "TARGET_ARCH64"
  "mov 0,%0\;movrnz %1,-1,%0"
  [(set_attr "type" "unary")
   (set_attr "length" "2")])

(define_insn "*snedi_zero_trunc"
  [(set (match_operand:SI 0 "register_operand" "=&r")
	(ne:DI (match_operand:DI 1 "register_operand" "r")
	       (const_int 0)))]
  "TARGET_ARCH64"
  "mov 0,%0\;movrnz %1,1,%0"
  [(set_attr "type" "unary")
   (set_attr "length" "2")])

(define_insn "*seqsi_zero"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(eq:SI (match_operand:SI 1 "register_operand" "r")
	       (const_int 0)))
   (clobber (reg:CC 100))]
  "! TARGET_LIVE_G0"
  "subcc %%g0,%1,%%g0\;subx %%g0,-1,%0"
  [(set_attr "type" "unary")
   (set_attr "length" "2")])

(define_insn "*neg_seqsi_zero"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(neg:SI (eq:SI (match_operand:SI 1 "register_operand" "r")
		       (const_int 0))))
   (clobber (reg:CC 100))]
  "! TARGET_LIVE_G0"
  "subcc %%g0,%1,%%g0\;addx %%g0,-1,%0"
  [(set_attr "type" "unary")
   (set_attr "length" "2")])

(define_insn "*seqsi_zero_extend"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(eq:SI (match_operand:SI 1 "register_operand" "r")
	       (const_int 0)))
   (clobber (reg:CC 100))]
  "TARGET_ARCH64"
  "subcc %%g0,%1,%%g0\;subx %%g0,-1,%0"
  [(set_attr "type" "unary")
   (set_attr "length" "2")])

(define_insn "*seqdi_zero"
  [(set (match_operand:DI 0 "register_operand" "=&r")
	(eq:DI (match_operand:DI 1 "register_operand" "r")
	       (const_int 0)))]
  "TARGET_ARCH64"
  "mov 0,%0\;movrz %1,1,%0"
  [(set_attr "type" "unary")
   (set_attr "length" "2")])

(define_insn "*neg_seqdi_zero"
  [(set (match_operand:DI 0 "register_operand" "=&r")
	(neg:DI (eq:DI (match_operand:DI 1 "register_operand" "r")
		       (const_int 0))))]
  "TARGET_ARCH64"
  "mov 0,%0\;movrz %1,-1,%0"
  [(set_attr "type" "unary")
   (set_attr "length" "2")]) 

(define_insn "*seqdi_zero_trunc"
  [(set (match_operand:SI 0 "register_operand" "=&r")
	(eq:DI (match_operand:DI 1 "register_operand" "r")
	       (const_int 0)))]
  "TARGET_ARCH64"
  "mov 0,%0\;movrz %1,1,%0"
  [(set_attr "type" "unary")
   (set_attr "length" "2")])

;; We can also do (x + (i == 0)) and related, so put them in.
;; ??? The addx/subx insns use the 32 bit carry flag so there are no DImode
;; versions for v9.

(define_insn "*x_plus_i_ne_0"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(plus:SI (ne:SI (match_operand:SI 1 "register_operand" "r")
			(const_int 0))
		 (match_operand:SI 2 "register_operand" "r")))
   (clobber (reg:CC 100))]
  "! TARGET_LIVE_G0"
  "subcc %%g0,%1,%%g0\;addx %2,0,%0"
  [(set_attr "length" "2")])

(define_insn "*x_minus_i_ne_0"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(minus:SI (match_operand:SI 2 "register_operand" "r")
		  (ne:SI (match_operand:SI 1 "register_operand" "r")
			 (const_int 0))))
   (clobber (reg:CC 100))]
  "! TARGET_LIVE_G0"
  "subcc %%g0,%1,%%g0\;subx %2,0,%0"
  [(set_attr "length" "2")])

(define_insn "*x_plus_i_eq_0"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(plus:SI (eq:SI (match_operand:SI 1 "register_operand" "r")
			(const_int 0))
		 (match_operand:SI 2 "register_operand" "r")))
   (clobber (reg:CC 100))]
  "! TARGET_LIVE_G0"
  "subcc %%g0,%1,%%g0\;subx %2,-1,%0"
  [(set_attr "length" "2")])

(define_insn "*x_minus_i_eq_0"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(minus:SI (match_operand:SI 2 "register_operand" "r")
		  (eq:SI (match_operand:SI 1 "register_operand" "r")
			 (const_int 0))))
   (clobber (reg:CC 100))]
  "! TARGET_LIVE_G0"
  "subcc %%g0,%1,%%g0\;addx %2,-1,%0"
  [(set_attr "length" "2")])

;; We can also do GEU and LTU directly, but these operate after a compare.
;; ??? The addx/subx insns use the 32 bit carry flag so there are no DImode
;; versions for v9.

(define_insn "*sltu_insn"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(ltu:SI (reg:CC 100) (const_int 0)))]
  "! TARGET_LIVE_G0"
  "addx %%g0,0,%0"
  [(set_attr "type" "misc")])

(define_insn "*neg_sltu_insn"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(neg:SI (ltu:SI (reg:CC 100) (const_int 0))))]
  "! TARGET_LIVE_G0"
  "subx %%g0,0,%0"
  [(set_attr "type" "misc")])

;; ??? Combine should canonicalize these next two to the same pattern.
(define_insn "*neg_sltu_minus_x"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(minus:SI (neg:SI (ltu:SI (reg:CC 100) (const_int 0)))
		  (match_operand:SI 1 "arith_operand" "rI")))]
  "! TARGET_LIVE_G0"
  "subx %%g0,%1,%0"
  [(set_attr "type" "unary")])

(define_insn "*neg_sltu_plus_x"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(neg:SI (plus:SI (ltu:SI (reg:CC 100) (const_int 0))
			 (match_operand:SI 1 "arith_operand" "rI"))))]
  "! TARGET_LIVE_G0"
  "subx %%g0,%1,%0"
  [(set_attr "type" "unary")])

(define_insn "*sgeu_insn"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(geu:SI (reg:CC 100) (const_int 0)))]
  "! TARGET_LIVE_G0"
  "subx %%g0,-1,%0"
  [(set_attr "type" "misc")])

(define_insn "*neg_sgeu_insn"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(neg:SI (geu:SI (reg:CC 100) (const_int 0))))]
  "! TARGET_LIVE_G0"
  "addx %%g0,-1,%0"
  [(set_attr "type" "misc")])

;; We can also do (x + ((unsigned) i >= 0)) and related, so put them in.
;; ??? The addx/subx insns use the 32 bit carry flag so there are no DImode
;; versions for v9.

(define_insn "*sltu_plus_x"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(plus:SI (ltu:SI (reg:CC 100) (const_int 0))
		 (match_operand:SI 1 "arith_operand" "rI")))]
  "! TARGET_LIVE_G0"
  "addx %%g0,%1,%0"
  [(set_attr "type" "unary")])

(define_insn "*sltu_plus_x_plus_y"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(plus:SI (ltu:SI (reg:CC 100) (const_int 0))
		 (plus:SI (match_operand:SI 1 "arith_operand" "%r")
			  (match_operand:SI 2 "arith_operand" "rI"))))]
  ""
  "addx %1,%2,%0")

(define_insn "*x_minus_sltu"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(minus:SI (match_operand:SI 1 "register_operand" "r")
		  (ltu:SI (reg:CC 100) (const_int 0))))]
  ""
  "subx %1,0,%0"
  [(set_attr "type" "unary")])

;; ??? Combine should canonicalize these next two to the same pattern.
(define_insn "*x_minus_y_minus_sltu"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(minus:SI (minus:SI (match_operand:SI 1 "register_operand" "r")
			    (match_operand:SI 2 "arith_operand" "rI"))
		  (ltu:SI (reg:CC 100) (const_int 0))))]
  ""
  "subx %1,%2,%0")

(define_insn "*x_minus_sltu_plus_y"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(minus:SI (match_operand:SI 1 "register_operand" "r")
		  (plus:SI (ltu:SI (reg:CC 100) (const_int 0))
			   (match_operand:SI 2 "arith_operand" "rI"))))]
  ""
  "subx %1,%2,%0")

(define_insn "*sgeu_plus_x"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(plus:SI (geu:SI (reg:CC 100) (const_int 0))
		 (match_operand:SI 1 "register_operand" "r")))]
  ""
  "subx %1,-1,%0"
  [(set_attr "type" "unary")])

(define_insn "*x_minus_sgeu"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(minus:SI (match_operand:SI 1 "register_operand" "r")
		  (geu:SI (reg:CC 100) (const_int 0))))]
  ""
  "addx %1,-1,%0"
  [(set_attr "type" "unary")])

;; Now we have the generic scc insns.
;; !v9: These will be done using a jump.
;; v9: Use conditional moves which are defined elsewhere.
;; We have to exclude the cases above, since we will not want combine to
;; turn something that does not require a jump into something that does.

(define_insn "*scc_si"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(match_operator:SI 2 "noov_compare_op"
			   [(match_operand 1 "icc_or_fcc_reg_operand" "")
			    (const_int 0)]))]
  ""
  "* return output_scc_insn (operands, insn); "
  [(set_attr "type" "multi")
   (set_attr "length" "3")])

(define_insn "*scc_di"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(match_operator:DI 2 "noov_compare_op"
			   [(match_operand 1 "icc_or_fcc_reg_operand" "")
			    (const_int 0)]))]
  "TARGET_ARCH64"
  "* return output_scc_insn (operands, insn); "
  [(set_attr "type" "multi")
   (set_attr "length" "3")])

;; These control RTL generation for conditional jump insns

;; The quad-word fp compare library routines all return nonzero to indicate
;; true, which is different from the equivalent libgcc routines, so we must
;; handle them specially here.

(define_expand "beq"
  [(set (pc)
	(if_then_else (eq (match_dup 1) (const_int 0))
		      (label_ref (match_operand 0 "" ""))
		      (pc)))]
  ""
  "
{
  if (TARGET_ARCH64 && sparc_compare_op1 == const0_rtx
      && GET_CODE (sparc_compare_op0) == REG
      && GET_MODE (sparc_compare_op0) == DImode)
    {
      emit_v9_brxx_insn (EQ, sparc_compare_op0, operands[0]);
      DONE;
    }
  else if (GET_MODE (sparc_compare_op0) == TFmode && ! TARGET_HARD_QUAD)
    {
      emit_float_lib_cmp (sparc_compare_op0, sparc_compare_op1, EQ);
      emit_jump_insn (gen_bne (operands[0]));
      DONE;
    }      
  operands[1] = gen_compare_reg (EQ, sparc_compare_op0, sparc_compare_op1);
}")

(define_expand "bne"
  [(set (pc)
	(if_then_else (ne (match_dup 1) (const_int 0))
		      (label_ref (match_operand 0 "" ""))
		      (pc)))]
  ""
  "
{
  if (TARGET_ARCH64 && sparc_compare_op1 == const0_rtx
      && GET_CODE (sparc_compare_op0) == REG
      && GET_MODE (sparc_compare_op0) == DImode)
    {
      emit_v9_brxx_insn (NE, sparc_compare_op0, operands[0]);
      DONE;
    }
  else if (GET_MODE (sparc_compare_op0) == TFmode && ! TARGET_HARD_QUAD)
    {
      emit_float_lib_cmp (sparc_compare_op0, sparc_compare_op1, NE);
      emit_jump_insn (gen_bne (operands[0]));
      DONE;
    }      
  operands[1] = gen_compare_reg (NE, sparc_compare_op0, sparc_compare_op1);
}")

(define_expand "bgt"
  [(set (pc)
	(if_then_else (gt (match_dup 1) (const_int 0))
		      (label_ref (match_operand 0 "" ""))
		      (pc)))]
  ""
  "
{
  if (TARGET_ARCH64 && sparc_compare_op1 == const0_rtx
      && GET_CODE (sparc_compare_op0) == REG
      && GET_MODE (sparc_compare_op0) == DImode)
    {
      emit_v9_brxx_insn (GT, sparc_compare_op0, operands[0]);
      DONE;
    }
  else if (GET_MODE (sparc_compare_op0) == TFmode && ! TARGET_HARD_QUAD)
    {
      emit_float_lib_cmp (sparc_compare_op0, sparc_compare_op1, GT);
      emit_jump_insn (gen_bne (operands[0]));
      DONE;
    }      
  operands[1] = gen_compare_reg (GT, sparc_compare_op0, sparc_compare_op1);
}")

(define_expand "bgtu"
  [(set (pc)
	(if_then_else (gtu (match_dup 1) (const_int 0))
		      (label_ref (match_operand 0 "" ""))
		      (pc)))]
  ""
  "
{ operands[1] = gen_compare_reg (GTU, sparc_compare_op0, sparc_compare_op1);
}")

(define_expand "blt"
  [(set (pc)
	(if_then_else (lt (match_dup 1) (const_int 0))
		      (label_ref (match_operand 0 "" ""))
		      (pc)))]
  ""
  "
{
  if (TARGET_ARCH64 && sparc_compare_op1 == const0_rtx
      && GET_CODE (sparc_compare_op0) == REG
      && GET_MODE (sparc_compare_op0) == DImode)
    {
      emit_v9_brxx_insn (LT, sparc_compare_op0, operands[0]);
      DONE;
    }
  else if (GET_MODE (sparc_compare_op0) == TFmode && ! TARGET_HARD_QUAD)
    {
      emit_float_lib_cmp (sparc_compare_op0, sparc_compare_op1, LT);
      emit_jump_insn (gen_bne (operands[0]));
      DONE;
    }      
  operands[1] = gen_compare_reg (LT, sparc_compare_op0, sparc_compare_op1);
}")

(define_expand "bltu"
  [(set (pc)
	(if_then_else (ltu (match_dup 1) (const_int 0))
		      (label_ref (match_operand 0 "" ""))
		      (pc)))]
  ""
  "
{ operands[1] = gen_compare_reg (LTU, sparc_compare_op0, sparc_compare_op1);
}")

(define_expand "bge"
  [(set (pc)
	(if_then_else (ge (match_dup 1) (const_int 0))
		      (label_ref (match_operand 0 "" ""))
		      (pc)))]
  ""
  "
{
  if (TARGET_ARCH64 && sparc_compare_op1 == const0_rtx
      && GET_CODE (sparc_compare_op0) == REG
      && GET_MODE (sparc_compare_op0) == DImode)
    {
      emit_v9_brxx_insn (GE, sparc_compare_op0, operands[0]);
      DONE;
    }
  else if (GET_MODE (sparc_compare_op0) == TFmode && ! TARGET_HARD_QUAD)
    {
      emit_float_lib_cmp (sparc_compare_op0, sparc_compare_op1, GE);
      emit_jump_insn (gen_bne (operands[0]));
      DONE;
    }      
  operands[1] = gen_compare_reg (GE, sparc_compare_op0, sparc_compare_op1);
}")

(define_expand "bgeu"
  [(set (pc)
	(if_then_else (geu (match_dup 1) (const_int 0))
		      (label_ref (match_operand 0 "" ""))
		      (pc)))]
  ""
  "
{ operands[1] = gen_compare_reg (GEU, sparc_compare_op0, sparc_compare_op1);
}")

(define_expand "ble"
  [(set (pc)
	(if_then_else (le (match_dup 1) (const_int 0))
		      (label_ref (match_operand 0 "" ""))
		      (pc)))]
  ""
  "
{
  if (TARGET_ARCH64 && sparc_compare_op1 == const0_rtx
      && GET_CODE (sparc_compare_op0) == REG
      && GET_MODE (sparc_compare_op0) == DImode)
    {
      emit_v9_brxx_insn (LE, sparc_compare_op0, operands[0]);
      DONE;
    }
  else if (GET_MODE (sparc_compare_op0) == TFmode && ! TARGET_HARD_QUAD)
    {
      emit_float_lib_cmp (sparc_compare_op0, sparc_compare_op1, LE);
      emit_jump_insn (gen_bne (operands[0]));
      DONE;
    }      
  operands[1] = gen_compare_reg (LE, sparc_compare_op0, sparc_compare_op1);
}")

(define_expand "bleu"
  [(set (pc)
	(if_then_else (leu (match_dup 1) (const_int 0))
		      (label_ref (match_operand 0 "" ""))
		      (pc)))]
  ""
  "
{ operands[1] = gen_compare_reg (LEU, sparc_compare_op0, sparc_compare_op1);
}")

;; Now match both normal and inverted jump.

(define_insn "*normal_branch"
  [(set (pc)
	(if_then_else (match_operator 0 "noov_compare_op"
				      [(reg 100) (const_int 0)])
		      (label_ref (match_operand 1 "" ""))
		      (pc)))]
  ""
  "*
{
  return output_cbranch (operands[0], 1, 0,
			 final_sequence && INSN_ANNULLED_BRANCH_P (insn),
			 ! final_sequence);
}"
  [(set_attr "type" "branch")])

(define_insn "*inverted_branch"
  [(set (pc)
	(if_then_else (match_operator 0 "noov_compare_op"
				      [(reg 100) (const_int 0)])
		      (pc)
		      (label_ref (match_operand 1 "" ""))))]
  ""
  "*
{
  return output_cbranch (operands[0], 1, 1,
			 final_sequence && INSN_ANNULLED_BRANCH_P (insn),
			 ! final_sequence);
}"
  [(set_attr "type" "branch")])

(define_insn "*normal_fp_branch"
  [(set (pc)
	(if_then_else (match_operator 1 "comparison_operator"
				      [(match_operand:CCFP 0 "fcc_reg_operand" "c")
				       (const_int 0)])
		      (label_ref (match_operand 2 "" ""))
		      (pc)))]
  ""
  "*
{
  return output_cbranch (operands[1], 2, 0,
			 final_sequence && INSN_ANNULLED_BRANCH_P (insn),
			 ! final_sequence);
}"
  [(set_attr "type" "branch")])

(define_insn "*inverted_fp_branch"
  [(set (pc)
	(if_then_else (match_operator 1 "comparison_operator"
				      [(match_operand:CCFP 0 "fcc_reg_operand" "c")
				       (const_int 0)])
		      (pc)
		      (label_ref (match_operand 2 "" ""))))]
  ""
  "*
{
  return output_cbranch (operands[1], 2, 1,
			 final_sequence && INSN_ANNULLED_BRANCH_P (insn),
			 ! final_sequence);
}"
  [(set_attr "type" "branch")])

(define_insn "*normal_fpe_branch"
  [(set (pc)
	(if_then_else (match_operator 1 "comparison_operator"
				      [(match_operand:CCFPE 0 "fcc_reg_operand" "c")
				       (const_int 0)])
		      (label_ref (match_operand 2 "" ""))
		      (pc)))]
  ""
  "*
{
  return output_cbranch (operands[1], 2, 0,
			 final_sequence && INSN_ANNULLED_BRANCH_P (insn),
			 ! final_sequence);
}"
  [(set_attr "type" "branch")])

(define_insn "*inverted_fpe_branch"
  [(set (pc)
	(if_then_else (match_operator 1 "comparison_operator"
				      [(match_operand:CCFPE 0 "fcc_reg_operand" "c")
				       (const_int 0)])
		      (pc)
		      (label_ref (match_operand 2 "" ""))))]
  ""
  "*
{
  return output_cbranch (operands[1], 2, 1,
			 final_sequence && INSN_ANNULLED_BRANCH_P (insn),
			 ! final_sequence);
}"
  [(set_attr "type" "branch")])

;; Sparc V9-specific jump insns.  None of these are guaranteed to be
;; in the architecture.

;; There are no 32 bit brreg insns.

(define_insn "*normal_int_branch_sp64"
  [(set (pc)
	(if_then_else (match_operator 0 "v9_regcmp_op"
				      [(match_operand:DI 1 "register_operand" "r")
				       (const_int 0)])
		      (label_ref (match_operand 2 "" ""))
		      (pc)))]
  "TARGET_ARCH64"
  "*
{
  return output_v9branch (operands[0], 1, 2, 0,
			  final_sequence && INSN_ANNULLED_BRANCH_P (insn),
			  ! final_sequence);
}"
  [(set_attr "type" "branch")])

(define_insn "*inverted_int_branch_sp64"
  [(set (pc)
	(if_then_else (match_operator 0 "v9_regcmp_op"
				      [(match_operand:DI 1 "register_operand" "r")
				       (const_int 0)])
		      (pc)
		      (label_ref (match_operand 2 "" ""))))]
  "TARGET_ARCH64"
  "*
{
  return output_v9branch (operands[0], 1, 2, 1,
			  final_sequence && INSN_ANNULLED_BRANCH_P (insn),
			  ! final_sequence);
}"
  [(set_attr "type" "branch")])

;; Esoteric move insns (lo_sum, high, pic).

(define_insn "*lo_sum_si"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(lo_sum:SI (match_operand:SI 1 "register_operand" "r")
		   (match_operand:SI 2 "immediate_operand" "in")))]
  ""
  ;; V9 needs "add" because of the code models.  We still use "or" for v8
  ;; so we can compare the old compiler with the new.
  "* return TARGET_ARCH64 ? \"add %1,%%lo(%a2),%0\" : \"or %1,%%lo(%a2),%0\";"
  ;; Need to set length for this arith insn because operand2
  ;; is not an "arith_operand".
  [(set_attr "length" "1")])

;; For PIC, symbol_refs are put inside unspec so that the optimizer will not
;; confuse them with real addresses.
(define_insn "pic_lo_sum_si"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(lo_sum:SI (match_operand:SI 1 "register_operand" "r")
		   (unspec:SI [(match_operand:SI 2 "immediate_operand" "in")] 0)))]
  "flag_pic"
  ;; V9 needs "add" because of the code models.  We still use "or" for v8
  ;; so we can compare the old compiler with the new.
  "* return TARGET_ARCH64 ? \"add %1,%%lo(%a2),%0\" : \"or %1,%%lo(%a2),%0\";"
  ;; Need to set length for this arith insn because operand2
  ;; is not an "arith_operand".
  [(set_attr "length" "1")])

;; The PIC version of sethi must appear before the non-pic case so that
;; the unspec will not be matched as part of the operand.
;; For PIC, symbol_refs are put inside unspec so that the optimizer will not
;; confuse them with real addresses.
(define_insn "pic_sethi_si"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(high:SI (unspec:SI [(match_operand 1 "" "")] 0)))]
  "flag_pic && check_pic (1)"
  "sethi %%hi(%a1),%0"
  [(set_attr "type" "move")
   (set_attr "length" "1")])

(define_insn "pic_lo_sum_di"
  [(set (match_operand:DI 0 "register_operand" "=r")
        (lo_sum:SI (match_operand:DI 1 "register_operand" "r")
                   (unspec:SI [(match_operand:DI 2 "immediate_operand" "in")] 0)))]
  "TARGET_ARCH64 && flag_pic"
  "add %1,%%lo(%a2),%0"
  [(set_attr "length" "1")])

(define_insn "pic_sethi_di"
  [(set (match_operand:DI 0 "register_operand" "=r")
        (high:SI (unspec:SI [(match_operand 1 "" "")] 0)))]
  "TARGET_ARCH64 && flag_pic && check_pic (1)"
  "sethi %%hi(%a1),%0"
  [(set_attr "type" "move")
   (set_attr "length" "1")])

(define_insn "get_pc_via_call"
  [(set (pc) (label_ref (match_operand 0 "" "")))
   (set (reg:SI 15) (label_ref (match_operand 1 "" "")))]
  ""
  "call %l0%#"
  [(set_attr "type" "uncond_branch")])

(define_insn "get_pc_via_rdpc"
  [(set (match_operand:DI 0 "register_operand" "=r") (pc))]
  "TARGET_PTR64"
  "rd %%pc,%0"
  [(set_attr "type" "move")])

;; Special pic pattern, for loading the address of a label into a register.
;; It clobbers o7 because the call puts the return address (i.e. pc value)
;; there.  The pic tablejump pattern also uses this.

(define_insn "move_pic_label_si"
  [(set (match_operand:SI 0 "register_operand" "=r")
	; This was previously (label_ref:SI (match_operand 1 "" "")) but that
	; loses the volatil and other flags of the original label_ref.
	(match_operand:SI 1 "label_ref_operand" ""))
   (set (reg:SI 15) (pc))]
  "flag_pic"
  "*
{
  if (get_attr_length (insn) == 2)
    return \"\\n1:\;call 2f\;add %%o7,%%lo(%l1-1b),%0\\n2:\";
  else
    return \"\\n1:\;call 2f\;sethi %%hi(%l1-1b),%0\\n2:\\tor %0,%%lo(%l1-1b),%0\;add %0,%%o7,%0\";
}"
  [(set_attr "type" "multi")
   ; 960 = 4096 bytes / 4 bytes/insn - 64 (for not always perfect length calcs)
   (set (attr "length") (if_then_else (ltu (minus (match_dup 1) (pc))
					   (const_int 960))
				      (const_int 2)
				      (const_int 4)))])

;; Special sparc64 pattern for loading the address of a label into a register.
;; The pic and non-pic cases are the same since it's the most efficient way.
;;
;; ??? The non-pic case doesn't need to use %o7, we could use a scratch
;; instead.  But the pic case doesn't need to use %o7 either.  We handle them
;; both here so that when this is fixed, they can both be fixed together.
;; Don't forget that the pic jump table stuff uses %o7 (that will need to be
;; changed too).

(define_insn "move_label_di"
  [(set (match_operand:DI 0 "register_operand" "=r")
	; This was previously (label_ref:DI (match_operand 1 "" "")) but that
	; loses the volatil and other flags of the original label_ref.
	(match_operand:DI 1 "label_ref_operand" ""))
   (set (reg:DI 15) (pc))]
  "TARGET_ARCH64"
  "*
{
  if (get_attr_length (insn) == 2)
    return \"\\n1:\;rd %%pc,%%o7\;add %%o7,%l1-1b,%0\";
  else
    return \"\\n1:\;rd %%pc,%%o7\;sethi %%hi(%l1-1b),%0\;add %0,%%lo(%l1-1b),%0\;sra %0,0,%0\;add %0,%%o7,%0\";
}"
  [(set_attr "type" "multi")
   ; 960 = 4096 bytes / 4 bytes/insn - 64 (for not always perfect length calcs)
   (set (attr "length") (if_then_else (ltu (minus (match_dup 1) (pc))
					   (const_int 960))
				      (const_int 2)
				      (const_int 5)))])

(define_insn "*sethi_hi"
  [(set (match_operand:HI 0 "register_operand" "=r")
	(high:HI (match_operand 1 "" "")))]
  "check_pic (1)"
  "sethi %%hi(%a1),%0"
  [(set_attr "type" "move")
   (set_attr "length" "1")])

;; This must appear after the PIC sethi so that the PIC unspec will not
;; be matched as part of the operand.
(define_insn "*sethi_si"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(high:SI (match_operand 1 "" "")))]
  "check_pic (1)"
  "sethi %%hi(%a1),%0"
  [(set_attr "type" "move")
   (set_attr "length" "1")])

(define_insn "*lo_sum_di_sp32"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(lo_sum:DI (match_operand:DI 1 "register_operand" "0")
		   (match_operand:DI 2 "immediate_operand" "in")))]
  "! TARGET_ARCH64"
  "*
{
  /* Don't output a 64 bit constant, since we can't trust the assembler to
     handle it correctly.  */
  if (GET_CODE (operands[2]) == CONST_DOUBLE)
    operands[2] = GEN_INT (CONST_DOUBLE_LOW (operands[2]));
  else if (GET_CODE (operands[2]) == CONST_INT
	   && HOST_BITS_PER_WIDE_INT > 32
	   && INTVAL (operands[2]) > 0xffffffff)
    operands[2] = GEN_INT (INTVAL (operands[2]) & 0xffffffff);

  return \"or %L1,%%lo(%a2),%L0\";
}"
  ;; Need to set length for this arith insn because operand2
  ;; is not an "arith_operand".
  [(set_attr "length" "1")])

;; ??? Optimizer does not handle "or %o1,%lo(0),%o1". How about add?

(define_insn "*lo_sum_di_sp64"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(lo_sum:DI (match_operand:DI 1 "register_operand" "0")
		   (match_operand:DI 2 "immediate_operand" "in")))]
  "TARGET_ARCH64"
  "*
{
  /* Don't output a 64 bit constant, since we can't trust the assembler to
     handle it correctly.  */
  if (GET_CODE (operands[2]) == CONST_DOUBLE)
    operands[2] = GEN_INT (CONST_DOUBLE_LOW (operands[2]));
  else if (GET_CODE (operands[2]) == CONST_INT
	   && HOST_BITS_PER_WIDE_INT > 32
	   && INTVAL (operands[2]) > 0xffffffff)
    operands[2] = GEN_INT (INTVAL (operands[2]) & 0xffffffff);

  /* Note that we use add here.  This is important because Medium/Anywhere
     code model support depends on it.  */
  return \"add %1,%%lo(%a2),%0\";
}"
  ;; Need to set length for this arith insn because operand2
  ;; is not an "arith_operand".
  [(set_attr "length" "1")])

(define_insn "*sethi_di_sp32"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(high:DI (match_operand 1 "" "")))]
  "! TARGET_ARCH64 && check_pic (1)"
  "*
{
  rtx op0 = operands[0];
  rtx op1 = operands[1];

  if (GET_CODE (op1) == CONST_INT)
    {
      operands[0] = operand_subword (op0, 1, 0, DImode);
      output_asm_insn (\"sethi %%hi(%a1),%0\", operands);

      operands[0] = operand_subword (op0, 0, 0, DImode);
      if (INTVAL (op1) < 0)
	return \"mov -1,%0\";
      else
	return \"mov 0,%0\";
    }
  else if (GET_CODE (op1) == CONST_DOUBLE)
    {
      operands[0] = operand_subword (op0, 1, 0, DImode);
      operands[1] = GEN_INT (CONST_DOUBLE_LOW (op1));
      output_asm_insn (\"sethi %%hi(%a1),%0\", operands);

      operands[0] = operand_subword (op0, 0, 0, DImode);
      operands[1] = GEN_INT (CONST_DOUBLE_HIGH (op1));
      return singlemove_string (operands);
    }
  else
    abort ();
  return \"\";
}"
  [(set_attr "type" "move")
   (set_attr "length" "2")])

;;; ??? This pattern originally clobbered a scratch register.  However, this
;;; is invalid, the movdi pattern may not use a temp register because it
;;; may be called from reload to reload a DImode value.  In that case, we
;;; end up with a scratch register that never gets allocated.  To avoid this,
;;; we use global register 1 which is never otherwise used by gcc as a temp.
;;; The correct solution here might be to force DImode constants to memory,
;;; e.g. by using a toc like the romp and rs6000 ports do for addresses, reg
;;; 1 will then no longer need to be considered a fixed reg.

(define_expand "sethi_di_sp64"
  [(parallel
     [(set (match_operand:DI 0 "register_operand" "")
	   (high:DI (match_operand 1 "general_operand" "")))
      (clobber (reg:DI 1))])]
  "TARGET_ARCH64"
  "")

(define_insn "*sethi_di_sp64_const"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(high:DI (match_operand 1 "const_double_operand" "")))
   (clobber (reg:DI 1))]
  "TARGET_ARCH64 && check_pic (1)"
  "*
{
#if HOST_BITS_PER_WIDE_INT == 32
  rtx high, low;
  
  split_double (operands[1], &high, &low);

  if (high == const0_rtx)
    {
      operands[1] = low;
      output_asm_insn (\"sethi %%hi(%a1),%0\", operands);
    }
  else
    {
      operands[1] = high;
      output_asm_insn (singlemove_string (operands), operands);

      operands[1] = low;
      output_asm_insn (\"sllx %0,32,%0\", operands);
      if (low != const0_rtx)
	output_asm_insn (\"sethi %%hi(%a1),%%g1; or %0,%%g1,%0\", operands);
    }
#else
  rtx op = operands[1];

  if (! SPARC_SETHI_P (INTVAL(op)))
    {
      operands[1] = GEN_INT (INTVAL (op) >> 32);
      output_asm_insn (singlemove_string (operands), operands);

      output_asm_insn (\"sllx %0,32,%0\", operands);
      if (INTVAL (op) & 0xffffffff)
	{
	  operands[1] = GEN_INT (INTVAL (op) & 0xffffffff);
	  output_asm_insn (\"sethi %%hi(%a1),%%g1; or %0,%%g1,%0\", operands);
	}
    }
  else
    {
      output_asm_insn (\"sethi %%hi(%a1),%0\", operands);
    }
#endif

  return \"\";
}"
  [(set_attr "type" "move")
   (set_attr "length" "5")])

;; Most of the required support for the various code models is here.
;; We can do this because sparcs need the high insn to load the address.  We
;; just need to get high to do the right thing for each code model.  Then each
;; uses the same "%X+%lo(...)" in the load/store insn, though in the case of
;; the medium/middle code model "%lo" is written "%l44".

;; When TARGET_CM_MEDLOW, assume that the upper 32 bits of symbol addresses are
;; always 0.
;; When TARGET_CM_MEDMID, the executable must be in the low 16 TB of memory.
;; This corresponds to the low 44 bits, and the %[hml]44 relocs are used.
;; ??? Not implemented yet.
;; When TARGET_CM_EMBMEDANY, the text and data segments have a maximum size of
;; 31 bits and may be located anywhere.  EMBMEDANY_BASE_REG contains the start
;; address of the data segment, currently %g4.
;; When TARGET_CM_MEDANY, the text and data segments have a maximum size of 31
;; bits and may be located anywhere.  The maximum offset from any instruction
;; to the label _GLOBAL_OFFSET_TABLE_ is 31 bits.

(define_insn "*sethi_di_medlow"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(high:DI (match_operand 1 "" "")))
  ;; The clobber is here because emit_move_sequence assumes the worst case.
   (clobber (reg:DI 1))]
  "TARGET_CM_MEDLOW && check_pic (1)"
  "sethi %%hi(%a1),%0"
  [(set_attr "type" "move")
   (set_attr "length" "1")])

(define_insn "*sethi_di_medium_pic"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(high:DI (match_operand 1 "sp64_medium_pic_operand" "")))]
  "(TARGET_CM_MEDLOW || TARGET_CM_EMBMEDANY) && check_pic (1)"
  "sethi %%hi(%a1),%0"
  [(set_attr "type" "move")
   (set_attr "length" "1")])

;; WARNING: %0 gets %hi(%1)+%g4.
;;          You cannot OR in %lo(%1), it must be added in.

(define_insn "*sethi_di_embmedany_data"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(high:DI (match_operand 1 "data_segment_operand" "")))
  ;; The clobber is here because emit_move_sequence assumes the worst case.
   (clobber (reg:DI 1))]
  "TARGET_CM_EMBMEDANY && check_pic (1)"
  "sethi %%hi(%a1),%0; add %0,%_,%0"
  [(set_attr "type" "move")
   (set_attr "length" "2")])

(define_insn "*sethi_di_embmedany_text"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(high:DI (match_operand 1 "text_segment_operand" "")))
  ;; The clobber is here because emit_move_sequence assumes the worst case.
   (clobber (reg:DI 1))]
  "TARGET_CM_EMBMEDANY && check_pic (1)"
  "sethi %%uhi(%a1),%%g1; or %%g1,%%ulo(%a1),%%g1; sllx %%g1,32,%%g1; sethi %%hi(%a1),%0; or %0,%%g1,%0"
  [(set_attr "type" "move")
   (set_attr "length" "5")])

;; Move instructions

(define_expand "movqi"
  [(set (match_operand:QI 0 "general_operand" "")
	(match_operand:QI 1 "general_operand" ""))]
  ""
  "
{
  if (emit_move_sequence (operands, QImode))
    DONE;
}")

(define_insn "*movqi_insn"
  [(set (match_operand:QI 0 "reg_or_nonsymb_mem_operand" "=r,r,r,Q")
	(match_operand:QI 1 "move_operand" "rI,K,Q,rJ"))]
  "! TARGET_LIVE_G0
   && (register_operand (operands[0], QImode)
       || register_operand (operands[1], QImode)
       || operands[1] == const0_rtx)"
  "@@
   mov %1,%0
   sethi %%hi(%a1),%0
   ldub %1,%0
   stb %r1,%0"
  [(set_attr "type" "move,move,load,store")
   (set_attr "length" "1")])

(define_insn "*movqi_insn_liveg0"
  [(set (match_operand:QI 0 "reg_or_nonsymb_mem_operand" "=r,r,r,r,r,Q")
	(match_operand:QI 1 "move_operand" "r,J,I,K,Q,r"))]
  "TARGET_LIVE_G0
   && (register_operand (operands[0], QImode)
       || register_operand (operands[1], QImode))"
  "@@
   mov %1,%0
   and %0,0,%0
   and %0,0,%0\;or %0,%1,%0
   sethi %%hi(%a1),%0
   ldub %1,%0
   stb %1,%0"
  [(set_attr "type" "move,move,move,move,load,store")
   (set_attr "length" "1,1,2,1,1,1")])

(define_insn "*lo_sum_qi"
  [(set (match_operand:QI 0 "register_operand" "=r")
	(subreg:QI (lo_sum:SI (match_operand:QI 1 "register_operand" "r")
			      (match_operand 2 "immediate_operand" "in")) 0))]
  ""
  "or %1,%%lo(%a2),%0"
  [(set_attr "length" "1")])

(define_insn "*store_qi"
  [(set (mem:QI (match_operand:SI 0 "symbolic_operand" ""))
	(match_operand:QI 1 "reg_or_0_operand" "rJ"))
   (clobber (match_scratch:SI 2 "=&r"))]
  "(reload_completed || reload_in_progress)
   && ! TARGET_PTR64"
  "sethi %%hi(%a0),%2\;stb %r1,[%2+%%lo(%a0)]"
  [(set_attr "type" "store")
   (set_attr "length" "2")])

(define_expand "movhi"
  [(set (match_operand:HI 0 "general_operand" "")
	(match_operand:HI 1 "general_operand" ""))]
  ""
  "
{
  if (emit_move_sequence (operands, HImode))
    DONE;
}")

(define_insn "*movhi_insn"
  [(set (match_operand:HI 0 "reg_or_nonsymb_mem_operand" "=r,r,r,Q")
	(match_operand:HI 1 "move_operand" "rI,K,Q,rJ"))]
  "! TARGET_LIVE_G0
   && (register_operand (operands[0], HImode)
       || register_operand (operands[1], HImode)
       || operands[1] == const0_rtx)"
  "@@
   mov %1,%0
   sethi %%hi(%a1),%0
   lduh %1,%0
   sth %r1,%0"
  [(set_attr "type" "move,move,load,store")
   (set_attr "length" "1")])

(define_insn "*movhi_insn_liveg0"
  [(set (match_operand:HI 0 "reg_or_nonsymb_mem_operand" "=r,r,r,r,r,Q")
	(match_operand:HI 1 "move_operand" "r,J,I,K,Q,r"))]
  "TARGET_LIVE_G0
   && (register_operand (operands[0], HImode)
       || register_operand (operands[1], HImode))"
  "@@
   mov %1,%0
   and %0,0,%0
   and %0,0,%0\;or %0,%1,%0
   sethi %%hi(%a1),%0
   lduh %1,%0
   sth %1,%0"
  [(set_attr "type" "move,move,move,move,load,store")
   (set_attr "length" "1,1,2,1,1,1")])

(define_insn "*lo_sum_hi"
  [(set (match_operand:HI 0 "register_operand" "=r")
	(lo_sum:HI (match_operand:HI 1 "register_operand" "r")
		   (match_operand 2 "immediate_operand" "in")))]
  ""
  "or %1,%%lo(%a2),%0"
  [(set_attr "length" "1")])

(define_insn "*store_hi"
  [(set (mem:HI (match_operand:SI 0 "symbolic_operand" ""))
	(match_operand:HI 1 "reg_or_0_operand" "rJ"))
   (clobber (match_scratch:SI 2 "=&r"))]
  "(reload_completed || reload_in_progress)
   && ! TARGET_PTR64"
  "sethi %%hi(%a0),%2\;sth %r1,[%2+%%lo(%a0)]"
  [(set_attr "type" "store")
   (set_attr "length" "2")])

(define_expand "movsi"
  [(set (match_operand:SI 0 "general_operand" "")
	(match_operand:SI 1 "general_operand" ""))]
  ""
  "
{
  if (emit_move_sequence (operands, SImode))
    DONE;
}")

;; We must support both 'r' and 'f' registers here, because combine may
;; convert SFmode hard registers to SImode hard registers when simplifying
;; subreg sets.

;; We cannot combine the similar 'r' and 'f' constraints, because it causes
;; problems with register allocation.  Reload might try to put an integer
;; in an fp register, or an fp number is an integer register.

(define_insn "*movsi_insn"
  [(set (match_operand:SI 0 "reg_or_nonsymb_mem_operand" "=r,f,r,r,f,Q,Q")
	(match_operand:SI 1 "move_operand" "rI,!f,K,Q,!Q,rJ,!f"))]
  "! TARGET_LIVE_G0
   && (register_operand (operands[0], SImode)
       || register_operand (operands[1], SImode)
       || operands[1] == const0_rtx)"
  "@@
   mov %1,%0
   fmovs %1,%0
   sethi %%hi(%a1),%0
   ld %1,%0
   ld %1,%0
   st %r1,%0
   st %1,%0"
  [(set_attr "type" "move,fp,move,load,fpload,store,fpstore")
   (set_attr "length" "1")])

(define_insn "*movsi_insn_liveg0"
  [(set (match_operand:SI 0 "reg_or_nonsymb_mem_operand" "=r,r,r,f,r,r,f,Q,Q")
	(match_operand:SI 1 "move_operand" "r,J,I,!f,K,Q,!Q,r,!f"))]
  "TARGET_LIVE_G0
   && (register_operand (operands[0], SImode)
       || register_operand (operands[1], SImode))"
  "@@
   mov %1,%0
   and %0,0,%0
   and %0,0,%0\;or %0,%1,%0
   fmovs %1,%0
   sethi %%hi(%a1),%0
   ld %1,%0
   ld %1,%0
   st %1,%0
   st %1,%0"
  [(set_attr "type" "move,move,move,fp,move,load,fpload,store,fpstore")
   (set_attr "length" "1,1,2,1,1,1,1,1,1")])

(define_insn "*store_si"
  [(set (mem:SI (match_operand:SI 0 "symbolic_operand" ""))
	(match_operand:SI 1 "reg_or_0_operand" "rJ"))
   (clobber (match_scratch:SI 2 "=&r"))]
  "(reload_completed || reload_in_progress)
   && ! TARGET_PTR64"
  "sethi %%hi(%a0),%2\;st %r1,[%2+%%lo(%a0)]"
  [(set_attr "type" "store")
   (set_attr "length" "2")])

(define_expand "movdi"
  [(set (match_operand:DI 0 "reg_or_nonsymb_mem_operand" "")
	(match_operand:DI 1 "general_operand" ""))]
  ""
  "
{
  if (emit_move_sequence (operands, DImode))
    DONE;
}")

(define_insn "*movdi_sp32_insn"
  [(set (match_operand:DI 0 "reg_or_nonsymb_mem_operand" "=r,T,U,Q,r,r,?f,?f,?Q")
	(match_operand:DI 1 "general_operand" "r,U,T,r,Q,i,f,Q,f"))]
  "! TARGET_ARCH64
   && (register_operand (operands[0], DImode)
       || register_operand (operands[1], DImode)
       || operands[1] == const0_rtx)"
  "*
{
  if (FP_REG_P (operands[0]) || FP_REG_P (operands[1]))
    return output_fp_move_double (operands);
  return output_move_double (operands);
}"
  [(set_attr "type" "move,store,load,store,load,multi,fp,fpload,fpstore")
   (set_attr "length" "2,1,1,3,3,3,2,3,3")])

;;; ??? The trick used below can be extended to load any negative 32 bit
;;; constant in two instructions.  Currently the compiler will use HIGH/LO_SUM
;;; for anything not matching the HIK constraints, which results in 5
;;; instructions.  Positive 32 bit constants can be loaded in the obvious way
;;; with sethi/ori.  To extend the trick, in the xor instruction, use 
;;; xor %o0, ((op1 & 0x3ff) | -0x400), %o0
;;; This needs the original value of operands[1], not the inverted value.

(define_insn "*movdi_sp64_insn"
  [(set (match_operand:DI 0 "reg_or_nonsymb_mem_operand" "=r,r,r,Q,?f,?f,?Q")
	(match_operand:DI 1 "move_operand" "rI,K,Q,rJ,f,Q,f"))]
  "TARGET_ARCH64
   && (register_operand (operands[0], DImode)
       || register_operand (operands[1], DImode)
       || operands[1] == const0_rtx)"
  "*
{
  switch (which_alternative)
    {
    case 0:
      return \"mov %1,%0\";
    case 1:
      /* Sethi does not sign extend, so we must use a little trickery
	 to use it for negative numbers.  Invert the constant before
	 loading it in, then use a xor immediate to invert the loaded bits
	 (along with the upper 32 bits) to the desired constant.  This
	 works because the sethi and immediate fields overlap.  */

      if ((INTVAL (operands[1]) & 0x80000000) == 0)
	return \"sethi %%hi(%a1),%0\";
      else
	{
	  operands[1] = GEN_INT (~INTVAL (operands[1]));
	  output_asm_insn (\"sethi %%hi(%a1),%0\", operands);
	  /* The low 10 bits are already zero, but invert the rest.
	     Assemblers don't accept 0x1c00, so use -0x400 instead.  */
	  return \"xor %0,-0x400,%0\";
	}
    case 2:
      return \"ldx %1,%0\";
    case 3:
      return \"stx %r1,%0\";
    case 4:
      return \"mov %1,%0\";
    case 5:
      return \"ldd %1,%0\";
    case 6:
      return \"std %1,%0\";
    }
}"
  [(set_attr "type" "move,move,load,store,fp,fpload,fpstore")
   (set_attr "length" "1,2,1,1,1,1,1")])

;; ??? There's no symbolic (set (mem:DI ...) ...).
;; Experimentation with v9 suggested one isn't needed.

;; Block move insns.

;; ??? We get better code without it.  See output_block_move in sparc.c.

;; The definition of this insn does not really explain what it does,
;; but it should suffice
;; that anything generated as this insn will be recognized as one
;; and that it will not successfully combine with anything.
;(define_expand "movstrsi"
;  [(parallel [(set (mem:BLK (match_operand:BLK 0 "general_operand" ""))
;		   (mem:BLK (match_operand:BLK 1 "general_operand" "")))
;	      (use (match_operand:SI 2 "nonmemory_operand" ""))
;	      (use (match_operand:SI 3 "immediate_operand" ""))
;	      (clobber (match_dup 0))
;	      (clobber (match_dup 1))
;	      (clobber (match_scratch:SI 4 ""))
;	      (clobber (reg:SI 100))
;	      (clobber (reg:SI 1))])]
;  ""
;  "
;{
;  /* If the size isn't known, don't emit inline code.  output_block_move
;     would output code that's much slower than the library function.
;     Also don't output code for large blocks.  */
;  if (GET_CODE (operands[2]) != CONST_INT
;      || GET_CODE (operands[3]) != CONST_INT
;      || INTVAL (operands[2]) / INTVAL (operands[3]) > 16)
;    FAIL;
;
;  operands[0] = copy_to_mode_reg (Pmode, XEXP (operands[0], 0));
;  operands[1] = copy_to_mode_reg (Pmode, XEXP (operands[1], 0));
;  operands[2] = force_not_mem (operands[2]);
;}")

;(define_insn "*block_move_insn"
;  [(set (mem:BLK (match_operand:SI 0 "register_operand" "+r"))
;	(mem:BLK (match_operand:SI 1 "register_operand" "+r")))
;   (use (match_operand:SI 2 "nonmemory_operand" "rn"))
;   (use (match_operand:SI 3 "immediate_operand" "i"))
;   (clobber (match_dup 0))
;   (clobber (match_dup 1))
;   (clobber (match_scratch:SI 4 "=&r"))
;   (clobber (reg:SI 100))
;   (clobber (reg:SI 1))]
;  ""
;  "* return output_block_move (operands);"
;  [(set_attr "type" "multi")
;   (set_attr "length" "6")])

;; Floating point move insns

;; This pattern forces (set (reg:SF ...) (const_double ...))
;; to be reloaded by putting the constant into memory.
;; It must come before the more general movsf pattern.
(define_insn "*movsf_const_insn"
  [(set (match_operand:SF 0 "general_operand" "=?r,f,m")
	(match_operand:SF 1 "" "?F,m,G"))]
  "TARGET_FPU
   && GET_CODE (operands[1]) == CONST_DOUBLE
   && (GET_CODE (operands[0]) == REG
       || fp_zero_operand (operands[1]))"
  "*
{
  switch (which_alternative)
    {
    case 0:
      return singlemove_string (operands);
    case 1:
      return \"ld %1,%0\";
    case 2:
      return \"st %%g0,%0\";
    }
}"
  [(set_attr "type" "load,fpload,store")
   (set_attr "length" "2,1,1")])

(define_expand "movsf"
  [(set (match_operand:SF 0 "general_operand" "")
	(match_operand:SF 1 "general_operand" ""))]
  ""
  "
{
  if (emit_move_sequence (operands, SFmode))
    DONE;
}")

(define_insn "*movsf_insn"
  [(set (match_operand:SF 0 "reg_or_nonsymb_mem_operand" "=f,r,f,r,Q,Q")
	(match_operand:SF 1 "reg_or_nonsymb_mem_operand" "f,r,Q,Q,f,r"))]
  "TARGET_FPU
   && (register_operand (operands[0], SFmode)
       || register_operand (operands[1], SFmode))"
  "@@
   fmovs %1,%0
   mov %1,%0
   ld %1,%0
   ld %1,%0
   st %1,%0
   st %1,%0"
  [(set_attr "type" "fp,move,fpload,load,fpstore,store")])

;; Exactly the same as above, except that all `f' cases are deleted.
;; This is necessary to prevent reload from ever trying to use a `f' reg
;; when -mno-fpu.

(define_insn "*movsf_no_f_insn"
  [(set (match_operand:SF 0 "reg_or_nonsymb_mem_operand" "=r,r,Q")
	(match_operand:SF 1 "reg_or_nonsymb_mem_operand" "r,Q,r"))]
  "! TARGET_FPU
   && (register_operand (operands[0], SFmode)
       || register_operand (operands[1], SFmode))"
  "@@
   mov %1,%0
   ld %1,%0
   st %1,%0"
  [(set_attr "type" "move,load,store")])

(define_insn "*store_sf"
  [(set (mem:SF (match_operand:SI 0 "symbolic_operand" "i"))
	(match_operand:SF 1 "reg_or_0_operand" "rfG"))
   (clobber (match_scratch:SI 2 "=&r"))]
  "(reload_completed || reload_in_progress)
   && ! TARGET_PTR64"
  "sethi %%hi(%a0),%2\;st %r1,[%2+%%lo(%a0)]"
  [(set_attr "type" "store")
   (set_attr "length" "2")])

;; This pattern forces (set (reg:DF ...) (const_double ...))
;; to be reloaded by putting the constant into memory.
;; It must come before the more general movdf pattern.

(define_insn "*movdf_const_insn"
  [(set (match_operand:DF 0 "general_operand" "=?r,e,o")
	(match_operand:DF 1 "" "?F,m,G"))]
  "TARGET_FPU
   && GET_CODE (operands[1]) == CONST_DOUBLE
   && (GET_CODE (operands[0]) == REG
       || fp_zero_operand (operands[1]))"
  "*
{
  switch (which_alternative)
    {
    case 0:
      return output_move_double (operands);
    case 1:
      return output_fp_move_double (operands);
    case 2:
      if (TARGET_ARCH64)
	{
	  return \"stx %%g0,%0\";
	}
      else
	{
	  operands[1] = adj_offsettable_operand (operands[0], 4);
	  return \"st %%g0,%0\;st %%g0,%1\";
	}
    }
}"
  [(set_attr "type" "load,fpload,store")
   (set_attr "length" "3,3,3")])

(define_expand "movdf"
  [(set (match_operand:DF 0 "general_operand" "")
	(match_operand:DF 1 "general_operand" ""))]
  ""
  "
{
  if (emit_move_sequence (operands, DFmode))
    DONE;
}")

(define_insn "*movdf_insn"
  [(set (match_operand:DF 0 "reg_or_nonsymb_mem_operand" "=T,U,e,r,Q,Q,e,r")
	(match_operand:DF 1 "reg_or_nonsymb_mem_operand" "U,T,e,r,e,r,Q,Q"))]
  "TARGET_FPU
   && (register_operand (operands[0], DFmode)
       || register_operand (operands[1], DFmode))"
  "*
{
  if (FP_REG_P (operands[0]) || FP_REG_P (operands[1]))
    return output_fp_move_double (operands);
  return output_move_double (operands);
}"
  [(set_attr "type" "fpstore,fpload,fp,move,fpstore,store,fpload,load")
   (set_attr "length" "1,1,2,2,3,3,3,3")])

;; Exactly the same as above, except that all `e' cases are deleted.
;; This is necessary to prevent reload from ever trying to use a `e' reg
;; when -mno-fpu.

(define_insn "*movdf_no_e_insn"
  [(set (match_operand:DF 0 "reg_or_nonsymb_mem_operand" "=T,U,r,Q,&r")
	(match_operand:DF 1 "reg_or_nonsymb_mem_operand" "U,T,r,r,Q"))]
  "! TARGET_FPU
   && (register_operand (operands[0], DFmode)
       || register_operand (operands[1], DFmode))"
  "* return output_move_double (operands);"
  [(set_attr "type" "store,load,move,store,load")
   (set_attr "length" "1,1,2,3,3")])

;; Must handle overlapping registers here, since parameters can be unaligned
;; in registers.

(define_split
  [(set (match_operand:DF 0 "register_operand" "")
	(match_operand:DF 1 "register_operand" ""))]
  "! TARGET_ARCH64 && reload_completed
   && REGNO (operands[0]) < SPARC_FIRST_V9_FP_REG
   && REGNO (operands[1]) < SPARC_FIRST_V9_FP_REG"
  [(set (match_dup 2) (match_dup 3))
   (set (match_dup 4) (match_dup 5))]
  "
{
  rtx first_set = operand_subword (operands[0], 0, 0, DFmode);
  rtx second_use = operand_subword (operands[1], 1, 0, DFmode);

  if (REGNO (first_set) == REGNO (second_use))
    {
      operands[2] = operand_subword (operands[0], 1, 0, DFmode);
      operands[3] = second_use;
      operands[4] = first_set;
      operands[5] = operand_subword (operands[1], 0, 0, DFmode);
    }
  else
    {
      operands[2] = first_set;
      operands[3] = operand_subword (operands[1], 0, 0, DFmode);
      operands[4] = operand_subword (operands[0], 1, 0, DFmode);
      operands[5] = second_use;
    }
}")

(define_insn "*store_df"
  [(set (mem:DF (match_operand:SI 0 "symbolic_operand" "i,i"))
	(match_operand:DF 1 "reg_or_0_operand" "re,G"))
   (clobber (match_scratch:SI 2 "=&r,&r"))]
  "(reload_completed || reload_in_progress)
   && ! TARGET_PTR64"
  "*
{
  output_asm_insn (\"sethi %%hi(%a0),%2\", operands);
  if (which_alternative == 0)
    return \"std %1,[%2+%%lo(%a0)]\";
  else
    return \"st %%g0,[%2+%%lo(%a0)]\;st %%g0,[%2+%%lo(%a0+4)]\";
}"
  [(set_attr "type" "store")
   (set_attr "length" "3")])

;; This pattern forces (set (reg:TF ...) (const_double ...))
;; to be reloaded by putting the constant into memory.
;; It must come before the more general movtf pattern.
(define_insn "*movtf_const_insn"
  [(set (match_operand:TF 0 "general_operand" "=?r,e,o")
	(match_operand:TF 1 "" "?F,m,G"))]
  "TARGET_FPU
   && GET_CODE (operands[1]) == CONST_DOUBLE
   && (GET_CODE (operands[0]) == REG
       || fp_zero_operand (operands[1]))"
  "*
{
  switch (which_alternative)
    {
    case 0:
      return output_move_quad (operands);
    case 1:
      return output_fp_move_quad (operands);
    case 2:
      if (TARGET_ARCH64)
	{
	  operands[1] = adj_offsettable_operand (operands[0], 8);
	  return \"stx %%g0,%0\;stx %%g0,%1\";
	}
      else
	{
	  /* ??? Do we run off the end of the array here? */
	  operands[1] = adj_offsettable_operand (operands[0], 4);
	  operands[2] = adj_offsettable_operand (operands[0], 8);
	  operands[3] = adj_offsettable_operand (operands[0], 12);
	  return \"st %%g0,%0\;st %%g0,%1\;st %%g0,%2\;st %%g0,%3\";
	}
    }
}"
  [(set_attr "type" "load,fpload,store")
   (set_attr "length" "5,5,5")])

(define_expand "movtf"
  [(set (match_operand:TF 0 "general_operand" "")
	(match_operand:TF 1 "general_operand" ""))]
  ""
  "
{
  if (emit_move_sequence (operands, TFmode))
    DONE;
}")

(define_insn "*movtf_insn"
  [(set (match_operand:TF 0 "reg_or_nonsymb_mem_operand" "=e,r,Q,Q,e,&r")
	(match_operand:TF 1 "reg_or_nonsymb_mem_operand" "e,r,e,r,Q,Q"))]
  "TARGET_FPU
   && (register_operand (operands[0], TFmode)
       || register_operand (operands[1], TFmode))"
  "*
{
  if (FP_REG_P (operands[0]) || FP_REG_P (operands[1]))
    return output_fp_move_quad (operands);
  return output_move_quad (operands);
}"
  [(set_attr "type" "fp,move,fpstore,store,fpload,load")
   (set_attr "length" "4,4,5,5,5,5")])

;; Exactly the same as above, except that all `e' cases are deleted.
;; This is necessary to prevent reload from ever trying to use a `e' reg
;; when -mno-fpu.

(define_insn "*movtf_no_e_insn"
  [(set (match_operand:TF 0 "reg_or_nonsymb_mem_operand" "=r,Q,&r")
	(match_operand:TF 1 "reg_or_nonsymb_mem_operand" "r,r,Q"))]
  "! TARGET_FPU
   && (register_operand (operands[0], TFmode)
       || register_operand (operands[1], TFmode))"
  "*
{
  if (FP_REG_P (operands[0]) || FP_REG_P (operands[1]))
    return output_fp_move_quad (operands);
  return output_move_quad (operands);
}"
  [(set_attr "type" "move,store,load")
   (set_attr "length" "4,5,5")])

;; This is disabled because it does not work.  Long doubles have only 8
;; byte alignment.  Adding an offset of 8 or 12 to an 8 byte aligned %lo may 
;; cause it to overflow.  See also GO_IF_LEGITIMATE_ADDRESS.
(define_insn "*store_tf"
  [(set (mem:TF (match_operand:SI 0 "symbolic_operand" "i,i"))
	(match_operand:TF 1 "reg_or_0_operand" "re,G"))
   (clobber (match_scratch:SI 2 "=&r,&r"))]
  "0 && (reload_completed || reload_in_progress)
   && ! TARGET_PTR64"
  "*
{
  output_asm_insn (\"sethi %%hi(%a0),%2\", operands);
  if (which_alternative == 0)
    return \"std %1,[%2+%%lo(%a0)]\;std %S1,[%2+%%lo(%a0+8)]\";
  else
    return \"st %%g0,[%2+%%lo(%a0)]\;st %%g0,[%2+%%lo(%a0+4)]\; st %%g0,[%2+%%lo(%a0+8)]\;st %%g0,[%2+%%lo(%a0+12)]\";
}"
  [(set_attr "type" "store")
   (set_attr "length" "5")])

;; Sparc V9 conditional move instructions.

;; We can handle larger constants here for some flavors, but for now we keep
;; it simple and only allow those constants supported by all flavours.
;; Note that emit_conditional_move canonicalizes operands 2,3 so that operand
;; 3 contains the constant if one is present, but we handle either for
;; generality (sparc.c puts a constant in operand 2).

(define_expand "movqicc"
  [(set (match_operand:QI 0 "register_operand" "")
	(if_then_else:QI (match_operand 1 "comparison_operator" "")
			 (match_operand:QI 2 "arith10_operand" "")
			 (match_operand:QI 3 "arith10_operand" "")))]
  "TARGET_V9"
  "
{
  enum rtx_code code = GET_CODE (operands[1]);

  if (GET_MODE (sparc_compare_op0) == DImode
      && ! TARGET_ARCH64)
    FAIL;

  if (sparc_compare_op1 == const0_rtx
      && GET_CODE (sparc_compare_op0) == REG
      && GET_MODE (sparc_compare_op0) == DImode
      && v9_regcmp_p (code))
    {
      operands[1] = gen_rtx (code, DImode,
			     sparc_compare_op0, sparc_compare_op1);
    }
  else
    {
      rtx cc_reg = gen_compare_reg (code,
				    sparc_compare_op0, sparc_compare_op1);
      operands[1] = gen_rtx (code, GET_MODE (cc_reg), cc_reg, const0_rtx);
    }
}")

(define_expand "movhicc"
  [(set (match_operand:HI 0 "register_operand" "")
	(if_then_else:HI (match_operand 1 "comparison_operator" "")
			 (match_operand:HI 2 "arith10_operand" "")
			 (match_operand:HI 3 "arith10_operand" "")))]
  "TARGET_V9"
  "
{
  enum rtx_code code = GET_CODE (operands[1]);

  if (GET_MODE (sparc_compare_op0) == DImode
      && ! TARGET_ARCH64)
    FAIL;

  if (sparc_compare_op1 == const0_rtx
      && GET_CODE (sparc_compare_op0) == REG
      && GET_MODE (sparc_compare_op0) == DImode
      && v9_regcmp_p (code))
    {
      operands[1] = gen_rtx (code, DImode,
			     sparc_compare_op0, sparc_compare_op1);
    }
  else
    {
      rtx cc_reg = gen_compare_reg (code,
				    sparc_compare_op0, sparc_compare_op1);
      operands[1] = gen_rtx (code, GET_MODE (cc_reg), cc_reg, const0_rtx);
    }
}")

(define_expand "movsicc"
  [(set (match_operand:SI 0 "register_operand" "")
	(if_then_else:SI (match_operand 1 "comparison_operator" "")
			 (match_operand:SI 2 "arith10_operand" "")
			 (match_operand:SI 3 "arith10_operand" "")))]
  "TARGET_V9"
  "
{
  enum rtx_code code = GET_CODE (operands[1]);

  if (GET_MODE (sparc_compare_op0) == DImode
      && ! TARGET_ARCH64)
    FAIL;

  if (sparc_compare_op1 == const0_rtx
      && GET_CODE (sparc_compare_op0) == REG
      && GET_MODE (sparc_compare_op0) == DImode
      && v9_regcmp_p (code))
    {
      operands[1] = gen_rtx (code, DImode,
			     sparc_compare_op0, sparc_compare_op1);
    }
  else
    {
      rtx cc_reg = gen_compare_reg (code,
				    sparc_compare_op0, sparc_compare_op1);
      operands[1] = gen_rtx (code, GET_MODE (cc_reg), cc_reg, const0_rtx);
    }
}")

(define_expand "movdicc"
  [(set (match_operand:DI 0 "register_operand" "")
	(if_then_else:DI (match_operand 1 "comparison_operator" "")
			 (match_operand:DI 2 "arith10_double_operand" "")
			 (match_operand:DI 3 "arith10_double_operand" "")))]
  "TARGET_ARCH64"
  "
{
  enum rtx_code code = GET_CODE (operands[1]);

  if (sparc_compare_op1 == const0_rtx
      && GET_CODE (sparc_compare_op0) == REG
      && GET_MODE (sparc_compare_op0) == DImode
      && v9_regcmp_p (code))
    {
      operands[1] = gen_rtx (code, DImode,
			     sparc_compare_op0, sparc_compare_op1);
    }
  else
    {
      rtx cc_reg = gen_compare_reg (code,
				    sparc_compare_op0, sparc_compare_op1);
      operands[1] = gen_rtx (code, GET_MODE (cc_reg), cc_reg, const0_rtx);
    }
}")

(define_expand "movsfcc"
  [(set (match_operand:SF 0 "register_operand" "")
	(if_then_else:SF (match_operand 1 "comparison_operator" "")
			 (match_operand:SF 2 "register_operand" "")
			 (match_operand:SF 3 "register_operand" "")))]
  "TARGET_V9 && TARGET_FPU"
  "
{
  enum rtx_code code = GET_CODE (operands[1]);

  if (GET_MODE (sparc_compare_op0) == DImode
      && ! TARGET_ARCH64)
    FAIL;

  if (sparc_compare_op1 == const0_rtx
      && GET_CODE (sparc_compare_op0) == REG
      && GET_MODE (sparc_compare_op0) == DImode
      && v9_regcmp_p (code))
    {
      operands[1] = gen_rtx (code, DImode,
			     sparc_compare_op0, sparc_compare_op1);
    }
  else
    {
      rtx cc_reg = gen_compare_reg (code,
				    sparc_compare_op0, sparc_compare_op1);
      operands[1] = gen_rtx (code, GET_MODE (cc_reg), cc_reg, const0_rtx);
    }
}")

(define_expand "movdfcc"
  [(set (match_operand:DF 0 "register_operand" "")
	(if_then_else:DF (match_operand 1 "comparison_operator" "")
			 (match_operand:DF 2 "register_operand" "")
			 (match_operand:DF 3 "register_operand" "")))]
  "TARGET_V9 && TARGET_FPU"
  "
{
  enum rtx_code code = GET_CODE (operands[1]);

  if (GET_MODE (sparc_compare_op0) == DImode
      && ! TARGET_ARCH64)
    FAIL;

  if (sparc_compare_op1 == const0_rtx
      && GET_CODE (sparc_compare_op0) == REG
      && GET_MODE (sparc_compare_op0) == DImode
      && v9_regcmp_p (code))
    {
      operands[1] = gen_rtx (code, DImode,
			     sparc_compare_op0, sparc_compare_op1);
    }
  else
    {
      rtx cc_reg = gen_compare_reg (code,
				    sparc_compare_op0, sparc_compare_op1);
      operands[1] = gen_rtx (code, GET_MODE (cc_reg), cc_reg, const0_rtx);
    }
}")

(define_expand "movtfcc"
  [(set (match_operand:TF 0 "register_operand" "")
	(if_then_else:TF (match_operand 1 "comparison_operator" "")
			 (match_operand:TF 2 "register_operand" "")
			 (match_operand:TF 3 "register_operand" "")))]
  "TARGET_V9 && TARGET_FPU"
  "
{
  enum rtx_code code = GET_CODE (operands[1]);

  if (GET_MODE (sparc_compare_op0) == DImode
      && ! TARGET_ARCH64)
    FAIL;

  if (sparc_compare_op1 == const0_rtx
      && GET_CODE (sparc_compare_op0) == REG
      && GET_MODE (sparc_compare_op0) == DImode
      && v9_regcmp_p (code))
    {
      operands[1] = gen_rtx (code, DImode,
			     sparc_compare_op0, sparc_compare_op1);
    }
  else
    {
      rtx cc_reg = gen_compare_reg (code,
				    sparc_compare_op0, sparc_compare_op1);
      operands[1] = gen_rtx (code, GET_MODE (cc_reg), cc_reg, const0_rtx);
    }
}")

;; Conditional move define_insns.

(define_insn "*movqi_cc_sp64"
  [(set (match_operand:QI 0 "register_operand" "=r,r")
	(if_then_else:QI (match_operator 1 "comparison_operator"
				[(match_operand 2 "icc_or_fcc_reg_operand" "X,X")
				 (const_int 0)])
		      (match_operand:QI 3 "arith11_operand" "rL,0")
		      (match_operand:QI 4 "arith11_operand" "0,rL")))]
  "TARGET_V9"
  "@@
   mov%C1 %x2,%3,%0
   mov%c1 %x2,%4,%0"
  [(set_attr "type" "cmove")])

(define_insn "*movhi_cc_sp64"
  [(set (match_operand:HI 0 "register_operand" "=r,r")
	(if_then_else:HI (match_operator 1 "comparison_operator"
				[(match_operand 2 "icc_or_fcc_reg_operand" "X,X")
				 (const_int 0)])
		      (match_operand:HI 3 "arith11_operand" "rL,0")
		      (match_operand:HI 4 "arith11_operand" "0,rL")))]
  "TARGET_V9"
  "@@
   mov%C1 %x2,%3,%0
   mov%c1 %x2,%4,%0"
  [(set_attr "type" "cmove")])

(define_insn "*movsi_cc_sp64"
  [(set (match_operand:SI 0 "register_operand" "=r,r")
	(if_then_else:SI (match_operator 1 "comparison_operator"
				[(match_operand 2 "icc_or_fcc_reg_operand" "X,X")
				 (const_int 0)])
		      (match_operand:SI 3 "arith11_operand" "rL,0")
		      (match_operand:SI 4 "arith11_operand" "0,rL")))]
  "TARGET_V9"
  "@@
   mov%C1 %x2,%3,%0
   mov%c1 %x2,%4,%0"
  [(set_attr "type" "cmove")])

;; ??? The constraints of operands 3,4 need work.
(define_insn "*movdi_cc_sp64"
  [(set (match_operand:DI 0 "register_operand" "=r,r")
	(if_then_else:DI (match_operator 1 "comparison_operator"
				[(match_operand 2 "icc_or_fcc_reg_operand" "X,X")
				 (const_int 0)])
		      (match_operand:DI 3 "arith11_double_operand" "rLH,0")
		      (match_operand:DI 4 "arith11_double_operand" "0,rLH")))]
  "TARGET_ARCH64"
  "@@
   mov%C1 %x2,%3,%0
   mov%c1 %x2,%4,%0"
  [(set_attr "type" "cmove")])

(define_insn "*movsf_cc_sp64"
  [(set (match_operand:SF 0 "register_operand" "=f,f")
	(if_then_else:SF (match_operator 1 "comparison_operator"
				[(match_operand 2 "icc_or_fcc_reg_operand" "X,X")
				 (const_int 0)])
		      (match_operand:SF 3 "register_operand" "f,0")
		      (match_operand:SF 4 "register_operand" "0,f")))]
  "TARGET_V9 && TARGET_FPU"
  "@@
   fmovs%C1 %x2,%3,%0
   fmovs%c1 %x2,%4,%0"
  [(set_attr "type" "cmove")])

(define_insn "*movdf_cc_sp64"
  [(set (match_operand:DF 0 "register_operand" "=e,e")
	(if_then_else:DF (match_operator 1 "comparison_operator"
				[(match_operand 2 "icc_or_fcc_reg_operand" "X,X")
				 (const_int 0)])
		      (match_operand:DF 3 "register_operand" "e,0")
		      (match_operand:DF 4 "register_operand" "0,e")))]
  "TARGET_V9 && TARGET_FPU"
  "@@
   fmovd%C1 %x2,%3,%0
   fmovd%c1 %x2,%4,%0"
  [(set_attr "type" "cmove")])

(define_insn "*movtf_cc_sp64"
  [(set (match_operand:TF 0 "register_operand" "=e,e")
	(if_then_else:TF (match_operator 1 "comparison_operator"
				[(match_operand 2 "icc_or_fcc_reg_operand" "X,X")
				 (const_int 0)])
		      (match_operand:TF 3 "register_operand" "e,0")
		      (match_operand:TF 4 "register_operand" "0,e")))]
  "TARGET_V9 && TARGET_FPU && TARGET_HARD_QUAD"
  "@@
   fmovq%C1 %x2,%3,%0
   fmovq%c1 %x2,%4,%0"
  [(set_attr "type" "cmove")])

(define_insn "*movqi_cc_reg_sp64"
  [(set (match_operand:QI 0 "register_operand" "=r,r")
	(if_then_else:QI (match_operator 1 "v9_regcmp_op"
				[(match_operand:DI 2 "register_operand" "r,r")
				 (const_int 0)])
		      (match_operand:QI 3 "arith10_operand" "rM,0")
		      (match_operand:QI 4 "arith10_operand" "0,rM")))]
  "TARGET_ARCH64"
  "@@
   movr%D1 %2,%r3,%0
   movr%d1 %2,%r4,%0"
  [(set_attr "type" "cmove")])

(define_insn "*movhi_cc_reg_sp64"
  [(set (match_operand:HI 0 "register_operand" "=r,r")
	(if_then_else:HI (match_operator 1 "v9_regcmp_op"
				[(match_operand:DI 2 "register_operand" "r,r")
				 (const_int 0)])
		      (match_operand:HI 3 "arith10_operand" "rM,0")
		      (match_operand:HI 4 "arith10_operand" "0,rM")))]
  "TARGET_ARCH64"
  "@@
   movr%D1 %2,%r3,%0
   movr%d1 %2,%r4,%0"
  [(set_attr "type" "cmove")])

(define_insn "*movsi_cc_reg_sp64"
  [(set (match_operand:SI 0 "register_operand" "=r,r")
	(if_then_else:SI (match_operator 1 "v9_regcmp_op"
				[(match_operand:DI 2 "register_operand" "r,r")
				 (const_int 0)])
		      (match_operand:SI 3 "arith10_operand" "rM,0")
		      (match_operand:SI 4 "arith10_operand" "0,rM")))]
  "TARGET_ARCH64"
  "@@
   movr%D1 %2,%r3,%0
   movr%d1 %2,%r4,%0"
  [(set_attr "type" "cmove")])

;; ??? The constraints of operands 3,4 need work.
(define_insn "*movdi_cc_reg_sp64"
  [(set (match_operand:DI 0 "register_operand" "=r,r")
	(if_then_else:DI (match_operator 1 "v9_regcmp_op"
				[(match_operand:DI 2 "register_operand" "r,r")
				 (const_int 0)])
		      (match_operand:DI 3 "arith10_double_operand" "rMH,0")
		      (match_operand:DI 4 "arith10_double_operand" "0,rMH")))]
  "TARGET_ARCH64"
  "@@
   movr%D1 %2,%r3,%0
   movr%d1 %2,%r4,%0"
  [(set_attr "type" "cmove")])

(define_insn "*movsf_cc_reg_sp64"
  [(set (match_operand:SF 0 "register_operand" "=f,f")
	(if_then_else:SF (match_operator 1 "v9_regcmp_op"
				[(match_operand:DI 2 "register_operand" "r,r")
				 (const_int 0)])
		      (match_operand:SF 3 "register_operand" "f,0")
		      (match_operand:SF 4 "register_operand" "0,f")))]
  "TARGET_ARCH64 && TARGET_FPU"
  "@@
   fmovrs%D1 %2,%3,%0
   fmovrs%d1 %2,%4,%0"
  [(set_attr "type" "cmove")])

(define_insn "*movdf_cc_reg_sp64"
  [(set (match_operand:DF 0 "register_operand" "=e,e")
	(if_then_else:DF (match_operator 1 "v9_regcmp_op"
				[(match_operand:DI 2 "register_operand" "r,r")
				 (const_int 0)])
		      (match_operand:DF 3 "register_operand" "e,0")
		      (match_operand:DF 4 "register_operand" "0,e")))]
  "TARGET_ARCH64 && TARGET_FPU"
  "@@
   fmovrd%D1 %2,%3,%0
   fmovrd%d1 %2,%4,%0"
  [(set_attr "type" "cmove")])

(define_insn "*movtf_cc_reg_sp64"
  [(set (match_operand:TF 0 "register_operand" "=e,e")
	(if_then_else:TF (match_operator 1 "v9_regcmp_op"
				[(match_operand:DI 2 "register_operand" "r,r")
				 (const_int 0)])
		      (match_operand:TF 3 "register_operand" "e,0")
		      (match_operand:TF 4 "register_operand" "0,e")))]
  "TARGET_ARCH64 && TARGET_FPU"
  "@@
   fmovrq%D1 %2,%3,%0
   fmovrq%d1 %2,%4,%0"
  [(set_attr "type" "cmove")])

;;- zero extension instructions

;; These patterns originally accepted general_operands, however, slightly
;; better code is generated by only accepting register_operands, and then
;; letting combine generate the ldu[hb] insns.

(define_expand "zero_extendhisi2"
  [(set (match_operand:SI 0 "register_operand" "")
	(zero_extend:SI (match_operand:HI 1 "register_operand" "")))]
  ""
  "
{
  rtx temp = gen_reg_rtx (SImode);
  rtx shift_16 = GEN_INT (16);
  int op1_subword = 0;

  if (GET_CODE (operand1) == SUBREG)
    {
      op1_subword = SUBREG_WORD (operand1);
      operand1 = XEXP (operand1, 0);
    }

  emit_insn (gen_ashlsi3 (temp, gen_rtx (SUBREG, SImode, operand1,
					 op1_subword),
			  shift_16));
  emit_insn (gen_lshrsi3 (operand0, temp, shift_16));
  DONE;
}")

(define_insn "*zero_extendhisi2_insn"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(zero_extend:SI (match_operand:HI 1 "memory_operand" "m")))]
  ""
  "lduh %1,%0"
  [(set_attr "type" "load")])

(define_expand "zero_extendqihi2"
  [(set (match_operand:HI 0 "register_operand" "")
	(zero_extend:HI (match_operand:QI 1 "register_operand" "")))]
  ""
  "")

(define_insn "*zero_extendqihi2_insn"
  [(set (match_operand:HI 0 "register_operand" "=r,r")
	(zero_extend:HI (match_operand:QI 1 "sparc_operand" "r,Q")))]
  "GET_CODE (operands[1]) != CONST_INT"
  "@@
   and %1,0xff,%0
   ldub %1,%0"
  [(set_attr "type" "unary,load")
   (set_attr "length" "1")])

(define_expand "zero_extendqisi2"
  [(set (match_operand:SI 0 "register_operand" "")
	(zero_extend:SI (match_operand:QI 1 "register_operand" "")))]
  ""
  "")

(define_insn "*zero_extendqisi2_insn"
  [(set (match_operand:SI 0 "register_operand" "=r,r")
	(zero_extend:SI (match_operand:QI 1 "sparc_operand" "r,Q")))]
  "GET_CODE (operands[1]) != CONST_INT"
  "@@
   and %1,0xff,%0
   ldub %1,%0"
  [(set_attr "type" "unary,load")
   (set_attr "length" "1")])

(define_expand "zero_extendqidi2"
  [(set (match_operand:DI 0 "register_operand" "")
	(zero_extend:DI (match_operand:QI 1 "register_operand" "")))]
  "TARGET_ARCH64"
  "")

(define_insn "*zero_extendqidi2_insn"
  [(set (match_operand:DI 0 "register_operand" "=r,r")
	(zero_extend:DI (match_operand:QI 1 "sparc_operand" "r,Q")))]
  "TARGET_ARCH64 && GET_CODE (operands[1]) != CONST_INT"
  "@@
   and %1,0xff,%0
   ldub %1,%0"
  [(set_attr "type" "unary,load")
   (set_attr "length" "1")])

(define_expand "zero_extendhidi2"
  [(set (match_operand:DI 0 "register_operand" "")
	(zero_extend:DI (match_operand:HI 1 "register_operand" "")))]
  "TARGET_ARCH64"
  "
{
  rtx temp = gen_reg_rtx (DImode);
  rtx shift_48 = GEN_INT (48);
  int op1_subword = 0;

  if (GET_CODE (operand1) == SUBREG)
    {
      op1_subword = SUBREG_WORD (operand1);
      operand1 = XEXP (operand1, 0);
    }

  emit_insn (gen_ashldi3 (temp, gen_rtx (SUBREG, DImode, operand1,
					 op1_subword),
			  shift_48));
  emit_insn (gen_lshrdi3 (operand0, temp, shift_48));
  DONE;
}")

(define_insn "*zero_extendhidi2_insn"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(zero_extend:DI (match_operand:HI 1 "memory_operand" "m")))]
  "TARGET_ARCH64"
  "lduh %1,%0"
  [(set_attr "type" "load")])

;; ??? Write truncdisi pattern using sra?

(define_expand "zero_extendsidi2"
  [(set (match_operand:DI 0 "register_operand" "")
	(zero_extend:DI (match_operand:SI 1 "register_operand" "")))]
  "TARGET_ARCH64"
  "")

(define_insn "*zero_extendsidi2_insn"
  [(set (match_operand:DI 0 "register_operand" "=r,r")
	(zero_extend:DI (match_operand:SI 1 "sparc_operand" "r,Q")))]
  "TARGET_ARCH64 && GET_CODE (operands[1]) != CONST_INT"
  "@@
   srl %1,0,%0
   lduw %1,%0"
  [(set_attr "type" "unary,load")
   (set_attr "length" "1")])

;; Simplify comparisons of extended values.

(define_insn "*cmp_zero_extendqisi2"
  [(set (reg:CC 100)
	(compare:CC (zero_extend:SI (match_operand:QI 0 "register_operand" "r"))
		    (const_int 0)))]
  ""
  "andcc %0,0xff,%%g0"
  [(set_attr "type" "compare")])

(define_insn "*cmp_zero_extendqisi2_set"
  [(set (reg:CC 100)
	(compare:CC (zero_extend:SI (match_operand:QI 1 "register_operand" "r"))
		    (const_int 0)))
   (set (match_operand:SI 0 "register_operand" "=r")
	(zero_extend:SI (match_dup 1)))]
  ""
  "andcc %1,0xff,%0"
  [(set_attr "type" "unary")])

;; Similarly, handle SI->QI mode truncation followed by a compare.

(define_insn "*cmp_siqi_trunc"
  [(set (reg:CC 100)
	(compare:CC (subreg:QI (match_operand:SI 0 "register_operand" "r") 0)
		    (const_int 0)))]
  ""
  "andcc %0,0xff,%%g0"
  [(set_attr "type" "compare")])

(define_insn "*cmp_siqi_trunc_set"
  [(set (reg:CC 100)
	(compare:CC (subreg:QI (match_operand:SI 1 "register_operand" "r") 0)
		    (const_int 0)))
   (set (match_operand:QI 0 "register_operand" "=r")
	(match_dup 1))]
  ""
  "andcc %1,0xff,%0"
  [(set_attr "type" "unary")])

;;- sign extension instructions

;; These patterns originally accepted general_operands, however, slightly
;; better code is generated by only accepting register_operands, and then
;; letting combine generate the lds[hb] insns.

(define_expand "extendhisi2"
  [(set (match_operand:SI 0 "register_operand" "")
	(sign_extend:SI (match_operand:HI 1 "register_operand" "")))]
  ""
  "
{
  rtx temp = gen_reg_rtx (SImode);
  rtx shift_16 = GEN_INT (16);
  int op1_subword = 0;

  if (GET_CODE (operand1) == SUBREG)
    {
      op1_subword = SUBREG_WORD (operand1);
      operand1 = XEXP (operand1, 0);
    }

  emit_insn (gen_ashlsi3 (temp, gen_rtx (SUBREG, SImode, operand1,
					 op1_subword),
			  shift_16));
  emit_insn (gen_ashrsi3 (operand0, temp, shift_16));
  DONE;
}")

(define_insn "*sign_extendhisi2_insn"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(sign_extend:SI (match_operand:HI 1 "memory_operand" "m")))]
  ""
  "ldsh %1,%0"
  [(set_attr "type" "load")])

(define_expand "extendqihi2"
  [(set (match_operand:HI 0 "register_operand" "")
	(sign_extend:HI (match_operand:QI 1 "register_operand" "")))]
  ""
  "
{
  rtx temp = gen_reg_rtx (SImode);
  rtx shift_24 = GEN_INT (24);
  int op1_subword = 0;
  int op0_subword = 0;

  if (GET_CODE (operand1) == SUBREG)
    {
      op1_subword = SUBREG_WORD (operand1);
      operand1 = XEXP (operand1, 0);
    }
  if (GET_CODE (operand0) == SUBREG)
    {
      op0_subword = SUBREG_WORD (operand0);
      operand0 = XEXP (operand0, 0);
    }
  emit_insn (gen_ashlsi3 (temp, gen_rtx (SUBREG, SImode, operand1,
					 op1_subword),
			  shift_24));
  if (GET_MODE (operand0) != SImode)
    operand0 = gen_rtx (SUBREG, SImode, operand0, op0_subword);
  emit_insn (gen_ashrsi3 (operand0, temp, shift_24));
  DONE;
}")

(define_insn "*sign_extendqihi2_insn"
  [(set (match_operand:HI 0 "register_operand" "=r")
	(sign_extend:HI (match_operand:QI 1 "memory_operand" "m")))]
  ""
  "ldsb %1,%0"
  [(set_attr "type" "load")])

(define_expand "extendqisi2"
  [(set (match_operand:SI 0 "register_operand" "")
	(sign_extend:SI (match_operand:QI 1 "register_operand" "")))]
  ""
  "
{
  rtx temp = gen_reg_rtx (SImode);
  rtx shift_24 = GEN_INT (24);
  int op1_subword = 0;

  if (GET_CODE (operand1) == SUBREG)
    {
      op1_subword = SUBREG_WORD (operand1);
      operand1 = XEXP (operand1, 0);
    }

  emit_insn (gen_ashlsi3 (temp, gen_rtx (SUBREG, SImode, operand1,
					 op1_subword),
			  shift_24));
  emit_insn (gen_ashrsi3 (operand0, temp, shift_24));
  DONE;
}")

(define_insn "*sign_extendqisi2_insn"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(sign_extend:SI (match_operand:QI 1 "memory_operand" "m")))]
  ""
  "ldsb %1,%0"
  [(set_attr "type" "load")])

(define_expand "extendqidi2"
  [(set (match_operand:DI 0 "register_operand" "")
	(sign_extend:DI (match_operand:QI 1 "register_operand" "")))]
  "TARGET_ARCH64"
  "
{
  rtx temp = gen_reg_rtx (DImode);
  rtx shift_56 = GEN_INT (56);
  int op1_subword = 0;

  if (GET_CODE (operand1) == SUBREG)
    {
      op1_subword = SUBREG_WORD (operand1);
      operand1 = XEXP (operand1, 0);
    }

  emit_insn (gen_ashldi3 (temp, gen_rtx (SUBREG, DImode, operand1,
					 op1_subword),
			  shift_56));
  emit_insn (gen_ashrdi3 (operand0, temp, shift_56));
  DONE;
}")

(define_insn "*sign_extendqidi2_insn"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(sign_extend:DI (match_operand:QI 1 "memory_operand" "m")))]
  "TARGET_ARCH64"
  "ldsb %1,%0"
  [(set_attr "type" "load")])

(define_expand "extendhidi2"
  [(set (match_operand:DI 0 "register_operand" "")
	(sign_extend:DI (match_operand:HI 1 "register_operand" "")))]
  "TARGET_ARCH64"
  "
{
  rtx temp = gen_reg_rtx (DImode);
  rtx shift_48 = GEN_INT (48);
  int op1_subword = 0;

  if (GET_CODE (operand1) == SUBREG)
    {
      op1_subword = SUBREG_WORD (operand1);
      operand1 = XEXP (operand1, 0);
    }

  emit_insn (gen_ashldi3 (temp, gen_rtx (SUBREG, DImode, operand1,
					 op1_subword),
			  shift_48));
  emit_insn (gen_ashrdi3 (operand0, temp, shift_48));
  DONE;
}")

(define_insn "*sign_extendhidi2_insn"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(sign_extend:DI (match_operand:HI 1 "memory_operand" "m")))]
  "TARGET_ARCH64"
  "ldsh %1,%0"
  [(set_attr "type" "load")])

(define_expand "extendsidi2"
  [(set (match_operand:DI 0 "register_operand" "")
	(sign_extend:DI (match_operand:SI 1 "register_operand" "")))]
  "TARGET_ARCH64"
  "")

(define_insn "*sign_extendsidi2_insn"
  [(set (match_operand:DI 0 "register_operand" "=r,r")
	(sign_extend:DI (match_operand:SI 1 "sparc_operand" "r,Q")))]
  "TARGET_ARCH64"
  "@@
  sra %1,0,%0
  ldsw %1,%0"
  [(set_attr "type" "unary,load")
   (set_attr "length" "1")])

;; Special pattern for optimizing bit-field compares.  This is needed
;; because combine uses this as a canonical form.

(define_insn "*cmp_zero_extract"
  [(set (reg:CC 100)
	(compare:CC
	 (zero_extract:SI (match_operand:SI 0 "register_operand" "r")
			  (match_operand:SI 1 "small_int" "n")
			  (match_operand:SI 2 "small_int" "n"))
	 (const_int 0)))]
  "INTVAL (operands[2]) > 19"
  "*
{
  int len = INTVAL (operands[1]);
  int pos = 32 - INTVAL (operands[2]) - len;
  unsigned mask = ((1 << len) - 1) << pos;

  operands[1] = GEN_INT (mask);
  return \"andcc %0,%1,%%g0\";
}")

(define_insn "*cmp_zero_extract_sp64"
  [(set (reg:CCX 100)
	(compare:CCX
	 (zero_extract:DI (match_operand:DI 0 "register_operand" "r")
			  (match_operand:SI 1 "small_int" "n")
			  (match_operand:SI 2 "small_int" "n"))
	 (const_int 0)))]
  "TARGET_ARCH64 && INTVAL (operands[2]) > 51"
  "*
{
  int len = INTVAL (operands[1]);
  int pos = 64 - INTVAL (operands[2]) - len;
  unsigned HOST_WIDE_INT mask = (((unsigned HOST_WIDE_INT) 1 << len) - 1) << pos;

  operands[1] = GEN_INT (mask);
  return \"andcc %0,%1,%%g0\";
}")

;; Conversions between float, double and long double.

(define_insn "extendsfdf2"
  [(set (match_operand:DF 0 "register_operand" "=e")
	(float_extend:DF
	 (match_operand:SF 1 "register_operand" "f")))]
  "TARGET_FPU"
  "fstod %1,%0"
  [(set_attr "type" "fp")])

(define_insn "extendsftf2"
  [(set (match_operand:TF 0 "register_operand" "=e")
	(float_extend:TF
	 (match_operand:SF 1 "register_operand" "f")))]
  "TARGET_FPU && TARGET_HARD_QUAD"
  "fstoq %1,%0"
  [(set_attr "type" "fp")])

(define_insn "extenddftf2"
  [(set (match_operand:TF 0 "register_operand" "=e")
	(float_extend:TF
	 (match_operand:DF 1 "register_operand" "e")))]
  "TARGET_FPU && TARGET_HARD_QUAD"
  "fdtoq %1,%0"
  [(set_attr "type" "fp")])

(define_insn "truncdfsf2"
  [(set (match_operand:SF 0 "register_operand" "=f")
	(float_truncate:SF
	 (match_operand:DF 1 "register_operand" "e")))]
  "TARGET_FPU"
  "fdtos %1,%0"
  [(set_attr "type" "fp")])

(define_insn "trunctfsf2"
  [(set (match_operand:SF 0 "register_operand" "=f")
	(float_truncate:SF
	 (match_operand:TF 1 "register_operand" "e")))]
  "TARGET_FPU && TARGET_HARD_QUAD"
  "fqtos %1,%0"
  [(set_attr "type" "fp")])

(define_insn "trunctfdf2"
  [(set (match_operand:DF 0 "register_operand" "=e")
	(float_truncate:DF
	 (match_operand:TF 1 "register_operand" "e")))]
  "TARGET_FPU && TARGET_HARD_QUAD"
  "fqtod %1,%0"
  [(set_attr "type" "fp")])

;; Conversion between fixed point and floating point.

(define_insn "floatsisf2"
  [(set (match_operand:SF 0 "register_operand" "=f")
	(float:SF (match_operand:SI 1 "register_operand" "f")))]
  "TARGET_FPU"
  "fitos %1,%0"
  [(set_attr "type" "fp")])

(define_insn "floatsidf2"
  [(set (match_operand:DF 0 "register_operand" "=e")
	(float:DF (match_operand:SI 1 "register_operand" "f")))]
  "TARGET_FPU"
  "fitod %1,%0"
  [(set_attr "type" "fp")])

(define_insn "floatsitf2"
  [(set (match_operand:TF 0 "register_operand" "=e")
	(float:TF (match_operand:SI 1 "register_operand" "f")))]
  "TARGET_FPU && TARGET_HARD_QUAD"
  "fitoq %1,%0"
  [(set_attr "type" "fp")])

;; Now the same for 64 bit sources.
;; ??? We cannot put DImode values in fp regs (see below near fix_truncdfsi2).

(define_expand "floatdisf2"
  [(parallel [(set (match_operand:SF 0 "register_operand" "")
		   (float:SF (match_operand:DI 1 "general_operand" "")))
	      (clobber (match_dup 2))
	      (clobber (match_dup 3))])]
  "TARGET_ARCH64 && TARGET_FPU"
  "
{
  operands[2] = gen_reg_rtx (DFmode);
  operands[3] = sparc64_fpconv_stack_temp ();
}")

(define_expand "floatdidf2"
  [(parallel [(set (match_operand:DF 0 "register_operand" "")
		   (float:DF (match_operand:DI 1 "general_operand" "")))
	      (clobber (match_dup 2))
	      (clobber (match_dup 3))])]
  "TARGET_ARCH64 && TARGET_FPU"
  "
{
  operands[2] = gen_reg_rtx (DFmode);
  operands[3] = sparc64_fpconv_stack_temp ();
}")

(define_expand "floatditf2"
  [(parallel [(set (match_operand:TF 0 "register_operand" "")
		   (float:TF (match_operand:DI 1 "general_operand" "")))
	      (clobber (match_dup 2))
	      (clobber (match_dup 3))])]
  "TARGET_ARCH64 && TARGET_FPU && TARGET_HARD_QUAD"
  "
{
  operands[2] = gen_reg_rtx (DFmode);
  operands[3] = sparc64_fpconv_stack_temp ();
}")

(define_insn "*floatdisf2_insn"
  [(parallel [(set (match_operand:SF 0 "register_operand" "=f")
		   (float:SF (match_operand:DI 1 "general_operand" "rm")))
	      (clobber (match_operand:DF 2 "register_operand" "=&e"))
	      (clobber (match_operand:DI 3 "memory_operand" "m"))])]
  "TARGET_ARCH64 && TARGET_FPU"
  "*
{
  if (GET_CODE (operands[1]) == MEM)
    output_asm_insn (\"ldd %1,%2\", operands);
  else
    output_asm_insn (\"stx %1,%3\;ldd %3,%2\", operands);
  return \"fxtos %2,%0\";
}"
  [(set_attr "type" "fp")
   (set_attr "length" "3")])

(define_insn "*floatdidf2_insn"
  [(parallel [(set (match_operand:DF 0 "register_operand" "=e")
		   (float:DF (match_operand:DI 1 "general_operand" "rm")))
	      (clobber (match_operand:DF 2 "register_operand" "=&e"))
	      (clobber (match_operand:DI 3 "memory_operand" "m"))])]
  "TARGET_ARCH64 && TARGET_FPU"
  "*
{
  if (GET_CODE (operands[1]) == MEM)
    output_asm_insn (\"ldd %1,%2\", operands);
  else
    output_asm_insn (\"stx %1,%3\;ldd %3,%2\", operands);
  return \"fxtod %2,%0\";
}"
  [(set_attr "type" "fp")
   (set_attr "length" "3")])

(define_insn "*floatditf2_insn"
  [(parallel [(set (match_operand:TF 0 "register_operand" "=e")
		   (float:TF (match_operand:DI 1 "general_operand" "rm")))
	      (clobber (match_operand:DF 2 "register_operand" "=&e"))
	      (clobber (match_operand:DI 3 "memory_operand" "m"))])]
  "TARGET_ARCH64 && TARGET_FPU && TARGET_HARD_QUAD"
  "*
{
  if (GET_CODE (operands[1]) == MEM)
    output_asm_insn (\"ldd %1,%2\", operands);
  else
    output_asm_insn (\"stx %1,%3\;ldd %3,%2\", operands);
  return \"fxtoq %2,%0\";
}"
  [(set_attr "type" "fp")
   (set_attr "length" "3")])

;; ??? Ideally, these are what we would like to use.

(define_insn "floatdisf2_sp64"
  [(set (match_operand:SF 0 "register_operand" "=f")
	(float:SF (match_operand:DI 1 "register_operand" "e")))]
  "0 && TARGET_ARCH64 && TARGET_FPU"
  "fxtos %1,%0"
  [(set_attr "type" "fp")])

(define_insn "floatdidf2_sp64"
  [(set (match_operand:DF 0 "register_operand" "=e")
	(float:DF (match_operand:DI 1 "register_operand" "e")))]
  "0 && TARGET_ARCH64 && TARGET_FPU"
  "fxtod %1,%0"
  [(set_attr "type" "fp")])

(define_insn "floatditf2_sp64"
  [(set (match_operand:TF 0 "register_operand" "=e")
	(float:TF (match_operand:DI 1 "register_operand" "e")))]
  "0 && TARGET_ARCH64 && TARGET_FPU && TARGET_HARD_QUAD"
  "fxtoq %1,%0"
  [(set_attr "type" "fp")])

;; Convert a float to an actual integer.
;; Truncation is performed as part of the conversion.

(define_insn "fix_truncsfsi2"
  [(set (match_operand:SI 0 "register_operand" "=f")
	(fix:SI (fix:SF (match_operand:SF 1 "register_operand" "f"))))]
  "TARGET_FPU"
  "fstoi %1,%0"
  [(set_attr "type" "fp")])

(define_insn "fix_truncdfsi2"
  [(set (match_operand:SI 0 "register_operand" "=f")
	(fix:SI (fix:DF (match_operand:DF 1 "register_operand" "e"))))]
  "TARGET_FPU"
  "fdtoi %1,%0"
  [(set_attr "type" "fp")])

(define_insn "fix_trunctfsi2"
  [(set (match_operand:SI 0 "register_operand" "=f")
	(fix:SI (fix:TF (match_operand:TF 1 "register_operand" "e"))))]
  "TARGET_FPU && TARGET_HARD_QUAD"
  "fqtoi %1,%0"
  [(set_attr "type" "fp")])

;; Now the same, for 64-bit targets
;; ??? We try to work around an interesting problem.
;; If gcc tries to do a subreg on the result it will get the wrong answer:
;; "(subreg:SI (reg:DI M int-reg) 0)" is the same as
;; "(subreg:SI (reg:DI N float-reg) 1)", but gcc does not know how to change
;; the "0" to a "1".  One could enhance alter_subreg but it is not clear how to
;; do this cleanly.

(define_expand "fix_truncsfdi2"
  [(parallel [(set (match_operand:DI 0 "general_operand" "")
		   (fix:DI (fix:SF (match_operand:SF 1 "register_operand" ""))))
	      (clobber (match_dup 2))
	      (clobber (match_dup 3))])]
  "TARGET_ARCH64 && TARGET_FPU"
  "
{
  operands[2] = gen_reg_rtx (DFmode);
  operands[3] = sparc64_fpconv_stack_temp ();
}")

(define_expand "fix_truncdfdi2"
  [(parallel [(set (match_operand:DI 0 "general_operand" "")
		   (fix:DI (fix:DF (match_operand:DF 1 "register_operand" ""))))
	      (clobber (match_dup 2))
	      (clobber (match_dup 3))])]
  "TARGET_ARCH64 && TARGET_FPU"
  "
{
  operands[2] = gen_reg_rtx (DFmode);
  operands[3] = sparc64_fpconv_stack_temp ();
}")

(define_expand "fix_trunctfdi2"
  [(parallel [(set (match_operand:DI 0 "general_operand" "")
		   (fix:DI (fix:TF (match_operand:TF 1 "register_operand" ""))))
	      (clobber (match_dup 2))
	      (clobber (match_dup 3))])]
  "TARGET_ARCH64 && TARGET_FPU && TARGET_HARD_QUAD"
  "
{
  operands[2] = gen_reg_rtx (DFmode);
  operands[3] = sparc64_fpconv_stack_temp ();
}")

(define_insn "*fix_truncsfdi2_insn"
  [(parallel [(set (match_operand:DI 0 "general_operand" "=rm")
		   (fix:DI (fix:SF (match_operand:SF 1 "register_operand" "f"))))
	      (clobber (match_operand:DF 2 "register_operand" "=&e"))
	      (clobber (match_operand:DI 3 "memory_operand" "m"))])]
  "TARGET_ARCH64 && TARGET_FPU"
  "*
{
  output_asm_insn (\"fstox %1,%2\", operands);
  if (GET_CODE (operands[0]) == MEM)
    return \"std %2,%0\";
  else
    return \"std %2,%3\;ldx %3,%0\";
}"
  [(set_attr "type" "fp")
   (set_attr "length" "3")])

(define_insn "*fix_truncdfdi2_insn"
  [(parallel [(set (match_operand:DI 0 "general_operand" "=rm")
		   (fix:DI (fix:DF (match_operand:DF 1 "register_operand" "e"))))
	      (clobber (match_operand:DF 2 "register_operand" "=&e"))
	      (clobber (match_operand:DI 3 "memory_operand" "m"))])]
  "TARGET_ARCH64 && TARGET_FPU"
  "*
{
  output_asm_insn (\"fdtox %1,%2\", operands);
  if (GET_CODE (operands[0]) == MEM)
    return \"std %2,%0\";
  else
    return \"std %2,%3\;ldx %3,%0\";
}"
  [(set_attr "type" "fp")
   (set_attr "length" "3")])

(define_insn "*fix_trunctfdi2_insn"
  [(parallel [(set (match_operand:DI 0 "general_operand" "=rm")
		   (fix:DI (fix:TF (match_operand:TF 1 "register_operand" "e"))))
	      (clobber (match_operand:DF 2 "register_operand" "=&e"))
	      (clobber (match_operand:DI 3 "memory_operand" "m"))])]
  "TARGET_ARCH64 && TARGET_FPU && TARGET_HARD_QUAD"
  "*
{
  output_asm_insn (\"fqtox %1,%2\", operands);
  if (GET_CODE (operands[0]) == MEM)
    return \"std %2,%0\";
  else
    return \"std %2,%3\;ldx %3,%0\";
}"
  [(set_attr "type" "fp")
   (set_attr "length" "3")])

;; ??? Ideally, these are what we would like to use.

(define_insn "fix_truncsfdi2_sp64"
  [(set (match_operand:DI 0 "register_operand" "=e")
	(fix:DI (fix:SF (match_operand:SF 1 "register_operand" "f"))))]
  "0 && TARGET_ARCH64 && TARGET_FPU"
  "fstox %1,%0"
  [(set_attr "type" "fp")])

(define_insn "fix_truncdfdi2_sp64"
  [(set (match_operand:DI 0 "register_operand" "=e")
	(fix:DI (fix:DF (match_operand:DF 1 "register_operand" "e"))))]
  "0 && TARGET_ARCH64 && TARGET_FPU"
  "fdtox %1,%0"
  [(set_attr "type" "fp")])

(define_insn "fix_trunctfdi2_sp64"
  [(set (match_operand:DI 0 "register_operand" "=e")
	(fix:DI (fix:TF (match_operand:TF 1 "register_operand" "e"))))]
  "0 && TARGET_ARCH64 && TARGET_FPU && TARGET_HARD_QUAD"
  "fqtox %1,%0"
  [(set_attr "type" "fp")])

;;- arithmetic instructions

(define_expand "adddi3"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(plus:DI (match_operand:DI 1 "arith_double_operand" "%r")
		 (match_operand:DI 2 "arith_double_operand" "rHI")))]
  ""
  "
{
  if (! TARGET_ARCH64)
    {
      emit_insn (gen_rtx (PARALLEL, VOIDmode, gen_rtvec (2,
			  gen_rtx (SET, VOIDmode, operands[0],
				   gen_rtx (PLUS, DImode, operands[1],
						  operands[2])),
			  gen_rtx (CLOBBER, VOIDmode,
				   gen_rtx (REG, SImode, SPARC_ICC_REG)))));
      DONE;
    }
}")

(define_insn "*adddi3_sp32"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(plus:DI (match_operand:DI 1 "arith_double_operand" "%r")
		 (match_operand:DI 2 "arith_double_operand" "rHI")))
   (clobber (reg:SI 100))]
  "! TARGET_ARCH64"
  "*
{
  rtx op2 = operands[2];

  if (GET_CODE (op2) == CONST_INT
      || GET_CODE (op2) == CONST_DOUBLE)
    {
      rtx xoperands[4];
      xoperands[0] = operands[0];
      xoperands[1] = operands[1];
      if (WORDS_BIG_ENDIAN)
	split_double (op2, &xoperands[2], &xoperands[3]);
      else
	split_double (op2, &xoperands[3], &xoperands[2]);
      if (xoperands[3] == const0_rtx && xoperands[0] == xoperands[1])
	output_asm_insn (\"add %H1,%2,%H0\", xoperands);
      else
	output_asm_insn (\"addcc %L1,%3,%L0\;addx %H1,%2,%H0\", xoperands);
      return \"\";
    }
  return \"addcc %L1,%L2,%L0\;addx %H1,%H2,%H0\";
}"
  [(set_attr "length" "2")])

(define_insn "*adddi3_sp64"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(plus:DI (match_operand:DI 1 "arith_double_operand" "%r")
		 (match_operand:DI 2 "arith_double_operand" "rHI")))]
  "TARGET_ARCH64"
  "add %1,%2,%0")

(define_insn "addsi3"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(plus:SI (match_operand:SI 1 "arith_operand" "%r")
		 (match_operand:SI 2 "arith_operand" "rI")))]
  ""
  "add %1,%2,%0"
  [(set_attr "type" "ialu")])

(define_insn "*cmp_cc_plus"
  [(set (reg:CC_NOOV 100)
	(compare:CC_NOOV (plus:SI (match_operand:SI 0 "arith_operand" "%r")
				  (match_operand:SI 1 "arith_operand" "rI"))
			 (const_int 0)))]
  ""
  "addcc %0,%1,%%g0"
  [(set_attr "type" "compare")])

(define_insn "*cmp_ccx_plus"
  [(set (reg:CCX_NOOV 100)
	(compare:CCX_NOOV (plus:DI (match_operand:DI 0 "arith_double_operand" "%r")
				   (match_operand:DI 1 "arith_double_operand" "rHI"))
			  (const_int 0)))]
  "TARGET_ARCH64"
  "addcc %0,%1,%%g0"
  [(set_attr "type" "compare")])

(define_insn "*cmp_cc_plus_set"
  [(set (reg:CC_NOOV 100)
	(compare:CC_NOOV (plus:SI (match_operand:SI 1 "arith_operand" "%r")
				  (match_operand:SI 2 "arith_operand" "rI"))
			 (const_int 0)))
   (set (match_operand:SI 0 "register_operand" "=r")
	(plus:SI (match_dup 1) (match_dup 2)))]
  ""
  "addcc %1,%2,%0")

(define_insn "*cmp_ccx_plus_set"
  [(set (reg:CCX_NOOV 100)
	(compare:CCX_NOOV (plus:DI (match_operand:DI 1 "arith_double_operand" "%r")
				   (match_operand:DI 2 "arith_double_operand" "rHI"))
			  (const_int 0)))
   (set (match_operand:DI 0 "register_operand" "=r")
	(plus:DI (match_dup 1) (match_dup 2)))]
  "TARGET_ARCH64"
  "addcc %1,%2,%0")

(define_expand "subdi3"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(minus:DI (match_operand:DI 1 "register_operand" "r")
		  (match_operand:DI 2 "arith_double_operand" "rHI")))]
  ""
  "
{
  if (! TARGET_ARCH64)
    {
      emit_insn (gen_rtx (PARALLEL, VOIDmode, gen_rtvec (2,
			  gen_rtx (SET, VOIDmode, operands[0],
				   gen_rtx (MINUS, DImode, operands[1],
						   operands[2])),
			  gen_rtx (CLOBBER, VOIDmode,
				   gen_rtx (REG, SImode, SPARC_ICC_REG)))));
      DONE;
    }
}")

(define_insn "*subdi3_sp32"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(minus:DI (match_operand:DI 1 "register_operand" "r")
		  (match_operand:DI 2 "arith_double_operand" "rHI")))
   (clobber (reg:SI 100))]
  "! TARGET_ARCH64"
  "*
{
  rtx op2 = operands[2];

  if (GET_CODE (op2) == CONST_INT
      || GET_CODE (op2) == CONST_DOUBLE)
    {
      rtx xoperands[4];
      xoperands[0] = operands[0];
      xoperands[1] = operands[1];
      if (WORDS_BIG_ENDIAN)
	split_double (op2, &xoperands[2], &xoperands[3]);
      else
	split_double (op2, &xoperands[3], &xoperands[2]);
      if (xoperands[3] == const0_rtx && xoperands[0] == xoperands[1])
	output_asm_insn (\"sub %H1,%2,%H0\", xoperands);
      else
	output_asm_insn (\"subcc %L1,%3,%L0\;subx %H1,%2,%H0\", xoperands);
      return \"\";
    }
  return \"subcc %L1,%L2,%L0\;subx %H1,%H2,%H0\";
}"
  [(set_attr "length" "2")])

(define_insn "*subdi3_sp64"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(minus:DI (match_operand:DI 1 "register_operand" "r")
		  (match_operand:DI 2 "arith_double_operand" "rHI")))]
  "TARGET_ARCH64"
  "sub %1,%2,%0")

(define_insn "subsi3"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(minus:SI (match_operand:SI 1 "register_operand" "r")
		  (match_operand:SI 2 "arith_operand" "rI")))]
  ""
  "sub %1,%2,%0"
  [(set_attr "type" "ialu")])

(define_insn "*cmp_minus_cc"
  [(set (reg:CC_NOOV 100)
	(compare:CC_NOOV (minus:SI (match_operand:SI 0 "register_operand" "r")
				   (match_operand:SI 1 "arith_operand" "rI"))
			 (const_int 0)))]
  ""
  "subcc %0,%1,%%g0"
  [(set_attr "type" "compare")])

(define_insn "*cmp_minus_ccx"
  [(set (reg:CCX_NOOV 100)
	(compare:CCX_NOOV (minus:DI (match_operand:DI 0 "register_operand" "r")
				    (match_operand:DI 1 "arith_double_operand" "rHI"))
			  (const_int 0)))]
  "TARGET_ARCH64"
  "subcc %0,%1,%%g0"
  [(set_attr "type" "compare")])

(define_insn "*cmp_minus_cc_set"
  [(set (reg:CC_NOOV 100)
	(compare:CC_NOOV (minus:SI (match_operand:SI 1 "register_operand" "r")
				   (match_operand:SI 2 "arith_operand" "rI"))
			 (const_int 0)))
   (set (match_operand:SI 0 "register_operand" "=r")
	(minus:SI (match_dup 1) (match_dup 2)))]
  ""
  "subcc %1,%2,%0")

(define_insn "*cmp_minus_ccx_set"
  [(set (reg:CCX_NOOV 100)
	(compare:CCX_NOOV (minus:DI (match_operand:DI 1 "register_operand" "r")
				    (match_operand:DI 2 "arith_double_operand" "rHI"))
			  (const_int 0)))
   (set (match_operand:DI 0 "register_operand" "=r")
	(minus:DI (match_dup 1) (match_dup 2)))]
  "TARGET_ARCH64"
  "subcc %1,%2,%0")

;; Integer Multiply/Divide.

;; The 32 bit multiply/divide instructions are deprecated on v9 and shouldn't
;; we used.  We still use them in 32 bit v9 compilers.
;; The 64 bit v9 compiler will (/should) widen the args and use muldi3.

(define_insn "mulsi3"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(mult:SI (match_operand:SI 1 "arith_operand" "%r")
		 (match_operand:SI 2 "arith_operand" "rI")))]
  "TARGET_V8 || TARGET_SPARCLITE || TARGET_SPARCLET || TARGET_DEPRECATED_V8_INSNS"
  "smul %1,%2,%0"
  [(set_attr "type" "imul")])

(define_insn "muldi3"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(mult:DI (match_operand:DI 1 "arith_double_operand" "%r")
		 (match_operand:DI 2 "arith_double_operand" "rHI")))]
  "TARGET_ARCH64"
  "mulx %1,%2,%0")

;; It is not known whether this will match.

(define_insn "*cmp_mul_set"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(mult:SI (match_operand:SI 1 "arith_operand" "%r")
		 (match_operand:SI 2 "arith_operand" "rI")))
   (set (reg:CC_NOOV 100)
	(compare:CC_NOOV (mult:SI (match_dup 1) (match_dup 2))
			 (const_int 0)))]
  "TARGET_V8 || TARGET_SPARCLITE || TARGET_DEPRECATED_V8_INSNS"
  "smulcc %1,%2,%0"
  [(set_attr "type" "imul")])

(define_expand "mulsidi3"
  [(set (match_operand:DI 0 "register_operand" "")
	(mult:DI (sign_extend:DI (match_operand:SI 1 "register_operand" ""))
		 (sign_extend:DI (match_operand:SI 2 "arith_operand" ""))))]
  "TARGET_V8 || TARGET_SPARCLITE || TARGET_SPARCLET || TARGET_DEPRECATED_V8_INSNS"
  "
{
  if (CONSTANT_P (operands[2]))
    {
      emit_insn (gen_const_mulsidi3 (operands[0], operands[1], operands[2]));
      DONE;
    }
}")

(define_insn "*mulsidi3_sp32"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(mult:DI (sign_extend:DI (match_operand:SI 1 "register_operand" "r"))
		 (sign_extend:DI (match_operand:SI 2 "register_operand" "r"))))]
  "TARGET_V8 || TARGET_SPARCLITE || TARGET_SPARCLET || TARGET_DEPRECATED_V8_INSNS"
  "*
{
  return TARGET_SPARCLET ? \"smuld %1,%2,%L0\" : \"smul %1,%2,%L0\;rd %%y,%H0\";
}"
  [(set (attr "length")
	(if_then_else (eq_attr "isa" "sparclet")
		      (const_int 1) (const_int 2)))])

;; Extra pattern, because sign_extend of a constant isn't valid.

(define_insn "const_mulsidi3"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(mult:DI (sign_extend:DI (match_operand:SI 1 "register_operand" "r"))
		 (match_operand:SI 2 "small_int" "I")))]
  "TARGET_V8 || TARGET_SPARCLITE || TARGET_SPARCLET || TARGET_DEPRECATED_V8_INSNS"
  "*
{
  return TARGET_SPARCLET ? \"smuld %1,%2,%L0\" : \"smul %1,%2,%L0\;rd %%y,%H0\";
}"
  [(set (attr "length")
	(if_then_else (eq_attr "isa" "sparclet")
		      (const_int 1) (const_int 2)))])

(define_expand "smulsi3_highpart"
  [(set (match_operand:SI 0 "register_operand" "")
	(truncate:SI
	 (lshiftrt:DI (mult:DI (sign_extend:DI (match_operand:SI 1 "register_operand" ""))
			       (sign_extend:DI (match_operand:SI 2 "arith_operand" "")))
		      (const_int 32))))]
  "TARGET_V8 || TARGET_SPARCLITE || TARGET_SPARCLET || TARGET_DEPRECATED_V8_INSNS"
  "
{
  if (CONSTANT_P (operands[2]))
    {
      emit_insn (gen_const_smulsi3_highpart (operands[0], operands[1], operands[2]));
      DONE;
    }
}")

(define_insn "*smulsidi3_highpart_sp32"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(truncate:SI
	 (lshiftrt:DI (mult:DI (sign_extend:DI (match_operand:SI 1 "register_operand" "r"))
			       (sign_extend:DI (match_operand:SI 2 "register_operand" "r")))
		      (const_int 32))))]
  "TARGET_V8 || TARGET_SPARCLITE || TARGET_SPARCLET || TARGET_DEPRECATED_V8_INSNS"
  "smul %1,%2,%%g0\;rd %%y,%0"
  [(set_attr "length" "2")])

(define_insn "const_smulsi3_highpart"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(truncate:SI
	 (lshiftrt:DI (mult:DI (sign_extend:DI (match_operand:SI 1 "register_operand" "r"))
			       (match_operand:SI 2 "register_operand" "r"))
		      (const_int 32))))]
  "TARGET_V8 || TARGET_SPARCLITE || TARGET_SPARCLET || TARGET_DEPRECATED_V8_INSNS"
  "smul %1,%2,%%g0\;rd %%y,%0"
  [(set_attr "length" "2")])

(define_expand "umulsidi3"
  [(set (match_operand:DI 0 "register_operand" "")
	(mult:DI (zero_extend:DI (match_operand:SI 1 "register_operand" ""))
		 (zero_extend:DI (match_operand:SI 2 "uns_arith_operand" ""))))]
  "TARGET_V8 || TARGET_SPARCLITE || TARGET_SPARCLET || TARGET_DEPRECATED_V8_INSNS"
  "
{
  if (CONSTANT_P (operands[2]))
    {
      emit_insn (gen_const_umulsidi3 (operands[0], operands[1], operands[2]));
      DONE;
    }
}")

(define_insn "*umulsidi3_sp32"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(mult:DI (zero_extend:DI (match_operand:SI 1 "register_operand" "r"))
		 (zero_extend:DI (match_operand:SI 2 "register_operand" "r"))))]
  "TARGET_V8 || TARGET_SPARCLITE || TARGET_SPARCLET || TARGET_DEPRECATED_V8_INSNS"
  "*
{
  return TARGET_SPARCLET ? \"umuld %1,%2,%L0\" : \"umul %1,%2,%L0\;rd %%y,%H0\";
}"
  [(set (attr "length")
	(if_then_else (eq_attr "isa" "sparclet")
		      (const_int 1) (const_int 2)))])

;; Extra pattern, because sign_extend of a constant isn't valid.

(define_insn "const_umulsidi3"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(mult:DI (zero_extend:DI (match_operand:SI 1 "register_operand" "r"))
		 (match_operand:SI 2 "uns_small_int" "")))]
  "TARGET_V8 || TARGET_SPARCLITE || TARGET_SPARCLET || TARGET_DEPRECATED_V8_INSNS"
  "*
{
  return TARGET_SPARCLET ? \"umuld %1,%2,%L0\" : \"umul %1,%2,%L0\;rd %%y,%H0\";
}"
  [(set (attr "length")
	(if_then_else (eq_attr "isa" "sparclet")
		      (const_int 1) (const_int 2)))])

(define_expand "umulsi3_highpart"
  [(set (match_operand:SI 0 "register_operand" "")
	(truncate:SI
	 (lshiftrt:DI (mult:DI (zero_extend:DI (match_operand:SI 1 "register_operand" ""))
			       (zero_extend:DI (match_operand:SI 2 "uns_arith_operand" "")))
		      (const_int 32))))]
  "TARGET_V8 || TARGET_SPARCLITE || TARGET_SPARCLET || TARGET_DEPRECATED_V8_INSNS"
  "
{
  if (CONSTANT_P (operands[2]))
    {
      emit_insn (gen_const_umulsi3_highpart (operands[0], operands[1], operands[2]));
      DONE;
    }
}")

(define_insn "*umulsidi3_highpart_sp32"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(truncate:SI
	 (lshiftrt:DI (mult:DI (zero_extend:DI (match_operand:SI 1 "register_operand" "r"))
			       (zero_extend:DI (match_operand:SI 2 "register_operand" "r")))
		      (const_int 32))))]
  "TARGET_V8 || TARGET_SPARCLITE || TARGET_SPARCLET || TARGET_DEPRECATED_V8_INSNS"
  "umul %1,%2,%%g0\;rd %%y,%0"
  [(set_attr "length" "2")])

(define_insn "const_umulsi3_highpart"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(truncate:SI
	 (lshiftrt:DI (mult:DI (zero_extend:DI (match_operand:SI 1 "register_operand" "r"))
			       (match_operand:SI 2 "uns_small_int" ""))
		      (const_int 32))))]
  "TARGET_V8 || TARGET_SPARCLITE || TARGET_SPARCLET || TARGET_DEPRECATED_V8_INSNS"
  "umul %1,%2,%%g0\;rd %%y,%0"
  [(set_attr "length" "2")])

;; The v8 architecture specifies that there must be 3 instructions between
;; a y register write and a use of it for correct results.

(define_insn "divsi3"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(div:SI (match_operand:SI 1 "register_operand" "r")
		(match_operand:SI 2 "arith_operand" "rI")))
   (clobber (match_scratch:SI 3 "=&r"))]
  "TARGET_V8 || TARGET_DEPRECATED_V8_INSNS"
  "*
{
  if (TARGET_V9)
    return \"sra %1,31,%3\;wr %%g0,%3,%%y\;sdiv %1,%2,%0\";
  else
    return \"sra %1,31,%3\;wr %%g0,%3,%%y\;nop\;nop\;nop\;sdiv %1,%2,%0\";
}"
  [(set (attr "length")
	(if_then_else (eq_attr "isa" "v9")
		      (const_int 3) (const_int 6)))])

(define_insn "divdi3"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(div:DI (match_operand:DI 1 "register_operand" "r")
		(match_operand:DI 2 "arith_double_operand" "rHI")))]
  "TARGET_ARCH64"
  "sdivx %1,%2,%0")

;; It is not known whether this will match.

(define_insn "*cmp_sdiv_cc_set"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(div:SI (match_operand:SI 1 "register_operand" "r")
		(match_operand:SI 2 "arith_operand" "rI")))
   (set (reg:CC 100)
	(compare:CC (div:SI (match_dup 1) (match_dup 2))
		    (const_int 0)))
   (clobber (match_scratch:SI 3 "=&r"))]
  "TARGET_V8 || TARGET_DEPRECATED_V8_INSNS"
  "*
{
  if (TARGET_V9)
    return \"sra %1,31,%3\;wr %%g0,%3,%%y\;sdivcc %1,%2,%0\";
  else
    return \"sra %1,31,%3\;wr %%g0,%3,%%y\;nop\;nop\;nop\;sdivcc %1,%2,%0\";
}"
  [(set (attr "length")
	(if_then_else (eq_attr "isa" "v9")
		      (const_int 3) (const_int 6)))])

(define_insn "udivsi3"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(udiv:SI (match_operand:SI 1 "register_operand" "r")
		 (match_operand:SI 2 "arith_operand" "rI")))]
  "TARGET_V8 || TARGET_DEPRECATED_V8_INSNS"
  "*
{
  if (TARGET_V9)
    return \"wr %%g0,%%g0,%%y\;udiv %1,%2,%0\";
  else
    return \"wr %%g0,%%g0,%%y\;nop\;nop\;nop\;udiv %1,%2,%0\";
}"
  [(set (attr "length")
	(if_then_else (eq_attr "isa" "v9")
		      (const_int 2) (const_int 5)))])

(define_insn "udivdi3"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(udiv:DI (match_operand:DI 1 "register_operand" "r")
		 (match_operand:DI 2 "arith_double_operand" "rHI")))]
  "TARGET_ARCH64"
  "udivx %1,%2,%0")

;; It is not known whether this will match.

(define_insn "*cmp_udiv_cc_set"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(udiv:SI (match_operand:SI 1 "register_operand" "r")
		(match_operand:SI 2 "arith_operand" "rI")))
   (set (reg:CC 100)
	(compare:CC (udiv:SI (match_dup 1) (match_dup 2))
		    (const_int 0)))]
  "TARGET_V8 || TARGET_DEPRECATED_V8_INSNS"
  "*
{
  if (TARGET_V9)
    return \"wr %%g0,%%g0,%%y\;udivcc %1,%2,%0\";
  else
    return \"wr %%g0,%%g0,%%y\;nop\;nop\;nop\;udivcc %1,%2,%0\";
}"
  [(set (attr "length")
	(if_then_else (eq_attr "isa" "v9")
		      (const_int 2) (const_int 5)))])

; sparclet multiply/accumulate insns

(define_insn "*smacsi"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(plus:SI (mult:SI (match_operand:SI 1 "register_operand" "%r")
			  (match_operand:SI 2 "arith_operand" "rI"))
		 (match_operand:SI 3 "register_operand" "0")))]
  "TARGET_SPARCLET"
  "smac %1,%2,%0"
  [(set_attr "type" "imul")])

(define_insn "*smacdi"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(plus:DI (mult:DI (sign_extend:DI
			   (match_operand:SI 1 "register_operand" "%r"))
			  (sign_extend:DI
			   (match_operand:SI 2 "register_operand" "r")))
		 (match_operand:DI 3 "register_operand" "0")))]
  "TARGET_SPARCLET"
  "smacd %1,%2,%L0"
  [(set_attr "type" "imul")])

(define_insn "*umacdi"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(plus:DI (mult:DI (zero_extend:DI
			   (match_operand:SI 1 "register_operand" "%r"))
			  (zero_extend:DI
			   (match_operand:SI 2 "register_operand" "r")))
		 (match_operand:DI 3 "register_operand" "0")))]
  "TARGET_SPARCLET"
  "umacd %1,%2,%L0"
  [(set_attr "type" "imul")])

;;- Boolean instructions
;; We define DImode `and' so with DImode `not' we can get
;; DImode `andn'.  Other combinations are possible.

(define_expand "anddi3"
  [(set (match_operand:DI 0 "register_operand" "")
	(and:DI (match_operand:DI 1 "arith_double_operand" "")
		(match_operand:DI 2 "arith_double_operand" "")))]
  ""
  "")

(define_insn "*anddi3_sp32"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(and:DI (match_operand:DI 1 "arith_double_operand" "%r")
		(match_operand:DI 2 "arith_double_operand" "rHI")))]
  "! TARGET_ARCH64"
  "*
{
  rtx op2 = operands[2];

  if (GET_CODE (op2) == CONST_INT
      || GET_CODE (op2) == CONST_DOUBLE)
    {
      rtx xoperands[4];
      xoperands[0] = operands[0];
      xoperands[1] = operands[1];
      if (WORDS_BIG_ENDIAN)
	split_double (op2, &xoperands[2], &xoperands[3]);
      else
	split_double (op2, &xoperands[3], &xoperands[2]);
      output_asm_insn (\"and %L1,%3,%L0\;and %H1,%2,%H0\", xoperands);
      return \"\";
    }
  return \"and %1,%2,%0\;and %R1,%R2,%R0\";
}"
  [(set_attr "length" "2")])

(define_insn "*anddi3_sp64"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(and:DI (match_operand:DI 1 "arith_double_operand" "%r")
		(match_operand:DI 2 "arith_double_operand" "rHI")))]
  "TARGET_ARCH64"
  "and %1,%2,%0")

(define_insn "andsi3"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(and:SI (match_operand:SI 1 "arith_operand" "%r")
		(match_operand:SI 2 "arith_operand" "rI")))]
  ""
  "and %1,%2,%0"
  [(set_attr "type" "ialu")])

(define_split
  [(set (match_operand:SI 0 "register_operand" "")
	(and:SI (match_operand:SI 1 "register_operand" "")
		(match_operand:SI 2 "" "")))
   (clobber (match_operand:SI 3 "register_operand" ""))]
  "GET_CODE (operands[2]) == CONST_INT
   && !SMALL_INT (operands[2])
   && (INTVAL (operands[2]) & 0x3ff) == 0x3ff"
  [(set (match_dup 3) (match_dup 4))
   (set (match_dup 0) (and:SI (not:SI (match_dup 3)) (match_dup 1)))]
  "
{
  operands[4] = GEN_INT (~INTVAL (operands[2]));
}")

(define_insn "*and_not_di_sp32"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(and:DI (not:DI (match_operand:DI 1 "register_operand" "r"))
		(match_operand:DI 2 "register_operand" "r")))]
  "! TARGET_ARCH64"
  "andn %2,%1,%0\;andn %R2,%R1,%R0"
  [(set_attr "length" "2")])

(define_insn "*and_not_di_sp64"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(and:DI (not:DI (match_operand:DI 1 "register_operand" "r"))
		(match_operand:DI 2 "register_operand" "r")))]
  "TARGET_ARCH64"
  "andn %2,%1,%0")

(define_insn "*and_not_si"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(and:SI (not:SI (match_operand:SI 1 "register_operand" "r"))
		(match_operand:SI 2 "register_operand" "r")))]
  ""
  "andn %2,%1,%0"
  [(set_attr "type" "ialu")])

(define_expand "iordi3"
  [(set (match_operand:DI 0 "register_operand" "")
	(ior:DI (match_operand:DI 1 "arith_double_operand" "")
		(match_operand:DI 2 "arith_double_operand" "")))]
  ""
  "")

(define_insn "*iordi3_sp32"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(ior:DI (match_operand:DI 1 "arith_double_operand" "%r")
		(match_operand:DI 2 "arith_double_operand" "rHI")))]
  "! TARGET_ARCH64"
  "*
{
  rtx op2 = operands[2];

  if (GET_CODE (op2) == CONST_INT
      || GET_CODE (op2) == CONST_DOUBLE)
    {
      rtx xoperands[4];
      xoperands[0] = operands[0];
      xoperands[1] = operands[1];
      if (WORDS_BIG_ENDIAN)
	split_double (op2, &xoperands[2], &xoperands[3]);
      else
	split_double (op2, &xoperands[3], &xoperands[2]);
      output_asm_insn (\"or %L1,%3,%L0\;or %H1,%2,%H0\", xoperands);
      return \"\";
    }
  return \"or %1,%2,%0\;or %R1,%R2,%R0\";
}"
  [(set_attr "length" "2")])

(define_insn "*iordi3_sp64"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(ior:DI (match_operand:DI 1 "arith_double_operand" "%r")
		(match_operand:DI 2 "arith_double_operand" "rHI")))]
  "TARGET_ARCH64"
  "or %1,%2,%0")

(define_insn "iorsi3"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(ior:SI (match_operand:SI 1 "arith_operand" "%r")
		(match_operand:SI 2 "arith_operand" "rI")))]
  ""
  "or %1,%2,%0"
  [(set_attr "type" "ialu")])

(define_split
  [(set (match_operand:SI 0 "register_operand" "")
	(ior:SI (match_operand:SI 1 "register_operand" "")
		(match_operand:SI 2 "" "")))
   (clobber (match_operand:SI 3 "register_operand" ""))]
  "GET_CODE (operands[2]) == CONST_INT
   && !SMALL_INT (operands[2])
   && (INTVAL (operands[2]) & 0x3ff) == 0x3ff"
  [(set (match_dup 3) (match_dup 4))
   (set (match_dup 0) (ior:SI (not:SI (match_dup 3)) (match_dup 1)))]
  "
{
  operands[4] = GEN_INT (~INTVAL (operands[2]));
}")

(define_insn "*or_not_di_sp32"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(ior:DI (not:DI (match_operand:DI 1 "register_operand" "r"))
		(match_operand:DI 2 "register_operand" "r")))]
  "! TARGET_ARCH64"
  "orn %2,%1,%0\;orn %R2,%R1,%R0"
  [(set_attr "length" "2")])

(define_insn "*or_not_di_sp64"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(ior:DI (not:DI (match_operand:DI 1 "register_operand" "r"))
		(match_operand:DI 2 "register_operand" "r")))]
  "TARGET_ARCH64"
  "orn %2,%1,%0")

(define_insn "*or_not_si"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(ior:SI (not:SI (match_operand:SI 1 "register_operand" "r"))
		(match_operand:SI 2 "register_operand" "r")))]
  ""
  "orn %2,%1,%0"
  [(set_attr "type" "ialu")])

(define_expand "xordi3"
  [(set (match_operand:DI 0 "register_operand" "")
	(xor:DI (match_operand:DI 1 "arith_double_operand" "")
		(match_operand:DI 2 "arith_double_operand" "")))]
  ""
  "")

(define_insn "*xorsi3_sp32"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(xor:DI (match_operand:DI 1 "arith_double_operand" "%r")
		(match_operand:DI 2 "arith_double_operand" "rHI")))]
  "! TARGET_ARCH64"
  "*
{
  rtx op2 = operands[2];

  if (GET_CODE (op2) == CONST_INT
      || GET_CODE (op2) == CONST_DOUBLE)
    {
      rtx xoperands[4];
      xoperands[0] = operands[0];
      xoperands[1] = operands[1];
      if (WORDS_BIG_ENDIAN)
	split_double (op2, &xoperands[2], &xoperands[3]);
      else
	split_double (op2, &xoperands[3], &xoperands[2]);
      output_asm_insn (\"xor %L1,%3,%L0\;xor %H1,%2,%H0\", xoperands);
      return \"\";
    }
  return \"xor %1,%2,%0\;xor %R1,%R2,%R0\";
}"
  [(set_attr "length" "2")])

(define_insn "*xordi3_sp64"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(xor:DI (match_operand:DI 1 "arith_double_operand" "%rJ")
		(match_operand:DI 2 "arith_double_operand" "rHI")))]
  "TARGET_ARCH64"
  "xor %r1,%2,%0")

(define_insn "xorsi3"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(xor:SI (match_operand:SI 1 "arith_operand" "%rJ")
		(match_operand:SI 2 "arith_operand" "rI")))]
  ""
  "xor %r1,%2,%0"
  [(set_attr "type" "ialu")])

(define_split
  [(set (match_operand:SI 0 "register_operand" "")
	(xor:SI (match_operand:SI 1 "register_operand" "")
		(match_operand:SI 2 "" "")))
   (clobber (match_operand:SI 3 "register_operand" ""))]
  "GET_CODE (operands[2]) == CONST_INT
   && !SMALL_INT (operands[2])
   && (INTVAL (operands[2]) & 0x3ff) == 0x3ff"
  [(set (match_dup 3) (match_dup 4))
   (set (match_dup 0) (not:SI (xor:SI (match_dup 3) (match_dup 1))))]
  "
{
  operands[4] = GEN_INT (~INTVAL (operands[2]));
}")

(define_split
  [(set (match_operand:SI 0 "register_operand" "")
	(not:SI (xor:SI (match_operand:SI 1 "register_operand" "")
			(match_operand:SI 2 "" ""))))
   (clobber (match_operand:SI 3 "register_operand" ""))]
  "GET_CODE (operands[2]) == CONST_INT
   && !SMALL_INT (operands[2])
   && (INTVAL (operands[2]) & 0x3ff) == 0x3ff"
  [(set (match_dup 3) (match_dup 4))
   (set (match_dup 0) (xor:SI (match_dup 3) (match_dup 1)))]
  "
{
  operands[4] = GEN_INT (~INTVAL (operands[2]));
}")

;; xnor patterns.  Note that (a ^ ~b) == (~a ^ b) == ~(a ^ b).
;; Combine now canonicalizes to the rightmost expression.
(define_insn "*xor_not_di_sp32"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(not:DI (xor:DI (match_operand:DI 1 "register_operand" "r")
			(match_operand:DI 2 "register_operand" "r"))))]
  "! TARGET_ARCH64"
  "xnor %1,%2,%0\;xnor %R1,%R2,%R0"
  [(set_attr "length" "2")])

(define_insn "*xor_not_di_sp64"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(not:DI (xor:DI (match_operand:DI 1 "reg_or_0_operand" "rJ")
			(match_operand:DI 2 "arith_double_operand" "rHI"))))]
  "TARGET_ARCH64"
  "xnor %r1,%2,%0")

(define_insn "*xor_not_si"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(not:SI (xor:SI (match_operand:SI 1 "reg_or_0_operand" "rJ")
			(match_operand:SI 2 "arith_operand" "rI"))))]
  ""
  "xnor %r1,%2,%0"
  [(set_attr "type" "ialu")])

;; These correspond to the above in the case where we also (or only)
;; want to set the condition code.  

(define_insn "*cmp_cc_arith_op"
  [(set (reg:CC 100)
	(compare:CC
	 (match_operator:SI 2 "cc_arithop"
			    [(match_operand:SI 0 "arith_operand" "%r")
			     (match_operand:SI 1 "arith_operand" "rI")])
	 (const_int 0)))]
  ""
  "%A2cc %0,%1,%%g0"
  [(set_attr "type" "compare")])

(define_insn "*cmp_ccx_arith_op"
  [(set (reg:CCX 100)
	(compare:CCX
	 (match_operator:DI 2 "cc_arithop"
			    [(match_operand:DI 0 "arith_double_operand" "%r")
			     (match_operand:DI 1 "arith_double_operand" "rHI")])
	 (const_int 0)))]
  "TARGET_ARCH64"
  "%A2cc %0,%1,%%g0"
  [(set_attr "type" "compare")])

(define_insn "*cmp_cc_arith_op_set"
  [(set (reg:CC 100)
	(compare:CC
	 (match_operator:SI 3 "cc_arithop"
			    [(match_operand:SI 1 "arith_operand" "%r")
			     (match_operand:SI 2 "arith_operand" "rI")])
	 (const_int 0)))
   (set (match_operand:SI 0 "register_operand" "=r")
	(match_dup 3))]
  ""
  "%A3cc %1,%2,%0")

(define_insn "*cmp_ccx_arith_op_set"
  [(set (reg:CCX 100)
	(compare:CCX
	 (match_operator:DI 3 "cc_arithop"
			    [(match_operand:DI 1 "arith_double_operand" "%r")
			     (match_operand:DI 2 "arith_double_operand" "rHI")])
	 (const_int 0)))
   (set (match_operand:DI 0 "register_operand" "=r")
	(match_dup 3))]
  "TARGET_ARCH64"
  "%A3cc %1,%2,%0")

(define_insn "*cmp_cc_xor_not"
  [(set (reg:CC 100)
	(compare:CC
	 (not:SI (xor:SI (match_operand:SI 0 "reg_or_0_operand" "%rJ")
			 (match_operand:SI 1 "arith_operand" "rI")))
	 (const_int 0)))]
  ""
  "xnorcc %r0,%1,%%g0"
  [(set_attr "type" "compare")])

(define_insn "*cmp_ccx_xor_not"
  [(set (reg:CCX 100)
	(compare:CCX
	 (not:DI (xor:DI (match_operand:DI 0 "reg_or_0_operand" "%rJ")
			 (match_operand:DI 1 "arith_double_operand" "rHI")))
	 (const_int 0)))]
  "TARGET_ARCH64"
  "xnorcc %r0,%1,%%g0"
  [(set_attr "type" "compare")])

(define_insn "*cmp_cc_xor_not_set"
  [(set (reg:CC 100)
	(compare:CC
	 (not:SI (xor:SI (match_operand:SI 1 "reg_or_0_operand" "%rJ")
			 (match_operand:SI 2 "arith_operand" "rI")))
	 (const_int 0)))
   (set (match_operand:SI 0 "register_operand" "=r")
	(not:SI (xor:SI (match_dup 1) (match_dup 2))))]
  ""
  "xnorcc %r1,%2,%0")

(define_insn "*cmp_ccx_xor_not_set"
  [(set (reg:CCX 100)
	(compare:CCX
	 (not:DI (xor:DI (match_operand:DI 1 "reg_or_0_operand" "%rJ")
			 (match_operand:DI 2 "arith_double_operand" "rHI")))
	 (const_int 0)))
   (set (match_operand:DI 0 "register_operand" "=r")
	(not:DI (xor:DI (match_dup 1) (match_dup 2))))]
  "TARGET_ARCH64"
  "xnorcc %r1,%2,%0")

(define_insn "*cmp_cc_arith_op_not"
  [(set (reg:CC 100)
	(compare:CC
	 (match_operator:SI 2 "cc_arithopn"
			    [(not:SI (match_operand:SI 0 "arith_operand" "rI"))
			     (match_operand:SI 1 "reg_or_0_operand" "rJ")])
	 (const_int 0)))]
  ""
  "%B2cc %r1,%0,%%g0"
  [(set_attr "type" "compare")])

(define_insn "*cmp_ccx_arith_op_not"
  [(set (reg:CCX 100)
	(compare:CCX
	 (match_operator:DI 2 "cc_arithopn"
			    [(not:DI (match_operand:DI 0 "arith_double_operand" "rHI"))
			     (match_operand:DI 1 "reg_or_0_operand" "rJ")])
	 (const_int 0)))]
  "TARGET_ARCH64"
  "%B2cc %r1,%0,%%g0"
  [(set_attr "type" "compare")])

(define_insn "*cmp_cc_arith_op_not_set"
  [(set (reg:CC 100)
	(compare:CC
	 (match_operator:SI 3 "cc_arithopn"
			    [(not:SI (match_operand:SI 1 "arith_operand" "rI"))
			     (match_operand:SI 2 "reg_or_0_operand" "rJ")])
	 (const_int 0)))
   (set (match_operand:SI 0 "register_operand" "=r")
	(match_dup 3))]
  ""
  "%B3cc %r2,%1,%0")

(define_insn "*cmp_ccx_arith_op_not_set"
  [(set (reg:CCX 100)
	(compare:CCX
	 (match_operator:DI 3 "cc_arithopn"
			    [(not:DI (match_operand:DI 1 "arith_double_operand" "rHI"))
			     (match_operand:DI 2 "reg_or_0_operand" "rJ")])
	 (const_int 0)))
   (set (match_operand:DI 0 "register_operand" "=r")
	(match_dup 3))]
  "TARGET_ARCH64"
  "%B3cc %r2,%1,%0")

;; We cannot use the "neg" pseudo insn because the Sun assembler
;; does not know how to make it work for constants.

(define_expand "negdi2"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(neg:DI (match_operand:DI 1 "register_operand" "r")))]
  ""
  "
{
  if (! TARGET_ARCH64)
    {
      emit_insn (gen_rtx (PARALLEL, VOIDmode, gen_rtvec (2,
			  gen_rtx (SET, VOIDmode, operand0,
				   gen_rtx (NEG, DImode, operand1)),
			  gen_rtx (CLOBBER, VOIDmode,
				   gen_rtx (REG, SImode, SPARC_ICC_REG)))));
      DONE;
    }
}")

(define_insn "*negdi2_sp32"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(neg:DI (match_operand:DI 1 "register_operand" "r")))
   (clobber (reg:SI 100))]
  "! TARGET_ARCH64"
  "*
{
  if (TARGET_LIVE_G0)
    output_asm_insn (\"and %%g0,0,%%g0\", operands);
  return \"subcc %%g0,%L1,%L0\;subx %%g0,%H1,%H0\";
}"
  [(set_attr "type" "unary")
   ;; ??? This is wrong for TARGET_LIVE_G0 but it's not critical.
   (set_attr "length" "2")])

(define_insn "*negdi2_sp64"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(neg:DI (match_operand:DI 1 "register_operand" "r")))]
  "TARGET_ARCH64"
  "sub %%g0,%1,%0"
  [(set_attr "type" "unary")
   (set_attr "length" "1")])

(define_insn "negsi2"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(neg:SI (match_operand:SI 1 "arith_operand" "rI")))]
  ""
  "*
{
  if (TARGET_LIVE_G0)
    return \"and %%g0,0,%%g0\;sub %%g0,%1,%0\";
  return \"sub %%g0,%1,%0\";
}"
  [(set_attr "type" "unary")
   (set (attr "length")
	(if_then_else (eq_attr "live_g0" "yes") (const_int 2) (const_int 1)))])

(define_insn "*cmp_cc_neg"
  [(set (reg:CC_NOOV 100)
	(compare:CC_NOOV (neg:SI (match_operand:SI 0 "arith_operand" "rI"))
			 (const_int 0)))]
  "! TARGET_LIVE_G0"
  "subcc %%g0,%0,%%g0"
  [(set_attr "type" "compare")])

(define_insn "*cmp_ccx_neg"
  [(set (reg:CCX_NOOV 100)
	(compare:CCX_NOOV (neg:DI (match_operand:DI 0 "arith_double_operand" "rHI"))
			  (const_int 0)))]
  "TARGET_ARCH64"
  "subcc %%g0,%0,%%g0"
  [(set_attr "type" "compare")])

(define_insn "*cmp_cc_set_neg"
  [(set (reg:CC_NOOV 100)
	(compare:CC_NOOV (neg:SI (match_operand:SI 1 "arith_operand" "rI"))
			 (const_int 0)))
   (set (match_operand:SI 0 "register_operand" "=r")
	(neg:SI (match_dup 1)))]
  "! TARGET_LIVE_G0"
  "subcc %%g0,%1,%0"
  [(set_attr "type" "unary")])

(define_insn "*cmp_ccx_set_neg"
  [(set (reg:CCX_NOOV 100)
	(compare:CCX_NOOV (neg:DI (match_operand:DI 1 "arith_double_operand" "rHI"))
			  (const_int 0)))
   (set (match_operand:DI 0 "register_operand" "=r")
	(neg:DI (match_dup 1)))]
  "TARGET_ARCH64"
  "subcc %%g0,%1,%0"
  [(set_attr "type" "unary")])

;; We cannot use the "not" pseudo insn because the Sun assembler
;; does not know how to make it work for constants.
(define_expand "one_cmpldi2"
  [(set (match_operand:DI 0 "register_operand" "")
	(not:DI (match_operand:DI 1 "register_operand" "")))]
  ""
  "")

(define_insn "*one_cmpldi2_sp32"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(not:DI (match_operand:DI 1 "register_operand" "r")))]
  "! TARGET_ARCH64"
  "xnor %1,0,%0\;xnor %R1,0,%R0"
  [(set_attr "type" "unary")
   (set_attr "length" "2")])

(define_insn "*one_cmpldi2_sp64"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(not:DI (match_operand:DI 1 "arith_double_operand" "rHI")))]
  "TARGET_ARCH64"
  "xnor %1,0,%0"
  [(set_attr "type" "unary")])

(define_insn "one_cmplsi2"
  [(set (match_operand:SI 0 "register_operand" "=r,r")
	(not:SI (match_operand:SI 1 "arith_operand" "r,I")))]
  ""
  "*
{
  if (which_alternative == 0)
    return \"xnor %1,0,%0\";
  if (TARGET_LIVE_G0)
    output_asm_insn (\"and %%g0,0,%%g0\", operands);
  return \"xnor %%g0,%1,%0\";
}"
  [(set_attr "type" "unary")
   (set_attr_alternative "length"
     [(const_int 1)
      (if_then_else (eq_attr "live_g0" "yes") (const_int 2) (const_int 1))])])

(define_insn "*cmp_cc_not"
  [(set (reg:CC 100)
	(compare:CC (not:SI (match_operand:SI 0 "arith_operand" "rI"))
		    (const_int 0)))]
  "! TARGET_LIVE_G0"
  "xnorcc %%g0,%0,%%g0"
  [(set_attr "type" "compare")])

(define_insn "*cmp_ccx_not"
  [(set (reg:CCX 100)
	(compare:CCX (not:DI (match_operand:DI 0 "arith_double_operand" "rHI"))
		     (const_int 0)))]
  "TARGET_ARCH64"
  "xnorcc %%g0,%0,%%g0"
  [(set_attr "type" "compare")])

(define_insn "*cmp_cc_set_not"
  [(set (reg:CC 100)
	(compare:CC (not:SI (match_operand:SI 1 "arith_operand" "rI"))
		    (const_int 0)))
   (set (match_operand:SI 0 "register_operand" "=r")
	(not:SI (match_dup 1)))]
  "! TARGET_LIVE_G0"
  "xnorcc %%g0,%1,%0"
  [(set_attr "type" "unary")])

(define_insn "*cmp_ccx_set_not"
  [(set (reg:CCX 100)
	(compare:CCX (not:DI (match_operand:DI 1 "arith_double_operand" "rHI"))
		    (const_int 0)))
   (set (match_operand:DI 0 "register_operand" "=r")
	(not:DI (match_dup 1)))]
  "TARGET_ARCH64"
  "xnorcc %%g0,%1,%0"
  [(set_attr "type" "unary")])

;; Floating point arithmetic instructions.

(define_insn "addtf3"
  [(set (match_operand:TF 0 "register_operand" "=e")
	(plus:TF (match_operand:TF 1 "register_operand" "e")
		 (match_operand:TF 2 "register_operand" "e")))]
  "TARGET_FPU && TARGET_HARD_QUAD"
  "faddq %1,%2,%0"
  [(set_attr "type" "fp")])

(define_insn "adddf3"
  [(set (match_operand:DF 0 "register_operand" "=e")
	(plus:DF (match_operand:DF 1 "register_operand" "e")
		 (match_operand:DF 2 "register_operand" "e")))]
  "TARGET_FPU"
  "faddd %1,%2,%0"
  [(set_attr "type" "fp")])

(define_insn "addsf3"
  [(set (match_operand:SF 0 "register_operand" "=f")
	(plus:SF (match_operand:SF 1 "register_operand" "f")
		 (match_operand:SF 2 "register_operand" "f")))]
  "TARGET_FPU"
  "fadds %1,%2,%0"
  [(set_attr "type" "fp")])

(define_insn "subtf3"
  [(set (match_operand:TF 0 "register_operand" "=e")
	(minus:TF (match_operand:TF 1 "register_operand" "e")
		  (match_operand:TF 2 "register_operand" "e")))]
  "TARGET_FPU && TARGET_HARD_QUAD"
  "fsubq %1,%2,%0"
  [(set_attr "type" "fp")])

(define_insn "subdf3"
  [(set (match_operand:DF 0 "register_operand" "=e")
	(minus:DF (match_operand:DF 1 "register_operand" "e")
		  (match_operand:DF 2 "register_operand" "e")))]
  "TARGET_FPU"
  "fsubd %1,%2,%0"
  [(set_attr "type" "fp")])

(define_insn "subsf3"
  [(set (match_operand:SF 0 "register_operand" "=f")
	(minus:SF (match_operand:SF 1 "register_operand" "f")
		  (match_operand:SF 2 "register_operand" "f")))]
  "TARGET_FPU"
  "fsubs %1,%2,%0"
  [(set_attr "type" "fp")])

(define_insn "multf3"
  [(set (match_operand:TF 0 "register_operand" "=e")
	(mult:TF (match_operand:TF 1 "register_operand" "e")
		 (match_operand:TF 2 "register_operand" "e")))]
  "TARGET_FPU && TARGET_HARD_QUAD"
  "fmulq %1,%2,%0"
  [(set_attr "type" "fpmul")])

(define_insn "muldf3"
  [(set (match_operand:DF 0 "register_operand" "=e")
	(mult:DF (match_operand:DF 1 "register_operand" "e")
		 (match_operand:DF 2 "register_operand" "e")))]
  "TARGET_FPU"
  "fmuld %1,%2,%0"
  [(set_attr "type" "fpmul")])

(define_insn "mulsf3"
  [(set (match_operand:SF 0 "register_operand" "=f")
	(mult:SF (match_operand:SF 1 "register_operand" "f")
		 (match_operand:SF 2 "register_operand" "f")))]
  "TARGET_FPU"
  "fmuls %1,%2,%0"
  [(set_attr "type" "fpmul")])

(define_insn "*muldf3_extend"
  [(set (match_operand:DF 0 "register_operand" "=e")
	(mult:DF (float_extend:DF (match_operand:SF 1 "register_operand" "f"))
		 (float_extend:DF (match_operand:SF 2 "register_operand" "f"))))]
  "(TARGET_V8 || TARGET_V9) && TARGET_FPU"
  "fsmuld %1,%2,%0"
  [(set_attr "type" "fpmul")])

(define_insn "*multf3_extend"
  [(set (match_operand:TF 0 "register_operand" "=e")
	(mult:TF (float_extend:TF (match_operand:DF 1 "register_operand" "e"))
		 (float_extend:TF (match_operand:DF 2 "register_operand" "e"))))]
  "(TARGET_V8 || TARGET_V9) && TARGET_FPU && TARGET_HARD_QUAD"
  "fdmulq %1,%2,%0"
  [(set_attr "type" "fpmul")])

;; don't have timing for quad-prec. divide.
(define_insn "divtf3"
  [(set (match_operand:TF 0 "register_operand" "=e")
	(div:TF (match_operand:TF 1 "register_operand" "e")
		(match_operand:TF 2 "register_operand" "e")))]
  "TARGET_FPU && TARGET_HARD_QUAD"
  "fdivq %1,%2,%0"
  [(set_attr "type" "fpdivd")])

(define_insn "divdf3"
  [(set (match_operand:DF 0 "register_operand" "=e")
	(div:DF (match_operand:DF 1 "register_operand" "e")
		(match_operand:DF 2 "register_operand" "e")))]
  "TARGET_FPU"
  "fdivd %1,%2,%0"
  [(set_attr "type" "fpdivd")])

(define_insn "divsf3"
  [(set (match_operand:SF 0 "register_operand" "=f")
	(div:SF (match_operand:SF 1 "register_operand" "f")
		(match_operand:SF 2 "register_operand" "f")))]
  "TARGET_FPU"
  "fdivs %1,%2,%0"
  [(set_attr "type" "fpdivs")])

(define_insn "negtf2"
  [(set (match_operand:TF 0 "register_operand" "=e,e")
	(neg:TF (match_operand:TF 1 "register_operand" "0,e")))]
  ; We don't use quad float insns here so we don't need TARGET_HARD_QUAD.
  "TARGET_FPU"
  "*
{
  /* v9: can't use fnegs, won't work with upper regs.  */
  if (which_alternative == 0)
   return TARGET_V9 ? \"fnegd %0,%0\" : \"fnegs %0,%0\";
  else
   return TARGET_V9 ? \"fnegd %1,%0\;fmovd %S1,%S0\"
     : \"fnegs %1,%0\;fmovs %R1,%R0\;fmovs %S1,%S0\;fmovs %T1,%T0\";
}"
  [(set_attr "type" "fp")
   (set_attr_alternative "length"
     [(const_int 1)
      (if_then_else (eq_attr "isa" "v9") (const_int 2) (const_int 4))])])

(define_insn "negdf2"
  [(set (match_operand:DF 0 "register_operand" "=e,e")
	(neg:DF (match_operand:DF 1 "register_operand" "0,e")))]
  "TARGET_FPU"
  "*
{
  if (TARGET_V9)
    return \"fnegd %1,%0\";
  else if (which_alternative == 0)
   return \"fnegs %0,%0\";
  else
   return \"fnegs %1,%0\;fmovs %R1,%R0\";
}"
  [(set_attr "type" "fp")
   (set_attr_alternative "length"
     [(const_int 1)
      (if_then_else (eq_attr "isa" "v9") (const_int 1) (const_int 2))])])

(define_insn "negsf2"
  [(set (match_operand:SF 0 "register_operand" "=f")
	(neg:SF (match_operand:SF 1 "register_operand" "f")))]
  "TARGET_FPU"
  "fnegs %1,%0"
  [(set_attr "type" "fp")])

(define_insn "abstf2"
  [(set (match_operand:TF 0 "register_operand" "=e,e")
	(abs:TF (match_operand:TF 1 "register_operand" "0,e")))]
  ; We don't use quad float insns here so we don't need TARGET_HARD_QUAD.
  "TARGET_FPU"
  "*
{
  /* v9: can't use fabss, won't work with upper regs.  */
  if (which_alternative == 0)
    return TARGET_V9 ? \"fabsd %0,%0\" : \"fabss %0,%0\";
  else
    return TARGET_V9 ? \"fabsd %1,%0\;fmovd %S1,%S0\"
      : \"fabss %1,%0\;fmovs %R1,%R0\;fmovs %S1,%S0\;fmovs %T1,%T0\";
}"
  [(set_attr "type" "fp")
   (set_attr_alternative "length"
     [(const_int 1)
      (if_then_else (eq_attr "isa" "v9") (const_int 2) (const_int 4))])])

(define_insn "absdf2"
  [(set (match_operand:DF 0 "register_operand" "=e,e")
	(abs:DF (match_operand:DF 1 "register_operand" "0,e")))]
  "TARGET_FPU"
  "*
{
  if (TARGET_V9)
    return \"fabsd %1,%0\";
  else if (which_alternative == 0)
    return \"fabss %0,%0\";
  else
    return \"fabss %1,%0\;fmovs %R1,%R0\";
}"
  [(set_attr "type" "fp")
   (set_attr_alternative "length"
     [(const_int 1)
      (if_then_else (eq_attr "isa" "v9") (const_int 1) (const_int 2))])])

(define_insn "abssf2"
  [(set (match_operand:SF 0 "register_operand" "=f")
	(abs:SF (match_operand:SF 1 "register_operand" "f")))]
  "TARGET_FPU"
  "fabss %1,%0"
  [(set_attr "type" "fp")])

(define_insn "sqrttf2"
  [(set (match_operand:TF 0 "register_operand" "=e")
	(sqrt:TF (match_operand:TF 1 "register_operand" "e")))]
  "TARGET_FPU && TARGET_HARD_QUAD"
  "fsqrtq %1,%0"
  [(set_attr "type" "fpsqrt")])

(define_insn "sqrtdf2"
  [(set (match_operand:DF 0 "register_operand" "=e")
	(sqrt:DF (match_operand:DF 1 "register_operand" "e")))]
  "TARGET_FPU"
  "fsqrtd %1,%0"
  [(set_attr "type" "fpsqrt")])

(define_insn "sqrtsf2"
  [(set (match_operand:SF 0 "register_operand" "=f")
	(sqrt:SF (match_operand:SF 1 "register_operand" "f")))]
  "TARGET_FPU"
  "fsqrts %1,%0"
  [(set_attr "type" "fpsqrt")])

;;- arithmetic shift instructions

(define_insn "ashlsi3"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(ashift:SI (match_operand:SI 1 "register_operand" "r")
		   (match_operand:SI 2 "arith_operand" "rI")))]
  ""
  "*
{
  if (GET_CODE (operands[2]) == CONST_INT
      && (unsigned HOST_WIDE_INT) INTVAL (operands[2]) > 31)
    operands[2] = GEN_INT (INTVAL (operands[2]) & 0x1f);

  return \"sll %1,%2,%0\";
}"
  [(set_attr "type" "shift")])

(define_insn "ashldi3"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(ashift:DI (match_operand:DI 1 "register_operand" "r")
		   (match_operand:SI 2 "arith_operand" "rI")))]
  "TARGET_ARCH64"
  "*
{
  if (GET_CODE (operands[2]) == CONST_INT
      && (unsigned HOST_WIDE_INT) INTVAL (operands[2]) > 31)
    operands[2] = GEN_INT (INTVAL (operands[2]) & 0x3f);

  return \"sllx %1,%2,%0\";
}")

(define_insn "*cmp_cc_ashift_1"
  [(set (reg:CC_NOOV 100)
	(compare:CC_NOOV (ashift:SI (match_operand:SI 0 "register_operand" "r")
				    (const_int 1))
			 (const_int 0)))]
  ""
  "addcc %0,%0,%%g0"
  [(set_attr "type" "compare")])

(define_insn "*cmp_cc_set_ashift_1"
  [(set (reg:CC_NOOV 100)
	(compare:CC_NOOV (ashift:SI (match_operand:SI 1 "register_operand" "r")
				    (const_int 1))
			 (const_int 0)))
   (set (match_operand:SI 0 "register_operand" "=r")
	(ashift:SI (match_dup 1) (const_int 1)))]
  ""
  "addcc %1,%1,%0")

(define_insn "ashrsi3"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(ashiftrt:SI (match_operand:SI 1 "register_operand" "r")
		     (match_operand:SI 2 "arith_operand" "rI")))]
  ""
  "*
{
  if (GET_CODE (operands[2]) == CONST_INT
      && (unsigned HOST_WIDE_INT) INTVAL (operands[2]) > 31)
    operands[2] = GEN_INT (INTVAL (operands[2]) & 0x1f);

  return \"sra %1,%2,%0\";
}"
  [(set_attr "type" "shift")])

(define_insn "ashrdi3"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(ashiftrt:DI (match_operand:DI 1 "register_operand" "r")
		     (match_operand:SI 2 "arith_operand" "rI")))]
  "TARGET_ARCH64"
  "*
{
  if (GET_CODE (operands[2]) == CONST_INT
      && (unsigned HOST_WIDE_INT) INTVAL (operands[2]) > 63)
    operands[2] = GEN_INT (INTVAL (operands[2]) & 0x3f);

  return \"srax %1,%2,%0\";
}")

(define_insn "lshrsi3"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(lshiftrt:SI (match_operand:SI 1 "register_operand" "r")
		     (match_operand:SI 2 "arith_operand" "rI")))]
  ""
  "*
{
  if (GET_CODE (operands[2]) == CONST_INT
      && (unsigned HOST_WIDE_INT) INTVAL (operands[2]) > 31)
    operands[2] = GEN_INT (INTVAL (operands[2]) & 0x1f);

  return \"srl %1,%2,%0\";
}"
  [(set_attr "type" "shift")])

(define_insn "lshrdi3"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(lshiftrt:DI (match_operand:DI 1 "register_operand" "r")
		     (match_operand:SI 2 "arith_operand" "rI")))]
  "TARGET_ARCH64"
  "*
{
  if (GET_CODE (operands[2]) == CONST_INT
      && (unsigned HOST_WIDE_INT) INTVAL (operands[2]) > 63)
    operands[2] = GEN_INT (INTVAL (operands[2]) & 0x3f);

  return \"srlx %1,%2,%0\";
}")

;; Unconditional and other jump instructions
;; On the Sparc, by setting the annul bit on an unconditional branch, the
;; following insn is never executed.  This saves us a nop.  Dbx does not
;; handle such branches though, so we only use them when optimizing.
(define_insn "jump"
  [(set (pc) (label_ref (match_operand 0 "" "")))]
  ""
  "*
{
  /* Some implementations are reported to have problems with
	foo: b,a foo
     i.e. an empty loop with the annul bit set.  The workaround is to use 
        foo: b foo; nop
     instead.  */

  if (flag_delayed_branch
      && (insn_addresses[INSN_UID (operands[0])]
	  == insn_addresses[INSN_UID (insn)]))
    return \"b %l0%#\";
  else
    return \"b%* %l0%(\";
}"
  [(set_attr "type" "uncond_branch")])

(define_expand "tablejump"
  [(parallel [(set (pc) (match_operand 0 "register_operand" "r"))
	      (use (label_ref (match_operand 1 "" "")))])]
  ""
  "
{
  if (GET_MODE (operands[0]) != Pmode)
    abort ();

  /* We need to use the PC value in %o7 that was set up when the address
     of the label was loaded into a register, so we need different RTL.  */
  if (flag_pic)
    {
      if (!TARGET_PTR64)
	emit_jump_insn (gen_pic_tablejump_32 (operands[0], operands[1]));
      else
	emit_jump_insn (gen_pic_tablejump_64 (operands[0], operands[1]));
      DONE;
    }
}")

(define_insn "pic_tablejump_32"
  [(set (pc) (match_operand:SI 0 "register_operand" "r"))
   (use (label_ref (match_operand 1 "" "")))
   (use (reg:SI 15))]
  "! TARGET_PTR64"
  "jmp %%o7+%0%#"
  [(set_attr "type" "uncond_branch")])

(define_insn "pic_tablejump_64"
  [(set (pc) (match_operand:DI 0 "register_operand" "r"))
   (use (label_ref (match_operand 1 "" "")))
   (use (reg:DI 15))]
  "TARGET_PTR64"
  "jmp %%o7+%0%#"
  [(set_attr "type" "uncond_branch")])

(define_insn "*tablejump_sp32"
  [(set (pc) (match_operand:SI 0 "address_operand" "p"))
   (use (label_ref (match_operand 1 "" "")))]
  "! TARGET_PTR64"
  "jmp %a0%#"
  [(set_attr "type" "uncond_branch")])

(define_insn "*tablejump_sp64"
  [(set (pc) (match_operand:DI 0 "address_operand" "p"))
   (use (label_ref (match_operand 1 "" "")))]
  "TARGET_PTR64"
  "jmp %a0%#"
  [(set_attr "type" "uncond_branch")])

;; This pattern recognizes the "instruction" that appears in 
;; a function call that wants a structure value, 
;; to inform the called function if compiled with Sun CC.
;(define_insn "*unimp_insn"
;  [(match_operand:SI 0 "immediate_operand" "")]
;  "GET_CODE (operands[0]) == CONST_INT && INTVAL (operands[0]) > 0"
;  "unimp %0"
;  [(set_attr "type" "marker")])

;;- jump to subroutine
(define_expand "call"
  ;; Note that this expression is not used for generating RTL.
  ;; All the RTL is generated explicitly below.
  [(call (match_operand 0 "call_operand" "")
	 (match_operand 3 "" "i"))]
  ;; operands[2] is next_arg_register
  ;; operands[3] is struct_value_size_rtx.
  ""
  "
{
  rtx fn_rtx, nregs_rtx;

   if (GET_MODE (operands[0]) != FUNCTION_MODE)
    abort ();

  if (GET_CODE (XEXP (operands[0], 0)) == LABEL_REF)
    {
      /* This is really a PIC sequence.  We want to represent
	 it as a funny jump so it's delay slots can be filled. 

	 ??? But if this really *is* a CALL, will not it clobber the
	 call-clobbered registers?  We lose this if it is a JUMP_INSN.
	 Why cannot we have delay slots filled if it were a CALL?  */

      if (! TARGET_ARCH64 && INTVAL (operands[3]) != 0)
	emit_jump_insn
	  (gen_rtx (PARALLEL, VOIDmode,
		    gen_rtvec (3,
			       gen_rtx (SET, VOIDmode, pc_rtx,
					XEXP (operands[0], 0)),
			       GEN_INT (INTVAL (operands[3]) & 0xfff),
			       gen_rtx (CLOBBER, VOIDmode,
					gen_rtx (REG, Pmode, 15)))));
      else
	emit_jump_insn
	  (gen_rtx (PARALLEL, VOIDmode,
		    gen_rtvec (2,
			       gen_rtx (SET, VOIDmode, pc_rtx,
					XEXP (operands[0], 0)),
			       gen_rtx (CLOBBER, VOIDmode,
					gen_rtx (REG, Pmode, 15)))));
      goto finish_call;
    }

  fn_rtx = operands[0];

  /* Count the number of parameter registers being used by this call.
     if that argument is NULL, it means we are using them all, which
     means 6 on the sparc.  */
#if 0
  if (operands[2])
    nregs_rtx = GEN_INT (REGNO (operands[2]) - 8);
  else
    nregs_rtx = GEN_INT (6);
#else
  nregs_rtx = const0_rtx;
#endif

  if (! TARGET_ARCH64 && INTVAL (operands[3]) != 0)
    emit_call_insn
      (gen_rtx (PARALLEL, VOIDmode,
		gen_rtvec (3, gen_rtx (CALL, VOIDmode, fn_rtx, nregs_rtx),
			   GEN_INT (INTVAL (operands[3]) & 0xfff),
			   gen_rtx (CLOBBER, VOIDmode,
				    gen_rtx (REG, Pmode, 15)))));
  else
    emit_call_insn
      (gen_rtx (PARALLEL, VOIDmode,
		gen_rtvec (2, gen_rtx (CALL, VOIDmode, fn_rtx, nregs_rtx),
			   gen_rtx (CLOBBER, VOIDmode,
				    gen_rtx (REG, Pmode, 15)))));

 finish_call:
#if 0
  /* If this call wants a structure value,
     emit an unimp insn to let the called function know about this.  */
  if (! TARGET_ARCH64 && INTVAL (operands[3]) > 0)
    {
      rtx insn = emit_insn (operands[3]);
      SCHED_GROUP_P (insn) = 1;
    }
#endif

  DONE;
}")

;; We can't use the same pattern for these two insns, because then registers
;; in the address may not be properly reloaded.

(define_insn "*call_address_sp32"
  [(call (mem:SI (match_operand:SI 0 "address_operand" "p"))
	 (match_operand 1 "" ""))
   (clobber (reg:SI 15))]
  ;;- Do not use operand 1 for most machines.
  "! TARGET_PTR64"
  "call %a0,%1%#"
  [(set_attr "type" "call")])

(define_insn "*call_symbolic_sp32"
  [(call (mem:SI (match_operand:SI 0 "symbolic_operand" "s"))
	 (match_operand 1 "" ""))
   (clobber (reg:SI 15))]
  ;;- Do not use operand 1 for most machines.
  "! TARGET_PTR64"
  "call %a0,%1%#"
  [(set_attr "type" "call")])

(define_insn "*call_address_sp64"
  [(call (mem:SI (match_operand:DI 0 "address_operand" "p"))
	 (match_operand 1 "" ""))
   (clobber (reg:DI 15))]
  ;;- Do not use operand 1 for most machines.
  "TARGET_PTR64"
  "call %a0,%1%#"
  [(set_attr "type" "call")])

(define_insn "*call_symbolic_sp64"
  [(call (mem:SI (match_operand:DI 0 "symbolic_operand" "s"))
	 (match_operand 1 "" ""))
   (clobber (reg:DI 15))]
  ;;- Do not use operand 1 for most machines.
  "TARGET_PTR64"
  "call %a0,%1%#"
  [(set_attr "type" "call")])

;; This is a call that wants a structure value.
;; There is no such critter for v9 (??? we may need one anyway).
(define_insn "*call_address_struct_value_sp32"
  [(call (mem:SI (match_operand:SI 0 "address_operand" "p"))
	 (match_operand 1 "" ""))
   (match_operand 2 "immediate_operand" "")
   (clobber (reg:SI 15))]
  ;;- Do not use operand 1 for most machines.
  "! TARGET_ARCH64 && GET_CODE (operands[2]) == CONST_INT && INTVAL (operands[2]) >= 0"
  "call %a0,%1\;nop\;unimp %2"
  [(set_attr "type" "call_no_delay_slot")])

;; This is a call that wants a structure value.
;; There is no such critter for v9 (??? we may need one anyway).
(define_insn "*call_symbolic_struct_value_sp32"
  [(call (mem:SI (match_operand:SI 0 "symbolic_operand" "s"))
	 (match_operand 1 "" ""))
   (match_operand 2 "immediate_operand" "")
   (clobber (reg:SI 15))]
  ;;- Do not use operand 1 for most machines.
  "! TARGET_ARCH64 && GET_CODE (operands[2]) == CONST_INT && INTVAL (operands[2]) >= 0"
  "call %a0,%1\;nop\;unimp %2"
  [(set_attr "type" "call_no_delay_slot")])

;; This is a call that may want a structure value.  This is used for
;; untyped_calls.
(define_insn "*call_address_untyped_struct_value_sp32"
  [(call (mem:SI (match_operand:SI 0 "address_operand" "p"))
	 (match_operand 1 "" ""))
   (match_operand 2 "immediate_operand" "")
   (clobber (reg:SI 15))]
  ;;- Do not use operand 1 for most machines.
  "! TARGET_ARCH64 && GET_CODE (operands[2]) == CONST_INT && INTVAL (operands[2]) < 0"
  "call %a0,%1\;nop\;nop"
  [(set_attr "type" "call_no_delay_slot")])

;; This is a call that wants a structure value.
(define_insn "*call_symbolic_untyped_struct_value_sp32"
  [(call (mem:SI (match_operand:SI 0 "symbolic_operand" "s"))
	 (match_operand 1 "" ""))
   (match_operand 2 "immediate_operand" "")
   (clobber (reg:SI 15))]
  ;;- Do not use operand 1 for most machines.
  "! TARGET_ARCH64 && GET_CODE (operands[2]) == CONST_INT && INTVAL (operands[2]) < 0"
  "call %a0,%1\;nop\;nop"
  [(set_attr "type" "call_no_delay_slot")])

(define_expand "call_value"
  ;; Note that this expression is not used for generating RTL.
  ;; All the RTL is generated explicitly below.
  [(set (match_operand 0 "register_operand" "=rf")
	(call (match_operand:SI 1 "" "")
	      (match_operand 4 "" "")))]
  ;; operand 2 is stack_size_rtx
  ;; operand 3 is next_arg_register
  ""
  "
{
  rtx fn_rtx, nregs_rtx;
  rtvec vec;

  if (GET_MODE (operands[1]) != FUNCTION_MODE)
    abort ();

  fn_rtx = operands[1];

#if 0
  if (operands[3])
    nregs_rtx = gen_rtx (CONST_INT, VOIDmode, REGNO (operands[3]) - 8);
  else
    nregs_rtx = gen_rtx (CONST_INT, VOIDmode, 6);
#else
  nregs_rtx = const0_rtx;
#endif

  vec = gen_rtvec (2,
		   gen_rtx (SET, VOIDmode, operands[0],
			    gen_rtx (CALL, VOIDmode, fn_rtx, nregs_rtx)),
		   gen_rtx (CLOBBER, VOIDmode, gen_rtx (REG, Pmode, 15)));

  emit_call_insn (gen_rtx (PARALLEL, VOIDmode, vec));

  DONE;
}")

(define_insn "*call_value_address_sp32"
  [(set (match_operand 0 "" "=rf")
	(call (mem:SI (match_operand:SI 1 "address_operand" "p"))
	      (match_operand 2 "" "")))
   (clobber (reg:SI 15))]
  ;;- Do not use operand 2 for most machines.
  "! TARGET_PTR64"
  "call %a1,%2%#"
  [(set_attr "type" "call")])

(define_insn "*call_value_symbolic_sp32"
  [(set (match_operand 0 "" "=rf")
	(call (mem:SI (match_operand:SI 1 "symbolic_operand" "s"))
	      (match_operand 2 "" "")))
   (clobber (reg:SI 15))]
  ;;- Do not use operand 2 for most machines.
  "! TARGET_PTR64"
  "call %a1,%2%#"
  [(set_attr "type" "call")])

(define_insn "*call_value_address_sp64"
  [(set (match_operand 0 "" "=rf")
	(call (mem:SI (match_operand:DI 1 "address_operand" "p"))
	      (match_operand 2 "" "")))
   (clobber (reg:DI 15))]
  ;;- Do not use operand 2 for most machines.
  "TARGET_PTR64"
  "call %a1,%2%#"
  [(set_attr "type" "call")])

(define_insn "*call_value_symbolic_sp64"
  [(set (match_operand 0 "" "=rf")
	(call (mem:SI (match_operand:DI 1 "symbolic_operand" "s"))
	      (match_operand 2 "" "")))
   (clobber (reg:DI 15))]
  ;;- Do not use operand 2 for most machines.
  "TARGET_PTR64"
  "call %a1,%2%#"
  [(set_attr "type" "call")])

(define_expand "untyped_call"
  [(parallel [(call (match_operand 0 "" "")
		    (const_int 0))
	      (match_operand 1 "" "")
	      (match_operand 2 "" "")])]
  ""
  "
{
  int i;

  /* Pass constm1 to indicate that it may expect a structure value, but
     we don't know what size it is.  */
  emit_call_insn (gen_call (operands[0], const0_rtx, NULL, constm1_rtx));

  for (i = 0; i < XVECLEN (operands[2], 0); i++)
    {
      rtx set = XVECEXP (operands[2], 0, i);
      emit_move_insn (SET_DEST (set), SET_SRC (set));
    }

  /* The optimizer does not know that the call sets the function value
     registers we stored in the result block.  We avoid problems by
     claiming that all hard registers are used and clobbered at this
     point.  */
  emit_insn (gen_blockage ());

  DONE;
}")

;; UNSPEC_VOLATILE is considered to use and clobber all hard registers and
;; all of memory.  This blocks insns from being moved across this point.

(define_insn "blockage"
  [(unspec_volatile [(const_int 0)] 0)]
  ""
  "")

;; Prepare to return any type including a structure value.

(define_expand "untyped_return"
  [(match_operand:BLK 0 "memory_operand" "")
   (match_operand 1 "" "")]
  ""
  "
{
  rtx valreg1 = gen_rtx (REG, DImode, 24);
  rtx valreg2 = gen_rtx (REG, TARGET_ARCH64 ? TFmode : DFmode, 32);
  rtx result = operands[0];

  if (! TARGET_ARCH64)
    {
      rtx rtnreg = gen_rtx (REG, SImode, (leaf_function ? 15 : 31));
      rtx value = gen_reg_rtx (SImode);

      /* Fetch the instruction where we will return to and see if it's an unimp
	 instruction (the most significant 10 bits will be zero).  If so,
	 update the return address to skip the unimp instruction.  */
      emit_move_insn (value,
		      gen_rtx (MEM, SImode, plus_constant (rtnreg, 8)));
      emit_insn (gen_lshrsi3 (value, value, GEN_INT (22)));
      emit_insn (gen_update_return (rtnreg, value));
    }

  /* Reload the function value registers.  */
  emit_move_insn (valreg1, change_address (result, DImode, XEXP (result, 0)));
  emit_move_insn (valreg2,
		  change_address (result, TARGET_ARCH64 ? TFmode : DFmode,
				  plus_constant (XEXP (result, 0), 8)));

  /* Put USE insns before the return.  */
  emit_insn (gen_rtx (USE, VOIDmode, valreg1));
  emit_insn (gen_rtx (USE, VOIDmode, valreg2));

  /* Construct the return.  */
  expand_null_return ();

  DONE;
}")

;; This is a bit of a hack.  We're incrementing a fixed register (%i7),
;; and parts of the compiler don't want to believe that the add is needed.

(define_insn "update_return"
  [(unspec:SI [(match_operand:SI 0 "register_operand" "r")
	       (match_operand:SI 1 "register_operand" "r")] 0)]
  "! TARGET_ARCH64"
  "cmp %1,0\;be,a .+8\;add %0,4,%0"
  [(set_attr "type" "multi")])

(define_insn "return"
  [(return)
   (use (reg:SI 31))]
  "! TARGET_EPILOGUE"
  "* return output_return (operands);"
  [(set_attr "type" "multi")])

(define_insn "nop"
  [(const_int 0)]
  ""
  "nop")

(define_expand "indirect_jump"
  [(set (pc) (match_operand 0 "address_operand" "p"))]
  ""
  "")

(define_insn "*branch_sp32"
  [(set (pc) (match_operand:SI 0 "address_operand" "p"))]
  "! TARGET_PTR64"
 "jmp %a0%#"
 [(set_attr "type" "uncond_branch")])
 
(define_insn "*branch_sp64"
  [(set (pc) (match_operand:DI 0 "address_operand" "p"))]
  "TARGET_PTR64"
  "jmp %a0%#"
  [(set_attr "type" "uncond_branch")])

;; ??? Doesn't work with -mflat.
(define_expand "nonlocal_goto"
  [(match_operand:SI 0 "general_operand" "")
   (match_operand:SI 1 "general_operand" "")
   (match_operand:SI 2 "general_operand" "")
   (match_operand:SI 3 "" "")]
  ""
  "
{
  /* Trap instruction to flush all the register windows.  */
  emit_insn (gen_flush_register_windows ());
  /* Load the fp value for the containing fn into %fp.
     This is needed because operands[2] refers to %fp.
     Virtual register instantiation fails if the virtual %fp isn't set from a
     register.  Thus we must copy operands[0] into a register if it isn't
     already one.  */
  if (GET_CODE (operands[0]) != REG)
    operands[0] = force_reg (Pmode, operands[0]);
  emit_move_insn (virtual_stack_vars_rtx, operands[0]);
  /* Find the containing function's current nonlocal goto handler,
     which will do any cleanups and then jump to the label.  */
  emit_move_insn (gen_rtx (REG, Pmode, 8), operands[1]);
  /* Restore %fp from stack pointer value for containing function.
     The restore insn that follows will move this to %sp,
     and reload the appropriate value into %fp.  */
  emit_move_insn (frame_pointer_rtx, operands[2]);
  /* Put in the static chain register the nonlocal label address.  */
  emit_move_insn (static_chain_rtx, operands[3]);
  /* USE of frame_pointer_rtx added for consistency; not clear if
     really needed.  */
  emit_insn (gen_rtx (USE, VOIDmode, frame_pointer_rtx));
  emit_insn (gen_rtx (USE, VOIDmode, stack_pointer_rtx));
  emit_insn (gen_rtx (USE, VOIDmode, static_chain_rtx));
  /* Return, restoring reg window and jumping to goto handler.  */
  emit_insn (gen_goto_handler_and_restore ());
  emit_barrier ();
  DONE;
}")

;; Special trap insn to flush register windows.
(define_insn "flush_register_windows"
  [(unspec_volatile [(const_int 0)] 1)]
  ""
  ;; ??? Use TARGET_V9 instead?
  "* return TARGET_ARCH64 ? \"flushw\" : \"ta 3\";"
  [(set_attr "type" "misc")])

(define_insn "goto_handler_and_restore"
  [(unspec_volatile [(const_int 0)] 2)
   (use (reg:SI 8))]
  ""
  "jmp %%o0+0\;restore"
  [(set_attr "type" "misc")
   (set_attr "length" "2")])

;; Pattern for use after a setjmp to store FP and the return register
;; into the stack area.

(define_expand "setjmp"
  [(const_int 0)]
  ""
  "
{
  if (TARGET_ARCH64)
    emit_insn (gen_setjmp_64 ());
  else
    emit_insn (gen_setjmp_32 ());

  DONE;
}")

(define_expand "setjmp_32"
  [(set (mem:SI (plus:SI (reg:SI 14) (const_int 56))) (match_dup 0))
   (set (mem:SI (plus:SI (reg:SI 14) (const_int 60))) (reg:SI 31))]
  ""
  "
{ operands[0] = frame_pointer_rtx; }")

(define_expand "setjmp_64"
  [(set (mem:DI (plus:DI (reg:DI 14) (const_int 112))) (match_dup 0))
   (set (mem:DI (plus:DI (reg:DI 14) (const_int 120))) (reg:DI 31))]
  ""
  "
{ operands[0] = frame_pointer_rtx; }")

;; Special pattern for the FLUSH instruction.

(define_insn "flush"
  [(unspec_volatile [(match_operand 0 "memory_operand" "m")] 3)]
  ""
  "* return TARGET_V9 ? \"flush %f0\" : \"iflush %f0\";"
  [(set_attr "type" "misc")])

;; find first set.

;; The scan instruction searches from the most significant bit while ffs
;; searches from the least significant bit.  The bit index and treatment of
;; zero also differ.  It takes at least 7 instructions to get the proper
;; result.  Here is an obvious 8 instruction sequence.

(define_insn "ffssi2"
  [(set (match_operand:SI 0 "register_operand" "=&r")
	(ffs:SI (match_operand:SI 1 "register_operand" "r")))
   (clobber (match_scratch:SI 2 "=&r"))]
  "TARGET_SPARCLITE || TARGET_SPARCLET"
  "*
{
  if (TARGET_LIVE_G0)
    output_asm_insn (\"and %%g0,0,%%g0\", operands);
  return \"sub %%g0,%1,%0\;and %0,%1,%0\;scan %0,0,%0\;mov 32,%2\;sub %2,%0,%0\;sra %0,31,%2\;and %2,31,%2\;add %2,%0,%0\";
}"
  [(set_attr "type" "multi")
   (set_attr "length" "8")])

;; ??? This should be a define expand, so that the extra instruction have
;; a chance of being optimized away.

(define_insn "ffsdi2"
  [(set (match_operand:DI 0 "register_operand" "=&r")
	(ffs:DI (match_operand:DI 1 "register_operand" "r")))
   (clobber (match_scratch:DI 2 "=&r"))]
  "TARGET_ARCH64"
  "neg %1,%2\;not %2,%2\;xor %1,%2,%2\;popc %2,%0\;movrz %1,0,%0"
  [(set_attr "type" "multi")
   (set_attr "length" "5")])

;; Split up troublesome insns for better scheduling.  */

;; The following patterns are straightforward.  They can be applied
;; either before or after register allocation.

(define_split
  [(set (match_operand 0 "splittable_symbolic_memory_operand" "")
	(match_operand 1 "reg_or_0_operand" ""))
   (clobber (match_operand:SI 2 "register_operand" ""))]
  "! flag_pic"
  [(set (match_dup 2) (high:SI (match_dup 3)))
   (set (match_dup 4) (match_dup 1))]
  "
{
  operands[3] = XEXP (operands[0], 0);
  operands[4] = gen_rtx (MEM, GET_MODE (operands[0]),
			 gen_rtx (LO_SUM, SImode, operands[2], operands[3]));
  MEM_IN_STRUCT_P (operands[4]) = MEM_IN_STRUCT_P (operands[0]);
  MEM_VOLATILE_P (operands[4]) = MEM_VOLATILE_P (operands[0]);
  RTX_UNCHANGING_P (operands[4]) = RTX_UNCHANGING_P (operands[0]);
}")

(define_split
  [(set (match_operand 0 "splittable_immediate_memory_operand" "")
	(match_operand 1 "general_operand" ""))
   (clobber (match_operand:SI 2 "register_operand" ""))]
  "flag_pic"
  [(set (match_dup 3) (match_dup 1))]
  "
{
  rtx addr = legitimize_pic_address (XEXP (operands[0], 0),
				     GET_MODE (operands[0]),
				     operands[2]);
  operands[3] = gen_rtx (MEM, GET_MODE (operands[0]), addr);
  MEM_IN_STRUCT_P (operands[3]) = MEM_IN_STRUCT_P (operands[0]);
  MEM_VOLATILE_P (operands[3]) = MEM_VOLATILE_P (operands[0]);
  RTX_UNCHANGING_P (operands[3]) = RTX_UNCHANGING_P (operands[0]);
}")

(define_split
  [(set (match_operand 0 "register_operand" "")
	(match_operand 1 "splittable_immediate_memory_operand" ""))]
  "flag_pic"
  [(set (match_dup 0) (match_dup 2))]
  "
{
  rtx addr = legitimize_pic_address (XEXP (operands[1], 0),
				     GET_MODE (operands[1]),
				     operands[0]);
  operands[2] = gen_rtx (MEM, GET_MODE (operands[1]), addr);
  MEM_IN_STRUCT_P (operands[2]) = MEM_IN_STRUCT_P (operands[1]);
  MEM_VOLATILE_P (operands[2]) = MEM_VOLATILE_P (operands[1]);
  RTX_UNCHANGING_P (operands[2]) = RTX_UNCHANGING_P (operands[1]);
}")

;; Sign- and Zero-extend operations can have symbolic memory operands.

(define_split
  [(set (match_operand 0 "register_operand" "")
	(match_operator 1 "extend_op" [(match_operand 2 "splittable_immediate_memory_operand" "")]))]
  "flag_pic"
  [(set (match_dup 0) (match_op_dup 1 [(match_dup 3)]))]
  "
{
  rtx addr = legitimize_pic_address (XEXP (operands[2], 0),
				     GET_MODE (operands[2]),
				     operands[0]);
  operands[3] = gen_rtx (MEM, GET_MODE (operands[2]), addr);
  MEM_IN_STRUCT_P (operands[3]) = MEM_IN_STRUCT_P (operands[2]);
  MEM_VOLATILE_P (operands[3]) = MEM_VOLATILE_P (operands[2]);
  RTX_UNCHANGING_P (operands[3]) = RTX_UNCHANGING_P (operands[2]);
}")

(define_split
  [(set (match_operand:SI 0 "register_operand" "")
	(match_operand:SI 1 "immediate_operand" ""))]
  "! flag_pic && (GET_CODE (operands[1]) == SYMBOL_REF
		  || GET_CODE (operands[1]) == CONST
		  || GET_CODE (operands[1]) == LABEL_REF)"
  [(set (match_dup 0) (high:SI (match_dup 1)))
   (set (match_dup 0)
	(lo_sum:SI (match_dup 0) (match_dup 1)))]
  "")

;; LABEL_REFs are not modified by `legitimize_pic_address'
;; so do not recurse infinitely in the PIC case.
(define_split
  [(set (match_operand:SI 0 "register_operand" "")
	(match_operand:SI 1 "immediate_operand" ""))]
  "flag_pic && (GET_CODE (operands[1]) == SYMBOL_REF
		|| GET_CODE (operands[1]) == CONST)"
  [(set (match_dup 0) (match_dup 1))]
  "
{
  operands[1] = legitimize_pic_address (operands[1], Pmode, operands[0]);
}")

;; These split sne/seq insns.  The forms of the resulting insns are 
;; somewhat bogus, but they avoid extra patterns and show data dependency.
;; Nothing will look at these in detail after splitting has occurred.

;; ??? v9 DImode versions are missing because addc and subc use %icc.

(define_split
  [(set (match_operand:SI 0 "register_operand" "")
	(ne:SI (match_operand:SI 1 "register_operand" "")
	       (const_int 0)))
   (clobber (reg:CC 100))]
  ""
  [(set (reg:CC_NOOV 100) (compare:CC_NOOV (neg:SI (match_dup 1))
					   (const_int 0)))
   (set (match_dup 0) (ltu:SI (reg:CC 100) (const_int 0)))]
  "")

(define_split
  [(set (match_operand:SI 0 "register_operand" "")
	(neg:SI (ne:SI (match_operand:SI 1 "register_operand" "")
		       (const_int 0))))
   (clobber (reg:CC 100))]
  ""
  [(set (reg:CC_NOOV 100) (compare:CC_NOOV (neg:SI (match_dup 1))
					   (const_int 0)))
   (set (match_dup 0) (neg:SI (ltu:SI (reg:CC 100) (const_int 0))))]
  "")

(define_split
  [(set (match_operand:SI 0 "register_operand" "")
	(eq:SI (match_operand:SI 1 "register_operand" "")
	       (const_int 0)))
   (clobber (reg:CC 100))]
  ""
  [(set (reg:CC_NOOV 100) (compare:CC_NOOV (neg:SI (match_dup 1))
					   (const_int 0)))
   (set (match_dup 0) (geu:SI (reg:CC 100) (const_int 0)))]
  "")

(define_split
  [(set (match_operand:SI 0 "register_operand" "")
	(neg:SI (eq:SI (match_operand:SI 1 "register_operand" "")
		       (const_int 0))))
   (clobber (reg:CC 100))]
  ""
  [(set (reg:CC_NOOV 100) (compare:CC_NOOV (neg:SI (match_dup 1))
					   (const_int 0)))
   (set (match_dup 0) (neg:SI (geu:SI (reg:CC 100) (const_int 0))))]
  "")

(define_split
  [(set (match_operand:SI 0 "register_operand" "")
	(plus:SI (ne:SI (match_operand:SI 1 "register_operand" "")
			(const_int 0))
		 (match_operand:SI 2 "register_operand" "")))
   (clobber (reg:CC 100))]
  ""
  [(set (reg:CC_NOOV 100) (compare:CC_NOOV (neg:SI (match_dup 1))
					   (const_int 0)))
   (set (match_dup 0) (plus:SI (ltu:SI (reg:CC 100) (const_int 0))
			       (match_dup 2)))]
  "")

(define_split
  [(set (match_operand:SI 0 "register_operand" "")
	(minus:SI (match_operand:SI 2 "register_operand" "")
		  (ne:SI (match_operand:SI 1 "register_operand" "")
			 (const_int 0))))
   (clobber (reg:CC 100))]
  ""
  [(set (reg:CC_NOOV 100) (compare:CC_NOOV (neg:SI (match_dup 1))
					   (const_int 0)))
   (set (match_dup 0) (minus:SI (match_dup 2)
				(ltu:SI (reg:CC 100) (const_int 0))))]
  "")

(define_split
  [(set (match_operand:SI 0 "register_operand" "")
	(plus:SI (eq:SI (match_operand:SI 1 "register_operand" "")
			(const_int 0))
		 (match_operand:SI 2 "register_operand" "")))
   (clobber (reg:CC 100))]
  ""
  [(set (reg:CC_NOOV 100) (compare:CC_NOOV (neg:SI (match_dup 1))
					   (const_int 0)))
   (set (match_dup 0) (plus:SI (geu:SI (reg:CC 100) (const_int 0))
			       (match_dup 2)))]
  "")

(define_split
  [(set (match_operand:SI 0 "register_operand" "")
	(minus:SI (match_operand:SI 2 "register_operand" "")
		  (eq:SI (match_operand:SI 1 "register_operand" "")
			 (const_int 0))))
   (clobber (reg:CC 100))]
  ""
  [(set (reg:CC_NOOV 100) (compare:CC_NOOV (neg:SI (match_dup 1))
					   (const_int 0)))
   (set (match_dup 0) (minus:SI (match_dup 2)
				(geu:SI (reg:CC 100) (const_int 0))))]
  "")

;; Peepholes go at the end.

;; Optimize consecutive loads or stores into ldd and std when possible.
;; The conditions in which we do this are very restricted and are 
;; explained in the code for {registers,memory}_ok_for_ldd functions.

(define_peephole
  [(set (match_operand:SI 0 "register_operand" "=rf")
        (match_operand:SI 1 "memory_operand" ""))
   (set (match_operand:SI 2 "register_operand" "=rf")
        (match_operand:SI 3 "memory_operand" ""))]
  "! TARGET_ARCH64
   && registers_ok_for_ldd_peep (operands[0], operands[2]) 
   && ! MEM_VOLATILE_P (operands[1]) && ! MEM_VOLATILE_P (operands[3])
   && addrs_ok_for_ldd_peep (XEXP (operands[1], 0), XEXP (operands[3], 0))" 
  "ldd %1,%0")

(define_peephole
  [(set (match_operand:SI 0 "memory_operand" "")
        (match_operand:SI 1 "register_operand" "rf"))
   (set (match_operand:SI 2 "memory_operand" "")
        (match_operand:SI 3 "register_operand" "rf"))]
  "! TARGET_ARCH64
   && registers_ok_for_ldd_peep (operands[1], operands[3]) 
   && ! MEM_VOLATILE_P (operands[0]) && ! MEM_VOLATILE_P (operands[2])
   && addrs_ok_for_ldd_peep (XEXP (operands[0], 0), XEXP (operands[2], 0))"
  "std %1,%0")
 
(define_peephole
  [(set (match_operand:SF 0 "register_operand" "=fr")
        (match_operand:SF 1 "memory_operand" ""))
   (set (match_operand:SF 2 "register_operand" "=fr")
        (match_operand:SF 3 "memory_operand" ""))]
  "! TARGET_ARCH64
   && registers_ok_for_ldd_peep (operands[0], operands[2]) 
   && ! MEM_VOLATILE_P (operands[1]) && ! MEM_VOLATILE_P (operands[3])
   && addrs_ok_for_ldd_peep (XEXP (operands[1], 0), XEXP (operands[3], 0))"
  "ldd %1,%0")

(define_peephole
  [(set (match_operand:SF 0 "memory_operand" "")
        (match_operand:SF 1 "register_operand" "fr"))
   (set (match_operand:SF 2 "memory_operand" "")
        (match_operand:SF 3 "register_operand" "fr"))]
  "! TARGET_ARCH64
   && registers_ok_for_ldd_peep (operands[1], operands[3]) 
   && ! MEM_VOLATILE_P (operands[0]) && ! MEM_VOLATILE_P (operands[2])
   && addrs_ok_for_ldd_peep (XEXP (operands[0], 0), XEXP (operands[2], 0))"
  "std %1,%0")

(define_peephole
  [(set (match_operand:SI 0 "register_operand" "=rf")
        (match_operand:SI 1 "memory_operand" ""))
   (set (match_operand:SI 2 "register_operand" "=rf")
        (match_operand:SI 3 "memory_operand" ""))]
  "! TARGET_ARCH64
   && registers_ok_for_ldd_peep (operands[2], operands[0]) 
   && ! MEM_VOLATILE_P (operands[3]) && ! MEM_VOLATILE_P (operands[1])
   && addrs_ok_for_ldd_peep (XEXP (operands[3], 0), XEXP (operands[1], 0))"
  "ldd %3,%2")

(define_peephole
  [(set (match_operand:SI 0 "memory_operand" "")
        (match_operand:SI 1 "register_operand" "rf"))
   (set (match_operand:SI 2 "memory_operand" "")
        (match_operand:SI 3 "register_operand" "rf"))]
  "! TARGET_ARCH64
   && registers_ok_for_ldd_peep (operands[3], operands[1]) 
   && ! MEM_VOLATILE_P (operands[2]) && ! MEM_VOLATILE_P (operands[0])
   && addrs_ok_for_ldd_peep (XEXP (operands[2], 0), XEXP (operands[0], 0))" 
  "std %3,%2")
 
(define_peephole
  [(set (match_operand:SF 0 "register_operand" "=fr")
        (match_operand:SF 1 "memory_operand" ""))
   (set (match_operand:SF 2 "register_operand" "=fr")
        (match_operand:SF 3 "memory_operand" ""))]
  "! TARGET_ARCH64
   && registers_ok_for_ldd_peep (operands[2], operands[0]) 
   && ! MEM_VOLATILE_P (operands[3]) && ! MEM_VOLATILE_P (operands[1])
   && addrs_ok_for_ldd_peep (XEXP (operands[3], 0), XEXP (operands[1], 0))"
  "ldd %3,%2")

(define_peephole
  [(set (match_operand:SF 0 "memory_operand" "")
        (match_operand:SF 1 "register_operand" "fr"))
   (set (match_operand:SF 2 "memory_operand" "")
        (match_operand:SF 3 "register_operand" "fr"))]
  "! TARGET_ARCH64
   && registers_ok_for_ldd_peep (operands[3], operands[1]) 
   && ! MEM_VOLATILE_P (operands[2]) && ! MEM_VOLATILE_P (operands[0])
   && addrs_ok_for_ldd_peep (XEXP (operands[2], 0), XEXP (operands[0], 0))"
  "std %3,%2")
 
;; Optimize the case of following a reg-reg move with a test
;; of reg just moved.  Don't allow floating point regs for operand 0 or 1.
;; This can result from a float to fix conversion.

(define_peephole
  [(set (match_operand:SI 0 "register_operand" "=r")
	(match_operand:SI 1 "register_operand" "r"))
   (set (reg:CC 100)
	(compare:CC (match_operand:SI 2 "register_operand" "r")
		    (const_int 0)))]
  "(rtx_equal_p (operands[2], operands[0])
    || rtx_equal_p (operands[2], operands[1]))
   && ! FP_REG_P (operands[0]) && ! FP_REG_P (operands[1])"
  "orcc %1,0,%0")

(define_peephole
  [(set (match_operand:DI 0 "register_operand" "=r")
	(match_operand:DI 1 "register_operand" "r"))
   (set (reg:CCX 100)
	(compare:CCX (match_operand:DI 2 "register_operand" "r")
		    (const_int 0)))]
  "TARGET_ARCH64
   && (rtx_equal_p (operands[2], operands[0])
       || rtx_equal_p (operands[2], operands[1]))
   && ! FP_REG_P (operands[0]) && ! FP_REG_P (operands[1])"
  "orcc %1,0,%0")

;; Do {sign,zero}-extended compares somewhat more efficiently.
;; ??? Is this now the Right Way to do this?  Or will SCRATCH
;;     eventually have some impact here?

(define_peephole
  [(set (match_operand:HI 0 "register_operand" "")
	(match_operand:HI 1 "memory_operand" ""))
   (set (match_operand:SI 2 "register_operand" "")
	(sign_extend:SI (match_dup 0)))
   (set (reg:CC 100)
	(compare:CC (match_dup 2)
		    (const_int 0)))]
  ""
  "ldsh %1,%0\;orcc %0,0,%2")

(define_peephole
  [(set (match_operand:HI 0 "register_operand" "")
	(match_operand:HI 1 "memory_operand" ""))
   (set (match_operand:DI 2 "register_operand" "")
	(sign_extend:DI (match_dup 0)))
   (set (reg:CCX 100)
	(compare:CCX (match_dup 2)
		     (const_int 0)))]
  "TARGET_ARCH64"
  "ldsh %1,%0\;orcc %0,0,%2")

(define_peephole
  [(set (match_operand:QI 0 "register_operand" "")
	(match_operand:QI 1 "memory_operand" ""))
   (set (match_operand:SI 2 "register_operand" "")
	(sign_extend:SI (match_dup 0)))
   (set (reg:CC 100)
	(compare:CC (match_dup 2)
		    (const_int 0)))]
  ""
  "ldsb %1,%0\;orcc %0,0,%2")

(define_peephole
  [(set (match_operand:QI 0 "register_operand" "")
	(match_operand:QI 1 "memory_operand" ""))
   (set (match_operand:DI 2 "register_operand" "")
	(sign_extend:DI (match_dup 0)))
   (set (reg:CCX 100)
	(compare:CCX (match_dup 2)
		     (const_int 0)))]
  "TARGET_ARCH64"
  "ldsb %1,%0\;orcc %0,0,%2")

;; Floating-point move peepholes
;; ??? v9: Do we want similar ones?

(define_peephole
  [(set (match_operand:SI 0 "register_operand" "=r")
	(lo_sum:SI (match_dup 0)
		   (match_operand:SI 1 "immediate_operand" "i")))
   (set (match_operand:DF 2 "register_operand" "=er")
	(mem:DF (match_dup 0)))]
  "RTX_UNCHANGING_P (operands[1]) && reg_unused_after (operands[0], insn)"
  "*
{
  /* Go by way of output_move_double in case the register in operand 2
     is not properly aligned for ldd.  */
  operands[1] = gen_rtx (MEM, DFmode,
			 gen_rtx (LO_SUM, SImode, operands[0], operands[1]));
  operands[0] = operands[2];
  return output_move_double (operands);
}")

(define_peephole
  [(set (match_operand:SI 0 "register_operand" "=r")
	(lo_sum:SI (match_dup 0)
		   (match_operand:SI 1 "immediate_operand" "i")))
   (set (match_operand:SF 2 "register_operand" "=fr")
	(mem:SF (match_dup 0)))]
  "RTX_UNCHANGING_P (operands[1]) && reg_unused_after (operands[0], insn)"
  "ld [%0+%%lo(%a1)],%2")

;; Return peepholes.  First the "normal" ones.
;; These are necessary to catch insns ending up in the epilogue delay list.

(define_insn "*return_qi"
  [(set (match_operand:QI 0 "restore_operand" "")
	(match_operand:QI 1 "arith_operand" "rI"))
   (return)]
  "! TARGET_EPILOGUE && ! TARGET_LIVE_G0"
  "*
{
  if (! TARGET_ARCH64 && current_function_returns_struct)
    return \"jmp %%i7+12\;restore %%g0,%1,%Y0\";
  else
    return \"ret\;restore %%g0,%1,%Y0\";
}"
  [(set_attr "type" "multi")])

(define_insn "*return_hi"
  [(set (match_operand:HI 0 "restore_operand" "")
	(match_operand:HI 1 "arith_operand" "rI"))
   (return)]
  "! TARGET_EPILOGUE && ! TARGET_LIVE_G0"
  "*
{
  if (! TARGET_ARCH64 && current_function_returns_struct)
    return \"jmp %%i7+12\;restore %%g0,%1,%Y0\";
  else
    return \"ret\;restore %%g0,%1,%Y0\";
}"
  [(set_attr "type" "multi")])

(define_insn "*return_si"
  [(set (match_operand:SI 0 "restore_operand" "")
	(match_operand:SI 1 "arith_operand" "rI"))
   (return)]
  "! TARGET_EPILOGUE && ! TARGET_LIVE_G0"
  "*
{
  if (! TARGET_ARCH64 && current_function_returns_struct)
    return \"jmp %%i7+12\;restore %%g0,%1,%Y0\";
  else
    return \"ret\;restore %%g0,%1,%Y0\";
}"
  [(set_attr "type" "multi")])

;; The following pattern is only generated by delayed-branch scheduling,
;; when the insn winds up in the epilogue.  This can only happen when
;; ! TARGET_FPU because otherwise fp return values are in %f0.
(define_insn "*return_sf_no_fpu"
  [(set (match_operand:SF 0 "restore_operand" "r")
	(match_operand:SF 1 "register_operand" "r"))
   (return)]
  "! TARGET_FPU && ! TARGET_EPILOGUE && ! TARGET_LIVE_G0"
  "*
{
  if (! TARGET_ARCH64 && current_function_returns_struct)
    return \"jmp %%i7+12\;restore %%g0,%1,%Y0\";
  else
    return \"ret\;restore %%g0,%1,%Y0\";
}"
  [(set_attr "type" "multi")])

(define_insn "*return_addsi"
  [(set (match_operand:SI 0 "restore_operand" "")
	(plus:SI (match_operand:SI 1 "arith_operand" "%r")
		 (match_operand:SI 2 "arith_operand" "rI")))
   (return)]
  "! TARGET_EPILOGUE && ! TARGET_LIVE_G0
   && (register_operand (operands[1], SImode)
       || register_operand (operands[2], SImode))"
  "*
{
  if (! TARGET_ARCH64 && current_function_returns_struct)
    return \"jmp %%i7+12\;restore %r1,%2,%Y0\";
  else
    return \"ret\;restore %r1,%2,%Y0\";
}"
  [(set_attr "type" "multi")])

(define_insn "*return_di"
  [(set (match_operand:DI 0 "restore_operand" "")
	(match_operand:DI 1 "arith_double_operand" "rHI"))
   (return)]
  "TARGET_ARCH64 && ! TARGET_EPILOGUE"
  "ret\;restore %%g0,%1,%Y0"
  [(set_attr "type" "multi")])

(define_insn "*return_adddi"
  [(set (match_operand:DI 0 "restore_operand" "")
	(plus:DI (match_operand:DI 1 "arith_double_operand" "%r")
		 (match_operand:DI 2 "arith_double_operand" "rHI")))
   (return)]
  "TARGET_ARCH64 && ! TARGET_EPILOGUE
   && (register_operand (operands[1], DImode)
       || register_operand (operands[2], DImode))"
  "ret\;restore %r1,%2,%Y0"
  [(set_attr "type" "multi")])

(define_insn "*return_subsi"
  [(set (match_operand:SI 0 "restore_operand" "")
	(minus:SI (match_operand:SI 1 "register_operand" "r")
		  (match_operand:SI 2 "small_int" "I")))
   (return)]
  "! TARGET_EPILOGUE && INTVAL (operands[2]) != -4096"
  "ret\;restore %1,%n2,%Y0"
  [(set_attr "type" "multi")])

;; The following pattern is only generated by delayed-branch scheduling,
;; when the insn winds up in the epilogue.
(define_insn "*return_sf"
  [(set (reg:SF 32)
	(match_operand:SF 0 "register_operand" "f"))
   (return)]
  "! TARGET_EPILOGUE"
  "ret\;fmovs %0,%%f0"
  [(set_attr "type" "multi")])

;; Now peepholes to do a call followed by a jump.

(define_peephole
  [(parallel [(set (match_operand 0 "" "")
		   (call (mem:SI (match_operand:SI 1 "call_operand_address" "ps"))
			 (match_operand 2 "" "")))
	      (clobber (reg:SI 15))])
   (set (pc) (label_ref (match_operand 3 "" "")))]
  "short_branch (INSN_UID (insn), INSN_UID (operands[3]))"
  "call %a1,%2\;add %%o7,(%l3-.-4),%%o7")

(define_peephole
  [(parallel [(call (mem:SI (match_operand:SI 0 "call_operand_address" "ps"))
		    (match_operand 1 "" ""))
	      (clobber (reg:SI 15))])
   (set (pc) (label_ref (match_operand 2 "" "")))]
  "short_branch (INSN_UID (insn), INSN_UID (operands[2]))"
  "*
{
  return \"call %a0,%1\;add %%o7,(%l2-.-4),%%o7\";
}")

(define_peephole
  [(parallel [(set (match_operand 0 "" "")
		   (call (mem:SI (match_operand:DI 1 "call_operand_address" "ps"))
			 (match_operand 2 "" "")))
	      (clobber (reg:DI 15))])
   (set (pc) (label_ref (match_operand 3 "" "")))]
  "TARGET_ARCH64 && short_branch (INSN_UID (insn), INSN_UID (operands[3]))"
  "call %a1,%2\;add %%o7,(%l3-.-4),%%o7")

(define_peephole
  [(parallel [(call (mem:SI (match_operand:DI 0 "call_operand_address" "ps"))
		    (match_operand 1 "" ""))
	      (clobber (reg:DI 15))])
   (set (pc) (label_ref (match_operand 2 "" "")))]
  "TARGET_ARCH64 && short_branch (INSN_UID (insn), INSN_UID (operands[2]))"
  "call %a0,%1\;add %%o7,(%l2-.-4),%%o7")

;; Other miscellaneous peepholes.

;; (reg:SI 100) is created by the {add,neg,sub}di patterns.
(define_peephole
  [(parallel [(set (match_operand:SI 0 "register_operand" "=r")
		   (minus:SI (match_operand:SI 1 "reg_or_0_operand" "rJ")
			     (reg:SI 100)))
	      (clobber (reg:CC 100))])
   (set (reg:CC 100) (compare (match_dup 0) (const_int 0)))]
  ""
  "subxcc %r1,0,%0")

;; After a nonlocal goto, we need to restore the PIC register, but only
;; if we need it.  So do nothing much here, but we'll check for this in
;; finalize_pic.

(define_insn "nonlocal_goto_receiver"
  [(unspec_volatile [(const_int 0)] 4)]
  "flag_pic"
  "")
@


1.2
log
@GCC 2.8.0 merge
@
text
@@


1.1
log
@Initial revision
@
text
@d2 1
a2 1
;;  Copyright (C) 1987, 88, 89, 92, 93, 94, 1995 Free Software Foundation, Inc.
d31 3
d35 14
a48 1
;; Architecture type.  Arch32bit includes v7, sparclite, v8.
d50 1
d52 3
a54 1
  (const (symbol_ref "sparc_arch_type")))
d56 2
a57 2
;; CPU type. This is only used for instruction scheduling
(define_attr "cpu" "cypress,supersparc"
d59 2
a60 2
  (cond [(symbol_ref "TARGET_SUPERSPARC") (const_string "supersparc")]
	(const_string "cypress"))))
d258 54
d332 1
a332 1
  [(set (reg:CC 0)
d344 1
a344 1
  [(set (reg:CCX 0)
d347 1
a347 1
  "TARGET_V9"
d356 2
a357 1
  [(set (reg:CCFP 0)
d369 2
a370 1
  [(set (reg:CCFP 0)
d382 2
a383 1
  [(set (reg:CCFP 0)
d394 96
d506 2
a507 2
	      (clobber (reg:CC 0))])]
  ""
d514 3
a516 4
   (parallel [(set (match_operand:DI 0 "register_operand" "")
		   (eq:DI (match_dup 3) (const_int 0)))
	      (clobber (reg:CCX 0))])]
  ""
d525 2
a526 2
	      (clobber (reg:CC 0))])]
  ""
d533 3
a535 4
   (parallel [(set (match_operand:DI 0 "register_operand" "")
		   (ne:DI (match_dup 3) (const_int 0)))
	      (clobber (reg:CCX 0))])]
  ""
d542 3
a544 4
   (parallel [(set (match_operand:SI 0 "register_operand" "")
		   (eq:SI (subreg:SI (match_dup 3) 0) (const_int 0)))
	      (clobber (reg:CC 0))])]
  ""
d551 3
a553 4
   (parallel [(set (match_operand:SI 0 "register_operand" "")
		   (ne:SI (subreg:SI (match_dup 3) 0) (const_int 0)))
	      (clobber (reg:CC 0))])]
  ""
d557 1
a557 1
  [(set (subreg:SI (match_dup 3) 0)
d561 4
a564 4
		   (eq:DI (match_dup 3) (const_int 0)))
	      (clobber (reg:CCX 0))])]
  ""
  "{ operands[3] = gen_reg_rtx (DImode); }")
d567 1
a567 1
  [(set (subreg:SI (match_dup 3) 0)
d571 4
a574 4
		   (ne:DI (match_dup 3) (const_int 0)))
	      (clobber (reg:CCX 0))])]
  ""
  "{ operands[3] = gen_reg_rtx (DImode); }")
d581 1
a581 1
  ""
d591 1
a591 1
      else if (! TARGET_V9)
d603 3
a605 1
      if (GET_MODE (operands[0]) == SImode)
a607 2
      else if (! TARGET_V9)
	FAIL;
d634 1
a634 1
  ""
d644 1
a644 1
      else if (! TARGET_V9)
d656 3
a658 1
      if (GET_MODE (operands[0]) == SImode)
a660 2
      else if (! TARGET_V9)
	FAIL;
d685 1
a685 1
  ""
d706 1
a706 1
  ""
d727 1
a727 1
  ""
d748 1
a748 1
  ""
d769 1
a769 1
  ""
d801 1
a801 1
  ""
d815 1
a815 1
  ""
d829 1
a829 1
  ""
d858 1
a858 113
;; Now the DEFINE_INSNs for the compare and scc cases.  First the compares.

(define_insn "*cmpsi_insn"
  [(set (reg:CC 0)
	(compare:CC (match_operand:SI 0 "register_operand" "r")
		    (match_operand:SI 1 "arith_operand" "rI")))]
  ""
  "cmp %r0,%1"
  [(set_attr "type" "compare")])

(define_insn "*cmpsf_fpe_sp32"
  [(set (reg:CCFPE 0)
	(compare:CCFPE (match_operand:SF 0 "register_operand" "f")
		       (match_operand:SF 1 "register_operand" "f")))]
  "! TARGET_V9 && TARGET_FPU"
  "fcmpes %0,%1"
  [(set_attr "type" "fpcmp")])

(define_insn "*cmpdf_fpe_sp32"
  [(set (reg:CCFPE 0)
	(compare:CCFPE (match_operand:DF 0 "register_operand" "e")
		       (match_operand:DF 1 "register_operand" "e")))]
  "! TARGET_V9 && TARGET_FPU"
  "fcmped %0,%1"
  [(set_attr "type" "fpcmp")])

(define_insn "*cmptf_fpe_sp32"
  [(set (reg:CCFPE 0)
	(compare:CCFPE (match_operand:TF 0 "register_operand" "e")
		       (match_operand:TF 1 "register_operand" "e")))]
  "! TARGET_V9 && TARGET_FPU && TARGET_HARD_QUAD"
  "fcmpeq %0,%1"
  [(set_attr "type" "fpcmp")])

(define_insn "*cmpsf_fp_sp32"
  [(set (reg:CCFP 0)
	(compare:CCFP (match_operand:SF 0 "register_operand" "f")
		      (match_operand:SF 1 "register_operand" "f")))]
  "! TARGET_V9 && TARGET_FPU"
  "fcmps %0,%1"
  [(set_attr "type" "fpcmp")])

(define_insn "*cmpdf_fp_sp32"
  [(set (reg:CCFP 0)
	(compare:CCFP (match_operand:DF 0 "register_operand" "e")
		      (match_operand:DF 1 "register_operand" "e")))]
  "! TARGET_V9 && TARGET_FPU"
  "fcmpd %0,%1"
  [(set_attr "type" "fpcmp")])

(define_insn "*cmptf_fp_sp32"
  [(set (reg:CCFP 0)
	(compare:CCFP (match_operand:TF 0 "register_operand" "e")
		      (match_operand:TF 1 "register_operand" "e")))]
  "! TARGET_V9 && TARGET_FPU && TARGET_HARD_QUAD"
  "fcmpq %0,%1"
  [(set_attr "type" "fpcmp")])

(define_insn "*cmpdi_sp64"
  [(set (reg:CCX 0)
	(compare:CCX (match_operand:DI 0 "register_operand" "r")
		     (match_operand:DI 1 "arith_double_operand" "rHI")))]
  "TARGET_V9"
  "cmp %r0,%1"
  [(set_attr "type" "compare")])

(define_insn "*cmpsf_fpe_sp64"
  [(set (match_operand:CCFPE 0 "ccfp_reg_operand" "=c")
	(compare:CCFPE (match_operand:SF 1 "register_operand" "f")
		       (match_operand:SF 2 "register_operand" "f")))]
  "TARGET_V9 && TARGET_FPU"
  "fcmpes %0,%1,%2"
  [(set_attr "type" "fpcmp")])

(define_insn "*cmpdf_fpe_sp64"
  [(set (match_operand:CCFPE 0 "ccfp_reg_operand" "=c")
	(compare:CCFPE (match_operand:DF 1 "register_operand" "e")
		       (match_operand:DF 2 "register_operand" "e")))]
  "TARGET_V9 && TARGET_FPU"
  "fcmped %0,%1,%2"
  [(set_attr "type" "fpcmp")])

(define_insn "*cmptf_fpe_sp64"
  [(set (match_operand:CCFPE 0 "ccfp_reg_operand" "=c")
	(compare:CCFPE (match_operand:TF 1 "register_operand" "e")
		       (match_operand:TF 2 "register_operand" "e")))]
  "TARGET_V9 && TARGET_FPU && TARGET_HARD_QUAD"
  "fcmpeq %0,%1,%2"
  [(set_attr "type" "fpcmp")])

(define_insn "*cmpsf_fp_sp64"
  [(set (match_operand:CCFP 0 "ccfp_reg_operand" "=c")
	(compare:CCFP (match_operand:SF 1 "register_operand" "f")
		      (match_operand:SF 2 "register_operand" "f")))]
  "TARGET_V9 && TARGET_FPU"
  "fcmps %0,%1,%2"
  [(set_attr "type" "fpcmp")])

(define_insn "*cmpdf_fp_sp64"
  [(set (match_operand:CCFP 0 "ccfp_reg_operand" "=c")
	(compare:CCFP (match_operand:DF 1 "register_operand" "e")
		      (match_operand:DF 2 "register_operand" "e")))]
  "TARGET_V9 && TARGET_FPU"
  "fcmpd %0,%1,%2"
  [(set_attr "type" "fpcmp")])

(define_insn "*cmptf_fp_sp64"
  [(set (match_operand:CCFP 0 "ccfp_reg_operand" "=c")
	(compare:CCFP (match_operand:TF 1 "register_operand" "e")
		      (match_operand:TF 2 "register_operand" "e")))]
  "TARGET_V9 && TARGET_FPU && TARGET_HARD_QUAD"
  "fcmpq %0,%1,%2"
  [(set_attr "type" "fpcmp")])
d867 2
a868 2
   (clobber (reg:CC 0))]
  ""
d877 2
a878 2
   (clobber (reg:CC 0))]
  ""
d883 10
d894 1
a894 1
  [(set (match_operand:DI 0 "register_operand" "=r")
d896 2
a897 3
	       (const_int 0)))
   (clobber (reg:CCX 0))]
  "TARGET_V9"
d903 1
a903 1
  [(set (match_operand:DI 0 "register_operand" "=r")
d905 2
a906 3
		       (const_int 0))))
   (clobber (reg:CCX 0))]
  "TARGET_V9"
d911 9
d924 2
a925 2
   (clobber (reg:CC 0))]
  ""
d934 2
a935 2
   (clobber (reg:CC 0))]
  ""
d940 10
d951 1
a951 1
  [(set (match_operand:DI 0 "register_operand" "=r")
d953 2
a954 3
	       (const_int 0)))
   (clobber (reg:CCX 0))]
  "TARGET_V9"
d960 1
a960 1
  [(set (match_operand:DI 0 "register_operand" "=r")
d962 2
a963 3
		       (const_int 0))))
   (clobber (reg:CCX 0))]
  "TARGET_V9"
d968 9
d986 2
a987 2
   (clobber (reg:CC 0))]
  ""
d996 2
a997 2
   (clobber (reg:CC 0))]
  ""
d1006 2
a1007 2
   (clobber (reg:CC 0))]
  ""
d1016 2
a1017 2
   (clobber (reg:CC 0))]
  ""
d1027 2
a1028 2
	(ltu:SI (reg:CC 0) (const_int 0)))]
  ""
d1034 2
a1035 2
	(neg:SI (ltu:SI (reg:CC 0) (const_int 0))))]
  ""
d1042 1
a1042 1
	(minus:SI (neg:SI (ltu:SI (reg:CC 0) (const_int 0)))
d1044 1
a1044 1
  ""
d1050 1
a1050 1
	(neg:SI (plus:SI (ltu:SI (reg:CC 0) (const_int 0))
d1052 1
a1052 1
  ""
d1058 2
a1059 2
	(geu:SI (reg:CC 0) (const_int 0)))]
  ""
d1065 2
a1066 2
	(neg:SI (geu:SI (reg:CC 0) (const_int 0))))]
  ""
d1076 1
a1076 1
	(plus:SI (ltu:SI (reg:CC 0) (const_int 0))
d1078 1
a1078 1
  ""
d1084 1
a1084 1
	(plus:SI (ltu:SI (reg:CC 0) (const_int 0))
d1093 1
a1093 1
		  (ltu:SI (reg:CC 0) (const_int 0))))]
d1103 1
a1103 1
		  (ltu:SI (reg:CC 0) (const_int 0))))]
d1110 1
a1110 1
		  (plus:SI (ltu:SI (reg:CC 0) (const_int 0))
d1117 1
a1117 1
	(plus:SI (geu:SI (reg:CC 0) (const_int 0))
d1126 1
a1126 1
		  (geu:SI (reg:CC 0) (const_int 0))))]
d1139 3
a1141 1
	(match_operator:SI 1 "noov_compare_op" [(reg 0) (const_int 0)]))]
d1149 4
a1152 2
	(match_operator:DI 1 "noov_compare_op" [(reg 0) (const_int 0)]))]
  "TARGET_V9"
d1171 1
a1171 1
  if (TARGET_V9 && sparc_compare_op1 == const0_rtx
d1195 1
a1195 1
  if (TARGET_V9 && sparc_compare_op1 == const0_rtx
d1219 1
a1219 1
  if (TARGET_V9 && sparc_compare_op1 == const0_rtx
d1253 1
a1253 1
  if (TARGET_V9 && sparc_compare_op1 == const0_rtx
d1287 1
a1287 1
  if (TARGET_V9 && sparc_compare_op1 == const0_rtx
d1321 1
a1321 1
  if (TARGET_V9 && sparc_compare_op1 == const0_rtx
d1352 1
a1352 1
				      [(reg 0) (const_int 0)])
d1358 1
a1358 1
  return output_cbranch (operands[0], 0, 1, 0,
d1367 1
a1367 1
				      [(reg 0) (const_int 0)])
d1373 1
a1373 1
  return output_cbranch (operands[0], 0, 1, 1,
d1379 1
a1379 1
(define_insn "*normal_fp_branch_sp64"
d1381 2
a1382 2
	(if_then_else (match_operator 0 "comparison_operator"
				      [(match_operand:CCFP 1 "ccfp_reg_operand" "c")
d1386 1
a1386 1
  "TARGET_V9"
d1389 1
a1389 1
  return output_cbranch (operands[0], operands[1], 2, 0,
d1395 1
a1395 1
(define_insn "*inverted_fp_branch_sp64"
d1397 2
a1398 2
	(if_then_else (match_operator 0 "comparison_operator"
				      [(match_operand:CCFP 1 "ccfp_reg_operand" "c")
d1402 1
a1402 1
  "TARGET_V9"
d1405 1
a1405 1
  return output_cbranch (operands[0], operands[1], 2, 1,
d1411 1
a1411 1
(define_insn "*normal_fpe_branch_sp64"
d1413 2
a1414 2
	(if_then_else (match_operator 0 "comparison_operator"
				      [(match_operand:CCFPE 1 "ccfp_reg_operand" "c")
d1418 1
a1418 1
  "TARGET_V9"
d1421 1
a1421 1
  return output_cbranch (operands[0], operands[1], 2, 0,
d1427 1
a1427 1
(define_insn "*inverted_fpe_branch_sp64"
d1429 2
a1430 2
	(if_then_else (match_operator 0 "comparison_operator"
				      [(match_operand:CCFPE 1 "ccfp_reg_operand" "c")
d1434 1
a1434 1
  "TARGET_V9"
d1437 1
a1437 1
  return output_cbranch (operands[0], operands[1], 2, 1,
d1455 1
a1455 1
  "TARGET_V9"
d1471 1
a1471 1
  "TARGET_V9"
d1489 1
a1489 1
  "* return TARGET_V9 ? \"add %1,%%lo(%a2),%0\" : \"or %1,%%lo(%a2),%0\";"
d1496 1
a1496 1
(define_insn "*pic_lo_sum_si"
d1500 1
a1500 1
  ""
d1503 1
a1503 1
  "* return TARGET_V9 ? \"add %1,%%lo(%a2),%0\" : \"or %1,%%lo(%a2),%0\";"
d1508 2
d1512 1
a1512 1
(define_insn "*pic_sethi_si"
d1515 1
a1515 1
  "check_pic (1)"
d1520 12
a1531 4
(define_insn "*sethi_si"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(high:SI (match_operand 1 "" "")))]
  "check_pic (1)"
d1536 12
a1547 7
(define_insn "*sethi_hi"
  [(set (match_operand:HI 0 "register_operand" "=r")
	(high:HI (match_operand 1 "" "")))]
  "check_pic (1)"
  "sethi %%hi(%a1),%0"
  [(set_attr "type" "move")
   (set_attr "length" "1")])
d1551 1
a1551 1
;; there.
d1553 1
a1553 1
(define_insn "*move_pic_label_si"
d1555 3
a1557 1
	(match_operand:SI 1 "move_pic_label" "i"))
d1559 8
a1566 2
  ""
  "\\n1:\;call 2f\;sethi %%hi(%l1-1b),%0\\n2:\\tor %0,%%lo(%l1-1b),%0\;add %0,%%o7,%0"
d1568 5
a1572 1
   (set_attr "length" "4")])
d1574 14
a1587 5
;; v9 special pic pattern, for loading the address of a label into a register.

(define_insn "*move_pic_label_di"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(match_operand:DI 1 "move_pic_label" "i"))
d1589 8
a1596 2
  "TARGET_V9"
  "\\n1:\;call 2f\;sethi %%hi(%l1-1b),%0\\n2:\\tor %0,%%lo(%l1-1b),%0\;add %0,%%o7,%0"
d1598 23
a1620 1
   (set_attr "length" "4")])
d1626 1
a1626 1
  "! TARGET_V9"
d1632 7
a1638 2
    operands[2] = gen_rtx (CONST_INT, VOIDmode, CONST_DOUBLE_LOW (operands[2]));
  return \"or %R1,%%lo(%a2),%R0\";
a1643 2
;; ??? Gas does not handle %lo(DI), so we use the same code for ! TARGET_V9.
;; ??? The previous comment is obsolete.
d1650 1
a1650 1
  "TARGET_V9"
d1656 6
a1661 1
    operands[2] = gen_rtx (CONST_INT, VOIDmode, CONST_DOUBLE_LOW (operands[2]));
d1673 1
a1673 1
  "! TARGET_V9 && check_pic (1)"
d1693 1
a1693 1
      operands[1] = gen_rtx (CONST_INT, VOIDmode, CONST_DOUBLE_LOW (op1));
d1697 1
a1697 1
      operands[1] = gen_rtx (CONST_INT, VOIDmode, CONST_DOUBLE_HIGH (op1));
d1716 7
a1722 4
;;; Gas doesn't have any 64 bit constant support, so don't use %uhi and %ulo
;;; on constants.  Symbols have to be handled by the linker, so we must use
;;; %uhi and %ulo for them, but gas will handle these correctly.
;;; ??? This comment is obsolete, gas handles them now.
d1724 1
a1724 1
(define_insn "*sethi_di_sp64"
d1728 1
a1728 1
  "TARGET_V9 && check_pic (1)"
d1731 1
d1751 20
d1780 2
a1781 1
;; uses the same "%X+%lo(...)" in the load/store insn.
d1783 1
a1783 1
;; When TARGET_MEDLOW, assume that the upper 32 bits of symbol addresses are
d1785 9
a1793 4
;; When TARGET_MEDANY, the upper 32 bits of function addresses are 0.
;; The data segment has a maximum size of 32 bits, but may be located anywhere.
;; MEDANY_BASE_REG contains the start address, currently %g4.
;; When TARGET_FULLANY, symbolic addresses are 64 bits.
d1798 1
a1798 1
;; ??? Why the clobber?
d1800 9
a1808 1
  "TARGET_MEDLOW && check_pic (1)"
d1816 1
a1816 1
(define_insn "*sethi_di_medany_data"
d1819 1
a1819 1
;; ??? Why the clobber?
d1821 2
a1822 2
  "TARGET_MEDANY && check_pic (1)"
  "sethi %%hi(%a1),%0; add %0,%%g4,%0"
d1826 1
a1826 1
(define_insn "*sethi_di_medany_text"
d1829 1
a1829 10
;; ??? Why the clobber?
   (clobber (reg:DI 1))]
  "TARGET_MEDANY && check_pic (1)"
  "sethi %%hi(%a1),%0"
  [(set_attr "type" "move")
   (set_attr "length" "1")])

(define_insn "*sethi_di_fullany"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(high:DI (match_operand 1 "" "")))
d1831 1
a1831 1
  "TARGET_FULLANY && check_pic (1)"
d1851 4
a1854 3
  "register_operand (operands[0], QImode)
   || register_operand (operands[1], QImode)
   || operands[1] == const0_rtx"
d1861 17
a1877 1
   (set_attr "length" "*,1,*,1")])
d1891 2
a1892 1
  "(reload_completed || reload_in_progress) && ! TARGET_PTR64"
d1910 4
a1913 3
  "register_operand (operands[0], HImode)
   || register_operand (operands[1], HImode)
   || operands[1] == const0_rtx"
d1920 17
a1936 1
   (set_attr "length" "*,1,*,1")])
d1950 2
a1951 1
  "(reload_completed || reload_in_progress) && ! TARGET_PTR64"
d1977 4
a1980 3
  "register_operand (operands[0], SImode)
   || register_operand (operands[1], SImode)
   || operands[1] == const0_rtx"
d1988 22
a2009 3
   st %r1,%0"
  [(set_attr "type" "move,fp,move,load,load,store,store")
   (set_attr "length" "*,*,1,*,*,*,*")])
d2015 2
a2016 1
  "(reload_completed || reload_in_progress) && ! TARGET_PTR64"
d2034 1
a2034 1
  "! TARGET_V9
d2058 1
a2058 1
  "TARGET_V9
d2079 1
a2079 2
	  operands[1] = gen_rtx (CONST_INT, VOIDmode,
				 ~ INTVAL (operands[1]));
d2119 1
a2119 1
;	      (clobber (reg:SI 0))
d2145 1
a2145 1
;   (clobber (reg:SI 0))
d2160 4
a2163 1
  "TARGET_FPU && GET_CODE (operands[1]) == CONST_DOUBLE"
d2200 2
a2201 2
   st %r1,%0
   st %r1,%0"
d2217 1
a2217 1
   st %r1,%0"
d2224 2
a2225 1
  "(reload_completed || reload_in_progress) && ! TARGET_PTR64"
d2237 4
a2240 1
  "TARGET_FPU && GET_CODE (operands[1]) == CONST_DOUBLE"
d2250 1
a2250 1
      if (TARGET_V9)
d2305 1
a2305 1
;; ??? Do we need a v9 version of this?
d2309 3
a2311 1
  "! TARGET_V9 && reload_completed"
d2339 2
a2340 1
  "(reload_completed || reload_in_progress) && ! TARGET_PTR64"
d2358 4
a2361 1
  "TARGET_FPU && GET_CODE (operands[1]) == CONST_DOUBLE"
d2371 1
a2371 1
      if (TARGET_V9)
d2440 2
a2441 1
  "0 && (reload_completed || reload_in_progress) && ! TARGET_PTR64"
d2455 65
a2519 2
;; We can handle larger constants here for some flavors, but for now we play
;; it safe and only allow those constants supported by all flavours.
d2523 3
a2525 3
	(if_then_else (match_operand 1 "comparison_operator" "")
		      (match_operand:SI 2 "arith10_operand" "")
		      (match_operand:SI 3 "register_operand" "")))]
d2531 4
d2553 4
a2556 4
	(if_then_else (match_operand 1 "comparison_operator" "")
		      (match_operand:DI 2 "arith10_operand" "")
		      (match_operand:DI 3 "register_operand" "")))]
  "TARGET_V9"
d2579 4
a2582 4
	(if_then_else (match_operand 1 "comparison_operator" "")
		      (match_operand:SF 2 "register_operand" "")
		      (match_operand:SF 3 "register_operand" "")))]
  "TARGET_V9"
d2587 4
d2609 4
a2612 4
	(if_then_else (match_operand 1 "comparison_operator" "")
		      (match_operand:DF 2 "register_operand" "")
		      (match_operand:DF 3 "register_operand" "")))]
  "TARGET_V9"
d2617 4
d2639 4
a2642 4
	(if_then_else (match_operand 1 "comparison_operator" "")
		      (match_operand:TF 2 "register_operand" "")
		      (match_operand:TF 3 "register_operand" "")))]
  "TARGET_V9"
d2647 4
d2667 1
a2667 21
/* Conditional move define_insns.  */

(define_insn "*movsi_cc_sp64"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(if_then_else (match_operator 1 "comparison_operator"
				      [(reg:CC 0) (const_int 0)])
		      (match_operand:SI 2 "arith11_operand" "ri")
		      (match_operand:SI 3 "register_operand" "0")))]
  "TARGET_V9"
  "mov%C1 %%icc,%2,%0"
  [(set_attr "type" "cmove")])

(define_insn "*movdi_cc_sp64"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(if_then_else (match_operator 1 "comparison_operator"
				      [(reg:CC 0) (const_int 0)])
		      (match_operand:DI 2 "arith11_double_operand" "rHI")
		      (match_operand:DI 3 "register_operand" "0")))]
  "TARGET_V9"
  "mov%C1 %%icc,%2,%0"
  [(set_attr "type" "cmove")])
d2669 4
a2672 24
(define_insn "*movsi_ccx_sp64"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(if_then_else (match_operator 1 "comparison_operator"
				      [(reg:CCX 0) (const_int 0)])
		      (match_operand:SI 2 "arith11_operand" "ri")
		      (match_operand:SI 3 "register_operand" "0")))]
  "TARGET_V9"
  "mov%C1 %%xcc,%2,%0"
  [(set_attr "type" "cmove")])

(define_insn "*movdi_ccx_sp64"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(if_then_else (match_operator 1 "comparison_operator"
				      [(reg:CCX 0) (const_int 0)])
		      (match_operand:DI 2 "arith11_double_operand" "rHI")
		      (match_operand:DI 3 "register_operand" "0")))]
  "TARGET_V9"
  "mov%C1 %%xcc,%2,%0"
  [(set_attr "type" "cmove")])

(define_insn "*movsi_ccfp_sp64"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(if_then_else (match_operator 1 "comparison_operator"
				[(match_operand:CCFP 2 "ccfp_reg_operand" "c")
d2674 2
a2675 2
		      (match_operand:SI 3 "arith11_operand" "ri")
		      (match_operand:SI 4 "register_operand" "0")))]
d2677 3
a2679 1
  "mov%C1 %2,%3,%0"
d2682 4
a2685 4
(define_insn "*movsi_ccfpe_sp64"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(if_then_else (match_operator 1 "comparison_operator"
				[(match_operand:CCFPE 2 "ccfp_reg_operand" "c")
d2687 2
a2688 2
		      (match_operand:SI 3 "arith11_operand" "ri")
		      (match_operand:SI 4 "register_operand" "0")))]
d2690 3
a2692 1
  "mov%C1 %2,%3,%0"
d2695 4
a2698 4
(define_insn "*movdi_ccfp_sp64"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(if_then_else (match_operator 1 "comparison_operator"
				[(match_operand:CCFP 2 "ccfp_reg_operand" "c")
d2700 2
a2701 2
		      (match_operand:DI 3 "arith11_double_operand" "rHI")
		      (match_operand:DI 4 "register_operand" "0")))]
d2703 3
a2705 1
  "mov%C1 %2,%3,%0"
d2708 5
a2712 4
(define_insn "*movdi_ccfpe_sp64"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(if_then_else (match_operator 1 "comparison_operator"
				[(match_operand:CCFPE 2 "ccfp_reg_operand" "c")
d2714 6
a2719 4
		      (match_operand:DI 3 "arith11_double_operand" "rHI")
		      (match_operand:DI 4 "register_operand" "0")))]
  "TARGET_V9"
  "mov%C1 %2,%3,%0"
d2722 4
a2725 4
(define_insn "*movsi_cc_reg_sp64"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(if_then_else (match_operator 1 "v9_regcmp_op"
				[(match_operand:DI 2 "register_operand" "r")
d2727 2
a2728 24
		      (match_operand:SI 3 "arith10_operand" "ri")
		      (match_operand:SI 4 "register_operand" "0")))]
  "TARGET_V9"
  "movr%D1 %2,%r3,%0"
  [(set_attr "type" "cmove")])

(define_insn "*movdi_cc_reg_sp64"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(if_then_else (match_operator 1 "v9_regcmp_op"
				[(match_operand:DI 2 "register_operand" "r")
				 (const_int 0)])
		      (match_operand:DI 3 "arith10_double_operand" "ri")
		      (match_operand:DI 4 "register_operand" "0")))]
  "TARGET_V9"
  "movr%D1 %2,%r3,%0"
  [(set_attr "type" "cmove")])

(define_insn "*movsf_cc_reg_sp64"
  [(set (match_operand:SF 0 "register_operand" "=f")
	(if_then_else (match_operator 1 "v9_regcmp_op"
				[(match_operand:DI 2 "register_operand" "r")
				 (const_int 0)])
		      (match_operand:SF 3 "register_operand" "f")
		      (match_operand:SF 4 "register_operand" "0")))]
d2730 3
a2732 1
  "fmovrs%D1 %2,%r3,%0"
d2735 4
a2738 4
(define_insn "*movdf_cc_reg_sp64"
  [(set (match_operand:DF 0 "register_operand" "=e")
	(if_then_else (match_operator 1 "v9_regcmp_op"
				[(match_operand:DI 2 "register_operand" "r")
d2740 2
a2741 2
		      (match_operand:DF 3 "register_operand" "e")
		      (match_operand:DF 4 "register_operand" "0")))]
d2743 3
a2745 1
  "fmovrd%D1 %2,%r3,%0"
d2748 4
a2751 4
(define_insn "*movtf_cc_reg_sp64"
  [(set (match_operand:TF 0 "register_operand" "=e")
	(if_then_else (match_operator 1 "v9_regcmp_op"
				[(match_operand:DI 2 "register_operand" "r")
d2753 6
a2758 48
		      (match_operand:TF 3 "register_operand" "e")
		      (match_operand:TF 4 "register_operand" "0")))]
  "TARGET_V9 && TARGET_FPU"
  "fmovrq%D1 %2,%r3,%0"
  [(set_attr "type" "cmove")])

(define_insn "*movsf_ccfp_sp64"
  [(set (match_operand:SF 0 "register_operand" "=f")
	(if_then_else (match_operator 1 "comparison_operator"
				[(match_operand:CCFP 2 "ccfp_reg_operand" "c")
				 (const_int 0)])
		      (match_operand:SF 3 "register_operand" "f")
		      (match_operand:SF 4 "register_operand" "0")))]
  "TARGET_V9 && TARGET_FPU"
  "fmovs%C1 %2,%3,%0"
  [(set_attr "type" "cmove")])

(define_insn "*movsf_ccfpe_sp64"
  [(set (match_operand:SF 0 "register_operand" "=f")
	(if_then_else (match_operator 1 "comparison_operator"
				[(match_operand:CCFPE 2 "ccfp_reg_operand" "c")
				 (const_int 0)])
		      (match_operand:SF 3 "register_operand" "f")
		      (match_operand:SF 4 "register_operand" "0")))]
  "TARGET_V9 && TARGET_FPU"
  "fmovs%C1 %2,%3,%0"
  [(set_attr "type" "cmove")])

(define_insn "*movdf_ccfp_sp64"
  [(set (match_operand:DF 0 "register_operand" "=e")
	(if_then_else (match_operator 1 "comparison_operator"
				[(match_operand:CCFP 2 "ccfp_reg_operand" "c")
				 (const_int 0)])
		      (match_operand:DF 3 "register_operand" "e")
		      (match_operand:DF 4 "register_operand" "0")))]
  "TARGET_V9 && TARGET_FPU"
  "fmovd%C1 %2,%3,%0"
  [(set_attr "type" "cmove")])

(define_insn "*movdf_ccfpe_sp64"
  [(set (match_operand:DF 0 "register_operand" "=e")
	(if_then_else (match_operator 1 "comparison_operator"
				[(match_operand:CCFPE 2 "ccfp_reg_operand" "c")
				 (const_int 0)])
		      (match_operand:DF 3 "register_operand" "e")
		      (match_operand:DF 4 "register_operand" "0")))]
  "TARGET_V9 && TARGET_FPU"
  "fmovd%C1 %2,%3,%0"
d2761 4
a2764 4
(define_insn "*movtf_ccfp_sp64"
  [(set (match_operand:TF 0 "register_operand" "=e")
	(if_then_else (match_operator 1 "comparison_operator"
				[(match_operand:CCFP 2 "ccfp_reg_operand" "c")
d2766 6
a2771 4
		      (match_operand:TF 3 "register_operand" "e")
		      (match_operand:TF 4 "register_operand" "0")))]
  "TARGET_V9 && TARGET_FPU"
  "fmovq%C1 %2,%3,%0"
d2774 4
a2777 4
(define_insn "*movtf_ccfpe_sp64"
  [(set (match_operand:TF 0 "register_operand" "=e")
	(if_then_else (match_operator 1 "comparison_operator"
				[(match_operand:CCFPE 2 "ccfp_reg_operand" "c")
d2779 6
a2784 4
		      (match_operand:TF 3 "register_operand" "e")
		      (match_operand:TF 4 "register_operand" "0")))]
  "TARGET_V9 && TARGET_FPU"
  "fmovq%C1 %2,%3,%0"
d2787 11
a2797 8
(define_insn "*movsf_cc_sp64"
  [(set (match_operand:SF 0 "register_operand" "=f")
	(if_then_else (match_operator 1 "comparison_operator"
				      [(reg:CC 0) (const_int 0)])
		      (match_operand:SF 2 "register_operand" "f")
		      (match_operand:SF 3 "register_operand" "0")))]
  "TARGET_V9 && TARGET_FPU"
  "fmovs%C1 %%icc,%2,%0"
d2800 12
a2811 8
(define_insn "*movdf_cc_sp64"
  [(set (match_operand:DF 0 "register_operand" "=e")
	(if_then_else (match_operator 1 "comparison_operator"
				      [(reg:CC 0) (const_int 0)])
		      (match_operand:DF 2 "register_operand" "e")
		      (match_operand:DF 3 "register_operand" "0")))]
  "TARGET_V9 && TARGET_FPU"
  "fmovd%C1 %%icc,%2,%0"
d2814 11
a2824 8
(define_insn "*movtf_cc_sp64"
  [(set (match_operand:TF 0 "register_operand" "=e")
	(if_then_else (match_operator 1 "comparison_operator"
				      [(reg:CC 0) (const_int 0)])
		      (match_operand:TF 2 "register_operand" "e")
		      (match_operand:TF 3 "register_operand" "0")))]
  "TARGET_V9 && TARGET_FPU"
  "fmovq%C1 %%icc,%2,%0"
d2827 11
a2837 8
(define_insn "*movsf_ccx_sp64"
  [(set (match_operand:SF 0 "register_operand" "=f")
	(if_then_else (match_operator 1 "comparison_operator"
				      [(reg:CCX 0) (const_int 0)])
		      (match_operand:SF 2 "register_operand" "f")
		      (match_operand:SF 3 "register_operand" "0")))]
  "TARGET_V9 && TARGET_FPU"
  "fmovs%C1 %%xcc,%2,%0"
d2840 11
a2850 18
(define_insn "*movdf_ccx_sp64"
  [(set (match_operand:DF 0 "register_operand" "=e")
	(if_then_else (match_operator 1 "comparison_operator"
				      [(reg:CCX 0) (const_int 0)])
		      (match_operand:DF 2 "register_operand" "e")
		      (match_operand:DF 3 "register_operand" "0")))]
  "TARGET_V9 && TARGET_FPU"
  "fmovd%C1 %%xcc,%2,%0"
  [(set_attr "type" "cmove")])

(define_insn "*movtf_ccx_sp64"
  [(set (match_operand:TF 0 "register_operand" "=e")
	(if_then_else (match_operator 1 "comparison_operator"
				      [(reg:CCX 0) (const_int 0)])
		      (match_operand:TF 2 "register_operand" "e")
		      (match_operand:TF 3 "register_operand" "0")))]
  "TARGET_V9 && TARGET_FPU"
  "fmovq%C1 %%xcc,%2,%0"
d2866 1
a2866 1
  rtx shift_16 = gen_rtx (CONST_INT, VOIDmode, 16);
d2924 1
a2924 1
  "TARGET_V9"
d2930 1
a2930 1
  "TARGET_V9 && GET_CODE (operands[1]) != CONST_INT"
d2940 1
a2940 1
  "TARGET_V9"
d2944 1
a2944 1
  rtx shift_48 = gen_rtx (CONST_INT, VOIDmode, 48);
d2963 1
a2963 1
  "TARGET_V9"
d2972 1
a2972 1
  "TARGET_V9"
d2978 1
a2978 1
  "TARGET_V9 && GET_CODE (operands[1]) != CONST_INT"
d2988 1
a2988 1
  [(set (reg:CC 0)
d2996 1
a2996 1
  [(set (reg:CC 0)
d3008 1
a3008 1
  [(set (reg:CC 0)
d3016 1
a3016 1
  [(set (reg:CC 0)
d3038 1
a3038 1
  rtx shift_16 = gen_rtx (CONST_INT, VOIDmode, 16);
d3068 1
a3068 1
  rtx shift_24 = gen_rtx (CONST_INT, VOIDmode, 24);
d3105 1
a3105 1
  rtx shift_24 = gen_rtx (CONST_INT, VOIDmode, 24);
d3131 1
a3131 1
  "TARGET_V9"
d3135 1
a3135 1
  rtx shift_56 = gen_rtx (CONST_INT, VOIDmode, 56);
d3154 1
a3154 1
  "TARGET_V9"
d3161 1
a3161 1
  "TARGET_V9"
d3165 1
a3165 1
  rtx shift_48 = gen_rtx (CONST_INT, VOIDmode, 48);
d3184 1
a3184 1
  "TARGET_V9"
d3191 1
a3191 1
  "TARGET_V9"
d3197 1
a3197 1
  "TARGET_V9"
d3208 1
a3208 1
  [(set (reg:CC 0)
d3221 1
a3221 1
  operands[1] = gen_rtx (CONST_INT, VOIDmode, mask);
d3226 1
a3226 1
  [(set (reg:CCX 0)
d3232 1
a3232 1
  "TARGET_V9 && INTVAL (operands[2]) > 51"
d3237 1
a3237 1
  unsigned mask = ((1 << len) - 1) << pos;
d3239 1
a3239 1
  operands[1] = gen_rtx (CONST_INT, VOIDmode, mask);
d3324 1
a3324 1
  "TARGET_V9 && TARGET_FPU"
d3336 1
a3336 1
  "TARGET_V9 && TARGET_FPU"
d3348 1
a3348 1
  "TARGET_V9 && TARGET_FPU && TARGET_HARD_QUAD"
d3360 1
a3360 1
  "TARGET_V9 && TARGET_FPU"
d3377 1
a3377 1
  "TARGET_V9 && TARGET_FPU"
d3394 1
a3394 1
  "TARGET_V9 && TARGET_FPU && TARGET_HARD_QUAD"
d3411 1
a3411 1
  "0 && TARGET_V9 && TARGET_FPU"
d3418 1
a3418 1
  "0 && TARGET_V9 && TARGET_FPU"
d3425 1
a3425 1
  "0 && TARGET_V9 && TARGET_FPU && TARGET_HARD_QUAD"
d3466 1
a3466 1
  "TARGET_V9 && TARGET_FPU"
d3478 1
a3478 1
  "TARGET_V9 && TARGET_FPU"
d3490 1
a3490 1
  "TARGET_V9 && TARGET_FPU && TARGET_HARD_QUAD"
d3502 1
a3502 1
  "TARGET_V9 && TARGET_FPU"
d3519 1
a3519 1
  "TARGET_V9 && TARGET_FPU"
d3536 1
a3536 1
  "TARGET_V9 && TARGET_FPU && TARGET_HARD_QUAD"
d3553 1
a3553 1
  "0 && TARGET_V9 && TARGET_FPU"
d3560 1
a3560 1
  "0 && TARGET_V9 && TARGET_FPU"
d3567 1
a3567 1
  "0 && TARGET_V9 && TARGET_FPU && TARGET_HARD_QUAD"
d3580 1
a3580 1
  if (! TARGET_V9)
d3586 2
a3587 1
			  gen_rtx (CLOBBER, VOIDmode, gen_rtx (REG, SImode, 0)))));
d3596 2
a3597 2
   (clobber (reg:SI 0))]
  "! TARGET_V9"
d3602 2
a3603 10
  /* If constant is positive, upper bits zeroed, otherwise unchanged.
     Give the assembler a chance to pick the move instruction. */
  if (GET_CODE (op2) == CONST_INT)
    {
      int sign = INTVAL (op2);
      if (sign < 0)
	return \"addcc %R1,%2,%R0\;addx %1,-1,%0\";
      return \"addcc %R1,%2,%R0\;addx %1,0,%0\";
    }
  else if (GET_CODE (op2) == CONST_DOUBLE)
d3608 2
a3609 4
      xoperands[2] = GEN_INT (CONST_DOUBLE_LOW (op2));
      xoperands[3] = GEN_INT (CONST_DOUBLE_HIGH (op2));
      if (xoperands[2] == const0_rtx && xoperands[0] == xoperands[1])
	output_asm_insn (\"add %1,%3,%0\", xoperands);
d3611 5
a3615 1
	output_asm_insn (\"addcc %R1,%2,%R0\;addx %1,%3,%0\", xoperands);
d3618 1
a3618 1
  return \"addcc %R1,%R2,%R0\;addx %1,%2,%0\";
d3626 1
a3626 1
  "TARGET_V9"
d3638 1
a3638 1
  [(set (reg:CC_NOOV 0)
d3647 1
a3647 1
  [(set (reg:CCX_NOOV 0)
d3651 1
a3651 1
  "TARGET_V9"
d3656 1
a3656 1
  [(set (reg:CC_NOOV 0)
d3666 1
a3666 1
  [(set (reg:CCX_NOOV 0)
d3672 1
a3672 1
  "TARGET_V9"
d3682 1
a3682 1
  if (! TARGET_V9)
d3688 2
a3689 1
			  gen_rtx (CLOBBER, VOIDmode, gen_rtx (REG, SImode, 0)))));
d3698 2
a3699 2
   (clobber (reg:SI 0))]
  "! TARGET_V9"
d3704 2
a3705 10
  /* If constant is positive, upper bits zeroed, otherwise unchanged.
     Give the assembler a chance to pick the move instruction. */
  if (GET_CODE (op2) == CONST_INT)
    {
      int sign = INTVAL (op2);
      if (sign < 0)
	return \"subcc %R1,%2,%R0\;subx %1,-1,%0\";
      return \"subcc %R1,%2,%R0\;subx %1,0,%0\";
    }
  else if (GET_CODE (op2) == CONST_DOUBLE)
d3710 2
a3711 4
      xoperands[2] = GEN_INT (CONST_DOUBLE_LOW (op2));
      xoperands[3] = GEN_INT (CONST_DOUBLE_HIGH (op2));
      if (xoperands[2] == const0_rtx && xoperands[0] == xoperands[1])
	output_asm_insn (\"sub %1,%3,%0\", xoperands);
d3713 5
a3717 1
	output_asm_insn (\"subcc %R1,%2,%R0\;subx %1,%3,%0\", xoperands);
d3720 1
a3720 1
  return \"subcc %R1,%R2,%R0\;subx %1,%2,%0\";
d3728 1
a3728 1
  "TARGET_V9"
d3740 1
a3740 1
  [(set (reg:CC_NOOV 0)
d3749 1
a3749 1
  [(set (reg:CCX_NOOV 0)
d3753 1
a3753 1
  "TARGET_V9"
d3758 1
a3758 1
  [(set (reg:CC_NOOV 0)
d3768 1
a3768 1
  [(set (reg:CCX_NOOV 0)
d3774 1
a3774 1
  "TARGET_V9"
d3776 2
d3779 3
a3781 2
;; This is anachronistic, and should not be used in v9 software.
;; The v9 compiler will widen the args and use muldi3.
d3787 1
a3787 1
  "TARGET_V8 || TARGET_SPARCLITE"
d3795 1
a3795 1
  "TARGET_V9"
d3804 1
a3804 1
   (set (reg:CC_NOOV 0)
d3807 1
a3807 1
  "TARGET_V8 || TARGET_SPARCLITE"
d3815 1
a3815 1
  "TARGET_V8 || TARGET_SPARCLITE"
d3829 8
a3836 3
  "TARGET_V8 || TARGET_SPARCLITE"
  "smul %1,%2,%R0\;rd %%y,%0"
  [(set_attr "length" "2")])
d3844 8
a3851 3
  "TARGET_V8 || TARGET_SPARCLITE"
  "smul %1,%2,%R0\;rd %%y,%0"
  [(set_attr "length" "2")])
d3859 1
a3859 1
  "TARGET_V8 || TARGET_SPARCLITE"
d3875 1
a3875 1
  "TARGET_V8 || TARGET_SPARCLITE"
d3885 1
a3885 1
  "TARGET_V8 || TARGET_SPARCLITE"
d3893 1
a3893 1
  "TARGET_V8 || TARGET_SPARCLITE"
d3907 8
a3914 3
  "TARGET_V8 || TARGET_SPARCLITE"
  "umul %1,%2,%R0\;rd %%y,%0"
  [(set_attr "length" "2")])
d3922 8
a3929 3
  "TARGET_V8 || TARGET_SPARCLITE"
  "umul %1,%2,%R0\;rd %%y,%0"
  [(set_attr "length" "2")])
d3937 1
a3937 1
  "TARGET_V8 || TARGET_SPARCLITE"
d3953 1
a3953 1
  "TARGET_V8 || TARGET_SPARCLITE"
d3963 1
a3963 1
  "TARGET_V8 || TARGET_SPARCLITE"
d3967 1
a3967 1
;; The architecture specifies that there must be 3 instructions between
d3975 11
a3985 3
  "TARGET_V8"
  "sra %1,31,%3\;wr %%g0,%3,%%y\;nop\;nop\;nop\;sdiv %1,%2,%0"
  [(set_attr "length" "6")])
d3991 1
a3991 1
  "TARGET_V9"
d4000 1
a4000 1
   (set (reg:CC 0)
d4004 11
a4014 3
  "TARGET_V8"
  "sra %1,31,%3\;wr %%g0,%3,%%y\;nop\;nop\;nop\;sdivcc %1,%2,%0"
  [(set_attr "length" "6")])
d4019 12
a4030 4
		(match_operand:SI 2 "arith_operand" "rI")))]
  "TARGET_V8"
  "wr %%g0,%%g0,%%y\;nop\;nop\;nop\;udiv %1,%2,%0"
  [(set_attr "length" "5")])
d4036 1
a4036 1
  "TARGET_V9"
d4045 1
a4045 1
   (set (reg:CC 0)
d4048 44
a4091 3
  "TARGET_V8"
  "wr %%g0,%%g0,%%y\;nop\;nop\;nop\;udivcc %1,%2,%0"
  [(set_attr "length" "5")])
d4094 2
a4095 2
;; We define DImode `and` so with DImode `not` we can get
;; DImode `andn`.  Other combinations are possible.
d4108 1
a4108 1
  "! TARGET_V9"
d4113 2
a4114 10
  /* If constant is positive, upper bits zeroed, otherwise unchanged.
     Give the assembler a chance to pick the move instruction. */
  if (GET_CODE (op2) == CONST_INT)
    {
      int sign = INTVAL (op2);
      if (sign < 0)
	return \"mov %1,%0\;and %R1,%2,%R0\";
      return \"mov 0,%0\;and %R1,%2,%R0\";
    }
  else if (GET_CODE (op2) == CONST_DOUBLE)
d4119 5
a4123 5
      xoperands[2] = GEN_INT (CONST_DOUBLE_LOW (op2));
      xoperands[3] = GEN_INT (CONST_DOUBLE_HIGH (op2));
      /* We could optimize then operands[1] == operands[0]
	 and either half of the constant is -1.  */
      output_asm_insn (\"and %R1,%2,%R0\;and %1,%3,%0\", xoperands);
d4134 1
a4134 1
  "TARGET_V9"
d4157 1
a4157 1
  operands[4] = gen_rtx (CONST_INT, VOIDmode, ~INTVAL (operands[2]));
d4164 1
a4164 1
  "! TARGET_V9"
d4172 1
a4172 1
  "TARGET_V9"
d4194 1
a4194 1
  "! TARGET_V9"
d4199 2
a4200 10
  /* If constant is positive, upper bits zeroed, otherwise unchanged.
     Give the assembler a chance to pick the move instruction. */
  if (GET_CODE (op2) == CONST_INT)
    {
      int sign = INTVAL (op2);
      if (sign < 0)
	return \"mov -1,%0\;or %R1,%2,%R0\";
      return \"mov %1,%0\;or %R1,%2,%R0\";
    }
  else if (GET_CODE (op2) == CONST_DOUBLE)
d4205 5
a4209 5
      xoperands[2] = GEN_INT (CONST_DOUBLE_LOW (op2));
      xoperands[3] = GEN_INT (CONST_DOUBLE_HIGH (op2));
      /* We could optimize then operands[1] == operands[0]
	 and either half of the constant is 0.  */
      output_asm_insn (\"or %R1,%2,%R0\;or %1,%3,%0\", xoperands);
d4220 1
a4220 1
  "TARGET_V9"
d4243 1
a4243 1
  operands[4] = gen_rtx (CONST_INT, VOIDmode, ~INTVAL (operands[2]));
d4250 1
a4250 1
  "! TARGET_V9"
d4258 1
a4258 1
  "TARGET_V9"
d4280 1
a4280 1
  "! TARGET_V9"
d4285 2
a4286 10
  /* If constant is positive, upper bits zeroed, otherwise unchanged.
     Give the assembler a chance to pick the move instruction. */
  if (GET_CODE (op2) == CONST_INT)
    {
      int sign = INTVAL (op2);
      if (sign < 0)
	return \"xor %1,-1,%0\;xor %R1,%2,%R0\";
      return \"mov %1,%0\;xor %R1,%2,%R0\";
    }
  else if (GET_CODE (op2) == CONST_DOUBLE)
d4291 5
a4295 5
      xoperands[2] = GEN_INT (CONST_DOUBLE_LOW (op2));
      xoperands[3] = GEN_INT (CONST_DOUBLE_HIGH (op2));
      /* We could optimize then operands[1] == operands[0]
	 and either half of the constant is 0.  */
      output_asm_insn (\"xor %R1,%2,%R0\;xor %1,%3,%0\", xoperands);
d4306 1
a4306 1
  "TARGET_V9"
d4329 1
a4329 1
  operands[4] = gen_rtx (CONST_INT, VOIDmode, ~INTVAL (operands[2]));
d4344 1
a4344 1
  operands[4] = gen_rtx (CONST_INT, VOIDmode, ~INTVAL (operands[2]));
d4353 1
a4353 1
  "! TARGET_V9"
d4361 1
a4361 1
  "TARGET_V9"
d4376 1
a4376 1
  [(set (reg:CC 0)
d4387 1
a4387 1
  [(set (reg:CCX 0)
d4393 1
a4393 1
  "TARGET_V9"
d4398 1
a4398 1
  [(set (reg:CC 0)
d4410 1
a4410 1
  [(set (reg:CCX 0)
d4418 1
a4418 1
  "TARGET_V9"
d4422 1
a4422 1
  [(set (reg:CC 0)
d4432 1
a4432 1
  [(set (reg:CCX 0)
d4437 1
a4437 1
  "TARGET_V9"
d4442 1
a4442 1
  [(set (reg:CC 0)
d4453 1
a4453 1
  [(set (reg:CCX 0)
d4460 1
a4460 1
  "TARGET_V9"
d4464 1
a4464 1
  [(set (reg:CC 0)
d4475 1
a4475 1
  [(set (reg:CCX 0)
d4481 1
a4481 1
  "TARGET_V9"
d4486 1
a4486 1
  [(set (reg:CC 0)
d4498 1
a4498 1
  [(set (reg:CCX 0)
d4506 1
a4506 1
  "TARGET_V9"
d4518 1
a4518 1
  if (! TARGET_V9)
d4523 2
a4524 1
			  gen_rtx (CLOBBER, VOIDmode, gen_rtx (REG, SImode, 0)))));
d4532 8
a4539 3
   (clobber (reg:SI 0))]
  "! TARGET_V9"
  "subcc %%g0,%R1,%R0\;subx %%g0,%1,%0"
d4541 1
d4547 1
a4547 1
  "TARGET_V9"
d4556 9
a4564 2
  "sub %%g0,%1,%0"
  [(set_attr "type" "unary")])
d4567 1
a4567 1
  [(set (reg:CC_NOOV 0)
d4570 1
a4570 1
  ""
d4575 1
a4575 1
  [(set (reg:CCX_NOOV 0)
d4578 1
a4578 1
  "TARGET_V9"
d4583 1
a4583 1
  [(set (reg:CC_NOOV 0)
d4588 1
a4588 1
  ""
d4593 1
a4593 1
  [(set (reg:CCX_NOOV 0)
d4598 1
a4598 1
  "TARGET_V9"
d4613 2
a4614 2
  "! TARGET_V9"
  "xnor %%g0,%1,%0\;xnor %%g0,%R1,%R0"
d4621 2
a4622 2
  "TARGET_V9"
  "xnor %%g0,%1,%0"
d4626 2
a4627 2
  [(set (match_operand:SI 0 "register_operand" "=r")
	(not:SI (match_operand:SI 1 "arith_operand" "rI")))]
d4629 12
a4640 2
  "xnor %%g0,%1,%0"
  [(set_attr "type" "unary")])
d4643 1
a4643 1
  [(set (reg:CC 0)
d4646 1
a4646 1
  ""
d4651 1
a4651 1
  [(set (reg:CCX 0)
d4654 1
a4654 1
  "TARGET_V9"
d4659 1
a4659 1
  [(set (reg:CC 0)
d4664 1
a4664 1
  ""
d4669 1
a4669 1
  [(set (reg:CCX 0)
d4674 1
a4674 1
  "TARGET_V9"
d4764 1
a4764 1
  "(TARGET_V8 || TARGET_V9) && TARGET_FPU"
d4796 1
d4800 3
a4802 4
  if (TARGET_V9)
    return \"fnegd %1,%0\"; /* Can't use fnegs, won't work with upper regs.  */
  else if (which_alternative == 0)
   return \"fnegs %0,%0\";
d4804 2
a4805 1
   return \"fnegs %1,%0\;fmovs %R1,%R0\;fmovs %S1,%S0\;fmovs %T1,%T0\";
d4810 1
a4810 1
      (if_then_else (eq_attr "arch" "arch32bit") (const_int 4) (const_int 1))])])
d4828 1
a4828 1
      (if_then_else (eq_attr "arch" "arch32bit") (const_int 2) (const_int 1))])])
d4840 1
d4844 3
a4846 4
  if (TARGET_V9)
    return \"fabsd %1,%0\"; /* Can't use fabss, won't work with upper regs.  */
  else if (which_alternative == 0)
    return \"fabss %0,%0\";
d4848 2
a4849 1
    return \"fabss %1,%0\;fmovs %R1,%R0\;fmovs %S1,%S0\;fmovs %T1,%T0\";
d4854 1
a4854 1
      (if_then_else (eq_attr "arch" "arch32bit") (const_int 4) (const_int 1))])])
d4872 1
a4872 1
      (if_then_else (eq_attr "arch" "arch32bit") (const_int 2) (const_int 1))])])
d4912 1
a4912 1
      && (unsigned) INTVAL (operands[2]) > 31)
d4923 1
a4923 1
  "TARGET_V9"
d4927 1
a4927 1
      && (unsigned) INTVAL (operands[2]) > 63)
d4934 1
a4934 1
  [(set (reg:CC_NOOV 0)
d4943 1
a4943 1
  [(set (reg:CC_NOOV 0)
d4960 1
a4960 1
      && (unsigned) INTVAL (operands[2]) > 31)
d4971 1
a4971 1
  "TARGET_V9"
d4975 1
a4975 1
      && (unsigned) INTVAL (operands[2]) > 63)
d4989 1
a4989 1
      && (unsigned) INTVAL (operands[2]) > 31)
d5000 1
a5000 1
  "TARGET_V9"
d5004 1
a5004 1
      && (unsigned) INTVAL (operands[2]) > 63)
d5017 15
a5031 1
  "b%* %l0%("
d5037 1
a5037 1
  "! TARGET_MEDANY"
a5084 48
(define_insn "*get_pc_sp32"
  [(set (pc) (label_ref (match_operand 0 "" "")))
   (set (reg:SI 15) (label_ref (match_dup 0)))]
  "! TARGET_PTR64"
  "call %l0%#"
  [(set_attr "type" "uncond_branch")])

(define_insn "*get_pc_sp64"
  [(set (pc) (label_ref (match_operand 0 "" "")))
   (set (reg:DI 15) (label_ref (match_dup 0)))]
  "TARGET_PTR64"
  "call %l0%#"
  [(set_attr "type" "uncond_branch")])

;; Implement a switch statement for the medium/anywhere code model.
;; This wouldn't be necessary if we could distinguish label refs of the jump
;; table from other label refs.  The problem is that jump tables live in the
;; .rodata section and thus we need to add %g4 to get their address.

(define_expand "casesi"
  [(set (match_dup 5)
	(minus:SI (match_operand:SI 0 "register_operand" "")
		  (match_operand:SI 1 "nonmemory_operand" "")))
   (set (reg:CC 0)
	(compare:CC (match_dup 5)
		    (match_operand:SI 2 "nonmemory_operand" "")))
   (set (pc)
	(if_then_else (gtu (reg:CC 0)
			   (const_int 0))
		      (label_ref (match_operand 4 "" ""))
		      (pc)))
   (parallel [(set (match_dup 6) (high:DI (label_ref (match_operand 3 "" ""))))
	      (clobber (reg:DI 1))])
   (set (match_dup 6)
	(lo_sum:DI (match_dup 6) (label_ref (match_dup 3))))
   (set (match_dup 6) (plus:DI (match_dup 6) (reg:DI 4)))
   (set (match_dup 7) (zero_extend:DI (match_dup 5)))
   (set (match_dup 7) (ashift:DI (match_dup 7) (const_int 3)))
   (set (match_dup 7) (mem:DI (plus:DI (match_dup 6) (match_dup 7))))
   (set (pc) (match_dup 7))]
  "TARGET_MEDANY"
  "
{
  operands[5] = gen_reg_rtx (SImode);
  operands[6] = gen_reg_rtx (DImode);
  operands[7] = gen_reg_rtx (DImode);
}")

d5110 1
a5110 1
 if (GET_CODE (XEXP (operands[0], 0)) == LABEL_REF)
d5119 9
a5127 7
      if (! TARGET_V9 && INTVAL (operands[3]) != 0)
	emit_jump_insn (gen_rtx (PARALLEL, VOIDmode, gen_rtvec (3,
				 gen_rtx (SET, VOIDmode, pc_rtx,
					  XEXP (operands[0], 0)),
				 operands[3],
				 gen_rtx (CLOBBER, VOIDmode,
					  gen_rtx (REG, Pmode, 15)))));
d5129 7
a5135 5
	emit_jump_insn (gen_rtx (PARALLEL, VOIDmode, gen_rtvec (2,
				 gen_rtx (SET, VOIDmode, pc_rtx,
					  XEXP (operands[0], 0)),
				 gen_rtx (CLOBBER, VOIDmode,
					  gen_rtx (REG, Pmode, 15)))));
d5146 1
a5146 1
    nregs_rtx = gen_rtx (CONST_INT, VOIDmode, REGNO (operands[2]) - 8);
d5148 1
a5148 1
    nregs_rtx = gen_rtx (CONST_INT, VOIDmode, 6);
d5153 13
a5165 11
  if (! TARGET_V9 && INTVAL (operands[3]) != 0)
    emit_call_insn (gen_rtx (PARALLEL, VOIDmode, gen_rtvec (3,
			     gen_rtx (CALL, VOIDmode, fn_rtx, nregs_rtx),
			     operands[3],
			     gen_rtx (CLOBBER, VOIDmode,
					       gen_rtx (REG, Pmode, 15)))));
  else
    emit_call_insn (gen_rtx (PARALLEL, VOIDmode, gen_rtvec (2,
			     gen_rtx (CALL, VOIDmode, fn_rtx, nregs_rtx),
			     gen_rtx (CLOBBER, VOIDmode,
					       gen_rtx (REG, Pmode, 15)))));
d5171 1
a5171 1
  if (! TARGET_V9 && INTVAL (operands[3]) > 0)
d5228 1
a5228 1
  "! TARGET_V9 && GET_CODE (operands[2]) == CONST_INT && INTVAL (operands[2]) > 0"
d5240 1
a5240 1
  "! TARGET_V9 && GET_CODE (operands[2]) == CONST_INT && INTVAL (operands[2]) > 0"
d5252 1
a5252 1
  "! TARGET_V9 && GET_CODE (operands[2]) == CONST_INT && INTVAL (operands[2]) < 0"
d5263 1
a5263 1
  "! TARGET_V9 && GET_CODE (operands[2]) == CONST_INT && INTVAL (operands[2]) < 0"
d5391 1
a5391 1
  rtx valreg2 = gen_rtx (REG, TARGET_V9 ? TFmode : DFmode, 32);
d5394 1
a5394 1
  if (! TARGET_V9)
d5411 1
a5411 1
		  change_address (result, TARGET_V9 ? TFmode : DFmode,
d5430 1
a5430 1
  "! TARGET_V9"
d5435 2
a5436 1
  [(return)]
a5495 1
  emit_insn (gen_rtx (USE, VOIDmode, gen_rtx (REG, Pmode, 8)));
d5498 1
d5506 2
a5507 1
  "* return TARGET_V9 ? \"flushw\" : \"ta 3\";"
d5511 2
a5512 1
  [(unspec_volatile [(const_int 0)] 2)]
d5518 30
d5567 7
a5573 2
  "TARGET_SPARCLITE"
  "sub %%g0,%1,%0\;and %0,%1,%0\;scan %0,0,%0\;mov 32,%2\;sub %2,%0,%0\;sra %0,31,%2\;and %2,31,%2\;add %2,%0,%0"
d5584 2
a5585 2
  "TARGET_V9"
  "neg %1,%2\;not %2,%2\;xor %1,%2,%2\;popc %2,%0\;movrz %1,%%g0,%0"
d5673 1
a5673 1
;; LABEL_REFs are not modified by `legitimize_pic_address`
d5696 1
a5696 1
   (clobber (reg:CC 0))]
d5698 3
a5700 3
  [(set (reg:CC_NOOV 0) (compare:CC_NOOV (neg:SI (match_dup 1))
					 (const_int 0)))
   (set (match_dup 0) (ltu:SI (reg:CC 0) (const_int 0)))]
d5707 1
a5707 1
   (clobber (reg:CC 0))]
d5709 3
a5711 3
  [(set (reg:CC_NOOV 0) (compare:CC_NOOV (neg:SI (match_dup 1))
					 (const_int 0)))
   (set (match_dup 0) (neg:SI (ltu:SI (reg:CC 0) (const_int 0))))]
d5718 1
a5718 1
   (clobber (reg:CC 0))]
d5720 3
a5722 3
  [(set (reg:CC_NOOV 0) (compare:CC_NOOV (neg:SI (match_dup 1))
					 (const_int 0)))
   (set (match_dup 0) (geu:SI (reg:CC 0) (const_int 0)))]
d5729 1
a5729 1
   (clobber (reg:CC 0))]
d5731 3
a5733 3
  [(set (reg:CC_NOOV 0) (compare:CC_NOOV (neg:SI (match_dup 1))
					 (const_int 0)))
   (set (match_dup 0) (neg:SI (geu:SI (reg:CC 0) (const_int 0))))]
d5741 1
a5741 1
   (clobber (reg:CC 0))]
d5743 3
a5745 3
  [(set (reg:CC_NOOV 0) (compare:CC_NOOV (neg:SI (match_dup 1))
					 (const_int 0)))
   (set (match_dup 0) (plus:SI (ltu:SI (reg:CC 0) (const_int 0))
d5754 1
a5754 1
   (clobber (reg:CC 0))]
d5756 2
a5757 2
  [(set (reg:CC_NOOV 0) (compare:CC_NOOV (neg:SI (match_dup 1))
					 (const_int 0)))
d5759 1
a5759 1
				(ltu:SI (reg:CC 0) (const_int 0))))]
d5767 1
a5767 1
   (clobber (reg:CC 0))]
d5769 3
a5771 3
  [(set (reg:CC_NOOV 0) (compare:CC_NOOV (neg:SI (match_dup 1))
					 (const_int 0)))
   (set (match_dup 0) (plus:SI (geu:SI (reg:CC 0) (const_int 0))
d5780 1
a5780 1
   (clobber (reg:CC 0))]
d5782 2
a5783 2
  [(set (reg:CC_NOOV 0) (compare:CC_NOOV (neg:SI (match_dup 1))
					 (const_int 0)))
d5785 1
a5785 1
				(geu:SI (reg:CC 0) (const_int 0))))]
d5799 1
a5799 1
  "! TARGET_V9
d5810 1
a5810 1
  "! TARGET_V9
d5821 1
a5821 1
  "! TARGET_V9
d5832 1
a5832 1
  "! TARGET_V9
d5843 1
a5843 1
  "! TARGET_V9
d5854 1
a5854 1
  "! TARGET_V9
d5865 1
a5865 1
  "! TARGET_V9
d5876 1
a5876 1
  "! TARGET_V9
d5889 1
a5889 1
   (set (reg:CC 0)
d5895 1
a5895 1
  "orcc %1,%%g0,%0")
d5900 1
a5900 1
   (set (reg:CCX 0)
d5903 1
a5903 1
  "TARGET_V9
d5907 1
a5907 1
  "orcc %1,%%g0,%0")
d5918 1
a5918 1
   (set (reg:CC 0)
d5922 1
a5922 1
  "ldsh %1,%0\;orcc %0,%%g0,%2")
d5929 1
a5929 1
   (set (reg:CCX 0)
d5932 2
a5933 2
  "TARGET_V9"
  "ldsh %1,%0\;orcc %0,%%g0,%2")
d5940 1
a5940 1
   (set (reg:CC 0)
d5944 1
a5944 1
  "ldsb %1,%0\;orcc %0,%%g0,%2")
d5951 1
a5951 1
   (set (reg:CCX 0)
d5954 2
a5955 2
  "TARGET_V9"
  "ldsb %1,%0\;orcc %0,%%g0,%2")
d5986 2
a5987 4
;; Return peepholes.  First the "normal" ones

;; ??? There are QImode, HImode, and SImode versions of this pattern.
;; It might be possible to write one more general pattern instead of three.
d5993 1
a5993 1
  "! TARGET_EPILOGUE"
d5996 1
a5996 1
  if (! TARGET_V9 && current_function_returns_struct)
d6007 1
a6007 1
  "! TARGET_EPILOGUE"
d6010 1
a6010 1
  if (! TARGET_V9 && current_function_returns_struct)
d6021 1
a6021 1
  "! TARGET_EPILOGUE"
d6024 1
a6024 1
  if (! TARGET_V9 && current_function_returns_struct)
d6038 1
a6038 1
  "! TARGET_FPU && ! TARGET_EPILOGUE"
d6041 1
a6041 1
  if (! TARGET_V9 && current_function_returns_struct)
d6053 3
a6055 1
  "! TARGET_EPILOGUE"
d6058 1
a6058 1
  if (! TARGET_V9 && current_function_returns_struct)
d6069 1
a6069 1
  "TARGET_V9 && ! TARGET_EPILOGUE"
d6075 1
a6075 1
	(plus:DI (match_operand:DI 1 "arith_operand" "%r")
d6078 3
a6080 1
  "TARGET_V9 && ! TARGET_EPILOGUE"
d6084 8
a6091 11
;; Turned off because it should never match (subtracting a constant
;; is turned into addition) and because it would do the wrong thing
;; when operand 2 is -4096 (--4096 == 4096 is not a valid immediate).
;;(define_insn "*minus_const"
;;  [(set (match_operand:SI 0 "restore_operand" "")
;;	(minus:SI (match_operand:SI 1 "register_operand" "r")
;;		  (match_operand:SI 2 "small_int" "I")))
;;   (return)]
;;  "! TARGET_EPILOGUE"
;;  "ret\;restore %1,-(%2),%Y0"
;;  [(set_attr "type" "multi")])
d6131 1
a6131 1
  "TARGET_V9 && short_branch (INSN_UID (insn), INSN_UID (operands[3]))"
d6139 1
a6139 1
  "TARGET_V9 && short_branch (INSN_UID (insn), INSN_UID (operands[2]))"
d6144 1
d6148 3
a6150 3
			     (reg:SI 0)))
	      (clobber (reg:CC 0))])
   (set (reg:CC 0) (compare (match_dup 0) (const_int 0)))]
d6153 9
@


1.1.1.1
log
@FSF GCC version 2.7.2
@
text
@@


1.1.1.2
log
@*** empty log message ***
@
text
@d2 1
a2 1
;;  Copyright (C) 1987, 88, 89, 92-96, 1997 Free Software Foundation, Inc.
a30 3
;;
;; -mlive-g0 is *not* supported for TARGET_ARCH64, so we don't bother to
;; test TARGET_LIVE_G0 if we have TARGET_ARCH64.
d32 1
a32 14
;; Attribute for cpu type.
;; These must match the values for enum processor_type in sparc.h.
(define_attr "cpu" "v7,cypress,v8,supersparc,sparclite,f930,f934,sparclet,tsc701,v8plus,v9,ultrasparc"
  (const (symbol_ref "sparc_cpu_attr")))

;; Attribute for the instruction set.
;; At present we only need to distinguish v9/!v9, but for clarity we
;; test TARGET_V8 too.
(define_attr "isa" "v6,v8,v9,sparclet"
 (const
  (cond [(symbol_ref "TARGET_V9") (const_string "v9")
	 (symbol_ref "TARGET_V8") (const_string "v8")
	 (symbol_ref "TARGET_SPARCLET") (const_string "sparclet")]
	(const_string "v6"))))
a33 1
;; Architecture size.
d35 1
a35 3
 (const
  (cond [(symbol_ref "TARGET_ARCH64") (const_string "arch64bit")]
	(const_string "arch32bit"))))
d37 2
a38 2
;; Whether -mlive-g0 is in effect.
(define_attr "live_g0" "no,yes"
d40 2
a41 2
  (cond [(symbol_ref "TARGET_LIVE_G0") (const_string "yes")]
	(const_string "no"))))
a238 54

;; ----- sparclet tsc701 scheduling
;; The tsc701 issues 1 insn per cycle.
;; Results may be written back out of order.

;; Loads take 2 extra cycles to complete and 4 can be buffered at a time.
(define_function_unit "tsc701_load" 4 1
  (and (eq_attr "type" "load")          (eq_attr "cpu" "tsc701")) 3 1)
;; Stores take 2(?) extra cycles to complete.
;; It is desirable to not have any memory operation in the following 2 cycles.
;; (??? or 2 memory ops in the case of std).
(define_function_unit "tsc701_store" 1 0
  (and (eq_attr "type" "store")		(eq_attr "cpu" "tsc701")) 3 3
  [(eq_attr "type" "load,store")])
;; The multiply unit has a latency of 5.
(define_function_unit "tsc701_mul" 1 0
  (and (eq_attr "type" "imul")		(eq_attr "cpu" "tsc701")) 5 5)

;; ----- The UltraSPARC-1 scheduling
;; The Ultrasparc can issue 1 - 4 insns per cycle; here we assume
;; four insns/cycle, and hence multiply all costs by four.

;; Memory delivers its result in three cycles to IU, three cycles to FP
(define_function_unit "memory" 1 0
  (and (eq_attr "type" "load,fpload")   (eq_attr "cpu" "ultrasparc")) 12 4)
(define_function_unit "memory" 1 0
  (and (eq_attr "type" "store,fpstore") (eq_attr "cpu" "ultrasparc"))  4 4)
(define_function_unit "ieu" 1 0
  (and (eq_attr "type" "ialu")          (eq_attr "cpu" "ultrasparc"))  1 2)
(define_function_unit "ieu" 1 0
  (and (eq_attr "type" "shift")         (eq_attr "cpu" "ultrasparc"))  1 4)
(define_function_unit "ieu" 1 0
  (and (eq_attr "type" "cmove")         (eq_attr "cpu" "ultrasparc"))  8 4)

;; Timings; throughput/latency
;; ?? FADD     1/3    add/sub, format conv, compar, abs, neg
;; ?? FMUL     1/3
;; ?? FDIVs    1/12
;; ?? FDIVd    1/22
;; ?? FSQRTs   1/12
;; ?? FSQRTd   1/22

(define_function_unit "fp" 1 0
  (and (eq_attr "type" "fp")       (eq_attr "cpu" "ultrasparc")) 12 2)
(define_function_unit "fp" 1 0
  (and (eq_attr "type" "fpcmp")    (eq_attr "cpu" "ultrasparc"))  8 2)
(define_function_unit "fp" 1 0
  (and (eq_attr "type" "fpmul")    (eq_attr "cpu" "ultrasparc")) 12 2)
(define_function_unit "fp" 1 0
  (and (eq_attr "type" "fpdivs")   (eq_attr "cpu" "ultrasparc")) 48 2)
(define_function_unit "fp" 1 0
  (and (eq_attr "type" "fpdivd")   (eq_attr "cpu" "ultrasparc")) 88 2)
(define_function_unit "fp" 1 0
  (and (eq_attr "type" "fpsqrt")   (eq_attr "cpu" "ultrasparc")) 48 2)
d259 1
a259 1
  [(set (reg:CC 100)
d271 1
a271 1
  [(set (reg:CCX 100)
d274 1
a274 1
  "TARGET_ARCH64"
d283 1
a283 2
  ;; The 96 here isn't ever used by anyone.
  [(set (reg:CCFP 96)
d295 1
a295 2
  ;; The 96 here isn't ever used by anyone.
  [(set (reg:CCFP 96)
d307 1
a307 2
  ;; The 96 here isn't ever used by anyone.
  [(set (reg:CCFP 96)
a317 96
;; Now the compare DEFINE_INSNs.

(define_insn "*cmpsi_insn"
  [(set (reg:CC 100)
	(compare:CC (match_operand:SI 0 "register_operand" "r")
		    (match_operand:SI 1 "arith_operand" "rI")))]
  ""
  "cmp %0,%1"
  [(set_attr "type" "compare")])

(define_insn "*cmpdi_sp64"
  [(set (reg:CCX 100)
	(compare:CCX (match_operand:DI 0 "register_operand" "r")
		     (match_operand:DI 1 "arith_double_operand" "rHI")))]
  "TARGET_ARCH64"
  "cmp %0,%1"
  [(set_attr "type" "compare")])

(define_insn "*cmpsf_fpe"
  [(set (match_operand:CCFPE 0 "fcc_reg_operand" "=c")
	(compare:CCFPE (match_operand:SF 1 "register_operand" "f")
		       (match_operand:SF 2 "register_operand" "f")))]
  "TARGET_FPU"
  "*
{
  if (TARGET_V9)
    return \"fcmpes %0,%1,%2\";
  return \"fcmpes %1,%2\";
}"
  [(set_attr "type" "fpcmp")])

(define_insn "*cmpdf_fpe"
  [(set (match_operand:CCFPE 0 "fcc_reg_operand" "=c")
	(compare:CCFPE (match_operand:DF 1 "register_operand" "e")
		       (match_operand:DF 2 "register_operand" "e")))]
  "TARGET_FPU"
  "*
{
  if (TARGET_V9)
    return \"fcmped %0,%1,%2\";
  return \"fcmped %1,%2\";
}"
  [(set_attr "type" "fpcmp")])

(define_insn "*cmptf_fpe"
  [(set (match_operand:CCFPE 0 "fcc_reg_operand" "=c")
	(compare:CCFPE (match_operand:TF 1 "register_operand" "e")
		       (match_operand:TF 2 "register_operand" "e")))]
  "TARGET_FPU && TARGET_HARD_QUAD"
  "*
{
  if (TARGET_V9)
    return \"fcmpeq %0,%1,%2\";
  return \"fcmpeq %1,%2\";
}"
  [(set_attr "type" "fpcmp")])

(define_insn "*cmpsf_fp"
  [(set (match_operand:CCFP 0 "fcc_reg_operand" "=c")
	(compare:CCFP (match_operand:SF 1 "register_operand" "f")
		      (match_operand:SF 2 "register_operand" "f")))]
  "TARGET_FPU"
  "*
{
  if (TARGET_V9)
    return \"fcmps %0,%1,%2\";
  return \"fcmps %1,%2\";
}"
  [(set_attr "type" "fpcmp")])

(define_insn "*cmpdf_fp"
  [(set (match_operand:CCFP 0 "fcc_reg_operand" "=c")
	(compare:CCFP (match_operand:DF 1 "register_operand" "e")
		      (match_operand:DF 2 "register_operand" "e")))]
  "TARGET_FPU"
  "*
{
  if (TARGET_V9)
    return \"fcmpd %0,%1,%2\";
  return \"fcmpd %1,%2\";
}"
  [(set_attr "type" "fpcmp")])

(define_insn "*cmptf_fp"
  [(set (match_operand:CCFP 0 "fcc_reg_operand" "=c")
	(compare:CCFP (match_operand:TF 1 "register_operand" "e")
		      (match_operand:TF 2 "register_operand" "e")))]
  "TARGET_FPU && TARGET_HARD_QUAD"
  "*
{
  if (TARGET_V9)
    return \"fcmpq %0,%1,%2\";
  return \"fcmpq %1,%2\";
}"
  [(set_attr "type" "fpcmp")])

d334 2
a335 2
	      (clobber (reg:CC 100))])]
  "! TARGET_LIVE_G0"
d342 4
a345 3
   (set (match_operand:DI 0 "register_operand" "")
	(eq:DI (match_dup 3) (const_int 0)))]
  "TARGET_ARCH64"
d354 2
a355 2
	      (clobber (reg:CC 100))])]
  "! TARGET_LIVE_G0"
d362 4
a365 3
   (set (match_operand:DI 0 "register_operand" "")
	(ne:DI (match_dup 3) (const_int 0)))]
  "TARGET_ARCH64"
d372 4
a375 3
   (set (match_operand:SI 0 "register_operand" "")
	(eq:DI (match_dup 3) (const_int 0)))]
  "TARGET_ARCH64"
d382 4
a385 3
   (set (match_operand:SI 0 "register_operand" "")
	(ne:DI (match_dup 3) (const_int 0)))]
  "TARGET_ARCH64"
d389 1
a389 1
  [(set (match_dup 3)
d393 4
a396 4
		   (eq:SI (match_dup 3) (const_int 0)))
	      (clobber (reg:CC 100))])]
  "TARGET_ARCH64"
  "{ operands[3] = gen_reg_rtx (SImode); }")
d399 1
a399 1
  [(set (match_dup 3)
d403 4
a406 4
		   (ne:SI (match_dup 3) (const_int 0)))
	      (clobber (reg:CC 100))])]
  "TARGET_ARCH64"
  "{ operands[3] = gen_reg_rtx (SImode); }")
d413 1
a413 1
  "! TARGET_LIVE_G0"
d423 1
a423 1
      else if (! TARGET_ARCH64)
d435 1
a435 3
      if (! TARGET_ARCH64)
	FAIL;
      else if (GET_MODE (operands[0]) == SImode)
d438 2
d466 1
a466 1
  "! TARGET_LIVE_G0"
d476 1
a476 1
      else if (! TARGET_ARCH64)
d488 1
a488 3
      if (! TARGET_ARCH64)
	FAIL;
      else if (GET_MODE (operands[0]) == SImode)
d491 2
d517 1
a517 1
  "! TARGET_LIVE_G0"
d538 1
a538 1
  "! TARGET_LIVE_G0"
d559 1
a559 1
  "! TARGET_LIVE_G0"
d580 1
a580 1
  "! TARGET_LIVE_G0"
d601 1
a601 1
  "! TARGET_LIVE_G0"
d633 1
a633 1
  "! TARGET_LIVE_G0"
d647 1
a647 1
  "! TARGET_LIVE_G0"
d661 1
a661 1
  "! TARGET_LIVE_G0"
d690 113
a802 1
;; Now the DEFINE_INSNs for the scc cases.
d811 2
a812 2
   (clobber (reg:CC 100))]
  "! TARGET_LIVE_G0"
d821 2
a822 2
   (clobber (reg:CC 100))]
  "! TARGET_LIVE_G0"
d827 1
a827 1
(define_insn "*snesi_zero_extend"
d829 1
a829 1
	(ne:SI (match_operand:SI 1 "register_operand" "r")
d831 2
a832 11
   (clobber (reg:CC 100))]
  "TARGET_ARCH64"
  "subcc %%g0,%1,%%g0\;addx %%g0,0,%0"
  [(set_attr "type" "unary")
   (set_attr "length" "2")])

(define_insn "*snedi_zero"
  [(set (match_operand:DI 0 "register_operand" "=&r")
	(ne:DI (match_operand:DI 1 "register_operand" "r")
	       (const_int 0)))]
  "TARGET_ARCH64"
d838 1
a838 1
  [(set (match_operand:DI 0 "register_operand" "=&r")
d840 3
a842 2
		       (const_int 0))))]
  "TARGET_ARCH64"
a846 9
(define_insn "*snedi_zero_trunc"
  [(set (match_operand:SI 0 "register_operand" "=&r")
	(ne:DI (match_operand:DI 1 "register_operand" "r")
	       (const_int 0)))]
  "TARGET_ARCH64"
  "mov 0,%0\;movrnz %1,1,%0"
  [(set_attr "type" "unary")
   (set_attr "length" "2")])

d851 2
a852 2
   (clobber (reg:CC 100))]
  "! TARGET_LIVE_G0"
d861 2
a862 2
   (clobber (reg:CC 100))]
  "! TARGET_LIVE_G0"
d867 1
a867 1
(define_insn "*seqsi_zero_extend"
d869 1
a869 1
	(eq:SI (match_operand:SI 1 "register_operand" "r")
d871 2
a872 11
   (clobber (reg:CC 100))]
  "TARGET_ARCH64"
  "subcc %%g0,%1,%%g0\;subx %%g0,-1,%0"
  [(set_attr "type" "unary")
   (set_attr "length" "2")])

(define_insn "*seqdi_zero"
  [(set (match_operand:DI 0 "register_operand" "=&r")
	(eq:DI (match_operand:DI 1 "register_operand" "r")
	       (const_int 0)))]
  "TARGET_ARCH64"
d878 1
a878 1
  [(set (match_operand:DI 0 "register_operand" "=&r")
d880 3
a882 2
		       (const_int 0))))]
  "TARGET_ARCH64"
a886 9
(define_insn "*seqdi_zero_trunc"
  [(set (match_operand:SI 0 "register_operand" "=&r")
	(eq:DI (match_operand:DI 1 "register_operand" "r")
	       (const_int 0)))]
  "TARGET_ARCH64"
  "mov 0,%0\;movrz %1,1,%0"
  [(set_attr "type" "unary")
   (set_attr "length" "2")])

d896 2
a897 2
   (clobber (reg:CC 100))]
  "! TARGET_LIVE_G0"
d906 2
a907 2
   (clobber (reg:CC 100))]
  "! TARGET_LIVE_G0"
d916 2
a917 2
   (clobber (reg:CC 100))]
  "! TARGET_LIVE_G0"
d926 2
a927 2
   (clobber (reg:CC 100))]
  "! TARGET_LIVE_G0"
d937 2
a938 2
	(ltu:SI (reg:CC 100) (const_int 0)))]
  "! TARGET_LIVE_G0"
d944 2
a945 2
	(neg:SI (ltu:SI (reg:CC 100) (const_int 0))))]
  "! TARGET_LIVE_G0"
d952 1
a952 1
	(minus:SI (neg:SI (ltu:SI (reg:CC 100) (const_int 0)))
d954 1
a954 1
  "! TARGET_LIVE_G0"
d960 1
a960 1
	(neg:SI (plus:SI (ltu:SI (reg:CC 100) (const_int 0))
d962 1
a962 1
  "! TARGET_LIVE_G0"
d968 2
a969 2
	(geu:SI (reg:CC 100) (const_int 0)))]
  "! TARGET_LIVE_G0"
d975 2
a976 2
	(neg:SI (geu:SI (reg:CC 100) (const_int 0))))]
  "! TARGET_LIVE_G0"
d986 1
a986 1
	(plus:SI (ltu:SI (reg:CC 100) (const_int 0))
d988 1
a988 1
  "! TARGET_LIVE_G0"
d994 1
a994 1
	(plus:SI (ltu:SI (reg:CC 100) (const_int 0))
d1003 1
a1003 1
		  (ltu:SI (reg:CC 100) (const_int 0))))]
d1013 1
a1013 1
		  (ltu:SI (reg:CC 100) (const_int 0))))]
d1020 1
a1020 1
		  (plus:SI (ltu:SI (reg:CC 100) (const_int 0))
d1027 1
a1027 1
	(plus:SI (geu:SI (reg:CC 100) (const_int 0))
d1036 1
a1036 1
		  (geu:SI (reg:CC 100) (const_int 0))))]
d1049 1
a1049 3
	(match_operator:SI 2 "noov_compare_op"
			   [(match_operand 1 "icc_or_fcc_reg_operand" "")
			    (const_int 0)]))]
d1057 2
a1058 4
	(match_operator:DI 2 "noov_compare_op"
			   [(match_operand 1 "icc_or_fcc_reg_operand" "")
			    (const_int 0)]))]
  "TARGET_ARCH64"
d1077 1
a1077 1
  if (TARGET_ARCH64 && sparc_compare_op1 == const0_rtx
d1101 1
a1101 1
  if (TARGET_ARCH64 && sparc_compare_op1 == const0_rtx
d1125 1
a1125 1
  if (TARGET_ARCH64 && sparc_compare_op1 == const0_rtx
d1159 1
a1159 1
  if (TARGET_ARCH64 && sparc_compare_op1 == const0_rtx
d1193 1
a1193 1
  if (TARGET_ARCH64 && sparc_compare_op1 == const0_rtx
d1227 1
a1227 1
  if (TARGET_ARCH64 && sparc_compare_op1 == const0_rtx
d1258 1
a1258 1
				      [(reg 100) (const_int 0)])
d1264 1
a1264 1
  return output_cbranch (operands[0], 1, 0,
d1273 1
a1273 1
				      [(reg 100) (const_int 0)])
d1279 1
a1279 1
  return output_cbranch (operands[0], 1, 1,
d1285 1
a1285 1
(define_insn "*normal_fp_branch"
d1287 2
a1288 2
	(if_then_else (match_operator 1 "comparison_operator"
				      [(match_operand:CCFP 0 "fcc_reg_operand" "c")
d1292 1
a1292 1
  ""
d1295 1
a1295 1
  return output_cbranch (operands[1], 2, 0,
d1301 1
a1301 1
(define_insn "*inverted_fp_branch"
d1303 2
a1304 2
	(if_then_else (match_operator 1 "comparison_operator"
				      [(match_operand:CCFP 0 "fcc_reg_operand" "c")
d1308 1
a1308 1
  ""
d1311 1
a1311 1
  return output_cbranch (operands[1], 2, 1,
d1317 1
a1317 1
(define_insn "*normal_fpe_branch"
d1319 2
a1320 2
	(if_then_else (match_operator 1 "comparison_operator"
				      [(match_operand:CCFPE 0 "fcc_reg_operand" "c")
d1324 1
a1324 1
  ""
d1327 1
a1327 1
  return output_cbranch (operands[1], 2, 0,
d1333 1
a1333 1
(define_insn "*inverted_fpe_branch"
d1335 2
a1336 2
	(if_then_else (match_operator 1 "comparison_operator"
				      [(match_operand:CCFPE 0 "fcc_reg_operand" "c")
d1340 1
a1340 1
  ""
d1343 1
a1343 1
  return output_cbranch (operands[1], 2, 1,
d1361 1
a1361 1
  "TARGET_ARCH64"
d1377 1
a1377 1
  "TARGET_ARCH64"
d1395 1
a1395 1
  "* return TARGET_ARCH64 ? \"add %1,%%lo(%a2),%0\" : \"or %1,%%lo(%a2),%0\";"
d1402 1
a1402 1
(define_insn "pic_lo_sum_si"
d1406 1
a1406 1
  "flag_pic"
d1409 1
a1409 1
  "* return TARGET_ARCH64 ? \"add %1,%%lo(%a2),%0\" : \"or %1,%%lo(%a2),%0\";"
a1413 2
;; The PIC version of sethi must appear before the non-pic case so that
;; the unspec will not be matched as part of the operand.
d1416 1
a1416 1
(define_insn "pic_sethi_si"
d1419 1
a1419 1
  "flag_pic && check_pic (1)"
d1424 7
a1430 7
(define_insn "pic_lo_sum_di"
  [(set (match_operand:DI 0 "register_operand" "=r")
        (lo_sum:SI (match_operand:DI 1 "register_operand" "r")
                   (unspec:SI [(match_operand:DI 2 "immediate_operand" "in")] 0)))]
  "TARGET_ARCH64 && flag_pic"
  "add %1,%%lo(%a2),%0"
  [(set_attr "length" "1")])
d1432 4
a1435 4
(define_insn "pic_sethi_di"
  [(set (match_operand:DI 0 "register_operand" "=r")
        (high:SI (unspec:SI [(match_operand 1 "" "")] 0)))]
  "TARGET_ARCH64 && flag_pic && check_pic (1)"
a1439 13
(define_insn "get_pc_via_call"
  [(set (pc) (label_ref (match_operand 0 "" "")))
   (set (reg:SI 15) (label_ref (match_operand 1 "" "")))]
  ""
  "call %l0%#"
  [(set_attr "type" "uncond_branch")])

(define_insn "get_pc_via_rdpc"
  [(set (match_operand:DI 0 "register_operand" "=r") (pc))]
  "TARGET_PTR64"
  "rd %%pc,%0"
  [(set_attr "type" "move")])

d1442 1
a1442 1
;; there.  The pic tablejump pattern also uses this.
d1444 1
a1444 1
(define_insn "move_pic_label_si"
d1446 1
a1446 3
	; This was previously (label_ref:SI (match_operand 1 "" "")) but that
	; loses the volatil and other flags of the original label_ref.
	(match_operand:SI 1 "label_ref_operand" ""))
d1448 2
a1449 8
  "flag_pic"
  "*
{
  if (get_attr_length (insn) == 2)
    return \"\\n1:\;call 2f\;add %%o7,%%lo(%l1-1b),%0\\n2:\";
  else
    return \"\\n1:\;call 2f\;sethi %%hi(%l1-1b),%0\\n2:\\tor %0,%%lo(%l1-1b),%0\;add %0,%%o7,%0\";
}"
d1451 3
a1453 5
   ; 960 = 4096 bytes / 4 bytes/insn - 64 (for not always perfect length calcs)
   (set (attr "length") (if_then_else (ltu (minus (match_dup 1) (pc))
					   (const_int 960))
				      (const_int 2)
				      (const_int 4)))])
d1455 3
a1457 14
;; Special sparc64 pattern for loading the address of a label into a register.
;; The pic and non-pic cases are the same since it's the most efficient way.
;;
;; ??? The non-pic case doesn't need to use %o7, we could use a scratch
;; instead.  But the pic case doesn't need to use %o7 either.  We handle them
;; both here so that when this is fixed, they can both be fixed together.
;; Don't forget that the pic jump table stuff uses %o7 (that will need to be
;; changed too).

(define_insn "move_label_di"
  [(set (match_operand:DI 0 "register_operand" "=r")
	; This was previously (label_ref:DI (match_operand 1 "" "")) but that
	; loses the volatil and other flags of the original label_ref.
	(match_operand:DI 1 "label_ref_operand" ""))
d1459 2
a1460 8
  "TARGET_ARCH64"
  "*
{
  if (get_attr_length (insn) == 2)
    return \"\\n1:\;rd %%pc,%%o7\;add %%o7,%l1-1b,%0\";
  else
    return \"\\n1:\;rd %%pc,%%o7\;sethi %%hi(%l1-1b),%0\;add %0,%%lo(%l1-1b),%0\;sra %0,0,%0\;add %0,%%o7,%0\";
}"
d1462 1
a1462 23
   ; 960 = 4096 bytes / 4 bytes/insn - 64 (for not always perfect length calcs)
   (set (attr "length") (if_then_else (ltu (minus (match_dup 1) (pc))
					   (const_int 960))
				      (const_int 2)
				      (const_int 5)))])

(define_insn "*sethi_hi"
  [(set (match_operand:HI 0 "register_operand" "=r")
	(high:HI (match_operand 1 "" "")))]
  "check_pic (1)"
  "sethi %%hi(%a1),%0"
  [(set_attr "type" "move")
   (set_attr "length" "1")])

;; This must appear after the PIC sethi so that the PIC unspec will not
;; be matched as part of the operand.
(define_insn "*sethi_si"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(high:SI (match_operand 1 "" "")))]
  "check_pic (1)"
  "sethi %%hi(%a1),%0"
  [(set_attr "type" "move")
   (set_attr "length" "1")])
d1468 1
a1468 1
  "! TARGET_ARCH64"
d1474 2
a1475 7
    operands[2] = GEN_INT (CONST_DOUBLE_LOW (operands[2]));
  else if (GET_CODE (operands[2]) == CONST_INT
	   && HOST_BITS_PER_WIDE_INT > 32
	   && INTVAL (operands[2]) > 0xffffffff)
    operands[2] = GEN_INT (INTVAL (operands[2]) & 0xffffffff);

  return \"or %L1,%%lo(%a2),%L0\";
d1481 2
d1489 1
a1489 1
  "TARGET_ARCH64"
d1495 1
a1495 6
    operands[2] = GEN_INT (CONST_DOUBLE_LOW (operands[2]));
  else if (GET_CODE (operands[2]) == CONST_INT
	   && HOST_BITS_PER_WIDE_INT > 32
	   && INTVAL (operands[2]) > 0xffffffff)
    operands[2] = GEN_INT (INTVAL (operands[2]) & 0xffffffff);

d1507 1
a1507 1
  "! TARGET_ARCH64 && check_pic (1)"
d1527 1
a1527 1
      operands[1] = GEN_INT (CONST_DOUBLE_LOW (op1));
d1531 1
a1531 1
      operands[1] = GEN_INT (CONST_DOUBLE_HIGH (op1));
d1550 4
a1553 7
(define_expand "sethi_di_sp64"
  [(parallel
     [(set (match_operand:DI 0 "register_operand" "")
	   (high:DI (match_operand 1 "general_operand" "")))
      (clobber (reg:DI 1))])]
  "TARGET_ARCH64"
  "")
d1555 1
a1555 1
(define_insn "*sethi_di_sp64_const"
d1559 1
a1559 1
  "TARGET_ARCH64 && check_pic (1)"
a1561 1
#if HOST_BITS_PER_WIDE_INT == 32
a1580 20
#else
  rtx op = operands[1];

  if (! SPARC_SETHI_P (INTVAL(op)))
    {
      operands[1] = GEN_INT (INTVAL (op) >> 32);
      output_asm_insn (singlemove_string (operands), operands);

      output_asm_insn (\"sllx %0,32,%0\", operands);
      if (INTVAL (op) & 0xffffffff)
	{
	  operands[1] = GEN_INT (INTVAL (op) & 0xffffffff);
	  output_asm_insn (\"sethi %%hi(%a1),%%g1; or %0,%%g1,%0\", operands);
	}
    }
  else
    {
      output_asm_insn (\"sethi %%hi(%a1),%0\", operands);
    }
#endif
d1590 1
a1590 2
;; uses the same "%X+%lo(...)" in the load/store insn, though in the case of
;; the medium/middle code model "%lo" is written "%l44".
d1592 1
a1592 1
;; When TARGET_CM_MEDLOW, assume that the upper 32 bits of symbol addresses are
d1594 4
a1597 9
;; When TARGET_CM_MEDMID, the executable must be in the low 16 TB of memory.
;; This corresponds to the low 44 bits, and the %[hml]44 relocs are used.
;; ??? Not implemented yet.
;; When TARGET_CM_EMBMEDANY, the text and data segments have a maximum size of
;; 31 bits and may be located anywhere.  EMBMEDANY_BASE_REG contains the start
;; address of the data segment, currently %g4.
;; When TARGET_CM_MEDANY, the text and data segments have a maximum size of 31
;; bits and may be located anywhere.  The maximum offset from any instruction
;; to the label _GLOBAL_OFFSET_TABLE_ is 31 bits.
d1602 1
a1602 1
  ;; The clobber is here because emit_move_sequence assumes the worst case.
d1604 1
a1604 9
  "TARGET_CM_MEDLOW && check_pic (1)"
  "sethi %%hi(%a1),%0"
  [(set_attr "type" "move")
   (set_attr "length" "1")])

(define_insn "*sethi_di_medium_pic"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(high:DI (match_operand 1 "sp64_medium_pic_operand" "")))]
  "(TARGET_CM_MEDLOW || TARGET_CM_EMBMEDANY) && check_pic (1)"
d1612 1
a1612 1
(define_insn "*sethi_di_embmedany_data"
d1615 1
a1615 1
  ;; The clobber is here because emit_move_sequence assumes the worst case.
d1617 2
a1618 2
  "TARGET_CM_EMBMEDANY && check_pic (1)"
  "sethi %%hi(%a1),%0; add %0,%_,%0"
d1622 1
a1622 1
(define_insn "*sethi_di_embmedany_text"
d1625 10
a1634 1
  ;; The clobber is here because emit_move_sequence assumes the worst case.
d1636 1
a1636 1
  "TARGET_CM_EMBMEDANY && check_pic (1)"
d1656 3
a1658 4
  "! TARGET_LIVE_G0
   && (register_operand (operands[0], QImode)
       || register_operand (operands[1], QImode)
       || operands[1] == const0_rtx)"
d1665 1
a1665 17
   (set_attr "length" "1")])

(define_insn "*movqi_insn_liveg0"
  [(set (match_operand:QI 0 "reg_or_nonsymb_mem_operand" "=r,r,r,r,r,Q")
	(match_operand:QI 1 "move_operand" "r,J,I,K,Q,r"))]
  "TARGET_LIVE_G0
   && (register_operand (operands[0], QImode)
       || register_operand (operands[1], QImode))"
  "@@
   mov %1,%0
   and %0,0,%0
   and %0,0,%0\;or %0,%1,%0
   sethi %%hi(%a1),%0
   ldub %1,%0
   stb %1,%0"
  [(set_attr "type" "move,move,move,move,load,store")
   (set_attr "length" "1,1,2,1,1,1")])
d1679 1
a1679 2
  "(reload_completed || reload_in_progress)
   && ! TARGET_PTR64"
d1697 3
a1699 4
  "! TARGET_LIVE_G0
   && (register_operand (operands[0], HImode)
       || register_operand (operands[1], HImode)
       || operands[1] == const0_rtx)"
d1706 1
a1706 17
   (set_attr "length" "1")])

(define_insn "*movhi_insn_liveg0"
  [(set (match_operand:HI 0 "reg_or_nonsymb_mem_operand" "=r,r,r,r,r,Q")
	(match_operand:HI 1 "move_operand" "r,J,I,K,Q,r"))]
  "TARGET_LIVE_G0
   && (register_operand (operands[0], HImode)
       || register_operand (operands[1], HImode))"
  "@@
   mov %1,%0
   and %0,0,%0
   and %0,0,%0\;or %0,%1,%0
   sethi %%hi(%a1),%0
   lduh %1,%0
   sth %1,%0"
  [(set_attr "type" "move,move,move,move,load,store")
   (set_attr "length" "1,1,2,1,1,1")])
d1720 1
a1720 2
  "(reload_completed || reload_in_progress)
   && ! TARGET_PTR64"
d1746 3
a1748 4
  "! TARGET_LIVE_G0
   && (register_operand (operands[0], SImode)
       || register_operand (operands[1], SImode)
       || operands[1] == const0_rtx)"
d1756 3
a1758 22
   st %1,%0"
  [(set_attr "type" "move,fp,move,load,fpload,store,fpstore")
   (set_attr "length" "1")])

(define_insn "*movsi_insn_liveg0"
  [(set (match_operand:SI 0 "reg_or_nonsymb_mem_operand" "=r,r,r,f,r,r,f,Q,Q")
	(match_operand:SI 1 "move_operand" "r,J,I,!f,K,Q,!Q,r,!f"))]
  "TARGET_LIVE_G0
   && (register_operand (operands[0], SImode)
       || register_operand (operands[1], SImode))"
  "@@
   mov %1,%0
   and %0,0,%0
   and %0,0,%0\;or %0,%1,%0
   fmovs %1,%0
   sethi %%hi(%a1),%0
   ld %1,%0
   ld %1,%0
   st %1,%0
   st %1,%0"
  [(set_attr "type" "move,move,move,fp,move,load,fpload,store,fpstore")
   (set_attr "length" "1,1,2,1,1,1,1,1,1")])
d1764 1
a1764 2
  "(reload_completed || reload_in_progress)
   && ! TARGET_PTR64"
d1782 1
a1782 1
  "! TARGET_ARCH64
d1806 1
a1806 1
  "TARGET_ARCH64
d1827 2
a1828 1
	  operands[1] = GEN_INT (~INTVAL (operands[1]));
d1868 1
a1868 1
;	      (clobber (reg:SI 100))
d1894 1
a1894 1
;   (clobber (reg:SI 100))
d1909 1
a1909 4
  "TARGET_FPU
   && GET_CODE (operands[1]) == CONST_DOUBLE
   && (GET_CODE (operands[0]) == REG
       || fp_zero_operand (operands[1]))"
d1946 2
a1947 2
   st %1,%0
   st %1,%0"
d1963 1
a1963 1
   st %1,%0"
d1970 1
a1970 2
  "(reload_completed || reload_in_progress)
   && ! TARGET_PTR64"
d1982 1
a1982 4
  "TARGET_FPU
   && GET_CODE (operands[1]) == CONST_DOUBLE
   && (GET_CODE (operands[0]) == REG
       || fp_zero_operand (operands[1]))"
d1992 1
a1992 1
      if (TARGET_ARCH64)
d2047 1
a2047 1

d2051 1
a2051 3
  "! TARGET_ARCH64 && reload_completed
   && REGNO (operands[0]) < SPARC_FIRST_V9_FP_REG
   && REGNO (operands[1]) < SPARC_FIRST_V9_FP_REG"
d2079 1
a2079 2
  "(reload_completed || reload_in_progress)
   && ! TARGET_PTR64"
d2097 1
a2097 4
  "TARGET_FPU
   && GET_CODE (operands[1]) == CONST_DOUBLE
   && (GET_CODE (operands[0]) == REG
       || fp_zero_operand (operands[1]))"
d2107 1
a2107 1
      if (TARGET_ARCH64)
d2176 1
a2176 2
  "0 && (reload_completed || reload_in_progress)
   && ! TARGET_PTR64"
d2190 2
a2191 65
;; We can handle larger constants here for some flavors, but for now we keep
;; it simple and only allow those constants supported by all flavours.
;; Note that emit_conditional_move canonicalizes operands 2,3 so that operand
;; 3 contains the constant if one is present, but we handle either for
;; generality (sparc.c puts a constant in operand 2).

(define_expand "movqicc"
  [(set (match_operand:QI 0 "register_operand" "")
	(if_then_else:QI (match_operand 1 "comparison_operator" "")
			 (match_operand:QI 2 "arith10_operand" "")
			 (match_operand:QI 3 "arith10_operand" "")))]
  "TARGET_V9"
  "
{
  enum rtx_code code = GET_CODE (operands[1]);

  if (GET_MODE (sparc_compare_op0) == DImode
      && ! TARGET_ARCH64)
    FAIL;

  if (sparc_compare_op1 == const0_rtx
      && GET_CODE (sparc_compare_op0) == REG
      && GET_MODE (sparc_compare_op0) == DImode
      && v9_regcmp_p (code))
    {
      operands[1] = gen_rtx (code, DImode,
			     sparc_compare_op0, sparc_compare_op1);
    }
  else
    {
      rtx cc_reg = gen_compare_reg (code,
				    sparc_compare_op0, sparc_compare_op1);
      operands[1] = gen_rtx (code, GET_MODE (cc_reg), cc_reg, const0_rtx);
    }
}")

(define_expand "movhicc"
  [(set (match_operand:HI 0 "register_operand" "")
	(if_then_else:HI (match_operand 1 "comparison_operator" "")
			 (match_operand:HI 2 "arith10_operand" "")
			 (match_operand:HI 3 "arith10_operand" "")))]
  "TARGET_V9"
  "
{
  enum rtx_code code = GET_CODE (operands[1]);

  if (GET_MODE (sparc_compare_op0) == DImode
      && ! TARGET_ARCH64)
    FAIL;

  if (sparc_compare_op1 == const0_rtx
      && GET_CODE (sparc_compare_op0) == REG
      && GET_MODE (sparc_compare_op0) == DImode
      && v9_regcmp_p (code))
    {
      operands[1] = gen_rtx (code, DImode,
			     sparc_compare_op0, sparc_compare_op1);
    }
  else
    {
      rtx cc_reg = gen_compare_reg (code,
				    sparc_compare_op0, sparc_compare_op1);
      operands[1] = gen_rtx (code, GET_MODE (cc_reg), cc_reg, const0_rtx);
    }
}")
d2195 3
a2197 3
	(if_then_else:SI (match_operand 1 "comparison_operator" "")
			 (match_operand:SI 2 "arith10_operand" "")
			 (match_operand:SI 3 "arith10_operand" "")))]
a2202 4
  if (GET_MODE (sparc_compare_op0) == DImode
      && ! TARGET_ARCH64)
    FAIL;

d2221 4
a2224 4
	(if_then_else:DI (match_operand 1 "comparison_operator" "")
			 (match_operand:DI 2 "arith10_double_operand" "")
			 (match_operand:DI 3 "arith10_double_operand" "")))]
  "TARGET_ARCH64"
d2247 4
a2250 4
	(if_then_else:SF (match_operand 1 "comparison_operator" "")
			 (match_operand:SF 2 "register_operand" "")
			 (match_operand:SF 3 "register_operand" "")))]
  "TARGET_V9 && TARGET_FPU"
a2254 4
  if (GET_MODE (sparc_compare_op0) == DImode
      && ! TARGET_ARCH64)
    FAIL;

d2273 4
a2276 4
	(if_then_else:DF (match_operand 1 "comparison_operator" "")
			 (match_operand:DF 2 "register_operand" "")
			 (match_operand:DF 3 "register_operand" "")))]
  "TARGET_V9 && TARGET_FPU"
a2280 4
  if (GET_MODE (sparc_compare_op0) == DImode
      && ! TARGET_ARCH64)
    FAIL;

d2299 4
a2302 4
	(if_then_else:TF (match_operand 1 "comparison_operator" "")
			 (match_operand:TF 2 "register_operand" "")
			 (match_operand:TF 3 "register_operand" "")))]
  "TARGET_V9 && TARGET_FPU"
a2306 4
  if (GET_MODE (sparc_compare_op0) == DImode
      && ! TARGET_ARCH64)
    FAIL;

d2323 1
a2323 1
;; Conditional move define_insns.
d2325 44
a2368 4
(define_insn "*movqi_cc_sp64"
  [(set (match_operand:QI 0 "register_operand" "=r,r")
	(if_then_else:QI (match_operator 1 "comparison_operator"
				[(match_operand 2 "icc_or_fcc_reg_operand" "X,X")
d2370 2
a2371 2
		      (match_operand:QI 3 "arith11_operand" "rL,0")
		      (match_operand:QI 4 "arith11_operand" "0,rL")))]
d2373 34
a2406 3
  "@@
   mov%C1 %x2,%3,%0
   mov%c1 %x2,%4,%0"
d2409 4
a2412 4
(define_insn "*movhi_cc_sp64"
  [(set (match_operand:HI 0 "register_operand" "=r,r")
	(if_then_else:HI (match_operator 1 "comparison_operator"
				[(match_operand 2 "icc_or_fcc_reg_operand" "X,X")
d2414 2
a2415 2
		      (match_operand:HI 3 "arith11_operand" "rL,0")
		      (match_operand:HI 4 "arith11_operand" "0,rL")))]
d2417 1
a2417 3
  "@@
   mov%C1 %x2,%3,%0
   mov%c1 %x2,%4,%0"
d2420 4
a2423 4
(define_insn "*movsi_cc_sp64"
  [(set (match_operand:SI 0 "register_operand" "=r,r")
	(if_then_else:SI (match_operator 1 "comparison_operator"
				[(match_operand 2 "icc_or_fcc_reg_operand" "X,X")
d2425 2
a2426 2
		      (match_operand:SI 3 "arith11_operand" "rL,0")
		      (match_operand:SI 4 "arith11_operand" "0,rL")))]
d2428 45
a2472 3
  "@@
   mov%C1 %x2,%3,%0
   mov%c1 %x2,%4,%0"
d2475 4
a2478 5
;; ??? The constraints of operands 3,4 need work.
(define_insn "*movdi_cc_sp64"
  [(set (match_operand:DI 0 "register_operand" "=r,r")
	(if_then_else:DI (match_operator 1 "comparison_operator"
				[(match_operand 2 "icc_or_fcc_reg_operand" "X,X")
d2480 4
a2483 6
		      (match_operand:DI 3 "arith11_double_operand" "rLH,0")
		      (match_operand:DI 4 "arith11_double_operand" "0,rLH")))]
  "TARGET_ARCH64"
  "@@
   mov%C1 %x2,%3,%0
   mov%c1 %x2,%4,%0"
d2486 4
a2489 4
(define_insn "*movsf_cc_sp64"
  [(set (match_operand:SF 0 "register_operand" "=f,f")
	(if_then_else:SF (match_operator 1 "comparison_operator"
				[(match_operand 2 "icc_or_fcc_reg_operand" "X,X")
d2491 2
a2492 2
		      (match_operand:SF 3 "register_operand" "f,0")
		      (match_operand:SF 4 "register_operand" "0,f")))]
d2494 1
a2494 3
  "@@
   fmovs%C1 %x2,%3,%0
   fmovs%c1 %x2,%4,%0"
d2497 4
a2500 4
(define_insn "*movdf_cc_sp64"
  [(set (match_operand:DF 0 "register_operand" "=e,e")
	(if_then_else:DF (match_operator 1 "comparison_operator"
				[(match_operand 2 "icc_or_fcc_reg_operand" "X,X")
d2502 2
a2503 2
		      (match_operand:DF 3 "register_operand" "e,0")
		      (match_operand:DF 4 "register_operand" "0,e")))]
d2505 1
a2505 3
  "@@
   fmovd%C1 %x2,%3,%0
   fmovd%c1 %x2,%4,%0"
d2507 5
a2511 5

(define_insn "*movtf_cc_sp64"
  [(set (match_operand:TF 0 "register_operand" "=e,e")
	(if_then_else:TF (match_operator 1 "comparison_operator"
				[(match_operand 2 "icc_or_fcc_reg_operand" "X,X")
d2513 4
a2516 6
		      (match_operand:TF 3 "register_operand" "e,0")
		      (match_operand:TF 4 "register_operand" "0,e")))]
  "TARGET_V9 && TARGET_FPU && TARGET_HARD_QUAD"
  "@@
   fmovq%C1 %x2,%3,%0
   fmovq%c1 %x2,%4,%0"
d2519 4
a2522 4
(define_insn "*movqi_cc_reg_sp64"
  [(set (match_operand:QI 0 "register_operand" "=r,r")
	(if_then_else:QI (match_operator 1 "v9_regcmp_op"
				[(match_operand:DI 2 "register_operand" "r,r")
d2524 4
a2527 6
		      (match_operand:QI 3 "arith10_operand" "rM,0")
		      (match_operand:QI 4 "arith10_operand" "0,rM")))]
  "TARGET_ARCH64"
  "@@
   movr%D1 %2,%r3,%0
   movr%d1 %2,%r4,%0"
d2530 8
a2537 11
(define_insn "*movhi_cc_reg_sp64"
  [(set (match_operand:HI 0 "register_operand" "=r,r")
	(if_then_else:HI (match_operator 1 "v9_regcmp_op"
				[(match_operand:DI 2 "register_operand" "r,r")
				 (const_int 0)])
		      (match_operand:HI 3 "arith10_operand" "rM,0")
		      (match_operand:HI 4 "arith10_operand" "0,rM")))]
  "TARGET_ARCH64"
  "@@
   movr%D1 %2,%r3,%0
   movr%d1 %2,%r4,%0"
d2540 8
a2547 11
(define_insn "*movsi_cc_reg_sp64"
  [(set (match_operand:SI 0 "register_operand" "=r,r")
	(if_then_else:SI (match_operator 1 "v9_regcmp_op"
				[(match_operand:DI 2 "register_operand" "r,r")
				 (const_int 0)])
		      (match_operand:SI 3 "arith10_operand" "rM,0")
		      (match_operand:SI 4 "arith10_operand" "0,rM")))]
  "TARGET_ARCH64"
  "@@
   movr%D1 %2,%r3,%0
   movr%d1 %2,%r4,%0"
d2550 8
a2557 12
;; ??? The constraints of operands 3,4 need work.
(define_insn "*movdi_cc_reg_sp64"
  [(set (match_operand:DI 0 "register_operand" "=r,r")
	(if_then_else:DI (match_operator 1 "v9_regcmp_op"
				[(match_operand:DI 2 "register_operand" "r,r")
				 (const_int 0)])
		      (match_operand:DI 3 "arith10_double_operand" "rMH,0")
		      (match_operand:DI 4 "arith10_double_operand" "0,rMH")))]
  "TARGET_ARCH64"
  "@@
   movr%D1 %2,%r3,%0
   movr%d1 %2,%r4,%0"
d2560 8
a2567 11
(define_insn "*movsf_cc_reg_sp64"
  [(set (match_operand:SF 0 "register_operand" "=f,f")
	(if_then_else:SF (match_operator 1 "v9_regcmp_op"
				[(match_operand:DI 2 "register_operand" "r,r")
				 (const_int 0)])
		      (match_operand:SF 3 "register_operand" "f,0")
		      (match_operand:SF 4 "register_operand" "0,f")))]
  "TARGET_ARCH64 && TARGET_FPU"
  "@@
   fmovrs%D1 %2,%3,%0
   fmovrs%d1 %2,%4,%0"
d2570 8
a2577 11
(define_insn "*movdf_cc_reg_sp64"
  [(set (match_operand:DF 0 "register_operand" "=e,e")
	(if_then_else:DF (match_operator 1 "v9_regcmp_op"
				[(match_operand:DI 2 "register_operand" "r,r")
				 (const_int 0)])
		      (match_operand:DF 3 "register_operand" "e,0")
		      (match_operand:DF 4 "register_operand" "0,e")))]
  "TARGET_ARCH64 && TARGET_FPU"
  "@@
   fmovrd%D1 %2,%3,%0
   fmovrd%d1 %2,%4,%0"
d2580 8
a2587 11
(define_insn "*movtf_cc_reg_sp64"
  [(set (match_operand:TF 0 "register_operand" "=e,e")
	(if_then_else:TF (match_operator 1 "v9_regcmp_op"
				[(match_operand:DI 2 "register_operand" "r,r")
				 (const_int 0)])
		      (match_operand:TF 3 "register_operand" "e,0")
		      (match_operand:TF 4 "register_operand" "0,e")))]
  "TARGET_ARCH64 && TARGET_FPU"
  "@@
   fmovrq%D1 %2,%3,%0
   fmovrq%d1 %2,%4,%0"
d2603 1
a2603 1
  rtx shift_16 = GEN_INT (16);
d2661 1
a2661 1
  "TARGET_ARCH64"
d2667 1
a2667 1
  "TARGET_ARCH64 && GET_CODE (operands[1]) != CONST_INT"
d2677 1
a2677 1
  "TARGET_ARCH64"
d2681 1
a2681 1
  rtx shift_48 = GEN_INT (48);
d2700 1
a2700 1
  "TARGET_ARCH64"
d2709 1
a2709 1
  "TARGET_ARCH64"
d2715 1
a2715 1
  "TARGET_ARCH64 && GET_CODE (operands[1]) != CONST_INT"
d2725 1
a2725 1
  [(set (reg:CC 100)
d2733 1
a2733 1
  [(set (reg:CC 100)
d2745 1
a2745 1
  [(set (reg:CC 100)
d2753 1
a2753 1
  [(set (reg:CC 100)
d2775 1
a2775 1
  rtx shift_16 = GEN_INT (16);
d2805 1
a2805 1
  rtx shift_24 = GEN_INT (24);
d2842 1
a2842 1
  rtx shift_24 = GEN_INT (24);
d2868 1
a2868 1
  "TARGET_ARCH64"
d2872 1
a2872 1
  rtx shift_56 = GEN_INT (56);
d2891 1
a2891 1
  "TARGET_ARCH64"
d2898 1
a2898 1
  "TARGET_ARCH64"
d2902 1
a2902 1
  rtx shift_48 = GEN_INT (48);
d2921 1
a2921 1
  "TARGET_ARCH64"
d2928 1
a2928 1
  "TARGET_ARCH64"
d2934 1
a2934 1
  "TARGET_ARCH64"
d2945 1
a2945 1
  [(set (reg:CC 100)
d2958 1
a2958 1
  operands[1] = GEN_INT (mask);
d2963 1
a2963 1
  [(set (reg:CCX 100)
d2969 1
a2969 1
  "TARGET_ARCH64 && INTVAL (operands[2]) > 51"
d2974 1
a2974 1
  unsigned HOST_WIDE_INT mask = (((unsigned HOST_WIDE_INT) 1 << len) - 1) << pos;
d2976 1
a2976 1
  operands[1] = GEN_INT (mask);
d3061 1
a3061 1
  "TARGET_ARCH64 && TARGET_FPU"
d3073 1
a3073 1
  "TARGET_ARCH64 && TARGET_FPU"
d3085 1
a3085 1
  "TARGET_ARCH64 && TARGET_FPU && TARGET_HARD_QUAD"
d3097 1
a3097 1
  "TARGET_ARCH64 && TARGET_FPU"
d3114 1
a3114 1
  "TARGET_ARCH64 && TARGET_FPU"
d3131 1
a3131 1
  "TARGET_ARCH64 && TARGET_FPU && TARGET_HARD_QUAD"
d3148 1
a3148 1
  "0 && TARGET_ARCH64 && TARGET_FPU"
d3155 1
a3155 1
  "0 && TARGET_ARCH64 && TARGET_FPU"
d3162 1
a3162 1
  "0 && TARGET_ARCH64 && TARGET_FPU && TARGET_HARD_QUAD"
d3203 1
a3203 1
  "TARGET_ARCH64 && TARGET_FPU"
d3215 1
a3215 1
  "TARGET_ARCH64 && TARGET_FPU"
d3227 1
a3227 1
  "TARGET_ARCH64 && TARGET_FPU && TARGET_HARD_QUAD"
d3239 1
a3239 1
  "TARGET_ARCH64 && TARGET_FPU"
d3256 1
a3256 1
  "TARGET_ARCH64 && TARGET_FPU"
d3273 1
a3273 1
  "TARGET_ARCH64 && TARGET_FPU && TARGET_HARD_QUAD"
d3290 1
a3290 1
  "0 && TARGET_ARCH64 && TARGET_FPU"
d3297 1
a3297 1
  "0 && TARGET_ARCH64 && TARGET_FPU"
d3304 1
a3304 1
  "0 && TARGET_ARCH64 && TARGET_FPU && TARGET_HARD_QUAD"
d3317 1
a3317 1
  if (! TARGET_ARCH64)
d3323 1
a3323 2
			  gen_rtx (CLOBBER, VOIDmode,
				   gen_rtx (REG, SImode, SPARC_ICC_REG)))));
d3332 2
a3333 2
   (clobber (reg:SI 100))]
  "! TARGET_ARCH64"
d3338 10
a3347 2
  if (GET_CODE (op2) == CONST_INT
      || GET_CODE (op2) == CONST_DOUBLE)
d3352 4
a3355 2
      if (WORDS_BIG_ENDIAN)
	split_double (op2, &xoperands[2], &xoperands[3]);
d3357 1
a3357 5
	split_double (op2, &xoperands[3], &xoperands[2]);
      if (xoperands[3] == const0_rtx && xoperands[0] == xoperands[1])
	output_asm_insn (\"add %H1,%2,%H0\", xoperands);
      else
	output_asm_insn (\"addcc %L1,%3,%L0\;addx %H1,%2,%H0\", xoperands);
d3360 1
a3360 1
  return \"addcc %L1,%L2,%L0\;addx %H1,%H2,%H0\";
d3368 1
a3368 1
  "TARGET_ARCH64"
d3380 1
a3380 1
  [(set (reg:CC_NOOV 100)
d3389 1
a3389 1
  [(set (reg:CCX_NOOV 100)
d3393 1
a3393 1
  "TARGET_ARCH64"
d3398 1
a3398 1
  [(set (reg:CC_NOOV 100)
d3408 1
a3408 1
  [(set (reg:CCX_NOOV 100)
d3414 1
a3414 1
  "TARGET_ARCH64"
d3424 1
a3424 1
  if (! TARGET_ARCH64)
d3430 1
a3430 2
			  gen_rtx (CLOBBER, VOIDmode,
				   gen_rtx (REG, SImode, SPARC_ICC_REG)))));
d3439 2
a3440 2
   (clobber (reg:SI 100))]
  "! TARGET_ARCH64"
d3445 10
a3454 2
  if (GET_CODE (op2) == CONST_INT
      || GET_CODE (op2) == CONST_DOUBLE)
d3459 4
a3462 2
      if (WORDS_BIG_ENDIAN)
	split_double (op2, &xoperands[2], &xoperands[3]);
d3464 1
a3464 5
	split_double (op2, &xoperands[3], &xoperands[2]);
      if (xoperands[3] == const0_rtx && xoperands[0] == xoperands[1])
	output_asm_insn (\"sub %H1,%2,%H0\", xoperands);
      else
	output_asm_insn (\"subcc %L1,%3,%L0\;subx %H1,%2,%H0\", xoperands);
d3467 1
a3467 1
  return \"subcc %L1,%L2,%L0\;subx %H1,%H2,%H0\";
d3475 1
a3475 1
  "TARGET_ARCH64"
d3487 1
a3487 1
  [(set (reg:CC_NOOV 100)
d3496 1
a3496 1
  [(set (reg:CCX_NOOV 100)
d3500 1
a3500 1
  "TARGET_ARCH64"
d3505 1
a3505 1
  [(set (reg:CC_NOOV 100)
d3515 1
a3515 1
  [(set (reg:CCX_NOOV 100)
d3521 1
a3521 1
  "TARGET_ARCH64"
a3522 2

;; Integer Multiply/Divide.
d3524 2
a3525 3
;; The 32 bit multiply/divide instructions are deprecated on v9 and shouldn't
;; we used.  We still use them in 32 bit v9 compilers.
;; The 64 bit v9 compiler will (/should) widen the args and use muldi3.
d3531 1
a3531 1
  "TARGET_V8 || TARGET_SPARCLITE || TARGET_SPARCLET || TARGET_DEPRECATED_V8_INSNS"
d3539 1
a3539 1
  "TARGET_ARCH64"
d3548 1
a3548 1
   (set (reg:CC_NOOV 100)
d3551 1
a3551 1
  "TARGET_V8 || TARGET_SPARCLITE || TARGET_DEPRECATED_V8_INSNS"
d3559 1
a3559 1
  "TARGET_V8 || TARGET_SPARCLITE || TARGET_SPARCLET || TARGET_DEPRECATED_V8_INSNS"
d3573 3
a3575 8
  "TARGET_V8 || TARGET_SPARCLITE || TARGET_SPARCLET || TARGET_DEPRECATED_V8_INSNS"
  "*
{
  return TARGET_SPARCLET ? \"smuld %1,%2,%L0\" : \"smul %1,%2,%L0\;rd %%y,%H0\";
}"
  [(set (attr "length")
	(if_then_else (eq_attr "isa" "sparclet")
		      (const_int 1) (const_int 2)))])
d3583 3
a3585 8
  "TARGET_V8 || TARGET_SPARCLITE || TARGET_SPARCLET || TARGET_DEPRECATED_V8_INSNS"
  "*
{
  return TARGET_SPARCLET ? \"smuld %1,%2,%L0\" : \"smul %1,%2,%L0\;rd %%y,%H0\";
}"
  [(set (attr "length")
	(if_then_else (eq_attr "isa" "sparclet")
		      (const_int 1) (const_int 2)))])
d3593 1
a3593 1
  "TARGET_V8 || TARGET_SPARCLITE || TARGET_SPARCLET || TARGET_DEPRECATED_V8_INSNS"
d3609 1
a3609 1
  "TARGET_V8 || TARGET_SPARCLITE || TARGET_SPARCLET || TARGET_DEPRECATED_V8_INSNS"
d3619 1
a3619 1
  "TARGET_V8 || TARGET_SPARCLITE || TARGET_SPARCLET || TARGET_DEPRECATED_V8_INSNS"
d3627 1
a3627 1
  "TARGET_V8 || TARGET_SPARCLITE || TARGET_SPARCLET || TARGET_DEPRECATED_V8_INSNS"
d3641 3
a3643 8
  "TARGET_V8 || TARGET_SPARCLITE || TARGET_SPARCLET || TARGET_DEPRECATED_V8_INSNS"
  "*
{
  return TARGET_SPARCLET ? \"umuld %1,%2,%L0\" : \"umul %1,%2,%L0\;rd %%y,%H0\";
}"
  [(set (attr "length")
	(if_then_else (eq_attr "isa" "sparclet")
		      (const_int 1) (const_int 2)))])
d3651 3
a3653 8
  "TARGET_V8 || TARGET_SPARCLITE || TARGET_SPARCLET || TARGET_DEPRECATED_V8_INSNS"
  "*
{
  return TARGET_SPARCLET ? \"umuld %1,%2,%L0\" : \"umul %1,%2,%L0\;rd %%y,%H0\";
}"
  [(set (attr "length")
	(if_then_else (eq_attr "isa" "sparclet")
		      (const_int 1) (const_int 2)))])
d3661 1
a3661 1
  "TARGET_V8 || TARGET_SPARCLITE || TARGET_SPARCLET || TARGET_DEPRECATED_V8_INSNS"
d3677 1
a3677 1
  "TARGET_V8 || TARGET_SPARCLITE || TARGET_SPARCLET || TARGET_DEPRECATED_V8_INSNS"
d3687 1
a3687 1
  "TARGET_V8 || TARGET_SPARCLITE || TARGET_SPARCLET || TARGET_DEPRECATED_V8_INSNS"
d3691 1
a3691 1
;; The v8 architecture specifies that there must be 3 instructions between
d3699 3
a3701 11
  "TARGET_V8 || TARGET_DEPRECATED_V8_INSNS"
  "*
{
  if (TARGET_V9)
    return \"sra %1,31,%3\;wr %%g0,%3,%%y\;sdiv %1,%2,%0\";
  else
    return \"sra %1,31,%3\;wr %%g0,%3,%%y\;nop\;nop\;nop\;sdiv %1,%2,%0\";
}"
  [(set (attr "length")
	(if_then_else (eq_attr "isa" "v9")
		      (const_int 3) (const_int 6)))])
d3707 1
a3707 1
  "TARGET_ARCH64"
d3716 1
a3716 1
   (set (reg:CC 100)
d3720 3
a3722 11
  "TARGET_V8 || TARGET_DEPRECATED_V8_INSNS"
  "*
{
  if (TARGET_V9)
    return \"sra %1,31,%3\;wr %%g0,%3,%%y\;sdivcc %1,%2,%0\";
  else
    return \"sra %1,31,%3\;wr %%g0,%3,%%y\;nop\;nop\;nop\;sdivcc %1,%2,%0\";
}"
  [(set (attr "length")
	(if_then_else (eq_attr "isa" "v9")
		      (const_int 3) (const_int 6)))])
d3727 4
a3730 12
		 (match_operand:SI 2 "arith_operand" "rI")))]
  "TARGET_V8 || TARGET_DEPRECATED_V8_INSNS"
  "*
{
  if (TARGET_V9)
    return \"wr %%g0,%%g0,%%y\;udiv %1,%2,%0\";
  else
    return \"wr %%g0,%%g0,%%y\;nop\;nop\;nop\;udiv %1,%2,%0\";
}"
  [(set (attr "length")
	(if_then_else (eq_attr "isa" "v9")
		      (const_int 2) (const_int 5)))])
d3736 1
a3736 1
  "TARGET_ARCH64"
d3745 1
a3745 1
   (set (reg:CC 100)
d3748 3
a3750 44
  "TARGET_V8 || TARGET_DEPRECATED_V8_INSNS"
  "*
{
  if (TARGET_V9)
    return \"wr %%g0,%%g0,%%y\;udivcc %1,%2,%0\";
  else
    return \"wr %%g0,%%g0,%%y\;nop\;nop\;nop\;udivcc %1,%2,%0\";
}"
  [(set (attr "length")
	(if_then_else (eq_attr "isa" "v9")
		      (const_int 2) (const_int 5)))])

; sparclet multiply/accumulate insns

(define_insn "*smacsi"
  [(set (match_operand:SI 0 "register_operand" "=r")
	(plus:SI (mult:SI (match_operand:SI 1 "register_operand" "%r")
			  (match_operand:SI 2 "arith_operand" "rI"))
		 (match_operand:SI 3 "register_operand" "0")))]
  "TARGET_SPARCLET"
  "smac %1,%2,%0"
  [(set_attr "type" "imul")])

(define_insn "*smacdi"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(plus:DI (mult:DI (sign_extend:DI
			   (match_operand:SI 1 "register_operand" "%r"))
			  (sign_extend:DI
			   (match_operand:SI 2 "register_operand" "r")))
		 (match_operand:DI 3 "register_operand" "0")))]
  "TARGET_SPARCLET"
  "smacd %1,%2,%L0"
  [(set_attr "type" "imul")])

(define_insn "*umacdi"
  [(set (match_operand:DI 0 "register_operand" "=r")
	(plus:DI (mult:DI (zero_extend:DI
			   (match_operand:SI 1 "register_operand" "%r"))
			  (zero_extend:DI
			   (match_operand:SI 2 "register_operand" "r")))
		 (match_operand:DI 3 "register_operand" "0")))]
  "TARGET_SPARCLET"
  "umacd %1,%2,%L0"
  [(set_attr "type" "imul")])
d3753 2
a3754 2
;; We define DImode `and' so with DImode `not' we can get
;; DImode `andn'.  Other combinations are possible.
d3767 1
a3767 1
  "! TARGET_ARCH64"
d3772 10
a3781 2
  if (GET_CODE (op2) == CONST_INT
      || GET_CODE (op2) == CONST_DOUBLE)
d3786 5
a3790 5
      if (WORDS_BIG_ENDIAN)
	split_double (op2, &xoperands[2], &xoperands[3]);
      else
	split_double (op2, &xoperands[3], &xoperands[2]);
      output_asm_insn (\"and %L1,%3,%L0\;and %H1,%2,%H0\", xoperands);
d3801 1
a3801 1
  "TARGET_ARCH64"
d3824 1
a3824 1
  operands[4] = GEN_INT (~INTVAL (operands[2]));
d3831 1
a3831 1
  "! TARGET_ARCH64"
d3839 1
a3839 1
  "TARGET_ARCH64"
d3861 1
a3861 1
  "! TARGET_ARCH64"
d3866 10
a3875 2
  if (GET_CODE (op2) == CONST_INT
      || GET_CODE (op2) == CONST_DOUBLE)
d3880 5
a3884 5
      if (WORDS_BIG_ENDIAN)
	split_double (op2, &xoperands[2], &xoperands[3]);
      else
	split_double (op2, &xoperands[3], &xoperands[2]);
      output_asm_insn (\"or %L1,%3,%L0\;or %H1,%2,%H0\", xoperands);
d3895 1
a3895 1
  "TARGET_ARCH64"
d3918 1
a3918 1
  operands[4] = GEN_INT (~INTVAL (operands[2]));
d3925 1
a3925 1
  "! TARGET_ARCH64"
d3933 1
a3933 1
  "TARGET_ARCH64"
d3955 1
a3955 1
  "! TARGET_ARCH64"
d3960 10
a3969 2
  if (GET_CODE (op2) == CONST_INT
      || GET_CODE (op2) == CONST_DOUBLE)
d3974 5
a3978 5
      if (WORDS_BIG_ENDIAN)
	split_double (op2, &xoperands[2], &xoperands[3]);
      else
	split_double (op2, &xoperands[3], &xoperands[2]);
      output_asm_insn (\"xor %L1,%3,%L0\;xor %H1,%2,%H0\", xoperands);
d3989 1
a3989 1
  "TARGET_ARCH64"
d4012 1
a4012 1
  operands[4] = GEN_INT (~INTVAL (operands[2]));
d4027 1
a4027 1
  operands[4] = GEN_INT (~INTVAL (operands[2]));
d4036 1
a4036 1
  "! TARGET_ARCH64"
d4044 1
a4044 1
  "TARGET_ARCH64"
d4059 1
a4059 1
  [(set (reg:CC 100)
d4070 1
a4070 1
  [(set (reg:CCX 100)
d4076 1
a4076 1
  "TARGET_ARCH64"
d4081 1
a4081 1
  [(set (reg:CC 100)
d4093 1
a4093 1
  [(set (reg:CCX 100)
d4101 1
a4101 1
  "TARGET_ARCH64"
d4105 1
a4105 1
  [(set (reg:CC 100)
d4115 1
a4115 1
  [(set (reg:CCX 100)
d4120 1
a4120 1
  "TARGET_ARCH64"
d4125 1
a4125 1
  [(set (reg:CC 100)
d4136 1
a4136 1
  [(set (reg:CCX 100)
d4143 1
a4143 1
  "TARGET_ARCH64"
d4147 1
a4147 1
  [(set (reg:CC 100)
d4158 1
a4158 1
  [(set (reg:CCX 100)
d4164 1
a4164 1
  "TARGET_ARCH64"
d4169 1
a4169 1
  [(set (reg:CC 100)
d4181 1
a4181 1
  [(set (reg:CCX 100)
d4189 1
a4189 1
  "TARGET_ARCH64"
d4201 1
a4201 1
  if (! TARGET_ARCH64)
d4206 1
a4206 2
			  gen_rtx (CLOBBER, VOIDmode,
				   gen_rtx (REG, SImode, SPARC_ICC_REG)))));
d4214 3
a4216 8
   (clobber (reg:SI 100))]
  "! TARGET_ARCH64"
  "*
{
  if (TARGET_LIVE_G0)
    output_asm_insn (\"and %%g0,0,%%g0\", operands);
  return \"subcc %%g0,%L1,%L0\;subx %%g0,%H1,%H0\";
}"
a4217 1
   ;; ??? This is wrong for TARGET_LIVE_G0 but it's not critical.
d4223 1
a4223 1
  "TARGET_ARCH64"
d4232 2
a4233 9
  "*
{
  if (TARGET_LIVE_G0)
    return \"and %%g0,0,%%g0\;sub %%g0,%1,%0\";
  return \"sub %%g0,%1,%0\";
}"
  [(set_attr "type" "unary")
   (set (attr "length")
	(if_then_else (eq_attr "live_g0" "yes") (const_int 2) (const_int 1)))])
d4236 1
a4236 1
  [(set (reg:CC_NOOV 100)
d4239 1
a4239 1
  "! TARGET_LIVE_G0"
d4244 1
a4244 1
  [(set (reg:CCX_NOOV 100)
d4247 1
a4247 1
  "TARGET_ARCH64"
d4252 1
a4252 1
  [(set (reg:CC_NOOV 100)
d4257 1
a4257 1
  "! TARGET_LIVE_G0"
d4262 1
a4262 1
  [(set (reg:CCX_NOOV 100)
d4267 1
a4267 1
  "TARGET_ARCH64"
d4282 2
a4283 2
  "! TARGET_ARCH64"
  "xnor %1,0,%0\;xnor %R1,0,%R0"
d4290 2
a4291 2
  "TARGET_ARCH64"
  "xnor %1,0,%0"
d4295 2
a4296 2
  [(set (match_operand:SI 0 "register_operand" "=r,r")
	(not:SI (match_operand:SI 1 "arith_operand" "r,I")))]
d4298 2
a4299 12
  "*
{
  if (which_alternative == 0)
    return \"xnor %1,0,%0\";
  if (TARGET_LIVE_G0)
    output_asm_insn (\"and %%g0,0,%%g0\", operands);
  return \"xnor %%g0,%1,%0\";
}"
  [(set_attr "type" "unary")
   (set_attr_alternative "length"
     [(const_int 1)
      (if_then_else (eq_attr "live_g0" "yes") (const_int 2) (const_int 1))])])
d4302 1
a4302 1
  [(set (reg:CC 100)
d4305 1
a4305 1
  "! TARGET_LIVE_G0"
d4310 1
a4310 1
  [(set (reg:CCX 100)
d4313 1
a4313 1
  "TARGET_ARCH64"
d4318 1
a4318 1
  [(set (reg:CC 100)
d4323 1
a4323 1
  "! TARGET_LIVE_G0"
d4328 1
a4328 1
  [(set (reg:CCX 100)
d4333 1
a4333 1
  "TARGET_ARCH64"
d4423 1
a4423 1
  "(TARGET_V8 || TARGET_V9) && TARGET_FPU && TARGET_HARD_QUAD"
a4454 1
  ; We don't use quad float insns here so we don't need TARGET_HARD_QUAD.
d4458 4
a4461 3
  /* v9: can't use fnegs, won't work with upper regs.  */
  if (which_alternative == 0)
   return TARGET_V9 ? \"fnegd %0,%0\" : \"fnegs %0,%0\";
d4463 1
a4463 2
   return TARGET_V9 ? \"fnegd %1,%0\;fmovd %S1,%S0\"
     : \"fnegs %1,%0\;fmovs %R1,%R0\;fmovs %S1,%S0\;fmovs %T1,%T0\";
d4468 1
a4468 1
      (if_then_else (eq_attr "isa" "v9") (const_int 2) (const_int 4))])])
d4486 1
a4486 1
      (if_then_else (eq_attr "isa" "v9") (const_int 1) (const_int 2))])])
a4497 1
  ; We don't use quad float insns here so we don't need TARGET_HARD_QUAD.
d4501 4
a4504 3
  /* v9: can't use fabss, won't work with upper regs.  */
  if (which_alternative == 0)
    return TARGET_V9 ? \"fabsd %0,%0\" : \"fabss %0,%0\";
d4506 1
a4506 2
    return TARGET_V9 ? \"fabsd %1,%0\;fmovd %S1,%S0\"
      : \"fabss %1,%0\;fmovs %R1,%R0\;fmovs %S1,%S0\;fmovs %T1,%T0\";
d4511 1
a4511 1
      (if_then_else (eq_attr "isa" "v9") (const_int 2) (const_int 4))])])
d4529 1
a4529 1
      (if_then_else (eq_attr "isa" "v9") (const_int 1) (const_int 2))])])
d4569 1
a4569 1
      && (unsigned HOST_WIDE_INT) INTVAL (operands[2]) > 31)
d4580 1
a4580 1
  "TARGET_ARCH64"
d4584 1
a4584 1
      && (unsigned HOST_WIDE_INT) INTVAL (operands[2]) > 31)
d4591 1
a4591 1
  [(set (reg:CC_NOOV 100)
d4600 1
a4600 1
  [(set (reg:CC_NOOV 100)
d4617 1
a4617 1
      && (unsigned HOST_WIDE_INT) INTVAL (operands[2]) > 31)
d4628 1
a4628 1
  "TARGET_ARCH64"
d4632 1
a4632 1
      && (unsigned HOST_WIDE_INT) INTVAL (operands[2]) > 63)
d4646 1
a4646 1
      && (unsigned HOST_WIDE_INT) INTVAL (operands[2]) > 31)
d4657 1
a4657 1
  "TARGET_ARCH64"
d4661 1
a4661 1
      && (unsigned HOST_WIDE_INT) INTVAL (operands[2]) > 63)
d4674 1
a4674 15
  "*
{
  /* Some implementations are reported to have problems with
	foo: b,a foo
     i.e. an empty loop with the annul bit set.  The workaround is to use 
        foo: b foo; nop
     instead.  */

  if (flag_delayed_branch
      && (insn_addresses[INSN_UID (operands[0])]
	  == insn_addresses[INSN_UID (insn)]))
    return \"b %l0%#\";
  else
    return \"b%* %l0%(\";
}"
d4680 1
a4680 1
  ""
d4728 48
d4801 1
a4801 1
  if (GET_CODE (XEXP (operands[0], 0)) == LABEL_REF)
d4810 7
a4816 9
      if (! TARGET_ARCH64 && INTVAL (operands[3]) != 0)
	emit_jump_insn
	  (gen_rtx (PARALLEL, VOIDmode,
		    gen_rtvec (3,
			       gen_rtx (SET, VOIDmode, pc_rtx,
					XEXP (operands[0], 0)),
			       GEN_INT (INTVAL (operands[3]) & 0xfff),
			       gen_rtx (CLOBBER, VOIDmode,
					gen_rtx (REG, Pmode, 15)))));
d4818 5
a4822 7
	emit_jump_insn
	  (gen_rtx (PARALLEL, VOIDmode,
		    gen_rtvec (2,
			       gen_rtx (SET, VOIDmode, pc_rtx,
					XEXP (operands[0], 0)),
			       gen_rtx (CLOBBER, VOIDmode,
					gen_rtx (REG, Pmode, 15)))));
d4833 1
a4833 1
    nregs_rtx = GEN_INT (REGNO (operands[2]) - 8);
d4835 1
a4835 1
    nregs_rtx = GEN_INT (6);
d4840 11
a4850 13
  if (! TARGET_ARCH64 && INTVAL (operands[3]) != 0)
    emit_call_insn
      (gen_rtx (PARALLEL, VOIDmode,
		gen_rtvec (3, gen_rtx (CALL, VOIDmode, fn_rtx, nregs_rtx),
			   GEN_INT (INTVAL (operands[3]) & 0xfff),
			   gen_rtx (CLOBBER, VOIDmode,
				    gen_rtx (REG, Pmode, 15)))));
  else
    emit_call_insn
      (gen_rtx (PARALLEL, VOIDmode,
		gen_rtvec (2, gen_rtx (CALL, VOIDmode, fn_rtx, nregs_rtx),
			   gen_rtx (CLOBBER, VOIDmode,
				    gen_rtx (REG, Pmode, 15)))));
d4856 1
a4856 1
  if (! TARGET_ARCH64 && INTVAL (operands[3]) > 0)
d4913 1
a4913 1
  "! TARGET_ARCH64 && GET_CODE (operands[2]) == CONST_INT && INTVAL (operands[2]) >= 0"
d4925 1
a4925 1
  "! TARGET_ARCH64 && GET_CODE (operands[2]) == CONST_INT && INTVAL (operands[2]) >= 0"
d4937 1
a4937 1
  "! TARGET_ARCH64 && GET_CODE (operands[2]) == CONST_INT && INTVAL (operands[2]) < 0"
d4948 1
a4948 1
  "! TARGET_ARCH64 && GET_CODE (operands[2]) == CONST_INT && INTVAL (operands[2]) < 0"
d5076 1
a5076 1
  rtx valreg2 = gen_rtx (REG, TARGET_ARCH64 ? TFmode : DFmode, 32);
d5079 1
a5079 1
  if (! TARGET_ARCH64)
d5096 1
a5096 1
		  change_address (result, TARGET_ARCH64 ? TFmode : DFmode,
d5115 1
a5115 1
  "! TARGET_ARCH64"
d5120 1
a5120 2
  [(return)
   (use (reg:SI 31))]
d5180 1
a5182 1
  emit_barrier ();
d5190 1
a5190 2
  ;; ??? Use TARGET_V9 instead?
  "* return TARGET_ARCH64 ? \"flushw\" : \"ta 3\";"
d5194 1
a5194 2
  [(unspec_volatile [(const_int 0)] 2)
   (use (reg:SI 8))]
a5199 30
;; Pattern for use after a setjmp to store FP and the return register
;; into the stack area.

(define_expand "setjmp"
  [(const_int 0)]
  ""
  "
{
  if (TARGET_ARCH64)
    emit_insn (gen_setjmp_64 ());
  else
    emit_insn (gen_setjmp_32 ());

  DONE;
}")

(define_expand "setjmp_32"
  [(set (mem:SI (plus:SI (reg:SI 14) (const_int 56))) (match_dup 0))
   (set (mem:SI (plus:SI (reg:SI 14) (const_int 60))) (reg:SI 31))]
  ""
  "
{ operands[0] = frame_pointer_rtx; }")

(define_expand "setjmp_64"
  [(set (mem:DI (plus:DI (reg:DI 14) (const_int 112))) (match_dup 0))
   (set (mem:DI (plus:DI (reg:DI 14) (const_int 120))) (reg:DI 31))]
  ""
  "
{ operands[0] = frame_pointer_rtx; }")

d5219 2
a5220 7
  "TARGET_SPARCLITE || TARGET_SPARCLET"
  "*
{
  if (TARGET_LIVE_G0)
    output_asm_insn (\"and %%g0,0,%%g0\", operands);
  return \"sub %%g0,%1,%0\;and %0,%1,%0\;scan %0,0,%0\;mov 32,%2\;sub %2,%0,%0\;sra %0,31,%2\;and %2,31,%2\;add %2,%0,%0\";
}"
d5231 2
a5232 2
  "TARGET_ARCH64"
  "neg %1,%2\;not %2,%2\;xor %1,%2,%2\;popc %2,%0\;movrz %1,0,%0"
d5320 1
a5320 1
;; LABEL_REFs are not modified by `legitimize_pic_address'
d5343 1
a5343 1
   (clobber (reg:CC 100))]
d5345 3
a5347 3
  [(set (reg:CC_NOOV 100) (compare:CC_NOOV (neg:SI (match_dup 1))
					   (const_int 0)))
   (set (match_dup 0) (ltu:SI (reg:CC 100) (const_int 0)))]
d5354 1
a5354 1
   (clobber (reg:CC 100))]
d5356 3
a5358 3
  [(set (reg:CC_NOOV 100) (compare:CC_NOOV (neg:SI (match_dup 1))
					   (const_int 0)))
   (set (match_dup 0) (neg:SI (ltu:SI (reg:CC 100) (const_int 0))))]
d5365 1
a5365 1
   (clobber (reg:CC 100))]
d5367 3
a5369 3
  [(set (reg:CC_NOOV 100) (compare:CC_NOOV (neg:SI (match_dup 1))
					   (const_int 0)))
   (set (match_dup 0) (geu:SI (reg:CC 100) (const_int 0)))]
d5376 1
a5376 1
   (clobber (reg:CC 100))]
d5378 3
a5380 3
  [(set (reg:CC_NOOV 100) (compare:CC_NOOV (neg:SI (match_dup 1))
					   (const_int 0)))
   (set (match_dup 0) (neg:SI (geu:SI (reg:CC 100) (const_int 0))))]
d5388 1
a5388 1
   (clobber (reg:CC 100))]
d5390 3
a5392 3
  [(set (reg:CC_NOOV 100) (compare:CC_NOOV (neg:SI (match_dup 1))
					   (const_int 0)))
   (set (match_dup 0) (plus:SI (ltu:SI (reg:CC 100) (const_int 0))
d5401 1
a5401 1
   (clobber (reg:CC 100))]
d5403 2
a5404 2
  [(set (reg:CC_NOOV 100) (compare:CC_NOOV (neg:SI (match_dup 1))
					   (const_int 0)))
d5406 1
a5406 1
				(ltu:SI (reg:CC 100) (const_int 0))))]
d5414 1
a5414 1
   (clobber (reg:CC 100))]
d5416 3
a5418 3
  [(set (reg:CC_NOOV 100) (compare:CC_NOOV (neg:SI (match_dup 1))
					   (const_int 0)))
   (set (match_dup 0) (plus:SI (geu:SI (reg:CC 100) (const_int 0))
d5427 1
a5427 1
   (clobber (reg:CC 100))]
d5429 2
a5430 2
  [(set (reg:CC_NOOV 100) (compare:CC_NOOV (neg:SI (match_dup 1))
					   (const_int 0)))
d5432 1
a5432 1
				(geu:SI (reg:CC 100) (const_int 0))))]
d5446 1
a5446 1
  "! TARGET_ARCH64
d5457 1
a5457 1
  "! TARGET_ARCH64
d5468 1
a5468 1
  "! TARGET_ARCH64
d5479 1
a5479 1
  "! TARGET_ARCH64
d5490 1
a5490 1
  "! TARGET_ARCH64
d5501 1
a5501 1
  "! TARGET_ARCH64
d5512 1
a5512 1
  "! TARGET_ARCH64
d5523 1
a5523 1
  "! TARGET_ARCH64
d5536 1
a5536 1
   (set (reg:CC 100)
d5542 1
a5542 1
  "orcc %1,0,%0")
d5547 1
a5547 1
   (set (reg:CCX 100)
d5550 1
a5550 1
  "TARGET_ARCH64
d5554 1
a5554 1
  "orcc %1,0,%0")
d5565 1
a5565 1
   (set (reg:CC 100)
d5569 1
a5569 1
  "ldsh %1,%0\;orcc %0,0,%2")
d5576 1
a5576 1
   (set (reg:CCX 100)
d5579 2
a5580 2
  "TARGET_ARCH64"
  "ldsh %1,%0\;orcc %0,0,%2")
d5587 1
a5587 1
   (set (reg:CC 100)
d5591 1
a5591 1
  "ldsb %1,%0\;orcc %0,0,%2")
d5598 1
a5598 1
   (set (reg:CCX 100)
d5601 2
a5602 2
  "TARGET_ARCH64"
  "ldsb %1,%0\;orcc %0,0,%2")
d5633 4
a5636 2
;; Return peepholes.  First the "normal" ones.
;; These are necessary to catch insns ending up in the epilogue delay list.
d5642 1
a5642 1
  "! TARGET_EPILOGUE && ! TARGET_LIVE_G0"
d5645 1
a5645 1
  if (! TARGET_ARCH64 && current_function_returns_struct)
d5656 1
a5656 1
  "! TARGET_EPILOGUE && ! TARGET_LIVE_G0"
d5659 1
a5659 1
  if (! TARGET_ARCH64 && current_function_returns_struct)
d5670 1
a5670 1
  "! TARGET_EPILOGUE && ! TARGET_LIVE_G0"
d5673 1
a5673 1
  if (! TARGET_ARCH64 && current_function_returns_struct)
d5687 1
a5687 1
  "! TARGET_FPU && ! TARGET_EPILOGUE && ! TARGET_LIVE_G0"
d5690 1
a5690 1
  if (! TARGET_ARCH64 && current_function_returns_struct)
d5702 1
a5702 3
  "! TARGET_EPILOGUE && ! TARGET_LIVE_G0
   && (register_operand (operands[1], SImode)
       || register_operand (operands[2], SImode))"
d5705 1
a5705 1
  if (! TARGET_ARCH64 && current_function_returns_struct)
d5716 1
a5716 1
  "TARGET_ARCH64 && ! TARGET_EPILOGUE"
d5722 1
a5722 1
	(plus:DI (match_operand:DI 1 "arith_double_operand" "%r")
d5725 1
a5725 3
  "TARGET_ARCH64 && ! TARGET_EPILOGUE
   && (register_operand (operands[1], DImode)
       || register_operand (operands[2], DImode))"
d5729 11
a5739 8
(define_insn "*return_subsi"
  [(set (match_operand:SI 0 "restore_operand" "")
	(minus:SI (match_operand:SI 1 "register_operand" "r")
		  (match_operand:SI 2 "small_int" "I")))
   (return)]
  "! TARGET_EPILOGUE && INTVAL (operands[2]) != -4096"
  "ret\;restore %1,%n2,%Y0"
  [(set_attr "type" "multi")])
d5779 1
a5779 1
  "TARGET_ARCH64 && short_branch (INSN_UID (insn), INSN_UID (operands[3]))"
d5787 1
a5787 1
  "TARGET_ARCH64 && short_branch (INSN_UID (insn), INSN_UID (operands[2]))"
a5791 1
;; (reg:SI 100) is created by the {add,neg,sub}di patterns.
d5795 3
a5797 3
			     (reg:SI 100)))
	      (clobber (reg:CC 100))])
   (set (reg:CC 100) (compare (match_dup 0) (const_int 0)))]
a5799 9

;; After a nonlocal goto, we need to restore the PIC register, but only
;; if we need it.  So do nothing much here, but we'll check for this in
;; finalize_pic.

(define_insn "nonlocal_goto_receiver"
  [(unspec_volatile [(const_int 0)] 4)]
  "flag_pic"
  "")
@

