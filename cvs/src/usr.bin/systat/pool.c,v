head	1.12;
access;
symbols
	OPENBSD_6_1:1.11.0.6
	OPENBSD_6_1_BASE:1.11
	OPENBSD_6_0:1.11.0.2
	OPENBSD_6_0_BASE:1.11
	OPENBSD_5_9:1.10.0.4
	OPENBSD_5_9_BASE:1.10
	OPENBSD_5_8:1.10.0.6
	OPENBSD_5_8_BASE:1.10
	OPENBSD_5_7:1.10.0.2
	OPENBSD_5_7_BASE:1.10
	OPENBSD_5_6:1.7.0.4
	OPENBSD_5_6_BASE:1.7
	OPENBSD_5_5:1.6.0.14
	OPENBSD_5_5_BASE:1.6
	OPENBSD_5_4:1.6.0.10
	OPENBSD_5_4_BASE:1.6
	OPENBSD_5_3:1.6.0.8
	OPENBSD_5_3_BASE:1.6
	OPENBSD_5_2:1.6.0.6
	OPENBSD_5_2_BASE:1.6
	OPENBSD_5_1_BASE:1.6
	OPENBSD_5_1:1.6.0.4
	OPENBSD_5_0:1.6.0.2
	OPENBSD_5_0_BASE:1.6
	OPENBSD_4_9:1.5.0.10
	OPENBSD_4_9_BASE:1.5
	OPENBSD_4_8:1.5.0.8
	OPENBSD_4_8_BASE:1.5
	OPENBSD_4_7:1.5.0.4
	OPENBSD_4_7_BASE:1.5
	OPENBSD_4_6:1.5.0.6
	OPENBSD_4_6_BASE:1.5
	OPENBSD_4_5:1.5.0.2
	OPENBSD_4_5_BASE:1.5;
locks; strict;
comment	@ * @;


1.12
date	2017.06.15.03.47.07;	author dlg;	state Exp;
branches;
next	1.11;
commitid	apYgCKWAUNLyOs4i;

1.11
date	2016.03.12.12.45.27;	author sthen;	state Exp;
branches;
next	1.10;
commitid	Ipk6iXXruFGtRHYt;

1.10
date	2015.01.16.00.03.37;	author deraadt;	state Exp;
branches;
next	1.9;
commitid	waQzIVMqUqjBDjYt;

1.9
date	2014.10.08.04.10.04;	author doug;	state Exp;
branches;
next	1.8;
commitid	cpW0LtZf9XzHlFrl;

1.8
date	2014.08.14.08.10.30;	author mpi;	state Exp;
branches;
next	1.7;
commitid	P2Yi9etIKcIRvYPW;

1.7
date	2014.07.02.00.12.34;	author dlg;	state Exp;
branches;
next	1.6;
commitid	zNbAzxmEBZMksTSx;

1.6
date	2011.03.02.06.48.17;	author jasper;	state Exp;
branches;
next	1.5;

1.5
date	2008.12.31.05.37.24;	author canacar;	state Exp;
branches;
next	1.4;

1.4
date	2008.12.07.07.46.05;	author canacar;	state Exp;
branches;
next	1.3;

1.3
date	2008.11.05.16.03.02;	author chl;	state Exp;
branches;
next	1.2;

1.2
date	2008.11.02.07.14.16;	author canacar;	state Exp;
branches;
next	1.1;

1.1
date	2008.11.02.06.23.28;	author canacar;	state Exp;
branches;
next	;


desc
@@


1.12
log
@add a rough start to a pcache view, to show pool cpu cache info.

ok mikeb@@ millert@@
@
text
@/*	$OpenBSD: pool.c,v 1.11 2016/03/12 12:45:27 sthen Exp $	*/
/*
 * Copyright (c) 2008 Can Erkin Acar <canacar@@openbsd.org>
 *
 * Permission to use, copy, modify, and distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 */

#include <sys/types.h>
#include <sys/signal.h>
#include <sys/sysctl.h>
#include <sys/pool.h>
#include <errno.h>
#include <stdlib.h>
#include <string.h>
#include <limits.h>

#include "systat.h"

#ifndef nitems
#define nitems(_a) (sizeof((_a)) / sizeof((_a)[0]))
#endif

static int sysctl_rdint(const int *, unsigned int);
static int hw_ncpusfound(void);

static int pool_get_npools(void);
static int pool_get_name(int, char *, size_t);
static int pool_get_cache(int, struct kinfo_pool_cache *);
static int pool_get_cache_cpus(int, struct kinfo_pool_cache_cpu *,
    unsigned int);

void print_pool(void);
int  read_pool(void);
void  sort_pool(void);
int  select_pool(void);
void showpool(int k);
int pool_keyboard_callback(int);

/* qsort callbacks */
int sort_name_callback(const void *s1, const void *s2);
int sort_req_callback(const void *s1, const void *s2);
int sort_psize_callback(const void *s1, const void *s2);
int sort_npage_callback(const void *s1, const void *s2);

struct pool_info {
	char name[32];
	struct kinfo_pool pool;
};

/*
 * the kernel gives an array of ncpusfound * kinfo_pool_cache structs, but
 * it's idea of how big that struct is may differ from here. we fetch both
 * ncpusfound and the size it thinks kinfo_pool_cache is from sysctl, and
 * then allocate the memory for this here.
 */
struct pool_cache_info {
	char name[32];
	struct kinfo_pool_cache cache;
	struct kinfo_pool_cache_cpu *cache_cpus;
};

int print_all = 0;
int num_pools = 0;
struct pool_info *pools = NULL;
int num_pool_caches = 0;
struct pool_cache_info *pool_caches = NULL;

int ncpusfound = 0;

field_def fields_pool[] = {
	{"NAME", 12, 32, 1, FLD_ALIGN_LEFT, -1, 0, 0, 0},
	{"SIZE", 8, 24, 1, FLD_ALIGN_RIGHT, -1, 0, 0, 0},
	{"REQUESTS", 8, 24, 1, FLD_ALIGN_RIGHT, -1, 0, 0, 0},
	{"FAIL", 8, 24, 1, FLD_ALIGN_RIGHT, -1, 0, 0, 0},
	{"INUSE", 8, 24, 1, FLD_ALIGN_RIGHT, -1, 0, 0, 0},
	{"PGREQ", 8, 24, 1, FLD_ALIGN_RIGHT, -1, 0, 0, 0},
	{"PGREL", 8, 24, 1, FLD_ALIGN_RIGHT, -1, 0, 0, 0},
	{"NPAGE", 8, 24, 1, FLD_ALIGN_RIGHT, -1, 0, 0, 0},
	{"HIWAT", 8, 24, 1, FLD_ALIGN_RIGHT, -1, 0, 0, 0},
	{"MINPG", 8, 24, 1, FLD_ALIGN_RIGHT, -1, 0, 0, 0},
	{"MAXPG", 8, 24, 1, FLD_ALIGN_RIGHT, -1, 0, 0, 0},
	{"IDLE", 8, 24, 1, FLD_ALIGN_RIGHT, -1, 0, 0, 0}
};

#define FLD_POOL_NAME	FIELD_ADDR(fields_pool,0)
#define FLD_POOL_SIZE	FIELD_ADDR(fields_pool,1)
#define FLD_POOL_REQS	FIELD_ADDR(fields_pool,2)
#define FLD_POOL_FAIL	FIELD_ADDR(fields_pool,3)
#define FLD_POOL_INUSE	FIELD_ADDR(fields_pool,4)
#define FLD_POOL_PGREQ	FIELD_ADDR(fields_pool,5)
#define FLD_POOL_PGREL	FIELD_ADDR(fields_pool,6)
#define FLD_POOL_NPAGE	FIELD_ADDR(fields_pool,7)
#define FLD_POOL_HIWAT	FIELD_ADDR(fields_pool,8)
#define FLD_POOL_MINPG	FIELD_ADDR(fields_pool,9)
#define FLD_POOL_MAXPG	FIELD_ADDR(fields_pool,10)
#define FLD_POOL_IDLE	FIELD_ADDR(fields_pool,11)

/* Define views */
field_def *view_pool_0[] = {
	FLD_POOL_NAME, FLD_POOL_SIZE, FLD_POOL_REQS, FLD_POOL_FAIL,
	FLD_POOL_INUSE, FLD_POOL_PGREQ, FLD_POOL_PGREL, FLD_POOL_NPAGE,
	FLD_POOL_HIWAT, FLD_POOL_MINPG, FLD_POOL_MAXPG, FLD_POOL_IDLE, NULL
};

order_type pool_order_list[] = {
	{"name", "name", 'N', sort_name_callback},
	{"requests", "requests", 'Q', sort_req_callback},
	{"size", "size", 'Z', sort_psize_callback},
	{"npages", "npages", 'P', sort_npage_callback},
	{NULL, NULL, 0, NULL}
};

/* Define view managers */
struct view_manager pool_mgr = {
	"Pool", select_pool, read_pool, sort_pool, print_header,
	print_pool, pool_keyboard_callback, pool_order_list, pool_order_list
};

field_view pool_view = {
	view_pool_0,
	"pool",
	'5',
	&pool_mgr
};

void	pool_cache_print(void);
int	pool_cache_read(void);
void	pool_cache_sort(void);
void	pool_cache_show(const struct pool_cache_info *);
int	pool_cache_kbd_cb(int);

field_def pool_cache_fields[] = {
	{"NAME", 12, 32, 1, FLD_ALIGN_LEFT, -1, 0, 0, 0},
	{"LEN", 4, 4, 1, FLD_ALIGN_RIGHT, -1, 0, 0, 0},
	{"NL", 4, 4, 1, FLD_ALIGN_RIGHT, -1, 0, 0, 0},
	{"NGC", 4, 4, 1, FLD_ALIGN_RIGHT, -1, 0, 0, 0},
	{"CPU",  4, 4, 1, FLD_ALIGN_RIGHT, -1, 0, 0, 0},
	{"REQ", 8, 12, 1, FLD_ALIGN_RIGHT, -1, 0, 0, 0},
	{"REL", 8, 12, 1, FLD_ALIGN_RIGHT, -1, 0, 0, 0},
	{"LREQ", 8, 12, 1, FLD_ALIGN_RIGHT, -1, 0, 0, 0},
	{"LREL", 8, 12, 1, FLD_ALIGN_RIGHT, -1, 0, 0, 0},
};

#define FLD_POOL_CACHE_NAME	FIELD_ADDR(pool_cache_fields, 0)
#define FLD_POOL_CACHE_LEN	FIELD_ADDR(pool_cache_fields, 1)
#define FLD_POOL_CACHE_NL	FIELD_ADDR(pool_cache_fields, 2)
#define FLD_POOL_CACHE_NGC	FIELD_ADDR(pool_cache_fields, 3)
#define FLD_POOL_CACHE_CPU	FIELD_ADDR(pool_cache_fields, 4)
#define FLD_POOL_CACHE_GET	FIELD_ADDR(pool_cache_fields, 5)
#define FLD_POOL_CACHE_PUT	FIELD_ADDR(pool_cache_fields, 6)
#define FLD_POOL_CACHE_LGET	FIELD_ADDR(pool_cache_fields, 7)
#define FLD_POOL_CACHE_LPUT	FIELD_ADDR(pool_cache_fields, 8)

field_def *view_pool_cache_0[] = {
	FLD_POOL_CACHE_NAME,
	FLD_POOL_CACHE_LEN,
	FLD_POOL_CACHE_NL,
	FLD_POOL_CACHE_NGC,
	FLD_POOL_CACHE_CPU,
	FLD_POOL_CACHE_GET,
	FLD_POOL_CACHE_PUT,
	FLD_POOL_CACHE_LGET,
	FLD_POOL_CACHE_LPUT,
	NULL,
};

order_type pool_cache_order_list[] = {
	{"name", "name", 'N', sort_name_callback},
	{"requests", "requests", 'G', sort_req_callback},
	{"releases", "releases", 'P', sort_req_callback},
	{NULL, NULL, 0, NULL}
};

/* Define view managers */
struct view_manager pool_cache_mgr = {
	"PoolCache",
	select_pool,
	pool_cache_read,
	pool_cache_sort,
	print_header,
	pool_cache_print,
	pool_keyboard_callback,
	pool_cache_order_list,
	pool_cache_order_list
};

field_view pool_cache_view = {
	view_pool_cache_0,
	"pcaches",
	'5',
	&pool_cache_mgr
};

int
sort_name_callback(const void *s1, const void *s2)
{
	struct pool_info *p1, *p2;
	p1 = (struct pool_info *)s1;
	p2 = (struct pool_info *)s2;

	return strcmp(p1->name, p2->name) * sortdir;
}

int
sort_req_callback(const void *s1, const void *s2)
{
	struct pool_info *p1, *p2;
	p1 = (struct pool_info *)s1;
	p2 = (struct pool_info *)s2;

	if (p1->pool.pr_nget <  p2->pool.pr_nget)
		return sortdir;
	if (p1->pool.pr_nget >  p2->pool.pr_nget)
		return -sortdir;

	return sort_name_callback(s1, s2);
}

int
sort_npage_callback(const void *s1, const void *s2)
{
	struct pool_info *p1, *p2;
	p1 = (struct pool_info *)s1;
	p2 = (struct pool_info *)s2;

	if (p1->pool.pr_npages <  p2->pool.pr_npages)
		return sortdir;
	if (p1->pool.pr_npages >  p2->pool.pr_npages)
		return -sortdir;

	return sort_name_callback(s1, s2);
}

int
sort_psize_callback(const void *s1, const void *s2)
{
	struct pool_info *p1, *p2;
	size_t ps1, ps2;

	p1 = (struct pool_info *)s1;
	p2 = (struct pool_info *)s2;

	ps1  = (size_t)(p1->pool.pr_nget - p1->pool.pr_nput) *
	    (size_t)p1->pool.pr_size;
	ps2  = (size_t)(p2->pool.pr_nget - p2->pool.pr_nput) *
	    (size_t)p2->pool.pr_size;

	if (ps1 <  ps2)
		return sortdir;
	if (ps1 >  ps2)
		return -sortdir;

	return sort_npage_callback(s1, s2);
}

void
sort_pool(void)
{
	order_type *ordering;

	if (curr_mgr == NULL)
		return;

	ordering = curr_mgr->order_curr;

	if (ordering == NULL)
		return;
	if (ordering->func == NULL)
		return;
	if (pools == NULL)
		return;
	if (num_pools <= 0)
		return;

	mergesort(pools, num_pools, sizeof(struct pool_info), ordering->func);
}

int
select_pool(void)
{
	num_disp = num_pools;
	return (0);
}

int
read_pool(void)
{
	int mib[] = { CTL_KERN, KERN_POOL, KERN_POOL_POOL, 0 };
	struct pool_info *p;
	int np, i;
	size_t size;

	np = pool_get_npools();
	if (np == -1) {
		error("sysctl(npools): %s", strerror(errno));
		return (-1);
	}

	if (np == 0) {
		free(pools);
		pools = NULL;
		num_pools = 0;
		return (0);
	}

	if (np > num_pools || pools == NULL) {
		p = reallocarray(pools, np, sizeof(*pools));
		if (p == NULL) {
			error("realloc: %s", strerror(errno));
			return (-1);
		}
		/* commit */
		pools = p;
		num_pools = np;
	}

	num_disp = num_pools;

	for (i = 0; i < num_pools; i++) {
		p = &pools[i];
		np = i + 1;

		mib[3] = np;
		size = sizeof(pools[i].pool);
		if (sysctl(mib, nitems(mib), &p->pool, &size, NULL, 0) < 0) {
			p->name[0] = '\0';
			num_disp--;
			continue;
		}

		if (pool_get_name(np, p->name, sizeof(p->name)) < 0)
			snprintf(p->name, sizeof(p->name), "#%d#", i + 1);
	}

	return 0;
}


void
print_pool(void)
{
	struct pool_info *p;
	int i, n, count = 0;

	if (pools == NULL)
		return;

	for (n = i = 0; i < num_pools; i++) {
		p = &pools[i];
		if (p->name[0] == 0)
			continue;

		if (!print_all &&
		   (p->pool.pr_nget == 0 && p->pool.pr_npagealloc == 0))
			continue;

		if (n++ < dispstart)
			continue;
		showpool(i);
		count++;
		if (maxprint > 0 && count >= maxprint)
			break;
	}
}

int
initpool(void)
{
	field_view *v;

	add_view(&pool_view);
	read_pool();

	ncpusfound = hw_ncpusfound();
	if (ncpusfound == -1) {
		error("sysctl(ncpusfound): %s", strerror(errno));
		exit(1);
	}

	add_view(&pool_cache_view);
	pool_cache_read();

	return(0);
}

void
showpool(int k)
{
	struct pool_info *p = pools + k;

	if (k < 0 || k >= num_pools)
		return;

	print_fld_str(FLD_POOL_NAME, p->name);
	print_fld_uint(FLD_POOL_SIZE, p->pool.pr_size);

	print_fld_size(FLD_POOL_REQS, p->pool.pr_nget);
	print_fld_size(FLD_POOL_FAIL, p->pool.pr_nfail);
	print_fld_ssize(FLD_POOL_INUSE, p->pool.pr_nget - p->pool.pr_nput);
	print_fld_size(FLD_POOL_PGREQ, p->pool.pr_npagealloc);
	print_fld_size(FLD_POOL_PGREL, p->pool.pr_npagefree);

	print_fld_size(FLD_POOL_NPAGE, p->pool.pr_npages);
	print_fld_size(FLD_POOL_HIWAT, p->pool.pr_hiwat);
	print_fld_size(FLD_POOL_MINPG, p->pool.pr_minpages);

	if (p->pool.pr_maxpages == UINT_MAX)
		print_fld_str(FLD_POOL_MAXPG, "inf");
	else
		print_fld_size(FLD_POOL_MAXPG, p->pool.pr_maxpages);

	print_fld_size(FLD_POOL_IDLE, p->pool.pr_nidle);

	end_line();
}

int
pool_keyboard_callback(int ch)
{
	switch (ch) {
	case 'A':
		print_all ^= 1;
		gotsig_alarm = 1;
	default:
		return keyboard_callback(ch);
	};

	return (1);
}

int
pool_cache_read(void)
{
	struct pool_cache_info *pc;
	int np, i;

	np = pool_get_npools();
	if (np == -1) {
		error("sysctl(npools): %s", strerror(errno));
		return (-1);
	}

	if (np > num_pool_caches) {
		pc = reallocarray(pool_caches, np, sizeof(*pc));
		if (pc == NULL) {
			error("realloc: %s", strerror(errno));
			return (-1);
		}
		/* commit to using the new memory */
		pool_caches = pc;

		for (i = num_pool_caches; i < np; i++) {
			pc = &pool_caches[i];
			pc->name[0] = '\0';

			pc->cache_cpus = reallocarray(NULL, ncpusfound,
			    sizeof(*pc->cache_cpus));
			if (pc->cache_cpus == NULL) {
				error("malloc cache cpus: %s", strerror(errno));
				goto unalloc;
			}
		}

		/* commit to using the new cache_infos */
		num_pool_caches = np;
	}

	for (i = 0; i < num_pool_caches; i++) {
		pc = &pool_caches[i];
		np = i + 1;

		if (pool_get_cache(np, &pc->cache) < 0 ||
		    pool_get_cache_cpus(np, pc->cache_cpus, ncpusfound) < 0) {
			pc->name[0] = '\0';
			continue;
		}

		if (pool_get_name(np, pc->name, sizeof(pc->name)) < 0)
			snprintf(pc->name, sizeof(pc->name), "#%d#", i + 1);
	}

	return 0;

unalloc:
	while (i > num_pool_caches) {
		pc = &pool_caches[--i];
		free(pc->cache_cpus);
	}
}

void
pool_cache_sort(void)
{
	/* XXX */
	order_type *ordering;

	if (curr_mgr == NULL)
		return;

	ordering = curr_mgr->order_curr;

	if (ordering == NULL)
		return;
	if (ordering->func == NULL)
		return;
	if (pools == NULL)
		return;
	if (num_pools <= 0)
		return;

	mergesort(pools, num_pools, sizeof(struct pool_info), ordering->func);
}

void
pool_cache_print(void)
{
	struct pool_cache_info *pc;
	int i, n, count = 0;

	if (pool_caches == NULL)
		return;

	for (n = i = 0; i < num_pool_caches; i++) {
		pc = &pool_caches[i];
		if (pc->name[0] == '\0')
			continue;

		if (n++ < dispstart)
			continue;

		pool_cache_show(pc);
		count++;
		if (maxprint > 0 && count >= maxprint)
			break;
	}
}

void
pool_cache_show(const struct pool_cache_info *pc)
{
	const struct kinfo_pool_cache *kpc;
	const struct kinfo_pool_cache_cpu *kpcc;
	int cpu;

	kpc = &pc->cache;

	print_fld_str(FLD_POOL_CACHE_NAME, pc->name);
	print_fld_uint(FLD_POOL_CACHE_LEN, kpc->pr_len);
	print_fld_uint(FLD_POOL_CACHE_NL, kpc->pr_nlist);
	print_fld_uint(FLD_POOL_CACHE_NGC, kpc->pr_ngc);

	for (cpu = 0; cpu < ncpusfound; cpu++) {
		kpcc = &pc->cache_cpus[cpu];

		print_fld_uint(FLD_POOL_CACHE_CPU, kpcc->pr_cpu);

		print_fld_size(FLD_POOL_CACHE_GET, kpcc->pr_nget);
		print_fld_size(FLD_POOL_CACHE_PUT, kpcc->pr_nput);
		print_fld_size(FLD_POOL_CACHE_LGET, kpcc->pr_nlget);
		print_fld_size(FLD_POOL_CACHE_LPUT, kpcc->pr_nlput);
		end_line();
	}

}

static int
pool_get_npools(void)
{
	int mib[] = { CTL_KERN, KERN_POOL, KERN_POOL_NPOOLS };

	return (sysctl_rdint(mib, nitems(mib)));
}

static int
pool_get_cache(int pool, struct kinfo_pool_cache *kpc)
{
	int mib[] = { CTL_KERN, KERN_POOL, KERN_POOL_CACHE, pool };
	size_t len = sizeof(*kpc);

	return (sysctl(mib, nitems(mib), kpc, &len, NULL, 0));
}

static int
pool_get_cache_cpus(int pool, struct kinfo_pool_cache_cpu *kpcc,
    unsigned int ncpus)
{
	int mib[] = { CTL_KERN, KERN_POOL, KERN_POOL_CACHE_CPUS, pool };
	size_t len = sizeof(*kpcc) * ncpus;

	return (sysctl(mib, nitems(mib), kpcc, &len, NULL, 0));
}

static int
pool_get_name(int pool, char *name, size_t len)
{
	int mib[] = { CTL_KERN, KERN_POOL, KERN_POOL_NAME, pool };

	return (sysctl(mib, nitems(mib), name, &len, NULL, 0));
}

static int
hw_ncpusfound(void)
{
	int mib[] = { CTL_HW, HW_NCPUFOUND };

	return (sysctl_rdint(mib, nitems(mib)));
}

static int
sysctl_rdint(const int *mib, unsigned int nmib)
{
	int i;
	size_t size = sizeof(i);

	if (sysctl(mib, nmib, &i, &size, NULL, 0) == -1)
		return (-1);

	return (i);
}
@


1.11
log
@Use 12 chars for pool name in "systat pool" to match vmstat -m.  ok stefan@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pool.c,v 1.10 2015/01/16 00:03:37 deraadt Exp $	*/
d29 13
d60 11
d75 2
d78 1
a94 1

d129 52
a180 2
field_view views_pool[] = {
	{view_pool_0, "pool", '5', &pool_mgr},
d184 19
d298 3
a300 1
	int mib[4], np, i;
d303 2
a304 6
	mib[0] = CTL_KERN;
	mib[1] = KERN_POOL;
	mib[2] = KERN_POOL_NPOOLS;
	size = sizeof(np);

	if (sysctl(mib, 3, &np, &size, NULL, 0) < 0) {
d309 3
a311 1
	if (np <= 0) {
d317 1
a317 1
		struct pool_info *p = reallocarray(pools, np, sizeof(*pools));
d322 1
d330 4
a333 4
		mib[0] = CTL_KERN;
		mib[1] = KERN_POOL;
		mib[2] = KERN_POOL_POOL;
		mib[3] = i + 1;
d335 2
a336 2
		if (sysctl(mib, 4, &pools[i].pool, &size, NULL, 0) < 0) {
			memset(&pools[i], 0, sizeof(pools[i]));
a339 6
		mib[2] = KERN_POOL_NAME;
		size = sizeof(pools[i].name);
		if (sysctl(mib, 4, &pools[i].name, &size, NULL, 0) < 0) {
			snprintf(pools[i].name, size, "#%d#", mib[3]);
		}
	}
d341 2
a342 3
	if (i != num_pools) {
		memset(pools, 0, sizeof(*pools) * num_pools);
		return (-1);
d381 8
a388 2
	for (v = views_pool; v->name != NULL; v++)
		add_view(v);
d390 2
a391 1
	read_pool();
d439 190
@


1.10
log
@first batch of programs adapting to the namespace cleanup
(pfvar.h nameser.h proc.h ucred.h)
ok guenther millert, and some review from doug as well.
@
text
@d1 1
a1 1
/*	$OpenBSD: pool.c,v 1.9 2014/10/08 04:10:04 doug Exp $	*/
d54 1
a54 1
	{"NAME", 11, 32, 1, FLD_ALIGN_LEFT, -1, 0, 0, 0},
@


1.9
log
@userland reallocarray audit.

Replace malloc() and realloc() calls that may have integer overflow in the
multiplication of the size argument with reallocarray().

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pool.c,v 1.8 2014/08/14 08:10:30 mpi Exp $	*/
d19 1
a19 1
#include <sys/param.h>
d25 1
@


1.8
log
@Show only active pools by default, pressing 'A' shows all of them.

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pool.c,v 1.7 2014/07/02 00:12:34 dlg Exp $	*/
d221 1
a221 1
		struct pool_info *p = realloc(pools, sizeof(*pools) * np);
@


1.7
log
@info about pools is currently given to userland by copying each
pools struct out. however, struct pool in the kernel contains lots
of things that userland probably isnt interested in, like actual
mutexes, and probably shouldnt get easy access to, like pointers
to kernel memory via all the lists/trees.

this implements a kinfo_pool structure that has only the data that
userland needs to know about. it cuts the sysctl code over to
building it from struct pool as required and copying that out
instead, and cuts userland over to only handling kinfo_pool.

the only problem with this is vmstat, which can read kernel images
via kvm, which needs some understanding of struct pool. to cope,
the struct pool definition is guarded by if defined(_KERNEL) ||
defined(_LIBKVM) as inspired by sysctl which needs to do the same
thing sometimes. struct pool itself is generally not visible to
userland though, which is good.

matthew@@ suggested struct kinfo_pool instead of struct pool_info.
the kinfo prefix has precedent.
lots of people liked this.
@
text
@d1 1
a1 1
/*	$OpenBSD: pool.c,v 1.6 2011/03/02 06:48:17 jasper Exp $	*/
d33 1
d47 1
d99 1
a99 1
	print_pool, keyboard_callback, pool_order_list, pool_order_list
d262 1
d269 2
a270 1
		if (pools[i].name[0] == 0)
d272 5
d328 14
@


1.6
log
@- use a common FIELD_ADDR macro, instead of rolling 78 identical copies.

ok canacar@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pool.c,v 1.5 2008/12/31 05:37:24 canacar Exp $	*/
d42 1
a42 1
	struct pool pool;
d235 1
a235 1
		size = sizeof(struct pool);
@


1.5
log
@Skip missing pool indices instead of printing errors.
@
text
@d1 1
a1 1
/*	$OpenBSD: pool.c,v 1.4 2008/12/07 07:46:05 canacar Exp $	*/
d66 12
a77 14
#define FIELD_ADDR(x) (&fields_pool[x])

#define FLD_POOL_NAME	FIELD_ADDR(0)
#define FLD_POOL_SIZE	FIELD_ADDR(1)
#define FLD_POOL_REQS	FIELD_ADDR(2)
#define FLD_POOL_FAIL	FIELD_ADDR(3)
#define FLD_POOL_INUSE	FIELD_ADDR(4)
#define FLD_POOL_PGREQ	FIELD_ADDR(5)
#define FLD_POOL_PGREL	FIELD_ADDR(6)
#define FLD_POOL_NPAGE	FIELD_ADDR(7)
#define FLD_POOL_HIWAT	FIELD_ADDR(8)
#define FLD_POOL_MINPG	FIELD_ADDR(9)
#define FLD_POOL_MAXPG	FIELD_ADDR(10)
#define FLD_POOL_IDLE	FIELD_ADDR(11)
@


1.4
log
@Add option to order the pool view by size and number of pages columns.
@
text
@d1 1
a1 1
/*	$OpenBSD: pool.c,v 1.3 2008/11/05 16:03:02 chl Exp $	*/
d230 2
d239 3
a241 2
			error("sysctl(pool): %s", strerror(errno));
			break;
d246 1
a246 2
			error("sysctl(pool_name): %s", strerror(errno));
			break;
d262 1
a262 1
	int n, count = 0;
d267 6
a272 2
	for (n = dispstart; n < num_disp; n++) {
		showpool(n);
@


1.3
log
@add missing header needed by strcmp/strerror/memset functions.

ok canacar@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pool.c,v 1.2 2008/11/02 07:14:16 canacar Exp $	*/
d37 2
d91 2
d131 37
@


1.2
log
@Add the option to sort by requests to the pool view, and document
the hotkeys 'o' to select and 'r' to reverse column orderings.
@
text
@d1 1
a1 1
/*	$OpenBSD: pool.c,v 1.1 2008/11/02 06:23:28 canacar Exp $	*/
d24 1
@


1.1
log
@Add a view that displays pool(9) information. Idea and ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d35 1
d86 2
a87 1
	{"name", "name", 0, sort_name_callback},
d110 16
a125 1
	return strcmp(p1->name, p2->name);
d147 1
a147 1
	qsort(pools, num_pools, sizeof(struct pool_info), ordering->func);
@

