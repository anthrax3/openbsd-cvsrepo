head	1.12;
access;
symbols
	OPENBSD_6_0:1.11.0.10
	OPENBSD_6_0_BASE:1.11
	OPENBSD_5_9:1.11.0.2
	OPENBSD_5_9_BASE:1.11
	OPENBSD_5_8:1.11.0.8
	OPENBSD_5_8_BASE:1.11
	OPENBSD_5_7:1.11.0.6
	OPENBSD_5_7_BASE:1.11
	OPENBSD_5_6:1.11.0.4
	OPENBSD_5_6_BASE:1.11
	butholakala:1.6
	openssl_1_0_1_g:1.1.1.4
	OPENSSL:1.1.1
	OPENBSD_5_5:1.5.0.8
	OPENBSD_5_5_BASE:1.5
	OPENBSD_5_4:1.5.0.4
	OPENBSD_5_4_BASE:1.5
	OPENBSD_5_3:1.5.0.2
	OPENBSD_5_3_BASE:1.5
	openssl_1_0_1_c:1.1.1.3
	OPENBSD_5_2:1.3.0.6
	OPENBSD_5_2_BASE:1.3
	OPENBSD_5_1_BASE:1.3
	OPENBSD_5_1:1.3.0.8
	openssl_1_0_0_f:1.1.1.2
	openssl_1_0_0_e:1.1.1.2
	OPENBSD_5_0:1.3.0.4
	OPENBSD_5_0_BASE:1.3
	OPENBSD_4_9:1.3.0.2
	OPENBSD_4_9_BASE:1.3
	openssh_1_0_0_a:1.1.1.2
	OPENBSD_4_8:1.2.0.8
	OPENBSD_4_8_BASE:1.2
	OPENBSD_4_7:1.2.0.4
	OPENBSD_4_7_BASE:1.2
	OPENBSD_4_6:1.2.0.6
	OPENBSD_4_6_BASE:1.2
	openssl_0_9_8_k:1.1.1.1
	OPENBSD_4_5:1.2.0.2
	OPENBSD_4_5_BASE:1.2
	openssl_0_9_8_j:1.1.1.1
	openssl_0_9_8_h:1.1.1.1
	openssl:1.1.1;
locks; strict;
comment	@# @;


1.12
date	2016.09.03.11.33.34;	author beck;	state dead;
branches;
next	1.11;
commitid	HnbXxsegngek41U2;

1.11
date	2014.06.02.15.08.37;	author deraadt;	state Exp;
branches;
next	1.10;
commitid	tWDKJg0nrCJLQhsu;

1.10
date	2014.04.24.01.04.52;	author tedu;	state Exp;
branches;
next	1.9;

1.9
date	2014.04.23.21.53.18;	author miod;	state Exp;
branches;
next	1.8;

1.8
date	2014.04.17.18.49.35;	author miod;	state Exp;
branches;
next	1.7;

1.7
date	2014.04.17.18.16.45;	author miod;	state Exp;
branches;
next	1.6;

1.6
date	2014.04.13.15.25.29;	author miod;	state Exp;
branches;
next	1.5;

1.5
date	2012.10.31.11.19.35;	author kettenis;	state Exp;
branches;
next	1.4;

1.4
date	2012.10.13.21.25.12;	author djm;	state Exp;
branches;
next	1.3;

1.3
date	2010.10.01.22.58.53;	author djm;	state Exp;
branches;
next	1.2;

1.2
date	2008.09.19.06.09.01;	author otto;	state Exp;
branches;
next	1.1;

1.1
date	2008.09.06.12.15.39;	author djm;	state Exp;
branches
	1.1.1.1;
next	;

1.1.1.1
date	2008.09.06.12.15.39;	author djm;	state Exp;
branches;
next	1.1.1.2;

1.1.1.2
date	2010.10.01.22.54.02;	author djm;	state Exp;
branches;
next	1.1.1.3;

1.1.1.3
date	2012.10.13.21.23.33;	author djm;	state Exp;
branches;
next	1.1.1.4;

1.1.1.4
date	2014.04.13.15.16.32;	author miod;	state Exp;
branches;
next	;


desc
@@


1.12
log
@Remove the libssl/src directory
@
text
@#!/usr/bin/env perl

$flavour = shift;
$output  = shift;
if ($flavour =~ /\./) { $output = $flavour; undef $flavour; }

$0 =~ m/(.*[\/\\])[^\/\\]+$/; $dir=$1;
( $xlate="${dir}x86_64-xlate.pl" and -f $xlate ) or
( $xlate="${dir}perlasm/x86_64-xlate.pl" and -f $xlate) or
die "can't locate x86_64-xlate.pl";

open OUT,"| \"$^X\" $xlate $flavour $output";
*STDOUT=*OUT;

($arg1,$arg2,$arg3,$arg4)=("%rdi","%rsi","%rdx","%rcx");	# Unix order

print<<___;
.extern		OPENSSL_cpuid_setup
.hidden		OPENSSL_cpuid_setup
.section	.init
	call	OPENSSL_cpuid_setup

.hidden	OPENSSL_ia32cap_P
.comm	OPENSSL_ia32cap_P,8,4

.text

.globl	OPENSSL_atomic_add
.type	OPENSSL_atomic_add,\@@abi-omnipotent
.align	16
OPENSSL_atomic_add:
	movl	($arg1),%eax
.Lspin:	leaq	($arg2,%rax),%r8
	.byte	0xf0		# lock
	cmpxchgl	%r8d,($arg1)
	jne	.Lspin
	movl	%r8d,%eax
	.byte	0x48,0x98	# cltq/cdqe
	ret
.size	OPENSSL_atomic_add,.-OPENSSL_atomic_add

.globl	OPENSSL_ia32_cpuid
.type	OPENSSL_ia32_cpuid,\@@abi-omnipotent
.align	16
OPENSSL_ia32_cpuid:
	mov	%rbx,%r8		# save %rbx

	xor	%eax,%eax
	cpuid
	mov	%eax,%r11d		# max value for standard query level

	xor	%eax,%eax
	cmp	\$0x756e6547,%ebx	# "Genu"
	setne	%al
	mov	%eax,%r9d
	cmp	\$0x49656e69,%edx	# "ineI"
	setne	%al
	or	%eax,%r9d
	cmp	\$0x6c65746e,%ecx	# "ntel"
	setne	%al
	or	%eax,%r9d		# 0 indicates Intel CPU
	jz	.Lintel

	cmp	\$0x68747541,%ebx	# "Auth"
	setne	%al
	mov	%eax,%r10d
	cmp	\$0x69746E65,%edx	# "enti"
	setne	%al
	or	%eax,%r10d
	cmp	\$0x444D4163,%ecx	# "cAMD"
	setne	%al
	or	%eax,%r10d		# 0 indicates AMD CPU
	jnz	.Lintel

	# AMD specific
	mov	\$0x80000000,%eax
	cpuid
	cmp	\$0x80000001,%eax
	jb	.Lintel
	mov	%eax,%r10d
	mov	\$0x80000001,%eax
	cpuid
	or	%ecx,%r9d
	and	\$0x00000801,%r9d	# isolate AMD XOP bit, 1<<11

	cmp	\$0x80000008,%r10d
	jb	.Lintel

	mov	\$0x80000008,%eax
	cpuid
	movzb	%cl,%r10		# number of cores - 1
	inc	%r10			# number of cores

	mov	\$1,%eax
	cpuid
	bt	\$28,%edx		# test hyper-threading bit
	jnc	.Lgeneric
	shr	\$16,%ebx		# number of logical processors
	cmp	%r10b,%bl
	ja	.Lgeneric
	and	\$0xefffffff,%edx	# ~(1<<28)
	jmp	.Lgeneric

.Lintel:
	cmp	\$4,%r11d
	mov	\$-1,%r10d
	jb	.Lnocacheinfo

	mov	\$4,%eax
	mov	\$0,%ecx		# query L1D
	cpuid
	mov	%eax,%r10d
	shr	\$14,%r10d
	and	\$0xfff,%r10d		# number of cores -1 per L1D

.Lnocacheinfo:
	mov	\$1,%eax
	cpuid
	and	\$0xbfefffff,%edx	# force reserved bits to 0
	cmp	\$0,%r9d
	jne	.Lnotintel
	or	\$0x40000000,%edx	# set reserved bit#30 on Intel CPUs
	and	\$15,%ah
	cmp	\$15,%ah		# examine Family ID
	jne	.Lnotintel
	or	\$0x00100000,%edx	# set reserved bit#20 to engage RC4_CHAR
.Lnotintel:
	bt	\$28,%edx		# test hyper-threading bit
	jnc	.Lgeneric
	and	\$0xefffffff,%edx	# ~(1<<28)
	cmp	\$0,%r10d
	je	.Lgeneric

	or	\$0x10000000,%edx	# 1<<28
	shr	\$16,%ebx
	cmp	\$1,%bl			# see if cache is shared
	ja	.Lgeneric
	and	\$0xefffffff,%edx	# ~(1<<28)
.Lgeneric:
	and	\$0x00000800,%r9d	# isolate AMD XOP flag
	and	\$0xfffff7ff,%ecx
	or	%ecx,%r9d		# merge AMD XOP flag

	mov	%edx,%r10d		# %r9d:%r10d is copy of %ecx:%edx
	bt	\$27,%r9d		# check OSXSAVE bit
	jnc	.Lclear_avx
	xor	%ecx,%ecx		# XCR0
	.byte	0x0f,0x01,0xd0		# xgetbv
	and	\$6,%eax		# isolate XMM and YMM state support
	cmp	\$6,%eax
	je	.Ldone
.Lclear_avx:
	mov	\$0xefffe7ff,%eax	# ~(1<<28|1<<12|1<<11)
	and	%eax,%r9d		# clear AVX, FMA and AMD XOP bits
.Ldone:
	shl	\$32,%r9
	mov	%r10d,%eax
	mov	%r8,%rbx		# restore %rbx
	or	%r9,%rax
	ret
.size	OPENSSL_ia32_cpuid,.-OPENSSL_ia32_cpuid
___

print<<___;
.globl	OPENSSL_wipe_cpu
.type	OPENSSL_wipe_cpu,\@@abi-omnipotent
.align	16
OPENSSL_wipe_cpu:
	pxor	%xmm0,%xmm0
	pxor	%xmm1,%xmm1
	pxor	%xmm2,%xmm2
	pxor	%xmm3,%xmm3
	pxor	%xmm4,%xmm4
	pxor	%xmm5,%xmm5
	pxor	%xmm6,%xmm6
	pxor	%xmm7,%xmm7
	pxor	%xmm8,%xmm8
	pxor	%xmm9,%xmm9
	pxor	%xmm10,%xmm10
	pxor	%xmm11,%xmm11
	pxor	%xmm12,%xmm12
	pxor	%xmm13,%xmm13
	pxor	%xmm14,%xmm14
	pxor	%xmm15,%xmm15
	xorq	%rcx,%rcx
	xorq	%rdx,%rdx
	xorq	%rsi,%rsi
	xorq	%rdi,%rdi
	xorq	%r8,%r8
	xorq	%r9,%r9
	xorq	%r10,%r10
	xorq	%r11,%r11
	leaq	8(%rsp),%rax
	ret
.size	OPENSSL_wipe_cpu,.-OPENSSL_wipe_cpu
___

close STDOUT;	# flush
@


1.11
log
@A few months back there was a big community fuss regarding direct-use
of the intel RDRAND instruction.  Consensus was RDRAND should probably
only be used as an additional source of entropy in a mixer.

Guess which library bends over backwards to provide easy access to
RDRAND?  Yep.  Guess which applications are using this support?  Not
even one... but still, this is being placed as a trap for someone.

Send this support straight to the abyss.
ok kettenis
@
text
@@


1.10
log
@repair missing semicolon. from Ian Mcwilliam
@
text
@a197 17
print<<___;
.globl	OPENSSL_ia32_rdrand
.type	OPENSSL_ia32_rdrand,\@@abi-omnipotent
.align	16
OPENSSL_ia32_rdrand:
	mov	\$8,%ecx
.Loop_rdrand:
	rdrand	%rax
	jc	.Lbreak_rdrand
	loop	.Loop_rdrand
.Lbreak_rdrand:
	cmp	\$0,%rax
	cmove	%rcx,%rax
	ret
.size	OPENSSL_ia32_rdrand,.-OPENSSL_ia32_rdrand
___

@


1.9
log
@Don't bother generating win64 assembly prologue.
@
text
@d164 1
a164 1
print<<___ 
@


1.8
log
@Remove oh-so-important-from-a-security-pov OpenSSL_rtdsc() function.
@
text
@a6 2
$win64=0; $win64=1 if ($flavour =~ /[nm]asm|mingw64/ || $output =~ /\.asm$/);

d15 1
a15 2
($arg1,$arg2,$arg3,$arg4)=$win64?("%rcx","%rdx","%r8", "%r9") :	# Win64 order
				 ("%rdi","%rsi","%rdx","%rcx");	# Unix order
d164 1
a164 1
print<<___ if (!$win64);
a188 21
	xorq	%r8,%r8
	xorq	%r9,%r9
	xorq	%r10,%r10
	xorq	%r11,%r11
	leaq	8(%rsp),%rax
	ret
.size	OPENSSL_wipe_cpu,.-OPENSSL_wipe_cpu
___
print<<___ if ($win64);
.globl	OPENSSL_wipe_cpu
.type	OPENSSL_wipe_cpu,\@@abi-omnipotent
.align	16
OPENSSL_wipe_cpu:
	pxor	%xmm0,%xmm0
	pxor	%xmm1,%xmm1
	pxor	%xmm2,%xmm2
	pxor	%xmm3,%xmm3
	pxor	%xmm4,%xmm4
	pxor	%xmm5,%xmm5
	xorq	%rcx,%rcx
	xorq	%rdx,%rdx
@


1.7
log
@Ok, there was a need for OPENSSL_cleanse() instead of bzero() to prevent
supposedly smart compilers from optimizing memory cleanups away. Understood.

Ok, in case of an hypothetically super smart compiler, OPENSSL_cleanse() had
to be convoluted enough for the compiler not to recognize that this was
actually bzero() in disguise. Understood.

But then why there had been optimized assembler versions of OPENSSL_cleanse()
is beyond me. Did someone not trust the C obfuscation?
@
text
@a44 10
.globl	OPENSSL_rdtsc
.type	OPENSSL_rdtsc,\@@abi-omnipotent
.align	16
OPENSSL_rdtsc:
	rdtsc
	shl	\$32,%rdx
	or	%rdx,%rax
	ret
.size	OPENSSL_rdtsc,.-OPENSSL_rdtsc

@


1.6
log
@Merge conflicts; remove MacOS, Netware, OS/2, VMS and Windows build machinery.
@
text
@a174 35

.globl  OPENSSL_cleanse
.type   OPENSSL_cleanse,\@@abi-omnipotent
.align  16
OPENSSL_cleanse:
	xor	%rax,%rax
	cmp	\$15,$arg2
	jae	.Lot
	cmp	\$0,$arg2
	je	.Lret
.Little:
	mov	%al,($arg1)
	sub	\$1,$arg2
	lea	1($arg1),$arg1
	jnz	.Little
.Lret:
	ret
.align	16
.Lot:
	test	\$7,$arg1
	jz	.Laligned
	mov	%al,($arg1)
	lea	-1($arg2),$arg2
	lea	1($arg1),$arg1
	jmp	.Lot
.Laligned:
	mov	%rax,($arg1)
	lea	-8($arg2),$arg2
	test	\$-8,$arg2
	lea	8($arg1),$arg1
	jnz	.Laligned
	cmp	\$0,$arg2
	jne	.Little
	ret
.size	OPENSSL_cleanse,.-OPENSSL_cleanse
@


1.5
log
@On amd64 OPENSSL_cpuid_setup and OPENSSL_ia32cap_P are now hidden so we don't
have to go through the PLT/GOT to get at them anymore.  In fact going through
the GOT now fails since we no longer have a GOT entry for OPENSSL_ia32cap_P.

Fixes the problem spotted by jasper@@ and sthen@@.  Based on a diff from mikeb@@
who did most of the actual work of tracking down the issue.

ok millert@@, mikeb@@
@
text
@d14 2
a15 1
open STDOUT,"| $^X $xlate $flavour $output";
@


1.4
log
@resolve conflicts
@
text
@a19 1
#include <machine/asm.h>
d23 1
a23 1
	call	PIC_PLT(OPENSSL_cpuid_setup)
@


1.3
log
@resolve conflicts, fix local changes
@
text
@d10 8
a17 1
open STDOUT,"| $^X ${dir}perlasm/x86_64-xlate.pl $flavour $output";
a18 2
if ($win64)	{ $arg1="%rcx"; $arg2="%rdx"; }
else		{ $arg1="%rdi"; $arg2="%rsi"; }
d22 1
d26 3
d59 1
a59 1
	mov	%rbx,%r8
d91 9
a99 1
	cmp	\$0x80000008,%eax
d110 1
a110 1
	jnc	.Ldone
d113 1
a113 1
	ja	.Ldone
d115 1
a115 1
	jmp	.Ldone
d132 1
d135 1
a135 1
	or	\$0x00100000,%edx	# use reserved 20th bit to engage RC4_CHAR
d138 2
a139 2
	je	.Lnotintel
	or	\$0x40000000,%edx	# use reserved bit to skip unrolled loop
d142 1
a142 1
	jnc	.Ldone
d145 1
a145 1
	je	.Ldone
d150 1
a150 1
	ja	.Ldone
d152 16
d169 4
a172 4
	shl	\$32,%rcx
	mov	%edx,%eax
	mov	%r8,%rbx
	or	%rcx,%rax
d265 17
@


1.2
log
@fix some cause of bad TEXTREL on i386 and amd64
- global function calls in .init sections (diff makes them via PLT)
- calls to global functions in aes-586.S (made static or local)
- global variable accesses in rc4-x86_64.S (now made via GOT)
from djm@@large; ok miod@@
@
text
@d3 3
a5 44
$output=shift;
$masm=1 if ($output =~ /\.asm/);
open STDOUT,">$output" || die "can't open $output: $!";

print<<___ if(defined($masm));
_TEXT	SEGMENT
PUBLIC	OPENSSL_rdtsc

PUBLIC	OPENSSL_atomic_add
ALIGN	16
OPENSSL_atomic_add	PROC
	mov	eax,DWORD PTR[rcx]
\$Lspin:	lea	r8,DWORD PTR[rdx+rax]
lock	cmpxchg	DWORD PTR[rcx],r8d
	jne	\$Lspin
	mov	eax,r8d
	cdqe    
	ret
OPENSSL_atomic_add	ENDP

PUBLIC	OPENSSL_wipe_cpu
ALIGN	16
OPENSSL_wipe_cpu	PROC
	pxor	xmm0,xmm0
	pxor	xmm1,xmm1
	pxor	xmm2,xmm2
	pxor	xmm3,xmm3
	pxor	xmm4,xmm4
	pxor	xmm5,xmm5
	xor	rcx,rcx
	xor	rdx,rdx
	xor	r8,r8
	xor	r9,r9
	xor	r10,r10
	xor	r11,r11
	lea	rax,QWORD PTR[rsp+8]
	ret
OPENSSL_wipe_cpu	ENDP
_TEXT	ENDS

CRT\$XIU	SEGMENT
EXTRN	OPENSSL_cpuid_setup:PROC
DQ	OPENSSL_cpuid_setup
CRT\$XIU	ENDS
d7 8
a14 2
___
print<<___ if(!defined($masm));
d16 3
d23 1
a23 1
.type	OPENSSL_atomic_add,\@@function
d26 4
a29 3
	movl	(%rdi),%eax
.Lspin:	leaq	(%rsi,%rax),%r8
lock;	cmpxchgl	%r8d,(%rdi)
d32 1
a32 1
	.byte	0x48,0x98
a35 41
.globl	OPENSSL_wipe_cpu
.type	OPENSSL_wipe_cpu,\@@function
.align	16
OPENSSL_wipe_cpu:
	pxor	%xmm0,%xmm0
	pxor	%xmm1,%xmm1
	pxor	%xmm2,%xmm2
	pxor	%xmm3,%xmm3
	pxor	%xmm4,%xmm4
	pxor	%xmm5,%xmm5
	pxor	%xmm6,%xmm6
	pxor	%xmm7,%xmm7
	pxor	%xmm8,%xmm8
	pxor	%xmm9,%xmm9
	pxor	%xmm10,%xmm10
	pxor	%xmm11,%xmm11
	pxor	%xmm12,%xmm12
	pxor	%xmm13,%xmm13
	pxor	%xmm14,%xmm14
	pxor	%xmm15,%xmm15
	xorq	%rcx,%rcx
	xorq	%rdx,%rdx
	xorq	%rsi,%rsi
	xorq	%rdi,%rdi
	xorq	%r8,%r8
	xorq	%r9,%r9
	xorq	%r10,%r10
	xorq	%r11,%r11
	leaq	8(%rsp),%rax
	ret
.size	OPENSSL_wipe_cpu,.-OPENSSL_wipe_cpu

.section	.init
	call	PIC_PLT(OPENSSL_cpuid_setup)

___

open STDOUT,"| $^X perlasm/x86_64-xlate.pl $output";
print<<___;
.text

d54 2
d65 46
a110 1
	or	%eax,%r9d
d112 1
d125 5
d141 35
d177 56
@


1.1
log
@Initial revision
@
text
@d50 2
d100 1
a100 1
	call	OPENSSL_cpuid_setup
@


1.1.1.1
log
@import of OpenSSL 0.9.8h
@
text
@@


1.1.1.2
log
@import OpenSSL-1.0.0a
@
text
@d3 44
a46 15
$flavour = shift;
$output  = shift;
if ($flavour =~ /\./) { $output = $flavour; undef $flavour; }

$win64=0; $win64=1 if ($flavour =~ /[nm]asm|mingw64/ || $output =~ /\.asm$/);

$0 =~ m/(.*[\/\\])[^\/\\]+$/; $dir=$1;
open STDOUT,"| $^X ${dir}perlasm/x86_64-xlate.pl $flavour $output";

if ($win64)	{ $arg1="%rcx"; $arg2="%rdx"; }
else		{ $arg1="%rdi"; $arg2="%rsi"; }
print<<___;
.extern		OPENSSL_cpuid_setup
.section	.init
	call	OPENSSL_cpuid_setup
d48 2
d53 1
a53 1
.type	OPENSSL_atomic_add,\@@abi-omnipotent
d56 3
a58 4
	movl	($arg1),%eax
.Lspin:	leaq	($arg2,%rax),%r8
	.byte	0xf0		# lock
	cmpxchgl	%r8d,($arg1)
d61 1
a61 1
	.byte	0x48,0x98	# cltq/cdqe
d65 41
a123 2
	mov	%eax,%r11d		# max value for standard query level

d133 1
a133 46
	or	%eax,%r9d		# 0 indicates Intel CPU
	jz	.Lintel

	cmp	\$0x68747541,%ebx	# "Auth"
	setne	%al
	mov	%eax,%r10d
	cmp	\$0x69746E65,%edx	# "enti"
	setne	%al
	or	%eax,%r10d
	cmp	\$0x444D4163,%ecx	# "cAMD"
	setne	%al
	or	%eax,%r10d		# 0 indicates AMD CPU
	jnz	.Lintel

	# AMD specific
	mov	\$0x80000000,%eax
	cpuid
	cmp	\$0x80000008,%eax
	jb	.Lintel

	mov	\$0x80000008,%eax
	cpuid
	movzb	%cl,%r10		# number of cores - 1
	inc	%r10			# number of cores

	mov	\$1,%eax
	cpuid
	bt	\$28,%edx		# test hyper-threading bit
	jnc	.Ldone
	shr	\$16,%ebx		# number of logical processors
	cmp	%r10b,%bl
	ja	.Ldone
	and	\$0xefffffff,%edx	# ~(1<<28)
	jmp	.Ldone

.Lintel:
	cmp	\$4,%r11d
	mov	\$-1,%r10d
	jb	.Lnocacheinfo

	mov	\$4,%eax
	mov	\$0,%ecx		# query L1D
	cpuid
	mov	%eax,%r10d
	shr	\$14,%r10d
	and	\$0xfff,%r10d		# number of cores -1 per L1D
a134 1
.Lnocacheinfo:
a146 5
	and	\$0xefffffff,%edx	# ~(1<<28)
	cmp	\$0,%r10d
	je	.Ldone

	or	\$0x10000000,%edx	# 1<<28
a157 69

.globl  OPENSSL_cleanse
.type   OPENSSL_cleanse,\@@abi-omnipotent
.align  16
OPENSSL_cleanse:
	xor	%rax,%rax
	cmp	\$15,$arg2
	jae	.Lot
	cmp	\$0,$arg2
	je	.Lret
.Little:
	mov	%al,($arg1)
	sub	\$1,$arg2
	lea	1($arg1),$arg1
	jnz	.Little
.Lret:
	ret
.align	16
.Lot:
	test	\$7,$arg1
	jz	.Laligned
	mov	%al,($arg1)
	lea	-1($arg2),$arg2
	lea	1($arg1),$arg1
	jmp	.Lot
.Laligned:
	mov	%rax,($arg1)
	lea	-8($arg2),$arg2
	test	\$-8,$arg2
	lea	8($arg1),$arg1
	jnz	.Laligned
	cmp	\$0,$arg2
	jne	.Little
	ret
.size	OPENSSL_cleanse,.-OPENSSL_cleanse
___

print<<___ if (!$win64);
.globl	OPENSSL_wipe_cpu
.type	OPENSSL_wipe_cpu,\@@abi-omnipotent
.align	16
OPENSSL_wipe_cpu:
	pxor	%xmm0,%xmm0
	pxor	%xmm1,%xmm1
	pxor	%xmm2,%xmm2
	pxor	%xmm3,%xmm3
	pxor	%xmm4,%xmm4
	pxor	%xmm5,%xmm5
	pxor	%xmm6,%xmm6
	pxor	%xmm7,%xmm7
	pxor	%xmm8,%xmm8
	pxor	%xmm9,%xmm9
	pxor	%xmm10,%xmm10
	pxor	%xmm11,%xmm11
	pxor	%xmm12,%xmm12
	pxor	%xmm13,%xmm13
	pxor	%xmm14,%xmm14
	pxor	%xmm15,%xmm15
	xorq	%rcx,%rcx
	xorq	%rdx,%rdx
	xorq	%rsi,%rsi
	xorq	%rdi,%rdi
	xorq	%r8,%r8
	xorq	%r9,%r9
	xorq	%r10,%r10
	xorq	%r11,%r11
	leaq	8(%rsp),%rax
	ret
.size	OPENSSL_wipe_cpu,.-OPENSSL_wipe_cpu
a158 22
print<<___ if ($win64);
.globl	OPENSSL_wipe_cpu
.type	OPENSSL_wipe_cpu,\@@abi-omnipotent
.align	16
OPENSSL_wipe_cpu:
	pxor	%xmm0,%xmm0
	pxor	%xmm1,%xmm1
	pxor	%xmm2,%xmm2
	pxor	%xmm3,%xmm3
	pxor	%xmm4,%xmm4
	pxor	%xmm5,%xmm5
	xorq	%rcx,%rcx
	xorq	%rdx,%rdx
	xorq	%r8,%r8
	xorq	%r9,%r9
	xorq	%r10,%r10
	xorq	%r11,%r11
	leaq	8(%rsp),%rax
	ret
.size	OPENSSL_wipe_cpu,.-OPENSSL_wipe_cpu
___

@


1.1.1.3
log
@import OpenSSL-1.0.1c
@
text
@d10 1
a10 8
( $xlate="${dir}x86_64-xlate.pl" and -f $xlate ) or
( $xlate="${dir}perlasm/x86_64-xlate.pl" and -f $xlate) or
die "can't locate x86_64-xlate.pl";

open STDOUT,"| $^X $xlate $flavour $output";

($arg1,$arg2,$arg3,$arg4)=$win64?("%rcx","%rdx","%r8", "%r9") :	# Win64 order
				 ("%rdi","%rsi","%rdx","%rcx");	# Unix order
d12 2
a15 1
.hidden		OPENSSL_cpuid_setup
a18 3
.hidden	OPENSSL_ia32cap_P
.comm	OPENSSL_ia32cap_P,8,4

d49 1
a49 1
	mov	%rbx,%r8		# save %rbx
d81 1
a81 9
	cmp	\$0x80000001,%eax
	jb	.Lintel
	mov	%eax,%r10d
	mov	\$0x80000001,%eax
	cpuid
	or	%ecx,%r9d
	and	\$0x00000801,%r9d	# isolate AMD XOP bit, 1<<11

	cmp	\$0x80000008,%r10d
d92 1
a92 1
	jnc	.Lgeneric
d95 1
a95 1
	ja	.Lgeneric
d97 1
a97 1
	jmp	.Lgeneric
a113 1
	and	\$0xbfefffff,%edx	# force reserved bits to 0
d116 1
a116 1
	or	\$0x40000000,%edx	# set reserved bit#30 on Intel CPUs
d119 2
a120 2
	jne	.Lnotintel
	or	\$0x00100000,%edx	# set reserved bit#20 to engage RC4_CHAR
d123 1
a123 1
	jnc	.Lgeneric
d126 1
a126 1
	je	.Lgeneric
d131 1
a131 1
	ja	.Lgeneric
a132 16
.Lgeneric:
	and	\$0x00000800,%r9d	# isolate AMD XOP flag
	and	\$0xfffff7ff,%ecx
	or	%ecx,%r9d		# merge AMD XOP flag

	mov	%edx,%r10d		# %r9d:%r10d is copy of %ecx:%edx
	bt	\$27,%r9d		# check OSXSAVE bit
	jnc	.Lclear_avx
	xor	%ecx,%ecx		# XCR0
	.byte	0x0f,0x01,0xd0		# xgetbv
	and	\$6,%eax		# isolate XMM and YMM state support
	cmp	\$6,%eax
	je	.Ldone
.Lclear_avx:
	mov	\$0xefffe7ff,%eax	# ~(1<<28|1<<12|1<<11)
	and	%eax,%r9d		# clear AVX, FMA and AMD XOP bits
d134 4
a137 4
	shl	\$32,%r9
	mov	%r10d,%eax
	mov	%r8,%rbx		# restore %rbx
	or	%r9,%rax
a229 17
___

print<<___;
.globl	OPENSSL_ia32_rdrand
.type	OPENSSL_ia32_rdrand,\@@abi-omnipotent
.align	16
OPENSSL_ia32_rdrand:
	mov	\$8,%ecx
.Loop_rdrand:
	rdrand	%rax
	jc	.Lbreak_rdrand
	loop	.Loop_rdrand
.Lbreak_rdrand:
	cmp	\$0,%rax
	cmove	%rcx,%rax
	ret
.size	OPENSSL_ia32_rdrand,.-OPENSSL_ia32_rdrand
@


1.1.1.4
log
@Import OpenSSL 1.0.1g
@
text
@d14 1
a14 2
open OUT,"| \"$^X\" $xlate $flavour $output";
*STDOUT=*OUT;
@


