head	1.4;
access;
symbols
	OPENBSD_3_2:1.3.0.16
	OPENBSD_3_2_BASE:1.3
	OPENBSD_3_1:1.3.0.14
	OPENBSD_3_1_BASE:1.3
	OPENBSD_3_0:1.3.0.12
	OPENBSD_3_0_BASE:1.3
	OPENBSD_2_9:1.3.0.10
	OPENBSD_2_9_BASE:1.3
	OPENBSD_2_8:1.3.0.8
	OPENBSD_2_8_BASE:1.3
	OPENBSD_2_7:1.3.0.6
	OPENBSD_2_7_BASE:1.3
	OPENBSD_2_6:1.3.0.4
	OPENBSD_2_6_BASE:1.3
	OPENBSD_2_5:1.3.0.2
	OPENBSD_2_5_BASE:1.3;
locks; strict;
comment	@ * @;


1.4
date	2003.01.20.18.14.06;	author marc;	state dead;
branches;
next	1.3;

1.3
date	98.12.21.07.38.43;	author d;	state Exp;
branches;
next	1.2;

1.2
date	98.11.21.14.02.10;	author d;	state Exp;
branches;
next	1.1;

1.1
date	98.11.20.11.15.38;	author d;	state Exp;
branches;
next	;


desc
@@


1.4
log
@
bye-bye libc_r sources.
the sources have been moved (with history) to /usr/src/lib/libpthread
@
text
@/*	$OpenBSD: slow_atomic_lock.c,v 1.3 1998/12/21 07:38:43 d Exp $	*/

#include <pthread.h>
#include "pthread_private.h"
#include "spinlock.h"
#include <signal.h>

/*
 * uthread atomic lock: 
 * 	attempt to acquire a lock (by giving it a non-zero value).
 *	Return zero on success, or the lock's value on failure
 *	This uses signal masking to make sure that no other thread
 *	can modify the lock while processing, hence it is very slow.
 */
int
_thread_slow_atomic_lock(volatile _spinlock_lock_t *lock)
{
	_spinlock_lock_t old;
	sigset_t oldset, newset = (sigset_t)~0;

	/* block signals - incurs a context switch */
	if (_thread_sys_sigprocmask(SIG_SETMASK, &newset, &oldset) < 0)
		PANIC("_atomic_lock block");

	old = *lock;
	if (old == _SPINLOCK_UNLOCKED)
		*lock = _SPINLOCK_LOCKED;

	/* restore signal mask to what it was */
	if (_thread_sys_sigprocmask(SIG_SETMASK, &oldset, NULL) < 0)
		PANIC("_atomic_lock restore");

	return (old != _SPINLOCK_UNLOCKED);
}

int
_thread_slow_atomic_is_locked(volatile _spinlock_lock_t *lock)
{

	return (*lock != _SPINLOCK_UNLOCKED);
}
@


1.3
log
@md spinlock
@
text
@d1 1
a1 1
/*	$OpenBSD: slow_atomic_lock.c,v 1.2 1998/11/21 14:02:10 d Exp $	*/
@


1.2
log
@missed an include
@
text
@d1 1
a1 1
/*	$OpenBSD: slow_atomic_lock.c,v 1.1 1998/11/20 11:15:38 d Exp $	*/
d15 2
a16 2
register_t
_thread_slow_atomic_lock(volatile register_t *lock)
d18 1
a18 1
	register_t old;
d26 2
a27 2
	if (old == 0)
		*lock = 1;
d33 8
a40 1
	return old;
@


1.1
log
@Move atomic_lock code from asm to C with inline asm;
Add m68k, mips and sparc. (needs more careful checking)
Add 'slow_atomic_lock' for crippled archs.
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d3 1
@

