head	1.17;
access;
symbols
	OPENBSD_3_2:1.10.0.6
	OPENBSD_3_2_BASE:1.10
	OPENBSD_3_1:1.10.0.4
	OPENBSD_3_1_BASE:1.10
	OPENBSD_3_0:1.10.0.2
	OPENBSD_3_0_BASE:1.10
	OPENBSD_2_9:1.6.0.6
	OPENBSD_2_9_BASE:1.6
	OPENBSD_2_8:1.6.0.4
	OPENBSD_2_8_BASE:1.6
	OPENBSD_2_7:1.6.0.2
	OPENBSD_2_7_BASE:1.6
	OPENBSD_2_6:1.5.0.2
	OPENBSD_2_6_BASE:1.5
	OPENBSD_2_5:1.4.0.2
	OPENBSD_2_5_BASE:1.4
	OPENBSD_2_4:1.1.0.2
	OPENBSD_2_4_BASE:1.1;
locks; strict;
comment	@ * @;


1.17
date	2003.01.20.18.14.07;	author marc;	state dead;
branches;
next	1.16;

1.16
date	2003.01.19.21.22.31;	author marc;	state Exp;
branches;
next	1.15;

1.15
date	2002.11.12.20.12.45;	author marc;	state Exp;
branches;
next	1.14;

1.14
date	2002.11.05.22.19.56;	author marc;	state Exp;
branches;
next	1.13;

1.13
date	2002.11.03.23.58.39;	author marc;	state Exp;
branches;
next	1.12;

1.12
date	2002.11.03.20.36.43;	author marc;	state Exp;
branches;
next	1.11;

1.11
date	2002.10.30.20.05.11;	author marc;	state Exp;
branches;
next	1.10;

1.10
date	2001.09.04.22.17.45;	author fgsch;	state Exp;
branches;
next	1.9;

1.9
date	2001.08.30.17.47.57;	author todd;	state Exp;
branches;
next	1.8;

1.8
date	2001.08.30.07.40.47;	author fgsch;	state Exp;
branches;
next	1.7;

1.7
date	2001.08.21.19.24.53;	author fgsch;	state Exp;
branches;
next	1.6;

1.6
date	99.11.25.07.01.34;	author d;	state Exp;
branches;
next	1.5;

1.5
date	99.05.26.00.18.23;	author d;	state Exp;
branches;
next	1.4;

1.4
date	99.01.10.23.09.36;	author d;	state Exp;
branches;
next	1.3;

1.3
date	98.12.23.22.49.46;	author d;	state Exp;
branches;
next	1.2;

1.2
date	98.11.09.03.13.19;	author d;	state Exp;
branches;
next	1.1;

1.1
date	98.08.27.09.01.01;	author d;	state Exp;
branches;
next	;


desc
@@


1.17
log
@
bye-bye libc_r sources.
the sources have been moved (with history) to /usr/src/lib/libpthread
@
text
@/*	$OpenBSD: uthread_fd.c,v 1.16 2003/01/19 21:22:31 marc Exp $	*/
/*
 * Copyright (c) 1995-1998 John Birrell <jb@@cimlogic.com.au>
 * All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *	This product includes software developed by John Birrell.
 * 4. Neither the name of the author nor the names of any co-contributors
 *    may be used to endorse or promote products derived from this software
 *    without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY JOHN BIRRELL AND CONTRIBUTORS ``AS IS'' AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE
 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
 *
 * $FreeBSD: uthread_fd.c,v 1.13 1999/08/28 00:03:31 peter Exp $
 *
 */
#include <errno.h>
#include <fcntl.h>
#include <stdlib.h>
#include <string.h>
#ifdef _THREAD_SAFE
#include <pthread.h>
#include "pthread_private.h"

/* Static variables: */
static	spinlock_t	fd_table_lock	= _SPINLOCK_INITIALIZER;

/*
 * Initialize the fd_table entry for the given fd.
 *
 * This function *must* return -1 and set the thread specific errno
 * as a system call. This is because the error return from this
 * function is propagated directly back from thread-wrapped system
 * calls.
 */
int
_thread_fd_table_init(int fd)
{
	int	ret = 0;
	struct fd_table_entry *entry;
	int	saved_errno;

	if (fd < 0 || fd >= _thread_dtablesize) {
		/*
		 * file descriptor is out of range, Return a bad file
		 * descriptor error:
		 */ 
		errno = EBADF;
		ret = -1;
	} else if (_thread_fd_table[fd] == NULL) {
		/* First time for this fd, build an entry */
		entry = (struct fd_table_entry *)
		        malloc(sizeof(struct fd_table_entry));
		if (entry == NULL) {
			errno = ENOMEM;
			ret = -1;
		} else {
			/* Initialise the file locks: */
			_SPINLOCK_INIT(&entry->lock);
			entry->r_owner = NULL;
			entry->w_owner = NULL;
			entry->r_fname = NULL;
			entry->w_fname = NULL;
			entry->r_lineno = 0;
			entry->w_lineno = 0;
			entry->r_lockcount = 0;
			entry->w_lockcount = 0;

			/* Initialise the read/write queues: */
			TAILQ_INIT(&entry->r_queue);
			TAILQ_INIT(&entry->w_queue);

			/* Get the flags for the file: */
			entry->flags = _thread_sys_fcntl(fd, F_GETFL, 0);
			if (entry->flags == -1)
				/* use the errno fcntl returned */
				ret = -1;
			else {
				/*
				 * Make the file descriptor non-blocking.
				 * This might fail if the device driver does
				 * not support non-blocking calls, or if the
				 * driver is naturally non-blocking.
				 */
				saved_errno = errno;
				_thread_sys_fcntl(fd, F_SETFL,
						  entry->flags | O_NONBLOCK);
				errno = saved_errno;

				/* Lock the file descriptor table: */
				_SPINLOCK(&fd_table_lock);

				/*
				 * Check if another thread allocated the
				 * file descriptor entry while this thread
				 * was doing the same thing. The table wasn't
				 * kept locked during this operation because
				 * it has the potential to recurse.
				 */
				if (_thread_fd_table[fd] == NULL) {
					/* This thread wins: */
					_thread_fd_table[fd] = entry;
					entry = NULL;
				}

				/* Unlock the file descriptor table: */
				_SPINUNLOCK(&fd_table_lock);
			}

			/*
			 * If there was an error in getting the flags for
			 * the file or if another thread initialized the
			 * table entry throw this entry away.
			 */
			if (entry != NULL)
				free(entry);
		}
	}

	/* Return the completion status: */
	return (ret);
}

/*
 * Unlock the fd table entry for a given thread, fd, and lock type.
 */
void
_thread_fd_unlock_thread(struct pthread	*thread, int fd, int lock_type,
			 const char *fname, int lineno)
{
	struct fd_table_entry *entry;
	int	ret;

	/*
	 * Check that the file descriptor table is initialised for this
	 * entry: 
	 */
	ret = _thread_fd_table_init(fd);
	if (ret == 0) {
		entry = _thread_fd_table[fd];

		/*
		 * Defer signals to protect the scheduling queues from
		 * access by the signal handler:
		 */
		_thread_kern_sig_defer();

		/*
		 * Lock the file descriptor table entry to prevent
		 * other threads for clashing with the current
		 * thread's accesses:
		 */
		if (fname)
			_spinlock_debug(&entry->lock, (char *)fname, lineno);
		else
			_SPINLOCK(&entry->lock);

		/* Check if the running thread owns the read lock: */
		if (entry->r_owner == thread &&
		    (lock_type == FD_READ || lock_type == FD_RDWR)) {
			/*
			 * Decrement the read lock count for the
			 * running thread: 
			 */
			entry->r_lockcount--;
			if (entry->r_lockcount == 0) {
				/*
				 * no read locks, dequeue any threads
				 * waiting for a read lock
				 */
				entry->r_owner = TAILQ_FIRST(&entry->r_queue);
				if (entry->r_owner != NULL) {
					TAILQ_REMOVE(&entry->r_queue,
						     entry->r_owner, qe);

					/*
					 * Set the state of the new owner of
					 * the thread to running:  
					 */
					PTHREAD_NEW_STATE(entry->r_owner,
							  PS_RUNNING);

					/*
					 * Reset the number of read locks.
					 * This will be incremented by the new
					 * owner of the lock when it sees that
					 *it has the lock.
					 */
					entry->r_lockcount = 0;
				}
			}

		}
		/* Check if the running thread owns the write lock: */
		if (entry->w_owner == thread &&
		    (lock_type == FD_WRITE || lock_type == FD_RDWR)) {
			/*
			 * Decrement the write lock count for the
			 * running thread: 
			 */
			entry->w_lockcount--;
			if (entry->w_lockcount == 0) {
				/*
				 * no write locks, dequeue any threads
				 * waiting on a write lock.
				 */
				entry->w_owner = TAILQ_FIRST(&entry->w_queue);
				if (entry->w_owner != NULL) {
					/* Remove this thread from the queue: */
					TAILQ_REMOVE(&entry->w_queue,
						     entry->w_owner, qe);

					/*
					 * Set the state of the new owner of
					 * the thread to running: 
					 */
					PTHREAD_NEW_STATE(entry->w_owner,
							  PS_RUNNING);

					/*
					 * Reset the number of write locks.
					 * This will be incremented by the
					 * new owner of the lock when it  
					 * sees that it has the lock.
					 */
					entry->w_lockcount = 0;
				}
			}
		}

		/* Unlock the file descriptor table entry: */
		_SPINUNLOCK(&entry->lock);

		/*
		 * Undefer and handle pending signals, yielding if
		 * necessary:
		 */
		_thread_kern_sig_undefer();
	}

	/* Nothing to return. */
	return;
}

/*
 * Unlock an fd table entry for the given fd and lock type.  Save
 * fname and lineno (debug variables).
 */
void
_thread_fd_unlock(int fd, int lock_type, const char *fname, int lineno)
{
	struct pthread	*curthread = _get_curthread();
	_thread_fd_unlock_thread(curthread, fd, lock_type, fname, lineno);
}

/*
 * Unlock all fd table entries owned by the given thread
 */
void
_thread_fd_unlock_owned(pthread_t pthread)
{
	struct fd_table_entry *entry;
	int do_unlock;
	int fd;

	for (fd = 0; fd < _thread_dtablesize; fd++) {
		entry = _thread_fd_table[fd];
		if (entry) {
			_SPINLOCK(&entry->lock);
			do_unlock = 0;
			/* force an unlock regardless of the recursion level */
			if (entry->r_owner == pthread) {
				entry->r_lockcount = 1;
				do_unlock++;
			}
			if (entry->w_owner == pthread) {
				entry->w_lockcount = 1;
				do_unlock++;
			}
			_SPINUNLOCK(&entry->lock);
			if (do_unlock)
				_thread_fd_unlock_thread(pthread, fd, FD_RDWR,
							 __FILE__, __LINE__);
		}
	}
}

/*
 * Lock an fd table entry for the given fd and lock type.  Save
 * fname and lineno (debug variables).  The debug variables may be
 * null when called by the non-debug version of the function.
 */
int
_thread_fd_lock(int fd, int lock_type, struct timespec * timeout,
		const char *fname, int lineno)
{
	struct pthread	*curthread = _get_curthread();
	struct fd_table_entry *entry;
	int	ret;

	/*
	 * Check that the file descriptor table is initialised for this
	 * entry: 
	 */
	ret = _thread_fd_table_init(fd);
	if (ret == 0) {
		entry = _thread_fd_table[fd];

		/*
		 * Lock the file descriptor table entry to prevent
		 * other threads for clashing with the current
		 * thread's accesses:
		 */
		if (fname)
			_spinlock_debug(&entry->lock, (char *)fname, lineno);
		else
			_SPINLOCK(&entry->lock);

		/* Handle read locks */
		if (lock_type == FD_READ || lock_type == FD_RDWR) {
			/*
			 * Enter a loop to wait for the file descriptor to be
			 * locked    for read for the current thread: 
			 */
			while (entry->r_owner != curthread) {
				/*
				 * Check if the file descriptor is locked by
				 * another thread: 
				 */
				if (entry->r_owner != NULL) {
					/*
					 * Another thread has locked the file
					 * descriptor for read, so join the
					 * queue of threads waiting for a  
					 * read lock on this file descriptor: 
					 */
					TAILQ_INSERT_TAIL(&entry->r_queue,
							  curthread, qe);

					/*
					 * Save the file descriptor details
					 * in the thread structure for the
					 * running thread: 
					 */
					curthread->data.fd.fd = fd;
					curthread->data.fd.branch = lineno;
					curthread->data.fd.fname =
						(char *)fname;

					/* Set the timeout: */
					_thread_kern_set_timeout(timeout);

					/*
					 * Unlock the file descriptor
					 * table entry:
					 */
					_SPINUNLOCK(&entry->lock);

					/*
					 * Schedule this thread to wait on
					 * the read lock. It will only be
					 * woken when it becomes the next in
					 * the   queue and is granted access
					 * to the lock by the thread that is
					 * unlocking the file descriptor.
					 */
					_thread_kern_sched_state(PS_FDLR_WAIT,
								 __FILE__,
								 __LINE__);

					/*
					 * Lock the file descriptor
					 * table entry again:
					 */
					_SPINLOCK(&entry->lock);

				} else {
					/*
					 * The running thread now owns the
					 * read lock on this file descriptor: 
					 */
					entry->r_owner = curthread;

					/*
					 * Reset the number of read locks for
					 * this file descriptor: 
					 */
					entry->r_lockcount = 0;
					entry->r_fname = fname;
					entry->r_lineno = lineno;
				}
			}

			/* Increment the read lock count: */
			entry->r_lockcount++;
		}

		/* Handle write locks */
		if (lock_type == FD_WRITE || lock_type == FD_RDWR) {
			/*
			 * Enter a loop to wait for the file descriptor to be
			 * locked for write for the current thread: 
			 */
			while (entry->w_owner != curthread) {
				/*
				 * Check if the file descriptor is locked by
				 * another thread: 
				 */
				if (entry->w_owner != NULL) {
					/*
					 * Another thread has locked the file
					 * descriptor for write, so join the
					 * queue of threads waiting for a 
					 * write lock on this file
					 * descriptor: 
					 */
					TAILQ_INSERT_TAIL(&entry->w_queue,
							  curthread, qe);

					/*
					 * Save the file descriptor details
					 * in the thread structure for the
					 * running thread: 
					 */
					curthread->data.fd.fd = fd;
					curthread->data.fd.branch = lineno;
					curthread->data.fd.fname =
						(char *)fname;

					/* Set the timeout: */
					_thread_kern_set_timeout(timeout);

					/*
					 * Unlock the file descriptor
					 * table entry:
					 */
					_SPINUNLOCK(&entry->lock);

					/*
					 * Schedule this thread to wait on
					 * the write lock. It will only be
					 * woken when it becomes the next in
					 * the queue and is granted access to
					 * the lock by the thread that is
					 * unlocking the file descriptor.
					 */
					_thread_kern_sched_state(PS_FDLW_WAIT,
								 __FILE__,
								 __LINE__);

					/*
					 * Lock the file descriptor
					 * table entry again:
					 */
					_SPINLOCK(&entry->lock);
				} else {
					/*
					 * The running thread now owns the
					 * write lock on this file descriptor: 
					 */
					entry->w_owner = curthread;

					/*
					 * Reset the number of write locks
					 * for this file descriptor: 
					 */
					entry->w_lockcount = 0;
					entry->w_fname = fname;
					entry->w_lineno = lineno;
				}
			}

			/* Increment the write lock count: */
			entry->w_lockcount++;
		}

		/* Unlock the file descriptor table entry: */
		_SPINUNLOCK(&entry->lock);
	}

	/* Return the completion status: */
	return (ret);
}

#endif
@


1.16
log
@
return (func(...)) not needed when the current function and func
are both void.
The select call is a cancellation point per IEEE Std 1003.1-2001.
This should fix a problem espie@@ found in kde.
@
text
@d1 1
a1 1
/*	$OpenBSD: uthread_fd.c,v 1.15 2002/11/12 20:12:45 marc Exp $	*/
@


1.15
log
@get rid of compiler warnings
@
text
@d1 1
a1 1
/*	$OpenBSD: uthread_fd.c,v 1.14 2002/11/05 22:19:56 marc Exp $	*/
d272 1
a272 2
	return (_thread_fd_unlock_thread(curthread, fd, lock_type,
					 fname, lineno));
@


1.14
log
@
thread safe libc -- 2nd try.   OK miod@@, millert@@
Thanks to miod@@ for m68k and vax fixes
@
text
@d1 1
a1 1
/*	$OpenBSD: uthread_fd.c,v 1.13 2002/11/03 23:58:39 marc Exp $	*/
a281 1
	struct pthread	*saved_thread = _get_curthread();
@


1.13
log
@back out previous patch.. there are still some vax/m68k issues
@
text
@d1 1
a1 1
/*	$OpenBSD: uthread_fd.c,v 1.12 2002/11/03 20:36:43 marc Exp $	*/
d148 1
a148 1
			 char *fname, int lineno)
d173 1
a173 1
			_spinlock_debug(&entry->lock, fname, lineno);
d269 1
a269 1
_thread_fd_unlock_debug(int fd, int lock_type, char *fname, int lineno)
a276 11
 * Unlock an fd table entry for the given fd and lock type (read,
 * write, or read-write).
 */
void
_thread_fd_unlock(int fd, int lock_type)
{
	struct pthread	*curthread = _get_curthread();
	return (_thread_fd_unlock_thread(curthread, fd, lock_type, NULL, 0));
}

/*
d315 2
a316 2
_thread_fd_lock_debug(int fd, int lock_type, struct timespec * timeout,
		      char *fname, int lineno)
d336 1
a336 1
			_spinlock_debug(&entry->lock, fname, lineno);
d368 2
a369 1
					curthread->data.fd.fname = fname;
d448 2
a449 1
					curthread->data.fd.fname = fname;
a503 10
}

/*
 * Non-debug version of fd locking.  Just call the debug version
 * passing a null file and line
 */
int
_thread_fd_lock(int fd, int lock_type, struct timespec * timeout)
{
	return (_thread_fd_lock_debug(fd, lock_type, timeout, NULL, 0));
@


1.12
log
@
libc changes for thread safety.  Tested on:
alpha (millert@@), i386 (marc@@), m68k (millert@@ and miod@@),
powerpc (drahn@@ and dhartmei@@), sparc (millert@@ and marc@@),
sparc64 (marc@@), and vax (millert@@ and miod@@).
Thanks to millert@@, miod@@, and mickey@@ for fixes along the way.
@
text
@d1 1
a1 1
/*	$OpenBSD: uthread_fd.c,v 1.11 2002/10/30 20:05:11 marc Exp $	*/
d148 1
a148 1
			 const char *fname, int lineno)
d173 1
a173 1
			_spinlock_debug(&entry->lock, (char *)fname, lineno);
d269 1
a269 1
_thread_fd_unlock(int fd, int lock_type, const char *fname, int lineno)
d277 11
d326 2
a327 2
_thread_fd_lock(int fd, int lock_type, struct timespec * timeout,
		const char *fname, int lineno)
d347 1
a347 1
			_spinlock_debug(&entry->lock, (char *)fname, lineno);
d379 1
a379 2
					curthread->data.fd.fname =
						(char *)fname;
d458 1
a458 2
					curthread->data.fd.fname =
						(char *)fname;
d513 10
@


1.11
log
@
removes duplicate functions and factor out common code so the needed (but
missing) _thread_fd_unlock_owned function can be added with minimal pain.
The incorrect special handling of the stdio fds was also removed.

Tested with the libc_r regression tests and the mysql regression tests.
No complaints from any developers
@
text
@d1 1
a1 1
/*	$OpenBSD: uthread_fd.c,v 1.10 2001/09/04 22:17:45 fgsch Exp $	*/
d148 1
a148 1
			 char *fname, int lineno)
d173 1
a173 1
			_spinlock_debug(&entry->lock, fname, lineno);
d269 1
a269 1
_thread_fd_unlock_debug(int fd, int lock_type, char *fname, int lineno)
a276 11
 * Unlock an fd table entry for the given fd and lock type (read,
 * write, or read-write).
 */
void
_thread_fd_unlock(int fd, int lock_type)
{
	struct pthread	*curthread = _get_curthread();
	return (_thread_fd_unlock_thread(curthread, fd, lock_type, NULL, 0));
}

/*
d315 2
a316 2
_thread_fd_lock_debug(int fd, int lock_type, struct timespec * timeout,
		      char *fname, int lineno)
d336 1
a336 1
			_spinlock_debug(&entry->lock, fname, lineno);
d368 2
a369 1
					curthread->data.fd.fname = fname;
d448 2
a449 1
					curthread->data.fd.fname = fname;
a503 10
}

/*
 * Non-debug version of fd locking.  Just call the debug version
 * passing a null file and line
 */
int
_thread_fd_lock(int fd, int lock_type, struct timespec * timeout)
{
	return (_thread_fd_lock_debug(fd, lock_type, timeout, NULL, 0));
@


1.10
log
@put changes back, this time ALL the files.
@
text
@d1 1
a1 1
/*	$OpenBSD: uthread_fd.c,v 1.9 2001/08/30 17:47:57 todd Exp $	*/
d48 2
a54 1

a61 1
	/* Check if the file descriptor is out of range: */
d63 4
a66 1
		/* Return a bad file descriptor error: */
d69 6
a74 34
	}

	/*
	 * Check if memory has already been allocated for this file
	 * descriptor: 
	 */
	else if (_thread_fd_table[fd] != NULL) {
		/* Memory has already been allocated. */

	/* Allocate memory for the file descriptor table entry: */
	} else if ((entry = (struct fd_table_entry *)
	    malloc(sizeof(struct fd_table_entry))) == NULL) {
		/* Return an insufficient memory error: */
		errno = ENOMEM;
		ret = -1;
	} else {
		/* Initialise the file locks: */
		_SPINLOCK_INIT(&entry->lock);
		entry->r_owner = NULL;
		entry->w_owner = NULL;
		entry->r_fname = NULL;
		entry->w_fname = NULL;
		entry->r_lineno = 0;
		entry->w_lineno = 0;
		entry->r_lockcount = 0;
		entry->w_lockcount = 0;

		/* Initialise the read/write queues: */
		TAILQ_INIT(&entry->r_queue);
		TAILQ_INIT(&entry->w_queue);

		/* Get the flags for the file: */
		if (((fd >= 3) || (_pthread_stdio_flags[fd] == -1)) &&
		    (entry->flags = _thread_sys_fcntl(fd, F_GETFL, 0)) == -1) {
d76 48
a123 13
		}
		else {
			/* Check if a stdio descriptor: */
			if ((fd < 3) && (_pthread_stdio_flags[fd] != -1))
				/*
				 * Use the stdio flags read by
				 * _pthread_init() to avoid
				 * mistaking the non-blocking
				 * flag that, when set on one
				 * stdio fd, is set on all stdio
				 * fds.
				 */
				entry->flags = _pthread_stdio_flags[fd];
d125 3
a127 13
			/*
			 * Make the file descriptor non-blocking.
			 * This might fail if the device driver does
			 * not support non-blocking calls, or if the
			 * driver is naturally non-blocking.
			 */
			saved_errno = errno;
			_thread_sys_fcntl(fd, F_SETFL,
			    entry->flags | O_NONBLOCK);
			errno = saved_errno;

			/* Lock the file descriptor table: */
			_SPINLOCK(&fd_table_lock);
d130 3
a132 5
			 * Check if another thread allocated the
			 * file descriptor entry while this thread
			 * was doing the same thing. The table wasn't
			 * kept locked during this operation because
			 * it has the potential to recurse.
d134 2
a135 8
			if (_thread_fd_table[fd] == NULL) {
				/* This thread wins: */
				_thread_fd_table[fd] = entry;
				entry = NULL;
			}

			/* Unlock the file descriptor table: */
			_SPINUNLOCK(&fd_table_lock);
a136 11

		/*
		 * Check if another thread initialised the table entry
		 * before this one could:
		 */
		if (entry != NULL)
			/*
			 * Throw away the table entry that this thread
			 * prepared. The other thread wins.
			 */
			free(entry);
d143 3
d147 2
a148 1
_thread_fd_unlock(int fd, int lock_type)
d150 1
a150 1
	struct pthread	*curthread = _get_curthread();
d157 4
a160 1
	if ((ret = _thread_fd_table_init(fd)) == 0) {
d172 4
a175 1
		_SPINLOCK(&_thread_fd_table[fd]->lock);
d178 8
a185 15
		if (_thread_fd_table[fd]->r_owner == curthread) {
			/* Check the file descriptor and lock types: */
			if (lock_type == FD_READ || lock_type == FD_RDWR) {
				/*
				 * Decrement the read lock count for the
				 * running thread: 
				 */
				_thread_fd_table[fd]->r_lockcount--;

				/*
				 * Check if the running thread still has read
				 * locks on this file descriptor: 
				 */
				if (_thread_fd_table[fd]->r_lockcount != 0) {
				}
d187 2
a188 2
				 * Get the next thread in the queue for a
				 * read lock on this file descriptor: 
d190 4
a193 5
				else if ((_thread_fd_table[fd]->r_owner = TAILQ_FIRST(&_thread_fd_table[fd]->r_queue)) == NULL) {
				} else {
					/* Remove this thread from the queue: */
					TAILQ_REMOVE(&_thread_fd_table[fd]->r_queue,
					    _thread_fd_table[fd]->r_owner, qe);
d197 1
a197 1
					 * the thread to running: 
d199 2
a200 1
					PTHREAD_NEW_STATE(_thread_fd_table[fd]->r_owner,PS_RUNNING);
d204 3
a206 3
					 * This will be incremented by the
					 * new owner of the lock when it sees
					 * that it has the lock.                           
d208 1
a208 1
					_thread_fd_table[fd]->r_lockcount = 0;
d211 1
d214 8
a221 3
		if (_thread_fd_table[fd]->w_owner == curthread) {
			/* Check the file descriptor and lock types: */
			if (lock_type == FD_WRITE || lock_type == FD_RDWR) {
d223 2
a224 2
				 * Decrement the write lock count for the
				 * running thread: 
d226 2
a227 14
				_thread_fd_table[fd]->w_lockcount--;

				/*
				 * Check if the running thread still has
				 * write locks on this file descriptor: 
				 */
				if (_thread_fd_table[fd]->w_lockcount != 0) {
				}
				/*
				 * Get the next thread in the queue for a
				 * write lock on this file descriptor: 
				 */
				else if ((_thread_fd_table[fd]->w_owner = TAILQ_FIRST(&_thread_fd_table[fd]->w_queue)) == NULL) {
				} else {
d229 2
a230 2
					TAILQ_REMOVE(&_thread_fd_table[fd]->w_queue,
					    _thread_fd_table[fd]->w_owner, qe);
d236 2
a237 1
					PTHREAD_NEW_STATE(_thread_fd_table[fd]->w_owner,PS_RUNNING);
d245 1
a245 1
					_thread_fd_table[fd]->w_lockcount = 0;
d251 1
a251 1
		_SPINUNLOCK(&_thread_fd_table[fd]->lock);
d264 6
a269 2
int
_thread_fd_lock(int fd, int lock_type, struct timespec * timeout)
d272 2
a273 164
	int	ret;

	/*
	 * Check that the file descriptor table is initialised for this
	 * entry: 
	 */
	if ((ret = _thread_fd_table_init(fd)) == 0) {
		/*
		 * Lock the file descriptor table entry to prevent
		 * other threads for clashing with the current
		 * thread's accesses:
		 */
		_SPINLOCK(&_thread_fd_table[fd]->lock);

		/* Check the file descriptor and lock types: */
		if (lock_type == FD_READ || lock_type == FD_RDWR) {
			/*
			 * Enter a loop to wait for the file descriptor to be
			 * locked    for read for the current thread: 
			 */
			while (_thread_fd_table[fd]->r_owner != curthread) {
				/*
				 * Check if the file descriptor is locked by
				 * another thread: 
				 */
				if (_thread_fd_table[fd]->r_owner != NULL) {
					/*
					 * Another thread has locked the file
					 * descriptor for read, so join the
					 * queue of threads waiting for a  
					 * read lock on this file descriptor: 
					 */
					TAILQ_INSERT_TAIL(&_thread_fd_table[fd]->r_queue, curthread, qe);

					/*
					 * Save the file descriptor details
					 * in the thread structure for the
					 * running thread: 
					 */
					curthread->data.fd.fd = fd;

					/* Set the timeout: */
					_thread_kern_set_timeout(timeout);

					/*
					 * Unlock the file descriptor
					 * table entry:
					 */
					_SPINUNLOCK(&_thread_fd_table[fd]->lock);

					/*
					 * Schedule this thread to wait on
					 * the read lock. It will only be
					 * woken when it becomes the next in
					 * the   queue and is granted access
					 * to the lock by the       thread
					 * that is unlocking the file
					 * descriptor.        
					 */
					_thread_kern_sched_state(PS_FDLR_WAIT, __FILE__, __LINE__);

					/*
					 * Lock the file descriptor
					 * table entry again:
					 */
					_SPINLOCK(&_thread_fd_table[fd]->lock);

				} else {
					/*
					 * The running thread now owns the
					 * read lock on this file descriptor: 
					 */
					_thread_fd_table[fd]->r_owner = curthread;

					/*
					 * Reset the number of read locks for
					 * this file descriptor: 
					 */
					_thread_fd_table[fd]->r_lockcount = 0;
				}
			}

			/* Increment the read lock count: */
			_thread_fd_table[fd]->r_lockcount++;
		}

		/* Check the file descriptor and lock types: */
		if (lock_type == FD_WRITE || lock_type == FD_RDWR) {
			/*
			 * Enter a loop to wait for the file descriptor to be
			 * locked for write for the current thread: 
			 */
			while (_thread_fd_table[fd]->w_owner != curthread) {
				/*
				 * Check if the file descriptor is locked by
				 * another thread: 
				 */
				if (_thread_fd_table[fd]->w_owner != NULL) {
					/*
					 * Another thread has locked the file
					 * descriptor for write, so join the
					 * queue of threads waiting for a 
					 * write lock on this file
					 * descriptor: 
					 */
					TAILQ_INSERT_TAIL(&_thread_fd_table[fd]->w_queue, curthread, qe);

					/*
					 * Save the file descriptor details
					 * in the thread structure for the
					 * running thread: 
					 */
					curthread->data.fd.fd = fd;

					/* Set the timeout: */
					_thread_kern_set_timeout(timeout);

					/*
					 * Unlock the file descriptor
					 * table entry:
					 */
					_SPINUNLOCK(&_thread_fd_table[fd]->lock);

					/*
					 * Schedule this thread to wait on
					 * the write lock. It will only be
					 * woken when it becomes the next in
					 * the queue and is granted access to
					 * the lock by the thread that is
					 * unlocking the file descriptor.        
					 */
					_thread_kern_sched_state(PS_FDLW_WAIT, __FILE__, __LINE__);

					/*
					 * Lock the file descriptor
					 * table entry again:
					 */
					_SPINLOCK(&_thread_fd_table[fd]->lock);
				} else {
					/*
					 * The running thread now owns the
					 * write lock on this   file
					 * descriptor: 
					 */
					_thread_fd_table[fd]->w_owner = curthread;

					/*
					 * Reset the number of write locks
					 * for this file descriptor: 
					 */
					_thread_fd_table[fd]->w_lockcount = 0;
				}
			}

			/* Increment the write lock count: */
			_thread_fd_table[fd]->w_lockcount++;
		}

		/* Unlock the file descriptor table entry: */
		_SPINUNLOCK(&_thread_fd_table[fd]->lock);
	}

	/* Return the completion status: */
	return (ret);
d276 4
d281 1
a281 1
_thread_fd_unlock_debug(int fd, int lock_type, char *fname, int lineno)
d284 2
a285 1
	int	ret;
d287 10
a296 10
	/*
	 * Check that the file descriptor table is initialised for this
	 * entry: 
	 */
	if ((ret = _thread_fd_table_init(fd)) == 0) {
		/*
		 * Defer signals to protect the scheduling queues from
		 * access by the signal handler:
		 */
		_thread_kern_sig_defer();
d298 9
a306 47
		/*
		 * Lock the file descriptor table entry to prevent
		 * other threads for clashing with the current
		 * thread's accesses:
		 */
		_spinlock_debug(&_thread_fd_table[fd]->lock, fname, lineno);

		/* Check if the running thread owns the read lock: */
		if (_thread_fd_table[fd]->r_owner == curthread) {
			/* Check the file descriptor and lock types: */
			if (lock_type == FD_READ || lock_type == FD_RDWR) {
				/*
				 * Decrement the read lock count for the
				 * running thread: 
				 */
				_thread_fd_table[fd]->r_lockcount--;

				/*
				 * Check if the running thread still has read
				 * locks on this file descriptor: 
				 */
				if (_thread_fd_table[fd]->r_lockcount != 0) {
				}
				/*
				 * Get the next thread in the queue for a
				 * read lock on this file descriptor: 
				 */
				else if ((_thread_fd_table[fd]->r_owner = TAILQ_FIRST(&_thread_fd_table[fd]->r_queue)) == NULL) {
				} else {
					/* Remove this thread from the queue: */
					TAILQ_REMOVE(&_thread_fd_table[fd]->r_queue,
					    _thread_fd_table[fd]->r_owner, qe);

					/*
					 * Set the state of the new owner of
					 * the thread to  running: 
					 */
					PTHREAD_NEW_STATE(_thread_fd_table[fd]->r_owner,PS_RUNNING);

					/*
					 * Reset the number of read locks.
					 * This will be incremented by the
					 * new owner of the lock when it sees
					 * that it has the lock.                           
					 */
					_thread_fd_table[fd]->r_lockcount = 0;
				}
d308 3
a310 41
		}
		/* Check if the running thread owns the write lock: */
		if (_thread_fd_table[fd]->w_owner == curthread) {
			/* Check the file descriptor and lock types: */
			if (lock_type == FD_WRITE || lock_type == FD_RDWR) {
				/*
				 * Decrement the write lock count for the
				 * running thread: 
				 */
				_thread_fd_table[fd]->w_lockcount--;

				/*
				 * Check if the running thread still has
				 * write locks on this file descriptor: 
				 */
				if (_thread_fd_table[fd]->w_lockcount != 0) {
				}
				/*
				 * Get the next thread in the queue for a
				 * write lock on this file descriptor: 
				 */
				else if ((_thread_fd_table[fd]->w_owner = TAILQ_FIRST(&_thread_fd_table[fd]->w_queue)) == NULL) {
				} else {
					/* Remove this thread from the queue: */
					TAILQ_REMOVE(&_thread_fd_table[fd]->w_queue,
					    _thread_fd_table[fd]->w_owner, qe);

					/*
					 * Set the state of the new owner of
					 * the thread to running: 
					 */
					PTHREAD_NEW_STATE(_thread_fd_table[fd]->w_owner,PS_RUNNING);

					/*
					 * Reset the number of write locks.
					 * This will be incremented by the
					 * new owner of the lock when it  
					 * sees that it has the lock.
					 */
					_thread_fd_table[fd]->w_lockcount = 0;
				}
d312 4
a316 9

		/* Unlock the file descriptor table entry: */
		_SPINUNLOCK(&_thread_fd_table[fd]->lock);

		/*
		 * Undefer and handle pending signals, yielding if
		 * necessary.
		 */
		_thread_kern_sig_undefer();
a317 3

	/* Nothing to return. */
	return;
d320 5
d327 1
a327 1
		char *fname, int lineno)
d330 1
d337 4
a340 1
	if ((ret = _thread_fd_table_init(fd)) == 0) {
d346 4
a349 1
		_spinlock_debug(&_thread_fd_table[fd]->lock, fname, lineno);
d351 1
a351 1
		/* Check the file descriptor and lock types: */
d357 1
a357 1
			while (_thread_fd_table[fd]->r_owner != curthread) {
d362 1
a362 1
				if (_thread_fd_table[fd]->r_owner != NULL) {
d369 2
a370 1
					TAILQ_INSERT_TAIL(&_thread_fd_table[fd]->r_queue, curthread, qe);
d388 1
a388 1
					_SPINUNLOCK(&_thread_fd_table[fd]->lock);
d395 2
a396 3
					 * to the lock by the       thread
					 * that is unlocking the file
					 * descriptor.        
d398 3
a400 1
					_thread_kern_sched_state(PS_FDLR_WAIT, __FILE__, __LINE__);
d406 1
a406 1
					_SPINLOCK(&_thread_fd_table[fd]->lock);
d413 1
a413 1
					_thread_fd_table[fd]->r_owner = curthread;
d419 3
a421 8
					_thread_fd_table[fd]->r_lockcount = 0;

					/*
					 * Save the source file details for
					 * debugging: 
					 */
					_thread_fd_table[fd]->r_fname = fname;
					_thread_fd_table[fd]->r_lineno = lineno;
d426 1
a426 1
			_thread_fd_table[fd]->r_lockcount++;
d429 1
a429 1
		/* Check the file descriptor and lock types: */
d435 1
a435 1
			while (_thread_fd_table[fd]->w_owner != curthread) {
d440 1
a440 1
				if (_thread_fd_table[fd]->w_owner != NULL) {
d448 2
a449 1
					TAILQ_INSERT_TAIL(&_thread_fd_table[fd]->w_queue, curthread, qe);
d467 1
a467 1
					_SPINUNLOCK(&_thread_fd_table[fd]->lock);
d475 1
a475 1
					 * unlocking the file descriptor.        
d477 3
a479 1
					_thread_kern_sched_state(PS_FDLW_WAIT, __FILE__, __LINE__);
d485 1
a485 1
					_SPINLOCK(&_thread_fd_table[fd]->lock);
d489 1
a489 2
					 * write lock on this   file
					 * descriptor: 
d491 1
a491 1
					_thread_fd_table[fd]->w_owner = curthread;
d497 3
a499 8
					_thread_fd_table[fd]->w_lockcount = 0;

					/*
					 * Save the source file details for
					 * debugging: 
					 */
					_thread_fd_table[fd]->w_fname = fname;
					_thread_fd_table[fd]->w_lineno = lineno;
d504 1
a504 1
			_thread_fd_table[fd]->w_lockcount++;
d508 1
a508 1
		_SPINUNLOCK(&_thread_fd_table[fd]->lock);
d514 11
@


1.9
log
@Back out fgsch@@'s tree breaking commits.
Test next time, ok?
@
text
@d1 1
a1 1
/*	$OpenBSD: uthread_fd.c,v 1.8 2001/08/30 07:40:47 fgsch Exp $	*/
d456 1
a456 1
_thread_fd_unlock_debug(int fd, int lock_type, const char *fname, int lineno)
d580 1
a580 1
		const char *fname, int lineno)
@


1.8
log
@fix some const warnings.
more sync with freebsd.
@
text
@d1 1
a1 1
/*	$OpenBSD: uthread_fd.c,v 1.7 2001/08/21 19:24:53 fgsch Exp $	*/
d456 1
a456 1
_thread_fd_unlock_debug(int fd, int lock_type, char *fname, int lineno)
d580 1
a580 1
		char *fname, int lineno)
@


1.7
log
@Start syncing with FreeBSD:

o Implement _get_curthread() and _set_curthread(). Use it where possible.
o Add missing _thread_[enter|leave]_cancellation_point().
o Add a couple of not yet used vars to pthread_private.h.
o Remove return's from void functions.

This is by no means complete, but instead of doing a big commit, i'll
split it in small ones, minimizing diffs.
@
text
@d1 1
a1 1
/*	$OpenBSD: uthread_fd.c,v 1.6 1999/11/25 07:01:34 d Exp $	*/
d456 1
a456 1
_thread_fd_unlock_debug(int fd, int lock_type, const char *fname, int lineno)
d580 1
a580 1
		const char *fname, int lineno)
@


1.6
log
@sync with FreeBSD
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d165 1
d187 1
a187 1
		if (_thread_fd_table[fd]->r_owner == _thread_run) {
d229 1
a229 1
		if (_thread_fd_table[fd]->w_owner == _thread_run) {
d288 1
d309 1
a309 1
			while (_thread_fd_table[fd]->r_owner != _thread_run) {
d321 1
a321 1
					TAILQ_INSERT_TAIL(&_thread_fd_table[fd]->r_queue, _thread_run, qe);
d328 1
a328 1
					_thread_run->data.fd.fd = fd;
d361 1
a361 1
					_thread_fd_table[fd]->r_owner = _thread_run;
d381 1
a381 1
			while (_thread_fd_table[fd]->w_owner != _thread_run) {
d394 1
a394 1
					TAILQ_INSERT_TAIL(&_thread_fd_table[fd]->w_queue, _thread_run, qe);
d401 1
a401 1
					_thread_run->data.fd.fd = fd;
d433 1
a433 1
					_thread_fd_table[fd]->w_owner = _thread_run;
d458 1
d480 1
a480 1
		if (_thread_fd_table[fd]->r_owner == _thread_run) {
d522 1
a522 1
		if (_thread_fd_table[fd]->w_owner == _thread_run) {
d582 1
d603 1
a603 1
			while (_thread_fd_table[fd]->r_owner != _thread_run) {
d615 1
a615 1
					TAILQ_INSERT_TAIL(&_thread_fd_table[fd]->r_queue, _thread_run, qe);
d622 3
a624 3
					_thread_run->data.fd.fd = fd;
					_thread_run->data.fd.branch = lineno;
					_thread_run->data.fd.fname = fname;
d657 1
a657 1
					_thread_fd_table[fd]->r_owner = _thread_run;
d684 1
a684 1
			while (_thread_fd_table[fd]->w_owner != _thread_run) {
d697 1
a697 1
					TAILQ_INSERT_TAIL(&_thread_fd_table[fd]->w_queue, _thread_run, qe);
d704 3
a706 3
					_thread_run->data.fd.fd = fd;
					_thread_run->data.fd.branch = lineno;
					_thread_run->data.fd.fname = fname;
d738 1
a738 1
					_thread_fd_table[fd]->w_owner = _thread_run;
@


1.5
log
@sync with FreeBSD
@
text
@d1 1
d24 1
a24 1
 * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE
d33 1
a33 2
 * $FreeBSD: uthread_fd.c,v 1.10 1999/03/23 05:07:55 jb Exp $
 * $OpenBSD: uthread_fd.c,v 1.4 1999/01/10 23:09:36 d Exp $
d83 1
a83 1
		_SPINUNLOCK(&entry->lock);
d88 4
a91 4
		entry->r_lineno = 0;;
		entry->w_lineno = 0;;
		entry->r_lockcount = 0;;
		entry->w_lockcount = 0;;
d94 2
a95 2
		_thread_queue_init(&entry->r_queue);
		_thread_queue_init(&entry->w_queue);
d98 2
a99 2
		if (fd >= 3 && (entry->flags =
		    _thread_sys_fcntl(fd, F_GETFL, 0)) == -1) {
d101 1
a101 1
		    }
d104 1
a104 1
			if (fd < 3)
d173 6
d205 1
a205 1
				else if ((_thread_fd_table[fd]->r_owner = _thread_queue_deq(&_thread_fd_table[fd]->r_queue)) == NULL) {
d207 4
d247 1
a247 1
				else if ((_thread_fd_table[fd]->w_owner = _thread_queue_deq(&_thread_fd_table[fd]->w_queue)) == NULL) {
d249 4
d272 6
d319 1
a319 1
					_thread_queue_enq(&_thread_fd_table[fd]->r_queue, _thread_run);
d392 1
a392 1
					_thread_queue_enq(&_thread_fd_table[fd]->w_queue, _thread_run);
d454 1
a454 1
_thread_fd_unlock_debug(int fd, int lock_type, char *fname, int lineno)
d464 6
d496 1
a496 1
				else if ((_thread_fd_table[fd]->r_owner = _thread_queue_deq(&_thread_fd_table[fd]->r_queue)) == NULL) {
d498 4
d538 1
a538 1
				else if ((_thread_fd_table[fd]->w_owner = _thread_queue_deq(&_thread_fd_table[fd]->w_queue)) == NULL) {
d540 4
d563 6
d611 1
a611 1
					_thread_queue_enq(&_thread_fd_table[fd]->r_queue, _thread_run);
d693 1
a693 1
					_thread_queue_enq(&_thread_fd_table[fd]->w_queue, _thread_run);
@


1.4
log
@initialise locks properly
@
text
@d32 2
a33 2
 * $FreeBSD: uthread_fd.c,v 1.9 1998/09/13 15:33:42 dt Exp $
 * $OpenBSD: uthread_fd.c,v 1.3 1998/12/23 22:49:46 d Exp $
d203 1
a203 1
					 * the thread to  running: 
@


1.3
log
@preserve FreeBSD idents
@
text
@d33 1
a33 1
 * $OpenBSD: uthread_fd.c,v 1.2 1998/11/09 03:13:19 d Exp $
d83 1
a83 1
		memset(&entry->lock, 0, sizeof(entry->lock));
@


1.2
log
@sync with FreeBSD (rwlock, gc thread, man pages)
add (broken) mips md stuff
fix some const warnings
add sigaltstack() stub
another hash at getting shlib auto-init to work (mips/elf and i386/a.out)
@
text
@d32 2
a33 2
 * $Id: uthread_fd.c,v 1.1 1998/08/27 09:01:01 d Exp $
 * $OpenBSD: uthread_fd.c,v 1.1 1998/08/27 09:01:01 d Exp $
@


1.1
log
@experimental threaded libc - kernel only
@
text
@d32 2
a33 2
 * $Id: uthread_fd.c,v 1.8 1998/06/09 23:16:53 jb Exp $
 * $OpenBSD$
d59 1
d121 1
d124 1
d537 1
a537 1
		char *fname, int lineno)
@

