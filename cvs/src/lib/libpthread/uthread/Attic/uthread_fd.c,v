head	1.34;
access;
symbols
	OPENBSD_5_2:1.33.0.12
	OPENBSD_5_2_BASE:1.33
	OPENBSD_5_1_BASE:1.33
	OPENBSD_5_1:1.33.0.10
	OPENBSD_5_0:1.33.0.8
	OPENBSD_5_0_BASE:1.33
	OPENBSD_4_9:1.33.0.6
	OPENBSD_4_9_BASE:1.33
	OPENBSD_4_8:1.33.0.4
	OPENBSD_4_8_BASE:1.33
	OPENBSD_4_7:1.33.0.2
	OPENBSD_4_7_BASE:1.33
	OPENBSD_4_6:1.31.0.6
	OPENBSD_4_6_BASE:1.31
	OPENBSD_4_5:1.31.0.2
	OPENBSD_4_5_BASE:1.31
	OPENBSD_4_4:1.30.0.6
	OPENBSD_4_4_BASE:1.30
	OPENBSD_4_3:1.30.0.4
	OPENBSD_4_3_BASE:1.30
	OPENBSD_4_2:1.30.0.2
	OPENBSD_4_2_BASE:1.30
	OPENBSD_4_1:1.27.0.2
	OPENBSD_4_1_BASE:1.27
	OPENBSD_4_0:1.22.0.10
	OPENBSD_4_0_BASE:1.22
	OPENBSD_3_9:1.22.0.8
	OPENBSD_3_9_BASE:1.22
	OPENBSD_3_8:1.22.0.6
	OPENBSD_3_8_BASE:1.22
	OPENBSD_3_7:1.22.0.4
	OPENBSD_3_7_BASE:1.22
	OPENBSD_3_6:1.22.0.2
	OPENBSD_3_6_BASE:1.22
	OPENBSD_3_5:1.21.0.6
	OPENBSD_3_5_BASE:1.21
	OPENBSD_3_4:1.21.0.4
	OPENBSD_3_4_BASE:1.21
	OPENBSD_3_3:1.21.0.2
	OPENBSD_3_3_BASE:1.21;
locks; strict;
comment	@ * @;


1.34
date	2012.09.01.00.32.23;	author guenther;	state dead;
branches;
next	1.33;

1.33
date	2010.01.03.23.05.35;	author fgsch;	state Exp;
branches;
next	1.32;

1.32
date	2009.12.06.17.54.59;	author kurt;	state Exp;
branches;
next	1.31;

1.31
date	2008.10.02.23.27.24;	author deraadt;	state Exp;
branches;
next	1.30;

1.30
date	2007.05.18.19.28.50;	author kurt;	state Exp;
branches;
next	1.29;

1.29
date	2007.04.27.18.04.08;	author kurt;	state Exp;
branches;
next	1.28;

1.28
date	2007.04.27.12.59.24;	author kurt;	state Exp;
branches;
next	1.27;

1.27
date	2006.12.01.16.34.41;	author kurt;	state Exp;
branches;
next	1.26;

1.26
date	2006.09.26.15.09.59;	author kurt;	state Exp;
branches;
next	1.25;

1.25
date	2006.09.26.14.18.28;	author kurt;	state Exp;
branches;
next	1.24;

1.24
date	2006.09.23.12.25.58;	author kurt;	state Exp;
branches;
next	1.23;

1.23
date	2006.09.22.19.04.33;	author kurt;	state Exp;
branches;
next	1.22;

1.22
date	2004.06.07.21.11.23;	author marc;	state Exp;
branches;
next	1.21;

1.21
date	2003.02.14.03.58.42;	author marc;	state Exp;
branches;
next	1.20;

1.20
date	2003.02.05.06.20.36;	author marc;	state Exp;
branches;
next	1.19;

1.19
date	2003.02.05.06.19.09;	author marc;	state Exp;
branches;
next	1.18;

1.18
date	2003.02.05.05.51.51;	author marc;	state Exp;
branches;
next	1.17;

1.17
date	2003.02.04.22.14.27;	author marc;	state Exp;
branches;
next	1.16;

1.16
date	2003.01.19.21.22.31;	author marc;	state Exp;
branches;
next	1.15;

1.15
date	2002.11.12.20.12.45;	author marc;	state Exp;
branches;
next	1.14;

1.14
date	2002.11.05.22.19.56;	author marc;	state Exp;
branches;
next	1.13;

1.13
date	2002.11.03.23.58.39;	author marc;	state Exp;
branches;
next	1.12;

1.12
date	2002.11.03.20.36.43;	author marc;	state Exp;
branches;
next	1.11;

1.11
date	2002.10.30.20.05.11;	author marc;	state Exp;
branches;
next	1.10;

1.10
date	2001.09.04.22.17.45;	author fgsch;	state Exp;
branches;
next	1.9;

1.9
date	2001.08.30.17.47.57;	author todd;	state Exp;
branches;
next	1.8;

1.8
date	2001.08.30.07.40.47;	author fgsch;	state Exp;
branches;
next	1.7;

1.7
date	2001.08.21.19.24.53;	author fgsch;	state Exp;
branches;
next	1.6;

1.6
date	99.11.25.07.01.34;	author d;	state Exp;
branches;
next	1.5;

1.5
date	99.05.26.00.18.23;	author d;	state Exp;
branches;
next	1.4;

1.4
date	99.01.10.23.09.36;	author d;	state Exp;
branches;
next	1.3;

1.3
date	98.12.23.22.49.46;	author d;	state Exp;
branches;
next	1.2;

1.2
date	98.11.09.03.13.19;	author d;	state Exp;
branches;
next	1.1;

1.1
date	98.08.27.09.01.01;	author d;	state Exp;
branches;
next	;


desc
@@


1.34
log
@   So passes uthreads
Like autumn leaves on water
   don't fear the tedu@@
@
text
@/*	$OpenBSD: uthread_fd.c,v 1.33 2010/01/03 23:05:35 fgsch Exp $	*/
/*
 * Copyright (c) 1995-1998 John Birrell <jb@@cimlogic.com.au>
 * All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *	This product includes software developed by John Birrell.
 * 4. Neither the name of the author nor the names of any co-contributors
 *    may be used to endorse or promote products derived from this software
 *    without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY JOHN BIRRELL AND CONTRIBUTORS ``AS IS'' AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE
 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
 *
 * $FreeBSD: uthread_fd.c,v 1.13 1999/08/28 00:03:31 peter Exp $
 *
 */
#include <sys/types.h>
#include <sys/stat.h>
#include <sys/socket.h>
#include <errno.h>
#include <fcntl.h>
#include <stdlib.h>
#include <string.h>
#ifdef _THREAD_SAFE
#include <pthread.h>
#include "pthread_private.h"

/* Static variables: */

static struct fd_table_entry	*_thread_fd_entries;
static struct fs_flags		*_thread_fd_flags;

static SLIST_HEAD(, fd_table_entry)	_thread_fd_entries_head;
static SLIST_HEAD(, fs_flags)		_thread_fd_flags_head;

int
_thread_fd_init_mem(void)
{
	int fd;

	_thread_fd_entries = calloc((size_t)_thread_max_fdtsize,
				  sizeof(struct fd_table_entry));
	if (_thread_fd_entries == NULL)
		return (-1);

	_thread_fd_flags = calloc((size_t)_thread_max_fdtsize,
				  sizeof(struct fs_flags));
	if (_thread_fd_flags == NULL) {
		free(_thread_fd_entries);
		_thread_fd_entries = NULL;
		return (-1);
	}

	/* add pre-allocated entries to freelists */
	for (fd = 0; fd < _thread_max_fdtsize; fd++)
	{
		SLIST_INSERT_HEAD(&_thread_fd_entries_head, &_thread_fd_entries[fd], fe);
		SLIST_INSERT_HEAD(&_thread_fd_flags_head, &_thread_fd_flags[fd], fe);
        }

	return (0);
}

/*
 * Build a new fd entry and return it.
 */
static struct fs_flags *
_thread_fs_flags_entry(void)
{
	struct fs_flags *entry;

        _thread_kern_sig_defer();
        entry = SLIST_FIRST(&_thread_fd_flags_head);
	if (entry != NULL) {
		SLIST_REMOVE_HEAD(&_thread_fd_flags_head, fe);
		memset(entry, 0, sizeof *entry);
	}
        _thread_kern_sig_undefer();
	return entry;
}

static void
_thread_fs_flags_free(struct fs_flags *entry)
{
        _thread_kern_sig_defer();
	SLIST_INSERT_HEAD(&_thread_fd_flags_head, entry, fe);
        _thread_kern_sig_undefer();
}

/*
 * Initialize a new status_flags entry and set system
 * file descriptor non-blocking.
 */
static int
_thread_fs_flags_init(struct fs_flags *status_flags, int fd)
{
	int ret = 0;
	int saved_errno;

	status_flags->flags = _thread_sys_fcntl(fd, F_GETFL, 0);
	if (status_flags->flags == -1)
		/* use the errno fcntl returned */
		ret = -1;
	else {
		/*
		 * Make the file descriptor non-blocking.
		 * This might fail if the device driver does
		 * not support non-blocking calls, or if the
		 * driver is naturally non-blocking.
		 */
		if ((status_flags->flags & O_NONBLOCK) == 0) {
			saved_errno = errno;
			_thread_sys_fcntl(fd, F_SETFL,
				  status_flags->flags | O_NONBLOCK);
			errno = saved_errno;
		}
	}

	return (ret);
}

/*
 * If existing entry's status_flags don't match new one,
 * then replace the current status flags with the new one.
 * It is assumed the entry is locked with a FD_RDWR_CLOSE
 * lock when this function is called.
 */
void
_thread_fs_flags_replace(int fd, struct fs_flags *new_status_flags)
{
	struct fd_table_entry *entry = _thread_fd_table[fd];
	struct fs_flags *old_status_flags;
	struct stat sb;
	int flags;
	int saved_errno;

        _thread_kern_sig_defer();
	if (entry->status_flags != new_status_flags) {
		if (entry->status_flags != NULL) {
			old_status_flags = entry->status_flags;
			old_status_flags->refcnt -= 1;
			if (old_status_flags->refcnt <= 0) {
				/*
				 * Check if the file should be left as blocking.
				 *
				 * This is so that the file descriptors shared with a parent
				 * process aren't left set to non-blocking if the child
				 * closes them prior to exit.  An example where this causes
				 * problems with /bin/sh is when a child closes stdin.
				 *
				 * Setting a file as blocking causes problems if a threaded
				 * parent accesses the file descriptor before the child exits.
				 * Once the threaded parent receives a SIGCHLD then it resets
				 * all of its files to non-blocking, and so it is then safe
				 * to access them.
				 *
				 * Pipes are not set to blocking when they are closed, as
				 * the parent and child will normally close the file
				 * descriptor of the end of the pipe that they are not
				 * using, which would then cause any reads to block
				 * indefinitely. However, stdin/out/err will be reset
				 * to avoid leaving them as non-blocking indefinitely.
				 *
				 * Files that we cannot fstat are probably not regular
				 * so we don't bother with them.
				 *
				 * Also don't reset fd to blocking if we are replacing
				 * the status flags with a shared version.
				 */
				saved_errno = errno;
				if (new_status_flags == NULL &&
				    (old_status_flags->flags & O_NONBLOCK) == 0 &&
				    (fd < 3 || (_thread_sys_fstat(fd, &sb) == 0 &&
				    (S_ISREG(sb.st_mode) || S_ISCHR(sb.st_mode)))))
				{
					/* Get the current flags: */
					flags = _thread_sys_fcntl(fd, F_GETFL, NULL);
					/* Clear the nonblocking file descriptor flag: */
					_thread_sys_fcntl(fd, F_SETFL, flags & ~O_NONBLOCK);
				}
				_thread_fs_flags_free(old_status_flags);
				errno = saved_errno;
			}
		}
		/* replace with new status flags */
		if (new_status_flags != NULL) {
			new_status_flags->refcnt += 1;
		}
		entry->status_flags = new_status_flags;
	}
        _thread_kern_sig_undefer();
}

/*
 * Build a new fd entry and return it.
 */
static struct fd_table_entry *
_thread_fd_entry(void)
{
	struct fd_table_entry *entry;

        _thread_kern_sig_defer();
        entry = SLIST_FIRST(&_thread_fd_entries_head);
	if (entry != NULL) {
		SLIST_REMOVE_HEAD(&_thread_fd_entries_head, fe);
		memset(entry, 0, sizeof *entry);
		TAILQ_INIT(&entry->r_queue);
		TAILQ_INIT(&entry->w_queue);
		entry->state = FD_ENTRY_CLOSED;
		entry->init_mode = FD_INIT_UNKNOWN;
	}
        _thread_kern_sig_undefer();
	return entry;
}

static void
_thread_fs_entry_free(struct fd_table_entry *entry)
{
        _thread_kern_sig_defer();
	SLIST_INSERT_HEAD(&_thread_fd_entries_head, entry, fe);
        _thread_kern_sig_undefer();
}

/*
 * Initialize the thread fd table for dup-ed fds, typically the stdio
 * fds.
 */

void
_thread_fd_init(void)
{
	int saved_errno;
	int fd;
	int fd2;
	int flag;
	int *flags;
	struct fd_table_entry *entry1, *entry2;
	struct fs_flags *status_flags;

        _thread_fd_init_mem();

	saved_errno = errno;
	flags = calloc((size_t)_thread_init_fdtsize, sizeof *flags);
	if (flags == NULL)
		PANIC("Cannot allocate memory for flags table");

	/* read the current file flags */
	for (fd = 0; fd < _thread_init_fdtsize; fd += 1)
		flags[fd] = _thread_sys_fcntl(fd, F_GETFL, 0);

	/*
	 * Now toggle the sync flags and see what other fd's
	 * change.   Those are the dup-ed fd's.   Dup-ed fd's are
	 * added to the table, all others are NOT added to the
	 * table.  They MUST NOT be added as the fds may belong
	 * to dlopen.   As dlclose doesn't go through the thread code
	 * so the entries would never be cleaned.
	 */

        _thread_kern_sig_defer();
	for (fd = 0; fd < _thread_init_fdtsize; fd += 1) {
		if (flags[fd] == -1)
			continue;
		entry1 = _thread_fd_entry();
		status_flags = _thread_fs_flags_entry();
		if (entry1 != NULL && status_flags != NULL) {
			_thread_sys_fcntl(fd, F_SETFL,
					  flags[fd] ^ O_SYNC);
			for (fd2 = fd + 1; fd2 < _thread_init_fdtsize; fd2 += 1) {
				if (flags[fd2] == -1)
					continue;
				flag = _thread_sys_fcntl(fd2, F_GETFL, 0);
				if (flag != flags[fd2]) {
					entry2 = _thread_fd_entry();
					if (entry2 != NULL) {
						status_flags->refcnt += 1;
						entry2->status_flags = status_flags;
						entry2->state = FD_ENTRY_OPEN;
						entry2->init_mode = FD_INIT_DUP2;
						_thread_fd_table[fd2] = entry2;
					} else
						PANIC("Cannot allocate memory for flags table");
					flags[fd2] = -1;
				}
			}
			if (status_flags->refcnt) {
				status_flags->refcnt += 1;
				status_flags->flags = flags[fd];
				entry1->status_flags = status_flags;
				entry1->state = FD_ENTRY_OPEN;
				entry1->init_mode = FD_INIT_DUP2;
				_thread_fd_table[fd] = entry1;
				flags[fd] |= O_NONBLOCK;
			} else {
				_thread_fs_entry_free(entry1);
				_thread_fs_flags_free(status_flags);
			}
		} else {
			PANIC("Cannot allocate memory for flags table");
		}
	}
        _thread_kern_sig_undefer();

	/* lastly, restore the file flags.   Flags for files that we
	   know to be duped have been modified so set the non-blocking'
	   flag.  Other files will be set to non-blocking when the
	   thread code is forced to take notice of the file. */
	for (fd = 0; fd < _thread_init_fdtsize; fd += 1)
		if (flags[fd] != -1)
			_thread_sys_fcntl(fd, F_SETFL, flags[fd]);

	free(flags);
	errno = saved_errno;
}

/*
 * Initialize the fd_table entry for the given fd.
 *
 * This function *must* return -1 and set the thread specific errno
 * as a system call. This is because the error return from this
 * function is propagated directly back from thread-wrapped system
 * calls.
 */
int
_thread_fd_table_init(int fd, enum fd_entry_mode init_mode, struct fs_flags *status_flags)
{
	int	ret = 0;
	int	saved_errno;
	struct fd_table_entry *entry;
	struct fs_flags *new_status_flags;

	if (fd < 0 || fd >= _thread_max_fdtsize) {
		/*
		 * file descriptor is out of range, Return a bad file
		 * descriptor error:
		 */ 
		errno = EBADF;
		return (-1);
	}
	
	if (_thread_fd_table[fd] == NULL) {
		/* First time for this fd, build an entry */
		entry = _thread_fd_entry();
		if (entry == NULL) {
			/* use _thread_fd_entry errno */
			ret = -1;
		} else {
			/* Protect the file descriptor table: */
        		_thread_kern_sig_defer();

			/*
			 * Check if another thread allocated the
			 * file descriptor entry while this thread
			 * was doing the same thing. The table wasn't
			 * kept locked during this operation because
			 * it has the potential to recurse.
			 */
			if (_thread_fd_table[fd] == NULL) {
				/* This thread wins: */
				_thread_fd_table[fd] = entry;
				entry = NULL;
			}

			/* Unprotect the file descriptor table: */
        		_thread_kern_sig_undefer();

			/*
			 * If another thread initialized the table entry
			 * throw the new entry away.
			 */
			if (entry != NULL)
				_thread_fs_entry_free(entry);
		}
	}

	if (ret == 0) {
		entry = _thread_fd_table[fd];
       		_thread_kern_sig_defer();
		switch (init_mode) {
		case FD_INIT_UNKNOWN:
			/*
			 * If the entry is closed, try to open it
			 * anyway since we may have inherited it or
			 * it may have been created by an unwrapped
			 * call such as openpty(3). Since we allow
			 * FD_RDWR_CLOSE locks on closed entries,
			 * we ignore EBADF status flags errors and
			 * return a closed entry. If the entry is
			 * not closed then there's nothing to do.
			 */
			if (entry->state == FD_ENTRY_CLOSED) {
				new_status_flags = _thread_fs_flags_entry();
				if (new_status_flags == NULL) {
					/* use _thread_fs_flags_entry errno */
					ret = -1;
				} else {
					saved_errno = errno;
					ret = _thread_fs_flags_init(new_status_flags, fd);
					if (ret == 0) {
						errno = saved_errno;
						new_status_flags->refcnt = 1;
						entry->status_flags = new_status_flags;
						new_status_flags = NULL;
						entry->state = FD_ENTRY_OPEN;
						entry->init_mode = init_mode;
					} else if (errno == EBADF) {
						errno = saved_errno;
						ret = 0;
					}
				}
				/* if flags init failed free new flags */
				if (new_status_flags != NULL)
					_thread_fs_flags_free(new_status_flags);
			}
			break;
		case FD_INIT_NEW:
			/*
			 * If the entry was initialized and opened
			 * by another thread (i.e. FD_INIT_DUP2 or
			 * FD_INIT_UNKNOWN), the status flags will
			 * be correct.
			 */
			if (entry->state == FD_ENTRY_CLOSED) {
				new_status_flags = _thread_fs_flags_entry();
				if (new_status_flags == NULL) {
					/* use _thread_fs_flags_entry errno */
					ret = -1;
				} else {
					ret = _thread_fs_flags_init(new_status_flags, fd);
				}
				if (ret == 0) {
					new_status_flags->refcnt = 1;
					entry->status_flags = new_status_flags;
					new_status_flags = NULL;
					entry->state = FD_ENTRY_OPEN;
					entry->init_mode = init_mode;
				}
				/* if flags init failed free new flags */
				if (new_status_flags != NULL)
					_thread_fs_flags_free(new_status_flags);
			}
			break;
		case FD_INIT_BLOCKING:
			/*
			 * If the entry was initialized and opened
			 * by another thread with FD_INIT_DUP2, the
			 * status flags will be correct. However,
			 * if FD_INIT_UNKNOWN raced in before us
			 * it means the app is not well behaved and
			 * tried to use the fd before it was returned
			 * to the client.
			 */
			if (entry->state == FD_ENTRY_CLOSED) {
				new_status_flags = _thread_fs_flags_entry();
				if (new_status_flags == NULL) {
					/* use _thread_fs_flags_entry errno */
					ret = -1;
				} else {
					ret = _thread_fs_flags_init(new_status_flags, fd);
				}
				if (ret == 0) {
					/* set user's view of status flags to blocking */
					new_status_flags->flags &= ~O_NONBLOCK;
					new_status_flags->refcnt = 1;
					entry->status_flags = new_status_flags;
					new_status_flags = NULL;
					entry->state = FD_ENTRY_OPEN;
					entry->init_mode = init_mode;
				}
				/* if flags init failed free new flags */
				if (new_status_flags != NULL)
					_thread_fs_flags_free(new_status_flags);
			} else if (entry->state == FD_ENTRY_OPEN &&
			    entry->init_mode == FD_INIT_UNKNOWN) {
				entry->status_flags->flags &= ~O_NONBLOCK;
			}
			break;
		case FD_INIT_DUP:
			/*
			 * If the entry was initialized and opened
			 * by another thread with FD_INIT_DUP2 then
			 * keep it. However, if FD_INIT_UNKNOWN raced
			 * in before us it means the app is not well
			 * behaved and tried to use the fd before it
			 * was returned to the client.
			 */
			if (entry->state == FD_ENTRY_CLOSED) {
				_thread_fs_flags_replace(fd, status_flags);
				entry->state = FD_ENTRY_OPEN;
				entry->init_mode = init_mode;
			} else if (entry->state == FD_ENTRY_OPEN &&
			    entry->init_mode == FD_INIT_UNKNOWN) {
				_thread_fs_flags_replace(fd, status_flags);
			}
			break;
		case FD_INIT_DUP2:
			/*
			 * This is only called when FD_RDWR_CLOSE
			 * is held and in state FD_ENTRY_CLOSING.
			 * Just replace flags and open entry.
			 * FD_INIT_UNKNOWN can't race in since we
			 * are in state FD_ENTRY_CLOSING before
			 * the _thread_sys_dup2 happens.
			 */
			_thread_fs_flags_replace(fd, status_flags);
			entry->state = FD_ENTRY_OPEN;
			entry->init_mode = init_mode;
			break;
		}
       		_thread_kern_sig_undefer();
	}

	/* Return the completion status: */
	return (ret);
}

/*
 * Close an fd entry. Replace existing status flags
 * with NULL. The entry is assummed to be locked with
 * a FD_RDWR_CLOSE lock and in state FD_ENTRY_CLOSING.
 */
void
_thread_fd_entry_close(int fd)
{
	_thread_fs_flags_replace(fd, NULL);
	_thread_fd_table[fd]->state = FD_ENTRY_CLOSED;
}

/*
 * Unlock an fd table entry for the given fd and lock type.
 */
void
_thread_fd_unlock(int fd, int lock_type)
{
	struct pthread *thread = _get_curthread();
	struct fd_table_entry *entry;

	/*
	 * If file descriptor is out of range or uninitialized,
	 * do nothing.
	 */ 
	if (fd >= 0 && fd < _thread_max_fdtsize && _thread_fd_table[fd] != NULL) {
		entry = _thread_fd_table[fd];

		/*
		 * Defer signals to protect the scheduling queues from
		 * access by the signal handler:
		 */
		_thread_kern_sig_defer();

		/* Check if the running thread owns the read lock: */
		if (entry->r_owner == thread &&
		    (lock_type & FD_READ)) {
			/*
			 * Decrement the read lock count for the
			 * running thread: 
			 */
			entry->r_lockcount--;
			if (entry->r_lockcount == 0) {
				/*
				 * no read locks, dequeue any threads
				 * waiting for a read lock
				 */
				entry->r_owner = TAILQ_FIRST(&entry->r_queue);
				if (entry->r_owner != NULL) {
					TAILQ_REMOVE(&entry->r_queue,
						     entry->r_owner, qe);

					/*
					 * Set the state of the new owner of
					 * the thread to running:  
					 */
					PTHREAD_NEW_STATE(entry->r_owner,
							  PS_RUNNING);

					/*
					 * Reset the number of read locks.
					 * This will be incremented by the new
					 * owner of the lock when it sees that
					 *it has the lock.
					 */
					entry->r_lockcount = 0;
				}
			}

		}
		/* Check if the running thread owns the write lock: */
		if (entry->w_owner == thread &&
		    (lock_type & FD_WRITE)) {
			/*
			 * Decrement the write lock count for the
			 * running thread: 
			 */
			entry->w_lockcount--;
			if (entry->w_lockcount == 0) {
				/*
				 * no write locks, dequeue any threads
				 * waiting on a write lock.
				 */
				entry->w_owner = TAILQ_FIRST(&entry->w_queue);
				if (entry->w_owner != NULL) {
					/* Remove this thread from the queue: */
					TAILQ_REMOVE(&entry->w_queue,
						     entry->w_owner, qe);

					/*
					 * Set the state of the new owner of
					 * the thread to running: 
					 */
					PTHREAD_NEW_STATE(entry->w_owner,
							  PS_RUNNING);

					/*
					 * Reset the number of write locks.
					 * This will be incremented by the
					 * new owner of the lock when it  
					 * sees that it has the lock.
					 */
					entry->w_lockcount = 0;
				}
			}
		}

		/*
		 * Undefer and handle pending signals, yielding if
		 * necessary:
		 */
		_thread_kern_sig_undefer();
	}
}

/*
 * Lock an fd table entry for the given fd and lock type.
 */
int
_thread_fd_lock(int fd, int lock_type, struct timespec * timeout)
{
	struct pthread	*curthread = _get_curthread();
	struct fd_table_entry *entry;
	int	ret;

	/*
	 * Check that the file descriptor table is initialised for this
	 * entry: 
	 */
	ret = _thread_fd_table_init(fd, FD_INIT_UNKNOWN, NULL);
	if (ret == 0) {
		entry = _thread_fd_table[fd];

		/*
		 * Protect the file descriptor table entry to prevent
		 * other threads for clashing with the current
		 * thread's accesses:
		 */
		_thread_kern_sig_defer();

		/* reject all new locks on entries that are closing */
		if (entry->state == FD_ENTRY_CLOSING) {
			ret = -1;
			errno = EBADF;
		} else if (lock_type == FD_RDWR_CLOSE) {
			/* allow closing locks on open and closed entries */
			entry->state = FD_ENTRY_CLOSING;
		} else if (entry->state == FD_ENTRY_CLOSED) {
			ret = -1;
			errno = EBADF;
		}

		/* Handle read locks */
		if (ret == 0 && (lock_type & FD_READ)) {
			/*
			 * Enter a loop to wait for the file descriptor to be
			 * locked    for read for the current thread: 
			 */
			while (entry->r_owner != curthread) {
				/*
				 * Check if the file descriptor is locked by
				 * another thread: 
				 */
				if (entry->r_owner != NULL) {
					/*
					 * Another thread has locked the file
					 * descriptor for read, so join the
					 * queue of threads waiting for a  
					 * read lock on this file descriptor: 
					 */
					TAILQ_INSERT_TAIL(&entry->r_queue,
							  curthread, qe);

					/*
					 * Save the file descriptor details
					 * in the thread structure for the
					 * running thread: 
					 */
					curthread->data.fd.fd = fd;

					/* Set the timeout: */
					_thread_kern_set_timeout(timeout);

					/*
					 * Unprotect the file descriptor
					 * table entry:
					 */
					_thread_kern_sig_undefer();

					/*
					 * Schedule this thread to wait on
					 * the read lock. It will only be
					 * woken when it becomes the next in
					 * the queue and is granted access
					 * to the lock by the thread that is
					 * unlocking the file descriptor.
					 */
					_thread_kern_sched_state(PS_FDLR_WAIT,
								 __FILE__,
								 __LINE__);

					/*
					 * Protect the file descriptor
					 * table entry again:
					 */
					_thread_kern_sig_defer();

				} else {
					/*
					 * The running thread now owns the
					 * read lock on this file descriptor: 
					 */
					entry->r_owner = curthread;

					/*
					 * Reset the number of read locks for
					 * this file descriptor: 
					 */
					entry->r_lockcount = 0;
				}
			}

			/* Increment the read lock count: */
			entry->r_lockcount++;
		}

		/* Handle write locks */
		if (ret == 0 && (lock_type & FD_WRITE)) {
			/*
			 * Enter a loop to wait for the file descriptor to be
			 * locked for write for the current thread: 
			 */
			while (entry->w_owner != curthread) {
				/*
				 * Check if the file descriptor is locked by
				 * another thread: 
				 */
				if (entry->w_owner != NULL) {
					/*
					 * Another thread has locked the file
					 * descriptor for write, so join the
					 * queue of threads waiting for a 
					 * write lock on this file
					 * descriptor: 
					 */
					TAILQ_INSERT_TAIL(&entry->w_queue,
							  curthread, qe);

					/*
					 * Save the file descriptor details
					 * in the thread structure for the
					 * running thread: 
					 */
					curthread->data.fd.fd = fd;

					/* Set the timeout: */
					_thread_kern_set_timeout(timeout);

					/*
					 * Unprotect the file descriptor
					 * table entry:
					 */
					_thread_kern_sig_undefer();

					/*
					 * Schedule this thread to wait on
					 * the write lock. It will only be
					 * woken when it becomes the next in
					 * the queue and is granted access to
					 * the lock by the thread that is
					 * unlocking the file descriptor.
					 */
					_thread_kern_sched_state(PS_FDLW_WAIT,
								 __FILE__,
								 __LINE__);

					/*
					 * Unprotect the file descriptor
					 * table entry again:
					 */
					_thread_kern_sig_defer();
				} else {
					/*
					 * The running thread now owns the
					 * write lock on this file descriptor: 
					 */
					entry->w_owner = curthread;

					/*
					 * Reset the number of write locks
					 * for this file descriptor: 
					 */
					entry->w_lockcount = 0;
				}
			}

			/* Increment the write lock count: */
			entry->w_lockcount++;
		}

		/* Unprotect the file descriptor table entry: */
		_thread_kern_sig_undefer();
	}

	/* Return the completion status: */
	return (ret);
}

struct timespec *
_thread_fd_timeout(int fd, int which)
{
	struct timeval tv;
	socklen_t len;
	int saved_errno;
	
	/* Avoid calling getsockopt if fd is not a socket. */
	if (!(_thread_fd_table[fd]->status_flags->flags & _FD_NOTSOCK)) {
		len = sizeof(tv);
		saved_errno = errno;
		if (_thread_sys_getsockopt(fd, SOL_SOCKET, which ?
		    SO_SNDTIMEO : SO_RCVTIMEO, &tv, &len) == 0) {
			if (timerisset(&tv)) {
				static struct timespec ts;
				TIMEVAL_TO_TIMESPEC(&tv, &ts);
				return (&ts);
			}
		} else if (errno == ENOTSOCK)
			_thread_fd_table[fd]->status_flags->flags |=
			    _FD_NOTSOCK;
		errno = saved_errno;
	}
	return (NULL);
}

#endif
@


1.33
log
@Make SO_RCVTIMEO and SO_SNDTIMEO work with pthreads. Fixes at least some of
the issues seen with www/varnish.
With input and help from guenther@@ and kurt@@. guenther@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: uthread_fd.c,v 1.32 2009/12/06 17:54:59 kurt Exp $	*/
@


1.32
log
@Make internal file descriptor handling async-signal safe by eliminating
the use of spinlocks and malloc. All needed memory is allocated upfront
and _thread_kern_sig_defer/undefer() is now used to protect critical
sections. okay guenther@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uthread_fd.c,v 1.31 2008/10/02 23:27:24 deraadt Exp $	*/
d36 3
a42 1
#include <sys/stat.h>
d729 1
a729 1
					 * the   queue and is granted access
d842 26
@


1.31
log
@Fix PR #5942: preserve errno across fd flag updates, so that successful
calls to close(), closefrom(), and dup2() don't change it.

ok tedu@@, deraadt@@, kurt@@, millert@@, art@@, marco@@
(miscommit: originally by guenther@@)
@
text
@d1 1
a1 1
/*	$OpenBSD: uthread_fd.c,v 1.30 2007/05/18 19:28:50 kurt Exp $	*/
d46 34
a79 1
static	spinlock_t	fd_table_lock	= _SPINLOCK_INITIALIZER;
d89 2
a90 1
	entry = (struct fs_flags *) malloc(sizeof(struct fs_flags));
d92 1
a93 1
		_SPINLOCK_INIT(&entry->lock);
d95 1
d99 8
d154 1
a157 1
			_SPINLOCK(&old_status_flags->lock);
d198 1
a198 1
				free(old_status_flags);
d200 1
a200 2
			} else
				_SPINUNLOCK(&old_status_flags->lock);
a203 1
			_SPINLOCK(&new_status_flags->lock);
a204 1
			_SPINUNLOCK(&new_status_flags->lock);
d208 1
d219 2
a220 1
	entry = (struct fd_table_entry *) malloc(sizeof(struct fd_table_entry));
d222 1
a223 1
		_SPINLOCK_INIT(&entry->lock);
d229 1
d233 8
d257 2
d277 1
a277 1
	_SPINLOCK(&fd_table_lock);
d312 2
a313 2
				free(entry1);
				free(status_flags);
d319 1
a319 1
	_SPINUNLOCK(&fd_table_lock);
d365 2
a366 2
			/* Lock the file descriptor table: */
			_SPINLOCK(&fd_table_lock);
d381 2
a382 2
			/* Unlock the file descriptor table: */
			_SPINUNLOCK(&fd_table_lock);
d389 1
a389 1
				free(entry);
d395 1
a395 1
		_SPINLOCK(&entry->lock);
d430 1
a430 1
					free(new_status_flags);
d457 1
a457 1
					free(new_status_flags);
d489 1
a489 1
					free(new_status_flags);
d527 1
a527 1
		_SPINUNLOCK(&entry->lock);
a567 7
		/*
		 * Lock the file descriptor table entry to prevent
		 * other threads for clashing with the current
		 * thread's accesses:
		 */
		_SPINLOCK(&entry->lock);

a640 3
		/* Unlock the file descriptor table entry: */
		_SPINUNLOCK(&entry->lock);

d668 1
a668 1
		 * Lock the file descriptor table entry to prevent
d672 1
a672 1
		_SPINLOCK(&entry->lock);
d718 1
a718 1
					 * Unlock the file descriptor
d721 1
a721 1
					_SPINUNLOCK(&entry->lock);
d736 1
a736 1
					 * Lock the file descriptor
d739 1
a739 1
					_SPINLOCK(&entry->lock);
d793 1
a793 1
					 * Unlock the file descriptor
d796 1
a796 1
					_SPINUNLOCK(&entry->lock);
d811 1
a811 1
					 * Lock the file descriptor
d814 1
a814 1
					_SPINLOCK(&entry->lock);
d834 2
a835 2
		/* Unlock the file descriptor table entry: */
		_SPINUNLOCK(&entry->lock);
@


1.30
log
@Eliminate many lint warnings by either: using the appropriate type,
casting when safe or adding ARGSUSED where needed. Reviewed and
improvements from millert@@ and marc@@. okay marc@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uthread_fd.c,v 1.29 2007/04/27 18:04:08 kurt Exp $	*/
d109 1
d144 1
d156 1
@


1.29
log
@Remove unused function _thread_fd_unlock_owned() and
merge _thread_fd_unlock_thread() into _thread_fd_unlock(). okay marc@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uthread_fd.c,v 1.28 2007/04/27 12:59:24 kurt Exp $	*/
d204 1
a204 1
	flags = calloc(_thread_init_fdtsize, sizeof *flags);
@


1.28
log
@Use rlimit nofiles max to size fd/fdp tables instead of cur. Fixes
applications that increase nofiles using setrlimit(2). ok marc@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uthread_fd.c,v 1.27 2006/12/01 16:34:41 kurt Exp $	*/
d491 1
a491 1
 * Unlock the fd table entry for a given thread, fd, and lock type.
d494 1
a494 1
_thread_fd_unlock_thread(struct pthread	*thread, int fd, int lock_type)
d496 1
a599 41
	}
}

/*
 * Unlock an fd table entry for the given fd and lock type.
 */
void
_thread_fd_unlock(int fd, int lock_type)
{
	struct pthread	*curthread = _get_curthread();
	_thread_fd_unlock_thread(curthread, fd, lock_type);
}

/*
 * Unlock all fd table entries owned by the given thread
 */
void
_thread_fd_unlock_owned(pthread_t pthread)
{
	struct fd_table_entry *entry;
	int do_unlock;
	int fd;

	for (fd = 0; fd < _thread_max_fdtsize; fd++) {
		entry = _thread_fd_table[fd];
		if (entry) {
			_SPINLOCK(&entry->lock);
			do_unlock = 0;
			/* force an unlock regardless of the recursion level */
			if (entry->r_owner == pthread) {
				entry->r_lockcount = 1;
				do_unlock++;
			}
			if (entry->w_owner == pthread) {
				entry->w_lockcount = 1;
				do_unlock++;
			}
			_SPINUNLOCK(&entry->lock);
			if (do_unlock)
				_thread_fd_unlock_thread(pthread, fd, FD_RDWR);
		}
@


1.27
log
@Normally pipes created by threaded apps are left non-blocking after being
closed so that a threaded child process can still read it without blocking.
However, leaving stdin/out/err non-blocking when closed is bad because it
can be shared with non-threaded apps that can't deal with a non-blocking
file descriptor (i.e. cat). Therefore special case stdin/out/err pipes so
that they are reset to blocking upon a close(). Tested by robert@@, jolan@@
and myself with multiple OOo builds on mp systems where the problem was
seen more frequently.
@
text
@d1 1
a1 1
/*	$OpenBSD: uthread_fd.c,v 1.26 2006/09/26 15:09:59 kurt Exp $	*/
d204 1
a204 1
	flags = calloc(_thread_dtablesize, sizeof *flags);
d209 1
a209 1
	for (fd = 0; fd < _thread_dtablesize; fd += 1)
d222 1
a222 1
	for (fd = 0; fd < _thread_dtablesize; fd += 1) {
d230 1
a230 1
			for (fd2 = fd + 1; fd2 < _thread_dtablesize; fd2 += 1) {
d269 1
a269 1
	for (fd = 0; fd < _thread_dtablesize; fd += 1)
d293 1
a293 1
	if (fd < 0 || fd >= _thread_dtablesize) {
d502 1
a502 1
	if (fd >= 0 && fd < _thread_dtablesize && _thread_fd_table[fd] != NULL) {
d622 1
a622 1
	for (fd = 0; fd < _thread_dtablesize; fd++) {
@


1.26
log
@style(9) extra space
@
text
@d1 1
a1 1
/*	$OpenBSD: uthread_fd.c,v 1.25 2006/09/26 14:18:28 kurt Exp $	*/
d134 2
a135 1
				 * indefinitely.
d144 3
a146 3
				    (_thread_sys_fstat(fd, &sb) == 0) && 
				    ((S_ISREG(sb.st_mode) || S_ISCHR(sb.st_mode)) &&
				    (old_status_flags->flags & O_NONBLOCK) == 0))
@


1.25
log
@Part 2 of file descriptor race and deadlock corrections.

Adjust design of file descriptor table to eliminate races
with both opening and closing of file descriptor entries
and eliminates one class of deadlocks. One nice side effect
of this change in design should be better performance for
applications that open and close many file descriptors due
to reduced fd_table_lock contention and fd entry reuse.

- Add entry states to manage use of entry and eliminate
some closing races. fd entries are not deallocated upon
close() now.
- Call _thread_fd_table_init with one of five discreet
modes to properly initialize an entry and manage the
state transition to open.
- When closing an entry hold the entry spinlock locked
across the state transition and the _thread_sys_close
call to close another race.
- Introduce a new lock type FD_RDWR_CLOSE that transitions
either a closed entry or an open entry into closing state
and then waits for a RDWR lock so that the lock queue can
unwind normally. All subsequent fd lock attempts for that
entry are rejected with EBADF until the fd is fully closed,
or reopened by dup2(). Once a thread holds the FD_RDWR_LOCK
it is safe to close() it or dup2() on it.
- When a thread creates a new fd there is a window of time
when another thread could attempt to use the fd before the
creating thread has initialized the entry for it. This can
result in improper status_flags for the entry, so record
the entries init mode, detect when this has happened and
correct the status_flags when needed.

reviewed by marc@@ & brad@@, tested by several, okay brad@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uthread_fd.c,v 1.24 2006/09/23 12:25:58 kurt Exp $	*/
d754 1
a754 1
		if ( ret == 0 && (lock_type & FD_WRITE)) {
@


1.24
log
@fix a bug where the logic was reversed
@
text
@d1 1
a1 1
/*	$OpenBSD: uthread_fd.c,v 1.23 2006/09/22 19:04:33 kurt Exp $	*/
d99 1
a99 1
 * It is assumed the entry is locked with a FD_RDWR
d180 2
d238 2
d250 2
d285 1
a285 1
_thread_fd_table_init(int fd, struct fs_flags *status_flags)
d288 1
d290 1
a290 1
	struct fs_flags *new_status_flags = NULL;
d305 1
a305 1
			errno = ENOMEM;
d308 44
a351 1
			if (status_flags == NULL) {
d353 2
a354 1
				if (new_status_flags == NULL)
d356 2
a357 1
				else
d359 2
a360 19
			}
			if (ret == 0) {
				/* Lock the file descriptor table: */
				_SPINLOCK(&fd_table_lock);

				/*
				 * Check if another thread allocated the
				 * file descriptor entry while this thread
				 * was doing the same thing. The table wasn't
				 * kept locked during this operation because
				 * it has the potential to recurse.
				 */
				if (_thread_fd_table[fd] == NULL) {
					if (status_flags != NULL) {
						_SPINLOCK(&status_flags->lock);
						status_flags->refcnt += 1;
						_SPINUNLOCK(&status_flags->lock);
						entry->status_flags = status_flags;
					} else {
d363 6
d370 56
a425 3
					/* This thread wins: */
					_thread_fd_table[fd] = entry;
					entry = NULL;
d427 2
d430 24
a453 3

				/* Unlock the file descriptor table: */
				_SPINUNLOCK(&fd_table_lock);
d455 2
a456 1

d458 6
a463 4
			 * If there was an error in getting the flags for
			 * the file or if another thread initialized the
			 * table entry throw this entry and new_status_flags
			 * away.
d465 4
a468 5
			if (entry != NULL)
				free(entry);

			if (new_status_flags != NULL)
				free(new_status_flags);
d470 1
a470 3
	} else {
		if (status_flags != NULL)
			_thread_fs_flags_replace(fd, status_flags);
d478 3
a480 2
 * Remove an fd entry from the table and replace its status flags
 * with NULL. The entry is assummed to be locked with a RDWR lock.
d483 1
a483 1
_thread_fd_table_remove(int fd)
a484 2
	_SPINLOCK(&fd_table_lock);

d486 1
a486 4
	free(_thread_fd_table[fd]);
	_thread_fd_table[fd] = NULL;

	_SPINUNLOCK(&fd_table_lock);
a495 1
	int	ret;
d498 4
a501 5
	 * Check that the file descriptor table is initialised for this
	 * entry: 
	 */
	ret = _thread_fd_table_init(fd, NULL);
	if (ret == 0) {
d519 1
a519 1
		    (lock_type == FD_READ || lock_type == FD_RDWR)) {
d555 1
a555 1
		    (lock_type == FD_WRITE || lock_type == FD_RDWR)) {
a598 3

	/* Nothing to return. */
	return;
d656 1
a656 1
	ret = _thread_fd_table_init(fd, NULL);
d667 12
d680 1
a680 1
		if (lock_type == FD_READ || lock_type == FD_RDWR) {
d754 1
a754 1
		if (lock_type == FD_WRITE || lock_type == FD_RDWR) {
@


1.23
log
@Part 1 of file descriptor race and deadlock corrections.

File status flags should be shared for dup'ed file descriptors.
However fd_table_entry's should not be shared for dup'ed file
descriptors so they can be independently be closed without
interfering with dup'ed fd's.

- split out file status flags into its own structure
fs_flags to manage sharing of status flags between
dup'ed file descriptors.
- when duplicating a fd, initialize a new fd_table_entry
for the new fd, but share the status flags via status_flags.
- consolidate the code that sets the underlying system fd
to be non-blocking to a new function _thread_fs_flags_init()
- consolidate the code that sets the underlying system
fd back to blocking into a new function _thread_fs_flags_replace()

This change is needed as a prerequisite to the coming race
and deadlock corrections. okay marc@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uthread_fd.c,v 1.22 2004/06/07 21:11:23 marc Exp $	*/
d142 1
a142 1
				if (new_status_flags != NULL &&
@


1.22
log
@
major bump to libc and libpthread to break the dependency of a
particular implementation of libpthread for libc.  libc no longer
needs pthread.h to compile.
OK millert@@, brad@@, tedu@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uthread_fd.c,v 1.21 2003/02/14 03:58:42 marc Exp $	*/
d40 1
d51 118
d197 2
a198 1
	struct fd_table_entry *entry;
a204 1

d222 3
a224 3
		entry = _thread_fd_entry();
		if (entry != NULL) {
			entry->flags = flags[fd];
d226 1
a226 1
					  entry->flags ^ O_SYNC);
d232 7
a238 2
					entry->refcnt += 1;
					_thread_fd_table[fd2] = entry;
d242 5
a246 3
			if (entry->refcnt) {
				entry->refcnt += 1;
				_thread_fd_table[fd] = entry;
d248 6
a253 2
			} else
				free(entry);
d279 1
a279 1
_thread_fd_table_init(int fd)
d283 1
a283 1
	int	saved_errno;
d291 4
a294 2
		ret = -1;
	} else if (_thread_fd_table[fd] == NULL) {
d301 8
a308 18
			entry->flags = _thread_sys_fcntl(fd, F_GETFL, 0);
			if (entry->flags == -1)
				/* use the errno fcntl returned */
				ret = -1;
			else {
				/*
				 * Make the file descriptor non-blocking.
				 * This might fail if the device driver does
				 * not support non-blocking calls, or if the
				 * driver is naturally non-blocking.
				 */
				if ((entry->flags & O_NONBLOCK) == 0) {
					saved_errno = errno;
					_thread_sys_fcntl(fd, F_SETFL,
						  entry->flags | O_NONBLOCK);
					errno = saved_errno;
				}

d320 9
a329 1
					entry->refcnt += 1;
d331 2
d342 2
a343 1
			 * table entry throw this entry away.
d345 1
a345 1
			if (entry->refcnt == 0)
d347 3
d351 3
d361 2
a362 36
 * Dup from_fd -> to_fd.  from_fd is assumed to be locked (which
 * guarantees that _thread_fd_table[from_fd] exists).
 */
int
_thread_fd_table_dup(int from_fd, int to_fd)
{
	struct fd_table_entry	*entry;
	int ret;

	if (from_fd != to_fd) {
		/* release any existing to_fd table entry */
		entry = _thread_fd_table[to_fd];
		if (entry != NULL) {
			ret = _FD_LOCK(to_fd, FD_RDWR, NULL);
			if (ret != -1)
				_thread_fd_table_remove(to_fd);
		} else
			ret = 0;

		/* to_fd is a copy of from_fd */
		if (ret != -1) {
			_SPINLOCK(&fd_table_lock);
			_thread_fd_table[to_fd] = _thread_fd_table[from_fd];
			_thread_fd_table[to_fd]->refcnt += 1;
			_SPINUNLOCK(&fd_table_lock);
		}
	} else
		ret = 0;

	return (ret);
}

/*
 * Remove an fd entry from the table and free it if it's reference count
 * goes to zero.   The entry is assumed to be locked with a RDWR lock!  It
 * will be unlocked if it is not freed.
d367 1
a367 1
	struct fd_table_entry	*entry;
d369 2
a370 6
	_SPINLOCK(&fd_table_lock);
	entry = _thread_fd_table[fd];
	if (--entry->refcnt == 0)
		free(entry);
	else
		_FD_UNLOCK(fd, FD_RDWR);
d372 1
d389 1
a389 1
	ret = _thread_fd_table_init(fd);
d548 1
a548 1
	ret = _thread_fd_table_init(fd);
d558 1
@


1.21
log
@
fix bug that would leave an FD locked if dup'd, then closed.
Also, for safety lock the _thread_fd_table when removing entries.
@
text
@d1 1
a1 1
/*	$OpenBSD: uthread_fd.c,v 1.20 2003/02/05 06:20:36 marc Exp $	*/
d278 1
a278 2
_thread_fd_unlock_thread(struct pthread	*thread, int fd, int lock_type,
			 const char *fname, int lineno)
d302 1
a302 4
		if (fname)
			_spinlock_debug(&entry->lock, (char *)fname, lineno);
		else
			_SPINLOCK(&entry->lock);
d392 1
a392 2
 * Unlock an fd table entry for the given fd and lock type.  Save
 * fname and lineno (debug variables).
d395 1
a395 1
_thread_fd_unlock(int fd, int lock_type, const char *fname, int lineno)
d398 1
a398 1
	_thread_fd_unlock_thread(curthread, fd, lock_type, fname, lineno);
d427 1
a427 2
				_thread_fd_unlock_thread(pthread, fd, FD_RDWR,
							 __FILE__, __LINE__);
d433 1
a433 3
 * Lock an fd table entry for the given fd and lock type.  Save
 * fname and lineno (debug variables).  The debug variables may be
 * null when called by the non-debug version of the function.
d436 1
a436 2
_thread_fd_lock(int fd, int lock_type, struct timespec * timeout,
		const char *fname, int lineno)
d455 1
a455 5
		if (fname)
			_spinlock_debug(&entry->lock, (char *)fname, lineno);
		else
			_SPINLOCK(&entry->lock);

a482 3
					curthread->data.fd.branch = lineno;
					curthread->data.fd.fname =
						(char *)fname;
a522 2
					entry->r_fname = fname;
					entry->r_lineno = lineno;
a557 3
					curthread->data.fd.branch = lineno;
					curthread->data.fd.fname =
						(char *)fname;
a596 2
					entry->w_fname = fname;
					entry->w_lineno = lineno;
@


1.20
log
@AARRGGH!  2nd try, handle the case where from_fd == to_fd in _thread_fd_table_dup
@
text
@d1 1
a1 1
/*	$OpenBSD: uthread_fd.c,v 1.18 2003/02/05 05:51:51 marc Exp $	*/
d236 2
a237 4
			if (ret != -1) {
				if (--entry->refcnt == 0)
					free(entry);
			}
d252 20
@


1.19
log
@handle the case where from_fd == to_fd in _thread_fd_table_dup
@
text
@d231 1
a231 1
	if (from_fd != too_fd) {
@


1.18
log
@
thread fd handling, part 2.   Don't mung file flags until forced
to notice that the file exists.  This fixes a problem where an
application may think a file was in non-block mode because the
threads kernel played with the flags.   Also fix a stupid error
introduced in the last commit -- the threaded version of dup and
dup2 were foobared.   Bad marc.
@
text
@d1 1
a1 1
/*	$OpenBSD: uthread_fd.c,v 1.17 2003/02/04 22:14:27 marc Exp $	*/
d231 13
a243 4
	/* release any existing to_fd table entry */
	entry = _thread_fd_table[to_fd];
	if (entry != NULL) {
		ret = _FD_LOCK(to_fd, FD_RDWR, NULL);
d245 4
a248 2
			if (--entry->refcnt == 0)
				free(entry);
a251 8

	/* to_fd is a copy of from_fd */
	if (ret != -1) {
		_SPINLOCK(&fd_table_lock);
		_thread_fd_table[to_fd] = _thread_fd_table[from_fd];
		_thread_fd_table[to_fd]->refcnt += 1;
		_SPINUNLOCK(&fd_table_lock);
	}
@


1.17
log
@
Part 1 of thread fd handling fixes.  In the new scheme fd_table_entries
for dup-ed fds are shared to ensure proper flag handling.  A refcnt
was added to control when entries should be freed.  Specific changes:

close: don't free entry unless refcnt is zero
dup: rewrite to use new function _thread_fd_table_dup
dup2: rewrite to use new function _thread_fd_table_dup
fcntl: use _thread_fd_table_dup
uthread_fd: initialize thread fd table, searching for dup-ed fds.  Add
function to share _thread_fd_table entries when an fd is dup-ed.
uthread_init: make it readable.   Call fd init functions.

All current regression tests plus the mysql torture test pass.  The
new stdfiles regression test fails (I/O redirection problem). Part
2 is intended to fix that problem
@
text
@d1 1
a1 1
/*	$OpenBSD: uthread_fd.c,v 1.16 2003/01/19 21:22:31 marc Exp $	*/
d91 1
a91 1
	 * Now toggle the non-block flags and see what other fd's
d95 1
a95 1
	 * to dlopen and dlclose doesn't go through the thread code
d107 1
a107 1
					  entry->flags ^ O_NONBLOCK);
d121 1
d128 4
a131 2
	/* lastly, set all files to non-blocking, ignoring errors for
	   those files/devices that don't support such a mode. */
d134 1
a134 2
			_thread_sys_fcntl(fd, F_SETFL,
					  flags[fd] | O_NONBLOCK);
d180 3
a182 2
				saved_errno = errno;
				_thread_sys_fcntl(fd, F_SETFL,
d184 2
a185 1
				errno = saved_errno;
@


1.16
log
@
return (func(...)) not needed when the current function and func
are both void.
The select call is a cancellation point per IEEE Std 1003.1-2001.
This should fix a problem espie@@ found in kde.
@
text
@d1 1
a1 1
/*	$OpenBSD: uthread_fd.c,v 1.15 2002/11/12 20:12:45 marc Exp $	*/
d48 91
d162 1
a162 2
		entry = (struct fd_table_entry *)
		        malloc(sizeof(struct fd_table_entry));
a166 16
			/* Initialise the file locks: */
			_SPINLOCK_INIT(&entry->lock);
			entry->r_owner = NULL;
			entry->w_owner = NULL;
			entry->r_fname = NULL;
			entry->w_fname = NULL;
			entry->r_lineno = 0;
			entry->w_lineno = 0;
			entry->r_lockcount = 0;
			entry->w_lockcount = 0;

			/* Initialise the read/write queues: */
			TAILQ_INIT(&entry->r_queue);
			TAILQ_INIT(&entry->w_queue);

			/* Get the flags for the file: */
d195 1
a196 1
					entry = NULL;
d208 1
a208 1
			if (entry != NULL)
d214 32
@


1.15
log
@get rid of compiler warnings
@
text
@d1 1
a1 1
/*	$OpenBSD: uthread_fd.c,v 1.14 2002/11/05 22:19:56 marc Exp $	*/
d272 1
a272 2
	return (_thread_fd_unlock_thread(curthread, fd, lock_type,
					 fname, lineno));
@


1.14
log
@
thread safe libc -- 2nd try.   OK miod@@, millert@@
Thanks to miod@@ for m68k and vax fixes
@
text
@d1 1
a1 1
/*	$OpenBSD: uthread_fd.c,v 1.13 2002/11/03 23:58:39 marc Exp $	*/
a281 1
	struct pthread	*saved_thread = _get_curthread();
@


1.13
log
@back out previous patch.. there are still some vax/m68k issues
@
text
@d1 1
a1 1
/*	$OpenBSD: uthread_fd.c,v 1.12 2002/11/03 20:36:43 marc Exp $	*/
d148 1
a148 1
			 char *fname, int lineno)
d173 1
a173 1
			_spinlock_debug(&entry->lock, fname, lineno);
d269 1
a269 1
_thread_fd_unlock_debug(int fd, int lock_type, char *fname, int lineno)
a276 11
 * Unlock an fd table entry for the given fd and lock type (read,
 * write, or read-write).
 */
void
_thread_fd_unlock(int fd, int lock_type)
{
	struct pthread	*curthread = _get_curthread();
	return (_thread_fd_unlock_thread(curthread, fd, lock_type, NULL, 0));
}

/*
d315 2
a316 2
_thread_fd_lock_debug(int fd, int lock_type, struct timespec * timeout,
		      char *fname, int lineno)
d336 1
a336 1
			_spinlock_debug(&entry->lock, fname, lineno);
d368 2
a369 1
					curthread->data.fd.fname = fname;
d448 2
a449 1
					curthread->data.fd.fname = fname;
a503 10
}

/*
 * Non-debug version of fd locking.  Just call the debug version
 * passing a null file and line
 */
int
_thread_fd_lock(int fd, int lock_type, struct timespec * timeout)
{
	return (_thread_fd_lock_debug(fd, lock_type, timeout, NULL, 0));
@


1.12
log
@
libc changes for thread safety.  Tested on:
alpha (millert@@), i386 (marc@@), m68k (millert@@ and miod@@),
powerpc (drahn@@ and dhartmei@@), sparc (millert@@ and marc@@),
sparc64 (marc@@), and vax (millert@@ and miod@@).
Thanks to millert@@, miod@@, and mickey@@ for fixes along the way.
@
text
@d1 1
a1 1
/*	$OpenBSD: uthread_fd.c,v 1.11 2002/10/30 20:05:11 marc Exp $	*/
d148 1
a148 1
			 const char *fname, int lineno)
d173 1
a173 1
			_spinlock_debug(&entry->lock, (char *)fname, lineno);
d269 1
a269 1
_thread_fd_unlock(int fd, int lock_type, const char *fname, int lineno)
d277 11
d326 2
a327 2
_thread_fd_lock(int fd, int lock_type, struct timespec * timeout,
		const char *fname, int lineno)
d347 1
a347 1
			_spinlock_debug(&entry->lock, (char *)fname, lineno);
d379 1
a379 2
					curthread->data.fd.fname =
						(char *)fname;
d458 1
a458 2
					curthread->data.fd.fname =
						(char *)fname;
d513 10
@


1.11
log
@
removes duplicate functions and factor out common code so the needed (but
missing) _thread_fd_unlock_owned function can be added with minimal pain.
The incorrect special handling of the stdio fds was also removed.

Tested with the libc_r regression tests and the mysql regression tests.
No complaints from any developers
@
text
@d1 1
a1 1
/*	$OpenBSD: uthread_fd.c,v 1.10 2001/09/04 22:17:45 fgsch Exp $	*/
d148 1
a148 1
			 char *fname, int lineno)
d173 1
a173 1
			_spinlock_debug(&entry->lock, fname, lineno);
d269 1
a269 1
_thread_fd_unlock_debug(int fd, int lock_type, char *fname, int lineno)
a276 11
 * Unlock an fd table entry for the given fd and lock type (read,
 * write, or read-write).
 */
void
_thread_fd_unlock(int fd, int lock_type)
{
	struct pthread	*curthread = _get_curthread();
	return (_thread_fd_unlock_thread(curthread, fd, lock_type, NULL, 0));
}

/*
d315 2
a316 2
_thread_fd_lock_debug(int fd, int lock_type, struct timespec * timeout,
		      char *fname, int lineno)
d336 1
a336 1
			_spinlock_debug(&entry->lock, fname, lineno);
d368 2
a369 1
					curthread->data.fd.fname = fname;
d448 2
a449 1
					curthread->data.fd.fname = fname;
a503 10
}

/*
 * Non-debug version of fd locking.  Just call the debug version
 * passing a null file and line
 */
int
_thread_fd_lock(int fd, int lock_type, struct timespec * timeout)
{
	return (_thread_fd_lock_debug(fd, lock_type, timeout, NULL, 0));
@


1.10
log
@put changes back, this time ALL the files.
@
text
@d1 1
a1 1
/*	$OpenBSD: uthread_fd.c,v 1.9 2001/08/30 17:47:57 todd Exp $	*/
d48 2
a54 1

a61 1
	/* Check if the file descriptor is out of range: */
d63 4
a66 1
		/* Return a bad file descriptor error: */
d69 6
a74 34
	}

	/*
	 * Check if memory has already been allocated for this file
	 * descriptor: 
	 */
	else if (_thread_fd_table[fd] != NULL) {
		/* Memory has already been allocated. */

	/* Allocate memory for the file descriptor table entry: */
	} else if ((entry = (struct fd_table_entry *)
	    malloc(sizeof(struct fd_table_entry))) == NULL) {
		/* Return an insufficient memory error: */
		errno = ENOMEM;
		ret = -1;
	} else {
		/* Initialise the file locks: */
		_SPINLOCK_INIT(&entry->lock);
		entry->r_owner = NULL;
		entry->w_owner = NULL;
		entry->r_fname = NULL;
		entry->w_fname = NULL;
		entry->r_lineno = 0;
		entry->w_lineno = 0;
		entry->r_lockcount = 0;
		entry->w_lockcount = 0;

		/* Initialise the read/write queues: */
		TAILQ_INIT(&entry->r_queue);
		TAILQ_INIT(&entry->w_queue);

		/* Get the flags for the file: */
		if (((fd >= 3) || (_pthread_stdio_flags[fd] == -1)) &&
		    (entry->flags = _thread_sys_fcntl(fd, F_GETFL, 0)) == -1) {
d76 48
a123 13
		}
		else {
			/* Check if a stdio descriptor: */
			if ((fd < 3) && (_pthread_stdio_flags[fd] != -1))
				/*
				 * Use the stdio flags read by
				 * _pthread_init() to avoid
				 * mistaking the non-blocking
				 * flag that, when set on one
				 * stdio fd, is set on all stdio
				 * fds.
				 */
				entry->flags = _pthread_stdio_flags[fd];
d125 3
a127 13
			/*
			 * Make the file descriptor non-blocking.
			 * This might fail if the device driver does
			 * not support non-blocking calls, or if the
			 * driver is naturally non-blocking.
			 */
			saved_errno = errno;
			_thread_sys_fcntl(fd, F_SETFL,
			    entry->flags | O_NONBLOCK);
			errno = saved_errno;

			/* Lock the file descriptor table: */
			_SPINLOCK(&fd_table_lock);
d130 3
a132 5
			 * Check if another thread allocated the
			 * file descriptor entry while this thread
			 * was doing the same thing. The table wasn't
			 * kept locked during this operation because
			 * it has the potential to recurse.
d134 2
a135 8
			if (_thread_fd_table[fd] == NULL) {
				/* This thread wins: */
				_thread_fd_table[fd] = entry;
				entry = NULL;
			}

			/* Unlock the file descriptor table: */
			_SPINUNLOCK(&fd_table_lock);
a136 11

		/*
		 * Check if another thread initialised the table entry
		 * before this one could:
		 */
		if (entry != NULL)
			/*
			 * Throw away the table entry that this thread
			 * prepared. The other thread wins.
			 */
			free(entry);
d143 3
d147 2
a148 1
_thread_fd_unlock(int fd, int lock_type)
d150 1
a150 1
	struct pthread	*curthread = _get_curthread();
d157 4
a160 1
	if ((ret = _thread_fd_table_init(fd)) == 0) {
d172 4
a175 1
		_SPINLOCK(&_thread_fd_table[fd]->lock);
d178 8
a185 15
		if (_thread_fd_table[fd]->r_owner == curthread) {
			/* Check the file descriptor and lock types: */
			if (lock_type == FD_READ || lock_type == FD_RDWR) {
				/*
				 * Decrement the read lock count for the
				 * running thread: 
				 */
				_thread_fd_table[fd]->r_lockcount--;

				/*
				 * Check if the running thread still has read
				 * locks on this file descriptor: 
				 */
				if (_thread_fd_table[fd]->r_lockcount != 0) {
				}
d187 2
a188 2
				 * Get the next thread in the queue for a
				 * read lock on this file descriptor: 
d190 4
a193 5
				else if ((_thread_fd_table[fd]->r_owner = TAILQ_FIRST(&_thread_fd_table[fd]->r_queue)) == NULL) {
				} else {
					/* Remove this thread from the queue: */
					TAILQ_REMOVE(&_thread_fd_table[fd]->r_queue,
					    _thread_fd_table[fd]->r_owner, qe);
d197 1
a197 1
					 * the thread to running: 
d199 2
a200 1
					PTHREAD_NEW_STATE(_thread_fd_table[fd]->r_owner,PS_RUNNING);
d204 3
a206 3
					 * This will be incremented by the
					 * new owner of the lock when it sees
					 * that it has the lock.                           
d208 1
a208 1
					_thread_fd_table[fd]->r_lockcount = 0;
d211 1
d214 8
a221 3
		if (_thread_fd_table[fd]->w_owner == curthread) {
			/* Check the file descriptor and lock types: */
			if (lock_type == FD_WRITE || lock_type == FD_RDWR) {
d223 2
a224 2
				 * Decrement the write lock count for the
				 * running thread: 
d226 2
a227 14
				_thread_fd_table[fd]->w_lockcount--;

				/*
				 * Check if the running thread still has
				 * write locks on this file descriptor: 
				 */
				if (_thread_fd_table[fd]->w_lockcount != 0) {
				}
				/*
				 * Get the next thread in the queue for a
				 * write lock on this file descriptor: 
				 */
				else if ((_thread_fd_table[fd]->w_owner = TAILQ_FIRST(&_thread_fd_table[fd]->w_queue)) == NULL) {
				} else {
d229 2
a230 2
					TAILQ_REMOVE(&_thread_fd_table[fd]->w_queue,
					    _thread_fd_table[fd]->w_owner, qe);
d236 2
a237 1
					PTHREAD_NEW_STATE(_thread_fd_table[fd]->w_owner,PS_RUNNING);
d245 1
a245 1
					_thread_fd_table[fd]->w_lockcount = 0;
d251 1
a251 1
		_SPINUNLOCK(&_thread_fd_table[fd]->lock);
d264 6
a269 2
int
_thread_fd_lock(int fd, int lock_type, struct timespec * timeout)
d272 2
a273 164
	int	ret;

	/*
	 * Check that the file descriptor table is initialised for this
	 * entry: 
	 */
	if ((ret = _thread_fd_table_init(fd)) == 0) {
		/*
		 * Lock the file descriptor table entry to prevent
		 * other threads for clashing with the current
		 * thread's accesses:
		 */
		_SPINLOCK(&_thread_fd_table[fd]->lock);

		/* Check the file descriptor and lock types: */
		if (lock_type == FD_READ || lock_type == FD_RDWR) {
			/*
			 * Enter a loop to wait for the file descriptor to be
			 * locked    for read for the current thread: 
			 */
			while (_thread_fd_table[fd]->r_owner != curthread) {
				/*
				 * Check if the file descriptor is locked by
				 * another thread: 
				 */
				if (_thread_fd_table[fd]->r_owner != NULL) {
					/*
					 * Another thread has locked the file
					 * descriptor for read, so join the
					 * queue of threads waiting for a  
					 * read lock on this file descriptor: 
					 */
					TAILQ_INSERT_TAIL(&_thread_fd_table[fd]->r_queue, curthread, qe);

					/*
					 * Save the file descriptor details
					 * in the thread structure for the
					 * running thread: 
					 */
					curthread->data.fd.fd = fd;

					/* Set the timeout: */
					_thread_kern_set_timeout(timeout);

					/*
					 * Unlock the file descriptor
					 * table entry:
					 */
					_SPINUNLOCK(&_thread_fd_table[fd]->lock);

					/*
					 * Schedule this thread to wait on
					 * the read lock. It will only be
					 * woken when it becomes the next in
					 * the   queue and is granted access
					 * to the lock by the       thread
					 * that is unlocking the file
					 * descriptor.        
					 */
					_thread_kern_sched_state(PS_FDLR_WAIT, __FILE__, __LINE__);

					/*
					 * Lock the file descriptor
					 * table entry again:
					 */
					_SPINLOCK(&_thread_fd_table[fd]->lock);

				} else {
					/*
					 * The running thread now owns the
					 * read lock on this file descriptor: 
					 */
					_thread_fd_table[fd]->r_owner = curthread;

					/*
					 * Reset the number of read locks for
					 * this file descriptor: 
					 */
					_thread_fd_table[fd]->r_lockcount = 0;
				}
			}

			/* Increment the read lock count: */
			_thread_fd_table[fd]->r_lockcount++;
		}

		/* Check the file descriptor and lock types: */
		if (lock_type == FD_WRITE || lock_type == FD_RDWR) {
			/*
			 * Enter a loop to wait for the file descriptor to be
			 * locked for write for the current thread: 
			 */
			while (_thread_fd_table[fd]->w_owner != curthread) {
				/*
				 * Check if the file descriptor is locked by
				 * another thread: 
				 */
				if (_thread_fd_table[fd]->w_owner != NULL) {
					/*
					 * Another thread has locked the file
					 * descriptor for write, so join the
					 * queue of threads waiting for a 
					 * write lock on this file
					 * descriptor: 
					 */
					TAILQ_INSERT_TAIL(&_thread_fd_table[fd]->w_queue, curthread, qe);

					/*
					 * Save the file descriptor details
					 * in the thread structure for the
					 * running thread: 
					 */
					curthread->data.fd.fd = fd;

					/* Set the timeout: */
					_thread_kern_set_timeout(timeout);

					/*
					 * Unlock the file descriptor
					 * table entry:
					 */
					_SPINUNLOCK(&_thread_fd_table[fd]->lock);

					/*
					 * Schedule this thread to wait on
					 * the write lock. It will only be
					 * woken when it becomes the next in
					 * the queue and is granted access to
					 * the lock by the thread that is
					 * unlocking the file descriptor.        
					 */
					_thread_kern_sched_state(PS_FDLW_WAIT, __FILE__, __LINE__);

					/*
					 * Lock the file descriptor
					 * table entry again:
					 */
					_SPINLOCK(&_thread_fd_table[fd]->lock);
				} else {
					/*
					 * The running thread now owns the
					 * write lock on this   file
					 * descriptor: 
					 */
					_thread_fd_table[fd]->w_owner = curthread;

					/*
					 * Reset the number of write locks
					 * for this file descriptor: 
					 */
					_thread_fd_table[fd]->w_lockcount = 0;
				}
			}

			/* Increment the write lock count: */
			_thread_fd_table[fd]->w_lockcount++;
		}

		/* Unlock the file descriptor table entry: */
		_SPINUNLOCK(&_thread_fd_table[fd]->lock);
	}

	/* Return the completion status: */
	return (ret);
d276 4
d281 1
a281 1
_thread_fd_unlock_debug(int fd, int lock_type, char *fname, int lineno)
d284 2
a285 1
	int	ret;
d287 10
a296 10
	/*
	 * Check that the file descriptor table is initialised for this
	 * entry: 
	 */
	if ((ret = _thread_fd_table_init(fd)) == 0) {
		/*
		 * Defer signals to protect the scheduling queues from
		 * access by the signal handler:
		 */
		_thread_kern_sig_defer();
d298 9
a306 47
		/*
		 * Lock the file descriptor table entry to prevent
		 * other threads for clashing with the current
		 * thread's accesses:
		 */
		_spinlock_debug(&_thread_fd_table[fd]->lock, fname, lineno);

		/* Check if the running thread owns the read lock: */
		if (_thread_fd_table[fd]->r_owner == curthread) {
			/* Check the file descriptor and lock types: */
			if (lock_type == FD_READ || lock_type == FD_RDWR) {
				/*
				 * Decrement the read lock count for the
				 * running thread: 
				 */
				_thread_fd_table[fd]->r_lockcount--;

				/*
				 * Check if the running thread still has read
				 * locks on this file descriptor: 
				 */
				if (_thread_fd_table[fd]->r_lockcount != 0) {
				}
				/*
				 * Get the next thread in the queue for a
				 * read lock on this file descriptor: 
				 */
				else if ((_thread_fd_table[fd]->r_owner = TAILQ_FIRST(&_thread_fd_table[fd]->r_queue)) == NULL) {
				} else {
					/* Remove this thread from the queue: */
					TAILQ_REMOVE(&_thread_fd_table[fd]->r_queue,
					    _thread_fd_table[fd]->r_owner, qe);

					/*
					 * Set the state of the new owner of
					 * the thread to  running: 
					 */
					PTHREAD_NEW_STATE(_thread_fd_table[fd]->r_owner,PS_RUNNING);

					/*
					 * Reset the number of read locks.
					 * This will be incremented by the
					 * new owner of the lock when it sees
					 * that it has the lock.                           
					 */
					_thread_fd_table[fd]->r_lockcount = 0;
				}
d308 3
a310 41
		}
		/* Check if the running thread owns the write lock: */
		if (_thread_fd_table[fd]->w_owner == curthread) {
			/* Check the file descriptor and lock types: */
			if (lock_type == FD_WRITE || lock_type == FD_RDWR) {
				/*
				 * Decrement the write lock count for the
				 * running thread: 
				 */
				_thread_fd_table[fd]->w_lockcount--;

				/*
				 * Check if the running thread still has
				 * write locks on this file descriptor: 
				 */
				if (_thread_fd_table[fd]->w_lockcount != 0) {
				}
				/*
				 * Get the next thread in the queue for a
				 * write lock on this file descriptor: 
				 */
				else if ((_thread_fd_table[fd]->w_owner = TAILQ_FIRST(&_thread_fd_table[fd]->w_queue)) == NULL) {
				} else {
					/* Remove this thread from the queue: */
					TAILQ_REMOVE(&_thread_fd_table[fd]->w_queue,
					    _thread_fd_table[fd]->w_owner, qe);

					/*
					 * Set the state of the new owner of
					 * the thread to running: 
					 */
					PTHREAD_NEW_STATE(_thread_fd_table[fd]->w_owner,PS_RUNNING);

					/*
					 * Reset the number of write locks.
					 * This will be incremented by the
					 * new owner of the lock when it  
					 * sees that it has the lock.
					 */
					_thread_fd_table[fd]->w_lockcount = 0;
				}
d312 4
a316 9

		/* Unlock the file descriptor table entry: */
		_SPINUNLOCK(&_thread_fd_table[fd]->lock);

		/*
		 * Undefer and handle pending signals, yielding if
		 * necessary.
		 */
		_thread_kern_sig_undefer();
a317 3

	/* Nothing to return. */
	return;
d320 5
d327 1
a327 1
		char *fname, int lineno)
d330 1
d337 4
a340 1
	if ((ret = _thread_fd_table_init(fd)) == 0) {
d346 4
a349 1
		_spinlock_debug(&_thread_fd_table[fd]->lock, fname, lineno);
d351 1
a351 1
		/* Check the file descriptor and lock types: */
d357 1
a357 1
			while (_thread_fd_table[fd]->r_owner != curthread) {
d362 1
a362 1
				if (_thread_fd_table[fd]->r_owner != NULL) {
d369 2
a370 1
					TAILQ_INSERT_TAIL(&_thread_fd_table[fd]->r_queue, curthread, qe);
d388 1
a388 1
					_SPINUNLOCK(&_thread_fd_table[fd]->lock);
d395 2
a396 3
					 * to the lock by the       thread
					 * that is unlocking the file
					 * descriptor.        
d398 3
a400 1
					_thread_kern_sched_state(PS_FDLR_WAIT, __FILE__, __LINE__);
d406 1
a406 1
					_SPINLOCK(&_thread_fd_table[fd]->lock);
d413 1
a413 1
					_thread_fd_table[fd]->r_owner = curthread;
d419 3
a421 8
					_thread_fd_table[fd]->r_lockcount = 0;

					/*
					 * Save the source file details for
					 * debugging: 
					 */
					_thread_fd_table[fd]->r_fname = fname;
					_thread_fd_table[fd]->r_lineno = lineno;
d426 1
a426 1
			_thread_fd_table[fd]->r_lockcount++;
d429 1
a429 1
		/* Check the file descriptor and lock types: */
d435 1
a435 1
			while (_thread_fd_table[fd]->w_owner != curthread) {
d440 1
a440 1
				if (_thread_fd_table[fd]->w_owner != NULL) {
d448 2
a449 1
					TAILQ_INSERT_TAIL(&_thread_fd_table[fd]->w_queue, curthread, qe);
d467 1
a467 1
					_SPINUNLOCK(&_thread_fd_table[fd]->lock);
d475 1
a475 1
					 * unlocking the file descriptor.        
d477 3
a479 1
					_thread_kern_sched_state(PS_FDLW_WAIT, __FILE__, __LINE__);
d485 1
a485 1
					_SPINLOCK(&_thread_fd_table[fd]->lock);
d489 1
a489 2
					 * write lock on this   file
					 * descriptor: 
d491 1
a491 1
					_thread_fd_table[fd]->w_owner = curthread;
d497 3
a499 8
					_thread_fd_table[fd]->w_lockcount = 0;

					/*
					 * Save the source file details for
					 * debugging: 
					 */
					_thread_fd_table[fd]->w_fname = fname;
					_thread_fd_table[fd]->w_lineno = lineno;
d504 1
a504 1
			_thread_fd_table[fd]->w_lockcount++;
d508 1
a508 1
		_SPINUNLOCK(&_thread_fd_table[fd]->lock);
d514 11
@


1.9
log
@Back out fgsch@@'s tree breaking commits.
Test next time, ok?
@
text
@d1 1
a1 1
/*	$OpenBSD: uthread_fd.c,v 1.8 2001/08/30 07:40:47 fgsch Exp $	*/
d456 1
a456 1
_thread_fd_unlock_debug(int fd, int lock_type, const char *fname, int lineno)
d580 1
a580 1
		const char *fname, int lineno)
@


1.8
log
@fix some const warnings.
more sync with freebsd.
@
text
@d1 1
a1 1
/*	$OpenBSD: uthread_fd.c,v 1.7 2001/08/21 19:24:53 fgsch Exp $	*/
d456 1
a456 1
_thread_fd_unlock_debug(int fd, int lock_type, char *fname, int lineno)
d580 1
a580 1
		char *fname, int lineno)
@


1.7
log
@Start syncing with FreeBSD:

o Implement _get_curthread() and _set_curthread(). Use it where possible.
o Add missing _thread_[enter|leave]_cancellation_point().
o Add a couple of not yet used vars to pthread_private.h.
o Remove return's from void functions.

This is by no means complete, but instead of doing a big commit, i'll
split it in small ones, minimizing diffs.
@
text
@d1 1
a1 1
/*	$OpenBSD: uthread_fd.c,v 1.6 1999/11/25 07:01:34 d Exp $	*/
d456 1
a456 1
_thread_fd_unlock_debug(int fd, int lock_type, const char *fname, int lineno)
d580 1
a580 1
		const char *fname, int lineno)
@


1.6
log
@sync with FreeBSD
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d165 1
d187 1
a187 1
		if (_thread_fd_table[fd]->r_owner == _thread_run) {
d229 1
a229 1
		if (_thread_fd_table[fd]->w_owner == _thread_run) {
d288 1
d309 1
a309 1
			while (_thread_fd_table[fd]->r_owner != _thread_run) {
d321 1
a321 1
					TAILQ_INSERT_TAIL(&_thread_fd_table[fd]->r_queue, _thread_run, qe);
d328 1
a328 1
					_thread_run->data.fd.fd = fd;
d361 1
a361 1
					_thread_fd_table[fd]->r_owner = _thread_run;
d381 1
a381 1
			while (_thread_fd_table[fd]->w_owner != _thread_run) {
d394 1
a394 1
					TAILQ_INSERT_TAIL(&_thread_fd_table[fd]->w_queue, _thread_run, qe);
d401 1
a401 1
					_thread_run->data.fd.fd = fd;
d433 1
a433 1
					_thread_fd_table[fd]->w_owner = _thread_run;
d458 1
d480 1
a480 1
		if (_thread_fd_table[fd]->r_owner == _thread_run) {
d522 1
a522 1
		if (_thread_fd_table[fd]->w_owner == _thread_run) {
d582 1
d603 1
a603 1
			while (_thread_fd_table[fd]->r_owner != _thread_run) {
d615 1
a615 1
					TAILQ_INSERT_TAIL(&_thread_fd_table[fd]->r_queue, _thread_run, qe);
d622 3
a624 3
					_thread_run->data.fd.fd = fd;
					_thread_run->data.fd.branch = lineno;
					_thread_run->data.fd.fname = fname;
d657 1
a657 1
					_thread_fd_table[fd]->r_owner = _thread_run;
d684 1
a684 1
			while (_thread_fd_table[fd]->w_owner != _thread_run) {
d697 1
a697 1
					TAILQ_INSERT_TAIL(&_thread_fd_table[fd]->w_queue, _thread_run, qe);
d704 3
a706 3
					_thread_run->data.fd.fd = fd;
					_thread_run->data.fd.branch = lineno;
					_thread_run->data.fd.fname = fname;
d738 1
a738 1
					_thread_fd_table[fd]->w_owner = _thread_run;
@


1.5
log
@sync with FreeBSD
@
text
@d1 1
d24 1
a24 1
 * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE
d33 1
a33 2
 * $FreeBSD: uthread_fd.c,v 1.10 1999/03/23 05:07:55 jb Exp $
 * $OpenBSD: uthread_fd.c,v 1.4 1999/01/10 23:09:36 d Exp $
d83 1
a83 1
		_SPINUNLOCK(&entry->lock);
d88 4
a91 4
		entry->r_lineno = 0;;
		entry->w_lineno = 0;;
		entry->r_lockcount = 0;;
		entry->w_lockcount = 0;;
d94 2
a95 2
		_thread_queue_init(&entry->r_queue);
		_thread_queue_init(&entry->w_queue);
d98 2
a99 2
		if (fd >= 3 && (entry->flags =
		    _thread_sys_fcntl(fd, F_GETFL, 0)) == -1) {
d101 1
a101 1
		    }
d104 1
a104 1
			if (fd < 3)
d173 6
d205 1
a205 1
				else if ((_thread_fd_table[fd]->r_owner = _thread_queue_deq(&_thread_fd_table[fd]->r_queue)) == NULL) {
d207 4
d247 1
a247 1
				else if ((_thread_fd_table[fd]->w_owner = _thread_queue_deq(&_thread_fd_table[fd]->w_queue)) == NULL) {
d249 4
d272 6
d319 1
a319 1
					_thread_queue_enq(&_thread_fd_table[fd]->r_queue, _thread_run);
d392 1
a392 1
					_thread_queue_enq(&_thread_fd_table[fd]->w_queue, _thread_run);
d454 1
a454 1
_thread_fd_unlock_debug(int fd, int lock_type, char *fname, int lineno)
d464 6
d496 1
a496 1
				else if ((_thread_fd_table[fd]->r_owner = _thread_queue_deq(&_thread_fd_table[fd]->r_queue)) == NULL) {
d498 4
d538 1
a538 1
				else if ((_thread_fd_table[fd]->w_owner = _thread_queue_deq(&_thread_fd_table[fd]->w_queue)) == NULL) {
d540 4
d563 6
d611 1
a611 1
					_thread_queue_enq(&_thread_fd_table[fd]->r_queue, _thread_run);
d693 1
a693 1
					_thread_queue_enq(&_thread_fd_table[fd]->w_queue, _thread_run);
@


1.4
log
@initialise locks properly
@
text
@d32 2
a33 2
 * $FreeBSD: uthread_fd.c,v 1.9 1998/09/13 15:33:42 dt Exp $
 * $OpenBSD: uthread_fd.c,v 1.3 1998/12/23 22:49:46 d Exp $
d203 1
a203 1
					 * the thread to  running: 
@


1.3
log
@preserve FreeBSD idents
@
text
@d33 1
a33 1
 * $OpenBSD: uthread_fd.c,v 1.2 1998/11/09 03:13:19 d Exp $
d83 1
a83 1
		memset(&entry->lock, 0, sizeof(entry->lock));
@


1.2
log
@sync with FreeBSD (rwlock, gc thread, man pages)
add (broken) mips md stuff
fix some const warnings
add sigaltstack() stub
another hash at getting shlib auto-init to work (mips/elf and i386/a.out)
@
text
@d32 2
a33 2
 * $Id: uthread_fd.c,v 1.1 1998/08/27 09:01:01 d Exp $
 * $OpenBSD: uthread_fd.c,v 1.1 1998/08/27 09:01:01 d Exp $
@


1.1
log
@experimental threaded libc - kernel only
@
text
@d32 2
a33 2
 * $Id: uthread_fd.c,v 1.8 1998/06/09 23:16:53 jb Exp $
 * $OpenBSD$
d59 1
d121 1
d124 1
d537 1
a537 1
		char *fname, int lineno)
@

