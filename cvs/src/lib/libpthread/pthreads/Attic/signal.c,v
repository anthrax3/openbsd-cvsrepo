head	1.4;
access;
symbols
	OPENBSD_2_4:1.3.0.2
	OPENBSD_2_4_BASE:1.3
	from_mysql_3_22_4:1.1.1.2
	mit:1.1.1
	OPENBSD_2_3:1.1.1.1.0.8
	OPENBSD_2_3_BASE:1.1.1.1
	OPENBSD_2_2:1.1.1.1.0.6
	OPENBSD_2_2_BASE:1.1.1.1
	OPENBSD_2_1:1.1.1.1.0.4
	OPENBSD_2_1_BASE:1.1.1.1
	OPENBSD_2_0:1.1.1.1.0.2
	OPENBSD_2_0_BASE:1.1.1.1
	netbsd_1_1:1.1.1.1;
locks; strict;
comment	@ * @;


1.4
date	99.03.10.08.53.41;	author d;	state dead;
branches;
next	1.3;

1.3
date	98.07.22.10.46.54;	author peter;	state Exp;
branches;
next	1.2;

1.2
date	98.07.21.19.48.04;	author peter;	state Exp;
branches;
next	1.1;

1.1
date	95.10.18.08.43.05;	author deraadt;	state Exp;
branches
	1.1.1.1;
next	;

1.1.1.1
date	95.10.18.08.43.05;	author deraadt;	state Exp;
branches;
next	1.1.1.2;

1.1.1.2
date	98.07.21.13.20.22;	author peter;	state Exp;
branches;
next	;


desc
@@


1.4
log
@Goodbye, MIT pthreads... you were a handy reference implementation
@
text
@/* ==== signal.c ============================================================
 * Copyright (c) 1993, 1994 by Chris Provenzano, proven@@mit.edu
 * All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *  This product includes software developed by Chris Provenzano.
 * 4. The name of Chris Provenzano may not be used to endorse or promote 
 *	  products derived from this software without specific prior written
 *	  permission.
 *
 * THIS SOFTWARE IS PROVIDED BY CHRIS PROVENZANO ``AS IS'' AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED.  IN NO EVENT SHALL CHRIS PROVENZANO BE LIABLE FOR ANY 
 * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
 * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR 
 * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT 
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF 
 * SUCH DAMAGE.
 *
 * Description : Queue functions.
 *
 *  1.00 93/07/21 proven
 *      -Started coding this file.
 */

#ifndef lint
static const char rcsid[] = "$Id: signal.c,v 1.3 1998/07/22 10:46:54 peter Exp $";
#endif

#include <pthread.h>
#include <signal.h>

/* This will force init.o to get dragged in; if you've got support for
   C++ initialization, that'll cause pthread_init to be called at
   program startup automatically, so the application won't need to
   call it explicitly.  */

extern char __pthread_init_hack;
char *__pthread_init_hack_2 = &__pthread_init_hack;

/*
 * Time which select in fd_kern_wait() will sleep.
 * If there are no threads to run we sleep for an hour or until
 * we get an interrupt or an fd thats awakens. To make sure we
 * don't miss an interrupt this variable gets reset too zero in
 * sig_handler_real().
 */
struct timeval __fd_kern_wait_timeout = { 0, 0 };

/*
 * Global for user-kernel lock, and blocked signals
 */

static sig_atomic_t signum_to_process[SIGMAX + 1] = { 0, };
volatile sig_atomic_t sig_to_process = 0;

/* static volatile	sigset_t sig_to_process; */
static volatile	int	sig_count = 0;

static void sig_handler(int signal);
static void set_thread_timer();
static void __cleanup_after_resume( void );
void sig_prevent(void);
void sig_resume(void);

/* ==========================================================================
 * context_switch()
 *
 * This routine saves the current state of the running thread gets
 * the next thread to run and restores it's state. To allow different
 * processors to work with this routine, I allow the machdep_restore_state()
 * to either return or have it return from machdep_save_state with a value
 * other than 0, this is for implementations which use setjmp/longjmp. 
 */
static void context_switch()
{
	struct pthread **current, *next, *last, **dead;

	if (pthread_run->state == PS_RUNNING) {
		/* Put current thread back on the queue */
		pthread_prio_queue_enq(pthread_current_prio_queue, pthread_run);
	}

	/* save floating point registers if necessary */
	if (!(pthread_run->attr.flags & PTHREAD_NOFLOAT)) {
		machdep_save_float_state(pthread_run);
	}
	/* save state of current thread */
	if (machdep_save_state()) {
		return;
	}

	last = pthread_run;

	/* Poll all fds */
	fd_kern_poll();

context_switch_reschedule:;
	/* Are there any threads to run */
	if (pthread_run = pthread_prio_queue_deq(pthread_current_prio_queue)) {
		/* restore floating point registers if necessary */
		if (!(pthread_run->attr.flags & PTHREAD_NOFLOAT)) {
			machdep_restore_float_state();
		}
		uthread_sigmask = &(pthread_run->sigmask);
      	/* restore state of new current thread */
		machdep_restore_state();
    	return;
   	} 

	/* Are there any threads at all */
	for (next = pthread_link_list; next; next = next->pll) {
		if ((next->state != PS_UNALLOCED) && (next->state != PS_DEAD)) {
			sigset_t sig_to_block, oset;

			sigfillset(&sig_to_block);

			/*
			 * Check sig_to_process before calling fd_kern_wait, to handle
			 * things like zero timeouts to select() which would register
			 * a signal with the sig_handler_fake() call.
			 *
			 * This case should ignore SIGVTALRM
			 */
			machdep_sys_sigprocmask(SIG_BLOCK, &sig_to_block, &oset);
			signum_to_process[SIGVTALRM] = 0;
			if (sig_to_process) {
              	/* Process interrupts */
               	/*
               	 * XXX pthread_run should not be set!
				 * Places where it dumps core should be fixed to 
				 * check for the existance of pthread_run --proven
               	 */
               	sig_handler(0);
           	} else {
				machdep_sys_sigprocmask(SIG_UNBLOCK, &sig_to_block, &oset);
				/*
				 * Do a wait, timeout is set to a hour unless we get an 
				 * intr. before the select in wich case it polls.
				 */
				fd_kern_wait();
				machdep_sys_sigprocmask(SIG_BLOCK, &sig_to_block, &oset);
				/* Check for interrupts, but ignore SIGVTALR */
				signum_to_process[SIGVTALRM] = 0;
				if (sig_to_process) {
					/* Process interrupts */
					sig_handler(0); 
				}
			}
			machdep_sys_sigprocmask(SIG_UNBLOCK, &sig_to_block, &oset); 
			goto context_switch_reschedule;
		}
	}

	/* There are no threads alive. */
	pthread_run = last;
	exit(0);
}

#if !defined(HAVE_SYSCALL_SIGSUSPEND) && defined(HAVE_SYSCALL_SIGPAUSE)

/* ==========================================================================
 * machdep_sys_sigsuspend()
 */ 
int machdep_sys_sigsuspend(sigset_t * set)
{
	return(machdep_sys_sigpause(* set));
}

#endif

/* ==========================================================================
 * sig_handler_pause()
 * 
 * Wait until a signal is sent to the process.
 */
void sig_handler_pause()
{
	sigset_t sig_to_block, sig_to_pause, oset;

	sigfillset(&sig_to_block);
	sigemptyset(&sig_to_pause);
	machdep_sys_sigprocmask(SIG_BLOCK, &sig_to_block, &oset);
/*	if (!(SIG_ANY(sig_to_process))) { */
	if (!sig_to_process) {
		machdep_sys_sigsuspend(&sig_to_pause);
	}
	machdep_sys_sigprocmask(SIG_UNBLOCK, &sig_to_block, &oset);
}

/* ==========================================================================
 * context_switch_done()
 *
 * This routine does all the things that are necessary after a context_switch()
 * calls the machdep_restore_state(). DO NOT put this in the context_switch()
 * routine because sometimes the machdep_restore_state() doesn't return
 * to context_switch() but instead ends up in machdep_thread_start() or
 * some such routine, which will need to call this routine and
 * sig_check_and_resume().
 */
void context_switch_done()
{
	/* sigdelset((sigset_t *)&sig_to_process, SIGVTALRM); */
	signum_to_process[SIGVTALRM] = 0;
	set_thread_timer();
}

/* ==========================================================================
 * set_thread_timer()
 *
 * Assums kernel is locked.
 */
static void set_thread_timer()
{
	static int last_sched_attr = SCHED_RR;

	switch (pthread_run->attr.schedparam_policy) {
	case SCHED_RR:
		machdep_set_thread_timer(&(pthread_run->machdep_data));
		break;
	case SCHED_FIFO:
		if (last_sched_attr != SCHED_FIFO) {
			machdep_unset_thread_timer(NULL);
		}
		break;
	case SCHED_IO:
		if ((last_sched_attr != SCHED_IO) && (!sig_count)) {
			machdep_set_thread_timer(&(pthread_run->machdep_data));
		}
		break;
	default:
		machdep_set_thread_timer(&(pthread_run->machdep_data));
		break;
	} 
    last_sched_attr = pthread_run->attr.schedparam_policy;
}

/* ==========================================================================
 * sigvtalrm()
 */
static inline void sigvtalrm() 
{
	if (sig_count) {
		sigset_t sigall, oset;

		sig_count = 0;

		/* Unblock all signals */
		sigemptyset(&sigall);
		machdep_sys_sigprocmask(SIG_SETMASK, &sigall, &oset); 
	}
	context_switch();
	context_switch_done();
}

/* ==========================================================================
 * sigdefault()
 */
static inline void sigdefault(int sig)
{
	int ret;

	ret = pthread_sig_register(sig);
	if (pthread_run && (ret > pthread_run->pthread_priority)) {
		sigvtalrm();
	}
}

/* ==========================================================================
 * sig_handler_switch()
 */
static inline void sig_handler_switch(int sig)
{
	int ret;

			switch(sig) {
			case 0:
				break;
			case SIGVTALRM:
				sigvtalrm();
				break;
			case SIGALRM:
/*		sigdelset((sigset_t *)&sig_to_process, SIGALRM); */
				signum_to_process[SIGALRM] = 0;
				switch (ret = sleep_wakeup()) {
				default:
					if (pthread_run && (ret > pthread_run->pthread_priority)) {
						sigvtalrm();
					}
				case 0:
					break;
				case NOTOK:
			/* Do the registered action, no threads were sleeping */
                                      /* There is a timing window that gets
                                       * here when no threads are on the
                                       * sleep queue.  This is a quick fix.
                                       * The real problem is possibly related
                                       * to heavy use of condition variables
                                       * with time outs.
                                       * (mevans)
                                       *sigdefault(sig);
                                       */
				  break;
				}
				break;
			case SIGCHLD:
/*		sigdelset((sigset_t *)&sig_to_process, SIGCHLD); */
				signum_to_process[SIGCHLD] = 0;
				switch (ret = wait_wakeup()) {
				default:
					if (pthread_run && (ret > pthread_run->pthread_priority)) {
						sigvtalrm();
					}
				case 0:
					break;
				case NOTOK:
			/* Do the registered action, no threads were waiting */
					sigdefault(sig);
					break;
				} 
				break;

#ifdef SIGINFO
			case SIGINFO:
				pthread_dump_info ();
				/* Then fall through, invoking the application's
		   		signal handler after printing our info out.

		   		I'm not convinced that this is right, but I'm not
		   		100% convinced that it is wrong, and this is how
		   		Chris wants it done...  */
#endif

	default:
		/* Do the registered action */
		if (!sigismember(uthread_sigmask, sig)) {
			/*
			 * If the signal isn't masked by the last running thread and
			 * the signal behavior is default or ignore then we can
			 * execute it immediatly. --proven
			 */
			pthread_sig_default(sig);
		}
		signum_to_process[sig] = 0;
		sigdefault(sig);
		break;
	}

}

/* ==========================================================================
 * sig_handler()
 *
 * Process signal that just came in, plus any pending on the signal mask.
 * All of these must be resolved.
 *
 * Assumes the kernel is locked. 
 */
static void sig_handler(int sig)
{
	if (pthread_kernel_lock != 1) {
		PANIC();
	}

	if (sig) { 
		sig_handler_switch(sig);
	}

	while (sig_to_process) {
		for (sig_to_process = 0, sig = 1; sig <= SIGMAX; sig++) {
			if (signum_to_process[sig]) {
				sig_handler_switch(sig);
			}
		}
	}

		
/*
	if (SIG_ANY(sig_to_process)) {
		for (sig = 1; sig <= SIGMAX; sig++) {
			if (sigismember((sigset_t *)&sig_to_process, sig)) {
				goto sig_handler_top;
			}
		}
	}
*/
}

/* ==========================================================================
 * sig_handler_real()
 * 
 * On a multi-processor this would need to use the test and set instruction
 * otherwise the following will work.
 */
void sig_handler_real(int sig)
{
	/*
	 * Get around systems with BROKEN signal handlers.
	 *
	 * Some systems will reissue SIGCHLD if the handler explicitly
	 * clear the signal pending by either doing a wait() or 
	 * ignoring the signal.
	 */
#if defined BROKEN_SIGNALS
	if (sig == SIGCHLD) {
		sigignore(SIGCHLD);
		signal(SIGCHLD, sig_handler_real);
	}
#endif

	if (pthread_kernel_lock) {
		/* sigaddset((sigset_t *)&sig_to_process, sig); */
		__fd_kern_wait_timeout.tv_sec = 0;
		signum_to_process[sig] = 1;
		sig_to_process = 1;
		return;
	}
	pthread_kernel_lock++;

	sig_count++;
	sig_handler(sig);

	/* Handle any signals the current thread might have just gotten */
	if (pthread_run && pthread_run->sigcount) {
		pthread_sig_process();
	}
	pthread_kernel_lock--;
}

/* ==========================================================================
 * sig_handler_fake()
 */
void sig_handler_fake(int sig)
{
	if (pthread_kernel_lock) {
		/* sigaddset((sigset_t *)&sig_to_process, sig); */
		signum_to_process[sig] = 1;
		sig_to_process = 1;
		return;
	}
	pthread_kernel_lock++;
	sig_handler(sig);
	while (!(--pthread_kernel_lock)) {
		if (sig_to_process) {
		/* if (SIG_ANY(sig_to_process)) { */
			pthread_kernel_lock++;
			sig_handler(0);
		} else {
			break;
		}
	}
}

/* ==========================================================================
 * __pthread_signal_delete(int sig)
 *
 * Assumes the kernel is locked.
 */
void __pthread_signal_delete(int sig)
{
		signum_to_process[sig] = 0;
}

/* ==========================================================================
 * pthread_sched_other_resume()
 *
 * Check if thread to be resumed is of higher priority and if so
 * stop current thread and start new thread.
 */
pthread_sched_other_resume(struct pthread * pthread)
{
	pthread->state = PS_RUNNING;
	pthread_prio_queue_enq(pthread_current_prio_queue, pthread);

	if (pthread->pthread_priority > pthread_run->pthread_priority) {
		if (pthread_kernel_lock == 1) {
			sig_handler(SIGVTALRM);
		}
	}

	__cleanup_after_resume();
}

/* ==========================================================================
 * pthread_resched_resume()
 *
 * This routine assumes that the caller is the current pthread, pthread_run
 * and that it has a lock the kernel thread and it wants to reschedule itself.
 */
void pthread_resched_resume(enum pthread_state state)
{
	pthread_run->state = state;

	/* Since we are about to block this thread, lets see if we are
	 * at a cancel point and if we've been cancelled.
	 * Avoid cancelling dead or unalloced threads.
	 */
	if( ! TEST_PF_RUNNING_TO_CANCEL(pthread_run) &&
		TEST_PTHREAD_IS_CANCELLABLE(pthread_run) &&
		state != PS_DEAD && state != PS_UNALLOCED ) {

		/* Set this flag to avoid recursively calling pthread_exit */
		/* We have to set this flag here because we will unlock the
		 * kernel prior to calling pthread_cancel_internal.
		 */
		SET_PF_RUNNING_TO_CANCEL(pthread_run);

		pthread_run->old_state = state;	/* unlock needs this data */
		pthread_sched_resume();			/* Unlock kernel before cancel */
		pthread_cancel_internal( 1 );	/* free locks and exit */
	}

	sig_handler(SIGVTALRM);

	__cleanup_after_resume();
}

/* ==========================================================================
 * pthread_sched_resume()
 */
void pthread_sched_resume()
{
	__cleanup_after_resume();
}

/*----------------------------------------------------------------------
 * Function:	__cleanup_after_resume
 * Purpose:		cleanup kernel locks after a resume
 * Args:		void
 * Returns:		void
 * Notes:
 *----------------------------------------------------------------------*/
static void
__cleanup_after_resume( void )
{
	/* Only bother if we are truely unlocking the kernel */
	while (!(--pthread_kernel_lock)) {
		/* if (SIG_ANY(sig_to_process)) { */
		if (sig_to_process) {
			pthread_kernel_lock++;
			sig_handler(0);
			continue;
		}
		if (pthread_run && pthread_run->sigcount) {
			pthread_kernel_lock++;
			pthread_sig_process();
			continue;
		}
		break;
	}

	if( pthread_run == NULL )
		return;							/* Must be during init processing */

	/* Test for cancel that should be handled now */

	if( ! TEST_PF_RUNNING_TO_CANCEL(pthread_run) &&
		TEST_PTHREAD_IS_CANCELLABLE(pthread_run) ) {
		/* Kernel is already unlocked */
		pthread_cancel_internal( 1 );	/* free locks and exit */
	}
}

/* ==========================================================================
 * pthread_sched_prevent()
 */
void pthread_sched_prevent(void)
{
	pthread_kernel_lock++;
}

/* ==========================================================================
 * sig_init()
 *
 * SIGVTALRM	(NOT POSIX) needed for thread timeslice timeouts.
 *				Since it's not POSIX I will replace it with a 
 *				virtual timer for threads.
 * SIGALRM		(IS POSIX) so some special handling will be
 * 				necessary to fake SIGALRM signals
 */
#ifndef SIGINFO
#define SIGINFO 0
#endif
void sig_init(void)
{
	static const int signum_to_initialize[] = 
					 { SIGCHLD, SIGALRM, SIGVTALRM, SIGINFO, 0 };
	static const int signum_to_ignore[] = { SIGKILL, SIGSTOP, 0 };
	int i, j;

	struct sigaction act;

	act.sa_handler = sig_handler_real;
	sigemptyset(&(act.sa_mask));
	act.sa_flags = 0;

	/* Initialize the important signals */
	for (i = 0; signum_to_initialize[i]; i++) {

		if (sigaction(signum_to_initialize[i], &act, NULL)) {
			PANIC();
		}
	}

	/* Initialize the rest of the signals */
	for (j = 1; j < SIGMAX; j++) {
		for (i = 0; signum_to_initialize[i]; i++) {
			if (signum_to_initialize[i] == j) {
				goto sig_next;
			}
		}
		/* Because Solaris 2.4 can't deal -- proven */
		for (i = 0; signum_to_ignore[i]; i++) {
			if (signum_to_ignore[i] == j) {
				goto sig_next;
			}
		}
		pthread_signal(j, SIG_DFL);
		
		sigaction(j, &act, NULL);

		sig_next:;
	}

#if defined BROKEN_SIGNALS 
	signal(SIGCHLD, sig_handler_real);
#endif

}

@


1.3
log
@o removed more unused or old, left over files

o general changes so that now the library compiles and many of the
  tests run correctly

o pthreads/Makefile.inc rebuilt using libc/sys/Makefile.inc as a template.
  this should be kept in sync in case of new syscalls

soon TODO:
figure out why remaining tests fail and fix
look at building .so version of library
tidy up arch/i386 directory - no longer uses syscall-template.S
port other arch's from libc syscall templates
@
text
@d39 1
a39 1
static const char rcsid[] = "$Id: signal.c,v 1.2 1998/07/21 19:48:04 peter Exp $";
@


1.2
log
@this will now compile on i386 if you move arch/i386/machdep.h to
arch/i386/pthread/machdep.h - not an ideal solution. Correct fix
is welcome. I am quiting work on this for today, so other hackers
are welcome to take it up for the rest of the day/night. More from
me tomorrow.
@
text
@d39 1
a39 1
static const char rcsid[] = "$Id: signal.c,v 1.1.1.2 1998/07/21 13:20:22 peter Exp $";
a602 1
#if defined(HAVE_SYSCALL_SIGACTION) || defined(HAVE_SYSCALL_KSIGACTION)
a607 1
#endif
a611 1
#if defined(HAVE_SYSCALL_SIGACTION) || defined(HAVE_SYSCALL_KSIGACTION)
a612 3
#else
		if (signal(signum_to_initialize[i], sig_handler_real)) { 
#endif
a631 1
#if defined(HAVE_SYSCALL_SIGACTION) || defined(HAVE_SYSCALL_KSIGACTION)
a632 3
#else
		signal(j, sig_handler_real);
#endif
@


1.1
log
@Initial revision
@
text
@d39 1
a39 1
static const char rcsid[] = "$Id: signal.c,v 1.3 1994/02/07 22:04:29 proven Exp $ $provenid: signal.c,v 1.18 1994/02/07 02:19:28 proven Exp $";
d45 8
d65 5
a69 3
static volatile	sigset_t sig_to_tryagain;
static volatile	sigset_t sig_to_process;
static volatile	int kernel_lock = 0;
d74 1
d89 6
a94 3
	struct pthread **current, *next, *last;
	semaphore *lock;
	int count;
d96 4
a105 5
	if (pthread_run = pthread_queue_deq(&pthread_current_queue)) {
		/* restore state of new current thread */
		machdep_restore_state();
		return;
	}
d107 1
a107 1
	/* Poll all the kernel fds */
d111 49
a159 31
	/*
	 * Go through the reschedule list once, this is the only place
	 * that goes through the queue without using the queue routines.
	 *
	 * But first delete the current queue.
	 */
	pthread_queue_init(&pthread_current_queue);
	current = &(pthread_link_list);
	count = 0;

	while (*current) {
		switch((*current)->state) {
		case PS_RUNNING:
			pthread_queue_enq(&pthread_current_queue, *current);
			current = &((*current)->pll);
			count++;
			break;
		case PS_DEAD:
			/* Cleanup thread, unless we're using the stack */
			if (((*current)->flags & PF_DETACHED) && (*current != last)) {
				next = (*current)->pll;
				lock = &((*current)->lock);
				if (SEMAPHORE_TEST_AND_SET(lock)) {
					/* Couldn't cleanup this time, try again later */
					current = &((*current)->pll);
				} else {
					if (!((*current)->attr.stackaddr_attr)) {
						free (machdep_pthread_cleanup(&((*current)->machdep_data)));
					}
					free (*current);
					*current = next;
a160 2
			} else {
				current = &((*current)->pll);
d162 2
a163 6
			break;
		default:
			/* Should be on a different queue. Ignore. */
			current = &((*current)->pll);
			count++;
			break;
d167 4
a170 6
	/* Are there any threads to run */
	if (pthread_run = pthread_queue_deq(&pthread_current_queue)) {
        /* restore state of new current thread */
		machdep_restore_state();
        return;
    }
d172 1
a172 7
	/* Are there any threads at all */
	if (count) {
		/*
		 * Do a wait, timeout is set to a hour unless we get an interrupt
		 * before the select in wich case it polls and returns. 
		 */
		fd_kern_wait();
d174 7
a180 2
		/* Check for interrupts, but ignore SIGVTALR */
		sigdelset(&sig_to_process, SIGVTALRM); 
d182 1
a182 10
		if (sig_to_process) {
			/* Process interrupts */
			sig_handler(0); 
		}

		goto context_switch_reschedule;

	}
	exit(0);
}
d191 1
a191 1
	sigset_t sig_to_block, sig_to_pause;
d195 2
a196 1
	sigprocmask(SIG_BLOCK, &sig_to_block, NULL);
d198 1
a198 1
		sigsuspend(&sig_to_pause);
d200 1
a200 1
	sigprocmask(SIG_UNBLOCK, &sig_to_block, NULL);
d215 2
a216 1
	sigdelset(&sig_to_process, SIGVTALRM);
d229 1
a229 1
	switch (pthread_run->attr.sched_attr) {
d235 1
a235 1
			machdep_unset_thread_timer();
d247 114
a360 1
    last_sched_attr = pthread_run->attr.sched_attr;
d366 3
d373 3
d377 2
a378 20
	/*
	 * First check for old signals, do one pass through and don't
 	 * check any twice.
     */
	if (sig_to_tryagain) {
		if (sigismember(&sig_to_tryagain, SIGALRM)) {
			switch (sleep_wakeup()) {
			case 1:
				/* Do the default action, no threads were sleeping */
			case OK:
				/* Woke up a sleeping thread */
				sigdelset(&sig_to_tryagain, SIGALRM);
				break;
			case NOTOK:
				/* Couldn't get appropriate locks, try again later */
				break;
			}
		} else {
			PANIC();
		}
a379 5
		
	/*
	 * NOW, process signal that just came in, plus any pending on the
	 * signal mask. All of these must be resolved.
	 */
d381 5
a385 14
sig_handler_top:;

	switch(sig) {
	case 0:
		break;
	case SIGVTALRM:
		if (sig_count) {
			sigset_t sigall;

			sig_count = 0;

			/* Unblock all signals */
			sigemptyset(&sigall);
			sigprocmask(SIG_SETMASK, &sigall, NULL); 
a386 19
		context_switch();
		context_switch_done();
		break;
	case SIGALRM:
		sigdelset(&sig_to_process, SIGALRM);
		switch (sleep_wakeup()) {
		case 1:
			/* Do the default action, no threads were sleeping */
		case OK:
			/* Woke up a sleeping thread */
			break;
		case NOTOK:
			/* Couldn't get appropriate locks, try again later */
			sigaddset(&sig_to_tryagain, SIGALRM);
			break;
		} 
		break;
	default:
		PANIC();
d389 3
a391 2
	/* Determine if there are any other signals */
	if (sig_to_process) {
d393 1
a393 3
			if (sigismember(&sig_to_process, sig)) {
		
				/* goto sig_handler_top */
d398 1
d409 16
a424 1
	if (kernel_lock) {
d426 2
a427 1
		sigaddset(&sig_to_process, sig);
d430 2
a431 1
	sig_prevent();
d434 6
a439 1
	sig_resume();
d447 5
a451 3
	if (kernel_lock) {
		/* Currently this should be impossible */
		PANIC();
d453 1
a453 1
	sig_prevent();
d455 9
a463 1
	sig_resume();
d467 1
a467 1
 * reschedule()
d469 12
a480 2
 * This routine assumes that the caller is the current pthread, pthread_run
 * and that it has a lock on itself and that it wants to reschedule itself.
d482 1
a482 1
void reschedule(enum pthread_state state)
d484 2
a485 1
	semaphore *plock;
d487 4
a490 3
	if (kernel_lock) {
		/* Currently this should be impossible */
		PANIC();
d492 2
a493 5
	sig_prevent();
	pthread_run->state = state;
	SEMAPHORE_RESET((plock = &(pthread_run->lock)));
	sig_handler(SIGVTALRM);
	sig_resume();
d497 4
a500 1
 * sig_prevent()
d502 1
a502 1
void sig_prevent(void)
d504 24
a527 1
	kernel_lock++;
d531 1
a531 1
 * sig_resume()
d533 1
a533 1
void sig_resume()
d535 1
a535 1
	kernel_lock--;
d538 9
a546 4
/* ==========================================================================
 * sig_check_and_resume()
 */
void sig_check_and_resume()
a547 2
	/* Some routine name that is yet to be determined. */
	
d549 2
a550 3
	while (!(--kernel_lock)) {

		/* Assume sigset_t is not a struct or union */
d552 1
a552 1
			kernel_lock++;
d554 6
a559 2
		} else {
			break;
d561 12
d577 8
d593 3
d598 4
a601 1
	int sig_to_init[] = { SIGVTALRM, SIGALRM, 0 };
d603 1
a603 1
#if defined(SA_RESTART)
a604 3
#endif

	int i;
a605 1
#if defined(SA_RESTART)
d608 1
a608 1
	act.sa_flags = SA_RESTART;
d611 2
a612 2
	/* Initialize only the necessary signals */
	for (i = 0; sig_to_init[i]; i++) {
d614 2
a615 2
#if defined(SA_RESTART)
		if (sigaction(sig_to_init[i], &act, NULL)) {
d617 1
a617 1
		if (signal(sig_to_init[i], sig_handler_real)) { 
d622 29
@


1.1.1.1
log
@initial import of NetBSD tree
@
text
@@


1.1.1.2
log
@Complete initial import from mySQL 3.22.4 (mit-pthreads/).
Lots of dross to move and remove yet.

At minimum:
o	remove GNU config and GNU Makefiles
o	build arch directory and migrate away machdep/
o	rebuild BSD Makefiles
o	move notes etc. into doc/
@
text
@d39 1
a39 1
static const char rcsid[] = "$Id: signal.c,v 1.76.2.3 1996/03/13 04:33:17 proven Exp $";
a43 9
#include <config.h>

/* This will force init.o to get dragged in; if you've got support for
   C++ initialization, that'll cause pthread_init to be called at
   program startup automatically, so the application won't need to
   call it explicitly.  */

extern char __pthread_init_hack;
char *__pthread_init_hack_2 = &__pthread_init_hack;
d57 3
a59 5

static sig_atomic_t signum_to_process[SIGMAX + 1] = { 0, };
volatile sig_atomic_t sig_to_process = 0;

/* static volatile	sigset_t sig_to_process; */
a63 1
static void __cleanup_after_resume( void );
d78 3
a80 6
	struct pthread **current, *next, *last, **dead;

	if (pthread_run->state == PS_RUNNING) {
		/* Put current thread back on the queue */
		pthread_prio_queue_enq(pthread_current_prio_queue, pthread_run);
	}
a81 4
	/* save floating point registers if necessary */
	if (!(pthread_run->attr.flags & PTHREAD_NOFLOAT)) {
		machdep_save_float_state(pthread_run);
	}
d88 5
d94 1
a94 1
	/* Poll all fds */
d98 44
d143 2
a144 7
	if (pthread_run = pthread_prio_queue_deq(pthread_current_prio_queue)) {
		/* restore floating point registers if necessary */
		if (!(pthread_run->attr.flags & PTHREAD_NOFLOAT)) {
			machdep_restore_float_state();
		}
		uthread_sigmask = &(pthread_run->sigmask);
      	/* restore state of new current thread */
d146 2
a147 2
    	return;
   	} 
d150 13
a162 40
	for (next = pthread_link_list; next; next = next->pll) {
		if ((next->state != PS_UNALLOCED) && (next->state != PS_DEAD)) {
			sigset_t sig_to_block, oset;

			sigfillset(&sig_to_block);

			/*
			 * Check sig_to_process before calling fd_kern_wait, to handle
			 * things like zero timeouts to select() which would register
			 * a signal with the sig_handler_fake() call.
			 *
			 * This case should ignore SIGVTALRM
			 */
			machdep_sys_sigprocmask(SIG_BLOCK, &sig_to_block, &oset);
			signum_to_process[SIGVTALRM] = 0;
			if (sig_to_process) {
              	/* Process interrupts */
               	/*
               	 * XXX pthread_run should not be set!
				 * Places where it dumps core should be fixed to 
				 * check for the existance of pthread_run --proven
               	 */
               	sig_handler(0);
           	} else {
				machdep_sys_sigprocmask(SIG_UNBLOCK, &sig_to_block, &oset);
				/*
				 * Do a wait, timeout is set to a hour unless we get an 
				 * intr. before the select in wich case it polls.
				 */
				fd_kern_wait();
				machdep_sys_sigprocmask(SIG_BLOCK, &sig_to_block, &oset);
				/* Check for interrupts, but ignore SIGVTALR */
				signum_to_process[SIGVTALRM] = 0;
				if (sig_to_process) {
					/* Process interrupts */
					sig_handler(0); 
				}
			}
			machdep_sys_sigprocmask(SIG_UNBLOCK, &sig_to_block, &oset); 
			goto context_switch_reschedule;
d164 3
a167 3

	/* There are no threads alive. */
	pthread_run = last;
a170 12
#if !defined(HAVE_SYSCALL_SIGSUSPEND) && defined(HAVE_SYSCALL_SIGPAUSE)

/* ==========================================================================
 * machdep_sys_sigsuspend()
 */ 
int machdep_sys_sigsuspend(sigset_t * set)
{
	return(machdep_sys_sigpause(* set));
}

#endif

d178 1
a178 1
	sigset_t sig_to_block, sig_to_pause, oset;
d182 1
a182 2
	machdep_sys_sigprocmask(SIG_BLOCK, &sig_to_block, &oset);
/*	if (!(SIG_ANY(sig_to_process))) { */
d184 1
a184 1
		machdep_sys_sigsuspend(&sig_to_pause);
d186 1
a186 1
	machdep_sys_sigprocmask(SIG_UNBLOCK, &sig_to_block, &oset);
d201 1
a201 2
	/* sigdelset((sigset_t *)&sig_to_process, SIGVTALRM); */
	signum_to_process[SIGVTALRM] = 0;
d214 1
a214 1
	switch (pthread_run->attr.schedparam_policy) {
d220 1
a220 1
			machdep_unset_thread_timer(NULL);
d232 1
a232 1
    last_sched_attr = pthread_run->attr.schedparam_policy;
d236 3
a238 1
 * sigvtalrm()
d240 1
a240 1
static inline void sigvtalrm() 
a241 2
	if (sig_count) {
		sigset_t sigall, oset;
d243 12
a254 32
		sig_count = 0;

		/* Unblock all signals */
		sigemptyset(&sigall);
		machdep_sys_sigprocmask(SIG_SETMASK, &sigall, &oset); 
	}
	context_switch();
	context_switch_done();
}

/* ==========================================================================
 * sigdefault()
 */
static inline void sigdefault(int sig)
{
	int ret;

	ret = pthread_sig_register(sig);
	if (pthread_run && (ret > pthread_run->pthread_priority)) {
		sigvtalrm();
	}
}

/* ==========================================================================
 * sig_handler_switch()
 */
static inline void sig_handler_switch(int sig)
{
	int ret;

			switch(sig) {
			case 0:
d256 2
a257 42
			case SIGVTALRM:
				sigvtalrm();
				break;
			case SIGALRM:
/*		sigdelset((sigset_t *)&sig_to_process, SIGALRM); */
				signum_to_process[SIGALRM] = 0;
				switch (ret = sleep_wakeup()) {
				default:
					if (pthread_run && (ret > pthread_run->pthread_priority)) {
						sigvtalrm();
					}
				case 0:
					break;
				case NOTOK:
			/* Do the registered action, no threads were sleeping */
                                      /* There is a timing window that gets
                                       * here when no threads are on the
                                       * sleep queue.  This is a quick fix.
                                       * The real problem is possibly related
                                       * to heavy use of condition variables
                                       * with time outs.
                                       * (mevans)
                                       *sigdefault(sig);
                                       */
				  break;
				}
				break;
			case SIGCHLD:
/*		sigdelset((sigset_t *)&sig_to_process, SIGCHLD); */
				signum_to_process[SIGCHLD] = 0;
				switch (ret = wait_wakeup()) {
				default:
					if (pthread_run && (ret > pthread_run->pthread_priority)) {
						sigvtalrm();
					}
				case 0:
					break;
				case NOTOK:
			/* Do the registered action, no threads were waiting */
					sigdefault(sig);
					break;
				} 
d259 10
d270 1
a270 10
#ifdef SIGINFO
			case SIGINFO:
				pthread_dump_info ();
				/* Then fall through, invoking the application's
		   		signal handler after printing our info out.

		   		I'm not convinced that this is right, but I'm not
		   		100% convinced that it is wrong, and this is how
		   		Chris wants it done...  */
#endif
d272 12
a283 9
	default:
		/* Do the registered action */
		if (!sigismember(uthread_sigmask, sig)) {
			/*
			 * If the signal isn't masked by the last running thread and
			 * the signal behavior is default or ignore then we can
			 * execute it immediatly. --proven
			 */
			pthread_sig_default(sig);
d285 2
a286 2
		signum_to_process[sig] = 0;
		sigdefault(sig);
d288 15
a302 15
	}

}

/* ==========================================================================
 * sig_handler()
 *
 * Process signal that just came in, plus any pending on the signal mask.
 * All of these must be resolved.
 *
 * Assumes the kernel is locked. 
 */
static void sig_handler(int sig)
{
	if (pthread_kernel_lock != 1) {
d306 4
a309 12
	if (sig) { 
		sig_handler_switch(sig);
	}

	while (sig_to_process) {
		for (sig_to_process = 0, sig = 1; sig <= SIGMAX; sig++) {
			if (signum_to_process[sig]) {
				sig_handler_switch(sig);
			}
		}
	}

d311 1
a311 4
/*
	if (SIG_ANY(sig_to_process)) {
		for (sig = 1; sig <= SIGMAX; sig++) {
			if (sigismember((sigset_t *)&sig_to_process, sig)) {
a315 1
*/
d326 1
a326 16
	/*
	 * Get around systems with BROKEN signal handlers.
	 *
	 * Some systems will reissue SIGCHLD if the handler explicitly
	 * clear the signal pending by either doing a wait() or 
	 * ignoring the signal.
	 */
#if defined BROKEN_SIGNALS
	if (sig == SIGCHLD) {
		sigignore(SIGCHLD);
		signal(SIGCHLD, sig_handler_real);
	}
#endif

	if (pthread_kernel_lock) {
		/* sigaddset((sigset_t *)&sig_to_process, sig); */
d328 1
a328 2
		signum_to_process[sig] = 1;
		sig_to_process = 1;
d331 1
a331 2
	pthread_kernel_lock++;

d334 1
a334 6

	/* Handle any signals the current thread might have just gotten */
	if (pthread_run && pthread_run->sigcount) {
		pthread_sig_process();
	}
	pthread_kernel_lock--;
d342 3
a344 5
	if (pthread_kernel_lock) {
		/* sigaddset((sigset_t *)&sig_to_process, sig); */
		signum_to_process[sig] = 1;
		sig_to_process = 1;
		return;
d346 1
a346 1
	pthread_kernel_lock++;
d348 1
a348 9
	while (!(--pthread_kernel_lock)) {
		if (sig_to_process) {
		/* if (SIG_ANY(sig_to_process)) { */
			pthread_kernel_lock++;
			sig_handler(0);
		} else {
			break;
		}
	}
d352 1
a352 1
 * __pthread_signal_delete(int sig)
d354 2
a355 1
 * Assumes the kernel is locked.
d357 1
a357 1
void __pthread_signal_delete(int sig)
d359 11
a369 1
		signum_to_process[sig] = 0;
d373 1
a373 4
 * pthread_sched_other_resume()
 *
 * Check if thread to be resumed is of higher priority and if so
 * stop current thread and start new thread.
d375 1
a375 1
pthread_sched_other_resume(struct pthread * pthread)
d377 1
a377 10
	pthread->state = PS_RUNNING;
	pthread_prio_queue_enq(pthread_current_prio_queue, pthread);

	if (pthread->pthread_priority > pthread_run->pthread_priority) {
		if (pthread_kernel_lock == 1) {
			sig_handler(SIGVTALRM);
		}
	}

	__cleanup_after_resume();
d381 1
a381 4
 * pthread_resched_resume()
 *
 * This routine assumes that the caller is the current pthread, pthread_run
 * and that it has a lock the kernel thread and it wants to reschedule itself.
d383 1
a383 1
void pthread_resched_resume(enum pthread_state state)
d385 1
a385 24
	pthread_run->state = state;

	/* Since we are about to block this thread, lets see if we are
	 * at a cancel point and if we've been cancelled.
	 * Avoid cancelling dead or unalloced threads.
	 */
	if( ! TEST_PF_RUNNING_TO_CANCEL(pthread_run) &&
		TEST_PTHREAD_IS_CANCELLABLE(pthread_run) &&
		state != PS_DEAD && state != PS_UNALLOCED ) {

		/* Set this flag to avoid recursively calling pthread_exit */
		/* We have to set this flag here because we will unlock the
		 * kernel prior to calling pthread_cancel_internal.
		 */
		SET_PF_RUNNING_TO_CANCEL(pthread_run);

		pthread_run->old_state = state;	/* unlock needs this data */
		pthread_sched_resume();			/* Unlock kernel before cancel */
		pthread_cancel_internal( 1 );	/* free locks and exit */
	}

	sig_handler(SIGVTALRM);

	__cleanup_after_resume();
d389 1
a389 1
 * pthread_sched_resume()
d391 1
a391 1
void pthread_sched_resume()
d393 4
a396 2
	__cleanup_after_resume();
}
d398 1
a398 13
/*----------------------------------------------------------------------
 * Function:	__cleanup_after_resume
 * Purpose:		cleanup kernel locks after a resume
 * Args:		void
 * Returns:		void
 * Notes:
 *----------------------------------------------------------------------*/
static void
__cleanup_after_resume( void )
{
	/* Only bother if we are truely unlocking the kernel */
	while (!(--pthread_kernel_lock)) {
		/* if (SIG_ANY(sig_to_process)) { */
d400 1
a400 1
			pthread_kernel_lock++;
d402 2
a403 6
			continue;
		}
		if (pthread_run && pthread_run->sigcount) {
			pthread_kernel_lock++;
			pthread_sig_process();
			continue;
a404 12
		break;
	}

	if( pthread_run == NULL )
		return;							/* Must be during init processing */

	/* Test for cancel that should be handled now */

	if( ! TEST_PF_RUNNING_TO_CANCEL(pthread_run) &&
		TEST_PTHREAD_IS_CANCELLABLE(pthread_run) ) {
		/* Kernel is already unlocked */
		pthread_cancel_internal( 1 );	/* free locks and exit */
a408 8
 * pthread_sched_prevent()
 */
void pthread_sched_prevent(void)
{
	pthread_kernel_lock++;
}

/* ==========================================================================
a416 3
#ifndef SIGINFO
#define SIGINFO 0
#endif
d419 1
a419 4
	static const int signum_to_initialize[] = 
					 { SIGCHLD, SIGALRM, SIGVTALRM, SIGINFO, 0 };
	static const int signum_to_ignore[] = { SIGKILL, SIGSTOP, 0 };
	int i, j;
d421 1
a421 1
#if defined(HAVE_SYSCALL_SIGACTION) || defined(HAVE_SYSCALL_KSIGACTION)
d423 3
d427 1
d430 1
a430 1
	act.sa_flags = 0;
d433 2
a434 2
	/* Initialize the important signals */
	for (i = 0; signum_to_initialize[i]; i++) {
d436 2
a437 2
#if defined(HAVE_SYSCALL_SIGACTION) || defined(HAVE_SYSCALL_KSIGACTION)
		if (sigaction(signum_to_initialize[i], &act, NULL)) {
d439 1
a439 1
		if (signal(signum_to_initialize[i], sig_handler_real)) { 
a443 29

	/* Initialize the rest of the signals */
	for (j = 1; j < SIGMAX; j++) {
		for (i = 0; signum_to_initialize[i]; i++) {
			if (signum_to_initialize[i] == j) {
				goto sig_next;
			}
		}
		/* Because Solaris 2.4 can't deal -- proven */
		for (i = 0; signum_to_ignore[i]; i++) {
			if (signum_to_ignore[i] == j) {
				goto sig_next;
			}
		}
		pthread_signal(j, SIG_DFL);
		
#if defined(HAVE_SYSCALL_SIGACTION) || defined(HAVE_SYSCALL_KSIGACTION)
		sigaction(j, &act, NULL);
#else
		signal(j, sig_handler_real);
#endif

		sig_next:;
	}

#if defined BROKEN_SIGNALS 
	signal(SIGCHLD, sig_handler_real);
#endif

@

