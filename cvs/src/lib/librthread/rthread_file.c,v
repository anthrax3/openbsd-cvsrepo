head	1.10;
access;
symbols
	OPENBSD_6_1:1.10.0.4
	OPENBSD_6_1_BASE:1.10
	OPENBSD_6_0:1.8.0.2
	OPENBSD_6_0_BASE:1.8
	OPENBSD_5_9:1.7.0.8
	OPENBSD_5_9_BASE:1.7
	OPENBSD_5_8:1.7.0.10
	OPENBSD_5_8_BASE:1.7
	OPENBSD_5_7:1.7.0.2
	OPENBSD_5_7_BASE:1.7
	OPENBSD_5_6:1.7.0.6
	OPENBSD_5_6_BASE:1.7
	OPENBSD_5_5:1.7.0.4
	OPENBSD_5_5_BASE:1.7
	OPENBSD_5_4:1.6.0.2
	OPENBSD_5_4_BASE:1.6
	OPENBSD_5_3:1.4.0.6
	OPENBSD_5_3_BASE:1.4
	OPENBSD_5_2:1.4.0.4
	OPENBSD_5_2_BASE:1.4
	OPENBSD_5_1_BASE:1.4
	OPENBSD_5_1:1.4.0.2
	OPENBSD_5_0:1.2.0.8
	OPENBSD_5_0_BASE:1.2
	OPENBSD_4_9:1.2.0.6
	OPENBSD_4_9_BASE:1.2
	OPENBSD_4_8:1.2.0.4
	OPENBSD_4_8_BASE:1.2
	OPENBSD_4_7:1.2.0.2
	OPENBSD_4_7_BASE:1.2;
locks; strict;
comment	@ * @;


1.10
date	2016.09.04.10.13.35;	author akfaew;	state Exp;
branches;
next	1.9;
commitid	tPNEomz2X1xlRc3u;

1.9
date	2016.09.03.16.44.20;	author akfaew;	state Exp;
branches;
next	1.8;
commitid	A8DISbEBB3jwsSL3;

1.8
date	2016.05.07.19.05.22;	author guenther;	state Exp;
branches;
next	1.7;
commitid	d9R7VGw9CHTkwXE1;

1.7
date	2013.11.21.17.45.10;	author fgsch;	state Exp;
branches;
next	1.6;

1.6
date	2013.06.01.23.06.26;	author tedu;	state Exp;
branches;
next	1.5;

1.5
date	2013.06.01.20.47.40;	author tedu;	state Exp;
branches;
next	1.4;

1.4
date	2012.01.17.02.34.18;	author guenther;	state Exp;
branches;
next	1.3;

1.3
date	2011.11.06.11.48.59;	author guenther;	state Exp;
branches;
next	1.2;

1.2
date	2009.11.27.19.45.54;	author guenther;	state Exp;
branches;
next	1.1;

1.1
date	2009.10.21.16.05.48;	author guenther;	state Exp;
branches;
next	;


desc
@@


1.10
log
@Get rid of ticket support, replace "struct _spinlock" with "_atomic_lock_t".

ok tedu@@
@
text
@/*	$OpenBSD: rthread_file.c,v 1.9 2016/09/03 16:44:20 akfaew Exp $	*/
/*
 * Copyright (c) 1995 John Birrell <jb@@cimlogic.com.au>.
 * All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *	This product includes software developed by John Birrell.
 * 4. Neither the name of the author nor the names of any co-contributors
 *    may be used to endorse or promote products derived from this software
 *    without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY JOHN BIRRELL AND CONTRIBUTORS ``AS IS'' AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE
 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
 *
 * $FreeBSD: uthread_file.c,v 1.9 1999/08/28 00:03:32 peter Exp $
 *
 * POSIX stdio FILE locking functions. These assume that the locking
 * is only required at FILE structure level, not at file descriptor
 * level too.
 *
 */
#include <stdint.h>
#include <stdio.h>
#include <stdlib.h>
#include <sys/queue.h>
#include <pthread.h>
#include "rthread.h"
#include "rthread_cb.h"

/*
 * The FILE lock structure. The FILE *fp is locked if the owner is
 * not NULL. If not locked, the file lock structure can be
 * reassigned to a different file by setting fp.
 */
struct	file_lock {
	LIST_ENTRY(file_lock)	entry;	/* Entry if file list.       */
	FILE			*fp;	/* The target file.          */
	struct pthread_queue	lockers;
	pthread_t		owner;
	int			count;
};

/*
 * The number of file lock lists into which the file pointer is
 * hashed. Ideally, the FILE structure size would have been increased,
 * but this causes incompatibility, so separate data structures are
 * required.
 */
#define NUM_HEADS	128

/*
 * This macro casts a file pointer to a long integer and right
 * shifts this by the number of bytes in a pointer. The shifted
 * value is then remaindered using the maximum number of hash
 * entries to produce and index into the array of static lock
 * structures. If there is a collision, a linear search of the
 * dynamic list of locks linked to each static lock is perfomed.
 */
#define file_idx(_p)	((int)((((uintptr_t) _p) >> sizeof(void *)) % NUM_HEADS))

/*
 * Global array of file locks. The first lock for each hash bucket is
 * allocated statically in the hope that there won't be too many
 * collisions that require a malloc and an element added to the list.
 */
static struct static_file_lock {
	LIST_HEAD(file_list_head, file_lock) head;
	struct	file_lock	fl;
} flh[NUM_HEADS];

/* Lock for accesses to the hash table: */
static _atomic_lock_t	hash_lock	= _SPINLOCK_UNLOCKED;

/*
 * Find a lock structure for a FILE, return NULL if the file is
 * not locked:
 */
static
struct file_lock *
find_lock(int idx, FILE *fp)
{
	struct file_lock *p;

	/* Check if the file is locked using the static structure: */
	if (flh[idx].fl.fp == fp && flh[idx].fl.owner != NULL)
		/* Return a pointer to the static lock: */
		p = &flh[idx].fl;
	else {
		/* Point to the first dynamic lock: */
		p = LIST_FIRST(&flh[idx].head);

		/*
		 * Loop through the dynamic locks looking for the
		 * target file:
		 */
		while (p != NULL && (p->fp != fp || p->owner == NULL))
			/* Not this file, try the next: */
			p = LIST_NEXT(p, entry);
	}
	return(p);
}

/*
 * Lock a file, assuming that there is no lock structure currently
 * assigned to it.
 */
static
struct file_lock *
do_lock(int idx, FILE *fp)
{
	struct file_lock *p;

	/* Check if the static structure is not being used: */
	if (flh[idx].fl.owner == NULL) {
		/* Return a pointer to the static lock: */
		p = &flh[idx].fl;
	}
	else {
		/* Point to the first dynamic lock: */
		p = LIST_FIRST(&flh[idx].head);

		/*
		 * Loop through the dynamic locks looking for a
		 * lock structure that is not being used:
		 */
		while (p != NULL && p->owner != NULL)
			/* This one is used, try the next: */
			p = LIST_NEXT(p, entry);
	}

	/*
	 * If an existing lock structure has not been found,
	 * allocate memory for a new one:
	 */
	if (p == NULL && (p = (struct file_lock *)
	    malloc(sizeof(struct file_lock))) != NULL) {
		/* Add the new element to the list: */
		LIST_INSERT_HEAD(&flh[idx].head, p, entry);
	}

	/* Check if there is a lock structure to acquire: */
	if (p != NULL) {
		/* Acquire the lock for the running thread: */
		p->fp		= fp;
		p->owner	= pthread_self();
		p->count	= 1;
		TAILQ_INIT(&p->lockers);
	}
	return(p);
}

void
_thread_flockfile(FILE * fp)
{
	int	idx = file_idx(fp);
	struct	file_lock	*p;
	pthread_t	self = pthread_self();

	/* Lock the hash table: */
	_spinlock(&hash_lock);

	/* Get a pointer to any existing lock for the file: */
	if ((p = find_lock(idx, fp)) == NULL) {
		/*
		 * The file is not locked, so this thread can
		 * grab the lock:
		 */
		do_lock(idx, fp);

	/*
	 * The file is already locked, so check if the
	 * running thread is the owner:
	 */
	} else if (p->owner == self) {
		/*
		 * The running thread is already the
		 * owner, so increment the count of
		 * the number of times it has locked
		 * the file:
		 */
		p->count++;
	} else {
		/*
		 * The file is locked for another thread.
		 * Append this thread to the queue of
		 * threads waiting on the lock.
		 */
		TAILQ_INSERT_TAIL(&p->lockers,self,waiting);
		while (p->owner != self) {
			__thrsleep(self, 0, NULL, &hash_lock, NULL);
			_spinlock(&hash_lock);
		}
	}

	/* Unlock the hash table: */
	_spinunlock(&hash_lock);
}

int
_thread_ftrylockfile(FILE * fp)
{
	int	ret = -1;
	int	idx = file_idx(fp);
	struct	file_lock	*p;

	/* Lock the hash table: */
	_spinlock(&hash_lock);

	/* Get a pointer to any existing lock for the file: */
	if ((p = find_lock(idx, fp)) == NULL) {
		/*
		 * The file is not locked, so this thread can
		 * grab the lock:
		 */
		p = do_lock(idx, fp);

	/*
	 * The file is already locked, so check if the
	 * running thread is the owner:
	 */
	} else if (p->owner == pthread_self()) {
		/*
		 * The running thread is already the
		 * owner, so increment the count of
		 * the number of times it has locked
		 * the file:
		 */
		p->count++;
	} else {
		/*
		 * The file is locked for another thread,
		 * so this try fails.
		 */
		p = NULL;
	}

	/* Unlock the hash table: */
	_spinunlock(&hash_lock);

	/* Check if the lock was obtained: */
	if (p != NULL)
		/* Return success: */
		ret = 0;

	return (ret);
}

void 
_thread_funlockfile(FILE * fp)
{
	int	idx = file_idx(fp);
	struct	file_lock	*p;

	/* Lock the hash table: */
	_spinlock(&hash_lock);

	/*
	 * Get a pointer to the lock for the file and check that
	 * the running thread is the one with the lock:
	 */
	if ((p = find_lock(idx, fp)) != NULL && p->owner == pthread_self()) {
		/*
		 * Check if this thread has locked the FILE
		 * more than once:
		 */
		if (--p->count == 0) {
			/* Get the new owner of the lock: */
			if ((p->owner = TAILQ_FIRST(&p->lockers)) != NULL) {
				/* Pop the thread off the queue: */
				TAILQ_REMOVE(&p->lockers,p->owner,waiting);

				/*
				 * This is the first lock for the new
				 * owner:
				 */
				p->count = 1;

				__thrwakeup(p->owner, 1);
			}
		}
	}

	/* Unlock the hash table: */
	_spinunlock(&hash_lock);
}
@


1.9
log
@Remove _USING_TICKETS, it's defined as 0. No functional change.

ok tedu@@ mpi@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rthread_file.c,v 1.8 2016/05/07 19:05:22 guenther Exp $	*/
d90 1
a90 1
static	struct _spinlock	hash_lock	= _SPINLOCK_UNLOCKED;
d208 1
a208 1
			__thrsleep(self, 0, NULL, &hash_lock.ticket, NULL);
a303 1

@


1.8
log
@Use a Thread Information Block in both single and multi-threaded programs.
This stores errno, the cancelation flags, and related bits for each thread
and is allocated by ld.so or libc.a.  This is an ABI break from 5.9-stable!

Make libpthread dlopen'able by moving the cancelation wrappers into libc
and doing locking and fork/errno handling via callbacks that libpthread
registers when it first initializes.  'errno' *must* be declared via
<errno.h> now!

Clean up libpthread's symbol exports like libc.

On powerpc, offset the TIB/TCB/TLS data from the register per the ELF spec.

Testing by various, particularly sthen@@ and patrick@@
ok kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rthread_file.c,v 1.7 2013/11/21 17:45:10 fgsch Exp $	*/
d208 1
a208 2
			__thrsleep(self, 0 | _USING_TICKETS, NULL,
			    &hash_lock.ticket, NULL);
@


1.7
log
@remove dead assignment as reported by llvm.
@
text
@d1 1
a1 1
/*	$OpenBSD: rthread_file.c,v 1.6 2013/06/01 23:06:26 tedu Exp $	*/
d46 1
d171 1
a171 1
(flockfile)(FILE * fp)
d219 1
a219 1
(ftrylockfile)(FILE * fp)
d268 1
a268 1
(funlockfile)(FILE * fp)
@


1.6
log
@something's not quite right yet. ticket locks result in more CPU usage
and spinning in kernel. partially back out, but in a way that makes going
forward again easy.
seen by ajacoutot
@
text
@d1 1
a1 1
/*	$OpenBSD: rthread_file.c,v 1.5 2013/06/01 20:47:40 tedu Exp $	*/
d185 1
a185 1
		p = do_lock(idx, fp);
@


1.5
log
@cleanup and consolidate the spinlock_lock (what a name!) code.
it's now atomic_lock to better reflect its usage, and librthread now
features a new spinlock that's really a ticket lock.
thrlseep can handle both types of lock via a flag in the clock arg.
(temp back compat hack)
remove some old stuff that's accumulated along the way and no longer used.
some feedback from dlg, who is concerned with all things ticket lock.
(you need to boot a new kernel before installing librthread)
@
text
@d1 1
a1 1
/*	$OpenBSD: rthread_file.c,v 1.4 2012/01/17 02:34:18 guenther Exp $	*/
d207 2
a208 1
			__thrsleep(self, 0 | 0x8, NULL, &hash_lock.ready, NULL);
@


1.4
log
@Reimplement mutexes, condvars, and rwlocks to eliminate bugs,
particularly the "consume the signal you just sent" hang, and putting
the wait queues in userspace.

Do cancellation handling in pthread_cond_*wait(), pthread_join(),
and sem_wait().

Add __ prefix to thr{sleep,wakeup,exit,sigdivert}() syscalls; add
'abort" argument to thrsleep to close cancellation race; make
thr{sleep,wakeup} return errno values via *retval to avoid touching
userspace errno.
@
text
@d1 1
a1 1
/*	$OpenBSD: rthread_file.c,v 1.3 2011/11/06 11:48:59 guenther Exp $	*/
d89 1
a89 1
static	_spinlock_lock_t	hash_lock	= _SPINLOCK_UNLOCKED;
d207 1
a207 1
			__thrsleep(self, 0, NULL, &hash_lock, NULL);
@


1.3
log
@Move <machine/spinlock.h> into rthread.h; strip out unnecessary #includes
@
text
@d1 1
a1 1
/*	$OpenBSD: rthread_file.c,v 1.2 2009/11/27 19:45:54 guenther Exp $	*/
d207 1
a207 1
			thrsleep(self, 0, NULL, &hash_lock);
d295 1
a295 1
				thrwakeup(p->owner, 1);
@


1.2
log
@Convert thrsleep() to an absolute timeout with clockid to eliminate a
race condition and prep for later support of pthread_condattr_setclock()

"get it in" deraadt@@, tedu@@, cheers by others
@
text
@d1 1
a1 1
/*	$OpenBSD: rthread_file.c,v 1.1 2009/10/21 16:05:48 guenther Exp $	*/
a42 1
#include <string.h>
a44 1
#include <machine/spinlock.h>
@


1.1
log
@Add f*lockfile() routines to librthread

ok kurt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uthread_file.c,v 1.14 2008/03/23 00:51:57 deraadt Exp $	*/
d209 1
a209 1
			thrsleep(self, 0, &hash_lock);
@

