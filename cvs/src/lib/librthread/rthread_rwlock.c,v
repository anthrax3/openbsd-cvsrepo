head	1.10;
access;
symbols
	OPENBSD_6_2:1.10.0.2
	OPENBSD_6_2_BASE:1.10
	OPENBSD_6_1:1.8.0.4
	OPENBSD_6_1_BASE:1.8
	OPENBSD_6_0:1.6.0.2
	OPENBSD_6_0_BASE:1.6
	OPENBSD_5_9:1.5.0.2
	OPENBSD_5_9_BASE:1.5
	OPENBSD_5_8:1.4.0.12
	OPENBSD_5_8_BASE:1.4
	OPENBSD_5_7:1.4.0.4
	OPENBSD_5_7_BASE:1.4
	OPENBSD_5_6:1.4.0.8
	OPENBSD_5_6_BASE:1.4
	OPENBSD_5_5:1.4.0.6
	OPENBSD_5_5_BASE:1.4
	OPENBSD_5_4:1.4.0.2
	OPENBSD_5_4_BASE:1.4
	OPENBSD_5_3:1.2.0.6
	OPENBSD_5_3_BASE:1.2
	OPENBSD_5_2:1.2.0.4
	OPENBSD_5_2_BASE:1.2
	OPENBSD_5_1_BASE:1.2
	OPENBSD_5_1:1.2.0.2;
locks; strict;
comment	@ * @;


1.10
date	2017.07.29.16.42.10;	author deraadt;	state Exp;
branches;
next	1.9;
commitid	ICfLVHfCLvzGEvCp;

1.9
date	2017.07.29.08.36.23;	author pirofti;	state Exp;
branches;
next	1.8;
commitid	LxkQgPLmJBjgc3Mx;

1.8
date	2016.09.04.10.13.35;	author akfaew;	state Exp;
branches;
next	1.7;
commitid	tPNEomz2X1xlRc3u;

1.7
date	2016.09.03.16.44.20;	author akfaew;	state Exp;
branches;
next	1.6;
commitid	A8DISbEBB3jwsSL3;

1.6
date	2016.04.02.19.56.53;	author guenther;	state Exp;
branches;
next	1.5;
commitid	8mfZyQLsoIGIAaFG;

1.5
date	2015.11.01.03.52.17;	author guenther;	state Exp;
branches;
next	1.4;
commitid	foeEYDHCuczbDswZ;

1.4
date	2013.06.01.23.06.26;	author tedu;	state Exp;
branches;
next	1.3;

1.3
date	2013.06.01.20.47.40;	author tedu;	state Exp;
branches;
next	1.2;

1.2
date	2012.01.17.02.34.18;	author guenther;	state Exp;
branches;
next	1.1;

1.1
date	2011.12.21.23.59.03;	author guenther;	state Exp;
branches;
next	;


desc
@@


1.10
log
@not all the world is an i386.  Back out breakage.
@
text
@/*	$OpenBSD: rthread_rwlock.c,v 1.8 2016/09/04 10:13:35 akfaew Exp $ */
/*
 * Copyright (c) 2004,2005 Ted Unangst <tedu@@openbsd.org>
 * Copyright (c) 2012 Philip Guenther <guenther@@openbsd.org>
 * All Rights Reserved.
 *
 * Permission to use, copy, modify, and distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 */
/*
 * rwlocks
 */

#include <assert.h>
#include <stdlib.h>
#include <unistd.h>
#include <errno.h>

#include <pthread.h>

#include "rthread.h"

static _atomic_lock_t rwlock_init_lock = _SPINLOCK_UNLOCKED;

int
pthread_rwlock_init(pthread_rwlock_t *lockp,
    const pthread_rwlockattr_t *attrp __unused)
{
	pthread_rwlock_t lock;

	lock = calloc(1, sizeof(*lock));
	if (!lock)
		return (errno);
	lock->lock = _SPINLOCK_UNLOCKED;
	TAILQ_INIT(&lock->writers);

	*lockp = lock;

	return (0);
}
DEF_STD(pthread_rwlock_init);

int
pthread_rwlock_destroy(pthread_rwlock_t *lockp)
{
	pthread_rwlock_t lock;

	assert(lockp);
	lock = *lockp;
	if (lock) {
		if (lock->readers || !TAILQ_EMPTY(&lock->writers)) {
#define MSG "pthread_rwlock_destroy on rwlock with waiters!\n"
			write(2, MSG, sizeof(MSG) - 1);
#undef MSG
			return (EBUSY);
		}
		free(lock);
	}
	*lockp = NULL;

	return (0);
}

static int
_rthread_rwlock_ensure_init(pthread_rwlock_t *lockp)
{
	int ret = 0;

	/*
	 * If the rwlock is statically initialized, perform the dynamic
	 * initialization.
	 */
	if (*lockp == NULL)
	{
		_spinlock(&rwlock_init_lock);
		if (*lockp == NULL)
			ret = pthread_rwlock_init(lockp, NULL);
		_spinunlock(&rwlock_init_lock);
	}
	return (ret);
}


static int
_rthread_rwlock_rdlock(pthread_rwlock_t *lockp, const struct timespec *abstime,
    int try)
{
	pthread_rwlock_t lock;
	pthread_t thread = pthread_self();
	int error;

	if ((error = _rthread_rwlock_ensure_init(lockp)))
		return (error);

	lock = *lockp;
	_rthread_debug(5, "%p: rwlock_rdlock %p\n", (void *)thread,
	    (void *)lock);
	_spinlock(&lock->lock);

	/* writers have precedence */
	if (lock->owner == NULL && TAILQ_EMPTY(&lock->writers))
		lock->readers++;
	else if (try)
		error = EBUSY;
	else if (lock->owner == thread)
		error = EDEADLK;
	else {
		do {
			if (__thrsleep(lock, CLOCK_REALTIME, abstime,
			    &lock->lock, NULL) == EWOULDBLOCK)
				return (ETIMEDOUT);
			_spinlock(&lock->lock);
		} while (lock->owner != NULL || !TAILQ_EMPTY(&lock->writers));
		lock->readers++;
	}
	_spinunlock(&lock->lock);

	return (error);
}

int
pthread_rwlock_rdlock(pthread_rwlock_t *lockp)
{
	return (_rthread_rwlock_rdlock(lockp, NULL, 0));
}

int
pthread_rwlock_tryrdlock(pthread_rwlock_t *lockp)
{
	return (_rthread_rwlock_rdlock(lockp, NULL, 1));
}

int
pthread_rwlock_timedrdlock(pthread_rwlock_t *lockp,
    const struct timespec *abstime)
{
	if (abstime == NULL || abstime->tv_sec < 0 || abstime->tv_nsec < 0 ||
	    abstime->tv_nsec > 1000000000)
		return (EINVAL);
	return (_rthread_rwlock_rdlock(lockp, abstime, 0));
}


static int
_rthread_rwlock_wrlock(pthread_rwlock_t *lockp, const struct timespec *abstime,
    int try)
{
	pthread_rwlock_t lock;
	pthread_t thread = pthread_self();
	int error;

	if ((error = _rthread_rwlock_ensure_init(lockp)))
		return (error);

	lock = *lockp;

	_rthread_debug(5, "%p: rwlock_timedwrlock %p\n", (void *)thread,
	    (void *)lock);
	_spinlock(&lock->lock);
	if (lock->readers == 0 && lock->owner == NULL)
		lock->owner = thread;
	else if (try)
		error = EBUSY;
	else if (lock->owner == thread)
		error = EDEADLK;
	else {
		int do_wait;

		/* gotta block */
		TAILQ_INSERT_TAIL(&lock->writers, thread, waiting);
		do {
			do_wait = __thrsleep(thread, CLOCK_REALTIME, abstime,
			    &lock->lock, NULL) != EWOULDBLOCK;
			_spinlock(&lock->lock);
		} while (lock->owner != thread && do_wait);

		if (lock->owner != thread) {
			/* timed out, sigh */
			TAILQ_REMOVE(&lock->writers, thread, waiting);
			error = ETIMEDOUT;
		}
	}
	_spinunlock(&lock->lock);

	return (error);
}

int
pthread_rwlock_wrlock(pthread_rwlock_t *lockp)
{
	return (_rthread_rwlock_wrlock(lockp, NULL, 0));
}

int
pthread_rwlock_trywrlock(pthread_rwlock_t *lockp)
{
	return (_rthread_rwlock_wrlock(lockp, NULL, 1));
}

int
pthread_rwlock_timedwrlock(pthread_rwlock_t *lockp,
    const struct timespec *abstime)
{
	if (abstime == NULL || abstime->tv_sec < 0 || abstime->tv_nsec < 0 ||
	    abstime->tv_nsec > 1000000000)
		return (EINVAL);
	return (_rthread_rwlock_wrlock(lockp, abstime, 0));
}


int
pthread_rwlock_unlock(pthread_rwlock_t *lockp)
{
	pthread_rwlock_t lock;
	pthread_t thread = pthread_self();
	pthread_t next;
	int was_writer;

	lock = *lockp;

	_rthread_debug(5, "%p: rwlock_unlock %p\n", (void *)thread,
	    (void *)lock);
	_spinlock(&lock->lock);
	if (lock->owner != NULL) {
		assert(lock->owner == thread);
		was_writer = 1;
	} else {
		assert(lock->readers > 0);
		lock->readers--;
		if (lock->readers > 0)
			goto out;
		was_writer = 0;
	}

	lock->owner = next = TAILQ_FIRST(&lock->writers);
	if (next != NULL) {
		/* dequeue and wake first writer */
		TAILQ_REMOVE(&lock->writers, next, waiting);
		_spinunlock(&lock->lock);
		__thrwakeup(next, 1);
		return (0);
	}

	/* could there have been blocked readers?  wake them all */
	if (was_writer)
		__thrwakeup(lock, 0);
out:
	_spinunlock(&lock->lock);

	return (0);
}
@


1.9
log
@Use memory barriers to prevent pointer use before initialization.

This work was sparked by the topic posted on hn by wuch. I am still not
sure that this fixes the defect he claims to have observed because I was
not able to create a proper regress test for it to manifest.

To that end, a proof of concept is more than welcomed!
Thank you for the report!

Discussed with and OK kettenis@@, tedu@@.
@
text
@a29 2
#include <sys/atomic.h>

a45 1
	membar_producer();
@


1.8
log
@Get rid of ticket support, replace "struct _spinlock" with "_atomic_lock_t".

ok tedu@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rthread_rwlock.c,v 1.7 2016/09/03 16:44:20 akfaew Exp $ */
d30 2
d48 1
@


1.7
log
@Remove _USING_TICKETS, it's defined as 0. No functional change.

ok tedu@@ mpi@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rthread_rwlock.c,v 1.6 2016/04/02 19:56:53 guenther Exp $ */
a22 1

d32 1
a32 2

static struct _spinlock rwlock_init_lock = _SPINLOCK_UNLOCKED;
d43 1
a43 1
	lock->lock = _SPINLOCK_UNLOCKED_ASSIGN;
d119 1
a119 1
			    &lock->lock.ticket, NULL) == EWOULDBLOCK)
d182 1
a182 1
			    &lock->lock.ticket, NULL) != EWOULDBLOCK;
@


1.6
log
@Wrap <pthread.h> and <pthread_np.h> to eliminate PLT entries for internal
references.  Use _thread_pagesize for the semaphore mmap size instead of
calling getpagesize() each time.

ok beck@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rthread_rwlock.c,v 1.5 2015/11/01 03:52:17 guenther Exp $ */
d120 2
a121 2
			if (__thrsleep(lock, CLOCK_REALTIME | _USING_TICKETS,
			    abstime, &lock->lock.ticket, NULL) == EWOULDBLOCK)
d183 1
a183 2
			do_wait = __thrsleep(thread, CLOCK_REALTIME |
			    _USING_TICKETS, abstime,
@


1.5
log
@delete old lint ARGSUSED comments
@
text
@d1 1
a1 1
/*	$OpenBSD: rthread_rwlock.c,v 1.4 2013/06/01 23:06:26 tedu Exp $ */
d52 1
@


1.4
log
@something's not quite right yet. ticket locks result in more CPU usage
and spinning in kernel. partially back out, but in a way that makes going
forward again easy.
seen by ajacoutot
@
text
@d1 1
a1 1
/*	$OpenBSD: rthread_rwlock.c,v 1.3 2013/06/01 20:47:40 tedu Exp $ */
a35 1
/* ARGSUSED1 */
@


1.3
log
@cleanup and consolidate the spinlock_lock (what a name!) code.
it's now atomic_lock to better reflect its usage, and librthread now
features a new spinlock that's really a ticket lock.
thrlseep can handle both types of lock via a flag in the clock arg.
(temp back compat hack)
remove some old stuff that's accumulated along the way and no longer used.
some feedback from dlg, who is concerned with all things ticket lock.
(you need to boot a new kernel before installing librthread)
@
text
@d1 1
a1 1
/*	$OpenBSD: rthread_rwlock.c,v 1.2 2012/01/17 02:34:18 guenther Exp $ */
d120 2
a121 2
			if (__thrsleep(lock, CLOCK_REALTIME | 0x8, abstime,
			    &lock->lock.ready, NULL) == EWOULDBLOCK)
d183 3
a185 2
			do_wait = __thrsleep(thread, CLOCK_REALTIME | 0x8, abstime,
			    &lock->lock.ready, NULL) != EWOULDBLOCK;
@


1.2
log
@Reimplement mutexes, condvars, and rwlocks to eliminate bugs,
particularly the "consume the signal you just sent" hang, and putting
the wait queues in userspace.

Do cancellation handling in pthread_cond_*wait(), pthread_join(),
and sem_wait().

Add __ prefix to thr{sleep,wakeup,exit,sigdivert}() syscalls; add
'abort" argument to thrsleep to close cancellation race; make
thr{sleep,wakeup} return errno values via *retval to avoid touching
userspace errno.
@
text
@d1 1
a1 1
/*	$OpenBSD: rthread_rwlock.c,v 1.1 2011/12/21 23:59:03 guenther Exp $ */
d34 1
a34 1
static _spinlock_lock_t rwlock_init_lock = _SPINLOCK_UNLOCKED;
d46 1
a46 1
	lock->lock = _SPINLOCK_UNLOCKED;
d120 2
a121 2
			if (__thrsleep(lock, CLOCK_REALTIME, abstime,
			    &lock->lock, NULL) == EWOULDBLOCK)
d183 2
a184 2
			do_wait = __thrsleep(thread, CLOCK_REALTIME, abstime,
			    &lock->lock, NULL) != EWOULDBLOCK;
@


1.1
log
@Split out the pthread_rwlock* and pthread_once() functions from rthread_sync.c
to new files rthread_rwlock.c, rthread_rwlockattr.c, and rthread_once.c
@
text
@d1 1
a1 1
/*	$OpenBSD: rthread_sync.c,v 1.26 2011/12/21 00:49:47 guenther Exp $ */
d4 1
d24 1
d36 1
d38 2
a39 1
pthread_rwlock_init(pthread_rwlock_t *lockp, const pthread_rwlockattr_t *attrp)
d47 2
a48 1
	lock->sem.lock = _SPINLOCK_UNLOCKED;
d57 6
a62 1
	if ((*lockp) && ((*lockp)->readers || (*lockp)->writer)) {
d64 1
a64 1
		write(2, MSG, sizeof(MSG) - 1);
d66 3
a68 1
		return (EBUSY);
a69 1
	free(*lockp);
d95 3
a97 2
int
pthread_rwlock_rdlock(pthread_rwlock_t *lockp)
d100 1
d107 2
a108 1
again:
d110 16
a125 5
	if (lock->writer) {
		_spinlock(&lock->sem.lock);
		_spinunlock(&lock->lock);
		_sem_waitl(&lock->sem, 0, 0, NULL);
		goto again;
a126 1
	lock->readers++;
d129 1
a129 1
	return (0);
d133 1
a133 2
pthread_rwlock_timedrdlock(pthread_rwlock_t *lockp,
    const struct timespec *abstime)
d135 1
a135 24
	pthread_rwlock_t lock;
	int do_wait = 1;
	int error;

	if ((error = _rthread_rwlock_ensure_init(lockp)))
		return (error);

	lock = *lockp;
	_spinlock(&lock->lock);
	while (lock->writer && do_wait) {
		_spinlock(&lock->sem.lock);
		_spinunlock(&lock->lock);
		do_wait = _sem_waitl(&lock->sem, 0, CLOCK_REALTIME, abstime);
		_spinlock(&lock->lock);
	}
	if (lock->writer) {
		/* do_wait must be 0, so timed out */
		_spinunlock(&lock->lock);
		return (ETIMEDOUT);
	}
	lock->readers++;
	_spinunlock(&lock->lock);

	return (0);
d141 2
a142 2
	pthread_rwlock_t lock;
	int error;
d144 9
a152 2
	if ((error = _rthread_rwlock_ensure_init(lockp)))
		return (error);
a153 1
	lock = *lockp;
d155 3
a157 13
	_spinlock(&lock->lock);
	if (lock->writer) {
		_spinunlock(&lock->lock);
		return (EBUSY);
	}
	lock->readers++;
	_spinunlock(&lock->lock);

	return (0);
}

int
pthread_rwlock_wrlock(pthread_rwlock_t *lockp)
d160 1
d168 2
d171 22
a192 6
	lock->writer++;
	while (lock->readers) {
		_spinlock(&lock->sem.lock);
		_spinunlock(&lock->lock);
		_sem_waitl(&lock->sem, 0, 0, NULL);
		_spinlock(&lock->lock);
a193 1
	lock->readers = -pthread_self()->tid;
d196 1
a196 1
	return (0);
d200 1
a200 2
pthread_rwlock_timedwrlock(pthread_rwlock_t *lockp,
    const struct timespec *abstime)
d202 1
a202 27
	pthread_rwlock_t lock;
	int do_wait = 1;
	int error;

	if ((error = _rthread_rwlock_ensure_init(lockp)))
		return (error);

	lock = *lockp;

	_spinlock(&lock->lock);
	lock->writer++;
	while (lock->readers && do_wait) {
		_spinlock(&lock->sem.lock);
		_spinunlock(&lock->lock);
		do_wait = _sem_waitl(&lock->sem, 0, CLOCK_REALTIME, abstime);
		_spinlock(&lock->lock);
	}
	if (lock->readers) {
		/* do_wait must be 0, so timed out */
		lock->writer--;
		_spinunlock(&lock->lock);
		return (ETIMEDOUT);
	}
	lock->readers = -pthread_self()->tid;
	_spinunlock(&lock->lock);

	return (0);
d208 2
a209 2
	pthread_rwlock_t lock;
	int error;
d211 9
a219 2
	if ((error = _rthread_rwlock_ensure_init(lockp)))
		return (error);
a220 13
	lock = *lockp;

	_spinlock(&lock->lock);
	if (lock->readers || lock->writer) {
		_spinunlock(&lock->lock);
		return (EBUSY);
	}
	lock->writer = 1;
	lock->readers = -pthread_self()->tid;
	_spinunlock(&lock->lock);

	return (0);
}
d226 3
d232 2
d235 5
a239 4
	if (lock->readers == -pthread_self()->tid) {
		lock->readers = 0;
		lock->writer--;
	} else if (lock->readers > 0) {
d241 9
a249 1
	} else {
d251 2
a252 1
		return (EPERM);
d254 5
a259 1
	_sem_wakeall(&lock->sem);
@

