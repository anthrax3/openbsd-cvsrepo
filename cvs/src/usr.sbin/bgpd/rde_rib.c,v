head	1.153;
access;
symbols
	OPENBSD_6_1_BASE:1.153
	OPENBSD_6_0:1.142.0.8
	OPENBSD_6_0_BASE:1.142
	OPENBSD_5_9:1.142.0.2
	OPENBSD_5_9_BASE:1.142
	OPENBSD_5_8:1.142.0.4
	OPENBSD_5_8_BASE:1.142
	OPENBSD_5_7:1.141.0.2
	OPENBSD_5_7_BASE:1.141
	OPENBSD_5_6:1.138.0.6
	OPENBSD_5_6_BASE:1.138
	OPENBSD_5_5:1.138.0.4
	OPENBSD_5_5_BASE:1.138
	OPENBSD_5_4:1.137.0.2
	OPENBSD_5_4_BASE:1.137
	OPENBSD_5_3:1.134.0.2
	OPENBSD_5_3_BASE:1.134
	OPENBSD_5_2:1.133.0.2
	OPENBSD_5_2_BASE:1.133
	OPENBSD_5_1_BASE:1.131
	OPENBSD_5_1:1.131.0.2
	OPENBSD_5_0:1.128.0.4
	OPENBSD_5_0_BASE:1.128
	OPENBSD_4_9:1.128.0.2
	OPENBSD_4_9_BASE:1.128
	OPENBSD_4_8:1.127.0.2
	OPENBSD_4_8_BASE:1.127
	OPENBSD_4_7:1.121.0.2
	OPENBSD_4_7_BASE:1.121
	OPENBSD_4_6:1.116.0.4
	OPENBSD_4_6_BASE:1.116
	OPENBSD_4_5:1.97.0.2
	OPENBSD_4_5_BASE:1.97
	OPENBSD_4_4:1.96.0.6
	OPENBSD_4_4_BASE:1.96
	OPENBSD_4_3:1.96.0.4
	OPENBSD_4_3_BASE:1.96
	OPENBSD_4_2:1.96.0.2
	OPENBSD_4_2_BASE:1.96
	OPENBSD_4_1:1.93.0.2
	OPENBSD_4_1_BASE:1.93
	OPENBSD_4_0:1.88.0.2
	OPENBSD_4_0_BASE:1.88
	OPENBSD_3_9:1.83.0.2
	OPENBSD_3_9_BASE:1.83
	OPENBSD_3_8:1.69.0.2
	OPENBSD_3_8_BASE:1.69
	OPENBSD_3_7:1.64.0.2
	OPENBSD_3_7_BASE:1.64
	OPENBSD_3_6:1.59.0.2
	OPENBSD_3_6_BASE:1.59
	OPENBSD_3_5:1.42.0.2
	OPENBSD_3_5_BASE:1.42;
locks; strict;
comment	@ * @;


1.153
date	2017.01.25.03.21.55;	author claudio;	state Exp;
branches;
next	1.152;
commitid	cao2hEetneZRFuIU;

1.152
date	2017.01.25.00.15.38;	author claudio;	state Exp;
branches;
next	1.151;
commitid	njwYsyFBZe4riTmC;

1.151
date	2017.01.24.23.38.12;	author claudio;	state Exp;
branches;
next	1.150;
commitid	o0u4P0zRnQoELo6o;

1.150
date	2017.01.24.04.22.42;	author benno;	state Exp;
branches;
next	1.149;
commitid	airB1W2Kb948lFil;

1.149
date	2017.01.23.22.53.52;	author claudio;	state Exp;
branches;
next	1.148;
commitid	GENNLgd0FzEuXHQN;

1.148
date	2017.01.23.22.47.59;	author claudio;	state Exp;
branches;
next	1.147;
commitid	pnGdVXq8GJLI0bC2;

1.147
date	2017.01.23.13.08.47;	author claudio;	state Exp;
branches;
next	1.146;
commitid	izU373N4GYVWJmcj;

1.146
date	2017.01.23.12.25.19;	author claudio;	state Exp;
branches;
next	1.145;
commitid	v3CPPZ2rgYxYsA45;

1.145
date	2017.01.23.11.46.02;	author claudio;	state Exp;
branches;
next	1.144;
commitid	K8zZdDB6ll7r7YIl;

1.144
date	2017.01.23.11.43.40;	author claudio;	state Exp;
branches;
next	1.143;
commitid	zHIgxV97QgdmH5L2;

1.143
date	2016.08.27.01.26.22;	author guenther;	state Exp;
branches;
next	1.142;
commitid	mLhDPn5m6RI81k8n;

1.142
date	2015.03.14.03.52.42;	author claudio;	state Exp;
branches;
next	1.141;
commitid	1OLz8RQEaC2xclFf;

1.141
date	2014.12.18.19.28.44;	author tedu;	state Exp;
branches;
next	1.140;
commitid	YDg6rOJSaQoATD9X;

1.140
date	2014.12.12.18.15.51;	author tedu;	state Exp;
branches;
next	1.139;
commitid	IULaxH7yDKF4X5ok;

1.139
date	2014.10.08.16.15.37;	author deraadt;	state Exp;
branches;
next	1.138;
commitid	8hXaK4f2GeAALziF;

1.138
date	2013.08.14.20.34.27;	author claudio;	state Exp;
branches;
next	1.137;

1.137
date	2013.07.17.14.09.13;	author benno;	state Exp;
branches;
next	1.136;

1.136
date	2013.05.20.11.26.13;	author claudio;	state Exp;
branches;
next	1.135;

1.135
date	2013.03.14.14.52.52;	author florian;	state Exp;
branches;
next	1.134;

1.134
date	2012.09.12.05.56.22;	author claudio;	state Exp;
branches;
next	1.133;

1.133
date	2012.07.01.11.55.13;	author sthen;	state Exp;
branches;
next	1.132;

1.132
date	2012.05.22.20.44.06;	author claudio;	state Exp;
branches;
next	1.131;

1.131
date	2011.09.21.08.59.01;	author claudio;	state Exp;
branches;
next	1.130;

1.130
date	2011.09.20.21.19.06;	author claudio;	state Exp;
branches;
next	1.129;

1.129
date	2011.09.17.16.29.44;	author claudio;	state Exp;
branches;
next	1.128;

1.128
date	2011.01.14.20.07.00;	author henning;	state Exp;
branches;
next	1.127;

1.127
date	2010.05.03.13.09.38;	author claudio;	state Exp;
branches;
next	1.126;

1.126
date	2010.04.20.09.02.12;	author claudio;	state Exp;
branches;
next	1.125;

1.125
date	2010.04.07.09.44.11;	author claudio;	state Exp;
branches;
next	1.124;

1.124
date	2010.04.06.13.25.08;	author claudio;	state Exp;
branches;
next	1.123;

1.123
date	2010.03.29.09.06.56;	author claudio;	state Exp;
branches;
next	1.122;

1.122
date	2010.03.26.15.38.39;	author claudio;	state Exp;
branches;
next	1.121;

1.121
date	2010.03.03.13.52.39;	author claudio;	state Exp;
branches;
next	1.120;

1.120
date	2010.01.13.06.02.37;	author claudio;	state Exp;
branches;
next	1.119;

1.119
date	2010.01.10.00.15.09;	author claudio;	state Exp;
branches;
next	1.118;

1.118
date	2009.12.01.14.28.05;	author claudio;	state Exp;
branches;
next	1.117;

1.117
date	2009.10.05.12.03.45;	author claudio;	state Exp;
branches;
next	1.116;

1.116
date	2009.06.29.14.13.48;	author claudio;	state Exp;
branches;
next	1.115;

1.115
date	2009.06.07.00.30.23;	author claudio;	state Exp;
branches;
next	1.114;

1.114
date	2009.06.04.21.53.43;	author claudio;	state Exp;
branches;
next	1.113;

1.113
date	2009.06.04.04.46.42;	author claudio;	state Exp;
branches;
next	1.112;

1.112
date	2009.06.03.20.22.04;	author claudio;	state Exp;
branches;
next	1.111;

1.111
date	2009.06.03.20.20.10;	author claudio;	state Exp;
branches;
next	1.110;

1.110
date	2009.06.03.20.17.59;	author claudio;	state Exp;
branches;
next	1.109;

1.109
date	2009.06.03.19.54.53;	author claudio;	state Exp;
branches;
next	1.108;

1.108
date	2009.06.02.00.09.02;	author claudio;	state Exp;
branches;
next	1.107;

1.107
date	2009.06.01.23.54.50;	author claudio;	state Exp;
branches;
next	1.106;

1.106
date	2009.06.01.22.54.02;	author claudio;	state Exp;
branches;
next	1.105;

1.105
date	2009.06.01.22.49.06;	author claudio;	state Exp;
branches;
next	1.104;

1.104
date	2009.06.01.21.20.17;	author claudio;	state Exp;
branches;
next	1.103;

1.103
date	2009.05.27.06.58.15;	author claudio;	state Exp;
branches;
next	1.102;

1.102
date	2009.05.21.15.47.03;	author claudio;	state Exp;
branches;
next	1.101;

1.101
date	2009.05.17.14.45.25;	author claudio;	state Exp;
branches;
next	1.100;

1.100
date	2009.05.17.13.20.12;	author claudio;	state Exp;
branches;
next	1.99;

1.99
date	2009.05.17.12.25.15;	author claudio;	state Exp;
branches;
next	1.98;

1.98
date	2009.04.23.19.23.27;	author claudio;	state Exp;
branches;
next	1.97;

1.97
date	2008.11.21.17.41.22;	author claudio;	state Exp;
branches;
next	1.96;

1.96
date	2007.06.01.04.17.30;	author claudio;	state Exp;
branches;
next	1.95;

1.95
date	2007.05.11.11.27.59;	author claudio;	state Exp;
branches;
next	1.94;

1.94
date	2007.04.02.12.51.06;	author claudio;	state Exp;
branches;
next	1.93;

1.93
date	2007.02.22.08.34.18;	author henning;	state Exp;
branches;
next	1.92;

1.92
date	2007.01.11.22.00.17;	author claudio;	state Exp;
branches;
next	1.91;

1.91
date	2006.12.12.10.34.22;	author claudio;	state Exp;
branches;
next	1.90;

1.90
date	2006.12.12.10.30.33;	author claudio;	state Exp;
branches;
next	1.89;

1.89
date	2006.12.12.10.26.47;	author claudio;	state Exp;
branches;
next	1.88;

1.88
date	2006.06.01.22.29.47;	author claudio;	state Exp;
branches;
next	1.87;

1.87
date	2006.05.28.23.24.15;	author claudio;	state Exp;
branches;
next	1.86;

1.86
date	2006.05.28.22.07.54;	author claudio;	state Exp;
branches;
next	1.85;

1.85
date	2006.04.04.12.03.26;	author henning;	state Exp;
branches;
next	1.84;

1.84
date	2006.03.15.15.37.40;	author claudio;	state Exp;
branches;
next	1.83;

1.83
date	2006.01.24.13.34.33;	author claudio;	state Exp;
branches;
next	1.82;

1.82
date	2006.01.24.13.00.35;	author claudio;	state Exp;
branches;
next	1.81;

1.81
date	2006.01.24.10.05.24;	author henning;	state Exp;
branches;
next	1.80;

1.80
date	2006.01.20.16.40.17;	author claudio;	state Exp;
branches;
next	1.79;

1.79
date	2006.01.20.16.06.12;	author claudio;	state Exp;
branches;
next	1.78;

1.78
date	2006.01.14.22.39.49;	author claudio;	state Exp;
branches;
next	1.77;

1.77
date	2006.01.12.14.05.13;	author claudio;	state Exp;
branches;
next	1.76;

1.76
date	2006.01.09.16.00.48;	author claudio;	state Exp;
branches;
next	1.75;

1.75
date	2006.01.05.17.33.40;	author claudio;	state Exp;
branches;
next	1.74;

1.74
date	2006.01.05.16.00.07;	author claudio;	state Exp;
branches;
next	1.73;

1.73
date	2006.01.04.16.13.07;	author claudio;	state Exp;
branches;
next	1.72;

1.72
date	2006.01.03.22.49.17;	author claudio;	state Exp;
branches;
next	1.71;

1.71
date	2005.12.30.14.07.40;	author claudio;	state Exp;
branches;
next	1.70;

1.70
date	2005.11.29.21.11.07;	author claudio;	state Exp;
branches;
next	1.69;

1.69
date	2005.07.29.12.38.40;	author claudio;	state Exp;
branches;
next	1.68;

1.68
date	2005.07.01.09.19.24;	author claudio;	state Exp;
branches;
next	1.67;

1.67
date	2005.06.29.09.43.26;	author claudio;	state Exp;
branches;
next	1.66;

1.66
date	2005.04.12.14.32.01;	author claudio;	state Exp;
branches;
next	1.65;

1.65
date	2005.03.26.12.46.52;	author claudio;	state Exp;
branches;
next	1.64;

1.64
date	2005.03.11.12.54.20;	author claudio;	state Exp;
branches;
next	1.63;

1.63
date	2004.11.23.13.07.01;	author claudio;	state Exp;
branches;
next	1.62;

1.62
date	2004.11.19.09.59.27;	author claudio;	state Exp;
branches;
next	1.61;

1.61
date	2004.11.10.16.12.11;	author claudio;	state Exp;
branches;
next	1.60;

1.60
date	2004.11.10.12.41.58;	author claudio;	state Exp;
branches;
next	1.59;

1.59
date	2004.08.17.15.39.36;	author claudio;	state Exp;
branches;
next	1.58;

1.58
date	2004.08.13.14.03.20;	author claudio;	state Exp;
branches;
next	1.57;

1.57
date	2004.08.12.10.24.16;	author claudio;	state Exp;
branches;
next	1.56;

1.56
date	2004.08.10.13.02.08;	author claudio;	state Exp;
branches;
next	1.55;

1.55
date	2004.08.06.12.04.08;	author claudio;	state Exp;
branches;
next	1.54;

1.54
date	2004.08.05.19.23.10;	author claudio;	state Exp;
branches;
next	1.53;

1.53
date	2004.08.05.18.44.19;	author claudio;	state Exp;
branches;
next	1.52;

1.52
date	2004.08.05.16.26.56;	author claudio;	state Exp;
branches;
next	1.51;

1.51
date	2004.08.05.15.58.21;	author claudio;	state Exp;
branches;
next	1.50;

1.50
date	2004.07.05.02.13.44;	author henning;	state Exp;
branches;
next	1.49;

1.49
date	2004.06.22.23.17.01;	author claudio;	state Exp;
branches;
next	1.48;

1.48
date	2004.06.22.20.28.58;	author claudio;	state Exp;
branches;
next	1.47;

1.47
date	2004.06.22.07.22.31;	author henning;	state Exp;
branches;
next	1.46;

1.46
date	2004.05.08.19.17.20;	author henning;	state Exp;
branches;
next	1.45;

1.45
date	2004.05.07.10.06.15;	author djm;	state Exp;
branches;
next	1.44;

1.44
date	2004.04.30.18.42.05;	author henning;	state Exp;
branches;
next	1.43;

1.43
date	2004.04.28.07.05.27;	author claudio;	state Exp;
branches;
next	1.42;

1.42
date	2004.03.11.14.22.23;	author claudio;	state Exp;
branches;
next	1.41;

1.41
date	2004.03.05.22.21.32;	author claudio;	state Exp;
branches;
next	1.40;

1.40
date	2004.03.01.16.02.01;	author claudio;	state Exp;
branches;
next	1.39;

1.39
date	2004.02.27.20.53.56;	author claudio;	state Exp;
branches;
next	1.38;

1.38
date	2004.02.27.14.46.09;	author claudio;	state Exp;
branches;
next	1.37;

1.37
date	2004.02.27.14.43.18;	author claudio;	state Exp;
branches;
next	1.36;

1.36
date	2004.02.26.16.16.41;	author claudio;	state Exp;
branches;
next	1.35;

1.35
date	2004.02.19.23.07.00;	author claudio;	state Exp;
branches;
next	1.34;

1.34
date	2004.02.19.13.54.58;	author claudio;	state Exp;
branches;
next	1.33;

1.33
date	2004.02.09.01.56.18;	author henning;	state Exp;
branches;
next	1.32;

1.32
date	2004.02.04.09.18.03;	author claudio;	state Exp;
branches;
next	1.31;

1.31
date	2004.02.02.19.14.11;	author deraadt;	state Exp;
branches;
next	1.30;

1.30
date	2004.02.02.18.56.25;	author claudio;	state Exp;
branches;
next	1.29;

1.29
date	2004.02.02.16.46.16;	author claudio;	state Exp;
branches;
next	1.28;

1.28
date	2004.01.27.21.56.21;	author henning;	state Exp;
branches;
next	1.27;

1.27
date	2004.01.22.20.34.56;	author henning;	state Exp;
branches;
next	1.26;

1.26
date	2004.01.18.00.44.44;	author deraadt;	state Exp;
branches;
next	1.25;

1.25
date	2004.01.17.19.35.36;	author claudio;	state Exp;
branches;
next	1.24;

1.24
date	2004.01.13.16.08.04;	author claudio;	state Exp;
branches;
next	1.23;

1.23
date	2004.01.13.13.45.50;	author claudio;	state Exp;
branches;
next	1.22;

1.22
date	2004.01.12.13.33.16;	author claudio;	state Exp;
branches;
next	1.21;

1.21
date	2004.01.11.22.08.04;	author henning;	state Exp;
branches;
next	1.20;

1.20
date	2004.01.11.21.59.45;	author henning;	state Exp;
branches;
next	1.19;

1.19
date	2004.01.11.21.47.20;	author claudio;	state Exp;
branches;
next	1.18;

1.18
date	2004.01.11.19.14.43;	author henning;	state Exp;
branches;
next	1.17;

1.17
date	2004.01.11.02.39.05;	author henning;	state Exp;
branches;
next	1.16;

1.16
date	2004.01.10.22.25.42;	author claudio;	state Exp;
branches;
next	1.15;

1.15
date	2004.01.10.16.20.29;	author claudio;	state Exp;
branches;
next	1.14;

1.14
date	2004.01.06.10.51.14;	author claudio;	state Exp;
branches;
next	1.13;

1.13
date	2003.12.30.13.03.27;	author henning;	state Exp;
branches;
next	1.12;

1.12
date	2003.12.26.22.41.01;	author henning;	state Exp;
branches;
next	1.11;

1.11
date	2003.12.26.21.51.57;	author henning;	state Exp;
branches;
next	1.10;

1.10
date	2003.12.26.21.30.20;	author henning;	state Exp;
branches;
next	1.9;

1.9
date	2003.12.26.18.07.33;	author henning;	state Exp;
branches;
next	1.8;

1.8
date	2003.12.25.23.41.23;	author claudio;	state Exp;
branches;
next	1.7;

1.7
date	2003.12.25.23.22.13;	author claudio;	state Exp;
branches;
next	1.6;

1.6
date	2003.12.24.11.39.43;	author henning;	state Exp;
branches;
next	1.5;

1.5
date	2003.12.22.06.42.19;	author deraadt;	state Exp;
branches;
next	1.4;

1.4
date	2003.12.21.16.11.34;	author claudio;	state Exp;
branches;
next	1.3;

1.3
date	2003.12.19.19.24.08;	author deraadt;	state Exp;
branches;
next	1.2;

1.2
date	2003.12.19.01.15.47;	author deraadt;	state Exp;
branches;
next	1.1;

1.1
date	2003.12.17.11.46.54;	author henning;	state Exp;
branches;
next	;


desc
@@


1.153
log
@Hopefully the last of the struct rib rototilling. Peer just points to a
struct rib and not rib_desc since the full descriptor is almost never needed.
This should now allow the update code to be changed.
@
text
@/*	$OpenBSD: rde_rib.c,v 1.152 2017/01/25 00:15:38 claudio Exp $ */

/*
 * Copyright (c) 2003, 2004 Claudio Jeker <claudio@@openbsd.org>
 *
 * Permission to use, copy, modify, and distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 */

#include <sys/types.h>
#include <sys/queue.h>

#include <stdlib.h>
#include <string.h>
#include <siphash.h>
#include <time.h>

#include "bgpd.h"
#include "rde.h"
#include "log.h"

/*
 * BGP RIB -- Routing Information Base
 *
 * The RIB is build with one aspect in mind. Speed -- actually update speed.
 * Therefore one thing needs to be absolutely avoided, long table walks.
 * This is achieved by heavily linking the different parts together.
 */
u_int16_t rib_size;
struct rib_desc *ribs;

LIST_HEAD(, rib_context) rib_dump_h = LIST_HEAD_INITIALIZER(rib_dump_h);

struct rib_entry *rib_add(struct rib *, struct bgpd_addr *, int);
int rib_compare(const struct rib_entry *, const struct rib_entry *);
void rib_remove(struct rib_entry *);
int rib_empty(struct rib_entry *);
struct rib_entry *rib_restart(struct rib_context *);

RB_PROTOTYPE(rib_tree, rib_entry, rib_e, rib_compare);
RB_GENERATE(rib_tree, rib_entry, rib_e, rib_compare);

static inline void
re_lock(struct rib_entry *re)
{
	re->__rib = (struct rib *)((intptr_t)re->__rib | 1);
}

static inline void
re_unlock(struct rib_entry *re)
{
	re->__rib = (struct rib *)((intptr_t)re->__rib & ~1);
}

static inline int
re_is_locked(struct rib_entry *re)
{
	return ((intptr_t)re->__rib & 1);
}

static inline struct rib_tree *
rib_tree(struct rib *rib)
{
	return (&rib->tree);
}

/* RIB specific functions */
struct rib *
rib_new(char *name, u_int rtableid, u_int16_t flags)
{
	struct rib_desc	*xribs;
	u_int16_t	id;

	for (id = 0; id < rib_size; id++) {
		if (*ribs[id].name == '\0')
			break;
	}

	if (id >= rib_size) {
		if ((xribs = reallocarray(ribs, id + 1,
		    sizeof(struct rib_desc))) == NULL) {
			/* XXX this is not clever */
			fatal("rib_add");
		}
		ribs = xribs;
		rib_size = id + 1;
	}

	bzero(&ribs[id], sizeof(struct rib_desc));
	strlcpy(ribs[id].name, name, sizeof(ribs[id].name));
	RB_INIT(rib_tree(&ribs[id].rib));
	ribs[id].state = RECONF_REINIT;
	ribs[id].rib.id = id;
	ribs[id].rib.flags = flags;
	ribs[id].rib.rtableid = rtableid;

	ribs[id].in_rules = calloc(1, sizeof(struct filter_head));
	if (ribs[id].in_rules == NULL)
		fatal(NULL);
	TAILQ_INIT(ribs[id].in_rules);

	return (&ribs[id].rib);
}

struct rib *
rib_find(char *name)
{
	u_int16_t id;

	if (name == NULL || *name == '\0')
		return (&ribs[1].rib);	/* no name returns the Loc-RIB */

	for (id = 0; id < rib_size; id++) {
		if (!strcmp(ribs[id].name, name))
			return (&ribs[id].rib);
	}

	return (NULL);
}

struct rib_desc *
rib_desc(struct rib *rib)
{
	return (&ribs[rib->id]);
}

void
rib_free(struct rib *rib)
{
	struct rib_context *ctx, *next;
	struct rib_desc *rd;
	struct rib_entry *re, *xre;
	struct prefix *p, *np;

	/* abort pending rib_dumps */
	for (ctx = LIST_FIRST(&rib_dump_h); ctx != NULL; ctx = next) {
		next = LIST_NEXT(ctx, entry);
		if (ctx->ctx_rib == rib) {
			re = ctx->ctx_re;
			re_unlock(re);
			LIST_REMOVE(ctx, entry);
			if (ctx->ctx_done)
				ctx->ctx_done(ctx->ctx_arg);
			else
				free(ctx);
		}
	}

	for (re = RB_MIN(rib_tree, rib_tree(rib)); re != NULL; re = xre) {
		xre = RB_NEXT(rib_tree, rib_tree(rib), re);

		/*
		 * Removing the prefixes is tricky because the last one
		 * will remove the rib_entry as well and because we do
		 * an empty check in prefix_destroy() it is not possible to
		 * use the default for loop.
		 */
		while ((p = LIST_FIRST(&re->prefix_h))) {
			np = LIST_NEXT(p, rib_l);
			if (p->aspath->pftableid) {
				struct bgpd_addr addr;

				pt_getaddr(p->prefix, &addr);
				/* Commit is done in peer_down() */
				rde_send_pftable(p->aspath->pftableid, &addr,
				    p->prefix->prefixlen, 1);
			}
			prefix_destroy(p);
			if (np == NULL)
				break;
		}
	}
	rd = &ribs[rib->id];
	filterlist_free(rd->in_rules_tmp);
	filterlist_free(rd->in_rules);
	bzero(rib, sizeof(struct rib_desc));
}

int
rib_compare(const struct rib_entry *a, const struct rib_entry *b)
{
	return (pt_prefix_cmp(a->prefix, b->prefix));
}

struct rib_entry *
rib_get(struct rib *rib, struct bgpd_addr *prefix, int prefixlen)
{
	struct rib_entry xre;
	struct pt_entry	*pte;

	pte = pt_fill(prefix, prefixlen);
	bzero(&xre, sizeof(xre));
	xre.prefix = pte;

	return (RB_FIND(rib_tree, rib_tree(rib), &xre));
}

struct rib_entry *
rib_lookup(struct rib *rib, struct bgpd_addr *addr)
{
	struct rib_entry *re;
	int		 i;

	switch (addr->aid) {
	case AID_INET:
	case AID_VPN_IPv4:
		for (i = 32; i >= 0; i--) {
			re = rib_get(rib, addr, i);
			if (re != NULL)
				return (re);
		}
		break;
	case AID_INET6:
		for (i = 128; i >= 0; i--) {
			re = rib_get(rib, addr, i);
			if (re != NULL)
				return (re);
		}
		break;
	default:
		fatalx("rib_lookup: unknown af");
	}
	return (NULL);
}


struct rib_entry *
rib_add(struct rib *rib, struct bgpd_addr *prefix, int prefixlen)
{
	struct pt_entry	*pte;
	struct rib_entry *re;

	pte = pt_get(prefix, prefixlen);
	if (pte == NULL)
		pte = pt_add(prefix, prefixlen);

	if ((re = calloc(1, sizeof(*re))) == NULL)
		fatal("rib_add");

	LIST_INIT(&re->prefix_h);
	re->prefix = pte;
	re->__rib = rib;

        if (RB_INSERT(rib_tree, rib_tree(rib), re) != NULL) {
		log_warnx("rib_add: insert failed");
		free(re);
		return (NULL);
	}

	pt_ref(pte);

	rdemem.rib_cnt++;

	return (re);
}

void
rib_remove(struct rib_entry *re)
{
	if (!rib_empty(re))
		fatalx("rib_remove: entry not empty");

	if (re_is_locked(re))
		/* entry is locked, don't free it. */
		return;

	pt_unref(re->prefix);
	if (pt_empty(re->prefix))
		pt_remove(re->prefix);

	if (RB_REMOVE(rib_tree, rib_tree(re_rib(re)), re) == NULL)
		log_warnx("rib_remove: remove failed.");

	free(re);
	rdemem.rib_cnt--;
}

int
rib_empty(struct rib_entry *re)
{
	return LIST_EMPTY(&re->prefix_h);
}

void
rib_dump(struct rib *rib, void (*upcall)(struct rib_entry *, void *),
    void *arg, u_int8_t aid)
{
	struct rib_context	*ctx;

	if ((ctx = calloc(1, sizeof(*ctx))) == NULL)
		fatal("rib_dump");
	ctx->ctx_rib = rib;
	ctx->ctx_upcall = upcall;
	ctx->ctx_arg = arg;
	ctx->ctx_aid = aid;
	rib_dump_r(ctx);
}

void
rib_dump_r(struct rib_context *ctx)
{
	struct rib_entry	*re;
	unsigned int		 i;

	if (ctx->ctx_re == NULL) {
		re = RB_MIN(rib_tree, rib_tree(ctx->ctx_rib));
		LIST_INSERT_HEAD(&rib_dump_h, ctx, entry);
	} else
		re = rib_restart(ctx);

	for (i = 0; re != NULL; re = RB_NEXT(rib_tree, unused, re)) {
		if (ctx->ctx_aid != AID_UNSPEC &&
		    ctx->ctx_aid != re->prefix->aid)
			continue;
		if (ctx->ctx_count && i++ >= ctx->ctx_count &&
		    re_is_locked(re)) {
			/* store and lock last element */
			ctx->ctx_re = re;
			re_lock(re);
			return;
		}
		ctx->ctx_upcall(re, ctx->ctx_arg);
	}

	LIST_REMOVE(ctx, entry);
	if (ctx->ctx_done)
		ctx->ctx_done(ctx->ctx_arg);
	else
		free(ctx);
}

struct rib_entry *
rib_restart(struct rib_context *ctx)
{
	struct rib_entry *re;

	re = ctx->ctx_re;
	re_unlock(re);

	/* find first non empty element */
	while (re && rib_empty(re))
		re = RB_NEXT(rib_tree, unused, re);

	/* free the previously locked rib element if empty */
	if (rib_empty(ctx->ctx_re))
		rib_remove(ctx->ctx_re);
	ctx->ctx_re = NULL;
	return (re);
}

void
rib_dump_runner(void)
{
	struct rib_context	*ctx, *next;

	for (ctx = LIST_FIRST(&rib_dump_h); ctx != NULL; ctx = next) {
		next = LIST_NEXT(ctx, entry);
		rib_dump_r(ctx);
	}
}

int
rib_dump_pending(void)
{
	return (!LIST_EMPTY(&rib_dump_h));
}

/* used to bump correct prefix counters */
#define PREFIX_COUNT(x, op)			\
	do {					\
		(x)->prefix_cnt += (op);	\
	} while (0)

/* path specific functions */

static void	path_link(struct rde_aspath *, struct rde_peer *);

struct path_table pathtable;

SIPHASH_KEY pathtablekey;

/* XXX the hash should also include communities and the other attrs */
#define PATH_HASH(x)				\
	&pathtable.path_hashtbl[SipHash24(&pathtablekey, (x)->data, (x)->len) & \
	    pathtable.path_hashmask]

void
path_init(u_int32_t hashsize)
{
	u_int32_t	hs, i;

	for (hs = 1; hs < hashsize; hs <<= 1)
		;
	pathtable.path_hashtbl = calloc(hs, sizeof(struct aspath_head));
	if (pathtable.path_hashtbl == NULL)
		fatal("path_init");

	for (i = 0; i < hs; i++)
		LIST_INIT(&pathtable.path_hashtbl[i]);

	pathtable.path_hashmask = hs - 1;
	arc4random_buf(&pathtablekey, sizeof(pathtablekey));
}

void
path_shutdown(void)
{
	u_int32_t	i;

	for (i = 0; i <= pathtable.path_hashmask; i++)
		if (!LIST_EMPTY(&pathtable.path_hashtbl[i]))
			log_warnx("path_free: free non-free table");

	free(pathtable.path_hashtbl);
}

int
path_update(struct rib *rib, struct rde_peer *peer, struct rde_aspath *nasp,
    struct bgpd_addr *prefix, int prefixlen)
{
	struct rde_aspath	*asp;
	struct prefix		*p;

	if (nasp->pftableid) {
		rde_send_pftable(nasp->pftableid, prefix, prefixlen, 0);
		rde_send_pftable_commit();
	}

	/*
	 * First try to find a prefix in the specified RIB.
	 */
	if ((p = prefix_get(rib, peer, prefix, prefixlen, 0)) != NULL) {
		if (path_compare(nasp, p->aspath) == 0) {
			/* no change, update last change */
			p->lastchange = time(NULL);
			return (0);
		}
	}

	/*
	 * Either the prefix does not exist or the path changed.
	 * In both cases lookup the new aspath to make sure it is not
	 * already in the RIB.
	 */
	if ((asp = path_lookup(nasp, peer)) == NULL) {
		/* Path not available, create and link a new one. */
		asp = path_copy(nasp);
		path_link(asp, peer);
	}

	/* If the prefix was found move it else add it to the aspath. */
	if (p != NULL)
		prefix_move(asp, p);
	else
		return (prefix_add(rib, asp, prefix, prefixlen));
	return (0);
}

int
path_compare(struct rde_aspath *a, struct rde_aspath *b)
{
	int		 r;

	if (a->origin > b->origin)
		return (1);
	if (a->origin < b->origin)
		return (-1);
	if ((a->flags & ~F_ATTR_LINKED) > (b->flags & ~F_ATTR_LINKED))
		return (1);
	if ((a->flags & ~F_ATTR_LINKED) < (b->flags & ~F_ATTR_LINKED))
		return (-1);
	if (a->med > b->med)
		return (1);
	if (a->med < b->med)
		return (-1);
	if (a->lpref > b->lpref)
		return (1);
	if (a->lpref < b->lpref)
		return (-1);
	if (a->weight > b->weight)
		return (1);
	if (a->weight < b->weight)
		return (-1);
	if (a->rtlabelid > b->rtlabelid)
		return (1);
	if (a->rtlabelid < b->rtlabelid)
		return (-1);
	if (a->pftableid > b->pftableid)
		return (1);
	if (a->pftableid < b->pftableid)
		return (-1);

	r = aspath_compare(a->aspath, b->aspath);
	if (r == 0)
		r = nexthop_compare(a->nexthop, b->nexthop);
	if (r > 0)
		return (1);
	if (r < 0)
		return (-1);

	return (attr_compare(a, b));
}

struct rde_aspath *
path_lookup(struct rde_aspath *aspath, struct rde_peer *peer)
{
	struct aspath_head	*head;
	struct rde_aspath	*asp;

	head = PATH_HASH(aspath->aspath);

	LIST_FOREACH(asp, head, path_l) {
		if (peer == asp->peer && path_compare(aspath, asp) == 0)
			return (asp);
	}
	return (NULL);
}

void
path_remove(struct rde_aspath *asp)
{
	struct prefix	*p, *np;

	for (p = LIST_FIRST(&asp->prefix_h); p != NULL; p = np) {
		np = LIST_NEXT(p, path_l);
		if (asp->pftableid) {
			struct bgpd_addr addr;

			pt_getaddr(p->prefix, &addr);
			/* Commit is done in peer_down() */
			rde_send_pftable(p->aspath->pftableid, &addr,
			    p->prefix->prefixlen, 1);
		}
		prefix_destroy(p);
	}
}

/* remove all stale routes or if staletime is 0 remove all routes for
   a specified AID. */
u_int32_t
path_remove_stale(struct rde_aspath *asp, u_int8_t aid)
{
	struct prefix	*p, *np;
	time_t		 staletime;
	u_int32_t	 rprefixes;

	rprefixes=0;
	staletime = asp->peer->staletime[aid];
	for (p = LIST_FIRST(&asp->prefix_h); p != NULL; p = np) {
		np = LIST_NEXT(p, path_l);
		if (p->prefix->aid != aid)
			continue;

		if (staletime && p->lastchange > staletime)
			continue;

		if (asp->pftableid) {
			struct bgpd_addr addr;

			pt_getaddr(p->prefix, &addr);
			/* Commit is done in peer_flush() */
			rde_send_pftable(p->aspath->pftableid, &addr,
			    p->prefix->prefixlen, 1);
		}

		/* only count Adj-RIB-In */
		if (re_rib(p->re) == &ribs[0].rib)
			rprefixes++;

		prefix_destroy(p);
	}
	return (rprefixes);
}


/* this function is only called by prefix_remove and path_remove */
void
path_destroy(struct rde_aspath *asp)
{
	/* path_destroy can only unlink and free empty rde_aspath */
	if (asp->prefix_cnt != 0 || asp->active_cnt != 0)
		log_warnx("path_destroy: prefix count out of sync");

	nexthop_unlink(asp);
	LIST_REMOVE(asp, path_l);
	LIST_REMOVE(asp, peer_l);
	asp->peer = NULL;
	asp->nexthop = NULL;
	asp->flags &= ~F_ATTR_LINKED;

	path_put(asp);
}

int
path_empty(struct rde_aspath *asp)
{
	return LIST_EMPTY(&asp->prefix_h);
}

/*
 * the path object is linked into multiple lists for fast access.
 * These are peer_l, path_l and nexthop_l.
 * peer_l: list of all aspaths that belong to that peer
 * path_l: hash list to find paths quickly
 * nexthop_l: list of all aspaths with an equal exit nexthop
 */
static void
path_link(struct rde_aspath *asp, struct rde_peer *peer)
{
	struct aspath_head	*head;

	head = PATH_HASH(asp->aspath);

	LIST_INSERT_HEAD(head, asp, path_l);
	LIST_INSERT_HEAD(&peer->path_h, asp, peer_l);
	asp->peer = peer;
	nexthop_link(asp);
	asp->flags |= F_ATTR_LINKED;
}

/*
 * copy asp to a new UNLINKED one mainly for filtering
 */
struct rde_aspath *
path_copy(struct rde_aspath *asp)
{
	struct rde_aspath *nasp;

	nasp = path_get();
	nasp->aspath = asp->aspath;
	if (nasp->aspath != NULL) {
		nasp->aspath->refcnt++;
		rdemem.aspath_refs++;
	}
	nasp->nexthop = asp->nexthop;
	nasp->med = asp->med;
	nasp->lpref = asp->lpref;
	nasp->weight = asp->weight;
	nasp->origin = asp->origin;
	nasp->rtlabelid = asp->rtlabelid;
	rtlabel_ref(nasp->rtlabelid);
	nasp->pftableid = asp->pftableid;
	pftable_ref(nasp->pftableid);

	nasp->flags = asp->flags & ~F_ATTR_LINKED;
	attr_copy(nasp, asp);

	return (nasp);
}

/* alloc and initialize new entry. May not fail. */
struct rde_aspath *
path_get(void)
{
	struct rde_aspath *asp;

	asp = calloc(1, sizeof(*asp));
	if (asp == NULL)
		fatal("path_alloc");
	rdemem.path_cnt++;

	LIST_INIT(&asp->prefix_h);
	asp->origin = ORIGIN_INCOMPLETE;
	asp->lpref = DEFAULT_LPREF;
	/* med = 0 */
	/* weight = 0 */
	/* rtlabel = 0 */

	return (asp);
}

/* free an unlinked element */
void
path_put(struct rde_aspath *asp)
{
	if (asp == NULL)
		return;

	if (asp->flags & F_ATTR_LINKED)
		fatalx("path_put: linked object");

	rtlabel_unref(asp->rtlabelid);
	pftable_unref(asp->pftableid);
	aspath_put(asp->aspath);
	attr_freeall(asp);
	rdemem.path_cnt--;
	free(asp);
}

/* prefix specific functions */

static struct prefix	*prefix_alloc(void);
static void		 prefix_free(struct prefix *);
static void		 prefix_link(struct prefix *, struct rib_entry *,
			     struct rde_aspath *);
static void		 prefix_unlink(struct prefix *);

/*
 * search for specified prefix of a peer. Returns NULL if not found.
 */
struct prefix *
prefix_get(struct rib *rib, struct rde_peer *peer, struct bgpd_addr *prefix,
    int prefixlen, u_int32_t flags)
{
	struct rib_entry	*re;

	re = rib_get(rib, prefix, prefixlen);
	if (re == NULL)
		return (NULL);
	return (prefix_bypeer(re, peer, flags));
}

/*
 * Adds or updates a prefix.
 */
int
prefix_add(struct rib *rib, struct rde_aspath *asp, struct bgpd_addr *prefix,
    int prefixlen)

{
	struct prefix		*p;
	struct rib_entry	*re;

	re = rib_get(rib, prefix, prefixlen);
	if (re == NULL)
		re = rib_add(rib, prefix, prefixlen);

	p = prefix_bypeer(re, asp->peer, asp->flags);
	if (p == NULL) {
		p = prefix_alloc();
		prefix_link(p, re, asp);
		return (1);
	} else {
		if (p->aspath != asp) {
			/* prefix belongs to a different aspath so move */
			prefix_move(asp, p);
		} else
			p->lastchange = time(NULL);
		return (0);
	}
}

/*
 * Move the prefix to the specified as path, removes the old asp if needed.
 */
void
prefix_move(struct rde_aspath *asp, struct prefix *p)
{
	struct prefix		*np;
	struct rde_aspath	*oasp;

	if (asp->peer != p->aspath->peer)
		fatalx("prefix_move: cross peer move");

	/* create new prefix node */
	np = prefix_alloc();
	np->aspath = asp;
	/* peer and prefix pointers are still equal */
	np->prefix = p->prefix;
	np->re = p->re;
	np->lastchange = time(NULL);

	/* add to new as path */
	LIST_INSERT_HEAD(&asp->prefix_h, np, path_l);
	PREFIX_COUNT(asp, 1);
	/*
	 * no need to update the peer prefix count because we are only moving
	 * the prefix without changing the peer.
	 */

	/*
	 * First kick the old prefix node out of the prefix list,
	 * afterwards run the route decision for new prefix node.
	 * Because of this only one update is generated if the prefix
	 * was active.
	 * This is save because we create a new prefix and so the change
	 * is noticed by prefix_evaluate().
	 */
	LIST_REMOVE(p, rib_l);
	prefix_evaluate(np, np->re);

	/* remove old prefix node */
	oasp = p->aspath;
	LIST_REMOVE(p, path_l);
	PREFIX_COUNT(oasp, -1);
	/* as before peer count needs no update because of move */

	/* destroy all references to other objects and free the old prefix */
	p->aspath = NULL;
	p->prefix = NULL;
	p->re = NULL;
	prefix_free(p);

	/* destroy old path if empty */
	if (path_empty(oasp))
		path_destroy(oasp);
}

/*
 * Removes a prefix from all lists. If the parent objects -- path or
 * pt_entry -- become empty remove them too.
 */
int
prefix_remove(struct rib *rib, struct rde_peer *peer, struct bgpd_addr *prefix,
    int prefixlen, u_int32_t flags)
{
	struct prefix		*p;
	struct rib_entry	*re;
	struct rde_aspath	*asp;

	re = rib_get(rib, prefix, prefixlen);
	if (re == NULL)	/* Got a dummy withdrawn request */
		return (0);

	p = prefix_bypeer(re, peer, flags);
	if (p == NULL)		/* Got a dummy withdrawn request. */
		return (0);

	asp = p->aspath;

	if (asp->pftableid) {
		/* only prefixes in the local RIB were pushed into pf */
		rde_send_pftable(asp->pftableid, prefix, prefixlen, 1);
		rde_send_pftable_commit();
	}

	prefix_destroy(p);

	return (1);
}

/* dump a prefix into specified buffer */
int
prefix_write(u_char *buf, int len, struct bgpd_addr *prefix, u_int8_t plen)
{
	int	totlen;

	switch (prefix->aid) {
	case AID_INET:
	case AID_INET6:
		totlen = PREFIX_SIZE(plen);

		if (totlen > len)
			return (-1);
		*buf++ = plen;
		memcpy(buf, &prefix->ba, totlen - 1);
		return (totlen);
	case AID_VPN_IPv4:
		totlen = PREFIX_SIZE(plen) + sizeof(prefix->vpn4.rd) +
		    prefix->vpn4.labellen;
		plen += (sizeof(prefix->vpn4.rd) + prefix->vpn4.labellen) * 8;

		if (totlen > len)
			return (-1);
		*buf++ = plen;
		memcpy(buf, &prefix->vpn4.labelstack, prefix->vpn4.labellen);
		buf += prefix->vpn4.labellen;
		memcpy(buf, &prefix->vpn4.rd, sizeof(prefix->vpn4.rd));
		buf += sizeof(prefix->vpn4.rd);
		memcpy(buf, &prefix->vpn4.addr, PREFIX_SIZE(plen) - 1);
		return (totlen);
	default:
		return (-1);
	}
}

int
prefix_writebuf(struct ibuf *buf, struct bgpd_addr *prefix, u_int8_t plen)
{
	int	 totlen;
	void	*bptr;

	switch (prefix->aid) {
	case AID_INET:
	case AID_INET6:
		totlen = PREFIX_SIZE(plen);
		break;
	case AID_VPN_IPv4:
		totlen = PREFIX_SIZE(plen) + sizeof(prefix->vpn4.rd) +
		    prefix->vpn4.labellen;
		break;
	default:
		return (-1);
	}

	if ((bptr = ibuf_reserve(buf, totlen)) == NULL)
		return (-1);
	if (prefix_write(bptr, totlen, prefix, plen) == -1)
		return (-1);
	return (0);
}

/*
 * Searches in the prefix list of specified pt_entry for a prefix entry
 * belonging to the peer peer. Returns NULL if no match found.
 */
struct prefix *
prefix_bypeer(struct rib_entry *re, struct rde_peer *peer, u_int32_t flags)
{
	struct prefix	*p;

	LIST_FOREACH(p, &re->prefix_h, rib_l) {
		if (p->aspath->peer != peer)
			continue;
		if (p->aspath->flags & flags &&
		    (flags & F_ANN_DYNAMIC) !=
		    (p->aspath->flags & F_ANN_DYNAMIC))
			continue;
		return (p);
	}
	return (NULL);
}

void
prefix_updateall(struct rde_aspath *asp, enum nexthop_state state,
    enum nexthop_state oldstate)
{
	struct prefix	*p;

	LIST_FOREACH(p, &asp->prefix_h, path_l) {
		/*
		 * skip non local-RIBs or RIBs that are flagged as noeval.
		 */
		if (re_rib(p->re)->flags & F_RIB_NOEVALUATE)
			continue;

		if (oldstate == state && state == NEXTHOP_REACH) {
			/*
			 * The state of the nexthop did not change. The only
			 * thing that may have changed is the true_nexthop
			 * or other internal infos. This will not change
			 * the routing decision so shortcut here.
			 */
			if ((re_rib(p->re)->flags & F_RIB_NOFIB) == 0 &&
			    p == p->re->active)
				rde_send_kroute(re_rib(p->re), p, NULL);
			continue;
		}

		/* redo the route decision */
		LIST_REMOVE(p, rib_l);
		/*
		 * If the prefix is the active one remove it first,
		 * this has to be done because we can not detect when
		 * the active prefix changes its state. In this case
		 * we know that this is a withdrawal and so the second
		 * prefix_evaluate() will generate no update because
		 * the nexthop is unreachable or ineligible.
		 */
		if (p == p->re->active)
			prefix_evaluate(NULL, p->re);
		prefix_evaluate(p, p->re);
	}
}

/* kill a prefix. */
void
prefix_destroy(struct prefix *p)
{
	struct rde_aspath	*asp;

	asp = p->aspath;
	prefix_unlink(p);
	prefix_free(p);

	if (path_empty(asp))
		path_destroy(asp);
}

/*
 * helper function to clean up the connected networks after a reload
 */
void
prefix_network_clean(struct rde_peer *peer, time_t reloadtime, u_int32_t flags)
{
	struct rde_aspath	*asp, *xasp;
	struct prefix		*p, *xp;

	for (asp = LIST_FIRST(&peer->path_h); asp != NULL; asp = xasp) {
		xasp = LIST_NEXT(asp, peer_l);
		if ((asp->flags & F_ANN_DYNAMIC) != flags)
			continue;
		for (p = LIST_FIRST(&asp->prefix_h); p != NULL; p = xp) {
			xp = LIST_NEXT(p, path_l);
			if (reloadtime > p->lastchange) {
				prefix_unlink(p);
				prefix_free(p);
			}
		}
		if (path_empty(asp))
			path_destroy(asp);
	}
}

/*
 * Link a prefix into the different parent objects.
 */
static void
prefix_link(struct prefix *pref, struct rib_entry *re, struct rde_aspath *asp)
{
	LIST_INSERT_HEAD(&asp->prefix_h, pref, path_l);
	PREFIX_COUNT(asp, 1);

	pref->aspath = asp;
	pref->re = re;
	pref->prefix = re->prefix;
	pt_ref(pref->prefix);
	pref->lastchange = time(NULL);

	/* make route decision */
	prefix_evaluate(pref, re);
}

/*
 * Unlink a prefix from the different parent objects.
 */
static void
prefix_unlink(struct prefix *pref)
{
	struct rib_entry	*re = pref->re;

	/* make route decision */
	LIST_REMOVE(pref, rib_l);
	prefix_evaluate(NULL, re);

	LIST_REMOVE(pref, path_l);
	PREFIX_COUNT(pref->aspath, -1);

	pt_unref(pref->prefix);
	if (pt_empty(pref->prefix))
		pt_remove(pref->prefix);
	if (rib_empty(re))
		rib_remove(re);

	/* destroy all references to other objects */
	pref->aspath = NULL;
	pref->prefix = NULL;
	pref->re = NULL;

	/*
	 * It's the caller's duty to remove empty aspath structures.
	 * Also freeing the unlinked prefix is the caller's duty.
	 */
}

/* alloc and bzero new entry. May not fail. */
static struct prefix *
prefix_alloc(void)
{
	struct prefix *p;

	p = calloc(1, sizeof(*p));
	if (p == NULL)
		fatal("prefix_alloc");
	rdemem.prefix_cnt++;
	return p;
}

/* free a unlinked entry */
static void
prefix_free(struct prefix *pref)
{
	rdemem.prefix_cnt--;
	free(pref);
}

/*
 * nexthop functions
 */
struct nexthop_head	*nexthop_hash(struct bgpd_addr *);
struct nexthop		*nexthop_lookup(struct bgpd_addr *);

/*
 * In BGP there exist two nexthops: the exit nexthop which was announced via
 * BGP and the true nexthop which is used in the FIB -- forward information
 * base a.k.a kernel routing table. When sending updates it is even more
 * confusing. In IBGP we pass the unmodified exit nexthop to the neighbors
 * while in EBGP normally the address of the router is sent. The exit nexthop
 * may be passed to the external neighbor if the neighbor and the exit nexthop
 * reside in the same subnet -- directly connected.
 */
struct nexthop_table {
	LIST_HEAD(nexthop_head, nexthop)	*nexthop_hashtbl;
	u_int32_t				 nexthop_hashmask;
} nexthoptable;

SIPHASH_KEY nexthoptablekey;

void
nexthop_init(u_int32_t hashsize)
{
	u_int32_t	 hs, i;

	for (hs = 1; hs < hashsize; hs <<= 1)
		;
	nexthoptable.nexthop_hashtbl = calloc(hs, sizeof(struct nexthop_head));
	if (nexthoptable.nexthop_hashtbl == NULL)
		fatal("nextop_init");

	for (i = 0; i < hs; i++)
		LIST_INIT(&nexthoptable.nexthop_hashtbl[i]);
	arc4random_buf(&nexthoptablekey, sizeof(nexthoptablekey));

	nexthoptable.nexthop_hashmask = hs - 1;
}

void
nexthop_shutdown(void)
{
	u_int32_t		 i;
	struct nexthop		*nh, *nnh;

	for (i = 0; i <= nexthoptable.nexthop_hashmask; i++) {
		for (nh = LIST_FIRST(&nexthoptable.nexthop_hashtbl[i]);
		    nh != NULL; nh = nnh) {
			nnh = LIST_NEXT(nh, nexthop_l);
			nh->state = NEXTHOP_UNREACH;
			(void)nexthop_delete(nh);
		}
		if (!LIST_EMPTY(&nexthoptable.nexthop_hashtbl[i]))
			log_warnx("nexthop_shutdown: non-free table");
	}

	free(nexthoptable.nexthop_hashtbl);
}

void
nexthop_update(struct kroute_nexthop *msg)
{
	struct nexthop		*nh;
	struct rde_aspath	*asp;
	enum nexthop_state	 oldstate;

	nh = nexthop_lookup(&msg->nexthop);
	if (nh == NULL) {
		log_warnx("nexthop_update: non-existent nexthop %s",
		    log_addr(&msg->nexthop));
		return;
	}

	oldstate = nh->state;
	if (msg->valid)
		nh->state = NEXTHOP_REACH;
	else
		nh->state = NEXTHOP_UNREACH;

	if (msg->connected) {
		nh->flags |= NEXTHOP_CONNECTED;
		memcpy(&nh->true_nexthop, &nh->exit_nexthop,
		    sizeof(nh->true_nexthop));
	} else
		memcpy(&nh->true_nexthop, &msg->gateway,
		    sizeof(nh->true_nexthop));

	memcpy(&nh->nexthop_net, &msg->net,
	    sizeof(nh->nexthop_net));
	nh->nexthop_netlen = msg->netlen;

	if (nexthop_delete(nh))
		/* nexthop no longer used */
		return;

	if (rde_noevaluate())
		/*
		 * if the decision process is turned off there is no need
		 * for the aspath list walk.
		 */
		return;

	LIST_FOREACH(asp, &nh->path_h, nexthop_l) {
		prefix_updateall(asp, nh->state, oldstate);
	}
}

void
nexthop_modify(struct rde_aspath *asp, struct bgpd_addr *nexthop,
    enum action_types type, u_int8_t aid)
{
	struct nexthop	*nh;

	if (type == ACTION_SET_NEXTHOP && aid != nexthop->aid)
		return;

	asp->flags &= ~F_NEXTHOP_MASK;
	switch (type) {
	case ACTION_SET_NEXTHOP_REJECT:
		asp->flags |= F_NEXTHOP_REJECT;
		break;
	case ACTION_SET_NEXTHOP_BLACKHOLE:
		asp->flags |= F_NEXTHOP_BLACKHOLE;
		break;
	case ACTION_SET_NEXTHOP_NOMODIFY:
		asp->flags |= F_NEXTHOP_NOMODIFY;
		break;
	case ACTION_SET_NEXTHOP_SELF:
		asp->flags |= F_NEXTHOP_SELF;
		break;
	case ACTION_SET_NEXTHOP:
		nh = nexthop_get(nexthop);
		if (asp->flags & F_ATTR_LINKED)
			nexthop_unlink(asp);
		asp->nexthop = nh;
		if (asp->flags & F_ATTR_LINKED)
			nexthop_link(asp);
		break;
	default:
		break;
	}
}

void
nexthop_link(struct rde_aspath *asp)
{
	if (asp->nexthop == NULL)
		return;

	LIST_INSERT_HEAD(&asp->nexthop->path_h, asp, nexthop_l);
}

void
nexthop_unlink(struct rde_aspath *asp)
{
	struct nexthop	*nh;

	if (asp->nexthop == NULL)
		return;

	LIST_REMOVE(asp, nexthop_l);

	/* see if list is empty */
	nh = asp->nexthop;
	asp->nexthop = NULL;

	(void)nexthop_delete(nh);
}

int
nexthop_delete(struct nexthop *nh)
{
	/* nexthop still used by some other aspath */
	if (!LIST_EMPTY(&nh->path_h))
		return (0);

	/* either pinned or in a state where it may not be deleted */
	if (nh->refcnt > 0 || nh->state == NEXTHOP_LOOKUP)
		return (0);

	LIST_REMOVE(nh, nexthop_l);
	rde_send_nexthop(&nh->exit_nexthop, 0);

	rdemem.nexthop_cnt--;
	free(nh);
	return (1);
}

struct nexthop *
nexthop_get(struct bgpd_addr *nexthop)
{
	struct nexthop	*nh;

	nh = nexthop_lookup(nexthop);
	if (nh == NULL) {
		nh = calloc(1, sizeof(*nh));
		if (nh == NULL)
			fatal("nexthop_alloc");
		rdemem.nexthop_cnt++;

		LIST_INIT(&nh->path_h);
		nh->state = NEXTHOP_LOOKUP;
		nh->exit_nexthop = *nexthop;
		LIST_INSERT_HEAD(nexthop_hash(nexthop), nh,
		    nexthop_l);

		rde_send_nexthop(&nh->exit_nexthop, 1);
	}

	return (nh);
}

int
nexthop_compare(struct nexthop *na, struct nexthop *nb)
{
	struct bgpd_addr	*a, *b;

	if (na == nb)
		return (0);
	if (na == NULL)
		return (-1);
	if (nb == NULL)
		return (1);

	a = &na->exit_nexthop;
	b = &nb->exit_nexthop;

	if (a->aid != b->aid)
		return (a->aid - b->aid);

	switch (a->aid) {
	case AID_INET:
		if (ntohl(a->v4.s_addr) > ntohl(b->v4.s_addr))
			return (1);
		if (ntohl(a->v4.s_addr) < ntohl(b->v4.s_addr))
			return (-1);
		return (0);
	case AID_INET6:
		return (memcmp(&a->v6, &b->v6, sizeof(struct in6_addr)));
	default:
		fatalx("nexthop_cmp: unknown af");
	}
	return (-1);
}

struct nexthop *
nexthop_lookup(struct bgpd_addr *nexthop)
{
	struct nexthop	*nh;

	LIST_FOREACH(nh, nexthop_hash(nexthop), nexthop_l) {
		if (memcmp(&nh->exit_nexthop, nexthop,
		    sizeof(struct bgpd_addr)) == 0)
			return (nh);
	}
	return (NULL);
}

struct nexthop_head *
nexthop_hash(struct bgpd_addr *nexthop)
{
	u_int32_t	 h = 0;

	switch (nexthop->aid) {
	case AID_INET:
		h = SipHash24(&nexthoptablekey, &nexthop->v4.s_addr,
		    sizeof(nexthop->v4.s_addr));
		break;
	case AID_INET6:
		h = SipHash24(&nexthoptablekey, &nexthop->v6,
		    sizeof(struct in6_addr));
		break;
	default:
		fatalx("nexthop_hash: unsupported AF");
	}
	return (&nexthoptable.nexthop_hashtbl[h & nexthoptable.nexthop_hashmask]);
}

@


1.152
log
@Switch rde_generate_update and rde_send_kroute to accept a struct rib instead
of the id. For this we move the rtableid into struct rib. Also move the update
code in rib.c up to where the kroute code is. Makes more senses like that.
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.151 2017/01/24 23:38:12 claudio Exp $ */
d77 1
a77 1
struct rib_desc *
d111 1
a111 1
	return (&ribs[id]);
d114 1
a114 1
struct rib_desc *
d120 1
a120 1
		return (&ribs[1]);	/* no name returns the Loc-RIB */
d124 1
a124 1
			return (&ribs[id]);
d130 6
d137 1
a137 1
rib_free(struct rib_desc *rib)
d140 1
d147 1
a147 1
		if (ctx->ctx_rib == &rib->rib) {
d158 2
a159 2
	for (re = RB_MIN(rib_tree, rib_tree(&rib->rib)); re != NULL; re = xre) {
		xre = RB_NEXT(rib_tree, rib_tree(&rib->rib), re);
d182 3
a184 2
	filterlist_free(rib->in_rules_tmp);
	filterlist_free(rib->in_rules);
@


1.151
log
@Save some space in struct rib_entry so it is back to 64bytes (on 64bit archs).
Doing this by folding the lock flag into a pointer and providing an accessor
function for the rib pointer. This is an acceptable middle path for this
important structure.
OK benno@@ on an earlier version
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.150 2017/01/24 04:22:42 benno Exp $ */
d104 1
a104 1
	ribs[id].rtableid = rtableid;
d937 1
a937 1
				rde_send_kroute(p, NULL, re_rib(p->re)->id);
@


1.150
log
@sync log.c from relayd et al to bgpd.

there is still a little difference regarding handling of the verbosity
value that will be handled later.

ok claudio@@ florian@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.149 2017/01/23 22:53:52 claudio Exp $ */
d52 18
d142 1
a142 1
			re->flags &= ~F_RIB_ENTRYLOCK;
d243 1
a243 2
	re->rib = rib;
	re->flags = rib->flags;
d264 1
a264 1
	if (re->flags & F_RIB_ENTRYLOCK)
d272 1
a272 1
	if (RB_REMOVE(rib_tree, rib_tree(re->rib), re) == NULL)
d317 1
a317 1
		    (re->flags & F_RIB_ENTRYLOCK) == 0) {
d320 1
a320 1
			re->flags |= F_RIB_ENTRYLOCK;
d339 1
a339 1
	re->flags &= ~F_RIB_ENTRYLOCK;
d568 1
a568 1
		if (p->re->rib == &ribs[0].rib)
d925 1
a925 1
		if (p->re->rib->flags & F_RIB_NOEVALUATE)
d935 1
a935 1
			if ((p->re->rib->flags & F_RIB_NOFIB) == 0 &&
d937 1
a937 1
				rde_send_kroute(p, NULL, p->re->rib->id);
@


1.149
log
@Rename rib pointer in struct prefix to re since it points to a rib_entry.
While there also remove a comment that is since a few years at least.
OK gcc
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.148 2017/01/23 22:47:59 claudio Exp $ */
d29 1
@


1.148
log
@Introduce a struct rib sitting between struct rib_desc and struct rib_tree.
This way the tree becomes a bit better decoupled.
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.147 2017/01/23 13:08:47 claudio Exp $ */
d550 1
a550 1
		if (p->rib->rib == &ribs[0].rib)
d743 1
a743 1
	np->rib = p->rib;
d763 1
a763 1
	prefix_evaluate(np, np->rib);
d774 1
a774 1
	p->rib = NULL;
d907 1
a907 1
		if (p->rib->rib->flags & F_RIB_NOEVALUATE)
d917 3
a919 3
			if ((p->rib->rib->flags & F_RIB_NOFIB) == 0 &&
			    p == p->rib->active)
				rde_send_kroute(p, NULL, p->rib->rib->id);
d933 3
a935 3
		if (p == p->rib->active)
			prefix_evaluate(NULL, p->rib);
		prefix_evaluate(p, p->rib);
d988 1
a988 1
	pref->rib = re;
d1003 1
a1003 1
	struct rib_entry	*re = pref->rib;
d1021 1
a1021 1
	pref->rib = NULL;
@


1.147
log
@Revert the struct rib_tree rename. I need a struct in between because of
how struct rib_entry is used.
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.146 2017/01/23 12:25:19 claudio Exp $ */
d42 1
a42 1
struct rib_entry *rib_add(struct rib_desc *, struct bgpd_addr *, int);
d51 5
d81 1
a81 1
	RB_INIT(&ribs[id].rib);
d83 2
a84 2
	ribs[id].id = id;
	ribs[id].flags = flags;
d121 1
a121 1
		if (ctx->ctx_rib == rib) {
d132 2
a133 2
	for (re = RB_MIN(rib_tree, &rib->rib); re != NULL; re = xre) {
		xre = RB_NEXT(rib_tree,  &rib->rib, re);
d168 1
a168 1
rib_get(struct rib_desc *rib, struct bgpd_addr *prefix, int prefixlen)
d177 1
a177 1
	return (RB_FIND(rib_tree, &rib->rib, &xre));
d181 1
a181 1
rib_lookup(struct rib_desc *rib, struct bgpd_addr *addr)
d210 1
a210 1
rib_add(struct rib_desc *rib, struct bgpd_addr *prefix, int prefixlen)
d224 1
a225 1
	re->ribid = rib->id;
d227 1
a227 1
        if (RB_INSERT(rib_tree, &rib->rib, re) != NULL) {
d254 1
a254 1
	if (RB_REMOVE(rib_tree, &ribs[re->ribid].rib, re) == NULL)
d268 1
a268 1
rib_dump(struct rib_desc *rib, void (*upcall)(struct rib_entry *, void *),
d289 1
a289 1
		re = RB_MIN(rib_tree, &ctx->ctx_rib->rib);
d401 1
a401 1
path_update(struct rib_desc *rib, struct rde_peer *peer, struct rde_aspath *nasp,
d550 1
a550 1
		if (p->rib->ribid == 0)
d685 1
a685 1
prefix_get(struct rib_desc *rib, struct rde_peer *peer, struct bgpd_addr *prefix,
d700 1
a700 1
prefix_add(struct rib_desc *rib, struct rde_aspath *asp, struct bgpd_addr *prefix,
d787 1
a787 1
prefix_remove(struct rib_desc *rib, struct rde_peer *peer, struct bgpd_addr *prefix,
d907 1
a907 1
		if (p->rib->flags & F_RIB_NOEVALUATE)
d917 1
a917 1
			if ((p->rib->flags & F_RIB_NOFIB) == 0 &&
d919 1
a919 1
				rde_send_kroute(p, NULL, p->rib->ribid);
@


1.146
log
@More rototilling, make rib_new and rib_find return a point to struct rib_desc
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.145 2017/01/23 11:46:02 claudio Exp $ */
d48 2
a49 2
RB_PROTOTYPE(rib, rib_entry, rib_e, rib_compare);
RB_GENERATE(rib, rib_entry, rib_e, rib_compare);
d127 2
a128 2
	for (re = RB_MIN(rib, &rib->rib); re != NULL; re = xre) {
		xre = RB_NEXT(rib,  &rib->rib, re);
d172 1
a172 1
	return (RB_FIND(rib, &rib->rib, &xre));
d222 1
a222 1
        if (RB_INSERT(rib, &rib->rib, re) != NULL) {
d249 1
a249 1
	if (RB_REMOVE(rib, &ribs[re->ribid].rib, re) == NULL)
d284 1
a284 1
		re = RB_MIN(rib, &ctx->ctx_rib->rib);
d289 1
a289 1
	for (i = 0; re != NULL; re = RB_NEXT(rib, unused, re)) {
d320 1
a320 1
		re = RB_NEXT(rib, unused, re);
@


1.145
log
@Now rename struct rib_tree to struct rib. Again OK gcc
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.144 2017/01/23 11:43:40 claudio Exp $ */
d53 1
a53 1
u_int16_t
a63 3
	if (id == RIB_FAILED)
		fatalx("rib_new: trying to use reserved id");

d87 1
a87 1
	return (id);
d90 1
a90 1
u_int16_t
d96 1
a96 1
		return (1);	/* no name returns the Loc-RIB */
d100 1
a100 1
			return (id);
d103 1
a103 1
	return (RIB_FAILED);
@


1.144
log
@Rename struct rib to struct rib_desc. Mechanical change, OK gcc
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.143 2016/08/27 01:26:22 guenther Exp $ */
d48 2
a49 2
RB_PROTOTYPE(rib_tree, rib_entry, rib_e, rib_compare);
RB_GENERATE(rib_tree, rib_entry, rib_e, rib_compare);
d130 2
a131 2
	for (re = RB_MIN(rib_tree, &rib->rib); re != NULL; re = xre) {
		xre = RB_NEXT(rib_tree,  &rib->rib, re);
d175 1
a175 1
	return (RB_FIND(rib_tree, &rib->rib, &xre));
d225 1
a225 1
        if (RB_INSERT(rib_tree, &rib->rib, re) != NULL) {
d252 1
a252 1
	if (RB_REMOVE(rib_tree, &ribs[re->ribid].rib, re) == NULL)
d287 1
a287 1
		re = RB_MIN(rib_tree, &ctx->ctx_rib->rib);
d292 1
a292 1
	for (i = 0; re != NULL; re = RB_NEXT(rib_tree, unused, re)) {
d323 1
a323 1
		re = RB_NEXT(rib_tree, unused, re);
@


1.143
log
@Pull in <time.h> for one or more of gmtime, strftime, strptime, time,
timegm, and tzset

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.142 2015/03/14 03:52:42 claudio Exp $ */
d38 1
a38 1
struct rib *ribs;
d42 1
a42 1
struct rib_entry *rib_add(struct rib *, struct bgpd_addr *, int);
d56 1
a56 1
	struct rib	*xribs;
d69 1
a69 1
		    sizeof(struct rib))) == NULL) {
d77 1
a77 1
	bzero(&ribs[id], sizeof(struct rib));
d110 1
a110 1
rib_free(struct rib *rib)
d156 1
a156 1
	bzero(rib, sizeof(struct rib));
d166 1
a166 1
rib_get(struct rib *rib, struct bgpd_addr *prefix, int prefixlen)
d179 1
a179 1
rib_lookup(struct rib *rib, struct bgpd_addr *addr)
d208 1
a208 1
rib_add(struct rib *rib, struct bgpd_addr *prefix, int prefixlen)
d266 1
a266 1
rib_dump(struct rib *rib, void (*upcall)(struct rib_entry *, void *),
d399 1
a399 1
path_update(struct rib *rib, struct rde_peer *peer, struct rde_aspath *nasp,
d683 1
a683 1
prefix_get(struct rib *rib, struct rde_peer *peer, struct bgpd_addr *prefix,
d698 1
a698 1
prefix_add(struct rib *rib, struct rde_aspath *asp, struct bgpd_addr *prefix,
d785 1
a785 1
prefix_remove(struct rib *rib, struct rde_peer *peer, struct bgpd_addr *prefix,
@


1.142
log
@rename rde_free_filter() to filterlist_free() and start using it outside
of the RDE to free the filterlists. Also refactor common code to merge
filterlists into its own function. Makes the code look nicer.
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.141 2014/12/18 19:28:44 tedu Exp $ */
d25 1
@


1.141
log
@two more uses of siphash. better hash for ipv4. maybe not needed for rbtree
hint, but still pretty. ok deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.140 2014/12/12 18:15:51 tedu Exp $ */
d153 2
a154 2
	rde_free_filter(rib->in_rules_tmp);
	rde_free_filter(rib->in_rules);
@


1.140
log
@convert some hash tables (the easy ones) to siphash. ok benno.
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.139 2014/10/08 16:15:37 deraadt Exp $ */
a20 1
#include <sys/hash.h>
d1067 2
d1082 1
d1313 2
a1314 3
		h = (AF_INET ^ ntohl(nexthop->v4.s_addr) ^
		    ntohl(nexthop->v4.s_addr) >> 13) &
		    nexthoptable.nexthop_hashmask;
d1317 2
a1318 2
		h = hash32_buf(&nexthop->v6, sizeof(struct in6_addr),
		    HASHINIT) & nexthoptable.nexthop_hashmask;
d1323 1
a1323 1
	return (&nexthoptable.nexthop_hashtbl[h]);
@


1.139
log
@Use reallocarray() throughout to spot multiplicative int overflow.
ok henning benno
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.138 2013/08/14 20:34:27 claudio Exp $ */
d25 1
d361 2
d365 1
a365 1
	&pathtable.path_hashtbl[hash32_buf((x)->data, (x)->len, HASHINIT) & \
d383 1
@


1.138
log
@Rewrite the internals of the RDE reload logic.
This is the first step to make bgpd reload non blocking in the RDE.
It also speeds up the reload time a fair bit in some cases (mainly if
you run with multiple RIBs and have larger filtersets) and it should also
fix a few edge cases on reloads.
Testing done by benno@@, florian@@ and sthen@@ OK henning@@ and benno@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.137 2013/07/17 14:09:13 benno Exp $ */
a55 1
	size_t		newsize;
d67 2
a68 2
		newsize = sizeof(struct rib) * (id + 1);
		if ((xribs = realloc(ribs, newsize)) == NULL) {
@


1.137
log
@on graceful restart, the number of prefixes could be counted wrong,
triping max-prefix.  fix it this way, at least until prefix accounting
is done better.
diff from florian@@
ok claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.136 2013/05/20 11:26:13 claudio Exp $ */
d85 5
d99 1
a99 1
		return (1);	/* XXX */
d116 1
d135 2
a136 2
		 * will remove the rib_entry as well and at because we do
		 * a empty check in prefix_destroy() it is not possible to
d154 2
@


1.136
log
@D'oh, add missing break in prefix_writebuf(). Another find by blambert@@
who is to shy to commit these by himself.
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.135 2013/03/14 14:52:52 florian Exp $ */
d510 1
a510 1
void
d515 1
d517 1
d535 5
d542 1
@


1.135
log
@correct struct in sizeof(); found by llvm
OK sthen@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.134 2012/09/12 05:56:22 claudio Exp $ */
d843 1
@


1.134
log
@Better graceful restart support (implementing more then just the EoR record).
This implements only the "Restarting Client" bits of the RFC -- in other
words bgpd will keep the FIB when the client restarts but it will not do GR
when restarting itself. The capability is still off by default (you need
"announce restart yes" to enable it).
Tested by Anders Berggren. OK sthen@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.133 2012/07/01 11:55:13 sthen Exp $ */
d1055 1
a1055 1
	nexthoptable.nexthop_hashtbl = calloc(hs, sizeof(struct nexthop_table));
@


1.133
log
@typo in comment, s/withdrawl/withdrawal/
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.132 2012/05/22 20:44:06 claudio Exp $ */
d507 30
@


1.132
log
@Flush the right networks, the dynamic ones not the static ones.
OK henning@@, sthen@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.131 2011/09/21 08:59:01 claudio Exp $ */
d877 1
a877 1
		 * we know that this is a withdrawl and so the second
@


1.131
log
@Fix nexthop_modify() to reset the flags when called. Until now
set nexthop-self was sticky and so later set nexthop <IP> were
not applied.
Problem found and fix tested by Tony Sarendal. OK henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.130 2011/09/20 21:19:06 claudio Exp $ */
d912 1
a912 1
		if ((asp->flags & F_ANN_DYNAMIC) == flags)
@


1.130
log
@Move a few functions into util.c because bgpctl will need them soon.
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.129 2011/09/17 16:29:44 claudio Exp $ */
d1109 6
a1114 1
	if (type == ACTION_SET_NEXTHOP_REJECT) {
d1116 2
a1117 3
		return;
	}
	if (type  == ACTION_SET_NEXTHOP_BLACKHOLE) {
d1119 2
a1120 3
		return;
	}
	if (type == ACTION_SET_NEXTHOP_NOMODIFY) {
d1122 2
a1123 3
		return;
	}
	if (type == ACTION_SET_NEXTHOP_SELF) {
d1125 11
a1135 1
		return;
a1136 9
	if (aid != nexthop->aid)
		return;

	nh = nexthop_get(nexthop);
	if (asp->flags & F_ATTR_LINKED)
		nexthop_unlink(asp);
	asp->nexthop = nh;
	if (asp->flags & F_ATTR_LINKED)
		nexthop_link(asp);
@


1.129
log
@Implement new mrt table dump format as specified in draft-ietf-grow-mrt.
Tested with IP and IPv6 sessions and against the libbgpdump parser.
OK henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.128 2011/01/14 20:07:00 henning Exp $ */
a628 60

int
prefix_compare(const struct bgpd_addr *a, const struct bgpd_addr *b,
    int prefixlen)
{
	in_addr_t	mask, aa, ba;
	int		i;
	u_int8_t	m;

	if (a->aid != b->aid)
		return (a->aid - b->aid);

	switch (a->aid) {
	case AID_INET:
		if (prefixlen > 32)
			fatalx("prefix_cmp: bad IPv4 prefixlen");
		mask = htonl(prefixlen2mask(prefixlen));
		aa = ntohl(a->v4.s_addr & mask);
		ba = ntohl(b->v4.s_addr & mask);
		if (aa != ba)
			return (aa - ba);
		return (0);
	case AID_INET6:
		if (prefixlen > 128)
			fatalx("prefix_cmp: bad IPv6 prefixlen");
		for (i = 0; i < prefixlen / 8; i++)
			if (a->v6.s6_addr[i] != b->v6.s6_addr[i])
				return (a->v6.s6_addr[i] - b->v6.s6_addr[i]);
		i = prefixlen % 8;
		if (i) {
			m = 0xff00 >> i;
			if ((a->v6.s6_addr[prefixlen / 8] & m) !=
			    (b->v6.s6_addr[prefixlen / 8] & m))
				return ((a->v6.s6_addr[prefixlen / 8] & m) -
				    (b->v6.s6_addr[prefixlen / 8] & m));
		}
		return (0);
	case AID_VPN_IPv4:
		if (prefixlen > 32)
			fatalx("prefix_cmp: bad IPv4 VPN prefixlen");
		if (betoh64(a->vpn4.rd) > betoh64(b->vpn4.rd))
			return (1);
		if (betoh64(a->vpn4.rd) < betoh64(b->vpn4.rd))
			return (-1);
		mask = htonl(prefixlen2mask(prefixlen));
		aa = ntohl(a->vpn4.addr.s_addr & mask);
		ba = ntohl(b->vpn4.addr.s_addr & mask);
		if (aa != ba)
			return (aa - ba);
		if (a->vpn4.labellen > b->vpn4.labellen)
			return (1);
		if (a->vpn4.labellen < b->vpn4.labellen)
			return (-1);
		return (memcmp(a->vpn4.labelstack, b->vpn4.labelstack,
		    a->vpn4.labellen));
	default:
		fatalx("prefix_cmp: unknown af");
	}
	return (-1);
}
@


1.128
log
@plug memleak in err path; from zinovik, ok claudio
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.127 2010/05/03 13:09:38 claudio Exp $ */
d857 25
@


1.127
log
@Make it possible to load multiple routing tables at the same time and use
those for alternate RIBs. This allows to use "rde rib TESTIT rtable 1".
NOTE: nexthop verification has changed for alternate tables. For now
nexthop will only be verified against the main routing table (id 0).
Because of this "nexthop qualify via bgp" may now compare the nexthops
against bgpd routes from a different RIB.
Tested by sthen@@, OK to move on by henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.126 2010/04/20 09:02:12 claudio Exp $ */
d219 1
@


1.126
log
@prefix_unlink() must remove the rib entry. Currently this was only done
in prefix_destroy() but there is another caller of prefix_unlink() which
missed the rib_remove() resulting in tree corruption and possible crashes.
Doing the remove in prefix_unlink() is better since we do the same with the
prefix and rib & prefix are linked. Fix some comments to match code and
remove double call to pt_empty()/pt_remove().
Found while hacking on something else.
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.125 2010/04/07 09:44:11 claudio Exp $ */
d53 1
a53 1
rib_new(char *name, u_int16_t flags)
d83 1
d901 1
a901 1
				rde_send_kroute(p, NULL);
@


1.125
log
@Call nexthop_delete() a bit later in nexthop_update(). The nh->state needs
to be changed before calling nexthop_delete() or the nexthop will not be
correclty removed in the unlikly event when all aspathes move to a different
nexthop while the lookup happens.
sthen@@ agrees with the logic.
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.124 2010/04/06 13:25:08 claudio Exp $ */
a923 1
	struct rib_entry	*re;
a925 1
	re = p->rib;
a929 2
	if (rib_empty(re))
		rib_remove(re);
a941 1
	struct pt_entry		*pte;
a949 1
				pte = p->prefix;
a951 3

				if (pt_empty(pte))
					pt_remove(pte);
d984 5
a988 5
	if (pref->rib) {
		/* make route decision */
		LIST_REMOVE(pref, rib_l);
		prefix_evaluate(NULL, pref->rib);
	}
d996 2
d1005 2
a1006 2
	 * It's the caller's duty to remove empty aspath respectively pt_entry
	 * structures. Also freeing the unlinked prefix is the caller's duty.
@


1.124
log
@Switch to a more address family independent nexthop imsg. Instead of passing
struct kroute or kroute6 pack the needed info into a struct bgpd_addr.
No flames comming out of my and sthen@@'s bgpd routers.
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.123 2010/03/29 09:06:56 claudio Exp $ */
a1108 4
	if (nexthop_delete(nh))
		/* nexthop no longer used */
		return;

d1126 4
@


1.123
log
@We always allocate rib ids dynamicaly so there is no need for allowing
fixed id allocation. Makes code simpler.
OK henning
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.122 2010/03/26 15:38:39 claudio Exp $ */
d1127 3
a1129 15
	switch (msg->nexthop.aid) {
	case AID_INET:
		nh->nexthop_netlen = msg->kr.kr4.prefixlen;
		nh->nexthop_net.aid = AID_INET;
		nh->nexthop_net.v4.s_addr = msg->kr.kr4.prefix.s_addr;
		break;
	case AID_INET6:
		nh->nexthop_netlen = msg->kr.kr6.prefixlen;
		nh->nexthop_net.aid = AID_INET6;
		memcpy(&nh->nexthop_net.v6, &msg->kr.kr6.prefix,
		    sizeof(struct in6_addr));
		break;
	default:
		fatalx("nexthop_update: unknown af");
	}
@


1.122
log
@Be more careful when walking the tree looking for a non-empty element,
we may actually hit the end of the tree (at least in theory).
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.121 2010/03/03 13:52:39 claudio Exp $ */
d53 1
a53 1
rib_new(int id, char *name, u_int16_t flags)
d57 1
d59 3
a61 5
	if (id < 0) {
		for (id = 0; id < rib_size; id++) {
			if (*ribs[id].name == '\0')
				break;
		}
@


1.121
log
@Replace enum rib_state with enum reconf_action since their doing the same.
NEW is now REINIT, ACTIVE is KEEP and DELETE and NONE stay the same.
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.120 2010/01/13 06:02:37 claudio Exp $ */
d313 1
a313 1
	while (rib_empty(re))
@


1.120
log
@Add support for BGP MPLS VPN aka RFC 4364. This is only the RDE part so
that it is possible to use OpenBGPD as a route-reflector for VPNv4.
Some clean up of the BGP MP code so that multiple protocols are easier
supported. kroute/kernel support not yet done but comming.
OK henning@@, reyk@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.119 2010/01/10 00:15:09 claudio Exp $ */
d81 1
a81 1
	ribs[id].state = RIB_NEW;
@


1.119
log
@Switch rib_dump() to use AID instead of AFs. OK henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.118 2009/12/01 14:28:05 claudio Exp $ */
d178 1
d665 18
d829 4
a832 2
	if (prefix->aid != AID_INET && prefix->aid != AID_INET6)
		return (-1);
d834 9
a842 1
	totlen = PREFIX_SIZE(plen);
d844 10
a853 1
	if (totlen > len)
d855 1
a855 3
	*buf++ = plen;
	memcpy(buf, &prefix->ba, totlen - 1);
	return (totlen);
d1316 1
a1316 1
		h = hash32_buf(nexthop->v6.s6_addr, sizeof(struct in6_addr),
@


1.118
log
@Use an artificial address family id in struct bgpd_addr and almost everywhere
else. Adds conversion functions to map AFI/SAFI and the Unix AF_ values
from and into AID used in bgpd.  This is needed to support things like MPLS
VPN and other upcomming changes that need to play a lot with AFI/SAFI pairs.
Mostly mechanical change, henning@@ has no particular issues with this.
Must go in so that I can continue working.
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.117 2009/10/05 12:03:45 claudio Exp $ */
d257 1
a257 1
    void *arg, sa_family_t af)
d266 1
a266 1
	ctx->ctx_af = af;
d283 2
a284 2
		if (ctx->ctx_af != AF_UNSPEC &&
		    ctx->ctx_af != aid2af(re->prefix->aid))
@


1.117
log
@Load prefixes into new created RIBs at reload time by walking over the
Adj-RIB-In. This only works correctly when softreconfig in is enabled
(which is the default). This is needed to allow dynamic creation of
additional RIBs. OK henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.116 2009/06/29 14:13:48 claudio Exp $ */
d176 2
a177 2
	switch (addr->af) {
	case AF_INET:
d184 1
a184 1
	case AF_INET6:
d283 2
a284 1
		if (ctx->ctx_af != AF_UNSPEC && ctx->ctx_af != re->prefix->af)
d636 2
a637 2
	if (a->af != b->af)
		return (a->af - b->af);
d639 2
a640 2
	switch (a->af) {
	case AF_INET:
d649 1
a649 1
	case AF_INET6:
d810 1
a810 1
	if (prefix->af != AF_INET && prefix->af != AF_INET6)
d1092 2
a1093 2
	switch (msg->nexthop.af) {
	case AF_INET:
d1095 1
a1095 1
		nh->nexthop_net.af = AF_INET;
d1098 1
a1098 1
	case AF_INET6:
d1100 1
a1100 1
		nh->nexthop_net.af = AF_INET6;
d1122 1
a1122 1
    enum action_types type, sa_family_t af)
d1142 1
a1142 1
	if (af != nexthop->af)
d1237 2
a1238 2
	if (a->af != b->af)
		return (a->af - b->af);
d1240 2
a1241 2
	switch (a->af) {
	case AF_INET:
d1247 1
a1247 1
	case AF_INET6:
d1273 2
a1274 2
	switch (nexthop->af) {
	case AF_INET:
d1279 1
a1279 1
	case AF_INET6:
@


1.116
log
@Protect the other rde_send_kroute() with a F_RIB_NOFIB check.
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.115 2009/06/07 00:30:23 claudio Exp $ */
d81 1
a81 1
	ribs[id].state = RIB_ACTIVE;
@


1.115
log
@First attempt at reload support for RIBs. There is some magic that I do
not fully understand but at least no flames are comming out of my test
box anymore.
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.114 2009/06/04 21:53:43 claudio Exp $ */
a841 1
/* XXX this completely wrong somewhat */
d862 2
a863 1
			if (p == p->rib->active)
@


1.114
log
@Implement rib_find and add a rib id to struct rde_peer.
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.113 2009/06/04 04:46:42 claudio Exp $ */
d114 2
d127 8
a134 2
		for (p = LIST_FIRST(&re->prefix_h); p != NULL; p = np) {
			np = LIST_NEXT(p, path_l);
d144 2
@


1.113
log
@Add "rde rib <name>" to the config and allow the rde to use these other RIBs.
Still a bit hackish, reload is missing and printconf as well. Looks good h@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.112 2009/06/03 20:22:04 claudio Exp $ */
d65 3
d86 16
@


1.112
log
@Allocate all rib contextes for tree walks and don't use static stack memory.
This will make interruptable walks a lot easier.
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.111 2009/06/03 20:20:10 claudio Exp $ */
a51 7
void
rib_init(void)
{
	rib_new(1, "DEFAULT", 0);
	rib_new(0, "Adj-RIB-In", F_RIB_NOEVALUATE);
}

d53 1
a53 1
rib_new(u_int16_t id, char *name, u_int16_t flags)
d57 7
@


1.111
log
@Initial stab at rib_free() until now unused.
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.110 2009/06/03 20:17:59 claudio Exp $ */
d230 1
a230 1
	struct rib_context	ctx;
d232 7
a238 6
	bzero(&ctx, sizeof(ctx));
	ctx.ctx_rib = rib;
	ctx.ctx_upcall = upcall;
	ctx.ctx_arg = arg;
	ctx.ctx_af = af;
	rib_dump_r(&ctx);
d269 2
@


1.110
log
@Better way to allocate new RIBs.
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.109 2009/06/03 19:54:53 claudio Exp $ */
d88 32
a119 2
	/* XXX */
	//bzero(rib, sizeof(struct rib));
a468 1

@


1.109
log
@Make prefix_destroy more generic and use it in prefix_remove this is possible
because path_remove was changed to remove the prefixes in a slightly different
way.
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.108 2009/06/02 00:09:02 claudio Exp $ */
d55 2
a56 11
	if ((ribs = calloc(1, sizeof(struct rib))) == NULL)
		fatal("rib_init");
	rib_new("DEFAULT");

	/* XXX we need to create Adj-RIB-In by hand */
	bzero(&ribs[0], sizeof(struct rib));
	RB_INIT(&ribs[0].rib);
	ribs[0].state = RIB_ACTIVE;
	ribs[0].id = 0;
	strlcpy(ribs[0].name, "Adj-RIB-In", sizeof("Adj-RIB-In"));
	ribs[0].flags = F_RIB_NOEVALUATE;
d60 1
a60 1
rib_new(char *name)
a63 3
	u_int16_t	id;

	id = rib_name2id(name);
d80 1
@


1.108
log
@Move the rest of the rib dump functions into rde_rib.c where it belongs.
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.107 2009/06/01 23:54:50 claudio Exp $ */
d438 1
a438 1
	struct prefix	*p;
d440 2
a441 1
	while ((p = LIST_FIRST(&asp->prefix_h)) != NULL) {
a452 1
	path_destroy(asp);
d748 1
a748 7
	prefix_unlink(p);
	prefix_free(p);

	if (rib_empty(re))
		rib_remove(re);
	if (path_empty(asp))
		path_destroy(asp);
d834 1
a834 1
/* kill a prefix. Only called by path_remove and path_update. */
d839 1
d842 1
d848 2
@


1.107
log
@Use only one list to queue the dump contextes on. Use the list in struct
rib_context instead of the ctl specific rde_dump_ctx to make it more general.
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.106 2009/06/01 22:54:02 claudio Exp $ */
d39 2
d229 1
d268 17
@


1.106
log
@Do not call the upcall twice on some prefixes. Move the upcall back to
where it was beforhands.
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.105 2009/06/01 22:49:06 claudio Exp $ */
a226 1
		LIST_INSERT_HEAD(&ctx->ctx_rib->ctxts, ctx, entry);
@


1.105
log
@Holy simplification batman. Use the per rib entry flags to lock entries
when interrupting rib dumps and now we no longer need evil RB magic to find
the next entry on restart.
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.104 2009/06/01 21:20:17 claudio Exp $ */
a233 1
		ctx->ctx_upcall(re, ctx->ctx_arg);
d241 1
@


1.104
log
@Instead of storing a pointer to the RIB head in the RIB element use that
space for a flags field and the RIB id. In the end bgpd will be able to
lock RIB elements and therefore make it possible to interrupt all tree
walks.
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.103 2009/05/27 06:58:15 claudio Exp $ */
d184 4
d225 1
a225 1
	if (ctx->ctx_p == NULL) {
d234 6
a239 4
		if (ctx->ctx_count && i++ >= ctx->ctx_count) {
			/* store next start point */
			ctx->ctx_p = re->prefix;
			pt_ref(ctx->ctx_p);
a241 1
		ctx->ctx_upcall(re, ctx->ctx_arg);
d252 1
a252 2
	struct rib_entry *tmp, *prev = NULL;
	int comp;
d254 2
a255 16
	/* frist check if the table is still around */
	if (ctx->ctx_rib == NULL)
		goto done;

	/* then try to find the element */
	tmp = RB_ROOT(&ctx->ctx_rib->rib);
	while (tmp) {
		prev = tmp;
		comp = pt_prefix_cmp(ctx->ctx_p, tmp->prefix);
		if (comp < 0)
			tmp = RB_LEFT(tmp, rib_e);
		else if (comp > 0)
			tmp = RB_RIGHT(tmp, rib_e);
		else
			goto done;
	}
d257 9
a265 26
	/* no match, empty tree */
	if (prev == NULL)
		goto done;

	/*
	 * no perfect match
	 * if last element was bigger use that as new start point
	 */
	if (comp < 0)
		goto done;

	/* backtrack until parent is bigger */
	do {
		prev = RB_PARENT(prev, rib_e);
		if (prev == NULL)
			/* all elements in the tree are smaller */
			goto done;
		comp = pt_prefix_cmp(ctx->ctx_p, prev->prefix);
	} while (comp > 0);

done:
	/* unref the prefix and cleanup if needed. */
	pt_unref(ctx->ctx_p);
	if (pt_empty(ctx->ctx_p))
		pt_remove(ctx->ctx_p);
	return (prev);
@


1.103
log
@Move update and withdraw code into own functions to simplify the necessary
changes to make multiple RIB functional. Also change the way we account the
prefixes per peer (for maxprefix check). Every prefix that was added to any
RIB is counted. OK henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.102 2009/05/21 15:47:03 claudio Exp $ */
d63 1
a63 1
	ribs[0].noevaluate = 1;
d163 2
a164 1
	re->rib = rib;
d188 1
a188 1
	if (RB_REMOVE(rib_tree, &re->rib->rib, re) == NULL)
d817 1
a817 1
		if (p->rib->rib->noevaluate)
@


1.102
log
@Make it possible to turn off the decision process per RIB. This is mainly
used for the Adj-Rib-In. Also initialize the Adj-Rib-In correctly and mark
it a noevaluate.
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.101 2009/05/17 14:45:25 claudio Exp $ */
d295 3
a297 6
#define PREFIX_COUNT(x, id, op)				\
	do {						\
		if (id == 1)				\
			(x)->prefix_cnt += (op);	\
		else					\
			(x)->rib_cnt += (op);		\
d340 1
a340 1
void
d359 1
a359 1
			return;
d378 2
a379 1
		prefix_add(rib, asp, prefix, prefixlen);
d467 1
a467 2
	if (asp->prefix_cnt != 0 || asp->active_cnt != 0 ||
	    asp->rib_cnt != 0)
d644 1
a644 1
void
d660 1
d665 3
a667 3
			return;
		}
		p->lastchange = time(NULL);
d693 1
a693 1
	PREFIX_COUNT(asp, p->rib->rib->id, 1);
d713 1
a713 1
	PREFIX_COUNT(oasp, p->rib->rib->id, -1);
d731 1
a731 1
void
d741 1
a741 1
		return;
d745 1
a745 1
		return;
d762 2
d898 1
a898 2
	PREFIX_COUNT(asp, re->rib->id, 1);
	PREFIX_COUNT(asp->peer, re->rib->id, 1);
d923 1
a923 2
	PREFIX_COUNT(pref->aspath, pref->rib->rib->id, -1);
	PREFIX_COUNT(pref->aspath->peer, pref->rib->rib->id, -1);
@


1.101
log
@F_LOCAL and F_ORIGINAL are gone. The Adj-Rib-In is now a distinct tree.
Fix pf table code by checking if the aspath has a pftableid set or not
instead of doing the F_LOCAL dance. This works because the in the
Adj-Rib-In it is impossible to set pftableid.
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.100 2009/05/17 13:20:12 claudio Exp $ */
d56 8
a811 4
	if (rde_noevaluate())
		/* if the decision process is turned off this is a no-op */
		return;

d814 1
a814 3
		 * XXX THIS IS MISSING AT THE MOMENT
		 * skip non local-RIB nodes, only local-RIB prefixes are
		 * eligible.
d816 2
@


1.100
log
@rib_dump_r needs to check the af of the prefix because there is no rib per
address family. In rib_restart fix a possible use after free.
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.99 2009/05/17 12:25:15 claudio Exp $ */
d342 1
a342 3
#if 0
	/* XXX NEEDS SOMETHING BETTER HERE */
	if (flags & F_LOCAL) {
a345 1
#endif
d442 2
a443 4
#if 0
		/* Commit is done in peer_down() */
		/* XXX AGAIN NEEDS A BETTER SOLUTION */
		struct bgpd_addr addr;
d445 2
a446 2
		pt_getaddr(p->prefix, &addr);
		if (p->flags & F_LOCAL)
d449 1
a449 1
#endif
d743 1
a743 3
#if 0
	/* XXX AGAIN THIS NEEDS A BETTER SOLUTION */
	if (p->flags & F_LOCAL) {
a747 1
#endif
d812 1
a812 1
		 * eligible. Both F_LOCAL and F_ORIGINAL may be set.
@


1.99
log
@Rework most of the RDE to allow multiple RIBs. This is mostly preparation
work by changing the way the RDE DB is built. struct prefix and struct
pt_entry are simplified and extended with a rib_entry where the decision
tree is run on. From now on a prefix can only reside on one particular RIB
which simplifies the code a bit. Currently there are two fixed ribs
(adj-rib-in and the local-rib) which needs to be made more dynamic in
upcomming commits.
This is work in progress, the RDE seems to work for me and sthen@@ (no flames
comming out of our testrouters but there is still a lot missing)
Move into the tree to simplify developement -- henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.98 2009/04/23 19:23:27 claudio Exp $ */
d219 2
d241 1
a241 5
	/* first unref the pt_entry and check if the table is still around */
	pt_unref(ctx->ctx_p);
	if (pt_empty(ctx->ctx_p))
		pt_remove(ctx->ctx_p);

d243 1
a243 1
		return NULL;
d255 1
a255 1
			return (tmp);
d260 1
a260 1
		return (NULL);
d267 1
a267 1
		return (prev);
d273 2
a274 2
			/* all elements in the tree are smaler */
			return (NULL);
d278 5
@


1.98
log
@Rework the way we handle announced networks. Instead of two freak rde_peers
use one that is less freaky. Merge bgpctl and config networks into one tree.
First step of a larger change in the RDE and this goes now in to allow to
move forward.
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.97 2008/11/21 17:41:22 claudio Exp $ */
d36 246
d284 1
a284 1
#define PREFIX_COUNT(x, f, op)				\
d286 1
a286 1
		if (f & F_LOCAL)			\
d288 2
a289 2
		if (f & F_ORIGINAL)			\
			(x)->adjrib_cnt += (op);	\
d333 2
a334 2
path_update(struct rde_peer *peer, struct rde_aspath *nasp,
    struct bgpd_addr *prefix, int prefixlen, u_int32_t flags)
d337 1
a337 1
	struct prefix		*p, *oldp = NULL;
d339 2
d345 1
d348 1
a348 3
	 * First try to find a prefix in the specified RIB or in the
	 * Adj-RIB-In. This works because Local-RIB has precedence over the
	 * Adj-RIB-In. In the end this saves use some additional lookups.
d350 6
a355 33
	if ((p = prefix_get(peer, prefix, prefixlen, flags | F_ORIGINAL)) !=
	    NULL) {
		do {
			if (path_compare(nasp, p->aspath) == 0) {
				if ((p->flags & flags & F_RIB_MASK) == 0) {
					if (oldp != NULL) {
						asp = oldp->aspath;
						prefix_destroy(oldp);
						if (path_empty(asp))
							path_destroy(asp);
					}
					p->flags |= flags & F_RIB_MASK;
					PREFIX_COUNT(p->aspath, flags, 1);
					PREFIX_COUNT(peer, flags, 1);

					/* re-evaluate prefix */
					LIST_REMOVE(p, prefix_l);
					prefix_evaluate(p, p->prefix);
				}
				/* update last change */
				p->lastchange = time(NULL);
				return;
			}
			/*
			 * If the prefix is not already part of the Adj-RIB-In
			 * do a lookup in there. But keep the original prefix
			 * around so that it can be removed later.
			 */
			if (p->flags & F_ORIGINAL)
				break;
			oldp = p;
			p = prefix_get(peer, prefix, prefixlen, F_ORIGINAL);
		} while (p != NULL);
a357 4
	/* Do not try to move a prefix that is in the wrong RIB. */
	if (p == NULL || (p->flags & flags & F_RIB_MASK) == 0)
		p = oldp;

d371 1
a371 1
		prefix_move(asp, p, flags);
d373 1
a373 1
		prefix_add(asp, prefix, prefixlen, flags);
a439 1
	struct bgpd_addr addr;
d442 1
d444 3
d451 1
d464 1
a464 1
	    asp->adjrib_cnt != 0)
d577 2
a578 2
static void		 prefix_link(struct prefix *, struct pt_entry *,
			     struct rde_aspath *, u_int32_t);
d627 2
a628 2
prefix_get(struct rde_peer *peer, struct bgpd_addr *prefix, int prefixlen,
    u_int32_t flags)
d630 1
a630 1
	struct pt_entry	*pte;
d632 2
a633 2
	pte = pt_get(prefix, prefixlen);
	if (pte == NULL)
d635 1
a635 1
	return (prefix_bypeer(pte, peer, flags));
d641 3
a643 3
struct pt_entry *
prefix_add(struct rde_aspath *asp, struct bgpd_addr *prefix, int prefixlen,
    u_int32_t flags)
d646 2
a647 2
	struct prefix	*p;
	struct pt_entry	*pte;
d649 3
a651 3
	pte = pt_get(prefix, prefixlen);
	if (pte == NULL)
		pte = pt_add(prefix, prefixlen);
d653 1
a653 1
	p = prefix_bypeer(pte, asp->peer, flags);
d656 1
a656 1
		prefix_link(p, pte, asp, flags);
d658 1
a658 1
		if (p->aspath != asp)
d660 3
a662 1
			return (prefix_move(asp, p, flags));
a664 2

	return (pte);
d670 2
a671 2
struct pt_entry *
prefix_move(struct rde_aspath *asp, struct prefix *p, u_int32_t flags)
d684 1
a685 1
	np->flags = flags;
d689 1
a689 1
	PREFIX_COUNT(asp, flags, 1);
a695 27
	 * fiddle around with the flags. If the p->flags is not equal
	 * to flags the old prefix p may not be removed but instead p->flags
	 * needs to be adjusted.
	 */
	if ((p->flags & F_RIB_MASK) != (flags & F_RIB_MASK)) {
		if ((p->flags & flags & F_RIB_MASK) == 0)
			fatalx("prefix_move: "
			    "prefix is not part of desired RIB");

		p->flags &= ~(flags & F_RIB_MASK);
		PREFIX_COUNT(p->aspath, flags, -1);
		/* as before peer count needs no update because of move */

		/* redo the route decision for p */
		LIST_REMOVE(p, prefix_l);
		/* If the prefix is the active one remove it first. */
		if (p == p->prefix->active)
			prefix_evaluate(NULL, p->prefix);
		prefix_evaluate(p, p->prefix);

		/* and now for np */
		prefix_evaluate(np, np->prefix);

		return (np->prefix);
	}

	/*
d703 2
a704 2
	LIST_REMOVE(p, prefix_l);
	prefix_evaluate(np, np->prefix);
d709 1
a709 1
	PREFIX_COUNT(oasp, flags, -1);
d715 1
a720 2

	return (np->prefix);
d728 2
a729 2
prefix_remove(struct rde_peer *peer, struct bgpd_addr *prefix, int prefixlen,
    u_int32_t flags)
d732 1
a732 1
	struct pt_entry		*pte;
d735 2
a736 2
	pte = pt_get(prefix, prefixlen);
	if (pte == NULL)	/* Got a dummy withdrawn request */
d739 1
a739 1
	p = prefix_bypeer(pte, peer, flags);
d745 2
d752 1
a752 16

	/* if prefix belongs to more than one RIB just remove one instance */
	if ((p->flags & F_RIB_MASK) != (flags & F_RIB_MASK)) {
		p->flags &= ~(flags & F_RIB_MASK);

		PREFIX_COUNT(p->aspath, flags, -1);
		PREFIX_COUNT(peer, flags, -1);

		/* redo the route decision for p */
		LIST_REMOVE(p, prefix_l);
		/* If the prefix is the active one remove it first. */
		if (p == p->prefix->active)
			prefix_evaluate(NULL, p->prefix);
		prefix_evaluate(p, p->prefix);
		return;
	}
d757 2
a758 2
	if (pt_empty(pte))
		pt_remove(pte);
d786 1
a786 1
prefix_bypeer(struct pt_entry *pte, struct rde_peer *peer, u_int32_t flags)
d790 2
a791 3
	LIST_FOREACH(p, &pte->prefix_h, prefix_l) {
		if (p->aspath->peer != peer ||
		    (p->flags & flags & F_RIB_MASK) == 0)
d793 3
a795 2
		if (flags & F_PREFIX_ANNOUNCED &&
		    (flags & F_ANN_DYNAMIC) != (p->flags & F_ANN_DYNAMIC))
d802 1
d815 1
a818 2
		if (!(p->flags & F_LOCAL))
			continue;
d827 1
a827 1
			if (p == p->prefix->active)
d833 1
a833 1
		LIST_REMOVE(p, prefix_l);
d842 3
a844 3
		if (p == p->prefix->active)
			prefix_evaluate(NULL, p->prefix);
		prefix_evaluate(p, p->prefix);
d852 1
a852 1
	struct pt_entry		*pte;
d854 1
a854 1
	pte = p->prefix;
d858 2
a859 2
	if (pt_empty(pte))
		pt_remove(pte);
d874 2
d878 1
a878 2
			if (reloadtime > p->lastchange &&
			    (p->flags & F_ANN_DYNAMIC) == flags) {
d896 1
a896 2
prefix_link(struct prefix *pref, struct pt_entry *pte, struct rde_aspath *asp,
    u_int32_t flags)
d899 2
a900 2
	PREFIX_COUNT(asp, flags, 1);
	PREFIX_COUNT(asp->peer, flags, 1);
d903 3
a905 1
	pref->prefix = pte;
a906 1
	pref->flags = flags;
d909 1
a909 1
	prefix_evaluate(pref, pte);
d918 5
a922 3
	/* make route decision */
	LIST_REMOVE(pref, prefix_l);
	prefix_evaluate(NULL, pref->prefix);
d925 6
a930 2
	PREFIX_COUNT(pref->aspath, pref->flags, -1);
	PREFIX_COUNT(pref->aspath->peer, pref->flags, -1);
d935 1
@


1.97
log
@Track nexthops when the underlying route is changing. Until now true nexthops
were only resolved when they were added. This calls for troubles if something
like ospfd starts to change the underlying routes.
Tested by gollo@@, OK henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.96 2007/06/01 04:17:30 claudio Exp $ */
d107 1
a107 1
				if ((p->flags & flags) == 0) {
d114 1
a114 1
					p->flags |= flags;
d139 1
a139 1
	if (p == NULL || (p->flags & flags) == 0)
d480 2
a481 2
	if (p->flags != flags) {
		if ((p->flags & flags) == 0)
d485 1
a485 1
		p->flags &= ~flags;
d560 2
a561 2
	if (p->flags != flags) {
		p->flags &= ~flags;
d612 7
a618 2
		if (p->aspath->peer == peer && p->flags & flags)
			return (p);
d687 1
a687 1
prefix_network_clean(struct rde_peer *peer, time_t reloadtime)
d697 2
a698 1
			if (reloadtime > p->lastchange) {
@


1.96
log
@Remove a stupid wrapper function that does nothing more then calling another
function with the same arguments.
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.95 2007/05/11 11:27:59 claudio Exp $ */
d619 2
a620 1
prefix_updateall(struct rde_aspath *asp, enum nexthop_state state)
d636 12
d833 1
d842 5
a851 4
	if (nexthop_delete(nh))
		/* nexthop no longer used */
		return;

d884 1
a884 1
		prefix_updateall(asp, nh->state);
@


1.95
log
@Various spelling fixes from Stuart Henderson.
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.94 2007/04/02 12:51:06 claudio Exp $ */
a237 10
void
path_updateall(struct rde_aspath *asp, enum nexthop_state state)
{
	if (rde_noevaluate())
		/* if the decision process is turned off this is a no-op */
		return;

	prefix_updateall(asp, state);
}

d869 1
a869 1
		path_updateall(asp, nh->state);
@


1.94
log
@Typo.
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.93 2007/02/22 08:34:18 henning Exp $ */
d33 1
a33 1
 * Therefor one thing needs to be absolutely avoided, long table walks.
d345 1
a345 1
/* free a unlinked element */
d650 1
a650 1
		 * the active prefix changes it's state. In this case
d779 1
a779 1
 * while in EBGP normaly the address of the router is sent. The exit nexthop
@


1.93
log
@KNF
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.92 2007/01/11 22:00:17 claudio Exp $ */
d295 1
a295 1
 * copy asp to a new UNLINKED one manly for filtering
@


1.92
log
@Correct logic in path_update() so that moves are only done when needed.
Previously prefix changes of neighbors with softreconfig in disabled where
using prefix_add() instead of prefix_move(). Luckily prefix_add() has
additional logic to detect this case and calls prefix_move() itself.
This made backtraces of a totaly different issue so strange that I was
hunting a bug for weeks at the completely wrong spot. Doh!
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.91 2006/12/12 10:34:22 claudio Exp $ */
a92 1
	
d812 1
a812 1
		for(nh = LIST_FIRST(&nexthoptable.nexthop_hashtbl[i]);
@


1.91
log
@Change nexthop_delete() to be more obvious what's going on. No functional
change. OK henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.90 2006/12/12 10:30:33 claudio Exp $ */
d140 1
a140 1
	if (p != NULL && (p->flags & flags) == 0)
@


1.90
log
@Even IPv6 has a prefixlen limit. This ensures that we do not overflow the
struct in6_addr later on. OK henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.89 2006/12/12 10:26:47 claudio Exp $ */
d946 4
d954 2
a955 3
	if (LIST_EMPTY(&nh->path_h)) {
		LIST_REMOVE(nh, nexthop_l);
		rde_send_nexthop(&nh->exit_nexthop, 0);
d957 3
a959 5
		rdemem.nexthop_cnt--;
		free(nh);
		return (1);
	}
	return (0);
@


1.89
log
@In path_remove() remove only local prefixes from the pftable.
OK henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.88 2006/06/01 22:29:47 claudio Exp $ */
d394 2
@


1.88
log
@Copy the pftableid in path_copy and correctly do the ref/unref dance in
path_copy and path_put. Diff from Kevin Brintnall, looks good henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.87 2006/05/28 23:24:15 claudio Exp $ */
d230 3
a232 2
		rde_send_pftable(p->aspath->pftableid,
		    &addr, p->prefix->prefixlen, 1);
@


1.87
log
@Even better nexthop delete behaviour. Do not delete nexthop if they are used
by filter sets or if the nexthop is currently looked up. With this the
"nexthop_update: non-existent nexthop" warning should be history. OK henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.86 2006/05/28 22:07:54 claudio Exp $ */
d315 2
d356 1
@


1.86
log
@Preload and pin nexthop used in filtersets so the are validiated when used.
This will fix problems with set nexthop on outgoing filters. Found by
gluk@@ OK henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.85 2006/04/04 12:03:26 henning Exp $ */
d804 1
d806 7
a812 1
	for (i = 0; i <= nexthoptable.nexthop_hashmask; i++)
d815 1
d828 2
a829 1
		log_warnx("nexthop_update: non-existent nexthop");
d838 4
d934 9
a942 2
	if (nh->refcnt > 0)
		return;
d950 1
d952 1
@


1.85
log
@add "set nexthop self", force nexthop to be set to own address even with IBGP
requested & tested Falk Brockerhoff <fb@@smartterra.de>, and tony sarendal
tested this too. claudio ok
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.84 2006/03/15 15:37:40 claudio Exp $ */
d920 3
@


1.84
log
@In nexthop_compare() if the two passed pointers point to the same object
the odds are better than good that there is no difference.
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.83 2006/01/24 13:34:33 claudio Exp $ */
d881 4
@


1.83
log
@Finally start using the Adj-RIB-In. The most complex part is the modification
of path_update(). There are about 10 different ways how to update a path and
some of them are tricky. Looks good henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.82 2006/01/24 13:00:35 claudio Exp $ */
d955 1
a955 1
	if (na == NULL && nb == NULL)
@


1.82
log
@It is possible that a prefix is part of two RIBs in that case prefix_remove()
needs to be extra careful and only remove the prefix from the specified RIB.
Looks good henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.81 2006/01/24 10:05:24 henning Exp $ */
d88 1
a88 1
    struct bgpd_addr *prefix, int prefixlen)
d91 1
a91 1
	struct prefix		*p;
d93 5
a97 2
	rde_send_pftable(nasp->pftableid, prefix, prefixlen, 0);
	rde_send_pftable_commit();
d99 43
a141 7
	if ((p = prefix_get(peer, prefix, prefixlen, F_LOCAL)) != NULL) {
		if (path_compare(nasp, p->aspath) == 0) {
			/* update last change */
			p->lastchange = time(NULL);
			return;
		}
	}
d149 1
a149 1
		/* path not available, create and link new one */
d154 1
a154 1
	/* if the prefix was found move it else add it to the aspath */
d156 1
a156 1
		prefix_move(asp, p, F_LOCAL);
d158 1
a158 1
		prefix_add(asp, prefix, prefixlen, F_LOCAL);
d656 1
a656 1
/* kill a prefix. Only called by path_remove. */
@


1.81
log
@KNF
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.80 2006/01/20 16:40:17 claudio Exp $ */
d523 16
@


1.80
log
@Proactively fix prefix counters. Currently only F_LOCAL prefixes exist but
as soon as F_ORIGINAL come the counters would no longer be correct and in the
end max-prefix would no longer work. Add additinal counters for F_ORIGINAL
prefixes and bump the correct conter depending on the prefix flags.
OK henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.79 2006/01/20 16:06:12 claudio Exp $ */
d454 1
a454 1
		
@


1.79
log
@Pass flags to prefix_move() so that a prefix that has both F_ORIGINAL and
F_LOCAL set can be moved correctly. This is more like a add as we have one
prefix more afterwards. Looks good henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.78 2006/01/14 22:39:49 claudio Exp $ */
d37 9
d214 2
a215 1
	if (asp->prefix_cnt != 0 || asp->active_cnt != 0)
d435 1
a435 1
	asp->prefix_cnt++;
d452 1
a452 1
		p->aspath->prefix_cnt--;
d482 1
a482 1
	oasp->prefix_cnt--;
d651 2
a652 2
	asp->prefix_cnt++;
	asp->peer->prefix_cnt++;
d674 2
a675 2
	pref->aspath->prefix_cnt--;
	pref->aspath->peer->prefix_cnt--;
@


1.78
log
@Small step in supporting the Adj-RIB-In additionaly to the Local-RIB.
First step is to define two flags F_LOCAL and F_ORIGINAL. These flags
are used to distinguish prefix in the Local-RIB and those in the Adj-
RIB-In. Adapt prefix API and add additional checks so that no Adj-RIB-
In prefixes get mistakenly selected. Currently no F_ORIGINAL prefixes
are created but this may change soon. Looks good Henning.
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.77 2006/01/12 14:05:13 claudio Exp $ */
d108 1
a108 1
		prefix_move(asp, p);
d396 1
a396 1
			return (prefix_move(asp, p));
d407 1
a407 1
prefix_move(struct rde_aspath *asp, struct prefix *p)
d421 1
a421 1
	np->flags = p->flags;
d432 27
d484 1
a484 1
	return np->prefix;
@


1.77
log
@Copy AS path in rde_filter() on demand instead of doing it before calling
rde_filter(). Adapt path_update() to this change too. path_update() does
a path_copy before linking the rde_aspath into the RIB. Looks good Henning.
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.76 2006/01/09 16:00:48 claudio Exp $ */
d87 1
a87 1
	if ((p = prefix_get(peer, prefix, prefixlen)) != NULL) {
d110 1
a110 1
		prefix_add(asp, prefix, prefixlen);
d316 1
a316 1
			     struct rde_aspath *);
d363 2
a364 1
prefix_get(struct rde_peer *peer, struct bgpd_addr *prefix, int prefixlen)
d371 1
a371 1
	return (prefix_bypeer(pte, peer));
d378 2
a379 1
prefix_add(struct rde_aspath *asp, struct bgpd_addr *prefix, int prefixlen)
a383 1
	int		 needlink = 0;
d389 1
a389 1
	p = prefix_bypeer(pte, asp->peer);
a390 1
		needlink = 1;
d392 2
a393 5
	}

	if (needlink == 1)
		prefix_link(p, pte, asp);
	else {
d396 1
a396 1
			return prefix_move(asp, p);
d400 1
a400 1
	return pte;
d421 1
d465 2
a466 1
prefix_remove(struct rde_peer *peer, struct bgpd_addr *prefix, int prefixlen)
d476 1
a476 1
	p = prefix_bypeer(pte, peer);
d482 5
a486 2
	rde_send_pftable(asp->pftableid, prefix, prefixlen, 1);
	rde_send_pftable_commit();
d520 1
a520 1
prefix_bypeer(struct pt_entry *pte, struct rde_peer *peer)
d525 1
a525 1
		if (p->aspath->peer == peer)
d541 7
d610 2
a611 1
prefix_link(struct prefix *pref, struct pt_entry *pte, struct rde_aspath *asp)
d620 1
@


1.76
log
@Ups. Inverse logic.
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.75 2006/01/05 17:33:40 claudio Exp $ */
a88 2
			/* already registered */
			path_put(nasp);
d101 4
a104 6
		/* path not available, link new */
		path_link(nasp, peer);
		asp = nasp;
	} else
		/* path found, new aspath no longer needed */
		path_put(nasp);
d298 3
@


1.75
log
@Kill ENSURE(), remove ensure.h, say bye bye to fatal_ensure() and
one hip hip hooray from Henning.
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.74 2006/01/05 16:00:07 claudio Exp $ */
d209 1
a209 1
	if (asp->prefix_cnt == 0 && asp->active_cnt == 0)
@


1.74
log
@Cache optional BGP attributes (mostly communities) and use a simple
pointer plus a ref counter to link the attributes to the path object.
Saves +/- 10M on 11 full feeds. Looks good Henning
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.73 2006/01/04 16:13:07 claudio Exp $ */
a26 1
#include "ensure.h"
d209 2
a210 2
	ENSURE(path_empty(asp));
	ENSURE(asp->prefix_cnt == 0 && asp->active_cnt == 0);
d416 2
a417 1
	ENSURE(asp->peer == p->aspath->peer);
d525 1
a525 1
			return p;
d527 1
a527 1
	return NULL;
a603 4
	ENSURE(pref->aspath == NULL &&
	    pref->prefix == NULL);
	ENSURE(prefix_bypeer(pte, asp->peer) == NULL);

a656 2
	ENSURE(pref->aspath == NULL &&
	    pref->prefix == NULL);
@


1.73
log
@Fix a mem leak of the unusual kind. In some cases a new aspath was added
to the RIB without checking if there was a equal path already available.
Modify path_update() so that we do not link a new aspath without calling
path_lookup() before to check if the aspath is not already in the RIB.
Found via bgpctl show rib mem. OK henning
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.72 2006/01/03 22:49:17 claudio Exp $ */
a120 1
	struct attr	*oa, *ob;
d160 1
a160 22
	for (oa = TAILQ_FIRST(&a->others), ob = TAILQ_FIRST(&b->others);
	    oa != NULL && ob != NULL;
	    oa = TAILQ_NEXT(oa, entry), ob = TAILQ_NEXT(ob, entry)) {
		if (oa->type > ob->type)
			return (1);
		if (oa->type < ob->type)
			return (-1);
		if (oa->len > ob->len)
			return (1);
		if (oa->len < ob->len)
			return (-1);
		r = memcmp(oa->data, ob->data, oa->len);
		if (r > 0)
			return (1);
		if (r < 0)
			return (-1);
	}
	if (oa != NULL)
		return (1);
	if (ob != NULL)
		return (-1);
	return (0);
d273 1
a273 3

	TAILQ_INIT(&nasp->others);
	attr_optcopy(nasp, asp);
a289 1
	TAILQ_INIT(&asp->others);
d308 1
a308 1
	attr_optfree(asp);
@


1.72
log
@Track some (memory) statistics in the RDE. Accessible via bgpctl.
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.71 2005/12/30 14:07:40 claudio Exp $ */
d89 1
a89 5
		if (path_compare(nasp, p->aspath) != 0) {
			/* non equal path attributes create new path */
			path_link(nasp, peer);
			prefix_move(nasp, p);
		} else {
d94 1
d96 9
a104 2
	} else if ((asp = path_lookup(nasp, peer)) == NULL) {
		/* path not available */
d106 9
a114 3
		prefix_add(nasp, prefix, prefixlen);
	} else {
		/* path found, just add prefix */
a115 2
		path_put(nasp);
	}
d194 1
a194 2
		if (path_compare(aspath, asp) == 0 &&
		    peer == asp->peer)
@


1.71
log
@Use sys/hash.h instead of own built functions that work similar.
While there reorder some structs to help with alignment.
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.70 2005/11/29 21:11:07 claudio Exp $ */
d275 1
a275 1
	if (nasp->aspath != NULL)
d277 2
d304 2
d327 1
d671 1
d681 1
d843 1
d858 1
@


1.70
log
@Add a flags field to struct prefix which will be used shortly. Remove the peer
pointer so that the size does not grow. Adding 4 bytes to struct prefix would
result in 64MB more memory usage on one of my systems.
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.69 2005/07/29 12:38:40 claudio Exp $ */
d21 1
d46 1
a46 1
	&pathtable.path_hashtbl[aspath_hash((x)->data, (x)->len) & \
d912 1
a912 1
	u_int32_t	 i, h = 0;
d921 2
a922 4
		h = 8271;
		for (i = 0; i < sizeof(struct in6_addr); i++)
			h = ((h << 5) + h) ^ nexthop->v6.s6_addr[i];
		h &= nexthoptable.nexthop_hashmask;
@


1.69
log
@Add another piece to the IPv6 puzzle. This time code to generate MP updates.
Does not affect IPv4 minimaly tested for IPv6 because we still don't have an
IPv6 capable neighbor. henning@@ ya
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.68 2005/07/01 09:19:24 claudio Exp $ */
d429 1
a429 1
	ENSURE(asp->peer == p->peer);
a435 1
	np->peer = p->peer;
d536 1
a536 1
		if (p->peer == peer)
a625 1
	pref->peer = asp->peer;
d644 1
a644 1
	pref->peer->prefix_cnt--;
@


1.68
log
@Make the pftable filter set use the name2id "cache" like the route labels.
This saves 14 bytes per aspath. OK henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.67 2005/06/29 09:43:26 claudio Exp $ */
d679 3
a681 1
/* nexthop functions */
d753 15
a767 3
	nh->nexthop_netlen = msg->kr.kr4.prefixlen;
	nh->nexthop_net.af = AF_INET;
	nh->nexthop_net.v4.s_addr = msg->kr.kr4.prefix.s_addr;
@


1.67
log
@rtlabel support via filter sets. Just use "set rtlabel foobar" in filters
network and neighbor statements and the routes are labeled accordingly.
While doing that fix some mem-leaks by introducing filterset_free() and
remove the free on send option of send_filterset().
This took a bit longer because we need to carefully track the rtlabel id
refcnts or bad things may happen on reloads.
henning@@ looks fine
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.66 2005/04/12 14:32:01 claudio Exp $ */
d84 1
a84 1
	rde_send_pftable(nasp->pftable, prefix, prefixlen, 0);
d139 4
d144 1
a144 3
	r = strcmp(a->pftable, b->pftable);
	if (r == 0)
		r = aspath_compare(a->aspath, b->aspath);
d201 1
a201 1
		rde_send_pftable(p->aspath->pftable,
d497 1
a497 1
	rde_send_pftable(asp->pftable, prefix, prefixlen, 1);
@


1.66
log
@Introduce a per prefix weight.  The weight is used to tip prefixes with equal
long AS pathes in one or the other direction.  It weights a prefix at a very
late stage in the decision process. This is a nice bgpd feature to traffic
engineer networks where most AS pathes are equally long.
OK henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.65 2005/03/26 12:46:52 claudio Exp $ */
d135 4
d279 2
d305 1
d317 1
@


1.65
log
@Move the path_empty()/path_destroy() check out of the inner for-loop.
Makes the code more obvious. Idea from tedu@@ OK henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.64 2005/03/11 12:54:20 claudio Exp $ */
d131 4
d273 1
d298 1
@


1.64
log
@Finally commit the transparent-as and nexthop no-modify stuff I wrote on the
way to FOSDEM. With transparent-as set to ye bgpd will not prepend his own
AS for sent updates. NB the neighbor needs to set "enforce neighbor-as no"
or it will not like the received AS paths. With set nexthop no-modify bgpd
will change the nexthop as done normaly.
OK henning@@ man page update with help of jmc@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.63 2004/11/23 13:07:01 claudio Exp $ */
a587 2
				if (path_empty(asp))
					path_destroy(asp);
d590 2
@


1.63
log
@Switch from a single filter_set to a linked list of sets. With this change
it is possible to specify multiple communities. This is also the first step
to better bgpd filters. OK henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.62 2004/11/19 09:59:27 claudio Exp $ */
d763 4
@


1.62
log
@Only unlink and link the asp in nexthop_modify if the asp is linked.
OK henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.61 2004/11/10 16:12:11 claudio Exp $ */
d752 2
a753 2
nexthop_modify(struct rde_aspath *asp, struct bgpd_addr *nexthop, int flags,
    sa_family_t af)
d757 1
a757 1
	if (flags & SET_NEXTHOP_REJECT)
d759 3
a761 1
	if (flags & SET_NEXTHOP_BLACKHOLE)
d763 3
a765 2
	if (!(flags & SET_NEXTHOP) ||
	    af != nexthop->af)
@


1.61
log
@prefix_write() works also for IPv6. OK henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.60 2004/11/10 12:41:58 claudio Exp $ */
d250 1
a251 2

	nexthop_link(asp);
d766 2
a767 1
	nexthop_unlink(asp);
d769 2
a770 1
	nexthop_link(asp);
@


1.60
log
@Remove no longer needed code. OK henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.59 2004/08/17 15:39:36 claudio Exp $ */
d500 1
a500 1
	if (prefix->af != AF_INET)
@


1.59
log
@Always update prefix timestamp even if nothing has changed. Without this
networks disappear after reload. OK henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.58 2004/08/13 14:03:20 claudio Exp $ */
a728 3
		if (!(nh->flags & NEXTHOP_LINKLOCAL))
			/* use linklocal address if provided */
			nh->true_nexthop = nh->exit_nexthop;
d730 5
a734 4
	} else {
		nh->true_nexthop = msg->gateway;
		nh->flags &= ~NEXTHOP_LINKLOCAL;
	}
@


1.58
log
@Fix minor issues with IPv6 dumps and add a function for dumping the RIB table
protocol independent. This new dump format is not (yet) supported by the
mrtd route_btoa tool. OK henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.57 2004/08/12 10:24:16 claudio Exp $ */
d95 2
@


1.57
log
@Just ignore RFC2545 and the silly idea of using link local addresses as
nexthop. This makes the code a lot simpler. OK henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.56 2004/08/10 13:02:08 claudio Exp $ */
d490 18
@


1.56
log
@switch nexthop in struct filter_set form struct in_addr to struct bgpd_addr
OK henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.55 2004/08/06 12:04:08 claudio Exp $ */
d748 1
a748 1
	nh = nexthop_get(nexthop, NULL);
d779 1
a779 5
		if (nh->flags & NEXTHOP_LINKLOCAL)
			rde_send_nexthop(&nh->exit_nexthop,
			    &nh->true_nexthop, 0);
		else
			rde_send_nexthop(&nh->exit_nexthop, NULL, 0);
d786 1
a786 1
nexthop_get(struct bgpd_addr *nexthop, struct bgpd_addr *ll)
a798 16
		if (ll) {
			/*
			 * The link local address should be used as nexthop
			 * if available but acctualy it does not care.
			 * There is only one link local address per nexthop
			 * if any. Therefor the key is still the nexthop.
			 */
			/*
			 * XXX unsure if this is the correct way. BTW.
			 * For link local address the scope is needed.
			 * I think we should use some nice hack with the kroute
			 * code and the nexthop updates to fix that.
			 */
			memcpy(&nh->true_nexthop, ll, sizeof(struct bgpd_addr));
			nh->flags |= NEXTHOP_LINKLOCAL;
		}
d802 1
a802 5
		if (nh->flags & NEXTHOP_LINKLOCAL)
			rde_send_nexthop(&nh->exit_nexthop,
			    &nh->true_nexthop, 1);
		else
			rde_send_nexthop(&nh->exit_nexthop, NULL, 1);
@


1.55
log
@Monster diff to get one step closer to IPv6 support.
Cleanup path attribute handling. First of all kill struct attr_flags, all
those infos are now in struct rde_aspath. Second move attribute parser
functions into rde.c, rde_attr.c is shared between bgpd and bgpctl.
Third reimplementation of the nexthop handling. Make it IPv6 ready and
fix some major bug relating to "set nexthop".
henning@@ OK if it breaks nothing
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.54 2004/08/05 19:23:10 claudio Exp $ */
d735 2
a736 1
nexthop_modify(struct rde_aspath *asp, struct bgpd_addr *nexthop, int flags)
d744 2
a745 1
	if (!(flags & SET_NEXTHOP))
d747 1
@


1.54
log
@Get rid of some statistics stuff that is no longer needed but helped in the
beginning. OK henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.53 2004/08/05 18:44:19 claudio Exp $ */
a39 3
static void	path_unlink(struct rde_aspath *);
static struct rde_aspath	*path_alloc(void);
static void	path_free(struct rde_aspath *);
d43 1
d78 1
a78 1
path_update(struct rde_peer *peer, struct attr_flags *attrs,
a82 1
	struct pt_entry		*pte;
d84 1
a84 1
	rde_send_pftable(attrs->pftable, prefix, prefixlen, 0);
d87 10
a96 1
	if ((asp = path_get(attrs->aspath, peer)) == NULL) {
d98 2
a99 2
		asp = path_add(peer, attrs);
		pte = prefix_add(asp, prefix, prefixlen);
d101 3
a103 14
		if (attr_compare(&asp->flags, attrs) == 0) {
			/* path are equal, just add prefix */
			pte = prefix_add(asp, prefix, prefixlen);
			attr_free(attrs);
		} else {
			/* non equal path attributes create new path */
			if ((p = prefix_get(asp, prefix, prefixlen)) == NULL) {
				asp = path_add(peer, attrs);
				pte = prefix_add(asp, prefix, prefixlen);
			} else {
				asp = path_add(peer, attrs);
				pte = prefix_move(asp, p);
			}
		}
d107 57
d165 1
a165 1
path_get(struct aspath *aspath, struct rde_peer *peer)
d170 1
a170 1
	head = PATH_HASH(aspath);
d173 1
a173 1
		if (aspath_compare(asp->flags.aspath, aspath) == 0 &&
d175 1
a175 1
			return asp;
d177 1
a177 14
	return NULL;
}

struct rde_aspath *
path_add(struct rde_peer *peer, struct attr_flags *attr)
{
	struct rde_aspath	*asp;

	asp = path_alloc();

	attr_move(&asp->flags, attr);

	path_link(asp, peer);
	return asp;
d189 1
a189 1
		rde_send_pftable(p->aspath->flags.pftable,
d213 8
d222 1
a222 2
	path_unlink(asp);
	path_free(asp);
d243 1
a243 1
	head = PATH_HASH(asp->flags.aspath);
d248 1
d250 1
a250 1
	nexthop_add(asp);
d253 5
a257 2
static void
path_unlink(struct rde_aspath *asp)
d259 12
a270 2
	ENSURE(path_empty(asp));
	ENSURE(asp->prefix_cnt == 0 && asp->active_cnt == 0);
d272 2
a273 5
	nexthop_remove(asp);
	LIST_REMOVE(asp, path_l);
	LIST_REMOVE(asp, peer_l);
	asp->peer = NULL;
	asp->nexthop = NULL;
d275 1
a275 1
	attr_free(&asp->flags);
d279 2
a280 2
static struct rde_aspath *
path_alloc(void)
d288 6
a293 1
	return asp;
d297 2
a298 2
static void
path_free(struct rde_aspath *asp)
d300 5
a304 3
	ENSURE(asp->peer == NULL &&
	    asp->flags.aspath == NULL &&
	    TAILQ_EMPTY(&asp->flags.others));
d357 1
a357 1
 * search in the path list for specified prefix. Returns NULL if not found.
d360 1
a360 1
prefix_get(struct rde_aspath *asp, struct bgpd_addr *prefix, int prefixlen)
d362 1
a362 2
	struct prefix	*p;
	struct bgpd_addr addr;
d364 4
a367 12
	LIST_FOREACH(p, &asp->prefix_h, path_l) {
		ENSURE(p->prefix != NULL);
		if (p->prefix->prefixlen != prefixlen)
			continue;
		pt_getaddr(p->prefix, &addr);
		if (!prefix_compare(&addr, prefix, prefixlen)) {
			ENSURE(p->aspath == asp);
			return p;
		}
	}

	return NULL;
d382 1
a382 1
	if (pte == NULL) {
d384 1
a384 1
	}
d480 1
a480 1
	rde_send_pftable(asp->flags.pftable, prefix, prefixlen, 1);
d645 2
a646 14

/*
 * XXX
 * Storing the nexthop info in a hash table is not optimal. The problem is
 * that updates (invalidate and validate) come in as prefixes and so storing
 * the nexthops in a hash is not optimal. An (in)validate needs to do a table
 * walk to find all candidates.
 * Currently I think that there are many more adds and removes so that a
 * hash table has more benefits and the table walk should not happen too often.
 */

static struct nexthop	*nexthop_get(struct in_addr);
static struct nexthop	*nexthop_alloc(void);
static void		 nexthop_free(struct nexthop *);
d658 2
a659 2
	LIST_HEAD(, nexthop)	*nexthop_hashtbl;
	u_int32_t		 nexthop_hashmask;
a661 4
#define NEXTHOP_HASH(x)						\
	&nexthoptable.nexthop_hashtbl[ntohl((x.s_addr)) &	\
	    nexthoptable.nexthop_hashmask]

a664 1
	struct nexthop	*nh;
a676 17

	/* add dummy entry for connected networks */
	nh = nexthop_alloc();
	nh->state = NEXTHOP_REACH;
	nh->exit_nexthop.af = AF_INET;
	nh->exit_nexthop.v4.s_addr = INADDR_ANY;

	LIST_INSERT_HEAD(NEXTHOP_HASH(nh->exit_nexthop.v4), nh,
	    nexthop_l);

	memcpy(&nh->true_nexthop, &nh->exit_nexthop,
	    sizeof(nh->true_nexthop));
	nh->nexthop_netlen = 0;
	nh->nexthop_net.af = AF_INET;
	nh->nexthop_net.v4.s_addr = INADDR_ANY;

	nh->flags = NEXTHOP_ANNOUNCE;
d682 1
a682 13
	struct in_addr	 addr;
	struct nexthop	*nh;
	u_int32_t	 i;

	/* remove the dummy entry for connected networks */
	addr.s_addr = INADDR_ANY;
	nh = nexthop_get(addr);
	if (nh != NULL) {
		if (!LIST_EMPTY(&nh->path_h))
			log_warnx("nexthop_free: free non-free announce node");
		LIST_REMOVE(nh, nexthop_l);
		nexthop_free(nh);
	}
d686 1
a686 1
			log_warnx("nexthop_free: free non-free table");
d692 1
a692 1
nexthop_add(struct rde_aspath *asp)
d694 2
a695 1
	struct nexthop	*nh;
d697 1
a697 2
	if ((nh = asp->nexthop) == NULL)
		nh = nexthop_get(asp->flags.nexthop);
d699 32
a730 7
		nh = nexthop_alloc();
		nh->state = NEXTHOP_LOOKUP;
		nh->exit_nexthop.af = AF_INET;
		nh->exit_nexthop.v4 = asp->flags.nexthop;
		LIST_INSERT_HEAD(NEXTHOP_HASH(asp->flags.nexthop), nh,
		    nexthop_l);
		rde_send_nexthop(&nh->exit_nexthop, 1);
d732 15
d748 1
a748 1
	LIST_INSERT_HEAD(&nh->path_h, asp, nexthop_l);
d752 10
a761 1
nexthop_remove(struct rde_aspath *asp)
d765 3
d772 1
a772 4

	/* never remove the dummy announce entry */
	if (nh->flags & NEXTHOP_ANNOUNCE)
		return;
d776 7
a782 2
		rde_send_nexthop(&nh->exit_nexthop, 0);
		nexthop_free(nh);
d786 2
a787 2
static struct nexthop *
nexthop_get(struct in_addr nexthop)
d791 5
a795 6
	LIST_FOREACH(nh, NEXTHOP_HASH(nexthop), nexthop_l) {
		if (nh->exit_nexthop.v4.s_addr == nexthop.s_addr)
			return nh;
	}
	return NULL;
}
d797 21
a817 5
void
nexthop_update(struct kroute_nexthop *msg)
{
	struct nexthop		*nh;
	struct rde_aspath	*asp;
d819 5
a823 11
	nh = nexthop_get(msg->nexthop.v4);
	if (nh == NULL) {
		log_warnx("nexthop_update: non-existent nexthop");
		return;
	}
	/* should I trust in the parent ??? */
	if (nh->exit_nexthop.af != msg->nexthop.af ||
	    (nh->exit_nexthop.af == AF_INET &&
	    nh->exit_nexthop.v4.s_addr != msg->nexthop.v4.s_addr)) {
		log_warnx("nexthop_update: bad nexthop returned");
		return;
d826 2
a827 4
	if (msg->valid)
		nh->state = NEXTHOP_REACH;
	else
		nh->state = NEXTHOP_UNREACH;
d829 4
a832 6
	if (msg->connected)
		memcpy(&nh->true_nexthop, &nh->exit_nexthop,
		    sizeof(nh->true_nexthop));
	else
		memcpy(&nh->true_nexthop, &msg->gateway,
		    sizeof(nh->true_nexthop));
d834 6
a839 3
	nh->nexthop_netlen = msg->kr.kr4.prefixlen;
	nh->nexthop_net.af = AF_INET;
	nh->nexthop_net.v4.s_addr = msg->kr.kr4.prefix.s_addr;
d841 2
a842 2
	if (msg->connected)
		nh->flags |= NEXTHOP_CONNECTED;
d844 2
a845 6
	if (rde_noevaluate())
		/*
		 * if the decision process is turned off there is no need
		 * for the aspath list walk.
		 */
		return;
d847 11
a857 2
	LIST_FOREACH(asp, &nh->path_h, nexthop_l) {
		path_updateall(asp, nh->state);
d859 1
d862 2
a863 2
static struct nexthop *
nexthop_alloc(void)
d865 1
a865 1
	struct nexthop *nh;
d867 6
a872 5
	nh = calloc(1, sizeof(*nh));
	if (nh == NULL)
		fatal("nexthop_alloc");
	LIST_INIT(&nh->path_h);
	return nh;
d875 2
a876 2
static void
nexthop_free(struct nexthop *nh)
d878 1
a878 1
	ENSURE(LIST_EMPTY(&nh->path_h));
d880 16
a895 1
	free(nh);
@


1.53
log
@Cleanup aspath specific functions and api. Mainly switch to a refcnt based
allocation. This helps to save a bit of RAM. looks good henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.52 2004/08/05 16:26:56 claudio Exp $ */
a36 29
struct rib_stats {
	u_int64_t	path_update;
	u_int64_t	path_get;
	u_int64_t	path_add;
	u_int64_t	path_remove;
	u_int64_t	path_updateall;
	u_int64_t	path_destroy;
	u_int64_t	path_link;
	u_int64_t	path_unlink;
	u_int64_t	path_alloc;
	u_int64_t	path_free;
	u_int64_t	prefix_get;
	u_int64_t	prefix_add;
	u_int64_t	prefix_move;
	u_int64_t	prefix_remove;
	u_int64_t	prefix_updateall;
	u_int64_t	prefix_link;
	u_int64_t	prefix_unlink;
	u_int64_t	prefix_alloc;
	u_int64_t	prefix_free;
	u_int64_t	nexthop_add;
	u_int64_t	nexthop_remove;
	u_int64_t	nexthop_update;
	u_int64_t	nexthop_get;
	u_int64_t	nexthop_alloc;
	u_int64_t	nexthop_free;
} ribstats;
#define RIB_STAT(x)	(ribstats.x++)

a86 2
	RIB_STAT(path_update);

a117 2
	RIB_STAT(path_get);

a132 2
	RIB_STAT(path_add);

a146 2
	RIB_STAT(path_remove);

a160 2
	RIB_STAT(path_updateall);

a171 1
	RIB_STAT(path_destroy);
a196 2
	RIB_STAT(path_link);

a208 1
	RIB_STAT(path_unlink);
a226 2
	RIB_STAT(path_alloc);

a237 1
	RIB_STAT(path_free);
a300 2
	RIB_STAT(prefix_get);

a325 2
	RIB_STAT(prefix_add);

a356 1
	RIB_STAT(prefix_move);
a414 2
	RIB_STAT(prefix_remove);

a457 2
	RIB_STAT(prefix_updateall);

a526 1
	RIB_STAT(prefix_link);
a549 2
	RIB_STAT(prefix_unlink);

a573 2
	RIB_STAT(prefix_alloc);

a583 1
	RIB_STAT(prefix_free);
a686 2
	RIB_STAT(nexthop_add);

a706 2
	RIB_STAT(nexthop_remove);

a727 2
	RIB_STAT(nexthop_get);

a740 2
	RIB_STAT(nexthop_update);

a789 2
	RIB_STAT(nexthop_alloc);

a799 1
	RIB_STAT(nexthop_free);
@


1.52
log
@struct prefix has a pointer to the peer so use it everywhere directly instead
of the detour via aspath.
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.51 2004/08/05 15:58:21 claudio Exp $ */
d76 2
a77 1
	&pathtable.path_hashtbl[aspath_hash((x)) & pathtable.path_hashmask]
@


1.51
log
@rename and move prefix_equal() to prefix_compare() which returns -1, 0, 1
similar to memcmp() and all other compare functions in bgpd. OK henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.50 2004/07/05 02:13:44 henning Exp $ */
d407 1
a407 1
	ENSURE(asp->peer == p->aspath->peer);
d499 1
a499 1
		if (p->aspath->peer == peer)
d613 1
a613 1
	pref->aspath->peer->prefix_cnt--;
@


1.50
log
@fix a few KNF fallouts
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.49 2004/06/22 23:17:01 claudio Exp $ */
d297 40
d353 1
a353 1
		if (prefix_equal(&addr, prefix, prefixlen)) {
@


1.49
log
@Cleanup. jajaja henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.48 2004/06/22 20:28:58 claudio Exp $ */
d777 1
a777 1
	    nh->exit_nexthop.v4.s_addr != msg->nexthop.v4.s_addr)) { 
@


1.48
log
@Make the RDE IPv6 ready missing is the message handling. The internal
prefix tree changed form a hash table to a per AF RB tree.
OK henning@@ some ideas are from Brent Graveland.
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.47 2004/06/22 07:22:31 henning Exp $ */
a150 1
	ENSURE(head != NULL);
a165 1
	ENSURE(peer != NULL);
a220 2
	ENSURE(asp != NULL);

a238 1
	ENSURE(head != NULL);
a243 1
	ENSURE(asp->nexthop == NULL);
a306 1
	ENSURE(asp != NULL);
a398 2
	ENSURE(oasp->prefix_cnt > 0);
	ENSURE(oasp->peer->prefix_cnt > 0);
a457 2
	ENSURE(pte != NULL);

a470 1
	ENSURE(asp != NULL);
a543 1
	ENSURE(pref != NULL && pte != NULL && asp != NULL);
a565 2
	ENSURE(pref != NULL);
	ENSURE(pref->prefix != NULL && pref->aspath != NULL);
a571 2
	ENSURE(pref->aspath->prefix_cnt > 0);
	ENSURE(pref->aspath->peer->prefix_cnt > 0);
a707 1
	ENSURE(asp != NULL);
a729 1
	ENSURE(asp != NULL);
d774 7
a780 1
	ENSURE(nh->exit_nexthop.v4.s_addr == msg->nexthop.v4.s_addr);
@


1.47
log
@introduce kroute6, which will be used to build a seperate v6 table
(smashing them into the v4 table would raise the memory requirements far too
much), and make kroute_nexthop (where we are not under such memory pressure,
you don't have a hundred thousand nexthops) v4/v6. change existing callers
to use the v4 part, claudio ok
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.46 2004/05/08 19:17:20 henning Exp $ */
d181 1
d187 1
d189 1
a189 1
		    &p->prefix->prefix, p->prefix->prefixlen, 1);
d310 1
d317 4
a320 2
		if (p->prefix->prefixlen == prefixlen &&
		    p->prefix->prefix.v4.s_addr == prefix->v4.s_addr) {
@


1.46
log
@KNF
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.45 2004/05/07 10:06:15 djm Exp $ */
d802 1
a802 1
	nh->nexthop_netlen = msg->kr.prefixlen;
d804 1
a804 1
	nh->nexthop_net.v4.s_addr = msg->kr.prefix.s_addr;
@


1.45
log
@add a filter option to dump prefixes learned in UPDATEs into a PF table,
intended for building realtime BGP blacklists (e.g. with spamd);
ok claudio & henning
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.44 2004/04/30 18:42:05 henning Exp $ */
d443 1
a443 1
    
@


1.44
log
@remove MAX_PREFIX_PER_AS debug gunk, claudio djm ok
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.43 2004/04/28 07:05:27 claudio Exp $ */
d117 3
d185 4
d440 4
@


1.43
log
@Pointer that are used later in the code should be initalized. Fixes a crash
noticed by Henning. OK henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.42 2004/03/11 14:22:23 claudio Exp $ */
a65 7
/*
 * Maximum number of prefixes we allow per prefix. The number should
 * not be too big and ensure only that the prefix count is properly
 * increased and decreased. Only useful if ENSURE is active.
 */
#define MAX_PREFIX_PER_AS 1500

a378 2
	/* XXX for debugging */
	ENSURE(asp->prefix_cnt < MAX_PREFIX_PER_AS);
a545 3

	/* XXX for debugging */
	ENSURE(asp->prefix_cnt < MAX_PREFIX_PER_AS);
@


1.42
log
@Shutdown the RDE cleanly on exit. Plug some memleaks. OK henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.41 2004/03/05 22:21:32 claudio Exp $ */
d376 1
d561 1
@


1.41
log
@Plug some memory leaks in rde. Based on a patch by Patrick Latifi.
Added attr_move() so that we can copy the attribute before calling the filter.
path_update() will now use the passed attribute so it can't be simply reused.
OK henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.40 2004/03/01 16:02:01 claudio Exp $ */
d103 12
d199 4
d690 24
d807 7
@


1.40
log
@Make it possible to diable the decision process. This is a feature only useful
for route-collectors. OK henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.39 2004/02/27 20:53:56 claudio Exp $ */
d120 1
d163 1
a163 1
	attr_copy(&asp->flags, attr);
@


1.39
log
@remove unneded peer pointer in struct prefix and change a in_addr_t to
struct in_addr. OK henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.38 2004/02/27 14:46:09 claudio Exp $ */
d458 4
@


1.38
log
@Cleanup no functional changes. OK henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.37 2004/02/27 14:43:18 claudio Exp $ */
d352 1
a352 1
	ENSURE(asp->peer == p->peer);
a358 1
	np->peer = p->peer;
a392 1
	p->peer = NULL;
d445 1
a445 1
		if (p->peer == peer)
d526 1
a526 2
	    pref->prefix == NULL &&
	    pref->peer == NULL);
a538 1
	pref->peer = asp->peer;
a567 1
	pref->peer = NULL;
d595 1
a595 2
	    pref->prefix == NULL &&
	    pref->peer == NULL);
d611 1
a611 1
static struct nexthop	*nexthop_get(in_addr_t);
d629 2
a630 2
#define NEXTHOP_HASH(x)					\
	&nexthoptable.nexthop_hashtbl[ntohl((x)) &	\
d656 1
a656 1
	LIST_INSERT_HEAD(NEXTHOP_HASH(nh->exit_nexthop.v4.s_addr), nh,
d682 1
a682 1
		nh->exit_nexthop.v4.s_addr = asp->flags.nexthop;
d716 1
a716 1
nexthop_get(in_addr_t nexthop)
d723 1
a723 1
		if (nh->exit_nexthop.v4.s_addr == nexthop)
d737 1
a737 1
	nh = nexthop_get(msg->nexthop.v4.s_addr);
@


1.37
log
@It is possible to end up in prefix_add with a prefix that needs to be moved.
This caused troubles with show rib because of an ENSURE.  OK henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.36 2004/02/26 16:16:41 claudio Exp $ */
d117 1
a117 1
		if (attr_compare(&asp->flags, attrs) == 0)
d120 1
a120 1
		else {
d122 1
a122 2
			if ((p = prefix_get(asp,
			    prefix, prefixlen)) == NULL) {
d171 1
a171 1
	struct prefix	*p, *np;
d175 1
a175 2
	for (p = LIST_FIRST(&asp->prefix_h); p != NULL; p = np) {
		np = LIST_NEXT(p, path_l);
a177 1
	LIST_INIT(&asp->prefix_h);
d308 1
a308 2
 * Adds or updates a prefix. Returns 1 if a new routing decision needs
 * to be done -- which is actually always.
d381 1
a381 1
	prefix_evaluate(np, p->prefix);
d399 1
a399 1
		path_destroy(oasp); /* XXX probably use path_remove */
d432 1
a432 1
		path_destroy(asp); /* XXX probably use path_remove */
@


1.36
log
@show rib infrastructure. At least full dumps and per as dumps. Per prefix
dump need some more work. OK henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.35 2004/02/19 23:07:00 claudio Exp $ */
d336 4
a339 1
	else
d341 1
@


1.35
log
@Add support for basic filters. Nothing optimized and it has some issues but
this is a huge step forward. OK henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.34 2004/02/19 13:54:58 claudio Exp $ */
d80 1
a80 4
struct path_table {
	struct aspath_head	*path_hashtbl;
	u_int32_t		 path_hashmask;
} pathtable;
@


1.34
log
@Make the code more portable. Add some missing header files and make the use
of the queue(3) makros more portable. OK henning@@ some time ago.
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.33 2004/02/09 01:56:18 henning Exp $ */
d253 1
a253 4
	/* free the aspath and all other path attributes */
	aspath_destroy(asp->flags.aspath);
	asp->flags.aspath = NULL;
	attr_optfree(&asp->flags);
@


1.33
log
@replace a bunch of u_long by u_int32_t
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.32 2004/02/04 09:18:03 claudio Exp $ */
d179 1
a179 3
	for (p = LIST_FIRST(&asp->prefix_h);
	    p != LIST_END(&asp->prefix_h);
	    p = np) {
a488 1
	struct rde_aspath	*asp;
a489 1
	asp = p->aspath;
d508 1
a508 3
	for (asp = LIST_FIRST(&peer->path_h);
	    asp != LIST_END(&peer->path_h);
	    asp = xasp) {
d510 1
a510 3
		for (p = LIST_FIRST(&asp->prefix_h);
		    p != LIST_END(&asp->prefix_h);
		    p = xp) {
@


1.32
log
@Move BGP path attribute handling functions in a own file. henning@@ conceptual ok
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.31 2004/02/02 19:14:11 deraadt Exp $ */
d82 1
a82 1
	u_long			 path_hashmask;
d89 1
a89 1
path_init(u_long hashsize)
d91 1
a91 1
	u_long	hs, i;
d646 1
a646 1
	u_long			 nexthop_hashmask;
d654 1
a654 1
nexthop_init(u_long hashsize)
d657 1
a657 1
	u_long		 hs, i;
@


1.31
log
@spaces
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.30 2004/02/02 18:56:25 claudio Exp $ */
a20 3
#include <sys/socket.h>
#include <netinet/in.h>
#include <arpa/inet.h>
a21 1
#include <errno.h>
a37 3
	u_int64_t	attr_copy;
	u_int64_t	aspath_create;
	u_int64_t	aspath_destroy;
a72 414
/* attribute specific functions */
void	attr_optfree(struct attr_flags *);

int
attr_compare(struct attr_flags *a, struct attr_flags *b)
{
	struct attr	*oa, *ob;
	int		 r;

	if (a->origin > b->origin)
		return (1);
	if (a->origin < b->origin)
		return (-1);
	if (a->nexthop > b->nexthop)
		return (1);
	if (a->nexthop < b->nexthop)
		return (-1);
	if (a->med > b->med)
		return (1);
	if (a->med < b->med)
		return (-1);
	if (a->lpref > b->lpref)
		return (1);
	if (a->lpref < b->lpref)
		return (-1);
	r = aspath_compare(a->aspath, b->aspath);
	if (r > 0)
		return (1);
	if (r < 0)
		return (-1);

	for (oa = TAILQ_FIRST(&a->others), ob = TAILQ_FIRST(&b->others);
	    oa != TAILQ_END(&a->others) && ob != TAILQ_END(&a->others);
	    oa = TAILQ_NEXT(oa, attr_l), ob = TAILQ_NEXT(ob, attr_l)) {
		if (oa->type > ob->type)
			return (1);
		if (oa->type < ob->type)
			return (-1);
		if (oa->len > ob->len)
			return (1);
		if (oa->len < ob->len)
			return (-1);
		r = memcmp(oa->data, ob->data, oa->len);
		if (r > 0)
			return (1);
		if (r < 0)
			return (-1);
	}
	if (oa != TAILQ_END(&a->others))
		return (1);
	if (ob != TAILQ_END(&a->others))
		return (-1);
	return (0);
}

void
attr_copy(struct attr_flags *t, struct attr_flags *s)
{
	struct attr	*os;
	/*
	 * first copy the full struct, then replace the path and tags with
	 * a own copy.
	 */
	memcpy(t, s, sizeof(struct attr_flags));
	t->aspath = aspath_create(s->aspath->data, s->aspath->hdr.len);
	TAILQ_INIT(&t->others);
	TAILQ_FOREACH(os, &s->others, attr_l)
		attr_optadd(t, os->flags, os->type, os->data, os->len);
}

int
attr_write(void *p, u_int16_t p_len, u_int8_t flags, u_int8_t type,
    void *data, u_int16_t data_len)
{
	u_char		*b = p;
	u_int16_t	 tmp, tot_len = 2; /* attribute header (without len) */

	if (data_len > 255) {
		tot_len += 2 + data_len;
		flags |= ATTR_EXTLEN;
	} else
		tot_len += 1 + data_len;

	if (tot_len > p_len)
		return (-1);

	*b++ = flags;
	*b++ = type;
	if (data_len > 255) {
		tmp = htons(data_len);
		memcpy(b, &tmp, 2);
		b += 2;
	} else
		*b++ = (u_char)(data_len & 0xff);

	if (data_len != 0)
		memcpy(b, data, data_len);

	return (tot_len);
}

void
attr_optadd(struct attr_flags *attr, u_int8_t flags, u_int8_t type,
    u_char *data, u_int16_t len)
{
	struct attr	*a, *p;

	if (flags & ATTR_OPTIONAL && ! flags & ATTR_TRANSITIVE)
		/*
		 * We already know that we're not intrested in this attribute.
		 * Currently only the MED is optional and non-transitive but
		 * MED is directly stored in struct attr_flags.
		 */
		return;

	a = calloc(1, sizeof(struct attr));
	if (a == NULL)
		fatal("attr_optadd");
	a->flags = flags;
	a->type = type;
	a->len = len;
	if (len != 0) {
		a->data = malloc(len);
		if (a->data == NULL)
			fatal("attr_optadd");
		memcpy(a->data, data, len);
	}
	/* keep a sorted list */
	TAILQ_FOREACH_REVERSE(p, &attr->others, attr_l, attr_list) {
		if (type > p->type) {
			TAILQ_INSERT_AFTER(&attr->others, p, a, attr_l);
			return;
		}
		ENSURE(type != p->type);
	}
}

void
attr_optfree(struct attr_flags *attr)
{
	struct attr	*a, *xa;

	for (a = TAILQ_FIRST(&attr->others); a != TAILQ_END(&attr->others);
	    a = xa) {
		xa = TAILQ_NEXT(a, attr_l);
		free(a->data);
		free(a);
	}
}

/* aspath specific functions */

/* TODO
 * aspath loop detection (partially done I think),
 * aspath regexp search,
 * aspath to string converter
 */
static u_int16_t	aspath_extract(void *, int);

/*
 * Extract the asnum out of the as segment at the specified position.
 * Direct access is not possible because of non-aligned reads.
 * ATTENTION: no bounds check are done.
 */
static u_int16_t
aspath_extract(void *seg, int pos)
{
	u_char		*ptr = seg;
	u_int16_t	 as = 0;

	ENSURE(0 <= pos && pos < 255);

	ptr += 2 + 2 * pos;
	as = *ptr++;
	as <<= 8;
	as |= *ptr;
	return as;
}

int
aspath_verify(void *data, u_int16_t len, u_int16_t myAS)
{
	u_int8_t	*seg = data;
	u_int16_t	 seg_size;
	u_int8_t	 i, seg_len, seg_type;

	for (; len > 0; len -= seg_size, seg += seg_size) {
		seg_type = seg[0];
		seg_len = seg[1];
		if (seg_type != AS_SET && seg_type != AS_SEQUENCE) {
			return AS_ERR_TYPE;
		}
		seg_size = 2 + 2 * seg_len;

		if (seg_size > len)
			return AS_ERR_LEN;

		if (seg_size == 0)
			/* empty aspath segment are not allowed */
			return AS_ERR_BAD;

		for (i = 0; i < seg_len; i++) {
			if (myAS == aspath_extract(seg, i))
				return AS_ERR_LOOP;
		}
	}
	return 0;	/* all OK */
}

struct aspath *
aspath_create(void *data, u_int16_t len)
{
	struct aspath	*aspath;

	RIB_STAT(aspath_create);

	/* The aspath must already have been checked for correctness. */
	aspath = malloc(ASPATH_HEADER_SIZE + len);
	if (aspath == NULL)
		fatal("aspath_create");
	aspath->hdr.len = len;
	memcpy(aspath->data, data, len);

	aspath->hdr.as_cnt = aspath_count(aspath);

	return aspath;
}

int
aspath_write(void *p, u_int16_t len, struct aspath *aspath, u_int16_t myAS,
    int prepend)
{
	u_char		*b = p;
	int		 tot_len, as_len, size, wpos = 0;
	u_int16_t	 tmp;
	u_int8_t	 type, attr_flag = ATTR_WELL_KNOWN;

	if (prepend > 255)
		/* lunatic prepends need to be blocked in the parser */
		return (-1);

	/* first calculate new size */
	if (aspath->hdr.len > 0) {
		ENSURE(aspath->hdr.len > 2);
		type = aspath->data[0];
		size = aspath->data[1];
	} else {
		/* empty as path */
		type = AS_SET;
		size = 0;
	}
	if (prepend == 0)
		as_len = aspath->hdr.len;
	else if (type == AS_SET || size + prepend > 255)
		/* need to attach a new AS_SEQUENCE */
		as_len = 2 + prepend * 2 + aspath->hdr.len;
	else
		as_len = prepend * 2 + aspath->hdr.len;

	/* check buffer size */
	tot_len = 2 + as_len;
	if (as_len > 255) {
		attr_flag |= ATTR_EXTLEN;
		tot_len += 2;
	} else
		tot_len += 1;

	if (tot_len > len)
		return (-1);

	/* header */
	b[wpos++] = attr_flag;
	b[wpos++] = ATTR_ASPATH;
	if (as_len > 255) {
		tmp = as_len;
		tmp = htons(tmp);
		memcpy(b, &tmp, 2);
		wpos += 2;
	} else
		b[wpos++] = (u_char)(as_len & 0xff);

	/* first prepends */
	myAS = htons(myAS);
	if (type == AS_SET) {
		b[wpos++] = AS_SEQUENCE;
		b[wpos++] = prepend;
		for (; prepend > 0; prepend--) {
			memcpy(b + wpos, &myAS, 2);
			wpos += 2;
		}
		memcpy(b + wpos, aspath->data, aspath->hdr.len);
	} else {
		if (size + prepend > 255) {
			b[wpos++] = AS_SEQUENCE;
			b[wpos++] = size + prepend - 255;
			for (; prepend + size > 255; prepend--) {
				memcpy(b + wpos, &myAS, 2);
				wpos += 2;
			}
		}
		b[wpos++] = AS_SEQUENCE;
		b[wpos++] = size + prepend;
		for (; prepend > 0; prepend--) {
			memcpy(b + wpos, &myAS, 2);
			wpos += 2;
		}
		memcpy(b + wpos, aspath->data + 2, aspath->hdr.len - 2);
	}
	return (tot_len);
}

void
aspath_destroy(struct aspath *aspath)
{
	RIB_STAT(aspath_destroy);
	/* currently there is only the aspath that needs to be freed */
	free(aspath);
}

u_char *
aspath_dump(struct aspath *aspath)
{
	return aspath->data;
}

u_int16_t
aspath_length(struct aspath *aspath)
{
	return aspath->hdr.len;
}

u_int16_t
aspath_count(struct aspath *aspath)
{
	u_int8_t	*seg;
	u_int16_t	 cnt, len, seg_size;
	u_int8_t	 seg_type, seg_len;

	cnt = 0;
	seg = aspath->data;
	for (len = aspath->hdr.len; len > 0; len -= seg_size, seg += seg_size) {
		seg_type = seg[0];
		seg_len = seg[1];
		ENSURE(seg_type == AS_SET || seg_type == AS_SEQUENCE);
		seg_size = 2 + 2 * seg_len;

		if (seg_type == AS_SET)
			cnt += 1;
		else
			cnt += seg_len;
	}
	return cnt;
}

u_int16_t
aspath_neighbour(struct aspath *aspath)
{
	/*
	 * Empty aspath is OK -- internal as route.
	 * But what is the neighbour? For now let's return 0 that
	 * should not break anything.
	 */

	if (aspath->hdr.len == 0)
		return 0;

	ENSURE(aspath->hdr.len > 2);
	return aspath_extract(aspath->data, 0);
}

#define AS_HASH_INITIAL 8271

u_long
aspath_hash(struct aspath *aspath)
{
	u_int8_t	*seg;
	u_long		 hash;
	u_int16_t	 len, seg_size;
	u_int8_t	 i, seg_len, seg_type;

	hash = AS_HASH_INITIAL;
	seg = aspath->data;
	for (len = aspath->hdr.len; len > 0; len -= seg_size, seg += seg_size) {
		seg_type = seg[0];
		seg_len = seg[1];
		ENSURE(seg_type == AS_SET || seg_type == AS_SEQUENCE);
		seg_size = 2 + 2 * seg_len;

		ENSURE(seg_size <= len);
		for (i = 0; i < seg_len; i++) {
			hash += (hash << 5);
			hash ^= aspath_extract(seg, i);
		}
	}
	return hash;
}

int
aspath_compare(struct aspath *a1, struct aspath *a2)
{
	int r;

	if (a1->hdr.len > a2->hdr.len)
		return (1);
	if (a1->hdr.len < a2->hdr.len)
		return (-1);
	r = memcmp(a1->data, a2->data, a1->hdr.len);
	if (r > 0)
		return (1);
	if (r < 0)
		return (-1);
	return 0;
}

a377 3
	if (asp->prefix_cnt == MAX_PREFIX_PER_AS)
		log_warnx("RDE: prefix hog, prefix %s/%d",
		    inet_ntoa(np->prefix->prefix.v4), np->prefix->prefixlen);
a551 3
	if (asp->prefix_cnt == MAX_PREFIX_PER_AS)
		log_warnx("RDE: prefix hog, prefix %s/%d",
		    inet_ntoa(pte->prefix.v4), pte->prefixlen);
@


1.30
log
@Fix bug in the decision process. The decision process is unable to directly
detect changes of the active prefix. This bug is only triggered when a
nexthop changes state. While doing that clarify prefix_move a bit.
OK henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.29 2004/02/02 16:46:16 claudio Exp $ */
d902 1
a902 1
		 * the nexthop is unreachable or ineligible. 
@


1.29
log
@Use correct struct in sizeof for calloc. OK henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.28 2004/01/27 21:56:21 henning Exp $ */
d786 2
a787 1
	memcpy(&np->prefix, &p->prefix, sizeof(np->prefix));
d794 4
a797 1
	asp->peer->prefix_cnt++;
d809 2
d821 1
a821 1
	oasp->peer->prefix_cnt--;
d896 10
@


1.28
log
@move strict kroute from in_addr_t for nexthop and prefix to struct in_addr
ok claudio
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.27 2004/01/22 20:34:56 henning Exp $ */
d1072 1
a1072 1
	nexthoptable.nexthop_hashtbl = calloc(hs, sizeof(struct aspath_head));
@


1.27
log
@use log_warnx and log_info. reclassify a few messages in the process and fix
a few messages.

ok claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.26 2004/01/18 00:44:44 deraadt Exp $ */
d1189 1
a1189 1
	nh->nexthop_net.v4.s_addr = msg->kr.prefix;
@


1.26
log
@spacing
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.25 2004/01/17 19:35:36 claudio Exp $ */
d796 1
a796 1
		logit(LOG_INFO, "RDE: prefix hog, prefix %s/%d",
d961 1
a961 1
		logit(LOG_INFO, "RDE: prefix hog, prefix %s/%d",
d1170 1
a1170 1
		logit(LOG_INFO, "nexthop_update: non-existent nexthop");
@


1.25
log
@Make it possible to announce own networks. In the RDE these prefixes are
attached to a pseudo peer and inserted like all other prefixes into the RIB.
OK henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.24 2004/01/13 16:08:04 claudio Exp $ */
d912 1
a912 1
 */ 
@


1.24
log
@Fix the aspath_* functions to allow empty aspath. A empty aspath is one
with len 0. Needed vor ibgp and local network announcements.
OK henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.23 2004/01/13 13:45:50 claudio Exp $ */
d765 2
d848 1
a848 1
	if (p == NULL)	/* Got a dummy withdrawn request. */
d911 32
d1067 2
a1068 1
	u_long hs, i;
d1080 17
d1135 4
d1191 2
a1192 1
	nh->connected = msg->connected;
@


1.23
log
@Implement a max-prefix and a announce none | self | all neighbor statement.
The first limits the number of sent prefixes per peer the latter controls
which prefix we do annouce to the neighbor.
Another looks good from henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.22 2004/01/12 13:33:16 claudio Exp $ */
d242 1
d250 1
a250 1
	ENSURE(0 <= pos && pos < 0xff);
d277 4
d322 9
a330 2
	type = aspath->data[0];
	size = aspath->data[1];
d353 1
a353 1
	if (as_len > 0xff) {
d443 2
a444 2
	if (aspath->hdr.len < 2)
		fatalx("aspath_neighbour: aspath has no data");
d446 2
a447 3
	if (aspath->data[1] > 0)
		return aspath_extract(aspath->data, 0);
	return 0;
@


1.22
log
@Nexthop announcement fixup. There are different rules for ibgp and ebgp.
For ibgp the nexthop is normally passed unmodified unless the nexthop is
equal to the remote peer ip. To ebgp peers the nexthop is changed to the
local session ip unless the remote peer ip and the nexthop are on the same
subnet. OK henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.21 2004/01/11 22:08:04 henning Exp $ */
d780 1
d800 1
d802 1
d912 1
d945 1
d947 1
@


1.21
log
@KNF
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.20 2004/01/11 21:59:45 henning Exp $ */
d1113 4
@


1.20
log
@set address family...
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.19 2004/01/11 21:47:20 claudio Exp $ */
d1010 1
a1010 1
	&nexthoptable.nexthop_hashtbl[ntohl((x)) & 	\
@


1.19
log
@Move all struct in_addr to either struct bgpd_addr or in_addr_t whichever
is more appropriate. The rde uses now in most cases struct bgpd_addr.
OK henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.18 2004/01/11 19:14:43 henning Exp $ */
d1043 1
@


1.18
log
@use struct bgpd_addr for nexthop and gateway in struct kroute_nexthop
(and thus the nexthop messages between parent and RDE)

ok claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.17 2004/01/11 02:39:05 henning Exp $ */
d21 3
d93 1
a93 1
	if (a->nexthop.s_addr > b->nexthop.s_addr)
d95 1
a95 1
	if (a->nexthop.s_addr < b->nexthop.s_addr)
d517 1
a517 1
    struct in_addr prefix, int prefixlen)
d709 1
a709 1
prefix_get(struct rde_aspath *asp, struct in_addr prefix, int prefixlen)
d719 1
a719 1
		    p->prefix->prefix.s_addr == prefix.s_addr) {
d733 1
a733 1
prefix_add(struct rde_aspath *asp, struct in_addr prefix, int prefixlen)
d773 1
a773 1
	np->prefix = p->prefix;
d782 2
a783 2
		logit(LOG_INFO, "RDE: prefix hog, prefix %#x/%d",
		    np->prefix->prefix.s_addr, np->prefix->prefixlen);
d819 1
a819 1
prefix_remove(struct rde_peer *peer, struct in_addr prefix, int prefixlen)
d912 2
a913 2
		logit(LOG_INFO, "RDE: prefix hog, prefix %#x/%d",
		    pte->prefix.s_addr, pte->prefixlen);
d1010 2
a1011 1
	&nexthoptable.nexthop_hashtbl[(x) & nexthoptable.nexthop_hashmask]
d1039 1
a1039 1
		nh = nexthop_get(asp->flags.nexthop.s_addr);
d1043 2
a1044 2
		nh->exit_nexthop = asp->flags.nexthop;
		LIST_INSERT_HEAD(NEXTHOP_HASH(asp->flags.nexthop.s_addr), nh,
d1046 1
a1046 1
		rde_send_nexthop(nh->exit_nexthop.s_addr, 1);
d1067 1
a1067 1
		rde_send_nexthop(nh->exit_nexthop.s_addr, 0);
d1080 1
a1080 1
		if (nh->exit_nexthop.s_addr == nexthop)
d1099 1
a1099 1
	ENSURE(nh->exit_nexthop.s_addr == msg->nexthop.v4.s_addr);
d1107 2
a1108 1
		nh->true_nexthop.s_addr = nh->exit_nexthop.s_addr;
d1110 2
a1111 1
		nh->true_nexthop.s_addr = msg->gateway.v4.s_addr;
@


1.17
log
@KNF
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.16 2004/01/10 22:25:42 claudio Exp $ */
d1090 1
a1090 1
	nh = nexthop_get(msg->nexthop);
d1095 1
a1095 1
	ENSURE(nh->exit_nexthop.s_addr == msg->nexthop);
d1105 1
a1105 1
		nh->true_nexthop.s_addr = msg->gateway;
@


1.16
log
@Implement as path prepends. At least one prepend is needed for ebgp
neighbors. Fix a bug in the update generation. If no path attributes are
available e.g. a packet with only withdraws we need to set (and write) the
bgp path attribute field to zero. With this change we are able to send
valid updates to our neighbors with one exception: the nexthop field which
needs to be changed for ebgp neighbors.
OK henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.15 2004/01/10 16:20:29 claudio Exp $ */
d98 1
a98 1
	if (a->lpref > b->lpref) 
d100 1
a100 1
	if (a->lpref < b->lpref) 
d109 2
a110 2
	   oa != TAILQ_END(&a->others) && ob != TAILQ_END(&a->others);
	   oa = TAILQ_NEXT(oa, attr_l), ob = TAILQ_NEXT(ob, attr_l)) {
@


1.15
log
@RDE update generation. First we queue all updates and withdraws on a per
peer basis. A queue runner will dequeue and package those messages to valid
bgp UPDATE messages and send them to the SE.
Not yet done is per peer type attribute handling (like aspath prepends and
nexthop modifications) and the queue runner could be a tad smarter. All in
all this gives us a good starting point for the missing parts.
OK henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.14 2004/01/06 10:51:14 claudio Exp $ */
d298 76
@


1.14
log
@2004 OK henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.13 2003/12/30 13:03:27 henning Exp $ */
d78 1
d81 1
a81 1
attr_equal(struct attr_flags *a, struct attr_flags *b)
d83 47
a129 11
	/* astags not yet used */
	if (a->origin != b->origin ||
	    aspath_equal(a->aspath, b->aspath) == 0 ||
	    a->nexthop.s_addr != b->nexthop.s_addr ||
	    a->med != b->med ||
	    a->lpref != b->lpref ||
	    a->aggr_atm != b->aggr_atm ||
	    a->aggr_as != b->aggr_as ||
	    a->aggr_ip.s_addr != b->aggr_ip.s_addr)
		return 0;
	return 1;
d135 1
a140 1
	/* XXX we could speed that a bit with a direct malloc, memcpy */
d142 3
a144 1
	t->astags = NULL;	/* XXX NOT YET */
d147 3
a149 2
u_int16_t
attr_length(struct attr_flags *attr)
d151 2
a152 1
	u_int16_t	alen, plen;
d154 8
a161 9
	alen = 4 /* origin */ + 7 /* nexthop */ + 7 /* lpref */;
	plen = aspath_length(attr->aspath);
	alen += 2 + plen + (plen > 255 ? 2 : 1);
	if (attr->med != 0)
		alen += 7;
	if (attr->aggr_atm == 1)
		alen += 3;
	if (attr->aggr_as != 0)
		alen += 9;
d163 13
a175 1
	return alen;
d178 3
a180 2
int
attr_dump(void *p, u_int16_t len, struct attr_flags *a)
d182 1
a182 35
	u_char		*buf = p;
	u_int32_t	 tmp32;
	u_int16_t	 tmp16;
	u_int16_t	 aslen, wlen = 0;

#define ATTR_WRITE(b, a, alen)				\
	do {						\
		if ((wlen + (alen)) > len)		\
			return (-1);			\
		memcpy((b) + wlen, (a), (alen));	\
		wlen += (alen);				\
	} while (0)
#define ATTR_WRITEB(b, c)				\
	do {						\
		if (wlen == len || (c) > 0xff)		\
			return (-1);			\
		(b)[wlen++] = (c);			\
	} while (0)

	/* origin */
	ATTR_WRITEB(buf, ATTR_ORIGIN_FLAGS);
	ATTR_WRITEB(buf, ATTR_ORIGIN);
	ATTR_WRITEB(buf, 1);
	ATTR_WRITEB(buf, a->origin);

	/* aspath */
	aslen = aspath_length(a->aspath);
	ATTR_WRITEB(buf, ATTR_TRANSITIVE | (aslen>255 ? ATTR_EXTLEN : 0));
	ATTR_WRITEB(buf, ATTR_ASPATH);
	if (aslen > 255) {
		tmp16 = htonl(aslen);
		ATTR_WRITE(buf, &tmp16, 4);
	} else
		ATTR_WRITEB(buf, aslen);
	ATTR_WRITE(buf, aspath_dump(a->aspath), aslen);
d184 27
a210 13
	/* nexthop */
	ATTR_WRITEB(buf, ATTR_NEXTHOP_FLAGS);
	ATTR_WRITEB(buf, ATTR_NEXTHOP);
	ATTR_WRITEB(buf, 4);
	ATTR_WRITE(buf, &a->nexthop, 4);	/* network byte order */

	/* MED */
	if (a->med != 0) {
		ATTR_WRITEB(buf, ATTR_MED_FLAGS);
		ATTR_WRITEB(buf, ATTR_MED);
		ATTR_WRITEB(buf, 4);
		tmp32 = htonl(a->med);
		ATTR_WRITE(buf, &tmp32, 4);
d212 1
d214 4
a217 13
	/* local preference */
	ATTR_WRITEB(buf, ATTR_LOCALPREF_FLAGS);
	ATTR_WRITEB(buf, ATTR_LOCALPREF);
	ATTR_WRITEB(buf, 4);
	tmp32 = htonl(a->lpref);
	ATTR_WRITE(buf, &tmp32, 4);

	/* atomic aggregate */
	if (a->aggr_atm == 1) {
		ATTR_WRITEB(buf, ATTR_ATOMIC_AGGREGATE_FLAGS);
		ATTR_WRITEB(buf, ATTR_ATOMIC_AGGREGATE);
		ATTR_WRITEB(buf, 0);
	}
d219 5
a223 8
	/* aggregator */
	if (a->aggr_as != 0) {
		ATTR_WRITEB(buf, ATTR_AGGREGATOR_FLAGS);
		ATTR_WRITEB(buf, ATTR_AGGREGATOR);
		ATTR_WRITEB(buf, 6);
		tmp16 = htons(a->aggr_as);
		ATTR_WRITE(buf, &tmp16, 2);
		ATTR_WRITE(buf, &a->aggr_ip, 4);	/* network byte order */
a224 4

	return wlen;
#undef ATTR_WRITEB
#undef ATTR_WRITE
d388 1
a388 1
aspath_equal(struct aspath *a1, struct aspath *a2)
d390 11
a400 3
	if (a1->hdr.len == a2->hdr.len &&
	    memcmp(a1->data, a2->data, a1->hdr.len) == 0)
		return 1;
d447 1
d451 5
a455 1
		if (attr_equal(&asp->flags, attrs) == 0) {
d464 1
a464 2
		} else
			pte = prefix_add(asp, prefix, prefixlen);
d480 1
a480 1
		if (aspath_equal(asp->flags.aspath, aspath) &&
d586 1
a586 1
	/* free the aspath and astags */
d589 1
a589 5

	/*
	 * astags_destroy(asp->flags.astags);
	 * asp->flags.astags = NULL;
	 */
d614 1
a614 1
	    asp->flags.astags == NULL);
@


1.13
log
@typos from david
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.12 2003/12/26 22:41:01 henning Exp $ */
d4 1
a4 1
 * Copyright (c) 2003 Claudio Jeker <claudio@@openbsd.org>
@


1.12
log
@"when you try to be very smart, something breaks horribly"
zap aspath->state, which was a copy of aspath->nexthop->state, for a tiny
little bit faster access. tho, it happened what had to happen, they ran
out of sync.
it's just not worth it.

also add a missinf LIST_INIT.
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.11 2003/12/26 21:51:57 henning Exp $ */
d342 1
a342 1
#define AS_HASH_INITAL 8271
d352 1
a352 1
	hash = AS_HASH_INITAL;
d521 3
a523 3
 * peer_l: list of all aspathes that belong to that peer
 * path_l: hash list to find pathes quickly
 * nexthop_l: list of all aspathes with an equal exit nexthop
d561 1
a561 1
	 * astags_destory(asp->flags.astags);
@


1.11
log
@set true_nexthop = exit_nexthop for directly connected nexthops
(in other words, make sure true_nexthop always has the right ip address
for nexthops in state reachable)
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.10 2003/12/26 21:30:20 henning Exp $ */
a494 3
	if (asp->state == state)
		return;		/* no need to redo it */
	asp->state = state;
d1022 1
@


1.10
log
@move struct nexthop definition to rde.h
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.9 2003/12/26 18:07:33 henning Exp $ */
d1003 5
a1007 1
	nh->true_nexthop.s_addr = msg->gateway;
@


1.9
log
@when this project started and i added the fatal() function, I made it take
the error number as parameter instead of accessing errno, because in one
place the error number was not in errno but fetched from a socket.
now, of course it makes much more sense to just set errno to the error number
just fecthed in this one place instead of having hundreds of fatal() calls
all transfer the errno round and round and round...
fix this, and also provide a fatalx, which does not care for errno and doesn't
invoke strerror.
oh, btw, in the place where we fetch the err # from the socket, we don't
call fatal anymore anyway...
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.8 2003/12/25 23:41:23 claudio Exp $ */
a901 12
struct nexthop {
	LIST_ENTRY(nexthop)	nexthop_l;
	enum nexthop_state	state;
#if 0
	u_int32_t		costs;
#endif
	struct aspath_head	path_h;
	struct in_addr		exit_nexthop;
	struct in_addr		true_nexthop;
	u_int8_t		connected;
};

@


1.8
log
@Turn the nexthop verification on. At least in the RDE.

ok henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.7 2003/12/25 23:22:13 claudio Exp $ */
d273 1
a273 1
		fatal("aspath_create", errno);
d335 1
a335 1
		fatal("aspath_neighbour: aspath has no data", 0);
d402 1
a402 1
		fatal("path_init", errno);
d579 1
a579 1
		fatal("path_alloc", errno);
d862 1
a862 1
		fatal("prefix_alloc", errno);
d931 1
a931 1
		fatal("nextop_init", errno);
d1032 1
a1032 1
		fatal("nexthop_alloc", errno);
@


1.7
log
@RDE part of the nexthop verification puzzle.
The RDE just tracks the nexthop IPs and reacts on nexthop messages
from the parent.

ok henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.6 2003/12/24 11:39:43 henning Exp $ */
d951 1
a951 2
		//nh->state = NEXTHOP_LOOKUP;
		nh->state = NEXTHOP_REACH;
@


1.6
log
@typos in comments, from jared
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.5 2003/12/22 06:42:19 deraadt Exp $ */
d63 1
a63 2
	u_int64_t	nexthop_invalidate;
	u_int64_t	nexthop_validate;
d889 1
a889 4
static struct nexthop	*nexthop_get(struct in_addr);
static void		 nexthop_updateall(struct in_addr, int,
			    enum nexthop_state);
static inline void	 nexthop_update(struct nexthop *, enum nexthop_state);
d893 9
d903 1
d909 3
a911 2
	struct in_addr		nexthop;
	LIST_ENTRY(nexthop)	nexthop_l;
d920 1
a920 1
	&nexthoptable.nexthop_hashtbl[x.s_addr & nexthoptable.nexthop_hashmask]
d948 1
a948 1
		nh = nexthop_get(asp->flags.nexthop);
d951 1
a951 5
		/*
		 * XXX nexthop_lookup()
		 * currently I assume that the nexthop is reachable.
		 * Getting that info could end with a big pain in the ass.
		 */
d953 2
a954 2
		nh->nexthop = asp->flags.nexthop;
		LIST_INSERT_HEAD(NEXTHOP_HASH(asp->flags.nexthop), nh,
d956 1
a958 1
	asp->state = nh->state;
d977 1
a981 16
void
nexthop_invalidate(struct in_addr prefix, int prefixlen)
{
	RIB_STAT(nexthop_invalidate);

	nexthop_updateall(prefix, prefixlen, NEXTHOP_UNREACH);
}

void
nexthop_validate(struct in_addr prefix, int prefixlen)
{
	RIB_STAT(nexthop_validate);

	nexthop_updateall(prefix, prefixlen, NEXTHOP_REACH);
}

d983 1
a983 1
nexthop_get(struct in_addr nexthop)
d990 1
a990 1
		if (nh->nexthop.s_addr == nexthop.s_addr)
d996 2
a997 3
static void
nexthop_updateall(struct in_addr prefix, int prefixlen,
    enum nexthop_state state)
d999 2
a1000 2
	struct nexthop	*nh;
	u_long		 ul;
d1002 1
a1002 2
	/* XXX probably I get shot for this code ... (: */
	prefix.s_addr >>= (32-prefixlen);
d1004 4
a1007 8
	for (ul = nexthoptable.nexthop_hashmask; ul >= 0; ul--) {
		LIST_FOREACH(nh, &nexthoptable.nexthop_hashtbl[ul], nexthop_l) {
			if (prefix.s_addr ==
			    nh->nexthop.s_addr >> (32-prefixlen)) {
				nh->state = state;
				nexthop_update(nh, state);
			}
		}
d1009 6
a1014 1
}
d1016 2
a1017 4
static inline void
nexthop_update(struct nexthop *nh, enum nexthop_state mode)
{
	struct rde_aspath	*asp;
d1020 1
a1020 1
		path_updateall(asp, mode);
@


1.5
log
@spelling
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.4 2003/12/21 16:11:34 claudio Exp $ */
d35 1
a35 1
 * This is achieved by heavily linking the different parts toghether.
d72 2
a73 2
 * maximum number of perfixes we allow per prefix. The number should
 * be not to big and ensures only that the prefix count is propperly
d213 1
a213 1
 * aspath loop detection (partialy done I think),
d220 1
a220 1
 * Extract the asnum out of the as segement at the specified position.
d570 1
a570 1
/* alloc and initalize new entry. May not fail. */
d629 1
a629 1
 * to be done -- which is acctually always.
d745 1
a745 1
 * seraches in the prefix list of specified pt_entry for a prefix entry
d848 2
a849 2
	 * It's the caller duty to remove empty aspath respectivly pt_entry
	 * structures. Also freeing the unlinked prefix is callers duty.
d887 1
a887 1
 * hash table has more benefits and the table walk shoulds not happen to often.
@


1.4
log
@yet more from the castathon; most aspath functions where accessing non-
aligned memory (u_int16_t) therefor crashed the RDE on my sparc64. All
buffer specific functions use now void * instead of u_char * so most cast
are now history. Tested on sparc64 and i386. OK henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.3 2003/12/19 19:24:08 deraadt Exp $ */
d33 3
a35 3
 * The RIB is build with one aspect in mind. Speed -- acctually update speed.
 * Therefor one thing needs to be absolutly avoided, long table walks.
 * This is achieved by heavly linking the different parts toghether.
@


1.3
log
@knf
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.2 2003/12/19 01:15:47 deraadt Exp $ */
d4 1
a4 1
 * Copyright (c) 2003 Claudio Jeker <cjeker@@diehard.n-r-g.com>
d128 1
a128 1
attr_dump(u_char *p, u_int16_t len, struct attr_flags *a)
d130 11
a140 6
#define ATTR_WRITE(b, a, alen)			\
	do {					\
		if ((wlen += (alen)) > len)	\
			return (-1);		\
		memcpy((b), (a), (alen));	\
		(b) += (alen);			\
d142 5
a146 5
#define ATTR_WRITEB(b, c)			\
	do {					\
		if (wlen++ == len)		\
			return (-1);		\
		*(b)++ = (u_char)(c);		\
a148 4
	u_int32_t	tmp32;
	u_int16_t	tmp16;
	u_int16_t	aslen, wlen = 0;

d150 4
a153 4
	ATTR_WRITEB(p, ATTR_ORIGIN_FLAGS);
	ATTR_WRITEB(p, ATTR_ORIGIN);
	ATTR_WRITEB(p, 1);
	ATTR_WRITEB(p, a->origin);
d157 2
a158 2
	ATTR_WRITEB(p, ATTR_TRANSITIVE | (aslen>255 ? ATTR_EXTLEN : 0));
	ATTR_WRITEB(p, ATTR_ASPATH);
d161 1
a161 1
		ATTR_WRITE(p, &tmp16, 4);
d163 2
a164 2
		ATTR_WRITEB(p, aslen);
	ATTR_WRITE(p, aspath_dump(a->aspath), aslen);
d167 4
a170 4
	ATTR_WRITEB(p, ATTR_NEXTHOP_FLAGS);
	ATTR_WRITEB(p, ATTR_NEXTHOP);
	ATTR_WRITEB(p, 4);
	ATTR_WRITE(p, &a->nexthop, 4);	/* network byte order */
d174 3
a176 3
		ATTR_WRITEB(p, ATTR_MED_FLAGS);
		ATTR_WRITEB(p, ATTR_MED);
		ATTR_WRITEB(p, 4);
d178 1
a178 1
		ATTR_WRITE(p, &tmp32, 4);
d182 3
a184 3
	ATTR_WRITEB(p, ATTR_LOCALPREF_FLAGS);
	ATTR_WRITEB(p, ATTR_LOCALPREF);
	ATTR_WRITEB(p, 4);
d186 1
a186 1
	ATTR_WRITE(p, &tmp32, 4);
d190 3
a192 3
		ATTR_WRITEB(p, ATTR_ATOMIC_AGGREGATE_FLAGS);
		ATTR_WRITEB(p, ATTR_ATOMIC_AGGREGATE);
		ATTR_WRITEB(p, 0);
d197 3
a199 3
		ATTR_WRITEB(p, ATTR_AGGREGATOR_FLAGS);
		ATTR_WRITEB(p, ATTR_AGGREGATOR);
		ATTR_WRITEB(p, 6);
d201 2
a202 2
		ATTR_WRITE(p, &tmp16, 2);
		ATTR_WRITE(p, &a->aggr_ip, 4);	/* network byte order */
d217 20
d239 1
a239 1
aspath_verify(u_char *data, u_int16_t len, u_int16_t myAS)
d241 8
a248 7
	struct as_segment	*seg;
	u_int16_t		 pos;
	u_int8_t		 i;

	for (pos = 0; pos + 1 < len; ) {
		seg = (struct as_segment *)(data + pos);
		if (seg->type != AS_SET && seg->type != AS_SEQUENCE) {
d251 1
d253 1
a253 1
		if ((pos += 2 + 2 * seg->len) > len)
d256 2
a257 2
		for (i = 0; i < seg->len; i++) {
			if (myAS == seg->as_num[i])
d261 1
a261 4
	if (pos == len)
		return 0;	/* all OK */

	return AS_ERR_LEN;
d265 1
a265 1
aspath_create(u_char *data, u_int16_t len)
d271 2
a272 2
	/* XXX we assume that the aspath was already checked for correctness */
	aspath = (struct aspath *)malloc(ASPATH_HEADER_SIZE + len);
d294 1
a294 1
	return (u_char *)aspath->data;
d306 3
a308 2
	struct as_segment	*seg;
	u_int16_t		 cnt, len, pos;
a309 1
	len = aspath->hdr.len;
d311 8
a318 4
	for (pos = 0; pos + 1 < len; ) {
		seg = (struct as_segment *)(aspath->data + pos);
		ENSURE(seg->type == AS_SET || seg->type == AS_SEQUENCE);
		if (seg->type == AS_SET)
d321 1
a321 2
			cnt += seg->len;
		pos += 2 + 2 * seg->len;
a328 1
	struct as_segment	*seg;
d335 2
a336 5
	ENSURE(aspath->hdr.len >= 2);

	seg = (struct as_segment *)aspath->data;
	if (seg->len > 0)
		return seg->as_num[0];
d338 2
d348 4
a351 4
	struct as_segment	*seg;
	u_long			 hash;
	u_int16_t		 len, pos;
	u_int8_t		 i;
d354 9
a362 5
	len = aspath->hdr.len;
	for (pos = 0; pos < len; ) {
		seg = (struct as_segment *)(aspath->data + pos);
		ENSURE(pos + 2 + 2 * seg->len <= len);
		for (i = 0; i < seg->len; i++) {
d364 1
a364 1
			hash ^= seg->as_num[i];
a365 1
		pos += 2 + 2 * seg->len;
@


1.2
log
@knf & 64-bit cleanup; henning ok
@
text
@d1 1
a1 1
/*	$OpenBSD: rde_rib.c,v 1.1 2003/12/17 11:46:54 henning Exp $ */
d375 2
a376 1
	for (hs = 1; hs < hashsize; hs <<= 1) ;
d896 2
a897 1
	for (hs = 1; hs < hashsize; hs <<= 1) ;
@


1.1
log
@welcome, bgpd
started by me some time ago with moral support from theo, the proceeded up to
the point where the session engine worked correctly. claudio jeker joined
then and did a lot of work in the RDE.
it is not particulary usefull as application right now as parts are still
missing but is imported to enable more people to work on it.
status:
BGP sessions get established fine, OPEN messages and then KEEPALIVEs
exchanged etc. session FSM works fine; NOTIFICATIONs are handled fine, and
all connection drops etc I provoked get handled fine.
Incoming UPDATE messgages are parsed well and the data entered to the RIB,
the decision process is not yet there, neither is outgoing UPDATEs or sync
to the kernel routing table.

not connected to the builds yet.
@
text
@d1 1
a1 1
/*	$OpenBSD$ */
d24 1
a82 2
	if (a->origin != b->origin) return 0;
	if (aspath_equal(a->aspath, b->aspath) == 0) return 0;
d84 9
a92 6
	if (a->nexthop.s_addr != b->nexthop.s_addr) return 0;
	if (a->med != b->med) return 0;
	if (a->lpref != b->lpref) return 0;
	if (a->aggr_atm != b->aggr_atm) return 0;
	if (a->aggr_as != b->aggr_as) return 0;
	if (a->aggr_ip.s_addr != b->aggr_ip.s_addr) return 0;
d116 1
a116 1
	alen += 2 + plen + (plen>255?2:1);
d402 1
a402 1
					    prefix, prefixlen)) == NULL) {
@

