head	1.183;
access;
symbols
	OPENBSD_6_1:1.183.0.4
	OPENBSD_6_1_BASE:1.183
	OPENBSD_6_0:1.178.0.4
	OPENBSD_6_0_BASE:1.178
	OPENBSD_5_9:1.176.0.2
	OPENBSD_5_9_BASE:1.176
	OPENBSD_5_8:1.166.0.6
	OPENBSD_5_8_BASE:1.166
	OPENBSD_5_7:1.166.0.2
	OPENBSD_5_7_BASE:1.166
	OPENBSD_5_6:1.165.0.4
	OPENBSD_5_6_BASE:1.165
	OPENBSD_5_5:1.159.0.2
	OPENBSD_5_5_BASE:1.159
	OPENBSD_5_4:1.153.0.2
	OPENBSD_5_4_BASE:1.153
	OPENBSD_5_3:1.146.0.2
	OPENBSD_5_3_BASE:1.146
	OPENBSD_5_2:1.121.0.2
	OPENBSD_5_2_BASE:1.121
	OPENBSD_5_1_BASE:1.117
	OPENBSD_5_1:1.117.0.2
	OPENBSD_5_0:1.104.0.2
	OPENBSD_5_0_BASE:1.104
	OPENBSD_4_9:1.94.0.2
	OPENBSD_4_9_BASE:1.94
	OPENBSD_4_8:1.89.0.2
	OPENBSD_4_8_BASE:1.89
	OPENBSD_4_7:1.77.0.2
	OPENBSD_4_7_BASE:1.77
	OPENBSD_4_6:1.68.0.4
	OPENBSD_4_6_BASE:1.68
	OPENBSD_4_5:1.56.0.2
	OPENBSD_4_5_BASE:1.56;
locks; strict;
comment	@ * @;


1.183
date	2017.01.09.09.53.23;	author reyk;	state Exp;
branches;
next	1.182;
commitid	jM4eOMW1AJwdfKrr;

1.182
date	2016.09.08.12.06.43;	author eric;	state Exp;
branches;
next	1.181;
commitid	LkfnyKFoItZAAepX;

1.181
date	2016.09.04.16.10.31;	author eric;	state Exp;
branches;
next	1.180;
commitid	I2r1xe6emhZl6xPg;

1.180
date	2016.09.01.10.54.25;	author eric;	state Exp;
branches;
next	1.179;
commitid	fYsbH2IujjKSME9c;

1.179
date	2016.08.31.21.49.01;	author eric;	state Exp;
branches;
next	1.178;
commitid	nfyDx1DVV3J9mwcW;

1.178
date	2016.05.28.21.21.20;	author eric;	state Exp;
branches;
next	1.177;
commitid	KhU4hSodVCiVoZ62;

1.177
date	2016.04.29.08.55.08;	author eric;	state Exp;
branches;
next	1.176;
commitid	oxMoHf5ouZJ0D4QU;

1.176
date	2016.01.27.12.46.03;	author sunil;	state Exp;
branches;
next	1.175;
commitid	zKnEiCIfZ7vWdZVV;

1.175
date	2015.12.28.22.08.30;	author jung;	state Exp;
branches;
next	1.174;
commitid	ZxnqOQqX6IeYI9jW;

1.174
date	2015.12.14.10.22.12;	author jung;	state Exp;
branches;
next	1.173;
commitid	HRAnniyhGW9Sadln;

1.173
date	2015.12.10.07.49.58;	author sunil;	state Exp;
branches;
next	1.172;
commitid	qsBFUWovDNs63G3N;

1.172
date	2015.11.23.06.54.21;	author sunil;	state Exp;
branches;
next	1.171;
commitid	YyzP3p5zJCsjsouQ;

1.171
date	2015.11.05.09.14.31;	author sunil;	state Exp;
branches;
next	1.170;
commitid	3vo6L6sIqhuEjLcD;

1.170
date	2015.10.29.10.25.36;	author sunil;	state Exp;
branches;
next	1.169;
commitid	TXZugvtal96cI6ec;

1.169
date	2015.10.16.13.37.44;	author millert;	state Exp;
branches;
next	1.168;
commitid	H99PcNtHGZMrNl2r;

1.168
date	2015.10.14.22.01.43;	author gilles;	state Exp;
branches;
next	1.167;
commitid	XSq2zfqNj1sXRZRl;

1.167
date	2015.10.13.11.03.30;	author gilles;	state Exp;
branches;
next	1.166;
commitid	2HxskerqqohBQT8v;

1.166
date	2015.01.20.17.37.54;	author deraadt;	state Exp;
branches;
next	1.165;
commitid	ZBTFreARDSMmzOIV;

1.165
date	2014.07.10.15.54.55;	author eric;	state Exp;
branches;
next	1.164;
commitid	Uxz21DeZX3Z1gOVr;

1.164
date	2014.07.10.14.45.02;	author eric;	state Exp;
branches;
next	1.163;
commitid	dolePHRcgnf1dDVL;

1.163
date	2014.07.08.15.45.32;	author eric;	state Exp;
branches;
next	1.162;
commitid	BLF7pkUK3dHr6Hox;

1.162
date	2014.04.19.13.40.24;	author gilles;	state Exp;
branches;
next	1.161;

1.161
date	2014.04.08.15.25.43;	author eric;	state Exp;
branches;
next	1.160;

1.160
date	2014.04.04.16.10.42;	author eric;	state Exp;
branches;
next	1.159;

1.159
date	2014.02.04.15.44.05;	author eric;	state Exp;
branches;
next	1.158;

1.158
date	2014.02.04.14.56.03;	author eric;	state Exp;
branches;
next	1.157;

1.157
date	2014.02.04.09.05.06;	author eric;	state Exp;
branches;
next	1.156;

1.156
date	2013.11.20.09.22.42;	author eric;	state Exp;
branches;
next	1.155;

1.155
date	2013.10.27.17.47.53;	author eric;	state Exp;
branches;
next	1.154;

1.154
date	2013.10.27.07.56.25;	author eric;	state Exp;
branches;
next	1.153;

1.153
date	2013.07.19.21.14.52;	author eric;	state Exp;
branches;
next	1.152;

1.152
date	2013.07.19.20.37.07;	author eric;	state Exp;
branches;
next	1.151;

1.151
date	2013.07.19.15.14.23;	author eric;	state Exp;
branches;
next	1.150;

1.150
date	2013.07.19.11.14.08;	author eric;	state Exp;
branches;
next	1.149;

1.149
date	2013.07.19.07.49.08;	author eric;	state Exp;
branches;
next	1.148;

1.148
date	2013.05.24.17.03.14;	author eric;	state Exp;
branches;
next	1.147;

1.147
date	2013.04.12.18.22.49;	author eric;	state Exp;
branches;
next	1.146;

1.146
date	2013.01.31.18.24.47;	author eric;	state Exp;
branches;
next	1.145;

1.145
date	2013.01.26.09.37.23;	author gilles;	state Exp;
branches;
next	1.144;

1.144
date	2012.11.23.09.25.44;	author eric;	state Exp;
branches;
next	1.143;

1.143
date	2012.11.20.09.47.45;	author eric;	state Exp;
branches;
next	1.142;

1.142
date	2012.11.13.13.23.23;	author eric;	state Exp;
branches;
next	1.141;

1.141
date	2012.11.12.14.58.53;	author eric;	state Exp;
branches;
next	1.140;

1.140
date	2012.10.25.09.51.08;	author eric;	state Exp;
branches;
next	1.139;

1.139
date	2012.10.14.18.45.34;	author eric;	state Exp;
branches;
next	1.138;

1.138
date	2012.10.14.13.31.46;	author chl;	state Exp;
branches;
next	1.137;

1.137
date	2012.09.21.12.33.32;	author eric;	state Exp;
branches;
next	1.136;

1.136
date	2012.09.19.18.20.36;	author eric;	state Exp;
branches;
next	1.135;

1.135
date	2012.09.16.16.43.28;	author chl;	state Exp;
branches;
next	1.134;

1.134
date	2012.09.10.14.22.11;	author eric;	state Exp;
branches;
next	1.133;

1.133
date	2012.08.25.22.03.26;	author gilles;	state Exp;
branches;
next	1.132;

1.132
date	2012.08.25.10.23.12;	author gilles;	state Exp;
branches;
next	1.131;

1.131
date	2012.08.24.21.24.25;	author eric;	state Exp;
branches;
next	1.130;

1.130
date	2012.08.24.18.46.46;	author eric;	state Exp;
branches;
next	1.129;

1.129
date	2012.08.24.18.26.01;	author eric;	state Exp;
branches;
next	1.128;

1.128
date	2012.08.21.13.13.17;	author eric;	state Exp;
branches;
next	1.127;

1.127
date	2012.08.18.20.52.36;	author eric;	state Exp;
branches;
next	1.126;

1.126
date	2012.08.18.18.18.23;	author gilles;	state Exp;
branches;
next	1.125;

1.125
date	2012.08.11.19.18.36;	author chl;	state Exp;
branches;
next	1.124;

1.124
date	2012.08.09.16.00.31;	author eric;	state Exp;
branches;
next	1.123;

1.123
date	2012.08.09.09.48.02;	author eric;	state Exp;
branches;
next	1.122;

1.122
date	2012.08.08.08.50.42;	author eric;	state Exp;
branches;
next	1.121;

1.121
date	2012.07.09.09.57.53;	author gilles;	state Exp;
branches;
next	1.120;

1.120
date	2012.07.08.18.13.08;	author chl;	state Exp;
branches;
next	1.119;

1.119
date	2012.06.20.20.45.23;	author eric;	state Exp;
branches;
next	1.118;

1.118
date	2012.06.18.10.21.16;	author chl;	state Exp;
branches;
next	1.117;

1.117
date	2012.01.28.11.33.07;	author gilles;	state Exp;
branches;
next	1.116;

1.116
date	2012.01.13.21.58.35;	author eric;	state Exp;
branches;
next	1.115;

1.115
date	2012.01.13.14.01.57;	author eric;	state Exp;
branches;
next	1.114;

1.114
date	2012.01.11.17.46.36;	author eric;	state Exp;
branches;
next	1.113;

1.113
date	2011.11.21.18.57.54;	author eric;	state Exp;
branches;
next	1.112;

1.112
date	2011.11.15.23.06.39;	author gilles;	state Exp;
branches;
next	1.111;

1.111
date	2011.11.14.19.23.41;	author chl;	state Exp;
branches;
next	1.110;

1.110
date	2011.11.07.11.14.10;	author eric;	state Exp;
branches;
next	1.109;

1.109
date	2011.10.26.20.47.31;	author gilles;	state Exp;
branches;
next	1.108;

1.108
date	2011.10.23.09.30.07;	author gilles;	state Exp;
branches;
next	1.107;

1.107
date	2011.10.09.18.39.53;	author eric;	state Exp;
branches;
next	1.106;

1.106
date	2011.09.01.19.56.49;	author eric;	state Exp;
branches;
next	1.105;

1.105
date	2011.08.29.18.49.29;	author chl;	state Exp;
branches;
next	1.104;

1.104
date	2011.05.16.21.05.52;	author gilles;	state Exp;
branches;
next	1.103;

1.103
date	2011.05.01.12.57.11;	author eric;	state Exp;
branches;
next	1.102;

1.102
date	2011.04.17.13.36.07;	author gilles;	state Exp;
branches;
next	1.101;

1.101
date	2011.04.17.11.39.22;	author gilles;	state Exp;
branches;
next	1.100;

1.100
date	2011.04.17.11.16.57;	author gilles;	state Exp;
branches;
next	1.99;

1.99
date	2011.04.15.17.01.05;	author gilles;	state Exp;
branches;
next	1.98;

1.98
date	2011.04.14.23.26.16;	author gilles;	state Exp;
branches;
next	1.97;

1.97
date	2011.04.14.22.36.09;	author gilles;	state Exp;
branches;
next	1.96;

1.96
date	2011.04.14.21.53.45;	author gilles;	state Exp;
branches;
next	1.95;

1.95
date	2011.04.13.20.53.18;	author gilles;	state Exp;
branches;
next	1.94;

1.94
date	2010.11.28.15.32.00;	author gilles;	state Exp;
branches;
next	1.93;

1.93
date	2010.11.28.14.35.58;	author gilles;	state Exp;
branches;
next	1.92;

1.92
date	2010.11.28.13.56.43;	author gilles;	state Exp;
branches;
next	1.91;

1.91
date	2010.10.09.22.05.35;	author gilles;	state Exp;
branches;
next	1.90;

1.90
date	2010.09.20.09.01.09;	author gilles;	state Exp;
branches;
next	1.89;

1.89
date	2010.07.23.22.23.24;	author gilles;	state Exp;
branches;
next	1.88;

1.88
date	2010.06.10.19.34.51;	author chl;	state Exp;
branches;
next	1.87;

1.87
date	2010.06.02.19.16.53;	author chl;	state Exp;
branches;
next	1.86;

1.86
date	2010.06.01.23.06.23;	author jacekm;	state Exp;
branches;
next	1.85;

1.85
date	2010.06.01.19.47.09;	author jacekm;	state Exp;
branches;
next	1.84;

1.84
date	2010.06.01.14.21.52;	author jacekm;	state Exp;
branches;
next	1.83;

1.83
date	2010.06.01.11.27.07;	author jacekm;	state Exp;
branches;
next	1.82;

1.82
date	2010.05.31.23.38.56;	author jacekm;	state Exp;
branches;
next	1.81;

1.81
date	2010.04.22.12.13.33;	author jacekm;	state Exp;
branches;
next	1.80;

1.80
date	2010.04.21.18.54.43;	author jacekm;	state Exp;
branches;
next	1.79;

1.79
date	2010.04.21.08.29.01;	author jacekm;	state Exp;
branches;
next	1.78;

1.78
date	2010.04.20.15.34.56;	author jacekm;	state Exp;
branches;
next	1.77;

1.77
date	2010.01.03.14.37.37;	author chl;	state Exp;
branches;
next	1.76;

1.76
date	2009.12.14.19.56.55;	author jacekm;	state Exp;
branches;
next	1.75;

1.75
date	2009.12.14.16.44.14;	author jacekm;	state Exp;
branches;
next	1.74;

1.74
date	2009.12.13.22.02.55;	author jacekm;	state Exp;
branches;
next	1.73;

1.73
date	2009.11.08.21.40.05;	author gilles;	state Exp;
branches;
next	1.72;

1.72
date	2009.11.01.22.15.27;	author gilles;	state Exp;
branches;
next	1.71;

1.71
date	2009.10.12.22.34.37;	author gilles;	state Exp;
branches;
next	1.70;

1.70
date	2009.09.15.16.50.06;	author jacekm;	state Exp;
branches;
next	1.69;

1.69
date	2009.09.03.08.19.13;	author jacekm;	state Exp;
branches;
next	1.68;

1.68
date	2009.06.06.04.14.21;	author pyr;	state Exp;
branches;
next	1.67;

1.67
date	2009.06.05.20.43.57;	author pyr;	state Exp;
branches;
next	1.66;

1.66
date	2009.06.01.13.20.56;	author jacekm;	state Exp;
branches;
next	1.65;

1.65
date	2009.05.24.14.38.56;	author jacekm;	state Exp;
branches;
next	1.64;

1.64
date	2009.05.24.14.22.23;	author jacekm;	state Exp;
branches;
next	1.63;

1.63
date	2009.05.19.11.24.24;	author jacekm;	state Exp;
branches;
next	1.62;

1.62
date	2009.05.14.15.05.12;	author eric;	state Exp;
branches;
next	1.61;

1.61
date	2009.04.21.14.37.32;	author eric;	state Exp;
branches;
next	1.60;

1.60
date	2009.04.18.21.01.20;	author jacekm;	state Exp;
branches;
next	1.59;

1.59
date	2009.04.16.15.35.06;	author jacekm;	state Exp;
branches;
next	1.58;

1.58
date	2009.03.29.14.18.20;	author jacekm;	state Exp;
branches;
next	1.57;

1.57
date	2009.03.01.12.12.58;	author jacekm;	state Exp;
branches;
next	1.56;

1.56
date	2009.02.22.19.07.33;	author chl;	state Exp;
branches;
next	1.55;

1.55
date	2009.02.20.18.47.53;	author jacekm;	state Exp;
branches;
next	1.54;

1.54
date	2009.02.15.10.32.23;	author jacekm;	state Exp;
branches;
next	1.53;

1.53
date	2009.01.29.21.59.15;	author jacekm;	state Exp;
branches;
next	1.52;

1.52
date	2009.01.29.12.43.25;	author jacekm;	state Exp;
branches;
next	1.51;

1.51
date	2009.01.28.17.29.11;	author jacekm;	state Exp;
branches;
next	1.50;

1.50
date	2009.01.28.12.58.17;	author gilles;	state Exp;
branches;
next	1.49;

1.49
date	2009.01.28.11.27.57;	author gilles;	state Exp;
branches;
next	1.48;

1.48
date	2009.01.27.22.48.29;	author gilles;	state Exp;
branches;
next	1.47;

1.47
date	2009.01.26.22.20.31;	author gilles;	state Exp;
branches;
next	1.46;

1.46
date	2009.01.26.21.26.07;	author gilles;	state Exp;
branches;
next	1.45;

1.45
date	2009.01.12.19.54.37;	author jacekm;	state Exp;
branches;
next	1.44;

1.44
date	2009.01.06.20.17.23;	author jacekm;	state Exp;
branches;
next	1.43;

1.43
date	2009.01.04.00.58.59;	author gilles;	state Exp;
branches;
next	1.42;

1.42
date	2009.01.02.22.08.02;	author jacekm;	state Exp;
branches;
next	1.41;

1.41
date	2009.01.02.19.52.53;	author jacekm;	state Exp;
branches;
next	1.40;

1.40
date	2009.01.01.16.15.47;	author jacekm;	state Exp;
branches;
next	1.39;

1.39
date	2008.12.31.09.55.24;	author jacekm;	state Exp;
branches;
next	1.38;

1.38
date	2008.12.31.09.50.40;	author jacekm;	state Exp;
branches;
next	1.37;

1.37
date	2008.12.31.09.47.11;	author jacekm;	state Exp;
branches;
next	1.36;

1.36
date	2008.12.29.09.03.25;	author jacekm;	state Exp;
branches;
next	1.35;

1.35
date	2008.12.27.18.18.33;	author jacekm;	state Exp;
branches;
next	1.34;

1.34
date	2008.12.27.17.36.37;	author jacekm;	state Exp;
branches;
next	1.33;

1.33
date	2008.12.27.17.12.39;	author jacekm;	state Exp;
branches;
next	1.32;

1.32
date	2008.12.27.17.03.29;	author jacekm;	state Exp;
branches;
next	1.31;

1.31
date	2008.12.18.15.11.21;	author jacekm;	state Exp;
branches;
next	1.30;

1.30
date	2008.12.17.18.47.37;	author jacekm;	state Exp;
branches;
next	1.29;

1.29
date	2008.12.14.19.27.47;	author jacekm;	state Exp;
branches;
next	1.28;

1.28
date	2008.12.14.19.24.42;	author jacekm;	state Exp;
branches;
next	1.27;

1.27
date	2008.12.14.19.20.59;	author jacekm;	state Exp;
branches;
next	1.26;

1.26
date	2008.12.14.19.16.06;	author jacekm;	state Exp;
branches;
next	1.25;

1.25
date	2008.12.13.23.19.34;	author jacekm;	state Exp;
branches;
next	1.24;

1.24
date	2008.12.11.23.19.00;	author gilles;	state Exp;
branches;
next	1.23;

1.23
date	2008.12.11.23.17.25;	author gilles;	state Exp;
branches;
next	1.22;

1.22
date	2008.12.07.16.00.07;	author jacekm;	state Exp;
branches;
next	1.21;

1.21
date	2008.12.06.23.49.40;	author jacekm;	state Exp;
branches;
next	1.20;

1.20
date	2008.12.06.14.30.51;	author jacekm;	state Exp;
branches;
next	1.19;

1.19
date	2008.12.05.02.51.32;	author gilles;	state Exp;
branches;
next	1.18;

1.18
date	2008.12.03.20.08.08;	author gilles;	state Exp;
branches;
next	1.17;

1.17
date	2008.12.03.17.58.00;	author gilles;	state Exp;
branches;
next	1.16;

1.16
date	2008.11.25.20.26.40;	author gilles;	state Exp;
branches;
next	1.15;

1.15
date	2008.11.24.23.55.25;	author gilles;	state Exp;
branches;
next	1.14;

1.14
date	2008.11.17.21.05.05;	author gilles;	state Exp;
branches;
next	1.13;

1.13
date	2008.11.17.21.03.33;	author gilles;	state Exp;
branches;
next	1.12;

1.12
date	2008.11.17.20.37.48;	author gilles;	state Exp;
branches;
next	1.11;

1.11
date	2008.11.11.21.17.49;	author gilles;	state Exp;
branches;
next	1.10;

1.10
date	2008.11.11.21.13.14;	author gilles;	state Exp;
branches;
next	1.9;

1.9
date	2008.11.11.01.08.08;	author gilles;	state Exp;
branches;
next	1.8;

1.8
date	2008.11.11.01.01.39;	author chl;	state Exp;
branches;
next	1.7;

1.7
date	2008.11.10.21.29.18;	author chl;	state Exp;
branches;
next	1.6;

1.6
date	2008.11.10.17.24.24;	author deraadt;	state Exp;
branches;
next	1.5;

1.5
date	2008.11.10.03.16.02;	author gilles;	state Exp;
branches;
next	1.4;

1.4
date	2008.11.10.01.14.05;	author gilles;	state Exp;
branches;
next	1.3;

1.3
date	2008.11.10.00.57.35;	author gilles;	state Exp;
branches;
next	1.2;

1.2
date	2008.11.05.12.14.45;	author sobrado;	state Exp;
branches;
next	1.1;

1.1
date	2008.11.01.21.35.28;	author gilles;	state Exp;
branches;
next	;


desc
@@


1.183
log
@smtpd joins the 7 other daemons that share the same log.c file.

The only major difference was the "log_trace" concept that is only
used by smtpd - move it from log.c into util.c and make it a local
concept.  This also needed to rename the global "verbose" variable to
"tracing" in a few places.

OK krw@@ gilles@@ eric@@
@
text
@/*	$OpenBSD: queue.c,v 1.182 2016/09/08 12:06:43 eric Exp $	*/

/*
 * Copyright (c) 2008 Gilles Chehade <gilles@@poolp.org>
 * Copyright (c) 2008 Pierre-Yves Ritschard <pyr@@openbsd.org>
 * Copyright (c) 2012 Eric Faurot <eric@@openbsd.org>
 *
 * Permission to use, copy, modify, and distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 */

#include <sys/types.h>
#include <sys/queue.h>
#include <sys/tree.h>
#include <sys/socket.h>
#include <sys/stat.h>

#include <err.h>
#include <event.h>
#include <imsg.h>
#include <inttypes.h>
#include <libgen.h>
#include <pwd.h>
#include <signal.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <time.h>
#include <unistd.h>
#include <limits.h>

#include "smtpd.h"
#include "log.h"

static void queue_imsg(struct mproc *, struct imsg *);
static void queue_timeout(int, short, void *);
static void queue_bounce(struct envelope *, struct delivery_bounce *);
static void queue_shutdown(void);
static void queue_log(const struct envelope *, const char *, const char *);
static void queue_msgid_walk(int, short, void *);


static void
queue_imsg(struct mproc *p, struct imsg *imsg)
{
	struct delivery_bounce	 bounce;
	struct msg_walkinfo	*wi;
	struct timeval		 tv;
	struct bounce_req_msg	*req_bounce;
	struct envelope		 evp;
	struct msg		 m;
	const char		*reason;
	uint64_t		 reqid, evpid, holdq;
	uint32_t		 msgid;
	time_t			 nexttry;
	size_t			 n_evp;
	int			 fd, mta_ext, ret, v, flags, code;

	if (imsg == NULL)
		queue_shutdown();

	memset(&bounce, 0, sizeof(struct delivery_bounce));
	if (p->proc == PROC_PONY) {

		switch (imsg->hdr.type) {
		case IMSG_SMTP_MESSAGE_CREATE:
			m_msg(&m, imsg);
			m_get_id(&m, &reqid);
			m_end(&m);

			ret = queue_message_create(&msgid);

			m_create(p, IMSG_SMTP_MESSAGE_CREATE, 0, 0, -1);
			m_add_id(p, reqid);
			if (ret == 0)
				m_add_int(p, 0);
			else {
				m_add_int(p, 1);
				m_add_msgid(p, msgid);
			}
			m_close(p);
			return;

		case IMSG_SMTP_MESSAGE_ROLLBACK:
			m_msg(&m, imsg);
			m_get_msgid(&m, &msgid);
			m_end(&m);

			queue_message_delete(msgid);

			m_create(p_scheduler, IMSG_QUEUE_MESSAGE_ROLLBACK,
			    0, 0, -1);
			m_add_msgid(p_scheduler, msgid);
			m_close(p_scheduler);
			return;

		case IMSG_SMTP_MESSAGE_COMMIT:
			m_msg(&m, imsg);
			m_get_id(&m, &reqid);
			m_get_msgid(&m, &msgid);
			m_end(&m);

			ret = queue_message_commit(msgid);

			m_create(p, IMSG_SMTP_MESSAGE_COMMIT, 0, 0, -1);
			m_add_id(p, reqid);
			m_add_int(p, (ret == 0) ? 0 : 1);
			m_close(p);

			if (ret) {
				m_create(p_scheduler, IMSG_QUEUE_MESSAGE_COMMIT,
				    0, 0, -1);
				m_add_msgid(p_scheduler, msgid);
				m_close(p_scheduler);
			}
			return;

		case IMSG_SMTP_MESSAGE_OPEN:
			m_msg(&m, imsg);
			m_get_id(&m, &reqid);
			m_get_msgid(&m, &msgid);
			m_end(&m);

			fd = queue_message_fd_rw(msgid);

			m_create(p, IMSG_SMTP_MESSAGE_OPEN, 0, 0, fd);
			m_add_id(p, reqid);
			m_add_int(p, (fd == -1) ? 0 : 1);
			m_close(p);
			return;

		case IMSG_QUEUE_SMTP_SESSION:
			bounce_fd(imsg->fd);
			return;
		}
	}

	if (p->proc == PROC_LKA) {
		switch (imsg->hdr.type) {
		case IMSG_LKA_ENVELOPE_SUBMIT:
			m_msg(&m, imsg);
			m_get_id(&m, &reqid);
			m_get_envelope(&m, &evp);
			m_end(&m);

			if (evp.id == 0)
				log_warnx("warn: imsg_queue_submit_envelope: evpid=0");
			if (evpid_to_msgid(evp.id) == 0)
				log_warnx("warn: imsg_queue_submit_envelope: msgid=0, "
				    "evpid=%016"PRIx64, evp.id);
			ret = queue_envelope_create(&evp);
			m_create(p_pony, IMSG_QUEUE_ENVELOPE_SUBMIT, 0, 0, -1);
			m_add_id(p_pony, reqid);
			if (ret == 0)
				m_add_int(p_pony, 0);
			else {
				m_add_int(p_pony, 1);
				m_add_evpid(p_pony, evp.id);
			}
			m_close(p_pony);
			if (ret) {
				m_create(p_scheduler,
				    IMSG_QUEUE_ENVELOPE_SUBMIT, 0, 0, -1);
				m_add_envelope(p_scheduler, &evp);
				m_close(p_scheduler);

			}
			return;

		case IMSG_LKA_ENVELOPE_COMMIT:
			m_msg(&m, imsg);
			m_get_id(&m, &reqid);
			m_end(&m);
			m_create(p_pony, IMSG_QUEUE_ENVELOPE_COMMIT, 0, 0, -1);
			m_add_id(p_pony, reqid);
			m_add_int(p_pony, 1);
			m_close(p_pony);
			return;
		}
	}

	if (p->proc == PROC_SCHEDULER) {
		switch (imsg->hdr.type) {
		case IMSG_SCHED_ENVELOPE_REMOVE:
			m_msg(&m, imsg);
			m_get_evpid(&m, &evpid);
			m_end(&m);

			m_create(p_scheduler, IMSG_QUEUE_ENVELOPE_ACK, 0, 0, -1);
			m_add_evpid(p_scheduler, evpid);
			m_close(p_scheduler);

			/* already removed by scheduler */
			if (queue_envelope_load(evpid, &evp) == 0)
				return;

			queue_log(&evp, "Remove", "Removed by administrator");
			queue_envelope_delete(evpid);
			return;

		case IMSG_SCHED_ENVELOPE_EXPIRE:
			m_msg(&m, imsg);
			m_get_evpid(&m, &evpid);
			m_end(&m);

			m_create(p_scheduler, IMSG_QUEUE_ENVELOPE_ACK, 0, 0, -1);
			m_add_evpid(p_scheduler, evpid);
			m_close(p_scheduler);

			/* already removed by scheduler*/
			if (queue_envelope_load(evpid, &evp) == 0)
				return;

			bounce.type = B_ERROR;
			envelope_set_errormsg(&evp, "Envelope expired");
			envelope_set_esc_class(&evp, ESC_STATUS_TEMPFAIL);
			envelope_set_esc_code(&evp, ESC_DELIVERY_TIME_EXPIRED);
			queue_bounce(&evp, &bounce);
			queue_log(&evp, "Expire", "Envelope expired");
			queue_envelope_delete(evpid);
			return;

		case IMSG_SCHED_ENVELOPE_BOUNCE:
			CHECK_IMSG_DATA_SIZE(imsg, sizeof *req_bounce);
			req_bounce = imsg->data;
			evpid = req_bounce->evpid;

			if (queue_envelope_load(evpid, &evp) == 0) {
				log_warnx("queue: bounce: failed to load envelope");
				m_create(p_scheduler, IMSG_QUEUE_ENVELOPE_REMOVE, 0, 0, -1);
				m_add_evpid(p_scheduler, evpid);
				m_add_u32(p_scheduler, 0); /* not in-flight */
				m_close(p_scheduler);
				return;
			}
			queue_bounce(&evp, &req_bounce->bounce);
			evp.lastbounce = req_bounce->timestamp;
			if (!queue_envelope_update(&evp))
				log_warnx("warn: could not update envelope %016"PRIx64, evpid);
			return;

		case IMSG_SCHED_ENVELOPE_DELIVER:
			m_msg(&m, imsg);
			m_get_evpid(&m, &evpid);
			m_end(&m);
			if (queue_envelope_load(evpid, &evp) == 0) {
				log_warnx("queue: deliver: failed to load envelope");
				m_create(p_scheduler, IMSG_QUEUE_ENVELOPE_REMOVE, 0, 0, -1);
				m_add_evpid(p_scheduler, evpid);
				m_add_u32(p_scheduler, 1); /* in-flight */
				m_close(p_scheduler);
				return;
			}
			evp.lasttry = time(NULL);
			m_create(p_pony, IMSG_QUEUE_DELIVER, 0, 0, -1);
			m_add_envelope(p_pony, &evp);
			m_close(p_pony);
			return;

		case IMSG_SCHED_ENVELOPE_INJECT:
			m_msg(&m, imsg);
			m_get_evpid(&m, &evpid);
			m_end(&m);
			bounce_add(evpid);
			return;

		case IMSG_SCHED_ENVELOPE_TRANSFER:
			m_msg(&m, imsg);
			m_get_evpid(&m, &evpid);
			m_end(&m);
			if (queue_envelope_load(evpid, &evp) == 0) {
				log_warnx("queue: failed to load envelope");
				m_create(p_scheduler, IMSG_QUEUE_ENVELOPE_REMOVE, 0, 0, -1);
				m_add_evpid(p_scheduler, evpid);
				m_add_u32(p_scheduler, 1); /* in-flight */
				m_close(p_scheduler);
				return;
			}
			evp.lasttry = time(NULL);
			m_create(p_pony, IMSG_QUEUE_TRANSFER, 0, 0, -1);
			m_add_envelope(p_pony, &evp);
			m_close(p_pony);
			return;

		case IMSG_CTL_LIST_ENVELOPES:
			if (imsg->hdr.len == sizeof imsg->hdr) {
				m_forward(p_control, imsg);
				return;
			}

			m_msg(&m, imsg);
			m_get_evpid(&m, &evpid);
			m_get_int(&m, &flags);
			m_get_time(&m, &nexttry);
			m_end(&m);

			if (queue_envelope_load(evpid, &evp) == 0)
				return; /* Envelope is gone, drop it */

			/*
			 * XXX consistency: The envelope might already be on
			 * its way back to the scheduler.  We need to detect
			 * this properly and report that state.
			 */
			if (flags & EF_INFLIGHT) {
				/*
				 * Not exactly correct but pretty close: The
				 * value is not recorded on the envelope unless
				 * a tempfail occurs.
				 */
				evp.lasttry = nexttry;
			}

			m_create(p_control, IMSG_CTL_LIST_ENVELOPES,
			    imsg->hdr.peerid, 0, -1);
			m_add_int(p_control, flags);
			m_add_time(p_control, nexttry);
			m_add_envelope(p_control, &evp);
			m_close(p_control);
			return;
		}
	}

	if (p->proc == PROC_PONY) {
		switch (imsg->hdr.type) {
		case IMSG_MDA_OPEN_MESSAGE:
		case IMSG_MTA_OPEN_MESSAGE:
			m_msg(&m, imsg);
			m_get_id(&m, &reqid);
			m_get_msgid(&m, &msgid);
			m_end(&m);
			fd = queue_message_fd_r(msgid);
			m_create(p, imsg->hdr.type, 0, 0, fd);
			m_add_id(p, reqid);
			m_close(p);
			return;

		case IMSG_MDA_DELIVERY_OK:
		case IMSG_MTA_DELIVERY_OK:
			m_msg(&m, imsg);
			m_get_evpid(&m, &evpid);
			if (imsg->hdr.type == IMSG_MTA_DELIVERY_OK)
				m_get_int(&m, &mta_ext);
			m_end(&m);
			if (queue_envelope_load(evpid, &evp) == 0) {
				log_warn("queue: dsn: failed to load envelope");
				return;
			}
			if (evp.dsn_notify & DSN_SUCCESS) {
				bounce.type = B_DSN;
				bounce.dsn_ret = evp.dsn_ret;
				envelope_set_esc_class(&evp, ESC_STATUS_OK);
				if (imsg->hdr.type == IMSG_MDA_DELIVERY_OK)
					queue_bounce(&evp, &bounce);
				else if (imsg->hdr.type == IMSG_MTA_DELIVERY_OK &&
				    (mta_ext & MTA_EXT_DSN) == 0) {
					bounce.mta_without_dsn = 1;
					queue_bounce(&evp, &bounce);
				}
			}
			queue_envelope_delete(evpid);
			m_create(p_scheduler, IMSG_QUEUE_DELIVERY_OK, 0, 0, -1);
			m_add_evpid(p_scheduler, evpid);
			m_close(p_scheduler);
			return;

		case IMSG_MDA_DELIVERY_TEMPFAIL:
		case IMSG_MTA_DELIVERY_TEMPFAIL:
			m_msg(&m, imsg);
			m_get_evpid(&m, &evpid);
			m_get_string(&m, &reason);
			m_get_int(&m, &code);
			m_end(&m);
			if (queue_envelope_load(evpid, &evp) == 0) {
				log_warnx("queue: tempfail: failed to load envelope");
				m_create(p_scheduler, IMSG_QUEUE_ENVELOPE_REMOVE, 0, 0, -1);
				m_add_evpid(p_scheduler, evpid);
				m_add_u32(p_scheduler, 1); /* in-flight */
				m_close(p_scheduler);
				return;
			}
			envelope_set_errormsg(&evp, "%s", reason);
			envelope_set_esc_class(&evp, ESC_STATUS_TEMPFAIL);
			envelope_set_esc_code(&evp, code);
			evp.retry++;
			if (!queue_envelope_update(&evp))
				log_warnx("warn: could not update envelope %016"PRIx64, evpid);
			m_create(p_scheduler, IMSG_QUEUE_DELIVERY_TEMPFAIL, 0, 0, -1);
			m_add_envelope(p_scheduler, &evp);
			m_close(p_scheduler);
			return;

		case IMSG_MDA_DELIVERY_PERMFAIL:
		case IMSG_MTA_DELIVERY_PERMFAIL:
			m_msg(&m, imsg);
			m_get_evpid(&m, &evpid);
			m_get_string(&m, &reason);
			m_get_int(&m, &code);
			m_end(&m);
			if (queue_envelope_load(evpid, &evp) == 0) {
				log_warnx("queue: permfail: failed to load envelope");
				m_create(p_scheduler, IMSG_QUEUE_ENVELOPE_REMOVE, 0, 0, -1);
				m_add_evpid(p_scheduler, evpid);
				m_add_u32(p_scheduler, 1); /* in-flight */
				m_close(p_scheduler);
				return;
			}
			bounce.type = B_ERROR;
			envelope_set_errormsg(&evp, "%s", reason);
			envelope_set_esc_class(&evp, ESC_STATUS_PERMFAIL);
			envelope_set_esc_code(&evp, code);
			queue_bounce(&evp, &bounce);
			queue_envelope_delete(evpid);
			m_create(p_scheduler, IMSG_QUEUE_DELIVERY_PERMFAIL, 0, 0, -1);
			m_add_evpid(p_scheduler, evpid);
			m_close(p_scheduler);
			return;

		case IMSG_MDA_DELIVERY_LOOP:
		case IMSG_MTA_DELIVERY_LOOP:
			m_msg(&m, imsg);
			m_get_evpid(&m, &evpid);
			m_end(&m);
			if (queue_envelope_load(evpid, &evp) == 0) {
				log_warnx("queue: loop: failed to load envelope");
				m_create(p_scheduler, IMSG_QUEUE_ENVELOPE_REMOVE, 0, 0, -1);
				m_add_evpid(p_scheduler, evpid);
				m_add_u32(p_scheduler, 1); /* in-flight */
				m_close(p_scheduler);
				return;
			}
			envelope_set_errormsg(&evp, "%s", "Loop detected");
			envelope_set_esc_class(&evp, ESC_STATUS_TEMPFAIL);
			envelope_set_esc_code(&evp, ESC_ROUTING_LOOP_DETECTED);
			bounce.type = B_ERROR;
			queue_bounce(&evp, &bounce);
			queue_envelope_delete(evp.id);
			m_create(p_scheduler, IMSG_QUEUE_DELIVERY_LOOP, 0, 0, -1);
			m_add_evpid(p_scheduler, evp.id);
			m_close(p_scheduler);
			return;

		case IMSG_MTA_DELIVERY_HOLD:
		case IMSG_MDA_DELIVERY_HOLD:
			imsg->hdr.type = IMSG_QUEUE_HOLDQ_HOLD;
			m_forward(p_scheduler, imsg);
			return;

		case IMSG_MTA_SCHEDULE:
			imsg->hdr.type = IMSG_QUEUE_ENVELOPE_SCHEDULE;
			m_forward(p_scheduler, imsg);
			return;

		case IMSG_MTA_HOLDQ_RELEASE:
		case IMSG_MDA_HOLDQ_RELEASE:
			m_msg(&m, imsg);
			m_get_id(&m, &holdq);
			m_get_int(&m, &v);
			m_end(&m);
			m_create(p_scheduler, IMSG_QUEUE_HOLDQ_RELEASE, 0, 0, -1);
			if (imsg->hdr.type == IMSG_MTA_HOLDQ_RELEASE)
				m_add_int(p_scheduler, D_MTA);
			else
				m_add_int(p_scheduler, D_MDA);
			m_add_id(p_scheduler, holdq);
			m_add_int(p_scheduler, v);
			m_close(p_scheduler);
			return;
		}
	}

	if (p->proc == PROC_CONTROL) {
		switch (imsg->hdr.type) {
		case IMSG_CTL_PAUSE_MDA:
		case IMSG_CTL_PAUSE_MTA:
		case IMSG_CTL_RESUME_MDA:
		case IMSG_CTL_RESUME_MTA:
			m_forward(p_scheduler, imsg);
			return;

		case IMSG_CTL_VERBOSE:
			m_msg(&m, imsg);
			m_get_int(&m, &v);
			m_end(&m);
			log_trace_verbose(v);
			return;

		case IMSG_CTL_PROFILE:
			m_msg(&m, imsg);
			m_get_int(&m, &v);
			m_end(&m);
			profiling = v;
			return;

		case IMSG_CTL_DISCOVER_EVPID:
			m_msg(&m, imsg);
			m_get_evpid(&m, &evpid);
			m_end(&m);
			if (queue_envelope_load(evpid, &evp) == 0) {
				log_warnx("queue: discover: failed to load "
				    "envelope %016" PRIx64, evpid);
				n_evp = 0;
				m_compose(p_control, imsg->hdr.type,
				    imsg->hdr.peerid, 0, -1,
				    &n_evp, sizeof n_evp);
				return;
			}

			m_create(p_scheduler, IMSG_QUEUE_DISCOVER_EVPID,
			    0, 0, -1);
			m_add_envelope(p_scheduler, &evp);
			m_close(p_scheduler);

			m_create(p_scheduler, IMSG_QUEUE_DISCOVER_MSGID,
			    0, 0, -1);
			m_add_msgid(p_scheduler, evpid_to_msgid(evpid));
			m_close(p_scheduler);
			n_evp = 1;
			m_compose(p_control, imsg->hdr.type, imsg->hdr.peerid,
			    0, -1, &n_evp, sizeof n_evp);
			return;

		case IMSG_CTL_DISCOVER_MSGID:
			m_msg(&m, imsg);
			m_get_msgid(&m, &msgid);
			m_end(&m);
			/* handle concurrent walk requests */
			wi = xcalloc(1, sizeof *wi, "queu_imsg");
			wi->msgid = msgid;
			wi->peerid = imsg->hdr.peerid;
			evtimer_set(&wi->ev, queue_msgid_walk, wi);
			tv.tv_sec = 0;
			tv.tv_usec = 10;
			evtimer_add(&wi->ev, &tv);
			return;

		case IMSG_CTL_UNCORRUPT_MSGID:
			m_msg(&m, imsg);
			m_get_msgid(&m, &msgid);
			m_end(&m);
			ret = queue_message_uncorrupt(msgid);
			m_compose(p_control, imsg->hdr.type, imsg->hdr.peerid,
			    0, -1, &ret, sizeof ret);
			return;
		}
	}

	errx(1, "queue_imsg: unexpected %s imsg", imsg_to_str(imsg->hdr.type));
}

static void
queue_msgid_walk(int fd, short event, void *arg)
{
	struct envelope		 evp;
	struct timeval		 tv;
	struct msg_walkinfo	*wi = arg;
	int			 r;

	r = queue_message_walk(&evp, wi->msgid, &wi->done, &wi->data);
	if (r == -1) {
		if (wi->n_evp) {
			m_create(p_scheduler, IMSG_QUEUE_DISCOVER_MSGID,
			    0, 0, -1);
			m_add_msgid(p_scheduler, wi->msgid);
			m_close(p_scheduler);
		}

		m_compose(p_control, IMSG_CTL_DISCOVER_MSGID, wi->peerid, 0, -1,
		    &wi->n_evp, sizeof wi->n_evp);
		evtimer_del(&wi->ev);
		free(wi);
		return;
	}

	if (r) {
		m_create(p_scheduler, IMSG_QUEUE_DISCOVER_EVPID, 0, 0, -1);
		m_add_envelope(p_scheduler, &evp);
		m_close(p_scheduler);
		wi->n_evp += 1;
	}

	tv.tv_sec = 0;
	tv.tv_usec = 10;
	evtimer_set(&wi->ev, queue_msgid_walk, wi);
	evtimer_add(&wi->ev, &tv);
}

static void
queue_bounce(struct envelope *e, struct delivery_bounce *d)
{
	struct envelope	b;

	b = *e;
	b.type = D_BOUNCE;
	b.agent.bounce = *d;
	b.retry = 0;
	b.lasttry = 0;
	b.creation = time(NULL);
	b.expire = 3600 * 24 * 7;

	if (e->dsn_notify & DSN_NEVER)
		return;

	if (b.id == 0)
		log_warnx("warn: queue_bounce: evpid=0");
	if (evpid_to_msgid(b.id) == 0)
		log_warnx("warn: queue_bounce: msgid=0, evpid=%016"PRIx64,
			b.id);
	if (e->type == D_BOUNCE) {
		log_warnx("warn: queue: double bounce!");
	} else if (e->sender.user[0] == '\0') {
		log_warnx("warn: queue: no return path!");
	} else if (!queue_envelope_create(&b)) {
		log_warnx("warn: queue: cannot bounce!");
	} else {
		log_debug("debug: queue: bouncing evp:%016" PRIx64
		    " as evp:%016" PRIx64, e->id, b.id);

		m_create(p_scheduler, IMSG_QUEUE_ENVELOPE_SUBMIT, 0, 0, -1);
		m_add_envelope(p_scheduler, &b);
		m_close(p_scheduler);

		m_create(p_scheduler, IMSG_QUEUE_MESSAGE_COMMIT, 0, 0, -1);
		m_add_msgid(p_scheduler, evpid_to_msgid(b.id));
		m_close(p_scheduler);

		stat_increment("queue.bounce", 1);
	}
}

static void
queue_shutdown(void)
{
	log_debug("debug: queue agent exiting");
	queue_close();
	_exit(0);
}

int
queue(void)
{
	struct passwd	*pw;
	struct timeval	 tv;
	struct event	 ev_qload;

	purge_config(PURGE_EVERYTHING);

	if ((pw = getpwnam(SMTPD_QUEUE_USER)) == NULL)
		if ((pw = getpwnam(SMTPD_USER)) == NULL)
			fatalx("unknown user " SMTPD_USER);

	env->sc_queue_flags |= QUEUE_EVPCACHE;
	env->sc_queue_evpcache_size = 1024;

	if (chroot(PATH_SPOOL) == -1)
		fatal("queue: chroot");
	if (chdir("/") == -1)
		fatal("queue: chdir(\"/\")");

	config_process(PROC_QUEUE);

	if (env->sc_queue_flags & QUEUE_COMPRESSION)
		log_info("queue: queue compression enabled");

	if (env->sc_queue_key) {
		if (!crypto_setup(env->sc_queue_key, strlen(env->sc_queue_key)))
			fatalx("crypto_setup: invalid key for queue encryption");
		log_info("queue: queue encryption enabled");
	}

	if (setgroups(1, &pw->pw_gid) ||
	    setresgid(pw->pw_gid, pw->pw_gid, pw->pw_gid) ||
	    setresuid(pw->pw_uid, pw->pw_uid, pw->pw_uid))
		fatal("queue: cannot drop privileges");

	imsg_callback = queue_imsg;
	event_init();

	signal(SIGINT, SIG_IGN);
	signal(SIGTERM, SIG_IGN);
	signal(SIGPIPE, SIG_IGN);
	signal(SIGHUP, SIG_IGN);

	config_peer(PROC_PARENT);
	config_peer(PROC_CONTROL);
	config_peer(PROC_LKA);
	config_peer(PROC_SCHEDULER);
	config_peer(PROC_PONY);

	/* setup queue loading task */
	evtimer_set(&ev_qload, queue_timeout, &ev_qload);
	tv.tv_sec = 0;
	tv.tv_usec = 10;
	evtimer_add(&ev_qload, &tv);

	if (pledge("stdio rpath wpath cpath flock recvfd sendfd", NULL) == -1)
		err(1, "pledge");

	event_dispatch();
	fatalx("exited event loop");

	return (0);
}

static void
queue_timeout(int fd, short event, void *p)
{
	static uint32_t	 msgid = 0;
	struct envelope	 evp;
	struct event	*ev = p;
	struct timeval	 tv;
	int		 r;

	r = queue_envelope_walk(&evp);
	if (r == -1) {
		if (msgid) {
			m_create(p_scheduler, IMSG_QUEUE_MESSAGE_COMMIT,
			    0, 0, -1);
			m_add_msgid(p_scheduler, msgid);
			m_close(p_scheduler);
		}
		log_debug("debug: queue: done loading queue into scheduler");
		return;
	}

	if (r) {
		if (msgid && evpid_to_msgid(evp.id) != msgid) {
			m_create(p_scheduler, IMSG_QUEUE_MESSAGE_COMMIT,
			    0, 0, -1);
			m_add_msgid(p_scheduler, msgid);
			m_close(p_scheduler);
		}
		msgid = evpid_to_msgid(evp.id);
		m_create(p_scheduler, IMSG_QUEUE_ENVELOPE_SUBMIT, 0, 0, -1);
		m_add_envelope(p_scheduler, &evp);
		m_close(p_scheduler);
	}

	tv.tv_sec = 0;
	tv.tv_usec = 10;
	evtimer_add(ev, &tv);
}

static void
queue_log(const struct envelope *e, const char *prefix, const char *status)
{
	char rcpt[LINE_MAX];

	(void)strlcpy(rcpt, "-", sizeof rcpt);
	if (strcmp(e->rcpt.user, e->dest.user) ||
	    strcmp(e->rcpt.domain, e->dest.domain))
		(void)snprintf(rcpt, sizeof rcpt, "%s@@%s",
		    e->rcpt.user, e->rcpt.domain);

	log_info("%s: %s for %016" PRIx64 ": from=<%s@@%s>, to=<%s@@%s>, "
	    "rcpt=<%s>, delay=%s, stat=%s",
	    e->type == D_MDA ? "delivery" : "relay",
	    prefix,
	    e->id, e->sender.user, e->sender.domain,
	    e->dest.user, e->dest.domain,
	    rcpt,
	    duration_to_text(time(NULL) - e->creation),
	    status);
}
@


1.182
log
@Streamline the daemon shutdown sequence.

Only the parent process handles SIGTERM and SIGINT.  Upon receiving one
of those, it closes all imsg sockets and waitpid() for the children. It
fatal()s if one of the sockets is closed unexpectedly.  Other processes
exit() "normally" when one of the imsg sockets is closed.

ok gilles@@ sunil@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.181 2016/09/04 16:10:31 eric Exp $	*/
d494 1
a494 1
			log_verbose(v);
@


1.181
log
@The smtpd processes are not expected to ever leave their event loop.
So stop pretending that the *_shutdown() functions could ever be called
in this context, and just fatal() if event_dispatch() returns.

ok gilles@@ sunil@@ giovanni@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.180 2016/09/01 10:54:25 eric Exp $	*/
a47 1
static void queue_sig_handler(int, short, void *);
d68 3
a640 13
queue_sig_handler(int sig, short event, void *p)
{
	switch (sig) {
	case SIGINT:
	case SIGTERM:
		queue_shutdown();
		break;
	default:
		fatalx("queue_sig_handler: unexpected signal");
	}
}

static void
d643 1
a643 1
	log_info("info: queue handler exiting");
a653 2
	struct event	 ev_sigint;
	struct event	 ev_sigterm;
d688 2
a689 4
	signal_set(&ev_sigint, SIGINT, queue_sig_handler, NULL);
	signal_set(&ev_sigterm, SIGTERM, queue_sig_handler, NULL);
	signal_add(&ev_sigint, NULL);
	signal_add(&ev_sigterm, NULL);
@


1.180
log
@remove noop function

ok sunil@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.179 2016/08/31 21:49:01 eric Exp $	*/
d723 2
a724 3
	if (event_dispatch() <  0)
		fatal("event_dispatch");
	queue_shutdown();
@


1.179
log
@Remove dead code. queue_flow_control() has never been used and is
probably a bad idea.

ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.178 2016/05/28 21:21:20 eric Exp $	*/
a712 1
	config_done();
@


1.178
log
@Implement the fork+exec pattern in smtpd.

The parent process forks child processes and re-exec each of them with
an additional "-x <proc>" argument.  During the early setup phase, the
parent process sends ipc socket pairs to interconnect the child
processes as needed, and it passes the queue encryption key to the
queue if necessary. When this is done, all processes have their
environment set as in the fork-only case, and they can start doing
their work as before.

ok gilles@@ jung@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.177 2016/04/29 08:55:08 eric Exp $	*/
a51 9
static size_t	flow_agent_hiwat = 10 * 1024 * 1024;
static size_t	flow_agent_lowat =   1 * 1024 * 1024;
static size_t	flow_scheduler_hiwat = 10 * 1024 * 1024;
static size_t	flow_scheduler_lowat = 1 * 1024 * 1024;

#define LIMIT_AGENT	0x01
#define LIMIT_SCHEDULER	0x02

static int limit = 0;
a789 46
}

void
queue_flow_control(void)
{
	size_t	bufsz;
	int	oldlimit = limit;
	int	set, unset;

	bufsz = p_pony->bytes_queued;
	if (bufsz <= flow_agent_lowat)
		limit &= ~LIMIT_AGENT;
	else if (bufsz > flow_agent_hiwat)
		limit |= LIMIT_AGENT;

	if (p_scheduler->bytes_queued <= flow_scheduler_lowat)
		limit &= ~LIMIT_SCHEDULER;
	else if (p_scheduler->bytes_queued > flow_scheduler_hiwat)
		limit |= LIMIT_SCHEDULER;

	set = limit & (limit ^ oldlimit);
	unset = oldlimit & (limit ^ oldlimit);

	if (set & LIMIT_SCHEDULER) {
		log_warnx("warn: queue: Hiwat reached on scheduler buffer: "
		    "suspending transfer, delivery and lookup input");
		mproc_disable(p_pony);
		mproc_disable(p_lka);
	}
	else if (unset & LIMIT_SCHEDULER) {
		log_warnx("warn: queue: Down to lowat on scheduler buffer: "
		    "resuming transfer, delivery and lookup input");
		mproc_enable(p_pony);
		mproc_enable(p_lka);
	}

	if (set & LIMIT_AGENT) {
		log_warnx("warn: queue: Hiwat reached on transfer and delivery "
		    "buffers: suspending scheduler input");
		mproc_disable(p_scheduler);
	}
	else if (unset & LIMIT_AGENT) {
		log_warnx("warn: queue: Down to lowat on transfer and delivery "
		    "buffers: resuming scheduler input");
		mproc_enable(p_scheduler);
	}
@


1.177
log
@fix "smtpctl show queue" reporting "invalid" envelope state.
runtime state is not serialized with the envelope, so add it to the imsg.

ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.176 2016/01/27 12:46:03 sunil Exp $	*/
d668 1
a668 1
pid_t
a670 1
	pid_t		 pid;
a675 10

	switch (pid = fork()) {
	case -1:
		fatal("queue: cannot fork");
	case 0:
		post_fork(PROC_QUEUE);
		break;
	default:
		return (pid);
	}
@


1.176
log
@Check imsg data length before use.

Ok jung@@ gilles@@ eric@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.175 2015/12/28 22:08:30 jung Exp $	*/
d75 1
a75 1
	size_t			 buflen, id_sz, n_evp;
a76 1
	char			 buf[sizeof(evp)];
a320 3
			evp.flags |= flags;
			/* In the past if running or runnable */
			evp.nexttry = nexttry;
d330 6
a335 6
			id_sz = sizeof evp.id;
			(void)memcpy(buf, &evp.id, id_sz);
			buflen = envelope_dump_buffer(&evp, buf + id_sz,
			    sizeof(buf) - id_sz);
			m_compose(p_control, IMSG_CTL_LIST_ENVELOPES,
			    imsg->hdr.peerid, 0, -1, buf, id_sz + buflen + 1);
@


1.175
log
@remove spaces after '!'

no binary change

ok millert
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.174 2015/12/14 10:22:12 jung Exp $	*/
d241 1
@


1.174
log
@remove trailing whitespace

ok sunil gilles
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.173 2015/12/10 07:49:58 sunil Exp $	*/
d711 1
a711 1
		if (! crypto_setup(env->sc_queue_key, strlen(env->sc_queue_key)))
@


1.173
log
@While listing envelopes using mailq(or smtpctl show queue), pass
the data between processes by dumping to and loading from a buffer
which is shorter compared to transferring a structure.  Also fixes
mailq on platforms where PATH_MAX is way larger than on OpenBSD
thus exceeding max imsg.

Ok jung@@ millert@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.172 2015/11/23 06:54:21 sunil Exp $	*/
d797 1
a797 1
	
d803 1
a803 1
	
@


1.172
log
@Restructure bounce content as a multi-part MIME message.
Content-Type header diff from Philipp Takacs <philipp<at>bureaucracy.de>

Ok gilles@@ jung@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.171 2015/11/05 09:14:31 sunil Exp $	*/
d75 1
a75 1
	size_t			 n_evp;
d77 1
d332 5
d338 1
a338 1
			    imsg->hdr.peerid, 0, -1, &evp, sizeof evp);
@


1.171
log
@Implement smtpctl uncorrupt <msgid>

"uncorrupt" moves envelopes from corrupt bucket back to the queue
for further discovery by the daemon.

After correcting the corrupt envelopes, admin could now...

# smtpctl uncorrupt msgid
# smtpctl discover msgid

to schedule the messages.

Ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.170 2015/10/29 10:25:36 sunil Exp $	*/
d365 1
a365 1

@


1.170
log
@Implement smtpctl discover <evpid|msgid>.

discover subcommand schedules envelopes manually moved to the queue.
It triggers a queue walk searching for envelopes with the given id,
schedules them and informs the user number of envelopes scheduled.
Admins no longer would need to restart the daemon to discover
manually moved messages.

Ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.169 2015/10/16 13:37:44 millert Exp $	*/
d548 9
@


1.169
log
@Implement real "flock" request and add it to userland programs that
use pledge and file locking.  OK deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.168 2015/10/14 22:01:43 gilles Exp $	*/
d50 1
d66 2
d75 1
d507 42
d553 37
@


1.168
log
@whitespaces
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.167 2015/10/13 11:03:30 gilles Exp $	*/
d646 1
a646 1
	if (pledge("stdio rpath wpath cpath recvfd sendfd", NULL) == -1)
@


1.167
log
@pledge() queue process

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.166 2015/01/20 17:37:54 deraadt Exp $	*/
d157 1
a157 1
		    
@


1.166
log
@use <limits.h> comprehensively.  For now try to push <> includes to
each .c file, and out of the .h files.  To avoid overinclude.
ok gilles, in principle.  If this has been done right, -portable should
become easier to maintain.
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.165 2014/07/10 15:54:55 eric Exp $	*/
d645 3
@


1.165
log
@make the control process broadcast verbose/profile admin requests directly,
rather than going through the parent process. simplify code in the meantime.
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.162 2014/04/19 13:40:24 gilles Exp $	*/
d39 1
d695 1
a695 1
	char rcpt[SMTPD_MAXLINESIZE];
@


1.164
log
@Improve the scheduler, better and simpler.

- Get rid of the scheduler_batch structure. The scheduler can now return
  envelopes of different types in a single run, interlacing them to avoid
  batch effects.

- Ask for an acknowledgement from the queue when removing or expiring
  an envelope to benefit from the inflight envelope limitation mechanism.
  This ensures that the scheduler always keeps sending envelopes at a rate
  that the queue can sustain in all cases.

- Limit the number of envelopes in a holdq.  When a holdq is full,
  new envelopes are put back in the pending queue instead, with a
  shorter retry time.

- Plumbing for proc-ified schedulers.

imsg version bump. smtpctl stop before updating.

ok gilles@@
@
text
@a487 2
		}
	}
a488 2
	if (p->proc == PROC_PARENT) {
		switch (imsg->hdr.type) {
a493 1
			m_forward(p_scheduler, imsg);
@


1.163
log
@various queue improvements:

- add a "close" hook to the backend API.
- improve the sync() pattern in queue_fs: only sync at commit
  time and not for every envelope creation
- various fixes to the experimental external queue API.
@
text
@d200 4
d207 1
d216 4
@


1.162
log
@(void) cast strlcpy() and snprintf() that cannot truncate
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.161 2014/04/08 15:25:43 eric Exp $	*/
d564 1
@


1.161
log
@use correct imsg

ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.160 2014/04/04 16:10:42 eric Exp $	*/
d691 1
a691 1
	strlcpy(rcpt, "-", sizeof rcpt);
d694 1
a694 1
		snprintf(rcpt, sizeof rcpt, "%s@@%s",
@


1.160
log
@Merge the mda, mta and smtp processes into a single unprivileged
process managing message reception, delivery and transfer.  Mostly
mechanical, but very intrusive as it required to rewamp all IMSG to
fix ambiguities.

with and ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d444 1
a444 1
			imsg->hdr.type = IMSG_QUEUE_HOLDQ_RELEASE;
@


1.159
log
@Add support for DSN and Enhanced Status Code
@
text
@d74 1
a74 1
	if (p->proc == PROC_SMTP) {
d77 1
a77 1
		case IMSG_QUEUE_CREATE_MESSAGE:
d84 1
a84 1
			m_create(p, IMSG_QUEUE_CREATE_MESSAGE, 0, 0, -1);
d95 1
a95 1
		case IMSG_QUEUE_REMOVE_MESSAGE:
d102 1
a102 1
			m_create(p_scheduler, IMSG_QUEUE_REMOVE_MESSAGE,
d108 1
a108 1
		case IMSG_QUEUE_COMMIT_MESSAGE:
d116 1
a116 1
			m_create(p,  IMSG_QUEUE_COMMIT_MESSAGE, 0, 0, -1);
d122 1
a122 1
				m_create(p_scheduler, IMSG_QUEUE_COMMIT_MESSAGE,
d129 1
a129 1
		case IMSG_QUEUE_MESSAGE_FILE:
d137 1
a137 1
			m_create(p, IMSG_QUEUE_MESSAGE_FILE, 0, 0, fd);
d143 1
a143 1
		case IMSG_SMTP_ENQUEUE_FD:
d151 1
a151 1
		case IMSG_QUEUE_SUBMIT_ENVELOPE:
d163 2
a164 2
			m_create(p_smtp, IMSG_QUEUE_SUBMIT_ENVELOPE, 0, 0, -1);
			m_add_id(p_smtp, reqid);
d166 1
a166 1
				m_add_int(p_smtp, 0);
d168 2
a169 2
				m_add_int(p_smtp, 1);
				m_add_evpid(p_smtp, evp.id);
d171 1
a171 1
			m_close(p_smtp);
d174 1
a174 1
				    IMSG_QUEUE_SUBMIT_ENVELOPE, 0, 0, -1);
d181 1
a181 1
		case IMSG_QUEUE_COMMIT_ENVELOPES:
d185 4
a188 4
			m_create(p_smtp, IMSG_QUEUE_COMMIT_ENVELOPES, 0, 0, -1);
			m_add_id(p_smtp, reqid);
			m_add_int(p_smtp, 1);
			m_close(p_smtp);
d195 1
a195 1
		case IMSG_QUEUE_REMOVE:
d207 1
a207 1
		case IMSG_QUEUE_EXPIRE:
d225 1
a225 1
		case IMSG_QUEUE_BOUNCE:
d231 1
a231 1
				m_create(p_scheduler, IMSG_QUEUE_REMOVE, 0, 0, -1);
d243 1
a243 1
		case IMSG_MDA_DELIVER:
d249 1
a249 1
				m_create(p_scheduler, IMSG_QUEUE_REMOVE, 0, 0, -1);
d256 3
a258 3
			m_create(p_mda, IMSG_MDA_DELIVER, 0, 0, -1);
			m_add_envelope(p_mda, &evp);
			m_close(p_mda);
d261 1
a261 1
		case IMSG_BOUNCE_INJECT:
d268 1
a268 1
		case IMSG_MTA_TRANSFER:
d274 1
a274 1
				m_create(p_scheduler, IMSG_QUEUE_REMOVE, 0, 0, -1);
d281 3
a283 3
			m_create(p_mta, IMSG_MTA_TRANSFER, 0, 0, -1);
			m_add_envelope(p_mta, &evp);
			m_close(p_mta);
d323 1
a323 1
	if (p->proc == PROC_MTA || p->proc == PROC_MDA) {
d325 2
a326 1
		case IMSG_QUEUE_MESSAGE_FD:
d332 1
a332 1
			m_create(p, IMSG_QUEUE_MESSAGE_FD, 0, 0, fd);
d337 2
a338 1
		case IMSG_DELIVERY_OK:
d341 1
a341 1
			if (p->proc == PROC_MTA)
d352 1
a352 1
				if (p->proc == PROC_MDA)
d354 1
a354 1
				else if (p->proc == PROC_MTA &&
d361 1
a361 1
			m_create(p_scheduler, IMSG_DELIVERY_OK, 0, 0, -1);
d366 2
a367 1
		case IMSG_DELIVERY_TEMPFAIL:
d375 1
a375 1
				m_create(p_scheduler, IMSG_QUEUE_REMOVE, 0, 0, -1);
d387 1
a387 1
			m_create(p_scheduler, IMSG_DELIVERY_TEMPFAIL, 0, 0, -1);
d392 2
a393 1
		case IMSG_DELIVERY_PERMFAIL:
d401 1
a401 1
				m_create(p_scheduler, IMSG_QUEUE_REMOVE, 0, 0, -1);
d413 1
a413 1
			m_create(p_scheduler, IMSG_DELIVERY_PERMFAIL, 0, 0, -1);
d418 2
a419 1
		case IMSG_DELIVERY_LOOP:
d425 1
a425 1
				m_create(p_scheduler, IMSG_QUEUE_REMOVE, 0, 0, -1);
d437 1
a437 1
			m_create(p_scheduler, IMSG_DELIVERY_LOOP, 0, 0, -1);
d442 6
a447 1
		case IMSG_DELIVERY_HOLD:
d449 1
d452 3
a454 1
		case IMSG_DELIVERY_RELEASE:
d459 2
a460 3

			m_create(p_scheduler, IMSG_DELIVERY_RELEASE, 0, 0, -1);
			if (p->proc == PROC_MTA)
a476 1
		case IMSG_QUEUE_REMOVE:
d535 1
a535 1
		m_create(p_scheduler, IMSG_QUEUE_SUBMIT_ENVELOPE, 0, 0, -1);
d539 1
a539 1
		m_create(p_scheduler, IMSG_QUEUE_COMMIT_MESSAGE, 0, 0, -1);
a628 3
	config_peer(PROC_SMTP);
	config_peer(PROC_MDA);
	config_peer(PROC_MTA);
d631 1
d659 1
a659 1
			m_create(p_scheduler, IMSG_QUEUE_COMMIT_MESSAGE,
d670 1
a670 1
			m_create(p_scheduler, IMSG_QUEUE_COMMIT_MESSAGE,
d676 1
a676 1
		m_create(p_scheduler, IMSG_QUEUE_SUBMIT_ENVELOPE, 0, 0, -1);
a685 36
void
queue_ok(uint64_t evpid)
{
	m_create(p_queue, IMSG_DELIVERY_OK, 0, 0, -1);
	m_add_evpid(p_queue, evpid);
	m_close(p_queue);
}

void
queue_tempfail(uint64_t evpid, const char *reason, enum enhanced_status_code code)
{
	m_create(p_queue, IMSG_DELIVERY_TEMPFAIL, 0, 0, -1);
	m_add_evpid(p_queue, evpid);
	m_add_string(p_queue, reason);
	m_add_int(p_queue, (int)code);
	m_close(p_queue);
}

void
queue_permfail(uint64_t evpid, const char *reason, enum enhanced_status_code code)
{
	m_create(p_queue, IMSG_DELIVERY_PERMFAIL, 0, 0, -1);
	m_add_evpid(p_queue, evpid);
	m_add_string(p_queue, reason);
	m_add_int(p_queue, (int)code);
	m_close(p_queue);
}

void
queue_loop(uint64_t evpid)
{
	m_create(p_queue, IMSG_DELIVERY_LOOP, 0, 0, -1);
	m_add_evpid(p_queue, evpid);
	m_close(p_queue);
}

d715 1
a715 1
	bufsz = p_mda->bytes_queued + p_mta->bytes_queued;
d732 1
a732 2
		mproc_disable(p_mta);
		mproc_disable(p_mda);
d738 1
a738 2
		mproc_enable(p_mta);
		mproc_enable(p_mda);
@


1.158
log
@internal improvements and cleanups

- get rid of the whole penalty thing for failed envelopes in the mta and scheduler.
- do not disable routes on smtp errors
- try to schedule all types of envelopes on each scheduler frame.
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.157 2014/02/04 09:05:06 eric Exp $	*/
d71 1
a71 1
	int			 fd, ret, v, flags;
d73 1
a216 2
			bounce.delay = 0;
			bounce.expire = 0;
d218 2
d339 2
d342 16
d368 1
d379 2
d393 1
a403 2
			bounce.delay = 0;
			bounce.expire = 0;
d405 2
d427 2
a429 2
			bounce.delay = 0;
			bounce.expire = 0;
d506 3
d686 1
a686 1
queue_tempfail(uint64_t evpid, const char *reason)
d691 1
d696 1
a696 1
queue_permfail(uint64_t evpid, const char *reason)
d701 1
@


1.157
log
@get rid of fdlimit()
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.156 2013/11/20 09:22:42 eric Exp $	*/
a69 1
	uint32_t		 penalty;
a347 1
			m_get_u32(&m, &penalty);
a363 1
			m_add_u32(p_scheduler, penalty);
d660 1
a660 1
queue_tempfail(uint64_t evpid, uint32_t penalty, const char *reason)
a663 1
	m_add_u32(p_queue, penalty);
@


1.156
log
@Rework the mda and scheduler to use the holdq mechanism instead of
tempfail for limiting the number of pending deliveries to the same
user.  This allows to reach optimal delivery time even in case of
burst, while keeping the number of inflight envelopes low.
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
a591 2

	fdlimit(1.0);
@


1.155
log
@Implement a feedback mechanism which allows the mta to "hold" envelopes
in the scheduler when it has too many tasks for a given relay.  The
envelopes are put on a wait queue, and are not scheduled again until
the mta "releases" some envelopes from that queue.

It prevents from having too many inflight envelopes, which are out of reach
for the admin.
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.154 2013/10/27 07:56:25 eric Exp $	*/
d68 1
a68 1
	uint64_t		 reqid, evpid;
a417 1
		case IMSG_DELIVERY_RELEASE:
d420 15
@


1.154
log
@Create the control socket in the parent process to abort early if
another smtpd instance is running.  Close the inherited socket in
every forked process but control.
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.153 2013/07/19 21:14:52 eric Exp $	*/
d417 2
@


1.153
log
@Many MTA improvements:

- Better transient error handling logic: failing destinations are
  automatically disabled for a while.  When a destination is active
  again, ask the scheduler to retry previous envelopes immediatly.
- More informative error report when all routes fail for a mail.
- Implement a "smtpctl show hoststats" command to get the latest stat
  message per MX domain.
- Implement a "smtpctl show routes" command to show the state the
  currently known routes to remote MXs.
- Implement a "smtpctl resume route" command to re-enable a route that
  has been disabled.
- Do not hardcode limits
- Minor code improvements
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d531 1
@


1.152
log
@Assorted queue improvements:
- cleanup the internal queue backend API and get rid of the QOP_* thing.
- implement a queue_proc backend
- rename queue_fsqueue.c to queue_fs
- enable support for queue encryption
- add an envelope cache
- better logging and error reporting
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.151 2013/07/19 15:14:23 eric Exp $	*/
a65 1
	static uint64_t		 batch_id;
d268 1
a268 8
		case IMSG_MTA_BATCH:
			batch_id = generate_uid();
			m_create(p_mta, IMSG_MTA_BATCH, 0, 0, -1);
			m_add_id(p_mta, batch_id);
			m_close(p_mta);
			return;

		case IMSG_MTA_BATCH_ADD:
d281 1
a281 2
			m_create(p_mta, IMSG_MTA_BATCH_ADD, 0, 0, -1);
			m_add_id(p_mta, batch_id);
a282 6
			m_close(p_mta);
			return;

		case IMSG_MTA_BATCH_END:
			m_create(p_mta, IMSG_MTA_BATCH_END, 0, 0, -1);
			m_add_id(p_mta, batch_id);
@


1.151
log
@scheduler improvements:
- implement suspend/resume scheduling for individual envelopes or message,
  with the associated smtpctl commands.
- allow the mta to request immediate scheduling of an envelope.
- on temporary failures a penalty can be given to further delay the next try.
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.150 2013/07/19 11:14:08 eric Exp $	*/
d557 3
d567 9
d692 17
a708 17
       char rcpt[SMTPD_MAXLINESIZE];

       rcpt[0] = '\0';
       if (strcmp(e->rcpt.user, e->dest.user) ||
           strcmp(e->rcpt.domain, e->dest.domain))
               snprintf(rcpt, sizeof rcpt, "rcpt=<%s@@%s>, ",
                   e->rcpt.user, e->rcpt.domain);

       log_info("%s: %s for %016" PRIx64 ": from=<%s@@%s>, to=<%s@@%s>, "
           "%sdelay=%s, stat=%s",
           e->type == D_MDA ? "delivery" : "relay",
           prefix,
           e->id, e->sender.user, e->sender.domain,
           e->dest.user, e->dest.domain,
           rcpt,
           duration_to_text(time(NULL) - e->creation),
           status);
@


1.150
log
@Get rid of env->sc_pw and env->sc_pwqueue.  Early queue initialization
now happens in queue_init(), and backends take the queue passwd as
parameter in their init function.

Remove useless SMTPD_FILTER_USER while there.
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.149 2013/07/19 07:49:08 eric Exp $	*/
d71 1
d240 2
a241 1
			queue_envelope_update(&evp);
d281 1
a281 1
				log_warnx("queue: batch: failed to load envelope");
d324 1
a324 1
			if (flags == EF_INFLIGHT) {
d364 1
d377 2
a378 1
			queue_envelope_update(&evp);
d381 1
d431 4
d651 1
a651 1
queue_tempfail(uint64_t evpid, const char *reason)
d655 1
@


1.149
log
@Remove useless sc_pid from struct smtpd.
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.148 2013/05/24 17:03:14 eric Exp $	*/
a542 4
	if (env->sc_pwqueue) {
		free(env->sc_pw);
		env->sc_pw = env->sc_pwqueue;
	}
d544 4
a547 1
	pw = env->sc_pw;
@


1.148
log
@sync with OpenSMTPD 5.3.2

ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.146 2013/01/31 18:24:47 eric Exp $	*/
a536 1
		env->sc_pid = getpid();
@


1.147
log
@replace MAX_LINE_SIZE and SMTP_LINE_MAX with SMTPD_MAXLINESIZE for
consistency and clarity.  Remove useless and confusing extra byte in
a few arrays based on this define.

ok gilles@@
@
text
@a23 1
#include <sys/param.h>
d84 1
a84 1
			m_create(p, IMSG_QUEUE_CREATE_MESSAGE, 0, 0, -1, 24);
d103 1
a103 1
			    0, 0, -1, 5);
d116 1
a116 1
			m_create(p,  IMSG_QUEUE_COMMIT_MESSAGE, 0, 0, -1, 16);
d123 1
a123 1
				    0, 0, -1, 5);
d137 1
a137 1
			m_create(p, IMSG_QUEUE_MESSAGE_FILE, 0, 0, fd, 16);
d158 1
a158 1
				log_warn("warn: imsg_queue_submit_envelope: evpid=0");
d160 1
a160 1
				log_warn("warn: imsg_queue_submit_envelope: msgid=0, "
d163 1
a163 2
			m_create(p_smtp, IMSG_QUEUE_SUBMIT_ENVELOPE, 0, 0, -1,
			    24);
d174 1
a174 2
				    IMSG_QUEUE_SUBMIT_ENVELOPE, 0, 0, -1,
				    MSZ_EVP);
d185 1
a185 2
			m_create(p_smtp, IMSG_QUEUE_COMMIT_ENVELOPES, 0, 0, -1,
			    16);
d199 2
d202 1
a202 1
				errx(1, "cannot load evp:%016" PRIx64, evpid);
d211 2
d214 2
a215 1
				errx(1, "cannot load evp:%016" PRIx64, evpid);
d228 9
a236 2
			if (queue_envelope_load(evpid, &evp) == 0)
				errx(1, "cannot load evp:%016" PRIx64, evpid);
d246 8
a253 2
			if (queue_envelope_load(evpid, &evp) == 0)
				errx(1, "cannot load evp:%016" PRIx64, evpid);
d255 1
a255 1
			m_create(p_mda, IMSG_MDA_DELIVER, 0, 0, -1, MSZ_EVP);
d269 1
a269 1
			m_create(p_mta, IMSG_MTA_BATCH, 0, 0, -1, 9);
d278 8
a285 2
			if (queue_envelope_load(evpid, &evp) == 0)
				errx(1, "cannot load evp:%016" PRIx64, evpid);
d287 1
a287 1
			m_create(p_mta, IMSG_MTA_BATCH_ADD, 0, 0, -1, MSZ_EVP);
d294 1
a294 1
			m_create(p_mta, IMSG_MTA_BATCH_END, 0, 0, -1, 9);
d344 1
a344 1
			m_create(p, IMSG_QUEUE_MESSAGE_FD, 0, 0, fd, 25);
d354 1
a354 1
			m_create(p_scheduler, IMSG_DELIVERY_OK, 0, 0, -1, 9);
d364 8
a371 2
			if (queue_envelope_load(evpid, &evp) == 0)
				errx(1, "cannot load evp:%016" PRIx64, evpid);
d375 1
a375 2
			m_create(p_scheduler, IMSG_DELIVERY_TEMPFAIL, 0, 0, -1,
			    MSZ_EVP);
d385 8
a392 2
			if (queue_envelope_load(evpid, &evp) == 0)
				errx(1, "cannot load evp:%016" PRIx64, evpid);
d399 1
a399 2
			m_create(p_scheduler, IMSG_DELIVERY_PERMFAIL, 0, 0, -1,
			    9);
d408 8
a415 2
			if (queue_envelope_load(evpid, &evp) == 0)
				errx(1, "cannot load evp:%016" PRIx64, evpid);
d422 1
a422 1
			m_create(p_scheduler, IMSG_DELIVERY_LOOP, 0, 0, -1, 9);
d477 1
a477 1
		log_warn("warn: queue_bounce: evpid=0");
d479 1
a479 1
		log_warn("warn: queue_bounce: msgid=0, evpid=%016"PRIx64,
d491 1
a491 2
		m_create(p_scheduler, IMSG_QUEUE_SUBMIT_ENVELOPE, 0, 0, -1,
		    MSZ_EVP);
d495 1
a495 1
		m_create(p_scheduler, IMSG_QUEUE_COMMIT_MESSAGE, 0, 0, -1, 5);
d609 1
a609 1
			    0, 0, -1, 5);
d620 1
a620 1
			    0, 0, -1, 5);
d625 1
a625 2
		m_create(p_scheduler, IMSG_QUEUE_SUBMIT_ENVELOPE, 0, 0, -1,
		    MSZ_EVP);
d638 1
a638 1
	m_create(p_queue, IMSG_DELIVERY_OK, 0, 0, -1, sizeof(evpid) + 1);
d646 1
a646 2
	m_create(p_queue, IMSG_DELIVERY_TEMPFAIL, 0, 0, -1,
	    sizeof(evpid) + strlen(reason) + 2);
d655 1
a655 2
	m_create(p_queue, IMSG_DELIVERY_PERMFAIL, 0, 0, -1,
	    sizeof(evpid) + strlen(reason) + 2);
d664 1
a664 1
	m_create(p_queue, IMSG_DELIVERY_LOOP, 0, 0, -1, sizeof(evpid) + 1);
@


1.146
log
@do not need to tweak the socket sndbuf, now that the envelopes are passed
in compressed form. reduce the default size for envelope messages.

ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.145 2013/01/26 09:37:23 gilles Exp $	*/
d640 1
a640 1
       char rcpt[MAX_LINE_SIZE];
@


1.145
log
@Sync with our smtpd repo:

* first bricks of ldap and sqlite support (not finished but both working)
* new table API to replace map API, all lookups are done through tables
* improved handling of temporary errors throughout the daemon
* improved scheduler and mta logic: connection reuse, optimizes batches
* improved queue: more tolerant to admin errors, new layout, less disk-IO
* improved memory usage under high load
* SSL certs/keys isolated to lookup process to avoid facing network
* VIRTUAL support improved, fully virtual setups possible now
* runtime tracing of processes through smtpctl trace
* ssl_privsep.c sync-ed with relayd
* ssl.c no longer contains smtpd specific interfaces
* smtpd-specific ssl bits moved to ssl_smtpd.c
* update mail address in copyright

FLUSH YOUR QUEUE. FLUSH YOUR QUEUE. FLUSH YOUR QUEUE. FLUSH YOUR QUEUE.

smtpd.conf(5) simplified, it will require adaptations

ok eric@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.141 2012/11/12 14:58:53 eric Exp $	*/
a487 26
static void
queue_set_sndbuf(struct mproc *p, int sz)
{
	int		 osz;
	socklen_t	 sl;

	sl = sizeof(osz);
	if (getsockopt(p->imsgbuf.fd, SOL_SOCKET, SO_SNDBUF, &osz, &sl) == -1) {
		log_warn("warn: getsockopt");
		return;
	}
	if (osz == sz)
		return;

	if (setsockopt(p->imsgbuf.fd, SOL_SOCKET, SO_SNDBUF, &sz, sl) == -1) {
		log_warn("warn: setsockopt");
		return;
	}
	if (getsockopt(p->imsgbuf.fd, SOL_SOCKET, SO_SNDBUF, &sz, &sl) == -1) {
		log_warn("warn: getsockopt");
		return;
	}
	log_debug("debug: queue: adjusted output buffer size for %s: %i -> %i",
		p->name, osz, sz);
}

a546 4

	queue_set_sndbuf(p_scheduler, 65536);
	queue_set_sndbuf(p_mta, 65536);
	queue_set_sndbuf(p_mda, 65536);
@


1.144
log
@Replace the qwalk API (to retreive on disk envelopes at runtime) with
a simple QOP_WALK queue operation. Some knf and formating fixes while
there.

ok gilles@@
@
text
@d4 1
a4 1
 * Copyright (c) 2008 Gilles Chehade <gilles@@openbsd.org>
d44 1
a44 1
static void queue_imsg(struct imsgev *, struct imsg *);
d46 1
a46 2
static void queue_bounce(struct envelope *);
static void queue_pass_to_scheduler(struct imsgev *, struct imsg *);
d49 11
d62 1
a62 1
queue_imsg(struct imsgev *iev, struct imsg *imsg)
d64 3
a66 1
	struct evpstate		*state;
d68 3
a70 4
	struct submit_status	 ss;
	struct envelope		*e, evp;
	int			 fd, ret;
	uint64_t		 id;
d72 2
d75 1
a75 2
	if (iev->proc == PROC_SMTP) {
		e = imsg->data;
d79 8
a86 4
			ss.id = e->session_id;
			ss.code = 250;
			ss.u.msgid = 0;
			ret = queue_message_create(&ss.u.msgid);
d88 6
a93 3
				ss.code = 421;
			imsg_compose_event(iev, IMSG_QUEUE_CREATE_MESSAGE, 0, 0,
			    -1, &ss, sizeof ss);
d97 10
a106 5
			msgid = *(uint32_t*)(imsg->data);
			queue_message_incoming_delete(msgid);
			imsg_compose_event(env->sc_ievs[PROC_SCHEDULER],
			    IMSG_QUEUE_REMOVE_MESSAGE, 0, 0, -1,
			    &msgid, sizeof msgid);
d110 18
a127 12
			ss.id = e->session_id;
			ss.code = 250;
			msgid = evpid_to_msgid(e->id);
			if (queue_message_commit(msgid)) {
				imsg_compose_event(env->sc_ievs[PROC_SCHEDULER],
				    IMSG_QUEUE_COMMIT_MESSAGE, 0, 0, -1,
				    &msgid, sizeof msgid);
			} else
				ss.code = 421;

			imsg_compose_event(iev, IMSG_QUEUE_COMMIT_MESSAGE, 0, 0,
			    -1, &ss, sizeof ss);
d131 11
a141 6
			ss.id = e->session_id;
			fd = queue_message_fd_rw(evpid_to_msgid(e->id));
			if (fd == -1)
				ss.code = 421;
			imsg_compose_event(iev, IMSG_QUEUE_MESSAGE_FILE, 0, 0,
			    fd, &ss, sizeof ss);
d144 2
a145 3
		case IMSG_SMTP_ENQUEUE:
			id = *(uint64_t*)(imsg->data);
			bounce_run(id, imsg->fd);
d150 1
a150 2
	if (iev->proc == PROC_LKA) {
		e = imsg->data;
d153 28
a180 11
			if (!queue_envelope_create(e)) {
				ss.id = e->session_id;
				ss.code = 421;
				imsg_compose_event(env->sc_ievs[PROC_SMTP],
				    IMSG_QUEUE_TEMPFAIL, 0, 0, -1, &ss,
				    sizeof ss);
			} else {
				/* tell the scheduler */
				imsg_compose_event(env->sc_ievs[PROC_SCHEDULER],
				    IMSG_QUEUE_SUBMIT_ENVELOPE, 0, 0, -1, e,
				    sizeof *e);
d185 8
a192 5
			ss.id = e->session_id;
			ss.code = 250;
			imsg_compose_event(env->sc_ievs[PROC_SMTP],
			    IMSG_QUEUE_COMMIT_ENVELOPES, 0, 0, -1, &ss,
			    sizeof ss);
d197 1
a197 1
	if (iev->proc == PROC_SCHEDULER) {
d200 7
a206 6
			id = *(uint64_t*)(imsg->data);
			if (queue_envelope_load(id, &evp) == 0)
				errx(1, "cannot load evp:%016" PRIx64, id);
			log_envelope(&evp, NULL, "Remove",
			    "Removed by administrator");
			queue_envelope_delete(&evp);
d210 8
a217 3
			id = *(uint64_t*)(imsg->data);
			if (queue_envelope_load(id, &evp) == 0)
				errx(1, "cannot load evp:%016" PRIx64, id);
d219 21
a239 9
			queue_bounce(&evp);
			log_envelope(&evp, NULL, "Expire", evp.errorline);
			queue_envelope_delete(&evp);
			return;

		case IMSG_MDA_SESS_NEW:
			id = *(uint64_t*)(imsg->data);
			if (queue_envelope_load(id, &evp) == 0)
				errx(1, "cannot load evp:%016" PRIx64, id);
d241 3
a243 2
			imsg_compose_event(env->sc_ievs[PROC_MDA],
			    IMSG_MDA_SESS_NEW, 0, 0, -1, &evp, sizeof evp);
d246 5
a250 3
		case IMSG_SMTP_ENQUEUE:
			id = *(uint64_t*)(imsg->data);
			bounce_add(id);
d253 1
a253 1
		case IMSG_BATCH_CREATE:
d255 3
a257 3
			imsg_compose_event(env->sc_ievs[PROC_MTA],
			    IMSG_BATCH_CREATE, 0, 0, -1,
			    &batch_id, sizeof batch_id);
d260 6
a265 4
		case IMSG_BATCH_APPEND:
			id = *(uint64_t*)(imsg->data);
			if (queue_envelope_load(id, &evp) == 0)
				errx(1, "cannot load evp:%016" PRIx64, id);
d267 4
a270 3
			evp.batch_id = batch_id;
			imsg_compose_event(env->sc_ievs[PROC_MTA],
			    IMSG_BATCH_APPEND, 0, 0, -1, &evp, sizeof evp);
d273 4
a276 4
		case IMSG_BATCH_CLOSE:
			imsg_compose_event(env->sc_ievs[PROC_MTA],
			    IMSG_BATCH_CLOSE, 0, 0, -1,
			    &batch_id, sizeof batch_id);
d279 1
a279 1
		case IMSG_SCHEDULER_ENVELOPES:
d281 1
a281 3
				imsg_compose_event(env->sc_ievs[PROC_CONTROL],
				    IMSG_SCHEDULER_ENVELOPES, imsg->hdr.peerid,
				    0, -1, NULL, 0);
d284 8
a291 2
			state = imsg->data;
			if (queue_envelope_load(state->evpid, &evp) == 0)
d293 1
d299 1
a299 1
			evp.flags |= state->flags;
d301 2
a302 2
			evp.nexttry = state->time;
			if (state->flags == DF_INFLIGHT) {
d308 1
a308 1
				evp.lasttry = state->time;
d310 2
a311 3
			imsg_compose_event(env->sc_ievs[PROC_CONTROL],
			    IMSG_SCHEDULER_ENVELOPES, imsg->hdr.peerid, 0, -1,
			    &evp, sizeof evp);
d316 1
a316 1
	if (iev->proc == PROC_MTA || iev->proc == PROC_MDA) {
d319 70
a388 38
			fd = queue_message_fd_r(imsg->hdr.peerid);
			imsg_compose_event(iev,  IMSG_QUEUE_MESSAGE_FD, 0, 0,
			    fd, imsg->data, imsg->hdr.len - sizeof imsg->hdr);
			return;

		case IMSG_QUEUE_DELIVERY_OK:
			e = imsg->data;
			queue_envelope_delete(e);
			imsg_compose_event(env->sc_ievs[PROC_SCHEDULER],
			    IMSG_QUEUE_DELIVERY_OK, 0, 0, -1, &e->id,
			    sizeof e->id);
			return;

		case IMSG_QUEUE_DELIVERY_TEMPFAIL:
			e = imsg->data;
			e->retry++;
			queue_envelope_update(e);
			imsg_compose_event(env->sc_ievs[PROC_SCHEDULER],
			    IMSG_QUEUE_DELIVERY_TEMPFAIL, 0, 0, -1, e,
			    sizeof *e);
			return;

		case IMSG_QUEUE_DELIVERY_PERMFAIL:
			e = imsg->data;
			queue_bounce(e);
			queue_envelope_delete(e);
			imsg_compose_event(env->sc_ievs[PROC_SCHEDULER],
			    IMSG_QUEUE_DELIVERY_PERMFAIL, 0, 0, -1, &e->id,
			    sizeof e->id);
			return;

		case IMSG_QUEUE_DELIVERY_LOOP:
			e = imsg->data;
			queue_bounce(e);
			queue_envelope_delete(e);
			imsg_compose_event(env->sc_ievs[PROC_SCHEDULER],
			    IMSG_QUEUE_DELIVERY_LOOP, 0, 0, -1, &e->id,
			    sizeof e->id);
d393 1
a393 1
	if (iev->proc == PROC_CONTROL) {
d395 4
a398 4
		case IMSG_QUEUE_PAUSE_MDA:
		case IMSG_QUEUE_PAUSE_MTA:
		case IMSG_QUEUE_RESUME_MDA:
		case IMSG_QUEUE_RESUME_MTA:
d400 1
a400 1
			queue_pass_to_scheduler(iev, imsg);
d405 1
a405 1
	if (iev->proc == PROC_PARENT) {
d408 12
a419 2
			log_verbose(*(int *)imsg->data);
			queue_pass_to_scheduler(iev, imsg);
d428 1
a428 9
queue_pass_to_scheduler(struct imsgev *iev, struct imsg *imsg)
{
	imsg_compose_event(env->sc_ievs[PROC_SCHEDULER], imsg->hdr.type,
	    iev->proc, imsg->hdr.pid, imsg->fd, imsg->data,
	    imsg->hdr.len - sizeof imsg->hdr);
}

static void
queue_bounce(struct envelope *e)
a430 1
	uint32_t	msgid;
d434 1
d440 5
d454 10
a463 5
		imsg_compose_event(env->sc_ievs[PROC_SCHEDULER],
		    IMSG_QUEUE_SUBMIT_ENVELOPE, 0, 0, -1, &b, sizeof b);
		msgid = evpid_to_msgid(b.id);
		imsg_compose_event(env->sc_ievs[PROC_SCHEDULER],
		    IMSG_QUEUE_COMMIT_MESSAGE, 0, 0, -1, &msgid, sizeof msgid);
d488 26
a523 10
	struct peer peers[] = {
		{ PROC_PARENT,		imsg_dispatch },
		{ PROC_CONTROL,		imsg_dispatch },
		{ PROC_SMTP,		imsg_dispatch },
		{ PROC_MDA,		imsg_dispatch },
		{ PROC_MTA,		imsg_dispatch },
		{ PROC_LKA,		imsg_dispatch },
		{ PROC_SCHEDULER,	imsg_dispatch }
	};

d528 1
d535 4
a540 1

d546 1
a546 2
	smtpd_process = PROC_QUEUE;
	setproctitle("%s", env->sc_title[smtpd_process]);
d565 12
a576 2
	config_pipes(peers, nitems(peers));
	config_peers(peers, nitems(peers));
d602 6
a607 4
		if (msgid)
			imsg_compose_event(env->sc_ievs[PROC_SCHEDULER],
			    IMSG_QUEUE_COMMIT_MESSAGE, 0, 0, -1, &msgid,
			    sizeof msgid);
d613 6
a618 4
		if (msgid && evpid_to_msgid(evp.id) != msgid)
			imsg_compose_event(env->sc_ievs[PROC_SCHEDULER],
			    IMSG_QUEUE_COMMIT_MESSAGE, 0, 0, -1, &msgid,
			    sizeof msgid);
d620 4
a623 2
		imsg_compose_event(env->sc_ievs[PROC_SCHEDULER],
		    IMSG_QUEUE_SUBMIT_ENVELOPE, 0, 0, -1, &evp, sizeof evp);
d629 106
@


1.143
log
@Allow "smtpctl show queue" to run in "online" mode if the smtpd server
is running.  The scheduler sends the runtime state of each envelope to
the queue process which loads the envelope, fills the runtime bits and
sends the envelope back to the client. Iteration over the envelope set
happens in small chunks to make the request interruptible and to allow
the server to keep doing its job in the meantime.

Adpat "smtpctl schedule-all" to schedule the messages one by one using
the same iteration mechanism.

Document "smtpctl monitor" and "smtpctl show queue".

ok gilles@@
@
text
@d440 9
a448 16
	static struct qwalk	*q = NULL;
	static uint32_t		 msgid = 0;
	static size_t		 evpcount = 0;
	struct event		*ev = p;
	struct envelope		 envelope;
	struct timeval		 tv;
	uint64_t		 evpid;

	if (q == NULL) {
		log_debug("debug: queue: loading queue into scheduler");
		q = qwalk_new(0);
	}

	while (qwalk(q, &evpid)) {

		if (msgid && evpid_to_msgid(evpid) != msgid && evpcount) {
d452 1
a452 17
			evpcount = 0;
		}
		msgid = evpid_to_msgid(evpid);

		if (!queue_envelope_load(evpid, &envelope))
			log_warnx("warn: Failed to load envelope %016"PRIx64,
			    evpid);
		else {
			imsg_compose_event(env->sc_ievs[PROC_SCHEDULER],
			    IMSG_QUEUE_SUBMIT_ENVELOPE, 0, 0, -1, &envelope,
			    sizeof envelope);
			evpcount++;
		}

		tv.tv_sec = 0;
		tv.tv_usec = 0;
		evtimer_add(ev, &tv);	
d456 6
a461 1
	if (msgid && evpcount) {
d463 1
a463 2
		    IMSG_QUEUE_COMMIT_MESSAGE, 0, 0, -1, &msgid, sizeof msgid);
		evpcount = 0;
d466 3
a468 2
	log_debug("debug: queue: done loading queue into scheduler");
	qwalk_close(q);
@


1.142
log
@do not miss the last envelope

ok gilles@@
@
text
@d54 1
d201 32
a232 1
 		}
@


1.141
log
@Cleanups and improvements:

* Log more events (especially client session) and use a better scheme
  for that: each messages is prefixed with a token to easily identify
  its class:
    - info/warn/debug: general server messages
    - smtp-in: smtp client connections
    - relay: status update for relayed messages
    - delivery: status update for local deliveries

* Implement "smtpctl monitor" to display updates of selected internal
  counters.

* When reloading the on-disk queue at startup do not commit a message
  if no envelope was submitted for that message.

* Remove unused stuff in the config parser.

ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.140 2012/10/25 09:51:08 eric Exp $	*/
d422 10
a431 1
		if (! queue_envelope_load(evpid, &envelope))
a440 8
		if (msgid && evpid_to_msgid(evpid) != msgid && evpcount) {
			imsg_compose_event(env->sc_ievs[PROC_SCHEDULER],
			    IMSG_QUEUE_COMMIT_MESSAGE, 0, 0, -1, &msgid,
			    sizeof msgid);
			evpcount = 0;
		}

		msgid = evpid_to_msgid(evpid);
@


1.140
log
@Make the mda request the message fd from the queue when needed, instead of
pushing the fd with the envelope.  This allows the mda to deal itself with
session limits.  Envelopes are sent at full rate to the mda, which buffers
them on per-user queues, or sends them back for rescheduling if it already
has too many pending envelopes.  Delivery sessions are created (within per-
user and global limits) to drain the queues.

This makes the server handle envelope bursts more efficiently.

ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.139 2012/10/14 18:45:34 eric Exp $	*/
d149 2
a150 1
			log_envelope(&evp, NULL, "Removed by administrator");
d160 1
a160 1
			log_envelope(&evp, NULL, evp.errorline);
d294 1
a294 1
		log_warnx("queue: double bounce!");
d296 1
a296 1
		log_warnx("queue: no return path!");
d298 1
a298 1
		log_warnx("queue: cannot bounce!");
d300 1
a300 1
		log_debug("queue: bouncing evp:%016" PRIx64
d307 1
d327 1
a327 1
	log_info("queue handler exiting");
d409 2
a410 1
	static uint32_t		 last_msgid = 0;
d417 1
a417 1
		log_debug("queue: loading queue into scheduler");
d422 4
a425 1
		if (queue_envelope_load(evpid, &envelope))
d429 2
d432 1
a432 1
		if (last_msgid && evpid_to_msgid(evpid) != last_msgid)
d434 4
a437 2
			    IMSG_QUEUE_COMMIT_MESSAGE, 0, 0, -1, &last_msgid,
			    sizeof last_msgid);
d439 1
a439 1
		last_msgid = evpid_to_msgid(evpid);
d446 1
a446 1
	if (last_msgid) {
d448 2
a449 2
		    IMSG_QUEUE_COMMIT_MESSAGE, 0, 0, -1, &last_msgid,
		    sizeof last_msgid);
d452 1
a452 1
	log_debug("queue: done loading queue into scheduler");
@


1.139
log
@When pushing too many envelopes to the mda at once, we can hit a filedesc
exhaustion situation that kills the server.  For now, put a safe limit on
the number of envelopes sent by the queue process to the mda.

ok gilles@@ chl@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.138 2012/10/14 13:31:46 chl Exp $	*/
a50 2
#define MDA_RUNMAX	50

a53 1
	static size_t		 mda_running;
a166 6
			if (mda_running >= MDA_RUNMAX) {
				imsg_compose_event(env->sc_ievs[PROC_SCHEDULER],
				    IMSG_QUEUE_DELIVERY_TEMPFAIL, 0, 0, -1,
				    &evp, sizeof evp);
				return;
			}
a167 1
			fd = queue_message_fd_r(evpid_to_msgid(id));
d169 1
a169 2
			    IMSG_MDA_SESS_NEW, 0, 0, fd, &evp, sizeof evp);
			mda_running += 1;
a215 2
			if (iev->proc == PROC_MDA)
				mda_running--;
a224 2
			if (iev->proc == PROC_MDA)
				mda_running--;
a233 2
			if (iev->proc == PROC_MDA)
				mda_running--;
a242 2
			if (iev->proc == PROC_MDA)
				mda_running--;
@


1.138
log
@substitute wrong comas into semicolons

ok gilles@@ eric@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.137 2012/09/21 12:33:32 eric Exp $	*/
d51 2
d56 1
d169 7
a175 1
				errx(1, "cannot load evp:%016" PRIx64, id),
d180 1
d227 2
d238 2
d249 2
d260 2
@


1.137
log
@Add a log_envelope() function that log envelope status in a uniform way.
It automagically adds an rcpt=<user@@domain> field if "dest" differs from
the original "rcpt". The function takes an "extra" parameter that allows
to add some specific info depending on the context.

ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.136 2012/09/19 18:20:36 eric Exp $	*/
d188 1
a188 1
				errx(1, "cannot load evp:%016" PRIx64, id),
@


1.136
log
@Remove DF_ENQUEUE flag. It is mostly unused and logically broken.
Ignore it in existing envelopes until it gets completely dropped.
Change "smtpctl show queue" to display the address family of the
envelope source instead of the ENQUEUE flag.

ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.135 2012/09/16 16:43:28 chl Exp $	*/
d149 1
a149 6
			envelope_set_errormsg(&evp, "Removed by administrator");
			log_info("%016" PRIx64 ": to=<%s@@%s>, delay=%s, stat=%s",
			    evp.id, evp.dest.user,
			    evp.dest.domain,
			    duration_to_text(time(NULL) - evp.creation),
			    evp.errorline);
a157 5
			log_info("%016" PRIx64 ": to=<%s@@%s>, delay=%s, stat=%s",
			    evp.id, evp.dest.user,
			    evp.dest.domain,
			    duration_to_text(time(NULL) - evp.creation),
			    evp.errorline);
d159 1
@


1.135
log
@Factorize log_imsg() in imsg_dispatch() instead of in each imsg_callback()'s
and put it out of profiling, so it's not accounted.

While there, for PROC_PARENT:
- set smtpd_process for PROC_PARENT
- use setproctitle() like other processes

ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.134 2012/09/10 14:22:11 eric Exp $	*/
a88 2
				stat_increment(e->flags & DF_ENQUEUED ?
				    "queue.local" : "queue.remote", 1);
@


1.134
log
@nasty typo.

ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.133 2012/08/25 22:03:26 gilles Exp $	*/
a59 2

	log_imsg(PROC_QUEUE, iev->proc, imsg);
@


1.133
log
@- add myself to the copyright in control.c, i've done quite a few changes
there in the last few years ;-)
- get rid of availdesc(): getdtablecount() is so much more reliable
- get rid of env->sc_maxconn, we can be much smarter with getdtablecount()
	and getdtablesize()
- disable accept when we hit the control process fd reserve
- disable accept when we fail
- enable accept when we're back below the limit

this is not the full fd exhaustion diff, i'll merge changes from relayd
tomorrow, this was only required to get rid of the env->sc_maxconn and
availdesc() mess

"reads alright" eric@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.132 2012/08/25 10:23:12 gilles Exp $	*/
d165 1
a165 1
				errx(1, "cannot load evp:%016" PRIx64, id),
@


1.132
log
@- introduce struct stat_value
- statistics can now have a type (counter, timestamp, timeval, timespec and
  possibly others in the future)
- stat_increment() / stat_decrement() now take an increment/decrement value
  and are at the moment only of type counter
- stat_set() now takes a stat_value
- provide helpers to convert raw values to stat_value

ok eric@@, ok chl@@

while at it fix a rq_queue_dump() call using a bogus timestamp in scheduler
ramqueue.
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.131 2012/08/24 21:24:25 eric Exp $	*/
a398 5
	/*
	 * queue opens fds for four purposes: smtp, mta, mda, and bounces.
	 * Therefore, use all available fd space and set the maxconn (=max
	 * session count for mta and mda) to a quarter of this value.
	 */
a399 2
	if ((env->sc_maxconn = availdesc() / 4) < 1)
		fatalx("queue: fd starvation");
@


1.131
log
@log forced removal and expiration of envelopes to maillog.
suggested by Jan Stary.

move queue loading notification to log_debug() while there.

ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.130 2012/08/24 18:46:46 eric Exp $	*/
d92 1
a92 1
				    "queue.local" : "queue.remote");
@


1.130
log
@When an smtp session fails and IMSG_QUEUE_REMOVE_MESSAGE is sent to the
queue, also notify the scheduler so it can rollback the current update.
Send only the msgid while there.

ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.129 2012/08/24 18:26:01 eric Exp $	*/
d150 9
a158 1
			evp.id = *(uint64_t*)(imsg->data);
d166 6
a171 1
			envelope_set_errormsg(&evp, "envelope expired");
d435 1
a435 1
		log_info("queue: loading queue into scheduler");
@


1.129
log
@Error out if queue_envelope_load() failed, rather than sending crap to
the mta/mda.

ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.128 2012/08/21 13:13:17 eric Exp $	*/
d79 5
a83 1
			queue_message_incoming_delete(evpid_to_msgid(e->id));
@


1.128
log
@Re-enable loop detection, but in mta and mda this time.

ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.127 2012/08/18 20:52:36 eric Exp $	*/
d152 2
a153 1
			queue_envelope_load(id, &evp);
d161 2
a162 1
			queue_envelope_load(id, &evp);
d183 2
a184 1
			queue_envelope_load(id, &evp);
@


1.127
log
@zap struct mta_batch. Only pass ids where needed.

ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.126 2012/08/18 18:18:23 gilles Exp $	*/
d227 9
@


1.126
log
@- introduce stat_backend, an API for pluggable statistic backends
  > statistics are no longer static structures in shared memory
  > statistics are only set, smtpd never uses them in its logic
  > each statistic is a key/value where key can be any (dynamic) string
- convert all uses of the former API to use the new one
- implement stat_ramstat that keeps non-persistent stats in ram structure

ok eric@@, ok chl@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.125 2012/08/11 19:18:36 chl Exp $	*/
d54 1
a54 1
	static struct mta_batch	 batch, *mta_batch;
d173 4
a176 1
			bzero(&batch, sizeof batch);
a181 7
			if (!batch.id) {   
				batch.id = generate_uid();
				batch.relay = evp.agent.mta.relay;
				imsg_compose_event(env->sc_ievs[PROC_MTA],
				    IMSG_BATCH_CREATE, 0, 0, -1,
				    &batch, sizeof batch);
			}
d183 1
a183 1
			evp.batch_id = batch.id;
d191 1
a191 1
			    &batch.id, sizeof batch.id);
d199 1
a199 2
			mta_batch = imsg->data;
			fd = queue_message_fd_r(mta_batch->msgid);
d201 1
a201 1
			    fd, mta_batch, sizeof *mta_batch);
@


1.125
log
@Add missing header needed by PRI format string
Add missing header needed by time()

ok eric@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.124 2012/08/09 16:00:31 eric Exp $	*/
d88 1
a88 1
				    STATS_QUEUE_LOCAL : STATS_QUEUE_REMOTE);
@


1.124
log
@Allow failure reports for different recipients of the same message
to be grouped into a single bounce message.

The bounce structure keeps a list of envelopes.  For now, the list
is constructed by delaying the re-enqueuing of a bounce envelope a
bit, to wait for other bounces from the same message to be part of
the same report.
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.123 2012/08/09 09:48:02 eric Exp $	*/
d31 1
d38 1
@


1.123
log
@Improve the message flows to completely isolate operations on the
queue backend within the queue process.

The scheduler sends envelope ids to the queue process which loads
the envelope and forward the request to the agent responsible for
the delivery.  The result is sent by the agent to the queue which
updates the storage before notifying the scheduler.

Bounces are created and enqueued (from the client side) by the
queue process, rather than the scheduler.

ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.122 2012/08/08 08:50:42 eric Exp $	*/
d108 1
a108 2
			queue_envelope_load(id, &evp);
			bounce_session(imsg->fd, &evp);
d167 1
a167 2
			imsg_compose_event(env->sc_ievs[PROC_SMTP],
			    IMSG_SMTP_ENQUEUE, 0, 0, -1, &id, sizeof id);
@


1.122
log
@Improve the scheduler backend API.

New envelopes are pushed into the scheduler through the insert()
commit() rollback() transactional interface functions.

Worklists are pulled from the scheduler through a single batch()
interface function, which returns a list of envelope ids and the
type of processing. Envelopes returned in this batch are said to
be "in-flight", as opposed to "pending". They are supposed to be
processed in some way, and either updated() or deleted() at some
point.

The schedule()/remove() functions are used to alter the internal
state of "pending" envelopes to make them schedulable.  The enve-
lopes will be part of a worklist on the next call to batch().

Rewrite the scheduler_ramqueue backend.

The initial queue loading in now done by the queue.

ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.121 2012/07/09 09:57:53 gilles Exp $	*/
d44 1
d52 1
d54 1
a54 2
	struct envelope		*e;
	struct mta_batch	*mta_batch;
d56 2
d72 2
a73 2
			imsg_compose_event(iev, IMSG_QUEUE_CREATE_MESSAGE, 0, 0, -1,
			    &ss, sizeof ss);
d83 2
a84 1
			if (queue_message_commit(evpid_to_msgid(e->id)))
d87 4
a90 1
			else
d93 2
a94 6
			imsg_compose_event(iev, IMSG_QUEUE_COMMIT_MESSAGE, 0, 0, -1,
			    &ss, sizeof ss);

			if (ss.code != 421)
				queue_pass_to_scheduler(iev, imsg);

d102 2
a103 2
			imsg_compose_event(iev, IMSG_QUEUE_MESSAGE_FILE, 0, 0, fd,
			    &ss, sizeof ss);
d107 3
a109 1
			queue_pass_to_scheduler(iev, imsg);
a115 1

d118 2
a119 3
			ss.id = e->session_id;
			ret = queue_envelope_create(e);
			if (ret == 0) {
d124 5
d143 55
a197 5
		/* forward imsgs from scheduler on its behalf */
		imsg_compose_event(env->sc_ievs[imsg->hdr.peerid], imsg->hdr.type,
		    0, imsg->hdr.pid, imsg->fd, (char *)imsg->data,
		    imsg->hdr.len - sizeof imsg->hdr);
		return;
d200 1
a200 1
	if (iev->proc == PROC_MTA) {
d210 7
d218 6
a223 3
		case IMSG_QUEUE_DELIVERY_PERMFAIL:
		case IMSG_BATCH_DONE:
			queue_pass_to_scheduler(iev, imsg);
a224 2
		}
	}
a225 4
	if (iev->proc == PROC_MDA) {
		switch (imsg->hdr.type) {
		case IMSG_QUEUE_DELIVERY_OK:
		case IMSG_QUEUE_DELIVERY_TEMPFAIL:
d227 6
a232 2
		case IMSG_MDA_SESS_NEW:
			queue_pass_to_scheduler(iev, imsg);
a242 1
		case IMSG_QUEUE_SCHEDULE:
d270 30
d400 1
a400 1
void
d404 1
a405 1
	static uint64_t		 last_evpid = 0;
d416 4
a419 2
		if (! queue_envelope_load(evpid, &envelope))
			continue;
d421 1
a421 3
		if (evpid_to_msgid(evpid) != evpid_to_msgid(last_evpid) &&
		    last_evpid != 0) {
			envelope.id = last_evpid;
d423 2
a424 3
			    IMSG_QUEUE_COMMIT_MESSAGE, 0, 0, -1, &envelope,
			    sizeof envelope);
		}
d426 1
a426 1
		last_evpid = evpid;
d433 1
a433 2
	if (last_evpid) {
		envelope.id = last_evpid;
d435 2
a436 2
		    IMSG_QUEUE_COMMIT_MESSAGE, 0, 0, -1, &envelope,
		    sizeof envelope);
d439 1
a439 1
	log_info("queue: done loading queue into scheduler");
a440 16
}

void
queue_submit_envelope(struct envelope *ep)
{
	imsg_compose_event(env->sc_ievs[PROC_QUEUE],
	    IMSG_QUEUE_SUBMIT_ENVELOPE, 0, 0, -1,
	    ep, sizeof(*ep));
}

void
queue_commit_envelopes(struct envelope *ep)
{
	imsg_compose_event(env->sc_ievs[PROC_QUEUE],
	    IMSG_QUEUE_COMMIT_ENVELOPES, 0, 0, -1,
	    ep, sizeof(*ep));
@


1.121
log
@- runner is the terminology we used back when we had runqueues, we no
  longer have them and runner is actually a scheduler so rename.
- introduce scheduler_backend which does the same to scheduler than
  queue_backend does to queue and map_backend does to maps
- remove all occurences of RUNNER and runner, replace them with SCHEDULER
  and scheduler

ok eric@@, ok chl@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.120 2012/07/08 18:13:08 chl Exp $	*/
d6 1
d43 1
d229 2
a230 1

d292 6
d303 45
@


1.120
log
@remove enum queue_kind from queue_fsqueue.c.
incoming messages are now always stored in /incoming, whatever the queue_backend is.
remove QOP_FD_RW and fsqueue_message_fd_rw().
while there check return value of generated paths before calling rmtree()

with advice from gilles@@ and eric@@

ok gilles@@ eric@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.119 2012/06/20 20:45:23 eric Exp $	*/
d42 1
a42 1
static void queue_pass_to_runner(struct imsgev *, struct imsg *);
d88 1
a88 1
				queue_pass_to_runner(iev, imsg);
d102 1
a102 1
			queue_pass_to_runner(iev, imsg);
d132 2
a133 2
	if (iev->proc == PROC_RUNNER) {
		/* forward imsgs from runner on its behalf */
d153 1
a153 1
			queue_pass_to_runner(iev, imsg);
d164 1
a164 1
			queue_pass_to_runner(iev, imsg);
d177 1
a177 1
			queue_pass_to_runner(iev, imsg);
d186 1
a186 1
			queue_pass_to_runner(iev, imsg);
d195 1
a195 1
queue_pass_to_runner(struct imsgev *iev, struct imsg *imsg)
d197 1
a197 1
	imsg_compose_event(env->sc_ievs[PROC_RUNNER], imsg->hdr.type,
d232 7
a238 7
		{ PROC_PARENT,	imsg_dispatch },
		{ PROC_CONTROL,	imsg_dispatch },
		{ PROC_SMTP,	imsg_dispatch },
		{ PROC_MDA,	imsg_dispatch },
		{ PROC_MTA,	imsg_dispatch },
		{ PROC_LKA,	imsg_dispatch },
		{ PROC_RUNNER,	imsg_dispatch }
d284 1
a284 1
		fatalx("runner: fd starvation");
@


1.119
log
@Finally get rid of the queue_kind enum in the queue API. Keep that
internally in fsqueue backend for now, and let the fsqueue_message()
and fsqueue_envelope() dispatchers do the right thing.

Based on a diff by chl@@

ok chl@@ gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.118 2012/06/18 10:21:16 chl Exp $	*/
d72 1
a72 1
			queue_message_delete(evpid_to_msgid(e->id));
@


1.118
log
@fix potential use of uninitialized variable.

found with valgrind on -portable.

ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.117 2012/01/28 11:33:07 gilles Exp $	*/
d64 1
a64 1
			ret = queue_message_create(Q_INCOMING, &ss.u.msgid);
d72 1
a72 1
			queue_message_delete(Q_INCOMING, evpid_to_msgid(e->id));
d78 1
a78 1
			if (queue_message_commit(Q_INCOMING, evpid_to_msgid(e->id)))
d94 1
a94 1
			fd = queue_message_fd_rw(Q_INCOMING, evpid_to_msgid(e->id));
d113 1
a113 1
			ret = queue_envelope_create(Q_INCOMING, e);
d144 1
a144 1
			fd = queue_message_fd_r(Q_QUEUE, mta_batch->msgid);
@


1.117
log
@- introduce the scheduler_backend API
- introduce the scheduler_ramqueue backend
- remove all occurences of ramqueue outside of the ramqueue backend
- teach runner how to use the new API

it is now possible to write custom schedulers !

ok eric@@, ok chl@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.116 2012/01/13 21:58:35 eric Exp $	*/
d77 1
@


1.116
log
@queue_message_purge() and queue_message_delete() are actually the same
thing. Remove queue_message_purge() in favor of queue_message_delete
and simplify fsqueue_message_delete() implementation to move the
message dir to purge/

ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.115 2012/01/13 14:01:57 eric Exp $	*/
d51 1
a51 1
	struct ramqueue_batch	*rq_batch;
d142 2
a143 2
			rq_batch = imsg->data;
			fd = queue_message_fd_r(Q_QUEUE, rq_batch->msgid);
d145 1
a145 1
			    fd, rq_batch, sizeof *rq_batch);
@


1.115
log
@Stop using envelope->status to report delivery outcome to the
runner/queue.  Instead, replace IMSG_QUEUE_MESSAGE_UPDATE with three
messages:

- IMSG_QUEUE_DELIVERY_OK
- IMSG_QUEUE_DELIVERY_TEMPFAIL
- IMSG_QUEUE_DELIVERY_PERMFAIL

1) it's less confusing as status is also used by smtp
2) it's easier to see what happens just looking at imsg traces
3) it makes the code path generally easier to follow
4) it's safer because it enforces clear semantics and intent, whereas
   the status field is loosely defined and could carry bogus values.

ok gilles@@ chl@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.114 2012/01/11 17:46:36 eric Exp $	*/
d72 1
a72 1
			queue_message_purge(Q_INCOMING, evpid_to_msgid(e->id));
@


1.114
log
@Simplify runner/queue by getting rid of Q_PURGE.  Instead, let smtpd
periodically clear the purge/ directory.  At init time, the fsqueue
backend simply moves the existing incoming/ dir in purge/ to discard
aborted sessions.

ok gilles@@ chl@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.113 2011/11/21 18:57:54 eric Exp $	*/
d148 3
a150 1
		case IMSG_QUEUE_MESSAGE_UPDATE:
d159 3
a161 1
		case IMSG_QUEUE_MESSAGE_UPDATE:
@


1.113
log
@get rid of the "enqueue/" queue; use "incoming/" instead.

ok gilles@@ chl@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.112 2011/11/15 23:06:39 gilles Exp $	*/
a44 1
static void queue_purge(enum queue_kind);
a283 2
	queue_purge(Q_INCOMING);

a288 15
}

static void
queue_purge(enum queue_kind qkind)
{
	struct qwalk	*q;
	u_int32_t	 msgid;
	u_int64_t	 evpid;

	q = qwalk_new(qkind, 0);
	while (qwalk(q, &evpid)) {
		msgid = evpid_to_msgid(evpid);
		queue_message_purge(qkind, msgid);
	}
	qwalk_close(q);
@


1.112
log
@Qwalk, our API to linearly walk over the persistent queue, did not take the
queue_backend into account and assumed a filesystem with a specific layout.

This commit does plenty of things:

- make qwalk an abstraction in the queue_backend API, and impose queue
  drivers to implement qwalk_open(), qwalk() and qwalk_close();

- move previous qwalk_open(), qwalk() and qwalk_close() to the fsqueue
  driver since they were fsqueue specific ...

- make qwalk API work with msgid/evpid instead of pathnames since we're
  going to use the queue_backend API to load envelopes by evpid anyway;

- makes smtpd use *solely* the queue_backend API when manipulating the
  queue. pathnames were removed from smtpd.h and moved into the fsqueue
  which means we can now store a queue anywhere ... as long as we write
  the ten functions or so required for a queue driver ;-)

ok eric@@, ok chl@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.111 2011/11/14 19:23:41 chl Exp $	*/
d65 1
a65 4
			if (e->flags & DF_ENQUEUED)
				ret = queue_message_create(Q_ENQUEUE, &ss.u.msgid);
			else
				ret = queue_message_create(Q_INCOMING, &ss.u.msgid);
d73 1
a73 4
			if (e->flags & DF_ENQUEUED)
				queue_message_purge(Q_ENQUEUE, evpid_to_msgid(e->id));
			else
				queue_message_purge(Q_INCOMING, evpid_to_msgid(e->id));
d78 6
a83 11
			if (e->flags & DF_ENQUEUED) {
				if (queue_message_commit(Q_ENQUEUE, evpid_to_msgid(e->id)))
					stat_increment(STATS_QUEUE_LOCAL);
				else
					ss.code = 421;
			} else {
				if (queue_message_commit(Q_INCOMING, evpid_to_msgid(e->id)))
					stat_increment(STATS_QUEUE_REMOTE);
				else
					ss.code = 421;
			}
d94 1
a94 4
			if (e->flags & DF_ENQUEUED)
				fd = queue_message_fd_rw(Q_ENQUEUE, evpid_to_msgid(e->id));
			else
				fd = queue_message_fd_rw(Q_INCOMING, evpid_to_msgid(e->id));
d113 1
a113 7

			/* Write to disk */
			if (e->flags & DF_ENQUEUED)
				ret = queue_envelope_create(Q_ENQUEUE, e);
			else
				ret = queue_envelope_create(Q_INCOMING, e);

a285 1
	queue_purge(Q_ENQUEUE);
@


1.111
log
@when receiving an unexpected imsg, print its name.

with help and ideas from eric@@

ok eric@@ gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.110 2011/11/07 11:14:10 eric Exp $	*/
d45 1
a45 1
static void queue_purge(enum queue_kind, char *);
d305 2
a306 2
	queue_purge(Q_INCOMING, PATH_INCOMING);
	queue_purge(Q_ENQUEUE, PATH_ENQUEUE);
d316 1
a316 1
queue_purge(enum queue_kind qkind, char *queuepath)
a317 1
	char		 path[MAXPATHLEN];
d319 2
d322 3
a324 9
	q = qwalk_new(queuepath);

	while (qwalk(q, path)) {
		u_int32_t msgid;

		if ((msgid = filename_to_msgid(basename(path))) == 0) {
			log_warnx("queue_purge: invalid evpid");
			continue;
		}
a326 1

@


1.110
log
@Let the smtpd process handle the enqueueing of offline messages at
startup, rather than playing tricks with the runner. This will allow
further simplifications and improvements in the runner/queue.

ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.109 2011/10/26 20:47:31 gilles Exp $	*/
d27 1
d207 1
a207 1
	fatalx("queue_imsg: unexpected imsg");
@


1.109
log
@- fix smtpctl pause/resume so the ramqueue scheduling is done correctly
- rename IMSG and smtpctl pause/resume parameters
- update man page

tested by me, ok chl@@, eric@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.108 2011/10/23 09:30:07 gilles Exp $	*/
a198 4
		case IMSG_PARENT_ENQUEUE_OFFLINE:
			queue_pass_to_runner(iev, imsg);
			return;

@


1.108
log
@fsqueue no longer stores envelopes by dumping the structure, instead use a
couple of load/dump functions to convert to and from a human readable fmt.
while at it kill struct delivery and merge back its fields to the envelope.

this basically means we shouldn't require users to flush their queues every
time we make a change to struct envelope.

work is not done, but we're at a better state than the binary fsqueue so
we'll improve it in-tree.

has been running on my own box for the last 12 hours or so
ok eric@@, chl@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.107 2011/10/09 18:39:53 eric Exp $	*/
d186 4
a189 4
		case IMSG_QUEUE_PAUSE_LOCAL:
		case IMSG_QUEUE_PAUSE_OUTGOING:
		case IMSG_QUEUE_RESUME_LOCAL:
		case IMSG_QUEUE_RESUME_OUTGOING:
@


1.107
log
@show messages sent between processes in debug mode

ok gilles@@ chl@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.106 2011/09/01 19:56:49 eric Exp $	*/
d64 1
a64 1
			if (e->delivery.flags & DF_ENQUEUED)
d75 2
a76 2
			if (e->delivery.flags & DF_ENQUEUED)
				queue_message_purge(Q_ENQUEUE, evpid_to_msgid(e->delivery.id));
d78 1
a78 1
				queue_message_purge(Q_INCOMING, evpid_to_msgid(e->delivery.id));
d83 2
a84 2
			if (e->delivery.flags & DF_ENQUEUED) {
				if (queue_message_commit(Q_ENQUEUE, evpid_to_msgid(e->delivery.id)))
d89 1
a89 1
				if (queue_message_commit(Q_INCOMING, evpid_to_msgid(e->delivery.id)))
d104 2
a105 2
			if (e->delivery.flags & DF_ENQUEUED)
				fd = queue_message_fd_rw(Q_ENQUEUE, evpid_to_msgid(e->delivery.id));
d107 1
a107 1
				fd = queue_message_fd_rw(Q_INCOMING, evpid_to_msgid(e->delivery.id));
d128 1
a128 1
			if (e->delivery.flags & DF_ENQUEUED)
@


1.106
log
@Introduce a small set of functions to manage stat counters in a
simpler and hopefully saner way.

ok gilles@@ chl@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.105 2011/08/29 18:49:29 chl Exp $	*/
d53 2
@


1.105
log
@add missing header needed by signal()

ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.104 2011/05/16 21:05:52 gilles Exp $	*/
d83 1
a83 1
					env->stats->queue.inserts_local++;
d88 1
a88 1
					env->stats->queue.inserts_remote++;
@


1.104
log
@murder struct path and make sure smtpd uses simpler structures that do not
bring a shitload of unnecessary information everywhere. this required many
parts of smtpd to be refactored and more specifically envelope expansion.

in the process lots of code got simplified, and the envelope expansion code
has been isolated to lka_session.c with some longstanding bugs fixed.

Diff has been tested by many with no major regression reported.
armani@@ spotted a bug in a setup where a domain is listed a both primary
and virtual, I will fix that in-tree as it's becoming painful to maintain
this diff out.
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.103 2011/05/01 12:57:11 eric Exp $	*/
d31 1
@


1.103
log
@the smtpd env is meant to be global, so do not pass it all around.

discussed with and ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.102 2011/04/17 13:36:07 gilles Exp $	*/
d49 1
a49 1
	struct envelope		*m;
d54 1
a54 1
		m = imsg->data;
d58 1
a58 1
			ss.id = m->session_id;
d61 1
a61 1
			if (m->flags & F_MESSAGE_ENQUEUED)
d72 2
a73 2
			if (m->flags & F_MESSAGE_ENQUEUED)
				queue_message_purge(Q_ENQUEUE, evpid_to_msgid(m->evpid));
d75 1
a75 1
				queue_message_purge(Q_INCOMING, evpid_to_msgid(m->evpid));
d79 3
a81 3
			ss.id = m->session_id;
			if (m->flags & F_MESSAGE_ENQUEUED) {
				if (queue_message_commit(Q_ENQUEUE, evpid_to_msgid(m->evpid)))
d86 1
a86 1
				if (queue_message_commit(Q_INCOMING, evpid_to_msgid(m->evpid)))
d100 3
a102 3
			ss.id = m->session_id;
			if (m->flags & F_MESSAGE_ENQUEUED)
				fd = queue_message_fd_rw(Q_ENQUEUE, evpid_to_msgid(m->evpid));
d104 1
a104 1
				fd = queue_message_fd_rw(Q_INCOMING, evpid_to_msgid(m->evpid));
d118 1
a118 1
		m = imsg->data;
d122 1
a122 7
			m->id = generate_uid();
			ss.id = m->session_id;

			if (IS_MAILBOX(m->recipient) || IS_EXT(m->recipient))
				m->type = T_MDA_MESSAGE;
			else
				m->type = T_MTA_MESSAGE;
d125 2
a126 2
			if (m->flags & F_MESSAGE_ENQUEUED)
				ret = queue_envelope_create(Q_ENQUEUE, m);
d128 1
a128 1
				ret = queue_envelope_create(Q_INCOMING, m);
d139 1
a139 1
			ss.id = m->session_id;
d337 1
a337 1
queue_submit_envelope(struct envelope *m)
d341 1
a341 1
	    m, sizeof(*m));
d345 1
a345 1
queue_commit_envelopes(struct envelope *m)
d349 1
a349 1
	    m, sizeof(*m));
@


1.102
log
@cleanups, cosmethic changes, functions that should be static are now static
no functionnal change
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.101 2011/04/17 11:39:22 gilles Exp $	*/
d39 2
a40 2
static void queue_imsg(struct smtpd *, struct imsgev *, struct imsg *);
static void queue_pass_to_runner(struct smtpd *, struct imsgev *, struct imsg *);
d43 1
a43 1
static void queue_purge(struct smtpd *, enum queue_kind, char *);
d46 1
a46 1
queue_imsg(struct smtpd *env, struct imsgev *iev, struct imsg *imsg)
d62 1
a62 1
				ret = queue_message_create(env, Q_ENQUEUE, &ss.u.msgid);
d64 1
a64 1
				ret = queue_message_create(env, Q_INCOMING, &ss.u.msgid);
d73 1
a73 1
				queue_message_purge(env, Q_ENQUEUE, evpid_to_msgid(m->evpid));
d75 1
a75 1
				queue_message_purge(env, Q_INCOMING, evpid_to_msgid(m->evpid));
d81 1
a81 1
				if (queue_message_commit(env, Q_ENQUEUE, evpid_to_msgid(m->evpid)))
d86 1
a86 1
				if (queue_message_commit(env, Q_INCOMING, evpid_to_msgid(m->evpid)))
d95 1
a95 1
				queue_pass_to_runner(env, iev, imsg);
d102 1
a102 1
				fd = queue_message_fd_rw(env, Q_ENQUEUE, evpid_to_msgid(m->evpid));
d104 1
a104 1
				fd = queue_message_fd_rw(env, Q_INCOMING, evpid_to_msgid(m->evpid));
d112 1
a112 1
			queue_pass_to_runner(env, iev, imsg);
d132 1
a132 1
				ret = queue_envelope_create(env, Q_ENQUEUE, m);
d134 1
a134 1
				ret = queue_envelope_create(env, Q_INCOMING, m);
d166 1
a166 1
			fd = queue_message_fd_r(env, Q_QUEUE, rq_batch->msgid);
d173 1
a173 1
			queue_pass_to_runner(env, iev, imsg);
d182 1
a182 1
			queue_pass_to_runner(env, iev, imsg);
d195 1
a195 1
			queue_pass_to_runner(env, iev, imsg);
d203 1
a203 1
			queue_pass_to_runner(env, iev, imsg);
d208 1
a208 1
			queue_pass_to_runner(env, iev, imsg);
d217 1
a217 1
queue_pass_to_runner(struct smtpd *env, struct imsgev *iev, struct imsg *imsg)
d245 1
a245 1
queue(struct smtpd *env)
d272 1
a272 1
	purge_config(env, PURGE_EVERYTHING);
d292 2
a293 2
	signal_set(&ev_sigint, SIGINT, queue_sig_handler, env);
	signal_set(&ev_sigterm, SIGTERM, queue_sig_handler, env);
d308 2
a309 2
	config_pipes(env, peers, nitems(peers));
	config_peers(env, peers, nitems(peers));
d311 2
a312 2
	queue_purge(env, Q_INCOMING, PATH_INCOMING);
	queue_purge(env, Q_ENQUEUE, PATH_ENQUEUE);
d322 1
a322 1
queue_purge(struct smtpd *env, enum queue_kind qkind, char *queuepath)
d336 1
a336 1
		queue_message_purge(env, qkind, msgid);
d343 1
a343 1
queue_submit_envelope(struct smtpd *env, struct envelope *m)
d351 1
a351 1
queue_commit_envelopes(struct smtpd *env, struct envelope *m)
@


1.101
log
@a structure describing an envelope should be called struct envelope, not
struct message ...
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.100 2011/04/17 11:16:57 gilles Exp $	*/
d39 5
a43 5
void		queue_imsg(struct smtpd *, struct imsgev *, struct imsg *);
void		queue_pass_to_runner(struct smtpd *, struct imsgev *, struct imsg *);
__dead void	queue_shutdown(void);
void		queue_sig_handler(int, short, void *);
void		queue_purge(struct smtpd *, enum queue_kind, char *);
d45 1
a45 2

void
d216 1
a216 1
void
d224 1
a224 1
void
d237 1
a237 1
void
d321 1
a321 1
void
@


1.100
log
@no functionnal change, getting rid of deprecated prototypes
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.99 2011/04/15 17:01:05 gilles Exp $	*/
d50 1
a50 1
	struct message		*m;
d344 1
a344 1
queue_submit_envelope(struct smtpd *env, struct message *message)
d348 1
a348 1
	    message, sizeof(struct message));
d352 1
a352 1
queue_commit_envelopes(struct smtpd *env, struct message *message)
d356 1
a356 1
	    message, sizeof(struct message));
@


1.99
log
@kill message_id and message_uid

smtpd now has an evpid associated to each delivery message, the evpid is an
u_int64_t where the upper 32 bits are the msgid, and the 32 bits are the
envelope unique identifier for that message. this results in lots of space
saved in both disk-based and ram-based queues, but also simplifies a lot of
code.

change has been stressed on my desktop, and has ran on my MX for the entire
afternoon without a regression.
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.98 2011/04/14 23:26:16 gilles Exp $	*/
a44 2
u_int32_t	filename_to_msgid(char *);
u_int64_t	filename_to_evpid(char *);
@


1.98
log
@- implement missing operations for fsqueue:
	fsqueue_envelope_create(), fsqueue_message_purge()
- kill deprecated functions in queue_shared.c

At this point fsqueue backend is almost complete, all that is left to do is
to move the qwalk() API inside the queue_backend API, then make sure smtpd
is no longer calling anything queue related directly.
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.97 2011/04/14 22:36:09 gilles Exp $	*/
d45 3
d63 1
a63 1
			bzero(ss.u.msgid, sizeof ss.u.msgid);
d65 1
a65 1
				ret = queue_message_create(env, Q_ENQUEUE, ss.u.msgid);
d67 1
a67 1
				ret = queue_message_create(env, Q_INCOMING, ss.u.msgid);
d76 1
a76 1
				queue_message_purge(env, Q_ENQUEUE, m->message_id);
d78 1
a78 1
				queue_message_purge(env, Q_INCOMING, m->message_id);
d84 1
a84 1
				if (queue_message_commit(env, Q_ENQUEUE, m->message_id))
d89 1
a89 1
				if (queue_message_commit(env, Q_INCOMING, m->message_id))
d105 1
a105 1
				fd = queue_message_fd_rw(env, Q_ENQUEUE, m->message_id);
d107 1
a107 1
				fd = queue_message_fd_rw(env, Q_INCOMING, m->message_id);
d169 1
a169 1
			fd = queue_message_fd_r(env, Q_QUEUE, rq_batch->m_id);
d332 9
a340 2
	while (qwalk(q, path))
		queue_message_purge(env, qkind, basename(path));
@


1.97
log
@- implement fsqueue_message_create() and fsqueue_message_commit()
- change a few prototypes to allow bounce messages to use the
	queue_backend API until it gets merged in
- kill functions of the queue API that have been deprecated
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.96 2011/04/14 21:53:45 gilles Exp $	*/
d43 1
a43 8
void		queue_purge(char *);

int		queue_create_layout_message(char *, char *);
void		queue_delete_layout_message(char *, char *);
int		queue_record_layout_envelope(char *, struct message *);
int		queue_remove_layout_envelope(char *, struct message *);
int		queue_commit_layout_message(char *, struct message *);
int		queue_open_layout_messagefile(char *, struct message *);
d73 1
a73 1
				enqueue_delete_message(m->message_id);
d75 1
a75 1
				queue_delete_incoming_message(m->message_id);
d132 1
a132 1
				ret = enqueue_record_envelope(m);
d134 1
a134 1
				ret = queue_record_incoming_envelope(m);
d311 2
a312 2
	queue_purge(PATH_INCOMING);
	queue_purge(PATH_ENQUEUE);
d322 1
a322 1
queue_purge(char *queuepath)
d330 1
a330 1
		queue_delete_layout_message(queuepath, basename(path));
@


1.96
log
@fsqueue now provides fsqueue_message_fd_r() and fsqueue_message_fd_rw() to
obtain a read{-only,/write} descriptor to the message file.

make sure smtpd uses the new API everywhere it needs a fd, and kill the
many functions that were used until now.
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.95 2011/04/13 20:53:18 gilles Exp $	*/
d69 1
a69 1
				ret = enqueue_create_layout(ss.u.msgid);
d71 1
a71 1
				ret = queue_create_incoming_layout(ss.u.msgid);
d88 1
a88 1
				if (enqueue_commit_message(m))
d93 1
a93 1
				if (queue_commit_incoming_message(m))
@


1.95
log
@following an idea from jacekm@@, smtpd now uses a ram-queue instead of doing
a continuous walk on the disk-queue. the implementation differs from what
jacekm@@ commited (and I backed out) a while ago in that it uses a queue and
a host tree required for upcoming features.

code will be improved in tree, it requires changes to be done in queue and
bounce API, I just wanted to commit a working version first ...

tested by todd@@ and I
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.94 2010/11/28 15:32:00 gilles Exp $	*/
d109 1
a109 1
				fd = enqueue_open_messagefile(m);
d111 1
a111 1
				fd = queue_open_incoming_message_file(m);
d173 1
a173 1
			fd = queue_open_message_file(rq_batch->m_id);
@


1.94
log
@remove unused functions
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.93 2010/11/28 14:35:58 gilles Exp $	*/
d57 1
a57 1
	struct batch		*b;
d100 4
d172 2
a173 2
			b = imsg->data;
			fd = queue_open_message_file(b->message_id);
d175 1
a175 1
			    fd, b, sizeof *b);
a326 10

struct batch *
batch_by_id(struct smtpd *env, u_int64_t id)
{
	struct batch lookup;

	lookup.id = id;
	return SPLAY_FIND(batchtree, &env->batch_queue, &lookup);
}

@


1.93
log
@remove all unused headers
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.92 2010/11/28 13:56:43 gilles Exp $	*/
a42 2
void		queue_setup_events(struct smtpd *);
void		queue_disable_events(struct smtpd *);
a246 10
void
queue_setup_events(struct smtpd *env)
{
}

void
queue_disable_events(struct smtpd *env)
{
}

a316 2
	queue_setup_events(env);
	
@


1.92
log
@a bit of .h cleanups, no functionnal change
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.91 2010/10/09 22:05:35 gilles Exp $	*/
a26 1
#include <errno.h>
a28 1
#include <fcntl.h>
a30 1
#include <signal.h>
@


1.91
log
@backout the "new" queue code commited 4 months ago. it has many good ideas,
is way more optimized than what we had earlier and there's definitely stuff
we want to keep, however it is early optimization that doesn't account for
many features and makes them hard (if not impossible) to write without
ugly workarounds that ruin the purpose of the optimizations.

the backout goes to 30 May's right before the commit and catches up on all
the non-queue related commits that happened since then.

i'll work on reintroducing the ideas from this queue when the basic
features we expect from a MTA are implemented.

suggested on tech@@ about a week ago, no objections, several "please make
smtpd move forward" mails from hackers and tech readers.
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.81 2010/04/22 12:13:33 jacekm Exp $	*/
d29 1
d40 1
@


1.90
log
@- fix a regression caused by latest commit (long story made short: do not
  attempt to expand the local delivery buffer when relaying mail, it was
  kind of ok before but no longer is)
- use the same buffer for local deliveries to files and commands

tested by jmc@@ and I
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.89 2010/07/23 22:23:24 gilles Exp $	*/
a3 1
 * Copyright (c) 2008-2010 Jacek Masiulaniec <jacekm@@dobremiasto.net>
a25 1
#include <sys/uio.h>
a26 1
#include <ctype.h>
a30 1
#include <math.h>
a38 2
#include "queue_backend.h"
#include "client.h"
d40 14
a53 45
void		 queue_imsg(struct smtpd *, struct imsgev *, struct imsg *);
int		 queue_append(struct incoming *, char *);
void		 queue_destroy(struct incoming *);
int		 queue_control(u_int64_t, int);
__dead void	 queue_shutdown(void);
void		 queue_sig_handler(int, short, void *);

void		 queue_mem_init(struct smtpd *);
void		 queue_mem_content_unref(struct content *);

void		 queue_send(int, short, void *);
void		 queue_expire(struct batch *);
void		 queue_update(int, int, u_int64_t, char *);
void		 queue_done(int, int);
void		 queue_schedule(int, struct batch *);
void		 queue_sleep(int);
time_t		 queue_retry(int, time_t, time_t);

void		 queue_bounce_wait(struct content *);
void		 queue_bounce_schedule(int, short, void *);
void		 queue_bounce_init(int, int);
void		 queue_bounce_event(int, short, void *);

int		 queue_detect_loop(struct incoming *);

struct incoming *incoming_alloc(u_int64_t);
struct batch	*incoming_batch(struct incoming *, char *);
void		 incoming_schedule(struct incoming *);

struct content	*content_alloc(u_int64_t);

struct batch	*batch_alloc(struct content *, char *);

struct action	*action_alloc(u_int64_t);
void		 action_insert(struct action *, struct batch *);
struct action	*action_grow(struct action *, char *);
void		 action_free(struct action *);

int		 batchsort(const void *, const void *);

/* table of batches in larval state */
void	**incoming;
int	  incoming_sz;

struct queue runqs[3];
d58 1
a58 2
	struct action		*update;
	struct incoming		*s;
d60 2
a61 4
	u_int64_t		 content_id;
	int			 i, fd, error;
	struct iovec		 iov[2];
	char			 aux[2048]; /* XXX */
d64 2
d67 12
a78 23
		case IMSG_QUEUE_CREATE:
			/*
			 * Create file that will hold mail content.  Its name
			 * uniquely identifies entire mail transaction.  Actions
			 * will refer to the this file as source of mail content.
			 */
			if (queue_be_content_create(&content_id) < 0)
				content_id = INVALID_ID;

			s = incoming_alloc(content_id);
			if (s == NULL)
				fatal(NULL);

			i = table_alloc(&incoming, &incoming_sz);
			incoming[i] = s;

			iov[0].iov_base = &content_id;
			iov[0].iov_len = sizeof content_id;
			iov[1].iov_base = &i;
			iov[1].iov_len = sizeof i;
			imsg_composev(&iev->ibuf, IMSG_QUEUE_CREATE,
			    imsg->hdr.peerid, 0, -1, iov, 2);
			imsg_event_add(iev);
d81 5
a85 12
		case IMSG_QUEUE_DELETE:
			/*
			 * Delete failed transaction's content and actions.
			 */
			memcpy(&i, imsg->data, sizeof i);

			s = table_lookup(incoming, incoming_sz, i);
			if (s == NULL)
				fatalx("queue: bogus delete req");

			queue_destroy(s);
			incoming[i] = NULL;
d88 15
a102 16
		case IMSG_QUEUE_OPEN:
			/*
			 * Open the file that will hold mail content.
			 */
			memcpy(&i, imsg->data, sizeof i);

			s = table_lookup(incoming, incoming_sz, i);
			if (s == NULL)
				fatalx("queue: bogus open req");

			fd = queue_be_content_open(s->content->id, 1);
			if (fd < 0)
				fatal("queue: content open error");

			imsg_compose_event(iev, IMSG_QUEUE_OPEN,
			    imsg->hdr.peerid, 0, fd, NULL, 0);
d105 10
a114 38
		case IMSG_QUEUE_CLOSE:
			/*
			 * Commit mail to queue: we take on responsibility for
			 * performing all requested actions on this content.
			 */
			memcpy(&i, imsg->data, sizeof i);

			s = table_lookup(incoming, incoming_sz, i);
			if (s == NULL)
				fatalx("queue: bogus commit req");

			if (queue_detect_loop(s) < 0) {
				error = S_MESSAGE_PERMFAILURE;
				imsg_compose_event(iev, IMSG_QUEUE_CLOSE,
				    imsg->hdr.peerid, 0, -1, &error, sizeof error);
				return;
			}

			if (queue_be_commit(s->content->id) < 0) {
				error = S_MESSAGE_TEMPFAILURE;
				imsg_compose_event(iev, IMSG_QUEUE_CLOSE,
				    imsg->hdr.peerid, 0, -1, &error, sizeof error);
				return;
			}

			env->stats->queue.inserts++;
			env->stats->queue.length++;

			incoming_schedule(s);
			incoming[i] = NULL;
			for (i = 0; i < s->nlocal; i++)
				free(s->local[i]);
			free(s->local);
			free(s);

			error = 0;
			imsg_compose_event(iev, IMSG_QUEUE_CLOSE,
			    imsg->hdr.peerid, 0, -1, &error, sizeof error);
d118 1
a118 1
			queue_bounce_init(imsg->hdr.peerid, imsg->fd);
d124 2
d127 8
a134 2
		case IMSG_QUEUE_APPEND:
			m = imsg->data;
d136 5
a140 98
			s = table_lookup(incoming, incoming_sz, m->queue_id);
			if (s == NULL)
				fatalx("queue: bogus append");

			switch (m->recipient.rule.r_action) {
			case A_MBOX:
			case A_MAILDIR:
			case A_EXT:
				/* ?|from|to|user1|user2|path */
				if (m->recipient.rule.r_action == A_MBOX)
					strlcpy(aux, "M|", sizeof aux);
				else if (m->recipient.rule.r_action == A_MAILDIR)
					strlcpy(aux, "D|", sizeof aux);
				else
					strlcpy(aux, "P|", sizeof aux);
				if (m->sender.user[0] && m->sender.domain[0]) {
					strlcat(aux, m->sender.user, sizeof aux);
					strlcat(aux, "@@", sizeof aux);
					strlcat(aux, m->sender.domain, sizeof aux);
				}
				strlcat(aux, "|", sizeof aux);
				strlcat(aux, m->session_rcpt.user, sizeof aux);
				strlcat(aux, "@@", sizeof aux);
				strlcat(aux, m->session_rcpt.domain, sizeof aux);
				strlcat(aux, "|", sizeof aux);
				strlcat(aux, m->sender.pw_name, sizeof aux);
				strlcat(aux, "|", sizeof aux);
				strlcat(aux, m->recipient.pw_name, sizeof aux);
				strlcat(aux, "|", sizeof aux);
				strlcat(aux, m->recipient.rule.r_value.buffer, sizeof aux);
				break;

			case A_FILENAME:
				/* F|from|to|user1|user2|path */
				strlcpy(aux, "F|", sizeof aux);
				if (m->sender.user[0] && m->sender.domain[0]) {
					strlcat(aux, m->sender.user, sizeof aux);
					strlcat(aux, "@@", sizeof aux);
					strlcat(aux, m->sender.domain, sizeof aux);
				}
				strlcat(aux, "|", sizeof aux);
				strlcat(aux, m->session_rcpt.user, sizeof aux);
				strlcat(aux, "@@", sizeof aux);
				strlcat(aux, m->session_rcpt.domain, sizeof aux);
				strlcat(aux, "|", sizeof aux);
				strlcat(aux, m->sender.pw_name, sizeof aux);
				strlcat(aux, "|", sizeof aux);
				strlcat(aux, SMTPD_USER, sizeof aux);
				strlcat(aux, "|", sizeof aux);
				strlcat(aux, m->recipient.u.filename, sizeof aux);
				break;

			case A_RELAY:
			case A_RELAYVIA:
				/* R|from|to|user|rcpt|via|port|ssl|cert|auth */
				strlcpy(aux, "R|", sizeof aux);
				if (m->sender.user[0] && m->sender.domain[0]) {
					strlcat(aux, m->sender.user, sizeof aux);
					strlcat(aux, "@@", sizeof aux);
					strlcat(aux, m->sender.domain, sizeof aux);
				}
				strlcat(aux, "|", sizeof aux);
				strlcat(aux, m->session_rcpt.user, sizeof aux);
				strlcat(aux, "@@", sizeof aux);
				strlcat(aux, m->session_rcpt.domain, sizeof aux);
				strlcat(aux, "|", sizeof aux);
				strlcat(aux, m->sender.pw_name, sizeof aux);
				strlcat(aux, "|", sizeof aux);
				strlcat(aux, m->recipient.user, sizeof aux);
				strlcat(aux, "@@", sizeof aux);
				strlcat(aux, m->recipient.domain, sizeof aux);
				strlcat(aux, "|", sizeof aux);
				if (m->recipient.rule.r_action == A_RELAYVIA)
					strlcat(aux, m->recipient.rule.r_value.relayhost.hostname, sizeof aux);
				strlcat(aux, "|", sizeof aux);
				if (m->recipient.rule.r_value.relayhost.port) {
					char port[10];
					snprintf(port, sizeof port, "%d", ntohs(m->recipient.rule.r_value.relayhost.port));
					strlcat(aux, port, sizeof aux);
				}
				strlcat(aux, "|", sizeof aux);
				switch (m->recipient.rule.r_value.relayhost.flags & F_SSL) {
				case F_SSL:
					strlcat(aux, "ssl", sizeof aux);
					break;
				case F_SMTPS:
					strlcat(aux, "smtps", sizeof aux);
					break;
				case F_STARTTLS:
					strlcat(aux, "starttls", sizeof aux);
					break;
				}
				strlcat(aux, "|", sizeof aux);
				strlcat(aux, m->recipient.rule.r_value.relayhost.cert, sizeof aux);
				strlcat(aux, "|", sizeof aux);
				if (m->recipient.rule.r_value.relayhost.flags & F_AUTH)
					strlcat(aux, "secrets", sizeof aux);
				break;
d142 5
a146 2
			default:
				fatalx("queue: bad r_action");
d148 1
d150 6
a155 7
			if (queue_append(s, aux) < 0)
				error = S_MESSAGE_TEMPFAILURE;
			else
				error = 0;

			imsg_compose_event(iev, IMSG_QUEUE_APPEND,
			    imsg->hdr.peerid, 0, -1, &error, sizeof error);
d160 9
a168 1
	if (iev->proc == PROC_MDA) {
d170 5
a174 4
		case IMSG_BATCH_UPDATE:
			update = imsg->data;
			queue_update(Q_LOCAL, imsg->hdr.peerid, update->id,
			    update->data);
d177 1
d179 1
a179 1
			queue_done(Q_LOCAL, imsg->hdr.peerid);
a180 1

d184 1
a184 1
	if (iev->proc == PROC_MTA) {
d186 3
a188 8
		case IMSG_BATCH_UPDATE:
			update = imsg->data;
			queue_update(Q_RELAY, imsg->hdr.peerid, update->id,
			    update->data);
			return;

		case IMSG_BATCH_DONE:
			queue_done(Q_RELAY, imsg->hdr.peerid);
d196 1
a196 9
			runqs[Q_LOCAL].max = 0;
			queue_sleep(Q_LOCAL);
			return;

		case IMSG_QUEUE_PAUSE_RELAY:
			runqs[Q_RELAY].max = 0;
			queue_sleep(Q_RELAY);
			return;

d198 1
a198 9
			runqs[Q_LOCAL].max = env->sc_maxconn;
			queue_sleep(Q_LOCAL);
			return;

		case IMSG_QUEUE_RESUME_RELAY:
			runqs[Q_RELAY].max = env->sc_maxconn;
			queue_sleep(Q_RELAY);
			return;

a199 13
			memcpy(&content_id, imsg->data, sizeof content_id);
			error = queue_control(content_id, 1);
			if (error)
				log_warnx("schedule request failed");
			else {
				queue_sleep(Q_LOCAL);
				queue_sleep(Q_RELAY);
				queue_sleep(Q_BOUNCE);
			}
			imsg_compose_event(iev, IMSG_QUEUE_SCHEDULE,
			    imsg->hdr.peerid, 0, -1, &error, sizeof error);
			return;

d201 1
a201 11
			memcpy(&content_id, imsg->data, sizeof content_id);
			error = queue_control(content_id, 0);
			if (error)
				log_warnx("remove request failed");
			else {
				queue_sleep(Q_LOCAL);
				queue_sleep(Q_RELAY);
				queue_sleep(Q_BOUNCE);
			}
			imsg_compose_event(iev, IMSG_QUEUE_REMOVE,
			    imsg->hdr.peerid, 0, -1, &error, sizeof error);
d208 4
d214 1
a221 62
int
queue_append(struct incoming *s, char *auxraw)
{
	struct batch	*batch;
	struct action	*action;
	char		*copy;
	struct aux	 aux;
	u_int64_t	 action_id;

	log_debug("aux %s", auxraw);

	copy = strdup(auxraw);
	if (copy == NULL)
		fatal(NULL);
	auxsplit(&aux, copy);

	/* remember local recipients for delivered-to: loop detection */
	if (aux.mode[0] != 'R') {
		if (s->nlocal == s->local_sz) {
			s->local_sz *= 2;
			s->local = realloc(s->local, ++s->local_sz *
			    sizeof s->local[0]);
			if (s->local == NULL)
				fatal(NULL);
		}
		/*
		 * XXX: using rcpt_to is wrong because it's unexpanded address
		 * as seen in RCPT TO; must use expanded address in the form
		 * <user>@@<domain>, but since lka expands local addresses to
		 * just <user> this is currently undoable.
		 */
		s->local[s->nlocal] = strdup(aux.rcpt_to);
		if (s->local[s->nlocal] == NULL)
			fatal(NULL);
		s->nlocal++;
	}

	/* assign batch */
	if (aux.mode[0] != 'R')
		batch = incoming_batch(s, "");
	else if (aux.relay_via[0])
		batch = incoming_batch(s, aux.relay_via);
	else
		batch = incoming_batch(s, strchr(aux.rcpt, '@@'));

	if (batch == NULL)
		fatal(NULL);

	free(copy);

	if (queue_be_action_new(s->content->id, &action_id, auxraw) < 0)
		return -1;

	action = action_alloc(action_id);
	if (action == NULL)
		fatal(NULL);

	action_insert(action, batch);

	return 0;
}

d223 1
a223 33
queue_destroy(struct incoming *s)
{
	struct batch	*batch;
	struct action	*action;
	u_int		 rq;
	int		 i;

	for (rq = 0; rq < nitems(s->batches); rq++) {
		while ((batch = SLIST_FIRST(&s->batches[rq]))) {
			SLIST_REMOVE_HEAD(&s->batches[rq], entry);
			while ((action = SLIST_FIRST(&batch->actions))) {
				SLIST_REMOVE_HEAD(&batch->actions, entry);
				queue_be_action_delete(s->content->id,
				    action->id);
				action_free(action);
			}
			free(batch);
		}
	}
	queue_be_content_delete(s->content->id);

	free(s->content);
	for (i = 0; i < s->nlocal; i++)
		free(s->local[i]);
	free(s->local);
	free(s);
}

/*
 * Walk all runqueues to schedule or remove requested content.
 */
int
queue_control(u_int64_t content_id, int schedule)
d225 3
a227 38
	struct batch	*b, *next;
	struct action	*action;
	struct action_be a;
	struct aux	 aux;
	u_int		 rq, n;

	n = 0;
	for (rq = 0; rq < nitems(runqs); rq++) {
		for (b = SLIST_FIRST(&runqs[rq].head); b; b = next) {
			next = SLIST_NEXT(b, entry);
			if (content_id && b->content->id != content_id)
				continue;
			n++;
			SLIST_REMOVE(&runqs[rq].head, b, batch, entry);
			if (schedule) {
				time(&b->retry);
				queue_schedule(rq, b);
				continue;
			}
			while ((action = SLIST_FIRST(&b->actions))) {
				SLIST_REMOVE_HEAD(&b->actions, entry);
				if (queue_be_action_read(&a, b->content->id,
				    action->id) < 0)
					fatal("queue: action read error");
				auxsplit(&aux, a.aux);
				log_info("%s: to=%s, delay=%d, stat=Removed",
				    queue_be_decode(b->content->id),
				    rcpt_pretty(&aux), time(NULL) - a.birth);
				queue_be_action_delete(b->content->id,
				    action->id);
				queue_mem_content_unref(b->content);
				action_free(action);
			}
			free(b);
		}
	}

	return (n > 0 ? 0 : -1);
d246 1
a246 1
	log_info("queue exiting");
d250 10
d265 1
a265 1
	u_int		 rq;
d275 2
a276 1
		{ PROC_LKA,	imsg_dispatch }
a304 9
	/*
	 * Queue opens fds for four purposes: smtp, mta, mda, and bounces.
	 * Therefore, use all available fd space and set the maxconn (=max
	 * session count for each of these tasks) to a quarter of this value.
	 */
	fdlimit(1.0);
	if ((env->sc_maxconn = availdesc() / 4) < 1)
		fatalx("queue: fd starvation");

a307 20
	config_pipes(env, peers, nitems(peers));
	config_peers(env, peers, nitems(peers));

	for (rq = 0; rq < nitems(runqs); rq++) {
		SLIST_INIT(&runqs[rq].head);
		runqs[rq].env = env;
		runqs[rq].max = env->sc_maxconn;
	}
	runqs[Q_LOCAL].name = "Q_LOCAL";
	runqs[Q_RELAY].name = "Q_RELAY";
	runqs[Q_BOUNCE].name = "Q_BOUNCE";

	/* bouncing costs 2 fds: file and socket */
	runqs[Q_BOUNCE].max /= 2;

	queue_mem_init(env);
	queue_sleep(Q_LOCAL);
	queue_sleep(Q_RELAY);
	queue_sleep(Q_BOUNCE);

a314 26
	if (event_dispatch() <  0)
		fatal("event_dispatch");
	queue_shutdown();

	return (0);
}

void
queue_mem_init(struct smtpd *env)
{
	SLIST_HEAD(,batch)	  bhash[4096];
	void			**btab;
	struct content		 *content;
	struct action		 *action;
	struct batch		 *batch;
	char			 *sortkey;
	struct action_be	  a;
	struct aux		  aux;
	int			  btab_sz, nbtab, rq, i;

	for (i = 0; i < 4096; i++)
		SLIST_INIT(&bhash[i]);
	btab = NULL;
	btab_sz = 0;
	nbtab = 0;

d316 3
a318 1
	 * Sort actions into batches.
d320 3
a322 31
	for (;;) {
		if (queue_be_getnext(&a) < 0)
			fatal("queue: backend error");
		if (a.action_id == 0)
			break;
		auxsplit(&aux, a.aux);

		/*
		 * Assignment to batch is based on the sortkey:
		 * B=<content_id>	for bounced mail
		 * R=<domain>		for relayed mail
		 * L=<action_id>	for local mail
		 */
		if (a.status[0] == '5' || a.status[0] == '6')
			asprintf(&sortkey, "B=%s", queue_be_decode(a.content_id));
		else if (aux.mode[0] == 'R') {
			if (aux.relay_via[0])
				asprintf(&sortkey, "R=%s", aux.relay_via);
			else
				asprintf(&sortkey, "R=%s", strchr(aux.rcpt, '@@'));
		} else
			asprintf(&sortkey, "L=%s", queue_be_decode(a.action_id));

		content = NULL;
		SLIST_FOREACH(batch, &bhash[a.content_id & 4095], entry) {
			if (batch->content->id == a.content_id) {
				content = batch->content;
				if (strcmp(batch->sortkey, sortkey) == 0)
					break;
			}
		}
d324 2
a325 167
		if (batch == NULL) {
			if (content == NULL) {
				content = content_alloc(a.content_id);
				if (content == NULL)
					fatal("queue_mem_init");
				env->stats->queue.length++;
			}

			batch = batch_alloc(content, sortkey);
			if (batch == NULL)
				fatal("queue_mem_init");

			if (*sortkey == 'B')
				rq = Q_BOUNCE;
			else if (*sortkey == 'R')
				rq = Q_RELAY;
			else
				rq = Q_LOCAL;

			batch->retry = queue_retry(rq, a.birth, a.birth);
			while (batch->retry < time(NULL))
				batch->retry = queue_retry(rq, a.birth,
				    batch->retry);

			if (batch->retry > a.birth + env->sc_qexpire)
				batch->retry = NO_RETRY_EXPIRED;

			SLIST_INSERT_HEAD(&bhash[a.content_id & 4095], batch,
			    entry);
			if (nbtab == btab_sz) {
				btab_sz *= 2;
				btab = realloc(btab, ++btab_sz * sizeof *btab);
				if (btab == NULL)
					fatal("queue_mem_init");
			}
			btab[nbtab] = batch;
			nbtab++;
		}

		action = action_alloc(a.action_id);
		if (action == NULL)
			fatal("queue_mem_init");

		action_insert(action, batch);

		free(sortkey);
	}

	/*
	 * Add batches to schedule.
	 */
	qsort(btab, nbtab, sizeof *btab, batchsort);
	for (i = 0; i < nbtab; i++) {
		batch = btab[i];
		if (batch->sortkey[0] == 'B')
			rq = Q_BOUNCE;
		else if (batch->sortkey[0] == 'R')
			rq = Q_RELAY;
		else
			rq = Q_LOCAL;
		queue_schedule(rq, batch);
	}

	free(btab);
}

int
batchsort(const void *x, const void *y)
{
	const struct batch *b1 = x, *b2 = y;
	return (b1->retry < b2->retry ? -1 : b1->retry > b2->retry);
}

void
queue_mem_content_unref(struct content *content)
{
	content->ref--;
	if (content->ref < 0)
		fatalx("queue: bad refcount");
	else if (content->ref == 0) {
		queue_be_content_delete(content->id);
		runqs[Q_LOCAL].env->stats->queue.length--;
	}
}

void
queue_send(int fd, short event, void *p)
{
	struct smtpd		*env;
	struct batch		*batch;
	struct action		*action;
	struct action_be	 a;
	int			 rq, i, to;
	time_t			 now;

	rq = (struct queue *)p - runqs;
	env = runqs[rq].env;
	time(&now);
	i = -1;

	while ((batch = SLIST_FIRST(&runqs[rq].head))) {
		if (batch->retry > now || runqs[rq].sessions >= runqs[rq].max)
			break;

		SLIST_REMOVE_HEAD(&runqs[rq].head, entry);
		i = table_alloc(&runqs[rq].session, &runqs[rq].session_sz);
		runqs[rq].session[i] = batch;
		runqs[rq].sessions++;

		log_debug("%s: %d: start %s", runqs[rq].name, i,
		    queue_be_decode(batch->content->id));

		if (batch->retry == NO_RETRY_EXPIRED) {
			log_debug("%s: %d: expire", runqs[rq].name, i);
			queue_expire(batch);
			queue_done(rq, i);
			continue;
		}

		if (rq == Q_BOUNCE) {
			log_debug("%s: %d: socket request", runqs[rq].name, i);
			imsg_compose_event(env->sc_ievs[PROC_SMTP],
			    IMSG_SMTP_ENQUEUE, i, 0, -1, NULL, 0);
			continue;
		}

		log_debug("%s: %d: send", runqs[rq].name, i);

		fd = queue_be_content_open(batch->content->id, 0);
		if (fd < 0)
			fatal("queue: content open error");

		if (rq == Q_LOCAL)
			to = PROC_MDA;
		else
			to = PROC_MTA;

		imsg_compose_event(env->sc_ievs[to], IMSG_BATCH_CREATE, i, 0,
		    fd, &batch->content->id, sizeof batch->content->id);

		while ((action = SLIST_FIRST(&batch->actions))) {
			SLIST_REMOVE_HEAD(&batch->actions, entry);

			if (queue_be_action_read(&a, batch->content->id,
			    action->id) < 0)
				fatal("queue: action read error");

			action = action_grow(action, a.aux);
			if (action == NULL)
				fatal(NULL);

			imsg_compose_event(env->sc_ievs[to], IMSG_BATCH_APPEND,
			    i, 0, -1, action, sizeof *action + strlen(a.aux));

			action_free(action);
		}

		imsg_compose_event(env->sc_ievs[to], IMSG_BATCH_CLOSE, i, 0, -1,
		    &a.birth, sizeof a.birth);
	}

	/* Sanity check: were we called for no good reason? */
	if (i == -1)
		fatalx("queue_send: empty run");

	queue_sleep(rq);
}
d327 2
a328 241
void
queue_expire(struct batch *batch)
{
	struct action	*action, *fail;
	struct action_be a;
	struct aux	 aux;
	time_t		 birth;
	int		 error;

	action = SLIST_FIRST(&batch->actions);
	if (queue_be_action_read(&a, batch->content->id, action->id) < 0)
		fatal("queue: action read error");

	auxsplit(&aux, a.aux);
	birth = a.birth;

	if (a.status[0] == '5' || a.status[0] == '6') {
		log_warnx("%s: to=%s, delay=%d, stat=Expired (no bounce due "
		    "to: larval bounce)",
		    queue_be_decode(batch->content->id), aux.mail_from,
		    time(NULL) - birth);

		while ((action = SLIST_FIRST(&batch->actions))) {
			SLIST_REMOVE_HEAD(&batch->actions, entry);
			queue_be_action_delete(batch->content->id, action->id);
			queue_mem_content_unref(batch->content);
			action_free(action);
		}

		return;
	}

	if (aux.mail_from[0] == '\0') {
		while ((action = SLIST_FIRST(&batch->actions))) {
			SLIST_REMOVE_HEAD(&batch->actions, entry);

			if (queue_be_action_read(&a, batch->content->id,
			    action->id) < 0)
				fatal("queue: action read error");
			auxsplit(&aux, a.aux);

			log_warnx("%s: to=%s, delay=%d, stat=Expired (no bounce "
			    "due to: double bounce)",
			    queue_be_decode(batch->content->id),
			    rcpt_pretty(&aux), time(NULL) - birth);

			queue_be_action_delete(batch->content->id, action->id);
			queue_mem_content_unref(batch->content);
			action_free(action);
		}
		return;
	}

	SLIST_FOREACH(action, &batch->actions, entry)
		if (queue_be_action_status(batch->content->id, action->id,
		    "600 Message expired after too many delivery attempts") < 0)
			break;

	if (action) {
		fail = action;
		error = errno;
	} else {
		fail = NULL;
		error = 0;
	}

	while ((action = SLIST_FIRST(&batch->actions))) {
		if (action == fail)
			break;
		SLIST_REMOVE_HEAD(&batch->actions, entry);

		if (queue_be_action_read(&a, batch->content->id,
		    action->id) < 0)
			fatal("queue: action read error");
		auxsplit(&aux, a.aux);

		log_info("%s: to=%s, delay=%d, stat=Expired",
		    queue_be_decode(batch->content->id), rcpt_pretty(&aux),
		    time(NULL) - birth);

		SLIST_INSERT_HEAD(&batch->content->actions, action, entry);
		queue_bounce_wait(batch->content);
	}

	while ((action = SLIST_FIRST(&batch->actions))) {
		SLIST_REMOVE_HEAD(&batch->actions, entry);

		if (queue_be_action_read(&a, batch->content->id,
		    action->id) < 0)
			fatal("queue: action read error");
		auxsplit(&aux, a.aux);

		log_warnx("%s: to=%s, delay=%d, stat=Expired (no bounce due "
		    "to: %s)",
		    queue_be_decode(batch->content->id), rcpt_pretty(&aux),
		    time(NULL) - birth, strerror(error));

		queue_be_action_delete(batch->content->id, action->id);
		queue_mem_content_unref(batch->content);
		action_free(action);
	}
}

void
queue_update(int rq, int i, u_int64_t action_id, char *new_status)
{
	struct batch	*batch;
	struct action	*action;
	struct action_be a;
	struct aux	 aux;

	batch = table_lookup(runqs[rq].session, runqs[rq].session_sz, i);
	if (batch == NULL)
		fatalx("queue: bogus update");

	if (*new_status == '2') {
		queue_be_action_delete(batch->content->id, action_id);
		queue_mem_content_unref(batch->content);
		return;
	}

	action = malloc(sizeof *action);
	if (action == NULL)
		fatal(NULL);
	action->id = action_id;

	if (*new_status == '5' || *new_status == '6') {
		if (queue_be_action_read(&a, batch->content->id, action_id) < 0)
			fatal("queue: queue read error");

		auxsplit(&aux, a.aux);

		if (aux.mail_from[0] == '\0') {
			log_warnx("%s: bounce recipient %s not contactable, "
			    "bounce dropped",
			    queue_be_decode(batch->content->id), aux.rcpt_to);
			queue_be_action_delete(batch->content->id, action_id);
			queue_mem_content_unref(batch->content);
			action_free(action);
			return;
		}

		if (queue_be_action_status(batch->content->id, action_id,
		    new_status) < 0) {
			log_warn("%s: recipient %s not contactable, bounce not "
			    "created due to queue error",
			    queue_be_decode(batch->content->id), aux.rcpt_to);
			queue_be_action_delete(batch->content->id, action_id);
			queue_mem_content_unref(batch->content);
			action_free(action);
			return;
		}

		SLIST_INSERT_HEAD(&batch->content->actions, action, entry);

		queue_bounce_wait(batch->content);
	} else {
		queue_be_action_status(batch->content->id, action_id, new_status);
		SLIST_INSERT_HEAD(&batch->actions, action, entry);
	}
}

void
queue_done(int rq, int i)
{
	struct action_be a;
	struct batch	*batch;
	struct action	*action;

	/* Take batch off the session table. */
	batch = table_lookup(runqs[rq].session, runqs[rq].session_sz, i);
	if (batch == NULL)
		fatalx("queue: bogus batch");
	runqs[rq].session[i] = NULL;
	runqs[rq].sessions--;

	log_debug("%s: %d: done", runqs[rq].name, i);

	/* All actions sent? */
	if (SLIST_EMPTY(&batch->actions)) {
		if (batch->content->ref == 0) {
			free(batch->content->ev);
			free(batch->content);
		}
		free(batch);
	} else {
		/* Batch has actions with temporary errors. */
		action = SLIST_FIRST(&batch->actions);
		if (queue_be_action_read(&a, batch->content->id,
		    action->id) < 0)
			fatal("queue: action read error");
		batch->retry = queue_retry(rq, a.birth, batch->retry);
		if (batch->retry > a.birth + runqs[rq].env->sc_qexpire)
			batch->retry = NO_RETRY_EXPIRED;
		queue_schedule(rq, batch);
	}

	queue_sleep(rq);
}

/*
 * Insert batch into runqueue in retry time order.
 */
void
queue_schedule(int rq, struct batch *batch)
{
	struct batch *b, *prev;

	prev = NULL;

	SLIST_FOREACH(b, &runqs[rq].head, entry) {
		if (b->retry >= batch->retry) {
			if (prev)
				SLIST_INSERT_AFTER(prev, batch, entry);
			else
				SLIST_INSERT_HEAD(&runqs[rq].head, batch,
				    entry);
			break;
		}
		prev = b;
	}

	if (b == NULL) {
		if (prev)
			SLIST_INSERT_AFTER(prev, batch, entry);
		else
			SLIST_INSERT_HEAD(&runqs[rq].head, batch, entry);
	}
}

void
queue_sleep(int rq)
{
	struct timeval	 tv;
	struct batch	*next;
	time_t		 now;

	evtimer_del(&runqs[rq].ev);

	if (runqs[rq].sessions >= runqs[rq].max)
		return;
d330 1
a330 3
	next = SLIST_FIRST(&runqs[rq].head);
	if (next == NULL)
		return;
d332 3
a334 6
	time(&now);
	if (next->retry < now)
		tv.tv_sec = 0;
	else
		tv.tv_sec = next->retry - now;
	tv.tv_usec = 0;
d336 1
a336 4
	log_debug("%s: sleep %lus", runqs[rq].name, tv.tv_sec);

	evtimer_set(&runqs[rq].ev, queue_send, &runqs[rq]);
	evtimer_add(&runqs[rq].ev, &tv);
d339 2
a340 7
/*
 * Qmail-like retry schedule.
 *
 * Local deliveries are tried more often than remote.
 */
time_t
queue_retry(int rq, time_t birth, time_t last)
d342 1
a342 1
	int n;
d344 2
a345 8
	if (last - birth < 0)
		n = 0;
	else if (rq == Q_RELAY)
		n = sqrt(last - birth) + 20;
	else
		n = sqrt(last - birth) + 10;

	return birth + n * n;
a347 21
/*
 * Wait for permanent failures against this content for few more seconds.
 * If none arrive, combine them into single batch and put on Q_BOUNCE
 * runqueue.  If one does arrive, append it, and restart the timer.
 */
void
queue_bounce_wait(struct content *content)
{
	struct timeval tv;

	if (content->ev == NULL) {
		content->ev = calloc(1, sizeof *content->ev);
		if (content->ev == NULL)
			fatal(NULL);
	}
	tv.tv_sec = 3;
	tv.tv_usec = 0;
	evtimer_del(content->ev);
	evtimer_set(content->ev, queue_bounce_schedule, content);
	evtimer_add(content->ev, &tv);
}
d350 1
a350 1
queue_bounce_schedule(int fd, short event, void *p)
d352 2
a353 20
	struct content	*content = p;
	struct batch	*batch;
	struct action	*action;

	free(content->ev);
	content->ev = NULL;

	batch = malloc(sizeof *batch);
	if (batch == NULL)
		fatal(NULL);
	SLIST_INIT(&batch->actions);
	batch->content = content;
	while ((action = SLIST_FIRST(&content->actions))) {
		SLIST_REMOVE_HEAD(&content->actions, entry);
		SLIST_INSERT_HEAD(&batch->actions, action, entry);
	}
	time(&batch->retry);
	queue_schedule(Q_BOUNCE, batch);
	queue_sleep(Q_BOUNCE);
}
d355 1
a355 22
void
queue_bounce_init(int i, int sock)
{
	struct smtpd	*env = runqs[Q_BOUNCE].env;
	struct batch	*batch;
	struct bounce	*s;
	struct action	*action;
	struct action_be a;
	struct aux	 aux;
	int		 fd, header;

	log_debug("%s: %d: init", runqs[Q_BOUNCE].name, i);

	batch = table_lookup(runqs[Q_BOUNCE].session,
	    runqs[Q_BOUNCE].session_sz, i);
	if (batch == NULL)
		fatalx("queue: bogus bounce batch");

	if (sock < 0) {
		queue_done(Q_BOUNCE, i);
		return;
	}
d357 2
a358 40
	fd = queue_be_content_open(batch->content->id, 0);
	if (fd < 0)
		fatal("queue: content open error");

	s = calloc(1, sizeof *s);
	if (s == NULL)
		fatal(NULL);
	s->batch = batch;
	s->pcb = client_init(sock, fd, env->sc_hostname, 1);
	s->id = i;
	client_sender(s->pcb, "");
	client_ssl_optional(s->pcb);

	header = 0;
	SLIST_FOREACH(action, &batch->actions, entry) {
		if (queue_be_action_read(&a, batch->content->id,
		    action->id) < 0)
			fatal("queue: backend read error");
		auxsplit(&aux, a.aux);
		if (header == 0) {
			client_rcpt(s->pcb, "%s", aux.mail_from);
			client_printf(s->pcb,
			    "From: Mailer Daemon <MAILER-DAEMON@@%s>\n"
			    "To: %s\n"
			    "Subject: Delivery status notification\n"
			    "Date: %s\n"
			    "\n"
			    "This is automated mail delivery notification, please DO NOT REPLY.\n"
			    "An error has occurred while attempting to deliver your mail to the\n"
			    "following recipients:\n"
			    "\n",
			    env->sc_hostname, aux.mail_from,
			    time_to_text(time(NULL)));
			header = 1;
		}
		if (strlen(a.status) > 4 && (a.status[0] == '1' || a.status[0] == '6'))
			a.status += 4;
		client_printf(s->pcb, "%s: %s\n\n", aux.rcpt_to, a.status);
	}
	client_printf(s->pcb, "Below is a copy of your mail:\n\n");
d360 1
a360 3
	session_socket_blockmode(sock, BM_NONBLOCK);
	event_set(&s->ev, sock, EV_READ|EV_WRITE, queue_bounce_event, s);
	event_add(&s->ev, &s->pcb->timeout);
d364 1
a364 55
queue_bounce_event(int fd, short event, void *p)
{
	struct action	*action;
	struct bounce	*s = p;
	char		*status = NULL;

	if (event & EV_TIMEOUT) {
		status = "100 timeout";
		goto out;
	}

	switch (client_talk(s->pcb, event & EV_WRITE)) {
	case CLIENT_STOP_WRITE:
		goto ro;
	case CLIENT_WANT_WRITE:
		goto rw;
	case CLIENT_RCPT_FAIL:
		status = s->pcb->reply;
		break;
	case CLIENT_DONE:
		status = s->pcb->status;
		break;
	default:
		fatalx("queue: bad client_talk");
	}

out:
	log_debug("%s: %d: last event", runqs[Q_BOUNCE].name, s->id);

	if (*status == '2' || *status == '5' || *status == '6') {
		while ((action = SLIST_FIRST(&s->batch->actions))) {
			SLIST_REMOVE_HEAD(&s->batch->actions, entry);
			queue_be_action_delete(s->batch->content->id,
			    action->id);
			queue_mem_content_unref(s->batch->content);
			action_free(action);
		}
	}
	queue_done(Q_BOUNCE, s->id);
	client_close(s->pcb);
	free(s);
	return;

ro:
	event_set(&s->ev, fd, EV_READ, queue_bounce_event, s);
	event_add(&s->ev, &s->pcb->timeout);
	return;

rw:
	event_set(&s->ev, fd, EV_READ|EV_WRITE, queue_bounce_event, s);
	event_add(&s->ev, &s->pcb->timeout);
}

int
queue_detect_loop(struct incoming *s)
d366 3
a368 103
	FILE	*fp;
	char	*buf, *lbuf;
	size_t	 len, received;
	int	 fd, i;

	fd = queue_be_content_open(s->content->id, 0);
	if (fd < 0)
		fatal("queue_detect_loop: content open error");
	fp = fdopen(fd, "r");
	if (fp == NULL)
		fatal("queue_detect_loop: fdopen");

	received = 0;
	lbuf = NULL;

	while ((buf = fgetln(fp, &len))) {
		free(lbuf);
		lbuf = NULL;

		if (buf[len - 1] == '\n') {
			buf[len - 1] = '\0';
			len--;
		} else {
			/* EOF without EOL, copy and add the NUL */
			if ((lbuf = malloc(len + 1)) == NULL)
				fatal(NULL);
			memcpy(lbuf, buf, len);
			lbuf[len] = '\0';
			buf = lbuf;
		}

		if (*buf == '\0') {
			buf = NULL;
			break;
		}

		if (strncasecmp(buf, "Received:", 9) == 0) {
			received++;
			if (received >= MAX_HOPS_COUNT) 
				break;
		} else if (strncasecmp(buf, "Delivered-To:", 13) == 0) {
			buf += 13;
			while (isspace(*buf))
				buf++;
			buf[strcspn(buf, " \t")] = '\0';
			for (i = 0; i < s->nlocal; i++)
				if (strcmp(s->local[i], buf) == 0)
					break;
			if (i < s->nlocal)
				break;
		}
	}
	free(lbuf);
	fclose(fp);

	return (buf == NULL ? 0 : -1);
}

struct incoming *
incoming_alloc(u_int64_t content_id)
{
	struct incoming *s;
	u_int rq;

	s = calloc(1, sizeof *s);
	if (s == NULL)
		return NULL;
	for (rq = 0; rq < nitems(s->batches); rq++)
		SLIST_INIT(&s->batches[rq]);

	s->content = content_alloc(content_id);
	if (s->content == NULL) {
		free(s);
		return NULL;
	}

	return s;
}

struct batch *
incoming_batch(struct incoming *s, char *sortkey)
{
	struct batch	*batch;
	u_int		 rq;

	if (*sortkey) {
		rq = Q_RELAY;
		SLIST_FOREACH(batch, &s->batches[rq], entry)
			if (strcmp(batch->sortkey, sortkey) == 0)
				break;
	} else {
		rq = Q_LOCAL;
		batch = NULL;
	}

	if (batch == NULL) {
		batch = batch_alloc(s->content, sortkey);
		if (batch == NULL)
			return NULL;
		SLIST_INSERT_HEAD(&s->batches[rq], batch, entry);
	}

	return batch;
d372 1
a372 33
incoming_schedule(struct incoming *s)
{
	struct batch *batch;
	u_int rq;

	for (rq = 0; rq < nitems(s->batches); rq++) {
		while ((batch = SLIST_FIRST(&s->batches[rq]))) {
			SLIST_REMOVE_HEAD(&s->batches[rq], entry);
			batch->retry = RETRY_NOW;
			queue_schedule(rq, batch);
		}
	}

	queue_sleep(Q_LOCAL);
	queue_sleep(Q_RELAY);
}

struct content *
content_alloc(u_int64_t content_id)
{
	struct content *content;

	content = calloc(1, sizeof *content);
	if (content == NULL)
		return NULL;

	content->id = content_id;

	return content;
}

struct batch *
batch_alloc(struct content *content, char *sortkey)
d374 3
a376 52
	struct batch *batch;

	batch = calloc(1, sizeof *batch + strlen(sortkey));
	if (batch == NULL)
		return NULL;

	SLIST_INIT(&batch->actions);
	batch->content = content;
	strlcpy(batch->sortkey, sortkey, strlen(sortkey) + 1);

	return batch;
}

struct action *
action_alloc(u_int64_t action_id)
{
	struct action *action;

	action = malloc(sizeof *action);
	if (action == NULL)
		return NULL;

	action->id = action_id;

	return action;
}

void
action_free(struct action *action)
{
	free(action);
}

void
action_insert(struct action *action, struct batch *batch)
{
	SLIST_INSERT_HEAD(&batch->actions, action, entry);
	batch->content->ref++;
}

struct action *
action_grow(struct action *action, char *aux)
{
	struct action *new;

	new = realloc(action, sizeof *new + strlen(aux));
	if (new == NULL)
		return NULL;

	strlcpy(new->data, aux, strlen(aux) + 1);

	return new;
@


1.89
log
@smtpd should NOT fatal when it permanently fails a bounce delivery as this
can be a normal situation and will allow a local/authenticated user to
trigger the fatal on purpose ...

ignore permanently failed bounce deliveries since there's not much smtpd
can do anyway, that's what the previous queue code did.

experienced and reported by pirofti@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.88 2010/06/10 19:34:51 chl Exp $	*/
d242 1
a242 1
				strlcat(aux, m->recipient.rule.r_value.path, sizeof aux);
@


1.88
log
@allow configure queue expiry

with help from jacekm@@

ok gilles@@ jacekm@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.87 2010/06/02 19:16:53 chl Exp $	*/
d1312 1
a1312 3
	if (*status == '5' || *status == '6')
		fatalx("queue: smtp refused bounce");
	if (*status == '2') {
@


1.87
log
@check event_dispatch() return value

ok jacekm@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.86 2010/06/01 23:06:23 jacekm Exp $	*/
d744 1
a744 1
			if (batch->retry > a.birth + SMTPD_EXPIRE)
d1080 1
a1080 1
		if (batch->retry > a.birth + SMTPD_EXPIRE)
@


1.86
log
@new queue, again; gcc2 compile tested by deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.84 2010/06/01 14:21:52 jacekm Exp $	*/
d659 2
a660 1
	event_dispatch();
@


1.85
log
@New queue doesn't compile on gcc2, back out.  Spotted by deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.81 2010/04/22 12:13:33 jacekm Exp $	*/
d4 1
d27 1
d29 1
d34 1
d43 2
d46 45
a90 14
void		queue_imsg(struct smtpd *, struct imsgev *, struct imsg *);
void		queue_pass_to_runner(struct smtpd *, struct imsgev *, struct imsg *);
__dead void	queue_shutdown(void);
void		queue_sig_handler(int, short, void *);
void		queue_setup_events(struct smtpd *);
void		queue_disable_events(struct smtpd *);
void		queue_purge(char *);

int		queue_create_layout_message(char *, char *);
void		queue_delete_layout_message(char *, char *);
int		queue_record_layout_envelope(char *, struct message *);
int		queue_remove_layout_envelope(char *, struct message *);
int		queue_commit_layout_message(char *, struct message *);
int		queue_open_layout_messagefile(char *, struct message *);
d95 2
a96 1
	struct submit_status	 ss;
d98 4
a101 2
	struct batch		*b;
	int			 fd, ret;
d104 25
a128 1
		m = imsg->data;
d130 12
a141 13
		switch (imsg->hdr.type) {
		case IMSG_QUEUE_CREATE_MESSAGE:
			ss.id = m->session_id;
			ss.code = 250;
			bzero(ss.u.msgid, sizeof ss.u.msgid);
			if (m->flags & F_MESSAGE_ENQUEUED)
				ret = enqueue_create_layout(ss.u.msgid);
			else
				ret = queue_create_incoming_layout(ss.u.msgid);
			if (ret == 0)
				ss.code = 421;
			imsg_compose_event(iev, IMSG_QUEUE_CREATE_MESSAGE, 0, 0, -1,
			    &ss, sizeof ss);
d144 16
a159 5
		case IMSG_QUEUE_REMOVE_MESSAGE:
			if (m->flags & F_MESSAGE_ENQUEUED)
				enqueue_delete_message(m->message_id);
			else
				queue_delete_incoming_message(m->message_id);
d162 23
a184 12
		case IMSG_QUEUE_COMMIT_MESSAGE:
			ss.id = m->session_id;
			if (m->flags & F_MESSAGE_ENQUEUED) {
				if (enqueue_commit_message(m))
					env->stats->queue.inserts_local++;
				else
					ss.code = 421;
			} else {
				if (queue_commit_incoming_message(m))
					env->stats->queue.inserts_remote++;
				else
					ss.code = 421;
a185 3
			imsg_compose_event(iev, IMSG_QUEUE_COMMIT_MESSAGE, 0, 0, -1,
			    &ss, sizeof ss);
			return;
d187 13
a199 10
		case IMSG_QUEUE_MESSAGE_FILE:
			ss.id = m->session_id;
			if (m->flags & F_MESSAGE_ENQUEUED)
				fd = enqueue_open_messagefile(m);
			else
				fd = queue_open_incoming_message_file(m);
			if (fd == -1)
				ss.code = 421;
			imsg_compose_event(iev, IMSG_QUEUE_MESSAGE_FILE, 0, 0, fd,
			    &ss, sizeof ss);
d203 1
a203 1
			queue_pass_to_runner(env, iev, imsg);
d209 3
a211 1
		m = imsg->data;
d213 98
a310 4
		switch (imsg->hdr.type) {
		case IMSG_QUEUE_SUBMIT_ENVELOPE:
			m->id = generate_uid();
			ss.id = m->session_id;
d312 3
a314 4
			if (IS_MAILBOX(m->recipient) || IS_EXT(m->recipient))
				m->type = T_MDA_MESSAGE;
			else
				m->type = T_MTA_MESSAGE;
d316 2
a317 3
			/* Write to disk */
			if (m->flags & F_MESSAGE_ENQUEUED)
				ret = enqueue_record_envelope(m);
d319 1
a319 1
				ret = queue_record_incoming_envelope(m);
d321 2
a322 14
			if (ret == 0) {
				ss.code = 421;
				imsg_compose_event(env->sc_ievs[PROC_SMTP],
				    IMSG_QUEUE_TEMPFAIL, 0, 0, -1, &ss,
				    sizeof ss);
			}
			return;

		case IMSG_QUEUE_COMMIT_ENVELOPES:
			ss.id = m->session_id;
			ss.code = 250;
			imsg_compose_event(env->sc_ievs[PROC_SMTP],
			    IMSG_QUEUE_COMMIT_ENVELOPES, 0, 0, -1, &ss,
			    sizeof ss);
d327 1
a327 9
	if (iev->proc == PROC_RUNNER) {
		/* forward imsgs from runner on its behalf */
		imsg_compose_event(env->sc_ievs[imsg->hdr.peerid], imsg->hdr.type,
		    0, imsg->hdr.pid, imsg->fd, (char *)imsg->data,
		    imsg->hdr.len - sizeof imsg->hdr);
		return;
	}

	if (iev->proc == PROC_MTA) {
d329 4
a332 5
		case IMSG_QUEUE_MESSAGE_FD:
			b = imsg->data;
			fd = queue_open_message_file(b->message_id);
			imsg_compose_event(iev,  IMSG_QUEUE_MESSAGE_FD, 0, 0,
			    fd, b, sizeof *b);
a334 1
		case IMSG_QUEUE_MESSAGE_UPDATE:
d336 1
a336 1
			queue_pass_to_runner(env, iev, imsg);
d338 1
d342 1
a342 1
	if (iev->proc == PROC_MDA) {
d344 8
a351 3
		case IMSG_QUEUE_MESSAGE_UPDATE:
		case IMSG_MDA_SESS_NEW:
			queue_pass_to_runner(env, iev, imsg);
d359 9
a367 1
		case IMSG_QUEUE_PAUSE_OUTGOING:
d369 9
a377 1
		case IMSG_QUEUE_RESUME_OUTGOING:
d379 13
d393 11
a403 1
			queue_pass_to_runner(env, iev, imsg);
a409 4
		case IMSG_PARENT_ENQUEUE_OFFLINE:
			queue_pass_to_runner(env, iev, imsg);
			return;

a411 1
			queue_pass_to_runner(env, iev, imsg);
d419 62
d482 1
a482 1
queue_pass_to_runner(struct smtpd *env, struct imsgev *iev, struct imsg *imsg)
d484 70
a553 3
	imsg_compose_event(env->sc_ievs[PROC_RUNNER], imsg->hdr.type,
	    iev->proc, imsg->hdr.pid, imsg->fd, imsg->data,
	    imsg->hdr.len - sizeof imsg->hdr);
d572 1
a572 1
	log_info("queue handler exiting");
a575 10
void
queue_setup_events(struct smtpd *env)
{
}

void
queue_disable_events(struct smtpd *env)
{
}

d581 1
a581 1

d591 1
a591 2
		{ PROC_LKA,	imsg_dispatch },
		{ PROC_RUNNER,	imsg_dispatch }
d620 9
d632 20
d659 25
d685 84
a768 3
	 * queue opens fds for four purposes: smtp, mta, mda, and bounces.
	 * Therefore, use all available fd space and set the maxconn (=max
	 * session count for mta and mda) to a quarter of this value.
d770 624
a1393 3
	fdlimit(1.0);
	if ((env->sc_maxconn = availdesc() / 4) < 1)
		fatalx("runner: fd starvation");
d1395 2
a1396 2
	config_pipes(env, peers, nitems(peers));
	config_peers(env, peers, nitems(peers));
d1398 5
a1402 2
	queue_purge(PATH_INCOMING);
	queue_purge(PATH_ENQUEUE);
d1404 11
a1414 3
	queue_setup_events(env);
	event_dispatch();
	queue_shutdown();
d1416 1
a1416 1
	return (0);
d1420 1
a1420 1
batch_by_id(struct smtpd *env, u_int64_t id)
d1422 12
a1433 1
	struct batch lookup;
d1435 8
a1442 2
	lookup.id = id;
	return SPLAY_FIND(batchtree, &env->batch_queue, &lookup);
d1445 13
d1459 36
a1494 2
void
queue_purge(char *queuepath)
d1496 1
a1496 2
	char		 path[MAXPATHLEN];
	struct qwalk	*q;
d1498 3
a1500 1
	q = qwalk_new(queuepath);
d1502 1
a1502 2
	while (qwalk(q, path))
		queue_delete_layout_message(queuepath, basename(path));
d1504 1
a1504 1
	qwalk_close(q);
d1508 1
a1508 1
queue_submit_envelope(struct smtpd *env, struct message *message)
d1510 1
a1510 3
	imsg_compose_event(env->sc_ievs[PROC_QUEUE],
	    IMSG_QUEUE_SUBMIT_ENVELOPE, 0, 0, -1,
	    message, sizeof(struct message));
d1514 1
a1514 1
queue_commit_envelopes(struct smtpd *env, struct message *message)
d1516 16
a1531 3
	imsg_compose_event(env->sc_ievs[PROC_QUEUE],
	    IMSG_QUEUE_COMMIT_ENVELOPES, 0, 0, -1,
	    message, sizeof(struct message));
@


1.84
log
@Schedule newly arrived mail immediately, ie. place it at the beginning
of the list of next items to try, or near the beginning if the schedule
contains expired mail, which is of highest priority.
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.83 2010/06/01 11:27:07 jacekm Exp $	*/
a3 1
 * Copyright (c) 2008-2010 Jacek Masiulaniec <jacekm@@dobremiasto.net>
a25 1
#include <sys/uio.h>
a26 1
#include <ctype.h>
a30 1
#include <math.h>
a38 2
#include "queue_backend.h"
#include "client.h"
d40 14
a53 35
void		 queue_imsg(struct smtpd *, struct imsgev *, struct imsg *);
int		 queue_append(struct incoming *, char *);
void		 queue_destroy(struct incoming *);
int		 queue_control(u_int64_t, int);
__dead void	 queue_shutdown(void);
void		 queue_sig_handler(int, short, void *);

void		 queue_mem_init(struct smtpd *);
void		 queue_mem_content_unref(struct content *);

void		 queue_send(int, short, void *);
void		 queue_expire(struct batch *);
void		 queue_update(int, int, u_int64_t, char *);
void		 queue_done(int, int);
void		 queue_schedule(int, struct batch *);
void		 queue_sleep(int);
time_t		 queue_retry(int, time_t, time_t);

void		 queue_bounce_wait(struct content *);
void		 queue_bounce_schedule(int, short, void *);
void		 queue_bounce_init(int, int);
void		 queue_bounce_event(int, short, void *);

int		 queue_detect_loop(struct incoming *);

struct batch	*batch_it(struct incoming *, char *);
int		 batchsort(const void *, const void *);
int		 action_grow(struct action **, char *);
char		*rcpt_pretty(struct aux *);

/* table of batches in larval state */
void	**incoming;
int	  incoming_sz;

struct queue runqs[3];
d58 1
a58 3
	struct action		*update;
	struct incoming		*s;
	struct batch		*batch;
d60 2
a61 6
	u_int64_t		 content_id;
	u_int			 rq;
	int			 i, fd, error;
	time_t			 now;
	struct iovec		 iov[2];
	char			 aux[2048]; /* XXX */
d64 2
d67 12
a78 25
		case IMSG_QUEUE_CREATE:
			/*
			 * Create file that will hold mail content.  Its name
			 * uniquely identifies entire mail transaction.  Actions
			 * will refer to the this file as source of mail content.
			 */
			s = calloc(1, sizeof *s);
			if (s == NULL)
				fatal(NULL);
			for (rq = 0; rq < nitems(s->batches); rq++)
				SLIST_INIT(&s->batches[rq]);
			s->content = calloc(1, sizeof *s->content);
			if (s->content == NULL)
				fatal(NULL);
			if (queue_be_content_create(&s->content->id) < 0)
				s->content->id = INVALID_ID;
			i = table_alloc(&incoming, &incoming_sz);
			incoming[i] = s;
			iov[0].iov_base = &s->content->id;
			iov[0].iov_len = sizeof s->content->id;
			iov[1].iov_base = &i;
			iov[1].iov_len = sizeof i;
			imsg_composev(&iev->ibuf, IMSG_QUEUE_CREATE,
			    imsg->hdr.peerid, 0, -1, iov, 2);
			imsg_event_add(iev);
d81 5
a85 10
		case IMSG_QUEUE_DELETE:
			/*
			 * Delete failed transaction's content and actions.
			 */
			memcpy(&i, imsg->data, sizeof i);
			s = table_lookup(incoming, incoming_sz, i);
			if (s == NULL)
				fatalx("queue: bogus delete req");
			incoming[i] = NULL;
			queue_destroy(s);
d88 15
a102 13
		case IMSG_QUEUE_OPEN:
			/*
			 * Open the file that will hold mail content.
			 */
			memcpy(&i, imsg->data, sizeof i);
			s = table_lookup(incoming, incoming_sz, i);
			if (s == NULL)
				fatalx("queue: bogus open req");
			fd = queue_be_content_open(s->content->id, 1);
			if (fd < 0)
				fatal("queue: content open error");
			imsg_compose_event(iev, IMSG_QUEUE_OPEN,
			    imsg->hdr.peerid, 0, fd, NULL, 0);
d105 10
a114 44
		case IMSG_QUEUE_CLOSE:
			/*
			 * Commit mail to queue: we take on responsibility for
			 * performing all requested actions on this content.
			 */
			memcpy(&i, imsg->data, sizeof i);
			s = table_lookup(incoming, incoming_sz, i);
			if (s == NULL)
				fatalx("queue: bogus commit req");
			incoming[i] = NULL;
			if (queue_detect_loop(s) < 0) {
				error = S_MESSAGE_PERMFAILURE;
				imsg_compose_event(iev, IMSG_QUEUE_CLOSE,
				    imsg->hdr.peerid, 0, -1, &error, sizeof error);
				return;
			}
			if (queue_be_commit(s->content->id) < 0) {
				error = S_MESSAGE_TEMPFAILURE;
				imsg_compose_event(iev, IMSG_QUEUE_CLOSE,
				    imsg->hdr.peerid, 0, -1, &error, sizeof error);
				return;
			}
			env->stats->queue.inserts++;
			env->stats->queue.length++;
			time(&now);
			for (rq = 0; rq < nitems(s->batches); rq++) {
				while ((batch = SLIST_FIRST(&s->batches[rq]))) {
					SLIST_REMOVE_HEAD(&s->batches[rq], entry);
					batch = realloc(batch, sizeof *batch);
					if (batch == NULL)
						fatal(NULL);
					batch->retry = RETRY_NOW;
					queue_schedule(rq, batch);
				}
			}
			for (i = 0; i < s->nlocal; i++)
				free(s->local[i]);
			free(s->local);
			free(s);
			queue_sleep(Q_LOCAL);
			queue_sleep(Q_RELAY);
			error = 0;
			imsg_compose_event(iev, IMSG_QUEUE_CLOSE,
			    imsg->hdr.peerid, 0, -1, &error, sizeof error);
d118 1
a118 1
			queue_bounce_init(imsg->hdr.peerid, imsg->fd);
d124 2
d127 14
a140 100
		case IMSG_QUEUE_APPEND:
			m = imsg->data;
			s = table_lookup(incoming, incoming_sz, m->queue_id);
			if (s == NULL)
				fatalx("queue: bogus append");

			switch (m->recipient.rule.r_action) {
			case A_MBOX:
			case A_MAILDIR:
			case A_EXT:
				/* ?|from|to|user1|user2|path */
				if (m->recipient.rule.r_action == A_MBOX)
					strlcpy(aux, "M|", sizeof aux);
				else if (m->recipient.rule.r_action == A_MAILDIR)
					strlcpy(aux, "D|", sizeof aux);
				else
					strlcpy(aux, "P|", sizeof aux);
				if (m->sender.user[0] && m->sender.domain[0]) {
					strlcat(aux, m->sender.user, sizeof aux);
					strlcat(aux, "@@", sizeof aux);
					strlcat(aux, m->sender.domain, sizeof aux);
				}
				strlcat(aux, "|", sizeof aux);
				strlcat(aux, m->session_rcpt.user, sizeof aux);
				strlcat(aux, "@@", sizeof aux);
				strlcat(aux, m->session_rcpt.domain, sizeof aux);
				strlcat(aux, "|", sizeof aux);
				strlcat(aux, m->sender.pw_name, sizeof aux);
				strlcat(aux, "|", sizeof aux);
				strlcat(aux, m->recipient.pw_name, sizeof aux);
				strlcat(aux, "|", sizeof aux);
				strlcat(aux, m->recipient.rule.r_value.path, sizeof aux);
				break;

			case A_FILENAME:
				/* F|from|to|user1|user2|path */
				strlcpy(aux, "F|", sizeof aux);
				if (m->sender.user[0] && m->sender.domain[0]) {
					strlcat(aux, m->sender.user, sizeof aux);
					strlcat(aux, "@@", sizeof aux);
					strlcat(aux, m->sender.domain, sizeof aux);
				}
				strlcat(aux, "|", sizeof aux);
				strlcat(aux, m->session_rcpt.user, sizeof aux);
				strlcat(aux, "@@", sizeof aux);
				strlcat(aux, m->session_rcpt.domain, sizeof aux);
				strlcat(aux, "|", sizeof aux);
				strlcat(aux, m->sender.pw_name, sizeof aux);
				strlcat(aux, "|", sizeof aux);
				strlcat(aux, SMTPD_USER, sizeof aux);
				strlcat(aux, "|", sizeof aux);
				strlcat(aux, m->recipient.u.filename, sizeof aux);
				break;

			case A_RELAY:
			case A_RELAYVIA:
				/* R|from|to|user|rcpt|via|port|ssl|cert|auth */
				strlcpy(aux, "R|", sizeof aux);
				if (m->sender.user[0] && m->sender.domain[0]) {
					strlcat(aux, m->sender.user, sizeof aux);
					strlcat(aux, "@@", sizeof aux);
					strlcat(aux, m->sender.domain, sizeof aux);
				}
				strlcat(aux, "|", sizeof aux);
				strlcat(aux, m->session_rcpt.user, sizeof aux);
				strlcat(aux, "@@", sizeof aux);
				strlcat(aux, m->session_rcpt.domain, sizeof aux);
				strlcat(aux, "|", sizeof aux);
				strlcat(aux, m->sender.pw_name, sizeof aux);
				strlcat(aux, "|", sizeof aux);
				strlcat(aux, m->recipient.user, sizeof aux);
				strlcat(aux, "@@", sizeof aux);
				strlcat(aux, m->recipient.domain, sizeof aux);
				strlcat(aux, "|", sizeof aux);
				if (m->recipient.rule.r_action == A_RELAYVIA)
					strlcat(aux, m->recipient.rule.r_value.relayhost.hostname, sizeof aux);
				strlcat(aux, "|", sizeof aux);
				if (m->recipient.rule.r_value.relayhost.port) {
					char port[10];
					snprintf(port, sizeof port, "%d", ntohs(m->recipient.rule.r_value.relayhost.port));
					strlcat(aux, port, sizeof aux);
				}
				strlcat(aux, "|", sizeof aux);
				switch (m->recipient.rule.r_value.relayhost.flags & F_SSL) {
				case F_SSL:
					strlcat(aux, "ssl", sizeof aux);
					break;
				case F_SMTPS:
					strlcat(aux, "smtps", sizeof aux);
					break;
				case F_STARTTLS:
					strlcat(aux, "starttls", sizeof aux);
					break;
				}
				strlcat(aux, "|", sizeof aux);
				strlcat(aux, m->recipient.rule.r_value.relayhost.cert, sizeof aux);
				strlcat(aux, "|", sizeof aux);
				if (m->recipient.rule.r_value.relayhost.flags & F_AUTH)
					strlcat(aux, "secrets", sizeof aux);
				break;
d142 5
a146 2
			default:
				fatalx("queue: bad r_action");
d148 8
a155 6
			if (queue_append(s, aux) < 0)
				error = S_MESSAGE_TEMPFAILURE;
			else
				error = 0;
			imsg_compose_event(iev, IMSG_QUEUE_APPEND,
			    imsg->hdr.peerid, 0, -1, &error, sizeof error);
d160 9
a168 1
	if (iev->proc == PROC_MDA) {
d170 5
a174 4
		case IMSG_BATCH_UPDATE:
			update = imsg->data;
			queue_update(Q_LOCAL, imsg->hdr.peerid, update->id,
			    update->arg);
d177 1
d179 1
a179 1
			queue_done(Q_LOCAL, imsg->hdr.peerid);
a180 1

d184 1
a184 1
	if (iev->proc == PROC_MTA) {
d186 3
a188 8
		case IMSG_BATCH_UPDATE:
			update = imsg->data;
			queue_update(Q_RELAY, imsg->hdr.peerid, update->id,
			    update->arg);
			return;

		case IMSG_BATCH_DONE:
			queue_done(Q_RELAY, imsg->hdr.peerid);
d196 1
a196 9
			runqs[Q_LOCAL].max = 0;
			queue_sleep(Q_LOCAL);
			return;

		case IMSG_QUEUE_PAUSE_RELAY:
			runqs[Q_RELAY].max = 0;
			queue_sleep(Q_RELAY);
			return;

d198 1
a198 9
			runqs[Q_LOCAL].max = env->sc_maxconn;
			queue_sleep(Q_LOCAL);
			return;

		case IMSG_QUEUE_RESUME_RELAY:
			runqs[Q_RELAY].max = env->sc_maxconn;
			queue_sleep(Q_RELAY);
			return;

a199 13
			memcpy(&content_id, imsg->data, sizeof content_id);
			error = queue_control(content_id, 1);
			if (error)
				log_warnx("schedule request failed");
			else {
				queue_sleep(Q_LOCAL);
				queue_sleep(Q_RELAY);
				queue_sleep(Q_BOUNCE);
			}
			imsg_compose_event(iev, IMSG_QUEUE_SCHEDULE,
			    imsg->hdr.peerid, 0, -1, &error, sizeof error);
			return;

d201 1
a201 11
			memcpy(&content_id, imsg->data, sizeof content_id);
			error = queue_control(content_id, 0);
			if (error)
				log_warnx("remove request failed");
			else {
				queue_sleep(Q_LOCAL);
				queue_sleep(Q_RELAY);
				queue_sleep(Q_BOUNCE);
			}
			imsg_compose_event(iev, IMSG_QUEUE_REMOVE,
			    imsg->hdr.peerid, 0, -1, &error, sizeof error);
d208 4
d214 1
a221 90
int
queue_append(struct incoming *s, char *auxraw)
{
	struct batch	*batch;
	struct action	*action;
	char		*copy;
	struct aux	 aux;

	log_debug("aux %s", auxraw);

	copy = strdup(auxraw);
	if (copy == NULL)
		fatal(NULL);
	auxsplit(&aux, copy);

	/* remember local recipients for delivered-to: loop detection */
	if (aux.mode[0] != 'R') {
		if (s->nlocal == s->local_sz) {
			s->local_sz *= 2;
			s->local = realloc(s->local, ++s->local_sz *
			    sizeof s->local[0]);
			if (s->local == NULL)
				fatal(NULL);
		}
		/*
		 * XXX: using rcpt_to is wrong because it's unexpanded address
		 * as seen in RCPT TO; must use expanded address in the form
		 * <user>@@<domain>, but since lka expands local addresses to
		 * just <user> this is currently undoable.
		 */
		s->local[s->nlocal] = strdup(aux.rcpt_to);
		if (s->local[s->nlocal] == NULL)
			fatal(NULL);
		s->nlocal++;
	}

	/* assign batch */
	if (aux.mode[0] != 'R')
		batch = batch_it(s, "");
	else if (aux.relay_via[0])
		batch = batch_it(s, aux.relay_via);
	else
		batch = batch_it(s, strchr(aux.rcpt, '@@'));
	if (batch == NULL)
		fatal(NULL);
	free(copy);

	action = malloc(sizeof *action);
	if (action == NULL)
		fatal(NULL);
	SLIST_INSERT_HEAD(&batch->actions, action, entry);
	if (queue_be_action_new(s->content->id, &action->id, auxraw) < 0)
		return -1;

	s->content->ref++;

	return 0;
}

struct batch *
batch_it(struct incoming *s, char *sortkey)
{
	struct batch	*batch;
	size_t		 batch_sz;
	u_int		 rq;

	if (*sortkey) {
		rq = Q_RELAY;
		SLIST_FOREACH(batch, &s->batches[rq], entry)
			if (strcmp(batch->sortkey, sortkey) == 0)
				break;
	} else {
		rq = Q_LOCAL;
		batch = NULL;
	}

	if (batch == NULL) {
		batch_sz = sizeof *batch + strlen(sortkey) + 1;
		batch = malloc(batch_sz);
		if (batch == NULL)
			return NULL;
		SLIST_INIT(&batch->actions);
		batch->content = s->content;
		strlcpy(batch->sortkey, sortkey, batch_sz - sizeof *batch);
		SLIST_INSERT_HEAD(&s->batches[rq], batch, entry);
	}

	return batch;
}

d223 1
a223 1
queue_destroy(struct incoming *s)
d225 3
a227 69
	struct batch	*batch;
	struct action	*action;
	u_int		 rq;
	int		 i;

	for (rq = 0; rq < nitems(s->batches); rq++) {
		while ((batch = SLIST_FIRST(&s->batches[rq]))) {
			SLIST_REMOVE_HEAD(&s->batches[rq], entry);
			while ((action = SLIST_FIRST(&batch->actions))) {
				SLIST_REMOVE_HEAD(&batch->actions, entry);
				queue_be_action_delete(s->content->id,
				    action->id);
				free(action);
			}
			free(batch);
		}
	}
	queue_be_content_delete(s->content->id);
	free(s->content);
	for (i = 0; i < s->nlocal; i++)
		free(s->local[i]);
	free(s->local);
	free(s);
}

/*
 * Walk all runqueues to schedule or remove requested content.
 */
int
queue_control(u_int64_t content_id, int schedule)
{
	struct batch	*b, *next;
	struct action	*action;
	struct action_be a;
	struct aux	 aux;
	u_int		 rq, n;

	n = 0;
	for (rq = 0; rq < nitems(runqs); rq++) {
		for (b = SLIST_FIRST(&runqs[rq].head); b; b = next) {
			next = SLIST_NEXT(b, entry);
			if (content_id && b->content->id != content_id)
				continue;
			n++;
			SLIST_REMOVE(&runqs[rq].head, b, batch, entry);
			if (schedule) {
				time(&b->retry);
				queue_schedule(rq, b);
				continue;
			}
			while ((action = SLIST_FIRST(&b->actions))) {
				SLIST_REMOVE_HEAD(&b->actions, entry);
				if (queue_be_action_read(&a, b->content->id,
				    action->id) < 0)
					fatal("queue: action read error");
				auxsplit(&aux, a.aux);
				log_info("%s: to=%s, delay=%d, stat=Removed",
				    queue_be_decode(b->content->id),
				    rcpt_pretty(&aux), time(NULL) - a.birth);
				queue_be_action_delete(b->content->id,
				    action->id);
				queue_mem_content_unref(b->content);
				free(action);
			}
			free(b);
		}
	}

	return (n > 0 ? 0 : -1);
d246 1
a246 1
	log_info("queue exiting");
d250 10
d265 1
a265 1
	u_int		 rq;
d275 2
a276 1
		{ PROC_LKA,	imsg_dispatch }
a304 9
	/*
	 * Queue opens fds for four purposes: smtp, mta, mda, and bounces.
	 * Therefore, use all available fd space and set the maxconn (=max
	 * session count for each of these tasks) to a quarter of this value.
	 */
	fdlimit(1.0);
	if ((env->sc_maxconn = availdesc() / 4) < 1)
		fatalx("queue: fd starvation");

a307 20
	config_pipes(env, peers, nitems(peers));
	config_peers(env, peers, nitems(peers));

	for (rq = 0; rq < nitems(runqs); rq++) {
		SLIST_INIT(&runqs[rq].head);
		runqs[rq].env = env;
		runqs[rq].max = env->sc_maxconn;
	}
	runqs[Q_LOCAL].name = "Q_LOCAL";
	runqs[Q_RELAY].name = "Q_RELAY";
	runqs[Q_BOUNCE].name = "Q_BOUNCE";

	/* bouncing costs 2 fds: file and socket */
	runqs[Q_BOUNCE].max /= 2;

	queue_mem_init(env);
	queue_sleep(Q_LOCAL);
	queue_sleep(Q_RELAY);
	queue_sleep(Q_BOUNCE);

a314 25
	event_dispatch();
	queue_shutdown();

	return (0);
}

void
queue_mem_init(struct smtpd *env)
{
	SLIST_HEAD(,batch)	  lookup[4096];
	void			**batch;
	struct content		 *content;
	struct action		 *action;
	struct batch		 *b;
	char			 *sortkey;
	struct action_be	  a;
	struct aux		  aux;
	int			  batch_sz, batches, rq, sz, i;

	for (i = 0; i < 4096; i++)
		SLIST_INIT(&lookup[i]);
	batch = NULL;
	batch_sz = 0;
	batches = 0;

d316 3
a318 1
	 * Sort actions into batches.
d320 3
a322 31
	for (;;) {
		if (queue_be_getnext(&a) < 0)
			fatal("queue: backend error");
		if (a.action_id == 0)
			break;
		auxsplit(&aux, a.aux);

		/*
		 * Assignment to batch is based on the sortkey:
		 * B=<content_id>	for bounced mail
		 * R=<domain>		for relayed mail
		 * L=<action_id>	for local mail
		 */
		if (a.status[0] == '5' || a.status[0] == '6')
			asprintf(&sortkey, "B=%s", queue_be_decode(a.content_id));
		else if (aux.mode[0] == 'R') {
			if (aux.relay_via[0])
				asprintf(&sortkey, "R=%s", aux.relay_via);
			else
				asprintf(&sortkey, "R=%s", strchr(aux.rcpt, '@@'));
		} else
			asprintf(&sortkey, "L=%s", queue_be_decode(a.action_id));

		content = NULL;
		SLIST_FOREACH(b, &lookup[a.content_id & 4095], entry) {
			if (b->content->id == a.content_id) {
				content = b->content;
				if (strcmp(b->sortkey, sortkey) == 0)
					break;
			}
		}
d324 2
a325 14
		if (b == NULL) {
			sz = sizeof *b + strlen(sortkey) + 1;
			b = malloc(sz);
			if (b == NULL)
				fatal("queue_mem_init");
			SLIST_INIT(&b->actions);
			strlcpy(b->sortkey, sortkey, sz - sizeof *b);

			if (*sortkey == 'B')
				rq = Q_BOUNCE;
			else if (*sortkey == 'R')
				rq = Q_RELAY;
			else
				rq = Q_LOCAL;
d327 2
a328 17
			b->retry = queue_retry(rq, a.birth, a.birth);
			while (b->retry < time(NULL))
				b->retry = queue_retry(rq, a.birth, b->retry);

			if (b->retry > a.birth + SMTPD_EXPIRE)
				b->retry = NO_RETRY_EXPIRED;

			if (content)
				b->content = content;
			else {
				b->content = calloc(1, sizeof *b->content);
				if (b->content == NULL)
					fatal("queue_mem_init");
				b->content->id = a.content_id;
				b->content->ref = 0;
				env->stats->queue.length++;
			}
d330 3
a332 10
			SLIST_INSERT_HEAD(&lookup[a.content_id & 4095], b, entry);
			if (batches == batch_sz) {
				batch_sz *= 2;
				batch = realloc(batch, ++batch_sz * sizeof *batch);
				if (batch == NULL)
					fatal("queue_mem_init");
			}
			batch[batches] = b;
			batches++;
		}
d334 1
a334 27
		action = malloc(sizeof *action);
		if (action == NULL)
			fatal("queue_mem_init");
		action->id = a.action_id;
		SLIST_INSERT_HEAD(&b->actions, action, entry);
		b->content->ref++;
		free(sortkey);
	}

	/*
	 * Add batches to schedule.
	 */
	qsort(batch, batches, sizeof *batch, batchsort);
	for (i = 0; i < batches; i++) {
		b = batch[i];
		if (b->sortkey[0] == 'B')
			rq = Q_BOUNCE;
		else if (b->sortkey[0] == 'R')
			rq = Q_RELAY;
		else
			rq = Q_LOCAL;
		b = realloc(b, sizeof *b);
		if (b == NULL)
			fatal("queue_mem_init");
		queue_schedule(rq, b);
	}
	free(batch);
d337 2
a338 2
int
batchsort(const void *x, const void *y)
d340 1
a340 3
	const struct batch *b1 = x, *b2 = y;
	return (b1->retry < b2->retry ? -1 : b1->retry > b2->retry);
}
d342 2
a343 10
void
queue_mem_content_unref(struct content *content)
{
	content->ref--;
	if (content->ref < 0)
		fatalx("queue: bad refcount");
	else if (content->ref == 0) {
		queue_be_content_delete(content->id);
		runqs[Q_LOCAL].env->stats->queue.length--;
	}
a345 323
void
queue_send(int fd, short event, void *p)
{
	struct smtpd		*env;
	struct batch		*batch;
	struct action		*action;
	struct action_be	 a;
	int			 rq, i, to, size;
	time_t			 now;

	rq = (struct queue *)p - runqs;
	env = runqs[rq].env;
	time(&now);
	i = -1;

	while ((batch = SLIST_FIRST(&runqs[rq].head))) {
		if (batch->retry > now || runqs[rq].sessions >= runqs[rq].max)
			break;

		SLIST_REMOVE_HEAD(&runqs[rq].head, entry);
		i = table_alloc(&runqs[rq].session, &runqs[rq].session_sz);
		runqs[rq].session[i] = batch;
		runqs[rq].sessions++;

		log_debug("%s: %d: start %s", runqs[rq].name, i,
		    queue_be_decode(batch->content->id));

		if (batch->retry == NO_RETRY_EXPIRED) {
			log_debug("%s: %d: expire", runqs[rq].name, i);
			queue_expire(batch);
			queue_done(rq, i);
			continue;
		}

		if (rq == Q_BOUNCE) {
			log_debug("%s: %d: socket request", runqs[rq].name, i);
			imsg_compose_event(env->sc_ievs[PROC_SMTP],
			    IMSG_SMTP_ENQUEUE, i, 0, -1, NULL, 0);
			continue;
		}

		log_debug("%s: %d: send", runqs[rq].name, i);

		fd = queue_be_content_open(batch->content->id, 0);
		if (fd < 0)
			fatal("queue: content open error");

		if (rq == Q_LOCAL)
			to = PROC_MDA;
		else
			to = PROC_MTA;

		imsg_compose_event(env->sc_ievs[to], IMSG_BATCH_CREATE, i, 0,
		    fd, &batch->content->id, sizeof batch->content->id);

		while ((action = SLIST_FIRST(&batch->actions))) {
			SLIST_REMOVE_HEAD(&batch->actions, entry);
			if (queue_be_action_read(&a, batch->content->id,
			    action->id) < 0)
				fatal("queue: action read error");
			size = action_grow(&action, a.aux);
			imsg_compose_event(env->sc_ievs[to], IMSG_BATCH_APPEND,
			    i, 0, -1, action, size);
			free(action);
		}

		imsg_compose_event(env->sc_ievs[to], IMSG_BATCH_CLOSE, i, 0, -1,
		    &a.birth, sizeof a.birth);
	}

	/* Sanity check: were we called for no good reason? */
	if (i == -1)
		fatalx("queue_send: empty run");

	queue_sleep(rq);
}

void
queue_expire(struct batch *batch)
{
	struct action	*action, *fail;
	struct action_be a;
	struct aux	 aux;
	time_t		 birth;
	int		 error;

	action = SLIST_FIRST(&batch->actions);
	if (queue_be_action_read(&a, batch->content->id, action->id) < 0)
		fatal("queue: action read error");

	auxsplit(&aux, a.aux);
	birth = a.birth;

	if (a.status[0] == '5' || a.status[0] == '6') {
		log_warnx("%s: to=%s, delay=%d, stat=Expired (no bounce due "
		    "to: larval bounce)",
		    queue_be_decode(batch->content->id), aux.mail_from,
		    time(NULL) - birth);
		while ((action = SLIST_FIRST(&batch->actions))) {
			SLIST_REMOVE_HEAD(&batch->actions, entry);
			queue_be_action_delete(batch->content->id, action->id);
			queue_mem_content_unref(batch->content);
			free(action);
		}
		return;
	}

	if (aux.mail_from[0] == '\0') {
		while ((action = SLIST_FIRST(&batch->actions))) {
			SLIST_REMOVE_HEAD(&batch->actions, entry);

			if (queue_be_action_read(&a, batch->content->id,
			    action->id) < 0)
				fatal("queue: action read error");
			auxsplit(&aux, a.aux);
			log_warnx("%s: to=%s, delay=%d, stat=Expired (no bounce "
			    "due to: double bounce)",
			    queue_be_decode(batch->content->id),
			    rcpt_pretty(&aux), time(NULL) - birth);

			queue_be_action_delete(batch->content->id, action->id);
			queue_mem_content_unref(batch->content);
			free(action);
		}
		return;
	}

	SLIST_FOREACH(action, &batch->actions, entry)
		if (queue_be_action_status(batch->content->id, action->id,
		    "600 Message expired after too many delivery attempts") < 0)
			break;

	if (action) {
		fail = action;
		error = errno;
	} else {
		fail = NULL;
		error = 0;
	}

	while ((action = SLIST_FIRST(&batch->actions))) {
		if (action == fail)
			break;
		SLIST_REMOVE_HEAD(&batch->actions, entry);

		if (queue_be_action_read(&a, batch->content->id,
		    action->id) < 0)
			fatal("queue: action read error");
		auxsplit(&aux, a.aux);
		log_info("%s: to=%s, delay=%d, stat=Expired",
		    queue_be_decode(batch->content->id), rcpt_pretty(&aux),
		    time(NULL) - birth);

		SLIST_INSERT_HEAD(&batch->content->actions, action, entry);

		queue_bounce_wait(batch->content);
	}

	while ((action = SLIST_FIRST(&batch->actions))) {
		SLIST_REMOVE_HEAD(&batch->actions, entry);

		if (queue_be_action_read(&a, batch->content->id,
		    action->id) < 0)
			fatal("queue: action read error");
		auxsplit(&aux, a.aux);
		log_warnx("%s: to=%s, delay=%d, stat=Expired (no bounce due "
		    "to: %s)",
		    queue_be_decode(batch->content->id), rcpt_pretty(&aux),
		    time(NULL) - birth, strerror(error));

		queue_be_action_delete(batch->content->id, action->id);
		queue_mem_content_unref(batch->content);
		free(action);
	}
}

/*
 * Grow action to append auxillary info needed by mta and mda.  To conserve
 * memory, queue calls this routine only for active delivery sessions so that
 * pending actions, potentially many, remain tiny.
 */
int
action_grow(struct action **action, char *aux)
{
	struct action *p;
	int size;

	size = sizeof *p + strlen(aux) + 1;
	p = realloc(*action, size);
	if (p == NULL)
		fatal(NULL);
	strlcpy(p->arg, aux, size - sizeof *p);
	*action = p;

	return size;
}

void
queue_update(int rq, int i, u_int64_t action_id, char *new_status)
{
	struct batch	*batch;
	struct action	*action;
	struct action_be a;
	struct aux	 aux;

	batch = table_lookup(runqs[rq].session, runqs[rq].session_sz, i);
	if (batch == NULL)
		fatalx("queue: bogus update");

	if (*new_status == '2') {
		queue_be_action_delete(batch->content->id, action_id);
		queue_mem_content_unref(batch->content);
		return;
	}

	action = malloc(sizeof *action);
	if (action == NULL)
		fatal(NULL);
	action->id = action_id;

	if (*new_status == '5' || *new_status == '6') {
		if (queue_be_action_read(&a, batch->content->id, action_id) < 0)
			fatal("queue: queue read error");

		auxsplit(&aux, a.aux);

		if (aux.mail_from[0] == '\0') {
			log_warnx("%s: bounce recipient %s not contactable, "
			    "bounce dropped",
			    queue_be_decode(batch->content->id), aux.rcpt_to);
			queue_be_action_delete(batch->content->id, action_id);
			queue_mem_content_unref(batch->content);
			free(action);
			return;
		}

		if (queue_be_action_status(batch->content->id, action_id,
		    new_status) < 0) {
			log_warn("%s: recipient %s not contactable, bounce not "
			    "created due to queue error",
			    queue_be_decode(batch->content->id), aux.rcpt_to);
			queue_be_action_delete(batch->content->id, action_id);
			queue_mem_content_unref(batch->content);
			free(action);
			return;
		}

		SLIST_INSERT_HEAD(&batch->content->actions, action, entry);

		queue_bounce_wait(batch->content);
	} else {
		queue_be_action_status(batch->content->id, action_id, new_status);
		SLIST_INSERT_HEAD(&batch->actions, action, entry);
	}
}

void
queue_done(int rq, int i)
{
	struct action_be a;
	struct batch	*batch;
	struct action	*action;

	/* Take batch off the session table. */
	batch = table_lookup(runqs[rq].session, runqs[rq].session_sz, i);
	if (batch == NULL)
		fatalx("queue: bogus batch");
	runqs[rq].session[i] = NULL;
	runqs[rq].sessions--;

	log_debug("%s: %d: done", runqs[rq].name, i);

	/* All actions sent? */
	if (SLIST_EMPTY(&batch->actions)) {
		if (batch->content->ref == 0) {
			free(batch->content->ev);
			free(batch->content);
		}
		free(batch);
	} else {
		/* Batch has actions with temporary errors. */
		action = SLIST_FIRST(&batch->actions);
		if (queue_be_action_read(&a, batch->content->id,
		    action->id) < 0)
			fatal("queue: action read error");
		batch->retry = queue_retry(rq, a.birth, batch->retry);
		if (batch->retry > a.birth + SMTPD_EXPIRE)
			batch->retry = NO_RETRY_EXPIRED;
		queue_schedule(rq, batch);
	}

	queue_sleep(rq);
}

/*
 * Insert batch into runqueue in retry time order.
 */
void
queue_schedule(int rq, struct batch *batch)
{
	struct batch *b, *prev;

	prev = NULL;

	SLIST_FOREACH(b, &runqs[rq].head, entry) {
		if (b->retry >= batch->retry) {
			if (prev)
				SLIST_INSERT_AFTER(prev, batch, entry);
			else
				SLIST_INSERT_HEAD(&runqs[rq].head, batch,
				    entry);
			break;
		}
		prev = b;
	}

	if (b == NULL) {
		if (prev)
			SLIST_INSERT_AFTER(prev, batch, entry);
		else
			SLIST_INSERT_HEAD(&runqs[rq].head, batch, entry);
	}
}
d348 1
a348 35
queue_sleep(int rq)
{
	struct timeval	 tv;
	struct batch	*next;
	time_t		 now;

	evtimer_del(&runqs[rq].ev);

	if (runqs[rq].sessions >= runqs[rq].max)
		return;

	next = SLIST_FIRST(&runqs[rq].head);
	if (next == NULL)
		return;
	
	time(&now);
	if (next->retry < now)
		tv.tv_sec = 0;
	else
		tv.tv_sec = next->retry - now;
	tv.tv_usec = 0;

	log_debug("%s: sleep %lus", runqs[rq].name, tv.tv_sec);

	evtimer_set(&runqs[rq].ev, queue_send, &runqs[rq]);
	evtimer_add(&runqs[rq].ev, &tv);
}

/*
 * Qmail-like retry schedule.
 *
 * Local deliveries are tried more often than remote.
 */
time_t
queue_retry(int rq, time_t birth, time_t last)
d350 2
a351 11
	int n;

	if (last - birth < 0)
		n = 0;
	else if (rq == Q_RELAY)
		n = sqrt(last - birth) + 20;
	else
		n = sqrt(last - birth) + 10;

	return birth + n * n;
}
d353 1
a353 9
/*
 * Wait for permanent failures against this content for few more seconds.
 * If none arrive, combine them into single batch and put on Q_BOUNCE
 * runqueue.  If one does arrive, append it, and restart the timer.
 */
void
queue_bounce_wait(struct content *content)
{
	struct timeval tv;
d355 2
a356 11
	if (content->ev == NULL) {
		content->ev = calloc(1, sizeof *content->ev);
		if (content->ev == NULL)
			fatal(NULL);
	}
	tv.tv_sec = 3;
	tv.tv_usec = 0;
	evtimer_del(content->ev);
	evtimer_set(content->ev, queue_bounce_schedule, content);
	evtimer_add(content->ev, &tv);
}
d358 1
a358 22
void
queue_bounce_schedule(int fd, short event, void *p)
{
	struct content	*content = p;
	struct batch	*batch;
	struct action	*action;

	free(content->ev);
	content->ev = NULL;

	batch = malloc(sizeof *batch);
	if (batch == NULL)
		fatal(NULL);
	SLIST_INIT(&batch->actions);
	batch->content = content;
	while ((action = SLIST_FIRST(&content->actions))) {
		SLIST_REMOVE_HEAD(&content->actions, entry);
		SLIST_INSERT_HEAD(&batch->actions, action, entry);
	}
	time(&batch->retry);
	queue_schedule(Q_BOUNCE, batch);
	queue_sleep(Q_BOUNCE);
d362 1
a362 1
queue_bounce_init(int i, int sock)
d364 3
a366 64
	struct smtpd	*env = runqs[Q_BOUNCE].env;
	struct batch	*batch;
	struct bounce	*s;
	struct action	*action;
	struct action_be a;
	struct aux	 aux;
	int		 fd, header;

	log_debug("%s: %d: init", runqs[Q_BOUNCE].name, i);

	batch = table_lookup(runqs[Q_BOUNCE].session,
	    runqs[Q_BOUNCE].session_sz, i);
	if (batch == NULL)
		fatalx("queue: bogus bounce batch");

	if (sock < 0) {
		queue_done(Q_BOUNCE, i);
		return;
	}

	fd = queue_be_content_open(batch->content->id, 0);
	if (fd < 0)
		fatal("queue: content open error");

	s = calloc(1, sizeof *s);
	if (s == NULL)
		fatal(NULL);
	s->batch = batch;
	s->pcb = client_init(sock, fd, env->sc_hostname, 1);
	s->id = i;
	client_sender(s->pcb, "");
	client_ssl_optional(s->pcb);

	header = 0;
	SLIST_FOREACH(action, &batch->actions, entry) {
		if (queue_be_action_read(&a, batch->content->id,
		    action->id) < 0)
			fatal("queue: backend read error");
		auxsplit(&aux, a.aux);
		if (header == 0) {
			client_rcpt(s->pcb, "%s", aux.mail_from);
			client_printf(s->pcb,
			    "From: Mailer Daemon <MAILER-DAEMON@@%s>\n"
			    "To: %s\n"
			    "Subject: Delivery status notification\n"
			    "Date: %s\n"
			    "\n"
			    "This is automated mail delivery notification, please DO NOT REPLY.\n"
			    "An error has occurred while attempting to deliver your mail to the\n"
			    "following recipients:\n"
			    "\n",
			    env->sc_hostname, aux.mail_from,
			    time_to_text(time(NULL)));
			header = 1;
		}
		if (strlen(a.status) > 4 && (a.status[0] == '1' || a.status[0] == '6'))
			a.status += 4;
		client_printf(s->pcb, "%s: %s\n\n", aux.rcpt_to, a.status);
	}
	client_printf(s->pcb, "Below is a copy of your mail:\n\n");

	session_socket_blockmode(sock, BM_NONBLOCK);
	event_set(&s->ev, sock, EV_READ|EV_WRITE, queue_bounce_event, s);
	event_add(&s->ev, &s->pcb->timeout);
d370 1
a370 57
queue_bounce_event(int fd, short event, void *p)
{
	struct action	*action;
	struct bounce	*s = p;
	char		*status = NULL;

	if (event & EV_TIMEOUT) {
		status = "100 timeout";
		goto out;
	}

	switch (client_talk(s->pcb, event & EV_WRITE)) {
	case CLIENT_STOP_WRITE:
		goto ro;
	case CLIENT_WANT_WRITE:
		goto rw;
	case CLIENT_RCPT_FAIL:
		status = s->pcb->reply;
		break;
	case CLIENT_DONE:
		status = s->pcb->status;
		break;
	default:
		fatalx("queue: bad client_talk");
	}

out:
	log_debug("%s: %d: last event", runqs[Q_BOUNCE].name, s->id);

	if (*status == '5' || *status == '6')
		fatalx("queue: smtp refused bounce");
	if (*status == '2') {
		while ((action = SLIST_FIRST(&s->batch->actions))) {
			SLIST_REMOVE_HEAD(&s->batch->actions, entry);
			queue_be_action_delete(s->batch->content->id,
			    action->id);
			queue_mem_content_unref(s->batch->content);
			free(action);
		}
	}
	queue_done(Q_BOUNCE, s->id);
	client_close(s->pcb);
	free(s);
	return;

ro:
	event_set(&s->ev, fd, EV_READ, queue_bounce_event, s);
	event_add(&s->ev, &s->pcb->timeout);
	return;

rw:
	event_set(&s->ev, fd, EV_READ|EV_WRITE, queue_bounce_event, s);
	event_add(&s->ev, &s->pcb->timeout);
}

int
queue_detect_loop(struct incoming *s)
d372 3
a374 56
	FILE	*fp;
	char	*buf, *lbuf;
	size_t	 len, received;
	int	 fd, i;

	fd = queue_be_content_open(s->content->id, 0);
	if (fd < 0)
		fatal("queue_detect_loop: content open error");
	fp = fdopen(fd, "r");
	if (fp == NULL)
		fatal("queue_detect_loop: fdopen");

	received = 0;
	lbuf = NULL;

	while ((buf = fgetln(fp, &len))) {
		free(lbuf);
		lbuf = NULL;

		if (buf[len - 1] == '\n') {
			buf[len - 1] = '\0';
			len--;
		} else {
			/* EOF without EOL, copy and add the NUL */
			if ((lbuf = malloc(len + 1)) == NULL)
				fatal(NULL);
			memcpy(lbuf, buf, len);
			lbuf[len] = '\0';
			buf = lbuf;
		}

		if (*buf == '\0') {
			buf = NULL;
			break;
		}

		if (strncasecmp(buf, "Received:", 9) == 0) {
			received++;
			if (received >= MAX_HOPS_COUNT) 
				break;
		} else if (strncasecmp(buf, "Delivered-To:", 13) == 0) {
			buf += 13;
			while (isspace(*buf))
				buf++;
			buf[strcspn(buf, " \t")] = '\0';
			for (i = 0; i < s->nlocal; i++)
				if (strcmp(s->local[i], buf) == 0)
					break;
			if (i < s->nlocal)
				break;
		}
	}
	free(lbuf);
	fclose(fp);

	return (buf == NULL ? 0 : -1);
@


1.83
log
@It's lasttry + 1 because I initially thought passing identical birth
and lasttry args to queue_retry would make it return birth leading
looped scheduling, but that's not true so drop the "+ 1".
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.82 2010/05/31 23:38:56 jacekm Exp $	*/
d183 1
a183 1
					batch->retry = now;
a493 1
		batch->retry = 0;
@


1.82
log
@Rewrite entire queue code.

Major goals:

1) Fix bad performance caused by the runner process doing full queue
read in 1s intervals.  My Soekris can now happily accept >50 msg/s
while having multi-thousand queue; before, one hundred queue would
bring the system to its knees.

2) Introduce Qmail-like scheduler that doesn't write as much to the
disk so that it needs less code for servicing error conditions,
which in some places can be tricky to get right.

3) Introduce separation between the scheduler and the backend; these
two queue aspects shouldn't be too tied too each other.  This means
that eg. storing queue in SQL requires rewrite of just queue_backend.c.

4) Make on-disk queue format architecture independent, and more
easily extensible, to reduce number of flag days in the future.

Minor goals:

ENOSPC no longer prevents delivery attempts, fixed session limiting
for relayed mail, improved batching of "relay via" mails, human-readable
mailq output, "show queue raw" command, clearer logging, sending
of single bounce about multiple recipients, exact delay= computation,
zero delay between deliveries while within session limit (currently
1s delay between re-scheduling is enforced), mta no longer requests
content fd, corrected session limit for bounce submissions, tiny
<100B queue files instead of multi-KB, detect loops before accepting
mail, reduce traffic on imsg channels by killing enormous struct
submit_status.
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.81 2010/04/22 12:13:33 jacekm Exp $	*/
d755 1
a755 1
			b->retry = queue_retry(rq, a.birth, a.birth + 1);
@


1.81
log
@- kill the runner_imsg_compose wrapper to reduce indirection
- kill noisy log_debug
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.80 2010/04/21 18:54:43 jacekm Exp $	*/
d4 1
d27 1
d29 1
d34 1
d43 2
d46 35
a80 14
void		queue_imsg(struct smtpd *, struct imsgev *, struct imsg *);
void		queue_pass_to_runner(struct smtpd *, struct imsgev *, struct imsg *);
__dead void	queue_shutdown(void);
void		queue_sig_handler(int, short, void *);
void		queue_setup_events(struct smtpd *);
void		queue_disable_events(struct smtpd *);
void		queue_purge(char *);

int		queue_create_layout_message(char *, char *);
void		queue_delete_layout_message(char *, char *);
int		queue_record_layout_envelope(char *, struct message *);
int		queue_remove_layout_envelope(char *, struct message *);
int		queue_commit_layout_message(char *, struct message *);
int		queue_open_layout_messagefile(char *, struct message *);
d85 3
a87 1
	struct submit_status	 ss;
d89 6
a94 2
	struct batch		*b;
	int			 fd, ret;
a96 2
		m = imsg->data;

d98 25
a122 12
		case IMSG_QUEUE_CREATE_MESSAGE:
			ss.id = m->session_id;
			ss.code = 250;
			bzero(ss.u.msgid, sizeof ss.u.msgid);
			if (m->flags & F_MESSAGE_ENQUEUED)
				ret = enqueue_create_layout(ss.u.msgid);
			else
				ret = queue_create_incoming_layout(ss.u.msgid);
			if (ret == 0)
				ss.code = 421;
			imsg_compose_event(iev, IMSG_QUEUE_CREATE_MESSAGE, 0, 0, -1,
			    &ss, sizeof ss);
d125 10
a134 5
		case IMSG_QUEUE_REMOVE_MESSAGE:
			if (m->flags & F_MESSAGE_ENQUEUED)
				enqueue_delete_message(m->message_id);
			else
				queue_delete_incoming_message(m->message_id);
d137 13
a149 15
		case IMSG_QUEUE_COMMIT_MESSAGE:
			ss.id = m->session_id;
			if (m->flags & F_MESSAGE_ENQUEUED) {
				if (enqueue_commit_message(m))
					env->stats->queue.inserts_local++;
				else
					ss.code = 421;
			} else {
				if (queue_commit_incoming_message(m))
					env->stats->queue.inserts_remote++;
				else
					ss.code = 421;
			}
			imsg_compose_event(iev, IMSG_QUEUE_COMMIT_MESSAGE, 0, 0, -1,
			    &ss, sizeof ss);
d152 44
a195 10
		case IMSG_QUEUE_MESSAGE_FILE:
			ss.id = m->session_id;
			if (m->flags & F_MESSAGE_ENQUEUED)
				fd = enqueue_open_messagefile(m);
			else
				fd = queue_open_incoming_message_file(m);
			if (fd == -1)
				ss.code = 421;
			imsg_compose_event(iev, IMSG_QUEUE_MESSAGE_FILE, 0, 0, fd,
			    &ss, sizeof ss);
d199 1
a199 1
			queue_pass_to_runner(env, iev, imsg);
a204 2
		m = imsg->data;

d206 100
a305 3
		case IMSG_QUEUE_SUBMIT_ENVELOPE:
			m->id = generate_uid();
			ss.id = m->session_id;
d307 5
a311 8
			if (IS_MAILBOX(m->recipient) || IS_EXT(m->recipient))
				m->type = T_MDA_MESSAGE;
			else
				m->type = T_MTA_MESSAGE;

			/* Write to disk */
			if (m->flags & F_MESSAGE_ENQUEUED)
				ret = enqueue_record_envelope(m);
d313 3
a315 16
				ret = queue_record_incoming_envelope(m);

			if (ret == 0) {
				ss.code = 421;
				imsg_compose_event(env->sc_ievs[PROC_SMTP],
				    IMSG_QUEUE_TEMPFAIL, 0, 0, -1, &ss,
				    sizeof ss);
			}
			return;

		case IMSG_QUEUE_COMMIT_ENVELOPES:
			ss.id = m->session_id;
			ss.code = 250;
			imsg_compose_event(env->sc_ievs[PROC_SMTP],
			    IMSG_QUEUE_COMMIT_ENVELOPES, 0, 0, -1, &ss,
			    sizeof ss);
d320 1
a320 9
	if (iev->proc == PROC_RUNNER) {
		/* forward imsgs from runner on its behalf */
		imsg_compose_event(env->sc_ievs[imsg->hdr.peerid], imsg->hdr.type,
		    0, imsg->hdr.pid, imsg->fd, (char *)imsg->data,
		    imsg->hdr.len - sizeof imsg->hdr);
		return;
	}

	if (iev->proc == PROC_MTA) {
d322 4
a325 5
		case IMSG_QUEUE_MESSAGE_FD:
			b = imsg->data;
			fd = queue_open_message_file(b->message_id);
			imsg_compose_event(iev,  IMSG_QUEUE_MESSAGE_FD, 0, 0,
			    fd, b, sizeof *b);
a327 1
		case IMSG_QUEUE_MESSAGE_UPDATE:
d329 1
a329 1
			queue_pass_to_runner(env, iev, imsg);
d331 1
d335 1
a335 1
	if (iev->proc == PROC_MDA) {
d337 8
a344 3
		case IMSG_QUEUE_MESSAGE_UPDATE:
		case IMSG_MDA_SESS_NEW:
			queue_pass_to_runner(env, iev, imsg);
d352 9
a360 1
		case IMSG_QUEUE_PAUSE_OUTGOING:
d362 9
a370 1
		case IMSG_QUEUE_RESUME_OUTGOING:
d372 13
d386 11
a396 1
			queue_pass_to_runner(env, iev, imsg);
a402 4
		case IMSG_PARENT_ENQUEUE_OFFLINE:
			queue_pass_to_runner(env, iev, imsg);
			return;

a404 1
			queue_pass_to_runner(env, iev, imsg);
d412 91
d504 1
a504 1
queue_pass_to_runner(struct smtpd *env, struct imsgev *iev, struct imsg *imsg)
d506 69
a574 3
	imsg_compose_event(env->sc_ievs[PROC_RUNNER], imsg->hdr.type,
	    iev->proc, imsg->hdr.pid, imsg->fd, imsg->data,
	    imsg->hdr.len - sizeof imsg->hdr);
d593 1
a593 1
	log_info("queue handler exiting");
a596 10
void
queue_setup_events(struct smtpd *env)
{
}

void
queue_disable_events(struct smtpd *env)
{
}

d602 1
a602 1

d612 1
a612 2
		{ PROC_LKA,	imsg_dispatch },
		{ PROC_RUNNER,	imsg_dispatch }
d641 9
d653 20
d680 113
d794 1
a794 3
	 * queue opens fds for four purposes: smtp, mta, mda, and bounces.
	 * Therefore, use all available fd space and set the maxconn (=max
	 * session count for mta and mda) to a quarter of this value.
d796 250
a1045 3
	fdlimit(1.0);
	if ((env->sc_maxconn = availdesc() / 4) < 1)
		fatalx("runner: fd starvation");
d1047 20
a1066 2
	config_pipes(env, peers, nitems(peers));
	config_peers(env, peers, nitems(peers));
d1068 10
a1077 2
	queue_purge(PATH_INCOMING);
	queue_purge(PATH_ENQUEUE);
d1079 1
a1079 3
	queue_setup_events(env);
	event_dispatch();
	queue_shutdown();
d1081 5
a1085 1
	return (0);
d1088 2
a1089 2
struct batch *
batch_by_id(struct smtpd *env, u_int64_t id)
d1091 31
a1121 1
	struct batch lookup;
d1123 1
a1123 2
	lookup.id = id;
	return SPLAY_FIND(batchtree, &env->batch_queue, &lookup);
d1126 29
d1157 35
a1191 1
queue_purge(char *queuepath)
d1193 11
a1203 2
	char		 path[MAXPATHLEN];
	struct qwalk	*q;
d1205 9
a1213 1
	q = qwalk_new(queuepath);
d1215 11
a1225 2
	while (qwalk(q, path))
		queue_delete_layout_message(queuepath, basename(path));
d1227 22
a1248 1
	qwalk_close(q);
d1252 1
a1252 1
queue_submit_envelope(struct smtpd *env, struct message *message)
d1254 64
a1317 3
	imsg_compose_event(env->sc_ievs[PROC_QUEUE],
	    IMSG_QUEUE_SUBMIT_ENVELOPE, 0, 0, -1,
	    message, sizeof(struct message));
d1321 57
a1377 1
queue_commit_envelopes(struct smtpd *env, struct message *message)
d1379 56
a1434 3
	imsg_compose_event(env->sc_ievs[PROC_QUEUE],
	    IMSG_QUEUE_COMMIT_ENVELOPES, 0, 0, -1,
	    message, sizeof(struct message));
@


1.80
log
@Runner process is just a helper for queue, so tear down its imsg
channels to parent, mda, mta, lka, smtp, and control.  This leaves
just the channel to queue, which forwards imsgs on runner's behalf
and redirects any replies back to it.

OK gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.79 2010/04/21 08:29:01 jacekm Exp $	*/
a161 1
		log_debug("queue: runner sent %d imsg type %d", imsg->hdr.peerid, imsg->hdr.type);
a224 1
	log_debug("queue_pass_to_runner: from %d type %d", iev->proc, imsg->hdr.type);
@


1.79
log
@Remove unusable ifdef DEBUG code.
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.78 2010/04/20 15:34:56 jacekm Exp $	*/
d41 1
d61 1
a61 1
	int			 fd, ret, verbose;
d116 4
d160 9
d179 2
a180 3
			imsg_compose_event(env->sc_ievs[PROC_RUNNER],
			    IMSG_RUNNER_UPDATE_ENVELOPE, 0, 0, -1, imsg->data,
			    sizeof(struct message));
d188 15
a202 3
			imsg_compose_event(env->sc_ievs[PROC_RUNNER],
			    IMSG_RUNNER_UPDATE_ENVELOPE, 0, 0, -1, imsg->data,
			    sizeof(struct message));
d209 4
d214 2
a215 2
			memcpy(&verbose, imsg->data, sizeof verbose);
			log_verbose(verbose);
d221 9
@


1.78
log
@Kill *2400* lines of code by abstracting common bits of the imsg handlers.
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.77 2010/01/03 14:37:37 chl Exp $	*/
a255 1
#ifndef DEBUG
a259 3
#else
#warning disabling privilege revocation and chroot in DEBUG MODE
#endif
a263 1
#ifndef DEBUG
a267 1
#endif
@


1.77
log
@Implement "log verbose" and "log brief" to enable or disable verbose debug
logging on runtime.

Based on claudio@@'s work on ripd, ospfd, ospf6d, dvmrpd, ldpd, bgpd.

With help/ideas/testing from gilles@@ jacekm@@ todd@@

ok jacekm@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.76 2009/12/14 19:56:55 jacekm Exp $	*/
d40 1
a42 7
void		queue_dispatch_parent(int, short, void *);
void		queue_dispatch_control(int, short, void *);
void		queue_dispatch_smtp(int, short, void *);
void		queue_dispatch_mda(int, short, void *);
void		queue_dispatch_mta(int, short, void *);
void		queue_dispatch_lka(int, short, void *);
void		queue_dispatch_runner(int, short, void *);
a53 16
void		queue_submit_envelope(struct smtpd *, struct message *);
void	        queue_commit_envelopes(struct smtpd *, struct message*);

void
queue_sig_handler(int sig, short event, void *p)
{
	switch (sig) {
	case SIGINT:
	case SIGTERM:
		queue_shutdown();
		break;
	default:
		fatalx("queue_sig_handler: unexpected signal");
	}
}

d55 1
a55 1
queue_dispatch_parent(int sig, short event, void *p)
d57 11
a67 140
	struct smtpd		*env = p;
	struct imsgev		*iev;
	struct imsgbuf		*ibuf;
	struct imsg		 imsg;
	ssize_t			 n;

	iev = env->sc_ievs[PROC_PARENT];
	ibuf = &iev->ibuf;

	if (event & EV_READ) {
		if ((n = imsg_read(ibuf)) == -1)
			fatal("imsg_read_error");
		if (n == 0) {
			/* this pipe is dead, so remove the event handler */
			event_del(&iev->ev);
			event_loopexit(NULL);
			return;
		}
	}

	if (event & EV_WRITE) {
		if (msgbuf_write(&ibuf->w) == -1)
			fatal("msgbuf_write");
	}

	for (;;) {
		if ((n = imsg_get(ibuf, &imsg)) == -1)
			fatal("queue_dispatch_parent: imsg_get error");
		if (n == 0)
			break;

		switch (imsg.hdr.type) {
		case IMSG_CTL_VERBOSE: {
			int verbose;

			IMSG_SIZE_CHECK(&verbose);

			memcpy(&verbose, imsg.data, sizeof(verbose));
			log_verbose(verbose);
			break;
		}
		default:
			log_warnx("got imsg %d", imsg.hdr.type);
			fatalx("queue_dispatch_parent: unexpected imsg");
		}
		imsg_free(&imsg);
	}
	imsg_event_add(iev);
}

void
queue_dispatch_control(int sig, short event, void *p)
{
	struct smtpd		*env = p;
	struct imsgev		*iev;
	struct imsgbuf		*ibuf;
	struct imsg		 imsg;
	ssize_t			 n;

	iev = env->sc_ievs[PROC_CONTROL];
	ibuf = &iev->ibuf;

	if (event & EV_READ) {
		if ((n = imsg_read(ibuf)) == -1)
			fatal("imsg_read_error");
		if (n == 0) {
			/* this pipe is dead, so remove the event handler */
			event_del(&iev->ev);
			event_loopexit(NULL);
			return;
		}
	}

	if (event & EV_WRITE) {
		if (msgbuf_write(&ibuf->w) == -1)
			fatal("msgbuf_write");
	}

	for (;;) {
		if ((n = imsg_get(ibuf, &imsg)) == -1)
			fatal("queue_dispatch_control: imsg_get error");
		if (n == 0)
			break;

		switch (imsg.hdr.type) {
		default:
			log_warnx("queue_dispatch_control: got imsg %d",
			    imsg.hdr.type);
			fatalx("queue_dispatch_control: unexpected imsg");
		}
		imsg_free(&imsg);
	}
	imsg_event_add(iev);
}

void
queue_dispatch_smtp(int sig, short event, void *p)
{
	struct smtpd		*env = p;
	struct imsgev		*iev;
	struct imsgbuf		*ibuf;
	struct imsg		 imsg;
	ssize_t			 n;

	iev = env->sc_ievs[PROC_SMTP];
	ibuf = &iev->ibuf;

	if (event & EV_READ) {
		if ((n = imsg_read(ibuf)) == -1)
			fatal("imsg_read_error");
		if (n == 0) {
			/* this pipe is dead, so remove the event handler */
			event_del(&iev->ev);
			event_loopexit(NULL);
			return;
		}
	}

	if (event & EV_WRITE) {
		if (msgbuf_write(&ibuf->w) == -1)
			fatal("msgbuf_write");
	}

	for (;;) {
		if ((n = imsg_get(ibuf, &imsg)) == -1)
			fatal("queue_dispatch_smtp: imsg_get error");
		if (n == 0)
			break;

		switch (imsg.hdr.type) {
		case IMSG_QUEUE_CREATE_MESSAGE: {
			struct message		*messagep = imsg.data;
			struct submit_status	 ss;
			int			(*f)(char *);

			log_debug("queue_dispatch_smtp: creating message file");

			IMSG_SIZE_CHECK(messagep);

			ss.id = messagep->session_id;
d69 3
a71 4
			bzero(ss.u.msgid, MAX_ID_SIZE);

			if (messagep->flags & F_MESSAGE_ENQUEUED)
				f = enqueue_create_layout;
d73 2
a74 3
				f = queue_create_incoming_layout;

			if (! f(ss.u.msgid))
a75 1

d77 2
a78 8
			    &ss, sizeof(ss));
			break;
		}
		case IMSG_QUEUE_REMOVE_MESSAGE: {
			struct message		*messagep = imsg.data;
			void			(*f)(char *);

			IMSG_SIZE_CHECK(messagep);
d80 3
a82 2
			if (messagep->flags & F_MESSAGE_ENQUEUED)
				f = enqueue_delete_message;
d84 2
a85 3
				f = queue_delete_incoming_message;

			f(messagep->message_id);
d87 7
a93 15
			break;
		}
		case IMSG_QUEUE_COMMIT_MESSAGE: {
			struct message		*messagep = imsg.data;
			struct submit_status	 ss;
			size_t			*counter;
			int			(*f)(struct message *);

			IMSG_SIZE_CHECK(messagep);

			ss.id = messagep->session_id;

			if (messagep->flags & F_MESSAGE_ENQUEUED) {
				f = enqueue_commit_message;
				counter = &env->stats->queue.inserts_local;
d95 4
a98 2
				f = queue_commit_incoming_message;
				counter = &env->stats->queue.inserts_remote;
a99 6

			if (f(messagep))
				(*counter)++;
			else
				ss.code = 421;

d101 2
a102 13
			    &ss, sizeof(ss));

			break;
		}
		case IMSG_QUEUE_MESSAGE_FILE: {
			struct message		*messagep = imsg.data;
			struct submit_status	 ss;
			int fd;
			int			(*f)(struct message *);

			IMSG_SIZE_CHECK(messagep);

			ss.id = messagep->session_id;
d104 4
a107 2
			if (messagep->flags & F_MESSAGE_ENQUEUED)
				f = enqueue_open_messagefile;
d109 1
a109 3
				f = queue_open_incoming_message_file;

			fd = f(messagep);
a111 1

d113 1
a113 83
			    &ss, sizeof(ss));
			break;
		}
		default:
			log_warnx("queue_dispatch_smtp: got imsg %d",
			    imsg.hdr.type);
			fatalx("queue_dispatch_smtp: unexpected imsg");
		}
		imsg_free(&imsg);
	}
	imsg_event_add(iev);
}

void
queue_dispatch_mda(int sig, short event, void *p)
{
	struct smtpd		*env = p;
	struct imsgev		*iev;
	struct imsgbuf		*ibuf;
	struct imsg		 imsg;
	ssize_t			 n;

	iev = env->sc_ievs[PROC_MDA];
	ibuf = &iev->ibuf;

	if (event & EV_READ) {
		if ((n = imsg_read(ibuf)) == -1)
			fatal("imsg_read_error");
		if (n == 0) {
			/* this pipe is dead, so remove the event handler */
			event_del(&iev->ev);
			event_loopexit(NULL);
			return;
		}
	}

	if (event & EV_WRITE) {
		if (msgbuf_write(&ibuf->w) == -1)
			fatal("msgbuf_write");
	}

	for (;;) {
		if ((n = imsg_get(ibuf, &imsg)) == -1)
			fatal("queue_dispatch_mda: imsg_get error");
		if (n == 0)
			break;

		switch (imsg.hdr.type) {

		case IMSG_QUEUE_MESSAGE_UPDATE: {
			imsg_compose_event(env->sc_ievs[PROC_RUNNER], IMSG_RUNNER_UPDATE_ENVELOPE,
			    0, 0, -1, imsg.data, sizeof(struct message));
			break;
		}

		default:
			log_warnx("got imsg %d", imsg.hdr.type);
			fatalx("queue_dispatch_mda: unexpected imsg");
		}
		imsg_free(&imsg);
	}
	imsg_event_add(iev);
}

void
queue_dispatch_mta(int sig, short event, void *p)
{
	struct smtpd		*env = p;
	struct imsgev		*iev;
	struct imsgbuf		*ibuf;
	struct imsg		 imsg;
	ssize_t			 n;

	iev = env->sc_ievs[PROC_MTA];
	ibuf = &iev->ibuf;

	if (event & EV_READ) {
		if ((n = imsg_read(ibuf)) == -1)
			fatal("imsg_read_error");
		if (n == 0) {
			/* this pipe is dead, so remove the event handler */
			event_del(&iev->ev);
			event_loopexit(NULL);
d118 2
a119 62
	if (event & EV_WRITE) {
		if (msgbuf_write(&ibuf->w) == -1)
			fatal("msgbuf_write");
	}

	for (;;) {
		if ((n = imsg_get(ibuf, &imsg)) == -1)
			fatal("queue_dispatch_mta: imsg_get error");
		if (n == 0)
			break;

		switch (imsg.hdr.type) {

		case IMSG_QUEUE_MESSAGE_FD: {
			struct batch *batchp = imsg.data;
			int fd;

			IMSG_SIZE_CHECK(batchp);

			fd = queue_open_message_file(batchp->message_id);
			imsg_compose_event(iev,  IMSG_QUEUE_MESSAGE_FD, 0, 0, fd, batchp,
			    sizeof(*batchp));
			break;
		}

		case IMSG_QUEUE_MESSAGE_UPDATE: {
			imsg_compose_event(env->sc_ievs[PROC_RUNNER], IMSG_RUNNER_UPDATE_ENVELOPE,
			    0, 0, -1, imsg.data, sizeof(struct message));
			break;
		}

		default:
			log_warnx("got imsg %d", imsg.hdr.type);
			fatalx("queue_dispatch_mda: unexpected imsg");
		}
		imsg_free(&imsg);
	}
	imsg_event_add(iev);
}

void
queue_dispatch_lka(int sig, short event, void *p)
{
	struct smtpd		*env = p;
	struct imsgev		*iev;
	struct imsgbuf		*ibuf;
	struct imsg		 imsg;
	ssize_t			 n;

	iev = env->sc_ievs[PROC_LKA];
	ibuf = &iev->ibuf;

	if (event & EV_READ) {
		if ((n = imsg_read(ibuf)) == -1)
			fatal("imsg_read_error");
		if (n == 0) {
			/* this pipe is dead, so remove the event handler */
			event_del(&iev->ev);
			event_loopexit(NULL);
			return;
		}
	}
d121 4
a124 4
	if (event & EV_WRITE) {
		if (msgbuf_write(&ibuf->w) == -1)
			fatal("msgbuf_write");
	}
d126 2
a127 21
	for (;;) {
		if ((n = imsg_get(ibuf, &imsg)) == -1)
			fatal("queue_dispatch_lka: imsg_get error");
		if (n == 0)
			break;

		switch (imsg.hdr.type) {

		case IMSG_QUEUE_SUBMIT_ENVELOPE: {
			struct message		*messagep = imsg.data;
			struct submit_status	 ss;
			int (*f)(struct message *);

			IMSG_SIZE_CHECK(messagep);

			messagep->id = generate_uid();
			ss.id = messagep->session_id;

			if (IS_MAILBOX(messagep->recipient) ||
			    IS_EXT(messagep->recipient))
				messagep->type = T_MDA_MESSAGE;
d129 1
a129 1
				messagep->type = T_MTA_MESSAGE;
d132 2
a133 2
			if (messagep->flags & F_MESSAGE_ENQUEUED)
				f = enqueue_record_envelope;
d135 1
a135 1
				f = queue_record_incoming_envelope;
d137 1
a137 1
			if (! f(messagep)) {
d141 1
a141 1
				    sizeof(ss));
d143 1
d145 7
a151 1
			break;
d153 1
d155 8
a162 3
		case IMSG_QUEUE_COMMIT_ENVELOPES: {
			struct message		*messagep = imsg.data;
			struct submit_status	 ss;
d164 5
a168 9
			IMSG_SIZE_CHECK(messagep);

			ss.id = messagep->session_id;
			ss.code = 250;

			imsg_compose_event(env->sc_ievs[PROC_SMTP], IMSG_QUEUE_COMMIT_ENVELOPES,
			    0, 0, -1, &ss, sizeof(ss));

			break;
d170 1
d172 7
a178 3
		default:
			log_warnx("got imsg %d", imsg.hdr.type);
			fatalx("queue_dispatch_lka: unexpected imsg");
a179 1
		imsg_free(&imsg);
a180 2
	imsg_event_add(iev);
}
d182 5
a186 19
void
queue_dispatch_runner(int sig, short event, void *p)
{
	struct smtpd		*env = p;
	struct imsgev		*iev;
	struct imsgbuf		*ibuf;
	struct imsg		 imsg;
	ssize_t			 n;

	iev = env->sc_ievs[PROC_RUNNER];
	ibuf = &iev->ibuf;

	if (event & EV_READ) {
		if ((n = imsg_read(ibuf)) == -1)
			fatal("imsg_read_error");
		if (n == 0) {
			/* this pipe is dead, so remove the event handler */
			event_del(&iev->ev);
			event_loopexit(NULL);
d191 2
a192 4
	if (event & EV_WRITE) {
		if (msgbuf_write(&ibuf->w) == -1)
			fatal("msgbuf_write");
	}
d194 10
a203 12
	for (;;) {
		if ((n = imsg_get(ibuf, &imsg)) == -1)
			fatal("queue_dispatch_runner: imsg_get error");
		if (n == 0)
			break;

		switch (imsg.hdr.type) {
		default:
			log_warnx("got imsg %d", imsg.hdr.type);
			fatalx("queue_dispatch_runner: unexpected imsg");
		}
		imsg_free(&imsg);
a204 1
	imsg_event_add(iev);
d234 7
a240 7
		{ PROC_PARENT,	queue_dispatch_parent },
		{ PROC_CONTROL,	queue_dispatch_control },
		{ PROC_SMTP,	queue_dispatch_smtp },
		{ PROC_MDA,	queue_dispatch_mda },
		{ PROC_MTA,	queue_dispatch_mta },
		{ PROC_LKA,	queue_dispatch_lka },
		{ PROC_RUNNER,	queue_dispatch_runner }
d275 1
@


1.76
log
@Tweak the logic behind setting the fd limits so that smtpd is less likely
to get upset by custom soft/hard ulimit settings.

Suggested by todd@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.75 2009/12/14 16:44:14 jacekm Exp $	*/
d42 1
d77 53
d587 1
@


1.75
log
@Impose sessions limit on the delivery sessions (mta and mda).
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.74 2009/12/13 22:02:55 jacekm Exp $	*/
d584 2
a585 2
	 * Therefore, double the fdlimit the second time to achieve a 4x
	 * increase relative to default.
d587 1
a587 1
	fdlimit(getdtablesize() * 2);
@


1.74
log
@Use safe fd limits in smtp, lka, queue, and control.  Removes a
possibility for fd-starvation fatal when under heavy load.
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.73 2009/11/08 21:40:05 gilles Exp $	*/
d588 2
@


1.73
log
@- make aliases expansion use a rb tree instead of a tail queue, the code
  doesn't take advantage of the new structure yet, but this was a needed
  change for upcoming improvements.
- introduce aliasestree_{lookup,insert,remove} to the aliases api
- rename queue_generate_id() to generate_uid() and move it to utils.c as
  it is used all over the place and not only in queue

tree idea discussed with jacekm@@, if you update rebuild aliases db, make
clean and flush queue
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.72 2009/11/01 22:15:27 gilles Exp $	*/
d581 7
@


1.72
log
@fix a couple log_info()s,
from Tim van der Molen <tbvdm@@xs4all.nl>
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.71 2009/10/12 22:34:37 gilles Exp $	*/
d413 1
a413 1
			messagep->id = queue_generate_id();
@


1.71
log
@- fix a null deref which could happen after a couple iterations of the
  aliases/virtual domains resolution code.

- fix a logic bug which caused virtual domains not to be correctly
  handled after one iteration of the aliases resolution code.

- introduce a few helper functions to help clean up and simplify the
  lka code.

- simplify the IS_EXT/IS_MAILBOX/IS_RELAY macros so they manipulate a
  struct path * instead of the mess of dereferences we were passing them.
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.70 2009/09/15 16:50:06 jacekm Exp $	*/
d509 1
a509 1
	log_info("queue handler");
@


1.70
log
@Extend SMTP client_* API to support SSL+AUTH, and use it in the mta
process to relay mails.  ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.69 2009/09/03 08:19:13 jacekm Exp $	*/
d59 3
d416 2
a417 2
			if (IS_MAILBOX(messagep->recipient.rule.r_action) ||
			    IS_EXT(messagep->recipient.rule.r_action))
d617 16
@


1.69
log
@imsg_get sets errno so use fatal instead of fatalx.
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.68 2009/06/06 04:14:21 pyr Exp $	*/
a591 16
int
queue_remove_batch_message(struct smtpd *env, struct batch *batchp, struct message *messagep)
{
	TAILQ_REMOVE(&batchp->messages, messagep, entry);
	bzero(messagep, sizeof(struct message));
	free(messagep);

	if (TAILQ_FIRST(&batchp->messages) == NULL) {
		SPLAY_REMOVE(batchtree, &env->batch_queue, batchp);
		bzero(batchp, sizeof(struct batch));
		free(batchp);
		return 1;
	}
	return 0;
}

a600 22

struct message *
message_by_id(struct smtpd *env, struct batch *batchp, u_int64_t id)
{
	struct message *messagep;

	if (batchp != NULL) {
		TAILQ_FOREACH(messagep, &batchp->messages, entry) {
			if (messagep->id == id)
				break;
		}
		return messagep;
	}

	SPLAY_FOREACH(batchp, batchtree, &env->batch_queue) {
		TAILQ_FOREACH(messagep, &batchp->messages, entry) {
			if (messagep->id == id)
				return messagep;
		}
	}
	return NULL;
}
@


1.68
log
@Sync with relayd:
Stop pushing event handling in the imsg framework.
Instead, provide a small glue layer on top of both imsg and libevent.
This finally clearly separates event handling and imsg construction.

Sidetrack bonus: remove the mega-ugly hack of having a dummy imsg_event_add
stub in smtpctl.
ok jaceckm@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.67 2009/06/05 20:43:57 pyr Exp $	*/
d102 1
a102 1
			fatalx("queue_dispatch_control: imsg_get error");
d147 1
a147 1
			fatalx("queue_dispatch_smtp: imsg_get error");
d283 1
a283 1
			fatalx("queue_dispatch_mda: imsg_get error");
d334 1
a334 1
			fatalx("queue_dispatch_mta: imsg_get error");
d397 1
a397 1
			fatalx("queue_dispatch_lka: imsg_get error");
d489 1
a489 1
			fatalx("queue_dispatch_runner: imsg_get error");
@


1.67
log
@make smtpd's imsg lib ready, just like relayd and ospfd.
ok gilles@@, jacekm@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.66 2009/06/01 13:20:56 jacekm Exp $	*/
d76 1
d81 2
a82 1
	ibuf = env->sc_ibufs[PROC_CONTROL];
d89 1
a89 1
			event_del(&ibuf->ev);
d114 1
a114 1
	imsg_event_add(ibuf);
d121 1
d126 2
a127 1
	ibuf = env->sc_ibufs[PROC_SMTP];
d134 1
a134 1
			event_del(&ibuf->ev);
d173 1
a173 1
			imsg_compose_event(ibuf, IMSG_QUEUE_CREATE_MESSAGE, 0, 0, -1,
d215 1
a215 1
			imsg_compose_event(ibuf, IMSG_QUEUE_COMMIT_MESSAGE, 0, 0, -1,
d239 1
a239 1
			imsg_compose_event(ibuf, IMSG_QUEUE_MESSAGE_FILE, 0, 0, fd,
d250 1
a250 1
	imsg_event_add(ibuf);
d257 1
d262 2
a263 1
	ibuf = env->sc_ibufs[PROC_MDA];
d270 1
a270 1
			event_del(&ibuf->ev);
d290 1
a290 1
			imsg_compose_event(env->sc_ibufs[PROC_RUNNER], IMSG_RUNNER_UPDATE_ENVELOPE,
d301 1
a301 1
	imsg_event_add(ibuf);
d308 1
d313 2
a314 1
	ibuf = env->sc_ibufs[PROC_MTA];
d321 1
a321 1
			event_del(&ibuf->ev);
d347 1
a347 1
			imsg_compose_event(ibuf,  IMSG_QUEUE_MESSAGE_FD, 0, 0, fd, batchp,
d353 1
a353 1
			imsg_compose_event(env->sc_ibufs[PROC_RUNNER], IMSG_RUNNER_UPDATE_ENVELOPE,
d364 1
a364 1
	imsg_event_add(ibuf);
d371 1
d376 2
a377 1
	ibuf = env->sc_ibufs[PROC_LKA];
d384 1
a384 1
			event_del(&ibuf->ev);
d427 1
a427 1
				imsg_compose_event(env->sc_ibufs[PROC_SMTP],
d444 1
a444 1
			imsg_compose_event(env->sc_ibufs[PROC_SMTP], IMSG_QUEUE_COMMIT_ENVELOPES,
d456 1
a456 1
	imsg_event_add(ibuf);
d463 1
d468 2
a469 1
	ibuf = env->sc_ibufs[PROC_RUNNER];
d476 1
a476 1
			event_del(&ibuf->ev);
d500 1
a500 1
	imsg_event_add(ibuf);
@


1.66
log
@Fix EV_READ/EV_WRITE testing inside IMSG handlers. Based on similar change
to the routing daemons by claudio@@; ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.65 2009/05/24 14:38:56 jacekm Exp $	*/
d169 1
a169 1
			imsg_compose(ibuf, IMSG_QUEUE_CREATE_MESSAGE, 0, 0, -1,
d211 1
a211 1
			imsg_compose(ibuf, IMSG_QUEUE_COMMIT_MESSAGE, 0, 0, -1,
d235 1
a235 1
			imsg_compose(ibuf, IMSG_QUEUE_MESSAGE_FILE, 0, 0, fd,
d284 1
a284 1
			imsg_compose(env->sc_ibufs[PROC_RUNNER], IMSG_RUNNER_UPDATE_ENVELOPE,
d339 1
a339 1
			imsg_compose(ibuf,  IMSG_QUEUE_MESSAGE_FD, 0, 0, fd, batchp,
d345 1
a345 1
			imsg_compose(env->sc_ibufs[PROC_RUNNER], IMSG_RUNNER_UPDATE_ENVELOPE,
d417 1
a417 1
				imsg_compose(env->sc_ibufs[PROC_SMTP],
d434 1
a434 1
			imsg_compose(env->sc_ibufs[PROC_SMTP], IMSG_QUEUE_COMMIT_ENVELOPES,
@


1.65
log
@Parent process forks 3 types of processes, track them all in a single tree
using newly introduced child struct.

Manage process titles centrally in struct smtpd.

ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.64 2009/05/24 14:22:23 jacekm Exp $	*/
d81 2
a82 2
	switch (event) {
	case EV_READ:
d91 3
a93 2
		break;
	case EV_WRITE:
a95 4
		imsg_event_add(ibuf);
		return;
	default:
		fatalx("unknown event");
d124 2
a125 2
	switch (event) {
	case EV_READ:
d134 3
a136 2
		break;
	case EV_WRITE:
a138 4
		imsg_event_add(ibuf);
		return;
	default:
		fatalx("unknown event");
d258 2
a259 2
	switch (event) {
	case EV_READ:
d268 3
a270 2
		break;
	case EV_WRITE:
a272 4
		imsg_event_add(ibuf);
		return;
	default:
		fatalx("unknown event");
d307 2
a308 2
	switch (event) {
	case EV_READ:
d317 3
a319 2
		break;
	case EV_WRITE:
a321 4
		imsg_event_add(ibuf);
		return;
	default:
		fatalx("unknown event");
d368 2
a369 2
	switch (event) {
	case EV_READ:
d378 3
a380 2
		break;
	case EV_WRITE:
a382 4
		imsg_event_add(ibuf);
		return;
 	default:
		fatalx("unknown event");
d458 2
a459 2
	switch (event) {
	case EV_READ:
d468 3
a470 2
		break;
	case EV_WRITE:
a472 4
		imsg_event_add(ibuf);
		return;
	default:
		fatalx("unknown event");
@


1.64
log
@Instead of keeping stats private to each process, and querying every
process individually whenever stats need to be fetched, keep stats
in MAP_ANON shared memory allocated by parent.

This means control has direct access to stats and can respond very
quickly without troubling any other daemon processes.

ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.63 2009/05/19 11:24:24 jacekm Exp $	*/
a565 1
	setproctitle("queue handler");
d567 1
@


1.63
log
@Verify the amount of IMSG payload is exactly as expected; ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.62 2009/05/14 15:05:12 eric Exp $	*/
a58 2
struct s_queue	s_queue;

a107 9
		case IMSG_STATS: {
			struct stats *s = imsg.data;

			IMSG_SIZE_CHECK(s);

			s->u.queue = s_queue;
			imsg_compose(ibuf, IMSG_STATS, 0, 0, -1, s, sizeof(*s));
			break;
		}
d206 1
a206 1
				counter = &s_queue.inserts_local;
d209 1
a209 1
				counter = &s_queue.inserts_remote;
@


1.62
log
@use the nitems() macro where appropriate

ok gilles@@, jacekm@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.61 2009/04/21 14:37:32 eric Exp $	*/
d111 3
a113 1
			struct stats *s;
a114 1
			s = imsg.data;
d166 1
a166 1
			struct message		*messagep;
d171 3
a173 1
			messagep = imsg.data;
d191 1
a191 1
			struct message		*messagep;
d194 2
a195 1
			messagep = imsg.data;
d206 1
a206 1
			struct message		*messagep;
d211 2
a212 1
			messagep = imsg.data;
d234 1
a234 1
			struct message		*messagep;
d239 2
a240 1
			messagep = imsg.data;
d356 1
a357 1
			struct batch *batchp;
d359 2
a360 1
			batchp = imsg.data;
d420 1
a420 1
			struct message		*messagep;
d424 2
a425 1
			messagep = imsg.data;
d452 1
a452 1
			struct message		*messagep;
d455 2
a456 1
			messagep = imsg.data;
@


1.61
log
@correct some fatal(x) calls and error strings

ok gilles@@ jacekm@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.60 2009/04/18 21:01:20 jacekm Exp $	*/
d587 2
a588 2
	config_pipes(env, peers, 6);
	config_peers(env, peers, 6);
@


1.60
log
@remove dead code; made possible by previous commit.
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.59 2009/04/16 15:35:06 jacekm Exp $	*/
d105 1
a105 1
			fatal("queue_dispatch_control: imsg_read error");
d159 1
a159 1
			fatal("queue_dispatch_smtp: imsg_read error");
d291 1
a291 1
			fatal("queue_dispatch_mda: imsg_read error");
d343 1
a343 1
			fatal("queue_dispatch_mda: imsg_read error");
d406 1
a406 1
			fatal("queue_dispatch_lka: imsg_read error");
d497 1
a497 1
			fatal("queue_dispatch_runner: imsg_read error");
@


1.59
log
@Total rewrite of the sendmail interface. Adds support for -t, -v,
and -F cmdline args. Also, date and Message-Id headers are added
when missing.

The main trouble with the current enqueue code is that it requires
dealing with problems in the control process that are already solved
in the smtp process, ie. duplicating a lot of code which interacts
with untrusted clients. This diff solves this by making sendmail
obtain a SMTP socket from smtp via smtpd.sock, and using that socket
to deliver the message. For smtpd it looks as if connection was
made from the network, only difference being the F_MESSAGE_ENQUEUED
message flag, handy when differentation between local and remote
deliveries is wanted.

Most of the features come from the femail program, created by henning@@.

Additional testing by Nigel J. Taylor.

ok gilles@@, henning@@ happy with smtpd using femail code
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.58 2009/03/29 14:18:20 jacekm Exp $	*/
a109 55
		case IMSG_QUEUE_CREATE_MESSAGE: {
			struct message		*messagep;
			struct submit_status	 ss;

			log_debug("queue_dispatch_control: creating message file");
			messagep = imsg.data;

			ss.id = messagep->session_id;
			ss.code = 250;
			bzero(ss.u.msgid, MAX_ID_SIZE);

			if (! enqueue_create_layout(ss.u.msgid))
				ss.code = 421;

			imsg_compose(ibuf, IMSG_QUEUE_CREATE_MESSAGE, 0, 0, -1,
			    &ss, sizeof(ss));

			break;
		}
		case IMSG_QUEUE_MESSAGE_FILE: {
			int fd;
			struct submit_status ss;
			struct message *messagep;

			messagep = imsg.data;
			ss.msg = *messagep;
			ss.id = messagep->session_id;
			ss.code = 250;
			fd = enqueue_open_messagefile(messagep);
			if (fd == -1) 
				ss.code = 421;

			imsg_compose(ibuf, IMSG_QUEUE_MESSAGE_FILE, 0, 0, fd, &ss,
			    sizeof(ss));

			break;
		}
		case IMSG_QUEUE_COMMIT_MESSAGE: {
			struct message		*messagep;
			struct submit_status	 ss;

			messagep = imsg.data;
			ss.id = messagep->session_id;

			ss.code = 250;
			if (enqueue_commit_message(messagep))
				s_queue.inserts_local++;
			else
				ss.code = 421;

			imsg_compose(ibuf, IMSG_QUEUE_COMMIT_MESSAGE, 0, 0, -1,
			    &ss, sizeof(ss));

			break;
		}
a415 1
			enum smtp_proc_type peer;
d428 1
a428 1
			if (messagep->flags & F_MESSAGE_ENQUEUED) {
d430 1
a430 3
				peer = PROC_CONTROL;
			}
			else {
a431 2
				peer = PROC_SMTP;
			}
d435 3
a437 2
				imsg_compose(env->sc_ibufs[peer], IMSG_QUEUE_TEMPFAIL,
				    0, 0, -1, &ss, sizeof(ss));
@


1.58
log
@turn some log_debugs into log_warns or even fatals; "looks ok" gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.57 2009/03/01 12:12:58 jacekm Exp $	*/
d222 1
d230 6
a235 1
			if (! queue_create_incoming_layout(ss.u.msgid))
d244 1
d247 7
a253 1
			queue_delete_incoming_message(messagep->message_id);
d259 2
d265 10
a274 2
			if (queue_commit_incoming_message(messagep))
				s_queue.inserts_remote++;
d287 1
d292 6
a297 1
			fd = queue_open_incoming_message_file(messagep);
a504 1
			enum smtp_proc_type	 peer;
d510 1
a510 6
			if (messagep->flags & F_MESSAGE_ENQUEUED)
				peer = PROC_CONTROL;
			else
				peer = PROC_SMTP;

			imsg_compose(env->sc_ibufs[peer], IMSG_QUEUE_COMMIT_ENVELOPES,
@


1.57
log
@In "smtpctl show stats", break queue.inserts into queue.inserts.remote
and queue.inserts.local; ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.56 2009/02/22 19:07:33 chl Exp $	*/
d114 1
a114 1
			log_debug("mfa_dispatch_control: creating message file");
d174 1
a174 1
			log_debug("queue_dispatch_control: unexpected imsg %d",
d176 1
a176 1
			break;
d223 1
a223 1
			log_debug("mfa_dispatch_smtp: creating message file");
d277 1
a277 1
			log_debug("queue_dispatch_smtp: unexpected imsg %d",
d279 1
a279 1
			break;
d330 2
a331 3
			log_debug("queue_dispatch_mda: unexpected imsg %d",
			    imsg.hdr.type);
			break;
d393 2
a394 3
			log_debug("queue_dispatch_mda: unexpected imsg %d",
			    imsg.hdr.type);
			break;
d494 2
a495 3
			log_debug("queue_dispatch_lka: unexpected imsg %d",
			    imsg.hdr.type);
			break;
d539 2
a540 3
			log_debug("queue_dispatch_runner: unexpected imsg %d",
			    imsg.hdr.type);
			break;
@


1.56
log
@add missing headers

ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.55 2009/02/20 18:47:53 jacekm Exp $	*/
d155 3
a157 1
			if (! enqueue_commit_message(messagep))
d250 3
a252 3
			s_queue.inserts++;

			if (! queue_commit_incoming_message(messagep))
@


1.55
log
@purge /enqueue at startup; ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.54 2009/02/15 10:32:23 jacekm Exp $	*/
d32 1
@


1.54
log
@New config.c that allows for process cloning. Done by pyr@@ for
relayd at n2k9, and adapted to smtpd; ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.53 2009/01/29 21:59:15 jacekm Exp $	*/
d49 1
a49 1
void		queue_purge_incoming(void);
d627 3
a630 1
	queue_purge_incoming();
d686 1
a686 1
queue_purge_incoming(void)
d691 1
a691 1
	q = qwalk_new(PATH_INCOMING);
d694 1
a694 1
		queue_delete_incoming_message(basename(path));
@


1.53
log
@Implement "smtpctl show stats"; ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.52 2009/01/29 12:43:25 jacekm Exp $	*/
d624 1
@


1.52
log
@Common queue walking code for smtpd and smtpctl. Kills majority of showqueue.c,
the remaining code was moved to queue_shared.c; ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.51 2009/01/28 17:29:11 jacekm Exp $	*/
d58 2
d162 8
d246 2
@


1.51
log
@Make races between queue and runner impossible by implementing the policy:
1) queue never reads /queue.
2) queue writes to /queue only at message injection time.
3) runner does all reading, and all writing apart from 2).

ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.50 2009/01/28 12:58:17 gilles Exp $	*/
a26 1
#include <dirent.h>
d30 1
d673 2
a674 2
	DIR		*dirp;
	struct dirent	*dp;
d676 1
a676 3
	dirp = opendir(PATH_INCOMING);
	if (dirp == NULL)
		fatal("queue_purge_incoming: opendir");
d678 2
a679 7
	while ((dp = readdir(dirp)) != NULL) {
		if (strcmp(dp->d_name, ".") == 0 ||
		    strcmp(dp->d_name, "..") == 0) {
			continue;
		}
		queue_delete_incoming_message(dp->d_name);
	}
d681 1
a681 1
	closedir(dirp);
a682 1

@


1.50
log
@move some functions from queue.c to queue_shared.c as they are not only
used by queue process but also by runner, while at it change the prototype
of queue_open_message_file() so it takes the message id and not a batch,
runner process requires the decriptor before it even starts building a
batch.
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.49 2009/01/28 11:27:57 gilles Exp $	*/
d309 2
a310 1
			queue_message_update(imsg.data);
d373 2
a374 1
			queue_message_update(imsg.data);
@


1.49
log
@add a struct path to struct message so that we can keep track of the RCPT
provided recipient even after aliases/forwards expansion, we'll need this
for loop detection.

message id and uid being MAXPATHLEN long is a waste, define MAX_ID_SIZE
which is currently set to 64 (but can probably be further reduced) and
make sure that structures and the few strlcpy's use the right define.

original idea by jacekm@@ a while ago
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.48 2009/01/27 22:48:29 gilles Exp $	*/
a50 3
void		queue_message_update(struct message *);


a57 3
int		queue_open_message_file(struct batch *);
void		queue_delete_message(char *);

d365 1
a365 1
			fd = queue_open_message_file(batchp);
a619 17
u_int64_t
queue_generate_id(void)
{
	u_int64_t	id;
	struct timeval	tp;

	if (gettimeofday(&tp, NULL) == -1)
		fatal("queue_generate_id: time");

	id = (u_int32_t)tp.tv_sec;
	id <<= 32;
	id |= (u_int32_t)tp.tv_usec;
	usleep(1);

	return (id);
}

a688 195
int
queue_remove_envelope(struct message *messagep)
{
	char pathname[MAXPATHLEN];
	u_int16_t hval;

	hval = queue_hash(messagep->message_id);

	if (! bsnprintf(pathname, MAXPATHLEN, "%s/%d/%s%s/%s", PATH_QUEUE,
		hval, messagep->message_id, PATH_ENVELOPES,
		messagep->message_uid))
		fatal("queue_remove_envelope: snprintf");

	if (unlink(pathname) == -1)
		fatal("queue_remove_envelope: unlink");

	if (! bsnprintf(pathname, MAXPATHLEN, "%s/%d/%s%s", PATH_QUEUE,
		hval, messagep->message_id, PATH_ENVELOPES))
		fatal("queue_remove_envelope: snprintf");

	if (rmdir(pathname) != -1)
		queue_delete_message(messagep->message_id);

	return 1;
}

int
queue_update_envelope(struct message *messagep)
{
	char temp[MAXPATHLEN];
	char dest[MAXPATHLEN];
	FILE *fp;

	if (! bsnprintf(temp, MAXPATHLEN, "%s/envelope.tmp", PATH_INCOMING))
		fatalx("queue_update_envelope");

	if (! bsnprintf(dest, MAXPATHLEN, "%s/%d/%s%s/%s", PATH_QUEUE,
		queue_hash(messagep->message_id), messagep->message_id,
		PATH_ENVELOPES, messagep->message_uid))
		fatal("queue_update_envelope: snprintf");

	fp = fopen(temp, "w");
	if (fp == NULL) {
		if (errno == ENOSPC || errno == ENFILE)
			goto tempfail;
		fatal("queue_update_envelope: open");
	}
	if (fwrite(messagep, sizeof(struct message), 1, fp) != 1) {
		if (errno == ENOSPC)
			goto tempfail;
		fatal("queue_update_envelope: fwrite");
	}
	if (! safe_fclose(fp))
		goto tempfail;

	if (rename(temp, dest) == -1) {
		if (errno == ENOSPC)
			goto tempfail;
		fatal("queue_update_envelope: rename");
	}

	return 1;

tempfail:
	if (unlink(temp) == -1)
		if (errno != ENOENT)
			fatal("queue_update_envelope: unlink");
	if (fp)
		fclose(fp);

	return 0;
}

int
queue_load_envelope(struct message *messagep, char *evpid)
{
	char pathname[MAXPATHLEN];
	char msgid[MAX_ID_SIZE];
	FILE *fp;

	if (strlcpy(msgid, evpid, MAX_ID_SIZE) >= MAX_ID_SIZE)
		fatalx("queue_load_envelope: truncation");
	*strrchr(msgid, '.') = '\0';

	if (! bsnprintf(pathname, MAXPATHLEN, "%s/%d/%s%s/%s", PATH_QUEUE,
		queue_hash(msgid), msgid, PATH_ENVELOPES, evpid))
		fatalx("queue_load_envelope: snprintf");

	fp = fopen(pathname, "r");
	if (fp == NULL) {
		if (errno == ENOENT)
			return 0;
		if (errno == ENOSPC || errno == ENFILE)
			return 0;
		fatal("queue_load_envelope: fopen");
	}
	if (fread(messagep, sizeof(struct message), 1, fp) != 1)
		fatal("queue_load_envelope: fread");
	fclose(fp);

	return 1;
}

int
queue_open_message_file(struct batch *batchp)
{
	int fd;
	char pathname[MAXPATHLEN];
	mode_t mode = O_RDONLY;
	u_int16_t hval;

	hval = queue_hash(batchp->message_id);

	if (! bsnprintf(pathname, MAXPATHLEN, "%s/%d/%s/message", PATH_QUEUE,
		hval, batchp->message_id))
		fatal("queue_open_message_file: snprintf");

	if ((fd = open(pathname, mode)) == -1)
		fatal("queue_open_message_file: open");

	return fd;
}

void
queue_delete_message(char *msgid)
{
	char rootdir[MAXPATHLEN];
	char evpdir[MAXPATHLEN];
	char msgpath[MAXPATHLEN];
	u_int16_t hval;

	hval = queue_hash(msgid);
	if (! bsnprintf(rootdir, MAXPATHLEN, "%s/%d/%s", PATH_QUEUE,
		hval, msgid))
		fatal("queue_delete_message: snprintf");

	if (! bsnprintf(evpdir, MAXPATHLEN, "%s%s",
		rootdir, PATH_ENVELOPES))
		fatal("queue_delete_message: snprintf");
	
	if (! bsnprintf(msgpath, MAXPATHLEN, "%s/message", rootdir))
		fatal("queue_delete_message: snprintf");

	if (unlink(msgpath) == -1)
		if (errno != ENOENT)
			fatal("queue_delete_message: unlink");

	if (rmdir(evpdir) == -1)
		if (errno != ENOENT)
			fatal("queue_delete_message: rmdir");

	if (rmdir(rootdir) == -1)
		if (errno != ENOENT)
			fatal("queue_delete_message: rmdir");

	if (! bsnprintf(rootdir, MAXPATHLEN, "%s/%d", PATH_QUEUE,
		hval))
		fatal("queue_delete_message: snprintf");

	rmdir(rootdir);

	return;
}

void
queue_message_update(struct message *messagep)
{
	messagep->flags &= ~F_MESSAGE_PROCESSING;
	messagep->batch_id = 0;
	messagep->retry++;

	if (messagep->status & S_MESSAGE_PERMFAILURE) {
		if (messagep->type & T_DAEMON_MESSAGE)
			queue_remove_envelope(messagep);
		else {
			messagep->id = queue_generate_id();
			messagep->type |= T_DAEMON_MESSAGE;
			messagep->status &= ~S_MESSAGE_PERMFAILURE;
			messagep->lasttry = 0;
			messagep->retry = 0;
			messagep->creation = time(NULL);
			queue_update_envelope(messagep);
		}
		return;
	}

	if (messagep->status & S_MESSAGE_TEMPFAILURE) {
		messagep->status &= ~S_MESSAGE_TEMPFAILURE;
		queue_update_envelope(messagep);
		return;
	}

	/* no error, remove envelope */
	queue_remove_envelope(messagep);
}
@


1.48
log
@first bricks of enqueue code which allows smtpctl to submit mail to queue
without "talking" smtp to listeners. currently, a big part of the server
side code is done (and requires a cleanup), next step is to get it usable
properly from a mail user agent.
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.47 2009/01/26 22:20:31 gilles Exp $	*/
d122 1
a122 1
			bzero(ss.u.msgid, MAXPATHLEN);
d220 1
a220 1
			bzero(ss.u.msgid, MAXPATHLEN);
d789 1
a789 1
	char msgid[MAXPATHLEN];
d792 1
a792 1
	if (strlcpy(msgid, evpid, MAXPATHLEN) >= MAXPATHLEN)
@


1.47
log
@move some queue related functions that are needed outside of smtpd to the
sharedqueue.c file, smtpctl cannot link queue.o without creating a mess
otherwise. while at it, move some prototypes to smtpd.h as they will be
needed by enqueue code
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.46 2009/01/26 21:26:07 gilles Exp $	*/
a50 6
int		queue_create_incoming_layout(char *);
void		queue_delete_incoming_message(char *);
int		queue_record_incoming_envelope(struct message *);
int		queue_remove_incoming_envelope(struct message *);
int		queue_commit_incoming_message(struct message *);
int		queue_open_incoming_message_file(struct message *);
d113 53
d417 1
a417 1
	default:
d432 2
d446 10
a455 1
			if (! queue_record_incoming_envelope(messagep)) {
d457 1
a457 1
				imsg_compose(env->sc_ibufs[PROC_SMTP], IMSG_QUEUE_TEMPFAIL,
a458 1
				break;
d467 1
d473 6
a478 1
			imsg_compose(env->sc_ibufs[PROC_SMTP], IMSG_QUEUE_COMMIT_ENVELOPES,
d480 1
a655 1

a709 36
}

int
queue_create_incoming_layout(char *msgid)
{
	return queue_create_layout_message(PATH_INCOMING, msgid);
}

void
queue_delete_incoming_message(char *msgid)
{
	queue_delete_layout_message(PATH_INCOMING, msgid);
}

int
queue_record_incoming_envelope(struct message *message)
{
	return queue_record_layout_envelope(PATH_INCOMING, message);
}

int
queue_remove_incoming_envelope(struct message *message)
{
	return queue_remove_layout_envelope(PATH_INCOMING, message);
}

int
queue_commit_incoming_message(struct message *message)
{
	return queue_commit_layout_message(PATH_INCOMING, message);
}

int
queue_open_incoming_message_file(struct message *message)
{
	return queue_open_layout_messagefile(PATH_INCOMING, message);
@


1.46
log
@we had a set of functions to deal specifically with incoming messages and
we need the same functions for the enqueue code i'm currently working on.
instead of duplicating the code, add a set of functions which take the
queue we're working on as a parameter and turn the old ones into wrappers.
no functionnal change ... yet

discussed with jacekm@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.45 2009/01/12 19:54:37 jacekm Exp $	*/
a648 168

int
queue_create_layout_message(char *queuepath, char *message_id)
{
	char rootdir[MAXPATHLEN];
	char evpdir[MAXPATHLEN];

	if (! bsnprintf(rootdir, MAXPATHLEN, "%s/%d.XXXXXXXXXXXXXXXX",
		queuepath, time(NULL)))
		fatalx("queue_create_message_layout: snprintf");

	if (mkdtemp(rootdir) == NULL) {
		if (errno == ENOSPC)
			return 0;
		fatal("queue_create_message_layout: mkdtemp");
	}

	if (strlcpy(message_id, rootdir + strlen(queuepath) + 1, MAXPATHLEN)
	    >= MAXPATHLEN)
		fatalx("queue_create_message_layout: truncation");
	
	if (! bsnprintf(evpdir, MAXPATHLEN, "%s%s", rootdir, PATH_ENVELOPES))
		fatalx("queue_create_message_layout: snprintf");

	if (mkdir(evpdir, 0700) == -1) {
		if (errno == ENOSPC) {
			rmdir(rootdir);
			return 0;
		}
		fatal("queue_create_message_layout: mkdir");
	}

	return 1;
}

void
queue_delete_layout_message(char *queuepath, char *msgid)
{
	char rootdir[MAXPATHLEN];
	char purgedir[MAXPATHLEN];

	if (! bsnprintf(rootdir, MAXPATHLEN, "%s/%s", queuepath, msgid))
		fatalx("snprintf");

	if (! bsnprintf(purgedir, MAXPATHLEN, "%s/%s", PATH_PURGE, msgid))
		fatalx("snprintf");

	if (rename(rootdir, purgedir) == -1) {
		if (errno == ENOENT)
			return;
		fatal("queue_delete_incoming_message: rename");
	}
}

int
queue_record_layout_envelope(char *queuepath, struct message *message)
{
	char evpname[MAXPATHLEN];
	FILE *fp;
	int fd;

again:
	if (! bsnprintf(evpname, MAXPATHLEN, "%s/%s%s/%s.%qu", queuepath,
		message->message_id, PATH_ENVELOPES, message->message_id,
		(u_int64_t)arc4random()))
		fatalx("queue_record_incoming_envelope: snprintf");

	fd = open(evpname, O_WRONLY|O_CREAT|O_EXCL, 0600);
	if (fd == -1) {
		if (errno == EEXIST)
			goto again;
		if (errno == ENOSPC || errno == ENFILE)
			goto tempfail;
		fatal("queue_record_incoming_envelope: open");
	}

	fp = fdopen(fd, "w");
	if (fp == NULL)
		fatal("queue_record_incoming_envelope: fdopen");

	message->creation = time(NULL);
	if (strlcpy(message->message_uid, strrchr(evpname, '/') + 1, MAXPATHLEN)
	    >= MAXPATHLEN)
		fatalx("queue_record_incoming_envelope: truncation");

	if (fwrite(message, sizeof (struct message), 1, fp) != 1) {
		if (errno == ENOSPC)
			goto tempfail;
		fatal("queue_record_incoming_envelope: write");
	}

	if (! safe_fclose(fp))
		goto tempfail;

	return 1;

tempfail:
	unlink(evpname);
	close(fd);
	message->creation = 0;
	message->message_uid[0] = '\0';

	return 0;
}

int
queue_remove_layout_envelope(char *queuepath, struct message *message)
{
	char pathname[MAXPATHLEN];

	if (! bsnprintf(pathname, MAXPATHLEN, "%s/%s%s/%s", queuepath,
		message->message_id, PATH_ENVELOPES, message->message_uid))
		fatal("queue_remove_incoming_envelope: snprintf");

	if (unlink(pathname) == -1)
		if (errno != ENOENT)
			fatal("queue_remove_incoming_envelope: unlink");

	return 1;
}

int
queue_commit_layout_message(char *queuepath, struct message *messagep)
{
	char rootdir[MAXPATHLEN];
	char queuedir[MAXPATHLEN];
	
	if (! bsnprintf(rootdir, MAXPATHLEN, "%s/%s", queuepath,
		messagep->message_id))
		fatal("queue_commit_message_incoming: snprintf");

	if (! bsnprintf(queuedir, MAXPATHLEN, "%s/%d", PATH_QUEUE,
		queue_hash(messagep->message_id)))
		fatal("queue_commit_message_incoming: snprintf");

	if (mkdir(queuedir, 0700) == -1) {
		if (errno == ENOSPC)
			return 0;
		if (errno != EEXIST)
			fatal("queue_commit_message_incoming: mkdir");
	}

	if (strlcat(queuedir, "/", MAXPATHLEN) >= MAXPATHLEN ||
	    strlcat(queuedir, messagep->message_id, MAXPATHLEN) >= MAXPATHLEN)
		fatalx("queue_commit_incoming_message: truncation");

	if (rename(rootdir, queuedir) == -1) {
		if (errno == ENOSPC)
			return 0;
		fatal("queue_commit_message_incoming: rename");
	}

	return 1;
}

int
queue_open_layout_messagefile(char *queuepath, struct message *messagep)
{
	char pathname[MAXPATHLEN];
	mode_t mode = O_CREAT|O_EXCL|O_RDWR;
	
	if (! bsnprintf(pathname, MAXPATHLEN, "%s/%s/message", queuepath,
		messagep->message_id))
		fatal("queue_open_incoming_message_file: snprintf");

	return open(pathname, mode, 0600);
}

a878 11
}

u_int16_t
queue_hash(char *msgid)
{
	u_int16_t	h;

	for (h = 5381; *msgid; msgid++)
		h = ((h << 5) + h) + *msgid;

	return (h % DIRHASH_BUCKETS);
@


1.45
log
@more checks in queue_record_incoming_envelope; ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.44 2009/01/06 20:17:23 jacekm Exp $	*/
d59 8
d649 1
d651 1
a651 1
queue_create_incoming_layout(char *message_id)
d657 2
a658 2
		PATH_INCOMING, time(NULL)))
		fatalx("queue_create_incoming_layout: snprintf");
d663 1
a663 1
		fatal("queue_create_incoming_layout: mkdtemp");
d666 1
a666 1
	if (strlcpy(message_id, rootdir + strlen(PATH_INCOMING) + 1, MAXPATHLEN)
d668 1
a668 1
		fatalx("queue_create_incoming_layout: truncation");
d671 1
a671 1
		fatalx("queue_create_incoming_layout: snprintf");
d678 1
a678 1
		fatal("queue_create_incoming_layout: mkdir");
d685 1
a685 1
queue_delete_incoming_message(char *msgid)
d690 1
a690 1
	if (! bsnprintf(rootdir, MAXPATHLEN, "%s/%s", PATH_INCOMING, msgid))
d704 1
a704 1
queue_record_incoming_envelope(struct message *message)
d711 1
a711 1
	if (! bsnprintf(evpname, MAXPATHLEN, "%s/%s%s/%s.%qu", PATH_INCOMING,
d755 1
a755 1
queue_remove_incoming_envelope(struct message *message)
d759 1
a759 1
	if (! bsnprintf(pathname, MAXPATHLEN, "%s/%s%s/%s", PATH_INCOMING,
d771 1
a771 1
queue_commit_incoming_message(struct message *messagep)
d776 1
a776 1
	if (! bsnprintf(rootdir, MAXPATHLEN, "%s/%s", PATH_INCOMING,
d805 1
a805 1
queue_open_incoming_message_file(struct message *messagep)
d810 1
a810 1
	if (! bsnprintf(pathname, MAXPATHLEN, "%s/%s/message", PATH_INCOMING,
d815 36
@


1.44
log
@make file update in queue_update_envelope atomic; ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.43 2009/01/04 00:58:59 gilles Exp $	*/
a696 1
	char evpdir[MAXPATHLEN];
d698 1
a698 1
	char message_uid[MAXPATHLEN];
a699 3
	int mode = O_CREAT|O_WRONLY|O_EXCL|O_SYNC;
	FILE *fp;
	int ret;
d701 23
a723 3
	if (! bsnprintf(evpdir, MAXPATHLEN, "%s/%s%s", PATH_INCOMING,
		message->message_id, PATH_ENVELOPES))
		fatal("queue_record_incoming_envelope: snprintf");
d725 5
a729 13
	for (;;) {
		if (! bsnprintf(evpname, MAXPATHLEN, "%s/%s.%qu", evpdir,
			message->message_id, (u_int64_t)arc4random()))
			fatal("queue_record_incoming_envelope: snprintf");

		(void)strlcpy(message_uid, evpname + strlen(evpdir) + 1, MAXPATHLEN);

		fd = open(evpname, mode, 0600);
		if (fd == -1) {
			if (errno == EEXIST)
				continue;
			return 0;
		}
d731 2
a732 18
		fp = fdopen(fd, "w");
		if (fp == NULL)
			fatal("fdopen");

		if (strlcpy(message->message_uid, message_uid, MAXPATHLEN)
		    >= MAXPATHLEN)
			fatal("queue_record_incoming_envelope: strlcpy");

		message->creation = time(NULL);

		if ((ret = fwrite(message, sizeof (struct message), 1, fp)) != 1) {
			fclose(fp);
			unlink(evpname);
			return 0;
		}
		fflush(fp);
		fsync(fd);
		fclose(fp);
a733 2
		break;
	}
d735 8
@


1.43
log
@aliases/forwards expansion was not done correctly and a race could
cause delivery to happen before expansion is over, causing some of
the recipients to never receive the mail. change how the mfa, lka,
queue and smtp processes communicate to ensure smtp never receives
an acknowledgment before ALL expanded envelopes are on disk. While
at it, lka was doing work which belongs in mfa, fix that also.

this is based on an idea from a talk with jacekm@@, change not over
but already better than what we had.
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.42 2009/01/02 22:08:02 jacekm Exp $	*/
d839 2
a840 1
	char pathname[MAXPATHLEN];
d843 4
a846 1
	if (! bsnprintf(pathname, MAXPATHLEN, "%s/%d/%s%s/%s", PATH_QUEUE,
d851 4
a854 2
	fp = fopen(pathname, "w");
	if (fp == NULL)
d856 1
a856 3
	if (flock(fileno(fp), LOCK_EX) == -1)
		fatal("queue_update_envelope: flock");

d859 1
a859 1
			return 0;
d862 19
a880 1
	return safe_fclose(fp);
@


1.42
log
@fix T_DAEMON_MESSAGE notices delivery; ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.41 2009/01/02 19:52:53 jacekm Exp $	*/
a180 49
		case IMSG_QUEUE_SUBMIT_ENVELOPE: {
			struct message		*messagep;
			struct submit_status	 ss;

			messagep = imsg.data;
			messagep->id = queue_generate_id();
			ss.id = messagep->session_id;
			ss.code = 250;
			ss.u.path = messagep->recipient;

			if (IS_MAILBOX(messagep->recipient.rule.r_action) ||
			    IS_EXT(messagep->recipient.rule.r_action))
				messagep->type = T_MDA_MESSAGE;
			else
				messagep->type = T_MTA_MESSAGE;

			/* Write to disk */
			if (! queue_record_incoming_envelope(messagep)) {
				ss.code = 421;
				imsg_compose(ibuf, IMSG_QUEUE_SUBMIT_ENVELOPE,
				    0, 0, -1, &ss, sizeof(ss));
				break;
			}

			imsg_compose(ibuf, IMSG_QUEUE_SUBMIT_ENVELOPE, 0, 0, -1,
			    &ss, sizeof(ss));

			if (messagep->type & T_MTA_MESSAGE) {
				break;
			}

			if ((messagep->recipient.flags & (F_ALIAS|F_VIRTUAL)) == 0) {
				/* not an alias, perform ~/.forward resolution */
				imsg_compose(env->sc_ibufs[PROC_LKA],
				    IMSG_LKA_FORWARD, 0, 0, -1, messagep,
				    sizeof(struct message));
				break;
			}

			/* Recipient is an alias, proceed to resolving it.
			 * ~/.forward will be handled by the IMSG_LKA_ALIAS
			 * dispatch case.
			 */
			imsg_compose(env->sc_ibufs[PROC_LKA],
			    IMSG_LKA_ALIAS, 0, 0, -1, messagep,
			    sizeof (struct message));

			break;
		}
d374 3
a376 2
		case IMSG_LKA_ALIAS: {
			struct message *messagep;
d380 1
a380 2
			messagep->batch_id = 0;
			queue_record_incoming_envelope(messagep);
d382 12
a393 3
			if (messagep->type & T_MDA_MESSAGE) {
				imsg_compose(ibuf, IMSG_LKA_FORWARD, 0, 0, -1,
				    messagep, sizeof(struct message));
d395 1
d399 3
a401 2
		case IMSG_LKA_FORWARD: {
			struct message *messagep;
d403 3
a405 9
			messagep = (struct message *)imsg.data;
			messagep->id = queue_generate_id();
			messagep->batch_id = 0;
			queue_record_incoming_envelope(messagep);
			break;
		}

		case IMSG_QUEUE_REMOVE_SUBMISSION: {
			struct message *messagep;
d407 2
a408 2
			messagep = (struct message *)imsg.data;
			queue_remove_incoming_envelope(messagep);
d852 1
@


1.41
log
@cleanup queue_load_envelope; ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.40 2009/01/01 16:15:47 jacekm Exp $	*/
d998 1
a1018 1
		messagep->flags &= ~F_MESSAGE_PROCESSING;
@


1.40
log
@remove unnecessary includes; ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.39 2008/12/31 09:55:24 jacekm Exp $	*/
d908 1
a908 1
	u_int16_t hval;
a909 1
	char msgid[MAXPATHLEN];
d911 2
a912 1
	strlcpy(msgid, evpid, MAXPATHLEN);
a914 1
	hval = queue_hash(msgid);
d916 2
a917 2
		hval, msgid, PATH_ENVELOPES, evpid))
		return 0;
d920 7
a926 3
	if (fp == NULL)
		return 0;

a928 1

@


1.39
log
@if mkdir/mkdtemp fails, fatal if errno != ENOSPC; ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.38 2008/12/31 09:50:40 jacekm Exp $	*/
a25 4
#include <sys/time.h>

#include <netinet/in.h>
#include <arpa/inet.h>
a30 1
#include <netdb.h>
a31 1
#include <signal.h>
a34 1
#include <time.h>
@


1.38
log
@rename may fail due to ENOSPC, make smtpd survive this condition; ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.37 2008/12/31 09:47:11 jacekm Exp $	*/
d702 5
a706 2
	if (mkdtemp(rootdir) == NULL)
		return 0;
d710 1
a710 1
		goto badroot;
d712 2
a713 3
	if (! bsnprintf(evpdir, MAXPATHLEN, "%s%s",
		rootdir, PATH_ENVELOPES))
		goto badroot;
d715 7
a721 2
	if (mkdir(evpdir, 0700) == -1)
		goto badroot;
a723 6

badroot:
	if (rmdir(rootdir) == -1)
		fatal("queue_create_incoming_layout: rmdir");

	return 0;
@


1.37
log
@kill unnecessary function; ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.36 2008/12/29 09:03:25 jacekm Exp $	*/
a817 1
	u_int16_t hval;
d823 2
a824 3
	hval = queue_hash(messagep->message_id);

	if (! bsnprintf(queuedir, MAXPATHLEN, "%s/%d", PATH_QUEUE, hval))
d834 3
a836 4
	if (! bsnprintf(queuedir, MAXPATHLEN, "%s/%d/%s", PATH_QUEUE, hval,
		messagep->message_id))
		fatal("queue_commit_message_incoming: snprintf");
	
d838 3
a840 1
	if (rename(rootdir, queuedir) == -1)
d842 1
@


1.36
log
@Handle ENOSPC in queue_update_envelope; cleanup the code a bit; ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.35 2008/12/27 18:18:33 jacekm Exp $	*/
a65 1
int		queue_record_envelope(struct message *);
a860 69
queue_record_envelope(struct message *messagep)
{
	char queuedir[MAXPATHLEN];
	char evpdir[MAXPATHLEN];
	char evpname[MAXPATHLEN];
	char message_uid[MAXPATHLEN];
	int fd;
	int mode = O_CREAT|O_WRONLY|O_EXCL|O_SYNC;
	FILE *fp;
	int ret;
	u_int16_t hval;

	if (! bsnprintf(queuedir, MAXPATHLEN, "%s/%s", PATH_QUEUE,
		messagep->message_id))
		fatal("queue_record_envelope: snprintf");

	hval = queue_hash(messagep->message_id);

	if (! bsnprintf(queuedir, MAXPATHLEN, "%s/%d", PATH_QUEUE, hval))
		fatal("queue_record_envelope: snprintf");

	if (! bsnprintf(evpdir, MAXPATHLEN, "%s/%s%s", queuedir,
		messagep->message_id, PATH_ENVELOPES))
		fatal("queue_record_envelope: snprintf");

	for (;;) {
		if (! bsnprintf(evpname, MAXPATHLEN, "%s/%s.%qu", evpdir,
			messagep->message_id, (u_int64_t)arc4random()))
			fatal("queue_record_envelope: snprintf");

		(void)strlcpy(message_uid, evpname + strlen(evpdir) + 1, MAXPATHLEN);

		fd = open(evpname, mode, 0600);
		if (fd == -1) {
			if (errno == EEXIST)
				continue;
			log_debug("failed to open %s", evpname);
			fatal("queue_record_envelope: open");
		}

		if (flock(fd, LOCK_EX) == -1)
			fatal("queue_record_envelope: flock");

		fp = fdopen(fd, "w");
		if (fp == NULL)
			fatal("fdopen");

		if (strlcpy(messagep->message_uid, message_uid, MAXPATHLEN)
		    >= MAXPATHLEN)
			fatal("queue_record_envelope: strlcpy");

		messagep->creation = time(NULL);

		if ((ret = fwrite(messagep, sizeof (struct message), 1, fp)) != 1) {
			fclose(fp);
			unlink(evpname);
			return 0;
		}
		fflush(fp);
		fsync(fd);
		fclose(fp);

		break;
	}
	return 1;

}

int
a1001 2
	struct message msave;

d1006 3
a1008 2
		if ((messagep->type & T_DAEMON_MESSAGE) == 0) {
			msave = *messagep;
a1009 1
			messagep->batch_id = 0;
d1014 2
a1015 2
			queue_record_envelope(messagep);
			*messagep = msave;
a1016 1
		queue_remove_envelope(messagep);
@


1.35
log
@kill unused function; ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.34 2008/12/27 17:36:37 jacekm Exp $	*/
a958 1
	int fd;
a960 4
	mode_t mode = O_RDWR;
	u_int16_t hval;

	hval = queue_hash(messagep->message_id);
d963 2
a964 1
		hval, messagep->message_id, PATH_ENVELOPES, messagep->message_uid))
d967 2
a968 1
	if ((fd = open(pathname, mode)) == -1)
d970 1
a970 2

	if (flock(fd, LOCK_EX) == -1)
d972 3
a974 6

	fp = fdopen(fd, "w");
	if (fp == NULL)
		fatal("queue_update_envelope: fdopen");

	if (fwrite(messagep, sizeof(struct message), 1, fp) != 1)
d976 2
a977 5
	fflush(fp);
	fsync(fd);
	fclose(fp);

	return 1;
@


1.34
log
@cleanup; ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.33 2008/12/27 17:12:39 jacekm Exp $	*/
a60 1
int		queue_update_incoming_envelope(struct message *);
a794 28
	return 1;
}

int
queue_update_incoming_envelope(struct message *messagep)
{
	int fd;
	char pathname[MAXPATHLEN];
	FILE *fp;
	mode_t mode = O_RDWR;

	if (! bsnprintf(pathname, MAXPATHLEN, "%s/%s%s/%s", PATH_INCOMING,
		messagep->message_id, PATH_ENVELOPES, messagep->message_uid))
		fatal("queue_update_incoming_envelope: snprintf");

	if ((fd = open(pathname, mode)) == -1)
		fatal("queue_update_incoming_envelope: open");

	fp = fdopen(fd, "w");
	if (fp == NULL)
		fatal("queue_update_incoming_envelope: fdopen");

	if (fwrite(messagep, sizeof(struct message), 1, fp) != 1)
		fatal("queue_update_incoming_envelope: fwrite");
	fflush(fp);
	fsync(fd);
	fclose(fp);

@


1.33
log
@Put common handler code in a function; ok chl@@ gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.32 2008/12/27 17:03:29 jacekm Exp $	*/
a55 1
void		queue_timeout(int, short, void *);
d57 1
d59 1
a59 6
int		queue_record_envelope(struct message *);
int		queue_remove_envelope(struct message *);
int		queue_open_message_file(struct batch *);
int		queue_batch_resolved(struct smtpd *, struct batch *);
int		queue_message_schedule(struct message *, time_t);
void		queue_delete_message_file(char *);
a63 2
void		queue_delete_incoming_message(char *);
int		queue_update_envelope(struct message *);
a64 6
void		queue_process(struct smtpd *);
int		queue_process_bucket(struct smtpd *, u_int16_t);
int		queue_process_message(struct smtpd *, char *);
void		queue_process_envelope(struct smtpd *, char *, char *);
int		queue_load_envelope(struct message *, char *);
void		queue_delete_message(char *);
d67 3
a69 4
void		batch_send(struct smtpd *, struct batch *, time_t);
struct batch	*queue_record_batch(struct smtpd *, struct message *);
struct batch    *batch_by_id(struct smtpd *, u_int64_t);
struct message	*message_by_id(struct smtpd *, struct batch *, u_int64_t);
d970 1
a970 1
		fatal("queue_remove_incoming_envelope: snprintf");
d973 1
a973 1
		fatal("queue_remove_incoming_envelope: unlink");
d977 1
a977 1
		fatal("queue_remove_incoming_envelope: snprintf");
@


1.32
log
@Merge hash() and queue_message_hash() into one func, queue_hash(). Fix callers
to use this interface consistently; ok chl@@ gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.31 2008/12/18 15:11:21 jacekm Exp $	*/
d78 1
d332 1
a332 33
			struct message *messagep;

			messagep = (struct message *)imsg.data;
			messagep->batch_id = 0;
			messagep->retry++;

			if (messagep->status & S_MESSAGE_TEMPFAILURE) {
				messagep->status &= ~S_MESSAGE_TEMPFAILURE;
				messagep->flags &= ~F_MESSAGE_PROCESSING;
				queue_update_envelope(messagep);
				break;
			}

			if (messagep->status & S_MESSAGE_PERMFAILURE) {
				struct message msave;

				messagep->status &= ~S_MESSAGE_PERMFAILURE;
				if ((messagep->type & T_DAEMON_MESSAGE) == 0) {
					msave = *messagep;
					messagep->id = queue_generate_id();
					messagep->batch_id = 0;
					messagep->type |= T_DAEMON_MESSAGE;
					messagep->lasttry = 0;
					messagep->retry = 0;
					queue_record_envelope(messagep);
					*messagep = msave;
				}
				queue_remove_envelope(messagep);
				break;
			}

			/* no error, remove envelope */
			queue_remove_envelope(messagep);
d395 1
a395 33
			struct message *messagep;

			messagep = (struct message *)imsg.data;
			messagep->batch_id = 0;
			messagep->retry++;

			if (messagep->status & S_MESSAGE_TEMPFAILURE) {
				messagep->status &= ~S_MESSAGE_TEMPFAILURE;
				messagep->flags &= ~F_MESSAGE_PROCESSING;
				queue_update_envelope(messagep);
				break;
			}

			if (messagep->status & S_MESSAGE_PERMFAILURE) {
				struct message msave;

				messagep->status &= ~S_MESSAGE_PERMFAILURE;
				if ((messagep->type & T_DAEMON_MESSAGE) == 0) {
					msave = *messagep;
					messagep->id = queue_generate_id();
					messagep->batch_id = 0;
					messagep->type |= T_DAEMON_MESSAGE;
					messagep->lasttry = 0;
					messagep->retry = 0;
					queue_record_envelope(messagep);
					*messagep = msave;
				}
				queue_remove_envelope(messagep);
				break;
			}

			/* no error, remove envelope */
			queue_remove_envelope(messagep);
d1120 35
@


1.31
log
@Cleanup /incoming before handling each MAIL FROM.
Improve cleanup condition to cover more cases.

ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.30 2008/12/17 18:47:37 jacekm Exp $	*/
a64 1
u_int16_t	queue_message_hash(struct message *);
a79 1
u_int32_t	hash(u_int8_t *, size_t);
d931 1
a931 1
	hval = queue_message_hash(messagep);
d984 1
a984 1
	hval = queue_message_hash(messagep);
d1042 1
a1042 1
	hval = queue_message_hash(messagep);
d1071 1
a1071 1
	hval = queue_message_hash(messagep);
d1107 1
a1107 1
	hval = hash(msgid, strlen(msgid)) % DIRHASH_BUCKETS;
d1132 1
a1132 1
	hval = hash(batchp->message_id, strlen(batchp->message_id)) % DIRHASH_BUCKETS;
d1152 1
a1152 1
	hval = hash(msgid, strlen(msgid)) % DIRHASH_BUCKETS;
d1186 1
a1186 1
queue_message_hash(struct message *messagep)
d1188 1
a1188 8
	return hash(messagep->message_id, strlen(messagep->message_id))
	    % DIRHASH_BUCKETS;
}

u_int32_t
hash(u_int8_t *buf, size_t len)
{
	u_int32_t h;
d1190 2
a1191 2
	for (h = 5381; len; len--)
		h = ((h << 5) + h) + *buf++;
d1193 1
a1193 1
	return h;
@


1.30
log
@Introduce /purge, where all msgs scheduled for deletion are put by
queue, and removed from disk by runner.

On startup, clean /incoming by moving msgs within it to /purge.

ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.29 2008/12/14 19:27:47 jacekm Exp $	*/
d202 1
a202 2
			if (messagep->message_id[0] != '\0')
				queue_delete_incoming_message(messagep->message_id);
@


1.29
log
@Files under /incoming don't need flock(2)ing anymore.

ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.28 2008/12/14 19:24:42 jacekm Exp $	*/
d57 1
d680 1
d753 21
d808 1
a808 1
queue_delete_incoming_message(char *message_id)
d811 1
a811 9
	char evpdir[MAXPATHLEN];
	char evppath[MAXPATHLEN];
	char msgpath[MAXPATHLEN];
	DIR *dirp;
	struct dirent *dp;
	
	if (! bsnprintf(rootdir, MAXPATHLEN, "%s/%s", PATH_INCOMING,
		message_id))
		fatal("queue_delete_incoming_message: snprintf");
d813 2
a814 6
	if (! bsnprintf(evpdir, MAXPATHLEN, "%s%s",
		rootdir, PATH_ENVELOPES))
		fatal("queue_delete_incoming_message: snprintf");
	
	if (! bsnprintf(msgpath, MAXPATHLEN, "%s/message", rootdir))
		fatal("queue_delete_incoming_message: snprintf");
d816 2
a817 4
	if (unlink(msgpath) == -1) {
		if (errno != ENOENT)
			fatal("queue_delete_incoming_message: unlink");
	}
d819 1
a819 2
	dirp = opendir(evpdir);
	if (dirp == NULL) {
d821 2
a822 2
			goto delroot;
		fatal("queue_delete_incoming_message: opendir");
a823 24
	while ((dp = readdir(dirp)) != NULL) {
		if (strcmp(dp->d_name, ".") == 0 ||
		    strcmp(dp->d_name, "..") == 0)
			continue;
		if (! bsnprintf(evppath, MAXPATHLEN, "%s/%s", evpdir, dp->d_name))
			fatal("queue_delete_incoming_message: snprintf");

		if (unlink(evppath) == -1) {
			if (errno != ENOENT)
				fatal("queue_delete_incoming_message: unlink");
		}
	}
	closedir(dirp);

	if (rmdir(evpdir) == -1)
		if (errno != ENOENT)
			fatal("queue_delete_incoming_message: rmdir");

delroot:
	if (rmdir(rootdir) == -1)
		if (errno != ENOENT)
			fatal("queue_delete_incoming_message: rmdir");

	return;
@


1.28
log
@O_TRUNC is redundant if O_EXCL is specified.

ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.27 2008/12/14 19:20:59 jacekm Exp $	*/
a870 3
		if (flock(fd, LOCK_EX) == -1)
			fatal("queue_record_submission: flock");

d877 1
a877 1
			fatal("queue_record_submission: strlcpy");
a908 3

	if (flock(fd, LOCK_EX) == -1)
		fatal("queue_update_incoming_envelope: flock");
@


1.27
log
@O_TRUNC is redundant if O_EXCL is specified.

ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.26 2008/12/14 19:16:06 jacekm Exp $	*/
d1000 1
a1000 1
	int mode = O_CREAT|O_TRUNC|O_WRONLY|O_EXCL|O_SYNC;
@


1.26
log
@queue_create_incoming_layout must return 0 on failure, not -1.

ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.25 2008/12/13 23:19:34 jacekm Exp $	*/
d849 1
a849 1
	int mode = O_CREAT|O_TRUNC|O_WRONLY|O_EXCL|O_SYNC;
@


1.25
log
@IMSG_* namespace cleanup.

ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.24 2008/12/11 23:19:00 gilles Exp $	*/
d759 1
a759 1
		return -1;
d762 1
a762 1
		return -1;
@


1.24
log
@- last snprintf -> bsnprintf
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.23 2008/12/11 23:17:25 gilles Exp $	*/
d193 1
a193 1
			imsg_compose(ibuf, IMSG_SMTP_MESSAGE_ID, 0, 0, -1,
d224 2
a225 2
				imsg_compose(ibuf, IMSG_SMTP_SUBMIT_ACK, 0, 0, -1,
				    &ss, sizeof(ss));
d229 1
a229 1
			imsg_compose(ibuf, IMSG_SMTP_SUBMIT_ACK, 0, 0, -1,
d238 3
a240 2
				imsg_compose(env->sc_ibufs[PROC_LKA], IMSG_LKA_FORWARD_LOOKUP, 0, 0, -1,
				    messagep, sizeof(struct message));
d245 1
a245 1
			 * ~/.forward will be handled by the IMSG_LKA_ALIAS_RESULT
d248 3
a250 2
			imsg_compose(env->sc_ibufs[PROC_LKA], IMSG_LKA_ALIAS_LOOKUP, 0, 0, -1,
			    messagep, sizeof (struct message));
d264 1
a264 1
			imsg_compose(ibuf, IMSG_SMTP_SUBMIT_ACK, 0, 0, -1,
d281 1
a281 1
			imsg_compose(ibuf, IMSG_SMTP_MESSAGE_FILE, 0, 0, fd,
d511 1
a511 1
		case IMSG_LKA_ALIAS_RESULT: {
d520 1
a520 1
				imsg_compose(ibuf, IMSG_LKA_FORWARD_LOOKUP, 0, 0, -1,
d526 1
a526 1
		case IMSG_LKA_FORWARD_LOOKUP: {
@


1.23
log
@- snprintf -> bsnprintf
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.22 2008/12/07 16:00:07 jacekm Exp $	*/
d766 1
a766 1
	if (! snprintf(evpdir, MAXPATHLEN, "%s%s",
@


1.22
log
@Simplify queue_record_incoming_envelope.

ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.21 2008/12/06 23:49:40 jacekm Exp $	*/
a751 1
	int spret;
d755 2
a756 3
	spret = snprintf(rootdir, MAXPATHLEN, "%s/%d.XXXXXXXXXXXXXXXX",
	    PATH_INCOMING, time(NULL));
	if (spret == -1 || spret >= MAXPATHLEN)
d766 2
a767 3
	spret = snprintf(evpdir, MAXPATHLEN, "%s%s",
	    rootdir, PATH_ENVELOPES);
	if (spret == -1 || spret >= MAXPATHLEN)
a784 1
	int spret;
d792 2
a793 3
	spret = snprintf(rootdir, MAXPATHLEN, "%s/%s", PATH_INCOMING,
	    message_id);
	if (spret == -1 || spret >= MAXPATHLEN)
d796 2
a797 3
	spret = snprintf(evpdir, MAXPATHLEN, "%s%s",
	    rootdir, PATH_ENVELOPES);
	if (spret == -1 || spret >= MAXPATHLEN)
d800 1
a800 2
	spret = snprintf(msgpath, MAXPATHLEN, "%s/message", rootdir);
	if (spret == -1 || spret >= MAXPATHLEN)
d818 1
a818 2
		spret = snprintf(evppath, MAXPATHLEN, "%s/%s", evpdir, dp->d_name);
		if (spret == -1 || spret >= MAXPATHLEN)
a847 1
	int spret;
d851 2
a852 3
	spret = snprintf(evpdir, MAXPATHLEN, "%s/%s%s", PATH_INCOMING,
	    message->message_id, PATH_ENVELOPES);
	if (spret == -1 || spret >= MAXPATHLEN)
d856 2
a857 3
		spret = snprintf(evpname, MAXPATHLEN, "%s/%s.%qu", evpdir,
		    message->message_id, (u_int64_t)arc4random());
		if (spret == -1 || spret >= MAXPATHLEN)
a900 1
	int spret;
d904 2
a905 3
	spret = snprintf(pathname, MAXPATHLEN, "%s/%s%s/%s", PATH_INCOMING,
	    messagep->message_id, PATH_ENVELOPES, messagep->message_uid);
	if (spret == -1 || spret >= MAXPATHLEN)
a930 1
	int spret;
d932 2
a933 3
	spret = snprintf(pathname, MAXPATHLEN, "%s/%s%s/%s", PATH_INCOMING,
	    message->message_id, PATH_ENVELOPES, message->message_uid);
	if (spret == -1 || spret >= MAXPATHLEN)
a945 1
	int spret;
d950 2
a951 3
	spret = snprintf(rootdir, MAXPATHLEN, "%s/%s", PATH_INCOMING,
	    messagep->message_id);
	if (spret == -1 || spret >= MAXPATHLEN)
d956 1
a956 2
	spret = snprintf(queuedir, MAXPATHLEN, "%s/%d", PATH_QUEUE, hval);
	if (spret == -1 || spret >= MAXPATHLEN)
d966 2
a967 3
	spret = snprintf(queuedir, MAXPATHLEN, "%s/%d/%s", PATH_QUEUE, hval,
		messagep->message_id);
	if (spret == -1 || spret >= MAXPATHLEN)
a980 1
	int spret;
d982 3
a984 4

	spret = snprintf(pathname, MAXPATHLEN, "%s/%s/message", PATH_INCOMING,
	    messagep->message_id);
	if (spret == -1 || spret >= MAXPATHLEN)
a998 1
	int spret;
d1003 2
a1004 3
	spret = snprintf(queuedir, MAXPATHLEN, "%s/%s", PATH_QUEUE,
	    messagep->message_id);
	if (spret == -1 || spret >= MAXPATHLEN)
d1009 1
a1009 2
	spret = snprintf(queuedir, MAXPATHLEN, "%s/%d", PATH_QUEUE, hval);
	if (spret == -1 || spret >= MAXPATHLEN)
d1012 2
a1013 3
	spret = snprintf(evpdir, MAXPATHLEN, "%s/%s%s", queuedir, messagep->message_id,
	    PATH_ENVELOPES);
	if (spret == -1 || spret >= MAXPATHLEN)
d1017 2
a1018 3
		spret = snprintf(evpname, MAXPATHLEN, "%s/%s.%qu", evpdir,
		    messagep->message_id, (u_int64_t)arc4random());
		if (spret == -1 || spret >= MAXPATHLEN)
a1063 1
	int spret;
d1067 3
a1069 3
	spret = snprintf(pathname, MAXPATHLEN, "%s/%d/%s%s/%s", PATH_QUEUE,
	    hval, messagep->message_id, PATH_ENVELOPES, messagep->message_uid);
	if (spret == -1 || spret >= MAXPATHLEN)
d1075 2
a1076 3
	spret = snprintf(pathname, MAXPATHLEN, "%s/%d/%s%s", PATH_QUEUE,
	    hval, messagep->message_id, PATH_ENVELOPES);
	if (spret == -1 || spret >= MAXPATHLEN)
a1089 1
	int spret;
d1096 2
a1097 3
	spret = snprintf(pathname, MAXPATHLEN, "%s/%d/%s%s/%s", PATH_QUEUE,
	    hval, messagep->message_id, PATH_ENVELOPES, messagep->message_uid);
	if (spret == -1 || spret >= MAXPATHLEN)
a1121 1
	int spret;
d1131 3
a1133 2
	spret = snprintf(pathname, MAXPATHLEN, "%s/%d/%s%s/%s", PATH_QUEUE,
	    hval, msgid, PATH_ENVELOPES, evpid);
a1151 1
	int spret;
d1157 2
a1158 3
	spret = snprintf(pathname, MAXPATHLEN, "%s/%d/%s/message", PATH_QUEUE,
	    hval, batchp->message_id);
	if (spret == -1 || spret >= MAXPATHLEN)
a1169 1
	int spret;
d1176 2
a1177 3
	spret = snprintf(rootdir, MAXPATHLEN, "%s/%d/%s", PATH_QUEUE,
	    hval, msgid);
	if (spret == -1 || spret >= MAXPATHLEN)
d1180 2
a1181 3
	spret = snprintf(evpdir, MAXPATHLEN, "%s%s",
	    rootdir, PATH_ENVELOPES);
	if (spret == -1 || spret >= MAXPATHLEN)
d1184 1
a1184 2
	spret = snprintf(msgpath, MAXPATHLEN, "%s/message", rootdir);
	if (spret == -1 || spret >= MAXPATHLEN)
d1199 2
a1200 3
	spret = snprintf(rootdir, MAXPATHLEN, "%s/%d", PATH_QUEUE,
	    hval);
	if (spret == -1 || spret >= MAXPATHLEN)
@


1.21
log
@Make queue_delete_incoming_message not fatal on ENOENT condition.
Also, fix function name in fatals.

ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.20 2008/12/06 14:30:51 jacekm Exp $	*/
a850 1
	char rootdir[MAXPATHLEN];
d860 2
a861 6
	spret = snprintf(rootdir, MAXPATHLEN, "%s/%s", PATH_INCOMING,
	    message->message_id);
	if (spret == -1 || spret >= MAXPATHLEN)
		fatal("queue_record_incoming_envelope: snprintf");

	spret = snprintf(evpdir, MAXPATHLEN, "%s%s", rootdir, PATH_ENVELOPES);
@


1.20
log
@Don't include <err.h> where log.c API must be used.

ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.19 2008/12/05 02:51:32 gilles Exp $	*/
d816 3
a818 1
	if (dirp == NULL)
d820 1
d827 1
a827 1
			fatal("queue_create_incoming_message: snprintf");
d831 1
a831 1
				fatal("queue_create_incoming_message: unlink");
d838 1
a838 1
			fatal("queue_create_incoming_message: rmdir");
d840 1
d843 1
a843 1
			fatal("queue_create_incoming_message: rmdir");
@


1.19
log
@- last part of the new queue code: the runner process (unprivileged and
	chrooted) is now in charge of doing the scheduling of deliveries,
	and the dispatching of messages to MDA and MTA. queue process only
	does inserts/updates/removals from the queue and can no longer be
	so busy that it delays answers to imsg from smtp server.
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.18 2008/12/03 20:08:08 gilles Exp $	*/
a31 1
#include <err.h>
@


1.18
log
@- remove log_debug() that's no longer needed
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.17 2008/12/03 17:58:00 gilles Exp $	*/
d54 1
a57 1
void		queue_process_runqueue(int, short, void *);
a83 1
struct batch    *batch_lookup(struct smtpd *, struct message *);
d543 3
a545 2
		case IMSG_LKA_MX_LOOKUP: {
			queue_batch_resolved(env, imsg.data);
d548 41
d590 1
a590 1
			log_debug("queue_dispatch_lka: unexpected imsg %d",
a608 11
	struct timeval	 tv;

	evtimer_set(&env->sc_ev, queue_timeout, env);
	tv.tv_sec = 0;
	tv.tv_usec = 10;
	evtimer_add(&env->sc_ev, &tv);

	evtimer_set(&env->sc_rqev, queue_process_runqueue, env);
	tv.tv_sec = 0;
	tv.tv_usec = 10;
	evtimer_add(&env->sc_rqev, &tv);
a613 35
	evtimer_del(&env->sc_ev);
}

void
queue_timeout(int fd, short event, void *p)
{
	struct smtpd		*env = p;
	struct timeval		 tv;
	time_t curtime;
	struct batch *batchp, *nxt;

	queue_process(env);

	curtime = time(NULL);

	for (batchp = SPLAY_MIN(batchtree, &env->batch_queue);
	     batchp != NULL;
	     batchp = nxt) {
		nxt = SPLAY_NEXT(batchtree, &env->batch_queue, batchp);
		if ((batchp->type & T_MTA_BATCH) &&
		    (batchp->flags & F_BATCH_RESOLVED) == 0) {
			continue;
		}

		batch_send(env, batchp, curtime);

		SPLAY_REMOVE(batchtree, &env->batch_queue, batchp);
		bzero(batchp, sizeof(struct batch));
		free(batchp);

	}

	tv.tv_sec = 0;
	tv.tv_usec = 10;
	evtimer_add(&env->sc_ev, &tv);
d630 2
a631 1
		{ PROC_LKA,	queue_dispatch_lka }
a665 2
	SPLAY_INIT(&env->batch_queue);

d675 1
a675 1
	config_peers(env, peers, 5);
a683 251
void
queue_process(struct smtpd *env)
{
	u_int16_t cbucket = 0;
	static u_int16_t lbucket = 0;
	DIR *dirp;
	struct dirent *dp;
	const char *errstr;
	static u_int8_t bucketdone = 1;

	if (! bucketdone) {
		bucketdone = queue_process_bucket(env, lbucket);
		if (bucketdone)
			lbucket = (lbucket + 1) % DIRHASH_BUCKETS;
		return;
	}

	dirp = opendir(PATH_QUEUE);
	if (dirp == NULL)
		fatal("queue_process: opendir");

	while ((dp = readdir(dirp)) != NULL) {

		if (strcmp(dp->d_name, ".") == 0 ||
		    strcmp(dp->d_name, "..") == 0)
			continue;

		cbucket = strtonum(dp->d_name, 0, DIRHASH_BUCKETS - 1, &errstr);
		if (errstr) {
			log_warn("queue_process: %s/%s is not a valid bucket",
			    PATH_QUEUE, dp->d_name);
			continue;
		}

		if (cbucket == lbucket)
			break;
	}
	closedir(dirp);

	if (dp == NULL) {
		lbucket = (lbucket + 1) % DIRHASH_BUCKETS;
		return;
	}

	bucketdone = queue_process_bucket(env, cbucket);
	if (bucketdone)
		lbucket = (lbucket + 1) % DIRHASH_BUCKETS;
}

int
queue_process_bucket(struct smtpd *env, u_int16_t bucket)
{
	int spret;
	static DIR *dirp = NULL;
	struct dirent *dp;
	static char *msgid = NULL;
	char bucketpath[MAXPATHLEN];
	static u_int8_t messagedone = 1;

	if (! messagedone) {
		messagedone = queue_process_message(env, msgid);
		if (! messagedone)
			return 0;
		msgid = NULL;
	}

	spret = snprintf(bucketpath, MAXPATHLEN, "%s/%d", PATH_QUEUE, bucket);
	if (spret == -1 || spret >= MAXPATHLEN)
		fatal("queue_process_bucket: snprintf");

	if (dirp == NULL) {
		dirp = opendir(bucketpath);
		if (dirp == NULL)
			fatal("queue_process_bucket: opendir");
	}

	while ((dp = readdir(dirp)) != NULL) {

		if (strcmp(dp->d_name, ".") == 0 ||
		    strcmp(dp->d_name, "..") == 0)
			continue;

		break;
	}

	if (dp != NULL) {
		msgid = dp->d_name;
		messagedone = queue_process_message(env, msgid);
		if (! messagedone)
			return 0;
		msgid = NULL;
	}

	closedir(dirp);
	dirp = NULL;
	return 1;
}

int
queue_process_message(struct smtpd *env, char *messageid)
{
	int spret;
	static DIR *dirp = NULL;
	struct dirent *dp;
	char evppath[MAXPATHLEN];
	u_int16_t hval = 0;

	hval = hash(messageid, strlen(messageid)) % DIRHASH_BUCKETS;

	spret = snprintf(evppath, MAXPATHLEN, "%s/%d/%s%s", PATH_QUEUE, hval,
	    messageid, PATH_ENVELOPES);
	if (spret == -1 || spret >= MAXPATHLEN)
		fatal("queue_process_message: snprintf");

	if (dirp == NULL) {
		dirp = opendir(evppath);
		if (dirp == NULL)
			fatal("queue_process_message: opendir");
	}

	while ((dp = readdir(dirp)) != NULL) {

		if (strcmp(dp->d_name, ".") == 0 ||
		    strcmp(dp->d_name, "..") == 0)
			continue;
		break;
	}

	if (dp != NULL) {
		queue_process_envelope(env, messageid, dp->d_name);
		return 0;
	}

	closedir(dirp);
	dirp = NULL;
	return 1;
}

void
queue_process_envelope(struct smtpd *env, char *msgid, char *evpid)
{
	int spret;
	struct message message;
	time_t tm;
	char evppath[MAXPATHLEN];
	char rqpath[MAXPATHLEN];
	u_int16_t hval;
	struct stat sb;

	if (! queue_load_envelope(&message, evpid)) {
		log_debug("failed to load envelope: %s", evpid);
		return;
	}

	tm = time(NULL);

	if (! queue_message_schedule(&message, tm)) {
		if (message.flags & F_MESSAGE_EXPIRED) {
			log_debug("message has expired, mdaemon");
			queue_remove_envelope(&message);
		}
		return;
	}

	message.flags |= F_MESSAGE_SCHEDULED;
	queue_update_envelope(&message);

	log_debug("SCHEDULED: %s", evpid);
	hval = hash(msgid, strlen(msgid)) % DIRHASH_BUCKETS;
	spret = snprintf(evppath, MAXPATHLEN, "%s/%d/%s%s/%s", PATH_QUEUE, hval,
	    msgid, PATH_ENVELOPES, evpid);
	if (spret == -1 || spret >= MAXPATHLEN)
		fatal("queue_process_envelope: snprintf");

	spret = snprintf(rqpath, MAXPATHLEN, "%s/%s", PATH_RUNQUEUE, evpid);
	if (spret == -1 || spret >= MAXPATHLEN)
		fatal("queue_process_envelope: snprintf");

	if (stat(rqpath, &sb) == -1) {
		if (errno != ENOENT)
			fatal("queue_process_envelope: stat");

		if (symlink(evppath, rqpath) == -1) {
			log_info("queue_process_envelope: "
			    "failed to place envelope in runqueue");
		}
	}
}

void
queue_process_runqueue(int fd, short event, void *p)
{
	DIR *dirp;
	struct dirent *dp;
	struct message message;
	struct message *messagep;
	struct batch *batchp;
	char pathname[MAXPATHLEN];
	time_t tm;
	struct smtpd *env = p;
	struct timeval	 tv;

	tm = time(NULL);

	dirp = opendir(PATH_RUNQUEUE);
	if (dirp == NULL)
		fatal("queue_process_runqueue: opendir");

	while ((dp = readdir(dirp)) != NULL) {
		if (strcmp(dp->d_name, ".") == 0 ||
		    strcmp(dp->d_name, "..") == 0)
			continue;

		/* XXX */
		snprintf(pathname, MAXPATHLEN, "%s/%s", PATH_RUNQUEUE, dp->d_name);
		unlink(pathname);

		if (! queue_load_envelope(&message, dp->d_name)) {
			log_debug("failed to load envelope");
			continue;
		}

		if (message.flags & F_MESSAGE_PROCESSING)
			continue;

		message.lasttry = tm;
		message.flags &= ~F_MESSAGE_SCHEDULED;
		message.flags |= F_MESSAGE_PROCESSING;
		queue_update_envelope(&message);

		messagep = calloc(1, sizeof (struct message));
		if (messagep == NULL)
			err(1, "calloc");
		*messagep = message;

		batchp = batch_lookup(env, messagep);
		if (batchp != NULL)
			messagep->batch_id = batchp->id;

		batchp = queue_record_batch(env, messagep);
		if (messagep->batch_id == 0)
			messagep->batch_id = batchp->id;
	}

	closedir(dirp);

	tv.tv_sec = 0;
	tv.tv_usec = 10;
	evtimer_add(&env->sc_rqev, &tv);
}

a700 56
struct batch *
queue_record_batch(struct smtpd *env, struct message *messagep)
{
	struct batch *batchp;
	struct path *path;

	batchp = NULL;
	if (messagep->batch_id != 0) {
		batchp = batch_by_id(env, messagep->batch_id);
		if (batchp == NULL)
			errx(1, "%s: internal inconsistency.", __func__);
	}

	if (batchp == NULL) {
		batchp = calloc(1, sizeof(struct batch));
		if (batchp == NULL)
			err(1, "%s: calloc", __func__);

		batchp->id = queue_generate_id();
		batchp->creation = messagep->creation;

		(void)strlcpy(batchp->message_id, messagep->message_id,
		    sizeof(batchp->message_id));

		TAILQ_INIT(&batchp->messages);
		SPLAY_INSERT(batchtree, &env->batch_queue, batchp);

		if (messagep->type & T_DAEMON_MESSAGE) {
			batchp->type = T_DAEMON_BATCH;
			path = &messagep->sender;
		}
		else {
			path = &messagep->recipient;
		}

		batchp->rule = path->rule;

		(void)strlcpy(batchp->hostname, path->domain,
		    sizeof(batchp->hostname));

		if (IS_MAILBOX(path->rule.r_action) ||
		    IS_EXT(path->rule.r_action)) {
			batchp->type |= T_MDA_BATCH;
		}
		else {
			batchp->type |= T_MTA_BATCH;
			imsg_compose(env->sc_ibufs[PROC_LKA], IMSG_LKA_MX_LOOKUP, 0, 0, -1,
			    batchp, sizeof(struct batch));
		}
	}

	TAILQ_INSERT_TAIL(&batchp->messages, messagep, entry);

	return batchp;
}

a717 189
int
queue_batch_resolved(struct smtpd *env, struct batch *lookup)
{
	u_int32_t i;
	struct batch *batchp;

	batchp = batch_by_id(env, lookup->id);
	batchp->getaddrinfo_error = lookup->getaddrinfo_error;
	batchp->mx_cnt = lookup->mx_cnt;

/*
           EAI_NODATA        no address associated with hostname
           EAI_NONAME        hostname or servname not provided, or not known
           EAI_PROTOCOL      resolved protocol is unknown
           EAI_SERVICE       servname not supported for ai_socktype
           EAI_SOCKTYPE      ai_socktype not supported
           EAI_SYSTEM        system error returned in errno


 */

	switch (batchp->getaddrinfo_error) {
	case EAI_ADDRFAMILY:
	case EAI_BADFLAGS:
	case EAI_BADHINTS:
	case EAI_FAIL:
	case EAI_FAMILY:
	case EAI_NODATA:
	case EAI_NONAME:
	case EAI_SERVICE:
	case EAI_SOCKTYPE:
	case EAI_SYSTEM:
		/* XXX */
		/*
		 * In the case of a DNS permanent error, do not generate a
		 * daemon message if the error originates from one already
		 * as this would cause a loop. Remove the initial batch as
		 * it will never succeed.
		 *
		 */
		return 0;

	case EAI_AGAIN:
	case EAI_MEMORY:
		/* XXX */
		/*
		 * Do not generate a daemon message if this error happened
		 * while processing a daemon message. Do NOT remove batch,
		 * it may succeed later.
		 */
		return 0;

	default:
		batchp->flags |= F_BATCH_RESOLVED;
		for (i = 0; i < batchp->mx_cnt; ++i)
			batchp->mxarray[i].ss = lookup->mxarray[i].ss;
	}
	return 1;
}

struct batch *
batch_lookup(struct smtpd *env, struct message *message)
{
	struct batch *batchp;
	struct batch lookup;

	/* If message->batch_id != 0, we can retrieve batch by id */
	if (message->batch_id != 0) {
		lookup.id = message->batch_id;
		return SPLAY_FIND(batchtree, &env->batch_queue, &lookup);
	}

	/* We do not know the batch_id yet, maybe it was created but we could not
	 * be notified, or it just does not exist. Let's scan to see if we can do
	 * a match based on our message_id and flags.
	 */
	SPLAY_FOREACH(batchp, batchtree, &env->batch_queue) {

		if (batchp->type != message->type)
			continue;

		if (strcasecmp(batchp->message_id, message->message_id) != 0)
			continue;

		if (batchp->type & T_MTA_BATCH)
			if (strcasecmp(batchp->hostname, message->recipient.domain) != 0)
				continue;

		break;
	}

	return batchp;
}

int
batch_cmp(struct batch *s1, struct batch *s2)
{
	/*
	 * do not return u_int64_t's
	 */
	if (s1->id < s2->id)
		return (-1);

	if (s1->id > s2->id)
		return (1);

	return (0);
}

int
queue_message_schedule(struct message *messagep, time_t tm)
{
	time_t delay;

	/* Batch has been in the queue for too long and expired */
	if (tm - messagep->creation >= SMTPD_QUEUE_EXPIRY) {
		messagep->flags |= F_MESSAGE_EXPIRED;
		return 0;
	}

	if (messagep->retry == 255) {
		messagep->flags |= F_MESSAGE_EXPIRED;
		return 0;
	}
	
	if ((messagep->flags & F_MESSAGE_SCHEDULED) != 0)
		return 0;

	if ((messagep->flags & F_MESSAGE_PROCESSING) != 0)
		return 0;

	if (messagep->lasttry == 0)
		return 1;

	delay = SMTPD_QUEUE_MAXINTERVAL;

	if (messagep->type & T_MDA_MESSAGE) {
		if (messagep->retry < 5)
			return 1;

		if (messagep->retry < 15)
			delay = (messagep->retry * 60) + arc4random() % 60;
	}

	if (messagep->type & T_MTA_MESSAGE) {
		if (messagep->retry < 3)
			delay = SMTPD_QUEUE_INTERVAL;
		else if (messagep->retry <= 7) {
			delay = SMTPD_QUEUE_INTERVAL * (1 << (messagep->retry - 3));
			if (delay > SMTPD_QUEUE_MAXINTERVAL)
				delay = SMTPD_QUEUE_MAXINTERVAL;
		}
	}

	if (tm >= messagep->lasttry + delay)
		return 1;

	return 0;
}

void
batch_send(struct smtpd *env, struct batch *batchp, time_t curtime)
{
	u_int8_t proctype;
	struct message *messagep;

	if ((batchp->type & (T_MDA_BATCH|T_MTA_BATCH)) == 0)
		fatal("batch_send: unknown batch type");

	if (batchp->type & T_MDA_BATCH)
		proctype = PROC_MDA;
	else if (batchp->type & T_MTA_BATCH)
		proctype = PROC_MTA;

	imsg_compose(env->sc_ibufs[proctype], IMSG_CREATE_BATCH, 0, 0, -1,
	    batchp, sizeof (struct batch));

	while ((messagep = TAILQ_FIRST(&batchp->messages))) {
		imsg_compose(env->sc_ibufs[proctype], IMSG_BATCH_APPEND, 0, 0,
		    -1, messagep, sizeof (struct message));
		TAILQ_REMOVE(&batchp->messages, messagep, entry);
		bzero(messagep, sizeof(struct message));
		free(messagep);
	}

	imsg_compose(env->sc_ibufs[proctype], IMSG_BATCH_CLOSE, 0, 0, -1,
	    batchp, sizeof(struct batch));
}

a1263 2

SPLAY_GENERATE(batchtree, batch, b_nodes, batch_cmp);
@


1.17
log
@- fix event masking issues in smtp process which could lead to a fatal() if
	queue process did not answer fast enough to an imsg. spotted by
	Jacek Masiulaniec <jacekm@@dobremiasto.net>
- queue layout was mostly to bootstrap the project, it does not behave good
	under load, it does complex things to stay in a recoverable state
	and it probably didnt do it too well. New queue code is simpler,
	smaller and allows for atomic submissions (a mail can never be in a
	state where it needs to be recovered). It still needs some work but
	works better than previous code, no regression.
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.16 2008/11/25 20:26:40 gilles Exp $	*/
a1317 1
	log_debug("evpdir: %s", evpdir);
@


1.16
log
@- recent change in parse.y caused htons() to be called twice on the port
	provided to "relay via" rules, once in parse.y once in lka.c, fix.
- rename struct address to struct relayhost, introduce struct mxhost which
	not only holds the sockaddr_storage, but also additionnal flags we
	want forwarded to the mta process.
- propagate the change
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.15 2008/11/24 23:55:25 gilles Exp $	*/
d57 7
a63 1
int		queue_create_message_file(char *);
d65 15
a79 5
int		queue_record_submission(struct message *);
int		queue_remove_submission(struct message *);
struct batch    *batch_lookup(struct smtpd *, struct message *);
int		batch_schedule(struct batch *, time_t);
void		batch_unschedule(struct batch *);
d81 1
a81 3
int		queue_update_database(struct message *);
int		queue_open_message_file(struct batch *);
int		queue_batch_resolved(struct smtpd *, struct batch *);
d84 1
a85 7
void		debug_display_batch(struct batch *);
void		debug_display_message(struct message *);
void		queue_load_submissions(struct smtpd *, time_t);
int		queue_message_schedule(struct message *, time_t);
int		queue_message_from_id(char *, struct message *);
int		queue_message_complete(struct message *);
int		queue_init_submissions(void);
d182 1
a182 1
		case IMSG_QUEUE_CREATE_MESSAGE_FILE: {
a184 1
			int			 fd;
d190 6
a195 2
			fd = queue_create_message_file(ss.u.msgid);
			imsg_compose(ibuf, IMSG_SMTP_MESSAGE_FILE, 0, 0, fd,
d199 1
a199 1
		case IMSG_QUEUE_DELETE_MESSAGE_FILE: {
d203 2
a204 1
			queue_delete_message_file(messagep->message_id);
d207 1
a207 1
		case IMSG_QUEUE_MESSAGE_SUBMIT: {
d224 7
a230 1
			queue_record_submission(messagep);
a234 2
				messagep->flags |= F_MESSAGE_READY;
				queue_update_database(messagep);
d254 1
a254 1
		case IMSG_QUEUE_MESSAGE_COMPLETE: {
d261 2
a262 1
			queue_message_complete(messagep);
d269 16
d342 1
a342 1
				queue_update_database(messagep);
a354 1
					messagep->flags |= F_MESSAGE_READY;
d357 1
a357 1
					queue_record_submission(messagep);
d360 1
a360 1
				queue_remove_submission(messagep);
d364 2
a365 2
			/* no error, remove submission */
			queue_remove_submission(messagep);
d437 1
a437 1
				queue_update_database(messagep);
a449 1
					messagep->flags |= F_MESSAGE_READY;
d452 1
a452 1
					queue_record_submission(messagep);
d455 1
a455 1
				queue_remove_submission(messagep);
d459 2
a460 2
			/* no error, remove submission */
			queue_remove_submission(messagep);
d517 1
a517 6
			queue_record_submission(messagep);

			if (messagep->type & T_MTA_MESSAGE) {
				messagep->flags |= F_MESSAGE_READY;
				queue_update_database(messagep);
			}
d532 1
a532 2
			messagep->flags |= F_MESSAGE_READY;
			queue_record_submission(messagep);
d540 1
a540 1
			queue_remove_submission(messagep);
d571 2
a572 2
	tv.tv_sec = 1;
	tv.tv_usec = 0;
d574 5
a590 1
	struct batch		*batchp, *nxt;
d593 3
a597 1
	queue_load_submissions(env, curtime);
d616 2
a617 2
	tv.tv_sec = 5;
	tv.tv_usec = 0;
a620 84
void
queue_load_submissions(struct smtpd *env, time_t tm)
{
	DIR *dirp;
	struct dirent *dp;
	struct batch *batchp;
	struct message *messagep;
	struct message message;

	dirp = opendir(PATH_ENVELOPES);
	if (dirp == NULL)
		err(1, "opendir");

	while ((dp = readdir(dirp)) != NULL) {

		if (dp->d_name[0] == '.')
			continue;

		if (! queue_message_from_id(dp->d_name, &message)) {
			warnx("failed to load message \"%s\"", dp->d_name);
			continue;
		}

		if (! queue_message_schedule(&message, tm)) {
			if (message.flags & F_MESSAGE_EXPIRED) {
				log_debug("message expired, create mdaemon");
				queue_remove_submission(&message);
			}
			continue;
		}

		message.lasttry = tm;
		message.flags |= F_MESSAGE_PROCESSING;
		queue_update_database(&message);

		messagep = calloc(1, sizeof (struct message));
		if (messagep == NULL)
			err(1, "calloc");
		*messagep = message;

		batchp = batch_lookup(env, messagep);
		if (batchp != NULL)
			messagep->batch_id = batchp->id;

		batchp = queue_record_batch(env, messagep);
		if (messagep->batch_id == 0)
			messagep->batch_id = batchp->id;
	}

	closedir(dirp);
}

int
queue_message_from_id(char *message_id, struct message *message)
{
	int spret;
	char pathname[MAXPATHLEN];
	FILE *fp;

	spret = snprintf(pathname, MAXPATHLEN, "%s/%s", PATH_ENVELOPES, message_id);
	if (spret == -1 || spret >= MAXPATHLEN) {
		warnx("queue_load_submissions: filename too long.");
		return 0;
	}

	fp = fopen(pathname, "r");
	if (fp == NULL) {
		warnx("queue_load_submissions: fopen: %s", message_id);
		goto bad;
	}

	if (fread(message, sizeof(struct message), 1, fp) != 1) {
		warnx("queue_load_submissions: fread: %s", message_id);
		goto bad;
	}

	fclose(fp);
	return 1;
bad:
	if (fp != NULL)
		fclose(fp);
	return 0;
}

a671 3
	queue_init_submissions();
	queue_load_submissions(env, time(NULL));

d690 2
a691 2
u_int64_t
queue_generate_id(void)
d693 30
a722 2
	u_int64_t	id;
	struct timeval	tp;
d724 4
a727 2
	if (gettimeofday(&tp, NULL) == -1)
		fatal("queue_generate_id: time");
d729 4
a732 4
	id = (u_int32_t)tp.tv_sec;
	id <<= 32;
	id |= (u_int32_t)tp.tv_usec;
	usleep(1);
d734 3
a736 1
	return (id);
d740 1
a740 1
queue_create_message_file(char *message_id)
a741 2
	int fd;
	char pathname[MAXPATHLEN];
d743 12
d756 1
a756 2
	spret = snprintf(pathname, MAXPATHLEN, "%s/%d.XXXXXXXXXXXXXXXX",
	    PATH_MESSAGES, time(NULL));
d758 1
a758 1
		return -1;
d760 5
a764 3
	fd = mkstemp(pathname);
	if (fd == -1)
		fatal("queue_create_message_file: mkstemp");
d766 1
a766 4
	/* XXX - this won't fail if message_id is MAXPATHLEN bytes */
	if (strlcpy(message_id, pathname + sizeof(PATH_MESSAGES), MAXPATHLEN)
	    >= MAXPATHLEN)
		fatal("queue_create_message_file: message id too long");
d768 3
a770 2
	return fd;
}
d772 2
a773 5
void
queue_delete_message_file(char *message_id)
{
	char pathname[MAXPATHLEN];
	int spret;
d775 7
a781 3
	spret = snprintf(pathname, MAXPATHLEN, "%s/%s", PATH_MESSAGES, message_id);
	if (spret == -1 || spret >= MAXPATHLEN)
		fatal("queue_delete_message_file: message id too long");
d783 3
a785 2
	if (unlink(pathname) == -1)
		fatal("queue_delete_message_file: unlink");
d789 1
a789 1
queue_record_submission(struct message *message)
a790 8
	char pathname[MAXPATHLEN];
	char linkname[MAXPATHLEN];
	char dbname[MAXPATHLEN];
	char message_uid[MAXPATHLEN];
	char *spool;
	size_t spoolsz;
	int fd;
	int mode = O_CREAT|O_TRUNC|O_WRONLY|O_EXCL|O_SYNC;
d792 11
a802 1
	FILE *fp;
d804 4
a807 2
	if (message->type & T_DAEMON_MESSAGE) {
		spool = PATH_DAEMON;
d809 7
a815 10
	else {
		switch (message->recipient.rule.r_action) {
		case A_MBOX:
		case A_MAILDIR:
		case A_EXT:
			spool = PATH_LOCAL;
			break;
		default:
			spool = PATH_RELAY;
		}
a816 1
	spoolsz = strlen(spool);
d818 4
a821 4
	spret = snprintf(pathname, MAXPATHLEN, "%s/%s", PATH_MESSAGES,
	    message->message_id);
	if (spret == -1 || spret >= MAXPATHLEN)
		fatal("queue_record_submission: message id too long");
d823 4
a826 5
	for (;;) {
		spret = snprintf(linkname, MAXPATHLEN, "%s/%s.%qu", spool,
		    message->message_id, (u_int64_t)arc4random());
		if (spret == -1 || spret >= MAXPATHLEN)
			fatal("queue_record_submission: message uid too long");
d828 10
a837 1
		(void)strlcpy(message_uid, linkname + spoolsz + 1, MAXPATHLEN);
d839 4
a842 5
		if (link(pathname, linkname) == -1) {
			if (errno == EEXIST)
				continue;
			err(1, "link: %s , %s", pathname, linkname);
		}
d844 1
a844 4
		spret = snprintf(dbname, MAXPATHLEN, "%s/%s", PATH_ENVELOPES,
		    message_uid);
		if (spret == -1 || spret >= MAXPATHLEN)
			fatal("queue_record_submission: database uid too long");
d846 7
a852 7
		fd = open(dbname, mode, 0600);
		if (fd == -1)
			if (unlink(linkname) == -1)
				fatal("queue_record_submission: unlink");

		if (flock(fd, LOCK_EX) == -1)
			fatal("queue_record_submission: flock");
d854 2
a855 3
		fp = fdopen(fd, "w");
		if (fp == NULL)
			fatal("fdopen");
d857 6
a862 3
		if (strlcpy(message->message_uid, message_uid, MAXPATHLEN)
		    >= MAXPATHLEN)
			fatal("queue_record_submission: message uid too long");
d864 3
a866 1
		message->creation = time(NULL);
d868 7
a874 4
		if (fwrite(message, sizeof(struct message), 1, fp) != 1) {
			fclose(fp);
			unlink(dbname);
			return 0;
a875 5
		fflush(fp);
		fsync(fd);
		fclose(fp);

		break;
a876 1
	return 1;
d879 2
a880 2
struct batch *
queue_record_batch(struct smtpd *env, struct message *messagep)
d882 4
d887 4
a890 8
	struct path *path;

	batchp = NULL;
	if (messagep->batch_id != 0) {
		batchp = batch_by_id(env, messagep->batch_id);
		if (batchp == NULL)
			errx(1, "%s: internal inconsistency.", __func__);
	}
d892 1
a892 4
	if (batchp == NULL) {
		batchp = calloc(1, sizeof(struct batch));
		if (batchp == NULL)
			err(1, "%s: calloc", __func__);
d894 3
a896 2
		batchp->id = queue_generate_id();
		batchp->creation = messagep->creation;
d898 4
a901 2
		(void)strlcpy(batchp->message_id, messagep->message_id,
		    sizeof(batchp->message_id));
d903 3
a905 2
		TAILQ_INIT(&batchp->messages);
		SPLAY_INSERT(batchtree, &env->batch_queue, batchp);
d907 3
a909 6
		if (messagep->type & T_DAEMON_MESSAGE) {
			batchp->type = T_DAEMON_BATCH;
			path = &messagep->sender;
		}
		else {
			path = &messagep->recipient;
d912 2
a913 1
		batchp->rule = path->rule;
d915 4
a918 2
		(void)strlcpy(batchp->hostname, path->domain,
		    sizeof(batchp->hostname));
d920 12
a931 9
		if (IS_MAILBOX(path->rule.r_action) ||
		    IS_EXT(path->rule.r_action)) {
			batchp->type |= T_MDA_BATCH;
		}
		else {
			batchp->type |= T_MTA_BATCH;
			imsg_compose(env->sc_ibufs[PROC_LKA], IMSG_LKA_MX_LOOKUP, 0, 0, -1,
			    batchp, sizeof(struct batch));
		}
d934 20
a953 1
	TAILQ_INSERT_TAIL(&batchp->messages, messagep, entry);
d955 1
a955 1
	return batchp;
d958 2
a959 2
int
queue_remove_submission(struct message *message)
d961 2
a962 6
	char pathname[MAXPATHLEN];
	char linkname[MAXPATHLEN];
	char dbname[MAXPATHLEN];
	char *spool;
	struct stat sb;
	int spret;
d964 5
a968 13
	if (message->type & T_DAEMON_MESSAGE) {
		spool = PATH_DAEMON;
	}
	else {
		switch (message->recipient.rule.r_action) {
		case A_MBOX:
		case A_MAILDIR:
		case A_EXT:
			spool = PATH_LOCAL;
			break;
		default:
			spool = PATH_RELAY;
		}
d971 7
a977 4
	spret = snprintf(dbname, MAXPATHLEN, "%s/%s", PATH_ENVELOPES,
	    message->message_uid);
	if (spret == -1 || spret >= MAXPATHLEN)
		fatal("queue_remove_submission: database uid too long");
d979 2
a980 4
	spret = snprintf(linkname, MAXPATHLEN, "%s/%s", spool,
	    message->message_uid);
	if (spret == -1 || spret >= MAXPATHLEN)
		fatal("queue_remove_submission: message uid too long");
d982 2
a983 4
	spret = snprintf(pathname, MAXPATHLEN, "%s/%s", PATH_MESSAGES,
	    message->message_id);
	if (spret == -1 || spret >= MAXPATHLEN)
		fatal("queue_remove_submission: message id too long");
d985 7
a991 4
	if (unlink(dbname) == -1) {
		warnx("dbname: %s", dbname);
		fatal("queue_remove_submission: unlink");
	}
d993 1
a993 4
	if (unlink(linkname) == -1) {
		warnx("linkname: %s", linkname);
		fatal("queue_remove_submission: unlink");
	}
d995 2
a996 4
	if (stat(pathname, &sb) == -1) {
		warnx("pathname: %s", pathname);
		fatal("queue_remove_submission: stat");
	}
d998 8
a1005 4
	if (sb.st_nlink == 1) {
		if (unlink(pathname) == -1) {
			warnx("pathname: %s", pathname);
			fatal("queue_remove_submission: unlink");
d1009 3
a1011 1
	return 1;
a1090 69
int
queue_open_message_file(struct batch *batch)
{
	int fd;
	char pathname[MAXPATHLEN];
	int spret;

	spret = snprintf(pathname, MAXPATHLEN, "%s/%s", PATH_MESSAGES,
	    batch->message_id);
	if (spret == -1 || spret >= MAXPATHLEN)
		fatal("queue_open_message_file: message id too long");

	fd = open(pathname, O_RDONLY);
	if (fd == -1)
		fatal("queue_open_message_file: open");

	return fd;
}

int
queue_update_database(struct message *message)
{
	int fd;
	char *spool;
	char pathname[MAXPATHLEN];
	int spret;
	FILE *fp;
	mode_t mode = O_RDWR;

	if (message->type & T_DAEMON_MESSAGE) {
		spool = PATH_DAEMON;
	}
	else {
		switch (message->recipient.rule.r_action) {
		case A_MBOX:
		case A_MAILDIR:
		case A_EXT:
			spool = PATH_LOCAL;
			break;
		default:
			spool = PATH_RELAY;
		}
	}

	spret = snprintf(pathname, MAXPATHLEN, "%s/%s", PATH_ENVELOPES,
	    message->message_uid);
	if (spret == -1 || spret >= MAXPATHLEN)
		fatal("queue_update_database: pathname too long");

	if ((fd = open(pathname, mode)) == -1)
		fatal("queue_update_database: cannot open database");


	if (flock(fd, LOCK_EX) == -1)
		fatal("queue_update_database: flock");

	fp = fdopen(fd, "w");
	if (fp == NULL)
		fatal("fdopen");

	if (fwrite(message, sizeof(struct message), 1, fp) != 1)
		fatal("queue_update_database: cannot write database");
	fflush(fp);
	fsync(fd);
	fclose(fp);

	return 1;
}

a1140 92
queue_init_submissions(void)
{
	DIR *dirp;
	struct dirent *dp;
	struct message message;
	char pathname[MAXPATHLEN];
	FILE *fp;
	int spret;

	dirp = opendir(PATH_ENVELOPES);
	if (dirp == NULL)
		err(1, "opendir");

	while ((dp = readdir(dirp)) != NULL) {

		if (dp->d_name[0] == '.')
			continue;

		spret = snprintf(pathname, MAXPATHLEN, "%s/%s", PATH_ENVELOPES,
		    dp->d_name);
		if (spret == -1 || spret >= MAXPATHLEN)
			continue;

		fp = fopen(pathname, "r");
		if (fp == NULL)
			continue;

		if (fread(&message, sizeof(struct message), 1, fp) != 1) {
			fclose(fp);
			continue;
		}
		fclose(fp);

		if ((message.flags & F_MESSAGE_COMPLETE) == 0)
			unlink(pathname);
		else {
			message.flags &= ~F_MESSAGE_PROCESSING;
			queue_update_database(&message);
		}
	}

	closedir(dirp);
	return 1;
}

int
queue_message_complete(struct message *messagep)
{
	DIR *dirp;
	struct dirent *dp;
	struct message message;
	char pathname[MAXPATHLEN];
	FILE *fp;
	int spret;

	dirp = opendir(PATH_ENVELOPES);
	if (dirp == NULL)
		err(1, "opendir");

	while ((dp = readdir(dirp)) != NULL) {

		if (dp->d_name[0] == '.')
			continue;

		if (strncmp(messagep->message_id,
			dp->d_name, strlen(messagep->message_id)) != 0)
			continue;

		spret = snprintf(pathname, MAXPATHLEN, "%s/%s", PATH_ENVELOPES,
		    dp->d_name);
		if (spret == -1 || spret >= MAXPATHLEN)
			continue;

		fp = fopen(pathname, "r");
		if (fp == NULL)
			continue;

		if (fread(&message, sizeof(struct message), 1, fp) != 1) {
			fclose(fp);
			continue;
		}
		fclose(fp);

		message.flags |= F_MESSAGE_COMPLETE;
		queue_update_database(&message);
	}

	closedir(dirp);
	return 1;
}

int
d1155 2
a1156 5

	if ((messagep->flags & F_MESSAGE_READY) == 0)
		return 0;

	if ((messagep->flags & F_MESSAGE_COMPLETE) == 0)
a1191 6
batch_unschedule(struct batch *batchp)
{
	batchp->flags &= ~(F_BATCH_SCHEDULED);
}

void
d1229 1
d1250 516
@


1.15
log
@- when using fread/fwrite, do not swap the size and nmemb arguments. no
	functionnal change here, just making use of fonctions the way C
	intended it ;-)
From Jacek Masiulaniec <jacekm@@dobremiasto.net>
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.14 2008/11/17 21:05:05 gilles Exp $	*/
d1033 1
a1033 1
	batchp->ss_cnt = lookup->ss_cnt;
d1079 2
a1080 2
		for (i = 0; i < batchp->ss_cnt; ++i)
			batchp->ss[i] = lookup->ss[i];
@


1.14
log
@- remove some unused prototypes
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.13 2008/11/17 21:03:33 gilles Exp $	*/
d661 1
a661 2
	if (fread(message, 1, sizeof(struct message), fp) !=
	    sizeof(struct message)) {
a813 1
	int hm;
d873 1
a873 2
		if ((hm = fwrite(message, 1, sizeof(struct message), fp)) !=
		    sizeof(struct message)) {
d1145 1
a1145 2
	if (fwrite(message, 1, sizeof(struct message), fp) !=
	    sizeof(struct message))
d1231 1
a1231 2
		if (fread(&message, 1, sizeof(struct message), fp) !=
		    sizeof(struct message)) {
d1281 1
a1281 2
		if (fread(&message, 1, sizeof(struct message), fp) !=
		    sizeof(struct message)) {
@


1.13
log
@- queue_record_daemon() no longer used, remove definition
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.12 2008/11/17 20:37:48 gilles Exp $	*/
a70 1
void		queue_mailer_daemon(struct smtpd *, struct batch *, enum batch_status);
a72 2
struct batch	*queue_register_daemon_batch(struct smtpd *, struct batch *);
void		queue_register_daemon_message(struct smtpd *, struct batch *, struct message *);
@


1.12
log
@- replace uses of O_EXLOCK and O_EXLOCK|O_NONBLOCK with the corresponding
	open()/flock() constructs as chl@@ says it prevents him from doing
	a portable build.

discussed with chl@@, diff is common work from him and myself
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.11 2008/11/11 21:17:49 gilles Exp $	*/
a73 1
int		queue_record_daemon(struct message *);
a1159 74


int
queue_record_daemon(struct message *message)
{
	char pathname[MAXPATHLEN];
	char linkname[MAXPATHLEN];
	char dbname[MAXPATHLEN];
	char message_uid[MAXPATHLEN];
	size_t spoolsz;
	int fd;
	int mode = O_CREAT|O_TRUNC|O_WRONLY|O_EXCL|O_SYNC;
	int spret;
	FILE *fp;

	spret = snprintf(pathname, MAXPATHLEN, "%s/%s",
	    PATH_MESSAGES, message->message_id);
	if (spret == -1 || spret >= MAXPATHLEN)
		return 0;

	spoolsz = strlen(PATH_DAEMON);

	for (;;) {
		spret = snprintf(linkname, MAXPATHLEN, "%s/%s.%qu",
		    PATH_DAEMON, message->message_id, (u_int64_t)arc4random());
		if (spret == -1 || spret >= MAXPATHLEN)
			return 0;

		if (strlcpy(message_uid, linkname + spoolsz + 1, MAXPATHLEN)
		    >= MAXPATHLEN)
			return 0;

		if (link(pathname, linkname) == -1) {
			if (errno == EEXIST)
				continue;
			err(1, "link");
		}

		spret = snprintf(dbname, MAXPATHLEN, "%s/%s",
		    PATH_ENVELOPES, message_uid);
		if (spret == -1 || spret >= MAXPATHLEN)
			return 0;

		fd = open(dbname, mode, 0600);
		if (fd == -1)
			if (unlink(linkname) == -1)
				err(1, "unlink");

		if (flock(fd, LOCK_EX) == -1)
			err(1, "flock");

		fp = fdopen(fd, "w");
		if (fp == NULL)
			fatal("fdopen");

		(void)strlcpy(message->message_uid, message_uid, MAXPATHLEN);

		message->creation = time(NULL);

		if (fwrite(message, 1, sizeof(struct message), fp) !=
		    sizeof(struct message)) {
			fclose(fp);
			unlink(dbname);
			return 0;
		}
		fflush(fp);
		fsync(fd);
		fclose(fp);
		break;
	}

	return 1;
}

@


1.11
log
@- mistakenly removed this lock
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.10 2008/11/11 21:13:14 gilles Exp $	*/
d816 1
a816 1
	int mode = O_CREAT|O_TRUNC|O_WRONLY|O_EXCL|O_SYNC|O_EXCL;
d866 2
a867 2
//		if (flock(fd, LOCK_EX) == -1)
//			fatal("queue_record_submission: flock");
d1119 1
d1141 1
a1141 1
	if ((fd = open(pathname, O_RDWR|O_EXLOCK)) == -1)
d1144 4
d1172 1
a1172 1
	int mode = O_CREAT|O_TRUNC|O_WRONLY|O_EXCL|O_SYNC|O_EXLOCK;
d1209 2
a1210 2
//		if (flock(fd, LOCK_EX) == -1)
//			err(1, "flock");
@


1.10
log
@- introduce queue_init_submissions() which will sanitize the disk-based
	queue at startup: catches left overs from interrupted sessions,
	reset F_MESSAGE_INPROCESS so that messages which were in MTA or
	MDA gets scheduled again.
- temporarily comment chl@@'s O_EXLOCK -> fcntl change until we figure
	why it locks my mailbox under load
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.9 2008/11/11 01:08:08 gilles Exp $	*/
d1140 1
a1140 1
	if ((fd = open(pathname, O_RDWR)) == -1)
@


1.9
log
@- queue process no longer schedules messages which do not have flag
	F_MESSAGE_COMPLETE
- submit recipients to the queue as we read them from RCPT instead of
	submiting them all at once when DATA is over. this prevents us
	from having to keep a potentially large number of recipients in
	memory during the whole session.
- remove all code that dealt with the recipients queue of a message as
	it is no longer used.
- several small changes to make sure the server is always in a recoverable
	state in case of an unexpected shutdown.
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.8 2008/11/11 01:01:39 chl Exp $	*/
d81 1
a575 1

d577 1
a577 1
		    (batchp->flags & F_BATCH_RESOLVED) == 0)
d579 1
d624 1
a640 1

d728 5
a743 2
	SPLAY_INIT(&env->batch_queue);

d816 1
a816 1
	int mode = O_CREAT|O_TRUNC|O_WRONLY|O_EXCL|O_SYNC;
d866 2
a867 2
		if (flock(fd, LOCK_EX) == -1)
			fatal("queue_record_submission: flock");
a1142 3
	if (flock(fd, LOCK_EX) == -1)
		fatal("queue_update_database: cannot get a lock on database");

d1167 1
a1167 1
	int mode = O_CREAT|O_TRUNC|O_WRONLY|O_EXCL|O_SYNC;
d1204 2
a1205 2
		if (flock(fd, LOCK_EX) == -1)
			err(1, "flock");
d1278 47
@


1.8
log
@remove the use of O_EXLOCK, when open()ing a file, and use flock() instead.

ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.7 2008/11/10 21:29:18 chl Exp $	*/
d80 1
d241 14
d1280 47
d1343 3
@


1.7
log
@rename h_errno field into getaddrinfo_error, to avoid confusion with errno.

h_errno has been obsoleted since the gethostbyname() --> getaddrinfo() replacement.

ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.6 2008/11/10 17:24:24 deraadt Exp $	*/
d797 1
a797 1
	int mode = O_CREAT|O_TRUNC|O_WRONLY|O_EXCL|O_SYNC|O_EXLOCK;
d847 3
d1121 1
a1121 1
	if ((fd = open(pathname, O_RDWR|O_EXLOCK)) == -1)
d1124 3
d1151 1
a1151 1
	int mode = O_CREAT|O_TRUNC|O_WRONLY|O_EXCL|O_SYNC|O_EXLOCK;
d1187 3
@


1.6
log
@spaces fixed while reading code
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.5 2008/11/10 03:16:02 gilles Exp $	*/
d1017 1
a1017 1
	batchp->h_errno = lookup->h_errno;
d1031 1
a1031 1
	switch (batchp->h_errno) {
@


1.5
log
@- in queue, do not use the atomic api when dealing with real files
	change based on a comment from deraadt@@

- in queue_register_submission(), if an envelope cannot be fully written
	because of some error (ie: disk full), not only return error but
	also remove the partial envelope from file system. this prevents
	the queue process from trying (failing) to reload it over and
	over.
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.4 2008/11/10 01:14:05 gilles Exp $	*/
a817 1
	
d1201 1
a1201 1
	
@


1.4
log
@- in queue_load_submissions(), if queue_message_from_id() fails for some
	reason just warn instead of aborting the whole smtpd.
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.3 2008/11/10 00:57:35 gilles Exp $	*/
d633 1
d635 1
a635 3
	int fd;
	int ret;
	int spret;
d643 3
a645 3
	fd = open(pathname, O_RDONLY);
	if (fd == -1) {
		warnx("queue_load_submissions: open: %s", message_id);
d649 3
a651 3
	ret = atomic_read(fd, message, sizeof(struct message));
	if (ret != sizeof(struct message)) {
		warnx("queue_load_submissions: atomic_read: %s", message_id);
d655 1
a655 1
	close(fd);
d658 2
a659 2
	if (fd != -1)
		close(fd);
d799 2
d848 4
d858 4
a861 3
		if (atomic_write(fd, message, sizeof(struct message))
		    != sizeof(struct message)) {
			close(fd);
d864 4
a867 1
		close(fd);
d1097 1
d1122 10
a1131 4
	if (atomic_write(fd, message, sizeof (struct message)) == -1)
		fatal("queue_update_database: cannot open database");

	close(fd);
d1148 1
d1183 4
d1191 9
a1199 2
		atomic_write(fd, message, sizeof(*message));
		close(fd);
d1202 1
a1202 1

@


1.3
log
@- snprintf() can return -1, make sure every call is checked properly
@
text
@d1 1
a1 1
/*	$OpenBSD: queue.c,v 1.2 2008/11/05 12:14:45 sobrado Exp $	*/
d596 4
a599 2
		if (! queue_message_from_id(dp->d_name, &message))
			errx(1, "failed to load message");
@


1.2
log
@add a few missing id tags; there are a bunch of files, and developers
will probably miss this change when working on more important matters,
so it is probably better to sort them now.  there is a risk of losing
the tags if a change needs to be reverted too.

written with excellent advice from jmc@@

ok gilles@@
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d634 1
d636 2
a637 2
	if (snprintf(pathname, MAXPATHLEN, "%s/%s", PATH_ENVELOPES, message_id)
	    >= MAXPATHLEN) {
d753 1
d755 3
a757 2
	if (snprintf(pathname, MAXPATHLEN, "%s/%d.XXXXXXXXXXXXXXXX",
		PATH_MESSAGES, time(NULL)) >= MAXPATHLEN)
d776 1
d778 2
a779 2
	if (snprintf(pathname, MAXPATHLEN, "%s/%s", PATH_MESSAGES, message_id)
	    >= MAXPATHLEN)
d797 1
d815 4
a818 2
	if (snprintf(pathname, MAXPATHLEN, "%s/%s", PATH_MESSAGES,
		message->message_id) >= MAXPATHLEN)
d822 3
a824 3
		if (snprintf(linkname, MAXPATHLEN, "%s/%s.%qu", spool,
			message->message_id, (u_int64_t)arc4random())
		    >= MAXPATHLEN)
d835 3
a837 2
		if (snprintf(dbname, MAXPATHLEN, "%s/%s", PATH_ENVELOPES,
			message_uid) >= MAXPATHLEN)
d926 1
d943 3
a945 2
	if (snprintf(dbname, MAXPATHLEN, "%s/%s", PATH_ENVELOPES,
		message->message_uid) >= MAXPATHLEN)
d948 3
a950 2
	if (snprintf(linkname, MAXPATHLEN, "%s/%s", spool,
		message->message_uid) >= MAXPATHLEN)
d953 3
a955 2
	if (snprintf(pathname, MAXPATHLEN, "%s/%s", PATH_MESSAGES,
		message->message_id) >= MAXPATHLEN)
d1065 1
d1067 3
a1069 2
	if (snprintf(pathname, MAXPATHLEN, "%s/%s", PATH_MESSAGES,
		batch->message_id) >= MAXPATHLEN)
d1085 1
d1102 3
a1104 2
	if (snprintf(pathname, MAXPATHLEN, "%s/%s", PATH_ENVELOPES,
		message->message_uid) >= MAXPATHLEN)
d1129 1
d1131 1
a1131 1
	(void)snprintf(pathname, MAXPATHLEN, "%s/%s",
d1133 2
d1139 1
a1139 1
		(void)snprintf(linkname, MAXPATHLEN, "%s/%s.%qu",
d1141 6
a1146 1
		(void)strlcpy(message_uid, linkname + spoolsz + 1, MAXPATHLEN);
d1154 1
a1154 1
		(void)snprintf(dbname, MAXPATHLEN, "%s/%s",
d1156 2
@


1.1
log
@smtpd is a smtp server implementation for OpenBSD. It is a work in progress
which still lacks many features. bringing it in tree will help working on it
more easily.

"at this stage it should go in" henning@@, "move ahead" deraadt@@
@
text
@d1 2
@

