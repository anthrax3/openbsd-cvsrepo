head	1.20;
access;
symbols
	OPENBSD_5_5:1.19.0.26
	OPENBSD_5_5_BASE:1.19
	OPENBSD_5_4:1.19.0.22
	OPENBSD_5_4_BASE:1.19
	OPENBSD_5_3:1.19.0.20
	OPENBSD_5_3_BASE:1.19
	OPENBSD_5_2:1.19.0.18
	OPENBSD_5_2_BASE:1.19
	OPENBSD_5_1_BASE:1.19
	OPENBSD_5_1:1.19.0.16
	OPENBSD_5_0:1.19.0.14
	OPENBSD_5_0_BASE:1.19
	OPENBSD_4_9:1.19.0.12
	OPENBSD_4_9_BASE:1.19
	OPENBSD_4_8:1.19.0.10
	OPENBSD_4_8_BASE:1.19
	OPENBSD_4_7:1.19.0.6
	OPENBSD_4_7_BASE:1.19
	OPENBSD_4_6:1.19.0.8
	OPENBSD_4_6_BASE:1.19
	OPENBSD_4_5:1.19.0.4
	OPENBSD_4_5_BASE:1.19
	OPENBSD_4_4:1.19.0.2
	OPENBSD_4_4_BASE:1.19
	OPENBSD_4_3:1.16.0.8
	OPENBSD_4_3_BASE:1.16
	OPENBSD_4_2:1.16.0.6
	OPENBSD_4_2_BASE:1.16
	OPENBSD_4_1:1.16.0.4
	OPENBSD_4_1_BASE:1.16
	OPENBSD_4_0:1.16.0.2
	OPENBSD_4_0_BASE:1.16
	OPENBSD_3_9:1.15.0.6
	OPENBSD_3_9_BASE:1.15
	OPENBSD_3_8:1.15.0.4
	OPENBSD_3_8_BASE:1.15
	OPENBSD_3_7:1.15.0.2
	OPENBSD_3_7_BASE:1.15
	OPENBSD_3_6:1.13.0.4
	OPENBSD_3_6_BASE:1.13
	OPENBSD_3_5:1.13.0.2
	OPENBSD_3_5_BASE:1.13
	apache_1_3_29-mod_ssl_2_8_16:1.1.1.5
	OPENBSD_3_4:1.12.0.2
	OPENBSD_3_4_BASE:1.12
	apache_1_3_28-mod_ssl_2_8_15:1.1.1.4
	OPENBSD_3_3:1.9.0.2
	OPENBSD_3_3_BASE:1.9
	apache_1_3_27-mod_ssl_2_8_12:1.1.1.3
	apache_1_3_27:1.1.1.3
	OPENBSD_3_2:1.8.0.4
	OPENBSD_3_2_BASE:1.8
	apache_1_3_26:1.1.1.2
	OPENBSD_3_1:1.8.0.2
	OPENBSD_3_1_BASE:1.8
	OPENBSD_3_0:1.7.0.4
	OPENBSD_3_0_BASE:1.7
	OPENBSD_2_9_BASE:1.7
	OPENBSD_2_9:1.7.0.2
	OPENBSD_2_8:1.5.0.4
	OPENBSD_2_8_BASE:1.5
	OPENBSD_2_7:1.5.0.2
	OPENBSD_2_7_BASE:1.5
	OPENBSD_2_6:1.4.0.2
	OPENBSD_2_6_BASE:1.4
	OPENBSD_2_5:1.3.0.2
	OPENBSD_2_5_BASE:1.3
	OPENBSD_2_4:1.2.0.2
	OPENBSD_2_4_BASE:1.2
	apache_1_3_2:1.1.1.1
	apache:1.1.1;
locks; strict;
comment	@ * @;


1.20
date	2014.04.22.14.47.26;	author henning;	state dead;
branches;
next	1.19;

1.19
date	2008.05.23.08.41.48;	author mbalmer;	state Exp;
branches;
next	1.18;

1.18
date	2008.05.14.08.42.20;	author mbalmer;	state Exp;
branches;
next	1.17;

1.17
date	2008.05.13.17.44.46;	author mbalmer;	state Exp;
branches;
next	1.16;

1.16
date	2006.04.04.12.50.02;	author henning;	state Exp;
branches;
next	1.15;

1.15
date	2005.02.09.12.13.09;	author henning;	state Exp;
branches;
next	1.14;

1.14
date	2004.12.02.19.42.46;	author henning;	state Exp;
branches;
next	1.13;

1.13
date	2003.11.17.18.57.05;	author henning;	state Exp;
branches;
next	1.12;

1.12
date	2003.08.21.13.45.05;	author henning;	state Exp;
branches;
next	1.11;

1.11
date	2003.08.21.13.11.35;	author henning;	state Exp;
branches;
next	1.10;

1.10
date	2003.04.08.16.21.54;	author henning;	state Exp;
branches;
next	1.9;

1.9
date	2002.10.07.20.23.06;	author henning;	state Exp;
branches;
next	1.8;

1.8
date	2002.03.29.02.08.05;	author beck;	state Exp;
branches;
next	1.7;

1.7
date	2001.03.29.10.21.42;	author beck;	state Exp;
branches;
next	1.6;

1.6
date	2000.12.15.22.18.05;	author beck;	state Exp;
branches;
next	1.5;

1.5
date	2000.01.25.18.29.45;	author beck;	state Exp;
branches;
next	1.4;

1.4
date	99.09.29.06.29.35;	author beck;	state Exp;
branches;
next	1.3;

1.3
date	99.03.01.01.06.04;	author beck;	state Exp;
branches;
next	1.2;

1.2
date	98.10.11.19.45.11;	author beck;	state Exp;
branches;
next	1.1;

1.1
date	98.10.01.17.19.39;	author beck;	state Exp;
branches
	1.1.1.1;
next	;

1.1.1.1
date	98.10.01.17.19.39;	author beck;	state Exp;
branches;
next	1.1.1.2;

1.1.1.2
date	2002.07.19.21.28.41;	author henning;	state Exp;
branches;
next	1.1.1.3;

1.1.1.3
date	2002.10.07.19.48.12;	author henning;	state Exp;
branches;
next	1.1.1.4;

1.1.1.4
date	2003.08.21.12.53.39;	author henning;	state Exp;
branches;
next	1.1.1.5;

1.1.1.5
date	2003.11.17.17.03.21;	author henning;	state Exp;
branches;
next	;


desc
@@


1.20
log
@this commit is really florian@@'s, since he's the one who made removal
of our forked apache possible by his work on nginx and slowcgi, but he
doesn't want it - so it is my pleasure to tedu it. I spent so much work
on chroot in it 10 years ago - and am very happy to see it go now, nginx
is a far better choice today.
Bye bye, Apache, won't miss you.
@
text
@/*	$OpenBSD: alloc.c,v 1.19 2008/05/23 08:41:48 mbalmer Exp $ */

/* ====================================================================
 * The Apache Software License, Version 1.1
 *
 * Copyright (c) 2000-2003 The Apache Software Foundation.  All rights
 * reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 *
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 *
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in
 *    the documentation and/or other materials provided with the
 *    distribution.
 *
 * 3. The end-user documentation included with the redistribution,
 *    if any, must include the following acknowledgment:
 *       "This product includes software developed by the
 *        Apache Software Foundation (http://www.apache.org/)."
 *    Alternately, this acknowledgment may appear in the software itself,
 *    if and wherever such third-party acknowledgments normally appear.
 *
 * 4. The names "Apache" and "Apache Software Foundation" must
 *    not be used to endorse or promote products derived from this
 *    software without prior written permission. For written
 *    permission, please contact apache@@apache.org.
 *
 * 5. Products derived from this software may not be called "Apache",
 *    nor may "Apache" appear in their name, without prior written
 *    permission of the Apache Software Foundation.
 *
 * THIS SOFTWARE IS PROVIDED ``AS IS'' AND ANY EXPRESSED OR IMPLIED
 * WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
 * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 * DISCLAIMED.  IN NO EVENT SHALL THE APACHE SOFTWARE FOUNDATION OR
 * ITS CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
 * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF
 * USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
 * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT
 * OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
 * ====================================================================
 *
 * This software consists of voluntary contributions made by many
 * individuals on behalf of the Apache Software Foundation.  For more
 * information on the Apache Software Foundation, please see
 * <http://www.apache.org/>.
 *
 * Portions of this software are based upon public domain software
 * originally written at the National Center for Supercomputing Applications,
 * University of Illinois, Urbana-Champaign.
 */

/*
 * Resource allocation code... the code here is responsible for making
 * sure that nothing leaks.
 *
 * rst --- 4/95 --- 6/95
 */

#include "httpd.h"
#include "http_config.h"
#include "http_conf_globals.h"
#include "multithread.h"
#include "http_log.h"

#include <stdarg.h>

/* debugging support, define this to enable code which helps detect re-use
 * of freed memory and other such nonsense.
 *
 * The theory is simple.  The FILL_BYTE (0xa5) is written over all malloc'd
 * memory as we receive it, and is written over everything that we free up
 * during a clear_pool.  We check that blocks on the free list always
 * have the FILL_BYTE in them, and we check during palloc() that the bytes
 * still have FILL_BYTE in them.  If you ever see garbage URLs or whatnot
 * containing lots of 0xa5s then you know something used data that's been
 * freed or uninitialized.
 */
/* #define ALLOC_DEBUG */

/* debugging support, if defined all allocations will be done with
 * malloc and free()d appropriately at the end.  This is intended to be
 * used with something like Electric Fence or Purify to help detect
 * memory problems.  Note that if you're using efence then you should also
 * add in ALLOC_DEBUG.  But don't add in ALLOC_DEBUG if you're using Purify
 * because ALLOC_DEBUG would hide all the uninitialized read errors that
 * Purify can diagnose.
 */
/* #define ALLOC_USE_MALLOC */

/* Pool debugging support.  This is intended to detect cases where the
 * wrong pool is used when assigning data to an object in another pool.
 * In particular, it causes the table_{set,add,merge}n routines to check
 * that their arguments are safe for the table they're being placed in.
 * It currently only works with the unix multiprocess model, but could
 * be extended to others.
 */
/* #define POOL_DEBUG */

/* Provide diagnostic information about make_table() calls which are
 * possibly too small.  This requires a recent gcc which supports
 * __builtin_return_address().  The error_log output will be a
 * message such as:
 *    table_push: table created by 0x804d874 hit limit of 10
 * Use "l *0x804d874" to find the source that corresponds to.  It
 * indicates that a table allocated by a call at that address has
 * possibly too small an initial table size guess.
 */
/* #define MAKE_TABLE_PROFILE */

#ifdef POOL_DEBUG
#ifdef ALLOC_USE_MALLOC
# error "sorry, no support for ALLOC_USE_MALLOC and POOL_DEBUG at the same time"
#endif
#endif

#ifdef ALLOC_USE_MALLOC
#undef BLOCK_MINFREE
#undef BLOCK_MINALLOC
#define BLOCK_MINFREE	0
#define BLOCK_MINALLOC	0
#endif

#if defined(EAPI_MM)
static AP_MM *mm = NULL;
#endif

/*****************************************************************
 *
 * Managing free storage blocks...
 */

union align {
	/*
	 * Types which are likely to have the longest RELEVANT alignment
	 * restrictions...
	 */
	char	*cp;
	void	(*f)(void);
	long	 l;
	FILE	*fp;
	double	 d;
};

#define CLICK_SZ (sizeof(union align))

union block_hdr {
	union align a;

	/* Actual header... */

	struct {
		char		*endp;
		union		 block_hdr *next;
		char		*first_avail;
#if defined(EAPI_MM)
		int		 is_shm;
#endif
#ifdef POOL_DEBUG
		union block_hdr	*global_next;
		struct pool	*owning_pool;
#endif
	} h;
};

static union block_hdr *block_freelist = NULL;
static mutex *alloc_mutex = NULL;
static mutex *spawn_mutex = NULL;
#ifdef POOL_DEBUG
static char *known_stack_point;
static int stack_direction;
static union block_hdr *global_block_list;
#define FREE_POOL	((struct pool *)(-1))
#endif

#ifdef ALLOC_DEBUG
#define FILL_BYTE	((char)(0xa5))

#define debug_fill(ptr,size)	((void)memset((ptr), FILL_BYTE, (size)))

static ap_inline void
debug_verify_filled(const char *ptr, const char *endp, const char *error_msg)
{
	for (; ptr < endp; ++ptr) {
		if (*ptr != FILL_BYTE) {
			fputs(error_msg, stderr);
			abort();
			exit(1);
		}
	}
}

#else
#define debug_fill(a,b)
#define debug_verify_filled(a,b,c)
#endif


/* Get a completely new block from the system pool. Note that we rely on
   malloc() to provide aligned memory. */

#if defined(EAPI_MM)
static union block_hdr
*malloc_block(int size, int is_shm)
#else
static union block_hdr
*malloc_block(int size)
#endif
{
	union block_hdr *blok;
	int request_size;

#ifdef ALLOC_DEBUG
	/*
	 * make some room at the end which we'll fill and expect to be
	 * always filled
	 */
	size += CLICK_SZ;
#endif
	request_size = size + sizeof(union block_hdr);
#if defined(EAPI_MM)
	if (is_shm)
		blok = (union block_hdr *)ap_mm_malloc(mm, request_size);
	else
#endif
		blok = (union block_hdr *) malloc(request_size);
	if (blok == NULL) {
		fprintf(stderr, "Ouch!  malloc(%d) failed in malloc_block()\n",
		    request_size);
		exit(1);
	}
	debug_fill(blok, size + sizeof(union block_hdr));
#if defined(EAPI_MM)
	blok->h.is_shm = is_shm;
#endif
	blok->h.next = NULL;
	blok->h.first_avail = (char *)(blok + 1);
	blok->h.endp = size + blok->h.first_avail;
#ifdef ALLOC_DEBUG
	blok->h.endp -= CLICK_SZ;
#endif
#ifdef POOL_DEBUG
	blok->h.global_next = global_block_list;
	global_block_list = blok;
	blok->h.owning_pool = NULL;
#endif

	return blok;
}

#if defined(ALLOC_DEBUG) && !defined(ALLOC_USE_MALLOC)
static void
chk_on_blk_list(union block_hdr *blok, union block_hdr *free_blk)
{
	debug_verify_filled(blok->h.endp, blok->h.endp + CLICK_SZ,
	    "Ouch!  Someone trounced the padding at the end of a block!\n");
	while (free_blk) {
		if (free_blk == blok) {
			fprintf(stderr, "Ouch!  Freeing free block\n");
			abort();
			exit(1);
		}
		free_blk = free_blk->h.next;
	}
}
#else
#define chk_on_blk_list(_x, _y)
#endif

/* Free a chain of blocks --- must be called with alarms blocked. */
static void
free_blocks(union block_hdr *blok)
{
#ifdef ALLOC_USE_MALLOC
	union block_hdr *next;

	for (; blok; blok = next) {
		next = blok->h.next;
		free(blok);
	}
#else
	/*
	 * First, put new blocks at the head of the free list ---
	 * we'll eventually bash the 'next' pointer of the last block
	 * in the chain to point to the free blocks we already had.
	 */
	union block_hdr *old_free_list;

	/* Sanity check --- freeing empty pool? */
	if (blok == NULL)
		return;

#if defined(EAPI_MM)
	if (blok->h.is_shm)
		(void)ap_mm_lock(mm, AP_MM_LOCK_RW);
#endif
	(void) ap_acquire_mutex(alloc_mutex);
	old_free_list = block_freelist;
	block_freelist = blok;

	/*
	 * Next, adjust first_avail pointers of each block --- have to do it
	 * sooner or later, and it simplifies the search in new_block to do it
	 * now.
	 */
	while (blok->h.next != NULL) {
		chk_on_blk_list(blok, old_free_list);
		blok->h.first_avail = (char *)(blok + 1);
		debug_fill(blok->h.first_avail,
		    blok->h.endp - blok->h.first_avail);
#ifdef POOL_DEBUG
		blok->h.owning_pool = FREE_POOL;
#endif
		blok = blok->h.next;
	}

	chk_on_blk_list(blok, old_free_list);
	blok->h.first_avail = (char *)(blok + 1);
	debug_fill(blok->h.first_avail, blok->h.endp - blok->h.first_avail);
#ifdef POOL_DEBUG
	blok->h.owning_pool = FREE_POOL;
#endif

	/* Finally, reset next pointer to get the old free blocks back */
	blok->h.next = old_free_list;

	(void) ap_release_mutex(alloc_mutex);
#if defined(EAPI_MM)
	if (blok->h.is_shm)
		(void)ap_mm_unlock(mm);
#endif
#endif
}


/* 
 * Get a new block, from our own free list if possible, from the system
 * if necessary.  Must be called with alarms blocked.
 */
#if defined(EAPI_MM)
static union block_hdr
*new_block(int min_size, int is_shm)
#else
static union block_hdr
*new_block(int min_size)
#endif
{
	union block_hdr **lastptr = &block_freelist;
	union block_hdr *blok = block_freelist;

	/*
	 * First, see if we have anything of the required size
	 * on the free list...
	 */
	while (blok != NULL) {
#if defined(EAPI_MM)
		if (blok->h.is_shm == is_shm &&
		    min_size + BLOCK_MINFREE <= blok->h.endp -
		    blok->h.first_avail) {
#else
		if (min_size + BLOCK_MINFREE <= blok->h.endp -
		    blok->h.first_avail) {
#endif
			*lastptr = blok->h.next;
			blok->h.next = NULL;
			debug_verify_filled(blok->h.first_avail, blok->h.endp,
			    "Ouch!  Someone trounced a block on the free "
			    "list!\n");
			return blok;
		}
		else {
			lastptr = &blok->h.next;
			blok = blok->h.next;
		}
	}

	/* Nope. */
	min_size += BLOCK_MINFREE;
#if defined(EAPI_MM)
	blok = malloc_block((min_size > BLOCK_MINALLOC) ?
	    min_size : BLOCK_MINALLOC, is_shm);
#else
	blok = malloc_block((min_size > BLOCK_MINALLOC) ?
	    min_size : BLOCK_MINALLOC);
#endif
	return blok;
}


/* Accounting */
static long
bytes_in_block_list(union block_hdr *blok)
{
	long size = 0;

	while (blok) {
		size += blok->h.endp - (char *)(blok + 1);
		blok = blok->h.next;
	}

	return size;
}


/*****************************************************************
 *
 * Pool internals and management...
 * NB that subprocesses are not handled by the generic cleanup code,
 * basically because we don't want cleanups for multiple subprocesses
 * to result in multiple three-second pauses.
 */

struct process_chain;
struct cleanup;

static void run_cleanups(struct cleanup *);
static void free_proc_chain(struct process_chain *);

struct pool {
	union block_hdr		*first;
	union block_hdr		*last;
	struct cleanup		*cleanups;
	struct process_chain	*subprocesses;
	struct pool		*sub_pools;
	struct pool		*sub_next;
	struct pool		*sub_prev;
	struct pool		*parent;
	char			*free_first_avail;
#ifdef ALLOC_USE_MALLOC
	void			*allocation_list;
#endif
#ifdef POOL_DEBUG
	struct pool		*joined;
#endif
#if defined(EAPI_MM)
	int			 is_shm;
#endif
};

static pool *permanent_pool;

/* Each pool structure is allocated in the start of its own first block,
 * so we need to know how many bytes that is (once properly aligned...).
 * This also means that when a pool's sub-pool is destroyed, the storage
 * associated with it is *completely* gone, so we have to make sure it
 * gets taken off the parent's sub-pool list...
 */

#define POOL_HDR_CLICKS (1 + ((sizeof(struct pool) - 1) / CLICK_SZ))
#define POOL_HDR_BYTES (POOL_HDR_CLICKS * CLICK_SZ)

#if defined(EAPI_MM)
static struct pool
*make_sub_pool_internal(struct pool *p, int is_shm)
#else
API_EXPORT(struct pool *)
ap_make_sub_pool(struct pool *p)
#endif
{
	union block_hdr *blok;
	pool *new_pool;

	ap_block_alarms();

#if defined(EAPI_MM)
	if (is_shm)
		(void)ap_mm_lock(mm, AP_MM_LOCK_RW);
#endif
	(void) ap_acquire_mutex(alloc_mutex);

#if defined(EAPI_MM)
	blok = new_block(POOL_HDR_BYTES, is_shm);
#else
	blok = new_block(POOL_HDR_BYTES);
#endif
	new_pool = (pool *)blok->h.first_avail;
	blok->h.first_avail += POOL_HDR_BYTES;
#ifdef POOL_DEBUG
	blok->h.owning_pool = new_pool;
#endif

	memset((char *)new_pool, '\0', sizeof(struct pool));
	new_pool->free_first_avail = blok->h.first_avail;
	new_pool->first = new_pool->last = blok;

	if (p) {
		new_pool->parent = p;
		new_pool->sub_next = p->sub_pools;
		if (new_pool->sub_next)
			new_pool->sub_next->sub_prev = new_pool;
		p->sub_pools = new_pool;
	}

#if defined(EAPI_MM)
	new_pool->is_shm = is_shm;
#endif

	(void)ap_release_mutex(alloc_mutex);
#if defined(EAPI_MM)
	if (is_shm)
		(void)ap_mm_unlock(mm);
#endif
	ap_unblock_alarms();

	return new_pool;
}

#if defined(EAPI_MM)
API_EXPORT(struct pool *)
ap_make_sub_pool(struct pool *p)
{
	return make_sub_pool_internal(p, 0);
}
API_EXPORT(struct pool *)
ap_make_shared_sub_pool(struct pool *p)
{
	return make_sub_pool_internal(p, 1);
}
#else
API_EXPORT(struct pool *)
ap_make_shared_sub_pool(struct pool *p)
{
	return NULL;
}
#endif

#ifdef POOL_DEBUG
static void
stack_var_init(char *s)
{
	char t;

	if (s < &t)
		stack_direction = 1; /* stack grows up */
	else
		stack_direction = -1; /* stack grows down */
}
#endif

int
ap_shared_pool_possible(void)
{
	return ap_mm_useable();
}

API_EXPORT(pool *)
ap_init_alloc(void)
{
#ifdef POOL_DEBUG
	char s;

	known_stack_point = &s;
	stack_var_init(&s);
#endif
	alloc_mutex = ap_create_mutex(NULL);
	spawn_mutex = ap_create_mutex(NULL);
	permanent_pool = ap_make_sub_pool(NULL);
	return permanent_pool;
}

void
ap_init_alloc_shared(int early)
{
#if defined(EAPI_MM)
	int mm_size;
	char *mm_path;
	char *err1, *err2;

	if (early) {
		/* process very early on startup */
		mm_size = ap_mm_maxsize();
		if (mm_size > EAPI_MM_CORE_MAXSIZE)
			mm_size = EAPI_MM_CORE_MAXSIZE;
		mm_path = ap_server_root_relative(permanent_pool, 
		ap_psprintf(permanent_pool, "%s.%ld", 
		EAPI_MM_CORE_PATH, (long)getpid()));
		if ((mm = ap_mm_create(mm_size, mm_path)) == NULL) {
			fprintf(stderr, "Ouch! ap_mm_create(%d, \"%s\") "
			    "failed\n", mm_size, mm_path);
			err1 = ap_mm_error();
			if (err1 == NULL)
				err1 = "-unknown-";
			err2 = strerror(errno);
			if (err2 == NULL)
				err2 = "-unknown-";
			fprintf(stderr, "Error: MM: %s: OS: %s\n", err1, err2);
			exit(1);
		}
	} else {
		/* process a lot later on startup */
		ap_mm_permission(mm, (S_IRUSR|S_IWUSR), ap_user_id, -1);
	}
#endif /* EAPI_MM */
	return; 
}

void
ap_kill_alloc_shared(void)
{
#if defined(EAPI_MM)
	if (mm != NULL) {
		ap_mm_destroy(mm);
		mm = NULL;
	}
#endif /* EAPI_MM */
	return;
}

void
ap_cleanup_alloc(void)
{
	ap_destroy_mutex(alloc_mutex);
	ap_destroy_mutex(spawn_mutex);
}

API_EXPORT(void)
ap_clear_pool(struct pool *a)
{
	ap_block_alarms();

#if defined(EAPI_MM)
	if (a->is_shm)
		(void)ap_mm_lock(mm, AP_MM_LOCK_RW);
#endif
	(void) ap_acquire_mutex(alloc_mutex);
	while (a->sub_pools)
		ap_destroy_pool(a->sub_pools);
	(void) ap_release_mutex(alloc_mutex);
#if defined(EAPI_MM)
	if (a->is_shm)
	(	void)ap_mm_unlock(mm);
#endif
	/* Don't hold the mutex during cleanups. */
	run_cleanups(a->cleanups);
	a->cleanups = NULL;
	free_proc_chain(a->subprocesses);
	a->subprocesses = NULL;
	free_blocks(a->first->h.next);
	a->first->h.next = NULL;

	a->last = a->first;
	a->first->h.first_avail = a->free_first_avail;
	debug_fill(a->first->h.first_avail,
	a->first->h.endp - a->first->h.first_avail);

#ifdef ALLOC_USE_MALLOC
	{
		void *c, *n;

		for (c = a->allocation_list; c; c = n) {
			n = *(void **)c;
			free(c);
		}
		a->allocation_list = NULL;
	}
#endif

	ap_unblock_alarms();
}

API_EXPORT(void)
ap_destroy_pool(pool *a)
{
	ap_block_alarms();
	ap_clear_pool(a);

#if defined(EAPI_MM)
	if (a->is_shm)
		(void)ap_mm_lock(mm, AP_MM_LOCK_RW);
#endif
	(void)ap_acquire_mutex(alloc_mutex);
	if (a->parent) {
		if (a->parent->sub_pools == a)
			a->parent->sub_pools = a->sub_next;
		if (a->sub_prev)
			a->sub_prev->sub_next = a->sub_next;
		if (a->sub_next)
			a->sub_next->sub_prev = a->sub_prev;
	}
	(void)ap_release_mutex(alloc_mutex);
#if defined(EAPI_MM)
	if (a->is_shm)
		(void)ap_mm_unlock(mm);
#endif

	free_blocks(a->first);
	ap_unblock_alarms();
}

API_EXPORT(long)
ap_bytes_in_pool(pool *p)
{
	return bytes_in_block_list(p->first);
}
API_EXPORT(long)
ap_bytes_in_free_blocks(void)
{
	return bytes_in_block_list(block_freelist);
}

API_EXPORT(int)
ap_acquire_pool(pool *p, ap_pool_lock_mode mode)
{
#if defined(EAPI_MM)
	if (!p->is_shm)
		return 1;
	return ap_mm_lock(mm, mode == AP_POOL_RD ?
	    AP_MM_LOCK_RD : AP_MM_LOCK_RW);
#else
	return 1;
#endif
}

API_EXPORT(int)
ap_release_pool(pool *p)
{
#if defined(EAPI_MM)
	if (!p->is_shm)
		return 1;
	return ap_mm_unlock(mm);
#else
	return 1;
#endif
}

/*****************************************************************
 * POOL_DEBUG support
 */
#ifdef POOL_DEBUG

/* the unix linker defines this symbol as the last byte + 1 of
 * the executable... so it includes TEXT, BSS, and DATA
 */
extern char _end;

/* is ptr in the range [lo,hi) */
#define is_ptr_in_range(ptr, lo, hi)	\
    (((unsigned long)(ptr) - (unsigned long)(lo)) \
	< \
	(unsigned long)(hi) - (unsigned long)(lo))

/* Find the pool that ts belongs to, return NULL if it doesn't
 * belong to any pool.
 */
API_EXPORT(pool *)
ap_find_pool(const void *ts)
{
	const char *s = ts;
	union block_hdr **pb;
	union block_hdr *b;

	/* short-circuit stuff which is in TEXT, BSS, or DATA */
	if (is_ptr_in_range(s, 0, &_end))
		return NULL;

	/* consider stuff on the stack to also be in the NULL pool...
	* XXX: there's cases where we don't want to assume this
	*/
	if ((stack_direction == -1 &&
	    is_ptr_in_range(s, &ts, known_stack_point))
	    || (stack_direction == 1 &&
	    is_ptr_in_range(s, known_stack_point, &ts))) {
		abort();
		return NULL;
	}
	ap_block_alarms();
	/* search the global_block_list */
	for (pb = &global_block_list; *pb; pb = &b->h.global_next) {
		b = *pb;
		if (is_ptr_in_range(s, b, b->h.endp)) {
			if (b->h.owning_pool == FREE_POOL) {
				fprintf(stderr,
				    "Ouch!  find_pool() called on pointer in "
				    "a free block\n");
				abort();
				exit(1);
			}
			if (b != global_block_list) {
				/* 
				 * promote b to front of list, this is a
				 * hack to speed up the lookup
				 */
				*pb = b->h.global_next;
				b->h.global_next = global_block_list;
				global_block_list = b;
			}
			ap_unblock_alarms();
			return b->h.owning_pool;
		}
	}
	ap_unblock_alarms();
	return NULL;
}

/* return TRUE iff a is an ancestor of b
 * NULL is considered an ancestor of all pools
 */
API_EXPORT(int)
ap_pool_is_ancestor(pool *a, pool *b)
{
	if (a == NULL)
		return 1;

	while (a->joined)
		a = a->joined;

	while (b) {
		if (a == b)
			return 1;
		b = b->parent;
	}
	return 0;
}

/* All blocks belonging to sub will be changed to point to p
 * instead.  This is a guarantee by the caller that sub will not
 * be destroyed before p is.
 */
API_EXPORT(void)
ap_pool_join(pool *p, pool *sub)
{
	union block_hdr *b;

	/* We could handle more general cases... but this is it for now. */
	if (sub->parent != p) {
		fprintf(stderr, "pool_join: p is not parent of sub\n");
		abort();
	}
	ap_block_alarms();
	while (p->joined)
		p = p->joined;

	sub->joined = p;
	for (b = global_block_list; b; b = b->h.global_next) {
		if (b->h.owning_pool == sub)
			b->h.owning_pool = p;
	}
	ap_unblock_alarms();
}
#endif

/*****************************************************************
 *
 * Allocating stuff...
 */


API_EXPORT(void *)
ap_palloc(struct pool *a, int reqsize)
{
#ifdef ALLOC_USE_MALLOC
	int size = reqsize + CLICK_SZ;
	void *ptr;

	ap_block_alarms();
	ptr = malloc(size);
	if (ptr == NULL) {
		fputs("Ouch!  Out of memory!\n", stderr);
		exit(1);
	}
	debug_fill(ptr, size); /* might as well get uninitialized protection */
	*(void **)ptr = a->allocation_list;
	a->allocation_list = ptr;
	ap_unblock_alarms();
	return (char *)ptr + CLICK_SZ;
#else

	/*
	 * Round up requested size to an even number of alignment units
	 * (core clicks)
	 */
	int nclicks = 1 + ((reqsize - 1) / CLICK_SZ);
	int size = nclicks * CLICK_SZ;

	/*
	 * First, see if we have space in the block most recently
	 * allocated to this pool
	 */
	union block_hdr *blok = a->last;
	char *first_avail = blok->h.first_avail;
	char *new_first_avail;

	if (reqsize <= 0)
		return NULL;

	new_first_avail = first_avail + size;

	if (new_first_avail <= blok->h.endp) {
		debug_verify_filled(first_avail, blok->h.endp,
		    "Ouch!  Someone trounced past the end of their "
		    "allocation!\n");
		blok->h.first_avail = new_first_avail;
		return (void *)first_avail;
	}

	/* Nope --- get a new one that's guaranteed to be big enough */
	ap_block_alarms();

#if defined(EAPI_MM)
	if (a->is_shm)
		(void)ap_mm_lock(mm, AP_MM_LOCK_RW);
#endif
	(void) ap_acquire_mutex(alloc_mutex);

#if defined(EAPI_MM)
	blok = new_block(size, a->is_shm);
#else
	blok = new_block(size);
#endif
	a->last->h.next = blok;
	a->last = blok;
#ifdef POOL_DEBUG
	blok->h.owning_pool = a;
#endif
#if defined(EAPI_MM)
	blok->h.is_shm = a->is_shm;
#endif

	(void)ap_release_mutex(alloc_mutex);
#if defined(EAPI_MM)
	if (a->is_shm)
		(void)ap_mm_unlock(mm);
#endif

	ap_unblock_alarms();

	first_avail = blok->h.first_avail;
	blok->h.first_avail += size;

	return (void *)first_avail;
#endif
}

API_EXPORT(void *)
ap_pcalloc(struct pool *a, int size)
{
	void *res = ap_palloc(a, size);
	memset(res, '\0', size);
	return res;
}

API_EXPORT(char *)
ap_pstrdup(struct pool *a, const char *s)
{
	char *res;
	size_t len;

	if (s == NULL)
		return NULL;
	len = strlen(s) + 1;
	res = ap_palloc(a, len);
	memcpy(res, s, len);
	return res;
}

API_EXPORT(char *)
ap_pstrndup(struct pool *a, const char *s, int n)
{
	char *res;

	if (s == NULL)
		return NULL;
	res = ap_palloc(a, n + 1);
	memcpy(res, s, n);
	res[n] = '\0';
	return res;
}

API_EXPORT_NONSTD(char *) ap_pstrcat(pool *a,...)
{
	char *cp, *argp, *res;

	/* Pass one --- find length of required string */
	int len = 0;
	va_list adummy;

	va_start(adummy, a);

	while ((cp = va_arg(adummy, char *)) != NULL)
		len += strlen(cp);

	va_end(adummy);

	/* Allocate the required string */
	res = (char *) ap_palloc(a, len + 1);
	cp = res;
	*cp = '\0';

	/* Pass two --- copy the argument strings into the result space */
	va_start(adummy, a);

	while ((argp = va_arg(adummy, char *)) != NULL) {
		strlcpy(cp, argp, len + 1);
		cp += strlen(argp);
	}

	va_end(adummy);

	/* Return the result string */
	return res;
}

/* ap_psprintf is implemented by writing directly into the current
 * block of the pool, starting right at first_avail.  If there's
 * insufficient room, then a new block is allocated and the earlier
 * output is copied over.  The new block isn't linked into the pool
 * until all the output is done.
 *
 * Note that this is completely safe because nothing else can
 * allocate in this pool while ap_psprintf is running.  alarms are
 * blocked, and the only thing outside of alloc.c that's invoked
 * is ap_vformatter -- which was purposefully written to be
 * self-contained with no callouts.
 */

struct psprintf_data {
	ap_vformatter_buff	 vbuff;
#ifdef ALLOC_USE_MALLOC
	char			*base;
#else
	union block_hdr		*blok;
	int			 got_a_new_block;
#endif
};

#define AP_PSPRINTF_MIN_SIZE 32  /* Minimum size of allowable avail block */

static int
psprintf_flush(ap_vformatter_buff *vbuff)
{
	struct psprintf_data *ps = (struct psprintf_data *)vbuff;
#ifdef ALLOC_USE_MALLOC
	int cur_len, size;
	char *ptr;

	cur_len = (char *)ps->vbuff.curpos - ps->base;
	size = cur_len << 1;
	if (size < AP_PSPRINTF_MIN_SIZE)
		size = AP_PSPRINTF_MIN_SIZE;
#if defined(EAPI_MM)
	if (ps->block->h.is_shm)
		ptr = ap_mm_realloc(ps->base, size);
	else
#endif
	ptr = realloc(ps->base, size);
	if (ptr == NULL) {
		fputs("Ouch!  Out of memory!\n", stderr);
		exit(1);
	}
	ps->base = ptr;
	ps->vbuff.curpos = ptr + cur_len;
	ps->vbuff.endpos = ptr + size - 1;
	return 0;
#else
	union block_hdr *blok;
	union block_hdr *nblok;
	size_t cur_len, size;
	char *strp;

	blok = ps->blok;
	strp = ps->vbuff.curpos;
	cur_len = strp - blok->h.first_avail;
	size = cur_len << 1;
	if (size < AP_PSPRINTF_MIN_SIZE)
		size = AP_PSPRINTF_MIN_SIZE;

	/* must try another blok */
#if defined(EAPI_MM)
	if (blok->h.is_shm)
		(void)ap_mm_lock(mm, AP_MM_LOCK_RW);
#endif
	(void)ap_acquire_mutex(alloc_mutex);
#if defined(EAPI_MM)
	nblok = new_block(size, blok->h.is_shm);
#else
	nblok = new_block(size);
#endif
	(void)ap_release_mutex(alloc_mutex);
#if defined(EAPI_MM)
	if (blok->h.is_shm)
		(void)ap_mm_unlock(mm);
#endif
	memcpy(nblok->h.first_avail, blok->h.first_avail, cur_len);
	ps->vbuff.curpos = nblok->h.first_avail + cur_len;
	/* save a byte for the NUL terminator */
	ps->vbuff.endpos = nblok->h.endp - 1;

	/* did we allocate the current blok? if so free it up */
	if (ps->got_a_new_block) {
		debug_fill(blok->h.first_avail,
		    blok->h.endp - blok->h.first_avail);
#if defined(EAPI_MM)
		if (blok->h.is_shm)
			(void)ap_mm_lock(mm, AP_MM_LOCK_RW);
#endif
		(void)ap_acquire_mutex(alloc_mutex);
		blok->h.next = block_freelist;
		block_freelist = blok;
		(void)ap_release_mutex(alloc_mutex);
#if defined(EAPI_MM)
		if (blok->h.is_shm)
			(void)ap_mm_unlock(mm);
#endif
	}
	ps->blok = nblok;
	ps->got_a_new_block = 1;
	/*
	 * note that we've deliberately not linked the new block onto
	 * the pool yet... because we may need to flush again later, and
	 * we'd have to spend more effort trying to unlink the block.
	 */
	return 0;
#endif
}

API_EXPORT(char *)
ap_pvsprintf(pool *p, const char *fmt, va_list ap)
{
#ifdef ALLOC_USE_MALLOC
	struct psprintf_data ps;
	void *ptr;

	ap_block_alarms();
#if defined(EAPI_MM)
	if (p->is_shm)
		ps.base = ap_mm_malloc(mm, 512);
	else
#endif
	ps.base = malloc(512);
	if (ps.base == NULL) {
		fputs("Ouch!  Out of memory!\n", stderr);
		exit(1);
	}
	/* need room at beginning for allocation_list */
	ps.vbuff.curpos = ps.base + CLICK_SZ;
	ps.vbuff.endpos = ps.base + 511;
	ap_vformatter(psprintf_flush, &ps.vbuff, fmt, ap);
	*ps.vbuff.curpos++ = '\0';
	ptr = ps.base;
	/* shrink */
#if defined(EAPI_MM)
	if (p->is_shm)
		ptr = ap_mm_realloc(ptr, (char *)ps.vbuff.curpos - (char *)ptr);
	else
#endif
	ptr = realloc(ptr, (char *)ps.vbuff.curpos - (char *)ptr);
	if (ptr == NULL) {
		fputs("Ouch!  Out of memory!\n", stderr);
		exit(1);
	}
	*(void **)ptr = p->allocation_list;
	p->allocation_list = ptr;
	ap_unblock_alarms();
	return (char *)ptr + CLICK_SZ;
#else
	struct psprintf_data ps;
	char *strp;
	int size;

	ap_block_alarms();
	ps.blok = p->last;
	ps.vbuff.curpos = ps.blok->h.first_avail;
	ps.vbuff.endpos = ps.blok->h.endp - 1;	/* save one for NUL */
	ps.got_a_new_block = 0;

	if (ps.blok->h.first_avail == ps.blok->h.endp)
		psprintf_flush(&ps.vbuff);	/* ensure room for NUL */
	ap_vformatter(psprintf_flush, &ps.vbuff, fmt, ap);

	strp = ps.vbuff.curpos;
	*strp++ = '\0';

	size = strp - ps.blok->h.first_avail;
	size = (1 + ((size - 1) / CLICK_SZ)) * CLICK_SZ;
	strp = ps.blok->h.first_avail;	/* save away result pointer */
	ps.blok->h.first_avail += size;

	/* have to link the block in if it's a new one */
	if (ps.got_a_new_block) {
		p->last->h.next = ps.blok;
		p->last = ps.blok;
#ifdef POOL_DEBUG
		ps.blok->h.owning_pool = p;
#endif
	}
	ap_unblock_alarms();

	return strp;
#endif
}

API_EXPORT_NONSTD(char *)
ap_psprintf(pool *p, const char *fmt, ...)
{
	va_list ap;
	char *res;

	va_start(ap, fmt);
	res = ap_pvsprintf(p, fmt, ap);
	va_end(ap);
	return res;
}

/*****************************************************************
 *
 * The 'array' functions...
 */

static void
make_array_core(array_header *res, pool *p, int nelts, int elt_size)
{
	if (nelts < 1)
		nelts = 1;	/* Assure sanity if someone asks for
				 * array of zero elts.
				 */

	res->elts = ap_pcalloc(p, nelts * elt_size);

	res->pool = p;
	res->elt_size = elt_size;
	res->nelts = 0;		/* No active elements yet... */
	res->nalloc = nelts;	/* ...but this many allocated */
}

API_EXPORT(array_header *)
ap_make_array(pool *p, int nelts, int elt_size)
{
	array_header *res = (array_header *)ap_palloc(p, sizeof(array_header));

	make_array_core(res, p, nelts, elt_size);
	return res;
}

API_EXPORT(void *)
ap_push_array(array_header *arr)
{
	if (arr->nelts == arr->nalloc) {
		int new_size = (arr->nalloc <= 0) ? 1 : arr->nalloc * 2;
		char *new_data;

		new_data = ap_pcalloc(arr->pool, arr->elt_size * new_size);

		memcpy(new_data, arr->elts, arr->nalloc * arr->elt_size);
		arr->elts = new_data;
		arr->nalloc = new_size;
	}

	++arr->nelts;
	return arr->elts + (arr->elt_size * (arr->nelts - 1));
}

API_EXPORT(void)
ap_array_cat(array_header *dst, const array_header *src)
{
	int elt_size = dst->elt_size;

	if (dst->nelts + src->nelts > dst->nalloc) {
		int new_size = (dst->nalloc <= 0) ? 1 : dst->nalloc * 2;
		char *new_data;

		while (dst->nelts + src->nelts > new_size)
			new_size *= 2;

		new_data = ap_pcalloc(dst->pool, elt_size * new_size);
		memcpy(new_data, dst->elts, dst->nalloc * elt_size);

		dst->elts = new_data;
		dst->nalloc = new_size;
	}

	memcpy(dst->elts + dst->nelts * elt_size, src->elts,
	    elt_size * src->nelts);
	dst->nelts += src->nelts;
}

API_EXPORT(array_header *)
ap_copy_array(pool *p, const array_header *arr)
{
	array_header *res = ap_make_array(p, arr->nalloc, arr->elt_size);

	memcpy(res->elts, arr->elts, arr->elt_size * arr->nelts);
	res->nelts = arr->nelts;
	return res;
}

/* This cute function copies the array header *only*, but arranges
 * for the data section to be copied on the first push or arraycat.
 * It's useful when the elements of the array being copied are
 * read only, but new stuff *might* get added on the end; we have the
 * overhead of the full copy only where it is really needed.
 */

static ap_inline void
copy_array_hdr_core(array_header *res, const array_header *arr)
{
	res->elts = arr->elts;
	res->elt_size = arr->elt_size;
	res->nelts = arr->nelts;
	res->nalloc = arr->nelts;	/* Force overflow on push */
}

API_EXPORT(array_header *)
ap_copy_array_hdr(pool *p, const array_header *arr)
{
	array_header *res = (array_header *) ap_palloc(p, sizeof(array_header));

	res->pool = p;
	copy_array_hdr_core(res, arr);
	return res;
}

/* The above is used here to avoid consing multiple new array bodies... */

API_EXPORT(array_header *)
ap_append_arrays(pool *p, const array_header *first, const array_header *second)
{
	array_header *res = ap_copy_array_hdr(p, first);

	ap_array_cat(res, second);
	return res;
}

/* ap_array_pstrcat generates a new string from the pool containing
 * the concatenated sequence of substrings referenced as elements within
 * the array.  The string will be empty if all substrings are empty or null,
 * or if there are no elements in the array.
 * If sep is non-NUL, it will be inserted between elements as a separator.
 */
API_EXPORT(char *)
ap_array_pstrcat(pool *p, const array_header *arr, const char sep)
{
	char *cp, *res, **strpp;
	int i, len;

	if (arr->nelts <= 0 || arr->elts == NULL)      /* Empty table? */
		return (char *)ap_pcalloc(p, 1);

	/* Pass one --- find length of required string */
	len = 0;
	for (i = 0, strpp = (char **)arr->elts; ; ++strpp) {
		if (strpp && *strpp != NULL)
			len += strlen(*strpp);

		if (++i >= arr->nelts)
			break;
		if (sep)
			++len;
	}

	/* Allocate the required string */
	res = (char *)ap_palloc(p, len + 1);
	cp = res;

	/* Pass two --- copy the argument strings into the result space */
	for (i = 0, strpp = (char **)arr->elts; ; ++strpp) {
		if (strpp && *strpp != NULL) {
			len = strlen(*strpp);
			memcpy(cp, *strpp, len);
			cp += len;
		}
		if (++i >= arr->nelts)
			break;
		if (sep)
			*cp++ = sep;
	}

	*cp = '\0';

	/* Return the result string */
	return res;
}


/*****************************************************************
 *
 * The "table" functions.
 */

/* XXX: if you tweak this you should look at is_empty_table() and table_elts()
 * in ap_alloc.h */
struct table {
	/* This has to be first to promote backwards compatibility with
	 * older modules which cast a table * to an array_header *...
	 * they should use the table_elts() function for most of the
	 * cases they do this for.
	 */
	array_header	 a;
#ifdef MAKE_TABLE_PROFILE
	void		*creator;
#endif
};

#ifdef MAKE_TABLE_PROFILE
static table_entry
*table_push(table *t)
{
	if (t->a.nelts == t->a.nalloc) {
		fprintf(stderr,
		    "table_push: table created by %p hit limit of %u\n",
		    t->creator, t->a.nalloc);
	}
	return (table_entry *)ap_push_array(&t->a);
}
#else
#define table_push(t)	((table_entry *)ap_push_array(&(t)->a))
#endif

API_EXPORT(table *)
ap_make_table(pool *p, int nelts)
{
	table *t = ap_palloc(p, sizeof(table));

	make_array_core(&t->a, p, nelts, sizeof(table_entry));
#ifdef MAKE_TABLE_PROFILE
	t->creator = __builtin_return_address(0);
#endif
	return t;
}

API_EXPORT(table *)
ap_copy_table(pool *p, const table *t)
{
	table *new = ap_palloc(p, sizeof(table));

#ifdef POOL_DEBUG
	/* we don't copy keys and values, so it's necessary that t->a.pool
	 * have a life span at least as long as p
	 */
	if (!ap_pool_is_ancestor(t->a.pool, p)) {
		fprintf(stderr, "copy_table: t's pool is not an "
		    "ancestor of p\n");
		abort();
	}
#endif
	make_array_core(&new->a, p, t->a.nalloc, sizeof(table_entry));
	memcpy(new->a.elts, t->a.elts, t->a.nelts * sizeof(table_entry));
	new->a.nelts = t->a.nelts;
	return new;
}

API_EXPORT(void)
ap_clear_table(table *t)
{
	t->a.nelts = 0;
}

API_EXPORT(const char *)
ap_table_get(const table *t, const char *key)
{
	table_entry *elts = (table_entry *) t->a.elts;
	int i;

	if (key == NULL)
		return NULL;

	for (i = 0; i < t->a.nelts; ++i)
		if (!strcasecmp(elts[i].key, key))
			return elts[i].val;

	return NULL;
}

API_EXPORT(void)
ap_table_set(table *t, const char *key, const char *val)
{
	int i, j, k;
	table_entry *elts = (table_entry *) t->a.elts;
	int done = 0;

	for (i = 0; i < t->a.nelts; ) {
		if (!strcasecmp(elts[i].key, key)) {
			if (!done) {
				elts[i].val = ap_pstrdup(t->a.pool, val);
				done = 1;
				++i;
			} else {	/* delete an extraneous element */
				for (j = i, k = i + 1; k < t->a.nelts;
				    ++j, ++k) {
					elts[j].key = elts[k].key;
					elts[j].val = elts[k].val;
				}
				--t->a.nelts;
			}
		} else
			++i;
	}

	if (!done) {
		elts = (table_entry *)table_push(t);
		elts->key = ap_pstrdup(t->a.pool, key);
		elts->val = ap_pstrdup(t->a.pool, val);
	}
}

API_EXPORT(void)
ap_table_setn(table *t, const char *key, const char *val)
{
	int i, j, k;
	table_entry *elts = (table_entry *) t->a.elts;
	int done = 0;

#ifdef POOL_DEBUG
	if (!ap_pool_is_ancestor(ap_find_pool(key), t->a.pool)) {
		fprintf(stderr, "table_set: key not in ancestor pool of t\n");
		abort();
	}
	if (!ap_pool_is_ancestor(ap_find_pool(val), t->a.pool)) {
		fprintf(stderr, "table_set: val not in ancestor pool of t\n");
		abort();
	}
#endif

	for (i = 0; i < t->a.nelts; ) {
		if (!strcasecmp(elts[i].key, key)) {
			if (!done) {
				elts[i].val = (char *)val;
				done = 1;
				++i;
			} else {	/* delete an extraneous element */
				for (j = i, k = i + 1; k < t->a.nelts;
				    ++j, ++k) {
					elts[j].key = elts[k].key;
					elts[j].val = elts[k].val;
				}
				--t->a.nelts;
			}
		} else
			++i;
	}

	if (!done) {
		elts = (table_entry *)table_push(t);
		elts->key = (char *)key;
		elts->val = (char *)val;
	}
}

API_EXPORT(void)
ap_table_unset(table *t, const char *key)
{
	int i, j, k;
	table_entry *elts = (table_entry *) t->a.elts;

	for (i = 0; i < t->a.nelts;) {
		if (!strcasecmp(elts[i].key, key)) {

                        /* found an element to skip over there are any
			 * number of ways to remove an element from a
			 * contiguous block of memory.  I've chosen one
			 * that doesn't do a memcpy/bcopy/array_delete,
			 * *shrug*...
                         */
			for (j = i, k = i + 1; k < t->a.nelts; ++j, ++k) {
				elts[j].key = elts[k].key;
				elts[j].val = elts[k].val;
			}
			--t->a.nelts;
		} else
			++i;
	}
}

API_EXPORT(void)
ap_table_merge(table *t, const char *key, const char *val)
{
	table_entry *elts = (table_entry *) t->a.elts;
	int i;

	for (i = 0; i < t->a.nelts; ++i)
		if (!strcasecmp(elts[i].key, key)) {
			elts[i].val = ap_pstrcat(t->a.pool, elts[i].val,
			    ", ", val, NULL);
			return;
		}

	elts = (table_entry *)table_push(t);
	elts->key = ap_pstrdup(t->a.pool, key);
	elts->val = ap_pstrdup(t->a.pool, val);
}

API_EXPORT(void)
ap_table_mergen(table *t, const char *key, const char *val)
{
	table_entry *elts = (table_entry *)t->a.elts;
	int i;

#ifdef POOL_DEBUG
	if (!ap_pool_is_ancestor(ap_find_pool(key), t->a.pool)) {
		fprintf(stderr, "table_set: key not in ancestor pool of t\n");
		abort();
	}
	if (!ap_pool_is_ancestor(ap_find_pool(val), t->a.pool)) {
		fprintf(stderr, "table_set: key not in ancestor pool of t\n");
		abort();
	}
#endif

	for (i = 0; i < t->a.nelts; ++i) {
		if (!strcasecmp(elts[i].key, key)) {
			elts[i].val = ap_pstrcat(t->a.pool, elts[i].val,
			    ", ", val, NULL);
			return;
		}
	}

	elts = (table_entry *)table_push(t);
	elts->key = (char *)key;
	elts->val = (char *)val;
}

API_EXPORT(void)
ap_table_add(table *t, const char *key, const char *val)
{
	table_entry *elts = (table_entry *)t->a.elts;

	elts = (table_entry *)table_push(t);
	elts->key = ap_pstrdup(t->a.pool, key);
	elts->val = ap_pstrdup(t->a.pool, val);
}

API_EXPORT(void)
ap_table_addn(table *t, const char *key, const char *val)
{
	table_entry *elts = (table_entry *) t->a.elts;

#ifdef POOL_DEBUG
	if (!ap_pool_is_ancestor(ap_find_pool(key), t->a.pool)) {
		fprintf(stderr, "table_set: key not in ancestor pool of t\n");
		abort();
	}
	if (!ap_pool_is_ancestor(ap_find_pool(val), t->a.pool)) {
		fprintf(stderr, "table_set: key not in ancestor pool of t\n");
		abort();
	}
#endif

	elts = (table_entry *)table_push(t);
	elts->key = (char *)key;
	elts->val = (char *)val;
}

API_EXPORT(table *)
ap_overlay_tables(pool *p, const table *overlay, const table *base)
{
	table *res;

#ifdef POOL_DEBUG
	/* we don't copy keys and values, so it's necessary that
	 * overlay->a.pool and base->a.pool have a life span at least
	 * as long as p
	 */
	if (!ap_pool_is_ancestor(overlay->a.pool, p)) {
		fprintf(stderr, "overlay_tables: overlay's pool is not an "
		    "ancestor of p\n");
		abort();
	}
	if (!ap_pool_is_ancestor(base->a.pool, p)) {
		fprintf(stderr, "overlay_tables: base's pool is not an "
		    "ancestor of p\n");
		abort();
	}
#endif

	res = ap_palloc(p, sizeof(table));
	/* behave like append_arrays */
	res->a.pool = p;
	copy_array_hdr_core(&res->a, &overlay->a);
	ap_array_cat(&res->a, &base->a);

	return res;
}

/* And now for something completely abstract ...

 * For each key value given as a vararg:
 *   run the function pointed to as
 *     int comp(void *r, char *key, char *value);
 *   on each valid key-value pair in the table t that matches the vararg key,
 *   or once for every valid key-value pair if the vararg list is empty,
 *   until the function returns false (0) or we finish the table.
 *
 * Note that we restart the traversal for each vararg, which means that
 * duplicate varargs will result in multiple executions of the function
 * for each matching key.  Note also that if the vararg list is empty,
 * only one traversal will be made and will cut short if comp returns 0.
 *
 * Note that the table_get and table_merge functions assume that each key in
 * the table is unique (i.e., no multiple entries with the same key).  This
 * function does not make that assumption, since it (unfortunately) isn't
 * true for some of Apache's tables.
 *
 * Note that rec is simply passed-on to the comp function, so that the
 * caller can pass additional info for the task.
 */
API_EXPORT_NONSTD(void)
ap_table_do(int (*comp)(void *, const char *, const char *), void *rec,
    const table *t,...)
{
	va_list vp;
	char *argp;
	table_entry *elts = (table_entry *)t->a.elts;
	int rv, i;

	va_start(vp, t);

	argp = va_arg(vp, char *);

	do {
		for (rv = 1, i = 0; rv && (i < t->a.nelts); ++i) {
			if (elts[i].key && (!argp ||
			    !strcasecmp(elts[i].key, argp)))
				rv = (*comp) (rec, elts[i].key, elts[i].val);
		}
	} while (argp && ((argp = va_arg(vp, char *)) != NULL));

	va_end(vp);
}

/* Curse libc and the fact that it doesn't guarantee a stable sort.  We
 * have to enforce stability ourselves by using the order field.  If it
 * provided a stable sort then we wouldn't even need temporary storage to
 * do the work below. -djg
 *
 * ("stable sort" means that equal keys retain their original relative
 * ordering in the output.)
 */
typedef struct {
	char	*key;
	char	*val;
	int	 order;
} overlap_key;

static int
sort_overlap(const void *va, const void *vb)
{
	const overlap_key *a = va;
	const overlap_key *b = vb;
	int r;

	r = strcasecmp(a->key, b->key);
	if (r)
		return r;
	return a->order - b->order;
}

/* prefer to use the stack for temp storage for overlaps smaller than this */
#ifndef AP_OVERLAP_TABLES_ON_STACK
#define AP_OVERLAP_TABLES_ON_STACK	(512)
#endif

API_EXPORT(void)
ap_overlap_tables(table *a, const table *b, unsigned flags)
{
	overlap_key cat_keys_buf[AP_OVERLAP_TABLES_ON_STACK];
	overlap_key *cat_keys;
	int nkeys;
	table_entry *e;
	table_entry *last_e;
	overlap_key *left;
	overlap_key *right;
	overlap_key *last;

	nkeys = a->a.nelts + b->a.nelts;
	if (nkeys < AP_OVERLAP_TABLES_ON_STACK) {
		cat_keys = cat_keys_buf;
	} else {
		/* XXX: could use scratch free space in a or b's pool instead...
		* which could save an allocation in b's pool.
		*/
		cat_keys = ap_palloc(b->a.pool, sizeof(overlap_key) * nkeys);
	}

	nkeys = 0;

	/* Create a list of the entries from a concatenated with the entries
	* from b.
	*/
	e = (table_entry *)a->a.elts;
	last_e = e + a->a.nelts;
	while (e < last_e) {
		cat_keys[nkeys].key = e->key;
		cat_keys[nkeys].val = e->val;
		cat_keys[nkeys].order = nkeys;
		++nkeys;
		++e;
	}

	e = (table_entry *)b->a.elts;
	last_e = e + b->a.nelts;
	while (e < last_e) {
		cat_keys[nkeys].key = e->key;
		cat_keys[nkeys].val = e->val;
		cat_keys[nkeys].order = nkeys;
		++nkeys;
		++e;
	}

	qsort(cat_keys, nkeys, sizeof(overlap_key), sort_overlap);

	/* Now iterate over the sorted list and rebuild a.
	 * Start by making sure it has enough space.
	 */
	a->a.nelts = 0;
	if (a->a.nalloc < nkeys) {
		a->a.elts = ap_palloc(a->a.pool, a->a.elt_size * nkeys * 2);
		a->a.nalloc = nkeys * 2;
	}

	/*
	 * In both the merge and set cases we retain the invariant:
	 *
	 * left->key, (left+1)->key, (left+2)->key, ..., (right-1)->key
	 * are all equal keys.  (i.e. strcasecmp returns 0)
	 *
	 * We essentially need to find the maximal
	 * right for each key, then we can do a quick merge or set as
	 * appropriate.
	 */

	if (flags & AP_OVERLAP_TABLES_MERGE) {
		left = cat_keys;
		last = left + nkeys;
		while (left < last) {
			right = left + 1;
			if (right == last
			    || strcasecmp(left->key, right->key)) {
				ap_table_addn(a, left->key, left->val);
				left = right;
			} else {
				char *strp;
				char *value;
				size_t len;

				/* Have to merge some headers.  Let's re-use
				 * the order field, since it's handy... we'll
				 * store the length of val there.
				 */
				left->order = strlen(left->val);
				len = left->order;
				do {
					right->order = strlen(right->val);
					len += 2 + right->order;
					++right;
				} while (right < last
				&& !strcasecmp(left->key, right->key));
				/* right points one past the last header to
				 * merge
				 */
				value = ap_palloc(a->a.pool, len + 1);
				strp = value;
				for (;;) {
					memcpy(strp, left->val, left->order);
					strp += left->order;
					++left;
					if (left == right) break;
					*strp++ = ',';
					*strp++ = ' ';
				}
				*strp = 0;
				ap_table_addn(a, (left-1)->key, value);
			}
		}
	} else {
		left = cat_keys;
		last = left + nkeys;
		while (left < last) {
			right = left + 1;
			while (right < last
			    && !strcasecmp(left->key, right->key)) {
				++right;
			}
			ap_table_addn(a, (right-1)->key, (right-1)->val);
			left = right;
		}
	}
}

/*****************************************************************
 *
 * Managing generic cleanups.  
 */

struct cleanup {
	void		*data;
	void		(*plain_cleanup)(void *);
	void		(*child_cleanup)(void *);
	struct cleanup	*next;
};

API_EXPORT(void)
ap_register_cleanup_ex(pool *p, void *data, void (*plain_cleanup)(void *),
    void (*child_cleanup)(void *), int (*magic_cleanup)(void *))
{
	struct cleanup *c;
	if (p) {
		c = (struct cleanup *)ap_palloc(p, sizeof(struct cleanup));
		c->data = data;
		c->plain_cleanup = plain_cleanup;
		c->child_cleanup = child_cleanup;
		c->next = p->cleanups;
		p->cleanups = c;
	}
	/* attempt to do magic even if not passed a pool. Allows us
	 * to perform the magic, therefore, "whenever" we want/need */
	if (magic_cleanup) {
		if (!magic_cleanup(data)) 
			ap_log_error(APLOG_MARK, APLOG_WARNING, NULL,
			    "exec() may not be safe");
	}
}

API_EXPORT(void)
ap_register_cleanup(pool *p, void *data, void (*plain_cleanup)(void *),
    void (*child_cleanup)(void *))
{
	ap_register_cleanup_ex(p, data, plain_cleanup, child_cleanup, NULL);
}

API_EXPORT(void)
ap_kill_cleanup(pool *p, void *data, void (*cleanup)(void *))
{
	struct cleanup *c = p->cleanups;
	struct cleanup **lastp = &p->cleanups;

	while (c) {
		if (c->data == data && c->plain_cleanup == cleanup) {
			*lastp = c->next;
			break;
		}

		lastp = &c->next;
		c = c->next;
	}
}

API_EXPORT(void)
ap_run_cleanup(pool *p, void *data, void (*cleanup)(void *))
{
	ap_block_alarms();		/* Run cleanup only once! */
	(*cleanup)(data);
	ap_kill_cleanup(p, data, cleanup);
	ap_unblock_alarms();
}

static void
run_cleanups(struct cleanup *c)
{
	while (c) {
		(*c->plain_cleanup)(c->data);
		c = c->next;
	}
}

static void
run_child_cleanups(struct cleanup *c)
{
	while (c) {
		(*c->child_cleanup)(c->data);
		c = c->next;
	}
}

static void
cleanup_pool_for_exec(pool *p)
{
	run_child_cleanups(p->cleanups);
	p->cleanups = NULL;

	for (p = p->sub_pools; p; p = p->sub_next)
		cleanup_pool_for_exec(p);
}

API_EXPORT(void)
ap_cleanup_for_exec(void)
{
	/*
	 * Don't need to do anything on NT, NETWARE or OS/2, because I
	 * am actually going to spawn the new process - not
	 * exec it. All handles that are not inheritable, will
	 * be automajically closed. The only problem is with
	 * file handles that are open, but there isn't much
	 * I can do about that (except if the child decides
	 * to go out and close them
	 */
	ap_block_alarms();
	cleanup_pool_for_exec(permanent_pool);
	ap_unblock_alarms();
}

API_EXPORT_NONSTD(void)
ap_null_cleanup(void *data)
{
	/* do nothing cleanup routine */
}

/*****************************************************************
 *
 * Files and file descriptors; these are just an application of the
 * generic cleanup interface.
 */

int
ap_close_fd_on_exec(int fd)
{
	/* Protect the fd so that it will not be inherited by child processes */
	if(fcntl(fd, F_SETFD, FD_CLOEXEC) < 0) {
		ap_log_error(APLOG_MARK, APLOG_ERR, NULL,
		    "fcntl(%d, F_SETFD, FD_CLOEXEC) failed", fd);
		return 0;
	}

	return 1;
}

static void
fd_cleanup(void *fdv)
{
	close((int)(long)fdv);
}

static int
fd_magic_cleanup(void *fdv)
{
	return ap_close_fd_on_exec((int)(long)fdv);
}

API_EXPORT(void)
ap_note_cleanups_for_fd_ex(pool *p, int fd, int domagic)
{
	ap_register_cleanup_ex(p, (void *)(long)fd, fd_cleanup, fd_cleanup,
	    domagic ? fd_magic_cleanup : NULL);
}

API_EXPORT(void)
ap_note_cleanups_for_fd(pool *p, int fd)
{
	ap_note_cleanups_for_fd_ex(p, fd, 0);
}

API_EXPORT(void)
ap_kill_cleanups_for_fd(pool *p, int fd)
{
	ap_kill_cleanup(p, (void *)(long)fd, fd_cleanup);
}

API_EXPORT(int)
ap_popenf_ex(pool *a, const char *name, int flg, int mode, int domagic)
{
	int fd;
	int save_errno;

	ap_block_alarms();
	fd = open(name, flg, mode);
	save_errno = errno;
	if (fd >= 0) {
		fd = ap_slack(fd, AP_SLACK_HIGH);
		ap_note_cleanups_for_fd_ex(a, fd, domagic);
	}
	ap_unblock_alarms();
	errno = save_errno;
	return fd;
}

API_EXPORT(int)
ap_popenf(pool *a, const char *name, int flg, int mode)
{
	return ap_popenf_ex(a, name, flg, mode, 0);
}

API_EXPORT(int)
ap_pclosef(pool *a, int fd)
{
	int res;
	int save_errno;

	ap_block_alarms();
	res = close(fd);
	save_errno = errno;
	ap_kill_cleanup(a, (void *)(long)fd, fd_cleanup);
	ap_unblock_alarms();
	errno = save_errno;
	return res;
}


/* Note that we have separate plain_ and child_ cleanups for FILE *s,
 * since fclose() would flush I/O buffers, which is extremely undesirable;
 * we just close the descriptor.
 */

static void
file_cleanup(void *fpv)
{
	fclose((FILE *)fpv);
}

static void
file_child_cleanup(void *fpv)
{
	close(fileno((FILE *)fpv));
}

static int
file_magic_cleanup(void *fpv)
{
	return ap_close_fd_on_exec(fileno((FILE *)fpv));
}

API_EXPORT(void)
ap_note_cleanups_for_file_ex(pool *p, FILE *fp, int domagic)
{
	ap_register_cleanup_ex(p, (void *)fp, file_cleanup, file_child_cleanup,
	    domagic ? file_magic_cleanup : NULL);
}

API_EXPORT(void)
ap_note_cleanups_for_file(pool *p, FILE *fp)
{
	ap_note_cleanups_for_file_ex(p, fp, 0);
}

API_EXPORT(FILE *)
ap_pfopen(pool *a, const char *name, const char *mode)
{
	FILE *fd = NULL;
	int baseFlag, desc;
	int modeFlags = 0;
	int saved_errno;

	modeFlags = S_IRUSR | S_IWUSR | S_IRGRP | S_IWGRP | S_IROTH | S_IWOTH;

	ap_block_alarms();

	if (*mode == 'a') {
		/* Work around faulty implementations of fopen */
		baseFlag = (*(mode + 1) == '+') ? O_RDWR : O_WRONLY;
		desc = open(name, baseFlag | O_APPEND | O_CREAT,
		modeFlags);
		if (desc >= 0) {
			desc = ap_slack(desc, AP_SLACK_LOW);
			fd = ap_fdopen(desc, mode);
		}
	} else {
		fd = fopen(name, mode);
	}
	saved_errno = errno;
	if (fd != NULL)
		ap_note_cleanups_for_file(a, fd);
	ap_unblock_alarms();
	errno = saved_errno;
	return fd;
}

API_EXPORT(FILE *)
ap_pfdopen(pool *a, int fd, const char *mode)
{
	FILE *f;
	int saved_errno;

	ap_block_alarms();
	f = ap_fdopen(fd, mode);
	saved_errno = errno;
	if (f != NULL)
		ap_note_cleanups_for_file(a, f);
	ap_unblock_alarms();
	errno = saved_errno;
	return f;
}


API_EXPORT(int)
ap_pfclose(pool *a, FILE *fd)
{
	int res;

	ap_block_alarms();
	res = fclose(fd);
	ap_kill_cleanup(a, (void *)fd, file_cleanup);
	ap_unblock_alarms();
	return res;
}

/*
 * DIR * with cleanup
 */

static void
dir_cleanup(void *dv)
{
	closedir((DIR *) dv);
}

API_EXPORT(DIR *)
ap_popendir(pool *p, const char *name)
{
	DIR *d;
	int save_errno;

	ap_block_alarms();
	d = opendir(name);
	if (d == NULL) {
		save_errno = errno;
		ap_unblock_alarms();
		errno = save_errno;
		return NULL;
	}
	ap_register_cleanup(p, (void *)d, dir_cleanup, dir_cleanup);
	ap_unblock_alarms();
	return d;
}

API_EXPORT(void)
ap_pclosedir(pool *p, DIR * d)
{
	ap_block_alarms();
	ap_kill_cleanup(p, (void *)d, dir_cleanup);
	closedir(d);
	ap_unblock_alarms();
}

/*****************************************************************
 *
 * Files and file descriptors; these are just an application of the
 * generic cleanup interface.
 */

static void
socket_cleanup(void *fdv)
{
	closesocket((int)(long)fdv);
}

static int
socket_magic_cleanup(void *fpv)
{
	return ap_close_fd_on_exec((int)(long)fpv);
}

API_EXPORT(void)
ap_note_cleanups_for_socket_ex(pool *p, int fd, int domagic)
{
	ap_register_cleanup_ex(p, (void *)(long) fd, socket_cleanup,
	    socket_cleanup, domagic ? socket_magic_cleanup : NULL);
}

API_EXPORT(void)
ap_note_cleanups_for_socket(pool *p, int fd)
{
	ap_note_cleanups_for_socket_ex(p, fd, 0);
}

API_EXPORT(void)
ap_kill_cleanups_for_socket(pool *p, int sock)
{
	ap_kill_cleanup(p, (void *)(long)sock, socket_cleanup);
}

API_EXPORT(int)
ap_psocket_ex(pool *p, int domain, int type, int protocol, int domagic)
{
	int fd;

	ap_block_alarms();
	fd = socket(domain, type, protocol);
	if (fd == -1) {
		int save_errno = errno;
		ap_unblock_alarms();
		errno = save_errno;
		return -1;
	}
	ap_note_cleanups_for_socket_ex(p, fd, domagic);
	ap_unblock_alarms();
	return fd;
}

API_EXPORT(int)
ap_psocket(pool *p, int domain, int type, int protocol)
{
	return ap_psocket_ex(p, domain, type, protocol, 0);
}

API_EXPORT(int)
ap_pclosesocket(pool *a, int sock)
{
	int res;
	int save_errno;

	ap_block_alarms();
	res = closesocket(sock);
	save_errno = errno;
	ap_kill_cleanup(a, (void *)(long)sock, socket_cleanup);
	ap_unblock_alarms();
	errno = save_errno;
	return res;
}


/*
 * Here's a pool-based interface to POSIX regex's regcomp().
 * Note that we return regex_t instead of being passed one.
 * The reason is that if you use an already-used regex_t structure,
 * the memory that you've already allocated gets forgotten, and
 * regfree() doesn't clear it. So we don't allow it.
 */

static void
regex_cleanup(void *preg)
{
	regfree((regex_t *)preg);
}

API_EXPORT(regex_t *)
ap_pregcomp(pool *p, const char *pattern, int cflags)
{
	regex_t *preg = ap_palloc(p, sizeof(regex_t));

	if (regcomp(preg, pattern, cflags))
		return NULL;

	ap_register_cleanup(p, (void *)preg, regex_cleanup, regex_cleanup);

	return preg;
}


API_EXPORT(void)
ap_pregfree(pool *p, regex_t *reg)
{
	ap_block_alarms();
	regfree(reg);
	ap_kill_cleanup(p, (void *)reg, regex_cleanup);
	ap_unblock_alarms();
}

/*****************************************************************
 *
 * More grotty system stuff... subprocesses.  Frump.  These don't use
 * the generic cleanup interface because I don't want multiple
 * subprocesses to result in multiple three-second pauses; the
 * subprocesses have to be "freed" all at once.  If someone comes
 * along with another resource they want to allocate which has the
 * same property, we might want to fold support for that into the
 * generic interface, but for now, it's a special case
 */

struct process_chain {
	pid_t			 pid;
	enum kill_conditions	 kill_how;
	struct process_chain	*next;
};

API_EXPORT(void)
ap_note_subprocess(pool *a, pid_t pid, enum kill_conditions how)
{
	struct process_chain *new =
	    (struct process_chain *)ap_palloc(a, sizeof(struct process_chain));

	new->pid = pid;
	new->kill_how = how;
	new->next = a->subprocesses;
	a->subprocesses = new;
}

#define os_pipe(fds) pipe(fds)

/* for ap_fdopen, to get binary mode */
#define BINMODE

static pid_t
spawn_child_core(pool *p, int (*func)(void *, child_info *), void *data,
enum kill_conditions kill_how, int *pipe_in, int *pipe_out, int *pipe_err)
{
	pid_t pid;
	int in_fds[2];
	int out_fds[2];
	int err_fds[2];
	int save_errno;

	if (pipe_in && os_pipe(in_fds) < 0)
		return 0;

	if (pipe_out && os_pipe(out_fds) < 0) {
		save_errno = errno;
		if (pipe_in) {
			close(in_fds[0]);
			close(in_fds[1]);
		}
		errno = save_errno;
		return 0;
	}

	if (pipe_err && os_pipe(err_fds) < 0) {
		save_errno = errno;
		if (pipe_in) {
			close(in_fds[0]);
			close(in_fds[1]);
		}
		if (pipe_out) {
			close(out_fds[0]);
			close(out_fds[1]);
		}
		errno = save_errno;
		return 0;
	}

	if ((pid = fork()) < 0) {
		save_errno = errno;
		if (pipe_in) {
			close(in_fds[0]);
			close(in_fds[1]);
		}
		if (pipe_out) {
			close(out_fds[0]);
			close(out_fds[1]);
		}
		if (pipe_err) {
			close(err_fds[0]);
			close(err_fds[1]);
		}
		errno = save_errno;
		return 0;
	}

	if (!pid) {
		/* Child process */
		RAISE_SIGSTOP(SPAWN_CHILD);

		if (pipe_out) {
			close(out_fds[0]);
			dup2(out_fds[1], STDOUT_FILENO);
			close(out_fds[1]);
		}

		if (pipe_in) {
			close(in_fds[1]);
			dup2(in_fds[0], STDIN_FILENO);
			close(in_fds[0]);
		}

		if (pipe_err) {
			close(err_fds[0]);
			dup2(err_fds[1], STDERR_FILENO);
			close(err_fds[1]);
		}

		/* HP-UX SIGCHLD fix goes here, if someone will remind me
		 * what it is... */
		signal(SIGCHLD, SIG_DFL);	/* Was that it? */

		func(data, NULL);
		exit(1);			/* Should only get here if
						 * the exec in func() failed
						 */
	}

	/* Parent process */
	ap_note_subprocess(p, pid, kill_how);

	if (pipe_out) {
		close(out_fds[1]);
		*pipe_out = out_fds[0];
	}

	if (pipe_in) {
		close(in_fds[0]);
		*pipe_in = in_fds[1];
	}

	if (pipe_err) {
		close(err_fds[1]);
		*pipe_err = err_fds[0];
	}

	return pid;
}


API_EXPORT(int)
ap_spawn_child(pool *p, int (*func)(void *, child_info *), void *data,
    enum kill_conditions kill_how, FILE **pipe_in, FILE **pipe_out,
    FILE **pipe_err)
{
	int fd_in, fd_out, fd_err;
	pid_t pid;
	int save_errno;

	ap_block_alarms();

	pid = spawn_child_core(p, func, data, kill_how,
	    pipe_in ? &fd_in : NULL,
	    pipe_out ? &fd_out : NULL,
	    pipe_err ? &fd_err : NULL);

	if (pid == 0) {
		save_errno = errno;
		ap_unblock_alarms();
		errno = save_errno;
		return 0;
	}

	if (pipe_out) {
		*pipe_out = ap_fdopen(fd_out, "r" BINMODE);
		if (*pipe_out)
			ap_note_cleanups_for_file(p, *pipe_out);
		else
			close(fd_out);
	}

	if (pipe_in) {
		*pipe_in = ap_fdopen(fd_in, "w" BINMODE);
		if (*pipe_in)
			ap_note_cleanups_for_file(p, *pipe_in);
		else
			close(fd_in);
	}

	if (pipe_err) {
		*pipe_err = ap_fdopen(fd_err, "r" BINMODE);
		if (*pipe_err)
			ap_note_cleanups_for_file(p, *pipe_err);
		else
			close(fd_err);
	}

	ap_unblock_alarms();
	return pid;
}

API_EXPORT(int)
ap_bspawn_child(pool *p, int (*func)(void *, child_info *), void *data,
    enum kill_conditions kill_how, BUFF **pipe_in, BUFF **pipe_out,
    BUFF **pipe_err)
{
	int fd_in, fd_out, fd_err;
	pid_t pid;
	int save_errno;

	ap_block_alarms();

	pid = spawn_child_core(p, func, data, kill_how,
	    pipe_in ? &fd_in : NULL,
	    pipe_out ? &fd_out : NULL,
	    pipe_err ? &fd_err : NULL);

	if (pid == 0) {
		save_errno = errno;
		ap_unblock_alarms();
		errno = save_errno;
		return 0;
	}

	if (pipe_out) {
		*pipe_out = ap_bcreate(p, B_RD);
		ap_note_cleanups_for_fd_ex(p, fd_out, 0);
		ap_bpushfd(*pipe_out, fd_out, fd_out);
	}

	if (pipe_in) {
		*pipe_in = ap_bcreate(p, B_WR);
		ap_note_cleanups_for_fd_ex(p, fd_in, 0);
		ap_bpushfd(*pipe_in, fd_in, fd_in);
	}

	if (pipe_err) {
		*pipe_err = ap_bcreate(p, B_RD);
		ap_note_cleanups_for_fd_ex(p, fd_err, 0);
		ap_bpushfd(*pipe_err, fd_err, fd_err);
	}

	ap_unblock_alarms();
	return pid;
}


/* 
 * Timing constants for killing subprocesses
 * There is a total 3-second delay between sending a SIGINT 
 * and sending of the final SIGKILL.
 * TIMEOUT_INTERVAL should be set to TIMEOUT_USECS / 64
 * for the exponential timeout algorithm.
 */
#define TIMEOUT_USECS    3000000
#define TIMEOUT_INTERVAL   46875

static void
free_proc_chain(struct process_chain *procs)
{
	/* Dispose of the subprocesses we've spawned off in the course of
	* whatever it was we're cleaning up now.  This may involve killing
	* some of them off...
	*/
	struct process_chain *p;
	int need_timeout = 0;
	int status;
	int timeout_interval;
	struct timeval tv;

	if (procs == NULL)
		return;			/* No work.  Whew! */

	/* First, check to see if we need to do the SIGTERM, sleep, SIGKILL
	 * dance with any of the processes we're cleaning up.  If we've got
	 * any kill-on-sight subprocesses, ditch them now as well, so they
	 * don't waste any more cycles doing whatever it is that they shouldn't
	 * be doing anymore.
	 */
	/* Pick up all defunct processes */
	for (p = procs; p; p = p->next) {
		if (waitpid(p->pid, (int *) 0, WNOHANG) > 0) {
			p->kill_how = kill_never;
		}
	}

	for (p = procs; p; p = p->next) {
		if ((p->kill_how == kill_after_timeout)
		    || (p->kill_how == kill_only_once)) {
			/*
			 * This is totally bogus, but seems to be the
			 * only portable (as in reliable) way to accomplish
			 * this. Note that this implies an unavoidable
			 * delay.
			 */
			ap_os_kill(p->pid, SIGTERM);
			need_timeout = 1;
		} else if (p->kill_how == kill_always) {
			kill(p->pid, SIGKILL);
		}
	}

	/* Sleep only if we have to. The sleep algorithm grows
	 * by a factor of two on each iteration. TIMEOUT_INTERVAL
	 * is equal to TIMEOUT_USECS / 64.
	 */
	if (need_timeout) {
		timeout_interval = TIMEOUT_INTERVAL;
		tv.tv_sec = 0;
		tv.tv_usec = timeout_interval;
		ap_select(0, NULL, NULL, NULL, &tv);

		do {
			need_timeout = 0;
			for (p = procs; p; p = p->next) {
				if (p->kill_how == kill_after_timeout) {
					if (waitpid(p->pid, (int *)0,
					    WNOHANG | WUNTRACED) > 0)
						p->kill_how = kill_never;
					else
						need_timeout = 1;
				}
			}
			if (need_timeout) {
				if (timeout_interval >= TIMEOUT_USECS)
					break;
				tv.tv_sec = timeout_interval / 1000000;
				tv.tv_usec = timeout_interval % 1000000;
				ap_select(0, NULL, NULL, NULL, &tv);
				timeout_interval *= 2;
			}
		} while (need_timeout);
	}

	/* OK, the scripts we just timed out for have had a chance to clean up
	 * --- now, just get rid of them, and also clean up the system
	 * accounting goop...
	 */
	for (p = procs; p; p = p->next) {
		if (p->kill_how == kill_after_timeout)
		kill(p->pid, SIGKILL);

		if (p->kill_how != kill_never)
			waitpid(p->pid, &status, 0);
	}
}
@


1.19
log
@de-register
@
text
@d1 1
a1 1
/*	$OpenBSD: alloc.c,v 1.18 2008/05/14 08:42:20 mbalmer Exp $ */
@


1.18
log
@Next chunk of KNF/readability changes.

no binary change.
@
text
@d1 1
a1 1
/*	$OpenBSD$ */
d1474 1
a1474 1
	register int i, j, k;
d1506 1
a1506 1
	register int i, j, k;
d1549 1
a1549 1
	register int i, j, k;
@


1.17
log
@A first chunk of readability/knf changes.  Since there is nothing more
to merge from upstream, we can safely sanitize the code and hopefully
the build system.

Discussed with and feedback from sthen, todd, dlg and henning.

no binary changes.
@
text
@d1 2
@


1.16
log
@dead code removal
@
text
@d140 9
a148 9
    /* Types which are likely to have the longest RELEVANT alignment
     * restrictions...
     */

    char *cp;
    void (*f) (void);
    long l;
    FILE *fp;
    double d;
d154 1
a154 1
    union align a;
d156 1
a156 1
    /* Actual header... */
d158 4
a161 4
    struct {
	char *endp;
	union block_hdr *next;
	char *first_avail;
d163 1
a163 1
	int is_shm;
d166 2
a167 2
	union block_hdr *global_next;
	struct pool *owning_pool;
d169 1
a169 1
    } h;
d187 2
a188 2
static ap_inline void debug_verify_filled(const char *ptr,
    const char *endp, const char *error_msg)
d190 6
a195 5
    for (; ptr < endp; ++ptr) {
	if (*ptr != FILL_BYTE) {
	    fputs(error_msg, stderr);
	    abort();
	    exit(1);
a196 1
    }
d209 2
a210 1
static union block_hdr *malloc_block(int size, int is_shm)
d212 2
a213 1
static union block_hdr *malloc_block(int size)
d216 2
a217 2
    union block_hdr *blok;
    int request_size;
d220 25
a244 24
    /* make some room at the end which we'll fill and expect to be
     * always filled
     */
    size += CLICK_SZ;
#endif
    request_size = size + sizeof(union block_hdr);
#if defined(EAPI_MM)
    if (is_shm)
        blok = (union block_hdr *)ap_mm_malloc(mm, request_size);
    else
#endif
    blok = (union block_hdr *) malloc(request_size);
    if (blok == NULL) {
	fprintf(stderr, "Ouch!  malloc(%d) failed in malloc_block()\n",
                request_size);
	exit(1);
    }
    debug_fill(blok, size + sizeof(union block_hdr));
#if defined(EAPI_MM)
    blok->h.is_shm = is_shm;
#endif
    blok->h.next = NULL;
    blok->h.first_avail = (char *) (blok + 1);
    blok->h.endp = size + blok->h.first_avail;
d246 1
a246 1
    blok->h.endp -= CLICK_SZ;
d249 3
a251 3
    blok->h.global_next = global_block_list;
    global_block_list = blok;
    blok->h.owning_pool = NULL;
d254 1
a254 1
    return blok;
a256 2


d258 2
a259 1
static void chk_on_blk_list(union block_hdr *blok, union block_hdr *free_blk)
d261 9
a269 7
    debug_verify_filled(blok->h.endp, blok->h.endp + CLICK_SZ,
	"Ouch!  Someone trounced the padding at the end of a block!\n");
    while (free_blk) {
	if (free_blk == blok) {
	    fprintf(stderr, "Ouch!  Freeing free block\n");
	    abort();
	    exit(1);
a270 2
	free_blk = free_blk->h.next;
    }
d277 2
a278 2

static void free_blocks(union block_hdr *blok)
d281 1
a281 1
    union block_hdr *next;
d283 4
a286 4
    for (; blok; blok = next) {
	next = blok->h.next;
	free(blok);
    }
d288 6
a293 6
    /* First, put new blocks at the head of the free list ---
     * we'll eventually bash the 'next' pointer of the last block
     * in the chain to point to the free blocks we already had.
     */

    union block_hdr *old_free_list;
d295 3
a297 2
    if (blok == NULL)
	return;			/* Sanity check --- freeing empty pool? */
d300 2
a301 2
    if (blok->h.is_shm)
        (void)ap_mm_lock(mm, AP_MM_LOCK_RW);
d303 3
a305 3
    (void) ap_acquire_mutex(alloc_mutex);
    old_free_list = block_freelist;
    block_freelist = blok;
d307 15
a321 5
    /*
     * Next, adjust first_avail pointers of each block --- have to do it
     * sooner or later, and it simplifies the search in new_block to do it
     * now.
     */
a322 1
    while (blok->h.next != NULL) {
d324 1
a324 1
	blok->h.first_avail = (char *) (blok + 1);
a328 2
	blok = blok->h.next;
    }
d330 2
a331 6
    chk_on_blk_list(blok, old_free_list);
    blok->h.first_avail = (char *) (blok + 1);
    debug_fill(blok->h.first_avail, blok->h.endp - blok->h.first_avail);
#ifdef POOL_DEBUG
    blok->h.owning_pool = FREE_POOL;
#endif
d333 1
a333 5
    /* Finally, reset next pointer to get the old free blocks back */

    blok->h.next = old_free_list;

    (void) ap_release_mutex(alloc_mutex);
d335 2
a336 2
    if (blok->h.is_shm)
        (void)ap_mm_unlock(mm);
d342 2
a343 1
/* Get a new block, from our own free list if possible, from the system
a345 1

d347 2
a348 1
static union block_hdr *new_block(int min_size, int is_shm)
d350 2
a351 1
static union block_hdr *new_block(int min_size)
d354 2
a355 2
    union block_hdr **lastptr = &block_freelist;
    union block_hdr *blok = block_freelist;
d357 5
a361 5
    /* First, see if we have anything of the required size
     * on the free list...
     */

    while (blok != NULL) {
d363 3
a365 2
    if (blok->h.is_shm == is_shm &&
        min_size + BLOCK_MINFREE <= blok->h.endp - blok->h.first_avail) {
d367 2
a368 1
	if (min_size + BLOCK_MINFREE <= blok->h.endp - blok->h.first_avail) {
d370 11
a380 5
	    *lastptr = blok->h.next;
	    blok->h.next = NULL;
	    debug_verify_filled(blok->h.first_avail, blok->h.endp,
		"Ouch!  Someone trounced a block on the free list!\n");
	    return blok;
a381 7
	else {
	    lastptr = &blok->h.next;
	    blok = blok->h.next;
	}
    }

    /* Nope. */
d383 2
a384 1
    min_size += BLOCK_MINFREE;
d386 2
a387 1
    blok = malloc_block((min_size > BLOCK_MINALLOC) ? min_size : BLOCK_MINALLOC, is_shm);
d389 2
a390 1
    blok = malloc_block((min_size > BLOCK_MINALLOC) ? min_size : BLOCK_MINALLOC);
d392 1
a392 1
    return blok;
d397 2
a398 2

static long bytes_in_block_list(union block_hdr *blok)
d400 1
a400 1
    long size = 0;
d402 4
a405 4
    while (blok) {
	size += blok->h.endp - (char *) (blok + 1);
	blok = blok->h.next;
    }
d407 1
a407 1
    return size;
d426 9
a434 9
    union block_hdr *first;
    union block_hdr *last;
    struct cleanup *cleanups;
    struct process_chain *subprocesses;
    struct pool *sub_pools;
    struct pool *sub_next;
    struct pool *sub_prev;
    struct pool *parent;
    char *free_first_avail;
d436 1
a436 1
    void *allocation_list;
d439 1
a439 1
    struct pool *joined;
d442 1
a442 1
    int is_shm;
d459 2
a460 1
static struct pool *make_sub_pool_internal(struct pool *p, int is_shm)
d462 2
a463 1
API_EXPORT(struct pool *) ap_make_sub_pool(struct pool *p)
d466 2
a467 2
    union block_hdr *blok;
    pool *new_pool;
d469 1
a469 1
    ap_block_alarms();
d472 2
a473 2
    if (is_shm)
        (void)ap_mm_lock(mm, AP_MM_LOCK_RW);
d475 1
a475 1
    (void) ap_acquire_mutex(alloc_mutex);
d478 1
a478 1
    blok = new_block(POOL_HDR_BYTES, is_shm);
d480 1
a480 1
    blok = new_block(POOL_HDR_BYTES);
d482 2
a483 2
    new_pool = (pool *) blok->h.first_avail;
    blok->h.first_avail += POOL_HDR_BYTES;
d485 1
a485 1
    blok->h.owning_pool = new_pool;
d488 3
a490 3
    memset((char *) new_pool, '\0', sizeof(struct pool));
    new_pool->free_first_avail = blok->h.first_avail;
    new_pool->first = new_pool->last = blok;
d492 7
a498 7
    if (p) {
	new_pool->parent = p;
	new_pool->sub_next = p->sub_pools;
	if (new_pool->sub_next)
	    new_pool->sub_next->sub_prev = new_pool;
	p->sub_pools = new_pool;
    }
d501 1
a501 1
    new_pool->is_shm = is_shm;
d504 1
a504 1
    (void) ap_release_mutex(alloc_mutex);
d506 2
a507 2
    if (is_shm)
	(void)ap_mm_unlock(mm);
d509 1
a509 1
    ap_unblock_alarms();
d511 1
a511 1
    return new_pool;
d515 2
a516 1
API_EXPORT(struct pool *) ap_make_sub_pool(struct pool *p)
d518 1
a518 1
    return make_sub_pool_internal(p, 0);
d520 2
a521 1
API_EXPORT(struct pool *) ap_make_shared_sub_pool(struct pool *p)
d523 1
a523 1
    return make_sub_pool_internal(p, 1);
d526 2
a527 1
API_EXPORT(struct pool *) ap_make_shared_sub_pool(struct pool *p)
d529 1
a529 1
    return NULL;
d534 2
a535 1
static void stack_var_init(char *s)
d537 1
a537 1
    char t;
d539 4
a542 6
    if (s < &t) {
	stack_direction = 1; /* stack grows up */
    }
    else {
	stack_direction = -1; /* stack grows down */
    }
d546 2
a547 1
int ap_shared_pool_possible(void)
d549 1
a549 1
    return ap_mm_useable();
d552 2
a553 1
API_EXPORT(pool *) ap_init_alloc(void)
d556 1
a556 1
    char s;
d558 2
a559 2
    known_stack_point = &s;
    stack_var_init(&s);
d561 38
a598 37
    alloc_mutex = ap_create_mutex(NULL);
    spawn_mutex = ap_create_mutex(NULL);
    permanent_pool = ap_make_sub_pool(NULL);
    return permanent_pool;
}

void ap_init_alloc_shared(int early)
{
#if defined(EAPI_MM)
    int mm_size;
    char *mm_path;
    char *err1, *err2;

    if (early) {
        /* process very early on startup */
        mm_size = ap_mm_maxsize();
        if (mm_size > EAPI_MM_CORE_MAXSIZE)
            mm_size = EAPI_MM_CORE_MAXSIZE;
        mm_path = ap_server_root_relative(permanent_pool, 
                  ap_psprintf(permanent_pool, "%s.%ld", 
                              EAPI_MM_CORE_PATH, (long)getpid()));
        if ((mm = ap_mm_create(mm_size, mm_path)) == NULL) {
            fprintf(stderr, "Ouch! ap_mm_create(%d, \"%s\") failed\n", mm_size, mm_path);
            err1 = ap_mm_error();
            if (err1 == NULL)
                err1 = "-unknown-";
            err2 = strerror(errno);
            if (err2 == NULL)
                err2 = "-unknown-";
            fprintf(stderr, "Error: MM: %s: OS: %s\n", err1, err2);
            exit(1);
        }
    }
    else {
        /* process a lot later on startup */
        ap_mm_permission(mm, (S_IRUSR|S_IWUSR), ap_user_id, -1);
    }
d600 1
a600 1
    return; 
d603 2
a604 1
void ap_kill_alloc_shared(void)
d607 4
a610 4
    if (mm != NULL) {
        ap_mm_destroy(mm);
        mm = NULL;
    }
d612 1
a612 1
    return;
d615 2
a616 1
void ap_cleanup_alloc(void)
d618 2
a619 2
    ap_destroy_mutex(alloc_mutex);
    ap_destroy_mutex(spawn_mutex);
d622 2
a623 1
API_EXPORT(void) ap_clear_pool(struct pool *a)
d625 1
a625 1
    ap_block_alarms();
d628 2
a629 2
    if (a->is_shm)
        (void)ap_mm_lock(mm, AP_MM_LOCK_RW);
d631 4
a634 4
    (void) ap_acquire_mutex(alloc_mutex);
    while (a->sub_pools)
	ap_destroy_pool(a->sub_pools);
    (void) ap_release_mutex(alloc_mutex);
d636 2
a637 2
    if (a->is_shm)
	    (void)ap_mm_unlock(mm);
d639 11
a649 11
    /* Don't hold the mutex during cleanups. */
    run_cleanups(a->cleanups);
    a->cleanups = NULL;
    free_proc_chain(a->subprocesses);
    a->subprocesses = NULL;
    free_blocks(a->first->h.next);
    a->first->h.next = NULL;

    a->last = a->first;
    a->first->h.first_avail = a->free_first_avail;
    debug_fill(a->first->h.first_avail,
d653 2
a654 2
    {
	void *c, *n;
d656 5
a660 3
	for (c = a->allocation_list; c; c = n) {
	    n = *(void **)c;
	    free(c);
a661 2
	a->allocation_list = NULL;
    }
d664 1
a664 1
    ap_unblock_alarms();
d667 2
a668 1
API_EXPORT(void) ap_destroy_pool(pool *a)
d670 2
a671 2
    ap_block_alarms();
    ap_clear_pool(a);
d674 2
a675 2
    if (a->is_shm)
	(void)ap_mm_lock(mm, AP_MM_LOCK_RW);
d677 10
a686 10
    (void) ap_acquire_mutex(alloc_mutex);
    if (a->parent) {
	if (a->parent->sub_pools == a)
	    a->parent->sub_pools = a->sub_next;
	if (a->sub_prev)
	    a->sub_prev->sub_next = a->sub_next;
	if (a->sub_next)
	    a->sub_next->sub_prev = a->sub_prev;
    }
    (void) ap_release_mutex(alloc_mutex);
d688 2
a689 2
    if (a->is_shm)
	(void)ap_mm_unlock(mm);
d692 2
a693 2
    free_blocks(a->first);
    ap_unblock_alarms();
d696 2
a697 1
API_EXPORT(long) ap_bytes_in_pool(pool *p)
d699 1
a699 1
    return bytes_in_block_list(p->first);
d701 2
a702 1
API_EXPORT(long) ap_bytes_in_free_blocks(void)
d704 1
a704 1
    return bytes_in_block_list(block_freelist);
d707 2
a708 1
API_EXPORT(int) ap_acquire_pool(pool *p, ap_pool_lock_mode mode)
d711 4
a714 3
    if (!p->is_shm)
        return 1;
    return ap_mm_lock(mm, mode == AP_POOL_RD ? AP_MM_LOCK_RD : AP_MM_LOCK_RW);
d720 2
a721 1
API_EXPORT(int) ap_release_pool(pool *p)
d724 3
a726 3
    if (!p->is_shm)
        return 1;
    return ap_mm_unlock(mm);
d751 2
a752 1
API_EXPORT(pool *) ap_find_pool(const void *ts)
d754 44
a797 14
    const char *s = ts;
    union block_hdr **pb;
    union block_hdr *b;

    /* short-circuit stuff which is in TEXT, BSS, or DATA */
    if (is_ptr_in_range(s, 0, &_end)) {
	return NULL;
    }
    /* consider stuff on the stack to also be in the NULL pool...
     * XXX: there's cases where we don't want to assume this
     */
    if ((stack_direction == -1 && is_ptr_in_range(s, &ts, known_stack_point))
	|| (stack_direction == 1 && is_ptr_in_range(s, known_stack_point, &ts))) {
	abort();
a798 25
    }
    ap_block_alarms();
    /* search the global_block_list */
    for (pb = &global_block_list; *pb; pb = &b->h.global_next) {
	b = *pb;
	if (is_ptr_in_range(s, b, b->h.endp)) {
	    if (b->h.owning_pool == FREE_POOL) {
		fprintf(stderr,
		    "Ouch!  find_pool() called on pointer in a free block\n");
		abort();
		exit(1);
	    }
	    if (b != global_block_list) {
		/* promote b to front of list, this is a hack to speed
		 * up the lookup */
		*pb = b->h.global_next;
		b->h.global_next = global_block_list;
		global_block_list = b;
	    }
	    ap_unblock_alarms();
	    return b->h.owning_pool;
	}
    }
    ap_unblock_alarms();
    return NULL;
d804 2
a805 1
API_EXPORT(int) ap_pool_is_ancestor(pool *a, pool *b)
d807 12
a818 13
    if (a == NULL) {
	return 1;
    }
    while (a->joined) {
	a = a->joined;
    }
    while (b) {
	if (a == b) {
	    return 1;
	}
	b = b->parent;
    }
    return 0;
d825 2
a826 1
API_EXPORT(void) ap_pool_join(pool *p, pool *sub)
d828 1
a828 1
    union block_hdr *b;
d830 13
a842 13
    /* We could handle more general cases... but this is it for now. */
    if (sub->parent != p) {
	fprintf(stderr, "pool_join: p is not parent of sub\n");
	abort();
    }
    ap_block_alarms();
    while (p->joined) {
	p = p->joined;
    }
    sub->joined = p;
    for (b = global_block_list; b; b = b->h.global_next) {
	if (b->h.owning_pool == sub) {
	    b->h.owning_pool = p;
d844 1
a844 2
    }
    ap_unblock_alarms();
d854 2
a855 1
API_EXPORT(void *) ap_palloc(struct pool *a, int reqsize)
d858 2
a859 2
    int size = reqsize + CLICK_SZ;
    void *ptr;
d861 11
a871 11
    ap_block_alarms();
    ptr = malloc(size);
    if (ptr == NULL) {
	fputs("Ouch!  Out of memory!\n", stderr);
	exit(1);
    }
    debug_fill(ptr, size); /* might as well get uninitialized protection */
    *(void **)ptr = a->allocation_list;
    a->allocation_list = ptr;
    ap_unblock_alarms();
    return (char *)ptr + CLICK_SZ;
d874 6
a879 2
    /* Round up requested size to an even number of alignment units (core clicks)
     */
d881 7
a887 2
    int nclicks = 1 + ((reqsize - 1) / CLICK_SZ);
    int size = nclicks * CLICK_SZ;
d889 2
a890 3
    /* First, see if we have space in the block most recently
     * allocated to this pool
     */
d892 1
a892 3
    union block_hdr *blok = a->last;
    char *first_avail = blok->h.first_avail;
    char *new_first_avail;
d894 7
a900 4
    if (reqsize <= 0)
	return NULL;

    new_first_avail = first_avail + size;
d902 2
a903 10
    if (new_first_avail <= blok->h.endp) {
	debug_verify_filled(first_avail, blok->h.endp,
	    "Ouch!  Someone trounced past the end of their allocation!\n");
	blok->h.first_avail = new_first_avail;
	return (void *) first_avail;
    }

    /* Nope --- get a new one that's guaranteed to be big enough */

    ap_block_alarms();
d906 2
a907 2
    if (a->is_shm)
	(void)ap_mm_lock(mm, AP_MM_LOCK_RW);
d909 1
a909 1
    (void) ap_acquire_mutex(alloc_mutex);
d912 1
a912 1
    blok = new_block(size, a->is_shm);
d914 1
a914 1
    blok = new_block(size);
d916 2
a917 2
    a->last->h.next = blok;
    a->last = blok;
d919 1
a919 1
    blok->h.owning_pool = a;
d922 1
a922 1
    blok->h.is_shm = a->is_shm;
d925 1
a925 1
    (void) ap_release_mutex(alloc_mutex);
d927 2
a928 2
    if (a->is_shm)
	(void)ap_mm_unlock(mm);
d931 1
a931 1
    ap_unblock_alarms();
d933 2
a934 2
    first_avail = blok->h.first_avail;
    blok->h.first_avail += size;
d936 1
a936 1
    return (void *) first_avail;
d940 2
a941 1
API_EXPORT(void *) ap_pcalloc(struct pool *a, int size)
d943 3
a945 3
    void *res = ap_palloc(a, size);
    memset(res, '\0', size);
    return res;
d948 2
a949 1
API_EXPORT(char *) ap_pstrdup(struct pool *a, const char *s)
d951 2
a952 2
    char *res;
    size_t len;
d954 6
a959 6
    if (s == NULL)
	return NULL;
    len = strlen(s) + 1;
    res = ap_palloc(a, len);
    memcpy(res, s, len);
    return res;
d962 2
a963 1
API_EXPORT(char *) ap_pstrndup(struct pool *a, const char *s, int n)
d965 1
a965 1
    char *res;
d967 6
a972 6
    if (s == NULL)
	return NULL;
    res = ap_palloc(a, n + 1);
    memcpy(res, s, n);
    res[n] = '\0';
    return res;
d977 1
a977 1
    char *cp, *argp, *res;
d979 3
a981 1
    /* Pass one --- find length of required string */
d983 1
a983 2
    int len = 0;
    va_list adummy;
d985 2
a986 1
    va_start(adummy, a);
d988 1
a988 2
    while ((cp = va_arg(adummy, char *)) != NULL)
	     len += strlen(cp);
d990 4
a993 1
    va_end(adummy);
d995 2
a996 1
    /* Allocate the required string */
d998 4
a1001 12
    res = (char *) ap_palloc(a, len + 1);
    cp = res;
    *cp = '\0';

    /* Pass two --- copy the argument strings into the result space */

    va_start(adummy, a);

    while ((argp = va_arg(adummy, char *)) != NULL) {
	strlcpy(cp, argp, len + 1);
	cp += strlen(argp);
    }
d1003 1
a1003 1
    va_end(adummy);
d1005 2
a1006 3
    /* Return the result string */

    return res;
d1023 1
a1023 1
    ap_vformatter_buff vbuff;
d1025 1
a1025 1
    char *base;
d1027 2
a1028 2
    union block_hdr *blok;
    int got_a_new_block;
d1034 2
a1035 1
static int psprintf_flush(ap_vformatter_buff *vbuff)
d1037 1
a1037 1
    struct psprintf_data *ps = (struct psprintf_data *)vbuff;
d1039 2
a1040 2
    int cur_len, size;
    char *ptr;
d1042 18
a1059 18
    cur_len = (char *)ps->vbuff.curpos - ps->base;
    size = cur_len << 1;
    if (size < AP_PSPRINTF_MIN_SIZE)
        size = AP_PSPRINTF_MIN_SIZE;
#if defined(EAPI_MM)
    if (ps->block->h.is_shm)
        ptr = ap_mm_realloc(ps->base, size);
    else
#endif
    ptr = realloc(ps->base, size);
    if (ptr == NULL) {
	fputs("Ouch!  Out of memory!\n", stderr);
	exit(1);
    }
    ps->base = ptr;
    ps->vbuff.curpos = ptr + cur_len;
    ps->vbuff.endpos = ptr + size - 1;
    return 0;
d1061 11
a1071 11
    union block_hdr *blok;
    union block_hdr *nblok;
    size_t cur_len, size;
    char *strp;

    blok = ps->blok;
    strp = ps->vbuff.curpos;
    cur_len = strp - blok->h.first_avail;
    size = cur_len << 1;
    if (size < AP_PSPRINTF_MIN_SIZE)
        size = AP_PSPRINTF_MIN_SIZE;
d1073 1
a1073 1
    /* must try another blok */
d1075 2
a1076 2
    if (blok->h.is_shm)
	(void)ap_mm_lock(mm, AP_MM_LOCK_RW);
d1078 1
a1078 1
    (void) ap_acquire_mutex(alloc_mutex);
d1080 1
a1080 1
    nblok = new_block(size, blok->h.is_shm);
d1082 1
a1082 1
    nblok = new_block(size);
d1084 1
a1084 1
    (void) ap_release_mutex(alloc_mutex);
d1086 2
a1087 2
    if (blok->h.is_shm)
	(void)ap_mm_unlock(mm);
d1089 4
a1092 4
    memcpy(nblok->h.first_avail, blok->h.first_avail, cur_len);
    ps->vbuff.curpos = nblok->h.first_avail + cur_len;
    /* save a byte for the NUL terminator */
    ps->vbuff.endpos = nblok->h.endp - 1;
d1094 4
a1097 3
    /* did we allocate the current blok? if so free it up */
    if (ps->got_a_new_block) {
	debug_fill(blok->h.first_avail, blok->h.endp - blok->h.first_avail);
d1099 2
a1100 2
    if (blok->h.is_shm)
	(void)ap_mm_lock(mm, AP_MM_LOCK_RW);
d1102 4
a1105 4
	(void) ap_acquire_mutex(alloc_mutex);
	blok->h.next = block_freelist;
	block_freelist = blok;
	(void) ap_release_mutex(alloc_mutex);
d1107 2
a1108 2
    if (blok->h.is_shm)
	(void)ap_mm_unlock(mm);
d1110 9
a1118 8
    }
    ps->blok = nblok;
    ps->got_a_new_block = 1;
    /* note that we've deliberately not linked the new block onto
     * the pool yet... because we may need to flush again later, and
     * we'd have to spend more effort trying to unlink the block.
     */
    return 0;
d1122 2
a1123 1
API_EXPORT(char *) ap_pvsprintf(pool *p, const char *fmt, va_list ap)
d1126 2
a1127 2
    struct psprintf_data ps;
    void *ptr;
d1129 1
a1129 1
    ap_block_alarms();
d1131 30
a1160 30
    if (p->is_shm)
        ps.base = ap_mm_malloc(mm, 512);
    else
#endif
    ps.base = malloc(512);
    if (ps.base == NULL) {
	fputs("Ouch!  Out of memory!\n", stderr);
	exit(1);
    }
    /* need room at beginning for allocation_list */
    ps.vbuff.curpos = ps.base + CLICK_SZ;
    ps.vbuff.endpos = ps.base + 511;
    ap_vformatter(psprintf_flush, &ps.vbuff, fmt, ap);
    *ps.vbuff.curpos++ = '\0';
    ptr = ps.base;
    /* shrink */
#if defined(EAPI_MM)
    if (p->is_shm)
        ptr = ap_mm_realloc(ptr, (char *)ps.vbuff.curpos - (char *)ptr);
    else
#endif
    ptr = realloc(ptr, (char *)ps.vbuff.curpos - (char *)ptr);
    if (ptr == NULL) {
	fputs("Ouch!  Out of memory!\n", stderr);
	exit(1);
    }
    *(void **)ptr = p->allocation_list;
    p->allocation_list = ptr;
    ap_unblock_alarms();
    return (char *)ptr + CLICK_SZ;
d1162 26
a1187 26
    struct psprintf_data ps;
    char *strp;
    int size;

    ap_block_alarms();
    ps.blok = p->last;
    ps.vbuff.curpos = ps.blok->h.first_avail;
    ps.vbuff.endpos = ps.blok->h.endp - 1;	/* save one for NUL */
    ps.got_a_new_block = 0;

    if (ps.blok->h.first_avail == ps.blok->h.endp)
        psprintf_flush(&ps.vbuff);		/* ensure room for NUL */
    ap_vformatter(psprintf_flush, &ps.vbuff, fmt, ap);

    strp = ps.vbuff.curpos;
    *strp++ = '\0';

    size = strp - ps.blok->h.first_avail;
    size = (1 + ((size - 1) / CLICK_SZ)) * CLICK_SZ;
    strp = ps.blok->h.first_avail;	/* save away result pointer */
    ps.blok->h.first_avail += size;

    /* have to link the block in if it's a new one */
    if (ps.got_a_new_block) {
	p->last->h.next = ps.blok;
	p->last = ps.blok;
d1189 1
a1189 1
	ps.blok->h.owning_pool = p;
d1191 2
a1192 2
    }
    ap_unblock_alarms();
d1194 1
a1194 1
    return strp;
d1198 2
a1199 1
API_EXPORT_NONSTD(char *) ap_psprintf(pool *p, const char *fmt, ...)
d1201 2
a1202 2
    va_list ap;
    char *res;
d1204 4
a1207 4
    va_start(ap, fmt);
    res = ap_pvsprintf(p, fmt, ap);
    va_end(ap);
    return res;
d1215 2
a1216 1
static void make_array_core(array_header *res, pool *p, int nelts, int elt_size)
d1218 2
a1219 2
    if (nelts < 1)
	nelts = 1;		/* Assure sanity if someone asks for
d1223 1
a1223 1
    res->elts = ap_pcalloc(p, nelts * elt_size);
d1225 4
a1228 4
    res->pool = p;
    res->elt_size = elt_size;
    res->nelts = 0;		/* No active elements yet... */
    res->nalloc = nelts;	/* ...but this many allocated */
d1231 2
a1232 1
API_EXPORT(array_header *) ap_make_array(pool *p, int nelts, int elt_size)
d1234 1
a1234 1
    array_header *res = (array_header *) ap_palloc(p, sizeof(array_header));
d1236 2
a1237 2
    make_array_core(res, p, nelts, elt_size);
    return res;
d1240 2
a1241 1
API_EXPORT(void *) ap_push_array(array_header *arr)
d1243 3
a1245 3
    if (arr->nelts == arr->nalloc) {
	int new_size = (arr->nalloc <= 0) ? 1 : arr->nalloc * 2;
	char *new_data;
d1247 1
a1247 1
	new_data = ap_pcalloc(arr->pool, arr->elt_size * new_size);
d1249 4
a1252 4
	memcpy(new_data, arr->elts, arr->nalloc * arr->elt_size);
	arr->elts = new_data;
	arr->nalloc = new_size;
    }
d1254 2
a1255 2
    ++arr->nelts;
    return arr->elts + (arr->elt_size * (arr->nelts - 1));
d1258 2
a1259 1
API_EXPORT(void) ap_array_cat(array_header *dst, const array_header *src)
d1261 1
a1261 1
    int elt_size = dst->elt_size;
d1263 3
a1265 3
    if (dst->nelts + src->nelts > dst->nalloc) {
	int new_size = (dst->nalloc <= 0) ? 1 : dst->nalloc * 2;
	char *new_data;
d1267 2
a1268 2
	while (dst->nelts + src->nelts > new_size)
	    new_size *= 2;
d1270 2
a1271 2
	new_data = ap_pcalloc(dst->pool, elt_size * new_size);
	memcpy(new_data, dst->elts, dst->nalloc * elt_size);
d1273 3
a1275 3
	dst->elts = new_data;
	dst->nalloc = new_size;
    }
d1277 3
a1279 2
    memcpy(dst->elts + dst->nelts * elt_size, src->elts, elt_size * src->nelts);
    dst->nelts += src->nelts;
d1282 2
a1283 1
API_EXPORT(array_header *) ap_copy_array(pool *p, const array_header *arr)
d1285 1
a1285 1
    array_header *res = ap_make_array(p, arr->nalloc, arr->elt_size);
d1287 3
a1289 3
    memcpy(res->elts, arr->elts, arr->elt_size * arr->nelts);
    res->nelts = arr->nelts;
    return res;
d1299 2
a1300 2
static ap_inline void copy_array_hdr_core(array_header *res,
    const array_header *arr)
d1302 4
a1305 4
    res->elts = arr->elts;
    res->elt_size = arr->elt_size;
    res->nelts = arr->nelts;
    res->nalloc = arr->nelts;	/* Force overflow on push */
d1308 2
a1309 1
API_EXPORT(array_header *) ap_copy_array_hdr(pool *p, const array_header *arr)
d1311 1
a1311 1
    array_header *res = (array_header *) ap_palloc(p, sizeof(array_header));
d1313 3
a1315 3
    res->pool = p;
    copy_array_hdr_core(res, arr);
    return res;
d1320 2
a1321 3
API_EXPORT(array_header *) ap_append_arrays(pool *p,
					 const array_header *first,
					 const array_header *second)
d1323 1
a1323 1
    array_header *res = ap_copy_array_hdr(p, first);
d1325 2
a1326 2
    ap_array_cat(res, second);
    return res;
d1335 2
a1336 2
API_EXPORT(char *) ap_array_pstrcat(pool *p, const array_header *arr,
                                    const char sep)
d1338 2
a1339 2
    char *cp, *res, **strpp;
    int i, len;
d1341 2
a1342 2
    if (arr->nelts <= 0 || arr->elts == NULL)      /* Empty table? */
        return (char *) ap_pcalloc(p, 1);
d1344 28
a1371 33
    /* Pass one --- find length of required string */

    len = 0;
    for (i = 0, strpp = (char **) arr->elts; ; ++strpp) {
        if (strpp && *strpp != NULL) {
            len += strlen(*strpp);
        }
        if (++i >= arr->nelts)
            break;
        if (sep)
            ++len;
    }

    /* Allocate the required string */

    res = (char *) ap_palloc(p, len + 1);
    cp = res;

    /* Pass two --- copy the argument strings into the result space */

    for (i = 0, strpp = (char **) arr->elts; ; ++strpp) {
        if (strpp && *strpp != NULL) {
            len = strlen(*strpp);
            memcpy(cp, *strpp, len);
            cp += len;
        }
        if (++i >= arr->nelts)
            break;
        if (sep)
            *cp++ = sep;
    }

    *cp = '\0';
d1373 1
a1373 1
    /* Return the result string */
d1375 2
a1376 1
    return res;
d1388 6
a1393 6
    /* This has to be first to promote backwards compatibility with
     * older modules which cast a table * to an array_header *...
     * they should use the table_elts() function for most of the
     * cases they do this for.
     */
    array_header a;
d1395 1
a1395 1
    void *creator;
d1400 2
a1401 1
static table_entry *table_push(table *t)
d1403 6
a1408 6
    if (t->a.nelts == t->a.nalloc) {
	fprintf(stderr,
	    "table_push: table created by %p hit limit of %u\n",
	    t->creator, t->a.nalloc);
    }
    return (table_entry *) ap_push_array(&t->a);
d1411 1
a1411 1
#define table_push(t)	((table_entry *) ap_push_array(&(t)->a))
d1414 2
a1415 2

API_EXPORT(table *) ap_make_table(pool *p, int nelts)
d1417 1
a1417 1
    table *t = ap_palloc(p, sizeof(table));
d1419 1
a1419 1
    make_array_core(&t->a, p, nelts, sizeof(table_entry));
d1421 1
a1421 1
    t->creator = __builtin_return_address(0);
d1423 1
a1423 1
    return t;
d1426 2
a1427 1
API_EXPORT(table *) ap_copy_table(pool *p, const table *t)
d1429 1
a1429 1
    table *new = ap_palloc(p, sizeof(table));
d1432 8
a1439 7
    /* we don't copy keys and values, so it's necessary that t->a.pool
     * have a life span at least as long as p
     */
    if (!ap_pool_is_ancestor(t->a.pool, p)) {
	fprintf(stderr, "copy_table: t's pool is not an ancestor of p\n");
	abort();
    }
d1441 4
a1444 4
    make_array_core(&new->a, p, t->a.nalloc, sizeof(table_entry));
    memcpy(new->a.elts, t->a.elts, t->a.nelts * sizeof(table_entry));
    new->a.nelts = t->a.nelts;
    return new;
d1447 2
a1448 1
API_EXPORT(void) ap_clear_table(table *t)
d1450 1
a1450 1
    t->a.nelts = 0;
d1453 2
a1454 1
API_EXPORT(const char *) ap_table_get(const table *t, const char *key)
d1456 2
a1457 2
    table_entry *elts = (table_entry *) t->a.elts;
    int i;
d1459 2
a1460 2
    if (key == NULL)
	return NULL;
d1462 3
a1464 3
    for (i = 0; i < t->a.nelts; ++i)
	if (!strcasecmp(elts[i].key, key))
	    return elts[i].val;
d1466 1
a1466 1
    return NULL;
d1469 2
a1470 1
API_EXPORT(void) ap_table_set(table *t, const char *key, const char *val)
d1472 26
a1497 18
    register int i, j, k;
    table_entry *elts = (table_entry *) t->a.elts;
    int done = 0;

    for (i = 0; i < t->a.nelts; ) {
	if (!strcasecmp(elts[i].key, key)) {
	    if (!done) {
		elts[i].val = ap_pstrdup(t->a.pool, val);
		done = 1;
		++i;
	    }
	    else {		/* delete an extraneous element */
		for (j = i, k = i + 1; k < t->a.nelts; ++j, ++k) {
		    elts[j].key = elts[k].key;
		    elts[j].val = elts[k].val;
		}
		--t->a.nelts;
	    }
a1498 10
	else {
	    ++i;
	}
    }

    if (!done) {
	elts = (table_entry *) table_push(t);
	elts->key = ap_pstrdup(t->a.pool, key);
	elts->val = ap_pstrdup(t->a.pool, val);
    }
d1501 6
a1506 5
API_EXPORT(void) ap_table_setn(table *t, const char *key, const char *val)
{
    register int i, j, k;
    table_entry *elts = (table_entry *) t->a.elts;
    int done = 0;
a1508 1
    {
d1510 2
a1511 2
	    fprintf(stderr, "table_set: key not in ancestor pool of t\n");
	    abort();
d1514 2
a1515 2
	    fprintf(stderr, "table_set: val not in ancestor pool of t\n");
	    abort();
a1516 1
    }
d1519 22
a1540 14
    for (i = 0; i < t->a.nelts; ) {
	if (!strcasecmp(elts[i].key, key)) {
	    if (!done) {
		elts[i].val = (char *)val;
		done = 1;
		++i;
	    }
	    else {		/* delete an extraneous element */
		for (j = i, k = i + 1; k < t->a.nelts; ++j, ++k) {
		    elts[j].key = elts[k].key;
		    elts[j].val = elts[k].val;
		}
		--t->a.nelts;
	    }
a1541 10
	else {
	    ++i;
	}
    }

    if (!done) {
	elts = (table_entry *) table_push(t);
	elts->key = (char *)key;
	elts->val = (char *)val;
    }
d1544 22
a1565 21
API_EXPORT(void) ap_table_unset(table *t, const char *key)
{
    register int i, j, k;
    table_entry *elts = (table_entry *) t->a.elts;

    for (i = 0; i < t->a.nelts;) {
	if (!strcasecmp(elts[i].key, key)) {

	    /* found an element to skip over
	     * there are any number of ways to remove an element from
	     * a contiguous block of memory.  I've chosen one that
	     * doesn't do a memcpy/bcopy/array_delete, *shrug*...
	     */
	    for (j = i, k = i + 1; k < t->a.nelts; ++j, ++k) {
		elts[j].key = elts[k].key;
		elts[j].val = elts[k].val;
	    }
	    --t->a.nelts;
	}
	else {
	    ++i;
a1566 1
    }
d1569 12
a1580 4
API_EXPORT(void) ap_table_merge(table *t, const char *key, const char *val)
{
    table_entry *elts = (table_entry *) t->a.elts;
    int i;
d1582 3
a1584 9
    for (i = 0; i < t->a.nelts; ++i)
	if (!strcasecmp(elts[i].key, key)) {
	    elts[i].val = ap_pstrcat(t->a.pool, elts[i].val, ", ", val, NULL);
	    return;
	}

    elts = (table_entry *) table_push(t);
    elts->key = ap_pstrdup(t->a.pool, key);
    elts->val = ap_pstrdup(t->a.pool, val);
d1587 2
a1588 1
API_EXPORT(void) ap_table_mergen(table *t, const char *key, const char *val)
d1590 2
a1591 2
    table_entry *elts = (table_entry *) t->a.elts;
    int i;
a1593 1
    {
d1595 2
a1596 2
	    fprintf(stderr, "table_set: key not in ancestor pool of t\n");
	    abort();
d1599 2
a1600 2
	    fprintf(stderr, "table_set: key not in ancestor pool of t\n");
	    abort();
a1601 1
    }
d1604 6
a1609 4
    for (i = 0; i < t->a.nelts; ++i) {
	if (!strcasecmp(elts[i].key, key)) {
	    elts[i].val = ap_pstrcat(t->a.pool, elts[i].val, ", ", val, NULL);
	    return;
a1610 1
    }
d1612 3
a1614 3
    elts = (table_entry *) table_push(t);
    elts->key = (char *)key;
    elts->val = (char *)val;
d1617 2
a1618 1
API_EXPORT(void) ap_table_add(table *t, const char *key, const char *val)
d1620 1
a1620 1
    table_entry *elts = (table_entry *) t->a.elts;
d1622 3
a1624 3
    elts = (table_entry *) table_push(t);
    elts->key = ap_pstrdup(t->a.pool, key);
    elts->val = ap_pstrdup(t->a.pool, val);
d1627 2
a1628 1
API_EXPORT(void) ap_table_addn(table *t, const char *key, const char *val)
d1630 1
a1630 1
    table_entry *elts = (table_entry *) t->a.elts;
a1632 1
    {
d1634 2
a1635 2
	    fprintf(stderr, "table_set: key not in ancestor pool of t\n");
	    abort();
d1638 2
a1639 2
	    fprintf(stderr, "table_set: key not in ancestor pool of t\n");
	    abort();
a1640 1
    }
d1643 3
a1645 3
    elts = (table_entry *) table_push(t);
    elts->key = (char *)key;
    elts->val = (char *)val;
d1648 2
a1649 1
API_EXPORT(table *) ap_overlay_tables(pool *p, const table *overlay, const table *base)
d1651 1
a1651 1
    table *res;
d1654 21
a1674 19
    /* we don't copy keys and values, so it's necessary that
     * overlay->a.pool and base->a.pool have a life span at least
     * as long as p
     */
    if (!ap_pool_is_ancestor(overlay->a.pool, p)) {
	fprintf(stderr, "overlay_tables: overlay's pool is not an ancestor of p\n");
	abort();
    }
    if (!ap_pool_is_ancestor(base->a.pool, p)) {
	fprintf(stderr, "overlay_tables: base's pool is not an ancestor of p\n");
	abort();
    }
#endif

    res = ap_palloc(p, sizeof(table));
    /* behave like append_arrays */
    res->a.pool = p;
    copy_array_hdr_core(&res->a, &overlay->a);
    ap_array_cat(&res->a, &base->a);
d1676 1
a1676 1
    return res;
d1701 20
a1720 7
API_EXPORT_NONSTD(void) ap_table_do(int (*comp) (void *, const char *, const char *), 
	                            void *rec, const table *t,...)
{
    va_list vp;
    char *argp;
    table_entry *elts = (table_entry *) t->a.elts;
    int rv, i;
d1722 1
a1722 13
    va_start(vp, t);

    argp = va_arg(vp, char *);

    do {
	for (rv = 1, i = 0; rv && (i < t->a.nelts); ++i) {
	    if (elts[i].key && (!argp || !strcasecmp(elts[i].key, argp))) {
		rv = (*comp) (rec, elts[i].key, elts[i].val);
	    }
	}
    } while (argp && ((argp = va_arg(vp, char *)) != NULL));

    va_end(vp);
d1734 3
a1736 3
    char *key;
    char *val;
    int order;
d1739 2
a1740 1
static int sort_overlap(const void *va, const void *vb)
d1742 8
a1749 9
    const overlap_key *a = va;
    const overlap_key *b = vb;
    int r;

    r = strcasecmp(a->key, b->key);
    if (r) {
	return r;
    }
    return a->order - b->order;
d1757 2
a1758 1
API_EXPORT(void) ap_overlap_tables(table *a, const table *b, unsigned flags)
d1760 48
a1807 16
    overlap_key cat_keys_buf[AP_OVERLAP_TABLES_ON_STACK];
    overlap_key *cat_keys;
    int nkeys;
    table_entry *e;
    table_entry *last_e;
    overlap_key *left;
    overlap_key *right;
    overlap_key *last;

    nkeys = a->a.nelts + b->a.nelts;
    if (nkeys < AP_OVERLAP_TABLES_ON_STACK) {
	cat_keys = cat_keys_buf;
    }
    else {
	/* XXX: could use scratch free space in a or b's pool instead...
	 * which could save an allocation in b's pool.
d1809 5
a1813 2
	cat_keys = ap_palloc(b->a.pool, sizeof(overlap_key) * nkeys);
    }
d1815 10
a1824 1
    nkeys = 0;
d1826 55
a1880 97
    /* Create a list of the entries from a concatenated with the entries
     * from b.
     */
    e = (table_entry *)a->a.elts;
    last_e = e + a->a.nelts;
    while (e < last_e) {
	cat_keys[nkeys].key = e->key;
	cat_keys[nkeys].val = e->val;
	cat_keys[nkeys].order = nkeys;
	++nkeys;
	++e;
    }

    e = (table_entry *)b->a.elts;
    last_e = e + b->a.nelts;
    while (e < last_e) {
	cat_keys[nkeys].key = e->key;
	cat_keys[nkeys].val = e->val;
	cat_keys[nkeys].order = nkeys;
	++nkeys;
	++e;
    }

    qsort(cat_keys, nkeys, sizeof(overlap_key), sort_overlap);

    /* Now iterate over the sorted list and rebuild a.
     * Start by making sure it has enough space.
     */
    a->a.nelts = 0;
    if (a->a.nalloc < nkeys) {
	a->a.elts = ap_palloc(a->a.pool, a->a.elt_size * nkeys * 2);
	a->a.nalloc = nkeys * 2;
    }

    /*
     * In both the merge and set cases we retain the invariant:
     *
     * left->key, (left+1)->key, (left+2)->key, ..., (right-1)->key
     * are all equal keys.  (i.e. strcasecmp returns 0)
     *
     * We essentially need to find the maximal
     * right for each key, then we can do a quick merge or set as
     * appropriate.
     */

    if (flags & AP_OVERLAP_TABLES_MERGE) {
	left = cat_keys;
	last = left + nkeys;
	while (left < last) {
	    right = left + 1;
	    if (right == last
		|| strcasecmp(left->key, right->key)) {
		ap_table_addn(a, left->key, left->val);
		left = right;
	    }
	    else {
		char *strp;
		char *value;
		size_t len;

		/* Have to merge some headers.  Let's re-use the order field,
		 * since it's handy... we'll store the length of val there.
		 */
		left->order = strlen(left->val);
		len = left->order;
		do {
		    right->order = strlen(right->val);
		    len += 2 + right->order;
		    ++right;
		} while (right < last
			&& !strcasecmp(left->key, right->key));
		/* right points one past the last header to merge */
		value = ap_palloc(a->a.pool, len + 1);
		strp = value;
		for (;;) {
		    memcpy(strp, left->val, left->order);
		    strp += left->order;
		    ++left;
		    if (left == right) break;
		    *strp++ = ',';
		    *strp++ = ' ';
		}
		*strp = 0;
		ap_table_addn(a, (left-1)->key, value);
	    }
	}
    }
    else {
	left = cat_keys;
	last = left + nkeys;
	while (left < last) {
	    right = left + 1;
	    while (right < last && !strcasecmp(left->key, right->key)) {
		++right;
	    }
	    ap_table_addn(a, (right-1)->key, (right-1)->val);
	    left = right;
a1881 1
    }
d1890 4
a1893 4
    void *data;
    void (*plain_cleanup) (void *);
    void (*child_cleanup) (void *);
    struct cleanup *next;
d1896 3
a1898 4
API_EXPORT(void) ap_register_cleanup_ex(pool *p, void *data,
				      void (*plain_cleanup) (void *),
				      void (*child_cleanup) (void *),
				      int (*magic_cleanup) (void *))
d1900 16
a1915 16
    struct cleanup *c;
    if (p) {
	c = (struct cleanup *) ap_palloc(p, sizeof(struct cleanup));
	c->data = data;
	c->plain_cleanup = plain_cleanup;
	c->child_cleanup = child_cleanup;
	c->next = p->cleanups;
	p->cleanups = c;
    }
    /* attempt to do magic even if not passed a pool. Allows us
     * to perform the magic, therefore, "whenever" we want/need */
    if (magic_cleanup) {
	if (!magic_cleanup(data)) 
	   ap_log_error(APLOG_MARK, APLOG_WARNING, NULL,
		 "exec() may not be safe");
    }
d1918 3
a1920 3
API_EXPORT(void) ap_register_cleanup(pool *p, void *data,
				     void (*plain_cleanup) (void *),
				     void (*child_cleanup) (void *))
d1922 1
a1922 1
    ap_register_cleanup_ex(p, data, plain_cleanup, child_cleanup, NULL);
d1925 2
a1926 1
API_EXPORT(void) ap_kill_cleanup(pool *p, void *data, void (*cleanup) (void *))
d1928 8
a1935 2
    struct cleanup *c = p->cleanups;
    struct cleanup **lastp = &p->cleanups;
d1937 2
a1938 4
    while (c) {
	if (c->data == data && c->plain_cleanup == cleanup) {
	    *lastp = c->next;
	    break;
a1939 4

	lastp = &c->next;
	c = c->next;
    }
d1942 2
a1943 1
API_EXPORT(void) ap_run_cleanup(pool *p, void *data, void (*cleanup) (void *))
d1945 4
a1948 4
    ap_block_alarms();		/* Run cleanup only once! */
    (*cleanup) (data);
    ap_kill_cleanup(p, data, cleanup);
    ap_unblock_alarms();
d1951 2
a1952 1
static void run_cleanups(struct cleanup *c)
d1954 4
a1957 4
    while (c) {
	(*c->plain_cleanup) (c->data);
	c = c->next;
    }
d1960 2
a1961 1
static void run_child_cleanups(struct cleanup *c)
d1963 4
a1966 4
    while (c) {
	(*c->child_cleanup) (c->data);
	c = c->next;
    }
d1969 2
a1970 1
static void cleanup_pool_for_exec(pool *p)
d1972 2
a1973 2
    run_child_cleanups(p->cleanups);
    p->cleanups = NULL;
d1975 2
a1976 2
    for (p = p->sub_pools; p; p = p->sub_next)
	cleanup_pool_for_exec(p);
d1979 2
a1980 1
API_EXPORT(void) ap_cleanup_for_exec(void)
d1982 12
a1993 12
    /*
     * Don't need to do anything on NT, NETWARE or OS/2, because I
     * am actually going to spawn the new process - not
     * exec it. All handles that are not inheritable, will
     * be automajically closed. The only problem is with
     * file handles that are open, but there isn't much
     * I can do about that (except if the child decides
     * to go out and close them
     */
    ap_block_alarms();
    cleanup_pool_for_exec(permanent_pool);
    ap_unblock_alarms();
d1996 2
a1997 1
API_EXPORT_NONSTD(void) ap_null_cleanup(void *data)
d1999 1
a1999 1
    /* do nothing cleanup routine */
d2008 2
a2009 1
int ap_close_fd_on_exec(int fd)
d2011 6
a2016 6
    /* Protect the fd so that it will not be inherited by child processes */
    if(fcntl(fd, F_SETFD, FD_CLOEXEC) < 0) {
	ap_log_error(APLOG_MARK, APLOG_ERR, NULL,
		     "fcntl(%d, F_SETFD, FD_CLOEXEC) failed", fd);
	return 0;
    }
d2018 1
a2018 1
    return 1;
d2021 2
a2022 1
static void fd_cleanup(void *fdv)
d2024 1
a2024 1
    close((int) (long) fdv);
d2027 2
a2028 1
static int fd_magic_cleanup(void *fdv)
d2030 1
a2030 1
    return ap_close_fd_on_exec((int) (long) fdv);
d2033 2
a2034 1
API_EXPORT(void) ap_note_cleanups_for_fd_ex(pool *p, int fd, int domagic)
d2036 2
a2037 2
    ap_register_cleanup_ex(p, (void *) (long) fd, fd_cleanup, fd_cleanup,
                           domagic ? fd_magic_cleanup : NULL);
d2040 2
a2041 1
API_EXPORT(void) ap_note_cleanups_for_fd(pool *p, int fd)
d2043 1
a2043 1
    ap_note_cleanups_for_fd_ex(p, fd, 0);
d2046 2
a2047 1
API_EXPORT(void) ap_kill_cleanups_for_fd(pool *p, int fd)
d2049 1
a2049 1
    ap_kill_cleanup(p, (void *) (long) fd, fd_cleanup);
d2052 2
a2053 2
API_EXPORT(int) ap_popenf_ex(pool *a, const char *name, int flg, int mode,
                             int domagic)
d2055 2
a2056 2
    int fd;
    int save_errno;
d2058 10
a2067 10
    ap_block_alarms();
    fd = open(name, flg, mode);
    save_errno = errno;
    if (fd >= 0) {
	fd = ap_slack(fd, AP_SLACK_HIGH);
	ap_note_cleanups_for_fd_ex(a, fd, domagic);
    }
    ap_unblock_alarms();
    errno = save_errno;
    return fd;
d2070 2
a2071 1
API_EXPORT(int) ap_popenf(pool *a, const char *name, int flg, int mode)
d2073 1
a2073 1
    return ap_popenf_ex(a, name, flg, mode, 0);
d2076 2
a2077 1
API_EXPORT(int) ap_pclosef(pool *a, int fd)
d2079 2
a2080 2
    int res;
    int save_errno;
d2082 7
a2088 7
    ap_block_alarms();
    res = close(fd);
    save_errno = errno;
    ap_kill_cleanup(a, (void *) (long) fd, fd_cleanup);
    ap_unblock_alarms();
    errno = save_errno;
    return res;
d2097 2
a2098 1
static void file_cleanup(void *fpv)
d2100 1
a2100 1
    fclose((FILE *) fpv);
d2103 2
a2104 1
static void file_child_cleanup(void *fpv)
d2106 1
a2106 1
    close(fileno((FILE *) fpv));
d2109 2
a2110 1
static int file_magic_cleanup(void *fpv)
d2112 1
a2112 1
    return ap_close_fd_on_exec(fileno((FILE *) fpv));
d2115 2
a2116 1
API_EXPORT(void) ap_note_cleanups_for_file_ex(pool *p, FILE *fp, int domagic)
d2118 2
a2119 2
    ap_register_cleanup_ex(p, (void *) fp, file_cleanup, file_child_cleanup,
                           domagic ? file_magic_cleanup : NULL);
d2122 2
a2123 1
API_EXPORT(void) ap_note_cleanups_for_file(pool *p, FILE *fp)
d2125 1
a2125 1
    ap_note_cleanups_for_file_ex(p, fp, 0);
d2128 2
a2129 1
API_EXPORT(FILE *) ap_pfopen(pool *a, const char *name, const char *mode)
d2131 4
a2134 4
    FILE *fd = NULL;
    int baseFlag, desc;
    int modeFlags = 0;
    int saved_errno;
d2136 1
a2136 1
    modeFlags = S_IRUSR | S_IWUSR | S_IRGRP | S_IWGRP | S_IROTH | S_IWOTH;
d2138 1
a2138 1
    ap_block_alarms();
d2140 11
a2150 8
    if (*mode == 'a') {
	/* Work around faulty implementations of fopen */
	baseFlag = (*(mode + 1) == '+') ? O_RDWR : O_WRONLY;
	desc = open(name, baseFlag | O_APPEND | O_CREAT,
		    modeFlags);
	if (desc >= 0) {
	    desc = ap_slack(desc, AP_SLACK_LOW);
	    fd = ap_fdopen(desc, mode);
d2152 6
a2157 10
    }
    else {
	fd = fopen(name, mode);
    }
    saved_errno = errno;
    if (fd != NULL)
	ap_note_cleanups_for_file(a, fd);
    ap_unblock_alarms();
    errno = saved_errno;
    return fd;
d2160 2
a2161 1
API_EXPORT(FILE *) ap_pfdopen(pool *a, int fd, const char *mode)
d2163 2
a2164 2
    FILE *f;
    int saved_errno;
d2166 8
a2173 8
    ap_block_alarms();
    f = ap_fdopen(fd, mode);
    saved_errno = errno;
    if (f != NULL)
	ap_note_cleanups_for_file(a, f);
    ap_unblock_alarms();
    errno = saved_errno;
    return f;
d2177 2
a2178 1
API_EXPORT(int) ap_pfclose(pool *a, FILE *fd)
d2180 1
a2180 1
    int res;
d2182 5
a2186 5
    ap_block_alarms();
    res = fclose(fd);
    ap_kill_cleanup(a, (void *) fd, file_cleanup);
    ap_unblock_alarms();
    return res;
d2193 2
a2194 1
static void dir_cleanup(void *dv)
d2196 1
a2196 1
    closedir((DIR *) dv);
d2199 2
a2200 1
API_EXPORT(DIR *) ap_popendir(pool *p, const char *name)
d2202 2
a2203 2
    DIR *d;
    int save_errno;
d2205 9
a2213 4
    ap_block_alarms();
    d = opendir(name);
    if (d == NULL) {
	save_errno = errno;
d2215 1
a2215 6
	errno = save_errno;
	return NULL;
    }
    ap_register_cleanup(p, (void *) d, dir_cleanup, dir_cleanup);
    ap_unblock_alarms();
    return d;
d2218 7
a2224 6
API_EXPORT(void) ap_pclosedir(pool *p, DIR * d)
{
    ap_block_alarms();
    ap_kill_cleanup(p, (void *) d, dir_cleanup);
    closedir(d);
    ap_unblock_alarms();
d2233 2
a2234 1
static void socket_cleanup(void *fdv)
d2236 1
a2236 1
    closesocket((int) (long) fdv);
d2239 2
a2240 1
static int socket_magic_cleanup(void *fpv)
d2242 1
a2242 1
    return ap_close_fd_on_exec((int) (long) fpv);
d2245 2
a2246 1
API_EXPORT(void) ap_note_cleanups_for_socket_ex(pool *p, int fd, int domagic)
d2248 2
a2249 3
    ap_register_cleanup_ex(p, (void *) (long) fd, socket_cleanup,
                           socket_cleanup,
                           domagic ? socket_magic_cleanup : NULL);
d2252 2
a2253 1
API_EXPORT(void) ap_note_cleanups_for_socket(pool *p, int fd)
d2255 1
a2255 1
    ap_note_cleanups_for_socket_ex(p, fd, 0);
d2258 2
a2259 1
API_EXPORT(void) ap_kill_cleanups_for_socket(pool *p, int sock)
d2261 1
a2261 1
    ap_kill_cleanup(p, (void *) (long) sock, socket_cleanup);
d2264 2
a2265 2
API_EXPORT(int) ap_psocket_ex(pool *p, int domain, int type, int protocol,
                              int domagic)
d2267 1
a2267 1
    int fd;
d2269 9
a2277 4
    ap_block_alarms();
    fd = socket(domain, type, protocol);
    if (fd == -1) {
	int save_errno = errno;
d2279 1
a2279 6
	errno = save_errno;
	return -1;
    }
    ap_note_cleanups_for_socket_ex(p, fd, domagic);
    ap_unblock_alarms();
    return fd;
d2282 2
a2283 1
API_EXPORT(int) ap_psocket(pool *p, int domain, int type, int protocol)
d2285 1
a2285 1
    return ap_psocket_ex(p, domain, type, protocol, 0);
d2288 2
a2289 1
API_EXPORT(int) ap_pclosesocket(pool *a, int sock)
d2291 2
a2292 2
    int res;
    int save_errno;
d2294 7
a2300 7
    ap_block_alarms();
    res = closesocket(sock);
    save_errno = errno;
    ap_kill_cleanup(a, (void *) (long) sock, socket_cleanup);
    ap_unblock_alarms();
    errno = save_errno;
    return res;
d2312 2
a2313 1
static void regex_cleanup(void *preg)
d2315 1
a2315 1
    regfree((regex_t *) preg);
d2318 2
a2319 1
API_EXPORT(regex_t *) ap_pregcomp(pool *p, const char *pattern, int cflags)
d2321 1
a2321 1
    regex_t *preg = ap_palloc(p, sizeof(regex_t));
d2323 2
a2324 2
    if (regcomp(preg, pattern, cflags))
	return NULL;
d2326 1
a2326 1
    ap_register_cleanup(p, (void *) preg, regex_cleanup, regex_cleanup);
d2328 1
a2328 1
    return preg;
d2332 2
a2333 1
API_EXPORT(void) ap_pregfree(pool *p, regex_t * reg)
d2335 4
a2338 4
    ap_block_alarms();
    regfree(reg);
    ap_kill_cleanup(p, (void *) reg, regex_cleanup);
    ap_unblock_alarms();
d2353 3
a2355 3
    pid_t pid;
    enum kill_conditions kill_how;
    struct process_chain *next;
d2358 10
a2367 9
API_EXPORT(void) ap_note_subprocess(pool *a, pid_t pid, enum kill_conditions 
how) {
    struct process_chain *new =
    (struct process_chain *) ap_palloc(a, sizeof(struct process_chain));

    new->pid = pid;
    new->kill_how = how;
    new->next = a->subprocesses;
    a->subprocesses = new;
d2375 22
a2396 9
static pid_t spawn_child_core(pool *p, int (*func) (void *, child_info *),
			    void *data,enum kill_conditions kill_how,
			    int *pipe_in, int *pipe_out, int *pipe_err)
{
    pid_t pid;
    int in_fds[2];
    int out_fds[2];
    int err_fds[2];
    int save_errno;
d2398 13
a2410 3
    if (pipe_in && os_pipe(in_fds) < 0) {
	return 0;
    }
d2412 16
a2427 5
    if (pipe_out && os_pipe(out_fds) < 0) {
	save_errno = errno;
	if (pipe_in) {
	    close(in_fds[0]);
	    close(in_fds[1]);
a2428 3
	errno = save_errno;
	return 0;
    }
d2430 21
a2450 13
    if (pipe_err && os_pipe(err_fds) < 0) {
	save_errno = errno;
	if (pipe_in) {
	    close(in_fds[0]);
	    close(in_fds[1]);
	}
	if (pipe_out) {
	    close(out_fds[0]);
	    close(out_fds[1]);
	}
	errno = save_errno;
	return 0;
    }
d2452 8
a2459 13
    if ((pid = fork()) < 0) {
	save_errno = errno;
	if (pipe_in) {
	    close(in_fds[0]);
	    close(in_fds[1]);
	}
	if (pipe_out) {
	    close(out_fds[0]);
	    close(out_fds[1]);
	}
	if (pipe_err) {
	    close(err_fds[0]);
	    close(err_fds[1]);
a2460 3
	errno = save_errno;
	return 0;
    }
d2462 2
a2463 3
    if (!pid) {
	/* Child process */
	RAISE_SIGSTOP(SPAWN_CHILD);
d2466 2
a2467 3
	    close(out_fds[0]);
	    dup2(out_fds[1], STDOUT_FILENO);
	    close(out_fds[1]);
d2471 2
a2472 3
	    close(in_fds[1]);
	    dup2(in_fds[0], STDIN_FILENO);
	    close(in_fds[0]);
d2476 2
a2477 3
	    close(err_fds[0]);
	    dup2(err_fds[1], STDERR_FILENO);
	    close(err_fds[1]);
d2480 1
a2480 27
	/* HP-UX SIGCHLD fix goes here, if someone will remind me what it is... */
	signal(SIGCHLD, SIG_DFL);	/* Was that it? */

	func(data, NULL);
	exit(1);		/* Should only get here if the exec in func() failed */
    }

    /* Parent process */

    ap_note_subprocess(p, pid, kill_how);

    if (pipe_out) {
	close(out_fds[1]);
	*pipe_out = out_fds[0];
    }

    if (pipe_in) {
	close(in_fds[0]);
	*pipe_in = in_fds[1];
    }

    if (pipe_err) {
	close(err_fds[1]);
	*pipe_err = err_fds[0];
    }

    return pid;
d2484 4
a2487 4
API_EXPORT(int) ap_spawn_child(pool *p, int (*func) (void *, child_info *),
			       void *data, enum kill_conditions kill_how,
			       FILE **pipe_in, FILE **pipe_out,
			       FILE **pipe_err)
d2489 3
a2491 3
    int fd_in, fd_out, fd_err;
    pid_t pid;
    int save_errno;
d2493 1
a2493 1
    ap_block_alarms();
d2495 4
a2498 4
    pid = spawn_child_core(p, func, data, kill_how,
			   pipe_in ? &fd_in : NULL,
			   pipe_out ? &fd_out : NULL,
			   pipe_err ? &fd_err : NULL);
d2500 6
a2505 6
    if (pid == 0) {
	save_errno = errno;
	ap_unblock_alarms();
	errno = save_errno;
	return 0;
    }
d2507 7
a2513 7
    if (pipe_out) {
	*pipe_out = ap_fdopen(fd_out, "r" BINMODE);
	if (*pipe_out)
	    ap_note_cleanups_for_file(p, *pipe_out);
	else
	    close(fd_out);
    }
d2515 7
a2521 7
    if (pipe_in) {
	*pipe_in = ap_fdopen(fd_in, "w" BINMODE);
	if (*pipe_in)
	    ap_note_cleanups_for_file(p, *pipe_in);
	else
	    close(fd_in);
    }
d2523 7
a2529 7
    if (pipe_err) {
	*pipe_err = ap_fdopen(fd_err, "r" BINMODE);
	if (*pipe_err)
	    ap_note_cleanups_for_file(p, *pipe_err);
	else
	    close(fd_err);
    }
d2531 2
a2532 2
    ap_unblock_alarms();
    return pid;
d2535 28
a2562 7
API_EXPORT(int) ap_bspawn_child(pool *p, int (*func) (void *, child_info *), void *data,
				enum kill_conditions kill_how,
				BUFF **pipe_in, BUFF **pipe_out, BUFF **pipe_err)
{
    int fd_in, fd_out, fd_err;
    pid_t pid;
    int save_errno;
d2564 5
a2568 1
    ap_block_alarms();
d2570 5
a2574 4
    pid = spawn_child_core(p, func, data, kill_how,
			   pipe_in ? &fd_in : NULL,
			   pipe_out ? &fd_out : NULL,
			   pipe_err ? &fd_err : NULL);
a2575 2
    if (pid == 0) {
	save_errno = errno;
d2577 1
a2577 24
	errno = save_errno;
	return 0;
    }

    if (pipe_out) {
	*pipe_out = ap_bcreate(p, B_RD);
	ap_note_cleanups_for_fd_ex(p, fd_out, 0);
	ap_bpushfd(*pipe_out, fd_out, fd_out);
    }

    if (pipe_in) {
	*pipe_in = ap_bcreate(p, B_WR);
	ap_note_cleanups_for_fd_ex(p, fd_in, 0);
	ap_bpushfd(*pipe_in, fd_in, fd_in);
    }

    if (pipe_err) {
	*pipe_err = ap_bcreate(p, B_RD);
	ap_note_cleanups_for_fd_ex(p, fd_err, 0);
	ap_bpushfd(*pipe_err, fd_err, fd_err);
    }

    ap_unblock_alarms();
    return pid;
d2591 2
a2592 1
static void free_proc_chain(struct process_chain *procs)
d2594 85
a2678 87
    /* Dispose of the subprocesses we've spawned off in the course of
     * whatever it was we're cleaning up now.  This may involve killing
     * some of them off...
     */
    struct process_chain *p;
    int need_timeout = 0;
    int status;
    int timeout_interval;
    struct timeval tv;

    if (procs == NULL)
	return;			/* No work.  Whew! */

    /* First, check to see if we need to do the SIGTERM, sleep, SIGKILL
     * dance with any of the processes we're cleaning up.  If we've got
     * any kill-on-sight subprocesses, ditch them now as well, so they
     * don't waste any more cycles doing whatever it is that they shouldn't
     * be doing anymore.
     */
    /* Pick up all defunct processes */
    for (p = procs; p; p = p->next) {
	if (waitpid(p->pid, (int *) 0, WNOHANG) > 0) {
	    p->kill_how = kill_never;
	}
    }

    for (p = procs; p; p = p->next) {
	if ((p->kill_how == kill_after_timeout)
	    || (p->kill_how == kill_only_once)) {
	    /*
	     * This is totally bogus, but seems to be the
	     * only portable (as in reliable) way to accomplish
	     * this. Note that this implies an unavoidable
	     * delay.
	     */
	    ap_os_kill(p->pid, SIGTERM);
	    need_timeout = 1;
	}
	else if (p->kill_how == kill_always) {
	    kill(p->pid, SIGKILL);
	}
    }

    /* Sleep only if we have to. The sleep algorithm grows
     * by a factor of two on each iteration. TIMEOUT_INTERVAL
     * is equal to TIMEOUT_USECS / 64.
     */
    if (need_timeout) {
        timeout_interval = TIMEOUT_INTERVAL;
        tv.tv_sec = 0;
        tv.tv_usec = timeout_interval;
        ap_select(0, NULL, NULL, NULL, &tv);

        do {
            need_timeout = 0;
            for (p = procs; p; p = p->next) {
                if (p->kill_how == kill_after_timeout) {
                    if (waitpid(p->pid, (int *) 0, WNOHANG | WUNTRACED) > 0)
                        p->kill_how = kill_never;
                    else
                        need_timeout = 1;
                }
            }
            if (need_timeout) {
                if (timeout_interval >= TIMEOUT_USECS) {
                    break;
                }
                tv.tv_sec = timeout_interval / 1000000;
                tv.tv_usec = timeout_interval % 1000000;
                ap_select(0, NULL, NULL, NULL, &tv);
                timeout_interval *= 2;
            }
        } while (need_timeout);
    }

    /* OK, the scripts we just timed out for have had a chance to clean up
     * --- now, just get rid of them, and also clean up the system accounting
     * goop...
     */

    for (p = procs; p; p = p->next) {
	if (p->kill_how == kill_after_timeout)
	    kill(p->pid, SIGKILL);

	if (p->kill_how != kill_never)
	    waitpid(p->pid, &status, 0);
    }
@


1.15
log
@cleanup and unifdef'ing, no change in object files
work by Daniel Ouellet <daniel@@presscom.net>
@
text
@a116 5
/* Provide some statistics on the cost of allocations.  It requires a
 * bit of an understanding of how alloc.c works.
 */
/* #define ALLOC_STATS */

a180 7
#ifdef ALLOC_STATS
static unsigned long long num_free_blocks_calls;
static unsigned long long num_blocks_freed;
static unsigned max_blocks_in_one_free;
static unsigned num_malloc_calls;
static unsigned num_malloc_bytes;
#endif
a222 4
#ifdef ALLOC_STATS
    ++num_malloc_calls;
    num_malloc_bytes += size + sizeof(union block_hdr);
#endif
a285 3
#ifdef ALLOC_STATS
    unsigned num_blocks;
#endif
a309 3
#ifdef ALLOC_STATS
    num_blocks = 1;
#endif
a310 3
#ifdef ALLOC_STATS
	++num_blocks;
#endif
a330 8
#ifdef ALLOC_STATS
    if (num_blocks > max_blocks_in_one_free) {
	max_blocks_in_one_free = num_blocks;
    }
    ++num_free_blocks_calls;
    num_blocks_freed += num_blocks;
#endif

a538 14
#ifdef ALLOC_STATS
static void dump_stats(void)
{
    fprintf(stderr,
	"alloc_stats: [%d] #free_blocks %llu #blocks %llu max %u #malloc %u #bytes %u\n",
	(int)getpid(),
	num_free_blocks_calls,
	num_blocks_freed,
	max_blocks_in_one_free,
	num_malloc_calls,
	num_malloc_bytes);
}
#endif

a549 4
#ifdef ALLOC_STATS
    atexit(dump_stats);
#endif

@


1.14
log
@big time httpd cleanup
this diff removes a lot of #ifdef'd stuff that is irrelevant for us.
done by Daniel Ouellet after my advice.
tested by many, ok miod@@
@
text
@a66 1
#ifdef EAPI
a68 1
#endif
a125 3
#ifdef MULTITHREAD
# error "sorry, no support for MULTITHREAD and POOL_DEBUG at the same time"
#endif
d135 1
a135 1
#if defined(EAPI) && defined(EAPI_MM)
d167 1
a167 1
#if defined(EAPI) && defined(EAPI_MM)
d220 1
a220 1
#if defined(EAPI) && defined(EAPI_MM)
d240 1
a240 1
#if defined(EAPI) && defined(EAPI_MM)
d252 1
a252 1
#if defined(EAPI) && defined(EAPI_MM)
d315 1
a315 1
#if defined(EAPI) && defined(EAPI_MM)
d365 1
a365 1
#if defined(EAPI) && defined(EAPI_MM)
d377 1
a377 1
#if defined(EAPI) && defined(EAPI_MM)
d391 1
a391 1
#if defined(EAPI) && defined(EAPI_MM)
d412 1
a412 1
#if defined(EAPI) && defined(EAPI_MM)
d466 1
a466 1
#if defined(EAPI) && defined(EAPI_MM)
d483 1
a483 1
#if defined(EAPI) && defined(EAPI_MM)
d494 1
a494 1
#if defined(EAPI) && defined(EAPI_MM)
d500 1
a500 1
#if defined(EAPI) && defined(EAPI_MM)
d523 1
a523 1
#if defined(EAPI) && defined(EAPI_MM)
d528 1
a528 1
#if defined(EAPI) && defined(EAPI_MM)
a536 1
#if defined(EAPI)
a551 1
#endif
a566 1
#if defined(EAPI)
a570 1
#endif
a603 1
#if defined(EAPI)
a648 1
#endif /* EAPI */
d660 1
a660 1
#if defined(EAPI) && defined(EAPI_MM)
d668 1
a668 1
#if defined(EAPI) && defined(EAPI_MM)
d705 1
a705 1
#if defined(EAPI) && defined(EAPI_MM)
d719 1
a719 1
#if defined(EAPI) && defined(EAPI_MM)
a736 1
#if defined(EAPI)
a757 1
#endif /* EAPI */
d924 1
a924 1
#if defined(EAPI) && defined(EAPI_MM)
d930 1
a930 1
#if defined(EAPI) && defined(EAPI_MM)
d940 1
a940 1
#if defined(EAPI) && defined(EAPI_MM)
d945 1
a945 1
#if defined(EAPI) && defined(EAPI_MM)
d1065 1
a1065 1
#if defined(EAPI) && defined(EAPI_MM)
d1093 1
a1093 1
#if defined(EAPI) && defined(EAPI_MM)
d1098 1
a1098 1
#if defined(EAPI) && defined(EAPI_MM)
d1104 1
a1104 1
#if defined(EAPI) && defined(EAPI_MM)
d1116 1
a1116 1
#if defined(EAPI) && defined(EAPI_MM)
d1124 1
a1124 1
#if defined(EAPI) && defined(EAPI_MM)
d1146 1
a1146 1
#if defined(EAPI) && defined(EAPI_MM)
d1163 1
a1163 1
#if defined(EAPI) && defined(EAPI_MM)
a2007 1
#if defined(F_SETFD) && defined(FD_CLOEXEC)
a2015 3
#else
    return 0;
#endif
a2579 1
#ifndef NEED_WAITPID
a2585 1
#endif
@


1.13
log
@merge apache 1.3.29 and mod_ssl 2.8.16
ok brad@@
@
text
@a75 5
#ifdef OS2
#define INCL_DOS
#include <os2.h>
#endif

a642 3
#ifdef WIN32
        ap_mm_permission(mm, (_S_IREAD|_S_IWRITE), ap_user_id, -1);
#else
a643 1
#endif
a1993 1
#if !defined(WIN32) && !defined(OS2) && !defined(NETWARE)
a2005 1
#endif /* ndef WIN32 */
a2018 38
#if defined(WIN32)
/* Provided by service.c, internal to the core library (not exported) */
BOOL isWindowsNT(void);

int ap_close_handle_on_exec(HANDLE nth)
{
    /* Protect the fd so that it will not be inherited by child processes */
    if (isWindowsNT()) {
        DWORD hinfo;
        if (!GetHandleInformation(nth, &hinfo)) {
	    ap_log_error(APLOG_MARK, APLOG_ERR, NULL, "GetHandleInformation"
                         "(%08x) failed", nth);
	    return 0;
        }
        if ((hinfo & HANDLE_FLAG_INHERIT)
                && !SetHandleInformation(nth, HANDLE_FLAG_INHERIT, 0)) {
	    ap_log_error(APLOG_MARK, APLOG_ERR, NULL, "SetHandleInformation"
                         "(%08x, HANDLE_FLAG_INHERIT, 0) failed", nth);
	    return 0;
        }
        return 1;
    }
    else /* Win9x */ {
        /* XXX: This API doesn't work... you can't change the handle by just
         * 'touching' it... you must duplicat to a second handle and close
         * the original.
         */
        return 0;
    }
}

int ap_close_fd_on_exec(int fd)
{
    return ap_close_handle_on_exec((HANDLE)_get_osfhandle(fd));
}

#else

a2034 2
#endif /* ndef(WIN32) */

a2046 3
#if defined(NETWARE)
    domagic = 0; /* skip magic for NetWare, at least for now */
#endif
a2097 42
#ifdef WIN32
static void h_cleanup(void *nth)
{
    CloseHandle((HANDLE) nth);
}

static int h_magic_cleanup(void *nth)
{
    /* Set handle not-inherited
     */
    return ap_close_handle_on_exec((HANDLE) nth);
}

API_EXPORT(void) ap_note_cleanups_for_h_ex(pool *p, HANDLE nth, int domagic)
{
    ap_register_cleanup_ex(p, (void *) nth, h_cleanup, h_cleanup,
                           domagic ? h_magic_cleanup : NULL);
}

API_EXPORT(void) ap_note_cleanups_for_h(pool *p, HANDLE nth)
{
    ap_note_cleanups_for_h_ex(p, nth, 0);
}

API_EXPORT(int) ap_pcloseh(pool *a, HANDLE hDevice)
{
    int res=0;
    int save_errno;

    ap_block_alarms();
    
    if (!CloseHandle(hDevice)) {
        res = GetLastError();
    }
    
    save_errno = errno;
    ap_kill_cleanup(a, (void *) hDevice, h_cleanup);
    ap_unblock_alarms();
    errno = save_errno;
    return res;
}
#endif
a2120 3
#if defined(NETWARE)
    domagic = 0; /* skip magic for NetWare, at least for now */
#endif
a2136 3
#ifdef WIN32
    modeFlags = _S_IREAD | _S_IWRITE;
#else
a2137 1
#endif
a2236 3
#ifdef WIN32
    return ap_close_handle_on_exec((HANDLE) fpv);
#else
a2237 1
#endif
a2241 3
#if defined(TPF) || defined(NETWARE)
    domagic = 0; /* skip magic (fcntl) for TPF sockets, at least for now */
#endif
a2286 3
#if defined(WIN32) || defined(NETWARE)
    errno = WSAGetLastError();
#endif /* WIN32 */
a2356 3
#ifdef WIN32
#define os_pipe(fds) _pipe(fds, 512, O_BINARY | O_NOINHERIT)
#else
a2357 1
#endif /* WIN32 */
a2359 3
#if defined (OS2) || defined (WIN32) || defined (NETWARE)
#define BINMODE	"b"
#else
a2360 1
#endif
a2399 141
#ifdef WIN32

    {
	HANDLE thread_handle;
	int hStdIn, hStdOut, hStdErr;
	int old_priority;
	child_info info;

	(void) ap_acquire_mutex(spawn_mutex);
	thread_handle = GetCurrentThread();	/* doesn't need to be closed */
	old_priority = GetThreadPriority(thread_handle);
	SetThreadPriority(thread_handle, THREAD_PRIORITY_HIGHEST);
	/* Now do the right thing with your pipes */
	if (pipe_in) {
	    hStdIn = dup(fileno(stdin));
	    if(dup2(in_fds[0], fileno(stdin)))
		ap_log_error(APLOG_MARK, APLOG_ERR, NULL, "dup2(stdin) failed");
	    close(in_fds[0]);
	}
	if (pipe_out) {
	    hStdOut = dup(fileno(stdout));
	    close(fileno(stdout));
	    if(dup2(out_fds[1], fileno(stdout)))
		ap_log_error(APLOG_MARK, APLOG_ERR, NULL, "dup2(stdout) failed");
	    close(out_fds[1]);
	}
	if (pipe_err) {
	    hStdErr = dup(fileno(stderr));
	    if(dup2(err_fds[1], fileno(stderr)))
		ap_log_error(APLOG_MARK, APLOG_ERR, NULL, "dup2(stderr) failed");
	    close(err_fds[1]);
	}

	info.hPipeInputRead   = GetStdHandle(STD_INPUT_HANDLE);
	info.hPipeOutputWrite = GetStdHandle(STD_OUTPUT_HANDLE);
	info.hPipeErrorWrite  = GetStdHandle(STD_ERROR_HANDLE);

	pid = (*func) (data, &info);
        if (pid == -1) pid = 0;   /* map Win32 error code onto Unix default */

        if (!pid) {
	    save_errno = errno;
	    close(in_fds[1]);
	    close(out_fds[0]);
	    close(err_fds[0]);
	}

	/* restore the original stdin, stdout and stderr */
	if (pipe_in) {
	    dup2(hStdIn, fileno(stdin));
	    close(hStdIn);
        }
	if (pipe_out) {
	    dup2(hStdOut, fileno(stdout));
	    close(hStdOut);
	}
	if (pipe_err) {
	    dup2(hStdErr, fileno(stderr));
	    close(hStdErr);
	}

        if (pid) {
	    ap_note_subprocess(p, pid, kill_how);
	    if (pipe_in) {
		*pipe_in = in_fds[1];
	    }
	    if (pipe_out) {
		*pipe_out = out_fds[0];
	    }
	    if (pipe_err) {
		*pipe_err = err_fds[0];
	    }
	}
	SetThreadPriority(thread_handle, old_priority);
	(void) ap_release_mutex(spawn_mutex);
	/*
	 * go on to the end of the function, where you can
	 * unblock alarms and return the pid
	 */

    }
#elif defined(NETWARE)
     /* NetWare currently has no pipes yet. This will
        be solved with the new libc for NetWare soon. */
     pid = 0;
#elif defined(OS2)
    {
        int save_in=-1, save_out=-1, save_err=-1;
        
        if (pipe_out) {
            save_out = dup(STDOUT_FILENO);
            dup2(out_fds[1], STDOUT_FILENO);
            close(out_fds[1]);
            DosSetFHState(out_fds[0], OPEN_FLAGS_NOINHERIT);
        }

        if (pipe_in) {
            save_in = dup(STDIN_FILENO);
            dup2(in_fds[0], STDIN_FILENO);
            close(in_fds[0]);
            DosSetFHState(in_fds[1], OPEN_FLAGS_NOINHERIT);
        }

        if (pipe_err) {
            save_err = dup(STDERR_FILENO);
            dup2(err_fds[1], STDERR_FILENO);
            close(err_fds[1]);
            DosSetFHState(err_fds[0], OPEN_FLAGS_NOINHERIT);
        }
        
        pid = func(data, NULL);
    
        if ( pid )
            ap_note_subprocess(p, pid, kill_how);

        if (pipe_out) {
            close(STDOUT_FILENO);
            dup2(save_out, STDOUT_FILENO);
            close(save_out);
            *pipe_out = out_fds[0];
        }

        if (pipe_in) {
            close(STDIN_FILENO);
            dup2(save_in, STDIN_FILENO);
            close(save_in);
            *pipe_in = in_fds[1];
        }

        if (pipe_err) {
            close(STDERR_FILENO);
            dup2(save_err, STDERR_FILENO);
            close(save_err);
            *pipe_err = err_fds[0];
        }
    }
#elif defined(TPF)
   return (pid = ap_tpf_spawn_child(p, func, data, kill_how,	
                 pipe_in, pipe_out, pipe_err, out_fds, in_fds, err_fds));		
#else

a2464 1
#endif /* WIN32 */
a2524 183
#ifdef WIN32
    SECURITY_ATTRIBUTES sa = {0};  
    HANDLE hPipeOutputRead  = NULL;
    HANDLE hPipeOutputWrite = NULL;
    HANDLE hPipeInputRead   = NULL;
    HANDLE hPipeInputWrite  = NULL;
    HANDLE hPipeErrorRead   = NULL;
    HANDLE hPipeErrorWrite  = NULL;
    HANDLE hPipeInputWriteDup = NULL;
    HANDLE hPipeOutputReadDup = NULL;
    HANDLE hPipeErrorReadDup  = NULL;
    HANDLE hCurrentProcess;
    pid_t pid = 0;
    child_info info;


    ap_block_alarms();

    /*
     *  First thing to do is to create the pipes that we will use for stdin, stdout, and
     *  stderr in the child process.
     */      
    sa.nLength = sizeof(sa);
    sa.bInheritHandle = TRUE;
    sa.lpSecurityDescriptor = NULL;


    /* Create pipes for standard input/output/error redirection. */
    if (pipe_in && !CreatePipe(&hPipeInputRead, &hPipeInputWrite, &sa, 0))
	return 0;

    if (pipe_out && !CreatePipe(&hPipeOutputRead, &hPipeOutputWrite, &sa, 0)) {
	if(pipe_in) {
	    CloseHandle(hPipeInputRead);
	    CloseHandle(hPipeInputWrite);
	}
	return 0;
    }

    if (pipe_err && !CreatePipe(&hPipeErrorRead, &hPipeErrorWrite, &sa, 0)) {
	if(pipe_in) {
	    CloseHandle(hPipeInputRead);
	    CloseHandle(hPipeInputWrite);
	}
	if(pipe_out) {
	    CloseHandle(hPipeOutputRead);
	    CloseHandle(hPipeOutputWrite);
	}
	return 0;
    }
    /*
     * When the pipe handles are created, the security descriptor
     * indicates that the handle can be inherited.  However, we do not
     * want the server side handles to the pipe to be inherited by the
     * child CGI process. If the child CGI does inherit the server
     * side handles, then the child may be left around if the server
     * closes its handles (e.g. if the http connection is aborted),
     * because the child will have a valid copy of handles to both
     * sides of the pipes, and no I/O error will occur.  Microsoft
     * recommends using DuplicateHandle to turn off the inherit bit
     * under NT and Win95.
     */
    hCurrentProcess = GetCurrentProcess();
    if ((pipe_in && !DuplicateHandle(hCurrentProcess, hPipeInputWrite,
				     hCurrentProcess,
				     &hPipeInputWriteDup, 0, FALSE,
				     DUPLICATE_SAME_ACCESS))
	|| (pipe_out && !DuplicateHandle(hCurrentProcess, hPipeOutputRead,
					 hCurrentProcess, &hPipeOutputReadDup,
					 0, FALSE, DUPLICATE_SAME_ACCESS))
	|| (pipe_err && !DuplicateHandle(hCurrentProcess, hPipeErrorRead,
					 hCurrentProcess, &hPipeErrorReadDup,
					 0, FALSE, DUPLICATE_SAME_ACCESS))) {
	if (pipe_in) {
	    CloseHandle(hPipeInputRead);
	    CloseHandle(hPipeInputWrite);
	}
	if (pipe_out) {
	    CloseHandle(hPipeOutputRead);
	    CloseHandle(hPipeOutputWrite);
	}
	if (pipe_err) {
	    CloseHandle(hPipeErrorRead);
	    CloseHandle(hPipeErrorWrite);
	}
	return 0;
    }
    else {
	if (pipe_in) {
	    CloseHandle(hPipeInputWrite);
	    hPipeInputWrite = hPipeInputWriteDup;
	}
	if (pipe_out) {
	    CloseHandle(hPipeOutputRead);
	    hPipeOutputRead = hPipeOutputReadDup;
	}
	if (pipe_err) {
	    CloseHandle(hPipeErrorRead);
	    hPipeErrorRead = hPipeErrorReadDup;
	}
    }

    /* The script writes stdout to this pipe handle */
    info.hPipeOutputWrite = hPipeOutputWrite;  

    /* The script reads stdin from this pipe handle */
    info.hPipeInputRead = hPipeInputRead;

    /* The script writes stderr to this pipe handle */
    info.hPipeErrorWrite = hPipeErrorWrite;    
     
    /*
     *  Try to launch the CGI.  Under the covers, this call 
     *  will try to pick up the appropriate interpreter if 
     *  one is needed.
     */
    pid = func(data, &info);
    if (pid == -1) {
        /* Things didn't work, so cleanup */
        pid = 0;   /* map Win32 error code onto Unix default */
        CloseHandle(hPipeOutputRead);
        CloseHandle(hPipeInputWrite);
        CloseHandle(hPipeErrorRead);
    }
    else {
        if (pipe_out) {
            /*
             *  This pipe represents stdout for the script, 
             *  so we read from this pipe.
             */
	    /* Create a read buffer */
            *pipe_out = ap_bcreate(p, B_RD);

	    /* Setup the cleanup routine for the handle */
            ap_note_cleanups_for_h_ex(p, hPipeOutputRead, 1);   

	    /* Associate the handle with the new buffer */
            ap_bpushh(*pipe_out, hPipeOutputRead);
        }
        
        if (pipe_in) {
            /*
             *  This pipe represents stdin for the script, so we 
             *  write to this pipe.
             */
	    /* Create a write buffer */
            *pipe_in = ap_bcreate(p, B_WR);             

	    /* Setup the cleanup routine for the handle */
            ap_note_cleanups_for_h_ex(p, hPipeInputWrite, 1);

	    /* Associate the handle with the new buffer */
            ap_bpushh(*pipe_in, hPipeInputWrite);

        }
      
        if (pipe_err) {
            /*
             *  This pipe represents stderr for the script, so 
             *  we read from this pipe.
             */
	    /* Create a read buffer */
            *pipe_err = ap_bcreate(p, B_RD);

	    /* Setup the cleanup routine for the handle */
            ap_note_cleanups_for_h_ex(p, hPipeErrorRead, 1);

	    /* Associate the handle with the new buffer */
            ap_bpushh(*pipe_err, hPipeErrorRead);
        }
    }  


    /*
     * Now that handles have been inherited, close them to be safe.
     * You don't want to read or write to them accidentally, and we
     * sure don't want to have a handle leak.
     */
    CloseHandle(hPipeOutputWrite);
    CloseHandle(hPipeInputRead);
    CloseHandle(hPipeErrorWrite);

#else
a2559 1
#endif
a2584 1
#if !defined(WIN32) && !defined(NETWARE)
a2586 1
#endif
a2596 37
#ifdef WIN32
    /* Pick up all defunct processes */
    for (p = procs; p; p = p->next) {
	if (GetExitCodeProcess((HANDLE) p->pid, &status)) {
	    p->kill_how = kill_never;
	}
    }


    for (p = procs; p; p = p->next) {
	if (p->kill_how == kill_after_timeout) {
	    need_timeout = 1;
	}
	else if (p->kill_how == kill_always) {
	    TerminateProcess((HANDLE) p->pid, 1);
	}
    }
    /* Sleep only if we have to... */

    if (need_timeout)
	sleep(3);

    /* OK, the scripts we just timed out for have had a chance to clean up
     * --- now, just get rid of them, and also clean up the system accounting
     * goop...
     */

    for (p = procs; p; p = p->next) {
	if (p->kill_how == kill_after_timeout)
	    TerminateProcess((HANDLE) p->pid, 1);
    }

    for (p = procs; p; p = p->next) {
	CloseHandle((HANDLE) p->pid);
    }
#elif defined(NETWARE)
#else
a2666 1
#endif /* !WIN32 && !NETWARE*/
@


1.12
log
@apache bug #21737 ( http://nagoya.apache.org/bugzilla/show_bug.cgi?id=21737)
introduced with 1.3.28:

Apparently there has been a regression in 1.3.28 from 1.3.27 whereby
CGI scripts are getting left around as zombies when suexec is in use,
apparently because of a change in src/main/alloc.c that altered the
behavior when sending SIGTERM to a child process.  With suexec, the
SIGTERM at line 2862 will fail not because the subprocess is dead already
but because the httpd uid has no permission to term the cgi process, which
is running as some other user.

fix by Ralf S. Engelschall:

That is, we don't have to check for the return value of ap_os_kill()
and especially not check for ESRCH, because we _HAVE_ to waitpid() for
it anyway (because it's our child and it either is already terminated
and is waiting as a zombie for our waitpid() or it is still running).

Under Unix it cannot be that a (non-detached in the sense of BSD's
daemon(3)) child of a process just does no longer exists as long as
the parent still exists and as long as the parent still has not done
waitpid() for the child. So ESRCH cannot happen in our situation and the
patch we currently use is fully sufficient. Both are at least portable
enough for Unix, of course...
@
text
@a2016 3
#ifdef EAPI
    ap_kill_alloc_shared();
#endif
d3095 6
a3100 1
	    /* Subprocess may be dead already.  Only need the timeout if not. */
@


1.11
log
@merge
@
text
@d3099 2
a3100 6
	    if (ap_os_kill(p->pid, SIGTERM) == -1) {
                p->kill_how = kill_never;
            }
            else {
		need_timeout = 1;
            }
@


1.10
log
@easy strcpy elimination
@
text
@d4 1
a4 1
 * Copyright (c) 2000-2002 The Apache Software Foundation.  All rights
d237 1
d249 1
d252 1
a252 1
        blok = (union block_hdr *)ap_mm_malloc(mm, size + sizeof(union block_hdr));
d255 1
a255 1
    blok = (union block_hdr *) malloc(size + sizeof(union block_hdr));
d257 2
a258 1
	fprintf(stderr, "Ouch!  malloc failed in malloc_block()\n");
d1922 4
a1925 2
API_EXPORT(void) ap_register_cleanup(pool *p, void *data, void (*plain_cleanup) (void *),
				  void (*child_cleanup) (void *))
d1927 23
a1949 6
    struct cleanup *c = (struct cleanup *) ap_palloc(p, sizeof(struct cleanup));
    c->data = data;
    c->plain_cleanup = plain_cleanup;
    c->child_cleanup = child_cleanup;
    c->next = p->cleanups;
    p->cleanups = c;
d2003 1
a2003 1
#if !defined(WIN32) && !defined(OS2)
d2005 1
a2005 1
     * Don't need to do anything on NT or OS/2, because I
d2017 3
d2033 56
d2094 14
d2110 1
a2110 1
    ap_register_cleanup(p, (void *) (long) fd, fd_cleanup, fd_cleanup);
d2118 2
a2119 1
API_EXPORT(int) ap_popenf(pool *a, const char *name, int flg, int mode)
d2129 1
a2129 1
	ap_note_cleanups_for_fd(a, fd);
d2136 5
d2156 1
a2156 1
static void h_cleanup(void *fdv)
d2158 1
a2158 1
    CloseHandle((HANDLE) fdv);
d2161 1
a2161 1
API_EXPORT(void) ap_note_cleanups_for_h(pool *p, HANDLE hDevice)
d2163 14
a2176 1
    ap_register_cleanup(p, (void *) hDevice, h_cleanup, h_cleanup);
d2207 1
d2213 14
d2229 1
a2229 1
    ap_register_cleanup(p, (void *) fp, file_cleanup, file_child_cleanup);
d2341 19
d2362 1
a2362 1
    ap_register_cleanup(p, (void *) (long) fd, socket_cleanup, socket_cleanup);
d2370 2
a2371 1
API_EXPORT(int) ap_psocket(pool *p, int domain, int type, int protocol)
d2383 1
a2383 1
    ap_note_cleanups_for_socket(p, fd);
d2388 5
d2925 1
a2925 1
            ap_note_cleanups_for_h(p, hPipeOutputRead);   
d2940 1
a2940 1
            ap_note_cleanups_for_h(p, hPipeInputWrite);
d2956 1
a2956 1
            ap_note_cleanups_for_h(p, hPipeErrorRead);
d2994 1
a2994 1
	ap_note_cleanups_for_fd(p, fd_out);
d3000 1
a3000 1
	ap_note_cleanups_for_fd(p, fd_in);
d3006 1
a3006 1
	ap_note_cleanups_for_fd(p, fd_err);
d3015 11
a3031 1

d3035 4
d3099 4
a3102 1
	    if (ap_os_kill(p->pid, SIGTERM) != -1)
d3104 1
d3111 31
a3141 4
    /* Sleep only if we have to... */

    if (need_timeout)
	sleep(3);
a3148 1

d3155 1
a3155 1
#endif /* WIN32 */
@


1.9
log
@merge apache 1.3.27 and mod_ssl 2.8.11
@
text
@d1037 1
a1037 1
	strcpy(cp, argp);
@


1.8
log
@fix half baked abortion of a merge to 1.3.23 and take
tree to apache-1.3.24+mod+ssl2.8.8
@
text
@d1071 2
d1077 1
a1077 1
    int size;
d1080 4
a1083 1
    size = (char *)ps->vbuff.curpos - ps->base;
d1086 1
a1086 1
        ptr = ap_mm_realloc(ps->base, 2*size);
d1089 1
a1089 1
    ptr = realloc(ps->base, 2*size);
d1095 2
a1096 2
    ps->vbuff.curpos = ptr + size;
    ps->vbuff.endpos = ptr + 2*size - 1;
d1101 1
a1101 1
    size_t cur_len;
d1107 3
d1118 1
a1118 1
    nblok = new_block(2 * cur_len, blok->h.is_shm);
d1120 1
a1120 1
    nblok = new_block(2 * cur_len);
d1207 2
@


1.7
log
@Apache 1.3.19+mod_ssl 2.8.1 merge - also adds shared build of mod_headers
and mod_expire
@
text
@d4 1
a4 1
 * Copyright (c) 2000 The Apache Software Foundation.  All rights
d597 1
a597 1
pool *ap_init_alloc(void)
d1717 2
a1718 2
API_EXPORT(void) ap_table_do(int (*comp) (void *, const char *, const char *), void *rec,
	      const table *t,...)
@


1.6
log
@apache 1.3.14 + mod_ssl 2.7.1 merge
@
text
@d2 4
a5 1
 * Copyright (c) 1995-1999 The Apache Group.  All rights reserved.
d12 1
a12 1
 *    notice, this list of conditions and the following disclaimer. 
d19 20
a38 23
 * 3. All advertising materials mentioning features or use of this
 *    software must display the following acknowledgment:
 *    "This product includes software developed by the Apache Group
 *    for use in the Apache HTTP server project (http://www.apache.org/)."
 *
 * 4. The names "Apache Server" and "Apache Group" must not be used to
 *    endorse or promote products derived from this software without
 *    prior written permission. For written permission, please contact
 *    apache@@apache.org.
 *
 * 5. Products derived from this software may not be called "Apache"
 *    nor may "Apache" appear in their names without prior written
 *    permission of the Apache Group.
 *
 * 6. Redistributions of any form whatsoever must retain the following
 *    acknowledgment:
 *    "This product includes software developed by the Apache Group
 *    for use in the Apache HTTP server project (http://www.apache.org/)."
 *
 * THIS SOFTWARE IS PROVIDED BY THE APACHE GROUP ``AS IS'' AND ANY
 * EXPRESSED OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE APACHE GROUP OR
d40 7
a46 7
 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
 * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
 * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,
 * STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED
 * OF THE POSSIBILITY OF SUCH DAMAGE.
d50 7
a56 6
 * individuals on behalf of the Apache Group and was originally based
 * on public domain software written at the National Center for
 * Supercomputing Applications, University of Illinois, Urbana-Champaign.
 * For more information on the Apache Group and the Apache HTTP server
 * project, please see <http://www.apache.org/>.
 *
@


1.5
log
@Apache 1.3.11 + mod_ssl 2.5.0 merge
@
text
@d666 6
d1407 1
a1407 1
 * in alloc.h */
@


1.4
log
@Apache 1.3.9 + Mod_ssl 2.4.2 - now builds with apaci nastiness.
@
text
@d627 3
a629 1
        mm_path = ap_server_root_relative(permanent_pool, EAPI_MM_CORE_PATH);
a638 1
            abort();
d2229 1
a2229 1
#ifdef WIN32
d2309 1
a2309 1
#if defined (OS2) || defined (WIN32)
d2382 1
a2382 1
		ap_log_error(APLOG_MARK, APLOG_ERR, NULL, "dup2(stdin) failed");
d2434 4
d2899 1
@


1.3
log
@Apache 1.3.4 merge
@
text
@d66 4
d75 5
d123 5
d144 4
d176 3
d195 7
d229 3
d233 1
d243 9
d258 3
d308 3
d321 4
d335 3
d339 3
d361 9
d371 4
d383 3
d387 1
d397 4
d402 1
d418 3
d422 1
d472 3
d489 3
d493 1
d500 4
d506 3
d510 1
d529 4
d534 4
d543 18
d575 21
d607 3
d614 51
d669 4
d677 4
d714 4
d728 4
d746 24
d935 4
d941 3
d945 1
d951 3
d956 4
d1071 5
d1096 4
d1101 3
d1105 1
d1107 4
d1119 4
d1127 4
d1149 5
d1166 5
d1963 1
a1963 1
#ifndef WIN32
d1965 1
a1965 1
     * Don't need to do anything on NT, because I
d2290 2
a2291 2
API_EXPORT(void) ap_note_subprocess(pool *a, int pid, enum kill_conditions how)
{
d2314 1
a2314 1
static int spawn_child_core(pool *p, int (*func) (void *, child_info *),
d2318 1
a2318 1
    int pid;
d2433 54
d2566 2
a2567 1
    int pid, save_errno;
d2627 1
a2627 1
    int pid = 0;
d2799 2
a2800 1
    int pid, save_errno;
d2908 1
a2908 1
	    if (kill(p->pid, SIGTERM) != -1)
@


1.2
log
@Apache 1.3.3 merge + proxy_segv fix
@
text
@d2 1
a2 1
 * Copyright (c) 1995-1998 The Apache Group.  All rights reserved.
d1047 54
@


1.1
log
@Initial revision
@
text
@d1747 1
d1770 1
a1770 1

d1774 1
d1781 1
d1785 1
d1789 1
d2225 4
d2266 51
@


1.1.1.1
log
@Apache 1.3.2
@
text
@@


1.1.1.2
log
@import apache 1.3.26 + mod_ssl 2.8.10
@
text
@d2 1
a2 4
 * The Apache Software License, Version 1.1
 *
 * Copyright (c) 2000-2002 The Apache Software Foundation.  All rights
 * reserved.
d9 1
a9 1
 *    notice, this list of conditions and the following disclaimer.
d16 23
a38 20
 * 3. The end-user documentation included with the redistribution,
 *    if any, must include the following acknowledgment:
 *       "This product includes software developed by the
 *        Apache Software Foundation (http://www.apache.org/)."
 *    Alternately, this acknowledgment may appear in the software itself,
 *    if and wherever such third-party acknowledgments normally appear.
 *
 * 4. The names "Apache" and "Apache Software Foundation" must
 *    not be used to endorse or promote products derived from this
 *    software without prior written permission. For written
 *    permission, please contact apache@@apache.org.
 *
 * 5. Products derived from this software may not be called "Apache",
 *    nor may "Apache" appear in their name, without prior written
 *    permission of the Apache Software Foundation.
 *
 * THIS SOFTWARE IS PROVIDED ``AS IS'' AND ANY EXPRESSED OR IMPLIED
 * WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
 * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 * DISCLAIMED.  IN NO EVENT SHALL THE APACHE SOFTWARE FOUNDATION OR
d40 7
a46 7
 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
 * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF
 * USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
 * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT
 * OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
d50 6
a55 7
 * individuals on behalf of the Apache Software Foundation.  For more
 * information on the Apache Software Foundation, please see
 * <http://www.apache.org/>.
 *
 * Portions of this software are based upon public domain software
 * originally written at the National Center for Supercomputing Applications,
 * University of Illinois, Urbana-Champaign.
a70 5
#ifdef OS2
#define INCL_DOS
#include <os2.h>
#endif

a113 5
/* Provide some statistics on the cost of allocations.  It requires a
 * bit of an understanding of how alloc.c works.
 */
/* #define ALLOC_STATS */

a173 7
#ifdef ALLOC_STATS
static unsigned long long num_free_blocks_calls;
static unsigned long long num_blocks_freed;
static unsigned max_blocks_in_one_free;
static unsigned num_malloc_calls;
static unsigned num_malloc_bytes;
#endif
a210 4
#ifdef ALLOC_STATS
    ++num_malloc_calls;
    num_malloc_bytes += size + sizeof(union block_hdr);
#endif
a263 3
#ifdef ALLOC_STATS
    unsigned num_blocks;
#endif
a283 3
#ifdef ALLOC_STATS
    num_blocks = 1;
#endif
a284 3
#ifdef ALLOC_STATS
	++num_blocks;
#endif
a303 9

#ifdef ALLOC_STATS
    if (num_blocks > max_blocks_in_one_free) {
	max_blocks_in_one_free = num_blocks;
    }
    ++num_free_blocks_calls;
    num_blocks_freed += num_blocks;
#endif

d451 1
a451 15
#ifdef ALLOC_STATS
static void dump_stats(void)
{
    fprintf(stderr,
	"alloc_stats: [%d] #free_blocks %llu #blocks %llu max %u #malloc %u #bytes %u\n",
	(int)getpid(),
	num_free_blocks_calls,
	num_blocks_freed,
	max_blocks_in_one_free,
	num_malloc_calls,
	num_malloc_bytes);
}
#endif

API_EXPORT(pool *) ap_init_alloc(void)
a461 3
#ifdef ALLOC_STATS
    atexit(dump_stats);
#endif
a465 6
void ap_cleanup_alloc(void)
{
    ap_destroy_mutex(alloc_mutex);
    ap_destroy_mutex(spawn_mutex);
}

a1049 54
/* ap_array_pstrcat generates a new string from the pool containing
 * the concatenated sequence of substrings referenced as elements within
 * the array.  The string will be empty if all substrings are empty or null,
 * or if there are no elements in the array.
 * If sep is non-NUL, it will be inserted between elements as a separator.
 */
API_EXPORT(char *) ap_array_pstrcat(pool *p, const array_header *arr,
                                    const char sep)
{
    char *cp, *res, **strpp;
    int i, len;

    if (arr->nelts <= 0 || arr->elts == NULL)      /* Empty table? */
        return (char *) ap_pcalloc(p, 1);

    /* Pass one --- find length of required string */

    len = 0;
    for (i = 0, strpp = (char **) arr->elts; ; ++strpp) {
        if (strpp && *strpp != NULL) {
            len += strlen(*strpp);
        }
        if (++i >= arr->nelts)
            break;
        if (sep)
            ++len;
    }

    /* Allocate the required string */

    res = (char *) ap_palloc(p, len + 1);
    cp = res;

    /* Pass two --- copy the argument strings into the result space */

    for (i = 0, strpp = (char **) arr->elts; ; ++strpp) {
        if (strpp && *strpp != NULL) {
            len = strlen(*strpp);
            memcpy(cp, *strpp, len);
            cp += len;
        }
        if (++i >= arr->nelts)
            break;
        if (sep)
            *cp++ = sep;
    }

    *cp = '\0';

    /* Return the result string */

    return res;
}

d1057 1
a1057 1
 * in ap_alloc.h */
d1366 2
a1367 2
API_EXPORT_NONSTD(void) ap_table_do(int (*comp) (void *, const char *, const char *), 
	                            void *rec, const table *t,...)
d1620 1
a1620 1
#if !defined(WIN32) && !defined(OS2)
d1622 1
a1622 1
     * Don't need to do anything on NT or OS/2, because I
a1746 1
    int saved_errno;
d1769 1
a1769 1
    saved_errno = errno;
a1772 1
    errno = saved_errno;
a1778 1
    int saved_errno;
a1781 1
    saved_errno = errno;
a1784 1
    errno = saved_errno;
d1880 1
a1880 1
#if defined(WIN32) || defined(NETWARE)
d1942 2
a1943 2
API_EXPORT(void) ap_note_subprocess(pool *a, pid_t pid, enum kill_conditions 
how) {
d1960 1
a1960 1
#if defined (OS2) || defined (WIN32) || defined (NETWARE)
d1966 1
a1966 1
static pid_t spawn_child_core(pool *p, int (*func) (void *, child_info *),
d1970 1
a1970 1
    pid_t pid;
d2033 1
a2033 1
		ap_log_error(APLOG_MARK, APLOG_ERR, NULL, "dup2(stderr) failed");
a2084 58
#elif defined(NETWARE)
     /* NetWare currently has no pipes yet. This will
        be solved with the new libc for NetWare soon. */
     pid = 0;
#elif defined(OS2)
    {
        int save_in=-1, save_out=-1, save_err=-1;
        
        if (pipe_out) {
            save_out = dup(STDOUT_FILENO);
            dup2(out_fds[1], STDOUT_FILENO);
            close(out_fds[1]);
            DosSetFHState(out_fds[0], OPEN_FLAGS_NOINHERIT);
        }

        if (pipe_in) {
            save_in = dup(STDIN_FILENO);
            dup2(in_fds[0], STDIN_FILENO);
            close(in_fds[0]);
            DosSetFHState(in_fds[1], OPEN_FLAGS_NOINHERIT);
        }

        if (pipe_err) {
            save_err = dup(STDERR_FILENO);
            dup2(err_fds[1], STDERR_FILENO);
            close(err_fds[1]);
            DosSetFHState(err_fds[0], OPEN_FLAGS_NOINHERIT);
        }
        
        pid = func(data, NULL);
    
        if ( pid )
            ap_note_subprocess(p, pid, kill_how);

        if (pipe_out) {
            close(STDOUT_FILENO);
            dup2(save_out, STDOUT_FILENO);
            close(save_out);
            *pipe_out = out_fds[0];
        }

        if (pipe_in) {
            close(STDIN_FILENO);
            dup2(save_in, STDIN_FILENO);
            close(save_in);
            *pipe_in = in_fds[1];
        }

        if (pipe_err) {
            close(STDERR_FILENO);
            dup2(save_err, STDERR_FILENO);
            close(save_err);
            *pipe_err = err_fds[0];
        }
    }
#elif defined(TPF)
   return (pid = ap_tpf_spawn_child(p, func, data, kill_how,	
                 pipe_in, pipe_out, pipe_err, out_fds, in_fds, err_fds));		
d2164 1
a2164 2
    pid_t pid;
    int save_errno;
d2220 1
a2220 5
    HANDLE hPipeInputWriteDup = NULL;
    HANDLE hPipeOutputReadDup = NULL;
    HANDLE hPipeErrorReadDup  = NULL;
    HANDLE hCurrentProcess;
    pid_t pid = 0;
a2257 51
    /*
     * When the pipe handles are created, the security descriptor
     * indicates that the handle can be inherited.  However, we do not
     * want the server side handles to the pipe to be inherited by the
     * child CGI process. If the child CGI does inherit the server
     * side handles, then the child may be left around if the server
     * closes its handles (e.g. if the http connection is aborted),
     * because the child will have a valid copy of handles to both
     * sides of the pipes, and no I/O error will occur.  Microsoft
     * recommends using DuplicateHandle to turn off the inherit bit
     * under NT and Win95.
     */
    hCurrentProcess = GetCurrentProcess();
    if ((pipe_in && !DuplicateHandle(hCurrentProcess, hPipeInputWrite,
				     hCurrentProcess,
				     &hPipeInputWriteDup, 0, FALSE,
				     DUPLICATE_SAME_ACCESS))
	|| (pipe_out && !DuplicateHandle(hCurrentProcess, hPipeOutputRead,
					 hCurrentProcess, &hPipeOutputReadDup,
					 0, FALSE, DUPLICATE_SAME_ACCESS))
	|| (pipe_err && !DuplicateHandle(hCurrentProcess, hPipeErrorRead,
					 hCurrentProcess, &hPipeErrorReadDup,
					 0, FALSE, DUPLICATE_SAME_ACCESS))) {
	if (pipe_in) {
	    CloseHandle(hPipeInputRead);
	    CloseHandle(hPipeInputWrite);
	}
	if (pipe_out) {
	    CloseHandle(hPipeOutputRead);
	    CloseHandle(hPipeOutputWrite);
	}
	if (pipe_err) {
	    CloseHandle(hPipeErrorRead);
	    CloseHandle(hPipeErrorWrite);
	}
	return 0;
    }
    else {
	if (pipe_in) {
	    CloseHandle(hPipeInputWrite);
	    hPipeInputWrite = hPipeInputWriteDup;
	}
	if (pipe_out) {
	    CloseHandle(hPipeOutputRead);
	    hPipeOutputRead = hPipeOutputReadDup;
	}
	if (pipe_err) {
	    CloseHandle(hPipeErrorRead);
	    hPipeErrorRead = hPipeErrorReadDup;
	}
    }
d2341 1
a2341 2
    pid_t pid;
    int save_errno;
a2434 1
#elif defined(NETWARE)
d2449 1
a2449 1
	    if (ap_os_kill(p->pid, SIGTERM) != -1)
@


1.1.1.3
log
@import apache 1.3.27 and mod_ssl 2.8.11
@
text
@a66 4
#ifdef EAPI
#include "http_config.h"
#include "http_conf_globals.h"
#endif
a140 4
#if defined(EAPI) && defined(EAPI_MM)
static AP_MM *mm = NULL;
#endif

a168 3
#if defined(EAPI) && defined(EAPI_MM)
	int is_shm;
#endif
a218 3
#if defined(EAPI) && defined(EAPI_MM)
static union block_hdr *malloc_block(int size, int is_shm)
#else
a219 1
#endif
a232 5
#if defined(EAPI) && defined(EAPI_MM)
    if (is_shm)
        blok = (union block_hdr *)ap_mm_malloc(mm, size + sizeof(union block_hdr));
    else
#endif
a238 3
#if defined(EAPI) && defined(EAPI_MM)
    blok->h.is_shm = is_shm;
#endif
a298 4
#if defined(EAPI) && defined(EAPI_MM)
    if (blok->h.is_shm)
        (void)ap_mm_lock(mm, AP_MM_LOCK_RW);
#endif
a344 4
#if defined(EAPI) && defined(EAPI_MM)
    if (blok->h.is_shm)
        (void)ap_mm_unlock(mm);
#endif
a352 3
#if defined(EAPI) && defined(EAPI_MM)
static union block_hdr *new_block(int min_size, int is_shm)
#else
a353 1
#endif
a362 4
#if defined(EAPI) && defined(EAPI_MM)
    if (blok->h.is_shm == is_shm &&
        min_size + BLOCK_MINFREE <= blok->h.endp - blok->h.first_avail) {
#else
a363 1
#endif
a378 3
#if defined(EAPI) && defined(EAPI_MM)
    blok = malloc_block((min_size > BLOCK_MINALLOC) ? min_size : BLOCK_MINALLOC, is_shm);
#else
a379 1
#endif
a428 3
#if defined(EAPI) && defined(EAPI_MM)
    int is_shm;
#endif
a442 3
#if defined(EAPI) && defined(EAPI_MM)
static struct pool *make_sub_pool_internal(struct pool *p, int is_shm)
#else
a443 1
#endif
a449 4
#if defined(EAPI) && defined(EAPI_MM)
    if (is_shm)
        (void)ap_mm_lock(mm, AP_MM_LOCK_RW);
#endif
a451 3
#if defined(EAPI) && defined(EAPI_MM)
    blok = new_block(POOL_HDR_BYTES, is_shm);
#else
a452 1
#endif
a470 4
#if defined(EAPI) && defined(EAPI_MM)
    new_pool->is_shm = is_shm;
#endif

a471 4
#if defined(EAPI) && defined(EAPI_MM)
    if (is_shm)
	(void)ap_mm_unlock(mm);
#endif
a476 18
#if defined(EAPI)
#if defined(EAPI_MM)
API_EXPORT(struct pool *) ap_make_sub_pool(struct pool *p)
{
    return make_sub_pool_internal(p, 0);
}
API_EXPORT(struct pool *) ap_make_shared_sub_pool(struct pool *p)
{
    return make_sub_pool_internal(p, 1);
}
#else
API_EXPORT(struct pool *) ap_make_shared_sub_pool(struct pool *p)
{
    return NULL;
}
#endif
#endif

a490 7
#if defined(EAPI)
int ap_shared_pool_possible(void)
{
    return ap_mm_useable();
}
#endif

a522 52
#if defined(EAPI)
void ap_init_alloc_shared(int early)
{
#if defined(EAPI_MM)
    int mm_size;
    char *mm_path;
    char *err1, *err2;

    if (early) {
        /* process very early on startup */
        mm_size = ap_mm_maxsize();
        if (mm_size > EAPI_MM_CORE_MAXSIZE)
            mm_size = EAPI_MM_CORE_MAXSIZE;
        mm_path = ap_server_root_relative(permanent_pool, 
                  ap_psprintf(permanent_pool, "%s.%ld", 
                              EAPI_MM_CORE_PATH, (long)getpid()));
        if ((mm = ap_mm_create(mm_size, mm_path)) == NULL) {
            fprintf(stderr, "Ouch! ap_mm_create(%d, \"%s\") failed\n", mm_size, mm_path);
            err1 = ap_mm_error();
            if (err1 == NULL)
                err1 = "-unknown-";
            err2 = strerror(errno);
            if (err2 == NULL)
                err2 = "-unknown-";
            fprintf(stderr, "Error: MM: %s: OS: %s\n", err1, err2);
            exit(1);
        }
    }
    else {
        /* process a lot later on startup */
#ifdef WIN32
        ap_mm_permission(mm, (_S_IREAD|_S_IWRITE), ap_user_id, -1);
#else
        ap_mm_permission(mm, (S_IRUSR|S_IWUSR), ap_user_id, -1);
#endif
    }
#endif /* EAPI_MM */
    return; 
}

void ap_kill_alloc_shared(void)
{
#if defined(EAPI_MM)
    if (mm != NULL) {
        ap_mm_destroy(mm);
        mm = NULL;
    }
#endif /* EAPI_MM */
    return;
}
#endif /* EAPI */

a532 4
#if defined(EAPI) && defined(EAPI_MM)
    if (a->is_shm)
        (void)ap_mm_lock(mm, AP_MM_LOCK_RW);
#endif
a536 4
#if defined(EAPI) && defined(EAPI_MM)
    if (a->is_shm)
	    (void)ap_mm_unlock(mm);
#endif
a569 4
#if defined(EAPI) && defined(EAPI_MM)
    if (a->is_shm)
	(void)ap_mm_lock(mm, AP_MM_LOCK_RW);
#endif
a579 4
#if defined(EAPI) && defined(EAPI_MM)
    if (a->is_shm)
	(void)ap_mm_unlock(mm);
#endif
a593 24
#if defined(EAPI)
API_EXPORT(int) ap_acquire_pool(pool *p, ap_pool_lock_mode mode)
{
#if defined(EAPI_MM)
    if (!p->is_shm)
        return 1;
    return ap_mm_lock(mm, mode == AP_POOL_RD ? AP_MM_LOCK_RD : AP_MM_LOCK_RW);
#else
	return 1;
#endif
}

API_EXPORT(int) ap_release_pool(pool *p)
{
#if defined(EAPI_MM)
    if (!p->is_shm)
        return 1;
    return ap_mm_unlock(mm);
#else
	return 1;
#endif
}
#endif /* EAPI */

a758 4
#if defined(EAPI) && defined(EAPI_MM)
    if (a->is_shm)
	(void)ap_mm_lock(mm, AP_MM_LOCK_RW);
#endif
a760 3
#if defined(EAPI) && defined(EAPI_MM)
    blok = new_block(size, a->is_shm);
#else
a761 1
#endif
a766 3
#if defined(EAPI) && defined(EAPI_MM)
    blok->h.is_shm = a->is_shm;
#endif
a768 4
#if defined(EAPI) && defined(EAPI_MM)
    if (a->is_shm)
	(void)ap_mm_unlock(mm);
#endif
a871 2
#define AP_PSPRINTF_MIN_SIZE 32  /* Minimum size of allowable avail block */

d876 1
a876 1
    int cur_len, size;
d879 2
a880 10
    cur_len = (char *)ps->vbuff.curpos - ps->base;
    size = cur_len << 1;
    if (size < AP_PSPRINTF_MIN_SIZE)
        size = AP_PSPRINTF_MIN_SIZE;
#if defined(EAPI) && defined(EAPI_MM)
    if (ps->block->h.is_shm)
        ptr = ap_mm_realloc(ps->base, size);
    else
#endif
    ptr = realloc(ps->base, size);
d886 2
a887 2
    ps->vbuff.curpos = ptr + cur_len;
    ps->vbuff.endpos = ptr + size - 1;
d892 1
a892 1
    size_t cur_len, size;
a897 3
    size = cur_len << 1;
    if (size < AP_PSPRINTF_MIN_SIZE)
        size = AP_PSPRINTF_MIN_SIZE;
a899 4
#if defined(EAPI) && defined(EAPI_MM)
    if (blok->h.is_shm)
	(void)ap_mm_lock(mm, AP_MM_LOCK_RW);
#endif
d901 1
a901 5
#if defined(EAPI) && defined(EAPI_MM)
    nblok = new_block(size, blok->h.is_shm);
#else
    nblok = new_block(size);
#endif
a902 4
#if defined(EAPI) && defined(EAPI_MM)
    if (blok->h.is_shm)
	(void)ap_mm_unlock(mm);
#endif
a910 4
#if defined(EAPI) && defined(EAPI_MM)
    if (blok->h.is_shm)
	(void)ap_mm_lock(mm, AP_MM_LOCK_RW);
#endif
a914 4
#if defined(EAPI) && defined(EAPI_MM)
    if (blok->h.is_shm)
	(void)ap_mm_unlock(mm);
#endif
a932 5
#if defined(EAPI) && defined(EAPI_MM)
    if (p->is_shm)
        ps.base = ap_mm_malloc(mm, 512);
    else
#endif
a944 5
#if defined(EAPI) && defined(EAPI_MM)
    if (p->is_shm)
        ptr = ap_mm_realloc(ptr, (char *)ps.vbuff.curpos - (char *)ptr);
    else
#endif
a964 2
    if (ps.blok->h.first_avail == ps.blok->h.endp)
        psprintf_flush(&ps.vbuff);		/* ensure room for NUL */
@


1.1.1.4
log
@import apache 1.3.28 and mod_ssl 2.8.15
@
text
@d4 1
a4 1
 * Copyright (c) 2000-2003 The Apache Software Foundation.  All rights
a236 1
    int request_size;
a247 1
    request_size = size + sizeof(union block_hdr);
d250 1
a250 1
        blok = (union block_hdr *)ap_mm_malloc(mm, request_size);
d253 1
a253 1
    blok = (union block_hdr *) malloc(request_size);
d255 1
a255 2
	fprintf(stderr, "Ouch!  malloc(%d) failed in malloc_block()\n",
                request_size);
d1919 2
a1920 4
API_EXPORT(void) ap_register_cleanup_ex(pool *p, void *data,
				      void (*plain_cleanup) (void *),
				      void (*child_cleanup) (void *),
				      int (*magic_cleanup) (void *))
d1922 6
a1927 23
    struct cleanup *c;
    if (p) {
	c = (struct cleanup *) ap_palloc(p, sizeof(struct cleanup));
	c->data = data;
	c->plain_cleanup = plain_cleanup;
	c->child_cleanup = child_cleanup;
	c->next = p->cleanups;
	p->cleanups = c;
    }
    /* attempt to do magic even if not passed a pool. Allows us
     * to perform the magic, therefore, "whenever" we want/need */
    if (magic_cleanup) {
	if (!magic_cleanup(data)) 
	   ap_log_error(APLOG_MARK, APLOG_WARNING, NULL,
		 "exec() may not be safe");
    }
}

API_EXPORT(void) ap_register_cleanup(pool *p, void *data,
				     void (*plain_cleanup) (void *),
				     void (*child_cleanup) (void *))
{
    ap_register_cleanup_ex(p, data, plain_cleanup, child_cleanup, NULL);
d1981 1
a1981 1
#if !defined(WIN32) && !defined(OS2) && !defined(NETWARE)
d1983 1
a1983 1
     * Don't need to do anything on NT, NETWARE or OS/2, because I
a1994 3
#ifdef EAPI
    ap_kill_alloc_shared();
#endif
a2007 56
#if defined(WIN32)
/* Provided by service.c, internal to the core library (not exported) */
BOOL isWindowsNT(void);

int ap_close_handle_on_exec(HANDLE nth)
{
    /* Protect the fd so that it will not be inherited by child processes */
    if (isWindowsNT()) {
        DWORD hinfo;
        if (!GetHandleInformation(nth, &hinfo)) {
	    ap_log_error(APLOG_MARK, APLOG_ERR, NULL, "GetHandleInformation"
                         "(%08x) failed", nth);
	    return 0;
        }
        if ((hinfo & HANDLE_FLAG_INHERIT)
                && !SetHandleInformation(nth, HANDLE_FLAG_INHERIT, 0)) {
	    ap_log_error(APLOG_MARK, APLOG_ERR, NULL, "SetHandleInformation"
                         "(%08x, HANDLE_FLAG_INHERIT, 0) failed", nth);
	    return 0;
        }
        return 1;
    }
    else /* Win9x */ {
        /* XXX: This API doesn't work... you can't change the handle by just
         * 'touching' it... you must duplicat to a second handle and close
         * the original.
         */
        return 0;
    }
}

int ap_close_fd_on_exec(int fd)
{
    return ap_close_handle_on_exec((HANDLE)_get_osfhandle(fd));
}

#else

int ap_close_fd_on_exec(int fd)
{
#if defined(F_SETFD) && defined(FD_CLOEXEC)
    /* Protect the fd so that it will not be inherited by child processes */
    if(fcntl(fd, F_SETFD, FD_CLOEXEC) < 0) {
	ap_log_error(APLOG_MARK, APLOG_ERR, NULL,
		     "fcntl(%d, F_SETFD, FD_CLOEXEC) failed", fd);
	return 0;
    }

    return 1;
#else
    return 0;
#endif
}

#endif /* ndef(WIN32) */

a2012 14
static int fd_magic_cleanup(void *fdv)
{
    return ap_close_fd_on_exec((int) (long) fdv);
}

API_EXPORT(void) ap_note_cleanups_for_fd_ex(pool *p, int fd, int domagic)
{
#if defined(NETWARE)
    domagic = 0; /* skip magic for NetWare, at least for now */
#endif
    ap_register_cleanup_ex(p, (void *) (long) fd, fd_cleanup, fd_cleanup,
                           domagic ? fd_magic_cleanup : NULL);
}

d2015 1
a2015 1
    ap_note_cleanups_for_fd_ex(p, fd, 0);
d2023 1
a2023 2
API_EXPORT(int) ap_popenf_ex(pool *a, const char *name, int flg, int mode,
                             int domagic)
d2033 1
a2033 1
	ap_note_cleanups_for_fd_ex(a, fd, domagic);
a2039 5
API_EXPORT(int) ap_popenf(pool *a, const char *name, int flg, int mode)
{
    return ap_popenf_ex(a, name, flg, mode, 0);
}

d2055 1
a2055 1
static void h_cleanup(void *nth)
d2057 1
a2057 1
    CloseHandle((HANDLE) nth);
d2060 1
a2060 1
static int h_magic_cleanup(void *nth)
d2062 1
a2062 14
    /* Set handle not-inherited
     */
    return ap_close_handle_on_exec((HANDLE) nth);
}

API_EXPORT(void) ap_note_cleanups_for_h_ex(pool *p, HANDLE nth, int domagic)
{
    ap_register_cleanup_ex(p, (void *) nth, h_cleanup, h_cleanup,
                           domagic ? h_magic_cleanup : NULL);
}

API_EXPORT(void) ap_note_cleanups_for_h(pool *p, HANDLE nth)
{
    ap_note_cleanups_for_h_ex(p, nth, 0);
a2092 1

a2097 14
static int file_magic_cleanup(void *fpv)
{
    return ap_close_fd_on_exec(fileno((FILE *) fpv));
}

API_EXPORT(void) ap_note_cleanups_for_file_ex(pool *p, FILE *fp, int domagic)
{
#if defined(NETWARE)
    domagic = 0; /* skip magic for NetWare, at least for now */
#endif
    ap_register_cleanup_ex(p, (void *) fp, file_cleanup, file_child_cleanup,
                           domagic ? file_magic_cleanup : NULL);
}

d2100 1
a2100 1
    ap_note_cleanups_for_file_ex(p, fp, 0);
a2211 19
static int socket_magic_cleanup(void *fpv)
{
#ifdef WIN32
    return ap_close_handle_on_exec((HANDLE) fpv);
#else
    return ap_close_fd_on_exec((int) (long) fpv);
#endif
}

API_EXPORT(void) ap_note_cleanups_for_socket_ex(pool *p, int fd, int domagic)
{
#if defined(TPF) || defined(NETWARE)
    domagic = 0; /* skip magic (fcntl) for TPF sockets, at least for now */
#endif
    ap_register_cleanup_ex(p, (void *) (long) fd, socket_cleanup,
                           socket_cleanup,
                           domagic ? socket_magic_cleanup : NULL);
}

d2214 1
a2214 1
    ap_note_cleanups_for_socket_ex(p, fd, 0);
d2222 1
a2222 2
API_EXPORT(int) ap_psocket_ex(pool *p, int domain, int type, int protocol,
                              int domagic)
d2234 1
a2234 1
    ap_note_cleanups_for_socket_ex(p, fd, domagic);
a2238 5
API_EXPORT(int) ap_psocket(pool *p, int domain, int type, int protocol)
{
    return ap_psocket_ex(p, domain, type, protocol, 0);
}

d2771 1
a2771 1
            ap_note_cleanups_for_h_ex(p, hPipeOutputRead, 1);   
d2786 1
a2786 1
            ap_note_cleanups_for_h_ex(p, hPipeInputWrite, 1);
d2802 1
a2802 1
            ap_note_cleanups_for_h_ex(p, hPipeErrorRead, 1);
d2840 1
a2840 1
	ap_note_cleanups_for_fd_ex(p, fd_out, 0);
d2846 1
a2846 1
	ap_note_cleanups_for_fd_ex(p, fd_in, 0);
d2852 1
a2852 1
	ap_note_cleanups_for_fd_ex(p, fd_err, 0);
a2860 11

/* 
 * Timing constants for killing subprocesses
 * There is a total 3-second delay between sending a SIGINT 
 * and sending of the final SIGKILL.
 * TIMEOUT_INTERVAL should be set to TIMEOUT_USECS / 64
 * for the exponential timeout algorithm.
 */
#define TIMEOUT_USECS    3000000
#define TIMEOUT_INTERVAL   46875

d2867 1
a2870 4
#if !defined(WIN32) && !defined(NETWARE)
    int timeout_interval;
    struct timeval tv;
#endif
d2931 1
a2931 4
	    if (ap_os_kill(p->pid, SIGTERM) == -1) {
                p->kill_how = kill_never;
            }
            else {
a2932 1
            }
d2939 4
a2942 31
    /* Sleep only if we have to. The sleep algorithm grows
     * by a factor of two on each iteration. TIMEOUT_INTERVAL
     * is equal to TIMEOUT_USECS / 64.
     */
    if (need_timeout) {
        timeout_interval = TIMEOUT_INTERVAL;
        tv.tv_sec = 0;
        tv.tv_usec = timeout_interval;
        ap_select(0, NULL, NULL, NULL, &tv);

        do {
            need_timeout = 0;
            for (p = procs; p; p = p->next) {
                if (p->kill_how == kill_after_timeout) {
                    if (waitpid(p->pid, (int *) 0, WNOHANG | WUNTRACED) > 0)
                        p->kill_how = kill_never;
                    else
                        need_timeout = 1;
                }
            }
            if (need_timeout) {
                if (timeout_interval >= TIMEOUT_USECS) {
                    break;
                }
                tv.tv_sec = timeout_interval / 1000000;
                tv.tv_usec = timeout_interval % 1000000;
                ap_select(0, NULL, NULL, NULL, &tv);
                timeout_interval *= 2;
            }
        } while (need_timeout);
    }
d2950 1
d2957 1
a2957 1
#endif /* !WIN32 && !NETWARE*/
@


1.1.1.5
log
@import Apache 1.3.29 and mod_ssl 2.8.16
@
text
@d2017 3
d3098 7
a3104 8
	    /*
	     * This is totally bogus, but seems to be the
	     * only portable (as in reliable) way to accomplish
	     * this. Note that this implies an unavoidable
	     * delay.
	     */
	    ap_os_kill(p->pid, SIGTERM);
	    need_timeout = 1;
@


