head	1.63;
access;
symbols
	OPENBSD_6_0:1.62.0.4
	OPENBSD_6_0_BASE:1.62
	OPENBSD_5_9:1.62.0.2
	OPENBSD_5_9_BASE:1.62
	OPENBSD_5_8:1.60.0.4
	OPENBSD_5_8_BASE:1.60
	OPENBSD_5_7:1.58.0.2
	OPENBSD_5_7_BASE:1.58
	OPENBSD_5_6:1.57.0.4
	OPENBSD_5_6_BASE:1.57
	OPENBSD_5_5:1.56.0.8
	OPENBSD_5_5_BASE:1.56
	OPENBSD_5_4:1.56.0.4
	OPENBSD_5_4_BASE:1.56
	OPENBSD_5_3:1.56.0.2
	OPENBSD_5_3_BASE:1.56
	OPENBSD_5_2:1.55.0.2
	OPENBSD_5_2_BASE:1.55
	OPENBSD_5_1_BASE:1.54
	OPENBSD_5_1:1.54.0.4
	OPENBSD_5_0:1.54.0.2
	OPENBSD_5_0_BASE:1.54
	OPENBSD_4_9:1.53.0.4
	OPENBSD_4_9_BASE:1.53
	OPENBSD_4_8:1.53.0.2
	OPENBSD_4_8_BASE:1.53
	OPENBSD_4_7:1.51.0.8
	OPENBSD_4_7_BASE:1.51
	OPENBSD_4_6:1.51.0.10
	OPENBSD_4_6_BASE:1.51
	OPENBSD_4_5:1.51.0.6
	OPENBSD_4_5_BASE:1.51
	OPENBSD_4_4:1.51.0.4
	OPENBSD_4_4_BASE:1.51
	OPENBSD_4_3:1.51.0.2
	OPENBSD_4_3_BASE:1.51
	OPENBSD_4_2:1.49.0.2
	OPENBSD_4_2_BASE:1.49
	OPENBSD_4_1:1.47.0.6
	OPENBSD_4_1_BASE:1.47
	OPENBSD_4_0:1.47.0.4
	OPENBSD_4_0_BASE:1.47
	OPENBSD_3_9:1.47.0.2
	OPENBSD_3_9_BASE:1.47
	OPENBSD_3_8:1.46.0.2
	OPENBSD_3_8_BASE:1.46
	OPENBSD_3_7:1.45.0.10
	OPENBSD_3_7_BASE:1.45
	OPENBSD_3_6:1.45.0.8
	OPENBSD_3_6_BASE:1.45
	SMP_SYNC_A:1.45
	SMP_SYNC_B:1.45
	OPENBSD_3_5:1.45.0.6
	OPENBSD_3_5_BASE:1.45
	OPENBSD_3_4:1.45.0.4
	OPENBSD_3_4_BASE:1.45
	UBC_SYNC_A:1.45
	OPENBSD_3_3:1.45.0.2
	OPENBSD_3_3_BASE:1.45
	OPENBSD_3_2:1.43.0.4
	OPENBSD_3_2_BASE:1.43
	OPENBSD_3_1:1.43.0.2
	OPENBSD_3_1_BASE:1.43
	UBC_SYNC_B:1.44
	UBC:1.40.0.2
	UBC_BASE:1.40
	OPENBSD_3_0:1.32.0.2
	OPENBSD_3_0_BASE:1.32
	OPENBSD_2_9_BASE:1.22
	OPENBSD_2_9:1.22.0.2
	OPENBSD_2_8:1.21.0.2
	OPENBSD_2_8_BASE:1.21
	OPENBSD_2_7:1.19.0.2
	OPENBSD_2_7_BASE:1.19
	SMP:1.12.0.2
	SMP_BASE:1.12
	kame_19991208:1.11
	OPENBSD_2_6:1.11.0.2
	OPENBSD_2_6_BASE:1.11
	OPENBSD_2_5:1.7.0.2
	OPENBSD_2_5_BASE:1.7
	OPENBSD_2_4:1.6.0.2
	OPENBSD_2_4_BASE:1.6
	OPENBSD_2_3:1.5.0.4
	OPENBSD_2_3_BASE:1.5
	OPENBSD_2_2:1.5.0.2
	OPENBSD_2_2_BASE:1.5
	OPENBSD_2_1:1.4.0.4
	OPENBSD_2_1_BASE:1.4
	OPENBSD_2_0:1.4.0.2
	OPENBSD_2_0_BASE:1.4
	netbsd_1_1:1.1.1.1;
locks; strict;
comment	@ * @;


1.63
date	2016.09.01.09.23.43;	author tedu;	state dead;
branches;
next	1.62;
commitid	Q2PxaFNhqAe0Wmla;

1.62
date	2015.11.06.06.33.26;	author guenther;	state Exp;
branches;
next	1.61;
commitid	wzHEHv1WzrJZbX9A;

1.61
date	2015.09.08.10.21.16;	author deraadt;	state Exp;
branches;
next	1.60;
commitid	DGOx6p2gOlciIkZ2;

1.60
date	2015.05.05.02.13.47;	author guenther;	state Exp;
branches;
next	1.59;
commitid	dNPv28CJI5BxtRGW;

1.59
date	2015.03.30.20.30.22;	author miod;	state Exp;
branches;
next	1.58;
commitid	f66FukLLgPJs9j5H;

1.58
date	2014.11.16.12.30.59;	author deraadt;	state Exp;
branches;
next	1.57;
commitid	yv0ECmCdICvq576h;

1.57
date	2014.07.12.18.44.43;	author tedu;	state Exp;
branches;
next	1.56;
commitid	uKVPYMN2MLxdZxzH;

1.56
date	2013.01.16.19.04.43;	author miod;	state Exp;
branches;
next	1.55;

1.55
date	2012.06.21.00.56.59;	author guenther;	state Exp;
branches;
next	1.54;

1.54
date	2011.04.07.15.30.16;	author miod;	state Exp;
branches;
next	1.53;

1.53
date	2010.06.29.21.26.12;	author miod;	state Exp;
branches;
next	1.52;

1.52
date	2010.06.22.20.27.32;	author oga;	state Exp;
branches;
next	1.51;

1.51
date	2007.11.28.16.33.20;	author martin;	state Exp;
branches;
next	1.50;

1.50
date	2007.10.10.15.53.53;	author art;	state Exp;
branches;
next	1.49;

1.49
date	2007.06.20.17.29.36;	author miod;	state Exp;
branches;
next	1.48;

1.48
date	2007.05.27.20.59.26;	author miod;	state Exp;
branches;
next	1.47;

1.47
date	2006.01.20.23.27.25;	author miod;	state Exp;
branches;
next	1.46;

1.46
date	2005.08.18.18.40.51;	author kettenis;	state Exp;
branches;
next	1.45;

1.45
date	2002.12.10.23.45.02;	author miod;	state Exp;
branches;
next	1.44;

1.44
date	2002.10.14.20.31.46;	author art;	state Exp;
branches;
next	1.43;

1.43
date	2002.02.20.22.28.23;	author deraadt;	state Exp;
branches;
next	1.42;

1.42
date	2002.01.16.20.50.17;	author miod;	state Exp;
branches;
next	1.41;

1.41
date	2001.12.19.08.58.05;	author art;	state Exp;
branches;
next	1.40;

1.40
date	2001.12.09.01.45.32;	author art;	state Exp;
branches
	1.40.2.1;
next	1.39;

1.39
date	2001.12.08.02.24.07;	author art;	state Exp;
branches;
next	1.38;

1.38
date	2001.12.07.10.47.38;	author art;	state Exp;
branches;
next	1.37;

1.37
date	2001.11.28.13.47.39;	author art;	state Exp;
branches;
next	1.36;

1.36
date	2001.11.22.09.49.43;	author art;	state Exp;
branches;
next	1.35;

1.35
date	2001.11.07.01.18.00;	author art;	state Exp;
branches;
next	1.34;

1.34
date	2001.11.06.19.53.16;	author miod;	state Exp;
branches;
next	1.33;

1.33
date	2001.11.06.18.41.10;	author art;	state Exp;
branches;
next	1.32;

1.32
date	2001.09.19.20.50.57;	author mickey;	state Exp;
branches;
next	1.31;

1.31
date	2001.09.17.15.18.16;	author art;	state Exp;
branches;
next	1.30;

1.30
date	2001.08.08.01.30.02;	author art;	state Exp;
branches;
next	1.29;

1.29
date	2001.07.25.13.25.33;	author art;	state Exp;
branches;
next	1.28;

1.28
date	2001.07.05.10.00.38;	author art;	state Exp;
branches;
next	1.27;

1.27
date	2001.06.10.01.45.04;	author deraadt;	state Exp;
branches;
next	1.26;

1.26
date	2001.06.08.08.09.28;	author art;	state Exp;
branches;
next	1.25;

1.25
date	2001.05.18.08.25.03;	author miod;	state Exp;
branches;
next	1.24;

1.24
date	2001.05.10.10.34.50;	author art;	state Exp;
branches;
next	1.23;

1.23
date	2001.05.05.20.56.53;	author art;	state Exp;
branches;
next	1.22;

1.22
date	2001.01.15.23.23.58;	author jason;	state Exp;
branches;
next	1.21;

1.21
date	2000.06.08.22.25.22;	author niklas;	state Exp;
branches;
next	1.20;

1.20
date	2000.06.05.11.02.53;	author art;	state Exp;
branches;
next	1.19;

1.19
date	2000.05.01.18.28.58;	author art;	state Exp;
branches;
next	1.18;

1.18
date	2000.02.28.16.34.28;	author deraadt;	state Exp;
branches;
next	1.17;

1.17
date	2000.02.21.21.05.59;	author art;	state Exp;
branches;
next	1.16;

1.16
date	2000.02.21.14.51.20;	author art;	state Exp;
branches;
next	1.15;

1.15
date	2000.02.18.17.40.04;	author art;	state Exp;
branches;
next	1.14;

1.14
date	2000.02.17.20.18.00;	author art;	state Exp;
branches;
next	1.13;

1.13
date	2000.02.15.16.32.41;	author art;	state Exp;
branches;
next	1.12;

1.12
date	99.12.09.16.19.50;	author art;	state Exp;
branches
	1.12.2.1;
next	1.11;

1.11
date	99.09.03.18.02.00;	author art;	state Exp;
branches;
next	1.10;

1.10
date	99.08.17.10.32.18;	author niklas;	state Exp;
branches;
next	1.9;

1.9
date	99.07.09.21.30.03;	author art;	state Exp;
branches;
next	1.8;

1.8
date	99.04.22.19.24.57;	author art;	state Exp;
branches;
next	1.7;

1.7
date	99.01.10.13.34.19;	author niklas;	state Exp;
branches;
next	1.6;

1.6
date	98.07.28.00.13.52;	author millert;	state Exp;
branches;
next	1.5;

1.5
date	97.08.08.08.27.48;	author downsj;	state Exp;
branches;
next	1.4;

1.4
date	96.08.11.05.35.28;	author deraadt;	state Exp;
branches;
next	1.3;

1.3
date	95.12.15.13.56.48;	author deraadt;	state Exp;
branches;
next	1.2;

1.2
date	95.11.10.00.25.06;	author chuck;	state Exp;
branches;
next	1.1;

1.1
date	95.10.18.08.51.48;	author deraadt;	state Exp;
branches
	1.1.1.1;
next	;

1.1.1.1
date	95.10.18.08.51.48;	author deraadt;	state Exp;
branches;
next	;

1.12.2.1
date	2000.02.20.11.56.56;	author niklas;	state Exp;
branches;
next	1.12.2.2;

1.12.2.2
date	2000.02.21.22.29.04;	author niklas;	state Exp;
branches;
next	1.12.2.3;

1.12.2.3
date	2000.03.02.07.04.34;	author niklas;	state Exp;
branches;
next	1.12.2.4;

1.12.2.4
date	2001.05.14.21.37.20;	author niklas;	state Exp;
branches;
next	1.12.2.5;

1.12.2.5
date	2001.07.04.10.23.49;	author niklas;	state Exp;
branches;
next	1.12.2.6;

1.12.2.6
date	2001.10.31.03.07.57;	author nate;	state Exp;
branches;
next	1.12.2.7;

1.12.2.7
date	2001.11.13.21.04.17;	author niklas;	state Exp;
branches;
next	1.12.2.8;

1.12.2.8
date	2001.12.05.00.39.13;	author niklas;	state Exp;
branches;
next	1.12.2.9;

1.12.2.9
date	2002.03.06.02.04.46;	author niklas;	state Exp;
branches;
next	1.12.2.10;

1.12.2.10
date	2003.03.27.23.49.26;	author niklas;	state Exp;
branches;
next	;

1.40.2.1
date	2002.01.31.22.55.23;	author niklas;	state Exp;
branches;
next	1.40.2.2;

1.40.2.2
date	2002.06.11.03.38.17;	author art;	state Exp;
branches;
next	1.40.2.3;

1.40.2.3
date	2002.10.29.00.28.11;	author art;	state Exp;
branches;
next	1.40.2.4;

1.40.2.4
date	2003.05.19.21.46.33;	author tedu;	state Exp;
branches;
next	;


desc
@@


1.63
log
@Celebrate OpenBSD 6.0 release by retiring the sparc port.
You've served us well, good friend, but now it's time to rest.
ok deraadt
@
text
@/*	$OpenBSD: vm_machdep.c,v 1.62 2015/11/06 06:33:26 guenther Exp $	*/
/*	$NetBSD: vm_machdep.c,v 1.30 1997/03/10 23:55:40 pk Exp $ */

/*
 * Copyright (c) 1996
 *	The President and Fellows of Harvard College. All rights reserved.
 * Copyright (c) 1992, 1993
 *	The Regents of the University of California.  All rights reserved.
 *
 * This software was developed by the Computer Systems Engineering group
 * at Lawrence Berkeley Laboratory under DARPA contract BG 91-66 and
 * contributed to Berkeley.
 *
 * All advertising materials mentioning features or use of this software
 * must display the following acknowledgement:
 *	This product includes software developed by the University of
 *	California, Lawrence Berkeley Laboratory.
 *	This product includes software developed by Harvard University.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *	This product includes software developed by Harvard University.
 *	This product includes software developed by the University of
 *	California, Berkeley and its contributors.
 * 4. Neither the name of the University nor the names of its contributors
 *    may be used to endorse or promote products derived from this software
 *    without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE
 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
 *
 *	@@(#)vm_machdep.c	8.2 (Berkeley) 9/23/93
 */

#include <sys/param.h>
#include <sys/systm.h>
#include <sys/proc.h>
#include <sys/signalvar.h>
#include <sys/user.h>
#include <sys/malloc.h>
#include <sys/buf.h>
#include <sys/exec.h>
#include <sys/vnode.h>
#include <sys/extent.h>

#include <uvm/uvm_extern.h>

#include <machine/cpu.h>
#include <machine/frame.h>
#include <machine/trap.h>

#include <sparc/sparc/cpuvar.h>

/*
 * Map an IO request into kernel virtual address space.
 */
void
vmapbuf(struct buf *bp, vsize_t sz)
{
	vaddr_t uva, kva;
	vsize_t size, off;
	struct pmap *pmap;
	paddr_t pa;

#ifdef DIAGNOSTIC
	if ((bp->b_flags & B_PHYS) == 0)
		panic("vmapbuf");
#endif
	pmap = vm_map_pmap(&bp->b_proc->p_vmspace->vm_map);

	bp->b_saveaddr = bp->b_data;
	uva = trunc_page((vaddr_t)bp->b_data);
	off = (vaddr_t)bp->b_data - uva;
	size = round_page(off + sz);
	/*
	 * Note that this is an expanded version of:
	 *   kva = uvm_km_valloc_wait(kernel_map, size);
	 * We do it on our own here to be able to specify an offset to uvm_map
	 * so that we can get all benefits of PMAP_PREFER.
	 */
	kva = uvm_km_valloc_prefer_wait(kernel_map, size, uva);
	bp->b_data = (caddr_t)(kva + off);

	while (size > 0) {
		if (pmap_extract(pmap, uva, &pa) == FALSE)
			panic("vmapbuf: null page frame");

		/*
		 * Don't enter uncached if cache is mandatory.
		 *
		 * XXX - there are probably other cases where we don't need
		 *       to uncache, but for now we're conservative.
		 */
		if (!(cpuinfo.flags & CPUFLG_CACHE_MANDATORY))
			pa |= PMAP_NC;

		pmap_enter(pmap_kernel(), kva, pa,
		    PROT_READ | PROT_WRITE, PMAP_WIRED);

		uva += PAGE_SIZE;
		kva += PAGE_SIZE;
		size -= PAGE_SIZE;
	}
	pmap_update(pmap_kernel());
}

/*
 * Free the io map addresses associated with this IO operation.
 */
void
vunmapbuf(bp, sz)
	register struct buf *bp;
	vsize_t sz;
{
	register vaddr_t kva;
	register vsize_t size, off;

	if ((bp->b_flags & B_PHYS) == 0)
		panic("vunmapbuf");

	kva = trunc_page((vaddr_t)bp->b_data);
	off = (vaddr_t)bp->b_data - kva;
	size = round_page(sz + off);

	pmap_remove(pmap_kernel(), kva, kva + size);
	pmap_update(pmap_kernel());
	uvm_km_free_wakeup(kernel_map, kva, size);
	bp->b_data = bp->b_saveaddr;
	bp->b_saveaddr = NULL;
	if (CACHEINFO.c_vactype != VAC_NONE)
		cpuinfo.cache_flush(bp->b_data, bp->b_bcount - bp->b_resid);
}


/*
 * The offset of the topmost frame in the kernel stack.
 */
#define	TOPFRAMEOFF (USPACE-sizeof(struct trapframe)-sizeof(struct frame))

/*
 * Finish a fork operation, with process p2 nearly set up.
 * Copy and update the pcb, making the child ready to run, and marking
 * it so that it can return differently than the parent.
 *
 * This function relies on the fact that the pcb is
 * the first element in struct user.
 */
void
cpu_fork(p1, p2, stack, stacksize, func, arg)
	struct proc *p1, *p2;
	void *stack;
	size_t stacksize;
	void (*func)(void *);
	void *arg;
{
	struct pcb *opcb = &p1->p_addr->u_pcb;
	struct pcb *npcb = &p2->p_addr->u_pcb;
	struct trapframe *tf2;
	struct rwindow *rp;

	/*
	 * Save all user registers to p1's stack or, in the case of
	 * user registers and invalid stack pointers, to opcb.
	 * We then copy the whole pcb to p2; when switch() selects p2
	 * to run, it will run at the `proc_trampoline' stub, rather
	 * than returning at the copying code below.
	 *
	 * If process p1 has an FPU state, we must copy it.  If it is
	 * the FPU user, we must save the FPU state first.
	 */

	if (p1 == curproc) {
		write_user_windows();
		opcb->pcb_psr = getpsr();
	}
#ifdef DIAGNOSTIC
	else if (p1 != &proc0)
		panic("cpu_fork: curproc");
#endif

	bcopy((caddr_t)opcb, (caddr_t)npcb, sizeof(struct pcb));
	if (p1->p_md.md_fpstate) {
		if (p1 == cpuinfo.fpproc)
			savefpstate(p1->p_md.md_fpstate);
		p2->p_md.md_fpstate = malloc(sizeof(struct fpstate),
		    M_SUBPROC, M_WAITOK);
		bcopy(p1->p_md.md_fpstate, p2->p_md.md_fpstate,
		    sizeof(struct fpstate));
	} else
		p2->p_md.md_fpstate = NULL;

	/*
	 * Setup (kernel) stack frame that will by-pass the child
	 * out of the kernel. (The trap frame invariably resides at
	 * the tippity-top of the u. area.)
	 */
	tf2 = p2->p_md.md_tf = (struct trapframe *)
			((int)npcb + USPACE - sizeof(*tf2));

	/* Copy parent's trapframe */
	*tf2 = *(struct trapframe *)((int)opcb + USPACE - sizeof(*tf2));

	/* Construct kernel frame to return to in cpu_switch() */
	rp = (struct rwindow *)((u_int)npcb + TOPFRAMEOFF);
	rp->rw_local[0] = (int)func;		/* Function to call */
	rp->rw_local[1] = (int)arg;		/* and its argument */

	/*
	 * If specified, give the child a different stack, with space
	 * reserved for the frame, and zero the frame pointer.
	 */
	if (stack != NULL) {
		tf2->tf_out[6] = (u_int)stack + stacksize
		    - sizeof(struct frame);
		rp->rw_in[6] = 0;
	}

	npcb->pcb_pc = (int)proc_trampoline - 8;
	npcb->pcb_sp = (int)rp;
	npcb->pcb_psr &= ~PSR_CWP;	/* Run in window #0 */
	npcb->pcb_wim = 1;		/* Fence at window #1 */

}

/*
 * cpu_exit is called as the last action during exit.
 *
 * We clean up a little and then call sched_exit() with the old proc
 * as an argument.  sched_exit() schedules the old vmspace and stack
 * to be freed, then selects a new process to run.
 */
void
cpu_exit(p)
	struct proc *p;
{
	register struct fpstate *fs;

	if ((fs = p->p_md.md_fpstate) != NULL) {
		if (p == cpuinfo.fpproc) {
			savefpstate(fs);
			cpuinfo.fpproc = NULL;
		}
		free(fs, M_SUBPROC, sizeof *fs);
	}

	pmap_deactivate(p);
	sched_exit(p);
}
@


1.62
log
@Move the logic for adjusting userspace registers in the child after fork
from cpu_fork() to child_return(), putting all the SYSCALL_G2RFLAG logic
in trap.c

sparc testing by sebastia@@ and miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.61 2015/09/08 10:21:16 deraadt Exp $	*/
@


1.61
log
@sizes for free(); ok semarie
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.60 2015/05/05 02:13:47 guenther Exp $	*/
a218 21

	/* Duplicate efforts of syscall(), but slightly differently */
	if (tf2->tf_global[1] & SYSCALL_G2RFLAG) {
		/* jmp %g2 (or %g7, deprecated) on success */
		tf2->tf_npc = tf2->tf_global[2];
	} else {
		/*
		 * old system call convention: clear C on success
		 * note: proc_trampoline() sets a fresh psr when
		 * returning to user mode.
		 */
		/*tf2->tf_psr &= ~PSR_C;   -* success */
	}

	/* Set return values in child mode */
	tf2->tf_out[0] = 0;
	tf2->tf_out[1] = 1;

	/* Skip trap instruction. */
	tf2->tf_pc = tf2->tf_npc;
	tf2->tf_npc += 4;
@


1.60
log
@emul_native is only used for kernel threads which can't dump core, so
delete coredump_trad(), uvm_coredump(), cpu_coredump(), struct md_coredump,
and various #includes that are superfluous.

This leaves compat_linux processes without a coredump callback.  If that
ability is desired, someone should update it to use coredump_elf32() and
verify the results...

ok kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.59 2015/03/30 20:30:22 miod Exp $	*/
d281 1
a281 1
		free((void *)fs, M_SUBPROC, 0);
@


1.59
log
@Add a bus_dma_tag_t for DVMA usage, suitable for use for devices not sitting
behind a sun4m iommu.

Move the existing dvma routines from vm_machdep.c to this new dvma.c; this
allows for a few declarations to be removed from public headers.

Extend the device attachment arguments (struct confargs) to pass a
bus_dma_tag_t. mainbus receives the dvma bus_dma_tag_t, and devices pass the
tag unchanged to their children, except for iommu(4) which replaces it with
its own.

Change the few sun4m-only drivers to pick the bus_dma_tag_t from confargs
rather than assume iommu; this allows qlw(4) to attach and work on sun4c.

ok kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.58 2014/11/16 12:30:59 deraadt Exp $	*/
a56 1
#include <sys/core.h>
a285 46
}

/*
 * cpu_coredump is called to write a core dump header.
 * (should this be defined elsewhere?  machdep.c?)
 */
int
cpu_coredump(p, vp, cred, chdr)
	struct proc *p;
	struct vnode *vp;
	struct ucred *cred;
	struct core *chdr;
{
	int error;
	struct md_coredump md_core;
	struct coreseg cseg;

	CORE_SETMAGIC(*chdr, COREMAGIC, MID_SPARC, 0);
	chdr->c_hdrsize = ALIGN(sizeof(*chdr));
	chdr->c_seghdrsize = ALIGN(sizeof(cseg));
	chdr->c_cpusize = sizeof(md_core);

	md_core.md_tf = *p->p_md.md_tf;
	md_core.md_wcookie = p->p_addr->u_pcb.pcb_wcookie;
	if (p->p_md.md_fpstate) {
		if (p == cpuinfo.fpproc)
			savefpstate(p->p_md.md_fpstate);
		md_core.md_fpstate = *p->p_md.md_fpstate;
	} else
		bzero((caddr_t)&md_core.md_fpstate, sizeof(struct fpstate));

	CORE_SETMAGIC(cseg, CORESEGMAGIC, MID_SPARC, CORE_CPU);
	cseg.c_addr = 0;
	cseg.c_size = chdr->c_cpusize;
	error = vn_rdwr(UIO_WRITE, vp, (caddr_t)&cseg, chdr->c_seghdrsize,
	    (off_t)chdr->c_hdrsize, UIO_SYSSPACE, IO_UNIT, cred, NULL, p);
	if (error)
		return error;

	error = vn_rdwr(UIO_WRITE, vp, (caddr_t)&md_core, sizeof(md_core),
	    (off_t)(chdr->c_hdrsize + chdr->c_seghdrsize), UIO_SYSSPACE,
	    IO_UNIT, cred, NULL, p);
	if (!error)
		chdr->c_nseg++;

	return error;
@


1.58
log
@Replace a plethora of historical protection options with just
PROT_NONE, PROT_READ, PROT_WRITE, and PROT_EXEC from mman.h.
PROT_MASK is introduced as the one true way of extracting those bits.
Remove UVM_ADV_* wrapper, using the standard names.
ok doug guenther kettenis
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.57 2014/07/12 18:44:43 tedu Exp $	*/
a70 189

/*
 * Wrapper for dvma_mapin() in kernel space,
 * so drivers need not include VM goo to get at kernel_map.
 */
caddr_t
kdvma_mapin(va, len, canwait)
	caddr_t	va;
	int	len, canwait;
{
	return ((caddr_t)dvma_mapin(kernel_map, (vaddr_t)va, len, canwait));
}

#if defined(SUN4M)
extern int has_iocache;
#endif

caddr_t
dvma_malloc_space(len, kaddr, flags, space)
	size_t	len;
	void	*kaddr;
	int	flags;
{
	vaddr_t	kva;
	vaddr_t	dva;

	len = round_page(len);
	kva = (vaddr_t)malloc(len, M_DEVBUF, flags);
	if (kva == 0)
		return (NULL);

#if defined(SUN4M)
	if (!has_iocache)
#endif
		kvm_uncache((caddr_t)kva, atop(len));

	*(vaddr_t *)kaddr = kva;
	dva = dvma_mapin_space(kernel_map, kva, len, (flags & M_NOWAIT) ? 0 : 1, space);
	if (dva == 0) {
		free((void *)kva, M_DEVBUF, 0);
		return (NULL);
	}
	return (caddr_t)dva;
}

void
dvma_free(dva, len, kaddr)
	caddr_t	dva;
	size_t	len;
	void	*kaddr;
{
	vaddr_t	kva = *(vaddr_t *)kaddr;

	len = round_page(len);

	dvma_mapout((vaddr_t)dva, kva, len);
	/*
	 * Even if we're freeing memory here, we can't be sure that it will
	 * be unmapped, so we must recache the memory range to avoid impact
	 * on other kernel subsystems.
	 */
#if defined(SUN4M)
	if (!has_iocache)
#endif
		kvm_recache(kaddr, atop(len));
	free((void *)kva, M_DEVBUF, 0);
}

u_long dvma_cachealign = 0;

/*
 * Map a range [va, va+len] of wired virtual addresses in the given map
 * to a valid DVMA address. On non-SRMMU systems, this establish a
 * second mapping of that range.
 */
vaddr_t
dvma_mapin_space(map, va, len, canwait, space)
	struct vm_map	*map;
	vaddr_t	va;
	int		len, canwait, space;
{
	vaddr_t	kva, tva;
	int npf, s;
	paddr_t pa;
	vaddr_t off;
	vaddr_t ova;
	int olen;
	int error;

	if (dvma_cachealign == 0)
	        dvma_cachealign = PAGE_SIZE;

	ova = va;
	olen = len;

	off = va & PAGE_MASK;
	va &= ~PAGE_MASK;
	len = round_page(len + off);
	npf = atop(len);

	s = splhigh();
	if (space & M_SPACE_D24)
		error = extent_alloc_subregion(dvmamap_extent,
		    DVMA_D24_BASE, DVMA_D24_END, len, dvma_cachealign,
		    va & (dvma_cachealign - 1), 0,
		    canwait ? EX_WAITSPACE : EX_NOWAIT, &tva);
	else
		error = extent_alloc(dvmamap_extent, len, dvma_cachealign, 
		    va & (dvma_cachealign - 1), 0,
		    canwait ? EX_WAITSPACE : EX_NOWAIT, &tva);
	splx(s);
	if (error)
		return 0;
	kva = tva;

	while (npf--) {
		if (pmap_extract(vm_map_pmap(map), va, &pa) == FALSE)
			panic("dvma_mapin: null page frame");
		pa = trunc_page(pa);

#if defined(SUN4M)
		if (CPU_ISSUN4M) {
			iommu_enter(tva, pa);
		} else
#endif
		{
			/*
			 * pmap_enter distributes this mapping to all
			 * contexts... maybe we should avoid this extra work
			 */
#ifdef notyet
#if defined(SUN4)
			if (have_iocache)
				pa |= PG_IOC;
#endif
#endif
			pmap_kenter_pa(tva, pa | PMAP_NC,
			    PROT_READ | PROT_WRITE);
		}

		tva += PAGE_SIZE;
		va += PAGE_SIZE;
	}
	pmap_update(pmap_kernel());

	/*
	 * XXX Only have to do this on write.
	 */
	if (CACHEINFO.c_vactype == VAC_WRITEBACK)	/* XXX */
		cpuinfo.cache_flush((caddr_t)ova, olen);	/* XXX */

	return kva + off;
}

/*
 * Remove DVMA mapping of `va' in DVMA space at `dva'.
 */
void
dvma_mapout(dva, va, len)
	vaddr_t	dva, va;
	int		len;
{
	int s, off;
	int error;
	int dlen;

	off = (int)dva & PGOFSET;
	dva -= off;
	dlen = round_page(len + off);

#if defined(SUN4M)
	if (CPU_ISSUN4M)
		iommu_remove(dva, dlen);
	else
#endif
	{
		pmap_kremove(dva, dlen);
		pmap_update(pmap_kernel());
	}

	s = splhigh();
	error = extent_free(dvmamap_extent, dva, dlen, EX_NOWAIT);
	if (error)
		printf("dvma_mapout: extent_free failed\n");
	splx(s);

	if (CACHEINFO.c_vactype != VAC_NONE)
		cpuinfo.cache_flush((caddr_t)va, len);
}
@


1.57
log
@add a size argument to free. will be used soon, but for now default to 0.
after discussions with beck deraadt kettenis.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.56 2013/01/16 19:04:43 miod Exp $	*/
d208 1
a208 1
			    VM_PROT_READ | VM_PROT_WRITE);
d305 1
a305 1
			   VM_PROT_READ | VM_PROT_WRITE, PMAP_WIRED);
@


1.56
log
@cpu_coredump() also needs to invoke vn_rdwr() without IO_NODELOCKED; only
affects a.out binaries' core dumps.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.55 2012/06/21 00:56:59 guenther Exp $	*/
d110 1
a110 1
		free((void *)kva, M_DEVBUF);
d136 1
a136 1
	free((void *)kva, M_DEVBUF);
d471 1
a471 1
		free((void *)fs, M_SUBPROC);
@


1.55
log
@__tfork() needs to set the stack address of the new thread in the kernel,
so that it can't get a signal while still running on the parent thread's
stack.  Also, pass in sizeof(struct __tfork) to provide forward compat
when more members are added.  This is an ABI change, so switch syscall
numbers and bump lib majors this time.

ok deraadt@@ matthew@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.54 2011/04/07 15:30:16 miod Exp $	*/
d511 1
a511 2
	    (off_t)chdr->c_hdrsize, UIO_SYSSPACE,
	    IO_NODELOCKED|IO_UNIT, cred, NULL, p);
d517 1
a517 1
	    IO_NODELOCKED|IO_UNIT, cred, NULL, p);
@


1.54
log
@Do not use NULL in integer comparisons. No functional change.
ok matthew@@ tedu@@, also eyeballed by at least krw@@ oga@@ kettenis@@ jsg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.53 2010/06/29 21:26:12 miod Exp $	*/
a409 6
	/*
	 * If specified, give the child a different stack.
	 */
	if (stack != NULL)
		tf2->tf_out[6] = (u_int)stack + stacksize;

d435 10
@


1.53
log
@There is absolutely no need to double map DVMA addresses into the kernel address
space on SRMMU systems (i.e. sun4m), so don't do it anymore and update
misleading comments.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.52 2010/06/22 20:27:32 oga Exp $	*/
d99 1
a99 1
	if (kva == NULL)
d109 1
a109 1
	if (dva == NULL) {
d183 1
a183 1
		return NULL;
@


1.52
log
@When mapping memory into dvma space, use pmap_kenter_pa() instead of
pmap_enter(), according to the XXX comment right above.

Removes another un-CANFAILed pmap_enter.

ok miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.51 2007/11/28 16:33:20 martin Exp $	*/
d143 2
a144 1
 * to a kernel address in DVMA space.
d226 1
a226 1
 * Remove double map of `va' in DVMA space at `kva'.
d229 2
a230 2
dvma_mapout(kva, va, len)
	vaddr_t	kva, va;
d235 1
a235 1
	int klen;
d237 3
a239 3
	off = (int)kva & PGOFSET;
	kva -= off;
	klen = round_page(len + off);
d243 1
a243 1
		iommu_remove(kva, klen);
d247 1
a247 1
		pmap_kremove(kva, klen);
d252 1
a252 1
	error = extent_free(dvmamap_extent, kva, klen, EX_NOWAIT);
@


1.51
log
@ctob/btoc -> ptoa/atop

from Rodolfo Gouveia
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.50 2007/10/10 15:53:53 art Exp $	*/
d206 2
a207 3
			/* XXX - this should probably be pmap_kenter */
			pmap_enter(pmap_kernel(), tva, pa | PMAP_NC,
				   VM_PROT_READ | VM_PROT_WRITE, PMAP_WIRED);
d246 1
a246 1
		pmap_remove(pmap_kernel(), kva, kva + klen);
@


1.50
log
@Make context switching much more MI:
 - Move the functionality of choosing a process from cpu_switch into
   a much simpler function: cpu_switchto. Instead of having the locore
   code walk the run queues, let the MI code choose the process we
   want to run and only implement the context switching itself in MD
   code.
 - Let MD context switching run without worrying about spls or locks.
 - Instead of having the idle loop implemented with special contexts
   in MD code, implement one idle proc for each cpu. make the idle
   loop MI with MD hooks.
 - Change the proc lists from the old style vax queues to TAILQs.
 - Change the sleep queue from vax queues to TAILQs. This makes
   wakeup() go from O(n^2) to O(n)

there will be some MD fallout, but it will be fixed shortly.
There's also a few cleanups to be done after this.

deraadt@@, kettenis@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.49 2007/06/20 17:29:36 miod Exp $	*/
d168 1
a168 1
	npf = btoc(len);
@


1.49
log
@In vunmapbuf(), explicitely remove mappings before invoking uvm_km_free().
Even if the latter would end up removing the mappings by itself, it would
do so using pmap_remove() because phys_map is not intrsafe; but some
platforms use pmap_kenter_pa() in vmapbuf(). By removing the mappings
ourselves, we can ensure the remove function used matches the enter function
which has been used.
Discussed and theoretical ok art@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.48 2007/05/27 20:59:26 miod Exp $	*/
d452 3
a454 4
 * We clean up a little and then call switchexit() with the old proc
 * as an argument.  switchexit() switches to the idle context, schedules
 * the old vmspace and stack to be freed, then selects a new process to
 * run.
d470 2
a471 2
	switchexit(p);
	/* NOTREACHED */
@


1.48
log
@pagemove() is no longer used.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.47 2006/01/20 23:27:25 miod Exp $	*/
d332 2
@


1.47
log
@b_un.b_addr -> b_data; no functional change.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.46 2005/08/18 18:40:51 kettenis Exp $	*/
a70 28

/*
 * Move pages from one kernel virtual address to another.
 */
void
pagemove(from, to, size)
	register caddr_t from, to;
	size_t size;
{
	paddr_t pa;

#ifdef DEBUG
	if ((size & PAGE_MASK) != 0 ||
	    ((vaddr_t)from & PAGE_MASK) != 0 ||
	    ((vaddr_t)to & PAGE_MASK) != 0)
		panic("pagemove 1");
#endif
	while (size > 0) {
		if (pmap_extract(pmap_kernel(), (vaddr_t)from, &pa) == FALSE)
			panic("pagemove 2");
		pmap_kremove((vaddr_t)from, PAGE_SIZE);
		pmap_kenter_pa((vaddr_t)to, pa, VM_PROT_READ|VM_PROT_WRITE);
		from += PAGE_SIZE;
		to += PAGE_SIZE;
		size -= PAGE_SIZE;
	}
	pmap_update(pmap_kernel());
}
@


1.46
log
@Skip (trap) instruction in cpu_fork() instead of proc_trampoline().
Add special handling for init(8) in setregs().
Fixes returning from fork(2) in the child with a pending signal.
ok deraadt@@, art@@ (screaming in agony)
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.45 2002/12/10 23:45:02 miod Exp $	*/
d364 1
a364 1
		cpuinfo.cache_flush(bp->b_un.b_addr, bp->b_bcount - bp->b_resid);
@


1.45
log
@Use CPU_ISSUN4M macro rather than check cputyp value. Consistent with the rest
of the file.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.44 2002/10/14 20:31:46 art Exp $	*/
d458 4
@


1.44
log
@Use uvm_km_valloc_prefer_wait instead of doing the same thing manually.

<miod> well, my comments are "looks sane, works for me, ok to commit"
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.43 2002/02/20 22:28:23 deraadt Exp $	*/
d270 1
a270 1
	if (cputyp == CPU_SUN4M)
@


1.43
log
@frantzen's stackghost code.  wcookie is set at 0 right now, until debugger
support added (i mean, written)
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.42 2002/01/16 20:50:17 miod Exp $	*/
d293 1
a293 3
vmapbuf(bp, sz)
	struct buf *bp;
	vsize_t sz;
a295 1
	paddr_t pa;
d298 1
d316 1
a316 8
	while (1) {
		kva = vm_map_min(kernel_map);
		if (uvm_map(kernel_map, &kva, size, NULL, uva, 0,
		    UVM_MAPFLAG(UVM_PROT_ALL, UVM_PROT_ALL,
		    UVM_INH_NONE, UVM_ADV_RANDOM, 0)) == 0)
			break;
		tsleep(kernel_map, PVM, "vallocwait", 0);
	}
@


1.42
log
@Don't include <sys/map.h> when you don't need what's in it.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.41 2001/12/19 08:58:05 art Exp $	*/
d527 1
@


1.41
log
@UBC was a disaster. It worked very good when it worked, but on some
machines or some configurations or in some phase of the moon (we actually
don't know when or why) files disappeared. Since we've not been able to
track down the problem in two weeks intense debugging and we need -current
to be stable, back out everything to a state it had before UBC.

We apologise for the inconvenience.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.40 2001/12/09 01:45:32 art Exp $	*/
a61 1
#include <sys/map.h>
@


1.40
log
@splbio?!? Where did that come from?
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.39 2001/12/08 02:24:07 art Exp $	*/
d118 4
a121 1
dvma_malloc_space(size_t len, void *kaddr, int flags, int space)
a122 2
	int waitok = (flags & M_NOWAIT) == 0;
	vsize_t maplen, tmplen;
a124 1
	int s;
d127 2
a128 5
	/* XXX - verify if maybe uvm_km_valloc from kernel_map would be ok. */
	s = splvm();
	kva = uvm_km_valloc(kmem_map, len);
	splx(s);
	if (kva == 0)
a130 14
	for (maplen = 0; maplen < len; maplen += PAGE_SIZE) {
		struct vm_page *pg;
		paddr_t pa;

again:
		pg = uvm_pagealloc(NULL, 0, NULL, 0);
		if (pg == NULL) {
			if (waitok) {
				uvm_wait("dvmapg");
				goto again;
			}
			goto dropit;
		}
		pa = VM_PAGE_TO_PHYS(pg);
d132 1
a132 1
		if (!has_iocache)
d134 1
a134 4
			pa |= PMAP_NC;
		pmap_kenter_pa(kva + maplen, pa, VM_PROT_ALL);
	}
	pmap_update(pmap_kernel());
d137 1
a137 1
	dva = dvma_mapin_space(kernel_map, kva, len, waitok ? 1 : 0, space);
d139 2
a140 1
		goto dropit;
a142 15
dropit:
	for (tmplen = 0; tmplen < maplen; tmplen += PAGE_SIZE) {
		paddr_t pa;

		if (pmap_extract(pmap_kernel(), kva + tmplen, &pa) == FALSE)
			panic("dvma_malloc_space: pmap_extract");

		pmap_kremove(kva + tmplen, PAGE_SIZE);
		uvm_pagefree(PHYS_TO_VM_PAGE(pa));
	}
	pmap_update(pmap_kernel());

	uvm_km_free(kmem_map, kva, len);

	return (NULL);
d146 4
a149 1
dvma_free(caddr_t dva, size_t len, void *kaddr)
a150 1
	size_t tmplen;
d156 10
a165 11
	for (tmplen = 0; tmplen < len; tmplen += PAGE_SIZE) {
		paddr_t pa;

		if (pmap_extract(pmap_kernel(), kva + tmplen, &pa) == FALSE)
			panic("dvma_malloc_space: pmap_extract");

		pmap_kremove(kva + tmplen, PAGE_SIZE);
		uvm_pagefree(PHYS_TO_VM_PAGE(pa));
	}

	uvm_km_free(kmem_map, kva, len);
@


1.40.2.1
log
@Merge in -current, builds on i386, otherwise untested
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.42 2002/01/16 20:50:17 miod Exp $	*/
d62 1
@


1.40.2.2
log
@Sync UBC branch to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.40.2.1 2002/01/31 22:55:23 niklas Exp $	*/
a559 1
	md_core.md_wcookie = p->p_addr->u_pcb.pcb_wcookie;
@


1.40.2.3
log
@sync to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.40.2.2 2002/06/11 03:38:17 art Exp $	*/
d326 3
a328 1
vmapbuf(struct buf *bp, vsize_t sz)
d331 1
a333 1
	paddr_t pa;
d351 8
a358 1
	kva = uvm_km_valloc_prefer_wait(kernel_map, size, uva);
@


1.40.2.4
log
@sync
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d303 1
a303 1
	if (CPU_ISSUN4M)
@


1.39
log
@Sprinkle pmap_update calls where relevant and some other
misc pmap usage fixes.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.38 2001/12/07 10:47:38 art Exp $	*/
d128 1
a128 1
	s = splbio();
d268 1
@


1.38
log
@In dvma_malloc_space and dvma_free allocate and map the memory
ourselves, don't malloc and then uncache the memory.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.37 2001/11/28 13:47:39 art Exp $	*/
d98 1
d154 1
d172 1
d275 1
d307 1
d309 2
d381 1
@


1.37
log
@Sync in more uvm changes from NetBSD.
This time we're getting rid of KERN_* and VM_PAGER_* error codes and
use errnos instead.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.36 2001/11/22 09:49:43 art Exp $	*/
d117 1
a117 4
dvma_malloc_space(len, kaddr, flags, space)
	size_t	len;
	void	*kaddr;
	int	flags;
d119 2
d123 1
d126 5
a130 2
	kva = (vaddr_t)malloc(len, M_DEVBUF, flags);
	if (kva == NULL)
d133 14
d148 1
a148 1
	if (!has_iocache)
d150 3
a152 1
		kvm_uncache((caddr_t)kva, atop(len));
d155 1
a155 1
	dva = dvma_mapin_space(kernel_map, kva, len, (flags & M_NOWAIT) ? 0 : 1, space);
d157 1
a157 2
		free((void *)kva, M_DEVBUF);
		return (NULL);
d160 14
d177 1
a177 4
dvma_free(dva, len, kaddr)
	caddr_t	dva;
	size_t	len;
	void	*kaddr;
d179 1
d185 11
a195 10
	/*
	 * Even if we're freeing memory here, we can't be sure that it will
	 * be unmapped, so we must recache the memory range to avoid impact
	 * on other kernel subsystems.
	 */
#if defined(SUN4M)
	if (!has_iocache)
#endif
		kvm_recache(kaddr, atop(len));
	free((void *)kva, M_DEVBUF);
@


1.36
log
@more pmap_enter vs. pmap_kenter.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.35 2001/11/07 01:18:00 art Exp $	*/
d317 1
a317 1
		    UVM_INH_NONE, UVM_ADV_RANDOM, 0)) == KERN_SUCCESS)
@


1.35
log
@Add an alignment argument to uvm_map that specifies an alignment hint
for the virtual address.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.34 2001/11/06 19:53:16 miod Exp $	*/
a335 4
		/*
		 * pmap_enter distributes this mapping to all
		 * contexts... maybe we should avoid this extra work
		 */
@


1.34
log
@Replace inclusion of <vm/foo.h> with the correct <uvm/bar.h> when necessary.
(Look ma, I might have broken the tree)
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.33 2001/11/06 18:41:10 art Exp $	*/
d315 1
a315 1
		if (uvm_map(kernel_map, &kva, size, NULL, uva,
@


1.33
log
@Let fork1, uvm_fork, and cpu_fork take a function/argument pair as argument,
instead of doing fork1, cpu_set_kpc. This lets us retire cpu_set_kpc and
avoid a multiprocessor race.

This commit breaks vax because it doesn't look like any other arch, someone
working on vax might want to look at this and try to adapt the code to be
more like the rest of the world.

Idea and uvm parts from NetBSD.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.32 2001/09/19 20:50:57 mickey Exp $	*/
a64 1
#include <vm/vm.h>
@


1.32
log
@merge vm/vm_kern.h into uvm/uvm_extern.h; art@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.31 2001/09/17 15:18:16 art Exp $	*/
d390 2
a391 2
cpu_fork(p1, p2, stack, stacksize)
	register struct proc *p1, *p2;
d394 2
d397 4
a400 4
	register struct pcb *opcb = &p1->p_addr->u_pcb;
	register struct pcb *npcb = &p2->p_addr->u_pcb;
	register struct trapframe *tf2;
	register struct rwindow *rp;
d469 2
a470 2
	rp->rw_local[0] = (int)child_return;	/* Function to call */
	rp->rw_local[1] = (int)p2;		/* and its argument */
a476 39
}

/*
 * cpu_set_kpc:
 *
 * Arrange for in-kernel execution of a process to continue at the
 * named pc, as if the code at that address were called as a function
 * with the current process's process pointer as an argument.
 *
 * Note that it's assumed that when the named process returns,
 * we immediately return to user mode.
 *
 * (Note that cpu_fork(), above, uses an open-coded version of this.)
 */
void
cpu_set_kpc(p, pc, arg)
	struct proc *p;
	void (*pc) __P((void *));
	void *arg;
{
	struct pcb *pcb;
	struct rwindow *rp;

	pcb = &p->p_addr->u_pcb;

	rp = (struct rwindow *)((u_int)pcb + TOPFRAMEOFF);
	rp->rw_local[0] = (int)pc;		/* Function to call */
	rp->rw_local[1] = (int)arg;		/* and its argument */

	/*
	 * Frob PCB:
	 *	- arrange to return to proc_trampoline() from cpu_switch()
	 *	- point it at the stack frame constructed above
	 *	- make it run in a clear set of register windows
	 */
	pcb->pcb_pc = (int)proc_trampoline - 8;
	pcb->pcb_sp = (int)rp;
	pcb->pcb_psr &= ~PSR_CWP;	/* Run in window #0 */
	pcb->pcb_wim = 1;		/* Fence at window #1 */
@


1.31
log
@Use pmap_k* to map the buffer cache.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.30 2001/08/08 01:30:02 art Exp $	*/
d66 1
a66 1
#include <vm/vm_kern.h>
@


1.30
log
@Fix broken logic in wait flags passed to extent_alloc.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.29 2001/07/25 13:25:33 art Exp $	*/
d93 2
a94 5
		pmap_remove(pmap_kernel(),
		    (vaddr_t)from, (vaddr_t)from + PAGE_SIZE);
		pmap_enter(pmap_kernel(),
		    (vaddr_t)to, pa, VM_PROT_READ | VM_PROT_WRITE,
		     VM_PROT_READ | VM_PROT_WRITE | PMAP_WIRED);
@


1.29
log
@Change the pmap_enter interface to merge access_type and the wired boolean
and arbitrary flags into one argument.

One new flag is PMAP_CANFAIL that tells pmap_enter that it can fail if there
are not enough resources to satisfy the request. If this flag is not passed,
pmap_enter should panic as it should have done before this change (XXX - many
pmaps are still not doing that).

Only i386 and alpha implement CANFAIL for now.

Includes uvm updates from NetBSD.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.28 2001/07/05 10:00:38 art Exp $	*/
d207 1
a207 1
		    canwait ? EX_WAITSPACE : EX_WAITOK, &tva);
d211 1
a211 1
		    canwait ? EX_WAITSPACE : EX_WAITOK, &tva);
@


1.28
log
@Get rid of the wrapper macros around extent_alloc*1
Pass the right amount of arguments and rename them back to their right names.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.27 2001/06/10 01:45:04 deraadt Exp $	*/
d96 2
a97 2
		    (vaddr_t)to, pa, VM_PROT_READ | VM_PROT_WRITE, 1,
		     VM_PROT_READ | VM_PROT_WRITE);
d239 1
a239 2
				   VM_PROT_READ | VM_PROT_WRITE, 1,
				   0);
d345 1
a345 1
			   VM_PROT_READ | VM_PROT_WRITE, 1, 0);
@


1.27
log
@Art error #2
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.26 2001/06/08 08:09:28 art Exp $	*/
d204 1
a204 1
		error = extent_alloc_subregion1(dvmamap_extent,
d209 1
a209 1
		error = extent_alloc1(dvmamap_extent, len, dvma_cachealign, 
@


1.26
log
@Change the paddr_t pmap_extract(struct pmap *, vaddr_t) interface to
boolean_t pmap_extract(struct pmap *, vaddr_t, paddr_t *).
Matches NetBSD. Tested by various people on various platforms.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.25 2001/05/18 08:25:03 miod Exp $	*/
d82 1
a82 1
	register paddr_t pa;
@


1.25
log
@Remove a duplicate variable initialization in vunmapbuf(), and remove
unncessary lint /*ARGSUSED*/ hint. art@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.24 2001/05/10 10:34:50 art Exp $	*/
d91 1
a91 2
		pa = pmap_extract(pmap_kernel(), (vaddr_t)from);
		if (pa == 0)
d218 1
a218 2
		pa = pmap_extract(vm_map_pmap(map), va);
		if (pa == 0)
d329 1
a329 2
		pa = pmap_extract(pmap, uva);
		if (pa == 0)
@


1.24
log
@UVM is no longer optional on sparc.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.23 2001/05/05 20:56:53 art Exp $	*/
a293 1
/*ARGSUSED*/
a359 1
/*ARGSUSED*/
d365 1
a365 1
	register vaddr_t kva = (vaddr_t)bp->b_data;
@


1.23
log
@Get rid of CLSIZE and all related stuff.
CLSIZE -> 1
CLBYTES -> PAGE_SIZE
OLOFSET -> PAGE_MASK
etc.
At the same time some archs needed some cleaning in vmparam.h so that
goes in at the same time.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.22 2001/01/15 23:23:58 jason Exp $	*/
a314 1
#if defined(UVM)
a328 3
#else
	kva = kmem_alloc_wait(kernel_map, size);
#endif
a376 1
#if defined(UVM)
a377 3
#else
	kmem_free_wakeup(kernel_map, kva, size);
#endif
@


1.22
log
@- increase the amount of space mapped for dvma on sun4m
- use a flag to specify allocations for 24 bit devices
- compatibility macros to deal with the 32 bit devices

This fixes the 'le at sbus' on sun4m problem (with the extent fixes
earlier), and allows the Artecon ethernet cards to work in sun4m machines.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.21 2000/06/08 22:25:22 niklas Exp $	*/
d84 4
a87 1
	if (size & CLOFSET || (int)from & CLOFSET || (int)to & CLOFSET)
d89 1
@


1.21
log
@Add explicit inclusions of signalvar.h to files actually using syms defined
there but relying on an indirect inclusion
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.21 2000/06/08 21:12:07 niklas Exp $	*/
d118 1
a118 1
dvma_malloc(len, kaddr, flags)
d137 1
a137 1
	dva = dvma_mapin(kernel_map, kva, len, (flags & M_NOWAIT) ? 0 : 1);
d175 1
a175 1
dvma_mapin(map, va, len, canwait)
d178 1
a178 1
	int		len, canwait;
d200 9
a208 3
	error = extent_alloc1(dvmamap_extent, len, dvma_cachealign, 
			      va & (dvma_cachealign - 1), 0,
			      canwait ? EX_WAITSPACE : 0, &tva);
@


1.20
log
@Changes to exit handling.

cpu_exit no longer frees the vmspace and u-area. This is now handled by a
separate kernel thread "reaper". This is to avoid sleeping locks in the
critical path of cpu_exit where we're not allowed to sleep.

From NetBSD
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.19 2000/05/01 18:28:58 art Exp $	*/
d55 1
@


1.19
log
@When cache is mandatory, don't pmap_enter uncached in vmapbuf.
This unbreaks physio on SM71 and SM81.

Thanks to mho@@ for borrowing me a cpu I could test on.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.18 2000/02/28 16:34:28 deraadt Exp $	*/
d524 5
a528 4
 * We release the address space and machine-dependent resources,
 * including the memory for the user structure and kernel stack.
 * Since the latter is also the interrupt stack, we release it
 * from assembly code after switching to a temporary pcb+stack.
d543 2
a544 6
#if defined(UVM)
	uvmspace_free(p->p_vmspace);
#else
	vmspace_free(p->p_vmspace);
#endif
	switchexit(kernel_map, p->p_addr, USPACE);
@


1.18
log
@Sanitize v{,un}mapbuf. (use the sizes we are passed, not the size from b_count); art
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.17 2000/02/21 21:05:59 art Exp $	*/
d330 9
d342 1
a342 1
		pmap_enter(pmap_kernel(), kva, pa | PMAP_NC,
@


1.17
log
@move fpproc into the cpuinfo structure.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.16 2000/02/21 14:51:20 art Exp $	*/
d289 1
a289 1
	vaddr_t addr, kva;
d292 1
a292 3
	int npf;
	struct proc *p;
	struct vm_map *map;
d298 2
a299 2
	p = bp->b_proc;
	map = &p->p_vmspace->vm_map;
d301 3
a303 3
	addr = (vaddr_t)bp->b_saveaddr;
	off = addr & PGOFSET;
	size = round_page(bp->b_bcount + off);
d313 1
a313 1
		if (uvm_map(kernel_map, &kva, size, NULL, addr,
d323 3
a325 4
	addr = trunc_page(addr);
	npf = btoc(size);
	while (npf--) {
		pa = pmap_extract(vm_map_pmap(map), (vaddr_t)addr);
d336 1
a336 1
		addr += PAGE_SIZE;
d338 1
d357 3
a359 3
	kva = (vaddr_t)bp->b_data;
	off = kva & PGOFSET;
	size = round_page(bp->b_bcount + off);
a360 1
	kva = trunc_page(kva);
d362 1
a362 1
	uvm_km_free_wakeup(kernel_map, trunc_page(kva), size);
d364 1
a364 1
	kmem_free_wakeup(kernel_map, trunc_page(kva), size);
@


1.16
log
@When mapping something into iommu space hypersparc requires us to align it
so that cache_alias_bits match in the kernel mapping and the iommu mapping.
(see code for better explaination).
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.15 2000/02/18 17:40:04 art Exp $	*/
d422 1
a422 1
		if (p1 == fpproc)
d530 1
a530 1
		if (p == fpproc) {
d532 1
a532 1
			fpproc = NULL;
d567 1
a567 1
		if (p == fpproc)
@


1.15
log
@In vmapbuf expand uvm_km_valloc_wait into a direct call to uvm_map
so that we can specify an offset. This allows uvm_map to use PMAP_PREFER
and removes a big source of bad cache aliases.
With this change I have not seen any bad cache aliases during normal use.
(it is still possible to force them).
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.14 2000/02/17 20:18:00 art Exp $	*/
d167 2
d182 3
a184 3
	long off;
	vaddr_t	ova;
	int		olen;
d187 3
d193 2
a194 2
	off = (int)va & PGOFSET;
	va -= off;
d199 3
a201 2
	error = extent_alloc(dvmamap_extent, len, PAGE_SIZE, 0,
			     canwait ? EX_WAITSPACE : 0, &tva);
@


1.14
log
@In dvma_mapout don't try to flush unmapped memory from cache.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.13 2000/02/15 16:32:41 art Exp $	*/
d280 1
a280 1
	register struct buf *bp;
d283 1
a283 1
	register vaddr_t addr, kva;
d285 2
a286 2
	register vsize_t size, off;
	register int npf;
d288 1
a288 1
	register struct vm_map *map;
d301 14
a314 1
	kva = uvm_km_valloc_wait(kernel_map, size);
@


1.13
log
@Use extents instead of rmaps to handle dvma space.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.12 1999/12/09 16:19:50 art Exp $	*/
d251 1
d255 1
a255 1
	len = round_page(len + off);
d259 1
a259 1
		iommu_remove(kva, len);
d262 1
a262 1
		pmap_remove(pmap_kernel(), kva, kva + len);
d265 1
a265 1
	error = extent_free(dvmamap_extent, kva, len, EX_NOWAIT);
@


1.12
log
@Since we uncache the memory in dvma_malloc, it is a good idea to recacheit in
dvma_free.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.11 1999/09/03 18:02:00 art Exp $	*/
d62 1
d178 3
a180 3
	register int npf, s;
	register paddr_t pa;
	long off, pn;
d183 1
d193 5
a197 12
	s = splimp();
	for (;;) {

		pn = rmalloc(dvmamap, npf);

		if (pn != 0)
			break;
		if (canwait) {
			(void)tsleep(dvmamap, PRIBIO+1, "physio", 0);
			continue;
		}
		splx(s);
d199 1
a199 4
	}
	splx(s);

	kva = tva = rctov(pn);
d249 2
a250 1
	register int s, off;
d263 4
a266 3
	s = splimp();
	rmfree(dvmamap, btoc(len), vtorc(kva));
	wakeup(dvmamap);
d342 2
@


1.12.2.1
log
@Merge in recent code from the trunk
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.15 2000/02/18 17:40:04 art Exp $	*/
a61 1
#include <sys/extent.h>
d177 3
a179 3
	int npf, s;
	paddr_t pa;
	long off;
a181 1
	int error;
d191 14
a204 3
	s = splhigh();
	error = extent_alloc(dvmamap_extent, len, PAGE_SIZE, 0,
			     canwait ? EX_WAITSPACE : 0, &tva);
d206 2
a207 3
	if (error)
		return NULL;
	kva = tva;
d257 1
a257 3
	int s, off;
	int error;
	int klen;
d261 1
a261 1
	klen = round_page(len + off);
d265 1
a265 1
		iommu_remove(kva, klen);
d268 1
a268 1
		pmap_remove(pmap_kernel(), kva, kva + klen);
d270 3
a272 4
	s = splhigh();
	error = extent_free(dvmamap_extent, kva, klen, EX_NOWAIT);
	if (error)
		printf("dvma_mapout: extent_free failed\n");
d285 1
a285 1
	struct buf *bp;
d288 1
a288 1
	vaddr_t addr, kva;
d290 2
a291 2
	vsize_t size, off;
	int npf;
d293 1
a293 1
	struct vm_map *map;
d306 1
a306 14
	/*
	 * Note that this is an expanded version of:
	 *   kva = uvm_km_valloc_wait(kernel_map, size);
	 * We do it on our own here to be able to specify an offset to uvm_map
	 * so that we can get all benefits of PMAP_PREFER.
	 */
	while (1) {
		kva = vm_map_min(kernel_map);
		if (uvm_map(kernel_map, &kva, size, NULL, addr,
		    UVM_MAPFLAG(UVM_PROT_ALL, UVM_PROT_ALL,
		    UVM_INH_NONE, UVM_ADV_RANDOM, 0)) == KERN_SUCCESS)
			break;
		tsleep(kernel_map, PVM, "vallocwait", 0);
	}
a347 2

	kva = trunc_page(kva);
@


1.12.2.2
log
@sync with -current
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.17 2000/02/21 21:05:59 art Exp $	*/
a166 2
u_long dvma_cachealign = 0;

d180 3
a182 3
	vaddr_t off;
	vaddr_t ova;
	int olen;
a184 3
	if (dvma_cachealign == 0)
	        dvma_cachealign = PAGE_SIZE;

d188 2
a189 2
	off = va & PAGE_MASK;
	va &= ~PAGE_MASK;
d194 2
a195 3
	error = extent_alloc1(dvmamap_extent, len, dvma_cachealign, 
			      va & (dvma_cachealign - 1), 0,
			      canwait ? EX_WAITSPACE : 0, &tva);
d416 1
a416 1
		if (p1 == cpuinfo.fpproc)
d524 1
a524 1
		if (p == cpuinfo.fpproc) {
d526 1
a526 1
			cpuinfo.fpproc = NULL;
d561 1
a561 1
		if (p == cpuinfo.fpproc)
@


1.12.2.3
log
@Sync with -current
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d289 1
a289 1
	vaddr_t uva, kva;
d292 3
a294 1
	struct pmap *pmap;
d300 2
a301 2
	pmap = vm_map_pmap(&bp->b_proc->p_vmspace->vm_map);

d303 3
a305 3
	uva = trunc_page((vaddr_t)bp->b_data);
	off = (vaddr_t)bp->b_data - uva;
	size = round_page(off + sz);
d315 1
a315 1
		if (uvm_map(kernel_map, &kva, size, NULL, uva,
d325 4
a328 3

	while (size > 0) {
		pa = pmap_extract(pmap, uva);
d339 1
a339 1
		uva += PAGE_SIZE;
a340 1
		size -= PAGE_SIZE;
d359 3
a361 3
	kva = trunc_page((vaddr_t)bp->b_data);
	off = (vaddr_t)bp->b_data - kva;
	size = round_page(sz + off);
d363 1
d365 1
a365 1
	uvm_km_free_wakeup(kernel_map, kva, size);
d367 1
a367 1
	kmem_free_wakeup(kernel_map, kva, size);
@


1.12.2.4
log
@Continue the aborted merge of current just before 2.9 was cut into the
SMP branch.  Note that this will not make any progress of SMP functionality,
it is just merging of new code from the trunk into the old branch.
Please do not ask me questions about SMP status because of this mail,
instead go read the archives of smp@@openbsd.org, where I mailed about
these commits some week ago.  Another note: I am doing this in chunks now,
so as to not lock too much of the tree for long times
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.22 2001/01/15 23:23:58 jason Exp $	*/
a54 1
#include <sys/signalvar.h>
d117 1
a117 1
dvma_malloc_space(len, kaddr, flags, space)
d136 1
a136 1
	dva = dvma_mapin_space(kernel_map, kva, len, (flags & M_NOWAIT) ? 0 : 1, space);
d174 1
a174 1
dvma_mapin_space(map, va, len, canwait, space)
d177 1
a177 1
	int		len, canwait, space;
d199 3
a201 9
	if (space & M_SPACE_D24)
		error = extent_alloc_subregion1(dvmamap_extent,
		    DVMA_D24_BASE, DVMA_D24_END, len, dvma_cachealign,
		    va & (dvma_cachealign - 1), 0,
		    canwait ? EX_WAITSPACE : EX_WAITOK, &tva);
	else
		error = extent_alloc1(dvmamap_extent, len, dvma_cachealign, 
		    va & (dvma_cachealign - 1), 0,
		    canwait ? EX_WAITSPACE : EX_WAITOK, &tva);
a329 9
		 * Don't enter uncached if cache is mandatory.
		 *
		 * XXX - there are probably other cases where we don't need
		 *       to uncache, but for now we're conservative.
		 */
		if (!(cpuinfo.flags & CPUFLG_CACHE_MANDATORY))
			pa |= PMAP_NC;

		/*
d333 1
a333 1
		pmap_enter(pmap_kernel(), kva, pa,
d515 4
a518 5
 *
 * We clean up a little and then call switchexit() with the old proc
 * as an argument.  switchexit() switches to the idle context, schedules
 * the old vmspace and stack to be freed, then selects a new process to
 * run.
d533 6
a538 2

	switchexit(p);
@


1.12.2.5
log
@Merge in -current from two days ago in the SMP branch.
As usual with merges, they do not indicate progress, so do not hold
your breath for working SMP, and do not mail me and ask about the
state of it.  It has not changed.  There is work ongoing, but very, very
slowly.  The commit is done in parts as to not lock up the tree in too
big chunks at a time.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.12.2.4 2001/05/14 21:37:20 niklas Exp $	*/
d82 1
a82 1
	paddr_t pa;
d84 1
a84 4
#ifdef DEBUG
	if ((size & PAGE_MASK) != 0 ||
	    ((vaddr_t)from & PAGE_MASK) != 0 ||
	    ((vaddr_t)to & PAGE_MASK) != 0)
a85 1
#endif
d87 2
a88 1
		if (pmap_extract(pmap_kernel(), (vaddr_t)from, &pa) == FALSE)
d215 2
a216 1
		if (pmap_extract(vm_map_pmap(map), va, &pa) == FALSE)
d290 1
d311 1
d326 3
d332 2
a333 1
		if (pmap_extract(pmap, uva, &pa) == FALSE)
d361 1
d367 1
a367 1
	register vaddr_t kva;
d377 1
d379 3
@


1.12.2.6
log
@Sync the SMP branch to something just after 3.0
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.12.2.5 2001/07/04 10:23:49 niklas Exp $	*/
d66 1
a66 1
#include <uvm/uvm_extern.h>
d93 5
a97 2
		pmap_kremove((vaddr_t)from, PAGE_SIZE);
		pmap_kenter_pa((vaddr_t)to, pa, VM_PROT_READ|VM_PROT_WRITE);
d204 1
a204 1
		error = extent_alloc_subregion(dvmamap_extent,
d207 1
a207 1
		    canwait ? EX_WAITSPACE : EX_NOWAIT, &tva);
d209 1
a209 1
		error = extent_alloc(dvmamap_extent, len, dvma_cachealign, 
d211 1
a211 1
		    canwait ? EX_WAITSPACE : EX_NOWAIT, &tva);
d239 2
a240 1
				   VM_PROT_READ | VM_PROT_WRITE, PMAP_WIRED);
d346 1
a346 1
			   VM_PROT_READ | VM_PROT_WRITE, PMAP_WIRED);
@


1.12.2.7
log
@Merge in -current
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d65 1
d316 1
a316 1
		if (uvm_map(kernel_map, &kva, size, NULL, uva, 0,
d390 2
a391 2
cpu_fork(p1, p2, stack, stacksize, func, arg)
	struct proc *p1, *p2;
a393 2
	void (*func)(void *);
	void *arg;
d395 4
a398 4
	struct pcb *opcb = &p1->p_addr->u_pcb;
	struct pcb *npcb = &p2->p_addr->u_pcb;
	struct trapframe *tf2;
	struct rwindow *rp;
d467 2
a468 2
	rp->rw_local[0] = (int)func;		/* Function to call */
	rp->rw_local[1] = (int)arg;		/* and its argument */
d475 39
@


1.12.2.8
log
@Merge in -current
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.12.2.7 2001/11/13 21:04:17 niklas Exp $	*/
d317 1
a317 1
		    UVM_INH_NONE, UVM_ADV_RANDOM, 0)) == 0)
d336 4
@


1.12.2.9
log
@Merge in trunk
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d62 1
a97 1
	pmap_update(pmap_kernel());
a233 1
			/* XXX - this should probably be pmap_kenter */
a240 1
	pmap_update(pmap_kernel());
a271 1
	{
a272 2
		pmap_update(pmap_kernel());
	}
a342 1
	pmap_update(pmap_kernel());
a520 1
	md_core.md_wcookie = p->p_addr->u_pcb.pcb_wcookie;
@


1.12.2.10
log
@Sync the SMP branch with 3.3
@
text
@d270 1
a270 1
	if (CPU_ISSUN4M)
d293 3
a295 1
vmapbuf(struct buf *bp, vsize_t sz)
d298 1
a300 1
	paddr_t pa;
d318 8
a325 1
	kva = uvm_km_valloc_prefer_wait(kernel_map, size, uva);
@


1.11
log
@Change the pmap_enter api to pass down an argument that indicates
the access type that caused this mapping. This is to simplify pmaps
with mod/ref emulation (none for the moment) and in some cases speed
up pmap_is_{referenced,modified}.
At the same time, clean up some mappings that had too high protection.

XXX - the access type is incorrect in old vm, it's only used by uvm and MD code.
The actual use of this in pmap_enter implementations is not in this commit.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.10 1999/08/17 10:32:18 niklas Exp $	*/
d111 4
a122 3
#if defined(SUN4M)
	extern int has_iocache;
#endif
d132 1
a132 1
		kvm_uncache((caddr_t)kva, len >> PGSHIFT);
d151 12
a162 1
	dvma_mapout((vaddr_t)dva, kva, round_page(len));
@


1.10
log
@New cpu_fork API to take a stack in which you point the child's stackpointer
to, at the bottom or the top, depending on your architecture's stack growth
direction.  This is in preparation for Linux' clone(2) emulation.
port maintainers, please check that I did the work right.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.9 1999/07/09 21:30:03 art Exp $	*/
d91 2
a92 1
		    (vaddr_t)to, pa, VM_PROT_READ|VM_PROT_WRITE, 1);
d219 3
a221 3
			pmap_enter(pmap_kernel(), tva,
				   pa | PMAP_NC,
				   VM_PROT_READ|VM_PROT_WRITE, 1);
d310 2
a311 3
		pmap_enter(pmap_kernel(), kva,
			   pa | PMAP_NC,
			   VM_PROT_READ|VM_PROT_WRITE, 1);
@


1.9
log
@vm_offset_t -> {v,p}addr_t and vm_size_t -> {v,p}size_t
remove "register" keywords
Various cleanups.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.8 1999/04/22 19:24:57 art Exp $	*/
d362 1
a362 1
cpu_fork(p1, p2)
d364 2
d413 6
@


1.8
log
@UVM stuff. Mostly name changes.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.7 1999/01/10 13:34:19 niklas Exp $	*/
d80 1
a80 1
	register vm_offset_t pa;
d85 1
a85 1
		pa = pmap_extract(pmap_kernel(), (vm_offset_t)from);
d89 1
a89 1
		    (vm_offset_t)from, (vm_offset_t)from + PAGE_SIZE);
d91 1
a91 1
		    (vm_offset_t)to, pa, VM_PROT_READ|VM_PROT_WRITE, 1);
d107 1
a107 1
	return ((caddr_t)dvma_mapin(kernel_map, (vm_offset_t)va, len, canwait));
d116 2
a117 2
	vm_offset_t	kva;
	vm_offset_t	dva;
d123 1
a123 1
	kva = (vm_offset_t)malloc(len, M_DEVBUF, flags);
d132 1
a132 1
	*(vm_offset_t *)kaddr = kva;
d147 1
a147 1
	vm_offset_t	kva = *(vm_offset_t *)kaddr;
d149 1
a149 1
	dvma_mapout((vm_offset_t)dva, kva, round_page(len));
d157 1
a157 1
vm_offset_t
d160 1
a160 1
	vm_offset_t	va;
d163 1
a163 1
	vm_offset_t	kva, tva;
d165 1
a165 1
	register vm_offset_t pa;
d167 1
a167 1
	vm_offset_t	ova;
d241 1
a241 1
	vm_offset_t	kva, va;
d273 1
a273 1
	vm_size_t sz;
d275 3
a277 2
	register vm_offset_t addr, kva, pa;
	register vm_size_t size, off;
d282 1
d285 1
d289 1
a289 1
	addr = (vm_offset_t)bp->b_saveaddr;
d301 1
a301 1
		pa = pmap_extract(vm_map_pmap(map), (vm_offset_t)addr);
d325 1
a325 1
	vm_size_t sz;
d327 2
a328 2
	register vm_offset_t kva = (vm_offset_t)bp->b_data;
	register vm_size_t size, off;
d333 1
a333 1
	kva = (vm_offset_t)bp->b_data;
@


1.7
log
@Generalize cpu_set_kpc to take any kind of arg; mostly from NetBSD
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.6 1998/07/28 00:13:52 millert Exp $	*/
d289 3
d293 1
d333 3
d337 1
d378 9
a386 2
	write_user_windows();
	opcb->pcb_psr = getpsr();
d497 3
d501 1
@


1.6
log
@Return EINVAL when msg_iovlen or iovcnt <= 0; Make uio_resid unsigned (size_t) and don't return EINVAL if it is < 0 in sys_{read,write}.  Remove check for uio_resid < 0 uiomove() now that uio_resid is unsigned and brack remaining panics with #ifdef DIAGNOSTIC.  vn_rdwr() must now take a size_t * as its 9th argument so change that and clean up uses of vn_rdwr().  Fixes 549 + more
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.5 1997/08/08 08:27:48 downsj Exp $	*/
d436 1
a436 1
cpu_set_kpc(p, pc)
d438 2
a439 1
	void (*pc) __P((struct proc *));
d448 1
a448 1
	rp->rw_local[1] = (int)p;		/* and its argument */
@


1.5
log
@Mostly sync to NetBSD-current 970804.

GENERIC currently compiles and runs; some devices (isp) are not complete and
not yet enabled.
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d519 1
a519 1
	    IO_NODELOCKED|IO_UNIT, cred, (int *)NULL, p);
d525 1
a525 1
	    IO_NODELOCKED|IO_UNIT, cred, (int *)NULL, p);
@


1.4
log
@netbsd port, now we merge our changes back in
@
text
@d1 2
a2 1
/*	$NetBSD: vm_machdep.c,v 1.27.4.1 1996/08/02 21:35:20 jtc Exp $ */
d70 1
a70 1
#include <sparc/sparc/cache.h>
d118 3
d127 5
d167 5
a171 3
#if defined(SUN4M)
	extern int has_iocache;
#endif
a177 5
#if defined(SUN4M)
	if (!has_iocache)
	    kvm_uncache((caddr_t)va, len >> PGSHIFT);
#endif

d203 1
a203 1
		if (cputyp == CPU_SUN4M) {
d226 7
d262 2
a263 2
	if (vactype != VAC_NONE)
		cache_flush((caddr_t)va, len);
d332 2
a333 2
	if (vactype != VAC_NONE)
		cache_flush(bp->b_un.b_addr, bp->b_bcount - bp->b_resid);
@


1.3
log
@new mapdev/()/mapiodev() calling convention uses "struct rom_reg *" to supply
base plus an offset
new dvma routines
@
text
@d1 1
a1 1
/*	$NetBSD: vm_machdep.c,v 1.18 1995/12/11 12:44:39 pk Exp $ */
d4 2
d17 1
d29 1
d60 1
d67 1
d74 1
d77 1
a77 1
	int size;
d118 1
d140 1
a140 1
	dvma_mapout((vm_offset_t)dva, kva, len);
d158 3
d167 4
a170 1
	kvm_uncache((caddr_t)va, len >> PGSHIFT);
d196 1
a196 1
#if defined(SUN4M) && 0
d202 1
a202 1
		/*
d205 1
a205 1
		 */
d212 1
a212 1
		pmap_enter(pmap_kernel(), tva,
d214 1
a214 1
		    VM_PROT_READ|VM_PROT_WRITE, 1);
d226 1
a226 1
int
d237 1
a237 1
#if defined(SUN4M) && 0
d242 1
a242 1
	pmap_remove(pmap_kernel(), kva, kva + len);
d256 3
a258 1
vmapbuf(bp)
d260 1
d301 3
a303 1
vunmapbuf(bp)
d305 1
d331 2
a332 3
 * Copy and update the kernel stack and pcb, making the child
 * ready to run, and marking it so that it can return differently
 * than the parent.  Returns 1 in the child process, 0 in the parent.
d337 1
d343 2
a344 1
	register u_int sp, topframe, off, ssize;
d347 1
a347 1
	 * Save all the registers to p1's stack or, in the case of
d349 3
a351 11
	 * snapshot() also sets the given pcb's pcb_sp and pcb_psr
	 * to the current %sp and %psr, and sets pcb_pc to a stub
	 * which returns 1.  We then copy the whole pcb to p2;
	 * when switch() selects p2 to run, it will run at the stub,
	 * rather than at the copying code below, and cpu_fork
	 * will return 1.
	 *
	 * Note that the order `*npcb = *opcb, snapshot(npcb)' is wrong,
	 * as user registers might then wind up only in opcb.
	 * We could call save_user_windows first,
	 * but that would only save 3 stores anyway.
d356 3
a358 1
	snapshot(opcb);
d371 3
a373 4
	 * Copy the active part of the kernel stack,
	 * then adjust each kernel sp -- the frame pointer
	 * in the top frame is a user sp -- in the child's copy,
	 * including the initial one in the child's pcb.
d375 61
a435 13
	sp = npcb->pcb_sp;		/* points to old kernel stack */
	ssize = (u_int)opcb + USPACE - sp;
	if (ssize >= USPACE - sizeof(struct pcb))
		panic("cpu_fork 1");
	off = (u_int)npcb - (u_int)opcb;
	qcopy((caddr_t)sp, (caddr_t)sp + off, ssize);
	sp += off;
	npcb->pcb_sp = sp;
	topframe = (u_int)npcb + TOPFRAMEOFF;
	while (sp < topframe)
		sp = ((struct rwindow *)sp)->rw_in[6] += off;
	if (sp != topframe)
		panic("cpu_fork 2");
d437 4
a440 2
	 * This might be unnecessary, but it may be possible for the child
	 * to run in ptrace or sendsig before it returns from fork.
d442 4
a445 2
	p2->p_md.md_tf = (struct trapframe *)((int)p1->p_md.md_tf + off);
	return (0);
a484 1
	register struct user *up = p->p_addr;
@


1.2
log
@fix DVMA problem on sun4 systems with writeback cache.   you need
to flush the cache after map in so that the info gets written into
main memory.   you really only need to do this when writing data
(e.g. disk write), but there is currently no way to tell if you are
writing so we do it for all cases (XXX this is stupid, fix later).
This causes 4/200's to be able to write disk files on SMD disks without
data corruption.
@
text
@d1 1
a1 1
/*	$NetBSD: vm_machdep.c,v 1.14 1995/06/26 22:46:04 pk Exp $ */
d91 48
a138 2
 * Map a range [va, va+len] in the given map to a kernel address
 * in DVMA space.
d146 1
a146 1
	vm_offset_t	kva, tva, va_0 = va;
d149 1
a149 1
	long pn;
d151 6
a156 1
	npf = btoc(round_page(len));
d160 1
d162 1
d180 1
d182 6
d189 2
a190 2
		 * ###	pmap_enter distributes this mapping to all contexts...
		 *      maybe we should avoid this extra work
d192 6
d199 1
a199 1
		    trunc_page(pa) | PMAP_NC,
d201 2
d206 1
a206 5

	if (vactype == VAC_WRITEBACK)
		cache_flush((caddr_t)va_0, len); /* XXX only needed on write */

	return kva;
d217 1
a217 1
	register int s;
d219 9
d245 3
a247 2
	register int len;
	register caddr_t addr;
d249 1
a249 2
	int off;
	vm_offset_t kva;
a252 2
	addr = bp->b_saveaddr = bp->b_un.b_addr;
	off = (int)addr & PGOFSET;
d254 25
a278 3
	len = round_page(bp->b_bcount + off);
	kva = dvma_mapin(&p->p_vmspace->vm_map, addr-off, len, 1);
	bp->b_un.b_addr = (caddr_t) (kva + off);
d287 2
a288 2
	register vm_offset_t kva = (vm_offset_t)bp->b_un.b_addr;
	register int off, npf;
d293 5
a297 1
	bp->b_un.b_addr = bp->b_saveaddr;
d299 2
a300 33

	off = (int)kva & PGOFSET;
	kva -= off;
	dvma_mapout(kva, bp->b_un.b_addr, round_page(bp->b_bcount + off));
}

/*
 * Allocate physical memory space in the dvma virtual address range.
 */
caddr_t
dvma_malloc(size)
	size_t size;
{
	vm_size_t vsize;
	caddr_t va;

	vsize = round_page(size);
	va = (caddr_t)kmem_alloc(phys_map, vsize);
	if (va == NULL)
		panic("dvma_malloc");
	kvm_uncache(va, vsize >> PGSHIFT);
	return (va);
}

/*
 * Free dvma addresses allocated with dvma_malloc()
 */
void
dvma_free(ptr, size)
	caddr_t ptr;
	size_t size;
{
	kmem_free(phys_map, (vm_offset_t)ptr, size);
@


1.1
log
@Initial revision
@
text
@d100 1
a100 1
	vm_offset_t	kva, tva;
d138 4
@


1.1.1.1
log
@initial import of NetBSD tree
@
text
@@
