head	1.61;
access;
symbols
	OPENBSD_6_0:1.60.0.4
	OPENBSD_6_0_BASE:1.60
	OPENBSD_5_9:1.60.0.2
	OPENBSD_5_9_BASE:1.60
	OPENBSD_5_8:1.59.0.4
	OPENBSD_5_8_BASE:1.59
	OPENBSD_5_7:1.57.0.2
	OPENBSD_5_7_BASE:1.57
	OPENBSD_5_6:1.54.0.6
	OPENBSD_5_6_BASE:1.54
	OPENBSD_5_5:1.54.0.4
	OPENBSD_5_5_BASE:1.54
	OPENBSD_5_4:1.53.0.2
	OPENBSD_5_4_BASE:1.53
	OPENBSD_5_3:1.52.0.8
	OPENBSD_5_3_BASE:1.52
	OPENBSD_5_2:1.52.0.6
	OPENBSD_5_2_BASE:1.52
	OPENBSD_5_1_BASE:1.52
	OPENBSD_5_1:1.52.0.4
	OPENBSD_5_0:1.52.0.2
	OPENBSD_5_0_BASE:1.52
	OPENBSD_4_9:1.50.0.2
	OPENBSD_4_9_BASE:1.50
	OPENBSD_4_8:1.48.0.2
	OPENBSD_4_8_BASE:1.48
	OPENBSD_4_7:1.45.0.4
	OPENBSD_4_7_BASE:1.45
	OPENBSD_4_6:1.45.0.6
	OPENBSD_4_6_BASE:1.45
	OPENBSD_4_5:1.45.0.2
	OPENBSD_4_5_BASE:1.45
	OPENBSD_4_4:1.44.0.2
	OPENBSD_4_4_BASE:1.44
	OPENBSD_4_3:1.43.0.2
	OPENBSD_4_3_BASE:1.43
	OPENBSD_4_2:1.41.0.2
	OPENBSD_4_2_BASE:1.41
	OPENBSD_4_1:1.40.0.8
	OPENBSD_4_1_BASE:1.40
	OPENBSD_4_0:1.40.0.6
	OPENBSD_4_0_BASE:1.40
	OPENBSD_3_9:1.40.0.4
	OPENBSD_3_9_BASE:1.40
	OPENBSD_3_8:1.40.0.2
	OPENBSD_3_8_BASE:1.40
	OPENBSD_3_7:1.37.0.4
	OPENBSD_3_7_BASE:1.37
	OPENBSD_3_6:1.37.0.2
	OPENBSD_3_6_BASE:1.37
	SMP_SYNC_A:1.37
	SMP_SYNC_B:1.37
	OPENBSD_3_5:1.36.0.2
	OPENBSD_3_5_BASE:1.36
	OPENBSD_3_4:1.35.0.4
	OPENBSD_3_4_BASE:1.35
	UBC_SYNC_A:1.35
	OPENBSD_3_3:1.35.0.2
	OPENBSD_3_3_BASE:1.35
	OPENBSD_3_2:1.33.0.2
	OPENBSD_3_2_BASE:1.33
	OPENBSD_3_1:1.32.0.2
	OPENBSD_3_1_BASE:1.32
	UBC_SYNC_B:1.34
	UBC:1.29.0.2
	UBC_BASE:1.29
	OPENBSD_3_0:1.23.0.2
	OPENBSD_3_0_BASE:1.23
	OPENBSD_2_9_BASE:1.16
	OPENBSD_2_9:1.16.0.4
	OPENBSD_2_8:1.16.0.2
	OPENBSD_2_8_BASE:1.16
	OPENBSD_2_7:1.15.0.4
	OPENBSD_2_7_BASE:1.15
	SMP:1.15.0.2
	SMP_BASE:1.15
	kame_19991208:1.12
	OPENBSD_2_6:1.11.0.2
	OPENBSD_2_6_BASE:1.11
	OPENBSD_2_5:1.7.0.6
	OPENBSD_2_5_BASE:1.7
	OPENBSD_2_4:1.7.0.4
	OPENBSD_2_4_BASE:1.7
	OPENBSD_2_3:1.7.0.2
	OPENBSD_2_3_BASE:1.7
	OPENBSD_2_2:1.6.0.2
	OPENBSD_2_2_BASE:1.6
	OPENBSD_2_1:1.3.0.4
	OPENBSD_2_1_BASE:1.3
	OPENBSD_2_0:1.3.0.2
	OPENBSD_2_0_BASE:1.3
	netbsd_1_1:1.1.1.1;
locks; strict;
comment	@ * @;


1.61
date	2016.09.01.09.23.42;	author tedu;	state dead;
branches;
next	1.60;
commitid	Q2PxaFNhqAe0Wmla;

1.60
date	2015.11.10.20.18.53;	author miod;	state Exp;
branches;
next	1.59;
commitid	gBwwYieLpLnDls0T;

1.59
date	2015.03.27.20.25.39;	author miod;	state Exp;
branches;
next	1.58;
commitid	DNjbblqLgBZmk6yi;

1.58
date	2015.03.18.20.56.40;	author miod;	state Exp;
branches;
next	1.57;
commitid	1t8JWNihm6Vc4kyS;

1.57
date	2015.02.15.21.34.33;	author miod;	state Exp;
branches;
next	1.56;
commitid	eahBabNpxnDWKzqJ;

1.56
date	2014.12.17.06.05.51;	author deraadt;	state Exp;
branches;
next	1.55;
commitid	1Ms05ApnZbB2QS7L;

1.55
date	2014.10.14.03.23.27;	author daniel;	state Exp;
branches;
next	1.54;
commitid	FL5lyyRu9c0a0IG7;

1.54
date	2014.01.30.18.16.41;	author miod;	state Exp;
branches;
next	1.53;

1.53
date	2013.06.11.16.42.11;	author deraadt;	state Exp;
branches;
next	1.52;

1.52
date	2011.04.28.20.36.29;	author ariane;	state Exp;
branches;
next	1.51;

1.51
date	2011.03.23.16.54.37;	author pirofti;	state Exp;
branches;
next	1.50;

1.50
date	2010.12.26.15.41.00;	author miod;	state Exp;
branches;
next	1.49;

1.49
date	2010.12.06.20.57.18;	author miod;	state Exp;
branches;
next	1.48;

1.48
date	2010.07.10.19.32.24;	author miod;	state Exp;
branches;
next	1.47;

1.47
date	2010.06.29.21.26.09;	author miod;	state Exp;
branches;
next	1.46;

1.46
date	2010.06.06.10.04.33;	author miod;	state Exp;
branches;
next	1.45;

1.45
date	2009.02.12.18.52.15;	author miod;	state Exp;
branches;
next	1.44;

1.44
date	2008.03.22.20.52.32;	author jasper;	state Exp;
branches;
next	1.43;

1.43
date	2007.12.15.17.24.07;	author deraadt;	state Exp;
branches;
next	1.42;

1.42
date	2007.09.10.18.49.45;	author miod;	state Exp;
branches;
next	1.41;

1.41
date	2007.06.06.17.15.12;	author deraadt;	state Exp;
branches;
next	1.40;

1.40
date	2005.04.17.18.47.48;	author miod;	state Exp;
branches;
next	1.39;

1.39
date	2005.04.04.23.40.02;	author miod;	state Exp;
branches;
next	1.38;

1.38
date	2005.04.03.10.36.10;	author miod;	state Exp;
branches;
next	1.37;

1.37
date	2004.05.20.09.20.41;	author kettenis;	state Exp;
branches;
next	1.36;

1.36
date	2003.11.14.19.05.36;	author miod;	state Exp;
branches;
next	1.35;

1.35
date	2003.01.24.00.51.54;	author miod;	state Exp;
branches;
next	1.34;

1.34
date	2002.10.28.19.30.21;	author art;	state Exp;
branches;
next	1.33;

1.33
date	2002.09.10.18.29.43;	author art;	state Exp;
branches;
next	1.32;

1.32
date	2002.03.14.03.16.00;	author millert;	state Exp;
branches;
next	1.31;

1.31
date	2002.03.14.01.26.43;	author millert;	state Exp;
branches;
next	1.30;

1.30
date	2001.12.19.08.58.05;	author art;	state Exp;
branches;
next	1.29;

1.29
date	2001.12.07.10.52.25;	author art;	state Exp;
branches
	1.29.2.1;
next	1.28;

1.28
date	2001.12.07.10.44.51;	author art;	state Exp;
branches;
next	1.27;

1.27
date	2001.12.07.10.35.33;	author art;	state Exp;
branches;
next	1.26;

1.26
date	2001.12.04.23.22.42;	author art;	state Exp;
branches;
next	1.25;

1.25
date	2001.11.28.15.34.16;	author art;	state Exp;
branches;
next	1.24;

1.24
date	2001.11.28.14.13.06;	author art;	state Exp;
branches;
next	1.23;

1.23
date	2001.08.19.15.36.27;	author art;	state Exp;
branches;
next	1.22;

1.22
date	2001.08.18.20.50.18;	author art;	state Exp;
branches;
next	1.21;

1.21
date	2001.07.25.13.25.33;	author art;	state Exp;
branches;
next	1.20;

1.20
date	2001.06.27.18.30.30;	author art;	state Exp;
branches;
next	1.19;

1.19
date	2001.06.10.01.45.03;	author deraadt;	state Exp;
branches;
next	1.18;

1.18
date	2001.06.08.08.09.26;	author art;	state Exp;
branches;
next	1.17;

1.17
date	2001.05.09.15.31.27;	author art;	state Exp;
branches;
next	1.16;

1.16
date	2000.06.05.11.02.52;	author art;	state Exp;
branches;
next	1.15;

1.15
date	99.12.09.21.35.28;	author art;	state Exp;
branches
	1.15.2.1;
next	1.14;

1.14
date	99.12.09.16.11.48;	author art;	state Exp;
branches;
next	1.13;

1.13
date	99.12.08.10.44.48;	author art;	state Exp;
branches;
next	1.12;

1.12
date	99.11.11.12.30.35;	author art;	state Exp;
branches;
next	1.11;

1.11
date	99.09.03.18.01.55;	author art;	state Exp;
branches;
next	1.10;

1.10
date	99.07.09.21.33.37;	author art;	state Exp;
branches;
next	1.9;

1.9
date	99.04.22.20.36.20;	author art;	state Exp;
branches;
next	1.8;

1.8
date	99.04.22.17.07.29;	author art;	state Exp;
branches;
next	1.7;

1.7
date	97.11.07.08.11.41;	author deraadt;	state Exp;
branches;
next	1.6;

1.6
date	97.09.17.06.47.14;	author downsj;	state Exp;
branches;
next	1.5;

1.5
date	97.08.08.08.26.38;	author downsj;	state Exp;
branches;
next	1.4;

1.4
date	97.06.12.21.38.40;	author grr;	state Exp;
branches;
next	1.3;

1.3
date	96.08.11.05.34.54;	author deraadt;	state Exp;
branches;
next	1.2;

1.2
date	95.10.18.18.10.10;	author deraadt;	state Exp;
branches;
next	1.1;

1.1
date	95.10.18.08.51.44;	author deraadt;	state Exp;
branches
	1.1.1.1;
next	;

1.1.1.1
date	95.10.18.08.51.44;	author deraadt;	state Exp;
branches;
next	;

1.15.2.1
date	2001.05.14.21.37.13;	author niklas;	state Exp;
branches;
next	1.15.2.2;

1.15.2.2
date	2001.07.04.10.23.32;	author niklas;	state Exp;
branches;
next	1.15.2.3;

1.15.2.3
date	2001.10.31.03.07.57;	author nate;	state Exp;
branches;
next	1.15.2.4;

1.15.2.4
date	2001.12.05.00.39.13;	author niklas;	state Exp;
branches;
next	1.15.2.5;

1.15.2.5
date	2002.03.06.02.04.46;	author niklas;	state Exp;
branches;
next	1.15.2.6;

1.15.2.6
date	2002.03.28.10.57.10;	author niklas;	state Exp;
branches;
next	1.15.2.7;

1.15.2.7
date	2003.03.27.23.49.25;	author niklas;	state Exp;
branches;
next	1.15.2.8;

1.15.2.8
date	2004.02.19.10.49.58;	author niklas;	state Exp;
branches;
next	1.15.2.9;

1.15.2.9
date	2004.06.05.23.10.58;	author niklas;	state Exp;
branches;
next	;

1.29.2.1
date	2002.06.11.03.38.16;	author art;	state Exp;
branches;
next	1.29.2.2;

1.29.2.2
date	2002.10.29.00.28.10;	author art;	state Exp;
branches;
next	1.29.2.3;

1.29.2.3
date	2003.05.19.21.46.32;	author tedu;	state Exp;
branches;
next	;


desc
@@


1.61
log
@Celebrate OpenBSD 6.0 release by retiring the sparc port.
You've served us well, good friend, but now it's time to rest.
ok deraadt
@
text
@/*	$OpenBSD: pmap.h,v 1.60 2015/11/10 20:18:53 miod Exp $	*/
/*	$NetBSD: pmap.h,v 1.30 1997/08/04 20:00:47 pk Exp $ */

/*
 * Copyright (c) 1996
 * 	The President and Fellows of Harvard College. All rights reserved.
 * Copyright (c) 1992, 1993
 *	The Regents of the University of California.  All rights reserved.
 *
 * This software was developed by the Computer Systems Engineering group
 * at Lawrence Berkeley Laboratory under DARPA contract BG 91-66 and
 * contributed to Berkeley.
 *
 * All advertising materials mentioning features or use of this software
 * must display the following acknowledgement:
 *	This product includes software developed by Aaron Brown and
 *	Harvard University.
 *	This product includes software developed by the University of
 *	California, Lawrence Berkeley Laboratory.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *	This product includes software developed by Aaron Brown and
 *	Harvard University.
 *	This product includes software developed by the University of
 *	California, Berkeley and its contributors.
 * 4. Neither the name of the University nor the names of its contributors
 *    may be used to endorse or promote products derived from this software
 *    without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE
 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
 *
 *	@@(#)pmap.h	8.1 (Berkeley) 6/11/93
 */

#ifndef	_MACHINE_PMAP_H_
#define _MACHINE_PMAP_H_

#include <machine/pte.h>

/*
 * Pmap structure.
 *
 * The pmap structure really comes in two variants, one---a single
 * instance---for kernel virtual memory and the other---up to nproc
 * instances---for user virtual memory.  Unfortunately, we have to mash
 * both into the same structure.  Fortunately, they are almost the same.
 *
 * The kernel begins at 0xf8000000 and runs to 0xffffffff (although
 * some of this is not actually used).  Kernel space is mapped identically
 * into all user contexts.
 * There is no point in duplicating this mapping in each user process
 * so they do not appear in the user structures.
 *
 * User space begins at 0x00000000 and runs through 0x1fffffff,
 * then has a `hole', then resumes at 0xe0000000 and runs until it
 * hits the kernel space at 0xf8000000.  This can be mapped
 * contiguously by ignorning the top two bits and pretending the
 * space goes from 0 to 37ffffff.  Typically the lower range is
 * used for text+data and the upper for stack, but the code here
 * makes no such distinction.
 *
 * Since each virtual segment covers 256 kbytes, the user space
 * requires 3584 segments, while the kernel (including DVMA on 4/4c)
 * requires only 512 segments.
 *
 *
 ** FOR THE SUN4/SUN4C
 *
 * The segment map entry for virtual segment vseg is offset in
 * pmap->pm_rsegmap by 0 if pmap is not the kernel pmap, or by
 * NUSEG if it is.  We keep a pointer called pmap->pm_segmap
 * pre-offset by this value.  pmap->pm_segmap thus contains the
 * values to be loaded into the user portion of the hardware segment
 * map so as to reach the proper PMEGs within the MMU.  The kernel
 * mappings are `set early' and are always valid in every context
 * (every change is always propagated immediately).
 *
 * The PMEGs within the MMU are loaded `on demand'; when a PMEG is
 * taken away from context `c', the pmap for context c has its
 * corresponding pm_segmap[vseg] entry marked invalid (the MMU segment
 * map entry is also made invalid at the same time).  Thus
 * pm_segmap[vseg] is the `invalid pmeg' number (127 or 511) whenever
 * the corresponding PTEs are not actually in the MMU.  On the other
 * hand, pm_pte[vseg] is NULL only if no pages in that virtual segment
 * are in core; otherwise it points to a copy of the 32 or 64 PTEs that
 * must be loaded in the MMU in order to reach those pages.
 * pm_npte[vseg] counts the number of valid pages in each vseg.
 *
 * XXX performance: faster to count valid bits?
 *
 * The kernel pmap cannot malloc() PTEs since malloc() will sometimes
 * allocate a new virtual segment.  Since kernel mappings are never
 * `stolen' out of the MMU, we just keep all its PTEs there, and
 * have no software copies.  Its mmu entries are nonetheless kept on lists
 * so that the code that fiddles with mmu lists has something to fiddle.
 *
 ** FOR THE SUN4M
 *
 * On this architecture, the virtual-to-physical translation (page) tables
 * are *not* stored within the MMU as they are in the earlier Sun architect-
 * ures; instead, they are maintained entirely within physical memory (there
 * is a TLB cache to prevent the high performance hit from keeping all page
 * tables in core). Thus there is no need to dynamically allocate PMEGs or
 * SMEGs; only contexts must be shared.
 *
 * We maintain two parallel sets of tables: one is the actual MMU-edible
 * hierarchy of page tables in allocated kernel memory; these tables refer
 * to each other by physical address pointers in SRMMU format (thus they
 * are not very useful to the kernel's management routines). The other set
 * of tables is similar to those used for the Sun4/400's 3-level MMU; it
 * is a hierarchy of regmap and segmap structures which contain kernel virtual
 * pointers to each other. These must (unfortunately) be kept in sync.
 *
 */
#define NKREG_4C \
	((unsigned int)(-VM_MIN_KERNEL_ADDRESS_SUN4 / NBPRG))	/* 16 */
#define NUREG_4C	(256 - NKREG_4C)		      /* 240 */
#define NKREG_4M \
	 ((unsigned int)(-VM_MIN_KERNEL_ADDRESS_SRMMU / NBPRG))	/* 64 */
#define NUREG_4M	(256 - NKREG_4M)		      /* 192 */

#define	NKREG_MAX	NKREG_4M

struct regmap {
	struct segmap	*rg_segmap;	/* point to NSGPRG PMEGs */
	int		*rg_seg_ptps; 	/* SRMMU-edible segment tables (NULL
					 * indicates invalid region (4m) */
	smeg_t		rg_smeg;	/* the MMU region number (4c) */
	u_char		rg_nsegmap;	/* number of valid PMEGS */
};

struct segmap {
	int	*sg_pte;		/* points to NPTESG PTEs */
	pmeg_t	sg_pmeg;		/* the MMU segment number (4c) */
	u_char	sg_npte;		/* number of valid PTEs per seg */
};

#ifdef _KERNEL

TAILQ_HEAD(mmuhd,mmuentry);

/*
 * data appearing in both user and kernel pmaps
 *
 * note: if we want the same binaries to work on the 4/4c and 4m, we have to
 *       include the fields for both to make sure that the struct kproc
 * 	 is the same size.
 */
struct pmap {
	union	ctxinfo *pm_ctx;	/* current context, if any */
	int	pm_ctxnum;		/* current context's number */
	int	pm_refcount;		/* just what it says */

	struct mmuhd	pm_reglist;	/* MMU regions on this pmap (4/4c) */
	struct mmuhd	pm_seglist;	/* MMU segments on this pmap (4/4c) */

	void		*pm_regstore;
	struct regmap	*pm_regmap;

	int		*pm_reg_ptps;	/* SRMMU-edible region table for 4m */
	int		pm_reg_ptps_pa;	/* _Physical_ address of pm_reg_ptps */

	int		pm_gap_start;	/* Starting with this vreg there's */
	int		pm_gap_end;	/* no valid mapping until here */

	struct pmap_statistics	pm_stats;	/* pmap statistics */
};

typedef struct pmap *pmap_t;

#define PMAP_NULL	((pmap_t)0)

extern struct pmap	kernel_pmap_store;

/*
 * Since PTEs also contain type bits, we have to have some way
 * to tell pmap_enter `this is an IO page' or `this is not to
 * be cached'.  Since physical addresses are always aligned, we
 * can do this with the low order bits.
 *
 * The ordering below is important: PMAP_PGTYPE << PG_TNC must give
 * exactly the PG_NC and PG_TYPE bits.
 */
#define	PMAP_OBIO	1		/* tells pmap_enter to use PG_OBIO */
#define	PMAP_VME16	2		/* etc */
#define	PMAP_VME32	3		/* etc */
#define	PMAP_NC		4		/* tells pmap_enter to set PG_NC */
#define	PMAP_TNC_4	7		/* mask to get PG_TYPE & PG_NC */

#define PMAP_T2PTE_4(x)		(((x) & PMAP_TNC_4) << PG_TNC_SHIFT)
#define PMAP_IOENC_4(io)	(io)

/*
 * On a SRMMU machine, the iospace is encoded in bits [3-6] of the
 * physical address passed to pmap_enter().
 */
#define PMAP_TYPE_SRMMU		0x78	/* mask to get 4m page type */
#define PMAP_PTESHFT_SRMMU	25	/* right shift to put type in pte */
#define PMAP_SHFT_SRMMU		3	/* left shift to extract iospace */
#define	PMAP_TNC_SRMMU		127	/* mask to get PG_TYPE & PG_NC */

/*#define PMAP_IOC      0x00800000      -* IO cacheable, NOT shifted */

#define PMAP_T2PTE_SRMMU(x)	(((x) & PMAP_TYPE_SRMMU) << PMAP_PTESHFT_SRMMU)
#define PMAP_IOENC_SRMMU(io)	((io) << PMAP_SHFT_SRMMU)

/* Encode IO space for pmap_enter() */
#define PMAP_IOENC(io)	(CPU_ISSUN4M ? PMAP_IOENC_SRMMU(io) : PMAP_IOENC_4(io))

int             pmap_dumpsize(void);
int             pmap_dumpmmu(int (*)(dev_t, daddr_t, caddr_t, size_t), daddr_t);

#define	pmap_kernel()	(&kernel_pmap_store)
#define	pmap_resident_count(pmap)	((pmap)->pm_stats.resident_count)

#define PMAP_PREFER(fo, ap)		pmap_prefer((fo), (ap))

extern int	cache_alias_dist;
/* pmap prefer alignment */
#define PMAP_PREFER_ALIGN()		cache_alias_dist
/* pmap prefer offset in alignment */
#define PMAP_PREFER_OFFSET(of)						\
	((of) & (cache_alias_dist ? cache_alias_dist - 1 : 0))

#define PMAP_EXCLUDE_DECLS	/* tells MI pmap.h *not* to include decls */

/* FUNCTION DECLARATIONS FOR COMMON PMAP MODULE */

struct proc;
void		pmap_activate(struct proc *);
void		pmap_bootstrap(int nmmu, int nctx, int nregion);
vaddr_t		pmap_prefer(vaddr_t, vaddr_t);
int		pmap_pa_exists(paddr_t);
void		pmap_unwire(pmap_t, vaddr_t);
void		pmap_copy(pmap_t, pmap_t, vaddr_t, vsize_t, vaddr_t);
pmap_t		pmap_create(void);
void		pmap_destroy(pmap_t);
void		pmap_init(void);
void		pmap_kremove(vaddr_t, vsize_t);
vaddr_t		pmap_map(vaddr_t, paddr_t, paddr_t, int);
void		pmap_reference(pmap_t);
void		pmap_release(pmap_t);
void		pmap_remove(pmap_t, vaddr_t, vaddr_t);
void		pmap_remove_holes(struct vmspace *);
void		pmap_virtual_space(vaddr_t *, vaddr_t *);
void		pmap_redzone(void);
void		kvm_setcache(caddr_t, int, int);
#define		kvm_uncache(addr, npages) kvm_setcache(addr, npages, 0)
#define		kvm_recache(addr, npages) kvm_setcache(addr, npages, 1)
void		pmap_cache_enable(void);
struct user;
void		switchexit(struct proc *);
int		mmu_pagein(struct pmap *pm, vaddr_t, int);
void		pmap_writetext(unsigned char *, int);

#define		pmap_collect(pm)		do { /* nothing */ } while (0)
#define		pmap_copy(DP,SP,D,L,S)		do { /* nothing */ } while (0)
#define		pmap_deactivate(p)		do { /* nothing */ } while (0)
#define		pmap_proc_iflush(p,va,len)	do { /* nothing */ } while (0)
#define		pmap_update(pm)			do { /* nothing */ } while (0)

#define		pmap_nested(pm)			0

/* SUN4/SUN4C SPECIFIC DECLARATIONS */

#if defined(SUN4) || defined(SUN4C) || defined(SUN4E)
boolean_t	pmap_clear_modify4_4c(struct vm_page *);
boolean_t	pmap_clear_reference4_4c(struct vm_page *);
int		pmap_enter4_4c(pmap_t, vaddr_t, paddr_t, vm_prot_t, int);
boolean_t	pmap_extract4_4c(pmap_t, vaddr_t, paddr_t *);
boolean_t	pmap_is_modified4_4c(struct vm_page *);
boolean_t	pmap_is_referenced4_4c(struct vm_page *);
void		pmap_kenter_pa4_4c(vaddr_t, paddr_t, vm_prot_t);
void		pmap_page_protect4_4c(struct vm_page *, vm_prot_t);
void		pmap_protect4_4c(pmap_t, vaddr_t, vaddr_t, vm_prot_t);
void		pmap_copy_page4_4c(struct vm_page *, struct vm_page *);
void		pmap_zero_page4_4c(struct vm_page *);
void		pmap_changeprot4_4c(pmap_t, vaddr_t, vm_prot_t, int);
#endif

/* SIMILAR DECLARATIONS FOR SUN4M MODULE */

#if defined(SUN4M)
boolean_t	pmap_clear_modify4m(struct vm_page *);
boolean_t	pmap_clear_reference4m(struct vm_page *);
int		pmap_enter4m(pmap_t, vaddr_t, paddr_t, vm_prot_t, int);
boolean_t	pmap_extract4m(pmap_t, vaddr_t, paddr_t *);
boolean_t	pmap_is_modified4m(struct vm_page *);
boolean_t	pmap_is_referenced4m(struct vm_page *);
void		pmap_kenter_pa4m(vaddr_t, paddr_t, vm_prot_t);
void		pmap_page_protect4m(struct vm_page *, vm_prot_t);
void		pmap_protect4m(pmap_t, vaddr_t, vaddr_t, vm_prot_t);
void		pmap_copy_page4m(struct vm_page *, struct vm_page *);
void		pmap_zero_page4m(struct vm_page *);
void		pmap_changeprot4m(pmap_t, vaddr_t, vm_prot_t, int);
#endif /* defined SUN4M */

#if !(defined(SUN4D) || defined(SUN4M)) && (defined(SUN4) || defined(SUN4C) || defined(SUN4E))

#define		pmap_clear_modify	pmap_clear_modify4_4c
#define		pmap_clear_reference	pmap_clear_reference4_4c
#define		pmap_copy_page		pmap_copy_page4_4c
#define		pmap_enter		pmap_enter4_4c
#define		pmap_extract		pmap_extract4_4c
#define		pmap_is_modified	pmap_is_modified4_4c
#define		pmap_is_referenced	pmap_is_referenced4_4c
#define		pmap_kenter_pa		pmap_kenter_pa4_4c
#define		pmap_page_protect	pmap_page_protect4_4c
#define		pmap_protect		pmap_protect4_4c
#define		pmap_zero_page		pmap_zero_page4_4c
#define		pmap_changeprot		pmap_changeprot4_4c

#elif (defined(SUN4D) || defined(SUN4M)) && !(defined(SUN4) || defined(SUN4C) || defined(SUN4E))

#define	  	pmap_clear_modify	pmap_clear_modify4m
#define		pmap_clear_reference	pmap_clear_reference4m
#define		pmap_copy_page		pmap_copy_page4m
#define		pmap_enter		pmap_enter4m
#define		pmap_extract		pmap_extract4m
#define		pmap_is_modified	pmap_is_modified4m
#define		pmap_is_referenced	pmap_is_referenced4m
#define		pmap_kenter_pa		pmap_kenter_pa4m
#define		pmap_page_protect	pmap_page_protect4m
#define		pmap_protect		pmap_protect4m
#define		pmap_zero_page		pmap_zero_page4m
#define		pmap_changeprot		pmap_changeprot4m

#else  /* must use function pointers */

extern boolean_t	(*pmap_clear_modify_p)(struct vm_page *);
extern boolean_t	(*pmap_clear_reference_p)(struct vm_page *);
extern int		(*pmap_enter_p)(pmap_t, vaddr_t, paddr_t,
					     vm_prot_t, int);
extern boolean_t	(*pmap_extract_p)(pmap_t, vaddr_t, paddr_t *);
extern boolean_t	(*pmap_is_modified_p)(struct vm_page *);
extern boolean_t	(*pmap_is_referenced_p)(struct vm_page *);
extern void		(*pmap_kenter_pa_p)(vaddr_t, paddr_t, vm_prot_t);
extern void		(*pmap_page_protect_p)(struct vm_page *, 
						    vm_prot_t);
extern void		(*pmap_protect_p)(pmap_t, vaddr_t, vaddr_t,
					       vm_prot_t);
extern void		(*pmap_copy_page_p)(struct vm_page *, struct vm_page *);
extern void		(*pmap_zero_page_p)(struct vm_page *);
extern void		(*pmap_changeprot_p)(pmap_t, vaddr_t,
						  vm_prot_t, int);

#define		pmap_clear_modify	(*pmap_clear_modify_p)
#define		pmap_clear_reference	(*pmap_clear_reference_p)
#define		pmap_copy_page		(*pmap_copy_page_p)
#define		pmap_enter		(*pmap_enter_p)
#define		pmap_extract		(*pmap_extract_p)
#define		pmap_is_modified	(*pmap_is_modified_p)
#define		pmap_is_referenced	(*pmap_is_referenced_p)
#define		pmap_kenter_pa		(*pmap_kenter_pa_p)
#define		pmap_page_protect	(*pmap_page_protect_p)
#define		pmap_protect		(*pmap_protect_p)
#define		pmap_zero_page		(*pmap_zero_page_p)
#define		pmap_changeprot		(*pmap_changeprot_p)

#endif

#endif /* _KERNEL */

/*
 * For each managed physical page, there is a list of all currently
 * valid virtual mappings of that page.  Since there is usually one
 * (or zero) mapping per page, the table begins with an initial entry,
 * rather than a pointer; this head entry is empty iff its pv_pmap
 * field is NULL.
 *
 * Note that these are per machine independent page (so there may be
 * only one for every two hardware pages, e.g.).  Since the virtual
 * address is aligned on a page boundary, the low order bits are free
 * for storing flags.  Only the head of each list has flags.
 */

struct pvlist {
	struct		pvlist *pv_next;	/* next pvlist, if any */
	struct		pmap *pv_pmap;		/* pmap of this va */
	vaddr_t		pv_va;			/* virtual address */
	int		pv_flags;		/* flags (below) */
};

struct vm_page_md {
	struct pvlist pv_head;
};

#ifdef _KERNEL

/*
 * Flags in pv_flags.  Note that PV_MOD must be 1 and PV_REF must be 2
 * since they must line up with the bits in the hardware PTEs (see pte.h).
 * SUN4M bits are at a slightly different location in the PTE.
 * Note: the REF, MOD and ANC flag bits occur only in the head of a pvlist.
 * The cacheable bit (either PV_NC or PV_C4M) is meaningful in each
 * individual pv entry.
 */
#define PV_MOD		1	/* page modified */
#define PV_REF		2	/* page referenced */
#define PV_NC		4	/* page cannot be cached */
#define PV_REF4M	1	/* page referenced (SRMMU) */
#define PV_MOD4M	2	/* page modified (SRMMU) */
#define PV_C4M		4	/* page _can_ be cached (SRMMU) */
#define PV_ANC		0x10	/* page has incongruent aliases */

#define VM_MDPAGE_INIT(pg) do {			\
	(pg)->mdpage.pv_head.pv_next = NULL;	\
	(pg)->mdpage.pv_head.pv_pmap = NULL;	\
	(pg)->mdpage.pv_head.pv_va = 0;		\
	(pg)->mdpage.pv_head.pv_flags = 0;	\
} while (0)

#endif /* _KERNEL */

#endif /* _MACHINE_PMAP_H_ */
@


1.60
log
@Define pmap_nested() here too, since we define PMAP_EXCLUDE_DECLS for the sake
of <uvm/uvm_pmap.h>.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.59 2015/03/27 20:25:39 miod Exp $	*/
@


1.59
log
@Lower VM_MIN_KERNEL_ADDRESS by 128MB on non-SRMMU systems (sun4/4c/4e) as well,
in order to give these systems a more reasonable amount of kva, yet still
providing .75GB to userland processes.

Although there is no dependency upon a recent boot loader on non-SRMMU systems,
SMALL_KERNEL will nevertheless stick to the legacy kvm layout, for the time
being.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.58 2015/03/18 20:56:40 miod Exp $	*/
d280 2
@


1.58
log
@Rework the virtual memory layout on SRMMU systems (sun4d/sun4m) to use a much
lower VM_MIN_KERNEL_ADDRESS, since these systems are not crippled by the
Sun-4 MMU hole and have the real 4GB of address space.

Kernels running on Sun-4 MMU are not affected and will still be restricted
to the existing 128MB of kernel space, with 1GB - 128MB of user space.

Kernels running on SRMMU will now provide the low 3GB of address space to
userland, and use the top 1GB for the kernel, except when compiled with
option SMALL_KERNEL, in which case they will keep Sun-4 style the layout
(this is temporary to allow for people to boot bsd.rd to upgrade even when
not running 2.10 boot blocks, and will be removed eventually)

A consequence of this is that the top of the userland stack is no longer at
0xf0000000. But since nothing in userland uses USRSTACK anymore, this should
not be an issue.

Tested on sun4c and various sun4m, with physical memory sizes ranging from 32
to 448MB.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.57 2015/02/15 21:34:33 miod Exp $	*/
d135 2
a136 2
	((unsigned int)(-VM_MIN_KERNEL_ADDRESS_OLD / NBPRG))	/* 8 */
#define NUREG_4C	(256 - NKREG_4C)		      /* 248 */
@


1.57
log
@Change pmap_remove_holes() to take a vmspace instead of a map as its argument.

Use this on vax to correctly pick the end of the stack area now that the
stackgap adjustment code will no longer guarantee it is a fixed location.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.56 2014/12/17 06:05:51 deraadt Exp $	*/
d134 8
a141 2
#define NKREG	((int)((-(unsigned)VM_MIN_KERNEL_ADDRESS) / NBPRG))	/* 8 */
#define NUREG	(256 - NKREG)					      /* 248 */
a188 9

#if 0
struct kvm_cpustate {
	int		kvm_npmemarr;
	struct memarr	kvm_pmemarr[MA_SIZE];
	int		kvm_seginval;			/* [4,4c] */
	struct segmap	kvm_segmap_store[NKREG*NSEGRG];	/* [4,4c] */
}/*not yet used*/;
#endif
@


1.56
log
@delete archaic simplelock use.
ok miod
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.55 2014/10/14 03:23:27 daniel Exp $	*/
d266 1
a266 1
void		pmap_remove_holes(struct vm_map *);
@


1.55
log
@NetBSD revision 1.20 of pmap.h (from 1996) deleted license text that should
not have been removed (per the license conditions).

Revert that removal of the BSD license text and conditions. Special thanks to
Aaron Brown who also provided explicit permission to make this change.

ok schwarze@@, miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.54 2014/01/30 18:16:41 miod Exp $	*/
a164 1
	struct simplelock pm_lock;	/* spinlock */
@


1.54
log
@Move declaration of struct vm_page_md from <machine/vmparam.h> to
<machine/pmap.h> where it belongs, and compensate in <uvm/uvm_extern.h>
by including <uvm/uvm_pmap.h> before <uvm/uvm_page.h>. Tested on all
MACHINE_ARCH but amd64 and i386 (and hppa64).
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.53 2013/06/11 16:42:11 deraadt Exp $	*/
d21 8
a28 1
 * @@InsertRedistribution@@
@


1.53
log
@final removal of daddr64_t.  daddr_t has been 64 bit for a long enough
test period; i think 3 years ago the last bugs fell out.
ok otto beck others
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.52 2011/04/28 20:36:29 ariane Exp $	*/
a177 32
/*
 * For each managed physical page, there is a list of all currently
 * valid virtual mappings of that page.  Since there is usually one
 * (or zero) mapping per page, the table begins with an initial entry,
 * rather than a pointer; this head entry is empty iff its pv_pmap
 * field is NULL.
 *
 * Note that these are per machine independent page (so there may be
 * only one for every two hardware pages, e.g.).  Since the virtual
 * address is aligned on a page boundary, the low order bits are free
 * for storing flags.  Only the head of each list has flags.
 *
 * THIS SHOULD BE PART OF THE CORE MAP
 */
/* XXX - struct pvlist moved to vmparam.h because of include ordering issues */

/*
 * Flags in pv_flags.  Note that PV_MOD must be 1 and PV_REF must be 2
 * since they must line up with the bits in the hardware PTEs (see pte.h).
 * SUN4M bits are at a slightly different location in the PTE.
 * Note: the REF, MOD and ANC flag bits occur only in the head of a pvlist.
 * The cacheable bit (either PV_NC or PV_C4M) is meaningful in each
 * individual pv entry.
 */
#define PV_MOD		1	/* page modified */
#define PV_REF		2	/* page referenced */
#define PV_NC		4	/* page cannot be cached */
#define PV_REF4M	1	/* page referenced (SRMMU) */
#define PV_MOD4M	2	/* page modified (SRMMU) */
#define PV_C4M		4	/* page _can_ be cached (SRMMU) */
#define PV_ANC		0x10	/* page has incongruent aliases */

d375 51
@


1.52
log
@Expose pmap prefer parameters.
Enables future uvm_map code to make intelligent decisions.

No functional change.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.51 2011/03/23 16:54:37 pirofti Exp $	*/
d259 1
a259 1
int             pmap_dumpmmu(int (*)(dev_t, daddr64_t, caddr_t, size_t), daddr64_t);
@


1.51
log
@Normalize sentinel. Use _MACHINE_*_H_ and _<ARCH>_*_H_ properly and consitently.

Discussed and okay drahn@@. Okay deraadt@@.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.50 2010/12/26 15:41:00 miod Exp $	*/
d265 7
@


1.50
log
@Kill pmap_phys_address(), and force every driver's mmap() routine to return
a physical address [more precisely, something suitable to pass to pmap_enter()'sphysical address argument].

This allows MI drivers to implement mmap() routines without having to know
about the pmap_phys_address() implementation and #ifdef obfuscation.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.49 2010/12/06 20:57:18 miod Exp $	*/
d47 2
a48 2
#ifndef	_SPARC_PMAP_H_
#define _SPARC_PMAP_H_
d403 1
a403 1
#endif /* _SPARC_PMAP_H_ */
@


1.49
log
@Change the signature of PMAP_PREFER from void PMAP_PREFER(..., vaddr_t *) to
vaddr_t PMAP_PREFER(..., vaddr_t). This allows better compiler optimization
when the function is inlined, and avoids accessing memory on architectures
when we can pass function arguments in registers.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.48 2010/07/10 19:32:24 miod Exp $	*/
a299 1
#define		pmap_phys_address(frame)	(frame)
@


1.48
log
@sun4e (i.e. SPARCengine 1e) support. This platform is a mix between sun4 and
sun4c, as it has a sun4c OpenPROM but a sun4 8KB pagesize. VME devices are
not supported yet.
ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.47 2010/06/29 21:26:09 miod Exp $	*/
d273 1
a273 1
void		pmap_prefer(vaddr_t, vaddr_t *);
@


1.47
log
@There is absolutely no need to double map DVMA addresses into the kernel address
space on SRMMU systems (i.e. sun4m), so don't do it anymore and update
misleading comments.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.46 2010/06/06 10:04:33 miod Exp $	*/
d306 1
a306 1
#if defined(SUN4) || defined(SUN4C)
d338 1
a338 1
#if !defined(SUN4M) && (defined(SUN4) || defined(SUN4C))
d353 1
a353 1
#elif defined(SUN4M) && !(defined(SUN4) || defined(SUN4C))
@


1.46
log
@typo in comment
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.45 2009/02/12 18:52:15 miod Exp $	*/
d61 2
a62 2
 * some of this is not actually used).  Kernel space, including DVMA
 * space (for now?), is mapped identically into all user contexts.
d75 2
a76 2
 * requires 3584 segments, while the kernel (including DVMA) requires
 * only 512 segments.
@


1.45
log
@Keep track of resident pages in pm_stats, and use this to implement a real
pmap_resident_count(). From NetBSD
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.44 2008/03/22 20:52:32 jasper Exp $	*/
d122 1
a122 1
 * of tables is similar to those used for the Sun4/100's 3-level MMU; it
@


1.44
log
@- remove pre-uvm prototype of pmap_page_index()

ok miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.43 2007/12/15 17:24:07 deraadt Exp $	*/
d262 1
a262 1
#define	pmap_resident_count(pmap)	pmap_count_ptes(pmap)
a272 1
int		pmap_count_ptes(struct pmap *);
@


1.43
log
@Remove a lot of symbols from the namespace, otherwise sys/sysctl.h and
rpc/pmap_prot.h collide.. "struct pmap" from the kernel should not make
it out to userland.
ok miod
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.42 2007/09/10 18:49:45 miod Exp $	*/
a286 1
int		pmap_page_index(paddr_t);
@


1.42
log
@Introduce a md pmap hook, pmap_remove_holes(), which is supposed to mark
the holes a MMU may have from a given vm_map. This will be automagically
invoked for newly created vmspaces.

On platforms with MMU holes (e.g. sun4, sun4c and vax), this prevents
mmap(2) hints which would end up being in the hole to be accepted as valid,
causing unexpected signals when the process tries to access the hole
(since pmap can not fill the hole anyway).

Unfortunately, the logic mmap() uses to pick a valid address for anonymous
mappings needs work, as it will only try to find an address higher than the
hint, which causes all mmap() with a hint in the hole to fail on vax. This
will be improved later.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.41 2007/06/06 17:15:12 deraadt Exp $	*/
d130 16
a175 14
struct regmap {
	struct segmap	*rg_segmap;	/* point to NSGPRG PMEGs */
	int		*rg_seg_ptps; 	/* SRMMU-edible segment tables (NULL
					 * indicates invalid region (4m) */
	smeg_t		rg_smeg;	/* the MMU region number (4c) */
	u_char		rg_nsegmap;	/* number of valid PMEGS */
};

struct segmap {
	int	*sg_pte;		/* points to NPTESG PTEs */
	pmeg_t	sg_pmeg;		/* the MMU segment number (4c) */
	u_char	sg_npte;		/* number of valid PTEs per seg */
};

a217 2

#ifdef _KERNEL
@


1.41
log
@now that all partition size/offsets are potentially 64-bit, change the
type of all variables to daddr64_t.  this includes the APIs for XXsize()
and XXdump(), all range checks inside bio drivers, internal variables
for disklabel handling, and even uvm's swap offsets.  re-read numerous
times by otto, miod, krw, thib to look for errors
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.40 2005/04/17 18:47:48 miod Exp $	*/
d286 1
@


1.40
log
@Do not use KERNBASE when VM_MIN_KERNEL_ADDRESS or VM_MAXUSER_ADDRESS are
implied; this currently does not change anything (yet).

Also, define the I/O space range in <machine/vmparam.h> rather than in
<sparc/sparc/vaddrs.h>.

ok deraadt@@ mickey@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.39 2005/04/04 23:40:02 miod Exp $	*/
d259 1
a259 1
int             pmap_dumpmmu(int (*)(dev_t, daddr_t, caddr_t, size_t), daddr_t);
@


1.39
log
@Nuke pmap_bootstrap_alloc(), not used anymore.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.38 2005/04/03 10:36:10 miod Exp $	*/
d127 2
a128 2
#define NKREG	((int)((-(unsigned)KERNBASE) / NBPRG))	/* i.e., 8 */
#define NUREG	(256 - NKREG)				/* i.e., 248 */
@


1.38
log
@Simple performance improvements:
- inline empty pmap_deactivate() and pmap_collect().
- inline pmap_phys_address().
- provide a real pmap_kremove() implementation, rather than invoking
  pmap_remove() on behalf of pmap_kernel().
- do not check for the MMU hole in pmap_prefer() for SUN4M-only kernels.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.37 2004/05/20 09:20:41 kettenis Exp $	*/
a275 1
void		*pmap_bootstrap_alloc(int);
a285 1
void		pmap_init(void);
@


1.37
log
@Properly flush instruction cache for ptrace(PT_WRTIE_{DI}, ...) on powerpc
and m68k.
ok drahn@@, millert@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.36 2003/11/14 19:05:36 miod Exp $	*/
a271 1
void		pmap_deactivate(struct proc *);
a277 1
void		pmap_collect(pmap_t);
d282 1
a283 2
vaddr_t		pmap_phys_address(int);
void		pmap_pinit(pmap_t);
d300 6
a305 4
#define		pmap_update(pm)		/* nothing */
#define		pmap_copy(DP,SP,D,L,S)	/* nothing */

#define		pmap_proc_iflush(p,va,len)	/* nothing */
a316 1
void		pmap_kremove4_4c(vaddr_t, vsize_t);
a333 1
void		pmap_kremove4m(vaddr_t, vsize_t);
a350 1
#define		pmap_kremove		pmap_kremove4_4c
a365 1
#define		pmap_kremove		pmap_kremove4m
a380 1
extern void		(*pmap_kremove_p)(vaddr_t, vsize_t);
a397 1
#define		pmap_kremove		(*pmap_kremove_p)
@


1.36
log
@the the; rohee@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.35 2003/01/24 00:51:54 miod Exp $	*/
d305 2
@


1.35
log
@PMAP_{DE,}ACTIVATE are not used anymore.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.34 2002/10/28 19:30:21 art Exp $	*/
d105 1
a105 1
 * `stolen' out of the the MMU, we just keep all its PTEs there, and
@


1.34
log
@Convert sparc pmap from physseg to VM_PAGE_MD.
This allows us to remove some ambiguities on how some functions are called,
remove some diagnostic checks for conditions that can never happen and
remove the ugly hack with "pmap_initialized". It also removes some unnecessary
overhead in time-critical functions like pmap_{zero,copy}_page and
pmap_{is,clear}_{mod*,ref*}.

miod@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.33 2002/09/10 18:29:43 art Exp $	*/
a263 2
#define PMAP_ACTIVATE(pmap, pcb, iscurproc)
#define PMAP_DEACTIVATE(pmap, pcb)
@


1.33
log
@Change the pmap_zero_page and pmap_copy_page API to take the struct vm_page *
instead of the pa. Most callers already had it handy and those who didn't
only called it for managed pages and were outside time-critical code.

This will allow us to make those functions clean and fast on sparc and
sparc64 letting us to avoid unnecessary cache flushes.

deraadt@@ miod@@ drahn@@ ok.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.32 2002/03/14 03:16:00 millert Exp $	*/
d190 1
a190 6
struct pvlist {
	struct		pvlist *pv_next;	/* next pvlist, if any */
	struct		pmap *pv_pmap;		/* pmap of this va */
	vaddr_t		pv_va;			/* virtual address */
	int		pv_flags;		/* flags (below) */
};
@


1.32
log
@Final __P removal plus some cosmetic fixups
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.31 2002/03/14 01:26:43 millert Exp $	*/
a317 1
void		pmap_copy_page4_4c(paddr_t, paddr_t);
d326 2
a327 1
void		pmap_zero_page4_4c(paddr_t);
a335 1
void		pmap_copy_page4m(paddr_t, paddr_t);
d344 2
a345 1
void		pmap_zero_page4m(paddr_t);
a384 1
extern void		(*pmap_copy_page_p)(paddr_t, paddr_t);
d396 2
a397 1
extern void		(*pmap_zero_page_p)(paddr_t);
@


1.31
log
@First round of __P removal in sys
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.30 2001/12/19 08:58:05 art Exp $	*/
d264 1
a264 2
int             pmap_dumpmmu __P((int (*)(dev_t, daddr_t, caddr_t, size_t),
                                 daddr_t));
@


1.30
log
@UBC was a disaster. It worked very good when it worked, but on some
machines or some configurations or in some phase of the moon (we actually
don't know when or why) files disappeared. Since we've not been able to
track down the problem in two weeks intense debugging and we need -current
to be stable, back out everything to a state it had before UBC.

We apologise for the inconvenience.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.29 2001/12/07 10:52:25 art Exp $	*/
d263 2
a264 2
int             pmap_dumpsize __P((void));
int             pmap_dumpmmu __P((int (*)__P((dev_t, daddr_t, caddr_t, size_t)),
d279 24
a302 24
void		pmap_activate __P((struct proc *));
void		pmap_deactivate __P((struct proc *));
void		pmap_bootstrap __P((int nmmu, int nctx, int nregion));
int		pmap_count_ptes __P((struct pmap *));
void		pmap_prefer __P((vaddr_t, vaddr_t *));
int		pmap_pa_exists __P((paddr_t));
void		*pmap_bootstrap_alloc __P((int));
void		pmap_unwire __P((pmap_t, vaddr_t));
void		pmap_collect __P((pmap_t));
void		pmap_copy __P((pmap_t, pmap_t, vaddr_t, vsize_t, vaddr_t));
pmap_t		pmap_create __P((void));
void		pmap_destroy __P((pmap_t));
void		pmap_init __P((void));
vaddr_t		pmap_map __P((vaddr_t, paddr_t, paddr_t, int));
vaddr_t		pmap_phys_address __P((int));
void		pmap_pinit __P((pmap_t));
void		pmap_reference __P((pmap_t));
void		pmap_release __P((pmap_t));
void		pmap_remove __P((pmap_t, vaddr_t, vaddr_t));
void		pmap_init __P((void));
int		pmap_page_index __P((paddr_t));
void		pmap_virtual_space __P((vaddr_t *, vaddr_t *));
void		pmap_redzone __P((void));
void		kvm_setcache __P((caddr_t, int, int));
d305 1
a305 1
void		pmap_cache_enable __P((void));
d307 3
a309 3
void		switchexit __P((struct proc *));
int		mmu_pagein __P((struct pmap *pm, vaddr_t, int));
void		pmap_writetext __P((unsigned char *, int));
d317 13
a329 13
boolean_t	pmap_clear_modify4_4c __P((struct vm_page *));
boolean_t	pmap_clear_reference4_4c __P((struct vm_page *));
void		pmap_copy_page4_4c __P((paddr_t, paddr_t));
int		pmap_enter4_4c __P((pmap_t, vaddr_t, paddr_t, vm_prot_t, int));
boolean_t	pmap_extract4_4c __P((pmap_t, vaddr_t, paddr_t *));
boolean_t	pmap_is_modified4_4c __P((struct vm_page *));
boolean_t	pmap_is_referenced4_4c __P((struct vm_page *));
void		pmap_kenter_pa4_4c __P((vaddr_t, paddr_t, vm_prot_t));
void		pmap_kremove4_4c __P((vaddr_t, vsize_t));
void		pmap_page_protect4_4c __P((struct vm_page *, vm_prot_t));
void		pmap_protect4_4c __P((pmap_t, vaddr_t, vaddr_t, vm_prot_t));
void		pmap_zero_page4_4c __P((paddr_t));
void		pmap_changeprot4_4c __P((pmap_t, vaddr_t, vm_prot_t, int));
d335 13
a347 13
boolean_t	pmap_clear_modify4m __P((struct vm_page *));
boolean_t	pmap_clear_reference4m __P((struct vm_page *));
void		pmap_copy_page4m __P((paddr_t, paddr_t));
int		pmap_enter4m __P((pmap_t, vaddr_t, paddr_t, vm_prot_t, int));
boolean_t	pmap_extract4m __P((pmap_t, vaddr_t, paddr_t *));
boolean_t	pmap_is_modified4m __P((struct vm_page *));
boolean_t	pmap_is_referenced4m __P((struct vm_page *));
void		pmap_kenter_pa4m __P((vaddr_t, paddr_t, vm_prot_t));
void		pmap_kremove4m __P((vaddr_t, vsize_t));
void		pmap_page_protect4m __P((struct vm_page *, vm_prot_t));
void		pmap_protect4m __P((pmap_t, vaddr_t, vaddr_t, vm_prot_t));
void		pmap_zero_page4m __P((paddr_t));
void		pmap_changeprot4m __P((pmap_t, vaddr_t, vm_prot_t, int));
d384 17
a400 17
extern boolean_t	(*pmap_clear_modify_p) __P((struct vm_page *));
extern boolean_t	(*pmap_clear_reference_p) __P((struct vm_page *));
extern void		(*pmap_copy_page_p) __P((paddr_t, paddr_t));
extern int		(*pmap_enter_p) __P((pmap_t, vaddr_t, paddr_t,
					     vm_prot_t, int));
extern boolean_t	(*pmap_extract_p) __P((pmap_t, vaddr_t, paddr_t *));
extern boolean_t	(*pmap_is_modified_p) __P((struct vm_page *));
extern boolean_t	(*pmap_is_referenced_p) __P((struct vm_page *));
extern void		(*pmap_kenter_pa_p) __P((vaddr_t, paddr_t, vm_prot_t));
extern void		(*pmap_kremove_p) __P((vaddr_t, vsize_t));
extern void		(*pmap_page_protect_p) __P((struct vm_page *, 
						    vm_prot_t));
extern void		(*pmap_protect_p) __P((pmap_t, vaddr_t, vaddr_t,
					       vm_prot_t));
extern void		(*pmap_zero_page_p) __P((paddr_t));
extern void		(*pmap_changeprot_p) __P((pmap_t, vaddr_t,
						  vm_prot_t, int));
@


1.29
log
@kvm_recache is now unnecessary, simplify.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.28 2001/12/07 10:44:51 art Exp $	*/
a297 1
#define		pmap_update(pm)	/* nothing */
d302 4
a305 1
void		kvm_uncache __P((caddr_t, int));
d310 3
@


1.29.2.1
log
@Sync UBC branch to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.29 2001/12/07 10:52:25 art Exp $	*/
d263 3
a265 2
int             pmap_dumpsize(void);
int             pmap_dumpmmu(int (*)(dev_t, daddr_t, caddr_t, size_t), daddr_t);
d279 19
a297 19
void		pmap_activate(struct proc *);
void		pmap_deactivate(struct proc *);
void		pmap_bootstrap(int nmmu, int nctx, int nregion);
int		pmap_count_ptes(struct pmap *);
void		pmap_prefer(vaddr_t, vaddr_t *);
int		pmap_pa_exists(paddr_t);
void		*pmap_bootstrap_alloc(int);
void		pmap_unwire(pmap_t, vaddr_t);
void		pmap_collect(pmap_t);
void		pmap_copy(pmap_t, pmap_t, vaddr_t, vsize_t, vaddr_t);
pmap_t		pmap_create(void);
void		pmap_destroy(pmap_t);
void		pmap_init(void);
vaddr_t		pmap_map(vaddr_t, paddr_t, paddr_t, int);
vaddr_t		pmap_phys_address(int);
void		pmap_pinit(pmap_t);
void		pmap_reference(pmap_t);
void		pmap_release(pmap_t);
void		pmap_remove(pmap_t, vaddr_t, vaddr_t);
d299 5
a303 5
void		pmap_init(void);
int		pmap_page_index(paddr_t);
void		pmap_virtual_space(vaddr_t *, vaddr_t *);
void		pmap_redzone(void);
void		kvm_uncache(caddr_t, int);
d305 3
a307 3
void		switchexit(struct proc *);
int		mmu_pagein(struct pmap *pm, vaddr_t, int);
void		pmap_writetext(unsigned char *, int);
d312 13
a324 13
boolean_t	pmap_clear_modify4_4c(struct vm_page *);
boolean_t	pmap_clear_reference4_4c(struct vm_page *);
void		pmap_copy_page4_4c(paddr_t, paddr_t);
int		pmap_enter4_4c(pmap_t, vaddr_t, paddr_t, vm_prot_t, int);
boolean_t	pmap_extract4_4c(pmap_t, vaddr_t, paddr_t *);
boolean_t	pmap_is_modified4_4c(struct vm_page *);
boolean_t	pmap_is_referenced4_4c(struct vm_page *);
void		pmap_kenter_pa4_4c(vaddr_t, paddr_t, vm_prot_t);
void		pmap_kremove4_4c(vaddr_t, vsize_t);
void		pmap_page_protect4_4c(struct vm_page *, vm_prot_t);
void		pmap_protect4_4c(pmap_t, vaddr_t, vaddr_t, vm_prot_t);
void		pmap_zero_page4_4c(paddr_t);
void		pmap_changeprot4_4c(pmap_t, vaddr_t, vm_prot_t, int);
d330 13
a342 13
boolean_t	pmap_clear_modify4m(struct vm_page *);
boolean_t	pmap_clear_reference4m(struct vm_page *);
void		pmap_copy_page4m(paddr_t, paddr_t);
int		pmap_enter4m(pmap_t, vaddr_t, paddr_t, vm_prot_t, int);
boolean_t	pmap_extract4m(pmap_t, vaddr_t, paddr_t *);
boolean_t	pmap_is_modified4m(struct vm_page *);
boolean_t	pmap_is_referenced4m(struct vm_page *);
void		pmap_kenter_pa4m(vaddr_t, paddr_t, vm_prot_t);
void		pmap_kremove4m(vaddr_t, vsize_t);
void		pmap_page_protect4m(struct vm_page *, vm_prot_t);
void		pmap_protect4m(pmap_t, vaddr_t, vaddr_t, vm_prot_t);
void		pmap_zero_page4m(paddr_t);
void		pmap_changeprot4m(pmap_t, vaddr_t, vm_prot_t, int);
d379 17
a395 17
extern boolean_t	(*pmap_clear_modify_p)(struct vm_page *);
extern boolean_t	(*pmap_clear_reference_p)(struct vm_page *);
extern void		(*pmap_copy_page_p)(paddr_t, paddr_t);
extern int		(*pmap_enter_p)(pmap_t, vaddr_t, paddr_t,
					     vm_prot_t, int);
extern boolean_t	(*pmap_extract_p)(pmap_t, vaddr_t, paddr_t *);
extern boolean_t	(*pmap_is_modified_p)(struct vm_page *);
extern boolean_t	(*pmap_is_referenced_p)(struct vm_page *);
extern void		(*pmap_kenter_pa_p)(vaddr_t, paddr_t, vm_prot_t);
extern void		(*pmap_kremove_p)(vaddr_t, vsize_t);
extern void		(*pmap_page_protect_p)(struct vm_page *, 
						    vm_prot_t);
extern void		(*pmap_protect_p)(pmap_t, vaddr_t, vaddr_t,
					       vm_prot_t);
extern void		(*pmap_zero_page_p)(paddr_t);
extern void		(*pmap_changeprot_p)(pmap_t, vaddr_t,
						  vm_prot_t, int);
@


1.29.2.2
log
@sync to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.29.2.1 2002/06/11 03:38:16 art Exp $	*/
d190 6
a195 1
/* XXX - struct pvlist moved to vmparam.h because of include ordering issues */
d313 1
d322 1
a322 2
void		pmap_copy_page4_4c(struct vm_page *, struct vm_page *);
void		pmap_zero_page4_4c(struct vm_page *);
d331 1
d340 1
a340 2
void		pmap_copy_page4m(struct vm_page *, struct vm_page *);
void		pmap_zero_page4m(struct vm_page *);
d380 1
d392 1
a392 2
extern void		(*pmap_copy_page_p)(struct vm_page *, struct vm_page *);
extern void		(*pmap_zero_page_p)(struct vm_page *);
@


1.29.2.3
log
@sync
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d264 2
@


1.28
log
@Remove pmap_cache_enable. it was a mistake.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.27 2001/12/07 10:35:33 art Exp $	*/
d303 1
a303 3
void		kvm_setcache __P((caddr_t, int, int));
#define		kvm_uncache(addr, npages) kvm_setcache(addr, npages, 0)
#define		kvm_recache(addr, npages) kvm_setcache(addr, npages, 1)
@


1.27
log
@Remove pmap_kenter_pgs leftovers.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.26 2001/12/04 23:22:42 art Exp $	*/
a305 1
void		pmap_cache_enable __P((void));
@


1.26
log
@Yet another sync to NetBSD uvm.
Today we add a pmap argument to pmap_update() and allocate map entries for
kernel_map from kmem_map instead of using the static entries. This should
get rid of MAX_KMAPENT panics. Also some uvm_loan problems are fixed.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.25 2001/11/28 15:34:16 art Exp $	*/
a322 1
void		pmap_kenter_pgs4_4c __P((vaddr_t, struct vm_page **, int));
a340 1
void		pmap_kenter_pgs4m __P((vaddr_t, struct vm_page **, int));
a390 2
extern void		(*pmap_kenter_pgs_p) __P((vaddr_t, struct vm_page **,
						  int));
@


1.25
log
@Make pmap_update functions into nops so that we can have a consistent
pmap_update API (right now it's nop).
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.24 2001/11/28 14:13:06 art Exp $	*/
d298 1
a298 1
#define		pmap_update()	/* nothing */
@


1.24
log
@pmap_kenter_pgs is not used and not really useful. remove.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.23 2001/08/19 15:36:27 art Exp $	*/
d298 1
a298 1
void		pmap_update __P((void));
@


1.23
log
@Ooops. sparc always needs own protos.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.21 2001/07/25 13:25:33 art Exp $	*/
a359 1
#define		pmap_kenter_pgs		pmap_kenter_pgs4_4c
a375 1
#define		pmap_kenter_pgs		pmap_kenter_pgs4m
a411 1
#define		pmap_kenter_pgs		(*pmap_kenter_pgs_p)
@


1.22
log
@Move pmap_{de,}activate to vm/pmap.h, it's same on all archs.
@
text
@d279 2
@


1.21
log
@Change the pmap_enter interface to merge access_type and the wired boolean
and arbitrary flags into one argument.

One new flag is PMAP_CANFAIL that tells pmap_enter that it can fail if there
are not enough resources to satisfy the request. If this flag is not passed,
pmap_enter should panic as it should have done before this change (XXX - many
pmaps are still not doing that).

Only i386 and alpha implement CANFAIL for now.

Includes uvm updates from NetBSD.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.20 2001/06/27 18:30:30 art Exp $	*/
a278 2
void		pmap_activate __P((struct proc *));
void		pmap_deactivate __P((struct proc *));
@


1.20
log
@PMAP_NEW is no longer an option on sparc.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.19 2001/06/10 01:45:03 deraadt Exp $	*/
d318 1
a318 2
void		pmap_enter4_4c __P((pmap_t, vaddr_t, paddr_t, vm_prot_t,
				    boolean_t, vm_prot_t));
d337 1
a337 2
void		pmap_enter4m __P((pmap_t, vaddr_t, paddr_t, vm_prot_t,
				  boolean_t, vm_prot_t));
d389 2
a390 2
extern void		(*pmap_enter_p) __P((pmap_t, vaddr_t, paddr_t,
					     vm_prot_t, boolean_t, vm_prot_t));
@


1.19
log
@Art error #2
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.18 2001/06/08 08:09:26 art Exp $	*/
a288 1
#ifdef PMAP_NEW
a289 3
#else
pmap_t		pmap_create __P((vsize_t));
#endif
a314 1
#ifdef PMAP_NEW
a316 4
#else
void		pmap_clear_modify4_4c __P((paddr_t pa));
void		pmap_clear_reference4_4c __P((paddr_t pa));
#endif
a320 1
#ifdef PMAP_NEW
a326 5
#else
boolean_t	pmap_is_modified4_4c __P((paddr_t pa));
boolean_t	pmap_is_referenced4_4c __P((paddr_t pa));
void		pmap_page_protect4_4c __P((paddr_t, vm_prot_t));
#endif
a334 1
#ifdef PMAP_NEW
a336 4
#else
void		pmap_clear_modify4m __P((paddr_t pa));
void		pmap_clear_reference4m __P((paddr_t pa));
#endif
a340 1
#ifdef PMAP_NEW
a346 5
#else
boolean_t	pmap_is_modified4m __P((paddr_t pa));
boolean_t	pmap_is_referenced4m __P((paddr_t pa));
void		pmap_page_protect4m __P((paddr_t, vm_prot_t));
#endif
a387 1
#ifdef PMAP_NEW
a389 4
#else
extern void		(*pmap_clear_modify_p) __P((paddr_t pa));
extern void		(*pmap_clear_reference_p) __P((paddr_t pa));
#endif
a393 1
#ifdef PMAP_NEW
a401 5
#else
extern boolean_t	(*pmap_is_modified_p) __P((paddr_t pa));
extern boolean_t	(*pmap_is_referenced_p) __P((paddr_t pa));
extern void		(*pmap_page_protect_p) __P((paddr_t, vm_prot_t));
#endif
@


1.18
log
@Change the paddr_t pmap_extract(struct pmap *, vaddr_t) interface to
boolean_t pmap_extract(struct pmap *, vaddr_t, paddr_t *).
Matches NetBSD. Tested by various people on various platforms.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.17 2001/05/09 15:31:27 art Exp $	*/
d329 1
a329 1
paddr_t		pmap_extract4_4c __P((pmap_t, vaddr_t));
d360 1
a360 1
paddr_t		pmap_extract4m __P((pmap_t, vaddr_t));
@


1.17
log
@More sync to NetBSD.

 - Change pmap_change_wiring to pmap_unwire because it's only called that way.
 - Remove pmap_pageable because it's seldom implemented and when it is, it's
   either almost useless or incorrect. The same information is already passed
   to the pmap anyway by pmap_enter and pmap_unwire.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.16 2000/06/05 11:02:52 art Exp $	*/
d424 1
a424 1
extern paddr_t		(*pmap_extract_p) __P((pmap_t, vaddr_t));
@


1.16
log
@Changes to exit handling.

cpu_exit no longer frees the vmspace and u-area. This is now handled by a
separate kernel thread "reaper". This is to avoid sleeping locks in the
critical path of cpu_exit where we're not allowed to sleep.

From NetBSD
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.15 1999/12/09 21:35:28 art Exp $	*/
d286 1
a286 1
void		pmap_change_wiring __P((pmap_t, vaddr_t, boolean_t));
a296 1
void		pmap_pageable __P((pmap_t, paddr_t, paddr_t, boolean_t));
@


1.15
log
@Fix a bug we've had for ages.
On some sun4m the pagetables must be uncached. This is indicated by the
CPUFLG_CACHEPAGETABLES in cpuinfo.flags. This was done in pmap_bootstrap4m.
The problem is that the CPUFLG_CACHEPAGETABLES is not set until after
pmap_bootstrap4m, so even the machines that could cache the pagetables
had them uncached, reducing performance.
Fix this by creating pmap_cache_enable that is called just after the
cache has been switched on (XXX - actually, we should call it before, but
CPUFLG_CACHEPAGETABLES can be set in the code that enables the cache).
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.14 1999/12/09 16:11:48 art Exp $	*/
d313 1
a313 1
void		switchexit __P((vm_map_t, struct user *, int));
@


1.15.2.1
log
@Continue the aborted merge of current just before 2.9 was cut into the
SMP branch.  Note that this will not make any progress of SMP functionality,
it is just merging of new code from the trunk into the old branch.
Please do not ask me questions about SMP status because of this mail,
instead go read the archives of smp@@openbsd.org, where I mailed about
these commits some week ago.  Another note: I am doing this in chunks now,
so as to not lock too much of the tree for long times
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.16 2000/06/05 11:02:52 art Exp $	*/
d313 1
a313 1
void		switchexit __P((struct proc *));
@


1.15.2.2
log
@Merge in -current from two days ago in the SMP branch.
As usual with merges, they do not indicate progress, so do not hold
your breath for working SMP, and do not mail me and ask about the
state of it.  It has not changed.  There is work ongoing, but very, very
slowly.  The commit is done in parts as to not lock up the tree in too
big chunks at a time.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.15.2.1 2001/05/14 21:37:13 niklas Exp $	*/
d286 1
a286 1
void		pmap_unwire __P((pmap_t, vaddr_t));
d289 1
d291 3
d297 1
d320 1
d323 4
d330 2
a331 1
boolean_t	pmap_extract4_4c __P((pmap_t, vaddr_t, paddr_t *));
d338 5
d351 1
d354 4
d361 2
a362 1
boolean_t	pmap_extract4m __P((pmap_t, vaddr_t, paddr_t *));
d369 5
d415 1
d418 4
d425 2
a426 1
extern boolean_t	(*pmap_extract_p) __P((pmap_t, vaddr_t, paddr_t *));
d435 5
@


1.15.2.3
log
@Sync the SMP branch to something just after 3.0
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.15.2.2 2001/07/04 10:23:32 niklas Exp $	*/
d318 2
a319 1
int		pmap_enter4_4c __P((pmap_t, vaddr_t, paddr_t, vm_prot_t, int));
d338 2
a339 1
int		pmap_enter4m __P((pmap_t, vaddr_t, paddr_t, vm_prot_t, int));
d391 2
a392 2
extern int		(*pmap_enter_p) __P((pmap_t, vaddr_t, paddr_t,
					     vm_prot_t, int));
@


1.15.2.4
log
@Merge in -current
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.15.2.3 2001/10/31 03:07:57 nate Exp $	*/
d298 1
a298 1
#define		pmap_update()	/* nothing */
d360 1
d377 1
d414 1
@


1.15.2.5
log
@Merge in trunk
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d298 1
a311 3
#define		pmap_update(pm)		/* nothing */
#define		pmap_copy(DP,SP,D,L,S)	/* nothing */

d323 1
d342 1
d393 2
@


1.15.2.6
log
@Merge in -current from about a week ago
@
text
@d263 3
a265 2
int             pmap_dumpsize(void);
int             pmap_dumpmmu(int (*)(dev_t, daddr_t, caddr_t, size_t), daddr_t);
d279 24
a302 24
void		pmap_activate(struct proc *);
void		pmap_deactivate(struct proc *);
void		pmap_bootstrap(int nmmu, int nctx, int nregion);
int		pmap_count_ptes(struct pmap *);
void		pmap_prefer(vaddr_t, vaddr_t *);
int		pmap_pa_exists(paddr_t);
void		*pmap_bootstrap_alloc(int);
void		pmap_unwire(pmap_t, vaddr_t);
void		pmap_collect(pmap_t);
void		pmap_copy(pmap_t, pmap_t, vaddr_t, vsize_t, vaddr_t);
pmap_t		pmap_create(void);
void		pmap_destroy(pmap_t);
void		pmap_init(void);
vaddr_t		pmap_map(vaddr_t, paddr_t, paddr_t, int);
vaddr_t		pmap_phys_address(int);
void		pmap_pinit(pmap_t);
void		pmap_reference(pmap_t);
void		pmap_release(pmap_t);
void		pmap_remove(pmap_t, vaddr_t, vaddr_t);
void		pmap_init(void);
int		pmap_page_index(paddr_t);
void		pmap_virtual_space(vaddr_t *, vaddr_t *);
void		pmap_redzone(void);
void		kvm_setcache(caddr_t, int, int);
d305 1
a305 1
void		pmap_cache_enable(void);
d307 3
a309 3
void		switchexit(struct proc *);
int		mmu_pagein(struct pmap *pm, vaddr_t, int);
void		pmap_writetext(unsigned char *, int);
d317 13
a329 13
boolean_t	pmap_clear_modify4_4c(struct vm_page *);
boolean_t	pmap_clear_reference4_4c(struct vm_page *);
void		pmap_copy_page4_4c(paddr_t, paddr_t);
int		pmap_enter4_4c(pmap_t, vaddr_t, paddr_t, vm_prot_t, int);
boolean_t	pmap_extract4_4c(pmap_t, vaddr_t, paddr_t *);
boolean_t	pmap_is_modified4_4c(struct vm_page *);
boolean_t	pmap_is_referenced4_4c(struct vm_page *);
void		pmap_kenter_pa4_4c(vaddr_t, paddr_t, vm_prot_t);
void		pmap_kremove4_4c(vaddr_t, vsize_t);
void		pmap_page_protect4_4c(struct vm_page *, vm_prot_t);
void		pmap_protect4_4c(pmap_t, vaddr_t, vaddr_t, vm_prot_t);
void		pmap_zero_page4_4c(paddr_t);
void		pmap_changeprot4_4c(pmap_t, vaddr_t, vm_prot_t, int);
d335 13
a347 13
boolean_t	pmap_clear_modify4m(struct vm_page *);
boolean_t	pmap_clear_reference4m(struct vm_page *);
void		pmap_copy_page4m(paddr_t, paddr_t);
int		pmap_enter4m(pmap_t, vaddr_t, paddr_t, vm_prot_t, int);
boolean_t	pmap_extract4m(pmap_t, vaddr_t, paddr_t *);
boolean_t	pmap_is_modified4m(struct vm_page *);
boolean_t	pmap_is_referenced4m(struct vm_page *);
void		pmap_kenter_pa4m(vaddr_t, paddr_t, vm_prot_t);
void		pmap_kremove4m(vaddr_t, vsize_t);
void		pmap_page_protect4m(struct vm_page *, vm_prot_t);
void		pmap_protect4m(pmap_t, vaddr_t, vaddr_t, vm_prot_t);
void		pmap_zero_page4m(paddr_t);
void		pmap_changeprot4m(pmap_t, vaddr_t, vm_prot_t, int);
d384 17
a400 17
extern boolean_t	(*pmap_clear_modify_p)(struct vm_page *);
extern boolean_t	(*pmap_clear_reference_p)(struct vm_page *);
extern void		(*pmap_copy_page_p)(paddr_t, paddr_t);
extern int		(*pmap_enter_p)(pmap_t, vaddr_t, paddr_t,
					     vm_prot_t, int);
extern boolean_t	(*pmap_extract_p)(pmap_t, vaddr_t, paddr_t *);
extern boolean_t	(*pmap_is_modified_p)(struct vm_page *);
extern boolean_t	(*pmap_is_referenced_p)(struct vm_page *);
extern void		(*pmap_kenter_pa_p)(vaddr_t, paddr_t, vm_prot_t);
extern void		(*pmap_kremove_p)(vaddr_t, vsize_t);
extern void		(*pmap_page_protect_p)(struct vm_page *, 
						    vm_prot_t);
extern void		(*pmap_protect_p)(pmap_t, vaddr_t, vaddr_t,
					       vm_prot_t);
extern void		(*pmap_zero_page_p)(paddr_t);
extern void		(*pmap_changeprot_p)(pmap_t, vaddr_t,
						  vm_prot_t, int);
@


1.15.2.7
log
@Sync the SMP branch with 3.3
@
text
@d190 6
a195 1
/* XXX - struct pvlist moved to vmparam.h because of include ordering issues */
d269 2
d318 1
d327 1
a327 2
void		pmap_copy_page4_4c(struct vm_page *, struct vm_page *);
void		pmap_zero_page4_4c(struct vm_page *);
d336 1
d345 1
a345 2
void		pmap_copy_page4m(struct vm_page *, struct vm_page *);
void		pmap_zero_page4m(struct vm_page *);
d385 1
d397 1
a397 2
extern void		(*pmap_copy_page_p)(struct vm_page *, struct vm_page *);
extern void		(*pmap_zero_page_p)(struct vm_page *);
@


1.15.2.8
log
@Merge of current from two weeks agointo the SMP branch
@
text
@d105 1
a105 1
 * `stolen' out of the MMU, we just keep all its PTEs there, and
@


1.15.2.9
log
@Merge with the trunk
@
text
@a305 2
#define		pmap_proc_iflush(p,va,len)	/* nothing */

@


1.14
log
@Change the kvm_uncache interface to a kvm_setcache that can uncache
a memory and allow the range to be cached again.
Make kvm_uncache and kvm_recache to macros that call kvm_setcache.
(also in the commit: Fix protection for pmap_kenter* and remove a redundant
 call to uvm_setpagesize).
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.13 1999/12/08 10:44:48 art Exp $	*/
d311 1
@


1.13
log
@Dumb implementation of PMAP_NEW, it works but without any gains yet.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.12 1999/11/11 12:30:35 art Exp $	*/
d308 3
a310 1
void		kvm_uncache __P((caddr_t, int));
@


1.12
log
@General cleanup of pmap.

- MACHINE_NONCONTIG will no longer work and all code that is not
  MACHINE_NEW_NONCONTIG is removed.
- Kill the pv_table hack which adds complexity to the code and wastes some
  memory, let the vm "handle" the pv lists through the vm_physmem array,
  this makes allocation a lot easier.
- kill the managed() macro, since it was only used to see if pvhead would
  end up in a "hole" in pv_table.
- pvhead() is now a function that returns NULL if the page is unmanaged. It
  also takes a page number as an argument instead of the physical address,
  since in most cases pvhead was called as pvhead(ptoa(pa)) anyway and it
  did an atop internally.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.11 1999/09/03 18:01:55 art Exp $	*/
d289 3
d293 1
d317 4
d323 1
d328 8
d339 1
d348 4
d354 1
d359 8
d370 1
d385 3
d402 3
d412 4
d418 1
d423 10
d436 1
d450 3
@


1.11
log
@Change the pmap_enter api to pass down an argument that indicates
the access type that caused this mapping. This is to simplify pmaps
with mod/ref emulation (none for the moment) and in some cases speed
up pmap_is_{referenced,modified}.
At the same time, clean up some mappings that had too high protection.

XXX - the access type is incorrect in old vm, it's only used by uvm and MD code.
The actual use of this in pmap_enter implementations is not in this commit.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.10 1999/07/09 21:33:37 art Exp $	*/
d176 37
a226 1
extern vaddr_t	vm_first_phys, vm_num_phys;
a268 1
#define	managed(pa)	((unsigned)((pa) - vm_first_phys) < vm_num_phys)
a308 5

#ifndef MACHINE_NEW_NONCONTIG
u_int		pmap_free_pages __P((void));
boolean_t	pmap_next_page __P((paddr_t *));
#endif
@


1.10
log
@vm_offset_t -> {v,p}addr_t and vm_size_t -> {v,p}size_t
remove "register" keywords
Various cleanups.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.9 1999/04/22 20:36:20 art Exp $	*/
d287 1
a287 1
				    boolean_t));
d304 1
a304 1
				  boolean_t));
d348 1
a348 1
					     vm_prot_t, boolean_t));
@


1.9
log
@MACHINE_NEW_NONCONTIG code. From NetBSD. Needed by UVM
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.8 1999/04/22 17:07:29 art Exp $	*/
d190 1
a190 1
extern vm_offset_t	vm_first_phys, vm_num_phys;
a226 6
#if xxx
void		pmap_bootstrap __P((int nmmu, int nctx, int nregion));
int		pmap_count_ptes __P((struct pmap *));
void		pmap_prefer __P((vm_offset_t, vm_offset_t *));
int		pmap_pa_exists __P((vm_offset_t));
#endif
d248 2
a249 2
void		pmap_prefer __P((vm_offset_t, vm_offset_t *));
int		pmap_pa_exists __P((vm_offset_t));
d251 17
a267 19
void            pmap_change_wiring __P((pmap_t, vm_offset_t, boolean_t));
void            pmap_collect __P((pmap_t));
void            pmap_copy __P((pmap_t,
			       pmap_t, vm_offset_t, vm_size_t, vm_offset_t));
pmap_t          pmap_create __P((vm_size_t));
void            pmap_destroy __P((pmap_t));
void            pmap_init __P((void));
vm_offset_t     pmap_map __P((vm_offset_t, vm_offset_t, vm_offset_t, int));
void            pmap_pageable __P((pmap_t,
				   vm_offset_t, vm_offset_t, boolean_t));
vm_offset_t     pmap_phys_address __P((int));
void            pmap_pinit __P((pmap_t));
void            pmap_reference __P((pmap_t));
void            pmap_release __P((pmap_t));
void            pmap_remove __P((pmap_t, vm_offset_t, vm_offset_t));
void            pmap_update __P((void));
void            pmap_init __P((void));
int		pmap_page_index __P((vm_offset_t));
void            pmap_virtual_space __P((vm_offset_t *, vm_offset_t *));
d272 1
a272 1
int		mmu_pagein __P((struct pmap *pm, int, int));
d276 2
a277 2
u_int           pmap_free_pages __P((void));
boolean_t       pmap_next_page __P((vm_offset_t *));
d283 12
a294 14
void            pmap_clear_modify4_4c __P((vm_offset_t pa));
void            pmap_clear_reference4_4c __P((vm_offset_t pa));
void            pmap_copy_page4_4c __P((vm_offset_t, vm_offset_t));
void            pmap_enter4_4c __P((pmap_t,
                    vm_offset_t, vm_offset_t, vm_prot_t, boolean_t));
vm_offset_t     pmap_extract4_4c __P((pmap_t, vm_offset_t));
boolean_t       pmap_is_modified4_4c __P((vm_offset_t pa));
boolean_t       pmap_is_referenced4_4c __P((vm_offset_t pa));
void            pmap_page_protect4_4c __P((vm_offset_t, vm_prot_t));
void            pmap_protect4_4c __P((pmap_t,
                    vm_offset_t, vm_offset_t, vm_prot_t));
void            pmap_zero_page4_4c __P((vm_offset_t));
void		pmap_changeprot4_4c __P((pmap_t, vm_offset_t, vm_prot_t, int));

d300 12
a311 14
void            pmap_clear_modify4m __P((vm_offset_t pa));
void            pmap_clear_reference4m __P((vm_offset_t pa));
void            pmap_copy_page4m __P((vm_offset_t, vm_offset_t));
void            pmap_enter4m __P((pmap_t,
                    vm_offset_t, vm_offset_t, vm_prot_t, boolean_t));
vm_offset_t     pmap_extract4m __P((pmap_t, vm_offset_t));
boolean_t       pmap_is_modified4m __P((vm_offset_t pa));
boolean_t       pmap_is_referenced4m __P((vm_offset_t pa));
void            pmap_page_protect4m __P((vm_offset_t, vm_prot_t));
void            pmap_protect4m __P((pmap_t,
                    vm_offset_t, vm_offset_t, vm_prot_t));
void            pmap_zero_page4m __P((vm_offset_t));
void		pmap_changeprot4m __P((pmap_t, vm_offset_t, vm_prot_t, int));

d316 1
a316 1
#define	  	pmap_clear_modify	pmap_clear_modify4_4c
d344 14
a357 14
extern void            	(*pmap_clear_modify_p) __P((vm_offset_t pa));
extern void            	(*pmap_clear_reference_p) __P((vm_offset_t pa));
extern void            	(*pmap_copy_page_p) __P((vm_offset_t, vm_offset_t));
extern void            	(*pmap_enter_p) __P((pmap_t,
		            vm_offset_t, vm_offset_t, vm_prot_t, boolean_t));
extern vm_offset_t     	(*pmap_extract_p) __P((pmap_t, vm_offset_t));
extern boolean_t       	(*pmap_is_modified_p) __P((vm_offset_t pa));
extern boolean_t       	(*pmap_is_referenced_p) __P((vm_offset_t pa));
extern void            	(*pmap_page_protect_p) __P((vm_offset_t, vm_prot_t));
extern void            	(*pmap_protect_p) __P((pmap_t,
		            vm_offset_t, vm_offset_t, vm_prot_t));
extern void            	(*pmap_zero_page_p) __P((vm_offset_t));
extern void	       	(*pmap_changeprot_p) __P((pmap_t, vm_offset_t,
		            vm_prot_t, int));
d359 1
a359 1
#define	  	pmap_clear_modify	(*pmap_clear_modify_p)
@


1.8
log
@implement pmap_{,de}activate
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.7 1997/11/07 08:11:41 deraadt Exp $	*/
a272 1
u_int           pmap_free_pages __P((void));
a273 1
boolean_t       pmap_next_page __P((vm_offset_t *));
d283 4
a286 1

@


1.7
log
@simple_lock api changed slightly
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.6 1997/09/17 06:47:14 downsj Exp $	*/
d249 3
@


1.6
log
@NETBSD_CURRENT_970916.  Lot's just ID changes, since changes don't apply to
us.  Includes some pmap changes, for which I don't have the original commit
message(s) handy.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.5 1997/08/08 08:26:38 downsj Exp $	*/
d142 1
a142 3
#if 0
	simple_lock_data_t pm_lock;	/* spinlock */
#endif
@


1.5
log
@Mostly sync to NetBSD-current 970804.

GENERIC currently compiles and runs; some devices (isp) are not complete and
not yet enabled.
@
text
@d1 2
a2 2
/*	$OpenBSD$	*/
/*	$NetBSD: pmap.h,v 1.29 1997/07/06 23:57:16 pk Exp $ */
d282 2
a283 3
#ifdef DEBUG
int		mmu_pagein4m __P((struct pmap *pm, int, int));
#endif
@


1.4
log
@sparc/pmap.c
@
text
@d1 2
a2 1
/*	$NetBSD: pmap.h,v 1.22.4.1 1996/06/12 20:29:01 pk Exp $ */
d142 1
a142 1
#if NCPUS > 1
d207 13
a220 5
#define PMAP_TYPE4M	0x78		/* mask to get 4m page type */
#define PMAP_PTESHFT4M	25		/* right shift to put type in pte */
#define PMAP_SHFT4M	0x3		/* left shift to extract type */
#define	PMAP_TNC	\
	(CPU_ISSUN4M?127:7)		/* mask to get PG_TYPE & PG_NC */
d223 5
d281 1
a281 1
int		mmu_pagein __P((struct pmap *pm, vm_offset_t, int));
d283 1
a283 1
int		mmu_pagein4m __P((struct pmap *pm, vm_offset_t, int));
@


1.3
log
@netbsd port, now we merge our changes back in
@
text
@d267 1
a267 1
int		mmu_pagein __P((struct pmap *pm, int, int));
d269 1
a269 1
int		mmu_pagein4m __P((struct pmap *pm, int, int));
@


1.2
log
@mmu_pagein proto
@
text
@d1 1
a1 1
/*	$NetBSD: pmap.h,v 1.16 1995/04/13 16:24:40 pk Exp $ */
d4 2
d15 2
d20 1
a20 8
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
d23 2
d77 3
d107 18
d131 7
a137 1
/* data appearing in both user and kernel pmaps */
d146 3
a148 2
	struct mmuhd	pm_reglist;	/* MMU regions on this pmap */
	struct mmuhd	pm_seglist;	/* MMU segments on this pmap */
d151 4
d163 3
a165 1
	smeg_t		rg_smeg;	/* the MMU region number */
d171 1
a171 1
	pmeg_t	sg_pmeg;		/* the MMU segment number */
d177 9
a205 2
#define	PMAP_TNC	7		/* mask to get PG_TYPE & PG_NC */
/*#define PMAP_IOC	0x00800000	-* IO cacheable, NOT shifted */
d207 9
d218 1
a218 1
vm_offset_t	pmap_prefer __P((vm_offset_t, vm_offset_t));
d220 4
a223 4
int		pmap_dumpsize __P((void));
int		pmap_dumpmmu __P((int (*)__P((dev_t, daddr_t, caddr_t, size_t)),
		    daddr_t));
int		mmu_pagein __P((struct pmap *, int va, vm_prot_t prot));
d231 138
a368 1
#define PMAP_PREFER(pa, va)		pmap_prefer((pa), (va))
@


1.1
log
@Initial revision
@
text
@d1 1
a1 1
/*	$NetBSD: pmap.h,v 1.17 1995/07/05 18:45:46 pk Exp $ */
d173 2
a174 1
				 daddr_t));
@


1.1.1.1
log
@initial import of NetBSD tree
@
text
@@
