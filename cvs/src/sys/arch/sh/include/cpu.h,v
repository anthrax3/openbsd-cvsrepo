head	1.27;
access;
symbols
	OPENBSD_6_1:1.27.0.14
	OPENBSD_6_1_BASE:1.27
	OPENBSD_6_0:1.27.0.10
	OPENBSD_6_0_BASE:1.27
	OPENBSD_5_9:1.27.0.6
	OPENBSD_5_9_BASE:1.27
	OPENBSD_5_8:1.27.0.8
	OPENBSD_5_8_BASE:1.27
	OPENBSD_5_7:1.27.0.2
	OPENBSD_5_7_BASE:1.27
	OPENBSD_5_6:1.27.0.4
	OPENBSD_5_6_BASE:1.27
	OPENBSD_5_5:1.26.0.6
	OPENBSD_5_5_BASE:1.26
	OPENBSD_5_4:1.26.0.2
	OPENBSD_5_4_BASE:1.26
	OPENBSD_5_3:1.24.0.2
	OPENBSD_5_3_BASE:1.24
	OPENBSD_5_2:1.21.0.8
	OPENBSD_5_2_BASE:1.21
	OPENBSD_5_1_BASE:1.21
	OPENBSD_5_1:1.21.0.6
	OPENBSD_5_0:1.21.0.4
	OPENBSD_5_0_BASE:1.21
	OPENBSD_4_9:1.21.0.2
	OPENBSD_4_9_BASE:1.21
	OPENBSD_4_8:1.20.0.2
	OPENBSD_4_8_BASE:1.20
	OPENBSD_4_7:1.19.0.2
	OPENBSD_4_7_BASE:1.19
	OPENBSD_4_6:1.19.0.4
	OPENBSD_4_6_BASE:1.19
	OPENBSD_4_5:1.18.0.2
	OPENBSD_4_5_BASE:1.18
	OPENBSD_4_4:1.14.0.2
	OPENBSD_4_4_BASE:1.14
	OPENBSD_4_3:1.12.0.2
	OPENBSD_4_3_BASE:1.12
	OPENBSD_4_2:1.10.0.2
	OPENBSD_4_2_BASE:1.10
	OPENBSD_4_1:1.6.0.2
	OPENBSD_4_1_BASE:1.6
	SH_20061006:1.1.1.1
	miod:1.1.1;
locks; strict;
comment	@ * @;


1.27
date	2014.07.11.10.53.07;	author uebayasi;	state Exp;
branches;
next	1.26;
commitid	CaCLs5fTSVpJlqFi;

1.26
date	2013.06.11.16.42.10;	author deraadt;	state Exp;
branches;
next	1.25;

1.25
date	2013.03.12.09.37.16;	author mpi;	state Exp;
branches;
next	1.24;

1.24
date	2013.02.12.08.06.22;	author mpi;	state Exp;
branches;
next	1.23;

1.23
date	2013.02.11.17.05.25;	author mpi;	state Exp;
branches;
next	1.22;

1.22
date	2012.12.02.07.03.31;	author guenther;	state Exp;
branches;
next	1.21;

1.21
date	2010.09.28.20.27.55;	author miod;	state Exp;
branches;
next	1.20;

1.20
date	2010.04.25.18.11.36;	author miod;	state Exp;
branches;
next	1.19;

1.19
date	2009.03.26.17.24.33;	author oga;	state Exp;
branches;
next	1.18;

1.18
date	2008.10.15.23.23.49;	author deraadt;	state Exp;
branches;
next	1.17;

1.17
date	2008.10.10.08.36.28;	author art;	state Exp;
branches;
next	1.16;

1.16
date	2008.10.10.08.05.45;	author art;	state Exp;
branches;
next	1.15;

1.15
date	2008.10.09.08.43.43;	author art;	state Exp;
branches;
next	1.14;

1.14
date	2008.07.18.23.43.31;	author art;	state Exp;
branches;
next	1.13;

1.13
date	2008.05.21.19.45.37;	author miod;	state Exp;
branches;
next	1.12;

1.12
date	2008.02.11.20.44.43;	author miod;	state Exp;
branches;
next	1.11;

1.11
date	2007.10.10.15.53.52;	author art;	state Exp;
branches;
next	1.10;

1.10
date	2007.06.06.17.15.12;	author deraadt;	state Exp;
branches;
next	1.9;

1.9
date	2007.05.14.07.05.49;	author art;	state Exp;
branches;
next	1.8;

1.8
date	2007.04.29.17.53.37;	author miod;	state Exp;
branches;
next	1.7;

1.7
date	2007.03.15.10.22.29;	author art;	state Exp;
branches;
next	1.6;

1.6
date	2007.03.03.21.37.27;	author miod;	state Exp;
branches;
next	1.5;

1.5
date	2007.03.02.06.11.54;	author miod;	state Exp;
branches;
next	1.4;

1.4
date	2007.01.15.22.22.19;	author martin;	state Exp;
branches;
next	1.3;

1.3
date	2006.11.29.12.26.14;	author miod;	state Exp;
branches;
next	1.2;

1.2
date	2006.10.06.22.30.26;	author mickey;	state Exp;
branches;
next	1.1;

1.1
date	2006.10.06.21.02.55;	author miod;	state Exp;
branches
	1.1.1.1;
next	;

1.1.1.1
date	2006.10.06.21.02.55;	author miod;	state Exp;
branches;
next	;


desc
@@


1.27
log
@CPU_BUSY_CYCLE(): A new MI statement for busy loop power reduction

The new CPU_BUSY_CYCLE() may be put in a busy loop body so that CPU can reduce
power consumption, as Linux's cpu_relax() and FreeBSD's cpu_spinwait().  To
start minimally, use PAUSE on i386/amd64 and empty on others.  The name is
chosen following the existing cpu_idle_*() functions.  Naming and API may be
polished later.

OK kettenis@@
@
text
@/*	$OpenBSD$	*/
/*	$NetBSD: cpu.h,v 1.41 2006/01/21 04:24:12 uwe Exp $	*/

/*-
 * Copyright (c) 2002 The NetBSD Foundation, Inc. All rights reserved.
 * Copyright (c) 1990 The Regents of the University of California.
 * All rights reserved.
 *
 * This code is derived from software contributed to Berkeley by
 * William Jolitz.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. Neither the name of the University nor the names of its contributors
 *    may be used to endorse or promote products derived from this software
 *    without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE
 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
 *
 *	@@(#)cpu.h	5.4 (Berkeley) 5/9/91
 */

/*
 * SH3/SH4 support.
 *
 *  T.Horiuchi    Brains Corp.   5/22/98
 */

#ifndef _SH_CPU_H_
#define	_SH_CPU_H_

#include <sh/psl.h>
#include <sh/frame.h>

#ifdef _KERNEL

/*
 * Per-CPU information.
 */

#include <machine/intr.h>
#include <sys/sched.h>

struct cpu_info {
	struct proc *ci_curproc;

	struct schedstate_percpu ci_schedstate; /* scheduler state */
	u_int32_t ci_randseed;
#ifdef DIAGNOSTIC
	int	ci_mutex_level;
#endif
#ifdef GPROF
	struct gmonparam *ci_gmon;
#endif
};

extern struct cpu_info cpu_info_store;
#define	curcpu()	(&cpu_info_store)
#define cpu_number()	0
#define CPU_IS_PRIMARY(ci)	1
#define CPU_INFO_ITERATOR	int
#define CPU_INFO_FOREACH(cii, ci) \
	for (cii = 0, ci = curcpu(); ci != NULL; ci = NULL)
#define CPU_INFO_UNIT(ci)	0
#define MAXCPUS	1
#define cpu_unidle(ci)

#define CPU_BUSY_CYCLE()	do {} while (0)


/*
 * Arguments to hardclock and gatherstats encapsulate the previous
 * machine state in an opaque clockframe.
 */
struct clockframe {
	int	spc;	/* program counter at time of interrupt */
	int	ssr;	/* status register at time of interrupt */
	int	ssp;	/* stack pointer at time of interrupt */
};

#define	CLKF_USERMODE(cf)	(!KERNELMODE((cf)->ssr))
#define	CLKF_PC(cf)		((cf)->spc)
#define	CLKF_INTR(cf)		0	/* XXX */

/*
 * This is used during profiling to integrate system time.  It can safely
 * assume that the process is resident.
 */
#define	PROC_PC(p)	((p)->p_md.md_regs->tf_spc)
#define	PROC_STACK(p)	((p)->p_md.md_regs->tf_r15)

/*
 * Preempt the current process if in interrupt from user mode,
 * or after the current trap/syscall if in system mode.
 */
#define	need_resched(ci)						\
do {									\
	want_resched = 1;						\
	if (curproc != NULL)						\
		aston(curproc);					\
} while (/*CONSTCOND*/0)
#define clear_resched(ci) 	want_resched = 0

/*
 * Give a profiling tick to the current process when the user profiling
 * buffer pages are invalid.  On the MIPS, request an ast to send us
 * through trap, marking the proc as needing a profiling tick.
 */
#define	need_proftick(p)	aston(p)

/*
 * Notify the current process (p) that it has a signal pending,
 * process as soon as possible.
 */
#define	signotify(p)	aston(p)

#define	aston(p)	((p)->p_md.md_astpending = 1)

extern int want_resched;		/* need_resched() was called */

/*
 * We need a machine-independent name for this.
 */
#define	DELAY(x)		delay(x)

#define	cpu_idle_enter()	do { /* nothing */ } while (0)
#define	cpu_idle_cycle()	__asm volatile("sleep")
#define	cpu_idle_leave()	do { /* nothing */ } while (0)

#endif /* _KERNEL */

/*
 * Logical address space of SH3/SH4 CPU.
 */
#define	SH3_PHYS_MASK	0x1fffffff

#define	SH3_P0SEG_BASE	0x00000000	/* TLB mapped, also U0SEG */
#define	SH3_P0SEG_END	0x7fffffff
#define	SH3_P1SEG_BASE	0x80000000	/* pa == va */
#define	SH3_P1SEG_END	0x9fffffff
#define	SH3_P2SEG_BASE	0xa0000000	/* pa == va, non-cacheable */
#define	SH3_P2SEG_END	0xbfffffff
#define	SH3_P3SEG_BASE	0xc0000000	/* TLB mapped, kernel mode */
#define	SH3_P3SEG_END	0xdfffffff
#define	SH3_P4SEG_BASE	0xe0000000	/* peripheral space */
#define	SH3_P4SEG_END	0xffffffff

#define	SH3_P1SEG_TO_PHYS(x)	((uint32_t)(x) & SH3_PHYS_MASK)
#define	SH3_P2SEG_TO_PHYS(x)	((uint32_t)(x) & SH3_PHYS_MASK)
#define	SH3_PHYS_TO_P1SEG(x)	((uint32_t)(x) | SH3_P1SEG_BASE)
#define	SH3_PHYS_TO_P2SEG(x)	((uint32_t)(x) | SH3_P2SEG_BASE)
#define	SH3_P1SEG_TO_P2SEG(x)	((uint32_t)(x) | 0x20000000)
#define	SH3_P2SEG_TO_P1SEG(x)	((uint32_t)(x) & ~0x20000000)

#ifdef _KERNEL
#ifndef __lint__

/*
 * Switch from P1 (cached) to P2 (uncached).  This used to be written
 * using gcc's assigned goto extension, but gcc4 aggressive optimizations
 * tend to optimize that away under certain circumstances.
 */
#define RUN_P2						\
	do {						\
		register uint32_t r0 asm("r0");		\
		uint32_t pc;				\
		__asm volatile(				\
			"	mov.l	1f, %1	;"	\
			"	mova	2f, %0	;"	\
			"	or	%0, %1	;"	\
			"	jmp	@@%1	;"	\
			"	 nop		;"	\
			"	.align 2	;"	\
			"1:	.long	0x20000000;"	\
			"2:;"				\
			: "=r"(r0), "=r"(pc));		\
	} while (0)

/*
 * Switch from P2 (uncached) back to P1 (cached).  We need to be
 * running on P2 to access cache control, memory-mapped cache and TLB
 * arrays, etc. and after touching them at least 8 instructinos are
 * necessary before jumping to P1, so provide that padding here.
 */
#define RUN_P1						\
	do {						\
		register uint32_t r0 asm("r0");		\
		uint32_t pc;				\
		__asm volatile(				\
		/*1*/	"	mov.l	1f, %1	;"	\
		/*2*/	"	mova	2f, %0	;"	\
		/*3*/	"	nop		;"	\
		/*4*/	"	and	%0, %1	;"	\
		/*5*/	"	nop		;"	\
		/*6*/	"	nop		;"	\
		/*7*/	"	nop		;"	\
		/*8*/	"	nop		;"	\
			"	jmp	@@%1	;"	\
			"	 nop		;"	\
			"	.align 2	;"	\
			"1:	.long	~0x20000000;"	\
			"2:;"				\
			: "=r"(r0), "=r"(pc));		\
	} while (0)

/*
 * If RUN_P1 is the last thing we do in a function we can omit it, b/c
 * we are going to return to a P1 caller anyway, but we still need to
 * ensure there's at least 8 instructions before jump to P1.
 */
#define PAD_P1_SWITCH	__asm volatile ("nop;nop;nop;nop;nop;nop;nop;nop;")

#else  /* __lint__ */
#define	RUN_P2		do {} while (/* CONSTCOND */ 0)
#define	RUN_P1		do {} while (/* CONSTCOND */ 0)
#define	PAD_P1_SWITCH	do {} while (/* CONSTCOND */ 0)
#endif
#endif

#if defined(SH4)
/* SH4 Processor Version Register */
#define	SH4_PVR_ADDR	0xff000030	/* P4  address */
#define	SH4_PVR		(*(volatile uint32_t *) SH4_PVR_ADDR)
#define	SH4_PRR_ADDR	0xff000044	/* P4  address */
#define	SH4_PRR		(*(volatile uint32_t *) SH4_PRR_ADDR)

#define	SH4_PVR_MASK	0xffffff00
#define	SH4_PVR_SH7750	0x04020500	/* SH7750  */
#define	SH4_PVR_SH7750S	0x04020600	/* SH7750S */
#define	SH4_PVR_SH775xR	0x04050000	/* SH775xR */
#define	SH4_PVR_SH7751	0x04110000	/* SH7751  */

#define	SH4_PRR_MASK	0xfffffff0
#define SH4_PRR_7750R	0x00000100	/* SH7750R */
#define SH4_PRR_7751R	0x00000110	/* SH7751R */
#endif

/*
 * pull in #defines for kinds of processors
 */
#include <machine/cputypes.h>

#ifdef _KERNEL
void sh_cpu_init(int, int);
void sh_startup(void);
__dead void cpu_reset(void);	/* soft reset */
void _cpu_spin(uint32_t);	/* for delay loop. */
void delay(int);
struct pcb;
void savectx(struct pcb *);
struct fpreg;
void fpu_save(struct fpreg *);
void fpu_restore(struct fpreg *);
u_int cpu_dump(int (*)(dev_t, daddr_t, caddr_t, size_t), daddr_t *);
u_int cpu_dumpsize(void);
void dumpconf(void);
void dumpsys(void);
#endif /* _KERNEL */
#endif /* !_SH_CPU_H_ */
@


1.26
log
@final removal of daddr64_t.  daddr_t has been 64 bit for a long enough
test period; i think 3 years ago the last bugs fell out.
ok otto beck others
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.25 2013/03/12 09:37:16 mpi Exp $	*/
d83 2
@


1.25
log
@Fix kernel profiling on MP systems by using per-CPU buffers and teach
kgmon(8) to deal with them, this time without public header changes.

Previously various CPUs were iterating over the same global buffer at
the same time to modify it and never ended.

This diff includes some ideas submited by Thor Simon to NetBSD via miod@@.

ok deraadt@@, mikeb@@, haesbaert@@
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.24 2013/02/12 08:06:22 mpi Exp $	*/
d268 1
a268 1
u_int cpu_dump(int (*)(dev_t, daddr64_t, caddr_t, size_t), daddr64_t *);
@


1.24
log
@Back out per-CPU kernel profiling, it shouldn't modify a public header
at this moment.
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.23 2013/02/11 17:05:25 mpi Exp $	*/
d67 3
@


1.23
log
@Fix kernel profiling on MP systems by using per-CPU buffer. Previously
various CPUs were iterating over the same global buffer at the same
time to modify it and never ended.

This diff includes some ideas submited by Thor Simon to NetBSD via miod@@.

ok mikeb@@, haesbaert@@
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.22 2012/12/02 07:03:31 guenther Exp $	*/
a66 3
#endif
#ifdef GPROF
	struct gmonparam *ci_gmon;
@


1.22
log
@Determine whether we're currently on the alternative signal stack
dynamically, by comparing the stack pointer against the altstack
base and size, so that you get the correct answer if you longjmp
out of the signal handler, as tested by regress/sys/kern/stackjmp/.
Also, fix alt stack handling on vax, where it was completely broken.

Testing and corrections by miod@@, krw@@, tobiasu@@, pirofti@@
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.21 2010/09/28 20:27:55 miod Exp $	*/
d67 3
@


1.21
log
@Implement a per-cpu held mutex counter if DIAGNOSTIC on all non-x86 platforms,
to complete matthew@@'s commit of a few days ago, and drop __HAVE_CPU_MUTEX_LEVEL
define. With help from, and ok deraadt@@.
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.20 2010/04/25 18:11:36 miod Exp $	*/
d100 2
a101 2
#define	PROC_PC(p)							\
	(((struct trapframe *)(p)->p_md.md_regs)->tf_spc)
@


1.20
log
@Do not include <machine/intr.h> from <sh/psl.h>, and fix <sh/cpu.h> which
used to depend on <sh/psl.h> bringing <machine/intr.h>.
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.19 2009/03/26 17:24:33 oga Exp $	*/
d65 3
@


1.19
log
@Remove cpu_wait(). It's original use was to be called from the reaper so
MD code would free resources that couldn't be freed until we were no
longer running in that processor. However, it's is unused on all
architectures since mikeb@@'s tss changes on x86 earlier in the year.

ok miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.18 2008/10/15 23:23:49 deraadt Exp $	*/
d57 1
d59 1
@


1.18
log
@make random(9) return per-cpu values (by saving the seed in the cpuinfo),
which are uniform for the profclock on each cpu in a SMP system (but using
a different seed for each cpu).  on all cpus, avoid seeding with a value out
of the [0, 2^31-1] range (since that is not stable)
ok kettenis drahn
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.17 2008/10/10 08:36:28 art Exp $	*/
a126 1
#define	cpu_wait(p)	((void)(p))
@


1.17
log
@Add empty cpu_unidle() macros for architectures that currently don't do
anything special to prod a cpu to leave the idle loop in signotify.
powerpc, i386, amd64 and sparc64 will follow soon so that everyone has
the same interface to wake an idling cpu.
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.16 2008/10/10 08:05:45 art Exp $	*/
d62 1
@


1.16
log
@Define MAXCPUS on all architectures.
For now, sparc64 is arbitrarily set to 256 (only architecture that didn't have
a practical limit in the code on the number of cpus).
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.15 2008/10/09 08:43:43 art Exp $	*/
d73 1
@


1.15
log
@Implement CPU_INFO_UNIT for everyone, not just MP kernels.
ok miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.14 2008/07/18 23:43:31 art Exp $	*/
d72 1
@


1.14
log
@Add a macro that clears the want_resched flag that need_resched sets.
Right now when mi_switch picks up the same proc, we didn't clear the
flag which would mean that every time we service an AST we would attempt
a context switch. For some architectures, amd64 being probably the
most extreme, that meant attempting to context switch for every
trap and interrupt.

Now we clear_resched explicitly after every context switch, even if it
didn't do anything. Which also allows us to remove some more code
in cpu_switchto (not done yet).

miod@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.13 2008/05/21 19:45:37 miod Exp $	*/
d71 1
@


1.13
log
@Not all cache operations need to be run from P2, so don't do this unless
necessary. Also, let the P2 functions return to P1 addresses, instead of
jumping to their own P1 image before returning. This gives a ~15% speedup.

From NetBSD, thanks uwe@@netbsd for spotting this in the sh4 docs!
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.12 2008/02/11 20:44:43 miod Exp $	*/
d104 1
@


1.12
log
@Remove long dead CLKF_BASEPRI which crept in by mistake.
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.11 2007/10/10 15:53:52 art Exp $	*/
d160 19
a178 6
/* switch from P1 to P2 */
#define	RUN_P2 do {							\
		void *p;						\
		p = &&P2;						\
		goto *(void *)SH3_P1SEG_TO_P2SEG(p);			\
	    P2:	(void)0;						\
d181 25
a205 7
/* switch from P2 to P1 */
#define	RUN_P1 do {							\
		void *p;						\
		p = &&P1;						\
		__asm volatile("nop;nop;nop;nop;nop;nop;nop;nop");	\
		goto *(void *)SH3_P2SEG_TO_P1SEG(p);			\
	    P1:	(void)0;						\
d208 7
d216 3
a218 2
#define	RUN_P2	do {} while (/* CONSTCOND */ 0)
#define	RUN_P1	do {} while (/* CONSTCOND */ 0)
@


1.11
log
@Make context switching much more MI:
 - Move the functionality of choosing a process from cpu_switch into
   a much simpler function: cpu_switchto. Instead of having the locore
   code walk the run queues, let the MI code choose the process we
   want to run and only implement the context switching itself in MD
   code.
 - Let MD context switching run without worrying about spls or locks.
 - Instead of having the idle loop implemented with special contexts
   in MD code, implement one idle proc for each cpu. make the idle
   loop MI with MD hooks.
 - Change the proc lists from the old style vax queues to TAILQs.
 - Change the sleep queue from vax queues to TAILQs. This makes
   wakeup() go from O(n^2) to O(n)

there will be some MD fallout, but it will be fixed shortly.
There's also a few cleanups to be done after this.

deraadt@@, kettenis@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.10 2007/06/06 17:15:12 deraadt Exp $	*/
a83 1
#define	CLKF_BASEPRI(cf)	(((cf)->ssr & 0xf0) == 0)
@


1.10
log
@now that all partition size/offsets are potentially 64-bit, change the
type of all variables to daddr64_t.  this includes the APIs for XXsize()
and XXdump(), all range checks inside bio drivers, internal variables
for disklabel handling, and even uvm's swap offsets.  re-read numerous
times by otto, miod, krw, thib to look for errors
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.9 2007/05/14 07:05:49 art Exp $	*/
d128 5
@


1.9
log
@Switch sh to __HAVE_CPUINFO. The least possible effort for now.

deraadt@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.8 2007/04/29 17:53:37 miod Exp $	*/
d213 1
a213 1
u_int cpu_dump(int (*)(dev_t, daddr_t, caddr_t, size_t), daddr_t *);
@


1.8
log
@machdep.led_blink sysctl for landisk, also move cpu_sysctl() code and related
variables from arch/sh/ to arch/landisk/. ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.7 2007/03/15 10:22:29 art Exp $	*/
d52 20
@


1.7
log
@Since p_flag is often manipulated in interrupts and without biglock
it's a good idea to use atomic.h operations on it. This mechanic
change updates all bit operations on p_flag to atomic_{set,clear}bits_int.

Only exception is that P_OWEUPC is set by MI code before calling
need_proftick and it's automatically cleared by ADDUPC. There's
no reason for MD handling of that flag since everyone handles it the
same way.

kettenis@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.6 2007/03/03 21:37:27 miod Exp $	*/
a180 13

/*
 * CTL_MACHDEP definitions.
 */
#define	CPU_CONSDEV		1	/* dev_t: console terminal device */
#define	CPU_KBDRESET		2	/* keyboard reset */
#define	CPU_MAXID		3	/* number of valid machdep ids */

#define	CTL_MACHDEP_NAMES {						\
	{ 0, 0 },							\
	{ "console_device",	CTLTYPE_STRUCT },			\
	{ "kbdreset",		CTLTYPE_INT },				\
}
@


1.6
log
@Kernel crash dumps and associated libkvm bits for landisk.
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.5 2007/03/02 06:11:54 miod Exp $	*/
d91 1
a91 5
#define	need_proftick(p)						\
do {									\
	(p)->p_flag |= P_OWEUPC;					\
	aston(p);							\
} while (/*CONSTCOND*/0)
@


1.5
log
@Move landisk to hardware floating point. At the moment the FPU context is
always saved upon context switches, as FPU registers are heavily used for
long long computations (don't ask). Gcc default to -m4.

Credits to drahn@@ otto@@ and deraadt@@ for feedback and help testing.

Upgrade procedure if you don't want to use the damn snapshots:
- build and install new kernel, reboot off it
- build new gcc, do not install it yet
- make includes
- install new gcc
- build and install lib/csu and lib/libc
- make build
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.4 2007/01/15 22:22:19 martin Exp $	*/
d210 3
@


1.4
log
@power(4) driver for the power switch on many landisk models, hooked
up to machdep.kbdreset; modelled after the sparc64 power(4) driver

discussed with miod@@ and jsg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.3 2006/11/29 12:26:14 miod Exp $	*/
d207 3
@


1.3
log
@Remove cpu_swapin() and cpu_swapout(), they are no longer necessary (except
for cpu_swapin() on hppa* which is kept).
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.2 2006/10/06 22:30:26 mickey Exp $	*/
d190 2
a191 1
#define	CPU_MAXID		2	/* number of valid machdep ids */
d196 1
@


1.2
log
@few more files
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.1.1.1 2006/10/06 21:02:55 miod Exp $	*/
a51 7

/*
 * Can't swapout u-area, (__SWAP_BROKEN)
 * since we use P1 converted address for trapframe.
 */
#define	cpu_swapin(p)			/* nothing */
#define	cpu_swapout(p)			/* nothing */
@


1.1
log
@Initial revision
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d114 1
@


1.1.1.1
log
@Preliminary bits for SuperH-based ports, based on NetBSD/sh3 codebase with
minor changes.
@
text
@@
