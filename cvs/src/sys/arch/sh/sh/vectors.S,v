head	1.8;
access;
symbols
	OPENBSD_6_2:1.8.0.30
	OPENBSD_6_2_BASE:1.8
	OPENBSD_6_1:1.8.0.28
	OPENBSD_6_1_BASE:1.8
	OPENBSD_6_0:1.8.0.24
	OPENBSD_6_0_BASE:1.8
	OPENBSD_5_9:1.8.0.20
	OPENBSD_5_9_BASE:1.8
	OPENBSD_5_8:1.8.0.22
	OPENBSD_5_8_BASE:1.8
	OPENBSD_5_7:1.8.0.14
	OPENBSD_5_7_BASE:1.8
	OPENBSD_5_6:1.8.0.18
	OPENBSD_5_6_BASE:1.8
	OPENBSD_5_5:1.8.0.16
	OPENBSD_5_5_BASE:1.8
	OPENBSD_5_4:1.8.0.12
	OPENBSD_5_4_BASE:1.8
	OPENBSD_5_3:1.8.0.10
	OPENBSD_5_3_BASE:1.8
	OPENBSD_5_2:1.8.0.8
	OPENBSD_5_2_BASE:1.8
	OPENBSD_5_1_BASE:1.8
	OPENBSD_5_1:1.8.0.6
	OPENBSD_5_0:1.8.0.4
	OPENBSD_5_0_BASE:1.8
	OPENBSD_4_9:1.8.0.2
	OPENBSD_4_9_BASE:1.8
	OPENBSD_4_8:1.7.0.2
	OPENBSD_4_8_BASE:1.7
	OPENBSD_4_7:1.3.0.6
	OPENBSD_4_7_BASE:1.3
	OPENBSD_4_6:1.3.0.8
	OPENBSD_4_6_BASE:1.3
	OPENBSD_4_5:1.3.0.4
	OPENBSD_4_5_BASE:1.3
	OPENBSD_4_4:1.3.0.2
	OPENBSD_4_4_BASE:1.3
	OPENBSD_4_3:1.2.0.4
	OPENBSD_4_3_BASE:1.2
	OPENBSD_4_2:1.2.0.2
	OPENBSD_4_2_BASE:1.2
	OPENBSD_4_1:1.1.1.1.0.2
	OPENBSD_4_1_BASE:1.1.1.1
	SH_20061006:1.1.1.1
	miod:1.1.1;
locks; strict;
comment	@# @;


1.8
date	2010.12.14.20.24.25;	author jasper;	state Exp;
branches;
next	1.7;

1.7
date	2010.07.01.07.24.26;	author jasper;	state Exp;
branches;
next	1.6;

1.6
date	2010.06.29.21.03.15;	author jasper;	state Exp;
branches;
next	1.5;

1.5
date	2010.06.06.21.18.47;	author jasper;	state Exp;
branches;
next	1.4;

1.4
date	2010.06.06.15.12.33;	author jasper;	state Exp;
branches;
next	1.3;

1.3
date	2008.06.26.05.42.13;	author ray;	state Exp;
branches;
next	1.2;

1.2
date	2007.05.14.07.05.49;	author art;	state Exp;
branches;
next	1.1;

1.1
date	2006.10.06.21.02.55;	author miod;	state Exp;
branches
	1.1.1.1;
next	;

1.1.1.1
date	2006.10.06.21.02.55;	author miod;	state Exp;
branches;
next	;


desc
@@


1.8
log
@"Implement fast path TLB miss handling.  Walk the page table without
creating a trapframe, with exceptions disabled and using only BANK1
registers.  If a valid pte is found, load it and return.  Otherwise
create a trapframe and proceed to the full-blown C handler."

from uwe@@netbsd, ok miod@@

speed-ups measured by miod@@ and me were between 44% and 50%...
@
text
@/*	$OpenBSD: vectors.S,v 1.7 2010/07/01 07:24:26 jasper Exp $	*/
/*	$NetBSD: exception_vector.S,v 1.19 2006/08/22 21:47:57 uwe Exp $	*/

/*-
 * Copyright (c) 2002 The NetBSD Foundation, Inc.
 * All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 *
 * THIS SOFTWARE IS PROVIDED BY THE NETBSD FOUNDATION, INC. AND CONTRIBUTORS
 * ``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED
 * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE FOUNDATION OR CONTRIBUTORS
 * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
 * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
 * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
 * POSSIBILITY OF SUCH DAMAGE.
 */

#include "assym.h"

#include <sh/param.h>
#include <sh/locore.h>
#include <sh/pte.h>
#include <sh/trap.h>
#include <sh/ubcreg.h>
#include <sh/mmu_sh3.h>
#include <sh/mmu_sh4.h>

/* 
 * Align vectors more strictly here (where we don't really care) so
 * that .align 5 (i.e. 32B cache line) before data block does the
 * right thing w.r.t. final destinations after vectors are copied.
 */
#define _ALIGN_TEXT	.align 5
#include <sh/asm.h>

/*
 * Exception vectors.
 * The following routines are copied to vector addreses.
 *	sh_vector_generic:	VBR + 0x100
 *	sh_vector_tlbmiss:	VBR + 0x400
 *	sh_vector_interrupt:	VBR + 0x600
 */

#define VECTOR_END_MARKER(sym)			\
		.globl	_C_LABEL(sym);		\
	_C_LABEL(sym):


/*
 * LINTSTUB: Var: char sh_vector_generic[1];
 *
 * void sh_vector_generic(void);
 *	Copied to VBR+0x100.  This code should be position independent
 *	and maximum 786 bytes long (== 0x400 - 0x100).
 */
NENTRY(sh_vector_generic)
	__EXCEPTION_ENTRY
	__INTR_MASK(r0, r1)
	/* Identify exception cause */
	MOV	(EXPEVT, r0)
	mov.l	@@r0,	r0
	mov.l	r0, @@(TF_EXPEVT, r14)	/* trapframe->tf_expevt = EXPEVT */
	/* Get curproc */
	mov.l	.Lg_curproc, r1
	mov.l	@@r1,	r4	/* 1st arg */
	/* Get TEA */
	MOV	(TEA,	r1)
	mov.l	@@r1,	r6	/* 3rd arg */
	/* Check TLB exception or not */
	mov.l	.Lg_TLB_PROT_ST, r1
	cmp/hi	r1,	r0
	bt	1f

	/* tlb_exception(curproc, trapframe, TEA); */
	mov.l	.Lg_VPN_MASK, r1
	and	r1,	r6	/* va = trunc_page(va) */
	__EXCEPTION_UNBLOCK(r0, r1)
	mov.l	.Lg_tlb_exception, r0
	jsr	@@r0
	 mov	r14,	r5	/* 2nd arg */
	bra	2f
	 nop

	/* general_exception(curproc, trapframe, TEA); */
1:	mov	r4,	r8
#ifdef DDB
	mov	#0,	r2
	MOV	(BBRA, r1)
	mov.w	r2,	@@r1	/* disable UBC */
	mov.l	r2,	@@(TF_UBC, r14)	/* clear trapframe->tf_ubc */
#endif /* DDB */
	__EXCEPTION_UNBLOCK(r0, r1)
	mov.l	.Lg_general_exception, r0
	jsr	@@r0
	 mov	r14,	r5	/* 2nd arg */

	/* Check for ASTs on exit to user mode. */
	mov	r8,	r4
	mov.l	.Lg_ast,	r0
	jsr	@@r0
	 mov	r14,	r5
#ifdef DDB	/* BBRA = trapframe->tf_ubc */
	__EXCEPTION_BLOCK(r0, r1)
	mov.l	@@(TF_UBC, r14), r0
	MOV	(BBRA, r1)
	mov.w	r0,	@@r1
#endif /* DDB */
2:	__EXCEPTION_RETURN
	/* NOTREACHED */
	.align	5
.Lg_curproc:			.long	_C_LABEL(cpu_info_store) + CI_CURPROC
REG_SYMBOL(EXPEVT)
REG_SYMBOL(BBRA)
REG_SYMBOL(TEA)
.Lg_tlb_exception:		.long	_C_LABEL(tlb_exception)
.Lg_general_exception:		.long	_C_LABEL(general_exception)
.Lg_ast:			.long	_C_LABEL(ast)
.Lg_TLB_PROT_ST:		.long	EXPEVT_TLB_PROT_ST
.Lg_VPN_MASK:			.long	0xfffff000

/* LINTSTUB: Var: char sh_vector_generic_end[1]; */
VECTOR_END_MARKER(sh_vector_generic_end)
	SET_ENTRY_SIZE(sh_vector_generic)


#ifdef SH3
/*
 * LINTSTUB: Var: char sh3_vector_tlbmiss[1];
 *
 * TLB miss vector.  We run through the fast path first, checking if
 * there's a valid mapping in curproc or kernel pmap.  We do fast path
 * with exceptions disabled, so no P3 addresses please (including no
 * kernel stack, as we cannot wire TLB entries on sh3).  We can only
 * use BANK1 registers, and of those r6 and r7 are already taken.
 *
 * If we don't find a valid mapping in the fast path, we do context
 * save and call tlb exception handler.
 *
 * Copied to VBR+0x400.  This code should be position independent
 * and maximum 512 bytes long (== 0x600 - 0x400).
 */
NENTRY(sh3_vector_tlbmiss)
	__EXCEPTION_ENTRY
	mov	#(SH3_PTEH & 0xff), r4
	mov.l	.L3_VPN_cleanup, r0
	mov.l	@@r4, r5
	and	r0, r5		/* trim vpn to 4K page boundary */
	/*
	 * For the duration of fast path we keep
	 * r4: SH3_PTEH - other PTE regs are addressable as @@(offset, r4)
	 * r5: { VPN, ASID } that caused the miss
	 */

	cmp/pz	r5		/* user space address? */
	bt/s	.L3_user_va
	 mov	r5, r2		/* copy of vpn to compute indices into ptd/ptp */

	/*
	 * kernel space address, use pmap_kernel(), adjust vpn for indexing
	 * see __pmap_kpte_lookup
	 */
.L3_kernel_va:
	mov.l	.L3_VM_MIN_KERNEL_ADDRESS, r0
	mov.l	.L3_kernptd,  r1 /* pmap_kernel()->pm_ptp */
	bra	.L3_fetch_pte
	 sub	r0, r2		/* vpn -= VM_MIN_KERNEL_ADDRESS */

	/* user space address, use curproc's pmap */
.L3_user_va:
	mov.l	.L3_curptd,  r1	! curproc->...->pm_ptp

	/* see __pmap_pte_lookup */
.L3_fetch_pte:
	mov.l	@@r1, r3		/* fetch ptd */

	/*
	 * r2: vpn, prepared for indexing into ptd
	 * r3: pt_entry_t **ptd => pt_entry_t *ptp => pt_entry_t pte
	 */
#ifdef DEBUG
	tst	r3, r3		/* ptd == NULL  - cannot happen */
	bt/s	.L3_call_tlb_exception
#endif
	 mov	#-22, r1	/* __PMAP_PTP_SHIFT */

	/* __PMAP_PTP_INDEX(vpn) */
	mov	r2, r0
	shld	r1, r0		/* vpn >> __PMAP_PTP_SHIFT */
	mov.l	.L3_ptp_index_mask, r1
	and	r1, r0		/* ... & (__PMAP_PTP_N - 1) */
	shll2	r0		/* array index -> array offset */
	mov.l	@@(r0, r3), r3	/* ptp = ptd[idx] */
	tst	r3, r3		/* if (ptp == NULL) */
	bt/s	.L3_call_tlb_exception
	 mov	#-(PGSHIFT - 2), r1

	/*
	 * __PMAP_PTP_OFSET(vpn) - except we pre-shift 2 bits left to
	 * get the array offset directly, as we know bits 10 and 11
	 * are zero (we cleaned them in r5 to get 4K aligned VPN)
	 */
	shld	r1, r2		/* vpn >> (PGSHIFT - 2) */
	mov.l	.L3_ptp_offset_mask, r0
	and	r2, r0		/* ... & ((__PMAP_PTP_PG_N - 1) << 2) */
	mov.l	@@(r0, r3), r3	/* pte = ptp[idx] */


	/* r3: pte */
	/* r4: SH3_PTEH */
	/* r5: { VPN, ASID } */

	mov.l	.L3_PG_V, r0
	tst	r0, r3		/* if ((pte & PG_V) == 0) */
	bt/s	.L3_call_tlb_exception
	 nop

	mov.l	.L3_PG_HW_BITS, r1
	cmp/pz	r5		/* user space address? */
	and	r1, r3		/* pte &= PG_HW_BITS */
	bf/s	.L3_load_kernel
	 mov.l	r3, @@(0x04, r4)	/* *SH3_PTEL = pte */

	/*
	 * load mapping for a user space page
	 * we reload PTEH to enter VPN aligned to 4K page boundary
	 */
.L3_load_user:
	mov.l	r5, @@r4		/* *SH3_PTEH = { VPN, ASID } */
	ldtlb			/* needs 2 insns padding before RTE */
	nop
	nop
	rte
	 nop

	/*
	 * load mapping for a kernel space page
	 * we need to temporary set ASID to 0
	 */
.L3_load_kernel:
	mov.l	.L3_clear_ASID, r1
	and	r5, r1		/* *SH3_PTEH & ~SH3_PTEH_ASID_MASK */
	mov.l	r1, @@r4		/* *SH3_PTEH = { VPN, ASID = 0 } */
 	ldtlb
	mov.l	r5, @@r4		/* restore ASID */
	nop
	rte
	 nop


	/*
	 * If we haven't found a valid mapping in the fast path
	 *     tlb_exception(curproc, trapframe, tea)
	 */
.L3_call_tlb_exception:
	__EXCEPTION_ENTRY
	mov.l	.L3_SH3_EXPEVT, r2
	mov.l	.L3_curproc, r1
	mov	#(SH3_TEA & 0xff), r0
	mov.l	@@r2, r2			/* *SH3_EXPEVT */
	mov.l	@@r0, r6			/* arg3: va = *SH3_TEA */
	mov.l	@@r1, r4			/* arg1: curproc */
	__INTR_MASK(r0, r1)
	__EXCEPTION_UNBLOCK(r0, r1)
	mov.l	.L3_tlb_exception,	r0
	ov.l	r2, @@(TF_EXPEVT, r14)	/* tf->tf_expevt = EXPEVT */
	jsr	@@r0
	 mov	r14, r5			/* arg2: trapframe */
	__EXCEPTION_RETURN

	.align	4
.L3_VPN_cleanup:		.long	~0x00000c00
.L3_curptd:			.long	_C_LABEL(curptd)
.L3_kernptd:			.long	_C_LABEL(__pmap_kernel)
.L3_VM_MIN_KERNEL_ADDRESS:	.long	VM_MIN_KERNEL_ADDRESS
.L3_ptp_index_mask:		.long	0x1ff
.L3_ptp_offset_mask:		.long	0x3ff << 2
.L3_PG_HW_BITS:			.long	PG_HW_BITS
.L3_PG_V:			.long	PG_V
.L3_clear_ASID:			.long	~SH3_PTEH_ASID_MASK
.L3_SH3_EXPEVT:			.long	SH3_EXPEVT
.L3_curproc:			.long	_C_LABEL(cpu_info_store) + CI_CURPROC
.L3_tlb_exception:		.long	_C_LABEL(tlb_exception)

/* LINTSTUB: Var: char sh3_vector_tlbmiss_end[1]; */
VECTOR_END_MARKER(sh3_vector_tlbmiss_end)
	SET_ENTRY_SIZE(sh3_vector_tlbmiss)
#endif /* SH3 */


#ifdef SH4
/*
 * LINTSTUB: Var: char sh4_vector_tlbmiss[1];
 *
 * TLB miss vector.  We run through the fast path first, checking if
 * there's a valid mapping in curproc or kernel pmap.  We do fast path
 * with exceptions disabled, so no P3 addresses please (though we can
 * use kernel stack if need be, as its TLB entries are wired).  We can
 * only use BANK1 registers, and of those r6 and r7 are already taken.
 *
 * If we don't find a valid mapping in the fast path, we do context
 * save and call tlb exception handler.
 *
 * Copied to VBR+0x400.  This code should be relocatable
 * and maximum 512 bytes long (== 0x600 - 0x400).
 */
NENTRY(sh4_vector_tlbmiss)
	mov.l	.L4_SH4_PTEH, r4
	mov.l	.L4_VPN_cleanup, r0
	mov.l	@@r4, r5
	and	r0, r5		/* trim vpn to 4K page boundary */
	/*
	 * For the duration of fast path we keep
	 * r4: SH4_PTEH - other PTE regs are addressable as @@(offset, r4)
	 * r5: { VPN, ASID } that caused the miss
	  */

	cmp/pz	r5		/* user space address? */
	bt/s	.L4_user_va
	 mov	r5, r2		/* copy of vpn to compute indices into ptd/ptp */

	/*
	 * kernel space address, use pmap_kernel(), adjust vpn for indexing
	 * see __pmap_kpte_lookup
	 */
.L4_kernel_va:
	mov.l	.L4_VM_MIN_KERNEL_ADDRESS, r0
	mov.l	.L4_kernptd,  r1 /* pmap_kernel()->pm_ptp */
	bra	.L4_fetch_pte
	 sub	r0, r2		/* vpn -= VM_MIN_KERNEL_ADDRESS */

	/* user space address, use curproc's pmap */
.L4_user_va:
	mov.l	.L4_curptd,  r1	/* curproc->...->pm_ptp */

	/* see __pmap_pte_lookup */
.L4_fetch_pte:
	mov.l	@@r1, r3		/* fetch ptd */

	/*
	 * r2: vpn, prepared for indexing into ptd
	 * r3: pt_entry_t **ptd => pt_entry_t *ptp => pt_entry_t pte
	 */
#ifdef DEBUG
	tst	r3, r3		/* ptd == NULL  - cannot happen */
	bt/s	.L4_call_tlb_exception
#endif
	 mov	#-22, r1	/* __PMAP_PTP_SHIFT */

	/* __PMAP_PTP_INDEX(vpn) */
	mov	r2, r0
	shld	r1, r0		/* vpn >> __PMAP_PTP_SHIFT */
	mov.l	.L4_ptp_index_mask, r1
	and	r1, r0		/* ... & (__PMAP_PTP_N - 1) */
	shll2	r0		/* array index -> array offset */
	mov.l	@@(r0, r3), r3	/* ptp = ptd[idx] */
	tst	r3, r3		/* if (ptp == NULL) */
	bt/s	.L4_call_tlb_exception
	 mov	#-(PGSHIFT - 2), r1

	/*
	 * __PMAP_PTP_OFSET(vpn) - except we pre-shift 2 bits left to
	 * get the array offset directly, as we know bits 10 and 11
	 * are zero (we cleaned them in r5 to get 4K aligned VPN)
	 */
	shld	r1, r2		/* vpn >> (PGSHIFT - 2) */
	mov.l	.L4_ptp_offset_mask, r0
	and	r2, r0		/* ... & ((__PMAP_PTP_PG_N - 1) << 2) */
	mov.l	@@(r0, r3), r3	/* pte = ptp[idx] */


	/* r3: pte */
	/* r4: SH4_PTEH */
	/* r5: { VPN, ASID } */

	mov.l	.L4_PG_V, r0
	tst	r0, r3		/* if ((pte & PG_V) == 0) */
	bt/s	.L4_call_tlb_exception
	 mov	r3, r0		/* prepare PCMCIA SA bits for SH4_PTEA */

	mov.l	.L4_PG_HW_BITS, r1
	shlr8	r0
	and	r1, r3		/* pte &= PG_HW_BITS */
	shlr	r0		/* pte >> _PG_PCMCIA_SHIFT */
	cmp/pz	r5		/* user space address? */
	and	#SH4_PTEA_SA_MASK, r0
	mov.l	r3, @@(0x04, r4)	/* *SH4_PTEL = pte */
	bf/s	.L4_load_kernel
	 mov.l	r0, @@(0x34, r4)	/* *SH4_PTEA = PCMCIA space attrs */

	/*
	 * Load mapping for a user space page
	 * we reload PTEH to enter VPN aligned to 4K page boundary
	 */
.L4_load_user:
	mov.l	r5, @@r4		/* *SH4_PTEH = { VPN, ASID } */
	ldtlb			/* needs 1 insn padding before RTE */
	nop
	rte
	 nop

	/*
	 * Load mapping for a kernel space page
	 * we need to temporary set ASID to 0
	 */
.L4_load_kernel:
	mov.l	.L4_clear_ASID, r1
	and	r5, r1		/* *SH4_PTEH & ~SH4_PTEH_ASID_MASK */
	mov.l	r1, @@r4		/* *SH4_PTEH = { VPN, ASID = 0 } */
	ldtlb
	mov.l	r5, @@r4		/* restore ASID */
	rte
	 nop


	/*
	 * If we haven't found a valid mapping in the fast path
	 *     tlb_exception(curproc, trapframe, tea)
	 */
.L4_call_tlb_exception:
	__EXCEPTION_ENTRY
	mov.l	.L4_SH4_PTEH, r0
	mov.l	.L4_curproc, r1
	mov.l	@@(0x24, r0), r2		/* *SH4_EXPEVT */
	mov.l	@@(0x0c, r0), r6		/* arg3: va = *SH4_TEA */
	mov.l	@@r1, r4			/* arg1: curproc */
	__INTR_MASK(r0, r1)
	__EXCEPTION_UNBLOCK(r0, r1)
	mov.l	.L4_tlb_exception,	r0
	mov.l	r2, @@(TF_EXPEVT, r14)	/* tf->tf_expevt = EXPEVT */
	jsr	@@r0
	 mov	r14,	r5	/* arg2: trapframe */
	__EXCEPTION_RETURN

	.align	5

.L4_SH4_PTEH:			.long	SH4_PTEH
.L4_VPN_cleanup:		.long	~0x00000c00
.L4_curptd:			.long	_C_LABEL(curptd)
.L4_kernptd:			.long	_C_LABEL(__pmap_kernel)
.L4_VM_MIN_KERNEL_ADDRESS:	.long	VM_MIN_KERNEL_ADDRESS
.L4_ptp_index_mask:		.long	0x1ff
.L4_ptp_offset_mask:		.long	0x3ff << 2
.L4_PG_HW_BITS:			.long	PG_HW_BITS
.L4_PG_V:			.long	PG_V
.L4_clear_ASID:			.long	~SH4_PTEH_ASID_MASK
.L4_curproc:			.long	_C_LABEL(cpu_info_store) + CI_CURPROC
.L4_tlb_exception:		.long	_C_LABEL(tlb_exception)


/* LINTSTUB: Var: char sh4_vector_tlbmiss_end[1]; */
VECTOR_END_MARKER(sh4_vector_tlbmiss_end)
	SET_ENTRY_SIZE(sh4_vector_tlbmiss)
#endif /* SH4 */


/*
 * LINTSTUB: Var: char sh_vector_interrupt[1];
 *
 * void sh_vector_interrupt(void);
 *	Copied to VBR+0x600.  This code should be position independent.
 */
NENTRY(sh_vector_interrupt)
	__EXCEPTION_ENTRY
	xor	r0,	r0
	mov.l	r0,	@@(TF_EXPEVT, r14) /* (for debug) */
	stc	r0_bank,r6	/* ssp */
	/* Enable exceptions for P3 access */
	__INTR_MASK(r0, r1)
	__EXCEPTION_UNBLOCK(r0, r1)
	/* uvmexp.intrs++ */
	mov.l	.Li_uvmexp_intrs, r0
	mov.l	@@r0,	r1
	add	#1	r1
	mov.l	r1,	@@r0
	/* Dispatch interrupt handler */
	mov.l	.Li_intc_intr, r0
	jsr	@@r0		/* intc_intr(ssr, spc, ssp) */
	 nop
	/* Check for ASTs on exit to user mode. */
	mov.l	.Li_curproc,	r0
	mov.l	@@r0,	r4	/* 1st arg */
	mov.l	.Li_ast, r0
	jsr	@@r0
	 mov	r14,	r5	/* 2nd arg */
	__EXCEPTION_RETURN

	.align	5
.Li_curproc:		.long	_C_LABEL(cpu_info_store) + CI_CURPROC
.Li_intc_intr:		.long	_C_LABEL(intc_intr)
.Li_ast:		.long	_C_LABEL(ast)
.Li_uvmexp_intrs:	.long	_C_LABEL(uvmexp) + UVMEXP_INTRS

/* LINTSTUB: Var: char sh_vector_interrupt_end[1]; */
VECTOR_END_MARKER(sh_vector_interrupt_end)
	SET_ENTRY_SIZE(sh_vector_interrupt)
@


1.7
log
@- don't do curupte checks if the current miss address is user space

from netbsd
ok miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vectors.S,v 1.6 2010/06/29 21:03:15 jasper Exp $	*/
d34 1
d86 1
a86 1
	/* tlb_exception(curlwp, trapframe, TEA); */
d142 11
a152 3
 * void sh3_vector_tlbmiss(void);
 *	Copied to VBR+0x400.  This code should be position independent
 *	and maximum 512 bytes long (== 0x600 - 0x400).
d156 104
a259 2
	mov	#(SH3_TEA & 0xff), r0
	mov.l	@@r0,	r6	/* 3rd arg: va = TEA */
a260 30
	/* if kernel stack is in P3, handle it here fast */
#if !defined(P1_STACK)
	cmp/pz	r6
	bt	6f		/* userspace address, proceed to handler */

	/* Load kernel stack */
	mov.l	.L3_VPN_MASK, r0
	and	r6,	r0	/* VPN */

	mov.l	.L3_CURUPTE, r1
	mov.l	@@r1, r1		/* upte = &l->l_md.md_upte[0] */
	mov	#UPAGES, r3	/* loop limit */

	/* for each page of u-area */
4:	mov.l	@@r1+, r7	/* upte->addr: u-area VPN */
	cmp/eq	r7, r0		/* if (vpn == upte->addr) */
	bt/s	5f		/*     goto found; */
	 dt	r3
	bf/s	4b
	 add	#4,	r1	/* skip upte->data; point to next md_upte[i] */
	/* not a page of u-area, proceed to handler */
	bra	7f		/* pull insn at 6f into delay slot */
	 mov	#(SH3_EXPEVT & 0xff), r0

	/* load entry for this uarea page into tlb */
5:	mov	#(SH3_PTEH & 0xff), r2
	mov.l	@@r1, r1		/* md_upte[i]->data */
	mov.l	@@r2, r3		/* save ASID */
	mov.l	r0, @@r2		/* SH3_PTEH = { VPN, ASID = 0 } */
	mov.l	r1, @@(4, r2)	/* SH3_PTEL = md_upte[i]->data */
d262 12
a273 10
	ldtlb
	bra	99f		/* return */
	 mov.l	r3,	@@r2	/*  restore ASID */
#endif /* !P1_STACK */
	/* tlb_exception(curproc, trapframe, tea) */
6:	mov	#(SH3_EXPEVT & 0xff), r0
7:	mov.l	@@r0,	r0
	mov.l	r0,	@@(TF_EXPEVT, r14) /* trapframe->tf_expevt = EXPEVT */
	mov.l	.L3_curproc,	r0
	mov.l	@@r0,	r4	/* 1st arg: curproc */
d277 1
d279 2
a280 2
	 mov	r14,	r5	/* 2nd arg: trap frame */
99:	__EXCEPTION_RETURN
d282 13
a294 5
	.align	5
.L3_curproc:		.long	_C_LABEL(cpu_info_store) + CI_CURPROC
.L3_tlb_exception:	.long	_C_LABEL(tlb_exception)
.L3_VPN_MASK:		.long	0xfffff000
.L3_CURUPTE:		.long	_C_LABEL(curupte)
d306 11
a316 3
 * void sh4_vector_tlbmiss(void);
 *	Copied to VBR+0x400.  This code should be position independent
 *	and maximum 512 bytes long (== 0x600 - 0x400).
d319 113
d433 5
a437 7
	mov.l	.L4_TEA4, r0
	mov.l	@@r0,	r6
	mov.l	.L4_EXPEVT4, r0
	mov.l	@@r0,	r0
	mov.l	r0,	@@(TF_EXPEVT, r14) /* trapframe->tf_expevt = EXPEVT */
	mov.l	.L4_curproc,	r0
	mov.l	@@r0,	r4	/* 1st arg */
d441 1
d443 1
a443 1
	 mov	r14,	r5	/* 2nd arg */
d447 14
a460 4
.L4_tlb_exception:	.long	_C_LABEL(tlb_exception)
.L4_curproc:		.long	_C_LABEL(cpu_info_store) + CI_CURPROC
.L4_EXPEVT4:		.long	SH4_EXPEVT
.L4_TEA4:			.long	SH4_TEA
@


1.6
log
@Shave off some instructions:
- Use dt to loop over md_upte in sh3_vector_tlbmiss.
- Shrink number of instructions for ldtlb

from netbsd

"commit it" miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vectors.S,v 1.5 2010/06/06 21:18:47 jasper Exp $	*/
d152 3
a157 2
	tst	r0,	r0
	bt	6f		/* punt if VPN is 0 */
@


1.5
log
@- add more comments to sh3_vector_tlbmiss (no binary change).
- arrange for data blocks to start on 32B cache line boundary.

from uwe@@netbsd
ok miod@@ (with an indentation suggestion)
@
text
@d1 1
a1 1
/*	$OpenBSD: vectors.S,v 1.4 2010/06/06 15:12:33 jasper Exp $	*/
a160 1
	mov	#1, r2		/* loop count */
d165 2
a166 3
	bt	5f		/*     goto found; */
	add	#4, r1		/* skip, upte->data; point to next md_upte[i] */
	cmp/eq	r2,	r3
d168 1
a168 1
	 add	#1,	r2
d174 5
a178 9
5:	mov.l	@@r1, r2		/* upte->data: u-area PTE */
	mov	#(SH3_PTEL & 0xff), r1
	mov.l	r2,	@@r1

	mov	#(SH3_PTEH & 0xff), r1
	mov.l	@@r1,	r2
	mov.l	.L3_VPN_MASK, r0
	and	r2,	r0
	mov.l	r0,	@@r1	/* ASID 0 */
d182 1
a182 1
	 mov.l	r2, @@r1		/*  restore ASID */
@


1.4
log
@use .L* for local labels and other small cosmetics

from uwe@@netbsd
ok miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vectors.S,v 1.3 2008/06/26 05:42:13 ray Exp $	*/
a32 1
#include <sh/asm.h>
d39 8
d121 1
a121 1
	.align	2
d149 2
d154 4
a157 3
	and	r6,	r0
	tst	r0,	r0	/* check VPN == 0 */
	bt	6f
d159 9
a167 7
	mov.l	@@r1,	r1
	mov	#UPAGES,r3
	mov	#1,	r2
4:	mov.l	@@r1+,	r7
	cmp/eq	r7,	r0	/* md_upte.addr: u-area VPN */
	bt	5f
	add	#4,	r1	/* skip md_upte.data */
d171 1
d174 3
a176 1
5:	mov.l	@@r1,	r2	/* md_upte.data: u-area PTE */
d179 1
d185 1
d187 2
a188 2
	bra	3f
	 mov.l	r2,	@@r1	/* restore ASID */
d190 1
d195 1
a195 1
	mov.l	@@r0,	r4	/* 1st arg */
d200 2
a201 2
	 mov	r14,	r5	/* 2nd arg */
3:	__EXCEPTION_RETURN
d203 1
a203 1
	.align	2
d239 1
a239 1
	.align	2
d282 1
a282 1
	.align	2
@


1.3
log
@First pass at removing clauses 3 and 4 from NetBSD licenses.

Not sure what's more surprising: how long it took for NetBSD to
catch up to the rest of the BSDs (including UCB), or the amount of
code that NetBSD has claimed for itself without attributing to the
actual authors.

OK deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vectors.S,v 1.2 2007/05/14 07:05:49 art Exp $	*/
d41 2
a42 1
 * Exception vectors. The following routines are copied to vector addreses.
d56 1
a56 1
 * void sh_vector_generic(void) __attribute__((__noreturn__))
d58 1
a58 1
 *	and no more than 786 bytes long (== 0x400 - 0x100).
d66 1
a66 1
	mov.l	r0,	@@(TF_EXPEVT, r14) /* trapframe->tf_expevt = EXPEVT */
d68 1
a68 1
	mov.l	_L.curproc, r1
d74 1
a74 1
	mov.l	_L.TLB_PROT_ST, r1
d78 2
a79 2
	/* tlb_exception(curproc, trapframe, trunc_page(TEA)); */
	mov.l	_L.VPN_MASK, r1
d82 1
a82 1
	mov.l	_L.tlb, r0
d97 1
a97 1
	mov.l	_L.general, r0
d103 1
a103 1
	mov.l	_L.ast,	r0
d115 1
a115 1
_L.curproc:	.long	_C_LABEL(cpu_info_store) + CI_CURPROC
d119 5
a123 5
_L.tlb:		.long	_C_LABEL(tlb_exception)
_L.general:	.long	_C_LABEL(general_exception)
_L.ast:		.long	_C_LABEL(ast)
_L.TLB_PROT_ST:	.long	0xc0
_L.VPN_MASK:	.long	0xfffff000
d134 1
a134 1
 * void sh3_vector_tlbmiss(void) __attribute__((__noreturn__))
d136 1
a136 1
 *	and no more than 512 bytes long (== 0x600 - 0x400).
d144 1
a144 1
	mov.l	__L.VPN_MASK, r0
d148 1
a148 1
	mov.l	_L.CURUPTE, r1
d166 1
a166 1
	mov.l	__L.VPN_MASK, r0
d176 1
a176 1
	mov.l	2f,	r0
d180 1
a180 1
	mov.l	1f,	r0
d184 1
d186 4
a189 4
2:		.long	_C_LABEL(cpu_info_store) + CI_CURPROC
1:		.long	_C_LABEL(tlb_exception)
__L.VPN_MASK:	.long	0xfffff000
_L.CURUPTE:	.long	_C_LABEL(curupte)
d201 1
a201 1
 * void sh4_vector_tlbmiss(void) __attribute__((__noreturn__))
d203 1
a203 1
 *	and no more than 512 bytes long (== 0x600 - 0x400).
d207 1
a207 1
	mov.l	_L.TEA4, r0
d209 1
a209 1
	mov.l	_L.EXPEVT4, r0
d212 1
a212 1
	mov.l	2f,	r0
d216 1
a216 1
	mov.l	1f,	r0
d220 1
d222 4
a225 4
1:		.long	_C_LABEL(tlb_exception)
2:		.long	_C_LABEL(cpu_info_store) + CI_CURPROC
_L.EXPEVT4:	.long	SH4_EXPEVT
_L.TEA4:	.long	SH4_TEA
d236 2
a237 2
 * void sh_vector_interrupt(void) __attribute__((__noreturn__)):
 *	copied to VBR+0x600. This code should be relocatable.
d244 1
a244 1
	/* Enable exception for P3 access */
d248 1
a248 1
	mov.l	__L.uvmexp.intrs, r0
d253 1
a253 1
	mov.l	__L.intc_intr, r0
d257 1
a257 1
	mov.l	1f,	r0
d259 1
a259 1
	mov.l	__L.ast, r0
d263 1
d265 4
a268 4
1:			.long	_C_LABEL(cpu_info_store) + CI_CURPROC
__L.intc_intr:		.long	_C_LABEL(intc_intr)
__L.ast:		.long	_C_LABEL(ast)
__L.uvmexp.intrs:	.long	_C_LABEL(uvmexp) + UVMEXP_INTRS
@


1.2
log
@Switch sh to __HAVE_CPUINFO. The least possible effort for now.

deraadt@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: vectors.S,v 1.1.1.1 2006/10/06 21:02:55 miod Exp $	*/
a15 7
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *        This product includes software developed by the NetBSD
 *        Foundation, Inc. and its contributors.
 * 4. Neither the name of The NetBSD Foundation nor the names of its
 *    contributors may be used to endorse or promote products derived
 *    from this software without specific prior written permission.
@


1.1
log
@Initial revision
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d121 1
a121 1
_L.curproc:	.long	_C_LABEL(curproc)
d191 1
a191 1
2:		.long	_C_LABEL(curproc)
d227 1
a227 1
2:		.long	_C_LABEL(curproc)
d268 1
a268 1
1:			.long	_C_LABEL(curproc)
@


1.1.1.1
log
@Preliminary bits for SuperH-based ports, based on NetBSD/sh3 codebase with
minor changes.
@
text
@@
