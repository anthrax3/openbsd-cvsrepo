head	1.10;
access;
symbols
	OPENBSD_5_9:1.9.0.4
	OPENBSD_5_9_BASE:1.9
	OPENBSD_5_8:1.9.0.6
	OPENBSD_5_8_BASE:1.9
	OPENBSD_5_7:1.9.0.2
	OPENBSD_5_7_BASE:1.9
	OPENBSD_5_6:1.8.0.12
	OPENBSD_5_6_BASE:1.8
	OPENBSD_5_5:1.8.0.10
	OPENBSD_5_5_BASE:1.8
	OPENBSD_5_4:1.8.0.6
	OPENBSD_5_4_BASE:1.8
	OPENBSD_5_3:1.8.0.4
	OPENBSD_5_3_BASE:1.8
	OPENBSD_5_2:1.8.0.2
	OPENBSD_5_2_BASE:1.8
	OPENBSD_5_1_BASE:1.7
	OPENBSD_5_1:1.7.0.4
	OPENBSD_5_0:1.7.0.2
	OPENBSD_5_0_BASE:1.7
	OPENBSD_4_9:1.5.0.2
	OPENBSD_4_9_BASE:1.5
	OPENBSD_4_8:1.4.0.4
	OPENBSD_4_8_BASE:1.4
	OPENBSD_4_7:1.4.0.2
	OPENBSD_4_7_BASE:1.4
	OPENBSD_4_6:1.3.0.4
	OPENBSD_4_6_BASE:1.3
	OPENBSD_4_5:1.1.0.6
	OPENBSD_4_5_BASE:1.1
	OPENBSD_4_4:1.1.0.4
	OPENBSD_4_4_BASE:1.1
	OPENBSD_4_3:1.1.0.2
	OPENBSD_4_3_BASE:1.1;
locks; strict;
comment	@ * @;


1.10
date	2016.05.11.21.52.50;	author deraadt;	state dead;
branches;
next	1.9;
commitid	VpgRpYXqYSJy4P7J;

1.9
date	2014.10.12.20.39.46;	author miod;	state Exp;
branches;
next	1.8;
commitid	n8DZa9w0X2LVgDkM;

1.8
date	2012.06.05.11.43.41;	author jsing;	state Exp;
branches;
next	1.7;

1.7
date	2011.04.21.04.34.12;	author miod;	state Exp;
branches;
next	1.6;

1.6
date	2011.04.03.18.46.40;	author miod;	state Exp;
branches;
next	1.5;

1.5
date	2010.09.28.20.27.54;	author miod;	state Exp;
branches;
next	1.4;

1.4
date	2009.08.13.13.24.55;	author weingart;	state Exp;
branches;
next	1.3;

1.3
date	2009.04.27.21.48.56;	author kettenis;	state Exp;
branches;
next	1.2;

1.2
date	2009.04.25.20.14.42;	author weingart;	state Exp;
branches;
next	1.1;

1.1
date	2007.10.06.14.54.38;	author kettenis;	state Exp;
branches;
next	;


desc
@@


1.10
log
@remove hppa64 port, which we never got going beyond broken single users.
hppa reverse-stack gives us a valuable test case, but most developers don't
have a 2nd one to proceed further with this.
ok kettenis
@
text
@/*	$OpenBSD: mutex.c,v 1.9 2014/10/12 20:39:46 miod Exp $	*/

/*
 * Copyright (c) 2004 Artur Grabowski <art@@openbsd.org>
 * All rights reserved. 
 *
 * Redistribution and use in source and binary forms, with or without 
 * modification, are permitted provided that the following conditions 
 * are met: 
 *
 * 1. Redistributions of source code must retain the above copyright 
 *    notice, this list of conditions and the following disclaimer. 
 * 2. The name of the author may not be used to endorse or promote products
 *    derived from this software without specific prior written permission. 
 *
 * THIS SOFTWARE IS PROVIDED ``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES,
 * INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY
 * AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL
 * THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
 * EXEMPLARY, OR CONSEQUENTIAL  DAMAGES (INCLUDING, BUT NOT LIMITED TO,
 * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS;
 * OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
 * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR
 * OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF
 * ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. 
 */

#include <sys/param.h>
#include <sys/mutex.h>
#include <sys/systm.h>
#include <sys/atomic.h>

#include <machine/intr.h>

#include <ddb/db_output.h>

static inline int
try_lock(struct mutex *mtx)
{
	volatile int *lock = (int *)(((vaddr_t)mtx->mtx_lock + 0xf) & ~0xf);
	volatile register_t ret = 0;

	/* Note: lock must be 16-byte aligned. */
	asm volatile (
		"ldcw,co	0(%2), %0"
		: "=&r" (ret), "+m" (lock)
		: "r" (lock)
	);

	return ret;
}

void
__mtx_init(struct mutex *mtx, int wantipl)
{
	mtx->mtx_lock[0] = 1;
	mtx->mtx_lock[1] = 1;
	mtx->mtx_lock[2] = 1;
	mtx->mtx_lock[3] = 1;
	mtx->mtx_wantipl = wantipl;
	mtx->mtx_oldipl = IPL_NONE;
}

void
mtx_enter(struct mutex *mtx)
{
	int s;

	for (;;) {
		if (mtx->mtx_wantipl != IPL_NONE)
			s = splraise(mtx->mtx_wantipl);
		if (try_lock(mtx)) {
			membar_enter();
			if (mtx->mtx_wantipl != IPL_NONE)
				mtx->mtx_oldipl = s;
			mtx->mtx_owner = curcpu();
#ifdef DIAGNOSTIC
			curcpu()->ci_mutex_level++;
#endif
			return;
		}
		if (mtx->mtx_wantipl != IPL_NONE)
			splx(s);
	}
}

int
mtx_enter_try(struct mutex *mtx)
{
	int s;
	
 	if (mtx->mtx_wantipl != IPL_NONE)
		s = splraise(mtx->mtx_wantipl);
	if (try_lock(mtx)) {
		membar_enter();
		if (mtx->mtx_wantipl != IPL_NONE)
			mtx->mtx_oldipl = s;
		mtx->mtx_owner = curcpu();
#ifdef DIAGNOSTIC
		curcpu()->ci_mutex_level++;
#endif
		return 1;
	}
	if (mtx->mtx_wantipl != IPL_NONE)
		splx(s);

	return 0;
}

void
mtx_leave(struct mutex *mtx)
{
	int s;

	MUTEX_ASSERT_LOCKED(mtx);

#ifdef DIAGNOSTIC
	curcpu()->ci_mutex_level--;
#endif
	s = mtx->mtx_oldipl;
	mtx->mtx_owner = NULL;
	membar_exit();

	mtx->mtx_lock[0] = 1;
	mtx->mtx_lock[1] = 1;
	mtx->mtx_lock[2] = 1;
	mtx->mtx_lock[3] = 1;

	if (mtx->mtx_wantipl != IPL_NONE)
		splx(s);
}
@


1.9
log
@Rough sync with hppa to make this compile again.
@
text
@d1 1
a1 1
/*	$OpenBSD: mutex.c,v 1.8 2012/06/05 11:43:41 jsing Exp $	*/
@


1.8
log
@Implement actual mutexes for hppa64.

ok kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mutex.c,v 1.8 2010/06/26 00:45:05 jsing Exp $	*/
d31 1
d40 1
a40 1
	volatile int *lock = &mtx->mtx_lock;
d43 1
d45 1
a45 1
		"ldcw,co 0(%2), %0"
d54 1
a54 1
mtx_init(struct mutex *mtx, int wantipl)
d56 4
a59 1
	mtx->mtx_lock = MUTEX_UNLOCKED;
d73 1
d95 1
d122 1
d124 4
a127 1
	mtx->mtx_lock = MUTEX_UNLOCKED;
@


1.7
log
@Revert the ``remove the `skip splraise/splx for IPL_NONE mutexes' optimization''
change. It seems to have unexpected side effects, especially on MP systems,
and drahn@@ disagrees with the way this change has been done and think there
is a better way to solve the original problem of msleep() fiddling with
mutex internals.
@
text
@d1 1
a1 1
/*	$OpenBSD: mutex.c,v 1.5 2010/09/28 20:27:54 miod Exp $	*/
d32 18
a49 3
#ifdef MULTIPROCESSOR
#error This code needs more work
#endif
a50 4
/*
 * Single processor systems don't need any mutexes, but they need the spl
 * raising semantics of the mutexes.
 */
d54 1
a54 1
	mtx->mtx_oldipl = 0;
d56 1
a56 1
	mtx->mtx_lock = 0;
d62 9
a70 4
	if (mtx->mtx_wantipl != IPL_NONE)
		mtx->mtx_oldipl = splraise(mtx->mtx_wantipl);
	MUTEX_ASSERT_UNLOCKED(mtx);
	mtx->mtx_lock = 1;
d72 1
a72 1
	curcpu()->ci_mutex_level++;
d74 5
d84 8
a91 4
	if (mtx->mtx_wantipl != IPL_NONE)
		mtx->mtx_oldipl = splraise(mtx->mtx_wantipl);
	MUTEX_ASSERT_UNLOCKED(mtx);
	mtx->mtx_lock = 1;
d93 1
a93 1
	curcpu()->ci_mutex_level++;
d95 4
d100 1
a100 1
	return 1;
d106 2
d109 1
d113 5
a117 1
	mtx->mtx_lock = 0;
d119 1
a119 1
		splx(mtx->mtx_oldipl);
@


1.6
log
@Remove the `skip splraise/splx for IPL_NONE mutexes' optimizations. It is not
always gaining anything, and msleep() implementation depends upon mtx_leave()
invoking splx().
@
text
@d51 2
a52 1
	mtx->mtx_oldipl = splraise(mtx->mtx_wantipl);
d63 2
a64 1
	mtx->mtx_oldipl = splraise(mtx->mtx_wantipl);
d82 2
a83 1
	splx(mtx->mtx_oldipl);
@


1.5
log
@Implement a per-cpu held mutex counter if DIAGNOSTIC on all non-x86 platforms,
to complete matthew@@'s commit of a few days ago, and drop __HAVE_CPU_MUTEX_LEVEL
define. With help from, and ok deraadt@@.
@
text
@d1 1
a1 1
/*	$OpenBSD: mutex.c,v 1.4 2009/08/13 13:24:55 weingart Exp $	*/
d51 1
a51 2
	if (mtx->mtx_wantipl != IPL_NONE)
		mtx->mtx_oldipl = splraise(mtx->mtx_wantipl);
d62 1
a62 2
	if (mtx->mtx_wantipl != IPL_NONE)
		mtx->mtx_oldipl = splraise(mtx->mtx_wantipl);
d80 1
a80 2
	if (mtx->mtx_wantipl != IPL_NONE)
		splx(mtx->mtx_oldipl);
@


1.4
log
@A new(er) mtx_enter_try().

Ok oga@@, "the time is now" deraadt@@.
@
text
@d1 1
a1 1
/*	$OpenBSD: mutex.c,v 1.3 2009/04/27 21:48:56 kettenis Exp $	*/
d55 3
d67 3
d78 3
@


1.3
log
@Revert mtx_enter_try.  It didn't compile on hppa, it doesn't compile on
landisk, and the sparc implementation is obviously wrong.  That's where I
stopped looking, so who knows what else was broken.  A simple comparison of
the existing mtx_enter with the new mtx_enter_try would have told anybody.
@
text
@d1 1
a1 1
/*	$OpenBSD: mutex.c,v 1.1 2007/10/06 14:54:38 kettenis Exp $	*/
d55 11
@


1.2
log
@Enter mtx_enter_try.  In part for completeness, things may start
using this soon(ish).  Ok oga@@, sorta yes kettenis@@.
@
text
@a56 11
int
mtx_enter_try(struct mutex *mtx)
{
	if (mtx->mtx_wantipl != IPL_NONE)
		mtx->mtx_oldipl = _splraise(mtx->mtx_wantipl);
	MUTEX_ASSERT_UNLOCKED(mtx);
	mtx->mtx_lock = 1;

	return 1;
}

@


1.1
log
@Simple single-processor only mutex implementation; cloned from hppa.
@
text
@d1 1
a1 1
/*	$OpenBSD: mutex.c,v 1.1 2007/05/05 12:00:55 miod Exp $	*/
d55 11
@

