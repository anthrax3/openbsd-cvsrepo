head	1.64;
access;
symbols
	SMP_SYNC_A:1.63
	SMP_SYNC_B:1.63
	OPENBSD_3_5:1.61.0.2
	OPENBSD_3_5_BASE:1.61
	OPENBSD_3_4:1.53.0.2
	OPENBSD_3_4_BASE:1.53
	UBC_SYNC_A:1.49
	OPENBSD_3_3:1.49.0.2
	OPENBSD_3_3_BASE:1.49
	OPENBSD_3_2:1.48.0.4
	OPENBSD_3_2_BASE:1.48
	OPENBSD_3_1:1.48.0.2
	OPENBSD_3_1_BASE:1.48
	UBC_SYNC_B:1.48
	UBC:1.43.0.2
	UBC_BASE:1.43
	OPENBSD_3_0:1.35.0.2
	OPENBSD_3_0_BASE:1.35
	OPENBSD_2_9:1.20.0.2
	OPENBSD_2_9_BASE:1.20
	OPENBSD_2_8:1.14.0.2
	OPENBSD_2_8_BASE:1.14
	OPENBSD_2_7:1.11.0.6
	OPENBSD_2_7_BASE:1.11
	SMP:1.11.0.4
	SMP_BASE:1.11
	kame_19991208:1.11
	OPENBSD_2_6:1.11.0.2
	OPENBSD_2_6_BASE:1.11
	OPENBSD_2_5:1.7.0.2
	OPENBSD_2_5_BASE:1.7
	OPENBSD_2_4:1.4.0.2
	OPENBSD_2_4_BASE:1.4
	OPENBSD_2_3:1.3.0.6
	OPENBSD_2_3_BASE:1.3
	OPENBSD_2_2:1.3.0.4
	OPENBSD_2_2_BASE:1.3
	OPENBSD_2_1:1.3.0.2
	OPENBSD_2_1_BASE:1.3
	mvme88kport:1.1.1.1
	OPENBSD_2_0:1.1.0.2
	OPENBSD_2_0_BASE:1.1;
locks; strict;
comment	@ * @;


1.64
date	2004.07.23.15.34.04;	author miod;	state dead;
branches;
next	1.63;

1.63
date	2004.05.23.20.53.18;	author miod;	state Exp;
branches;
next	1.62;

1.62
date	2004.05.23.20.52.16;	author miod;	state Exp;
branches;
next	1.61;

1.61
date	2004.03.03.22.23.58;	author miod;	state Exp;
branches;
next	1.60;

1.60
date	2004.01.28.13.04.58;	author miod;	state Exp;
branches;
next	1.59;

1.59
date	2004.01.12.07.46.17;	author miod;	state Exp;
branches;
next	1.58;

1.58
date	2004.01.08.14.35.33;	author miod;	state Exp;
branches;
next	1.57;

1.57
date	2004.01.02.17.08.58;	author miod;	state Exp;
branches;
next	1.56;

1.56
date	2003.11.17.14.48.20;	author miod;	state Exp;
branches;
next	1.55;

1.55
date	2003.10.24.20.40.07;	author miod;	state Exp;
branches;
next	1.54;

1.54
date	2003.10.05.20.27.47;	author miod;	state Exp;
branches;
next	1.53;

1.53
date	2003.08.08.13.47.36;	author miod;	state Exp;
branches;
next	1.52;

1.52
date	2003.06.02.23.27.52;	author millert;	state Exp;
branches;
next	1.51;

1.51
date	2003.06.01.00.22.12;	author miod;	state Exp;
branches;
next	1.50;

1.50
date	2003.05.30.20.47.53;	author miod;	state Exp;
branches;
next	1.49;

1.49
date	2003.01.04.01.12.08;	author miod;	state Exp;
branches;
next	1.48;

1.48
date	2002.03.14.01.26.40;	author millert;	state Exp;
branches;
next	1.47;

1.47
date	2002.01.16.20.50.17;	author miod;	state Exp;
branches;
next	1.46;

1.46
date	2002.01.14.21.34.41;	author miod;	state Exp;
branches;
next	1.45;

1.45
date	2001.12.24.04.07.26;	author miod;	state Exp;
branches;
next	1.44;

1.44
date	2001.12.22.10.23.50;	author smurph;	state Exp;
branches;
next	1.43;

1.43
date	2001.12.16.23.49.47;	author miod;	state Exp;
branches
	1.43.2.1;
next	1.42;

1.42
date	2001.12.13.08.55.52;	author smurph;	state Exp;
branches;
next	1.41;

1.41
date	2001.12.08.02.24.06;	author art;	state Exp;
branches;
next	1.40;

1.40
date	2001.11.28.16.13.29;	author art;	state Exp;
branches;
next	1.39;

1.39
date	2001.11.27.05.37.02;	author miod;	state Exp;
branches;
next	1.38;

1.38
date	2001.11.07.22.40.59;	author miod;	state Exp;
branches;
next	1.37;

1.37
date	2001.11.06.19.53.15;	author miod;	state Exp;
branches;
next	1.36;

1.36
date	2001.11.06.18.41.10;	author art;	state Exp;
branches;
next	1.35;

1.35
date	2001.09.23.02.51.36;	author miod;	state Exp;
branches;
next	1.34;

1.34
date	2001.09.21.02.11.57;	author miod;	state Exp;
branches;
next	1.33;

1.33
date	2001.09.19.20.50.57;	author mickey;	state Exp;
branches;
next	1.32;

1.32
date	2001.08.26.14.31.12;	author miod;	state Exp;
branches;
next	1.31;

1.31
date	2001.08.11.23.21.14;	author art;	state Exp;
branches;
next	1.30;

1.30
date	2001.08.11.01.54.07;	author miod;	state Exp;
branches;
next	1.29;

1.29
date	2001.08.05.20.35.46;	author miod;	state Exp;
branches;
next	1.28;

1.28
date	2001.07.25.13.25.32;	author art;	state Exp;
branches;
next	1.27;

1.27
date	2001.07.05.10.03.48;	author art;	state Exp;
branches;
next	1.26;

1.26
date	2001.06.27.04.29.22;	author art;	state Exp;
branches;
next	1.25;

1.25
date	2001.06.08.08.09.16;	author art;	state Exp;
branches;
next	1.24;

1.24
date	2001.05.06.00.45.54;	author art;	state Exp;
branches;
next	1.23;

1.23
date	2001.05.05.21.26.39;	author art;	state Exp;
branches;
next	1.22;

1.22
date	2001.05.05.20.56.47;	author art;	state Exp;
branches;
next	1.21;

1.21
date	2001.04.29.19.00.03;	author miod;	state Exp;
branches;
next	1.20;

1.20
date	2001.03.12.23.03.25;	author miod;	state Exp;
branches;
next	1.19;

1.19
date	2001.03.09.05.44.43;	author smurph;	state Exp;
branches;
next	1.18;

1.18
date	2001.03.08.00.03.31;	author miod;	state Exp;
branches;
next	1.17;

1.17
date	2001.01.13.05.19.00;	author smurph;	state Exp;
branches;
next	1.16;

1.16
date	2001.01.12.07.29.26;	author smurph;	state Exp;
branches;
next	1.15;

1.15
date	2000.12.28.21.21.25;	author smurph;	state Exp;
branches;
next	1.14;

1.14
date	2000.06.08.22.25.21;	author niklas;	state Exp;
branches;
next	1.13;

1.13
date	2000.06.08.09.50.16;	author art;	state Exp;
branches;
next	1.12;

1.12
date	2000.06.05.11.03.02;	author art;	state Exp;
branches;
next	1.11;

1.11
date	99.09.27.19.13.24;	author smurph;	state Exp;
branches
	1.11.4.1;
next	1.10;

1.10
date	99.09.03.18.01.33;	author art;	state Exp;
branches;
next	1.9;

1.9
date	99.08.17.10.32.17;	author niklas;	state Exp;
branches;
next	1.8;

1.8
date	99.05.29.04.41.47;	author smurph;	state Exp;
branches;
next	1.7;

1.7
date	99.02.09.06.36.30;	author smurph;	state Exp;
branches;
next	1.6;

1.6
date	99.01.10.13.34.18;	author niklas;	state Exp;
branches;
next	1.5;

1.5
date	98.12.15.05.11.03;	author smurph;	state Exp;
branches;
next	1.4;

1.4
date	98.07.28.00.13.46;	author millert;	state Exp;
branches;
next	1.3;

1.3
date	97.03.03.20.21.54;	author rahnds;	state Exp;
branches;
next	1.2;

1.2
date	97.03.03.19.08.18;	author rahnds;	state dead;
branches;
next	1.1;

1.1
date	95.10.18.12.32.35;	author deraadt;	state Exp;
branches
	1.1.1.1;
next	;

1.1.1.1
date	97.03.03.19.32.25;	author rahnds;	state Exp;
branches;
next	;

1.11.4.1
date	2001.04.18.16.11.41;	author niklas;	state Exp;
branches;
next	1.11.4.2;

1.11.4.2
date	2001.07.04.10.20.24;	author niklas;	state Exp;
branches;
next	1.11.4.3;

1.11.4.3
date	2001.10.31.03.01.20;	author nate;	state Exp;
branches;
next	1.11.4.4;

1.11.4.4
date	2001.11.13.21.04.15;	author niklas;	state Exp;
branches;
next	1.11.4.5;

1.11.4.5
date	2001.12.05.00.39.13;	author niklas;	state Exp;
branches;
next	1.11.4.6;

1.11.4.6
date	2002.03.06.02.04.45;	author niklas;	state Exp;
branches;
next	1.11.4.7;

1.11.4.7
date	2002.03.28.10.36.03;	author niklas;	state Exp;
branches;
next	1.11.4.8;

1.11.4.8
date	2003.03.27.23.32.19;	author niklas;	state Exp;
branches;
next	1.11.4.9;

1.11.4.9
date	2003.06.07.11.13.17;	author ho;	state Exp;
branches;
next	1.11.4.10;

1.11.4.10
date	2004.02.19.10.49.08;	author niklas;	state Exp;
branches;
next	1.11.4.11;

1.11.4.11
date	2004.06.05.23.09.51;	author niklas;	state Exp;
branches;
next	;

1.43.2.1
date	2002.01.31.22.55.19;	author niklas;	state Exp;
branches;
next	1.43.2.2;

1.43.2.2
date	2002.06.11.03.37.11;	author art;	state Exp;
branches;
next	1.43.2.3;

1.43.2.3
date	2003.05.19.21.45.53;	author tedu;	state Exp;
branches;
next	;


desc
@@


1.64
log
@Move luna88k and mvme88k vm_machdep to m88k-agnostic code area.
@
text
@/*	$OpenBSD: vm_machdep.c,v 1.63 2004/05/23 20:53:18 miod Exp $	*/

/*
 * Copyright (c) 1998 Steve Murphree, Jr.
 * Copyright (c) 1996 Nivas Madhur
 * Copyright (c) 1993 Adam Glass
 * Copyright (c) 1988 University of Utah.
 * Copyright (c) 1982, 1986, 1990 The Regents of the University of California.
 * All rights reserved.
 *
 * This code is derived from software contributed to Berkeley by
 * the Systems Programming Group of the University of Utah Computer
 * Science Department.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. Neither the name of the University nor the names of its contributors
 *    may be used to endorse or promote products derived from this software
 *    without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE
 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
 *
 *	from: Utah $Hdr: vm_machdep.c 1.21 91/04/06$
 *	from: @@(#)vm_machdep.c	7.10 (Berkeley) 5/7/91
 *	vm_machdep.c,v 1.3 1993/07/07 07:09:32 cgd Exp
 */

#include <sys/param.h>
#include <sys/systm.h>
#include <sys/proc.h>
#include <sys/signalvar.h>
#include <sys/malloc.h>
#include <sys/buf.h>
#include <sys/user.h>
#include <sys/vnode.h>
#include <sys/extent.h>
#include <sys/core.h>
#include <sys/exec.h>
#include <sys/ptrace.h>

#include <uvm/uvm_extern.h>

#include <machine/mmu.h>
#include <machine/board.h>
#include <machine/cmmu.h>
#include <machine/cpu.h>
#include <machine/cpu_number.h>
#include <machine/locore.h>
#include <machine/trap.h>

extern struct extent *iomap_extent;
extern struct vm_map *iomap_map;

vaddr_t iomap_mapin(paddr_t, psize_t, boolean_t);
void iomap_mapout(vaddr_t, vsize_t);
void *mapiodev(void *, int);
void unmapiodev(void *, int);

/*
 * Finish a fork operation, with process p2 nearly set up.
 * Copy and update the kernel stack and pcb, making the child
 * ready to run, and marking it so that it can return differently
 * than the parent.  Returns 1 in the child process, 0 in the parent.
 * We currently double-map the user area so that the stack is at the same
 * address in each process; in the future we will probably relocate
 * the frame pointers on the stack after copying.
 */

void
cpu_fork(p1, p2, stack, stacksize, func, arg)
	struct proc *p1, *p2;
	void *stack;
	size_t stacksize;
	void (*func)(void *);
	void *arg;
{
	struct switchframe *p2sf;
	struct ksigframe {
		void (*func)(void *);
		void *proc;
	} *ksfp;
	extern struct pcb *curpcb;
	extern void proc_trampoline(void);
        extern void save_u_area(struct proc *, vaddr_t);

	/* Copy pcb from p1 to p2. */
	if (p1 == curproc) {
		/* Sync the PCB before we copy it. */
		savectx(curpcb);
	}
#ifdef DIAGNOSTIC
	else if (p1 != &proc0)
		panic("cpu_fork: curproc");
#endif

	bcopy(&p1->p_addr->u_pcb, &p2->p_addr->u_pcb, sizeof(struct pcb));
	p2->p_addr->u_pcb.kernel_state.pcb_ipl = IPL_NONE;	/* XXX */
	p2->p_md.md_tf = (struct trapframe *)USER_REGS(p2);

	/*XXX these may not be necessary nivas */
	save_u_area(p2, (vaddr_t)p2->p_addr);

	/*
	 * Create a switch frame for proc 2
	 */
	p2sf = (struct switchframe *)((char *)p2->p_addr + USPACE - 8) - 1;

	p2sf->sf_pc = (u_int)proc_do_uret;
	p2sf->sf_proc = p2;
	p2->p_addr->u_pcb.kernel_state.pcb_sp = (u_int)p2sf;

	/*
	 * If specified, give the child a different stack.
	 */
	if (stack != NULL)
		USER_REGS(p2)->r[31] = (u_int)stack + stacksize;

	ksfp = (struct ksigframe *)p2->p_addr->u_pcb.kernel_state.pcb_sp - 1;

	ksfp->func = func;
	ksfp->proc = arg;

	/*
	 * When this process resumes, r31 will be ksfp and
	 * the process will be at the beginning of proc_trampoline().
	 * proc_trampoline will execute the function func, pop off
	 * ksfp frame, and call the function in the switchframe
	 * now exposed.
	 */

	p2->p_addr->u_pcb.kernel_state.pcb_sp = (u_int)ksfp;
	p2->p_addr->u_pcb.kernel_state.pcb_pc = (u_int)proc_trampoline;
}

/*
 * cpu_exit is called as the last action during exit.
 * We release the address space and machine-dependent resources,
 * including the memory for the user structure and kernel stack.
 * Once finished, we call switch_exit, which switches to a temporary
 * pcb and stack and never returns.  We block memory allocation
 * until switch_exit has made things safe again.
 */
void
cpu_exit(struct proc *p)
{
	pmap_deactivate(p);

	splhigh();

	uvmexp.swtch++;
	switch_exit(p);
	/* NOTREACHED */
}

/*
 * Dump the machine specific header information at the start of a core dump.
 */
int
cpu_coredump(p, vp, cred, chdr)
	struct proc *p;
	struct vnode *vp;
	struct ucred *cred;
	struct core *chdr;
{
	struct reg reg;
	struct coreseg cseg;
	int error;

	CORE_SETMAGIC(*chdr, COREMAGIC, MID_MACHINE, 0);
	chdr->c_hdrsize = ALIGN(sizeof(*chdr));
	chdr->c_seghdrsize = ALIGN(sizeof(cseg));
	chdr->c_cpusize = sizeof(reg);

	/* Save registers. */
	error = process_read_regs(p, &reg);
	if (error)
		return error;

	CORE_SETMAGIC(cseg, CORESEGMAGIC, MID_MACHINE, CORE_CPU);
	cseg.c_addr = 0;
	cseg.c_size = chdr->c_cpusize;

	error = vn_rdwr(UIO_WRITE, vp, (caddr_t)&cseg, chdr->c_seghdrsize,
	    (off_t)chdr->c_hdrsize, UIO_SYSSPACE, IO_NODELOCKED|IO_UNIT, cred,
	    NULL, p);
	if (error)
		return error;

	error = vn_rdwr(UIO_WRITE, vp, (caddr_t)&reg, sizeof(reg),
	    (off_t)(chdr->c_hdrsize + chdr->c_seghdrsize), UIO_SYSSPACE,
	    IO_NODELOCKED|IO_UNIT, cred, NULL, p);
	if (error)
		return error;

	chdr->c_nseg++;
	return 0;
}

/*
 * Finish a swapin operation.
 * We neded to update the cached PTEs for the user area in the
 * machine dependent part of the proc structure.
 */

void
cpu_swapin(struct proc *p)
{
        extern void save_u_area(struct proc *, vaddr_t);

	save_u_area(p, (vaddr_t)p->p_addr);
}

/*
 * Map an IO request into kernel virtual address space.  Requests fall into
 * one of five catagories:
 *
 *	B_PHYS|B_UAREA:	User u-area swap.
 *			Address is relative to start of u-area (p_addr).
 *	B_PHYS|B_PAGET:	User page table swap.
 *			Address is a kernel VA in usrpt (Usrptmap).
 *	B_PHYS|B_DIRTY:	Dirty page push.
 *			Address is a VA in proc2's address space.
 *	B_PHYS|B_PGIN:	Kernel pagein of user pages.
 *			Address is VA in user's address space.
 *	B_PHYS:		User "raw" IO request.
 *			Address is VA in user's address space.
 *
 * All requests are (re)mapped into kernel VA space via phys_map
 *
 * XXX we allocate KVA space by using kmem_alloc_wait which we know
 * allocates space without backing physical memory.  This implementation
 * is a total crock, the multiple mappings of these physical pages should
 * be reflected in the higher-level VM structures to avoid problems.
 */
void
vmapbuf(bp, len)
	struct buf *bp;
	vsize_t len;
{
	caddr_t addr;
	vaddr_t kva, off;
	paddr_t pa;
	struct pmap *pmap;

#ifdef DIAGNOSTIC
	if ((bp->b_flags & B_PHYS) == 0)
		panic("vmapbuf");
#endif

	addr = (caddr_t)trunc_page((vaddr_t)(bp->b_saveaddr = bp->b_data));
	off = (vaddr_t)bp->b_saveaddr & PGOFSET;
	len = round_page(off + len);
	pmap = vm_map_pmap(&bp->b_proc->p_vmspace->vm_map);

	/*
	 * You may ask: Why phys_map? kernel_map should be OK - after all,
	 * we are mapping user va to kernel va or remapping some
	 * kernel va to another kernel va. The answer is TLB flushing
	 * when the address gets a new mapping.
	 */

	kva = uvm_km_valloc_wait(phys_map, len);

	/*
	 * Flush the TLB for the range [kva, kva + off]. Strictly speaking,
	 * we should do this in vunmapbuf(), but we do it lazily here, when
	 * new pages get mapped in.
	 */

	cmmu_flush_tlb(cpu_number(), 1, kva, len);

	bp->b_data = (caddr_t)(kva + off);
	while (len > 0) {
		if (pmap_extract(pmap, (vaddr_t)addr, &pa) == FALSE)
			panic("vmapbuf: null page frame");
		pmap_enter(vm_map_pmap(phys_map), kva, pa,
			   VM_PROT_READ | VM_PROT_WRITE,
			   VM_PROT_READ | VM_PROT_WRITE | PMAP_WIRED);
		/* make sure snooping will be possible... */
		pmap_cache_ctrl(pmap_kernel(), kva, kva + PAGE_SIZE,
		    CACHE_GLOBAL);
		addr += PAGE_SIZE;
		kva += PAGE_SIZE;
		len -= PAGE_SIZE;
	}
	pmap_update(pmap_kernel());
}

/*
 * Free the io map PTEs associated with this IO operation.
 * We also restore the original b_addr.
 */
void
vunmapbuf(bp, len)
	struct buf *bp;
	vsize_t len;
{
	vaddr_t addr, off;

#ifdef DIAGNOSTIC
	if ((bp->b_flags & B_PHYS) == 0)
		panic("vunmapbuf");
#endif

	addr = trunc_page((vaddr_t)bp->b_data);
	off = (vaddr_t)bp->b_data & PGOFSET;
	len = round_page(off + len);
	uvm_km_free_wakeup(phys_map, addr, len);
	bp->b_data = bp->b_saveaddr;
	bp->b_saveaddr = 0;
}


/*
 * Map a range [pa, pa+len] in the given map to a kernel address
 * in iomap space.
 *
 * Note: To be flexible, I did not put a restriction on the alignment
 * of pa. However, it is advisable to have pa page aligned since otherwise,
 * we might have several mappings for a given chunk of the IO page.
 */
vaddr_t
iomap_mapin(paddr_t pa, psize_t len, boolean_t canwait)
{
	vaddr_t	iova, tva, off;
	paddr_t ppa;
	int s, error;

	if (len == 0)
		return NULL;

	ppa = trunc_page(pa);
	off = pa & PGOFSET;
	len = round_page(off + len);

	s = splhigh();
	error = extent_alloc(iomap_extent, len, PAGE_SIZE, 0, EX_NOBOUNDARY,
	    canwait ? EX_WAITSPACE : EX_NOWAIT, &iova);
	splx(s);

	if (error != 0)
		return NULL;

	cmmu_flush_tlb(cpu_number(), 1, iova, len);	/* necessary? */

	tva = iova;
	while (len != 0) {
		pmap_enter(vm_map_pmap(iomap_map), tva, ppa,
			   VM_PROT_WRITE | VM_PROT_READ,
			   VM_PROT_WRITE | VM_PROT_READ | PMAP_WIRED);
		len -= PAGE_SIZE;
		tva += PAGE_SIZE;
		ppa += PAGE_SIZE;
	}
	pmap_update(pmap_kernel());

	return (iova + off);
}

/*
 * Free up the mapping in iomap.
 */
void
iomap_mapout(vaddr_t kva, vsize_t len)
{
	vaddr_t 	off;
	int 		s, error;

	off = kva & PGOFSET;
	kva = trunc_page(kva);
	len = round_page(off + len);

	pmap_remove(vm_map_pmap(iomap_map), kva, kva + len);
	pmap_update(vm_map_pmap(iomap_map));

	s = splhigh();
	error = extent_free(iomap_extent, kva, len, EX_NOWAIT);
	splx(s);

	if (error != 0)
		printf("iomap_mapout: extent_free failed\n");
}

/*
 * Allocate/deallocate a cache-inhibited range of kernel virtual address
 * space mapping the indicated physical address range [pa - pa+size)
 */
void *
mapiodev(pa, size)
	void *pa;
	int size;
{
	paddr_t ppa;
	ppa = (paddr_t)pa;
	return ((void *)iomap_mapin(ppa, size, 0));
}

void
unmapiodev(kva, size)
	void *kva;
	int size;
{
	vaddr_t va;
	va = (vaddr_t)kva;
	iomap_mapout(va, size);
}

int
badvaddr(vaddr_t va, int size)
{
	volatile int x;

	if (badaddr(va, size)) {
		return -1;
	}

	switch (size) {
	case 1:
		x = *(unsigned char *volatile)va;
		break;
	case 2:
		x = *(unsigned short *volatile)va;
		break;
	case 4:
		x = *(unsigned long *volatile)va;
		break;
	default:
                return -1;
	}
	return (0);
}

/*
 * Move pages from one kernel virtual address to another.
 */
void
pagemove(from, to, size)
	caddr_t from, to;
	size_t size;
{
	paddr_t pa;
	boolean_t rv;

#ifdef DEBUG
	if ((size & PAGE_MASK) != 0)
		panic("pagemove");
#endif
	while (size > 0) {
		rv = pmap_extract(pmap_kernel(), (vaddr_t)from, &pa);
#ifdef DEBUG
		if (rv == FALSE)
			panic("pagemove 2");
		if (pmap_extract(pmap_kernel(), (vaddr_t)to, NULL) == TRUE)
			panic("pagemove 3");
#endif
		pmap_kremove((vaddr_t)from, PAGE_SIZE);
		pmap_kenter_pa((vaddr_t)to, pa, VM_PROT_READ|VM_PROT_WRITE);
		from += PAGE_SIZE;
		to += PAGE_SIZE;
		size -= PAGE_SIZE;
	}
	pmap_update(pmap_kernel());
}
@


1.63
log
@Simplify iomap_mapin().
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.62 2004/05/23 20:52:16 miod Exp $	*/
@


1.62
log
@Nuke kvtop(), preserving a private copy in mvme88k vs(4) for now.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.61 2004/03/03 22:23:58 miod Exp $	*/
d348 2
a349 3
	ppa = pa;
	off = (u_long)ppa & PGOFSET;

a361 3
	ppa = trunc_page(ppa);

#ifndef NEW_MAPPING
d363 1
a363 5
#else
	tva = ppa;
#endif

	while (len>0) {
d372 1
a372 1
#ifndef NEW_MAPPING
a373 4
#else
	return (pa + off);
#endif

@


1.61
log
@In vmapbuf(), we actually only need to allow cache snooping, but enforcing
write through is not necessary.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.60 2004/01/28 13:04:58 miod Exp $	*/
a490 11
}

u_int
kvtop(va)
	vaddr_t va;
{
	paddr_t pa;

	pmap_extract(pmap_kernel(), va, &pa);
	/* XXX check for failure */
	return ((u_int)pa);
@


1.60
log
@Use write-back mappings whenever possible again, but make sure that
vmapbuf() returns write-through mappings.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.59 2004/01/12 07:46:17 miod Exp $	*/
d295 1
d297 1
a297 1
		    CACHE_WT | CACHE_GLOBAL);
@


1.59
log
@Get rid of that ugly m88100_saved_state structure, use trapframe everywhere
instead.

Allow struct reg and struct trapframe to live different lives and grow
separately. Righty now they are still the same, and code expects a trapframe
to always start with a struct reg. This may change...
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.58 2004/01/08 14:35:33 miod Exp $	*/
d295 2
@


1.58
log
@switch_exit() must be invoked at splhigh(), or you race the clock.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.57 2004/01/02 17:08:58 miod Exp $	*/
d114 1
a114 1
	p2->p_md.md_tf = USER_REGS(p2);
@


1.57
log
@When both cmmu_dofoo() and cmmu_remote_dofoo() exist, kill the first one,
and rename the second one to the first one, i.e. have the cmmu_dofoo()
functions always take a cpu# parameter.

No functional change, simply makes code more readable and saves a few
call frames.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.56 2003/11/17 14:48:20 miod Exp $	*/
d164 1
a164 1
	(void) splimp();
@


1.56
log
@Be sure to pmap_deactivate() pmaps when processes exit or are scheduled out.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.55 2003/10/24 20:40:07 miod Exp $	*/
d63 1
d286 1
a286 1
	cmmu_flush_tlb(1, kva, len);
d358 1
a358 1
	cmmu_flush_tlb(1, iova, len);
@


1.55
log
@Remove dead code.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.54 2003/10/05 20:27:47 miod Exp $	*/
d161 2
@


1.54
log
@Kill vm_offset_t and vm_size_t, in favor of the [pv]addr_t and [pv]size_t
typedefs.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.53 2003/08/08 13:47:36 miod Exp $	*/
a72 3
vaddr_t mapiospace(caddr_t, int);
void unmapiospace(vaddr_t);
int badpaddr(caddr_t, int);
d367 1
a367 1
			   VM_PROT_WRITE | VM_PROT_READ |(CACHE_INH << 16),
a429 34
/*
 * Map the given physical IO address into the kernel temporarily.
 * Maps one page.
 * Should have some sort of lockig for the use of phys_map_vaddr. XXX nivas
 */

vaddr_t
mapiospace(caddr_t pa, int len)
{
	int off = (u_long)pa & PGOFSET;
	extern vaddr_t phys_map_vaddr1;

	pa = (caddr_t)trunc_page((paddr_t)pa);

	pmap_kenter_pa(phys_map_vaddr1, (paddr_t)pa,
	    VM_PROT_READ|VM_PROT_WRITE);
	pmap_update(pmap_kernel());

	return (phys_map_vaddr1 + off);
}

/*
 * Unmap the address from above.
 */

void
unmapiospace(vaddr_t va)
{
	va = trunc_page(va);

	pmap_kremove(va, PAGE_SIZE);
	pmap_update(pmap_kernel());
}

d433 2
a434 1
	register int 	x;
d452 1
a452 20
	return(0);
}

int
badpaddr(caddr_t pa, int size)
{
	vaddr_t va;
	int val;

	/*
	 * Do not allow crossing a page boundary.
	 */
	if (((int)pa & PGOFSET) + size > NBPG) {
		return -1;
	}

	va = mapiospace(pa, NBPG);
	val = badvaddr(va, size);
	unmapiospace(va);
	return (val);
d494 1
@


1.53
log
@Slightly clean up cpu_fork().
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.52 2003/06/02 23:27:52 millert Exp $	*/
d6 1
a6 1
 * Copyright (c) 1993 Adam Glass 
d69 2
a70 2
vm_offset_t iomap_mapin(vm_offset_t, vm_size_t, boolean_t);
void iomap_mapout(vm_offset_t, vm_size_t);
d73 2
a74 2
vm_offset_t mapiospace(caddr_t, int);
void unmapiospace(vm_offset_t);
d102 1
a102 1
        extern void save_u_area(struct proc *, vm_offset_t);
d113 1
a113 1
	
d119 1
a119 1
	save_u_area(p2, (vm_offset_t)p2->p_addr);
d224 1
a224 1
        extern void save_u_area(struct proc *, vm_offset_t);
d226 1
a226 1
	save_u_area(p, (vm_offset_t)p->p_addr);
d254 1
a254 1
	vm_size_t len;
d256 3
a258 3
	register caddr_t addr;
	register vm_offset_t kva, off;
	vm_offset_t pa;
d267 1
a267 1
	off = (vm_offset_t)bp->b_saveaddr & PGOFSET;
d279 1
a279 1
	
d290 1
a290 1
		if (pmap_extract(pmap, (vm_offset_t)addr, &pa) == FALSE)
d309 1
a309 1
	vm_size_t len;
d311 1
a311 1
	register vm_offset_t addr, off;
d319 1
a319 1
	off = (vm_offset_t)bp->b_data & PGOFSET;
d335 2
a336 2
vm_offset_t
iomap_mapin(vm_offset_t pa, vm_size_t len, boolean_t canwait)
d338 3
a340 2
	vm_offset_t	iova, tva, off, ppa;
	int 		s, error;
d344 1
a344 1
	
d357 1
a357 1
	
d366 1
a366 1
#endif 
d381 1
a381 1
#endif 
d389 1
a389 1
iomap_mapout(vm_offset_t kva, vm_size_t len)
d391 1
a391 1
	vm_offset_t 	off;
d418 2
a419 2
	vm_offset_t ppa;
	ppa = (vm_offset_t)pa;
d428 2
a429 2
	vm_offset_t va;
	va = (vm_offset_t)kva;
d439 1
a439 1
vm_offset_t
d443 1
a443 1
	extern vm_offset_t phys_map_vaddr1;
d447 1
a447 1
	pmap_kenter_pa(phys_map_vaddr1, (vm_offset_t)pa,
d450 1
a450 1
	
d459 1
a459 1
unmapiospace(vm_offset_t va)
d468 1
a468 1
badvaddr(vm_offset_t va, int size)
d494 1
a494 1
	vm_offset_t va;
d544 1
a544 1
	vm_offset_t va;
d546 1
a546 1
	vm_offset_t pa;
@


1.52
log
@Remove the advertising clause in the UCB license which Berkeley
rescinded 22 July 1999.  Proofed by myself and Theo.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.51 2003/06/01 00:22:12 miod Exp $	*/
d104 9
a112 4
/*	
	savectx(p1->p_addr->u_pcb);
*/
	savectx(curpcb);
d114 2
a115 4
	/* copy p1 pcb to p2 */
	bcopy((void *)&p1->p_addr->u_pcb, (void *)&p2->p_addr->u_pcb, sizeof(struct pcb));
	p2->p_addr->u_pcb.kernel_state.pcb_ipl = 0;

a119 3
#ifdef notneeded 
	pmap_activate(p2);
#endif /* notneeded */
@


1.51
log
@Remove unused variable.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.50 2003/05/30 20:47:53 miod Exp $	*/
d23 1
a23 5
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *	This product includes software developed by the University of
 *	California, Berkeley and its contributors.
 * 4. Neither the name of the University nor the names of its contributors
@


1.50
log
@Working process core dumps, borrowed from m68k code.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.49 2003/01/04 01:12:08 miod Exp $	*/
a66 1
#include <machine/cpu_number.h>
a99 1
	int cpu;
a107 1
	cpu = cpu_number();
@


1.49
log
@Correctly invoke pmap_enter() [fix last argument]
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.48 2002/03/14 01:26:40 millert Exp $	*/
d57 3
d178 3
d182 5
a186 1
cpu_coredump(struct proc *p, struct vnode *vp, struct ucred *cred, struct core *corep)
d188 32
a219 2
	return (vn_rdwr(UIO_WRITE, vp, (caddr_t) p->p_addr, ctob(UPAGES),
	    (off_t)0, UIO_SYSSPACE, IO_NODELOCKED|IO_UNIT, cred, NULL, p));
@


1.48
log
@First round of __P removal in sys
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.47 2002/01/16 20:50:17 miod Exp $	*/
d260 2
a261 1
			   VM_PROT_READ|VM_PROT_WRITE, PMAP_WIRED);
d336 2
a337 1
			   VM_PROT_WRITE|VM_PROT_READ|(CACHE_INH << 16), PMAP_WIRED);
@


1.47
log
@Don't include <sys/map.h> when you don't need what's in it.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.46 2002/01/14 21:34:41 miod Exp $	*/
d71 7
a77 7
vm_offset_t iomap_mapin __P((vm_offset_t, vm_size_t, boolean_t));
void iomap_mapout __P((vm_offset_t, vm_size_t));
void *mapiodev __P((void *, int));
void unmapiodev __P((void *, int));
vm_offset_t mapiospace __P((caddr_t, int));
void unmapiospace __P((vm_offset_t));
int badpaddr __P((caddr_t, int));
d94 1
a94 1
	void (*func) __P((void *));
d100 1
a100 1
		void (*func) __P((void *));
d104 2
a105 2
	extern void proc_trampoline __P((void));
        extern void save_u_area __P((struct proc *, vm_offset_t));
d191 1
a191 1
        extern void save_u_area __P((struct proc *, vm_offset_t));
@


1.46
log
@volatile police.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.45 2001/12/24 04:07:26 miod Exp $	*/
a52 1
#include <sys/map.h>
@


1.45
log
@<machine/pte.h> not needed here.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.44 2001/12/22 10:23:50 smurph Exp $	*/
d442 1
a442 1
		x = *(volatile unsigned char *)va;
d445 1
a445 1
		x = *(volatile unsigned short *)va;
d448 1
a448 1
		x = *(volatile unsigned long *)va;
@


1.44
log
@correct badvaddr()
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.43 2001/12/16 23:49:47 miod Exp $	*/
a66 1
#include <machine/pte.h>
@


1.43
log
@Revert the mvme88k to 20011212. Recent changes had not been merged correctly,
and I am fed up with dissecting diffs to put back code that disappeared.
This will likely be fixed shortly.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.41 2001/12/08 02:24:06 art Exp $	*/
a436 1

d451 2
d454 1
a454 1
	return(x);
@


1.43.2.1
log
@Merge in -current, builds on i386, otherwise untested
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.47 2002/01/16 20:50:17 miod Exp $	*/
d53 1
d67 1
d437 1
d444 1
a444 1
		x = *(unsigned char *volatile)va;
d447 1
a447 1
		x = *(unsigned short *volatile)va;
d450 1
a450 1
		x = *(unsigned long *volatile)va;
a451 2
	default:
                return -1;
d453 1
a453 1
	return(0);
@


1.43.2.2
log
@Sync UBC branch to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.43.2.1 2002/01/31 22:55:19 niklas Exp $	*/
d71 7
a77 7
vm_offset_t iomap_mapin(vm_offset_t, vm_size_t, boolean_t);
void iomap_mapout(vm_offset_t, vm_size_t);
void *mapiodev(void *, int);
void unmapiodev(void *, int);
vm_offset_t mapiospace(caddr_t, int);
void unmapiospace(vm_offset_t);
int badpaddr(caddr_t, int);
d94 1
a94 1
	void (*func)(void *);
d100 1
a100 1
		void (*func)(void *);
d104 2
a105 2
	extern void proc_trampoline(void);
        extern void save_u_area(struct proc *, vm_offset_t);
d191 1
a191 1
        extern void save_u_area(struct proc *, vm_offset_t);
@


1.43.2.3
log
@sync
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d260 1
a260 2
			   VM_PROT_READ | VM_PROT_WRITE,
			   VM_PROT_READ | VM_PROT_WRITE | PMAP_WIRED);
d335 1
a335 2
			   VM_PROT_WRITE | VM_PROT_READ |(CACHE_INH << 16),
			   VM_PROT_WRITE | VM_PROT_READ | PMAP_WIRED);
@


1.42
log
@Support for MVME197 completed.  Fix SPL defs.
@
text
@d437 1
a451 2
	default:
                return -1;
d453 1
a453 1
	return(0);
@


1.41
log
@Sprinkle pmap_update calls where relevant and some other
misc pmap usage fixes.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.40 2001/11/28 16:13:29 art Exp $	*/
a436 1

d451 2
d454 1
a454 1
	return(x);
@


1.40
log
@zap some typedefs.
vm_map_t -> struct vm_map *
vm_map_entry_t -> struct vm_map_entry *
simple_lock_data_t -> struct simplelock

(uvm not done yet, coming in the next commit)
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.39 2001/11/27 05:37:02 miod Exp $	*/
d267 1
d342 1
d365 1
d415 1
d430 1
d504 1
@


1.39
log
@Adapt to include files changes.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.38 2001/11/07 22:40:59 miod Exp $	*/
d71 1
a71 1
extern vm_map_t   iomap_map;
@


1.38
log
@Unbreak cpu_fork(). mvme88k kernels compile and work again.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.37 2001/11/06 19:53:15 miod Exp $	*/
d61 2
@


1.37
log
@Replace inclusion of <vm/foo.h> with the correct <uvm/bar.h> when necessary.
(Look ma, I might have broken the tree)
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.36 2001/11/06 18:41:10 art Exp $	*/
d90 6
a95 2
cpu_fork(struct proc *p1, struct proc *p2, void *stack, size_t stacksize,
	void (*func)(void *), void *arg)
d100 1
a100 1
		void (*func)(struct proc *);
d143 1
a143 2
	ksfp->arg = arg;
	ksfp->proc = p2;
@


1.36
log
@Let fork1, uvm_fork, and cpu_fork take a function/argument pair as argument,
instead of doing fork1, cpu_set_kpc. This lets us retire cpu_set_kpc and
avoid a multiprocessor race.

This commit breaks vax because it doesn't look like any other arch, someone
working on vax might want to look at this and try to adapt the code to be
more like the rest of the world.

Idea and uvm parts from NetBSD.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.35 2001/09/23 02:51:36 miod Exp $	*/
a57 2

#include <vm/vm.h>
@


1.35
log
@kernel_pmap -> pmap_kernel()
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.34 2001/09/21 02:11:57 miod Exp $	*/
d92 2
a93 1
cpu_fork(struct proc *p1, struct proc *p2, void *stack, size_t stacksize)
d140 2
a141 1
	ksfp->func = child_return;
a153 18
}

void
cpu_set_kpc(struct proc *p, void (*func)(void *), void *arg)
{
	/*
	 * override func pointer in ksigframe with func.
	 */

	struct ksigframe {
		void (*func)(void *);
		void *arg;
	} *ksfp;

	ksfp = (struct ksigframe *)p->p_addr->u_pcb.kernel_state.pcb_sp;

	ksfp->func = func;
	ksfp->arg = arg;
@


1.34
log
@phys_map declaration comes from <vm/vm.h>, no need to declare it locally.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.33 2001/09/19 20:50:57 mickey Exp $	*/
d499 1
a499 1
		rv = pmap_extract(kernel_pmap, (vaddr_t)from, &pa);
d503 1
a503 1
		if (pmap_extract(kernel_pmap, (vaddr_t)to, NULL) == TRUE)
d520 1
a520 1
	pmap_extract(kernel_pmap, va, &pa);
@


1.33
log
@merge vm/vm_kern.h into uvm/uvm_extern.h; art@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.32 2001/08/26 14:31:12 miod Exp $	*/
a209 2

extern vm_map_t phys_map;
@


1.32
log
@Add prototypes, fix compilation warnings, random style fixes.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.31 2001/08/11 23:21:14 art Exp $	*/
a59 1
#include <vm/vm_kern.h>
@


1.31
log
@Unnecessary and redundant includes.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.30 2001/08/11 01:54:07 miod Exp $	*/
d64 1
a67 1
#include <machine/cmmu.h>
d69 1
d74 8
d102 2
a103 4
	extern void proc_do_uret(), child_return();
	extern void proc_trampoline();
	extern void savectx();
        extern void save_u_area();
d118 1
a118 1
	save_u_area(p2, p2->p_addr);
a152 2

	return;
a183 2
	extern volatile void switch_exit();

a193 1

d207 2
a208 1
        extern void save_u_area();
a462 2
	default:
		break;	
d474 1
a474 1
	 * Do not allow crossing the page boundary.
@


1.30
log
@Make iomap_mapout() a void function, since its return value is always 1
and never used anyway.
While there, beautify the extent_alloc() call.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.29 2001/08/05 20:35:46 miod Exp $	*/
a60 1
#include <vm/vm_map.h>
@


1.29
log
@Use syntaxic sugar provided by PMAP_NEW
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.28 2001/07/25 13:25:32 art Exp $	*/
d331 2
a332 2
	error = extent_alloc(iomap_extent, len, PAGE_SIZE, 0, 0,
	    canwait ? EX_WAITSPACE : 0, &iova);
d366 1
a366 1
int
d381 1
a383 2

	return 1;
@


1.28
log
@Change the pmap_enter interface to merge access_type and the wired boolean
and arbitrary flags into one argument.

One new flag is PMAP_CANFAIL that tells pmap_enter that it can fail if there
are not enough resources to satisfy the request. If this flag is not passed,
pmap_enter should panic as it should have done before this change (XXX - many
pmaps are still not doing that).

Only i386 and alpha implement CANFAIL for now.

Includes uvm updates from NetBSD.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.27 2001/07/05 10:03:48 art Exp $	*/
d425 2
a426 2
	pmap_enter(kernel_pmap, phys_map_vaddr1, (vm_offset_t)pa,
		   VM_PROT_READ|VM_PROT_WRITE, PMAP_WIRED);
d440 1
a440 1
	pmap_remove(kernel_pmap, va, va + NBPG);
d495 2
a496 1
	vm_offset_t pa;
d503 1
a503 1
		pmap_extract(kernel_pmap, (vm_offset_t)from, &pa);
d505 1
a505 2
#if 0
		if (pa == 0)
d507 1
a507 1
		if (pmap_extract(kernel_pmap, (vm_offset_t)to, XXX) != 0)
d510 5
a514 9
#endif
		pmap_remove(kernel_pmap,
			    (vm_offset_t)from, (vm_offset_t)from + NBPG);
		pmap_enter(kernel_pmap,
			   (vm_offset_t)to, pa, VM_PROT_READ|VM_PROT_WRITE,
			   VM_PROT_READ|VM_PROT_WRITE|PMAP_WIRED);
		from += NBPG;
		to += NBPG;
		size -= NBPG;
a522 1
	extern pmap_t kernel_pmap;
@


1.27
log
@Oops. missed this file in the extent_alloc fix.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.26 2001/06/27 04:29:22 art Exp $	*/
d276 1
a276 1
			   VM_PROT_READ|VM_PROT_WRITE, TRUE, 0);
d350 1
a350 1
			   VM_PROT_WRITE|VM_PROT_READ|(CACHE_INH << 16), 1, 0);
d426 1
a426 1
		   VM_PROT_READ|VM_PROT_WRITE, 1, 0);
d514 2
a515 2
			   (vm_offset_t)to, pa, VM_PROT_READ|VM_PROT_WRITE, 1,
			   VM_PROT_READ|VM_PROT_WRITE);
@


1.26
log
@rip old vm
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.25 2001/06/08 08:09:16 art Exp $	*/
d331 1
a331 1
	error = extent_alloc(iomap_extent, len, PAGE_SIZE, 0,
@


1.25
log
@Change the paddr_t pmap_extract(struct pmap *, vaddr_t) interface to
boolean_t pmap_extract(struct pmap *, vaddr_t, paddr_t *).
Matches NetBSD. Tested by various people on various platforms.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.24 2001/05/06 00:45:54 art Exp $	*/
a62 1
#if defined(UVM)
a63 1
#endif
a183 1
#if defined(UVM)
a184 3
#else
	cnt.v_swtch++;
#endif
a260 1
#if defined(UVM)
a261 3
#else
	kva = kmem_alloc_wait(phys_map, len);
#endif
a301 1
#if defined(UVM)
a302 3
#else
	kmem_free_wakeup(phys_map, addr, len);
#endif
@


1.24
log
@Update some comments wrt. the CLSIZE changes.
And remove that memory price comment from 1981. It is amusing, but also
confusing because the math in there is only correct on vax.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.23 2001/05/05 21:26:39 art Exp $	*/
d246 2
a247 1
	register vm_offset_t pa, kva, off;
d283 1
a283 2
		pa = pmap_extract(pmap, (vm_offset_t)addr);
		if (pa == 0)
d505 3
a507 1
pagemove(caddr_t from, caddr_t to, size_t size)
d509 1
a509 1
	register vm_offset_t pa;
d516 1
a516 1
		pa = pmap_extract(kernel_pmap, (vm_offset_t)from);
d518 1
d521 1
a521 1
		if (pmap_extract(kernel_pmap, (vm_offset_t)to) != 0)
d524 1
d537 2
a538 1
kvtop(vm_offset_t va)
d540 1
a541 25
	return ((u_int)pmap_extract(kernel_pmap, va));
}

/*
 * Map `size' bytes of physical memory starting at `paddr' into
 * kernel VA space at `vaddr'.  Read/write and cache-inhibit status
 * are specified by `prot'.
 */ 
#if 0
physaccess(vaddr, paddr, size, prot)
	void *vaddr, *paddr;
	register int size, prot;
{
/*	register pt_entry_t *pte;*/
	pte_template_t *pte;
	register u_int page;

	pte = kvtopte(vaddr);
	page = (u_int)paddr & PG_FRAME;
	for (size = btoc(size); size; size--) {
		*pte++ = PG_V | prot | page;
		page += NBPG;
	}
	TBIAS();
}
d543 2
a544 10
physunaccess(vaddr, size)
	caddr_t vaddr;
	register int size;
{
	register pt_entry_t *pte;

	pte = kvtopte(vaddr);
	for (size = btoc(size); size; size--)
		*pte++ = PG_NV;
	TBIAS();
a545 2

#endif
@


1.23
log
@Remove the (vaddr_t) casts inside the round_page and trunc_page macros.
We might want to use them on types that are bigger than vaddr_t.

Fix all callers that pass pointers without casts.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.22 2001/05/05 20:56:47 art Exp $	*/
a502 1
 * Size must be a multiple of CLSIZE.
@


1.22
log
@Get rid of CLSIZE and all related stuff.
CLSIZE -> 1
CLBYTES -> PAGE_SIZE
OLOFSET -> PAGE_MASK
etc.
At the same time some archs needed some cleaning in vmparam.h so that
goes in at the same time.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.21 2001/04/29 19:00:03 miod Exp $	*/
d254 1
a254 1
	addr = (caddr_t)trunc_page(bp->b_saveaddr = bp->b_data);
d309 1
a309 1
	addr = trunc_page(bp->b_data);
d437 1
a437 1
	pa = (caddr_t)trunc_page(pa);
@


1.21
log
@Replace resource maps with extents, and cleanup associated variables.
Idea from art's todolist, art@@ ok.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.20 2001/03/12 23:03:25 miod Exp $	*/
d511 1
a511 1
	if (size & CLOFSET)
@


1.20
log
@Simplify vmapbuf by moving the vm_map_pmap computation off loop (inspired
by similar code in the sparc port).
Compile the diagnostic code in vmapbuf and vunmapbuf only if DIAGNOSTIC
is defined.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.19 2001/03/09 05:44:43 smurph Exp $	*/
d57 1
d73 1
a73 1
extern struct map *iomap;
d322 1
a322 2
#if 1
/* XXX_FUTURE
d333 2
a334 2
	vm_offset_t		iova, tva, off, ppa;
	register int 		s;
d344 6
a349 10
	s = splimp();
	for (;;) {
		iova = rmalloc(iomap, len);
		if (iova != 0)
			break;
		if (canwait) {
			(void)tsleep(iomap, PRIBIO+1, "iomapin", 0);
			continue;
		}
		splx(s);
a350 2
	}
	splx(s);
d383 2
a384 2
	register int 		s;
	vm_offset_t 		off;
d392 2
a393 3
	s = splimp();
	rmfree(iomap, len, kva);
	wakeup(iomap);
d395 3
a399 2

#endif /* XXX_FUTURE */
@


1.19
log
@kernel will compile with -Werror.  Added intr.h
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.18 2001/03/08 00:03:31 miod Exp $	*/
d240 3
a242 1
vmapbuf(struct buf *bp, vm_size_t len)
d246 1
a246 1
	struct proc *p;
d248 1
d251 1
d256 1
a256 1
	p = bp->b_proc;
d281 1
a281 2
		pa = pmap_extract(vm_map_pmap(&p->p_vmspace->vm_map),
		    (vm_offset_t)addr);
d297 3
a299 1
vunmapbuf(struct buf *bp, vm_size_t len)
d303 1
d306 1
@


1.18
log
@Some warning hunting.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.17 2001/01/13 05:19:00 smurph Exp $	*/
d68 2
d97 3
a99 1
	
d211 1
a535 1

@


1.17
log
@Booting kernel with MACHINE_NEW_NONCONTIG.  UVM code added but not working.
New stand config.  Lots of header fixes.  Can now cross-compile i386->m88k.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.16 2001/01/12 07:29:26 smurph Exp $	*/
a86 1
	int off, ssz;
d322 1
a322 1
	register int 		npf, s;
a413 1
	int ix;
@


1.16
log
@Update vm interface to MACHIN_NEW_NONCONTIG.  Fix compile warning in pcctwo.c
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.15 2000/12/28 21:21:25 smurph Exp $	*/
d62 4
d112 1
a112 1
	PMAP_ACTIVATE(p2->p_vmspace->vm_map.pmap, &p2->p_addr->u_pcb, cpu);
d257 3
d261 1
d300 3
d304 1
d329 1
a329 1
   off = (u_long)ppa & PGOFSET;
d347 1
a347 1
   cmmu_flush_tlb(1, iova, len);
d349 1
a349 1
   ppa = trunc_page(ppa);
d354 1
a354 1
   tva = ppa;
d357 1
a357 1
   while (len>0) {
d359 1
a359 1
		    	VM_PROT_WRITE|VM_PROT_READ|(CACHE_INH << 16), 1, 0);
@


1.15
log
@mvme88k updates to -current.  finally!
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.14 2000/06/08 22:25:21 niklas Exp $	*/
a182 4

#if 1
	exit2(p);		/* XXX - can't be right! */
#endif 
@


1.14
log
@Add explicit inclusions of signalvar.h to files actually using syms defined
there but relying on an indirect inclusion
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.13 2000/06/08 09:50:16 art Exp $	*/
a77 1
#undef pcb_sp
a78 3
#ifdef __FORK_BRAINDAMAGE
int
#else
a79 1
#endif
d84 1
a84 1
   int cpu;
d89 1
d94 6
a99 2
   savectx(p1->p_addr);

a141 3
#ifdef __FORK_BRAINDAMAGE
	return(0);
#else
a142 1
#endif
d177 8
d186 1
@


1.13
log
@&vm_pmap -> vm_map.pmap
@
text
@d1 2
a2 1
/*	$OpenBSD: vm_machdep.c,v 1.12 2000/06/05 11:03:02 art Exp $	*/
a45 1
 *	$Id: vm_machdep.c,v 1.12 2000/06/05 11:03:02 art Exp $
d51 1
@


1.12
log
@Changes to exit handling.

cpu_exit no longer frees the vmspace and u-area. This is now handled by a
separate kernel thread "reaper". This is to avoid sleeping locks in the
critical path of cpu_exit where we're not allowed to sleep.

From NetBSD
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.11 1999/09/27 19:13:24 smurph Exp $	*/
d45 1
a45 1
 *	$Id: vm_machdep.c,v 1.11 1999/09/27 19:13:24 smurph Exp $
d107 1
a107 1
	PMAP_ACTIVATE(&p2->p_vmspace->vm_pmap, &p2->p_addr->u_pcb, cpu);
@


1.11
log
@Added to support MVME188 and MVME197
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.10 1999/09/03 18:01:33 art Exp $	*/
d45 1
a45 1
 *	$Id: vm_machdep.c,v 1.10 1999/09/03 18:01:33 art Exp $
a177 1
	vmspace_free(p->p_vmspace);
d180 1
a180 1
	kmem_free(kernel_map, (vm_offset_t)p->p_addr, ctob(UPAGES));
@


1.11.4.1
log
@Update the SMP branch to -current, this breaks the SMP branch though.
But it will be fixed soonish.  Note, nothing new has happened, this is just
a merge of the trunk into this branch.
@
text
@d1 1
a1 2
/*	$OpenBSD: vm_machdep.c,v 1.20 2001/03/12 23:03:25 miod Exp $	*/

d45 1
a50 1
#include <sys/signalvar.h>
a60 4
#if defined(UVM)
#include <uvm/uvm_extern.h>
#endif

a62 2
#include <machine/locore.h>
#include <machine/cmmu.h>
d77 1
d79 3
d83 1
d87 2
a88 1
	int cpu;
a92 1
	extern struct pcb *curpcb;
d95 3
a97 2
	extern void savectx();
        extern void save_u_area();
a98 7
	cpu = cpu_number();
/*	
	savectx(p1->p_addr->u_pcb);
*/
	savectx(curpcb);
	
	/* copy p1 pcb to p2 */
d107 1
a107 1
	pmap_activate(p2);
d141 3
d145 1
d178 1
d181 1
a181 6

#if defined(UVM)
	uvmexp.swtch++;
#else
	cnt.v_swtch++;
#endif
a202 1
        extern void save_u_area();
d231 1
a231 3
vmapbuf(bp, len)
	struct buf *bp;
	vm_size_t len;
d235 1
a235 1
	struct pmap *pmap;
a236 1
#ifdef DIAGNOSTIC
a238 1
#endif
d243 1
a243 1
	pmap = vm_map_pmap(&bp->b_proc->p_vmspace->vm_map);
a251 3
#if defined(UVM)
	kva = uvm_km_valloc_wait(phys_map, len);
#else
a252 1
#endif
d264 2
a265 1
		pa = pmap_extract(pmap, (vm_offset_t)addr);
d281 1
a281 3
vunmapbuf(bp, len)
	struct buf *bp;
	vm_size_t len;
a284 1
#ifdef DIAGNOSTIC
a286 1
#endif
a290 3
#if defined(UVM)
	uvm_km_free_wakeup(phys_map, addr, len);
#else
a291 1
#endif
d310 1
a310 1
	register int 		s;
d316 1
a316 1
	off = (u_long)ppa & PGOFSET;
d334 1
a334 1
	cmmu_flush_tlb(1, iova, len);
d336 1
a336 1
	ppa = trunc_page(ppa);
d341 1
a341 1
	tva = ppa;
d344 1
a344 1
	while (len>0) {
d346 1
a346 1
			   VM_PROT_WRITE|VM_PROT_READ|(CACHE_INH << 16), 1, 0);
d402 1
d520 1
@


1.11.4.2
log
@Merge in -current from two days ago in the SMP branch.
As usual with merges, they do not indicate progress, so do not hold
your breath for working SMP, and do not mail me and ask about the
state of it.  It has not changed.  There is work ongoing, but very, very
slowly.  The commit is done in parts as to not lock up the tree in too
big chunks at a time.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.11.4.1 2001/04/18 16:11:41 niklas Exp $	*/
a56 1
#include <sys/extent.h>
d62 1
d64 1
d72 1
a72 1
extern struct extent *iomap_extent;
d185 1
d187 3
d245 1
a245 2
	register vm_offset_t kva, off;
	vm_offset_t pa;
d253 1
a253 1
	addr = (caddr_t)trunc_page((vaddr_t)(bp->b_saveaddr = bp->b_data));
d265 1
d267 3
d281 2
a282 1
		if (pmap_extract(pmap, (vm_offset_t)addr, &pa) == FALSE)
d308 1
a308 1
	addr = trunc_page((vaddr_t)bp->b_data);
d311 1
d313 3
d321 2
a322 1
/*
d333 2
a334 2
	vm_offset_t	iova, tva, off, ppa;
	int 		s, error;
d344 12
a355 3
	s = splhigh();
	error = extent_alloc(iomap_extent, len, PAGE_SIZE, 0,
	    canwait ? EX_WAITSPACE : 0, &iova);
a356 3

	if (error != 0)
		return NULL;
d389 2
a390 2
	vm_offset_t 	off;
	int 		s, error;
d398 3
a400 2
	s = splhigh();
	error = extent_free(iomap_extent, kva, len, EX_NOWAIT);
a401 3
	if (error != 0)
		printf("iomap_mapout: extent_free failed\n");

d405 2
d443 1
a443 1
	pa = (caddr_t)trunc_page((paddr_t)pa);
d509 1
d512 1
a512 3
pagemove(from, to, size)
	caddr_t from, to;
	size_t size;
d514 1
a514 1
	vm_offset_t pa;
d517 1
a517 1
	if ((size & PAGE_MASK) != 0)
d521 1
a521 1
		pmap_extract(kernel_pmap, (vm_offset_t)from, &pa);
a522 1
#if 0
d525 1
a525 1
		if (pmap_extract(kernel_pmap, (vm_offset_t)to, XXX) != 0)
a527 1
#endif
d540 1
a540 2
kvtop(va)
	vm_offset_t va;
a541 1
	vm_offset_t pa;
d543 25
d569 10
a578 2
	pmap_extract(kernel_pmap, va, &pa);
	return ((u_int)pa);
d580 2
@


1.11.4.3
log
@Sync the SMP branch to something just after 3.0
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.11.4.2 2001/07/04 10:20:24 niklas Exp $	*/
d60 2
a64 1
#include <machine/cmmu.h>
d68 1
a69 1
#include <machine/trap.h>
a73 8
vm_offset_t iomap_mapin __P((vm_offset_t, vm_size_t, boolean_t));
void iomap_mapout __P((vm_offset_t, vm_size_t));
void *mapiodev __P((void *, int));
void unmapiodev __P((void *, int));
vm_offset_t mapiospace __P((caddr_t, int));
void unmapiospace __P((vm_offset_t));
int badpaddr __P((caddr_t, int));

d94 4
a97 2
	extern void proc_trampoline __P((void));
        extern void save_u_area __P((struct proc *, vm_offset_t));
d112 1
a112 1
	save_u_area(p2, (vm_offset_t)p2->p_addr);
d147 2
d180 2
d192 1
d206 1
a206 2
        extern void save_u_area __P((struct proc *, vm_offset_t));

d210 2
d276 1
a276 1
			   VM_PROT_READ|VM_PROT_WRITE, PMAP_WIRED);
d331 2
a332 2
	error = extent_alloc(iomap_extent, len, PAGE_SIZE, 0, EX_NOBOUNDARY,
	    canwait ? EX_WAITSPACE : EX_NOWAIT, &iova);
d350 1
a350 1
			   VM_PROT_WRITE|VM_PROT_READ|(CACHE_INH << 16), PMAP_WIRED);
d366 1
a366 1
void
a380 1

d383 2
d425 2
a426 2
	pmap_kenter_pa(phys_map_vaddr1, (vm_offset_t)pa,
	    VM_PROT_READ|VM_PROT_WRITE);
d440 1
a440 1
	pmap_kremove(va, PAGE_SIZE);
d462 2
d475 1
a475 1
	 * Do not allow crossing a page boundary.
d495 1
a495 2
	paddr_t pa;
	boolean_t rv;
d502 1
a502 1
		rv = pmap_extract(pmap_kernel(), (vaddr_t)from, &pa);
d504 2
a505 1
		if (rv == FALSE)
d507 1
a507 1
		if (pmap_extract(pmap_kernel(), (vaddr_t)to, NULL) == TRUE)
d510 9
a518 5
		pmap_kremove((vaddr_t)from, PAGE_SIZE);
		pmap_kenter_pa((vaddr_t)to, pa, VM_PROT_READ|VM_PROT_WRITE);
		from += PAGE_SIZE;
		to += PAGE_SIZE;
		size -= PAGE_SIZE;
d527 1
d529 1
a529 1
	pmap_extract(pmap_kernel(), va, &pa);
@


1.11.4.4
log
@Merge in -current
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d59 2
d92 1
a92 6
cpu_fork(p1, p2, stack, stacksize, func, arg)
	struct proc *p1, *p2;
	void *stack;
	size_t stacksize;
	void (*func) __P((void *));
	void *arg;
d97 1
a97 1
		void (*func) __P((void *));
d139 2
a140 2
	ksfp->func = func;
	ksfp->proc = arg;
d152 18
@


1.11.4.5
log
@Merge in -current
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.11.4.4 2001/11/13 21:04:15 niklas Exp $	*/
a60 2
#include <machine/mmu.h>
#include <machine/board.h>
d69 1
a69 1
extern struct vm_map *iomap_map;
@


1.11.4.6
log
@Merge in trunk
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d53 1
d67 1
a266 1
	pmap_update(pmap_kernel());
a340 1
	pmap_update(pmap_kernel());
a362 1
	pmap_update(vm_map_pmap(iomap_map));
a411 1
	pmap_update(pmap_kernel());
a425 1
	pmap_update(pmap_kernel());
d432 1
d439 1
a439 1
		x = *(unsigned char *volatile)va;
d442 1
a442 1
		x = *(unsigned short *volatile)va;
d445 1
a445 1
		x = *(unsigned long *volatile)va;
a446 2
	default:
                return -1;
d448 1
a448 1
	return(0);
a498 1
	pmap_update(pmap_kernel());
@


1.11.4.7
log
@Merge in -current from about a week ago
@
text
@d71 7
a77 7
vm_offset_t iomap_mapin(vm_offset_t, vm_size_t, boolean_t);
void iomap_mapout(vm_offset_t, vm_size_t);
void *mapiodev(void *, int);
void unmapiodev(void *, int);
vm_offset_t mapiospace(caddr_t, int);
void unmapiospace(vm_offset_t);
int badpaddr(caddr_t, int);
d94 1
a94 1
	void (*func)(void *);
d100 1
a100 1
		void (*func)(void *);
d104 2
a105 2
	extern void proc_trampoline(void);
        extern void save_u_area(struct proc *, vm_offset_t);
d191 1
a191 1
        extern void save_u_area(struct proc *, vm_offset_t);
@


1.11.4.8
log
@Sync the SMP branch with 3.3
@
text
@d260 1
a260 2
			   VM_PROT_READ | VM_PROT_WRITE,
			   VM_PROT_READ | VM_PROT_WRITE | PMAP_WIRED);
d335 1
a335 2
			   VM_PROT_WRITE | VM_PROT_READ |(CACHE_INH << 16),
			   VM_PROT_WRITE | VM_PROT_READ | PMAP_WIRED);
@


1.11.4.9
log
@Sync SMP branch to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.11.4.8 2003/03/27 23:32:19 niklas Exp $	*/
d23 5
a27 1
 * 3. Neither the name of the University nor the names of its contributors
a56 3
#include <sys/core.h>
#include <sys/exec.h>
#include <sys/ptrace.h>
d64 1
d98 1
d107 1
a174 3
/*
 * Dump the machine specific header information at the start of a core dump.
 */
d176 1
a176 5
cpu_coredump(p, vp, cred, chdr)
	struct proc *p;
	struct vnode *vp;
	struct ucred *cred;
	struct core *chdr;
d178 2
a179 32
	struct reg reg;
	struct coreseg cseg;
	int error;

	CORE_SETMAGIC(*chdr, COREMAGIC, MID_MACHINE, 0);
	chdr->c_hdrsize = ALIGN(sizeof(*chdr));
	chdr->c_seghdrsize = ALIGN(sizeof(cseg));
	chdr->c_cpusize = sizeof(reg);

	/* Save registers. */
	error = process_read_regs(p, &reg);
	if (error)
		return error;

	CORE_SETMAGIC(cseg, CORESEGMAGIC, MID_MACHINE, CORE_CPU);
	cseg.c_addr = 0;
	cseg.c_size = chdr->c_cpusize;

	error = vn_rdwr(UIO_WRITE, vp, (caddr_t)&cseg, chdr->c_seghdrsize,
	    (off_t)chdr->c_hdrsize, UIO_SYSSPACE, IO_NODELOCKED|IO_UNIT, cred,
	    NULL, p);
	if (error)
		return error;

	error = vn_rdwr(UIO_WRITE, vp, (caddr_t)&reg, sizeof(reg),
	    (off_t)(chdr->c_hdrsize + chdr->c_seghdrsize), UIO_SYSSPACE,
	    IO_NODELOCKED|IO_UNIT, cred, NULL, p);
	if (error)
		return error;

	chdr->c_nseg++;
	return 0;
@


1.11.4.10
log
@Merge of current from two weeks agointo the SMP branch
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d6 1
a6 1
 * Copyright (c) 1993 Adam Glass
a62 1
#include <machine/cpu_number.h>
d69 2
a70 2
vaddr_t iomap_mapin(paddr_t, psize_t, boolean_t);
void iomap_mapout(vaddr_t, vsize_t);
d73 3
d102 1
a102 1
        extern void save_u_area(struct proc *, vaddr_t);
d104 8
a111 9
	/* Copy pcb from p1 to p2. */
	if (p1 == curproc) {
		/* Sync the PCB before we copy it. */
		savectx(curpcb);
	}
#ifdef DIAGNOSTIC
	else if (p1 != &proc0)
		panic("cpu_fork: curproc");
#endif
d113 1
a113 3
	bcopy(&p1->p_addr->u_pcb, &p2->p_addr->u_pcb, sizeof(struct pcb));
	p2->p_addr->u_pcb.kernel_state.pcb_ipl = IPL_NONE;	/* XXX */
	p2->p_md.md_tf = (struct trapframe *)USER_REGS(p2);
d116 4
a119 1
	save_u_area(p2, (vaddr_t)p2->p_addr);
d164 1
a164 3
	pmap_deactivate(p);

	splhigh();
d224 1
a224 1
        extern void save_u_area(struct proc *, vaddr_t);
d226 1
a226 1
	save_u_area(p, (vaddr_t)p->p_addr);
d254 1
a254 1
	vsize_t len;
d256 3
a258 3
	caddr_t addr;
	vaddr_t kva, off;
	paddr_t pa;
d267 1
a267 1
	off = (vaddr_t)bp->b_saveaddr & PGOFSET;
d279 1
a279 1

d286 1
a286 1
	cmmu_flush_tlb(cpu_number(), 1, kva, len);
d290 1
a290 1
		if (pmap_extract(pmap, (vaddr_t)addr, &pa) == FALSE)
a294 2
		pmap_cache_ctrl(pmap_kernel(), kva, kva + PAGE_SIZE,
		    CACHE_WT | CACHE_GLOBAL);
d309 1
a309 1
	vsize_t len;
d311 1
a311 1
	vaddr_t addr, off;
d319 1
a319 1
	off = (vaddr_t)bp->b_data & PGOFSET;
d335 2
a336 2
vaddr_t
iomap_mapin(paddr_t pa, psize_t len, boolean_t canwait)
d338 2
a339 3
	vaddr_t	iova, tva, off;
	paddr_t ppa;
	int s, error;
d343 1
a343 1

d356 2
a357 2

	cmmu_flush_tlb(cpu_number(), 1, iova, len);	/* necessary? */
d365 1
a365 1
#endif
d369 1
a369 1
			   VM_PROT_WRITE | VM_PROT_READ,
d380 1
a380 1
#endif
d388 1
a388 1
iomap_mapout(vaddr_t kva, vsize_t len)
d390 1
a390 1
	vaddr_t 	off;
d417 2
a418 2
	paddr_t ppa;
	ppa = (paddr_t)pa;
d427 2
a428 2
	vaddr_t va;
	va = (vaddr_t)kva;
d432 34
d467 1
a467 1
badvaddr(vaddr_t va, int size)
d469 1
a469 2
	volatile int x;

d487 20
a506 1
	return (0);
d543 1
a543 1
	vaddr_t va;
d545 1
a545 1
	paddr_t pa;
a547 1
	/* XXX check for failure */
@


1.11.4.11
log
@Merge with the trunk
@
text
@a294 1
		/* make sure snooping will be possible... */
d296 1
a296 1
		    CACHE_GLOBAL);
d347 3
a349 2
	ppa = trunc_page(pa);
	off = pa & PGOFSET;
d362 3
d366 5
a370 1
	while (len != 0) {
d379 5
a384 1
	return (iova + off);
d490 11
@


1.10
log
@Change the pmap_enter api to pass down an argument that indicates
the access type that caused this mapping. This is to simplify pmaps
with mod/ref emulation (none for the moment) and in some cases speed
up pmap_is_{referenced,modified}.
At the same time, clean up some mappings that had too high protection.

XXX - the access type is incorrect in old vm, it's only used by uvm and MD code.
The actual use of this in pmap_enter implementations is not in this commit.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.9 1999/08/17 10:32:17 niklas Exp $	*/
d45 1
a45 1
 *	$Id: vm_machdep.c,v 1.9 1999/08/17 10:32:17 niklas Exp $
d62 1
d77 1
d88 1
d96 2
a97 1
	savectx(p1->p_addr);
d107 1
a107 1
	PMAP_ACTIVATE(&p2->p_vmspace->vm_pmap, &p2->p_addr->u_pcb, 0);
d123 1
a123 1
		USER_REGS(p2)->pcb_sp = (u_int)stack + stacksize;
d339 1
a339 1
   tva = iova;
d343 1
a343 1
   
d444 3
a446 9
	int i;
	int ret = 0;
	
	for (i=0; i<5; i++){
	    ret = badaddr(va, size);
	    if (ret) 
		delay(500);
	    else
		break;
a447 2
	if (ret) 
	    return -1;
@


1.9
log
@New cpu_fork API to take a stack in which you point the child's stackpointer
to, at the bottom or the top, depending on your architecture's stack growth
direction.  This is in preparation for Linux' clone(2) emulation.
port maintainers, please check that I did the work right.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.8 1999/05/29 04:41:47 smurph Exp $	*/
d45 1
a45 1
 *	$Id: vm_machdep.c,v 1.8 1999/05/29 04:41:47 smurph Exp $
d265 1
a265 1
			   VM_PROT_READ|VM_PROT_WRITE, TRUE);
d342 1
a342 1
		    	VM_PROT_WRITE|VM_PROT_READ|(CACHE_INH << 16), 1);
d419 1
a419 1
		   VM_PROT_READ|VM_PROT_WRITE, 1);
d512 2
a513 1
			   (vm_offset_t)to, pa, VM_PROT_READ|VM_PROT_WRITE, 1);
@


1.8
log
@Added vme bus device drivers. MVME328, MVME376, MVME332
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.7 1999/02/09 06:36:30 smurph Exp $	*/
d45 1
a45 1
 *	$Id: vm_machdep.c,v 1.7 1999/02/09 06:36:30 smurph Exp $
d82 1
a82 1
cpu_fork(struct proc *p1, struct proc *p2)
d114 6
@


1.7
log
@Added kernel support for user debugging.  Fixed file ID's
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_machdep.c,v 1.28 1995/04/19 22:37:27 smurph Exp $	*/
d45 1
a45 1
 *	$Id: vm_machdep.c,v 1.6 1999/01/10 13:34:18 niklas Exp $
a63 1
#ifdef XXX_FUTURE
d65 1
a65 2
#endif
extern struct map extiomap;
d305 2
a306 1
	off = (u_long)pa & PGOFSET;
d312 1
a312 1
		iova = rmalloc(&extiomap, len);
d316 1
a316 1
			(void)tsleep(&extiomap, PRIBIO+1, "iomapin", 0);
d323 2
d326 1
a326 2
	tva = iova;
	pa = trunc_page(pa);
d328 9
a336 3
	while (len) {
		pmap_enter(kernel_pmap, tva, pa,
		    	VM_PROT_READ|VM_PROT_WRITE, 1);
d341 1
d343 4
d362 1
a362 1
	pmap_remove(kernel_pmap, kva, kva + len);
d365 2
a366 2
	rmfree(&extiomap, len, kva);
	wakeup(&extiomap);
d434 9
a442 3

	if (badaddr(va, size)) {
		return -1;
d444 2
@


1.6
log
@Generalize cpu_set_kpc to take any kind of arg; mostly from NetBSD
@
text
@d1 1
d45 1
a45 1
 *	$Id: vm_machdep.c,v 1.5 1998/12/15 05:11:03 smurph Exp $
@


1.5
log
@Commit for the first working mvme88k port.
@
text
@d44 1
a44 1
 *	$Id: vm_machdep.c,v 1.4 1998/07/28 00:13:46 millert Exp $
d140 1
a140 1
cpu_set_kpc(struct proc *p, void (*func)(struct proc *))
d147 2
a148 2
		void (*func)(struct proc *);
		void *proc;
d154 1
a154 1

@


1.4
log
@Return EINVAL when msg_iovlen or iovcnt <= 0; Make uio_resid unsigned (size_t) and don't return EINVAL if it is < 0 in sys_{read,write}.  Remove check for uio_resid < 0 uiomove() now that uio_resid is unsigned and brack remaining panics with #ifdef DIAGNOSTIC.  vn_rdwr() must now take a size_t * as its 9th argument so change that and clean up uses of vn_rdwr().  Fixes 549 + more
@
text
@d2 1
d44 1
a44 1
 *	$Id: vm_machdep.c,v 1.3 1997/03/03 20:21:54 rahnds Exp $
d51 1
d61 1
d66 1
d103 1
a103 1
#ifdef notneeded
d111 1
d165 1
a165 1
volatile void
d287 3
a289 2
#ifdef XXX_FUTURE
/*
d300 1
a300 1
	vm_offset_t		iova, tva, off;
d305 1
a305 1

d312 1
a312 1
		iova = rmalloc(iomap, len);
d316 1
a316 1
			(void)tsleep(iomap, PRIBIO+1, "iomapin", 0);
d332 1
a332 1
		pa += PAGE_SIZE;
d350 1
a350 1
	pmap_remove(pmap_kernel(), kva, kva + len);
d353 2
a354 2
	rmfree(iomap, len, kva);
	wakeup(iomap);
d356 1
d358 1
d360 26
d500 37
@


1.3
log
@Cleanup after import. This also seems to bring up the current version.
@
text
@d43 1
a43 1
 *	$Id: vm_machdep.c,v 1.1.1.1 1997/03/03 19:32:25 rahnds Exp $
d177 1
a177 2
	    (off_t)0, UIO_SYSSPACE, IO_NODELOCKED|IO_UNIT, cred, (int *)NULL,
	    p));
@


1.2
log
@This is a remove to get rid of the old mvme88k port which was incomplete
to replace it with a working version. The kernel compiles and works
at least.  The new version will be imported shortly.
@
text
@d2 1
d43 1
a43 1
 *	$Id: vm_machdep.c,v 1.1 1995/10/18 12:32:35 deraadt Exp $
d60 4
d73 6
d81 1
a81 1
	register struct user *up = p2->p_addr;
d83 6
a88 3
	caddr_t sp;
	extern caddr_t getsp();
	extern char kstack[];
d90 12
a101 1
	p2->p_md.md_tf = p1->p_md.md_tf;
d104 1
a104 9
	 * Copy pcb and stack from proc p1 to p2. 
	 * We do this as cheaply as possible, copying only the active
	 * part of the stack.  The stack and pcb need to agree;
	 * this is tricky, as the final pcb is constructed by savectx,
	 * but its frame isn't yet on the stack when the stack is copied.
	 * cpu_switch compensates for this when the child eventually runs.
	 * This should be done differently, with a single call
	 * that copies and updates the pcb+stack,
	 * replacing the bcopy and savectx.
d106 27
a132 13
	p2->p_addr->u_pcb = p1->p_addr->u_pcb;
	sp = getsp();
	ssz = (unsigned int)UADDR + UPAGES * NBPG - (unsigned int)sp;
	off = (unsigned int)sp - (unsigned int)UADDR;
#if 0
	bcopy((caddr_t)(UADDR + off), (caddr_t)((unsigned int)p2->p_addr + off),
			 ssz);
#endif /* 0 */
	/* copy from UADDR to p2 */
	memcpy((caddr_t)((unsigned int)p2->p_addr + off),
		(caddr_t)(UADDR + off), ssz);
	save_u_area(p2, p2->p_addr);
	PMAP_ACTIVATE(&p2->p_vmspace->vm_pmap, &up->u_pcb, 0);
d134 3
d138 1
a138 2
	 * Arrange for a non-local goto when the new process
	 * is started, to resume here, returning nonzero from setjmp.
d140 10
a149 7
	if (savectx(up, 1)) {
		/*
		 * Return 1 in child.
		 */
		return (1);
	}
	return (0);
d173 1
a173 1
cpu_coredump(struct proc *p, struct vnode *vp, struct ucred *cred)
d210 1
a210 2
 * All requests are (re)mapped into kernel VA space via the useriomap
 * (a name with only slightly more meaning than "kernelmap")
d218 1
a218 1
vmapbuf(struct buf *bp)
a219 1
	register int npf;
d221 1
a221 1
	register long flags = bp->b_flags;
a222 3
	int off;
	vm_offset_t kva;
	register vm_offset_t pa;
d224 1
a224 1
	if ((flags & B_PHYS) == 0)
d226 4
a229 2
	addr = bp->b_saveaddr = bp->b_data;
	off = (int)addr & PGOFSET;
a230 1
	npf = btoc(round_page(bp->b_bcount + off));
d233 1
a233 1
	 * Why phys_map? kernelmap should be OK - after all, the
d235 10
a244 1
	 * kernel va to another kernel va. XXX -nivas
d247 4
a250 3
	kva = kmem_alloc_wait(phys_map, ctob(npf));
	bp->b_data = (caddr_t) (kva + off);
	while (npf--) {
d255 1
a255 1
		pmap_enter(vm_map_pmap(phys_map), kva, trunc_page(pa),
d259 1
d265 1
a265 1
 * We also invalidate the TLB entries and restore the original b_addr.
d268 1
a268 1
vunmapbuf(struct buf *bp)
d270 1
a270 3
	register caddr_t addr;
	register int npf;
	vm_offset_t kva;
d274 5
a278 4
	addr = bp->b_data;
	npf = btoc(round_page(bp->b_bcount + ((int)addr & PGOFSET)));
	kva = (vm_offset_t)((int)addr & ~PGOFSET);
	kmem_free_wakeup(phys_map, kva, ctob(npf));
d280 1
a280 1
	bp->b_saveaddr = NULL;
d283 11
a293 2
caddr_t
obio_vm_alloc(int npages)
d295 132
a426 13
    vm_size_t size;
    vm_offset_t addr;
    int result;

    if (npages == 0);
    size = npages*NBPG;
    addr = vm_map_min(phys_map);
    result = vm_map_find(phys_map, NULL, (vm_offset_t) 0, &addr, size, TRUE);
    if (result != KERN_SUCCESS) return NULL;
    vm_map_lock(phys_map);
    vm_map_delete(phys_map, addr, addr+size);
    vm_map_unlock(phys_map);
    return (caddr_t) addr;
d431 1
a431 2
 * Both addresses are assumed to reside in the Sysmap,
 * and size must be a multiple of CLSIZE.
d434 1
a434 1
pagemove(caddr_t from, caddr_t to, int size)
d458 8
@


1.1
log
@moved from m88k directory
@
text
@d42 1
a42 1
 *	$Id: vm_machdep.c,v 1.1.1.1 1995/10/18 10:54:27 deraadt Exp $
@


1.1.1.1
log
@Third try at importing the mvme88k port. This is a working kernel
from nivas.
Userland and compiler still need to be worked on.
Make certain what directory the import is done from.
@
text
@a1 1
 * Copyright (c) 1996 Nivas Madhur
d42 1
a42 1
 *	$Id: vm_machdep.c,v 1.5 1996/08/02 02:44:31 build Exp build $
a58 4
#ifdef XXX_FUTURE
extern struct map *iomap;
#endif

a67 6

#ifdef __FORK_BRAINDAMAGE
int
#else
void
#endif
d70 1
a70 1
	struct switchframe *p2sf;
d72 3
a74 6
	struct ksigframe {
		void (*func)(struct proc *);
		void *proc;
	} *ksfp;
	extern void proc_do_uret(), child_return();
	extern void proc_trampoline();
d76 1
a76 12
	savectx(p1->p_addr);

	bcopy((void *)&p1->p_addr->u_pcb, (void *)&p2->p_addr->u_pcb, sizeof(struct pcb));
	p2->p_addr->u_pcb.kernel_state.pcb_ipl = 0;

	p2->p_md.md_tf = USER_REGS(p2);

	/*XXX these may not be necessary nivas */
	save_u_area(p2, p2->p_addr);
#ifdef notneeded
	PMAP_ACTIVATE(&p2->p_vmspace->vm_pmap, &p2->p_addr->u_pcb, 0);
#endif /* notneeded */
d79 9
a87 1
	 * Create a switch frame for proc 2
d89 13
a101 9
	p2sf = (struct switchframe *)((char *)p2->p_addr + USPACE - 8) - 1;
	p2sf->sf_pc = (u_int)proc_do_uret;
	p2sf->sf_proc = p2;
	p2->p_addr->u_pcb.kernel_state.pcb_sp = (u_int)p2sf;

	ksfp = (struct ksigframe *)p2->p_addr->u_pcb.kernel_state.pcb_sp - 1;

	ksfp->func = child_return;
	ksfp->proc = p2;
d104 2
a105 5
	 * When this process resumes, r31 will be ksfp and
	 * the process will be at the beginning of proc_trampoline().
	 * proc_trampoline will execute the function func, pop off
	 * ksfp frame, and call the function in the switchframe
	 * now exposed.
d107 7
a113 27

	p2->p_addr->u_pcb.kernel_state.pcb_sp = (u_int)ksfp;
	p2->p_addr->u_pcb.kernel_state.pcb_pc = (u_int)proc_trampoline;

#ifdef __FORK_BRAINDAMAGE
	return(0);
#else
	return;
#endif
}

void
cpu_set_kpc(struct proc *p, void (*func)(struct proc *))
{
	/*
	 * override func pointer in ksigframe with func.
	 */

	struct ksigframe {
		void (*func)(struct proc *);
		void *proc;
	} *ksfp;

	ksfp = (struct ksigframe *)p->p_addr->u_pcb.kernel_state.pcb_sp;

	ksfp->func = func;

d137 1
a137 1
cpu_coredump(struct proc *p, struct vnode *vp, struct ucred *cred, struct core *corep)
d174 2
a175 1
 * All requests are (re)mapped into kernel VA space via phys_map
d183 1
a183 1
vmapbuf(struct buf *bp, vm_size_t len)
d185 1
d187 1
a187 1
	register vm_offset_t pa, kva, off;
d189 3
d193 1
a193 1
	if ((bp->b_flags & B_PHYS) == 0)
d195 2
a196 4

	addr = (caddr_t)trunc_page(bp->b_saveaddr = bp->b_data);
	off = (vm_offset_t)bp->b_saveaddr & PGOFSET;
	len = round_page(off + len);
d198 1
d201 1
a201 1
	 * You may ask: Why phys_map? kernel_map should be OK - after all,
d203 1
a203 10
	 * kernel va to another kernel va. The answer is TLB flushing
	 * when the address gets a new mapping.
	 */

	kva = kmem_alloc_wait(phys_map, len);
	
	/*
	 * Flush the TLB for the range [kva, kva + off]. Strictly speaking,
	 * we should do this in vunmapbuf(), but we do it lazily here, when
	 * new pages get mapped in.
d206 3
a208 4
	cmmu_flush_tlb(1, kva, len);

	bp->b_data = (caddr_t)(kva + off);
	while (len > 0) {
d213 1
a213 1
		pmap_enter(vm_map_pmap(phys_map), kva, pa,
a216 1
		len -= PAGE_SIZE;
d222 1
a222 1
 * We also restore the original b_addr.
d225 1
a225 1
vunmapbuf(struct buf *bp, vm_size_t len)
d227 3
a229 1
	register vm_offset_t addr, off;
d233 4
a236 5

	addr = trunc_page(bp->b_data);
	off = (vm_offset_t)bp->b_data & PGOFSET;
	len = round_page(off + len);
	kmem_free_wakeup(phys_map, addr, len);
d238 1
a238 1
	bp->b_saveaddr = 0;
d241 2
a242 11
#ifdef XXX_FUTURE
/*
 * Map a range [pa, pa+len] in the given map to a kernel address
 * in iomap space.
 *
 * Note: To be flexible, I did not put a restriction on the alignment
 * of pa. However, it is advisable to have pa page aligned since otherwise,
 * we might have several mappings for a given chunk of the IO page.
 */
vm_offset_t
iomap_mapin(vm_offset_t pa, vm_size_t len, boolean_t canwait)
d244 13
a256 132
	vm_offset_t		iova, tva, off;
	register int 		npf, s;

	if (len == 0)
		return NULL;

	off = (u_long)pa & PGOFSET;

	len = round_page(off + len);

	s = splimp();
	for (;;) {
		iova = rmalloc(iomap, len);
		if (iova != 0)
			break;
		if (canwait) {
			(void)tsleep(iomap, PRIBIO+1, "iomapin", 0);
			continue;
		}
		splx(s);
		return NULL;
	}
	splx(s);

	tva = iova;
	pa = trunc_page(pa);

	while (len) {
		pmap_enter(kernel_pmap, tva, pa,
		    	VM_PROT_READ|VM_PROT_WRITE, 1);
		len -= PAGE_SIZE;
		tva += PAGE_SIZE;
		pa += PAGE_SIZE;
	}
	return (iova + off);
}

/*
 * Free up the mapping in iomap.
 */
int
iomap_mapout(vm_offset_t kva, vm_size_t len)
{
	register int 		s;
	vm_offset_t 		off;

	off = kva & PGOFSET;
	kva = trunc_page(kva);
	len = round_page(off + len);

	pmap_remove(pmap_kernel(), kva, kva + len);

	s = splimp();
	rmfree(iomap, len, kva);
	wakeup(iomap);
	splx(s);
}
#endif /* XXX_FUTURE */
/*
 * Map the given physical IO address into the kernel temporarily.
 * Maps one page.
 * Should have some sort of lockig for the use of phys_map_vaddr. XXX nivas
 */

vm_offset_t
mapiospace(caddr_t pa, int len)
{
	int off = (u_long)pa & PGOFSET;
	extern vm_offset_t phys_map_vaddr1;

	pa = (caddr_t)trunc_page(pa);

	pmap_enter(kernel_pmap, phys_map_vaddr1, (vm_offset_t)pa,
		   VM_PROT_READ|VM_PROT_WRITE, 1);
	
	return (phys_map_vaddr1 + off);
}

/*
 * Unmap the address from above.
 */

void
unmapiospace(vm_offset_t va)
{
	va = trunc_page(va);

	pmap_remove(kernel_pmap, va, va + NBPG);
}

int
badvaddr(vm_offset_t va, int size)
{
	register int 	x;

	if (badaddr(va, size)) {
		return -1;
	}

	switch (size) {
	case 1:
		x = *(volatile unsigned char *)va;
		break;
	case 2:
		x = *(volatile unsigned short *)va;
		break;
	case 4:
		x = *(volatile unsigned long *)va;
		break;
	default:
		break;	
	}
	return(x);
}

int
badpaddr(caddr_t pa, int size)
{
	vm_offset_t va;
	int val;

	/*
	 * Do not allow crossing the page boundary.
	 */
	if (((int)pa & PGOFSET) + size > NBPG) {
		return -1;
	}

	va = mapiospace(pa, NBPG);
	val = badvaddr(va, size);
	unmapiospace(va);
	return (val);
d261 2
a262 1
 * Size must be a multiple of CLSIZE.
d265 1
a265 1
pagemove(caddr_t from, caddr_t to, size_t size)
a288 8
}

u_int
kvtop(vm_offset_t va)
{
	extern pmap_t kernel_pmap;

	return ((u_int)pmap_extract(kernel_pmap, va));
@
