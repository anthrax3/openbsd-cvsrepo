head	1.50;
access;
symbols
	OPENBSD_5_5:1.49.0.4
	OPENBSD_5_5_BASE:1.49
	OPENBSD_5_4:1.48.0.2
	OPENBSD_5_4_BASE:1.48
	OPENBSD_5_3:1.47.0.2
	OPENBSD_5_3_BASE:1.47
	OPENBSD_5_2:1.46.0.4
	OPENBSD_5_2_BASE:1.46
	OPENBSD_5_1_BASE:1.46
	OPENBSD_5_1:1.46.0.2
	OPENBSD_5_0:1.45.0.4
	OPENBSD_5_0_BASE:1.45
	OPENBSD_4_9:1.45.0.2
	OPENBSD_4_9_BASE:1.45
	OPENBSD_4_8:1.42.0.2
	OPENBSD_4_8_BASE:1.42
	OPENBSD_4_7:1.41.0.2
	OPENBSD_4_7_BASE:1.41
	OPENBSD_4_6:1.40.0.4
	OPENBSD_4_6_BASE:1.40
	OPENBSD_4_5:1.38.0.2
	OPENBSD_4_5_BASE:1.38
	OPENBSD_4_4:1.26.0.4
	OPENBSD_4_4_BASE:1.26
	OPENBSD_4_3:1.26.0.2
	OPENBSD_4_3_BASE:1.26
	OPENBSD_4_2:1.14.0.2
	OPENBSD_4_2_BASE:1.14
	OPENBSD_4_1:1.12.0.4
	OPENBSD_4_1_BASE:1.12
	OPENBSD_4_0:1.12.0.2
	OPENBSD_4_0_BASE:1.12
	OPENBSD_3_9:1.7.0.4
	OPENBSD_3_9_BASE:1.7
	OPENBSD_3_8:1.7.0.2
	OPENBSD_3_8_BASE:1.7
	OPENBSD_3_7:1.5.0.2
	OPENBSD_3_7_BASE:1.5;
locks; strict;
comment	@ * @;


1.50
date	2014.03.18.22.36.36;	author miod;	state dead;
branches;
next	1.49;

1.49
date	2014.01.21.23.54.48;	author jsg;	state Exp;
branches;
next	1.48;

1.48
date	2013.05.17.22.46.28;	author miod;	state Exp;
branches;
next	1.47;

1.47
date	2013.02.17.18.07.36;	author miod;	state Exp;
branches;
next	1.46;

1.46
date	2011.10.25.18.38.06;	author miod;	state Exp;
branches;
next	1.45;

1.45
date	2011.01.05.22.14.39;	author miod;	state Exp;
branches;
next	1.44;

1.44
date	2010.12.31.21.38.08;	author miod;	state Exp;
branches;
next	1.43;

1.43
date	2010.12.31.20.54.21;	author miod;	state Exp;
branches;
next	1.42;

1.42
date	2010.06.22.17.42.37;	author miod;	state Exp;
branches;
next	1.41;

1.41
date	2009.08.30.12.11.35;	author miod;	state Exp;
branches;
next	1.40;

1.40
date	2009.03.15.20.39.53;	author miod;	state Exp;
branches;
next	1.39;

1.39
date	2009.03.04.19.39.41;	author miod;	state Exp;
branches;
next	1.38;

1.38
date	2009.03.01.17.44.46;	author miod;	state Exp;
branches;
next	1.37;

1.37
date	2009.02.27.05.19.36;	author miod;	state Exp;
branches;
next	1.36;

1.36
date	2009.02.21.18.37.49;	author miod;	state Exp;
branches;
next	1.35;

1.35
date	2009.02.21.18.35.22;	author miod;	state Exp;
branches;
next	1.34;

1.34
date	2009.02.17.21.04.01;	author miod;	state Exp;
branches;
next	1.33;

1.33
date	2009.02.16.23.03.33;	author miod;	state Exp;
branches;
next	1.32;

1.32
date	2009.02.16.22.55.03;	author miod;	state Exp;
branches;
next	1.31;

1.31
date	2009.02.13.23.33.51;	author miod;	state Exp;
branches;
next	1.30;

1.30
date	2009.02.13.23.28.07;	author miod;	state Exp;
branches;
next	1.29;

1.29
date	2009.02.13.23.26.51;	author miod;	state Exp;
branches;
next	1.28;

1.28
date	2009.02.08.21.40.58;	author miod;	state Exp;
branches;
next	1.27;

1.27
date	2008.09.19.20.18.03;	author miod;	state Exp;
branches;
next	1.26;

1.26
date	2007.12.27.23.20.31;	author miod;	state Exp;
branches;
next	1.25;

1.25
date	2007.12.26.22.21.41;	author miod;	state Exp;
branches;
next	1.24;

1.24
date	2007.12.25.21.13.11;	author miod;	state Exp;
branches;
next	1.23;

1.23
date	2007.12.15.21.19.48;	author miod;	state Exp;
branches;
next	1.22;

1.22
date	2007.12.15.19.37.41;	author miod;	state Exp;
branches;
next	1.21;

1.21
date	2007.12.15.19.34.35;	author miod;	state Exp;
branches;
next	1.20;

1.20
date	2007.12.04.23.45.53;	author miod;	state Exp;
branches;
next	1.19;

1.19
date	2007.12.02.21.32.10;	author miod;	state Exp;
branches;
next	1.18;

1.18
date	2007.11.24.14.17.17;	author miod;	state Exp;
branches;
next	1.17;

1.17
date	2007.11.22.23.33.42;	author miod;	state Exp;
branches;
next	1.16;

1.16
date	2007.11.17.05.36.23;	author miod;	state Exp;
branches;
next	1.15;

1.15
date	2007.11.17.05.32.05;	author miod;	state Exp;
branches;
next	1.14;

1.14
date	2007.05.14.16.59.43;	author miod;	state Exp;
branches;
next	1.13;

1.13
date	2007.05.12.20.02.14;	author miod;	state Exp;
branches;
next	1.12;

1.12
date	2006.05.08.14.36.10;	author miod;	state Exp;
branches;
next	1.11;

1.11
date	2006.04.27.20.21.19;	author miod;	state Exp;
branches;
next	1.10;

1.10
date	2006.04.27.20.19.31;	author miod;	state Exp;
branches;
next	1.9;

1.9
date	2006.04.19.22.09.40;	author miod;	state Exp;
branches;
next	1.8;

1.8
date	2006.04.13.21.16.17;	author miod;	state Exp;
branches;
next	1.7;

1.7
date	2005.04.30.16.42.37;	author miod;	state Exp;
branches;
next	1.6;

1.6
date	2005.04.27.14.07.38;	author miod;	state Exp;
branches;
next	1.5;

1.5
date	2004.12.24.22.50.30;	author miod;	state Exp;
branches;
next	1.4;

1.4
date	2004.11.09.21.50.01;	author miod;	state Exp;
branches;
next	1.3;

1.3
date	2004.11.09.12.01.19;	author miod;	state Exp;
branches;
next	1.2;

1.2
date	2004.11.08.16.39.31;	author miod;	state Exp;
branches;
next	1.1;

1.1
date	2004.10.01.19.00.52;	author miod;	state Exp;
branches;
next	;


desc
@@


1.50
log
@Retire hp300, mvme68k and mvme88k ports. These ports have no users, keeping
this hardware alive is becoming increasingly difficult, and I should heed the
message sent by the three disks which have died on me over the last few days.

Noone sane will mourn these ports anyway. So long, and thanks for the fish.
@
text
@/*	$OpenBSD: m197_machdep.c,v 1.49 2014/01/21 23:54:48 jsg Exp $	*/

/*
 * Copyright (c) 2009 Miodrag Vallat.
 *
 * Permission to use, copy, modify, and distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 */
/*
 * Copyright (c) 1998, 1999, 2000, 2001 Steve Murphree, Jr.
 * Copyright (c) 1996 Nivas Madhur
 * All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *      This product includes software developed by Nivas Madhur.
 * 4. The name of the author may not be used to endorse or promote products
 *    derived from this software without specific prior written permission
 *
 * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR
 * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
 * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
 * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,
 * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
 * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
 * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
 * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF
 * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 *
 */
/*
 * Mach Operating System
 * Copyright (c) 1993-1991 Carnegie Mellon University
 * Copyright (c) 1991 OMRON Corporation
 * All Rights Reserved.
 *
 * Permission to use, copy, modify and distribute this software and its
 * documentation is hereby granted, provided that both the copyright
 * notice and this permission notice appear in all copies of the
 * software, derivative works or modified versions, and any portions
 * thereof, and that both notices appear in supporting documentation.
 *
 */

#include <sys/param.h>
#include <sys/systm.h>
#include <sys/kernel.h>
#include <sys/errno.h>

#include <uvm/uvm_extern.h>

#include <machine/asm_macro.h>
#include <machine/board.h>
#include <machine/bugio.h>
#include <machine/cmmu.h>
#include <machine/cpu.h>
#include <machine/pmap_table.h>
#include <machine/reg.h>
#include <machine/trap.h>

#include <machine/m88410.h>
#include <machine/mvme197.h>

#include <mvme88k/dev/busswreg.h>
#include <mvme88k/mvme88k/clockvar.h>

#ifdef MULTIPROCESSOR
#include <machine/db_machdep.h>
#endif

extern const struct cmmu_p cmmu88110;
extern const struct cmmu_p cmmu88410;

const struct pmap_table m197_pmap_table[] = {
	/* We need flash 1:1 mapped to access the 88410 chip underneath */
	{ FLASH_START,		FLASH_SIZE,	UVM_PROT_RW, CACHE_INH },
	{ OBIO197_START,	OBIO197_SIZE,	UVM_PROT_RW, CACHE_INH },
	/* No need to mention BUG here - it is contained inside OBIO */
	{ 0, 0xffffffff, 0, 0 },
};

extern void m1x7_reboot(int);

const struct board board_mvme197le = {
	.bootstrap = m197_bootstrap,
	.memsize = m197_memsize,
	.cpuspeed = m197_cpuspeed,
	.reboot = m1x7_reboot,
	.is_syscon = m1x7_is_syscon,
	.intr = m197_intr,
	.nmi = m197_nmi,
	.nmi_wrapup = m197_nmi_wrapup,
	.getipl = m197_getipl,
	.setipl = m197_setipl,
	.raiseipl = m197_raiseipl,
	.intsrc_available = m1x7_intsrc_available,
	.intsrc_enable = m1x7_intsrc_enable,
	.intsrc_disable = NULL,
	.intsrc_establish = NULL,
	.intsrc_disestablish = NULL,
	.init_clocks = m1x7_init_clocks,
	.delay = m1x7_delay,
	.init_vme = m1x7_init_vme,
#ifdef MULTIPROCESSOR
	.send_ipi = m197_send_ipi,
	.smp_setup = m197_smp_setup,
#endif
	.ptable = m197_pmap_table,
	.cmmu = &cmmu88110
};

void	m197spdp_bootstrap(void);

const struct board board_mvme197spdp = {
	.bootstrap = m197spdp_bootstrap,
	.memsize = m197_memsize,
	.cpuspeed = m197_cpuspeed,
	.reboot = m1x7_reboot,
	.is_syscon = m1x7_is_syscon,
	.intr = m197_intr,
	.nmi = m197_nmi,
	.nmi_wrapup = m197_nmi_wrapup,
	.getipl = m197_getipl,
	.setipl = m197_setipl,
	.raiseipl = m197_raiseipl,
	.intsrc_available = m1x7_intsrc_available,
	.intsrc_enable = m1x7_intsrc_enable,
	.intsrc_disable = NULL,
	.intsrc_establish = NULL,
	.intsrc_disestablish = NULL,
	.init_clocks = m1x7_init_clocks,
#ifdef MULTIPROCESSOR
	.delay = m197_delay,
#else
	.delay = m1x7_delay,
#endif
	.init_vme = m1x7_init_vme,
#ifdef MULTIPROCESSOR
	.send_ipi = m197_send_ipi,
	.smp_setup = m197_smp_setup,
#endif
	.ptable = m197_pmap_table,
	.cmmu = &cmmu88410
};

int	m197_ipi_handler(struct trapframe *);
uint32_t m197_mp_atomic_begin(__cpu_simple_lock_t *, uint *);
void	m197_mp_atomic_end(uint32_t, __cpu_simple_lock_t *, uint);
void	m197_soft_ipi(void);

void
m197_bootstrap()
{
	u_int8_t version, btimer, pbt;

	/*
	 * Kernels running without snooping enabled (i.e. without
	 * CACHE_GLOBAL set in the apr in pmap.c) need increased processor
	 * bus timeout limits, or the instruction cache might not be able
	 * to fill or answer fast enough. It does not hurt to increase
	 * them unconditionnaly, though.
	 *
	 * Do this as soon as possible (i.e. now...), since this is
	 * especially critical on 40MHz boards, while some 50MHz boards can
	 * run without this timeout change... but better be safe than sorry.
	 *
	 * Boot blocks do this for us now, but again, better stay on the
	 * safe side. Be sure to update the boot blocks code if the logic
	 * below changes.
	 */
	version = *(volatile u_int8_t *)(BS_BASE + BS_CHIPREV);
	btimer = *(volatile u_int8_t *)(BS_BASE + BS_BTIMER);
	pbt = btimer & BS_BTIMER_PBT_MASK;
	btimer &= ~BS_BTIMER_PBT_MASK;
	
	/* XXX PBT256 might only be necessary for busswitch rev1? */
	if (m197_cpuspeed(NULL) < 50 || version <= 0x01) {
		if (pbt < BS_BTIMER_PBT256)
			pbt = BS_BTIMER_PBT256;
	} else {
		if (pbt < BS_BTIMER_PBT64)
			pbt = BS_BTIMER_PBT64;
	}

	*(volatile u_int8_t *)(BS_BASE + BS_BTIMER) = btimer | pbt;
}

void
m197spdp_bootstrap()
{
	u_int16_t cpu;

	/*
	 * Make sure all interrupts (levels 1 to 7) get routed to the boot cpu.
	 *
	 * We only need to write to one ISEL registers, this will set the
	 * correct value in the other one, since we set all the active bits.
	 */
	cpu = *(u_int16_t *)(BS_BASE + BS_GCSR) & BS_GCSR_CPUID;
	*(u_int8_t *)(BS_BASE + (cpu ? BS_ISEL1 : BS_ISEL0)) = 0xfe;

	m197_bootstrap();
}

/*
 * Figure out how much real memory is available.
 *
 * This relies on the fact that the BUG will configure the BusSwitch
 * system translation decoders to allow access to the whole memory
 * from address zero.
 *
 * If the BUG is not configured correctly wrt to the real amount of
 * memory in the system, this will return incorrect values, but we do
 * not care if you can't configure your system correctly.
 */
vaddr_t
m197_memsize()
{
	int i;
	u_int8_t sar;
	u_int16_t ssar, sear;
	struct mvmeprom_brdid brdid;

	/*
	 * MVME197LE 01-W3869B0[12][EF] boards shipped with a broken DCAM2
	 * chip, which can only address 32MB of memory. Unfortunately, 02[EF]
	 * were fitted with 64MB...
	 * Note that we can't decide on letter < F since this would match
	 * post-Z boards (AA, AB, etc).
	 *
	 * If the CNFG memory has been lost, you're on your own...
	 */
	bzero(&brdid, sizeof(brdid));
	bugbrdid(&brdid);
	if (bcmp(brdid.pwa, "01-W3869B02", 11) == 0) {
		if (brdid.pwa[11] == 'E' || brdid.pwa[11] == 'F')
			return (32 * 1024 * 1024);
	}

	for (i = 0; i < 4; i++) {
		sar = *(u_int8_t *)(BS_BASE + BS_SAR + i);
		if (!ISSET(sar, BS_SAR_DEN))
			continue;

		ssar = *(u_int16_t *)(BS_BASE + BS_SSAR1 + i * 4);
		sear = *(u_int16_t *)(BS_BASE + BS_SEAR1 + i * 4);

		if (ssar != 0)
			continue;

		return ((sear + 1) << 16);
	}

	/*
	 * If no decoder was enabled, how could we run so far?
	 * Return a ``safe'' 32MB.
	 */
	return (32 * 1024 * 1024);
}

/*
 * Return the processor speed in MHz.
 */
int
m197_cpuspeed(const struct mvmeprom_brdid *brdid)
{
	/*
	 * Find out the processor speed, from the BusSwitch prescaler
	 * adjust register.
	 */
	return 256 - *(volatile u_int8_t *)(BS_BASE + BS_PADJUST);
}

/*
 * Device interrupt handler for MVME197
 */
void
m197_intr(struct trapframe *eframe)
{
	u_int32_t psr;
	int level;
	struct intrhand *intr;
	intrhand_t *list;
	int ret;
	vaddr_t ivec;
	u_int8_t vec;

#ifdef MULTIPROCESSOR
	if (eframe->tf_mask < IPL_SCHED)
		__mp_lock(&kernel_lock);
#endif

	uvmexp.intrs++;

	level = *(u_int8_t *)M197_ILEVEL & 0x07;
	/* generate IACK and get the vector */
	ivec = M197_IACK + (level << 2) + 0x03;
	vec = *(volatile u_int8_t *)ivec;

	/* block interrupts at level or lower */
	m197_setipl(level);
	psr = get_psr();
	set_psr(psr & ~PSR_IND);

	list = &intr_handlers[vec];
	if (SLIST_EMPTY(list))
		printf("Spurious interrupt (level %x and vec %x)\n",
		    level, vec);

	/*
	 * Walk through all interrupt handlers in the chain for the
	 * given vector, calling each handler in turn, till some handler
	 * returns a value != 0.
	 */

	ret = 0;
	SLIST_FOREACH(intr, list, ih_link) {
		if (intr->ih_wantframe != 0)
			ret = (*intr->ih_fn)((void *)eframe);
		else
			ret = (*intr->ih_fn)(intr->ih_arg);
		if (ret != 0) {
			intr->ih_count.ec_count++;
			break;
		}
	}

	if (ret == 0) {
		printf("Unclaimed interrupt (level %x and vec %x)\n",
		    level, vec);
	}

#if 0
	/*
	 * Disable interrupts before returning to assembler,
	 * the spl will be restored later.
	 */
	set_psr(psr | PSR_IND);
#endif

#ifdef MULTIPROCESSOR
	if (eframe->tf_mask < IPL_SCHED)
		__mp_unlock(&kernel_lock);
#endif
}

/*
 * NMI handler. Invoked with interrupts disabled.
 * Returns nonzero if NMI have been reenabled, and the exception handler
 * is allowed to run soft interrupts and AST; nonzero otherwise.
 */
int
m197_nmi(struct trapframe *eframe)
{
	u_int8_t abort;
	int rc;

	/*
	 * Non-maskable interrupts are either the abort switch (on
	 * cpu0 only) or IPIs (on any cpu). We check for IPI first.
	 */
#ifdef MULTIPROCESSOR
	if ((*(volatile u_int8_t *)(BS_BASE + BS_CPINT)) & BS_CPI_INT) {
		/* disable further NMI for now */
		*(volatile u_int8_t *)(BS_BASE + BS_CPINT) = 0;

		rc = m197_ipi_handler(eframe);

		/* acknowledge */
		*(volatile u_int8_t *)(BS_BASE + BS_CPINT) = BS_CPI_ICLR;

		if (rc != 0)
			m197_nmi_wrapup(eframe);
	} else
#endif
		rc = 1;

	if (CPU_IS_PRIMARY(curcpu())) {
		abort = *(u_int8_t *)(BS_BASE + BS_ABORT);
		if (abort & BS_ABORT_INT) {
			*(u_int8_t *)(BS_BASE + BS_ABORT) =
			    (abort & ~BS_ABORT_IEN) | BS_ABORT_ICLR;
			nmihand(eframe);
			*(u_int8_t *)(BS_BASE + BS_ABORT) |= BS_ABORT_IEN;
		}
	}

	return rc;
}

void
m197_nmi_wrapup(struct trapframe *eframe)
{
#ifdef MULTIPROCESSOR
	/* reenable IPIs */
	*(volatile u_int8_t *)(BS_BASE + BS_CPINT) = BS_CPI_IEN;
#endif
}

u_int
m197_getipl(void)
{
	return *(u_int8_t *)M197_IMASK & 0x07;
}

u_int
m197_setipl(u_int level)
{
	u_int curspl, psr;

	psr = get_psr();
	set_psr(psr | PSR_IND);
	curspl = *(u_int8_t *)M197_IMASK & 0x07;
	*(u_int8_t *)M197_IMASK = level;
	/*
	 * We do not flush the pipeline here, because interrupts are disabled,
	 * and set_psr() will synchronize the pipeline.
	 */
	set_psr(psr);
	return curspl;
}

u_int
m197_raiseipl(u_int level)
{
	u_int curspl, psr;

	psr = get_psr();
	set_psr(psr | PSR_IND);
	curspl = *(u_int8_t *)M197_IMASK & 0x07;
	if (curspl < level)
		*(u_int8_t *)M197_IMASK = level;
	/*
	 * We do not flush the pipeline here, because interrupts are disabled,
	 * and set_psr() will synchronize the pipeline.
	 */
	set_psr(psr);
	return curspl;
}

#ifdef MULTIPROCESSOR

/*
 * IPIs groups.
 *
 * There are three sorts of IPI on MVME197:
 *
 * - synchronous IPIs: TLB and cache operations
 *
 *	Those require immediate attention from the other processor, and the
 *	sender will wait for completion before resuming normal operations.
 *	This is done for so-called complex IPIs (those which take arguments),
 *	so that it isn't necessary to maintain a list of pending IPI work.
 *	However it is better to make tlb updates synchronous as well.
 *
 *	Handling of synchronous exceptions makes sure they can not be
 *	interrupted by another NMI; upon returning from the exception,
 *	the interrupted processor will not attempt to run soft interrupts
 *	and will not check for AST.
 *
 * - asynchronous fast IPIs: notify, ddb
 *
 *	Notify is just a trick to get the other processor to check for
 *	AST, it is processed almost immediately, but since it may cause
 *	preemption, the sender can not really wait for completion.
 *	As for DDB, waiting would interfere with ddb's logic.
 *
 * - asynchronous slow IPIs: clock
 *
 *	These may take a long time to execute. They cause the processor
 *	to self-inflict itself a soft interrupt, to make sure we won't
 *	run clock operations if it was running at splclock or higher when
 *	the IPI was received.
 */

#define	CI_IPI_CLOCK \
	(CI_IPI_HARDCLOCK | CI_IPI_STATCLOCK)
#define	CI_IPI_SYNCHRONOUS \
	(CI_IPI_TLB_FLUSH_KERNEL | CI_IPI_TLB_FLUSH_USER | \
	 CI_IPI_CACHE_FLUSH | CI_IPI_ICACHE_FLUSH | CI_IPI_DMA_CACHECTL)

void
m197_send_ipi(int ipi, cpuid_t cpu)
{
	struct cpu_info *ci = &m88k_cpus[cpu];

	KASSERT((ipi & CI_IPI_SYNCHRONOUS) == 0);

	if ((ci->ci_flags & CIF_ALIVE) == 0)
		return;			/* XXX not ready yet */

	if (ci->ci_ddb_state == CI_DDB_PAUSE)
		return;			/* XXX skirting deadlock */

	atomic_setbits_int(&ci->ci_ipi, ipi);
	*(volatile u_int8_t *)(BS_BASE + BS_CPINT) |= BS_CPI_SCPI;
}

void
m197_send_complex_ipi(int ipi, cpuid_t cpu, u_int32_t arg1, u_int32_t arg2)
{
	struct cpu_info *ci = &m88k_cpus[cpu];
	uint32_t psr;
	int wait;

	if ((ci->ci_flags & CIF_ALIVE) == 0)
		return;				/* XXX not ready yet */

	if (ci->ci_ddb_state == CI_DDB_PAUSE)
		return;				/* XXX skirting deadlock */

	psr = get_psr();
	set_psr(psr | PSR_IND);

	/*
	 * Wait for the other processor to be ready to accept an IPI.
	 */
	for (wait = 1000000; wait != 0; wait--) {
		if (!ISSET(*(volatile u_int8_t *)(BS_BASE + BS_CPINT),
		    BS_CPI_STAT))
			break;
	}
	if (wait == 0)
		panic("couldn't send complex ipi %x to cpu %d: busy",
		    ipi, cpu);

#ifdef DEBUG
	if (ci->ci_ipi != 0)
		printf("%s: cpu %d ipi %x did not clear during wait\n",
		    __func__, ci->ci_cpuid, ci->ci_ipi);
#endif

	/*
	 * In addition to the ipi bit itself, we need to set up ipi arguments.
	 * Note that we do not need to protect against another processor
	 * trying to send another complex IPI, since we know there are only
	 * two processors on the board. This is also why we do not use atomic
	 * operations on ci_ipi there, since we know from the loop above that
	 * the other process is done doing any IPI work.
	 */
	ci->ci_ipi_arg1 = arg1;
	ci->ci_ipi_arg2 = arg2;
	ci->ci_ipi |= ipi;

	*(volatile u_int8_t *)(BS_BASE + BS_CPINT) |= BS_CPI_SCPI;

	/*
	 * Wait for the other processor to complete ipi processing.
	 */
	for (wait = 1000000; wait != 0; wait--) {
		if (!ISSET(*(volatile u_int8_t *)(BS_BASE + BS_CPINT),
		    BS_CPI_STAT))
			break;
	}
	if (wait == 0)
		panic("couldn't send complex ipi %x to cpu %d: no ack",
		    ipi, cpu);

#ifdef DEBUG
	/*
	 * If there are any simple IPIs pending, trigger them now.
	 * There really shouldn't any, since we have waited for all
	 * asynchronous ipi processing to complete before sending this
	 * one.
	 */
	if (ci->ci_ipi != 0) {
		printf("%s: cpu %d ipi %x did not clear after completion\n",
		    __func__, ci->ci_cpuid, ci->ci_ipi);
		*(volatile u_int8_t *)(BS_BASE + BS_CPINT) |= BS_CPI_SCPI;
	}
#endif

	set_psr(psr);
}
void
m197_broadcast_complex_ipi(int ipi, u_int32_t arg1, u_int32_t arg2)
{
	/*
	 * This relies upon the fact that we only have two processors,
	 * and their cpuid are 0 and 1.
	 */
	m197_send_complex_ipi(ipi, 1 - curcpu()->ci_cpuid, arg1, arg2);
}

int
m197_ipi_handler(struct trapframe *eframe)
{
	struct cpu_info *ci = curcpu();
	int ipi;
	u_int32_t arg1, arg2;

	if ((ipi = atomic_clear_int(&ci->ci_ipi)) == 0)
		return 1;

	/*
	 * Synchronous IPIs. There can only be one pending at the same time,
	 * sending processor will wait for us to have processed the current
	 * one before sending a new one.
	 * We process them ASAP, ignoring any other pending ipi - sender will
	 * take care of resending an ipi if necessary.
	 */
	if (ipi & CI_IPI_SYNCHRONOUS) {
		/* no need to use atomic ops, the other cpu waits */
		/* leave asynchronous ipi pending */
		ci->ci_ipi = ipi & ~CI_IPI_SYNCHRONOUS;

		arg1 = ci->ci_ipi_arg1;
		arg2 = ci->ci_ipi_arg2;

		if (ipi & CI_IPI_TLB_FLUSH_KERNEL) {
			cmmu_tlbis(ci->ci_cpuid, arg1, arg2);
		}
		else if (ipi & CI_IPI_TLB_FLUSH_USER) {
			cmmu_tlbiu(ci->ci_cpuid, arg1, arg2);
		}
		else if (ipi & CI_IPI_CACHE_FLUSH) {
			cmmu_cache_wbinv(ci->ci_cpuid, arg1, arg2);
		}
		else if (ipi & CI_IPI_ICACHE_FLUSH) {
			cmmu_icache_inv(ci->ci_cpuid, arg1, arg2);
		}
		else if (ipi & CI_IPI_DMA_CACHECTL) {
			dma_cachectl_local(arg1, arg2, DMA_CACHE_INV);
		}

		return 0;
	}

	/*
	 * Asynchronous IPIs. We can have as many bits set as possible.
	 */

	if (ipi & CI_IPI_CLOCK) {
		/*
		 * Even if the current spl level would allow it, we can
		 * not run the clock handlers from there because we would
		 * need to grab the kernel lock, which might already
		 * held by the other processor.
		 *
		 * Instead, schedule a soft interrupt. But remember the
		 * important fields from the exception frame first, so
		 * that a valid clockframe can be reconstructed from the
		 * soft interrupt handler (which can not get an exception
		 * frame).
		 */
		if (ipi & CI_IPI_HARDCLOCK) {
			ci->ci_h_sxip = eframe->tf_sxip;
			ci->ci_h_epsr = eframe->tf_epsr;
		}
		if (ipi & CI_IPI_STATCLOCK) {
			ci->ci_s_sxip = eframe->tf_sxip;
			ci->ci_s_epsr = eframe->tf_epsr;
		}

		/* inflict ourselves a soft ipi */
		ci->ci_softipi_cb = m197_soft_ipi;
	}

	if (ipi & CI_IPI_DDB) {
#ifdef DDB
		/*
		 * Another processor has entered DDB. Spin on the ddb lock
		 * until it is done.
		 */
		extern struct __mp_lock ddb_mp_lock;

		ci->ci_ddb_state = CI_DDB_PAUSE;

		__mp_lock(&ddb_mp_lock);
		__mp_unlock(&ddb_mp_lock);

		ci->ci_ddb_state = CI_DDB_RUNNING;

		/*
		 * If ddb is hoping to us, it's our turn to enter ddb now.
		 */
		if (ci->ci_cpuid == ddb_mp_nextcpu)
			Debugger();
#endif
	}
	if (ipi & CI_IPI_NOTIFY) {
		/* nothing to do! */
	}

	return 1;
}

/*
 * Maskable IPIs.
 *
 * These IPIs are received as non maskable, but are not processed in
 * the NMI handler; instead, they are processed from the soft interrupt
 * handler.
 *
 * XXX This is grossly suboptimal.
 */
void
m197_soft_ipi()
{
	struct cpu_info *ci = curcpu();
	struct trapframe faketf;
	int s;

	__mp_lock(&kernel_lock);
	s = splclock();

	if (ci->ci_h_sxip != 0) {
		faketf.tf_cpu = ci;
		faketf.tf_sxip = ci->ci_h_sxip;
		faketf.tf_epsr = ci->ci_h_epsr;
		ci->ci_h_sxip = 0;
		hardclock((struct clockframe *)&faketf);
	}

	if (ci->ci_s_sxip != 0) {
		faketf.tf_cpu = ci;
		faketf.tf_sxip = ci->ci_s_sxip;
		faketf.tf_epsr = ci->ci_s_epsr;
		ci->ci_s_sxip = 0;
		statclock((struct clockframe *)&faketf);
	}

	splx(s);
	__mp_unlock(&kernel_lock);
}

/*
 * Special version of delay() for MP kernels.
 * Processors need to use different timers, so we'll use the two
 * BusSwitch timers for this purpose.
 */
void
m197_delay(int us)
{
	if (CPU_IS_PRIMARY(curcpu())) {
		*(volatile u_int32_t *)(BS_BASE + BS_TCOMP1) = 0xffffffff;
		*(volatile u_int32_t *)(BS_BASE + BS_TCOUNT1) = 0;
		*(volatile u_int8_t *)(BS_BASE + BS_TCTRL1) |= BS_TCTRL_CEN;

		while ((*(volatile u_int32_t *)(BS_BASE + BS_TCOUNT1)) <
		    (u_int32_t)us)
			;
		*(volatile u_int8_t *)(BS_BASE + BS_TCTRL1) &= ~BS_TCTRL_CEN;
	} else {
		*(volatile u_int32_t *)(BS_BASE + BS_TCOMP2) = 0xffffffff;
		*(volatile u_int32_t *)(BS_BASE + BS_TCOUNT2) = 0;
		*(volatile u_int8_t *)(BS_BASE + BS_TCTRL2) |= BS_TCTRL_CEN;

		while ((*(volatile u_int32_t *)(BS_BASE + BS_TCOUNT2)) <
		    (u_int32_t)us)
			;
		*(volatile u_int8_t *)(BS_BASE + BS_TCTRL2) &= ~BS_TCTRL_CEN;
	}
}

void
m197_smp_setup(struct cpu_info *ci)
{
	/*
	 * Setup function pointers for mplock operation.
	 */
	ci->ci_mp_atomic_begin = m197_mp_atomic_begin;
	ci->ci_mp_atomic_end = m197_mp_atomic_end;
}

uint32_t
m197_mp_atomic_begin(__cpu_simple_lock_t *lock, uint *csr)
{
	uint32_t psr;

	psr = get_psr();
	set_psr(psr | PSR_IND);

	*csr = *(volatile uint8_t *)(BS_BASE + BS_CPINT);
	*(volatile uint8_t *)(BS_BASE + BS_CPINT) = 0;

	__cpu_simple_lock(lock);

	return psr;
}

void
m197_mp_atomic_end(uint32_t psr, __cpu_simple_lock_t *lock, uint csr)
{
	__cpu_simple_unlock(lock);

	*(volatile uint8_t *)(BS_BASE + BS_CPINT) = csr & BS_CPI_IEN;

	set_psr(psr);
}
#endif	/* MULTIPROCESSOR */
@


1.49
log
@add missing arguments to debug printfs
@
text
@d1 1
a1 1
/*	$OpenBSD: m197_machdep.c,v 1.48 2013/05/17 22:46:28 miod Exp $	*/
@


1.48
log
@Replace the bunch of md_* function pointers with a `struct board' containing
function pointers for all the board-specific code.

Add a bunch of `struct board' methods to cover most, if not all, of the
`per-board' logic. This allows most of the md drivers to be cleaned up and
no longer need to embed board-specific knowledge.
@
text
@d1 1
a1 1
/*	$OpenBSD: m197_machdep.c,v 1.47 2013/02/17 18:07:36 miod Exp $	*/
d548 1
a548 1
		    ci->ci_cpuid, ci->ci_ipi);
d586 1
a586 1
		    ci->ci_cpuid, ci->ci_ipi);
@


1.47
log
@Constify struct cmmu.
@
text
@d1 1
a1 1
/*	$OpenBSD: m197_machdep.c,v 1.46 2011/10/25 18:38:06 miod Exp $	*/
d71 1
d75 1
d78 1
d89 75
a163 4
void	m197_bootstrap(void);
void	m197_delay(int);
void	m197_ext_int(struct trapframe *);
u_int	m197_getipl(void);
a164 1
vaddr_t	m197_memsize(void);
a166 5
int	m197_nmi(struct trapframe *);
void	m197_nmi_wrapup(struct trapframe *);
u_int	m197_raiseipl(u_int);
u_int	m197_setipl(u_int);
void	m197_smp_setup(struct cpu_info *);
d169 54
d280 13
a294 1

d296 1
a296 1
m197_ext_int(struct trapframe *eframe)
a369 1

a458 78
void
m197_bootstrap()
{
	extern const struct cmmu_p cmmu88110;
	extern const struct cmmu_p cmmu88410;
	extern int cpuspeed;
	u_int16_t cpu;
	u_int8_t version, btimer, pbt;

	if (mc88410_present()) {
		cmmu = &cmmu88410;	/* 197SP/197DP */

		/*
		 * Make sure all interrupts (levels 1 to 7) get routed
		 * to the boot cpu.
		 *
		 * We only need to write to one ISEL registers, this will
		 * set the correct value in the other one, since we set
		 * all the active bits.
		 */
		cpu = *(u_int16_t *)(BS_BASE + BS_GCSR) & BS_GCSR_CPUID;
		*(u_int8_t *)(BS_BASE + (cpu ? BS_ISEL1 : BS_ISEL0)) = 0xfe;
	} else
		cmmu = &cmmu88110;	/* 197LE */

	/*
	 * Find out the processor speed, from the BusSwitch prescaler
	 * adjust register.
	 */
	cpuspeed = 256 - *(volatile u_int8_t *)(BS_BASE + BS_PADJUST);

	/*
	 * Kernels running without snooping enabled (i.e. without
	 * CACHE_GLOBAL set in the apr in pmap.c) need increased processor
	 * bus timeout limits, or the instruction cache might not be able
	 * to fill or answer fast enough. It does not hurt to increase
	 * them unconditionnaly, though.
	 *
	 * Do this as soon as possible (i.e. now...), since this is
	 * especially critical on 40MHz boards, while some 50MHz boards can
	 * run without this timeout change... but better be safe than sorry.
	 *
	 * Boot blocks do this for us now, but again, better stay on the
	 * safe side. Be sure to update the boot blocks code if the logic
	 * below changes.
	 */
	version = *(volatile u_int8_t *)(BS_BASE + BS_CHIPREV);
	btimer = *(volatile u_int8_t *)(BS_BASE + BS_BTIMER);
	pbt = btimer & BS_BTIMER_PBT_MASK;
	btimer = (btimer & ~BS_BTIMER_PBT_MASK);
	
	/* XXX PBT256 might only be necessary for busswitch rev1? */
	if (cpuspeed < 50 || version <= 0x01) {
		if (pbt < BS_BTIMER_PBT256)
			pbt = BS_BTIMER_PBT256;
	} else {
		if (pbt < BS_BTIMER_PBT64)
			pbt = BS_BTIMER_PBT64;
	}

	*(volatile u_int8_t *)(BS_BASE + BS_BTIMER) = btimer | pbt;

	md_interrupt_func_ptr = m197_ext_int;
	md_nmi_func_ptr = m197_nmi;
	md_nmi_wrapup_func_ptr = m197_nmi_wrapup;
	md_getipl = m197_getipl;
	md_setipl = m197_setipl;
	md_raiseipl = m197_raiseipl;
	md_init_clocks = m1x7_init_clocks;
#ifdef MULTIPROCESSOR
	md_send_ipi = m197_send_ipi;
	md_delay = m197_delay;
	md_smp_setup = m197_smp_setup;
#else
	md_delay = m1x7_delay;
#endif
}

a779 1

@


1.46
log
@Replace the naive 88110 tlb update code, which would always invalidate the
whole tlb (32 of 'em), with smarter `tlb probe and update with new pte if tlb
match found' code. This makes the 88110-specific pmap_update() unnecessary, as
updates are no longer aggregated to avoid the number of flushes. This also
makes tlb handling similar between 88100 and 88110, from the pmap's point of
view, so there is no need to use different routines.

No impact on 88100, no user-noticeable performance change on 88100 GENERIC,
slight improvement on 88110 GENERIC.MP.
@
text
@d1 1
a1 1
/*	$OpenBSD: m197_machdep.c,v 1.45 2011/01/05 22:14:39 miod Exp $	*/
d329 2
a330 2
	extern struct cmmu_p cmmu88110;
	extern struct cmmu_p cmmu88410;
@


1.45
log
@Now that pmap_copy_page() no longer needs to flush a couple contiguous tlb
entries, drop the count parameter to cmmu_tlb_inv(), and introduce
cmmu_tlb_inv_all() to drop all user tlb entries (to be used during context
switches).
@
text
@d1 1
a1 1
/*	$OpenBSD: m197_machdep.c,v 1.44 2010/12/31 21:38:08 miod Exp $	*/
d417 1
a417 1
 *	However it is better to make tlb shootdowns synchronous as well.
d450 4
a453 5
	if (ipi & CI_IPI_SYNCHRONOUS) {
		m197_send_complex_ipi(ipi, cpu, 0, 0);
	} else {
		if ((ci->ci_flags & CIF_ALIVE) == 0)
			return;			/* XXX not ready yet */
d455 2
a456 2
		if (ci->ci_ddb_state == CI_DDB_PAUSE)
			return;			/* XXX skirting deadlock */
d458 2
a459 3
		atomic_setbits_int(&ci->ci_ipi, ipi);
		*(volatile u_int8_t *)(BS_BASE + BS_CPINT) |= BS_CPI_SCPI;
	}
d574 1
a574 1
			cmmu_tlb_inv(ci->ci_cpuid, 1, 0);
d577 1
a577 1
			cmmu_tlb_inv(ci->ci_cpuid, 0, 0);
@


1.44
log
@Massive overhauling of the m88k pmap, though I can't pretend it's a new pmap
since a large part of the structures and logic remains.

Since m88k has separate supervisor/user spaces, we can map physical memory 1:1
in supervisor space, and have the kernel virtual address space start from the
end of physical memory.

This allows us to switch to __HAVE_PMAP_DIRECT. And to get rid of the double
mapped sdt, since now their virtual and physical addresses will always match.

The upper bound of the kernel virtual memory space is now platform dependent,
until the code which relies upon some hardware devices being mapped 1:1 in
supervisor mode is updated to no longer require this (this is mainly a PITA on
luna88k, where onboard devices start at 0x40000000, leaving only 1GB of KVA at
the moment - still much better than the previous 512MB).

Tested on mvme88k only (187, 188, 197LE, 197DP). Other platforms ought to
work, aviion will be checked shortly and fixed if necessary. No known
OpenBSD/luna88k system in working condition at the moment.
@
text
@d1 1
a1 1
/*	$OpenBSD: m197_machdep.c,v 1.43 2010/12/31 20:54:21 miod Exp $	*/
d576 1
a576 1
			cmmu_tlb_inv(ci->ci_cpuid, 1, 0, 0);
d579 1
a579 1
			cmmu_tlb_inv(ci->ci_cpuid, 0, 0, 0);
@


1.43
log
@Standardize cache handling functions and defines to use wb/wbinv/inv instead
of flush/sync/inval. No functional change.
@
text
@d1 1
a1 1
/*	$OpenBSD: m197_machdep.c,v 1.42 2010/06/22 17:42:37 miod Exp $	*/
a99 4
void	m197_startup(void);

vaddr_t obiova;
vaddr_t flashva;
a154 26
}

void
m197_startup()
{
	/*
	 * Grab the FLASH space that we hardwired in pmap_bootstrap
	 */
	flashva = FLASH_START;
	uvm_map(kernel_map, (vaddr_t *)&flashva, FLASH_SIZE,
	    NULL, UVM_UNKNOWN_OFFSET, 0,
	      UVM_MAPFLAG(UVM_PROT_NONE, UVM_PROT_NONE, UVM_INH_NONE,
	        UVM_ADV_NORMAL, UVM_FLAG_FIXED));
	if (flashva != FLASH_START)
		panic("flashva %lx: FLASH not free", flashva);

	/*
	 * Grab the OBIO space that we hardwired in pmap_bootstrap
	 */
	obiova = OBIO197_START;
	uvm_map(kernel_map, (vaddr_t *)&obiova, OBIO197_SIZE,
	    NULL, UVM_UNKNOWN_OFFSET, 0,
	      UVM_MAPFLAG(UVM_PROT_NONE, UVM_PROT_NONE, UVM_INH_NONE,
	        UVM_ADV_NORMAL, UVM_FLAG_FIXED));
	if (obiova != OBIO197_START)
		panic("obiova %lx: OBIO not free", obiova);
@


1.42
log
@Since our caches are snooping, we only need to broadcast cache invalidates
on 88110 designs. Brings a ~8% speedup on GENERIC.MP on 197DP.
@
text
@d1 1
a1 1
/*	$OpenBSD: m197_machdep.c,v 1.41 2009/08/30 12:11:35 miod Exp $	*/
d606 1
a606 1
			cmmu_flush_tlb(ci->ci_cpuid, 1, 0, 0);
d609 1
a609 1
			cmmu_flush_tlb(ci->ci_cpuid, 0, 0, 0);
d612 1
a612 1
			cmmu_flush_cache(ci->ci_cpuid, arg1, arg2);
d615 1
a615 1
			cmmu_flush_inst_cache(ci->ci_cpuid, arg1, arg2);
@


1.41
log
@Use UVM_FLAG_FIXED for fixed allocations make with uvm_map() during early
bootstrap.
@
text
@d1 1
a1 1
/*	$OpenBSD: m197_machdep.c,v 1.40 2009/03/15 20:39:53 miod Exp $	*/
d618 1
a618 2
			dma_cachectl_local(arg1, arg2 & ~DMA_CACHE_MASK,
			    arg2 & DMA_CACHE_MASK);
@


1.40
log
@Generic softinterrupt support for m88k based platforms, adapted from arm
with different locking mechanism. 88110 soft ipi are replaced with an
ipi callback which is checked upon return from exception (it can not be kept
as a softintr, as the generic softinterrupt code doesn't have per-cpu
pending softintr queues).
@
text
@d1 1
a1 1
/*	$OpenBSD: m197_machdep.c,v 1.39 2009/03/04 19:39:41 miod Exp $	*/
d171 1
a171 1
	        UVM_ADV_NORMAL, 0));
d182 1
a182 1
	        UVM_ADV_NORMAL, 0));
@


1.39
log
@Clean up the ipi code a bit and try to provide useful comments as well.
@
text
@d1 1
a1 1
/*	$OpenBSD: m197_machdep.c,v 1.38 2009/03/01 17:44:46 miod Exp $	*/
a426 1
	md_soft_ipi = m197_soft_ipi;
d650 3
a652 1
		setsoftipi(ci);
@


1.38
log
@Make more IPI synchronous. Performance slightly down, stability slightly up.

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: m197_machdep.c,v 1.37 2009/02/27 05:19:36 miod Exp $	*/
d438 30
a467 1
 * IPIs groups
d469 1
d481 5
a485 5
	if (ci->ci_ipi & ipi)
		return;

	if ((ci->ci_flags & CIF_ALIVE) == 0)
		return;				/* XXX not ready yet */
d487 2
a488 2
	if (ci->ci_ddb_state == CI_DDB_PAUSE)
		return;				/* XXX skirting deadlock */
d490 1
a490 5
	atomic_setbits_int(&ci->ci_ipi, ipi);

	if (ipi & CI_IPI_SYNCHRONOUS)
		m197_send_complex_ipi(ipi, cpu, 0, 0);
	else
d492 1
d523 6
d555 1
d558 7
a564 2
	 */
	if (ci->ci_ipi != 0)
d566 2
d585 1
a585 1
	int ipi = ci->ci_ipi;
a586 3
#ifdef DDB
	int need_ddb = 0;
#endif
d588 1
a588 1
	if (ipi == 0)
d600 2
a601 1
		ci->ci_ipi &= ~CI_IPI_SYNCHRONOUS;
a629 2
	atomic_clearbits_int(&ci->ci_ipi, ipi);

d673 1
a673 1
			need_ddb = 1;
a678 5

#ifdef DDB
	if (need_ddb)
		Debugger();
#endif
@


1.37
log
@Rework nmi handling to handle ``complex'' NMI faster, and return as fast as
possible from the exception, without doing the AST and softintr dance.

This should avoid too much stack usage under load.

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: m197_machdep.c,v 1.36 2009/02/21 18:37:49 miod Exp $	*/
a104 5
#define	CI_IPI_MASKABLE \
	(CI_IPI_HARDCLOCK | CI_IPI_STATCLOCK)
#define	CI_IPI_COMPLEX \
	(CI_IPI_CACHE_FLUSH | CI_IPI_ICACHE_FLUSH | CI_IPI_DMA_CACHECTL)

d437 9
d462 4
a465 1
	*(volatile u_int8_t *)(BS_BASE + BS_CPINT) |= BS_CPI_SCPI;
d554 4
a557 4
	 * Complex IPIs (with extra arguments). There can only be one
	 * pending at the same time, sending processor will wait for us
	 * to have processed the current one before sending a new one.
	 * We process them ASAP, ignoring any other ipi - sender will
d560 1
a560 1
	if (ipi & CI_IPI_COMPLEX) {
d562 1
a562 1
		ci->ci_ipi &= ~ipi;
d567 7
a573 1
		if (ipi & CI_IPI_CACHE_FLUSH) {
d587 4
d593 1
a593 1
	if (ipi & CI_IPI_MASKABLE) {
a616 9
	/*
	 * Regular, simple, IPIs. We can have as many bits set as possible.
	 */
	if (ipi & CI_IPI_TLB_FLUSH_KERNEL) {
		cmmu_flush_tlb(ci->ci_cpuid, 1, 0, 0);
	}
	if (ipi & CI_IPI_TLB_FLUSH_USER) {
		cmmu_flush_tlb(ci->ci_cpuid, 0, 0, 0);
	}
@


1.36
log
@Move part of the mp lock logic into per-cpu callbacks; on MVME197DP we need
to disable NMI sources in addition to interrupt sources, and we can not
use a quick sequence with shadowing frozen as done for atomic ops.

This lets GENERIC.MP boot multiuser on MVME197DP boards, and is so far stable
enough to be able to recompile a kernel from scratch (with make -j2).
@
text
@d1 1
a1 1
/*	$OpenBSD: m197_machdep.c,v 1.35 2009/02/21 18:35:22 miod Exp $	*/
d90 1
a90 1
void	m197_ipi_handler(struct trapframe *);
d94 2
a95 1
void	m197_nmi(struct trapframe *);
d268 2
d271 2
a272 1
void
d276 1
d286 9
a294 5
		m197_ipi_handler(eframe);
		/* acknowledge and reenable IPIs */
		*(volatile u_int8_t *)(BS_BASE + BS_CPINT) =
		    BS_CPI_ICLR | BS_CPI_IEN;
	}
d296 1
d307 11
d425 1
d465 1
d474 3
d486 2
a487 1
		panic("couldn't send complex ipi %x to cpu %d", ipi, cpu);
d493 3
a495 1
	 * two processors on the board.
d499 1
a499 1
	atomic_setbits_int(&ci->ci_ipi, ipi);
d502 20
a522 1

d533 1
a533 1
void
d544 29
a572 1
		return;
a600 21
	 * Complex IPIs (with extra arguments). There can only be one
	 * pending at the same time, sending processor will wait for us
	 * to have processed the current one before sending a new one.
	 */
	if (ipi & CI_IPI_COMPLEX) {
		arg1 = ci->ci_ipi_arg1;
		arg2 = ci->ci_ipi_arg2;

		if (ipi & CI_IPI_CACHE_FLUSH) {
			cmmu_flush_cache(ci->ci_cpuid, arg1, arg2);
		}
		else if (ipi & CI_IPI_ICACHE_FLUSH) {
			cmmu_flush_inst_cache(ci->ci_cpuid, arg1, arg2);
		}
		else if (ipi & CI_IPI_DMA_CACHECTL) {
			dma_cachectl_local(arg1, arg2 & ~DMA_CACHE_MASK,
			    arg2 & DMA_CACHE_MASK);
		}
	}

	/*
d639 2
@


1.35
log
@Get rid of 88110 nmi stacks. This was a good idea, but I outsmarted myself
since it was intended to service NMI occuring in user mode, and we could
end up invoking preempt() and have another cpu start using this stack,
with interesting results.
@
text
@d1 1
a1 1
/*	$OpenBSD: m197_machdep.c,v 1.34 2009/02/17 21:04:01 miod Exp $	*/
d92 2
d97 1
d412 1
d654 36
@


1.34
log
@Pass a cpu_info * to setsoftipi() so it does not need to curcpu(), which
synchronizes the pipeline on 88110.
@
text
@d1 1
a1 1
/*	$OpenBSD: m197_machdep.c,v 1.33 2009/02/16 23:03:33 miod Exp $	*/
a268 8
#if 0
	u_int32_t psr;

	/* block all hardware interrupts */
	m197_setipl(IPL_HIGH);	/* IPL_IPI? */
	psr = get_psr();
	set_psr(psr & ~PSR_IND);
#endif
a293 9

#if 0
	/*
	 * Disable interrupts before returning to assembler,
	 * the spl will be restored later.
	 */
	set_psr(psr | PSR_IND);
#endif

@


1.33
log
@More 88110 SMP work. Contains, horribly entangled:
- dma_cachectl() split into a ``local cpu only'' and ``all cpus'', and an ipi
  to broadcast ``local dma_cachectl'' is added.
- cpu_info fields are rearranged, to have the 88100-specific information
  and the 88110-specific information overlap, and has many more 88110
  ugly things.
- more ipi handling in the 197-specific area. Since it is not possible to
  have the second processor receive any hardware interrupt (selection
  is done on a level basis via ISEL, and we definitely do not want the
  main cpu to lose interrupts), the best we can do is to inflict ourselves
  a soft interrupt for late ipi processing. It gets used for softclock and
  hardclock on the secondary processor, but since the soft interrupt
  dispatcher doesn't have an exception frame, we have to remember parts
  of it to build a fake clockframe from the soft ipi handler (ugly but
  works).

This now lets GENERIC.MP run a few userland binaries before bugs trigger.
@
text
@d1 1
a1 1
/*	$OpenBSD: m197_machdep.c,v 1.32 2009/02/16 22:55:03 miod Exp $	*/
d534 1
a534 1
		setsoftipi();
@


1.32
log
@Since NMI are now handled separately, remove the ``interrupt type'' argument
from interrupt() and related function pointers.
@
text
@d1 1
a1 1
/*	$OpenBSD: m197_machdep.c,v 1.31 2009/02/13 23:33:51 miod Exp $	*/
a86 1
void	m197_clock_ipi_handler(struct trapframe *);
d95 1
d101 5
a194 3
#ifdef MULTIPROCESSOR
	struct cpu_info *ci = curcpu();
#endif
a219 10
#ifdef MULTIPROCESSOR
	/*
	 * If we have pending hardware IPIs and the current
	 * level allows them to be processed, do them now.
	 */
	if (eframe->tf_mask < IPL_SCHED &&
	    ISSET(ci->ci_ipi, CI_IPI_HARDCLOCK | CI_IPI_STATCLOCK))
		m197_clock_ipi_handler(eframe);
#endif

d262 3
d268 2
a270 1
	u_int8_t abort;
d276 1
d424 1
d489 10
d508 27
a534 3
	if (ipi != 0) {
		atomic_clearbits_int(&ci->ci_ipi,
		    ipi & ~(CI_IPI_HARDCLOCK | CI_IPI_STATCLOCK));
d542 1
a542 2
	if (ipi &
	    (CI_IPI_CACHE_FLUSH | CI_IPI_ICACHE_FLUSH)) {
d552 4
d589 2
a590 3
	if (ipi & (CI_IPI_NOTIFY | CI_IPI_HARDCLOCK | CI_IPI_STATCLOCK)) {
		/* force an AST */
		aston(ci->ci_curproc);
d603 2
a604 3
 * the NMI handler; instead, they are checked again when changing
 * spl level on return from regular interrupts to process them as soon
 * as possible.
d609 1
a609 1
m197_clock_ipi_handler(struct trapframe *eframe)
d612 1
a612 1
	int ipi = ci->ci_ipi & (CI_IPI_HARDCLOCK | CI_IPI_STATCLOCK);
d615 18
a632 1
	atomic_clearbits_int(&ci->ci_ipi, ipi);
a633 5
	s = splclock();
	if (ipi & CI_IPI_HARDCLOCK)
		hardclock((struct clockframe *)eframe);
	if (ipi & CI_IPI_STATCLOCK)
		statclock((struct clockframe *)eframe);
d635 1
@


1.31
log
@Use a different dispatcher for the NMI traps on 88110, these are too
different from regular hardware interrupts to be worth handling the
same way.

Disable IPI reception while we are handling pending IPIs. And do not
reenable them by mistake if we need to send an IPI in return.

This lets GENERIC.MP boot single user on a MVME197DP. There are still
many bugs to fix.
@
text
@d1 1
a1 1
/*	$OpenBSD: m197_machdep.c,v 1.30 2009/02/13 23:28:07 miod Exp $	*/
d89 1
a89 1
void	m197_ext_int(u_int, struct trapframe *);
d188 1
a188 1
m197_ext_int(u_int v, struct trapframe *eframe)
@


1.30
log
@Provide a specific delay() routine using separate timers for the two cpus
on MVME197DP boards running the MP kernel.
@
text
@d1 17
a17 1
/*	$OpenBSD: m197_machdep.c,v 1.29 2009/02/13 23:26:51 miod Exp $	*/
d93 1
a199 1
	u_int8_t abort;
d208 10
a217 5
	if (v == T_NON_MASK) {
		/*
		 * Non-maskable interrupts are either the abort switch (on
		 * cpu0 only) or IPIs (on any cpu). We check for IPI first.
		 */
d219 7
a225 2
		if ((*(volatile u_int8_t *)(BS_BASE + BS_CPINT)) & BS_CPI_INT)
			m197_ipi_handler(eframe);
d228 20
a247 6
		abort = *(u_int8_t *)(BS_BASE + BS_ABORT);
		if (abort & BS_ABORT_INT) {
			*(u_int8_t *)(BS_BASE + BS_ABORT) =
			    (abort & ~BS_ABORT_IEN) | BS_ABORT_ICLR;
			nmihand(eframe);
			*(u_int8_t *)(BS_BASE + BS_ABORT) |= BS_ABORT_IEN;
d249 6
d256 6
a261 13
#ifdef MULTIPROCESSOR
		/*
		 * If we have pending hardware IPIs and the current
		 * level allows them to be processed, do them now.
		 */
		if (eframe->tf_mask < IPL_SCHED &&
		    ISSET(ci->ci_ipi,
		      CI_IPI_HARDCLOCK | CI_IPI_STATCLOCK)) {
			psr = get_psr();
			set_psr(psr & ~PSR_IND);
			m197_clock_ipi_handler(eframe);
			set_psr(psr);
		}
a262 10
	} else {
		level = *(u_int8_t *)M197_ILEVEL & 0x07;
		/* generate IACK and get the vector */
		ivec = M197_IACK + (level << 2) + 0x03;
		vec = *(volatile u_int8_t *)ivec;

		/* block interrupts at level or lower */
		m197_setipl(level);
		psr = get_psr();
		set_psr(psr & ~PSR_IND);
d265 2
a266 7
		/*
		 * If we have pending hardware IPIs and the current
		 * level allows them to be processed, do them now.
		 */
		if (eframe->tf_mask < IPL_SCHED &&
		    ISSET(ci->ci_ipi, CI_IPI_HARDCLOCK | CI_IPI_STATCLOCK))
			m197_clock_ipi_handler(eframe);
d268 1
d270 5
a274 4
		list = &intr_handlers[vec];
		if (SLIST_EMPTY(list))
			printf("Spurious interrupt (level %x and vec %x)\n",
			    level, vec);
d276 4
a279 5
		/*
		 * Walk through all interrupt handlers in the chain for the
		 * given vector, calling each handler in turn, till some handler
		 * returns a value != 0.
		 */
d281 14
a294 11
		ret = 0;
		SLIST_FOREACH(intr, list, ih_link) {
			if (intr->ih_wantframe != 0)
				ret = (*intr->ih_fn)((void *)eframe);
			else
				ret = (*intr->ih_fn)(intr->ih_arg);
			if (ret != 0) {
				intr->ih_count.ec_count++;
				break;
			}
		}
d296 7
a302 3
		if (ret == 0) {
			printf("Unclaimed interrupt (level %x and vec %x)\n",
			    level, vec);
a303 6

		/*
		 * Disable interrupts before returning to assembler,
		 * the spl will be restored later.
		 */
		set_psr(psr | PSR_IND);
d306 6
a311 3
#ifdef MULTIPROCESSOR
	if (eframe->tf_mask < IPL_SCHED)
		__mp_unlock(&kernel_lock);
d313 1
d420 1
d443 3
d451 1
a451 1
	*(volatile u_int8_t *)(BS_BASE + BS_CPINT) = BS_CPI_SCPI | BS_CPI_IEN;
d487 1
a487 4
	/*
	 * Send an IPI, keeping our IPIs enabled.
	 */
	*(volatile u_int8_t *)(BS_BASE + BS_CPINT) = BS_CPI_SCPI | BS_CPI_IEN;
d494 1
a494 1
	int ipi = ci->ci_ipi & ~(CI_IPI_HARDCLOCK | CI_IPI_STATCLOCK);
d496 3
d500 4
a503 2
	if (ipi != 0)
		atomic_clearbits_int(&ci->ci_ipi, ipi);
d551 1
a551 1
			Debugger();
d554 3
a556 2
	if (ipi & CI_IPI_NOTIFY) {
		/* nothing to do */
d559 4
a562 4
	/*
	 * Acknowledge IPIs.
	 */
	*(volatile u_int8_t *)(BS_BASE + BS_CPINT) = BS_CPI_ICLR | BS_CPI_IEN;
d568 6
a573 3
 * These IPIs are received as non maskable, but are only processed if
 * the current spl permits it; so they are checked again on return from
 * regular interrupts to process them as soon as possible.
@


1.29
log
@Make delay() a per-board function pointer.
@
text
@d1 1
a1 1
/*	$OpenBSD: m197_machdep.c,v 1.28 2009/02/08 21:40:58 miod Exp $	*/
d72 1
d396 3
a399 1
	md_delay = m1x7_delay;
d552 30
a581 1
#endif
@


1.28
log
@On 88110 processors, use a separate stack to handle NMI; these can occur
while we are switching pcbs and all sort of bad things could happen.
@
text
@d1 1
a1 1
/*	$OpenBSD: m197_machdep.c,v 1.27 2008/09/19 20:18:03 miod Exp $	*/
d396 1
@


1.27
log
@Perform the mvme197 latency timer reprogramming in the boot blocks, in
addition to the kernel, and unconditionnaly handle all busswitch revision 1
based boards as horribly broken, even with 50MHz clocks.

Based on an report of an early 50MHz 197LE board being unable to boot,
due to memory corruption.
@
text
@d1 1
a1 1
/*	$OpenBSD: m197_machdep.c,v 1.26 2007/12/27 23:20:31 miod Exp $	*/
d204 1
a204 1
			    abort | BS_ABORT_ICLR;
d206 1
@


1.26
log
@Remove leftover code in m197_machdep.c, back when I wanted to address the
DCAM2 boards in a different way.
@
text
@d1 1
a1 1
/*	$OpenBSD: m197_machdep.c,v 1.25 2007/12/26 22:21:41 miod Exp $	*/
d332 1
a332 3
#ifndef MULTIPROCESSOR
	u_int8_t btimer, pbt;
#endif
a355 1
#ifndef MULTIPROCESSOR
d360 2
a361 1
	 * to fill or answer fast enough.
d366 4
d371 1
d376 2
a377 2
	/* PBT256 only be necessary for busswitch rev1? */
	if (cpuspeed < 50) {
a385 1
#endif
@


1.25
log
@Remove the last debug bit from the PSR on 88110: do not force memory accesses
instructions to be serialized (this defeats the purpose of having a superscalar
processor, and accesses to volatile variables are done with explicit memory
barriers anyway).

This brings a HUGE speedup: openssl speed -elapsed shows AES is 90% faster,
blowfish is 75% faster, and sha1 is 50% faster. Not so bad!

However, doing this increases the pressure on the processor bus, so it is
necessary to increase the processor bus timeout on 40MHz boards again (to 256
usec). ``black cat'' 50MHz boards seem to be unaffected, so they remain at
64 usec.
@
text
@d1 1
a1 1
/*	$OpenBSD: m197_machdep.c,v 1.24 2007/12/25 21:13:11 miod Exp $	*/
a116 7

	/*
	 * If we had to constrain memory access on boards with
	 * bogus DCAM, don't look into the decoders.
	 */
	if (physmem != 0)
		return (ptoa(physmem));
@


1.24
log
@Limit physmem to 32MB on 01-W3869B02[EF] boards which shipped with 64MB of
memory but a memory controller limited to 32MB.

Not tested for lack of such crippled hardware, just the average
once-per-leap-year act of niceness from me (a bit early though).
@
text
@d1 1
a1 1
/*	$OpenBSD: m197_machdep.c,v 1.23 2007/12/15 21:19:48 miod Exp $	*/
d339 3
d365 27
d417 1
a417 7
	/*
	 * If the other processor doesn't have an IPI pending, send one,
	 * keeping IPIs enabled for us.
	 */
	if ((*(volatile u_int8_t *)(BS_BASE + BS_CPINT) & BS_CPI_STAT) == 0)
		*(volatile u_int8_t *)(BS_BASE + BS_CPINT) =
		    BS_CPI_SCPI | BS_CPI_IEN;
d424 1
a424 1
	int wait = 0;
d435 1
a435 1
	for (wait = 10000000; wait != 0; wait--) {
@


1.23
log
@Get the MVME197 memory size from the BusSwitch decoders.
@
text
@d1 1
a1 1
/*	$OpenBSD: m197_machdep.c,v 1.22 2007/12/15 19:37:41 miod Exp $	*/
d55 1
d100 24
@


1.22
log
@Unconditionnaly disable the instruction cache on 40MHz MVME197LE boards,
so that they run stably. Definitely overkill and causing a severe performance
hit (they now run about as fast as a 25MHz board with I$ enabled would), but
sometimes you can't fight silicon bugs.

Other boards (i.e. 50MHz ones) are not affected.
@
text
@d1 1
a1 1
/*	$OpenBSD: m197_machdep.c,v 1.21 2007/12/15 19:34:35 miod Exp $	*/
d84 8
a91 2
 * Start looking from the megabyte after the end of the kernel data,
 * until we find non-memory.
d96 18
a113 6
	unsigned int *volatile look;
	unsigned int *max;
	extern char *end;
#define PATTERN   0x5a5a5a5a
#define STRIDE    (4*1024) 	/* 4k at a time */
#define Roundup(value, stride) (((unsigned)(value) + (stride) - 1) & ~((stride)-1))
d115 2
a116 1
	 * count it up.
d118 1
a118 29
#define	MAXPHYSMEM	0x30000000	/* 768MB */
	max = (void *)MAXPHYSMEM;
	for (look = (void *)Roundup(end, STRIDE); look < max;
	    look = (int *)((unsigned)look + STRIDE)) {
		unsigned save;

		/* if can't access, we've reached the end */
		if (badaddr((vaddr_t)look, 4)) {
#if defined(DEBUG)
			printf("%x\n", look);
#endif
			look = (int *)((int)look - STRIDE);
			break;
		}

		/*
		 * If we write a value, we expect to read the same value back.
		 * We'll do this twice, the 2nd time with the opposite bit
		 * pattern from the first, to make sure we check all bits.
		 */
		save = *look;
		if (*look = PATTERN, *look != PATTERN)
			break;
		if (*look = ~PATTERN, *look != ~PATTERN)
			break;
		*look = save;
	}

	return (trunc_page((vaddr_t)look));
@


1.21
log
@Since the 88110 can not invalidate a particular tlb entry, do not stack
invalidate tlb ipis, and turn them into simple ``handle once'' ipis.
@
text
@d1 1
a1 1
/*	$OpenBSD: m197_machdep.c,v 1.20 2007/12/04 23:45:53 miod Exp $	*/
d321 1
d339 6
@


1.20
log
@Work in progress SMP code for 88110 processor using the BusSwitch chip as
an IPI facility, for MVME197DP.

It's still missing a few remote cache IPIs and IPI do not seem to be reliably
triggered on remote processors at the moment (but this could be a problem
on the board I am currently testing on), at least it will boot multiuser
using only cpu0 to schedule processes.
@
text
@d1 1
a1 1
/*	$OpenBSD: m197_machdep.c,v 1.19 2007/12/02 21:32:10 miod Exp $	*/
a75 1
void	m197_send_ipi(int, cpuid_t);
d428 1
a428 1
	    (CI_IPI_TLB_FLUSH | CI_IPI_CACHE_FLUSH | CI_IPI_ICACHE_FLUSH)) {
d431 2
a432 4
		if (ipi & CI_IPI_TLB_FLUSH) {
			cmmu_flush_tlb(ci->ci_cpuid, arg1, arg2, 0);
		}
		else if (ipi & CI_IPI_CACHE_FLUSH) {
d443 6
@


1.19
log
@The beginning of a real floating-point exception handler for the 88110. The
existing code to enable TCFP was broken, as it was not setting the TCFP bit
in the right register.

So far, the exception handler will deliver SIGFPE in all cases. It will
eventually do the necessary rounding, and handle the odd-numbered register
pair operation, as I get time to write this (or see how much can be lifted
from the 88100 floating-point exception code).
@
text
@d1 1
a1 1
/*	$OpenBSD: m197_machdep.c,v 1.18 2007/11/24 14:17:17 miod Exp $	*/
d65 4
d70 1
d73 1
d76 1
d164 4
d174 8
d184 30
a213 3
		/* This is the abort switch */
		level = IPL_NMI;
		vec = BS_ABORTVEC;
a218 1
	}
a219 8
#ifdef MULTIPROCESSOR
	if (eframe->tf_mask < IPL_SCHED)
		__mp_lock(&kernel_lock);
#endif

	uvmexp.intrs++;

	if (v != T_NON_MASK || cold == 0) {
d222 2
a223 3
		flush_pipeline();
		set_psr(get_psr() & ~PSR_IND);
	}
d225 8
a232 12
	list = &intr_handlers[vec];
	if (SLIST_EMPTY(list)) {
		printf("Spurious interrupt (level %x and vec %x)\n",
		       level, vec);
	} else {
#ifdef DEBUG
		intr = SLIST_FIRST(list);
		if (intr->ih_ipl != level) {
			panic("Handler ipl %x not the same as level %x. "
			    "vec = 0x%x",
			    intr->ih_ipl, level, vec);
		}
d235 5
a261 1
	}
a262 1
	if (v != T_NON_MASK || cold == 0) {
d267 1
a267 1
		set_psr(get_psr() | PSR_IND);
d335 2
a336 4
		cpu = *(volatile u_int16_t *)(BS_BASE + BS_GCSR) &
		    BS_GCSR_CPUID;
		*(volatile u_int8_t *)(BS_BASE + (cpu ? BS_ISEL1 : BS_ISEL0)) =
		    0xfe;
d345 27
d373 130
@


1.18
log
@Be sure to program the busswitch interrupt selection register on 197SP
and 197DP to route interrupts to the processor we're booting on. This allows
a 197DP to run when booting from the second cpu.
@
text
@d1 1
a1 1
/*	$OpenBSD: m197_machdep.c,v 1.17 2007/11/22 23:33:42 miod Exp $	*/
a286 1
	extern void set_tcfp(void);
a311 2

	set_tcfp(); /* Set Time Critical Floating Point Mode */
@


1.17
log
@Split the cmmu code routines into single 88110 (MVME197LE) and 88110+88410
combos (MVME197SP/DP), and implement supposedly smarter cache routines.

There is still room for improvement, however, cache flush operation errata
permissing.

Tested on 197LE and 197DP.
@
text
@d1 1
a1 1
/*	$OpenBSD: m197_machdep.c,v 1.16 2007/11/17 05:36:23 miod Exp $	*/
d288 1
d290 1
a290 1
	if (mc88410_present())
d292 14
a305 1
	else
@


1.16
log
@Replace many ``unsigned'' variables with ``unsigned int'', ``u_int'' or other
appropriate types. No functional change.
@
text
@d1 1
a1 1
/*	$OpenBSD: m197_machdep.c,v 1.15 2007/11/17 05:32:05 miod Exp $	*/
d59 1
d286 1
d289 5
a293 1
	cmmu = &cmmu88110;
@


1.15
log
@Rework {get,set,raise}ipl() to minimize psr modification, especially on
boards such as mvme1[89]7 where spl changes can be atomic.
@
text
@d1 1
a1 1
/*	$OpenBSD: m197_machdep.c,v 1.14 2007/05/14 16:59:43 miod Exp $	*/
d120 1
a120 1
	return (trunc_page((unsigned)look));
@


1.14
log
@Hold kernel_lock when processing interrupts at a level under IPL_SCHED, as
done on 188, for MULTIPROCESSOR kernels.
@
text
@d1 1
a1 1
/*	$OpenBSD: m197_machdep.c,v 1.13 2007/05/12 20:02:14 miod Exp $	*/
d249 1
a249 1
	u_int curspl;
d251 2
d255 5
d266 1
a266 1
	u_int curspl;
d268 2
d273 5
@


1.13
log
@Change the 88100 interrupt handlers to process DAEs with interrupts enabled,
as done for DAEs not occuring during interrupts.

Remove the check for unprocessed DAE on return from trap() in eh_common.S,
since this can't happen. As a result, the return-from-trap code becomes
identical on 88100 and 88110 systems.
@
text
@d1 1
a1 1
/*	$OpenBSD: m197_machdep.c,v 1.12 2006/05/08 14:36:10 miod Exp $	*/
d174 5
d233 5
@


1.12
log
@Replace gazillions of badvaddr() or badwordaddr() calls with badaddr() calls.
With a few prototype declarations shuffling, this finally allows
<machine/locore.h> to die.
@
text
@d1 1
a1 1
/*	$OpenBSD: m197_machdep.c,v 1.11 2006/04/27 20:21:19 miod Exp $	*/
d156 1
a156 1
	int mask, level;
a162 1
	mask = *(u_int8_t *)M197_IMASK & 0x07;
a221 2
		set_psr(get_psr() | PSR_IND);

d223 2
a224 2
		 * Restore the mask level to what it was when the interrupt
		 * was taken.
d226 1
a226 1
		m197_setipl(mask);
@


1.11
log
@<machine/mvme1x7.h> is not really used anymore, remove it.
@
text
@d1 1
a1 1
/*	$OpenBSD: m197_machdep.c,v 1.10 2006/04/27 20:19:31 miod Exp $	*/
a56 1
#include <machine/locore.h>
d99 1
a99 1
		if (badwordaddr((vaddr_t)look)) {
@


1.10
log
@Adjust sizes for the mandatory 1:1 mappings created in pmap_bootstrap().
Saves up to 12KB of no longer necessary page tables.
@
text
@d1 1
a1 1
/*	$OpenBSD: m197_machdep.c,v 1.9 2006/04/19 22:09:40 miod Exp $	*/
d63 1
@


1.9
log
@Get rid of the clock device attachment - since the clock is not something
we can live without, move it into the board-dependent code. This even makes
the code slightly smaller.

clock.c is moved from dev/ to mvme88k/ and only keeps common variables and
delay().
@
text
@d1 1
a1 1
/*	$OpenBSD: m197_machdep.c,v 1.8 2006/04/13 21:16:17 miod Exp $	*/
d140 2
a141 2
	obiova = OBIO_START;
	uvm_map(kernel_map, (vaddr_t *)&obiova, OBIO_SIZE,
d145 1
a145 1
	if (obiova != OBIO_START)
@


1.8
log
@Drop the ivec[] interrupt acknowledge address array, compute the address
itself in the interrupt dispatcher instead of accessing the array: this
computation is of similar complexity, so why bother adding a memory
indirection. No functional change.
@
text
@d1 1
a1 1
/*	$OpenBSD: m197_machdep.c,v 1.7 2005/04/30 16:42:37 miod Exp $	*/
d267 5
a271 4
	md_interrupt_func_ptr = &m197_ext_int;
	md_getipl = &m197_getipl;
	md_setipl = &m197_setipl;
	md_raiseipl = &m197_raiseipl;
@


1.7
log
@Remove m88k_psr_type and function with utterly long names to control the psr,
and use get_psr() / set_psr() or simple macros that expand into them everywhere.
No functional change.
@
text
@d1 1
a1 1
/*	$OpenBSD: m197_machdep.c,v 1.6 2005/04/27 14:07:38 miod Exp $	*/
a69 1
void	m197_setupiackvectors(void);
a148 15
void
m197_setupiackvectors()
{
	u_int8_t *vaddr = (u_int8_t *)M197_IACK;

	ivec[0] = vaddr + 0x03;	/* We dont use level 0 */
	ivec[1] = vaddr + 0x07;
	ivec[2] = vaddr + 0x0b;
	ivec[3] = vaddr + 0x0f;
	ivec[4] = vaddr + 0x13;
	ivec[5] = vaddr + 0x17;
	ivec[6] = vaddr + 0x1b;
	ivec[7] = vaddr + 0x1f;
}

d160 1
d171 2
a172 1
		vec = *ivec[level];
@


1.6
log
@Always include <uvm/uvm_extern.h> before <machine/cmmu.h>.
@
text
@d1 1
a1 1
/*	$OpenBSD: m197_machdep.c,v 1.5 2004/12/24 22:50:30 miod Exp $	*/
d195 1
a195 1
		enable_interrupt();
d237 1
a237 1
		disable_interrupt();
@


1.5
log
@{e,}intr{cnt,names} bye-bye.
@
text
@d1 1
a1 1
/*	$OpenBSD: m197_machdep.c,v 1.4 2004/11/09 21:50:01 miod Exp $	*/
d52 2
a60 2

#include <uvm/uvm_extern.h>
@


1.4
log
@Kill guarded_access() - the way we map OBIO, there is no need for special
treatement of interrupt vectors variables, a simple read will do.

While there, speed up the interrupt handlers a bit:
- remove old debug code or only compile it if option DEBUG.
- use short circuits for setipl() if we know interrupts are disabled at
  this point: there is no need playing with the psr in these cases.
@
text
@d1 1
a1 1
/*	$OpenBSD: m197_machdep.c,v 1.3 2004/11/09 12:01:19 miod Exp $	*/
a199 2
		/* increment intr counter */
		intrcnt[M88K_SPUR_IRQ]++;
a224 1
				intrcnt[level]++;
@


1.3
log
@Split {get,set,raise}ipl() into per-board implementations.
@
text
@d1 1
a1 1
/*	$OpenBSD: m197_machdep.c,v 1.2 2004/11/08 16:39:31 miod Exp $	*/
d172 1
a172 1
	int mask, level, src;
d176 1
a176 1
	u_char vec;
a177 1
	/* get src and mask */
a178 2
	src = *(u_int8_t *)M197_ISRC;

a183 1
		/* get level  */
d185 2
a188 11
#ifdef DIAGNOSTIC
	/*
	 * Interrupting level cannot be 0--0 doesn't produce an interrupt.
	 * Weird! XXX nivas
	 */

	if (level == 0) {
		panic("Bogons... level %x and mask %x", level, mask);
	}
#endif

a190 11
	if (v != T_NON_MASK) {
		/* generate IACK and get the vector */
		flush_pipeline();
		if (guarded_access(ivec[level], 1, &vec) == EFAULT) {
			panic("Unable to get vector for this interrupt (level %x)", level);
		}
		flush_pipeline();
		flush_pipeline();
		flush_pipeline();
	}

d193 2
a194 2
		setipl(level);

d205 1
a205 1
#ifdef DIAGNOSTIC
d246 1
a246 1
		setipl(mask);
@


1.2
log
@Kill struct md_p, which was really only necessary for mvme88k; on
luna88k it disappears completely, while mvme88k keeps 3 global variables,
one of them scheduled to disappear very soon.
@
text
@d1 1
a1 1
/*	$OpenBSD: m197_machdep.c,v 1.1 2004/10/01 19:00:52 miod Exp $	*/
d66 1
d68 2
d179 1
a179 1
	mask = *md_intr_mask & 0x07;
d274 27
d309 4
a312 1
	md_intr_mask = (u_char *)M197_IMASK;
@


1.1
log
@More mvme88k code cleaning:
- merge locore_c_routines.c into machdep.c
- split machdep.c into really machdep.c content, and board-specific routines
  (memory sizing, early initialization, etc).

No functionnal change.
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d176 2
a177 2
	mask = *md.intr_mask & 0x07;
	src = *md.intr_src;
d185 1
a185 1
		level = *md.intr_ipl & 0x07;
d278 2
a279 4
	md.interrupt_func = &m197_ext_int;
	md.intr_mask = (u_char *)M197_IMASK;
	md.intr_ipl = (u_char *)M197_ILEVEL;
	md.intr_src = (u_char *)M197_ISRC;
@

