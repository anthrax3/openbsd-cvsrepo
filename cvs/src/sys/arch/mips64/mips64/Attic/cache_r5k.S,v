head	1.37;
access;
symbols
	OPENBSD_5_1_BASE:1.28
	OPENBSD_5_1:1.28.0.10
	OPENBSD_5_0:1.28.0.8
	OPENBSD_5_0_BASE:1.28
	OPENBSD_4_9:1.28.0.6
	OPENBSD_4_9_BASE:1.28
	OPENBSD_4_8:1.28.0.4
	OPENBSD_4_8_BASE:1.28
	OPENBSD_4_7:1.28.0.2
	OPENBSD_4_7_BASE:1.28
	OPENBSD_4_6:1.23.0.4
	OPENBSD_4_6_BASE:1.23
	OPENBSD_4_5:1.22.0.4
	OPENBSD_4_5_BASE:1.22
	OPENBSD_4_4:1.22.0.2
	OPENBSD_4_4_BASE:1.22
	OPENBSD_4_3:1.21.0.2
	OPENBSD_4_3_BASE:1.21
	OPENBSD_4_2:1.19.0.2
	OPENBSD_4_2_BASE:1.19
	OPENBSD_4_1:1.16.0.8
	OPENBSD_4_1_BASE:1.16
	OPENBSD_4_0:1.16.0.6
	OPENBSD_4_0_BASE:1.16
	OPENBSD_3_9:1.16.0.4
	OPENBSD_3_9_BASE:1.16
	OPENBSD_3_8:1.16.0.2
	OPENBSD_3_8_BASE:1.16
	OPENBSD_3_7:1.15.0.2
	OPENBSD_3_7_BASE:1.15
	OPENBSD_3_6:1.7.0.2
	OPENBSD_3_6_BASE:1.7;
locks; strict;
comment	@# @;


1.37
date	2012.06.23.21.56.06;	author miod;	state dead;
branches;
next	1.36;

1.36
date	2012.04.24.20.06.21;	author miod;	state Exp;
branches;
next	1.35;

1.35
date	2012.04.21.12.20.30;	author miod;	state Exp;
branches;
next	1.34;

1.34
date	2012.04.06.20.11.18;	author miod;	state Exp;
branches;
next	1.33;

1.33
date	2012.03.25.13.45.05;	author miod;	state Exp;
branches;
next	1.32;

1.32
date	2012.03.19.20.42.26;	author miod;	state Exp;
branches;
next	1.31;

1.31
date	2012.02.16.20.31.30;	author miod;	state Exp;
branches;
next	1.30;

1.30
date	2012.02.16.20.28.14;	author miod;	state Exp;
branches;
next	1.29;

1.29
date	2012.02.16.20.21.46;	author miod;	state Exp;
branches;
next	1.28;

1.28
date	2010.01.09.23.34.29;	author miod;	state Exp;
branches;
next	1.27;

1.27
date	2009.12.25.20.59.45;	author miod;	state Exp;
branches;
next	1.26;

1.26
date	2009.11.19.20.16.27;	author miod;	state Exp;
branches;
next	1.25;

1.25
date	2009.08.06.21.09.18;	author miod;	state Exp;
branches;
next	1.24;

1.24
date	2009.08.06.21.06.30;	author miod;	state Exp;
branches;
next	1.23;

1.23
date	2009.05.22.20.37.53;	author miod;	state Exp;
branches;
next	1.22;

1.22
date	2008.04.07.22.30.47;	author miod;	state Exp;
branches;
next	1.21;

1.21
date	2007.10.24.20.04.26;	author miod;	state Exp;
branches;
next	1.20;

1.20
date	2007.10.18.04.32.25;	author miod;	state Exp;
branches;
next	1.19;

1.19
date	2007.06.18.20.25.55;	author miod;	state Exp;
branches;
next	1.18;

1.18
date	2007.05.27.09.23.04;	author miod;	state Exp;
branches;
next	1.17;

1.17
date	2007.03.21.05.26.37;	author miod;	state Exp;
branches;
next	1.16;

1.16
date	2005.07.20.21.36.32;	author miod;	state Exp;
branches;
next	1.15;

1.15
date	2004.09.29.12.52.44;	author pefo;	state Exp;
branches;
next	1.14;

1.14
date	2004.09.29.12.16.55;	author pefo;	state Exp;
branches;
next	1.13;

1.13
date	2004.09.21.08.39.46;	author pefo;	state Exp;
branches;
next	1.12;

1.12
date	2004.09.20.15.43.35;	author miod;	state Exp;
branches;
next	1.11;

1.11
date	2004.09.20.11.04.23;	author pefo;	state Exp;
branches;
next	1.10;

1.10
date	2004.09.20.10.29.57;	author pefo;	state Exp;
branches;
next	1.9;

1.9
date	2004.09.16.10.13.37;	author miod;	state Exp;
branches;
next	1.8;

1.8
date	2004.09.16.07.25.26;	author miod;	state Exp;
branches;
next	1.7;

1.7
date	2004.09.10.09.32.13;	author pefo;	state Exp;
branches;
next	1.6;

1.6
date	2004.09.10.08.58.27;	author pefo;	state Exp;
branches;
next	1.5;

1.5
date	2004.09.09.22.11.38;	author pefo;	state Exp;
branches;
next	1.4;

1.4
date	2004.08.10.20.15.47;	author deraadt;	state Exp;
branches;
next	1.3;

1.3
date	2004.08.09.14.57.26;	author pefo;	state Exp;
branches;
next	1.2;

1.2
date	2004.08.07.14.48.26;	author pefo;	state Exp;
branches;
next	1.1;

1.1
date	2004.08.06.20.56.03;	author pefo;	state Exp;
branches;
next	;


desc
@@


1.37
log
@Replace R5000 and R10000 family assembly cache routines with C equivalents,
which will be easier to maintain on the long run. Be sure to rm cache_r*.d in
your kernel compile directories after updating.
@
text
@/*	$OpenBSD: cache_r5k.S,v 1.36 2012/04/24 20:06:21 miod Exp $ */

/*
 * Copyright (c) 1998-2004 Opsycon AB (www.opsycon.se)
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 *
 * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS
 * OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
 * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY
 * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
 *
 */

/*
 * Processors supported:
 * R4600/R4700 (if option CPU_R4600)
 * R5000, RM52xx, RM7xxx, RM9xxx
 *
 * The following assumptions are made:
 * - L1 I$ is 2 way, 32 bytes/line
 * - L1 D$ is WB, 2 way, 32 bytes/line
 * - L2 may not exist
 * - L3 may not exist
 * - L3 implies internal L2
 * - all external caches are WT
 */

#include <sys/errno.h>
#include <sys/syscall.h>

#include <machine/param.h>
#include <machine/asm.h>
#include <machine/cpu.h>
#include <machine/regnum.h>

#include "assym.h"

	.set	mips3

/*
 *  Skip the .h file. Noone else need to know!
 */

#define	IndexInvalidate_I	0x00
#define	IndexWBInvalidate_D	0x01
#define	IndexWBInvalidate_S	0x03

#define	IndexStoreTag_S		0x0b

#define	HitInvalidate_D		0x11
#define	HitInvalidate_S		0x13

#define	HitWBInvalidate_D	0x15
#define	InvalidatePage_T	0x16
#define	HitWBInvalidate_S	0x17
#define	InvalidatePage_S	0x17	/* Only RM527[0-1] */

/*
 *  R5000 and RM52xx config register bits.
 */
#define	CF_5_SE		(1 << 12)	/* Secondary cache enable */
#define	CF_5_SC		(1 << 17)	/* Secondary cache not present */
#define	CF_5_SS		(3 << 20)	/* Secondary cache size */
#define	CF_5_SS_AL	20		/* Shift to align */

/*
 *  RM7000 config register bits.
 */
#define	CF_7_SE		(1 << 3)	/* Secondary cache enable */
#define	CF_7_SC		(1 << 31)	/* Secondary cache not present */
#define	CF_7_TE		(1 << 12)	/* Tertiary cache enable */
#define	CF_7_TC		(1 << 17)	/* Tertiary cache not present */
#define	CF_7_TS		(3 << 20)	/* Tertiary cache size */
#define	CF_7_TS_AL	20		/* Shift to align */

/*
 *  Define cache type definition bits. NOTE! the 3 lsb may NOT change!
 */
#define	CTYPE_DIR		0x0001	/* Cache is direct mapped */
#define	CTYPE_2WAY		0x0002	/* Cache is TWO way */
#define	CTYPE_4WAY		0x0004	/* Cache is FOUR way */
#define	CTYPE_WAYMASK		0x0007

#define	CTYPE_HAS_IL2		0x0100	/* Internal L2 Cache present */
#define	CTYPE_HAS_XL2		0x0200	/* External L2 Cache present */
#define	CTYPE_HAS_XL3		0x0400	/* External L3 Cache present */

/*
 *  Due to a flaw in RM7000 1.x processors a pipeline 'drain' is
 *  required after some mtc0 instructions.
 *  Ten nops in sequence does the trick.
 */
#define NOP10	nop;nop;nop;nop;nop;\
		nop;nop;nop;nop;nop	/* Two cycles for dual issue machine */

	.set	noreorder		# Noreorder is default style!

/*----------------------------------------------------------------------------
 *
 * Mips5k_ConfigCache(struct cpu_info *ci) --
 *
 *	Size and configure the caches.
 *	NOTE: should only be called from mips_init().
 *
 * Side effects:
 *	The size of the data cache is stored into ci_l1datacachesize.
 *	The size of instruction cache is stored into ci_l1instcachesize.
 *	Alignment mask for cache aliasing test is stored in cache_valias_mask.
 *	ci_l2size is set to the size of the secondary cache.
 *	ci_l3size is set to the size of the tertiary cache.
 *	ci_cacheways is set to 0 for direct mapped caches, 2 for two way
 *	caches and 4 for four way caches. This primarily indicates the
 *	primary cache associativity.
 *
 * Allocation:
 *	ta0, ta1 ta2 used to hold I and D set size and Alias mask.
 *
 *----------------------------------------------------------------------------
 */
LEAF(Mips5k_ConfigCache, 0)
	.set	noreorder
	LA	v0, 1f
	LA	v1, CKSEG1_BASE
	or	v0, v1
	jr	v0				# Switch to uncached.
	nop
1:
	mfc0	v1, COP_0_PRID			# read processor ID register
	mfc0	v0, COP_0_CONFIG		# Get configuration register

	srl	t1, v0, 9			# Get I cache size.
	and	t1, 7
	li	t2, 4096
	sllv	ta0, t2, t1			# ta0 = Initial I set size.

	and	t2, v0, 0x20
	srl	t2, 1				# Get I cache line size.
	addu	t2, 16
	sw	t2, CI_L1INSTCACHELINE(a0)

	srl	t1, v0, 6			# Get D cache size.
	and	t1, 7
	li	t2, 4096			# Fixed page size.
	sllv	ta1, t2, t1

	and	t2, v0, 0x10
	addu	t2, 16				# Get D cache line size.
	sw	t2, CI_L1DATACACHELINE(a0)

	li	t2, CTYPE_2WAY			# Assume two way cache
	li	ta2, 0				# Secondary size 0.
	li	ta3, 0				# Tertiary size 0.

	and	v1, 0xff00			# Recognize CPU's with
	li	t1, (MIPS_R5000 << 8)		# N way L1 caches only.
	beq	v1, t1, Conf5K			# R5K 2 way, check L2
	li	t1, (MIPS_RM52X0 << 8)
	beq	v1, t1, Conf5K			# RM52xx 2 way, check L2
	li	t1, (MIPS_RM7000 << 8)
	beq	v1, t1, Conf7K
	li	t1, (MIPS_RM9000 << 8)
	beq	v1, t1, Conf7K
	nop

	b	ConfResult			# R4[67]00 2 way, No L2 control
	nop

#---- R5K ------------------------------
Conf5K:						# R5xxx type, check for L2 cache
	and	t1, v0, CF_5_SC
	bnez	t1, ConfResult			# not enabled
	li	ta2, 0				# set size to 0.

	li	t3, CF_5_SS
	and	t1, t3, v0
	beq	t1, t3, ConfResult		# No L2 cache
	srl	t1, CF_5_SS_AL

	li	t3, CF_5_SE			# Set SE in conf
	or	v0, t3				# Update config register
	li	ta2, 512*1024			# 512k per 'click'.
	sll	ta2, t1

	mtc0	v0, COP_0_CONFIG		# Enable L2 cache
	or	t2, CTYPE_HAS_XL2		# External L2 present.
	mtc0	zero, COP_0_TAG_LO		# necessary for RM52xx
	LOAD_XKPHYS(t0, CCA_CACHED)
	PTR_ADDU t1, t0, ta2
1:
	cache	InvalidatePage_S, 0(t0)
	PTR_ADDU t0, 4096
	bne	t0, t1, 1b
	nop

	b	ConfResult
	nop

#---- RM7K -----------------------------
Conf7K:					# RM7000, check for L2 and L3 cache
	li	t2, CTYPE_4WAY			# 4-way cache
	and	t1, v0, CF_7_TC
	bnez	t1, Conf7KL2			# No L3 cache if set
	li	ta3, 0				# Set size = 0

#ifndef L3SZEXT
	li	t3, CF_7_TS
	and	t1, t3, v0
	beq	t1, t3, Conf7KL2		# No L3 cache
	srl	t1, CF_7_TS_AL

	or	t2, CTYPE_HAS_XL3		# External L2 present.
	li	t3, CF_7_TE			# Set TE in conf
	or	v0, t3				# Update config register
	li	ta3, 512*1024			# 512k per 'click'.
	sll	ta3, t1
#else
	lw	ta3, CI_L3SIZE(a0)
	and	t2, ~CTYPE_HAS_XL3
	beqz	ta3, Conf7KL2			# No L3 cache present
	nop

	li	t3, CF_7_TE			# Set SE in conf
	or	v0, t3				# Update config register
	mtc0	v0, COP_0_CONFIG		# Enable L3 cache
	or	t2, CTYPE_HAS_XL3
#endif

	mtc0	zero, COP_0_TAG_LO
	LOAD_XKPHYS(t0, CCA_CACHED)
	PTR_ADDU t1, t0, ta3
1:
	cache	InvalidatePage_T, 0(t0)
	PTR_ADDU t0, 4096
	bne	t0, t1, 1b
	nop

Conf7KL2:
	and	t1, v0, CF_7_SC			# check for L2 cache
	bnez	t1, ConfResult
	li	ta2, 0				# No L2?

	and	t1, v0, CF_7_SE
	bnez	t1, 3f
	ori	v0, CF_7_SE

	mtc0	v0, COP_0_CONFIG		# Enable and init L2 cache
	LOAD_XKPHYS(t0, CCA_CACHED)
	PTR_ADDU t1, t0, ta3
1:
	PTR_ADDU t0, 32
	bne	t0, t1, 1b
	cache	IndexStoreTag_S, -4(t0)
	sync

	LOAD_XKPHYS(t0, CCA_CACHED)
	PTR_ADDU t1, t0, ta3
1:
	PTR_ADDU t0, 32
	bne	t0, t1, 1b
	lw	zero, -4(t0)
	sync

	LOAD_XKPHYS(t0, CCA_CACHED)
	PTR_ADDU t1, t0, ta3
1:
	PTR_ADDU t0, 32
	bne	t0, t1, 1b
	cache	IndexStoreTag_S, -4(t0)
	sync

3:
	or	t2, CTYPE_HAS_IL2		# L2 is on chip
	b	ConfResult
	li	ta2, 256*1024			# L2 size = 256k

/*
 * Get here with t2 = Cache type, ta0 = L1 I size, ta1 = L1 D size.
 * ta2 = secondary size, ta3 = tertiary size.
 */
ConfResult:
	sw	t2, CI_CACHECONFIGURATION(a0)	# Save cache attributes
	and	t2, CTYPE_WAYMASK		# isolate number of sets.
	sw	t2, CI_CACHEWAYS(a0)
	srl	t2, 1				# get div shift for set size.

	sw	ta2, CI_L2SIZE(a0)
	sw	ta3, CI_L3SIZE(a0)

	addu	t1, ta0, -1			# Use icache for alias mask
	srl	t1, t2
	srl	t1, PAGE_SHIFT
	beqz	t1, 1f
	sll	t1, PAGE_SHIFT
	or	t1, (PAGE_SIZE - 1)
1:
	PTR_S	t1, cache_valias_mask
	PTR_S	t1, pmap_prefer_mask

	sw	ta0, CI_L1INSTCACHESIZE(a0)	# store cache size.
	srl	ta0, t2				# calculate set size.
	sw	ta0, CI_L1INSTCACHESET(a0)

	sw	ta1, CI_L1DATACACHESIZE(a0)	# store cache size.
	srl	ta1, t2				# calculate set size.
	sw	ta1, CI_L1DATACACHESET(a0)

	and	v0, ~7
	or	v0, CCA_CACHED			# set cachable writeback kseg0
	mtc0	v0, COP_0_CONFIG		# establish any new config
	NOP10
	j	ra
	nop
END(Mips5k_ConfigCache)

/*----------------------------------------------------------------------------
 *
 * Mips5k_SyncCache(struct cpu_info *ci) --
 *
 *	Sync ALL caches.
 *	No need to look at number of sets since we are cleaning out
 *	the entire cache and thus will address all sets anyway.
 *
 * Side effects:
 *	The contents of ALL caches are Invalidated or Synched.
 *
 *----------------------------------------------------------------------------
 */
LEAF(Mips5k_SyncCache, 0)
	.set	noreorder
	lw	t1, CI_L1INSTCACHESIZE(a0)
	lw	t2, CI_L1DATACACHESIZE(a0)

/*
 * Sync the instruction cache.
 */
#ifdef CPUR4600
	mfc0	v1, COP_0_STATUS_REG		# Save the status register.
	li	v0, SR_DIAG_DE
	mtc0	v0, COP_0_STATUS_REG		# Disable interrupts
#endif

	LOAD_XKPHYS(t0, CCA_CACHED)
	PTR_ADDU t1, t0, t1			# Compute end address
	PTR_SUBU t1, 128

1:
	cache	IndexInvalidate_I, 0(t0)
	cache	IndexInvalidate_I, 32(t0)
	cache	IndexInvalidate_I, 64(t0)
	cache	IndexInvalidate_I, 96(t0)

	bne	t0, t1, 1b
	PTR_ADDU t0, 128

/*
 * Sync the data cache. Do L1 first. Indexed only operate on
 * the selected cache and differs from Hit in that sense.
 */

	LOAD_XKPHYS(t0, CCA_CACHED)
	PTR_ADDU t1, t0, t2			# End address
	PTR_SUBU t1, 128
1:
	cache	IndexWBInvalidate_D, 0(t0)
	cache	IndexWBInvalidate_D, 32(t0)
	cache	IndexWBInvalidate_D, 64(t0)
	cache	IndexWBInvalidate_D, 96(t0)

	bne	t0, t1, 1b
	PTR_ADDU t0, 128

/* Do on chip L2 if present */
	lw	t0, CI_CACHECONFIGURATION(a0)
	and	t0, CTYPE_HAS_IL2
	beqz	t0, 20f
	nop

3:
	LOAD_XKPHYS(t3, CCA_CACHED)
	lw	ta0, CI_L2SIZE(a0)
1:
	cache	IndexWBInvalidate_S, 0(t3)
	PTR_SUBU ta0, 32			# Fixed cache line size.
	bgtz	ta0, 1b
	PTR_ADDU t3, 32

/* Do off chip L2 if present */
20:
	lw	t0, CI_CACHECONFIGURATION(a0)
	and	t0, CTYPE_HAS_XL2
	beqz	t0, 30f
	nop

	mtc0    zero, COP_0_TAG_LO
	LOAD_XKPHYS(t3, CCA_CACHED)
	lw	ta0, CI_L2SIZE(a0)
1:
	cache	InvalidatePage_S, 0(t3)
	PTR_SUBU ta0, 4096			# Fixed external cache page size
	bgtz	ta0, 1b
	PTR_ADDU t3, 4096

/* Do off chip L3 if present */
30:
	lw	t0, CI_CACHECONFIGURATION(a0)
	and	t0, CTYPE_HAS_XL3
	beqz	t0, 99f
	nop

	mtc0    zero, COP_0_TAG_LO
	LOAD_XKPHYS(t3, CCA_CACHED)
	lw	ta0, CI_L3SIZE(a0)
1:
	cache	InvalidatePage_T, 0(t3)
	PTR_SUBU ta0, 4096			# Fixed external cache page size
	bgtz	ta0, 1b
	PTR_ADDU t3, 4096

99:
#ifdef CPUR4600
	mtc0	v1, COP_0_STATUS_REG	# Restore the status register.
	NOP10
#endif
	sync
	j	ra
	nop
END(Mips5k_SyncCache)

/*----------------------------------------------------------------------------
 *
 * Mips5k_SyncICache(struct cpu_info *, vaddr_t va, size_t len)
 *
 *	Invalidate the L1 instruction cache for at least range of va to
 *	va + len - 1.
 *
 * Side effects:
 *	The contents of the L1 Instruction cache is flushed.
 *
 *----------------------------------------------------------------------------
 */
LEAF(Mips5k_InvalidateICache, 0)
#ifdef CPUR4600
	mfc0	v1, COP_0_STATUS_REG		# Save the status register.
	li	v0, SR_DIAG_DE
	mtc0	v0, COP_0_STATUS_REG		# Disable interrupts
#endif
	lw	v0, CI_CACHEWAYS(a0)		# Cache properties
	lw	t0, CI_L1INSTCACHESET(a0)	# Set size
	dsll	a1, (64 - 57)
	dsrl	a1, (64 - 57)
	LOAD_XKPHYS(a3, CCA_CACHED)
	PTR_ADDU a2, 31				# Round up size
	PTR_ADDU a2, a1				# Add extra from address
	dsrl	a1, 5				# Align start address
	dsll	a1, 5
	PTR_SUBU a2, a1
	PTR_ADDU a1, a3				# a1 now new XKPHYS address
	dsrl	a2, 5				# Number of unrolled loops
	addiu	v0, -2				# <0 1way, 0 = two, >0 four
1:
	bltz	v0, 3f
	PTR_ADDU a2, -1

2:
	PTR_ADDU t1, t0, a1			# Nway cache, flush set B.
	cache	IndexInvalidate_I, 0(t1)
	beqz	v0, 3f				# If two way do set A
	PTR_ADDU t1, t0				# else step to set C.

	cache	IndexInvalidate_I, 0(t1)

	PTR_ADDU t1, t0				# step to set D
	cache	IndexInvalidate_I, 0(t1)

3:
	cache	IndexInvalidate_I, 0(a1)	# do set (A if NWay)

	bnez	a2, 1b
	PTR_ADDU a1, 32

#ifdef CPUR4600
	mtc0	v1, COP_0_STATUS_REG	# Restore the status register.
	NOP10
#endif
	sync
	j	ra
	nop
END(Mips5k_InvalidateICache)

/*----------------------------------------------------------------------------
 *
 * Mips5k_SyncDCachePage(struct cpu_info *ci, vaddr_t va, paddr_t pa)
 *
 *	Sync the L1 data cache page for address va.
 *	The physical address is used to compute the L2 index.
 *
 * Side effects:
 *	The contents of the cache is written back to primary memory.
 *	The cache line is invalidated.
 *
 *----------------------------------------------------------------------------
 */
LEAF(Mips5k_SyncDCachePage, 0)
#ifdef CPUR4600
	mfc0	v1, COP_0_STATUS_REG		# Save the status register.
	li	v0, SR_DIAG_DE
	mtc0	v0, COP_0_STATUS_REG		# Disable interrupts
#endif
	LOAD_XKPHYS(a3, CCA_CACHED)
	lw	v0, CI_CACHEWAYS(a0)
	dsll	a1, (64 - 57)
	dsrl	a1, (64 - 57) + PAGE_SHIFT
	dsll	a1, PAGE_SHIFT			# Page align start address
	PTR_ADDU a1, a3				# a1 now new XKPHYS address
	PTR_ADDU a4, a1, PAGE_SIZE-128
	addiu	v0, -2				# <0 1way, 0 = two, >0 four
	lw	a3, CI_L1DATACACHESET(a0)

1:
	bltz	v0, 3f
	PTR_ADDU t1, a1, a3
	cache	IndexWBInvalidate_D, 0(t1)	# flush set B.
	cache	IndexWBInvalidate_D, 32(t1)
	cache	IndexWBInvalidate_D, 64(t1)
	cache	IndexWBInvalidate_D, 96(t1)
	beqz	v0, 3f				# two way, skip C and D.
	PTR_ADDU t1, a3

	cache	IndexWBInvalidate_D, 0(t1)	# do set C
	cache	IndexWBInvalidate_D, 32(t1)
	cache	IndexWBInvalidate_D, 64(t1)
	cache	IndexWBInvalidate_D, 96(t1)

	PTR_ADDU t1, a3				# do set D
	cache	IndexWBInvalidate_D, 0(t1)
	cache	IndexWBInvalidate_D, 32(t1)
	cache	IndexWBInvalidate_D, 64(t1)
	cache	IndexWBInvalidate_D, 96(t1)
3:
	cache	IndexWBInvalidate_D, 0(a1)	# do set A
	cache	IndexWBInvalidate_D, 32(a1)
	cache	IndexWBInvalidate_D, 64(a1)
	cache	IndexWBInvalidate_D, 96(a1)

	bne	a4, a1, 1b
	PTR_ADDU a1, 128

	lw	t0, CI_CACHECONFIGURATION(a0)
	and	t0, CTYPE_HAS_IL2		# Have internal L2?
	beqz	t0, 9f

	LOAD_XKPHYS(a3, CCA_CACHED)		# Yes, do L2 with the physical
	dsrl	a2, PAGE_SHIFT
	dsll	a2, PAGE_SHIFT			# Page align start address
	PTR_ADDU a1, a2, a3			# address for the index
	PTR_ADDU a4, a1, PAGE_SIZE-128
	lw	a3, CI_L2SIZE(a0)
	srl	a3, 2				# Hardcoded 4-way

1:
	cache	IndexWBInvalidate_S, 0(a1)	# do set A
	cache	IndexWBInvalidate_S, 32(a1)
	cache	IndexWBInvalidate_S, 64(a1)
	cache	IndexWBInvalidate_S, 96(a1)

	PTR_ADDU t1, a1, a3
	cache	IndexWBInvalidate_S, 0(t1)	# do set B.
	cache	IndexWBInvalidate_S, 32(t1)
	cache	IndexWBInvalidate_S, 64(t1)
	cache	IndexWBInvalidate_S, 96(t1)

	PTR_ADDU t1, a3
	cache	IndexWBInvalidate_S, 0(t1)	# do set C
	cache	IndexWBInvalidate_S, 32(t1)
	cache	IndexWBInvalidate_S, 64(t1)
	cache	IndexWBInvalidate_S, 96(t1)

	PTR_ADDU t1, a3				# do set D
	cache	IndexWBInvalidate_S, 0(t1)
	cache	IndexWBInvalidate_S, 32(t1)
	cache	IndexWBInvalidate_S, 64(t1)
	cache	IndexWBInvalidate_S, 96(t1)

	bne	a4, a1, 1b
	PTR_ADDU a1, 128

9:
#ifdef CPUR4600
	mtc0	v1, COP_0_STATUS_REG	# Restore the status register.
#endif
	sync
	j	ra
	nop
END(Mips5k_SyncDCachePage)

/*----------------------------------------------------------------------------
 *
 * Mips5k_HitSyncDCache(struct cpu_info *ci, vaddr_t va, size_t len)
 *
 *	Sync data cache for range of va to va + len - 1.
 *	Only lines with matching addresses are flushed.
 *
 * Side effects:
 *	The contents of the L1 cache is written back to primary memory.
 *	The cache line is invalidated.
 *
 * IMPORTANT NOTE:
 *	Since orphaned L1 cache entries will not be synched it is
 *	mandatory to pass over the L1 cache once after the L2 is done.
 *
 *----------------------------------------------------------------------------
 */
LEAF(Mips5k_HitSyncDCache, 0)
#ifdef CPUR4600
	mfc0	v1, COP_0_STATUS_REG		# Save the status register.
	li	v0, SR_DIAG_DE
	mtc0	v0, COP_0_STATUS_REG		# Disable interrupts
#endif
	beqz	a2, 3f				# size is zero!
	PTR_ADDU a2, 31				# Round up
	PTR_ADDU a2, a1				# Add extra from address
	dsrl	a1, 5
	dsll	a1, 5				# align address
	PTR_SUBU a2, a1
	dsrl	a2, 5				# Compute number of cache lines

1:
	PTR_ADDU a2, -1
	cache	HitWBInvalidate_D, 0(a1)
	bnez	a2, 1b
	PTR_ADDU a1, 32

3:
#ifdef CPUR4600
	mtc0	v1, COP_0_STATUS_REG	# Restore the status register.
	NOP10
#endif
	sync
	j	ra
	nop
END(Mips5k_HitSyncDCache)


/*----------------------------------------------------------------------------
 *
 * _mips5k_HitSyncSCache(struct cpu_info *ci, vaddr_t va, size_t len)
 *
 *	Sync secondary cache for range of va to va + len - 1.
 *	Only lines with matching addresses are flushed.
 *
 * Side effects:
 *	The contents of the L2 cache is written back to primary memory.
 *	The cache line is invalidated.
 *
 * IMPORTANT NOTE:
 *	Since orphaned L1 cache entries will not be synched it is
 *	mandatory to pass over the L1 cache once after the L2 is done.
 *
 *----------------------------------------------------------------------------
 */
ALEAF(_mips5k_HitSyncSCache)
#ifdef CPUR4600
	mfc0	v1, COP_0_STATUS_REG		# Save the status register.
	li	v0, SR_DIAG_DE
	mtc0	v0, COP_0_STATUS_REG		# Disable interrupts
#endif

	beqz	a2, 3f				# size is zero!
	PTR_ADDU a2, 31				# Round up
	PTR_ADDU a2, a1				# Add in extra from align
	dsrl	a1, 5
	dsll	a1, 5				# align address
	PTR_SUBU a2, a1
	dsrl	a2, 5				# Compute number of cache lines
1:
	PTR_ADDU a2, -1
	cache	HitWBInvalidate_S, 0(a1)
	cache	HitWBInvalidate_D, 0(a1)	# Orphans in L1
	bnez	a2, 1b
	PTR_ADDU a1, 32

3:
#ifdef CPUR4600
	mtc0	v1, COP_0_STATUS_REG	# Restore the status register.
	NOP10
#endif
	sync
	j	ra
	nop

/*----------------------------------------------------------------------------
 *
 * Mips5k_HitInvalidateDCache(struct cpu_info *ci, vaddr_t va, size_t len)
 *
 *	Invalidate data cache for range of va to va + len - 1.
 *	Only lines with matching addresses are invalidated.
 *
 * Side effects:
 *	The L1 cache line is invalidated.
 *
 *----------------------------------------------------------------------------
 */
LEAF(Mips5k_HitInvalidateDCache, 0)
#ifdef CPUR4600
	mfc0	v1, COP_0_STATUS_REG		# Save the status register.
	li	v0, SR_DIAG_DE
	mtc0	v0, COP_0_STATUS_REG		# Disable interrupts
#endif

	beqz	a2, 3f				# size is zero!
	PTR_ADDU a2, 31				# Round up
	PTR_ADDU a2, a1				# Add in extra from align
	dsrl	a1, 5
	dsll	a1, 5				# align address
	PTR_SUBU a2, a1
	dsrl	a2, 5				# Compute number of cache lines
1:
	PTR_ADDU a2, -1
	cache	HitInvalidate_D, 0(a1)
	bnez	a2, 1b
	PTR_ADDU a1, 32

3:
#ifdef CPUR4600
	mtc0	v1, COP_0_STATUS_REG		# Restore the status register.
	NOP10
#endif
	sync
	j	ra
	nop
END(Mips5k_HitInvalidateDCache)

/*----------------------------------------------------------------------------
 *
 * _mips5k_HitInvalidateSCache(struct cpu_info *ci, vaddr_t va, size_t len)
 *
 *	Invalidate secondary cache for range of va to va + len - 1.
 *	Only lines with matching addresses are invalidated.
 *
 * Side effects:
 *	The L2 cache line is invalidated.
 *
 *----------------------------------------------------------------------------
 */
ALEAF(_mips5k_HitInvalidateSCache)
#ifdef CPUR4600
	mfc0	v1, COP_0_STATUS_REG		# Save the status register.
	li	v0, SR_DIAG_DE
	mtc0	v0, COP_0_STATUS_REG		# Disable interrupts
#endif

	beqz	a2, 3f				# size is zero!
	PTR_ADDU a2, 31				# Round up
	PTR_ADDU a2, a1				# Add in extra from align
	dsrl	a1, 5
	dsll	a1, 5				# align address
	PTR_SUBU a2, a1
	dsrl	a2, 5				# Compute number of cache lines
1:
	PTR_ADDU a2, -1
	cache	HitInvalidate_S, 0(a1)
	cache	HitInvalidate_D, 0(a1)		# Orphans in L1
	bnez	a2, 1b
	PTR_ADDU a1, 32

3:
#ifdef CPUR4600
	mtc0	v1, COP_0_STATUS_REG	# Restore the status register.
	NOP10
#endif
	sync
	j	ra
	nop

/*----------------------------------------------------------------------------
 *
 * Mips5k_IOSyncDCache(struct cpu_info *ci, vaddr_t va, size_t len, int how)
 *
 *	Invalidate or flush data cache for range of va to va + len - 1.
 *
 *	In case of the existence of an external cache we invalidate pages
 *	which are in the given range ONLY if transfer direction is READ.
 *	The assumption here is a 'write through' external cache which is
 *	true for all now supported processors.
 *
 * Side effects:
 *	If how == 0 (read), L1 and on-chip L2 caches are invalidated or
 *		flushed if the area does not match the alignment requirements.
 *		Writethrough L2 and L3 cache are invalidated for the address
 *		range.
 *	If how == 1 (write), L1 and on-chip L2 caches are written back to
 *		memory and invalidated. Writethrough L2 and L3 caches are
 *		left alone.
 *	If how == 2 (write-read), L1 and on-chip L2 caches are written back
 *		to memory and invalidated. Writethrough L2 and L3 caches are
 *		invalidated.
 *
 *----------------------------------------------------------------------------
 */
NON_LEAF(Mips5k_IOSyncDCache, FRAMESZ(CF_SZ+2*REGSZ), ra)
	PTR_SUBU sp, FRAMESZ(CF_SZ+2*REGSZ)
	PTR_S	ra, CF_RA_OFFS+2*REGSZ(sp)
	REG_S	a1, CF_ARGSZ(sp)		# save args
	REG_S	a2, CF_ARGSZ+REGSZ(sp)
	beqz	a3, SyncRD			# Sync PREREAD
	lw	t0, CI_CACHECONFIGURATION(a0)

	addiu	a3, -1
	bnez	a3, SyncRDWB			# Sync PREWRITE+PREREAD
	nop

	and	t0, CTYPE_HAS_IL2		# Sync PREWRITE
	bnez	t0, SyncSC			# Have internal L2?
	PTR_ADDU sp, FRAMESZ(CF_SZ+2*REGSZ)
	j	Mips5k_HitSyncDCache		# No flush L1.
	nop
SyncSC:
	j	_mips5k_HitSyncSCache		# Do internal L2 cache
	nop					# L1 done in parallel

SyncRD:
	or	t1, a1, a2			# check if invalidate possible
	and	t1, 31				# both address and size must
	bnez	t1, SyncRDWB			# be aligned to the cache size
	nop

/*
 *  Sync for aligned read, no writeback required.
 */
	and	t0, CTYPE_HAS_IL2		# Have internal L2?
	bnez	t0, SyncRDL2
	nop

	jal	Mips5k_HitInvalidateDCache	# External L2 or no L2. Do L1.
	nop

	b	SyncRDXL2
	PTR_L	ra, CF_RA_OFFS+2*REGSZ(sp)	# External L2 if present

SyncRDL2:
	jal	_mips5k_HitInvalidateSCache	# Internal L2 cache
	nop					# L1 done in parallel

	b	SyncRDL3
	PTR_L	ra, CF_RA_OFFS+2*REGSZ(sp)	# L3 invalidate if present

/*
 *  Sync for unaligned read or write-read.
 */
SyncRDWB:
	and	t0, CTYPE_HAS_IL2		# Have internal L2?
	bnez	t0, SyncRDWBL2			# Yes, do L2
	nop

	jal	Mips5k_HitSyncDCache
	nop

	b	SyncRDXL2
	PTR_L	ra, CF_RA_OFFS+2*REGSZ(sp)	# External L2 if present

SyncRDWBL2:
	jal	_mips5k_HitSyncSCache		# Internal L2 cache
	nop					# L1 done in parallel

	b	SyncRDL3
	PTR_L	ra, CF_RA_OFFS+2*REGSZ(sp)	# L3 invalidate if present

SyncRDXL2:
	lw	t0, CI_CACHECONFIGURATION(a0)
	and	t0, CTYPE_HAS_XL2		# Have external L2?
	beqz	t0, SyncRDL3			# Nope.
	REG_L	a1, CF_ARGSZ(sp)
	REG_L	a2, CF_ARGSZ+REGSZ(sp)
	and	a3, a1, 4095			# align on external page size
	mtc0	zero, COP_0_TAG_LO
	PTR_SUBU a1, a3
	PTR_ADDU a2, a3
1:
	blez	a2, SyncDone
	PTR_SUBU a2, 4096			# Fixed external cache page size

	cache	InvalidatePage_S, 0(a1)
	b	1b
	PTR_ADDU a1, 4096

SyncRDL3:
	lw	t0, CI_CACHECONFIGURATION(a0)
	and	t0, CTYPE_HAS_XL3		# Have L3?
	beqz	t0, SyncDone			# Nope.
	REG_L	a1, CF_ARGSZ(sp)
	REG_L	a2, CF_ARGSZ+REGSZ(sp)
	and	a3, a1, 4095			# align on external page size
	mtc0	zero, COP_0_TAG_LO
	PTR_SUBU a1, a3
	PTR_ADDU a2, a3
1:
	blez	a2, SyncDone
	PTR_SUBU a2, 4096			# Fixed external cache page size

	cache	InvalidatePage_T, 0(a1)
	b	1b
	PTR_ADDU a1, 4096

SyncDone:
	sync
	j	ra
	PTR_ADDU sp, FRAMESZ(CF_SZ+2*REGSZ)
END(Mips5k_IOSyncDCache)
@


1.36
log
@Harvest some low-hanging fruit in thu R5k/RM7k cache routines:
- replace masking with large `power of two minus one' constants with a pair of
  shifts, this is shorter code and does not require the at register.
- merge R5000 and RM52xx setup, as the configuration register layout is the same
  on both processors.
- In Mips5k_IOSyncDCache(), delay building the call frame until we know we
  will not perform a leaf call. Replace leaf calls with jumps to the
  appropriate routines.

Tested on R5000, RM5271 and RM7000.
@
text
@d1 1
a1 1
/*	$OpenBSD: cache_r5k.S,v 1.35 2012/04/21 12:20:30 miod Exp $ */
@


1.35
log
@Rework the signature of the cache handling routines again. It makes more sense
to pass both the virtual and physical addresses of the page to clean to
SyncDCachePage, which is the only routine using `Index' operations on the data
cache, which might be virtually indexed at some levels but physically indexed
at others. On the other hand, it does not make any sense to pass a physical
address to routines using `Hit' operations (and they were discarding them
anyway).

In addition to making things cleaner, this fixes sporadic userland misbehaviour
(read: SIGSGEV) on RM7000 O2 systems.
@
text
@d1 1
a1 1
/*	$OpenBSD: cache_r5k.S,v 1.34 2012/04/06 20:11:18 miod Exp $ */
d74 1
a74 1
 *  R5000 config register bits.
a81 8
 *  RM52xx config register bits. (like R5000)
 */
#define	CF_52_SE	(1 << 12)	/* Secondary cache enable */
#define	CF_52_SC	(1 << 17)	/* Secondary cache not present */
#define	CF_52_SS	(3 << 20)	/* Secondary cache size */
#define	CF_52_SS_AL	20		/* Shift to align */

/*
d173 1
a173 1
	beq	v1, t1, Conf52K			# R52K 2 way, check L2
d201 1
a212 32

#---- R52K ------------------------------
Conf52K:					# R5200 type, check for L2 cache
	and	t1, v0, CF_52_SC
	bnez	t1, ConfResult			# not present
	li	ta2, 0				# set size to 0.

	li	t3, CF_52_SS
	and	t1, t3, v0
	beq	t1, t3, ConfResult		# No L2 cache
	srl	t1, CF_52_SS_AL

	li	t3, CF_52_SE			# Set SE in conf
	or	v0, t3				# Update config register
	li	ta2, 512*1024			# 512k per 'click'.
	sll	ta2, t1

	mtc0	v0, COP_0_CONFIG		# Enable L2 cache
	or	t2, CTYPE_HAS_XL2		# External L2 present.
	mtc0	zero, COP_0_TAG_LO
	LOAD_XKPHYS(t0, CCA_CACHED)
	PTR_ADDU t1, t0, ta2
1:
	cache	InvalidatePage_S, 0(t0)
	PTR_ADDU t0, 4096
	bne	t0, t1, 1b
	nop

	b	ConfResult
	nop


d306 1
a306 1
	and	t1, ~(PAGE_SIZE - 1)
d308 1
a308 1
	nop
d464 2
a465 1
	and	a1, 0x00ffffff			# Reduce addr to cache index
d469 2
a470 1
	and	a1, -32				# Align start address
d473 1
a473 1
	srl	a2, 5				# Number of unrolled loops
d526 3
a528 2
	dsll	a1, 34
	dsrl	a1, 34
a529 1
	and	a1, ~PAGE_MASK			# Page align start address
d568 2
a570 1
	and	a1, ~PAGE_MASK			# Page align start address
a633 1

d637 2
a638 1
	and	a1, -32				# align address
d640 1
a640 1
	srl	a2, 5				# Compute number of cache lines
d684 1
d686 2
a687 1
	and	a1, -32				# Align address
d689 1
d691 1
a691 2
	PTR_ADDU a2, -32

d694 1
a694 2

	bgtz	a2, 1b
d726 1
d728 2
a729 1
	and	a1, -32				# Align address
d731 1
a731 1

d733 1
a733 2
	PTR_ADDU a2, -32

d735 1
a735 2

	bgtz	a2, 1b
d768 1
d770 2
a771 1
	and	a1, -32				# Align address
d773 1
d775 1
a775 2
	PTR_ADDU a2, -32

d778 1
a778 2

	bgtz	a2, 1b
d819 1
d821 2
a822 1
	REG_S	a2, CF_ARGSZ+REGSZ(sp)
d827 4
a830 3
	lw	t0, CI_CACHECONFIGURATION(a0)	# Sync PREWRITE
	and	t0, CTYPE_HAS_IL2		# Have internal L2?
	bnez	t0, SyncSC			# Yes
a831 5
	jal	Mips5k_HitSyncDCache		# No flush L1.
	nop
	b	SyncDone
	PTR_L	ra, CF_RA_OFFS+2*REGSZ(sp)

d833 1
a833 1
	jal	_mips5k_HitSyncSCache		# Do internal L2 cache
a834 2
	b	SyncDone
	PTR_L	ra, CF_RA_OFFS+2*REGSZ(sp)
d837 3
a839 4
	and	t0, a1, 31			# check if invalidate possible
	bnez	t0, SyncRDWB			# both address and size must
	and	t0, a2, 31			# be aligned to the cache size
	bnez	t0, SyncRDWB
a844 1
	lw	t0, CI_CACHECONFIGURATION(a0)	# Aligned, do invalidate
a865 1
	lw	t0, CI_CACHECONFIGURATION(a0)
@


1.34
log
@Make the logic for PMAP_PREFER() and the logic, inside pmap, to do the
necessary cache coherency work wrt similar virtual indexes of different
physical pages, depending upon two distinct global variables, instead of
a shared one. R4000/R4400 VCE requires a 32KB mask for PMAP_PREFER, which
is otherwise not necessary for pmap coherency (especially since, on these
processors, only L1 uses virtual indexes, and the L1 size is not greater
than the page size, as we are using 16KB pages).
@
text
@d1 1
a1 1
/*	$OpenBSD: cache_r5k.S,v 1.33 2012/03/25 13:45:05 miod Exp $ */
d30 3
a32 5
 * NOTE!
 *
 * This code does not support caches with other linesize than 32.
 * Neither will it support R4000 or R4400 Secondary caches. These
 * configurations will need another set of cache functions.
d34 7
a40 6
 * Processors supported:
 * R4600/R4700 (if option CPUR4600)
 * R5000
 * RM52xx
 * RM7xxx
 * RM9xxx
a60 1
#define	IndexFlashInvalidate_T	0x02
a62 8
#define	IndexLoadTag_I		0x04
#define	IndexLoadTag_D		0x05
#define	IndexLoadTag_T		0x06
#define	IndexLoadTag_S		0x07

#define	IndexStoreTag_I		0x08
#define	IndexStoreTag_D		0x09
#define	IndexStoreTag_T		0x0a
a64 3
#define	CreateDirtyExclusive	0x0d

#define	HitInvalidate_I		0x10
a67 1
#define	Fill_I			0x14
a72 4
#define	HitWB_I			0x18
#define	HitWB_D			0x19
#define	HitWB_S			0x1b

a127 3
 * Results:
 *	Returns the value of the cpu configuration register.
 *
d178 1
a178 5
	li	t1, (MIPS_R4600 << 8)		# N way L1 caches only.
	beq	v1, t1, ConfResult		# R4K 2 way, no L2 control
	li	t1, (MIPS_R4700 << 8)
	beq	v1, t1, ConfResult		# R4K 2 way, No L2 control
	li	t1, (MIPS_R5000 << 8)
d187 2
a188 3
						# R4000PC/R4400PC or unknown.
	li	t2, CTYPE_DIR			# default direct mapped cache
	b	ConfResult
a376 3
 * Results:
 *	None.
 *
d485 1
a485 3
 * Mips5k_InvalidateICache --
 *
 *	void Mips5k_SyncICache(struct cpu_info *, vaddr_t addr, size_t len)
d487 2
a488 6
 *	Invalidate the L1 instruction cache for at least range
 *	of addr to addr + len - 1.
 *	The address is reduced to a XKPHYS index to avoid TLB faults.
 *
 * Results:
 *	None.
d544 1
a544 6
 * Mips5k_SyncDCachePage --
 *
 *	void Mips5k_SyncDCachePage(struct cpu_info *ci, vaddr_t addr)
 *
 *	Sync the L1 data cache page for address addr.
 *	The address is reduced to a XKPHYS index to avoid TLB faults.
d546 2
a547 2
 * Results:
 *	None.
d567 1
a567 1
	PTR_ADDU a2, a1, PAGE_SIZE-128
d597 1
a597 1
	bne	a2, a1, 1b
d600 39
d649 1
a649 9
 * Mips5k_HitSyncDCache --
 *
 *	void Mips5k_HitSyncDCache(struct cpu_info *ci,
 *	    vaddr_t addr, size_t len)
 *
 *	Sync data cache for range of addr to addr + len - 1.
 *	The address can be any valid virtual address as long
 *	as no TLB invalid traps occur. Only lines with matching
 *	addr are flushed.
d651 2
a652 2
 * Results:
 *	None.
d697 1
a697 1
 * Mips5k_HitSyncSCache --
d699 2
a700 10
 *	static void Mips5k_HitSyncSCache(struct cpu_info *ci,
 *	    vaddr_t addr, size_t len)
 *
 *	Sync secondary cache for range of addr to addr + len - 1.
 *	The address can be any valid virtual address as long
 *	as no TLB invalid traps occur. Only lines with matching
 *	addr are flushed.
 *
 * Results:
 *	None.
d712 1
a712 1
LEAF(Mips5k_HitSyncSCache, 0)
a739 1
END(Mips5k_HitSyncSCache)
d743 1
a743 4
 * Mips5k_HitInvalidateDCache --
 *
 *	void Mips5k_HitInvalidateDCache(struct cpu_info *ci,
 *	    vaddr_t addr, size_t len)
d745 1
a745 3
 *	Invalidate data cache for range of addr to addr + len - 1.
 *	The address can be any valid address as long as no TLB misses occur.
 *	(Be sure to use cached K0SEG kernel addresses or mapped addresses)
a747 3
 * Results:
 *	None.
 *
a782 1

d785 1
a785 1
 * Mips5k_HitInvalidateSCache --
d787 1
a787 6
 *	static void Mips5k_HitInvalidateSCache(struct cpu_info *ci,
 *	    vaddr_t addr, size_t len)
 *
 *	Invalidate secondary cache for range of addr to addr + len - 1.
 *	The address can be any valid address as long as no TLB misses occur.
 *	(Be sure to use cached K0SEG kernel addresses or mapped addresses)
a789 3
 * Results:
 *	None.
 *
d795 1
a795 1
LEAF(Mips5k_HitInvalidateSCache, 0)
a822 1
END(Mips5k_HitInvalidateSCache)
d826 1
a826 1
 * Mips5k_IOSyncDCache --
d828 1
a828 6
 *	void Mips5k_IOSyncDCache(struct cpu_info *ci,
 *	    vaddr_t addr, size_t len, int rw)
 *
 *	Invalidate or flush data cache for range of addr to addr + len - 1.
 *	The address can be any valid address as long as no TLB misses occur.
 *	(Be sure to use cached K0SEG kernel addresses or mapped addresses)
a834 3
 * Results:
 *	None.
 *
d836 10
a845 10
 *	If rw == 0 (read), L1 and on-chip L2 caches are invalidated or
 *		flushed if the area does not match the alignment
 *		requirements. Writethrough L2 and L3 cache are
 *		invalidated for the address range.
 *	If rw == 1 (write), L1 and on-chip L2 caches are written back
 *		to memory and invalidated. Writethrough L2 and L3 caches
 *		are left alone.
 *	If rw == 2 (write-read), L1 and on-chip L2 caches are written back
 *		to memory and invalidated. Writethrough L2 and L3 caches
 *		are invalidated.
d869 1
a869 1
	jal	Mips5k_HitSyncSCache		# Do internal L2 cache
d896 1
a896 1
	jal	Mips5k_HitInvalidateSCache	# Internal L2 cache
d918 1
a918 1
	jal	Mips5k_HitSyncSCache		# Internal L2 cache
@


1.33
log
@Only set the low order bits of CpuCacheAliasMask if it is nonzero, regression
of previous computation fix.
@
text
@d1 1
a1 1
/*	$OpenBSD: cache_r5k.S,v 1.32 2012/03/19 20:42:26 miod Exp $ */
d152 1
a152 1
 *	Alignment mask for cache aliasing test is stored in CpuCacheAliasMask.
d376 2
a377 1
	PTR_S	t1, CpuCacheAliasMask
@


1.32
log
@Recent uvm code (and maybe not-so-recent, but it did not explode^WKASSERT at
my face then...) depends upon PMAP_PREFER_ALIGN to be a power of two, minus one.

On mips64 with 4KB pages, the runtime variable used to compute PMAP_PREFER_ALIGN
had the low PAGE_SHIFT bits zeroed (for no good reason I'd say). Don't bother
zeroing them anymore.
@
text
@d1 1
a1 1
/*	$OpenBSD: cache_r5k.S,v 1.31 2012/02/16 20:31:30 miod Exp $ */
d371 3
d375 1
@


1.31
log
@Do an explicit `sync' instruction before returning from cache routines; this is
a nop on R5k and RM52xx, but actually required on RM7k.
@
text
@d1 1
a1 1
/*	$OpenBSD: cache_r5k.S,v 1.30 2012/02/16 20:28:14 miod Exp $ */
d370 2
a371 2
	srl	t1, t2				# Some cpus have different
	and	t1, ~(NBPG - 1)			# I and D cache sizes...
@


1.30
log
@Be sure to reset coprocessor 0 TAG_LO register to zero before attempting
InvalidatePage_* cache operations on RM52xx and RM7k, as strongly recommended
by the manual.
@
text
@d1 1
a1 1
/*	$OpenBSD: cache_r5k.S,v 1.29 2012/02/16 20:21:46 miod Exp $ */
d502 1
d567 1
d638 1
d693 1
d749 1
d799 1
d850 1
a888 1

d1000 1
@


1.29
log
@Use abbreviated mnemonics whenever possible (e.g. beqz instead of beq ...,zero),
fix various typos in comments, harmonize a few of them, and rename the internal
InvalidateSecondaryPage define to InvalidatePage_S for consistency.

No change in generated code.
@
text
@d1 1
a1 1
/*	$OpenBSD: cache_r5k.S,v 1.28 2010/01/09 23:34:29 miod Exp $ */
d265 1
d307 2
d477 1
a477 1
	PTR_SUBU ta0, 4096			# Fixed cache page size.
d493 1
a493 1
	PTR_SUBU ta0, 4096			# Fixed cache page size.
d963 2
a964 1
	and	a3, a1, 4095			# align on page size
d969 1
a969 1
	PTR_SUBU a2, 4096			# Fixed cache page size.
d981 2
a982 1
	and	a3, a1, 4095			# align on page size
d987 1
a987 1
	PTR_SUBU a2, 4096			# Fixed cache page size.
@


1.28
log
@Move cache information from global variables to per-cpu_info fields; this
allows processors with different cache sizes to be used.

Cache management routines now take a struct cpu_info * as first parameter.
@
text
@d1 1
a1 1
/*	$OpenBSD: cache_r5k.S,v 1.27 2009/12/25 20:59:45 miod Exp $ */
d75 1
a75 1
#define	CreateDirtyExclusive	0x09
d85 1
a90 4
#define	InvalidateSecondaryPage	0x17	/* Only RM527[0-1] */



d181 2
a182 2
	srl	t2, t2, 1			# Get I cache line size.
	addu	t2, t2, 16
d191 1
a191 1
	addu	t2, t2, 16			# Get D cache line size.
d238 1
a238 1
	cache	InvalidateSecondaryPage, 0(t0)
d268 1
a268 1
	cache	InvalidateSecondaryPage, 0(t0)
d291 1
a291 1
	li	t3, CF_7_TE			# Set SE in conf
d368 1
a368 1
	and	t1, ~(NBPG - 1)			# i and d cache sizes...
d428 1
a428 1
	PTR_ADDU t0, t0, 128
d437 1
a437 1
	PTR_SUBU t1, t1, 128
d445 1
a445 1
	PTR_ADDU t0, t0, 128
d456 1
a456 1
10:
d459 1
a459 1
	bgtz	ta0, 10b
d472 2
a473 2
21:
	cache	InvalidateSecondaryPage, 0(t3)
d475 1
a475 1
	bgtz	ta0, 21b
d488 1
a488 1
31:
d491 1
a491 1
	bgtz	ta0, 31b
d534 1
a534 1
	PTR_SUBU a2, a2, a1
d536 1
a536 1
	srl	a2, a2, 5			# Number of unrolled loops
d556 1
a556 1
	bne	a2, zero, 1b
d669 1
a669 1
	beq	a2, zero, 3f			# size is zero!
d671 4
a674 4
	PTR_ADDU a2, a2, a1			# Add extra from address
	and	a1, a1, -32			# align address
	PTR_SUBU a2, a2, a1
	srl	a2, a2, 5			# Compute number of cache lines
d679 1
a679 1
	bne	a2, zero, 1b
d724 4
a727 4
	beq	a2, zero, 3f			# size is zero!
	PTR_ADDU a2, a2, a1			# Add in extra from align
	and	a1, a1, -32			# Align address
	PTR_SUBU a2, a2, a1
d732 1
a732 1
	cache	HitWBInvalidate_D, 0(a1)	# Kill any orphans...
d773 4
a776 4
	beq	a2, zero, 3f			# size is zero!
	PTR_ADDU a2, a2, a1			# Add in extra from align
	and	a1, a1, -32			# Align address
	PTR_SUBU a2, a2, a1
d823 4
a826 4
	beq	a2, zero, 3f			# size is zero!
	PTR_ADDU a2, a2, a1			# Add in extra from align
	and	a1, a1, -32			# Align address
	PTR_SUBU a2, a2, a1
d907 1
a907 1
	and	t0, a2, 31			# be aligned at the cache size
d963 1
a963 1
50:
d967 2
a968 2
	cache	InvalidateSecondaryPage, 0(a1)
	b	50b
d980 1
a980 1
40:
d985 1
a985 1
	b	40b
@


1.27
log
@Don't bother returning a value in *_InvalidateICache(), as it's supposed to be
a void function.
@
text
@d1 1
a1 1
/*	$OpenBSD: cache_r5k.S,v 1.26 2009/11/19 20:16:27 miod Exp $ */
d30 1
a30 1
 *  NOTE!
d32 10
a41 10
 *  This code does not support caches with other linesize than 32.
 *  Neither will it support R4000 or R4400 Secondary caches. These
 *  configurations will need another set of cache functions.
 *
 *  Processors supported:
 *  R4600/R4700 (if option CPUR4600)
 *  R5000
 *  RM52xx
 *  RM7xxx
 *  RM9xxx
a55 4
#define	LOAD_XKPHYS(reg, cca) \
	li	reg, cca | 0x10; \
	dsll	reg, reg, 59

d144 1
a144 1
 * Mips5k_ConfigCache --
d153 2
a154 2
 *	The size of the data cache is stored into CpuPrimaryDataCacheSize.
 *	The size of instruction cache is stored into CpuPrimaryInstCacheSize.
d156 3
a158 3
 *	CpuSecondaryCacheSize is set to the size of the secondary cache.
 *	CpuTertiaryCacheSize is set to the size of the tertiary cache.
 *	CpuNWayCache is set to 0 for direct mapped caches, 2 for two way
d186 1
a186 1
	sw	t2, CpuPrimaryInstCacheLSize
d195 1
a195 1
	sw	t2, CpuPrimaryDataCacheLSize
d299 1
a299 1
	lw	ta3, CpuTertiaryCacheSize
d361 1
a361 4
	sw	v0, CpuConfigRegister
	mfc0	t3, COP_0_STATUS_REG
	sw	t2, CpuCacheType		# Save cache attributes
	sw	t3, CpuStatusRegister
d363 1
a363 1
	sw	t2, CpuNWayCache
d366 2
a367 2
	sw	ta2, CpuSecondaryCacheSize
	sw	ta3, CpuTertiaryCacheSize
d372 1
a372 1
	sw	t1, CpuCacheAliasMask
d374 1
a374 1
	sw	ta0, CpuPrimaryInstCacheSize	# store cache size.
d376 1
a376 1
	sw	ta0, CpuPrimaryInstSetSize
d378 1
a378 1
	sw	ta1, CpuPrimaryDataCacheSize	# store cache size.
d380 1
a380 1
	sw	ta1, CpuPrimaryDataSetSize
d392 1
a392 1
 * Mips5k_SyncCache --
d408 2
a409 2
	lw	t1, CpuPrimaryInstCacheSize
	lw	t2, CpuPrimaryDataCacheSize
d451 1
a451 1
	lw	t0, CpuCacheType
d458 1
a458 1
	lw	ta0, CpuSecondaryCacheSize
d467 1
a467 1
	lw	t0, CpuCacheType
d474 1
a474 1
	lw	ta0, CpuSecondaryCacheSize
d483 1
a483 1
	lw	t0, CpuCacheType
d490 1
a490 1
	lw	ta0, CpuTertiaryCacheSize
d510 1
a510 2
 *	void Mips5k_SyncICache(addr, len)
 *		vaddr_t addr, len;
d530 10
a539 10
	lw	v0, CpuNWayCache		# Cache properties
	lw	t0, CpuPrimaryInstSetSize	# Set size
	and	a0, 0x00ffffff			# Reduce addr to cache index
	LOAD_XKPHYS(a2, CCA_CACHED)
	PTR_ADDU a1, 31				# Round up size
	PTR_ADDU a1, a0				# Add extra from address
	and	a0, -32				# Align start address
	PTR_SUBU a1, a1, a0
	PTR_ADDU a0, a2				# a0 now new XKPHYS address
	srl	a1, a1, 5			# Number of unrolled loops
d543 1
a543 1
	PTR_ADDU a1, -1
d546 1
a546 1
	PTR_ADDU t1, t0, a0			# Nway cache, flush set B.
d548 1
a548 1
	beqz	v0, 3f				# Is two way do set A
d557 1
a557 1
	cache	IndexInvalidate_I, 0(a0)	# do set (A if NWay)
d559 2
a560 2
	bne	a1, zero, 1b
	PTR_ADDU a0, 32
d574 1
a574 2
 *	void Mips5k_SyncDCachePage(addr)
 *		vaddr_t addr;
d594 7
a600 7
	LOAD_XKPHYS(a2, CCA_CACHED)
	lw	v0, CpuNWayCache
	dsll	a0, 34
	dsrl	a0, 34
	PTR_ADDU a0, a2				# a0 now new XKPHYS address
	and	a0, ~PAGE_MASK			# Page align start address
	PTR_ADDU a1, a0, PAGE_SIZE-128
d602 1
a602 1
	lw	a2, CpuPrimaryDataSetSize
d606 2
a607 2
	PTR_ADDU t1, a0, a2			# flush set B.
	cache	IndexWBInvalidate_D, 0(t1)
d611 2
a612 2
	beqz	v0, 3f				# Two way, do set A,
	PTR_ADDU t1, a2
d619 1
a619 1
	PTR_ADDU t1, a2				# do set D
a623 1

d625 4
a628 4
	cache	IndexWBInvalidate_D, 0(a0)	# do set A
	cache	IndexWBInvalidate_D, 32(a0)
	cache	IndexWBInvalidate_D, 64(a0)
	cache	IndexWBInvalidate_D, 96(a0)
d630 2
a631 2
	bne	a1, a0, 1b
	PTR_ADDU a0, 128
d644 2
a645 2
 *	void Mips5k_HitSyncDCache(addr, len)
 *		vaddr_t addr, len;
d672 6
a677 6
	beq	a1, zero, 3f			# size is zero!
	PTR_ADDU a1, 31				# Round up
	PTR_ADDU a1, a1, a0			# Add extra from address
	and	a0, a0, -32			# align address
	PTR_SUBU a1, a1, a0
	srl	a1, a1, 5			# Compute number of cache lines
d680 4
a683 4
	PTR_ADDU a1, -1
	cache	HitWBInvalidate_D, 0(a0)
	bne	a1, zero, 1b
	PTR_ADDU a0, 32
d699 2
a700 2
 *	void Mips5k_HitSyncSCache(addr, len)
 *		vaddr_t addr, len;
d727 4
a730 4
	beq	a1, zero, 3f			# size is zero!
	PTR_ADDU a1, a1, a0			# Add in extra from align
	and	a0, a0, -32			# Align address
	PTR_SUBU a1, a1, a0
d732 1
a732 1
	PTR_ADDU a1, -32
d734 2
a735 2
	cache	HitWBInvalidate_S, 0(a0)
	cache	HitWBInvalidate_D, 0(a0)	# Kill any orphans...
d737 2
a738 2
	bgtz	a1, 1b
	PTR_ADDU a0, 32
d753 2
a754 2
 *	void Mips5k_HitInvalidateDCache(addr, len)
 *		vaddr_t addr, len;
d776 4
a779 4
	beq	a1, zero, 3f			# size is zero!
	PTR_ADDU a1, a1, a0			# Add in extra from align
	and	a0, a0, -32			# Align address
	PTR_SUBU a1, a1, a0
d782 1
a782 1
	PTR_ADDU a1, -32
d784 1
a784 1
	cache	HitInvalidate_D, 0(a0)
d786 2
a787 2
	bgtz	a1, 1b
	PTR_ADDU a0, 32
d803 2
a804 2
 *	void Mips5k_HitInvalidateSCache(addr, len)
 *		vaddr_t addr, len;
d826 4
a829 4
	beq	a1, zero, 3f			# size is zero!
	PTR_ADDU a1, a1, a0			# Add in extra from align
	and	a0, a0, -32			# Align address
	PTR_SUBU a1, a1, a0
d831 1
a831 1
	PTR_ADDU a1, -32
d833 2
a834 2
	cache	HitInvalidate_S, 0(a0)
	cache	HitInvalidate_D, 0(a0)		# Orphans in L1
d836 2
a837 2
	bgtz	a1, 1b
	PTR_ADDU a0, 32
d852 2
a853 3
 *	void Mips5k_IOSyncDCache(addr, len, rw)
 *		vaddr_t addr;
 *		int  len, rw;
d885 5
a889 5
	REG_S	a0, CF_ARGSZ(sp)		# save args
	beqz	a2, SyncRD			# Sync PREREAD
	REG_S	a1, CF_ARGSZ+REGSZ(sp)
	addiu	a2, -1
	bnez	a2, SyncRDWB			# Sync PREWRITE+PREREAD
d892 1
a892 1
	lw	t0, CpuCacheType		# Sync PREWRITE
d908 1
a908 1
	and	t0, a0, 31			# check if invalidate possible
d910 1
a910 1
	and	t0, a1, 31			# be aligned at the cache size
d917 1
a917 1
	lw	t0, CpuCacheType		# Aligned, do invalidate
d933 1
a933 1
	PTR_L	ra, CF_RA_OFFS+2*REGSZ(sp)		# L3 invalidate if present
d939 1
a939 1
	lw	t0, CpuCacheType
d948 1
a948 1
	PTR_L	ra, CF_RA_OFFS+2*REGSZ(sp)		# External L2 if present
d955 1
a955 1
	PTR_L	ra, CF_RA_OFFS+2*REGSZ(sp)		# L3 invalidate if present
d958 1
a958 1
	lw	t0, CpuCacheType
d961 5
a965 5
	REG_L	a0, CF_ARGSZ(sp)
	REG_L	a1, CF_ARGSZ+REGSZ(sp)
	and	a2, a0, 4095			# align on page size
	PTR_SUBU a0, a2
	PTR_ADDU a1, a2
d967 2
a968 2
	blez	a1, SyncDone
	PTR_SUBU a1, 4096			# Fixed cache page size.
d970 1
a970 1
	cache	InvalidateSecondaryPage, 0(a0)
d972 1
a972 1
	PTR_ADDU a0, 4096
d975 1
a975 1
	lw	t0, CpuCacheType
d978 5
a982 5
	REG_L	a0, CF_ARGSZ(sp)
	REG_L	a1, CF_ARGSZ+REGSZ(sp)
	and	a2, a0, 4095			# align on page size
	PTR_SUBU a0, a2
	PTR_ADDU a1, a2
d984 2
a985 2
	blez	a1, SyncDone
	PTR_SUBU a1, 4096			# Fixed cache page size.
d987 1
a987 1
	cache	InvalidatePage_T, 0(a0)
d989 1
a989 1
	PTR_ADDU a0, 4096
@


1.26
log
@Rename KSEG* defines to CKSEG* to match their names in 64 bit mode; also
define more 64 bit spaces.
@
text
@d1 1
a1 1
/*	$OpenBSD: cache_r5k.S,v 1.25 2009/08/06 21:09:18 miod Exp $ */
a528 1
 *	Must not touch v0.
d575 1
a575 1
	move	v0, zero
@


1.25
log
@R4k-style coprocessor 0 config register uses 3 bits wide fields to tell
L1 caches sizes; fix the masking accordingly.
@
text
@d1 1
a1 1
/*	$OpenBSD: cache_r5k.S,v 1.24 2009/08/06 21:06:30 miod Exp $ */
d174 1
a174 1
	LA	v1, KSEG1_BASE
@


1.24
log
@Remove _InvalidateICachePage cache op, it isn't used by anything.
@
text
@d1 1
a1 1
/*	$OpenBSD: cache_r5k.S,v 1.23 2009/05/22 20:37:53 miod Exp $ */
d183 1
a183 1
	and	t1, 3
d193 1
a193 1
	and	t1, 3
@


1.23
log
@Drop almost unused <machine/psl.h> on sgi; move USERMODE() definition from
there to trap.c which is its only user. This also cleans up multiple
inclusion of <machine/cpu.h> (because <machine/psl.h> includes it) in many
places.
@
text
@d1 1
a1 1
/*	$OpenBSD: cache_r5k.S,v 1.22 2008/04/07 22:30:47 miod Exp $ */
d37 1
a37 1
 *  R4600/R4700
a320 1

d389 2
a390 2
	and	v0, 0xfffffff8
	or	v0, 0x00000003			# set cachable writeback kseg0
a514 45
 * Mips5k_InvalidateICachePage --
 *
 *	void Mips5k_InvalidateICachePage(addr)
 *		vaddr_t addr;
 *
 *	Invalidate the L1 instruction cache page given by addr.
 *
 * Results:
 *	Void.
 *
 * Side effects:
 *	The contents of the L1 Instruction cache is flushed.
 *
 *----------------------------------------------------------------------------
 */
LEAF(Mips5k_InvalidateICachePage, 0)
#ifdef CPUR4600
	mfc0	v1, COP_0_STATUS_REG		# Save the status register.
	li	v0, SR_DIAG_DE
	mtc0	v0, COP_0_STATUS_REG		# Disable interrupts
#endif
	lw	v0, CpuNWayCache		# Cache properties
	lw	t0, CpuPrimaryInstSetSize	# Set size
	and	a0, ~PAGE_MASK			# Page align start address
	PTR_ADDU a1, a0, PAGE_SIZE-128		# End address.
	addiu	v0, -2				# <0 1way, 0 = two, >0 four
1:
	cache	HitInvalidate_I, 0(a0)
	cache	HitInvalidate_I, 32(a0)
	cache	HitInvalidate_I, 64(a0)
	cache	HitInvalidate_I, 96(a0)

	bne	a0, a1, 1b
	PTR_ADDU a0, 128

#ifdef CPUR4600
	mtc0	v1, COP_0_STATUS_REG	# Restore the status register.
	NOP10
#endif
	j	ra
	move	v0, zero
END(Mips5k_InvalidateICachePage)

/*----------------------------------------------------------------------------
 *
d552 1
a552 1
	addu	a1, -1
a662 3
 *	Note: Use the CpuNWayCache flag to select 16 or 32 byte linesize.
 *	      All Nway cpu's now available have a fixed 32byte linesize.
 *
d908 1
a908 1
	jal	 Mips5k_HitSyncDCache		# No flush L1.
@


1.22
log
@Use CCA_CACHED as the default CCA for all cached mappings and addresses.
@
text
@d1 1
a1 1
/*	$OpenBSD: cache_r5k.S,v 1.21 2007/10/24 20:04:26 miod Exp $ */
a47 1
#include <machine/psl.h>
@


1.21
log
@pipleine -> pipeline
@
text
@d1 1
a1 1
/*	$OpenBSD: cache_r5k.S,v 1.20 2007/10/18 04:32:25 miod Exp $ */
d243 1
a243 1
	LOAD_XKPHYS(t0, CCA_NONCOHERENT)
d273 1
a273 1
	LOAD_XKPHYS(t0, CCA_NONCOHERENT)
d314 1
a314 1
	LOAD_XKPHYS(t0, CCA_NONCOHERENT)
d333 1
a333 1
	LOAD_XKPHYS(t0, CCA_NONCOHERENT)
d341 1
a341 1
	LOAD_XKPHYS(t0, CCA_NONCOHERENT)
d349 1
a349 1
	LOAD_XKPHYS(t0, CCA_NONCOHERENT)
d429 1
a429 1
	LOAD_XKPHYS(t0, CCA_NONCOHERENT)
d447 1
a447 1
	LOAD_XKPHYS(t0, CCA_NONCOHERENT)
d466 1
a466 1
	LOAD_XKPHYS(t3, CCA_NONCOHERENT)
d482 1
a482 1
	LOAD_XKPHYS(t3, CCA_NONCOHERENT)
d498 1
a498 1
	LOAD_XKPHYS(t3, CCA_NONCOHERENT)
d589 1
a589 1
	LOAD_XKPHYS(a2, CCA_NONCOHERENT)
d651 1
a651 1
	LOAD_XKPHYS(a2, CCA_NONCOHERENT)
@


1.20
log
@No need to include <machine/pte.h> here.
@
text
@d1 1
a1 1
/*	$OpenBSD: cache_r5k.S,v 1.19 2007/06/18 20:25:55 miod Exp $ */
d138 1
a138 1
 *  Due to a flaw in RM7000 1.x processors a pipleine 'drain' is
@


1.19
log
@Use a shorter form to load XKPHYS constants in .S code, shaves a few text
bytes, no functional change.
@
text
@d1 1
a1 1
/*	$OpenBSD: cache_r5k.S,v 1.18 2007/05/27 09:23:04 miod Exp $ */
a51 1
#include <machine/pte.h>
@


1.18
log
@Always use XKPHYS addresses to perform cache operations now, for consistency.
@
text
@d1 1
a1 1
/*	$OpenBSD: cache_r5k.S,v 1.17 2007/03/21 05:26:37 miod Exp $ */
d58 4
d176 1
a176 1
	LA	v1, XKPHYS_NC
d244 1
a244 1
	LA	t0, XKPHYS_NONCOHERENT
d274 1
a274 1
	LA	t0, XKPHYS_NONCOHERENT
d315 1
a315 1
	LA	t0, XKPHYS_NONCOHERENT
d334 1
a334 1
	LA	t0, XKPHYS_NONCOHERENT
d342 1
a342 1
	LA	t0, XKPHYS_NONCOHERENT
d350 1
a350 1
	LA	t0, XKPHYS_NONCOHERENT
d430 1
a430 1
	LA	t0, XKPHYS_NONCOHERENT
d448 1
a448 1
	LA	t0, XKPHYS_NONCOHERENT
d467 1
a467 1
	LA	t3, XKPHYS_NONCOHERENT
d483 1
a483 1
	LA	t3, XKPHYS_NONCOHERENT
d499 1
a499 1
	LA	t3, XKPHYS_NONCOHERENT
d590 1
d595 1
a595 1
	PTR_ADDU a0, XKPHYS_NONCOHERENT		# a0 now new XKPHYS address
d652 1
a652 1
	lw	a2, CpuPrimaryDataSetSize
d656 1
a656 1
	PTR_ADDU a0, XKPHYS_NONCOHERENT		# a0 now new XKPHYS address
d660 1
@


1.17
log
@Mips_IOSyncDCache last argument is in the 0..2 range, not -1..1, so let
C and asm code agree on this; this causes no functional change on r10k
and fewer wt invalidates on r5k. ok kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: cache_r5k.S,v 1.16 2005/07/20 21:36:32 miod Exp $ */
d172 1
a172 1
	LA	v1, KSEG1_BASE
d240 1
a240 1
	LA	t0, KSEG0_BASE
d270 1
a270 1
	LA	t0, KSEG0_BASE
d311 1
a311 1
	LA	t0, KSEG0_BASE
d330 1
a330 1
	LA	t0, KSEG0_BASE
d338 1
a338 1
	LA	t0, KSEG0_BASE
d346 1
a346 1
	LA	t0, KSEG0_BASE
d426 1
a426 1
	LA	t0, KSEG0_BASE
d444 1
a444 1
	LA	t0, KSEG0_BASE
d463 1
a463 1
	LA	t3, KSEG0_BASE
d479 1
a479 1
	LA	t3, KSEG0_BASE
d495 1
a495 1
	LA	t3, KSEG0_BASE
d566 1
a566 1
 *	The address is reduced to a KSEG0 index to avoid TLB faults.
d590 1
a590 1
	PTR_ADDU a0, KSEG0_BASE			# a0 now new KSEG0 address
d630 1
a630 1
 *	The address is reduced to a KSEG0 index to avoid TLB faults.
d651 1
a651 1
	PTR_ADDU a0, KSEG0_BASE			# a0 now new KSEG0 address
@


1.16
log
@typos
@
text
@d1 1
a1 1
/*	$OpenBSD: cache_r5k.S,v 1.15 2004/09/29 12:52:44 pefo Exp $ */
d945 1
a945 1
	addiu	a2, 1
@


1.15
log
@fix typo
@
text
@d1 1
a1 1
/*	$OpenBSD: cache_r5k.S,v 1.14 2004/09/29 12:16:55 pefo Exp $ */
d136 1
a136 1
 *  requierd after some mtc0 instructions.
d972 1
a972 1
 *  Sync for aligned read, no writeback requierd.
@


1.14
log
@Better RM7K cache init dealing with lazy firmware
@
text
@d1 1
a1 1
/*	$OpenBSD: cache_r5k.S,v 1.13 2004/09/21 08:39:46 pefo Exp $ */
d335 1
a335 1
	cache	IndexStoreTagS, -4(t0)
d351 1
a351 1
	cache	IndexStoreTagS, -4(t0)
@


1.13
log
@Make RM7K get L3 cache from config reg. cleanup
@
text
@d1 1
a1 1
/*	$OpenBSD: cache_r5k.S,v 1.12 2004/09/20 15:43:35 miod Exp $ */
d171 6
d223 1
a223 1
Conf5K:					# R5000 type, check for L2 cache
a232 1
	or	t2, CTYPE_HAS_XL2		# External L2 present.
d239 1
d244 1
a244 1
	PTR_ADDU t0, 128*32
a262 1
	or	t2, CTYPE_HAS_XL2		# External L2 present.
d269 1
d274 1
a274 1
	PTR_ADDU t0, 128*32
a305 1
	or	t2, CTYPE_HAS_XL3
d308 2
d311 8
d325 30
d467 1
a467 1
	PTR_SUBU ta0, 32				# Fixed cache line size.
@


1.12
log
@There was one CF_5_xx constant left in the 52xx code, change it to CF_52_xx
(purely cosmetic, as these constant share the same values).
@
text
@d1 1
a1 1
/*	$OpenBSD: cache_r5k.S,v 1.11 2004/09/20 11:04:23 pefo Exp $ */
d283 12
d301 3
a303 8
	lw	t3, CpuExternalCacheOn		# Check if disabled
	bnez	t3, Conf7KL2			# No, use it
	nop

	and	v0, ~CF_7_TE			# Clear TE in conf
	mtc0	v0, COP_0_CONFIG		# establish any new config
	NOP10
	li	ta3, 0				# L3 cache disabled
a310 19
	lw	t3, CpuOnboardCacheOn		# Check if disabled
	bnez	t3, ConfResult			# No, use it
	li	ta2, 256*1024			# size = 256k

/* Sync on chip L2 */

	LA	a0, KSEG0_BASE
	LA	a1, KSEG0_BASE+0x00040000
10:
	cache	IndexWBInvalidate_S, 0(a0)
	PTR_ADDU a0, 32
	bne	a0, a1, 10b
	nop

	and	t2, ~CTYPE_HAS_IL2
	li	t1, ~CF_7_SE			# Clear SE in conf
	and	v0, t1
	mtc0	v0, COP_0_CONFIG		# establish any new config
	NOP10
d312 1
a312 1
	li	ta2, 0				# L2 cache disabled
@


1.11
log
@Some cleanups for RM52x0 cpus.
@
text
@d1 1
a1 1
/*	$OpenBSD: cache_r5k.S,v 1.10 2004/09/20 10:29:57 pefo Exp $ */
d99 1
a100 1
#define	CF_5_SE		(1 << 12)	/* Secondary cache enable */
d258 1
a258 1
	li	t3, CF_5_SE			# Set SE in conf
@


1.10
log
@Add support for R10K cpu class
@
text
@d1 1
a1 1
/*	$OpenBSD: cache_r5k.S,v 1.9 2004/09/16 10:13:37 miod Exp $ */
a260 2
	lw	t3, CpuExternalCacheOn		# Check if disabled
	bnez	t3, ConfResult			# No use it.
d263 9
a271 3
	and	t2, ~CTYPE_HAS_XL2
	li	t1, ~CF_52_SE			# Clear SE in conf
	and	v0, t1				# Update config register
d273 1
a273 1
	li	ta2, 0				# L2 cache disabled
@


1.9
log
@typo
@
text
@d1 1
a1 1
/*	$OpenBSD: cache_r5k.S,v 1.8 2004/09/16 07:25:26 miod Exp $ */
d204 1
a204 1
	li	t1, (MIPS_RM52XX << 8)
d517 1
a517 1
	move	v0, zero		# suiword depends on this!!
d582 1
a582 1
	move	v0, zero		# suiword depends on this!!
@


1.8
log
@``viritual'' is a virtual word and this is a real tree.
@
text
@d1 1
a1 1
/*	$OpenBSD: cache_r5k.S,v 1.7 2004/09/10 09:32:13 pefo Exp $ */
d33 1
a33 1
 *  Neither will it support R4000 or R4400 Secondary cahes. These
@


1.7
log
@Use correct register aliases wrt the __mips_n64 regdef.
@
text
@d1 1
a1 1
/*	$OpenBSD: cache_r5k.S,v 1.6 2004/09/10 08:58:27 pefo Exp $ */
d664 1
a664 1
 *	The address can be any valid viritual address as long
d722 1
a722 1
 *	The address can be any valid viritual address as long
@


1.6
log
@Fix LEAF usage adding new extra arg. spotted by miod.
@
text
@d1 1
a1 1
/*	$OpenBSD: cache_r5k.S,v 1.5 2004/09/09 22:11:38 pefo Exp $ */
d165 1
a165 1
 *	ta4, ta5 ta6 used to hold I and D set size and Alias mask.
d177 1
a177 1
	sllv	ta4, t2, t1			# ta4 = Initial I set size.
d187 1
a187 1
	sllv	ta5, t2, t1
d194 2
a195 2
	li	ta6, 0				# Secondary size 0.
	li	ta7, 0				# Tertiary size 0.
d220 1
a220 1
	li	ta6, 0				# set size to 0.
d230 2
a231 2
	li	ta6, 512*1024			# 512k per 'click'.
	sll	ta6, t1
d235 1
a235 1
	PTR_ADDU t1, t0, ta6
d250 1
a250 1
	li	ta6, 0				# set size to 0.
d260 1
a260 1
	li	ta6, 512*1024			# 512k per 'click'.
d263 1
a263 1
	sll	ta6, t1
d269 1
a269 1
	li	ta6, 0				# L2 cache disabled
d277 1
a277 1
	li	ta7, 0				# Set size = 0
d279 1
a279 1
	lw	ta7, CpuTertiaryCacheSize
d281 1
a281 1
	beqz	ta7, Conf7KL2			# No L3 cache present
d292 1
a292 1
	li	ta7, 0				# L3 cache disabled
d297 1
a297 1
	li	ta6, 0				# No L2?
d302 1
a302 1
	li	ta6, 256*1024			# size = 256k
d320 1
a320 1
	li	ta6, 0				# L2 cache disabled
d323 2
a324 2
 * Get here with t2 = Cache type, ta4 = L1 I size, ta5 = L1 D size.
 * ta6 = secondary size, ta7 = tertiary size.
d335 2
a336 2
	sw	ta6, CpuSecondaryCacheSize
	sw	ta7, CpuTertiaryCacheSize
d338 1
a338 1
	addu	t1, ta4, -1			# Use icache for alias mask
d343 7
a349 7
	sw	ta4, CpuPrimaryInstCacheSize	# store cache size.
	srl	ta4, t2				# calculate set size.
	sw	ta4, CpuPrimaryInstSetSize

	sw	ta5, CpuPrimaryDataCacheSize	# store cache size.
	srl	ta5, t2				# calculate set size.
	sw	ta5, CpuPrimaryDataSetSize
d427 1
a427 1
	lw	ta4, CpuSecondaryCacheSize
d430 2
a431 2
	PTR_SUBU ta4, 32				# Fixed cache line size.
	bgtz	ta4, 10b
d443 1
a443 1
	lw	ta4, CpuSecondaryCacheSize
d446 2
a447 2
	PTR_SUBU ta4, 4096			# Fixed cache page size.
	bgtz	ta4, 21b
d459 1
a459 1
	lw	ta4, CpuTertiaryCacheSize
d462 2
a463 2
	PTR_SUBU ta4, 4096			# Fixed cache page size.
	bgtz	ta4, 31b
@


1.5
log
@Kernel moves to 64 bit. A few more tweaks when binutils is updated.
@
text
@d1 1
a1 1
/*	$OpenBSD: cache_r5k.S,v 1.4 2004/08/10 20:15:47 deraadt Exp $ */
d169 1
a169 1
LEAF(Mips5k_ConfigCache)
d375 1
a375 1
LEAF(Mips5k_SyncCache)
d492 1
a492 1
LEAF(Mips5k_InvalidateICachePage)
d540 1
a540 1
LEAF(Mips5k_InvalidateICache)
d604 1
a604 1
LEAF(Mips5k_SyncDCachePage)
d684 1
a684 1
LEAF(Mips5k_HitSyncDCache)
d739 1
a739 1
LEAF(Mips5k_HitSyncSCache)
d788 1
a788 1
LEAF(Mips5k_HitInvalidateDCache)
d838 1
a838 1
LEAF(Mips5k_HitInvalidateSCache)
@


1.4
log
@spacing
@
text
@d1 1
a1 1
/*	$OpenBSD: cache_r5k.S,v 1.3 2004/08/09 14:57:26 pefo Exp $ */
d165 1
a165 1
 *	t4, t5 t6 used to hold I and D set size and Alias mask.
d177 1
a177 1
	sllv	t4, t2, t1			# t4 = Initial I set size.
d187 1
a187 1
	sllv	t5, t2, t1
d194 2
a195 2
	li	t6, 0				# Secondary size 0.
	li	t7, 0				# Tertiary size 0.
d220 1
a220 1
	li	t6, 0				# set size to 0.
d230 2
a231 2
	li	t6, 512*1024			# 512k per 'click'.
	sll	t6, t1
d234 2
a235 2
	la	t0, KSEG0_BASE
	addu	t1, t0, t6
d238 1
a238 1
	addu	t0, 128*32
d250 1
a250 1
	li	t6, 0				# set size to 0.
d260 1
a260 1
	li	t6, 512*1024			# 512k per 'click'.
d263 1
a263 1
	sll	t6, t1
d269 1
a269 1
	li	t6, 0				# L2 cache disabled
d277 1
a277 1
	li	t7, 0				# Set size = 0
d279 1
a279 1
	lw	t7, CpuTertiaryCacheSize
d281 1
a281 1
	beqz	t7, Conf7KL2			# No L3 cache present
d292 1
a292 1
	li	t7, 0				# L3 cache disabled
d297 1
a297 1
	li	t6, 0				# No L2?
d302 1
a302 1
	li	t6, 256*1024			# size = 256k
d306 2
a307 2
	li	a0, 0x80000000
	li	a1, 0x80040000
d310 1
a310 1
	addu	a0, 32
d320 1
a320 1
	li	t6, 0				# L2 cache disabled
d323 2
a324 2
 * Get here with t2 = Cache type, t4 = L1 I size, t5 = L1 D size.
 * t6 = secondary size, t7 = tertiary size.
d335 2
a336 2
	sw	t6, CpuSecondaryCacheSize
	sw	t7, CpuTertiaryCacheSize
d338 1
a338 1
	addu	t1, t4, -1			# Use icache for alias mask
d343 7
a349 7
	sw	t4, CpuPrimaryInstCacheSize	# store cache size.
	srl	t4, t2				# calculate set size.
	sw	t4, CpuPrimaryInstSetSize

	sw	t5, CpuPrimaryDataCacheSize	# store cache size.
	srl	t5, t2				# calculate set size.
	sw	t5, CpuPrimaryDataSetSize
d427 1
a427 1
	lw	t4, CpuSecondaryCacheSize
d430 2
a431 2
	PTR_SUBU t4, 32				# Fixed cache line size.
	bgtz	t4, 10b
d443 1
a443 1
	lw	t4, CpuSecondaryCacheSize
d446 2
a447 2
	PTR_SUBU t4, 4096			# Fixed cache page size.
	bgtz	t4, 21b
d459 1
a459 1
	lw	t4, CpuTertiaryCacheSize
d462 2
a463 2
	PTR_SUBU t4, 4096			# Fixed cache page size.
	bgtz	t4, 31b
d901 1
a901 1
NON_LEAF(Mips5k_IOSyncDCache, FRAMESZ(CF_SZ), ra)
d903 3
a905 3
	PTR_SUBU sp, FRAMESZ(CF_SZ)
	PTR_S	ra, CF_RA_OFFS(sp)
	REG_S	a0, FRAMESZ(CF_SZ)(sp)		# save args
d907 1
a907 1
	REG_S	a1, FRAMESZ(CF_SZ)+REGSZ(sp)
d914 6
a919 2
	beqzl	t0, Mips5k_HitSyncDCache	# No flush L1.
	PTR_ADDU sp, FRAMESZ(CF_SZ)
d921 2
a922 1
	b	Mips5k_HitSyncSCache		# Do internal L2 cache
d924 2
d946 1
a946 1
	PTR_L	ra, CF_RA_OFFS(sp)		# External L2 if present
d953 1
a953 1
	PTR_L	ra, CF_RA_OFFS(sp)		# L3 invalidate if present
d968 1
a968 1
	PTR_L	ra, CF_RA_OFFS(sp)		# External L2 if present
d975 1
a975 1
	PTR_L	ra, CF_RA_OFFS(sp)		# L3 invalidate if present
d981 2
a982 2
	REG_L	a0, FRAMESZ(CF_SZ)(sp)
	REG_L	a1, FRAMESZ(CF_SZ)+REGSZ(sp)
d998 2
a999 2
	REG_L	a0, FRAMESZ(CF_SZ)(sp)
	REG_L	a1, FRAMESZ(CF_SZ)+REGSZ(sp)
d1013 1
a1013 1
	PTR_ADDU sp, FRAMESZ(CF_SZ)
@


1.3
log
@Big cleanup. Removed some unused obsolete stuff and fixed copyrights
on some files. Arcbios support is now in, thus detects memorysize and cpu
clock frequency.
@
text
@d1 1
a1 1
/*	$OpenBSD: cache_r5k.S,v 1.2 2004/08/07 14:48:26 pefo Exp $ */
d5 1
a5 1
 * 
d182 1
a182 1
	sw	t2, CpuPrimaryInstCacheLSize	
d199 2
a200 2
	beq	v1, t1, ConfResult		# R4K 2 way, no L2 control	
	li	t1, (MIPS_R4700 << 8)	
d269 1
a269 1
	li	t6, 0				# L2 cache disabled 
d292 1
a292 1
	li	t7, 0				# L3 cache disabled 
d306 1
a306 1
	li	a0, 0x80000000 
d594 1
a594 1
 *	
d670 1
a670 1
 *	
d880 1
a880 1
 *	which are in the given range ONLY if transfer direction is READ. 
d919 1
a919 1
	
@


1.2
log
@fix bug in L2 cache size detection code
@
text
@d1 1
a1 1
/*	$OpenBSD: cache_r5k.S,v 1.1 2004/08/06 20:56:03 pefo Exp $ */
a162 1
 *	cpu_id is set for later decision testing.
a172 1
	sw	v1, cpu_id			# save PRID register
@


1.1
log
@initial mips64
@
text
@d1 1
a1 1
/*	$OpenBSD$ */
d230 2
a231 2
	li	t1, CF_5_SE			# Set SE in conf
	or	v0, t1				# Update config register
d260 2
a261 2
	li	t1, CF_5_SE			# Set SE in conf
	or	v0, t1				# Update config register
@

