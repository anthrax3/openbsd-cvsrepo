head	1.7;
access;
symbols
	OPENBSD_6_1_BASE:1.7
	OPENBSD_6_0:1.6.0.2
	OPENBSD_6_0_BASE:1.6
	OPENBSD_5_9:1.5.0.4
	OPENBSD_5_9_BASE:1.5
	OPENBSD_5_8:1.5.0.6
	OPENBSD_5_8_BASE:1.5
	OPENBSD_5_7:1.5.0.2
	OPENBSD_5_7_BASE:1.5
	OPENBSD_5_6:1.4.0.4
	OPENBSD_5_6_BASE:1.4;
locks; strict;
comment	@ * @;


1.7
date	2016.12.22.15.33.36;	author visa;	state Exp;
branches;
next	1.6;
commitid	sw48d58czeutOmw2;

1.6
date	2016.03.06.19.42.27;	author mpi;	state Exp;
branches;
next	1.5;
commitid	cyYKarj4qRTft4gD;

1.5
date	2014.11.16.12.30.58;	author deraadt;	state Exp;
branches;
next	1.4;
commitid	yv0ECmCdICvq576h;

1.4
date	2014.04.04.20.52.05;	author miod;	state Exp;
branches;
next	1.3;

1.3
date	2014.04.03.08.07.16;	author mpi;	state Exp;
branches;
next	1.2;

1.2
date	2014.03.24.17.12.52;	author miod;	state Exp;
branches;
next	1.1;

1.1
date	2014.03.22.00.01.04;	author miod;	state Exp;
branches;
next	;


desc
@@


1.7
log
@Extend the size of user virtual address space from 2GB to 1TB on mips64
by adding another level to page directories. This improves ASLR and
complements W^X added earlier on some systems, giving a notable update
to the architecture's security. Besides, there is now more room for
running tasks that hog memory.

Testing help from deraadt@@ and fcambus@@.
Platforms tested: loongson, octeon, sgi/IP27 and sgi/IP30
(IP30 also with 4KB pages).
@
text
@/*	$OpenBSD: r4000_errata.c,v 1.6 2016/03/06 19:42:27 mpi Exp $	*/

/*
 * Copyright (c) 2014 Miodrag Vallat.
 *
 * Permission to use, copy, modify, and distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 */

/*
 * The following routines attempt to workaround the `end-of-page' errata
 * affecting R4000 processors rev < 3.
 *
 * This particular errata, scarcely documented as errata #4 and #14 in the
 * `R4000PC, R4000SC Errata, Processor Revision 2.2 and 3.0' document,
 * is not recoverable.
 *
 *
 * This errata is triggered by branch instructions in the last word of a
 * page, when the next page (containing the delay slot instruction) causes
 * a TLB miss.  The only safe way to avoid it is to have the toolchain
 * force all branch instructions to be aligned on 8-byte boundaries, but
 * that wouldn't prevent a rogue binary (or just-in-time compilation) to
 * fail this requirement.
 *
 * The following logic is a ``best effort'' (well, ok, ``lazy man's effort'')
 * at trying to prevent the errata from triggering. It will not be enough
 * when confronted to a carefully crafted binary (but then, there are easier
 * way to get kernel mode privileges from userland, when running on the R4000
 * processors vulnerable to the end-of-page errata, so why bother?). Yet,
 * experience has shown this code is surprisingly good enough to allow for
 * regular binaries to run, with a minimal performance hit.
 *
 *
 * The idea behind this code is simple:
 * - executable pages are checked - with eop_page_check() - for a branch in
 *   their last word. If they are vulnerable to this errata, page table entries
 *   for these pages get the `special' bit set.
 * - tlb miss handlers will check for the `special' bit set in the pte and
 *   will always defer to the C code in trap() in that case. trap() will
 *   then invoke eop_tlb_miss_handler(), which will 1) force the next page
 *   to be faulted in, and 2) set up wired TLB entries for both the vulnerable
 *   page and the next page (and their neighbors if they do not share the same
 *   TLB pair), so that there is no risk of a TLB miss when the branch
 *   instruction is reached.
 * - context switches will remove these wired entries.
 * - tlb modification handlers will check for the current exception PC, and
 *   will remove the wired entries if the exception PC is no longer in the
 *   vulnerable page.
 *
 *
 * There are a few limitations:
 * - heavy paging may cause the page next to a vulnerable page to be swapped
 *   out (this code does not attempt to wire the vm_page). It would be worth
 *   mapping a page full of special break instructions when the page gets
 *   swapped out.
 * - there might be other vulnerable pages in the wired tlb entries being
 *   set up. It should be simple enough to walk the next pages until the last
 *   would-be-wired TLB pair contains two safe pages.  However, the amount of
 *   TLB is quite limited, so a limit has to be set at some point.
 * - no effort has been put to catch executable pages being temporarily made
 *   writable, then vulnerable (by putting a branch instruction in the last
 *   word). This is unlikely to happen (except for just-in-time compilation).
 *
 *
 * Note that, by using 16KB page sizes, the number of vulnerable pages is
 * reduced.
 */

#include <sys/param.h>
#include <sys/systm.h>
#include <sys/proc.h>
#include <sys/user.h>

#include <machine/cpu.h>

#include <uvm/uvm_extern.h>

int	r4000_errata;

static inline void eop_undo(struct pcb *);

static inline void
eop_undo(struct pcb *pcb)
{
	tlb_set_wired(UPAGES / 2);
	tlb_flush((UPAGES / 2) + pcb->pcb_nwired);
	pcb->pcb_nwired = 0;
}

/*
 * Check for an R4000 end-of-page errata condition in an executable code page.
 * Returns a bitmask to set in the given page pg_flags.
 */
u_int
eop_page_check(paddr_t pa)
{
	uint32_t insn;

	insn = *(uint32_t *)PHYS_TO_XKPHYS(pa + PAGE_SIZE - 4, CCA_CACHED);
	if (classify_insn(insn) != INSNCLASS_NEUTRAL)
		return PGF_EOP_VULN;

	return 0;
}

/*
 * Invalidate a TLB entry. If it is part of a wired pair, drop all wired
 * entries.
 *
 * Note that, in case of heavy swapping, this can cause the page following
 * a vulnerable page to be swapped out and immediately faulted back in,
 * iff the userland pc is in the vulnerable page. Help me, Obi Wan LRU.
 * You are my only hope.
 */
void
eop_tlb_flush_addr(struct pmap *pmap, vaddr_t va, u_long asid)
{
	struct proc *p = curproc;
	struct pcb *pcb;

	if (p->p_vmspace->vm_map.pmap == pmap) {
		pcb = &p->p_addr->u_pcb;
		if (pcb->pcb_nwired != 0 &&
		    (va - pcb->pcb_wiredva) < ptoa(pcb->pcb_nwired * 2)) {
			eop_undo(pcb);
			return;
		}
	}

	tlb_flush_addr(va | asid);
}

/*
 * Handle a TLB miss exception for a page marked as able to trigger the
 * end-of-page errata.
 * Returns nonzero if the exception has been completely serviced, and no
 * further processing in the trap handler is necessary.
 */
int
eop_tlb_miss_handler(struct trapframe *trapframe, struct cpu_info *ci,
    struct proc *p)
{
	struct pcb *pcb;
	vaddr_t va, faultva;
	struct vmspace *vm;
	vm_map_t map;
	pmap_t pmap;
	pt_entry_t *pte, entry;
	int onfault;
	u_long asid;
	uint i, npairs;
	int64_t tlbidx;

	/*
	 * Check for a valid pte with the `special' bit set (PG_SP)
	 * in order to apply the end-of-page errata workaround.
	 */

	vm = p->p_vmspace;
	map = &vm->vm_map;
	faultva = trunc_page((vaddr_t)trapframe->badvaddr);
	pmap = map->pmap;

	pte = pmap_pte_lookup(pmap, faultva);
	if (pte == NULL)
		return 0;
	entry = *pte;
	if ((entry & PG_SP) == 0)
		return 0;

	pcb = &p->p_addr->u_pcb;
	asid = pmap->pm_asid[ci->ci_cpuid].pma_asid << PG_ASID_SHIFT;

	/*
	 * For now, only allow one EOP vulnerable page to get a wired TLB
	 * entry.  We will aggressively attempt to recycle the wired TLB
	 * entries created for that purpose, as soon as we are no longer
	 * needing the EOP page resident in the TLB.
	 */

	/*
	 * Figure out how many pages to wire in the TLB.
	 */

	if ((faultva & PG_ODDPG) != 0) {
		/* odd page: need two pairs */
		npairs = 2;
	} else {
		/* even page: only need one pair */
		npairs = 1;
	}

	/*
	 * Fault-in the next page.
	 */

	va = faultva + PAGE_SIZE;
	pte = pmap_pte_lookup(pmap, va);
	if (pte == NULL || (*pte & PG_V) == 0) {
		onfault = pcb->pcb_onfault;
		pcb->pcb_onfault = 0;
		KERNEL_LOCK();
		(void)uvm_fault(map, va, 0, PROT_READ | PROT_EXEC);
		KERNEL_UNLOCK();
		pcb->pcb_onfault = onfault;
	}

	/*
	 * Clear possible TLB entries for the pages we're about to wire.
	 */

	for (i = npairs, va = faultva & PG_HVPN; i != 0;
	    i--, va += 2 * PAGE_SIZE) {
		tlbidx = tlb_probe(va | asid);
		if (tlbidx >= 0)
			tlb_update_indexed(CKSEG0_BASE, PG_NV, PG_NV, tlbidx);
	}

	/*
	 * Reserve the extra wired TLB, and fill them with the existing ptes.
	 */

	tlb_set_wired((UPAGES / 2) + npairs);
	for (i = 0, va = faultva & PG_HVPN; i != npairs;
	    i++, va += 2 * PAGE_SIZE) {
		pte = pmap_pte_lookup(pmap, va);
		if (pte == NULL)
			tlb_update_indexed(va | asid,
			    PG_NV, PG_NV, (UPAGES / 2) + i);
		else
			tlb_update_indexed(va | asid,
			    pte[0], pte[1], (UPAGES / 2) + i);
	}

	/*
	 * Save the base address of the EOP vulnerable page, to be able to
	 * figure out when the wired entry is no longer necessary.
	 */

	pcb->pcb_nwired = npairs;
	pcb->pcb_wiredva = faultva & PG_HVPN;
	pcb->pcb_wiredpc = faultva;

	return 1;
}

/*
 * Attempt to cleanup the current end-of-page errata workaround, if the
 * current pc is no longer in an errata vulnerable page.
 */
void
eop_cleanup(struct trapframe *trapframe, struct proc *p)
{
	struct pcb *pcb;

	pcb = &p->p_addr->u_pcb;
	if (pcb->pcb_nwired != 0) {
		if (trunc_page(trapframe->pc) != pcb->pcb_wiredpc)
			eop_undo(pcb);
	}
}
@


1.6
log
@Rename mips64's trap_frame into trapframe.

For coherency with other archs and in order to use it in MI code.

ok visa@@, tobiasu@@
@
text
@d1 1
a1 1
/*	$OpenBSD: r4000_errata.c,v 1.5 2014/11/16 12:30:58 deraadt Exp $	*/
d174 1
a174 1
	pte = pmap_segmap(pmap, faultva);
a176 2

	pte += uvtopte(faultva);
d208 1
a208 4
	pte = pmap_segmap(pmap, va);
	if (pte != NULL)
		pte += uvtopte(va);

d236 1
a236 1
		pte = pmap_segmap(pmap, va);
d240 1
a240 2
		else {
			pte += uvtopte(va);
a242 1
		}
@


1.5
log
@Replace a plethora of historical protection options with just
PROT_NONE, PROT_READ, PROT_WRITE, and PROT_EXEC from mman.h.
PROT_MASK is introduced as the one true way of extracting those bits.
Remove UVM_ADV_* wrapper, using the standard names.
ok doug guenther kettenis
@
text
@d1 1
a1 1
/*	$OpenBSD: r4000_errata.c,v 1.4 2014/04/04 20:52:05 miod Exp $	*/
d150 1
a150 1
eop_tlb_miss_handler(struct trap_frame *trapframe, struct cpu_info *ci,
d269 1
a269 1
eop_cleanup(struct trap_frame *trapframe, struct proc *p)
@


1.4
log
@Second step of the R4000 EOP errata WAR: when pmap invalidates a page which
is currently being covered by the wired TLB entries, flush them, so that,
if the process' pc is still running in a vulnerable page, the WAR will
reapply immediately and fault the next page.
@
text
@d1 1
a1 1
/*	$OpenBSD: r4000_errata.c,v 1.3 2014/04/03 08:07:16 mpi Exp $	*/
d218 1
a218 1
		(void)uvm_fault(map, va, 0, VM_PROT_READ | VM_PROT_EXECUTE);
@


1.3
log
@Moar <uvm/uvm.h> -> <uvm/uvm_extern.h> love.
@
text
@d1 1
a1 1
/*	$OpenBSD: r4000_errata.c,v 1.2 2014/03/24 17:12:52 miod Exp $	*/
d90 10
d117 27
d275 2
a276 5
		if (trunc_page(trapframe->pc) != pcb->pcb_wiredpc) {
			tlb_set_wired(UPAGES / 2);
			tlb_flush((UPAGES / 2) + pcb->pcb_nwired);
			pcb->pcb_nwired = 0;
		}
a278 1

@


1.2
log
@Only need to call tlb_probe() once per pair, instead of once per page.
@
text
@d1 1
a1 1
/*	$OpenBSD: r4000_errata.c,v 1.1 2014/03/22 00:01:04 miod Exp $	*/
d86 1
a86 1
#include <uvm/uvm.h>
@


1.1
log
@Second draft of my attempt to workaround the infamous R4000 end-of-page errata,
affecting R4000 processors revision 2.x and below (found on most R4000 Indigo
and a few R4000 Indy).

Since this errata gets triggered by TLB misses when the code flow crosses a
page boundary, this code attempts to identify code pages prone to trigger the
errata, and force the next page to be mapped for at least as long as the
current pc lies in the troublesome page, by creating wiring extra TLB entries.
These entries get recycled in a lazy-but-aggressive-enough way, either because
of context switches, or because of further tlb exceptions reaching trap().

The errata workaround code is only compiled on R4000-capable kernels (i.e.
sgi GENERIC-IP22 and nothing else), and only enabled on affected processors
(i.e. not on R4000 revision 3, or on R4400).

There is still room for improvemnt in unlucky cases, but in this simple enough
incarnation, this allows my R4000 2.2 Indigo to finally reliably boot multiuser,
even though both /sbin/init and /bin/sh contain code pages which can trigger
the errata.
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d190 2
a191 2
	for (i = npairs * 2, va = faultva & PG_HVPN; i != 0;
	    i--, va += PAGE_SIZE) {
@

