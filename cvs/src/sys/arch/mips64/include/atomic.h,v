head	1.10;
access;
symbols
	OPENBSD_6_1_BASE:1.10
	OPENBSD_6_0:1.10.0.8
	OPENBSD_6_0_BASE:1.10
	OPENBSD_5_9:1.10.0.4
	OPENBSD_5_9_BASE:1.10
	OPENBSD_5_8:1.10.0.6
	OPENBSD_5_8_BASE:1.10
	OPENBSD_5_7:1.10.0.2
	OPENBSD_5_7_BASE:1.10
	OPENBSD_5_6:1.8.0.4
	OPENBSD_5_6_BASE:1.8
	OPENBSD_5_5:1.7.0.14
	OPENBSD_5_5_BASE:1.7
	OPENBSD_5_4:1.7.0.10
	OPENBSD_5_4_BASE:1.7
	OPENBSD_5_3:1.7.0.8
	OPENBSD_5_3_BASE:1.7
	OPENBSD_5_2:1.7.0.6
	OPENBSD_5_2_BASE:1.7
	OPENBSD_5_1_BASE:1.7
	OPENBSD_5_1:1.7.0.4
	OPENBSD_5_0:1.7.0.2
	OPENBSD_5_0_BASE:1.7
	OPENBSD_4_9:1.6.0.6
	OPENBSD_4_9_BASE:1.6
	OPENBSD_4_8:1.6.0.4
	OPENBSD_4_8_BASE:1.6
	OPENBSD_4_7:1.6.0.2
	OPENBSD_4_7_BASE:1.6
	OPENBSD_4_6:1.4.0.4
	OPENBSD_4_6_BASE:1.4
	OPENBSD_4_5:1.3.0.8
	OPENBSD_4_5_BASE:1.3
	OPENBSD_4_4:1.3.0.6
	OPENBSD_4_4_BASE:1.3
	OPENBSD_4_3:1.3.0.4
	OPENBSD_4_3_BASE:1.3
	OPENBSD_4_2:1.3.0.2
	OPENBSD_4_2_BASE:1.3
	OPENBSD_4_1:1.2.0.2
	OPENBSD_4_1_BASE:1.2;
locks; strict;
comment	@ * @;


1.10
date	2015.02.10.23.54.09;	author dlg;	state Exp;
branches;
next	1.9;
commitid	E9H9Qh9Z8zw6UMrN;

1.9
date	2014.09.30.06.51.58;	author jmatthew;	state Exp;
branches;
next	1.8;
commitid	pUEUpP9FlbomZUiI;

1.8
date	2014.03.29.18.09.30;	author guenther;	state Exp;
branches;
next	1.7;

1.7
date	2011.03.23.16.54.36;	author pirofti;	state Exp;
branches;
next	1.6;

1.6
date	2009.12.28.06.55.27;	author syuu;	state Exp;
branches;
next	1.5;

1.5
date	2009.11.27.00.08.27;	author syuu;	state Exp;
branches;
next	1.4;

1.4
date	2009.04.12.17.52.17;	author miod;	state Exp;
branches;
next	1.3;

1.3
date	2007.03.23.21.07.36;	author miod;	state Exp;
branches;
next	1.2;

1.2
date	2007.02.19.17.18.43;	author deraadt;	state Exp;
branches;
next	1.1;

1.1
date	2007.02.06.17.13.33;	author art;	state Exp;
branches;
next	;


desc
@@


1.10
log
@atomic_{cas,swap}_ptr takes a volatile void *, not a volatile void **.
this makes mips64 consistent with the api and all other archs.

testing and ok miod@@
@
text
@/*	$OpenBSD: atomic.h,v 1.9 2014/09/30 06:51:58 jmatthew Exp $	*/

/* Public Domain */

#ifndef _MIPS64_ATOMIC_H_
#define _MIPS64_ATOMIC_H_

#if defined(_KERNEL)

/* wait until the bits to set are clear, and set them */
static __inline void
atomic_wait_and_setbits_int(volatile unsigned int *uip, unsigned int v)
{
	unsigned int tmp0, tmp1;

	__asm__ volatile (
	"1:	ll	%0,	0(%2)\n"
	"	and	%1,	%0,	%3\n"
	"	bnez	%1,	1b\n"
	"	or	%0,	%3,	%0\n"
	"	sc	%0,	0(%2)\n"
	"	beqz	%0,	1b\n"
	"	 nop\n" :
		"=&r"(tmp0), "=&r"(tmp1) :
		"r"(uip), "r"(v) : "memory");
}

static __inline void
atomic_setbits_int(volatile unsigned int *uip, unsigned int v)
{
	unsigned int tmp;

	__asm__ volatile (
	"1:	ll	%0,	0(%1)\n"
	"	or	%0,	%2,	%0\n"
	"	sc	%0,	0(%1)\n"
	"	beqz	%0,	1b\n"
	"	 nop\n" :
		"=&r"(tmp) :
		"r"(uip), "r"(v) : "memory");
}

static __inline void
atomic_clearbits_int(volatile unsigned int *uip, unsigned int v)
{
	unsigned int tmp;

	__asm__ volatile (
	"1:	ll	%0,	0(%1)\n"
	"	and	%0,	%2,	%0\n"
	"	sc	%0,	0(%1)\n"
	"	beqz	%0,	1b\n"
	"	 nop\n" :
		"=&r"(tmp) :
		"r"(uip), "r"(~v) : "memory");
}


static inline unsigned int
_atomic_cas_uint(volatile unsigned int *p, unsigned int o, unsigned int n)
{
	unsigned int rv, wv;

	__asm__ volatile (
	"1:	ll	%0,	%1\n"
	"	bne	%0,	%4,	2f\n"
	"	move	%2,	%3\n"
	"	sc	%2,	%1\n"
	"	beqz	%2,	1b\n"
	"2:	nop\n"
	    : "=&r" (rv), "+m" (*p), "=&r" (wv)
	    : "r" (n), "Ir" (o));

	return (rv);
}
#define atomic_cas_uint(_p, _o, _n) _atomic_cas_uint((_p), (_o), (_n))

static inline unsigned long
_atomic_cas_ulong(volatile unsigned long *p, unsigned long o, unsigned long n)
{
	unsigned long rv, wv;

	__asm__ volatile (
	"1:	lld	%0,	%1\n"
	"	bne	%0,	%4,	2f\n"
	"	move	%2,	%3\n"
	"	scd	%2,	%1\n"
	"	beqz	%2,	1b\n"
	"2:	nop\n"
	    : "=&r" (rv), "+m" (*p), "=&r" (wv)
	    : "r" (n), "Ir" (o));

	return (rv);
}
#define atomic_cas_ulong(_p, _o, _n) _atomic_cas_ulong((_p), (_o), (_n))

static inline void *
_atomic_cas_ptr(volatile void *pp, void *o, void *n)
{
	void * volatile *p = pp;
	void *rv, *wv;

	__asm__ volatile (
	"1:	lld	%0,	%1\n"
	"	bne	%0,	%4,	2f\n"
	"	move	%2,	%3\n"
	"	scd	%2,	%1\n"
	"	beqz	%2,	1b\n"
	"2:	nop\n"
	    : "=&r" (rv), "+m" (*p), "=&r" (wv)
	    : "r" (n), "Ir" (o));

	return (rv);
}
#define atomic_cas_ptr(_p, _o, _n) _atomic_cas_ptr((_p), (_o), (_n))



static inline unsigned int
_atomic_swap_uint(volatile unsigned int *uip, unsigned int v)
{
	unsigned int o, t;

	__asm__ volatile (
	"1:	ll	%0,	%1\n"
	"	move	%2,	%3\n"
	"	sc	%2,	%1\n"
	"	beqz	%2,	1b\n"
	"	nop\n" 
	    : "=&r" (o), "+m" (*uip), "=&r" (t)
	    : "r" (v));

	return (o);
}
#define atomic_swap_uint(_p, _v) _atomic_swap_uint((_p), (_v))

static inline unsigned long
_atomic_swap_ulong(volatile unsigned long *uip, unsigned long v)
{
	unsigned long o, t;

	__asm__ volatile (
	"1:	lld	%0,	%1\n"
	"	move	%2,	%3\n"
	"	scd	%2,	%1\n"
	"	beqz	%2,	1b\n"
	"	nop\n" 
	    : "=&r" (o), "+m" (*uip), "=&r" (t)
	    : "r" (v));

	return (o);
}
#define atomic_swap_ulong(_p, _v) _atomic_swap_ulong((_p), (_v))


static inline void *
_atomic_swap_ptr(volatile void *uipp, void *n)
{
	void * volatile *uip = uipp;
	void *o, *t;

	__asm__ volatile (
	"1:	lld	%0,	%1\n"
	"	move	%2,	%3\n"
	"	scd	%2,	%1\n"
	"	beqz	%2,	1b\n"
	"	nop\n"
	    : "=&r" (o), "+m" (*uip), "=&r" (t)
	    : "r" (n));

	return (o);
}
#define atomic_swap_ptr(_p, _n) _atomic_swap_ptr((_p), (_n))

static inline unsigned int
_atomic_add_int_nv(volatile unsigned int *uip, unsigned int v)
{
	unsigned int rv, nv;

	__asm__ volatile (
	"1:	ll	%0,	%1\n"
	"	addu	%2,	%0,	%3\n"
	"	sc	%2,	%1\n"
	"	beqz	%2,	1b\n"
	"	nop\n"
	    : "=&r" (rv), "+m" (*uip), "=&r" (nv)
	    : "Ir" (v));

	return (rv + v);
}
#define atomic_add_int_nv(_uip, _v) _atomic_add_int_nv((_uip), (_v))
#define atomic_sub_int_nv(_uip, _v) _atomic_add_int_nv((_uip), 0 - (_v))

static inline unsigned long
_atomic_add_long_nv(volatile unsigned long *uip, unsigned long v)
{
	unsigned long rv, nv;

	__asm__ volatile (
	"1:	lld	%0,	%1\n"
	"	daddu	%2,	%0,	%3\n"
	"	scd	%2,	%1\n"
	"	beqz	%2,	1b\n"
	"	nop\n"
	    : "=&r" (rv), "+m" (*uip), "=&r" (nv)
	    : "Ir" (v));

	return (rv + v);
}
#define atomic_add_long_nv(_uip, _v) _atomic_add_long_nv((_uip), (_v))
#define atomic_sub_long_nv(_uip, _v) _atomic_add_long_nv((_uip), 0 - (_v))

#endif /* defined(_KERNEL) */
#endif /* _MIPS64_ATOMIC_H_ */
@


1.9
log
@implement atomic operations using ll/sc, and convert rw_cas and callers of the
pre-existing atomics to match.

tested on sgi (octane) and octeon (erl)
ok miod@@ dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: atomic.h,v 1.8 2014/03/29 18:09:30 guenther Exp $	*/
d98 1
a98 1
_atomic_cas_ptr(volatile void **p, void *o, void *n)
d100 1
d157 1
a157 1
_atomic_swap_ptr(volatile void **uip, void *n)
d159 1
@


1.8
log
@It's been a quarter century: we can assume volatile is present with that name.

ok dlg@@ mpi@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: atomic.h,v 1.7 2011/03/23 16:54:36 pirofti Exp $	*/
d58 117
a174 2
static __inline void
atomic_add_int(volatile unsigned int *uip, unsigned int v)
d176 1
a176 1
	unsigned int tmp;
d179 9
a187 7
	"1:	ll	%0,	0(%1)\n"
	"	addu	%0,	%2,	%0\n"
	"	sc	%0,	0(%1)\n"
	"	beqz	%0,	1b\n"
	"	 nop\n" :
		"=&r"(tmp) :
		"r"(uip), "r"(v) : "memory");
d189 5
a193 2
static __inline void
atomic_add_uint64(volatile uint64_t *uip, uint64_t v)
d195 1
a195 1
	uint64_t tmp;
d198 9
a206 7
	"1:	lld	%0,	0(%1)\n"
	"	daddu	%0,	%2,	%0\n"
	"	scd	%0,	0(%1)\n"
	"	beqz	%0,	1b\n"
	"	 nop\n" :
		"=&r"(tmp) :
		"r"(uip), "r"(v) : "memory");
d208 3
@


1.7
log
@Normalize sentinel. Use _MACHINE_*_H_ and _<ARCH>_*_H_ properly and consitently.

Discussed and okay drahn@@. Okay deraadt@@.
@
text
@d1 1
a1 1
/*	$OpenBSD: atomic.h,v 1.6 2009/12/28 06:55:27 syuu Exp $	*/
d12 1
a12 1
atomic_wait_and_setbits_int(__volatile unsigned int *uip, unsigned int v)
d16 1
a16 1
	__asm__ __volatile__ (
d29 1
a29 1
atomic_setbits_int(__volatile unsigned int *uip, unsigned int v)
d33 1
a33 1
	__asm__ __volatile__ (
d44 1
a44 1
atomic_clearbits_int(__volatile unsigned int *uip, unsigned int v)
d48 1
a48 1
	__asm__ __volatile__ (
d59 1
a59 1
atomic_add_int(__volatile unsigned int *uip, unsigned int v)
d63 1
a63 1
	__asm__ __volatile__ (
d73 1
a73 1
atomic_add_uint64(__volatile uint64_t *uip, uint64_t v)
d77 1
a77 1
	__asm__ __volatile__ (
@


1.6
log
@MP-safe pmap implemented, enable IPI in interrupt handler to avoid deadlock.
ok miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: atomic.h,v 1.5 2009/11/27 00:08:27 syuu Exp $	*/
d5 2
a6 2
#ifndef __MIPS64_ATOMIC_H__
#define __MIPS64_ATOMIC_H__
d87 1
a87 1
#endif /* __MIPS64_ATOMIC_H__ */
@


1.5
log
@atomic counter increment for SMP.
ok jsing@@
@
text
@d1 1
a1 1
/*	$OpenBSD: atomic.h,v 1.4 2009/04/12 17:52:17 miod Exp $	*/
d9 18
@


1.4
log
@Better constraints on the temporary register in atomic_{set,clear}bits_int.
@
text
@d1 1
a1 1
/*	$OpenBSD: atomic.h,v 1.3 2007/03/23 21:07:36 miod Exp $	*/
d40 28
@


1.3
log
@Real atomic_{set,clear}bits_int implementation, and replace similar
{set,clr}_ipending with the above routines.
ok kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: atomic.h,v 1.2 2007/02/19 17:18:43 deraadt Exp $	*/
d21 1
a21 1
		"+r"(tmp) :
d36 1
a36 1
		"+r"(tmp) :
@


1.2
log
@only make this interface available to the kernel for now, discussed witha
rt and such; tested and ok miod drahn
@
text
@d1 1
a1 1
/*	$OpenBSD: atomic.h,v 1.1 2007/02/06 17:13:33 art Exp $	*/
d13 10
a22 1
	*uip |= v;
d28 10
a37 1
	*uip &= ~v;
@


1.1
log
@Add machine/atomic.h to all architectures and define two operations
right now that are supposed to be atomic with respect to interrupts and
SMP: atomic_setbits_int and atomic_clearbits_int.

All architectures other than i386 and amd64 get dummy implementations
since at first we'll be replacing operations that are done with
"a |= bit" and "a &= ~bit" today. More proper implementations will follow

kettenis@@, miod@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d8 2
d22 2
a23 1
#endif
@

