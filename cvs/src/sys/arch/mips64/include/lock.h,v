head	1.8;
access;
symbols
	OPENBSD_6_1:1.7.0.12
	OPENBSD_6_1_BASE:1.7
	OPENBSD_6_0:1.7.0.8
	OPENBSD_6_0_BASE:1.7
	OPENBSD_5_9:1.7.0.4
	OPENBSD_5_9_BASE:1.7
	OPENBSD_5_8:1.7.0.6
	OPENBSD_5_8_BASE:1.7
	OPENBSD_5_7:1.7.0.2
	OPENBSD_5_7_BASE:1.7
	OPENBSD_5_6:1.5.0.8
	OPENBSD_5_6_BASE:1.5
	OPENBSD_5_5:1.5.0.6
	OPENBSD_5_5_BASE:1.5
	OPENBSD_5_4:1.5.0.2
	OPENBSD_5_4_BASE:1.5
	OPENBSD_5_3:1.4.0.12
	OPENBSD_5_3_BASE:1.4
	OPENBSD_5_2:1.4.0.10
	OPENBSD_5_2_BASE:1.4
	OPENBSD_5_1_BASE:1.4
	OPENBSD_5_1:1.4.0.8
	OPENBSD_5_0:1.4.0.6
	OPENBSD_5_0_BASE:1.4
	OPENBSD_4_9:1.4.0.4
	OPENBSD_4_9_BASE:1.4
	OPENBSD_4_8:1.4.0.2
	OPENBSD_4_8_BASE:1.4
	OPENBSD_4_7:1.3.0.2
	OPENBSD_4_7_BASE:1.3
	OPENBSD_4_6:1.1.0.12
	OPENBSD_4_6_BASE:1.1
	OPENBSD_4_5:1.1.0.8
	OPENBSD_4_5_BASE:1.1
	OPENBSD_4_4:1.1.0.6
	OPENBSD_4_4_BASE:1.1
	OPENBSD_4_3:1.1.0.4
	OPENBSD_4_3_BASE:1.1
	OPENBSD_4_2:1.1.0.2
	OPENBSD_4_2_BASE:1.1;
locks; strict;
comment	@ * @;


1.8
date	2017.05.19.00.52.49;	author visa;	state Exp;
branches;
next	1.7;
commitid	brVG3gpt7QG6HzRJ;

1.7
date	2015.02.11.00.14.11;	author dlg;	state Exp;
branches;
next	1.6;
commitid	OPUATglsyqcmeG4g;

1.6
date	2014.09.30.06.51.58;	author jmatthew;	state Exp;
branches;
next	1.5;
commitid	pUEUpP9FlbomZUiI;

1.5
date	2013.05.21.20.05.30;	author tedu;	state Exp;
branches;
next	1.4;

1.4
date	2010.04.21.03.03.26;	author deraadt;	state Exp;
branches;
next	1.3;

1.3
date	2009.11.21.23.28.14;	author syuu;	state Exp;
branches;
next	1.2;

1.2
date	2009.09.15.04.54.31;	author syuu;	state Exp;
branches;
next	1.1;

1.1
date	2007.05.01.18.56.30;	author miod;	state Exp;
branches;
next	;


desc
@@


1.8
log
@Replace __cpu_cas() with atomic_cas_ulong().

OK kettenis@@
@
text
@/*	$OpenBSD: lock.h,v 1.7 2015/02/11 00:14:11 dlg Exp $	*/

/* public domain */

#ifndef	_MIPS64_LOCK_H_
#define	_MIPS64_LOCK_H_

#include <sys/atomic.h>

#endif	/* _MIPS64_LOCK_H_ */
@


1.7
log
@make the rwlock implementation MI.

each arch used to have to provide an rw_cas operation, but now we
have the rwlock code build its own version. on smp machines it uses
atomic_cas_ulong. on uniproc machines it avoids interlocked
instructions by using straight loads and stores. this is safe because
rwlocks are only used from process context and processes are currently
not preemptible in our kernel. so alpha/ppc/etc might get a benefit.

ok miod@@ kettenis@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: lock.h,v 1.6 2014/09/30 06:51:58 jmatthew Exp $	*/
a8 6

static __inline int
__cpu_cas(volatile unsigned long *addr, unsigned long old, unsigned long new)
{
	return (atomic_cas_ulong(addr, old, new) != old);
}
@


1.6
log
@implement atomic operations using ll/sc, and convert rw_cas and callers of the
pre-existing atomics to match.

tested on sgi (octane) and octeon (erl)
ok miod@@ dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: lock.h,v 1.5 2013/05/21 20:05:30 tedu Exp $	*/
a9 1
#define rw_cas __cpu_cas
@


1.5
log
@remove unused cpu_lock code (where it is truly unused). it is not
part of the future we have planned. middling ok from a few
@
text
@d1 1
a1 1
/*	$OpenBSD: lock.h,v 1.4 2010/04/21 03:03:26 deraadt Exp $	*/
d8 1
a8 1
#include <mips64/atomic.h>
d14 1
a14 22
	int success, scratch0, scratch1;

        __asm volatile(
		".set noreorder\n"
		"1:\n"
		"lld	%0, (%5)\n"
		"bne	%0, %3, 2f\n"
		"move	%1, %4\n"
		"scd	%1, (%5)\n"
		"beqz	%1, 1b\n"
		"move   %2, $0\n"
		"j	3f\n"
		"nop\n"
		"2:\n"
		"daddi   %2, $0, 1\n"
		"3:\n"
		".set reorder\n"
		: "=&r"(scratch0), "=&r"(scratch1), "=&r"(success)
		: "r"(old), "r"(new), "r"(addr)
		: "memory");

	return success;
@


1.4
log
@more cleanup to cope with the change that tries to make proc.h not act
like it is everything.h
ok tedu
@
text
@d1 1
a1 1
/*	$OpenBSD: lock.h,v 1.3 2009/11/21 23:28:14 syuu Exp $	*/
a8 46

typedef volatile u_int __cpu_simple_lock_t;

#define	__SIMPLELOCK_LOCKED	1
#define	__SIMPLELOCK_UNLOCKED	0

static __inline__ void
__cpu_simple_lock_init(__cpu_simple_lock_t *l)
{
	*l = __SIMPLELOCK_UNLOCKED;
}

static __inline__ void
__cpu_simple_lock(__cpu_simple_lock_t *l)
{
	__cpu_simple_lock_t old, new;

	do {
		new = __SIMPLELOCK_LOCKED;
		__asm__ __volatile__
		   ("1:\tll\t%0, %1\n" 
		    "\tsc\t%2, %1\n"
		    "\tbeqz\t%2, 1b\n"
		    "\t nop" : "=&r" (old) : "m" (*l), "r" (new));
	} while (old != __SIMPLELOCK_UNLOCKED);
}

static __inline__ int
__cpu_simple_lock_try(__cpu_simple_lock_t *l)
{
	__cpu_simple_lock_t old, new = __SIMPLELOCK_LOCKED;

	__asm__ __volatile__
	   ("1:\tll\t%0, %1\n" 
	    "\tsc\t%2, %1\n"
	    "\tbeqz\t%2, 1b\n"
	    "\t nop" : "=&r" (old) : "m" (*l), "r" (new));

	return (old == __SIMPLELOCK_UNLOCKED);
}

static __inline__ void
__cpu_simple_unlock(__cpu_simple_lock_t *l)
{
	*l = __SIMPLELOCK_UNLOCKED;
}
@


1.3
log
@mplock, rw_cas implemented
ok miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: lock.h,v 1.2 2009/09/15 04:54:31 syuu Exp $	*/
d7 2
@


1.2
log
@cpu status flag, cpuid added to cpu_info.
cpu_info pointer array, cpu_info iterator, cpu_number() implementation added.
constraint modifier fixed in lock.h to output correct assembly.
calling proc_trampoline_mp in exception.S.
@
text
@d1 1
a1 1
/*	$OpenBSD: lock.h,v 1.1 2007/05/01 18:56:30 miod Exp $	*/
d52 28
@


1.1
log
@Provide <machine/lock.h> on all platforms, so that MI code may #include it
unconditionnaly.
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d30 1
a30 1
		    "\t nop" : "=r" (old) : "m" (*l), "r" (new));
d43 1
a43 1
	    "\t nop" : "=r" (old) : "m" (*l), "r" (new));
@

