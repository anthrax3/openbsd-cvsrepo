head	1.3;
access;
symbols;
locks; strict;
comment	@# @;


1.3
date	2017.03.24.19.48.01;	author kettenis;	state Exp;
branches;
next	1.2;
commitid	bfLkKPORusoVcbLW;

1.2
date	2017.03.12.21.05.25;	author kettenis;	state Exp;
branches;
next	1.1;
commitid	bmNVgJq8eatf0eeZ;

1.1
date	2017.02.06.19.23.45;	author patrick;	state Exp;
branches;
next	;
commitid	5it27ZRIjA5PXf5f;


desc
@@


1.3
log
@Simplify ASID allocation code considerably by allocating an ASID up front
when a pmap is created and freeing it when the pmap is destroyed.  This
diff relies on the fill 16-bit ASID space being implemented in the processor.
While this is documented as an optional feature in the ARMv8 architecture
reference manual, all ARMv8 processors seen in the wild so far implement
the full 16-bit space.  This change incorporates changes by drahn@@ to
allocate an empty page table for the lower half of the address space for the
kernel.

ok drahn@@, patrick@@
@
text
@/* $OpenBSD: cpufunc_asm.S,v 1.2 2017/03/12 21:05:25 kettenis Exp $ */
/*-
 * Copyright (c) 2014 Robin Randhawa
 * Copyright (c) 2015 The FreeBSD Foundation
 * All rights reserved.
 *
 * Portions of this software were developed by Andrew Turner
 * under sponsorship from the FreeBSD Foundation
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 *
 * THIS SOFTWARE IS PROVIDED BY THE AUTHOR AND CONTRIBUTORS ``AS IS'' AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE
 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
 *
 */

#include <machine/asm.h>
#include <machine/param.h>
//__FBSDID("$FreeBSD: head/sys/arm64/arm64/cpufunc_asm.S 305546 2016-09-07 16:46:54Z andrew $");

/*
 * FIXME:
 * Need big.LITTLE awareness at some point.
 * Using [id]cache_line_size may not be the best option.
 * Need better SMP awareness.
 */
	.text
	.align	2

/*
 * Macro to handle the cache. This takes the start address in x0, length
 * in x1. It will corrupt x0, x1, x2, and x3.
 */
.macro cache_handle_range dcop = 0, ic = 0, icop = 0
.if \ic == 0
	ldr	x3, =dcache_line_size	/* Load the D cache line size */
.else
	ldr	x3, =idcache_line_size	/* Load the I & D cache line size */
.endif
	ldr	x3, [x3]
	sub	x4, x3, #1		/* Get the address mask */
	and	x2, x0, x4		/* Get the low bits of the address */
	add	x1, x1, x2		/* Add these to the size */
	bic	x0, x0, x4		/* Clear the low bit of the address */
1:
	dc	\dcop, x0
	dsb	ish
.if \ic != 0
	ic	\icop, x0
	dsb	ish
.endif
	add	x0, x0, x3		/* Move to the next line */
	subs	x1, x1, x3		/* Reduce the size */
	b.hi	1b			/* Check if we are done */
.if \ic != 0
	isb
.endif
	ret
.endm

/*
 * Generic functions to read/modify/write the internal coprocessor registers
 */

ENTRY(cpu_setttb)
	dsb	ish
	msr	ttbr0_el1, x0
	dsb	ish
	isb
	ret
END(cpu_setttb)

ENTRY(cpu_tlb_flush)
	dsb	ishst
	tlbi	vmalle1is
	dsb	ish
	isb
	ret
END(cpu_tlb_flush)

ENTRY(cpu_tlb_flush_asid)
	dsb	ishst
	tlbi	vae1is, x0
	dsb	ish
	isb
	ret
END(cpu_tlb_flush_asid)

ENTRY(cpu_tlb_flush_all_asid)
	dsb	ishst
	tlbi	vaale1is, x0
	dsb	ish
	isb
	ret
END(cpu_tlb_flush_all_asid)

ENTRY(cpu_tlb_flush_asid_all)
	dsb	ishst
	tlbi	aside1is, x0
	dsb	ish
	isb
	ret
END(cpu_tlb_flush_asid_all)

/*
 * void cpu_dcache_wb_range(vaddr_t, vsize_t)
 */
ENTRY(cpu_dcache_wb_range)
	cache_handle_range	dcop = cvac
END(cpu_dcache_wb_range)

/*
 * void cpu_dcache_wbinv_range(vaddr_t, vsize_t)
 */
ENTRY(cpu_dcache_wbinv_range)
	cache_handle_range	dcop = civac
END(cpu_dcache_wbinv_range)

/*
 * void cpu_dcache_inv_range(vaddr_t, vsize_t)
 *
 * Note, we must not invalidate everything.  If the range is too big we
 * must use wb-inv of the entire cache.
 */
ENTRY(cpu_dcache_inv_range)
	cache_handle_range	dcop = ivac
END(cpu_dcache_inv_range)

/*
 * void cpu_idcache_wbinv_range(vaddr_t, vsize_t)
 */
ENTRY(cpu_idcache_wbinv_range)
	cache_handle_range	dcop = civac, ic = 1, icop = ivau
END(cpu_idcache_wbinv_range)

/*
 * void cpu_icache_sync_range(vaddr_t, vsize_t)
 */
ENTRY(cpu_icache_sync_range)
	cache_handle_range	dcop = cvau, ic = 1, icop = ivau
END(cpu_icache_sync_range)
@


1.2
log
@Add a "dsm ishst" barrier before TLB maintenance instructions.  The ARMv8
architecture reference manual says this is required (D4.7 under "Ordering
and completion of TLB maintenance instructions" to guarantee that the
translation table walk can observe previous store to the page tables.  It
also has a note that says

  In all cases in this section, where a DMB or DSB is referred to, it
  refers to a DMB or DSB whose required access type is both loads and
  stores.

But both Linux and FreeBSD use a Store-Store barrier here.

Sadly this doesn't fix the arm64 stability problems (or at least not all
of them).

ok patrick@@
@
text
@d1 1
a1 1
/* $OpenBSD: cpufunc_asm.S,v 1.1 2017/02/06 19:23:45 patrick Exp $ */
d112 8
@


1.1
log
@Move cache and tlb flush functions, which were mostly inline assembly,
into separate functions.  This makes them reusable from other parts in
the kernel.  Assembly and header are taken from FreeBSD, but modified
to fit our requirements and with some unnecessary stuff removed.  While
there remove micro optimization for uniprocessor kernels.
@
text
@d1 1
a1 1
/* $OpenBSD$ */
d90 1
d98 1
d106 1
@

