head	1.33;
access;
symbols
	OPENBSD_5_9:1.32.0.4
	OPENBSD_5_9_BASE:1.32
	OPENBSD_5_8:1.32.0.6
	OPENBSD_5_8_BASE:1.32
	OPENBSD_5_7:1.32.0.2
	OPENBSD_5_7_BASE:1.32
	OPENBSD_5_6:1.29.0.4
	OPENBSD_5_6_BASE:1.29
	OPENBSD_5_5:1.27.0.14
	OPENBSD_5_5_BASE:1.27
	OPENBSD_5_4:1.27.0.10
	OPENBSD_5_4_BASE:1.27
	OPENBSD_5_3:1.27.0.8
	OPENBSD_5_3_BASE:1.27
	OPENBSD_5_2:1.27.0.6
	OPENBSD_5_2_BASE:1.27
	OPENBSD_5_1_BASE:1.27
	OPENBSD_5_1:1.27.0.4
	OPENBSD_5_0:1.27.0.2
	OPENBSD_5_0_BASE:1.27
	OPENBSD_4_9:1.26.0.2
	OPENBSD_4_9_BASE:1.26
	OPENBSD_4_8:1.24.0.2
	OPENBSD_4_8_BASE:1.24
	OPENBSD_4_7:1.23.0.2
	OPENBSD_4_7_BASE:1.23
	OPENBSD_4_6:1.23.0.4
	OPENBSD_4_6_BASE:1.23
	OPENBSD_4_5:1.20.0.2
	OPENBSD_4_5_BASE:1.20
	OPENBSD_4_4:1.19.0.2
	OPENBSD_4_4_BASE:1.19
	OPENBSD_4_3:1.18.0.2
	OPENBSD_4_3_BASE:1.18
	OPENBSD_4_2:1.16.0.8
	OPENBSD_4_2_BASE:1.16
	OPENBSD_4_1:1.16.0.6
	OPENBSD_4_1_BASE:1.16
	OPENBSD_4_0:1.16.0.4
	OPENBSD_4_0_BASE:1.16
	OPENBSD_3_9:1.16.0.2
	OPENBSD_3_9_BASE:1.16
	OPENBSD_3_8:1.14.0.4
	OPENBSD_3_8_BASE:1.14
	OPENBSD_3_7:1.14.0.2
	OPENBSD_3_7_BASE:1.14
	OPENBSD_3_6:1.12.0.8
	OPENBSD_3_6_BASE:1.12
	SMP_SYNC_A:1.12
	SMP_SYNC_B:1.12
	OPENBSD_3_5:1.12.0.6
	OPENBSD_3_5_BASE:1.12
	OPENBSD_3_4:1.12.0.4
	OPENBSD_3_4_BASE:1.12
	UBC_SYNC_A:1.12
	OPENBSD_3_3:1.12.0.2
	OPENBSD_3_3_BASE:1.12
	OPENBSD_3_2:1.10.0.4
	OPENBSD_3_2_BASE:1.10
	OPENBSD_3_1:1.10.0.2
	OPENBSD_3_1_BASE:1.10
	UBC_SYNC_B:1.12
	UBC:1.8.0.2
	UBC_BASE:1.8
	OPENBSD_3_0:1.5.0.2
	OPENBSD_3_0_BASE:1.5
	SMP:1.1.0.8
	OPENBSD_2_9_BASE:1.1
	OPENBSD_2_9:1.1.0.6
	OPENBSD_2_8:1.1.0.4
	OPENBSD_2_8_BASE:1.1
	OPENBSD_2_7:1.1.0.2
	OPENBSD_2_7_BASE:1.1;
locks; strict;
comment	@ * @;


1.33
date	2016.03.09.16.28.49;	author deraadt;	state dead;
branches;
next	1.32;
commitid	OSDG2O3Cgeifnf1W;

1.32
date	2014.12.23.21.39.12;	author miod;	state Exp;
branches;
next	1.31;
commitid	foSDoFEw0OUhYWGt;

1.31
date	2014.11.16.12.30.59;	author deraadt;	state Exp;
branches;
next	1.30;
commitid	yv0ECmCdICvq576h;

1.30
date	2014.09.13.16.06.37;	author doug;	state Exp;
branches;
next	1.29;
commitid	jdBY2kKXhfcoQitp;

1.29
date	2014.07.12.18.44.43;	author tedu;	state Exp;
branches;
next	1.28;
commitid	uKVPYMN2MLxdZxzH;

1.28
date	2014.07.11.09.36.26;	author mpi;	state Exp;
branches;
next	1.27;
commitid	vsYjSRfS3Y783BvW;

1.27
date	2011.06.23.20.44.39;	author ariane;	state Exp;
branches;
next	1.26;

1.26
date	2010.12.26.15.41.00;	author miod;	state Exp;
branches;
next	1.25;

1.25
date	2010.11.20.20.33.24;	author miod;	state Exp;
branches;
next	1.24;

1.24
date	2010.03.29.19.21.58;	author oga;	state Exp;
branches;
next	1.23;

1.23
date	2009.04.20.00.42.06;	author oga;	state Exp;
branches;
next	1.22;

1.22
date	2009.04.14.16.01.04;	author oga;	state Exp;
branches;
next	1.21;

1.21
date	2009.03.07.15.34.34;	author miod;	state Exp;
branches;
next	1.20;

1.20
date	2008.08.15.22.40.00;	author miod;	state Exp;
branches;
next	1.19;

1.19
date	2008.06.26.05.42.14;	author ray;	state Exp;
branches;
next	1.18;

1.18
date	2007.10.02.00.59.12;	author krw;	state Exp;
branches;
next	1.17;

1.17
date	2007.09.03.01.09.09;	author krw;	state Exp;
branches;
next	1.16;

1.16
date	2005.11.08.15.05.56;	author martin;	state Exp;
branches;
next	1.15;

1.15
date	2005.11.06.22.21.33;	author miod;	state Exp;
branches;
next	1.14;

1.14
date	2004.12.25.23.02.26;	author miod;	state Exp;
branches;
next	1.13;

1.13
date	2004.11.09.19.17.01;	author claudio;	state Exp;
branches;
next	1.12;

1.12
date	2002.10.07.18.35.57;	author mickey;	state Exp;
branches;
next	1.11;

1.11
date	2002.10.06.22.06.15;	author art;	state Exp;
branches;
next	1.10;

1.10
date	2002.03.14.01.26.48;	author millert;	state Exp;
branches;
next	1.9;

1.9
date	2002.01.16.20.50.17;	author miod;	state Exp;
branches;
next	1.8;

1.8
date	2001.12.08.02.24.07;	author art;	state Exp;
branches
	1.8.2.1;
next	1.7;

1.7
date	2001.11.28.16.24.26;	author art;	state Exp;
branches;
next	1.6;

1.6
date	2001.11.06.02.49.23;	author art;	state Exp;
branches;
next	1.5;

1.5
date	2001.09.19.20.50.57;	author mickey;	state Exp;
branches;
next	1.4;

1.4
date	2001.08.02.21.30.30;	author hugh;	state Exp;
branches;
next	1.3;

1.3
date	2001.07.25.13.25.33;	author art;	state Exp;
branches;
next	1.2;

1.2
date	2001.06.08.08.09.31;	author art;	state Exp;
branches;
next	1.1;

1.1
date	2000.04.27.01.10.10;	author bjc;	state Exp;
branches
	1.1.8.1;
next	;

1.1.8.1
date	2001.05.14.21.38.42;	author niklas;	state Exp;
branches;
next	1.1.8.2;

1.1.8.2
date	2001.07.04.10.24.33;	author niklas;	state Exp;
branches;
next	1.1.8.3;

1.1.8.3
date	2001.10.31.03.08.01;	author nate;	state Exp;
branches;
next	1.1.8.4;

1.1.8.4
date	2001.11.13.21.04.18;	author niklas;	state Exp;
branches;
next	1.1.8.5;

1.1.8.5
date	2002.03.06.02.04.48;	author niklas;	state Exp;
branches;
next	1.1.8.6;

1.1.8.6
date	2002.03.28.11.26.46;	author niklas;	state Exp;
branches;
next	1.1.8.7;

1.1.8.7
date	2002.03.30.08.27.12;	author niklas;	state Exp;
branches;
next	;

1.8.2.1
date	2002.01.31.22.55.27;	author niklas;	state Exp;
branches;
next	1.8.2.2;

1.8.2.2
date	2002.06.11.03.39.19;	author art;	state Exp;
branches;
next	1.8.2.3;

1.8.2.3
date	2002.10.29.00.28.14;	author art;	state Exp;
branches;
next	;


desc
@@


1.33
log
@We are done providing support for the vax.
lots of agreement.
@
text
@/*	$OpenBSD: bus_dma.c,v 1.32 2014/12/23 21:39:12 miod Exp $	*/
/*	$NetBSD: bus_dma.c,v 1.5 1999/11/13 00:32:20 thorpej Exp $	*/

/*-
 * Copyright (c) 1996, 1997, 1998 The NetBSD Foundation, Inc.
 * All rights reserved.
 *
 * This code is derived from software contributed to The NetBSD Foundation
 * by Jason R. Thorpe of the Numerical Aerospace Simulation Facility,
 * NASA Ames Research Center.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 *
 * THIS SOFTWARE IS PROVIDED BY THE NETBSD FOUNDATION, INC. AND CONTRIBUTORS
 * ``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED
 * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE FOUNDATION OR CONTRIBUTORS
 * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
 * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
 * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
 * POSSIBILITY OF SUCH DAMAGE.
 */
/*
 * bus_dma routines for vax. File copied from arm32/bus_dma.c.
 * NetBSD: bus_dma.c,v 1.11 1998/09/21 22:53:35 thorpej Exp
 */

#include <sys/param.h>
#include <sys/systm.h>
#include <sys/kernel.h>
#include <sys/proc.h>
#include <sys/buf.h>
#include <sys/reboot.h>
#include <sys/conf.h>
#include <sys/file.h>
#include <sys/malloc.h>
#include <sys/mbuf.h>
#include <sys/vnode.h>
#include <sys/device.h>

#include <uvm/uvm_extern.h>

#define _VAX_BUS_DMA_PRIVATE
#include <machine/bus.h>

#include <machine/ka43.h>
#include <machine/sid.h>

extern	vaddr_t virtual_avail;

int	_bus_dmamap_load_buffer(bus_dma_tag_t, bus_dmamap_t, void *,
	    bus_size_t, struct proc *, int, paddr_t *, int *, int);
int	_bus_dma_inrange(bus_dma_segment_t *, int, bus_addr_t);
int	_bus_dmamem_alloc_range(bus_dma_tag_t, bus_size_t, bus_size_t,
	    bus_size_t, bus_dma_segment_t*, int, int *, int, vaddr_t, vaddr_t);
/*
 * Common function for DMA map creation.  May be called by bus-specific
 * DMA map creation functions.
 */
int
_bus_dmamap_create(t, size, nsegments, maxsegsz, boundary, flags, dmamp)
	bus_dma_tag_t t;
	bus_size_t size;
	int nsegments;
	bus_size_t maxsegsz;
	bus_size_t boundary;
	int flags;
	bus_dmamap_t *dmamp;
{
	struct vax_bus_dmamap *map;
	void *mapstore;
	size_t mapsize;

#ifdef DEBUG_DMA
	printf("dmamap_create: t=%p size=%lx nseg=%x msegsz=%lx boundary=%lx flags=%x\n",
	    t, size, nsegments, maxsegsz, boundary, flags);
#endif	/* DEBUG_DMA */

	/*
	 * Allocate and initialize the DMA map.  The end of the map
	 * is a variable-sized array of segments, so we allocate enough
	 * room for them in one shot.
	 *
	 * Note we don't preserve the WAITOK or NOWAIT flags.  Preservation
	 * of ALLOCNOW notifies others that we've reserved these resources,
	 * and they are not to be freed.
	 *
	 * The bus_dmamap_t includes one bus_dma_segment_t, hence
	 * the (nsegments - 1).
	 */
	mapsize = sizeof(struct vax_bus_dmamap) +
	    (sizeof(bus_dma_segment_t) * (nsegments - 1));
	if ((mapstore = malloc(mapsize, M_DEVBUF, (flags & BUS_DMA_NOWAIT) ?
	    (M_NOWAIT | M_ZERO) : (M_WAITOK | M_ZERO))) == NULL)
		return (ENOMEM);

	map = (struct vax_bus_dmamap *)mapstore;
	map->_dm_size = size;
	map->_dm_segcnt = nsegments;
	map->_dm_maxsegsz = maxsegsz;
	map->_dm_boundary = boundary;
	map->_dm_flags = flags & ~(BUS_DMA_WAITOK|BUS_DMA_NOWAIT);
	map->dm_mapsize = 0;		/* no valid mappings */
	map->dm_nsegs = 0;

	*dmamp = map;
#ifdef DEBUG_DMA
	printf("dmamap_create:map=%p\n", map);
#endif	/* DEBUG_DMA */
	return (0);
}

/*
 * Common function for DMA map destruction.  May be called by bus-specific
 * DMA map destruction functions.
 */
void
_bus_dmamap_destroy(t, map)
	bus_dma_tag_t t;
	bus_dmamap_t map;
{
	size_t mapsize;

#ifdef DEBUG_DMA
	printf("dmamap_destroy: t=%p map=%p\n", t, map);
#endif	/* DEBUG_DMA */
#ifdef DIAGNOSTIC
	if (map->dm_nsegs > 0)
		printf("bus_dmamap_destroy() called for map with valid mappings\n");
#endif	/* DIAGNOSTIC */
	mapsize = sizeof(struct vax_bus_dmamap) +
	    (sizeof(bus_dma_segment_t) * (map->_dm_segcnt - 1));
	free(map, M_DEVBUF, mapsize);
}

/*
 * Common function for loading a DMA map with a linear buffer.  May
 * be called by bus-specific DMA map load functions.
 */
int
_bus_dmamap_load(t, map, buf, buflen, p, flags)
	bus_dma_tag_t t;
	bus_dmamap_t map;
	void *buf;
	bus_size_t buflen;
	struct proc *p;
	int flags;
{
	paddr_t lastaddr;
	int seg, error;

#ifdef DEBUG_DMA
	printf("dmamap_load: t=%p map=%p buf=%p len=%lx p=%p f=%d\n",
	    t, map, buf, buflen, p, flags);
#endif	/* DEBUG_DMA */

	/*
	 * Make sure that on error condition we return "no valid mappings".
	 */
	map->dm_mapsize = 0;
	map->dm_nsegs = 0;

	if (buflen > map->_dm_size)
		return (EINVAL);

	seg = 0;
	error = _bus_dmamap_load_buffer(t, map, buf, buflen, p, flags,
	    &lastaddr, &seg, 1);
	if (error == 0) {
		map->dm_mapsize = buflen;
		map->dm_nsegs = seg + 1;
	}
#ifdef DEBUG_DMA
	printf("dmamap_load: error=%d\n", error);
#endif	/* DEBUG_DMA */
	return (error);
}

/*
 * Like _bus_dmamap_load(), but for mbufs.
 */
int
_bus_dmamap_load_mbuf(t, map, m0, flags)
	bus_dma_tag_t t;
	bus_dmamap_t map;
	struct mbuf *m0;
	int flags;
{
	paddr_t lastaddr;
	int seg, error, first;
	struct mbuf *m;

#ifdef DEBUG_DMA
	printf("dmamap_load_mbuf: t=%p map=%p m0=%p f=%d\n",
	    t, map, m0, flags);
#endif	/* DEBUG_DMA */

	/*
	 * Make sure that on error condition we return "no valid mappings."
	 */
	map->dm_mapsize = 0;
	map->dm_nsegs = 0;

#ifdef DIAGNOSTIC
	if ((m0->m_flags & M_PKTHDR) == 0)
		panic("_bus_dmamap_load_mbuf: no packet header");
#endif	/* DIAGNOSTIC */

	if (m0->m_pkthdr.len > map->_dm_size)
		return (EINVAL);

	first = 1;
	seg = 0;
	error = 0;
	for (m = m0; m != NULL && error == 0; m = m->m_next) {
		if (m->m_len == 0)
			continue;
		error = _bus_dmamap_load_buffer(t, map, m->m_data, m->m_len,
		    NULL, flags, &lastaddr, &seg, first);
		first = 0;
	}
	if (error == 0) {
		map->dm_mapsize = m0->m_pkthdr.len;
		map->dm_nsegs = seg + 1;
	}
#ifdef DEBUG_DMA
	printf("dmamap_load_mbuf: error=%d\n", error);
#endif	/* DEBUG_DMA */
	return (error);
}

/*
 * Like _bus_dmamap_load(), but for uios.
 */
int
_bus_dmamap_load_uio(t, map, uio, flags)
	bus_dma_tag_t t;
	bus_dmamap_t map;
	struct uio *uio;
	int flags;
{
	paddr_t lastaddr;
	int seg, i, error, first;
	bus_size_t minlen, resid;
	struct proc *p = NULL;
	struct iovec *iov;
	caddr_t addr;

	/*
	 * Make sure that on error condition we return "no valid mappings."
	 */
	map->dm_mapsize = 0;
	map->dm_nsegs = 0;

	resid = uio->uio_resid;
	iov = uio->uio_iov;

	if (uio->uio_segflg == UIO_USERSPACE) {
		p = uio->uio_procp;
#ifdef DIAGNOSTIC
		if (p == NULL)
			panic("_bus_dmamap_load_uio: USERSPACE but no proc");
#endif
	}

	first = 1;
	seg = 0;
	error = 0;
	for (i = 0; i < uio->uio_iovcnt && resid != 0 && error == 0; i++) {
		/*
		 * Now at the first iovec to load.  Load each iovec
		 * until we have exhausted the residual count.
		 */
		minlen = resid < iov[i].iov_len ? resid : iov[i].iov_len;
		addr = (caddr_t)iov[i].iov_base;

		error = _bus_dmamap_load_buffer(t, map, addr, minlen,
		    p, flags, &lastaddr, &seg, first);
		first = 0;

		resid -= minlen;
	}
	if (error == 0) {
		map->dm_mapsize = uio->uio_resid;
		map->dm_nsegs = seg + 1;
	}
	return (error);
}

/*
 * Like _bus_dmamap_load(), but for raw memory allocated with
 * bus_dmamem_alloc().
 */
int
_bus_dmamap_load_raw(t, map, segs, nsegs, size, flags)
	bus_dma_tag_t t;
	bus_dmamap_t map;
	bus_dma_segment_t *segs;
	int nsegs;
	bus_size_t size;
	int flags;
{

	panic("_bus_dmamap_load_raw: not implemented");
}

/*
 * Common function for unloading a DMA map.  May be called by
 * bus-specific DMA map unload functions.
 */
void
_bus_dmamap_unload(t, map)
	bus_dma_tag_t t;
	bus_dmamap_t map;
{

#ifdef DEBUG_DMA
	printf("dmamap_unload: t=%p map=%p\n", t, map);
#endif	/* DEBUG_DMA */

	/*
	 * No resources to free; just mark the mappings as
	 * invalid.
	 */
	map->dm_mapsize = 0;
	map->dm_nsegs = 0;
}

/*
 * Common function for DMA map synchronization.  May be called
 * by bus-specific DMA map synchronization functions.
 */
void
_bus_dmamap_sync(t, map, offset, len, ops)
	bus_dma_tag_t t;
	bus_dmamap_t map;
	bus_addr_t offset;
	bus_size_t len;
	int ops;
{
#ifdef DEBUG_DMA
	printf("dmamap_sync: t=%p map=%p offset=%lx len=%lx ops=%x\n",
	    t, map, offset, len, ops);
#endif	/* DEBUG_DMA */
	/*
	 * A vax only has snoop-cache, so this routine is a no-op.
	 */
	return;
}

/*
 * Common function for DMA-safe memory allocation.  May be called
 * by bus-specific DMA memory allocation functions.
 */

int
_bus_dmamem_alloc(t, size, alignment, boundary, segs, nsegs, rsegs, flags)
	bus_dma_tag_t t;
	bus_size_t size, alignment, boundary;
	bus_dma_segment_t *segs;
	int nsegs;
	int *rsegs;
	int flags;
{
	int error;

	error = _bus_dmamem_alloc_range(t, size, alignment, boundary,
	    segs, nsegs, rsegs, flags, 0, -1);
	return(error);
}

/*
 * Common function for freeing DMA-safe memory.  May be called by
 * bus-specific DMA memory free functions.
 */
void
_bus_dmamem_free(t, segs, nsegs)
	bus_dma_tag_t t;
	bus_dma_segment_t *segs;
	int nsegs;
{
	struct vm_page *m;
	bus_addr_t addr;
	struct pglist mlist;
	int curseg;

#ifdef DEBUG_DMA
	printf("dmamem_free: t=%p segs=%p nsegs=%x\n", t, segs, nsegs);
#endif	/* DEBUG_DMA */

	/*
	 * Build a list of pages to free back to the VM system.
	 */
	TAILQ_INIT(&mlist);
	for (curseg = 0; curseg < nsegs; curseg++) {
		for (addr = segs[curseg].ds_addr;
		    addr < (segs[curseg].ds_addr + segs[curseg].ds_len);
		    addr += PAGE_SIZE) {
			m = PHYS_TO_VM_PAGE(addr);
			TAILQ_INSERT_TAIL(&mlist, m, pageq);
		}
	}
	uvm_pglistfree(&mlist);
}

/*
 * Common function for mapping DMA-safe memory.  May be called by
 * bus-specific DMA memory map functions.
 */
int
_bus_dmamem_map(t, segs, nsegs, size, kvap, flags)
	bus_dma_tag_t t;
	bus_dma_segment_t *segs;
	int nsegs;
	size_t size;
	caddr_t *kvap;
	int flags;
{
	vaddr_t va, sva;
	size_t ssize;
	bus_addr_t addr;
	int curseg, error;
	const struct kmem_dyn_mode *kd;

	/*
	 * Special case (but common):
	 * If there is only one physical segment then the already-mapped
	 * virtual address is returned, since all physical memory is already
	 * in the beginning of kernel virtual memory.
	 */
	if (nsegs == 1) {
		*kvap = (caddr_t)(segs[0].ds_addr | KERNBASE);
		/*
		 * KA43 (3100/m76) must have its DMA-safe memory accessed
		 * through DIAGMEM. Remap it here.
		 */
		if (vax_boardtype == VAX_BTYP_43) {
			pmap_map((vaddr_t)*kvap, segs[0].ds_addr|KA43_DIAGMEM,
			    (segs[0].ds_addr|KA43_DIAGMEM) + size,
			    PROT_READ | PROT_WRITE);
		}
		return 0;
	}
	size = round_page(size);
	kd = flags & BUS_DMA_NOWAIT ? &kd_trylock : &kd_waitok;
	va = (vaddr_t)km_alloc(size, &kv_any, &kp_none, kd);
	if (va == 0)
		return (ENOMEM);

	*kvap = (caddr_t)va;

	sva = va;
	ssize = size;
	for (curseg = 0; curseg < nsegs; curseg++) {
		for (addr = segs[curseg].ds_addr;
		    addr < (segs[curseg].ds_addr + segs[curseg].ds_len);
		    addr += NBPG, va += NBPG, size -= NBPG) {
			if (size == 0)
				panic("_bus_dmamem_map: size botch");
			if (vax_boardtype == VAX_BTYP_43)
				addr |= KA43_DIAGMEM;
			error = pmap_enter(pmap_kernel(), va, addr,
			    PROT_READ | PROT_WRITE,
			    PROT_READ | PROT_WRITE | PMAP_WIRED | PMAP_CANFAIL);
			if (error) {
				pmap_update(pmap_kernel());
				km_free((void *)sva, ssize, &kv_any, &kp_none);
				return (error);
			}
		}
	}
	pmap_update(pmap_kernel());
	return (0);
}

/*
 * Common function for unmapping DMA-safe memory.  May be called by
 * bus-specific DMA memory unmapping functions.
 */
void
_bus_dmamem_unmap(t, kva, size)
	bus_dma_tag_t t;
	caddr_t kva;
	size_t size;
{

#ifdef DEBUG_DMA
	printf("dmamem_unmap: t=%p kva=%p size=%x\n", t, kva, size);
#endif	/* DEBUG_DMA */
#ifdef DIAGNOSTIC
	if ((u_long)kva & PGOFSET)
		panic("_bus_dmamem_unmap");
#endif	/* DIAGNOSTIC */

	/* Avoid free'ing if not mapped */
	if (kva >= (caddr_t)virtual_avail)
		km_free(kva, round_page(size), &kv_any, &kp_none);
}

/*
 * Common function for mmap(2)'ing DMA-safe memory.  May be called by
 * bus-specific DMA mmap(2)'ing functions.
 */
paddr_t
_bus_dmamem_mmap(t, segs, nsegs, off, prot, flags)
	bus_dma_tag_t t;
	bus_dma_segment_t *segs;
	int nsegs;
	off_t off;
	int prot, flags;
{
	int i;

	for (i = 0; i < nsegs; i++) {
#ifdef DIAGNOSTIC
		if (off & PGOFSET)
			panic("_bus_dmamem_mmap: offset unaligned");
		if (segs[i].ds_addr & PGOFSET)
			panic("_bus_dmamem_mmap: segment unaligned");
		if (segs[i].ds_len & PGOFSET)
			panic("_bus_dmamem_mmap: segment size not multiple"
			    " of page size");
#endif	/* DIAGNOSTIC */
		if (off >= segs[i].ds_len) {
			off -= segs[i].ds_len;
			continue;
		}

		return (segs[i].ds_addr + off);
	}

	/* Page not found. */
	return (-1);
}

/**********************************************************************
 * DMA utility functions
 **********************************************************************/

/*
 * Utility function to load a linear buffer.  lastaddrp holds state
 * between invocations (for multiple-buffer loads).  segp contains
 * the starting segment on entrance, and the ending segment on exit.
 * first indicates if this is the first invocation of this function.
 */
int
_bus_dmamap_load_buffer(t, map, buf, buflen, p, flags, lastaddrp, segp, first)
	bus_dma_tag_t t;
	bus_dmamap_t map;
	void *buf;
	bus_size_t buflen;
	struct proc *p;
	int flags;
	paddr_t *lastaddrp;
	int *segp;
	int first;
{
	bus_size_t sgsize;
	bus_addr_t curaddr, lastaddr, baddr, bmask;
	vaddr_t vaddr = (vaddr_t)buf;
	int seg;
	pmap_t pmap;

#ifdef DEBUG_DMA
	printf("_bus_dmamem_load_buffer(buf=%p, len=%lx, flags=%d, 1st=%d)\n",
	    buf, buflen, flags, first);
#endif	/* DEBUG_DMA */

	if (p != NULL)
		pmap = p->p_vmspace->vm_map.pmap;
	else
		pmap = pmap_kernel();

	lastaddr = *lastaddrp;
	bmask  = ~(map->_dm_boundary - 1);

	for (seg = *segp; buflen > 0; ) {
		/*
		 * Get the physical address for this segment.
		 */
		pmap_extract(pmap, (vaddr_t)vaddr, &curaddr);
#if 0
		/*
		 * Make sure we're in an allowed DMA range.
		 */
		if (t->_ranges != NULL &&
		    _bus_dma_inrange(t->_ranges, t->_nranges, curaddr) == 0)
			return (EINVAL);
#endif

		/*
		 * Compute the segment size, and adjust counts.
		 */
		sgsize = NBPG - ((u_long)vaddr & PGOFSET);
		if (buflen < sgsize)
			sgsize = buflen;

		/*
		 * Make sure we don't cross any boundaries.
		 */
		if (map->_dm_boundary > 0) {
			baddr = (curaddr + map->_dm_boundary) & bmask;
			if (sgsize > (baddr - curaddr))
				sgsize = (baddr - curaddr);
		}

		/*
		 * Insert chunk into a segment, coalescing with
		 * previous segment if possible.
		 */
		if (first) {
			map->dm_segs[seg].ds_addr = curaddr;
			map->dm_segs[seg].ds_len = sgsize;
			first = 0;
		} else {
			if (curaddr == lastaddr &&
			    (map->dm_segs[seg].ds_len + sgsize) <=
			     map->_dm_maxsegsz &&
			    (map->_dm_boundary == 0 ||
			     (map->dm_segs[seg].ds_addr & bmask) ==
			     (curaddr & bmask)))
				map->dm_segs[seg].ds_len += sgsize;
			else {
				if (++seg >= map->_dm_segcnt)
					break;
				map->dm_segs[seg].ds_addr = curaddr;
				map->dm_segs[seg].ds_len = sgsize;
			}
		}

		lastaddr = curaddr + sgsize;
		vaddr += sgsize;
		buflen -= sgsize;
	}

	*segp = seg;
	*lastaddrp = lastaddr;

	/*
	 * Did we fit?
	 */
	if (buflen != 0)
		return (EFBIG);		/* XXX better return value here? */
	return (0);
}

/*
 * Check to see if the specified page is in an allowed DMA range.
 */
int
_bus_dma_inrange(ranges, nranges, curaddr)
	bus_dma_segment_t *ranges;
	int nranges;
	bus_addr_t curaddr;
{
	bus_dma_segment_t *ds;
	int i;

	for (i = 0, ds = ranges; i < nranges; i++, ds++) {
		if (curaddr >= ds->ds_addr &&
		    round_page(curaddr) <= (ds->ds_addr + ds->ds_len))
			return (1);
	}

	return (0);
}

/*
 * Allocate physical memory from the given physical address range.
 * Called by DMA-safe memory allocation methods.
 */
int
_bus_dmamem_alloc_range(t, size, alignment, boundary, segs, nsegs, rsegs,
    flags, low, high)
	bus_dma_tag_t t;
	bus_size_t size, alignment, boundary;
	bus_dma_segment_t *segs;
	int nsegs;
	int *rsegs;
	int flags;
	vaddr_t low;
	vaddr_t high;
{
	paddr_t curaddr, lastaddr;
	struct vm_page *m;
	struct pglist mlist;
	int curseg, error, plaflag;

#ifdef DEBUG_DMA
	printf("alloc_range: t=%p size=%lx align=%lx boundary=%lx segs=%p nsegs=%x rsegs=%p flags=%x lo=%lx hi=%lx\n",
	    t, size, alignment, boundary, segs, nsegs, rsegs, flags, low, high);
#endif	/* DEBUG_DMA */

	/* Always round the size. */
	size = round_page(size);

	/*
	 * Allocate pages from the VM system.
	 */
	plaflag = flags & BUS_DMA_NOWAIT ? UVM_PLA_NOWAIT : UVM_PLA_WAITOK;
	if (flags & BUS_DMA_ZERO)
		plaflag |= UVM_PLA_ZERO;

	TAILQ_INIT(&mlist);
	error = uvm_pglistalloc(size, low, high, alignment, boundary,
	    &mlist, nsegs, plaflag);
	if (error)
		return (error);

	/*
	 * Compute the location, size, and number of segments actually
	 * returned by the VM code.
	 */
	m = TAILQ_FIRST(&mlist);
	curseg = 0;
	lastaddr = segs[curseg].ds_addr = VM_PAGE_TO_PHYS(m);
	segs[curseg].ds_len = PAGE_SIZE;
#ifdef DEBUG_DMA
		printf("alloc: page %lx\n", lastaddr);
#endif	/* DEBUG_DMA */
	m = TAILQ_NEXT(m, pageq);

	for (; m != NULL; m = TAILQ_NEXT(m, pageq)) {
		curaddr = VM_PAGE_TO_PHYS(m);
#ifdef DIAGNOSTIC
		if (curaddr < low || curaddr >= high) {
			printf("vm_page_alloc_memory returned non-sensical"
			    " address 0x%lx\n", curaddr);
			panic("_bus_dmamem_alloc_range");
		}
#endif	/* DIAGNOSTIC */
#ifdef DEBUG_DMA
		printf("alloc: page %lx\n", curaddr);
#endif	/* DEBUG_DMA */
		if (curaddr == (lastaddr + PAGE_SIZE))
			segs[curseg].ds_len += PAGE_SIZE;
		else {
			curseg++;
			segs[curseg].ds_addr = curaddr;
			segs[curseg].ds_len = PAGE_SIZE;
		}
		lastaddr = curaddr;
	}

	*rsegs = curseg + 1;

	return (0);
}

/*
 * "generic" DMA struct, nothing special.
 */
struct vax_bus_dma_tag vax_bus_dma_tag = {
	NULL,
	0, 
	0,
	0,
	NULL,
	_bus_dmamap_create,
	_bus_dmamap_destroy,
	_bus_dmamap_load,
	_bus_dmamap_load_mbuf,
	_bus_dmamap_load_uio,
	_bus_dmamap_load_raw,
	_bus_dmamap_unload,
	_bus_dmamap_sync,
	_bus_dmamem_alloc,
	_bus_dmamem_free,
	_bus_dmamem_map,
	_bus_dmamem_unmap,
	_bus_dmamem_mmap,
};
@


1.32
log
@Pass real sizes to free()
@
text
@d1 1
a1 1
/*	$OpenBSD: bus_dma.c,v 1.31 2014/11/16 12:30:59 deraadt Exp $	*/
@


1.31
log
@Replace a plethora of historical protection options with just
PROT_NONE, PROT_READ, PROT_WRITE, and PROT_EXEC from mman.h.
PROT_MASK is introduced as the one true way of extracting those bits.
Remove UVM_ADV_* wrapper, using the standard names.
ok doug guenther kettenis
@
text
@d1 1
a1 1
/*	$OpenBSD: bus_dma.c,v 1.30 2014/09/13 16:06:37 doug Exp $	*/
d132 1
d141 3
a143 1
	free(map, M_DEVBUF, 0);
@


1.30
log
@Replace all queue *_END macro calls except CIRCLEQ_END with NULL.

CIRCLEQ_* is deprecated and not called in the tree.  The other queue types
have *_END macros which were added for symmetry with CIRCLEQ_END.  They are
defined as NULL.  There's no reason to keep the other *_END macro calls.

ok millert@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bus_dma.c,v 1.29 2014/07/12 18:44:43 tedu Exp $	*/
d447 1
a447 1
			    VM_PROT_READ|VM_PROT_WRITE);
d470 2
a471 2
			    VM_PROT_READ | VM_PROT_WRITE, VM_PROT_READ |
			    VM_PROT_WRITE | PMAP_WIRED | PMAP_CANFAIL);
@


1.29
log
@add a size argument to free. will be used soon, but for now default to 0.
after discussions with beck deraadt kettenis.
@
text
@d1 1
a1 1
/*	$OpenBSD: bus_dma.c,v 1.28 2014/07/11 09:36:26 mpi Exp $	*/
d730 1
a730 1
	for (; m != TAILQ_END(&mlist); m = TAILQ_NEXT(m, pageq)) {
@


1.28
log
@Convert bus_dmamem_map(9) to km_alloc(9) in order to make it fail and
not sleep if the allocator cannot obtain a lock when BUS_DMA_NOWAIT is
specified.

idea and inputs from kettenis@@, ok miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bus_dma.c,v 1.27 2011/06/23 20:44:39 ariane Exp $	*/
d140 1
a140 1
	free(map, M_DEVBUF);
@


1.27
log
@Fix the error path in bus_dmamem_map.
As discussed on icb: remove the comment,
remove pmap_remove (uvm_km_free does that for us).

ok oga@@, deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bus_dma.c,v 1.26 2010/12/26 15:41:00 miod Exp $	*/
d430 1
d452 2
a453 2
	va = uvm_km_valloc(kernel_map, size);

d474 1
a474 1
				uvm_km_free(kernel_map, sva, ssize);
d504 1
a504 1
		uvm_km_free(kernel_map, (vaddr_t)kva, round_page(size));
@


1.26
log
@Kill pmap_phys_address(), and force every driver's mmap() routine to return
a physical address [more precisely, something suitable to pass to pmap_enter()'sphysical address argument].

This allows MI drivers to implement mmap() routines without having to know
about the pmap_phys_address() implementation and #ifdef obfuscation.
@
text
@d1 1
a1 1
/*	$OpenBSD: bus_dma.c,v 1.25 2010/11/20 20:33:24 miod Exp $	*/
a471 4
				/*
				 * Clean up after ourselves.
				 * XXX uvm_wait on WAITOK
				 */
d473 1
a473 1
				uvm_km_free(kernel_map, va, ssize);
@


1.25
log
@This is a first step towards getting rid of avail_start and avail_end in the
kernel, currently limited to low-hanging fruit: these variables were used
by bus_dma to specify the range in which to allocate memory, back when
uvm_pglistalloc() was stupid and would not walk the vm_physseg[].

Nowadays, except on some platforms for early initialization, these variables
are not used, or do not need to be global variables. Therefore:
- remove `extern' declarations of avail_start and avail_end (or close cousins,
  such as arm physical_start and physical_end) from files which no longer need
  to use them.
- make them local variables whenever possible.
- remove them when they are assigned to but no longer used.
@
text
@d1 1
a1 1
/*	$OpenBSD: bus_dma.c,v 1.24 2010/03/29 19:21:58 oga Exp $	*/
d539 1
a539 1
		return (atop(segs[i].ds_addr + off));
@


1.24
log
@PMAP_CANFAIL for bus_dmamem_map on all other architectures (and some
whitespace tweaks on i386 so that it matches).

ok kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bus_dma.c,v 1.23 2009/04/20 00:42:06 oga Exp $	*/
d59 1
a59 1
extern	vaddr_t avail_start, avail_end, virtual_avail;
@


1.23
log
@Add a BUS_DMA_ZERO flag for bus_dmamem_alloc() to return zeroed memory.

Saves every damned driver calling bzero(), and continues the M_ZERO,
PR_ZERO symmetry.
@
text
@d1 1
a1 1
/*	$OpenBSD: bus_dma.c,v 1.22 2009/04/14 16:01:04 oga Exp $	*/
d426 2
a427 1
	vaddr_t va;
d429 1
a429 1
	int curseg;
d458 2
d468 12
a479 3
			pmap_enter(pmap_kernel(), va, addr,
			    VM_PROT_READ | VM_PROT_WRITE,
			    VM_PROT_READ | VM_PROT_WRITE | PMAP_WIRED);
@


1.22
log
@Convert the waitok field of uvm_pglistalloc to "flags", more will be added soon.

For the possibility of sleeping, the first two flags are UVM_PLA_WAITOK
and UVM_PLA_NOWAIT. It is an error not to show intention, so assert that
one of the two is provided. Switch over every caller in the tree to
using the appropriate flag.

ok art@@, ariane@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bus_dma.c,v 1.21 2009/03/07 15:34:34 miod Exp $	*/
d699 2
@


1.21
log
@When allocating memory in bus_dmamem_alloc() with uvm_pglistalloc(), do not
try to be smart for the address range, uvm_pglistalloc() is smart enough
nowadays.
@
text
@d1 1
a1 1
/*	$OpenBSD: bus_dma.c,v 1.20 2008/08/15 22:40:00 miod Exp $	*/
d685 1
a685 1
	int curseg, error;
d698 2
d702 1
a702 1
	    &mlist, nsegs, (flags & BUS_DMA_NOWAIT) == 0);
@


1.20
log
@Remove unused and incomplete vax_bus_t enum, and unused vaxbus_dma_get_tag()
macro and related function pointers.
@
text
@d1 1
a1 1
/*	$OpenBSD: bus_dma.c,v 1.19 2008/06/26 05:42:14 ray Exp $	*/
d374 2
a375 3
	error =  (_bus_dmamem_alloc_range(t, size, alignment, boundary,
	    segs, nsegs, rsegs, flags, round_page(avail_start),
	    trunc_page(avail_end)));
@


1.19
log
@First pass at removing clauses 3 and 4 from NetBSD licenses.

Not sure what's more surprising: how long it took for NetBSD to
catch up to the rest of the BSDs (including UCB), or the amount of
code that NetBSD has claimed for itself without attributing to the
actual authors.

OK deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bus_dma.c,v 1.18 2007/10/02 00:59:12 krw Exp $	*/
d753 1
a753 2
	0,
	0,
@


1.18
log
@Apply (with slight variants) this elimination of bzero() with M_ZERO:

-	if ((mapstore = malloc(mapsize, M_DEVBUF,
-	    (flags & BUS_DMA_NOWAIT) ? M_NOWAIT : M_WAITOK)) == NULL)
+	if ((mapstore = malloc(mapsize, M_DEVBUF, (flags & BUS_DMA_NOWAIT) ?
+	    (M_NOWAIT | M_ZERO) : (M_WAITOK | M_ZERO))) == NULL)
 		return (ENOMEM);

-	bzero(mapstore, mapsize);
@
text
@d1 1
a1 1
/*	$OpenBSD: bus_dma.c,v 1.17 2007/09/03 01:09:09 krw Exp $	*/
a19 7
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *	This product includes software developed by the NetBSD
 *	Foundation, Inc. and its contributors.
 * 4. Neither the name of The NetBSD Foundation nor the names of its
 *    contributors may be used to endorse or promote products derived
 *    from this software without specific prior written permission.
@


1.17
log
@Typos from miod. 'functin' -> 'functin' in some comments.
@
text
@d1 1
a1 1
/*	$OpenBSD: bus_dma.c,v 1.16 2005/11/08 15:05:56 martin Exp $	*/
d110 2
a111 2
	if ((mapstore = malloc(mapsize, M_DEVBUF,
	    (flags & BUS_DMA_NOWAIT) ? M_NOWAIT : M_WAITOK)) == NULL)
a113 1
	bzero(mapstore, mapsize);
@


1.16
log
@use atop()
@
text
@d1 1
a1 1
/*	$OpenBSD: bus_dma.c,v 1.15 2005/11/06 22:21:33 miod Exp $	*/
d508 1
a508 1
 * Common functin for mmap(2)'ing DMA-safe memory.  May be called by
@


1.15
log
@Kill deprecated vm_offset_t and vm_size_t types on vax.
@
text
@d1 1
a1 1
/*	$OpenBSD: bus_dma.c,v 1.14 2004/12/25 23:02:26 miod Exp $	*/
d536 1
a536 1
		return (btop((u_long)segs[i].ds_addr + off));
@


1.14
log
@Use list and queue macros where applicable to make the code easier to read;
no functional change.
@
text
@d1 1
a1 1
/*	$OpenBSD: bus_dma.c,v 1.13 2004/11/09 19:17:01 claudio Exp $	*/
d69 1
a69 1
	    bus_size_t, struct proc *, int, vm_offset_t *, int *, int);
d164 1
a164 1
	vm_offset_t lastaddr;
d204 1
a204 1
	vm_offset_t lastaddr;
d257 1
a257 1
	vm_offset_t lastaddr;
d435 1
a435 1
	vm_offset_t va;
d504 1
a504 1
		uvm_km_free(kernel_map, (vm_offset_t)kva, round_page(size));
d550 1
a550 1
 * the starting segment on entrace, and the ending segment on exit.
d561 1
a561 1
	vm_offset_t *lastaddrp;
d567 1
a567 1
	vm_offset_t vaddr = (vm_offset_t)buf;
d688 2
a689 2
	vm_offset_t low;
	vm_offset_t high;
d691 1
a691 1
	vm_offset_t curaddr, lastaddr;
@


1.13
log
@Do not map empty mbufs (m_len == 0) in bus_dmamap_load_mbuf() as these mappings
may disturb the dma as seen in ipw(4). Emtpy mbufs are at the beginning of the
mbuf chain and are as example a "side-effect" of a previous m_adj() call.
OK miod@@ mickey@@ jason@@ markus@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bus_dma.c,v 1.12 2002/10/07 18:35:57 mickey Exp $	*/
d717 1
a717 1
	m = mlist.tqh_first;
d724 1
a724 1
	m = m->pageq.tqe_next;
d726 1
a726 1
	for (; m != NULL; m = m->pageq.tqe_next) {
@


1.12
log
@this removes the functionality of adding allocated
pages into the queue already containing allocated pages.
breaks i386:setup_buffers() because of this.
@
text
@d1 1
a1 1
/*	$OpenBSD: bus_dma.c,v 1.11 2002/10/06 22:06:15 art Exp $	*/
d231 2
@


1.11
log
@No more need to initialize the result list before uvm_pglistalloc.
@
text
@d1 1
a1 1
/*	$OpenBSD: bus_dma.c,v 1.10 2002/03/14 01:26:48 millert Exp $	*/
d705 1
@


1.10
log
@First round of __P removal in sys
@
text
@d1 1
a1 1
/*	$OpenBSD: bus_dma.c,v 1.9 2002/01/16 20:50:17 miod Exp $	*/
a704 1
	TAILQ_INIT(&mlist);
@


1.9
log
@Don't include <sys/map.h> when you don't need what's in it.
@
text
@d1 1
a1 1
/*	$OpenBSD: bus_dma.c,v 1.8 2001/12/08 02:24:07 art Exp $	*/
d68 5
a72 5
int	_bus_dmamap_load_buffer __P((bus_dma_tag_t, bus_dmamap_t, void *,
	    bus_size_t, struct proc *, int, vm_offset_t *, int *, int));
int	_bus_dma_inrange __P((bus_dma_segment_t *, int, bus_addr_t));
int	_bus_dmamem_alloc_range __P((bus_dma_tag_t, bus_size_t, bus_size_t,
	    bus_size_t, bus_dma_segment_t*, int, int *, int, vaddr_t, vaddr_t));
@


1.8
log
@Sprinkle pmap_update calls where relevant and some other
misc pmap usage fixes.
@
text
@d1 1
a1 1
/*	$OpenBSD: bus_dma.c,v 1.7 2001/11/28 16:24:26 art Exp $	*/
a47 1
#include <sys/map.h>
@


1.8.2.1
log
@Merge in -current, builds on i386, otherwise untested
@
text
@d1 1
a1 1
/*	$OpenBSD: bus_dma.c,v 1.9 2002/01/16 20:50:17 miod Exp $	*/
d48 1
@


1.8.2.2
log
@Sync UBC branch to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: bus_dma.c,v 1.8.2.1 2002/01/31 22:55:27 niklas Exp $	*/
d68 5
a72 5
int	_bus_dmamap_load_buffer(bus_dma_tag_t, bus_dmamap_t, void *,
	    bus_size_t, struct proc *, int, vm_offset_t *, int *, int);
int	_bus_dma_inrange(bus_dma_segment_t *, int, bus_addr_t);
int	_bus_dmamem_alloc_range(bus_dma_tag_t, bus_size_t, bus_size_t,
	    bus_size_t, bus_dma_segment_t*, int, int *, int, vaddr_t, vaddr_t);
@


1.8.2.3
log
@sync to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: bus_dma.c,v 1.8.2.2 2002/06/11 03:39:19 art Exp $	*/
@


1.7
log
@more typedef zapping vm_page_t -> struct vm_page *
@
text
@d1 1
a1 1
/*	$OpenBSD: bus_dma.c,v 1.6 2001/11/06 02:49:23 art Exp $	*/
d478 1
@


1.6
log
@remove the last uses of vm/vm_page.h
@
text
@d1 1
a1 1
/*	$OpenBSD: bus_dma.c,v 1.5 2001/09/19 20:50:57 mickey Exp $	*/
d397 1
a397 1
	vm_page_t m;
d690 1
a690 1
	vm_page_t m;
@


1.5
log
@merge vm/vm_kern.h into uvm/uvm_extern.h; art@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: bus_dma.c,v 1.4 2001/08/02 21:30:30 hugh Exp $	*/
a57 3

#include <vm/vm.h>
#include <vm/vm_page.h>
@


1.4
log
@match updated prototype
@
text
@d1 1
a1 1
/*	$OpenBSD: bus_dma.c,v 1.3 2001/07/25 13:25:33 art Exp $	*/
a59 1
#include <vm/vm_kern.h>
@


1.3
log
@Change the pmap_enter interface to merge access_type and the wired boolean
and arbitrary flags into one argument.

One new flag is PMAP_CANFAIL that tells pmap_enter that it can fail if there
are not enough resources to satisfy the request. If this flag is not passed,
pmap_enter should panic as it should have done before this change (XXX - many
pmaps are still not doing that).

Only i386 and alpha implement CANFAIL for now.

Includes uvm updates from NetBSD.
@
text
@d1 1
a1 1
/*	$OpenBSD: bus_dma.c,v 1.2 2001/06/08 08:09:31 art Exp $	*/
d513 1
a513 1
int
d517 3
a519 1
	int nsegs, off, prot, flags;
@


1.2
log
@Change the paddr_t pmap_extract(struct pmap *, vaddr_t) interface to
boolean_t pmap_extract(struct pmap *, vaddr_t, paddr_t *).
Matches NetBSD. Tested by various people on various platforms.
@
text
@d1 1
a1 1
/*	$OpenBSD: bus_dma.c,v 1.1 2000/04/27 01:10:10 bjc Exp $	*/
d478 2
a479 2
			    VM_PROT_READ | VM_PROT_WRITE, TRUE,
			    VM_PROT_READ | VM_PROT_WRITE);
@


1.1
log
@sync with netbsd of early april; some archs still untested
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d588 1
a588 2
		curaddr = pmap_extract(pmap, (vaddr_t)vaddr);

@


1.1.8.1
log
@Continue the aborted merge of current just before 2.9 was cut into the
SMP branch.  Note that this will not make any progress of SMP functionality,
it is just merging of new code from the trunk into the old branch.
Please do not ask me questions about SMP status because of this mail,
instead go read the archives of smp@@openbsd.org, where I mailed about
these commits some week ago.  Another note: I am doing this in chunks now,
so as to not lock too much of the tree for long times
@
text
@d1 1
a1 1
/*	$OpenBSD: bus_dma.c,v 1.1 2000/04/27 01:10:10 bjc Exp $	*/
@


1.1.8.2
log
@Merge in -current from two days ago in the SMP branch.
As usual with merges, they do not indicate progress, so do not hold
your breath for working SMP, and do not mail me and ask about the
state of it.  It has not changed.  There is work ongoing, but very, very
slowly.  The commit is done in parts as to not lock up the tree in too
big chunks at a time.
@
text
@d1 1
a1 1
/*	$OpenBSD: bus_dma.c,v 1.1.8.1 2001/05/14 21:38:42 niklas Exp $	*/
d588 2
a589 1
		pmap_extract(pmap, (vaddr_t)vaddr, &curaddr);
@


1.1.8.3
log
@Sync the SMP branch to something just after 3.0
@
text
@d1 1
a1 1
/*	$OpenBSD: bus_dma.c,v 1.1.8.2 2001/07/04 10:24:33 niklas Exp $	*/
d60 1
d478 2
a479 2
			    VM_PROT_READ | VM_PROT_WRITE,
			    VM_PROT_READ | VM_PROT_WRITE | PMAP_WIRED);
d513 1
a513 1
paddr_t
d517 1
a517 3
	int nsegs;
	off_t off;
	int prot, flags;
@


1.1.8.4
log
@Merge in -current
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d58 3
@


1.1.8.5
log
@Merge in trunk
@
text
@d48 1
a477 1
	pmap_update(pmap_kernel());
@


1.1.8.6
log
@Merge in -current from about a week ago
@
text
@d68 5
a72 5
int	_bus_dmamap_load_buffer(bus_dma_tag_t, bus_dmamap_t, void *,
	    bus_size_t, struct proc *, int, vm_offset_t *, int *, int);
int	_bus_dma_inrange(bus_dma_segment_t *, int, bus_addr_t);
int	_bus_dmamem_alloc_range(bus_dma_tag_t, bus_size_t, bus_size_t,
	    bus_size_t, bus_dma_segment_t*, int, int *, int, vaddr_t, vaddr_t);
@


1.1.8.7
log
@manually merge stuff cvs missed long ago
@
text
@d1 1
a1 1
/*	$OpenBSD: bus_dma.c,v 1.10 2002/03/14 01:26:48 millert Exp $	*/
d396 1
a396 1
	struct vm_page *m;
d690 1
a690 1
	struct vm_page *m;
@


