head	1.23;
access;
symbols
	OPENBSD_5_9:1.22.0.6
	OPENBSD_5_9_BASE:1.22
	OPENBSD_5_8:1.22.0.8
	OPENBSD_5_8_BASE:1.22
	OPENBSD_5_7:1.22.0.2
	OPENBSD_5_7_BASE:1.22
	OPENBSD_5_6:1.22.0.4
	OPENBSD_5_6_BASE:1.22
	OPENBSD_5_5:1.20.0.6
	OPENBSD_5_5_BASE:1.20
	OPENBSD_5_4:1.20.0.2
	OPENBSD_5_4_BASE:1.20
	OPENBSD_5_3:1.18.0.2
	OPENBSD_5_3_BASE:1.18
	OPENBSD_5_2:1.17.0.6
	OPENBSD_5_2_BASE:1.17
	OPENBSD_5_1_BASE:1.17
	OPENBSD_5_1:1.17.0.4
	OPENBSD_5_0:1.17.0.2
	OPENBSD_5_0_BASE:1.17
	OPENBSD_4_9:1.16.0.6
	OPENBSD_4_9_BASE:1.16
	OPENBSD_4_8:1.16.0.4
	OPENBSD_4_8_BASE:1.16
	OPENBSD_4_7:1.16.0.2
	OPENBSD_4_7_BASE:1.16
	OPENBSD_4_6:1.15.0.10
	OPENBSD_4_6_BASE:1.15
	OPENBSD_4_5:1.15.0.6
	OPENBSD_4_5_BASE:1.15
	OPENBSD_4_4:1.15.0.4
	OPENBSD_4_4_BASE:1.15
	OPENBSD_4_3:1.15.0.2
	OPENBSD_4_3_BASE:1.15
	OPENBSD_4_2:1.14.0.4
	OPENBSD_4_2_BASE:1.14
	OPENBSD_4_1:1.14.0.2
	OPENBSD_4_1_BASE:1.14
	OPENBSD_4_0:1.13.0.4
	OPENBSD_4_0_BASE:1.13
	OPENBSD_3_9:1.13.0.2
	OPENBSD_3_9_BASE:1.13
	OPENBSD_3_8:1.12.0.10
	OPENBSD_3_8_BASE:1.12
	OPENBSD_3_7:1.12.0.8
	OPENBSD_3_7_BASE:1.12
	OPENBSD_3_6:1.12.0.6
	OPENBSD_3_6_BASE:1.12
	SMP_SYNC_A:1.12
	SMP_SYNC_B:1.12
	OPENBSD_3_5:1.12.0.4
	OPENBSD_3_5_BASE:1.12
	OPENBSD_3_4:1.12.0.2
	OPENBSD_3_4_BASE:1.12
	UBC_SYNC_A:1.11
	OPENBSD_3_3:1.11.0.4
	OPENBSD_3_3_BASE:1.11
	OPENBSD_3_2:1.11.0.2
	OPENBSD_3_2_BASE:1.11
	OPENBSD_3_1:1.9.0.2
	OPENBSD_3_1_BASE:1.9
	UBC_SYNC_B:1.11
	UBC:1.8.0.10
	UBC_BASE:1.8
	OPENBSD_3_0:1.8.0.8
	OPENBSD_3_0_BASE:1.8
	OPENBSD_2_9_BASE:1.8
	OPENBSD_2_9:1.8.0.6
	OPENBSD_2_8:1.8.0.4
	OPENBSD_2_8_BASE:1.8
	OPENBSD_2_7:1.8.0.2
	OPENBSD_2_7_BASE:1.8
	SMP:1.7.0.12
	SMP_BASE:1.7
	kame_19991208:1.7
	OPENBSD_2_6:1.7.0.10
	OPENBSD_2_6_BASE:1.7
	OPENBSD_2_5:1.7.0.8
	OPENBSD_2_5_BASE:1.7
	OPENBSD_2_4:1.7.0.6
	OPENBSD_2_4_BASE:1.7
	OPENBSD_2_3:1.7.0.4
	OPENBSD_2_3_BASE:1.7
	OPENBSD_2_2:1.7.0.2
	OPENBSD_2_2_BASE:1.7
	OPENBSD_2_1:1.5.0.2
	OPENBSD_2_1_BASE:1.5
	OPENBSD_2_0:1.4.0.2
	OPENBSD_2_0_BASE:1.4
	netbsd_1_1:1.1.1.1;
locks; strict;
comment	@ * @;


1.23
date	2016.03.09.16.28.48;	author deraadt;	state dead;
branches;
next	1.22;
commitid	OSDG2O3Cgeifnf1W;

1.22
date	2014.03.29.18.09.30;	author guenther;	state Exp;
branches;
next	1.21;

1.21
date	2014.03.11.19.45.27;	author guenther;	state Exp;
branches;
next	1.20;

1.20
date	2013.07.05.21.10.50;	author miod;	state Exp;
branches;
next	1.19;

1.19
date	2013.03.23.16.12.28;	author deraadt;	state Exp;
branches;
next	1.18;

1.18
date	2012.11.25.22.35.19;	author miod;	state Exp;
branches;
next	1.17;

1.17
date	2011.03.23.16.54.37;	author pirofti;	state Exp;
branches;
next	1.16;

1.16
date	2009.08.19.19.47.51;	author miod;	state Exp;
branches;
next	1.15;

1.15
date	2007.10.10.15.53.53;	author art;	state Exp;
branches;
next	1.14;

1.14
date	2006.11.06.21.31.36;	author miod;	state Exp;
branches;
next	1.13;

1.13
date	2006.02.22.22.16.07;	author miod;	state Exp;
branches;
next	1.12;

1.12
date	2003.08.01.02.23.45;	author avsm;	state Exp;
branches;
next	1.11;

1.11
date	2002.08.09.20.26.45;	author jsyn;	state Exp;
branches;
next	1.10;

1.10
date	2002.06.11.09.36.24;	author hugh;	state Exp;
branches;
next	1.9;

1.9
date	2002.03.14.01.26.48;	author millert;	state Exp;
branches;
next	1.8;

1.8
date	2000.04.26.03.08.41;	author bjc;	state Exp;
branches
	1.8.10.1;
next	1.7;

1.7
date	97.09.10.11.47.08;	author maja;	state Exp;
branches
	1.7.12.1;
next	1.6;

1.6
date	97.05.29.00.04.44;	author niklas;	state Exp;
branches;
next	1.5;

1.5
date	97.01.15.23.24.41;	author maja;	state Exp;
branches;
next	1.4;

1.4
date	96.05.03.09.09.40;	author mickey;	state Exp;
branches;
next	1.3;

1.3
date	95.12.14.13.59.55;	author deraadt;	state Exp;
branches;
next	1.2;

1.2
date	95.10.26.01.16.42;	author deraadt;	state Exp;
branches;
next	1.1;

1.1
date	95.10.18.08.52.06;	author deraadt;	state Exp;
branches
	1.1.1.1;
next	;

1.1.1.1
date	95.10.18.08.52.06;	author deraadt;	state Exp;
branches;
next	;

1.7.12.1
date	2001.05.14.21.38.02;	author niklas;	state Exp;
branches;
next	1.7.12.2;

1.7.12.2
date	2002.03.28.11.26.46;	author niklas;	state Exp;
branches;
next	1.7.12.3;

1.7.12.3
date	2003.03.27.23.52.19;	author niklas;	state Exp;
branches;
next	1.7.12.4;

1.7.12.4
date	2004.02.19.10.50.02;	author niklas;	state Exp;
branches;
next	;

1.8.10.1
date	2002.06.11.03.39.19;	author art;	state Exp;
branches;
next	1.8.10.2;

1.8.10.2
date	2002.10.29.00.28.13;	author art;	state Exp;
branches;
next	;


desc
@@


1.23
log
@We are done providing support for the vax.
lots of agreement.
@
text
@/*	$OpenBSD: macros.h,v 1.22 2014/03/29 18:09:30 guenther Exp $ */
/*	$NetBSD: macros.h,v 1.20 2000/07/19 01:02:52 matt Exp $	*/

/*
 * Copyright (c) 1994, 1998, 2000 Ludd, University of Lule}, Sweden.
 * All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *     This product includes software developed at Ludd, University of Lule}.
 * 4. The name of the author may not be used to endorse or promote products
 *    derived from this software without specific prior written permission
 *
 * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR
 * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
 * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
 * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,
 * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
 * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
 * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
 * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF
 * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

 /* All bugs are subject to removal without further notice */

#ifndef _MACHINE_MACROS_H_
#define _MACHINE_MACROS_H_

/* Here general macros are supposed to be stored */

static __inline__ int
ffs(int reg)
{
	register int val;

	__asm__ volatile ("ffs	$0,$32,%1,%0;"
		"	bneq	1f;"
		"	mnegl	$1,%0;"
		"1:	incl	%0"
			: "=&r" (val)
			: "r" (reg) );
	return	val;
}

static __inline__ size_t
strlen(const char *cp)
{
	register size_t ret;

	__asm__ volatile("locc $0,$65535,(%1);subl3 %%r0,$65535,%0"
			: "=r" (ret)
			: "r" (cp)
			: "r0","r1","cc" );
	return	ret;
}

#if 0
static __inline__ char *
strncat(char *cp, const char *c2, size_t count)
{
	__asm__ volatile("locc $0,%2,(%1);subl3 %%r0,%2,%%r2;"
			   "locc $0,$65535,(%0);movc3 %%r2,(%1),(%%r1);"
			   "movb $0,(%%r3)"
			:
			: "r" (cp), "r" (c2), "g"(count)
			: "r0","r1","r2","r3","r4","r5","memory","cc");
	return	cp;
}
#endif

static __inline__ char *
strncpy(char *cp, const char *c2, size_t len)
{
	__asm__ volatile("movl %2,%%r2;locc $0,%%r2,(%1);beql 1f;"
			   "subl3 %%r0,%2,%%r2;clrb (%0)[%%r2];1:"
			   "movc3 %%r2,(%1),(%0)"
			:
			: "r" (cp), "r" (c2), "g"(len)
			: "r0","r1","r2","r3","r4","r5","memory","cc");
	return	cp;
}

static __inline__ void *
memchr(const void *cp, int c, size_t len)
{
	void *ret;
	__asm__ volatile("locc %2,%3,(%1);bneq 1f;clrl %%r1;1:movl %%r1,%0"
			: "=g"(ret)
			: "r" (cp), "r" (c), "g"(len)
			: "r0","r1","cc");
	return	ret;
}

static __inline__ int
strcmp(const char *cp, const char *c2)
{
	register int ret;
	__asm__ volatile("locc $0,$65535,(%1);subl3 %%r0,$65535,%%r0;"
			   "incl %%r0;cmpc3 %%r0,(%1),(%2);beql 1f;"
			   "movl $1,%%r2;cmpb (%%r1),(%%r3);bcc 1f;"
			   "movl $-1,%%r2;1:movl %%r2,%0"
			: "=g"(ret)
			: "r" (cp), "r" (c2)
			: "r0","r1","r2","r3","cc");
	return	ret;
}
/* End nya */

#if 0 /* unused, but no point in deleting it since it _is_ an instruction */
static __inline__ int
locc(int mask, char *cp, size_t size)
{
	register ret;

	__asm__ volatile("locc %1,%2,(%3);movl %%r0,%0"
			: "=r" (ret)
			: "r" (mask),"r"(size),"r"(cp)
			: "r0","r1" );
	return	ret;
}
#endif

static __inline__ int
scanc(u_int size, const u_char *cp, const u_char *table, int mask)
{
	register int ret;

	__asm__ volatile("scanc %1,(%2),(%3),%4;movl %%r0,%0"
			: "=g"(ret)
			: "r"(size),"r"(cp),"r"(table),"r"(mask)
			: "r0","r1","r2","r3" );
	return ret;
}

static __inline__ int
skpc(int mask, size_t size, u_char *cp)
{
	register int ret;

	__asm__ volatile("skpc %1,%2,(%3);movl %%r0,%0"
			: "=g"(ret)
			: "r"(mask),"r"(size),"r"(cp)
			: "r0","r1" );
	return	ret;
}

#define	cpu_switchto(o, n) \
	__asm__ volatile( \
	    "movl %0, %%r0; movl %1, %%r1; movpsl -(%%sp); jsb __cpu_switchto" \
	    :: "g"(o), "g"(n) : "r0", "r1");

/*
 * Interlock instructions. Used both in multiprocessor environments to
 * lock between CPUs and in uniprocessor systems when locking is required
 * between I/O devices and the master CPU.
 */
/*
 * Insqti() locks and inserts an element into the end of a queue.
 * Returns -1 if interlock failed, 1 if inserted OK and 0 if first in queue.
 */
static __inline__ int
insqti(void *entry, void *header) {
	register int ret;

	__asm__ volatile(
		"	mnegl $1,%0;"
		"	insqti (%1),(%2);"
		"	bcs 1f;			# failed insert"
		"	beql 2f;		# jump if first entry"
		"	movl $1,%0;"
		"	brb 1f;"
		"2:	clrl %0;"
		"	1:;"
			: "=&g"(ret)
			: "r"(entry), "r"(header)
			: "memory");

	return ret;
}

/*
 * Remqhi() removes an element from the head of the queue.
 * Returns -1 if interlock failed, 0 if queue empty, address of the 
 * removed element otherwise.
 */
static __inline__ void *
remqhi(void *header) {
	register void *ret;

	__asm__ volatile(
		"	remqhi (%1),%0;"
		"	bcs 1f;			# failed interlock"
		"	bvs 2f;			# nothing was removed"
		"	brb 3f;"
		"1:	mnegl $1,%0;"
		"	brb 3f;"
		"2:	clrl %0;"
		"	3:;"
			: "=&g"(ret)
			: "r"(header)
			: "memory");

	return ret;
}
#define	ILCK_FAILED	-1	/* Interlock failed */
#define	Q_EMPTY		0	/* Queue is/was empty */
#define	Q_OK		1	/* Inserted OK */

#endif	/* _MACHINE_MACROS_H_ */
@


1.22
log
@It's been a quarter century: we can assume volatile is present with that name.

ok dlg@@ mpi@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: macros.h,v 1.21 2014/03/11 19:45:27 guenther Exp $ */
@


1.21
log
@lint is gone, and the 'lint' conditional was never in the implementation
namespace, so stop changing behavior when it's #defined

ok beck@@ krw@@
@
text
@d1 1
a1 1
/*	$OpenBSD: macros.h,v 1.20 2013/07/05 21:10:50 miod Exp $ */
d46 1
a46 1
	__asm__ __volatile ("ffs	$0,$32,%1,%0;"
d60 1
a60 1
	__asm__ __volatile("locc $0,$65535,(%1);subl3 %%r0,$65535,%0"
d71 1
a71 1
	__asm__ __volatile("locc $0,%2,(%1);subl3 %%r0,%2,%%r2;"
d84 1
a84 1
	__asm__ __volatile("movl %2,%%r2;locc $0,%%r2,(%1);beql 1f;"
d97 1
a97 1
	__asm__ __volatile("locc %2,%3,(%1);bneq 1f;clrl %%r1;1:movl %%r1,%0"
d108 1
a108 1
	__asm__ __volatile("locc $0,$65535,(%1);subl3 %%r0,$65535,%%r0;"
d125 1
a125 1
	__asm__ __volatile("locc %1,%2,(%3);movl %%r0,%0"
d138 1
a138 1
	__asm__ __volatile("scanc %1,(%2),(%3),%4;movl %%r0,%0"
d150 1
a150 1
	__asm__ __volatile("skpc %1,%2,(%3);movl %%r0,%0"
d158 1
a158 1
	__asm__ __volatile__( \
d175 1
a175 1
	__asm__ __volatile(
d200 1
a200 1
	__asm__ __volatile(
@


1.20
log
@VAX ELF userland bits. Consists mostly of register prefix additions.
@
text
@d1 1
a1 1
/*	$OpenBSD: macros.h,v 1.19 2013/03/23 16:12:28 deraadt Exp $ */
d36 1
a36 1
#if !defined(_MACHINE_MACROS_H_) && !defined(lint)
@


1.19
log
@refactor sys/param.h and machine/param.h.  A lot of #ifdef _KERNEL is added
to keep definitions our of user space.  The MD files now follow a consistant
order -- all namespace intrusion is at the tail can be cleaned up
independently.  locore, bootblocks, and libkvm still see enough visibility to
build.  Checked on 90% of platforms...
@
text
@d1 1
a1 1
/*	$OpenBSD: macros.h,v 1.18 2012/11/25 22:35:19 miod Exp $ */
d58 1
a58 1
        register size_t ret;
d60 5
a64 5
        __asm__ __volatile("locc $0,$65535,(%1);subl3 r0,$65535,%0"
                        : "=r" (ret)
                        : "r" (cp)
                        : "r0","r1","cc" );
        return  ret;
d71 7
a77 6
        __asm__ __volatile("locc $0,%2,(%1);subl3 r0,%2,r2;"
                           "locc $0,$65535,(%0);movc3 r2,(%1),(r1);movb $0,(r3)"
                        :
                        : "r" (cp), "r" (c2), "g"(count)
                        : "r0","r1","r2","r3","r4","r5","memory","cc");
        return  cp;
d84 7
a90 6
        __asm__ __volatile("movl %2,r2;locc $0,r2,(%1);beql 1f;subl3 r0,%2,r2;"
                           "clrb (%0)[r2];1:;movc3 r2,(%1),(%0)"
                        :
                        : "r" (cp), "r" (c2), "g"(len)
                        : "r0","r1","r2","r3","r4","r5","memory","cc");
        return  cp;
d96 6
a101 6
        void *ret;
        __asm__ __volatile("locc %2,%3,(%1);bneq 1f;clrl r1;1:movl r1,%0"
                        : "=g"(ret)
                        : "r" (cp), "r" (c), "g"(len)
                        : "r0","r1","cc");
        return  ret;
d107 9
a115 8
        register int ret;
        __asm__ __volatile("locc $0,$65535,(%1);subl3 r0,$65535,r0;incl r0;"
                           "cmpc3 r0,(%1),(%2);beql 1f;movl $1,r2;"
                           "cmpb (r1),(r3);bcc 1f;movl $-1,r2;1:movl r2,%0"
                        : "=g"(ret)
                        : "r" (cp), "r" (c2)
                        : "r0","r1","r2","r3","cc");
        return  ret;
d120 3
a122 1
static __inline__ int locc(int mask, char *cp, size_t size){
d125 1
a125 1
	__asm__ __volatile("locc %1,%2,(%3);movl r0,%0"
d138 1
a138 1
	__asm__ __volatile("scanc	%1,(%2),(%3),%4;movl r0,%0"
d150 1
a150 1
	__asm__ __volatile("skpc %1,%2,(%3);movl r0,%0"
d159 1
a159 1
	    "movl %0,r0; movl %1, r1; movpsl -(sp); jsb __cpu_switchto" \
@


1.18
log
@Avoid using multiline litterals in __asm__ statement, gcc3 complains about
them.
@
text
@d1 1
a1 1
/*	$OpenBSD: macros.h,v 1.17 2011/03/23 16:54:37 pirofti Exp $ */
d67 1
d78 1
@


1.17
log
@Normalize sentinel. Use _MACHINE_*_H_ and _<ARCH>_*_H_ properly and consitently.

Discussed and okay drahn@@. Okay deraadt@@.
@
text
@d1 1
a1 1
/*	$OpenBSD: macros.h,v 1.16 2009/08/19 19:47:51 miod Exp $ */
d46 4
a49 4
	__asm__ __volatile ("ffs	$0,$32,%1,%0
			bneq	1f
			mnegl	$1,%0
		1:	incl	%0"
d70 2
a71 2
        __asm__ __volatile("locc $0,%2,(%1);subl3 r0,%2,r2;
                            locc $0,$65535,(%0);movc3 r2,(%1),(r1);movb $0,(r3)"
d81 2
a82 2
        __asm__ __volatile("movl %2,r2;locc $0,r2,(%1);beql 1f;subl3 r0,%2,r2;
                            clrb (%0)[r2];1:;movc3 r2,(%1),(%0)"
d104 3
a106 3
        __asm__ __volatile("locc $0,$65535,(%1);subl3 r0,$65535,r0;incl r0;
                            cmpc3 r0,(%1),(%2);beql 1f;movl $1,r2;
                            cmpb (r1),(r3);bcc 1f;movl $-1,r2;1:movl r2,%0"
d168 9
a176 9
	__asm__ __volatile("
			mnegl $1,%0;
			insqti (%1),(%2);
			bcs 1f;			# failed insert
			beql 2f;		# jump if first entry
			movl $1,%0;
			brb 1f;
		2:	clrl %0;
			1:;"
d193 9
a201 9
	__asm__ __volatile("
			remqhi (%1),%0;
			bcs 1f;			# failed interlock
			bvs 2f;			# nothing was removed
			brb 3f;
		1:	mnegl $1,%0;
			brb 3f;
		2:	clrl %0;
			3:;"
@


1.16
log
@<machine/macros.h> would provide inline version of a few of the functions
traditionnaly found in libkern. However, the memcmp() flavour would behave
as bcmp() with only two possible return values: zero and positive non-zero.

This broke the name cache RB trees which now rely upon proper memcmp()
semantics(negative value, zero, or positive value).

Just give up on these macros and provide the same code as libc, in libkern.
As a side effect, this no longer uses the cmpc3 instruction, which is not
implemented and requires (slow) kernel emulation, on the original uVax.
@
text
@d1 1
a1 1
/*	$OpenBSD: macros.h,v 1.15 2007/10/10 15:53:53 art Exp $ */
d36 2
a37 2
#if !defined(_VAX_MACROS_H_) && !defined(lint)
#define _VAX_MACROS_H_
d212 1
a212 1
#endif	/* _VAX_MACROS_H_ */
@


1.15
log
@Make context switching much more MI:
 - Move the functionality of choosing a process from cpu_switch into
   a much simpler function: cpu_switchto. Instead of having the locore
   code walk the run queues, let the MI code choose the process we
   want to run and only implement the context switching itself in MD
   code.
 - Let MD context switching run without worrying about spls or locks.
 - Instead of having the idle loop implemented with special contexts
   in MD code, implement one idle proc for each cpu. make the idle
   loop MI with MD hooks.
 - Change the proc lists from the old style vax queues to TAILQs.
 - Change the sleep queue from vax queues to TAILQs. This makes
   wakeup() go from O(n^2) to O(n)

there will be some MD fallout, but it will be fixed shortly.
There's also a few cleanups to be done after this.

deraadt@@, kettenis@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: macros.h,v 1.14 2006/11/06 21:31:36 miod Exp $ */
a54 85
static __inline__ void *
memcpy(void *toe, const void *from, size_t len)
{
	__asm__ __volatile ("movc3 %0,(%1),(%2)"
			:
			: "r" (len),"r" (from),"r"(toe)
			:"r0","r1","r2","r3","r4","r5","memory","cc");
	return toe;
}
static __inline__ void *
memmove(void *toe, const void *from, size_t len)
{
	__asm__ __volatile ("movc3 %0,(%1),(%2)"
			:
			: "r" (len),"r" (from),"r"(toe)
			:"r0","r1","r2","r3","r4","r5","memory","cc");
	return toe;
}

#ifdef notnow
static __inline__ void
bcopy(const void *from, void *toe, size_t len)
{
	__asm__ __volatile ("movc3 %0,(%1),(%2)"
			:
			: "r" (len),"r" (from),"r"(toe)
			:"r0","r1","r2","r3","r4","r5","memory","cc");
}
#endif

void	blkfill(void *, int, size_t);

static __inline__ void *
memset(void *block, int c, size_t len)
{
	if (len > 65535)
		blkfill(block, c, len);
	else {
		__asm__ __volatile ("movc5 $0,(%0),%2,%1,(%0)"
			:
			: "r" (block), "r" (len), "r"(c)
			:"r0","r1","r2","r3","r4","r5","memory","cc");
	}
	return block;
}

static __inline__ void
bzero(void *block, size_t len)
{
	if (len > 65535)
		blkfill(block, 0, len);
	else {
		__asm__ __volatile ("movc5 $0,(%0),$0,%1,(%0)"
			:
			: "r" (block), "r" (len)
			:"r0","r1","r2","r3","r4","r5","memory","cc");
	}
}

/* XXX - the return syntax of memcmp is wrong */
static __inline__ int
memcmp(const void *b1, const void *b2, size_t len)
{
	register int ret;

	__asm__ __volatile("cmpc3 %3,(%1),(%2);movl r0,%0"
			: "=r" (ret)
			: "r" (b1), "r" (b2), "r" (len)
			: "r0","r1","r2","r3" );
	return ret;
}

static __inline__ int
bcmp(const void *b1, const void *b2, size_t len)
{
	register int ret;

	__asm__ __volatile("cmpc3 %3,(%1),(%2);movl r0,%0"
			: "=r" (ret)
			: "r" (b1), "r" (b2), "r" (len)
			: "r0","r1","r2","r3" );
	return ret;
}

/* Begin nya */
@


1.14
log
@Let CISCoholic memset() do not behave as bzero for a length over 64KB.
@
text
@d1 1
a1 1
/*	$OpenBSD: macros.h,v 1.13 2006/02/22 22:16:07 miod Exp $ */
d235 4
a238 9
#define setrunqueue(p)	\
	__asm__ __volatile("movl %0,r0;jsb Setrq":: "g"(p):"r0","r1","r2");

#define remrunqueue(p)	\
	__asm__ __volatile("movl %0,r0;jsb Remrq":: "g"(p):"r0","r1","r2");

#define cpu_switch(p) \
	__asm__ __volatile("movl %0,r0;movpsl -(sp);jsb Swtch" \
	    ::"g"(p):"r0","r1","r2","r3");
@


1.13
log
@Remove unused _{ins,rem}que functions - they were not even implemented on
all architectures.
@
text
@d1 1
a1 1
/*	$OpenBSD: macros.h,v 1.12 2003/08/01 02:23:45 avsm Exp $ */
d85 1
a85 1
void	blkclr(void *, size_t);
d91 1
a91 1
		blkclr(block, len);
d105 1
a105 1
		blkclr(block, len);
@


1.12
log
@remove the strcpy/strcat macros
deraadt@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: macros.h,v 1.11 2002/08/09 20:26:45 jsyn Exp $ */
a52 18
}

static __inline__ void 
_remque(void *p)
{
	__asm__ __volatile ("remque (%0),%0;clrl 4(%0)"
			:
			: "r" (p)
			: "memory" );
}

static __inline__ void 
_insque(void *p, void *q)
{
	__asm__ __volatile ("insque (%0), (%1)"
			:
			: "r" (p),"r" (q)
			: "memory" );
@


1.11
log
@Get rid of remaining __P usage (except for imported code);
ok millert@@, rogue ok pjanzen@@
@
text
@d1 1
a1 1
/*	$OpenBSD: macros.h,v 1.10 2002/06/11 09:36:24 hugh Exp $ */
a170 11
strcat(char *cp, const char *c2)
{
        __asm__ __volatile("locc $0,$65535,(%1);subl3 r0,$65535,r2;incl r2;
                            locc $0,$65535,(%0);movc3 r2,(%1),(r1)"
                        :
                        : "r" (cp), "r" (c2)
                        : "r0","r1","r2","r3","r4","r5","memory","cc");
        return  cp;
}

static __inline__ char *
a176 11
                        : "r0","r1","r2","r3","r4","r5","memory","cc");
        return  cp;
}

static __inline__ char *
strcpy(char *cp, const char *c2)
{
        __asm__ __volatile("locc $0,$65535,(%1);subl3 r0,$65535,r2;
                            movc3 r2,(%1),(%0);movb $0,(r3)"
                        :
                        : "r" (cp), "r" (c2)
@


1.10
log
@New boot code, mostly from ragge's work in NetBSD.
Some header syncing and a couple network drivers came along for the ride.
Assembly files have been renamed from .s to .S to facilitate diffs.
Kernel is backwards compat - with manual interaction.
OpenBSD features have been preserved.
@
text
@d1 1
a1 1
/*	$OpenBSD$ */
d103 1
a103 1
void	blkclr __P((void *, size_t));
@


1.9
log
@First round of __P removal in sys
@
text
@d1 2
a2 2
/*	$OpenBSD: macros.h,v 1.8 2000/04/26 03:08:41 bjc Exp $	*/
/*	$NetBSD: macros.h,v 1.17 1998/11/07 17:22:58 ragge Exp $	*/
d5 1
a5 1
 * Copyright (c) 1994, 1998 Ludd, University of Lule}, Sweden.
d74 1
a74 1
memcpy(void *toe, const void *from, u_int len)
d83 1
a83 1
memmove(void *toe, const void *from, u_int len)
d94 1
a94 1
bcopy(const void *from, void *toe, u_int len)
d103 1
a103 1
void	blkclr(void *, u_int);
d120 1
a120 1
bzero(void *block, u_int len)
d240 1
a240 1
static __inline__ int locc(int mask, char *cp,u_int size){
d284 58
@


1.8
log
@vax resurrection, part 1: sync with early-april netbsd

many changes here, notable:  uvm, ansi.h, more (and cleaner) vsbus support
@
text
@d1 1
a1 1
/*	$OpenBSD: macros.h,v 1.7 1997/09/10 11:47:08 maja Exp $	*/
d103 1
a103 1
void	blkclr __P((void *, u_int));
@


1.8.10.1
log
@Sync UBC branch to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: macros.h,v 1.8 2000/04/26 03:08:41 bjc Exp $	*/
d103 1
a103 1
void	blkclr(void *, u_int);
@


1.8.10.2
log
@sync to -current
@
text
@d1 2
a2 2
/*	$OpenBSD$ */
/*	$NetBSD: macros.h,v 1.20 2000/07/19 01:02:52 matt Exp $	*/
d5 1
a5 1
 * Copyright (c) 1994, 1998, 2000 Ludd, University of Lule}, Sweden.
d74 1
a74 1
memcpy(void *toe, const void *from, size_t len)
d83 1
a83 1
memmove(void *toe, const void *from, size_t len)
d94 1
a94 1
bcopy(const void *from, void *toe, size_t len)
d103 1
a103 1
void	blkclr(void *, size_t);
d120 1
a120 1
bzero(void *block, size_t len)
d240 1
a240 1
static __inline__ int locc(int mask, char *cp, size_t size){
a283 58

/*
 * Interlock instructions. Used both in multiprocessor environments to
 * lock between CPUs and in uniprocessor systems when locking is required
 * between I/O devices and the master CPU.
 */
/*
 * Insqti() locks and inserts an element into the end of a queue.
 * Returns -1 if interlock failed, 1 if inserted OK and 0 if first in queue.
 */
static __inline__ int
insqti(void *entry, void *header) {
	register int ret;

	__asm__ __volatile("
			mnegl $1,%0;
			insqti (%1),(%2);
			bcs 1f;			# failed insert
			beql 2f;		# jump if first entry
			movl $1,%0;
			brb 1f;
		2:	clrl %0;
			1:;"
			: "=&g"(ret)
			: "r"(entry), "r"(header)
			: "memory");

	return ret;
}

/*
 * Remqhi() removes an element from the head of the queue.
 * Returns -1 if interlock failed, 0 if queue empty, address of the 
 * removed element otherwise.
 */
static __inline__ void *
remqhi(void *header) {
	register void *ret;

	__asm__ __volatile("
			remqhi (%1),%0;
			bcs 1f;			# failed interlock
			bvs 2f;			# nothing was removed
			brb 3f;
		1:	mnegl $1,%0;
			brb 3f;
		2:	clrl %0;
			3:;"
			: "=&g"(ret)
			: "r"(header)
			: "memory");

	return ret;
}
#define	ILCK_FAILED	-1	/* Interlock failed */
#define	Q_EMPTY		0	/* Queue is/was empty */
#define	Q_OK		1	/* Inserted OK */

@


1.7
log
@Sync with NetBSD 970516. -moj
@
text
@d1 2
a2 2
/*	$OpenBSD: macros.h,v 1.6 1997/05/29 00:04:44 niklas Exp $	*/
/*	$NetBSD: macros.h,v 1.11 1997/03/15 15:08:23 ragge Exp $	*/
d5 1
a5 1
 * Copyright (c) 1994 Ludd, University of Lule}, Sweden.
d36 2
a37 3
#if !defined(_VAX_MACROS_H_) && !defined(STANDALONE) && \
	(!defined(_LOCORE) && defined(_VAX_INLINE_))
#define	_VAX_MACROS_H_
d41 3
a43 1
static __inline__ int ffs(int reg){
d46 1
a46 1
	asm __volatile ("ffs	$0,$32,%1,%0
d49 2
a50 2
		1:	incl    %0"
			: "&=r" (val)
d55 4
a58 2
static __inline__ void _remque(void*p){
	asm __volatile ("remque (%0),%0;clrl 4(%0)"
d64 26
a89 5
static __inline__ void _insque(void*p, void*q) {
        asm __volatile ("insque (%0), (%1)"
                        :
                        : "r" (p),"r" (q)
                        : "memory" );
d92 5
a96 31
#define	bitset(bitnr,var)				\
({	asm __volatile ("bbss %0,%1,1f;1:;"		\
			:				\
			: "g" (bitnr), "g" (var));	\
})

#define	bitclear(bitnr,var)				\
({      asm __volatile ("bbsc %0,%1,1f;1:;"             \
                        :                               \
                        : "g" (bitnr), "g" (var));      \
})

#define	bitisset(bitnr,var)				\
({							\
	register int val;                               \
	asm __volatile ("clrl %0;bbc %1,%2,1f;incl %0;1:;" \
			: "=g" (val)			\
			: "g" (bitnr), "g" (var));	\
	val;						\
})

#define bitisclear(bitnr,var)                                \
({                                                      \
        register int val;                               \
        asm __volatile ("clrl %0;bbs %1,%2,1f;incl %0;1:;" \
                        : "=g" (val)                    \
                        : "g" (bitnr), "g" (var));      \
	val;						\
})
static __inline__ void bcopy(const void*from, void*toe, u_int len) {
	asm __volatile ("movc3 %0,(%1),(%2)"
d99 18
a116 1
			:"r0","r1","r2","r3","r4","r5");
d119 7
a125 2
static __inline__ void bzero(void*block, u_int len){
	asm __volatile ("movc5 $0,(%0),$0,%1,(%0)"
d128 2
a129 1
			:"r0","r1","r2","r3","r4","r5");
d132 17
a148 2
static __inline__ int bcmp(const void *b1, const void *b2, size_t len){
	register ret;
d150 1
a150 1
	asm __volatile("cmpc3 %3,(%1),(%2);movl r0,%0"
d157 82
d243 1
a243 1
	asm __volatile("locc %1,%2,(%3);movl r0,%0"
d252 3
a254 2
scanc(u_int size, const u_char *cp, const u_char *table, int mask){
	register ret;
d256 1
a256 1
	asm __volatile("scanc	%1,(%2),(%3),%4;movl r0,%0"
d263 4
a266 2
static __inline__ int skpc(int mask, size_t size, u_char *cp){
	register ret;
d268 1
a268 1
	asm __volatile("skpc %1,%2,(%3);movl r0,%0"
a273 29
#if 0
static __inline__ int imin(int a, int b){
	asm __volatile("cmpl %0,%2;bleq 1f;movl %2,%0;1:"
			: "=r"(a)
			: "r"(a),"r"(b) );
	return a;
}

static __inline__ int imax(int a, int b){
        asm __volatile("cmpl %0,%2;bgeq 1f;movl %2,%0;1:"
                        : "=r"(a)
                        : "r"(a),"r"(b) );
        return a;
}

static __inline__ int min(int a, int b){
        asm __volatile("cmpl %0,%2;bleq 1f;movl %2,%0;1:"
                        : "=r"(a)
                        : "r"(a),"r"(b) );
        return a;
}

static __inline__ int max(int a, int b){
        asm __volatile("cmpl %0,%2;bgeq 1f;movl %2,%0;1:"
                        : "=r"(a)
                        : "r"(a),"r"(b) );
        return a;
}
#endif
d275 5
a279 32
static __inline__ void blkcpy(const void*from, void*to, u_int len) {
	asm __volatile("
			movl    %0,r1
			movl    %1,r3
			movl	%2,r6
			jbr 2f
		1:	subl2   r0,r6
			movc3   r0,(r1),(r3)
		2:	movzwl  $65535,r0
			cmpl    r6,r0
			jgtr    1b
			movc3   r6,(r1),(r3)"
			:
			: "g" (from), "g" (to), "g" (len)
			: "r0","r1","r2","r3","r4","r5", "r6" );
}

static __inline__ void blkclr(void *blk, int len) {
	asm __volatile("
			movl	%0, r3
			movl	%1, r6
			jbr	2f
		1:	subl2	r0, r6
			movc5	$0,(r3),$0,r0,(r3)
		2:	movzwl	$65535,r0
			cmpl	r6, r0
			jgtr	1b
			movc5	$0,(r3),$0,r6,(r3)"
			:
			: "g" (blk), "g" (len)
			: "r0","r1","r2","r3","r4","r5", "r6" );
}
d281 3
@


1.7.12.1
log
@Continue the aborted merge of current just before 2.9 was cut into the
SMP branch.  Note that this will not make any progress of SMP functionality,
it is just merging of new code from the trunk into the old branch.
Please do not ask me questions about SMP status because of this mail,
instead go read the archives of smp@@openbsd.org, where I mailed about
these commits some week ago.  Another note: I am doing this in chunks now,
so as to not lock too much of the tree for long times
@
text
@d1 2
a2 2
/*	$OpenBSD: macros.h,v 1.8 2000/04/26 03:08:41 bjc Exp $	*/
/*	$NetBSD: macros.h,v 1.17 1998/11/07 17:22:58 ragge Exp $	*/
d5 1
a5 1
 * Copyright (c) 1994, 1998 Ludd, University of Lule}, Sweden.
d36 3
a38 2
#if !defined(_VAX_MACROS_H_) && !defined(lint)
#define _VAX_MACROS_H_
d42 1
a42 3
static __inline__ int
ffs(int reg)
{
d45 1
a45 1
	__asm__ __volatile ("ffs	$0,$32,%1,%0
d48 2
a49 2
		1:	incl	%0"
			: "=&r" (val)
d54 2
a55 4
static __inline__ void 
_remque(void *p)
{
	__asm__ __volatile ("remque (%0),%0;clrl 4(%0)"
d61 5
a65 7
static __inline__ void 
_insque(void *p, void *q)
{
	__asm__ __volatile ("insque (%0), (%1)"
			:
			: "r" (p),"r" (q)
			: "memory" );
d68 31
a98 13
static __inline__ void *
memcpy(void *toe, const void *from, u_int len)
{
	__asm__ __volatile ("movc3 %0,(%1),(%2)"
			:
			: "r" (len),"r" (from),"r"(toe)
			:"r0","r1","r2","r3","r4","r5","memory","cc");
	return toe;
}
static __inline__ void *
memmove(void *toe, const void *from, u_int len)
{
	__asm__ __volatile ("movc3 %0,(%1),(%2)"
d101 1
a101 29
			:"r0","r1","r2","r3","r4","r5","memory","cc");
	return toe;
}

#ifdef notnow
static __inline__ void
bcopy(const void *from, void *toe, u_int len)
{
	__asm__ __volatile ("movc3 %0,(%1),(%2)"
			:
			: "r" (len),"r" (from),"r"(toe)
			:"r0","r1","r2","r3","r4","r5","memory","cc");
}
#endif

void	blkclr __P((void *, u_int));

static __inline__ void *
memset(void *block, int c, size_t len)
{
	if (len > 65535)
		blkclr(block, len);
	else {
		__asm__ __volatile ("movc5 $0,(%0),%2,%1,(%0)"
			:
			: "r" (block), "r" (len), "r"(c)
			:"r0","r1","r2","r3","r4","r5","memory","cc");
	}
	return block;
d104 2
a105 7
static __inline__ void
bzero(void *block, u_int len)
{
	if (len > 65535)
		blkclr(block, len);
	else {
		__asm__ __volatile ("movc5 $0,(%0),$0,%1,(%0)"
d108 1
a108 2
			:"r0","r1","r2","r3","r4","r5","memory","cc");
	}
d111 2
a112 17
/* XXX - the return syntax of memcmp is wrong */
static __inline__ int
memcmp(const void *b1, const void *b2, size_t len)
{
	register int ret;

	__asm__ __volatile("cmpc3 %3,(%1),(%2);movl r0,%0"
			: "=r" (ret)
			: "r" (b1), "r" (b2), "r" (len)
			: "r0","r1","r2","r3" );
	return ret;
}

static __inline__ int
bcmp(const void *b1, const void *b2, size_t len)
{
	register int ret;
d114 1
a114 1
	__asm__ __volatile("cmpc3 %3,(%1),(%2);movl r0,%0"
a120 82
/* Begin nya */
static __inline__ size_t
strlen(const char *cp)
{
        register size_t ret;

        __asm__ __volatile("locc $0,$65535,(%1);subl3 r0,$65535,%0"
                        : "=r" (ret)
                        : "r" (cp)
                        : "r0","r1","cc" );
        return  ret;
}

static __inline__ char *
strcat(char *cp, const char *c2)
{
        __asm__ __volatile("locc $0,$65535,(%1);subl3 r0,$65535,r2;incl r2;
                            locc $0,$65535,(%0);movc3 r2,(%1),(r1)"
                        :
                        : "r" (cp), "r" (c2)
                        : "r0","r1","r2","r3","r4","r5","memory","cc");
        return  cp;
}

static __inline__ char *
strncat(char *cp, const char *c2, size_t count)
{
        __asm__ __volatile("locc $0,%2,(%1);subl3 r0,%2,r2;
                            locc $0,$65535,(%0);movc3 r2,(%1),(r1);movb $0,(r3)"
                        :
                        : "r" (cp), "r" (c2), "g"(count)
                        : "r0","r1","r2","r3","r4","r5","memory","cc");
        return  cp;
}

static __inline__ char *
strcpy(char *cp, const char *c2)
{
        __asm__ __volatile("locc $0,$65535,(%1);subl3 r0,$65535,r2;
                            movc3 r2,(%1),(%0);movb $0,(r3)"
                        :
                        : "r" (cp), "r" (c2)
                        : "r0","r1","r2","r3","r4","r5","memory","cc");
        return  cp;
}

static __inline__ char *
strncpy(char *cp, const char *c2, size_t len)
{
        __asm__ __volatile("movl %2,r2;locc $0,r2,(%1);beql 1f;subl3 r0,%2,r2;
                            clrb (%0)[r2];1:;movc3 r2,(%1),(%0)"
                        :
                        : "r" (cp), "r" (c2), "g"(len)
                        : "r0","r1","r2","r3","r4","r5","memory","cc");
        return  cp;
}

static __inline__ void *
memchr(const void *cp, int c, size_t len)
{
        void *ret;
        __asm__ __volatile("locc %2,%3,(%1);bneq 1f;clrl r1;1:movl r1,%0"
                        : "=g"(ret)
                        : "r" (cp), "r" (c), "g"(len)
                        : "r0","r1","cc");
        return  ret;
}

static __inline__ int
strcmp(const char *cp, const char *c2)
{
        register int ret;
        __asm__ __volatile("locc $0,$65535,(%1);subl3 r0,$65535,r0;incl r0;
                            cmpc3 r0,(%1),(%2);beql 1f;movl $1,r2;
                            cmpb (r1),(r3);bcc 1f;movl $-1,r2;1:movl r2,%0"
                        : "=g"(ret)
                        : "r" (cp), "r" (c2)
                        : "r0","r1","r2","r3","cc");
        return  ret;
}
/* End nya */

d125 1
a125 1
	__asm__ __volatile("locc %1,%2,(%3);movl r0,%0"
d134 2
a135 3
scanc(u_int size, const u_char *cp, const u_char *table, int mask)
{
	register int ret;
d137 1
a137 1
	__asm__ __volatile("scanc	%1,(%2),(%3),%4;movl r0,%0"
d144 2
a145 4
static __inline__ int
skpc(int mask, size_t size, u_char *cp)
{
	register int ret;
d147 1
a147 1
	__asm__ __volatile("skpc %1,%2,(%3);movl r0,%0"
d153 29
d183 32
a214 5
#define setrunqueue(p)	\
	__asm__ __volatile("movl %0,r0;jsb Setrq":: "g"(p):"r0","r1","r2");

#define remrunqueue(p)	\
	__asm__ __volatile("movl %0,r0;jsb Remrq":: "g"(p):"r0","r1","r2");
a215 3
#define cpu_switch(p) \
	__asm__ __volatile("movl %0,r0;movpsl -(sp);jsb Swtch" \
	    ::"g"(p):"r0","r1","r2","r3");
@


1.7.12.2
log
@Merge in -current from about a week ago
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d103 1
a103 1
void	blkclr(void *, u_int);
@


1.7.12.3
log
@Sync the SMP branch with 3.3
@
text
@d1 2
a2 2
/*	$OpenBSD$ */
/*	$NetBSD: macros.h,v 1.20 2000/07/19 01:02:52 matt Exp $	*/
d5 1
a5 1
 * Copyright (c) 1994, 1998, 2000 Ludd, University of Lule}, Sweden.
d74 1
a74 1
memcpy(void *toe, const void *from, size_t len)
d83 1
a83 1
memmove(void *toe, const void *from, size_t len)
d94 1
a94 1
bcopy(const void *from, void *toe, size_t len)
d103 1
a103 1
void	blkclr(void *, size_t);
d120 1
a120 1
bzero(void *block, size_t len)
d240 1
a240 1
static __inline__ int locc(int mask, char *cp, size_t size){
a283 58

/*
 * Interlock instructions. Used both in multiprocessor environments to
 * lock between CPUs and in uniprocessor systems when locking is required
 * between I/O devices and the master CPU.
 */
/*
 * Insqti() locks and inserts an element into the end of a queue.
 * Returns -1 if interlock failed, 1 if inserted OK and 0 if first in queue.
 */
static __inline__ int
insqti(void *entry, void *header) {
	register int ret;

	__asm__ __volatile("
			mnegl $1,%0;
			insqti (%1),(%2);
			bcs 1f;			# failed insert
			beql 2f;		# jump if first entry
			movl $1,%0;
			brb 1f;
		2:	clrl %0;
			1:;"
			: "=&g"(ret)
			: "r"(entry), "r"(header)
			: "memory");

	return ret;
}

/*
 * Remqhi() removes an element from the head of the queue.
 * Returns -1 if interlock failed, 0 if queue empty, address of the 
 * removed element otherwise.
 */
static __inline__ void *
remqhi(void *header) {
	register void *ret;

	__asm__ __volatile("
			remqhi (%1),%0;
			bcs 1f;			# failed interlock
			bvs 2f;			# nothing was removed
			brb 3f;
		1:	mnegl $1,%0;
			brb 3f;
		2:	clrl %0;
			3:;"
			: "=&g"(ret)
			: "r"(header)
			: "memory");

	return ret;
}
#define	ILCK_FAILED	-1	/* Interlock failed */
#define	Q_EMPTY		0	/* Queue is/was empty */
#define	Q_OK		1	/* Inserted OK */

@


1.7.12.4
log
@Merge of current from two weeks agointo the SMP branch
@
text
@d171 11
d188 11
@


1.6
log
@RCS tagging
@
text
@d1 2
a2 2
/*	$OpenBSD: macros.h,v 1.10 1997/01/11 11:07:52 ragge Exp $	*/
/*	$NetBSD: macros.h,v 1.10 1997/01/11 11:07:52 ragge Exp $	*/
d36 2
a37 2
#if !defined(_VAX_MACROS_H_) && (defined(STANDALONE) || \
	(!defined(_LOCORE) && defined(_VAX_INLINE_)))
@


1.5
log
@sync with NetBSD 970112 -moj
@
text
@d1 1
@


1.4
log
@sync w/ 0430
@
text
@d1 1
a1 1
/*	$NetBSD: macros.h,v 1.8 1996/03/17 22:44:50 ragge Exp $	*/
d120 1
d130 1
d132 2
a133 1
static __inline__ int scanc(u_int size, u_char *cp,u_char *table, int mask){
@


1.3
log
@update from netbsd
@
text
@d1 1
a1 1
/*	$NetBSD: macros.h,v 1.6 1995/12/13 18:56:01 ragge Exp $	*/
d36 1
a36 1
	(!defined(ASSEMBLER) && defined(_VAX_INLINE_)))
d140 1
a140 1
static __inline__ int skpc(int mask, int size, char *cp){
@


1.2
log
@update from netbsd tree
@
text
@d1 1
a1 1
/*	$NetBSD: macros.h,v 1.5 1995/10/20 12:55:06 ragge Exp $	*/
a177 9

#define	waitabit(tid)	\
({	\
	asm __volatile ("mfpr $27,r0;addl2 %0,r0;1:;mfpr $27,r1; \
			cmpl r0,r1;bneq 1b;"	\
			:		\
			: "g"(tid)	\
			: "r0","r1");	\
})
@


1.1
log
@Initial revision
@
text
@d1 1
a1 1
/*	$NetBSD: macros.h,v 1.4 1995/07/05 08:22:21 ragge Exp $	*/
d35 2
a36 1
#if !defined(_VAX_MACROS_H_)&&!defined(ASSEMBLER)&&defined(_VAX_INLINE_)
@


1.1.1.1
log
@initial import of NetBSD tree
@
text
@@
