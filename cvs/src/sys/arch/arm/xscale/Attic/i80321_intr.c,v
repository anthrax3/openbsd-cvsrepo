head	1.19;
access;
symbols
	OPENBSD_6_0:1.18.0.2
	OPENBSD_6_0_BASE:1.18
	OPENBSD_5_9:1.17.0.2
	OPENBSD_5_9_BASE:1.17
	OPENBSD_5_8:1.16.0.8
	OPENBSD_5_8_BASE:1.16
	OPENBSD_5_7:1.16.0.2
	OPENBSD_5_7_BASE:1.16
	OPENBSD_5_6:1.16.0.4
	OPENBSD_5_6_BASE:1.16
	OPENBSD_5_5:1.14.0.16
	OPENBSD_5_5_BASE:1.14
	OPENBSD_5_4:1.14.0.12
	OPENBSD_5_4_BASE:1.14
	OPENBSD_5_3:1.14.0.10
	OPENBSD_5_3_BASE:1.14
	OPENBSD_5_2:1.14.0.8
	OPENBSD_5_2_BASE:1.14
	OPENBSD_5_1_BASE:1.14
	OPENBSD_5_1:1.14.0.6
	OPENBSD_5_0:1.14.0.4
	OPENBSD_5_0_BASE:1.14
	OPENBSD_4_9:1.14.0.2
	OPENBSD_4_9_BASE:1.14
	OPENBSD_4_8:1.13.0.4
	OPENBSD_4_8_BASE:1.13
	OPENBSD_4_7:1.13.0.2
	OPENBSD_4_7_BASE:1.13
	OPENBSD_4_6:1.12.0.4
	OPENBSD_4_6_BASE:1.12
	OPENBSD_4_5:1.11.0.8
	OPENBSD_4_5_BASE:1.11
	OPENBSD_4_4:1.11.0.6
	OPENBSD_4_4_BASE:1.11
	OPENBSD_4_3:1.11.0.4
	OPENBSD_4_3_BASE:1.11
	OPENBSD_4_2:1.11.0.2
	OPENBSD_4_2_BASE:1.11
	OPENBSD_4_1:1.9.0.2
	OPENBSD_4_1_BASE:1.9
	OPENBSD_4_0:1.8.0.2
	OPENBSD_4_0_BASE:1.8;
locks; strict;
comment	@ * @;


1.19
date	2016.08.14.11.30.54;	author jsg;	state dead;
branches;
next	1.18;
commitid	3XHAPSr5dKOYN1hw;

1.18
date	2016.04.03.10.29.41;	author jsg;	state Exp;
branches;
next	1.17;
commitid	Wc8k8HnUtCtl1oqF;

1.17
date	2016.01.31.00.14.50;	author jsg;	state Exp;
branches;
next	1.16;
commitid	pbLjedMudUFrVMk6;

1.16
date	2014.04.03.10.17.34;	author mpi;	state Exp;
branches;
next	1.15;

1.15
date	2014.03.29.18.09.28;	author guenther;	state Exp;
branches;
next	1.14;

1.14
date	2010.09.20.06.33.47;	author matthew;	state Exp;
branches;
next	1.13;

1.13
date	2009.08.22.02.54.50;	author mk;	state Exp;
branches;
next	1.12;

1.12
date	2009.04.08.21.19.31;	author kettenis;	state Exp;
branches;
next	1.11;

1.11
date	2007.05.19.15.47.16;	author miod;	state Exp;
branches;
next	1.10;

1.10
date	2007.05.09.19.24.54;	author miod;	state Exp;
branches;
next	1.9;

1.9
date	2006.12.20.14.27.58;	author drahn;	state Exp;
branches;
next	1.8;

1.8
date	2006.07.02.02.51.13;	author drahn;	state Exp;
branches;
next	1.7;

1.7
date	2006.06.19.05.09.14;	author drahn;	state Exp;
branches;
next	1.6;

1.6
date	2006.06.17.20.48.18;	author drahn;	state Exp;
branches;
next	1.5;

1.5
date	2006.06.15.21.35.30;	author drahn;	state Exp;
branches;
next	1.4;

1.4
date	2006.06.01.17.33.47;	author drahn;	state Exp;
branches;
next	1.3;

1.3
date	2006.06.01.08.24.53;	author drahn;	state Exp;
branches;
next	1.2;

1.2
date	2006.05.29.17.27.31;	author drahn;	state Exp;
branches;
next	1.1;

1.1
date	2006.05.29.17.01.42;	author drahn;	state Exp;
branches;
next	;


desc
@@


1.19
log
@Remove code for Intel 80219/80321 xscale processors used by armish.
Generic xscale support and support for pxa2x0 used by zaurus remains.
@
text
@/* $OpenBSD: i80321_intr.c,v 1.18 2016/04/03 10:29:41 jsg Exp $ */

/*
 * Copyright (c) 2006 Dale Rahn <drahn@@openbsd.org>
 *
 * Permission to use, copy, modify, and distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 */

#include <sys/param.h>
#include <sys/systm.h>
#include <sys/malloc.h>
#include <sys/evcount.h>

#include <uvm/uvm_extern.h>

#include <machine/intr.h>

#include <arm/cpufunc.h>
#include <arm/xscale/i80321reg.h>
#include <arm/xscale/i80321var.h>

/*
 * autoconf glue
 */
int		i80321intc_match(struct device *, void *, void *);
void		i80321intc_attach(struct device *, struct device *, void *);

/* internal functions */
static void	i80321intc_write_intctl(uint32_t mask);
void		i80321intc_write_steer(uint32_t mask);
uint32_t	i80321intc_read_intsrc(void);
void		i80321intc_calc_mask(void);
void		i80321intc_init(void);
void		i80321intc_intr_init(void);
static void	i80321intc_setipl(int new);
void		i80321intc_do_pending(void);

uint32_t	i80321intc_imask[NIPL];
uint32_t	i80321intc_smask[NIPL];

#define SI_TO_IRQBIT(x)	(1 << (x))

volatile int current_ipl_level;
volatile int softint_pending;

struct cfattach i80321intc_ca = {
	sizeof(struct device), i80321intc_match, i80321intc_attach
};
        
struct cfdriver i80321intc_cd = {
	NULL, "i80321intc", DV_DULL
};

int i80321intc_attached = 0;

int
i80321intc_match(struct device *parent, void *v, void *aux)
{
	if (i80321intc_attached == 0)
		return 1;

	i80321intc_attached = 1;
	return 0;
}

void
i80321intc_attach(struct device *parent, struct device *self, void *args)
{
	i80321intc_init();
}

static inline void
i80321intc_write_intctl(uint32_t mask)
{
	__asm__ volatile ("mcr p6, 0, %0, c0, c0, 0" : : "r" (mask));
}

void
i80321intc_write_steer(uint32_t mask)
{
	__asm__ volatile ("mcr p6, 0, %0, c4, c0, 0" : : "r" (mask));
}

uint32_t
i80321intc_read_intsrc(void)
{
	uint32_t mask;
	__asm__ volatile ("mrc p6, 0, %0, c8, c0, 0" : "=r" (mask));
	return mask;
}

static inline void
i80321intc_setipl(int new)
{
	int psw;

	psw = disable_interrupts(PSR_I);
	current_ipl_level = new;
	i80321intc_write_intctl(i80321intc_imask[new]);
	restore_interrupts(psw);
}


struct intrq i80321_handler[NIRQ];

/*
 * Recompute the irq mask bits.
 * Must be called with interrupts disabled.
 */
void
i80321intc_calc_mask(void)
{
	int irq;
	struct intrhand *ih;
	int i;

	for (irq = 0; irq < NIRQ; irq++) {
		int i;
		int max = IPL_NONE;
		int min = IPL_HIGH;
		TAILQ_FOREACH(ih, &i80321_handler[irq].iq_list, ih_list) {
			if (ih->ih_ipl > max)
				max = ih->ih_ipl;

			if (ih->ih_ipl < min)
				min = ih->ih_ipl;
		}

		i80321_handler[irq].iq_irq = max;

		if (max == IPL_NONE)
			min = IPL_NONE; /* interrupt not enabled */
#if 0
		printf("irq %d: min %x max %x\n", irq, min, max);
#endif

		/* Enable interrupts at lower levels */
		for (i = 0; i < min; i++)
			i80321intc_imask[i] |= (1 << irq);
		/* Disable interrupts at upper levels */
		for (;i <= IPL_HIGH; i++)
			i80321intc_imask[i] &= ~(1 << irq);
	}
	/* initialize soft interrupt mask */
	for (i = IPL_NONE; i <= IPL_HIGH; i++)  {
		i80321intc_smask[i] = 0;
		if (i < IPL_SOFT)
			i80321intc_smask[i] |= SI_TO_IRQBIT(SI_SOFT);
		if (i < IPL_SOFTCLOCK)
			i80321intc_smask[i] |= SI_TO_IRQBIT(SI_SOFTCLOCK);
		if (i < IPL_SOFTNET)
			i80321intc_smask[i] |= SI_TO_IRQBIT(SI_SOFTNET);
		if (i < IPL_SOFTTTY)
			i80321intc_smask[i] |= SI_TO_IRQBIT(SI_SOFTTTY);
#if 0
		printf("mask[%d]: %x %x\n", i, i80321intc_smask[i],
		    i80321intc_imask[i]);
#endif
	}

	i80321intc_setipl(current_ipl_level);
}

void
i80321intc_do_pending(void)
{
	int oldirqstate, spl_save;

	oldirqstate = disable_interrupts(PSR_I);

	spl_save = current_ipl_level;

#define DO_SOFTINT(si, ipl) \
	if ((softint_pending & i80321intc_smask[current_ipl_level]) &	\
	    SI_TO_IRQBIT(si)) {						\
		softint_pending &= ~SI_TO_IRQBIT(si);			\
		if (current_ipl_level < ipl)				\
			i80321intc_setipl(ipl);				\
		restore_interrupts(oldirqstate);			\
		softintr_dispatch(si);					\
		oldirqstate = disable_interrupts(PSR_I);		\
		i80321intc_setipl(spl_save);				\
	}

	do {
		DO_SOFTINT(SI_SOFTTTY, IPL_SOFTTTY);
		DO_SOFTINT(SI_SOFTNET, IPL_SOFTNET);
		DO_SOFTINT(SI_SOFTCLOCK, IPL_SOFTCLOCK);
		DO_SOFTINT(SI_SOFT, IPL_SOFT);
	} while (softint_pending & i80321intc_smask[current_ipl_level]);
		
	restore_interrupts(oldirqstate);
}

void
splx(int new)
{
	i80321intc_setipl(new);

	if (softint_pending & i80321intc_smask[current_ipl_level])
		i80321intc_do_pending();
}

int
_spllower(int new)
{
	int old = current_ipl_level;
	splx(new);
	return (old);
}

int
_splraise(int new)
{
	int old;
	old = current_ipl_level;

	/* 
	 * setipl must always be called because there is a race window
	 * where the variable is updated before the mask is set
	 * an interrupt occurs in that window without the mask always
	 * being set, the hardware might not get updated on the next
	 * splraise completely messing up spl protection.
	 */
	if (old > new)
		new = old;

	i80321intc_setipl(new);

	return (old);
}

void
_setsoftintr(int si)
{
	int oldirqstate;

        oldirqstate = disable_interrupts(PSR_I);
	softint_pending |= SI_TO_IRQBIT(si);
	restore_interrupts(oldirqstate);

	/* Process unmasked pending soft interrupts. */
	if (softint_pending & i80321intc_smask[current_ipl_level])
		i80321intc_do_pending();
}

/*
 * i80321_icu_init:
 *
 *	Initialize the i80321 ICU.  Called early in bootstrap
 *	to make sure the ICU is in a pristine state.
 */
void
i80321intc_intr_init(void)
{
	i80321intc_write_intctl(0);

	i80321intc_write_steer(0);
}
	   
/*
 * i80321_intr_init:
 *
 *      Initialize the rest of the interrupt subsystem, making it
 *      ready to handle interrupts from devices.  
 */     
void
i80321intc_init(void)
{
	struct intrq *iq;
	int i;
			     
	for (i = 0; i < NIRQ; i++) {
		iq = &i80321_handler[i];
		TAILQ_INIT(&iq->iq_list);
	}       
 
	i80321intc_calc_mask();
      
	/* Enable IRQs (don't yet use FIQs). */
	enable_interrupts(PSR_I);
}

void *
i80321_intr_establish(int irq, int ipl, int (*func)(void *), void *arg,
    const char *name)
{
	struct intrq *iq;
	struct intrhand *ih;
	uint32_t oldirqstate;

	if (irq < 0 || irq > NIRQ)
		panic("i80321_intr_establish: IRQ %d out of range", irq);

	ih = malloc(sizeof(*ih), M_DEVBUF, M_NOWAIT);
	if (ih == NULL)
		return (NULL);
		  
	ih->ih_func = func;
	ih->ih_arg = arg;
	ih->ih_ipl = ipl;
	ih->ih_name = name;
	ih->ih_irq = irq;
	   
	iq = &i80321_handler[irq];

	if (name != NULL)
		evcount_attach(&ih->ih_count, name, &ih->ih_irq);

	/* All IOP321 interrupts are level-triggered. */
	iq->iq_ist = IST_LEVEL;

	oldirqstate = disable_interrupts(PSR_I);
	
	TAILQ_INSERT_TAIL(&iq->iq_list, ih, ih_list);
 
	i80321intc_calc_mask();

	restore_interrupts(oldirqstate);
			     
	return (ih);
}


void
i80321_intr_disestablish(void *cookie)   
{
	struct intrhand *ih = cookie;
	struct intrq *iq = &i80321_handler[ih->ih_irq];
	int oldirqstate;
		
	oldirqstate = disable_interrupts(PSR_I);

	TAILQ_REMOVE(&iq->iq_list, ih, ih_list);
	if (ih->ih_name != NULL)
		evcount_detach(&ih->ih_count);

	i80321intc_calc_mask();

	restore_interrupts(oldirqstate);
}

void  
i80321_irq_handler(void *arg)
{
	struct clockframe *frame = arg;
	uint32_t hwpend;
	int irq;
	int saved_spl_level;
	struct intrhand *ih;
	
	saved_spl_level = current_ipl_level;

	/* get pending IRQs */
	hwpend = i80321intc_read_intsrc();

	while ((irq = find_first_bit(hwpend)) >= 0) {
		/* XXX: Should we handle IRQs in priority order? */
 
		/* raise spl to stop interrupts of lower priorities */
		if (saved_spl_level < i80321_handler[irq].iq_irq)
			i80321intc_setipl(i80321_handler[irq].iq_irq);

		/* Enable interrupt */
		enable_interrupts(PSR_I);
		TAILQ_FOREACH(ih, &i80321_handler[irq].iq_list, ih_list) {
			if ((ih->ih_func)( ih->ih_arg == 0
			    ? frame : ih->ih_arg))
				ih->ih_count.ec_count++;
		}
		/* Disable interrupt */
		disable_interrupts(PSR_I);
		hwpend &= ~(1<<irq);
	}
	uvmexp.intrs++;

	/* restore spl to that was when this interrupt happen */
	i80321intc_setipl(saved_spl_level);

	if(softint_pending & i80321intc_smask[current_ipl_level])
		i80321intc_do_pending();
}

#ifdef DIAGNOSTIC
void
i80321_splassert_check(int wantipl, const char *func)
{
	int oldipl = current_ipl_level;

	if (oldipl < wantipl) {
		splassert_fail(wantipl, oldipl, func);
		/*
		 * If the splassert_ctl is set to not panic, raise the ipl
		 * in a feeble attempt to reduce damage.
		 */
		i80321intc_setipl(wantipl);
	}
}
#endif
@


1.18
log
@Remove tests for "processing" which was never set.  It attempted to
protect against multiple entries of a function that handled pending
soft interrupts.  This seems to have been a mistake made when converting
code that used simple lock in the 80321 code which got reused in armv7.

arm softintr_dispatch() already has mutexes around invoked callbacks
which should be enough.  Make the pxa2x0 code work the same way which
removes the last remaining simple lock use on arm.

ok patrick@@
@
text
@d1 1
a1 1
/* $OpenBSD: i80321_intr.c,v 1.17 2016/01/31 00:14:50 jsg Exp $ */
@


1.17
log
@Switch from PSR_X_bit and X32_bit PSR macro names to just PSR_X.
This matches FreeBSD and makes things a bit more consistent.
Discussed with Patrick.
@
text
@d1 1
a1 1
/* $OpenBSD: i80321_intr.c,v 1.16 2014/04/03 10:17:34 mpi Exp $ */
a176 1
	static int processing = 0;
a182 5
	if (processing == 1) {
		restore_interrupts(oldirqstate);
		return;
	}

a201 2

	processing = 0;
@


1.16
log
@More uvm_extern.h cleanup.
@
text
@d1 1
a1 1
/* $OpenBSD: i80321_intr.c,v 1.15 2014/03/29 18:09:28 guenther Exp $ */
d107 1
a107 1
	psw = disable_interrupts(I32_bit);
d180 1
a180 1
	oldirqstate = disable_interrupts(I32_bit);
d197 1
a197 1
		oldirqstate = disable_interrupts(I32_bit);		\
d256 1
a256 1
        oldirqstate = disable_interrupts(I32_bit);
d299 1
a299 1
	enable_interrupts(I32_bit);
d331 1
a331 1
	oldirqstate = disable_interrupts(I32_bit);
d350 1
a350 1
	oldirqstate = disable_interrupts(I32_bit);
d383 1
a383 1
		enable_interrupts(I32_bit);
d390 1
a390 1
		disable_interrupts(I32_bit);
@


1.15
log
@It's been a quarter century: we can assume volatile is present with that name.

ok dlg@@ mpi@@ deraadt@@
@
text
@d1 1
a1 1
/* $OpenBSD: i80321_intr.c,v 1.14 2010/09/20 06:33:47 matthew Exp $ */
d24 1
a24 1
#include <uvm/uvm.h>	/* uvmexp */
@


1.14
log
@Get rid of evcount's support for arranging counters in a tree
hierarchy.  Everything attached to a single root node anyway, so at
best we had a bush.

"i think it is good" deraadt@@
@
text
@d1 1
a1 1
/* $OpenBSD: i80321_intr.c,v 1.13 2009/08/22 02:54:50 mk Exp $ */
d53 2
a54 2
__volatile int current_ipl_level;
__volatile int softint_pending;
@


1.13
log
@Constify the what/name parameter of pci_intr_establish().

Tested by myself, sthen, oga, kettenis, and jasper.
Input from sthen and jasper.

ok kettenis

(Manpage follows shortly.)
@
text
@d1 1
a1 1
/* $OpenBSD: i80321_intr.c,v 1.12 2009/04/08 21:19:31 kettenis Exp $ */
d326 1
a326 2
		evcount_attach(&ih->ih_count, name, (void *)&ih->ih_irq,
		    &evcount_intr);
@


1.12
log
@Cleanup arm soft interrupt handling; remove the unused IPL_SERIAL and rename
IPL_SOFTSERIAL to IPL_SOFTTTY.

tested by oga@@
ok miod@@
@
text
@d1 1
a1 1
/* $OpenBSD: i80321_intr.c,v 1.11 2007/05/19 15:47:16 miod Exp $ */
d304 1
a304 1
    char *name)
@


1.11
log
@Implement splassert for armish and zaurus.
@
text
@d1 1
a1 1
/* $OpenBSD: i80321_intr.c,v 1.10 2007/05/09 19:24:54 miod Exp $ */
d163 2
a164 2
		if (i < IPL_SOFTSERIAL)
			i80321intc_smask[i] |= SI_TO_IRQBIT(SI_SOFTSERIAL);
d202 1
a202 1
		DO_SOFTINT(SI_SOFTSERIAL, IPL_SOFTSERIAL);
@


1.10
log
@diable -> disable
@
text
@d1 1
a1 1
/* $OpenBSD: i80321_intr.c,v 1.9 2006/12/20 14:27:58 drahn Exp $ */
d402 17
@


1.9
log
@Enable recursive interrupts on armish. nudge by deraadt@@
@
text
@d1 1
a1 1
/* $OpenBSD: i80321_intr.c,v 1.8 2006/07/02 02:51:13 drahn Exp $ */
d150 1
a150 1
		/* Diable interrupts at upper levels */
@


1.8
log
@count interrupts (uvmexp).
@
text
@d1 1
a1 1
/* $OpenBSD: i80321_intr.c,v 1.7 2006/06/19 05:09:14 drahn Exp $ */
d105 3
d110 1
a382 1
#ifdef notyet
d384 1
a384 2
		restore_interrupts(I32_bit);
#endif
a389 1
#ifdef notyet
a391 1
#endif
@


1.7
log
@Close a race in the interrupt handler code.
Inline functions when it makes sense.
@
text
@d1 1
a1 1
/* $OpenBSD: i80321_intr.c,v 1.6 2006/06/17 20:48:18 drahn Exp $ */
d24 2
d394 1
@


1.6
log
@Fix error where soft irq mask was not initialized for IPL_HIGH, and cleanup.
@
text
@d1 1
a1 1
/* $OpenBSD: i80321_intr.c,v 1.5 2006/06/15 21:35:30 drahn Exp $ */
d37 1
a37 1
void		i80321intc_write_intctl(uint32_t mask);
d43 1
a43 1
void		i80321intc_setipl(int new);
d80 1
a80 1
void
d100 1
a100 1
void
d229 13
a241 2
	if (new > old)
		i80321intc_setipl(new);
@


1.5
log
@rewritten, simplifed interrupt controller for 80321, half the lines
and much less complex. IPL_SERIAL goes at the same time.
@
text
@d1 1
a1 1
/* $OpenBSD$ */
d110 4
d136 1
a136 1
			min = IPL_NONE;
d149 1
a149 1
	for (i = IPL_NONE; i < IPL_HIGH; i++)  {
@


1.4
log
@Splraise is strictly to increase spl, do not lower.
@
text
@d1 1
a1 2
/*	$OpenBSD: i80321_intr.c,v 1.3 2006/06/01 08:24:53 drahn Exp $	*/
/*	$NetBSD: i80321_icu.c,v 1.11 2005/12/24 20:06:52 perry Exp $	*/
d4 1
a4 2
 * Copyright (c) 2001, 2002 Wasabi Systems, Inc.
 * All rights reserved.
d6 3
a8 1
 * Written by Jason R. Thorpe for Wasabi Systems, Inc.
d10 7
a16 33
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *	This product includes software developed for the NetBSD Project by
 *	Wasabi Systems, Inc.
 * 4. The name of Wasabi Systems, Inc. may not be used to endorse
 *    or promote products derived from this software without specific prior
 *    written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY WASABI SYSTEMS, INC. ``AS IS'' AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED
 * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL WASABI SYSTEMS, INC
 * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
 * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
 * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
 * POSSIBILITY OF SUCH DAMAGE.
 */

#include <sys/cdefs.h>

/*
 * Interrupt support for the Intel i80321 I/O Processor.
a23 3
#include <uvm/uvm_extern.h>

#include <machine/bus.h>
a26 1

a29 22
/* Interrupt handler queues. */
struct intrq intrq[NIRQ];

/* Interrupts to mask at each level. */
int i80321_imask[NIPL];

/* Current interrupt priority level. */
volatile int current_ipl_level;  

/* Interrupts pending. */
volatile int i80321_ipending;
volatile int softint_ipending;

/* Software copy of the IRQs we have enabled. */
volatile uint32_t intr_enabled;

/* Mask if interrupts steered to FIQs. */
uint32_t intr_steer;

#define INT_SWMASK                                                      \
        ((1U << ICU_INT_bit23) | (1U << ICU_INT_bit22) |                \
         (1U << ICU_INT_bit5)  | (1U << ICU_INT_bit4))
d31 1
a31 3
 * Map a software interrupt queue index (to the unused bits in the
 * ICU registers -- XXX will need to revisit this if those bits are
 * ever used in future steppings).
d33 2
a34 6
static const uint32_t si_to_irqbit[SI_NQUEUES] = {
	ICU_INT_bit23,		/* SI_SOFT */
	ICU_INT_bit22,		/* SI_SOFTCLOCK */
	ICU_INT_bit5,		/* SI_SOFTNET */
	ICU_INT_bit4,		/* SI_SOFTSERIAL */
};
d36 9
a44 11
#define	SI_TO_IRQBIT(si)	(1U << si_to_irqbit[(si)])

/*
 * Map a software interrupt queue to an interrupt priority level.
 */
static const int si_to_ipl[SI_NQUEUES] = {
	IPL_SOFT,		/* SI_SOFT */
	IPL_SOFTCLOCK,		/* SI_SOFTCLOCK */
	IPL_SOFTNET,		/* SI_SOFTNET */
	IPL_SOFTSERIAL,		/* SI_SOFTSERIAL */
};
d46 2
a47 37
/*
 * Interrupt bit names.
 */
const char *i80321_irqnames[] = {
	"DMA0 EOT",
	"DMA0 EOC",
	"DMA1 EOT",
	"DMA1 EOC",
	"irq 4",
	"irq 5",
	"AAU EOT",
	"AAU EOC",
	"core PMU",
	"TMR0 (hardclock)",
	"TMR1",
	"I2C0",
	"I2C1",
	"MU",
	"BIST",
	"periph PMU",
	"XScale PMU",
	"BIU error",
	"ATU error",
	"MCU error",
	"DMA0 error",
	"DMA1 error",
	"irq 22",
	"AAU error",
	"MU error",
	"SSP",
	"irq 26",
	"irq 27",
	"irq 28",
	"irq 29",
	"irq 30",
	"irq 31",
};
d49 1
a49 8
int	i80321intc_match(struct device *parent, void *cf, void *aux);
void	i80321intc_attach(struct device *, struct device *, void *);
void	i80321_set_intrmask(void);
void	i80321_do_pending(void);
uint32_t i80321_iintsrc_read(void);
void	i80321_enable_irq(int irq);
void	i80321_disable_irq(int irq);
void	i80321_intr_calculate_masks(void);
d51 2
d57 1
a57 1

d62 2
d65 1
a65 1
i80321intc_match(struct device *parent, void *cf, void *aux)
d67 2
a68 4
 
	/* XXX */
#if 0
	struct ip_attach_args *pxa = aux;
d70 3
a72 3
	if (pxaintc_attached || pxa->pxa_addr != PXA2X0_INTCTL_BASE)
		return (0);
#endif
a73 2
	return (1);
}
d77 1
a77 1
	i80321_icu_init();
d80 2
a81 2
void 
i80321_set_intrmask(void)
d83 1
a83 5
	extern volatile uint32_t intr_enabled;

	__asm volatile("mcr p6, 0, %0, c0, c0, 0"
		:
		: "r" (intr_enabled & ICU_INT_HWMASK));
d86 2
a87 5

void	i80321_intr_dispatch(struct clockframe *frame);

uint32_t
i80321_iintsrc_read(void)
d89 1
a89 11
	uint32_t iintsrc;

	__asm volatile("mrc p6, 0, %0, c8, c0, 0"
		: "=r" (iintsrc));

	/*
	 * The IINTSRC register shows bits that are active even
	 * if they are masked in INTCTL, so we have to mask them
	 * off with the interrupts we consider enabled.
	 */
	return (iintsrc & intr_enabled);
d92 2
a93 2
static inline void
i80321_set_intrsteer(void)
d95 3
a97 4

	__asm volatile("mcr p6, 0, %0, c4, c0, 0"
		:
		: "r" (intr_steer & ICU_INT_HWMASK));
d101 1
a101 1
i80321_enable_irq(int irq)
d103 2
a104 3

	intr_enabled |= (1U << irq);
	i80321_set_intrmask();
a106 3
void
i80321_disable_irq(int irq)
{
d108 1
a108 3
	intr_enabled &= ~(1U << irq);
	i80321_set_intrmask();
}
a109 3
/*
 * NOTE: This routine must be called with interrupts disabled in the CPSR.
 */
d111 1
a111 1
i80321_intr_calculate_masks(void)
d113 1
a113 1
	struct intrq *iq;
d115 1
a115 1
	int irq, ipl;
a116 1
	/* First, figure out which IPLs each IRQ has. */
d118 6
a123 8
		int levels = 0;
		iq = &intrq[irq];
		i80321_disable_irq(irq);
		for (ih = TAILQ_FIRST(&iq->iq_list); ih != NULL;
		     ih = TAILQ_NEXT(ih, ih_list))
			levels |= (1U << ih->ih_ipl);
		iq->iq_levels = levels;
	}
d125 2
a126 6
	/* Next, figure out which IRQs are used by each IPL. */
	for (ipl = 0; ipl < NIPL; ipl++) {
		int irqs = 0;
		for (irq = 0; irq < NIRQ; irq++) {
			if (intrq[irq].iq_levels & (1U << ipl))
				irqs |= (1U << irq);
a127 2
		i80321_imask[ipl] = irqs;
	}
d129 7
a135 1
	i80321_imask[IPL_NONE] = 0;
d137 22
a158 79
	/*
	 * Initialize the soft interrupt masks to block themselves.
	 */
	i80321_imask[IPL_SOFT] = SI_TO_IRQBIT(SI_SOFT);
	i80321_imask[IPL_SOFTCLOCK] = SI_TO_IRQBIT(SI_SOFTCLOCK);
	i80321_imask[IPL_SOFTNET] = SI_TO_IRQBIT(SI_SOFTNET);
	i80321_imask[IPL_SOFTSERIAL] = SI_TO_IRQBIT(SI_SOFTSERIAL);

	/*
	 * splsoftclock() is the only interface that users of the
	 * generic software interrupt facility have to block their
	 * soft intrs, so splsoftclock() must also block IPL_SOFT.
	 */
	i80321_imask[IPL_SOFTCLOCK] |= i80321_imask[IPL_SOFT];

	/*
	 * splsoftnet() must also block splsoftclock(), since we don't
	 * want timer-driven network events to occur while we're
	 * processing incoming packets.
	 */
	i80321_imask[IPL_SOFTNET] |= i80321_imask[IPL_SOFTCLOCK];

	/*
	 * Enforce a heirarchy that gives "slow" device (or devices with
	 * limited input buffer space/"real-time" requirements) a better
	 * chance at not dropping data.
	 */
	i80321_imask[IPL_BIO] |= i80321_imask[IPL_SOFTNET];
	i80321_imask[IPL_NET] |= i80321_imask[IPL_BIO];
	i80321_imask[IPL_SOFTSERIAL] |= i80321_imask[IPL_NET];
	i80321_imask[IPL_TTY] |= i80321_imask[IPL_SOFTSERIAL];

	/*
	 * splvm() blocks all interrupts that use the kernel memory
	 * allocation facilities.
	 */
	i80321_imask[IPL_VM] |= i80321_imask[IPL_TTY];

	/*
	 * Audio devices are not allowed to perform memory allocation
	 * in their interrupt routines, and they have fairly "real-time"
	 * requirements, so give them a high interrupt priority.
	 */
	i80321_imask[IPL_AUDIO] |= i80321_imask[IPL_VM];

	/*
	 * splclock() must block anything that uses the scheduler.
	 */
	i80321_imask[IPL_CLOCK] |= i80321_imask[IPL_AUDIO];

	/*
	 * No separate statclock on the IQ80310.
	 */
	i80321_imask[IPL_STATCLOCK] |= i80321_imask[IPL_CLOCK];

	/*
	 * splhigh() must block "everything".
	 */
	i80321_imask[IPL_HIGH] |= i80321_imask[IPL_STATCLOCK];

	/*
	 * XXX We need serial drivers to run at the absolute highest priority
	 * in order to avoid overruns, so serial > high.
	 */
	i80321_imask[IPL_SERIAL] |= i80321_imask[IPL_HIGH];

	/*
	 * Now compute which IRQs must be blocked when servicing any
	 * given IRQ.
	 */
	for (irq = 0; irq < NIRQ; irq++) {
		int maxirq = IPL_NONE;
		iq = &intrq[irq];
		if (TAILQ_FIRST(&iq->iq_list) != NULL)
			i80321_enable_irq(irq);
		for (ih = TAILQ_FIRST(&iq->iq_list); ih != NULL;
		     ih = TAILQ_NEXT(ih, ih_list))
			maxirq = ih->ih_ipl > maxirq ? ih->ih_ipl : maxirq;
		iq->iq_irq = maxirq;
d160 2
d165 1
a165 1
i80321_do_pending(void)
d168 1
a168 1
	int new, oldirqstate;
d172 3
a174 1
	if (processing) {
d179 6
a184 9
	processing = 1;

	new = current_ipl_level;


#define	DO_SOFTINT(si)							\
	if ((softint_ipending & ~i80321_imask[new]) & SI_TO_IRQBIT(si)){	\
		softint_ipending &= ~SI_TO_IRQBIT(si);			\
		current_ipl_level = si_to_ipl[(si)];			\
d188 1
a188 1
		current_ipl_level = new;				\
d192 6
a197 5
		DO_SOFTINT(SI_SOFTSERIAL);
		DO_SOFTINT(SI_SOFTNET);
		DO_SOFTINT(SI_SOFTCLOCK);
		DO_SOFTINT(SI_SOFT);
	} while( softint_ipending & i80321_imask[current_ipl_level] );
a202 2
int spl_debug;
int nesting;
d206 1
d208 2
a209 20
	int oldirqstate, hwpend;

	current_ipl_level = new;

	hwpend = (i80321_ipending & ICU_INT_HWMASK) & ~i80321_imask[new];
	if (hwpend != 0) {
		oldirqstate = disable_interrupts(I32_bit);
		intr_enabled |= hwpend;
		i80321_set_intrmask();
		restore_interrupts(oldirqstate);
	}
	if (spl_debug) {
		nesting ++;
		if (nesting == 1)
		printf("sX %d\n", new);
		nesting --;
	}

	if ((softint_ipending & INT_SWMASK) & ~i80321_imask[new])
		i80321_do_pending();
d213 1
a213 1
_spllower(int ipl)
a214 2

	extern int i80321_imask[];
d216 2
a217 9

	splx(i80321_imask[ipl]);
	if (spl_debug) {
		nesting ++;
		if (nesting == 1)
		printf("sL %d\n", ipl);
		nesting --;
	}
	return(old);
d221 1
a221 1
_splraise(int ipl)
d223 1
a223 3

	int	old;

d225 2
a226 9
	if (ipl > old)
		current_ipl_level = ipl;
	if (spl_debug) {
		nesting ++;
		if (nesting == 1)
		printf("sR %d\n", ipl);
		nesting --;
	}

d235 2
a236 2
	oldirqstate = disable_interrupts(I32_bit);
	softint_ipending |= SI_TO_IRQBIT(si);
d240 2
a241 2
	if ((softint_ipending & INT_SWMASK) & ~i80321_imask[current_ipl_level])
		i80321_do_pending();
d251 1
a251 1
i80321_icu_init(void)
d253 1
a253 2
	intr_enabled = 0;	/* All interrupts disabled */
	i80321_set_intrmask();
d255 1
a255 2
	intr_steer = 0;		/* All interrupts steered to IRQ */
	i80321_set_intrsteer();
d257 1
a257 6

struct {
	int id;
	struct evcount ev;
} i80321_spur[NIRQ];

d261 3
a263 3
 *	Initialize the rest of the interrupt subsystem, making it
 *	ready to handle interrupts from devices.
 */
d265 1
a265 1
i80321_intr_init(void)
d269 1
a269 3

	intr_enabled = 0;

d271 1
a271 1
		iq = &intrq[i];
d273 4
a276 8

		i80321_spur[i].id = i;
		evcount_attach(&i80321_spur[i].ev, "spur",
		    (void *)&i80321_spur[i].id, &evcount_intr);
	}

	i80321_intr_calculate_masks();

d287 1
a287 1
	u_int oldirqstate;
d295 1
a295 1

d301 2
a302 2

	iq = &intrq[irq];
d312 1
a312 1

d314 2
a315 2

	i80321_intr_calculate_masks();
d318 1
a318 1

d322 1
d324 1
a324 1
i80321_intr_disestablish(void *cookie)
d327 1
a327 1
	struct intrq *iq = &intrq[ih->ih_irq];
d329 1
a329 1

d336 1
a336 1
	i80321_intr_calculate_masks();
d341 2
a342 2
void
i80321_irq_handler(void *v) 
d344 4
a347 2
	struct clockframe *frame = v;
	struct intrq *iq;
d349 2
a350 2
	int oldirqstate, pipl, irq, ibit, hwpend;
	int spur = 1;
d352 2
a353 1
	pipl = current_ipl_level;
d355 10
a364 17
	hwpend = i80321_iintsrc_read();

	/*
	 * Disable all the interrupts that are pending.  We will
	 * reenable them once they are processed and not masked.
	 */
	intr_enabled &= ~hwpend;
	i80321_set_intrmask();


	while (hwpend != 0) {
		irq = ffs(hwpend) - 1;
		ibit = (1U << irq);

#if 0
		if (irq != 9)
			printf("irq %d\n", irq);
d366 3
a368 21

		hwpend &= ~ibit;

		if (i80321_imask[pipl] & ibit) {
			/*
			 * IRQ is masked; mark it as pending and check
			 * the next one.  Note: the IRQ is already disabled.
			 */
			i80321_ipending |= ibit;
			continue;
		}

		i80321_ipending &= ~ibit;

		iq = &intrq[irq];
		uvmexp.intrs++;
		current_ipl_level = iq->iq_irq;
		oldirqstate = enable_interrupts(I32_bit);
		for (ih = TAILQ_FIRST(&iq->iq_list); ih != NULL;
		     ih = TAILQ_NEXT(ih, ih_list)) {
			if ((*ih->ih_func)(ih->ih_arg ? ih->ih_arg : frame)) {
a369 2
				spur = 0;
			}
d371 6
a376 6
		restore_interrupts(oldirqstate);
	
		if (spur == 1)
			i80321_spur[irq].ev.ec_count++;

		current_ipl_level = pipl;
d378 2
a379 10
		/* Re-enable this interrupt now that's it's cleared. */
		intr_enabled |= ibit;
		i80321_set_intrmask();

		/*
		 * Don't forget to include interrupts which may have
		 * arrived in the meantime.
		 */
		hwpend |= ((i80321_ipending & ICU_INT_HWMASK) & ~i80321_imask[pipl]);
	}
d381 2
a382 29
	/* Check for pendings soft intrs. */
	if ((softint_ipending & INT_SWMASK) & ~i80321_imask[current_ipl_level]) {
		oldirqstate = enable_interrupts(I32_bit);
		i80321_do_pending();
		restore_interrupts(oldirqstate);
	}
}
uint32_t get_pending_irq(void);
uint32_t
get_pending_irq()
{
	uint32_t pending;
#if 1
	uint32_t ointr_enabled;
	uint32_t oldirqstate;
	oldirqstate = disable_interrupts(I32_bit);
	ointr_enabled = intr_enabled;
	intr_enabled = 0xffffffff;
	__asm volatile("mcr p6, 0, %0, c0, c0, 0":: "r" (0xffffffff));
	i80321_set_intrmask();
#endif
	__asm volatile("mrc p6, 0, %0, c8, c0, 0"
		: "=r" (pending));
#if 1
	intr_enabled = ointr_enabled;
	i80321_set_intrmask();
	restore_interrupts(oldirqstate);
#endif
	return pending;
@


1.3
log
@current_ipl_level is a value, not a mask, do not '|=' into it.
@
text
@d1 1
a1 1
/*	$OpenBSD: i80321_intr.c,v 1.2 2006/05/29 17:27:31 drahn Exp $	*/
d442 2
a443 1
	current_ipl_level = ipl;
@


1.2
log
@Tags.
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d372 1
a372 1
		current_ipl_level |= si_to_ipl[(si)];			\
d621 1
a621 1
		current_ipl_level |= iq->iq_irq;
@


1.1
log
@Add support for i80321 based systems.
@
text
@d1 1
@

