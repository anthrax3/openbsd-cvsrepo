head	1.18;
access;
symbols
	OPENBSD_6_2_BASE:1.18
	OPENBSD_6_1:1.16.0.4
	OPENBSD_6_1_BASE:1.16
	OPENBSD_6_0:1.15.0.2
	OPENBSD_6_0_BASE:1.15
	OPENBSD_5_9:1.13.0.2
	OPENBSD_5_9_BASE:1.13
	OPENBSD_5_8:1.11.0.4
	OPENBSD_5_8_BASE:1.11
	OPENBSD_5_7:1.10.0.2
	OPENBSD_5_7_BASE:1.10
	OPENBSD_5_6:1.9.0.4
	OPENBSD_5_6_BASE:1.9
	OPENBSD_5_5:1.8.0.14
	OPENBSD_5_5_BASE:1.8
	OPENBSD_5_4:1.8.0.10
	OPENBSD_5_4_BASE:1.8
	OPENBSD_5_3:1.8.0.8
	OPENBSD_5_3_BASE:1.8
	OPENBSD_5_2:1.8.0.6
	OPENBSD_5_2_BASE:1.8
	OPENBSD_5_1_BASE:1.8
	OPENBSD_5_1:1.8.0.4
	OPENBSD_5_0:1.8.0.2
	OPENBSD_5_0_BASE:1.8
	OPENBSD_4_9:1.7.0.4
	OPENBSD_4_9_BASE:1.7
	OPENBSD_4_8:1.7.0.2
	OPENBSD_4_8_BASE:1.7
	OPENBSD_4_7:1.5.0.10
	OPENBSD_4_7_BASE:1.5
	OPENBSD_4_6:1.5.0.12
	OPENBSD_4_6_BASE:1.5
	OPENBSD_4_5:1.5.0.8
	OPENBSD_4_5_BASE:1.5
	OPENBSD_4_4:1.5.0.6
	OPENBSD_4_4_BASE:1.5
	OPENBSD_4_3:1.5.0.4
	OPENBSD_4_3_BASE:1.5
	OPENBSD_4_2:1.5.0.2
	OPENBSD_4_2_BASE:1.5
	OPENBSD_4_1:1.4.0.2
	OPENBSD_4_1_BASE:1.4
	OPENBSD_3_9:1.1.0.12
	OPENBSD_3_9_BASE:1.1
	OPENBSD_3_8:1.1.0.10
	OPENBSD_3_8_BASE:1.1
	OPENBSD_3_7:1.1.0.8
	OPENBSD_3_7_BASE:1.1
	OPENBSD_3_6:1.1.0.6
	OPENBSD_3_6_BASE:1.1
	SMP_SYNC_A:1.1
	SMP_SYNC_B:1.1
	OPENBSD_3_5:1.1.0.4
	OPENBSD_3_5_BASE:1.1
	SMP:1.1.0.2;
locks; strict;
comment	@ * @;


1.18
date	2017.07.31.11.52.49;	author kettenis;	state Exp;
branches;
next	1.17;
commitid	u5c43uo21Iqte0ho;

1.17
date	2017.05.12.08.53.46;	author mpi;	state Exp;
branches;
next	1.16;
commitid	SyJzHBxYSi45K75D;

1.16
date	2017.01.06.00.06.02;	author jsg;	state Exp;
branches;
next	1.15;
commitid	YCbIRye8xzoWl68V;

1.15
date	2016.05.16.13.18.51;	author jsg;	state Exp;
branches;
next	1.14;
commitid	Dkp7kPJ2l296nqlG;

1.14
date	2016.04.25.08.00.43;	author patrick;	state Exp;
branches;
next	1.13;
commitid	hqPZKbjGBRwTBGv6;

1.13
date	2016.01.31.00.14.50;	author jsg;	state Exp;
branches;
next	1.12;
commitid	pbLjedMudUFrVMk6;

1.12
date	2015.09.12.16.12.50;	author miod;	state Exp;
branches;
next	1.11;
commitid	hqyc6En7noEANxbQ;

1.11
date	2015.06.29.04.16.32;	author jsg;	state Exp;
branches;
next	1.10;
commitid	wAcX33iStalNfYUF;

1.10
date	2014.11.14.09.56.06;	author dlg;	state Exp;
branches;
next	1.9;
commitid	Z3djpPRPe92exHie;

1.9
date	2014.03.29.18.09.28;	author guenther;	state Exp;
branches;
next	1.8;

1.8
date	2011.03.23.16.54.34;	author pirofti;	state Exp;
branches;
next	1.7;

1.7
date	2010.04.22.21.03.17;	author drahn;	state Exp;
branches;
next	1.6;

1.6
date	2010.04.21.03.03.25;	author deraadt;	state Exp;
branches;
next	1.5;

1.5
date	2007.03.17.23.42.06;	author drahn;	state Exp;
branches;
next	1.4;

1.4
date	2007.02.19.17.18.42;	author deraadt;	state Exp;
branches;
next	1.3;

1.3
date	2007.02.06.17.13.33;	author art;	state Exp;
branches;
next	1.2;

1.2
date	2006.07.12.17.26.19;	author miod;	state dead;
branches;
next	1.1;

1.1
date	2004.02.01.05.09.49;	author drahn;	state Exp;
branches
	1.1.2.1;
next	;

1.1.2.1
date	2004.02.19.10.48.01;	author niklas;	state Exp;
branches;
next	;


desc
@@


1.18
log
@Use unsigned long instead of uint32_t, which is the appropriate integer
type for storing pointers in our universe.  Avoids an implicit dependence
on <sys/types.h>.

ok tom@@
@
text
@/*	$OpenBSD: atomic.h,v 1.17 2017/05/12 08:53:46 mpi Exp $	*/

/* Public Domain */

#ifndef _ARM_ATOMIC_H_
#define _ARM_ATOMIC_H_

/*
 * Compare and set:
 * ret = *ptr
 * if (ret == expect)
 * 	*ptr = new
 * return (ret)
 */
#define _def_atomic_cas(_f, _t)					\
static inline _t						\
_f(volatile _t *p, _t e, _t n)					\
{								\
	_t ret, modified;					\
								\
	__asm volatile (					\
	    "1:	ldrex %0, [%4]		\n\t"			\
	    "	cmp %0, %3		\n\t"			\
	    "	bne 2f			\n\t"			\
	    "	strex %1, %2, [%4]	\n\t"			\
	    "	cmp %1, #0		\n\t"			\
	    "	bne 1b			\n\t"			\
	    "	b 3f			\n\t"			\
	    "2:	clrex			\n\t"			\
	    "3:				\n\t"			\
	    : "=&r" (ret), "=&r" (modified)			\
	    : "r" (n), "r" (e), "r" (p)				\
	    : "memory", "cc"					\
	);							\
	return (ret);						\
}
_def_atomic_cas(_atomic_cas_uint, unsigned int)
_def_atomic_cas(_atomic_cas_ulong, unsigned long)
#undef _def_atomic_cas

#define atomic_cas_uint(_p, _e, _n) _atomic_cas_uint((_p), (_e), (_n))
#define atomic_cas_ulong(_p, _e, _n) _atomic_cas_ulong((_p), (_e), (_n))

static inline void *
_atomic_cas_ptr(volatile void *p, void *e, void *n)
{
	void *ret;
	unsigned long modified;

	__asm volatile (
	    "1:	ldrex %0, [%4]		\n\t"
	    "	cmp %0, %3		\n\t"
	    "	bne 2f			\n\t"
	    "	strex %1, %2, [%4]	\n\t"
	    "	cmp %1, #0		\n\t"
	    "	bne 1b			\n\t"
	    "	b 3f			\n\t"
	    "2:	clrex			\n\t"
	    "3:				\n\t"
	    : "=&r" (ret), "=&r" (modified)
	    : "r" (n), "r" (e), "r" (p)
	    : "memory", "cc"
	);
	return (ret);
}
#define atomic_cas_ptr(_p, _e, _n) _atomic_cas_ptr((_p), (_e), (_n))

/*
 * Swap:
 * ret = *p
 * *p = val
 * return (ret)
 */
#define _def_atomic_swap(_f, _t)				\
static inline _t						\
_f(volatile _t *p, _t v)					\
{								\
	_t ret, modified;					\
								\
	__asm volatile (					\
	    "1:	ldrex %0, [%3]		\n\t"			\
	    "	strex %1, %2, [%3]	\n\t"			\
	    "	cmp %1, #0		\n\t"			\
	    "	bne 1b			\n\t"			\
	    : "=&r" (ret), "=&r" (modified)			\
	    : "r" (v), "r" (p)					\
	    : "memory", "cc"					\
	);							\
	return (ret);						\
}
_def_atomic_swap(_atomic_swap_uint, unsigned int)
_def_atomic_swap(_atomic_swap_ulong, unsigned long)
#undef _def_atomic_swap

#define atomic_swap_uint(_p, _v) _atomic_swap_uint((_p), (_v))
#define atomic_swap_ulong(_p, _v) _atomic_swap_ulong((_p), (_v))

static inline void *
_atomic_swap_ptr(volatile void *p, void *v)
{
	void *ret;
	unsigned long modified;

	__asm volatile (
	    "1:	ldrex %0, [%3]		\n\t"
	    "	strex %1, %2, [%3]	\n\t"
	    "	cmp %1, #0		\n\t"
	    "	bne 1b			\n\t"
	    : "=&r" (ret), "=&r" (modified)
	    : "r" (v), "r" (p)
	    : "memory", "cc"
	);
	return (ret);
}
#define atomic_swap_ptr(_p, _v) _atomic_swap_ptr((_p), (_v))

/*
 * Increment returning the new value
 * *p += 1
 * return (*p)
 */
#define _def_atomic_inc_nv(_f, _t)				\
static inline _t						\
_f(volatile _t *p)						\
{								\
	_t ret, modified;					\
								\
	__asm volatile (					\
	   "1:	ldrex %0, [%2]		\n\t"			\
	    "	add %0, %0, #1		\n\t"			\
	    "	strex %1, %0, [%2]	\n\t"			\
	    "	cmp %1, #0		\n\t"			\
	    "	bne 1b			\n\t"			\
	    : "=&r" (ret), "=&r" (modified)			\
	    : "r" (p)						\
	    : "memory", "cc"					\
	);							\
	return (ret);						\
}
_def_atomic_inc_nv(_atomic_inc_int_nv, unsigned int)
_def_atomic_inc_nv(_atomic_inc_long_nv, unsigned long)
#undef _def_atomic_inc_nv

#define atomic_inc_int_nv(_p) _atomic_inc_int_nv((_p))
#define atomic_inc_long_nv(_p) _atomic_inc_long_nv((_p))

/*
 * Decrement returning the new value
 * *p -= 1
 * return (*p)
 */
#define _def_atomic_dec_nv(_f, _t)				\
static inline _t						\
_f(volatile _t *p)						\
{								\
	_t ret, modified;					\
								\
	__asm volatile (					\
	    "1:	ldrex %0, [%2]		\n\t"			\
	    "	sub %0, %0, #1		\n\t"			\
	    "	strex %1, %0, [%2]	\n\t"			\
	    "	cmp %1, #0		\n\t"			\
	    "	bne 1b			\n\t"			\
	    : "=&r" (ret), "=&r" (modified)			\
	    : "r" (p)						\
	    : "memory", "cc"					\
	);							\
	return (ret);						\
}
_def_atomic_dec_nv(_atomic_dec_int_nv, unsigned int)
_def_atomic_dec_nv(_atomic_dec_long_nv, unsigned long)
#undef _def_atomic_dec_nv

#define atomic_dec_int_nv(_p) _atomic_dec_int_nv((_p))
#define atomic_dec_long_nv(_p) _atomic_dec_long_nv((_p))

/*
 * Addition returning the new value
 * *p += v
 * return (*p)
 */
#define _def_atomic_add_nv(_f, _t)				\
static inline _t						\
_f(volatile _t *p, _t v)					\
{								\
	_t ret, modified;					\
								\
	__asm volatile (					\
	    "1:	ldrex %0, [%2]		\n\t"			\
	    "	add %0, %0, %3		\n\t"			\
	    "	strex %1, %0, [%2]	\n\t"			\
	    "	cmp %1, #0		\n\t"			\
	    "	bne 1b			\n\t"			\
	    : "=&r" (ret), "=&r" (modified)			\
	    : "r" (p), "r" (v)					\
	    : "memory", "cc"					\
	);							\
	return (ret);						\
}
_def_atomic_add_nv(_atomic_add_int_nv, unsigned int)
_def_atomic_add_nv(_atomic_add_long_nv, unsigned long)
#undef _def_atomic_add_nv

#define atomic_add_int_nv(_p, _v) _atomic_add_int_nv((_p), (_v))
#define atomic_add_long_nv(_p, _v) _atomic_add_long_nv((_p), (_v))

/*
 * Subtraction returning the new value
 * *p -= v
 * return (*p)
 */
#define _def_atomic_sub_nv(_f, _t)				\
static inline _t						\
_f(volatile _t *p, _t v)					\
{								\
	_t ret, modified;					\
								\
	__asm volatile (					\
	    "1:	ldrex %0, [%2]		\n\t"			\
	    "	sub %0, %0, %3		\n\t"			\
	    "	strex %1, %0, [%2]	\n\t"			\
	    "	cmp %1, #0		\n\t"			\
	    "	bne 1b			\n\t"			\
	    : "=&r" (ret), "=&r" (modified)			\
	    : "r" (p), "r" (v)					\
	    : "memory", "cc"					\
	);							\
	return (ret);						\
}
_def_atomic_sub_nv(_atomic_sub_int_nv, unsigned int)
_def_atomic_sub_nv(_atomic_sub_long_nv, unsigned long)
#undef _def_atomic_sub_nv

#define atomic_sub_int_nv(_p, _v) _atomic_sub_int_nv((_p), (_v))
#define atomic_sub_long_nv(_p, _v) _atomic_sub_long_nv((_p), (_v))

#define __membar(_f) do { __asm __volatile(_f ::: "memory"); } while (0)

#define membar_enter()		__membar("dmb sy")
#define membar_exit()		__membar("dmb sy")
#define membar_producer()	__membar("dmb st")
#define membar_consumer()	__membar("dmb sy")
#define membar_sync()		__membar("dmb sy")

#if defined(_KERNEL)

/* virtio needs MP membars even on SP kernels */
#define virtio_membar_producer()	__membar("dmb st")
#define virtio_membar_consumer()	__membar("dmb sy")
#define virtio_membar_sync()		__membar("dmb sy")

/*
 * Set bits
 * *p = *p | v
 */
static inline void
atomic_setbits_int(volatile unsigned int *p, unsigned int v)
{
	unsigned int modified, tmp;

	__asm volatile (
	    "1:	ldrex %0, [%3]		\n\t"
	    "	orr %0, %0, %2		\n\t"
	    "	strex %1, %0, [%3]	\n\t"
	    "	cmp %1, #0		\n\t"
	    "	bne 1b			\n\t"
	    : "=&r" (tmp), "=&r" (modified)
	    : "r" (v), "r" (p)
	    : "memory", "cc"
	);
}

/*
 * Clear bits
 * *p = *p & (~v)
 */
static inline void
atomic_clearbits_int(volatile unsigned int *p, unsigned int v)
{
	unsigned int modified, tmp;

	__asm volatile (
	    "1:	ldrex %0, [%3]		\n\t"
	    "	bic %0, %0, %2		\n\t"
	    "	strex %1, %0, [%3]	\n\t"
	    "	cmp %1, #0		\n\t"
	    "	bne 1b			\n\t"
	    : "=&r" (tmp), "=&r" (modified)
	    : "r" (v), "r" (p)
	    : "memory", "cc"
	);
}

#endif /* defined(_KERNEL) */
#endif /* _ARM_ATOMIC_H_ */
@


1.17
log
@Make atomic.h ready to be included in userland.

- keep setbits/clearbits and virtio barriers inside _KERNEL
- prefix def_atomic_xxx macros with underscores
@
text
@d1 1
a1 1
/*	$OpenBSD: atomic.h,v 1.16 2017/01/06 00:06:02 jsg Exp $	*/
d48 1
a48 1
	uint32_t modified;
d102 1
a102 1
	uint32_t modified;
@


1.16
log
@unifdef CPU_ARMv7 and ARM_ARCH_7
ok kettenis@@ patrick@@
@
text
@d1 1
a1 1
/*	$OpenBSD: atomic.h,v 1.15 2016/05/16 13:18:51 jsg Exp $	*/
a7 2
#if defined(_KERNEL)

d15 1
a15 1
#define def_atomic_cas(_f, _t)					\
d37 3
a39 3
def_atomic_cas(_atomic_cas_uint, unsigned int)
def_atomic_cas(_atomic_cas_ulong, unsigned long)
#undef def_atomic_cas
d74 1
a74 1
#define def_atomic_swap(_f, _t)					\
d91 3
a93 3
def_atomic_swap(_atomic_swap_uint, unsigned int)
def_atomic_swap(_atomic_swap_ulong, unsigned long)
#undef def_atomic_swap
d122 1
a122 1
#define def_atomic_inc_nv(_f, _t)				\
d140 3
a142 3
def_atomic_inc_nv(_atomic_inc_int_nv, unsigned int)
def_atomic_inc_nv(_atomic_inc_long_nv, unsigned long)
#undef def_atomic_inc_nv
d152 1
a152 1
#define def_atomic_dec_nv(_f, _t)				\
d170 3
a172 3
def_atomic_dec_nv(_atomic_dec_int_nv, unsigned int)
def_atomic_dec_nv(_atomic_dec_long_nv, unsigned long)
#undef def_atomic_dec_nv
d182 1
a182 1
#define def_atomic_add_nv(_f, _t)				\
d200 3
a202 3
def_atomic_add_nv(_atomic_add_int_nv, unsigned int)
def_atomic_add_nv(_atomic_add_long_nv, unsigned long)
#undef def_atomic_add_nv
d212 1
a212 1
#define def_atomic_sub_nv(_f, _t)				\
d230 3
a232 3
def_atomic_sub_nv(_atomic_sub_int_nv, unsigned int)
def_atomic_sub_nv(_atomic_sub_long_nv, unsigned long)
#undef def_atomic_sub_nv
d237 15
a292 12

#define __membar(_f) do { __asm __volatile(_f ::: "memory"); } while (0)

#define membar_enter()		__membar("dmb sy")
#define membar_exit()		__membar("dmb sy")
#define membar_producer()	__membar("dmb st")
#define membar_consumer()	__membar("dmb sy")
#define membar_sync()		__membar("dmb sy")

#define virtio_membar_producer()	__membar("dmb st")
#define virtio_membar_consumer()	__membar("dmb sy")
#define virtio_membar_sync()		__membar("dmb sy")
@


1.15
log
@Implement membar(9) for armv5.  As there are no barrier instructions in
armv5 this is just a "memory" clobber hint to the compiler.

ok kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: atomic.h,v 1.14 2016/04/25 08:00:43 patrick Exp $	*/
a9 187
#if !defined(CPU_ARMv7)

#include <arm/cpufunc.h>
#include <arm/armreg.h>

/*
 * on pre-v6 arm processors, it is necessary to disable interrupts if
 * in the kernel and atomic updates are necessary without full mutexes
 */

static inline unsigned int
_atomic_cas_uint(volatile unsigned int *uip, unsigned int o, unsigned int n)
{
	unsigned int cpsr;
	unsigned int rv;

	cpsr = disable_interrupts(PSR_I|PSR_F);
	rv = *uip;
	if (rv == o)
		*uip = n;
	restore_interrupts(cpsr);

	return (rv);
}
#define atomic_cas_uint(_p, _o, _n) _atomic_cas_uint((_p), (_o), (_n))

static inline unsigned int
_atomic_cas_ulong(volatile unsigned long *uip, unsigned long o, unsigned long n)
{
	unsigned int cpsr;
	unsigned long rv;

	cpsr = disable_interrupts(PSR_I|PSR_F);
	rv = *uip;
	if (rv == o)
		*uip = n;
	restore_interrupts(cpsr);

	return (rv);
}
#define atomic_cas_ulong(_p, _o, _n) _atomic_cas_ulong((_p), (_o), (_n))

static inline void *
_atomic_cas_ptr(volatile void *uip, void *o, void *n)
{
	unsigned int cpsr;
	void * volatile *uipp = (void * volatile *)uip;
	void *rv;

	cpsr = disable_interrupts(PSR_I|PSR_F);
	rv = *uipp;
	if (rv == o)
		*uipp = n;
	restore_interrupts(cpsr);

	return (rv);
}
#define atomic_cas_ptr(_p, _o, _n) _atomic_cas_ptr((_p), (_o), (_n))

static inline unsigned int
_atomic_swap_uint(volatile unsigned int *uip, unsigned int n)
{
	unsigned int cpsr;
	unsigned int rv;

	cpsr = disable_interrupts(PSR_I|PSR_F);
	rv = *uip;
	*uip = n;
	restore_interrupts(cpsr);

	return (rv);
}
#define atomic_swap_uint(_p, _n) _atomic_swap_uint((_p), (_n))

static inline unsigned long
_atomic_swap_ulong(volatile unsigned long *uip, unsigned long n)
{
	unsigned int cpsr;
	unsigned long rv;

	cpsr = disable_interrupts(PSR_I|PSR_F);
	rv = *uip;
	*uip = n;
	restore_interrupts(cpsr);

	return (rv);
}
#define atomic_swap_ulong(_p, _n) _atomic_swap_ulong((_p), (_n))

static inline void *
_atomic_swap_ptr(volatile void *uip, void *n)
{
	unsigned int cpsr;
	void * volatile *uipp = (void * volatile *)uip;
	void *rv;

	cpsr = disable_interrupts(PSR_I|PSR_F);
	rv = *uipp;
	*uipp = n;
	restore_interrupts(cpsr);

	return (rv);
}
#define atomic_swap_ptr(_p, _n) _atomic_swap_ptr((_p), (_n))

static inline unsigned int
_atomic_add_int_nv(volatile unsigned int *uip, unsigned int v)
{
	unsigned int cpsr;
	unsigned int rv;

	cpsr = disable_interrupts(PSR_I|PSR_F);
	rv = *uip + v;
	*uip = rv;
	restore_interrupts(cpsr);

	return (rv);
}
#define atomic_add_int_nv(_p, _v) _atomic_add_int_nv((_p), (_v))

static inline unsigned long
_atomic_add_long_nv(volatile unsigned long *uip, unsigned long v)
{
	unsigned int cpsr;
	unsigned long rv;

	cpsr = disable_interrupts(PSR_I|PSR_F);
	rv = *uip + v;
	*uip = rv;
	restore_interrupts(cpsr);

	return (rv);
}
#define atomic_add_long_nv(_p, _v) _atomic_add_long_nv((_p), (_v))

static inline unsigned int
_atomic_sub_int_nv(volatile unsigned int *uip, unsigned int v)
{
	unsigned int cpsr;
	unsigned int rv;

	cpsr = disable_interrupts(PSR_I|PSR_F);
	rv = *uip - v;
	*uip = rv;
	restore_interrupts(cpsr);

	return (rv);
}
#define atomic_sub_int_nv(_p, _v) _atomic_sub_int_nv((_p), (_v))

static inline unsigned long
_atomic_sub_long_nv(volatile unsigned long *uip, unsigned long v)
{
	unsigned int cpsr;
	unsigned long rv;

	cpsr = disable_interrupts(PSR_I|PSR_F);
	rv = *uip - v;
	*uip = rv;
	restore_interrupts(cpsr);

	return (rv);
}
#define atomic_sub_long_nv(_p, _v) _atomic_sub_long_nv((_p), (_v))

static inline void
atomic_setbits_int(volatile unsigned int *uip, unsigned int v)
{
	unsigned int cpsr;

	cpsr = disable_interrupts(PSR_I|PSR_F);
	*uip |= v;
	restore_interrupts(cpsr);
}

static inline void
atomic_clearbits_int(volatile unsigned int *uip, unsigned int v)
{
	unsigned int cpsr;

	cpsr = disable_interrupts(PSR_I|PSR_F);
	*uip &= ~v;
	restore_interrupts(cpsr);
}

#else /* !CPU_ARMv7 */

a178 1

a279 13
#endif /* CPU_ARMv7 */

#if !defined(CPU_ARMv7)

#define __membar() do { __asm __volatile("" ::: "memory"); } while (0)

#define membar_enter()		__membar()
#define membar_exit()		__membar()
#define membar_producer()	__membar()
#define membar_consumer()	__membar()
#define membar_sync()		__membar()

#else /* !CPU_ARMv7 */
a291 1
#endif /* CPU_ARMv7 */
@


1.14
log
@Implement atomic operations using the atomic instructions available
since ARMv6K.  As we also support ARMs that are older than that,
guard the new atomic operations with an ifdef specifically for ARMv7.

ok jsg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: atomic.h,v 1.13 2016/01/31 00:14:50 jsg Exp $	*/
d468 13
@


1.13
log
@Switch from PSR_X_bit and X32_bit PSR macro names to just PSR_X.
This matches FreeBSD and makes things a bit more consistent.
Discussed with Patrick.
@
text
@d1 1
a1 1
/*	$OpenBSD: atomic.h,v 1.12 2015/09/12 16:12:50 miod Exp $	*/
d10 2
a17 4
*
 * eventually it would be interesting to have these functions
 * support the V6/V7+ atomic instructions ldrex/strex if available
 * on the CPU.
d195 274
a468 1
#if defined(CPU_ARMv7)
@


1.12
log
@Explicitely include <arm/armreg.h> here instead of expecting previously
included files to bring it in.
@
text
@d1 1
a1 1
/*	$OpenBSD: atomic.h,v 1.11 2015/06/29 04:16:32 jsg Exp $	*/
d28 1
a28 1
	cpsr = disable_interrupts(I32_bit|F32_bit);
d44 1
a44 1
	cpsr = disable_interrupts(I32_bit|F32_bit);
d61 1
a61 1
	cpsr = disable_interrupts(I32_bit|F32_bit);
d77 1
a77 1
	cpsr = disable_interrupts(I32_bit|F32_bit);
d92 1
a92 1
	cpsr = disable_interrupts(I32_bit|F32_bit);
d108 1
a108 1
	cpsr = disable_interrupts(I32_bit|F32_bit);
d123 1
a123 1
	cpsr = disable_interrupts(I32_bit|F32_bit);
d138 1
a138 1
	cpsr = disable_interrupts(I32_bit|F32_bit);
d153 1
a153 1
	cpsr = disable_interrupts(I32_bit|F32_bit);
d168 1
a168 1
	cpsr = disable_interrupts(I32_bit|F32_bit);
d182 1
a182 1
	cpsr = disable_interrupts(I32_bit|F32_bit);
d192 1
a192 1
	cpsr = disable_interrupts(I32_bit|F32_bit);
@


1.11
log
@Implement membar_* for armv7 with the dmb instruction.  The previous
sys/sys/atomic.h default of __sync_synchronize() resulted in "dmb sy",
a full system barrier for all memory operations.  With this change
membar_producer() switches to "dmb st" (StoreStore).

earlier version ok rapha@@
@
text
@d1 1
a1 1
/*	$OpenBSD: atomic.h,v 1.10 2014/11/14 09:56:06 dlg Exp $	*/
d11 1
@


1.10
log
@implement the atomic_foo things on arm.

testing and ok jsg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: atomic.h,v 1.9 2014/03/29 18:09:28 guenther Exp $	*/
d195 14
@


1.9
log
@It's been a quarter century: we can assume volatile is present with that name.

ok dlg@@ mpi@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: atomic.h,v 1.8 2011/03/23 16:54:34 pirofti Exp $	*/
d10 2
d15 4
d21 174
a194 2
void atomic_setbits_int(volatile unsigned int *, unsigned int);
void atomic_clearbits_int(volatile unsigned int *, unsigned int);
@


1.8
log
@Normalize sentinel. Use _MACHINE_*_H_ and _<ARCH>_*_H_ properly and consitently.

Discussed and okay drahn@@. Okay deraadt@@.
@
text
@d1 1
a1 1
/*	$OpenBSD: atomic.h,v 1.7 2010/04/22 21:03:17 drahn Exp $	*/
d15 2
a16 2
void atomic_setbits_int(__volatile unsigned int *, unsigned int);
void atomic_clearbits_int(__volatile unsigned int *, unsigned int);
@


1.7
log
@De-inline atomic_setbits_int and atomic_clearbits_int, on arm these functions
are emulated by disabling interrupts which requires a lot more header files
than a simple atomic operation should be need. ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: atomic.h,v 1.6 2010/04/21 03:03:25 deraadt Exp $	*/
d5 2
a6 2
#ifndef __ARM_ATOMIC_H__
#define __ARM_ATOMIC_H__
d19 1
a19 1
#endif /* __ARM_ATOMIC_H__ */
@


1.6
log
@more cleanup to cope with the change that tries to make proc.h not act
like it is everything.h
ok tedu
@
text
@d1 1
a1 1
/*	$OpenBSD: atomic.h,v 1.5 2007/03/17 23:42:06 drahn Exp $	*/
a9 3
#include <arm/armreg.h>
#include <arm/cpufunc.h>

d15 2
a16 17
static __inline void
atomic_setbits_int(__volatile unsigned int *uip, unsigned int v)
{
	int oldirqstate;
	oldirqstate = disable_interrupts(I32_bit|F32_bit);
	*uip |= v;
	restore_interrupts(oldirqstate);
}

static __inline void
atomic_clearbits_int(__volatile unsigned int *uip, unsigned int v)
{
	int oldirqstate;
	oldirqstate = disable_interrupts(I32_bit|F32_bit);
	*uip &= ~v;
	restore_interrupts(oldirqstate);
}
@


1.5
log
@For arm pre-v6 (ie all supported machines) it is necessary to disable
interrupts to be able to have an atomic update of a variable without a mutex.
@
text
@d1 1
a1 1
/*	$OpenBSD: atomic.h,v 1.4 2007/02/19 17:18:42 deraadt Exp $	*/
d9 3
@


1.4
log
@only make this interface available to the kernel for now, discussed witha
rt and such; tested and ok miod drahn
@
text
@d1 1
a1 1
/*	$OpenBSD: atomic.h,v 1.3 2007/02/06 17:13:33 art Exp $	*/
d10 5
d18 2
d21 1
d27 2
d30 1
@


1.3
log
@Add machine/atomic.h to all architectures and define two operations
right now that are supposed to be atomic with respect to interrupts and
SMP: atomic_setbits_int and atomic_clearbits_int.

All architectures other than i386 and amd64 get dummy implementations
since at first we'll be replacing operations that are done with
"a |= bit" and "a &= ~bit" today. More proper implementations will follow

kettenis@@, miod@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d8 2
d22 2
a23 1
#endif
@


1.2
log
@Orphaned stuff.
@
text
@d1 1
a1 2
/*	$OpenBSD: atomic.h,v 1.1 2004/02/01 05:09:49 drahn Exp $	*/
/* $NetBSD: atomic.h,v 1.1 2002/10/19 12:22:34 bsh Exp $ */
d3 1
a3 32
/*
 * Copyright (C) 1994-1997 Mark Brinicombe
 * Copyright (C) 1994 Brini
 * All rights reserved.
 *
 * This code is derived from software written for Brini by Mark Brinicombe
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *	This product includes software developed by Brini.
 * 4. The name of Brini may not be used to endorse or promote products
 *    derived from this software without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY BRINI ``AS IS'' AND ANY EXPRESS OR
 * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
 * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
 * IN NO EVENT SHALL BRINI BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
 * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS;
 * OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
 * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR
 * OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF
 * ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */
d5 2
a6 41
#ifndef	_ARM_ATOMIC_H_
#define	_ARM_ATOMIC_H_

#ifndef ATOMIC_SET_BIT_NONINLINE_REQUIRED

#if defined(__PROG26) || defined(ATOMIC_SET_BIT_NOINLINE)
#define	ATOMIC_SET_BIT_NONINLINE_REQUIRED
#endif

#endif /* ATOMIC_SET_BIT_NONINLINE_REQUIRED */


#ifndef _LOCORE

#include <sys/types.h>
#include <arm/armreg.h>			/* I32_bit */

#ifdef ATOMIC_SET_BIT_NONINLINE_REQUIRED
void atomic_set_bit( u_int *, u_int );
void atomic_clear_bit( u_int *, u_int );
#endif

#ifdef __PROG32
#define __with_interrupts_disabled(expr) \
	do {						\
		u_int cpsr_save, tmp;			\
							\
		__asm __volatile(			\
			"mrs  %0, cpsr;"		\
			"orr  %1, %0, %2;"		\
			"msr  cpsr_all, %1;"		\
			: "=r" (cpsr_save), "=r" (tmp)	\
			: "I" (I32_bit)		\
		        : "cc" );		\
		(expr);				\
		 __asm __volatile(		\
			"msr  cpsr_all, %0"	\
			: /* no output */	\
			: "r" (cpsr_save)	\
			: "cc" );		\
	} while(0)
d9 1
a9 1
inline_atomic_set_bit( u_int *address, u_int setmask )
d11 1
a11 1
	__with_interrupts_disabled( *address |= setmask );
d15 1
a15 1
inline_atomic_clear_bit( u_int *address, u_int clearmask )
d17 1
a17 1
	__with_interrupts_disabled( *address &= ~clearmask );
a19 5
#if !defined(ATOMIC_SET_BIT_NOINLINE)

#define atomic_set_bit(a,m)   inline_atomic_set_bit(a,m)
#define atomic_clear_bit(a,m) inline_atomic_clear_bit(a,m)

a20 7

#endif /* __PROG32 */

#undef __with_interrupts_disabled

#endif /* _LOCORE */
#endif /* _ARM_ATOMIC_H_ */
@


1.1
log
@Arm port, NetBSD codebase stripped down, 32bit only support.
@
text
@d1 1
a1 1
/*	$OpenBSD: atomic.h,v 1.1 2004/01/29 16:17:16 drahn Exp $	*/
@


1.1.2.1
log
@Merge of current from two weeks agointo the SMP branch
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
@

