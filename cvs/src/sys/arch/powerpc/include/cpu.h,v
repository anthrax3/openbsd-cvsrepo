head	1.63;
access;
symbols
	OPENBSD_6_2:1.63.0.4
	OPENBSD_6_2_BASE:1.63
	OPENBSD_6_1:1.63.0.6
	OPENBSD_6_1_BASE:1.63
	OPENBSD_6_0:1.63.0.2
	OPENBSD_6_0_BASE:1.63
	OPENBSD_5_9:1.62.0.2
	OPENBSD_5_9_BASE:1.62
	OPENBSD_5_8:1.62.0.4
	OPENBSD_5_8_BASE:1.62
	OPENBSD_5_7:1.60.0.2
	OPENBSD_5_7_BASE:1.60
	OPENBSD_5_6:1.53.0.4
	OPENBSD_5_6_BASE:1.53
	OPENBSD_5_5:1.51.0.6
	OPENBSD_5_5_BASE:1.51
	OPENBSD_5_4:1.51.0.2
	OPENBSD_5_4_BASE:1.51
	OPENBSD_5_3:1.50.0.2
	OPENBSD_5_3_BASE:1.50
	OPENBSD_5_2:1.46.0.8
	OPENBSD_5_2_BASE:1.46
	OPENBSD_5_1_BASE:1.46
	OPENBSD_5_1:1.46.0.6
	OPENBSD_5_0:1.46.0.4
	OPENBSD_5_0_BASE:1.46
	OPENBSD_4_9:1.46.0.2
	OPENBSD_4_9_BASE:1.46
	OPENBSD_4_8:1.45.0.4
	OPENBSD_4_8_BASE:1.45
	OPENBSD_4_7:1.45.0.2
	OPENBSD_4_7_BASE:1.45
	OPENBSD_4_6:1.44.0.4
	OPENBSD_4_6_BASE:1.44
	OPENBSD_4_5:1.42.0.2
	OPENBSD_4_5_BASE:1.42
	OPENBSD_4_4:1.38.0.2
	OPENBSD_4_4_BASE:1.38
	OPENBSD_4_3:1.32.0.2
	OPENBSD_4_3_BASE:1.32
	OPENBSD_4_2:1.31.0.2
	OPENBSD_4_2_BASE:1.31
	OPENBSD_4_1:1.28.0.2
	OPENBSD_4_1_BASE:1.28
	OPENBSD_4_0:1.27.0.4
	OPENBSD_4_0_BASE:1.27
	OPENBSD_3_9:1.27.0.2
	OPENBSD_3_9_BASE:1.27
	OPENBSD_3_8:1.21.0.4
	OPENBSD_3_8_BASE:1.21
	OPENBSD_3_7:1.21.0.2
	OPENBSD_3_7_BASE:1.21
	OPENBSD_3_6:1.19.0.2
	OPENBSD_3_6_BASE:1.19
	SMP_SYNC_A:1.18
	SMP_SYNC_B:1.18
	OPENBSD_3_5:1.18.0.2
	OPENBSD_3_5_BASE:1.18
	OPENBSD_3_4:1.16.0.2
	OPENBSD_3_4_BASE:1.16
	UBC_SYNC_A:1.13
	OPENBSD_3_3:1.13.0.4
	OPENBSD_3_3_BASE:1.13
	OPENBSD_3_2:1.13.0.2
	OPENBSD_3_2_BASE:1.13
	OPENBSD_3_1:1.9.0.2
	OPENBSD_3_1_BASE:1.9
	UBC_SYNC_B:1.13
	UBC:1.8.0.4
	UBC_BASE:1.8
	OPENBSD_3_0:1.8.0.2
	OPENBSD_3_0_BASE:1.8
	OPENBSD_2_9:1.5.0.2
	OPENBSD_2_9_BASE:1.5
	OPENBSD_2_8:1.3.0.16
	OPENBSD_2_8_BASE:1.3
	OPENBSD_2_7:1.3.0.14
	OPENBSD_2_7_BASE:1.3
	SMP:1.3.0.12
	SMP_BASE:1.3
	kame_19991208:1.3
	OPENBSD_2_6:1.3.0.10
	OPENBSD_2_6_BASE:1.3
	OPENBSD_2_5:1.3.0.8
	OPENBSD_2_5_BASE:1.3
	OPENBSD_2_4:1.3.0.6
	OPENBSD_2_4_BASE:1.3
	OPENBSD_2_3:1.3.0.4
	OPENBSD_2_3_BASE:1.3
	OPENBSD_2_2:1.3.0.2
	OPENBSD_2_2_BASE:1.3
	OPENBSD_2_1:1.2.0.2
	OPENBSD_2_1_BASE:1.2
	powerpc_1:1.1.1.1;
locks; strict;
comment	@ * @;


1.63
date	2016.05.07.22.46.54;	author kettenis;	state Exp;
branches;
next	1.62;
commitid	YWkdWeWRIs0mDVt4;

1.62
date	2015.07.02.01.33.59;	author dlg;	state Exp;
branches;
next	1.61;
commitid	HBmwORlhlW47BLMN;

1.61
date	2015.03.31.16.00.38;	author mpi;	state Exp;
branches;
next	1.60;
commitid	MMWnK4Mn4W58afQM;

1.60
date	2015.02.11.07.05.39;	author dlg;	state Exp;
branches;
next	1.59;
commitid	JTpbkhDknrIuy9pn;

1.59
date	2015.01.04.13.01.42;	author mpi;	state Exp;
branches;
next	1.58;
commitid	NhpbICTczAMSUxav;

1.58
date	2014.10.10.04.08.11;	author mpi;	state Exp;
branches;
next	1.57;
commitid	Dz3LFRntpRMXzobA;

1.57
date	2014.10.08.10.12.41;	author mpi;	state Exp;
branches;
next	1.56;
commitid	744ecbjJTf8RMATb;

1.56
date	2014.09.06.10.45.29;	author mpi;	state Exp;
branches;
next	1.55;
commitid	psPuYzRRUiGpyp76;

1.55
date	2014.09.06.10.15.52;	author mpi;	state Exp;
branches;
next	1.54;
commitid	RzNS2F7j0UQHdMTX;

1.54
date	2014.09.06.09.22.40;	author mpi;	state Exp;
branches;
next	1.53;
commitid	IsbdFINYLL0WOhn8;

1.53
date	2014.07.11.10.53.07;	author uebayasi;	state Exp;
branches;
next	1.52;
commitid	CaCLs5fTSVpJlqFi;

1.52
date	2014.03.29.18.09.30;	author guenther;	state Exp;
branches;
next	1.51;

1.51
date	2013.03.12.09.37.16;	author mpi;	state Exp;
branches;
next	1.50;

1.50
date	2013.02.12.08.06.22;	author mpi;	state Exp;
branches;
next	1.49;

1.49
date	2013.02.11.17.05.25;	author mpi;	state Exp;
branches;
next	1.48;

1.48
date	2012.12.08.12.49.00;	author mpi;	state Exp;
branches;
next	1.47;

1.47
date	2012.12.02.07.03.31;	author guenther;	state Exp;
branches;
next	1.46;

1.46
date	2010.09.28.20.27.55;	author miod;	state Exp;
branches;
next	1.45;

1.45
date	2009.08.24.21.44.21;	author dms;	state Exp;
branches;
next	1.44;

1.44
date	2009.03.26.17.24.33;	author oga;	state Exp;
branches;
next	1.43;

1.43
date	2009.03.15.20.07.14;	author miod;	state Exp;
branches;
next	1.42;

1.42
date	2008.11.22.14.42.29;	author art;	state Exp;
branches;
next	1.41;

1.41
date	2008.10.15.23.23.49;	author deraadt;	state Exp;
branches;
next	1.40;

1.40
date	2008.10.10.08.05.45;	author art;	state Exp;
branches;
next	1.39;

1.39
date	2008.09.16.04.20.42;	author drahn;	state Exp;
branches;
next	1.38;

1.38
date	2008.07.18.23.43.31;	author art;	state Exp;
branches;
next	1.37;

1.37
date	2008.05.04.20.54.22;	author drahn;	state Exp;
branches;
next	1.36;

1.36
date	2008.05.01.08.25.32;	author kettenis;	state Exp;
branches;
next	1.35;

1.35
date	2008.04.29.04.08.25;	author drahn;	state Exp;
branches;
next	1.34;

1.34
date	2008.04.27.15.59.49;	author drahn;	state Exp;
branches;
next	1.33;

1.33
date	2008.04.26.22.37.41;	author drahn;	state Exp;
branches;
next	1.32;

1.32
date	2007.12.04.22.36.39;	author kettenis;	state Exp;
branches;
next	1.31;

1.31
date	2007.03.23.21.06.05;	author miod;	state Exp;
branches;
next	1.30;

1.30
date	2007.03.20.20.59.53;	author kettenis;	state Exp;
branches;
next	1.29;

1.29
date	2007.03.15.10.22.29;	author art;	state Exp;
branches;
next	1.28;

1.28
date	2006.11.29.12.26.13;	author miod;	state Exp;
branches;
next	1.27;

1.27
date	2006.02.10.21.27.22;	author kettenis;	state Exp;
branches;
next	1.26;

1.26
date	2005.11.26.22.40.30;	author kettenis;	state Exp;
branches;
next	1.25;

1.25
date	2005.11.13.21.46.03;	author drahn;	state Exp;
branches;
next	1.24;

1.24
date	2005.11.08.20.30.47;	author kettenis;	state Exp;
branches;
next	1.23;

1.23
date	2005.10.22.09.19.18;	author kettenis;	state Exp;
branches;
next	1.22;

1.22
date	2005.10.01.19.55.25;	author drahn;	state Exp;
branches;
next	1.21;

1.21
date	2005.03.10.19.24.30;	author otto;	state Exp;
branches;
next	1.20;

1.20
date	2004.11.18.16.10.08;	author miod;	state Exp;
branches;
next	1.19;

1.19
date	2004.06.13.21.49.19;	author niklas;	state Exp;
branches;
next	1.18;

1.18
date	2004.02.14.15.09.22;	author grange;	state Exp;
branches;
next	1.17;

1.17
date	2003.12.24.00.25.42;	author drahn;	state Exp;
branches;
next	1.16;

1.16
date	2003.07.08.21.46.19;	author drahn;	state Exp;
branches;
next	1.15;

1.15
date	2003.07.02.21.30.12;	author drahn;	state Exp;
branches;
next	1.14;

1.14
date	2003.07.02.21.23.35;	author drahn;	state Exp;
branches;
next	1.13;

1.13
date	2002.09.15.09.01.59;	author deraadt;	state Exp;
branches;
next	1.12;

1.12
date	2002.09.15.02.02.44;	author deraadt;	state Exp;
branches;
next	1.11;

1.11
date	2002.06.08.15.45.32;	author miod;	state Exp;
branches;
next	1.10;

1.10
date	2002.06.07.21.33.43;	author nordin;	state Exp;
branches;
next	1.9;

1.9
date	2002.03.14.01.26.41;	author millert;	state Exp;
branches;
next	1.8;

1.8
date	2001.09.01.15.49.05;	author drahn;	state Exp;
branches
	1.8.4.1;
next	1.7;

1.7
date	2001.07.09.01.35.32;	author mickey;	state Exp;
branches;
next	1.6;

1.6
date	2001.06.24.04.43.04;	author drahn;	state Exp;
branches;
next	1.5;

1.5
date	2001.01.24.21.29.12;	author drahn;	state Exp;
branches;
next	1.4;

1.4
date	2001.01.15.19.50.39;	author deraadt;	state Exp;
branches;
next	1.3;

1.3
date	97.10.13.10.53.42;	author pefo;	state Exp;
branches
	1.3.12.1;
next	1.2;

1.2
date	96.12.28.06.25.03;	author rahnds;	state Exp;
branches;
next	1.1;

1.1
date	96.12.21.20.35.53;	author rahnds;	state Exp;
branches
	1.1.1.1;
next	;

1.1.1.1
date	96.12.21.20.35.53;	author rahnds;	state Exp;
branches;
next	;

1.3.12.1
date	2001.04.18.16.13.01;	author niklas;	state Exp;
branches;
next	1.3.12.2;

1.3.12.2
date	2001.07.04.10.22.20;	author niklas;	state Exp;
branches;
next	1.3.12.3;

1.3.12.3
date	2001.10.31.03.07.55;	author nate;	state Exp;
branches;
next	1.3.12.4;

1.3.12.4
date	2001.11.13.22.14.34;	author niklas;	state dead;
branches;
next	1.3.12.5;

1.3.12.5
date	2002.03.29.16.11.59;	author niklas;	state Exp;
branches;
next	1.3.12.6;

1.3.12.6
date	2003.03.27.23.42.35;	author niklas;	state Exp;
branches;
next	1.3.12.7;

1.3.12.7
date	2004.02.19.10.49.57;	author niklas;	state Exp;
branches;
next	1.3.12.8;

1.3.12.8
date	2004.06.05.23.10.56;	author niklas;	state Exp;
branches;
next	1.3.12.9;

1.3.12.9
date	2004.06.06.05.23.39;	author tedu;	state Exp;
branches;
next	;

1.8.4.1
date	2002.06.11.03.37.28;	author art;	state Exp;
branches;
next	1.8.4.2;

1.8.4.2
date	2002.10.29.00.28.08;	author art;	state Exp;
branches;
next	;


desc
@@


1.63
log
@Flush page (through the direct map) before mapping it into AGP.  Fixes
artifacts seen in X on some G5 machines.  Unfortunately not enough to fix
G4 machines.  With help from Marcus Glocker.

ok mpi@@
@
text
@/*	$OpenBSD: cpu.h,v 1.62 2015/07/02 01:33:59 dlg Exp $	*/
/*	$NetBSD: cpu.h,v 1.1 1996/09/30 16:34:21 ws Exp $	*/

/*
 * Copyright (C) 1995, 1996 Wolfgang Solfrank.
 * Copyright (C) 1995, 1996 TooLs GmbH.
 * All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *	This product includes software developed by TooLs GmbH.
 * 4. The name of TooLs GmbH may not be used to endorse or promote products
 *    derived from this software without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY TOOLS GMBH ``AS IS'' AND ANY EXPRESS OR
 * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
 * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
 * IN NO EVENT SHALL TOOLS GMBH BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
 * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS;
 * OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
 * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR
 * OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF
 * ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */
#ifndef	_POWERPC_CPU_H_
#define	_POWERPC_CPU_H_

#include <machine/frame.h>

#include <sys/device.h>
#include <sys/sched.h>

struct cpu_info {
	struct device *ci_dev;		/* our device */
	struct schedstate_percpu ci_schedstate; /* scheduler state */

	struct proc *ci_curproc;

	struct pcb *ci_curpcb;
	struct pmap *ci_curpm;
	struct proc *ci_fpuproc;
	struct proc *ci_vecproc;
	int ci_cpuid;

	volatile int ci_want_resched;
	volatile int ci_cpl;
	volatile int ci_ipending;

	volatile int	ci_flags;
#define	CI_FLAGS_SLEEPING		2

#if defined(MULTIPROCESSOR)
	struct srp_hazard ci_srp_hazards[SRP_HAZARD_NUM];
#endif

	int ci_intrdepth;
	char *ci_intstk;
#define CPUSAVE_LEN	8
	register_t ci_tempsave[CPUSAVE_LEN];
	register_t ci_ddbsave[CPUSAVE_LEN];
#define DISISAVE_LEN	4
	register_t ci_disisave[DISISAVE_LEN];

	volatile u_int64_t ci_nexttimerevent;
	volatile u_int64_t ci_prevtb;
	volatile u_int64_t ci_lasttb;
	volatile u_int64_t ci_nextstatevent;
	int ci_statspending;

	volatile int    ci_ddb_paused;
#define	CI_DDB_RUNNING	0
#define	CI_DDB_SHOULDSTOP	1
#define	CI_DDB_STOPPED		2
#define	CI_DDB_ENTERDDB		3
#define	CI_DDB_INDDB		4

	u_int32_t ci_randseed;

#ifdef DIAGNOSTIC
	int	ci_mutex_level;
#endif
#ifdef GPROF
	struct gmonparam *ci_gmon;
#endif
};

static __inline struct cpu_info *
curcpu(void)
{
	struct cpu_info *ci;

	__asm volatile ("mfsprg %0,0" : "=r"(ci));
	return ci;
}

#define	curpcb			(curcpu()->ci_curpcb)
#define	curpm			(curcpu()->ci_curpm)

#define CPU_INFO_UNIT(ci)	((ci)->ci_dev ? (ci)->ci_dev->dv_unit : 0)

#ifdef MULTIPROCESSOR

#define PPC_MAXPROCS		4

static __inline int
cpu_number(void)
{
	int pir;

	pir = curcpu()->ci_cpuid;
	return pir;
}

void	cpu_boot_secondary_processors(void);

#define CPU_IS_PRIMARY(ci)	((ci)->ci_cpuid == 0)
#define CPU_INFO_ITERATOR		int
#define CPU_INFO_FOREACH(cii, ci)					\
	for (cii = 0, ci = &cpu_info[0]; cii < ncpusfound; cii++, ci++)

void cpu_unidle(struct cpu_info *);

#else

#define PPC_MAXPROCS		1

#define cpu_number()		0

#define CPU_IS_PRIMARY(ci)	1
#define CPU_INFO_ITERATOR		int
#define CPU_INFO_FOREACH(cii, ci)					\
	for (cii = 0, ci = curcpu(); ci != NULL; ci = NULL)

#define cpu_unidle(ci)

#endif

#define CPU_BUSY_CYCLE()	do {} while (0)

#define MAXCPUS	PPC_MAXPROCS

extern struct cpu_info cpu_info[PPC_MAXPROCS];

#define	CLKF_USERMODE(frame)	(((frame)->srr1 & PSL_PR) != 0)
#define	CLKF_PC(frame)		((frame)->srr0)
#define	CLKF_INTR(frame)	((frame)->depth != 0)

extern int ppc_cpuidle;
extern int ppc_proc_is_64b;
extern int ppc_nobat;

void	cpu_bootstrap(void);

/*
 * This is used during profiling to integrate system time.
 */
#define	PROC_PC(p)		(trapframe(p)->srr0)
#define	PROC_STACK(p)		(trapframe(p)->fixreg[1])

void	delay(unsigned);
#define	DELAY(n)		delay(n)

#define	aston(p)		((p)->p_md.md_astpending = 1)

/*
 * Preempt the current process if in interrupt from user mode,
 * or after the current trap/syscall if in system mode.
 */
#define	need_resched(ci) \
do {									\
	ci->ci_want_resched = 1;					\
	if (ci->ci_curproc != NULL)					\
		aston(ci->ci_curproc);					\
} while (0)
#define clear_resched(ci) (ci)->ci_want_resched = 0

#define	need_proftick(p)	aston(p)

void	signotify(struct proc *);

extern char *bootpath;

#ifndef	CACHELINESIZE
#define	CACHELINESIZE	32			/* For now		XXX */
#endif

static __inline void
syncicache(void *from, int len)
{
	int l;
	char *p = from;

	len = len + (((u_int32_t) from) & (CACHELINESIZE - 1));
	l = len;

	do {
		__asm volatile ("dcbst 0,%0" :: "r"(p));
		p += CACHELINESIZE;
	} while ((l -= CACHELINESIZE) > 0);
	__asm volatile ("sync");
	p = from;
	l = len;
	do {
		__asm volatile ("icbi 0,%0" :: "r"(p));
		p += CACHELINESIZE;
	} while ((l -= CACHELINESIZE) > 0);
	__asm volatile ("isync");
}

static __inline void
invdcache(void *from, int len)
{
	int l;
	char *p = from;

	len = len + (((u_int32_t) from) & (CACHELINESIZE - 1));
	l = len;

	do {
		__asm volatile ("dcbi 0,%0" :: "r"(p));
		p += CACHELINESIZE;
	} while ((l -= CACHELINESIZE) > 0);
	__asm volatile ("sync");
}

static __inline void
flushdcache(void *from, int len)
{
	int l;
	char *p = from;

	len = len + (((u_int32_t) from) & (CACHELINESIZE - 1));
	l = len;

	do {
		__asm volatile ("dcbf 0,%0" :: "r"(p));
		p += CACHELINESIZE;
	} while ((l -= CACHELINESIZE) > 0);
	__asm volatile ("sync");
}

#define FUNC_SPR(n, name) \
static __inline u_int32_t ppc_mf ## name (void)			\
{								\
	u_int32_t ret;						\
	__asm volatile ("mfspr %0," # n : "=r" (ret));		\
	return ret;						\
}								\
static __inline void ppc_mt ## name (u_int32_t val)		\
{								\
	__asm volatile ("mtspr "# n ",%0" :: "r" (val));	\
}								\

FUNC_SPR(0, mq)
FUNC_SPR(1, xer)
FUNC_SPR(4, rtcu)
FUNC_SPR(5, rtcl)
FUNC_SPR(8, lr)
FUNC_SPR(9, ctr)
FUNC_SPR(18, dsisr)
FUNC_SPR(19, dar)
FUNC_SPR(22, dec)
FUNC_SPR(25, sdr1)
FUNC_SPR(26, srr0)
FUNC_SPR(27, srr1)
FUNC_SPR(256, vrsave)
FUNC_SPR(272, sprg0)
FUNC_SPR(273, sprg1)
FUNC_SPR(274, sprg2)
FUNC_SPR(275, sprg3)
FUNC_SPR(280, asr)
FUNC_SPR(282, ear)
FUNC_SPR(287, pvr)
FUNC_SPR(311, hior)
FUNC_SPR(528, ibat0u)
FUNC_SPR(529, ibat0l)
FUNC_SPR(530, ibat1u)
FUNC_SPR(531, ibat1l)
FUNC_SPR(532, ibat2u)
FUNC_SPR(533, ibat2l)
FUNC_SPR(534, ibat3u)
FUNC_SPR(535, ibat3l)
FUNC_SPR(560, ibat4u)
FUNC_SPR(561, ibat4l)
FUNC_SPR(562, ibat5u)
FUNC_SPR(563, ibat5l)
FUNC_SPR(564, ibat6u)
FUNC_SPR(565, ibat6l)
FUNC_SPR(566, ibat7u)
FUNC_SPR(567, ibat7l)
FUNC_SPR(536, dbat0u)
FUNC_SPR(537, dbat0l)
FUNC_SPR(538, dbat1u)
FUNC_SPR(539, dbat1l)
FUNC_SPR(540, dbat2u)
FUNC_SPR(541, dbat2l)
FUNC_SPR(542, dbat3u)
FUNC_SPR(543, dbat3l)
FUNC_SPR(568, dbat4u)
FUNC_SPR(569, dbat4l)
FUNC_SPR(570, dbat5u)
FUNC_SPR(571, dbat5l)
FUNC_SPR(572, dbat6u)
FUNC_SPR(573, dbat6l)
FUNC_SPR(574, dbat7u)
FUNC_SPR(575, dbat7l)
FUNC_SPR(1009, hid1)
FUNC_SPR(1010, iabr)
FUNC_SPR(1017, l2cr)
FUNC_SPR(1018, l3cr)
FUNC_SPR(1013, dabr)
FUNC_SPR(1023, pir)

static __inline u_int32_t
ppc_mftbl (void)
{
	int ret;
	__asm volatile ("mftb %0" : "=r" (ret));
	return ret;
}


static __inline u_int64_t
ppc_mftb(void)
{
	u_long scratch;
	u_int64_t tb;

	__asm volatile ("1: mftbu %0; mftb %0+1; mftbu %1;"
	    " cmpw 0,%0,%1; bne 1b" : "=r"(tb), "=r"(scratch));
	return tb;
}

static __inline void
ppc_mttb(u_int64_t tb)
{
	__asm volatile ("mttbl %0" :: "r"(0));
	__asm volatile ("mttbu %0" :: "r"((u_int32_t)(tb >> 32)));
	__asm volatile ("mttbl %0" :: "r"((u_int32_t)(tb & 0xffffffff)));
}

static __inline u_int32_t
ppc_mfmsr (void)
{
	int ret;
        __asm volatile ("mfmsr %0" : "=r" (ret));
	return ret;
}

static __inline void
ppc_mtmsr (u_int32_t val)
{
        __asm volatile ("mtmsr %0" :: "r" (val));
}

static __inline void
ppc_mtsrin(u_int32_t val, u_int32_t sn_shifted)
{
	__asm volatile ("mtsrin %0,%1" :: "r"(val), "r"(sn_shifted));
}

u_int64_t ppc64_mfscomc(void);
void ppc_mtscomc(u_int32_t);
void ppc64_mtscomc(u_int64_t);
u_int64_t ppc64_mfscomd(void);
void ppc_mtscomd(u_int32_t);
u_int32_t ppc_mfhid0(void);
void ppc_mthid0(u_int32_t);
u_int64_t ppc64_mfhid1(void);
void ppc64_mthid1(u_int64_t);
u_int64_t ppc64_mfhid4(void);
void ppc64_mthid4(u_int64_t);
u_int64_t ppc64_mfhid5(void);
void ppc64_mthid5(u_int64_t);

#include <machine/psl.h>

/*
 * General functions to enable and disable interrupts
 * without having inlined assembly code in many functions.
 */
static __inline void
ppc_intr_enable(int enable)
{
	u_int32_t msr;
	if (enable != 0) {
		msr = ppc_mfmsr();
		msr |= PSL_EE;
		ppc_mtmsr(msr);
	}
}

static __inline int
ppc_intr_disable(void)
{
	u_int32_t emsr, dmsr;
	emsr = ppc_mfmsr();
	dmsr = emsr & ~PSL_EE;
	ppc_mtmsr(dmsr);
	return (emsr & PSL_EE);
}

int ppc_cpuspeed(int *);

/*
 * PowerPC CPU types
 */
#define	PPC_CPU_MPC601		1
#define	PPC_CPU_MPC603		3
#define	PPC_CPU_MPC604		4
#define	PPC_CPU_MPC603e		6
#define	PPC_CPU_MPC603ev	7
#define	PPC_CPU_MPC750		8
#define	PPC_CPU_MPC604ev	9
#define	PPC_CPU_MPC7400		12
#define	PPC_CPU_IBM970		0x0039
#define	PPC_CPU_IBM970FX	0x003c
#define	PPC_CPU_IBM970MP	0x0044
#define	PPC_CPU_IBM750FX	0x7000
#define	PPC_CPU_MPC7410		0x800c
#define	PPC_CPU_MPC7447A	0x8003
#define	PPC_CPU_MPC7448		0x8004
#define	PPC_CPU_MPC7450		0x8000
#define	PPC_CPU_MPC7455		0x8001
#define	PPC_CPU_MPC7457		0x8002
#define	PPC_CPU_MPC83xx		0x8083

/*
 * This needs to be included late since it relies on definitions higher
 * up in this file.
 */
#if defined(MULTIPROCESSOR) && defined(_KERNEL)
#include <sys/mplock.h>
#endif

#endif	/* _POWERPC_CPU_H_ */
@


1.62
log
@introduce srp, which according to the manpage i wrote is short for
"shared reference pointers".

srp allows concurrent access to a data structure by multiple cpus
while avoiding interlocking cpu opcodes. it manages its own reference
counts and the garbage collection of those data structure to avoid
use after frees.

internally srp is a twisted version of hazard pointers, which are
a relative of RCU.

jmatthew wrote the bulk of a hazard pointer implementation and
changed bpf to use it to allow mpsafe access to bpfilters. however,
at s2k15 we were trying to apply it to other data structures but
the memory overhead of every hazard pointer would have blown out
significantly in several uses cases. a bulk of our time at s2k15
was spent reworking hazard pointers into srp.

this diff adds the srp api and adds the necessary metadata to struct
cpuinfo on our MP architectures. srp on uniprocessor platforms has
alternate code that is optimised because it knows there'll be no
concurrent access to data by multiple cpus.

srp is made available to the system via param.h, so it should be
available everywhere in the kernel.

the docs likely need improvement cos im too close to the implementation.

ok mpi@@
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.61 2015/03/31 16:00:38 mpi Exp $	*/
d230 16
@


1.61
log
@Make it possisble to disable block address translation mechanism on
processors that support it.

Due to the way trap code is patched it is currently not possible to
enabled/disable BAT at runtime.

ok miod@@, kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.60 2015/02/11 07:05:39 dlg Exp $	*/
d60 4
@


1.60
log
@no md code wants lockmgr locks, so no md code needs to include sys/lock.h

with and ok miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.59 2015/01/04 13:01:42 mpi Exp $	*/
d153 6
a158 1
extern	int ppc_cpuidle;
a392 2
void ppc_check_procid(void);
extern int ppc_proc_is_64b;
d415 1
@


1.59
log
@Implement splassert(9) for powerpc.

This changes the logic to prevent a recursion when processing soft
interrupts.  Previously a per-CPU flag was set before re-enabling
interrupts.  Now the IPL level is raised to SOFTTTY which makes
splsoftassert() happy, greatly inspired by mips64.

As a side effect, the ppc_intr_{disable,enable}() dance is now done
only once instead of twice per splx(9).

While here, make use of dosoftint() instead of having 3 different
functions for dispatching soft interrupts.

Tested by deraadt@@ on G4 smp and by myself G5 smp, G3, G4 and socppc.

No objection from the usual (and over busy) suspects.
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.58 2014/10/10 04:08:11 mpi Exp $	*/
a39 1
#include <sys/lock.h>
@


1.58
log
@
Make CPU_INFO_FOREACH useable before secondary CPUs are started.

ok deraadt@@, mlarkin@@
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.57 2014/10/08 10:12:41 mpi Exp $	*/
a59 1
#define	CI_FLAGS_PROCESSING_SOFT	1
@


1.57
log
@Introduce ppc_mttb() and use it instead of rerolling the move to time
base dance in inline assembly in various places.

tweak and ok miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.56 2014/09/06 10:45:29 mpi Exp $	*/
d126 1
a126 1
	for (cii = 0, ci = &cpu_info[0]; cii < ncpus; cii++, ci++)
@


1.56
log
@Rename ci_iactive into ci_flags, this field now holds the going-to-
sleep bit.
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.55 2014/09/06 10:15:52 mpi Exp $	*/
d308 1
d318 8
@


1.55
log
@Rewrite cpu_idle & friends to not check and update the hid0 register
in the idle loop, in preparation for G5 support.

Only do a disable/enable interrupt dance if the running CPU supports a
sleep mode.

Fix entering ddb(8) from interrupt context by not modifying the return
address of the 'forced' trap frame.

While here, modify the existing logic to terminate prefetching of all
data streams if AltiVec is supported before setting the POW bit.

With inputs/explanations from drahn, looks ok to miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.54 2014/09/06 09:22:40 mpi Exp $	*/
a56 3
	volatile int ci_iactive;
#define		CI_IACTIVE_PROCESSING_SOFT	1
#define		CI_IACTIVE_SLEEPING		2
d58 4
@


1.54
log
@Add functions to manipulate IBM PowerPC 970 specific registers that
will be used in upcoming MP and idle support.

ok miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.53 2014/07/11 10:53:07 uebayasi Exp $	*/
d59 1
a59 1
#define		CI_IACTIVE_PROCESSING_HARD	2
d154 1
@


1.53
log
@CPU_BUSY_CYCLE(): A new MI statement for busy loop power reduction

The new CPU_BUSY_CYCLE() may be put in a busy loop body so that CPU can reduce
power consumption, as Linux's cpu_relax() and FreeBSD's cpu_spinwait().  To
start minimally, use PAUSE on i386/amd64 and empty on others.  The name is
chosen following the existing cpu_idle_*() functions.  Naming and API may be
polished later.

OK kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d258 1
a290 1
FUNC_SPR(1008, hid0)
d342 8
@


1.52
log
@It's been a quarter century: we can assume volatile is present with that name.

ok dlg@@ mpi@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.51 2013/03/12 09:37:16 mpi Exp $	*/
d143 2
@


1.51
log
@Fix kernel profiling on MP systems by using per-CPU buffers and teach
kgmon(8) to deal with them, this time without public header changes.

Previously various CPUs were iterating over the same global buffer at
the same time to modify it and never ended.

This diff includes some ideas submited by Thor Simon to NetBSD via miod@@.

ok deraadt@@, mikeb@@, haesbaert@@
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.50 2013/02/12 08:06:22 mpi Exp $	*/
d195 1
a195 1
		__asm __volatile ("dcbst 0,%0" :: "r"(p));
d198 1
a198 1
	__asm __volatile ("sync");
d202 1
a202 1
		__asm __volatile ("icbi 0,%0" :: "r"(p));
d205 1
a205 1
	__asm __volatile ("isync");
d218 1
a218 1
		__asm __volatile ("dcbi 0,%0" :: "r"(p));
d221 1
a221 1
	__asm __volatile ("sync");
d228 1
a228 1
	__asm __volatile ("mfspr %0," # n : "=r" (ret));	\
d233 1
a233 1
	__asm __volatile ("mtspr "# n ",%0" :: "r" (val));	\
d300 1
a300 1
	__asm __volatile ("mftb %0" : "=r" (ret));
d310 1
a310 1
	__asm __volatile ("1: mftbu %0; mftb %0+1; mftbu %1;"
d319 1
a319 1
        __asm __volatile ("mfmsr %0" : "=r" (ret));
d326 1
a326 1
        __asm __volatile ("mtmsr %0" :: "r" (val));
d332 1
a332 1
	__asm __volatile ("mtsrin %0,%1" :: "r"(val), "r"(sn_shifted));
@


1.50
log
@Back out per-CPU kernel profiling, it shouldn't modify a public header
at this moment.
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.49 2013/02/11 17:05:25 mpi Exp $	*/
d87 3
@


1.49
log
@Fix kernel profiling on MP systems by using per-CPU buffer. Previously
various CPUs were iterating over the same global buffer at the same
time to modify it and never ended.

This diff includes some ideas submited by Thor Simon to NetBSD via miod@@.

ok mikeb@@, haesbaert@@
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.48 2012/12/08 12:49:00 mpi Exp $	*/
a86 3
#endif
#ifdef GPROF
	struct gmonparam *ci_gmon;
@


1.48
log
@Recognize PowerPC 970 CPUs present in early PowerMac G5 from 2003 (7,2 and
7,3) and let OpenBSD boot on these machines, yay! The 970 are similar to
the 970FX except that they are manufactured in 130nm.

Fix an issue reported by Andrew Fresh and kirby@@ on misc@@
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.47 2012/12/02 07:03:31 guenther Exp $	*/
d87 3
@


1.47
log
@Determine whether we're currently on the alternative signal stack
dynamically, by comparing the stack pointer against the altstack
base and size, so that you get the correct answer if you longjmp
out of the signal handler, as tested by regress/sys/kern/stackjmp/.
Also, fix alt stack handling on vax, where it was completely broken.

Testing and corrections by miod@@, krw@@, tobiasu@@, pirofti@@
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.46 2010/09/28 20:27:55 miod Exp $	*/
d380 1
@


1.46
log
@Implement a per-cpu held mutex counter if DIAGNOSTIC on all non-x86 platforms,
to complete matthew@@'s commit of a few days ago, and drop __HAVE_CPU_MUTEX_LEVEL
define. With help from, and ok deraadt@@.
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.45 2009/08/24 21:44:21 dms Exp $	*/
d153 1
@


1.45
log
@Add definitions for 4 additionl BAT registers, found on some newer PowerPC
chips, like MPC8xxx family.

ok kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.44 2009/03/26 17:24:33 oga Exp $	*/
d84 4
@


1.44
log
@Remove cpu_wait(). It's original use was to be called from the reaper so
MD code would free resources that couldn't be freed until we were no
longer running in that processor. However, it's is unused on all
architectures since mikeb@@'s tss changes on x86 earlier in the year.

ok miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.43 2009/03/15 20:07:14 miod Exp $	*/
d256 8
d272 8
@


1.43
log
@Let CPU_INFO_UNIT() be used before cpu0 attaches, and make sure
CPU_INFO_FOREACH() only covers attached cpus. With drahn@@, ok kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.42 2008/11/22 14:42:29 art Exp $	*/
a148 2

#define	cpu_wait(p)		do { /* nothing */ } while (0)
@


1.42
log
@cpu_unidle for macppc
ok drahn@@
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.41 2008/10/15 23:23:49 deraadt Exp $	*/
d98 1
a98 1
#define CPU_INFO_UNIT(ci)	((ci)->ci_dev->dv_unit)
d118 1
a118 1
	for (cii = 0, ci = &cpu_info[0]; cii < PPC_MAXPROCS; cii++, ci++)
@


1.41
log
@make random(9) return per-cpu values (by saving the seed in the cpuinfo),
which are uniform for the profclock on each cpu in a SMP system (but using
a different seed for each cpu).  on all cpus, avoid seeding with a value out
of the [0, 2^31-1] range (since that is not stable)
ok kettenis drahn
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.40 2008/10/10 08:05:45 art Exp $	*/
d120 2
d132 2
@


1.40
log
@Define MAXCPUS on all architectures.
For now, sparc64 is arbitrarily set to 256 (only architecture that didn't have
a practical limit in the code on the number of cpus).
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.39 2008/09/16 04:20:42 drahn Exp $	*/
d83 1
a83 1
	u_long ci_randseed;
@


1.39
log
@SMP ddb support, with some feedback from kettenis.
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.38 2008/07/18 23:43:31 art Exp $	*/
d132 2
@


1.38
log
@Add a macro that clears the want_resched flag that need_resched sets.
Right now when mi_switch picks up the same proc, we didn't clear the
flag which would mean that every time we service an AST we would attempt
a context switch. For some architectures, amd64 being probably the
most extreme, that meant attempting to context switch for every
trap and interrupt.

Now we clear_resched explicitly after every context switch, even if it
didn't do anything. Which also allows us to remove some more code
in cpu_switchto (not done yet).

miod@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.37 2008/05/04 20:54:22 drahn Exp $	*/
d75 7
@


1.37
log
@Manage interrupts based on priority better, still working on this...
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.36 2008/05/01 08:25:32 kettenis Exp $	*/
d154 1
@


1.36
log
@Implement a nop IPI to signal other CPUs.

ok drahn@@
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.35 2008/04/29 04:08:25 drahn Exp $	*/
d58 2
@


1.35
log
@PIR is not defined to be a writable register, do not use it.
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.34 2008/04/27 15:59:49 drahn Exp $	*/
d140 16
a155 4
#define	need_resched(ci)	(ci->ci_want_resched = 1, \
				    ci->ci_curproc->p_md.md_astpending = 1)
#define	need_proftick(p)	do { p->p_md.md_astpending = 1; } while (0)
#define	signotify(p)		(p->p_md.md_astpending = 1)
@


1.34
log
@Switch to proc based ast pending for SMP. ok kettenis.
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.33 2008/04/26 22:37:41 drahn Exp $	*/
d100 1
a100 1
	__asm ("mfspr %0,1023" : "=r"(pir));
@


1.33
log
@Changes to get closer to SMP.
add biglock before interrupt calls into the kernel.
switch the clock to using cpuinfo variables instead of globals
move cpu_switchto into C code so that on multiprocessor the FPU
and Altivec can be saved before switching CPUs.
add a lock into pmap when modifying the hash table.
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.32 2007/12/04 22:36:39 kettenis Exp $	*/
a54 1
	volatile int ci_astpending;
d140 4
a143 3
#define	need_resched(ci)	(ci->ci_want_resched = 1, ci->ci_astpending = 1)
#define	need_proftick(p)	do { curcpu()->ci_astpending = 1; } while (0)
#define	signotify(p)		(curcpu()->ci_astpending = 1)
@


1.32
log
@Remove remains of the idle pcb/stack.

ok miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.31 2007/03/23 21:06:05 miod Exp $	*/
d60 1
d68 8
@


1.31
log
@Define PROC_PC and simplify userret(); ok kettenis@@ (and I think drahn@@ too)
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.30 2007/03/20 20:59:53 kettenis Exp $	*/
a52 1
	struct pcb *ci_idle_pcb;	/* PA of our idle pcb */
@


1.30
log
@Move macppc to __HAVE_CPUINFO, and make locore.S and trap.c suitable for
MULTIPROCESSOR.  From now on sprg0 holds a pointer to struct cpuinfo, which
is used to spill registers to during trap instead of the globals we used to
use for that purpose.  Bits and pieces from NetBSD.  Help from drahn@@ and art@@.
Tested by xsa@@, thib@@, miod@@, gwk@@, deraadt@@.

ok drahn@@, gwk@@
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.29 2007/03/15 10:22:29 art Exp $	*/
d123 6
a128 1
#define	cpu_wait(p)
@


1.29
log
@Since p_flag is often manipulated in interrupts and without biglock
it's a good idea to use atomic.h operations on it. This mechanic
change updates all bit operations on p_flag to atomic_{set,clear}bits_int.

Only exception is that P_OWEUPC is set by MI code before calling
need_proftick and it's automatically cleared by ADDUPC. There's
no reason for MD handling of that flag since everyone handles it the
same way.

kettenis@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.28 2006/11/29 12:26:13 miod Exp $	*/
d39 79
a117 1
#include <machine/psl.h>
d128 3
a130 6
extern volatile int want_resched;
extern volatile int astpending;

#define	need_resched(ci)	(want_resched = 1, astpending = 1)
#define	need_proftick(p)	do { astpending = 1; } while (0)
#define	signotify(p)		(astpending = 1)
d278 2
d329 8
@


1.28
log
@Remove cpu_swapin() and cpu_swapout(), they are no longer necessary (except
for cpu_swapin() on hppa* which is kept).
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.27 2006/02/10 21:27:22 kettenis Exp $	*/
d54 1
a54 1
#define	need_proftick(p)	((p)->p_flag |= P_OWEUPC, astpending = 1)
@


1.27
log
@Add a few more CPU types.
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.26 2005/11/26 22:40:30 kettenis Exp $	*/
a44 1
#define	cpu_swapout(p)
@


1.26
log
@Frequency scaling for IBM 970FX.
ok drahn@@
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.25 2005/11/13 21:46:03 drahn Exp $	*/
d249 1
d252 1
@


1.25
log
@Recognized 970MP processor.
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.24 2005/11/08 20:30:47 kettenis Exp $	*/
d199 1
d202 1
@


1.24
log
@Add support for 64-bit SPRs.
ok drahn@@
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.23 2005/10/22 09:19:18 kettenis Exp $	*/
d243 1
@


1.23
log
@s/970/970FX/g
ok drahn@@
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.22 2005/10/01 19:55:25 drahn Exp $	*/
d54 1
a54 1
#define	need_resched(ci)		(want_resched = 1, astpending = 1)
d106 1
a106 1
	int ret;						\
d173 2
a174 2
	__asm __volatile ("1: mftbu %0; mftb %0+1; mftbu %1; cmpw 0,%0,%1; bne 1b"
	     : "=r"(tb), "=r"(scratch));
d195 2
a196 1
	__asm __volatile ("mtsrin %0,%1" :: "r"(val), "r"(sn_shifted) );
d198 3
a200 1
}
d210 1
a210 1
	if (enable != 0)  {
@


1.22
log
@Recognize 970 processor and provide a function/variable to determine if
the current processor is 64bit.
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.21 2005/03/10 19:24:30 otto Exp $	*/
d239 1
a239 1
#define	PPC_CPU_IBM970		0x003c
@


1.21
log
@Recognize 7447A processor, as found in the Mac mini; print
rev number in hex explicitly. ok deraadt@@ drahn@@
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.20 2004/11/18 16:10:08 miod Exp $	*/
d132 1
d225 2
d239 1
@


1.20
log
@Move PowerPC cpu type constants to <machine/cpu.h>

ok drahn@@
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.19 2004/06/13 21:49:19 niklas Exp $	*/
d238 1
@


1.19
log
@debranch SMP, have fun
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d46 1
a46 1
#define cpu_wait(p)
d72 1
a72 1
	
d92 1
a92 1
	
d95 1
a95 1
	
d107 1
a107 1
        __asm __volatile ("mfspr %0," # n : "=r" (ret));	\
d112 1
a112 1
        __asm __volatile ("mtspr "# n ",%0" :: "r" (val));	\
d162 1
a162 1
        __asm __volatile ("mftb %0" : "=r" (ret));
d224 16
@


1.18
log
@Simplify hw.{cpuspeed,setperf} api moving all the sysctl stuff
from the underlying callbacks.

Testing hppa mickey@@, ppc drahn@@
Ok markus@@ tedu@@
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.17 2003/12/24 00:25:42 drahn Exp $	*/
d54 1
a54 1
#define	need_resched()		(want_resched = 1, astpending = 1)
@


1.17
log
@support cpu_cpuspeed on macppc.
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.16 2003/07/08 21:46:19 drahn Exp $	*/
d223 1
a223 1
int ppc_cpuspeed(void *oldp, size_t *oldlenp, void *newp, size_t newlen);
@


1.16
log
@Improved timebase register handling. use all 64 bits, instead of the
lower 32 bits.
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.15 2003/07/02 21:30:12 drahn Exp $	*/
d222 3
@


1.15
log
@Reduce the amount of asm code in powerpc/macppc by replacing it with
inlined functions, helps improve readability and fix a couple of bugs.
ok miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.14 2003/07/02 21:23:35 drahn Exp $	*/
d74 1
a74 1
		__asm__ __volatile__ ("dcbst 0,%0" :: "r"(p));
d77 1
a77 1
	__asm__ __volatile__ ("sync");
d81 1
a81 1
		__asm__ __volatile__ ("icbi 0,%0" :: "r"(p));
d84 1
a84 1
	__asm__ __volatile__ ("isync");
d97 1
a97 1
		__asm__ __volatile__ ("dcbi 0,%0" :: "r"(p));
d100 1
a100 1
	__asm__ __volatile__ ("sync");
d166 11
d194 1
a194 1
	asm volatile ("mtsrin %0,%1" :: "r"(val), "r"(sn_shifted) );
@


1.14
log
@make ppc_intr_(enable|disable)() inlined functions.
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.13 2002/09/15 09:01:59 deraadt Exp $	*/
d103 84
d196 1
a196 1
		__asm__ volatile("mfmsr %0" : "=r"(msr));
d198 1
a198 1
		__asm__ volatile("mtmsr %0" :: "r"(msr));
d206 1
a206 1
	__asm__ volatile("mfmsr %0" : "=r"(emsr));
d208 1
a208 1
	__asm__ volatile("mtmsr %0" :: "r"(dmsr));
@


1.13
log
@backout premature
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.11 2002/06/08 15:45:32 miod Exp $	*/
d103 24
@


1.12
log
@KNF
@
text
@d72 1
a72 1

d92 1
a92 1

d95 1
a95 1

@


1.11
log
@Factorize common parts (cache-related stuff).
ok drahn@@
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.10 2002/06/07 21:33:43 nordin Exp $	*/
d72 1
a72 1
	
d92 1
a92 1
	
d95 1
a95 1
	
@


1.10
log
@Remove obsolete CLKF_BASEPRI(). ok niklas@@, miod@@ and art@@
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.9 2002/03/14 01:26:41 millert Exp $	*/
d59 43
@


1.9
log
@First round of __P removal in sys
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.8 2001/09/01 15:49:05 drahn Exp $	*/
a41 1
#define	CLKF_BASEPRI(frame)	((frame)->pri == 0)
@


1.8
log
@The "powerpc" port which has supported the newer Apple Macintosh powerpc based
is being renamed to macppc. This is to allow sharing of common code
between different powerpc base platforms.

Most of the work involved in the renaming process was performed by miod@@

Files moved from powerpc/include to macppc/include
Some files were not "moved" but wrapper files were created which include
the powerpc/include version.

Several of the powerpc/include files where changed to reflect that they
are POWERPC_* not MACHINE_*.
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.7 2001/07/09 01:35:32 mickey Exp $	*/
d49 1
a49 1
void	delay __P((unsigned));
@


1.8.4.1
log
@Sync UBC branch to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.8 2001/09/01 15:49:05 drahn Exp $	*/
d42 1
d49 1
a49 1
void	delay(unsigned);
a59 43

#ifndef	CACHELINESIZE
#define	CACHELINESIZE	32			/* For now		XXX */
#endif

static __inline void
syncicache(void *from, int len)
{
	int l;
	char *p = from;

	len = len + (((u_int32_t) from) & (CACHELINESIZE - 1));
	l = len;
	
	do {
		__asm__ __volatile__ ("dcbst 0,%0" :: "r"(p));
		p += CACHELINESIZE;
	} while ((l -= CACHELINESIZE) > 0);
	__asm__ __volatile__ ("sync");
	p = from;
	l = len;
	do {
		__asm__ __volatile__ ("icbi 0,%0" :: "r"(p));
		p += CACHELINESIZE;
	} while ((l -= CACHELINESIZE) > 0);
	__asm__ __volatile__ ("isync");
}

static __inline void
invdcache(void *from, int len)
{
	int l;
	char *p = from;
	
	len = len + (((u_int32_t) from) & (CACHELINESIZE - 1));
	l = len;
	
	do {
		__asm__ __volatile__ ("dcbi 0,%0" :: "r"(p));
		p += CACHELINESIZE;
	} while ((l -= CACHELINESIZE) > 0);
	__asm__ __volatile__ ("sync");
}
@


1.8.4.2
log
@sync to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.8.4.1 2002/06/11 03:37:28 art Exp $	*/
@


1.7
log
@lots of parens, protos
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.6 2001/06/24 04:43:04 drahn Exp $	*/
d34 2
a35 2
#ifndef	_MACHINE_CPU_H_
#define	_MACHINE_CPU_H_
a48 1
void	child_return __P((struct proc *));
a58 22
#define	CACHELINESIZE	32			/* For now		XXX */

static __inline void
syncicache(void *from, int len)
{
	int l = len;
	char *p = from;
	
	do {
		__asm__ __volatile__ ("dcbst 0,%0" :: "r"(p));
		p += CACHELINESIZE;
	} while ((l -= CACHELINESIZE) > 0);
	__asm__ __volatile__ ("sync");
	p = from;
	l = len;
	do {
		__asm__ __volatile__ ("icbi 0,%0" :: "r"(p));
		p += CACHELINESIZE;
	} while ((l -= CACHELINESIZE) > 0);
	__asm__ __volatile__ ("isync");
}

d61 1
a61 1
#endif	/* _MACHINE_CPU_H_ */
@


1.6
log
@More inline function cleanup for stricter -W flags.
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.5 2001/01/24 21:29:12 drahn Exp $	*/
d49 2
a50 1
extern void delay __P((unsigned));
@


1.5
log
@Optimization base on looking at generated asm code.
also change type of a variable from (void) * to (char *) since it is
incremented as if a (char *).
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.4 2001/01/15 19:50:39 deraadt Exp $	*/
d61 2
a62 4
extern __inline void
syncicache(from, len)
	void *from;
	int len;
@


1.4
log
@__asm__ and __volatile__
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.3 1997/10/13 10:53:42 pefo Exp $	*/
d67 1
a67 1
	void *p = from;
d74 2
d77 3
a79 3
		__asm__ __volatile__ ("icbi 0,%0" :: "r"(from));
		from += CACHELINESIZE;
	} while ((len -= CACHELINESIZE) > 0);
@


1.3
log
@Monolithic PowerPC kernel, new include
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.2 1996/12/28 06:25:03 rahnds Exp $	*/
d70 1
a70 1
		asm volatile ("dcbst 0,%0" :: "r"(p));
d73 1
a73 1
	asm volatile ("sync");
d75 1
a75 1
		asm volatile ("icbi 0,%0" :: "r"(from));
d78 1
a78 1
	asm volatile ("isync");
@


1.3.12.1
log
@Update the SMP branch to -current, this breaks the SMP branch though.
But it will be fixed soonish.  Note, nothing new has happened, this is just
a merge of the trunk into this branch.
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.5 2001/01/24 21:29:12 drahn Exp $	*/
d67 1
a67 1
	char *p = from;
d70 1
a70 1
		__asm__ __volatile__ ("dcbst 0,%0" :: "r"(p));
d73 1
a73 3
	__asm__ __volatile__ ("sync");
	p = from;
	l = len;
d75 4
a78 4
		__asm__ __volatile__ ("icbi 0,%0" :: "r"(p));
		p += CACHELINESIZE;
	} while ((l -= CACHELINESIZE) > 0);
	__asm__ __volatile__ ("isync");
@


1.3.12.2
log
@Merge in -current from two days ago in the SMP branch.
As usual with merges, they do not indicate progress, so do not hold
your breath for working SMP, and do not mail me and ask about the
state of it.  It has not changed.  There is work ongoing, but very, very
slowly.  The commit is done in parts as to not lock up the tree in too
big chunks at a time.
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.3.12.1 2001/04/18 16:13:01 niklas Exp $	*/
d61 4
a64 2
static __inline void
syncicache(void *from, int len)
@


1.3.12.3
log
@Sync the SMP branch to something just after 3.0
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.3.12.2 2001/07/04 10:22:20 niklas Exp $	*/
d34 2
a35 2
#ifndef	_POWERPC_CPU_H_
#define	_POWERPC_CPU_H_
d49 1
a49 1
void	delay __P((unsigned));
d59 22
d83 1
a83 1
#endif	/* _POWERPC_CPU_H_ */
@


1.3.12.4
log
@repair
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.3.12.3 2001/10/31 03:07:55 nate Exp $	*/
@


1.3.12.5
log
@Re-add missing pieces
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.9 2002/03/14 01:26:41 millert Exp $	*/
d49 1
a49 1
void	delay(unsigned);
@


1.3.12.6
log
@Sync the SMP branch with 3.3
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d42 1
a59 43

#ifndef	CACHELINESIZE
#define	CACHELINESIZE	32			/* For now		XXX */
#endif

static __inline void
syncicache(void *from, int len)
{
	int l;
	char *p = from;

	len = len + (((u_int32_t) from) & (CACHELINESIZE - 1));
	l = len;
	
	do {
		__asm__ __volatile__ ("dcbst 0,%0" :: "r"(p));
		p += CACHELINESIZE;
	} while ((l -= CACHELINESIZE) > 0);
	__asm__ __volatile__ ("sync");
	p = from;
	l = len;
	do {
		__asm__ __volatile__ ("icbi 0,%0" :: "r"(p));
		p += CACHELINESIZE;
	} while ((l -= CACHELINESIZE) > 0);
	__asm__ __volatile__ ("isync");
}

static __inline void
invdcache(void *from, int len)
{
	int l;
	char *p = from;
	
	len = len + (((u_int32_t) from) & (CACHELINESIZE - 1));
	l = len;
	
	do {
		__asm__ __volatile__ ("dcbi 0,%0" :: "r"(p));
		p += CACHELINESIZE;
	} while ((l -= CACHELINESIZE) > 0);
	__asm__ __volatile__ ("sync");
}
@


1.3.12.7
log
@Merge of current from two weeks agointo the SMP branch
@
text
@d74 1
a74 1
		__asm __volatile ("dcbst 0,%0" :: "r"(p));
d77 1
a77 1
	__asm __volatile ("sync");
d81 1
a81 1
		__asm __volatile ("icbi 0,%0" :: "r"(p));
d84 1
a84 1
	__asm __volatile ("isync");
d97 1
a97 1
		__asm __volatile ("dcbi 0,%0" :: "r"(p));
d100 1
a100 1
	__asm __volatile ("sync");
a101 122

#define FUNC_SPR(n, name) \
static __inline u_int32_t ppc_mf ## name (void)			\
{								\
	int ret;						\
        __asm __volatile ("mfspr %0," # n : "=r" (ret));	\
	return ret;						\
}								\
static __inline void ppc_mt ## name (u_int32_t val)		\
{								\
        __asm __volatile ("mtspr "# n ",%0" :: "r" (val));	\
}								\

FUNC_SPR(0, mq)
FUNC_SPR(1, xer)
FUNC_SPR(4, rtcu)
FUNC_SPR(5, rtcl)
FUNC_SPR(8, lr)
FUNC_SPR(9, ctr)
FUNC_SPR(18, dsisr)
FUNC_SPR(19, dar)
FUNC_SPR(22, dec)
FUNC_SPR(25, sdr1)
FUNC_SPR(26, srr0)
FUNC_SPR(27, srr1)
FUNC_SPR(256, vrsave)
FUNC_SPR(272, sprg0)
FUNC_SPR(273, sprg1)
FUNC_SPR(274, sprg2)
FUNC_SPR(275, sprg3)
FUNC_SPR(282, ear)
FUNC_SPR(287, pvr)
FUNC_SPR(528, ibat0u)
FUNC_SPR(529, ibat0l)
FUNC_SPR(530, ibat1u)
FUNC_SPR(531, ibat1l)
FUNC_SPR(532, ibat2u)
FUNC_SPR(533, ibat2l)
FUNC_SPR(534, ibat3u)
FUNC_SPR(535, ibat3l)
FUNC_SPR(536, dbat0u)
FUNC_SPR(537, dbat0l)
FUNC_SPR(538, dbat1u)
FUNC_SPR(539, dbat1l)
FUNC_SPR(540, dbat2u)
FUNC_SPR(541, dbat2l)
FUNC_SPR(542, dbat3u)
FUNC_SPR(543, dbat3l)
FUNC_SPR(1008, hid0)
FUNC_SPR(1009, hid1)
FUNC_SPR(1010, iabr)
FUNC_SPR(1017, l2cr)
FUNC_SPR(1018, l3cr)
FUNC_SPR(1013, dabr)
FUNC_SPR(1023, pir)

static __inline u_int32_t
ppc_mftbl (void)
{
	int ret;
        __asm __volatile ("mftb %0" : "=r" (ret));
	return ret;
}

static __inline u_int64_t
ppc_mftb(void)
{
	u_long scratch;
	u_int64_t tb;

	__asm __volatile ("1: mftbu %0; mftb %0+1; mftbu %1; cmpw 0,%0,%1; bne 1b"
	     : "=r"(tb), "=r"(scratch));
	return tb;
}

static __inline u_int32_t
ppc_mfmsr (void)
{
	int ret;
        __asm __volatile ("mfmsr %0" : "=r" (ret));
	return ret;
}

static __inline void
ppc_mtmsr (u_int32_t val)
{
        __asm __volatile ("mtmsr %0" :: "r" (val));
}

static __inline void
ppc_mtsrin(u_int32_t val, u_int32_t sn_shifted)
{
	__asm __volatile ("mtsrin %0,%1" :: "r"(val), "r"(sn_shifted) );

}

/*
 * General functions to enable and disable interrupts
 * without having inlined assembly code in many functions.
 */
static __inline void
ppc_intr_enable(int enable)
{
	u_int32_t msr;
	if (enable != 0)  {
		msr = ppc_mfmsr();
		msr |= PSL_EE;
		ppc_mtmsr(msr);
	}
}

static __inline int
ppc_intr_disable(void)
{
	u_int32_t emsr, dmsr;
	emsr = ppc_mfmsr();
	dmsr = emsr & ~PSL_EE;
	ppc_mtmsr(dmsr);
	return (emsr & PSL_EE);
}

int ppc_cpuspeed(void *oldp, size_t *oldlenp, void *newp, size_t newlen);
@


1.3.12.8
log
@Merge with the trunk
@
text
@d223 1
a223 1
int ppc_cpuspeed(int *);
@


1.3.12.9
log
@need_resched macro needs to take ci arg to be compat with MP function
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu.h,v 1.3.12.8 2004/06/05 23:10:56 niklas Exp $	*/
d54 1
a54 1
#define	need_resched(ci)		(want_resched = 1, astpending = 1)
@


1.2
log
@adding OpenBSD tag to files.
@
text
@d1 1
a1 1
/*	$OpenBSD:$	*/
a38 6
struct machvec {
	void (*splx) __P((int));
	void (*irq_establish) __P((int, int, void (*)(void *), void *));
};
extern struct machvec machine_interface;

a39 3

#define	irq_establish(irq, level, handler, arg)	\
	((*machine_interface.irq_establish)((irq), (level), (handler), (arg)))
@


1.1
log
@Initial revision
@
text
@d1 1
@


1.1.1.1
log
@Check-in of powerpc kernel support.
NOTE: This will not work until the other pieces are checked in.
This is primarily the NetBSD powerpc port, with modifications
to support ELF. 
@
text
@@
