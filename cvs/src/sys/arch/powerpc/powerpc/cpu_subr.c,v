head	1.8;
access;
symbols
	OPENBSD_6_1:1.8.0.10
	OPENBSD_6_1_BASE:1.8
	OPENBSD_6_0:1.8.0.6
	OPENBSD_6_0_BASE:1.8
	OPENBSD_5_9:1.8.0.2
	OPENBSD_5_9_BASE:1.8
	OPENBSD_5_8:1.8.0.4
	OPENBSD_5_8_BASE:1.8
	OPENBSD_5_7:1.5.0.2
	OPENBSD_5_7_BASE:1.5
	OPENBSD_5_6:1.3.0.4
	OPENBSD_5_6_BASE:1.3
	OPENBSD_5_5:1.2.0.36
	OPENBSD_5_5_BASE:1.2
	OPENBSD_5_4:1.2.0.32
	OPENBSD_5_4_BASE:1.2
	OPENBSD_5_3:1.2.0.30
	OPENBSD_5_3_BASE:1.2
	OPENBSD_5_2:1.2.0.28
	OPENBSD_5_2_BASE:1.2
	OPENBSD_5_1_BASE:1.2
	OPENBSD_5_1:1.2.0.26
	OPENBSD_5_0:1.2.0.24
	OPENBSD_5_0_BASE:1.2
	OPENBSD_4_9:1.2.0.22
	OPENBSD_4_9_BASE:1.2
	OPENBSD_4_8:1.2.0.20
	OPENBSD_4_8_BASE:1.2
	OPENBSD_4_7:1.2.0.16
	OPENBSD_4_7_BASE:1.2
	OPENBSD_4_6:1.2.0.18
	OPENBSD_4_6_BASE:1.2
	OPENBSD_4_5:1.2.0.14
	OPENBSD_4_5_BASE:1.2
	OPENBSD_4_4:1.2.0.12
	OPENBSD_4_4_BASE:1.2
	OPENBSD_4_3:1.2.0.10
	OPENBSD_4_3_BASE:1.2
	OPENBSD_4_2:1.2.0.8
	OPENBSD_4_2_BASE:1.2
	OPENBSD_4_1:1.2.0.6
	OPENBSD_4_1_BASE:1.2
	OPENBSD_4_0:1.2.0.4
	OPENBSD_4_0_BASE:1.2
	OPENBSD_3_9:1.2.0.2
	OPENBSD_3_9_BASE:1.2;
locks; strict;
comment	@ * @;


1.8
date	2015.04.27.07.20.57;	author mpi;	state Exp;
branches;
next	1.7;
commitid	fhRbBpvLIFyQuzLF;

1.7
date	2015.03.31.16.00.38;	author mpi;	state Exp;
branches;
next	1.6;
commitid	MMWnK4Mn4W58afQM;

1.6
date	2015.03.31.15.51.05;	author mpi;	state Exp;
branches;
next	1.5;
commitid	V6LJj7jikqpWX3RD;

1.5
date	2014.09.06.10.15.52;	author mpi;	state Exp;
branches;
next	1.4;
commitid	RzNS2F7j0UQHdMTX;

1.4
date	2014.09.06.09.22.40;	author mpi;	state Exp;
branches;
next	1.3;
commitid	IsbdFINYLL0WOhn8;

1.3
date	2014.03.29.18.09.30;	author guenther;	state Exp;
branches;
next	1.2;

1.2
date	2005.11.26.22.40.31;	author kettenis;	state Exp;
branches;
next	1.1;

1.1
date	2005.11.08.20.30.47;	author kettenis;	state Exp;
branches;
next	;


desc
@@


1.8
log
@Correctly write the 64bits of the HID 1, 4 and 5 registers.

This makes the secondary cpu of my PowerMac as fast as the primary one,
and divide the build time by 3 with a GENERIC.MP kernel on MP G5s

Found thanks to MP kernel profiling.

ok dlg@@, miod@@
@
text
@/*	$OpenBSD: cpu_subr.c,v 1.7 2015/03/31 16:00:38 mpi Exp $	*/

/*
 * Copyright (c) 2013 Martin Pieuchot
 * Copyright (c) 2005 Mark Kettenis
 *
 * Permission to use, copy, modify, and distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 */

#include <sys/param.h>

#include <powerpc/cpu.h>

int		ppc_cpuidle;		/* Support DOZE, NAP or DEEP NAP? */
int		ppc_altivec;		/* CPU has altivec support. */
int		ppc_proc_is_64b;	/* CPU is 64bit */
int		ppc_nobat;		/* Do not use BAT registers. */

struct patch {
	uint32_t *s;
	uint32_t *e;
};
extern struct patch	rfi_start, nop32_start, nopbat_start;
extern uint32_t		rfid_inst, nop_inst;

void
cpu_bootstrap(void)
{
	uint32_t cpu;
	uint32_t *inst;
	struct patch *p;

	cpu = ppc_mfpvr() >> 16;

	switch (cpu) {
	case PPC_CPU_IBM970:
	case PPC_CPU_IBM970FX:
	case PPC_CPU_IBM970MP:
		ppc_nobat = 1;
		ppc_proc_is_64b = 1;

		for (p = &rfi_start; p->s; p++) {
			for (inst = p->s; inst < p->e; inst++)
				*inst = rfid_inst;
			syncicache(p->s, (p->e - p->s) * sizeof(*p->e));
		}
		break;
	case PPC_CPU_MPC83xx:
		ppc_mtibat4u(0);
		ppc_mtibat5u(0);
		ppc_mtibat6u(0);
		ppc_mtibat7u(0);
		ppc_mtdbat4u(0);
		ppc_mtdbat5u(0);
		ppc_mtdbat6u(0);
		ppc_mtdbat7u(0);
		/* FALLTHROUGH */
	default:
		ppc_mtibat0u(0);
		ppc_mtibat1u(0);
		ppc_mtibat2u(0);
		ppc_mtibat3u(0);
		ppc_mtdbat0u(0);
		ppc_mtdbat1u(0);
		ppc_mtdbat2u(0);
		ppc_mtdbat3u(0);

		for (p = &nop32_start; p->s; p++) {
			for (inst = p->s; inst < p->e; inst++)
				*inst = nop_inst;
			syncicache(p->s, (p->e - p->s) * sizeof(*p->e));
		}
	}

	if (ppc_nobat) {
		for (p = &nopbat_start; p->s; p++) {
			for (inst = p->s; inst < p->e; inst++)
				*inst = nop_inst;
			syncicache(p->s, (p->e - p->s) * sizeof(*p->e));
		}
	}
}

void
ppc_mtscomc(u_int32_t val)
{
	int s;

	s = ppc_intr_disable();
	__asm volatile ("mtspr 276,%0; isync" :: "r" (val));
	ppc_intr_enable(s);
}

void
ppc_mtscomd(u_int32_t val)
{
	int s;

	s = ppc_intr_disable();
	__asm volatile ("mtspr 277,%0; isync" :: "r" (val));
	ppc_intr_enable(s);
}

u_int64_t
ppc64_mfscomc(void)
{
	u_int64_t ret;
	int s;

	s = ppc_intr_disable();
	__asm volatile ("mfspr %0,276;"
	    " mr %0+1, %0; srdi %0,%0,32" : "=r" (ret));
	ppc_intr_enable(s);
	return ret;
}

void
ppc64_mtscomc(u_int64_t val)
{
	int s;

	s = ppc_intr_disable();
	__asm volatile ("sldi %0,%0,32; or %0,%0,%0+1;"
	    " mtspr 276,%0; isync" :: "r" (val));
	ppc_intr_enable(s);
}

u_int64_t
ppc64_mfscomd(void)
{
	u_int64_t ret;
	int s;

	s = ppc_intr_disable();
	__asm volatile ("mfspr %0,277;"
            " mr %0+1, %0; srdi %0,%0,32" : "=r" (ret));
	ppc_intr_enable(s);
	return ret;
}

static __inline u_int32_t
ppc64_mfhid0(u_int32_t *lo)
{
	u_int32_t hid0_hi, hid0_lo;

	__asm volatile ("mfspr %0,1008;"
	    " mr %1, %0; srdi %0,%0,32;" : "=r" (hid0_hi), "=r" (hid0_lo));
	if (lo != NULL)
		*lo = hid0_lo;
	return hid0_hi;
}

static __inline void
ppc64_mthid0(u_int32_t hid0_hi, u_int32_t hid0_lo)
{
	/*
	 * No! It's not a joke (:
	 *
	 * Note 1 of the Table 2-3 from the 970MP User manual.
	 */
	__asm volatile ("sldi %0,%0,32; or %0,%0,%1;"
	    "sync; mtspr 1008,%0;"
	    "mfspr %0,1008; mfspr %0,1008; mfspr %0,1008;"
	    "mfspr %0,1008; mfspr %0,1008; mfspr %0,1008;"
	    "isync" :: "r" (hid0_hi), "r"(hid0_lo));
}

u_int32_t
ppc_mfhid0(void)
{
	u_int32_t ret;

	/* Since the lower 32 bits are reserved, do not expose them. */
	if (ppc_proc_is_64b)
		return ppc64_mfhid0(NULL);

	__asm volatile ("mfspr %0,1008" : "=r" (ret));
	return ret;
}

void
ppc_mthid0(u_int32_t val)
{
	if (ppc_proc_is_64b) {
		u_int32_t lo;

		/* Don't write any garbage in the lower 32 bits. */
		(void)ppc64_mfhid0(&lo);
		return ppc64_mthid0(val, lo);
	}

	__asm volatile ("mtspr 1008,%0; isync" :: "r" (val));
}

u_int64_t
ppc64_mfhid1(void)
{
	u_int64_t ret;

	__asm volatile ("mfspr %0,1009;"
            " mr %0+1, %0; srdi %0,%0,32" : "=r" (ret));
	return ret;
}

void
ppc64_mthid1(u_int64_t val)
{
	__asm volatile ("sldi %0,%0,32; or %0,%0,%0+1;"
	    "mtspr 1009,%0; mtspr 1009,%0; isync;" :: "r" (val));
}

u_int64_t
ppc64_mfhid4(void)
{
	u_int64_t ret;

	__asm volatile ("mfspr %0,1012;"
            " mr %0+1, %0; srdi %0,%0,32" : "=r" (ret));
	return ret;
}

void
ppc64_mthid4(u_int64_t val)
{
	__asm volatile ("sldi %0,%0,32; or %0,%0,%0+1;"
	    "sync; mtspr 1012,%0; isync;" :: "r" (val));
}

u_int64_t
ppc64_mfhid5(void)
{
	u_int64_t ret;

	__asm volatile ("mfspr %0,1014;"
            " mr %0+1, %0; srdi %0,%0,32" : "=r" (ret));
	return ret;
}

void
ppc64_mthid5(u_int64_t val)
{
	__asm volatile ("sldi %0,%0,32; or %0,%0,%0+1;"
	    "sync; mtspr 1014,%0; isync;" :: "r" (val));
}
@


1.7
log
@Make it possisble to disable block address translation mechanism on
processors that support it.

Due to the way trap code is patched it is currently not possible to
enabled/disable BAT at runtime.

ok miod@@, kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu_subr.c,v 1.6 2015/03/31 15:51:05 mpi Exp $	*/
d218 2
a219 1
	__asm volatile ("mtspr 1009,%0; mtspr 1009,%0; isync;" :: "r" (val));
d235 2
a236 1
	__asm volatile ("sync; mtspr 1012,%0; isync;" :: "r" (val));
d252 2
a253 1
	__asm volatile ("sync; mtspr 1014,%0; isync;" :: "r" (val));
@


1.6
log
@Merge two versions of ppc_check_procid().

ok miod@@, kettenis@@ as part of a larger diff
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu_subr.c,v 1.5 2014/09/06 10:15:52 mpi Exp $	*/
d22 6
a27 1
#include <machine/cpu.h>
d33 2
a34 6
extern struct patch	rfi_start, nop32_start, nop64_start;
extern uint32_t		rfi_inst, rfid_inst, nop_inst;

int		ppc_cpuidle;	/* Support DOZE, NAP or DEEP NAP? */
int		ppc_altivec;
int		ppc_proc_is_64b;
d37 1
a37 1
ppc_check_procid(void)
d49 1
d51 1
d57 22
a78 1
		for (p = &nop64_start; p->s; p++) {
d83 1
d85 2
a86 4
		break;
	default:
		ppc_proc_is_64b = 0;
		for (p = &nop32_start; p->s; p++) {
@


1.5
log
@Rewrite cpu_idle & friends to not check and update the hid0 register
in the idle loop, in preparation for G5 support.

Only do a disable/enable interrupt dance if the running CPU supports a
sleep mode.

Fix entering ddb(8) from interrupt context by not modifying the return
address of the 'forced' trap frame.

While here, modify the existing logic to terminate prefetching of all
data streams if AltiVec is supported before setting the POW bit.

With inputs/explanations from drahn, looks ok to miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu_subr.c,v 1.4 2014/09/06 09:22:40 mpi Exp $	*/
d24 7
d33 37
@


1.4
log
@Add functions to manipulate IBM PowerPC 970 specific registers that
will be used in upcoming MP and idle support.

ok miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu_subr.c,v 1.3 2014/03/29 18:09:30 guenther Exp $	*/
d23 3
@


1.3
log
@It's been a quarter century: we can assume volatile is present with that name.

ok dlg@@ mpi@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu_subr.c,v 1.2 2005/11/26 22:40:31 kettenis Exp $	*/
d4 1
d79 102
@


1.2
log
@Frequency scaling for IBM 970FX.
ok drahn@@
@
text
@d1 1
a1 1
/*	$OpenBSD: cpu_subr.c,v 1.1 2005/11/08 20:30:47 kettenis Exp $	*/
d29 1
a29 1
	__asm __volatile ("mtspr 276,%0; isync" :: "r" (val));
d39 1
a39 1
	__asm __volatile ("mtspr 277,%0; isync" :: "r" (val));
d50 1
a50 1
	__asm __volatile ("mfspr %0,276;"
d62 1
a62 1
	__asm __volatile ("sldi %0,%0,32; or %0,%0,%0+1;"
d74 1
a74 1
	__asm __volatile ("mfspr %0,277;"
@


1.1
log
@Add support for 64-bit SPRs.
ok drahn@@
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d22 20
@

