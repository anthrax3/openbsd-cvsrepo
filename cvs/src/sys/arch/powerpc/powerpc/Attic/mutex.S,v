head	1.17;
access;
symbols
	OPENBSD_5_8:1.16.0.8
	OPENBSD_5_8_BASE:1.16
	OPENBSD_5_7:1.16.0.2
	OPENBSD_5_7_BASE:1.16
	OPENBSD_5_6:1.16.0.4
	OPENBSD_5_6_BASE:1.16
	OPENBSD_5_5:1.15.0.4
	OPENBSD_5_5_BASE:1.15
	OPENBSD_5_4:1.14.0.8
	OPENBSD_5_4_BASE:1.14
	OPENBSD_5_3:1.14.0.6
	OPENBSD_5_3_BASE:1.14
	OPENBSD_5_2:1.14.0.4
	OPENBSD_5_2_BASE:1.14
	OPENBSD_5_1_BASE:1.14
	OPENBSD_5_1:1.14.0.2
	OPENBSD_5_0:1.13.0.2
	OPENBSD_5_0_BASE:1.13
	OPENBSD_4_9:1.12.0.2
	OPENBSD_4_9_BASE:1.12
	OPENBSD_4_8:1.10.0.4
	OPENBSD_4_8_BASE:1.10
	OPENBSD_4_7:1.10.0.2
	OPENBSD_4_7_BASE:1.10
	OPENBSD_4_6:1.9.0.4
	OPENBSD_4_6_BASE:1.9
	OPENBSD_4_5:1.5.0.2
	OPENBSD_4_5_BASE:1.5
	OPENBSD_4_4:1.3.0.6
	OPENBSD_4_4_BASE:1.3
	OPENBSD_4_3:1.3.0.4
	OPENBSD_4_3_BASE:1.3
	OPENBSD_4_2:1.3.0.2
	OPENBSD_4_2_BASE:1.3;
locks; strict;
comment	@# @;


1.17
date	2015.08.14.06.14.19;	author dlg;	state dead;
branches;
next	1.16;
commitid	fjF8E1NC4JOIKQOD;

1.16
date	2014.06.18.18.42.29;	author kettenis;	state Exp;
branches;
next	1.15;
commitid	TdoWs7LHnN3oLWtY;

1.15
date	2014.01.22.11.01.15;	author kettenis;	state Exp;
branches;
next	1.14;

1.14
date	2011.08.29.20.21.44;	author drahn;	state Exp;
branches;
next	1.13;

1.13
date	2011.07.07.05.43.48;	author drahn;	state Exp;
branches;
next	1.12;

1.12
date	2011.01.08.18.10.22;	author deraadt;	state Exp;
branches;
next	1.11;

1.11
date	2010.09.28.20.27.55;	author miod;	state Exp;
branches;
next	1.10;

1.10
date	2009.08.13.13.24.55;	author weingart;	state Exp;
branches;
next	1.9;

1.9
date	2009.06.09.01.12.38;	author deraadt;	state Exp;
branches;
next	1.8;

1.8
date	2009.06.02.21.38.10;	author drahn;	state Exp;
branches;
next	1.7;

1.7
date	2009.04.27.21.48.56;	author kettenis;	state Exp;
branches;
next	1.6;

1.6
date	2009.04.25.20.14.43;	author weingart;	state Exp;
branches;
next	1.5;

1.5
date	2008.11.21.17.35.52;	author deraadt;	state Exp;
branches;
next	1.4;

1.4
date	2008.09.18.03.56.25;	author drahn;	state Exp;
branches;
next	1.3;

1.3
date	2007.05.31.23.50.25;	author drahn;	state Exp;
branches;
next	1.2;

1.2
date	2007.05.29.20.22.10;	author drahn;	state Exp;
branches;
next	1.1;

1.1
date	2007.03.22.19.26.28;	author kettenis;	state Exp;
branches;
next	;


desc
@@


1.17
log
@replace the asm mutexes with a c implementation.

there's no real functional advantage to this, except that it will
make it easier to add deadlock detection to the code.

this is modelled on the c mutex implementation thats on alpha,
mips64, and hppa.

ok mpi@@ kettenis@@
@
text
@/*	$OpenBSD: mutex.S,v 1.16 2014/06/18 18:42:29 kettenis Exp $	*/

/*
 * Copyright (c) 2007 Dale Rahn
 * Copyright (c) 2007 Mark Kettenis
 *
 * Permission to use, copy, modify, and distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 */

#include "assym.h"

#include <machine/asm.h>

/* XXX */
#define GET_CPUINFO(r)	mfsprg r,0

ENTRY(__mtx_init)
	li	%r5,0
	stw	%r4,MTX_WANTIPL(%r3)
	stw	%r5,MTX_OLDCPL(%r3)
	stw	%r5,MTX_OWNER(%r3)
	blr


ENTRY(mtx_enter)
	stwu	%r1,-16(%r1)			# reserve stack
	mflr	%r0
	stw	%r0,20(%r1)			# save return address
.L_retry:
	stw	%r3, 12(%r1)
	lwz	%r3,MTX_WANTIPL(%r3)		# load new ipl
	bl	_C_LABEL(splraise)
	mr	%r7, %r3
	GET_CPUINFO(%r4)
	lwz	%r3,12(%r1)
	li	%r5,MTX_OWNER			# load offset constant
	lwarx	%r6,%r5,%r3			# load reserve owner
	cmpwi	0,%r6,0				# test owner == 0
	beq+	0,.L_mutex_free			# if owner == 0 branch free
.L_mutex_locked:
#ifdef DIAGNOSTIC
	cmpl	0,%r4,%r6
	beq-	.L_mutex_selflocked
#endif
	stw	%r3,12(%r1)			# save mtx during lcsplx
	la	%r4,12(%r1)
	stwcx.	%r3,0,%r4			# unreserve owner
	mr	%r3,%r7				# move old cpl to arg0
	bl	_C_LABEL(lcsplx)		# call splx on old cpl
	lwz	%r3,12(%r1)
	b	.L_retry

.L_mutex_free:
	stwcx.	%r4,%r5,%r3			# old owner was 0 cond store
	bne-	.L_mutex_locked			# branch if reserve cancelled
	isync					# memory barrier
#ifdef DIAGNOSTIC
	lwz	%r6,CI_MUTEX_LEVEL(%r4)
	addi	%r6,%r6,1			# curpcu->ci_mutex_level++
	stw	%r6,CI_MUTEX_LEVEL(%r4)
#endif
	stw	%r7,MTX_OLDCPL(%r3)		# save old ipl
	lwz	%r0,20(%r1)			# load return address
	mtlr	%r0
	addi	%r1,%r1,16			# restore stack
	blr

#ifdef DIAGNOSTIC
.L_mutex_selflocked:
	mr	%r5, %r3
	lis	%r3,.L_paniclocked@@ha
	la	%r3,.L_paniclocked@@l(%r3)
	bl 	panic
.L_paniclocked:
	.string "mtx_enter: recursed %x %x\n"
#endif


ENTRY(mtx_enter_try)
	stwu	%r1,-16(%r1)			# reserve stack
	mflr	%r0
	stw	%r0,20(%r1)			# save return address
	stw	%r3, 12(%r1)
	lwz	%r3,MTX_WANTIPL(%r3)		# load new ipl
	bl	_C_LABEL(splraise)
	mr	%r7, %r3
	GET_CPUINFO(%r4)
	lwz	%r3,12(%r1)
	li	%r5,MTX_OWNER			# load offset constant
	lwarx	%r6,%r5,%r3			# load reserve owner
	cmpwi	0,%r6,0				# test owner == 0
	beq+	0,.L_mutex_try_free		# if owner == 0 branch free
.L_mutex_try_locked:
#ifdef DIAGNOSTIC
	cmpl	0,%r4,%r6
	beq-	.L_mutex_try_selflocked
#endif
	stw	%r3,12(%r1)			# save mtx during lcsplx
	la	%r4,12(%r1)
	stwcx.	%r3,0,%r4			# unreserve owner
	mr	%r3,%r7				# move old cpl to arg0
	bl	_C_LABEL(lcsplx)		# call splx on old cpl

	lwz	%r0,20(%r1)			# load return address
	mtlr	%r0
	addi	%r1,%r1,16			# restore stack
	li	%r3,0				# return zero
	blr

.L_mutex_try_free:
	stwcx.	%r4,%r5,%r3			# old owner was 0 cond store
	bne-	.L_mutex_try_locked		# branch if reserve cancelled
	isync					# memory barrier
#ifdef DIAGNOSTIC
	lwz	%r6,CI_MUTEX_LEVEL(%r4)
	addi	%r6,%r6,1			# curpcu->ci_mutex_level++
	stw	%r6,CI_MUTEX_LEVEL(%r4)
#endif
	stw	%r7,MTX_OLDCPL(%r3)		# save old ipl
	lwz	%r0,20(%r1)			# load return address
	mtlr	%r0
	addi	%r1,%r1,16			# restore stack
	li	%r3,1				# return nonzero
	blr

#ifdef DIAGNOSTIC
.L_mutex_try_selflocked:
	mr	%r5, %r3
	lis	%r3,.L_panictrylocked@@ha
	la	%r3,.L_panictrylocked@@l(%r3)
	bl 	panic
.L_panictrylocked:
	.string "mtx_enter_try: recursed %x %x\n"
#endif


ENTRY(mtx_leave)
#ifdef DIAGNOSTIC
	lwz	%r6,MTX_OWNER(%r3)
	cmpwi   0,%r6,0				# test owner == 0

	beq-	.L_mutex_notlocked
#endif
	li	%r4,0
	lwz	%r5,MTX_OLDCPL(%r3)
	stw	%r4,MTX_OLDCPL(%r3)
	sync					# memory barrier
	stw	%r4,MTX_OWNER(%r3)
	GET_CPUINFO(%r4)
#ifdef DIAGNOSTIC
	lwz	%r6,CI_MUTEX_LEVEL(%r4)
	addi	%r6,%r6,-1			# curpcu->ci_mutex_level--
	stw	%r6,CI_MUTEX_LEVEL(%r4)
#endif
	mr	%r3,%r5
	lwz	%r5,CI_CPL(%r4)
	cmpl	0,%r3,%r5
	beq	1f
	b	_C_LABEL(lcsplx)
1:
	blr

#ifdef DIAGNOSTIC
.L_mutex_notlocked:
	GET_CPUINFO(%r4)
	mr	%r5, %r3
	lis	%r3,.L_panicnotlocked@@ha
	la	%r3,.L_panicnotlocked@@l(%r3)
	bl 	panic
.L_panicnotlocked:
	.string "mtx_leave: not locked %x %x\n"
#endif
@


1.16
log
@Add missing synchronization instructions.

ok mpi@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mutex.S,v 1.15 2014/01/22 11:01:15 kettenis Exp $	*/
@


1.15
log
@To prevent lock ordering problems with the kernel lock, we need to make sure
we block all interrupts that can grab the kernel lock.  The simplest way to
achieve this is to make sure mutexes always raise the ipl to the highest
level that has interrupts that grab the kernel lock.  This will allow us
to have "mpsafe" interrupt handlers at lower priority levels.

No change for non-MULTIPROCESSOR kernels.

tested by mpi@@, landry@@
ok mpi@@, dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mutex.S,v 1.14 2011/08/29 20:21:44 drahn Exp $	*/
d66 1
d123 1
d157 1
@


1.14
log
@Return of the long missing powerpc interrupt rewrite.  Was working for
several weeks before release on macppc, socppc bugs just fixed.
@
text
@d1 1
a1 1
/*	$OpenBSD: mutex.S,v 1.13 2011/07/07 05:43:48 drahn Exp $	*/
d27 1
a27 1
ENTRY(mtx_init)
@


1.13
log
@Return retcode in correct register. 'better commit that' kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mutex.S,v 1.12 2011/01/08 18:10:22 deraadt Exp $	*/
d36 1
a36 1
	stwu	%r1,-32(%r1)			# reserve stack
d38 1
a38 1
	stw	%r0,36(%r1)			# save return address
d40 4
d45 1
a45 8
	lwz	%r5,MTX_WANTIPL(%r3)		# load new ipl
	lis	%r6,_C_LABEL(cpu_imask)@@ha	# convert into cpl
	slwi	%r5,%r5,2
	addi	%r5,%r5,_C_LABEL(cpu_imask)@@l
	lwzx	%r5,%r5,%r6
	lwz	%r7,CI_CPL(%r4)			# load current cpl
	or	%r6,%r5,%r7			# raise	cpl
	stw	%r6,CI_CPL(%r4)			# store new cpl
d55 2
a56 2
	stw	%r3,28(%r1)			# save mtx during lcsplx
	la	%r4,28(%r1)
d60 1
a60 1
	lwz	%r3,28(%r1)
d72 1
a72 1
	lwz	%r0,36(%r1)			# load return address
d74 1
a74 1
	addi	%r1,%r1,32			# restore stack
d89 1
a89 1
	stwu	%r1,-32(%r1)			# reserve stack
d91 5
a95 1
	stw	%r0,36(%r1)			# save return address
d97 1
a97 8
	lwz	%r5,MTX_WANTIPL(%r3)		# load new ipl
	lis	%r6,_C_LABEL(cpu_imask)@@ha	# convert into cpl
	slwi	%r5,%r5,2
	addi	%r5,%r5,_C_LABEL(cpu_imask)@@l
	lwzx	%r5,%r5,%r6
	lwz	%r7,CI_CPL(%r4)			# load current cpl
	or	%r6,%r5,%r7			# raise	cpl
	stw	%r6,CI_CPL(%r4)			# store new cpl
d107 2
a108 2
	stw	%r3,28(%r1)			# save mtx during lcsplx
	la	%r4,28(%r1)
d113 1
a113 1
	lwz	%r0,36(%r1)			# load return address
d115 1
a115 1
	addi	%r1,%r1,32			# restore stack
d128 1
a128 1
	lwz	%r0,36(%r1)			# load return address
d130 1
a130 1
	addi	%r1,%r1,32			# restore stack
d148 1
a148 1
	cmpwi   0,%r6,0                         # test owner == 0
@


1.12
log
@rename imask[] to cpu_imask[] to because imask is too loud as far as
kernel namespace
ok miod
@
text
@d1 1
a1 1
/*	$OpenBSD: mutex.S,v 1.11 2010/09/28 20:27:55 miod Exp $	*/
d122 1
a122 1
	li	%r2,0				# return zero
d137 1
a137 1
	li	%r2,1				# return nonzero
@


1.11
log
@Implement a per-cpu held mutex counter if DIAGNOSTIC on all non-x86 platforms,
to complete matthew@@'s commit of a few days ago, and drop __HAVE_CPU_MUTEX_LEVEL
define. With help from, and ok deraadt@@.
@
text
@d1 1
a1 1
/*	$OpenBSD: mutex.S,v 1.10 2009/08/13 13:24:55 weingart Exp $	*/
d42 1
a42 1
	lis	%r6,_C_LABEL(imask)@@ha		# convert into cpl
d44 1
a44 1
	addi	%r5,%r5,_C_LABEL(imask)@@l
d97 1
a97 1
	lis	%r6,_C_LABEL(imask)@@ha		# convert into cpl
d99 1
a99 1
	addi	%r5,%r5,_C_LABEL(imask)@@l
@


1.10
log
@A new(er) mtx_enter_try().

Ok oga@@, "the time is now" deraadt@@.
@
text
@d1 1
a1 1
/*	$OpenBSD: mutex.S,v 1.9 2009/06/09 01:12:38 deraadt Exp $	*/
d69 5
d128 5
d163 5
@


1.9
log
@backout interrupt diff until it the next round of fixes
@
text
@d1 1
a1 1
/*	$OpenBSD: mutex.S,v 1.7 2009/04/27 21:48:56 kettenis Exp $	*/
d83 55
@


1.8
log
@Reintroduce the macppc interrupt subsystem rewrite. Several bugs have
been found and corrected.
@
text
@d1 1
a1 1
/*	$OpenBSD: mutex.S,v 1.4 2008/09/18 03:56:25 drahn Exp $	*/
a24 3
#ifdef USERLAND
#define GET_CPUINFO(r)	mr r, %r4
#else
a25 1
#endif
a34 3
/*
 * mtx_enter(struct mutex *mtx[%r3])
 */
d36 1
a36 1
	stwu	%r1,-16(%r1)			# reserve stack
d38 1
a38 1
	stw	%r0,20(%r1)			# save return address
a39 4
	stw	%r3, 12(%r1)
	lwz	%r3,MTX_WANTIPL(%r3)		# load new ipl
	bl	_C_LABEL(splraise)
	mr	%r7, %r3			
d41 8
a48 1
	lwz	%r3,12(%r1)
d53 1
d58 2
a59 3
.L_mutex_busy:
	stw	%r3,12(%r1)			# save mtx during lcsplx
	la	%r4,12(%r1)
d63 1
a63 1
	lwz	%r3,12(%r1)
d68 1
a68 1
	bne-	.L_mutex_busy			# branch if reserve cancelled
d70 1
a70 1
	lwz	%r0,20(%r1)			# load return address
d72 1
a72 1
	addi	%r1,%r1,16			# restore stack
d97 1
d99 3
@


1.7
log
@Revert mtx_enter_try.  It didn't compile on hppa, it doesn't compile on
landisk, and the sparc implementation is obviously wrong.  That's where I
stopped looking, so who knows what else was broken.  A simple comparison of
the existing mtx_enter with the new mtx_enter_try would have told anybody.
@
text
@d1 1
a1 1
/*	$OpenBSD: mutex.S,v 1.5 2008/11/21 17:35:52 deraadt Exp $	*/
d25 3
d29 1
d39 3
d43 1
a43 1
	stwu	%r1,-32(%r1)			# reserve stack
d45 1
a45 1
	stw	%r0,36(%r1)			# save return address
d47 4
d52 1
a52 8
	lwz	%r5,MTX_WANTIPL(%r3)		# load new ipl
	lis	%r6,_C_LABEL(imask)@@ha		# convert into cpl
	slwi	%r5,%r5,2
	addi	%r5,%r5,_C_LABEL(imask)@@l
	lwzx	%r5,%r5,%r6
	lwz	%r7,CI_CPL(%r4)			# load current cpl
	or	%r6,%r5,%r7			# raise	cpl
	stw	%r6,CI_CPL(%r4)			# store new cpl
a56 1
.L_mutex_locked:
d61 3
a63 2
	stw	%r3,28(%r1)			# save mtx during lcsplx
	la	%r4,28(%r1)
d67 1
a67 1
	lwz	%r3,28(%r1)
d72 1
a72 1
	bne-	.L_mutex_locked			# branch if reserve cancelled
d74 1
a74 1
	lwz	%r0,36(%r1)			# load return address
d76 1
a76 1
	addi	%r1,%r1,32			# restore stack
a100 1
	GET_CPUINFO(%r4)
a101 3
	lwz	%r5,CI_CPL(%r4)
	cmpl	0,%r3,%r5
	beq	1f
@


1.6
log
@Enter mtx_enter_try.  In part for completeness, things may start
using this soon(ish).  Ok oga@@, sorta yes kettenis@@.
@
text
@a85 55
ENTRY(mtx_enter_try)
	stwu	%r1,-32(%r1)			# reserve stack
	mflr	%r0
	stw	%r0,36(%r1)			# save return address
	GET_CPUINFO(%r4)
	lwz	%r5,MTX_WANTIPL(%r3)		# load new ipl
	lis	%r6,_C_LABEL(imask)@@ha		# convert into cpl
	slwi	%r5,%r5,2
	addi	%r5,%r5,_C_LABEL(imask)@@l
	lwzx	%r5,%r5,%r6
	lwz	%r7,CI_CPL(%r4)			# load current cpl
	or	%r6,%r5,%r7			# raise	cpl
	stw	%r6,CI_CPL(%r4)			# store new cpl
	li	%r5,MTX_OWNER			# load offset constant
	lwarx	%r6,%r5,%r3			# load reserve owner
	cmpwi	0,%r6,0				# test owner == 0
	beq+	0,.L_mutex_try_free		# if owner == 0 branch free
.L_mutex_try_locked:
#ifdef DIAGNOSTIC
	cmpl	0,%r4,%r6
	beq-	.L_mutex_try_selflocked
#endif
	stw	%r3,28(%r1)			# save mtx during lcsplx
	la	%r4,28(%r1)
	stwcx.	%r3,0,%r4			# unreserve owner
	mr	%r3,%r7				# move old cpl to arg0
	bl	_C_LABEL(lcsplx)		# call splx on old cpl

	lwz	%r0,36(%r1)			# load return address
	mtlr	%r0
	addi	%r1,%r1,32			# restore stack
	li	%r2,0				# return zero
	blr

.L_mutex_try_free:
	stwcx.	%r4,%r5,%r3			# old owner was 0 cond store
	bne-	.L_mutex_try_locked		# branch if reserve cancelled
	stw	%r7,MTX_OLDCPL(%r3)		# save old ipl
	lwz	%r0,36(%r1)			# load return address
	mtlr	%r0
	addi	%r1,%r1,32			# restore stack
	li	%r2,1				# return nonzero
	blr

#ifdef DIAGNOSTIC
.L_mutex_try_selflocked:
	mr	%r5, %r3
	lis	%r3,.L_panictrylocked@@ha
	la	%r3,.L_panictrylocked@@l(%r3)
	bl 	panic
.L_panictrylocked:
	.string "mtx_enter_try: recursed %x %x\n"
#endif


@


1.5
log
@back out the new interrupt subsystem because some little bug still lurks in there
@
text
@d1 1
a1 1
/*	$OpenBSD: mutex.S,v 1.3 2007/05/31 23:50:25 drahn Exp $	*/
d83 55
@


1.4
log
@Redesign of the powerpc interrupt architecture, use true levels intead of
blocking specific interrupts. Needs signficant testing to prove that
one remaining elusive bug has been squashed.
@
text
@a24 3
#ifdef USERLAND
#define GET_CPUINFO(r)	mr r, %r4
#else
a25 1
#endif
a34 3
/*
 * mtx_enter(struct mutex *mtx[%r3])
 */
d36 1
a36 1
	stwu	%r1,-16(%r1)			# reserve stack
d38 1
a38 1
	stw	%r0,20(%r1)			# save return address
a39 4
	stw	%r3, 12(%r1)
	lwz	%r3,MTX_WANTIPL(%r3)		# load new ipl
	bl	_C_LABEL(splraise)
	mr	%r7, %r3			
d41 8
a48 1
	lwz	%r3,12(%r1)
d53 1
d58 2
a59 3
.L_mutex_busy:
	stw	%r3,12(%r1)			# save mtx during lcsplx
	la	%r4,12(%r1)
d63 1
a63 1
	lwz	%r3,12(%r1)
d68 1
a68 1
	bne-	.L_mutex_busy			# branch if reserve cancelled
d70 1
a70 1
	lwz	%r0,20(%r1)			# load return address
d72 1
a72 1
	addi	%r1,%r1,16			# restore stack
d94 1
a94 1
	lwz	% r5,MTX_OLDCPL(%r3)
d97 1
d99 3
@


1.3
log
@panic if mtx_leave is called on an unlocked mutex. ok kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mutex.S,v 1.2 2007/05/29 20:22:10 drahn Exp $	*/
d25 3
d29 1
d39 3
d43 1
a43 1
	stwu	%r1,-32(%r1)			# reserve stack
d45 1
a45 1
	stw	%r0,36(%r1)			# save return address
d47 4
d52 1
a52 8
	lwz	%r5,MTX_WANTIPL(%r3)		# load new ipl
	lis	%r6,_C_LABEL(imask)@@ha		# convert into cpl
	slwi	%r5,%r5,2
	addi	%r5,%r5,_C_LABEL(imask)@@l
	lwzx	%r5,%r5,%r6
	lwz	%r7,CI_CPL(%r4)			# load current cpl
	or	%r6,%r5,%r7			# raise	cpl
	stw	%r6,CI_CPL(%r4)			# store new cpl
a56 1
.L_mutex_locked:
d61 3
a63 2
	stw	%r3,28(%r1)			# save mtx during lcsplx
	la	%r4,28(%r1)
d67 1
a67 1
	lwz	%r3,28(%r1)
d72 1
a72 1
	bne-	.L_mutex_locked			# branch if reserve cancelled
d74 1
a74 1
	lwz	%r0,36(%r1)			# load return address
d76 1
a76 1
	addi	%r1,%r1,32			# restore stack
d98 1
a98 1
	lwz	%r5,MTX_OLDCPL(%r3)
a100 1
	GET_CPUINFO(%r4)
a101 3
	lwz	%r5,CI_CPL(%r4)
	cmpl	0,%r3,%r5
	beq	1f
@


1.2
log
@Panic if the locker is self.
@
text
@d1 1
a1 1
/*	$OpenBSD: mutex.S,v 1.1 2007/03/22 19:26:28 kettenis Exp $	*/
d78 2
a79 2
	lis	%r3,.L_panicstr@@ha
	la	%r3,.L_panicstr@@l(%r3)
d81 1
a81 1
.L_panicstr:
d87 6
d105 11
@


1.1
log
@Move powerpc to __HAVE_MUTEX.  With help from drahn@@.  Tested by nick@@, xsa@@,
deraadt@@.

"reads right" deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d54 4
d74 10
@

