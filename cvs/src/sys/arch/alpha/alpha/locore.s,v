head	1.45;
access;
symbols
	OPENBSD_6_1:1.45.0.6
	OPENBSD_6_1_BASE:1.45
	OPENBSD_6_0:1.45.0.2
	OPENBSD_6_0_BASE:1.45
	OPENBSD_5_9:1.43.0.2
	OPENBSD_5_9_BASE:1.43
	OPENBSD_5_8:1.43.0.4
	OPENBSD_5_8_BASE:1.43
	OPENBSD_5_7:1.38.0.2
	OPENBSD_5_7_BASE:1.38
	OPENBSD_5_6:1.38.0.6
	OPENBSD_5_6_BASE:1.38
	OPENBSD_5_5:1.38.0.4
	OPENBSD_5_5_BASE:1.38
	OPENBSD_5_4:1.37.0.2
	OPENBSD_5_4_BASE:1.37
	OPENBSD_5_3:1.35.0.2
	OPENBSD_5_3_BASE:1.35
	OPENBSD_5_2:1.34.0.18
	OPENBSD_5_2_BASE:1.34
	OPENBSD_5_1_BASE:1.34
	OPENBSD_5_1:1.34.0.16
	OPENBSD_5_0:1.34.0.14
	OPENBSD_5_0_BASE:1.34
	OPENBSD_4_9:1.34.0.12
	OPENBSD_4_9_BASE:1.34
	OPENBSD_4_8:1.34.0.10
	OPENBSD_4_8_BASE:1.34
	OPENBSD_4_7:1.34.0.6
	OPENBSD_4_7_BASE:1.34
	OPENBSD_4_6:1.34.0.8
	OPENBSD_4_6_BASE:1.34
	OPENBSD_4_5:1.34.0.4
	OPENBSD_4_5_BASE:1.34
	OPENBSD_4_4:1.34.0.2
	OPENBSD_4_4_BASE:1.34
	OPENBSD_4_3:1.32.0.2
	OPENBSD_4_3_BASE:1.32
	OPENBSD_4_2:1.30.0.2
	OPENBSD_4_2_BASE:1.30
	OPENBSD_4_1:1.29.0.4
	OPENBSD_4_1_BASE:1.29
	OPENBSD_4_0:1.29.0.2
	OPENBSD_4_0_BASE:1.29
	OPENBSD_3_9:1.28.0.4
	OPENBSD_3_9_BASE:1.28
	OPENBSD_3_8:1.28.0.2
	OPENBSD_3_8_BASE:1.28
	OPENBSD_3_7:1.27.0.2
	OPENBSD_3_7_BASE:1.27
	OPENBSD_3_6:1.26.0.2
	OPENBSD_3_6_BASE:1.26
	SMP_SYNC_A:1.21
	SMP_SYNC_B:1.21
	OPENBSD_3_5:1.21.0.2
	OPENBSD_3_5_BASE:1.21
	OPENBSD_3_4:1.20.0.4
	OPENBSD_3_4_BASE:1.20
	UBC_SYNC_A:1.20
	OPENBSD_3_3:1.20.0.2
	OPENBSD_3_3_BASE:1.20
	OPENBSD_3_2:1.19.0.2
	OPENBSD_3_2_BASE:1.19
	OPENBSD_3_1:1.17.0.6
	OPENBSD_3_1_BASE:1.17
	UBC_SYNC_B:1.19
	UBC:1.17.0.4
	UBC_BASE:1.17
	OPENBSD_3_0:1.17.0.2
	OPENBSD_3_0_BASE:1.17
	OPENBSD_2_9:1.15.0.2
	OPENBSD_2_9_BASE:1.15
	OPENBSD_2_8:1.12.0.2
	OPENBSD_2_8_BASE:1.12
	OPENBSD_2_7:1.11.0.4
	OPENBSD_2_7_BASE:1.11
	SMP:1.11.0.2
	SMP_BASE:1.11
	kame_19991208:1.11
	OPENBSD_2_6:1.10.0.2
	OPENBSD_2_6_BASE:1.10
	OPENBSD_2_5:1.9.0.8
	OPENBSD_2_5_BASE:1.9
	OPENBSD_2_4:1.9.0.6
	OPENBSD_2_4_BASE:1.9
	OPENBSD_2_3:1.9.0.4
	OPENBSD_2_3_BASE:1.9
	OPENBSD_2_2:1.9.0.2
	OPENBSD_2_2_BASE:1.9
	OPENBSD_2_1:1.7.0.2
	OPENBSD_2_1_BASE:1.7
	OPENBSD_2_0:1.4.0.2
	OPENBSD_2_0_BASE:1.4
	netbsd_1_1:1.1.1.1;
locks; strict;
comment	@# @;


1.45
date	2016.05.23.20.11.48;	author deraadt;	state Exp;
branches;
next	1.44;
commitid	0oWSDXhpPUnuLpPD;

1.44
date	2016.05.10.18.39.40;	author deraadt;	state Exp;
branches;
next	1.43;
commitid	qfOifNidEGDB2jL1;

1.43
date	2015.07.20.07.45.23;	author dlg;	state Exp;
branches;
next	1.42;
commitid	vDDwYIAFot3OxByx;

1.42
date	2015.06.23.19.49.41;	author miod;	state Exp;
branches;
next	1.41;
commitid	Kjl7576CD2ozP04h;

1.41
date	2015.06.11.17.26.17;	author deraadt;	state Exp;
branches;
next	1.40;
commitid	HQeHvkQfx0LdSY4f;

1.40
date	2015.06.05.19.36.28;	author deraadt;	state Exp;
branches;
next	1.39;
commitid	PpPRzO0dJvJYf65X;

1.39
date	2015.06.05.18.36.07;	author deraadt;	state Exp;
branches;
next	1.38;
commitid	uZipwpqk2xD1bNIp;

1.38
date	2014.01.26.17.40.09;	author miod;	state Exp;
branches;
next	1.37;

1.37
date	2013.06.13.02.27.23;	author deraadt;	state Exp;
branches;
next	1.36;

1.36
date	2013.06.11.21.16.14;	author deraadt;	state Exp;
branches;
next	1.35;

1.35
date	2012.11.01.21.09.17;	author miod;	state Exp;
branches;
next	1.34;

1.34
date	2008.07.28.19.08.43;	author miod;	state Exp;
branches;
next	1.33;

1.33
date	2008.06.26.05.42.08;	author ray;	state Exp;
branches;
next	1.32;

1.32
date	2008.01.13.20.59.52;	author kettenis;	state Exp;
branches;
next	1.31;

1.31
date	2007.10.10.15.53.51;	author art;	state Exp;
branches;
next	1.30;

1.30
date	2007.05.28.23.10.10;	author beck;	state Exp;
branches;
next	1.29;

1.29
date	2006.05.25.01.33.43;	author brad;	state Exp;
branches;
next	1.28;

1.28
date	2005.06.17.21.54.14;	author miod;	state Exp;
branches;
next	1.27;

1.27
date	2004.12.24.22.50.27;	author miod;	state Exp;
branches;
next	1.26;

1.26
date	2004.07.03.19.22.57;	author deraadt;	state Exp;
branches;
next	1.25;

1.25
date	2004.07.03.18.24.42;	author deraadt;	state Exp;
branches;
next	1.24;

1.24
date	2004.07.03.18.18.26;	author deraadt;	state Exp;
branches;
next	1.23;

1.23
date	2004.06.28.02.28.42;	author aaron;	state Exp;
branches;
next	1.22;

1.22
date	2004.06.13.21.49.11;	author niklas;	state Exp;
branches;
next	1.21;

1.21
date	2003.10.18.20.14.40;	author jmc;	state Exp;
branches;
next	1.20;

1.20
date	2003.01.09.22.27.03;	author miod;	state Exp;
branches;
next	1.19;

1.19
date	2002.05.02.23.05.27;	author millert;	state Exp;
branches;
next	1.18;

1.18
date	2002.04.28.20.55.14;	author pvalchev;	state Exp;
branches;
next	1.17;

1.17
date	2001.09.30.13.08.45;	author art;	state Exp;
branches
	1.17.4.1;
next	1.16;

1.16
date	2001.06.11.08.51.20;	author art;	state Exp;
branches;
next	1.15;

1.15
date	2001.02.08.13.38.14;	author art;	state Exp;
branches;
next	1.14;

1.14
date	2000.11.08.19.16.59;	author ericj;	state Exp;
branches;
next	1.13;

1.13
date	2000.11.08.16.01.00;	author art;	state Exp;
branches;
next	1.12;

1.12
date	2000.06.05.11.02.54;	author art;	state Exp;
branches;
next	1.11;

1.11
date	99.11.13.21.33.44;	author deraadt;	state Exp;
branches
	1.11.2.1;
next	1.10;

1.10
date	99.09.26.11.07.32;	author kstailey;	state Exp;
branches;
next	1.9;

1.9
date	97.07.08.10.55.53;	author niklas;	state Exp;
branches;
next	1.8;

1.8
date	97.07.06.16.26.46;	author niklas;	state Exp;
branches;
next	1.7;

1.7
date	97.01.24.19.56.35;	author niklas;	state Exp;
branches;
next	1.6;

1.6
date	96.11.14.13.17.06;	author niklas;	state Exp;
branches;
next	1.5;

1.5
date	96.10.30.22.38.13;	author niklas;	state Exp;
branches;
next	1.4;

1.4
date	96.07.29.22.57.41;	author niklas;	state Exp;
branches;
next	1.3;

1.3
date	96.06.18.09.42.17;	author deraadt;	state Exp;
branches;
next	1.2;

1.2
date	95.12.14.03.52.39;	author deraadt;	state Exp;
branches;
next	1.1;

1.1
date	95.10.18.08.49.39;	author deraadt;	state Exp;
branches
	1.1.1.1;
next	;

1.1.1.1
date	95.10.18.08.49.39;	author deraadt;	state Exp;
branches;
next	;

1.11.2.1
date	2001.04.18.16.00.22;	author niklas;	state Exp;
branches;
next	1.11.2.2;

1.11.2.2
date	2001.07.04.10.14.20;	author niklas;	state Exp;
branches;
next	1.11.2.3;

1.11.2.3
date	2001.10.31.02.52.44;	author nate;	state Exp;
branches;
next	1.11.2.4;

1.11.2.4
date	2003.03.27.23.18.06;	author niklas;	state Exp;
branches;
next	1.11.2.5;

1.11.2.5
date	2004.02.19.09.59.33;	author niklas;	state Exp;
branches;
next	1.11.2.6;

1.11.2.6
date	2004.06.07.01.01.20;	author tedu;	state Exp;
branches;
next	;

1.17.4.1
date	2002.06.11.03.33.39;	author art;	state Exp;
branches;
next	1.17.4.2;

1.17.4.2
date	2003.05.19.21.38.52;	author tedu;	state Exp;
branches;
next	;


desc
@@


1.45
log
@Place a cpu-dependent trap/illegal instruction over the remainder of the
sigtramp page, so that it will generate a nice kernel fault if touched.
While here, move most of the sigtramps to the .rodata segment, because
they are not executed in the kernel.
Also some preparation for sliding the actual sigtramp forward (will need
some gdb changes)
ok mlarkin kettenis
@
text
@/* $OpenBSD: locore.s,v 1.44 2016/05/10 18:39:40 deraadt Exp $ */
/* $NetBSD: locore.s,v 1.94 2001/04/26 03:10:44 ross Exp $ */

/*-
 * Copyright (c) 1999, 2000 The NetBSD Foundation, Inc.
 * All rights reserved.
 *
 * This code is derived from software contributed to The NetBSD Foundation
 * by Jason R. Thorpe of the Numerical Aerospace Simulation Facility,
 * NASA Ames Research Center.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 *
 * THIS SOFTWARE IS PROVIDED BY THE NETBSD FOUNDATION, INC. AND CONTRIBUTORS
 * ``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED
 * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE FOUNDATION OR CONTRIBUTORS
 * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
 * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
 * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
 * POSSIBILITY OF SUCH DAMAGE.
 */

/*
 * Copyright (c) 1994, 1995, 1996 Carnegie-Mellon University.
 * All rights reserved.
 *
 * Author: Chris G. Demetriou
 *
 * Permission to use, copy, modify and distribute this software and
 * its documentation is hereby granted, provided that both the copyright
 * notice and this permission notice appear in all copies of the
 * software, derivative works or modified versions, and any portions
 * thereof, and that both notices appear in supporting documentation.
 *
 * CARNEGIE MELLON ALLOWS FREE USE OF THIS SOFTWARE IN ITS "AS IS"
 * CONDITION.  CARNEGIE MELLON DISCLAIMS ANY LIABILITY OF ANY KIND
 * FOR ANY DAMAGES WHATSOEVER RESULTING FROM THE USE OF THIS SOFTWARE.
 *
 * Carnegie Mellon requests users of this software to return to
 *
 *  Software Distribution Coordinator  or  Software.Distribution@@CS.CMU.EDU
 *  School of Computer Science
 *  Carnegie Mellon University
 *  Pittsburgh PA 15213-3890
 *
 * any improvements or extensions that they make and grant Carnegie the
 * rights to redistribute these changes.
 */

.file	1 __FILE__

#include <machine/asm.h>

#include "assym.h"

#if defined(MULTIPROCESSOR)

/*
 * Get various per-cpu values.  A pointer to our cpu_info structure
 * is stored in SysValue.  These macros clobber v0, t0, t8..t11.
 *
 * All return values are in v0.
 */
#define	GET_CPUINFO		call_pal PAL_OSF1_rdval

#define	GET_CURPROC							\
	call_pal PAL_OSF1_rdval					;	\
	addq	v0, CPU_INFO_CURPROC, v0

#define	GET_FPCURPROC							\
	call_pal PAL_OSF1_rdval					;	\
	addq	v0, CPU_INFO_FPCURPROC, v0

#define	GET_CURPCB							\
	call_pal PAL_OSF1_rdval					;	\
	addq	v0, CPU_INFO_CURPCB, v0

#define	GET_IDLE_PCB(reg)						\
	call_pal PAL_OSF1_rdval					;	\
	ldq	reg, CPU_INFO_IDLE_PCB_PADDR(v0)

#else	/* if not MULTIPROCESSOR... */

IMPORT(cpu_info_primary, CPU_INFO_SIZEOF)

#define	GET_CPUINFO		lda v0, cpu_info_primary

#define	GET_CURPROC		lda v0, cpu_info_primary + CPU_INFO_CURPROC

#define	GET_FPCURPROC		lda v0, cpu_info_primary + CPU_INFO_FPCURPROC

#define	GET_CURPCB		lda v0, cpu_info_primary + CPU_INFO_CURPCB

#define	GET_IDLE_PCB(reg)						\
	lda	reg, cpu_info_primary				;	\
	ldq	reg, CPU_INFO_IDLE_PCB_PADDR(reg)
#endif

/*
 * Perform actions necessary to switch to a new context.  The
 * hwpcb should be in a0.  Clobbers v0, t0, t8..t11, a0.
 */
#define	SWITCH_CONTEXT							\
	/* Make a note of the context we're running on. */		\
	GET_CURPCB						;	\
	stq	a0, 0(v0)					;	\
									\
	/* Swap in the new context. */					\
	call_pal PAL_OSF1_swpctx


	/* don't reorder instructions; paranoia. */
	.set noreorder
	.text

	.macro	bfalse	reg, dst
	beq	\reg, \dst
	.endm

	.macro	btrue	reg, dst
	bne	\reg, \dst
	.endm

/*
 * This is for kvm_mkdb, and should be the address of the beginning
 * of the kernel text segment (not necessarily the same as kernbase).
 */
	EXPORT(kernel_text)
.loc	1 __LINE__
kernel_text:

/*
 * bootstack: a temporary stack, for booting.
 *
 * Extends from 'start' down.
 */
bootstack:

/*
 * __start: Kernel start.
 *
 * Arguments:
 *	a0 is the first free page frame number (PFN) (no longer used)
 *	a1 is the page table base register (PTBR)
 *	a2 is the bootinfo magic number
 *	a3 is the pointer to the bootinfo structure
 *
 * All arguments are passed to alpha_init().
 */
NESTED_NOPROFILE(__start,1,0,ra,0,0)
	br	pv,Lstart1
Lstart1: LDGP(pv)

	/* Switch to the boot stack. */
	lda	sp,bootstack

	/* Load KGP with current GP. */
	or	gp,zero,a0
	call_pal PAL_OSF1_wrkgp		/* clobbers a0, t0, t8-t11 */

	/*
	 * Call alpha_init() to do pre-main initialization.
	 * alpha_init() gets the arguments we were called with,
	 * which are already in a0 (destroyed), a1, a2, a3 and a4.
	 */
	CALL(alpha_init)

	/* Set up the virtual page table pointer. */
	ldiq	a0, VPTBASE
	call_pal PAL_OSF1_wrvptptr	/* clobbers a0, t0, t8-t11 */

	/*
	 * Switch to proc0's PCB.
	 */
	lda	a0, proc0
	ldq	a0, P_MD_PCBPADDR(a0)		/* phys addr of PCB */
	SWITCH_CONTEXT

	/*
	 * We've switched to a new page table base, so invalidate the TLB
	 * and I-stream.  This happens automatically everywhere but here.
	 */
	ldiq	a0, -2				/* TBIA */
	call_pal PAL_OSF1_tbi
	call_pal PAL_imb

	/*
	 * All ready to go!  Call main()!
	 */
	CALL(main)

	/* This should never happen. */
	PANIC("main() returned",Lmain_returned_pmsg)
	END(__start)

/**************************************************************************/

/*
 * Pull in the PROM interface routines; these are needed for
 * prom printf (while bootstrapping), and for determining the
 * boot device, etc.
 */
#include <alpha/alpha/prom_disp.s>

/**************************************************************************/

/*
 * Pull in the PALcode function stubs.
 */
#include <alpha/alpha/pal.s>

/**************************************************************************/

/**************************************************************************/

#if defined(MULTIPROCESSOR)
/*
 * Pull in the multiprocessor glue.
 */
#include <alpha/alpha/multiproc.s>
#endif /* MULTIPROCESSOR */

/**************************************************************************/

/**************************************************************************/

#if defined(DDB)
/*
 * Pull in debugger glue.
 */
#include <alpha/alpha/debug.s>
#endif /* DDB */

/**************************************************************************/

/**************************************************************************/

	.text
.loc	1 __LINE__
backtolocore1:
/**************************************************************************/

/*
 * Signal "trampoline" code. Invoked from RTE setup by sendsig().
 *
 * On entry, stack & registers look like:
 *
 *      a0	signal number
 *      a1	signal specific code
 *      a2	pointer to signal context frame (scp)
 *      a3	address of handler
 *      sp+0	saved hardware state
 *                      .
 *                      .
 *      scp+0	beginning of signal context frame
 */

	.section .rodata
NESTED(sigcode,0,0,ra,0,0)
	lda	sp, -16(sp)		/* save the sigcontext pointer */
	stq	a2, 0(sp)
	jsr	ra, (t12)		/* call the signal handler (t12==pv) */
	ldq	a0, 0(sp)		/* get the sigcontext pointer */
	lda	sp, 16(sp)
	CALLSYS_NOERROR(sigreturn)	/* and call sigreturn() with it. */
	.globl  sigcoderet
sigcoderet:
	mov	v0, a0			/* if that failed, get error code */
	CALLSYS_NOERROR(exit)		/* and call exit() with it. */
XNESTED(esigcode,0)
	END(sigcode)

	.globl	sigfill
sigfill:
	halt
esigfill:

	.globl	sigfillsiz
sigfillsiz:
	.quad	esigfill - sigfill

	.text

/**************************************************************************/

/*
 * exception_return: return from trap, exception, or syscall
 */

BSS(ssir, 8)

LEAF(exception_return, 1)			/* XXX should be NESTED */
	br	pv, 1f
1:	LDGP(pv)

	ldq	s1, (FRAME_PS * 8)(sp)		/* get the saved PS */
	and	s1, ALPHA_PSL_IPL_MASK, t0	/* look at the saved IPL */
	bne	t0, 4f				/* != 0: can't do AST or SIR */

	/* see if we can do an SIR */
2:	ldq	t1, ssir			/* SIR pending? */
	bne	t1, 5f				/* yes */
	/* no */

	/* check for AST */
3:	and	s1, ALPHA_PSL_USERMODE, t0	/* are we returning to user? */
	beq	t0, 4f				/* no: just return */
	/* yes */

	/* GET_CPUINFO clobbers v0, t0, t8...t11. */
	GET_CPUINFO
	ldq	t1, CPU_INFO_CURPROC(v0)
	ldl	t2, P_MD_ASTPENDING(t1)		/* AST pending? */
	bne	t2, 6f				/* yes */
	/* no: return & deal with FP */

	/*
	 * We are going back to usermode.  Enable the FPU based on whether
	 * the current proc is fpcurproc.  v0 already contains the cpu_info
	 * pointer from above.
	 */
	ldq	t2, CPU_INFO_FPCURPROC(v0)
	cmpeq	t1, t2, t1
	mov	zero, a0
	cmovne	t1, 1, a0
	call_pal PAL_OSF1_wrfen

	/* restore the registers, and return */
4:	bsr	ra, exception_restore_regs	/* jmp/CALL trashes pv/t12 */
	ldq	ra,(FRAME_RA*8)(sp)
	.set noat
	ldq	at_reg,(FRAME_AT*8)(sp)

	lda	sp,(FRAME_SW_SIZE*8)(sp)
	call_pal PAL_OSF1_rti
	.set at
	/* NOTREACHED */

	/* We've got a SIR */
5:	ldiq	a0, ALPHA_PSL_IPL_SOFT
	call_pal PAL_OSF1_swpipl
	mov	v0, s2				/* remember old IPL */
	CALL(softintr_dispatch)

	/* SIR handled; restore IPL and check again */
	mov	s2, a0
	call_pal PAL_OSF1_swpipl
	br	2b

	/* We've got an AST */
6:	ldiq	a0, ALPHA_PSL_IPL_0		/* drop IPL to zero */
	call_pal PAL_OSF1_swpipl
	mov	v0, s2				/* remember old IPL */

	mov	sp, a0				/* only arg is frame */
	CALL(ast)

	/* AST handled; restore IPL and check again */
	mov	s2, a0
	call_pal PAL_OSF1_swpipl
	br	3b

	END(exception_return)

LEAF(exception_save_regs, 0)
	stq	v0,(FRAME_V0*8)(sp)
	stq	a3,(FRAME_A3*8)(sp)
	stq	a4,(FRAME_A4*8)(sp)
	stq	a5,(FRAME_A5*8)(sp)
	stq	s0,(FRAME_S0*8)(sp)
	stq	s1,(FRAME_S1*8)(sp)
	stq	s2,(FRAME_S2*8)(sp)
	stq	s3,(FRAME_S3*8)(sp)
	stq	s4,(FRAME_S4*8)(sp)
	stq	s5,(FRAME_S5*8)(sp)
	stq	s6,(FRAME_S6*8)(sp)
	stq	t0,(FRAME_T0*8)(sp)
	stq	t1,(FRAME_T1*8)(sp)
	stq	t2,(FRAME_T2*8)(sp)
	stq	t3,(FRAME_T3*8)(sp)
	stq	t4,(FRAME_T4*8)(sp)
	stq	t5,(FRAME_T5*8)(sp)
	stq	t6,(FRAME_T6*8)(sp)
	stq	t7,(FRAME_T7*8)(sp)
	stq	t8,(FRAME_T8*8)(sp)
	stq	t9,(FRAME_T9*8)(sp)
	stq	t10,(FRAME_T10*8)(sp)
	stq	t11,(FRAME_T11*8)(sp)
	stq	t12,(FRAME_T12*8)(sp)
	RET
	END(exception_save_regs)

LEAF(exception_restore_regs, 0)
	ldq	v0,(FRAME_V0*8)(sp)
	ldq	a3,(FRAME_A3*8)(sp)
	ldq	a4,(FRAME_A4*8)(sp)
	ldq	a5,(FRAME_A5*8)(sp)
	ldq	s0,(FRAME_S0*8)(sp)
	ldq	s1,(FRAME_S1*8)(sp)
	ldq	s2,(FRAME_S2*8)(sp)
	ldq	s3,(FRAME_S3*8)(sp)
	ldq	s4,(FRAME_S4*8)(sp)
	ldq	s5,(FRAME_S5*8)(sp)
	ldq	s6,(FRAME_S6*8)(sp)
	ldq	t0,(FRAME_T0*8)(sp)
	ldq	t1,(FRAME_T1*8)(sp)
	ldq	t2,(FRAME_T2*8)(sp)
	ldq	t3,(FRAME_T3*8)(sp)
	ldq	t4,(FRAME_T4*8)(sp)
	ldq	t5,(FRAME_T5*8)(sp)
	ldq	t6,(FRAME_T6*8)(sp)
	ldq	t7,(FRAME_T7*8)(sp)
	ldq	t8,(FRAME_T8*8)(sp)
	ldq	t9,(FRAME_T9*8)(sp)
	ldq	t10,(FRAME_T10*8)(sp)
	ldq	t11,(FRAME_T11*8)(sp)
	ldq	t12,(FRAME_T12*8)(sp)
	RET
	END(exception_restore_regs)

/**************************************************************************/

/*
 * XentArith:
 * System arithmetic trap entry point.
 */

	PALVECT(XentArith)		/* setup frame, save registers */

	/* a0, a1, & a2 already set up */
	ldiq	a3, ALPHA_KENTRY_ARITH
	mov	sp, a4			; .loc 1 __LINE__
	CALL(trap)

	jmp	zero, exception_return
	END(XentArith)

/**************************************************************************/

/*
 * XentIF:
 * System instruction fault trap entry point.
 */

	PALVECT(XentIF)			/* setup frame, save registers */

	/* a0, a1, & a2 already set up */
	ldiq	a3, ALPHA_KENTRY_IF
	mov	sp, a4			; .loc 1 __LINE__
	CALL(trap)
	jmp	zero, exception_return	
	END(XentIF)

/**************************************************************************/

/*
 * XentInt:
 * System interrupt entry point.
 */

	PALVECT(XentInt)		/* setup frame, save registers */

	/* a0, a1, & a2 already set up */
	mov	sp, a3			; .loc 1 __LINE__
	CALL(interrupt)
	jmp	zero, exception_return
	END(XentInt)

/**************************************************************************/

/*
 * XentMM:
 * System memory management fault entry point.
 */

	PALVECT(XentMM)			/* setup frame, save registers */

	/* a0, a1, & a2 already set up */
	ldiq	a3, ALPHA_KENTRY_MM
	mov	sp, a4			; .loc 1 __LINE__
	CALL(trap)

	jmp	zero, exception_return
	END(XentMM)

/**************************************************************************/

/*
 * XentSys:
 * System call entry point.
 */

	ESETUP(XentSys)			; .loc 1 __LINE__

	stq	v0,(FRAME_V0*8)(sp)		/* in case we need to restart */
	stq	s0,(FRAME_S0*8)(sp)
	stq	s1,(FRAME_S1*8)(sp)
	stq	s2,(FRAME_S2*8)(sp)
	stq	s3,(FRAME_S3*8)(sp)
	stq	s4,(FRAME_S4*8)(sp)
	stq	s5,(FRAME_S5*8)(sp)
	stq	s6,(FRAME_S6*8)(sp)
	stq	a0,(FRAME_A0*8)(sp)
	stq	a1,(FRAME_A1*8)(sp)
	stq	a2,(FRAME_A2*8)(sp)
	stq	a3,(FRAME_A3*8)(sp)
	stq	a4,(FRAME_A4*8)(sp)
	stq	a5,(FRAME_A5*8)(sp)
	stq	ra,(FRAME_RA*8)(sp)

	/* syscall number, passed in v0, is first arg, frame pointer second */
	mov	v0,a0
	mov	sp,a1			; .loc 1 __LINE__
	CALL(syscall)

	jmp	zero, exception_return
	END(XentSys)

/**************************************************************************/

/*
 * XentUna:
 * System unaligned access entry point.
 */

LEAF(XentUna, 3)				/* XXX should be NESTED */
	.set noat
	lda	sp,-(FRAME_SW_SIZE*8)(sp)
	stq	at_reg,(FRAME_AT*8)(sp)
	.set at
	stq	ra,(FRAME_RA*8)(sp)
	bsr	ra, exception_save_regs		/* jmp/CALL trashes pv/t12 */

	/* a0, a1, & a2 already set up */
	ldiq	a3, ALPHA_KENTRY_UNA
	mov	sp, a4			; .loc 1 __LINE__
	CALL(trap)

	jmp	zero, exception_return
	END(XentUna)

/**************************************************************************/

/*
 * savefpstate: Save a process's floating point state.
 *
 * Arguments:
 *	a0	'struct fpstate *' to save into
 */

LEAF(savefpstate, 1)
	LDGP(pv)
	/* save all of the FP registers */
	lda	t1, FPREG_FPR_REGS(a0)	/* get address of FP reg. save area */
	stt	$f0,   (0 * 8)(t1)	/* save first register, using hw name */
	stt	$f1,   (1 * 8)(t1)	/* etc. */
	stt	$f2,   (2 * 8)(t1)
	stt	$f3,   (3 * 8)(t1)
	stt	$f4,   (4 * 8)(t1)
	stt	$f5,   (5 * 8)(t1)
	stt	$f6,   (6 * 8)(t1)
	stt	$f7,   (7 * 8)(t1)
	stt	$f8,   (8 * 8)(t1)
	stt	$f9,   (9 * 8)(t1)
	stt	$f10, (10 * 8)(t1)
	stt	$f11, (11 * 8)(t1)
	stt	$f12, (12 * 8)(t1)
	stt	$f13, (13 * 8)(t1)
	stt	$f14, (14 * 8)(t1)
	stt	$f15, (15 * 8)(t1)
	stt	$f16, (16 * 8)(t1)
	stt	$f17, (17 * 8)(t1)
	stt	$f18, (18 * 8)(t1)
	stt	$f19, (19 * 8)(t1)
	stt	$f20, (20 * 8)(t1)
	stt	$f21, (21 * 8)(t1)
	stt	$f22, (22 * 8)(t1)
	stt	$f23, (23 * 8)(t1)
	stt	$f24, (24 * 8)(t1)
	stt	$f25, (25 * 8)(t1)
	stt	$f26, (26 * 8)(t1)
	stt	$f27, (27 * 8)(t1)
	stt	$f28, (28 * 8)(t1)
	stt	$f29, (29 * 8)(t1)
	stt	$f30, (30 * 8)(t1)

	/*
	 * Then save the FPCR; note that the necessary 'trapb's are taken
	 * care of on kernel entry and exit.
	 */
	mf_fpcr	ft0
	stt	ft0, FPREG_FPR_CR(a0)	/* store to FPCR save area */

	RET
	END(savefpstate)

/**************************************************************************/

/*
 * restorefpstate: Restore a process's floating point state.
 *
 * Arguments:
 *	a0	'struct fpstate *' to restore from
 */

LEAF(restorefpstate, 1)
	LDGP(pv)
	/*
	 * Restore the FPCR; note that the necessary 'trapb's are taken care of
	 * on kernel entry and exit.
	 */
	ldt	ft0, FPREG_FPR_CR(a0)	/* load from FPCR save area */
	mt_fpcr	ft0

	/* Restore all of the FP registers. */
	lda	t1, FPREG_FPR_REGS(a0)	/* get address of FP reg. save area */
	ldt	$f0,   (0 * 8)(t1)	/* restore first reg., using hw name */
	ldt	$f1,   (1 * 8)(t1)	/* etc. */
	ldt	$f2,   (2 * 8)(t1)
	ldt	$f3,   (3 * 8)(t1)
	ldt	$f4,   (4 * 8)(t1)
	ldt	$f5,   (5 * 8)(t1)
	ldt	$f6,   (6 * 8)(t1)
	ldt	$f7,   (7 * 8)(t1)
	ldt	$f8,   (8 * 8)(t1)
	ldt	$f9,   (9 * 8)(t1)
	ldt	$f10, (10 * 8)(t1)
	ldt	$f11, (11 * 8)(t1)
	ldt	$f12, (12 * 8)(t1)
	ldt	$f13, (13 * 8)(t1)
	ldt	$f14, (14 * 8)(t1)
	ldt	$f15, (15 * 8)(t1)
	ldt	$f16, (16 * 8)(t1)
	ldt	$f17, (17 * 8)(t1)
	ldt	$f18, (18 * 8)(t1)
	ldt	$f19, (19 * 8)(t1)
	ldt	$f20, (20 * 8)(t1)
	ldt	$f21, (21 * 8)(t1)
	ldt	$f22, (22 * 8)(t1)
	ldt	$f23, (23 * 8)(t1)
	ldt	$f24, (24 * 8)(t1)
	ldt	$f25, (25 * 8)(t1)
	ldt	$f26, (26 * 8)(t1)
	ldt	$f27, (27 * 8)(t1)
	.set noat
	ldt	$f28, (28 * 8)(t1)
	.set at
	ldt	$f29, (29 * 8)(t1)
	ldt	$f30, (30 * 8)(t1)

	RET
	END(restorefpstate)

/**************************************************************************/

/*
 * savectx: save process context, i.e. callee-saved registers
 *
 * Note that savectx() only works for processes other than curproc,
 * since cpu_switch will copy over the info saved here.  (It _can_
 * sanely be used for curproc iff cpu_switch won't be called again, e.g.
 * if called from boot().)
 *
 * Arguments:
 *	a0	'struct user *' of the process that needs its context saved
 *
 * Return:
 *	v0	0.  (note that for child processes, it seems
 *		like savectx() returns 1, because the return address
 *		in the PCB is set to the return address from savectx().)
 */

LEAF(savectx, 1)
	br	pv, 1f
1:	LDGP(pv)
	stq	sp, U_PCB_HWPCB_KSP(a0)		/* store sp */
	stq	s0, U_PCB_CONTEXT+(0 * 8)(a0)	/* store s0 - s6 */
	stq	s1, U_PCB_CONTEXT+(1 * 8)(a0)
	stq	s2, U_PCB_CONTEXT+(2 * 8)(a0)
	stq	s3, U_PCB_CONTEXT+(3 * 8)(a0)
	stq	s4, U_PCB_CONTEXT+(4 * 8)(a0)
	stq	s5, U_PCB_CONTEXT+(5 * 8)(a0)
	stq	s6, U_PCB_CONTEXT+(6 * 8)(a0)
	stq	ra, U_PCB_CONTEXT+(7 * 8)(a0)	/* store ra */
	call_pal PAL_OSF1_rdps			/* NOTE: doesn't kill a0 */
	stq	v0, U_PCB_CONTEXT+(8 * 8)(a0)	/* store ps, for ipl */

	mov	zero, v0
	RET
	END(savectx)

/**************************************************************************/

/*
 * cpu_switchto(struct proc *old, struct proc *new)
 * Switch from "old" proc to "new".
 */
LEAF(cpu_switchto, 2)
	LDGP(pv)

	/*
	 * Don't bother saving the old context if oldproc is NULL.
	 */
	beq	a0, 1f

	/*
	 * do an inline savectx(), to save old context
	 */
	call_pal PAL_OSF1_rdps			/* NOTE: doesn't kill a0 */
	ldq	t0, P_ADDR(a0)
	/* NOTE: ksp is stored by the swpctx */
	stq	s0, U_PCB_CONTEXT+(0 * 8)(t0)	/* store s0 - s6 */
	stq	s1, U_PCB_CONTEXT+(1 * 8)(t0)
	stq	s2, U_PCB_CONTEXT+(2 * 8)(t0)
	stq	s3, U_PCB_CONTEXT+(3 * 8)(t0)
	stq	s4, U_PCB_CONTEXT+(4 * 8)(t0)
	stq	s5, U_PCB_CONTEXT+(5 * 8)(t0)
	stq	s6, U_PCB_CONTEXT+(6 * 8)(t0)
	stq	ra, U_PCB_CONTEXT+(7 * 8)(t0)	/* store ra */
	stq	v0, U_PCB_CONTEXT+(8 * 8)(t0)	/* store ps, for ipl */

1:
	mov	a0, s0				/* save old proc */
	mov	a1, s2				/* save new proc */
	ldq	s3, P_MD_PCBPADDR(s2)		/* save new pcbpaddr */

	/*
	 * Deactivate the old address space before activating the
	 * new one.  We need to do this before activating the
	 * new process's address space in the event that new
	 * process is using the same vmspace as the old.  If we
	 * do this after we activate, then we might end up
	 * incorrectly marking the pmap inactive!
	 *
	 * We don't deactivate if we came here from sched_exit
	 * (old pmap no longer exists; vmspace has been freed).
	 * oldproc will be NULL in this case.  We have actually
	 * taken care of calling pmap_deactivate() in cpu_exit(),
	 * before the vmspace went away.
	 */
	beq	s0, 2f

	mov	s0, a0				/* pmap_deactivate(oldproc) */
	CALL(pmap_deactivate)

2:	/*
	 * Activate the new process's address space and perform
	 * the actual context swap.
	 */

	mov	s2, a0				/* pmap_activate(p) */
	CALL(pmap_activate)

	mov	s3, a0				/* swap the context */
	SWITCH_CONTEXT

	/*
	 * Now that the switch is done, update curproc and other
	 * globals.  We must do this even if switching to ourselves
	 * because we might have re-entered cpu_switch() from idle(),
	 * in which case curproc would be NULL.
	 *
	 * Note: GET_CPUINFO clobbers v0, t0, t8...t11.
	 */
EXPORT(__bwx_switch0)
	addq	s2, P_STAT, t3			/* p->p_stat = SONPROC */
	ldq_u	t1, 0(t3)
	ldiq	t0, SONPROC
	insbl	t0, t3, t0
	mskbl	t1, t3, t1
	or	t0, t1, t0
	stq_u	t0, 0(t3)
EXPORT(__bwx_switch1)

	GET_CPUINFO
	/* p->p_cpu initialized in fork1() for single-processor */
#if defined(MULTIPROCESSOR)
	stq	v0, P_CPU(s2)			/* p->p_cpu = curcpu() */
#endif
	stq	s2, CPU_INFO_CURPROC(v0)	/* curproc = p */

	/*
	 * Now running on the new u struct.
	 * Restore registers and return.
	 */
	ldq	t0, P_ADDR(s2)

	/* NOTE: ksp is restored by the swpctx */
	ldq	s0, U_PCB_CONTEXT+(0 * 8)(t0)		/* restore s0 - s6 */
	ldq	s1, U_PCB_CONTEXT+(1 * 8)(t0)
	ldq	s2, U_PCB_CONTEXT+(2 * 8)(t0)
	ldq	s3, U_PCB_CONTEXT+(3 * 8)(t0)
	ldq	s4, U_PCB_CONTEXT+(4 * 8)(t0)
	ldq	s5, U_PCB_CONTEXT+(5 * 8)(t0)
	ldq	s6, U_PCB_CONTEXT+(6 * 8)(t0)
	ldq	ra, U_PCB_CONTEXT+(7 * 8)(t0)		/* restore ra */
	ldq	a0, U_PCB_CONTEXT+(8 * 8)(t0)		/* restore ipl */
	and	a0, ALPHA_PSL_IPL_MASK, a0
	call_pal PAL_OSF1_swpipl

	ldiq	v0, 1				/* possible ret to savectx() */
	RET
	END(cpu_switchto)

#ifndef SMALL_KERNEL
	/*
	 * BWX-enhanced version of the p->p_stat assignment, to be copied
	 * over the __bwx_switch0 area.

	 * Do not put anything between the end of cpu_switch and this!
	 */
EXPORT(__bwx_switch2)
	ldiq	t0, SONPROC			/* p->p_stat = SONPROC */
	stb	t0, P_STAT(s2)
EXPORT(__bwx_switch3)
#endif

LEAF(cpu_idle_enter, 0)
	RET
	END(cpu_idle_enter)

LEAF(cpu_idle_cycle, 0)
	RET
	END(cpu_idle_cycle)

LEAF(cpu_idle_leave, 0)
	RET
	END(cpu_idle_leave)

/*
 * switch_trampoline()
 *
 * Arrange for a function to be invoked neatly, after a cpu_fork().
 *
 * Invokes the function specified by the s0 register with the return
 * address specified by the s1 register and with one argument specified
 * by the s2 register.
 */
LEAF(switch_trampoline, 0)
#if defined(MULTIPROCESSOR)
	CALL(proc_trampoline_mp)
#endif
	mov	s0, pv
	mov	s1, ra
	mov	s2, a0
	jmp	zero, (pv)
	END(switch_trampoline)

/**************************************************************************/

/*
 * Copy a null-terminated string within the kernel's address space.
 * If lenp is not NULL, store the number of chars copied in *lenp
 *
 * int copystr(char *from, char *to, size_t len, size_t *lenp);
 */
LEAF(copystr, 4)
	LDGP(pv)

	mov	a2, t0			/* t0 = i = len */
	bne	a2, 1f			/* if (len != 0), proceed */
	ldiq	t1, 1			/* else bail */
	br	zero, 2f

1:	ldq_u	t1, 0(a0)		/* t1 = *from */
	extbl	t1, a0, t1
	ldq_u	t3, 0(a1)		/* set up t2 with quad around *to */
	insbl	t1, a1, t2
	mskbl	t3, a1, t3
	or	t3, t2, t3		/* add *from to quad around *to */
	stq_u	t3, 0(a1)		/* write out that quad */

	subl	a2, 1, a2		/* len-- */
	beq	t1, 2f			/* if (*from == 0), bail out */
	addq	a1, 1, a1		/* to++ */
	addq	a0, 1, a0		/* from++ */
	bne	a2, 1b			/* if (len != 0) copy more */

2:	beq	a3, 3f			/* if (lenp != NULL) */
	subl	t0, a2, t0		/* *lenp = (i - len) */
	stq	t0, 0(a3)
3:	beq	t1, 4f			/* *from == '\0'; leave quietly */

	ldiq	v0, ENAMETOOLONG	/* *from != '\0'; error. */
	RET

4:	mov	zero, v0		/* return 0. */
	RET
	END(copystr)

NESTED(copyinstr, 4, 16, ra, IM_RA|IM_S0, 0)
	LDGP(pv)
	ldiq	t0, VM_MAX_ADDRESS		/* make sure that src addr   */
	cmpult	a0, t0, t1			/* is in user space.	     */
	beq	t1, copyfault			/* if it's not, error out.   */
	lda	sp, -16(sp)			/* set up stack frame	     */
	stq	ra, (16-8)(sp)			/* save ra		     */
	stq	s0, (16-16)(sp)			/* save s0		     */
	/* Note: GET_CURPROC clobbers v0, t0, t8...t11. */
	GET_CURPROC
	ldq	t0, 0(v0)
	ldq	s0, P_ADDR(t0)
	lda	v0, copyerr			/* set up fault handler.     */
	stq	v0, U_PCB_ONFAULT(s0)
	CALL(copystr)				/* do the copy.		     */
	stq	zero, U_PCB_ONFAULT(s0)		/* kill the fault handler.   */
	ldq	ra, (16-8)(sp)			/* restore ra.		     */
	ldq	s0, (16-16)(sp)			/* restore s0.		     */
	lda	sp, 16(sp)			/* kill stack frame.	     */
	RET					/* v0 left over from copystr */
	END(copyinstr)

NESTED(copyoutstr, 4, 16, ra, IM_RA|IM_S0, 0)
	LDGP(pv)
	ldiq	t0, VM_MAX_ADDRESS		/* make sure that dest addr  */
	cmpult	a1, t0, t1			/* is in user space.	     */
	beq	t1, copyfault			/* if it's not, error out.   */
	lda	sp, -16(sp)			/* set up stack frame	     */
	stq	ra, (16-8)(sp)			/* save ra		     */
	stq	s0, (16-16)(sp)			/* save s0		     */
	/* Note: GET_CURPROC clobbers v0, t0, t8...t11. */
	GET_CURPROC
	ldq	t0, 0(v0)
	ldq	s0, P_ADDR(t0)
	lda	v0, copyerr			/* set up fault handler.     */
	stq	v0, U_PCB_ONFAULT(s0)
	CALL(copystr)				/* do the copy.		     */
	stq	zero, U_PCB_ONFAULT(s0)		/* kill the fault handler.   */
	ldq	ra, (16-8)(sp)			/* restore ra.		     */
	ldq	s0, (16-16)(sp)			/* restore s0.		     */
	lda	sp, 16(sp)			/* kill stack frame.	     */
	RET					/* v0 left over from copystr */
	END(copyoutstr)

/*
 * kcopy(const void *src, void *dst, size_t len);
 *
 * Copy len bytes from src to dst, aborting if we encounter a fatal
 * page fault.
 *
 * kcopy() _must_ save and restore the old fault handler since it is
 * called by uiomove(), which may be in the path of servicing a non-fatal
 * page fault.
 */
NESTED(kcopy, 3, 32, ra, IM_RA|IM_S0|IM_S1, 0)
	LDGP(pv)
	lda	sp, -32(sp)			/* set up stack frame	     */
	stq	ra, (32-8)(sp)			/* save ra		     */
	stq	s0, (32-16)(sp)			/* save s0		     */
	stq	s1, (32-24)(sp)			/* save s1		     */
	/* Note: GET_CURPROC clobbers v0, t0, t8...t11. */
	GET_CURPROC
	ldq	t0, 0(v0)
	ldq	s1, P_ADDR(t0)
	lda	v0, kcopyerr			/* set up fault handler.     */
	ldq	s0, U_PCB_ONFAULT(s1)		/* save old handler.	     */
	stq	v0, U_PCB_ONFAULT(s1)
	CALL(bcopy)				/* do the copy.		     */
	stq	s0, U_PCB_ONFAULT(s1)
	ldq	ra, (32-8)(sp)			/* restore ra.		     */
	ldq	s0, (32-16)(sp)			/* restore s0.		     */
	ldq	s1, (32-24)(sp)			/* restore s1.		     */
	lda	sp, 32(sp)			/* kill stack frame.	     */
	mov	zero, v0			/* return 0. */
	RET
	END(kcopy)

LEAF(kcopyerr, 0)
	stq	s0, U_PCB_ONFAULT(s1)		/* restore the old handler.  */
	ldq	ra, (32-8)(sp)			/* restore ra.		     */
	ldq	s0, (32-16)(sp)			/* restore s0.		     */
	ldq	s1, (32-24)(sp)			/* restore s1.		     */
	lda	sp, 32(sp)			/* kill stack frame.	     */
	ldiq	v0, EFAULT			/* return EFAULT.	     */
	RET
END(kcopyerr)

NESTED(copyin, 3, 16, ra, IM_RA|IM_S0, 0)
	LDGP(pv)
	ldiq	t0, VM_MAX_ADDRESS		/* make sure that src addr   */
	cmpult	a0, t0, t1			/* is in user space.	     */
	beq	t1, copyfault			/* if it's not, error out.   */
	lda	sp, -16(sp)			/* set up stack frame	     */
	stq	ra, (16-8)(sp)			/* save ra		     */
	stq	s0, (16-16)(sp)			/* save s0		     */
	/* Note: GET_CURPROC clobbers v0, t0, t8...t11. */
	GET_CURPROC
	ldq	t0, 0(v0)
	ldq	s0, P_ADDR(t0)
	lda	v0, copyerr			/* set up fault handler.     */
	stq	v0, U_PCB_ONFAULT(s0)
	CALL(bcopy)				/* do the copy.		     */
	stq	zero, U_PCB_ONFAULT(s0)		/* kill the fault handler.   */
	ldq	ra, (16-8)(sp)			/* restore ra.		     */
	ldq	s0, (16-16)(sp)			/* restore s0.		     */
	lda	sp, 16(sp)			/* kill stack frame.	     */
	mov	zero, v0			/* return 0. */
	RET
	END(copyin)

NESTED(copyout, 3, 16, ra, IM_RA|IM_S0, 0)
	LDGP(pv)
	ldiq	t0, VM_MAX_ADDRESS		/* make sure that dest addr  */
	cmpult	a1, t0, t1			/* is in user space.	     */
	beq	t1, copyfault			/* if it's not, error out.   */
	lda	sp, -16(sp)			/* set up stack frame	     */
	stq	ra, (16-8)(sp)			/* save ra		     */
	stq	s0, (16-16)(sp)			/* save s0		     */
	/* Note: GET_CURPROC clobbers v0, t0, t8...t11. */
	GET_CURPROC
	GET_CURPROC
	ldq	t0, 0(v0)
	ldq	s0, P_ADDR(t0)
	lda	v0, copyerr			/* set up fault handler.     */
	stq	v0, U_PCB_ONFAULT(s0)
	CALL(bcopy)				/* do the copy.		     */
	stq	zero, U_PCB_ONFAULT(s0)		/* kill the fault handler.   */
	ldq	ra, (16-8)(sp)			/* restore ra.		     */
	ldq	s0, (16-16)(sp)			/* restore s0.		     */
	lda	sp, 16(sp)			/* kill stack frame.	     */
	mov	zero, v0			/* return 0. */
	RET
	END(copyout)

LEAF(copyerr, 0)
	LDGP(pv)
	stq	zero, U_PCB_ONFAULT(s0)		/* kill the fault handler.   */
	ldq	ra, (16-8)(sp)			/* restore ra.		     */
	ldq	s0, (16-16)(sp)			/* restore s0.		     */
	lda	sp, 16(sp)			/* kill stack frame.	     */
copyfault:
	ldiq	v0, EFAULT			/* return EFAULT.	     */
	RET
END(copyerr)

/**************************************************************************/

/*
 * console 'restart' routine to be placed in HWRPB.
 */
LEAF(XentRestart, 1)			/* XXX should be NESTED */
	.set noat
	lda	sp,-(FRAME_SIZE*8)(sp)
	stq	at_reg,(FRAME_AT*8)(sp)
	.set at
	stq	v0,(FRAME_V0*8)(sp)
	stq	a0,(FRAME_A0*8)(sp)
	stq	a1,(FRAME_A1*8)(sp)
	stq	a2,(FRAME_A2*8)(sp)
	stq	a3,(FRAME_A3*8)(sp)
	stq	a4,(FRAME_A4*8)(sp)
	stq	a5,(FRAME_A5*8)(sp)
	stq	s0,(FRAME_S0*8)(sp)
	stq	s1,(FRAME_S1*8)(sp)
	stq	s2,(FRAME_S2*8)(sp)
	stq	s3,(FRAME_S3*8)(sp)
	stq	s4,(FRAME_S4*8)(sp)
	stq	s5,(FRAME_S5*8)(sp)
	stq	s6,(FRAME_S6*8)(sp)
	stq	t0,(FRAME_T0*8)(sp)
	stq	t1,(FRAME_T1*8)(sp)
	stq	t2,(FRAME_T2*8)(sp)
	stq	t3,(FRAME_T3*8)(sp)
	stq	t4,(FRAME_T4*8)(sp)
	stq	t5,(FRAME_T5*8)(sp)
	stq	t6,(FRAME_T6*8)(sp)
	stq	t7,(FRAME_T7*8)(sp)
	stq	t8,(FRAME_T8*8)(sp)
	stq	t9,(FRAME_T9*8)(sp)
	stq	t10,(FRAME_T10*8)(sp)
	stq	t11,(FRAME_T11*8)(sp)
	stq	t12,(FRAME_T12*8)(sp)
	stq	ra,(FRAME_RA*8)(sp)

	br	pv,1f
1:	LDGP(pv)

	mov	sp,a0
	CALL(console_restart)

	call_pal PAL_halt
	END(XentRestart)

/**************************************************************************/

/*
 * Kernel setjmp and longjmp.  Rather minimalist.
 *
 *	longjmp(label_t *a)
 * will generate a "return (1)" from the last call to
 *	setjmp(label_t *a)
 * by restoring registers from the stack,
 */

	.set	noreorder

LEAF(setjmp, 1)
	LDGP(pv)

	stq	ra, (0 * 8)(a0)			/* return address */
	stq	s0, (1 * 8)(a0)			/* callee-saved registers */
	stq	s1, (2 * 8)(a0)
	stq	s2, (3 * 8)(a0)
	stq	s3, (4 * 8)(a0)
	stq	s4, (5 * 8)(a0)
	stq	s5, (6 * 8)(a0)
	stq	s6, (7 * 8)(a0)
	stq	sp, (8 * 8)(a0)

	ldiq	t0, 0xbeeffedadeadbabe		/* set magic number */
	stq	t0, (9 * 8)(a0)

	mov	zero, v0			/* return zero */
	RET
END(setjmp)

LEAF(longjmp, 1)
	LDGP(pv)

	ldiq	t0, 0xbeeffedadeadbabe		/* check magic number */
	ldq	t1, (9 * 8)(a0)
	cmpeq	t0, t1, t0
	beq	t0, longjmp_botch		/* if bad, punt */

	ldq	ra, (0 * 8)(a0)			/* return address */
	ldq	s0, (1 * 8)(a0)			/* callee-saved registers */
	ldq	s1, (2 * 8)(a0)
	ldq	s2, (3 * 8)(a0)
	ldq	s3, (4 * 8)(a0)
	ldq	s4, (5 * 8)(a0)
	ldq	s5, (6 * 8)(a0)
	ldq	s6, (7 * 8)(a0)
	ldq	sp, (8 * 8)(a0)

	ldiq	v0, 1
	RET

longjmp_botch:
	lda	a0, longjmp_botchmsg
	mov	ra, a1
	CALL(panic)
	call_pal PAL_bugchk

	.data
longjmp_botchmsg:
	.asciz	"longjmp botch from %p"
	.text
END(longjmp)

/*
 * void sts(int rn, u_int32_t *rval);
 * void stt(int rn, u_int64_t *rval);
 * void lds(int rn, u_int32_t *rval);
 * void ldt(int rn, u_int64_t *rval);
 */

#ifndef NO_IEEE
.macro make_freg_util name, op
	LEAF(alpha_\name, 2)
	and	a0, 0x1f, a0
	s8addq	a0, pv, pv
	addq	pv, 1f - alpha_\name, pv
	jmp	(pv)
1:
	rn = 0
	.rept   32
	\op     $f0 + rn, 0(a1)
	RET
	rn = rn + 1
	.endr
	END(alpha_\name)
.endm
/*
LEAF(alpha_sts, 2)
LEAF(alpha_stt, 2)
LEAF(alpha_lds, 2)
LEAF(alpha_ldt, 2)
 */
	make_freg_util sts, sts
	make_freg_util stt, stt
	make_freg_util lds, lds
	make_freg_util ldt, ldt

LEAF(alpha_read_fpcr, 0); f30save = 0; rettmp = 8; framesz = 16
	lda	sp, -framesz(sp)
	stt	$f30, f30save(sp)
	mf_fpcr	$f30
	stt	$f30, rettmp(sp)
	ldt	$f30, f30save(sp)
	ldq	v0, rettmp(sp)
	lda	sp, framesz(sp)
	RET
END(alpha_read_fpcr)

LEAF(alpha_write_fpcr, 1); f30save = 0; fpcrtmp = 8; framesz = 16
	lda	sp, -framesz(sp)
	stq	a0, fpcrtmp(sp)
	stt	$f30, f30save(sp)
	ldt	$f30, fpcrtmp(sp)
	mt_fpcr	$f30
	ldt	$f30, f30save(sp)
	lda	sp, framesz(sp)
	RET
END(alpha_write_fpcr)
#endif

#if 0
NESTED(transfer_check,0,0,ra,0,0)
	CALL(U_need_2_run_config)
	END(transfer_check)
#endif

/* Random data that shouldn't be necessary. */
	.data
EXPORT(cold)
	.long 1			/* cold start flag (.long -> _4_ bytes) */
	.align 3
EXPORT(esym)
	.quad 1			/* store end of kernel symbol table here */


/**************************************************************************/
@


1.44
log
@SROP mitigation.  sendsig() stores a (per-process ^ &sigcontext) cookie
inside the sigcontext.  sigreturn(2) checks syscall entry was from the
exact PC addr in the (per-process ASLR) sigtramp, verifies the cookie,
and clears it to prevent sigcontext reuse.
not yet tested on landisk, sparc, *88k, socppc.
ok kettenis
@
text
@d1 1
a1 1
/* $OpenBSD: locore.s,v 1.43 2015/07/20 07:45:23 dlg Exp $ */
d269 1
d283 11
@


1.43
log
@go a bit further with miods last change to copy{in,out}{,str} and
stash the address of the user structure to avoid having to always
follow two pointers to get to the address of the onfault handler.
this lets the code shrink and avoids some register use.

while here, move the range checking of the arguments before saving
the callers args onto the stack so we can ret faster on error.

ok miod@@
@
text
@d1 1
a1 1
/* $OpenBSD: locore.s,v 1.42 2015/06/23 19:49:41 miod Exp $ */
d276 2
@


1.42
log
@In the copy(9) function, make sure to remember curproc accross the bcopy()
call, instead of &curproc. The copy routine may sleep and we may resume on
a different processor. This has been plaguing the alpha MULTIPROCESSOR kernels
since the very beginning; it's amazing this did not cause more havoc.

Joint debugging and hair pulling with dlg@@ and deraadt@@; ok dlg@@
@
text
@d1 1
a1 1
/* $OpenBSD: locore.s,v 1.41 2015/06/11 17:26:17 deraadt Exp $ */
d890 3
d898 2
a899 4
	ldq	s0, 0(v0)
	ldiq	t0, VM_MAX_ADDRESS		/* make sure that src addr   */
	cmpult	a0, t0, t1			/* is in user space.	     */
	beq	t1, copyerr			/* if it's not, error out.   */
d901 1
a901 4
	.set noat
	ldq	at_reg, P_ADDR(s0)
	stq	v0, U_PCB_ONFAULT(at_reg)
	.set at
d903 1
a903 4
	.set noat
	ldq	at_reg, P_ADDR(s0)
	stq	zero, U_PCB_ONFAULT(at_reg)
	.set at
d912 3
d920 2
a921 4
	ldq	s0, 0(v0)
	ldiq	t0, VM_MAX_ADDRESS		/* make sure that dest addr  */
	cmpult	a1, t0, t1			/* is in user space.	     */
	beq	t1, copyerr			/* if it's not, error out.   */
d923 1
a923 4
	.set noat
	ldq	at_reg, P_ADDR(s0)
	stq	v0, U_PCB_ONFAULT(at_reg)
	.set at
d925 1
a925 4
	.set noat
	ldq	at_reg, P_ADDR(s0)		/* kill the fault handler.   */
	stq	zero, U_PCB_ONFAULT(at_reg)
	.set at
d950 2
a951 1
	ldq	s1, 0(v0)
d953 2
a954 5
	.set noat
	ldq	at_reg, P_ADDR(s1)
	ldq	s0, U_PCB_ONFAULT(at_reg)	/* save old handler.	     */
	stq	v0, U_PCB_ONFAULT(at_reg)
	.set at
d956 1
a956 4
	.set noat
	ldq	at_reg, P_ADDR(s1)		/* restore the old handler.  */
	stq	s0, U_PCB_ONFAULT(at_reg)
	.set at
d966 1
a966 5
	LDGP(pv)
	.set noat
	ldq	at_reg, P_ADDR(s1)		/* restore the old handler.  */
	stq	s0, U_PCB_ONFAULT(at_reg)
	.set at
d977 3
d985 2
a986 4
	ldq	s0, 0(v0)
	ldiq	t0, VM_MAX_ADDRESS		/* make sure that src addr   */
	cmpult	a0, t0, t1			/* is in user space.	     */
	beq	t1, copyerr			/* if it's not, error out.   */
d988 1
a988 4
	.set noat
	ldq	at_reg, P_ADDR(s0)
	stq	v0, U_PCB_ONFAULT(at_reg)
	.set at
d990 1
a990 4
	.set noat
	ldq	at_reg, P_ADDR(s0)		/* kill the fault handler.   */
	stq	zero, U_PCB_ONFAULT(at_reg)
	.set at
d1000 3
d1008 3
a1010 4
	ldq	s0, 0(v0)
	ldiq	t0, VM_MAX_ADDRESS		/* make sure that dest addr  */
	cmpult	a1, t0, t1			/* is in user space.	     */
	beq	t1, copyerr			/* if it's not, error out.   */
d1012 1
a1012 4
	.set noat
	ldq	at_reg, P_ADDR(s0)
	stq	v0, U_PCB_ONFAULT(at_reg)
	.set at
d1014 1
a1014 4
	.set noat
	ldq	at_reg, P_ADDR(s0)		/* kill the fault handler.   */
	stq	zero, U_PCB_ONFAULT(at_reg)
	.set at
d1024 1
a1024 4
	.set noat
	ldq	at_reg, P_ADDR(s0)		/* kill the fault handler.   */
	stq	zero, U_PCB_ONFAULT(at_reg)
	.set at
d1028 1
@


1.41
log
@In the copyout family of functions, if the address is out of range
ensure the register containing the proc pointer is initialized.
ok miod
@
text
@d1 1
a1 1
/* $OpenBSD: locore.s,v 1.40 2015/06/05 19:36:28 deraadt Exp $ */
d895 1
a895 1
	mov	v0, s0
d901 1
a901 2
	ldq	at_reg, 0(s0)
	ldq	at_reg, P_ADDR(at_reg)
d906 1
a906 2
	ldq	at_reg, 0(s0)			/* kill the fault handler.   */
	ldq	at_reg, P_ADDR(at_reg)
d922 1
a922 1
	mov	v0, s0
d928 1
a928 2
	ldq	at_reg, 0(s0)
	ldq	at_reg, P_ADDR(at_reg)
d933 1
a933 2
	ldq	at_reg, 0(s0)			/* kill the fault handler.   */
	ldq	at_reg, P_ADDR(at_reg)
d960 1
a960 1
	mov	v0, s1
d963 1
a963 2
	ldq	at_reg, 0(s1)
	ldq	at_reg, P_ADDR(at_reg)
d969 1
a969 2
	ldq	at_reg, 0(s1)			/* restore the old handler.  */
	ldq	at_reg, P_ADDR(at_reg)
d983 1
a983 2
	ldq	at_reg, 0(s1)			/* restore the old handler.  */
	ldq	at_reg, P_ADDR(at_reg)
d1001 1
a1001 1
	mov	v0, s0
d1007 1
a1007 2
	ldq	at_reg, 0(s0)
	ldq	at_reg, P_ADDR(at_reg)
d1012 1
a1012 2
	ldq	at_reg, 0(s0)			/* kill the fault handler.   */
	ldq	at_reg, P_ADDR(at_reg)
d1029 1
a1029 1
	mov	v0, s0
d1035 1
a1035 2
	ldq	at_reg, 0(s0)
	ldq	at_reg, P_ADDR(at_reg)
d1040 1
a1040 2
	ldq	at_reg, 0(s0)			/* kill the fault handler.   */
	ldq	at_reg, P_ADDR(at_reg)
d1053 1
a1053 2
	ldq	at_reg, 0(s0)			/* kill the fault handler.   */
	ldq	at_reg, P_ADDR(at_reg)
@


1.40
log
@And ... more discussion occurs between miod and kettenis about
what register dance copyerr should do.....
@
text
@d1 1
a1 1
/* $OpenBSD: locore.s,v 1.39 2015/06/05 18:36:07 deraadt Exp $ */
d893 3
a898 3
	/* Note: GET_CURPROC clobbers v0, t0, t8...t11. */
	GET_CURPROC
	mov	v0, s0
d922 3
a927 3
	/* Note: GET_CURPROC clobbers v0, t0, t8...t11. */
	GET_CURPROC
	mov	v0, s0
d1006 3
a1011 3
	/* Note: GET_CURPROC clobbers v0, t0, t8...t11. */
	GET_CURPROC
	mov	v0, s0
d1036 3
a1041 3
	/* Note: GET_CURPROC clobbers v0, t0, t8...t11. */
	GET_CURPROC
	mov	v0, s0
@


1.39
log
@And part 2 of the onfault repair.  Do the actual clearing of pcb_onfault
in copyerr itself, like other architectures of this type do.
as a result of chatter between miod and kettenis
@
text
@d1 1
a1 1
/* $OpenBSD: locore.s,v 1.38 2014/01/26 17:40:09 miod Exp $ */
d1064 2
a1065 1
	ldq	at_reg, P_ADDR(at_reg)		/* clear handler.            */
@


1.38
log
@Work in progress work towards SMP, heavily based upon NetBSD. The MP kernel
will boot multiuser, but will deadlock under load, and I can't find my
mistake yet.
@
text
@d1 1
a1 1
/* $OpenBSD: locore.s,v 1.37 2013/06/13 02:27:23 deraadt Exp $ */
d1063 4
@


1.37
log
@bcopy/memmove/memcpy are now in libkern
tested, but noone commented because it is apparently summer
@
text
@d1 1
a1 1
/* $OpenBSD: locore.s,v 1.36 2013/06/11 21:16:14 deraadt Exp $ */
d95 1
a95 1
IMPORT(cpu_info_store, CPU_INFO_SIZEOF)
d97 1
a97 1
#define	GET_CPUINFO		lda v0, cpu_info_store
d99 1
a99 1
#define	GET_CURPROC		lda v0, cpu_info_store + CPU_INFO_CURPROC
d101 1
a101 1
#define	GET_FPCURPROC		lda v0, cpu_info_store + CPU_INFO_FPCURPROC
d103 1
a103 1
#define	GET_CURPCB		lda v0, cpu_info_store + CPU_INFO_CURPCB
d106 1
a106 1
	lda	reg, cpu_info_store				;	\
a291 14

#if defined(MULTIPROCESSOR)
	/* XXX XXX XXX */
	/*
	 * Check the current processor ID.  If we're not the primary
	 * CPU, then just restore registers and bail out.
	 */
	call_pal PAL_OSF1_whami
	lda	t0, hwrpb
	ldq	t0, 0(t0)
	ldq	t1, RPB_PRIMARY_CPU_ID(t0)
	cmpeq	t1, v0, t0
	beq	t0, 4f				/* == 0: bail out now */
#endif
@


1.36
log
@bcopy (and family) can check for 0 length, but negative lengths should
proceed through to crash and show the bug.
ok miod
@
text
@d1 1
a1 1
/* $OpenBSD: locore.s,v 1.35 2012/11/01 21:09:17 miod Exp $ */
a958 237

/*
 * Copy a bytes within the kernel's address space.
 *
 * Although bcopy() is not specified to handle overlapping regions,
 * this version does do so.
 *
 * void bcopy(char *from, char *to, size_t len);
 */
LEAF(memcpy,3)
	cmoveq  zero,a0,t5
	cmoveq  zero,a1,a0
	cmoveq  zero,t5,a1

XLEAF(bcopy,3)
XLEAF(ovbcopy,3)

	/* Check for zero length */
	beq	a2,bcopy_done

	/* Check for overlap */
	subq	a1,a0,t5
	cmpult	t5,a2,t5
	bne	t5,bcopy_overlap

	/* a3 = end address */
	addq	a0,a2,a3

	/* Get the first word */
	ldq_u	t2,0(a0)

	/* Do they have the same alignment? */
	xor	a0,a1,t0
	and	t0,7,t0
	and	a1,7,t1
	bne	t0,bcopy_different_alignment

	/* src & dst have same alignment */
	beq	t1,bcopy_all_aligned

	ldq_u	t3,0(a1)
	addq	a2,t1,a2
	mskqh	t2,a0,t2
	mskql	t3,a0,t3
	or	t2,t3,t2

	/* Dst is 8-byte aligned */

bcopy_all_aligned:
	/* If less than 8 bytes,skip loop */
	subq	a2,1,t0
	and	a2,7,a2
	bic	t0,7,t0
	beq	t0,bcopy_samealign_lp_end

bcopy_samealign_lp:
	stq_u	t2,0(a1)
	addq	a1,8,a1
	ldq_u	t2,8(a0)
	subq	t0,8,t0
	addq	a0,8,a0
	bne	t0,bcopy_samealign_lp

bcopy_samealign_lp_end:
	/* If we're done, exit */
	bne	a2,bcopy_small_left
	stq_u	t2,0(a1)
	RET

bcopy_small_left:
	mskql	t2,a2,t4
	ldq_u	t3,0(a1)
	mskqh	t3,a2,t3
	or	t4,t3,t4
	stq_u	t4,0(a1)
	RET

bcopy_different_alignment:
	/*
	 * this is the fun part
	 */
	addq	a0,a2,a3
	cmpule	a2,8,t0
	bne	t0,bcopy_da_finish

	beq	t1,bcopy_da_noentry

	/* Do the initial partial word */
	subq	zero,a1,t0
	and	t0,7,t0
	ldq_u	t3,7(a0)
	extql	t2,a0,t2
	extqh	t3,a0,t3
	or	t2,t3,t5
	insql	t5,a1,t5
	ldq_u	t6,0(a1)
	mskql	t6,a1,t6
	or	t5,t6,t5
	stq_u	t5,0(a1)
	addq	a0,t0,a0
	addq	a1,t0,a1
	subq	a2,t0,a2
	ldq_u	t2,0(a0)

bcopy_da_noentry:
	subq	a2,1,t0
	bic	t0,7,t0
	and	a2,7,a2
	beq	t0,bcopy_da_finish2

bcopy_da_lp:
	ldq_u	t3,7(a0)
	addq	a0,8,a0
	extql	t2,a0,t4
	extqh	t3,a0,t5
	subq	t0,8,t0
	or	t4,t5,t5
	stq	t5,0(a1)
	addq	a1,8,a1
	beq	t0,bcopy_da_finish1
	ldq_u	t2,7(a0)
	addq	a0,8,a0
	extql	t3,a0,t4
	extqh	t2,a0,t5
	subq	t0,8,t0
	or	t4,t5,t5
	stq	t5,0(a1)
	addq	a1,8,a1
	bne	t0,bcopy_da_lp

bcopy_da_finish2:
	/* Do the last new word */
	mov	t2,t3

bcopy_da_finish1:
	/* Do the last partial word */
	ldq_u	t2,-1(a3)
	extql	t3,a0,t3
	extqh	t2,a0,t2
	or	t2,t3,t2
	br	zero,bcopy_samealign_lp_end

bcopy_da_finish:
	/* Do the last word in the next source word */
	ldq_u	t3,-1(a3)
	extql	t2,a0,t2
	extqh	t3,a0,t3
	or	t2,t3,t2
	insqh	t2,a1,t3
	insql	t2,a1,t2
	lda	t4,-1(zero)
	mskql	t4,a2,t5
	cmovne	t5,t5,t4
	insqh	t4,a1,t5
	insql	t4,a1,t4
	addq	a1,a2,a4
	ldq_u	t6,0(a1)
	ldq_u	t7,-1(a4)
	bic	t6,t4,t6
	bic	t7,t5,t7
	and	t2,t4,t2
	and	t3,t5,t3
	or	t2,t6,t2
	or	t3,t7,t3
	stq_u	t3,-1(a4)
	stq_u	t2,0(a1)
	RET

bcopy_overlap:
	/*
	 * Basically equivalent to previous case, only backwards.
	 * Not quite as highly optimized
	 */
	addq	a0,a2,a3
	addq	a1,a2,a4

	/* less than 8 bytes - don't worry about overlap */
	cmpule	a2,8,t0
	bne	t0,bcopy_ov_short

	/* Possibly do a partial first word */
	and	a4,7,t4
	beq	t4,bcopy_ov_nostart2
	subq	a3,t4,a3
	subq	a4,t4,a4
	ldq_u	t1,0(a3)
	subq	a2,t4,a2
	ldq_u	t2,7(a3)
	ldq	t3,0(a4)
	extql	t1,a3,t1
	extqh	t2,a3,t2
	or	t1,t2,t1
	mskqh	t3,t4,t3
	mskql	t1,t4,t1
	or	t1,t3,t1
	stq	t1,0(a4)

bcopy_ov_nostart2:
	bic	a2,7,t4
	and	a2,7,a2
	beq	t4,bcopy_ov_lp_end

bcopy_ov_lp:
	/* This could be more pipelined, but it doesn't seem worth it */
	ldq_u	t0,-8(a3)
	subq	a4,8,a4
	ldq_u	t1,-1(a3)
	subq	a3,8,a3
	extql	t0,a3,t0
	extqh	t1,a3,t1
	subq	t4,8,t4
	or	t0,t1,t0
	stq	t0,0(a4)
	bne	t4,bcopy_ov_lp

bcopy_ov_lp_end:
	beq	a2,bcopy_done

	ldq_u	t0,0(a0)
	ldq_u	t1,7(a0)
	ldq_u	t2,0(a1)
	extql	t0,a0,t0
	extqh	t1,a0,t1
	or	t0,t1,t0
	insql	t0,a1,t0
	mskql	t2,a1,t2
	or	t2,t0,t2
	stq_u	t2,0(a1)

bcopy_done:
	RET

bcopy_ov_short:
	ldq_u	t2,0(a0)
	br	zero,bcopy_da_finish

	END(memcpy)
@


1.35
log
@Switch alpha to per-process astpending.
@
text
@d1 1
a1 1
/* $OpenBSD: locore.s,v 1.34 2008/07/28 19:08:43 miod Exp $ */
d976 2
a977 2
	/* Check for negative length */
	ble	a2,bcopy_done
@


1.34
log
@No longer clear ci_want_resched within cpu_switchto(), now that it's done
in the MI code.
@
text
@d1 1
a1 1
/* $OpenBSD: locore.s,v 1.33 2008/06/26 05:42:08 ray Exp $ */
d154 1
a154 1
 *	a0 is the first free page frame number (PFN)
a168 1
	or	a0,zero,s0		/* save pfn */
a170 1
	or	s0,zero,a0		/* restore pfn */
d175 1
a175 1
	 * which are already in a0, a1, a2, a3 and a4.
d323 2
a324 1
	ldq	t2, CPU_INFO_ASTPENDING(v0)	/* AST pending? */
a332 1
	ldq	t1, CPU_INFO_CURPROC(v0)
@


1.33
log
@First pass at removing clauses 3 and 4 from NetBSD licenses.

Not sure what's more surprising: how long it took for NetBSD to
catch up to the rest of the BSDs (including UCB), or the amount of
code that NetBSD has claimed for itself without attributing to the
actual authors.

OK deraadt@@
@
text
@d1 1
a1 1
/* $OpenBSD: locore.s,v 1.32 2008/01/13 20:59:52 kettenis Exp $ */
a793 1
	stq	zero, CPU_INFO_WANT_RESCHED(v0)	/* we've rescheduled */
@


1.32
log
@Replace STABS debug info (which causes problems with truncated relocations)
with some limited DWARF2 generating .file and .line symbols.  Makes it possible
to build kernels with debug information again.

ok miod@@
@
text
@d1 1
a1 1
/* $OpenBSD: locore.s,v 1.31 2007/10/10 15:53:51 art Exp $ */
a19 7
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *	This product includes software developed by the NetBSD
 *	Foundation, Inc. and its contributors.
 * 4. Neither the name of The NetBSD Foundation nor the names of its
 *    contributors may be used to endorse or promote products derived
 *    from this software without specific prior written permission.
@


1.31
log
@Make context switching much more MI:
 - Move the functionality of choosing a process from cpu_switch into
   a much simpler function: cpu_switchto. Instead of having the locore
   code walk the run queues, let the MI code choose the process we
   want to run and only implement the context switching itself in MD
   code.
 - Let MD context switching run without worrying about spls or locks.
 - Instead of having the idle loop implemented with special contexts
   in MD code, implement one idle proc for each cpu. make the idle
   loop MI with MD hooks.
 - Change the proc lists from the old style vax queues to TAILQs.
 - Change the sleep queue from vax queues to TAILQs. This makes
   wakeup() go from O(n^2) to O(n)

there will be some MD fallout, but it will be fixed shortly.
There's also a few cleanups to be done after this.

deraadt@@, kettenis@@ ok
@
text
@d1 1
a1 1
/* $OpenBSD: locore.s,v 1.30 2007/05/28 23:10:10 beck Exp $ */
d68 1
a68 3
.file 1 __FILE__

.stabs	__FILE__,100,0,0,kernel_text
a73 2
.stabs	__FILE__,132,0,0,kernel_text

a258 1
.stabs	__FILE__,132,0,0,backtolocore1	/* done with includes */
@


1.30
log
@Maintaining a broken compatibility layer for a broken OS is not a productive
activity for anyone. Bye bye COMPAT_NETBSD. ok tedu@@, deraadt@@, and many others
in the hackathon room.
@
text
@d1 1
a1 1
/* $OpenBSD: locore.s,v 1.29 2006/05/25 01:33:43 brad Exp $ */
a718 29
IMPORT(whichqs, 4)

/*
 * When no processes are on the runq, cpu_switch branches to idle
 * to wait for something to come ready.
 * Note: this is really a part of cpu_switch() but defined here for kernel
 * profiling.
 */
LEAF(idle, 0)
	br	pv, 1f
1:	LDGP(pv)
	/* Note: GET_CURPROC clobbers v0, t0, t8...t11. */
	GET_CURPROC
	stq	zero, 0(v0)			/* curproc <- NULL for stats */
#if defined(MULTIPROCESSOR) || defined(LOCKDEBUG)
	CALL(sched_unlock_idle)			/* release sched_lock */
#endif
	mov	zero, a0			/* enable all interrupts */
	call_pal PAL_OSF1_swpipl
2:	ldl	t0, whichqs			/* look for non-empty queue */
	beq	t0, 2b
	ldiq	a0, ALPHA_PSL_IPL_HIGH		/* disable all interrupts */
	call_pal PAL_OSF1_swpipl
#if defined(MULTIPROCESSOR) || defined(LOCKDEBUG)
	CALL(sched_lock_idle)			/* acquire sched_lock */
#endif
	jmp	zero, cpu_switch_queuescan	/* jump back into the fire */
	END(idle)

d720 2
a721 2
 * cpu_switch()
 * Find the highest priority process and resume it.
d723 1
a723 1
LEAF(cpu_switch, 0)
a724 58
	/*
	 * do an inline savectx(), to save old context
	 * Note: GET_CURPROC clobbers v0, t0, t8...t11.
	 */
	GET_CURPROC
	ldq	a0, 0(v0)
	ldq	a1, P_ADDR(a0)
	/* NOTE: ksp is stored by the swpctx */
	stq	s0, U_PCB_CONTEXT+(0 * 8)(a1)	/* store s0 - s6 */
	stq	s1, U_PCB_CONTEXT+(1 * 8)(a1)
	stq	s2, U_PCB_CONTEXT+(2 * 8)(a1)
	stq	s3, U_PCB_CONTEXT+(3 * 8)(a1)
	stq	s4, U_PCB_CONTEXT+(4 * 8)(a1)
	stq	s5, U_PCB_CONTEXT+(5 * 8)(a1)
	stq	s6, U_PCB_CONTEXT+(6 * 8)(a1)
	stq	ra, U_PCB_CONTEXT+(7 * 8)(a1)	/* store ra */
	call_pal PAL_OSF1_rdps			/* NOTE: doesn't kill a0 */
	stq	v0, U_PCB_CONTEXT+(8 * 8)(a1)	/* store ps, for ipl */

	mov	a0, s0				/* save old curproc */
	mov	a1, s1				/* save old U-area */
 
cpu_switch_queuescan:
	br	pv, 1f
1:	LDGP(pv)
	ldl	t0, whichqs		/* look for non-empty queue */
	beq	t0, idle			/* and if none, go idle */
	mov	t0, t3				/* t3 = saved whichqs */
	mov	zero, t2			/* t2 = lowest bit set */
	blbs	t0, 3f				/* if low bit set, done! */

2:	srl	t0, 1, t0			/* try next bit */
	addq	t2, 1, t2
	blbc	t0, 2b				/* if clear, try again */

3:	/*
	 * Remove process from queue
	 */
	lda	t1, qs				/* get queues */
	sll	t2, 4, t0			/* queue head is 16 bytes */
	addq	t1, t0, t0			/* t0 = qp = &qs[firstbit] */

	ldq	t4, PH_LINK(t0)			/* t4 = p = highest pri proc */
	bne	t4, 4f				/* make sure p != NULL */
	PANIC("cpu_switch",Lcpu_switch_pmsg)	/* nothing in queue! */

4:
	ldq	t5, P_FORW(t4)			/* t5 = p->p_forw */
	stq	t5, PH_LINK(t0)			/* qp->ph_link = p->p_forw */
	stq	t0, P_BACK(t5)			/* p->p_forw->p_back = qp */
	stq	zero, P_BACK(t4)		/* firewall: p->p_back = NULL */
	cmpeq	t0, t5, t0			/* see if queue is empty */
	beq	t0, 5f				/* nope, it's not! */

	ldiq	t0, 1				/* compute bit in whichqs */
	sll	t0, t2, t0
	xor	t3, t0, t3			/* clear bit in whichqs */
	stl	t3, whichqs
a725 4
5:
	mov	t4, s2				/* save new proc */
	ldq	s3, P_MD_PCBPADDR(s2)		/* save new pcbpaddr */
#if defined(MULTIPROCESSOR) || defined(LOCKDEBUG)
d727 1
a727 2
	 * Done mucking with the run queues, release the
	 * scheduler lock, but keep interrupts out.
d729 1
a729 2
	CALL(sched_unlock_idle)
#endif
d732 1
a732 8
	 * Check to see if we're switching to ourself.  If we are,
	 * don't bother loading the new context.
	 *
	 * Note that even if we re-enter cpu_switch() from idle(),
	 * s0 will still contain the old curproc value because any
	 * users of that register between then and now must have
	 * saved it.  Also note that switch_exit() ensures that
	 * s0 is clear before jumping here to find a new process.
d734 17
a750 2
	cmpeq	s0, s2, t0			/* oldproc == newproc? */
	bne	t0, 7f				/* Yes!  Skip! */
d760 1
a760 1
	 * We don't deactivate if we came here from switch_exit
d766 1
a766 1
	beq	s0, 6f
d771 1
a771 1
6:	/*
d782 1
a782 1
7:	/*
d829 1
a829 1
	END(cpu_switch)
d844 12
a873 40

/*
 * switch_exit(struct proc *p)
 * Make a the named process exit.  Partially switch to our idle thread
 * (we don't update curproc or restore registers), and jump into the middle
 * of cpu_switch to switch into a few process.  The process reaper will
 * free the dead process's VM resources.  MUST BE CALLED AT SPLHIGH.
 */
LEAF(switch_exit, 1)
	LDGP(pv)

	/* save the exiting proc pointer */
	mov	a0, s2

	/* Switch to our idle stack. */
	GET_IDLE_PCB(a0)			/* clobbers v0, t0, t8-t11 */
	SWITCH_CONTEXT

	/*
	 * Now running as idle thread, except for the value of 'curproc' and
	 * the saved regs.
	 */

	/* Schedule the vmspace and stack to be freed. */
	mov	s2, a0
	CALL(exit2)

#if defined(MULTIPROCESSOR) || defined(LOCKDEBUG)
	CALL(sched_lock_idle)			/* acquire sched_lock */
#endif

	/*
	 * Now jump back into the middle of cpu_switch().  Note that
	 * we must clear s0 to guarantee that the check for switching
	 * to ourselves in cpu_switch() will fail.  This is safe since
	 * s0 will be restored when a new process is resumed.
	 */
	mov	zero, s0
	jmp	zero, cpu_switch_queuescan
	END(switch_exit)
@


1.29
log
@gas will error out with a number of "Error: unassigned file number 1"
messages when compiling with gcc3, so to appease gas I have added
".file 1 __FILE__" at the top of locore. now a kernel will compile
using gcc3.

thanks to jason@@ for pointing out the fix via this URL..
http://sourceware.org/ml/binutils/2001-05/msg00043.html

ok deraadt@@
@
text
@d1 1
a1 1
/* $OpenBSD: locore.s,v 1.28 2005/06/17 21:54:14 miod Exp $ */
a293 21

/**************************************************************************/

#ifdef COMPAT_NETBSD
/*
 * NetBSD signal trampoline code.  Almost identical to the normal one.
 */

NESTED(netbsd_sigcode,0,0,ra,0,0)
	lda	sp, -16(sp)		/* save the sigcontext pointer */
	stq	a2, 0(sp)
	jsr	ra, (t12)		/* call the signal handler (t12==pv) */
	ldq	a0, 0(sp)		/* get the sigcontext pointer */
	lda	sp, 16(sp)
	NETBSD_CALLSYS_NOERROR(__sigreturn14)/* and call sigreturn() with it. */
	mov	v0, a0			/* if that failed, get error code */
	NETBSD_CALLSYS_NOERROR(exit)		/* and call exit() with it. */
XNESTED(netbsd_esigcode,0)
	END(netbsd_sigcode)

#endif /* COMPAT_NETBSD */
@


1.28
log
@Override cpu_switch() with a faster version if we can use BWX instructions.
From RusticBSD, ok deraadt@@
@
text
@d1 1
a1 1
/* $OpenBSD: locore.s,v 1.27 2004/12/24 22:50:27 miod Exp $ */
d68 2
d1344 1
a1344 1
	END(bcopy)
@


1.27
log
@{e,}intr{cnt,names} bye-bye.
@
text
@d1 1
a1 1
/* $OpenBSD: locore.s,v 1.26 2004/07/03 19:22:57 deraadt Exp $ */
d894 1
a894 4
#ifdef __alpha_bwx__
	ldiq	t0, SONPROC			/* p->p_stat = SONPROC */
	stb	t0, P_STAT(s2)
#else
d902 1
a902 1
#endif /* __alpha_bwx__ */
d934 13
@


1.26
log
@sigh, not yet
@
text
@d1 1
a1 1
/* $OpenBSD: locore.s,v 1.23 2004/06/28 02:28:42 aaron Exp $ */
a1456 15

/**************************************************************************/

	.data
/* Some bogus data, to keep vmstat happy, for now. */
EXPORT(intrnames)
	.type intrnames,@@object
EXPORT(eintrnames)
	.type eintrnames,@@object
	.align 3
EXPORT(intrcnt)
	.type intrcnt,@@object
EXPORT(eintrcnt)
	.type eintrcnt,@@object
	.text
@


1.25
log
@oops something went wrong in commit
@
text
@d1458 17
@


1.24
log
@{e,}intr{names,cnt} are extinct
@
text
@a1642 36
From deraadt Sat Jul  3 12:18:12 2004
To: alpha/locore.s
Subject: {e,}intr{names,cnt} are extinct

Index: alpha/locore.s
===================================================================
RCS file: /cvs/src/sys/arch/alpha/alpha/locore.s,v
retrieving revision 1.23
diff -u -r1.23 locore.s
--- alpha/locore.s	28 Jun 2004 02:28:42 -0000	1.23
+++ alpha/locore.s	3 Jul 2004 18:01:10 -0000
@@@@ -1455,23 +1455,6 @@@@
 	RET
 END(copyerr)
 
-/**************************************************************************/
-
-	.data
-/* Some bogus data, to keep vmstat happy, for now. */
-EXPORT(intrnames)
-	.type intrnames,@@object
-EXPORT(eintrnames)
-	.type eintrnames,@@object
-	.align 3
-EXPORT(intrcnt)
-	.type intrcnt,@@object
-EXPORT(eintrcnt)
-	.type eintrcnt,@@object
-	.text
-
-/**************************************************************************/
-
 /*
  * console 'restart' routine to be placed in HWRPB.
  */

@


1.23
log
@Use new event counter API for interrupt counting on alpha.  By me, with some
edits by Theo.  deraadt@@ ok
@
text
@d1 1
a1 1
/* $OpenBSD: locore.s,v 1.22 2004/06/13 21:49:11 niklas Exp $ */
a1457 17
/**************************************************************************/

	.data
/* Some bogus data, to keep vmstat happy, for now. */
EXPORT(intrnames)
	.type intrnames,@@object
EXPORT(eintrnames)
	.type eintrnames,@@object
	.align 3
EXPORT(intrcnt)
	.type intrcnt,@@object
EXPORT(eintrcnt)
	.type eintrcnt,@@object
	.text

/**************************************************************************/

d1643 36
@


1.22
log
@debranch SMP, have fun
@
text
@d1 1
a1 1
/* $OpenBSD$ */
a1459 6
/*
 * Some bogus data, to keep vmstat happy, for now.
 */

#include <machine/intrcnt.h>

d1461 1
a1463 3
#ifndef EVCNT_COUNTERS
	INTRNAMES_DEFINITION
#endif
a1468 3
#ifndef EVCNT_COUNTERS
	INTRCNT_DEFINITION
#endif
@


1.21
log
@typos from Jared Yanovich;
@
text
@d1 1
a1 1
/* $OpenBSD: locore.s,v 1.20 2003/01/09 22:27:03 miod Exp $ */
a893 1
#if 0
a905 1
#endif
@


1.20
log
@Remove fetch(9) and store(9) functions from the kernel, and replace the few
remaining instances of them with appropriate copy(9) usage.

ok art@@, tested on all arches unless my memory is non-ECC
@
text
@d1 1
a1 1
/* $OpenBSD: locore.s,v 1.19 2002/05/02 23:05:27 millert Exp $ */
d240 1
a240 1
 * Pull in the multiprocssor glue.
@


1.19
log
@Add a type specifier for intrnames, eintrnames, intrcnt, and eintrcnt.
Without this, n_type in struct nlist ends up as N_UNDF for those
symbols which makes vmstat -i unhappy.
mido@@ OK
@
text
@d1 1
a1 1
/* $OpenBSD: locore.s,v 1.18 2002/04/28 20:55:14 pvalchev Exp $ */
a1458 313

/**************************************************************************/

/*
 * {fu,su},{ibyte,isword,iword}, fetch or store a byte, short or word to
 * user text space.
 * {fu,su},{byte,sword,word}, fetch or store a byte, short or word to
 * user data space.
 */
LEAF(fuword, 1)
XLEAF(fuiword, 1)
	LDGP(pv)
	ldiq	t0, VM_MAX_ADDRESS		/* make sure that addr */
	cmpult	a0, t0, t1			/* is in user space. */
	beq	t1, fswberr			/* if it's not, error out. */
	/* Note: GET_CURPROC clobbers v0, t0, t8...t11. */
	GET_CURPROC
	mov	v0, t1
	lda	t0, fswberr
	.set noat
	ldq	at_reg, 0(t1)
	ldq	at_reg, P_ADDR(at_reg)
	stq	t0, U_PCB_ONFAULT(at_reg)
	.set at
	ldq	v0, 0(a0)
	zap	v0, 0xf0, v0
	.set noat
	ldq	at_reg, 0(t1)
	ldq	at_reg, P_ADDR(at_reg)
	stq	zero, U_PCB_ONFAULT(at_reg)
	.set at
	RET
	END(fuword)

LEAF(fusword, 1)
XLEAF(fuisword, 1)
	LDGP(pv)
	ldiq	t0, VM_MAX_ADDRESS		/* make sure that addr */
	cmpult	a0, t0, t1			/* is in user space. */
	beq	t1, fswberr			/* if it's not, error out. */
	/* Note: GET_CURPROC clobbers v0, t0, t8...t11. */
	GET_CURPROC
	mov	v0, t1
	lda	t0, fswberr
	.set noat
	ldq	at_reg, 0(t1)
	ldq	at_reg, P_ADDR(at_reg)
	stq	t0, U_PCB_ONFAULT(at_reg)
	.set at
	/* XXX FETCH IT */
	.set noat
	ldq	at_reg, 0(t1)
	ldq	at_reg, P_ADDR(at_reg)
	stq	zero, U_PCB_ONFAULT(at_reg)
	.set at
	RET
	END(fusword)

LEAF(fubyte, 1)
XLEAF(fuibyte, 1)
	LDGP(pv)
	ldiq	t0, VM_MAX_ADDRESS		/* make sure that addr */
	cmpult	a0, t0, t1			/* is in user space. */
	beq	t1, fswberr			/* if it's not, error out. */
	/* Note: GET_CURPROC clobbers v0, t0, t8...t11. */
	GET_CURPROC
	mov	v0, t1
	lda	t0, fswberr
	.set noat
	ldq	at_reg, 0(t1)
	ldq	at_reg, P_ADDR(at_reg)
	stq	t0, U_PCB_ONFAULT(at_reg)
	.set at
	/* XXX FETCH IT */
	.set noat
	ldq	at_reg, 0(t1)
	ldq	at_reg, P_ADDR(at_reg)
	stq	zero, U_PCB_ONFAULT(at_reg)
	.set at
	RET
	END(fubyte)

LEAF(suword, 2)
	LDGP(pv)
	ldiq	t0, VM_MAX_ADDRESS		/* make sure that addr */
	cmpult	a0, t0, t1			/* is in user space. */
	beq	t1, fswberr			/* if it's not, error out. */
	/* Note: GET_CURPROC clobbers v0, t0, t8...t11. */
	GET_CURPROC
	mov	v0, t1
	lda	t0, fswberr
	.set noat
	ldq	at_reg, 0(t1)
	ldq	at_reg, P_ADDR(at_reg)
	stq	t0, U_PCB_ONFAULT(at_reg)
	.set at
	stq	a1, 0(a0)			/* do the store. */
	.set noat
	ldq	at_reg, 0(t1)
	ldq	at_reg, P_ADDR(at_reg)
	stq	zero, U_PCB_ONFAULT(at_reg)
	.set at
	mov	zero, v0
	RET
	END(suword)

#ifdef notdef
LEAF(suiword, 2)
	LDGP(pv)
	ldiq	t0, VM_MAX_ADDRESS		/* make sure that addr */
	cmpult	a0, t0, t1			/* is in user space. */
	beq	t1, fswberr			/* if it's not, error out. */
	/* Note: GET_CURPROC clobbers v0, t0, t8...t11. */
	GET_CURPROC
	mov	v0, t1
	lda	t0, fswberr
	.set noat
	ldq	at_reg, 0(t1)
	ldq	at_reg, P_ADDR(at_reg)
	stq	t0, U_PCB_ONFAULT(at_reg)
	.set at
	/* XXX STORE IT */
	.set noat
	ldq	at_reg, 0(t1)
	ldq	at_reg, P_ADDR(at_reg)
	stq	zero, U_PCB_ONFAULT(at_reg)
	.set at
	call_pal PAL_OSF1_imb			/* sync instruction stream */
	mov	zero, v0
	RET
	END(suiword)

LEAF(susword, 2)
	LDGP(pv)
	ldiq	t0, VM_MAX_ADDRESS		/* make sure that addr */
	cmpult	a0, t0, t1			/* is in user space. */
	beq	t1, fswberr			/* if it's not, error out. */
	/* Note: GET_CURPROC clobbers v0, t0, t8...t11. */
	GET_CURPROC
	mov	v0, t1
	lda	t0, fswberr
	.set noat
	ldq	at_reg, 0(t1)
	ldq	at_reg, P_ADDR(at_reg)
	stq	t0, U_PCB_ONFAULT(at_reg)
	.set at
	/* XXX STORE IT */
	.set noat
	ldq	at_reg, 0(t1)
	ldq	at_reg, P_ADDR(at_reg)
	stq	zero, U_PCB_ONFAULT(at_reg)
	.set at
	mov	zero, v0
	RET
	END(susword)

LEAF(suisword, 2)
	LDGP(pv)
	ldiq	t0, VM_MAX_ADDRESS		/* make sure that addr */
	cmpult	a0, t0, t1			/* is in user space. */
	beq	t1, fswberr			/* if it's not, error out. */
	/* Note: GET_CURPROC clobbers v0, t0, t8...t11. */
	GET_CURPROC
	mov	v0, t1
	lda	t0, fswberr
	.set noat
	ldq	at_reg, 0(t1)
	ldq	at_reg, P_ADDR(at_reg)
	stq	t0, U_PCB_ONFAULT(at_reg)
	.set at
	/* XXX STORE IT */
	.set noat
	ldq	at_reg, 0(t1)
	ldq	at_reg, P_ADDR(at_reg)
	stq	zero, U_PCB_ONFAULT(at_reg)
	.set at
	call_pal PAL_OSF1_imb			/* sync instruction stream */
	mov	zero, v0
	RET
	END(suisword)
#endif /* notdef */

LEAF(subyte, 2)
	LDGP(pv)
	ldiq	t0, VM_MAX_ADDRESS		/* make sure that addr */
	cmpult	a0, t0, t1			/* is in user space. */
	beq	t1, fswberr			/* if it's not, error out. */
	/* Note: GET_CURPROC clobbers v0, t0, t8...t11. */
	GET_CURPROC
	mov	v0, t1
	lda	t0, fswberr
	.set noat
	ldq	at_reg, 0(t1)
	ldq	at_reg, P_ADDR(at_reg)
	stq	t0, U_PCB_ONFAULT(at_reg)
	.set at
	zap	a1, 0xfe, a1			/* kill arg's high bytes */
	insbl	a1, a0, a1			/* move it to the right byte */
	ldq_u	t0, 0(a0)			/* load quad around byte */
	mskbl	t0, a0, t0			/* kill the target byte */
	or	t0, a1, a1			/* put the result together */
	stq_u	a1, 0(a0)			/* and store it. */
	.set noat
	ldq	at_reg, 0(t1)
	ldq	at_reg, P_ADDR(at_reg)
	stq	zero, U_PCB_ONFAULT(at_reg)
	.set at
	mov	zero, v0
	RET
	END(subyte)

LEAF(suibyte, 2)
	LDGP(pv)
	ldiq	t0, VM_MAX_ADDRESS		/* make sure that addr */
	cmpult	a0, t0, t1			/* is in user space. */
	beq	t1, fswberr			/* if it's not, error out. */
	/* Note: GET_CURPROC clobbers v0, t0, t8...t11. */
	GET_CURPROC
	mov	v0, t1
	lda	t0, fswberr
	.set noat
	ldq	at_reg, 0(t1)
	ldq	at_reg, P_ADDR(at_reg)
	stq	t0, U_PCB_ONFAULT(at_reg)
	.set at
	zap	a1, 0xfe, a1			/* kill arg's high bytes */
	insbl	a1, a0, a1			/* move it to the right byte */
	ldq_u	t0, 0(a0)			/* load quad around byte */
	mskbl	t0, a0, t0			/* kill the target byte */
	or	t0, a1, a1			/* put the result together */
	stq_u	a1, 0(a0)			/* and store it. */
	.set noat
	ldq	at_reg, 0(t1)
	ldq	at_reg, P_ADDR(at_reg)
	stq	zero, U_PCB_ONFAULT(at_reg)
	.set at
	call_pal PAL_OSF1_imb			/* sync instruction stream */
	mov	zero, v0
	RET
	END(suibyte)

LEAF(fswberr, 0)
	LDGP(pv)
	ldiq	v0, -1
	RET
	END(fswberr)

/**************************************************************************/

#ifdef notdef
/*
 * fuswintr and suswintr are just like fusword and susword except that if
 * the page is not in memory or would cause a trap, then we return an error.
 * The important thing is to prevent sleep() and switch().
 */

LEAF(fuswintr, 2)
	LDGP(pv)
	ldiq	t0, VM_MAX_ADDRESS		/* make sure that addr */
	cmpult	a0, t0, t1			/* is in user space. */
	beq	t1, fswintrberr			/* if it's not, error out. */
	/* Note: GET_CURPROC clobbers v0, t0, t8...t11. */
	GET_CURPROC
	mov	v0, t1
	lda	t0, fswintrberr
	.set noat
	ldq	at_reg, 0(t1)
	ldq	at_reg, P_ADDR(at_reg)
	stq	t0, U_PCB_ONFAULT(at_reg)
	stq	a0, U_PCB_ACCESSADDR(at_reg)
	.set at
	/* XXX FETCH IT */
	.set noat
	ldq	at_reg, 0(t1)
	ldq	at_reg, P_ADDR(at_reg)
	stq	zero, U_PCB_ONFAULT(at_reg)
	.set at
	RET
	END(fuswintr)

LEAF(suswintr, 2)
	LDGP(pv)
	ldiq	t0, VM_MAX_ADDRESS		/* make sure that addr */
	cmpult	a0, t0, t1			/* is in user space. */
	beq	t1, fswintrberr			/* if it's not, error out. */
	/* Note: GET_CURPROC clobbers v0, t0, t8...t11. */
	GET_CURPROC
	mov	v0, t1
	lda	t0, fswintrberr
	.set noat
	ldq	at_reg, 0(t1)
	ldq	at_reg, P_ADDR(at_reg)
	stq	t0, U_PCB_ONFAULT(at_reg)
	stq	a0, U_PCB_ACCESSADDR(at_reg)
	.set at
	/* XXX STORE IT */
	.set noat
	ldq	at_reg, 0(t1)
	ldq	at_reg, P_ADDR(at_reg)
	stq	zero, U_PCB_ONFAULT(at_reg)
	.set at
	mov	zero, v0
	RET
	END(suswintr)
#endif

LEAF(fswintrberr, 0)
XLEAF(fuswintr, 2)				/* XXX what is a 'word'? */
XLEAF(suswintr, 2)				/* XXX what is a 'word'? */
	LDGP(pv)
	ldiq	v0, -1
	RET
	END(fswberr)
@


1.18
log
@IEEE 754 floating point completion code, and implementation of the
FP_C (Floating Point Control Quadword).

From ross@@NetBSD.  Added a way to disable it with option NO_IEEE,
which appears on the ramdisks to save space.  This affects only
programs compiled with -mieee, and what it essentially does is
enabling infinities and NaNs, instead of generating SIGFPE on
division by zero, overflow, etc.
ok art, deraadt
@
text
@d1 1
a1 1
/* $OpenBSD: locore.s,v 1.17 2001/09/30 13:08:45 art Exp $ */
d1783 1
d1788 1
d1791 1
d1796 1
@


1.17
log
@Generic soft interrupts from NetBSD plus some minor cleanups.
@
text
@d1 2
a2 2
/* $OpenBSD: locore.s,v 1.16 2001/06/11 08:51:20 art Exp $ */
/* $NetBSD: locore.s,v 1.80 2000/09/04 00:31:59 thorpej Exp $ */
d1908 57
@


1.17.4.1
log
@Sync UBC branch to -current
@
text
@d1 2
a2 2
/* $OpenBSD$ */
/* $NetBSD: locore.s,v 1.94 2001/04/26 03:10:44 ross Exp $ */
a1782 1
	.type intrnames,@@object
a1786 1
	.type eintrnames,@@object
a1788 1
	.type intrcnt,@@object
a1792 1
	.type eintrcnt,@@object
a1907 57

/*
 * void sts(int rn, u_int32_t *rval);
 * void stt(int rn, u_int64_t *rval);
 * void lds(int rn, u_int32_t *rval);
 * void ldt(int rn, u_int64_t *rval);
 */

#ifndef NO_IEEE
.macro make_freg_util name, op
	LEAF(alpha_\name, 2)
	and	a0, 0x1f, a0
	s8addq	a0, pv, pv
	addq	pv, 1f - alpha_\name, pv
	jmp	(pv)
1:
	rn = 0
	.rept   32
	\op     $f0 + rn, 0(a1)
	RET
	rn = rn + 1
	.endr
	END(alpha_\name)
.endm
/*
LEAF(alpha_sts, 2)
LEAF(alpha_stt, 2)
LEAF(alpha_lds, 2)
LEAF(alpha_ldt, 2)
 */
	make_freg_util sts, sts
	make_freg_util stt, stt
	make_freg_util lds, lds
	make_freg_util ldt, ldt

LEAF(alpha_read_fpcr, 0); f30save = 0; rettmp = 8; framesz = 16
	lda	sp, -framesz(sp)
	stt	$f30, f30save(sp)
	mf_fpcr	$f30
	stt	$f30, rettmp(sp)
	ldt	$f30, f30save(sp)
	ldq	v0, rettmp(sp)
	lda	sp, framesz(sp)
	RET
END(alpha_read_fpcr)

LEAF(alpha_write_fpcr, 1); f30save = 0; fpcrtmp = 8; framesz = 16
	lda	sp, -framesz(sp)
	stq	a0, fpcrtmp(sp)
	stt	$f30, f30save(sp)
	ldt	$f30, fpcrtmp(sp)
	mt_fpcr	$f30
	ldt	$f30, f30save(sp)
	lda	sp, framesz(sp)
	RET
END(alpha_write_fpcr)
#endif
@


1.17.4.2
log
@sync
@
text
@d1463 313
@


1.16
log
@Remove workaround for a gas bug fixed in binutils-2.10.1.
gas confused $f28 with $at.
@
text
@d1 1
a1 1
/* $OpenBSD: locore.s,v 1.15 2001/02/08 13:38:14 art Exp $ */
d387 1
a387 1
	CALL(do_sir)
@


1.15
log
@Actually give esym some storage. As it was, esym pointed
into the memory of some other variable.
How did this ever work?
(well, the floppies didn't work, but they should now).
@
text
@d1 1
a1 1
/* $OpenBSD: locore.s,v 1.14 2000/11/08 19:16:59 ericj Exp $ */
a626 1
	.set noat
a627 1
	.set at
@


1.14
log
@add tags
@
text
@d1 1
a1 1
/* $OpenBSD$ */
d1923 1
a1923 1
	.quad			/* store end of kernel symbol table here */
@


1.13
log
@Merge in big portions of the improvements NetBSD did to their alpha port.
Highlights: UVM, PMAP_NEW, bus_dma (only on some buses for now), new hardware
support, possiblity for ELF, etc, etc. Too much to mention.

This is still work in progress. video consoles might be broken, otherwise
we have basically the same functionality as before plus more.
@
text
@d1 1
@


1.12
log
@Changes to exit handling.

cpu_exit no longer frees the vmspace and u-area. This is now handled by a
separate kernel thread "reaper". This is to avoid sleeping locks in the
critical path of cpu_exit where we're not allowed to sleep.

From NetBSD
@
text
@d1 38
a38 2
/*	$OpenBSD: locore.s,v 1.11 1999/11/13 21:33:44 deraadt Exp $	*/
/*	$NetBSD: locore.s,v 1.27 1996/12/03 19:54:16 cgd Exp $	*/
d67 2
d70 46
a115 2
#ifndef EVCNT_COUNTERS
#include <machine/intrcnt.h>
d117 13
a129 1
#include "assym.h"
d135 8
d148 1
d164 2
a165 1
 *	a2 is the end of the symbol table
d185 1
a185 1
	 * which are already in a0, a1 and a2.
d194 1
a194 1
	 * Switch to proc0's PCB, which is at U_PCB off of proc0paddr.
d196 3
a198 5
	lda	t0,proc0			/* get phys addr of pcb */
	ldq	a0,P_MD_PCBPADDR(t0)
	call_pal PAL_OSF1_swpctx
	ldiq	a0, -2
	call_pal PAL_OSF1_tbi
d201 2
a202 3
	 * Construct a fake trap frame, so execve() can work normally.
	 * Note that setregs() is responsible for setting its contents
	 * to 'reasonable' values.
d204 3
a206 3
	lda	sp,-(FRAME_SIZE * 8)(sp)	/* space for struct trapframe */
	mov	sp, a0				/* main()'s arg is frame ptr */
	CALL(main)				/* go to main()! */
d209 1
a209 2
	 * Call exception_return, to simulate return from (fake)
	 * exception to user-land, running process 1, init!
d211 4
a214 1
	jmp	zero, exception_return		/* "And that's all she wrote." */
d235 24
a258 6
	.data
EXPORT(cold)
	.long 1			/* cold start flag (.long -> _4_ bytes) */
	.align 3
EXPORT(esym)
	.quad			/* store end of kernel symbol table here */
d260 3
a262 1

a319 1
IMPORT(astpending, 8)
d322 16
a337 2
	br	pv, Ler1
Ler1:	LDGP(pv)
d341 1
a341 1
	bne	t0, Lrestoreregs		/* != 0: can't do AST or SIR */
d344 14
a357 2
	ldq	t1, ssir			/* SIR pending? */
	beq	t1, Lchkast			/* no, try an AST*/
d359 8
a366 22
	/* We've got a SIR. */
	CALL(do_sir)				/* do the SIR; lowers IPL */

Lchkast:
	ldiq	a0, ALPHA_PSL_IPL_0		/* drop IPL to zero*/
	call_pal PAL_OSF1_swpipl

	and	s1, ALPHA_PSL_USERMODE, t0	/* are we returning to user? */
	beq	t0, Lrestoreregs		/* no: just return */

	ldq	t2, astpending			/* AST pending? */
	beq	t2, Lsetfpenable		/* no: return & deal with FP */

	/* We've got an AST.  Handle it. */
	mov	sp, a0				/* only arg is frame */
	CALL(ast)

Lsetfpenable:
	/* enable FPU based on whether the current proc is fpcurproc */
	ldq	t0, curproc
	ldq	t1, fpcurproc
	cmpeq	t0, t1, t0
d368 1
a368 1
	cmovne	t0, 1, a0
a370 1
Lrestoreregs:
d372 1
a372 1
	bsr	ra, exception_restore_regs	/* jmp/CALL trashes pv/t12 */
d380 26
d471 1
a471 7
LEAF(XentArith, 2)				/* XXX should be NESTED */
	.set noat
	lda	sp,-(FRAME_SW_SIZE*8)(sp)
	stq	at_reg,(FRAME_AT*8)(sp)
	.set at
	stq	ra,(FRAME_RA*8)(sp)
	bsr	ra, exception_save_regs		/* jmp/CALL trashes pv/t12 */
d475 1
a475 1
	mov	sp, a4
d488 1
a488 7
LEAF(XentIF, 1)					/* XXX should be NESTED */
	.set noat
	lda	sp,-(FRAME_SW_SIZE*8)(sp)
	stq	at_reg,(FRAME_AT*8)(sp)
	.set at
	stq	ra,(FRAME_RA*8)(sp)
	bsr	ra, exception_save_regs		/* jmp/CALL trashes pv/t12 */
d492 1
a492 1
	mov	sp, a4
d494 1
a494 2

	jmp	zero, exception_return
d504 1
a504 7
LEAF(XentInt, 2)				/* XXX should be NESTED */
	.set noat
	lda	sp,-(FRAME_SW_SIZE*8)(sp)
	stq	at_reg,(FRAME_AT*8)(sp)
	.set at
	stq	ra,(FRAME_RA*8)(sp)
	bsr	ra, exception_save_regs		/* jmp/CALL trashes pv/t12 */
d507 1
a507 1
	mov	sp, a3
a508 1

d519 1
a519 7
LEAF(XentMM, 3)					/* XXX should be NESTED */
	.set noat
	lda	sp,-(FRAME_SW_SIZE*8)(sp)
	stq	at_reg,(FRAME_AT*8)(sp)
	.set at
	stq	ra,(FRAME_RA*8)(sp)
	bsr	ra, exception_save_regs		/* jmp/CALL trashes pv/t12 */
d523 1
a523 1
	mov	sp, a4
d536 2
a537 2
LEAF(XentSys, 0)				/* XXX should be NESTED */
	lda	sp,-(FRAME_SW_SIZE*8)(sp)
d556 1
a556 1
	mov	sp,a1
d579 1
a579 1
	mov	sp, a4
d690 1
d692 1
d707 1
a707 1
 * from if called from boot().)
d710 1
a710 1
 *	a0	'struct pcb *' of the process that needs its context saved
d719 11
a729 11
	br	pv, Lsavectx1
Lsavectx1: LDGP(pv)
	stq	sp, PCB_HWPCB_KSP(a0)		/* store sp */
	stq	s0, PCB_CONTEXT+(0 * 8)(a0)	/* store s0 - s6 */
	stq	s1, PCB_CONTEXT+(1 * 8)(a0)
	stq	s2, PCB_CONTEXT+(2 * 8)(a0)
	stq	s3, PCB_CONTEXT+(3 * 8)(a0)
	stq	s4, PCB_CONTEXT+(4 * 8)(a0)
	stq	s5, PCB_CONTEXT+(5 * 8)(a0)
	stq	s6, PCB_CONTEXT+(6 * 8)(a0)
	stq	ra, PCB_CONTEXT+(7 * 8)(a0)	/* store ra */
d731 1
a731 1
	stq	v0, PCB_CONTEXT+(8 * 8)(a0)	/* store ps, for ipl */
a738 2
BSS(curpcb, 8)

a739 2
IMPORT(want_resched, 8)
IMPORT(Lev1map, 8)
d748 8
a755 3
	br	pv, Lidle1
Lidle1:	LDGP(pv)
	stq	zero, curproc			/* curproc <- NULL for stats */
d758 2
a759 3
Lidle2:
	ldl	t0, whichqs			/* look for non-empty queue */
	beq	t0, Lidle2
d762 4
a765 1
	jmp	zero, sw1				/* jump back into the fray */
a770 1
 * XXX should optimiize, and not do the switch if switching to curproc
d774 6
a779 2
	/* do an inline savectx(), to save old context */
	ldq	a0, curproc
d782 8
a789 8
	stq	s0, U_PCB+PCB_CONTEXT+(0 * 8)(a1)	/* store s0 - s6 */
	stq	s1, U_PCB+PCB_CONTEXT+(1 * 8)(a1)
	stq	s2, U_PCB+PCB_CONTEXT+(2 * 8)(a1)
	stq	s3, U_PCB+PCB_CONTEXT+(3 * 8)(a1)
	stq	s4, U_PCB+PCB_CONTEXT+(4 * 8)(a1)
	stq	s5, U_PCB+PCB_CONTEXT+(5 * 8)(a1)
	stq	s6, U_PCB+PCB_CONTEXT+(6 * 8)(a1)
	stq	ra, U_PCB+PCB_CONTEXT+(7 * 8)(a1)	/* store ra */
d791 1
a791 1
	stq	v0, U_PCB+PCB_CONTEXT+(8 * 8)(a1)	/* store ps, for ipl */
d795 5
a799 10

	ldl	t0, whichqs			/* look for non-empty queue */
	beq	t0, idle			/* and if none, go idle */

	ldiq	a0, ALPHA_PSL_IPL_HIGH		/* disable all interrupts */
	call_pal PAL_OSF1_swpipl
sw1:
	br	pv, Lcs1
Lcs1:	LDGP(pv)
	ldl	t0, whichqs			/* look for non-empty queue */
d803 1
a803 1
	blbs	t0, Lcs3			/* if low bit set, done! */
d805 1
a805 1
Lcs2:	srl	t0, 1, t0			/* try next bit */
d807 1
a807 1
	blbc	t0, Lcs2			/* if clear, try again */
d809 1
a809 2
Lcs3:
	/*
d817 1
a817 2
	ldq	t5, P_FORW(t4)			/* t5 = p->p_forw */
	bne	t4, Lcs4			/* make sure p != NULL */
d820 2
a821 1
Lcs4:
d826 1
a826 1
	beq	t0, Lcs5			/* nope, it's not! */
d833 4
a836 1
Lcs5:
d838 2
a839 1
	 * Switch to the new context
d841 2
d844 12
a855 6
	/* mark the new curproc, and other globals */
	stq	zero, want_resched		/* we've rescheduled */
	/* XXX should allocate an ASN, rather than just flushing */
	stq	t4, curproc			/* curproc = p */
	ldq	t5, P_MD_PCBPADDR(t4)		/* t5 = p->p_md.md_pcbpaddr */
	stq	t5, curpcb			/* and store it in curpcb */
a856 1
#ifndef NEW_PMAP
d858 12
a869 2
	 * Do the context swap, and invalidate old TLB entries (XXX).
	 * XXX should do the ASN thing, and therefore not have to invalidate.
d871 4
a874 8
	ldq	t2, P_VMSPACE(t4)		/* t2 = p->p_vmspace */
	ldq	t2, VM_PMAP_STPTE(t2)		/* = p_vmspace.vm_pmap.pm_ste */
	ldq	t3, Lev1map			/* and store pte into Lev1map */
	stq	t2, USTP_OFFSET(t3)
	mov	t5, a0				/* swap the context */
	call_pal PAL_OSF1_swpctx
	ldiq	a0, -1				/* & invalidate old TLB ents */
	call_pal PAL_OSF1_tbi
d876 3
a878 3
	/*
	 * Now running on the new u struct.
	 * Restore registers and return.
d880 2
a881 11
	ldq	t0, curproc
	ldq	t0, P_ADDR(t0)
#else /* NEW_PMAP */
	mov	t4, s2				/* save new curproc */
	mov	t5, s3				/* save new pcbpaddr */
	ldq	s4, P_ADDR(t4)			/* load/save new U-AREA */

	ldq	a0, P_VMSPACE(s2)		/* p->p_vmspace */
	lda	a1, U_PCB+PCB_HWPCB(s4)		/* &hardware PCB */
	mov	zero, a2
	lda	a0, VM_PMAP(a0)			/* &p->p_vmspace->vm_pmap */
d885 24
a908 3
	call_pal PAL_OSF1_swpctx
	ldiq	a0, -2				/* & invalidate old TLB ents */
	call_pal PAL_OSF1_tbi
d910 7
a916 5
	ldq	a0, P_VMSPACE(s0)
	lda	a1, U_PCB+PCB_HWPCB(s1)
	mov	zero, a2
	lda	a0, VM_PMAP(a0)
	CALL(pmap_deactivate)
d922 2
a923 2
	mov	s4, t0
#endif /* NEW_PMAP */
d925 9
a933 9
	ldq	s0, U_PCB+PCB_CONTEXT+(0 * 8)(t0)	/* restore s0 - s6 */
	ldq	s1, U_PCB+PCB_CONTEXT+(1 * 8)(t0)
	ldq	s2, U_PCB+PCB_CONTEXT+(2 * 8)(t0)
	ldq	s3, U_PCB+PCB_CONTEXT+(3 * 8)(t0)
	ldq	s4, U_PCB+PCB_CONTEXT+(4 * 8)(t0)
	ldq	s5, U_PCB+PCB_CONTEXT+(5 * 8)(t0)
	ldq	s6, U_PCB+PCB_CONTEXT+(6 * 8)(t0)
	ldq	ra, U_PCB+PCB_CONTEXT+(7 * 8)(t0)	/* restore ra */
	ldq	a0, U_PCB+PCB_CONTEXT+(8 * 8)(t0)	/* restore ipl */
a940 1

d944 1
a944 1
 * Arrange for a function to be invoked neatly, after a cpu_switch().
d947 2
a948 2
 * address specified by the s1 register and with one argument, a
 * pointer to the executing process's proc structure.
d951 3
d956 1
a956 1
	ldq	a0, curproc
d962 4
a965 3
 * Make a the named process exit.  Partially switch to proc0, unmap
 * the old proc's user struct, and jump into the middle of cpu_switch
 * to switch into a few process.  MUST BE CALLED AT SPLHIGH.
d973 3
a975 26
	/* Switch to proc0. */
	lda	t4, proc0			/* t4 = &proc0 */
	ldq	t5, P_MD_PCBPADDR(t4)		/* t5 = p->p_md.md_pcbpaddr */
	stq	t5, curpcb			/* and store it in curpcb */

#ifndef NEW_PMAP
	mov	t4, s0
	ldq	s1, P_ADDR(t4)
#endif

	/*
	 * Do the context swap, and invalidate old TLB entries (XXX).
	 * XXX should do the ASN thing, and therefore not have to invalidate.
	 */
#ifndef NEW_PMAP
	ldq	t2, P_VMSPACE(t4)		/* t2 = p->p_vmspace */
	ldq	t2, VM_PMAP_STPTE(t2)		/* = p_vmspace.vm_pmap.pm_ste */
	ldq	t3, Lev1map			/* and store pte into Lev1map */
	stq	t2, USTP_OFFSET(t3)
#endif /* NEW_PMAP */
	mov	t5, a0				/* swap the context */
	call_pal PAL_OSF1_swpctx
#ifndef NEW_PMAP
	ldiq	a0, -1				/* & invalidate old TLB ents */
	call_pal PAL_OSF1_tbi
#endif /* NEW_PMAP */
d978 1
a978 1
	 * Now running as proc0, except for the value of 'curproc' and
d983 1
a983 1
	mov     s2, a0
d986 2
a987 3
	/* and jump into the middle of cpu_switch. */
#ifdef NEW_PMAP
	/* XXX XXX LOSE */
d989 9
a997 1
	jmp	zero, sw1
d1012 1
a1012 1
	bne	a2, Lcopystr1		/* if (len != 0), proceed */
d1014 1
a1014 1
	br	zero, Lcopystr2
d1016 1
a1016 2
Lcopystr1:
	ldq_u	t1, 0(a0)		/* t1 = *from */
d1025 1
a1025 1
	beq	t1, Lcopystr2		/* if (*from == 0), bail out */
d1028 1
a1028 1
	bne	a2, Lcopystr1		/* if (len != 0) copy more */
d1030 1
a1030 2
Lcopystr2:
	beq	a3, Lcopystr3		/* if (lenp != NULL) */
d1033 1
a1033 2
Lcopystr3:
	beq	t1, Lcopystr4		/* *from == '\0'; leave quietly */
d1038 1
a1038 2
Lcopystr4:
	mov	zero, v0		/* return 0. */
d1042 1
a1042 1
NESTED(copyinstr, 4, 16, ra, 0, 0)
d1046 1
d1050 3
d1055 1
a1055 1
	ldq	at_reg, curproc
d1057 1
a1057 1
	stq	v0, U_PCB+PCB_ONFAULT(at_reg)
d1061 1
a1061 1
	ldq	at_reg, curproc			/* kill the fault handler.   */
d1063 1
a1063 1
	stq	zero, U_PCB+PCB_ONFAULT(at_reg)
d1066 1
d1071 1
a1071 1
NESTED(copyoutstr, 4, 16, ra, 0, 0)
d1075 1
d1079 3
d1084 1
a1084 1
	ldq	at_reg, curproc
d1086 1
a1086 1
	stq	v0, U_PCB+PCB_ONFAULT(at_reg)
d1090 1
a1090 1
	ldq	at_reg, curproc			/* kill the fault handler.   */
d1092 1
a1092 1
	stq	zero, U_PCB+PCB_ONFAULT(at_reg)
d1095 1
d1103 2
a1104 3
 * In the kernel, bcopy() doesn't have to handle the overlapping
 * case; that's that ovbcopy() is for.  However, it doesn't hurt
 * to do both in bcopy, and it does provide a measure of safety.
a1105 1
 * void memcpy(char *to, char*from, size_t len);
a1106 1
 * void ovbcopy(char *from, char *to, size_t len);
d1109 3
a1111 3
	cmoveq	zero,a0,t5
	cmoveq	zero,a1,a0
	cmoveq	zero,t5,a1
d1337 56
a1392 1
NESTED(copyin, 3, 16, ra, 0, 0)
d1396 1
d1400 3
d1405 1
a1405 1
	ldq	at_reg, curproc
d1407 1
a1407 1
	stq	v0, U_PCB+PCB_ONFAULT(at_reg)
d1411 1
a1411 1
	ldq	at_reg, curproc			/* kill the fault handler.   */
d1413 1
a1413 1
	stq	zero, U_PCB+PCB_ONFAULT(at_reg)
d1416 1
d1422 1
a1422 1
NESTED(copyout, 3, 16, ra, 0, 0)
d1426 1
d1430 3
d1435 1
a1435 1
	ldq	at_reg, curproc
d1437 1
a1437 1
	stq	v0, U_PCB+PCB_ONFAULT(at_reg)
d1441 1
a1441 1
	ldq	at_reg, curproc			/* kill the fault handler.   */
d1443 1
a1443 1
	stq	zero, U_PCB+PCB_ONFAULT(at_reg)
d1446 1
d1455 1
a1468 1
#ifdef notdef
d1475 3
d1480 1
a1480 1
	ldq	at_reg, curproc
d1482 1
a1482 1
	stq	t0, U_PCB+PCB_ONFAULT(at_reg)
d1487 1
a1487 1
	ldq	at_reg, curproc
d1489 1
a1489 1
	stq	zero, U_PCB+PCB_ONFAULT(at_reg)
d1500 3
d1505 1
a1505 1
	ldq	at_reg, curproc
d1507 1
a1507 1
	stq	t0, U_PCB+PCB_ONFAULT(at_reg)
d1511 1
a1511 1
	ldq	at_reg, curproc
d1513 1
a1513 1
	stq	zero, U_PCB+PCB_ONFAULT(at_reg)
d1524 3
d1529 1
a1529 1
	ldq	at_reg, curproc
d1531 1
a1531 1
	stq	t0, U_PCB+PCB_ONFAULT(at_reg)
d1535 1
a1535 1
	ldq	at_reg, curproc
d1537 1
a1537 1
	stq	zero, U_PCB+PCB_ONFAULT(at_reg)
a1540 1
#endif /* notdef */
d1547 3
d1552 1
a1552 1
	ldq	at_reg, curproc
d1554 1
a1554 1
	stq	t0, U_PCB+PCB_ONFAULT(at_reg)
d1556 1
a1556 1
	stq	a1, 0(a0)			/* do the wtore. */
d1558 1
a1558 1
	ldq	at_reg, curproc
d1560 1
a1560 1
	stq	zero, U_PCB+PCB_ONFAULT(at_reg)
d1572 3
d1577 1
a1577 1
	ldq	at_reg, curproc
d1579 1
a1579 1
	stq	t0, U_PCB+PCB_ONFAULT(at_reg)
d1583 1
a1583 1
	ldq	at_reg, curproc
d1585 1
a1585 1
	stq	zero, U_PCB+PCB_ONFAULT(at_reg)
d1597 3
d1602 1
a1602 1
	ldq	at_reg, curproc
d1604 1
a1604 1
	stq	t0, U_PCB+PCB_ONFAULT(at_reg)
d1608 1
a1608 1
	ldq	at_reg, curproc
d1610 1
a1610 1
	stq	zero, U_PCB+PCB_ONFAULT(at_reg)
d1621 3
d1626 1
a1626 1
	ldq	at_reg, curproc
d1628 1
a1628 1
	stq	t0, U_PCB+PCB_ONFAULT(at_reg)
d1632 1
a1632 1
	ldq	at_reg, curproc
d1634 1
a1634 1
	stq	zero, U_PCB+PCB_ONFAULT(at_reg)
d1647 3
d1652 1
a1652 1
	ldq	at_reg, curproc
d1654 1
a1654 1
	stq	t0, U_PCB+PCB_ONFAULT(at_reg)
d1663 1
a1663 1
	ldq	at_reg, curproc
d1665 1
a1665 1
	stq	zero, U_PCB+PCB_ONFAULT(at_reg)
d1676 3
d1681 1
a1681 1
	ldq	at_reg, curproc
d1683 1
a1683 1
	stq	t0, U_PCB+PCB_ONFAULT(at_reg)
d1692 1
a1692 1
	ldq	at_reg, curproc
d1694 1
a1694 1
	stq	zero, U_PCB+PCB_ONFAULT(at_reg)
d1721 3
d1726 1
a1726 1
	ldq	at_reg, curproc
d1728 2
a1729 2
	stq	t0, U_PCB+PCB_ONFAULT(at_reg)
	stq	a0, U_PCB+PCB_ACCESSADDR(at_reg)
d1733 1
a1733 1
	ldq	at_reg, curproc
d1735 1
a1735 1
	stq	zero, U_PCB+PCB_ONFAULT(at_reg)
d1745 3
d1750 1
a1750 1
	ldq	at_reg, curproc
d1752 2
a1753 2
	stq	t0, U_PCB+PCB_ONFAULT(at_reg)
	stq	a0, U_PCB+PCB_ACCESSADDR(at_reg)
d1757 1
a1757 1
	ldq	at_reg, curproc
d1759 1
a1759 1
	stq	zero, U_PCB+PCB_ONFAULT(at_reg)
d1780 2
a1798 20
 *	Object:
 *		swpctxt			EXPORTED function
 *
 *	Change HW process context
 *
 *	Arguments:
 *		pcb			PHYSICAL struct pcb_hw *
 *		old_ksp			VIRTUAL long *
 *
 *	If old_ksp is non-zero it saves the current KSP in it.
 *	Execute the PAL call.
 */
LEAF(swpctxt,2)
	beq	a1,Lswpctxt1
	stq	sp,0(a1)
Lswpctxt1: call_pal PAL_OSF1_swpctx
	RET
	END(swpctxt)

/*
d1807 3
d1835 2
a1836 2
	br	pv,LXconsole_restart1
LXconsole_restart1: LDGP(pv)
d1838 1
a1838 3
	ldq	a0,(FRAME_RA*8)(sp)		/* a0 = ra */
	ldq	a1,(FRAME_T11*8)(sp)		/* a1 = ai */
	ldq	a2,(FRAME_T12*8)(sp)		/* a2 = pv */
d1844 13
d1859 3
a1861 2
	stq	ra, (0 * 8)(a0)
	stq	s0, (1 * 8)(a0)
d1869 4
a1872 1
	/* We don't need to store the FP context in the kernel */
d1877 1
a1877 1
LEAF(longjmp, 2)
d1879 8
a1886 3
	mov	a1, v0
	ldq	ra, (0 * 8)(a0)
	ldq	s0, (1 * 8)(a0)
d1894 2
d1897 11
d1909 17
@


1.11
log
@overflow fixes; chuq
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.10 1999/09/26 11:07:32 kstailey Exp $	*/
d836 3
a838 5
	/* blow away the old user struct */
	ldq	a0, kernel_map
	ldq	a1, P_ADDR(s2)
	ldiq	a2, (UPAGES * NBPG)
	CALL(kmem_free)
@


1.11.2.1
log
@Update the SMP branch to -current, this breaks the SMP branch though.
But it will be fixed soonish.  Note, nothing new has happened, this is just
a merge of the trunk into this branch.
@
text
@d1 2
a2 39
/* $OpenBSD: locore.s,v 1.15 2001/02/08 13:38:14 art Exp $ */
/* $NetBSD: locore.s,v 1.80 2000/09/04 00:31:59 thorpej Exp $ */

/*-
 * Copyright (c) 1999, 2000 The NetBSD Foundation, Inc.
 * All rights reserved.
 *
 * This code is derived from software contributed to The NetBSD Foundation
 * by Jason R. Thorpe of the Numerical Aerospace Simulation Facility,
 * NASA Ames Research Center.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *	This product includes software developed by the NetBSD
 *	Foundation, Inc. and its contributors.
 * 4. Neither the name of The NetBSD Foundation nor the names of its
 *    contributors may be used to endorse or promote products derived
 *    from this software without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE NETBSD FOUNDATION, INC. AND CONTRIBUTORS
 * ``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED
 * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE FOUNDATION OR CONTRIBUTORS
 * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
 * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
 * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
 * POSSIBILITY OF SUCH DAMAGE.
 */
a30 2
.stabs	__FILE__,100,0,0,kernel_text

d32 3
a34 1

a36 58
.stabs	__FILE__,132,0,0,kernel_text

#if defined(MULTIPROCESSOR)

/*
 * Get various per-cpu values.  A pointer to our cpu_info structure
 * is stored in SysValue.  These macros clobber v0, t0, t8..t11.
 *
 * All return values are in v0.
 */
#define	GET_CPUINFO		call_pal PAL_OSF1_rdval

#define	GET_CURPROC							\
	call_pal PAL_OSF1_rdval					;	\
	addq	v0, CPU_INFO_CURPROC, v0

#define	GET_FPCURPROC							\
	call_pal PAL_OSF1_rdval					;	\
	addq	v0, CPU_INFO_FPCURPROC, v0

#define	GET_CURPCB							\
	call_pal PAL_OSF1_rdval					;	\
	addq	v0, CPU_INFO_CURPCB, v0

#define	GET_IDLE_PCB(reg)						\
	call_pal PAL_OSF1_rdval					;	\
	ldq	reg, CPU_INFO_IDLE_PCB_PADDR(v0)

#else	/* if not MULTIPROCESSOR... */

IMPORT(cpu_info_store, CPU_INFO_SIZEOF)

#define	GET_CPUINFO		lda v0, cpu_info_store

#define	GET_CURPROC		lda v0, cpu_info_store + CPU_INFO_CURPROC

#define	GET_FPCURPROC		lda v0, cpu_info_store + CPU_INFO_FPCURPROC

#define	GET_CURPCB		lda v0, cpu_info_store + CPU_INFO_CURPCB

#define	GET_IDLE_PCB(reg)						\
	lda	reg, cpu_info_store				;	\
	ldq	reg, CPU_INFO_IDLE_PCB_PADDR(reg)
#endif

/*
 * Perform actions necessary to switch to a new context.  The
 * hwpcb should be in a0.  Clobbers v0, t0, t8..t11, a0.
 */
#define	SWITCH_CONTEXT							\
	/* Make a note of the context we're running on. */		\
	GET_CURPCB						;	\
	stq	a0, 0(v0)					;	\
									\
	/* Swap in the new context. */					\
	call_pal PAL_OSF1_swpctx


a40 8
	.macro	bfalse	reg, dst
	beq	\reg, \dst
	.endm

	.macro	btrue	reg, dst
	bne	\reg, \dst
	.endm

a45 1
.loc	1 __LINE__
d61 1
a61 2
 *	a2 is the bootinfo magic number
 *	a3 is the pointer to the bootinfo structure
d81 1
a81 1
	 * which are already in a0, a1, a2, a3 and a4.
d90 1
a90 1
	 * Switch to proc0's PCB.
d92 5
a96 3
	lda	a0, proc0
	ldq	a0, P_MD_PCBPADDR(a0)		/* phys addr of PCB */
	SWITCH_CONTEXT
d99 3
a101 2
	 * We've switched to a new page table base, so invalidate the TLB
	 * and I-stream.  This happens automatically everywhere but here.
d103 3
a105 3
	ldiq	a0, -2				/* TBIA */
	call_pal PAL_OSF1_tbi
	call_pal PAL_imb
d108 2
a109 1
	 * All ready to go!  Call main()!
d111 1
a111 4
	CALL(main)

	/* This should never happen. */
	PANIC("main() returned",Lmain_returned_pmsg)
d132 7
a138 21
/**************************************************************************/

#if defined(MULTIPROCESSOR)
/*
 * Pull in the multiprocssor glue.
 */
#include <alpha/alpha/multiproc.s>
#endif /* MULTIPROCESSOR */

/**************************************************************************/

/**************************************************************************/

#if defined(DDB)
/*
 * Pull in debugger glue.
 */
#include <alpha/alpha/debug.s>
#endif /* DDB */

/**************************************************************************/
a141 6
	.text
.stabs	__FILE__,132,0,0,backtolocore1	/* done with includes */
.loc	1 __LINE__
backtolocore1:
/**************************************************************************/

d197 1
d200 2
a201 16
	br	pv, 1f
1:	LDGP(pv)

#if defined(MULTIPROCESSOR)
	/* XXX XXX XXX */
	/*
	 * Check the current processor ID.  If we're not the primary
	 * CPU, then just restore registers and bail out.
	 */
	call_pal PAL_OSF1_whami
	lda	t0, hwrpb
	ldq	t0, 0(t0)
	ldq	t1, RPB_PRIMARY_CPU_ID(t0)
	cmpeq	t1, v0, t0
	beq	t0, 4f				/* == 0: bail out now */
#endif
d205 1
a205 1
	bne	t0, 4f				/* != 0: can't do AST or SIR */
d208 19
a226 14
2:	ldq	t1, ssir			/* SIR pending? */
	bne	t1, 5f				/* yes */
	/* no */

	/* check for AST */
3:	and	s1, ALPHA_PSL_USERMODE, t0	/* are we returning to user? */
	beq	t0, 4f				/* no: just return */
	/* yes */

	/* GET_CPUINFO clobbers v0, t0, t8...t11. */
	GET_CPUINFO
	ldq	t2, CPU_INFO_ASTPENDING(v0)	/* AST pending? */
	bne	t2, 6f				/* yes */
	/* no: return & deal with FP */
d228 5
a232 8
	/*
	 * We are going back to usermode.  Enable the FPU based on whether
	 * the current proc is fpcurproc.  v0 already contains the cpu_info
	 * pointer from above.
	 */
	ldq	t1, CPU_INFO_CURPROC(v0)
	ldq	t2, CPU_INFO_FPCURPROC(v0)
	cmpeq	t1, t2, t1
d234 1
a234 1
	cmovne	t1, 1, a0
d237 1
d239 1
a239 1
4:	bsr	ra, exception_restore_regs	/* jmp/CALL trashes pv/t12 */
a246 26
	/* NOTREACHED */

	/* We've got a SIR */
5:	ldiq	a0, ALPHA_PSL_IPL_SOFT
	call_pal PAL_OSF1_swpipl
	mov	v0, s2				/* remember old IPL */
	CALL(do_sir)

	/* SIR handled; restore IPL and check again */
	mov	s2, a0
	call_pal PAL_OSF1_swpipl
	br	2b

	/* We've got an AST */
6:	ldiq	a0, ALPHA_PSL_IPL_0		/* drop IPL to zero */
	call_pal PAL_OSF1_swpipl
	mov	v0, s2				/* remember old IPL */

	mov	sp, a0				/* only arg is frame */
	CALL(ast)

	/* AST handled; restore IPL and check again */
	mov	s2, a0
	call_pal PAL_OSF1_swpipl
	br	3b

d312 7
a318 1
	PALVECT(XentArith)		/* setup frame, save registers */
d322 1
a322 1
	mov	sp, a4			; .loc 1 __LINE__
d335 7
a341 1
	PALVECT(XentIF)			/* setup frame, save registers */
d345 1
a345 1
	mov	sp, a4			; .loc 1 __LINE__
d347 2
a348 1
	jmp	zero, exception_return	
d358 7
a364 1
	PALVECT(XentInt)		/* setup frame, save registers */
d367 1
a367 1
	mov	sp, a3			; .loc 1 __LINE__
d369 1
d380 7
a386 1
	PALVECT(XentMM)			/* setup frame, save registers */
d390 1
a390 1
	mov	sp, a4			; .loc 1 __LINE__
d403 2
a404 2
	ESETUP(XentSys)			; .loc 1 __LINE__

d423 1
a423 1
	mov	sp,a1			; .loc 1 __LINE__
d446 1
a446 1
	mov	sp, a4			; .loc 1 __LINE__
a556 1
	.set noat
a557 1
	.set at
d572 1
a572 1
 * if called from boot().)
d575 1
a575 1
 *	a0	'struct user *' of the process that needs its context saved
d584 11
a594 11
	br	pv, 1f
1:	LDGP(pv)
	stq	sp, U_PCB_HWPCB_KSP(a0)		/* store sp */
	stq	s0, U_PCB_CONTEXT+(0 * 8)(a0)	/* store s0 - s6 */
	stq	s1, U_PCB_CONTEXT+(1 * 8)(a0)
	stq	s2, U_PCB_CONTEXT+(2 * 8)(a0)
	stq	s3, U_PCB_CONTEXT+(3 * 8)(a0)
	stq	s4, U_PCB_CONTEXT+(4 * 8)(a0)
	stq	s5, U_PCB_CONTEXT+(5 * 8)(a0)
	stq	s6, U_PCB_CONTEXT+(6 * 8)(a0)
	stq	ra, U_PCB_CONTEXT+(7 * 8)(a0)	/* store ra */
d596 1
a596 1
	stq	v0, U_PCB_CONTEXT+(8 * 8)(a0)	/* store ps, for ipl */
d604 2
d607 2
d617 3
a619 8
	br	pv, 1f
1:	LDGP(pv)
	/* Note: GET_CURPROC clobbers v0, t0, t8...t11. */
	GET_CURPROC
	stq	zero, 0(v0)			/* curproc <- NULL for stats */
#if defined(MULTIPROCESSOR) || defined(LOCKDEBUG)
	CALL(sched_unlock_idle)			/* release sched_lock */
#endif
d622 3
a624 2
2:	ldl	t0, whichqs			/* look for non-empty queue */
	beq	t0, 2b
d627 1
a627 4
#if defined(MULTIPROCESSOR) || defined(LOCKDEBUG)
	CALL(sched_lock_idle)			/* acquire sched_lock */
#endif
	jmp	zero, cpu_switch_queuescan	/* jump back into the fire */
d633 1
d637 2
a638 6
	/*
	 * do an inline savectx(), to save old context
	 * Note: GET_CURPROC clobbers v0, t0, t8...t11.
	 */
	GET_CURPROC
	ldq	a0, 0(v0)
d641 8
a648 8
	stq	s0, U_PCB_CONTEXT+(0 * 8)(a1)	/* store s0 - s6 */
	stq	s1, U_PCB_CONTEXT+(1 * 8)(a1)
	stq	s2, U_PCB_CONTEXT+(2 * 8)(a1)
	stq	s3, U_PCB_CONTEXT+(3 * 8)(a1)
	stq	s4, U_PCB_CONTEXT+(4 * 8)(a1)
	stq	s5, U_PCB_CONTEXT+(5 * 8)(a1)
	stq	s6, U_PCB_CONTEXT+(6 * 8)(a1)
	stq	ra, U_PCB_CONTEXT+(7 * 8)(a1)	/* store ra */
d650 1
a650 1
	stq	v0, U_PCB_CONTEXT+(8 * 8)(a1)	/* store ps, for ipl */
d654 10
a663 5
 
cpu_switch_queuescan:
	br	pv, 1f
1:	LDGP(pv)
	ldl	t0, whichqs		/* look for non-empty queue */
d667 1
a667 1
	blbs	t0, 3f				/* if low bit set, done! */
d669 1
a669 1
2:	srl	t0, 1, t0			/* try next bit */
d671 1
a671 1
	blbc	t0, 2b				/* if clear, try again */
d673 2
a674 1
3:	/*
d682 2
a683 1
	bne	t4, 4f				/* make sure p != NULL */
d686 1
a686 2
4:
	ldq	t5, P_FORW(t4)			/* t5 = p->p_forw */
d691 1
a691 1
	beq	t0, 5f				/* nope, it's not! */
d698 1
a698 4
5:
	mov	t4, s2				/* save new proc */
	ldq	s3, P_MD_PCBPADDR(s2)		/* save new pcbpaddr */
#if defined(MULTIPROCESSOR) || defined(LOCKDEBUG)
d700 1
a700 2
	 * Done mucking with the run queues, release the
	 * scheduler lock, but keep interrupts out.
a701 2
	CALL(sched_unlock_idle)
#endif
d703 8
d712 2
a713 8
	 * Check to see if we're switching to ourself.  If we are,
	 * don't bother loading the new context.
	 *
	 * Note that even if we re-enter cpu_switch() from idle(),
	 * s0 will still contain the old curproc value because any
	 * users of that register between then and now must have
	 * saved it.  Also note that switch_exit() ensures that
	 * s0 is clear before jumping here to find a new process.
d715 8
a722 2
	cmpeq	s0, s2, t0			/* oldproc == newproc? */
	bne	t0, 7f				/* Yes!  Skip! */
d725 2
a726 21
	 * Deactivate the old address space before activating the
	 * new one.  We need to do this before activating the
	 * new process's address space in the event that new
	 * process is using the same vmspace as the old.  If we
	 * do this after we activate, then we might end up
	 * incorrectly marking the pmap inactive!
	 *
	 * We don't deactivate if we came here from switch_exit
	 * (old pmap no longer exists; vmspace has been freed).
	 * oldproc will be NULL in this case.  We have actually
	 * taken care of calling pmap_deactivate() in cpu_exit(),
	 * before the vmspace went away.
	 */
	beq	s0, 6f

	mov	s0, a0				/* pmap_deactivate(oldproc) */
	CALL(pmap_deactivate)

6:	/*
	 * Activate the new process's address space and perform
	 * the actual context swap.
d728 11
a738 2

	mov	s2, a0				/* pmap_activate(p) */
d742 3
a744 1
	SWITCH_CONTEXT
d746 5
a750 30
7:	/*
	 * Now that the switch is done, update curproc and other
	 * globals.  We must do this even if switching to ourselves
	 * because we might have re-entered cpu_switch() from idle(),
	 * in which case curproc would be NULL.
	 *
	 * Note: GET_CPUINFO clobbers v0, t0, t8...t11.
	 */
#if 0
#ifdef __alpha_bwx__
	ldiq	t0, SONPROC			/* p->p_stat = SONPROC */
	stb	t0, P_STAT(s2)
#else
	addq	s2, P_STAT, t3			/* p->p_stat = SONPROC */
	ldq_u	t1, 0(t3)
	ldiq	t0, SONPROC
	insbl	t0, t3, t0
	mskbl	t1, t3, t1
	or	t0, t1, t0
	stq_u	t0, 0(t3)
#endif /* __alpha_bwx__ */
#endif

	GET_CPUINFO
	/* p->p_cpu initialized in fork1() for single-processor */
#if defined(MULTIPROCESSOR)
	stq	v0, P_CPU(s2)			/* p->p_cpu = curcpu() */
#endif
	stq	s2, CPU_INFO_CURPROC(v0)	/* curproc = p */
	stq	zero, CPU_INFO_WANT_RESCHED(v0)	/* we've rescheduled */
d756 2
a757 2
	ldq	t0, P_ADDR(s2)

d759 9
a767 9
	ldq	s0, U_PCB_CONTEXT+(0 * 8)(t0)		/* restore s0 - s6 */
	ldq	s1, U_PCB_CONTEXT+(1 * 8)(t0)
	ldq	s2, U_PCB_CONTEXT+(2 * 8)(t0)
	ldq	s3, U_PCB_CONTEXT+(3 * 8)(t0)
	ldq	s4, U_PCB_CONTEXT+(4 * 8)(t0)
	ldq	s5, U_PCB_CONTEXT+(5 * 8)(t0)
	ldq	s6, U_PCB_CONTEXT+(6 * 8)(t0)
	ldq	ra, U_PCB_CONTEXT+(7 * 8)(t0)		/* restore ra */
	ldq	a0, U_PCB_CONTEXT+(8 * 8)(t0)		/* restore ipl */
d775 1
d779 1
a779 1
 * Arrange for a function to be invoked neatly, after a cpu_fork().
d782 2
a783 2
 * address specified by the s1 register and with one argument specified
 * by the s2 register.
a785 3
#if defined(MULTIPROCESSOR)
	CALL(proc_trampoline_mp)
#endif
d788 1
a788 1
	mov	s2, a0
d794 3
a796 4
 * Make a the named process exit.  Partially switch to our idle thread
 * (we don't update curproc or restore registers), and jump into the middle
 * of cpu_switch to switch into a few process.  The process reaper will
 * free the dead process's VM resources.  MUST BE CALLED AT SPLHIGH.
d804 26
a829 3
	/* Switch to our idle stack. */
	GET_IDLE_PCB(a0)			/* clobbers v0, t0, t8-t11 */
	SWITCH_CONTEXT
d832 1
a832 1
	 * Now running as idle thread, except for the value of 'curproc' and
d836 9
a844 6
	/* Schedule the vmspace and stack to be freed. */
	mov	s2, a0
	CALL(exit2)

#if defined(MULTIPROCESSOR) || defined(LOCKDEBUG)
	CALL(sched_lock_idle)			/* acquire sched_lock */
d846 1
a846 9

	/*
	 * Now jump back into the middle of cpu_switch().  Note that
	 * we must clear s0 to guarantee that the check for switching
	 * to ourselves in cpu_switch() will fail.  This is safe since
	 * s0 will be restored when a new process is resumed.
	 */
	mov	zero, s0
	jmp	zero, cpu_switch_queuescan
d861 1
a861 1
	bne	a2, 1f			/* if (len != 0), proceed */
d863 1
a863 1
	br	zero, 2f
d865 2
a866 1
1:	ldq_u	t1, 0(a0)		/* t1 = *from */
d875 1
a875 1
	beq	t1, 2f			/* if (*from == 0), bail out */
d878 1
a878 1
	bne	a2, 1b			/* if (len != 0) copy more */
d880 2
a881 1
2:	beq	a3, 3f			/* if (lenp != NULL) */
d884 2
a885 1
3:	beq	t1, 4f			/* *from == '\0'; leave quietly */
d890 2
a891 1
4:	mov	zero, v0		/* return 0. */
d895 1
a895 1
NESTED(copyinstr, 4, 16, ra, IM_RA|IM_S0, 0)
a898 1
	stq	s0, (16-16)(sp)			/* save s0		     */
a901 3
	/* Note: GET_CURPROC clobbers v0, t0, t8...t11. */
	GET_CURPROC
	mov	v0, s0
d904 1
a904 1
	ldq	at_reg, 0(s0)
d906 1
a906 1
	stq	v0, U_PCB_ONFAULT(at_reg)
d910 1
a910 1
	ldq	at_reg, 0(s0)			/* kill the fault handler.   */
d912 1
a912 1
	stq	zero, U_PCB_ONFAULT(at_reg)
a914 1
	ldq	s0, (16-16)(sp)			/* restore s0.		     */
d919 1
a919 1
NESTED(copyoutstr, 4, 16, ra, IM_RA|IM_S0, 0)
a922 1
	stq	s0, (16-16)(sp)			/* save s0		     */
a925 3
	/* Note: GET_CURPROC clobbers v0, t0, t8...t11. */
	GET_CURPROC
	mov	v0, s0
d928 1
a928 1
	ldq	at_reg, 0(s0)
d930 1
a930 1
	stq	v0, U_PCB_ONFAULT(at_reg)
d934 1
a934 1
	ldq	at_reg, 0(s0)			/* kill the fault handler.   */
d936 1
a936 1
	stq	zero, U_PCB_ONFAULT(at_reg)
a938 1
	ldq	s0, (16-16)(sp)			/* restore s0.		     */
d946 3
a948 2
 * Although bcopy() is not specified to handle overlapping regions,
 * this version does do so.
d950 1
d952 1
d955 3
a957 3
	cmoveq  zero,a0,t5
	cmoveq  zero,a1,a0
	cmoveq  zero,t5,a1
d1183 1
a1183 56
/*
 * kcopy(const void *src, void *dst, size_t len);
 *
 * Copy len bytes from src to dst, aborting if we encounter a fatal
 * page fault.
 *
 * kcopy() _must_ save and restore the old fault handler since it is
 * called by uiomove(), which may be in the path of servicing a non-fatal
 * page fault.
 */
NESTED(kcopy, 3, 32, ra, IM_RA|IM_S0|IM_S1, 0)
	LDGP(pv)
	lda	sp, -32(sp)			/* set up stack frame	     */
	stq	ra, (32-8)(sp)			/* save ra		     */
	stq	s0, (32-16)(sp)			/* save s0		     */
	stq	s1, (32-24)(sp)			/* save s1		     */
	/* Note: GET_CURPROC clobbers v0, t0, t8...t11. */
	GET_CURPROC
	mov	v0, s1
	lda	v0, kcopyerr			/* set up fault handler.     */
	.set noat
	ldq	at_reg, 0(s1)
	ldq	at_reg, P_ADDR(at_reg)
	ldq	s0, U_PCB_ONFAULT(at_reg)	/* save old handler.	     */
	stq	v0, U_PCB_ONFAULT(at_reg)
	.set at
	CALL(bcopy)				/* do the copy.		     */
	.set noat
	ldq	at_reg, 0(s1)			/* restore the old handler.  */
	ldq	at_reg, P_ADDR(at_reg)
	stq	s0, U_PCB_ONFAULT(at_reg)
	.set at
	ldq	ra, (32-8)(sp)			/* restore ra.		     */
	ldq	s0, (32-16)(sp)			/* restore s0.		     */
	ldq	s1, (32-24)(sp)			/* restore s1.		     */
	lda	sp, 32(sp)			/* kill stack frame.	     */
	mov	zero, v0			/* return 0. */
	RET
	END(kcopy)

LEAF(kcopyerr, 0)
	LDGP(pv)
	.set noat
	ldq	at_reg, 0(s1)			/* restore the old handler.  */
	ldq	at_reg, P_ADDR(at_reg)
	stq	s0, U_PCB_ONFAULT(at_reg)
	.set at
	ldq	ra, (32-8)(sp)			/* restore ra.		     */
	ldq	s0, (32-16)(sp)			/* restore s0.		     */
	ldq	s1, (32-24)(sp)			/* restore s1.		     */
	lda	sp, 32(sp)			/* kill stack frame.	     */
	ldiq	v0, EFAULT			/* return EFAULT.	     */
	RET
END(kcopyerr)

NESTED(copyin, 3, 16, ra, IM_RA|IM_S0, 0)
a1186 1
	stq	s0, (16-16)(sp)			/* save s0		     */
a1189 3
	/* Note: GET_CURPROC clobbers v0, t0, t8...t11. */
	GET_CURPROC
	mov	v0, s0
d1192 1
a1192 1
	ldq	at_reg, 0(s0)
d1194 1
a1194 1
	stq	v0, U_PCB_ONFAULT(at_reg)
d1198 1
a1198 1
	ldq	at_reg, 0(s0)			/* kill the fault handler.   */
d1200 1
a1200 1
	stq	zero, U_PCB_ONFAULT(at_reg)
a1202 1
	ldq	s0, (16-16)(sp)			/* restore s0.		     */
d1208 1
a1208 1
NESTED(copyout, 3, 16, ra, IM_RA|IM_S0, 0)
a1211 1
	stq	s0, (16-16)(sp)			/* save s0		     */
a1214 3
	/* Note: GET_CURPROC clobbers v0, t0, t8...t11. */
	GET_CURPROC
	mov	v0, s0
d1217 1
a1217 1
	ldq	at_reg, 0(s0)
d1219 1
a1219 1
	stq	v0, U_PCB_ONFAULT(at_reg)
d1223 1
a1223 1
	ldq	at_reg, 0(s0)			/* kill the fault handler.   */
d1225 1
a1225 1
	stq	zero, U_PCB_ONFAULT(at_reg)
a1227 1
	ldq	s0, (16-16)(sp)			/* restore s0.		     */
a1235 1
	ldq	s0, (16-16)(sp)			/* restore s0.		     */
d1249 1
a1255 3
	/* Note: GET_CURPROC clobbers v0, t0, t8...t11. */
	GET_CURPROC
	mov	v0, t1
d1258 1
a1258 1
	ldq	at_reg, 0(t1)
d1260 1
a1260 1
	stq	t0, U_PCB_ONFAULT(at_reg)
d1265 1
a1265 1
	ldq	at_reg, 0(t1)
d1267 1
a1267 1
	stq	zero, U_PCB_ONFAULT(at_reg)
a1277 3
	/* Note: GET_CURPROC clobbers v0, t0, t8...t11. */
	GET_CURPROC
	mov	v0, t1
d1280 1
a1280 1
	ldq	at_reg, 0(t1)
d1282 1
a1282 1
	stq	t0, U_PCB_ONFAULT(at_reg)
d1286 1
a1286 1
	ldq	at_reg, 0(t1)
d1288 1
a1288 1
	stq	zero, U_PCB_ONFAULT(at_reg)
a1298 3
	/* Note: GET_CURPROC clobbers v0, t0, t8...t11. */
	GET_CURPROC
	mov	v0, t1
d1301 1
a1301 1
	ldq	at_reg, 0(t1)
d1303 1
a1303 1
	stq	t0, U_PCB_ONFAULT(at_reg)
d1307 1
a1307 1
	ldq	at_reg, 0(t1)
d1309 1
a1309 1
	stq	zero, U_PCB_ONFAULT(at_reg)
d1313 1
a1319 3
	/* Note: GET_CURPROC clobbers v0, t0, t8...t11. */
	GET_CURPROC
	mov	v0, t1
d1322 1
a1322 1
	ldq	at_reg, 0(t1)
d1324 1
a1324 1
	stq	t0, U_PCB_ONFAULT(at_reg)
d1326 1
a1326 1
	stq	a1, 0(a0)			/* do the store. */
d1328 1
a1328 1
	ldq	at_reg, 0(t1)
d1330 1
a1330 1
	stq	zero, U_PCB_ONFAULT(at_reg)
a1341 3
	/* Note: GET_CURPROC clobbers v0, t0, t8...t11. */
	GET_CURPROC
	mov	v0, t1
d1344 1
a1344 1
	ldq	at_reg, 0(t1)
d1346 1
a1346 1
	stq	t0, U_PCB_ONFAULT(at_reg)
d1350 1
a1350 1
	ldq	at_reg, 0(t1)
d1352 1
a1352 1
	stq	zero, U_PCB_ONFAULT(at_reg)
a1363 3
	/* Note: GET_CURPROC clobbers v0, t0, t8...t11. */
	GET_CURPROC
	mov	v0, t1
d1366 1
a1366 1
	ldq	at_reg, 0(t1)
d1368 1
a1368 1
	stq	t0, U_PCB_ONFAULT(at_reg)
d1372 1
a1372 1
	ldq	at_reg, 0(t1)
d1374 1
a1374 1
	stq	zero, U_PCB_ONFAULT(at_reg)
a1384 3
	/* Note: GET_CURPROC clobbers v0, t0, t8...t11. */
	GET_CURPROC
	mov	v0, t1
d1387 1
a1387 1
	ldq	at_reg, 0(t1)
d1389 1
a1389 1
	stq	t0, U_PCB_ONFAULT(at_reg)
d1393 1
a1393 1
	ldq	at_reg, 0(t1)
d1395 1
a1395 1
	stq	zero, U_PCB_ONFAULT(at_reg)
a1407 3
	/* Note: GET_CURPROC clobbers v0, t0, t8...t11. */
	GET_CURPROC
	mov	v0, t1
d1410 1
a1410 1
	ldq	at_reg, 0(t1)
d1412 1
a1412 1
	stq	t0, U_PCB_ONFAULT(at_reg)
d1421 1
a1421 1
	ldq	at_reg, 0(t1)
d1423 1
a1423 1
	stq	zero, U_PCB_ONFAULT(at_reg)
a1433 3
	/* Note: GET_CURPROC clobbers v0, t0, t8...t11. */
	GET_CURPROC
	mov	v0, t1
d1436 1
a1436 1
	ldq	at_reg, 0(t1)
d1438 1
a1438 1
	stq	t0, U_PCB_ONFAULT(at_reg)
d1447 1
a1447 1
	ldq	at_reg, 0(t1)
d1449 1
a1449 1
	stq	zero, U_PCB_ONFAULT(at_reg)
a1475 3
	/* Note: GET_CURPROC clobbers v0, t0, t8...t11. */
	GET_CURPROC
	mov	v0, t1
d1478 1
a1478 1
	ldq	at_reg, 0(t1)
d1480 2
a1481 2
	stq	t0, U_PCB_ONFAULT(at_reg)
	stq	a0, U_PCB_ACCESSADDR(at_reg)
d1485 1
a1485 1
	ldq	at_reg, 0(t1)
d1487 1
a1487 1
	stq	zero, U_PCB_ONFAULT(at_reg)
a1496 3
	/* Note: GET_CURPROC clobbers v0, t0, t8...t11. */
	GET_CURPROC
	mov	v0, t1
d1499 1
a1499 1
	ldq	at_reg, 0(t1)
d1501 2
a1502 2
	stq	t0, U_PCB_ONFAULT(at_reg)
	stq	a0, U_PCB_ACCESSADDR(at_reg)
d1506 1
a1506 1
	ldq	at_reg, 0(t1)
d1508 1
a1508 1
	stq	zero, U_PCB_ONFAULT(at_reg)
a1528 2
#include <machine/intrcnt.h>

d1546 20
a1573 3
	stq	a0,(FRAME_A0*8)(sp)
	stq	a1,(FRAME_A1*8)(sp)
	stq	a2,(FRAME_A2*8)(sp)
d1599 2
a1600 2
	br	pv,1f
1:	LDGP(pv)
d1602 3
a1604 1
	mov	sp,a0
a1609 13
/**************************************************************************/

/*
 * Kernel setjmp and longjmp.  Rather minimalist.
 *
 *	longjmp(label_t *a)
 * will generate a "return (1)" from the last call to
 *	setjmp(label_t *a)
 * by restoring registers from the stack,
 */

	.set	noreorder

d1612 2
a1613 3

	stq	ra, (0 * 8)(a0)			/* return address */
	stq	s0, (1 * 8)(a0)			/* callee-saved registers */
d1621 1
a1621 4

	ldiq	t0, 0xbeeffedadeadbabe		/* set magic number */
	stq	t0, (9 * 8)(a0)

d1626 1
a1626 1
LEAF(longjmp, 1)
d1628 3
a1630 8

	ldiq	t0, 0xbeeffedadeadbabe		/* check magic number */
	ldq	t1, (9 * 8)(a0)
	cmpeq	t0, t1, t0
	beq	t0, longjmp_botch		/* if bad, punt */

	ldq	ra, (0 * 8)(a0)			/* return address */
	ldq	s0, (1 * 8)(a0)			/* callee-saved registers */
a1637 2

	ldiq	v0, 1
a1638 11

longjmp_botch:
	lda	a0, longjmp_botchmsg
	mov	ra, a1
	CALL(panic)
	call_pal PAL_bugchk

	.data
longjmp_botchmsg:
	.asciz	"longjmp botch from %p"
	.text
a1639 17

#if 0
NESTED(transfer_check,0,0,ra,0,0)
	CALL(U_need_2_run_config)
	END(transfer_check)
#endif

/* Random data that shouldn't be necessary. */
	.data
EXPORT(cold)
	.long 1			/* cold start flag (.long -> _4_ bytes) */
	.align 3
EXPORT(esym)
	.quad 1			/* store end of kernel symbol table here */


/**************************************************************************/
@


1.11.2.2
log
@Merge in -current from two days ago in the SMP branch.
As usual with merges, they do not indicate progress, so do not hold
your breath for working SMP, and do not mail me and ask about the
state of it.  It has not changed.  There is work ongoing, but very, very
slowly.  The commit is done in parts as to not lock up the tree in too
big chunks at a time.
@
text
@d1 1
a1 1
/* $OpenBSD: locore.s,v 1.11.2.1 2001/04/18 16:00:22 niklas Exp $ */
d627 1
d629 1
@


1.11.2.3
log
@Sync the SMP branch to something just after 3.0
@
text
@d1 1
a1 1
/* $OpenBSD: locore.s,v 1.11.2.2 2001/07/04 10:14:20 niklas Exp $ */
d387 1
a387 1
	CALL(softintr_dispatch)
@


1.11.2.4
log
@Sync the SMP branch with 3.3
@
text
@d1 2
a2 2
/* $OpenBSD$ */
/* $NetBSD: locore.s,v 1.94 2001/04/26 03:10:44 ross Exp $ */
d1463 313
a1782 1
	.type intrnames,@@object
a1786 1
	.type eintrnames,@@object
a1788 1
	.type intrcnt,@@object
a1792 1
	.type eintrcnt,@@object
a1907 57

/*
 * void sts(int rn, u_int32_t *rval);
 * void stt(int rn, u_int64_t *rval);
 * void lds(int rn, u_int32_t *rval);
 * void ldt(int rn, u_int64_t *rval);
 */

#ifndef NO_IEEE
.macro make_freg_util name, op
	LEAF(alpha_\name, 2)
	and	a0, 0x1f, a0
	s8addq	a0, pv, pv
	addq	pv, 1f - alpha_\name, pv
	jmp	(pv)
1:
	rn = 0
	.rept   32
	\op     $f0 + rn, 0(a1)
	RET
	rn = rn + 1
	.endr
	END(alpha_\name)
.endm
/*
LEAF(alpha_sts, 2)
LEAF(alpha_stt, 2)
LEAF(alpha_lds, 2)
LEAF(alpha_ldt, 2)
 */
	make_freg_util sts, sts
	make_freg_util stt, stt
	make_freg_util lds, lds
	make_freg_util ldt, ldt

LEAF(alpha_read_fpcr, 0); f30save = 0; rettmp = 8; framesz = 16
	lda	sp, -framesz(sp)
	stt	$f30, f30save(sp)
	mf_fpcr	$f30
	stt	$f30, rettmp(sp)
	ldt	$f30, f30save(sp)
	ldq	v0, rettmp(sp)
	lda	sp, framesz(sp)
	RET
END(alpha_read_fpcr)

LEAF(alpha_write_fpcr, 1); f30save = 0; fpcrtmp = 8; framesz = 16
	lda	sp, -framesz(sp)
	stq	a0, fpcrtmp(sp)
	stt	$f30, f30save(sp)
	ldt	$f30, fpcrtmp(sp)
	mt_fpcr	$f30
	ldt	$f30, f30save(sp)
	lda	sp, framesz(sp)
	RET
END(alpha_write_fpcr)
#endif
@


1.11.2.5
log
@Merge of -current from two weeks ago into the SMP branch
@
text
@d240 1
a240 1
 * Pull in the multiprocessor glue.
@


1.11.2.6
log
@p_stat = SONPROC
@
text
@d1 1
a1 1
/* $OpenBSD: locore.s,v 1.11.2.5 2004/02/19 09:59:33 niklas Exp $ */
d894 1
d907 1
@


1.10
log
@netbsd_sendsig() + supporting code
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.9 1997/07/08 10:55:53 niklas Exp $	*/
d861 3
a863 1
	beq	a2, Lcopystr2		/* if (len == 0), bail out */
d887 1
a887 1
	ldiq	v0, ENAMETOOLONG		/* *from != '\0'; error. */
@


1.9
log
@Recognize that a symbol table may exist, move up proc0paddr if so.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.8 1997/07/06 16:26:46 niklas Exp $	*/
d168 21
@


1.8
log
@Add kernel versions of setjmp/longjmp, needed for DDB.  Add an esym pointer
too that should be initialized by the bootloader with the end of the symtab.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.7 1997/01/24 19:56:35 niklas Exp $	*/
d61 1
d81 1
a81 1
	 * which are already in a0 and a1.
@


1.7
log
@Sync with NetBSD 961207
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.6 1996/11/14 13:17:06 niklas Exp $	*/
d134 3
d1585 31
@


1.6
log
@Add memcpy entrypoint to bcopy et al.  With this, in-tree gcc now
compiles a kernel which can be booted.  In-tree as still loses though.
@
text
@d1 2
a2 2
/*	$OpenBSD: locore.s,v 1.5 1996/10/30 22:38:13 niklas Exp $	*/
/*	$NetBSD: locore.s,v 1.26 1996/10/17 02:50:38 cgd Exp $	*/
d187 1
a187 3
	ldiq	a0, ALPHA_PSL_IPL_SOFT		/* yes, lower IPL to soft */
	call_pal PAL_OSF1_swpipl
	CALL(do_sir)				/* do the SIR */
a276 1
#ifndef __OpenBSD__
a277 1
#endif
@


1.5
log
@Merge to NetBSD 961020.  Retained our kernel APIs where NetBSD has changed.
-Wall -Wstrict-prototypes -Wmissing-prototypes too.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.26 1996/10/17 02:50:38 cgd Exp $	*/
d927 1
d931 6
a936 1
LEAF(bcopy,3)
@


1.4
log
@Add OpenBSD tags.  Adapt to OpenBSD *_intr_establish calling convention
@
text
@d1 2
a2 2
/*	$OpenBSD: locore.s,v 1.13.4.1 1996/06/13 18:06:59 cgd Exp $	*/
/*	$NetBSD: locore.s,v 1.13.4.1 1996/06/13 18:06:59 cgd Exp $	*/
d65 2
a66 2
	br	pv,1f
1:	SETGP(pv)
d68 2
a69 2
	/* Save a0, used by pal_wrkgp. */
	or	a0,zero,s0
d72 1
d74 2
a75 4
	CALL(pal_wrkgp)

	/* Switch to the boot stack. */
	lda	sp,bootstack
d78 3
a80 2
	 * Call alpha_init() to do pre-main initialization.  Restore
	 * a0, and pass alpha_init the arguments we were called with.
a81 1
	or	s0,zero,a0
d85 2
a86 2
	CONST(VPTBASE, a0)
	CALL(pal_wrvptptr)
d94 1
a94 1
	CONST(-1, a0)
a97 7
	 * put a fake RA (0 XXX) on the stack, to panic if anything
	 * ever tries to return off the end of the stack
	 */
	lda	sp,-8(sp)
	stq	zero,0(sp)

	/*
d102 1
a102 2
	lda	sp,-(FRAMESIZE)(sp)		/* space for struct trapframe */

d107 2
a108 2
	 * Call REI, to restore the faked up trap frame and return
	 * to proc 1 == init!
d110 1
a110 2
	mov	zero, a0
	JMP(rei)			/* "And that's all she wrote." */
d159 1
a159 2
	CONST(SYS_sigreturn, v0)	/* and call sigreturn() with it. */
	call_pal PAL_OSF1_callsys
d161 1
a161 2
	CONST(SYS_exit, v0)		/* and call exit() with it. */
	call_pal PAL_OSF1_callsys
d168 1
a168 1
 * rei: pseudo-emulation of VAX REI.
d174 3
a176 3
LEAF(rei, 1)					/* XXX should be NESTED */
	br	pv, 1f
1:	SETGP(pv)
d178 2
a179 2
	ldq	s1, TF_PS(sp)			/* get the saved PS */
	and	s1, PSL_IPL, t0			/* look at the saved IPL */
d187 1
a187 1
	CONST(PSL_IPL_SOFT, a0)			/* yes, lower IPL to soft */
d192 1
a192 1
	CONST(PSL_IPL_0, a0)			/* drop IPL to zero*/
d195 1
a195 1
	and	s1, PSL_U, t0			/* are we returning to user? */
d201 3
a203 6
	/* we've got an AST.  call trap to handle it */
	CONST(T_ASTFLT, a0)			/* type = T_ASTFLT */
	mov	zero, a1			/* code = 0 */
	mov	zero, a2			/* v = 0 */
	mov	sp, a3				/* frame */
	CALL(trap)
d215 38
a252 3
	/* restore the USP and the registers, and return */
	ldq	a0,(FRAME_SP*8)(sp)
	call_pal PAL_OSF1_wrusp
d254 1
a254 1
	.set noat
d256 10
a273 10
	ldq	s0,(FRAME_S0*8)(sp)
	ldq	s1,(FRAME_S1*8)(sp)
	ldq	s2,(FRAME_S2*8)(sp)
	ldq	s3,(FRAME_S3*8)(sp)
	ldq	s4,(FRAME_S4*8)(sp)
	ldq	s5,(FRAME_S5*8)(sp)
	ldq	s6,(FRAME_S6*8)(sp)
	ldq	a3,(FRAME_A3*8)(sp)
	ldq	a4,(FRAME_A4*8)(sp)
	ldq	a5,(FRAME_A5*8)(sp)
a277 1
	ldq	ra,(FRAME_RA*8)(sp)
d279 4
a282 5
	ldq	at_reg,(FRAME_AT*8)(sp)

	lda	sp,(FRAME_NSAVEREGS*8)(sp)
	call_pal PAL_OSF1_rti
	END(rei)
d293 1
a293 28
	lda	sp,-(FRAME_NSAVEREGS*8)(sp)
	stq	v0,(FRAME_V0*8)(sp)
	stq	t0,(FRAME_T0*8)(sp)
	stq	t1,(FRAME_T1*8)(sp)
	stq	t2,(FRAME_T2*8)(sp)
	stq	t3,(FRAME_T3*8)(sp)
	stq	t4,(FRAME_T4*8)(sp)
	stq	t5,(FRAME_T5*8)(sp)
	stq	t6,(FRAME_T6*8)(sp)
	stq	t7,(FRAME_T7*8)(sp)
	stq	s0,(FRAME_S0*8)(sp)
	stq	s1,(FRAME_S1*8)(sp)
	stq	s2,(FRAME_S2*8)(sp)
	mov	a0,s0
	stq	s3,(FRAME_S3*8)(sp)
	stq	s4,(FRAME_S4*8)(sp)
	stq	s5,(FRAME_S5*8)(sp)
	stq	s6,(FRAME_S6*8)(sp)
	mov	a1,s1
	stq	a3,(FRAME_A3*8)(sp)
	stq	a4,(FRAME_A4*8)(sp)
	stq	a5,(FRAME_A5*8)(sp)
	stq	t8,(FRAME_T8*8)(sp)
	stq	t9,(FRAME_T9*8)(sp)
	stq	t10,(FRAME_T10*8)(sp)
	stq	t11,(FRAME_T11*8)(sp)
	stq	ra,(FRAME_RA*8)(sp)
	stq	t12,(FRAME_T12*8)(sp)
a294 4

	call_pal PAL_OSF1_rdusp
	stq	v0,(FRAME_SP*8)(sp)

d296 2
d299 3
a301 7
	br	pv, 1f
1:	SETGP(pv)

	CONST(T_ARITHFLT, a0)			/* type = T_ARITHFLT */
	mov	s0, a1				/* code = "summary" */
	mov	s1, a2				/* v = "reguster mask" */
	mov	sp, a3				/* frame */
d304 1
a304 1
	JMP(rei)
d316 1
a316 27
	lda	sp,-(FRAME_NSAVEREGS*8)(sp)
	stq	v0,(FRAME_V0*8)(sp)
	stq	t0,(FRAME_T0*8)(sp)
	stq	t1,(FRAME_T1*8)(sp)
	stq	t2,(FRAME_T2*8)(sp)
	stq	t3,(FRAME_T3*8)(sp)
	stq	t4,(FRAME_T4*8)(sp)
	stq	t5,(FRAME_T5*8)(sp)
	stq	t6,(FRAME_T6*8)(sp)
	stq	t7,(FRAME_T7*8)(sp)
	stq	s0,(FRAME_S0*8)(sp)
	stq	s1,(FRAME_S1*8)(sp)
	stq	s2,(FRAME_S2*8)(sp)
	mov	a0,s0
	stq	s3,(FRAME_S3*8)(sp)
	stq	s4,(FRAME_S4*8)(sp)
	stq	s5,(FRAME_S5*8)(sp)
	stq	s6,(FRAME_S6*8)(sp)
	stq	a3,(FRAME_A3*8)(sp)
	stq	a4,(FRAME_A4*8)(sp)
	stq	a5,(FRAME_A5*8)(sp)
	stq	t8,(FRAME_T8*8)(sp)
	stq	t9,(FRAME_T9*8)(sp)
	stq	t10,(FRAME_T10*8)(sp)
	stq	t11,(FRAME_T11*8)(sp)
	stq	ra,(FRAME_RA*8)(sp)
	stq	t12,(FRAME_T12*8)(sp)
a317 4

	call_pal PAL_OSF1_rdusp
	stq	v0,(FRAME_SP*8)(sp)

d319 2
d322 3
a324 7
	br	pv, 1f
1:	SETGP(pv)

	or	s0, T_IFLT, a0			/* type = T_IFLT|type*/
	mov	s0, a1				/* code = type */
	ldq	a2, TF_PC(sp)			/* v = frame's pc */
	mov	sp, a3				/* frame */
d327 1
a327 1
	JMP(rei)
d339 1
a339 29
	lda	sp,-(FRAME_NSAVEREGS*8)(sp)
	stq	v0,(FRAME_V0*8)(sp)
	stq	t0,(FRAME_T0*8)(sp)
	stq	t1,(FRAME_T1*8)(sp)
	stq	t2,(FRAME_T2*8)(sp)
	stq	t3,(FRAME_T3*8)(sp)
	stq	t4,(FRAME_T4*8)(sp)
	stq	t5,(FRAME_T5*8)(sp)
	stq	t6,(FRAME_T6*8)(sp)
	stq	t7,(FRAME_T7*8)(sp)
	stq	s0,(FRAME_S0*8)(sp)
	stq	s1,(FRAME_S1*8)(sp)
	stq	s2,(FRAME_S2*8)(sp)
	mov	a0,s0
	stq	s3,(FRAME_S3*8)(sp)
	stq	s4,(FRAME_S4*8)(sp)
	stq	s5,(FRAME_S5*8)(sp)
	stq	s6,(FRAME_S6*8)(sp)
	mov	a1,s1
	stq	a3,(FRAME_A3*8)(sp)
	stq	a4,(FRAME_A4*8)(sp)
	stq	a5,(FRAME_A5*8)(sp)
	stq	t8,(FRAME_T8*8)(sp)
	mov	a2,s2
	stq	t9,(FRAME_T9*8)(sp)
	stq	t10,(FRAME_T10*8)(sp)
	stq	t11,(FRAME_T11*8)(sp)
	stq	ra,(FRAME_RA*8)(sp)
	stq	t12,(FRAME_T12*8)(sp)
a340 4

	call_pal PAL_OSF1_rdusp
	stq	v0,(FRAME_SP*8)(sp)

d342 2
d345 2
a346 7
	br	pv, 1f
1:	SETGP(pv)

	mov	s2,a3
	mov	s1,a2
	mov	s0,a1
	mov	sp,a0
d349 1
a349 1
	JMP(rei)
d361 1
a361 29
	lda	sp,-(FRAME_NSAVEREGS*8)(sp)
	stq	v0,(FRAME_V0*8)(sp)
	stq	t0,(FRAME_T0*8)(sp)
	stq	t1,(FRAME_T1*8)(sp)
	stq	t2,(FRAME_T2*8)(sp)
	stq	t3,(FRAME_T3*8)(sp)
	stq	t4,(FRAME_T4*8)(sp)
	stq	t5,(FRAME_T5*8)(sp)
	stq	t6,(FRAME_T6*8)(sp)
	stq	t7,(FRAME_T7*8)(sp)
	stq	s0,(FRAME_S0*8)(sp)
	stq	s1,(FRAME_S1*8)(sp)
	stq	s2,(FRAME_S2*8)(sp)
	mov	a0,s0
	stq	s3,(FRAME_S3*8)(sp)
	stq	s4,(FRAME_S4*8)(sp)
	stq	s5,(FRAME_S5*8)(sp)
	stq	s6,(FRAME_S6*8)(sp)
	mov	a1,s1
	stq	a3,(FRAME_A3*8)(sp)
	stq	a4,(FRAME_A4*8)(sp)
	stq	a5,(FRAME_A5*8)(sp)
	stq	t8,(FRAME_T8*8)(sp)
	mov	a2,s2
	stq	t9,(FRAME_T9*8)(sp)
	stq	t10,(FRAME_T10*8)(sp)
	stq	t11,(FRAME_T11*8)(sp)
	stq	ra,(FRAME_RA*8)(sp)
	stq	t12,(FRAME_T12*8)(sp)
a362 4

	call_pal PAL_OSF1_rdusp
	stq	v0,(FRAME_SP*8)(sp)

d364 2
d367 3
a369 7
	br	pv, 1f
1:	SETGP(pv)

	or	s1, T_MMFLT, a0			/* type = T_MMFLT|MMCSR */
	mov	s2, a1				/* code = "cause" */
	mov	s0, a2				/* v = VA */
	mov	sp, a3				/* frame */
d372 1
a372 1
	JMP(rei)
d383 1
a383 2
	.set noat
	lda	sp,-(FRAME_NSAVEREGS*8)(sp)
d392 3
a394 3
	stq	a0,TF_A0(sp)
	stq	a1,TF_A1(sp)
	stq	a2,TF_A2(sp)
d400 2
a401 12
	/* save syscall number, which was passed in v0. */
	mov	v0,s0

	call_pal PAL_OSF1_rdusp
	stq	v0,(FRAME_SP*8)(sp)

	.set at

	br	pv, 1f
1:	SETGP(pv)

	mov	s0,a0
d405 1
a405 1
	JMP(rei)
d417 1
a417 29
	lda	sp,-(FRAME_NSAVEREGS*8)(sp)
	stq	v0,(FRAME_V0*8)(sp)
	stq	t0,(FRAME_T0*8)(sp)
	stq	t1,(FRAME_T1*8)(sp)
	stq	t2,(FRAME_T2*8)(sp)
	stq	t3,(FRAME_T3*8)(sp)
	stq	t4,(FRAME_T4*8)(sp)
	stq	t5,(FRAME_T5*8)(sp)
	stq	t6,(FRAME_T6*8)(sp)
	stq	t7,(FRAME_T7*8)(sp)
	stq	s0,(FRAME_S0*8)(sp)
	stq	s1,(FRAME_S1*8)(sp)
	stq	s2,(FRAME_S2*8)(sp)
	mov	a0,s0
	stq	s3,(FRAME_S3*8)(sp)
	stq	s4,(FRAME_S4*8)(sp)
	stq	s5,(FRAME_S5*8)(sp)
	stq	s6,(FRAME_S6*8)(sp)
	mov	a1,s1
	stq	a3,(FRAME_A3*8)(sp)
	stq	a4,(FRAME_A4*8)(sp)
	stq	a5,(FRAME_A5*8)(sp)
	stq	t8,(FRAME_T8*8)(sp)
	mov	a2,s2
	stq	t9,(FRAME_T9*8)(sp)
	stq	t10,(FRAME_T10*8)(sp)
	stq	t11,(FRAME_T11*8)(sp)
	stq	ra,(FRAME_RA*8)(sp)
	stq	t12,(FRAME_T12*8)(sp)
a418 4

	call_pal PAL_OSF1_rdusp
	stq	v0,(FRAME_SP*8)(sp)

d420 2
d423 3
a425 7
	br	pv, 1f
1:	SETGP(pv)

	CONST(T_UNAFLT, a0)			/* type = T_UNAFLT */
	mov	zero, a1			/* code = 0 */
	mov	zero, a2			/* v = 0 */
	mov	sp, a3				/* frame */
d428 1
a428 1
	JMP(rei)
d441 1
a441 1
	SETGP(pv)
d472 1
d474 1
d482 1
a482 1
	MF_FPCR(ft0)
d498 1
a498 1
	SETGP(pv)
d504 1
a504 1
	MT_FPCR(ft0)
d554 1
a554 1
 *	a0	'struct user *' of the process that needs its context saved
d563 11
a573 11
	br	pv, 1f
1:	SETGP(pv)
	stq	sp, U_PCB_KSP(a0)		/* store sp */
	stq	s0, U_PCB_CONTEXT+(0 * 8)(a0)	/* store s0 - s6 */
	stq	s1, U_PCB_CONTEXT+(1 * 8)(a0)
	stq	s2, U_PCB_CONTEXT+(2 * 8)(a0)
	stq	s3, U_PCB_CONTEXT+(3 * 8)(a0)
	stq	s4, U_PCB_CONTEXT+(4 * 8)(a0)
	stq	s5, U_PCB_CONTEXT+(5 * 8)(a0)
	stq	s6, U_PCB_CONTEXT+(6 * 8)(a0)
	stq	ra, U_PCB_CONTEXT+(7 * 8)(a0)	/* store ra */
d575 1
a575 1
	stq	v0, U_PCB_CONTEXT+(8 * 8)(a0)	/* store ps, for ipl */
d596 2
a597 2
	br	pv, 1f
1:	SETGP(pv)
d601 1
a601 1
2:
d603 2
a604 2
	beq	t0, 2b
	CONST(PSL_IPL_HIGH, a0)			/* disable all interrupts */
d606 1
a606 1
	JMP(sw1)				/* jump back into the fray */
d615 1
a615 1
	SETGP(pv)
d618 1
a618 1
	ldq	a0, P_ADDR(a0)
d620 8
a627 8
	stq	s0, U_PCB_CONTEXT+(0 * 8)(a0)	/* store s0 - s6 */
	stq	s1, U_PCB_CONTEXT+(1 * 8)(a0)
	stq	s2, U_PCB_CONTEXT+(2 * 8)(a0)
	stq	s3, U_PCB_CONTEXT+(3 * 8)(a0)
	stq	s4, U_PCB_CONTEXT+(4 * 8)(a0)
	stq	s5, U_PCB_CONTEXT+(5 * 8)(a0)
	stq	s6, U_PCB_CONTEXT+(6 * 8)(a0)
	stq	ra, U_PCB_CONTEXT+(7 * 8)(a0)	/* store ra */
d629 4
a632 1
	stq	v0, U_PCB_CONTEXT+(8 * 8)(a0)	/* store ps, for ipl */
d637 1
a637 1
	CONST(PSL_IPL_HIGH, a0)			/* disable all interrupts */
d640 2
a641 2
	br	pv, 1f
1:	SETGP(pv)
d646 1
a646 1
	blbs	t0, 3f				/* if low bit set, done! */
d648 1
a648 1
2:	srl	t0, 1, t0			/* try next bit */
d650 1
a650 1
	blbc	t0, 2b				/* if clear, try again */
d652 1
a652 1
3:
d662 2
a663 2
	bne	t4, 4f				/* make sure p != NULL */
	PANIC("cpu_switch")			/* nothing in queue! */
d665 1
a665 1
4:
d670 1
a670 1
	beq	t0, 5f				/* nope, it's not! */
d672 1
a672 1
	CONST(1, t0)				/* compute bit in whichqs */
d677 1
a677 1
5:
d689 1
d700 1
a700 1
	CONST(-1, a0)				/* & invalidate old TLB ents */
d709 28
d738 10
a747 10
	ldq	s0, U_PCB_CONTEXT+(0 * 8)(t0)		/* restore s0 - s6 */
	ldq	s1, U_PCB_CONTEXT+(1 * 8)(t0)
	ldq	s2, U_PCB_CONTEXT+(2 * 8)(t0)
	ldq	s3, U_PCB_CONTEXT+(3 * 8)(t0)
	ldq	s4, U_PCB_CONTEXT+(4 * 8)(t0)
	ldq	s5, U_PCB_CONTEXT+(5 * 8)(t0)
	ldq	s6, U_PCB_CONTEXT+(6 * 8)(t0)
	ldq	ra, U_PCB_CONTEXT+(7 * 8)(t0)		/* restore ra */
	ldq	a0, U_PCB_CONTEXT+(8 * 8)(t0)		/* restore ipl */
	and	a0, PSL_IPL, a0
d750 1
a750 1
	CONST(1, v0)				/* possible ret to savectx() */
d754 1
d756 1
a756 1
 * proc_trampoline()
d764 1
a764 1
LEAF(proc_trampoline, 0)
d769 1
a769 1
	END(proc_trampoline)
d778 1
a778 1
	SETGP(pv)
d781 1
a781 1
	mov	a0, s0
d788 5
d797 1
d802 1
d805 2
a806 1
	CONST(-1, a0)				/* & invalidate old TLB ents */
d808 1
d817 2
a818 2
	ldq	a1, P_ADDR(s0)
	CONST(UPAGES*NBPG, a2)
d822 4
a825 1
	JMP(sw1)
d837 1
a837 1
	SETGP(pv)
d840 1
a840 1
	beq	a2, 2f			/* if (len == 0), bail out */
d842 1
a842 1
1:
d852 1
a852 1
	beq	t1, 2f			/* if (*from == 0), bail out */
d855 1
a855 1
	bne	a2, 1b			/* if (len != 0) copy more */
d857 2
a858 2
2:
	beq	a3, 3f			/* if (lenp != NULL) */
d861 2
a862 2
3:
	beq	t1, 4f			/* *from == '\0'; leave quietly */
d864 1
a864 1
	CONST(ENAMETOOLONG, v0)		/* *from != '\0'; error. */
d867 1
a867 1
4:
d873 1
a873 1
	SETGP(pv)
d876 1
a876 1
	CONST(VM_MAX_ADDRESS, t0)		/* make sure that src addr   */
d883 1
a883 1
	stq	v0, U_PCB_ONFAULT(at_reg)
d889 1
a889 1
	stq	zero, U_PCB_ONFAULT(at_reg)
d897 1
a897 1
	SETGP(pv)
d900 1
a900 1
	CONST(VM_MAX_ADDRESS, t0)		/* make sure that dest addr  */
d907 1
a907 1
	stq	v0, U_PCB_ONFAULT(at_reg)
d913 1
a913 1
	stq	zero, U_PCB_ONFAULT(at_reg)
d1155 1
a1155 1
	SETGP(pv)
d1158 1
a1158 1
	CONST(VM_MAX_ADDRESS, t0)		/* make sure that src addr   */
d1165 1
a1165 1
	stq	v0, U_PCB_ONFAULT(at_reg)
d1171 1
a1171 1
	stq	zero, U_PCB_ONFAULT(at_reg)
d1180 1
a1180 1
	SETGP(pv)
d1183 1
a1183 1
	CONST(VM_MAX_ADDRESS, t0)		/* make sure that dest addr  */
d1190 1
a1190 1
	stq	v0, U_PCB_ONFAULT(at_reg)
d1196 1
a1196 1
	stq	zero, U_PCB_ONFAULT(at_reg)
d1205 1
a1205 1
	SETGP(pv)
d1208 1
a1208 1
	CONST(EFAULT, v0)			/* return EFAULT.	     */
d1223 2
a1224 2
	SETGP(pv)
	CONST(VM_MAX_ADDRESS, t0)		/* make sure that addr */
d1231 1
a1231 1
	stq	t0, U_PCB_ONFAULT(at_reg)
d1238 1
a1238 1
	stq	zero, U_PCB_ONFAULT(at_reg)
d1245 2
a1246 2
	SETGP(pv)
	CONST(VM_MAX_ADDRESS, t0)		/* make sure that addr */
d1253 1
a1253 1
	stq	t0, U_PCB_ONFAULT(at_reg)
d1259 1
a1259 1
	stq	zero, U_PCB_ONFAULT(at_reg)
d1266 2
a1267 2
	SETGP(pv)
	CONST(VM_MAX_ADDRESS, t0)		/* make sure that addr */
d1274 1
a1274 1
	stq	t0, U_PCB_ONFAULT(at_reg)
d1280 1
a1280 1
	stq	zero, U_PCB_ONFAULT(at_reg)
d1287 2
a1288 2
	SETGP(pv)
	CONST(VM_MAX_ADDRESS, t0)		/* make sure that addr */
d1295 1
a1295 1
	stq	t0, U_PCB_ONFAULT(at_reg)
d1301 1
a1301 1
	stq	zero, U_PCB_ONFAULT(at_reg)
d1309 2
a1310 2
	SETGP(pv)
	CONST(VM_MAX_ADDRESS, t0)		/* make sure that addr */
d1317 1
a1317 1
	stq	t0, U_PCB_ONFAULT(at_reg)
d1323 1
a1323 1
	stq	zero, U_PCB_ONFAULT(at_reg)
d1331 2
a1332 2
	SETGP(pv)
	CONST(VM_MAX_ADDRESS, t0)		/* make sure that addr */
d1339 1
a1339 1
	stq	t0, U_PCB_ONFAULT(at_reg)
d1345 1
a1345 1
	stq	zero, U_PCB_ONFAULT(at_reg)
d1352 2
a1353 2
	SETGP(pv)
	CONST(VM_MAX_ADDRESS, t0)		/* make sure that addr */
d1360 1
a1360 1
	stq	t0, U_PCB_ONFAULT(at_reg)
d1366 1
a1366 1
	stq	zero, U_PCB_ONFAULT(at_reg)
d1375 2
a1376 2
	SETGP(pv)
	CONST(VM_MAX_ADDRESS, t0)		/* make sure that addr */
d1383 1
a1383 1
	stq	t0, U_PCB_ONFAULT(at_reg)
d1394 1
a1394 1
	stq	zero, U_PCB_ONFAULT(at_reg)
d1401 2
a1402 2
	SETGP(pv)
	CONST(VM_MAX_ADDRESS, t0)		/* make sure that addr */
d1409 1
a1409 1
	stq	t0, U_PCB_ONFAULT(at_reg)
d1420 1
a1420 1
	stq	zero, U_PCB_ONFAULT(at_reg)
d1428 2
a1429 2
	SETGP(pv)
	CONST(-1, v0)
d1443 2
a1444 2
	SETGP(pv)
	CONST(VM_MAX_ADDRESS, t0)		/* make sure that addr */
d1451 2
a1452 1
	stq	t0, U_PCB_ONFAULT(at_reg)
d1458 1
a1458 1
	stq	zero, U_PCB_ONFAULT(at_reg)
d1464 2
a1465 2
	SETGP(pv)
	CONST(VM_MAX_ADDRESS, t0)		/* make sure that addr */
d1472 2
a1473 1
	stq	t0, U_PCB_ONFAULT(at_reg)
d1479 1
a1479 1
	stq	zero, U_PCB_ONFAULT(at_reg)
d1489 2
a1490 2
	SETGP(pv)
	CONST(-1, v0)
d1516 17
a1532 3
	.text
LEAF(rpcc,1)
	rpcc	v0
d1534 1
a1534 1
	END(pal_mtpr_mces)
d1536 44
a1579 1
/**************************************************************************/
@


1.3
log
@sync to 0616, retaining local diffs
@
text
@d1 1
@


1.2
log
@update to netbsd
@
text
@d1 1
a1 1
/*	$NetBSD: locore.s,v 1.7 1995/11/23 02:34:11 cgd Exp $	*/
d4 1
a4 1
 * Copyright (c) 1994, 1995 Carnegie-Mellon University.
a29 2
#define LOCORE

d34 1
a34 1
#include "assym.s"
d38 8
a59 3
 *	a2 argc
 *	a3 argv
 *	a4 envp
a62 1
	.text
d1624 8
@


1.1
log
@Initial revision
@
text
@d1 1
a1 1
/*	$NetBSD: locore.s,v 1.6 1995/08/03 01:00:11 cgd Exp $	*/
d8 1
a8 1
 * 
d14 3
a16 3
 * 
 * CARNEGIE MELLON ALLOWS FREE USE OF THIS SOFTWARE IN ITS "AS IS" 
 * CONDITION.  CARNEGIE MELLON DISCLAIMS ANY LIABILITY OF ANY KIND 
d18 1
a18 1
 * 
d33 3
d61 1
a61 1
NESTED(__start,1,0,ra,0,0)
d123 1
a123 1
 * Pull in the PROM interface routines; these are needed for 
d905 1
a905 1
	
d910 1
a910 1
	
a940 4
#define	COPY_FRAME_SIZE	32
#define	COPY_FRAME_RA	0
#define	COPY_FRAME_S6	8

a949 5
	/* set up stack frame */
	lda	sp, -COPY_FRAME_SIZE(sp)
	stq	ra, COPY_FRAME_RA(sp)
	stq	s6, COPY_FRAME_S6(sp)

a972 5
	/* tear down stack frame */
	ldq	ra, COPY_FRAME_RA(sp)
	ldq	s6, COPY_FRAME_S6(sp)
	addq	sp, COPY_FRAME_SIZE, sp

d989 1
a989 1
	beq	t1, copyerr_noframe		/* if it's not, error out.   */
d1013 1
a1013 1
	beq	t1, copyerr_noframe		/* if it's not, error out.   */
d1034 6
a1039 1
 * int bcopy(char *from, char *to, u_int len);
d1041 2
a1042 2
LEAF(bcopy, 3)
	SETGP(pv)
d1044 2
a1045 4
	/* set up stack frame */
	lda	sp, -COPY_FRAME_SIZE(sp)
	stq	ra, COPY_FRAME_RA(sp)
	stq	s6, COPY_FRAME_S6(sp)
d1047 56
a1102 2
	mov	a2, t0			/* t0 = i = len */
	beq	a2, 2f			/* if (len == 0), bail out */
d1104 90
a1193 8
1:
	ldq_u	t1, 0(a0)		/* t1 = *from */
	extbl	t1, a0, t1
	ldq_u	t3, 0(a1)		/* set up t2 with quad around *to */
	insbl	t1, a1, t2
	mskbl	t3, a1, t3
	or	t3, t2, t3		/* add *from to quad around *to */
	stq_u	t3, 0(a1)		/* write out that quad */
d1195 7
a1201 4
	subl	a2, 1, a2		/* len-- */
	addq	a1, 1, a1		/* to++ */
	addq	a0, 1, a0		/* from++ */
	bne	a2, 1b			/* if (len != 0) copy more */
d1203 59
a1261 5
2:
	/* tear down stack frame */
	ldq	ra, COPY_FRAME_RA(sp)
	ldq	s6, COPY_FRAME_S6(sp)
	addq	sp, COPY_FRAME_SIZE, sp
a1262 1
	RET
d1271 1
a1271 1
	beq	t1, copyerr_noframe		/* if it's not, error out.   */
d1296 1
a1296 1
	beq	t1, copyerr_noframe		/* if it's not, error out.   */
a1316 7

	/* tear down copy functions' stack frame */
	ldq	ra, COPY_FRAME_RA(sp)
	ldq	s6, COPY_FRAME_S6(sp)
	addq	sp, COPY_FRAME_SIZE, sp

XLEAF(copyerr_noframe, 0)
d1602 20
@


1.1.1.1
log
@initial import of NetBSD tree
@
text
@@
