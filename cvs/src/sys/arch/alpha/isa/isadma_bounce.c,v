head	1.12;
access;
symbols
	OPENBSD_6_0:1.12.0.4
	OPENBSD_6_0_BASE:1.12
	OPENBSD_5_9:1.12.0.2
	OPENBSD_5_9_BASE:1.12
	OPENBSD_5_8:1.11.0.8
	OPENBSD_5_8_BASE:1.11
	OPENBSD_5_7:1.11.0.2
	OPENBSD_5_7_BASE:1.11
	OPENBSD_5_6:1.11.0.4
	OPENBSD_5_6_BASE:1.11
	OPENBSD_5_5:1.10.0.16
	OPENBSD_5_5_BASE:1.10
	OPENBSD_5_4:1.10.0.12
	OPENBSD_5_4_BASE:1.10
	OPENBSD_5_3:1.10.0.10
	OPENBSD_5_3_BASE:1.10
	OPENBSD_5_2:1.10.0.8
	OPENBSD_5_2_BASE:1.10
	OPENBSD_5_1_BASE:1.10
	OPENBSD_5_1:1.10.0.6
	OPENBSD_5_0:1.10.0.4
	OPENBSD_5_0_BASE:1.10
	OPENBSD_4_9:1.10.0.2
	OPENBSD_4_9_BASE:1.10
	OPENBSD_4_8:1.9.0.2
	OPENBSD_4_8_BASE:1.9
	OPENBSD_4_7:1.8.0.6
	OPENBSD_4_7_BASE:1.8
	OPENBSD_4_6:1.8.0.8
	OPENBSD_4_6_BASE:1.8
	OPENBSD_4_5:1.8.0.4
	OPENBSD_4_5_BASE:1.8
	OPENBSD_4_4:1.8.0.2
	OPENBSD_4_4_BASE:1.8
	OPENBSD_4_3:1.7.0.2
	OPENBSD_4_3_BASE:1.7
	OPENBSD_4_2:1.6.0.6
	OPENBSD_4_2_BASE:1.6
	OPENBSD_4_1:1.6.0.4
	OPENBSD_4_1_BASE:1.6
	OPENBSD_4_0:1.6.0.2
	OPENBSD_4_0_BASE:1.6
	OPENBSD_3_9:1.5.0.16
	OPENBSD_3_9_BASE:1.5
	OPENBSD_3_8:1.5.0.14
	OPENBSD_3_8_BASE:1.5
	OPENBSD_3_7:1.5.0.12
	OPENBSD_3_7_BASE:1.5
	OPENBSD_3_6:1.5.0.10
	OPENBSD_3_6_BASE:1.5
	SMP_SYNC_A:1.5
	SMP_SYNC_B:1.5
	OPENBSD_3_5:1.5.0.8
	OPENBSD_3_5_BASE:1.5
	OPENBSD_3_4:1.5.0.6
	OPENBSD_3_4_BASE:1.5
	UBC_SYNC_A:1.5
	OPENBSD_3_3:1.5.0.4
	OPENBSD_3_3_BASE:1.5
	OPENBSD_3_2:1.5.0.2
	OPENBSD_3_2_BASE:1.5
	OPENBSD_3_1:1.4.0.2
	OPENBSD_3_1_BASE:1.4
	UBC_SYNC_B:1.5
	UBC:1.3.0.4
	UBC_BASE:1.3
	SMP:1.3.0.2;
locks; strict;
comment	@ * @;


1.12
date	2015.09.27.10.12.09;	author semarie;	state Exp;
branches;
next	1.11;
commitid	1dIhYMDj5NezOASM;

1.11
date	2014.07.12.18.44.40;	author tedu;	state Exp;
branches;
next	1.10;
commitid	uKVPYMN2MLxdZxzH;

1.10
date	2010.11.20.20.58.49;	author miod;	state Exp;
branches;
next	1.9;

1.9
date	2010.03.27.02.09.54;	author oga;	state Exp;
branches;
next	1.8;

1.8
date	2008.06.26.05.42.08;	author ray;	state Exp;
branches;
next	1.7;

1.7
date	2007.10.06.23.12.17;	author krw;	state Exp;
branches;
next	1.6;

1.6
date	2006.05.12.20.48.19;	author brad;	state Exp;
branches;
next	1.5;

1.5
date	2002.06.25.21.33.21;	author miod;	state Exp;
branches;
next	1.4;

1.4
date	2002.03.14.01.26.27;	author millert;	state Exp;
branches;
next	1.3;

1.3
date	2001.11.06.19.53.13;	author miod;	state Exp;
branches
	1.3.2.1
	1.3.4.1;
next	1.2;

1.2
date	2001.11.05.17.25.57;	author art;	state Exp;
branches;
next	1.1;

1.1
date	2001.11.05.02.39.56;	author art;	state Exp;
branches;
next	;

1.3.2.1
date	2001.11.13.21.00.49;	author niklas;	state Exp;
branches;
next	1.3.2.2;

1.3.2.2
date	2002.03.28.10.06.13;	author niklas;	state Exp;
branches;
next	1.3.2.3;

1.3.2.3
date	2003.03.27.23.18.06;	author niklas;	state Exp;
branches;
next	;

1.3.4.1
date	2002.06.11.03.33.40;	author art;	state Exp;
branches;
next	1.3.4.2;

1.3.4.2
date	2002.10.29.00.28.00;	author art;	state Exp;
branches;
next	;


desc
@@


1.12
log
@free(x, 0) cleanup:
  - set size argument of free()
  - remove pointless if expression around free() call

ok guenther@@
@
text
@/*	$OpenBSD: isadma_bounce.c,v 1.11 2014/07/12 18:44:40 tedu Exp $	*/
/* $NetBSD: isadma_bounce.c,v 1.3 2000/06/29 09:02:57 mrg Exp $ */

/*-
 * Copyright (c) 1996, 1997, 1998, 2000 The NetBSD Foundation, Inc.
 * All rights reserved.
 *
 * This code is derived from software contributed to The NetBSD Foundation
 * by Jason R. Thorpe of the Numerical Aerospace Simulation Facility,
 * NASA Ames Research Center.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 *
 * THIS SOFTWARE IS PROVIDED BY THE NETBSD FOUNDATION, INC. AND CONTRIBUTORS
 * ``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED
 * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE FOUNDATION OR CONTRIBUTORS
 * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
 * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
 * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
 * POSSIBILITY OF SUCH DAMAGE.
 */

#define _ALPHA_BUS_DMA_PRIVATE
#include <sys/param.h>
#include <sys/systm.h>
#include <sys/syslog.h>
#include <sys/device.h>
#include <sys/malloc.h>
#include <sys/proc.h>
#include <sys/mbuf.h>

#include <machine/bus.h>

#include <dev/isa/isareg.h>
#include <dev/isa/isavar.h>

#include <uvm/uvm_extern.h>

extern	paddr_t avail_end;

/*
 * ISA can only DMA to 0-16M.
 */
#define	ISA_DMA_BOUNCE_THRESHOLD	(16 * 1024 * 1024)

/*
 * Cookie used by bouncing ISA DMA.  A pointer to one of these is stashed
 * in the DMA map.
 */
struct isadma_bounce_cookie {
	int	id_flags;		/* flags; see below */

	/*
	 * Information about the original buffer used during
	 * DMA map syncs.  Note that origbuflen is only used
	 * for ID_BUFTYPE_LINEAR.
	 */
	void	*id_origbuf;		/* pointer to orig buffer if
					   bouncing */
	bus_size_t id_origbuflen;	/* ...and size */
	int	id_buftype;		/* type of buffer */

	void	*id_bouncebuf;		/* pointer to the bounce buffer */
	bus_size_t id_bouncebuflen;	/* ...and size */
	int	id_nbouncesegs;		/* number of valid bounce segs */
	bus_dma_segment_t id_bouncesegs[1]; /* array of bounce buffer
					       physical memory segments */
};

/* id_flags */
#define	ID_MIGHT_NEED_BOUNCE	0x01	/* map could need bounce buffers */
#define	ID_HAS_BOUNCE		0x02	/* map currently has bounce buffers */
#define	ID_IS_BOUNCING		0x04	/* map is bouncing current xfer */

/* id_buftype */
#define	ID_BUFTYPE_INVALID	0
#define	ID_BUFTYPE_LINEAR	1
#define	ID_BUFTYPE_MBUF		2
#define	ID_BUFTYPE_UIO		3
#define	ID_BUFTYPE_RAW		4

int	isadma_bounce_alloc_bouncebuf(bus_dma_tag_t, bus_dmamap_t,
	    bus_size_t, int);
void	isadma_bounce_free_bouncebuf(bus_dma_tag_t, bus_dmamap_t);

/*
 * Create an ISA DMA map.
 */
int
isadma_bounce_dmamap_create(bus_dma_tag_t t, bus_size_t size, int nsegments,
    bus_size_t maxsegsz, bus_size_t boundary, int flags, bus_dmamap_t *dmamp)
{
	struct isadma_bounce_cookie *cookie;
	bus_dmamap_t map;
	int error, cookieflags;
	void *cookiestore;
	size_t cookiesize;

	/* Call common function to create the basic map. */
	error = _bus_dmamap_create(t, size, nsegments, maxsegsz, boundary,
	    flags, dmamp);
	if (error)
		return (error);

	map = *dmamp;
	map->_dm_cookie = NULL;

	cookiesize = sizeof(*cookie);

	/*
	 * ISA only has 24-bits of address space.  This means
	 * we can't DMA to pages over 16M.  In order to DMA to
	 * arbitrary buffers, we use "bounce buffers" - pages
	 * in memory below the 16M boundary.  On DMA reads,
	 * DMA happens to the bounce buffers, and is copied into
	 * the caller's buffer.  On writes, data is copied into
	 * the bounce buffer, and the DMA happens from those
	 * pages.  To software using the DMA mapping interface,
	 * this looks simply like a data cache.
	 *
	 * If we have more than 16M of RAM in the system, we may
	 * need bounce buffers.  We check and remember that here.
	 *
	 * ...or, there is an opposite case.  The most segments
	 * a transfer will require is (maxxfer / PAGE_SIZE) + 1.  If
	 * the caller can't handle that many segments (e.g. the
	 * ISA DMA controller), we may have to bounce it as well.
	 */
	cookieflags = 0;
	if (avail_end > (t->_wbase + t->_wsize) ||
	    ((map->_dm_size / PAGE_SIZE) + 1) > map->_dm_segcnt) {
		cookieflags |= ID_MIGHT_NEED_BOUNCE;
		cookiesize += (sizeof(bus_dma_segment_t) *
		    (map->_dm_segcnt - 1));
	}

	/*
	 * Allocate our cookie.
	 */
	if ((cookiestore = malloc(cookiesize, M_DEVBUF, (flags & BUS_DMA_NOWAIT)
	    ? (M_NOWAIT | M_ZERO) : (M_WAITOK | M_ZERO))) == NULL) {
		error = ENOMEM;
		goto out;
	}
	cookie = (struct isadma_bounce_cookie *)cookiestore;
	cookie->id_flags = cookieflags;
	map->_dm_cookie = cookie;

	if (cookieflags & ID_MIGHT_NEED_BOUNCE) {
		/*
		 * Allocate the bounce pages now if the caller
		 * wishes us to do so.
		 */
		if ((flags & BUS_DMA_ALLOCNOW) == 0)
			goto out;

		error = isadma_bounce_alloc_bouncebuf(t, map, size, flags);
	}

 out:
	if (error) {
		free(map->_dm_cookie, M_DEVBUF, cookiesize);
		_bus_dmamap_destroy(t, map);
	}
	return (error);
}

/*
 * Destroy an ISA DMA map.
 */
void
isadma_bounce_dmamap_destroy(bus_dma_tag_t t, bus_dmamap_t map)
{
	struct isadma_bounce_cookie *cookie = map->_dm_cookie;

	/*
	 * Free any bounce pages this map might hold.
	 */
	if (cookie->id_flags & ID_HAS_BOUNCE)
		isadma_bounce_free_bouncebuf(t, map);

	free(cookie, M_DEVBUF, 0);
	_bus_dmamap_destroy(t, map);
}

/*
 * Load an ISA DMA map with a linear buffer.
 */
int
isadma_bounce_dmamap_load(bus_dma_tag_t t, bus_dmamap_t map, void *buf,
    size_t buflen, struct proc *p, int flags)
{
	struct isadma_bounce_cookie *cookie = map->_dm_cookie;
	int error;

	/*
	 * Make sure that on error condition we return "no valid mappings."
	 */
	map->dm_mapsize = 0;
	map->dm_nsegs = 0;

	/*
	 * Try to load the map the normal way.  If this errors out,
	 * and we can bounce, we will.
	 */
	error = _bus_dmamap_load_direct(t, map, buf, buflen, p, flags);
	if (error == 0 ||
	    (error != 0 && (cookie->id_flags & ID_MIGHT_NEED_BOUNCE) == 0))
		return (error);

	/*
	 * First attempt failed; bounce it.
	 */

	/*
	 * Allocate bounce pages, if necessary.
	 */
	if ((cookie->id_flags & ID_HAS_BOUNCE) == 0) {
		error = isadma_bounce_alloc_bouncebuf(t, map, buflen, flags);
		if (error)
			return (error);
	}

	/*
	 * Cache a pointer to the caller's buffer and load the DMA map
	 * with the bounce buffer.
	 */
	cookie->id_origbuf = buf;
	cookie->id_origbuflen = buflen;
	cookie->id_buftype = ID_BUFTYPE_LINEAR;
	error = _bus_dmamap_load_direct(t, map, cookie->id_bouncebuf, buflen,
	    p, flags);
	if (error) {
		/*
		 * Free the bounce pages, unless our resources
		 * are reserved for our exclusive use.
		 */
		if ((map->_dm_flags & BUS_DMA_ALLOCNOW) == 0)
			isadma_bounce_free_bouncebuf(t, map);
		return (error);
	}

	/* ...so isadma_bounce_dmamap_sync() knows we're bouncing */
	cookie->id_flags |= ID_IS_BOUNCING;
	map->_dm_window = t;
	return (0);
}

/*
 * Like isadma_bounce_dmamap_load(), but for mbufs.
 */
int
isadma_bounce_dmamap_load_mbuf(bus_dma_tag_t t, bus_dmamap_t map,
    struct mbuf *m0, int flags)  
{
	struct isadma_bounce_cookie *cookie = map->_dm_cookie;
	int error;

	/*
	 * Make sure on error condition we return "no valid mappings."
	 */
	map->dm_mapsize = 0;
	map->dm_nsegs = 0;

#ifdef DIAGNOSTIC
	if ((m0->m_flags & M_PKTHDR) == 0)
		panic("isadma_bounce_dmamap_load_mbuf: no packet header");
#endif

	if (m0->m_pkthdr.len > map->_dm_size)
		return (EINVAL);

	/*
	 * Try to load the map the normal way.  If this errors out,
	 * and we can bounce, we will.
	 */
	error = _bus_dmamap_load_mbuf_direct(t, map, m0, flags);
	if (error == 0 ||
	    (error != 0 && (cookie->id_flags & ID_MIGHT_NEED_BOUNCE) == 0))
		return (error);

	/*
	 * First attempt failed; bounce it.
	 */

	/*
	 * Allocate bounce pages, if necessary.
	 */
	if ((cookie->id_flags & ID_HAS_BOUNCE) == 0) {
		error = isadma_bounce_alloc_bouncebuf(t, map, m0->m_pkthdr.len,
		    flags);
		if (error)
			return (error);
	}

	/*
	 * Cache a pointer to the caller's buffer and load the DMA map
	 * with the bounce buffer.
	 */
	cookie->id_origbuf = m0;
	cookie->id_origbuflen = m0->m_pkthdr.len;	/* not really used */
	cookie->id_buftype = ID_BUFTYPE_MBUF;
	error = _bus_dmamap_load_direct(t, map, cookie->id_bouncebuf,
	    m0->m_pkthdr.len, NULL, flags);
	if (error) {
		/*
		 * Free the bounce pages, unless our resources
		 * are reserved for our exclusive use.
		 */
		if ((map->_dm_flags & BUS_DMA_ALLOCNOW) == 0)
			isadma_bounce_free_bouncebuf(t, map);
		return (error);
	}

	/* ...so isadma_bounce_dmamap_sync() knows we're bouncing */
	cookie->id_flags |= ID_IS_BOUNCING;
	map->_dm_window = t;
	return (0);
}

/*
 * Like isadma_bounce_dmamap_load(), but for uios.
 */
int
isadma_bounce_dmamap_load_uio(bus_dma_tag_t t, bus_dmamap_t map,
    struct uio *uio, int flags)
{

	panic("isadma_bounce_dmamap_load_uio: not implemented");
}

/*
 * Like isadma_bounce_dmamap_load(), but for raw memory allocated with
 * bus_dmamem_alloc().
 */
int
isadma_bounce_dmamap_load_raw(bus_dma_tag_t t, bus_dmamap_t map,
    bus_dma_segment_t *segs, int nsegs, bus_size_t size, int flags)
{

	panic("isadma_bounce_dmamap_load_raw: not implemented");
}

/*
 * Unload an ISA DMA map.
 */
void
isadma_bounce_dmamap_unload(bus_dma_tag_t t, bus_dmamap_t map)
{
	struct isadma_bounce_cookie *cookie = map->_dm_cookie;

	/*
	 * If we have bounce pages, free them, unless they're
	 * reserved for our exclusive use.
	 */
	if ((cookie->id_flags & ID_HAS_BOUNCE) &&
	    (map->_dm_flags & BUS_DMA_ALLOCNOW) == 0)
		isadma_bounce_free_bouncebuf(t, map);

	cookie->id_flags &= ~ID_IS_BOUNCING;
	cookie->id_buftype = ID_BUFTYPE_INVALID;

	/*
	 * Do the generic bits of the unload.
	 */
	_bus_dmamap_unload(t, map);
}

void
isadma_bounce_dmamap_sync(bus_dma_tag_t t, bus_dmamap_t map, bus_addr_t offset,
	bus_size_t len, int ops)
{
	struct isadma_bounce_cookie *cookie = map->_dm_cookie;

	/*
	 * Mixing PRE and POST operations is not allowed.
	 */
	if ((ops & (BUS_DMASYNC_PREREAD|BUS_DMASYNC_PREWRITE)) != 0 &&
	    (ops & (BUS_DMASYNC_POSTREAD|BUS_DMASYNC_POSTWRITE)) != 0)
		panic("isadma_bounce_dmamap_sync: mix PRE and POST");

#ifdef DIAGNOSTIC
	if ((ops & (BUS_DMASYNC_PREWRITE|BUS_DMASYNC_POSTREAD)) != 0) {
		if (offset >= map->dm_mapsize)
			panic("isadma_bounce_dmamap_sync: bad offset");
		if (len == 0 || (offset + len) > map->dm_mapsize)
			panic("isadma_bounce_dmamap_sync: bad length");
	}
#endif

	/*
	 * If we're not bouncing, just drain the write buffer
	 * and return.
	 */
	if ((cookie->id_flags & ID_IS_BOUNCING) == 0) {
		alpha_mb();
		return;
	}

	switch (cookie->id_buftype) {
	case ID_BUFTYPE_LINEAR:
		/*
		 * Nothing to do for pre-read.
		 */

		if (ops & BUS_DMASYNC_PREWRITE) {
			/*
			 * Copy the caller's buffer to the bounce buffer.
			 */
			memcpy((char *)cookie->id_bouncebuf + offset,
			    (char *)cookie->id_origbuf + offset, len);
		}

		if (ops & BUS_DMASYNC_POSTREAD) {
			/*
			 * Copy the bounce buffer to the caller's buffer.
			 */
			memcpy((char *)cookie->id_origbuf + offset,
			    (char *)cookie->id_bouncebuf + offset, len);
		}

		/*
		 * Nothing to do for post-write.
		 */
		break;

	case ID_BUFTYPE_MBUF:
	    {
		struct mbuf *m, *m0 = cookie->id_origbuf;
		bus_size_t minlen, moff;

		/*
		 * Nothing to do for pre-read.
		 */

		if (ops & BUS_DMASYNC_PREWRITE) {
			/*
			 * Copy the caller's buffer to the bounce buffer.
			 */
			m_copydata(m0, offset, len,
			    (char *)cookie->id_bouncebuf + offset);
		}

		if (ops & BUS_DMASYNC_POSTREAD) {
			/*
			 * Copy the bounce buffer to the caller's buffer.
			 */
			for (moff = offset, m = m0; m != NULL && len != 0;
			     m = m->m_next) {
				/* Find the beginning mbuf. */
				if (moff >= m->m_len) {
					moff -= m->m_len;
					continue;
				}

				/*
				 * Now at the first mbuf to sync; nail
				 * each one until we have exhausted the
				 * length.
				 */
				minlen = len < m->m_len - moff ?
				    len : m->m_len - moff;

				memcpy(mtod(m, caddr_t) + moff,
				    (char *)cookie->id_bouncebuf + offset,
				    minlen);

				moff = 0;
				len -= minlen;
				offset += minlen;
			}
		}

		/*
		 * Nothing to do for post-write.
		 */
		break;
	    }

	case ID_BUFTYPE_UIO:
		panic("isadma_bounce_dmamap_sync: ID_BUFTYPE_UIO");
		break;

	case ID_BUFTYPE_RAW:
		panic("isadma_bounce_dmamap_sync: ID_BUFTYPE_RAW");
		break;

	case ID_BUFTYPE_INVALID:
		panic("isadma_bounce_dmamap_sync: ID_BUFTYPE_INVALID");
		break;

	default:
		panic("isadma_bounce_dmamap_sync: unknown buffer type %d",
		    cookie->id_buftype);
	}

	/* Drain the write buffer. */
	alpha_mb();
}

/*
 * Allocate memory safe for ISA DMA.
 */
int
isadma_bounce_dmamem_alloc(bus_dma_tag_t t, bus_size_t size,
    bus_size_t alignment, bus_size_t boundary, bus_dma_segment_t *segs,
    int nsegs, int *rsegs, int flags)
{
	int error;

	/* Try in ISA addressable region first */
	error = _bus_dmamem_alloc_range(t, size, alignment, boundary,
	    segs, nsegs, rsegs, flags, 0, ISA_DMA_BOUNCE_THRESHOLD);
	if (!error)
		return (error);

	/* Otherwise try anywhere (we'll bounce later) */
	error = _bus_dmamem_alloc_range(t, size, alignment, boundary,
	    segs, nsegs, rsegs, flags, (paddr_t)0, (paddr_t)-1);
	return (error);
}

/**********************************************************************
 * ISA DMA utility functions
 **********************************************************************/

int
isadma_bounce_alloc_bouncebuf(bus_dma_tag_t t, bus_dmamap_t map,
    bus_size_t size, int flags)
{
	struct isadma_bounce_cookie *cookie = map->_dm_cookie;
	int error = 0;

	cookie->id_bouncebuflen = round_page(size);
	error = _bus_dmamem_alloc_range(t, cookie->id_bouncebuflen,
	    PAGE_SIZE, map->_dm_boundary, cookie->id_bouncesegs,
	    map->_dm_segcnt, &cookie->id_nbouncesegs, flags,
	    0, ISA_DMA_BOUNCE_THRESHOLD);
	if (error)
		goto out;
	error = _bus_dmamem_map(t, cookie->id_bouncesegs,
	    cookie->id_nbouncesegs, cookie->id_bouncebuflen,
	    (caddr_t *)&cookie->id_bouncebuf, flags);

 out:
	if (error) {
		_bus_dmamem_free(t, cookie->id_bouncesegs,
		    cookie->id_nbouncesegs);
		cookie->id_bouncebuflen = 0;
		cookie->id_nbouncesegs = 0;
	} else
		cookie->id_flags |= ID_HAS_BOUNCE;

	return (error);
}

void
isadma_bounce_free_bouncebuf(bus_dma_tag_t t, bus_dmamap_t map)
{
	struct isadma_bounce_cookie *cookie = map->_dm_cookie;

	_bus_dmamem_unmap(t, cookie->id_bouncebuf,
	    cookie->id_bouncebuflen);
	_bus_dmamem_free(t, cookie->id_bouncesegs,
	    cookie->id_nbouncesegs);
	cookie->id_bouncebuflen = 0;
	cookie->id_nbouncesegs = 0;
	cookie->id_flags &= ~ID_HAS_BOUNCE;
}
@


1.11
log
@add a size argument to free. will be used soon, but for now default to 0.
after discussions with beck deraadt kettenis.
@
text
@d1 1
a1 1
/*	$OpenBSD: isadma_bounce.c,v 1.10 2010/11/20 20:58:49 miod Exp $	*/
d173 1
a173 2
		if (map->_dm_cookie != NULL)
			free(map->_dm_cookie, M_DEVBUF, 0);
@


1.10
log
@typo
@
text
@d1 1
a1 1
/*	$OpenBSD: isadma_bounce.c,v 1.9 2010/03/27 02:09:54 oga Exp $	*/
d174 1
a174 1
			free(map->_dm_cookie, M_DEVBUF);
d194 1
a194 1
	free(cookie, M_DEVBUF);
@


1.9
log
@Similar fix to amd64 and i386 for isa bus_dma.

Don't trunc_page when determining the highest address to alloc. it is
not what pglistalloc expects and pmemrange will fail that allocation.

For consistency, if we fail to alloc under 16meg then alloc high as
assume we'll bounce (same as i386 and amd64)

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: isadma_bounce.c,v 1.8 2008/06/26 05:42:08 ray Exp $	*/
d128 1
a128 1
	 * but bounce buffer, and the DMA happens from those
@


1.8
log
@First pass at removing clauses 3 and 4 from NetBSD licenses.

Not sure what's more surprising: how long it took for NetBSD to
catch up to the rest of the BSDs (including UCB), or the amount of
code that NetBSD has claimed for itself without attributing to the
actual authors.

OK deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: isadma_bounce.c,v 1.7 2007/10/06 23:12:17 krw Exp $	*/
d521 1
a521 1
	paddr_t high;
d523 5
a527 4
	if (avail_end > ISA_DMA_BOUNCE_THRESHOLD)
		high = trunc_page(ISA_DMA_BOUNCE_THRESHOLD);
	else
		high = trunc_page(avail_end);
d529 4
a532 2
	return (_bus_dmamem_alloc_range(t, size, alignment, boundary,
	    segs, nsegs, rsegs, flags, 0, high));
d547 1
a547 1
	error = isadma_bounce_dmamem_alloc(t, cookie->id_bouncebuflen,
d549 2
a550 1
	    map->_dm_segcnt, &cookie->id_nbouncesegs, flags);
@


1.7
log
@Some archs used memset() rather than bzero(). So duplicate diff
previously applied to other archs deleting a memset() this time. e.g.

-	if ((mapstore = malloc(mapsize, M_DEVBUF,
-	    (flags & BUS_DMA_NOWAIT) ? M_NOWAIT : M_WAITOK)) == NULL)
+	if ((mapstore = malloc(mapsize, M_DEVBUF, (flags & BUS_DMA_NOWAIT) ?
+	    (M_NOWAIT | M_ZERO) : (M_WAITOK | M_ZERO))) == NULL)
 		return (ENOMEM);

-	memset(mapstore, 0, mapsize);
@
text
@d1 1
a1 1
/*	$OpenBSD: isadma_bounce.c,v 1.6 2006/05/12 20:48:19 brad Exp $	*/
a19 7
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *	This product includes software developed by the NetBSD
 *	Foundation, Inc. and its contributors.
 * 4. Neither the name of The NetBSD Foundation nor the names of its
 *    contributors may be used to endorse or promote products derived
 *    from this software without specific prior written permission.
@


1.6
log
@Keep track of which DMA window was actually used to map the
request (not always the passed in DMA tag if we try direct-map
and then fall back to sgmap-mapped).  Use the actual window
when performing dmamap_sync and dmamap_unload operations.

From NetBSD

ok martin@@
@
text
@d1 1
a1 1
/*	$OpenBSD: isadma_bounce.c,v 1.5 2002/06/25 21:33:21 miod Exp $	*/
d158 2
a159 2
	if ((cookiestore = malloc(cookiesize, M_DEVBUF,
	    (flags & BUS_DMA_NOWAIT) ? M_NOWAIT : M_WAITOK)) == NULL) {
a162 1
	memset(cookiestore, 0, cookiesize);
@


1.5
log
@No \n at the end of a panic() message... I thought all occurences had been
squashed already.
@
text
@d1 1
a1 1
/*	$OpenBSD: isadma_bounce.c,v 1.4 2002/03/14 01:26:27 millert Exp $	*/
d265 1
d337 1
@


1.4
log
@First round of __P removal in sys
@
text
@d1 1
a1 1
/*	$OpenBSD: isadma_bounce.c,v 1.3 2001/11/06 19:53:13 miod Exp $	*/
d511 2
a512 2
		printf("unknown buffer type %d\n", cookie->id_buftype);
		panic("isadma_bounce_dmamap_sync");
@


1.3
log
@Replace inclusion of <vm/foo.h> with the correct <uvm/bar.h> when necessary.
(Look ma, I might have broken the tree)
@
text
@d1 1
a1 1
/*	$OpenBSD: isadma_bounce.c,v 1.2 2001/11/05 17:25:57 art Exp $	*/
d100 3
a102 3
int	isadma_bounce_alloc_bouncebuf __P((bus_dma_tag_t, bus_dmamap_t,
	    bus_size_t, int));
void	isadma_bounce_free_bouncebuf __P((bus_dma_tag_t, bus_dmamap_t));
@


1.3.4.1
log
@Sync UBC branch to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: isadma_bounce.c,v 1.3 2001/11/06 19:53:13 miod Exp $	*/
d100 3
a102 3
int	isadma_bounce_alloc_bouncebuf(bus_dma_tag_t, bus_dmamap_t,
	    bus_size_t, int);
void	isadma_bounce_free_bouncebuf(bus_dma_tag_t, bus_dmamap_t);
@


1.3.4.2
log
@sync to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: isadma_bounce.c,v 1.3.4.1 2002/06/11 03:33:40 art Exp $	*/
d511 2
a512 2
		panic("isadma_bounce_dmamap_sync: unknown buffer type %d",
		    cookie->id_buftype);
@


1.3.2.1
log
@Merge in -current
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
@


1.3.2.2
log
@Merge in -current from about a week ago
@
text
@d100 3
a102 3
int	isadma_bounce_alloc_bouncebuf(bus_dma_tag_t, bus_dmamap_t,
	    bus_size_t, int);
void	isadma_bounce_free_bouncebuf(bus_dma_tag_t, bus_dmamap_t);
@


1.3.2.3
log
@Sync the SMP branch with 3.3
@
text
@d511 2
a512 2
		panic("isadma_bounce_dmamap_sync: unknown buffer type %d",
		    cookie->id_buftype);
@


1.2
log
@Switch everything to the new bus_dmamap_sync API.
Most work by Wilbern Cobb <vedge@@csoft.org> with some fixes from me, mickey@@
and drahn@@.
@
text
@d1 1
a1 1
/*	$OpenBSD: isadma_bounce.c,v 1.1 2001/11/05 02:39:56 art Exp $	*/
a54 1
#include <vm/vm.h>
@


1.1
log
@Code for isadma bouncing.
From NetBSD.
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d389 2
a390 2
isadma_bounce_dmamap_sync(bus_dma_tag_t t, bus_dmamap_t map,
	bus_dmasync_op_t ops)
a392 2
	bus_addr_t offset = 0;
	bus_size_t len = map->dm_mapsize;
@

