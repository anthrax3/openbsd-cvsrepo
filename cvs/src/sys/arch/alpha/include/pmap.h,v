head	1.40;
access;
symbols
	OPENBSD_6_1_BASE:1.40
	OPENBSD_6_0:1.40.0.2
	OPENBSD_6_0_BASE:1.40
	OPENBSD_5_9:1.39.0.2
	OPENBSD_5_9_BASE:1.39
	OPENBSD_5_8:1.36.0.6
	OPENBSD_5_8_BASE:1.36
	OPENBSD_5_7:1.36.0.2
	OPENBSD_5_7_BASE:1.36
	OPENBSD_5_6:1.32.0.6
	OPENBSD_5_6_BASE:1.32
	OPENBSD_5_5:1.32.0.4
	OPENBSD_5_5_BASE:1.32
	OPENBSD_5_4:1.28.0.2
	OPENBSD_5_4_BASE:1.28
	OPENBSD_5_3:1.26.0.6
	OPENBSD_5_3_BASE:1.26
	OPENBSD_5_2:1.26.0.4
	OPENBSD_5_2_BASE:1.26
	OPENBSD_5_1_BASE:1.26
	OPENBSD_5_1:1.26.0.2
	OPENBSD_5_0:1.25.0.4
	OPENBSD_5_0_BASE:1.25
	OPENBSD_4_9:1.25.0.2
	OPENBSD_4_9_BASE:1.25
	OPENBSD_4_8:1.24.0.10
	OPENBSD_4_8_BASE:1.24
	OPENBSD_4_7:1.24.0.6
	OPENBSD_4_7_BASE:1.24
	OPENBSD_4_6:1.24.0.8
	OPENBSD_4_6_BASE:1.24
	OPENBSD_4_5:1.24.0.4
	OPENBSD_4_5_BASE:1.24
	OPENBSD_4_4:1.24.0.2
	OPENBSD_4_4_BASE:1.24
	OPENBSD_4_3:1.23.0.2
	OPENBSD_4_3_BASE:1.23
	OPENBSD_4_2:1.21.0.8
	OPENBSD_4_2_BASE:1.21
	OPENBSD_4_1:1.21.0.6
	OPENBSD_4_1_BASE:1.21
	OPENBSD_4_0:1.21.0.4
	OPENBSD_4_0_BASE:1.21
	OPENBSD_3_9:1.21.0.2
	OPENBSD_3_9_BASE:1.21
	OPENBSD_3_8:1.20.0.6
	OPENBSD_3_8_BASE:1.20
	OPENBSD_3_7:1.20.0.4
	OPENBSD_3_7_BASE:1.20
	OPENBSD_3_6:1.20.0.2
	OPENBSD_3_6_BASE:1.20
	SMP_SYNC_A:1.17
	SMP_SYNC_B:1.17
	OPENBSD_3_5:1.15.0.2
	OPENBSD_3_5_BASE:1.15
	OPENBSD_3_4:1.14.0.2
	OPENBSD_3_4_BASE:1.14
	UBC_SYNC_A:1.13
	OPENBSD_3_3:1.13.0.4
	OPENBSD_3_3_BASE:1.13
	OPENBSD_3_2:1.13.0.2
	OPENBSD_3_2_BASE:1.13
	OPENBSD_3_1:1.11.0.4
	OPENBSD_3_1_BASE:1.11
	UBC_SYNC_B:1.13
	UBC:1.11.0.2
	UBC_BASE:1.11
	OPENBSD_3_0:1.9.0.2
	OPENBSD_3_0_BASE:1.9
	OPENBSD_2_9:1.8.0.2
	OPENBSD_2_9_BASE:1.8
	OPENBSD_2_8:1.4.0.18
	OPENBSD_2_8_BASE:1.4
	OPENBSD_2_7:1.4.0.16
	OPENBSD_2_7_BASE:1.4
	SMP:1.4.0.14
	SMP_BASE:1.4
	kame_19991208:1.4
	OPENBSD_2_6:1.4.0.12
	OPENBSD_2_6_BASE:1.4
	OPENBSD_2_5:1.4.0.10
	OPENBSD_2_5_BASE:1.4
	OPENBSD_2_4:1.4.0.8
	OPENBSD_2_4_BASE:1.4
	OPENBSD_2_3:1.4.0.6
	OPENBSD_2_3_BASE:1.4
	OPENBSD_2_2:1.4.0.4
	OPENBSD_2_2_BASE:1.4
	OPENBSD_2_1:1.4.0.2
	OPENBSD_2_1_BASE:1.4
	OPENBSD_2_0:1.3.0.2
	OPENBSD_2_0_BASE:1.3
	netbsd_1_1:1.1.1.1;
locks; strict;
comment	@ * @;


1.40
date	2016.04.20.05.24.18;	author landry;	state Exp;
branches;
next	1.39;
commitid	ynPX4b0o4cxuPCh8;

1.39
date	2016.02.22.07.50.37;	author deraadt;	state Exp;
branches;
next	1.38;
commitid	rzSRqqQo0cmY40ve;

1.38
date	2016.02.22.07.13.47;	author landry;	state Exp;
branches;
next	1.37;
commitid	8qRMizYrW35Z3d9h;

1.37
date	2015.10.01.16.03.48;	author kettenis;	state Exp;
branches;
next	1.36;
commitid	XWF4k0c2g2s1Sgwf;

1.36
date	2015.02.15.21.34.33;	author miod;	state Exp;
branches;
next	1.35;
commitid	eahBabNpxnDWKzqJ;

1.35
date	2015.02.11.01.13.22;	author dlg;	state Exp;
branches;
next	1.34;
commitid	CEDdiZTkUWnRZPMs;

1.34
date	2015.02.09.22.35.06;	author miod;	state Exp;
branches;
next	1.33;
commitid	s2XX23mPOpJ68vOr;

1.33
date	2014.12.17.15.23.42;	author deraadt;	state Exp;
branches;
next	1.32;
commitid	m1QU4zfUVMSJqLJo;

1.32
date	2014.01.30.18.16.41;	author miod;	state Exp;
branches;
next	1.31;

1.31
date	2014.01.26.17.40.11;	author miod;	state Exp;
branches;
next	1.30;

1.30
date	2014.01.05.14.37.08;	author miod;	state Exp;
branches;
next	1.29;

1.29
date	2014.01.01.22.13.52;	author miod;	state Exp;
branches;
next	1.28;

1.28
date	2013.03.31.17.07.03;	author deraadt;	state Exp;
branches;
next	1.27;

1.27
date	2013.03.25.20.03.02;	author deraadt;	state Exp;
branches;
next	1.26;

1.26
date	2011.11.16.20.50.18;	author deraadt;	state Exp;
branches;
next	1.25;

1.25
date	2010.12.26.15.40.58;	author miod;	state Exp;
branches;
next	1.24;

1.24
date	2008.06.26.05.42.08;	author ray;	state Exp;
branches;
next	1.23;

1.23
date	2007.12.14.18.32.20;	author deraadt;	state Exp;
branches;
next	1.22;

1.22
date	2007.09.10.18.49.44;	author miod;	state Exp;
branches;
next	1.21;

1.21
date	2006.02.07.07.59.23;	author martin;	state Exp;
branches;
next	1.20;

1.20
date	2004.08.06.22.39.10;	author deraadt;	state Exp;
branches;
next	1.19;

1.19
date	2004.07.13.14.51.29;	author tedu;	state Exp;
branches;
next	1.18;

1.18
date	2004.06.13.21.49.12;	author niklas;	state Exp;
branches;
next	1.17;

1.17
date	2004.06.09.20.17.23;	author tedu;	state Exp;
branches;
next	1.16;

1.16
date	2004.05.20.09.20.41;	author kettenis;	state Exp;
branches;
next	1.15;

1.15
date	2003.10.18.20.14.42;	author jmc;	state Exp;
branches;
next	1.14;

1.14
date	2003.06.02.23.27.43;	author millert;	state Exp;
branches;
next	1.13;

1.13
date	2002.09.12.12.50.47;	author art;	state Exp;
branches;
next	1.12;

1.12
date	2002.07.24.00.33.50;	author art;	state Exp;
branches;
next	1.11;

1.11
date	2001.12.05.00.11.51;	author millert;	state Exp;
branches
	1.11.2.1;
next	1.10;

1.10
date	2001.11.28.15.34.16;	author art;	state Exp;
branches;
next	1.9;

1.9
date	2001.08.18.20.50.18;	author art;	state Exp;
branches;
next	1.8;

1.8
date	2001.03.16.14.10.23;	author art;	state Exp;
branches;
next	1.7;

1.7
date	2001.03.16.09.06.02;	author art;	state Exp;
branches;
next	1.6;

1.6
date	2000.11.08.21.27.21;	author ericj;	state Exp;
branches;
next	1.5;

1.5
date	2000.11.08.16.01.12;	author art;	state Exp;
branches;
next	1.4;

1.4
date	96.10.30.22.39.16;	author niklas;	state Exp;
branches
	1.4.14.1;
next	1.3;

1.3
date	96.07.29.22.59.01;	author niklas;	state Exp;
branches;
next	1.2;

1.2
date	95.12.14.03.53.09;	author deraadt;	state Exp;
branches;
next	1.1;

1.1
date	95.10.18.08.49.43;	author deraadt;	state Exp;
branches
	1.1.1.1;
next	;

1.1.1.1
date	95.10.18.08.49.43;	author deraadt;	state Exp;
branches;
next	;

1.4.14.1
date	2001.04.18.16.00.56;	author niklas;	state Exp;
branches;
next	1.4.14.2;

1.4.14.2
date	2001.10.31.02.52.44;	author nate;	state Exp;
branches;
next	1.4.14.3;

1.4.14.3
date	2001.12.05.00.39.08;	author niklas;	state Exp;
branches;
next	1.4.14.4;

1.4.14.4
date	2002.03.06.00.47.44;	author niklas;	state Exp;
branches;
next	1.4.14.5;

1.4.14.5
date	2002.03.12.11.54.17;	author ho;	state Exp;
branches;
next	1.4.14.6;

1.4.14.6
date	2003.03.27.23.18.06;	author niklas;	state Exp;
branches;
next	1.4.14.7;

1.4.14.7
date	2003.06.07.11.11.33;	author ho;	state Exp;
branches;
next	1.4.14.8;

1.4.14.8
date	2004.02.19.09.59.34;	author niklas;	state Exp;
branches;
next	1.4.14.9;

1.4.14.9
date	2004.06.05.23.10.43;	author niklas;	state Exp;
branches;
next	1.4.14.10;

1.4.14.10
date	2004.06.10.11.40.20;	author niklas;	state Exp;
branches;
next	;

1.11.2.1
date	2002.10.29.00.28.00;	author art;	state Exp;
branches;
next	;


desc
@@


1.40
log
@Move back #include <sys/mutex.h> outside #ifdef _KERNEL as it was
originally intended in r1.38. (ie more or less revert r1.39)

(re-)Fixes at least net/net-snmp, sysutils/gkrellm/gkrellm,-client,
sysutils/xuvmstat and sysutils/bubblemon-dockapp on alpha.

From miod@@
@
text
@/* $OpenBSD: pmap.h,v 1.39 2016/02/22 07:50:37 deraadt Exp $ */
/* $NetBSD: pmap.h,v 1.37 2000/11/19 03:16:35 thorpej Exp $ */

/*-
 * Copyright (c) 1998, 1999, 2000 The NetBSD Foundation, Inc.
 * All rights reserved.
 *
 * This code is derived from software contributed to The NetBSD Foundation
 * by Jason R. Thorpe of the Numerical Aerospace Simulation Facility,
 * NASA Ames Research Center and by Chris G. Demetriou.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 *
 * THIS SOFTWARE IS PROVIDED BY THE NETBSD FOUNDATION, INC. AND CONTRIBUTORS
 * ``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED
 * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE FOUNDATION OR CONTRIBUTORS
 * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
 * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
 * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
 * POSSIBILITY OF SUCH DAMAGE.
 */

/* 
 * Copyright (c) 1987 Carnegie-Mellon University
 * Copyright (c) 1991, 1993
 *	The Regents of the University of California.  All rights reserved.
 *
 * This code is derived from software contributed to Berkeley by
 * the Systems Programming Group of the University of Utah Computer
 * Science Department.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. Neither the name of the University nor the names of its contributors
 *    may be used to endorse or promote products derived from this software
 *    without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE
 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
 *
 *	@@(#)pmap.h	8.1 (Berkeley) 6/10/93
 */

#ifndef	_PMAP_MACHINE_
#define	_PMAP_MACHINE_

#include <sys/mutex.h>
#include <machine/pte.h>

#ifdef _KERNEL

#include <sys/queue.h>

/*
 * Machine-dependent virtual memory state.
 *
 * If we ever support processor numbers higher than 63, we'll have to
 * rethink the CPU mask.
 *
 * Note pm_asn and pm_asngen are arrays allocated in pmap_create().
 * Their size is based on the PCS count from the HWRPB, and indexed
 * by processor ID (from `whami').
 *
 * The kernel pmap is a special case; it gets statically-allocated
 * arrays which hold enough for ALPHA_MAXPROCS.
 */
struct pmap_asn_info {
	unsigned int		pma_asn;	/* address space number */
	unsigned long		pma_asngen;	/* ASN generation number */
};

struct pmap {
	TAILQ_ENTRY(pmap)	pm_list;	/* list of all pmaps */
	pt_entry_t		*pm_lev1map;	/* level 1 map */
	int			pm_count;	/* pmap reference count */
	struct mutex		pm_mtx;		/* lock on pmap */
	struct pmap_statistics	pm_stats;	/* pmap statistics */
	unsigned long		pm_cpus;	/* mask of CPUs using pmap */
	unsigned long		pm_needisync;	/* mask of CPUs needing isync */
	struct pmap_asn_info	pm_asni[1];	/* ASN information */
			/*	variable length		*/
};
typedef struct pmap	*pmap_t;

/*
 * Compute the sizeof of a pmap structure.  Subtract one because one
 * ASN info structure is already included in the pmap structure itself.
 */
#define PMAP_SIZEOF(x)							\
	(ALIGN(sizeof(struct pmap) +					\
	       (sizeof(struct pmap_asn_info) * ((x) - 1))))

#define	PMAP_ASN_RESERVED	0	/* reserved for Lev1map users */

extern struct pmap	kernel_pmap_store[];

#define pmap_kernel()	kernel_pmap_store

/*
 * For each vm_page_t, there is a list of all currently valid virtual
 * mappings of that page.  An entry is a pv_entry_t, the list is pv_table.
 */
typedef struct pv_entry {
	struct pv_entry *pv_next;	/* next pv_entry on list */
	struct pmap	*pv_pmap;	/* pmap where mapping lies */
	vaddr_t		pv_va;		/* virtual address for mapping */
	pt_entry_t	*pv_pte;	/* PTE that maps the VA */
} *pv_entry_t;

/* pvh_attrs */
#define	PGA_MODIFIED		0x01		/* modified */
#define	PGA_REFERENCED		0x02		/* referenced */

/* pvh_usage */
#define	PGU_NORMAL		0		/* free or normal use */
#define	PGU_PVENT		1		/* PV entries */
#define	PGU_L1PT		2		/* level 1 page table */
#define	PGU_L2PT		3		/* level 2 page table */
#define	PGU_L3PT		4		/* level 3 page table */

#define	PGU_ISPTPAGE(pgu)	((pgu) >= PGU_L1PT)

#if defined(NEW_SCC_DRIVER)
#if defined(DEC_KN8AE)
#define	_PMAP_MAY_USE_PROM_CONSOLE
#endif
#else /* ! NEW_SCC_DRIVER */
#if defined(DEC_3000_300)		\
 || defined(DEC_3000_500)		\
 || defined(DEC_KN8AE) 				/* XXX */
#define _PMAP_MAY_USE_PROM_CONSOLE		/* XXX */
#endif						/* XXX */
#endif /* NEW_SCC_DRIVER */

#if defined(MULTIPROCESSOR)
void	pmap_tlb_shootdown(pmap_t, vaddr_t, pt_entry_t, u_long *);
void	pmap_tlb_shootnow(u_long);
void	pmap_do_tlb_shootdown(struct cpu_info *, struct trapframe *);
#define	PMAP_TLB_SHOOTDOWN_CPUSET_DECL		u_long shootset = 0;
#define	PMAP_TLB_SHOOTDOWN(pm, va, pte)					\
	pmap_tlb_shootdown((pm), (va), (pte), &shootset)
#define	PMAP_TLB_SHOOTNOW()						\
	pmap_tlb_shootnow(shootset)
#else
#define	PMAP_TLB_SHOOTDOWN_CPUSET_DECL		/* nothing */
#define	PMAP_TLB_SHOOTDOWN(pm, va, pte)		/* nothing */
#define	PMAP_TLB_SHOOTNOW()			/* nothing */
#endif /* MULTIPROCESSOR */
 
#define	pmap_resident_count(pmap)	((pmap)->pm_stats.resident_count)
#define	pmap_wired_count(pmap)		((pmap)->pm_stats.wired_count)

#define pmap_copy(dp, sp, da, l, sa)	/* nothing */
#define pmap_update(pmap)		/* nothing (yet) */

#define pmap_proc_iflush(p, va, len)	/* nothing */
#define pmap_unuse_final(p)		/* nothing */
#define	pmap_remove_holes(vm)		do { /* nothing */ } while (0)

extern	pt_entry_t *VPT;		/* Virtual Page Table */

#define	PMAP_STEAL_MEMORY		/* enable pmap_steal_memory() */
#define PMAP_GROWKERNEL			/* enable pmap_growkernel() */

/*
 * Alternate mapping hooks for pool pages.  Avoids thrashing the TLB.
 */
#define	pmap_map_direct(pg)	ALPHA_PHYS_TO_K0SEG(VM_PAGE_TO_PHYS(pg))
#define	pmap_unmap_direct(va)	PHYS_TO_VM_PAGE(ALPHA_K0SEG_TO_PHYS((va)))
#define	__HAVE_PMAP_DIRECT

paddr_t vtophys(vaddr_t);

/* Machine-specific functions. */
void	pmap_bootstrap(paddr_t ptaddr, u_int maxasn, u_long ncpuids);
int	pmap_emulate_reference(struct proc *p, vaddr_t v, int user, int type);
#ifdef _PMAP_MAY_USE_PROM_CONSOLE
int	pmap_uses_prom_console(void);
#endif

#define	pmap_pte_pa(pte)	(PG_PFNUM(*(pte)) << PAGE_SHIFT)
#define	pmap_pte_prot(pte)	(*(pte) & PG_PROT)
#define	pmap_pte_w(pte)		(*(pte) & PG_WIRED)
#define	pmap_pte_v(pte)		(*(pte) & PG_V)
#define	pmap_pte_pv(pte)	(*(pte) & PG_PVLIST)
#define	pmap_pte_asm(pte)	(*(pte) & PG_ASM)
#define	pmap_pte_exec(pte)	(*(pte) & PG_EXEC)

#define	pmap_pte_set_w(pte, v)						\
do {									\
	if (v)								\
		*(pte) |= PG_WIRED;					\
	else								\
		*(pte) &= ~PG_WIRED;					\
} while (0)

#define	pmap_pte_w_chg(pte, nw)	((nw) ^ pmap_pte_w(pte))

#define	pmap_pte_set_prot(pte, np)					\
do {									\
	*(pte) &= ~PG_PROT;						\
	*(pte) |= (np);							\
} while (0)

#define	pmap_pte_prot_chg(pte, np) ((np) ^ pmap_pte_prot(pte))

static __inline pt_entry_t *pmap_l2pte(pmap_t, vaddr_t, pt_entry_t *);
static __inline pt_entry_t *pmap_l3pte(pmap_t, vaddr_t, pt_entry_t *);

#define	pmap_l1pte(pmap, v)						\
	(&(pmap)->pm_lev1map[l1pte_index((vaddr_t)(v))])

static __inline pt_entry_t *
pmap_l2pte(pmap, v, l1pte)
	pmap_t pmap;
	vaddr_t v;
	pt_entry_t *l1pte;
{
	pt_entry_t *lev2map;

	if (l1pte == NULL) {
		l1pte = pmap_l1pte(pmap, v);
		if (pmap_pte_v(l1pte) == 0)
			return (NULL);
	}

	lev2map = (pt_entry_t *)ALPHA_PHYS_TO_K0SEG(pmap_pte_pa(l1pte));
	return (&lev2map[l2pte_index(v)]);
}

static __inline pt_entry_t *
pmap_l3pte(pmap, v, l2pte)
	pmap_t pmap;
	vaddr_t v;
	pt_entry_t *l2pte;
{
	pt_entry_t *l1pte, *lev2map, *lev3map;

	if (l2pte == NULL) {
		l1pte = pmap_l1pte(pmap, v);
		if (pmap_pte_v(l1pte) == 0)
			return (NULL);

		lev2map = (pt_entry_t *)ALPHA_PHYS_TO_K0SEG(pmap_pte_pa(l1pte));
		l2pte = &lev2map[l2pte_index(v)];
		if (pmap_pte_v(l2pte) == 0)
			return (NULL);
	}

	lev3map = (pt_entry_t *)ALPHA_PHYS_TO_K0SEG(pmap_pte_pa(l2pte));
	return (&lev3map[l3pte_index(v)]);
}

/*
 * Macro for processing deferred I-stream synchronization.
 *
 * The pmap module may defer syncing the user I-stream until the
 * return to userspace, since the IMB PALcode op can be quite
 * expensive.  Since user instructions won't be executed until the
 * return to userspace, this can be deferred until just before userret().
 */
#define	PMAP_USERRET(pmap)						\
do {									\
	u_long cpu_mask = (1UL << cpu_number());			\
									\
	if ((pmap)->pm_needisync & cpu_mask) {				\
		atomic_clearbits_ulong(&(pmap)->pm_needisync,		\
		    cpu_mask);						\
		alpha_pal_imb();					\
	}								\
} while (0)

#endif /* _KERNEL */

/*
 * pmap-specific data stored in the vm_page structure.
 */
struct vm_page_md {
	struct mutex pvh_mtx;
	struct pv_entry *pvh_list;	/* pv entry list */
	int pvh_attrs;			/* page attributes */
};

#define	VM_MDPAGE_INIT(pg)						\
do {									\
	mtx_init(&(pg)->mdpage.pvh_mtx, IPL_VM);			\
	(pg)->mdpage.pvh_list = NULL;					\
	(pg)->mdpage.pvh_attrs = 0;					\
} while (0)

#endif /* _PMAP_MACHINE_ */
@


1.39
log
@put mutex.h lower
@
text
@d1 1
a1 1
/* $OpenBSD: pmap.h,v 1.38 2016/02/22 07:13:47 landry Exp $ */
d73 1
a78 1
#include <sys/mutex.h>
@


1.38
log
@Move #include <sys/mutex.h> from pmap.c to pmap.h, like every other archs
using struct mutex in pmap.h do. Fixes net-snmp on alpha.
ok deraadt@@
@
text
@d1 1
a1 1
/* $OpenBSD: pmap.h,v 1.37 2015/10/01 16:03:48 kettenis Exp $ */
a73 1
#include <sys/mutex.h>
d78 1
@


1.37
log
@Make the alpha pmap (more) mpsafe by protecting both the pmap itself and the
pv lists with a mutex.  This should make pmap_enter(9), pmap_remove(9) and
pmap_page_protect(9) safe to use without holding the kernel lock.  This
largely reverts rev. 1.75, but now of course the pmap locks are defined
to actually call mtx_enter(9) and mtx_leave(9).

ok visa@@
@
text
@d1 1
a1 1
/* $OpenBSD: pmap.h,v 1.36 2015/02/15 21:34:33 miod Exp $ */
d74 1
@


1.36
log
@Change pmap_remove_holes() to take a vmspace instead of a map as its argument.

Use this on vax to correctly pick the end of the stack area now that the
stackgap adjustment code will no longer guarantee it is a fixed location.
@
text
@d1 1
a1 1
/* $OpenBSD: pmap.h,v 1.35 2015/02/11 01:13:22 dlg Exp $ */
d101 1
d304 1
d311 1
@


1.35
log
@alpha (nor any other arch) uses any types or api provided by sys/lock.h.
@
text
@d1 1
a1 1
/* $OpenBSD: pmap.h,v 1.34 2015/02/09 22:35:06 miod Exp $ */
d182 1
a182 1
#define	pmap_remove_holes(map)		do { /* nothing */ } while (0)
@


1.34
log
@_LKM leftovers
@
text
@d1 1
a1 1
/* $OpenBSD: pmap.h,v 1.33 2014/12/17 15:23:42 deraadt Exp $ */
a76 1
#include <sys/lock.h>
@


1.33
log
@remove simplelocks
ok tedu
@
text
@d1 1
a1 1
/* $OpenBSD: pmap.h,v 1.32 2014/01/30 18:16:41 miod Exp $ */
a147 1
#ifndef _LKM
a173 1
#endif /* _LKM */
@


1.32
log
@Move declaration of struct vm_page_md from <machine/vmparam.h> to
<machine/pmap.h> where it belongs, and compensate in <uvm/uvm_extern.h>
by including <uvm/uvm_pmap.h> before <uvm/uvm_page.h>. Tested on all
MACHINE_ARCH but amd64 and i386 (and hppa64).
@
text
@d1 1
a1 1
/* $OpenBSD: pmap.h,v 1.31 2014/01/26 17:40:11 miod Exp $ */
a101 1
	struct simplelock	pm_slock;	/* lock on pmap */
a279 11

/*
 * Macros for locking pmap structures.
 *
 * Note that we if we access the kernel pmap in interrupt context, it
 * is only to update statistics.  Since stats are updated using atomic
 * operations, locking the kernel pmap is not necessary.  Therefore,
 * it is not necessary to block interrupts when locking pmap structures.
 */
#define	PMAP_LOCK(pmap)		simple_lock(&(pmap)->pm_slock)
#define	PMAP_UNLOCK(pmap)	simple_unlock(&(pmap)->pm_slock)
@


1.31
log
@Work in progress work towards SMP, heavily based upon NetBSD. The MP kernel
will boot multiuser, but will deadlock under load, and I can't find my
mistake yet.
@
text
@d1 1
a1 1
/* $OpenBSD: pmap.h,v 1.30 2014/01/05 14:37:08 miod Exp $ */
d313 14
@


1.30
log
@Cleanup some leftovers from previous changes.
@
text
@d1 1
a1 1
/* $OpenBSD: pmap.h,v 1.29 2014/01/01 22:13:52 miod Exp $ */
d93 5
a103 4
	long			pm_nlev2;	/* level 2 pt page count */
	long			pm_nlev3;	/* level 3 pt page count */
	unsigned int		*pm_asn;	/* address space number */
	unsigned long		*pm_asngen;	/* ASN generation number */
d106 2
d109 1
d111 7
a117 1
typedef struct pmap	*pmap_t;
d121 1
a121 1
extern struct pmap	kernel_pmap_store;
d123 1
a123 1
#define pmap_kernel()	(&kernel_pmap_store)
d163 2
a164 1
void	pmap_tlb_shootdown(pmap_t, vaddr_t, pt_entry_t);
d166 1
a166 1
void	pmap_tlb_shootdown_q_drain(u_long, boolean_t);
d168 3
a170 1
	pmap_tlb_shootdown((pm), (va), (pte))
d172 1
d174 1
d180 2
@


1.29
log
@Switch alpha to __HAVE_VM_PAGE_MD. From NetBSD.
@
text
@d1 1
a1 1
/* $OpenBSD: pmap.h,v 1.28 2013/03/31 17:07:03 deraadt Exp $ */
a137 9

#define	PGU_STRINGS							\
{									\
	"normal",							\
	"pvent",							\
	"l1pt",								\
	"l2pt",								\
	"l3pt",								\
}
@


1.28
log
@try to avoid pulling in pte.h and other more crazy things.  Checked against
the things that libkvm needs.
@
text
@d1 1
a1 1
/* $OpenBSD: pmap.h,v 1.27 2013/03/25 20:03:02 deraadt Exp $ */
d120 1
a120 1
	LIST_ENTRY(pv_entry) pv_list;	/* pv_entry list */
a124 11

/*
 * The head of the list of pv_entry_t's, also contains page attributes.
 */
struct pv_head {
	LIST_HEAD(, pv_entry) pvh_list;		/* pv_entry list */
	struct simplelock pvh_slock;		/* lock on this head */
	int pvh_attrs;				/* page attributes */
	int pvh_usage;				/* page usage */
	int pvh_refcnt;				/* special use ref count */
};
@


1.27
log
@PGSHIFT -> PAGE_SHIFT
@
text
@d1 1
a1 1
/* $OpenBSD: pmap.h,v 1.26 2011/11/16 20:50:18 deraadt Exp $ */
a72 3
#include <sys/lock.h>
#include <sys/queue.h>

d76 3
@


1.26
log
@Make userret() MI.  On architectures which jammed stuff into it in the
past, pull that code out seperately.
ok guenther miod
@
text
@d1 1
a1 1
/* $OpenBSD: pmap.h,v 1.25 2010/12/26 15:40:58 miod Exp $ */
d212 1
a212 1
#define	pmap_pte_pa(pte)	(PG_PFNUM(*(pte)) << PGSHIFT)
@


1.25
log
@Kill pmap_phys_address(), and force every driver's mmap() routine to return
a physical address [more precisely, something suitable to pass to pmap_enter()'sphysical address argument].

This allows MI drivers to implement mmap() routines without having to know
about the pmap_phys_address() implementation and #ifdef obfuscation.
@
text
@d1 1
a1 1
/* $OpenBSD: pmap.h,v 1.24 2008/06/26 05:42:08 ray Exp $ */
d301 2
a302 2
 * expensive.  Since user instructions won't be executed until
 * the return to userspace, this can be deferred until userret().
@


1.24
log
@First pass at removing clauses 3 and 4 from NetBSD licenses.

Not sure what's more surprising: how long it took for NetBSD to
catch up to the rest of the BSDs (including UCB), or the amount of
code that NetBSD has claimed for itself without attributing to the
actual authors.

OK deraadt@@
@
text
@d1 1
a1 1
/* $OpenBSD: pmap.h,v 1.23 2007/12/14 18:32:20 deraadt Exp $ */
a185 1
#define pmap_phys_address(ppn)		ptoa(ppn)
@


1.23
log
@Remove a lot of symbols from the namespace, otherwise sys/sysctl.h and
rpc/pmap_prot.h collide.. "struct pmap" from the kernel should not make
it out to userland.
@
text
@d1 1
a1 1
/* $OpenBSD: pmap.h,v 1.22 2007/09/10 18:49:44 miod Exp $ */
a19 7
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *	This product includes software developed by the NetBSD
 *	Foundation, Inc. and its contributors.
 * 4. Neither the name of The NetBSD Foundation nor the names of its
 *    contributors may be used to endorse or promote products derived
 *    from this software without specific prior written permission.
@


1.22
log
@Introduce a md pmap hook, pmap_remove_holes(), which is supposed to mark
the holes a MMU may have from a given vm_map. This will be automagically
invoked for newly created vmspaces.

On platforms with MMU holes (e.g. sun4, sun4c and vax), this prevents
mmap(2) hints which would end up being in the hole to be accepted as valid,
causing unexpected signals when the process tries to access the hole
(since pmap can not fill the hole anyway).

Unfortunately, the logic mmap() uses to pick a valid address for anonymous
mappings needs work, as it will only try to find an address higher than the
hint, which causes all mmap() with a hint in the hole to fail on vax. This
will be improved later.
@
text
@d1 1
a1 1
/* $OpenBSD: pmap.h,v 1.21 2006/02/07 07:59:23 martin Exp $ */
d85 2
a164 2

#ifdef _KERNEL
@


1.21
log
@convert pmap_phys_address() to a define, consistent with other archs;
avoids losing information due to int in proto ...

thanks to KUDO Takashi for tracking this down

ok miod@@
@
text
@d1 1
a1 1
/* $OpenBSD: pmap.h,v 1.20 2004/08/06 22:39:10 deraadt Exp $ */
d197 1
@


1.20
log
@rename sparc kill_user_windows() to pmap_unuse_final().  provide empty stubs
on all other architectures.  remove last architecture dependent #ifdef from
uvm code.
@
text
@d1 1
a1 1
/* $OpenBSD: pmap.h,v 1.19 2004/07/13 14:51:29 tedu Exp $ */
d193 1
@


1.19
log
@#define __HAVE_PMAP_DIRECT and use it.  requested by art
@
text
@d1 1
a1 1
/* $OpenBSD: pmap.h,v 1.18 2004/06/13 21:49:12 niklas Exp $ */
d195 1
@


1.18
log
@debranch SMP, have fun
@
text
@d1 1
a1 1
/* $OpenBSD$ */
d206 1
@


1.17
log
@rename POOLPAGE macros to pmap_map_direct
break out uvm_km_page bits for this case, no thread here
lots of testing tech@@, deraadt@@, naddy@@, mickey@@, ...
@
text
@d1 1
a1 1
/* $OpenBSD: pmap.h,v 1.16 2004/05/20 09:20:41 kettenis Exp $ */
d181 1
a181 1
void	pmap_do_tlb_shootdown(void);
@


1.16
log
@Properly flush instruction cache for ptrace(PT_WRTIE_{DI}, ...) on powerpc
and m68k.
ok drahn@@, millert@@
@
text
@d1 1
a1 1
/* $OpenBSD: pmap.h,v 1.15 2003/10/18 20:14:42 jmc Exp $ */
d204 2
a205 2
#define	PMAP_MAP_POOLPAGE(pg)	ALPHA_PHYS_TO_K0SEG(VM_PAGE_TO_PHYS(pg))
#define	PMAP_UNMAP_POOLPAGE(va)	PHYS_TO_VM_PAGE(ALPHA_K0SEG_TO_PHYS((va)))
@


1.15
log
@typos from Jared Yanovich;
@
text
@d1 1
a1 1
/* $OpenBSD: pmap.h,v 1.14 2003/06/02 23:27:43 millert Exp $ */
d193 2
@


1.14
log
@Remove the advertising clause in the UCB license which Berkeley
rescinded 22 July 1999.  Proofed by myself and Theo.
@
text
@d1 1
a1 1
/* $OpenBSD: pmap.h,v 1.13 2002/09/12 12:50:47 art Exp $ */
d293 1
a293 1
 * it is not necessary to block interrupts when locking pmap strucutres.
@


1.13
log
@Change the PMAP_{MAP,UNMAP}_POOLPAGE api to take a vm_page as argument
and return a VM_PAGE. This is to allow sparc64 to cheaply record the
VAC color for those pages.
@
text
@d1 1
a1 1
/* $OpenBSD: pmap.h,v 1.12 2002/07/24 00:33:50 art Exp $ */
d58 1
a58 5
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *	This product includes software developed by the University of
 *	California, Berkeley and its contributors.
 * 4. Neither the name of the University nor the names of its contributors
@


1.12
log
@Pretty nasty hack to make non-exec mappings work.
Instead of using FOE for just emulating references, we also keep track
of a pages executability and don't remove the FOE bit if the page
is not executable.

This is implmented with horrible hacks. Maybe when I have time, I'll
reimplment the whole pmap to allow this without ugly hacks (read: probably
not this decade).

The stack on alpha is now non-exec.
@
text
@d1 1
a1 1
/* $OpenBSD: pmap.h,v 1.11 2001/12/05 00:11:51 millert Exp $ */
d206 2
a207 2
#define	PMAP_MAP_POOLPAGE(pa)		ALPHA_PHYS_TO_K0SEG((pa))
#define	PMAP_UNMAP_POOLPAGE(va)		ALPHA_K0SEG_TO_PHYS((va))
@


1.11
log
@Update pmap_update macro for arches Art missed.  Still just a noop.
@
text
@d1 1
a1 1
/* $OpenBSD: pmap.h,v 1.10 2001/11/28 15:34:16 art Exp $ */
d213 1
a213 2
void	pmap_emulate_reference(struct proc *p, vaddr_t v,
		int user, int write);
@


1.11.2.1
log
@sync to -current
@
text
@d1 1
a1 1
/* $OpenBSD: pmap.h,v 1.11 2001/12/05 00:11:51 millert Exp $ */
d206 2
a207 2
#define	PMAP_MAP_POOLPAGE(pg)	ALPHA_PHYS_TO_K0SEG(VM_PAGE_TO_PHYS(pg))
#define	PMAP_UNMAP_POOLPAGE(va)	PHYS_TO_VM_PAGE(ALPHA_K0SEG_TO_PHYS((va)))
d213 2
a214 1
int	pmap_emulate_reference(struct proc *p, vaddr_t v, int user, int type);
@


1.10
log
@Make pmap_update functions into nops so that we can have a consistent
pmap_update API (right now it's nop).
@
text
@d1 1
a1 1
/* $OpenBSD: pmap.h,v 1.9 2001/08/18 20:50:18 art Exp $ */
d196 1
a196 1
#define pmap_update()			/* nothing */
@


1.9
log
@Move pmap_{de,}activate to vm/pmap.h, it's same on all archs.
@
text
@d1 1
a1 1
/* $OpenBSD: pmap.h,v 1.8 2001/03/16 14:10:23 art Exp $ */
d196 1
@


1.8
log
@Some more pmap improvements from NetBSD.
@
text
@d1 1
a1 1
/* $OpenBSD: pmap.h,v 1.7 2001/03/16 09:06:02 art Exp $ */
a216 2
void	pmap_activate(struct proc *);
void	pmap_deactivate(struct proc *);
@


1.7
log
@Implement pmap_growkernel. From NetBSD.
@
text
@d1 2
a2 2
/* $OpenBSD: pmap.h,v 1.6 2000/11/08 21:27:21 ericj Exp $ */
/* $NetBSD: pmap.h,v 1.35 2000/06/08 03:10:06 thorpej Exp $ */
d186 5
@


1.6
log
@tag the rest of alpha tree
@
text
@d1 1
a1 1
/* $OpenBSD: pmap.h,v 1.35 2000/06/08 03:10:06 thorpej Exp $ */
d195 1
@


1.5
log
@Merge in big portions of the improvements NetBSD did to their alpha port.
Highlights: UVM, PMAP_NEW, bus_dma (only on some buses for now), new hardware
support, possiblity for ELF, etc, etc. Too much to mention.

This is still work in progress. video consoles might be broken, otherwise
we have basically the same functionality as before plus more.
@
text
@d1 1
@


1.4
log
@Merge to NetBSD 961020.  Retained our kernel APIs where NetBSD has changed.
-Wall -Wstrict-prototypes -Wmissing-prototypes too.
@
text
@d1 1
a1 2
/*	$OpenBSD: pmap.h,v 1.9 1996/08/20 23:02:30 cgd Exp $	*/
/*	$NetBSD: pmap.h,v 1.9 1996/08/20 23:02:30 cgd Exp $	*/
d3 170
a172 4
#ifndef NEW_PMAP
#include <machine/pmap.old.h>
#else
#include <machine/pmap.new.h>
d174 143
d318 1
a318 1
void pmap_unmap_prom __P((void));
@


1.4.14.1
log
@Update the SMP branch to -current, this breaks the SMP branch though.
But it will be fixed soonish.  Note, nothing new has happened, this is just
a merge of the trunk into this branch.
@
text
@d1 2
a2 2
/* $OpenBSD: pmap.h,v 1.8 2001/03/16 14:10:23 art Exp $ */
/* $NetBSD: pmap.h,v 1.37 2000/11/19 03:16:35 thorpej Exp $ */
d4 2
a5 185
/*-
 * Copyright (c) 1998, 1999, 2000 The NetBSD Foundation, Inc.
 * All rights reserved.
 *
 * This code is derived from software contributed to The NetBSD Foundation
 * by Jason R. Thorpe of the Numerical Aerospace Simulation Facility,
 * NASA Ames Research Center and by Chris G. Demetriou.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *	This product includes software developed by the NetBSD
 *	Foundation, Inc. and its contributors.
 * 4. Neither the name of The NetBSD Foundation nor the names of its
 *    contributors may be used to endorse or promote products derived
 *    from this software without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE NETBSD FOUNDATION, INC. AND CONTRIBUTORS
 * ``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED
 * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE FOUNDATION OR CONTRIBUTORS
 * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
 * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
 * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
 * POSSIBILITY OF SUCH DAMAGE.
 */

/* 
 * Copyright (c) 1987 Carnegie-Mellon University
 * Copyright (c) 1991, 1993
 *	The Regents of the University of California.  All rights reserved.
 *
 * This code is derived from software contributed to Berkeley by
 * the Systems Programming Group of the University of Utah Computer
 * Science Department.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *	This product includes software developed by the University of
 *	California, Berkeley and its contributors.
 * 4. Neither the name of the University nor the names of its contributors
 *    may be used to endorse or promote products derived from this software
 *    without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE
 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
 *
 *	@@(#)pmap.h	8.1 (Berkeley) 6/10/93
 */

#ifndef	_PMAP_MACHINE_
#define	_PMAP_MACHINE_

#include <sys/lock.h>
#include <sys/queue.h>

#include <machine/pte.h>

/*
 * Machine-dependent virtual memory state.
 *
 * If we ever support processor numbers higher than 63, we'll have to
 * rethink the CPU mask.
 *
 * Note pm_asn and pm_asngen are arrays allocated in pmap_create().
 * Their size is based on the PCS count from the HWRPB, and indexed
 * by processor ID (from `whami').
 *
 * The kernel pmap is a special case; it gets statically-allocated
 * arrays which hold enough for ALPHA_MAXPROCS.
 */
struct pmap {
	TAILQ_ENTRY(pmap)	pm_list;	/* list of all pmaps */
	pt_entry_t		*pm_lev1map;	/* level 1 map */
	int			pm_count;	/* pmap reference count */
	struct simplelock	pm_slock;	/* lock on pmap */
	struct pmap_statistics	pm_stats;	/* pmap statistics */
	long			pm_nlev2;	/* level 2 pt page count */
	long			pm_nlev3;	/* level 3 pt page count */
	unsigned int		*pm_asn;	/* address space number */
	unsigned long		*pm_asngen;	/* ASN generation number */
	unsigned long		pm_cpus;	/* mask of CPUs using pmap */
	unsigned long		pm_needisync;	/* mask of CPUs needing isync */
};

typedef struct pmap	*pmap_t;

#define	PMAP_ASN_RESERVED	0	/* reserved for Lev1map users */

extern struct pmap	kernel_pmap_store;

#define pmap_kernel()	(&kernel_pmap_store)

/*
 * For each vm_page_t, there is a list of all currently valid virtual
 * mappings of that page.  An entry is a pv_entry_t, the list is pv_table.
 */
typedef struct pv_entry {
	LIST_ENTRY(pv_entry) pv_list;	/* pv_entry list */
	struct pmap	*pv_pmap;	/* pmap where mapping lies */
	vaddr_t		pv_va;		/* virtual address for mapping */
	pt_entry_t	*pv_pte;	/* PTE that maps the VA */
} *pv_entry_t;

/*
 * The head of the list of pv_entry_t's, also contains page attributes.
 */
struct pv_head {
	LIST_HEAD(, pv_entry) pvh_list;		/* pv_entry list */
	struct simplelock pvh_slock;		/* lock on this head */
	int pvh_attrs;				/* page attributes */
	int pvh_usage;				/* page usage */
	int pvh_refcnt;				/* special use ref count */
};

/* pvh_attrs */
#define	PGA_MODIFIED		0x01		/* modified */
#define	PGA_REFERENCED		0x02		/* referenced */

/* pvh_usage */
#define	PGU_NORMAL		0		/* free or normal use */
#define	PGU_PVENT		1		/* PV entries */
#define	PGU_L1PT		2		/* level 1 page table */
#define	PGU_L2PT		3		/* level 2 page table */
#define	PGU_L3PT		4		/* level 3 page table */

#define	PGU_ISPTPAGE(pgu)	((pgu) >= PGU_L1PT)

#define	PGU_STRINGS							\
{									\
	"normal",							\
	"pvent",							\
	"l1pt",								\
	"l2pt",								\
	"l3pt",								\
}

#ifdef _KERNEL

#ifndef _LKM
#if defined(NEW_SCC_DRIVER)
#if defined(DEC_KN8AE)
#define	_PMAP_MAY_USE_PROM_CONSOLE
#endif
#else /* ! NEW_SCC_DRIVER */
#if defined(DEC_3000_300)		\
 || defined(DEC_3000_500)		\
 || defined(DEC_KN8AE) 				/* XXX */
#define _PMAP_MAY_USE_PROM_CONSOLE		/* XXX */
#endif						/* XXX */
#endif /* NEW_SCC_DRIVER */

#if defined(MULTIPROCESSOR)
void	pmap_tlb_shootdown(pmap_t, vaddr_t, pt_entry_t);
void	pmap_do_tlb_shootdown(void);
void	pmap_tlb_shootdown_q_drain(u_long, boolean_t);
#define	PMAP_TLB_SHOOTDOWN(pm, va, pte)					\
	pmap_tlb_shootdown((pm), (va), (pte))
d7 1
a7 26
#define	PMAP_TLB_SHOOTDOWN(pm, va, pte)		/* nothing */
#endif /* MULTIPROCESSOR */
#endif /* _LKM */
 
#define	pmap_resident_count(pmap)	((pmap)->pm_stats.resident_count)
#define	pmap_wired_count(pmap)		((pmap)->pm_stats.wired_count)

extern	pt_entry_t *VPT;		/* Virtual Page Table */

#define	PMAP_STEAL_MEMORY		/* enable pmap_steal_memory() */
#define PMAP_GROWKERNEL			/* enable pmap_growkernel() */

/*
 * Alternate mapping hooks for pool pages.  Avoids thrashing the TLB.
 */
#define	PMAP_MAP_POOLPAGE(pa)		ALPHA_PHYS_TO_K0SEG((pa))
#define	PMAP_UNMAP_POOLPAGE(va)		ALPHA_K0SEG_TO_PHYS((va))

paddr_t vtophys(vaddr_t);

/* Machine-specific functions. */
void	pmap_bootstrap(paddr_t ptaddr, u_int maxasn, u_long ncpuids);
void	pmap_emulate_reference(struct proc *p, vaddr_t v,
		int user, int write);
#ifdef _PMAP_MAY_USE_PROM_CONSOLE
int	pmap_uses_prom_console(void);
a8 107
void	pmap_activate(struct proc *);
void	pmap_deactivate(struct proc *);

#define	pmap_pte_pa(pte)	(PG_PFNUM(*(pte)) << PGSHIFT)
#define	pmap_pte_prot(pte)	(*(pte) & PG_PROT)
#define	pmap_pte_w(pte)		(*(pte) & PG_WIRED)
#define	pmap_pte_v(pte)		(*(pte) & PG_V)
#define	pmap_pte_pv(pte)	(*(pte) & PG_PVLIST)
#define	pmap_pte_asm(pte)	(*(pte) & PG_ASM)
#define	pmap_pte_exec(pte)	(*(pte) & PG_EXEC)

#define	pmap_pte_set_w(pte, v)						\
do {									\
	if (v)								\
		*(pte) |= PG_WIRED;					\
	else								\
		*(pte) &= ~PG_WIRED;					\
} while (0)

#define	pmap_pte_w_chg(pte, nw)	((nw) ^ pmap_pte_w(pte))

#define	pmap_pte_set_prot(pte, np)					\
do {									\
	*(pte) &= ~PG_PROT;						\
	*(pte) |= (np);							\
} while (0)

#define	pmap_pte_prot_chg(pte, np) ((np) ^ pmap_pte_prot(pte))

static __inline pt_entry_t *pmap_l2pte(pmap_t, vaddr_t, pt_entry_t *);
static __inline pt_entry_t *pmap_l3pte(pmap_t, vaddr_t, pt_entry_t *);

#define	pmap_l1pte(pmap, v)						\
	(&(pmap)->pm_lev1map[l1pte_index((vaddr_t)(v))])

static __inline pt_entry_t *
pmap_l2pte(pmap, v, l1pte)
	pmap_t pmap;
	vaddr_t v;
	pt_entry_t *l1pte;
{
	pt_entry_t *lev2map;

	if (l1pte == NULL) {
		l1pte = pmap_l1pte(pmap, v);
		if (pmap_pte_v(l1pte) == 0)
			return (NULL);
	}

	lev2map = (pt_entry_t *)ALPHA_PHYS_TO_K0SEG(pmap_pte_pa(l1pte));
	return (&lev2map[l2pte_index(v)]);
}

static __inline pt_entry_t *
pmap_l3pte(pmap, v, l2pte)
	pmap_t pmap;
	vaddr_t v;
	pt_entry_t *l2pte;
{
	pt_entry_t *l1pte, *lev2map, *lev3map;

	if (l2pte == NULL) {
		l1pte = pmap_l1pte(pmap, v);
		if (pmap_pte_v(l1pte) == 0)
			return (NULL);

		lev2map = (pt_entry_t *)ALPHA_PHYS_TO_K0SEG(pmap_pte_pa(l1pte));
		l2pte = &lev2map[l2pte_index(v)];
		if (pmap_pte_v(l2pte) == 0)
			return (NULL);
	}

	lev3map = (pt_entry_t *)ALPHA_PHYS_TO_K0SEG(pmap_pte_pa(l2pte));
	return (&lev3map[l3pte_index(v)]);
}

/*
 * Macros for locking pmap structures.
 *
 * Note that we if we access the kernel pmap in interrupt context, it
 * is only to update statistics.  Since stats are updated using atomic
 * operations, locking the kernel pmap is not necessary.  Therefore,
 * it is not necessary to block interrupts when locking pmap strucutres.
 */
#define	PMAP_LOCK(pmap)		simple_lock(&(pmap)->pm_slock)
#define	PMAP_UNLOCK(pmap)	simple_unlock(&(pmap)->pm_slock)

/*
 * Macro for processing deferred I-stream synchronization.
 *
 * The pmap module may defer syncing the user I-stream until the
 * return to userspace, since the IMB PALcode op can be quite
 * expensive.  Since user instructions won't be executed until
 * the return to userspace, this can be deferred until userret().
 */
#define	PMAP_USERRET(pmap)						\
do {									\
	u_long cpu_mask = (1UL << cpu_number());			\
									\
	if ((pmap)->pm_needisync & cpu_mask) {				\
		atomic_clearbits_ulong(&(pmap)->pm_needisync,		\
		    cpu_mask);						\
		alpha_pal_imb();					\
	}								\
} while (0)

#endif /* _KERNEL */
d10 1
a10 1
#endif /* _PMAP_MACHINE_ */
@


1.4.14.2
log
@Sync the SMP branch to something just after 3.0
@
text
@d1 1
a1 1
/* $OpenBSD: pmap.h,v 1.4.14.1 2001/04/18 16:00:56 niklas Exp $ */
d217 2
@


1.4.14.3
log
@Merge in -current
@
text
@d1 1
a1 1
/* $OpenBSD: pmap.h,v 1.4.14.2 2001/10/31 02:52:44 nate Exp $ */
a195 1
#define pmap_update()			/* nothing */
@


1.4.14.4
log
@Merge in trunk
@
text
@d1 1
a1 1
/* $OpenBSD$ */
d196 1
a196 1
#define pmap_update(pmap)		/* nothing (yet) */
@


1.4.14.5
log
@A bit on the way to make GENERIC compile in the SMP branch.
@
text
@d1 1
a1 1
/* $OpenBSD: pmap.h,v 1.4.14.4 2002/03/06 00:47:44 niklas Exp $ */
d185 1
a185 1
void	pmap_do_tlb_shootdown(struct cpu_info *, struct trapframe *);
@


1.4.14.6
log
@Sync the SMP branch with 3.3
@
text
@d1 1
a1 1
/* $OpenBSD$ */
d206 2
a207 2
#define	PMAP_MAP_POOLPAGE(pg)	ALPHA_PHYS_TO_K0SEG(VM_PAGE_TO_PHYS(pg))
#define	PMAP_UNMAP_POOLPAGE(va)	PHYS_TO_VM_PAGE(ALPHA_K0SEG_TO_PHYS((va)))
d213 2
a214 1
int	pmap_emulate_reference(struct proc *p, vaddr_t v, int user, int type);
@


1.4.14.7
log
@Sync SMP branch to -current
@
text
@d1 1
a1 1
/* $OpenBSD: pmap.h,v 1.4.14.6 2003/03/27 23:18:06 niklas Exp $ */
d58 5
a62 1
 * 3. Neither the name of the University nor the names of its contributors
@


1.4.14.8
log
@Merge of -current from two weeks ago into the SMP branch
@
text
@d1 1
a1 1
/* $OpenBSD$ */
d293 1
a293 1
 * it is not necessary to block interrupts when locking pmap structures.
@


1.4.14.9
log
@Merge with the trunk
@
text
@a193 2
#define pmap_proc_iflush(p, va, len)	/* nothing */

@


1.4.14.10
log
@sync with head, make i386 __HAVE_CPUINFO
@
text
@d204 2
a205 2
#define	pmap_map_direct(pg)	ALPHA_PHYS_TO_K0SEG(VM_PAGE_TO_PHYS(pg))
#define	pmap_unmap_direct(va)	PHYS_TO_VM_PAGE(ALPHA_K0SEG_TO_PHYS((va)))
@


1.3
log
@Add OpenBSD tags.  Adapt to OpenBSD *_intr_establish calling convention
@
text
@d1 2
a2 2
/*	$OpenBSD: pmap.h,v 1.4 1995/11/23 02:36:25 cgd Exp $	*/
/*	$NetBSD: pmap.h,v 1.4 1995/11/23 02:36:25 cgd Exp $	*/
d4 5
a8 39
/* 
 * Copyright (c) 1987 Carnegie-Mellon University
 * Copyright (c) 1991, 1993
 *	The Regents of the University of California.  All rights reserved.
 *
 * This code is derived from software contributed to Berkeley by
 * the Systems Programming Group of the University of Utah Computer
 * Science Department.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *	This product includes software developed by the University of
 *	California, Berkeley and its contributors.
 * 4. Neither the name of the University nor the names of its contributors
 *    may be used to endorse or promote products derived from this software
 *    without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE
 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
 *
 *	@@(#)pmap.h	8.1 (Berkeley) 6/10/93
 */
d10 1
a10 84
#ifndef	_PMAP_MACHINE_
#define	_PMAP_MACHINE_

#include <machine/pte.h>

#define	ALPHA_PAGE_SIZE	NBPG
#define	ALPHA_SEG_SIZE	NBSEG

#define alpha_trunc_seg(x)	(((u_long)(x)) & ~(ALPHA_SEG_SIZE-1))
#define alpha_round_seg(x)	alpha_trunc_seg((u_long)(x) + ALPHA_SEG_SIZE-1)

/*
 * Pmap stuff
 */
struct pmap {
	pt_entry_t		*pm_ptab;	/* KVA of page table */
	pt_entry_t		*pm_stab;	/* KVA of segment table */
	int			pm_stchanged;	/* ST changed */
	pt_entry_t		pm_stpte;	/* PTE mapping STE */
	short			pm_sref;	/* segment table ref count */
	short			pm_count;	/* pmap reference count */
	simple_lock_data_t	pm_lock;	/* lock on pmap */
	struct pmap_statistics	pm_stats;	/* pmap statistics */
	long			pm_ptpages;	/* more stats: PT pages */
};

typedef struct pmap	*pmap_t;

extern struct pmap	kernel_pmap_store;

#define pmap_kernel()	(&kernel_pmap_store)
#define	active_pmap(pm) \
	((pm) == pmap_kernel() || (pm) == curproc->p_vmspace->vm_map.pmap)

/*
 * Macros for speed
 */
#define PMAP_ACTIVATE(pmapp, iscurproc)					\
	if ((pmapp) != NULL && (pmapp)->pm_stchanged) {			\
		if (iscurproc)						\
			loadustp((pmapp)->pm_stpte);			\
		(pmapp)->pm_stchanged = FALSE;				\
	}
#define PMAP_DEACTIVATE(pmapp, pcbp)

/*
 * For each vm_page_t, there is a list of all currently valid virtual
 * mappings of that page.  An entry is a pv_entry_t, the list is pv_table.
 */
typedef struct pv_entry {
	struct pv_entry	*pv_next;	/* next pv_entry */
	struct pmap	*pv_pmap;	/* pmap where mapping lies */
	vm_offset_t	pv_va;		/* virtual address for mapping */
	pt_entry_t	*pv_ptpte;	/* non-zero if VA maps a PT page */
	struct pmap	*pv_ptpmap;	/* if pv_ptpte, pmap for PT page */
	int		pv_flags;	/* flags */
} *pv_entry_t;

#define PV_PTPAGE	0x01	/* header: entry maps a page table page */

/*
 * bits of pmap_attributes[]
 */
#define	PMAP_ATTR_MOD	0x01			/* modified */
#define	PMAP_ATTR_REF	0x02			/* referenced */

#ifdef _KERNEL
pv_entry_t	pv_table;		/* array of entries, one per page */

#define pa_index(pa)		atop(pa - vm_first_phys)
#define pa_to_pvh(pa)		(&pv_table[pa_index(pa)])

#define	pmap_resident_count(pmap)	((pmap)->pm_stats.resident_count)
#define	pmap_wired_count(pmap)		((pmap)->pm_stats.wired_count)

extern	pt_entry_t *Sysmap;
extern	char *vmmap;			/* map for mem, dumps, etc. */

/* Machine-specific functions. */
void	pmap_emulate_reference __P((struct proc *p, vm_offset_t v,
		int user, int write));
#endif /* _KERNEL */

#endif /* _PMAP_MACHINE_ */
@


1.2
log
@update to netbsd
@
text
@d1 1
@


1.1
log
@Initial revision
@
text
@d1 1
a1 1
/*	$NetBSD: pmap.h,v 1.3 1995/04/10 12:41:38 mycroft Exp $	*/
d103 6
d120 4
@


1.1.1.1
log
@initial import of NetBSD tree
@
text
@@
