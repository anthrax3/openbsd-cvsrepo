head	1.27;
access;
symbols
	OPENBSD_6_1:1.27.0.4
	OPENBSD_6_1_BASE:1.27
	OPENBSD_6_0:1.27.0.2
	OPENBSD_6_0_BASE:1.27
	OPENBSD_5_9:1.25.0.2
	OPENBSD_5_9_BASE:1.25
	OPENBSD_5_8:1.25.0.4
	OPENBSD_5_8_BASE:1.25
	OPENBSD_5_7:1.22.0.2
	OPENBSD_5_7_BASE:1.22
	OPENBSD_5_6:1.21.0.4
	OPENBSD_5_6_BASE:1.21
	OPENBSD_5_5:1.20.0.4
	OPENBSD_5_5_BASE:1.20
	OPENBSD_5_4:1.18.0.2
	OPENBSD_5_4_BASE:1.18
	OPENBSD_5_3:1.17.0.2
	OPENBSD_5_3_BASE:1.17
	OPENBSD_5_2:1.16.0.4
	OPENBSD_5_2_BASE:1.16
	OPENBSD_5_1_BASE:1.16
	OPENBSD_5_1:1.16.0.2
	OPENBSD_5_0:1.13.0.2
	OPENBSD_5_0_BASE:1.13
	OPENBSD_4_9:1.11.0.2
	OPENBSD_4_9_BASE:1.11
	OPENBSD_4_8:1.10.0.2
	OPENBSD_4_8_BASE:1.10
	OPENBSD_4_7:1.9.0.2
	OPENBSD_4_7_BASE:1.9
	OPENBSD_4_6:1.3.0.4
	OPENBSD_4_6_BASE:1.3
	OPENBSD_4_5:1.2.0.2
	OPENBSD_4_5_BASE:1.2;
locks; strict;
comment	@# @;


1.27
date	2016.05.20.02.30.41;	author mlarkin;	state Exp;
branches;
next	1.26;
commitid	F5BmBZzZKQUK5NHq;

1.26
date	2016.05.16.01.19.27;	author mlarkin;	state Exp;
branches;
next	1.25;
commitid	ejjZCIi4SS95OnQx;

1.25
date	2015.04.26.11.09.32;	author kettenis;	state Exp;
branches;
next	1.24;
commitid	o9YdhMEc9lBSn0pk;

1.24
date	2015.04.26.09.49.42;	author kettenis;	state Exp;
branches;
next	1.23;
commitid	nLIpXZ5Z4eVxs71w;

1.23
date	2015.03.20.07.07.57;	author mlarkin;	state Exp;
branches;
next	1.22;
commitid	egUzLcflEEjkBtmH;

1.22
date	2014.11.22.20.09.36;	author mlarkin;	state Exp;
branches;
next	1.21;
commitid	wRLVawd8196eSbjn;

1.21
date	2014.06.01.00.37.37;	author mlarkin;	state Exp;
branches;
next	1.20;
commitid	upjmIeN2TuoFwYNx;

1.20
date	2014.01.05.20.23.57;	author mlarkin;	state Exp;
branches;
next	1.19;

1.19
date	2013.10.18.15.07.59;	author mlarkin;	state Exp;
branches;
next	1.18;

1.18
date	2013.06.04.16.21.24;	author mlarkin;	state Exp;
branches;
next	1.17;

1.17
date	2012.10.19.16.56.06;	author mlarkin;	state Exp;
branches;
next	1.16;

1.16
date	2011.11.13.18.38.10;	author mlarkin;	state Exp;
branches;
next	1.15;

1.15
date	2011.09.22.11.08.01;	author deraadt;	state Exp;
branches;
next	1.14;

1.14
date	2011.09.21.02.51.23;	author mlarkin;	state Exp;
branches;
next	1.13;

1.13
date	2011.07.09.00.55.00;	author mlarkin;	state Exp;
branches;
next	1.12;

1.12
date	2011.04.30.15.33.18;	author mlarkin;	state Exp;
branches;
next	1.11;

1.11
date	2010.11.18.21.15.14;	author miod;	state Exp;
branches;
next	1.10;

1.10
date	2010.07.01.01.02.31;	author pirofti;	state Exp;
branches;
next	1.9;

1.9
date	2010.02.22.19.44.11;	author kettenis;	state Exp;
branches;
next	1.8;

1.8
date	2009.12.09.16.20.33;	author pirofti;	state Exp;
branches;
next	1.7;

1.7
date	2009.11.30.16.41.04;	author pirofti;	state Exp;
branches;
next	1.6;

1.6
date	2009.11.25.15.41.43;	author pirofti;	state Exp;
branches;
next	1.5;

1.5
date	2009.11.24.17.00.01;	author mlarkin;	state Exp;
branches;
next	1.4;

1.4
date	2009.11.22.22.38.43;	author mlarkin;	state Exp;
branches;
next	1.3;

1.3
date	2009.05.31.03.24.54;	author mlarkin;	state Exp;
branches;
next	1.2;

1.2
date	2009.02.19.21.02.05;	author marco;	state Exp;
branches;
next	1.1;

1.1
date	2009.01.20.20.21.03;	author mlarkin;	state Exp;
branches;
next	;


desc
@@


1.27
log
@
split the ACPI resume trampoline into code and data pages, and protect
with proper permissions. Same treatment was done on amd64 last year, i386
is catching up.

This diff has been in snaps for a few days, no regressions reported.

ok deraadt@@
@
text
@/*
 * Copyright (c) 2001 Takanori Watanabe <takawata@@jp.freebsd.org>
 * Copyright (c) 2001 Mitsuru IWASAKI <iwasaki@@jp.freebsd.org>
 * All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 *
 * THIS SOFTWARE IS PROVIDED BY THE AUTHOR AND CONTRIBUTORS ``AS IS'' AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE
 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
 */
/*
 * Copyright (c) 2008 Mike Larkin <mlarkin@@openbsd.org>
 *
 * Permission to use, copy, modify, and distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 */

#define _ACPI_WAKECODE

#include "assym.h"
#include <machine/asm.h>
#ifdef HIBERNATE
#include <machine/hibernate_var.h>
#endif /* HIBERNATE */
#include <machine/specialreg.h>
#include <machine/param.h>
#include <machine/segments.h>
#include <dev/acpi/acpivar.h>

#define _ACPI_TRMP_LABEL(a) a = . - _C_LABEL(acpi_real_mode_resume) + ACPI_TRAMPOLINE
#define _ACPI_TRMP_OFFSET(a) a = . - _C_LABEL(acpi_real_mode_resume)
#define _ACPI_TRMP_DATA_LABEL(a) a = . - _C_LABEL(acpi_tramp_data_start) + \
	ACPI_TRAMP_DATA
#define _ACPI_TRMP_DATA_OFFSET(a) a = . - _C_LABEL(acpi_tramp_data_start)
#define _ACPI_RM_CODE_SEG (ACPI_TRAMPOLINE >> 4)
#define _ACPI_RM_DATA_SEG (ACPI_TRAMP_DATA >> 4)

#ifdef HIBERNATE
#define HIBERNATE_STACK_OFFSET 0x0F00
#endif

/*
 * On wakeup, we'll start executing at acpi_real_mode_resume.
 * This is based on the wakeup vector previously stored with
 * ACPI before we went to sleep. ACPI's wakeup vector is a
 * physical address - in our case, it's calculated and mapped
 * by the kernel and stuffed into a low page early in the boot
 * process.
 *
 * We wakeup in real mode, at some phys addr based on the ACPI
 * specification (cs = phys>>8, ip = phys & 0xF). For example,
 * if our phys addr is 0x13000, we'd have cs=0x1300,ip=0
 *
 * The wakeup code needs to do the following:
 *     1. Reenable the video display
 *     2. Enter 32 bit protected mode
 *     3. Reenable paging
 *     4. Restore saved CPU registers
 */

	.text
	.code16
	.align 4, 0xcc
	.global _C_LABEL(acpi_real_mode_resume)
	.global _C_LABEL(acpi_protected_mode_resume)
	.global _C_LABEL(acpi_resume_end)
	.global _C_LABEL(acpi_tramp_data_start)
	.global _C_LABEL(acpi_tramp_data_end)
_C_LABEL(acpi_real_mode_resume):
_ACPI_TRMP_OFFSET(acpi_s3_vector_real)
	nop
	cli
	cld

	/*
	 * Set up segment registers for real mode.
	 * We'll only be in real mode for a moment, and we don't have
	 * want real dependencies on data or stack, so we'll just use
	 * the code segment for data and stack (eg, a 64k memory space).
	 */
	movw	$(_ACPI_RM_DATA_SEG), %ax
	movw	%ax, %ds
	movw	%ax, %ss
	movw	%cs, %ax
	movw	%ax, %es
	lidtl	clean_idt

	/*
	 * Set up stack to grow down from offset 0x0FFE.
	 * We will only be doing a few push/pops and no calls in real
	 * mode, so as long as the real mode code in the segment
	 * plus stack doesn't exceed 0x0FFE (4094) bytes, we'll be ok.
	 */
	movw	$0x0FFE,%sp

	/*
	 * Clear flags
	 */
	pushl	$0
	popfl

	/*
	 * Flush instruction prefetch queue
	 */
	jmp	1f
1:	jmp	1f
1:

	/*
	 * We're about to enter protected mode, so we need a GDT for that.
	 * Set up a temporary GDT describing 2 segments, one for code
	 * extending from 0x00000000-0xffffffff and one for data
	 * with the same range. This GDT will only be in use for a short
	 * time, until we restore the saved GDT that we had when we went
	 * to sleep (although on i386, the saved GDT will most likely
	 * represent something similar based on machine/segment.h).
	 */
	data32 addr32 lgdt	tmp_gdt

	/*
	 * Enable protected mode by setting the PE bit in CR0
	 */
	mov	%cr0,%eax
	orl	$(CR0_PE),%eax
	mov	%eax,%cr0

	/*
	 * Force CPU into protected mode
	 * by making an intersegment jump (to ourselves, just a few lines
	 * down from here. We rely on the kernel to fixup the jump
	 * target addres previously.
	 *
	 */
	ljmpl	$0x8, $acpi_protected_mode_trampoline

	.code32
	.align 16, 0xcc
_ACPI_TRMP_LABEL(acpi_protected_mode_trampoline)
_C_LABEL(acpi_protected_mode_resume):
	nop

	/*
	 * We're in protected mode now, without paging enabled.
	 *
	 * Set up segment selectors for protected mode.
	 * We've already set up our cs via the intersegment jump earlier,
	 * but we need to set ds,es,fs,gs,ss to all point to the
	 * 4GB flat data segment we defined earlier.
	 */
	movw	$GSEL(GDATA_SEL,SEL_KPL),%ax
	movw	%ax,%ds
	movw	%ax,%es
	movw	%ax,%gs
	movw	%ax,%ss
	movw	%ax,%fs

	/*
	 * Reset ESP based on protected mode. We can do this here
	 * because we haven't put anything on the stack via a
	 * call or push that we haven't cleaned up already.
	 */
	addl	$(ACPI_TRAMP_DATA), %esp

	/*
	 * Reset our page size extension (via restoring cr4) to what
	 * it was before we suspended. If we don't do this, cr4 might
	 * contain garbage in the PSE bit, leading to pages that
	 * are incorrectly interpreted as the wrong size
	 * CR4 was added in i586, so there is
	 * an implicit assumption here that this code will execute on
	 * i586 or later.
	 */
	mov	acpi_saved_cr4,%eax
	mov	%eax,%cr4

	testl	$CR4_PAE, %eax
	jz	1f

	movl	$MSR_EFER, %ecx
	rdmsr
	orl	$EFER_NXE, %eax
	wrmsr

1:
	/*
	 * Re-enable paging, using the CR3 we stored before suspend
	 * as our new page table base location. Restore CR0 after
	 * that.
	 */
	movl	acpi_saved_cr3,%eax
	movl	%eax,%cr3
	movl	acpi_saved_cr0, %eax
	movl	%eax, %cr0

	/*
	 * Flush the prefetch queue in order to enforce usage
	 * of the new (old) page tables we just re-enabled
	 */
	jmp	1f
1:	jmp	1f
1:
	nop

	/*
	 * Restore CPU segment descriptor registers
	 */
	lgdt	acpi_saved_gdt
	lidt	acpi_saved_idt
	lldt	acpi_saved_ldt

	mov	acpi_saved_cr2,%eax
	mov	%eax,%cr2

	/*
	 * It is highly likely that the selectors we already loaded into
	 * these registers are already accurate, but we reload them
	 * again, for consistency.
	 */
	movw	acpi_saved_es,%ax
	movw	%ax,%es
	movw	acpi_saved_fs,%ax
	movw	%ax,%fs
	movw	acpi_saved_gs,%ax
	movw	%ax,%gs
	movw	acpi_saved_ss,%ax
	movw	%ax,%ss
	movw	acpi_saved_ds,%ax
	movw	%ax,%ds

	/*
	 * Shortly, we'll restore the TSS for the task that was running
	 * immediately before suspend occured. Since that task was the
	 * running task, it's TSS busy flag will have been set. We need
	 * to clear that bit (since we're effectively "restarting" the OS)
	 * in order to convince the processor that the task is no longer
	 * running (which is true, now). If we don't do this, when the
	 * OS resumes and resumes this task, it will assume we're trying
	 * to recurse into an already active task, which would cause
	 * a GP violation (and probably, a crash).
	 *
	 * We accomplish this by changing the TSS descriptor from
	 * BUSY (0x0B) to AVAILABLE (0x09). We keep the other
	 * high 4 bits intact.
	 */
	movl	acpi_saved_gdt+2,%ebx
	xorl	%ecx, %ecx
	movw	acpi_saved_tr,%cx
	leal	(%ebx,%ecx),%eax
	andb	$0xF9,5(%eax)

	ltr	acpi_saved_tr

	/*
	 * Everything is almost reset back to the way it was immediately before
	 * suspend. There are a few more registers to restore, and after
	 * that, jump back to the OS. There's still some things
	 * to do there, like re-enable interrupts, resume devices, APICs,
	 * etc.
	 */
	movl	acpi_saved_ebx, %ebx
	movl	acpi_saved_ecx, %ecx
	movl	acpi_saved_edx, %edx
	movl	acpi_saved_ebp, %ebp
	movl	acpi_saved_esi, %esi
	movl	acpi_saved_edi, %edi
	movl	acpi_saved_esp, %esp
	push	acpi_saved_fl
	popfl

	/* Poke CR3 one more time. Might not be necessary */
	movl	acpi_saved_cr3,%eax
	movl	%eax,%cr3

	/*
	 * Return to the OS. We've previously saved the resume
	 * address in acpi_saved_ret (via a call to acpi_savecpu
	 * before we went to sleep.)
	 */
	xorl  %eax, %eax
	jmp	*acpi_saved_ret

#ifdef HIBERNATE
	/*
	 * hibernate_resume_machdep drops to real mode and
	 * restarts the OS using the saved S3 resume vector
	 */
	.code32
NENTRY(hibernate_resume_machdep)
	cli
	/* Jump to the identity mapped version of ourself */
	mov	$hibernate_resume_vector_2, %eax
	jmp	*%eax
_ACPI_TRMP_LABEL(hibernate_resume_vector_2)

	/* Get out of 32 bit CS */
	lgdt	gdt_16
	ljmp	$0x8, $hibernate_resume_vector_3

_ACPI_TRMP_LABEL(hibernate_resume_vector_3)
	.code16
	movl	%cr0, %eax
	/* Disable CR0.PG - no paging */
	andl	$(~CR0_PG), %eax
	/* Disable CR0.PE - real mode */
	andl	$(~CR0_PE), %eax
	movl	%eax, %cr0

	/* Flush TLB */
	xorl	%eax, %eax
	movl	%eax, %cr3

	/* Set up real mode segment selectors */
	movw	$(_ACPI_RM_DATA_SEG), %ax
	movw	%ax, %ds
	movw	%ax, %ss
	movw	%ax, %es
	movw	%ax, %fs
	movw	%ax, %gs
	movl	$0x0FFE, %esp
	lidtl	clean_idt

	/* Jump to the S3 resume vector */
	ljmp	$(_ACPI_RM_CODE_SEG), $acpi_s3_vector_real

	.code32
	/* Switch to hibernate resume pagetable */
NENTRY(hibernate_activate_resume_pt_machdep)
	/* Enable large pages */
	movl	%cr4, %eax
	orl	$(CR4_PSE), %eax

	/* Disable global pages */
	andl	$(~CR4_PGE), %eax
	movl	%eax, %cr4

	/* 
	 * Switch to the hibernate resume pagetable if we're running
	 * in non-PAE mode.  If we're running in PAE mode, this will
	 * switch to the PTPDEs we stashed into the hibernate resume
	 * pagetable, but continue to use the normal pagetables until we
	 * disable PAE below.
	 */
	movl	$HIBERNATE_PD_PAGE, %eax
	orl	$0xfe0, %eax
	movl	%eax, %cr3

	/* Disable PAE */
	movl	%cr4, %eax
	andl	$(~CR4_PAE), %eax
	movl	%eax, %cr4

	wbinvd
	movl	$HIBERNATE_PD_PAGE, %eax
	movl	%eax, %cr3
	jmp	1f

1:	nop
	ret

	/*
	 * Switch to the private resume-time hibernate stack
	 */
NENTRY(hibernate_switch_stack_machdep)
	movl	(%esp), %eax
	movl    %eax, HIBERNATE_STACK_PAGE + HIBERNATE_STACK_OFFSET
	movl    $(HIBERNATE_STACK_PAGE + HIBERNATE_STACK_OFFSET), %eax
	movl    %eax, %esp

	/* On our own stack from here onward */
	ret

NENTRY(hibernate_flush)
	invlpg  HIBERNATE_INFLATE_PAGE
	ret
#endif /* HIBERNATE */

	/*
	 * End of resume code (code copied to ACPI_TRAMPOLINE)
	 */
_C_LABEL(acpi_resume_end):

	/*
	 * Initial copy of this data gets placed in .rodata, kernel makes
	 * RW copy of it in the tramp data page.
	 */
	.section .rodata
_C_LABEL(acpi_tramp_data_start):
_ACPI_TRMP_DATA_OFFSET(tmp_gdt)
	.word	tmp_gdt_end - tmp_gdtable
	.long	tmp_gdtable

	.align 8, 0xcc
_ACPI_TRMP_DATA_LABEL(tmp_gdtable)
	/*
	 * null
	 */
	.word	0, 0
	.byte	0, 0, 0, 0
	/*
	 * Code
	 * Limit: 0xffffffff
	 * Base: 0x00000000
	 * Descriptor Type: Code
	 * Segment Type: CRA
	 * Present: True
	 * Priv: 0
	 * AVL: False
	 * 64-bit: False
	 * 32-bit: True
	 *
	 */
	.word	0xffff, 0
	.byte	0, 0x9f, 0xcf, 0

	/*
	 * Data
	 * Limit: 0xffffffff
	 * Base: 0x00000000
	 * Descriptor Type:
	 * Segment Type: W
	 * Present: True
	 * Priv: 0
	 * AVL: False
	 * 64-bit: False
	 * 32-bit: True
	 *
	 */
	.word	0xffff, 0
	.byte	0, 0x93, 0xcf, 0
_ACPI_TRMP_DATA_LABEL(tmp_gdt_end)

	.align 8, 0xcc
_ACPI_TRMP_DATA_OFFSET(clean_idt)
	.word	0xffff
	.long	0
	.word	0

	/*
	 * gdt_16 is the gdt used when returning to real mode for bios
	 * reads/writes (sets up a 16 bit segment)
	 */
	.align 8, 0xcc
_ACPI_TRMP_DATA_LABEL(gdt_16)
	.word   gdt_16_end - gdt_16_table
	.long   gdt_16_table

	.align 8, 0xcc
_ACPI_TRMP_DATA_LABEL(gdt_16_table)
	/*
	 * null
	 */
	.word   0, 0
	.byte   0, 0, 0, 0
	/*
	 * Code
	 * Limit: 0xffffffff
	 * Base: 0x00000000
	 * Descriptor Type: Code
	 * Segment Type: CRA
	 * Present: True
	 * Priv: 0
	 * AVL: False
	 * 64-bit: False
	 * 32-bit: False
	 *
	 */
	.word   0xffff, 0
	.byte   0, 0x9f, 0x8f, 0

	/*
	 * Data
	 * Limit: 0xffffffff
	 * Base: 0x00000000
	 * Descriptor Type:
	 * Segment Type: W
	 * Present: True
	 * Priv: 0
	 * AVL: False
	 * 64-bit: False
	 * 32-bit: False
	 *
	 */
	.word   0xffff, 0
	.byte   0, 0x93, 0x8f, 0

_ACPI_TRMP_DATA_LABEL(gdt_16_end)

	.align 4, 0xcc
_ACPI_TRMP_DATA_LABEL(acpi_saved_ebx)
	.long 0
_ACPI_TRMP_DATA_LABEL(acpi_saved_ecx)
	.long 0
_ACPI_TRMP_DATA_LABEL(acpi_saved_edx)
	.long 0
_ACPI_TRMP_DATA_LABEL(acpi_saved_ebp)
	.long 0
_ACPI_TRMP_DATA_LABEL(acpi_saved_esi)
	.long 0
_ACPI_TRMP_DATA_LABEL(acpi_saved_edi)
	.long 0
_ACPI_TRMP_DATA_LABEL(acpi_saved_esp)
	.long 0
_ACPI_TRMP_DATA_LABEL(acpi_saved_fl)
	.long 0
_ACPI_TRMP_DATA_LABEL(acpi_saved_cr0)
	.long 0
_ACPI_TRMP_DATA_LABEL(acpi_saved_cr2)
	.long 0
_ACPI_TRMP_DATA_LABEL(acpi_saved_cr3)
	.long 0
_ACPI_TRMP_DATA_LABEL(acpi_saved_cr4)
	.long 0
_ACPI_TRMP_DATA_LABEL(acpi_saved_ret)
	.long 0

	.align 16, 0xcc
_ACPI_TRMP_DATA_LABEL(acpi_saved_idt)
	.space 6

	.align 16, 0xcc
_ACPI_TRMP_DATA_LABEL(acpi_saved_gdt)
	.space 6

	.align 16, 0xcc
_ACPI_TRMP_DATA_LABEL(acpi_saved_ldt)
	.short 0
_ACPI_TRMP_DATA_LABEL(acpi_saved_cs)
	.short 0
_ACPI_TRMP_DATA_LABEL(acpi_saved_ds)
	.short 0
_ACPI_TRMP_DATA_LABEL(acpi_saved_es)
	.short 0
_ACPI_TRMP_DATA_LABEL(acpi_saved_fs)
	.short 0
_ACPI_TRMP_DATA_LABEL(acpi_saved_gs)
	.short 0
_ACPI_TRMP_DATA_LABEL(acpi_saved_ss)
	.short 0
_ACPI_TRMP_DATA_LABEL(acpi_saved_tr)
	.short 0

_C_LABEL(acpi_tramp_data_end):

	/*
	 * acpi_savecpu saves the processor's registers and flags
	 * for use during the ACPI suspend/resume process.
	 */

	.code32
NENTRY(acpi_savecpu)
	movl	(%esp), %eax
	movl	%eax, acpi_saved_ret

	movw	%cs, acpi_saved_cs
	movw	%ds, acpi_saved_ds
	movw	%es, acpi_saved_es
	movw	%fs, acpi_saved_fs
	movw	%gs, acpi_saved_gs
	movw	%ss, acpi_saved_ss

	movl	%ebx, acpi_saved_ebx
	movl	%ecx, acpi_saved_ecx
	movl	%edx, acpi_saved_edx
	movl	%ebp, acpi_saved_ebp
	movl	%esi, acpi_saved_esi
	movl	%edi, acpi_saved_edi
	movl	%esp, acpi_saved_esp

	pushfl
	popl	acpi_saved_fl

	movl	%cr0, %eax
	movl	%eax, acpi_saved_cr0
	movl	%cr2, %eax
	movl	%eax, acpi_saved_cr2
	movl	%cr3, %eax
	movl	%eax, acpi_saved_cr3
	movl	%cr4, %eax
	movl	%eax, acpi_saved_cr4

	sgdt	acpi_saved_gdt
	sidt	acpi_saved_idt
	sldt	acpi_saved_ldt
	str	acpi_saved_tr

	movl	$1, %eax
	ret
@


1.26
log
@
Use int3 padding instead of nop in the ACPI resume trampoline, as it is
certain no intentional nop sled is required here.

ok deraadt@@
@
text
@d57 5
a61 1
#define _ACPI_RM_SEGMENT (ACPI_TRAMPOLINE >> 4)
d92 2
d106 5
a110 4
	movw	%cs,%ax
	movw	%ax,%ds
	movw	%ax,%es
	movw	%ax,%ss
a127 7
	 * Set up esi to point to start of current routine's CS.
	 */
	xorl    %esi,%esi
	movw    %cs,%si
	shll    $4,%esi

	/*
d187 1
a187 3
	movl    %esi, %esp
	addl    $0x0FFE, %esp

d338 1
a338 1
	movw	$0x1300, %ax
d340 1
d348 1
a348 1
	ljmp	$0x1300, $acpi_s3_vector_real
d402 12
a413 3
	.code16
	.align 8, 0xcc
_ACPI_TRMP_OFFSET(tmp_gdt)
d418 1
a418 1
_ACPI_TRMP_LABEL(tmp_gdtable)
d455 1
a455 1
_ACPI_TRMP_LABEL(tmp_gdt_end)
d458 1
a458 1
_ACPI_TRMP_OFFSET(clean_idt)
d468 1
a468 1
_ACPI_TRMP_LABEL(gdt_16)
d473 1
a473 1
_ACPI_TRMP_LABEL(gdt_16_table)
d511 1
a511 1
_ACPI_TRMP_LABEL(gdt_16_end)
d514 1
a514 1
_ACPI_TRMP_LABEL(acpi_saved_ebx)
d516 1
a516 1
_ACPI_TRMP_LABEL(acpi_saved_ecx)
d518 1
a518 1
_ACPI_TRMP_LABEL(acpi_saved_edx)
d520 1
a520 1
_ACPI_TRMP_LABEL(acpi_saved_ebp)
d522 1
a522 1
_ACPI_TRMP_LABEL(acpi_saved_esi)
d524 1
a524 1
_ACPI_TRMP_LABEL(acpi_saved_edi)
d526 1
a526 1
_ACPI_TRMP_LABEL(acpi_saved_esp)
d528 1
a528 1
_ACPI_TRMP_LABEL(acpi_saved_fl)
d530 1
a530 1
_ACPI_TRMP_LABEL(acpi_saved_cr0)
d532 1
a532 1
_ACPI_TRMP_LABEL(acpi_saved_cr2)
d534 1
a534 1
_ACPI_TRMP_LABEL(acpi_saved_cr3)
d536 1
a536 1
_ACPI_TRMP_LABEL(acpi_saved_cr4)
d538 1
a538 1
_ACPI_TRMP_LABEL(acpi_saved_ret)
d542 1
a542 1
_ACPI_TRMP_LABEL(acpi_saved_idt)
d546 1
a546 1
_ACPI_TRMP_LABEL(acpi_saved_gdt)
d550 1
a550 1
_ACPI_TRMP_LABEL(acpi_saved_ldt)
d552 1
a552 1
_ACPI_TRMP_LABEL(acpi_saved_cs)
d554 1
a554 1
_ACPI_TRMP_LABEL(acpi_saved_ds)
d556 1
a556 1
_ACPI_TRMP_LABEL(acpi_saved_es)
d558 1
a558 1
_ACPI_TRMP_LABEL(acpi_saved_fs)
d560 1
a560 1
_ACPI_TRMP_LABEL(acpi_saved_gs)
d562 1
a562 1
_ACPI_TRMP_LABEL(acpi_saved_ss)
d564 1
a564 1
_ACPI_TRMP_LABEL(acpi_saved_tr)
d567 1
a567 4
	/*
	 * End of resume code (code copied to ACPI_TRAMPOLINE)
	 */
_C_LABEL(acpi_resume_end):
@


1.25
log
@Disable PAE when switching to the hibernate resume pagetables.  This involves
a slightly conmplicated dance where we stash the PAE PDPTEs into the
hibernate resume pagetables and use those before turning off PAE.
Makes (un)hibernate work with the new PAE pmap.

ok mlarkin@@
@
text
@d84 1
a84 1
	.align 4
d162 1
a162 1
	.align 16
d404 1
a404 1
	.align 8
d409 1
a409 1
	.align 8
d449 1
a449 1
	.align 8
d459 1
a459 1
	.align 8
d464 1
a464 1
	.align 8
d505 1
a505 1
	.align 4
d533 1
a533 1
	.align 16
d537 1
a537 1
	.align 16
d541 1
a541 1
	.align 16
@


1.24
log
@Enable NX support in the resume path.  Makes suspend/resume work with the
PAE pmap.

ok deraadt@@, mlarkin@@
@
text
@d362 16
d380 1
a380 1
	movl	%eax,	%cr3
@


1.23
log
@
Fix an outdated comment, spotted by mpi@@
@
text
@d203 9
@


1.22
log
@
Previous diff changed the location of the ACPI S3/S4 trampoline, which has
a common #defined location for both i386 and amd64. This diff fixes i386 to
match.

Also fix a tab/space issue in amd64 hibernate_var.h

discussed with deraadt
@
text
@d273 1
a273 2
	 * suspend. There are a few more registers to restore - this is
	 * done in acpi_restorecpu. We'll jump to that routine, and after
@


1.21
log
@
Remove real mode VGA repost option. It was used by nobody, and even if it
were to be enabled, it had a bug that prevented it from working anyway.

ok deraadt@@, kettenis@@
@
text
@d73 1
a73 1
 * if our phys addr is 0x11000, we'd have cs=0x1100,ip=0
d332 1
a332 1
	movw	$0x1100, %ax
d341 1
a341 1
	ljmp	$0x1100, $acpi_s3_vector_real
@


1.20
log
@

Don't use the first 64KB for anything, including tramps. Move tramps and
hibernate goo up after 64KB to avoid posible corruption by buggy BIOS SMM
code. Diff also ensures the first 64KB doesn't get handed to UVM either.

ok deraadt@@, tested by many with no regressions reported
@
text
@a87 1
	.global _C_LABEL(do_real_mode_post)
a120 26
	 * Reset the video hardware (as best as we can).
	 * We call the video bios at c000:0003, similar to
	 * what the BIOS does on a machine restart.
	 * Note that this will only reset the video card,
	 * and may not enable LCDs or other attached displays.
	 *
	 * This will also put the hardware in "factory default"
	 * display mode, which may not match what we had
	 * when we went to sleep. On many machines (specifically
	 * laptops), we might not restore the proper VGA mode
	 * on resume. Caveat emptor.
	 */
	cmpl	$0, do_real_mode_post_off
	jz	nobiosreset
	lcall	$0xc000,$3

	/*
	 * Restore our segment registers in case the call to
	 * reset the video hardware clobbered them.
	 */
	movw	%cs,%ax
	movw	%ax,%ds
	movw	%ax,%ss
nobiosreset:

	/*
a479 5

	.align 4
_C_LABEL(do_real_mode_post):
_ACPI_TRMP_OFFSET(do_real_mode_post_off)
	.long 0
@


1.19
log
@

Disable global page mappings before we start to unpack. This was likely
one cause of the random gzip errors and reboots we've been seeing with
hibernate as we were creating new mappings for kernel text which likely
conflicted with the non-flushed global mappings from the resuming kernel.

Also remove an unnecessary wbinvd (i386)

ok deraadt
@
text
@d73 1
a73 1
 * if our phys addr is 0x4000, we'd have cs=0x0400,ip=0
d359 1
a359 1
	movw	$0x0400, %ax
d368 1
a368 1
	ljmp	$0x0400, $acpi_s3_vector_real
@


1.18
log
@

Remove remaining references to HIBERNATE_COPY_PAGE. It was effectively
removed at n2k13 but a few errant references still remained. No functional
change. Spot tested by my on i386 and amd64 UP environments, no regressions
seen.

noticed by deraadt@@
@
text
@d376 3
d381 1
a401 1
	wbinvd
@


1.17
log
@

add an #ifdef HIBERNATE for diffability with amd64
@
text
@a399 1
	invlpg  HIBERNATE_COPY_PAGE
@


1.16
log
@

Fix a handful of bugs that were causing reboots and other bad behavior
during hibernate resumes.
@
text
@d47 1
d49 1
@


1.15
log
@spacing cleanup after mlarkin visited the file
@
text
@d372 1
a372 1
	movl	%eax, %cr4
d397 2
a398 2
	movl	$hibernate_inflate_page, %eax
	invlpg  (%eax)
@


1.14
log
@

Perform most of the remaining refactoring of hibernate code into
MI/MD parts. This also introduces a chunk placement routine that was
originally developed at c2k11 with help from drahn and ariane.

There are still a few more things to do for hibernate, but those can be
worked on in-tree. This code is disabled by default, and not yet called.

ok deraadt@@ (and deraadt@@ said kettenis@@ also ok'ed it :) )
@
text
@d67 1
a67 1
 * process. 
d94 1
a94 1
	 * Set up segment registers for real mode. 
d107 2
a108 2
	 * We will only be doing a few push/pops and no calls in real 
	 * mode, so as long as the real mode code in the segment 
d123 1
a123 1
	 * Note that this will only reset the video card, 
d137 1
a137 1
	 * Restore our segment registers in case the call to 
d155 2
a156 2
	jmp     1f
1:	jmp     1f
d167 1
a167 1
	 */ 
d178 1
a178 1
	 * Force CPU into protected mode 
d181 1
a181 1
	 * target addres previously. 
d197 1
a197 1
	 * but we need to set ds,es,fs,gs,ss to all point to the 
d217 2
a218 2
	 * Reset our page size extension (via restoring cr4) to what 
	 * it was before we suspended. If we don't do this, cr4 might 
d247 1
a247 1
	/* 
d279 1
a279 1
	 * running (which is true, now). If we don't do this, when the 
d286 1
a286 1
	 * high 4 bits intact. 
d294 1
a294 1
	ltr	acpi_saved_tr 
d296 1
a296 1
	/* 
d298 1
a298 1
	 * suspend. There are a few more registers to restore - this is 
d301 1
a301 1
	 * to do there, like re-enable interrupts, resume devices, APICs, 
d420 1
a420 1
	 * Segment Type: CRA 
d427 1
a427 1
	 */ 
d435 1
a435 1
	 * Descriptor Type: 
d443 1
a443 1
	 */ 
d478 1
a478 1
 	 * AVL: False
d546 1
a546 1
_ACPI_TRMP_LABEL(acpi_saved_ldt)	
d554 1
a554 1
_ACPI_TRMP_LABEL(acpi_saved_fs)	
@


1.13
log
@

Extract MI pmap function hibernate_enter_resume_mapping, refactor old i386
resume pmap code to match.

Add hibernate deflater and inflater and cache flush routines.

Code is not presently called or automatically built.
@
text
@d56 2
d59 1
d326 1
d328 1
a328 1
	 * hibernate_resume_machine drops to real mode and
d332 1
a332 1
NENTRY(hibernate_resume_machine)
d370 1
a370 1
NENTRY(hibernate_activate_resume_pt)
d376 1
a376 1
	movl	$HIBERNATE_PT_PAGE, %eax
d383 4
a386 1
NENTRY(hibernate_switch_stack)
d388 3
a390 3
	movl	%eax, HIBERNATE_STACK_PAGE + HIBERNATE_STACK_OFFSET
	movl	$(HIBERNATE_STACK_PAGE + HIBERNATE_STACK_OFFSET), %eax
	movl	%eax, %esp
d397 2
a398 1
	invlpg  HIBERNATE_TEMP_PAGE
d400 1
@


1.12
log
@Preliminary plumbing code for i386 hibernate (suspend-to-disk).
This code is not yet called as there are still some important parts
not completed.

ok deraadt@@, kettenis@@ "looks reasonable"
@
text
@d388 5
@


1.11
log
@Don't
  #include "foo.h"
  #if NFOO > 0
  (whole file)
  #endif
since config(8) file inclusion rules already do it for you.
ok deraadt@@
@
text
@d47 1
d56 1
d85 1
d323 66
d440 50
d559 1
@


1.10
log
@Add a look-up table for machines that have special vga cards. This table will
tell, based on vendor/product/subvendor/subproduct ids, how the video reposting
should be done: via the emulator or the bios video call in locore. The default
is to do none of those, which is how most machines work.

Okay kettenis@@, deraadt@@.
@
text
@a42 5
#include "acpi.h"

#if NACPI > 0
#ifndef SMALL_KERNEL

a477 2
#endif /* SMALL_KERNEL */
#endif /* NACPI > 0 */
@


1.9
log
@Don't attempt to repost the video hardware.  There are quite a few machines
where jumping to the "standard" video BIOS entry point locks up or even
resets the machine.  This will break resume on some other machines in the
sense that the display on them will remain disabled.  But hopefully those
machines make it into a state where the kernel is running and we can fix that.

ok deraadt@@, marco@@, mlarkin@@
@
text
@d86 1
d131 2
a132 1
	jmp	nobiosreset	/* XXX make this a tunable */
d375 5
@


1.8
log
@Remove the clean gdt bit and leave the idt part in.

Fixes most laptops out there on resume. Okay deraadt@@.
@
text
@d130 1
a130 1
 	/* jmp	nobiosreset */  	/* XXX make this a tunable */ 
@


1.7
log
@KNF
@
text
@a90 22
	/* Some BIOS vendors screw up the gdt, make sure we clean it */
	movw	$0x10,	%cx
	lgdtl	%cs:clean_gdt
	movl	%cr0,	%eax
	orb	$(CR0_PE), %al
	movl	%eax,	%cr0
	jmp	1f
1:	ljmpw	$0x8, $clean1

_ACPI_TRMP_OFFSET(clean1)
	movw	%cx,	%ds	
	movw	%cx,	%es
	movw	%cx,	%ss
	movw	%cx,	%fs
	movw	%cx,	%gs
	
	andb	$~(CR0_PE), %al
	movl	%eax,	%cr0
	ljmpw	$_ACPI_RM_SEGMENT , $clean2

_ACPI_TRMP_OFFSET(clean2)

a372 16

_ACPI_TRMP_OFFSET(clean_gdt)
	.word	clean_gdt_end - clean_gdtable
	.long	clean_gdtable

	.align 8
_ACPI_TRMP_LABEL(clean_gdtable)
	.word	0, 0
	.byte	0, 0, 0, 0

	.word	0xffff, ACPI_TRAMPOLINE
	.byte	0, 0x9b, 0, 0

	.word	0xffff, ACPI_TRAMPOLINE
	.byte	0, 0x93, 0, 0
_ACPI_TRMP_LABEL(clean_gdt_end)
@


1.6
log
@Make sure we get a clean gdt from the BIOS.

Some vendors screw us up on resume giving back a dirty gdt which
prevents us to go into protected mode. This makes sure the gdt is
clean, its the only way to do this and its the only way to be sure
we're clean on resume.

This fixes quite a few laptops that didn't resume but rebooted or did
other screwy things because of a dirty gdt.

Worked with mlarkin@@ for quite a few houres last night.
Tested by many on both amd64 and i386.
Okay deraadt@@.
@
text
@d82 1
a82 1
	.align 4,0
d350 1
a350 1
	.align 8,0
d390 1
a390 1
	.align 8, 0
d400 1
a400 1
	.align 8, 0
@


1.5
log
@

Poke CR3 one last time before resuming. Suggested by deraadt@@.

ok deraadt@@
@
text
@d59 1
d91 22
d121 1
d123 1
d389 22
@


1.4
log
@

Repost the vbios and remove a spurious cli on i386 ACPI resume code.
Makes i386 and amd64 behave the same way with respect to vbios repost.
ok pirofti@@
@
text
@d308 4
@


1.3
log
@Move task register restore code to proper place.

ok marco@@
@
text
@d127 1
a127 1
	jmp	nobiosreset	/* XXX make this a tunable */
a306 1
	cli
@


1.2
log
@suspend/resume bits so that we can develop this in tree.  This is disabled.
code from mlarkin and me
help from art,toby,jordan and several others
ok jordan, go for it deraadt
@
text
@a208 19
	/*
	 * Shortly, we'll restore the TSS for the task that was running
	 * immediately before suspend occured. Since that task was the
	 * running task, it's TSS busy flag will have been set. We need
	 * to clear that bit (since we're effectively "restarting" the OS)
	 * in order to convince the processor that the task is no longer
	 * running (which is true, now). If we don't do this, when the 
	 * OS resumes and resumes this task, it will assume we're trying
	 * to recurse into an already active task, which would cause
	 * a GP violation (and probably, a crash).
	 *
	 * We accomplish this by changing the TSS descriptor from
	 * BUSY (0x0B) to AVAILABLE (0x09). We keep the other
	 * high 4 bits intact. 
	 */
	movl	acpi_saved_gdt+2,%ebx
	movzxw	acpi_saved_tr,%ecx
	leal	(%ebx,%ecx),%eax
	andb	$0xF9,5(%eax)
d267 23
d307 1
a307 15

	/*
	 * XXX - The following ltr instruction occasionally causes
	 *       A GP(0) violation. According to Intel, this can
	 *       happen for various reasons, none of which is 
	 *       possible based on the register restore code above.
	 *       The task register restore is thereby disabled
	 *       until the reason for the occasional GP(0) can 
	 *       be identified.
	 * 
	 *       It's either a bad DS (unlikely), or the saved TR
	 *       points to something other than a TSS (equally 
	 *       unlikely).
	 */
	 /* ltr	acpi_saved_tr */
d312 1
a312 1
	 * before we went to sleep.
@


1.1
log
@
Install ACPI S3 resume trampoline code in a lowmem page. First part
of ACPI S3 suspend/resume support. This is for i386.

Help/comments from art, toby, marco, jordan, kurt
ok marco@@, kurt@@
@
text
@d93 1
a93 1
	 * ant real dependencies on data or stack, so we'll just use
d127 1
d137 1
a152 1

d180 2
a183 3
	.code32
	.align 16

d325 1
a325 3
	jmp   *acpi_saved_ret


a369 1

a386 1

a396 1

a473 2


@

