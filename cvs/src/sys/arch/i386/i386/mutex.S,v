head	1.10;
access;
symbols
	OPENBSD_6_1:1.10.0.4
	OPENBSD_6_1_BASE:1.10
	OPENBSD_6_0:1.9.0.14
	OPENBSD_6_0_BASE:1.9
	OPENBSD_5_9:1.9.0.10
	OPENBSD_5_9_BASE:1.9
	OPENBSD_5_8:1.9.0.12
	OPENBSD_5_8_BASE:1.9
	OPENBSD_5_7:1.9.0.4
	OPENBSD_5_7_BASE:1.9
	OPENBSD_5_6:1.9.0.8
	OPENBSD_5_6_BASE:1.9
	OPENBSD_5_5:1.9.0.6
	OPENBSD_5_5_BASE:1.9
	OPENBSD_5_4:1.9.0.2
	OPENBSD_5_4_BASE:1.9
	OPENBSD_5_3:1.8.0.10
	OPENBSD_5_3_BASE:1.8
	OPENBSD_5_2:1.8.0.8
	OPENBSD_5_2_BASE:1.8
	OPENBSD_5_1_BASE:1.8
	OPENBSD_5_1:1.8.0.6
	OPENBSD_5_0:1.8.0.4
	OPENBSD_5_0_BASE:1.8
	OPENBSD_4_9:1.8.0.2
	OPENBSD_4_9_BASE:1.8
	OPENBSD_4_8:1.7.0.4
	OPENBSD_4_8_BASE:1.7
	OPENBSD_4_7:1.7.0.2
	OPENBSD_4_7_BASE:1.7
	OPENBSD_4_6:1.6.0.4
	OPENBSD_4_6_BASE:1.6
	OPENBSD_4_5:1.4.0.8
	OPENBSD_4_5_BASE:1.4
	OPENBSD_4_4:1.4.0.6
	OPENBSD_4_4_BASE:1.4
	OPENBSD_4_3:1.4.0.4
	OPENBSD_4_3_BASE:1.4
	OPENBSD_4_2:1.4.0.2
	OPENBSD_4_2_BASE:1.4
	OPENBSD_4_1:1.3.0.4
	OPENBSD_4_1_BASE:1.3
	OPENBSD_4_0:1.3.0.2
	OPENBSD_4_0_BASE:1.3
	OPENBSD_3_9:1.2.0.4
	OPENBSD_3_9_BASE:1.2
	OPENBSD_3_8:1.2.0.2
	OPENBSD_3_8_BASE:1.2
	OPENBSD_3_7:1.1.0.4
	OPENBSD_3_7_BASE:1.1
	OPENBSD_3_6:1.1.0.2
	OPENBSD_3_6_BASE:1.1;
locks; strict;
comment	@# @;


1.10
date	2017.03.07.14.03.22;	author visa;	state Exp;
branches;
next	1.9;
commitid	4JP9fO12Ulby6hlV;

1.9
date	2013.07.10.21.31.11;	author kettenis;	state Exp;
branches;
next	1.8;

1.8
date	2010.09.24.13.21.30;	author matthew;	state Exp;
branches;
next	1.7;

1.7
date	2009.08.13.13.24.55;	author weingart;	state Exp;
branches;
next	1.6;

1.6
date	2009.04.27.21.48.56;	author kettenis;	state Exp;
branches;
next	1.5;

1.5
date	2009.04.25.20.14.43;	author weingart;	state Exp;
branches;
next	1.4;

1.4
date	2007.05.27.18.34.01;	author art;	state Exp;
branches;
next	1.3;

1.3
date	2006.05.11.13.21.11;	author mickey;	state Exp;
branches;
next	1.2;

1.2
date	2005.04.08.07.07.06;	author jolan;	state Exp;
branches;
next	1.1;

1.1
date	2004.07.20.20.16.44;	author art;	state Exp;
branches;
next	;


desc
@@


1.10
log
@Use the pause instruction on the slow path. This improves
performance a bit.

OK mikeb@@, kettenis@@, mpi@@, tom@@, mlarkin@@
@
text
@/*	$OpenBSD: mutex.S,v 1.9 2013/07/10 21:31:11 kettenis Exp $	*/

/*
 * Copyright (c) 2004 Artur Grabowski <art@@openbsd.org>
 * All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 *
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. The name of the author may not be used to endorse or promote products
 *    derived from this software without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED ``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES,
 * INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY
 * AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL
 * THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
 * EXEMPLARY, OR CONSEQUENTIAL  DAMAGES (INCLUDING, BUT NOT LIMITED TO,
 * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS;
 * OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
 * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR
 * OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF
 * ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

#include "assym.h"
/*
 * Yeah, we don't really need to implement mtx_init here, but let's keep
 * all the functions in the same place.
 */
ENTRY(__mtx_init)
	pushl	%ebp
	movl	%esp, %ebp
	movl	8(%esp), %eax
	movl	12(%esp), %edx
	movl	%edx, MTX_WANTIPL(%eax)
	xorl	%edx, %edx
	movl	%edx, MTX_OLDIPL(%eax)
	movl	%edx, MTX_LOCK(%eax)
	movl	%edx, MTX_OWNER(%eax)
	leave
	ret

#define SOFF	8

ENTRY(mtx_enter)
	pushl	%ebp
	movl	%esp, %ebp	
1:	movl	SOFF(%ebp), %ecx
	movl	MTX_WANTIPL(%ecx), %eax
	movl	CPL, %edx		# oipl = cpl;
	cmpl	%edx, %eax		# if (cpl < mtx->mtx_wantipl)
	jle	2f
	movl	%eax, CPL		#	cpl = mtx->mtx_wantipl;
2:	/*
	 * %edx now contains the oldipl.
	 * %ecx contains the mtx.
	 */
	movl	$1, %eax
	xchgl	%eax, MTX_LOCK(%ecx)	# test_and_set(mtx->mtx_lock)
	testl	%eax, %eax		# if (already held)
	jnz	3f
	movl	CPUVAR(SELF), %eax
#ifdef DIAGNOSTIC
	incl	CPU_INFO_MUTEX_LEVEL(%eax)
#endif
	movl	%eax, MTX_OWNER(%ecx)
	movl	%edx, MTX_OLDIPL(%ecx)
	leave
	ret

	/* We failed to obtain the lock. splx, spin and retry. */
3:	pushl	%edx
	call	_C_LABEL(splx)
	movl	%ebp, %esp
	movl	SOFF(%ebp), %ecx		# %ecx clobbered
4:
	pause
#ifdef DIAGNOSTIC
	movl	CPUVAR(SELF), %edx
	cmpl	MTX_OWNER(%ecx), %edx
	je	5f
#endif
	movl	MTX_LOCK(%ecx), %eax
	testl	%eax, %eax
	jz	1b
	jmp	4b
#ifdef DIAGNOSTIC
5:	pushl	$6f
	call	_C_LABEL(panic)
6:	.asciz	"mtx_enter: locking against myself"
#endif

ENTRY(mtx_enter_try)
	pushl	%ebp
	movl	%esp, %ebp	
1:	movl	SOFF(%ebp), %ecx
	movl	MTX_WANTIPL(%ecx), %eax
	movl	CPL, %edx		# oipl = cpl;
	cmpl	%edx, %eax		# if (cpl < mtx->mtx_wantipl)
	jle	2f
	movl	%eax, CPL		#	cpl = mtx->mtx_wantipl;
2:	/*
	 * %edx now contains the oldipl.
	 * %ecx contains the mtx.
	 */
	movl	$1, %eax
	xchgl	%eax, MTX_LOCK(%ecx)	# test_and_set(mtx->mtx_lock)
	testl	%eax, %eax		# if (already held)
	jnz	3f
	movl	CPUVAR(SELF), %eax
#ifdef DIAGNOSTIC
	incl	CPU_INFO_MUTEX_LEVEL(%eax)
#endif
	movl	%eax, MTX_OWNER(%ecx)
	movl	%edx, MTX_OLDIPL(%ecx)
	movl	$1, %eax
	leave
	ret

	/* We failed to obtain the lock. splx and return zero. */
3:	pushl	%edx
	call	_C_LABEL(splx)
	movl	%ebp, %esp
	movl	SOFF(%ebp), %ecx		# %ecx clobbered
#ifdef DIAGNOSTIC
	movl	CPUVAR(SELF), %edx
	cmpl	MTX_OWNER(%ecx), %edx
	je	4f
#endif
	xorl	%eax, %eax
	leave
	ret

#ifdef DIAGNOSTIC
4:	pushl	$5f
	call	_C_LABEL(panic)
5:	.asciz	"mtx_enter_try: locking against myself"
#endif

	
ENTRY(mtx_leave)
	pushl	%ebp
	movl	%esp, %ebp
	movl	SOFF(%ebp), %ecx
#ifdef DIAGNOSTIC
	movl	CPUVAR(SELF), %eax
	cmpl	%eax, MTX_OWNER(%ecx)
	jne	1f
	decl	CPU_INFO_MUTEX_LEVEL(%eax)
#endif
	xorl	%eax, %eax
	movl	%eax, MTX_OWNER(%ecx)
	pushl	MTX_OLDIPL(%ecx)
	movl	%eax, MTX_OLDIPL(%ecx)
	movl	%eax, MTX_LOCK(%ecx)
	call	_C_LABEL(splx)
	leave
	ret

#ifdef DIAGNOSTIC
1:	pushl	$2f
	call	_C_LABEL(panic)
2:	.asciz	"mtx_leave: lock not held"
#endif
@


1.9
log
@To prevent lock ordering problems with the kernel lock, we need to make sure
we block all interrupts that can grab the kernel lock.  The simplest way to
achieve this is to make sure mutexes always raise the ipl to the highest
level that has interrupts that grab the kernel lock.  This will allow us
to have "mpsafe" interrupt handlers at lower priority levels.

No change for non-MULTIPROCESSOR kernels.

ok matthew@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mutex.S,v 1.8 2010/09/24 13:21:30 matthew Exp $	*/
d80 1
@


1.8
log
@Add stricter asserts to DIAGNOSTIC kernels to help catch mutex and
rwlock misuse.  In particular, this commit makes the following
changes:

  1. i386 and amd64 now count the number of active mutexes so that
assertwaitok(9) can detect attempts to sleep while holding a mutex.

  2. i386 and amd64 check that we actually hold mutexes when passed to
mtx_leave().

  3. Calls to rw_exit*() now call rw_assert_{rd,wr}lock() as
appropriate.

ok krw@@, oga@@; "sounds good to me" deraadt@@; assembly bits double
checked by pirofti@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mutex.S,v 1.7 2009/08/13 13:24:55 weingart Exp $	*/
d33 1
a33 1
ENTRY(mtx_init)
@


1.7
log
@A new(er) mtx_enter_try().

Ok oga@@, "the time is now" deraadt@@.
@
text
@d1 1
a1 1
/*	$OpenBSD: mutex.S,v 1.6 2009/04/27 21:48:56 kettenis Exp $	*/
d66 3
d113 3
d139 1
a139 1
5:	.asciz	"mtx_enter: locking against myself"
d147 6
d161 6
@


1.6
log
@Revert mtx_enter_try.  It didn't compile on hppa, it doesn't compile on
landisk, and the sparc implementation is obviously wrong.  That's where I
stopped looking, so who knows what else was broken.  A simple comparison of
the existing mtx_enter with the new mtx_enter_try would have told anybody.
@
text
@d1 1
a1 1
/*	$OpenBSD: mutex.S,v 1.4 2007/05/27 18:34:01 art Exp $	*/
d91 45
@


1.5
log
@Enter mtx_enter_try.  In part for completeness, things may start
using this soon(ish).  Ok oga@@, sorta yes kettenis@@.
@
text
@a90 45

ENTRY(mtx_enter_try)
	pushl	%ebp
	movl	%esp, %ebp	
1:	movl	SOFF(%ebp), %ecx
	movl	MTX_WANTIPL(%ecx), %eax
	movl	CPL, %edx		# oipl = cpl;
	cmpl	%edx, %eax		# if (cpl < mtx->mtx_wantipl)
	jle	2f
	movl	%eax, CPL		#	cpl = mtx->mtx_wantipl;
2:	/*
	 * %edx now contains the oldipl.
	 * %ecx contains the mtx.
	 */
	movl	$1, %eax
	xchgl	%eax, MTX_LOCK(%ecx)	# test_and_set(mtx->mtx_lock)
	testl	%eax, %eax		# if (already held)
	jnz	3f
	movl	CPUVAR(SELF), %eax
	movl	%eax, MTX_OWNER(%ecx)
	movl	%edx, MTX_OLDIPL(%ecx)
	movl	$1, %eax
	leave
	ret

	/* We failed to obtain the lock. splx and return zero. */
3:	pushl	%edx
	call	_C_LABEL(splx)
	movl	%ebp, %esp
	movl	SOFF(%ebp), %ecx		# %ecx clobbered
#ifdef DIAGNOSTIC
	movl	CPUVAR(SELF), %edx
	cmpl	MTX_OWNER(%ecx), %edx
	je	4f
#endif
	xorl	%eax, %eax
	leave
	ret

#ifdef DIAGNOSTIC
4:	pushl	$5f
	call	_C_LABEL(panic)
5:	.asciz	"mtx_enter: locking against myself"
#endif

@


1.4
log
@We can now access curcpu() members through %fs instead of doing it
with the complicated and expensive macros.

tom@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: mutex.S,v 1.3 2006/05/11 13:21:11 mickey Exp $	*/
d91 45
@


1.3
log
@kill trainling spaces
@
text
@d1 1
a1 1
/*	$OpenBSD: mutex.S,v 1.2 2005/04/08 07:07:06 jolan Exp $	*/
d65 1
a65 1
	GET_CPUINFO(%eax)
d78 1
a78 1
	GET_CPUINFO(%edx)
@


1.2
log
@add rcs ids
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d5 1
a5 1
 * All rights reserved. 
d7 3
a9 3
 * Redistribution and use in source and binary forms, with or without 
 * modification, are permitted provided that the following conditions 
 * are met: 
d11 2
a12 2
 * 1. Redistributions of source code must retain the above copyright 
 *    notice, this list of conditions and the following disclaimer. 
d14 1
a14 1
 *    derived from this software without specific prior written permission. 
d25 1
a25 1
 * ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. 
@


1.1
log
@MD mutex implementation for i386.
@
text
@d1 2
@

