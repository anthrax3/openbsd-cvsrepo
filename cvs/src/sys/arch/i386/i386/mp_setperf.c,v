head	1.6;
access;
symbols
	OPENBSD_6_2:1.6.0.14
	OPENBSD_6_2_BASE:1.6
	OPENBSD_6_1:1.6.0.12
	OPENBSD_6_1_BASE:1.6
	OPENBSD_6_0:1.6.0.8
	OPENBSD_6_0_BASE:1.6
	OPENBSD_5_9:1.6.0.4
	OPENBSD_5_9_BASE:1.6
	OPENBSD_5_8:1.6.0.6
	OPENBSD_5_8_BASE:1.6
	OPENBSD_5_7:1.6.0.2
	OPENBSD_5_7_BASE:1.6
	OPENBSD_5_6:1.5.0.4
	OPENBSD_5_6_BASE:1.5
	OPENBSD_5_5:1.4.0.18
	OPENBSD_5_5_BASE:1.4
	OPENBSD_5_4:1.4.0.14
	OPENBSD_5_4_BASE:1.4
	OPENBSD_5_3:1.4.0.12
	OPENBSD_5_3_BASE:1.4
	OPENBSD_5_2:1.4.0.10
	OPENBSD_5_2_BASE:1.4
	OPENBSD_5_1_BASE:1.4
	OPENBSD_5_1:1.4.0.8
	OPENBSD_5_0:1.4.0.6
	OPENBSD_5_0_BASE:1.4
	OPENBSD_4_9:1.4.0.4
	OPENBSD_4_9_BASE:1.4
	OPENBSD_4_8:1.4.0.2
	OPENBSD_4_8_BASE:1.4
	OPENBSD_4_7:1.3.0.2
	OPENBSD_4_7_BASE:1.3
	OPENBSD_4_6:1.3.0.4
	OPENBSD_4_6_BASE:1.3
	OPENBSD_4_5:1.2.0.8
	OPENBSD_4_5_BASE:1.2
	OPENBSD_4_4:1.2.0.6
	OPENBSD_4_4_BASE:1.2
	OPENBSD_4_3:1.2.0.4
	OPENBSD_4_3_BASE:1.2
	OPENBSD_4_2:1.2.0.2
	OPENBSD_4_2_BASE:1.2;
locks; strict;
comment	@ * @;


1.6
date	2014.09.12.09.52.45;	author kettenis;	state Exp;
branches;
next	1.5;
commitid	fg3shv1MuGeLLh3b;

1.5
date	2014.06.29.01.01.20;	author deraadt;	state Exp;
branches;
next	1.4;
commitid	JGrnYVidTgBVOphO;

1.4
date	2010.04.20.22.05.41;	author tedu;	state Exp;
branches;
next	1.3;

1.3
date	2009.06.06.20.37.45;	author gwk;	state Exp;
branches;
next	1.2;

1.2
date	2007.05.01.04.18.32;	author gwk;	state Exp;
branches;
next	1.1;

1.1
date	2007.04.21.21.06.14;	author gwk;	state Exp;
branches;
next	;


desc
@@


1.6
log
@Remove the code that attempts to synchronize P-state transitions between CPUs.
Spinning inside an IPI handler is generally a bad idea as it is very hard to
avoid deadlocks.  As far as I can tell the synchronization isn't necessary.
Multi-core CPUs have hardware mechanisms to do the appropropriate coordination
between cores and coordination between sockets isn't necessary either.

This seems to fix the various hangs and suspend/resume failures that people
have been seeing when running apmd -A or apmd -C.

Tested by many.
ok kspillner@@, mpi@@
@
text
@/* $OpenBSD: mp_setperf.c,v 1.5 2014/06/29 01:01:20 deraadt Exp $ */
/*
 * Copyright (c) 2007 Gordon Willem Klok <gwk@@openbsd.org>
 *
 * Permission to use, copy, modify, and distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 */

#include <sys/param.h>
#include <sys/systm.h>
#include <sys/sysctl.h>
#include <sys/mutex.h>

#include <machine/cpu.h>
#include <machine/intr.h>

struct mutex setperf_mp_mutex = MUTEX_INITIALIZER(IPL_HIGH);

/* underlying setperf mechanism e.g. k8_powernow_setperf() */
void (*ul_setperf)(int);

/* protected by setperf_mp_mutex */
volatile int mp_perflevel;

void mp_setperf(int);

void
mp_setperf(int level)
{
	mtx_enter(&setperf_mp_mutex);
	mp_perflevel = level;

	ul_setperf(mp_perflevel);
	i386_broadcast_ipi(I386_IPI_SETPERF);
	mtx_leave(&setperf_mp_mutex);
}

void
i386_setperf_ipi(struct cpu_info *ci)
{
	ul_setperf(mp_perflevel);
}

void
mp_setperf_init(void)
{
	if (!cpu_setperf)
		return;

	ul_setperf = cpu_setperf;
	cpu_setperf = mp_setperf;
	mtx_init(&setperf_mp_mutex, IPL_HIGH);
}
@


1.5
log
@Don't ridiculously assume that sysctl.h will (through a set of extremely
unfortunate circumstances) pull machine/cpufunc.h
@
text
@d1 1
a1 1
/* $OpenBSD: mp_setperf.c,v 1.4 2010/04/20 22:05:41 tedu Exp $ */
a19 1
#include <sys/proc.h>
a23 2
#include <machine/cpufunc.h>

a30 6
#define MP_SETPERF_STEADY 	0	/* steady state - normal operation */
#define MP_SETPERF_INTRANSIT 	1	/* in transition */
#define MP_SETPERF_PROCEED 	2	/* proceed with transition */
#define MP_SETPERF_FINISH 	3	/* return from IPI */


a31 1
volatile int mp_setperf_state = MP_SETPERF_STEADY;
d39 2
a40 56
	CPU_INFO_ITERATOR cii;
	struct cpu_info *ci;
	int notready, s;

	if (mp_setperf_state == MP_SETPERF_STEADY) {
		mtx_enter(&setperf_mp_mutex);
		disable_intr();

		mp_perflevel = level;

		curcpu()->ci_setperf_state = CI_SETPERF_INTRANSIT;
		/* ask all other processors to drop what they are doing */
		CPU_INFO_FOREACH(cii, ci) {
			if (ci->ci_setperf_state != CI_SETPERF_INTRANSIT) {
				ci->ci_setperf_state =
				    CI_SETPERF_SHOULDSTOP;
				i386_send_ipi(ci, I386_IPI_SETPERF);
			}
		}


		/* Loop until all processors report ready */
		do {
			CPU_INFO_FOREACH(cii, ci) {
				if ((notready = (ci->ci_setperf_state
				    != CI_SETPERF_INTRANSIT)))
					break;
			}
		} while (notready);

		mp_setperf_state = MP_SETPERF_PROCEED; /* release the hounds */

		s = splipi();

		ul_setperf(mp_perflevel);

		splx(s);

		curcpu()->ci_setperf_state = CI_SETPERF_DONE;
		/* Loop until all processors report done */
		do {
			CPU_INFO_FOREACH(cii, ci) {
				if ((notready = (ci->ci_setperf_state
				    != CI_SETPERF_DONE)))
					break;
			}
		} while (notready);

		mp_setperf_state = MP_SETPERF_FINISH;
		/* delay a little for potential straglers */
		DELAY(2);
		curcpu()->ci_setperf_state = CI_SETPERF_READY;
		mp_setperf_state = MP_SETPERF_STEADY; /* restore normallity */
		enable_intr();
		mtx_leave(&setperf_mp_mutex);
	}
d42 3
a49 9

	disable_intr();

	if (ci->ci_setperf_state == CI_SETPERF_SHOULDSTOP)
		ci->ci_setperf_state = CI_SETPERF_INTRANSIT;

	while (mp_setperf_state != MP_SETPERF_PROCEED)
		;

a50 8

	ci->ci_setperf_state = CI_SETPERF_DONE;

	while (mp_setperf_state != MP_SETPERF_FINISH)
		;
	ci->ci_setperf_state = CI_SETPERF_READY;

	enable_intr();
d54 1
a54 1
mp_setperf_init()
a55 3
	CPU_INFO_ITERATOR cii;
	struct cpu_info *ci;

d58 1
a59 1

a60 4

	CPU_INFO_FOREACH(cii, ci) {
		ci->ci_setperf_state = CI_SETPERF_READY;
	}
@


1.4
log
@remove proc.h include from uvm_map.h.  This has far reaching effects, as
sysctl.h was reliant on this particular include, and many drivers included
sysctl.h unnecessarily.  remove sysctl.h or add proc.h as needed.
ok deraadt
@
text
@d1 1
a1 1
/* $OpenBSD: mp_setperf.c,v 1.3 2009/06/06 20:37:45 gwk Exp $ */
d25 1
@


1.3
log
@Disable interrupts durring the lock step frequency/voltage change. Generic
IPIs are handled without blocking interrupts. This solves the random lockups
people have been seeing with apmd -C, thanks to marco@@ for showing me how
to reliably recreate this hang, and claudio@@ for telling me it was also
affecting his Athlon64 machine so I stopped chasing bugs in est.

ok oga@@, weingart@@
@
text
@d1 1
a1 1
/* $OpenBSD: mp_setperf.c,v 1.2 2007/05/01 04:18:32 gwk Exp $ */
d20 1
@


1.2
log
@Missing RCS tag.
@
text
@d1 1
a1 1
/* $OpenBSD$ */
d53 2
d100 1
d110 2
d125 2
a133 1

@


1.1
log
@Introduce a smp aware hw.setperf mechanism, it will scale all CPUs or
cores by the same amount, i.e. if you do hw.setperf=50 both cores will
be scaled to the opearting state corresponing to 50%. Tested by many with
est (mainly on core2duo machines like X60 thinkpads). Only enable est
during GENERIC.MP build no one tested powernow.

ok art@@
@
text
@d1 1
@

