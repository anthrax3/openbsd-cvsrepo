head	1.31;
access;
symbols
	OPENBSD_4_9:1.30.0.2
	OPENBSD_4_9_BASE:1.30
	OPENBSD_4_8:1.29.0.6
	OPENBSD_4_8_BASE:1.29
	OPENBSD_4_7:1.29.0.2
	OPENBSD_4_7_BASE:1.29
	OPENBSD_4_6:1.29.0.4
	OPENBSD_4_6_BASE:1.29
	OPENBSD_4_5:1.23.0.2
	OPENBSD_4_5_BASE:1.23
	OPENBSD_4_4:1.22.0.2
	OPENBSD_4_4_BASE:1.22
	OPENBSD_4_3:1.21.0.2
	OPENBSD_4_3_BASE:1.21
	OPENBSD_4_2:1.20.0.2
	OPENBSD_4_2_BASE:1.20
	OPENBSD_4_1:1.18.0.2
	OPENBSD_4_1_BASE:1.18
	OPENBSD_4_0:1.16.0.2
	OPENBSD_4_0_BASE:1.16
	OPENBSD_3_9:1.16.0.4
	OPENBSD_3_9_BASE:1.16
	OPENBSD_3_8:1.13.0.2
	OPENBSD_3_8_BASE:1.13;
locks; strict;
comment	@ * @;


1.31
date	2011.04.02.18.16.50;	author oga;	state dead;
branches;
next	1.30;

1.30
date	2010.09.10.21.37.03;	author kettenis;	state Exp;
branches;
next	1.29;

1.29
date	2009.05.04.16.48.37;	author oga;	state Exp;
branches;
next	1.28;

1.28
date	2009.04.21.17.05.29;	author oga;	state Exp;
branches;
next	1.27;

1.27
date	2009.04.15.23.53.22;	author oga;	state Exp;
branches;
next	1.26;

1.26
date	2009.03.11.23.38.51;	author oga;	state Exp;
branches;
next	1.25;

1.25
date	2009.03.10.23.28.42;	author oga;	state Exp;
branches;
next	1.24;

1.24
date	2009.03.10.15.03.17;	author oga;	state Exp;
branches;
next	1.23;

1.23
date	2008.12.03.15.46.06;	author oga;	state Exp;
branches;
next	1.22;

1.22
date	2008.04.28.06.17.47;	author brad;	state Exp;
branches;
next	1.21;

1.21
date	2007.09.17.15.34.38;	author chl;	state Exp;
branches;
next	1.20;

1.20
date	2007.05.27.21.44.23;	author jason;	state Exp;
branches;
next	1.19;

1.19
date	2007.05.27.21.08.07;	author jason;	state Exp;
branches;
next	1.18;

1.18
date	2007.02.09.04.48.10;	author jason;	state Exp;
branches;
next	1.17;

1.17
date	2007.02.09.02.58.10;	author jason;	state Exp;
branches;
next	1.16;

1.16
date	2005.09.29.21.30.42;	author marco;	state Exp;
branches;
next	1.15;

1.15
date	2005.09.27.17.41.12;	author marco;	state Exp;
branches;
next	1.14;

1.14
date	2005.09.27.17.37.30;	author marco;	state Exp;
branches;
next	1.13;

1.13
date	2005.06.17.19.25.39;	author marco;	state Exp;
branches;
next	1.12;

1.12
date	2005.06.08.04.21.24;	author marc;	state Exp;
branches;
next	1.11;

1.11
date	2005.06.07.16.40.31;	author deraadt;	state Exp;
branches;
next	1.10;

1.10
date	2005.06.06.15.10.20;	author jason;	state Exp;
branches;
next	1.9;

1.9
date	2005.06.02.15.26.03;	author jason;	state Exp;
branches;
next	1.8;

1.8
date	2005.05.27.23.48.24;	author jason;	state Exp;
branches;
next	1.7;

1.7
date	2005.05.27.21.44.54;	author art;	state Exp;
branches;
next	1.6;

1.6
date	2005.05.27.18.37.07;	author jason;	state Exp;
branches;
next	1.5;

1.5
date	2005.05.27.07.46.38;	author jason;	state Exp;
branches;
next	1.4;

1.4
date	2005.05.27.06.40.45;	author jason;	state Exp;
branches;
next	1.3;

1.3
date	2005.05.27.06.27.43;	author jason;	state Exp;
branches;
next	1.2;

1.2
date	2005.05.26.19.47.44;	author jason;	state Exp;
branches;
next	1.1;

1.1
date	2005.05.26.17.48.20;	author jason;	state Exp;
branches;
next	;


desc
@@


1.31
log
@Remove the AMD GART based iommu code.

With current strategies to put memory in the ``correct'' place it isn't
needed.  There's also the problem that it did not work on all machines,
failing completely on some and utterly breaking DMA. So just remove it.
If anyone needs it it will be in the Attic.

ok deraadt@@
@
text
@/*	$OpenBSD: iommu.c,v 1.30 2010/09/10 21:37:03 kettenis Exp $	*/

/*
 * Copyright (c) 2005 Jason L. Wright (jason@@thought.net)
 * All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 *
 * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR
 * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
 * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 * DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT,
 * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
 * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,
 * STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN
 * ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
 * POSSIBILITY OF SUCH DAMAGE.
 */

#include <sys/types.h>
#include <sys/param.h>
#include <sys/time.h>
#include <sys/systm.h>
#include <sys/errno.h>
#include <sys/device.h>
#include <sys/lock.h>
#include <sys/malloc.h>

#include <uvm/uvm_extern.h>

#include <machine/bus.h>

#include <machine/pio.h>
#include <machine/intr.h>

#include <dev/isa/isareg.h>
#include <dev/isa/isavar.h>
#include <dev/pci/pcivar.h>
#include <dev/pci/pcireg.h>
#include <dev/pci/pcidevs.h>

#define	MCANB_CTRL	0x40		/* Machine Check, NorthBridge */
#define	SCRUB_CTRL	0x58		/* dram/l2/dcache */
#define	GART_APCTRL	0x90		/* aperture control */
#define	GART_APBASE	0x94		/* aperture base */
#define	GART_TBLBASE	0x98		/* aperture table base */
#define	GART_CACHECTRL	0x9c		/* aperture cache control */

#define	MCANB_CORRECCEN		0x00000001	/* correctable ecc error */
#define	MCANB_UNCORRECCEN	0x00000002	/* uncorrectable ecc error */
#define	MCANB_CRCERR0EN		0x00000004	/* hypertrans link 0 crc */
#define	MCANB_CRCERR1EN		0x00000008	/* hypertrans link 1 crc */
#define	MCANB_CRCERR2EN		0x00000010	/* hypertrans link 2 crc */
#define	MCANB_SYNCPKT0EN	0x00000020	/* hypertrans link 0 sync */
#define	MCANB_SYNCPKT1EN	0x00000040	/* hypertrans link 1 sync */
#define	MCANB_SYNCPKT2EN	0x00000080	/* hypertrans link 2 sync */
#define	MCANB_MSTRABRTEN	0x00000100	/* master abort error */
#define	MCANB_TGTABRTEN		0x00000200	/* target abort error */
#define	MCANB_GARTTBLWKEN	0x00000400	/* gart table walk error */
#define	MCANB_ATOMICRMWEN	0x00000800	/* atomic r/m/w error */
#define	MCANB_WCHDOGTMREN	0x00001000	/* watchdog timer error */

#define	GART_APCTRL_ENABLE	0x00000001	/* enable */
#define	GART_APCTRL_SIZE	0x0000000e	/* size mask */
#define	GART_APCTRL_SIZE_32M	0x00000000	/*  32M */
#define	GART_APCTRL_SIZE_64M	0x00000002	/*  64M */
#define	GART_APCTRL_SIZE_128M	0x00000004	/*  128M */
#define	GART_APCTRL_SIZE_256M	0x00000006	/*  256M */
#define	GART_APCTRL_SIZE_512M	0x00000008	/*  512M */
#define	GART_APCTRL_SIZE_1G	0x0000000a	/*  1G */
#define	GART_APCTRL_SIZE_2G	0x0000000c	/*  2G */
#define	GART_APCTRL_DISCPU	0x00000010	/* disable CPU access */
#define	GART_APCTRL_DISIO	0x00000020	/* disable IO access */
#define	GART_APCTRL_DISTBL	0x00000040	/* disable table walk probe */

#define	GART_APBASE_MASK	0x00007fff	/* base [39:25] */

#define	GART_TBLBASE_MASK	0xfffffff0	/* table base [39:12] */

#define	GART_PTE_VALID		0x00000001	/* valid */
#define	GART_PTE_COHERENT	0x00000002	/* coherent */
#define	GART_PTE_PHYSHI		0x00000ff0	/* phys addr[39:32] */
#define	GART_PTE_PHYSLO		0xfffff000	/* phys addr[31:12] */

#define	GART_CACHE_INVALIDATE	0x00000001	/* invalidate (s/c) */
#define	GART_CACHE_PTEERR	0x00000002	/* pte error */

#define	IOMMU_START		0x80000000	/* beginning */
#define	IOMMU_END		0xffffffff	/* end */
#define	IOMMU_SIZE		512		/* size in MB */
#define	IOMMU_ALIGN		IOMMU_SIZE

int amdgart_enable = 0;

#ifndef SMALL_KERNEL /* no bigmem in ramdisks */

struct amdgart_softc {
	pci_chipset_tag_t	 g_pc;
	paddr_t			 g_pa;
	paddr_t			 g_scribpa;
	void			*g_scrib;
	u_int32_t		 g_scribpte;
	u_int32_t		*g_pte;
	bus_dma_tag_t		 g_dmat;
	int			 g_count;
	pcitag_t		 g_tags[1];
};

void	amdgart_probe(struct pcibus_attach_args *);
void	amdgart_dumpregs(struct amdgart_softc *);
int	amdgart_ok(pci_chipset_tag_t, pcitag_t);
int	amdgart_enabled(pci_chipset_tag_t, pcitag_t);
void	amdgart_initpt(struct amdgart_softc *, u_long);
void	amdgart_bind_page(void *, bus_addr_t, paddr_t,  int);
void	amdgart_unbind_page(void *, bus_addr_t);
void	amdgart_invalidate(void *);
void	amdgart_invalidate_wait(struct amdgart_softc *);

struct bus_dma_tag amdgart_bus_dma_tag = {
	NULL,			/* _may_bounce */
	sg_dmamap_create,
	sg_dmamap_destroy,
	sg_dmamap_load,
	sg_dmamap_load_mbuf,
	sg_dmamap_load_uio,
	sg_dmamap_load_raw,
	sg_dmamap_unload,
	_bus_dmamap_sync,
	sg_dmamem_alloc,
	_bus_dmamem_free,
	_bus_dmamem_map,
	_bus_dmamem_unmap,
	_bus_dmamem_mmap,
};

void
amdgart_bind_page(void *handle, bus_addr_t offset, paddr_t page,  int flags)
{
	struct amdgart_softc	*sc = handle;
	u_int32_t		 pgno, pte;

	pgno = (offset - sc->g_pa) >> PGSHIFT;
	pte = GART_PTE_VALID | GART_PTE_COHERENT |
	    ((page >> 28) & GART_PTE_PHYSHI) | (page & GART_PTE_PHYSLO);
	sc->g_pte[pgno] = pte;
}

void
amdgart_unbind_page(void *handle, bus_addr_t offset)
{
	struct amdgart_softc	*sc = handle;
	u_int32_t		 pgno;

	pgno = (offset - sc->g_pa) >> PGSHIFT;
	sc->g_pte[pgno] = sc->g_scribpte;
}

void
amdgart_invalidate_wait(struct amdgart_softc *sc)
{
	int	i, n;

	for (n = 0; n < sc->g_count; n++) {
		for (i = 1000; i > 0; i--) {
			if ((pci_conf_read(sc->g_pc, sc->g_tags[n],
			    GART_CACHECTRL) & GART_CACHE_INVALIDATE) == 0)
				break;
			delay(1);
		}
		if (i == 0)
			printf("GART%d: timeout\n", n);
	}
}

void
amdgart_invalidate(void* handle)
{
	struct amdgart_softc	*sc = handle;
	int n;

	for (n = 0; n < sc->g_count; n++)
		pci_conf_write(sc->g_pc, sc->g_tags[n], GART_CACHECTRL,
		    GART_CACHE_INVALIDATE);
	amdgart_invalidate_wait(sc);
}

void
amdgart_dumpregs(struct amdgart_softc *sc)
{
	int n, i, dirty = 0;
	u_int8_t *p;

	for (n = 0; n < sc->g_count; n++) {
		printf("GART%d:\n", n);
		printf(" apctl %x\n", pci_conf_read(sc->g_pc, sc->g_tags[n],
		    GART_APCTRL));
		printf(" apbase %x\n", pci_conf_read(sc->g_pc, sc->g_tags[n],
		    GART_APBASE));
		printf(" tblbase %x\n", pci_conf_read(sc->g_pc, sc->g_tags[n],
		    GART_TBLBASE));
		printf(" cachectl %x\n", pci_conf_read(sc->g_pc, sc->g_tags[n],
		    GART_CACHECTRL));

	}
	p = sc->g_scrib;
	for (i = 0; i < PAGE_SIZE; i++, p++)
		if (*p != '\0')
			dirty++;
	printf(" scribble: %s\n", dirty ? "dirty" : "clean");
}

int
amdgart_ok(pci_chipset_tag_t pc, pcitag_t tag)
{
	pcireg_t v;

	v = pci_conf_read(pc, tag, PCI_ID_REG);
	if (PCI_VENDOR(v) == PCI_VENDOR_AMD &&
	    (PCI_PRODUCT(v) == PCI_PRODUCT_AMD_AMD64_0F_MISC ||
	    PCI_PRODUCT(v) == PCI_PRODUCT_AMD_AMD64_10_MISC))
		return (1);
	return (0);
}

int
amdgart_enabled(pci_chipset_tag_t pc, pcitag_t tag)
{
	return (pci_conf_read(pc, tag, GART_APCTRL) & GART_APCTRL_ENABLE);
}

static const struct gart_size {
	pcireg_t	reg;
	bus_size_t	size;
} apsizes[] = {
	{ GART_APCTRL_SIZE_32M, 32 },
	{ GART_APCTRL_SIZE_64M, 64 },
	{ GART_APCTRL_SIZE_128M, 128 },
	{ GART_APCTRL_SIZE_256M, 256 },
	{ GART_APCTRL_SIZE_512M, 512 },
	{ GART_APCTRL_SIZE_1G, 1024 },
	{ GART_APCTRL_SIZE_2G, 2048 },
};

void
amdgart_probe(struct pcibus_attach_args *pba)
{
	struct amdgart_softc	*sc;
	struct sg_cookie	*cookie = NULL;
	void			*scrib = NULL;
	u_int32_t		*pte;
	int			 dev, count = 0, encount = 0, r, nseg;
	u_long			 mapsize, ptesize, gartsize = 0;
	bus_dma_segment_t	 seg;
	pcitag_t		 tag;
	pcireg_t		 v;
	paddr_t			 pa, ptepa;

	if (amdgart_enable == 0)
		return;

	/* Function is always three */
	for (count = 0, dev = 24; dev < 32; dev++) {
		tag = pci_make_tag(pba->pba_pc, 0, dev, 3);

		if (!amdgart_ok(pba->pba_pc, tag))
			continue;
		count++;
		if (amdgart_enabled(pba->pba_pc, tag)) {
			encount++;
			pa = pci_conf_read(pba->pba_pc, tag,
			    GART_APBASE) << 25;
			v = pci_conf_read(pba->pba_pc, tag,
			    GART_APCTRL) & GART_APCTRL_SIZE;
		}
	}

	if (count == 0)
		return;

	if (encount > 0 && encount != count) {
		printf("\niommu: holy mismatched enabling, batman!\n");
		return;
	}

	sc = malloc(sizeof(*sc) + (sizeof(pcitag_t) * (count - 1)),
	    M_DEVBUF, M_NOWAIT | M_ZERO);
	if (sc == NULL) {
		printf("\nGART: can't get softc");
		return;
	}

	if (encount > 0) {
		int i;
		/*
		 * GART exists, use the current value.
		 *
		 * It appears that the bios mentions this in it's memory map
		 * (sample size of 1), so we don't need to allocate
		 * address space for it.
		 */
		sc->g_pa = pa;
		for (i = 0; i < nitems(apsizes); i++)
			if (apsizes[i].reg == v)
				gartsize = apsizes[i].size;
		if (gartsize == 0) {
			printf("iommu: strange size\n");
			free(sc, M_DEVBUF);
			return;
		}

		mapsize = gartsize * 1024 * 1024;
	} else {
		/* We've gotta allocate one. Heuristic time! */
		/*
		 * XXX right now we stuff the iommu where we want. this need
		 * XXX changing to allocate from pci space.
		 */
		sc->g_pa = IOMMU_START;
		gartsize = IOMMU_SIZE;
	}

	mapsize = gartsize * 1024 * 1024;
	ptesize = mapsize / (PAGE_SIZE / sizeof(u_int32_t));

	/*
	 * use the low level version so we know we get memory we can use.
	 * Hardware can deal with up to 40bits, which should be all our memory,
	 * be safe anyway.
	 */
	r = _bus_dmamem_alloc_range(pba->pba_dmat, ptesize, ptesize, ptesize,
	    &seg, 1, &nseg, BUS_DMA_NOWAIT, ptesize, 0x4000000000);
	if (r != 0) {
		printf("\nGART: failed to get pte pages");
		goto nofreeseg;
	}

	r = _bus_dmamem_map(pba->pba_dmat, &seg, 1, ptesize, (caddr_t *)&pte,
	    BUS_DMA_NOWAIT | BUS_DMA_NOCACHE);
	if (r != 0) {
		printf("\nGART: failed to map pte pages");
		goto err;
	}
	ptepa = seg.ds_addr;

	scrib = malloc(PAGE_SIZE, M_DEVBUF, M_NOWAIT|M_ZERO);
	if (scrib == NULL) {
		printf("\nGART: didn't get scribble page");
		goto err;
	}
	sc->g_pc = pba->pba_pc;
	pmap_extract(pmap_kernel(), (vaddr_t)scrib,
	    &sc->g_scribpa);
	sc->g_scrib = scrib;
	sc->g_scribpte = GART_PTE_VALID | GART_PTE_COHERENT |
	    ((sc->g_scribpa >> 28) & GART_PTE_PHYSHI) |
	    (sc->g_scribpa & GART_PTE_PHYSLO);
	sc->g_pte = pte;
	sc->g_dmat = pba->pba_dmat;

	if ((cookie = sg_dmatag_init("iommu", sc, sc->g_pa, mapsize,
	    amdgart_bind_page, amdgart_unbind_page,
	    amdgart_invalidate)) == NULL) {
		printf("\nGART: didn't get dma cookie\n");
		goto err;
	}

	for (count = 0, dev = 24; dev < 32; dev++) {
		tag = pci_make_tag(pba->pba_pc, 0, dev, 3);

		if (!amdgart_ok(pba->pba_pc, tag))
			continue;

		v = pci_conf_read(pba->pba_pc, tag, GART_APCTRL);
		v |= GART_APCTRL_DISCPU | GART_APCTRL_DISTBL |
		    GART_APCTRL_DISIO;
		v &= ~(GART_APCTRL_ENABLE | GART_APCTRL_SIZE);
		switch (gartsize) {
		case 32:
			v |= GART_APCTRL_SIZE_32M;
			break;
		case 64:
			v |= GART_APCTRL_SIZE_64M;
			break;
		case 128:
			v |= GART_APCTRL_SIZE_128M;
			break;
		case 256:
			v |= GART_APCTRL_SIZE_256M;
			break;
		case 512:
			v |= GART_APCTRL_SIZE_512M;
			break;
		case 1024:
			v |= GART_APCTRL_SIZE_1G;
			break;
		case 2048:
			v |= GART_APCTRL_SIZE_2G;
			break;
		default:
			printf("\nGART: bad size");
			return;
		}
		pci_conf_write(pba->pba_pc, tag, GART_APCTRL, v);

		pci_conf_write(pba->pba_pc, tag, GART_APBASE,
		    sc->g_pa >> 25);

		pci_conf_write(pba->pba_pc, tag, GART_TBLBASE,
		    (ptepa >> 8) & GART_TBLBASE_MASK);

		v = pci_conf_read(pba->pba_pc, tag, GART_APCTRL);
		v |= GART_APCTRL_ENABLE;
		v &= ~GART_APCTRL_DISIO;
		pci_conf_write(pba->pba_pc, tag, GART_APCTRL, v);

		sc->g_tags[count] = tag;

		printf("\niommu%d at cpu%d: base 0x%lx length %dMB"
		    " pte 0x%lx", count, dev - 24, sc->g_pa,
		    gartsize, ptepa);
		count++;
	}
	amdgart_initpt(sc, ptesize / sizeof(*sc->g_pte));
	sc->g_count = count;

	amdgart_bus_dma_tag._cookie = cookie;
	pba->pba_dmat = &amdgart_bus_dma_tag;

	return;

err:
	_bus_dmamem_free(pba->pba_dmat, &seg, 1);
nofreeseg:
	if (scrib != NULL)
		free(scrib, M_DEVBUF);
	if (cookie != NULL)
		sg_dmatag_destroy(cookie);
	if (sc != NULL)
		free(sc, M_DEVBUF);
}

void
amdgart_initpt(struct amdgart_softc *sc, u_long nent)
{
	u_long i;

	for (i = 0; i < nent; i++)
		sc->g_pte[i] = sc->g_scribpte;
	amdgart_invalidate(sc);
}

#endif /* !SMALL_KERNEL */
@


1.30
log
@Provide a bus_dmamap_sync() implementation for the IOMMU.  Fixes bigmem.

tested by naddy@@, ok dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: iommu.c,v 1.29 2009/05/04 16:48:37 oga Exp $	*/
@


1.29
log
@type pedantry.

the type we bind to an iommu or a GART is paddr_t, by definition, on the
other hand, the type we get out of it is not a vaddr_t, it's bus_addr_t.

fix up sparc64 iommu, amd64 iommu and the sg_dma backedn that uses it to
realise this.

ok kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: iommu.c,v 1.28 2009/04/21 17:05:29 oga Exp $	*/
d137 1
a137 1
	NULL,
@


1.28
log
@add a sg_dma backend for amd64 bus_dma. This is a lot more clever about
mapping to the gart than the old code, and shouldn't conflict with
bouncebuffers when they're added.

This is essentially the sparc64 iommu code that's been modularised a bit
so I can eventually use the same code for agp-based dma for memory
managed drm drivers.

Now, this would overflow ramdiskA, so iommu and sg_dma are now #ifndef
SMALL_KERNEL.

ok kettenis@@, marco@@. SMALL_KERNEL discussions with deraadt.
@
text
@d1 1
a1 1
/*	$OpenBSD: iommu.c,v 1.27 2009/04/15 23:53:22 oga Exp $	*/
d123 2
a124 2
void	amdgart_bind_page(void *, vaddr_t, paddr_t,  int);
void	amdgart_unbind_page(void *, vaddr_t);
d146 1
a146 1
amdgart_bind_page(void *handle, vaddr_t offset, paddr_t page,  int flags)
d158 1
a158 1
amdgart_unbind_page(void *handle, vaddr_t offset)
@


1.27
log
@The current iommu code only touches the hardware if the bios did not
enable it (I have found the code that does enable it problematic on
quite a few machines, however, that's a different issue). So provide
some code that so if the bios initialised the iommu for us, we'll use
what it gave us. Makes iommu work on a machine of todd's.

while i'm here, we don't need to scan all pci functoins to find the
hypertransport bridge. the gart is always on function 3, so just scan
for all the bridges and not iterate over the functions too.

Thanks to todd for his infinite patience while I gave him diffs that
went ``Boom!''.
@
text
@d1 1
a1 1
/*	$OpenBSD: iommu.c,v 1.26 2009/03/11 23:38:51 oga Exp $	*/
a35 1
#include <sys/extent.h>
d102 1
a102 2
extern paddr_t avail_end;
extern struct extent *iomem_ex;
d104 1
a104 1
int amdgart_enable = 0;
a107 1
	struct extent		*g_ex;
d118 9
a126 33
void amdgart_invalidate_wait(struct amdgart_softc *);
void amdgart_invalidate(struct amdgart_softc *);
void amdgart_probe(struct pcibus_attach_args *);
void amdgart_dumpregs(struct amdgart_softc *);
int amdgart_iommu_map(struct amdgart_softc *, bus_dmamap_t,
        bus_dma_segment_t *);
int amdgart_iommu_unmap(struct amdgart_softc *, bus_dma_segment_t *);
int amdgart_reload(struct amdgart_softc *, bus_dmamap_t);
int amdgart_ok(pci_chipset_tag_t, pcitag_t);
int amdgart_enabled(pci_chipset_tag_t, pcitag_t);
void amdgart_initpt(struct amdgart_softc *, u_long);

int amdgart_dmamap_create(bus_dma_tag_t, bus_size_t, int, bus_size_t,
    bus_size_t, int, bus_dmamap_t *);
void amdgart_dmamap_destroy(bus_dma_tag_t, bus_dmamap_t);
int amdgart_dmamap_load(bus_dma_tag_t, bus_dmamap_t, void *, bus_size_t,
    struct proc *, int);
int amdgart_dmamap_load_mbuf(bus_dma_tag_t, bus_dmamap_t, struct mbuf *, int);
int amdgart_dmamap_load_uio(bus_dma_tag_t, bus_dmamap_t, struct uio *, int);
int amdgart_dmamap_load_raw(bus_dma_tag_t, bus_dmamap_t,
    bus_dma_segment_t *, int, bus_size_t, int);
void amdgart_dmamap_unload(bus_dma_tag_t, bus_dmamap_t);
void amdgart_dmamap_sync(bus_dma_tag_t, bus_dmamap_t, bus_addr_t,
    bus_size_t, int);

int amdgart_dmamem_alloc(bus_dma_tag_t, bus_size_t, bus_size_t, bus_size_t,
    bus_dma_segment_t *, int, int *, int);
void amdgart_dmamem_free(bus_dma_tag_t, bus_dma_segment_t *, int);
int amdgart_dmamem_map(bus_dma_tag_t, bus_dma_segment_t *, int, size_t,
    caddr_t *, int);
void amdgart_dmamem_unmap(bus_dma_tag_t, caddr_t, size_t);
paddr_t amdgart_dmamem_mmap(bus_dma_tag_t, bus_dma_segment_t *, int, off_t,
    int, int);
d130 7
a136 7
	amdgart_dmamap_create,
	amdgart_dmamap_destroy,
	amdgart_dmamap_load,
	amdgart_dmamap_load_mbuf,
	amdgart_dmamap_load_uio,
	amdgart_dmamap_load_raw,
	amdgart_dmamap_unload,
d138 5
a142 5
	amdgart_dmamem_alloc,
	amdgart_dmamem_free,
	amdgart_dmamem_map,
	amdgart_dmamem_unmap,
	amdgart_dmamem_mmap,
d146 22
d185 1
a185 1
amdgart_invalidate(struct amdgart_softc *sc)
d187 1
d256 10
a265 10
	struct amdgart_softc *sc;
	int dev, count = 0, encount = 0, r, nseg;
	u_long mapsize, ptesize, gartsize = 0;
	bus_dma_segment_t seg;
	pcitag_t tag;
	pcireg_t v;
	paddr_t pa;
	void *scrib = NULL;
	u_int32_t *pte = NULL;
	paddr_t ptepa;
a353 7
	sc->g_ex = extent_create("iommu", sc->g_pa, sc->g_pa + mapsize - 1,
	    M_DEVBUF, NULL, NULL, EX_NOWAIT | EX_NOCOALESCE);
	if (sc->g_ex == NULL) {
		printf("\nGART: extent create failed");
		goto err;
	}

d369 7
d435 1
a435 1
	amdgart_bus_dma_tag._cookie = sc;
a442 2
	if (sc->g_ex != NULL)
		extent_destroy(sc->g_ex);
d445 2
d461 1
a461 253
int
amdgart_reload(struct amdgart_softc *sc, bus_dmamap_t dmam)
{
	int i, j, err;

	for (i = 0; i < dmam->dm_nsegs; i++) {
		psize_t len;

		len = dmam->dm_segs[i].ds_len;
		err = amdgart_iommu_map(sc, dmam, &dmam->dm_segs[i]);
		if (err) {
			for (j = 0; j < i - 1; j++)
				amdgart_iommu_unmap(sc, &dmam->dm_segs[j]);
			return (err);
		}
	}
	return (0);
}

int
amdgart_iommu_map(struct amdgart_softc *sc, bus_dmamap_t dmam,
    bus_dma_segment_t *seg)
{
	paddr_t base, end, idx;
	psize_t alen;
	u_long res;
	int err, s;
	u_int32_t pgno, flags;

	base = trunc_page(seg->ds_addr);
	end = roundup(seg->ds_addr + seg->ds_len, PAGE_SIZE);
	alen = end - base;

	s = splhigh();
	err = extent_alloc(sc->g_ex, alen, PAGE_SIZE, 0, dmam->_dm_boundary,
	    EX_NOWAIT, &res);
	splx(s);
	if (err) {
		printf("GART: extent_alloc %d\n", err);
		return (err);
	}

	seg->ds_addr = res | (seg->ds_addr & PGOFSET);

	for (idx = 0; idx < alen; idx += PAGE_SIZE) {
		pgno = ((res + idx) - sc->g_pa) >> PGSHIFT;
		flags = GART_PTE_VALID | GART_PTE_COHERENT |
		    (((base + idx) >> 28) & GART_PTE_PHYSHI) |
		     ((base + idx) & GART_PTE_PHYSLO);
		sc->g_pte[pgno] = flags;
	}

	return (0);
}

int
amdgart_iommu_unmap(struct amdgart_softc *sc, bus_dma_segment_t *seg)
{
	paddr_t base, end, idx;
	psize_t alen;
	int err, s;
	u_int32_t pgno;

	base = trunc_page(seg->ds_addr);
	end = roundup(seg->ds_addr + seg->ds_len, PAGE_SIZE);
	alen = end - base;

	/*
	 * order is significant here; invalidate the iommu page table
	 * entries, then mark them as freed in the extent.
	 */

	for (idx = 0; idx < alen; idx += PAGE_SIZE) {
		pgno = ((base - sc->g_pa) + idx) >> PGSHIFT;
		sc->g_pte[pgno] = sc->g_scribpte;
	}

	s = splhigh();
	err = extent_free(sc->g_ex, base, alen, EX_NOWAIT);
	splx(s);
	if (err) {
		/* XXX Shouldn't happen, but if it does, I think we lose. */
		printf("GART: extent_free %d\n", err);
		return (err);
	}

	return (0);
}

int
amdgart_dmamap_create(bus_dma_tag_t tag, bus_size_t size, int nsegments,
    bus_size_t maxsegsz, bus_size_t boundary, int flags, bus_dmamap_t *dmamp)
{
	struct amdgart_softc *sc = tag->_cookie;

	return (bus_dmamap_create(sc->g_dmat, size, nsegments,
	    maxsegsz, boundary, flags, dmamp));
}

void
amdgart_dmamap_destroy(bus_dma_tag_t tag, bus_dmamap_t dmam)
{
	struct amdgart_softc *sc = tag->_cookie;

	bus_dmamap_destroy(sc->g_dmat, dmam);
}

int
amdgart_dmamap_load(bus_dma_tag_t tag, bus_dmamap_t dmam, void *buf,
    bus_size_t buflen, struct proc *p, int flags)
{
	struct amdgart_softc *sc = tag->_cookie;
	int err;

	err = bus_dmamap_load(sc->g_dmat, dmam, buf, buflen,
	    p, flags);
	if (err)
		return (err);
	err = amdgart_reload(sc, dmam);
	if (err)
		bus_dmamap_unload(sc->g_dmat, dmam);
	else
		amdgart_invalidate(sc);
	return (err);
}

int
amdgart_dmamap_load_mbuf(bus_dma_tag_t tag, bus_dmamap_t dmam,
    struct mbuf *chain, int flags)
{
	struct amdgart_softc *sc = tag->_cookie;
	int err;

	err = bus_dmamap_load_mbuf(sc->g_dmat, dmam,
	    chain, flags);
	if (err)
		return (err);
	err = amdgart_reload(sc, dmam);
	if (err)
		bus_dmamap_unload(sc->g_dmat, dmam);
	else
		amdgart_invalidate(sc);
	return (err);
}

int
amdgart_dmamap_load_uio(bus_dma_tag_t tag, bus_dmamap_t dmam,
    struct uio *uio, int flags)
{
	struct amdgart_softc *sc = tag->_cookie;
	int err;

	err = bus_dmamap_load_uio(sc->g_dmat, dmam, uio, flags);
	if (err)
		return (err);
	err = amdgart_reload(sc, dmam);
	if (err)
		bus_dmamap_unload(sc->g_dmat, dmam);
	else
		amdgart_invalidate(sc);
	return (err);
}

int
amdgart_dmamap_load_raw(bus_dma_tag_t tag, bus_dmamap_t dmam,
    bus_dma_segment_t *segs, int nsegs, bus_size_t size, int flags)
{
	struct amdgart_softc *sc = tag->_cookie;
	int err;

	err = bus_dmamap_load_raw(sc->g_dmat, dmam, segs, nsegs,
	    size, flags);
	if (err)
		return (err);
	err = amdgart_reload(sc, dmam);
	if (err)
		bus_dmamap_unload(sc->g_dmat, dmam);
	else
		amdgart_invalidate(sc);
	return (err);
}

void
amdgart_dmamap_unload(bus_dma_tag_t tag, bus_dmamap_t dmam)
{
	struct amdgart_softc *sc = tag->_cookie;
	int i;

	for (i = 0; i < dmam->dm_nsegs; i++)
		amdgart_iommu_unmap(sc, &dmam->dm_segs[i]);
	amdgart_invalidate(sc);
	bus_dmamap_unload(sc->g_dmat, dmam);
}

void
amdgart_dmamap_sync(bus_dma_tag_t tag, bus_dmamap_t dmam, bus_addr_t offset,
    bus_size_t size, int ops)
{
	struct amdgart_softc *sc = tag->_cookie;

	/*
	 * XXX how do we deal with non-coherent mappings?  We don't
	 * XXX allow them right now.
	 */
	bus_dmamap_sync(sc->g_dmat, dmam, offset, size, ops);
}

int
amdgart_dmamem_alloc(bus_dma_tag_t tag, bus_size_t size, bus_size_t alignment,
    bus_size_t boundary, bus_dma_segment_t *segs, int nsegs, int *rsegs,
    int flags)
{
	struct amdgart_softc *sc = tag->_cookie;

	return (bus_dmamem_alloc(sc->g_dmat, size, alignment,
	    boundary, segs, nsegs, rsegs, flags));
}

void
amdgart_dmamem_free(bus_dma_tag_t tag, bus_dma_segment_t *segs, int nsegs)
{
	struct amdgart_softc *sc = tag->_cookie;

	bus_dmamem_free(sc->g_dmat, segs, nsegs);
}

int
amdgart_dmamem_map(bus_dma_tag_t tag, bus_dma_segment_t *segs, int nsegs,
    size_t size, caddr_t *kvap, int flags)
{
	struct amdgart_softc *sc = tag->_cookie;

	return (bus_dmamem_map(sc->g_dmat, segs, nsegs, size,
	    kvap, flags));
}

void
amdgart_dmamem_unmap(bus_dma_tag_t tag, caddr_t kva, size_t size)
{
	struct amdgart_softc *sc = tag->_cookie;

	bus_dmamem_unmap(sc->g_dmat, kva, size);
}

paddr_t
amdgart_dmamem_mmap(bus_dma_tag_t tag, bus_dma_segment_t *segs, int nsegs,
    off_t off, int prot, int flags)
{
	struct amdgart_softc *sc = tag->_cookie;

	return (bus_dmamem_mmap(sc->g_dmat, segs, nsegs, off,
	    prot, flags));
}
@


1.26
log
@Attach iommu on AMD family 10h processors (e.g. phenom) too.

11h (Turion) still needs testing, so isn't part of this commit.

ok reyk@@, marco@@
@
text
@d1 1
a1 1
/*	$OpenBSD: iommu.c,v 1.25 2009/03/10 23:28:42 oga Exp $	*/
d130 1
d231 6
a236 9
	if (PCI_VENDOR(v) != PCI_VENDOR_AMD)
		return (0);
	if (PCI_PRODUCT(v) != PCI_PRODUCT_AMD_AMD64_0F_MISC &&
	    PCI_PRODUCT(v) != PCI_PRODUCT_AMD_AMD64_10_MISC)
		return (0);

	v = pci_conf_read(pc, tag, GART_APCTRL);
	if (v & GART_APCTRL_ENABLE)
		return (0);
d238 4
a241 1
	return (1);
d244 13
d261 2
a262 2
	int dev, func, count = 0, r, nseg;
	u_long mapsize, ptesize;
d266 1
d274 1
d276 1
a276 2
		for (func = 0; func < 8; func++) {
			tag = pci_make_tag(pba->pba_pc, 0, dev, func);
d278 9
a286 2
			if (amdgart_ok(pba->pba_pc, tag))
				count++;
d293 5
d305 29
a333 1
	sc->g_pa = IOMMU_START;
d335 1
a335 1
	mapsize = IOMMU_SIZE * 1024 * 1024;
d381 1
a381 2
		for (func = 0; func < 8; func++) {
			tag = pci_make_tag(pba->pba_pc, 0, dev, func);
d383 2
a384 2
			if (!amdgart_ok(pba->pba_pc, tag))
				continue;
d386 29
a414 48
			v = pci_conf_read(pba->pba_pc, tag, GART_APCTRL);
			v |= GART_APCTRL_DISCPU | GART_APCTRL_DISTBL |
			    GART_APCTRL_DISIO;
			v &= ~(GART_APCTRL_ENABLE | GART_APCTRL_SIZE);
			switch (IOMMU_SIZE) {
			case 32:
				v |= GART_APCTRL_SIZE_32M;
				break;
			case 64:
				v |= GART_APCTRL_SIZE_64M;
				break;
			case 128:
				v |= GART_APCTRL_SIZE_128M;
				break;
			case 256:
				v |= GART_APCTRL_SIZE_256M;
				break;
			case 512:
				v |= GART_APCTRL_SIZE_512M;
				break;
			case 1024:
				v |= GART_APCTRL_SIZE_1G;
				break;
			case 2048:
				v |= GART_APCTRL_SIZE_2G;
				break;
			default:
				printf("\nGART: bad size");
				return;
			}
			pci_conf_write(pba->pba_pc, tag, GART_APCTRL, v);

			pci_conf_write(pba->pba_pc, tag, GART_APBASE,
			    sc->g_pa >> 25);

			pci_conf_write(pba->pba_pc, tag, GART_TBLBASE,
			    (ptepa >> 8) & GART_TBLBASE_MASK);

			v = pci_conf_read(pba->pba_pc, tag, GART_APCTRL);
			v |= GART_APCTRL_ENABLE;
			v &= ~GART_APCTRL_DISIO;
			pci_conf_write(pba->pba_pc, tag, GART_APCTRL, v);

			sc->g_tags[count] = tag;

			printf("\niommu%d at cpu%d: base 0x%lx length %dMB pte 0x%lx",
			    count, dev - 24, sc->g_pa, IOMMU_SIZE, ptepa);
			count++;
d416 19
@


1.25
log
@First step in cleaning up amd64 iommu.

Firstly, don't keep identical data for each of the GARTs (we keep them
in sync, but there is one per cpu socket), all that varies is the
pci_tag_t, so just keep an array of those and have the rest of the
information once.

Secondly, don't keep the softc as a global, use the _cookie field of the
dmatag_t, that's what it's there for.

Finally, use dmamap_map to map the page tables, instead of the direct NC
map.  This is because later changes to support PAT will be a lot easier
with one direct map (where we change the cacheability if needed), since
otherwise it's just asking for illegal cache aliases.

More changes will be upcoming.

Tested by a few people, with an without bigmem, thanks to those.

weingart@@ liked the direction this is going, marco@@ and kettenis@@ oked it.
@
text
@d1 1
a1 1
/*	$OpenBSD: iommu.c,v 1.24 2009/03/10 15:03:17 oga Exp $	*/
d232 2
a233 1
	if (PCI_PRODUCT(v) != PCI_PRODUCT_AMD_AMD64_0F_MISC)
@


1.24
log
@remove the _BUS_DMA_PRIVATE define from amd64 and i386.

a define needed to get to ``private'' functions that needs to be defined
5 or more times isn't much use and may cause namespace issues anyway.
Other archs will probably follow.

Discussed in portugal.  "Hell yes" weingart@@, ok kettenis@@, no
objections miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: iommu.c,v 1.23 2008/12/03 15:46:06 oga Exp $	*/
a105 1
int amdgarts;
d109 11
a119 10
	pci_chipset_tag_t g_pc;
	pcitag_t g_tag;
	struct extent *g_ex;
	paddr_t g_pa;
	paddr_t g_scribpa;
	void *g_scrib;
	u_int32_t g_scribpte;
	u_int32_t *g_pte;
	bus_dma_tag_t g_dmat;
} *amdgart_softcs;
d121 2
a122 2
void amdgart_invalidate_wait(void);
void amdgart_invalidate(void);
d124 5
a128 4
void amdgart_dumpregs(void);
int amdgart_iommu_map(bus_dmamap_t, struct extent *, bus_dma_segment_t *);
int amdgart_iommu_unmap(struct extent *, bus_dma_segment_t *);
int amdgart_reload(struct extent *, bus_dmamap_t);
d172 1
a172 1
amdgart_invalidate_wait(void)
d174 1
a174 2
	u_int32_t v;
	int i, n;
d176 1
a176 1
	for (n = 0; n < amdgarts; n++) {
d178 2
a179 3
			v = pci_conf_read(amdgart_softcs[n].g_pc,
			    amdgart_softcs[n].g_tag, GART_CACHECTRL);
			if ((v & GART_CACHE_INVALIDATE) == 0)
d189 1
a189 1
amdgart_invalidate(void)
d193 2
a194 3
	for (n = 0; n < amdgarts; n++)
		pci_conf_write(amdgart_softcs[n].g_pc,
		    amdgart_softcs[n].g_tag, GART_CACHECTRL,
d196 1
a196 1
	amdgart_invalidate_wait();
d200 1
a200 1
amdgart_dumpregs(void)
d202 1
a202 1
	int n, i, dirty;
d205 1
a205 1
	for (n = 0; n < amdgarts; n++) {
d207 9
a215 15
		printf(" apctl %x\n", pci_conf_read(amdgart_softcs[n].g_pc,
		    amdgart_softcs[n].g_tag, GART_APCTRL));
		printf(" apbase %x\n", pci_conf_read(amdgart_softcs[n].g_pc,
		    amdgart_softcs[n].g_tag, GART_APBASE));
		printf(" tblbase %x\n", pci_conf_read(amdgart_softcs[n].g_pc,
		    amdgart_softcs[n].g_tag, GART_TBLBASE));
		printf(" cachectl %x\n", pci_conf_read(amdgart_softcs[n].g_pc,
		    amdgart_softcs[n].g_tag, GART_CACHECTRL));

		p = amdgart_softcs[n].g_scrib;
		dirty = 0;
		for (i = 0; i < PAGE_SIZE; i++, p++)
			if (*p != '\0')
				dirty++;
		printf(" scribble: %s\n", dirty ? "dirty" : "clean");
d217 5
d245 4
a248 2
	int dev, func, count = 0, r;
	u_long dvabase = (u_long)-1, mapsize, ptesize;
a250 1
	struct pglist plist;
d252 1
a252 2
	struct extent *ex = NULL;
	u_int32_t *pte;
a257 2
	TAILQ_INIT(&plist);

d270 3
a272 3
	amdgart_softcs = malloc(sizeof(*amdgart_softcs) * count, M_DEVBUF,
	    M_NOWAIT);
	if (amdgart_softcs == NULL) {
d274 1
a274 1
		goto err;
d277 1
a277 1
	dvabase = IOMMU_START;
d282 7
a288 2
	r = uvm_pglistalloc(ptesize, ptesize, trunc_page(avail_end),
	    ptesize, ptesize, &plist, 1, 0);
d291 7
d300 1
a300 2
	ptepa = VM_PAGE_TO_PHYS(TAILQ_FIRST(&plist));
	pte = (u_int32_t *)pmap_map_nc_direct(TAILQ_FIRST(&plist));
d302 3
a304 3
	ex = extent_create("iommu", dvabase, dvabase + mapsize - 1, M_DEVBUF,
	    NULL, NULL, EX_NOWAIT | EX_NOCOALESCE);
	if (ex == NULL) {
d314 9
d364 1
a364 1
			    dvabase >> 25);
d374 1
a374 18
			amdgart_softcs[count].g_pc = pba->pba_pc;
			amdgart_softcs[count].g_tag = tag;
			amdgart_softcs[count].g_ex = ex;
			amdgart_softcs[count].g_pa = dvabase;
			pmap_extract(pmap_kernel(), (vaddr_t)scrib,
			    &amdgart_softcs[count].g_scribpa);
			amdgart_softcs[count].g_scrib = scrib;
			amdgart_softcs[count].g_scribpte =
			    GART_PTE_VALID | GART_PTE_COHERENT |
			    ((amdgart_softcs[count].g_scribpa >> 28) &
			      GART_PTE_PHYSHI) |
			     (amdgart_softcs[count].g_scribpa &
			      GART_PTE_PHYSLO);
			amdgart_softcs[count].g_pte = pte;
			amdgart_softcs[count].g_dmat = pba->pba_dmat;

			amdgart_initpt(&amdgart_softcs[count],
			    ptesize / sizeof(*amdgart_softcs[count].g_pte));
d377 1
a377 1
			    count, dev - 24, dvabase, IOMMU_SIZE, ptepa);
d381 2
d384 1
a385 1
	amdgarts = count;
d390 4
a393 2
	if (ex != NULL)
		extent_destroy(ex);
d396 2
a397 4
	if (amdgart_softcs != NULL)
		free(amdgart_softcs, M_DEVBUF);
	if (!TAILQ_EMPTY(&plist))
		uvm_pglistfree(&plist);
d407 1
a407 1
	amdgart_invalidate();
d411 1
a411 1
amdgart_reload(struct extent *ex, bus_dmamap_t dmam)
d419 1
a419 1
		err = amdgart_iommu_map(dmam, ex, &dmam->dm_segs[i]);
d422 1
a422 1
				amdgart_iommu_unmap(ex, &dmam->dm_segs[j]);
d430 2
a431 1
amdgart_iommu_map(bus_dmamap_t dmam, struct extent *ex, bus_dma_segment_t *seg)
d444 1
a444 1
	err = extent_alloc(ex, alen, PAGE_SIZE, 0, dmam->_dm_boundary,
d455 1
a455 1
		pgno = ((res + idx) - amdgart_softcs[0].g_pa) >> PGSHIFT;
d459 1
a459 1
		amdgart_softcs[0].g_pte[pgno] = flags;
d466 1
a466 1
amdgart_iommu_unmap(struct extent *ex, bus_dma_segment_t *seg)
d483 2
a484 2
		pgno = ((base - amdgart_softcs[0].g_pa) + idx) >> PGSHIFT;
		amdgart_softcs[0].g_pte[pgno] = amdgart_softcs[0].g_scribpte;
d488 1
a488 1
	err = extent_free(ex, base, alen, EX_NOWAIT);
d503 3
a505 1
	return (bus_dmamap_create(amdgart_softcs[0].g_dmat, size, nsegments,
d512 3
a514 1
	bus_dmamap_destroy(amdgart_softcs[0].g_dmat, dmam);
d521 1
d524 1
a524 1
	err = bus_dmamap_load(amdgart_softcs[0].g_dmat, dmam, buf, buflen,
d528 1
a528 1
	err = amdgart_reload(amdgart_softcs[0].g_ex, dmam);
d530 1
a530 1
		bus_dmamap_unload(amdgart_softcs[0].g_dmat, dmam);
d532 1
a532 1
		amdgart_invalidate();
d540 1
d543 1
a543 1
	err = bus_dmamap_load_mbuf(amdgart_softcs[0].g_dmat, dmam,
d547 1
a547 1
	err = amdgart_reload(amdgart_softcs[0].g_ex, dmam);
d549 1
a549 1
		bus_dmamap_unload(amdgart_softcs[0].g_dmat, dmam);
d551 1
a551 1
		amdgart_invalidate();
d559 1
d562 1
a562 1
	err = bus_dmamap_load_uio(amdgart_softcs[0].g_dmat, dmam, uio, flags);
d565 1
a565 1
	err = amdgart_reload(amdgart_softcs[0].g_ex, dmam);
d567 1
a567 1
		bus_dmamap_unload(amdgart_softcs[0].g_dmat, dmam);
d569 1
a569 1
		amdgart_invalidate();
d577 1
d580 1
a580 1
	err = bus_dmamap_load_raw(amdgart_softcs[0].g_dmat, dmam, segs, nsegs,
d584 1
a584 1
	err = amdgart_reload(amdgart_softcs[0].g_ex, dmam);
d586 1
a586 1
		bus_dmamap_unload(amdgart_softcs[0].g_dmat, dmam);
d588 1
a588 1
		amdgart_invalidate();
d595 1
d599 3
a601 3
		amdgart_iommu_unmap(amdgart_softcs[0].g_ex, &dmam->dm_segs[i]);
	amdgart_invalidate();
	bus_dmamap_unload(amdgart_softcs[0].g_dmat, dmam);
d608 2
d614 1
a614 1
	bus_dmamap_sync(amdgart_softcs[0].g_dmat, dmam, offset, size, ops);
d622 3
a624 1
	return (bus_dmamem_alloc(amdgart_softcs[0].g_dmat, size, alignment,
d631 3
a633 1
	bus_dmamem_free(amdgart_softcs[0].g_dmat, segs, nsegs);
d640 3
a642 1
	return (bus_dmamem_map(amdgart_softcs[0].g_dmat, segs, nsegs, size,
d649 3
a651 1
	bus_dmamem_unmap(amdgart_softcs[0].g_dmat, kva, size);
d658 3
a660 1
	return (bus_dmamem_mmap(amdgart_softcs[0].g_dmat, segs, nsegs, off,
@


1.23
log
@Remove the x86 and i386 prefixes to the bus_dma types. It's really quite
pointless and just makes the code different for no reason. This moves i386 and
amd64 bus_dma to being a lot closer to identical.

suggestion to just remove the prefix instead of merge them from deraadt@@.

no objections art@@, kettenis@@, ok weingart@@
@
text
@d1 1
a1 1
/*	$OpenBSD: iommu.c,v 1.22 2008/04/28 06:17:47 brad Exp $	*/
a40 1
#define _BUS_DMA_PRIVATE
@


1.22
log
@Sync PCI ids.
@
text
@d1 1
a1 1
/*	$OpenBSD: iommu.c,v 1.21 2007/09/17 15:34:38 chl Exp $	*/
d41 1
a41 1
#define _X86_BUS_DMA_PRIVATE
d154 1
a154 1
struct x86_bus_dma_tag amdgart_bus_dma_tag = {
@


1.21
log
@MALLOC/FREE -> malloc/free and M_ZERO changes

ok krw@@
@
text
@d1 1
a1 1
/*	$OpenBSD: iommu.c,v 1.20 2007/05/27 21:44:23 jason Exp $	*/
d236 1
a236 1
	if (PCI_PRODUCT(v) != PCI_PRODUCT_AMD_AMD64_MISC)
@


1.20
log
@be more agressive on invalidation; perform invalidates on load* and unload
@
text
@d1 1
a1 1
/*	$OpenBSD: iommu.c,v 1.19 2007/05/27 21:08:07 jason Exp $	*/
d304 1
a304 1
	scrib = malloc(PAGE_SIZE, M_DEVBUF, M_NOWAIT);
a308 1
	bzero(scrib, PAGE_SIZE);
@


1.19
log
@remove two TODO items:
- map the GART page table uncached
- disable table walk probes
@
text
@d1 1
a1 1
/*	$OpenBSD: iommu.c,v 1.18 2007/02/09 04:48:10 jason Exp $	*/
d199 1
a409 1
	amdgart_invalidate_wait();
d592 1
a592 1
	/* XXX should we invalidate here? */
a599 8
	if (ops & (BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE)) {
		/*
		 * XXX this should be conditionalized... only do it
		 * XXX when necessary.
		 */
		amdgart_invalidate_wait();
	}

a603 1

@


1.18
log
@simplify the argument passing (use a pointer to bus_dma_segment_t instead
of separate addr/len pairs).
@
text
@d1 1
a1 1
/*	$OpenBSD: iommu.c,v 1.17 2007/02/09 02:58:10 jason Exp $	*/
a28 5
/*
 * TODO:
 *	- map the PTE uncacheable and disable table walk probes
 */

d294 1
a294 1
	pte = (u_int32_t *)pmap_map_direct(TAILQ_FIRST(&plist));
d357 1
a357 1
			v &= ~(GART_APCTRL_DISIO | GART_APCTRL_DISTBL);
@


1.17
log
@according to the errata, invalid pages shouldn't be used.  Always make
sure a page is mapped at every location (a page is already reserved for
just this occaision).  And no, this doesn't fix it.
@
text
@d1 1
a1 1
/*	$OpenBSD: iommu.c,v 1.16 2005/09/29 21:30:42 marco Exp $	*/
d131 2
a132 3
int amdgart_iommu_map(bus_dmamap_t, struct extent *, paddr_t,
    paddr_t *, psize_t);
int amdgart_iommu_unmap(struct extent *, paddr_t, psize_t);
a422 1
		paddr_t opa, npa;
a424 1
		opa = dmam->dm_segs[i].ds_addr;
d426 1
a426 1
		err = amdgart_iommu_map(dmam, ex, opa, &npa, len);
d429 1
a429 3
				amdgart_iommu_unmap(ex,
				    dmam->dm_segs[j].ds_addr,
				    dmam->dm_segs[j].ds_len);
a431 1
		dmam->dm_segs[i].ds_addr = npa;
d437 1
a437 2
amdgart_iommu_map(bus_dmamap_t dmam, struct extent *ex, paddr_t opa,
    paddr_t *npa, psize_t len)
d445 2
a446 2
	base = trunc_page(opa);
	end = roundup(opa + len, PAGE_SIZE);
d448 1
d457 2
a458 1
	*npa = res | (opa & PGOFSET);
d472 1
a472 1
amdgart_iommu_unmap(struct extent *ex, paddr_t pa, psize_t len)
d479 2
a480 2
	base = trunc_page(pa);
	end = roundup(pa + len, PAGE_SIZE);
d596 1
a596 2
		amdgart_iommu_unmap(amdgart_softcs[0].g_ex,
		    dmam->dm_segs[i].ds_addr, dmam->dm_segs[i].ds_len);
@


1.16
log
@Execute operations in the correct order.  From jason@@
@
text
@d1 1
a1 1
/*	$OpenBSD: iommu.c,v 1.15 2005/09/27 17:41:12 marco Exp $	*/
d495 1
a495 1
		amdgart_softcs[0].g_pte[pgno] = 0;
@


1.15
log
@ARGH! disable gart, I suck!
@
text
@d1 1
a1 1
/*	$OpenBSD: iommu.c,v 1.14 2005/09/27 17:37:30 marco Exp $	*/
d432 3
a434 1
				amdgart_iommu_unmap(ex, opa, len);
d487 11
d502 1
a504 5
	}

	for (idx = 0; idx < alen; idx += PAGE_SIZE) {
		pgno = ((base - amdgart_softcs[0].g_pa) + idx) >> PGSHIFT;
		amdgart_softcs[0].g_pte[pgno] = amdgart_softcs[0].g_scribpte;
@


1.14
log
@Clean up prints.  From jason@@
@
text
@d1 1
a1 1
/*	$OpenBSD: iommu.c,v 1.13 2005/06/17 19:25:39 marco Exp $	*/
d113 1
a113 1
int amdgart_enable = 1;
@


1.13
log
@- remove old debugging code
- allocate and use scribble page
- provide method to see if something has scribbled out of bounds

The gart still remains disabled by default.

From jason@@
@
text
@d1 1
a1 1
/*	$OpenBSD: iommu.c,v 1.12 2005/06/08 04:21:24 marc Exp $	*/
d113 1
a113 1
int amdgart_enable = 0;
d221 1
a221 1
		printf("cachectl %x\n", pci_conf_read(amdgart_softcs[n].g_pc,
d229 1
a229 1
		printf("scribble: %s\n", dirty ? "dirty" : "clean");
@


1.12
log
@
revert enabling iommu on amd64 as it breaks at least one MP host.
OK deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: iommu.c,v 1.11 2005/06/07 16:40:31 deraadt Exp $	*/
d113 1
a113 1
int amdgart_enable;
a129 1
int amdgart_initpte(pci_chipset_tag_t, pcitag_t, paddr_t, psize_t, psize_t);
d136 1
d210 2
a211 1
	int n;
d223 7
a287 9
#if 0
	r = extent_alloc_subregion(iomem_ex, IOMMU_START, IOMMU_END,
	    IOMMU_SIZE * 1024 * 1024, IOMMU_ALIGN * 1024 * 1024, 0,
	    EX_NOBOUNDARY, EX_NOWAIT, &dvabase);
	if (r != 0) {
		printf("\nGART: extent alloc failed: %d", r);
		goto err;
	}
#else
a288 1
#endif
d309 7
d382 3
a402 4
#if 0
	if (dvabase == (u_long)-1)
		extent_free(iomem_ex, dvabase, IOMMU_SIZE * 1024 * 1024, 0);
#endif
d405 11
@


1.11
log
@make it prettier; jason ok
@
text
@d1 1
a1 1
/*	$OpenBSD: iommu.c,v 1.10 2005/06/06 15:10:20 jason Exp $	*/
d113 1
d255 3
@


1.10
log
@enable iommu on all systems where we support it.  We'll support it on more
systems in a week or two (hey, getting a machine is taking me longer than
I expected =)
@
text
@d1 1
a1 1
/*	$OpenBSD: iommu.c,v 1.9 2005/06/02 15:26:03 jason Exp $	*/
d373 1
a373 1
			printf("\niommu%d(cpu%d): base 0x%lx length %dMB pte 0x%lx",
@


1.9
log
@- wish there was a better way to do this... put splhigh() around the
extent_* functions to ensure they stay consistent
- also remove some debugging crap
@
text
@d1 1
a1 1
/*	$OpenBSD: iommu.c,v 1.8 2005/05/27 23:48:24 jason Exp $	*/
a112 1
int amdgart_enable;
a253 3

	if (amdgart_enable == 0)
		return;
@


1.8
log
@oops, need to get the boundary from the map when allocating gart addresses
(fixes borked pciide chipsets)
@
text
@d1 1
a1 1
/*	$OpenBSD: iommu.c,v 1.7 2005/05/27 21:44:54 art Exp $	*/
d395 1
d398 1
d432 1
a432 1
	int err;
d438 1
d441 1
d464 1
a464 1
	int err;
d470 1
d472 1
@


1.7
log
@ - Use the direct map for mapping the PTEs.
 - Actually allocate the right number of softcs.
@
text
@d1 1
a1 1
/*	$OpenBSD: iommu.c,v 1.6 2005/05/27 18:37:07 jason Exp $	*/
d132 2
a133 1
int amdgart_iommu_map(struct extent *, paddr_t, paddr_t *, psize_t);
d412 1
a412 1
		err = amdgart_iommu_map(ex, opa, &npa, len);
d424 2
a425 1
amdgart_iommu_map(struct extent *ex, paddr_t opa, paddr_t *npa, psize_t len)
d436 1
a436 1
	err = extent_alloc(ex, alen, PAGE_SIZE, 0, EX_NOBOUNDARY,
@


1.6
log
@use a fixed address for the base dva, also don't forget to setup the
pae table base address.
@
text
@d1 1
a1 1
/*	$OpenBSD: iommu.c,v 1.5 2005/05/27 07:46:38 jason Exp $	*/
d113 1
a113 1
int amdgart_enable = 0;
a135 1
int amdgart_load_phys(struct pglist *, vaddr_t);
a241 22
int
amdgart_load_phys(struct pglist *plist, vaddr_t va)
{
	struct vm_page *m;
	paddr_t pa;
	psize_t off;

	m = TAILQ_FIRST(plist);
	pa = VM_PAGE_TO_PHYS(m);
	for (off = 0; m; m = TAILQ_NEXT(m, pageq), off += PAGE_SIZE) {
		if (VM_PAGE_TO_PHYS(m) != (pa + off)) {
			printf("\nGART: too many segments");
			return (-1);
		}
		pmap_enter(pmap_kernel(), va + off, pa + off,
		    VM_PROT_READ | VM_PROT_WRITE,
		    VM_PROT_READ | VM_PROT_WRITE | PMAP_WIRED);
	}
	pmap_update(pmap_kernel());
	return (0);
}

d272 2
a273 2
	amdgart_softcs = (struct amdgart_softc *)malloc(sizeof(*amdgart_softcs),
	    M_DEVBUF, M_NOWAIT);
a299 4
	pte = (u_int32_t *)uvm_km_valloc(kernel_map, ptesize);

	if (amdgart_load_phys(&plist, (vaddr_t)pte))
		goto err;
d301 1
a387 3
	/* XXX pmap_remove? */
	if (pte != NULL)
		uvm_km_free(kernel_map, (vaddr_t)pte, ptesize);
@


1.5
log
@hook in iommu, but it's still disabled by default for now
@
text
@d1 1
a1 1
/*	$OpenBSD: iommu.c,v 1.4 2005/05/27 06:40:45 jason Exp $	*/
d276 1
d302 1
d310 3
d327 1
d378 3
d403 1
a403 2
			    count, dev - 24, dvabase, IOMMU_SIZE,
			    VM_PAGE_TO_PHYS(TAILQ_FIRST(&plist)));
@


1.4
log
@fix printf
@
text
@d1 1
a1 1
/*	$OpenBSD: iommu.c,v 1.3 2005/05/27 06:27:43 jason Exp $	*/
d113 1
d276 3
@


1.3
log
@handle multi-cpu GART allocation:
iommu0(cpu0): base 0x80000000 length 512 pte 0xa80000
@
text
@d1 1
a1 1
/*	$OpenBSD: iommu.c,v 1.2 2005/05/26 19:47:44 jason Exp $	*/
d389 1
a389 1
			printf("\niommu%d(cpu%d): base 0x%lx length %d pte 0x%lx",
@


1.2
log
@make all mappings valid/coherent.  For pages not currently mapped, fill
the entry with a scribble page.  In the future, we'll use this for
detecting bad device drivers.  Page faults are bad in an iommu =)
@
text
@d1 1
a1 1
/*	$OpenBSD: iommu.c,v 1.1 2005/05/26 17:48:20 jason Exp $	*/
a30 1
 *	- scribble page for devices that lie about being done with memory.
d112 1
a112 10
u_int32_t *gartpt;
struct pglist gartplist;
struct extent *gartex;
pci_chipset_tag_t gartpc;
pcitag_t garttag;
bus_dma_tag_t gartparent;
paddr_t gartpa;
paddr_t gartscribpa;
void *gartscrib;
u_int32_t gartscribflags;
d114 14
a127 2
void amdgart_invalidate_wait(pci_chipset_tag_t, pcitag_t);
void amdgart_invalidate(pci_chipset_tag_t, pcitag_t);
d134 2
d177 1
a177 1
amdgart_invalidate_wait(pci_chipset_tag_t pc, pcitag_t tag)
d180 1
a180 1
	int i;
d182 10
a191 5
	for (i = 1000; i > 0; i--) {
		v = pci_conf_read(NULL, tag, GART_CACHECTRL);
		if ((v & GART_CACHE_INVALIDATE) == 0)
			break;
		delay(1);
a192 2
	if (i == 0)
		printf("GART: invalidate timeout\n");
d196 12
a207 1
amdgart_invalidate(pci_chipset_tag_t pc, pcitag_t tag)
d209 13
a221 1
	pci_conf_write(pc, tag, GART_CACHECTRL, GART_CACHE_INVALIDATE);
d225 1
a225 2
amdgart_initpte(pci_chipset_tag_t pc, pcitag_t tag, paddr_t base,
    psize_t mapsize, psize_t sz)
d227 1
a227 5
	struct vm_page *m;
	vaddr_t va;
	paddr_t pa, off;
	u_int32_t r, *pte;
	int err;
d229 5
a233 1
	TAILQ_INIT(&gartplist);
d235 3
a237 9
	gartscrib = (void *)malloc(PAGE_SIZE, M_DEVBUF, M_NOWAIT);
	if (gartscrib == NULL) {
		printf("\nGART: failed to get scribble page");
		goto err;
	}
	pmap_extract(pmap_kernel(), (vaddr_t)gartscrib, &gartscribpa);
	gartscribflags = GART_PTE_VALID | GART_PTE_COHERENT |
	    ((gartscribpa >> 28) & GART_PTE_PHYSHI) |
	     (gartscribpa & GART_PTE_PHYSLO);
d239 2
a240 12
	err = uvm_pglistalloc(sz, sz, trunc_page(avail_end), sz, sz,
	    &gartplist, 1, 0);
	if (err) {
		printf("\nGART: failed to get PTE pages: %d", err);
		goto err;
	}
	va = uvm_km_valloc(kernel_map, sz);
	if (va == 0) {
		printf("\nGART: failed to get PTE vspace");
		goto err;
	}
	gartpt = (u_int32_t *)va;
d242 6
a247 9
	gartex = extent_create("iommu", base, base + mapsize - 1, M_DEVBUF,
	    NULL, NULL, EX_NOWAIT | EX_NOCOALESCE);
	gartpa = base;
	if (gartex == NULL) {
		printf("\nGART: can't create extent");
		goto err;
	}
	printf("\n");
	extent_print(gartex);
d249 1
a249 1
	m = TAILQ_FIRST(&gartplist);
d253 2
a254 2
			printf("\nGART: too many segments!");
			goto err;
a255 1
		/* XXX check for error?  art? */
a260 8

	pci_conf_write(NULL, tag, GART_TBLBASE, (pa >> 8) & GART_TBLBASE_MASK);

	for (r = 0, pte = gartpt; r < (sz / sizeof(*gartpt)); r++, pte++)
		*pte = gartscribflags;
	amdgart_invalidate(pc, tag);
	amdgart_invalidate_wait(pc, tag);
		
a261 20

err:
	if (gartscrib)
		free(gartscrib, M_DEVBUF);
	if (!TAILQ_EMPTY(&gartplist))
		uvm_pglistfree(&gartplist);
	if (gartex != NULL) {
		extent_destroy(gartex);
		gartex = NULL;
	}
	return (-1);
}

void
amdgart_dumpregs(void)
{
	printf("apctl %x\n", pci_conf_read(gartpc, garttag, GART_APCTRL));
	printf("apbase %x\n", pci_conf_read(gartpc, garttag, GART_APBASE));
	printf("tblbase %x\n", pci_conf_read(gartpc, garttag, GART_TBLBASE));
	printf("cachectl %x\n", pci_conf_read(gartpc, garttag, GART_CACHECTRL));
d267 2
a268 1
	pci_chipset_tag_t pc = pba->pba_pc;
d270 15
a284 12
	u_int32_t apctl, v;
	u_long base;
	int r;

	gartpc = pc;
	garttag = tag = pci_make_tag(pc, 0, 24, 3);
	gartparent = pba->pba_dmat;
	v = pci_conf_read(pc, tag, PCI_ID_REG);
	if (PCI_VENDOR(v) != PCI_VENDOR_AMD ||
	    PCI_PRODUCT(v) != PCI_PRODUCT_AMD_AMD64_MISC) {
		printf("\ndidn't find misc registers, no gart.");
		return;
d287 1
a287 3
	apctl = pci_conf_read(pc, tag, GART_APCTRL);
	if (apctl & GART_APCTRL_ENABLE) {
		printf("\nBIOS already enabled it, this is hard, no gart.");
d289 6
d299 11
a309 1
	    EX_NOBOUNDARY, EX_NOWAIT, &base);
d311 2
a312 2
		printf("\nGART extent alloc failed: %d", r);
		return;
d314 4
d319 5
a323 26
	apctl &= ~GART_APCTRL_SIZE;
	switch (IOMMU_SIZE) {
	case 32:
		apctl |= GART_APCTRL_SIZE_32M;
		break;
	case 64:
		apctl |= GART_APCTRL_SIZE_64M;
		break;
	case 128:
		apctl |= GART_APCTRL_SIZE_128M;
		break;
	case 256:
		apctl |= GART_APCTRL_SIZE_256M;
		break;
	case 512:
		apctl |= GART_APCTRL_SIZE_512M;
		break;
	case 1024:
		apctl |= GART_APCTRL_SIZE_1G;
		break;
	case 2048:
		apctl |= GART_APCTRL_SIZE_2G;
		break;
	default:
		printf("\nGART: bad size");
		return;
d325 69
a393 9
	apctl |= GART_APCTRL_ENABLE | GART_APCTRL_DISCPU | GART_APCTRL_DISTBL |
	    GART_APCTRL_DISIO;
	pci_conf_write(pc, tag, GART_APCTRL, apctl);
	pci_conf_write(pc, tag, GART_APBASE, base >> 25);

	v = ((IOMMU_SIZE * 1024) / (PAGE_SIZE / sizeof(u_int32_t))) * 1024;
	if (amdgart_initpte(pc, tag, base, IOMMU_SIZE * 1024 * 1024, v)) {
		printf("\nGART: initpte failed");
		return;
a394 4
	apctl &= ~(GART_APCTRL_DISIO | GART_APCTRL_DISTBL);
	pci_conf_write(pc, tag, GART_APCTRL, apctl);
	printf("\nGART base 0x%08x (%uMB) pte 0x%lx",
	    base, v / 1024, VM_PAGE_TO_PHYS(TAILQ_FIRST(&gartplist)));
a395 1
	/* switch to our own bus_dma_tag_t */
d397 18
d428 1
a428 1
		err = amdgart_iommu_map(gartex, opa, &npa, len);
d460 1
a460 1
		pgno = ((res + idx) - gartpa) >> PGSHIFT;
d464 1
a464 1
		gartpt[pgno] = flags;
d488 2
a489 2
		pgno = ((base - gartpa) + idx) >> PGSHIFT;
		gartpt[pgno] = gartscribflags;
d499 2
a500 8
	static int once = 0;

	if (!once) {
		once = 1;
		printf("using AMDGART bus_dma!\n");
	}
	return (bus_dmamap_create(gartparent, size, nsegments, maxsegsz,
	    boundary, flags, dmamp));
d506 1
a506 1
	bus_dmamap_destroy(gartparent, dmam);
d515 2
a516 1
	err = bus_dmamap_load(gartparent, dmam, buf, buflen, p, flags);
d519 1
a519 1
	err = amdgart_reload(gartex, dmam);
d521 1
a521 1
		bus_dmamap_unload(gartparent, dmam);
d523 1
a523 1
		amdgart_invalidate(gartpc, garttag);
d533 2
a534 1
	err = bus_dmamap_load_mbuf(gartparent, dmam, chain, flags);
d537 1
a537 1
	err = amdgart_reload(gartex, dmam);
d539 1
a539 1
		bus_dmamap_unload(gartparent, dmam);
d541 1
a541 1
		amdgart_invalidate(gartpc, garttag);
d551 1
a551 1
	err = bus_dmamap_load_uio(gartparent, dmam, uio, flags);
d554 1
a554 1
	err = amdgart_reload(gartex, dmam);
d556 1
a556 1
		bus_dmamap_unload(gartparent, dmam);
d558 1
a558 1
		amdgart_invalidate(gartpc, garttag);
d568 2
a569 1
	err = bus_dmamap_load_raw(gartparent, dmam, segs, nsegs, size, flags);
d572 1
a572 1
	err = amdgart_reload(gartex, dmam);
d574 1
a574 1
		bus_dmamap_unload(gartparent, dmam);
d576 1
a576 1
		amdgart_invalidate(gartpc, garttag);
d586 2
a587 2
		amdgart_iommu_unmap(gartex, dmam->dm_segs[i].ds_addr,
		    dmam->dm_segs[i].ds_len);
d589 1
a589 1
	bus_dmamap_unload(gartparent, dmam);
d601 1
a601 1
		amdgart_invalidate_wait(gartpc, garttag);
d609 1
a609 1
	bus_dmamap_sync(gartparent, dmam, offset, size, ops);
d617 2
a618 2
	return (bus_dmamem_alloc(gartparent, size, alignment, boundary, segs,
	    nsegs, rsegs, flags));
d624 1
a624 1
	bus_dmamem_free(gartparent, segs, nsegs);
d631 2
a632 1
	return (bus_dmamem_map(gartparent, segs, nsegs, size, kvap, flags));
d638 1
a638 1
	bus_dmamem_unmap(gartparent, kva, size);
d645 2
a646 1
	return (bus_dmamem_mmap(gartparent, segs, nsegs, off, prot, flags));
@


1.1
log
@iommu meets amd64.  This currently only works on machines where the GART
is NOT enabled by the BIOS.  It's also not hooked in by default yet.
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d120 3
d206 10
d256 1
a256 1
		*pte = 0;
d263 2
a301 6
#if 0
	v = pci_conf_read(pc, tag, MCANB_CTRL);
	v |= MCANB_GARTTBLWKEN;
	pci_conf_write(pc, tag, MCANB_CTRL, v);
#endif

d434 1
a434 1
		gartpt[pgno] = GART_PTE_COHERENT;
@

