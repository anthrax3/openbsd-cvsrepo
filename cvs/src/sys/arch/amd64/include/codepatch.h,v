head	1.3;
access;
symbols
	OPENBSD_6_1:1.2.0.10
	OPENBSD_6_1_BASE:1.2
	OPENBSD_6_0:1.2.0.6
	OPENBSD_6_0_BASE:1.2
	OPENBSD_5_9:1.2.0.2
	OPENBSD_5_9_BASE:1.2
	OPENBSD_5_8:1.2.0.4
	OPENBSD_5_8_BASE:1.2
	OPENBSD_5_7:1.1.0.2
	OPENBSD_5_7_BASE:1.1;
locks; strict;
comment	@ * @;


1.3
date	2017.07.01.19.38.41;	author sf;	state Exp;
branches;
next	1.2;
commitid	IPVKrsb3BQkAgG28;

1.2
date	2015.04.19.19.45.21;	author sf;	state Exp;
branches;
next	1.1;
commitid	QHmlY8tYf1BGbIw1;

1.1
date	2015.01.16.10.17.51;	author sf;	state Exp;
branches;
next	;
commitid	Mg2nJormk2PyesMj;


desc
@@


1.3
log
@Use absolute pointers in codepatch entries

Instead of offsets to KERNBASE, store absolute pointers in the
codepatch entries. This makes the resulting kernel a few KB larger on
amd64, but KERNBASE will go away when ASLR is introduced.

Requested by deraadt@@
@
text
@/*      $OpenBSD: codepatch.h,v 1.2 2015/04/19 19:45:21 sf Exp $    */
/*
 * Copyright (c) 2014-2015 Stefan Fritsch <sf@@sfritsch.de>
 *
 * Permission to use, copy, modify, and distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 */

#ifndef _MACHINE_CODEPATCH_H_
#define _MACHINE_CODEPATCH_H_

#include <machine/param.h>

#ifndef _LOCORE

void *codepatch_maprw(vaddr_t *nva, vaddr_t dest);
void codepatch_unmaprw(vaddr_t nva);
void codepatch_fill_nop(void *caddr, uint16_t len);
void codepatch_nop(uint16_t tag);
void codepatch_replace(uint16_t tag, void *code, size_t len);
void codepatch_call(uint16_t tag, void *func);

#endif /* !_LOCORE */

/*
 * Mark the start of some code snippet to be patched.
 */
#define	CODEPATCH_START	998:
/*
 * Mark the end of some code to be patched, and assign the given tag.
 */
#define	CODEPATCH_END(tag)			 \
	999:					 \
	.section .codepatch, "a"		;\
	.quad 998b				;\
	.short (999b - 998b)			;\
	.short tag				;\
	.int 0					;\
	.previous

#define CPTAG_STAC		1
#define CPTAG_CLAC		2
#define CPTAG_EOI		3

#endif /* _MACHINE_CODEPATCH_H_ */
@


1.2
log
@Add support for x2apic mode

This is currently only enabled on hypervisors because on real hardware, it
requires interrupt remapping which we don't support yet. But on virtualization
it reduces the number of vmexits required per IPI from 4 to 1, causing a
significant speed-up for MP guests.

ok kettenis@@
@
text
@d1 1
a1 1
/*      $OpenBSD: codepatch.h,v 1.1 2015/01/16 10:17:51 sf Exp $    */
d44 1
a44 1
	.int (998b - KERNBASE)			;\
d47 1
@


1.1
log
@Binary code patching on amd64

This commit adds generic infrastructure to do binary code patching on amd64.
The existing code patching for SMAP is converted to the new infrastruture.

More consumers and support for i386 will follow later.

This version of the diff has some simplifications in codepatch_fill_nop()
compared to a version that was:

OK @@kettenis @@mlarkin @@jsg
@
text
@d1 1
a1 1
/*      $OpenBSD: codepatch.h,v Exp $    */
d51 1
@

