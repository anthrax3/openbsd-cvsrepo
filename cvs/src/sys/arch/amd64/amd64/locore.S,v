head	1.87;
access;
symbols
	OPENBSD_6_2:1.87.0.2
	OPENBSD_6_2_BASE:1.87
	OPENBSD_6_1:1.84.0.4
	OPENBSD_6_1_BASE:1.84
	OPENBSD_6_0:1.82.0.2
	OPENBSD_6_0_BASE:1.82
	OPENBSD_5_9:1.75.0.2
	OPENBSD_5_9_BASE:1.75
	OPENBSD_5_8:1.72.0.4
	OPENBSD_5_8_BASE:1.72
	OPENBSD_5_7:1.62.0.2
	OPENBSD_5_7_BASE:1.62
	OPENBSD_5_6:1.54.0.10
	OPENBSD_5_6_BASE:1.54
	OPENBSD_5_5:1.54.0.8
	OPENBSD_5_5_BASE:1.54
	OPENBSD_5_4:1.54.0.4
	OPENBSD_5_4_BASE:1.54
	OPENBSD_5_3:1.54.0.2
	OPENBSD_5_3_BASE:1.54
	OPENBSD_5_2:1.52.0.2
	OPENBSD_5_2_BASE:1.52
	OPENBSD_5_1_BASE:1.51
	OPENBSD_5_1:1.51.0.2
	OPENBSD_5_0:1.48.0.2
	OPENBSD_5_0_BASE:1.48
	OPENBSD_4_9:1.44.0.2
	OPENBSD_4_9_BASE:1.44
	OPENBSD_4_8:1.39.0.6
	OPENBSD_4_8_BASE:1.39
	OPENBSD_4_7:1.39.0.2
	OPENBSD_4_7_BASE:1.39
	OPENBSD_4_6:1.39.0.4
	OPENBSD_4_6_BASE:1.39
	OPENBSD_4_5:1.31.0.2
	OPENBSD_4_5_BASE:1.31
	OPENBSD_4_4:1.27.0.2
	OPENBSD_4_4_BASE:1.27
	OPENBSD_4_3:1.25.0.2
	OPENBSD_4_3_BASE:1.25
	OPENBSD_4_2:1.22.0.2
	OPENBSD_4_2_BASE:1.22
	OPENBSD_4_1:1.21.0.8
	OPENBSD_4_1_BASE:1.21
	OPENBSD_4_0:1.21.0.4
	OPENBSD_4_0_BASE:1.21
	OPENBSD_3_9:1.21.0.6
	OPENBSD_3_9_BASE:1.21
	OPENBSD_3_8:1.21.0.2
	OPENBSD_3_8_BASE:1.21
	OPENBSD_3_7:1.16.0.2
	OPENBSD_3_7_BASE:1.16
	OPENBSD_3_6:1.14.0.2
	OPENBSD_3_6_BASE:1.14
	SMP_SYNC_A:1.10
	SMP_SYNC_B:1.10
	OPENBSD_3_5:1.9.0.2
	OPENBSD_3_5_BASE:1.9
	SMP:1.3.0.2;
locks; strict;
comment	@# @;


1.87
date	2017.07.06.06.17.04;	author deraadt;	state Exp;
branches;
next	1.86;
commitid	8lSpPCbSabFJN412;

1.86
date	2017.06.29.17.17.28;	author deraadt;	state Exp;
branches;
next	1.85;
commitid	W8lruZ7GPI2dyHQY;

1.85
date	2017.05.31.19.18.18;	author deraadt;	state Exp;
branches;
next	1.84;
commitid	HlDgymhwBU2bW7Tm;

1.84
date	2017.02.06.09.15.51;	author mpi;	state Exp;
branches;
next	1.83;
commitid	syiLTu061M9oaQM8;

1.83
date	2016.09.04.09.22.28;	author mpi;	state Exp;
branches;
next	1.82;
commitid	jBolvsPoQ0BaYiLs;

1.82
date	2016.07.16.06.04.29;	author mlarkin;	state Exp;
branches;
next	1.81;
commitid	2VViksTJanHcGpAF;

1.81
date	2016.06.22.01.12.38;	author mikeb;	state Exp;
branches;
next	1.80;
commitid	aoZwpavraFkBTbjg;

1.80
date	2016.06.06.06.02.02;	author deraadt;	state Exp;
branches;
next	1.79;
commitid	0RVhrCgzyhuYyPyl;

1.79
date	2016.05.23.20.11.49;	author deraadt;	state Exp;
branches;
next	1.78;
commitid	0oWSDXhpPUnuLpPD;

1.78
date	2016.05.10.18.39.42;	author deraadt;	state Exp;
branches;
next	1.77;
commitid	qfOifNidEGDB2jL1;

1.77
date	2016.05.10.14.15.57;	author mikeb;	state Exp;
branches;
next	1.76;
commitid	lWKVtwCDVaFanOT6;

1.76
date	2016.02.26.02.23.07;	author mlarkin;	state Exp;
branches;
next	1.75;
commitid	e4E2zaYiFk2BixAH;

1.75
date	2016.01.04.01.03.03;	author mlarkin;	state Exp;
branches;
next	1.74;
commitid	tby1bHvscKD3M0n0;

1.74
date	2015.12.08.18.54.10;	author mikeb;	state Exp;
branches;
next	1.73;
commitid	1BfOSlse1q4NIVV4;

1.73
date	2015.11.09.01.08.56;	author mlarkin;	state Exp;
branches;
next	1.72;
commitid	GACoBIAiVbzhU6Pi;

1.72
date	2015.07.17.15.37.58;	author guenther;	state Exp;
branches;
next	1.71;
commitid	fZhyUgCUYQOMyZ4Z;

1.71
date	2015.07.17.06.13.44;	author mlarkin;	state Exp;
branches;
next	1.70;
commitid	hg6zbTFd8ryZhOOU;

1.70
date	2015.07.16.23.04.12;	author mlarkin;	state Exp;
branches;
next	1.69;
commitid	77tNyMwJMoXAvLU3;

1.69
date	2015.07.16.21.12.12;	author mlarkin;	state Exp;
branches;
next	1.68;
commitid	rhUZ7G8TLWMBnTgH;

1.68
date	2015.06.28.18.54.54;	author guenther;	state Exp;
branches;
next	1.67;
commitid	9qSlzkscc1lVVnYi;

1.67
date	2015.06.28.01.16.28;	author guenther;	state Exp;
branches;
next	1.66;
commitid	cOmfOzJx69tehqZa;

1.66
date	2015.06.23.14.19.21;	author bluhm;	state Exp;
branches;
next	1.65;
commitid	pMN0nXGj5UUs9Zim;

1.65
date	2015.05.18.19.59.27;	author guenther;	state Exp;
branches;
next	1.64;
commitid	MLFvGCnCMKMdmAtY;

1.64
date	2015.04.18.05.14.05;	author guenther;	state Exp;
branches;
next	1.63;
commitid	omyqf8P2CTirfWNm;

1.63
date	2015.03.22.05.55.39;	author guenther;	state Exp;
branches;
next	1.62;
commitid	F8WJ1eAw5l69o1sl;

1.62
date	2015.01.16.10.17.51;	author sf;	state Exp;
branches;
next	1.61;
commitid	Mg2nJormk2PyesMj;

1.61
date	2014.12.21.16.27.07;	author mlarkin;	state Exp;
branches;
next	1.60;
commitid	dB4lAFOCpyuORTUm;

1.60
date	2014.11.27.17.35.12;	author mlarkin;	state Exp;
branches;
next	1.59;
commitid	XWGaIeI43xeytX3r;

1.59
date	2014.11.20.08.56.52;	author mlarkin;	state Exp;
branches;
next	1.58;
commitid	9oYzqQtIbRm1NsM6;

1.58
date	2014.11.20.06.51.41;	author mlarkin;	state Exp;
branches;
next	1.57;
commitid	rZAY1nGaAOyEEKdK;

1.57
date	2014.11.07.19.34.22;	author mlarkin;	state Exp;
branches;
next	1.56;
commitid	v0qj0pmawZ2Fdf45;

1.56
date	2014.11.05.05.40.02;	author mlarkin;	state Exp;
branches;
next	1.55;
commitid	fkdKbrT5EFqNsWev;

1.55
date	2014.10.09.04.18.09;	author tedu;	state Exp;
branches;
next	1.54;
commitid	TALRTC31uBKXjwur;

1.54
date	2012.11.10.09.45.05;	author mglocker;	state Exp;
branches;
next	1.53;

1.53
date	2012.09.25.09.58.57;	author pirofti;	state Exp;
branches;
next	1.52;

1.52
date	2012.05.06.04.20.40;	author guenther;	state Exp;
branches;
next	1.51;

1.51
date	2011.12.26.23.07.04;	author haesbaert;	state Exp;
branches;
next	1.50;

1.50
date	2011.10.12.18.30.07;	author miod;	state Exp;
branches;
next	1.49;

1.49
date	2011.09.03.01.21.00;	author guenther;	state Exp;
branches;
next	1.48;

1.48
date	2011.07.04.15.54.24;	author guenther;	state Exp;
branches;
next	1.47;

1.47
date	2011.04.13.02.49.12;	author guenther;	state Exp;
branches;
next	1.46;

1.46
date	2011.04.10.03.56.38;	author guenther;	state Exp;
branches;
next	1.45;

1.45
date	2011.04.05.21.14.00;	author guenther;	state Exp;
branches;
next	1.44;

1.44
date	2010.12.04.05.20.18;	author guenther;	state Exp;
branches;
next	1.43;

1.43
date	2010.11.13.04.16.42;	author guenther;	state Exp;
branches;
next	1.42;

1.42
date	2010.10.26.05.49.10;	author guenther;	state Exp;
branches;
next	1.41;

1.41
date	2010.10.14.04.38.24;	author guenther;	state Exp;
branches;
next	1.40;

1.40
date	2010.09.28.03.53.14;	author guenther;	state Exp;
branches;
next	1.39;

1.39
date	2009.06.09.02.56.38;	author krw;	state Exp;
branches;
next	1.38;

1.38
date	2009.06.06.23.45.35;	author guenther;	state Exp;
branches;
next	1.37;

1.37
date	2009.06.05.10.51.44;	author guenther;	state Exp;
branches;
next	1.36;

1.36
date	2009.06.02.03.04.54;	author jordan;	state Exp;
branches;
next	1.35;

1.35
date	2009.05.28.09.05.33;	author art;	state Exp;
branches;
next	1.34;

1.34
date	2009.04.27.17.48.22;	author deraadt;	state Exp;
branches;
next	1.33;

1.33
date	2009.04.23.07.42.02;	author art;	state Exp;
branches;
next	1.32;

1.32
date	2009.03.31.08.49.18;	author art;	state Exp;
branches;
next	1.31;

1.31
date	2009.02.15.17.06.30;	author mikeb;	state Exp;
branches;
next	1.30;

1.30
date	2008.11.12.21.42.43;	author weingart;	state Exp;
branches;
next	1.29;

1.29
date	2008.10.24.06.32.17;	author deraadt;	state Exp;
branches;
next	1.28;

1.28
date	2008.08.13.16.01.08;	author weingart;	state Exp;
branches;
next	1.27;

1.27
date	2008.07.28.19.08.46;	author miod;	state Exp;
branches;
next	1.26;

1.26
date	2008.06.27.06.03.07;	author ray;	state Exp;
branches;
next	1.25;

1.25
date	2007.11.03.20.58.30;	author gwk;	state Exp;
branches;
next	1.24;

1.24
date	2007.10.10.15.53.51;	author art;	state Exp;
branches;
next	1.23;

1.23
date	2007.09.12.18.18.27;	author deraadt;	state Exp;
branches;
next	1.22;

1.22
date	2007.05.27.08.58.31;	author art;	state Exp;
branches;
next	1.21;

1.21
date	2005.08.20.00.33.59;	author jsg;	state Exp;
branches;
next	1.20;

1.20
date	2005.07.26.08.38.29;	author art;	state Exp;
branches;
next	1.19;

1.19
date	2005.05.29.03.20.36;	author deraadt;	state Exp;
branches;
next	1.18;

1.18
date	2005.05.27.19.32.39;	author art;	state Exp;
branches;
next	1.17;

1.17
date	2005.05.25.23.17.47;	author niklas;	state Exp;
branches;
next	1.16;

1.16
date	2005.01.06.20.15.47;	author martin;	state Exp;
branches;
next	1.15;

1.15
date	2005.01.01.03.11.02;	author millert;	state Exp;
branches;
next	1.14;

1.14
date	2004.06.25.11.03.27;	author art;	state Exp;
branches;
next	1.13;

1.13
date	2004.06.22.01.16.50;	author art;	state Exp;
branches;
next	1.12;

1.12
date	2004.06.21.22.35.47;	author niklas;	state Exp;
branches;
next	1.11;

1.11
date	2004.06.13.21.49.12;	author niklas;	state Exp;
branches;
next	1.10;

1.10
date	2004.05.13.20.20.24;	author sturm;	state Exp;
branches;
next	1.9;

1.9
date	2004.02.25.00.16.04;	author deraadt;	state Exp;
branches;
next	1.8;

1.8
date	2004.02.23.09.12.59;	author mickey;	state Exp;
branches;
next	1.7;

1.7
date	2004.02.23.08.32.36;	author mickey;	state Exp;
branches;
next	1.6;

1.6
date	2004.02.23.01.19.52;	author tom;	state Exp;
branches;
next	1.5;

1.5
date	2004.02.22.19.20.09;	author tom;	state Exp;
branches;
next	1.4;

1.4
date	2004.02.20.20.49.57;	author deraadt;	state Exp;
branches;
next	1.3;

1.3
date	2004.02.07.17.00.12;	author miod;	state Exp;
branches
	1.3.2.1;
next	1.2;

1.2
date	2004.02.03.12.09.47;	author mickey;	state Exp;
branches;
next	1.1;

1.1
date	2004.01.28.01.39.38;	author mickey;	state Exp;
branches;
next	;

1.3.2.1
date	2004.02.22.22.08.18;	author niklas;	state Exp;
branches;
next	1.3.2.2;

1.3.2.2
date	2004.06.05.23.09.24;	author niklas;	state Exp;
branches;
next	1.3.2.3;

1.3.2.3
date	2004.06.06.05.42.27;	author tedu;	state Exp;
branches;
next	;


desc
@@


1.87
log
@0xcc-fill a few more alignments.  Not because these ones matter particularily,
but because elimination highlights more important ones.
Cursory review mortimer, ok mlarkin
@
text
@/*	$OpenBSD: locore.S,v 1.86 2017/06/29 17:17:28 deraadt Exp $	*/
/*	$NetBSD: locore.S,v 1.13 2004/03/25 18:33:17 drochner Exp $	*/

/*
 * Copyright-o-rama!
 */

/*
 * Copyright (c) 2001 Wasabi Systems, Inc.
 * All rights reserved.
 *
 * Written by Frank van der Linden for Wasabi Systems, Inc.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *      This product includes software developed for the NetBSD Project by
 *      Wasabi Systems, Inc.
 * 4. The name of Wasabi Systems, Inc. may not be used to endorse
 *    or promote products derived from this software without specific prior
 *    written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY WASABI SYSTEMS, INC. ``AS IS'' AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED
 * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL WASABI SYSTEMS, INC
 * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
 * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
 * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
 * POSSIBILITY OF SUCH DAMAGE.
 */


/*-
 * Copyright (c) 1998, 2000 The NetBSD Foundation, Inc.
 * All rights reserved.
 *
 * This code is derived from software contributed to The NetBSD Foundation
 * by Charles M. Hannum.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 *
 * THIS SOFTWARE IS PROVIDED BY THE NETBSD FOUNDATION, INC. AND CONTRIBUTORS
 * ``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED
 * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE FOUNDATION OR CONTRIBUTORS
 * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
 * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
 * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
 * POSSIBILITY OF SUCH DAMAGE.
 */

/*-
 * Copyright (c) 1990 The Regents of the University of California.
 * All rights reserved.
 *
 * This code is derived from software contributed to Berkeley by
 * William Jolitz.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. Neither the name of the University nor the names of its contributors
 *    may be used to endorse or promote products derived from this software
 *    without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE
 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
 *
 *	@@(#)locore.s	7.3 (Berkeley) 5/13/91
 */

#include "assym.h"
#include "lapic.h"
#include "ksyms.h"
#include "xen.h"
#include "hyperv.h"

#include <sys/syscall.h>

#include <machine/param.h>
#include <machine/segments.h>
#include <machine/specialreg.h>
#include <machine/trap.h>
#include <machine/frameasm.h>

#if NLAPIC > 0
#include <machine/i82489reg.h>
#endif

/*
 * override user-land alignment before including asm.h
 */
#define	ALIGN_DATA	.align	8,0xcc
#define ALIGN_TEXT	.align 16,0x90
#define _ALIGN_TEXT	ALIGN_TEXT

#include <machine/asm.h>

#define SET_CURPROC(proc,cpu)			\
	movq	CPUVAR(SELF),cpu	;	\
	movq	proc,CPUVAR(CURPROC)      ;	\
	movq	cpu,P_CPU(proc)

#define GET_CURPCB(reg)			movq	CPUVAR(CURPCB),reg      
#define SET_CURPCB(reg)			movq	reg,CPUVAR(CURPCB)


/*
 * Initialization
 */
	.data

#if NLAPIC > 0 
	.align  NBPG, 0xcc
	.globl _C_LABEL(local_apic), _C_LABEL(lapic_id), _C_LABEL(lapic_tpr)
_C_LABEL(local_apic):
	.space  LAPIC_ID
_C_LABEL(lapic_id):
	.long   0x00000000
	.space  LAPIC_TPRI-(LAPIC_ID+4)
_C_LABEL(lapic_tpr):
	.space  LAPIC_PPRI-LAPIC_TPRI
_C_LABEL(lapic_ppr):
	.space  LAPIC_ISR-LAPIC_PPRI 
_C_LABEL(lapic_isr):
	.space  NBPG-LAPIC_ISR
#endif

	.globl	_C_LABEL(cpu_id),_C_LABEL(cpu_vendor)
	.globl	_C_LABEL(cpuid_level),_C_LABEL(cpu_feature)
	.globl	_C_LABEL(cpu_ebxfeature)
	.globl	_C_LABEL(cpu_ecxfeature),_C_LABEL(ecpu_ecxfeature)
	.globl	_C_LABEL(cpu_perf_eax)
	.globl	_C_LABEL(cpu_perf_ebx)
	.globl	_C_LABEL(cpu_perf_edx)
	.globl	_C_LABEL(cpu_apmi_edx)
	.globl	_C_LABEL(ssym),_C_LABEL(esym),_C_LABEL(boothowto)
	.globl	_C_LABEL(bootdev)
	.globl	_C_LABEL(bootinfo), _C_LABEL(bootinfo_size), _C_LABEL(atdevbase)
	.globl	_C_LABEL(proc0paddr),_C_LABEL(PTDpaddr)
	.globl	_C_LABEL(biosbasemem),_C_LABEL(biosextmem)
	.globl	_C_LABEL(bootapiver)
	.globl	_C_LABEL(pg_nx)
_C_LABEL(cpu_id):	.long	0	# saved from `cpuid' instruction
_C_LABEL(cpu_feature):	.long	0	# feature flags from 'cpuid'
					#   instruction
_C_LABEL(cpu_ebxfeature):.long	0	# ext. ebx feature flags from 'cpuid'
_C_LABEL(cpu_ecxfeature):.long	0	# ext. ecx feature flags from 'cpuid'
_C_LABEL(ecpu_ecxfeature):.long	0	# extended ecx feature flags
_C_LABEL(cpu_perf_eax):	.long	0	# arch. perf. mon. flags from 'cpuid'
_C_LABEL(cpu_perf_ebx):	.long	0	# arch. perf. mon. flags from 'cpuid'
_C_LABEL(cpu_perf_edx):	.long	0	# arch. perf. mon. flags from 'cpuid'
_C_LABEL(cpu_apmi_edx):	.long	0	# adv. power mgmt. info. from 'cpuid'
_C_LABEL(cpuid_level):	.long	-1	# max. level accepted by 'cpuid'
					#   instruction
_C_LABEL(cpu_vendor):	.space	16	# vendor string returned by `cpuid'
					#   instruction
_C_LABEL(ssym):		.quad	0	# ptr to start of syms
_C_LABEL(esym):		.quad	0	# ptr to end of syms
_C_LABEL(atdevbase):	.quad	0	# location of start of iomem in virtual
_C_LABEL(bootapiver):	.long	0	# /boot API version
_C_LABEL(bootdev):	.long	0	# device we booted from
_C_LABEL(proc0paddr):	.quad	0
_C_LABEL(PTDpaddr):	.quad	0	# paddr of PTD, for libkvm
#ifndef REALBASEMEM
_C_LABEL(biosbasemem):	.long	0	# base memory reported by BIOS
#else
_C_LABEL(biosbasemem):	.long	REALBASEMEM
#endif
#ifndef REALEXTMEM
_C_LABEL(biosextmem):	.long	0	# extended memory reported by BIOS
#else
_C_LABEL(biosextmem):	.long	REALEXTMEM
#endif
_C_LABEL(pg_nx):	.quad	0	# NX PTE bit (if CPU supports)

#define	_RELOC(x)	((x) - KERNBASE)
#define	RELOC(x)	_RELOC(_C_LABEL(x))

	.globl	gdt64

gdt64:
	.word	gdt64_end-gdt64_start-1
	.quad	_RELOC(gdt64_start)
.align 64, 0xcc

gdt64_start:
	.quad 0x0000000000000000	/* always empty */
	.quad 0x00af9a000000ffff	/* kernel CS */
	.quad 0x00cf92000000ffff	/* kernel DS */
gdt64_end:

/*
 * Some hackage to deal with 64bit symbols in 32 bit mode.
 * This may not be needed if things are cleaned up a little.
 */

/*****************************************************************************/

/*
 * Signal trampoline; copied to top of user stack.
 * gdb's backtrace logic matches against the instructions in this.
 */
	.section .rodata
	.globl	_C_LABEL(sigcode)
_C_LABEL(sigcode):
	call	*%rax

	movq	%rsp,%rdi
	pushq	%rdi			/* fake return address */
	movq	$SYS_sigreturn,%rax
	syscall
	.globl	_C_LABEL(sigcoderet)
_C_LABEL(sigcoderet):
	movq	$SYS_exit,%rax
	syscall
	.globl	_C_LABEL(esigcode)
_C_LABEL(esigcode):

	.globl	_C_LABEL(sigfill)
_C_LABEL(sigfill):
	int3
_C_LABEL(esigfill):
	.globl	_C_LABEL(sigfillsiz)
_C_LABEL(sigfillsiz):
	.long	_C_LABEL(esigfill) - _C_LABEL(sigfill)

	.text
/*
 * void lgdt(struct region_descriptor *rdp);
 * Change the global descriptor table.
 */
NENTRY(lgdt)
	/* Reload the descriptor table. */
	movq	%rdi,%rax
	lgdt	(%rax)
	/* Flush the prefetch q. */
	jmp	1f
	nop
1:	/* Reload "stale" selectors. */
	movl	$GSEL(GDATA_SEL, SEL_KPL),%eax
	movl	%eax,%ds
	movl	%eax,%es
	movl	%eax,%ss
	/* Reload code selector by doing intersegment return. */
	popq	%rax
	pushq	$GSEL(GCODE_SEL, SEL_KPL)
	pushq	%rax
	lretq

ENTRY(setjmp)
	/*
	 * Only save registers that must be preserved across function
	 * calls according to the ABI (%rbx, %rsp, %rbp, %r12-%r15)
	 * and %rip.
	 */
	movq	%rdi,%rax
	movq	%rbx,(%rax)
	movq	%rsp,8(%rax)
	movq	%rbp,16(%rax)
	movq	%r12,24(%rax)
	movq	%r13,32(%rax)
	movq	%r14,40(%rax)
	movq	%r15,48(%rax)
	movq	(%rsp),%rdx
	movq	%rdx,56(%rax)
	xorl	%eax,%eax
	ret

ENTRY(longjmp)
	movq	%rdi,%rax
	movq	(%rax),%rbx
	movq	8(%rax),%rsp
	movq	16(%rax),%rbp
	movq	24(%rax),%r12
	movq	32(%rax),%r13
	movq	40(%rax),%r14
	movq	48(%rax),%r15
	movq	56(%rax),%rdx
	movq	%rdx,(%rsp)
	xorl	%eax,%eax
	incl	%eax
	ret

/*****************************************************************************/

/*
 * int cpu_switchto(struct proc *old, struct proc *new)
 * Switch from "old" proc to "new".
 */
ENTRY(cpu_switchto)
	pushq	%rbx
	pushq	%rbp
	pushq	%r12
	pushq	%r13
	pushq	%r14
	pushq	%r15

	movq	%rdi, %r13
	movq	%rsi, %r12

	/* Record new proc. */
	movb	$SONPROC,P_STAT(%r12)	# p->p_stat = SONPROC
	SET_CURPROC(%r12,%rcx)

	movl	CPUVAR(CPUID),%edi

	/* If old proc exited, don't bother. */
	testq	%r13,%r13
	jz	switch_exited

	/*
	 * Save old context.
	 *
	 * Registers:
	 *   %rax, %rcx - scratch
	 *   %r13 - old proc, then old pcb
	 *   %r12 - new proc
	 *   %edi - cpuid
	 */

	movq	P_ADDR(%r13),%r13

	/* clear the old pmap's bit for the cpu */
	movq	PCB_PMAP(%r13),%rcx
	lock
	btrq	%rdi,PM_CPUS(%rcx)

	/* Save stack pointers. */
	movq	%rsp,PCB_RSP(%r13)
	movq	%rbp,PCB_RBP(%r13)

switch_exited:
	/* did old proc run in userspace?  then reset the segment regs */
	btrl	$CPUF_USERSEGS_BIT, CPUVAR(FLAGS)
	jnc	restore_saved

	/* set %ds, %es, and %fs to expected value to prevent info leak */
	movw	$(GSEL(GUDATA_SEL, SEL_UPL)),%ax
	movw	%ax,%ds
	movw	%ax,%es
	movw	%ax,%fs

restore_saved:
	/*
	 * Restore saved context.
	 *
	 * Registers:
	 *   %rax, %rcx, %rdx - scratch
	 *   %r13 - new pcb
	 *   %r12 - new process
	 */

	/* No interrupts while loading new state. */
	cli
	movq	P_ADDR(%r12),%r13

	/* Restore stack pointers. */
	movq	PCB_RSP(%r13),%rsp
	movq	PCB_RBP(%r13),%rbp

	movq	CPUVAR(TSS),%rcx
	movq	PCB_KSTACK(%r13),%rdx
	movq	%rdx,TSS_RSP0(%rcx)

	movq	PCB_CR3(%r13),%rax
	movq	%rax,%cr3

	/* Don't bother with the rest if switching to a system process. */
	testl	$P_SYSTEM,P_FLAG(%r12)
	jnz	switch_restored

	/* set the new pmap's bit for the cpu */
	movl	CPUVAR(CPUID),%edi
	movq	PCB_PMAP(%r13),%rcx
	lock
	btsq	%rdi,PM_CPUS(%rcx)
#ifdef DIAGNOSTIC
	jc	_C_LABEL(switch_pmcpu_set)
#endif

switch_restored:
	/* Restore cr0 (including FPU state). */
	movl	PCB_CR0(%r13),%ecx
#ifdef MULTIPROCESSOR
	movq	PCB_FPCPU(%r13),%r8
	cmpq	CPUVAR(SELF),%r8
	jz	1f
	orl	$CR0_TS,%ecx
1:
#endif
	movq	%rcx,%cr0

	SET_CURPCB(%r13)

	/* Interrupts are okay again. */
	sti

switch_return:

	popq	%r15
	popq	%r14
	popq	%r13
	popq	%r12
	popq	%rbp
	popq	%rbx
	ret

ENTRY(cpu_idle_enter)
	movq	_C_LABEL(cpu_idle_enter_fcn),%rax
	cmpq	$0,%rax
	je	1f
	jmpq	*%rax
1:
	ret

ENTRY(cpu_idle_cycle)
	movq	_C_LABEL(cpu_idle_cycle_fcn),%rax
	cmpq	$0,%rax
	je	1f
	call	*%rax
	ret
1:
	sti
	hlt
	ret

ENTRY(cpu_idle_leave)
	movq	_C_LABEL(cpu_idle_leave_fcn),%rax
	cmpq	$0,%rax
	je	1f
	jmpq	*%rax
1:
	ret

	.globl	_C_LABEL(panic)

#ifdef DIAGNOSTIC
NENTRY(switch_pmcpu_set)
	movabsq	$switch_active,%rdi
	call	_C_LABEL(panic)
	/* NOTREACHED */

	.section .rodata
switch_active:
	.asciz	"activate already active pmap"
	.text
#endif /* DIAGNOSTIC */
/*
 * savectx(struct pcb *pcb);
 * Update pcb, saving current processor state.
 */
ENTRY(savectx)
	/* Save stack pointers. */
	movq	%rsp,PCB_RSP(%rdi)
	movq	%rbp,PCB_RBP(%rdi)

	ret

IDTVEC(syscall32)
	sysret		/* go away please */

/*
 * syscall insn entry. This currently isn't much faster, but
 * it can be made faster in the future.
 */
IDTVEC(syscall)
	/*
	 * Enter here with interrupts blocked; %rcx contains the caller's
	 * %rip and the original rflags has been copied to %r11.  %cs and
	 * %ss have been updated to the kernel segments, but %rsp is still
	 * the user-space value.
	 * First order of business is to swap to the kernel gs.base so that
	 * we can access our struct cpu_info and use the scratch space there
	 * to switch to our kernel stack.  Once that's in place we can
	 * unblock interrupts and save the rest of the syscall frame.
	 */
	swapgs
	movq	%r15,CPUVAR(SCRATCH)
	movq	CPUVAR(CURPCB),%r15
	movq	PCB_KSTACK(%r15),%r15
	xchgq	%r15,%rsp
	sti

	/*
	 * XXX don't need this whole frame, split of the
	 * syscall frame and trapframe is needed.
	 * First, leave some room for the trapno, error,
	 * ss:rsp, etc, so that all GP registers can be
	 * saved. Then, fill in the rest.
	 */
	pushq	$(GSEL(GUDATA_SEL, SEL_UPL))
	pushq	%r15
	subq	$(TF_RSP-TF_TRAPNO),%rsp
	movq	CPUVAR(SCRATCH),%r15
	subq	$32,%rsp
	INTR_SAVE_GPRS
	movq	%r11, TF_RFLAGS(%rsp)	/* old rflags from syscall insn */
	movq	$(GSEL(GUCODE_SEL, SEL_UPL)), TF_CS(%rsp)
	movq	%rcx,TF_RIP(%rsp)
	movq	$2,TF_ERR(%rsp)		/* ignored */

	movq	CPUVAR(CURPROC),%r14
	movq	%rsp,P_MD_REGS(%r14)	# save pointer to frame
	andl	$~MDP_IRET,P_MD_FLAGS(%r14)
	movq	%rsp,%rdi
	call	_C_LABEL(syscall)

.Lsyscall_check_asts:
	/* Check for ASTs on exit to user mode. */
	cli
	CHECK_ASTPENDING(%r11)
	je	2f
	CLEAR_ASTPENDING(%r11)
	sti
	movq	%rsp,%rdi
	call	_C_LABEL(ast)
	jmp	.Lsyscall_check_asts

2:
#ifdef DIAGNOSTIC
	cmpl	$IPL_NONE,CPUVAR(ILEVEL)
	jne	.Lsyscall_spl_not_lowered
#endif /* DIAGNOSTIC */

	/* Could registers have been changed that require an iretq? */
	testl	$MDP_IRET, P_MD_FLAGS(%r14)
	jne	intr_fast_exit

	movq	TF_RDI(%rsp),%rdi
	movq	TF_RSI(%rsp),%rsi
	movq	TF_R8(%rsp),%r8
	movq	TF_R9(%rsp),%r9
	movq	TF_R10(%rsp),%r10
	movq	TF_R12(%rsp),%r12
	movq	TF_R13(%rsp),%r13
	movq	TF_R14(%rsp),%r14
	movq	TF_R15(%rsp),%r15
	movq	TF_RBP(%rsp),%rbp
	movq	TF_RBX(%rsp),%rbx

	INTR_RESTORE_SELECTORS

	movq	TF_RDX(%rsp),%rdx
	movq	TF_RAX(%rsp),%rax

	movq	TF_RIP(%rsp),%rcx
	movq	TF_RFLAGS(%rsp),%r11
	movq	TF_RSP(%rsp),%rsp
	sysretq

#ifdef DIAGNOSTIC
.Lsyscall_spl_not_lowered:
	movabsq	$spl_lowered, %rdi
	movl	TF_RAX(%rsp),%esi
	movl	TF_RDI(%rsp),%edx
	movl	%ebx,%ecx
	movl	CPUVAR(ILEVEL),%r8d
	xorq	%rax,%rax
	call	_C_LABEL(printf)
#ifdef DDB
	int	$3
#endif /* DDB */
	movl	$IPL_NONE,CPUVAR(ILEVEL)
	jmp	.Lsyscall_check_asts

	.section .rodata
spl_lowered:
	.asciz	"WARNING: SPL NOT LOWERED ON SYSCALL %d %d EXIT %x %x\n"
	.text
#endif

NENTRY(proc_trampoline)
#ifdef MULTIPROCESSOR
	call	_C_LABEL(proc_trampoline_mp)
#endif
	movl	$IPL_NONE,CPUVAR(ILEVEL)
	movq	%r13,%rdi
	call	*%r12
	movq	CPUVAR(CURPROC),%r14
	jmp	.Lsyscall_check_asts


/*
 * Return via iretq, for real interrupts and signal returns
 */
NENTRY(intr_fast_exit)
	movq	TF_RDI(%rsp),%rdi
	movq	TF_RSI(%rsp),%rsi
	movq	TF_R8(%rsp),%r8
	movq	TF_R9(%rsp),%r9
	movq	TF_R10(%rsp),%r10
	movq	TF_R12(%rsp),%r12
	movq	TF_R13(%rsp),%r13
	movq	TF_R14(%rsp),%r14
	movq	TF_R15(%rsp),%r15
	movq	TF_RBP(%rsp),%rbp
	movq	TF_RBX(%rsp),%rbx

	testq	$SEL_RPL,TF_CS(%rsp)
	je	5f

	INTR_RESTORE_SELECTORS

5:	movq	TF_RDX(%rsp),%rdx
	movq	TF_RCX(%rsp),%rcx
	movq	TF_R11(%rsp),%r11
	movq	TF_RAX(%rsp),%rax

#if !defined(GPROF) && defined(DDBPROF)
	/*
	 * If we are returning from a probe trap we need to fix the
	 * stack layout and emulate the patched instruction.
	 *
	 * The code below does that by trashing %rax, so it MUST be
	 * restored afterward.
	 */
	cmpl	$INTR_FAKE_TRAP, TF_ERR(%rsp)
	je	.Lprobe_fixup
#endif /* !defined(GPROF) && defined(DDBPROF) */

	addq	$TF_RIP,%rsp

	.globl	_C_LABEL(doreti_iret)
_C_LABEL(doreti_iret):
	iretq


#if !defined(GPROF) && defined(DDBPROF)
.Lprobe_fixup:
	/* Reserve enough room to emulate "pushq %rbp". */
	subq	$16, %rsp

	/* Shift hardware-saved registers. */
	movq	(TF_RIP + 16)(%rsp), %rax
	movq	%rax, TF_RIP(%rsp)
	movq	(TF_CS + 16)(%rsp), %rax
	movq	%rax, TF_CS(%rsp)
	movq	(TF_RFLAGS + 16)(%rsp), %rax
	movq	%rax, TF_RFLAGS(%rsp)
	movq	(TF_RSP + 16)(%rsp), %rax
	movq	%rax, TF_RSP(%rsp)
	movq	(TF_SS + 16)(%rsp), %rax
	movq	%rax, TF_SS(%rsp)

	/* Pull 8 bytes off the stack and store %rbp in the expected location.*/
	movq	TF_RSP(%rsp), %rax
	subq	$8, %rax
	movq	%rax, TF_RSP(%rsp)
	movq	%rbp, (%rax)

	/* Write back overwritten %rax */
	movq	(TF_RAX + 16)(%rsp),%rax

	addq	$TF_RIP,%rsp
	iretq
#endif /* !defined(GPROF) && defined(DDBPROF) */

ENTRY(pagezero)
	movq    $-PAGE_SIZE,%rdx
	subq    %rdx,%rdi
	xorq    %rax,%rax
1:
	movnti  %rax,(%rdi,%rdx)
	movnti  %rax,8(%rdi,%rdx)
	movnti  %rax,16(%rdi,%rdx)
	movnti  %rax,24(%rdi,%rdx)
	addq    $32,%rdx
	jne     1b
	sfence
	ret

#if NXEN > 0
	/* Hypercall page needs to be page aligned */
	.text
	.align	NBPG, 0xcc
	.globl	_C_LABEL(xen_hypercall_page)
_C_LABEL(xen_hypercall_page):
	.skip	0x1000, 0xcc
#endif /* NXEN > 0 */

#if NHYPERV > 0
	/* Hypercall page needs to be page aligned */
	.text
	.align	NBPG, 0xcc
	.globl	_C_LABEL(hv_hypercall_page)
_C_LABEL(hv_hypercall_page):
	.skip	0x1000, 0xcc
#endif /* NXEN > 0 */
@


1.86
log
@Put asm-generated strings into .rodata
ok millert
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.85 2017/05/31 19:18:18 deraadt Exp $	*/
d128 1
a128 1
#define	ALIGN_DATA	.align	8
@


1.85
log
@Split early startup code out of locore.S into locore0.S.  Adjust link
run so that this locore0.o is always at the start of the executable.
But randomize the link order of all other .o files in the kernel, so
that their exec/rodata/data/bss segments land all over the place.
Late during kernel boot, unmap the early startup code.

As a result, the internal layout of every newly build bsd kernel is
different from past kernels.  Internal relative offsets are not known
to an outside attacker.  The only known offsets are in the startup code,
which has been unmapped.

Ramdisk kernels cannot be compiled like this, because they are gzip'd.
When the internal pointer references change, the compression dictionary
bloats and results in poorer compression.

ok kettenis mlarkin visa, also thanks to tedu for getting me back to this
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.84 2017/02/06 09:15:51 mpi Exp $	*/
d475 1
a475 1
	movabsq	$1f,%rdi
d478 5
a482 1
1:	.asciz	"activate already active pmap"
a483 1

d589 1
a589 1
	movabsq	$4f, %rdi
d601 5
a605 1
4:	.asciz	"WARNING: SPL NOT LOWERED ON SYSCALL %d %d EXIT %x %x\n"
a606 1

@


1.84
log
@Sync a comment with i386.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.83 2016/09/04 09:22:28 mpi Exp $	*/
a142 5
/* XXX temporary kluge; these should not be here */
/* Get definitions for IOM_BEGIN, IOM_END, and IOM_SIZE */
#include <dev/isa/isareg.h>


a227 10
farjmp64:
	.long	longmode-KERNBASE
	.word	GSEL(GCODE_SEL, SEL_KPL)

	.space 512
tmpstk:

	.globl _C_LABEL(cpu_private)
	.comm _C_LABEL(cpu_private),NBPG,NBPG

a232 503
	.text
	.globl	_C_LABEL(kernel_text)
	.set	_C_LABEL(kernel_text),KERNTEXTOFF

	.code32

	.globl	start
start:	movw	$0x1234,0x472			# warm boot

	/*
	 * Load parameters from stack
	 * (howto, bootdev, bootapiver, esym, extmem, cnvmem, ac, av)
	 */
	movl	4(%esp),%eax
	movl	%eax, RELOC(boothowto)
	movl	8(%esp),%eax
	movl	%eax, RELOC(bootdev)

	/*
	 * Syms are placed after last load and bss of the kernel.
	 * XXX Boot ignores 2MB roundup of _end, so esyms can be < _end.
	 */
	movl	16(%esp), %eax
	testl   %eax,%eax
	jz      1f
	addl    $KERNBASE_LO,%eax
	movl    $RELOC(esym),%ebp
	movl    %eax,(%ebp)
	movl    $KERNBASE_HI,4(%ebp)
1:
	movl	20(%esp), %eax
	movl	%eax, RELOC(biosextmem)
	movl	24(%esp), %eax
	movl	%eax, RELOC(biosbasemem)

	movl	12(%esp), %eax
	movl	%eax, RELOC(bootapiver)

	/*
	 * Copy the boot arguments to bootinfo[] in machdep.c.
	 *
	 * We are passed the size of the data /boot passed to us in
	 * 28(%esp). We copy up to bootinfo_size bytes of data into
	 * bootinfo and report back how much we copied in bootinfo_size.
	 *
	 * machdep.c can then take action if bootinfo_size >= bootinfo[]
	 * (which would meant that we may have been passed too much data).
	 */
 	movl	28(%esp), %eax
	movl	%eax, %ecx
	cmpl	RELOC(bootinfo_size), %ecx	/* Too much? */
	jb	bi_size_ok
	movl	RELOC(bootinfo_size), %ecx	/* Only copy this much */
bi_size_ok:
	movl	%eax, RELOC(bootinfo_size)	/* Report full amount */
 
	movl	$RELOC(bootinfo), %edi		/* Destination */
	movl	32(%esp), %esi			/* Source */
	rep movsb				/* Copy this many bytes */

	/* First, reset the PSL. */
	pushl	$PSL_MBO
	popfl

	xorl	%eax,%eax
	cpuid
	movl	%eax,RELOC(cpuid_level)
	movl	$RELOC(cpu_vendor),%ebp
	movl	%ebx,(%ebp)
	movl	%edx,4(%ebp)
	movl	%ecx,8(%ebp)
	movl	$0,  12(%ebp)

	movl	$1,%eax
	cpuid
	movl	%eax,RELOC(cpu_id)
	movl	%ebx,RELOC(cpu_ebxfeature)
	movl	%ecx,RELOC(cpu_ecxfeature)
	movl	%edx,RELOC(cpu_feature)

	movl	$0x0a,%eax
	cpuid
	movl	%eax,RELOC(_C_LABEL(cpu_perf_eax))
	movl	%ebx,RELOC(_C_LABEL(cpu_perf_ebx))
	movl	%edx,RELOC(_C_LABEL(cpu_perf_edx))

	movl	$0x80000001, %eax
	cpuid
	andl	$CPUID_NXE, %edx	/* other bits may clash */
	jz	cont

	/*
	 * We have NX, set pg_nx accordingly.
	 * NX bit is bit 63 (bit 31 of the second 32 bit dword) - need
	 * to use 32 bit registers here
	 */
	pushl	%edx
	movl	RELOC((pg_nx + 4)), %edx	/* Second dword */
	orl	$0x80000000, %edx 		/* Bit 31 (really 63) */
	movl	%edx, RELOC((pg_nx + 4))
	popl	%edx
cont:
	orl     %edx, RELOC(cpu_feature)

	movl	$0x80000007,%eax
	cpuid
	movl	%edx,RELOC(_C_LABEL(cpu_apmi_edx))

	/*
	 * Finished with old stack; load new %esp now instead of later so we
	 * can trace this code without having to worry about the trace trap
	 * clobbering the memory test or the zeroing of the bss+bootstrap page
	 * tables.
	 *
	 * The boot program should check:
	 *	text+data <= &stack_variable - more_space_for_stack
	 *	text+data+bss+pad+space_for_page_tables <= end_of_memory
	 * Oops, the gdt is in the carcass of the boot program so clearing
	 * the rest of memory is still not possible.
	 */
	movl	$RELOC(tmpstk),%esp

/*
 * Virtual address space of kernel:
 *
 * text | data | bss | [syms] | page dir | proc0 kstack | L1 ptp | L2 ptp | L3 
 *			      0          1       2      3
 */

#if L2_SLOT_KERNBASE > 0
#define TABLE_L2_ENTRIES (2 * (NKL2_KIMG_ENTRIES + 1))
#else
#define TABLE_L2_ENTRIES (NKL2_KIMG_ENTRIES + 1)
#endif

#if L3_SLOT_KERNBASE > 0
#define TABLE_L3_ENTRIES (2 * NKL3_KIMG_ENTRIES)
#else
#define TABLE_L3_ENTRIES NKL3_KIMG_ENTRIES
#endif


#define PROC0_PML4_OFF	0
#define PROC0_STK_OFF	(PROC0_PML4_OFF + NBPG)
#define PROC0_PTP3_OFF	(PROC0_STK_OFF + UPAGES * NBPG)
#define PROC0_PTP2_OFF	(PROC0_PTP3_OFF + NKL4_KIMG_ENTRIES * NBPG)
#define PROC0_PTP1_OFF	(PROC0_PTP2_OFF + TABLE_L3_ENTRIES * NBPG)
#define	PROC0_DMP3_OFF	(PROC0_PTP1_OFF + TABLE_L2_ENTRIES * NBPG)
#define PROC0_DMP2_OFF	(PROC0_DMP3_OFF + NDML3_ENTRIES * NBPG)
#define TABLESIZE \
    ((NKL4_KIMG_ENTRIES + TABLE_L3_ENTRIES + TABLE_L2_ENTRIES + 1 + UPAGES + \
	NDML3_ENTRIES + NDML2_ENTRIES) * NBPG)

#define fillkpt \
1:	movl	%eax,(%ebx)	; 	/* store phys addr */ \
	movl	$0,4(%ebx)	; 	/* upper 32 bits 0 */ \
	addl	$8,%ebx		; 	/* next pte/pde */ \
	addl	$NBPG,%eax	; 	/* next phys page */ \
	loop	1b		;	/* till finished */


#define fillkpt_nx \
	pushl	%ebp				;	/* save */ \
1:	movl	%eax,(%ebx)			; 	/* store phys addr */ \
	movl	RELOC((pg_nx + 4)), %ebp	;	/* NX bit? */ \
	movl	%ebp,4(%ebx)			; 	/* upper 32 bits */ \
	addl	$8,%ebx				; 	/* next pte/pde */ \
	addl	$NBPG,%eax			; 	/* next phys page */ \
	loop	1b				;	/* till finished */ \
	popl	%ebp

	/* Find end of kernel image. */
	movl	$RELOC(end),%edi
#if (NKSYMS || defined(DDB))
	/* Save the symbols (if loaded). */
	movl	RELOC(esym),%eax
	testl	%eax,%eax
	jz	1f
	subl	$KERNBASE_LO,%eax	/* XXX */
	/* Page tables must be after symbols and after kernel image. */
	cmpl	%eax,%edi
	jg	1f
	movl	%eax,%edi
1:
#endif
	/* Clear tables */
	movl	%edi,%esi
	addl	$PGOFSET,%esi
	andl	$~PGOFSET,%esi

	movl	%esi,%edi
	xorl	%eax,%eax
	cld
	movl	$TABLESIZE,%ecx
	shrl	$2,%ecx
	rep
	stosl

	leal	(PROC0_PTP1_OFF)(%esi), %ebx

	/*
	 * Compute etext - KERNBASE. This can't be > 4G, or we can't deal
	 * with it anyway, since we can't load it in 32 bit mode. So use
	 * the bottom 32 bits.
	 */
	movl	$RELOC(etext),%edx
	addl	$PGOFSET,%edx
	andl	$~PGOFSET,%edx

	/*
	 * Skip the first MB.
	 */
	movl	$(KERNTEXTOFF_LO - KERNBASE_LO),%eax
	movl	%eax,%ecx
	shrl	$(PGSHIFT-3),%ecx	/* ((n >> PGSHIFT) << 3) for # pdes */
	addl	%ecx,%ebx

	/* Map kernel text RO, X */
	movl	%edx,%ecx
	subl	%eax,%ecx
	shrl	$PGSHIFT,%ecx
	orl     $(PG_V|PG_KR),%eax
	fillkpt

	/* Map .rodata RO, NX */
	movl	$RELOC(__rodata_start), %eax
	movl	$RELOC(erodata), %ecx
	addl	$PGOFSET, %ecx
	andl	$~PGOFSET, %ecx
	subl	%eax, %ecx
	shrl	$PGSHIFT, %ecx
	orl	$(PG_V|PG_KR), %eax
	fillkpt_nx

	/* Map the data and BSS sections RW, NX */
	movl	$RELOC(__data_start), %eax
	movl	$RELOC(__kernel_bss_end),%ecx
	addl	$PGOFSET, %ecx
	andl	$~PGOFSET, %ecx
	subl	%eax, %ecx
	shrl	$PGSHIFT,%ecx
	orl	$(PG_V|PG_KW), %eax
	fillkpt_nx

	/* Map "hole" at end of BSS RO, NX */
	movl	$RELOC(__kernel_bss_end), %eax
	movl	$RELOC(end), %ecx
	addl	$PGOFSET, %ecx
	andl	$~PGOFSET, %ecx
	cmpl	%eax, %ecx
	je	map_syms
	subl	%eax, %ecx
	shrl	$PGSHIFT, %ecx
	orl	$(PG_V|PG_KR), %eax
	fillkpt_nx

map_syms:
	/* Map symbol space RO, NX */
	movl	$RELOC(end), %eax
	movl	%esi, %ecx
	addl	$PGOFSET, %ecx
	andl	$~PGOFSET, %ecx
	cmpl	%eax, %ecx
	je	map_tables
	subl	%eax, %ecx
	shrl	$PGSHIFT, %ecx
	orl	$(PG_V|PG_KR), %eax
	fillkpt_nx

map_tables:
	/* Map the bootstrap tables RW, NX */
	movl	%esi, %edx
	leal	(PG_V|PG_KW)(%edx),%eax
	movl	$TABLESIZE,%ecx
	shrl	$PGSHIFT,%ecx
	fillkpt_nx

	/* Map ISA I/O mem (later atdevbase) RW, NX */
	movl	$(IOM_BEGIN|PG_V|PG_KW/*|PG_N*/),%eax
	movl	$(IOM_SIZE>>PGSHIFT),%ecx
	fillkpt_nx

	/* Set up level 2 pages (RWX) */
	leal    (PROC0_PTP2_OFF)(%esi),%ebx
	leal	(PROC0_PTP1_OFF)(%esi),%eax
	orl	$(PG_V|PG_KW), %eax
	movl	$(NKL2_KIMG_ENTRIES+1),%ecx
	fillkpt

#if L2_SLOT_KERNBASE > 0
	/* If needed, set up L2 entries for actual kernel mapping (RWX) */
	leal	(PROC0_PTP2_OFF+ L2_SLOT_KERNBASE*8)(%esi),%ebx
	leal    (PROC0_PTP1_OFF)(%esi),%eax
	orl     $(PG_V|PG_KW), %eax
	movl    $(NKL2_KIMG_ENTRIES+1),%ecx
	fillkpt
#endif

	/* Set up level 3 pages (RWX) */
	leal    (PROC0_PTP3_OFF)(%esi),%ebx
	leal	(PROC0_PTP2_OFF)(%esi),%eax
	orl	$(PG_V|PG_KW), %eax
	movl	$NKL3_KIMG_ENTRIES,%ecx
	fillkpt

#if L3_SLOT_KERNBASE > 0
	/* If needed, set up L3 entries for actual kernel mapping (RWX) */
	leal	(PROC0_PTP3_OFF+ L3_SLOT_KERNBASE*8)(%esi),%ebx
	leal    (PROC0_PTP2_OFF)(%esi),%eax
	orl     $(PG_V|PG_KW), %eax
	movl    $NKL3_KIMG_ENTRIES,%ecx
	fillkpt
#endif

	/* Set up top level entries for identity mapping (RWX) */
	leal    (PROC0_PML4_OFF)(%esi),%ebx
	leal	(PROC0_PTP3_OFF)(%esi),%eax
	orl	$(PG_V|PG_KW), %eax
	movl	$NKL4_KIMG_ENTRIES,%ecx
	fillkpt

	/* Set up top level entries for actual kernel mapping (RWX) */
	leal    (PROC0_PML4_OFF + L4_SLOT_KERNBASE*8)(%esi),%ebx
	leal	(PROC0_PTP3_OFF)(%esi),%eax
	orl	$(PG_V|PG_KW), %eax
	movl	$NKL4_KIMG_ENTRIES,%ecx
	fillkpt

	/*
	 * Map the first 4 GB with the direct map. We'll map the rest
	 * in pmap_bootstrap. But we always need the first 4GB during
	 * bootstrap. The direct map is mapped RW, NX. We also change
	 * the permissions on the 2MB pages corresponding to the kernel
	 * PAs to RO to prevent someone writing to the kernel area
	 * via the direct map.
	 */
	leal	(PROC0_DMP2_OFF)(%esi), %ebx
	xorl	%eax, %eax
	movl	$(NDML2_ENTRIES * NPDPG), %ecx
1:	orl	$(PG_V|PG_KW|PG_PS|PG_G), %eax
	cmpl	$__kernel_base_phys, %eax
	jl	store_pte
	cmpl	$__kernel_end_phys, %eax
	jg	store_pte
	andl	$(~PG_KW), %eax
store_pte:
	movl	%eax, (%ebx)
	pushl	%ebp
	movl	RELOC((pg_nx + 4)), %ebp
	movl	%ebp, 4(%ebx)
	popl	%ebp
	addl	$8, %ebx
	addl	$NBPD_L2, %eax
	loop	1b

	leal	(PROC0_DMP3_OFF)(%esi), %ebx
	leal	(PROC0_DMP2_OFF)(%esi), %eax
	orl	$(PG_V|PG_KW), %eax
	movl	$NDML2_ENTRIES, %ecx
	fillkpt_nx

	leal	(PROC0_PML4_OFF + PDIR_SLOT_DIRECT * 8)(%esi), %ebx
	leal	(PROC0_DMP3_OFF)(%esi), %eax
	orl	$(PG_V|PG_KW), %eax
	movl	$NDML3_ENTRIES, %ecx
	fillkpt_nx

	/* Install recursive top level PDE */
	leal	(PROC0_PML4_OFF + PDIR_SLOT_PTE*8)(%esi),%ebx
	leal	(PROC0_PML4_OFF)(%esi),%eax
	orl	$(PG_V|PG_KW),%eax
	movl	%eax,(%ebx)
	pushl	%ebp
	movl	RELOC((pg_nx + 4)), %ebp
	movl	%ebp, 4(%ebx)
	popl 	%ebp

	/* Save phys. addr of PTD, for libkvm. */
	movl	$RELOC(PTDpaddr),%ebp
	movl	%esi,(%ebp)
	movl	$0,4(%ebp)

	/*
	 * Startup checklist:
	 * 1. Enable PAE (and SSE while here).
	 */
	movl	%cr4,%eax
	orl	$(CR4_DEFAULT),%eax
	movl	%eax,%cr4

	/*
	 * 2. Set Long Mode Enable in EFER. Also enable the
	 *    syscall extensions and NX (if available).
	 */
	movl    $MSR_EFER,%ecx
	rdmsr
	xorl	%eax,%eax	/* XXX */
	orl	$(EFER_LME|EFER_SCE),%eax
	movl	RELOC((pg_nx + 4)), %ebx
	cmpl	$0, %ebx
	je 	write_efer
	orl	$(EFER_NXE), %eax
write_efer:	
	wrmsr

	/*
	 * 3. Load %cr3 with pointer to PML4.
	 */
	movl	%esi,%eax
	movl	%eax,%cr3

	/*
	 * 4. Enable paging and the rest of it.
	 */
	movl	%cr0,%eax
	orl	$(CR0_PE|CR0_PG|CR0_NE|CR0_TS|CR0_MP|CR0_WP),%eax
	movl	%eax,%cr0
	jmp	compat
compat:

	/*
	 * 5.
	 * Not quite done yet, we're now in a compatibility segment,
	 * in legacy mode. We must jump to a long mode segment.
	 * Need to set up a temporary GDT with a long mode segment
	 * in it to do that.
	 */

	movl	$RELOC(gdt64),%eax
	lgdt	(%eax)
	movl	$RELOC(farjmp64),%eax
	ljmp	*(%eax)

.code64
longmode:
	/*
	 * 6.
	 * Finally, we're in long mode. However, we're still
	 * in the identity mapped area (could not jump out
	 * of that earlier because it would have been a > 32bit
	 * jump). We can do that now, so here we go.
	 */
	movabsq	$longmode_hi,%rax
	jmp	*%rax
longmode_hi:
	/*
	 * We have arrived.
	 * There's no need anymore for the identity mapping in low
	 * memory, remove it.
	 */
	movq	$KERNBASE,%r8

#if L2_SLOT_KERNBASE > 0
	movq	$(NKL2_KIMG_ENTRIES+1),%rcx
	leaq	(PROC0_PTP2_OFF)(%rsi),%rbx
	addq	%r8, %rbx
1:	movq	$0 ,(%rbx)
	addq	$8,%rbx
	loop	1b
#endif

#if L3_SLOT_KERNBASE > 0
	movq	$NKL3_KIMG_ENTRIES,%rcx
	leaq	(PROC0_PTP3_OFF)(%rsi),%rbx
	addq	%r8, %rbx
1:	movq	$0 ,(%rbx)
	addq	$8,%rbx
	loop	1b
#endif

	movq	$NKL4_KIMG_ENTRIES,%rcx
	leaq	(PROC0_PML4_OFF)(%rsi),%rbx	# old, phys  address of PML4
	addq	%r8, %rbx			# new, virtual address of PML4
1:	movq	$0, (%rbx)
	addq	$8,%rbx
	loop	1b

	/* Relocate atdevbase. */
	movq	$(TABLESIZE+KERNBASE),%rdx
	addq	%rsi,%rdx
	movq	%rdx,_C_LABEL(atdevbase)(%rip)

	/* Record start of symbols */
	movq	$__kernel_bss_end, _C_LABEL(ssym)(%rip)

	/* Set up bootstrap stack. */
	leaq	(PROC0_STK_OFF)(%rsi),%rax
	addq	%r8,%rax
	movq	%rax,_C_LABEL(proc0paddr)(%rip)
	leaq	(USPACE-FRAMESIZE)(%rax),%rsp
	movq	%rsi,PCB_CR3(%rax)	# pcb->pcb_cr3
	xorq	%rbp,%rbp               # mark end of frames

	xorw	%ax,%ax
	movw	%ax,%gs
	movw	%ax,%fs

	/* XXX merge these */
	leaq	TABLESIZE(%rsi),%rdi
	call	_C_LABEL(init_x86_64)

	call 	_C_LABEL(main)

a700 11

	.section .codepatch,"a"
	.align  8, 0xcc
	.globl _C_LABEL(codepatch_begin)
_C_LABEL(codepatch_begin):
	.previous

	.section .codepatchend,"a"
	.globl _C_LABEL(codepatch_end)
_C_LABEL(codepatch_end):
	.previous
@


1.83
log
@Introduce Dynamic Profiling, a ddb(4) based & gprof compatible kernel
profiling framework.

Code patching is used to enable probes when entering functions.  The
probes will call a mcount()-like function to match the behavior of a
GPROF kernel.

Currently only available on amd64 and guarded under DDBPROF.  Support
for other archs will follow soon.

A new sysctl knob, ddb.console, need to be set to 1 in securelevel 0
to be able to use this feature.

Inputs and ok guenther@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.82 2016/07/16 06:04:29 mlarkin Exp $	*/
d1193 1
a1193 1
	/* Pull 8 bytes off the stack and store the content of the register. */
@


1.82
log
@
remove some unused #includes
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.81 2016/06/22 01:12:38 mikeb Exp $	*/
d1156 13
d1175 30
@


1.81
log
@Setup Hyper-V hypercall page and an IDT vector.

ok mlarkin, kettenis, deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.80 2016/06/06 06:02:02 deraadt Exp $	*/
a108 1
#include "ioapic.h"
a109 1
#include "acpi.h"
a112 1
#include <sys/errno.h>
@


1.80
log
@Fill a few more pads with 0xcc
ok mikeb, mlarkin
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.79 2016/05/23 20:11:49 deraadt Exp $	*/
d113 1
d1197 9
@


1.79
log
@Place a cpu-dependent trap/illegal instruction over the remainder of the
sigtramp page, so that it will generate a nice kernel fault if touched.
While here, move most of the sigtramps to the .rodata segment, because
they are not executed in the kernel.
Also some preparation for sliding the actual sigtramp forward (will need
some gdb changes)
ok mlarkin kettenis
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.78 2016/05/10 18:39:42 deraadt Exp $	*/
d156 1
a156 1
	.align  NBPG
d227 1
a227 1
.align 64
d1180 1
a1180 1
	.align  8
d1193 1
a1193 1
	.align	NBPG
d1196 1
a1196 1
	.skip	0x1000, 0xcc	/* Fill with int3 */
@


1.78
log
@SROP mitigation.  sendsig() stores a (per-process ^ &sigcontext) cookie
inside the sigcontext.  sigreturn(2) checks syscall entry was from the
exact PC addr in the (per-process ASLR) sigtramp, verifies the cookie,
and clears it to prevent sigcontext reuse.
not yet tested on landisk, sparc, *88k, socppc.
ok kettenis
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.77 2016/05/10 14:15:57 mikeb Exp $	*/
d759 3
a761 1
NENTRY(sigcode)
d768 1
a768 1
	.globl  _C_LABEL(sigcoderet)
d775 9
@


1.77
log
@Fill Xen hypercall page with int3's like the hypervisor does.

Idea from deraadt@@ and mlarkin@@.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.76 2016/02/26 02:23:07 mlarkin Exp $	*/
d766 2
@


1.76
log
@
SYMTAB_SPACE is no longer used (last used with a.out ddb)
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.75 2016/01/04 01:03:03 mlarkin Exp $	*/
d1183 1
a1183 1
	.skip	0x1000, 0x90	/* Fill with NOPs */
@


1.75
log
@
wrap a long line
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.74 2015/12/08 18:54:10 mikeb Exp $	*/
d423 1
a423 1
#if (NKSYMS || defined(DDB)) && !defined(SYMTAB_SPACE)
@


1.74
log
@Setup a hypercall page in the kernel .text segment

Its location will be communicated with the Xen hypervisor
that will fill it in with instructions resulting in VMEXIT
events.

Discussed with kettenis@@ and deraadt@@, with input from and
OK mpi, mlarkin, reyk
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.73 2015/11/09 01:08:56 mlarkin Exp $	*/
d179 2
a180 1
	.globl	_C_LABEL(ssym),_C_LABEL(esym),_C_LABEL(boothowto),_C_LABEL(bootdev)
@


1.73
log
@
Cache the result of cpuid leaf function $0x1 from the host's boot CPU
during locore, information based on this will be returned to guest VMs
issuing cpuid instructions later, under certain circumstances.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.72 2015/07/17 15:37:58 guenther Exp $	*/
d112 1
d1175 9
@


1.72
log
@Consistently use SEL_RPL as the mask when testing selector privilege level
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.71 2015/07/17 06:13:44 mlarkin Exp $	*/
d172 1
d187 2
a188 1
_C_LABEL(cpu_ecxfeature):.long	0	# extended feature flags from 'cpuid'
d324 1
@


1.71
log
@
"are we 386, 386sx, or 486, or Pentium, or.."

I'm pretty sure the amd64 kernel won't boot on any of those CPUs, so
delete the (unused) variable that was supposed to track which 32 bit
CPU we were running on.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.70 2015/07/16 23:04:12 mlarkin Exp $	*/
d1131 1
a1131 1
	testq	$SEL_UPL,TF_CS(%rsp)
@


1.70
log
@
remove 'cpu_brand_id' as we no longer use that method to calculate the
name of the cpu. Further, the calculation of cpu_brand_id was in the
wrong place to begin with, so it was being calculated incorrectly anyway.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.69 2015/07/16 21:12:12 mlarkin Exp $	*/
a182 2
_C_LABEL(cpu):		.long	0	# are we 386, 386sx, or 486,
					#   or Pentium, or..
@


1.69
log
@
Fix a backward compare in boot argument parsing, and clarify a comment that
was wrong.

ok guenther@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.68 2015/06/28 18:54:54 guenther Exp $	*/
d170 1
a170 1
	.globl	_C_LABEL(cpu_id),_C_LABEL(cpu_vendor), _C_LABEL(cpu_brand_id)
a197 1
_C_LABEL(cpu_brand_id):	.long	0	# brand ID from 'cpuid' instruction
a353 4

	/* Brand ID is bits 0-7 of %ebx */
	andl	$255,%ebx
	movl	%ebx,RELOC(cpu_brand_id)
@


1.68
log
@Force the return to userspace from execve to go through iretq to get all
registers.  This lets us kill the special handling of pid 1 in fork and
merge {proc,child}_trampoline(). Do the same if ptrace(PT_SETREGS) is used
to modify registers.

ok mlarkin@@ kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.67 2015/06/28 01:16:28 guenther Exp $	*/
d290 3
a292 2
	 * We are passed the size of bootinfo[] in bootinfo_size, and
	 * we report how much data /boot passed us back in the same variable.
d300 1
a300 1
	jnc	bi_size_ok
@


1.67
log
@Split AST handling from trap() into ast() and get rid of T_ASTFLT.
Don't skip the AST check when returning from *fork() in the child.
Make sure to count interrupts even when they're deferred or stray.

testing by krw@@, and then many via snapshots
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.66 2015/06/23 14:19:21 bluhm Exp $	*/
a1110 10
#ifdef MULTIPROCESSOR
	call	_C_LABEL(proc_trampoline_mp)
#endif
	movl	$IPL_NONE,CPUVAR(ILEVEL)
	movq	%r13,%rdi
	call	*%r12
	INTRFASTEXIT
	/* NOTREACHED */

NENTRY(child_trampoline)
@


1.66
log
@If the kernel symbols fit completely into the 2 MB alignment hole
after kernel bss but before end of the image, the page tables used
the read-only mapping of the hole.  When booting a small non-generic
kernel, this resulted in a crash, while writing to the page tables
later.
Make sure that the page tables are created after esym and after
end.
OK mlarkin@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.65 2015/05/18 19:59:27 guenther Exp $	*/
a1041 1
	movq	$T_ASTFLT, TF_TRAPNO(%rsp)
d1048 3
a1050 1
1:	/* Check for ASTs on exit to user mode. */
a1053 1
	/* Always returning to user mode here. */
a1055 1
	/* Pushed T_ASTFLT into tf_trapno on entry. */
d1057 3
a1059 2
	call	_C_LABEL(trap)
	jmp	1b
a1060 4
	sti
	testl	$MDP_IRET, P_MD_FLAGS(%r14)
	jne	iret_return;
syscall_return:
d1063 1
a1063 1
	jne	3f
d1066 4
d1093 2
a1094 1
3:	movabsq	$4f, %rdi
d1105 1
a1105 1
	jmp	1b
d1127 2
a1128 1
	jmp	syscall_return
d1134 1
a1134 8
iret_return:
1:
#ifdef DIAGNOSTIC
	cmpl	$IPL_NONE,CPUVAR(ILEVEL)
	jne	3f
#endif /* DIAGNOSTIC */
	.globl	intr_fast_exit
intr_fast_exit:
a1160 13

#ifdef DIAGNOSTIC
3:	sti
	movabsq	$4f, %rdi
	xorq	%rax,%rax
	call	_C_LABEL(printf)
#ifdef DDB
	int	$3
#endif /* DDB */
	movl	$IPL_NONE,CPUVAR(ILEVEL)
	jmp	2b
4:	.asciz	"WARNING: SPL NOT LOWERED ON SYSCALL EXIT\n"
#endif /* DIAGNOSTIC */
@


1.65
log
@Do lazy update/reset of the FS.base and %[def]s segment registers: reseting
segment registers in cpu_switchto if the old thread had made it to userspace
and restoring FS.base only on first return to userspace since context switch.

ok mlarkin@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.64 2015/04/18 05:14:05 guenther Exp $	*/
d267 4
d430 3
@


1.64
log
@i386 and amd64 have only one syscall entry point now, so simply the
EIP/RIP adjustment for ERESTART

ok mlarkin@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.63 2015/03/22 05:55:39 guenther Exp $	*/
d870 11
a1030 4
	movw	%fs,TF_FS(%rsp)
	movw	%gs,TF_GS(%rsp)
	movw	%es,TF_ES(%rsp)
	movw	$(GSEL(GUDATA_SEL, SEL_UPL)),TF_DS(%rsp)
@


1.63
log
@Explain the state on syscall entry
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.62 2015/01/16 10:17:51 sf Exp $	*/
d1027 1
a1027 1
	movq	$2,TF_ERR(%rsp)
@


1.62
log
@Binary code patching on amd64

This commit adds generic infrastructure to do binary code patching on amd64.
The existing code patching for SMAP is converted to the new infrastruture.

More consumers and support for i386 will follow later.

This version of the diff has some simplifications in codepatch_fill_nop()
compared to a version that was:

OK @@kettenis @@mlarkin @@jsg
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.61 2014/12/21 16:27:07 mlarkin Exp $	*/
d990 10
@


1.61
log
@Prevent writing to the kernel area via the direct map. We do this by padding
the end of the kernel area to 2MB, so that the direct map pages can then
have the W permission removed (X permission was already removed in a previous
diff). This creates a VA hole at the end of bss, so adjust for that since
that's where symbols get loaded by the bootloader (for now, map that region
RO until the boot loader can be updated to place the symbols at "end" instead
of "end of bss").

with help from and ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.60 2014/11/27 17:35:12 mlarkin Exp $	*/
d1171 10
@


1.60
log
@
Missing comparison caused NX to always be enabled during boot, even on CPUs
that may have had it disabled in BIOS.

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.59 2014/11/20 08:56:52 mlarkin Exp $	*/
d177 1
a177 1
	.globl	_C_LABEL(esym),_C_LABEL(boothowto),_C_LABEL(bootdev)
d199 1
d478 9
a486 2
	/* Reload %edx for data_start */
	movl	$RELOC(__data_start), %edx
d488 28
a515 1
	/* Map the data, BSS, and bootstrap tables RW, NX */
a517 2
	addl	%esi,%ecx		/* %ecx = end + TABLESIZE */
	subl	%edx,%ecx		/* %ecx = %ecx - data_start */
d575 4
a578 1
	 * bootstrap. The direct map is mapped RW, NX.
a581 1
	orl	$(PG_V|PG_KW|PG_PS|PG_G), %eax
d583 8
a590 1
1:	movl	%eax, (%ebx)
d725 3
@


1.59
log
@
When removing the identity mapping in low memory used during bootstrap,
there is no reason to keep the NX bit around on null PTEs (PTEs that have
been removed).
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.58 2014/11/20 06:51:41 mlarkin Exp $	*/
d601 2
a602 1
	jz 	write_efer
@


1.58
log
@
Move previous PTE permission fixup code into locore, and fixup some more
ranges while we're there.

ok deraadt@@, tested by many and in snaps
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.57 2014/11/07 19:34:22 mlarkin Exp $	*/
d657 1
a657 1
1:	movq	_C_LABEL(pg_nx),(%rbx)
d666 1
a666 2
	movq	_C_LABEL(pg_nx), %r9
1:	movq	%r9 ,(%rbx)
d674 1
a674 2
	movq	_C_LABEL(pg_nx), %r9
1:	movq	%r9, (%rbx)
@


1.57
log
@
Wrong comment - NX is handled later (for now), not in locore. No functional
change.

noticed by deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.56 2014/11/05 05:40:02 mlarkin Exp $	*/
d182 1
d215 1
a247 1

d331 13
d399 1
a399 1
#define fillkpt	\
d404 1
a404 1
	loop	1b		;  \
d407 10
d460 1
a460 1
	/* Map kernel text read-only */
d467 1
a467 1
	/* Map .rodata read-only */
d475 1
a475 1
	fillkpt
d480 1
a480 1
	/* Map the data, BSS, and bootstrap tables read-write. */
d486 1
a486 1
	fillkpt
d488 1
a488 1
	/* Map ISA I/O mem (later atdevbase) */
d491 1
a491 1
	fillkpt
d493 1
a493 1
	/* Set up level 2 pages */
d501 1
a501 1
	/* If needed, set up level 2 entries for actual kernel mapping */
d509 1
a509 1
	/* Set up level 3 pages */
d517 1
a517 1
	/* If needed, set up level 3 entries for actual kernel mapping */
d525 1
a525 1
	/* Set up top level entries for identity mapping */
d532 1
a532 1
	/* Set up top level entries for actual kernel mapping */
d542 1
a542 1
	 * bootstrap.
d549 4
a552 1
	movl	$0, 4(%ebx)
d561 1
a561 1
	fillkpt
d567 1
a567 1
	fillkpt
d574 4
a577 2
	movl	$0, 4(%ebx)

d594 1
a594 1
	 *    syscall extensions.
d600 4
d657 1
a657 1
1:	movq	$0,(%rbx)
d666 2
a667 1
1:	movq	$0,(%rbx)
d675 2
a676 1
1:	movq	$0,(%rbx)
@


1.56
log
@
Map .rodata RO after boot on amd64. Makefile.amd64 changes from deraadt.

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.55 2014/10/09 04:18:09 tedu Exp $	*/
d443 1
a443 1
	/* Map .rodata read-only, and NX if available */
@


1.55
log
@no need for lkm_map now
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.54 2012/11/10 09:45:05 mglocker Exp $	*/
d443 13
d459 2
a460 2
	addl	%esi,%ecx		/* %ecx = &end[TABLESIZE] */
	subl	%edx,%ecx		/* %ecx = %ecx - etext */
@


1.54
log
@Recent x86 CPUs come with a constant time stamp counter.  If this is
the case we verify if the CPU supports a specific version of the
architectural performance monitoring feature and read out the current
frequency from the fixed-function performance counter of the unhalted
core.

My initial motivation to implement this was the Soekris net6501-70
which comes with an Intel Atom E6xx 1.60GHz CPU.  It has a constant
time stamp counter plus speed step support and boots on the lowest
frequency of 600MHz.  This caused hw.cpuspeed and hw.setperf to
reflect the wrong values.

The diff is a cooperation work with jsg@@.  The fixed-function
performance counter read code comes from a former diff of him.

OK jsg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.53 2012/09/25 09:58:57 pirofti Exp $	*/
d395 1
a395 1
#if (NKSYMS || defined(DDB) || defined(LKM)) && !defined(SYMTAB_SPACE)
@


1.53
log
@Remove unused acpi locking code.

To be replaced with higher level C routines once we settle for a common
consistent set of atomic operations across platforms.

Discussed with and okay by deraadt@@ and kettenis@@.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.52 2012/05/06 04:20:40 guenther Exp $	*/
d173 4
d189 4
d321 6
d331 4
@


1.52
log
@Garbage collect the old int$80 kernel entry point: the last use of
it by the not-normally-used sigreturn() stub in libc was changed to
use 'syscall' instruction in 5.0

ok mikeb@@ jsg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.51 2011/12/26 23:07:04 haesbaert Exp $	*/
a1059 28

#if NACPI > 0
ENTRY(acpi_acquire_global_lock)
	movq	%rdi, %rcx
1:	movl	(%rcx), %eax
	movl	%eax, %edx
	andl	$~1, %edx
	btsl	$1, %edx
	adcl	$0, %edx
	lock
	cmpxchgl       %edx, (%rcx)
	jnz	1b
	andl	$3, %edx
	cmpl	$3, %edx
	sbb	%eax, %eax
	ret

ENTRY(acpi_release_global_lock)
	movq	%rdi, %rcx
1:	movl	(%rcx), %eax
	movl	%eax, %edx
	andl	$~3, %edx
	lock
	cmpxchgl	%edx, (%rcx)
	jnz	1b
	andl	$1, %eax
	ret
#endif
@


1.51
log
@Add the missing ECX cpu flags from CPUID at 0x80000001.
This is all documented at:

http://support.amd.com/us/Embedded_TechDocs/25481.pdf (page 20)
http://www.intel.com/assets/pdf/appnote/241618.pdf (page 41)

ok jsg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.50 2011/10/12 18:30:07 miod Exp $	*/
a993 25

/*
 * Trap gate entry for old int $80 syscall (used to be used by sigreturn)
 */
IDTVEC(osyscall)
	pushq	$2		# size of instruction for restart
	pushq	$T_ASTFLT	# trap # for doing ASTs
	INTRENTRY
	sti
	movq	CPUVAR(CURPROC),%rdx
	movq	%rsp,P_MD_REGS(%rdx)	# save pointer to frame
	movq	%rsp,%rdi
	call	_C_LABEL(syscall)
_C_LABEL(osyscall_return):
2:	/* Check for ASTs on exit to user mode. */
	cli
	CHECK_ASTPENDING(%r11)
	je	1f
	/* Always returning to user mode here. */
	CLEAR_ASTPENDING(%r11)
	sti
	/* Pushed T_ASTFLT into tf_trapno on entry. */
	movq	%rsp,%rdi
	call	_C_LABEL(trap)
	jmp	2b
@


1.50
log
@Remove all MD diagnostics in cpu_switchto(), and move them to MI code if
they apply.

ok oga@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.49 2011/09/03 01:21:00 guenther Exp $	*/
d172 1
a172 1
	.globl	_C_LABEL(cpu_ecxfeature)
d184 1
@


1.49
log
@Add a general warning about gdb matching against sigcode instructions
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.48 2011/07/04 15:54:24 guenther Exp $	*/
a726 8
#ifdef DIAGNOSTIC
	xorq	%rax,%rax
	cmpq	%rax,P_WCHAN(%r12)
	jne	_C_LABEL(switch_error2)
	cmpb	$SRUN,P_STAT(%r12)
	jne	_C_LABEL(switch_error3)
#endif

a852 15
NENTRY(switch_error1)
	movabsq	$1f,%rdi
	call	_C_LABEL(panic)
	/* NOTREACHED */
1:	.asciz	"cpu_switch 1"
NENTRY(switch_error2)
	movabsq	$1f,%rdi
	call	_C_LABEL(panic)
	/* NOTREACHED */
1:	.asciz	"cpu_switch 2"
NENTRY(switch_error3)
	movabsq	$1f,%rdi
	call	_C_LABEL(panic)
	/* NOTREACHED */
1:	.asciz	"cpu_switch 3"
@


1.48
log
@Force the sigreturn syscall to return to userspace via iretq by setting
the MDP_IRET flag in md_proc, then switch sigcode to enter the kernel
via syscall instead of int$80.  Rearrange the return paths in both the
sysretq and iretq paths to reduce how long interrupts are blocked and
shave instructions.

ok kettenis@@, extra testing krw@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.47 2011/04/13 02:49:12 guenther Exp $	*/
d640 1
@


1.47
log
@Unrevert the FS.base diff: the issues were actually elsewhere
Additional testing by jasper@@ and pea@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.46 2011/04/10 03:56:38 guenther Exp $	*/
a639 6
 *
 * Note, the "system call" to sigreturn() needs to be an 'int $0x80' one
 * so that the kernel returns using 'iretq' method.  This way if a process
 * was interrupted (by tick) as opposed to in the kernel when a signal was
 * being delivered, the process will be completely restored, including the
 * userland %rcx register, which the 'sysret' instruction can not restore.
d647 1
a647 1
	int	$0x80
d955 14
a968 4
#endif
	/*
	 * XXX interrupts off longer than they should be here.
	 */
d970 7
a976 6
	INTR_RESTORE_GPRS
	addq	$48,%rsp
	popq	%rcx	/* return rip */
	addq	$8,%rsp
	popq	%r11	/* flags as set by sysret insn */
	movq	%ss:(%rsp),%rsp
a1014 2
	.globl  _C_LABEL(osyscall_return)

d1017 1
a1017 1
 * Trap gate entry for int $80 syscall, also used by sigreturn.
d1041 3
d1052 12
d1066 1
d1068 7
a1074 2
5:	INTR_RESTORE_GPRS
	addq	$48,%rsp
@


1.46
log
@Revert bulk of the FS.base diff, as it causes issues on some machines
and the problem isn't obvious yet.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.45 2011/04/05 21:14:00 guenther Exp $	*/
d965 1
a965 5
	cli
	swapgs
	movw	TF_ES(%rsp),%es
	movw	TF_FS(%rsp),%fs
	movw	TF_GS(%rsp),%gs
a966 2
	movw	$(GSEL(GUDATA_SEL, SEL_UPL)),%r11
	movw	%r11,%ds
d1046 1
a1046 2
	INTR_RESTORE_GPRS
	testq	$SEL_UPL,56(%rsp)
d1048 3
a1050 7
	cli
	swapgs
	movw	0(%rsp),%gs
	movw	8(%rsp),%fs
	movw	16(%rsp),%es
	movw	24(%rsp),%ds
5:	addq	$48,%rsp
@


1.45
log
@Add support for per-rthread base-offset for the %fs selector on amd64.
Add pcb_fsbase to the PCB for tracking what the value for the thread
is, and ci_cur_fsbase to struct cpu_info for tracking the CPU's current
value for FS.base, then on return to user-space, skip the setting if the
CPU has the right value already.  Non-threaded processes without TLS leave
FS.base zero, which can be conveniently optimized: setting %fs zeros
FS.base for fewer cycles than wrmsr.

ok kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.44 2010/12/04 05:20:18 guenther Exp $	*/
d965 5
a969 1
	INTR_RESTORE_SELECTORS
d971 2
d1052 2
a1053 1
	testq	$SEL_UPL,TF_CS(%rsp)
d1055 7
a1061 3
	INTR_RESTORE_SELECTORS
5:	INTR_RESTORE_GPRS
	addq	$48,%rsp
@


1.44
log
@The pm_cpus member of the pmap is now a 64bit integer: update the assembly
used in cpu_switch() for handling it.  Also, delete an unnecessary
instruction that I added while debugging the pm_cpus handling before

ok kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.43 2010/11/13 04:16:42 guenther Exp $	*/
d965 1
a965 5
	cli
	swapgs
	movw	TF_ES(%rsp),%es
	movw	TF_FS(%rsp),%fs
	movw	TF_GS(%rsp),%gs
a966 2
	movw	$(GSEL(GUDATA_SEL, SEL_UPL)),%r11
	movw	%r11,%ds
d1046 1
a1046 2
	INTR_RESTORE_GPRS
	testq	$SEL_UPL,56(%rsp)
d1048 3
a1050 7
	cli
	swapgs
	movw	0(%rsp),%gs
	movw	8(%rsp),%fs
	movw	16(%rsp),%es
	movw	24(%rsp),%ds
5:	addq	$48,%rsp
@


1.43
log
@Switch from TSS-per-process to TSS-per-CPU, placing the TSS right
next to the cpu's GDT, also making the double-fault stack per-CPU,
leaving it at the top of the page of the CPU's idle process.  Inline
pmap_activate() and pmap_deactivate() into the asm cpu_switchto
routine, adding a check for the new pmap already being marked as
active on the CPU.  Garbage collect the hasn't-been-used-in-years
GDT update IPI.

Tested by many; ok mikeb@@, kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.42 2010/10/26 05:49:10 guenther Exp $	*/
d765 1
a765 1
	btrl	%edi,PM_CPUS(%rcx)
a802 1
	movl	PM_CPUS(%rcx),%eax
d804 1
a804 1
	btsl	%edi,PM_CPUS(%rcx)
@


1.42
log
@The LDT is only used by dead compat code now, so load the ldt
register with the null selector (disabling use of it), stop reloading
it on every context switch, and blow away the table itself, as well
as the pcb and pmap bits that were used to track it.  Also, delete
two other unused pcb members: pcb_usersp and pcb_flags.  (Deleting
pcb_usersp also keeps the pcb_savefpu member aligned properly.)
Finally, delete the defines for the unimplemented AMD64_{GET,SET}_LDT
sysarch() calls.

Tested by various with both AMD and Intel chips
ok mikeb@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.41 2010/10/14 04:38:24 guenther Exp $	*/
d744 2
d757 1
d760 1
a760 2
	movq	%r13,%rdi
	call	pmap_deactivate
d762 4
a765 1
	movq	P_ADDR(%r13),%r13
d789 7
a795 1
#if 0
a798 1
#endif
d800 8
a807 5
	/* Load TSS info. */
#ifdef MULTIPROCESSOR
	movq    CPUVAR(GDT),%rax
#else   
	movq	_C_LABEL(gdtstore)(%rip),%rax
a808 5
	movl	P_MD_TSS_SEL(%r12),%edx

	/* Switch TSS. Reset "task busy" flag before */
	andl	$~0x0200,4(%rax,%rdx, 1)
	ltr	%dx
a809 4
	movq	%r12,%rdi
	call	_C_LABEL(pmap_activate)

#if 0
a810 1
#endif
d882 5
d911 1
a911 1
	movq	PCB_RSP0(%r15),%r15
@


1.41
log
@Clean up segment handling: switch user-space to using code and data
segments in the GDT instead of the LDT and eliminate the GDT slots
that we don't actually use.

tested on both amd and intel by several
not really the right person, but ok: kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.40 2010/09/28 03:53:14 guenther Exp $	*/
a1010 13
/* XXX - can we zap the following two? */

/*
 * Old call gate entry for syscall. only needed if we're
 * going to support running old NetBSD or ibcs2 binaries, etc,
 * on NetBSD/amd64.
 */
IDTVEC(oosyscall)
	/* Set rflags in trap frame. */
	pushfq
	popq	8(%rsp)
	pushq	$7		# size of instruction for restart
	jmp	osyscall1
a1016 1
osyscall1:
@


1.40
log
@Correct the handling of GS.base when iretq faults: the fault happens
with CPL == 0 but the user's GS.base, so the normal INTRENTRY handling
won't work.  Contrawise, the asm that trap() redirects us to when that
happens (resume_iret) sees a trapframe showing CPL==3 but it's run with
the kernel's GS.base, so INTRENTRY won't work there either.

asm style fixes drahn@@ and mikeb@@
ok kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.39 2009/06/09 02:56:38 krw Exp $	*/
d914 1
a914 1
	pushq	$(LSEL(LUDATA_SEL, SEL_UPL))
d923 1
a923 1
	movw	$(LSEL(LUDATA_SEL, SEL_UPL)),TF_DS(%rsp)
d925 1
a925 1
	movq	$(LSEL(LUCODE_SEL, SEL_UPL)), TF_CS(%rsp)
d964 1
a964 1
	movw	$(LSEL(LUDATA_SEL, SEL_UPL)),%r11
@


1.39
log
@revert guenther@@'s un-revert of art's curpmap.

My

bios0: ASUSTeK Computer INC. P5K-E
cpu0: Intel(R) Core(TM)2 Quad CPU Q6600 @@ 2.40GHz, 2405.74 MHz
cpu1: Intel(R) Core(TM)2 Quad CPU Q6600 @@ 2.40GHz, 2405.46 MHz
cpu2: Intel(R) Core(TM)2 Quad CPU Q6600 @@ 2.40GHz, 2405.46 MHz
cpu3: Intel(R) Core(TM)2 Quad CPU Q6600 @@ 2.40GHz, 2405.46 MHz

can't boot with this in. It always hangs somewhere in fsck'ing if
any, or between netstart and local daemons if no fsck'ing. Also
fubars theo's real amd machine.

Much more testing needed for this.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.38 2009/06/06 23:45:35 guenther Exp $	*/
d1052 3
a1054 4
#ifndef DIAGNOSTIC
1:	INTRFASTEXIT
#else /* DIAGNOSTIC */
1:	cmpl	$IPL_NONE,CPUVAR(ILEVEL)
d1056 18
a1073 1
	INTRFASTEXIT
@


1.38
log
@Unrevert the curpmap change with the addition of correct %gs handling
in the IPI handler so that it works when it interrupts userspace,
waiting for the droppmap IPI to complete when destroying it, and
(most importantly) don't call pmap_tlb_droppmap() from cpu_exit().
Tested by myself and ckuethe, as our machines choked on the original.

ok @@art
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.36 2009/06/02 03:04:54 jordan Exp $	*/
d135 9
d148 1
d729 3
d734 1
a734 1
	cmpq	%rax,P_WCHAN(%rsi)
d736 1
a736 1
	cmpb	$SRUN,P_STAT(%rsi)
a739 3
	/* No interrupts while loading new state. */
	cli

d741 2
a742 2
	movb	$SONPROC,P_STAT(%rsi)	# p->p_stat = SONPROC
	movq	%rsi, CPUVAR(CURPROC)
d744 2
a745 2
	/* If old proc exited, don't bother saving state. */
	testq	%rdi,%rdi
d748 14
a762 1
	movq	P_ADDR(%rdi),%r13
d765 1
d773 1
d776 4
a780 1
	movq	P_ADDR(%rsi),%r13
d784 5
a788 1
	movq	%r13, CPUVAR(CURPCB)
d791 1
d793 4
a796 1
	movl	P_MD_TSS_SEL(%rsi),%edx
d802 2
a803 2
	call	_C_LABEL(pmap_switch)
	/* %rsi and %rdi no longer valid */
d805 3
d819 2
d823 2
@


1.37
log
@Revert the curpmap change.  We know the IPI is broken on both ends,
but even with proposed fixes, the reaper panics are back.
@
text
@a134 9
#define SET_CURPROC(proc,cpu)			\
	movq	CPUVAR(SELF),cpu	;	\
	movq	proc,CPUVAR(CURPROC)      ;	\
	movq	cpu,P_CPU(proc)

#define GET_CURPCB(reg)			movq	CPUVAR(CURPCB),reg      
#define SET_CURPCB(reg)			movq	reg,CPUVAR(CURPCB)


a138 1

a718 3
	movq	%rdi, %r13
	movq	%rsi, %r12

d721 1
a721 1
	cmpq	%rax,P_WCHAN(%r12)
d723 1
a723 1
	cmpb	$SRUN,P_STAT(%r12)
d727 3
d731 2
a732 2
	movb	$SONPROC,P_STAT(%r12)	# p->p_stat = SONPROC
	SET_CURPROC(%r12,%rcx)
d734 2
a735 2
	/* If old proc exited, don't bother. */
	testq	%r13,%r13
a737 14
	/*
	 * Save old context.
	 *
	 * Registers:
	 *   %rax, %rcx - scratch
	 *   %r13 - old proc, then old pcb
	 *   %r12 - new proc
	 */

	movq	%r13,%rdi
	call	pmap_deactivate

	movq	P_ADDR(%r13),%r13

d739 1
a741 1

a748 1
	 *   %r12 - new process
a750 4
	/* No interrupts while loading new state. */
	cli
	movq	P_ADDR(%r12),%r13

d752 1
d756 1
a756 5
#if 0
	/* Don't bother with the rest if switching to a system process. */
	testl	$P_SYSTEM,P_FLAG(%r12)
	jnz	switch_restored
#endif
a758 1
#ifdef MULTIPROCESSOR
d760 1
a760 4
#else   
	movq	_C_LABEL(gdtstore)(%rip),%rax
#endif
	movl	P_MD_TSS_SEL(%r12),%edx
d766 2
a767 2
	movq	%r12,%rdi
	call	_C_LABEL(pmap_activate)
a768 3
#if 0
switch_restored:
#endif
a779 2
	SET_CURPCB(%r13)

a781 2

switch_return:
@


1.36
log
@Added interface for cpu idle on amd64
ok gwk@@, toby@@, marco@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.35 2009/05/28 09:05:33 art Exp $	*/
d135 9
d148 1
d729 3
d734 1
a734 1
	cmpq	%rax,P_WCHAN(%rsi)
d736 1
a736 1
	cmpb	$SRUN,P_STAT(%rsi)
a739 3
	/* No interrupts while loading new state. */
	cli

d741 2
a742 2
	movb	$SONPROC,P_STAT(%rsi)	# p->p_stat = SONPROC
	movq	%rsi, CPUVAR(CURPROC)
d744 2
a745 2
	/* If old proc exited, don't bother saving state. */
	testq	%rdi,%rdi
d748 14
a762 1
	movq	P_ADDR(%rdi),%r13
d765 1
d773 1
d776 4
a780 1
	movq	P_ADDR(%rsi),%r13
d784 5
a788 1
	movq	%r13, CPUVAR(CURPCB)
d791 1
d793 4
a796 1
	movl	P_MD_TSS_SEL(%rsi),%edx
d802 2
a803 2
	call	_C_LABEL(pmap_switch)
	/* %rsi and %rdi no longer valid */
d805 3
d819 2
d823 2
@


1.35
log
@Bring back the curpmap change. It was missing a reload of the pmap on
curcpu when we were freeing a pmap. Tested and working for a few weeks
now, but I was a bit too busy to commit it earlier.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.33 2009/04/23 07:42:02 art Exp $	*/
d792 5
d800 7
d811 5
d1069 1
@


1.34
log
@turning pmap_deactivate into a NOP brought back the reaper panics, probably
because the reaper is running on the mappings of pmap from the process it
is about to unmap.  back it out until ht is fixed right; don't let this sit
in the tree waiting for a fix.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.32 2009/03/31 08:49:18 art Exp $	*/
a134 9
#define SET_CURPROC(proc,cpu)			\
	movq	CPUVAR(SELF),cpu	;	\
	movq	proc,CPUVAR(CURPROC)      ;	\
	movq	cpu,P_CPU(proc)

#define GET_CURPCB(reg)			movq	CPUVAR(CURPCB),reg      
#define SET_CURPCB(reg)			movq	reg,CPUVAR(CURPCB)


a138 1

a718 3
	movq	%rdi, %r13
	movq	%rsi, %r12

d721 1
a721 1
	cmpq	%rax,P_WCHAN(%r12)
d723 1
a723 1
	cmpb	$SRUN,P_STAT(%r12)
d727 3
d731 2
a732 2
	movb	$SONPROC,P_STAT(%r12)	# p->p_stat = SONPROC
	SET_CURPROC(%r12,%rcx)
d734 2
a735 2
	/* If old proc exited, don't bother. */
	testq	%r13,%r13
a737 14
	/*
	 * Save old context.
	 *
	 * Registers:
	 *   %rax, %rcx - scratch
	 *   %r13 - old proc, then old pcb
	 *   %r12 - new proc
	 */

	movq	%r13,%rdi
	call	pmap_deactivate

	movq	P_ADDR(%r13),%r13

d739 1
a741 1

a748 1
	 *   %r12 - new process
a750 4
	/* No interrupts while loading new state. */
	cli
	movq	P_ADDR(%r12),%r13

d752 1
d756 1
a756 5
#if 0
	/* Don't bother with the rest if switching to a system process. */
	testl	$P_SYSTEM,P_FLAG(%r12)
	jnz	switch_restored
#endif
a758 1
#ifdef MULTIPROCESSOR
d760 1
a760 4
#else   
	movq	_C_LABEL(gdtstore)(%rip),%rax
#endif
	movl	P_MD_TSS_SEL(%r12),%edx
d766 2
a767 2
	movq	%r12,%rdi
	call	_C_LABEL(pmap_activate)
a768 3
#if 0
switch_restored:
#endif
a779 2
	SET_CURPCB(%r13)

a781 2

switch_return:
@


1.33
log
@Make pmap_deactivate a NOP.

Instead of keeping a bitmask of on which cpu the pmap might be active which
we clear in pmap_deactivate, always keep a pointer to the currently loaded
pmap in cpu_info. We can now optimize a context switch to the kernel pmap
(idle and kernel threads) to keep the previously loaded pmap still loaded
and then reuse that pmap if we context switch back to the same process.

Introduce a new IPI to force a pmap reload before the pmap is destroyed.

Clean up cpu_switchto.

toby@@ ok
@
text
@d135 9
d148 1
d729 3
d734 1
a734 1
	cmpq	%rax,P_WCHAN(%rsi)
d736 1
a736 1
	cmpb	$SRUN,P_STAT(%rsi)
a739 3
	/* No interrupts while loading new state. */
	cli

d741 2
a742 2
	movb	$SONPROC,P_STAT(%rsi)	# p->p_stat = SONPROC
	movq	%rsi, CPUVAR(CURPROC)
d744 2
a745 2
	/* If old proc exited, don't bother saving state. */
	testq	%rdi,%rdi
d748 14
a762 1
	movq	P_ADDR(%rdi),%r13
d765 1
d773 1
d776 4
a780 1
	movq	P_ADDR(%rsi),%r13
d784 5
a788 1
	movq	%r13, CPUVAR(CURPCB)
d791 1
d793 4
a796 1
	movl	P_MD_TSS_SEL(%rsi),%edx
d802 2
a803 2
	call	_C_LABEL(pmap_switch)
	/* %rsi and %rdi no longer valid */
d805 3
d819 2
d823 2
@


1.32
log
@- remove obsolete comment
- remove dead (#if 0) code
- move switch_error panics to after cpu_switchto to make branch prediction
  happier and the code more readable.

no functional change
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.31 2009/02/15 17:06:30 mikeb Exp $	*/
a134 9
#define SET_CURPROC(proc,cpu)			\
	movq	CPUVAR(SELF),cpu	;	\
	movq	proc,CPUVAR(CURPROC)      ;	\
	movq	cpu,P_CPU(proc)

#define GET_CURPCB(reg)			movq	CPUVAR(CURPCB),reg      
#define SET_CURPCB(reg)			movq	reg,CPUVAR(CURPCB)


a138 1

a718 3
	movq	%rdi, %r13
	movq	%rsi, %r12

d721 1
a721 1
	cmpq	%rax,P_WCHAN(%r12)
d723 1
a723 1
	cmpb	$SRUN,P_STAT(%r12)
d727 3
d731 2
a732 2
	movb	$SONPROC,P_STAT(%r12)	# p->p_stat = SONPROC
	SET_CURPROC(%r12,%rcx)
d734 2
a735 2
	/* If old proc exited, don't bother. */
	testq	%r13,%r13
a737 14
	/*
	 * Save old context.
	 *
	 * Registers:
	 *   %rax, %rcx - scratch
	 *   %r13 - old proc, then old pcb
	 *   %r12 - new proc
	 */

	movq	%r13,%rdi
	call	pmap_deactivate

	movq	P_ADDR(%r13),%r13

d739 1
a741 1

a748 1
	 *   %r12 - new process
a750 4
	/* No interrupts while loading new state. */
	cli
	movq	P_ADDR(%r12),%r13

d752 1
d756 1
a756 5
#if 0
	/* Don't bother with the rest if switching to a system process. */
	testl	$P_SYSTEM,P_FLAG(%r12)
	jnz	switch_restored
#endif
a758 1
#ifdef MULTIPROCESSOR
d760 1
a760 4
#else   
	movq	_C_LABEL(gdtstore)(%rip),%rax
#endif
	movl	P_MD_TSS_SEL(%r12),%edx
d766 2
a767 2
	movq	%r12,%rdi
	call	_C_LABEL(pmap_activate)
a768 3
#if 0
switch_restored:
#endif
a779 2
	SET_CURPCB(%r13)

a781 2

switch_return:
@


1.31
log
@Set the limit of the GDT table to its size - 1.

Reported by and diff from Remco <remco at d-compu.dyndns.org>, thanks!
Checked with kettenis@@.

ok kettenis
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.30 2008/11/12 21:42:43 weingart Exp $	*/
a717 29
 * The following primitives manipulate the run queues.
 * _whichqs tells which of the 32 queues _qs
 * have processes in them.  Setrq puts processes into queues, Remrq
 * removes them from queues.  The running process is on no queue,
 * other processes are on a queue related to p->p_pri, divided by 4
 * actually to shrink the 0-127 range of priorities into the 32 available
 * queues.
 */
	.globl	_C_LABEL(uvmexp),_C_LABEL(panic)

#ifdef DIAGNOSTIC
NENTRY(switch_error1)
	movabsq	$1f,%rdi
	call	_C_LABEL(panic)
	/* NOTREACHED */
1:	.asciz	"cpu_switch 1"
NENTRY(switch_error2)
	movabsq	$1f,%rdi
	call	_C_LABEL(panic)
	/* NOTREACHED */
1:	.asciz	"cpu_switch 2"
NENTRY(switch_error3)
	movabsq	$1f,%rdi
	call	_C_LABEL(panic)
	/* NOTREACHED */
1:	.asciz	"cpu_switch 3"
#endif /* DIAGNOSTIC */

/*
a825 7
#if 0
	/* Violation of lock ordering, since we're holding the sched_lock */
	movl	$IPL_NONE,%edi
	call	_C_LABEL(Xspllower)
	movl	$IPL_HIGH,CPUVAR(ILEVEL)
#endif

d844 19
@


1.30
log
@Add a comment to sigcode() to explain why the use of 'int $0x80' is
necessary, so that future hackers will not be mislead the same way I
was when looking at this code.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.29 2008/10/24 06:32:17 deraadt Exp $	*/
d212 1
a212 1
	.word	gdt64_end-gdt64_start
@


1.29
log
@remove unused label
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.28 2008/08/13 16:01:08 weingart Exp $	*/
d640 6
@


1.28
log
@This tab had bugged me forever.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.27 2008/07/28 19:08:46 miod Exp $	*/
a754 1
switch_resume:
@


1.27
log
@No longer clear ci_want_resched within cpu_switchto(), now that it's done
in the MI code.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.26 2008/06/27 06:03:07 ray Exp $	*/
d225 1
a225 1
	
@


1.26
log
@More removal of clauses 3 and 4 from NetBSD licenses.

OK deraadt@@ and millert@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.25 2007/11/03 20:58:30 gwk Exp $	*/
a754 3
	xorq	%rax,%rax
	movl	%eax,CPUVAR(RESCHED)

d757 1
@


1.25
log
@Add acpi_acquire_global_lock(), and acpi_release_global_lock to
amd64 the not ghetto architecture.

ok toby@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.24 2007/10/10 15:53:51 art Exp $	*/
a58 7
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *        This product includes software developed by the NetBSD
 *        Foundation, Inc. and its contributors.
 * 4. Neither the name of The NetBSD Foundation nor the names of its
 *    contributors may be used to endorse or promote products derived
 *    from this software without specific prior written permission.
@


1.24
log
@Make context switching much more MI:
 - Move the functionality of choosing a process from cpu_switch into
   a much simpler function: cpu_switchto. Instead of having the locore
   code walk the run queues, let the MI code choose the process we
   want to run and only implement the context switching itself in MD
   code.
 - Let MD context switching run without worrying about spls or locks.
 - Instead of having the idle loop implemented with special contexts
   in MD code, implement one idle proc for each cpu. make the idle
   loop MI with MD hooks.
 - Change the proc lists from the old style vax queues to TAILQs.
 - Change the sleep queue from vax queues to TAILQs. This makes
   wakeup() go from O(n^2) to O(n)

there will be some MD fallout, but it will be fixed shortly.
There's also a few cleanups to be done after this.

deraadt@@, kettenis@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.23 2007/09/12 18:18:27 deraadt Exp $	*/
d118 1
d1088 28
@


1.23
log
@port of i386 pctr code to amd64; Mike Belopuhov
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.22 2007/05/27 08:58:31 art Exp $	*/
a725 1
	.globl	_C_LABEL(whichqs),_C_LABEL(qs)
a727 4
#if NAPM > 0
	.globl _C_LABEL(apm_cpu_idle),_C_LABEL(apm_cpu_busy)
#endif

d747 2
a748 4
 * int cpu_switch(struct proc *)
 * Find a runnable process and switch to it.  Wait if necessary.  If the new
 * proc is the same as the old one, we short-circuit the context save and
 * restore.
d750 1
a750 1
ENTRY(cpu_switch)
d758 2
a759 153
	movq	%rdi,%r13

	/*
	 * Clear curproc so that we don't accumulate system time while idle.
	 * This also insures that schedcpu() will move the old proc to
	 * the correct queue if it happens to get called from the spllower()
	 * below and changes the priority.  (See corresponding comment in
	 * userret()).
	 */
	movq	$0,CPUVAR(CURPROC)


	/*
	 * First phase: find new proc.
	 *
	 * Registers:
	 *   %rax - queue head, scratch, then zero
	 *   %r8 - queue number
	 *   %ecx - cached value of whichqs
	 *   %rdx - next process in queue
	 *   %r13 - old proc
	 *   %r12 - new proc
	 */

	/* Look for new proc. */
	cli				# splhigh doesn't do a cli
	movl	_C_LABEL(whichqs)(%rip),%ecx
	bsfl	%ecx,%r8d		# find a full q
	jnz	switch_dequeue

	/*
	 * idling: save old context
	 *
	 * Registers:
	 * %rax, %rcx - scratch
	 * %r13 - old proc, then old pcb
	 * %r12 - idle pcb
	 */

	/* old proc still in %rdi */
	call	_C_LABEL(pmap_deactivate)

	movq	P_ADDR(%r13),%r13

	/* Save stack pointers */

	movq	%rsp,PCB_RSP(%r13)
	movq	%rbp,PCB_RBP(%r13)

	/* Find idle PCB for this CPU */
#ifndef MULTIPROCESSOR
	leaq	_C_LABEL(proc0)(%rip),%rcx
	movq	P_ADDR(%rcx),%r12
	movl	P_MD_TSS_SEL(%rcx),%edx
#else
	movq	CPUVAR(IDLE_PCB),%r12
	movl	CPUVAR(IDLE_TSS_SEL),%edx
#endif
	movq	$0,CPUVAR(CURPROC)

	/* Restore the idle context (avoid interrupts) */
	cli

	/* Restore stack pointers. */
	movq	PCB_RSP(%r12),%rsp
	movq	PCB_RBP(%r12),%rbp

	/* Switch address space. */
	movq	PCB_CR3(%r12),%rcx
	movq	%rcx,%cr3

#ifdef MULTIPROCESSOR
	movq	CPUVAR(GDT),%rax
#else
	movq	_C_LABEL(gdtstore)(%rip),%rax
#endif

	/* Switch TSS. Reset "task busy" flag before */
	andl	$~0x0200,4(%rax,%rdx, 1)
	ltr	%dx

	/* Restore cr0 (including FPU state). */
	movl	PCB_CR0(%r12),%ecx
	movq	%rcx,%cr0

	SET_CURPCB(%r12)

	xorq	%r13,%r13
	sti
idle_unlock:
#if defined(MULTIPROCESSOR) || defined(LOCKDEBUG)       
	call	_C_LABEL(sched_unlock_idle)
#endif
	/* Interrupts are okay again. */
	movl	$IPL_NONE,%edi
	call	_C_LABEL(Xspllower)
	jmp	idle_start
idle_zero:
	sti
	call	_C_LABEL(uvm_pageidlezero)
	cli
	cmpl	$0,_C_LABEL(whichqs)(%rip)
	jnz	idle_exit
idle_loop:
#if NPCTR > 0
	incq	_C_LABEL(pctr_idlcnt)
#endif
	/* Try to zero some pages. */
	movl	_C_LABEL(uvm)+UVM_PAGE_IDLE_ZERO(%rip),%ecx
	testl	%ecx,%ecx
	jnz	idle_zero
	sti
	hlt
NENTRY(mpidle)
idle_start:
	cli
	cmpl	$0,_C_LABEL(whichqs)(%rip)
	jz	idle_loop
idle_exit:
	movl	$IPL_HIGH,CPUVAR(ILEVEL)
	sti
#if defined(MULTIPROCESSOR) || defined(LOCKDEBUG)       
	call	_C_LABEL(sched_lock_idle)
#endif
switch_search:
	movl	_C_LABEL(whichqs)(%rip),%ecx
	bsfl	%ecx,%r8d
	jz	idle_unlock

switch_dequeue:

	sti
	movq	%r8,%r9

	shlq	$4, %r9
	leaq	_C_LABEL(qs)(%rip),%rax
	addq	%r9,%rax
	/* movq	(%rax),%rax */

	movq	P_FORW(%rax),%r12	# unlink from front of process q
#ifdef	DIAGNOSTIC
	cmpq	%r12,%rax		# linked to self (i.e. nothing queued)?
	je	_C_LABEL(switch_error1)	# not possible
#endif /* DIAGNOSTIC */
	movq	P_FORW(%r12),%rdx
	movq	%rdx,P_FORW(%rax)
	movq	%rax,P_BACK(%rdx)

	cmpq	%rdx,%rax		# q empty?
	jne	3f

	btrl	%r8d,%ecx		# yes, clear to indicate empty
	movl	%ecx,_C_LABEL(whichqs)(%rip) # update q status
a760 1
3:	/* We just did it. */
d763 1
a771 3
	/* Isolate proc.  XXX Is this necessary? */
	movq	%rax,P_BACK(%r12)

a775 5
	/* Skip context switch if same proc. */
	xorl	%ebx,%ebx
	cmpq	%r12,%r13
	je	switch_return

d781 1
a781 1
	 * Second phase: save old context.
d800 1
a800 1
	 * Third phase: restore saved context.
a856 3
#if defined(MULTIPROCESSOR) || defined(LOCKDEBUG)     
	call	_C_LABEL(sched_unlock_idle)
#endif
d858 2
d863 1
a863 2

	movl	%ebx,%eax
d873 2
a874 7
ENTRY(cpu_switchto)
	pushq	%rbx
	pushq	%rbp
	pushq	%r12
	pushq	%r13
	pushq	%r14
	pushq	%r15
d876 3
a878 2
	movq	%rdi,%r13
	movq	%rsi,%r12
d880 2
a881 65
	movq	$0,CPUVAR(CURPROC)

	xorq	%rax,%rax
	jmp	switch_resume


/*
 * void switch_exit(struct proc *l, void (*exit)(struct proc *));
 * Switch to proc0's saved context and deallocate the address space and kernel
 * stack for p.  Then jump into cpu_switch(), as if we were in proc0 all along.
 */
	.globl	_C_LABEL(proc0)
ENTRY(switch_exit)
#ifdef MULTIPROCESSOR
	movq	CPUVAR(IDLE_PCB),%r8
	movl	CPUVAR(IDLE_TSS_SEL),%edx
#else
	leaq	_C_LABEL(proc0)(%rip),%r9
	movq	P_ADDR(%r9),%r8
	movl	P_MD_TSS_SEL(%r9),%edx
#endif

	/* In case we fault... */
	movq	$0,CPUVAR(CURPROC)

	cli

	/* Restore stack pointers. */
	movq	PCB_RSP(%r8),%rsp
	movq	PCB_RBP(%r8),%rbp

	/* Load TSS info. */
#ifdef MULTIPROCESSOR
	movq	CPUVAR(GDT),%rax
#else
	movq	_C_LABEL(gdtstore)(%rip),%rax
#endif

	/* Switch address space. */
	movq	PCB_CR3(%r8),%rcx
	movq	%rcx,%cr3

	/* Switch TSS. */
	andl	$~0x0200,4-SEL_KPL(%rax,%rdx,1)
	ltr	%dx

	/* We're always in the kernel, so we don't need the LDT. */

	/* Restore cr0 (including FPU state). */
	movl	PCB_CR0(%r8),%ecx
	movq	%rcx,%cr0

	/* Record new pcb. */
	SET_CURPCB(%r8)

	/* Interrupts are okay again. */
	sti

	/*
	 * Schedule the dead process's vmspace and stack to be freed.
	 * {lpw_}exit2(l). Function still in %rsi (2nd arg), proc in
	 * %rdi (first arg).
	 */

	call	*%rsi
a882 4
	/* Jump into cpu_switch() with the right state. */
	xorq	%r13,%r13
	movq	%r13, CPUVAR(CURPROC)
	jmp	switch_search
@


1.22
log
@- Redo the way we set up the direct map. Map the first 4GB of it
  in locore so that we can use the direct map in pmap_bootstrap when
  setting up the initial page tables.

- Introduce a second direct map (I love large address spaces) with
  uncached pages.

jason@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.21 2005/08/20 00:33:59 jsg Exp $	*/
d869 3
@


1.21
log
@Check for and report the presense of SSE3.  This has started to appear
in AMD products with the arrival of the venice core.
ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.20 2005/07/26 08:38:29 art Exp $	*/
d366 2
d369 2
a370 2
  ((NKL4_KIMG_ENTRIES + TABLE_L3_ENTRIES + TABLE_L2_ENTRIES + 1 + UPAGES) \
    * NBPG)
d489 27
d517 2
a518 2
	leal    (PROC0_PML4_OFF + PDIR_SLOT_PTE*8)(%esi),%ebx
	leal    (PROC0_PML4_OFF)(%esi),%eax
@


1.20
log
@Instead of juggling around with cr4 and enabling parts of it sometimes,
other parts later, etc. Just set it to the same default value everywhere.
We won't survive without PSE and tt's not like someone will suddenly make
an amd64 that doesn't support PGE.

This will allow us to make the bootstrap process slightly more sane.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.19 2005/05/29 03:20:36 deraadt Exp $	*/
d178 1
d189 1
d315 1
@


1.19
log
@sched work by niklas and art backed out; causes panics
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.16 2005/01/06 20:15:47 martin Exp $	*/
d502 1
a502 1
	orl	$(CR4_PAE|CR4_OSFXSR|CR4_OSXMMEXCPT),%eax
d1028 1
a1028 2
	.globl	_C_LABEL(proc0),_C_LABEL(uvmspace_free),_C_LABEL(kernel_map)
	.globl	_C_LABEL(uvm_km_free),_C_LABEL(tss_free)
@


1.18
log
@Stop pretending that amd64 is i386. We're insulting the cpu by not even
pretending to use all the address space it gives us.

 - Map all physical memory 1-1 and implement PMAP_DIRECT
 - Remove the vast magic we do to map pages for pmap_zero_page,
   pmap_copy_page, pv allocation, magic while bootstrapping,
   reading of /dev/mem, etc.
 - implement a fast pmap_zero_page based on sse instructions.

I love removing code. More to come.

deraadt@@ ok tested by many.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.17 2005/05/25 23:17:47 niklas Exp $	*/
d849 1
d851 1
a851 1
#if defined(MULTIPROCESSOR)
@


1.17
log
@This patch is mortly art's work and was done *a year* ago.  Art wants to thank
everyone for the prompt review and ok of this work ;-)  Yeah, that includes me
too, or maybe especially me.  I am sorry.

Change the sched_lock to a mutex. This fixes, among other things, the infamous
"telnet localhost &" problem.  The real bug in that case was that the sched_lock
which is by design a non-recursive lock, was recursively acquired, and not
enough releases made us hold the lock in the idle loop, blocking scheduling
on the other processors.  Some of the other processors would hold the biglock though,
which made it impossible for cpu 0 to enter the kernel...  A nice deadlock.
Let me just say debugging this for days just to realize that it was all fixed
in an old diff noone ever ok'd was somewhat of an anti-climax.

This diff also changes splsched to be correct for all our architectures.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.16 2005/01/06 20:15:47 martin Exp $	*/
d1276 15
@


1.16
log
@missing $OpenBSD$
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
a848 1
	movl	$IPL_HIGH,CPUVAR(ILEVEL)
d850 1
a850 1
#if defined(MULTIPROCESSOR) || defined(LOCKDEBUG)       
@


1.15
log
@gcc 3.3.5 will store zero-initialized variables in bss by default,
move bootdev to data so it doesn't get zapped when bss is cleared.
deraadt@@ OK
@
text
@d1 1
@


1.14
log
@SMP support. Big parts from NetBSD, but with some really serious debugging
done by me, niklas and others. Especially wrt. NXE support.

Still needs some polishing, especially in dmesg messages, but we're now
building kernel faster than ever.
@
text
@d195 1
@


1.13
log
@Switch amd64 to __HAVE_CPUINFO

deraadt@@ ok
@
text
@d1 1
a1 2
/*	$OpenBSD: locore.S,v 1.12 2004/06/21 22:35:47 niklas Exp $	*/
/*	$NetBSD: locore.S,v 1.2 2003/04/26 19:34:45 fvdl Exp $	*/
d94 1
a94 5
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *	This product includes software developed by the University of
 *	California, Berkeley and its contributors.
 * 4. Neither the name of the University nor the names of its contributors
a181 1
	.globl	_C_LABEL(gdtstore)
d541 1
a541 1
	.code64
d580 1
a580 1
	addq	%r8, %rbx			# new, virtual adress of PML4
d718 1
a718 32
 * When no processes are on the runq, cpu_switch() branches to here to wait for
 * something to come ready.
 */
ENTRY(idle)
#if defined(MULTIPROCESSOR) || defined(LOCKDEBUG)       
	call	_C_LABEL(sched_unlock_idle)
#endif
	jmp	idle_start
idle_zero:
	sti
	call	_C_LABEL(uvm_pageidlezero)
	jmp	idle_start
idle_loop:
	/* Try to zero some pages. */
	movl	_C_LABEL(uvm)+UVM_PAGE_IDLE_ZERO(%rip),%ecx
	testl	%ecx,%ecx
	jnz	idle_zero
	sti
	hlt
NENTRY(mpidle)
idle_start:
	cli
	movl	_C_LABEL(whichqs)(%rip),%ecx
	testl	%ecx, %ecx
	jz	idle_loop
#if defined(MULTIPROCESSOR) || defined(LOCKDEBUG)       
	call	_C_LABEL(sched_lock_idle)
#endif
	jmp	sw1

/*
 * void cpu_switch(struct proc *)
a729 2
	movl	CPUVAR(ILEVEL), %ebx
	pushq	%rbx
d740 1
a740 1
	movq	$0, CPUVAR(CURPROC)
a741 2
	movl	$IPL_NONE, %edi
	call	_C_LABEL(Xspllower)
a754 1
switch_search:
d758 2
d761 95
a855 2
sw1:	bsfl	%ecx,%r8d		# find a full q
	jz	_C_LABEL(idle)
d858 2
a899 2
	sti

d901 1
a901 1
	movl	$1,%eax
d918 3
a958 4
	/* Switch address space. */
	movq	PCB_CR3(%r13),%rcx
	movq	%rcx,%cr3

d963 3
a965 2
	movq	PCB_LDT_SEL(%r13),%rcx
	lldt	%cx
d989 6
a994 6
	/*
	 * Restore old cpl from stack.  Note that this is always an increase,
	 * due to the spl0() on entry.
	 */
	popq	%rbx
	movl	%ebx, CPUVAR(ILEVEL)
d1083 1
a1083 1
	xorq	%r13, %r13
d1139 1
d1149 1
d1158 1
a1158 2
	movl	CPUVAR(ILEVEL), %r8d
	testl	%r8d, %r8d
d1166 2
a1168 2
	movw	TF_FS(%rsp),%fs
	movw	TF_ES(%rsp),%es
d1170 2
d1176 1
a1176 1
	movq	(%rsp),%rsp
d1184 1
d1217 2
d1220 1
a1220 1
 * Old call gate entry for syscall. XXXfvdl: only needed if we're
d1242 1
d1253 1
d1256 1
@


1.12
log
@Pure luck has protected us from this bug until now: locore.S
%r9 are not saved over function calls
and more we did not even want &proc0 as the old process  in switch_search, but zero.  Fixes bsd.rd.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.11 2004/06/13 21:49:12 niklas Exp $	*/
a144 2
#if defined(MULTIPROCESSOR)

a148 7

#else

#define SET_CURPROC(proc,tcpu)		movq	proc,CPUVAR(CURPROC)
#define GET_CURPROC(reg)		movq	CPUVAR(CURPROC),reg

#endif
@


1.11
log
@debranch SMP, have fun
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d1039 2
a1040 2
	movq	%r9, %r13
	movq	$0, CPUVAR(CURPROC)
@


1.10
log
@activate systrace on amd64, while here get rid of syscall_{plain,fancy}
instead use syscall() as everywhere else

ok mickey, tested and ok tedu@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.9 2004/02/25 00:16:04 deraadt Exp $	*/
d851 1
a851 3
#ifdef MULTIPROCESSOR
	movb	$SONPROC,P_STAT(%r12)	# l->l_stat = SONPROC
#endif
@


1.9
log
@dkcsum stuff for amd64, written by tom, who cannot commit it at the moment.
now the amd64 knows what drive it was booted from.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.8 2004/02/23 09:12:59 mickey Exp $	*/
d1097 1
a1097 1
	call	*P_MD_SYSCALL(%r14)
d1194 1
a1194 1
	call	*P_MD_SYSCALL(%rdx)
@


1.8
log
@the consdev pass from boot and a cnset() in the kernel seems to be a bit premature and cause problems
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.7 2004/02/23 08:32:36 mickey Exp $	*/
d146 1
a146 1
        
d151 1
a151 1
        
d161 1
a161 1
        
d192 1
a192 1
	.globl	_C_LABEL(bootinfo),_C_LABEL(atdevbase)
d195 1
a195 1
	.globl	_C_LABEL(bootapiver), _C_LABEL(bootargc), _C_LABEL(bootargv)
a209 2
_C_LABEL(bootargc):	.long	0	# /boot argc
_C_LABEL(bootargv):	.quad	0	# /boot argv
a266 1
	 *
d288 21
a308 7
	movl	28(%esp), %eax
	movl	%eax, RELOC(bootargc)
	movl	32(%esp), %eax
	movl	$RELOC(bootargv), %ebx
	movl	%eax, (%ebx)
	xorl	%eax, %eax
	movl	%eax, 4(%ebx)
@


1.7
log
@get use of NX; partially from netbsd; passes the regress; deraadt@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.6 2004/02/23 01:19:52 tom Exp $	*/
a195 1
	.globl	_C_LABEL(boot_consdev)
a211 1
_C_LABEL(boot_consdev):	.long	0	# console device (temporary)
a269 1
	 * XXX boot_consdev temporarily tacked on to the end
a297 3

	movl	36(%esp), %eax
	movl	%eax, RELOC(boot_consdev)
@


1.6
log
@- Pick up the /boot argc, argv in locore.S (though not currently used)
- Probe for console devices (incl serial) in /boot
- Pass console device from /boot to kernel (temp via additional param)

With this, boot> set tty com0 now works.

"just don't break a build" deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.5 2004/02/22 19:20:09 tom Exp $	*/
d322 5
@


1.5
log
@- Make comment about parameters passed by /boot reflect reality
- Don't use _C_LABEL() on a parameter given to RELOC(), since RELOC()
  does this itself

ok mickey@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.4 2004/02/20 20:49:57 deraadt Exp $	*/
d195 2
d210 4
d255 1
a255 1
 * This may not be needed it things are cleaned up a little.
d271 2
d287 1
a287 1
        movl    20(%esp), %eax
d289 1
a289 1
        movl    24(%esp), %eax
d291 13
@


1.4
log
@use an old syscall (int $0x80) for the sigreturn; otherwise %rcx is trashed.
we've been chasing this for 2 weeks.. finally spotted by kettenis@@chello.nl
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.3 2004/02/07 17:00:12 miod Exp $	*/
d264 1
a264 1
	 * (howto, bootdev, bootapiver, esym, cnvmem, extmem, ac, av)
d267 1
a267 1
	movl	%eax,RELOC(_C_LABEL(boothowto))
d269 1
a269 1
	movl	%eax,RELOC(_C_LABEL(bootdev))
d271 1
a271 1
        movl    16(%esp), %eax
@


1.3
log
@Be sure to flag pte constants as UL, and cope with this in locore.
ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.2 2004/02/03 12:09:47 mickey Exp $	*/
d603 1
a603 1
	syscall
@


1.3.2.1
log
@The merge of these files were done to another date than the rest, fix.
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
a126 2
#include <machine/pte.h>
#include <machine/pmap.h>
@


1.3.2.2
log
@Merge with the trunk
@
text
@d127 2
d148 1
a148 1

d153 1
a153 1

d163 1
a163 1

d194 1
a194 1
	.globl	_C_LABEL(bootinfo), _C_LABEL(bootinfo_size), _C_LABEL(atdevbase)
a196 1
	.globl	_C_LABEL(bootapiver)
a209 1
_C_LABEL(bootapiver):	.long	0	# /boot API version
d251 1
a251 1
 * This may not be needed if things are cleaned up a little.
d266 1
a266 1
	 * (howto, bootdev, bootapiver, esym, extmem, cnvmem, ac, av)
d269 1
a269 1
	movl	%eax, RELOC(boothowto)
d271 1
a271 1
	movl	%eax, RELOC(bootdev)
d273 1
a273 1
	movl	16(%esp), %eax
d281 1
a281 1
	movl	20(%esp), %eax
d283 1
a283 1
	movl	24(%esp), %eax
a285 24
	movl	12(%esp), %eax
	movl	%eax, RELOC(bootapiver)

	/*
	 * Copy the boot arguments to bootinfo[] in machdep.c.
	 *
	 * We are passed the size of bootinfo[] in bootinfo_size, and
	 * we report how much data /boot passed us back in the same variable.
	 *
	 * machdep.c can then take action if bootinfo_size >= bootinfo[]
	 * (which would meant that we may have been passed too much data).
	 */
 	movl	28(%esp), %eax
	movl	%eax, %ecx
	cmpl	RELOC(bootinfo_size), %ecx	/* Too much? */
	jnc	bi_size_ok
	movl	RELOC(bootinfo_size), %ecx	/* Only copy this much */
bi_size_ok:
	movl	%eax, RELOC(bootinfo_size)	/* Report full amount */
 
	movl	$RELOC(bootinfo), %edi		/* Destination */
	movl	32(%esp), %esi			/* Source */
	rep movsb				/* Copy this many bytes */

a303 5
	movl	$0x80000001, %eax
	cpuid
	andl	$CPUID_NXE, %edx	/* other bits may clash */
	orl     %edx, RELOC(cpu_feature)

d605 1
a605 1
	int	$0x80
d1068 1
a1068 1
	call	_C_LABEL(syscall)
d1165 1
a1165 1
	call	_C_LABEL(syscall)
@


1.3.2.3
log
@must set p_stat to SONPROC
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.3.2.2 2004/06/05 23:09:24 niklas Exp $	*/
d851 3
a853 1
	movb	$SONPROC,P_STAT(%r12)	# p->p_stat = SONPROC
@


1.2
log
@das boot; das cloned das from das i386
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.S,v 1.1 2004/01/28 01:39:38 mickey Exp $	*/
a126 2
#include <machine/pte.h>
#include <machine/pmap.h>
@


1.1
log
@an amd64 arch support.
hacked by art@@ from netbsd sources and then later debugged
by me into the shape where it can host itself.
no bootloader yet as needs redoing from the
recent advanced i386 sources (anyone? ;)
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
a131 1
#include <machine/bootinfo.h>
d193 1
a193 1
	.globl	_C_LABEL(esym),_C_LABEL(boothowto)
d259 1
a259 1
.code32
d266 1
a266 1
	 * (howto, [bootdev], bootinfo, esym, basemem, extmem).
d269 11
a279 63
	movl	%eax,RELOC(boothowto)
	movl	12(%esp),%eax
	testl	%eax, %eax
	jz	1f
	movl	(%eax), %ebx		/* number of entries */
	movl	$RELOC(bootinfo),%ebp
	movl	%ebp, %edx
	addl	$BOOTINFO_MAXSIZE,%ebp
	movl	%ebx, (%edx)
	addl	$4, %edx
2:
	testl	%ebx, %ebx
	jz	1f
	addl	$4, %eax
	movl	(%eax), %ecx		/* address of entry */
	pushl	%edi
	pushl	%esi
	pushl	%eax

	movl	(%ecx),%eax	/* len */
	movl	%edx,%edi
	addl	(%ecx), %edx		/* update dest pointer */
	cmpl	%ebp, %edx
	jg	2f
	movl	%ecx,%esi
	movl	%eax,%ecx
	rep
	movsb
	popl	%eax
	popl	%esi
	popl	%edi
	subl	$1, %ebx
	jmp	2b
2:	/* cleanup for overflow case */
	popl	%eax
	popl	%esi
	popl	%edi
	movl	$RELOC(bootinfo),%ebp
	movl	%ebp, %edx
	subl	%ebx, (%edx)		/* correct number of entries */
1:

 	movl	16(%esp),%eax
	testl	%eax,%eax
	jz	1f
	addl	$KERNBASE_LO,%eax
1: 	movl	$RELOC(esym),%ebp
	movl	%eax,(%ebp)
	movl	$KERNBASE_HI,4(%ebp)

	movl	$RELOC(biosextmem),%ebp
	movl	(%ebp),%eax
	testl	%eax,%eax
	jnz	1f
	movl	20(%esp),%eax
	movl	%eax,(%ebp)
1:
	movl	$RELOC(biosbasemem),%ebp
	movl	(%ebp),%eax
	testl	%eax,%eax
	jnz	1f
	movl	24(%esp),%eax
	movl	%eax,(%ebp)
d281 4
d527 1
a527 1
.code64
@

