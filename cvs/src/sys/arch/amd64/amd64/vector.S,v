head	1.51;
access;
symbols
	OPENBSD_6_2:1.51.0.2
	OPENBSD_6_2_BASE:1.51
	OPENBSD_6_1:1.47.0.4
	OPENBSD_6_1_BASE:1.47
	OPENBSD_6_0:1.46.0.2
	OPENBSD_6_0_BASE:1.46
	OPENBSD_5_9:1.44.0.2
	OPENBSD_5_9_BASE:1.44
	OPENBSD_5_8:1.43.0.4
	OPENBSD_5_8_BASE:1.43
	OPENBSD_5_7:1.36.0.2
	OPENBSD_5_7_BASE:1.36
	OPENBSD_5_6:1.34.0.6
	OPENBSD_5_6_BASE:1.34
	OPENBSD_5_5:1.34.0.4
	OPENBSD_5_5_BASE:1.34
	OPENBSD_5_4:1.33.0.2
	OPENBSD_5_4_BASE:1.33
	OPENBSD_5_3:1.32.0.4
	OPENBSD_5_3_BASE:1.32
	OPENBSD_5_2:1.32.0.2
	OPENBSD_5_2_BASE:1.32
	OPENBSD_5_1_BASE:1.31
	OPENBSD_5_1:1.31.0.4
	OPENBSD_5_0:1.31.0.2
	OPENBSD_5_0_BASE:1.31
	OPENBSD_4_9:1.27.0.2
	OPENBSD_4_9_BASE:1.27
	OPENBSD_4_8:1.25.0.2
	OPENBSD_4_8_BASE:1.25
	OPENBSD_4_7:1.24.0.2
	OPENBSD_4_7_BASE:1.24
	OPENBSD_4_6:1.22.0.4
	OPENBSD_4_6_BASE:1.22
	OPENBSD_4_5:1.16.0.2
	OPENBSD_4_5_BASE:1.16
	OPENBSD_4_4:1.14.0.2
	OPENBSD_4_4_BASE:1.14
	OPENBSD_4_3:1.10.0.4
	OPENBSD_4_3_BASE:1.10
	OPENBSD_4_2:1.10.0.2
	OPENBSD_4_2_BASE:1.10
	OPENBSD_4_1:1.7.0.6
	OPENBSD_4_1_BASE:1.7
	OPENBSD_4_0:1.7.0.2
	OPENBSD_4_0_BASE:1.7
	OPENBSD_3_9:1.7.0.4
	OPENBSD_3_9_BASE:1.7
	OPENBSD_3_8:1.6.0.4
	OPENBSD_3_8_BASE:1.6
	OPENBSD_3_7:1.6.0.2
	OPENBSD_3_7_BASE:1.6
	OPENBSD_3_6:1.5.0.2
	OPENBSD_3_6_BASE:1.5
	SMP_SYNC_A:1.1
	SMP_SYNC_B:1.1
	OPENBSD_3_5:1.1.0.4
	OPENBSD_3_5_BASE:1.1
	SMP:1.1.0.2;
locks; strict;
comment	@# @;


1.51
date	2017.10.04.02.10.33;	author guenther;	state Exp;
branches;
next	1.50;
commitid	LsvDJKBN9IDUAAqy;

1.50
date	2017.08.25.19.28.48;	author guenther;	state Exp;
branches;
next	1.49;
commitid	pIA4jy9i3oGgdop6;

1.49
date	2017.06.29.17.17.28;	author deraadt;	state Exp;
branches;
next	1.48;
commitid	W8lruZ7GPI2dyHQY;

1.48
date	2017.05.30.12.41.55;	author mlarkin;	state Exp;
branches;
next	1.47;
commitid	yZk0oJDrVea2Th12;

1.47
date	2016.09.04.09.22.28;	author mpi;	state Exp;
branches
	1.47.4.1;
next	1.46;
commitid	jBolvsPoQ0BaYiLs;

1.46
date	2016.06.22.01.12.38;	author mikeb;	state Exp;
branches
	1.46.2.1;
next	1.45;
commitid	aoZwpavraFkBTbjg;

1.45
date	2016.03.03.12.32.23;	author mpi;	state Exp;
branches;
next	1.44;
commitid	M5r4S7Tt7Pvfl2xO;

1.44
date	2015.12.08.19.45.55;	author mikeb;	state Exp;
branches;
next	1.43;
commitid	k3df0wPG0WyTVD3t;

1.43
date	2015.07.17.15.37.58;	author guenther;	state Exp;
branches;
next	1.42;
commitid	fZhyUgCUYQOMyZ4Z;

1.42
date	2015.07.16.05.10.14;	author guenther;	state Exp;
branches;
next	1.41;
commitid	vUE3LzynpntlHxEC;

1.41
date	2015.07.09.13.23.51;	author mikeb;	state Exp;
branches;
next	1.40;
commitid	hdCmJFY7kzSxTyNj;

1.40
date	2015.06.29.03.02.38;	author mlarkin;	state Exp;
branches;
next	1.39;
commitid	tikyc8CiSbx6N6c6;

1.39
date	2015.06.28.01.16.29;	author guenther;	state Exp;
branches;
next	1.38;
commitid	cOmfOzJx69tehqZa;

1.38
date	2015.05.18.19.59.27;	author guenther;	state Exp;
branches;
next	1.37;
commitid	MLFvGCnCMKMdmAtY;

1.37
date	2015.04.19.19.45.21;	author sf;	state Exp;
branches;
next	1.36;
commitid	QHmlY8tYf1BGbIw1;

1.36
date	2015.02.07.00.26.37;	author deraadt;	state Exp;
branches;
next	1.35;
commitid	kEuv7zJ8MalymF3m;

1.35
date	2014.11.23.00.25.05;	author guenther;	state Exp;
branches;
next	1.34;
commitid	83mVtEFG1oiGteGB;

1.34
date	2013.11.02.14.23.38;	author kettenis;	state Exp;
branches;
next	1.33;

1.33
date	2013.05.12.14.15.31;	author ratchov;	state Exp;
branches;
next	1.32;

1.32
date	2012.07.09.16.01.16;	author deraadt;	state Exp;
branches;
next	1.31;

1.31
date	2011.06.16.19.46.40;	author kettenis;	state Exp;
branches;
next	1.30;

1.30
date	2011.04.19.06.07.03;	author dlg;	state Exp;
branches;
next	1.29;

1.29
date	2011.04.16.00.40.56;	author deraadt;	state Exp;
branches;
next	1.28;

1.28
date	2011.04.01.22.51.45;	author guenther;	state Exp;
branches;
next	1.27;

1.27
date	2010.12.21.14.56.23;	author claudio;	state Exp;
branches;
next	1.26;

1.26
date	2010.09.28.03.53.14;	author guenther;	state Exp;
branches;
next	1.25;

1.25
date	2010.04.05.19.04.32;	author kettenis;	state Exp;
branches;
next	1.24;

1.24
date	2009.11.01.22.13.27;	author kettenis;	state Exp;
branches;
next	1.23;

1.23
date	2009.07.10.13.51.47;	author jsg;	state Exp;
branches;
next	1.22;

1.22
date	2009.06.09.02.56.38;	author krw;	state Exp;
branches;
next	1.21;

1.21
date	2009.06.06.23.45.35;	author guenther;	state Exp;
branches;
next	1.20;

1.20
date	2009.06.05.10.51.44;	author guenther;	state Exp;
branches;
next	1.19;

1.19
date	2009.05.28.09.05.33;	author art;	state Exp;
branches;
next	1.18;

1.18
date	2009.04.27.17.48.22;	author deraadt;	state Exp;
branches;
next	1.17;

1.17
date	2009.04.23.07.42.02;	author art;	state Exp;
branches;
next	1.16;

1.16
date	2008.12.06.19.59.38;	author tedu;	state Exp;
branches;
next	1.15;

1.15
date	2008.12.06.04.31.24;	author tedu;	state Exp;
branches;
next	1.14;

1.14
date	2008.06.27.06.03.08;	author ray;	state Exp;
branches;
next	1.13;

1.13
date	2008.05.23.15.39.43;	author jasper;	state Exp;
branches;
next	1.12;

1.12
date	2008.05.14.21.53.08;	author weingart;	state Exp;
branches;
next	1.11;

1.11
date	2008.04.28.18.09.00;	author kettenis;	state Exp;
branches;
next	1.10;

1.10
date	2007.06.01.21.01.51;	author art;	state Exp;
branches;
next	1.9;

1.9
date	2007.05.25.16.22.11;	author art;	state Exp;
branches;
next	1.8;

1.8
date	2007.05.10.17.59.23;	author deraadt;	state Exp;
branches;
next	1.7;

1.7
date	2005.10.09.17.09.34;	author fgsch;	state Exp;
branches;
next	1.6;

1.6
date	2004.12.24.22.50.29;	author miod;	state Exp;
branches;
next	1.5;

1.5
date	2004.07.10.14.21.40;	author art;	state Exp;
branches;
next	1.4;

1.4
date	2004.06.28.01.52.24;	author deraadt;	state Exp;
branches;
next	1.3;

1.3
date	2004.06.25.17.27.01;	author andreas;	state Exp;
branches;
next	1.2;

1.2
date	2004.06.25.11.03.27;	author art;	state Exp;
branches;
next	1.1;

1.1
date	2004.01.28.01.39.39;	author mickey;	state Exp;
branches;
next	;

1.46.2.1
date	2017.08.26.00.15.05;	author bluhm;	state Exp;
branches;
next	1.46.2.2;
commitid	EJSKXWVfg55NrgI5;

1.46.2.2
date	2017.10.04.19.41.01;	author bluhm;	state Exp;
branches;
next	;
commitid	nCmaIbQLOn3TYIBp;

1.47.4.1
date	2017.08.26.00.14.20;	author bluhm;	state Exp;
branches;
next	1.47.4.2;
commitid	ubjDaswy90l5VD3W;

1.47.4.2
date	2017.10.04.19.38.03;	author bluhm;	state Exp;
branches;
next	;
commitid	YXXNvijEDGKpPpqh;


desc
@@


1.51
log
@Follow the pattern set by copy*/pcb_onfault: when xrstor faults, return
from the trap to a 'resume' address to effectively make xrstor_user()
return an error indication, then do the FPU cleanup and trap generation
from there where we can get access to the original, userspace trapframe.

The original fix tried to handle the trap while on the wrong trapframe,
leaking kernel addresses and possibly leading to double faults.
Problem pointed out by abluhm@@
ok deraadt@@ mikeb@@
@
text
@/*	$OpenBSD: vector.S,v 1.50 2017/08/25 19:28:48 guenther Exp $	*/
/*	$NetBSD: vector.S,v 1.5 2004/06/28 09:13:11 fvdl Exp $	*/

/*
 * Copyright (c) 2001 Wasabi Systems, Inc.
 * All rights reserved.
 *
 * Written by Frank van der Linden for Wasabi Systems, Inc.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *      This product includes software developed for the NetBSD Project by
 *      Wasabi Systems, Inc.
 * 4. The name of Wasabi Systems, Inc. may not be used to endorse
 *    or promote products derived from this software without specific prior
 *    written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY WASABI SYSTEMS, INC. ``AS IS'' AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED
 * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL WASABI SYSTEMS, INC
 * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
 * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
 * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
 * POSSIBILITY OF SUCH DAMAGE.
 */

/*-
 * Copyright (c) 1998 The NetBSD Foundation, Inc.
 * All rights reserved.
 *
 * This code is derived from software contributed to The NetBSD Foundation
 * by Charles M. Hannum.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 *
 * THIS SOFTWARE IS PROVIDED BY THE NETBSD FOUNDATION, INC. AND CONTRIBUTORS
 * ``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED
 * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE FOUNDATION OR CONTRIBUTORS
 * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
 * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
 * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
 * POSSIBILITY OF SUCH DAMAGE.
 */

#define ALIGN_TEXT	.align 16,0x90

#include <machine/param.h>
#include <machine/i8259.h>
#include <machine/i82093reg.h>
#include <machine/i82489reg.h>
#include <machine/asm.h>
#include <machine/frameasm.h>
#include <machine/segments.h>
#include <machine/trap.h>
#include <machine/intr.h>
#include <machine/psl.h>
#include <machine/codepatch.h>
#include <machine/specialreg.h>

#include "ioapic.h"
#include "lapic.h"
#include "assym.h"
#include "xen.h"
#include "hyperv.h"

/*****************************************************************************/

/*
 * Trap and fault vector routines
 *
 * On exit from the kernel to user mode, we always need to check for ASTs.  In
 * addition, we need to do this atomically; otherwise an interrupt may occur
 * which causes an AST, but it won't get processed until the next kernel entry
 * (possibly the next clock tick).  Thus, we disable interrupt before checking,
 * and only enable them again on the final `iret' or before calling the AST
 * handler.
 */

/*****************************************************************************/

#define	TRAP(a)		pushq $(a) ; jmp _C_LABEL(alltraps)
#define	ZTRAP(a)	pushq $0 ; TRAP(a)

	.text
IDTVEC(trap00)
	ZTRAP(T_DIVIDE)
IDTVEC(trap01)
	ZTRAP(T_TRCTRAP)
IDTVEC(trap02)
	ZTRAP(T_NMI)
IDTVEC(trap03)
	ZTRAP(T_BPTFLT)
IDTVEC(trap04)
	ZTRAP(T_OFLOW)
IDTVEC(trap05)
	ZTRAP(T_BOUND)
IDTVEC(trap06)
	ZTRAP(T_PRIVINFLT)
IDTVEC(trap07)
	pushq	$0			# dummy error code
	pushq	$T_DNA
	INTRENTRY
	sti
	cld
	SMAP_CLAC
	movq	CPUVAR(SELF),%rdi
	movq	%rsp, %rsi
	call	_C_LABEL(fpudna)
	INTRFASTEXIT
IDTVEC(trap08)
	TRAP(T_DOUBLEFLT)
IDTVEC(trap09)
	ZTRAP(T_FPOPFLT)
IDTVEC(trap0a)
	TRAP(T_TSSFLT)
IDTVEC(trap0b)
	TRAP(T_SEGNPFLT)
IDTVEC(trap0c)
	TRAP(T_STKFLT)

	/*
	 * If iretq faults, we'll get a trap at doreti_iret with CPL==0 but
	 * the user's GS.base, which INTRENTRY wouldn't handle correctly
	 * (it would skip the swapgs), so locally expand both it and
	 * INTR_SAVE_GPRS, but add an extra test comparing %rip to doreti_iret
	 * so that we can do the necessary swapgs in that case.
	 */
IDTVEC(trap0d)
	subq	$TF_ERR,%rsp
	movl	$T_PROTFLT,TF_TRAPNO(%rsp)
	movq	%rdi,TF_RDI(%rsp)
	leaq	_C_LABEL(doreti_iret)(%rip),%rdi
	cmpq	%rdi,TF_RIP(%rsp)
	je	1f
	testq	$SEL_RPL,TF_CS(%rsp)
	jz	2f
1:	swapgs
2:	movq	%r15,TF_R15(%rsp)
	movq	%r14,TF_R14(%rsp)
	movq	%r13,TF_R13(%rsp)
	movq	%r12,TF_R12(%rsp)
	movq	%r11,TF_R11(%rsp)
	movq	%r10,TF_R10(%rsp)
	movq	%r9,TF_R9(%rsp)
	movq	%r8,TF_R8(%rsp)
	/*movq	%rdi,TF_RDI(%rsp)	done above */
	movq	%rsi,TF_RSI(%rsp)
	movq	%rbp,TF_RBP(%rsp)
	movq	%rbx,TF_RBX(%rsp)
	movq	%rdx,TF_RDX(%rsp)
	movq	%rcx,TF_RCX(%rsp)
	movq	%rax,TF_RAX(%rsp)
	sti
	jmp	calltrap

IDTVEC(trap0e)
	TRAP(T_PAGEFLT)
IDTVEC(intrspurious)
IDTVEC(trap0f)
	iretq
IDTVEC(trap10)
	ZTRAP(T_ARITHTRAP)
IDTVEC(trap11)
	ZTRAP(T_ALIGNFLT)
IDTVEC(trap12)
	ZTRAP(T_MCA)
IDTVEC(trap13)
	ZTRAP(T_XMM)
IDTVEC(trap14)
IDTVEC(trap15)
IDTVEC(trap16)
IDTVEC(trap17)
IDTVEC(trap18)
IDTVEC(trap19)
IDTVEC(trap1a)
IDTVEC(trap1b)
IDTVEC(trap1c)
IDTVEC(trap1d)
IDTVEC(trap1e)
IDTVEC(trap1f)
	/* 20 - 31 reserved for future exp */
	ZTRAP(T_RESERVED)

IDTVEC(exceptions)
	.quad	_C_LABEL(Xtrap00), _C_LABEL(Xtrap01)
	.quad	_C_LABEL(Xtrap02), _C_LABEL(Xtrap03)
	.quad	_C_LABEL(Xtrap04), _C_LABEL(Xtrap05)
	.quad	_C_LABEL(Xtrap06), _C_LABEL(Xtrap07)
	.quad	_C_LABEL(Xtrap08), _C_LABEL(Xtrap09)
	.quad	_C_LABEL(Xtrap0a), _C_LABEL(Xtrap0b)
	.quad	_C_LABEL(Xtrap0c), _C_LABEL(Xtrap0d)
	.quad	_C_LABEL(Xtrap0e), _C_LABEL(Xtrap0f)
	.quad	_C_LABEL(Xtrap10), _C_LABEL(Xtrap11)
	.quad	_C_LABEL(Xtrap12), _C_LABEL(Xtrap13)
	.quad	_C_LABEL(Xtrap14), _C_LABEL(Xtrap15)
	.quad	_C_LABEL(Xtrap16), _C_LABEL(Xtrap17)
	.quad	_C_LABEL(Xtrap18), _C_LABEL(Xtrap19)
	.quad	_C_LABEL(Xtrap1a), _C_LABEL(Xtrap1b)
	.quad	_C_LABEL(Xtrap1c), _C_LABEL(Xtrap1d)
	.quad	_C_LABEL(Xtrap1e), _C_LABEL(Xtrap1f)

/*
 * If an error is detected during trap, syscall, or interrupt exit, trap() will
 * change %rip to point to this label.  At that point, we'll be running with
 * the kernel GS.base, but the trap frame will be from CPL==3, so we can't
 * go through INTRENTRY as it would do the swapgs that we don't want/need.
 * So, locally expand INTRENTRY but without the swapgs: manually
 * clean up the stack and resume as if we were handling a general
 * protection fault.  This will cause the process to get a SIGBUS.
 */
NENTRY(resume_iret)
	pushq	$0
	pushq	$T_PROTFLT
	subq	$32,%rsp
	INTR_SAVE_GPRS
	sti
	jmp	calltrap

/*
 * All traps go through here. Call the generic trap handler, and
 * check for ASTs afterwards.
 */
NENTRY(alltraps)
	INTRENTRY
	sti
calltrap:
	cld
	SMAP_CLAC
#ifdef DIAGNOSTIC
	movl	CPUVAR(ILEVEL),%ebx
#endif /* DIAGNOSTIC */
#if !defined(GPROF) && defined(DDBPROF)
	cmpl	$T_BPTFLT,TF_TRAPNO(%rsp)
	jne	.Lreal_trap

	movq	%rsp, %rdi
	call	_C_LABEL(db_prof_hook)
	cmpl	$1, %eax
	jne	.Lreal_trap

	/*
	 * Abuse the error field to indicate that intr_fast_exit needs
	 * to emulate the patched instruction.
	 */
	movl	$INTR_FAKE_TRAP, TF_ERR(%rsp)
	jz	2f
.Lreal_trap:
#endif /* !defined(GPROF) && defined(DDBPROF) */
	movq	%rsp, %rdi
	call	_C_LABEL(trap)
2:	/* Check for ASTs on exit to user mode. */
	cli
	CHECK_ASTPENDING(%r11)
	je	1f
	testb	$SEL_RPL,TF_CS(%rsp)
	jz	1f
5:	CLEAR_ASTPENDING(%r11)
	sti
	movq	%rsp, %rdi
	call	_C_LABEL(ast)
	jmp	2b
#ifndef DIAGNOSTIC
1:	INTRFASTEXIT
#else /* DIAGNOSTIC */
1:	cmpl	CPUVAR(ILEVEL),%ebx
	jne	3f
	INTRFASTEXIT
3:	sti
	movabsq	$spl_lowered,%rdi
	movl	CPUVAR(ILEVEL),%esi
	movl	%ebx,%edx
	xorq	%rax,%rax
	call	_C_LABEL(printf)
#ifdef DDB
	int	$3
#endif /* DDB */
	movl	%ebx,CPUVAR(ILEVEL)
	jmp	2b

	.section .rodata
spl_lowered:
	.asciz	"WARNING: SPL NOT LOWERED ON TRAP EXIT %x %x\n"
	.text
#endif /* DIAGNOSTIC */


/*
 * Macros for interrupt entry, call to handler, and exit.
 *
 * XXX
 * The interrupt frame is set up to look like a trap frame.  This may be a
 * waste.  The only handler which needs a frame is the clock handler, and it
 * only needs a few bits.  Xdoreti() needs a trap frame for handling ASTs, but
 * it could easily convert the frame on demand.
 *
 * The direct costs of setting up a trap frame are two pushq's (error code and
 * trap number), an addl to get rid of these, and pushing and popping the
 * callee-saved registers %ebx, %ebp, and %r1[2-5] twice.
 *
 * If the interrupt frame is made more flexible,  INTR can push %eax first and
 * decide the ipending case with less overhead, e.g., by avoiding loading the
 * segment registers.
 *
 */

/* XXX See comment in locore.s */
#define	XINTR(name,num)		Xintr_##name##num

	.globl _C_LABEL(x2apic_eoi)
_C_LABEL(x2apic_eoi):
	pushq   %rax
	pushq   %rcx
	pushq   %rdx
	mov     $MSR_X2APIC_EOI,%ecx
	mov     $0,%eax
	mov     $0,%edx
	wrmsr
	popq    %rdx
	popq    %rcx
	popq    %rax
	ret

#if NLAPIC > 0
#ifdef MULTIPROCESSOR
IDTVEC(recurse_lapic_ipi)
	INTR_RECURSE_HWFRAME
	pushq	$0		
	subq	$8,%rsp			/* unused __if_trapno */
	INTRENTRY		
	jmp	1f
IDTVEC(intr_lapic_ipi)
	pushq	$0		
	subq	$8,%rsp			/* unused __if_trapno */
	INTRENTRY		
	CODEPATCH_START
	movl	$0,_C_LABEL(local_apic)+LAPIC_EOI
	CODEPATCH_END(CPTAG_EOI)
	movl	CPUVAR(ILEVEL),%ebx
	cmpl	$IPL_IPI,%ebx
	jae	2f
IDTVEC(resume_lapic_ipi)
1:
	incl	CPUVAR(IDEPTH)
	movl	$IPL_IPI,CPUVAR(ILEVEL)
        sti
	cld
	SMAP_CLAC
	pushq	%rbx
	call	_C_LABEL(x86_ipi_handler)
	jmp	_C_LABEL(Xdoreti)
2:
	movq	$(1 << LIR_IPI),%rax
	orq	%rax,CPUVAR(IPENDING)
	INTRFASTEXIT

IDTVEC(ipi_invltlb)
	pushq	%rax

	ioapic_asm_ack()

	movq	%cr3, %rax
	movq	%rax, %cr3

	lock
	decq	tlb_shoot_wait

	popq	%rax
	iretq

IDTVEC(ipi_invlpg)
	pushq	%rax

	ioapic_asm_ack()

	movq	tlb_shoot_addr1, %rax
	invlpg	(%rax)

	lock
	decq	tlb_shoot_wait

	popq	%rax
	iretq

IDTVEC(ipi_invlrange)
	pushq	%rax
	pushq	%rdx

	ioapic_asm_ack()

	movq	tlb_shoot_addr1, %rax
	movq	tlb_shoot_addr2, %rdx
1:	invlpg	(%rax)
	addq	$PAGE_SIZE, %rax
	cmpq	%rdx, %rax
	jb	1b

	lock
	decq	tlb_shoot_wait

	popq	%rdx
	popq	%rax
	iretq

#endif /* MULTIPROCESSOR */
	
	/*
	 * Interrupt from the local APIC timer.
	 */
IDTVEC(recurse_lapic_ltimer)
	INTR_RECURSE_HWFRAME
	pushq	$0		
	subq	$8,%rsp			/* unused __if_trapno */
	INTRENTRY		
	jmp	1f
IDTVEC(intr_lapic_ltimer)
	pushq	$0		
	subq	$8,%rsp			/* unused __if_trapno */
	INTRENTRY		
	CODEPATCH_START
	movl	$0,_C_LABEL(local_apic)+LAPIC_EOI
	CODEPATCH_END(CPTAG_EOI)
	movl	CPUVAR(ILEVEL),%ebx
	cmpl	$IPL_CLOCK,%ebx
	jae	2f
IDTVEC(resume_lapic_ltimer)
1:
	incl	CPUVAR(IDEPTH)
	movl	$IPL_CLOCK,CPUVAR(ILEVEL)
	sti
	cld
	SMAP_CLAC
	pushq	%rbx
	xorq	%rdi,%rdi
	call	_C_LABEL(lapic_clockintr)
	jmp	_C_LABEL(Xdoreti)
2:
	movq	$(1 << LIR_TIMER),%rax
	orq	%rax,CPUVAR(IPENDING)
	INTRFASTEXIT

#if NXEN > 0
/*
 * Xen event channel upcall interrupt handler.
 * Only used when the hypervisor supports direct vector callbacks.
 */
IDTVEC(recurse_xen_upcall)
	INTR_RECURSE_HWFRAME
	pushq	$0
	subq	$8,%rsp			/* unused __if_trapno */
	INTRENTRY
	jmp	1f
IDTVEC(intr_xen_upcall)
	pushq	$0
	subq	$8,%rsp			/* unused __if_trapno */
	INTRENTRY
	call	_C_LABEL(xen_intr_ack)
	movl	CPUVAR(ILEVEL),%ebx
	cmpl	$IPL_NET,%ebx
	jae	2f
IDTVEC(resume_xen_upcall)
1:
	incl	CPUVAR(IDEPTH)
	movl	$IPL_NET,CPUVAR(ILEVEL)
	sti
	cld
	SMAP_CLAC
	pushq	%rbx
	call	_C_LABEL(xen_intr)
	jmp	_C_LABEL(Xdoreti)
2:
	movq	$(1 << LIR_XEN),%rax
	orq	%rax,CPUVAR(IPENDING)
3:
	INTRFASTEXIT
#endif /* NXEN > 0 */

#if NHYPERV > 0
/*
 * Hyperv event channel upcall interrupt handler.
 * Only used when the hypervisor supports direct vector callbacks.
 */
IDTVEC(recurse_hyperv_upcall)
	INTR_RECURSE_HWFRAME
	pushq	$0
	subq	$8,%rsp			/* unused __if_trapno */
	INTRENTRY
	jmp	1f
IDTVEC(intr_hyperv_upcall)
	pushq	$0
	subq	$8,%rsp			/* unused __if_trapno */
	INTRENTRY
	movl	CPUVAR(ILEVEL),%ebx
	cmpl	$IPL_NET,%ebx
	jae	2f
IDTVEC(resume_hyperv_upcall)
1:
	incl	CPUVAR(IDEPTH)
	movl	$IPL_NET,CPUVAR(ILEVEL)
	sti
	cld
	SMAP_CLAC
	pushq	%rbx
	call	_C_LABEL(hv_intr)
	jmp	_C_LABEL(Xdoreti)
2:
	movq	$(1 << LIR_HYPERV),%rax
	orq	%rax,CPUVAR(IPENDING)
3:
	INTRFASTEXIT
#endif /* NHYPERV > 0 */
#endif /* NLAPIC > 0 */

#define voidop(num)


/*
 * This macro defines the generic stub code. Its arguments modify it
 * for specific PICs.
 */

#define	INTRSTUB(name, num, early_ack, late_ack, mask, unmask, level_mask) \
IDTVEC(recurse_##name##num)						;\
	INTR_RECURSE_HWFRAME						;\
	subq	$16,%rsp		/* space for __if_{trapno,err} */;\
	INTRENTRY							;\
IDTVEC(resume_##name##num)						\
	movq	$IREENT_MAGIC,TF_ERR(%rsp)				;\
	movl	%ebx,%r13d						;\
	movq	CPUVAR(ISOURCES) + (num) * 8, %r14			;\
	movl	IS_MAXLEVEL(%r14),%ebx					;\
	jmp	1f							;\
IDTVEC(intr_##name##num)						;\
	pushq	$0			/* dummy error code */		;\
	subq	$8,%rsp			/* unused __if_trapno */	;\
	INTRENTRY							;\
	movq	CPUVAR(ISOURCES) + (num) * 8, %r14			;\
	mask(num)			/* mask it in hardware */	;\
	early_ack(num)			/* and allow other intrs */	;\
	incl	_C_LABEL(uvmexp)+V_INTR	/* statistical info */		;\
	testq	%r14,%r14						;\
	jz	9f			/* stray */			;\
	movl	IS_MAXLEVEL(%r14),%ebx					;\
	movl	CPUVAR(ILEVEL),%r13d					;\
	cmpl	%ebx,%r13d						;\
	jae	10f			/* currently masked; hold it */	;\
1:									\
	pushq	%r13							;\
	movl	%ebx,CPUVAR(ILEVEL)					;\
	sti								;\
	cld								;\
	SMAP_CLAC							;\
	incl	CPUVAR(IDEPTH)						;\
	movq	IS_HANDLERS(%r14),%rbx					;\
6:									\
	movl	IH_LEVEL(%rbx),%r12d					;\
	cmpl	%r13d,%r12d						;\
	jle	7f							;\
	movl	%r12d,CPUVAR(ILEVEL)					;\
	movq	%rbx, %rsi						;\
	movq	%rsp, %rdi						;\
	call	_C_LABEL(intr_handler)	/* call it */			;\
	orl	%eax,%eax		/* should it be counted? */	;\
	jz	4f			/* no, skip it */		;\
	incq	IH_COUNT(%rbx)		/* count the intrs */		;\
	cmpl	$0,_C_LABEL(intr_shared_edge)				;\
	jne	4f			/* if no shared edges ... */	;\
	orl	%eax,%eax		/* 1 means stop trying */	;\
	jns	5f							;\
4:	movq	IH_NEXT(%rbx),%rbx	/* next handler in chain */	;\
	testq	%rbx,%rbx						;\
	jnz	6b							;\
5:									\
	cli								;\
	unmask(num)			/* unmask it in hardware */	;\
	late_ack(num)							;\
	sti								;\
	jmp	_C_LABEL(Xdoreti)	/* lower spl and do ASTs */	;\
7:									\
	cli								;\
	movq	$(1 << num),%rax					;\
	orq     %rax,CPUVAR(IPENDING)					;\
	level_mask(num)							;\
	late_ack(num)							;\
	sti								;\
	jmp	_C_LABEL(Xdoreti)	/* lower spl and do ASTs */	;\
10:									\
	cli								;\
	movq	$(1 << num),%rax					;\
	orq	%rax,CPUVAR(IPENDING)					;\
	level_mask(num)							;\
	late_ack(num)							;\
	INTRFASTEXIT							;\
9:									\
	unmask(num)							;\
	late_ack(num)							;\
	INTRFASTEXIT

#define ICUADDR IO_ICU1

INTRSTUB(legacy,0,i8259_asm_ack1,voidop,i8259_asm_mask,i8259_asm_unmask,
    voidop)
INTRSTUB(legacy,1,i8259_asm_ack1,voidop,i8259_asm_mask,i8259_asm_unmask,
    voidop)
INTRSTUB(legacy,2,i8259_asm_ack1,voidop,i8259_asm_mask,i8259_asm_unmask,
    voidop)
INTRSTUB(legacy,3,i8259_asm_ack1,voidop,i8259_asm_mask,i8259_asm_unmask,
    voidop)
INTRSTUB(legacy,4,i8259_asm_ack1,voidop,i8259_asm_mask,i8259_asm_unmask,
    voidop)
INTRSTUB(legacy,5,i8259_asm_ack1,voidop,i8259_asm_mask,i8259_asm_unmask,
    voidop)
INTRSTUB(legacy,6,i8259_asm_ack1,voidop,i8259_asm_mask,i8259_asm_unmask,
    voidop)
INTRSTUB(legacy,7,i8259_asm_ack1,voidop,i8259_asm_mask,i8259_asm_unmask,
    voidop)
#undef ICUADDR
#define ICUADDR IO_ICU2

INTRSTUB(legacy,8,i8259_asm_ack2,voidop,i8259_asm_mask,i8259_asm_unmask,
    voidop)
INTRSTUB(legacy,9,i8259_asm_ack2,voidop,i8259_asm_mask,i8259_asm_unmask,
    voidop)
INTRSTUB(legacy,10,i8259_asm_ack2,voidop,i8259_asm_mask,i8259_asm_unmask,
    voidop)
INTRSTUB(legacy,11,i8259_asm_ack2,voidop,i8259_asm_mask,i8259_asm_unmask,
    voidop)
INTRSTUB(legacy,12,i8259_asm_ack2,voidop,i8259_asm_mask,i8259_asm_unmask,
    voidop)
INTRSTUB(legacy,13,i8259_asm_ack2,voidop,i8259_asm_mask,i8259_asm_unmask,
    voidop)
INTRSTUB(legacy,14,i8259_asm_ack2,voidop,i8259_asm_mask,i8259_asm_unmask,
    voidop)
INTRSTUB(legacy,15,i8259_asm_ack2,voidop,i8259_asm_mask,i8259_asm_unmask,
    voidop)

#if NIOAPIC > 0

INTRSTUB(ioapic_edge,0,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,1,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,2,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,3,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,4,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,5,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,6,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,7,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,8,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,9,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,10,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,11,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,12,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,13,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,14,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,15,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,16,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,17,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,18,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,19,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,20,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,21,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,22,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,23,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,24,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,25,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,26,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,27,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,28,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,29,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,30,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,31,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,32,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,33,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,34,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,35,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,36,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,37,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,38,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,39,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,40,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,41,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,42,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,43,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,44,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,45,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,46,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,47,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,48,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,49,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,50,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,51,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,52,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,53,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,54,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,55,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,56,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,57,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,58,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,59,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,60,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,61,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,62,voidop,ioapic_asm_ack,voidop,voidop,voidop)
INTRSTUB(ioapic_edge,63,voidop,ioapic_asm_ack,voidop,voidop,voidop)

INTRSTUB(ioapic_level,0,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,1,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,2,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,3,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,4,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,5,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,6,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,7,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,8,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,9,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,10,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,11,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,12,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,13,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,14,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,15,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,16,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,17,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,18,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,19,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,20,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,21,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,22,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,23,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,24,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,25,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,26,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,27,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,28,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,29,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,30,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,31,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,32,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,33,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,34,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,35,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,36,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,37,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,38,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,39,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,40,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,41,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,42,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,43,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,44,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,45,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,46,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,47,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,48,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,49,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,50,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,51,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,52,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,53,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,54,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,55,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,56,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,57,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,58,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,59,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,60,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,61,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,62,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)
INTRSTUB(ioapic_level,63,voidop,ioapic_asm_ack,voidop,ioapic_unmask,ioapic_mask)

#endif

	.section .rodata

	.globl _C_LABEL(i8259_stubs)
_C_LABEL(i8259_stubs):
	.quad _C_LABEL(Xintr_legacy0), _C_LABEL(Xrecurse_legacy0)
	.quad _C_LABEL(Xresume_legacy0)
	.quad _C_LABEL(Xintr_legacy1), _C_LABEL(Xrecurse_legacy1)
	.quad _C_LABEL(Xresume_legacy1)
	.quad _C_LABEL(Xintr_legacy2), _C_LABEL(Xrecurse_legacy2)
	.quad _C_LABEL(Xresume_legacy2)
	.quad _C_LABEL(Xintr_legacy3), _C_LABEL(Xrecurse_legacy3)
	.quad _C_LABEL(Xresume_legacy3)
	.quad _C_LABEL(Xintr_legacy4), _C_LABEL(Xrecurse_legacy4)
	.quad _C_LABEL(Xresume_legacy4)
	.quad _C_LABEL(Xintr_legacy5), _C_LABEL(Xrecurse_legacy5)
	.quad _C_LABEL(Xresume_legacy5)
	.quad _C_LABEL(Xintr_legacy6), _C_LABEL(Xrecurse_legacy6)
	.quad _C_LABEL(Xresume_legacy6)
	.quad _C_LABEL(Xintr_legacy7), _C_LABEL(Xrecurse_legacy7)
	.quad _C_LABEL(Xresume_legacy7)
	.quad _C_LABEL(Xintr_legacy8), _C_LABEL(Xrecurse_legacy8)
	.quad _C_LABEL(Xresume_legacy8)
	.quad _C_LABEL(Xintr_legacy9), _C_LABEL(Xrecurse_legacy9)
	.quad _C_LABEL(Xresume_legacy9)
	.quad _C_LABEL(Xintr_legacy10), _C_LABEL(Xrecurse_legacy10)
	.quad _C_LABEL(Xresume_legacy10)
	.quad _C_LABEL(Xintr_legacy11), _C_LABEL(Xrecurse_legacy11)
	.quad _C_LABEL(Xresume_legacy11)
	.quad _C_LABEL(Xintr_legacy12), _C_LABEL(Xrecurse_legacy12)
	.quad _C_LABEL(Xresume_legacy12)
	.quad _C_LABEL(Xintr_legacy13), _C_LABEL(Xrecurse_legacy13)
	.quad _C_LABEL(Xresume_legacy13)
	.quad _C_LABEL(Xintr_legacy14), _C_LABEL(Xrecurse_legacy14)
	.quad _C_LABEL(Xresume_legacy14)
	.quad _C_LABEL(Xintr_legacy15), _C_LABEL(Xrecurse_legacy15)
	.quad _C_LABEL(Xresume_legacy15)

#if NIOAPIC > 0
	.globl _C_LABEL(ioapic_edge_stubs)
_C_LABEL(ioapic_edge_stubs):
	.quad _C_LABEL(Xintr_ioapic_edge0), _C_LABEL(Xrecurse_ioapic_edge0)
	.quad _C_LABEL(Xresume_ioapic_edge0)
	.quad _C_LABEL(Xintr_ioapic_edge1), _C_LABEL(Xrecurse_ioapic_edge1)
	.quad _C_LABEL(Xresume_ioapic_edge1)
	.quad _C_LABEL(Xintr_ioapic_edge2), _C_LABEL(Xrecurse_ioapic_edge2)
	.quad _C_LABEL(Xresume_ioapic_edge2)
	.quad _C_LABEL(Xintr_ioapic_edge3), _C_LABEL(Xrecurse_ioapic_edge3)
	.quad _C_LABEL(Xresume_ioapic_edge3)
	.quad _C_LABEL(Xintr_ioapic_edge4), _C_LABEL(Xrecurse_ioapic_edge4)
	.quad _C_LABEL(Xresume_ioapic_edge4)
	.quad _C_LABEL(Xintr_ioapic_edge5), _C_LABEL(Xrecurse_ioapic_edge5)
	.quad _C_LABEL(Xresume_ioapic_edge5)
	.quad _C_LABEL(Xintr_ioapic_edge6), _C_LABEL(Xrecurse_ioapic_edge6)
	.quad _C_LABEL(Xresume_ioapic_edge6)
	.quad _C_LABEL(Xintr_ioapic_edge7), _C_LABEL(Xrecurse_ioapic_edge7)
	.quad _C_LABEL(Xresume_ioapic_edge7)
	.quad _C_LABEL(Xintr_ioapic_edge8), _C_LABEL(Xrecurse_ioapic_edge8)
	.quad _C_LABEL(Xresume_ioapic_edge8)
	.quad _C_LABEL(Xintr_ioapic_edge9), _C_LABEL(Xrecurse_ioapic_edge9)
	.quad _C_LABEL(Xresume_ioapic_edge9)
	.quad _C_LABEL(Xintr_ioapic_edge10), _C_LABEL(Xrecurse_ioapic_edge10)
	.quad _C_LABEL(Xresume_ioapic_edge10)
	.quad _C_LABEL(Xintr_ioapic_edge11), _C_LABEL(Xrecurse_ioapic_edge11)
	.quad _C_LABEL(Xresume_ioapic_edge11)
	.quad _C_LABEL(Xintr_ioapic_edge12), _C_LABEL(Xrecurse_ioapic_edge12)
	.quad _C_LABEL(Xresume_ioapic_edge12)
	.quad _C_LABEL(Xintr_ioapic_edge13), _C_LABEL(Xrecurse_ioapic_edge13)
	.quad _C_LABEL(Xresume_ioapic_edge13)
	.quad _C_LABEL(Xintr_ioapic_edge14), _C_LABEL(Xrecurse_ioapic_edge14)
	.quad _C_LABEL(Xresume_ioapic_edge14)
	.quad _C_LABEL(Xintr_ioapic_edge15), _C_LABEL(Xrecurse_ioapic_edge15)
	.quad _C_LABEL(Xresume_ioapic_edge15)
	.quad _C_LABEL(Xintr_ioapic_edge16), _C_LABEL(Xrecurse_ioapic_edge16)
	.quad _C_LABEL(Xresume_ioapic_edge16)
	.quad _C_LABEL(Xintr_ioapic_edge17), _C_LABEL(Xrecurse_ioapic_edge17)
	.quad _C_LABEL(Xresume_ioapic_edge17)
	.quad _C_LABEL(Xintr_ioapic_edge18), _C_LABEL(Xrecurse_ioapic_edge18)
	.quad _C_LABEL(Xresume_ioapic_edge18)
	.quad _C_LABEL(Xintr_ioapic_edge19), _C_LABEL(Xrecurse_ioapic_edge19)
	.quad _C_LABEL(Xresume_ioapic_edge19)
	.quad _C_LABEL(Xintr_ioapic_edge20), _C_LABEL(Xrecurse_ioapic_edge20)
	.quad _C_LABEL(Xresume_ioapic_edge20)
	.quad _C_LABEL(Xintr_ioapic_edge21), _C_LABEL(Xrecurse_ioapic_edge21)
	.quad _C_LABEL(Xresume_ioapic_edge21)
	.quad _C_LABEL(Xintr_ioapic_edge22), _C_LABEL(Xrecurse_ioapic_edge22)
	.quad _C_LABEL(Xresume_ioapic_edge22)
	.quad _C_LABEL(Xintr_ioapic_edge23), _C_LABEL(Xrecurse_ioapic_edge23)
	.quad _C_LABEL(Xresume_ioapic_edge23)
	.quad _C_LABEL(Xintr_ioapic_edge24), _C_LABEL(Xrecurse_ioapic_edge24)
	.quad _C_LABEL(Xresume_ioapic_edge24)
	.quad _C_LABEL(Xintr_ioapic_edge25), _C_LABEL(Xrecurse_ioapic_edge25)
	.quad _C_LABEL(Xresume_ioapic_edge25)
	.quad _C_LABEL(Xintr_ioapic_edge26), _C_LABEL(Xrecurse_ioapic_edge26)
	.quad _C_LABEL(Xresume_ioapic_edge26)
	.quad _C_LABEL(Xintr_ioapic_edge27), _C_LABEL(Xrecurse_ioapic_edge27)
	.quad _C_LABEL(Xresume_ioapic_edge27)
	.quad _C_LABEL(Xintr_ioapic_edge28), _C_LABEL(Xrecurse_ioapic_edge28)
	.quad _C_LABEL(Xresume_ioapic_edge28)
	.quad _C_LABEL(Xintr_ioapic_edge29), _C_LABEL(Xrecurse_ioapic_edge29)
	.quad _C_LABEL(Xresume_ioapic_edge29)
	.quad _C_LABEL(Xintr_ioapic_edge30), _C_LABEL(Xrecurse_ioapic_edge30)
	.quad _C_LABEL(Xresume_ioapic_edge30)
	.quad _C_LABEL(Xintr_ioapic_edge31), _C_LABEL(Xrecurse_ioapic_edge31)
	.quad _C_LABEL(Xresume_ioapic_edge31)
	.quad _C_LABEL(Xintr_ioapic_edge32), _C_LABEL(Xrecurse_ioapic_edge32)
	.quad _C_LABEL(Xresume_ioapic_edge32)
	.quad _C_LABEL(Xintr_ioapic_edge33), _C_LABEL(Xrecurse_ioapic_edge33)
	.quad _C_LABEL(Xresume_ioapic_edge33)
	.quad _C_LABEL(Xintr_ioapic_edge34), _C_LABEL(Xrecurse_ioapic_edge34)
	.quad _C_LABEL(Xresume_ioapic_edge34)
	.quad _C_LABEL(Xintr_ioapic_edge35), _C_LABEL(Xrecurse_ioapic_edge35)
	.quad _C_LABEL(Xresume_ioapic_edge35)
	.quad _C_LABEL(Xintr_ioapic_edge36), _C_LABEL(Xrecurse_ioapic_edge36)
	.quad _C_LABEL(Xresume_ioapic_edge36)
	.quad _C_LABEL(Xintr_ioapic_edge37), _C_LABEL(Xrecurse_ioapic_edge37)
	.quad _C_LABEL(Xresume_ioapic_edge37)
	.quad _C_LABEL(Xintr_ioapic_edge38), _C_LABEL(Xrecurse_ioapic_edge38)
	.quad _C_LABEL(Xresume_ioapic_edge38)
	.quad _C_LABEL(Xintr_ioapic_edge39), _C_LABEL(Xrecurse_ioapic_edge39)
	.quad _C_LABEL(Xresume_ioapic_edge39)
	.quad _C_LABEL(Xintr_ioapic_edge40), _C_LABEL(Xrecurse_ioapic_edge40)
	.quad _C_LABEL(Xresume_ioapic_edge40)
	.quad _C_LABEL(Xintr_ioapic_edge41), _C_LABEL(Xrecurse_ioapic_edge41)
	.quad _C_LABEL(Xresume_ioapic_edge41)
	.quad _C_LABEL(Xintr_ioapic_edge42), _C_LABEL(Xrecurse_ioapic_edge42)
	.quad _C_LABEL(Xresume_ioapic_edge42)
	.quad _C_LABEL(Xintr_ioapic_edge43), _C_LABEL(Xrecurse_ioapic_edge43)
	.quad _C_LABEL(Xresume_ioapic_edge43)
	.quad _C_LABEL(Xintr_ioapic_edge44), _C_LABEL(Xrecurse_ioapic_edge44)
	.quad _C_LABEL(Xresume_ioapic_edge44)
	.quad _C_LABEL(Xintr_ioapic_edge45), _C_LABEL(Xrecurse_ioapic_edge45)
	.quad _C_LABEL(Xresume_ioapic_edge45)
	.quad _C_LABEL(Xintr_ioapic_edge46), _C_LABEL(Xrecurse_ioapic_edge46)
	.quad _C_LABEL(Xresume_ioapic_edge46)
	.quad _C_LABEL(Xintr_ioapic_edge47), _C_LABEL(Xrecurse_ioapic_edge47)
	.quad _C_LABEL(Xresume_ioapic_edge47)
	.quad _C_LABEL(Xintr_ioapic_edge48), _C_LABEL(Xrecurse_ioapic_edge48)
	.quad _C_LABEL(Xresume_ioapic_edge48)
	.quad _C_LABEL(Xintr_ioapic_edge49), _C_LABEL(Xrecurse_ioapic_edge49)
	.quad _C_LABEL(Xresume_ioapic_edge49)
	.quad _C_LABEL(Xintr_ioapic_edge50), _C_LABEL(Xrecurse_ioapic_edge50)
	.quad _C_LABEL(Xresume_ioapic_edge50)
	.quad _C_LABEL(Xintr_ioapic_edge51), _C_LABEL(Xrecurse_ioapic_edge51)
	.quad _C_LABEL(Xresume_ioapic_edge51)
	.quad _C_LABEL(Xintr_ioapic_edge52), _C_LABEL(Xrecurse_ioapic_edge52)
	.quad _C_LABEL(Xresume_ioapic_edge52)
	.quad _C_LABEL(Xintr_ioapic_edge53), _C_LABEL(Xrecurse_ioapic_edge53)
	.quad _C_LABEL(Xresume_ioapic_edge53)
	.quad _C_LABEL(Xintr_ioapic_edge54), _C_LABEL(Xrecurse_ioapic_edge54)
	.quad _C_LABEL(Xresume_ioapic_edge54)
	.quad _C_LABEL(Xintr_ioapic_edge55), _C_LABEL(Xrecurse_ioapic_edge55)
	.quad _C_LABEL(Xresume_ioapic_edge55)
	.quad _C_LABEL(Xintr_ioapic_edge56), _C_LABEL(Xrecurse_ioapic_edge56)
	.quad _C_LABEL(Xresume_ioapic_edge56)
	.quad _C_LABEL(Xintr_ioapic_edge57), _C_LABEL(Xrecurse_ioapic_edge57)
	.quad _C_LABEL(Xresume_ioapic_edge57)
	.quad _C_LABEL(Xintr_ioapic_edge58), _C_LABEL(Xrecurse_ioapic_edge58)
	.quad _C_LABEL(Xresume_ioapic_edge58)
	.quad _C_LABEL(Xintr_ioapic_edge59), _C_LABEL(Xrecurse_ioapic_edge59)
	.quad _C_LABEL(Xresume_ioapic_edge59)
	.quad _C_LABEL(Xintr_ioapic_edge60), _C_LABEL(Xrecurse_ioapic_edge60)
	.quad _C_LABEL(Xresume_ioapic_edge60)
	.quad _C_LABEL(Xintr_ioapic_edge61), _C_LABEL(Xrecurse_ioapic_edge61)
	.quad _C_LABEL(Xresume_ioapic_edge61)
	.quad _C_LABEL(Xintr_ioapic_edge62), _C_LABEL(Xrecurse_ioapic_edge62)
	.quad _C_LABEL(Xresume_ioapic_edge62)
	.quad _C_LABEL(Xintr_ioapic_edge63), _C_LABEL(Xrecurse_ioapic_edge63)
	.quad _C_LABEL(Xresume_ioapic_edge63)

	.globl _C_LABEL(ioapic_level_stubs)
_C_LABEL(ioapic_level_stubs):
	.quad _C_LABEL(Xintr_ioapic_level0), _C_LABEL(Xrecurse_ioapic_level0)
	.quad _C_LABEL(Xresume_ioapic_level0)
	.quad _C_LABEL(Xintr_ioapic_level1), _C_LABEL(Xrecurse_ioapic_level1)
	.quad _C_LABEL(Xresume_ioapic_level1)
	.quad _C_LABEL(Xintr_ioapic_level2), _C_LABEL(Xrecurse_ioapic_level2)
	.quad _C_LABEL(Xresume_ioapic_level2)
	.quad _C_LABEL(Xintr_ioapic_level3), _C_LABEL(Xrecurse_ioapic_level3)
	.quad _C_LABEL(Xresume_ioapic_level3)
	.quad _C_LABEL(Xintr_ioapic_level4), _C_LABEL(Xrecurse_ioapic_level4)
	.quad _C_LABEL(Xresume_ioapic_level4)
	.quad _C_LABEL(Xintr_ioapic_level5), _C_LABEL(Xrecurse_ioapic_level5)
	.quad _C_LABEL(Xresume_ioapic_level5)
	.quad _C_LABEL(Xintr_ioapic_level6), _C_LABEL(Xrecurse_ioapic_level6)
	.quad _C_LABEL(Xresume_ioapic_level6)
	.quad _C_LABEL(Xintr_ioapic_level7), _C_LABEL(Xrecurse_ioapic_level7)
	.quad _C_LABEL(Xresume_ioapic_level7)
	.quad _C_LABEL(Xintr_ioapic_level8), _C_LABEL(Xrecurse_ioapic_level8)
	.quad _C_LABEL(Xresume_ioapic_level8)
	.quad _C_LABEL(Xintr_ioapic_level9), _C_LABEL(Xrecurse_ioapic_level9)
	.quad _C_LABEL(Xresume_ioapic_level9)
	.quad _C_LABEL(Xintr_ioapic_level10), _C_LABEL(Xrecurse_ioapic_level10)
	.quad _C_LABEL(Xresume_ioapic_level10)
	.quad _C_LABEL(Xintr_ioapic_level11), _C_LABEL(Xrecurse_ioapic_level11)
	.quad _C_LABEL(Xresume_ioapic_level11)
	.quad _C_LABEL(Xintr_ioapic_level12), _C_LABEL(Xrecurse_ioapic_level12)
	.quad _C_LABEL(Xresume_ioapic_level12)
	.quad _C_LABEL(Xintr_ioapic_level13), _C_LABEL(Xrecurse_ioapic_level13)
	.quad _C_LABEL(Xresume_ioapic_level13)
	.quad _C_LABEL(Xintr_ioapic_level14), _C_LABEL(Xrecurse_ioapic_level14)
	.quad _C_LABEL(Xresume_ioapic_level14)
	.quad _C_LABEL(Xintr_ioapic_level15), _C_LABEL(Xrecurse_ioapic_level15)
	.quad _C_LABEL(Xresume_ioapic_level15)
	.quad _C_LABEL(Xintr_ioapic_level16), _C_LABEL(Xrecurse_ioapic_level16)
	.quad _C_LABEL(Xresume_ioapic_level16)
	.quad _C_LABEL(Xintr_ioapic_level17), _C_LABEL(Xrecurse_ioapic_level17)
	.quad _C_LABEL(Xresume_ioapic_level17)
	.quad _C_LABEL(Xintr_ioapic_level18), _C_LABEL(Xrecurse_ioapic_level18)
	.quad _C_LABEL(Xresume_ioapic_level18)
	.quad _C_LABEL(Xintr_ioapic_level19), _C_LABEL(Xrecurse_ioapic_level19)
	.quad _C_LABEL(Xresume_ioapic_level19)
	.quad _C_LABEL(Xintr_ioapic_level20), _C_LABEL(Xrecurse_ioapic_level20)
	.quad _C_LABEL(Xresume_ioapic_level20)
	.quad _C_LABEL(Xintr_ioapic_level21), _C_LABEL(Xrecurse_ioapic_level21)
	.quad _C_LABEL(Xresume_ioapic_level21)
	.quad _C_LABEL(Xintr_ioapic_level22), _C_LABEL(Xrecurse_ioapic_level22)
	.quad _C_LABEL(Xresume_ioapic_level22)
	.quad _C_LABEL(Xintr_ioapic_level23), _C_LABEL(Xrecurse_ioapic_level23)
	.quad _C_LABEL(Xresume_ioapic_level23)
	.quad _C_LABEL(Xintr_ioapic_level24), _C_LABEL(Xrecurse_ioapic_level24)
	.quad _C_LABEL(Xresume_ioapic_level24)
	.quad _C_LABEL(Xintr_ioapic_level25), _C_LABEL(Xrecurse_ioapic_level25)
	.quad _C_LABEL(Xresume_ioapic_level25)
	.quad _C_LABEL(Xintr_ioapic_level26), _C_LABEL(Xrecurse_ioapic_level26)
	.quad _C_LABEL(Xresume_ioapic_level26)
	.quad _C_LABEL(Xintr_ioapic_level27), _C_LABEL(Xrecurse_ioapic_level27)
	.quad _C_LABEL(Xresume_ioapic_level27)
	.quad _C_LABEL(Xintr_ioapic_level28), _C_LABEL(Xrecurse_ioapic_level28)
	.quad _C_LABEL(Xresume_ioapic_level28)
	.quad _C_LABEL(Xintr_ioapic_level29), _C_LABEL(Xrecurse_ioapic_level29)
	.quad _C_LABEL(Xresume_ioapic_level29)
	.quad _C_LABEL(Xintr_ioapic_level30), _C_LABEL(Xrecurse_ioapic_level30)
	.quad _C_LABEL(Xresume_ioapic_level30)
	.quad _C_LABEL(Xintr_ioapic_level31), _C_LABEL(Xrecurse_ioapic_level31)
	.quad _C_LABEL(Xresume_ioapic_level31)
	.quad _C_LABEL(Xintr_ioapic_level32), _C_LABEL(Xrecurse_ioapic_level32)
	.quad _C_LABEL(Xresume_ioapic_level32)
	.quad _C_LABEL(Xintr_ioapic_level33), _C_LABEL(Xrecurse_ioapic_level33)
	.quad _C_LABEL(Xresume_ioapic_level33)
	.quad _C_LABEL(Xintr_ioapic_level34), _C_LABEL(Xrecurse_ioapic_level34)
	.quad _C_LABEL(Xresume_ioapic_level34)
	.quad _C_LABEL(Xintr_ioapic_level35), _C_LABEL(Xrecurse_ioapic_level35)
	.quad _C_LABEL(Xresume_ioapic_level35)
	.quad _C_LABEL(Xintr_ioapic_level36), _C_LABEL(Xrecurse_ioapic_level36)
	.quad _C_LABEL(Xresume_ioapic_level36)
	.quad _C_LABEL(Xintr_ioapic_level37), _C_LABEL(Xrecurse_ioapic_level37)
	.quad _C_LABEL(Xresume_ioapic_level37)
	.quad _C_LABEL(Xintr_ioapic_level38), _C_LABEL(Xrecurse_ioapic_level38)
	.quad _C_LABEL(Xresume_ioapic_level38)
	.quad _C_LABEL(Xintr_ioapic_level39), _C_LABEL(Xrecurse_ioapic_level39)
	.quad _C_LABEL(Xresume_ioapic_level39)
	.quad _C_LABEL(Xintr_ioapic_level40), _C_LABEL(Xrecurse_ioapic_level40)
	.quad _C_LABEL(Xresume_ioapic_level40)
	.quad _C_LABEL(Xintr_ioapic_level41), _C_LABEL(Xrecurse_ioapic_level41)
	.quad _C_LABEL(Xresume_ioapic_level41)
	.quad _C_LABEL(Xintr_ioapic_level42), _C_LABEL(Xrecurse_ioapic_level42)
	.quad _C_LABEL(Xresume_ioapic_level42)
	.quad _C_LABEL(Xintr_ioapic_level43), _C_LABEL(Xrecurse_ioapic_level43)
	.quad _C_LABEL(Xresume_ioapic_level43)
	.quad _C_LABEL(Xintr_ioapic_level44), _C_LABEL(Xrecurse_ioapic_level44)
	.quad _C_LABEL(Xresume_ioapic_level44)
	.quad _C_LABEL(Xintr_ioapic_level45), _C_LABEL(Xrecurse_ioapic_level45)
	.quad _C_LABEL(Xresume_ioapic_level45)
	.quad _C_LABEL(Xintr_ioapic_level46), _C_LABEL(Xrecurse_ioapic_level46)
	.quad _C_LABEL(Xresume_ioapic_level46)
	.quad _C_LABEL(Xintr_ioapic_level47), _C_LABEL(Xrecurse_ioapic_level47)
	.quad _C_LABEL(Xresume_ioapic_level47)
	.quad _C_LABEL(Xintr_ioapic_level48), _C_LABEL(Xrecurse_ioapic_level48)
	.quad _C_LABEL(Xresume_ioapic_level48)
	.quad _C_LABEL(Xintr_ioapic_level49), _C_LABEL(Xrecurse_ioapic_level49)
	.quad _C_LABEL(Xresume_ioapic_level49)
	.quad _C_LABEL(Xintr_ioapic_level50), _C_LABEL(Xrecurse_ioapic_level50)
	.quad _C_LABEL(Xresume_ioapic_level50)
	.quad _C_LABEL(Xintr_ioapic_level51), _C_LABEL(Xrecurse_ioapic_level51)
	.quad _C_LABEL(Xresume_ioapic_level51)
	.quad _C_LABEL(Xintr_ioapic_level52), _C_LABEL(Xrecurse_ioapic_level52)
	.quad _C_LABEL(Xresume_ioapic_level52)
	.quad _C_LABEL(Xintr_ioapic_level53), _C_LABEL(Xrecurse_ioapic_level53)
	.quad _C_LABEL(Xresume_ioapic_level53)
	.quad _C_LABEL(Xintr_ioapic_level54), _C_LABEL(Xrecurse_ioapic_level54)
	.quad _C_LABEL(Xresume_ioapic_level54)
	.quad _C_LABEL(Xintr_ioapic_level55), _C_LABEL(Xrecurse_ioapic_level55)
	.quad _C_LABEL(Xresume_ioapic_level55)
	.quad _C_LABEL(Xintr_ioapic_level56), _C_LABEL(Xrecurse_ioapic_level56)
	.quad _C_LABEL(Xresume_ioapic_level56)
	.quad _C_LABEL(Xintr_ioapic_level57), _C_LABEL(Xrecurse_ioapic_level57)
	.quad _C_LABEL(Xresume_ioapic_level57)
	.quad _C_LABEL(Xintr_ioapic_level58), _C_LABEL(Xrecurse_ioapic_level58)
	.quad _C_LABEL(Xresume_ioapic_level58)
	.quad _C_LABEL(Xintr_ioapic_level59), _C_LABEL(Xrecurse_ioapic_level59)
	.quad _C_LABEL(Xresume_ioapic_level59)
	.quad _C_LABEL(Xintr_ioapic_level60), _C_LABEL(Xrecurse_ioapic_level60)
	.quad _C_LABEL(Xresume_ioapic_level60)
	.quad _C_LABEL(Xintr_ioapic_level61), _C_LABEL(Xrecurse_ioapic_level61)
	.quad _C_LABEL(Xresume_ioapic_level61)
	.quad _C_LABEL(Xintr_ioapic_level62), _C_LABEL(Xrecurse_ioapic_level62)
	.quad _C_LABEL(Xresume_ioapic_level62)
	.quad _C_LABEL(Xintr_ioapic_level63), _C_LABEL(Xrecurse_ioapic_level63)
	.quad _C_LABEL(Xresume_ioapic_level63)
#endif

/*
 * Soft interrupt handlers
 */
	.text
IDTVEC(softtty)
	movl	$IPL_SOFTTTY, CPUVAR(ILEVEL)
	sti
	incl	CPUVAR(IDEPTH)
	movl	$X86_SOFTINTR_SOFTTTY,%edi
	call	_C_LABEL(softintr_dispatch)
	decl	CPUVAR(IDEPTH)
	jmp	*%r13

IDTVEC(softnet)
	movl	$IPL_SOFTNET, CPUVAR(ILEVEL)
	sti
	incl	CPUVAR(IDEPTH)
	movl	$X86_SOFTINTR_SOFTNET,%edi
	call	_C_LABEL(softintr_dispatch)
	decl	CPUVAR(IDEPTH)
	jmp	*%r13

IDTVEC(softclock)
	movl	$IPL_SOFTCLOCK, CPUVAR(ILEVEL)
	sti
	incl	CPUVAR(IDEPTH)
	movl	$X86_SOFTINTR_SOFTCLOCK,%edi
	call	_C_LABEL(softintr_dispatch)
	decl	CPUVAR(IDEPTH)
	jmp	*%r13
@


1.50
log
@If SMAP is present, clear PSL_AC on kernel entry and interrupt so that
only the code in copy{in,out}* that need it run with it set.  Panic if
it's set on entry to trap() or syscall().  Prompted by Maxime Villard's
NetBSD work.

ok kettenis@@ mlarkin@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vector.S,v 1.49 2017/06/29 17:17:28 deraadt Exp $	*/
d130 1
@


1.49
log
@Put asm-generated strings into .rodata
ok millert
@
text
@d1 1
a1 1
/*	$OpenBSD: vector.S,v 1.48 2017/05/30 12:41:55 mlarkin Exp $	*/
d128 1
d250 1
d369 1
d453 1
d488 1
d523 1
d573 1
@


1.48
log
@move some data tables out of .text and into .rodata where they belong

ok deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: vector.S,v 1.47 2016/09/04 09:22:28 mpi Exp $	*/
d289 1
a289 1
	movabsq	$4f,%rdi
d299 5
a303 1
4:	.asciz	"WARNING: SPL NOT LOWERED ON TRAP EXIT %x %x\n"
@


1.47
log
@Introduce Dynamic Profiling, a ddb(4) based & gprof compatible kernel
profiling framework.

Code patching is used to enable probes when entering functions.  The
probes will call a mcount()-like function to match the behavior of a
GPROF kernel.

Currently only available on amd64 and guarded under DDBPROF.  Support
for other archs will follow soon.

A new sysctl knob, ddb.console, need to be set to 1 in securelevel 0
to be able to use this feature.

Inputs and ok guenther@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vector.S,v 1.46 2016/06/22 01:12:38 mikeb Exp $	*/
d781 2
a1081 1
	.data
@


1.47.4.1
log
@If SMAP is present, clear PSL_AC on kernel entry and interrupt so that
only the code in copy{in,out}* that need it run with it set.  Panic if
it's set on entry to trap() or syscall().  Prompted by Maxime Villard's
NetBSD work.
@
text
@d1 1
a1 1
/*	$OpenBSD: vector.S,v 1.47 2016/09/04 09:22:28 mpi Exp $	*/
a127 1
	SMAP_CLAC
a248 1
	SMAP_CLAC
a362 1
	SMAP_CLAC
a445 1
	SMAP_CLAC
a479 1
	SMAP_CLAC
a513 1
	SMAP_CLAC
a562 1
	SMAP_CLAC							;\
@


1.47.4.2
log
@Follow the pattern set by copy*/pcb_onfault: when xrstor faults, return
from the trap to a 'resume' address to effectively make xrstor_user()
return an error indication, then do the FPU cleanup and trap generation
from there where we can get access to the original, userspace trapframe.

The original fix tried to handle the trap while on the wrong trapframe,
leaking kernel addresses and possibly leading to double faults.
Problem pointed out by abluhm@@
from guenther@@; ok deraadt@@ mikeb@@
OpenBSD 6.1 errata 031
@
text
@d1 1
a1 1
/*	$OpenBSD: vector.S,v 1.47.4.1 2017/08/26 00:14:20 bluhm Exp $	*/
a129 1
	movq	%rsp, %rsi
@


1.46
log
@Setup Hyper-V hypercall page and an IDT vector.

ok mlarkin, kettenis, deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: vector.S,v 1.45 2016/03/03 12:32:23 mpi Exp $	*/
d252 17
@


1.46.2.1
log
@If SMAP is present, clear PSL_AC on kernel entry and interrupt so that
only the code in copy{in,out}* that need it run with it set.  Panic if
it's set on entry to trap() or syscall().  Prompted by Maxime Villard's
NetBSD work.
@
text
@d1 1
a1 1
/*	$OpenBSD: vector.S,v 1.46 2016/06/22 01:12:38 mikeb Exp $	*/
a127 1
	SMAP_CLAC
a248 1
	SMAP_CLAC
a345 1
	SMAP_CLAC
a428 1
	SMAP_CLAC
a462 1
	SMAP_CLAC
a496 1
	SMAP_CLAC
a545 1
	SMAP_CLAC							;\
@


1.46.2.2
log
@Follow the pattern set by copy*/pcb_onfault: when xrstor faults, return
from the trap to a 'resume' address to effectively make xrstor_user()
return an error indication, then do the FPU cleanup and trap generation
from there where we can get access to the original, userspace trapframe.

The original fix tried to handle the trap while on the wrong trapframe,
leaking kernel addresses and possibly leading to double faults.
Problem pointed out by abluhm@@
from guenther@@; ok deraadt@@ mikeb@@
OpenBSD 6.0 errata 045
@
text
@d1 1
a1 1
/*	$OpenBSD: vector.S,v 1.46.2.1 2017/08/26 00:15:05 bluhm Exp $	*/
a129 1
	movq	%rsp, %rsi
@


1.45
log
@Kill BPTTRAP() and reduce some differences betwen i386 and amd64 trap
handlers.

No functionnal change.

ok mlarkin@@, mikeb@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vector.S,v 1.44 2015/12/08 19:45:55 mikeb Exp $	*/
d87 1
d472 34
@


1.44
log
@Set up an IDT vector for Xen callbacks

This adds support for delivering the combined Xen interrupt
that later fans out into event port specific (device specific)
interrupts via an IDT of a guest system.

The Xen IDT vector is set to be the first of the IPL_NET group
and is implemented the same way LAPIC timer and IPIs are done.
The additional machinery is there to be able to mask it via
standard mechanisms (e.g. splnet).

Discussed with kettenis@@, OK mlarkin, reyk
@
text
@d1 1
a1 1
/*	$OpenBSD: vector.S,v 1.43 2015/07/17 15:37:58 guenther Exp $	*/
d99 1
a99 1
 */ 
a105 2
#define	BPTTRAP(a)	ZTRAP(a)

d110 1
a110 1
	BPTTRAP(T_TRCTRAP)
d114 1
a114 1
	BPTTRAP(T_BPTFLT)
a245 1
	.globl	calltrap
@


1.43
log
@Consistently use SEL_RPL as the mask when testing selector privilege level
@
text
@d1 1
a1 1
/*	$OpenBSD: vector.S,v 1.42 2015/07/16 05:10:14 guenther Exp $	*/
d86 1
d439 35
a474 1

@


1.42
log
@Move grab/release of the kernel_lock for softintrs from the ASM stubs to
softintr_dispatch().  Delete traces of long superseded stats code.

ok beck@@ mpi@@ uebayasi@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vector.S,v 1.41 2015/07/09 13:23:51 mikeb Exp $	*/
d156 1
a156 1
	testq	$SEL_UPL,TF_CS(%rsp)
@


1.41
log
@Prevent possible interrupt recursion before unwinding the stack.

Xen delivers about 20 seconds worth of missed LAPIC timer events
after we enable interrupts on application CPUs and this makes us
recurse and burn the stack.

OK kettenis, guenther, deraadt, "good find" mlarkin
@
text
@d1 1
a1 1
/*	$OpenBSD: vector.S,v 1.40 2015/06/29 03:02:38 mlarkin Exp $	*/
a1004 4
#ifdef MULTIPROCESSOR
	call	_C_LABEL(x86_softintlock)
#endif
	movq	CPUVAR(ISOURCES) + SIR_TTY * 8, %r12
a1006 3
#ifdef MULTIPROCESSOR	
	call	_C_LABEL(x86_softintunlock)
#endif
a1013 4
#ifdef MULTIPROCESSOR	
	call	_C_LABEL(x86_softintlock)
#endif
	movq	CPUVAR(ISOURCES) + SIR_NET * 8, %r12
a1015 3
#ifdef MULTIPROCESSOR	
	call	_C_LABEL(x86_softintunlock)	
#endif
a1022 5
#ifdef MULTIPROCESSOR	
	call	_C_LABEL(x86_softintlock)
#endif
	movq	CPUVAR(ISOURCES) + SIR_CLOCK * 8, %r12

a1024 3
#ifdef MULTIPROCESSOR	
	call	_C_LABEL(x86_softintunlock)		
#endif
@


1.40
log
@
Fix trap setup for double faults; error pointed out by Wei Liu a few months
ago and I forgot to commit this until now.

From Wei Liu <wei.liu2 at citrix.com>

ok mikeb@@, guenther@@, ratchov@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vector.S,v 1.39 2015/06/28 01:16:29 guenther Exp $	*/
a352 1
	sti
a436 1
	sti
a518 1
	sti								;\
a522 1
	sti								;\
@


1.39
log
@Split AST handling from trap() into ast() and get rid of T_ASTFLT.
Don't skip the AST check when returning from *fork() in the child.
Make sure to count interrupts even when they're deferred or stray.

testing by krw@@, and then many via snapshots
@
text
@d1 1
a1 1
/*	$OpenBSD: vector.S,v 1.38 2015/05/18 19:59:27 guenther Exp $	*/
d132 1
a132 1
	ZTRAP(T_DOUBLEFLT)
@


1.38
log
@Do lazy update/reset of the FS.base and %[def]s segment registers: reseting
segment registers in cpu_switchto if the old thread had made it to userspace
and restoring FS.base only on first return to userspace since context switch.

ok mlarkin@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vector.S,v 1.37 2015/04/19 19:45:21 sf Exp $	*/
a262 1
	movl	$T_ASTFLT,TF_TRAPNO(%rsp)
d264 1
a264 1
	call	_C_LABEL(trap)
d328 1
a328 1
	pushq	$T_ASTFLT
d333 1
a333 1
	pushq	$T_ASTFLT
d412 1
a412 1
	pushq	$T_ASTFLT
d417 1
a417 1
	pushq	$T_ASTFLT
d454 1
a454 2
	subq	$8,%rsp							;\
	pushq	$T_ASTFLT		/* trap # for doing ASTs */	;\
d464 1
a464 1
	pushq	$T_ASTFLT		/* trap # for doing ASTs */	;\
d469 1
a475 1
	incl	_C_LABEL(uvmexp)+V_INTR	/* statistical info */		;\
@


1.37
log
@Add support for x2apic mode

This is currently only enabled on hypervisors because on real hardware, it
requires interrupt remapping which we don't support yet. But on virtualization
it reduces the number of vmexits required per IPI from 4 to 1, causing a
significant speed-up for MP guests.

ok kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vector.S,v 1.36 2015/02/07 00:26:37 deraadt Exp $	*/
d159 1
a159 5
2:	movw	%gs,TF_GS(%rsp)
	movw	%fs,TF_FS(%rsp)
	movw	%es,TF_ES(%rsp)
	movw	%ds,TF_DS(%rsp)
	movq	%r15,TF_R15(%rsp)
@


1.36
log
@Delete non-ELF support, in particular .align 12 (always a bit jarring)
ok miod
@
text
@d1 1
a1 1
/*	$OpenBSD: vector.S,v 1.35 2014/11/23 00:25:05 guenther Exp $	*/
d80 2
d314 14
d340 1
d342 1
d424 1
d426 1
@


1.35
log
@Make sure the direction bit is cleared on entry to the kernel by syscall
or interrupt, as specified by the ABIs.  Our current gcc doesn't assume
this bit of the ABI, but future compilers may and some ASM can be
simplified by assuming it.

in snaps for a bit
@
text
@d1 1
a1 1
/*	$OpenBSD: vector.S,v 1.34 2013/11/02 14:23:38 kettenis Exp $	*/
a309 1
#ifdef __ELF__
a310 3
#else
#define	XINTR(name,num)		_Xintr_##name##num
#endif
@


1.34
log
@Make calltrap global such that gdb can always find it.

ok bluhm@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vector.S,v 1.33 2013/05/12 14:15:31 ratchov Exp $	*/
d125 1
d251 1
d337 1
d419 1
d470 1
@


1.33
log
@Take the kernel lock and call the actual interrupt handler from a
single c function. This will hopefully make easier to stop taking
the kernel lock when running "mp safe" interrupt handlers.

help from ok kettenis
@
text
@d1 1
a1 1
/*	$OpenBSD: vector.S,v 1.32 2012/07/09 16:01:16 deraadt Exp $	*/
d248 1
@


1.32
log
@Remove a useless macro
@
text
@d1 1
a1 1
/*	$OpenBSD: vector.S,v 1.31 2011/06/16 19:46:40 kettenis Exp $	*/
a425 7
#ifdef MULTIPROCESSOR
#define LOCK_KERNEL	movq %rsp, %rdi; call _C_LABEL(x86_intlock)
#define UNLOCK_KERNEL	movq %rsp, %rdi; call _C_LABEL(x86_intunlock)
#else
#define LOCK_KERNEL
#define UNLOCK_KERNEL
#endif
a466 1
	LOCK_KERNEL							;\
d471 2
a472 3
	movq	IH_ARG(%rbx),%rdi					;\
	testq	%rdi, %rdi						;\
	jnz	8f							;\
d474 1
a474 2
8:	movl	%r12d,CPUVAR(ILEVEL)					;\
	call	*IH_FUN(%rbx)		/* call it */			;\
a485 1
	UNLOCK_KERNEL							;\
a491 1
	UNLOCK_KERNEL							;\
@


1.31
log
@Raise the number of interrupt sources per CPU from 32 to 64.  This effectively
triples the number of interrupt vectors that can be handled by the primary
CPU.  Important for MSI, but could also fix some issues with large machines
loaded with a lot of devices.

tested by many; ok deraadt@@, marco@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vector.S,v 1.30 2011/04/19 06:07:03 dlg Exp $	*/
a305 2
#define MY_COUNT _C_LABEL(uvmexp)

d467 1
a467 1
	incl	MY_COUNT+V_INTR		/* statistical info */		;\
@


1.30
log
@use "orl" to test the return value from an interrupt handler not "orq"
since its an int, not a long.

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vector.S,v 1.29 2011/04/16 00:40:56 deraadt Exp $	*/
d340 2
a341 1
	orl	$(1 << LIR_IPI),CPUVAR(IPENDING)
d422 2
a423 1
	orl	$(1 << LIR_TIMER),CPUVAR(IPENDING)
d507 2
a508 1
	orl     $(1 << num),CPUVAR(IPENDING)				;\
d515 2
a516 1
	orl     $(1 << num),CPUVAR(IPENDING)				;\
d599 32
d664 32
d801 64
d932 64
@


1.29
log
@More than a decade ago, interrupt handlers on sparc started returning 0
(interrupt was not for me), 1 (positive interrupt was for me), or -1
(i am not sure...).  We have continued with this practice in as many
drivers as possible, throughout the tree.

This makes some of the architectures use that information in their
interrupt handler calling code -- if 1 is returned (and we know
this specific machine does not have edge-shared interrupts), we
finish servicing other possible handlers on the same pin.  If the
interrupt pin remains asserted (from a different device), we will
end up back in the interrupt servicing code of course... but this is
cheaper than calling all the chained interrupts on a pin.

This does of course count on shared level interrupts being properly
sorted by IPL.

There have been some concerns about starvation of drivers which
incorrectly return 1.  Those drivers should be hunted down so that
they return -1.

ok and help from various people.  In snaps for about a week now.
@
text
@d1 1
a1 1
/*	$OpenBSD: vector.S,v 1.28 2011/04/01 22:51:45 guenther Exp $	*/
d485 1
a485 1
	orq	%rax,%rax		/* should it be counted? */	;\
d490 1
a490 1
	orq	%rax,%rax		/* 1 means stop trying */	;\
@


1.28
log
@Fix comment: amd64's list of callee-saved registers isn't the same as i386
@
text
@d1 1
a1 1
/*	$OpenBSD: vector.S,v 1.27 2010/12/21 14:56:23 claudio Exp $	*/
d486 6
a491 2
	jz	4f							;\
	incq	IH_COUNT(%rbx)						;\
@


1.27
log
@Convert netisr to a normal soft interrupt instead of hanving MD code
for it. This makes the netisr a real C function which will help further
development. No noticable performance change on i386 and amd64.
With input from kettenis@@ and miod@@ additional OKs mikeb@@ and henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vector.S,v 1.26 2010/09/28 03:53:14 guenther Exp $	*/
d298 1
a298 1
 * callee-saved registers %esi, %edi, %ebx, and %ebp twice.
@


1.26
log
@Correct the handling of GS.base when iretq faults: the fault happens
with CPL == 0 but the user's GS.base, so the normal INTRENTRY handling
won't work.  Contrawise, the asm that trap() redirects us to when that
happens (resume_iret) sees a trapframe showing CPL==3 but it's run with
the kernel's GS.base, so INTRENTRY won't work there either.

asm style fixes drahn@@ and mikeb@@
ok kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vector.S,v 1.25 2010/04/05 19:04:32 kettenis Exp $	*/
a80 2
#include <net/netisr.h>

a801 4
	.globl	_C_LABEL(netisr)
_C_LABEL(netisr):
	.word	0

a826 13

	xorq	%r12,%r12
	xchgl	_C_LABEL(netisr),%r12d

	/* XXX Do the legacy netisrs here for now. */
#define DONETISR(s, c) \
	.globl  _C_LABEL(c)	;\
	testl	$(1 << s),%r12d	;\
	jz	1f		;\
	call	_C_LABEL(c)	;\
1:
#include <net/netisr_dispatch.h>
	
@


1.25
log
@Fix indentation.
@
text
@d1 1
a1 1
/*	$OpenBSD: vector.S,v 1.24 2009/11/01 22:13:27 kettenis Exp $	*/
d140 8
d149 31
a179 1
	TRAP(T_PROTFLT)
d228 6
a233 3
 * change %eip to point to one of these labels.  We clean up the stack, if
 * necessary, and resume as if we were handling a general protection fault.
 * This will cause the process to get a SIGBUS.
d236 7
a242 1
	ZTRAP(T_PROTFLT)
@


1.24
log
@Remove bogus #define __HAVE_GENERIC_SOFT_INTERRUPTS.  No code change.
@
text
@d1 1
a1 1
/*	$OpenBSD: vector.S,v 1.23 2009/07/10 13:51:47 jsg Exp $	*/
d413 2
a414 2
	movq	CPUVAR(ISOURCES) + (num) * 8, %r14		;\
	mask(num)		/* mask it in hardware */	;\
@


1.23
log
@Switch away from using -traditional-cpp to iso/ansi cpp for asm files.
More architectures hopefully to follow.
ok kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vector.S,v 1.22 2009/06/09 02:56:38 krw Exp $	*/
a239 3


#define __HAVE_GENERIC_SOFT_INTERRUPTS	/* XXX */
@


1.22
log
@revert guenther@@'s un-revert of art's curpmap.

My

bios0: ASUSTeK Computer INC. P5K-E
cpu0: Intel(R) Core(TM)2 Quad CPU Q6600 @@ 2.40GHz, 2405.74 MHz
cpu1: Intel(R) Core(TM)2 Quad CPU Q6600 @@ 2.40GHz, 2405.46 MHz
cpu2: Intel(R) Core(TM)2 Quad CPU Q6600 @@ 2.40GHz, 2405.46 MHz
cpu3: Intel(R) Core(TM)2 Quad CPU Q6600 @@ 2.40GHz, 2405.46 MHz

can't boot with this in. It always hangs somewhere in fsck'ing if
any, or between netstart and local daemons if no fsck'ing. Also
fubars theo's real amd machine.

Much more testing needed for this.
@
text
@d1 1
a1 1
/*	$OpenBSD: vector.S,v 1.21 2009/06/06 23:45:35 guenther Exp $	*/
d268 1
a268 1
#define	XINTR(name,num)		Xintr_/**/name/**/num
d270 1
a270 1
#define	XINTR(name,num)		_Xintr_/**/name/**/num
d401 1
a401 1
IDTVEC(recurse_/**/name/**/num)						;\
d406 1
a406 1
IDTVEC(resume_/**/name/**/num)						\
d412 1
a412 1
IDTVEC(intr_/**/name/**/num)						;\
@


1.21
log
@Unrevert the curpmap change with the addition of correct %gs handling
in the IPI handler so that it works when it interrupts userspace,
waiting for the droppmap IPI to complete when destroying it, and
(most importantly) don't call pmap_tlb_droppmap() from cpu_exit().
Tested by myself and ckuethe, as our machines choked on the original.

ok @@art
@
text
@d1 1
a1 1
/*	$OpenBSD: vector.S,v 1.19 2009/05/28 09:05:33 art Exp $	*/
a76 1
#include <machine/specialreg.h>
a346 35
	popq	%rax
	iretq

IDTVEC(ipi_reloadcr3)
	pushq	%rax
	pushq	%rcx
	pushq	%rdx
	pushq	%r9

	ioapic_asm_ack()

	movl	$MSR_GSBASE, %ecx
	rdmsr
	movq	$VM_MAXUSER_ADDRESS, %rcx
	shlq	$32, %rdx
	leaq	(%rax,%rdx), %r9
	cmpq	%rcx, %r9
	jb	1f
	swapgs
1:
	movq	CPUVAR(CURPCB), %rax
	movq	PCB_PMAP(%rax), %rax
	movq	%rax, CPUVAR(CURPMAP)
	movq	PM_PDIRPA(%rax), %rax
	movq	%rax, %cr3

	lock
	decq	tlb_shoot_wait

	cmpq	%rcx, %r9
	jb	1f
	swapgs
1:	popq	%r9
	popq	%rdx
	popq	%rcx
@


1.20
log
@Revert the curpmap change.  We know the IPI is broken on both ends,
but even with proposed fixes, the reaper panics are back.
@
text
@d77 1
d348 35
@


1.19
log
@Bring back the curpmap change. It was missing a reload of the pmap on
curcpu when we were freeing a pmap. Tested and working for a few weeks
now, but I was a bit too busy to commit it earlier.
@
text
@d1 1
a1 1
/*	$OpenBSD: vector.S,v 1.17 2009/04/23 07:42:02 art Exp $	*/
a346 17
	popq	%rax
	iretq

IDTVEC(ipi_reloadcr3)
	pushq	%rax

	ioapic_asm_ack()

	movq	CPUVAR(CURPCB), %rax
	movq	PCB_PMAP(%rax), %rax
	movq	%rax, CPUVAR(CURPMAP)
	movq	PM_PDIRPA(%rax), %rax
	movq	%rax, %cr3

	lock
	decq	tlb_shoot_wait

@


1.18
log
@turning pmap_deactivate into a NOP brought back the reaper panics, probably
because the reaper is running on the mappings of pmap from the process it
is about to unmap.  back it out until ht is fixed right; don't let this sit
in the tree waiting for a fix.
@
text
@d1 1
a1 1
/*	$OpenBSD: vector.S,v 1.16 2008/12/06 19:59:38 tedu Exp $	*/
d347 17
@


1.17
log
@Make pmap_deactivate a NOP.

Instead of keeping a bitmask of on which cpu the pmap might be active which
we clear in pmap_deactivate, always keep a pointer to the currently loaded
pmap in cpu_info. We can now optimize a context switch to the kernel pmap
(idle and kernel threads) to keep the previously loaded pmap still loaded
and then reuse that pmap if we context switch back to the same process.

Introduce a new IPI to force a pmap reload before the pmap is destroyed.

Clean up cpu_switchto.

toby@@ ok
@
text
@a349 17
IDTVEC(ipi_reloadcr3)
	pushq	%rax

	ioapic_asm_ack()

	movq	CPUVAR(CURPCB), %rax
	movq	PCB_PMAP(%rax), %rax
	movq	%rax, CPUVAR(CURPMAP)
	movq	PM_PDIRPA(%rax), %rax
	movq	%rax, %cr3

	lock
	decq	tlb_shoot_wait

	popq	%rax
	iretq

@


1.16
log
@revert all changes related to the mpsafe intr handler.  i screwed up the commit
and even then it didn't work.  we have higher standards than this.
@
text
@d1 1
a1 1
/*	$OpenBSD: vector.S,v 1.15 2008/12/06 04:31:24 tedu Exp $	*/
d347 17
@


1.15
log
@mpsafe intr_establish that doesn't get biglock, so that we may dream of the day when this is useful.
mostly macro magic that does nothing.  only actually useful on amd64 for now, compliments of art.
@
text
@d1 1
a1 1
/*	$OpenBSD: vector.S,v 1.14 2008/06/27 06:03:08 ray Exp $	*/
d384 8
d432 1
d450 1
d457 1
@


1.14
log
@More removal of clauses 3 and 4 from NetBSD licenses.

OK deraadt@@ and millert@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vector.S,v 1.13 2008/05/23 15:39:43 jasper Exp $	*/
a383 8
#ifdef MULTIPROCESSOR
#define LOCK_KERNEL	movq %rsp, %rdi; call _C_LABEL(x86_intlock)
#define UNLOCK_KERNEL	movq %rsp, %rdi; call _C_LABEL(x86_intunlock)
#else
#define LOCK_KERNEL
#define UNLOCK_KERNEL
#endif

a423 1
	LOCK_KERNEL							;\
a440 1
	UNLOCK_KERNEL							;\
a446 1
	UNLOCK_KERNEL							;\
@


1.13
log
@- remove USER_LDT, it was never in a state where it would copile, nor will
we support i386-compat mode on amd64.

agreed by beck@@, dlg@@, kettenis@@
ok deraadt@@, tom@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vector.S,v 1.12 2008/05/14 21:53:08 weingart Exp $	*/
a53 7
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *        This product includes software developed by the NetBSD
 *        Foundation, Inc. and its contributors.
 * 4. Neither the name of The NetBSD Foundation nor the names of its
 *    contributors may be used to endorse or promote products derived
 *    from this software without specific prior written permission.
@


1.12
log
@Add a '.text' to make sure we understand IDTVEC()'s are in the text
segment.  kettenis@@ ok.  miod@@ pointed out that the define already
does a '.text', this makes it explicit.
@
text
@d1 1
a1 1
/*	$OpenBSD: vector.S,v 1.11 2008/04/28 18:09:00 kettenis Exp $	*/
a199 4
 *
 * XXXfvdl currently unused, as pop %ds and pop %es are illegal in long
 * mode. However, if the x86-64 port is going to support USER_LDT, we
 * may need something like this after all.
a202 9
#if 0
NENTRY(resume_pop_ds)
	movl	$GSEL(GDATA_SEL, SEL_KPL),%eax
	movl	%eax,%es
NENTRY(resume_pop_es)
	movl	$T_PROTFLT,TF_TRAPNO(%rsp)
	jmp	calltrap
#endif

@


1.11
log
@Rename IPL_SOFTSERIAL to IPL_SOFTTY and rename the associated symbols.
Remove IPL_SERIAL since it is unused.

ok krw@@, weingart@@, deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vector.S,v 1.10 2007/06/01 21:01:51 art Exp $	*/
a776 1

d784 1
@


1.10
log
@Instead of reexporting PAGE_SIZE from assym.h which causes warnings
for locore, just include machine/param.h in vector.S
@
text
@d1 1
a1 1
/*	$OpenBSD: vector.S,v 1.9 2007/05/25 16:22:11 art Exp $	*/
d785 2
a786 2
IDTVEC(softserial)
	movl	$IPL_SOFTSERIAL, CPUVAR(ILEVEL)
d792 2
a793 2
	movq	CPUVAR(ISOURCES) + SIR_SERIAL * 8, %r12
	movl	$X86_SOFTINTR_SOFTSERIAL,%edi
@


1.9
log
@Change the old slow and complicated TLB shootdown code to new, fast and
simple. This is basically the same code as on i386 and basically the same
performance improvements.

This change also includes code to delay the freeing of ptps until they
have been properly shot.

in snaps for a week, no problems reported.
@
text
@d1 1
a1 1
/*	$OpenBSD: vector.S,v 1.8 2007/05/10 17:59:23 deraadt Exp $	*/
d77 1
@


1.8
log
@evcnt & friends were replaced by a proper interrupt counting mechanism 3 years ago; ok miod
@
text
@d1 1
a1 1
/*	$OpenBSD: vector.S,v 1.7 2005/10/09 17:09:34 fgsch Exp $	*/
d320 48
@


1.7
log
@spelling
@
text
@d1 1
a1 1
/*	$OpenBSD: vector.S,v 1.6 2004/12/24 22:50:29 miod Exp $	*/
a396 1
	incq	IS_EVCNT(%r14)						;\
a743 1
	incq	IS_EVCNT(%r12)
a759 1
	incq    IS_EVCNT(%r12)
a788 1
	incq	IS_EVCNT(%r12)
@


1.6
log
@{e,}intr{cnt,names} bye-bye.
@
text
@d1 1
a1 1
/*	$OpenBSD: vector.S,v 1.5 2004/07/10 14:21:40 art Exp $	*/
d367 1
a367 1
 * This macro defines the generic stub code. Its arguments modifiy it
@


1.5
log
@From NetBSD:
date: 2004/06/28 09:13:11;  author: fvdl;  state: Exp;  lines: +6 -5
Updaing ci_ilevel and testing ci_ipending must be done with all interrupts
off, or priority inversion can occur, which can lead to IPI deadlocks.
Leaves interrupts off for a bit longer, sadly, but with no noticeable
effects on the systems I tested on.

From YAMAMOTO Takashi.

Fixes the IPI rendezvous panics for me.
@
text
@d1 1
a1 1
/*	$OpenBSD: vector.S,v 1.4 2004/06/28 01:52:24 deraadt Exp $	*/
a728 12
/*
 * Symbols that vmstat -i wants, even though they're not used.
 */
	.globl	_C_LABEL(intrnames)
_C_LABEL(intrnames):
	.globl	_C_LABEL(eintrnames)
_C_LABEL(eintrnames):

	.globl	_C_LABEL(intrcnt)
_C_LABEL(intrcnt):
	.globl	_C_LABEL(eintrcnt)
_C_LABEL(eintrcnt):
@


1.4
log
@Use new event counter API for interrupt counting on amd64.  Based in part
on some changes in the i386 codebase.
@
text
@d1 2
a2 2
/*	$OpenBSD: vector.S,v 1.3 2004/06/25 17:27:01 andreas Exp $	*/
/*	$NetBSD: vector.S,v 1.2 2003/05/04 23:46:41 fvdl Exp $	*/
a298 2
IDTVEC(resume_lapic_ipi)
	cli
d308 1
a330 2
IDTVEC(resume_lapic_ltimer)
	cli
d340 1
d751 1
d768 1
d798 1
@


1.3
log
@'machine cpuinfo' and 'machine ddbcpu' in ddb for amd64
@
text
@d1 1
a1 1
/*	$OpenBSD: vector.S,v 1.2 2004/06/25 11:03:27 art Exp $	*/
d417 4
a420 1
	movq	IH_NEXT(%rbx),%rbx	/* next handler in chain */	;\
@


1.2
log
@SMP support. Big parts from NetBSD, but with some really serious debugging
done by me, niklas and others. Especially wrt. NXE support.

Still needs some polishing, especially in dmesg messages, but we're now
building kernel faster than ever.
@
text
@d1 1
a1 1
/*	$OpenBSD: vector.S,v 1.1 2004/01/28 01:39:39 mickey Exp $	*/
a321 15
#if defined(DDB)
IDTVEC(intrddb)
1:
	pushq	$0
	pushq	$T_BPTFLT
	INTRENTRY
	movl	$0xf,%eax
	movq	%rax,%cr8
	movl	$0,_C_LABEL(local_apic)+LAPIC_EOI
	sti
	call	_C_LABEL(ddb_ipi)
	xorl	%eax,%eax
	movq	%rax,%cr8
	INTRFASTEXIT
#endif /* DDB */
@


1.1
log
@an amd64 arch support.
hacked by art@@ from netbsd sources and then later debugged
by me into the shape where it can host itself.
no bootloader yet as needs redoing from the
recent advanced i386 sources (anyone? ;)
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d226 1
d237 1
d373 2
a374 2
#define LOCK_KERNEL	call _C_LABEL(x86_intlock)
#define UNLOCK_KERNEL	call _C_LABEL(x86_intunlock)
@

