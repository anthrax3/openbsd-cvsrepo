head	1.39;
access;
symbols
	OPENBSD_6_1:1.39.0.2
	OPENBSD_6_1_BASE:1.39
	OPENBSD_6_0:1.38.0.2
	OPENBSD_6_0_BASE:1.38
	OPENBSD_5_9:1.37.0.2
	OPENBSD_5_9_BASE:1.37
	OPENBSD_5_8:1.36.0.4
	OPENBSD_5_8_BASE:1.36
	OPENBSD_5_7:1.35.0.2
	OPENBSD_5_7_BASE:1.35
	OPENBSD_5_6:1.29.0.4
	OPENBSD_5_6_BASE:1.29
	OPENBSD_5_5:1.27.0.4
	OPENBSD_5_5_BASE:1.27
	OPENBSD_5_4:1.18.0.2
	OPENBSD_5_4_BASE:1.18
	OPENBSD_5_3:1.16.0.2
	OPENBSD_5_3_BASE:1.16
	OPENBSD_5_2:1.12.0.8
	OPENBSD_5_2_BASE:1.12
	OPENBSD_5_1_BASE:1.12
	OPENBSD_5_1:1.12.0.6
	OPENBSD_5_0:1.12.0.4
	OPENBSD_5_0_BASE:1.12
	OPENBSD_4_9:1.12.0.2
	OPENBSD_4_9_BASE:1.12
	OPENBSD_4_8:1.11.0.2
	OPENBSD_4_8_BASE:1.11
	OPENBSD_4_7:1.10.0.2
	OPENBSD_4_7_BASE:1.10
	OPENBSD_4_6:1.3.0.6
	OPENBSD_4_6_BASE:1.3
	OPENBSD_4_5:1.3.0.2
	OPENBSD_4_5_BASE:1.3;
locks; strict;
comment	@# @;


1.39
date	2016.12.19.20.03.15;	author kettenis;	state Exp;
branches;
next	1.38;
commitid	FPreFlAsNawLnJLw;

1.38
date	2016.05.16.01.19.27;	author mlarkin;	state Exp;
branches;
next	1.37;
commitid	ejjZCIi4SS95OnQx;

1.37
date	2015.09.11.14.26.12;	author sf;	state Exp;
branches;
next	1.36;
commitid	9iMoxzsdbKkOGsWf;

1.36
date	2015.06.22.20.06.11;	author bluhm;	state Exp;
branches;
next	1.35;
commitid	w5MkiKeuktj3dXE8;

1.35
date	2014.12.08.07.12.37;	author mlarkin;	state Exp;
branches;
next	1.34;
commitid	9gsjQWzKEbWkbtZI;

1.34
date	2014.12.01.04.33.00;	author mlarkin;	state Exp;
branches;
next	1.33;
commitid	0aHkKi2f0fiKk7oL;

1.33
date	2014.11.30.20.48.51;	author mlarkin;	state Exp;
branches;
next	1.32;
commitid	RD20jZOrzxmW5hqb;

1.32
date	2014.11.30.18.29.11;	author mlarkin;	state Exp;
branches;
next	1.31;
commitid	VxipkLhzoC0bnd0Q;

1.31
date	2014.11.22.18.31.46;	author mlarkin;	state Exp;
branches;
next	1.30;
commitid	OZhulzwbZ5ey9UWV;

1.30
date	2014.10.16.17.37.42;	author mlarkin;	state Exp;
branches;
next	1.29;
commitid	YY6kfXhc3Ht3f3gw;

1.29
date	2014.06.01.00.37.37;	author mlarkin;	state Exp;
branches;
next	1.28;
commitid	upjmIeN2TuoFwYNx;

1.28
date	2014.03.10.05.03.50;	author mlarkin;	state Exp;
branches;
next	1.27;

1.27
date	2014.02.01.07.10.33;	author mlarkin;	state Exp;
branches;
next	1.26;

1.26
date	2014.01.22.03.09.39;	author kettenis;	state Exp;
branches;
next	1.25;

1.25
date	2014.01.16.19.32.26;	author brad;	state Exp;
branches;
next	1.24;

1.24
date	2014.01.10.22.34.41;	author mlarkin;	state Exp;
branches;
next	1.23;

1.23
date	2014.01.05.20.23.56;	author mlarkin;	state Exp;
branches;
next	1.22;

1.22
date	2013.12.26.18.52.09;	author mlarkin;	state Exp;
branches;
next	1.21;

1.21
date	2013.11.02.00.42.16;	author mlarkin;	state Exp;
branches;
next	1.20;

1.20
date	2013.10.18.15.07.58;	author mlarkin;	state Exp;
branches;
next	1.19;

1.19
date	2013.08.03.09.39.29;	author mlarkin;	state Exp;
branches;
next	1.18;

1.18
date	2013.06.04.16.21.23;	author mlarkin;	state Exp;
branches;
next	1.17;

1.17
date	2013.06.01.17.16.51;	author mlarkin;	state Exp;
branches;
next	1.16;

1.16
date	2013.01.17.00.54.48;	author mlarkin;	state Exp;
branches;
next	1.15;

1.15
date	2013.01.17.00.11.24;	author mlarkin;	state Exp;
branches;
next	1.14;

1.14
date	2013.01.16.22.45.40;	author mlarkin;	state Exp;
branches;
next	1.13;

1.13
date	2012.10.19.16.38.30;	author mlarkin;	state Exp;
branches;
next	1.12;

1.12
date	2010.11.18.21.15.13;	author miod;	state Exp;
branches;
next	1.11;

1.11
date	2010.07.01.01.02.31;	author pirofti;	state Exp;
branches;
next	1.10;

1.10
date	2010.02.22.19.44.11;	author kettenis;	state Exp;
branches;
next	1.9;

1.9
date	2009.12.09.16.20.33;	author pirofti;	state Exp;
branches;
next	1.8;

1.8
date	2009.11.30.16.41.04;	author pirofti;	state Exp;
branches;
next	1.7;

1.7
date	2009.11.26.00.14.11;	author mlarkin;	state Exp;
branches;
next	1.6;

1.6
date	2009.11.25.15.41.43;	author pirofti;	state Exp;
branches;
next	1.5;

1.5
date	2009.11.24.17.00.01;	author mlarkin;	state Exp;
branches;
next	1.4;

1.4
date	2009.11.22.22.00.51;	author mlarkin;	state Exp;
branches;
next	1.3;

1.3
date	2009.02.19.21.02.05;	author marco;	state Exp;
branches;
next	1.2;

1.2
date	2009.02.15.02.06.09;	author marco;	state Exp;
branches;
next	1.1;

1.1
date	2009.02.15.02.03.40;	author marco;	state Exp;
branches;
next	;


desc
@@


1.39
log
@Generating mixed 16-bit/32-bit/64-bit code with clang's integrated
assembler is a bit tricky.  It supports the .code16, .code32 and
.code64 directives.  But it doesn't know about the data16/data32 and
addr16/addr32 instruction prefixes.  Instead it tries to determine
those from the instruction opcode.  It mostly succeeds, but there are
a couple of corner cases where clang will generate the "addr32" form
where gas generates the "addr16" form in .code16 segments.  That
should be no problem (and just waste a couple of bytes), but it makes
comparing the generated code a bit difficult.

Allow the trampoline code to be compiled with both.  For clang #define
away the addr32 prefix and avoid using the data32 prefix by using a
mnemonic that explicitly encodes the size of the operand.  Add a few
addr32 prefixes in .code16 blocks to reduce the differences between
code generated by clang and gas.

ok patrick@@, deraadt@@, mlarkin@@
@
text
@/* $OpenBSD: acpi_wakecode.S,v 1.38 2016/05/16 01:19:27 mlarkin Exp $ */
/*
 * Copyright (c) 2001 Takanori Watanabe <takawata@@jp.freebsd.org>
 * Copyright (c) 2001 Mitsuru IWASAKI <iwasaki@@jp.freebsd.org>
 * All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 *
 * THIS SOFTWARE IS PROVIDED BY THE AUTHOR AND CONTRIBUTORS ``AS IS'' AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE
 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
 */
/*
 * Copyright (c) 2008, 2009 Mike Larkin <mlarkin@@openbsd.org>
 *
 * Permission to use, copy, modify, and distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 */

#define _ACPI_WAKECODE

#include "assym.h"
#include <machine/asm.h>
#ifdef HIBERNATE
#include <machine/hibernate_var.h>
#endif /* HIBERNATE */
#include <machine/specialreg.h>
#include <machine/param.h>
#include <machine/segments.h>
#include <dev/acpi/acpivar.h>
#include "lapic.h"

#ifdef __clang__
#define addr32
#endif

#define _ACPI_TRMP_LABEL(a) a = . - _C_LABEL(acpi_real_mode_resume) + \
	ACPI_TRAMPOLINE
#define _ACPI_TRMP_OFFSET(a) a = . - _C_LABEL(acpi_real_mode_resume)
#define _ACPI_TRMP_DATA_LABEL(a) a = . - _C_LABEL(acpi_tramp_data_start) + \
	ACPI_TRAMP_DATA
#define _ACPI_TRMP_DATA_OFFSET(a) a = . - _C_LABEL(acpi_tramp_data_start)
#define _ACPI_RM_CODE_SEG (ACPI_TRAMPOLINE >> 4)
#define _ACPI_RM_DATA_SEG (ACPI_TRAMP_DATA >> 4)

/*
 * On wakeup, we'll start executing at acpi_real_mode_resume.
 * This is based on the wakeup vector previously stored with
 * ACPI before we went to sleep. ACPI's wakeup vector is a
 * physical address - in our case, it's calculated and mapped
 * by the kernel and stuffed into a low page early in the boot
 * process. 
 *
 * We wakeup in real mode, at some phys addr based on the ACPI
 * specification (cs = phys>>8, ip = phys & 0xF). For example,
 * if our phys addr is 0x13000, we'd have cs=0x1300,ip=0
 *
 * The wakeup code needs to do the following:
 *     1. Reenable the video display
 *     2. Enter 32 bit protected mode
 *     3. Reenable paging
 *     4. Enter long mode
 *     5. Restore saved CPU registers
 */
	.text
	.code16
	.align 4, 0xcc
	.global _C_LABEL(acpi_real_mode_resume)
	.global _C_LABEL(acpi_protected_mode_resume)
	.global _C_LABEL(acpi_long_mode_resume)
	.global _C_LABEL(acpi_resume_end)
	.global _C_LABEL(acpi_pdirpa)
	.global _C_LABEL(acpi_tramp_data_start)
	.global _C_LABEL(acpi_tramp_data_end)
_C_LABEL(acpi_real_mode_resume):
_ACPI_TRMP_OFFSET(acpi_s3_vector_real)
	nop
	cli
	cld

	/*
	 * Set up segment registers for real mode. 
	 * We'll only be in real mode for a moment, and we don't have
	 * ant real dependencies on data or stack, so we'll just use
	 * the code segment for data and stack (eg, a 64k memory space).
	 */
	movw	$(_ACPI_RM_DATA_SEG), %ax
	movw	%ax, %ds
	movw	%ax, %ss
	movw	%cs, %ax
	movw	%ax, %es
	addr32 lidtl	clean_idt

	/*
	 * Set up stack to grow down from offset 0x0FFE.
	 * We will only be doing a few push/pops and no calls in real 
	 * mode, so as long as the real mode code in the segment 
	 * plus stack doesn't exceed 0x0FFE (4094) bytes, we'll be ok.
	 */
	movw	$0x0FFE,%sp

	/*
	 * Clear flags
	 */
	pushl	$0
	popfl

	/*
	 * Flush instruction prefetch queue
	 */
	jmp     1f
1:	jmp     1f
1:

	/*
	 * We're about to enter protected mode, so we need a GDT for that.
	 * Set up a temporary GDT describing 2 segments, one for code
	 * extending from 0x00000000-0xffffffff and one for data
	 * with the same range. This GDT will only be in use for a short
	 * time, until we restore the saved GDT that we had when we went
	 * to sleep.
	 */ 
	addr32 lgdtl	tmp_gdt

	/*
	 * Enable protected mode by setting the PE bit in CR0
	 */
	mov	%cr0,%eax
	orl	$(CR0_PE),%eax
	mov	%eax,%cr0

	/*
	 * Force CPU into protected mode by making an intersegment jump (to
	 * ourselves, just a few lines down from here). We rely on the kernel
	 * to fixup the jump target addres previously. 
	 */
	ljmpl	$0x8, $acpi_protected_mode_trampoline

	.code32
	.align 16, 0xcc
_ACPI_TRMP_LABEL(acpi_protected_mode_trampoline)
_C_LABEL(acpi_protected_mode_resume):
	nop

	/*
	 * We're in protected mode now, without paging enabled.
	 *
	 * Set up segment selectors for protected mode.
	 * We've already set up our cs via the intersegment jump earlier,
	 * but we need to set ds,es,fs,gs,ss to all point to the 
	 * 4GB flat data segment we defined earlier.
	 */
	movw	$GSEL(GDATA_SEL,SEL_KPL),%ax
	movw	%ax,%ds
	movw	%ax,%es
	movw	%ax,%gs
	movw	%ax,%ss
	movw	%ax,%fs

	/*
	 * Reset ESP based on protected mode. We can do this here
	 * because we haven't put anything on the stack via a
	 * call or push that we haven't cleaned up already.
	 */
	addl    $(ACPI_TRAMP_DATA), %esp

	/* Set CR4 to something sane for entry into long mode */
	mov	$(CR4_PAE|CR4_OSFXSR|CR4_OSXMMEXCPT|CR4_PSE),%eax
	mov	%eax,%cr4

	/*
	 * Set up a temporary long mode GDT describing 2
	 * segments, one for code and one for data.
	 */
	lgdt 	tmp_gdt64	

	/* Restore saved EFER (LME, NXE, etc) */
	movl	$MSR_EFER, %ecx
	rdmsr
	movl	acpi_saved_efer, %eax
	andl 	$(EFER_LME | EFER_NXE | EFER_SCE), %eax	
	wrmsr

	/* Reenable paging using temporary cr3 */
	movl	$acpi_pdirpa, %eax
	movl	(%eax), %eax
	movl	%eax, %cr3

	/* Flush the prefetch queue again */
	jmp 	1f
1:	jmp	1f
1:

	/* Reenable paging by setting the appropriate bits in CR0 */
	movl    %cr0,%eax
	orl     $(CR0_PE|CR0_PG|CR0_NE|CR0_TS|CR0_MP|CR0_WP),%eax
	movl    %eax,%cr0

	/* Flush the prefetch queue again */
	jmp 	1f
1:	jmp	1f
1:

	/* Enter long mode by making another intersegment jump */
	ljmp 	$0x8, $acpi_long_mode_trampoline

	.code64
	.align 16, 0xcc
_ACPI_TRMP_LABEL(acpi_long_mode_trampoline)
_C_LABEL(acpi_long_mode_resume):

	/* Reset stack */
	movq	$(ACPI_TRAMP_DATA + 0x0FF8), %rsp

	/* Load GDT based on our saved copy */
	lgdt	acpi_saved_gdt

	/* Reset segment registers */
	movw    $GSEL(GDATA_SEL, SEL_KPL),%ax
	movw    %ax,%ds
	movw    %ax,%es
	movw    %ax,%ss

	xorw	%ax, %ax
	movw	%ax, %fs
	movw	%ax, %gs

	/* Restore registers - start with the MSRs */
#if NLAPIC > 0
	movl	$MSR_APICBASE, %ecx
	movl	acpi_saved_apicbase, %eax
	movl	acpi_saved_apicbase+4, %edx
	wrmsr
#endif

	movl	$MSR_STAR, %ecx
	movl	acpi_saved_star, %eax
	movl	acpi_saved_star+4, %edx
	wrmsr

	movl	$MSR_LSTAR, %ecx
	movl	acpi_saved_lstar, %eax
	movl	acpi_saved_lstar+4, %edx
	wrmsr

	movl	$MSR_CSTAR, %ecx
	movl	acpi_saved_cstar, %eax
	movl	acpi_saved_cstar+4, %edx
	wrmsr

	movl	$MSR_SFMASK, %ecx
	movl	acpi_saved_sfmask, %eax
	movl	acpi_saved_sfmask+4, %edx
	wrmsr

	movl	$MSR_FSBASE, %ecx
	movl	acpi_saved_fsbase, %eax
	movl	acpi_saved_fsbase+4, %edx
	wrmsr

	movl	$MSR_GSBASE, %ecx
	movl	acpi_saved_gsbase, %eax
	movl	acpi_saved_gsbase+4, %edx
	wrmsr

	movl	$MSR_KERNELGSBASE, %ecx
	movl	acpi_saved_kgs, %eax
	movl	acpi_saved_kgs+4, %edx
	wrmsr

	/* Restore control registers */
	movq	acpi_saved_cr8, %rax
	movq	%rax, %cr8
	movq	acpi_saved_cr4, %rax
	movq	%rax, %cr4
	movq	acpi_saved_cr3, %rax
	movq	%rax, %cr3

	/* Flush the prefetch queue again */
	jmp 	1f
1:	jmp	1f
1:

	movq	acpi_saved_cr2, %rax
	movq	%rax, %cr2
	movq	acpi_saved_cr0,	%rax
	movq	%rax, %cr0

	/* Flush the prefetch queue again */
	jmp 	1f
1:	jmp	1f
1:
	
	lldt	acpi_saved_ldt
	lidt	acpi_saved_idt

	/* Restore the saved task register */
	xorq	%rcx, %rcx
	movw	acpi_saved_tr, %cx
	movq	acpi_saved_gdt+2, %rax
	andb	$0xF9, 5(%rax,%rcx)
	ltr	%cx

	pushq 	acpi_saved_fl
	popfq

	movq    acpi_saved_rbx, %rbx
	movq    acpi_saved_rcx, %rcx
	movq    acpi_saved_rdx, %rdx
	movq    acpi_saved_rbp, %rbp
	movq    acpi_saved_rsi, %rsi
	movq    acpi_saved_rdi, %rdi
	movq    acpi_saved_rsp, %rsp

	movq    acpi_saved_r8, %r8
	movq    acpi_saved_r9, %r9
	movq    acpi_saved_r10, %r10
	movq    acpi_saved_r11, %r11
	movq    acpi_saved_r12, %r12
	movq    acpi_saved_r13, %r13
	movq    acpi_saved_r14, %r14
	movq    acpi_saved_r15, %r15

	/* Poke CR3 one more time. Might not be necessary */	
	movq	acpi_saved_cr3, %rax
	movq	%rax, %cr3

	xorq	%rax, %rax	
	jmp   	*acpi_saved_ret

#ifdef HIBERNATE
	/*
	 * hibernate_resume_machdep drops to real mode and
	 * restarts the OS using the saved S3 resume vector
	 */
	.code64
NENTRY(hibernate_resume_machdep)
	cli
	/* Jump to the identity mapped version of ourself */
	mov	$hibernate_resume_vector_2, %rax
	jmp	*%rax
_ACPI_TRMP_LABEL(hibernate_resume_vector_2)

	/* Get out of 64 bit CS */
	lgdtq	tmp_gdt6416

	/* Jump out of 64 bit mode, to hibernate_resume_vector_3 below */
	ljmp	*(hibernate_indirect_16)

_ACPI_TRMP_OFFSET(hibernate_resume_vector_3)
	.code16

	movl	%cr0, %eax
	/* Disable CR0.PG - no paging */
	andl	$(~CR0_PG), %eax
	/* Disable CR0.PE - real mode */
	andl	$(~CR0_PE), %eax
	movl	%eax, %cr0

	/* Set up real mode segment selectors */
	movw	$(_ACPI_RM_DATA_SEG), %ax
	movw	%ax, %ds
	movw	%ax, %ss
	movw	%ax, %es
	movw	%ax, %fs
	movw	%ax, %gs
	movl	$0x0FFE, %esp
	addr32 lidtl	clean_idt

	/* Jump to the S3 resume vector */
	ljmp	$(_ACPI_RM_CODE_SEG), $acpi_s3_vector_real

NENTRY(hibernate_drop_to_real_mode)
	.code64
	cli
	/* Jump to the identity mapped version of ourself */
	mov	$hibernate_resume_vector_2b, %rax
	jmp	*%rax
_ACPI_TRMP_LABEL(hibernate_resume_vector_2b)

	/* Get out of 64 bit CS */
	lgdtq	tmp_gdt6416

	/* Jump out of 64 bit mode, to hibernate_resume_vector_3b below */
	ljmp	*(hibernate_indirect_16b)

_ACPI_TRMP_OFFSET(hibernate_resume_vector_3b)
	.code16

	movl	%cr0, %eax
	/* Disable CR0.PG - no paging */
	andl	$(~CR0_PG), %eax
	/* Disable CR0.PE - real mode */
	andl	$(~CR0_PE), %eax
	movl	%eax, %cr0

	/* Set up real mode segment selectors */
	movw	$(_ACPI_RM_DATA_SEG), %ax
	movw	%ax, %ds
	movw	%ax, %es
	movw	%ax, %fs
	movw	%ax, %gs
	movw	%ax, %ss
	movl	$0x0FFE, %esp
	addr32 lidtl	clean_idt

_ACPI_TRMP_OFFSET(hib_hlt_real)
	hlt
	ljmp	$(_ACPI_RM_CODE_SEG), $hib_hlt_real

	.code64
	/* Switch to hibernate resume pagetable */
NENTRY(hibernate_activate_resume_pt_machdep)
	/* Enable large pages */
	movq	%cr4, %rax
	orq	$(CR4_PSE), %rax

	/* Disable global pages */
	andq	$(~CR4_PGE), %rax
	movq	%rax, %cr4

	wbinvd
	movq	$HIBERNATE_PML4T, %rax
	movq	%rax,	%cr3
	jmp	1f

1:	nop
	ret

	/*
	 * Switch to the private resume-time hibernate stack
	 */
NENTRY(hibernate_switch_stack_machdep)
	movq	(%rsp), %rax
	movq    %rax, HIBERNATE_STACK_PAGE + HIBERNATE_STACK_OFFSET
	movq    $(HIBERNATE_STACK_PAGE + HIBERNATE_STACK_OFFSET), %rax
	movq    %rax, %rsp

	/* On our own stack from here onward */
	ret

NENTRY(hibernate_flush)
	invlpg	HIBERNATE_INFLATE_PAGE
	ret
#endif /* HIBERNATE */

	/*
	 * End of resume code (code copied to ACPI_TRAMPOLINE)
	 */
_C_LABEL(acpi_resume_end):

	/*
	 * Initial copy of this data gets placed in .rodata, kernel makes
	 * RW copy of it in the tramp data page.
	 */
	.section .rodata
_C_LABEL(acpi_tramp_data_start):
_ACPI_TRMP_DATA_OFFSET(tmp_gdt)
	.word	tmp_gdt_end - tmp_gdtable
	.long	tmp_gdtable

	.align 8, 0xcc
_ACPI_TRMP_DATA_LABEL(tmp_gdtable)
	/*
	 * null
	 */
	.word	0, 0
	.byte	0, 0, 0, 0
	/*
	 * Code
	 * Limit: 0xffffffff
	 * Base: 0x00000000
	 * Descriptor Type: Code
	 * Segment Type: CRA 
	 * Present: True
	 * Priv: 0
	 * AVL: False
	 * 64-bit: False
	 * 32-bit: True
	 *
	 */ 
	.word	0xffff, 0
	.byte	0, 0x9f, 0xcf, 0

	/*
	 * Data
	 * Limit: 0xffffffff
	 * Base: 0x00000000
	 * Descriptor Type: 
	 * Segment Type: W
	 * Present: True
	 * Priv: 0
	 * AVL: False
	 * 64-bit: False
	 * 32-bit: True
	 *
	 */ 
	.word	0xffff, 0
	.byte	0, 0x93, 0xcf, 0
_ACPI_TRMP_DATA_LABEL(tmp_gdt_end)

	.align 8, 0xcc
_ACPI_TRMP_DATA_OFFSET(clean_idt)
	.word	0xffff
	.long	0
	.word	0

	.align 8, 0xcc
_ACPI_TRMP_DATA_LABEL(tmp_gdt64)
	.word 	tmp_gdt64_end - tmp_gdtable64
	.long	tmp_gdtable64

	.align 8, 0xcc
_ACPI_TRMP_DATA_LABEL(tmp_gdtable64)
	.quad	0x0000000000000000
	.quad	0x00af9a000000ffff
	.quad	0x00cf92000000ffff
_ACPI_TRMP_DATA_LABEL(tmp_gdt64_end)

	.align 8, 0xcc
_ACPI_TRMP_DATA_LABEL(tmp_gdt6416)
	.word 	tmp_gdt6416_end - tmp_gdtable6416
	.quad	tmp_gdtable6416

	.align 8, 0xcc
_ACPI_TRMP_DATA_LABEL(tmp_gdtable6416)
	.quad	0x0000000000000000
	.quad	0x00af9a000000ffff
	.quad	0x00cf92000000ffff
	.word	0x0fff, (ACPI_TRAMPOLINE % 0x10000)
	.byte	(ACPI_TRAMPOLINE >> 16), 0x9a, 0, 0
_ACPI_TRMP_DATA_LABEL(tmp_gdt6416_end)

	.align 8, 0xcc
_ACPI_TRMP_DATA_LABEL(acpi_saved_rbx)
	.quad 0
_ACPI_TRMP_DATA_LABEL(acpi_saved_rcx)
	.quad 0
_ACPI_TRMP_DATA_LABEL(acpi_saved_rdx)
	.quad 0
_ACPI_TRMP_DATA_LABEL(acpi_saved_rbp)
	.quad 0
_ACPI_TRMP_DATA_LABEL(acpi_saved_rsi)
	.quad 0
_ACPI_TRMP_DATA_LABEL(acpi_saved_rdi)
	.quad 0
_ACPI_TRMP_DATA_LABEL(acpi_saved_rsp)
	.quad 0
_ACPI_TRMP_DATA_LABEL(acpi_saved_r8)
	.quad 0
_ACPI_TRMP_DATA_LABEL(acpi_saved_r9)
	.quad 0
_ACPI_TRMP_DATA_LABEL(acpi_saved_r10)
	.quad 0
_ACPI_TRMP_DATA_LABEL(acpi_saved_r11)
	.quad 0
_ACPI_TRMP_DATA_LABEL(acpi_saved_r12)
	.quad 0
_ACPI_TRMP_DATA_LABEL(acpi_saved_r13)
	.quad 0
_ACPI_TRMP_DATA_LABEL(acpi_saved_r14)
	.quad 0
_ACPI_TRMP_DATA_LABEL(acpi_saved_r15)
	.quad 0
_ACPI_TRMP_DATA_LABEL(acpi_saved_fl)
	.quad 0
_ACPI_TRMP_DATA_LABEL(acpi_saved_cr0)
	.quad 0
_ACPI_TRMP_DATA_LABEL(acpi_saved_cr2)
	.quad 0
_ACPI_TRMP_DATA_LABEL(acpi_saved_cr3)
	.quad 0
_ACPI_TRMP_DATA_LABEL(acpi_saved_cr4)
	.quad 0
_ACPI_TRMP_DATA_LABEL(acpi_saved_cr8)
	.quad 0
_ACPI_TRMP_DATA_LABEL(acpi_saved_ret)
	.quad 0

	.align 8, 0xcc
_ACPI_TRMP_DATA_LABEL(acpi_saved_idt)
	.space 10

	.align 8, 0xcc
_ACPI_TRMP_DATA_LABEL(acpi_saved_gdt)
	.space 10

	.align 8, 0xcc
_ACPI_TRMP_DATA_LABEL(acpi_saved_ldt)	
	.space 10
	
_ACPI_TRMP_DATA_LABEL(acpi_saved_tr)
	.short 0

	.align 4, 0xcc
_ACPI_TRMP_DATA_LABEL(acpi_saved_efer)
	.long 0

	.align 8, 0xcc
_ACPI_TRMP_DATA_LABEL(acpi_saved_fsbase)
	.quad 0
_ACPI_TRMP_DATA_LABEL(acpi_saved_gsbase)
	.quad 0
_ACPI_TRMP_DATA_LABEL(acpi_saved_kgs)
	.quad 0
_ACPI_TRMP_DATA_LABEL(acpi_saved_star)
	.quad 0
_ACPI_TRMP_DATA_LABEL(acpi_saved_lstar)
	.quad 0
_ACPI_TRMP_DATA_LABEL(acpi_saved_cstar)
	.quad 0
_ACPI_TRMP_DATA_LABEL(acpi_saved_sfmask)
	.quad 0
#if NLAPIC > 0
_ACPI_TRMP_DATA_LABEL(acpi_saved_apicbase)
	.quad 0
#endif

	.align 4, 0xcc
_ACPI_TRMP_DATA_LABEL(acpi_pdirpa)
	.long 0
#ifdef HIBERNATE
_ACPI_TRMP_DATA_LABEL(hibernate_indirect_16)
	.long	hibernate_resume_vector_3
	.word	0x18
_ACPI_TRMP_DATA_LABEL(hibernate_indirect_16b)
	.long	hibernate_resume_vector_3b
	.word	0x18
#endif /* HIBERNATE */

_C_LABEL(acpi_tramp_data_end):

	/*
	 * acpi_savecpu saves the processor's registers and flags
	 * for use during the ACPI suspend/resume process.
	 */

	.code64
NENTRY(acpi_savecpu)
	movq	(%rsp), %rax
	movq	%rax, acpi_saved_ret

	movq	%rbx, acpi_saved_rbx
	movq	%rcx, acpi_saved_rcx
	movq	%rdx, acpi_saved_rdx
	movq	%rbp, acpi_saved_rbp
	movq	%rsi, acpi_saved_rsi
	movq	%rdi, acpi_saved_rdi
	movq	%rsp, acpi_saved_rsp
	addq	$0x8, acpi_saved_rsp

	movq	%r8, acpi_saved_r8
	movq	%r9, acpi_saved_r9
	movq	%r10, acpi_saved_r10
	movq	%r11, acpi_saved_r11
	movq	%r12, acpi_saved_r12
	movq	%r13, acpi_saved_r13
	movq	%r14, acpi_saved_r14
	movq	%r15, acpi_saved_r15

	pushfq
	popq	acpi_saved_fl

	movq	%cr0, %rax
	movq	%rax, acpi_saved_cr0
	movq	%cr2, %rax
	movq	%rax, acpi_saved_cr2
	movq	%cr3, %rax
	movq	%rax, acpi_saved_cr3
	movq	%cr4, %rax
	movq	%rax, acpi_saved_cr4
	movq	%cr8, %rax
	movq	%rax, acpi_saved_cr8
	
	pushq	%rcx
	pushq	%rdx
#if NLAPIC > 0
	movl	$MSR_APICBASE, %ecx
	rdmsr
	movl	%eax, acpi_saved_apicbase
	movl	%edx, acpi_saved_apicbase+4
#endif

	movl	$MSR_STAR, %ecx
	rdmsr
	movl	%eax, acpi_saved_star
	movl	%edx, acpi_saved_star+4

	movl	$MSR_CSTAR, %ecx
	rdmsr
	movl	%eax, acpi_saved_cstar
	movl	%edx, acpi_saved_cstar+4

	movl	$MSR_LSTAR, %ecx
	rdmsr
	movl	%eax, acpi_saved_lstar
	movl	%edx, acpi_saved_lstar+4

	movl	$MSR_SFMASK, %ecx
	rdmsr
	movl	%eax, acpi_saved_sfmask
	movl	%edx, acpi_saved_sfmask+4

	movl	$MSR_FSBASE, %ecx
	rdmsr
	movl	%eax, acpi_saved_fsbase
	movl	%edx, acpi_saved_fsbase+4

	movl	$MSR_GSBASE, %ecx
	rdmsr
	movl	%eax, acpi_saved_gsbase
	movl	%edx, acpi_saved_gsbase+4

	movl	$MSR_KERNELGSBASE, %ecx
	rdmsr
	movl	%eax, acpi_saved_kgs
	movl	%edx, acpi_saved_kgs+4
	
	movl	$MSR_EFER, %ecx
	rdmsr
	movl	%eax, acpi_saved_efer
	popq 	%rdx
	popq	%rcx

	sgdt	acpi_saved_gdt
	sidt	acpi_saved_idt
	sldt	acpi_saved_ldt
	str	acpi_saved_tr

	movl	$1, %eax
	ret
@


1.38
log
@
Use int3 padding instead of nop in the ACPI resume trampoline, as it is
certain no intentional nop sled is required here.

ok deraadt@@
@
text
@d1 1
a1 1
/* $OpenBSD: acpi_wakecode.S,v 1.37 2015/09/11 14:26:12 sf Exp $ */
d57 4
d116 1
a116 1
	lidtl	clean_idt
d147 1
a147 1
	data32 addr32 lgdt	tmp_gdt
d392 1
a392 1
	lidtl	clean_idt
d429 1
a429 1
	lidtl	clean_idt
@


1.37
log
@Save/restore MSR_APICBASE during suspend/resume

This register contains the x2apic enable bit. Restoring it re-enables x2apic on
the application processors at resume.  On the boot processor, the normal
initialization code path is used.

Tested by many

OK mlarkin@@
"Go for it" deraadt@@
@
text
@d1 1
a1 1
/* $OpenBSD: acpi_wakecode.S,v 1.36 2015/06/22 20:06:11 bluhm Exp $ */
d87 1
a87 1
	.align 4
d160 1
a160 1
	.align 16
d228 1
a228 1
	.align 16
d482 1
a482 1
	.align 8
d522 1
a522 1
	.align 8
d528 1
a528 1
	.align 8
d533 1
a533 1
	.align 8
d540 1
a540 1
	.align 8
d545 1
a545 1
	.align 8
d554 1
a554 1
	.align 8
d600 1
a600 1
	.align 8
d604 1
a604 1
	.align 8
d608 1
a608 1
	.align 8
d615 1
a615 1
	.align 4
d619 1
a619 1
	.align 8
d639 1
a639 1
	.align 4
@


1.36
log
@Add an #ifdef HIBERNATE to allow to build a kernel without hibernate but
with acpi.
OK mlarkin@@
@
text
@d1 1
a1 1
/* $OpenBSD: acpi_wakecode.S,v 1.35 2014/12/08 07:12:37 mlarkin Exp $ */
d55 1
d249 7
d634 4
d697 7
@


1.35
log
@
Split the ACPI resume trampoline into code and data, move the data page to
.rodata (kernel copies to the RW page), protect the code page with RX
permissions, protect the code page with RW permissions.

ok deraadt@@
@
text
@d1 1
a1 1
/* $OpenBSD: acpi_wakecode.S,v 1.34 2014/12/01 04:33:00 mlarkin Exp $ */
d630 1
d637 1
@


1.34
log
@
Remove an unused gdt structure definition.
@
text
@d1 1
a1 1
/* $OpenBSD: acpi_wakecode.S,v 1.33 2014/11/30 20:48:51 mlarkin Exp $ */
d56 2
a57 1
#define _ACPI_TRMP_LABEL(a) a = . - _C_LABEL(acpi_real_mode_resume) + ACPI_TRAMPOLINE
d59 5
a63 1
#define _ACPI_RM_SEGMENT (ACPI_TRAMPOLINE >> 4)
a83 1

d92 2
d106 5
a110 4
	movw	%cs,%ax
	movw	%ax,%ds
	movw	%ax,%es
	movw	%ax,%ss
a127 7
	 * Set up esi to point to start of current routine's CS.
	 */
	xorl    %esi,%esi
	movw    %cs,%si
	shll    $4,%esi

	/*
d140 1
a140 2
	 * to sleep (although on i386, the saved GDT will most likely
	 * represent something similar based on machine/segment.h).
d152 3
a154 5
	 * Force CPU into protected mode 
	 * by making an intersegment jump (to ourselves, just a few lines
	 * down from here. We rely on the kernel to fixup the jump
	 * target addres previously. 
	 *
d184 1
a184 2
	movl    %esi, %esp
	addl    $0x0FFE, %esp
d212 1
d231 3
d295 1
d359 1
a360 3
_ACPI_TRMP_LABEL(hibernate_indirect_16)
	.long	hibernate_resume_vector_3
	.word	0x18
d373 1
a373 1
	movw	$(ACPI_TRAMPOLINE >> 4), %ax
d375 1
d383 1
a383 1
	ljmp	$(ACPI_TRAMPOLINE >> 4), $acpi_s3_vector_real
d396 1
a397 3
_ACPI_TRMP_LABEL(hibernate_indirect_16b)
	.long	hibernate_resume_vector_3b
	.word	0x18
d410 1
a410 1
	movw	$(ACPI_TRAMPOLINE >> 4), %ax
d415 1
a418 2
	ljmp	$(ACPI_TRAMPOLINE >> 4), $hib_hlt_real

d421 1
a421 1
	ljmp 	$(ACPI_TRAMPOLINE >> 4), $hib_hlt_real
d459 12
a470 2
	.align 8
_ACPI_TRMP_OFFSET(tmp_gdt)
d475 1
a475 1
_ACPI_TRMP_LABEL(tmp_gdtable)
d512 1
a512 1
_ACPI_TRMP_LABEL(tmp_gdt_end)
d515 1
a515 1
_ACPI_TRMP_OFFSET(clean_idt)
d521 1
a521 1
_ACPI_TRMP_LABEL(tmp_gdt64)
d526 1
a526 1
_ACPI_TRMP_LABEL(tmp_gdtable64)
d530 1
a530 1
_ACPI_TRMP_LABEL(tmp_gdt64_end)
d533 1
a533 1
_ACPI_TRMP_LABEL(tmp_gdt6416)
d538 1
a538 1
_ACPI_TRMP_LABEL(tmp_gdtable6416)
d544 1
a544 1
_ACPI_TRMP_LABEL(tmp_gdt6416_end)
d547 1
a547 1
_ACPI_TRMP_LABEL(acpi_saved_rbx)
d549 1
a549 1
_ACPI_TRMP_LABEL(acpi_saved_rcx)
d551 1
a551 1
_ACPI_TRMP_LABEL(acpi_saved_rdx)
d553 1
a553 1
_ACPI_TRMP_LABEL(acpi_saved_rbp)
d555 1
a555 1
_ACPI_TRMP_LABEL(acpi_saved_rsi)
d557 1
a557 1
_ACPI_TRMP_LABEL(acpi_saved_rdi)
d559 1
a559 1
_ACPI_TRMP_LABEL(acpi_saved_rsp)
d561 1
a561 1
_ACPI_TRMP_LABEL(acpi_saved_r8)
d563 1
a563 1
_ACPI_TRMP_LABEL(acpi_saved_r9)
d565 1
a565 1
_ACPI_TRMP_LABEL(acpi_saved_r10)
d567 1
a567 1
_ACPI_TRMP_LABEL(acpi_saved_r11)
d569 1
a569 1
_ACPI_TRMP_LABEL(acpi_saved_r12)
d571 1
a571 1
_ACPI_TRMP_LABEL(acpi_saved_r13)
d573 1
a573 1
_ACPI_TRMP_LABEL(acpi_saved_r14)
d575 1
a575 1
_ACPI_TRMP_LABEL(acpi_saved_r15)
d577 1
a577 1
_ACPI_TRMP_LABEL(acpi_saved_fl)
d579 1
a579 1
_ACPI_TRMP_LABEL(acpi_saved_cr0)
d581 1
a581 1
_ACPI_TRMP_LABEL(acpi_saved_cr2)
d583 1
a583 1
_ACPI_TRMP_LABEL(acpi_saved_cr3)
d585 1
a585 1
_ACPI_TRMP_LABEL(acpi_saved_cr4)
d587 1
a587 1
_ACPI_TRMP_LABEL(acpi_saved_cr8)
d589 1
a589 1
_ACPI_TRMP_LABEL(acpi_saved_ret)
d593 1
a593 1
_ACPI_TRMP_LABEL(acpi_saved_idt)
d597 1
a597 1
_ACPI_TRMP_LABEL(acpi_saved_gdt)
d601 1
a601 1
_ACPI_TRMP_LABEL(acpi_saved_ldt)	
d604 1
a604 1
_ACPI_TRMP_LABEL(acpi_saved_tr)
d608 1
a608 1
_ACPI_TRMP_LABEL(acpi_saved_efer)
d612 1
a612 1
_ACPI_TRMP_LABEL(acpi_saved_fsbase)
d614 1
a614 1
_ACPI_TRMP_LABEL(acpi_saved_gsbase)
d616 1
a616 1
_ACPI_TRMP_LABEL(acpi_saved_kgs)
d618 1
a618 1
_ACPI_TRMP_LABEL(acpi_saved_star)
d620 1
a620 1
_ACPI_TRMP_LABEL(acpi_saved_lstar)
d622 1
a622 1
_ACPI_TRMP_LABEL(acpi_saved_cstar)
d624 1
a624 1
_ACPI_TRMP_LABEL(acpi_saved_sfmask)
d628 1
a628 1
_ACPI_TRMP_LABEL(acpi_pdirpa)
d630 6
d637 1
a637 4
	/*
	 * End of resume code (code copied to ACPI_TRAMPOLINE)
	 */
_C_LABEL(acpi_resume_end):
@


1.33
log
@
Unbreak zzz/ZZZ resume - ensure NX is re-enabled on resume (if enabled).
Also transformed some complicated code that was setting EFER into something
much simpler.

Tested on a variety of real machines, emulators/VMs, MP, UP, zzz, ZZZ,
NX on, NX off ...

ok deraadt@@
@
text
@d1 1
a1 1
/* $OpenBSD: acpi_wakecode.S,v 1.32 2014/11/30 18:29:11 mlarkin Exp $ */
a511 50

	/*
	 * gdt_16 is the gdt used when returning to real mode for bios
	 * reads/writes (sets up a 16 bit segment)
	 */
	.align 8
_ACPI_TRMP_LABEL(gdt_16)
	.word   gdt_16_end - gdt_16_table
	.long   gdt_16_table

	.align 8
_ACPI_TRMP_LABEL(gdt_16_table)
	/*
	 * null
	 */
	.word   0, 0
	.byte   0, 0, 0, 0
	/*
	 * Code
	 * Limit: 0xffffffff
	 * Base: 0x00000000
	 * Descriptor Type: Code
	 * Segment Type: CRA
	 * Present: True
	 * Priv: 0
	 * AVL: False
	 * 64-bit: False
	 * 32-bit: False
	 *
	 */
	.word   0xffff, 0
	.byte   0, 0x9f, 0x8f, 0

	/*
	 * Data
	 * Limit: 0xffffffff
	 * Base: 0x00000000
	 * Descriptor Type:
	 * Segment Type: W
	 * Present: True
	 * Priv: 0
	 * AVL: False
	 * 64-bit: False
	 * 32-bit: False
	 *
	 */
	.word   0xffff, 0
	.byte   0, 0x93, 0x8f, 0

_ACPI_TRMP_LABEL(gdt_16_end)
@


1.32
log
@
Mask out EFER_LMA when restoring saved EFER on zzz/ZZZ resume as it's a
read only bit.

Also fix some comments describing EFER bits that were obviously wrong.

ok deraadt@@
@
text
@d1 1
a1 1
/* $OpenBSD: acpi_wakecode.S,v 1.31 2014/11/22 18:31:46 mlarkin Exp $ */
a194 9
	 * Stash away our previously saved EFER in EBX.
	 * We have to make sure we don't write to any
	 * of the EFER reserved bits, so we zero those
	 * out here.
	 */
	movl	acpi_saved_efer, %ebx
	andl 	$(EFER_LME | EFER_NXE | EFER_SCE), %ebx	

	/*
d200 1
a200 1
	/* Prepare to enter long mode by enabling LME in EFER */
d203 2
a204 1
	orl	$EFER_LME, %eax
a232 4
	/* Restore the stashed copy of EFER we set aside earlier */	
	movl	%ebx, %eax
	movl	$MSR_EFER, %ecx
	wrmsr
d236 1
a236 1
	
@


1.31
log
@
Split the MP trampoline into two pages, one for code and one for data/stack
and then protect the code page as RX and the data/stack page as RW (NX).

ok deraadt@@
@
text
@d1 1
a1 1
/* $OpenBSD: acpi_wakecode.S,v 1.30 2014/10/16 17:37:42 mlarkin Exp $ */
d201 1
a201 1
	andl 	$(EFER_LME | EFER_LMA | EFER_NXE | EFER_SCE), %ebx	
@


1.30
log
@
Use an instruction encoding for the return-to-realmode code that works on
both AMD and Intel CPUs. Previously, the encoding was causing illegal
instruction exceptions on AMD, causing hibernate resume to fail.
@
text
@d1 1
a1 1
/* $OpenBSD: acpi_wakecode.S,v 1.29 2014/06/01 00:37:37 mlarkin Exp $ */
d70 1
a70 1
 * if our phys addr is 0x11000, we'd have cs=0x1100,ip=0
d386 1
a386 1
	movw	$0x1100, %ax
d395 1
a395 1
	ljmp	$0x1100, $acpi_s3_vector_real
d424 1
a424 1
	movw	$0x1100, %ax
d432 1
a432 1
	ljmp	$0x1100, $hib_hlt_real
d436 1
a436 1
	ljmp 	$0x1100, $hib_hlt_real
d597 2
a598 1
	.quad   0x00009a0110000fff
@


1.29
log
@
Remove real mode VGA repost option. It was used by nobody, and even if it
were to be enabled, it had a bug that prevented it from working anyway.

ok deraadt@@, kettenis@@
@
text
@d1 1
a1 1
/* $OpenBSD: acpi_wakecode.S,v 1.28 2014/03/10 05:03:50 mlarkin Exp $ */
d370 1
a370 1
	rex64	ljmp	*(hibernate_indirect_16)
d372 1
a372 1
	.quad	hibernate_resume_vector_3
d408 1
a408 1
	rex64	ljmp	*(hibernate_indirect_16b)
d410 1
a410 1
	.quad	hibernate_resume_vector_3b
@


1.28
log
@acpi_saved_rsp was defined twice. The asm resume code was using the first
definition and the C part of the resume code was using the second. This
manifested itself as mysterious reboot and stack corruption problems on
resume.

ok deraadt@@
@
text
@d1 1
a1 1
/* $OpenBSD: acpi_wakecode.S,v 1.27 2014/02/01 07:10:33 mlarkin Exp $ */
a87 1
	.global _C_LABEL(do_real_mode_post)
a120 26
	 * Reset the video hardware (as best as we can).
	 * We call the video bios at c000:0003, similar to
	 * what the BIOS does on a machine restart.
	 * Note that this will only reset the video card, 
	 * and may not enable LCDs or other attached displays.
	 *
	 * This will also put the hardware in "factory default"
	 * display mode, which may not match what we had
	 * when we went to sleep. On many machines (specifically
	 * laptops), we might not restore the proper VGA mode
	 * on resume. Caveat emptor.
	 */
	cmpl	$0, do_real_mode_post_off
	jz	nobiosreset
	lcall	$0xc000,$3

	/*
	 * Restore our segment registers in case the call to 
	 * reset the video hardware clobbered them.
	 */
	movw	%cs,%ax
	movw	%ax,%ds
	movw	%ax,%ss
nobiosreset:

	/*
a598 5

	.align 4
_C_LABEL(do_real_mode_post):
_ACPI_TRMP_OFFSET(do_real_mode_post_off)
	.long	0
@


1.27
log
@

Remove some of the excessive cache and TLB flushing going on during
hibernate unpack - these were added a while ago when we were fighting
different issues that have now been solved.

Tested by myself and dcoppa on a variety of machines
@
text
@d1 1
a1 1
/* $OpenBSD: acpi_wakecode.S,v 1.26 2014/01/22 03:09:39 kettenis Exp $ */
a643 2
	.quad 0
_ACPI_TRMP_LABEL(acpi_saved_rsp)
@


1.26
log
@Use ljmp instead of ljmpq since binutils 2.17 doesn't like the latter.

ok mlarkin@@
@
text
@d1 1
a1 1
/* $OpenBSD: acpi_wakecode.S,v 1.25 2014/01/16 19:32:26 brad Exp $ */
d497 1
a497 2
	movq	$HIBERNATE_PML4T, %rax
	movq	%rax, %cr3
@


1.25
log
@Appease LLVM's integrated assembler. Matches the same code as it exists
for i386.

error: ambiguous instructions require an explicit suffix (could be 'cmpb', 'cmpw', 'cmpl', or 'cmpq')

ok mlarkin@@
@
text
@d1 1
a1 1
/* $OpenBSD: acpi_wakecode.S,v 1.24 2014/01/10 22:34:41 mlarkin Exp $ */
d397 1
a397 1
	rex64	ljmpq	*(hibernate_indirect_16)
d435 1
a435 1
	rex64	ljmpq	*(hibernate_indirect_16b)
@


1.24
log
@

Resurrect the "park APs in realmode" idea that we explored back at t2k13
(and which didn't work at that time due to a bug which has since been
fixed). The APs are now demoted to real mode and placed in a HLT loop
while the hibernated image is being unpacked.

Helps my x230 significantly, no more spurious reboots on resume.

ok deraadt
@
text
@d1 1
a1 1
/* $OpenBSD: acpi_wakecode.S,v 1.23 2014/01/05 20:23:56 mlarkin Exp $ */
d134 1
a134 1
	cmp	$0, do_real_mode_post_off
@


1.23
log
@

Don't use the first 64KB for anything, including tramps. Move tramps and
hibernate goo up after 64KB to avoid posible corruption by buggy BIOS SMM
code. Diff also ensures the first 64KB doesn't get handed to UVM either.

ok deraadt@@, tested by many with no regressions reported
@
text
@d1 1
a1 1
/* $OpenBSD: acpi_wakecode.S,v 1.22 2013/12/26 18:52:09 mlarkin Exp $ */
d397 1
a397 1
	rex64	ljmp	*(hibernate_indirect_16)
d402 1
a402 1
_ACPI_TRMP_LABEL(hibernate_resume_vector_3)
d435 1
a435 1
	rex64	ljmp	*(hibernate_indirect_16b)
d440 1
a440 1
_ACPI_TRMP_LABEL(hibernate_resume_vector_3b)
d625 1
a625 1
	.quad   0x00009a000000ffff
@


1.22
log
@

Back at t2k13, I wrote code to park APs in real mode before resuming a
hibernated image. We backed out the code because it was causing reboots on
resume. Turns out the parking code had a bug that caused the CPU to jump
to some bogus address (calculating a bad offset for the jump target), which
was likely the source of the problem. This diff fixes the bad offset
calculation (verified by looking at the resulting asm output). This will be
the first step in attempting to resurrect the original idea (and eventually
add i386 if/when it works).

discussed with deraadt@@
@
text
@d1 1
a1 1
/* $OpenBSD: acpi_wakecode.S,v 1.21 2013/11/02 00:42:16 mlarkin Exp $ */
d70 1
a70 1
 * if our phys addr is 0x4000, we'd have cs=0x0400,ip=0
d413 1
a413 1
	movw	$0x0400, %ax
d422 1
a422 1
	ljmp	$0x0400, $acpi_s3_vector_real
d451 1
a451 1
	movw	$0x0400, %ax
d459 1
a459 1
	ljmp	$0x0400, $hib_hlt_real
d463 1
a463 1
	ljmp 	$0x0400, $hib_hlt_real
@


1.21
log
@

Some more aggressive CR3 whacking is needed on some machines to completely
flush the inflate page TLB entry.
@
text
@d1 1
a1 1
/* $OpenBSD: acpi_wakecode.S,v 1.20 2013/10/18 15:07:58 mlarkin Exp $ */
d461 1
a461 1
_ACPI_TRMP_LABEL(hib_hlt_real)
@


1.20
log
@

Disable global page mappings before we start to unpack. This was likely
one cause of the random gzip errors and reboots we've been seeing with
hibernate as we were creating new mappings for kernel text which likely
conflicted with the non-flushed global mappings from the resuming kernel.

Also remove an unnecessary wbinvd (i386)

ok deraadt
@
text
@d1 1
a1 1
/* $OpenBSD: acpi_wakecode.S,v 1.19 2013/08/03 09:39:29 mlarkin Exp $ */
d497 2
a498 1
	invlpg  HIBERNATE_INFLATE_PAGE
@


1.19
log
@

Don't flush the cache on page inflate for hibernate on amd64.
Makes the x200 and w500 and probably other machines go a bit
faster during resume from hibernate. This had been in my tree since
t2k13.
@
text
@d1 1
a1 1
/* $OpenBSD: acpi_wakecode.S,v 1.18 2013/06/04 16:21:23 mlarkin Exp $ */
d471 3
d476 1
@


1.18
log
@

Remove remaining references to HIBERNATE_COPY_PAGE. It was effectively
removed at n2k13 but a few errant references still remained. No functional
change. Spot tested by my on i386 and amd64 UP environments, no regressions
seen.

noticed by deraadt@@
@
text
@d1 1
a1 1
/* $OpenBSD: acpi_wakecode.S,v 1.17 2013/06/01 17:16:51 mlarkin Exp $ */
a492 1
	wbinvd
@


1.17
log
@

Add code to drop a CPU from long mode back to real mode, will be used to
park CPUs back to a known state in preparation for re-INIT/SIPIing them
later in the hibernate resume cycle.
@
text
@d1 1
a1 1
/* $OpenBSD: acpi_wakecode.S,v 1.16 2013/01/17 00:54:48 mlarkin Exp $ */
a494 1
	invlpg  HIBERNATE_COPY_PAGE
@


1.16
log
@

use .quad for gdt load when returning from long mode. Fixes a reboot
problem after unpack
@
text
@d1 1
a1 1
/* $OpenBSD: acpi_wakecode.S,v 1.15 2013/01/17 00:11:24 mlarkin Exp $ */
d423 41
@


1.15
log
@

fix an error in the amd64 asm unhibernate code and a slight adjustment to
the MI hibernate code to handle 64 bit archs
@
text
@d1 1
a1 1
/* $OpenBSD: acpi_wakecode.S,v 1.14 2013/01/16 22:45:40 mlarkin Exp $ */
d574 1
a574 1
	.long	tmp_gdtable6416
@


1.14
log
@

asm resume functions for amd64 hibernate
@
text
@d1 1
a1 1
/* $OpenBSD: acpi_wakecode.S,v 1.13 2012/10/19 16:38:30 mlarkin Exp $ */
a393 1
	.code32
d399 1
a399 1
	.quad	hibernate_resume_vector3
@


1.13
log
@

amd64 hibernate "unpack-time" mmu/pmap code and asm goo. Work in
progress.
@
text
@d1 1
a1 1
/* $OpenBSD: acpi_wakecode.S,v 1.12 2010/11/18 21:15:13 miod Exp $ */
d394 3
a396 5
	/* Exit long mode */
	movl	$MSR_EFER, %ecx
	rdmsr
	andl	$(~EFER_LME), %eax
	wrmsr
d398 4
a401 4
	.code32
	/* Get out of 32 bit CS */
	lgdt	gdt_16
	ljmp	$0x8, $hibernate_resume_vector_3
a412 4
	/* Flush TLB */
	xorl	%eax, %eax
	movl	%eax, %cr3

d425 1
a425 1
	.code32
d429 3
a431 3
	movl	%cr4, %eax
	orl	$(CR4_PSE), %eax
	movl	%eax, %cr4
d433 2
a434 2
	movl	$HIBERNATE_PML4_PAGE, %eax
	movl	%eax,	%cr3
d444 4
a447 4
	movl	(%esp), %eax
	movl    %eax, HIBERNATE_STACK_PAGE + HIBERNATE_STACK_OFFSET
	movl    $(HIBERNATE_STACK_PAGE + HIBERNATE_STACK_OFFSET), %eax
	movl    %eax, %esp
d458 1
d571 13
@


1.12
log
@Don't
  #include "foo.h"
  #if NFOO > 0
  (whole file)
  #endif
since config(8) file inclusion rules already do it for you.
ok deraadt@@
@
text
@d1 1
a1 1
/* $OpenBSD: acpi_wakecode.S,v 1.11 2010/07/01 01:02:31 pirofti Exp $ */
d48 3
d90 1
d381 83
d515 50
d679 1
@


1.11
log
@Add a look-up table for machines that have special vga cards. This table will
tell, based on vendor/product/subvendor/subproduct ids, how the video reposting
should be done: via the emulator or the bios video call in locore. The default
is to do none of those, which is how most machines work.

Okay kettenis@@, deraadt@@.
@
text
@d1 1
a1 1
/* $OpenBSD: acpi_wakecode.S,v 1.10 2010/02/22 19:44:11 kettenis Exp $ */
a43 5
#include "acpi.h"

#if NACPI > 0
#ifndef SMALL_KERNEL

a627 2
#endif /* SMALL_KERNEL */
#endif /* NACPI > 0 */
@


1.10
log
@Don't attempt to repost the video hardware.  There are quite a few machines
where jumping to the "standard" video BIOS entry point locks up or even
resets the machine.  This will break resume on some other machines in the
sense that the display on them will remain disabled.  But hopefully those
machines make it into a state where the kernel is running and we can fix that.

ok deraadt@@, marco@@, mlarkin@@
@
text
@d1 1
a1 1
/* $OpenBSD: acpi_wakecode.S,v 1.9 2009/12/09 16:20:33 pirofti Exp $ */
d90 1
d135 2
a136 1
	jmp	nobiosreset	/* XXX make this a tunable */
d444 5
@


1.9
log
@Remove the clean gdt bit and leave the idt part in.

Fixes most laptops out there on resume. Okay deraadt@@.
@
text
@d1 1
a1 1
/* $OpenBSD: acpi_wakecode.S,v 1.8 2009/11/30 16:41:04 pirofti Exp $ */
d134 1
a134 1
	/* jmp	nobiosreset */ 	/* XXX make this a tunable */
@


1.8
log
@KNF
@
text
@d1 1
a1 1
/* $OpenBSD: acpi_wakecode.S,v 1.7 2009/11/26 00:14:11 mlarkin Exp $ */
a94 22
	/* Some BIOS vendors screw up the gdt, make sure we clean it */
	movw	$0x10,	%cx
	lgdtl	%cs:clean_gdt
	movl	%cr0,	%eax
	orb	$(CR0_PE), %al
	movl	%eax,	%cr0
	jmp	1f
1:	ljmpw	$0x8, $clean1

_ACPI_TRMP_OFFSET(clean1)
	movw	%cx,	%ds	
	movw	%cx,	%es
	movw	%cx,	%ss
	movw	%cx,	%fs
	movw	%cx,	%gs
	
	andb	$~(CR0_PE), %al
	movl	%eax,	%cr0
	ljmpw	$_ACPI_RM_SEGMENT , $clean2

_ACPI_TRMP_OFFSET(clean2)

a429 16

_ACPI_TRMP_OFFSET(clean_gdt)
	.word	clean_gdt_end - clean_gdtable
	.long	clean_gdtable

	.align 8
_ACPI_TRMP_LABEL(clean_gdtable)
	.word	0, 0
	.byte	0, 0, 0, 0

	.word	0xffff, ACPI_TRAMPOLINE
	.byte	0, 0x9b, 0, 0

	.word	0xffff, ACPI_TRAMPOLINE
	.byte	0, 0x93, 0, 0
_ACPI_TRMP_LABEL(clean_gdt_end)
@


1.7
log
@

Fix a stack problem on amd64, now the resume functions get called properly.
Tested mlarkin on thinkpad x60, pirofti on dell d620, and deraadt on
thinkpad T61.

ok deraadt@@, pirofti@@
@
text
@d1 1
a1 1
/* $OpenBSD: acpi_wakecode.S,v 1.6 2009/11/25 15:41:43 pirofti Exp $ */
d84 1
a84 1
	.align 4,0
d407 1
a407 1
	.align 8,0
d447 1
a447 1
	.align 8, 0
d457 1
a457 1
	.align 8, 0
d474 1
a474 1
	.align 8,0
@


1.6
log
@Make sure we get a clean gdt from the BIOS.

Some vendors screw us up on resume giving back a dirty gdt which
prevents us to go into protected mode. This makes sure the gdt is
clean, its the only way to do this and its the only way to be sure
we're clean on resume.

This fixes quite a few laptops that didn't resume but rebooted or did
other screwy things because of a dirty gdt.

Worked with mlarkin@@ for quite a few houres last night.
Tested by many on both amd64 and i386.
Okay deraadt@@.
@
text
@d1 1
a1 1
/* $OpenBSD: acpi_wakecode.S,v 1.5 2009/11/24 17:00:01 mlarkin Exp $ */
d589 1
@


1.5
log
@

Poke CR3 one last time before resuming. Suggested by deraadt@@.

ok deraadt@@
@
text
@d1 1
a1 1
/* $OpenBSD: acpi_wakecode.S,v 1.4 2009/11/22 22:00:51 mlarkin Exp $ */
d60 1
d95 22
d125 1
d127 1
d446 22
@


1.4
log
@

Missed 4 MSRs on suspend/resume in previous version. Tested by pirofti
and myself, ok pirofti@@
@
text
@d1 1
a1 1
/* $OpenBSD: acpi_wakecode.S,v 1.3 2009/02/19 21:02:05 marco Exp $ */
d369 4
@


1.3
log
@suspend/resume bits so that we can develop this in tree.  This is disabled.
code from mlarkin and me
help from art,toby,jordan and several others
ok jordan, go for it deraadt
@
text
@d1 1
a1 1
/* $OpenBSD: acpi_wakecode.S,v 1.2 2009/02/15 02:06:09 marco Exp $ */
d131 1
a131 1
	jmp	nobiosreset	/* XXX make this a tunable */
d283 20
d504 8
d564 20
@


1.2
log
@Add cvs tag
@
text
@d1 1
a1 1
/* $OpenBSD$ */
d131 1
d141 1
a156 1

d184 2
a187 3
	.code32
	.align 16

d260 2
a263 5
	.code64
	.align 16



a352 2


a395 1

a407 1

a442 1

a454 1

a556 1

a563 2


@


1.1
log
@Add sleep plumbing code for amd64 making it the sameish as i386. Committing
per mlarkin request.

Code from mlarkin, mptramp code from kurt
Lots of comments weingart, art & others
Tested in snaps for weeks
ok kurt, marco
@
text
@d1 1
@

