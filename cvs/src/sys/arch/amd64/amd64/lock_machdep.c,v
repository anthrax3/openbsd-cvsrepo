head	1.11;
access;
symbols
	OPENBSD_6_1:1.11.0.4
	OPENBSD_6_1_BASE:1.11
	OPENBSD_6_0:1.10.0.2
	OPENBSD_6_0_BASE:1.10
	OPENBSD_5_9:1.9.0.2
	OPENBSD_5_9_BASE:1.9
	OPENBSD_5_8:1.9.0.4
	OPENBSD_5_8_BASE:1.9
	OPENBSD_5_7:1.7.0.2
	OPENBSD_5_7_BASE:1.7
	OPENBSD_5_6:1.6.0.4
	OPENBSD_5_6_BASE:1.6
	OPENBSD_5_5:1.4.0.4
	OPENBSD_5_5_BASE:1.4
	OPENBSD_5_4:1.3.0.20
	OPENBSD_5_4_BASE:1.3
	OPENBSD_5_3:1.3.0.18
	OPENBSD_5_3_BASE:1.3
	OPENBSD_5_2:1.3.0.16
	OPENBSD_5_2_BASE:1.3
	OPENBSD_5_1_BASE:1.3
	OPENBSD_5_1:1.3.0.14
	OPENBSD_5_0:1.3.0.12
	OPENBSD_5_0_BASE:1.3
	OPENBSD_4_9:1.3.0.10
	OPENBSD_4_9_BASE:1.3
	OPENBSD_4_8:1.3.0.8
	OPENBSD_4_8_BASE:1.3
	OPENBSD_4_7:1.3.0.4
	OPENBSD_4_7_BASE:1.3
	OPENBSD_4_6:1.3.0.6
	OPENBSD_4_6_BASE:1.3
	OPENBSD_4_5:1.3.0.2
	OPENBSD_4_5_BASE:1.3
	OPENBSD_4_4:1.2.0.4
	OPENBSD_4_4_BASE:1.2
	OPENBSD_4_3:1.2.0.2
	OPENBSD_4_3_BASE:1.2;
locks; strict;
comment	@ * @;


1.11
date	2017.03.07.14.41.57;	author visa;	state Exp;
branches;
next	1.10;
commitid	QuoJY64mTVcW3iGY;

1.10
date	2016.03.19.11.34.22;	author mpi;	state Exp;
branches;
next	1.9;
commitid	15xZY6veDWwRM6Iq;

1.9
date	2015.06.25.00.58.49;	author dlg;	state Exp;
branches;
next	1.8;
commitid	iB2tITvW8ONiPx0E;

1.8
date	2015.03.14.03.38.46;	author jsg;	state Exp;
branches;
next	1.7;
commitid	p4LJxGKbi0BU2cG6;

1.7
date	2015.02.11.06.39.24;	author dlg;	state Exp;
branches;
next	1.6;
commitid	VbZbol1NfaqkBbwH;

1.6
date	2014.07.10.12.14.48;	author mlarkin;	state Exp;
branches;
next	1.5;
commitid	HJVrj1M0qsHVknqv;

1.5
date	2014.03.14.02.08.57;	author dlg;	state Exp;
branches;
next	1.4;

1.4
date	2013.12.05.01.28.45;	author uebayasi;	state Exp;
branches;
next	1.3;

1.3
date	2008.12.04.15.48.19;	author weingart;	state Exp;
branches;
next	1.2;

1.2
date	2007.11.27.15.55.29;	author art;	state Exp;
branches;
next	1.1;

1.1
date	2007.11.26.23.50.03;	author art;	state Exp;
branches;
next	;


desc
@@


1.11
log
@Keep on trying to grab the lock after leaving ddb after lock spin-out.
This restores the behaviour that preceded ticket locks. The feature can
be useful in some debug cases where the system is not totally borken.

OK guenther@@, dlg@@, mpi@@
@
text
@/*	$OpenBSD: lock_machdep.c,v 1.10 2016/03/19 11:34:22 mpi Exp $	*/

/*
 * Copyright (c) 2007 Artur Grabowski <art@@openbsd.org>
 *
 * Permission to use, copy, modify, and distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 */


#include <sys/param.h>
#include <sys/systm.h>

#include <machine/atomic.h>
#include <machine/lock.h>
#include <machine/cpufunc.h>

#include <ddb/db_output.h>

void
__mp_lock_init(struct __mp_lock *mpl)
{
	memset(mpl->mpl_cpus, 0, sizeof(mpl->mpl_cpus));
	mpl->mpl_users = 0;
	mpl->mpl_ticket = 0;
}

#if defined(MP_LOCKDEBUG)
#ifndef DDB
#error "MP_LOCKDEBUG requires DDB"
#endif

/* CPU-dependent timing, needs this to be settable from ddb. */
extern int __mp_lock_spinout;
#endif

static __inline void
__mp_lock_spin(struct __mp_lock *mpl, u_int me)
{
#ifndef MP_LOCKDEBUG
	while (mpl->mpl_ticket != me)
		SPINLOCK_SPIN_HOOK;
#else
	int nticks = __mp_lock_spinout;

	while (mpl->mpl_ticket != me) {
		SPINLOCK_SPIN_HOOK;

		if (--nticks <= 0) {
			db_printf("__mp_lock(%p): lock spun out", mpl);
			Debugger();
			nticks = __mp_lock_spinout;
		}
	}
#endif
}

static inline u_int
fetch_and_add(u_int *var, u_int value)
{
	asm volatile("lock; xaddl %%eax, %2;"
	    : "=a" (value)
	    : "a" (value), "m" (*var)
	    : "memory");

	return (value);
}

void
__mp_lock(struct __mp_lock *mpl)
{
	struct __mp_lock_cpu *cpu = &mpl->mpl_cpus[cpu_number()];
	long rf = read_rflags();

	disable_intr();
	if (cpu->mplc_depth++ == 0)
		cpu->mplc_ticket = fetch_and_add(&mpl->mpl_users, 1);
	write_rflags(rf);

	__mp_lock_spin(mpl, cpu->mplc_ticket);
}

void
__mp_unlock(struct __mp_lock *mpl)
{
	struct __mp_lock_cpu *cpu = &mpl->mpl_cpus[cpu_number()];
	long rf = read_rflags();

#ifdef MP_LOCKDEBUG
	if (!__mp_lock_held(mpl)) {
		db_printf("__mp_unlock(%p): not held lock\n", mpl);
		Debugger();
	}
#endif

	disable_intr();	
	if (--cpu->mplc_depth == 0)
		mpl->mpl_ticket++;
	write_rflags(rf);
}

int
__mp_release_all(struct __mp_lock *mpl)
{
	struct __mp_lock_cpu *cpu = &mpl->mpl_cpus[cpu_number()];
	long rf = read_rflags();
	int rv;

	disable_intr();
 	rv = cpu->mplc_depth;
	cpu->mplc_depth = 0;
	mpl->mpl_ticket++;
	write_rflags(rf);

	return (rv);
}

int
__mp_release_all_but_one(struct __mp_lock *mpl)
{
	struct __mp_lock_cpu *cpu = &mpl->mpl_cpus[cpu_number()];
	int rv = cpu->mplc_depth - 1;

#ifdef MP_LOCKDEBUG
	if (!__mp_lock_held(mpl)) {
		db_printf("__mp_release_all_but_one(%p): not held lock\n", mpl);
		Debugger();
	}
#endif

	cpu->mplc_depth = 1;

	return (rv);
}

void
__mp_acquire_count(struct __mp_lock *mpl, int count)
{
	while (count--)
		__mp_lock(mpl);
}

int
__mp_lock_held(struct __mp_lock *mpl)
{
	struct __mp_lock_cpu *cpu = &mpl->mpl_cpus[cpu_number()];

	return (cpu->mplc_ticket == mpl->mpl_ticket && cpu->mplc_depth > 0);
}
@


1.10
log
@Reduces the noise around the global ``ticks'' variable by renaming
all the local ones to ``nticks''.

ok stefan@@, deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: lock_machdep.c,v 1.9 2015/06/25 00:58:49 dlg Exp $	*/
d55 1
a55 1
	while (mpl->mpl_ticket != me && --nticks > 0)
d58 5
a62 3
	if (nticks == 0) {
		db_printf("__mp_lock(%p): lock spun out", mpl);
		Debugger();
@


1.9
log
@you need to include ddb/db_output.h so you know how to call db_printf
inside MP_LOCKDEBUG.
@
text
@d1 1
a1 1
/*	$OpenBSD: lock_machdep.c,v 1.8 2015/03/14 03:38:46 jsg Exp $	*/
d53 1
a53 1
	int ticks = __mp_lock_spinout;
d55 1
a55 1
	while (mpl->mpl_ticket != me && --ticks > 0)
d58 1
a58 1
	if (ticks == 0) {
@


1.8
log
@Remove some includes include-what-you-use claims don't
have any direct symbols used.  Tested for indirect use by compiling
amd64/i386/sparc64 kernels.

ok tedu@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: lock_machdep.c,v 1.7 2015/02/11 06:39:24 dlg Exp $	*/
d26 2
@


1.7
log
@this doesnt need lockmgr. we dont need sys/lock.h
@
text
@d1 1
a1 1
/*	$OpenBSD: lock_machdep.c,v 1.6 2014/07/10 12:14:48 mlarkin Exp $	*/
a25 2

#include <ddb/db_output.h>
@


1.6
log
@

fix some errors in lockdebug code. not enabled by default.

ok dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: lock_machdep.c,v 1.5 2014/03/14 02:08:57 dlg Exp $	*/
a20 1
#include <sys/lock.h>
@


1.5
log
@rework mplocks to use tickets instead of spinning. this provides
fairer access to the kernel lock between logical cpus, especially
in multi socket systems.

i first wrote this diff in 2011. it provided the model for the i386
and sparc64 ticket locks.

ok n2k14 for post 5.5 (deraadt@@ and kettenis@@ in particular)
@
text
@d1 1
a1 1
/*	$OpenBSD: lock_machdep.c,v 1.4 2013/12/05 01:28:45 uebayasi Exp $	*/
d60 1
a60 1
		db_printf("__mp_lock(0x%x): lock spun out", mpl);
d98 1
a98 1
	if (mpl->mpl_cpu != curcpu()) {
d133 1
a133 1
	if (mpl->mpl_cpu != curcpu()) {
a157 1

@


1.4
log
@Correct spin timeout detection in __mp_lock debug code.

OK pirofti@@ krw@@ miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d31 1
a31 1
__mp_lock_init(struct __mp_lock *lock)
d33 3
a35 2
	lock->mpl_cpu = NULL;
	lock->mpl_count = 0;
d48 1
a48 1
__mp_lock_spin(struct __mp_lock *mpl)
d51 1
a51 1
	while (mpl->mpl_count != 0)
d56 1
a56 1
	while (mpl->mpl_count != 0 && --ticks > 0)
d66 11
d80 2
a81 26
	/*
	 * Please notice that mpl_count gets incremented twice for the
	 * first lock. This is on purpose. The way we release the lock
	 * in mp_unlock is to decrement the mpl_count and then check if
	 * the lock should be released. Since mpl_count is what we're
	 * spinning on, decrementing it in mpl_unlock to 0 means that
	 * we can't clear mpl_cpu, because we're no longer holding the
	 * lock. In theory mpl_cpu doesn't need to be cleared, but it's
	 * safer to clear it and besides, setting mpl_count to 2 on the
	 * first lock makes most of this code much simpler.
	 */

	while (1) {
		long rf = read_rflags();

		disable_intr();
		if (x86_atomic_cas_ul(&mpl->mpl_count, 0, 1) == 0) {
			mpl->mpl_cpu = curcpu();
		}

		if (mpl->mpl_cpu == curcpu()) {
			mpl->mpl_count++;
			write_rflags(rf);
			break;
		}
		write_rflags(rf);
d83 6
a88 2
		__mp_lock_spin(mpl);
	}
d94 1
d105 2
a106 4
	if (--mpl->mpl_count == 1) {
		mpl->mpl_cpu = NULL;
		mpl->mpl_count = 0;
	}
d113 1
a113 1
	int rv = mpl->mpl_count - 1;
d115 1
a115 7

#ifdef MP_LOCKDEBUG
	if (mpl->mpl_cpu != curcpu()) {
		db_printf("__mp_release_all(%p): not held lock\n", mpl);
		Debugger();
	}
#endif
d118 3
a120 2
	mpl->mpl_cpu = NULL;
	mpl->mpl_count = 0;
d129 2
a130 1
	int rv = mpl->mpl_count - 2;
d139 1
a139 1
	mpl->mpl_count = 2;
d154 3
a156 1
	return mpl->mpl_cpu == curcpu();
@


1.3
log
@Fix "fp_save ipi didn't" panic, and move i386/amd64 closer in the process.
Positive test results by a handful of people.  Ok kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: lock_machdep.c,v 1.2 2007/11/27 15:55:29 art Exp $	*/
d55 1
a55 1
	while (mpl->mpl_count != 0 && ticks-- > 0)
@


1.2
log
@ARGH. Work has poisoned my mind. KNF the braces.
@
text
@d1 1
a1 1
/*	$OpenBSD: lock_machdep.c,v 1.1 2007/11/26 23:50:03 art Exp $	*/
a44 2

#define SPINLOCK_SPIN_HOOK	__asm __volatile("pause": : :"memory")
@


1.1
log
@Like i386 - make the __mp_lock not spin at splhigh.

deraadt@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d122 2
a123 1
__mp_release_all(struct __mp_lock *mpl) {
d143 2
a144 1
__mp_release_all_but_one(struct __mp_lock *mpl) {
d160 2
a161 1
__mp_acquire_count(struct __mp_lock *mpl, int count) {
d167 2
a168 1
__mp_lock_held(struct __mp_lock *mpl) {
@

