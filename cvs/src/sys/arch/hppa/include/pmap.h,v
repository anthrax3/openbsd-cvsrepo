head	1.51;
access;
symbols
	OPENBSD_6_0:1.51.0.6
	OPENBSD_6_0_BASE:1.51
	OPENBSD_5_9:1.51.0.2
	OPENBSD_5_9_BASE:1.51
	OPENBSD_5_8:1.51.0.4
	OPENBSD_5_8_BASE:1.51
	OPENBSD_5_7:1.49.0.2
	OPENBSD_5_7_BASE:1.49
	OPENBSD_5_6:1.45.0.6
	OPENBSD_5_6_BASE:1.45
	OPENBSD_5_5:1.45.0.4
	OPENBSD_5_5_BASE:1.45
	OPENBSD_5_4:1.44.0.2
	OPENBSD_5_4_BASE:1.44
	OPENBSD_5_3:1.43.0.6
	OPENBSD_5_3_BASE:1.43
	OPENBSD_5_2:1.43.0.4
	OPENBSD_5_2_BASE:1.43
	OPENBSD_5_1_BASE:1.43
	OPENBSD_5_1:1.43.0.2
	OPENBSD_5_0:1.42.0.2
	OPENBSD_5_0_BASE:1.42
	OPENBSD_4_9:1.40.0.2
	OPENBSD_4_9_BASE:1.40
	OPENBSD_4_8:1.37.0.4
	OPENBSD_4_8_BASE:1.37
	OPENBSD_4_7:1.37.0.2
	OPENBSD_4_7_BASE:1.37
	OPENBSD_4_6:1.36.0.4
	OPENBSD_4_6_BASE:1.36
	OPENBSD_4_5:1.35.0.6
	OPENBSD_4_5_BASE:1.35
	OPENBSD_4_4:1.35.0.4
	OPENBSD_4_4_BASE:1.35
	OPENBSD_4_3:1.35.0.2
	OPENBSD_4_3_BASE:1.35
	OPENBSD_4_2:1.33.0.14
	OPENBSD_4_2_BASE:1.33
	OPENBSD_4_1:1.33.0.12
	OPENBSD_4_1_BASE:1.33
	OPENBSD_4_0:1.33.0.10
	OPENBSD_4_0_BASE:1.33
	OPENBSD_3_9:1.33.0.8
	OPENBSD_3_9_BASE:1.33
	OPENBSD_3_8:1.33.0.6
	OPENBSD_3_8_BASE:1.33
	OPENBSD_3_7:1.33.0.4
	OPENBSD_3_7_BASE:1.33
	OPENBSD_3_6:1.33.0.2
	OPENBSD_3_6_BASE:1.33
	SMP_SYNC_A:1.31
	SMP_SYNC_B:1.31
	OPENBSD_3_5:1.27.0.6
	OPENBSD_3_5_BASE:1.27
	OPENBSD_3_4:1.27.0.4
	OPENBSD_3_4_BASE:1.27
	UBC_SYNC_A:1.27
	OPENBSD_3_3:1.27.0.2
	OPENBSD_3_3_BASE:1.27
	OPENBSD_3_2:1.23.0.2
	OPENBSD_3_2_BASE:1.23
	OPENBSD_3_1:1.19.0.2
	OPENBSD_3_1_BASE:1.19
	UBC_SYNC_B:1.25
	UBC:1.15.0.2
	UBC_BASE:1.15
	OPENBSD_3_0:1.14.0.2
	OPENBSD_3_0_BASE:1.14
	OPENBSD_2_9:1.13.0.2
	OPENBSD_2_9_BASE:1.13
	OPENBSD_2_8:1.12.0.6
	OPENBSD_2_8_BASE:1.12
	OPENBSD_2_7:1.12.0.4
	OPENBSD_2_7_BASE:1.12
	SMP:1.12.0.2
	SMP_BASE:1.12
	kame_19991208:1.10
	OPENBSD_2_6:1.9.0.2
	OPENBSD_2_6_BASE:1.9
	OPENBSD_2_5:1.7.0.2
	OPENBSD_2_5_BASE:1.7
	OPENBSD_2_4:1.3.0.2
	OPENBSD_2_4_BASE:1.3;
locks; strict;
comment	@ * @;


1.51
date	2015.07.27.03.36.38;	author guenther;	state Exp;
branches;
next	1.50;
commitid	6ewyuwC7kjkZGgSb;

1.50
date	2015.07.14.06.50.04;	author kettenis;	state Exp;
branches;
next	1.49;
commitid	a0X7A6rPqFayOd1j;

1.49
date	2015.02.15.21.34.33;	author miod;	state Exp;
branches;
next	1.48;
commitid	eahBabNpxnDWKzqJ;

1.48
date	2015.02.11.06.43.27;	author dlg;	state Exp;
branches;
next	1.47;
commitid	J3pcGScS2tb9Iouf;

1.47
date	2014.12.17.15.01.47;	author deraadt;	state Exp;
branches;
next	1.46;
commitid	C6XE7SFGDfwfHXJP;

1.46
date	2014.11.16.12.30.57;	author deraadt;	state Exp;
branches;
next	1.45;
commitid	yv0ECmCdICvq576h;

1.45
date	2014.01.30.18.16.41;	author miod;	state Exp;
branches;
next	1.44;

1.44
date	2013.03.31.17.07.03;	author deraadt;	state Exp;
branches;
next	1.43;

1.43
date	2011.11.14.14.29.53;	author deraadt;	state Exp;
branches;
next	1.42;

1.42
date	2011.05.07.15.27.01;	author oga;	state Exp;
branches;
next	1.41;

1.41
date	2011.04.28.20.42.28;	author ariane;	state Exp;
branches;
next	1.40;

1.40
date	2010.12.26.15.40.59;	author miod;	state Exp;
branches;
next	1.39;

1.39
date	2010.12.06.20.57.16;	author miod;	state Exp;
branches;
next	1.38;

1.38
date	2010.11.18.21.21.36;	author miod;	state Exp;
branches;
next	1.37;

1.37
date	2010.01.03.19.23.49;	author kettenis;	state Exp;
branches;
next	1.36;

1.36
date	2009.06.11.20.10.51;	author kettenis;	state Exp;
branches;
next	1.35;

1.35
date	2007.12.14.18.32.23;	author deraadt;	state Exp;
branches;
next	1.34;

1.34
date	2007.09.10.18.49.44;	author miod;	state Exp;
branches;
next	1.33;

1.33
date	2004.08.06.22.39.12;	author deraadt;	state Exp;
branches;
next	1.32;

1.32
date	2004.07.13.14.51.29;	author tedu;	state Exp;
branches;
next	1.31;

1.31
date	2004.06.09.20.17.23;	author tedu;	state Exp;
branches;
next	1.30;

1.30
date	2004.05.20.09.20.42;	author kettenis;	state Exp;
branches;
next	1.29;

1.29
date	2004.04.21.22.14.34;	author mickey;	state Exp;
branches;
next	1.28;

1.28
date	2004.04.07.18.24.19;	author mickey;	state Exp;
branches;
next	1.27;

1.27
date	2003.01.22.18.16.35;	author mickey;	state Exp;
branches;
next	1.26;

1.26
date	2002.11.07.19.22.56;	author mickey;	state Exp;
branches;
next	1.25;

1.25
date	2002.10.28.20.49.16;	author mickey;	state Exp;
branches;
next	1.24;

1.24
date	2002.10.17.02.21.08;	author mickey;	state Exp;
branches;
next	1.23;

1.23
date	2002.09.12.12.50.47;	author art;	state Exp;
branches;
next	1.22;

1.22
date	2002.09.05.18.41.19;	author mickey;	state Exp;
branches;
next	1.21;

1.21
date	2002.05.09.17.45.24;	author mickey;	state Exp;
branches;
next	1.20;

1.20
date	2002.04.22.06.31.28;	author mickey;	state Exp;
branches;
next	1.19;

1.19
date	2002.03.15.21.44.18;	author mickey;	state Exp;
branches;
next	1.18;

1.18
date	2002.03.14.01.26.32;	author millert;	state Exp;
branches;
next	1.17;

1.17
date	2002.02.21.06.12.31;	author mickey;	state Exp;
branches;
next	1.16;

1.16
date	2002.01.10.01.23.08;	author mickey;	state Exp;
branches;
next	1.15;

1.15
date	2001.12.04.23.22.42;	author art;	state Exp;
branches
	1.15.2.1;
next	1.14;

1.14
date	2001.05.09.15.31.24;	author art;	state Exp;
branches;
next	1.13;

1.13
date	2001.01.12.23.37.01;	author mickey;	state Exp;
branches;
next	1.12;

1.12
date	99.12.12.03.16.26;	author mickey;	state Exp;
branches
	1.12.2.1;
next	1.11;

1.11
date	99.12.09.01.49.43;	author mickey;	state Exp;
branches;
next	1.10;

1.10
date	99.11.16.16.42.29;	author mickey;	state Exp;
branches;
next	1.9;

1.9
date	99.07.21.05.38.03;	author mickey;	state Exp;
branches;
next	1.8;

1.8
date	99.04.20.19.29.12;	author mickey;	state Exp;
branches;
next	1.7;

1.7
date	99.01.20.19.39.53;	author mickey;	state Exp;
branches;
next	1.6;

1.6
date	99.01.20.19.29.51;	author mickey;	state Exp;
branches;
next	1.5;

1.5
date	99.01.03.04.01.35;	author mickey;	state Exp;
branches;
next	1.4;

1.4
date	98.11.23.03.28.22;	author mickey;	state Exp;
branches;
next	1.3;

1.3
date	98.09.12.03.14.49;	author mickey;	state Exp;
branches;
next	1.2;

1.2
date	98.08.20.15.50.59;	author mickey;	state Exp;
branches;
next	1.1;

1.1
date	98.07.07.21.32.44;	author mickey;	state Exp;
branches;
next	;

1.12.2.1
date	2001.04.18.16.06.27;	author niklas;	state Exp;
branches;
next	1.12.2.2;

1.12.2.2
date	2001.07.04.10.16.11;	author niklas;	state Exp;
branches;
next	1.12.2.3;

1.12.2.3
date	2002.03.06.00.57.22;	author niklas;	state Exp;
branches;
next	1.12.2.4;

1.12.2.4
date	2002.03.28.10.29.05;	author niklas;	state Exp;
branches;
next	1.12.2.5;

1.12.2.5
date	2003.03.27.23.26.54;	author niklas;	state Exp;
branches;
next	1.12.2.6;

1.12.2.6
date	2004.06.05.23.10.49;	author niklas;	state Exp;
branches;
next	1.12.2.7;

1.12.2.7
date	2004.06.10.11.40.23;	author niklas;	state Exp;
branches;
next	;

1.15.2.1
date	2002.01.31.22.55.09;	author niklas;	state Exp;
branches;
next	1.15.2.2;

1.15.2.2
date	2002.06.11.03.35.37;	author art;	state Exp;
branches;
next	1.15.2.3;

1.15.2.3
date	2002.10.29.00.28.03;	author art;	state Exp;
branches;
next	1.15.2.4;

1.15.2.4
date	2003.05.19.21.49.42;	author tedu;	state Exp;
branches;
next	;


desc
@@


1.51
log
@Always #include <sys/mutex.h>: need struct mutex for struct vm_page_md

problem noted by landry@@
ok dlg@@
@
text
@/*	$OpenBSD: pmap.h,v 1.50 2015/07/14 06:50:04 kettenis Exp $	*/

/*
 * Copyright (c) 2002-2004 Michael Shalayeff
 * All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 *
 * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR
 * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
 * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
 * IN NO EVENT SHALL THE AUTHOR OR HIS RELATIVES BE LIABLE FOR ANY DIRECT,
 * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
 * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 * SERVICES; LOSS OF MIND, USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,
 * STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING
 * IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
 * THE POSSIBILITY OF SUCH DAMAGE.
 */

#ifndef _MACHINE_PMAP_H_
#define _MACHINE_PMAP_H_

#include <uvm/uvm_object.h>
#include <sys/mutex.h>

#ifdef	_KERNEL
#include <machine/pte.h>

struct pmap {
	struct mutex pm_mtx;
	struct uvm_object pm_obj;
	struct vm_page	*pm_ptphint;
	struct vm_page	*pm_pdir_pg;	/* vm_page for pdir */
	volatile u_int32_t *pm_pdir;	/* page dir (read-only after create) */
	pa_space_t	pm_space;	/* space id (read-only after create) */
	u_int		pm_pid;		/* prot id (read-only after create) */

	struct pmap_statistics	pm_stats;
};
typedef struct pmap *pmap_t;

#define HPPA_MAX_PID    0xfffa
#define	HPPA_SID_MAX	0x7ffd
#define HPPA_SID_KERNEL 0
#define HPPA_PID_KERNEL 2

#define KERNEL_ACCESS_ID 1
#define KERNEL_TEXT_PROT (TLB_AR_KRX | (KERNEL_ACCESS_ID << 1))
#define KERNEL_DATA_PROT (TLB_AR_KRW | (KERNEL_ACCESS_ID << 1))

struct pv_entry {			/* locked by its list's pvh_lock */
	struct pv_entry	*pv_next;
	struct pmap	*pv_pmap;	/* the pmap */
	vaddr_t		pv_va;		/* the virtual address */
	struct vm_page	*pv_ptp;	/* the vm_page of the PTP */
};

/* also match the hardware tlb walker definition */
struct vp_entry {
	u_int	vp_tag;
	u_int	vp_tlbprot;
	u_int	vp_tlbpage;
	u_int	vp_ptr;
};

extern void gateway_page(void);
extern struct pmap kernel_pmap_store;

#if defined(HP7100LC_CPU) || defined(HP7300LC_CPU)
extern int pmap_hptsize;
extern struct pdc_hwtlb pdc_hwtlb;
#endif

/*
 * pool quickmaps
 */
#define	pmap_map_direct(pg)	((vaddr_t)VM_PAGE_TO_PHYS(pg))
struct vm_page *pmap_unmap_direct(vaddr_t);
#define	__HAVE_PMAP_DIRECT

/*
 * according to the parisc manual aliased va's should be
 * different by high 12 bits only.
 */
#define	PMAP_PREFER(o,h)	pmap_prefer(o, h)
static __inline__ vaddr_t
pmap_prefer(vaddr_t offs, vaddr_t hint)
{
	vaddr_t pmap_prefer_hint = (hint & HPPA_PGAMASK) | (offs & HPPA_PGAOFF);
	if (pmap_prefer_hint < hint)
		pmap_prefer_hint += HPPA_PGALIAS;
	return pmap_prefer_hint;
}

/* pmap prefer alignment */
#define PMAP_PREFER_ALIGN()	(HPPA_PGALIAS)
/* pmap prefer offset within alignment */
#define PMAP_PREFER_OFFSET(of)	((of) & HPPA_PGAOFF)

#define	pmap_sid2pid(s)			(((s) + 1) << 1)
#define pmap_kernel()			(&kernel_pmap_store)
#define	pmap_resident_count(pmap)	((pmap)->pm_stats.resident_count)
#define	pmap_update(pm)			(void)(pm)
#define pmap_copy(dpmap,spmap,da,len,sa)

#define pmap_clear_modify(pg)	pmap_changebit(pg, 0, PTE_PROT(TLB_DIRTY))
#define pmap_clear_reference(pg) pmap_changebit(pg, PTE_PROT(TLB_REFTRAP), 0)
#define pmap_is_modified(pg)	pmap_testbit(pg, PTE_PROT(TLB_DIRTY))
#define pmap_is_referenced(pg)	pmap_testbit(pg, PTE_PROT(TLB_REFTRAP))

#define pmap_unuse_final(p)		/* nothing */
#define	pmap_remove_holes(vm)		do { /* nothing */ } while (0)

void pmap_bootstrap(vaddr_t);
boolean_t pmap_changebit(struct vm_page *, pt_entry_t, pt_entry_t);
boolean_t pmap_testbit(struct vm_page *, pt_entry_t);
void pmap_write_protect(struct pmap *, vaddr_t, vaddr_t, vm_prot_t);
void pmap_remove(struct pmap *pmap, vaddr_t sva, vaddr_t eva);
void pmap_page_remove(struct vm_page *pg);

static __inline int
pmap_prot(struct pmap *pmap, int prot)
{
	extern u_int hppa_prot[];
	return (hppa_prot[prot] | (pmap == pmap_kernel()? 0 : TLB_USER));
}

static __inline void
pmap_page_protect(struct vm_page *pg, vm_prot_t prot)
{
	if ((prot & PROT_WRITE) == 0) {
		if (prot & (PROT_READ | PROT_EXEC))
			pmap_changebit(pg, 0, PTE_PROT(TLB_WRITE));
		else
			pmap_page_remove(pg);
	}
}

static __inline void
pmap_protect(struct pmap *pmap, vaddr_t sva, vaddr_t eva, vm_prot_t prot)
{
	if ((prot & PROT_WRITE) == 0) {
		if (prot & (PROT_READ | PROT_EXEC))
			pmap_write_protect(pmap, sva, eva, prot);
		else
			pmap_remove(pmap, sva, eva);
	}
}

#endif /* _KERNEL */

#if !defined(_LOCORE)
struct pv_entry;
struct vm_page_md {
	struct mutex pvh_mtx;
	struct pv_entry	*pvh_list;	/* head of list (locked by pvh_mtx) */
	u_int		pvh_attrs;	/* to preserve ref/mod */
};

#define	VM_MDPAGE_INIT(pg) do {				\
	mtx_init(&(pg)->mdpage.pvh_mtx, IPL_VM);	\
	(pg)->mdpage.pvh_list = NULL;			\
	(pg)->mdpage.pvh_attrs = 0;			\
} while (0)
#endif

#endif /* _MACHINE_PMAP_H_ */
@


1.50
log
@First stab at making the hppa mpsafe.  Not quite there yet though.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.49 2015/02/15 21:34:33 miod Exp $	*/
d33 1
a35 1
#include <sys/mutex.h>
@


1.49
log
@Change pmap_remove_holes() to take a vmspace instead of a map as its argument.

Use this on vax to correctly pick the end of the stack area now that the
stackgap adjustment code will no longer guarantee it is a fixed location.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.48 2015/02/11 06:43:27 dlg Exp $	*/
d35 1
d39 2
a40 2
	struct uvm_object pm_obj;	/* object (lck by object lock) */
#define	pm_lock	pm_obj.vmobjlock
d164 2
a165 1
	struct pv_entry	*pvh_list;	/* head of list (locked by pvh_lock) */
d170 1
@


1.48
log
@dont need lockmgr for pmap things, so we dont need sys/lock.h
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.47 2014/12/17 15:01:47 deraadt Exp $	*/
d120 1
a120 1
#define	pmap_remove_holes(map)		do { /* nothing */ } while (0)
@


1.47
log
@remove simplelocks
ok kettenis
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.46 2014/11/16 12:30:57 deraadt Exp $	*/
a160 3

#include <sys/lock.h>

@


1.46
log
@Replace a plethora of historical protection options with just
PROT_NONE, PROT_READ, PROT_WRITE, and PROT_EXEC from mman.h.
PROT_MASK is introduced as the one true way of extracting those bits.
Remove UVM_ADV_* wrapper, using the standard names.
ok doug guenther kettenis
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.45 2014/01/30 18:16:41 miod Exp $	*/
a165 1
	struct simplelock pvh_lock;	/* locks every pv on this list */
a170 1
	simple_lock_init(&(pg)->mdpage.pvh_lock);	\
@


1.45
log
@Move declaration of struct vm_page_md from <machine/vmparam.h> to
<machine/pmap.h> where it belongs, and compensate in <uvm/uvm_extern.h>
by including <uvm/uvm_pmap.h> before <uvm/uvm_page.h>. Tested on all
MACHINE_ARCH but amd64 and i386 (and hppa64).
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.44 2013/03/31 17:07:03 deraadt Exp $	*/
d139 2
a140 2
	if ((prot & UVM_PROT_WRITE) == 0) {
		if (prot & (UVM_PROT_RX))
d150 2
a151 2
	if ((prot & UVM_PROT_WRITE) == 0) {
		if (prot & (UVM_PROT_RX))
@


1.44
log
@try to avoid pulling in pte.h and other more crazy things.  Checked against
the things that libkvm needs.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.43 2011/11/14 14:29:53 deraadt Exp $	*/
d159 19
@


1.43
log
@merge various differences between hppa and hppa64
ok jsing
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.42 2011/05/07 15:27:01 oga Exp $	*/
a31 1
#include <machine/pte.h>
d35 1
@


1.42
log
@So long, uvm_pglist.h

This header defined three thing. two of which are unused throughout the tree,
the final one was the definition of the pagq head type, move that to uvm_page.h
and nuke the header

ok thib@@. Thanks to krw@@ for testing the hppa build for me.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.41 2011/04/28 20:42:28 ariane Exp $	*/
d123 2
a124 2
boolean_t pmap_changebit(struct vm_page *, u_int, u_int);
boolean_t pmap_testbit(struct vm_page *, u_int);
@


1.41
log
@Expose pmap_prefer parameters.
This will enable intelligent decisions with future uvm_map.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.40 2010/12/26 15:40:59 miod Exp $	*/
a32 1
#include <uvm/uvm_pglist.h>
@


1.40
log
@Kill pmap_phys_address(), and force every driver's mmap() routine to return
a physical address [more precisely, something suitable to pass to pmap_enter()'sphysical address argument].

This allows MI drivers to implement mmap() routines without having to know
about the pmap_phys_address() implementation and #ifdef obfuscation.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.39 2010/12/06 20:57:16 miod Exp $	*/
d103 5
@


1.39
log
@Change the signature of PMAP_PREFER from void PMAP_PREFER(..., vaddr_t *) to
vaddr_t PMAP_PREFER(..., vaddr_t). This allows better compiler optimization
when the function is inlined, and avoids accessing memory on architectures
when we can pass function arguments in registers.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.38 2010/11/18 21:21:36 miod Exp $	*/
a113 1
#define pmap_phys_address(ppn)	((ppn) << PAGE_SHIFT)
@


1.38
log
@Declare pmap_proc_iflush() in <uvm/uvm_pmap.h> unless <machine/pmap.h>
provides an inline version of it.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.37 2010/01/03 19:23:49 kettenis Exp $	*/
d94 9
a102 7
#define	PMAP_PREFER(o,h)	do {					\
	vaddr_t pmap_prefer_hint;					\
	pmap_prefer_hint = (*(h) & HPPA_PGAMASK) | ((o) & HPPA_PGAOFF);	\
	if (pmap_prefer_hint < *(h))					\
		pmap_prefer_hint += HPPA_PGALIAS;			\
	*(h) = pmap_prefer_hint;					\
} while(0)
@


1.37
log
@Implement pmap_proc_iflush() such that the instruction cache is synchronized
with the data cache when ptrace(2) is used to write into a process' address
space.

ok miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.36 2009/06/11 20:10:51 kettenis Exp $	*/
a122 1
void pmap_proc_iflush(struct proc *, vaddr_t, vsize_t);
@


1.36
log
@Correctly flush direct mappings (cache/tlb).  Uncovered by ariane's new
allocator.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.35 2007/12/14 18:32:23 deraadt Exp $	*/
a113 1
#define pmap_proc_iflush(p,va,len)	/* nothing */
d123 1
@


1.35
log
@Remove a lot of symbols from the namespace, otherwise sys/sysctl.h and
rpc/pmap_prot.h collide.. "struct pmap" from the kernel should not make
it out to userland.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.34 2007/09/10 18:49:44 miod Exp $	*/
d87 1
a87 1
#define	pmap_unmap_direct(va) PHYS_TO_VM_PAGE((paddr_t)(va))
@


1.34
log
@Introduce a md pmap hook, pmap_remove_holes(), which is supposed to mark
the holes a MMU may have from a given vm_map. This will be automagically
invoked for newly created vmspaces.

On platforms with MMU holes (e.g. sun4, sun4c and vax), this prevents
mmap(2) hints which would end up being in the hole to be accepted as valid,
causing unexpected signals when the process tries to access the hole
(since pmap can not fill the hole anyway).

Unfortunately, the logic mmap() uses to pick a valid address for anonymous
mappings needs work, as it will only try to find an address higher than the
hint, which causes all mmap() with a hint in the hole to fail on vax. This
will be improved later.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.33 2004/08/06 22:39:12 deraadt Exp $	*/
d36 2
a73 2

#ifdef	_KERNEL
@


1.33
log
@rename sparc kill_user_windows() to pmap_unuse_final().  provide empty stubs
on all other architectures.  remove last architecture dependent #ifdef from
uvm code.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.32 2004/07/13 14:51:29 tedu Exp $	*/
d116 1
@


1.32
log
@#define __HAVE_PMAP_DIRECT and use it.  requested by art
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.31 2004/06/09 20:17:23 tedu Exp $	*/
d115 1
@


1.31
log
@rename POOLPAGE macros to pmap_map_direct
break out uvm_km_page bits for this case, no thread here
lots of testing tech@@, deraadt@@, naddy@@, mickey@@, ...
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.30 2004/05/20 09:20:42 kettenis Exp $	*/
d88 1
@


1.30
log
@Properly flush instruction cache for ptrace(PT_WRTIE_{DI}, ...) on powerpc
and m68k.
ok drahn@@, millert@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.29 2004/04/21 22:14:34 mickey Exp $	*/
d86 2
a87 2
#define	PMAP_MAP_POOLPAGE(pg)	((vaddr_t)VM_PAGE_TO_PHYS(pg))
#define	PMAP_UNMAP_POOLPAGE(va) PHYS_TO_VM_PAGE((paddr_t)(va))
@


1.29
log
@put some volatile on volatiles
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.28 2004/04/07 18:24:19 mickey Exp $	*/
d112 2
@


1.28
log
@update copyright; miod@@ is fine w/ files where he holds it too
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.27 2003/01/22 18:16:35 mickey Exp $	*/
d41 1
a41 1
	u_int32_t	*pm_pdir;	/* page dir (read-only after create) */
@


1.27
log
@consistantly use uvm_prot_* vs vm_prot_* evewrhere
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.26 2002/11/07 19:22:56 mickey Exp $	*/
d4 1
a4 1
 * Copyright (c) 2002 Michael Shalayeff
a14 5
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *      This product includes software developed by Michael Shalayeff.
 * 4. The name of the author may not be used to endorse or promote products
 *    derived from this software without specific prior written permission.
@


1.26
log
@pmap_[de]activate() are not nops; w/ art@@'s help
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.25 2002/10/28 20:49:16 mickey Exp $	*/
d135 2
a136 2
	if ((prot & VM_PROT_WRITE) == 0) {
		if (prot & (VM_PROT_READ|VM_PROT_EXECUTE))
d146 2
a147 2
	if ((prot & VM_PROT_WRITE) == 0) {
		if (prot & (VM_PROT_READ|VM_PROT_EXECUTE))
@


1.25
log
@do not use asm for accessing the page tables since they are mapped now.
fix ptp accounting and move diagnostic check in pmap_destroy()
into a DIAGNOSTIC and it has not caught a one problem so far.
when random-allocating the space ids use linear rehashing instead
of a full new random which produces a better cache locality.
miod@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.24 2002/10/17 02:21:08 mickey Exp $	*/
a109 2
#define	pmap_activate(pm)		(void)(pm)
#define	pmap_deactivate(pm)		(void)(pm)
@


1.24
log
@convert to use vm_page_md instead of pmap_physseg, make code smaller and simpler, indeed; after art's suggestion and by looking into his diffs oneyed
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.23 2002/09/12 12:50:47 art Exp $	*/
d46 1
a46 1
	paddr_t		pm_pdir;	/* PA of PD (read-only after create) */
@


1.23
log
@Change the PMAP_{MAP,UNMAP}_POOLPAGE api to take a vm_page as argument
and return a VM_PAGE. This is to allow sparc64 to cheaply record the
VAC color for those pages.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.22 2002/09/05 18:41:19 mickey Exp $	*/
a61 8

struct pv_entry;

struct pv_head {
	struct simplelock pvh_lock;	/* locks every pv on this list */
	struct pv_entry	*pvh_list;	/* head of list (locked by pvh_lock) */
	pt_entry_t	pvh_attrs;	/* to preserve ref/mod */
};
@


1.22
log
@move the kernel virtual away from the physical addresses
and equivalently map the whole physical.
this allows a lot of simplification in how kernel
deals w/ page tables and physical pages.
avoid series of bugs related to that.
check for aliased mappings (none found so far),
and properly flush/purge pages on zero/copy.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.21 2002/05/09 17:45:24 mickey Exp $	*/
d99 2
a100 2
#define	PMAP_MAP_POOLPAGE(pa)	((vaddr_t)(pa))
#define	PMAP_UNMAP_POOLPAGE(va) ((paddr_t)(va))
@


1.21
log
@sid max should be such that after conversion into prot-id it will not overflow
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.20 2002/04/22 06:31:28 mickey Exp $	*/
d97 6
d147 1
a147 2
			(void) pmap_changebit(pg, PTE_PROT(TLB_READ),
			    PTE_PROT(TLB_WRITE));
@


1.20
log
@forgot this, no steal anymore
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.19 2002/03/15 21:44:18 mickey Exp $	*/
d55 1
a55 1
#define	HPPA_SID_MAX	0x7fff
@


1.19
log
@rewrite a pmap to use multilevel page tables.
lower 12 bits contain the perms, no unused bits left,
but a couple for off-tlb use (as the ref implemented now).
do not use the hvt, which might get some use later
if proven to speed thigs up, tlb handlers would po
another dozen of insns though, but if that's worth its...
move on the data seg and map kernel text rdonly (idea form fredette),
since all of the page0 mods done before that we are all fine
except for some viper fluff, but later w/ that.
this also picks up a bit more of ddb magic for bpt and ss.
tlb handlers can use a little bit more of attention,
but things, visually, seem to be much faster already, --
sorry, no benchmarks for now.

* effort sponsored in part by the `henry st. old ale house'
* and mr.pete and mr.lee in particular in thier generous entrirety.
* the proj took a little more that 72man*h as it was expected,
* but within murhy's law estimations.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.18 2002/03/14 01:26:32 millert Exp $	*/
a94 2

#define	PMAP_STEAL_MEMORY	/* we have some memory to steal */
@


1.18
log
@First round of __P removal in sys
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.17 2002/02/21 06:12:31 mickey Exp $	*/
d4 1
a4 1
 * Copyright (c) 1998,1999 Michael Shalayeff
d17 1
a17 1
 *	This product includes software developed by Michael Shalayeff.
d24 8
a31 50
 * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,
 * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
 * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
 * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
 * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF
 * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */
/*
 * Copyright 1996 1995 by Open Software Foundation, Inc.   
 *              All Rights Reserved 
 *  
 * Permission to use, copy, modify, and distribute this software and 
 * its documentation for any purpose and without fee is hereby granted, 
 * provided that the above copyright notice appears in all copies and 
 * that both the copyright notice and this permission notice appear in 
 * supporting documentation. 
 *  
 * OSF DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE 
 * INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS 
 * FOR A PARTICULAR PURPOSE. 
 *  
 * IN NO EVENT SHALL OSF BE LIABLE FOR ANY SPECIAL, INDIRECT, OR 
 * CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM 
 * LOSS OF USE, DATA OR PROFITS, WHETHER IN ACTION OF CONTRACT, 
 * NEGLIGENCE, OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION 
 * WITH THE USE OR PERFORMANCE OF THIS SOFTWARE. 
 */
/* 
 * Copyright (c) 1990,1993,1994 The University of Utah and
 * the Computer Systems Laboratory at the University of Utah (CSL).
 * All rights reserved.
 *
 * Permission to use, copy, modify and distribute this software is hereby
 * granted provided that (1) source code retains these copyright, permission,
 * and disclaimer notices, and (2) redistributions including binaries
 * reproduce the notices in supporting documentation, and (3) all advertising
 * materials mentioning features or use of this software display the following
 * acknowledgement: ``This product includes software developed by the
 * Computer Systems Laboratory at the University of Utah.''
 *
 * THE UNIVERSITY OF UTAH AND CSL ALLOW FREE USE OF THIS SOFTWARE IN ITS "AS
 * IS" CONDITION.  THE UNIVERSITY OF UTAH AND CSL DISCLAIM ANY LIABILITY OF
 * ANY KIND FOR ANY DAMAGES WHATSOEVER RESULTING FROM THE USE OF THIS SOFTWARE.
 *
 * CSL requests users of this software to return to csl-dist@@cs.utah.edu any
 * improvements that they make and grant CSL redistribution rights.
 *
 * 	Utah $Hdr: pmap.h 1.24 94/12/14$
 *	Author: Mike Hibler, Bob Wheeler, University of Utah CSL, 9/90
d34 2
a35 6
/*
 *	Pmap header for hppa.
 */

#ifndef	_MACHINE_PMAP_H_
#define	_MACHINE_PMAP_H_
d38 2
a40 1
typedef
d42 7
a48 7
	TAILQ_ENTRY(pmap)	pmap_list;	/* pmap free list */
	struct simplelock	pmap_lock;	/* lock on map */
	int			pmap_refcnt;	/* reference count */
	pa_space_t		pmap_space;	/* space for this pmap */
	struct pmap_statistics	pmap_stats;	/* statistics */
} *pmap_t;
extern pmap_t	kernel_pmap;			/* The kernel's map */
d50 1
a50 17
/*
 * If HPT is defined, we cache the last miss for each bucket using a
 * structure defined for the 7100 hardware TLB walker. On non-7100s, this
 * acts as a software cache that cuts down on the number of times we have
 * to search the hash chain. (thereby reducing the number of instructions
 * and cache misses incurred during the TLB miss).
 *
 * The pv_entry pointer is the address of the associated hash bucket
 * list for fast tlbmiss search.
 */
struct hpt_entry {
	u_int	hpt_valid:1,	/* Valid bit */
		hpt_vpn:15,	/* Virtual Page Number */
		hpt_space:16;	/* Space ID */
	u_int	hpt_tlbprot;	/* prot/access rights (for TLB load) */
	u_int	hpt_tlbpage;	/* physical page (<<5 for TLB load) */
	void	*hpt_entry;	/* Pointer to associated hash list */
d52 12
a63 3
#ifdef _KERNEL
extern struct hpt_entry *hpt_table;
#endif /* _KERNEL */
d65 4
a68 13
/*
 * keep it at 32 bytes for the cache overall satisfaction
 * also, align commonly used pairs on double-word boundary
 */
struct pv_entry {
	struct pv_entry	*pv_next;	/* list of mappings of a given PA */
	pmap_t		pv_pmap;	/* back link to pmap */
	u_int		pv_va;		/* virtual page number */
	u_int		pv_space;	/* copy of space id from pmap */
	u_int		pv_tlbpage;	/* physical page (for TLB load) */
	u_int		pv_tlbprot;	/* TLB format protection */
	struct pv_entry *pv_hash;	/* VTOP hash bucket list */
	u_int		pv_pad;		/* pad to 32 bytes */
d71 5
a75 8
#define NPVPPG (NBPG/32-1)
struct pv_page {
	TAILQ_ENTRY(pv_page) pvp_list;	/* Chain of pages */
	u_int		pvp_nfree;
	struct pv_entry *pvp_freelist;
	u_int		pvp_flag;	/* is it direct mapped (unused) */ 
	u_int		pvp_pad[3];	/* align to 32 */
	struct pv_entry pvp_pv[NPVPPG];
d78 7
a84 3
#define HPPA_SID_MAX	0x7fff
#define	HPPA_SID_KERNEL	0
#define	HPPA_PID_KERNEL	2
d86 1
a86 1
#define KERNEL_ACCESS_ID 1
d88 2
a89 2
#define KERNEL_TEXT_PROT (TLB_AR_KRX | (KERNEL_ACCESS_ID << 1))
#define KERNEL_DATA_PROT (TLB_AR_KRW | (KERNEL_ACCESS_ID << 1))
d91 4
a94 2
#ifdef _KERNEL
extern void gateway_page(void);
a109 3
#define pmap_kernel_va(VA)	\
	(((VA) >= VM_MIN_KERNEL_ADDRESS) && ((VA) <= VM_MAX_KERNEL_ADDRESS))

d111 5
a115 10
#define pmap_kernel()			(kernel_pmap)
#define	pmap_resident_count(pmap)	((pmap)->pmap_stats.resident_count)
#define pmap_reference(pmap) \
do { if (pmap) { \
	simple_lock(&pmap->pmap_lock); \
	pmap->pmap_refcnt++; \
	simple_unlock(&pmap->pmap_lock); \
} } while (0)
#define pmap_collect(pmap)
#define pmap_release(pmap)
a116 3
#define	pmap_update(pm)
#define	pmap_activate(p)
#define	pmap_deactivate(p)
d118 12
a129 2
#define pmap_phys_address(x)	((x) << PGSHIFT)
#define pmap_phys_to_frame(x)	((x) >> PGSHIFT)
d134 25
a158 2
	extern u_int kern_prot[], user_prot[];
	return (pmap == kernel_pmap? kern_prot: user_prot)[prot];
a160 1
void pmap_bootstrap(vaddr_t *, vaddr_t *);
a161 1

@


1.17
log
@pmap.pmap_pd is redundant -- no more
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.16 2002/01/10 01:23:08 mickey Exp $	*/
d152 1
a152 1
extern void gateway_page __P((void));
d197 1
a197 1
void pmap_bootstrap __P((vaddr_t *, vaddr_t *));
@


1.16
log
@cache_align is not used
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.15 2001/12/04 23:22:42 art Exp $	*/
a90 1
	u_int			pmap_pid;	/* protection id for pmap */
d142 1
a142 1
#define HPPA_MAX_PID	0xfffa
d171 1
@


1.15
log
@Yet another sync to NetBSD uvm.
Today we add a pmap argument to pmap_update() and allocate map entries for
kernel_map from kmem_map instead of using the static entries. This should
get rid of MAX_KMAPENT panics. Also some uvm_loan problems are fixed.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.14 2001/05/09 15:31:24 art Exp $	*/
a152 3
#define cache_align(x)	(((x) + dcache_line_mask) & ~(dcache_line_mask))
extern int dcache_line_mask;

@


1.15.2.1
log
@Merge in -current, builds on i386, otherwise untested
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.16 2002/01/10 01:23:08 mickey Exp $	*/
d153 3
@


1.15.2.2
log
@Sync UBC branch to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.15.2.1 2002/01/31 22:55:09 niklas Exp $	*/
d4 1
a4 1
 * Copyright (c) 2002 Michael Shalayeff
d17 1
a17 1
 *      This product includes software developed by Michael Shalayeff.
d24 54
a77 8
 * IN NO EVENT SHALL THE AUTHOR OR HIS RELATIVES BE LIABLE FOR ANY DIRECT,
 * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
 * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 * SERVICES; LOSS OF MIND, USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,
 * STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING
 * IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
 * THE POSSIBILITY OF SUCH DAMAGE.
d80 2
a81 2
#ifndef _MACHINE_PMAP_H_
#define _MACHINE_PMAP_H_
a83 2
#include <uvm/uvm_pglist.h>
#include <uvm/uvm_object.h>
d85 1
d87 8
a94 7
	struct uvm_object pm_obj;	/* object (lck by object lock) */
#define	pm_lock	pm_obj.vmobjlock
	struct vm_page	*pm_ptphint;
	struct vm_page	*pm_pdir_pg;	/* vm_page for pdir */
	paddr_t		pm_pdir;	/* PA of PD (read-only after create) */
	pa_space_t	pm_space;	/* space id (read-only after create) */
	u_int		pm_pid;		/* prot id (read-only after create) */
d96 17
a112 1
	struct pmap_statistics	pm_stats;
d114 3
a116 1
typedef struct pmap *pmap_t;
d118 14
a131 4
#define HPPA_MAX_PID    0xfffa
#define	HPPA_SID_MAX	0x7ffd
#define HPPA_SID_KERNEL 0
#define HPPA_PID_KERNEL 2
d133 8
a140 10
#define KERNEL_ACCESS_ID 1
#define KERNEL_TEXT_PROT (TLB_AR_KRX | (KERNEL_ACCESS_ID << 1))
#define KERNEL_DATA_PROT (TLB_AR_KRW | (KERNEL_ACCESS_ID << 1))

struct pv_entry;

struct pv_head {
	struct simplelock pvh_lock;	/* locks every pv on this list */
	struct pv_entry	*pvh_list;	/* head of list (locked by pvh_lock) */
	pt_entry_t	pvh_attrs;	/* to preserve ref/mod */
d143 3
a145 6
struct pv_entry {			/* locked by its list's pvh_lock */
	struct pv_entry	*pv_next;
	struct pmap	*pv_pmap;	/* the pmap */
	vaddr_t		pv_va;		/* the virtual address */
	struct vm_page	*pv_ptp;	/* the vm_page of the PTP */
};
d147 1
a147 7
/* also match the hardware tlb walker definition */
struct vp_entry {
	u_int	vp_tag;
	u_int	vp_tlbprot;
	u_int	vp_tlbpage;
	u_int	vp_ptr;
};
d149 2
a150 1
#ifdef	_KERNEL
d152 2
a153 2
extern void gateway_page(void);
extern struct pmap kernel_pmap_store;
d155 1
a155 4
#if defined(HP7100LC_CPU) || defined(HP7300LC_CPU)
extern int pmap_hptsize;
extern struct pdc_hwtlb pdc_hwtlb;
#endif
d169 13
a181 6
#define	pmap_sid2pid(s)			(((s) + 1) << 1)
#define pmap_kernel()			(&kernel_pmap_store)
#define	pmap_resident_count(pmap)	((pmap)->pm_stats.resident_count)
#define	pmap_update(pm)			(void)(pm)
#define	pmap_activate(pm)		(void)(pm)
#define	pmap_deactivate(pm)		(void)(pm)
d183 3
d187 2
a188 12
#define pmap_clear_modify(pg)	pmap_changebit(pg, 0, PTE_PROT(TLB_DIRTY))
#define pmap_clear_reference(pg) pmap_changebit(pg, PTE_PROT(TLB_REFTRAP), 0)
#define pmap_is_modified(pg)	pmap_testbit(pg, PTE_PROT(TLB_DIRTY))
#define pmap_is_referenced(pg)	pmap_testbit(pg, PTE_PROT(TLB_REFTRAP))
#define pmap_phys_address(ppn)	((ppn) << PAGE_SHIFT)

void pmap_bootstrap(vaddr_t);
boolean_t pmap_changebit(struct vm_page *, u_int, u_int);
boolean_t pmap_testbit(struct vm_page *, u_int);
void pmap_write_protect(struct pmap *, vaddr_t, vaddr_t, vm_prot_t);
void pmap_remove(struct pmap *pmap, vaddr_t sva, vaddr_t eva);
void pmap_page_remove(struct vm_page *pg);
d193 2
a194 2
	extern u_int hppa_prot[];
	return (hppa_prot[prot] | (pmap == pmap_kernel()? 0 : TLB_USER));
d197 2
a198 11
static __inline void
pmap_page_protect(struct vm_page *pg, vm_prot_t prot)
{
	if ((prot & VM_PROT_WRITE) == 0) {
		if (prot & (VM_PROT_READ|VM_PROT_EXECUTE))
			(void) pmap_changebit(pg, PTE_PROT(TLB_READ),
			    PTE_PROT(TLB_WRITE));
		else
			pmap_page_remove(pg);
	}
}
a199 12
static __inline void
pmap_protect(struct pmap *pmap, vaddr_t sva, vaddr_t eva, vm_prot_t prot)
{
	if ((prot & VM_PROT_WRITE) == 0) {
		if (prot & (VM_PROT_READ|VM_PROT_EXECUTE))
			pmap_write_protect(pmap, sva, eva, prot);
		else
			pmap_remove(pmap, sva, eva);
	}
}

#endif /* _KERNEL */
@


1.15.2.3
log
@sync to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.15.2.2 2002/06/11 03:35:37 art Exp $	*/
d46 1
a46 1
	u_int32_t	*pm_pdir;	/* page dir (read-only after create) */
d63 8
a96 6
 * pool quickmaps
 */
#define	PMAP_MAP_POOLPAGE(pg)	((vaddr_t)VM_PAGE_TO_PHYS(pg))
#define	PMAP_UNMAP_POOLPAGE(va) PHYS_TO_VM_PAGE((paddr_t)(va))

/*
d141 2
a142 1
			pmap_changebit(pg, 0, PTE_PROT(TLB_WRITE));
@


1.15.2.4
log
@sync
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d110 2
d137 2
a138 2
	if ((prot & UVM_PROT_WRITE) == 0) {
		if (prot & (UVM_PROT_RX))
d148 2
a149 2
	if ((prot & UVM_PROT_WRITE) == 0) {
		if (prot & (UVM_PROT_RX))
@


1.14
log
@More sync to NetBSD.

 - Change pmap_change_wiring to pmap_unwire because it's only called that way.
 - Remove pmap_pageable because it's seldom implemented and when it is, it's
   either almost useless or incorrect. The same information is already passed
   to the pmap anyway by pmap_enter and pmap_unwire.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.13 2001/01/12 23:37:01 mickey Exp $	*/
d186 1
a186 1
#define	pmap_update()
@


1.13
log
@move pmap_physseg back to vmparam.h where it belongs.
define PMAP_PREFER in pmap.h, as afar as i understand it works.
no more pmap_changebit()
grow USRIOSIZE in vmparam.h
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.12 1999/12/12 03:16:26 mickey Exp $	*/
a184 1
#define pmap_pageable(pmap, start, end, pageable)
@


1.12
log
@do homebrew pmap_changebit pmap_new way
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.11 1999/12/09 01:49:43 mickey Exp $	*/
a142 4
struct pmap_physseg {
	struct pv_entry *pvent;
};

d160 12
a201 1
void pmap_changebit __P((vm_page_t, u_int, u_int));
@


1.12.2.1
log
@Update the SMP branch to -current, this breaks the SMP branch though.
But it will be fixed soonish.  Note, nothing new has happened, this is just
a merge of the trunk into this branch.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.13 2001/01/12 23:37:01 mickey Exp $	*/
d143 4
a163 12
/*
 * according to the parisc manual aliased va's should be
 * different by high 12 bits only.
 */
#define	PMAP_PREFER(o,h)	do {					\
	vaddr_t pmap_prefer_hint;					\
	pmap_prefer_hint = (*(h) & HPPA_PGAMASK) | ((o) & HPPA_PGAOFF);	\
	if (pmap_prefer_hint < *(h))					\
		pmap_prefer_hint += HPPA_PGALIAS;			\
	*(h) = pmap_prefer_hint;					\
} while(0)

d194 1
@


1.12.2.2
log
@Merge in -current from two days ago in the SMP branch.
As usual with merges, they do not indicate progress, so do not hold
your breath for working SMP, and do not mail me and ask about the
state of it.  It has not changed.  There is work ongoing, but very, very
slowly.  The commit is done in parts as to not lock up the tree in too
big chunks at a time.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.12.2.1 2001/04/18 16:06:27 niklas Exp $	*/
d185 1
@


1.12.2.3
log
@Merge in trunk
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d91 1
d143 1
a143 1
#define HPPA_SID_MAX	0x7fff
d153 3
a174 1
#define	pmap_sid2pid(s)			(((s) + 1) << 1)
d186 1
a186 1
#define	pmap_update(pm)
@


1.12.2.4
log
@Merge in -current from about a week ago
@
text
@d4 1
a4 1
 * Copyright (c) 2002 Michael Shalayeff
d17 1
a17 1
 *      This product includes software developed by Michael Shalayeff.
d24 54
a77 8
 * IN NO EVENT SHALL THE AUTHOR OR HIS RELATIVES BE LIABLE FOR ANY DIRECT,
 * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
 * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 * SERVICES; LOSS OF MIND, USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,
 * STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING
 * IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
 * THE POSSIBILITY OF SUCH DAMAGE.
d80 2
a81 2
#ifndef _MACHINE_PMAP_H_
#define _MACHINE_PMAP_H_
a83 2
#include <uvm/uvm_pglist.h>
#include <uvm/uvm_object.h>
d85 1
d87 7
a93 7
	struct uvm_object pm_obj;	/* object (lck by object lock) */
#define	pm_lock	pm_obj.vmobjlock
	struct vm_page	*pm_ptphint;
	struct vm_page	*pm_pdir_pg;	/* vm_page for pdir */
	paddr_t		pm_pdir;	/* PA of PD (read-only after create) */
	pa_space_t	pm_space;	/* space id (read-only after create) */
	u_int		pm_pid;		/* prot id (read-only after create) */
d95 17
a111 1
	struct pmap_statistics	pm_stats;
d113 3
a115 1
typedef struct pmap *pmap_t;
d117 13
a129 15
#define HPPA_MAX_PID    0xfffa
#define	HPPA_SID_MAX	0x7fff
#define HPPA_SID_KERNEL 0
#define HPPA_PID_KERNEL 2

#define KERNEL_ACCESS_ID 1
#define KERNEL_TEXT_PROT (TLB_AR_KRX | (KERNEL_ACCESS_ID << 1))
#define KERNEL_DATA_PROT (TLB_AR_KRW | (KERNEL_ACCESS_ID << 1))

struct pv_entry;

struct pv_head {
	struct simplelock pvh_lock;	/* locks every pv on this list */
	struct pv_entry	*pvh_list;	/* head of list (locked by pvh_lock) */
	pt_entry_t	pvh_attrs;	/* to preserve ref/mod */
d132 8
a139 5
struct pv_entry {			/* locked by its list's pvh_lock */
	struct pv_entry	*pv_next;
	struct pmap	*pv_pmap;	/* the pmap */
	vaddr_t		pv_va;		/* the virtual address */
	struct vm_page	*pv_ptp;	/* the vm_page of the PTP */
d142 3
a144 7
/* also match the hardware tlb walker definition */
struct vp_entry {
	u_int	vp_tag;
	u_int	vp_tlbprot;
	u_int	vp_tlbpage;
	u_int	vp_ptr;
};
d146 1
a146 1
#ifdef	_KERNEL
d148 2
a149 2
extern void gateway_page(void);
extern struct pmap kernel_pmap_store;
d151 2
a152 4
#if defined(HP7100LC_CPU) || defined(HP7300LC_CPU)
extern int pmap_hptsize;
extern struct pdc_hwtlb pdc_hwtlb;
#endif
d168 3
d172 10
a181 5
#define pmap_kernel()			(&kernel_pmap_store)
#define	pmap_resident_count(pmap)	((pmap)->pm_stats.resident_count)
#define	pmap_update(pm)			(void)(pm)
#define	pmap_activate(pm)		(void)(pm)
#define	pmap_deactivate(pm)		(void)(pm)
d183 3
d187 2
a188 12
#define pmap_clear_modify(pg)	pmap_changebit(pg, 0, PTE_PROT(TLB_DIRTY))
#define pmap_clear_reference(pg) pmap_changebit(pg, PTE_PROT(TLB_REFTRAP), 0)
#define pmap_is_modified(pg)	pmap_testbit(pg, PTE_PROT(TLB_DIRTY))
#define pmap_is_referenced(pg)	pmap_testbit(pg, PTE_PROT(TLB_REFTRAP))
#define pmap_phys_address(ppn)	((ppn) << PAGE_SHIFT)

void pmap_bootstrap(vaddr_t);
boolean_t pmap_changebit(struct vm_page *, u_int, u_int);
boolean_t pmap_testbit(struct vm_page *, u_int);
void pmap_write_protect(struct pmap *, vaddr_t, vaddr_t, vm_prot_t);
void pmap_remove(struct pmap *pmap, vaddr_t sva, vaddr_t eva);
void pmap_page_remove(struct vm_page *pg);
d193 2
a194 2
	extern u_int hppa_prot[];
	return (hppa_prot[prot] | (pmap == pmap_kernel()? 0 : TLB_USER));
d197 2
a198 11
static __inline void
pmap_page_protect(struct vm_page *pg, vm_prot_t prot)
{
	if ((prot & VM_PROT_WRITE) == 0) {
		if (prot & (VM_PROT_READ|VM_PROT_EXECUTE))
			(void) pmap_changebit(pg, PTE_PROT(TLB_READ),
			    PTE_PROT(TLB_WRITE));
		else
			pmap_page_remove(pg);
	}
}
a199 12
static __inline void
pmap_protect(struct pmap *pmap, vaddr_t sva, vaddr_t eva, vm_prot_t prot)
{
	if ((prot & VM_PROT_WRITE) == 0) {
		if (prot & (VM_PROT_READ|VM_PROT_EXECUTE))
			pmap_write_protect(pmap, sva, eva, prot);
		else
			pmap_remove(pmap, sva, eva);
	}
}

#endif /* _KERNEL */
@


1.12.2.5
log
@Sync the SMP branch with 3.3
@
text
@d46 1
a46 1
	u_int32_t	*pm_pdir;	/* page dir (read-only after create) */
d55 1
a55 1
#define	HPPA_SID_MAX	0x7ffd
d63 8
d96 1
a96 5
/*
 * pool quickmaps
 */
#define	PMAP_MAP_POOLPAGE(pg)	((vaddr_t)VM_PAGE_TO_PHYS(pg))
#define	PMAP_UNMAP_POOLPAGE(va) PHYS_TO_VM_PAGE((paddr_t)(va))
d114 2
d141 4
a144 3
	if ((prot & UVM_PROT_WRITE) == 0) {
		if (prot & (UVM_PROT_RX))
			pmap_changebit(pg, 0, PTE_PROT(TLB_WRITE));
d153 2
a154 2
	if ((prot & UVM_PROT_WRITE) == 0) {
		if (prot & (UVM_PROT_RX))
@


1.12.2.6
log
@Merge with the trunk
@
text
@d4 1
a4 1
 * Copyright (c) 2002-2004 Michael Shalayeff
d15 5
d46 1
a46 1
	volatile u_int32_t *pm_pdir;	/* page dir (read-only after create) */
a116 2

#define pmap_proc_iflush(p,va,len)	/* nothing */
@


1.12.2.7
log
@sync with head, make i386 __HAVE_CPUINFO
@
text
@d86 2
a87 2
#define	pmap_map_direct(pg)	((vaddr_t)VM_PAGE_TO_PHYS(pg))
#define	pmap_unmap_direct(va) PHYS_TO_VM_PAGE((paddr_t)(va))
@


1.11
log
@first arg to pmap_changebit is paddr_t
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.10 1999/11/16 16:42:29 mickey Exp $	*/
d194 1
a194 1
void pmap_changebit __P((paddr_t, u_int, u_int));
@


1.10
log
@hpt_hashsize no more, using cr24 instead
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.9 1999/07/21 05:38:03 mickey Exp $	*/
d194 1
a194 1
void pmap_changebit __P((vaddr_t, u_int, u_int));
@


1.9
log
@better fields order for pv_entry
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.8 1999/04/20 19:29:12 mickey Exp $	*/
a115 1
extern u_int hpt_hashsize;
@


1.8
log
@uvm names and definitions
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.7 1999/01/20 19:39:53 mickey Exp $	*/
d4 1
a4 1
 * Copyright (c) 1998 Michael Shalayeff
a84 6
/*
 * This hash function is the one used by the hardware TLB walker on the 7100.
 */
#define pmap_hash(space, va) \
	((((u_int)(space) << 5) ^ (((u_int)va) >> 12)) & (hpt_hashsize-1))

d119 4
a122 1
/* keep it at 32 bytes for the cache overall satisfaction */
a124 1
	struct pv_entry *pv_hash;	/* VTOP hash bucket list */
d126 1
d128 1
a128 1
	u_int		pv_va;		/* virtual page number */
d130 1
a130 1
	u_int		pv_tlbpage;	/* physical page (for TLB load) */
d139 1
a139 1
	u_int		pvp_flag;	/* is it direct mapped */ 
@


1.7
log
@s/MAX_PID/HPPA_MAX_PID/g
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap.h,v 1.6 1999/01/20 19:29:51 mickey Exp $	*/
d164 2
d184 2
a185 2
#define	pmap_activate(pmap, pcb)
#define	pmap_deactivate(pmap, pcb)
d197 2
a198 2
void pmap_bootstrap __P((vm_offset_t *, vm_offset_t *));
void pmap_changebit __P((vm_offset_t, u_int, u_int));
@


1.6
log
@cleanup some rudimentaries
@
text
@d1 1
a1 1
/* $OpenBSD: pmap.h,v 1.5 1999/01/03 04:01:35 mickey Exp $ */
d4 29
a84 4
#define EQUIV_HACK	/* no multiple mapping of kernel equiv space allowed */

#define BTLB		/* Use block TLBs: PA 1.1 and above */

d151 1
a151 1
#define MAX_PID		0xfffa
@


1.5
log
@add pmap_changebit(); fix pmap_enter() so it handles mapping's PA changes
@
text
@d1 1
a1 1
/* $OpenBSD: pmap.h,v 1.4 1998/11/23 03:28:22 mickey Exp $ */
d109 1
a109 1
	u_int		pv_tlbsw;
@


1.4
log
@proper m-include protection, some minor cleanups
@
text
@d1 1
a1 1
/* $OpenBSD: pmap.h,v 1.3 1998/09/12 03:14:49 mickey Exp $ */
d171 1
@


1.3
log
@typos, thinkos, brainos, buritos and amigos
@
text
@d1 1
a1 1
/* $OpenBSD: pmap.h,v 1.2 1998/08/20 15:50:59 mickey Exp $ */
d51 2
a52 2
#ifndef	_HPPA_PMAP_H_
#define	_HPPA_PMAP_H_
d170 1
a170 6
/* 
 * prototypes.
 */
vm_offset_t kvtophys __P((vm_offset_t addr));
vm_offset_t pmap_map __P((vm_offset_t, vm_offset_t, vm_offset_t, vm_prot_t));
void pmap_bootstrap __P((vm_offset_t *,	vm_offset_t *));
d173 1
a173 1
#endif /* _HPPA_PMAP_H_ */
@


1.2
log
@some pmap definitions
@
text
@d1 1
a1 1
/* $OpenBSD$ */
d54 2
a58 1
#define USEALIGNMENT	/* Take advantage of cache alignment for optimization*/
d64 1
a64 1
	((((u_int)(space) << 5) ^ btop(va)) & (hpt_hashsize-1))
d92 1
a92 1
	u_int	hpt_tlbpage;	/* physical page (for TLB load) */
d100 1
a100 1
/* keep it under 32 bytes for the cache sake */
a103 1
	struct pv_entry	*pv_writer;	/* mapping with R/W access XXX */
d105 1
a105 1
#define pv_space pv_pmap->pmap_space
d112 1
a112 1
#define NPVPPG 127
d117 2
a118 1
	u_int		pvp_pad[4];	/* align to 32 */
d122 4
d135 3
a137 5
/* Block TLB flags */
#define BLK_ICACHE	0
#define BLK_DCACHE	1
#define BLK_COMBINED	2
#define BLK_LCOMBINED	3
d139 1
a139 1
#define cache_align(x)		(((x) + 64) & ~(64 - 1))
a140 1
#ifdef _KERNEL
d163 7
d174 2
a175 6
vm_offset_t pmap_map __P((vm_offset_t va, vm_offset_t spa,
				 vm_offset_t epa, vm_prot_t prot));
void pmap_bootstrap __P((vm_offset_t *avail_start,
				vm_offset_t *avail_end));
void pmap_block_map __P((vm_offset_t pa, vm_size_t size, vm_prot_t prot,
				int entry, int dtlb));
@


1.1
log
@more includes
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d3 20
a53 2
#include <sys/queue.h>

a55 1
#ifdef hp700
d57 1
a57 12
#define HPT		/* Hashed (Hardware) Page Table */
#define USEALIGNMENT	/* Take advantage of cache alignment for optimization */
#endif

/*
 * Virtual to physical mapping macros/structures.
 * IMPORTANT NOTE: there is one mapping per HW page, not per MACH page.
 */

#define HPPA_HASHSIZE		4096	/* size of hash table */
#define HPPA_HASHSIZE_LOG2	12
#define HPPA_MIN_MPP		2	/* min # of mappings per phys page */
d62 2
a63 23
#define pmap_hash(space, offset) \
	(((u_int)(space) << 5 ^ (u_int)(offset) >> PGSHIFT) & (HPPA_HASHSIZE-1))

/*
 * Do not change these structures unless you change the assembly code in
 * locore.s
 */
struct mapping {
	TAILQ_ENTRY(mapping) hash_link;	/* hash table links */
	TAILQ_ENTRY(mapping) phys_link;	/* for mappings of a given PA */
	pa_space_t	map_space;	/* virtual space */
	vm_offset_t	map_offset;	/* virtual page number */
	u_int		map_tlbpage;	/* physical page (for TLB load) */
	u_int		map_tlbprot;	/* prot/access rights (for TLB load) */
	u_int		map_tlbsw;	/* */
};

/* XXX could be in vm_param.h */

#define HPPA_QUADBYTES		0x40000000
#define	hppa_round_quad(x)	((((unsigned)(x)) + HPPA_QUADBYTES-1) & \
					~(HPPA_QUADBYTES-1))
#define hppa_trunc_quad(x)	(((unsigned)(x)) & ~(HPPA_QUADBYTES-1))
d65 1
d67 8
a74 10
	simple_lock_data_t	lock;	     /* lock on pmap */
	int			ref_count;   /* reference count */
	pa_space_t		space;	     /* space for this pmap */
	int			pid;	     /* protection id for pmap */
	struct pmap		*next;	     /* linked list of free pmaps */
	struct pmap_statistics	stats;	     /* statistics */
	TAILQ_ENTRY(pmap)	pmap_link;   /* hashed list of pmaps */
};

typedef struct pmap *pmap_t;
a75 17
extern struct pmap	kernel_pmap_store;


struct vtop_entry {
	TAILQ_HEAD(, mapping)	hash_link;	/* head of vtop chain */
};
#define vtop_next	hash_link.tqe_next
#define vtop_prev	hash_link.tqe_prev

struct phys_entry {
	TAILQ_HEAD(, mapping) phys_link; /* head of mappings of a given PA */
	struct mapping	*writer;	/* mapping with R/W access */
	unsigned	tlbprot;	/* TLB format protection */
};


#ifdef 	HPT
d80 1
a80 1
 * to search the vtop chain. (thereby reducing the number of instructions
d83 2
a84 3
 * The vtop_entry pointer is the address of the associated vtop table entry.
 * This avoids having to reform the address into the new table on a cache
 * miss.
d87 23
a109 6
	unsigned	valid:1,	/* Valid bit */
			vpn:15,		/* Virtual Page Number */
			space:16;	/* Space ID */
	unsigned	tlbprot;	/* prot/access rights (for TLB load) */
	unsigned	tlbpage;	/* physical page (for TLB load) */
	unsigned	vtop_entry;	/* Pointer to associated VTOP entry */
a110 1
#endif
d112 8
a119 4
#define HPT_SHIFT	27		/* 16 byte entry (31-4) */
#define VTOP_SHIFT	28		/* 8  byte entry (31-3) */
#define HPT_LEN		HPPA_HASHSIZE_LOG2
#define VTOP_LEN	HPPA_HASHSIZE_LOG2
d122 2
a123 2
#define	HPPA_SID_KERNEL  0
#define	HPPA_PID_KERNEL  2
a126 1

d136 17
a152 3
#define pmap_kernel()			(&kernel_pmap_store)
#define	pmap_resident_count(pmap)	((pmap)->stats.resident_count)
#define pmap_remove_attributes(pmap,start,end)
d155 2
d161 11
a171 1
#define cache_align(x)		(((x) + 64) & ~(64 - 1))
d173 1
a173 1
#endif	/* _HPPA_PMAP_H_ */
@

