head	1.64;
access;
symbols
	OPENBSD_5_1_BASE:1.63
	OPENBSD_5_1:1.63.0.8
	OPENBSD_5_0:1.63.0.6
	OPENBSD_5_0_BASE:1.63
	OPENBSD_4_9:1.63.0.4
	OPENBSD_4_9_BASE:1.63
	OPENBSD_4_8:1.63.0.2
	OPENBSD_4_8_BASE:1.63
	OPENBSD_4_7:1.62.0.2
	OPENBSD_4_7_BASE:1.62
	OPENBSD_4_6:1.62.0.4
	OPENBSD_4_6_BASE:1.62
	OPENBSD_4_5:1.61.0.6
	OPENBSD_4_5_BASE:1.61
	OPENBSD_4_4:1.61.0.4
	OPENBSD_4_4_BASE:1.61
	OPENBSD_4_3:1.61.0.2
	OPENBSD_4_3_BASE:1.61
	OPENBSD_4_2:1.58.0.2
	OPENBSD_4_2_BASE:1.58
	OPENBSD_4_1:1.56.0.4
	OPENBSD_4_1_BASE:1.56
	OPENBSD_4_0:1.56.0.2
	OPENBSD_4_0_BASE:1.56
	OPENBSD_3_9:1.51.0.2
	OPENBSD_3_9_BASE:1.51
	OPENBSD_3_8:1.44.0.4
	OPENBSD_3_8_BASE:1.44
	OPENBSD_3_7:1.44.0.2
	OPENBSD_3_7_BASE:1.44
	OPENBSD_3_6:1.35.0.2
	OPENBSD_3_6_BASE:1.35
	SMP_SYNC_A:1.34
	SMP_SYNC_B:1.34
	OPENBSD_3_5:1.33.0.2
	OPENBSD_3_5_BASE:1.33
	OPENBSD_3_4:1.32.0.2
	OPENBSD_3_4_BASE:1.32
	UBC_SYNC_A:1.31
	OPENBSD_3_3:1.31.0.4
	OPENBSD_3_3_BASE:1.31
	OPENBSD_3_2:1.31.0.2
	OPENBSD_3_2_BASE:1.31
	OPENBSD_3_1:1.30.0.2
	OPENBSD_3_1_BASE:1.30
	UBC_SYNC_B:1.31
	UBC:1.29.0.2
	UBC_BASE:1.29
	OPENBSD_3_0:1.28.0.2
	OPENBSD_3_0_BASE:1.28
	OPENBSD_2_9:1.24.0.2
	OPENBSD_2_9_BASE:1.24
	NIKLAS_UNDEAD:1.23.0.4
	OPENBSD_2_8:1.23.0.2
	OPENBSD_2_8_BASE:1.23
	OPENBSD_2_7:1.22.0.8
	OPENBSD_2_7_BASE:1.22
	SMP:1.22.0.6
	SMP_BASE:1.22
	kame_19991208:1.22
	OPENBSD_2_6:1.22.0.4
	OPENBSD_2_6_BASE:1.22
	OPENBSD_2_5:1.22.0.2
	OPENBSD_2_5_BASE:1.22
	OPENBSD_2_4:1.21.0.8
	OPENBSD_2_4_BASE:1.21
	OPENBSD_2_3:1.21.0.6
	OPENBSD_2_3_BASE:1.21
	OPENBSD_2_2:1.21.0.4
	OPENBSD_2_2_BASE:1.21
	OPENBSD_2_1:1.21.0.2
	OPENBSD_2_1_BASE:1.21
	OPENBSD_2_0:1.12.0.2
	OPENBSD_2_0_BASE:1.12
	netbsd_1_1:1.1.1.1;
locks; strict;
comment	@# @;


1.64
date	2012.06.20.18.23.52;	author matthew;	state dead;
branches;
next	1.63;

1.63
date	2010.06.29.20.30.32;	author guenther;	state Exp;
branches;
next	1.62;

1.62
date	2009.03.15.20.40.25;	author miod;	state Exp;
branches;
next	1.61;

1.61
date	2007.12.30.14.45.25;	author miod;	state Exp;
branches;
next	1.60;

1.60
date	2007.11.24.20.58.26;	author deraadt;	state Exp;
branches;
next	1.59;

1.59
date	2007.10.10.15.53.52;	author art;	state Exp;
branches;
next	1.58;

1.58
date	2007.05.15.13.46.22;	author martin;	state Exp;
branches;
next	1.57;

1.57
date	2007.03.17.20.05.22;	author miod;	state Exp;
branches;
next	1.56;

1.56
date	2006.07.06.17.49.45;	author miod;	state Exp;
branches;
next	1.55;

1.55
date	2006.07.06.17.48.55;	author miod;	state Exp;
branches;
next	1.54;

1.54
date	2006.06.24.13.24.21;	author miod;	state Exp;
branches;
next	1.53;

1.53
date	2006.06.11.20.57.44;	author miod;	state Exp;
branches;
next	1.52;

1.52
date	2006.06.11.20.49.27;	author miod;	state Exp;
branches;
next	1.51;

1.51
date	2006.01.21.12.27.58;	author miod;	state Exp;
branches;
next	1.50;

1.50
date	2006.01.13.19.36.45;	author miod;	state Exp;
branches;
next	1.49;

1.49
date	2006.01.04.20.39.05;	author miod;	state Exp;
branches;
next	1.48;

1.48
date	2006.01.01.13.16.01;	author miod;	state Exp;
branches;
next	1.47;

1.47
date	2006.01.01.13.14.44;	author miod;	state Exp;
branches;
next	1.46;

1.46
date	2005.11.13.23.14.34;	author miod;	state Exp;
branches;
next	1.45;

1.45
date	2005.09.13.14.05.49;	author martin;	state Exp;
branches;
next	1.44;

1.44
date	2004.12.30.21.28.48;	author miod;	state Exp;
branches;
next	1.43;

1.43
date	2004.12.26.22.36.34;	author miod;	state Exp;
branches;
next	1.42;

1.42
date	2004.12.24.22.50.30;	author miod;	state Exp;
branches;
next	1.41;

1.41
date	2004.12.01.23.02.55;	author miod;	state Exp;
branches;
next	1.40;

1.40
date	2004.12.01.21.20.17;	author miod;	state Exp;
branches;
next	1.39;

1.39
date	2004.11.30.01.44.22;	author martin;	state Exp;
branches;
next	1.38;

1.38
date	2004.11.27.14.26.32;	author miod;	state Exp;
branches;
next	1.37;

1.37
date	2004.11.26.21.21.28;	author miod;	state Exp;
branches;
next	1.36;

1.36
date	2004.11.25.18.32.10;	author miod;	state Exp;
branches;
next	1.35;

1.35
date	2004.07.02.17.33.43;	author miod;	state Exp;
branches;
next	1.34;

1.34
date	2004.05.20.09.20.42;	author kettenis;	state Exp;
branches;
next	1.33;

1.33
date	2004.03.08.23.48.26;	author xsa;	state Exp;
branches;
next	1.32;

1.32
date	2003.06.02.23.27.49;	author millert;	state Exp;
branches;
next	1.31;

1.31
date	2002.04.25.22.49.51;	author miod;	state Exp;
branches;
next	1.30;

1.30
date	2002.02.10.23.15.05;	author deraadt;	state Exp;
branches;
next	1.29;

1.29
date	2001.12.06.21.13.28;	author millert;	state Exp;
branches
	1.29.2.1;
next	1.28;

1.28
date	2001.08.13.00.01.41;	author miod;	state Exp;
branches;
next	1.27;

1.27
date	2001.06.27.04.22.37;	author art;	state Exp;
branches;
next	1.26;

1.26
date	2001.06.08.03.27.36;	author aaron;	state Exp;
branches;
next	1.25;

1.25
date	2001.05.08.17.30.41;	author aaron;	state Exp;
branches;
next	1.24;

1.24
date	2001.04.06.09.34.15;	author art;	state Exp;
branches;
next	1.23;

1.23
date	2000.06.05.11.02.59;	author art;	state Exp;
branches;
next	1.22;

1.22
date	99.01.20.13.31.16;	author niklas;	state Exp;
branches
	1.22.6.1;
next	1.21;

1.21
date	97.03.28.12.38.58;	author briggs;	state Exp;
branches;
next	1.20;

1.20
date	97.03.12.13.34.23;	author briggs;	state Exp;
branches;
next	1.19;

1.19
date	97.03.08.16.17.03;	author briggs;	state Exp;
branches;
next	1.18;

1.18
date	97.02.21.05.49.28;	author briggs;	state Exp;
branches;
next	1.17;

1.17
date	97.02.10.12.01.45;	author downsj;	state Exp;
branches;
next	1.16;

1.16
date	97.01.24.01.35.47;	author briggs;	state Exp;
branches;
next	1.15;

1.15
date	96.11.23.23.19.38;	author kstailey;	state Exp;
branches;
next	1.14;

1.14
date	96.10.23.04.49.47;	author briggs;	state Exp;
branches;
next	1.13;

1.13
date	96.10.14.01.20.38;	author briggs;	state Exp;
branches;
next	1.12;

1.12
date	96.09.21.04.14.01;	author briggs;	state Exp;
branches;
next	1.11;

1.11
date	96.06.23.16.24.08;	author briggs;	state Exp;
branches;
next	1.10;

1.10
date	96.06.15.21.27.17;	author briggs;	state Exp;
branches;
next	1.9;

1.9
date	96.06.09.00.47.25;	author briggs;	state Exp;
branches;
next	1.8;

1.8
date	96.05.26.18.36.20;	author briggs;	state Exp;
branches;
next	1.7;

1.7
date	96.05.26.18.14.25;	author briggs;	state Exp;
branches;
next	1.6;

1.6
date	96.02.20.05.25.25;	author briggs;	state Exp;
branches;
next	1.5;

1.5
date	96.02.20.04.45.55;	author briggs;	state Exp;
branches;
next	1.4;

1.4
date	96.02.04.16.40.13;	author briggs;	state Exp;
branches;
next	1.3;

1.3
date	96.01.14.21.06.29;	author briggs;	state Exp;
branches;
next	1.2;

1.2
date	95.12.14.11.36.06;	author deraadt;	state Exp;
branches;
next	1.1;

1.1
date	95.10.18.08.51.07;	author deraadt;	state Exp;
branches
	1.1.1.1;
next	;

1.1.1.1
date	95.10.18.08.51.07;	author deraadt;	state Exp;
branches;
next	;

1.22.6.1
date	2001.04.18.16.10.10;	author niklas;	state Exp;
branches;
next	1.22.6.2;

1.22.6.2
date	2001.07.04.10.18.37;	author niklas;	state Exp;
branches;
next	1.22.6.3;

1.22.6.3
date	2001.10.31.03.01.14;	author nate;	state Exp;
branches;
next	1.22.6.4;

1.22.6.4
date	2002.03.06.01.05.35;	author niklas;	state Exp;
branches;
next	1.22.6.5;

1.22.6.5
date	2003.03.27.23.28.44;	author niklas;	state Exp;
branches;
next	1.22.6.6;

1.22.6.6
date	2003.06.07.11.13.14;	author ho;	state Exp;
branches;
next	1.22.6.7;

1.22.6.7
date	2004.06.05.23.10.51;	author niklas;	state Exp;
branches;
next	;

1.29.2.1
date	2002.06.11.03.36.19;	author art;	state Exp;
branches;
next	;


desc
@@


1.64
log
@RIP mac68k.  No one loves you anymore.
@
text
@/*	$OpenBSD: locore.s,v 1.63 2010/06/29 20:30:32 guenther Exp $	*/
/*	$NetBSD: locore.s,v 1.103 1998/07/09 06:02:50 scottr Exp $	*/

/*
 * Copyright (c) 1988 University of Utah.
 * Copyright (c) 1982, 1990 The Regents of the University of California.
 * All rights reserved.
 *
 * This code is derived from software contributed to Berkeley by
 * the Systems Programming Group of the University of Utah Computer
 * Science Department.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. Neither the name of the University nor the names of its contributors
 *    may be used to endorse or promote products derived from this software
 *    without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE
 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
 */
/*-
 * Copyright (C) 1993	Allen K. Briggs, Chris P. Caputo,
 *			Michael L. Finch, Bradley A. Grantham, and
 *			Lawrence A. Kesteloot
 * All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *	This product includes software developed by the Alice Group.
 * 4. The names of the Alice Group or any of its members may not be used
 *    to endorse or promote products derived from this software without
 *    specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE ALICE GROUP ``AS IS'' AND ANY EXPRESS OR
 * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
 * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
 * IN NO EVENT SHALL THE ALICE GROUP BE LIABLE FOR ANY DIRECT, INDIRECT,
 * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
 * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
 * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
 * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 *
 */

/*
 * from: Utah $Hdr: locore.s 1.58 91/04/22$
 *
 *	@@(#)locore.s	7.11 (Berkeley) 5/9/91
 */

#include "assym.h"
#include <machine/asm.h>
#include <machine/trap.h>

/*
 * This is for kvm_mkdb, and should be the address of the beginning
 * of the kernel text segment (not necessarily the same as kernbase).
 */
	.text
GLOBAL(kernel_text)

/*
 * Clear and skip the first page of text; it will not be mapped.
 */
	.fill	NBPG / 4, 4, 0

/*
 * Initialization
 */

	.data
| Scratch memory.  Careful when messing with these...
ASLOCAL(longscratch)
	.long	0
ASLOCAL(longscratch2)
	.long	0
ASLOCAL(pte_tmp)			| for get_pte()
	.long	0 
GLOBAL(macos_crp1)
	.long	0
GLOBAL(macos_crp2)
	.long	0
GLOBAL(macos_tc)
	.long	0
GLOBAL(macos_tt0)
	.long	0
GLOBAL(macos_tt1)
	.long	0
GLOBAL(bletch)
	.long	0

GLOBAL(sanity_check)
	.long	0x18621862	| this is our stack overflow checker.

	.space	4 * NBPG
ASLOCAL(tmpstk)

#include <mac68k/mac68k/vectors.s>

BSS(esym,4)

ASENTRY_NOPROFILE(start)
GLOBAL(kernel_start)
	movw	#PSL_HIGHIPL,sr		| no interrupts.  ever.
	lea	_ASM_LABEL(tmpstk),sp	| give ourselves a temporary stack

	movl	#CACHE_OFF,d0
	movc	d0,cacr			| clear and disable on-chip cache(s)

	/* Initialize source/destination control registers for movs */
	movql	#FC_USERD,d0		| user space
	movc	d0,sfc			|   as source
	movc	d0,dfc			|   and destination of transfers

	/*
	 * Some parameters provided by MacOS
	 *
	 * LAK: This section is the new way to pass information from the booter
	 * to the kernel.  At A1 there is an environment variable which has
	 * a bunch of stuff in ascii format, "VAR=value\0VAR=value\0\0".
	 */
	movl	a1,sp@@-			| Address of buffer
	movl	d4,sp@@-			| Some flags... (mostly not used)
	jbsr	_C_LABEL(getenvvars)	| Parse the environment buffer
	addql	#8,sp

	/* Determine MMU/MPU from what we can test empirically */
	movl	#0x200,d0		| data freeze bit
	movc	d0,cacr			|   only exists on 68030
	movc	cacr,d0			| read it back
	tstl	d0			| zero?
	jeq	Lnot68030		| yes, we have 68020/68040

	lea	_C_LABEL(mmutype),a0	| no, we have 68030
	movl	#MMU_68030,a0@@		| set to reflect 68030 PMMU
	lea	_C_LABEL(cputype),a0
	movl	#CPU_68030,a0@@		| and 68030 MPU
	jra	Lstart1

Lnot68030:
	bset	#31,d0			| data cache enable bit
	movc	d0,cacr			|   only exists on 68040
	movc	cacr,d0			| read it back
	tstl	d0			| zero?
	beq	Lis68020		| yes, we have 68020

	movql	#CACHE40_OFF,d0		| now turn it back off
	movc	d0,cacr			|   before we access any data
	.word	0xf4f8			| cpusha bc ;push and invalidate caches
	lea	_C_LABEL(mmutype),a0
	movl	#MMU_68040,a0@@		| Reflect 68040 MMU
	lea	_C_LABEL(cputype),a0
	movl	#CPU_68040,a0@@		| and 68040 MPU
	jra	Lstart1

Lis68020:
	movl	#CACHE_OFF,d0		| disable and clear cache
	movc	d0,cacr
	lea	_C_LABEL(mmutype),a0	| Must be 68020+68851
	movl	#MMU_68851,a0@@		| Reflect 68851 PMMU
	lea	_C_LABEL(cputype),a0
	movl	#CPU_68020,a0@@		| and 68020 MPU

Lstart1:
	/*
	 * Now that we know what CPU we have, initialize the address error
	 * and bus error handlers in the vector table:
	 *
	 *	vectab+8	bus error
	 *	vectab+12	address error
	 */
	lea	_C_LABEL(cputype),a0
	lea	_C_LABEL(vectab),a2
#if defined(M68040)
	cmpl	#CPU_68040,a0@@		| 68040?
	jne	1f			| no, skip
	movl	#_C_LABEL(buserr40),a2@@(8)
	movl	#_C_LABEL(addrerr4060),a2@@(12)
	jra	Lstart2
1:
#endif
#if defined(M68020) || defined(M68030)
#if defined(M68030)
	cmpl	#CPU_68030,a0@@		| 68030?
	jeq	1f			| yes, ok
#endif
#if defined(M68020)
	cmpl	#CPU_68020,a0@@		| 68020?
	jeq	1f			| yes, ok
#endif
	jra	9f
1:
	movl	#_C_LABEL(busaddrerr2030),a2@@(8)
	movl	#_C_LABEL(busaddrerr2030),a2@@(12)
	jra	Lstart2
#endif
9:
	/* Config botch; no hope. */
	movl	_C_LABEL(MacOSROMBase),a1 | Load MacOS ROMBase
	jra	Ldoboot1

Lstart2:
	jbsr	_C_LABEL(setmachdep)	| Set some machine-dep stuff
	jbsr	_C_LABEL(consinit)	| XXX Should only be if graybar on

/*
 * Figure out MacOS mappings and bootstrap OpenBSD
 */
	lea	_C_LABEL(macos_tc),a0	| get current TC
	cmpl	#MMU_68040,_C_LABEL(mmutype) | check to see if 68040
	jeq	Lget040TC

	pmove	tc,a0@@
	jra	Lstart3

Lget040TC:
#if 0
	movl	_C_LABEL(current_mac_model),a1	 | if an AV Mac, save current
	cmpl	#MACH_CLASSAV,a1@@(CPUINFO_CLASS) | TC so internal video will
	jne	LnotAV				 | get configured
#endif
	.long	0x4e7a0003		| movc tc,d0
	jra	LsaveTC
LnotAV:
	movql	#0,d0			| otherwise,
	.long	0x4e7b0003		| movc d0,tc ;Disable MMU
LsaveTC:
	movl	d0,a0@@

Lstart3:
	movl	a0@@,sp@@-		| get Mac OS mapping, relocate video,
	jbsr	_C_LABEL(bootstrap_mac68k) |   bootstrap pmap, et al.
	addql	#4,sp

	/*
	 * Set up the vector table, and race to get the MMU
	 * enabled.
	 */
	movl	#_C_LABEL(vectab),d0	| set Vector Base Register
	movc	d0,vbr

/*
 * We might not be running physical, but we don't have read-only mappings
 * yet either. It's time to override copypage() with the 68040
 * optimized version, copypage040(), if possible.
 * This relies upon the fact that copypage() immediately follows
 * copypage040() in memory.
 */
	movl	#_C_LABEL(mmutype),a0
	cmpl	#MMU_68040,a0@@
	jgt	Lmmu_enable
	movl	#_C_LABEL(copypage040),a0
	movl	#_C_LABEL(copypage),a1
	movl	a1, a2
1:
	movw	a0@@+, a2@@+
	cmpl	a0, a1
	jgt	1b

Lmmu_enable:
	movl	_C_LABEL(Sysseg),a1	| system segment table addr
	addl	_C_LABEL(load_addr),a1	| Make it physical addr
	cmpl	#MMU_68040,_C_LABEL(mmutype)
	jne	Lenablepre040MMU	| if not 040, skip

	movql	#0,d0
	.long	0x4e7b0003		| movc d0,tc   ;Disable MMU
	.long	0x4e7b0004		| movc d0,itt0 ;Disable itt0
	.long	0x4e7b0005		| movc d0,itt1 ;Disable itt1
	.long	0x4e7b0006		| movc d0,dtt0 ;Disable dtt0
	.long	0x4e7b0007		| movc d0,dtt1 ;Disable dtt1
	movl	a1,d1
	.word	0xf4d8			| cinva bc
	.word	0xf518			| pflusha
	.long	0x4e7b1807		| movc d1,srp
	movl	#0x8000,d0
	.long	0x4e7b0003		| movc d0,tc   ;Enable MMU
	movl	#CACHE40_ON,d0
	movc	d0,cacr			| turn on both caches
	jra	Lloaddone

Lenablepre040MMU:
	tstl	_C_LABEL(mmutype)	| TTx instructions will break 68851
	jgt	LnokillTT

	lea	_ASM_LABEL(longscratch),a0 | disable TTx registers on 68030
	movl	#0,a0@@
	.long	0xf0100800		| movl a0@@,tt0
	.long	0xf0100c00		| movl a0@@,tt1

LnokillTT:
	lea	_C_LABEL(protorp),a0
	movl	#0x80000202,a0@@		| nolimit + share global + 4 byte PTEs
	movl	a1,a0@@(4)		| + segtable address
	pmove	a0@@,srp			| load the supervisor root pointer
	movl	#0x80000002,a0@@		| reinit upper half for CRP loads
	lea	_ASM_LABEL(longscratch),a2
	movl	#0x82c0aa00,a2@@		| value to load TC with
	pmove	a2@@,tc			| load it

Lloaddone:

/*
 * Should be running mapped from this point on
 */
/* select the software page size now */
	lea	_ASM_LABEL(tmpstk),sp	| temporary stack
	jbsr	_C_LABEL(uvm_setpagesize)  | select software page size

/* set kernel stack, user SP, proc0, and initial pcb */
	movl	_C_LABEL(proc0paddr),a1	| get proc0 pcb addr
	lea	a1@@(USPACE-4),sp	| set kernel stack to end of area
	lea	_C_LABEL(proc0),a2	| initialize proc0.p_addr so that
	movl	a1,a2@@(P_ADDR)		|   we don't deref NULL in trap()
	movl	#USRSTACK-4,a2
	movl	a2,usp			| init user SP
	movl	a1,_C_LABEL(curpcb)	| proc0 is running

/* flush TLB and turn on caches */
	jbsr	_ASM_LABEL(TBIA)	| invalidate TLB
	cmpl	#MMU_68040,_C_LABEL(mmutype) | 68040?
	jeq	Lnocache0		| yes, cache already on
	movl	#CACHE_ON,d0
	movc	d0,cacr			| clear cache(s)

Lnocache0:
/* Final setup for call to main(). */
	jbsr	_C_LABEL(mac68k_init)

/*
 * Create a fake exception frame so that cpu_fork() can copy it.
 * main() never returns; we exit to user mode from a forked process
 * later on.
 */
	clrw	sp@@-			| vector offset/frame type
	clrl	sp@@-			| PC - filled in by "execve"
	movw	#PSL_USER,sp@@-		| in user mode
	clrl	sp@@-			| stack adjust count and padding
	lea	sp@@(-64),sp		| construct space for D0-D7/A0-A7
	lea	_C_LABEL(proc0),a0	| save pointer to frame
	movl	sp,a0@@(P_MD_REGS)	|   in proc0.p_md.md_regs

	jra	_C_LABEL(main)		| main()
	PANIC("main() returned")
	/* NOTREACHED */

/*
 * proc_trampoline
 *	Call function in register a2 with a3 as an arg and then rei.  Note
 * that we restore the stack before calling, thus giving "a2" more stack.
 * (for the case that, e.g., if curproc had a deeply nested call chain...)
 * cpu_fork() also depends on struct frame being a second arg to the
 * function in a2.
 */
GLOBAL(proc_trampoline)
	movl	a3,sp@@-			| push function arg (curproc)
	jbsr	a2@@			| call function
	addql	#4,sp			| pop arg
	movl	sp@@(FR_SP),a0		| usp to a0
	movl	a0,usp			| setup user's stack pointer
	movml	sp@@+,#0x7fff		| restore all but sp
	addql	#8,sp			| pop sp and stack adjust
	jra	_ASM_LABEL(rei)		| all done

/*
 * Trap/interrupt vector routines
 */ 
#include <m68k/m68k/trap_subr.s>

	.data
GLOBAL(m68k_fault_addr)
	.long	0

#if defined(M68040)
ENTRY_NOPROFILE(addrerr4060)
	clrl	sp@@-			| stack adjust count
	moveml	#0xFFFF,sp@@-		| save user registers
	movl	usp,a0			| save the user SP
	movl	a0,sp@@(FR_SP)		|   in the savearea
	movl	sp@@(FR_HW+8),sp@@-
	clrl	sp@@-			| dummy code
	movl	#T_ADDRERR,sp@@-		| mark address error
	jra	_ASM_LABEL(faultstkadj)	| and deal with it
#endif

#if defined(M68040)
ENTRY_NOPROFILE(buserr40)
	clrl	sp@@-			| stack adjust count
	moveml	#0xFFFF,sp@@-		| save user registers
	movl	usp,a0			| save the user SP
	movl	a0,sp@@(FR_SP)		|   in the savearea
	movl	sp@@(FR_HW+20),d1	| get fault address
	moveq	#0,d0
	movw	sp@@(FR_HW+12),d0	| get SSW
	btst	#11,d0			| check for mis-aligned
	jeq	Lbe1stpg		| no skip
	addl	#3,d1			| get into next page
	andl	#PG_FRAME,d1		| and truncate
Lbe1stpg:
	movl	d1,sp@@-			| pass fault address.
	movl	d0,sp@@-			| pass SSW as code
	btst	#10,d0			| test ATC
	jeq	Lberr40			| it is a bus error
	movl	#T_MMUFLT,sp@@-		| show that we are an MMU fault
	jra	_ASM_LABEL(faultstkadj)	| and deal with it
Lberr40:
	tstl	_C_LABEL(nofault)	| catch bus error?
	jeq	Lisberr			| no, handle as usual
	movl	sp@@(FR_HW+8+20),_C_LABEL(m68k_fault_addr) | save fault addr
	movl	_C_LABEL(nofault),sp@@-	| yes,
	jbsr	_C_LABEL(longjmp)	|  longjmp(nofault)
	/* NOTREACHED */
#endif

ENTRY_NOPROFILE(busaddrerr2030)
#if !(defined(M68020) || defined(M68030))
	jra	_badtrap
#else
	clrl	sp@@-			| stack adjust count
	moveml	#0xFFFF,sp@@-		| save user registers
	movl	usp,a0			| save the user SP
	movl	a0,sp@@(FR_SP)		|   in the savearea
	moveq	#0,d0
	movw	sp@@(FR_HW+10),d0	| grab SSW for fault processing
	btst	#12,d0			| RB set?
	jeq	LbeX0			| no, test RC
	bset	#14,d0			| yes, must set FB
	movw	d0,sp@@(FR_HW+10)	| for hardware too
LbeX0:
	btst	#13,d0			| RC set?
	jeq	LbeX1			| no, skip
	bset	#15,d0			| yes, must set FC
	movw	d0,sp@@(FR_HW+10)	| for hardware too
LbeX1:
	btst	#8,d0			| data fault?
	jeq	Lbe0			| no, check for hard cases
	movl	sp@@(FR_HW+16),d1	| fault address is as given in frame
	jra	Lbe10			| thats it
Lbe0:
	btst	#4,sp@@(FR_HW+6)		| long (type B) stack frame?
	jne	Lbe4			| yes, go handle
	movl	sp@@(FR_HW+2),d1		| no, can use save PC
	btst	#14,d0			| FB set?
	jeq	Lbe3			| no, try FC
	addql	#4,d1			| yes, adjust address
	jra	Lbe10			| done
Lbe3:
	btst	#15,d0			| FC set?
	jeq	Lbe10			| no, done
	addql	#2,d1			| yes, adjust address
	jra	Lbe10			| done
Lbe4:
	movl	sp@@(FR_HW+36),d1	| long format, use stage B address
	btst	#15,d0			| FC set?
	jeq	Lbe10			| no, all done
	subql	#2,d1			| yes, adjust address
Lbe10:
	movl	d1,sp@@-			| push fault VA
	movl	d0,sp@@-			| and padded SSW
	movw	sp@@(FR_HW+8+6),d0	| get frame format/vector offset
	andw	#0x0FFF,d0		| clear out frame format
	cmpw	#12,d0			| address error vector?
	jeq	Lisaerr			| yes, go to it
	movl	d1,a0			| fault address
	movl	sp@@,d0			| function code from ssw
	btst	#8,d0			| data fault?
	jne	Lbe10a
	movql	#1,d0			| user program access FC
					| (we dont separate data/program)
	btst	#5,sp@@(FR_HW+8)		| supervisor mode?
	jeq	Lbe10a			| if no, done
	movql	#5,d0			| else supervisor program access
Lbe10a:
	ptestr	d0,a0@@,#7		| do a table search
	pmove	psr,sp@@			| save result
	movb	sp@@,d1
	btst	#2,d1			| invalid (incl. limit viol. and berr)?
	jeq	Lmightnotbemerr		| no -> wp check
	btst	#7,d1			| is it MMU table berr?
	jne	Lisberr1		| yes, needs not be fast.
Lismerr:
	movl	#T_MMUFLT,sp@@-		| show that we are an MMU fault
	jra	_ASM_LABEL(faultstkadj)	| and deal with it
Lmightnotbemerr:
	btst	#3,d1			| write protect bit set?
	jeq	Lisberr1		| no: must be bus error
	movl	sp@@,d0			| ssw into low word of d0
	andw	#0xc0,d0		| Write protect is set on page:
	cmpw	#0x40,d0		| was it read cycle?
	jne	Lismerr			| no, was not WPE, must be MMU fault
	jra	Lisberr1		| real bus err needs not be fast.
Lisaerr:
	movl	#T_ADDRERR,sp@@-		| mark address error
	jra	_ASM_LABEL(faultstkadj)	| and deal with it
Lisberr1:
	clrw	sp@@			| re-clear pad word
	tstl	_C_LABEL(nofault)	| catch bus error?
	jeq	Lisberr			| no, handle as usual
	movl	sp@@(FR_HW+8+16),_C_LABEL(m68k_fault_addr) | save fault addr
	movl	_C_LABEL(nofault),sp@@-	| yes,
	jbsr	_C_LABEL(longjmp)	|  longjmp(nofault)
	/* NOTREACHED */
#endif
Lisberr:				| also used by M68040/60
	movl	#T_BUSERR,sp@@-		| mark bus error
	jra	_ASM_LABEL(faultstkadj)	| and deal with it

/*
 * FP exceptions.
 */
ENTRY_NOPROFILE(fpfline)
#if defined(M68040)
	cmpl	#FPU_68040,_C_LABEL(fputype) | 68040 FPU?
	jne	Lfp_unimp		| no, skip FPSP
	cmpw	#0x202c,sp@@(6)		| format type 2?
	jne	_C_LABEL(illinst)	| no, not an FP emulation
Ldofp_unimp:
#ifdef FPSP
	jmp	_ASM_LABEL(fpsp_unimp)	| yes, go handle it
#endif
Lfp_unimp:
#endif /* M68040 */
#ifdef FPU_EMULATE
	clrl	sp@@-			| stack adjust count
	moveml	#0xFFFF,sp@@-		| save registers
	moveq	#T_FPEMULI,d0		| denote as FP emulation trap
	jra	_ASM_LABEL(fault)	| do it
#else
	jra	_C_LABEL(illinst)
#endif

ENTRY_NOPROFILE(fpunsupp)
#if defined(M68040)
	cmpl	#FPU_68040,_C_LABEL(fputype) | 68040 FPU?
	jne	_C_LABEL(illinst)	| no, treat as illinst
#ifdef FPSP
	jmp	_ASM_LABEL(fpsp_unsupp)	| yes, go handle it
#endif
Lfp_unsupp:
#endif /* M68040 */
#ifdef FPU_EMULATE
	clrl	sp@@-			| stack adjust count
	moveml	#0xFFFF,sp@@-		| save registers
	moveq	#T_FPEMULD,d0		| denote as FP emulation trap
	jra	_ASM_LABEL(fault)	| do it
#else
	jra	_C_LABEL(illinst)
#endif

/*
 * Handles all other FP coprocessor exceptions.
 * Note that since some FP exceptions generate mid-instruction frames
 * and may cause signal delivery, we need to test for stack adjustment
 * after the trap call.
 */
ENTRY_NOPROFILE(fpfault)
	clrl	sp@@-		| stack adjust count
	moveml	#0xFFFF,sp@@-	| save user registers
	movl	usp,a0		| and save
	movl	a0,sp@@(FR_SP)	|   the user stack pointer
	clrl	sp@@-		| no VA arg
	movl	_C_LABEL(curpcb),a0 | current pcb
	lea	a0@@(PCB_FPCTX),a0 | address of FP savearea
	fsave	a0@@		| save state
#if defined(M68040) || defined(M68060)
	/* always null state frame on 68040, 68060 */
	cmpl	#FPU_68040,_C_LABEL(fputype)
	jge	Lfptnull
#endif
	tstb	a0@@		| null state frame?
	jeq	Lfptnull	| yes, safe
	clrw	d0		| no, need to tweak BIU
	movb	a0@@(1),d0	| get frame size
	bset	#3,a0@@(0,d0:w)	| set exc_pend bit of BIU
Lfptnull:
	fmovem	fpsr,sp@@-	| push fpsr as code argument
	frestore a0@@		| restore state
	movl	#T_FPERR,sp@@-	| push type arg
	jra	_ASM_LABEL(faultstkadj) | call trap and deal with stack cleanup

/*
 * Other exceptions only cause four and six word stack frame and require
 * no post-trap stack adjustment.
 */

ENTRY_NOPROFILE(badtrap)
	moveml	#0xC0C0,sp@@-		| save scratch regs
	movw	sp@@(22),sp@@-		| push exception vector info
	clrw	sp@@-
	movl	sp@@(22),sp@@-		| and PC
	jbsr	_C_LABEL(straytrap)	| report
	addql	#8,sp			| pop args
	moveml	sp@@+,#0x0303		| restore regs
	jra	_ASM_LABEL(rei)		| all done

ENTRY_NOPROFILE(trap0)
	clrl	sp@@-			| pad SR to longword
	moveml	#0xFFFF,sp@@-		| save user registers
	movl	usp,a0			| save the user SP
	movl	a0,sp@@(FR_SP)		|   in the savearea
	movl	d0,sp@@-			| push syscall number
	jbsr	_C_LABEL(syscall)	| handle it
	addql	#4,sp			| pop syscall arg
	tstl	_C_LABEL(astpending)
	jne	Lrei2
	tstl	_C_LABEL(softpending)
	jeq	Ltrap1
	movw	#SPL1,sr
	tstl	_C_LABEL(softpending)
	jne	Lsir1
Ltrap1:
	movl	sp@@(FR_SP),a0		| grab and restore
	movl	a0,usp			|   user SP
	moveml	sp@@+,#0x7FFF		| restore most registers
	addql	#8,sp			| pop SSP and align word
	rte

/*
 * Trap 1 - sigreturn
 */
ENTRY_NOPROFILE(trap1)
	jra	_ASM_LABEL(sigreturn)

/*
 * Trap 2 - trace trap
 */
ENTRY_NOPROFILE(trap2)
	jra	_C_LABEL(trace)

/*
 * Trap 12 is the entry point for the cachectl "syscall" (both HP-UX & BSD)
 *	cachectl(command, addr, length)
 * command in d0, addr in a1, length in d1
 */
ENTRY_NOPROFILE(trap12)
	movl	d1,sp@@-			| push length
	movl	a1,sp@@-			| push addr
	movl	d0,sp@@-			| push command
	movl	CURPROC,sp@@-		| push proc pointer
	jbsr	_C_LABEL(cachectl)	| do it
	lea	sp@@(16),sp		| pop args
	jra	_ASM_LABEL(rei)		| all done

/*
 * Trace (single-step) trap.  Kernel-mode is special.
 * User mode traps are simply passed on to trap().
 */
ENTRY_NOPROFILE(trace)
	clrl	sp@@-			| stack adjust count
	moveml	#0xFFFF,sp@@-
	moveq	#T_TRACE,d0

	| Check PSW and see what happened.
	|   T=0 S=0     (should not happen)
	|   T=1 S=0     trace trap from user mode
	|   T=0 S=1     trace trap on a trap instruction
	|   T=1 S=1     trace trap from system mode (kernel breakpoint)

	movw	sp@@(FR_HW),d1		| get PSW
	notw	d1			| XXX no support for T0 on 680[234]0
	andw	#PSL_TS,d1		| from system mode (T=1, S=1)?
	jeq	Lkbrkpt			| yes, kernel breakpoint
	jra	_ASM_LABEL(fault)	| no, user-mode fault

/*
 * Trap 15 is used for:
 *	- GDB breakpoints (in user programs)
 *	- KGDB breakpoints (in the kernel)
 *	- trace traps for SUN binaries (not fully supported yet)
 * User mode traps are simply passed to trap().
 */
ENTRY_NOPROFILE(trap15)
	clrl	sp@@-			| stack adjust count
	moveml	#0xFFFF,sp@@-
	moveq	#T_TRAP15,d0
	movw	sp@@(FR_HW),d1		| get PSW
	andw	#PSL_S,d1		| from system mode?
	jne	Lkbrkpt			| yes, kernel breakpoint
	jra	_ASM_LABEL(fault)	| no, user-mode fault

Lkbrkpt: | Kernel-mode breakpoint or trace trap. (d0=trap_type)
	| Save the system sp rather than the user sp.
	movw	#PSL_HIGHIPL,sr		| lock out interrupts
	lea	sp@@(FR_SIZE),a6		| Save stack pointer
	movl	a6,sp@@(FR_SP)		|  from before trap

	| If we are not on tmpstk switch to it.
	| (so debugger can change the stack pointer)
	movl	a6,d1
	cmpl	#_ASM_LABEL(tmpstk),d1
	jls	Lbrkpt2			| already on tmpstk
	| Copy frame to the temporary stack
	movl	sp,a0			| a0=src
	lea	_ASM_LABEL(tmpstk)-96,a1 | a1=dst
	movl	a1,sp			| sp=new frame
	moveq	#FR_SIZE,d1
Lbrkpt1:
	movl	a0@@+,a1@@+
	subql	#4,d1
	bgt	Lbrkpt1

Lbrkpt2:
	| Call the trap handler for the kernel debugger.
	| Do not call trap() to do it, so that we can
	| set breakpoints in trap() if we want.  We know
	| the trap type is either T_TRACE or T_BREAKPOINT.
	| If we have both DDB and KGDB, let KGDB see it first,
	| because KGDB will just return 0 if not connected.
	| Save args in d2, a2
	movl	d0,d2			| trap type
	movl	sp,a2			| frame ptr
#ifdef KGDB
	| Let KGDB handle it (if connected)
	movl	a2,sp@@-			| push frame ptr
	movl	d2,sp@@-			| push trap type
	jbsr	_C_LABEL(kgdb_trap)	| handle the trap
	addql	#8,sp			| pop args
	cmpl	#0,d0			| did kgdb handle it?
	jne	Lbrkpt3			| yes, done
#endif
#ifdef DDB
	| Let DDB handle it
	movl	a2,sp@@-			| push frame ptr
	movl	d2,sp@@-			| push trap type
	jbsr	_C_LABEL(kdb_trap)	| handle the trap
	addql	#8,sp			| pop args
#endif
Lbrkpt3:
	| The stack pointer may have been modified, or
	| data below it modified (by kgdb push call),
	| so push the hardware frame at the current sp
	| before restoring registers and returning.

	movl	sp@@(FR_SP),a0		| modified sp
	lea	sp@@(FR_SIZE),a1		| end of our frame
	movl	a1@@-,a0@@-		| copy 2 longs with
	movl	a1@@-,a0@@-		| ... predecrement
	movl	a0,sp@@(FR_SP)		| sp = h/w frame
	moveml	sp@@+,#0x7FFF		| restore all but sp
	movl	sp@@,sp			| ... and sp
	rte				| all done

/* Use common m68k sigreturn */
#include <m68k/m68k/sigreturn.s>

/*
 * Interrupt handlers.
 *
 * Most 68k-based Macintosh computers
 *
 *	Level 0:	Spurious: ignored
 *	Level 1:	VIA1 (clock, ADB)
 *	Level 2:	VIA2 (NuBus, SCSI)
 *	Level 3:
 *	Level 4:	Serial (SCC)
 *	Level 5:
 *	Level 6:
 *	Level 7:	Non-maskable: parity errors, RESET button
 *
 * On the Q700, Q900 and Q950 in "A/UX mode": this should become:
 *
 *	Level 0:	Spurious: ignored
 *	Level 1:	Software
 *	Level 2:	VIA2 (except ethernet, sound)
 *	Level 3:	Ethernet
 *	Level 4:	Serial (SCC)
 *	Level 5:	Sound
 *	Level 6:	VIA1
 *	Level 7:	NMIs: parity errors, RESET button, YANCC error
 *
 * On the 660AV and 840AV:
 *
 *	Level 0:	Spurious: ignored
 *	Level 1:	VIA1 (clock, ADB)
 *	Level 2:	VIA2 (NuBus, SCSI)
 *	Level 3:	PSC device interrupt
 *	Level 4:	PSC DMA and serial
 *	Level 5:	???
 *	Level 6:	???
 *	Level 7:	NMIs: parity errors?, RESET button
 */

#define	INTERRUPT_SAVEREG	moveml	#0xC0C0,sp@@-
#define	INTERRUPT_RESTOREREG	moveml	sp@@+,#0x0303

ENTRY_NOPROFILE(spurintr)
	addql	#1,_C_LABEL(uvmexp)+UVMEXP_INTRS
	jra	_ASM_LABEL(rei)

ENTRY_NOPROFILE(intrhand)	/* levels 3 through 6 */
	INTERRUPT_SAVEREG
	movw	sp@@(22),sp@@-		| push exception vector info	
	clrw	sp@@-
	jbsr	_C_LABEL(intr_dispatch) | call dispatch routine
	addql	#4,sp
	INTERRUPT_RESTOREREG
	jra	_ASM_LABEL(rei)		| all done

ENTRY_NOPROFILE(lev7intr)
	clrl	sp@@-			| pad SR to longword
	moveml	#0xFFFF,sp@@-		| save registers
	movl	usp,a0			| and save
	movl	a0,sp@@(FR_SP)		|   the user stack pointer
	jbsr	_C_LABEL(nmihand)	| call handler
	movl	sp@@(FR_SP),a0		| restore
	movl	a0,usp			|   user SP
	moveml	sp@@+,#0x7FFF		| and remaining registers
	addql	#8,sp			| pop SSP and align word
	jra	_ASM_LABEL(rei)

/* 
 * We could tweak rtclock_intr and gain 12 cycles on the 020 and 030 by
 * saving the status register directly to the stack, but this would lose
 * badly on the 040.  Aligning the stack takes 10 more cycles than this
 * code does, so it's a good compromise.
 */
ENTRY_NOPROFILE(rtclock_intr)
	movl	d2,sp@@-			| save d2
	movw	sr,d2			| save SPL
	movw	_C_LABEL(mac68k_clockipl),sr	| raise SPL to splclock()
	movl	a6@@,a1			| unwind to frame in intr_dispatch
	lea	a1@@(28),a1		| push pointer to interrupt frame
	movl	a1,sp@@-			| 28 = 16 for regs in intrhand,
					|    + 4 for args to intr_dispatch
					|    + 4 for return address to intrhand
					|    + 4 for value of A6
	jbsr	_C_LABEL(hardclock)	| call generic clock int routine
	addql	#4,sp			| pop params
	movw	d2,sr			| restore SPL
	movl	sp@@+,d2			| restore d2
	movl	#1,d0			| clock taken care of
	rts				| go back from whence we came

/*
 * Emulation of VAX REI instruction.
 *
 * This code deals with checking for and servicing ASTs
 * (profiling, scheduling) and software interrupts (network, softclock).
 * We check for ASTs first, just like the VAX.  To avoid excess overhead
 * the T_ASTFLT handling code will also check for software interrupts so we
 * do not have to do it here.  After identifing that we need an AST we
 * drop the IPL to allow device interrupts.
 *
 * This code is complicated by the fact that sendsig may have been called
 * necessitating a stack cleanup.
 */

BSS(softpending,4)

ASENTRY_NOPROFILE(rei)
	tstl	_C_LABEL(astpending)	| AST pending?
	jeq	Lchksir			| no, go check for SIR
Lrei1:
	btst	#5,sp@@			| yes, are we returning to user mode?
	jne	Lchksir			| no, go check for SIR
	movw	#PSL_LOWIPL,sr		| lower SPL
	clrl	sp@@-			| stack adjust
	moveml	#0xFFFF,sp@@-		| save all registers
	movl	usp,a1			| including
	movl	a1,sp@@(FR_SP)		|    the users SP
Lrei2:
	clrl	sp@@-			| VA == none
	clrl	sp@@-			| code == none
	movl	#T_ASTFLT,sp@@-		| type == async system trap
	jbsr	_C_LABEL(trap)		| go handle it
	lea	sp@@(12),sp		| pop value args
	movl	sp@@(FR_SP),a0		| restore user SP
	movl	a0,usp			|   from save area
	movw	sp@@(FR_ADJ),d0		| need to adjust stack?
	jne	Laststkadj		| yes, go to it
	moveml	sp@@+,#0x7FFF		| no, restore most user regs
	addql	#8,sp			| toss SP and stack adjust
	rte				| and do real RTE
Laststkadj:
	lea	sp@@(FR_HW),a1		| pointer to HW frame
	addql	#8,a1			| source pointer
	movl	a1,a0			| source
	addw	d0,a0			|  + hole size = dest pointer
	movl	a1@@-,a0@@-		| copy
	movl	a1@@-,a0@@-		|  8 bytes
	movl	a0,sp@@(FR_SP)		| new SSP
	moveml	sp@@+,#0x7FFF		| restore user registers
	movl	sp@@,sp			| and our SP
	rte				| and do real RTE
Lchksir:
	tstl	_C_LABEL(softpending)	| SIR pending?
	jeq	Ldorte			| no, all done
	movl	d0,sp@@-			| need a scratch register
	movw	sp@@(4),d0		| get SR
	andw	#PSL_IPL7,d0		| mask all but IPL
	jne	Lnosir			| came from interrupt, no can do
	movl	sp@@+,d0			| restore scratch register
Lgotsir:
	movw	#SPL1,sr		| prevent others from servicing int
	tstl	_C_LABEL(softpending)	| too late?
	jeq	Ldorte			| yes, oh well...
	clrl	sp@@-			| stack adjust
	moveml	#0xFFFF,sp@@-		| save all registers
	movl	usp,a1			| including
	movl	a1,sp@@(FR_SP)		|    the users SP
Lsir1:
	clrl	sp@@-			| VA == none
	clrl	sp@@-			| code == none
	movl	#T_SSIR,sp@@-		| type == software interrupt
	jbsr	_C_LABEL(trap)		| go handle it
	lea	sp@@(12),sp		| pop value args
	movl	sp@@(FR_SP),a0		| restore
	movl	a0,usp			|   user SP
	moveml	sp@@+,#0x7FFF		| and all remaining registers
	addql	#8,sp			| pop SP and stack adjust
	rte
Lnosir:
	movl	sp@@+,d0			| restore scratch register
Ldorte:
	rte				| real return

/*
 * Use common m68k sigcode.
 */
#include <m68k/m68k/sigcode.s>

/*
 * Primitives
 */ 

/*
 * Use common m68k support routines.
 */
#include <m68k/m68k/support.s>

	.data
GLOBAL(curpcb)
	.long	0

ASBSS(nullpcb,SIZEOF_PCB)

ENTRY_NOPROFILE(cpu_idle_cycle)
	stop	#PSL_LOWIPL
	rts

/*
 * cpu_switchto(struct proc *oldproc, struct proc *newproc)
 *
 * NOTE: On the mc68851 (318/319/330) we attempt to avoid flushing the
 * entire ATC.  The effort involved in selective flushing may not be
 * worth it, maybe we should just flush the whole thing?
 *
 * NOTE 2: With the new VM layout we now no longer know if an inactive
 * user's PTEs have been changed (formerly denoted by the SPTECHG p_flag
 * bit).  For now, we just always flush the full ATC.
 */
ENTRY(cpu_switchto)
	movl	sp@@(4), d0		| oldproc
	beq	Lswnofpsave		| is NULL, don't save anything

	/*
	 * Save state of previous process in its pcb.
	 */
	movl	_C_LABEL(curpcb),a1
	movw	sr, a1@@(PCB_PS)		| save sr before switching context
	moveml	#0xFCFC,a1@@(PCB_REGS)	| save non-scratch registers
	movl	usp,a2			| grab USP (a2 has been saved)
	movl	a2,a1@@(PCB_USP)		| and save it

	tstl	_C_LABEL(fputype)	| Do we have an FPU?
	jeq	Lswnofpsave		| No  Then don't attempt save.
	lea	a1@@(PCB_FPCTX),a2	| pointer to FP save area
	fsave	a2@@			| save FP state
	tstb	a2@@			| null state frame?
	jeq	Lswnofpsave		| yes, all done
	fmovem	fp0-fp7,a2@@(FPF_REGS)	| save FP general registers
	fmovem	fpcr/fpsr/fpi,a2@@(FPF_FPCR)	| save FP control registers

Lswnofpsave:
	movl	sp@@(8), a0		| newproc

	movl	a0, CURPROC
	movb	#SONPROC,a0@@(P_STAT)
	movl	a0@@(P_ADDR),a1		| get p_addr
	movl	a1,_C_LABEL(curpcb)

	/*
	 * Activate the process's address space.
	 * XXX Should remember the last USTP value loaded, and call this
	 * XXX only if it has changed.
	 */
	pea	a0@@			| push proc
	jbsr	_C_LABEL(pmap_activate)	| pmap_activate(p)
	addql	#4,sp
	movl	_C_LABEL(curpcb),a1	| restore p_addr

	lea	_ASM_LABEL(tmpstk),sp	| now goto a tmp stack for NMI

	moveml	a1@@(PCB_REGS),#0xFCFC	| and registers
	movl	a1@@(PCB_USP),a0
	movl	a0,usp			| and USP

	tstl	_C_LABEL(fputype)	| If we don't have an FPU,
	jeq	Lnofprest		|  don't try to restore it.
	lea	a1@@(PCB_FPCTX),a0	| pointer to FP save area
	tstb	a0@@			| null state frame?
	jeq	Lresfprest		| yes, easy
#if defined(M68040)
#if defined(M68020) || defined(M68030)
	cmpl	#MMU_68040,_C_LABEL(mmutype) | 68040?
	jne	Lresnot040		| no, skip
#endif
	clrl	sp@@-			| yes...
	frestore sp@@+			| ...magic!
Lresnot040:
#endif
	fmovem	a0@@(FPF_FPCR),fpcr/fpsr/fpi	| restore FP control registers
	fmovem	a0@@(FPF_REGS),fp0-fp7	| restore FP general registers
Lresfprest:
	frestore a0@@			| restore state

Lnofprest:
	movw	a1@@(PCB_PS),sr		| no, restore PS
	moveq	#1,d0			| return 1 (for alternate returns)
	rts

/*
 * savectx(pcb)
 * Update pcb, saving current processor state.
 */
ENTRY(savectx)
	movl	sp@@(4),a1
	movw	sr,a1@@(PCB_PS)
	movl	usp,a0			| grab USP
	movl	a0,a1@@(PCB_USP)		| and save it
	moveml	#0xFCFC,a1@@(PCB_REGS)	| save non-scratch registers

	tstl	_C_LABEL(fputype)	| Do we have FPU?
	jeq	Lsvnofpsave		| No?  Then don't save state.
	lea	a1@@(PCB_FPCTX),a0	| pointer to FP save area
	fsave	a0@@			| save FP state
	tstb	a0@@			| null state frame?
	jeq	Lsvnofpsave		| yes, all done
	fmovem	fp0-fp7,a0@@(FPF_REGS)	| save FP general registers
	fmovem	fpcr/fpsr/fpi,a0@@(FPF_FPCR)	| save FP control registers
Lsvnofpsave:
	moveq	#0,d0			| return 0
	rts

#if defined(M68040)
ENTRY(suline)
	movl	sp@@(4),a0		| address to write
	movl	_C_LABEL(curpcb),a1	| current pcb
	movl	#Lslerr,a1@@(PCB_ONFAULT) | where to return to on a fault
	movl	sp@@(8),a1		| address of line
	movl	a1@@+,d0			| get lword
	movsl	d0,a0@@+			| put lword
	nop				| sync
	movl	a1@@+,d0			| get lword
	movsl	d0,a0@@+			| put lword
	nop				| sync
	movl	a1@@+,d0			| get lword
	movsl	d0,a0@@+			| put lword
	nop				| sync
	movl	a1@@+,d0			| get lword
	movsl	d0,a0@@+			| put lword
	nop				| sync
	moveq	#0,d0			| indicate no fault
	jra	Lsldone
Lslerr:
	moveq	#-1,d0
Lsldone:
	movl	_C_LABEL(curpcb),a1	| current pcb
	clrl	a1@@(PCB_ONFAULT)	| clear fault address
	rts
#endif

/*
 * Invalidate entire TLB.
 */
ASENTRY_NOPROFILE(TBIA)
#if defined(M68040)
	cmpl	#MMU_68040,_C_LABEL(mmutype) | 68040?
	jne	Lmotommu3		| no, skip
	.word	0xf518			| yes, pflusha
	rts
Lmotommu3:
#endif
	pflusha
#if defined(M68020)
	tstl	_C_LABEL(mmutype)
	jgt	Ltbia851		| 68851 implies no d-cache
#endif
	movl	#DC_CLEAR,d0
	movc	d0,cacr			| invalidate on-chip d-cache
Ltbia851:
	rts

/*
 * Invalidate any TLB entry for given VA (TB Invalidate Single)
 */
ENTRY(TBIS)
	movl	sp@@(4),a0
#if defined(M68040)
	cmpl	#MMU_68040,_C_LABEL(mmutype) | 68040?
	jne	Lmotommu4		| no, skip
	movc	dfc,d1
	moveq	#FC_USERD,d0		| user space
	movc	d0,dfc
	.word	0xf508			| pflush a0@@
	moveq	#FC_SUPERD,d0		| supervisor space
	movc	d0,dfc
	.word	0xf508			| pflush a0@@
	movc	d1,dfc
	rts
Lmotommu4:
#endif
#if defined(M68020)
	tstl	_C_LABEL(mmutype)
	jle	Ltbis851
	pflushs	#0,#0,a0@@		| flush address from both sides
	rts
Ltbis851:
#endif
	pflush	#0,#0,a0@@		| flush address from both sides
	movl	#DC_CLEAR,d0
	movc	d0,cacr			| invalidate on-chip data cache
	rts

/*
 * Invalidate supervisor side of TLB
 */
ENTRY(TBIAS)
#if defined(M68040)
	cmpl	#MMU_68040,_C_LABEL(mmutype) | 68040?
	jne	Lmotommu5		| no, skip
	.word	0xf518			| yes, pflusha (for now) XXX
	rts
Lmotommu5:
#endif
#if defined(M68020)
	tstl	_C_LABEL(mmutype)
	jle	Ltbias851
	pflushs	#4,#4			| flush supervisor TLB entries
	rts
Ltbias851:
#endif
	pflush	#4,#4			| flush supervisor TLB entries
	movl	#DC_CLEAR,d0
	movc	d0,cacr			| invalidate on-chip d-cache
	rts

/*
 * Invalidate instruction cache
 */
ENTRY(ICIA)
#if defined(M68040)
	cmpl	#MMU_68040,_C_LABEL(mmutype) | 68040?
	jne	Lmotommu7		| no, skip
	.word	0xf498			| cinva ic
	rts
Lmotommu7:
#endif
	movl	#IC_CLEAR,d0
	movc	d0,cacr			| invalidate i-cache
	rts

/*
 * Invalidate data cache.
 *
 * NOTE: we do not flush 68030 on-chip cache as there are no aliasing
 * problems with DC_WA.  The only cases we have to worry about are context
 * switch and TLB changes, both of which are handled "in-line" in resume
 * and TBI*.
 * Because of this, since there is no way on 68040 and 68060 to flush
 * user and supervisor modes specfically, DCIS and DCIU are the same entry
 * point as DCIA.
 */
ENTRY(DCIA)
ENTRY(DCIS)
ENTRY(DCIU)
#if defined(M68040)
	cmpl	#MMU_68040,_C_LABEL(mmutype) | 68040 or 68060?
	jgt	1f			| no, skip
	.word	0xf478			| cpusha dc
1:
#endif
	rts

#ifdef M68040
ENTRY(ICPA)
	.word	0xf498			| cinva ic
	rts
ENTRY(DCFA)
	.word	0xf478			| cpusha dc
	rts
ENTRY(ICPL)	/* invalidate instruction physical cache line */
	movl	sp@@(4),a0		| address
	.word	0xf488			| cinvl ic,a0@@
	rts
ENTRY(ICPP)	/* invalidate instruction physical cache page */
	movl	sp@@(4),a0		| address
	.word	0xf490			| cinvp ic,a0@@
	rts
ENTRY(DCPL)	/* invalidate data physical cache line */
	movl	sp@@(4),a0		| address
	.word	0xf448			| cinvl dc,a0@@
	rts
ENTRY(DCPP)	/* invalidate data physical cache page */
	movl	sp@@(4),a0		| address
	.word	0xf450			| cinvp dc,a0@@
	rts
ENTRY(DCFL)	/* data cache flush line */
	movl	sp@@(4),a0		| address
	.word	0xf468			| cpushl dc,a0@@
	rts
ENTRY(DCFP)	/* data cache flush page */
	movl	sp@@(4),a0		| address
	.word	0xf470			| cpushp dc,a0@@
	rts
#endif /* M68040 */

ENTRY(PCIA)
#if defined(M68040)
	cmpl	#MMU_68040,_C_LABEL(mmutype) | 68040?
	jne	LmotommuB		| no, skip
	.word	0xf478			| cpusha dc
	rts
LmotommuB:
#endif
	movl	#DC_CLEAR,d0
	movc	d0,cacr			| invalidate on-chip d-cache
	rts

ENTRY_NOPROFILE(getsfc)
	movc	sfc,d0
	rts

ENTRY_NOPROFILE(getdfc)
	movc	dfc,d0
	rts

/*
 * Load a new user segment table pointer.
 */
ENTRY(loadustp)
	movl	sp@@(4),d0		| new USTP
	moveq	#PGSHIFT,d1
	lsll	d1,d0			| convert to addr
#if defined(M68040)
	cmpl	#MMU_68040,_C_LABEL(mmutype) | 68040?
	jne	LmotommuC		| no, skip
	.word	0xf518			| pflusha
	.long	0x4e7b0806		| movec d0, URP
	rts
LmotommuC:
#endif
	pflusha				| flush entire TLB
	lea	_C_LABEL(protorp),a0	| CRP prototype
	movl	d0,a0@@(4)		| stash USTP
	pmove	a0@@,crp			| load root pointer
	movl	#CACHE_CLR,d0
	movc	d0,cacr			| invalidate cache(s)
	rts

/*
 * Set processor priority level calls.  Most are implemented with
 * inline asm expansions.  However, spl0 requires special handling
 * as we need to check for our emulated software interrupts.
 */

ENTRY(spl0)
	moveq	#0,d0
	movw	sr,d0			| get old SR for return
	movw	#PSL_LOWIPL,sr		| restore new SR
	tstl	_C_LABEL(softpending)	| software interrupt pending?
	jeq	Lspldone		| no, all done
	subql	#4,sp			| make room for RTE frame
	movl	sp@@(4),sp@@(2)		| position return address
	clrw	sp@@(6)			| set frame type 0
	movw	#PSL_LOWIPL,sp@@		| and new SR
	jra	Lgotsir			| go handle it
Lspldone:
	rts

/*
 * Save and restore 68881 state.
 * Pretty awful looking since our assembler does not
 * recognize FP mnemonics.
 */
ENTRY(m68881_save)
	movl	sp@@(4),a0		| save area pointer
	fsave	a0@@			| save state
	tstb	a0@@			| null state frame?
	jeq	Lm68881sdone		| yes, all done
	fmovem fp0-fp7,a0@@(FPF_REGS)	| save FP general registers
	fmovem fpcr/fpsr/fpi,a0@@(FPF_FPCR)	| save FP control registers
Lm68881sdone:
	rts

ENTRY(m68881_restore)
	movl	sp@@(4),a0		| save area pointer
	tstb	a0@@			| null state frame?
	jeq	Lm68881rdone		| yes, easy
	fmovem	a0@@(FPF_FPCR),fpcr/fpsr/fpi	| restore FP control registers
	fmovem	a0@@(FPF_REGS),fp0-fp7	| restore FP general registers
Lm68881rdone:
	frestore a0@@			| restore state
	rts

/*
 * delay() - delay for a specified number of microseconds
 * _delay() - calibrator helper for delay()
 *
 * Notice that delay_factor is scaled up by a factor of 128 to avoid loss
 * of precision for small delays.  As a result of this we need to avoid
 * overflow.
 *
 * The branch target for the loops must be aligned on a half-line (8-byte)
 * boundary to minimize cache effects.  This guarantees both that there
 * will be no prefetch stalls due to cache line burst operations and that
 * the loops will run from a single cache half-line.
 */
	.balign	8			| align to half-line boundary

ALTENTRY(_delay, delay)
ENTRY(delay)
	movl	sp@@(4),d0		| get microseconds to delay
	cmpl	#0x40000,d0		| is it a "large" delay?
	bls	Ldelayshort		| no, normal calculation
	movql	#0x7f,d1		| adjust for scaled multipler (to
	addl	d1,d0			|   avoid overflow)
	lsrl	#7,d0
	mulul	_C_LABEL(delay_factor),d0 | calculate number of loop iterations
	bra	Ldelaysetup		| go do it!
Ldelayshort:
	mulul	_C_LABEL(delay_factor),d0 | calculate number of loop iterations
	lsrl	#7,d0			| adjust for scaled multiplier
Ldelaysetup:
	jeq	Ldelayexit		| bail out if nothing to do
	movql	#0,d1			| put bits 15-0 in d1 for the
	movw	d0,d1			|   inner loop, and move bits
	movw	#0,d0			|   31-16 to the low-order word
	subql	#1,d1			|   of d0 for the outer loop
	swap	d0
Ldelay:
	tstl	_C_LABEL(delay_flag)	| this never changes for delay()!
	dbeq	d1,Ldelay		|   (used only for timing purposes)
	dbeq	d0,Ldelay
	addqw	#1,d1			| adjust end count and
	swap	d0			|    return the longword result
	orl	d1,d0
Ldelayexit:
	rts

/*
 * Handle the nitty-gritty of rebooting the machine.
 * Basically we just turn off the MMU and jump to the appropriate ROM routine.
 * Note that we must be running in an address range that is mapped one-to-one
 * logical to physical so that the PC is still valid immediately after the MMU
 * is turned off.  We have conveniently mapped the last page of physical
 * memory this way.
 */
ENTRY_NOPROFILE(doboot)
#if defined(M68040)
	cmpl	#MMU_68040,_C_LABEL(mmutype) | 68040?
	jeq	Lnocache5		| yes, skip
#endif
	movl	#CACHE_OFF,d0
	movc	d0,cacr			| disable on-chip cache(s)
Lnocache5:
	movl	_C_LABEL(maxaddr),a0	| last page of physical memory
	lea	Lbootcode,a1		| start of boot code
	lea	Lebootcode,a3		| end of boot code
Lbootcopy:
	movw	a1@@+,a0@@+		| copy a word
	cmpl	a3,a1			| done yet?
	jcs	Lbootcopy		| no, keep going
#if defined(M68040)
	cmpl	#MMU_68040,_C_LABEL(mmutype) | 68040?
	jne	LmotommuE		| no, skip
	.word	0xf4f8			| cpusha bc
LmotommuE:
#endif
	movl	_C_LABEL(maxaddr),a0
	jmp	a0@@			| jump to last page

Lbootcode:
	lea	a0@@(0x800),sp		| physical SP in case of NMI
	movl	_C_LABEL(MacOSROMBase),a1 | Load MacOS ROMBase

#if defined(M68040)
	cmpl	#MMU_68040,_C_LABEL(mmutype) | 68040?
	jne	LmotommuF		| no, skip
	movl	#0,d0
	movc	d0,cacr			| caches off
	.long	0x4e7b0003		| movc d0,tc (disable MMU)
	jra	Ldoboot1
LmotommuF:
#endif
	movl	#0,a3@@			| value for pmove to TC (turn off MMU)
	pmove	a3@@,tc			| disable MMU

Ldoboot1:
	lea	a1@@(0x90),a1		| offset of ROM reset routine
	jmp	a1@@			| and jump to ROM to reset machine
Lebootcode:

/*
 * u_long ptest040(caddr_t addr, u_int fc);
 *
 * ptest040() does an 040 PTESTR (addr) and returns the 040 MMUSR iff
 * translation is enabled.  This allows us to find the physical address
 * corresponding to a MacOS logical address for get_physical().
 * sar  01-oct-1996
 */
ENTRY_NOPROFILE(ptest040)
#if defined(M68040)
	.long	0x4e7a0003		| movc tc,d0
	andw	#0x8000,d0
	jeq	Lget_phys1		| MMU is disabled
	movc	dfc,d1			| Save DFC
	movl	sp@@(8),d0		| Set FC for ptestr
	movc	d0,dfc
	movl	sp@@(4),a0		| logical address to look up
	.word	0xf568			| ptestr (a0)
	.long	0x4e7a0805		| movc mmusr,d0
	movc	d1,dfc			| Restore DFC
	rts
Lget_phys1:
#endif
	movql	#0,d0			| return failure
	rts

/*
 * LAK: (7/24/94) This routine was added so that the
 *  C routine that runs at startup can figure out how MacOS
 *  had mapped memory.  We want to keep the same mapping so
 *  that when we set our MMU pointer, the PC doesn't point
 *  in the middle of nowhere.
 *
 * long get_pte(void *addr, unsigned long pte[2], unsigned short *psr)
 *
 *  Takes "addr" and looks it up in the current MMU pages.  Puts
 *  the PTE of that address in "pte" and the result of the
 *  search in "psr".  "pte" should be 2 longs in case it is
 *  a long-format entry.
 *
 *  One possible problem here is that setting the TT register
 *  may screw something up if we access user data space in a
 *  called function or in an interrupt service routine.
 *
 *  Returns -1 on error, 0 if pte is a short-format pte, or
 *  1 if pte is a long-format pte.
 *
 *  Be sure to only call this routine if the MMU is enabled.  This
 *  routine is probably more general than it needs to be -- it
 *  could simply return the physical address (replacing
 *  get_physical() in machdep).
 *
 *  "gas" does not understand the tt0 register, so we must hand-
 *  assemble the instructions.
 */
ENTRY_NOPROFILE(get_pte)
	subql	#4,sp		| make temporary space

	lea	_ASM_LABEL(longscratch),a0
	movl	#0x00ff8710,a0@@	| Set up FC 1 r/w access
	.long	0xf0100800	| pmove a0@@,tt0

	movl	sp@@(8),a0	| logical address to look up
	movl	#0,a1		| clear in case of failure
	ptestr	#FC_USERD,a0@@,#7,a1 | search for logical address
	pmove	psr,sp@@		| store processor status register
	movw	sp@@,d1
	movl	sp@@(16),a0	| where to store the psr
	movw	d1,a0@@		| send back to caller
	andw	#0xc400,d1	| if bus error, exceeded limit, or invalid
	jne	get_pte_fail1	| leave now
	tstl	a1		| check address we got back
	jeq	get_pte_fail2	| if 0, then was not set -- fail

	movl	a1,d0
	movl	d0,_ASM_LABEL(pte_tmp)	| save for later

	| send first long back to user
	movl	sp@@(12),a0	| address of where to put pte
	movsl	a1@@,d0		|
	movl	d0,a0@@		| first long

	andl	#3,d0		| dt bits of pte
	cmpl	#1,d0		| should be 1 if page descriptor
	jne	get_pte_fail3	| if not, get out now

	movl	sp@@(16),a0	| addr of stored psr
	movw	a0@@,d0		| get psr again
	andw	#7,d0		| number of levels it found
	addw	#-1,d0		| find previous level
	movl	sp@@(8),a0	| logical address to look up
	movl	#0,a1		| clear in case of failure

	cmpl	#0,d0
	jeq	pte_level_zero
	cmpl	#1,d0
	jeq	pte_level_one
	cmpl	#2,d0
	jeq	pte_level_two
	cmpl	#3,d0
	jeq	pte_level_three
	cmpl	#4,d0
	jeq	pte_level_four
	cmpl	#5,d0
	jeq	pte_level_five
	cmpl	#6,d0
	jeq	pte_level_six
	jra	get_pte_fail4	| really should have been one of these...

pte_level_zero:
	| must get CRP to get length of entries at first level
	lea	_ASM_LABEL(longscratch),a0 | space for two longs
	pmove	crp,a0@@		| save root pointer
	movl	a0@@,d0		| load high long
	jra	pte_got_parent
pte_level_one:
	ptestr	#FC_USERD,a0@@,#1,a1 | search for logical address
	pmove	psr,sp@@		| store processor status register
	movw	sp@@,d1
	jra	pte_got_it
pte_level_two:
	ptestr	#FC_USERD,a0@@,#2,a1 | search for logical address
	pmove	psr,sp@@		| store processor status register
	movw	sp@@,d1
	jra	pte_got_it
pte_level_three:
	ptestr	#FC_USERD,a0@@,#3,a1 | search for logical address
	pmove	psr,sp@@		| store processor status register
	movw	sp@@,d1
	jra	pte_got_it
pte_level_four:
	ptestr	#FC_USERD,a0@@,#4,a1 | search for logical address
	pmove	psr,sp@@		| store processor status register
	movw	sp@@,d1
	jra	pte_got_it
pte_level_five:
	ptestr	#FC_USERD,a0@@,#5,a1 | search for logical address
	pmove	psr,sp@@		| store processor status register
	movw	sp@@,d1
	jra	pte_got_it
pte_level_six:
	ptestr	#FC_USERD,a0@@,#6,a1 | search for logical address
	pmove	psr,sp@@		| store processor status register
	movw	sp@@,d1

pte_got_it:
	andw	#0xc400,d1	| if bus error, exceeded limit, or invalid
	jne	get_pte_fail5	| leave now
	tstl	a1		| check address we got back
	jeq	get_pte_fail6	| if 0, then was not set -- fail

	movsl	a1@@,d0		| get pte of parent
	movl	d0,_C_LABEL(macos_tt0)	| XXX for later analysis (kill me)
pte_got_parent:
	andl	#3,d0		| dt bits of pte
	cmpl	#2,d0		| child is short-format descriptor
	jeq	short_format
	cmpl	#3,d0		| child is long-format descriptor
	jne	get_pte_fail7

	| long_format -- we must go back, change the tt, and get the
	|  second long.  The reason we didn't do this in the first place
	|  is that the first long might have been the last long of RAM.

	movl	_ASM_LABEL(pte_tmp),a1	| get address of our original pte
	addql	#4,a1		| address of ite second long

	| send second long back to user
	movl	sp@@(12),a0	| address of where to put pte
	movsl	a1@@,d0		|
	movl	d0,a0@@(4)	| write in second long

	movql	#1,d0		| return long-format
	jra	get_pte_success

short_format:
	movql	#0,d0		| return short-format
	jra	get_pte_success

#ifndef DEBUG
get_pte_fail1:
get_pte_fail2:
get_pte_fail3:
get_pte_fail4:
get_pte_fail5:
get_pte_fail6:
get_pte_fail7:
get_pte_fail8:
get_pte_fail9:
get_pte_fail10:
#endif
get_pte_fail:
	movql	#-1,d0		| return failure

get_pte_success:
	lea	_ASM_LABEL(longscratch),a0 | disable tt
	movl	#0,a0@@
	.long	0xf0100800	| pmove a0@@,tt0

	addql	#4,sp		| return temporary space
	rts

#ifdef DEBUG
get_pte_fail10:
	jbsr	_C_LABEL(printstar)
get_pte_fail9:
	jbsr	_C_LABEL(printstar)
get_pte_fail8:
	jbsr	_C_LABEL(printstar)
get_pte_fail7:
	jbsr	_C_LABEL(printstar)
get_pte_fail6:
	jbsr	_C_LABEL(printstar)
get_pte_fail5:
	jbsr	_C_LABEL(printstar)
get_pte_fail4:
	jbsr	_C_LABEL(printstar)
get_pte_fail3:
	jbsr	_C_LABEL(printstar)
get_pte_fail2:
	jbsr	_C_LABEL(printstar)
get_pte_fail1:
	jbsr	_C_LABEL(printstar)
	jra	get_pte_fail
#endif

/*
 * Misc. global variables.
 */
	.data
GLOBAL(machineid)
	.long	0

GLOBAL(mmutype)
	.long	MMU_68851	| default to 68851 PMMU

GLOBAL(cputype)
	.long	CPU_68020	| default to 68020 CPU

GLOBAL(fputype)
	.long	FPU_68882	| default to 68882 FPU

GLOBAL(protorp)
	.long	0,0		| prototype root pointer

GLOBAL(cold)
	.long	1		| cold start flag

GLOBAL(want_resched)
	.long	0

GLOBAL(proc0paddr)
	.long	0		| KVA of proc0 u-area

GLOBAL(intiolimit)
	.long	0		| KVA of end of internal IO space

GLOBAL(load_addr)
	.long	0		| Physical address of kernel

ASLOCAL(lastpage)
	.long	0		| LAK: to store the addr of last page in mem

GLOBAL(MacOSROMBase)
	.long	0x40800000
GLOBAL(mac68k_vrsrc_cnt)
	.long	0
GLOBAL(mac68k_vrsrc_vec)
	.word	0, 0, 0, 0, 0, 0
@


1.63
log
@Remove COMPAT_HPUX.  No one wanted to support it and its fewmets were
blocking other cleanups
ok miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.62 2009/03/15 20:40:25 miod Exp $	*/
@


1.62
log
@Generic softinterrupt code for m68k platforms, now copied from m88k.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.61 2007/12/30 14:45:25 miod Exp $	*/
a1172 24

#if defined(COMPAT_HPUX)
/*
 * Invalidate user side of TLB
 */
ENTRY(TBIAU)
#if defined(M68040)
	cmpl	#MMU_68040,_C_LABEL(mmutype) | 68040?
	jne	Lmotommu6		| no, skip
	.word	0xf518			| yes, pflusha (for now) XXX
Lmotommu6:
#endif
#if defined(M68020)
	tstl	_C_LABEL(mmutype)
	jle	Ltbiau851
	pflush	#0,#4			| flush user TLB entries
	rts
Ltbiau851:
#endif
	pflush	#0,#4			| flush user TLB entries
	movl	#DC_CLEAR,d0
	movc	d0,cacr			| invalidate on-chip d-cache
	rts
#endif	/* COMPAT_HPUX */
@


1.61
log
@Correctly handle non-null state frames on 68020 and 68030 in fpfault.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.60 2007/11/24 20:58:26 deraadt Exp $	*/
d632 1
a632 1
	tstb	_C_LABEL(ssir)
d635 1
a635 1
	tstb	_C_LABEL(ssir)
d874 1
a874 1
BSS(ssir,1)
d912 1
a912 1
	tstb	_C_LABEL(ssir)		| SIR pending?
d921 1
a921 1
	tstb	_C_LABEL(ssir)		| too late?
d1321 1
a1321 1
	tstb	_C_LABEL(ssir)		| software interrupt pending?
@


1.60
log
@make ALTENTRY() use _C_LABEL() for the 2nd argument, and adjust callers
ok miod
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.59 2007/10/10 15:53:52 art Exp $	*/
d594 1
a594 1
	jle	Lfptnull
@


1.59
log
@Make context switching much more MI:
 - Move the functionality of choosing a process from cpu_switch into
   a much simpler function: cpu_switchto. Instead of having the locore
   code walk the run queues, let the MI code choose the process we
   want to run and only implement the context switching itself in MD
   code.
 - Let MD context switching run without worrying about spls or locks.
 - Instead of having the idle loop implemented with special contexts
   in MD code, implement one idle proc for each cpu. make the idle
   loop MI with MD hooks.
 - Change the proc lists from the old style vax queues to TAILQs.
 - Change the sleep queue from vax queues to TAILQs. This makes
   wakeup() go from O(n^2) to O(n)

there will be some MD fallout, but it will be fixed shortly.
There's also a few cleanups to be done after this.

deraadt@@, kettenis@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.58 2007/05/15 13:46:22 martin Exp $	*/
d1371 1
a1371 1
ALTENTRY(_delay, _delay)
@


1.58
log
@switch m68k to __HAVE_CPUINFO

help miod@@, art@@
ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.57 2007/03/17 20:05:22 miod Exp $	*/
a956 5
/*
 * Use common m68k process manipulation routines.
 */
#include <m68k/m68k/proc_subr.s>

d963 1
a963 23
/*
 * At exit of a process, do a switch for the last time.
 * Switch to a safe stack and PCB, and select a new process to run.  The
 * old stack and u-area will be freed by the reaper.
 */
ENTRY(switch_exit)
	movl	sp@@(4),a0
	/* save state into garbage pcb */
	movl	#_ASM_LABEL(nullpcb),_C_LABEL(curpcb)
	lea	_ASM_LABEL(tmpstk),sp	| goto a tmp stack

	/* Schedule the vmspace and stack to be freed. */
	movl	a0,sp@@-			| exit2(p)
	jbsr	_C_LABEL(exit2)
	lea	sp@@(4),sp		| pop args

	jra	_C_LABEL(cpu_switch)

/*
 * When no processes are on the runq, Swtch branches to Idle
 * to wait for something to come ready.
 */
ASENTRY_NOPROFILE(Idle)
d965 1
a965 8
	movw	#PSL_HIGHIPL,sr
	movl	_C_LABEL(whichqs),d0
	jeq	_ASM_LABEL(Idle)
	jra	Lsw1

Lbadsw:
	PANIC("switch")
	/*NOTREACHED*/
d968 1
a968 1
 * cpu_switch()
d978 3
a980 7
ENTRY(cpu_switch)
	movl	_C_LABEL(curpcb),a0	| current pcb
	movw	sr,a0@@(PCB_PS)		| save sr before changing ipl
#ifdef notyet
	movl	CURPROC,sp@@-		| remember last proc running
#endif
	clrl	CURPROC
a982 37
	 * Find the highest-priority queue that isn't empty,
	 * then take the first proc from that queue.
	 */
	movw	#PSL_HIGHIPL,sr		| lock out interrupts
	movl	_C_LABEL(whichqs),d0
	jeq	_ASM_LABEL(Idle)
Lsw1:
	movl	d0,d1
	negl	d0
	andl	d1,d0
	bfffo	d0{#0:#32},d1
	eorib	#31,d1

	movl	d1,d0
	lslb	#3,d1			| convert queue number to index
	addl	#_C_LABEL(qs),d1	| locate queue (q)
	movl	d1,a1
	movl	a1@@(P_FORW),a0		| p = q->p_forw
	cmpal	d1,a0			| anyone on queue?
	jeq	Lbadsw			| no, panic
	movl	a0@@(P_FORW),a1@@(P_FORW)	| q->p_forw = p->p_forw
	movl	a0@@(P_FORW),a1		| n = p->p_forw
	movl	d1,a1@@(P_BACK)		| n->p_back = q
	cmpal	d1,a1			| anyone left on queue?
	jne	Lsw2			| yes, skip
	movl	_C_LABEL(whichqs),d1
	bclr	d0,d1			| no, clear bit
	movl	d1,_C_LABEL(whichqs)
Lsw2:
	movl	a0,CURPROC
	clrl	_C_LABEL(want_resched)
#ifdef notyet
	movl	sp@@+,a1
	cmpl	a0,a1			| switching to same proc?
	jeq	Lswdone			| yes, skip save and restore
#endif
	/*
d986 1
d999 1
d1001 1
d1003 1
a1003 6
#ifdef DIAGNOSTIC
	tstl	a0@@(P_WCHAN)
	jne	Lbadsw
	cmpb	#SRUN,a0@@(P_STAT)
	jne	Lbadsw
#endif
a1004 1
	clrl	a0@@(P_BACK)		| clear back link
@


1.57
log
@Only invoke printstar() in get_pte() if option DEBUG.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.56 2006/07/06 17:49:45 miod Exp $	*/
d665 1
a665 1
	movl	_C_LABEL(curproc),sp@@-	| push proc pointer
d1016 1
a1016 1
	movl	_C_LABEL(curproc),sp@@-	| remember last proc running
d1018 1
a1018 1
	clrl	_C_LABEL(curproc)
d1050 1
a1050 1
	movl	a0,_C_LABEL(curproc)
@


1.56
log
@Insert an empty page at the beginning of the kernel, so that we can map it
invalid and have NULL pointer dereferences in the kernel fault now.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.55 2006/07/06 17:48:55 miod Exp $	*/
d1711 12
d1734 2
a1735 1
get_pte_fail1:
d1737 1
a1737 2
	jra	get_pte_fail
get_pte_fail2:
d1739 1
d1741 1
a1741 2
	jra	get_pte_fail
get_pte_fail3:
d1743 1
d1745 1
a1746 1
	jra	get_pte_fail
d1749 1
d1751 1
d1753 1
d1756 1
a1756 57
get_pte_fail5:
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jra	get_pte_fail
get_pte_fail6:
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jra	get_pte_fail
get_pte_fail7:
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jra	get_pte_fail
get_pte_fail8:
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jra	get_pte_fail
get_pte_fail9:
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jra	get_pte_fail
get_pte_fail10:
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jra	get_pte_fail
@


1.55
log
@Adapt rtclock_intr() to the current interrupt scheme; from NetBSD
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.54 2006/06/24 13:24:21 miod Exp $	*/
d89 5
d209 10
a218 2
	cmpl	#CPU_68040,a0@@		| 68040?
	jeq	1f			| yes, skip
a221 1
1:
d223 1
@


1.54
log
@Use pmap_enter_cache() instead of physacc() in bus_mem_add_mapping(), and let
physacc() die. As a bonus, kvtop() dies too.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.53 2006/06/11 20:57:44 miod Exp $	*/
d834 6
a839 4
	movl	a6@@(8),a1		| get pointer to frame in via1_intr
	movl	a1@@(64),sp@@-		| push ps
	movl	a1@@(68),sp@@-		| push pc
	movl	sp,sp@@-			| push pointer to ps, pc
d841 1
a841 1
	lea	sp@@(12),sp		| pop params
@


1.53
log
@Clean the various cache and TLB invalidation function, arch by arch:
- [DI]C{FL,PL,PP} and DCFA are only called on 680[46]0 systems and are
  identical on these platforms, so don't bother checking for the MMU type.
- TBIAS is on 68060 codepath only.
- DCIAS, PCIA and TBIA are specific to some platforms and do not need to be
  implemented everywhere.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.52 2006/06/11 20:49:27 miod Exp $	*/
d333 1
a333 1
	jbsr	_C_LABEL(TBIA)		| invalidate TLB
d1165 1
a1165 1
ENTRY(TBIA)
@


1.52
log
@Remove traces of cut'n'pasted 68060 support, since there aren't any 68060-based
macintoshes.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.51 2006/01/21 12:27:58 miod Exp $	*/
a1165 1
__TBIA:
a1186 4
#ifdef DEBUG
	tstl	_ASM_LABEL(fulltflush)	| being conservative?
	jne	_C_LABEL(_TBIA)		| yes, flush entire TLB
#endif
a1217 4
#ifdef DEBUG
	tstl	_ASM_LABEL(fulltflush)	| being conservative?
	jne	_C_LABEL(_TBIA)		| yes, flush everything
#endif
d1237 1
a1241 4
#ifdef DEBUG
	tstl	_ASM_LABEL(fulltflush)	| being conservative?
	jne	_C_LABEL(_TBIA)		| yes, flush everything
#endif
d1259 1
a1265 1
ENTRY(ICPA)
d1278 1
d1283 3
d1288 2
a1289 1
_C_LABEL(_DCIA):
d1291 2
a1292 2
	cmpl	#MMU_68040,_C_LABEL(mmutype) | 68040?
	jne	Lmotommu8		| no, skip
d1294 1
a1294 1
Lmotommu8:
d1298 3
a1300 8
ENTRY(DCIS)
_C_LABEL(_DCIS):
#if defined(M68040)
	cmpl	#MMU_68040,_C_LABEL(mmutype) | 68040?
	jne	Lmotommu9		| no, skip
	.word	0xf478			| cpusha dc
Lmotommu9:
#endif
d1302 1
a1302 6

ENTRY(DCIU)
_C_LABEL(_DCIU):
#if defined(M68040)
	cmpl	#MMU_68040,_C_LABEL(mmutype) | 68040?
	jne	LmotommuA		| no, skip
a1303 2
LmotommuA:
#endif
a1304 2

#ifdef M68040
a1320 3
ENTRY(DCPA)	/* invalidate instruction physical cache line */
	.word	0xf458			| cinva dc
	rts
a1332 1
ENTRY(DCFA)
a1825 8

#ifdef DEBUG
ASGLOBAL(fulltflush)
	.long	0

ASGLOBAL(fullcflush)
	.long	0
#endif
@


1.51
log
@Remove old mdpflag debug help.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.50 2006/01/13 19:36:45 miod Exp $	*/
d387 1
a387 1
#if defined(M68040) || defined(M68060)
a398 40
#if defined(M68060)
ENTRY_NOPROFILE(buserr60)
	clrl	sp@@-			| stack adjust count
	moveml	#0xFFFF,sp@@-		| save user registers
	movl	usp,a0			| save the user SP
	movl	a0,sp@@(FR_SP)		|   in the savearea
	movel	sp@@(FR_HW+12),d0	| FSLW
	btst	#2,d0			| branch prediction error?
	jeq	Lnobpe
	movc	cacr,d2
	orl	#IC60_CABC,d2		| clear all branch cache entries
	movc	d2,cacr
	movl	d0,d1
	addql	#1,L60bpe
	andl	#0x7ffd,d1
	jeq	_ASM_LABEL(faultstkadjnotrap2)
Lnobpe:
| we need to adjust for misaligned addresses
	movl	sp@@(FR_HW+8),d1		| grab VA
	btst	#27,d0			| check for mis-aligned access
	jeq	Lberr3			| no, skip
	addl	#28,d1			| yes, get into next page
					| operand case: 3,
					| instruction case: 4+12+12
	andl	#PG_FRAME,d1		| and truncate
Lberr3:
	movl	d1,sp@@-
	movl	d0,sp@@-			| code is FSLW now.
	andw	#0x1f80,d0 
	jeq	Lberr60			| it is a bus error
	movl	#T_MMUFLT,sp@@-		| show that we are an MMU fault
	jra	_ASM_LABEL(faultstkadj)	| and deal with it
Lberr60:
	tstl	_C_LABEL(nofault)	| catch bus error?
	jeq	Lisberr			| no, handle as usual
	movl	sp@@(FR_HW+8+8),_C_LABEL(m68k_fault_addr) | save fault addr
	movl	_C_LABEL(nofault),sp@@-	| yes,
	jbsr	_C_LABEL(longjmp)	|  longjmp(nofault)
	/* NOTREACHED */
#endif
@


1.50
log
@Remove the Mac Rom Glue code completely. With the ADB ``direct'' code being
used by default, and since all PRAM accesses are either directly fiddling
with VIA registers or through ADB commands, the MRG code has no reason to
stay. This means the kernel is now not running unknown PROM code anymore.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.49 2006/01/04 20:39:05 miod Exp $	*/
a988 1
GLOBAL(masterpaddr)		| XXX compatibility (debuggers)
a990 4
ASLOCAL(mdpflag)
	.byte	0		| copy of proc md_flags low byte
	.align	2

a1107 1
	movb	a0@@(P_MD_FLAGS+3),mdpflag | low byte of p_md.md_flags
@


1.49
log
@Import NetBSD's direct adb code on mac68k, switching to real keyboard and mouse
drivers, and to wscons as the console; a few parts borrowed from OpenBSD/macppc
as well.

Currently only working with displays configured in 1bpp or 8bpp modes; this
limitation will be worked on ASAP.

Tested by claudio@@ kettenis@@ martin@@ nick@@ and I on various models. X11 changes
coming soon.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.48 2006/01/01 13:16:01 miod Exp $	*/
a88 10
 * Mac OS global variable space; storage for global variables used by
 * Mac ROM traps and glue routines (see macrom.c, macrom.h macromasm.s)
 *
 * Some routine running before ADBReInit chooses to write to 0x1fb8.
 * With the trap table from 0x0 to 0x3ff, this additional space of
 * 0x2a00 should be sufficient.
 */
	.space 0x2a00

/*
a779 4
#if 0	/* not needed on mac68k */
	cmpl	#0,d0			| did ddb handle it?
	jne	Lbrkpt3			| yes, done
#endif
a780 1
	/* Sun 3 drops into PROM here. */
a879 1
	jbsr	_C_LABEL(mrg_VBLQueue)	| give programs in the VBLqueue a chance
@


1.48
log
@Enable A/UX style interrupt routing on non-AV Centrises and Quadras, gives us
smarter spl levels and the clock drift is reduced; adapted from NetBSD.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.47 2006/01/01 13:14:44 miod Exp $	*/
a347 5
#ifdef __notyet__
	tstl	_C_LABEL(ectype)
	jeq	Lnocache0
					| Enable external cache here
#endif
a351 1
	movw	#PSL_LOWIPL,sr		| lower SPL ; enable interrupts
a1881 5

#ifdef __notyet__
GLOBAL(ectype)
	.long	EC_NONE		| external cache type, default to none
#endif
@


1.47
log
@Service clock interrupts at the computed splclock(), not spl2(); from NetBSD.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.46 2005/11/13 23:14:34 miod Exp $	*/
a860 23
	addql	#1,_C_LABEL(uvmexp)+UVMEXP_INTRS
	jra	_ASM_LABEL(rei)

ENTRY_NOPROFILE(lev1intr)
	clrl	sp@@-
	moveml	#0xFFFF,sp@@-
	movl	sp, sp@@-
	jbsr	_C_LABEL(via1_intr)
	addql	#4,sp
	moveml	sp@@+,#0xFFFF
	addql	#4,sp
	addql	#1,_C_LABEL(uvmexp)+UVMEXP_INTRS
	jra	_ASM_LABEL(rei)

ENTRY_NOPROFILE(lev2intr)
	clrl	sp@@-
	moveml	#0xFFFF,sp@@-
	movl	sp, sp@@-
	movl	_C_LABEL(real_via2_intr),a2
	jbsr	a2@@
	addql	#4,sp
	moveml	sp@@+,#0xFFFF
	addql	#4,sp
@


1.46
log
@Align _delay() on 8 bytes, not 2^8 bytes.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.45 2005/09/13 14:05:49 martin Exp $	*/
d917 1
a917 1
	movw	#SPL2,sr		| raise SPL to splclock()
@


1.45
log
@merge the macglobals one-liner into locore

prompted by miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.44 2004/12/30 21:28:48 miod Exp $	*/
d1548 1
a1548 1
	.align	8			| align to half-line boundary
@


1.44
log
@If we are running on a 68040 or a 68060 processor, overwrite the copypage()
code with the faster copypage040() before the kernel text is mapped read-only.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.43 2004/12/26 22:36:34 miod Exp $	*/
d88 9
a96 1
#include <mac68k/mac68k/macglobals.s>
@


1.43
log
@Typo
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.42 2004/12/24 22:50:30 miod Exp $	*/
d257 19
@


1.42
log
@{e,}intr{cnt,names} bye-bye.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.41 2004/12/01 23:02:55 miod Exp $	*/
d729 1
a729 1
	| If were are not on tmpstk switch to it.
@


1.41
log
@Do not store preciouss data below the kernel stack, or they risk becoming
invisible and being lost...
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.40 2004/12/01 21:20:17 miod Exp $	*/
a1927 6

/* old interrupt counters */
GLOBAL(intrnames)
GLOBAL(eintrnames)
GLOBAL(intrcnt)
GLOBAL(eintrcnt)
@


1.40
log
@No more splnone alias for spl0.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.39 2004/11/30 01:44:22 martin Exp $	*/
a87 1
#include <mac68k/mac68k/vectors.s>
d120 2
@


1.39
log
@provide a more accurate assembly delay() routine

ok miod@@

>From: NetBSD
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.38 2004/11/27 14:26:32 miod Exp $	*/
a1467 1
ALTENTRY(splnone, _spl0)
@


1.38
log
@In pmap_bootstrap(), replace PMAP_MD_RWZERO, which would leave the lowest
page writeable, with PMAP_MD_RWLOW, which tells how many pages have to be
left writeable on low addresses, since the mac rom needs more than one.
This lets non-DDB mac68k kernels run.
No change on non-mac68k platforms.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.37 2004/11/26 21:21:28 miod Exp $	*/
d1506 45
@


1.37
log
@More interrupt system cleaning and homogenization:
- switch all interrupt functions to an int (*)(void *) prototype.
- do not register dummy functions for all unhandled interrupts, instead
  let the dispatchers cope with NULL.
- add evcount interrupt counters.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.36 2004/11/25 18:32:10 miod Exp $	*/
d125 1
@


1.36
log
@Move towards a more flexible and generic interrupt system, as well as better
zs behaviour.

From NetBSD; integration work by Martin Reindl
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.35 2004/07/02 17:33:43 miod Exp $	*/
a831 1
	addql	#1,_C_LABEL(intrcnt)+0
a835 1
	addql	#1,_C_LABEL(intrcnt)+4
a846 1
	addql	#1,_C_LABEL(intrcnt)+8
a867 1
	addql	#1,_C_LABEL(intrcnt)+16
a895 2
	addql	#1,_C_LABEL(intrcnt)+20
	addql	#1,_C_LABEL(uvmexp)+UVMEXP_INTRS
d1883 1
a1883 2
/* interrupt counters */

a1884 9
	.asciz	"spur"
	.asciz	"via1"
	.asciz	"via2"
	.asciz	"scc"
	.asciz	"nmi"
	.asciz	"clock"
	.asciz	"unused1"
	.asciz	"unused2"
	.asciz	"unused3"
a1885 2
	.even

a1886 1
	.long	0,0,0,0,0,0,0,0,0
@


1.35
log
@Cope with SONPROC scheduler changes.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.34 2004/05/20 09:20:42 kettenis Exp $	*/
d230 1
d234 1
d828 3
d861 5
a865 7
ENTRY_NOPROFILE(lev3intr)
	addql	#1,_C_LABEL(intrcnt)+24
	clrl	sp@@-
	moveml	#0xFFFF,sp@@-
	movl	sp, sp@@-
	movl	_C_LABEL(lev3_intrvec),a2
	jbsr	a2@@
d867 2
a868 49
	moveml	sp@@+, #0xFFFF
	addql	#4,sp
	addql	#1,_C_LABEL(uvmexp)+UVMEXP_INTRS
	jra	_ASM_LABEL(rei)

ENTRY_NOPROFILE(lev4intr)
	addql	#1,_C_LABEL(intrcnt)+12
	clrl	sp@@-
	moveml	#0xFFFF,sp@@-
	movl	sp, sp@@-
	movl	_C_LABEL(lev4_intrvec),a2
	jbsr	a2@@
	addql	#4,sp
	tstl	d0
	beq	normal_rei
	moveml	sp@@+, #0xFFFF
	addql	#4,sp
	rte
normal_rei:
	moveml	sp@@+, #0xFFFF
	addql	#4,sp
	addql	#1,_C_LABEL(uvmexp)+UVMEXP_INTRS
	jra	_ASM_LABEL(rei)

ENTRY_NOPROFILE(lev5intr)
	addql	#1,_C_LABEL(intrcnt)+28
	clrl	sp@@-
	moveml	#0xFFFF,sp@@-
	movl	sp, sp@@-
	movl	_C_LABEL(lev5_intrvec),a2
	jbsr	a2@@
	addql	#4,sp
	moveml	sp@@+, #0xFFFF
	addql	#4,sp
	addql	#1,_C_LABEL(uvmexp)+UVMEXP_INTRS
	jra	_ASM_LABEL(rei)

ENTRY_NOPROFILE(lev6intr)
	addql	#1,_C_LABEL(intrcnt)+32
	clrl	sp@@-
	moveml	#0xFFFF,sp@@-
	movl	sp, sp@@-
	movl	_C_LABEL(lev6_intrvec),a2
	jbsr	a2@@
	addql	#4,sp
	moveml	sp@@+, #0xFFFF
	addql	#4,sp
	addql	#1,_C_LABEL(uvmexp)+UVMEXP_INTRS
	jra	_ASM_LABEL(rei)
@


1.34
log
@Properly flush instruction cache for ptrace(PT_WRTIE_{DI}, ...) on powerpc
and m68k.
ok drahn@@, millert@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.33 2004/03/08 23:48:26 xsa Exp $	*/
d1177 1
@


1.33
log
@
typo; from Martin Reindl <mreindl at catai.org>
ok miod@@.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.32 2003/06/02 23:27:49 millert Exp $	*/
d677 1
d679 1
a679 1
	lea	sp@@(12),sp		| pop args
@


1.32
log
@Remove the advertising clause in the UCB license which Berkeley
rescinded 22 July 1999.  Proofed by myself and Theo.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.31 2002/04/25 22:49:51 miod Exp $	*/
d330 1
a330 1
 * main() nevers returns; we exit to user mode from a forked process
@


1.31
log
@Harmonize some bootstrap procedures with hp300, and move some variables
from text to data section.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.30 2002/02/10 23:15:05 deraadt Exp $	*/
d21 1
a21 5
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *	This product includes software developed by the University of
 *	California, Berkeley and its contributors.
 * 4. Neither the name of the University nor the names of its contributors
@


1.30
log
@spelling
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.29 2001/12/06 21:13:28 millert Exp $	*/
d120 6
a158 2
	movl	#CACHE_OFF,d0		| disable and clear both caches
	movc	d0,cacr
d224 1
a224 1
 * Figure out MacOS mappings and bootstrap NetBSD
d269 1
d609 1
a609 1
	cmpl	#CPU_68040,_C_LABEL(cputype)
d693 7
d701 3
a703 2
	andw	#PSL_S,d1		| from system mode?
	jne	Lkbrkpt			| yes, kernel breakpoint
d768 1
a768 1
#if 0	/* not needed on hp300 */
d1056 1
d1207 1
d1210 1
d1291 1
a1291 1
	jgt	Ltbia851
d1410 1
a1410 1
__DCIA:
d1420 1
a1420 1
__DCIS:
d1430 1
a1430 1
__DCIU:
a1881 6
GLOBAL(sanity_check)
	.long	0x18621862	| this is our stack overflow checker.

	.space	4 * NBPG
ASLOCAL(tmpstk)

d1883 1
a1883 1
	.long	0		| default to 320
@


1.29
log
@Define proper macros for FP frame offsets rather than magic numbers.
From NetBSD (tsutsui).
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.28 2001/08/13 00:01:41 miod Exp $	*/
d506 1
a506 1
					| (we dont seperate data/program)
@


1.29.2.1
log
@Sync UBC branch to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.29 2001/12/06 21:13:28 millert Exp $	*/
a119 6
GLOBAL(sanity_check)
	.long	0x18621862	| this is our stack overflow checker.

	.space	4 * NBPG
ASLOCAL(tmpstk)

d153 2
d220 1
a220 1
 * Figure out MacOS mappings and bootstrap OpenBSD
a264 1
	.word	0xf4d8			| cinva bc
d506 1
a506 1
					| (we dont separate data/program)
d604 1
a604 1
	cmpl	#FPU_68040,_C_LABEL(fputype)
a687 7

	| Check PSW and see what happened.
	|   T=0 S=0     (should not happen)
	|   T=1 S=0     trace trap from user mode
	|   T=0 S=1     trace trap on a trap instruction
	|   T=1 S=1     trace trap from system mode (kernel breakpoint)

d689 2
a690 3
	notw	d1			| XXX no support for T0 on 680[234]0
	andw	#PSL_TS,d1		| from system mode (T=1, S=1)?
	jeq	Lkbrkpt			| yes, kernel breakpoint
d755 1
a755 1
#if 0	/* not needed on mac68k */
a1042 1
	.data
a1192 1
#if defined(M68020) || defined(M68030)
a1194 1
#endif
d1275 1
a1275 1
	jgt	Ltbia851		| 68851 implies no d-cache
d1394 1
a1394 1
_C_LABEL(_DCIA):
d1404 1
a1404 1
_C_LABEL(_DCIS):
d1414 1
a1414 1
_C_LABEL(_DCIU):
d1866 6
d1873 1
a1873 1
	.long	0
@


1.28
log
@ecacheon(), ecacheoff() good bye.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.27 2001/06/27 04:22:37 art Exp $	*/
d1156 2
a1157 2
	fmovem	fp0-fp7,a2@@(216)	| save FP general registers
	fmovem	fpcr/fpsr/fpi,a2@@(312)	| save FP control registers
d1199 2
a1200 2
	fmovem	a0@@(312),fpcr/fpsr/fpi	| restore FP control registers
	fmovem	a0@@(216),fp0-fp7	| restore FP general registers
d1226 2
a1227 2
	fmovem	fp0-fp7,a0@@(216)	| save FP general registers
	fmovem	fpcr/fpsr/fpi,a0@@(312)	| save FP control registers
d1528 2
a1529 2
	fmovem fp0-fp7,a0@@(216)		| save FP general registers
	fmovem fpcr/fpsr/fpi,a0@@(312)	| save FP control registers
d1537 2
a1538 2
	fmovem	a0@@(312),fpcr/fpsr/fpi	| restore FP control registers
	fmovem	a0@@(216),fp0-fp7	| restore FP general registers
@


1.27
log
@old vm no more
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.26 2001/06/08 03:27:36 aaron Exp $	*/
a1463 6
	rts

ENTRY(ecacheon)
	rts

ENTRY(ecacheoff)
@


1.26
log
@More changes from NetBSD that should have been part of the UVM update; tested
by beck@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.25 2001/05/08 17:30:41 aaron Exp $	*/
a298 1
#if defined(UVM)
a299 3
#else
	jbsr	_C_LABEL(vm_set_page_size) | select software page size
#endif
a817 1
#if defined(UVM)
a818 3
#else
	addql	#1,_C_LABEL(cnt)+V_INTR
#endif
a829 1
#if defined(UVM)
a830 3
#else
	addql	#1,_C_LABEL(cnt)+V_INTR
#endif
a842 1
#if defined(UVM)
a843 3
#else
	addql	#1,_C_LABEL(cnt)+V_INTR
#endif
a855 1
#if defined(UVM)
a856 3
#else
	addql	#1,_C_LABEL(cnt)+V_INTR
#endif
a874 1
#if defined(UVM)
a875 3
#else
	addql	#1,_C_LABEL(cnt)+V_INTR
#endif
a887 1
#if defined(UVM)
a888 3
#else
	addql	#1,_C_LABEL(cnt)+V_INTR
#endif
a900 1
#if defined(UVM)
a901 3
#else
	addql	#1,_C_LABEL(cnt)+V_INTR
#endif
a934 1
#if defined(UVM)
a935 3
#else
	addql	#1,_C_LABEL(cnt)+V_INTR
#endif
@


1.25
log
@Substantial update from NetBSD, most notably gives us UVM support; deraadt@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.24 2001/04/06 09:34:15 art Exp $	*/
d119 2
a120 2
GLOBAL(esym)
	.long	0
@


1.24
log
@Get rid of vm_pmap.
beck@@ ok.
@
text
@d1 2
a2 2
/*	$OpenBSD: locore.s,v 1.23 2000/06/05 11:02:59 art Exp $	*/
/*	$NetBSD: locore.s,v 1.74 1997/02/02 08:17:46 thorpej Exp $	*/
d81 4
d86 1
a86 1
 * This is for kvm_mkdb, and should be the address of the beginning 
d90 235
a324 2
	.globl	_kernel_text
_kernel_text:
d326 4
a329 3
#include "assym.h"
#include "vectors.s"
#include "macglobals.s"
d332 14
a345 14
 * This is where we wind up if the kernel jumps to location 0.
 * (i.e. a bogus PC)  This is known to immediately follow the vector
 * table and is hence at 0x400 (see reset vector in vectors.s).
 */
	.globl	_panic, _panicstr
	.globl	_jmp0panic

_jmp0panic:
	tstl	_panicstr
	jeq	jmp0panic
	stop	#0x2700
jmp0panic:
	pea	Ljmp0panic
	jbsr	_panic
a346 3
Ljmp0panic:
	.asciz	"kernel jump to zero"
	.even
d348 17
d369 5
d375 52
a426 4
	.globl	_trap, _nofault, _longjmp, _mac68k_buserr_addr
_buserr:
	tstl	_nofault		| device probe?
	jeq	Lberr			| no, handle as usual
d428 1
a428 14
	cmpl	#MMU_68040,_mmutype	| 68040?
	jne	Lberrfault30		| no, handle as 030
	movl	sp@@(0x14),_mac68k_buserr_addr
	movl	_nofault,sp@@-		| yes,
	jbsr	_longjmp
#endif
Lberrfault30:
	movl	sp@@(0x10),_mac68k_buserr_addr
	movl	_nofault,sp@@-		| yes,
	jbsr	_longjmp		|  longjmp(nofault)
Lberr:
#if defined(M68040)
	cmpl	#MMU_68040,_mmutype	| 68040?
	jne	_addrerr		| no, skip
d433 1
a433 1
	lea	sp@@(FR_HW),a1		| grab base of HW berr frame
d435 4
a438 5
	movw	a1@@(12),d0		| grab SSW
	movl	a1@@(20),d1		| and fault VA
	btst	#11,d0			| check for mis-aligned access
	jeq	Lberr2			| no, skip
	addl	#3,d1			| yes, get into next page
d440 14
a453 13
Lberr2:
	movl	d1,sp@@-			| push fault VA
	movl	d0,sp@@-			| and padded SSW
	btst	#10,d0			| ATC bit set?
	jeq	Lisberr			| no, must be a real bus error
	movc	dfc,d1			| yes, get MMU fault
	movc	d0,dfc			| store faulting function code
	movl	sp@@(4),a0		| get faulting address
	.word	0xf568			| ptestr a0@@
	movc	d1,dfc
	.long	0x4e7a0805		| movc mmusr,d0
	movw	d0,sp@@			| save (ONLY LOW 16 BITS!)
	jra	Lismerr
d455 6
a460 2
_addrerr:
	clrl	sp@@-			| pad SR to longword
a463 9
	lea	sp@@(FR_HW),a1		| grab base of HW berr frame
#if defined(M68040)
	cmpl	#MMU_68040,_mmutype	| 68040?
	jne	Lbenot040		| no, skip
	movl	a1@@(8),sp@@-		| yes, push fault address
	clrl	sp@@-			| no SSW for address fault
	jra	Lisaerr			| go deal with it
Lbenot040:
#endif
d465 1
a465 1
	movw	a1@@(10),d0		| grab SSW for fault processing
d469 1
a469 1
	movw	d0,a1@@(10)		| for hardware, too
d474 1
a474 1
	movw	d0,a1@@(10)		| for hardware, too
d478 2
a479 2
	movl	a1@@(16),d1		| fault address is as given in frame
	jra	Lbe10			| that's it!
d481 1
a481 1
	btst	#4,a1@@(6)		| long (type B) stack frame?
d483 1
a483 1
	movl	a1@@(2),d1		| no, can use save PC
d494 1
a494 1
	movl	a1@@(36),d1		| long format, use stage B address
d501 1
a501 1
	movw	a1@@(6),d0		| get frame format/vector offset
d511 1
a511 1
	btst	#5,a1@@			| supervisor mode?
d521 4
a524 2
	jeq	Lismerr			| no, must be fast
	jra	Lisberr1		| real bus err needs not be fast.
d531 2
a532 4
	jeq	Lisberr1		| yes, was not WPE, must be bus err
Lismerr:
	movl	#T_MMUFLT,sp@@-		| show that we are an MMU fault
	jra	Ltrapnstkadj		| and deal with it
d535 1
a535 1
	jra	Ltrapnstkadj		| and deal with it
d538 8
a545 1
Lisberr:
d547 1
a547 21
Ltrapnstkadj:
	jbsr	_trap			| handle the error
	lea	sp@@(12),sp		| pop value args
	movl	sp@@(FR_SP),a0		| restore user SP
	movl	a0,usp			|   from save area
	movw	sp@@(FR_ADJ),d0		| need to adjust stack?
	jne	Lstkadj			| yes, go to it
	moveml	sp@@+,#0x7FFF		| no, restore most user regs
	addql	#8,sp			| toss SSP and pad
	jra	rei			| all done
Lstkadj:
	lea	sp@@(FR_HW),a1		| pointer to HW frame
	addql	#8,a1			| source pointer
	movl	a1,a0			| source
	addw	d0,a0			|  + hole size = dest pointer
	movl	a1@@-,a0@@-		| copy
	movl	a1@@-,a0@@-		|  8 bytes
	movl	a0,sp@@(FR_SP)		| new SSP
	moveml	sp@@+,#0x7FFF		| restore user registers
	movl	sp@@,sp			| and our SP
	jra	rei			| all done
d552 1
a552 1
_fpfline:
d554 1
a554 1
	cmpl	#FPU_68040,_fputype	| 68040? (see fpu.c)
d557 1
a557 1
	jne	Lfp_unimp		| no, FPEMUL or illinst
d560 1
a560 2
	.globl	fpsp_unimp
	jmp	fpsp_unimp		| go handle in fpsp
d563 1
a563 1
#endif
d565 4
a568 4
	clrl	sp@@-		| pad SR to longword
	moveml	#0xFFFF,sp@@-	| save user registers
	moveq	#T_FPEMULI,d0	| denote it as an FP emulation trap.
	jra	fault		| do it.
d570 1
a570 1
	jra	_illinst
d573 1
a573 1
_fpunsupp:
d575 2
a576 2
	cmpl	#FPU_68040,_fputype	| 68040? (see fpu.c)
	jne	Lfp_unsupp		| no, treat as illinst
d578 1
a578 2
	.globl	fpsp_unsupp
	jmp	fpsp_unsupp		| yes, go handle it
d581 1
a581 1
#endif
d583 4
a586 4
	clrl	sp@@-			| pad SR to longword
	moveml	#0xFFFF,sp@@-		| save user registers
	moveq	#T_FPEMULD,d0		| denote it as an FP emulation trap.
	jra	fault			| do it.
d588 1
a588 1
	jra	_illinst
d597 2
a598 2
_fpfault:
	clrl	sp@@-		| pad SR to longword
d603 1
a603 1
	movl	_curpcb,a0	| current pcb
d606 3
a608 2
#if defined(M68040)
	cmpl	#MMU_68040,_mmutype	| if 68040, (060 ha!), etc...
d617 1
a617 1
	fmovem	fpsr,sp@@-	| push fpsr!as code argument
d620 1
a620 26
	jra	Ltrapnstkadj	| call trap and deal with stack cleanup

/*
 * Coprocessor and format errors can generate mid-instruction stack
 * frames and cause signal delivery hence we need to check for potential
 * stack adjustment.
 */
_coperr:
	clrl	sp@@-
	moveml	#0xFFFF,sp@@-
	movl	usp,a0		| get and save
	movl	a0,sp@@(FR_SP)	|   the user stack pointer
	clrl	sp@@-		| no VA arg
	clrl	sp@@-		| or code arg
	movl	#T_COPERR,sp@@-	| push trap type
	jra	Ltrapnstkadj	| call trap and deal with stack adjustments

_fmterr:
	clrl	sp@@-
	moveml	#0xFFFF,sp@@-
	movl	usp,a0		| get and save
	movl	a0,sp@@(FR_SP)	|   the user stack pointer
	clrl	sp@@-		| no VA arg
	clrl	sp@@-		| or code arg
	movl	#T_FMTERR,sp@@-	| push trap type
	jra	Ltrapnstkadj	| call trap and deal with stack adjustments
a625 5
_illinst:
	clrl	sp@@-
	moveml	#0xFFFF,sp@@-
	moveq	#T_ILLINST,d0
	jra	fault
d627 6
a632 46
_zerodiv:
	clrl	sp@@-
	moveml	#0xFFFF,sp@@-
	moveq	#T_ZERODIV,d0
	jra	fault

_chkinst:
	clrl	sp@@-
	moveml	#0xFFFF,sp@@-
	moveq	#T_CHKINST,d0
	jra	fault

_trapvinst:
	clrl	sp@@-
	moveml	#0xFFFF,sp@@-
	moveq	#T_TRAPVINST,d0
	jra	fault

_privinst:
	clrl	sp@@-
	moveml	#0xFFFF,sp@@-
	moveq	#T_PRIVINST,d0
	jra	fault

	.globl	fault
fault:
	movl	usp,a0			| get and save
	movl	a0,sp@@(FR_SP)		|   the user stack pointer
	clrl	sp@@-			| no VA arg
	clrl	sp@@-			| or code arg
	movl	d0,sp@@-			| push trap type
	jbsr	_trap			| handle trap
	lea	sp@@(12),sp		| pop value args
	movl	sp@@(FR_SP),a0		| restore
	movl	a0,usp			|   user SP
	moveml	sp@@+,#0x7FFF		| restore most user regs
	addql	#8,sp			| pop SP and pad word
	jra	rei			| all done

	.globl	_straytrap
_badtrap:
	moveml	#0xC0C0,sp@@-		| save scratch regs
	movw	sp@@(22),sp@@-		| push exception vector info
	clrw	sp@@-			| and pad
	movl	sp@@(22),sp@@-		| and PC
	jbsr	_straytrap		| report
d634 2
a635 2
	moveml	sp@@+, #0x0303		| restore regs
	jra	rei
d637 1
a637 2
	.globl	_syscall
_trap0:
d643 1
a643 1
	jbsr	_syscall		| handle it
d645 1
a645 1
	tstl	_astpending
d647 1
a647 1
	tstb	_ssir
d650 1
a650 1
	tstb	_ssir
d660 1
a660 2
 * Our native 4.3 implementation uses trap 1 as sigreturn() and trap 2
 * as a breakpoint trap.
d662 2
a663 2
_trap1:
	jra	sigreturn
d665 5
a669 2
_trap2:
	jra	_trace
d672 1
a672 1
 * Trap 12 is the entry point for the cachectl "syscall" (both HPUX & BSD)
d676 1
a676 2
	.globl	_cachectl
_trap12:
d680 1
a680 1
	jbsr	_cachectl		| do it
d682 14
a695 1
	jra	rei			| all done
d699 2
a700 1
 *	- KGDB traps
d702 1
a702 1
 * We just pass it on and let trap() sort it all out
d704 2
a705 2
_trap15:
	clrl	sp@@-
a706 1
#ifdef KGDB
d709 9
a717 9
	andw	#PSL_S,d1		| from user mode?
	jeq	fault			| yes, just a regular fault
	movl	d0,sp@@-
	.globl	_kgdb_trap_glue
	jbsr	_kgdb_trap_glue		| returns if no debugger
	addl	#4,sp
#endif
	moveq	#T_TRAP15,d0
	jra	fault
d719 25
a743 7
/*
 * Hit a breakpoint (trap 1 or 2) instruction.
 * Push the code and treat as a normal fault.
 */
_trace:
	clrl	sp@@-
	moveml	#0xFFFF,sp@@-
d745 7
a751 7
	moveq	#T_TRACE,d0
	movw	sp@@(FR_HW),d1		| get SSW
	andw	#PSL_S,d1		| from user mode?
	jeq	fault			| yes, just a regular fault
	movl	d0,sp@@-
	jbsr	_kgdb_trap_glue		| returns if no debugger
	addl	#4,sp
d753 26
a778 2
	moveq	#T_TRACE,d0
	jra	fault
d780 2
a781 36
/*
 * The sigreturn() syscall comes here.  It requires special handling
 * because we must open a hole in the stack to fill in the (possibly much
 * larger) original stack frame.
 */
sigreturn:
	lea	sp@@(-84),sp		| leave enough space for largest frame
	movl	sp@@(84),sp@@		| move up current 8 byte frame
	movl	sp@@(88),sp@@(4)
	movl	#84,sp@@-		| default: adjust by 84 bytes
	moveml	#0xFFFF,sp@@-		| save user registers
	movl	usp,a0			| save the user SP
	movl	a0,sp@@(FR_SP)		|   in the savearea
	movl	#SYS_sigreturn,sp@@-	| push syscall number
	jbsr	_syscall		| handle it
	addql	#4,sp			| pop syscall#
	movl	sp@@(FR_SP),a0		| grab and restore
	movl	a0,usp			|   user SP
	lea	sp@@(FR_HW),a1		| pointer to HW frame
	movw	sp@@(FR_ADJ),d0		| do we need to adjust the stack?
	jeq	Lsigr1			| no, just continue
	moveq	#92,d1			| total size
	subw	d0,d1			|  - hole size = frame size
	lea	a1@@(92),a0		| destination
	addw	d1,a1			| source
	lsrw	#1,d1			| convert to word count
	subqw	#1,d1			| minus 1 for dbf
Lsigrlp:
	movw	a1@@-,a0@@-		| copy a word
	dbf	d1,Lsigrlp		| continue
	movl	a0,a1			| new HW frame base
Lsigr1:
	movl	a1,sp@@(FR_SP)		| new SP value
	moveml	sp@@+,#0x7FFF		| restore user registers
	movl	sp@@,sp			| and our SP
	jra	rei			| all done
d786 42
a827 42
 *	Level 0:	Spurious: ignored.
 *	Level 1:	HIL
 *	Level 2:
 *	Level 3:	Internal HP-IB
 *	Level 4:	"Fast" HP-IBs, SCSI
 *	Level 5:	DMA, Ethernet, Built-in RS232
 *	Level 6:	Clock
 *	Level 7:	Non-maskable: parity errors, RESET key
 *
 * ALICE: Here are our assignments:
 *
 *      Level 0:        Spurious: ignored
 *      Level 1:        VIA1 (clock, ADB)
 *      Level 2:        VIA2 (NuBus, SCSI)
 *      Level 3:
 *      Level 4:        Serial (SCC)
 *      Level 5:
 *      Level 6:
 *      Level 7:        Non-maskable: parity errors, RESET button, FOO key
 *
 * On the Q700, at least, in "A/UX mode," this should become:
 *
 *	Level 0:        Spurious: ignored
 *	Level 1:        Software
 *	Level 2:        VIA2 (except ethernet, sound)
 *	Level 3:        Ethernet
 *	Level 4:        Serial (SCC)
 *	Level 5:        Sound
 *	Level 6:        VIA1
 *	Level 7:        NMIs: parity errors, RESET button, YANCC error
 */
/* BARF We must re-configure this. */
	.globl	_hardclock, _nmihand
	.globl	_mrg_VBLQueue

_spurintr:
_lev3intr:
_lev5intr:
_lev6intr:
	addql	#1,_intrcnt+0
	addql	#1,_cnt+V_INTR
	jra	rei
d829 2
a830 2
_lev1intr:
	addql	#1,_intrcnt+4
d834 1
a834 1
	jbsr	_via1_intr
d838 6
a843 2
	addql	#1,_cnt+V_INTR
	jra	rei
d845 2
a846 3
	.globl	_real_via2_intr
_lev2intr:
	addql	#1,_intrcnt+8
d850 1
a850 1
	movl	_real_via2_intr,a2
d855 6
a860 4
	addql	#1,_cnt+V_INTR
	jra	rei

	.globl _zshard
d862 2
a863 3
_lev4intr:
	/* handle level 4 (SCC) interrupt special... */
	addql	#1,_intrcnt+12
d865 4
a868 5
	moveml	#0xFFFF,sp@@-	| save registers
	clrl	sp@@-		| push 0
	jsr	_zshard		| call C routine to deal with it (ser.c/zs.c)
	addl	#4,sp		| throw away arg
	moveml	sp@@+, #0xFFFF	| restore registers
d870 4
a873 87
	rte			| return from exception

/* 
 * We could tweak rtclock_intr and gain 12 cycles on the 020 and 030 by
 * saving the status register directly to the stack, but this would lose
 * badly on the 040.  Aligning the stack takes 10 more cycles than this
 * code does, so it's a good compromise.
 */
	.globl _rtclock_intr

_rtclock_intr:
	movl	d2,sp@@-			| save d2
	movw	sr,d2			| save SPL
	movw	#SPL2,sr		| raise SPL to splclock()
	movl	a6@@(8),a1		| get pointer to frame in via1_intr
	movl	a1@@(64),sp@@-		| push ps
	movl	a1@@(68),sp@@-		| push pc
	movl	sp,sp@@-			| push pointer to ps, pc
	jbsr	_hardclock		| call generic clock int routine
	lea	sp@@(12),sp		| pop params
	jbsr	_mrg_VBLQueue		| give programs in the VBLqueue a chance
	addql	#1,_intrcnt+20		| add another system clock interrupt
	addql	#1,_cnt+V_INTR		| chalk up another interrupt
	movw	d2,sr			| restore SPL
	movl	sp@@+,d2			| restore d2
	movl	#1,d0			| clock taken care of
	rts				| go back from whence we came

_lev7intr:
	addql	#1, _intrcnt+16
	clrl	sp@@-			| pad SR to longword
	moveml	#0xFFFF,sp@@-		| save registers
	movl	usp,a0			| and save
	movl	a0,sp@@(FR_SP)		|   the user stack pointer
	jbsr	_nmihand		| call handler
	movl	sp@@(FR_SP),a0		| restore
	movl	a0,usp			|   user SP
	moveml	sp@@+,#0x7FFF		| and remaining registers
	addql	#8,sp			| pop SSP and align word
	jra	rei			| all done

/*
 * Emulation of VAX REI instruction.
 *
 * This code deals with checking for and servicing ASTs
 * (profiling, scheduling) and software interrupts (network, softclock).
 * We check for ASTs first, just like the VAX.  To avoid excess overhead
 * the T_ASTFLT handling code will also check for software interrupts so we
 * do not have to do it here.  After identifying that we need an AST we
 * drop the IPL to allow device interrupts.
 *
 * This code is complicated by the fact that sendsig may have been called
 * necessitating a stack cleanup.
 */
	.comm	_ssir,1
	.globl	_astpending
	.globl	rei
rei:
#undef STACKCHECK
#ifdef STACKCHECK
	tstl	_panicstr		| have we paniced?
	jne	Ldorte1			| yes, do not make matters worse
#endif
	tstl	_astpending		| AST pending?
	jeq	Lchksir			| no, go check for SIR
Lrei1:
	btst	#5,sp@@			| yes, are we returning to user mode?
	jne	Lchksir			| no, go check for SIR
	movw	#PSL_LOWIPL,sr		| lower SPL
	clrl	sp@@-			| stack adjust
	moveml	#0xFFFF,sp@@-		| save all registers
	movl	usp,a1			| including
	movl	a1,sp@@(FR_SP)		|    the users SP
Lrei2:
	clrl	sp@@-			| VA == none
	clrl	sp@@-			| code == none
	movl	#T_ASTFLT,sp@@-		| type == async system trap
	jbsr	_trap			| go handle it
	lea	sp@@(12),sp		| pop value args
	movl	sp@@(FR_SP),a0		| restore user SP
	movl	a0,usp			|   from save area
	movw	sp@@(FR_ADJ),d0		| need to adjust stack?
	jne	Laststkadj		| yes, go to it
	moveml	sp@@+,#0x7FFF		| no, restore most user regs
	addql	#8,sp			| toss SP and stack adjust
#ifdef STACKCHECK
	jra	Ldorte
d875 1
a875 1
	rte				| and do real RTE
d877 14
a890 44
Laststkadj:
	lea	sp@@(FR_HW),a1		| pointer to HW frame
	addql	#8,a1			| source pointer
	movl	a1,a0			| source
	addw	d0,a0			|  + hole size = dest pointer
	movl	a1@@-,a0@@-		| copy
	movl	a1@@-,a0@@-		|  8 bytes
	movl	a0,sp@@(FR_SP)		| new SSP
	moveml	sp@@+,#0x7FFF		| restore user registers
	movl	sp@@,sp			| and our SP
#ifdef STACKCHECK
	jra	Ldorte
#else
	rte				| and do real RTE
#endif
Lchksir:
	tstb	_ssir			| SIR pending?
	jeq	Ldorte			| no, all done
	movl	d0,sp@@-			| need a scratch register
	movw	sp@@(4),d0		| get SR
	andw	#PSL_IPL7,d0		| mask all but IPL
	jne	Lnosir			| came from interrupt, no can do
	movl	sp@@+,d0			| restore scratch register
Lgotsir:
	movw	#SPL1,sr		| prevent others from servicing int
	tstb	_ssir			| too late?
	jeq	Ldorte			| yes, oh well...
	clrl	sp@@-			| stack adjust
	moveml	#0xFFFF,sp@@-		| save all registers
	movl	usp,a1			| including
	movl	a1,sp@@(FR_SP)		|    the users SP
Lsir1:
	clrl	sp@@-			| VA == none
	clrl	sp@@-			| code == none
	movl	#T_SSIR,sp@@-		| type == software interrupt
	jbsr	_trap			| go handle it
	lea	sp@@(12),sp		| pop value args
	movl	sp@@(FR_SP),a0		| restore
	movl	a0,usp			|   user SP
	moveml	sp@@+,#0x7FFF		| and all remaining registers
	addql	#8,sp			| pop SP and stack adjust
#ifdef STACKCHECK
	jra	Ldorte
#else
d892 2
a893 31
#endif
Lnosir:
	movl	sp@@+,d0			| restore scratch register
Ldorte:
#ifdef STACKCHECK
	movw	#SPL6,sr		| avoid trouble
	btst	#5,sp@@			| are we returning to user mode?
	jne	Ldorte1			| no, skip it
	movl	a6,tmpstk-20
	movl	d0,tmpstk-76
	moveq	#0,d0
	movb	sp@@(6),d0		| get format/vector
	lsrl	#3,d0			| convert to index
	lea	_exframesize,a6		|  into exframesize
	addl	d0,a6			|  to get pointer to correct entry
	movw	a6@@,d0			| get size for this frame
	addql	#8,d0			| adjust for unaccounted for bytes
	lea	_kstackatbase,a6	| desired stack base
	subl	d0,a6			|   - frame size == our stack
	cmpl	a6,sp			| are we where we think?
	jeq	Ldorte2			| yes, skip it
	lea	tmpstk,a6		| will be using tmpstk
	movl	sp@@(4),a6@@-		| copy common
	movl	sp@@,a6@@-		|   frame info
	clrl	a6@@-
	movl	sp,a6@@-			| save sp
	subql	#4,a6			| skip over already saved a6
	moveml	#0x7FFC,a6@@-		| push remaining regs (d0/a6/a7 done)
	lea	a6@@(-4),sp		| switch to tmpstk (skip saved d0)
	clrl	sp@@-			| is an underflow
	jbsr	_badkstack		| badkstack(0, frame)
d895 4
a898 7
	moveml	sp@@+,#0x7FFF		| restore most registers
	movl	sp@@,sp			| and SP
	rte
Ldorte2:
	movl	tmpstk-76,d0
	movl	tmpstk-20,a6
Ldorte1:
d900 1
a900 1
	rte				| real return
d902 12
a913 111
/*
 * Kernel access to the current processes kernel stack is via a fixed
 * virtual address.  It is at the same address as in the users VA space.
 */
		.data
| Scratch memory.  Careful when messing with these...
longscratch:	.long	0
longscratch2:	.long	0
pte_tmp:	.long	0  | for get_pte()
_macos_crp1:	.long	0
_macos_crp2:	.long	0
_macos_tc:	.long	0
_macos_tt0:	.long	0
_macos_tt1:	.long	0
_bletch:	.long	0
_esym:		.long	0
		.globl	_esym, _bletch
		.globl	_macos_crp1, _macos_crp2, _macos_tc
		.globl	_macos_tt0, _macos_tt1

/*
 * Initialization
 */
	.even

	.text
	.globl	_edata
	.globl	_etext
	.globl	start
	.globl	_getenvvars		| in machdep.c
	.globl	_setmachdep		| in machdep.c

start:
	movw	#PSL_HIGHIPL,sr		| no interrupts.  ever.
	lea	tmpstk,sp		| give ourselves a temporary stack
	movql	#0,d0			| disables caches
	movc	d0,cacr

	/* Initialize source/destination control registers for movs */
	movql	#FC_USERD,d0		| user space
	movc	d0,sfc			|   as source
	movc	d0,dfc			|   and destination of transfers

	/* Determine MMU/MPU from what we can test empirically */
	movl	#0x200,d0		| data freeze bit
	movc	d0,cacr			|   only exists on 68030
	movc	cacr,d0			| read it back
	tstl	d0			| zero?
	jeq	Lnot68030		| yes, we have 68020/68040

	movl	#CACHE_OFF,d0		| disable and clear both caches
	movc	d0,cacr
	lea	_mmutype,a0		| no, we have 68030
	movl	#MMU_68030,a0@@		| set to reflect 68030 PMMU
	lea	_cputype,a0
	movl	#CPU_68030,a0@@		| and 68030 MPU
	jra	Lstart1

Lnot68030:
	bset	#31,d0			| data cache enable bit
	movc	d0,cacr			|   only exists on 68040
	movc	cacr,d0			| read it back
	tstl	d0			| zero?
	beq	Lis68020		| yes, we have 68020

	movql	#CACHE40_OFF,d0		| now turn it back off
	movc	d0,cacr			|   before we access any data
	.word	0xf4f8			| cpusha bc ;push and invalidate caches
	lea	_mmutype,a0
	movl	#MMU_68040,a0@@		| Reflect 68040 MMU
	lea	_cputype,a0
	movl	#CPU_68040,a0@@		| and 68040 MPU
	jra	Lstart1

Lis68020:
	movl	#CACHE_OFF,d0		| disable and clear cache
	movc	d0,cacr
	lea	_mmutype,a0		| Must be 68020+68851
	movl	#MMU_68851,a0@@		| Reflect 68851 PMMU
	lea	_cputype,a0
	movl	#CPU_68020,a0@@		| and 68020 MPU
  
Lstart1:
	/*
	 * Some parameters provided by MacOS
	 *
	 * LAK: This section is the new way to pass information from the booter
	 * to the kernel.  At A1 there is an environment variable which has
	 * a bunch of stuff in ascii format, "VAR=value\0VAR=value\0\0".
	 */
	movl	a1,sp@@-			| Address of buffer
	movl	d4,sp@@-			| Some flags... (mostly not used)
	jbsr	_getenvvars		| Parse the environment buffer
	addql	#8, sp
	jbsr	_setmachdep		| Set some machine-dep stuff

	jbsr	_vm_set_page_size	| Set the vm system page size, now.
	jbsr	_consinit		| XXX Should only be if graybar on

/*
 * Figure out MacOS mappings and bootstrap BSD
 */
	lea	_macos_tc,a0		| get current TC
	cmpl	#MMU_68040, _mmutype	| check to see if 68040
	jeq	Lget040TC
	pmove	tc,a0@@
	jra	do_bootstrap

Lget040TC:
#ifdef __notyet__
	.long	0x4e7a0003		| movc tc,d0
d915 1
a915 2
	movql	#0,d0
	.long	0x4e7b0003		| movc d0,tc ;Disable MMU
d917 1
a917 72
	movl	d0,a0@@

do_bootstrap:
	movl	a0@@,sp@@-		| get MacOS mapping, relocate video,
	jbsr	_bootstrap_mac68k	|   bootstrap pmap, et al.
	addql	#4,sp
	
/*
 * Prepare to enable MMU.
 */
	movl	_Sysseg,a1		| system segment table addr
	addl	_load_addr,a1		| Make it physical addr

	cmpl	#MMU_68040,_mmutype
	jne	Lenablepre040MMU	| if not 040, skip

	movql	#0,d0
	.long	0x4e7b0003		| movc d0,tc   ;Disable MMU
	.long	0x4e7b0004		| movc d0,itt0 ;Disable itt0
	.long	0x4e7b0005		| movc d0,itt1 ;Disable itt1
	.long	0x4e7b0006		| movc d0,dtt0 ;Disable dtt0
	.long	0x4e7b0007		| movc d0,dtt1 ;Disable dtt1
	movl	a1,d1
	.word	0xf518			| pflusha
	.long	0x4e7b1807		| movc d1,srp
	movl	#0x8000,d0
	.long	0x4e7b0003		| movc d0,tc   ;Enable MMU
	movl	#CACHE40_ON,d0
	movc	d0,cacr			| turn on both caches
	jra	Lloaddone

Lenablepre040MMU:
	tstl	_mmutype		| TTx instructions will break 68851
	jgt	LnokillTT

	lea	longscratch,a0		| disable TTx registers on 68030
	movl	#0,a0@@
	.long	0xf0100800		| movl a0@@,tt0
	.long	0xf0100c00		| movl a0@@,tt1

LnokillTT:
	lea	_protorp,a0
	movl	#0x80000202,a0@@		| nolimit + share global + 4 byte PTEs
	movl	a1,a0@@(4)		| + segtable address
	pmove	a0@@,srp			| load the supervisor root pointer
	movl	#0x80000002,a0@@		| reinit upper half for CRP loads
	lea	longscratch,a2
	movl	#0x82c0aa00,a2@@		| value to load TC with
	pmove	a2@@,tc			| load it

Lloaddone:

/*
 * Should be running mapped from this point on
 */

/* init mem sizes */

/* set kernel stack, user SP, proc0, and initial pcb */
	movl	_proc0paddr,a1		| get proc0 pcb addr
	lea	a1@@(USPACE-4),sp	| set kernel stack to end of area
	lea	_proc0,a2		| initialize proc0.p_addr so that
	movl	a1,a2@@(P_ADDR)		|   we don't deref NULL in trap()
	movl	#USRSTACK-4,a2
	movl	a2,usp			| init user SP
	movl	a1,_curpcb		| proc0 is running
	jbsr	_TBIA			| invalidate TLB
	cmpl	#MMU_68040,_mmutype	| 68040?
	jeq	Lnocache0		| yes, cache already on
	movl	#CACHE_ON,d0
	movc	d0,cacr			| clear cache(s)
/* XXX Enable external cache here. */
d919 16
a934 4
Lnocache0:
/* final setup for C code */
	jbsr	_setmachdep		| Set some machine-dep stuff
	movw	#PSL_LOWIPL,sr		| lower SPL ; enable interrupts
d936 12
a947 12
/*
 * Create a fake exception frame so that cpu_fork() can copy it.
 * main() never returns; we exit to user mode from a forked process
 * later on.
 */
	clrw	sp@@-			| vector offset/frame type
	clrl	sp@@-			| PC - filled in by "execve"
	movw	#PSL_USER,sp@@-		| in user mode
	clrl	sp@@-			| stack adjust count and padding
	lea	sp@@(-64),sp		| construct space for D0-D7/A0-A7
	lea	_proc0,a0		| save pointer to frame
	movl	sp,a0@@(P_MD_REGS)	|   in proc0.p_md.md_regs
d949 5
a953 12
	jra	_main

	pea     Lmainreturned           | Yow!  Main returned!
	jbsr    _panic
	/* NOTREACHED */
Lmainreturned:
	.asciz  "main() returned"
	.even

/*
 * proc_trampoline
 *	Call function in register a2 with a3 as an arg and then rei.
d955 21
a975 11
	.globl	_proc_trampoline
_proc_trampoline:
	movl	a3,sp@@-			| push function arg (curproc)
	jbsr	a2@@			| call function
	addql	#4,sp			| pop arg
	movl	sp@@(FR_SP),a0		| usp to a0
	movl	a0,usp			| setup user's stack pointer
	movml	sp@@+,#0x7fff		| restore all but sp
	addql	#8,sp			| pop sp and stack adjust
	jra	rei			| all done

d978 11
a988 2
 * Icode is copied out to process 1 to exec init.
 * If the exec fails, process 1 exits.
a989 19
	.globl	_icode,_szicode
	.text
_icode: 
	clrl	sp@@-
	pea	pc@@((argv-.)-2)
	pea	pc@@((init-.)-2)
	clrl	sp@@-
	moveq	#SYS_execve,d0
	trap	#0
	moveq	#SYS_exit,d0
	trap	#0
init:
	.asciz	"/sbin/init"
	.even
argv:   
	.long	init+6-_icode		| argv[0] = "init" ("/sbin/init" + 6)
	.long	eicode-_icode		| argv[1] follows icode after copyout
	.long	0
eicode:
d991 1
a991 2
_szicode:
	.long	_szicode-_icode
d993 66
d1061 1
a1061 12
 * Signal "trampoline" code (18 bytes).  Invoked from RTE setup by sendsig().
 * 
 * Stack looks like:
 *
 *	sp+0 ->	signal number
 *	sp+4	pointer to siginfo (sip)
 *	sp+8	pointer to signal context frame (scp)
 *	sp+12	address of handler
 *	sp+16	saved hardware state
 *			.
 *			.
 *	scp+0->	beginning of signal context frame
d1063 1
a1063 14
	.globl	_sigcode, _esigcode
	.data
	.align	2
_sigcode:
	movl	sp@@(12),a0		| signal handler addr	(4 bytes)
	jsr	a0@@			| call signal handler	(2 bytes)
	addql	#4,sp			| pop signo		(2 bytes)
	trap	#1			| special syscall entry	(2 bytes)
	movl	d0,sp@@(4)		| save errno		(4 bytes)
	moveq	#1,d0			| syscall == exit	(2 bytes)
	trap	#0			| exit(errno)		(2 bytes)
	.align	2
_esigcode:
	.text
a1068 2
#include <m68k/asm.h>

d1075 1
a1075 6
 * The following primitives manipulate the run queues.
 * _whichqs tells which of the 32 queues _qs have processes in them.
 * Setrunqueue puts processes into queues, remrunqueue removes them from
 * queues.  The running process is on no queue, other processes are on a queue
 * related to p->p_priority, divided by 4 actually to shrink the 0-127
 * range of priorities into the 32 available queues.
d1077 1
d1079 3
a1081 2
	.globl	_whichqs,_qs,_cnt,_panic
	.globl	_curproc,_want_resched
d1083 3
a1085 77
/*
 * setrunqueue(p)
 *
 * Call should be made at spl6(), and p->p_stat should be SRUN
 */
ENTRY(setrunqueue)
	movl	sp@@(4),a0
#ifdef DIAGNOSTIC
	tstl	a0@@(P_BACK)
	jne	Lset1
	tstl	a0@@(P_WCHAN)
	jne	Lset1
	cmpb	#SRUN,a0@@(P_STAT)
	jne	Lset1
#endif
	clrl	d0
	movb	a0@@(P_PRIORITY),d0
	lsrb	#2,d0
	movl	_whichqs,d1
	bset	d0,d1
	movl	d1,_whichqs
	lslb	#3,d0
	addl	#_qs,d0
	movl	d0,a0@@(P_FORW)
	movl	d0,a1
	movl	a1@@(P_BACK),a0@@(P_BACK)
	movl	a0,a1@@(P_BACK)
	movl	a0@@(P_BACK),a1
	movl	a0,a1@@(P_FORW)
	rts
#ifdef DIAGNOSTIC
Lset1:
	movl	#Lset2,sp@@-
	jbsr	_panic
Lset2:
	.asciz	"setrunqueue"
	.even
#endif

/*
 * Remrq(proc *p)
 *
 * Call should be made at spl6().
 */
ENTRY(remrunqueue)
	movl	sp@@(4),a0		| proc *p
	movb	a0@@(P_PRIORITY),d0	| d0 = processes priority
#ifdef DIAGNOSTIC
	lsrb	#2,d0			| d0 /= 4
	movl	_whichqs,d1		| d1 = whichqs
	bclr	d0,d1			| clear bit in whichqs corresponding to
					|  processes priority
	jeq	Lrem2			| if (d1 & (1 << d0)) == 0
#endif
	movl	a0@@(P_BACK),a1
	clrl	a0@@(P_BACK)
	movl	a0@@(P_FORW),a0
	movl	a0,a1@@(P_FORW)
	movl	a1,a0@@(P_BACK)
	cmpal	a0,a1
	jne	Lrem1
#ifndef DIAGNOSTIC
	lsrb	#2,d0
	movl	_whichqs,d1
#endif
	bclr	d0,d1
	movl	d1,_whichqs
Lrem1:
	rts
#ifdef DIAGNOSTIC
Lrem2:
	movl	#Lrem3,sp@@-
	jbsr	_panic
Lrem3:
	.asciz	"remrunqueue"
	.even
#endif
d1087 1
a1087 15
Lsw0:
	.asciz	"cpu_switch"
	.even

	.globl	_curpcb
	.globl	_masterpaddr	| XXX compatibility (debuggers)
	.data
_masterpaddr:			| XXX compatibility (debuggers)
_curpcb:
	.long	0
pcbflag:
	.byte	0		| copy of pcb_flags low byte
	.align	2
	.comm	nullpcb,SIZEOF_PCB
	.text
d1090 3
a1092 3
 * switch_exit()
 * 	At the exit of a process, do a switch for the last time.
 * Switch to a safe stack and PCB, then deallocate the process's resources
d1096 3
a1098 2
	movl	#nullpcb,_curpcb	| save state into garbage pcb
	lea	tmpstk,sp		| goto a tmp stack
d1100 4
a1103 4
        /* Schedule the vmspace and stack to be freed. */
	movl    a0,sp@@-                 | exit2(p)
	jbsr    _C_LABEL(exit2)
	lea     sp@@(4),sp               | pop args
d1105 1
a1105 1
	jra	_cpu_switch
d1108 1
a1108 1
 * When no processes are on the runq, Swtch branches to idle
d1111 1
a1111 2
	.globl	Idle
Idle:
d1114 2
a1115 2
	movl	_whichqs,d0
	jeq	Idle
d1119 1
a1119 2
	movl	#Lsw0,sp@@-
	jbsr	_panic
d1134 1
a1134 1
	movl	_curpcb,a0		| current pcb
d1137 3
a1139 3
	movl	_curproc,sp@@-		| remember last proc running
#endif /* notyet */
	clrl	_curproc
d1146 2
a1147 2
	movl	_whichqs,d0
	jeq	Idle
d1157 1
a1157 1
	addl	#_qs,d1			| locate queue (q)
d1167 3
a1169 3
	movl	_whichqs,d1
	bclr	d0,d1			| no, reset bit
	movl	d1,_whichqs
d1171 2
a1172 2
	movl	a0,_curproc
	clrl	_want_resched
d1177 1
a1177 1
#endif /* notyet */
d1181 1
a1181 1
	movl	_curpcb,a1
d1186 2
a1187 2
	tstl	_fputype		| Do we have an fpu?
	jeq	Lswnofpsave		| No?  Then don't attempt save.
d1201 1
a1201 1
#endif /* DIAGNOSTIC */
d1203 1
a1203 1
	movb	a0@@(P_MD_FLAGS+3),pcbflag | low byte of p_md.md_flags
d1205 11
a1215 1
	movl	a1,_curpcb
d1217 1
a1217 15
	/* see if pmap_activate needs to be called; should remove this */
	movl	a0@@(P_VMSPACE),a0	| vmspace = p->p_vmspace
#ifdef DIAGNOSTIC
	tstl	a0			| map == VM_MAP_NULL?
	jeq	Lbadsw			| panic
#endif /* DIAGNOSTIC */
	movl	a0@@(VM_PMAP),a0		| pmap = vmspace->vm_map.pmap
	tstl	a0@@(PM_STCHG)		| pmap->st_changed?
	jeq	Lswnochg		| no, skip
	pea	a1@@			| push pcb (at p_addr)
	pea	a0@@			| push pmap
	jbsr	_pmap_activate		| pmap_activate(pmap, pcb)
	addql	#8,sp
	movl	_curpcb,a1		| restore p_addr
Lswnochg:
a1218 22
	lea	tmpstk,sp		| now goto a tmp stack for NMI
#if defined(M68040)
	cmpl	#MMU_68040,_mmutype	| 68040?
	jne	Lres1a			| no, skip
	.word	0xf518			| yes, pflusha
	movl	a1@@(PCB_USTP),d0	| get USTP
	moveq	#PGSHIFT,d1
	lsll	d1,d0			| convert to addr
	.long	0x4e7b0806		| movc d0,urp
	jra	Lcxswdone
Lres1a:
#endif
	movl	#CACHE_CLR,d0
	movc	d0,cacr			| invalidate cache(s)
	pflusha				| flush entire TLB
	movl	a1@@(PCB_USTP),d0	| get USTP
	moveq	#PGSHIFT,d1
	lsll	d1,d0			| convert to addr
	lea	_protorp,a0		| CRP prototype
	movl	d0,a0@@(4)		| stash USTP
	pmove	a0@@,crp			| load new user root pointer
Lcxswdone:
d1223 1
a1223 1
	tstl	_fputype		| If we don't have an fpu,
d1229 1
a1229 1
	cmpl	#MMU_68040,_mmutype	| 68040?
d1247 1
a1247 1
 *	Update pcb, saving current processor state.
d1256 2
a1257 2
	tstl	_fputype		| Do we have FPU?
	jeq	Lsavedone		| No?  Then don't save state.
d1261 1
a1261 1
	jeq	Lsavedone		| yes, all done
d1264 1
a1264 1
Lsavedone:
d1271 1
a1271 1
	movl	_curpcb,a1		| current pcb
d1291 1
a1291 1
	movl	_curpcb,a1		| current pcb
d1302 1
a1302 1
	cmpl	#MMU_68040,_mmutype	| 68040?
d1310 1
a1310 1
	tstl	_mmutype
d1323 2
a1324 2
	tstl	fulltflush		| being conservative?
	jne	__TBIA			| yes, flush entire TLB
d1328 1
a1328 1
	cmpl	#MMU_68040,_mmutype	| 68040?
d1342 1
a1342 1
	tstl	_mmutype
d1358 2
a1359 2
	tstl	fulltflush		| being conservative?
	jne	__TBIA			| yes, flush everything
d1362 1
a1362 1
	cmpl	#MMU_68040,_mmutype	| 68040?
d1369 1
a1369 1
	tstl	_mmutype
d1385 2
a1386 2
	tstl	fulltflush		| being conservative?
	jne	__TBIA			| yes, flush everything
d1389 1
a1389 1
	cmpl	#MMU_68040,_mmutype	| 68040?
d1395 1
a1395 1
	tstl	_mmutype
d1412 1
a1412 1
	cmpl	#MMU_68040,_mmutype	| 68040?
d1432 1
a1432 1
	cmpl	#MMU_68040,_mmutype	| 68040?
d1442 1
a1442 1
	cmpl	#MMU_68040,_mmutype	| 68040?
d1452 1
a1452 1
	cmpl	#MMU_68040,_mmutype	| 68040?
d1492 1
a1492 1
	cmpl	#MMU_68040,_mmutype	| 68040?
d1508 2
a1509 10
/*
 * Get callers current SP value.
 * Note that simply taking the address of a local variable in a C function
 * doesn't work because callee saved registers may be outside the stack frame
 * defined by A6 (e.g. GCC generated code).
 */
	.globl	_getsp
_getsp:
	movl	sp,d0			| get current SP
	addql	#4,d0			| compensate for return address
d1512 1
a1512 5
	.globl	_getsfc, _getdfc
_getsfc:
	movc	sfc,d0
	rts
_getdfc:
a1516 16
 * Check out a virtual address to see if it's okay to write to.
 *
 * probeva(va, fc)
 *
 */
ENTRY(probeva)
	movl	sp@@(8),d0
	movec	d0,dfc
	movl	sp@@(4),a0
	.word	0xf548		| ptestw (a0)
	moveq	#FC_USERD,d0		| restore DFC to user space
	movc	d0,dfc
	.long	0x4e7a0805	| movec  MMUSR,d0
	rts

/*
d1524 1
a1524 1
	cmpl	#MMU_68040,_mmutype	| 68040?
d1526 1
d1531 2
a1532 2
	pflusha
	lea	_protorp,a0		| CRP prototype
d1535 3
a1537 3
	movl	#DC_CLEAR,d0
	movc	d0,cacr			| invalidate on-chip d-cache
	rts				|   since pmove flushes TLB
d1550 1
a1550 1
	tstb	_ssir			| software interrupt pending?
d1587 5
a1591 2
 * Basically we just jump to the appropriate ROM routine after mapping
 * the ROM into its proper home (back in machdep).
d1593 5
a1597 13
	.globl	_doboot, _ROMBase
_doboot:
	movw	#PSL_HIGHIPL,sr		| no interrupts

	cmpl	#MMU_68040,_mmutype
	jne	Ldobootnot040		| It's not an '040

	movl	#CACHE40_OFF,d0		| 68040 cache disable
	movc	d0, cacr
	.word	0xf4f8			| cpusha bc - push and invalidate caches
	jra	Ldoboot1

Ldobootnot040:
d1600 32
d1634 3
a1636 5
	movl	_MacOSROMBase, _ROMBase	| Load MacOS ROMBase

	movl	#0x90,a1		| offset of ROM reset routine
	addl	_ROMBase,a1		| add to ROM base
	jra	a1@@			| and jump to ROM to reset machine
d1646 1
a1646 2
	.globl	_ptest040
_ptest040:
d1693 1
a1693 2
	.globl	_get_pte
_get_pte:
d1696 1
a1696 1
	lea	longscratch,a0
d1713 1
a1713 1
	movl	d0,pte_tmp	| save for later
d1749 1
a1749 1
	lea	longscratch,a0	| space for two longs
d1790 1
a1790 1
	movl	d0,_macos_tt0	| XXX for later analysis (kill this line)
d1802 1
a1802 1
	movl	pte_tmp,a1	| get address of our original pte
d1821 1
a1821 1
	lea	longscratch,a0	| disable tt
d1829 1
a1829 1
	jbsr	_printstar
d1832 2
a1833 2
	jbsr	_printstar
	jbsr	_printstar
d1836 3
a1838 3
	jbsr	_printstar
	jbsr	_printstar
	jbsr	_printstar
d1841 4
a1844 4
	jbsr	_printstar
	jbsr	_printstar
	jbsr	_printstar
	jbsr	_printstar
d1847 5
a1851 5
	jbsr	_printstar
	jbsr	_printstar
	jbsr	_printstar
	jbsr	_printstar
	jbsr	_printstar
d1854 6
a1859 6
	jbsr	_printstar
	jbsr	_printstar
	jbsr	_printstar
	jbsr	_printstar
	jbsr	_printstar
	jbsr	_printstar
d1862 7
a1868 7
	jbsr	_printstar
	jbsr	_printstar
	jbsr	_printstar
	jbsr	_printstar
	jbsr	_printstar
	jbsr	_printstar
	jbsr	_printstar
d1871 8
a1878 8
	jbsr	_printstar
	jbsr	_printstar
	jbsr	_printstar
	jbsr	_printstar
	jbsr	_printstar
	jbsr	_printstar
	jbsr	_printstar
	jbsr	_printstar
d1881 9
a1889 9
	jbsr	_printstar
	jbsr	_printstar
	jbsr	_printstar
	jbsr	_printstar
	jbsr	_printstar
	jbsr	_printstar
	jbsr	_printstar
	jbsr	_printstar
	jbsr	_printstar
d1892 10
a1901 10
	jbsr	_printstar
	jbsr	_printstar
	jbsr	_printstar
	jbsr	_printstar
	jbsr	_printstar
	jbsr	_printstar
	jbsr	_printstar
	jbsr	_printstar
	jbsr	_printstar
	jbsr	_printstar
d1904 3
d1908 1
a1908 2
	.globl	_sanity_check
_sanity_check:
d1912 3
a1914 3
tmpstk:
	.globl	_machineid
_machineid:
d1916 16
a1931 6
	.globl	_mmutype,_cputype,_protorp
_mmutype:
	.long	MMU_68851	| Default to 68851 PMMU
_cputype:
	.long	CPU_68020	| Default to 68020
_protorp:
d1933 2
a1934 2
	.globl	_cold
_cold:
d1936 5
a1940 2
	.globl	_proc0paddr
_proc0paddr:
d1942 2
a1943 2
	.globl	_intiolimit
_intiolimit:
d1945 2
a1946 2
	.globl	_load_addr
_load_addr:
d1948 2
a1949 1
lastpage:
d1951 8
d1960 1
a1960 2
	.globl	fulltflush, fullcflush
fulltflush:
d1962 2
a1963 4
fullcflush:
	.long	0
	.globl	timebomb
timebomb:
d1966 1
d1968 2
a1969 2
	.globl	_intrcnt,_intrnames,_eintrcnt,_eintrnames
_intrnames:
d1976 4
a1979 1
_eintrnames:
d1981 4
a1984 14
_intrcnt:
	.long	0,0,0,0,0,0
_eintrcnt:			| Unused, but needed for vmstat
	.long	0
	.globl	_MacOSROMBase
_MacOSROMBase:
	.long	0x40800000
	.globl	_mac68k_vrsrc_cnt, _mac68k_vrsrc_vec
_mac68k_vrsrc_cnt:
	.long	0
_mac68k_vrsrc_vec:
	.word	0, 0, 0, 0, 0, 0
_mac68k_buserr_addr:
	.long	0
@


1.23
log
@Changes to exit handling.

cpu_exit no longer frees the vmspace and u-area. This is now handled by a
separate kernel thread "reaper". This is to avoid sleeping locks in the
critical path of cpu_exit where we're not allowed to sleep.

From NetBSD
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.22 1999/01/20 13:31:16 niklas Exp $	*/
d1350 1
a1350 1
	lea	a0@@(VM_PMAP),a0		| pmap = &vmspace.vm_pmap
@


1.22
log
@setregs does not reset stack anymore
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.21 1997/03/28 12:38:58 briggs Exp $	*/
d1235 4
a1238 6
	/* Free old process's user area. */
	movl	#USPACE,sp@@-		| size of u-area
	movl	a0@@(P_ADDR),sp@@-	| address of process's u-area
	movl	_kernel_map,sp@@-	| map it was allocated in
	jbsr	_kmem_free		| deallocate it
	lea	sp@@(12),sp		| pop args
@


1.22.6.1
log
@Update the SMP branch to -current, this breaks the SMP branch though.
But it will be fixed soonish.  Note, nothing new has happened, this is just
a merge of the trunk into this branch.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.24 2001/04/06 09:34:15 art Exp $	*/
d1235 6
a1240 4
        /* Schedule the vmspace and stack to be freed. */
	movl    a0,sp@@-                 | exit2(p)
	jbsr    _C_LABEL(exit2)
	lea     sp@@(4),sp               | pop args
d1352 1
a1352 1
	movl	a0@@(VM_PMAP),a0		| pmap = vmspace->vm_map.pmap
@


1.22.6.2
log
@Merge in -current from two days ago in the SMP branch.
As usual with merges, they do not indicate progress, so do not hold
your breath for working SMP, and do not mail me and ask about the
state of it.  It has not changed.  There is work ongoing, but very, very
slowly.  The commit is done in parts as to not lock up the tree in too
big chunks at a time.
@
text
@d1 2
a2 2
/*	$OpenBSD$	*/
/*	$NetBSD: locore.s,v 1.103 1998/07/09 06:02:50 scottr Exp $	*/
a80 4
#include "assym.h"
#include <machine/asm.h>
#include <machine/trap.h>

d82 1
a82 1
 * This is for kvm_mkdb, and should be the address of the beginning
d86 2
a87 1
GLOBAL(kernel_text)
d89 3
a91 234
#include <mac68k/mac68k/vectors.s>
#include <mac68k/mac68k/macglobals.s>

/*
 * Initialization
 */

	.data
| Scratch memory.  Careful when messing with these...
ASLOCAL(longscratch)
	.long	0
ASLOCAL(longscratch2)
	.long	0
ASLOCAL(pte_tmp)			| for get_pte()
	.long	0 
GLOBAL(macos_crp1)
	.long	0
GLOBAL(macos_crp2)
	.long	0
GLOBAL(macos_tc)
	.long	0
GLOBAL(macos_tt0)
	.long	0
GLOBAL(macos_tt1)
	.long	0
GLOBAL(bletch)
	.long	0

BSS(esym,4)

ASENTRY_NOPROFILE(start)
	movw	#PSL_HIGHIPL,sr		| no interrupts.  ever.
	lea	_ASM_LABEL(tmpstk),sp	| give ourselves a temporary stack

	movl	#CACHE_OFF,d0
	movc	d0,cacr			| clear and disable on-chip cache(s)

	/* Initialize source/destination control registers for movs */
	movql	#FC_USERD,d0		| user space
	movc	d0,sfc			|   as source
	movc	d0,dfc			|   and destination of transfers

	/*
	 * Some parameters provided by MacOS
	 *
	 * LAK: This section is the new way to pass information from the booter
	 * to the kernel.  At A1 there is an environment variable which has
	 * a bunch of stuff in ascii format, "VAR=value\0VAR=value\0\0".
	 */
	movl	a1,sp@@-			| Address of buffer
	movl	d4,sp@@-			| Some flags... (mostly not used)
	jbsr	_C_LABEL(getenvvars)	| Parse the environment buffer
	addql	#8,sp

	/* Determine MMU/MPU from what we can test empirically */
	movl	#0x200,d0		| data freeze bit
	movc	d0,cacr			|   only exists on 68030
	movc	cacr,d0			| read it back
	tstl	d0			| zero?
	jeq	Lnot68030		| yes, we have 68020/68040

	movl	#CACHE_OFF,d0		| disable and clear both caches
	movc	d0,cacr
	lea	_C_LABEL(mmutype),a0	| no, we have 68030
	movl	#MMU_68030,a0@@		| set to reflect 68030 PMMU
	lea	_C_LABEL(cputype),a0
	movl	#CPU_68030,a0@@		| and 68030 MPU
	jra	Lstart1

Lnot68030:
	bset	#31,d0			| data cache enable bit
	movc	d0,cacr			|   only exists on 68040
	movc	cacr,d0			| read it back
	tstl	d0			| zero?
	beq	Lis68020		| yes, we have 68020

	movql	#CACHE40_OFF,d0		| now turn it back off
	movc	d0,cacr			|   before we access any data
	.word	0xf4f8			| cpusha bc ;push and invalidate caches
	lea	_C_LABEL(mmutype),a0
	movl	#MMU_68040,a0@@		| Reflect 68040 MMU
	lea	_C_LABEL(cputype),a0
	movl	#CPU_68040,a0@@		| and 68040 MPU
	jra	Lstart1

Lis68020:
	movl	#CACHE_OFF,d0		| disable and clear cache
	movc	d0,cacr
	lea	_C_LABEL(mmutype),a0	| Must be 68020+68851
	movl	#MMU_68851,a0@@		| Reflect 68851 PMMU
	lea	_C_LABEL(cputype),a0
	movl	#CPU_68020,a0@@		| and 68020 MPU

Lstart1:
	/*
	 * Now that we know what CPU we have, initialize the address error
	 * and bus error handlers in the vector table:
	 *
	 *	vectab+8	bus error
	 *	vectab+12	address error
	 */
	lea	_C_LABEL(cputype),a0
	lea	_C_LABEL(vectab),a2
#if defined(M68040)
	cmpl	#CPU_68040,a0@@		| 68040?
	jne	1f			| no, skip
	movl	#_C_LABEL(buserr40),a2@@(8)
	movl	#_C_LABEL(addrerr4060),a2@@(12)
	jra	Lstart2
1:
#endif
#if defined(M68020) || defined(M68030)
	cmpl	#CPU_68040,a0@@		| 68040?
	jeq	1f			| yes, skip
	movl	#_C_LABEL(busaddrerr2030),a2@@(8)
	movl	#_C_LABEL(busaddrerr2030),a2@@(12)
	jra	Lstart2
1:
#endif
	/* Config botch; no hope. */
	movl	_C_LABEL(MacOSROMBase),a1 | Load MacOS ROMBase
	jra	Ldoboot1

Lstart2:
	jbsr	_C_LABEL(setmachdep)	| Set some machine-dep stuff
	jbsr	_C_LABEL(consinit)	| XXX Should only be if graybar on

/*
 * Figure out MacOS mappings and bootstrap NetBSD
 */
	lea	_C_LABEL(macos_tc),a0	| get current TC
	cmpl	#MMU_68040,_C_LABEL(mmutype) | check to see if 68040
	jeq	Lget040TC

	pmove	tc,a0@@
	jra	Lstart3

Lget040TC:
	movl	_C_LABEL(current_mac_model),a1	 | if an AV Mac, save current
	cmpl	#MACH_CLASSAV,a1@@(CPUINFO_CLASS) | TC so internal video will
	jne	LnotAV				 | get configured
	.long	0x4e7a0003		| movc tc,d0
	jra	LsaveTC
LnotAV:
	movql	#0,d0			| otherwise,
	.long	0x4e7b0003		| movc d0,tc ;Disable MMU
LsaveTC:
	movl	d0,a0@@

Lstart3:
	movl	a0@@,sp@@-		| get Mac OS mapping, relocate video,
	jbsr	_C_LABEL(bootstrap_mac68k) |   bootstrap pmap, et al.
	addql	#4,sp

	/*
	 * Set up the vector table, and race to get the MMU
	 * enabled.
	 */
	movl	#_C_LABEL(vectab),d0	| set Vector Base Register
	movc	d0,vbr

	movl	_C_LABEL(Sysseg),a1	| system segment table addr
	addl	_C_LABEL(load_addr),a1	| Make it physical addr
	cmpl	#MMU_68040,_C_LABEL(mmutype)
	jne	Lenablepre040MMU	| if not 040, skip

	movql	#0,d0
	.long	0x4e7b0003		| movc d0,tc   ;Disable MMU
	.long	0x4e7b0004		| movc d0,itt0 ;Disable itt0
	.long	0x4e7b0005		| movc d0,itt1 ;Disable itt1
	.long	0x4e7b0006		| movc d0,dtt0 ;Disable dtt0
	.long	0x4e7b0007		| movc d0,dtt1 ;Disable dtt1
	movl	a1,d1
	.word	0xf518			| pflusha
	.long	0x4e7b1807		| movc d1,srp
	movl	#0x8000,d0
	.long	0x4e7b0003		| movc d0,tc   ;Enable MMU
	movl	#CACHE40_ON,d0
	movc	d0,cacr			| turn on both caches
	jra	Lloaddone

Lenablepre040MMU:
	tstl	_C_LABEL(mmutype)	| TTx instructions will break 68851
	jgt	LnokillTT

	lea	_ASM_LABEL(longscratch),a0 | disable TTx registers on 68030
	movl	#0,a0@@
	.long	0xf0100800		| movl a0@@,tt0
	.long	0xf0100c00		| movl a0@@,tt1

LnokillTT:
	lea	_C_LABEL(protorp),a0
	movl	#0x80000202,a0@@		| nolimit + share global + 4 byte PTEs
	movl	a1,a0@@(4)		| + segtable address
	pmove	a0@@,srp			| load the supervisor root pointer
	movl	#0x80000002,a0@@		| reinit upper half for CRP loads
	lea	_ASM_LABEL(longscratch),a2
	movl	#0x82c0aa00,a2@@		| value to load TC with
	pmove	a2@@,tc			| load it

Lloaddone:

/*
 * Should be running mapped from this point on
 */
/* select the software page size now */
	lea	_ASM_LABEL(tmpstk),sp	| temporary stack
	jbsr	_C_LABEL(uvm_setpagesize)  | select software page size

/* set kernel stack, user SP, proc0, and initial pcb */
	movl	_C_LABEL(proc0paddr),a1	| get proc0 pcb addr
	lea	a1@@(USPACE-4),sp	| set kernel stack to end of area
	lea	_C_LABEL(proc0),a2	| initialize proc0.p_addr so that
	movl	a1,a2@@(P_ADDR)		|   we don't deref NULL in trap()
	movl	#USRSTACK-4,a2
	movl	a2,usp			| init user SP
	movl	a1,_C_LABEL(curpcb)	| proc0 is running

/* flush TLB and turn on caches */
	jbsr	_C_LABEL(TBIA)		| invalidate TLB
	cmpl	#MMU_68040,_C_LABEL(mmutype) | 68040?
	jeq	Lnocache0		| yes, cache already on
	movl	#CACHE_ON,d0
	movc	d0,cacr			| clear cache(s)
#ifdef __notyet__
	tstl	_C_LABEL(ectype)
	jeq	Lnocache0
					| Enable external cache here
#endif

Lnocache0:
/* Final setup for call to main(). */
	jbsr	_C_LABEL(mac68k_init)
	movw	#PSL_LOWIPL,sr		| lower SPL ; enable interrupts
d94 14
a107 14
 * Create a fake exception frame so that cpu_fork() can copy it.
 * main() nevers returns; we exit to user mode from a forked process
 * later on.
 */
	clrw	sp@@-			| vector offset/frame type
	clrl	sp@@-			| PC - filled in by "execve"
	movw	#PSL_USER,sp@@-		| in user mode
	clrl	sp@@-			| stack adjust count and padding
	lea	sp@@(-64),sp		| construct space for D0-D7/A0-A7
	lea	_C_LABEL(proc0),a0	| save pointer to frame
	movl	sp,a0@@(P_MD_REGS)	|   in proc0.p_md.md_regs

	jra	_C_LABEL(main)		| main()
	PANIC("main() returned")
d109 3
a112 17
/*
 * proc_trampoline
 *	Call function in register a2 with a3 as an arg and then rei.  Note
 * that we restore the stack before calling, thus giving "a2" more stack.
 * (for the case that, e.g., if curproc had a deeply nested call chain...)
 * cpu_fork() also depends on struct frame being a second arg to the
 * function in a2.
 */
GLOBAL(proc_trampoline)
	movl	a3,sp@@-			| push function arg (curproc)
	jbsr	a2@@			| call function
	addql	#4,sp			| pop arg
	movl	sp@@(FR_SP),a0		| usp to a0
	movl	a0,usp			| setup user's stack pointer
	movml	sp@@+,#0x7fff		| restore all but sp
	addql	#8,sp			| pop sp and stack adjust
	jra	_ASM_LABEL(rei)		| all done
a116 1
#include <m68k/m68k/trap_subr.s>
d118 16
a133 56
	.data
GLOBAL(m68k_fault_addr)
	.long	0

#if defined(M68040) || defined(M68060)
ENTRY_NOPROFILE(addrerr4060)
	clrl	sp@@-			| stack adjust count
	moveml	#0xFFFF,sp@@-		| save user registers
	movl	usp,a0			| save the user SP
	movl	a0,sp@@(FR_SP)		|   in the savearea
	movl	sp@@(FR_HW+8),sp@@-
	clrl	sp@@-			| dummy code
	movl	#T_ADDRERR,sp@@-		| mark address error
	jra	_ASM_LABEL(faultstkadj)	| and deal with it
#endif

#if defined(M68060)
ENTRY_NOPROFILE(buserr60)
	clrl	sp@@-			| stack adjust count
	moveml	#0xFFFF,sp@@-		| save user registers
	movl	usp,a0			| save the user SP
	movl	a0,sp@@(FR_SP)		|   in the savearea
	movel	sp@@(FR_HW+12),d0	| FSLW
	btst	#2,d0			| branch prediction error?
	jeq	Lnobpe
	movc	cacr,d2
	orl	#IC60_CABC,d2		| clear all branch cache entries
	movc	d2,cacr
	movl	d0,d1
	addql	#1,L60bpe
	andl	#0x7ffd,d1
	jeq	_ASM_LABEL(faultstkadjnotrap2)
Lnobpe:
| we need to adjust for misaligned addresses
	movl	sp@@(FR_HW+8),d1		| grab VA
	btst	#27,d0			| check for mis-aligned access
	jeq	Lberr3			| no, skip
	addl	#28,d1			| yes, get into next page
					| operand case: 3,
					| instruction case: 4+12+12
	andl	#PG_FRAME,d1		| and truncate
Lberr3:
	movl	d1,sp@@-
	movl	d0,sp@@-			| code is FSLW now.
	andw	#0x1f80,d0 
	jeq	Lberr60			| it is a bus error
	movl	#T_MMUFLT,sp@@-		| show that we are an MMU fault
	jra	_ASM_LABEL(faultstkadj)	| and deal with it
Lberr60:
	tstl	_C_LABEL(nofault)	| catch bus error?
	jeq	Lisberr			| no, handle as usual
	movl	sp@@(FR_HW+8+8),_C_LABEL(m68k_fault_addr) | save fault addr
	movl	_C_LABEL(nofault),sp@@-	| yes,
	jbsr	_C_LABEL(longjmp)	|  longjmp(nofault)
	/* NOTREACHED */
#endif
d135 2
a136 1
ENTRY_NOPROFILE(buserr40)
d141 1
a141 1
	movl	sp@@(FR_HW+20),d1	| get fault address
d143 5
a147 4
	movw	sp@@(FR_HW+12),d0	| get SSW
	btst	#11,d0			| check for mis-aligned
	jeq	Lbe1stpg		| no skip
	addl	#3,d1			| get into next page
d149 13
a161 14
Lbe1stpg:
	movl	d1,sp@@-			| pass fault address.
	movl	d0,sp@@-			| pass SSW as code
	btst	#10,d0			| test ATC
	jeq	Lberr40			| it is a bus error
	movl	#T_MMUFLT,sp@@-		| show that we are an MMU fault
	jra	_ASM_LABEL(faultstkadj)	| and deal with it
Lberr40:
	tstl	_C_LABEL(nofault)	| catch bus error?
	jeq	Lisberr			| no, handle as usual
	movl	sp@@(FR_HW+8+20),_C_LABEL(m68k_fault_addr) | save fault addr
	movl	_C_LABEL(nofault),sp@@-	| yes,
	jbsr	_C_LABEL(longjmp)	|  longjmp(nofault)
	/* NOTREACHED */
d163 2
a164 6

ENTRY_NOPROFILE(busaddrerr2030)
#if !(defined(M68020) || defined(M68030))
	jra	_badtrap
#else
	clrl	sp@@-			| stack adjust count
d168 9
d178 1
a178 1
	movw	sp@@(FR_HW+10),d0	| grab SSW for fault processing
d182 1
a182 1
	movw	d0,sp@@(FR_HW+10)	| for hardware too
d187 1
a187 1
	movw	d0,sp@@(FR_HW+10)	| for hardware too
d191 2
a192 2
	movl	sp@@(FR_HW+16),d1	| fault address is as given in frame
	jra	Lbe10			| thats it
d194 1
a194 1
	btst	#4,sp@@(FR_HW+6)		| long (type B) stack frame?
d196 1
a196 1
	movl	sp@@(FR_HW+2),d1		| no, can use save PC
d207 1
a207 1
	movl	sp@@(FR_HW+36),d1	| long format, use stage B address
d214 1
a214 1
	movw	sp@@(FR_HW+8+6),d0	| get frame format/vector offset
d224 1
a224 1
	btst	#5,sp@@(FR_HW+8)		| supervisor mode?
d234 2
a235 4
	jne	Lisberr1		| yes, needs not be fast.
Lismerr:
	movl	#T_MMUFLT,sp@@-		| show that we are an MMU fault
	jra	_ASM_LABEL(faultstkadj)	| and deal with it
d242 4
a245 2
	jne	Lismerr			| no, was not WPE, must be MMU fault
	jra	Lisberr1		| real bus err needs not be fast.
d248 1
a248 1
	jra	_ASM_LABEL(faultstkadj)	| and deal with it
d251 1
a251 8
	tstl	_C_LABEL(nofault)	| catch bus error?
	jeq	Lisberr			| no, handle as usual
	movl	sp@@(FR_HW+8+16),_C_LABEL(m68k_fault_addr) | save fault addr
	movl	_C_LABEL(nofault),sp@@-	| yes,
	jbsr	_C_LABEL(longjmp)	|  longjmp(nofault)
	/* NOTREACHED */
#endif
Lisberr:				| also used by M68040/60
d253 21
a273 1
	jra	_ASM_LABEL(faultstkadj)	| and deal with it
d278 1
a278 1
ENTRY_NOPROFILE(fpfline)
d280 1
a280 1
	cmpl	#FPU_68040,_C_LABEL(fputype) | 68040 FPU?
d283 1
a283 1
	jne	_C_LABEL(illinst)	| no, not an FP emulation
d286 2
a287 1
	jmp	_ASM_LABEL(fpsp_unimp)	| yes, go handle it
d290 1
a290 1
#endif /* M68040 */
d292 4
a295 4
	clrl	sp@@-			| stack adjust count
	moveml	#0xFFFF,sp@@-		| save registers
	moveq	#T_FPEMULI,d0		| denote as FP emulation trap
	jra	_ASM_LABEL(fault)	| do it
d297 1
a297 1
	jra	_C_LABEL(illinst)
d300 1
a300 1
ENTRY_NOPROFILE(fpunsupp)
d302 2
a303 2
	cmpl	#FPU_68040,_C_LABEL(fputype) | 68040 FPU?
	jne	_C_LABEL(illinst)	| no, treat as illinst
d305 2
a306 1
	jmp	_ASM_LABEL(fpsp_unsupp)	| yes, go handle it
d309 1
a309 1
#endif /* M68040 */
d311 4
a314 4
	clrl	sp@@-			| stack adjust count
	moveml	#0xFFFF,sp@@-		| save registers
	moveq	#T_FPEMULD,d0		| denote as FP emulation trap
	jra	_ASM_LABEL(fault)	| do it
d316 1
a316 1
	jra	_C_LABEL(illinst)
d325 2
a326 2
ENTRY_NOPROFILE(fpfault)
	clrl	sp@@-		| stack adjust count
d331 1
a331 1
	movl	_C_LABEL(curpcb),a0 | current pcb
d334 2
a335 3
#if defined(M68040) || defined(M68060)
	/* always null state frame on 68040, 68060 */
	cmpl	#CPU_68040,_C_LABEL(cputype)
d344 1
a344 1
	fmovem	fpsr,sp@@-	| push fpsr as code argument
d347 26
a372 1
	jra	_ASM_LABEL(faultstkadj) | call trap and deal with stack cleanup
d378 11
d390 35
a424 1
ENTRY_NOPROFILE(badtrap)
d427 1
a427 1
	clrw	sp@@-
d429 1
a429 1
	jbsr	_C_LABEL(straytrap)	| report
d431 2
a432 2
	moveml	sp@@+,#0x0303		| restore regs
	jra	_ASM_LABEL(rei)		| all done
d434 2
a435 1
ENTRY_NOPROFILE(trap0)
d441 1
a441 1
	jbsr	_C_LABEL(syscall)	| handle it
d443 1
a443 1
	tstl	_C_LABEL(astpending)
d445 1
a445 1
	tstb	_C_LABEL(ssir)
d448 1
a448 1
	tstb	_C_LABEL(ssir)
d458 2
a459 1
 * Trap 1 - sigreturn
d461 2
a462 2
ENTRY_NOPROFILE(trap1)
	jra	_ASM_LABEL(sigreturn)
d464 2
a465 5
/*
 * Trap 2 - trace trap
 */
ENTRY_NOPROFILE(trap2)
	jra	_C_LABEL(trace)
d468 1
a468 1
 * Trap 12 is the entry point for the cachectl "syscall" (both HP-UX & BSD)
d472 2
a473 1
ENTRY_NOPROFILE(trap12)
d477 1
a477 1
	jbsr	_C_LABEL(cachectl)	| do it
d479 1
a479 1
	jra	_ASM_LABEL(rei)		| all done
d482 4
a485 2
 * Trace (single-step) trap.  Kernel-mode is special.
 * User mode traps are simply passed on to trap().
d487 2
a488 2
ENTRY_NOPROFILE(trace)
	clrl	sp@@-			| stack adjust count
d490 2
a491 1
	moveq	#T_TRACE,d0
d493 9
a501 3
	andw	#PSL_S,d1		| from system mode?
	jne	Lkbrkpt			| yes, kernel breakpoint
	jra	_ASM_LABEL(fault)	| no, user-mode fault
d504 2
a505 5
 * Trap 15 is used for:
 *	- GDB breakpoints (in user programs)
 *	- KGDB breakpoints (in the kernel)
 *	- trace traps for SUN binaries (not fully supported yet)
 * User mode traps are simply passed to trap().
d507 2
a508 2
ENTRY_NOPROFILE(trap15)
	clrl	sp@@-			| stack adjust count
a509 37
	moveq	#T_TRAP15,d0
	movw	sp@@(FR_HW),d1		| get PSW
	andw	#PSL_S,d1		| from system mode?
	jne	Lkbrkpt			| yes, kernel breakpoint
	jra	_ASM_LABEL(fault)	| no, user-mode fault

Lkbrkpt: | Kernel-mode breakpoint or trace trap. (d0=trap_type)
	| Save the system sp rather than the user sp.
	movw	#PSL_HIGHIPL,sr		| lock out interrupts
	lea	sp@@(FR_SIZE),a6		| Save stack pointer
	movl	a6,sp@@(FR_SP)		|  from before trap

	| If were are not on tmpstk switch to it.
	| (so debugger can change the stack pointer)
	movl	a6,d1
	cmpl	#_ASM_LABEL(tmpstk),d1
	jls	Lbrkpt2			| already on tmpstk
	| Copy frame to the temporary stack
	movl	sp,a0			| a0=src
	lea	_ASM_LABEL(tmpstk)-96,a1 | a1=dst
	movl	a1,sp			| sp=new frame
	moveq	#FR_SIZE,d1
Lbrkpt1:
	movl	a0@@+,a1@@+
	subql	#4,d1
	bgt	Lbrkpt1

Lbrkpt2:
	| Call the trap handler for the kernel debugger.
	| Do not call trap() to do it, so that we can
	| set breakpoints in trap() if we want.  We know
	| the trap type is either T_TRACE or T_BREAKPOINT.
	| If we have both DDB and KGDB, let KGDB see it first,
	| because KGDB will just return 0 if not connected.
	| Save args in d2, a2
	movl	d0,d2			| trap type
	movl	sp,a2			| frame ptr
d511 7
a517 7
	| Let KGDB handle it (if connected)
	movl	a2,sp@@-			| push frame ptr
	movl	d2,sp@@-			| push trap type
	jbsr	_C_LABEL(kgdb_trap)	| handle the trap
	addql	#8,sp			| pop args
	cmpl	#0,d0			| did kgdb handle it?
	jne	Lbrkpt3			| yes, done
d519 2
a520 26
#ifdef DDB
	| Let DDB handle it
	movl	a2,sp@@-			| push frame ptr
	movl	d2,sp@@-			| push trap type
	jbsr	_C_LABEL(kdb_trap)	| handle the trap
	addql	#8,sp			| pop args
#if 0	/* not needed on hp300 */
	cmpl	#0,d0			| did ddb handle it?
	jne	Lbrkpt3			| yes, done
#endif
#endif
	/* Sun 3 drops into PROM here. */
Lbrkpt3:
	| The stack pointer may have been modified, or
	| data below it modified (by kgdb push call),
	| so push the hardware frame at the current sp
	| before restoring registers and returning.

	movl	sp@@(FR_SP),a0		| modified sp
	lea	sp@@(FR_SIZE),a1		| end of our frame
	movl	a1@@-,a0@@-		| copy 2 longs with
	movl	a1@@-,a0@@-		| ... predecrement
	movl	a0,sp@@(FR_SP)		| sp = h/w frame
	moveml	sp@@+,#0x7FFF		| restore all but sp
	movl	sp@@,sp			| ... and sp
	rte				| all done
d522 36
a557 2
/* Use common m68k sigreturn */
#include <m68k/m68k/sigreturn.s>
d562 42
a603 38
 * Most 68k-based Macintosh computers
 *
 *	Level 0:	Spurious: ignored
 *	Level 1:	VIA1 (clock, ADB)
 *	Level 2:	VIA2 (NuBus, SCSI)
 *	Level 3:
 *	Level 4:	Serial (SCC)
 *	Level 5:
 *	Level 6:
 *	Level 7:	Non-maskable: parity errors, RESET button
 *
 * On the Q700, Q900 and Q950 in "A/UX mode": this should become:
 *
 *	Level 0:	Spurious: ignored
 *	Level 1:	Software
 *	Level 2:	VIA2 (except ethernet, sound)
 *	Level 3:	Ethernet
 *	Level 4:	Serial (SCC)
 *	Level 5:	Sound
 *	Level 6:	VIA1
 *	Level 7:	NMIs: parity errors, RESET button, YANCC error
 *
 * On the 660AV and 840AV:
 *
 *	Level 0:	Spurious: ignored
 *	Level 1:	VIA1 (clock, ADB)
 *	Level 2:	VIA2 (NuBus, SCSI)
 *	Level 3:	PSC device interrupt
 *	Level 4:	PSC DMA and serial
 *	Level 5:	???
 *	Level 6:	???
 *	Level 7:	NMIs: parity errors?, RESET button
 */

ENTRY_NOPROFILE(spurintr)
	addql	#1,_C_LABEL(intrcnt)+0
	addql	#1,_C_LABEL(uvmexp)+UVMEXP_INTRS
	jra	_ASM_LABEL(rei)
d605 2
a606 2
ENTRY_NOPROFILE(lev1intr)
	addql	#1,_C_LABEL(intrcnt)+4
d610 1
a610 1
	jbsr	_C_LABEL(via1_intr)
d614 2
a615 2
	addql	#1,_C_LABEL(uvmexp)+UVMEXP_INTRS
	jra	_ASM_LABEL(rei)
d617 3
a619 2
ENTRY_NOPROFILE(lev2intr)
	addql	#1,_C_LABEL(intrcnt)+8
d623 1
a623 1
	movl	_C_LABEL(real_via2_intr),a2
d628 2
a629 2
	addql	#1,_C_LABEL(uvmexp)+UVMEXP_INTRS
	jra	_ASM_LABEL(rei)
d631 5
a635 2
ENTRY_NOPROFILE(lev3intr)
	addql	#1,_C_LABEL(intrcnt)+24
d637 172
a808 4
	moveml	#0xFFFF,sp@@-
	movl	sp, sp@@-
	movl	_C_LABEL(lev3_intrvec),a2
	jbsr	a2@@
d810 130
a939 1
	moveml	sp@@+, #0xFFFF
d941 33
a973 2
	addql	#1,_C_LABEL(uvmexp)+UVMEXP_INTRS
	jra	_ASM_LABEL(rei)
d975 37
a1011 18
ENTRY_NOPROFILE(lev4intr)
	addql	#1,_C_LABEL(intrcnt)+12
	clrl	sp@@-
	moveml	#0xFFFF,sp@@-
	movl	sp, sp@@-
	movl	_C_LABEL(lev4_intrvec),a2
	jbsr	a2@@
	addql	#4,sp
	tstl	d0
	beq	normal_rei
	moveml	sp@@+, #0xFFFF
	addql	#4,sp
	rte
normal_rei:
	moveml	sp@@+, #0xFFFF
	addql	#4,sp
	addql	#1,_C_LABEL(uvmexp)+UVMEXP_INTRS
	jra	_ASM_LABEL(rei)
d1013 12
a1024 12
ENTRY_NOPROFILE(lev5intr)
	addql	#1,_C_LABEL(intrcnt)+28
	clrl	sp@@-
	moveml	#0xFFFF,sp@@-
	movl	sp, sp@@-
	movl	_C_LABEL(lev5_intrvec),a2
	jbsr	a2@@
	addql	#4,sp
	moveml	sp@@+, #0xFFFF
	addql	#4,sp
	addql	#1,_C_LABEL(uvmexp)+UVMEXP_INTRS
	jra	_ASM_LABEL(rei)
d1026 1
a1026 12
ENTRY_NOPROFILE(lev6intr)
	addql	#1,_C_LABEL(intrcnt)+32
	clrl	sp@@-
	moveml	#0xFFFF,sp@@-
	movl	sp, sp@@-
	movl	_C_LABEL(lev6_intrvec),a2
	jbsr	a2@@
	addql	#4,sp
	moveml	sp@@+, #0xFFFF
	addql	#4,sp
	addql	#1,_C_LABEL(uvmexp)+UVMEXP_INTRS
	jra	_ASM_LABEL(rei)
d1028 6
a1033 12
ENTRY_NOPROFILE(lev7intr)
	addql	#1,_C_LABEL(intrcnt)+16
	clrl	sp@@-			| pad SR to longword
	moveml	#0xFFFF,sp@@-		| save registers
	movl	usp,a0			| and save
	movl	a0,sp@@(FR_SP)		|   the user stack pointer
	jbsr	_C_LABEL(nmihand)	| call handler
	movl	sp@@(FR_SP),a0		| restore
	movl	a0,usp			|   user SP
	moveml	sp@@+,#0x7FFF		| and remaining registers
	addql	#8,sp			| pop SSP and align word
	jra	_ASM_LABEL(rei)
d1035 3
a1037 5
/* 
 * We could tweak rtclock_intr and gain 12 cycles on the 020 and 030 by
 * saving the status register directly to the stack, but this would lose
 * badly on the 040.  Aligning the stack takes 10 more cycles than this
 * code does, so it's a good compromise.
d1039 11
a1049 17
ENTRY_NOPROFILE(rtclock_intr)
	movl	d2,sp@@-			| save d2
	movw	sr,d2			| save SPL
	movw	#SPL2,sr		| raise SPL to splclock()
	movl	a6@@(8),a1		| get pointer to frame in via1_intr
	movl	a1@@(64),sp@@-		| push ps
	movl	a1@@(68),sp@@-		| push pc
	movl	sp,sp@@-			| push pointer to ps, pc
	jbsr	_C_LABEL(hardclock)	| call generic clock int routine
	lea	sp@@(12),sp		| pop params
	jbsr	_C_LABEL(mrg_VBLQueue)	| give programs in the VBLqueue a chance
	addql	#1,_C_LABEL(intrcnt)+20
	addql	#1,_C_LABEL(uvmexp)+UVMEXP_INTRS
	movw	d2,sr			| restore SPL
	movl	sp@@+,d2			| restore d2
	movl	#1,d0			| clock taken care of
	rts				| go back from whence we came
d1052 2
a1053 11
 * Emulation of VAX REI instruction.
 *
 * This code deals with checking for and servicing ASTs
 * (profiling, scheduling) and software interrupts (network, softclock).
 * We check for ASTs first, just like the VAX.  To avoid excess overhead
 * the T_ASTFLT handling code will also check for software interrupts so we
 * do not have to do it here.  After identifing that we need an AST we
 * drop the IPL to allow device interrupts.
 *
 * This code is complicated by the fact that sendsig may have been called
 * necessitating a stack cleanup.
d1055 19
d1075 2
a1076 1
BSS(ssir,1)
a1077 66
ASENTRY_NOPROFILE(rei)
	tstl	_C_LABEL(astpending)	| AST pending?
	jeq	Lchksir			| no, go check for SIR
Lrei1:
	btst	#5,sp@@			| yes, are we returning to user mode?
	jne	Lchksir			| no, go check for SIR
	movw	#PSL_LOWIPL,sr		| lower SPL
	clrl	sp@@-			| stack adjust
	moveml	#0xFFFF,sp@@-		| save all registers
	movl	usp,a1			| including
	movl	a1,sp@@(FR_SP)		|    the users SP
Lrei2:
	clrl	sp@@-			| VA == none
	clrl	sp@@-			| code == none
	movl	#T_ASTFLT,sp@@-		| type == async system trap
	jbsr	_C_LABEL(trap)		| go handle it
	lea	sp@@(12),sp		| pop value args
	movl	sp@@(FR_SP),a0		| restore user SP
	movl	a0,usp			|   from save area
	movw	sp@@(FR_ADJ),d0		| need to adjust stack?
	jne	Laststkadj		| yes, go to it
	moveml	sp@@+,#0x7FFF		| no, restore most user regs
	addql	#8,sp			| toss SP and stack adjust
	rte				| and do real RTE
Laststkadj:
	lea	sp@@(FR_HW),a1		| pointer to HW frame
	addql	#8,a1			| source pointer
	movl	a1,a0			| source
	addw	d0,a0			|  + hole size = dest pointer
	movl	a1@@-,a0@@-		| copy
	movl	a1@@-,a0@@-		|  8 bytes
	movl	a0,sp@@(FR_SP)		| new SSP
	moveml	sp@@+,#0x7FFF		| restore user registers
	movl	sp@@,sp			| and our SP
	rte				| and do real RTE
Lchksir:
	tstb	_C_LABEL(ssir)		| SIR pending?
	jeq	Ldorte			| no, all done
	movl	d0,sp@@-			| need a scratch register
	movw	sp@@(4),d0		| get SR
	andw	#PSL_IPL7,d0		| mask all but IPL
	jne	Lnosir			| came from interrupt, no can do
	movl	sp@@+,d0			| restore scratch register
Lgotsir:
	movw	#SPL1,sr		| prevent others from servicing int
	tstb	_C_LABEL(ssir)		| too late?
	jeq	Ldorte			| yes, oh well...
	clrl	sp@@-			| stack adjust
	moveml	#0xFFFF,sp@@-		| save all registers
	movl	usp,a1			| including
	movl	a1,sp@@(FR_SP)		|    the users SP
Lsir1:
	clrl	sp@@-			| VA == none
	clrl	sp@@-			| code == none
	movl	#T_SSIR,sp@@-		| type == software interrupt
	jbsr	_C_LABEL(trap)		| go handle it
	lea	sp@@(12),sp		| pop value args
	movl	sp@@(FR_SP),a0		| restore
	movl	a0,usp			|   user SP
	moveml	sp@@+,#0x7FFF		| and all remaining registers
	addql	#8,sp			| pop SP and stack adjust
	rte
Lnosir:
	movl	sp@@+,d0			| restore scratch register
Ldorte:
	rte				| real return
d1080 12
a1091 1
 * Use common m68k sigcode.
d1093 14
a1106 1
#include <m68k/m68k/sigcode.s>
d1112 2
d1120 54
a1173 1
 * Use common m68k process manipulation routines.
d1175 33
a1207 1
#include <m68k/m68k/proc_subr.s>
d1209 9
a1217 2
GLOBAL(curpcb)
GLOBAL(masterpaddr)		| XXX compatibility (debuggers)
d1219 2
a1220 3

ASLOCAL(mdpflag)
	.byte	0		| copy of proc md_flags low byte
d1222 2
a1223 2

ASBSS(nullpcb,SIZEOF_PCB)
d1226 3
a1228 3
 * At exit of a process, do a switch for the last time.
 * Switch to a safe stack and PCB, and select a new process to run.  The
 * old stack and u-area will be freed by the reaper.
d1232 2
a1233 3
	/* save state into garbage pcb */
	movl	#_ASM_LABEL(nullpcb),_C_LABEL(curpcb)
	lea	_ASM_LABEL(tmpstk),sp	| goto a tmp stack
d1235 4
a1238 4
	/* Schedule the vmspace and stack to be freed. */
	movl	a0,sp@@-			| exit2(p)
	jbsr	_C_LABEL(exit2)
	lea	sp@@(4),sp		| pop args
d1240 1
a1240 1
	jra	_C_LABEL(cpu_switch)
d1243 1
a1243 1
 * When no processes are on the runq, Swtch branches to Idle
d1246 2
a1247 1
ASENTRY_NOPROFILE(Idle)
d1250 2
a1251 2
	movl	_C_LABEL(whichqs),d0
	jeq	_ASM_LABEL(Idle)
d1255 2
a1256 1
	PANIC("switch")
d1271 1
a1271 1
	movl	_C_LABEL(curpcb),a0	| current pcb
d1274 3
a1276 3
	movl	_C_LABEL(curproc),sp@@-	| remember last proc running
#endif
	clrl	_C_LABEL(curproc)
d1283 2
a1284 2
	movl	_C_LABEL(whichqs),d0
	jeq	_ASM_LABEL(Idle)
d1294 1
a1294 1
	addl	#_C_LABEL(qs),d1	| locate queue (q)
d1304 3
a1306 3
	movl	_C_LABEL(whichqs),d1
	bclr	d0,d1			| no, clear bit
	movl	d1,_C_LABEL(whichqs)
d1308 2
a1309 2
	movl	a0,_C_LABEL(curproc)
	clrl	_C_LABEL(want_resched)
d1314 1
a1314 1
#endif
d1318 1
a1318 1
	movl	_C_LABEL(curpcb),a1
d1323 2
a1324 2
	tstl	_C_LABEL(fputype)	| Do we have an FPU?
	jeq	Lswnofpsave		| No  Then don't attempt save.
d1338 1
a1338 1
#endif
d1340 1
a1340 1
	movb	a0@@(P_MD_FLAGS+3),mdpflag | low byte of p_md.md_flags
d1342 1
a1342 1
	movl	a1,_C_LABEL(curpcb)
d1344 15
a1358 11
	/*
	 * Activate the process's address space.
	 * XXX Should remember the last USTP value loaded, and call this
	 * XXX only if it has changed.
	 */
	pea	a0@@			| push proc
	jbsr	_C_LABEL(pmap_activate)	| pmap_activate(p)
	addql	#4,sp
	movl	_C_LABEL(curpcb),a1	| restore p_addr

	lea	_ASM_LABEL(tmpstk),sp	| now goto a tmp stack for NMI
d1360 22
d1386 1
a1386 1
	tstl	_C_LABEL(fputype)	| If we don't have an FPU,
d1392 1
a1392 1
	cmpl	#MMU_68040,_C_LABEL(mmutype) | 68040?
d1410 1
a1410 1
 * Update pcb, saving current processor state.
d1419 2
a1420 2
	tstl	_C_LABEL(fputype)	| Do we have FPU?
	jeq	Lsvnofpsave		| No?  Then don't save state.
d1424 1
a1424 1
	jeq	Lsvnofpsave		| yes, all done
d1427 1
a1427 1
Lsvnofpsave:
d1434 1
a1434 1
	movl	_C_LABEL(curpcb),a1	| current pcb
d1454 1
a1454 1
	movl	_C_LABEL(curpcb),a1	| current pcb
d1465 1
a1465 1
	cmpl	#MMU_68040,_C_LABEL(mmutype) | 68040?
d1473 1
a1473 1
	tstl	_C_LABEL(mmutype)
d1486 2
a1487 2
	tstl	_ASM_LABEL(fulltflush)	| being conservative?
	jne	_C_LABEL(_TBIA)		| yes, flush entire TLB
d1491 1
a1491 1
	cmpl	#MMU_68040,_C_LABEL(mmutype) | 68040?
d1505 1
a1505 1
	tstl	_C_LABEL(mmutype)
d1521 2
a1522 2
	tstl	_ASM_LABEL(fulltflush)	| being conservative?
	jne	_C_LABEL(_TBIA)		| yes, flush everything
d1525 1
a1525 1
	cmpl	#MMU_68040,_C_LABEL(mmutype) | 68040?
d1532 1
a1532 1
	tstl	_C_LABEL(mmutype)
d1548 2
a1549 2
	tstl	_ASM_LABEL(fulltflush)	| being conservative?
	jne	_C_LABEL(_TBIA)		| yes, flush everything
d1552 1
a1552 1
	cmpl	#MMU_68040,_C_LABEL(mmutype) | 68040?
d1558 1
a1558 1
	tstl	_C_LABEL(mmutype)
d1575 1
a1575 1
	cmpl	#MMU_68040,_C_LABEL(mmutype) | 68040?
d1595 1
a1595 1
	cmpl	#MMU_68040,_C_LABEL(mmutype) | 68040?
d1605 1
a1605 1
	cmpl	#MMU_68040,_C_LABEL(mmutype) | 68040?
d1615 1
a1615 1
	cmpl	#MMU_68040,_C_LABEL(mmutype) | 68040?
d1655 1
a1655 1
	cmpl	#MMU_68040,_C_LABEL(mmutype) | 68040?
d1671 14
a1684 1
ENTRY_NOPROFILE(getsfc)
d1687 3
d1691 14
a1704 2
ENTRY_NOPROFILE(getdfc)
	movc	dfc,d0
d1715 1
a1715 1
	cmpl	#MMU_68040,_C_LABEL(mmutype) | 68040?
a1716 1
	.word	0xf518			| pflusha
d1721 2
a1722 2
	pflusha				| flush entire TLB
	lea	_C_LABEL(protorp),a0	| CRP prototype
d1725 3
a1727 3
	movl	#CACHE_CLR,d0
	movc	d0,cacr			| invalidate cache(s)
	rts
d1740 1
a1740 1
	tstb	_C_LABEL(ssir)		| software interrupt pending?
d1777 2
a1778 5
 * Basically we just turn off the MMU and jump to the appropriate ROM routine.
 * Note that we must be running in an address range that is mapped one-to-one
 * logical to physical so that the PC is still valid immediately after the MMU
 * is turned off.  We have conveniently mapped the last page of physical
 * memory this way.
d1780 13
a1792 5
ENTRY_NOPROFILE(doboot)
#if defined(M68040)
	cmpl	#MMU_68040,_C_LABEL(mmutype) | 68040?
	jeq	Lnocache5		| yes, skip
#endif
a1794 20
Lnocache5:
	movl	_C_LABEL(maxaddr),a0	| last page of physical memory
	lea	Lbootcode,a1		| start of boot code
	lea	Lebootcode,a3		| end of boot code
Lbootcopy:
	movw	a1@@+,a0@@+		| copy a word
	cmpl	a3,a1			| done yet?
	jcs	Lbootcopy		| no, keep going
#if defined(M68040)
	cmpl	#MMU_68040,_C_LABEL(mmutype) | 68040?
	jne	LmotommuE		| no, skip
	.word	0xf4f8			| cpusha bc
LmotommuE:
#endif
	movl	_C_LABEL(maxaddr),a0
	jmp	a0@@			| jump to last page

Lbootcode:
	lea	a0@@(0x800),sp		| physical SP in case of NMI
	movl	_C_LABEL(MacOSROMBase),a1 | Load MacOS ROMBase
d1796 2
a1797 11
#if defined(M68040)
	cmpl	#MMU_68040,_C_LABEL(mmutype) | 68040?
	jne	LmotommuF		| no, skip
	movl	#0,d0
	movc	d0,cacr			| caches off
	.long	0x4e7b0003		| movc d0,tc (disable MMU)
	jra	Ldoboot1
LmotommuF:
#endif
	movl	#0,a3@@			| value for pmove to TC (turn off MMU)
	pmove	a3@@,tc			| disable MMU
d1799 3
a1801 4
Ldoboot1:
	lea	a1@@(0x90),a1		| offset of ROM reset routine
	jmp	a1@@			| and jump to ROM to reset machine
Lebootcode:
d1811 2
a1812 1
ENTRY_NOPROFILE(ptest040)
d1859 2
a1860 1
ENTRY_NOPROFILE(get_pte)
d1863 1
a1863 1
	lea	_ASM_LABEL(longscratch),a0
d1880 1
a1880 1
	movl	d0,_ASM_LABEL(pte_tmp)	| save for later
d1916 1
a1916 1
	lea	_ASM_LABEL(longscratch),a0 | space for two longs
d1957 1
a1957 1
	movl	d0,_C_LABEL(macos_tt0)	| XXX for later analysis (kill me)
d1969 1
a1969 1
	movl	_ASM_LABEL(pte_tmp),a1	| get address of our original pte
d1988 1
a1988 1
	lea	_ASM_LABEL(longscratch),a0 | disable tt
d1996 1
a1996 1
	jbsr	_C_LABEL(printstar)
d1999 2
a2000 2
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
d2003 3
a2005 3
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
d2008 4
a2011 4
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
d2014 5
a2018 5
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
d2021 6
a2026 6
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
d2029 7
a2035 7
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
d2038 8
a2045 8
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
d2048 9
a2056 9
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
d2059 10
a2068 10
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
	jbsr	_C_LABEL(printstar)
a2070 3
/*
 * Misc. global variables.
 */
d2072 2
a2073 1
GLOBAL(sanity_check)
d2077 3
a2079 3
ASLOCAL(tmpstk)

GLOBAL(machineid)
d2081 6
a2086 16

GLOBAL(mmutype)
	.long	MMU_68851	| default to 68851 PMMU

GLOBAL(cputype)
	.long	CPU_68020	| default to 68020 CPU

#ifdef __notyet__
GLOBAL(ectype)
	.long	EC_NONE		| external cache type, default to none
#endif

GLOBAL(fputype)
	.long	FPU_68882	| default to 68882 FPU

GLOBAL(protorp)
d2088 2
a2089 2

GLOBAL(cold)
d2091 2
a2092 5

GLOBAL(want_resched)
	.long	0

GLOBAL(proc0paddr)
d2094 2
a2095 2

GLOBAL(intiolimit)
d2097 2
a2098 2

GLOBAL(load_addr)
d2100 1
a2100 2

ASLOCAL(lastpage)
d2102 3
a2104 4

GLOBAL(MacOSROMBase)
	.long	0x40800000
GLOBAL(mac68k_vrsrc_cnt)
d2106 1
a2106 5
GLOBAL(mac68k_vrsrc_vec)
	.word	0, 0, 0, 0, 0, 0

#ifdef DEBUG
ASGLOBAL(fulltflush)
d2108 2
a2109 2

ASGLOBAL(fullcflush)
a2111 1

d2113 2
a2114 2

GLOBAL(intrnames)
d2121 1
a2121 4
	.asciz	"unused1"
	.asciz	"unused2"
	.asciz	"unused3"
GLOBAL(eintrnames)
d2123 14
a2136 4

GLOBAL(intrcnt)
	.long	0,0,0,0,0,0,0,0,0
GLOBAL(eintrcnt)
@


1.22.6.3
log
@Sync the SMP branch to something just after 3.0
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.22.6.2 2001/07/04 10:18:37 niklas Exp $	*/
d1464 6
@


1.22.6.4
log
@Merge in trunk
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d506 1
a506 1
					| (we dont separate data/program)
d1156 2
a1157 2
	fmovem	fp0-fp7,a2@@(FPF_REGS)	| save FP general registers
	fmovem	fpcr/fpsr/fpi,a2@@(FPF_FPCR)	| save FP control registers
d1199 2
a1200 2
	fmovem	a0@@(FPF_FPCR),fpcr/fpsr/fpi	| restore FP control registers
	fmovem	a0@@(FPF_REGS),fp0-fp7	| restore FP general registers
d1226 2
a1227 2
	fmovem	fp0-fp7,a0@@(FPF_REGS)	| save FP general registers
	fmovem	fpcr/fpsr/fpi,a0@@(FPF_FPCR)	| save FP control registers
d1528 2
a1529 2
	fmovem fp0-fp7,a0@@(FPF_REGS)	| save FP general registers
	fmovem fpcr/fpsr/fpi,a0@@(FPF_FPCR)	| save FP control registers
d1537 2
a1538 2
	fmovem	a0@@(FPF_FPCR),fpcr/fpsr/fpi	| restore FP control registers
	fmovem	a0@@(FPF_REGS),fp0-fp7	| restore FP general registers
@


1.22.6.5
log
@Sync the SMP branch with 3.3
@
text
@a119 6
GLOBAL(sanity_check)
	.long	0x18621862	| this is our stack overflow checker.

	.space	4 * NBPG
ASLOCAL(tmpstk)

d153 2
d220 1
a220 1
 * Figure out MacOS mappings and bootstrap OpenBSD
a264 1
	.word	0xf4d8			| cinva bc
d604 1
a604 1
	cmpl	#FPU_68040,_C_LABEL(fputype)
a687 7

	| Check PSW and see what happened.
	|   T=0 S=0     (should not happen)
	|   T=1 S=0     trace trap from user mode
	|   T=0 S=1     trace trap on a trap instruction
	|   T=1 S=1     trace trap from system mode (kernel breakpoint)

d689 2
a690 3
	notw	d1			| XXX no support for T0 on 680[234]0
	andw	#PSL_TS,d1		| from system mode (T=1, S=1)?
	jeq	Lkbrkpt			| yes, kernel breakpoint
d755 1
a755 1
#if 0	/* not needed on mac68k */
a1042 1
	.data
a1192 1
#if defined(M68020) || defined(M68030)
a1194 1
#endif
d1275 1
a1275 1
	jgt	Ltbia851		| 68851 implies no d-cache
d1394 1
a1394 1
_C_LABEL(_DCIA):
d1404 1
a1404 1
_C_LABEL(_DCIS):
d1414 1
a1414 1
_C_LABEL(_DCIU):
d1866 6
d1873 1
a1873 1
	.long	0
@


1.22.6.6
log
@Sync SMP branch to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.22.6.5 2003/03/27 23:28:44 niklas Exp $	*/
d21 5
a25 1
 * 3. Neither the name of the University nor the names of its contributors
@


1.22.6.7
log
@Merge with the trunk
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d330 1
a330 1
 * main() never returns; we exit to user mode from a forked process
a676 1
	movl	_C_LABEL(curproc),sp@@-	| push proc pointer
d678 1
a678 1
	lea	sp@@(16),sp		| pop args
@


1.21
log
@Use more from m68k/m68k.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.20 1997/03/12 13:34:23 briggs Exp $	*/
d1037 1
a1037 5
 *	Call function in register a2 with a3 as an arg and then rei.  Note
 * that we restore the stack before calling, thus giving "a2" more stack.
 * (for the case that, e.g., if curproc had a deeply nested call chain...)
 * cpu_fork() also depends on struct frame being a second arg to the
 * function in a2.
@


1.20
log
@Remove reference to obsolete SONICSPACE.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.19 1997/03/08 16:17:03 briggs Exp $	*/
d1119 1
a1119 1
 * non-local gotos
d1121 1
a1121 13
ENTRY(setjmp)
	movl	sp@@(4),a0	| savearea pointer
	moveml	#0xFCFC,a0@@	| save d2-d7/a2-a7
	movl	sp@@,a0@@(48)	| and return address
	moveq	#0,d0		| return 0
	rts

ENTRY(longjmp)
	movl	sp@@(4),a0
	moveml	a0@@+,#0xFCFC
	movl	a0@@,sp@@
	moveq	#1,d0
	rts
a1753 24
	rts

ENTRY(_insque)
	movw	sr,d0
	movw	#PSL_HIGHIPL,sr		| atomic
	movl	sp@@(8),a0		| where to insert (after)
	movl	sp@@(4),a1		| element to insert (e)
	movl	a0@@,a1@@			| e->next = after->next
	movl	a0,a1@@(4)		| e->prev = after
	movl	a1,a0@@			| after->next = e
	movl	a1@@,a0
	movl	a1,a0@@(4)		| e->next->prev = e
	movw	d0,sr
	rts

ENTRY(_remque)
	movw	sr,d0
	movw	#PSL_HIGHIPL,sr		| atomic
	movl	sp@@(4),a0		| element to remove (e)
	movl	a0@@,a1
	movl	a0@@(4),a0
	movl	a0,a1@@(4)		| e->next->prev = e->prev
	movl	a1,a0@@			| e->prev->next = e->next
	movw	d0,sr
@


1.19
log
@Sync with NetBSD of about 4 March.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.18 1997/02/21 05:49:28 briggs Exp $	*/
a2178 7
	.globl	_SONICSPACE, _SONICSPACE_size
_SONICSPACE:
	.space	108123
/* size is figured out in if_sn.c.
   This should be dynamically allocated at some point. */
_SONICSPACE_size:
	.long	108123
@


1.18
log
@Bring in siginfo changes from mvme68k port & Theo.  Compiles.
@
text
@d1 2
a2 2
/*	$OpenBSD: locore.s,v 1.17 1997/02/10 12:01:45 downsj Exp $	*/
/*	$NetBSD: locore.s,v 1.73 1997/01/09 07:28:12 scottr Exp $	*/
@


1.17
log
@mac68k copypage/zeropage changes.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.16 1997/01/24 01:35:47 briggs Exp $	*/
d1089 1
a1089 1
 *	sp+4	signal specific code
d1110 1
@


1.16
log
@Sync w/ NETBSD_CURRENT_971122.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.15 1996/11/23 23:19:38 kstailey Exp $	*/
a1115 32

/*
 * copypage(fromaddr, toaddr)
 *
 * Optimized version of bcopy for a single page-aligned NBPG byte copy.
 */
ENTRY(copypage)
	movl	sp@@(4),a0		| source address
	movl	sp@@(8),a1		| destination address
	movl	#NBPG/32,d0		| number of 32 byte chunks
#if defined(M68040)
	cmpl	#MMU_68040,_mmutype	| 68040?
	jne	Lmlloop			| no, use movl
Lm16loop:
	.long	0xf6209000		| move16 a0@@+,a1@@+
	.long	0xf6209000		| move16 a0@@+,a1@@+
	subql	#1,d0
	jne	Lm16loop
	rts
#endif
Lmlloop:
	movl	a0@@+,a1@@+
	movl	a0@@+,a1@@+
	movl	a0@@+,a1@@+
	movl	a0@@+,a1@@+
	movl	a0@@+,a1@@+
	movl	a0@@+,a1@@+
	movl	a0@@+,a1@@+
	movl	a0@@+,a1@@+
	subql	#1,d0
	jne	Lmlloop
	rts
@


1.15
log
@remrq -> remrunqueue
@
text
@d1 2
a2 2
/*	$OpenBSD: locore.s,v 1.14 1996/10/23 04:49:47 briggs Exp $	*/
/*	$NetBSD: locore.s,v 1.70 1996/10/17 06:32:13 scottr Exp $	*/
d849 2
a853 2

| Give ourself a stack
d855 2
a856 11
	movl	#CACHE_OFF,d0
	movc	d0, cacr

| Some parameters provided by MacOS
|
| LAK: This section is the new way to pass information from the booter
| to the kernel.  At A1 there is an environment variable which has
| a bunch of stuff in ascii format, "VAR=value\0VAR=value\0\0".

	.globl	_initenv, _getenvvars	| in machdep.c
	.globl	_setmachdep		| in machdep.c
d859 1
a859 1
	moveq	#FC_USERD,d0		| user space
d863 50
a912 3
	movl	a1, sp@@-		| Address of buffer
	movl	d4, sp@@-		| Some flags... (mostly not used)
	jbsr	_initenv
a913 3

	jbsr	_getenvvars		| Parse the environment buffer

d919 7
a925 15
	cmpl	#MMU_68040, _mmutype	| Set in _getenvvars ONLY if 040.
	jne	Lstartnot040		| It's not an '040
	.word	0xf4f8			| cpusha bc - push and invalidate caches

	movl	#CACHE40_OFF,d0		| 68040 cache disable
	movc	d0, cacr

	movql	#0, d0
	.long	0x4e7b0004		| movc d0,itt0 ;Disable itt0
	.long	0x4e7b0005		| movc d0,itt1 ;Disable itt1
	.long	0x4e7b0006		| movc d0,dtt0 ;Disable dtt0
	.long	0x4e7b0007		| movc d0,dtt1 ;Disable dtt1
	.long	0x4e7b0003		| movc d0,tc   ;Disable MMU

	movl	#0x0,sp@@-		| Fake unenabled MMU
d928 8
a935 1
Lstartnot040:
a936 19
| BG - Figure out our MMU
	movl	#0x200, d0		| data freeze bit (??)
	movc	d0, cacr		| only exists in 68030
	movc	cacr, d0		| on an '851, it'll go away.
	tstl	d0
	jeq	Lisa68020
	movl	#MMU_68030, _mmutype	| 68030 MMU
	jra	Lmmufigured
Lisa68020:
	movl	#MMU_68851, _mmutype	| 68020, implies 68851, or crash.
Lmmufigured:

	lea	_macos_tc,a0
	pmove	tc,a0@@
	movl	a0@@,sp@@-		| Save current TC for bootstrap

/*
 * Figure out MacOS mappings and bootstrap NetBSD
 */
d938 2
a939 1
	jbsr	_bootstrap_mac68k
d948 1
a948 1
	cmpl	#MMU_68040, _mmutype
d950 7
d958 1
a959 2
	.word	0xf4d8			| cinva bc
	.word	0xf518			| pflusha
d961 2
a962 2
	.long	0x4e7b0003		| Enable MMU
	movl	#0x80008000,d0
d967 9
a980 11

| LAK: Kill the TT0 and TT1 registers so the don't screw us up later.
	tstl	_mmutype		| ttx instructions will break 68851
	jgt	LnokillTT

	lea	longscratch,a0
	movl	#0, a0@@
	.long	0xF0100800		| movl a0@@,tt0
	.long	0xF0100C00		| movl a0@@,tt1

LnokillTT:
d1169 2
a1170 2
 * Setrunqueue puts processes into queues, Remrq removes them from queues.
 * The running process is on no queue, other processes are on a queue
d1543 2
a1544 2
	moveq	#FC_USERD, d0		| user space
	movc	d0, dfc
d1547 1
a1547 1
	movc	d0, dfc
d1857 1
a1857 2
#if defined(M68040)
	cmpl	#MMU_68040, _mmutype	| Set in _getenvvars ONLY if 040.
a1858 1
	.word	0xf4f8			| cpusha bc - push and invalidate caches
d1862 1
d1864 1
a1865 2
#endif

d1877 2
d1887 1
a1887 1
	.long	0x4e7a0003		| movec tc,d0
d1890 3
a1892 3
	movc	sfc,d1
	movql	#1,d0			| FC for ptestr
	movc	d0,sfc
d1895 2
a1896 2
	.long	0x4e7a0805		| movec mmusr,d0
	movc	d1,sfc
d1917 3
a1919 3
 *  One possible problem here is that setting the tt register
 *  may screw something up if, say, the address returned by ptest
 *  in a0 has msb of 0.
d1934 6
a1939 1
	addl	#-4,sp		| make temporary space
d1942 1
a1942 1
	ptestr	#1,a0@@,#7,a1	| search for logical address
a1951 1
	| enable tt0
a1953 5
	andl	#0xff000000,d0	| keep msb
	orl	#0x00008707,d0	| enable tt for reading and writing
	movl	d0,longscratch
	lea	longscratch,a0
	.long	0xf0100800	| pmove a0@@,tt0
d1957 1
a1957 1
	movl	a1@@,d0		|
d1994 1
a1994 1
	ptestr	#1,a0@@,#1,a1	| search for logical address
d1999 1
a1999 1
	ptestr	#1,a0@@,#2,a1	| search for logical address
d2004 1
a2004 1
	ptestr	#1,a0@@,#3,a1	| search for logical address
d2009 1
a2009 1
	ptestr	#1,a0@@,#4,a1	| search for logical address
d2014 1
a2014 1
	ptestr	#1,a0@@,#5,a1	| search for logical address
d2019 1
a2019 1
	ptestr	#1,a0@@,#6,a1	| search for logical address
d2029 1
a2029 9
	| change tt0
	movl	a1,d0
	andl	#0xff000000,d0	| keep msb
	orl	#0x00008707,d0	| enable tt for reading and writing
	movl	d0,longscratch
	lea	longscratch,a0
	.long	0xF0100800	| pmove a0@@,tt0

	movl	a1@@,d0		| get pte of parent
d2043 1
a2043 1
	addl	#4,a1		| address of ite second long
d2045 4
a2048 10
	| change tt0 back
	movl	a1,d0
	andl	#0xff000000,d0	| keep msb
	orl	#0x00008707,d0	| enable tt for reading and writing
	movl	d0,longscratch
	lea	longscratch,a0
	.long	0xF0100800	| pmove a0@@,tt0

	movl	sp@@(12),a0	| address of return pte
	movl	a1@@,a0@@(4)	| write in second long
d2050 1
a2050 1
	movl	#1,d0		| return long-format
d2054 1
a2054 1
	movl	#0,d0		| return short-format
d2058 1
a2058 1
	movl	#-1,d0		| return failure
d2061 3
a2063 4
	clrl	d1		| disable tt
	movl	d1,longscratch
	lea	longscratch,a0
	.long	0xF0100800	| pmove a0@@,tt0
d2065 1
a2065 1
	addl	#4,sp		| return temporary space
d2154 1
a2154 1
	.globl	_mmutype,_protorp
d2156 3
a2158 1
	.long	0		| Are we running 68851, 68030, or 68040?
@


1.14
log
@Sync up with NetBSD and include patch from Dave Huang <khym@@bga.com>
that puts AV I/O in the right place.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.13 1996/10/14 01:20:38 briggs Exp $	*/
d1202 1
a1202 1
ENTRY(remrq)
d1232 1
a1232 1
	.asciz	"remrq"
@


1.13
log
@More from NetBSD:
 * Disable 040 caches in doboot(), and some minor stylistic changes to
   make the hand-coded assembly consistent throughout.
 * Use fputype instead of mmutype for fpu_type.
 * Use defines from m68k/cpu.h.
@
text
@d1 2
a2 2
/*	$OpenBSD: locore.s,v 1.12 1996/09/21 04:14:01 briggs Exp $	*/
/*	$NetBSD: locore.s,v 1.68 1996/10/07 01:37:20 scottr Exp $	*/
d283 1
a283 1
	jne	_illinst		| no, treat as illinst
d973 1
a973 1
/* set kernel stack, user SP, and initial pcb */
d976 2
d1008 7
d1857 25
@


1.12
log
@Actually provide space for mac68k_buserr_addr.
@
text
@d1 2
a2 2
/*	$OpenBSD: locore.s,v 1.11 1996/06/23 16:24:08 briggs Exp $	*/
/*	$NetBSD: locore.s,v 1.65 1996/06/15 21:25:21 briggs Exp $	*/
d280 1
a280 1
	cmpl	#MMU_68040,_mmutype	| 68040?
d302 1
a302 1
	cmpl	#MMU_68040,_mmutype	| 68040?
d334 2
a335 2
#if defined(M68040) || defined(M68040)
	cmpl	#MMU_68040, _mmutype	| if 68040, (060 ha!), etc...
d888 1
a888 1
	movl	#CACHE4_OFF,d0		| 68040 cache disable
d891 6
a896 6
	movel	#0x0, d0
	.word	0x4e7b, 0x0004		| Disable itt0
	.word	0x4e7b, 0x0005		| Disable itt1
	.word	0x4e7b, 0x0006		| Disable dtt0
	.word	0x4e7b, 0x0007		| Disable dtt1
	.word	0x4e7b, 0x0003		| Disable MMU
d1343 1
a1343 1
	tstl	_fpu_type		| Do we have an fpu?
d1406 1
a1406 1
	tstl	_fpu_type		| If we don't have an fpu,
d1439 1
a1439 1
	tstl	_fpu_type		| Do we have FPU?
d1724 1
a1724 1
	.word	0x4e7a,0x0805	| movec  MMUSR,d0
d1827 12
d1842 1
@


1.11
log
@Sync up with NetBSD.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.10 1996/06/15 21:27:17 briggs Exp $	*/
d2156 1
@


1.10
log
@NetBSD PR #2547: wrong bus error detection from is@@beverly.rhein.de.
@
text
@d1 2
a2 2
/*	$OpenBSD: locore.s,v 1.9 1996/06/09 00:47:25 briggs Exp $	*/
/*	$NetBSD: locore.s,v 1.64 1996/06/09 01:53:42 briggs Exp $	*/
@


1.9
log
@Implement suggestion from is -- handle _fpfault differently for 040 and
better processors.  Basically, don't clear and muck with the exc_pend
bit in the BIU for any FP frames on those processors.  It is, in fact,
unclear if we should check the frame type and only do this for the IDLE
frames as there are only three frames (NULL, IDLE, BUSY) and the BIU
only appears in the IDLE frame on the 881/882.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.8 1996/05/26 18:36:20 briggs Exp $	*/
d219 10
a228 1
	ptestr	#1,a0@@,#7		| do a table search
d230 13
a242 4
	btst	#7,sp@@			| bus error bit set?
	jeq	Lismerr			| no, must be MMU fault
	clrw	sp@@			| yes, re-clear pad word
	jra	Lisberr			| and process as normal bus error
d249 2
@


1.8
log
@Add OpenBSD Id string.
@
text
@d1 2
a2 2
/*	$OpenBSD$	*/
/*	$NetBSD: locore.s,v 1.63 1996/05/17 02:11:47 briggs Exp $	*/
d314 4
@


1.7
log
@Sync with NetBSD-current.
@
text
@d1 1
@


1.6
log
@Makefile generates assym.h instead of assym.s, now.
@
text
@d1 1
a1 1
/*	$NetBSD: locore.s,v 1.52 1995/12/11 02:38:08 thorpej Exp $	*/
d80 8
a91 2
	.text

d121 8
d570 1
d620 6
a627 1
/* MAJORBARF: Fix this routine to be like Mac clocks */
d629 3
d633 3
a635 3
	movl	a1@@(64), sp@@-		| push ps
	movl	a1@@(68), sp@@-		| push pc
	movl	sp, sp@@-		| push pointer to ps, pc
d637 2
a638 1
	lea	sp@@(12), sp		| pop params
a639 1

d641 3
a643 2

	movl	#1, d0			| clock taken care of
a823 6
	.globl _videoaddr, _videorowbytes
	.globl _videobitdepth
	.globl _machineid
	.globl _videosize
	.globl _IOBase
	.globl _NuBusBase
d1061 1
a1061 1
#include "m68k/asm.h"
d1467 1
d1470 1
d1499 1
d1501 5
a1505 1
	jgt	Ltbis851
a1509 3
Ltbis851:
	pflushs	#0,#0,a0@@		| flush address from both sides
	rts
d1526 1
d1528 5
a1532 1
	jgt	Ltbias851
a1536 3
Ltbias851:
	pflushs	#4,#4			| flush supervisor TLB entries
	rts
d1552 1
d1554 1
a1554 1
	jgt	Ltbiau851
a1555 2
	movl	#DC_CLEAR,d0
	movc	d0,cacr			| invalidate on-chip d-cache
d1558 1
d1560 2
d1796 2
a1797 5
 * Basically we just turn off the MMU and jump to the appropriate ROM routine.
 * Note that we must be running in an address range that is mapped one-to-one
 * logical to physical so that the PC is still valid immediately after the MMU
 * is turned off.  We have conveniently mapped the last page of physical
 * memory this way.
a2130 1
	.long	0
@


1.5
log
@Move VIA_Initialize() back to where it works.
@
text
@d80 1
a80 1
#include "assym.s"
@


1.4
log
@New self-calibrating spin-wait delay() from Scott Reynolds <scottr@@edsi.org>.
@
text
@a822 1
	.globl	_VIA_initialize		| in via.c
a836 1
	jbsr	_VIA_initialize		| Initialize the VIAs
@


1.3
log
@from netbsd--remove bogus code.
@
text
@d823 1
d838 1
d2111 7
@


1.2
log
@update from netbsd (without losing local changes)
@
text
@a806 18
	.globl _locore_dodebugmarks

#define DEBUG
#ifdef DEBUG
#define debug_mark(s)			\
	.data	;			\
0:	.asciz	s ;			\
	.text	;			\
	tstl	_locore_dodebugmarks ;	\
	beq	1f ;			\
	movml	#0xC0C0, sp@@- ;		\
	pea	0b ;			\
	jbsr	_printf ;		\
	addql	#4, sp ;		\
	movml	sp@@+, #0x0303 ;		\
1:	;
#endif

a2107 2
	.long	0
_locore_dodebugmarks:
@


1.1
log
@Initial revision
@
text
@d1 1
a1 1
/*	$NetBSD: locore.s,v 1.51 1995/10/10 04:14:18 briggs Exp $	*/
a1758 75
	rts

ENTRY(memcpy)
	movl	sp@@(12),d0		| get count
	jeq	Lcpyexit		| if zero, return
	movl	sp@@(8), a0		| src address
	movl	sp@@(4), a1		| dest address
	jra	Ldocopy			| jump into bcopy
/*
 * {ov}bcopy(from, to, len)
 *
 * Works for counts up to 128K.
 */
ALTENTRY(ovbcopy, _bcopy)
ENTRY(bcopy)
	movl	sp@@(12),d0		| get count
	jeq	Lcpyexit		| if zero, return
	movl	sp@@(4),a0		| src address
	movl	sp@@(8),a1		| dest address
Ldocopy:
	cmpl	a1,a0			| src before dest?
	jlt	Lcpyback		| yes, copy backwards (avoids overlap)
	movl	a0,d1
	btst	#0,d1			| src address odd?
	jeq	Lcfeven			| no, go check dest
	movb	a0@@+,a1@@+		| yes, copy a byte
	subql	#1,d0			| update count
	jeq	Lcpyexit		| exit if done
Lcfeven:
	movl	a1,d1
	btst	#0,d1			| dest address odd?
	jne	Lcfbyte			| yes, must copy by bytes
	movl	d0,d1			| no, get count
	lsrl	#2,d1			| convert to longwords
	jeq	Lcfbyte			| no longwords, copy bytes
	subql	#1,d1			| set up for dbf
Lcflloop:
	movl	a0@@+,a1@@+		| copy longwords
	dbf	d1,Lcflloop		| til done
	andl	#3,d0			| get remaining count
	jeq	Lcpyexit		| done if none
Lcfbyte:
	subql	#1,d0			| set up for dbf
Lcfbloop:
	movb	a0@@+,a1@@+		| copy bytes
	dbf	d0,Lcfbloop		| til done
Lcpyexit:
	rts
Lcpyback:
	addl	d0,a0			| add count to src
	addl	d0,a1			| add count to dest
	movl	a0,d1
	btst	#0,d1			| src address odd?
	jeq	Lcbeven			| no, go check dest
	movb	a0@@-,a1@@-		| yes, copy a byte
	subql	#1,d0			| update count
	jeq	Lcpyexit		| exit if done
Lcbeven:
	movl	a1,d1
	btst	#0,d1			| dest address odd?
	jne	Lcbbyte			| yes, must copy by bytes
	movl	d0,d1			| no, get count
	lsrl	#2,d1			| convert to longwords
	jeq	Lcbbyte			| no longwords, copy bytes
	subql	#1,d1			| set up for dbf
Lcblloop:
	movl	a0@@-,a1@@-		| copy longwords
	dbf	d1,Lcblloop		| til done
	andl	#3,d0			| get remaining count
	jeq	Lcpyexit		| done if none
Lcbbyte:
	subql	#1,d0			| set up for dbf
Lcbbloop:
	movb	a0@@-,a1@@-		| copy bytes
	dbf	d0,Lcbbloop		| til done
@


1.1.1.1
log
@initial import of NetBSD tree
@
text
@@
