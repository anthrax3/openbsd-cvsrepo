head	1.42;
access;
symbols
	OPENBSD_5_6:1.40.0.4
	OPENBSD_5_6_BASE:1.40
	OPENBSD_5_5:1.37.0.8
	OPENBSD_5_5_BASE:1.37
	OPENBSD_5_4:1.37.0.4
	OPENBSD_5_4_BASE:1.37
	OPENBSD_5_3:1.37.0.2
	OPENBSD_5_3_BASE:1.37
	OPENBSD_5_2:1.35.0.6
	OPENBSD_5_2_BASE:1.35
	OPENBSD_5_1_BASE:1.35
	OPENBSD_5_1:1.35.0.4
	OPENBSD_5_0:1.35.0.2
	OPENBSD_5_0_BASE:1.35
	OPENBSD_4_9:1.34.0.2
	OPENBSD_4_9_BASE:1.34
	OPENBSD_4_8:1.33.0.2
	OPENBSD_4_8_BASE:1.33
	OPENBSD_4_7:1.31.0.2
	OPENBSD_4_7_BASE:1.31
	OPENBSD_4_6:1.31.0.4
	OPENBSD_4_6_BASE:1.31
	OPENBSD_4_5:1.28.0.4
	OPENBSD_4_5_BASE:1.28
	OPENBSD_4_4:1.28.0.2
	OPENBSD_4_4_BASE:1.28
	OPENBSD_4_3:1.27.0.2
	OPENBSD_4_3_BASE:1.27
	OPENBSD_4_2:1.25.0.2
	OPENBSD_4_2_BASE:1.25
	OPENBSD_4_1:1.24.0.6
	OPENBSD_4_1_BASE:1.24
	OPENBSD_4_0:1.24.0.4
	OPENBSD_4_0_BASE:1.24
	OPENBSD_3_9:1.24.0.2
	OPENBSD_3_9_BASE:1.24
	OPENBSD_3_8:1.22.0.4
	OPENBSD_3_8_BASE:1.22
	OPENBSD_3_7:1.22.0.2
	OPENBSD_3_7_BASE:1.22
	OPENBSD_3_6:1.21.0.4
	OPENBSD_3_6_BASE:1.21
	SMP_SYNC_A:1.21
	SMP_SYNC_B:1.21
	OPENBSD_3_5:1.21.0.2
	OPENBSD_3_5_BASE:1.21
	OPENBSD_3_4:1.19.0.2
	OPENBSD_3_4_BASE:1.19
	UBC_SYNC_A:1.18
	OPENBSD_3_3:1.18.0.2
	OPENBSD_3_3_BASE:1.18
	OPENBSD_3_2:1.15.0.2
	OPENBSD_3_2_BASE:1.15
	OPENBSD_3_1:1.13.0.2
	OPENBSD_3_1_BASE:1.13
	UBC_SYNC_B:1.17
	UBC:1.9.0.2
	UBC_BASE:1.9
	SMP:1.3.0.4
	OPENBSD_3_0:1.3.0.2
	OPENBSD_3_0_BASE:1.3;
locks; strict;
comment	@ * @;


1.42
date	2015.01.20.17.08.35;	author mpi;	state dead;
branches;
next	1.41;
commitid	9SVbxff6jAFsGD1m;

1.41
date	2014.11.16.12.30.58;	author deraadt;	state Exp;
branches;
next	1.40;
commitid	yv0ECmCdICvq576h;

1.40
date	2014.07.12.18.44.42;	author tedu;	state Exp;
branches;
next	1.39;
commitid	uKVPYMN2MLxdZxzH;

1.39
date	2014.07.11.09.36.26;	author mpi;	state Exp;
branches;
next	1.38;
commitid	vsYjSRfS3Y783BvW;

1.38
date	2014.03.31.18.58.41;	author mpi;	state Exp;
branches;
next	1.37;

1.37
date	2012.12.04.10.14.25;	author mpi;	state Exp;
branches;
next	1.36;

1.36
date	2012.08.30.18.14.26;	author mpi;	state Exp;
branches;
next	1.35;

1.35
date	2011.06.23.20.44.39;	author ariane;	state Exp;
branches;
next	1.34;

1.34
date	2010.12.26.15.40.59;	author miod;	state Exp;
branches;
next	1.33;

1.33
date	2010.06.26.23.24.43;	author guenther;	state Exp;
branches;
next	1.32;

1.32
date	2010.03.29.19.21.58;	author oga;	state Exp;
branches;
next	1.31;

1.31
date	2009.04.20.00.42.06;	author oga;	state Exp;
branches;
next	1.30;

1.30
date	2009.04.14.16.01.04;	author oga;	state Exp;
branches;
next	1.29;

1.29
date	2009.03.07.15.34.34;	author miod;	state Exp;
branches;
next	1.28;

1.28
date	2008.06.26.05.42.12;	author ray;	state Exp;
branches;
next	1.27;

1.27
date	2007.10.02.00.59.12;	author krw;	state Exp;
branches;
next	1.26;

1.26
date	2007.09.03.01.09.09;	author krw;	state Exp;
branches;
next	1.25;

1.25
date	2007.05.27.15.46.02;	author drahn;	state Exp;
branches;
next	1.24;

1.24
date	2005.12.17.07.31.26;	author miod;	state Exp;
branches;
next	1.23;

1.23
date	2005.10.26.18.57.51;	author martin;	state Exp;
branches;
next	1.22;

1.22
date	2004.11.09.19.17.01;	author claudio;	state Exp;
branches;
next	1.21;

1.21
date	2003.12.20.22.40.27;	author miod;	state Exp;
branches;
next	1.20;

1.20
date	2003.10.15.17.50.16;	author drahn;	state Exp;
branches;
next	1.19;

1.19
date	2003.06.02.18.14.16;	author jason;	state Exp;
branches;
next	1.18;

1.18
date	2002.12.10.23.41.37;	author miod;	state Exp;
branches;
next	1.17;

1.17
date	2002.10.07.18.35.56;	author mickey;	state Exp;
branches;
next	1.16;

1.16
date	2002.10.06.22.06.15;	author art;	state Exp;
branches;
next	1.15;

1.15
date	2002.09.15.09.01.58;	author deraadt;	state Exp;
branches;
next	1.14;

1.14
date	2002.09.15.02.02.43;	author deraadt;	state Exp;
branches;
next	1.13;

1.13
date	2002.03.14.01.26.36;	author millert;	state Exp;
branches;
next	1.12;

1.12
date	2002.02.18.14.26.24;	author drahn;	state Exp;
branches;
next	1.11;

1.11
date	2002.01.03.07.14.50;	author drahn;	state Exp;
branches;
next	1.10;

1.10
date	2001.12.31.17.03.59;	author miod;	state Exp;
branches;
next	1.9;

1.9
date	2001.12.12.19.18.23;	author jason;	state Exp;
branches
	1.9.2.1;
next	1.8;

1.8
date	2001.12.08.02.24.06;	author art;	state Exp;
branches;
next	1.7;

1.7
date	2001.11.28.16.24.26;	author art;	state Exp;
branches;
next	1.6;

1.6
date	2001.11.16.20.46.16;	author jason;	state Exp;
branches;
next	1.5;

1.5
date	2001.11.06.19.53.15;	author miod;	state Exp;
branches;
next	1.4;

1.4
date	2001.11.05.17.25.58;	author art;	state Exp;
branches;
next	1.3;

1.3
date	2001.09.19.20.50.57;	author mickey;	state Exp;
branches
	1.3.4.1;
next	1.2;

1.2
date	2001.09.15.01.40.36;	author mickey;	state Exp;
branches;
next	1.1;

1.1
date	2001.09.01.15.44.20;	author drahn;	state Exp;
branches;
next	;

1.3.4.1
date	2001.10.31.03.01.16;	author nate;	state Exp;
branches;
next	1.3.4.2;

1.3.4.2
date	2001.11.13.21.00.53;	author niklas;	state Exp;
branches;
next	1.3.4.3;

1.3.4.3
date	2001.12.05.00.39.11;	author niklas;	state Exp;
branches;
next	1.3.4.4;

1.3.4.4
date	2002.03.06.01.06.11;	author niklas;	state Exp;
branches;
next	1.3.4.5;

1.3.4.5
date	2002.03.28.10.36.01;	author niklas;	state Exp;
branches;
next	1.3.4.6;

1.3.4.6
date	2003.03.27.23.29.46;	author niklas;	state Exp;
branches;
next	1.3.4.7;

1.3.4.7
date	2003.06.07.11.13.14;	author ho;	state Exp;
branches;
next	1.3.4.8;

1.3.4.8
date	2004.02.19.10.49.03;	author niklas;	state Exp;
branches;
next	;

1.9.2.1
date	2002.01.31.22.55.14;	author niklas;	state Exp;
branches;
next	1.9.2.2;

1.9.2.2
date	2002.02.02.03.28.25;	author art;	state Exp;
branches;
next	1.9.2.3;

1.9.2.3
date	2002.06.11.03.36.34;	author art;	state Exp;
branches;
next	1.9.2.4;

1.9.2.4
date	2002.10.29.00.28.06;	author art;	state Exp;
branches;
next	1.9.2.5;

1.9.2.5
date	2003.05.19.21.49.43;	author tedu;	state Exp;
branches;
next	;


desc
@@


1.42
log
@Merge two copies of the same dma code into one file and sync the headers.

ok kettenis@@
@
text
@/*	$OpenBSD: dma.c,v 1.41 2014/11/16 12:30:58 deraadt Exp $	*/
/*	$NetBSD: machdep.c,v 1.214 1996/11/10 03:16:17 thorpej Exp $	*/

/*-
 * Copyright (c) 1996, 1997 The NetBSD Foundation, Inc.
 * All rights reserved.
 *
 * This code is derived from software contributed to The NetBSD Foundation
 * by Jason R. Thorpe of the Numerical Aerospace Simulation Facility,
 * NASA Ames Research Center.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 *
 * THIS SOFTWARE IS PROVIDED BY THE NETBSD FOUNDATION, INC. AND CONTRIBUTORS
 * ``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED
 * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE FOUNDATION OR CONTRIBUTORS
 * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
 * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
 * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
 * POSSIBILITY OF SUCH DAMAGE.
 */

#include <sys/param.h>
#include <sys/proc.h>
#include <sys/extent.h>
#include <sys/buf.h>
#include <sys/device.h>
#include <sys/systm.h>
#include <sys/conf.h>
#include <sys/file.h>
#include <sys/malloc.h>
#include <sys/mbuf.h>
#include <sys/mount.h>

#include <uvm/uvm_extern.h>

#include <machine/bus.h>

int _dmamem_alloc_range( bus_dma_tag_t t, bus_size_t size,
    bus_size_t alignment, bus_size_t boundary, bus_dma_segment_t *segs,
    int nsegs, int *rsegs, int flags, vaddr_t low, vaddr_t high);
int _dmamap_load_buffer(bus_dma_tag_t, bus_dmamap_t, void *, bus_size_t,
    struct proc *, int, bus_addr_t *, int *, int);
/*
 * Common function for DMA map creation.  May be called by bus-specific
 * DMA map creation functions.
 */
int
_dmamap_create(bus_dma_tag_t t, bus_size_t size, int nsegments,
    bus_size_t maxsegsz, bus_size_t boundary, int flags, bus_dmamap_t *dmamp)
{
	struct powerpc_bus_dmamap *map;
	void *mapstore;
	size_t mapsize;

	/*
	 * Allocate and initialize the DMA map.  The end of the map
	 * is a variable-sized array of segments, so we allocate enough
	 * room for them in one shot.
	 *
	 * Note we don't preserve the WAITOK or NOWAIT flags.  Preservation
	 * of ALLOCNOW notifies others that we've reserved these resources,
	 * and they are not to be freed.
	 *
	 * The bus_dmamap_t includes one bus_dma_segment_t, hence
	 * the (nsegments - 1).
	 */
	mapsize = sizeof(struct powerpc_bus_dmamap) +
	    (sizeof(bus_dma_segment_t) * (nsegments - 1));
	if ((mapstore = malloc(mapsize, M_DEVBUF, (flags & BUS_DMA_NOWAIT) ?
	    (M_NOWAIT | M_ZERO) : (M_WAITOK | M_ZERO))) == NULL)
		return (ENOMEM);

	map = (struct powerpc_bus_dmamap *)mapstore;
	map->_dm_size = size;
	map->_dm_segcnt = nsegments;
	map->_dm_maxsegsz = maxsegsz;
	map->_dm_boundary = boundary;
	map->_dm_flags = flags & ~(BUS_DMA_WAITOK|BUS_DMA_NOWAIT);
	map->dm_nsegs = 0;		/* no valid mappings */
	map->dm_mapsize = 0;

	*dmamp = map;
	return (0);
}

/*
 * Common function for DMA map destruction.  May be called by bus-specific
 * DMA map destruction functions.
 */
void
_dmamap_destroy(bus_dma_tag_t t, bus_dmamap_t map)
{

	free(map, M_DEVBUF, 0);
}


int
_dmamap_load_buffer(bus_dma_tag_t t, bus_dmamap_t map, void *buf,
    bus_size_t buflen, struct proc *p, int flags, bus_addr_t *lastaddrp,
    int *segp, int first)
{
	bus_size_t sgsize;
	bus_addr_t curaddr, lastaddr, baddr, bmask;
	vaddr_t vaddr = (vaddr_t)buf;
	pmap_t pmap;
	int seg;

	lastaddr = *lastaddrp;
	bmask = ~(map->_dm_boundary - 1);

	if (p != NULL)
		pmap = p->p_vmspace->vm_map.pmap;
	else
		pmap = pmap_kernel();

	for (seg = *segp; buflen > 0; ) {
		/*
		 * Get the physical address for this segment.
		 */
		if (pmap_extract(pmap, vaddr, (paddr_t *)&curaddr) != TRUE) {
			panic("dmamap_load_buffer pmap %p vaddr %lx "
				"pmap_extract failed", pmap, vaddr);
		}

		/*
		 * Compute the segment size, and adjust counts.
		 */
		sgsize = PAGE_SIZE - ((u_long)vaddr & PGOFSET);
		if (buflen < sgsize)
			sgsize = buflen;

		/*
		 * Make sure we don't cross any boundaries.
		 */
		if (map->_dm_boundary > 0) {
			baddr = (curaddr + map->_dm_boundary) & bmask;
			if (sgsize > (baddr - curaddr))
				sgsize = (baddr - curaddr);
		}

		/*
		 * Insert chunk into a segment, coalescing with the
		 * previous segment if possible.
		 */
		if (first) {
			map->dm_segs[seg].ds_addr = curaddr;
			map->dm_segs[seg].ds_len = sgsize;
			first = 0;
		} else {
			if (curaddr == lastaddr &&
			    (map->dm_segs[seg].ds_len + sgsize) <=
			     map->_dm_maxsegsz &&
			    (map->_dm_boundary == 0 ||
			     (map->dm_segs[seg].ds_addr & bmask) ==
			     (curaddr & bmask)))
				map->dm_segs[seg].ds_len += sgsize;
			else {
				if (++seg >= map->_dm_segcnt)
					break;
				map->dm_segs[seg].ds_addr = curaddr;
				map->dm_segs[seg].ds_len = sgsize;
			}
		}

		lastaddr = curaddr + sgsize;
		vaddr += sgsize;
		buflen -= sgsize;
	}

	*segp = seg;
	*lastaddrp = lastaddr;

	/*
	 * Did we fit?
	 */
	if (buflen != 0)
		return (EFBIG);		/* XX better return value here? */

	return (0);
}

/*
 * Common function for loading a DMA map with a linear buffer.  May
 * be called by bus-specific DMA map load functions.
 */
int
_dmamap_load(bus_dma_tag_t t, bus_dmamap_t map, void *buf, bus_size_t buflen,
    struct proc *p, int flags)
{
	bus_addr_t lastaddr;
	int seg, error;

	/*
	 * Make sure that on error condition we return "no valid mappings".
	 */
	map->dm_mapsize = 0;
	map->dm_nsegs = 0;

	if (buflen > map->_dm_size)
		return (EINVAL);

	seg = 0;
	error = _dmamap_load_buffer(t, map, buf, buflen, p, flags,
	    &lastaddr, &seg, 1);
	if (error == 0) {
		map->dm_mapsize = buflen;
		map->dm_nsegs = seg + 1;
	}
	return (error);
}

/*
 * Like _bus_dmamap_load(), but for mbufs.
 */
int
_dmamap_load_mbuf(bus_dma_tag_t t, bus_dmamap_t map, struct mbuf *m0,
    int flags)
{
	bus_addr_t lastaddr;
	int seg, error, first;
	struct mbuf *m;

	/*
	 * Make sure that on error condition we return "no valid mappings".
	 */
	map->dm_mapsize = 0;
	map->dm_nsegs = 0;

#ifdef DIAGNOSTIC
	if ((m0->m_flags & M_PKTHDR) == 0)
		panic("_bus_dmamap_load_mbuf: no packet header");
#endif

	if (m0->m_pkthdr.len > map->_dm_size)
		return (EINVAL);

	first = 1;
	seg = 0;
	error = 0;
	for (m = m0; m != NULL && error == 0; m = m->m_next) {
		if (m->m_len == 0)
			continue;
		error = _dmamap_load_buffer(t, map, m->m_data, m->m_len,
		    NULL, flags, &lastaddr, &seg, first);
		first = 0;
	}
	if (error == 0) {
		map->dm_mapsize = m0->m_pkthdr.len;
		map->dm_nsegs = seg + 1;
	}
	return (error);
}

/*
 * Like _bus_dmamap_load(), but for uios.
 */
int
_dmamap_load_uio(bus_dma_tag_t t, bus_dmamap_t map, struct uio *uio, int flags)
{
	bus_addr_t lastaddr;
	int seg, i, error, first;
	bus_size_t minlen, resid;
	struct proc *p = NULL;
	struct iovec *iov;
	caddr_t addr;

	/*
	 * Make sure that on error condition we return "no valid mappings".
	 */
	map->dm_mapsize = 0;
	map->dm_nsegs = 0;

	resid = uio->uio_resid;
	iov = uio->uio_iov;

	if (resid > map->_dm_size)
		return (EINVAL);

	if (uio->uio_segflg == UIO_USERSPACE) {
		p = uio->uio_procp;
#ifdef DIAGNOSTIC
		if (p == NULL)
			panic("_bus_dmamap_load_uio: USERSPACE but no proc");
#endif
	}

	first = 1;
	seg = 0;
	error = 0;
	for (i = 0; i < uio->uio_iovcnt && resid != 0 && error == 0; i++) {
		/*
		 * Now at the first iovec to load.  Load each iovec
		 * until we have exhausted the residual count.
		 */
		minlen = resid < iov[i].iov_len ? resid : iov[i].iov_len;
		addr = (caddr_t)iov[i].iov_base;

		error = _dmamap_load_buffer(t, map, addr, minlen,
		    p, flags, &lastaddr, &seg, first);
		first = 0;

		resid -= minlen;
	}
	if (error == 0) {
		map->dm_mapsize = uio->uio_resid;
		map->dm_nsegs = seg + 1;
	}
	return (error);
}

/*
 * Like _bus_dmamap_load(), but for raw memory allocated with
 * bus_dmamem_alloc().
 */
int
_dmamap_load_raw(bus_dma_tag_t t, bus_dmamap_t map, bus_dma_segment_t *segs,
    int nsegs, bus_size_t size, int flags)
{
	if (nsegs > map->_dm_segcnt || size > map->_dm_size)
		return (EINVAL);

	/*
	 * Make sure we don't cross any boundaries.
	 */
	if (map->_dm_boundary) {
		bus_addr_t bmask = ~(map->_dm_boundary - 1);
		int i;

		for (i = 0; i < nsegs; i++) {
			if (segs[i].ds_len > map->_dm_maxsegsz)
				return (EINVAL);
			if ((segs[i].ds_addr & bmask) !=
			    ((segs[i].ds_addr + segs[i].ds_len - 1) & bmask))
				return (EINVAL);
		}
	}

	bcopy(segs, map->dm_segs, nsegs * sizeof(*segs));
	map->dm_nsegs = nsegs;
	map->dm_mapsize = size;
	return (0);
}

/*
 * Common function for unloading a DMA map.  May be called by
 * bus-specific DMA map unload functions.
 */
void
_dmamap_unload(bus_dma_tag_t t, bus_dmamap_t map)
{

	/*
	 * No resources to free; just mark the mappings as
	 * invalid.
	 */
	map->dm_nsegs = 0;
	map->dm_mapsize = 0;
}

/*
 * Common function for DMA map synchronization.  May be called
 * by bus-specific DMA map synchronization functions.
 */
void
_dmamap_sync(bus_dma_tag_t t, bus_dmamap_t map, bus_addr_t offset,
bus_size_t len, int op)
{
	int i;
	bus_size_t minlen, wlen;
	bus_addr_t pa, addr;
	struct vm_page *pg;

	for (i = 0; i < map->dm_nsegs && len != 0; i++) {
		/* Find the beginning segment. */
		if (offset >= map->dm_segs[i].ds_len) {
			offset -= map->dm_segs[i].ds_len;
			continue;
		}

		minlen = len < map->dm_segs[i].ds_len - offset ?
		    len : map->dm_segs[i].ds_len - offset;

		addr = map->dm_segs[i].ds_addr + offset;

		switch (op) {
		case BUS_DMASYNC_POSTWRITE:
			for (pa = trunc_page(addr), wlen = 0;
			    pa < round_page(addr + minlen);
			    pa += PAGE_SIZE) {
				pg = PHYS_TO_VM_PAGE(pa);
				if (pg != NULL)
					atomic_clearbits_int(&pg->pg_flags,
					    PG_PMAP_EXE);
			}
		}
		
	}
}

/*
 * Common function for DMA-safe memory allocation.  May be called
 * by bus-specific DMA memory allocation functions.
 */
int
_dmamem_alloc(bus_dma_tag_t t, bus_size_t size, bus_size_t alignment,
    bus_size_t boundary, bus_dma_segment_t *segs, int nsegs, int *rsegs,
    int flags)
{
	return (_dmamem_alloc_range(t, size, alignment, boundary,
	    segs, nsegs, rsegs, flags, 0, -1));
}

/*
 * Common function for freeing DMA-safe memory.  May be called by
 * bus-specific DMA memory free functions.
 */
void
_dmamem_free(bus_dma_tag_t t, bus_dma_segment_t *segs, int nsegs)
{
	struct vm_page *m;
	bus_addr_t addr;
	struct pglist mlist;
	int curseg;

	/*
	 * Build a list of pages to free back to the VM system.
	 */
	TAILQ_INIT(&mlist);
	for (curseg = 0; curseg < nsegs; curseg++) {
		for (addr = segs[curseg].ds_addr;
		    addr < (segs[curseg].ds_addr + segs[curseg].ds_len);
		    addr += PAGE_SIZE) {
			m = PHYS_TO_VM_PAGE(addr);
			TAILQ_INSERT_TAIL(&mlist, m, pageq);
		}
	}

	uvm_pglistfree(&mlist);
}

/*
 * Common function for mapping DMA-safe memory.  May be called by
 * bus-specific DMA memory map functions.
 */
int
_dmamem_map(bus_dma_tag_t t, bus_dma_segment_t *segs, int nsegs, size_t size,
    caddr_t *kvap, int flags)
{
	vaddr_t va, sva;
	size_t ssize;
	bus_addr_t addr;
	int curseg, pmapflags = 0, error;
	const struct kmem_dyn_mode *kd;

	if (flags & BUS_DMA_NOCACHE)
		pmapflags |= PMAP_NOCACHE;

	size = round_page(size);
	kd = flags & BUS_DMA_NOWAIT ? &kd_trylock : &kd_waitok;
	va = (vaddr_t)km_alloc(size, &kv_any, &kp_none, kd);
	if (va == 0)
		return (ENOMEM);

	*kvap = (caddr_t)va;

	sva = va;
	ssize = size;
	for (curseg = 0; curseg < nsegs; curseg++) {
		for (addr = segs[curseg].ds_addr;
		    addr < (segs[curseg].ds_addr + segs[curseg].ds_len);
		    addr += PAGE_SIZE, va += PAGE_SIZE, size -= PAGE_SIZE) {
			if (size == 0)
				panic("_bus_dmamem_map: size botch");
			error = pmap_enter(pmap_kernel(), va, addr | pmapflags,
			    PROT_READ | PROT_WRITE,
			    PROT_READ | PROT_WRITE | PMAP_WIRED | PMAP_CANFAIL);
			if (error) {
				pmap_update(pmap_kernel());
				km_free((void *)sva, ssize, &kv_any, &kp_none);
				return (error);
			}
		}
	}
	pmap_update(pmap_kernel());

	return (0);
}

/*
 * Common function for unmapping DMA-safe memory.  May be called by
 * bus-specific DMA memory unmapping functions.
 */
void
_dmamem_unmap(bus_dma_tag_t t, caddr_t kva, size_t size)
{

#ifdef DIAGNOSTIC
	if ((u_long)kva & PGOFSET)
		panic("_bus_dmamem_unmap");
#endif

	km_free(kva, round_page(size), &kv_any, &kp_none);
}

/*
 * Common function for mmap(2)'ing DMA-safe memory.  May be called by
 * bus-specific DMA mmap(2)'ing functions.
 */
paddr_t
_dmamem_mmap(bus_dma_tag_t t, bus_dma_segment_t *segs, int nsegs, off_t off,
    int prot, int flags)
{
	int i, pmapflags = 0;

	if (flags & BUS_DMA_NOCACHE)
		pmapflags |= PMAP_NOCACHE;

	for (i = 0; i < nsegs; i++) {
#ifdef DIAGNOSTIC
		if (off & PGOFSET)
			panic("_bus_dmamem_mmap: offset unaligned");
		if (segs[i].ds_addr & PGOFSET)
			panic("_bus_dmamem_mmap: segment unaligned");
		if (segs[i].ds_len & PGOFSET)
			panic("_bus_dmamem_mmap: segment size not multiple"
			    " of page size");
#endif
		if (off >= segs[i].ds_len) {
			off -= segs[i].ds_len;
			continue;
		}

		return ((segs[i].ds_addr + off) | pmapflags);
	}

	/* Page not found. */
	return (-1);
}

/**********************************************************************
 * DMA utility functions
 **********************************************************************/

/*
 * Allocate physical memory from the given physical address range.
 * Called by DMA-safe memory allocation methods.
 */
int
_dmamem_alloc_range(bus_dma_tag_t t, bus_size_t size, bus_size_t alignment,
    bus_size_t boundary, bus_dma_segment_t *segs, int nsegs, int *rsegs,
    int flags, vaddr_t low, vaddr_t high)
{
	vaddr_t curaddr, lastaddr;
	struct vm_page *m;
	struct pglist mlist;
	int curseg, error, plaflag;

	/* Always round the size. */
	size = round_page(size);

	/*
	 * Allocate pages from the VM system.
	 */
	plaflag = flags & BUS_DMA_NOWAIT ? UVM_PLA_NOWAIT : UVM_PLA_WAITOK;
	if (flags & BUS_DMA_ZERO)
		plaflag |= UVM_PLA_ZERO;

	TAILQ_INIT(&mlist);
	error = uvm_pglistalloc(size, low, high,
	    alignment, boundary, &mlist, nsegs, plaflag);
	if (error)
		return (error);

	/*
	 * Compute the location, size, and number of segments actually
	 * returned by the VM code.
	 */
	m = TAILQ_FIRST(&mlist);
	curseg = 0;
	lastaddr = segs[curseg].ds_addr = VM_PAGE_TO_PHYS(m);
	segs[curseg].ds_len = PAGE_SIZE;
	m = TAILQ_NEXT(m, pageq);

	for (; m != NULL; m = TAILQ_NEXT(m, pageq)) {
		curaddr = VM_PAGE_TO_PHYS(m);
#ifdef DIAGNOSTIC
		if (curaddr < low || curaddr >= high) {
			printf("vm_page_alloc_memory returned non-sensical"
			    " address 0x%lx\n", curaddr);
			panic("dmamem_alloc_range");
		}
#endif
		if (curaddr == (lastaddr + PAGE_SIZE))
			segs[curseg].ds_len += PAGE_SIZE;
		else {
			curseg++;
			segs[curseg].ds_addr = curaddr;
			segs[curseg].ds_len = PAGE_SIZE;
		}
		lastaddr = curaddr;
	}

	*rsegs = curseg + 1;

	return (0);
}
@


1.41
log
@Replace a plethora of historical protection options with just
PROT_NONE, PROT_READ, PROT_WRITE, and PROT_EXEC from mman.h.
PROT_MASK is introduced as the one true way of extracting those bits.
Remove UVM_ADV_* wrapper, using the standard names.
ok doug guenther kettenis
@
text
@d1 1
a1 1
/*	$OpenBSD: dma.c,v 1.40 2014/07/12 18:44:42 tedu Exp $	*/
@


1.40
log
@add a size argument to free. will be used soon, but for now default to 0.
after discussions with beck deraadt kettenis.
@
text
@d1 1
a1 1
/*	$OpenBSD: dma.c,v 1.39 2014/07/11 09:36:26 mpi Exp $	*/
d488 2
a489 2
			    VM_PROT_READ | VM_PROT_WRITE, VM_PROT_READ |
			    VM_PROT_WRITE | PMAP_WIRED | PMAP_CANFAIL);
@


1.39
log
@Convert bus_dmamem_map(9) to km_alloc(9) in order to make it fail and
not sleep if the allocator cannot obtain a lock when BUS_DMA_NOWAIT is
specified.

idea and inputs from kettenis@@, ok miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: dma.c,v 1.38 2014/03/31 18:58:41 mpi Exp $	*/
d106 1
a106 1
	free(map, M_DEVBUF);
@


1.38
log
@Including <uvm/uvm_extern.h> is enough, no need for <uvm/uvm.h> or more.
@
text
@d1 1
a1 1
/*	$OpenBSD: dma.c,v 1.37 2012/12/04 10:14:25 mpi Exp $	*/
d466 1
d472 2
a473 1
	va = uvm_km_valloc(kernel_map, size);
d492 1
a492 1
				uvm_km_free(kernel_map, sva, ssize);
d515 1
a515 2
	size = round_page(size);
	uvm_km_free(kernel_map, (vaddr_t)kva, size);
@


1.37
log
@Make bus_dmamem_mmap(9) understand the BUS_DMA_NOCACHE flag, required for
upcoming agp changes.

ok kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: dma.c,v 1.36 2012/08/30 18:14:26 mpi Exp $	*/
d46 1
a46 2
#include <uvm/uvm.h>
#include <uvm/uvm_page.h>
d49 1
@


1.36
log
@Add the possibility to map DMA memory non-cached, based on the i386/amd64
implementation. For the moment only the BUS_DMA_NOCACHE macro is required
to build drm on macppc but it will be used soon.

ok kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: dma.c,v 1.35 2011/06/23 20:44:39 ariane Exp $	*/
d525 4
a528 1
	int i;
d545 1
a545 1
		return (segs[i].ds_addr + off);
@


1.35
log
@Fix the error path in bus_dmamem_map.
As discussed on icb: remove the comment,
remove pmap_remove (uvm_km_free does that for us).

ok oga@@, deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: dma.c,v 1.34 2010/12/26 15:40:59 miod Exp $	*/
d465 4
a468 1
	int curseg, error;
d485 1
a485 1
			error = pmap_enter(pmap_kernel(), va, addr,
@


1.34
log
@Kill pmap_phys_address(), and force every driver's mmap() routine to return
a physical address [more precisely, something suitable to pass to pmap_enter()'sphysical address argument].

This allows MI drivers to implement mmap() routines without having to know
about the pmap_phys_address() implementation and #ifdef obfuscation.
@
text
@d1 1
a1 1
/*	$OpenBSD: dma.c,v 1.33 2010/06/26 23:24:43 guenther Exp $	*/
a485 4
				/*
				 * Clean up after ourselves.
				 * XXX uvm_wait on WAITOK
				 */
d487 1
a487 1
				uvm_km_free(kernel_map, va, ssize);
@


1.33
log
@Don't #include <sys/user.h> into files that don't need the stuff
it defines.  In some cases, this means pulling in uvm.h or pcb.h
instead, but most of the inclusions were just noise.  Tested on
alpha, amd64, armish, hppa, i386, macpcc, sgi, sparc64, and vax,
mostly by krw and naddy.
ok krw@@
@
text
@d1 1
a1 1
/*	$OpenBSD: dma.c,v 1.32 2010/03/29 19:21:58 oga Exp $	*/
d543 1
a543 1
		return (atop(segs[i].ds_addr + off));
@


1.32
log
@PMAP_CANFAIL for bus_dmamem_map on all other architectures (and some
whitespace tweaks on i386 so that it matches).

ok kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: dma.c,v 1.31 2009/04/20 00:42:06 oga Exp $	*/
a35 1
#include <sys/user.h>
@


1.31
log
@Add a BUS_DMA_ZERO flag for bus_dmamem_alloc() to return zeroed memory.

Saves every damned driver calling bzero(), and continues the M_ZERO,
PR_ZERO symmetry.
@
text
@d1 1
a1 1
/*	$OpenBSD: dma.c,v 1.30 2009/04/14 16:01:04 oga Exp $	*/
d463 2
a464 1
	vaddr_t va;
d466 1
a466 1
	int curseg;
d475 2
d483 12
a494 3
			pmap_enter(pmap_kernel(), va, addr,
			    VM_PROT_READ | VM_PROT_WRITE,
			    VM_PROT_READ | VM_PROT_WRITE | PMAP_WIRED);
@


1.30
log
@Convert the waitok field of uvm_pglistalloc to "flags", more will be added soon.

For the possibility of sleeping, the first two flags are UVM_PLA_WAITOK
and UVM_PLA_NOWAIT. It is an error not to show intention, so assert that
one of the two is provided. Switch over every caller in the tree to
using the appropriate flag.

ok art@@, ariane@@
@
text
@d1 1
a1 1
/*	$OpenBSD: dma.c,v 1.29 2009/03/07 15:34:34 miod Exp $	*/
d564 2
@


1.29
log
@When allocating memory in bus_dmamem_alloc() with uvm_pglistalloc(), do not
try to be smart for the address range, uvm_pglistalloc() is smart enough
nowadays.
@
text
@d1 1
a1 1
/*	$OpenBSD: dma.c,v 1.28 2008/06/26 05:42:12 ray Exp $	*/
d555 1
a555 1
	int curseg, error;
d563 2
d567 1
a567 1
	    alignment, boundary, &mlist, nsegs, (flags & BUS_DMA_NOWAIT) == 0);
@


1.28
log
@First pass at removing clauses 3 and 4 from NetBSD licenses.

Not sure what's more surprising: how long it took for NetBSD to
catch up to the rest of the BSDs (including UCB), or the amount of
code that NetBSD has claimed for itself without attributing to the
actual authors.

OK deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: dma.c,v 1.27 2007/10/02 00:59:12 krw Exp $	*/
d424 1
a424 1
	    segs, nsegs, rsegs, flags, 0, 0xf0000000));
@


1.27
log
@Apply (with slight variants) this elimination of bzero() with M_ZERO:

-	if ((mapstore = malloc(mapsize, M_DEVBUF,
-	    (flags & BUS_DMA_NOWAIT) ? M_NOWAIT : M_WAITOK)) == NULL)
+	if ((mapstore = malloc(mapsize, M_DEVBUF, (flags & BUS_DMA_NOWAIT) ?
+	    (M_NOWAIT | M_ZERO) : (M_WAITOK | M_ZERO))) == NULL)
 		return (ENOMEM);

-	bzero(mapstore, mapsize);
@
text
@d1 1
a1 1
/*	$OpenBSD: dma.c,v 1.26 2007/09/03 01:09:09 krw Exp $	*/
a19 7
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *	This product includes software developed by the NetBSD
 *	Foundation, Inc. and its contributors.
 * 4. Neither the name of The NetBSD Foundation nor the names of its
 *    contributors may be used to endorse or promote products derived
 *    from this software without specific prior written permission.
@


1.26
log
@Typos from miod. 'functin' -> 'functin' in some comments.
@
text
@d1 1
a1 1
/*	$OpenBSD: dma.c,v 1.25 2007/05/27 15:46:02 drahn Exp $	*/
d89 2
a90 2
	if ((mapstore = malloc(mapsize, M_DEVBUF,
	    (flags & BUS_DMA_NOWAIT) ? M_NOWAIT : M_WAITOK)) == NULL)
a92 1
	bzero(mapstore, mapsize);
@


1.25
log
@Move powerpc to vm_page_md, 'throw it in' kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: dma.c,v 1.24 2005/12/17 07:31:26 miod Exp $	*/
d516 1
a516 1
 * Common functin for mmap(2)'ing DMA-safe memory.  May be called by
@


1.24
log
@Get rid of deprecated vm_{offset,size}_t types for good, use {p,v}{addr,size}_t
instead; looked at millert@@
@
text
@d1 1
a1 1
/*	$OpenBSD: dma.c,v 1.23 2005/10/26 18:57:51 martin Exp $	*/
d390 16
d407 13
a419 1
	/* Nothing to do here. */
@


1.23
log
@Mach-macro wipeout

'do it' deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: dma.c,v 1.22 2004/11/09 19:17:01 claudio Exp $	*/
d60 1
a60 1
    int nsegs, int *rsegs, int flags, vm_offset_t low, vm_offset_t high);
d443 1
a443 1
	vm_offset_t va;
d484 1
a484 1
	uvm_km_free(kernel_map, (vm_offset_t)kva, size);
d530 1
a530 1
    int flags, vm_offset_t low, vm_offset_t high)
d532 1
a532 1
	vm_offset_t curaddr, lastaddr;
@


1.22
log
@Do not map empty mbufs (m_len == 0) in bus_dmamap_load_mbuf() as these mappings
may disturb the dma as seen in ipw(4). Emtpy mbufs are at the beginning of the
mbuf chain and are as example a "side-effect" of a previous m_adj() call.
OK miod@@ mickey@@ jason@@ markus@@
@
text
@d1 1
a1 1
/*	$OpenBSD: dma.c,v 1.21 2003/12/20 22:40:27 miod Exp $	*/
d512 1
a512 1
		return (powerpc_btop((caddr_t)segs[i].ds_addr + off));
@


1.21
log
@Pass -Wformat
@
text
@d1 1
a1 1
/*	$OpenBSD: dma.c,v 1.20 2003/10/15 17:50:16 drahn Exp $	*/
d263 2
@


1.20
log
@The ANSI/KNF trail continues. No binary differences.
@
text
@d1 1
a1 1
/*	$OpenBSD: dma.c,v 1.19 2003/06/02 18:14:16 jason Exp $	*/
d143 1
a143 1
			panic("dmamap_load_buffer pmap %x vaddr %x "
@


1.19
log
@add length checks on bus_dmamap_load_uio() on the total length vs. what the
map is expecting.  Also, sparc64 was missing the equivalent check in
_load_mbuf() and the "make sure no valid mappings are returned" goop.
@
text
@d1 1
a1 1
/*	$OpenBSD: dma.c,v 1.18 2002/12/10 23:41:37 miod Exp $	*/
d59 4
a62 3
	bus_size_t alignment, bus_size_t boundary, bus_dma_segment_t *segs,
	int nsegs, int *rsegs, int flags, vm_offset_t low, vm_offset_t high);

d68 2
a69 8
_dmamap_create(t, size, nsegments, maxsegsz, boundary, flags, dmamp)
	bus_dma_tag_t t;
	bus_size_t size;
	int nsegments;
	bus_size_t maxsegsz;
	bus_size_t boundary;
	int flags;
	bus_dmamap_t *dmamp;
d112 1
a112 3
_dmamap_destroy(t, map)
	bus_dma_tag_t t;
	bus_dmamap_t map;
a117 2
int _dmamap_load_buffer(bus_dma_tag_t, bus_dmamap_t, void *, bus_size_t,
    struct proc *, int, bus_addr_t *, int *, int);
d120 3
a122 10
_dmamap_load_buffer(t, map, buf, buflen, p, flags, lastaddrp, segp, first)
	bus_dma_tag_t t;
	bus_dmamap_t map;
	void *buf;
	bus_size_t buflen;
	struct proc *p;
	int flags;
	bus_addr_t *lastaddrp;
	int *segp;
	int first;
d209 2
a210 7
_dmamap_load(t, map, buf, buflen, p, flags)
	bus_dma_tag_t t;
	bus_dmamap_t map;
	void *buf;
	bus_size_t buflen;
	struct proc *p;
	int flags;
d238 2
a239 5
_dmamap_load_mbuf(t, map, m0, flags)
	bus_dma_tag_t t;
	bus_dmamap_t map;
	struct mbuf *m0;
	int flags;
d278 1
a278 5
_dmamap_load_uio(t, map, uio, flags)
	bus_dma_tag_t t;
	bus_dmamap_t map;
	struct uio *uio;
	int flags;
d336 2
a337 7
_dmamap_load_raw(t, map, segs, nsegs, size, flags)
	bus_dma_tag_t t;
	bus_dmamap_t map;
	bus_dma_segment_t *segs;
	int nsegs;
	bus_size_t size;
	int flags;
d369 1
a369 3
_dmamap_unload(t, map)
	bus_dma_tag_t t;
	bus_dmamap_t map;
d385 2
a386 6
_dmamap_sync(t, map, offset, len, op)
	bus_dma_tag_t t;
	bus_dmamap_t map;
	bus_addr_t offset;
	bus_size_t len;
	int op;
d397 3
a399 7
_dmamem_alloc(t, size, alignment, boundary, segs, nsegs, rsegs, flags)
	bus_dma_tag_t t;
	bus_size_t size, alignment, boundary;
	bus_dma_segment_t *segs;
	int nsegs;
	int *rsegs;
	int flags;
d410 1
a410 4
_dmamem_free(t, segs, nsegs)
	bus_dma_tag_t t;
	bus_dma_segment_t *segs;
	int nsegs;
d438 2
a439 7
_dmamem_map(t, segs, nsegs, size, kvap, flags)
	bus_dma_tag_t t;
	bus_dma_segment_t *segs;
	int nsegs;
	size_t size;
	caddr_t *kvap;
	int flags;
d473 1
a473 4
_dmamem_unmap(t, kva, size)
	bus_dma_tag_t t;
	caddr_t kva;
	size_t size;
d490 2
a491 6
_dmamem_mmap(t, segs, nsegs, off, prot, flags)
	bus_dma_tag_t t;
	bus_dma_segment_t *segs;
	int nsegs;
	off_t off;
	int prot, flags;
d526 3
a528 10
_dmamem_alloc_range(t, size, alignment, boundary, segs, nsegs, rsegs,
    flags, low, high)
	bus_dma_tag_t t;
	bus_size_t size, alignment, boundary;
	bus_dma_segment_t *segs;
	int nsegs;
	int *rsegs;
	int flags;
	vm_offset_t low;
	vm_offset_t high;
@


1.18
log
@Use bus_addr_t rather than paddr_t when it makes sense, and use TAILQ macros
as well.
@
text
@d1 1
a1 1
/*	$OpenBSD: dma.c,v 1.17 2002/10/07 18:35:56 mickey Exp $	*/
d323 3
@


1.17
log
@this removes the functionality of adding allocated
pages into the queue already containing allocated pages.
breaks i386:setup_buffers() because of this.
@
text
@d1 1
a1 1
/*	$OpenBSD: dma.c,v 1.16 2002/10/06 22:06:15 art Exp $	*/
d126 1
a126 1
    struct proc *, int, paddr_t *, int *, int);
d136 1
a136 1
	paddr_t *lastaddrp;
d233 1
a233 1
	paddr_t lastaddr;
d265 1
a265 1
	paddr_t lastaddr;
d308 1
a308 1
	paddr_t lastaddr;
d613 1
a613 1
	m = mlist.tqh_first;
d617 1
a617 1
	m = m->pageq.tqe_next;
d619 1
a619 1
	for (; m != NULL; m = m->pageq.tqe_next) {
@


1.16
log
@No more need to initialize the result list before uvm_pglistalloc.
@
text
@d1 1
a1 1
/*	$OpenBSD: dma.c,v 1.15 2002/09/15 09:01:58 deraadt Exp $	*/
d603 1
@


1.15
log
@backout premature
@
text
@d1 1
a1 1
/*	$OpenBSD: dma.c,v 1.13 2002/03/14 01:26:36 millert Exp $	*/
a602 1
	TAILQ_INIT(&mlist);
@


1.14
log
@KNF
@
text
@d190 1
a190 1
			    map->_dm_maxsegsz &&
d192 2
a193 2
			    (map->dm_segs[seg].ds_addr & bmask) ==
			    (curaddr & bmask)))
@


1.13
log
@First round of __P removal in sys
@
text
@d1 1
a1 1
/*	$OpenBSD: dma.c,v 1.12 2002/02/18 14:26:24 drahn Exp $	*/
d190 1
a190 1
			     map->_dm_maxsegsz &&
d192 2
a193 2
			     (map->dm_segs[seg].ds_addr & bmask) ==
			     (curaddr & bmask)))
@


1.12
log
@change the dma memory allocation to use kernel_map, not kmem_map.
suggestion by art.
@
text
@d1 1
a1 1
/*	$OpenBSD: dma.c,v 1.11 2002/01/03 07:14:50 drahn Exp $	*/
d125 2
a126 2
int _dmamap_load_buffer __P((bus_dma_tag_t, bus_dmamap_t, void *, bus_size_t,
    struct proc *, int, paddr_t *, int *, int));
@


1.11
log
@If the dma decides to perform I/O on memory that is not mapped, panic
immediately instead of writing on random memory addresses.
Could the mapping be faulted in, no?
@
text
@d1 1
a1 1
/*	$OpenBSD: dma.c,v 1.10 2001/12/31 17:03:59 miod Exp $	*/
d494 1
a494 1
	va = uvm_km_valloc(kmem_map, size);
d533 1
a533 1
	uvm_km_free(kmem_map, (vm_offset_t)kva, size);
@


1.10
log
@Fix a glitch in _dmamap_load_buffer introduced in the last commit.
jason@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: dma.c,v 1.9 2001/12/12 19:18:23 jason Exp $	*/
d158 4
a161 1
		(void) pmap_extract(pmap, vaddr, (paddr_t *)&curaddr);
@


1.9
log
@Full suite of bus_dma functions (except bus_dmamap_load_raw)... this allows
the crypto layer and drivers using bus_dmamap_load_mbuf() to work (tested
with hifn and dc); Mostly from NetBSD
@
text
@d1 1
a1 1
/*	$OpenBSD: dma.c,v 1.8 2001/12/08 02:24:06 art Exp $	*/
d143 1
d149 5
d158 1
a158 5
		if (p != NULL)
			(void) pmap_extract(p->p_vmspace->vm_map.pmap,
			    vaddr, (paddr_t *)&curaddr);
		else
			curaddr = vtophys(vaddr);
@


1.9.2.1
log
@Merge in -current, builds on i386, otherwise untested
@
text
@d1 1
a1 1
/*	$OpenBSD: dma.c,v 1.11 2002/01/03 07:14:50 drahn Exp $	*/
a142 1
	pmap_t pmap;
a147 5
	if (p != NULL)
		pmap = p->p_vmspace->vm_map.pmap;
	else
		pmap = pmap_kernel();

d152 5
a156 4
		if (pmap_extract(pmap, vaddr, (paddr_t *)&curaddr) != TRUE) {
			panic("dmamap_load_buffer pmap %x vaddr %x "
				"pmap_extract failed", pmap, vaddr);
		}
@


1.9.2.2
log
@Merge in UBC performance changes from NetBSD.
Fix a bunch of merge errors from yesterday.
@
text
@d1 1
a1 1
/*	$OpenBSD: dma.c,v 1.9.2.1 2002/01/31 22:55:14 niklas Exp $	*/
d494 1
a494 1
	va = uvm_km_valloc(kernel_map, size);
d533 1
a533 1
	uvm_km_free(kernel_map, (vm_offset_t)kva, size);
@


1.9.2.3
log
@Sync UBC branch to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: dma.c,v 1.9.2.2 2002/02/02 03:28:25 art Exp $	*/
d125 2
a126 2
int _dmamap_load_buffer(bus_dma_tag_t, bus_dmamap_t, void *, bus_size_t,
    struct proc *, int, paddr_t *, int *, int);
@


1.9.2.4
log
@sync to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: dma.c,v 1.9.2.3 2002/06/11 03:36:34 art Exp $	*/
@


1.9.2.5
log
@sync
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d126 1
a126 1
    struct proc *, int, bus_addr_t *, int *, int);
d136 1
a136 1
	bus_addr_t *lastaddrp;
d233 1
a233 1
	bus_addr_t lastaddr;
d265 1
a265 1
	bus_addr_t lastaddr;
d308 1
a308 1
	bus_addr_t lastaddr;
d613 1
a613 1
	m = TAILQ_FIRST(&mlist);
d617 1
a617 1
	m = TAILQ_NEXT(m, pageq);
d619 1
a619 1
	for (; m != NULL; m = TAILQ_NEXT(m, pageq)) {
@


1.8
log
@Sprinkle pmap_update calls where relevant and some other
misc pmap usage fixes.
@
text
@d1 1
a1 1
/*	$OpenBSD: dma.c,v 1.7 2001/11/28 16:24:26 art Exp $	*/
d125 3
a127 4
/*
 * Common function for loading a DMA map with a linear buffer.  May
 * be called by bus-specific DMA map load functions.
 */
d129 1
a129 1
_dmamap_load(t, map, buf, buflen, p, flags)
d136 3
d142 2
a143 10
	caddr_t vaddr = buf;
	int first, seg;
	pmap_t pmap;
	bus_size_t saved_buflen;

	/*
	 * Make sure that on error condition we return "no valid mappings".
	 */
	map->dm_nsegs = 0;
	map->dm_mapsize = 0;
d145 2
a146 2
	if (buflen > map->_dm_size)
		return (EINVAL);
d148 1
a148 10
	if (p != NULL)
		pmap = p->p_vmspace->vm_map.pmap;
	else
		pmap = pmap_kernel();

	lastaddr = ~0;		/* XXX gcc */
	bmask  = ~(map->_dm_boundary - 1);

	saved_buflen = buflen;
	for (first = 1, seg = 0; buflen > 0; ) {
d152 5
a156 1
		pmap_extract(pmap, (vm_offset_t)vaddr, (paddr_t *)&curaddr);
d175 1
a175 1
		 * Insert chunk into a segment, coalescing with
d186 1
a186 1
			     (map->_dm_boundary == 0 ||
d203 3
d210 1
a210 1
		return (EFBIG);		/* XXX better return value here? */
a211 2
	map->dm_nsegs = seg + 1;
	map->dm_mapsize = saved_buflen;
d216 35
d254 1
a254 1
_dmamap_load_mbuf(t, map, m, flags)
d257 1
a257 1
	struct mbuf *m;
d260 17
d278 13
a290 1
	panic("_bus_dmamap_load: not implemented");
d303 46
a348 2
	/* XXX Need a real implementation. */
	return (EOPNOTSUPP);
@


1.7
log
@more typedef zapping vm_page_t -> struct vm_page *
@
text
@d1 1
a1 1
/*	$OpenBSD: dma.c,v 1.6 2001/11/16 20:46:16 jason Exp $	*/
d408 1
@


1.6
log
@_load_uio returns an error now until a real implementation is in place.
@
text
@d1 1
a1 1
/*	$OpenBSD: dma.c,v 1.5 2001/11/06 19:53:15 miod Exp $	*/
d352 1
a352 1
	vm_page_t m;
d489 1
a489 1
	vm_page_t m;
@


1.5
log
@Replace inclusion of <vm/foo.h> with the correct <uvm/bar.h> when necessary.
(Look ma, I might have broken the tree)
@
text
@d1 1
a1 1
/*	$OpenBSD: dma.c,v 1.4 2001/11/05 17:25:58 art Exp $	*/
d249 2
a250 2

	panic("_bus_dmamap_load_uio: not implemented");
@


1.4
log
@Switch everything to the new bus_dmamap_sync API.
Most work by Wilbern Cobb <vedge@@csoft.org> with some fixes from me, mickey@@
and drahn@@.
@
text
@d1 1
a1 1
/*	$OpenBSD: dma.c,v 1.3 2001/09/19 20:50:57 mickey Exp $	*/
a53 1
#include <vm/vm.h>
@


1.3
log
@merge vm/vm_kern.h into uvm/uvm_extern.h; art@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: dma.c,v 1.2 2001/09/15 01:40:36 mickey Exp $	*/
d107 1
d144 1
d150 1
d163 1
d222 1
d288 1
d307 1
d315 1
a315 1
_dmamap_sync(t, map, op)
d318 3
a320 1
	bus_dmasync_op_t op;
@


1.3.4.1
log
@Sync the SMP branch to something just after 3.0
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
@


1.3.4.2
log
@Merge in -current
@
text
@d54 1
a106 1
	map->dm_mapsize = 0;
a142 1
	bus_size_t saved_buflen;
a147 1
	map->dm_mapsize = 0;
a159 1
	saved_buflen = buflen;
a217 1
	map->dm_mapsize = saved_buflen;
a282 1
	map->dm_mapsize = size;
a300 1
	map->dm_mapsize = 0;
d308 1
a308 1
_dmamap_sync(t, map, offset, len, op)
d311 1
a311 3
	bus_addr_t offset;
	bus_size_t len;
	int op;
@


1.3.4.3
log
@Merge in -current
@
text
@d1 1
a1 1
/*	$OpenBSD: dma.c,v 1.3.4.2 2001/11/13 21:00:53 niklas Exp $	*/
d249 2
a250 2
	/* XXX Need a real implementation. */
	return (EOPNOTSUPP);
d352 1
a352 1
	struct vm_page *m;
d489 1
a489 1
	struct vm_page *m;
@


1.3.4.4
log
@Merge in trunk
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d125 4
a128 3
int _dmamap_load_buffer __P((bus_dma_tag_t, bus_dmamap_t, void *, bus_size_t,
    struct proc *, int, paddr_t *, int *, int));

d130 1
a130 1
_dmamap_load_buffer(t, map, buf, buflen, p, flags, lastaddrp, segp, first)
a136 3
	paddr_t *lastaddrp;
	int *segp;
	int first;
d140 2
a141 1
	vaddr_t vaddr = (vaddr_t)buf;
d143 1
a143 1
	int seg;
d145 8
a152 2
	lastaddr = *lastaddrp;
	bmask = ~(map->_dm_boundary - 1);
d159 5
a163 1
	for (seg = *segp; buflen > 0; ) {
d167 1
a167 4
		if (pmap_extract(pmap, vaddr, (paddr_t *)&curaddr) != TRUE) {
			panic("dmamap_load_buffer pmap %x vaddr %x "
				"pmap_extract failed", pmap, vaddr);
		}
d186 1
a186 1
		 * Insert chunk into a segment, coalescing with the
d197 1
a197 1
			    (map->_dm_boundary == 0 ||
a213 3
	*segp = seg;
	*lastaddrp = lastaddr;

d218 1
a218 1
		return (EFBIG);		/* XX better return value here? */
d220 2
a225 35
 * Common function for loading a DMA map with a linear buffer.  May
 * be called by bus-specific DMA map load functions.
 */
int
_dmamap_load(t, map, buf, buflen, p, flags)
	bus_dma_tag_t t;
	bus_dmamap_t map;
	void *buf;
	bus_size_t buflen;
	struct proc *p;
	int flags;
{
	paddr_t lastaddr;
	int seg, error;

	/*
	 * Make sure that on error condition we return "no valid mappings".
	 */
	map->dm_mapsize = 0;
	map->dm_nsegs = 0;

	if (buflen > map->_dm_size)
		return (EINVAL);

	seg = 0;
	error = _dmamap_load_buffer(t, map, buf, buflen, p, flags,
	    &lastaddr, &seg, 1);
	if (error == 0) {
		map->dm_mapsize = buflen;
		map->dm_nsegs = seg + 1;
	}
	return (error);
}

/*
d229 1
a229 1
_dmamap_load_mbuf(t, map, m0, flags)
d232 1
a232 1
	struct mbuf *m0;
a234 3
	paddr_t lastaddr;
	int seg, error, first;
	struct mbuf *m;
d236 1
a236 27
	/*
	 * Make sure that on error condition we return "no valid mappings".
	 */
	map->dm_mapsize = 0;
	map->dm_nsegs = 0;

#ifdef DIAGNOSTIC
	if ((m0->m_flags & M_PKTHDR) == 0)
		panic("_bus_dmamap_load_mbuf: no packet header");
#endif

	if (m0->m_pkthdr.len > map->_dm_size)
		return (EINVAL);

	first = 1;
	seg = 0;
	error = 0;
	for (m = m0; m != NULL && error == 0; m = m->m_next) {
		error = _dmamap_load_buffer(t, map, m->m_data, m->m_len,
		    NULL, flags, &lastaddr, &seg, first);
		first = 0;
	}
	if (error == 0) {
		map->dm_mapsize = m0->m_pkthdr.len;
		map->dm_nsegs = seg + 1;
	}
	return (error);
d249 2
a250 46
	paddr_t lastaddr;
	int seg, i, error, first;
	bus_size_t minlen, resid;
	struct proc *p = NULL;
	struct iovec *iov;
	caddr_t addr;

	/*
	 * Make sure that on error condition we return "no valid mappings".
	 */
	map->dm_mapsize = 0;
	map->dm_nsegs = 0;

	resid = uio->uio_resid;
	iov = uio->uio_iov;

	if (uio->uio_segflg == UIO_USERSPACE) {
		p = uio->uio_procp;
#ifdef DIAGNOSTIC
		if (p == NULL)
			panic("_bus_dmamap_load_uio: USERSPACE but no proc");
#endif
	}

	first = 1;
	seg = 0;
	error = 0;
	for (i = 0; i < uio->uio_iovcnt && resid != 0 && error == 0; i++) {
		/*
		 * Now at the first iovec to load.  Load each iovec
		 * until we have exhausted the residual count.
		 */
		minlen = resid < iov[i].iov_len ? resid : iov[i].iov_len;
		addr = (caddr_t)iov[i].iov_base;

		error = _dmamap_load_buffer(t, map, addr, minlen,
		    p, flags, &lastaddr, &seg, first);
		first = 0;

		resid -= minlen;
	}
	if (error == 0) {
		map->dm_mapsize = uio->uio_resid;
		map->dm_nsegs = seg + 1;
	}
	return (error);
d391 1
a391 1
	va = uvm_km_valloc(kernel_map, size);
a407 1
	pmap_update(pmap_kernel());
d429 1
a429 1
	uvm_km_free(kernel_map, (vm_offset_t)kva, size);
@


1.3.4.5
log
@Merge in -current from about a week ago
@
text
@d125 2
a126 2
int _dmamap_load_buffer(bus_dma_tag_t, bus_dmamap_t, void *, bus_size_t,
    struct proc *, int, paddr_t *, int *, int);
@


1.3.4.6
log
@Sync the SMP branch with 3.3
@
text
@d126 1
a126 1
    struct proc *, int, bus_addr_t *, int *, int);
d136 1
a136 1
	bus_addr_t *lastaddrp;
d233 1
a233 1
	bus_addr_t lastaddr;
d265 1
a265 1
	bus_addr_t lastaddr;
d308 1
a308 1
	bus_addr_t lastaddr;
d613 1
a613 1
	m = TAILQ_FIRST(&mlist);
d617 1
a617 1
	m = TAILQ_NEXT(m, pageq);
d619 1
a619 1
	for (; m != NULL; m = TAILQ_NEXT(m, pageq)) {
@


1.3.4.7
log
@Sync SMP branch to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: dma.c,v 1.3.4.6 2003/03/27 23:29:46 niklas Exp $	*/
a322 3

	if (resid > map->_dm_size)
		return (EINVAL);
@


1.3.4.8
log
@Merge of current from two weeks agointo the SMP branch
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d59 3
a61 4
    bus_size_t alignment, bus_size_t boundary, bus_dma_segment_t *segs,
    int nsegs, int *rsegs, int flags, vm_offset_t low, vm_offset_t high);
int _dmamap_load_buffer(bus_dma_tag_t, bus_dmamap_t, void *, bus_size_t,
    struct proc *, int, bus_addr_t *, int *, int);
d67 8
a74 2
_dmamap_create(bus_dma_tag_t t, bus_size_t size, int nsegments,
    bus_size_t maxsegsz, bus_size_t boundary, int flags, bus_dmamap_t *dmamp)
d117 3
a119 1
_dmamap_destroy(bus_dma_tag_t t, bus_dmamap_t map)
d125 2
d129 10
a138 3
_dmamap_load_buffer(bus_dma_tag_t t, bus_dmamap_t map, void *buf,
    bus_size_t buflen, struct proc *p, int flags, bus_addr_t *lastaddrp,
    int *segp, int first)
d159 1
a159 1
			panic("dmamap_load_buffer pmap %p vaddr %lx "
d225 7
a231 2
_dmamap_load(bus_dma_tag_t t, bus_dmamap_t map, void *buf, bus_size_t buflen,
    struct proc *p, int flags)
d259 5
a263 2
_dmamap_load_mbuf(bus_dma_tag_t t, bus_dmamap_t map, struct mbuf *m0,
    int flags)
d302 5
a306 1
_dmamap_load_uio(bus_dma_tag_t t, bus_dmamap_t map, struct uio *uio, int flags)
d364 7
a370 2
_dmamap_load_raw(bus_dma_tag_t t, bus_dmamap_t map, bus_dma_segment_t *segs,
    int nsegs, bus_size_t size, int flags)
d402 3
a404 1
_dmamap_unload(bus_dma_tag_t t, bus_dmamap_t map)
d420 6
a425 2
_dmamap_sync(bus_dma_tag_t t, bus_dmamap_t map, bus_addr_t offset,
bus_size_t len, int op)
d436 7
a442 3
_dmamem_alloc(bus_dma_tag_t t, bus_size_t size, bus_size_t alignment,
    bus_size_t boundary, bus_dma_segment_t *segs, int nsegs, int *rsegs,
    int flags)
d453 4
a456 1
_dmamem_free(bus_dma_tag_t t, bus_dma_segment_t *segs, int nsegs)
d484 7
a490 2
_dmamem_map(bus_dma_tag_t t, bus_dma_segment_t *segs, int nsegs, size_t size,
    caddr_t *kvap, int flags)
d524 4
a527 1
_dmamem_unmap(bus_dma_tag_t t, caddr_t kva, size_t size)
d544 6
a549 2
_dmamem_mmap(bus_dma_tag_t t, bus_dma_segment_t *segs, int nsegs, off_t off,
    int prot, int flags)
d584 10
a593 3
_dmamem_alloc_range(bus_dma_tag_t t, bus_size_t size, bus_size_t alignment,
    bus_size_t boundary, bus_dma_segment_t *segs, int nsegs, int *rsegs,
    int flags, vm_offset_t low, vm_offset_t high)
@


1.2
log
@implement _bus_dmamap_load_raw; drahn@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: dma.c,v 1.1 2001/09/01 15:44:20 drahn Exp $	*/
a54 1
#include <vm/vm_kern.h>
@


1.1
log
@The "powerpc" port which has supported the newer Apple Macintosh powerpc based
is being renamed to macppc. This is to allow sharing of common code
between different powerpc base platforms.

Most of the work involved in the renaming process was performed by miod@@

Files moved from powerpc/powerpc to macppc/macppc

This moves hardware specific files from the common directory to the
platform specific directory. This leaves common files.
With this change all of the debugger (db_) files have been moved to
the platform specific directory. The debugger should be reconsidered
and commonized.
@
text
@d1 1
a1 1
/*	$OpenBSD: dma.c,v 1.10 2001/08/18 21:59:48 drahn Exp $	*/
d263 2
d266 19
a284 1
	panic("_bus_dmamap_load_raw: not implemented");
@

