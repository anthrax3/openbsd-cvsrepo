head	1.25;
access;
symbols
	OPENBSD_5_5:1.24.0.18
	OPENBSD_5_5_BASE:1.24
	OPENBSD_5_4:1.24.0.14
	OPENBSD_5_4_BASE:1.24
	OPENBSD_5_3:1.24.0.12
	OPENBSD_5_3_BASE:1.24
	OPENBSD_5_2:1.24.0.10
	OPENBSD_5_2_BASE:1.24
	OPENBSD_5_1_BASE:1.24
	OPENBSD_5_1:1.24.0.8
	OPENBSD_5_0:1.24.0.6
	OPENBSD_5_0_BASE:1.24
	OPENBSD_4_9:1.24.0.4
	OPENBSD_4_9_BASE:1.24
	OPENBSD_4_8:1.24.0.2
	OPENBSD_4_8_BASE:1.24
	OPENBSD_4_7:1.23.0.8
	OPENBSD_4_7_BASE:1.23
	OPENBSD_4_6:1.23.0.10
	OPENBSD_4_6_BASE:1.23
	OPENBSD_4_5:1.23.0.6
	OPENBSD_4_5_BASE:1.23
	OPENBSD_4_4:1.23.0.4
	OPENBSD_4_4_BASE:1.23
	OPENBSD_4_3:1.23.0.2
	OPENBSD_4_3_BASE:1.23
	OPENBSD_4_2:1.22.0.6
	OPENBSD_4_2_BASE:1.22
	OPENBSD_4_1:1.22.0.4
	OPENBSD_4_1_BASE:1.22
	OPENBSD_4_0:1.22.0.2
	OPENBSD_4_0_BASE:1.22
	OPENBSD_3_9:1.21.0.2
	OPENBSD_3_9_BASE:1.21
	OPENBSD_3_8:1.19.0.4
	OPENBSD_3_8_BASE:1.19
	OPENBSD_3_7:1.19.0.2
	OPENBSD_3_7_BASE:1.19
	OPENBSD_3_6:1.18.0.6
	OPENBSD_3_6_BASE:1.18
	SMP_SYNC_A:1.18
	SMP_SYNC_B:1.18
	OPENBSD_3_5:1.18.0.4
	OPENBSD_3_5_BASE:1.18
	OPENBSD_3_4:1.18.0.2
	OPENBSD_3_4_BASE:1.18
	UBC_SYNC_A:1.16
	OPENBSD_3_3:1.16.0.2
	OPENBSD_3_3_BASE:1.16
	OPENBSD_3_2:1.15.0.4
	OPENBSD_3_2_BASE:1.15
	OPENBSD_3_1:1.15.0.2
	OPENBSD_3_1_BASE:1.15
	UBC_SYNC_B:1.16
	UBC:1.11.0.2
	UBC_BASE:1.11
	OPENBSD_3_0:1.7.0.4
	OPENBSD_3_0_BASE:1.7
	OPENBSD_2_9:1.7.0.2
	OPENBSD_2_9_BASE:1.7
	OPENBSD_2_8:1.5.0.4
	OPENBSD_2_8_BASE:1.5
	OPENBSD_2_7:1.5.0.2
	OPENBSD_2_7_BASE:1.5
	SMP:1.4.0.2
	SMP_BASE:1.4
	kame_19991208:1.3
	OPENBSD_2_6:1.3.0.14
	OPENBSD_2_6_BASE:1.3
	OPENBSD_2_5:1.3.0.12
	OPENBSD_2_5_BASE:1.3
	OPENBSD_2_4:1.3.0.10
	OPENBSD_2_4_BASE:1.3
	OPENBSD_2_3:1.3.0.8
	OPENBSD_2_3_BASE:1.3
	OPENBSD_2_2:1.3.0.6
	OPENBSD_2_2_BASE:1.3
	OPENBSD_2_1:1.3.0.4
	OPENBSD_2_1_BASE:1.3
	OPENBSD_2_0:1.3.0.2
	OPENBSD_2_0_BASE:1.3
	theo-1:1.1.1.2
	netbsd_1_1:1.1.1.1;
locks; strict;
comment	@ * @;


1.25
date	2014.03.18.22.36.34;	author miod;	state dead;
branches;
next	1.24;

1.24
date	2010.06.28.04.20.28;	author miod;	state Exp;
branches;
next	1.23;

1.23
date	2008.01.04.19.05.32;	author miod;	state Exp;
branches;
next	1.22;

1.22
date	2006.05.19.22.51.09;	author miod;	state Exp;
branches;
next	1.21;

1.21
date	2005.11.24.22.43.19;	author miod;	state Exp;
branches;
next	1.20;

1.20
date	2005.10.27.16.04.08;	author martin;	state Exp;
branches;
next	1.19;

1.19
date	2004.12.30.21.22.20;	author miod;	state Exp;
branches;
next	1.18;

1.18
date	2003.06.02.23.27.51;	author millert;	state Exp;
branches;
next	1.17;

1.17
date	2003.06.02.05.09.14;	author deraadt;	state Exp;
branches;
next	1.16;

1.16
date	2002.10.12.01.09.43;	author krw;	state Exp;
branches;
next	1.15;

1.15
date	2002.02.23.04.58.28;	author miod;	state Exp;
branches;
next	1.14;

1.14
date	2002.02.22.22.45.34;	author miod;	state Exp;
branches;
next	1.13;

1.13
date	2002.02.11.19.08.30;	author miod;	state Exp;
branches;
next	1.12;

1.12
date	2001.12.20.19.02.29;	author miod;	state Exp;
branches;
next	1.11;

1.11
date	2001.12.14.21.44.05;	author miod;	state Exp;
branches
	1.11.2.1;
next	1.10;

1.10
date	2001.11.30.20.58.18;	author miod;	state Exp;
branches;
next	1.9;

1.9
date	2001.11.25.18.13.37;	author miod;	state Exp;
branches;
next	1.8;

1.8
date	2001.11.06.19.53.15;	author miod;	state Exp;
branches;
next	1.7;

1.7
date	2001.04.05.20.39.40;	author deraadt;	state Exp;
branches;
next	1.6;

1.6
date	2001.03.12.07.38.32;	author smurph;	state Exp;
branches;
next	1.5;

1.5
date	2000.02.22.19.27.54;	author deraadt;	state Exp;
branches;
next	1.4;

1.4
date	2000.01.06.03.21.43;	author smurph;	state Exp;
branches
	1.4.2.1;
next	1.3;

1.3
date	96.04.28.10.59.08;	author deraadt;	state Exp;
branches;
next	1.2;

1.2
date	95.11.07.08.50.24;	author deraadt;	state Exp;
branches;
next	1.1;

1.1
date	95.10.18.08.51.13;	author deraadt;	state Exp;
branches
	1.1.1.1;
next	;

1.1.1.1
date	95.10.18.08.51.13;	author deraadt;	state Exp;
branches;
next	1.1.1.2;

1.1.1.2
date	95.10.18.10.42.56;	author deraadt;	state Exp;
branches;
next	;

1.4.2.1
date	2000.03.02.07.04.31;	author niklas;	state Exp;
branches;
next	1.4.2.2;

1.4.2.2
date	2001.04.18.16.10.40;	author niklas;	state Exp;
branches;
next	1.4.2.3;

1.4.2.3
date	2001.11.13.21.04.14;	author niklas;	state Exp;
branches;
next	1.4.2.4;

1.4.2.4
date	2001.12.05.00.39.12;	author niklas;	state Exp;
branches;
next	1.4.2.5;

1.4.2.5
date	2002.03.06.01.07.00;	author niklas;	state Exp;
branches;
next	1.4.2.6;

1.4.2.6
date	2003.03.27.23.32.17;	author niklas;	state Exp;
branches;
next	1.4.2.7;

1.4.2.7
date	2003.06.07.11.13.16;	author ho;	state Exp;
branches;
next	;

1.11.2.1
date	2002.01.31.22.55.16;	author niklas;	state Exp;
branches;
next	1.11.2.2;

1.11.2.2
date	2002.06.11.03.36.50;	author art;	state Exp;
branches;
next	1.11.2.3;

1.11.2.3
date	2002.10.29.00.28.07;	author art;	state Exp;
branches;
next	;


desc
@@


1.25
log
@Retire hp300, mvme68k and mvme88k ports. These ports have no users, keeping
this hardware alive is becoming increasingly difficult, and I should heed the
message sent by the three disks which have died on me over the last few days.

Noone sane will mourn these ports anyway. So long, and thanks for the fish.
@
text
@/*	$OpenBSD: pmap_bootstrap.c,v 1.24 2010/06/28 04:20:28 miod Exp $ */

/* 
 * Copyright (c) 1995 Theo de Raadt
 * Copyright (c) 1999 Steve Murphree, Jr. (68060 support)
 * 
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 *
 * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS
 * OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
 * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY
 * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
 *
 * Copyright (c) 1991, 1993
 *	The Regents of the University of California.  All rights reserved.
 *
 * This code is derived from software contributed to Berkeley by
 * the Systems Programming Group of the University of Utah Computer
 * Science Department.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. Neither the name of the University nor the names of its contributors
 *    may be used to endorse or promote products derived from this software
 *    without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE
 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
 *
 *	@@(#)pmap_bootstrap.c	8.1 (Berkeley) 6/10/93
 */

#include <sys/param.h>
#include <sys/msgbuf.h>

#include <machine/cpu.h>
#include <machine/frame.h>
#include <machine/pte.h>
#include <machine/vmparam.h>

#include <uvm/uvm_extern.h>
#include <uvm/uvm_km.h>

vaddr_t iiomapbase;
int iiomapsize;
#define	ETHERPAGES	16
void *etherbuf;
int etherlen;

extern vaddr_t extiobase;
extern int physmem;

#define	RELOC(v, t)	*((t*)((u_int)&(v) + firstpa))
#define	PA2VA(v, t)	*((t*)((u_int)&(v)))

#define	MACHINE_IIOMAPSIZE	RELOC(iiomapsize, vaddr_t)
#define	MACHINE_INTIOBASE	RELOC(iiomapbase, vaddr_t)
#define	MACHINE_EIOMAPSIZE	EIOMAPSIZE

#define	PMAP_MD_LOCALS		/* nothing */

#define	PMAP_MD_RELOC1() \
do { \
	RELOC(etherbuf, void *) = (void *)nextpa; \
	nextpa += ETHERPAGES * NBPG; \
} while (0)

#define	PMAP_MD_MAPIOSPACE() \
do { \
	pte = &((u_int *)kptpa)[atop((vaddr_t)etherbuf)]; \
	epte = pte + ETHERPAGES; \
	while (pte < epte) { \
		*pte = (*pte & ~PG_CMASK) | PG_CIS | PG_U; \
		pte++; \
	} \
	RELOC(etherlen, int) = ETHERPAGES * NBPG; \
} while (0)

	/*
	 * intiobase, intiolimit: base and end of internal IO space.
	 * MACHINE_IIOMAPSIZE pages prior to external IO space at end of
	 * static kernel page table.
	 * extiobase: base of external IO space.
	 * MACHINE_EIOMAPSIZE pages at the end of the static kernel page table.
	 */
#define	PMAP_MD_RELOC2() \
do { \
	RELOC(intiobase, vaddr_t) = (vaddr_t)iiobase; \
	RELOC(intiolimit, vaddr_t) = (vaddr_t)eiobase; \
	RELOC(extiobase, vaddr_t) = (vaddr_t)eiobase; \
} while (0)

#define	PMAP_MD_MEMSIZE() \
do { \
	RELOC(avail_end, paddr_t) = ptoa(RELOC(physmem, int)) - \
	    round_page(MSGBUFSIZE); \
} while (0)

#define	PMAP_MD_RELOC3()	/* nothing */

#include <m68k/m68k/pmap_bootstrap.c>

void
pmap_init_md()
{
	vaddr_t         addr;

	/*
	 * mark as unavailable the regions which we have mapped in
	 * pmap_bootstrap().
	 */
	addr = intiobase;
	if (uvm_map(kernel_map, &addr, ptoa(iiomapsize + EIOMAPSIZE),
	    NULL, UVM_UNKNOWN_OFFSET, 0,
	    UVM_MAPFLAG(UVM_PROT_NONE, UVM_PROT_NONE,
	      UVM_INH_NONE, UVM_ADV_RANDOM, UVM_FLAG_FIXED)))
		panic("pmap_init: bogons in the VM system!");
}
@


1.24
log
@Move uvm_km_pages struct declaration and watermark bounds to uvm_km.h, so
that md code can peek at it, and update m68k !__HAVE_PMAP_DIRECT setup code
to the recent uvm_km changes.
ok thib@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap_bootstrap.c,v 1.23 2008/01/04 19:05:32 miod Exp $ */
@


1.23
log
@Do not leave a page unused after the kernel message buffer on m68k platforms.
While there, compute the physical memory size in a much simpler way on mac68k.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap_bootstrap.c,v 1.22 2006/05/19 22:51:09 miod Exp $ */
d71 1
@


1.22
log
@Get rid of ``maxmem'' and fix the descriptive comment for ``physmem''.
Either maxmem is not used (mac68k), or the position of the physical memory
is set in stone so we don't need to know the top of the memory (MAXADDR
on hp300, physmem on mvme68k) it was pointing to.

Plus this gets rid of unused lowram on mvme68k - all the m68k world is not an
hp300, after all.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap_bootstrap.c,v 1.21 2005/11/24 22:43:19 miod Exp $ */
d124 1
a124 1
	    (round_page(MSGBUFSIZE) + ptoa(1)); \
@


1.21
log
@Prefer vaddr_t and paddr_t types in device softc, instead of void * and
heavy casts. Improves readability, no functional change.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap_bootstrap.c,v 1.20 2005/10/27 16:04:08 martin Exp $ */
d79 1
a79 1
extern int maxmem;
d123 1
a123 1
	RELOC(avail_end, paddr_t) = ptoa(RELOC(maxmem, int)) - \
@


1.20
log
@stupid me, of course these MD macros need to be converted to MI macros
as well
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap_bootstrap.c,v 1.19 2004/12/30 21:22:20 miod Exp $ */
d72 1
a72 1
char *iiomapbase;
d78 1
a78 1
extern char *extiobase;
d84 2
a85 2
#define	MACHINE_IIOMAPSIZE	RELOC(iiomapsize, int)
#define	MACHINE_INTIOBASE	RELOC(iiomapbase, int)
d98 1
a98 1
	pte = &((u_int *)kptpa)[atop(etherbuf)]; \
d116 3
a118 3
	RELOC(intiobase, char *) = (char *)iiobase; \
	RELOC(intiolimit, char *) = (char *)eiobase; \
	RELOC(extiobase, char *) = (char *)eiobase; \
d140 2
a141 2
	addr = (vaddr_t) intiobase;
	if (uvm_map(kernel_map, &addr, ptoa(iiomapsize+EIOMAPSIZE),
@


1.19
log
@Rework pmap_bootstrap() computations of I/O maps. Makes the MD part of
this much simpler.

Also, make sure an userland process can fill its UPT as expected.

No functional change.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap_bootstrap.c,v 1.18 2003/06/02 23:27:51 millert Exp $ */
d98 1
a98 1
	pte = &((u_int *)kptpa)[m68k_btop(etherbuf)]; \
d123 2
a124 2
	RELOC(avail_end, paddr_t) = m68k_ptob(RELOC(maxmem, int)) - \
	    (round_page(MSGBUFSIZE) + m68k_ptob(1)); \
d141 1
a141 1
	if (uvm_map(kernel_map, &addr, m68k_ptob(iiomapsize+EIOMAPSIZE),
@


1.18
log
@Remove the advertising clause in the UCB license which Berkeley
rescinded 22 July 1999.  Proofed by myself and Theo.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap_bootstrap.c,v 1.17 2003/06/02 05:09:14 deraadt Exp $ */
d116 3
a118 7
	RELOC(intiobase, char *) = \
	    (char *)m68k_ptob(nptpages * NPTEPG - \
	        (MACHINE_IIOMAPSIZE + MACHINE_EIOMAPSIZE)); \
	RELOC(intiolimit, char *) = \
	    (char *)m68k_ptob(nptpages * NPTEPG - MACHINE_EIOMAPSIZE); \
	RELOC(extiobase, char *) = \
	    (char *)m68k_ptob(nptpages * NPTEPG - MACHINE_EIOMAPSIZE); \
@


1.17
log
@license cleanup of my files
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap_bootstrap.c,v 1.16 2002/10/12 01:09:43 krw Exp $ */
d43 1
a43 5
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *	This product includes software developed by the University of
 *	California, Berkeley and its contributors.
 * 4. Neither the name of the University nor the names of its contributors
@


1.16
log
@Remove more '\n's from panic() statements. Both trailing and leading.

Diff generated by Chris Kuethe.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap_bootstrap.c,v 1.15 2002/02/23 04:58:28 miod Exp $ */
a14 6
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *	This product includes software developed under OpenBSD by
 *	Theo de Raadt for Willowglen Singapore.
 * 4. The name of the author may not be used to endorse or promote products
 *    derived from this software without specific prior written permission.
@


1.15
log
@Factorize most of the pmap_bootstrap() guts used by pmap_motorola users,
with a few hooks to cope with each architecture's specifics.

The new arch/m68k/m68k/pmap_bootstrap.c is not a standalone file, but will
be #included by the existing pmap_bootstrap.c code.

Tested on hp300 and mvme68k, mac68k coming soon. amiga will be left out
for now because it is a bit too different.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap_bootstrap.c,v 1.14 2002/02/22 22:45:34 miod Exp $ */
d159 1
a159 1
		panic("pmap_init: bogons in the VM system!\n");
@


1.14
log
@Switch mvme68k to pmap_motorola again.
68060 operation tested by deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap_bootstrap.c,v 1.13 2002/02/11 19:08:30 miod Exp $ */
a81 16
#define RELOC(v, t)	*((t*)((u_int)&(v) + firstpa))

extern char *etext;
extern int Sysptsize;
extern char *extiobase, *proc0paddr;
extern st_entry_t *Sysseg;
extern pt_entry_t *Sysptmap, *Sysmap;

extern int maxmem, physmem;
extern paddr_t avail_start, avail_end;
extern vaddr_t virtual_avail, virtual_end;
extern vsize_t mem_size;
#ifdef M68K_MMU_HP
extern int pmap_aliasmask;
#endif

d88 6
d96 1
d98 1
a98 293
void  pmap_bootstrap __P((paddr_t, paddr_t));


/*
 * Special purpose kernel virtual addresses, used for mapping
 * physical pages for a variety of temporary or permanent purposes:
 *
 *	CADDR1, CADDR2:	pmap zero/copy operations
 *	vmmap:		/dev/mem, crash dumps, parity error checking
 *	ledbase:	SPU LEDs
 *	msgbufp:	kernel message buffer
 */
caddr_t		CADDR1, CADDR2, vmmap;

/*
 * Bootstrap the VM system.
 *
 * Called with MMU off so we must relocate all global references by `firstpa'
 * (don't call any functions here!)  `nextpa' is the first available physical
 * memory address.  Returns an updated first PA reflecting the memory we
 * have allocated.  MMU is still off when we return.
 *
 * XXX assumes sizeof(u_int) == sizeof(pt_entry_t)
 * XXX a PIC compiler would make this much easier.
 */
void
pmap_bootstrap(nextpa, firstpa)
	paddr_t nextpa;
	paddr_t firstpa;
{
	paddr_t kstpa, kptpa, iiopa, eiopa, kptmpa, lkptpa, p0upa;
	u_int nptpages, kstsize;
	st_entry_t protoste, *ste;
	pt_entry_t protopte, *pte, *epte;

	/*
	 * Calculate important physical addresses:
	 *
	 *	kstpa		kernel segment table	1 page (020/030)
	 *						N pages (040/060)
	 *
	 *	kptpa		statically allocated
	 *			kernel PT pages		Sysptsize+ pages
	 *
	 *	iiopa		internal IO space
	 *			PT pages		MACHINE_IIOMAPSIZE pages
	 *
	 *	eiopa		external IO space
	 *			PT pages		EIOMAPSIZE pages
	 *
	 * [ Sysptsize is the number of pages of PT, MACHINE_IIOMAPSIZE and
	 *   EIOMAPSIZE are the number of PTEs, hence we need to round
	 *   the total to a page boundary with IO maps at the end. ]
	 *
	 *	kptmpa		kernel PT map		1 page
	 *
	 *	lkptpa		last kernel PT page	1 page
	 *
	 *	p0upa		proc 0 u-area		UPAGES pages
	 *
	 * The KVA corresponding to any of these PAs is:
	 *	(PA - firstpa + KERNBASE).
	 */
	if (RELOC(mmutype, int) <= MMU_68040)
		kstsize = MAXKL2SIZE / (NPTEPG/SG4_LEV2SIZE);
	else
		kstsize = 1;
	kstpa = nextpa;
	nextpa += kstsize * NBPG;
	kptpa = nextpa;
	nptpages = RELOC(Sysptsize, int) +
	    (MACHINE_IIOMAPSIZE + EIOMAPSIZE + NPTEPG - 1) / NPTEPG;
	nextpa += nptpages * NBPG;
	eiopa = nextpa - EIOMAPSIZE * sizeof(pt_entry_t);
	iiopa = eiopa - MACHINE_IIOMAPSIZE * sizeof(pt_entry_t);
	kptmpa = nextpa;
	nextpa += NBPG;
	lkptpa = nextpa;
	nextpa += NBPG;
	p0upa = nextpa;
	nextpa += USPACE;

	RELOC(etherbuf, void *) = (void *)nextpa;
	nextpa += ETHERPAGES * NBPG;

	/*
	 * Initialize segment table and kernel page table map.
	 *
	 * On 68030s and earlier MMUs the two are identical except for
	 * the valid bits so both are initialized with essentially the
	 * same values.  On the 680[46]0, which have a mandatory 3-level
	 * structure, the segment table holds the level 1 table and part
	 * (or all) of the level 2 table and hence is considerably
	 * different.  Here the first level consists of 128 descriptors
	 * (512 bytes) each mapping 32mb of address space.  Each of these
	 * points to blocks of 128 second level descriptors (512 bytes)
	 * each mapping 256kb.  Note that there may be additional "segment
	 * table" pages depending on how large MAXKL2SIZE is.
	 *
	 * Portions of the last segment of KVA space (0xFFF00000 -
	 * 0xFFFFFFFF) are mapped for a couple of purposes.  0xFFF00000
	 * for UPAGES is used for mapping the current process u-area
	 * (u + kernel stack).  The very last page (0xFFFFF000) is mapped
	 * to the last physical page of RAM to give us a region in which
	 * PA == VA.  We use the first part of this page for enabling
	 * and disabling mapping.  The last part of this page also contains
	 * info left by the boot ROM.
	 *
	 * XXX cramming two levels of mapping into the single "segment"
	 * table on the 68040 is intended as a temporary hack to get things
	 * working.  The 224mb of address space that this allows will most
	 * likely be insufficient in the future (at least for the kernel).
	 */
	if (RELOC(mmutype, int) <= MMU_68040) {
		int num;

		/*
		 * First invalidate the entire "segment table" pages
		 * (levels 1 and 2 have the same "invalid" value).
		 */
		pte = (u_int *)kstpa;
		epte = &pte[kstsize * NPTEPG];
		while (pte < epte)
			*pte++ = SG_NV;
		/*
		 * Initialize level 2 descriptors (which immediately
		 * follow the level 1 table).  We need:
		 *	NPTEPG / SG4_LEV3SIZE
		 * level 2 descriptors to map each of the nptpages+1
		 * pages of PTEs.  Note that we set the "used" bit
		 * now to save the HW the expense of doing it.
		 */
		num = (nptpages + 1) * (NPTEPG / SG4_LEV3SIZE);
		pte = &((u_int *)kstpa)[SG4_LEV1SIZE];
		epte = &pte[num];
		protoste = kptpa | SG_U | SG_RW | SG_V;
		while (pte < epte) {
			*pte++ = protoste;
			protoste += (SG4_LEV3SIZE * sizeof(st_entry_t));
		}
		/*
		 * Initialize level 1 descriptors.  We need:
		 *	roundup(num, SG4_LEV2SIZE) / SG4_LEV2SIZE
		 * level 1 descriptors to map the `num' level 2's.
		 */
		pte = (u_int *)kstpa;
		epte = &pte[roundup(num, SG4_LEV2SIZE) / SG4_LEV2SIZE];
		protoste = (u_int)&pte[SG4_LEV1SIZE] | SG_U | SG_RW | SG_V;
		while (pte < epte) {
			*pte++ = protoste;
			protoste += (SG4_LEV2SIZE * sizeof(st_entry_t));
		}
		/*
		 * Initialize the final level 1 descriptor to map the last
		 * block of level 2 descriptors.
		 */
		ste = &((u_int *)kstpa)[SG4_LEV1SIZE-1];
		pte = &((u_int *)kstpa)[kstsize*NPTEPG - SG4_LEV2SIZE];
		*ste = (u_int)pte | SG_U | SG_RW | SG_V;
		/*
		 * Now initialize the final portion of that block of
		 * descriptors to map the "last PT page".
		 */
		pte = &((u_int *)kstpa)[kstsize*NPTEPG - NPTEPG/SG4_LEV3SIZE];
		epte = &pte[NPTEPG/SG4_LEV3SIZE];
		protoste = lkptpa | SG_U | SG_RW | SG_V;
		while (pte < epte) {
			*pte++ = protoste;
			protoste += (SG4_LEV3SIZE * sizeof(st_entry_t));
		}
		/*
		 * Initialize Sysptmap
		 */
		pte = (u_int *)kptmpa;
		epte = &pte[nptpages+1];
		protopte = kptpa | PG_RW | PG_CI | PG_V | PG_U;
		while (pte < epte) {
			*pte++ = protopte;
			protopte += NBPG;
		}
		/*
		 * Invalidate all but the last remaining entry.
		 */
		epte = &((u_int *)kptmpa)[NPTEPG-1];
		while (pte < epte) {
			*pte++ = PG_NV | PG_U;
		}
		/*
		 * Initialize the last to point to the page
		 * table page allocated earlier.
		 */
		*pte = lkptpa | PG_RW | PG_CI | PG_V | PG_U;
	} else {
		/*
		 * Map the page table pages in both the HW segment table
		 * and the software Sysptmap.  Note that Sysptmap is also
		 * considered a PT page hence the +1.
		 */
		ste = (u_int *)kstpa;
		pte = (u_int *)kptmpa;
		epte = &pte[nptpages+1];
		protoste = kptpa | SG_RW | SG_V;
		protopte = kptpa | PG_RW | PG_CI | PG_V;
		while (pte < epte) {
			*ste++ = protoste;
			*pte++ = protopte;
			protoste += NBPG;
			protopte += NBPG;
		}
		/*
		 * Invalidate all but the last remaining entries in both.
		 */
		epte = &((u_int *)kptmpa)[NPTEPG-1];
		while (pte < epte) {
			*ste++ = SG_NV;
			*pte++ = PG_NV;
		}
		/*
		 * Initialize the last to point to point to the page
		 * table page allocated earlier.
		 */
		*ste = lkptpa | SG_RW | SG_V;
		*pte = lkptpa | PG_RW | PG_CI | PG_V;
	}
	/*
	 * Invalidate all but the final entry in the last kernel PT page
	 * (u-area PTEs will be validated later).  The final entry maps
	 * the last page of physical memory.
	 */
	pte = (u_int *)lkptpa;
	epte = &pte[NPTEPG-1];
	while (pte < epte)
		*pte++ = PG_NV;
#ifdef MAXADDR
	/*
	 * Temporary double-map for machines with physmem at the end of
	 * memory
	 */
	*pte = MAXADDR | PG_RW | PG_CI | PG_V | PG_U;
#endif
	/*
	 * Initialize kernel page table.
	 * Start by invalidating the `nptpages' that we have allocated.
	 */
	pte = (u_int *)kptpa;
	epte = &pte[nptpages * NPTEPG];
	while (pte < epte)
		*pte++ = PG_NV | PG_U;

	/*
	 * Validate PTEs for kernel text (RO).  The first page
	 * of kernel text remains invalid; see locore.s
	 */
	pte = &((u_int *)kptpa)[m68k_btop(KERNBASE)];
	epte = &pte[m68k_btop(trunc_page((vaddr_t)&etext))];
#if defined(KGDB) || defined(DDB)
	protopte = firstpa | PG_RW | PG_V | PG_U;	/* XXX RW for now */
#else
	protopte = firstpa | PG_RO | PG_V | PG_U;
#endif
	*pte++ = firstpa | PG_NV;	/* make *NULL fail in the kernel */
	protopte += NBPG;
	while (pte < epte) {
		*pte++ = protopte;
		protopte += NBPG;
	}
	/*
	 * Validate PTEs for kernel data/bss, dynamic data allocated
	 * by us so far (nextpa - firstpa bytes), and pages for proc0
	 * u-area and page table allocated below (RW).
	 */
	epte = &((u_int *)kptpa)[m68k_btop(nextpa - firstpa)];
	protopte = (protopte & ~PG_PROT) | PG_RW | PG_U;
	/*
	 * Enable copy-back caching of data pages on 040, and write-through
	 * caching on 060
	 */
	if (RELOC(mmutype, int) == MMU_68040)
		protopte |= PG_CCB;
	else if (RELOC(mmutype, int) == MMU_68060)
		protopte |= PG_CWT;
	while (pte < epte) {
		*pte++ = protopte;
		protopte += NBPG;
	}

	pte = &((u_int *)kptpa)[m68k_btop(etherbuf)];
	epte = pte + ETHERPAGES;
	while (pte < epte) {
		*pte = (*pte & ~PG_CMASK) | PG_CIS | PG_U;
		pte++;
	}
	RELOC(etherlen, int) = ETHERPAGES * NBPG;
d100 16
a115 14
	/*
	 * Finally, validate the internal IO space PTEs (RW+CI).
	 * We do this here since on hp300 machines with the HP MMU, the
	 * the MMU registers (also used, but to a lesser extent, on other
	 * models) are mapped in this range and it would be nice to be able
	 * to access them after the MMU is turned on.
	 */
	pte = (u_int *)iiopa;
	epte = (u_int *)eiopa;
	protopte = MACHINE_INTIOBASE | PG_RW | PG_CI | PG_V | PG_U;
	while (pte < epte) {
		*pte++ = protopte;
		protopte += NBPG;
	}
d118 1
a118 20
	 * Calculate important exported kernel virtual addresses
	 */
	/*
	 * Sysseg: base of kernel segment table
	 */
	RELOC(Sysseg, st_entry_t *) =
	    (st_entry_t *)(kstpa - firstpa);
	/*
	 * Sysptmap: base of kernel page table map
	 */
	RELOC(Sysptmap, pt_entry_t *) =
	    (pt_entry_t *)(kptmpa - firstpa);
	/*
	 * Sysmap: kernel page table (as mapped through Sysptmap)
	 * Immediately follows `nptpages' of static kernel page table.
	 */
	RELOC(Sysmap, pt_entry_t *) =
	    (pt_entry_t *)m68k_ptob(nptpages * NPTEPG);
	/*
	 * intiobase, intiolimit: base and end of internal (DIO) IO space.
d121 2
d124 16
a139 95
	RELOC(intiobase, char *) =
	    (char *)m68k_ptob(nptpages*NPTEPG - (MACHINE_IIOMAPSIZE+EIOMAPSIZE));
	RELOC(intiolimit, char *) =
	    (char *)m68k_ptob(nptpages*NPTEPG - EIOMAPSIZE);
	/*
	 * extiobase: base of external (DIO-II) IO space.
	 * EIOMAPSIZE pages at the end of the static kernel page table.
	 */
	RELOC(extiobase, char *) =
	    (char *)m68k_ptob(nptpages*NPTEPG - EIOMAPSIZE);

	/*
	 * Setup u-area for process 0.
	 */
	/*
	 * Zero the u-area.
	 * NOTE: `pte' and `epte' aren't PTEs here.
	 */
	pte = (u_int *)p0upa;
	epte = (u_int *)(p0upa + USPACE);
	while (pte < epte)
		*pte++ = 0;
	/*
	 * Remember the u-area address so it can be loaded in the
	 * proc struct p_addr field later.
	 */
	RELOC(proc0paddr, char *) = (char *)(p0upa - firstpa);

	/*
	 * VM data structures are now initialized, set up data for
	 * the pmap module.
	 *
	 * Note about avail_end: msgbuf is initialized just after
	 * avail_end in machdep.c.  Since the last page is used
	 * for rebooting the system (code is copied there and
	 * excution continues from copied code before the MMU
	 * is disabled), the msgbuf will get trounced between
	 * reboots if it's placed in the last physical page.
	 * To work around this, we move avail_end back one more
	 * page so the msgbuf can be preserved.
	 */
	RELOC(avail_start, paddr_t) = nextpa;
	RELOC(avail_end, paddr_t) = m68k_ptob(RELOC(maxmem, int)) -
	    (round_page(MSGBUFSIZE) + m68k_ptob(1));
	RELOC(mem_size, vsize_t) = m68k_ptob(RELOC(physmem, int));
	RELOC(virtual_avail, vaddr_t) =
	    VM_MIN_KERNEL_ADDRESS + (nextpa - firstpa);
	RELOC(virtual_end, vaddr_t) = VM_MAX_KERNEL_ADDRESS;

#ifdef M68K_MMU_HP
	/*
	 * Determine VA aliasing distance if any
	 */
	if (RELOC(ectype, int) == EC_VIRT) {
		if (RELOC(machineid, int) == HP_320)
			RELOC(pmap_aliasmask, int) = 0x3fff;	/* 16k */
		else if (RELOC(machineid, int) == HP_350)
			RELOC(pmap_aliasmask, int) = 0x7fff;	/* 32k */
	}
#endif

	/*
	 * Kernel page/segment table allocated in locore,
	 * just initialize pointers.
	 */
	{
		struct pmap *kpm = &RELOC(kernel_pmap_store, struct pmap);

		kpm->pm_stab = RELOC(Sysseg, st_entry_t *);
		kpm->pm_ptab = RELOC(Sysmap, pt_entry_t *);
		simple_lock_init(&kpm->pm_lock);
		kpm->pm_count = 1;
		kpm->pm_stpa = (st_entry_t *)kstpa;
		/*
		 * For the 040 and 060 we also initialize the free level 2
		 * descriptor mask noting that we have used:
		 *	0:		level 1 table
		 *	1 to `num':	map page tables
		 *	MAXKL2SIZE-1:	maps last-page page table
		 */
		if (RELOC(mmutype, int) <= MMU_68040) {
			int num;
			
			kpm->pm_stfree = ~l2tobm(0);
			num = roundup((nptpages + 1) * (NPTEPG / SG4_LEV3SIZE),
			    SG4_LEV2SIZE) / SG4_LEV2SIZE;
			while (num)
				kpm->pm_stfree &= ~l2tobm(num--);
			kpm->pm_stfree &= ~l2tobm(MAXKL2SIZE-1);
			for (num = MAXKL2SIZE;
			     num < sizeof(kpm->pm_stfree)*NBBY;
			     num++)
				kpm->pm_stfree &= ~l2tobm(num);
		}
	}
d141 1
a141 5
	/*
	 * Allocate some fixed, special purpose kernel virtual addresses
	 */
	{
		vaddr_t va = RELOC(virtual_avail, vaddr_t);
d143 1
a143 11
		RELOC(CADDR1, caddr_t) = (caddr_t)va;
		va += NBPG;
		RELOC(CADDR2, caddr_t) = (caddr_t)va;
		va += NBPG;
		RELOC(vmmap, caddr_t) = (caddr_t)va;
		va += NBPG;
		RELOC(msgbufp, struct msgbuf *) = (struct msgbuf *)va;
		va += MSGBUFSIZE;
		RELOC(virtual_avail, vaddr_t) = va;
	}
}
@


1.13
log
@Merge pmap_bootstrap060() with pmap_bootstrap().
Thanks to deraadt@@ for testing on mvme177.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap_bootstrap.c,v 1.12 2001/12/20 19:02:29 miod Exp $ */
a90 1
extern int protection_codes[];
a501 19
	 * Initialize protection array.
	 * XXX don't use a switch statement, it might produce an
	 * absolute "jmp" table.
	 */
	{
		register int *kp;

		kp = &RELOC(protection_codes, int);
		kp[VM_PROT_NONE|VM_PROT_NONE|VM_PROT_NONE] = 0;
		kp[VM_PROT_READ|VM_PROT_NONE|VM_PROT_NONE] = PG_RO;
		kp[VM_PROT_READ|VM_PROT_NONE|VM_PROT_EXECUTE] = PG_RO;
		kp[VM_PROT_NONE|VM_PROT_NONE|VM_PROT_EXECUTE] = PG_RO;
		kp[VM_PROT_NONE|VM_PROT_WRITE|VM_PROT_NONE] = PG_RW;
		kp[VM_PROT_NONE|VM_PROT_WRITE|VM_PROT_EXECUTE] = PG_RW;
		kp[VM_PROT_READ|VM_PROT_WRITE|VM_PROT_NONE] = PG_RW;
		kp[VM_PROT_READ|VM_PROT_WRITE|VM_PROT_EXECUTE] = PG_RW;
	}

	/*
d552 17
@


1.12
log
@Temporarily revert the pmap_motorola changes, as they may account for
some problems as well.
Requested by deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap_bootstrap.c,v 1.11 2001/12/14 21:44:05 miod Exp $ */
d74 3
a78 2
#include <machine/cpu.h>
#include <machine/autoconf.h>
a86 2
char *iiomapbase;
int iiomapsize;
a90 2
extern vm_offset_t avail_start, avail_end, virtual_avail, virtual_end;
extern vm_size_t mem_size;
d92 18
d120 1
a120 370
caddr_t     CADDR1, CADDR2, vmmap, ledbase;
#define ETHERPAGES 16
void  *etherbuf;
int   etherlen;

void
pmap_bootstrap060(nextpa, firstpa)
vm_offset_t nextpa;
register vm_offset_t firstpa;
{
	vm_offset_t kstpa, kptpa, iiopa, eiopa, kptmpa, lkptpa, p0upa;
	u_int nptpages, kstsize;
	register st_entry_t protoste, *ste;
	register pt_entry_t protopte, *pte, *epte;

	/*
	 * Calculate important physical addresses:
	 *
	 *	kstpa		kernel segment table	1 page (!040)
	 *						N pages (040)
	 *
	 *	kptpa		statically allocated
	 *			kernel PT pages		Sysptsize+ pages
	 *
	 *	iiopa		internal IO space
	 *			PT pages		iiomapsize pages
	 *
	 *	eiopa		external IO space
	 *			PT pages		EIOMAPSIZE pages
	 *
	 * [ Sysptsize is the number of pages of PT, iiomapsize and
	 *   EIOMAPSIZE are the number of PTEs, hence we need to round
	 *   the total to a page boundary with IO maps at the end. ]
	 *
	 *	kptmpa		kernel PT map		1 page
	 *
	 *	lkptpa		last kernel PT page	1 page
	 *
	 *	p0upa		proc 0 u-area		UPAGES pages
	 *
	 * The KVA corresponding to any of these PAs is:
	 *	(PA - firstpa + KERNBASE).
	 * NPTEPG == 1024
	 */
	kstsize = MAXKL2SIZE / (NPTEPG/SG4_LEV2SIZE);
	kstpa = nextpa;
	nextpa += kstsize * NBPG;
	kptpa = nextpa;
	nptpages = RELOC(Sysptsize, int) + 
		(RELOC(iiomapsize, int) + EIOMAPSIZE + NPTEPG - 1) / NPTEPG;
	nextpa += nptpages * NBPG;
	eiopa = nextpa - EIOMAPSIZE * sizeof(pt_entry_t);
	iiopa = eiopa - RELOC(iiomapsize, int) * sizeof(pt_entry_t);
	kptmpa = nextpa;
	nextpa += NBPG;
	lkptpa = nextpa;
	nextpa += NBPG;
	p0upa = nextpa;
	nextpa += USPACE;

	RELOC(etherbuf, void *) = (void *)nextpa;
	nextpa += ETHERPAGES * NBPG;

	/*
	 * Initialize segment table and kernel page table map.
	 *
	 * On the 68060, which has a mandatory 3-level structure, the 
	 * segment table holds the level 1 table and part (or all) of 
	 * the level 2 table. The first level consists of 128 descriptors
	 * (512 bytes) each mapping 32mb of address space.  Each of these
	 * points to blocks of 128 second level descriptors (512 bytes)
	 * each mapping 256kb.  Note that there may be additional "segment
	 * table" pages depending on how large MAXKL2SIZE is.
	 *
	 * Portions of the last segment of KVA space (0xFFF00000 -
	 * 0xFFFFFFFF) are mapped for a couple of purposes.  0xFFF00000
	 * for UPAGES is used for mapping the current process u-area
	 * (u + kernel stack).  The very last page (0xFFFFF000) is mapped
	 * to the last physical page of RAM to give us a region in which
	 * PA == VA.  We use the first part of this page for enabling
	 * and disabling mapping.  The last part of this page also contains
	 * info left by the boot ROM.
	 */

	{
		register int num;

		/*
		 * First invalidate the entire "segment table" pages
		 * (levels 1 and 2 have the same "invalid" value).
		 */
		pte = (u_int *)kstpa;
		epte = &pte[kstsize * NPTEPG];
		while (pte < epte)
			*pte++ = SG_NV;
		/*
		 * Initialize level 2 descriptors (which immediately
		 * follow the level 1 table).  We need:
		 *	NPTEPG / SG4_LEV3SIZE
		 * level 2 descriptors to map each of the nptpages+1
		 * pages of PTEs.  Note that we set the "used" bit
		 * now to save the HW the expense of doing it.
		 */
		num = (nptpages + 1) * (NPTEPG / SG4_LEV3SIZE);
		pte = &((u_int *)kstpa)[SG4_LEV1SIZE];
		epte = &pte[num];
		protoste = kptpa | SG_U | SG_RW | SG_V;
		while (pte < epte) {
			*pte++ = protoste;
			protoste += (SG4_LEV3SIZE * sizeof(st_entry_t));
		}
		/*
		 * Initialize level 1 descriptors.  We need:
		 *	roundup(num, SG4_LEV2SIZE) / SG4_LEV2SIZE
		 * level 1 descriptors to map the `num' level 2's.
		 */
		pte = (u_int *)kstpa;
		epte = &pte[roundup(num, SG4_LEV2SIZE) / SG4_LEV2SIZE];
		protoste = (u_int)&pte[SG4_LEV1SIZE] | SG_U | SG_RW | SG_V;
		while (pte < epte) {
			*pte++ = protoste;
			protoste += (SG4_LEV2SIZE * sizeof(st_entry_t));
		}
		/*
		 * Initialize the final level 1 descriptor to map the last
		 * block of level 2 descriptors.
		 */
		ste = &((u_int *)kstpa)[SG4_LEV1SIZE-1];
		pte = &((u_int *)kstpa)[kstsize*NPTEPG - SG4_LEV2SIZE];
		*ste = (u_int)pte | SG_U | SG_RW | SG_V;
		/*
		 * Now initialize the final portion of that block of
		 * descriptors to map the "last PT page".
		 */
		pte = &((u_int *)kstpa)[kstsize*NPTEPG - NPTEPG/SG4_LEV3SIZE];
		epte = &pte[NPTEPG/SG4_LEV3SIZE];
		protoste = lkptpa | SG_U | SG_RW | SG_V;
		while (pte < epte) {
			*pte++ = protoste;
			protoste += (SG4_LEV3SIZE * sizeof(st_entry_t));
		}
		/*
		 * Initialize Sysptmap
		 */
		pte = (u_int *)kptmpa;
		epte = &pte[nptpages+1];
		protopte = kptpa | PG_RW | PG_CI | PG_V | PG_U;
		while (pte < epte) {
			*pte++ = protopte;
			protopte += NBPG;
		}
		/*
		 * Invalidate all but the last remaining entries in both.
		 */
		epte = &((u_int *)kptmpa)[NPTEPG-1];
		while (pte < epte) {
			*pte++ = PG_NV | PG_U; /* XXX */
		}
		pte = &((u_int *)kptmpa)[NPTEPG-1];
		*pte = lkptpa | PG_RW | PG_CI | PG_V | PG_U;
	}

	/*
	 * Invalidate all but the final entry in the last kernel PT page
	 * (u-area PTEs will be validated later).  The final entry maps
	 * the last page of physical memory.
	 */
	pte = (u_int *)lkptpa;
	epte = &pte[NPTEPG-1];
	while (pte < epte)
		*pte++ = PG_NV;
#ifdef MAXADDR
	/* tmp double-map for cpu's with physmem at the end of memory */
	*pte = MAXADDR | PG_RW | PG_CI | PG_V | PG_U;
#endif
	/*
	 * Initialize kernel page table.
	 * Start by invalidating the `nptpages' that we have allocated.
	 */
	pte = (u_int *)kptpa;
	epte = &pte[nptpages * NPTEPG];
	while (pte < epte)
		*pte++ = PG_NV | PG_U;
	/*
	 * Validate PTEs for kernel text (RO)
	 */
	pte = &((u_int *)kptpa)[m68k_btop(KERNBASE)];
	epte = &pte[m68k_btop(m68k_trunc_page(&etext))];
#if defined(KGDB) || defined(DDB)
	protopte = firstpa | PG_RW | PG_V | PG_U;	/* XXX RW for now */
#else
	protopte = firstpa | PG_RO | PG_V | PG_U;
#endif
	*pte++ = firstpa | PG_NV;		/* make *NULL fail in the kernel */
	protopte += NBPG;
	while (pte < epte) {
		*pte++ = protopte;
		protopte += NBPG;
	}
	/*
	 * Validate PTEs for kernel data/bss, dynamic data allocated
	 * by us so far (nextpa - firstpa bytes), and pages for proc0
	 * u-area and page table allocated below (RW).
	 */                    
	epte = &((u_int *)kptpa)[m68k_btop(nextpa - firstpa)];
	protopte = (protopte & ~PG_PROT) | PG_RW | PG_U;
	/*
	 * Enable write-through caching of data pages
	 */
	protopte |= PG_CWT; /* XXX */;
	while (pte < epte) {
		*pte++ = protopte;
		protopte += NBPG;
	}

	pte = &((u_int *)kptpa)[m68k_btop(etherbuf)];
	epte = pte + ETHERPAGES;
	while (pte < epte) {
		*pte = (*pte & ~PG_CMASK) | PG_CIS | PG_U;
		pte++;
	}
	RELOC(etherlen, int) = ETHERPAGES * NBPG;

	/*
	 * Finally, validate the internal IO space PTEs (RW+CI).
	 */
	pte = (u_int *)iiopa;
	epte = (u_int *)eiopa;
	protopte = RELOC(iiomapbase, int) | PG_RW | PG_CI | PG_V | PG_U;
	while (pte < epte) {
		*pte++ = protopte;
		protopte += NBPG;
	}

	/*
	 * Calculate important exported kernel virtual addresses
	 */
	/*
	 * Sysseg: base of kernel segment table
	 */
	RELOC(Sysseg, st_entry_t *) =
	(st_entry_t *)(kstpa - firstpa);
	/*
	 * Sysptmap: base of kernel page table map
	 */
	RELOC(Sysptmap, pt_entry_t *) =
	(pt_entry_t *)(kptmpa - firstpa);
	/*
	 * Sysmap: kernel page table (as mapped through Sysptmap)
	 * Immediately follows `nptpages' of static kernel page table.
	 */
	RELOC(Sysmap, pt_entry_t *) =
	(pt_entry_t *)m68k_ptob(nptpages * NPTEPG);
	/*
	 * intiobase, intiolimit: base and end of internal (DIO) IO space.
	 * iiomapsize pages prior to external IO space at end of static
	 * kernel page table.
	 */
	RELOC(intiobase, char *) = (char *)m68k_ptob(nptpages*NPTEPG - (RELOC(iiomapsize, int)+EIOMAPSIZE));
	RELOC(intiolimit, char *) = (char *)m68k_ptob(nptpages*NPTEPG - EIOMAPSIZE);
	/*
	 * extiobase: base of external (DIO-II) IO space.
	 * EIOMAPSIZE pages at the end of the static kernel page table.
	 */
	RELOC(extiobase, char *) =
	(char *)m68k_ptob(nptpages*NPTEPG - EIOMAPSIZE);

	/*
	 * Setup u-area for process 0.
	 */
	/*
	 * Zero the u-area.
	 * NOTE: `pte' and `epte' aren't PTEs here.
	 */
	pte = (u_int *)p0upa;
	epte = (u_int *)(p0upa + USPACE);
	while (pte < epte)
		*pte++ = 0;
	/*
	 * Remember the u-area address so it can be loaded in the
	 * proc struct p_addr field later.
	 */
	RELOC(proc0paddr, char *) = (char *)(p0upa - firstpa);

	/*
	 * VM data structures are now initialized, set up data for
	 * the pmap module.
	 */
	RELOC(avail_start, vm_offset_t) = nextpa;
	RELOC(avail_end, vm_offset_t) = m68k_ptob(RELOC(maxmem, int))
	   /* XXX allow for msgbuf */
	   - m68k_round_page(MSGBUFSIZE);
	RELOC(mem_size, vm_size_t) = m68k_ptob(RELOC(physmem, int));
	RELOC(virtual_avail, vm_offset_t) =
	VM_MIN_KERNEL_ADDRESS + (nextpa - firstpa);
	RELOC(virtual_end, vm_offset_t) = VM_MAX_KERNEL_ADDRESS;

	/*
	 * Initialize protection array.
	 * XXX don't use a switch statement, it might produce an
	 * absolute "jmp" table.
	 */
	{
		register int *kp;

		kp = &RELOC(protection_codes, int);
		kp[VM_PROT_NONE|VM_PROT_NONE|VM_PROT_NONE] = 0;
		kp[VM_PROT_READ|VM_PROT_NONE|VM_PROT_NONE] = PG_RO;
		kp[VM_PROT_READ|VM_PROT_NONE|VM_PROT_EXECUTE] = PG_RO;
		kp[VM_PROT_NONE|VM_PROT_NONE|VM_PROT_EXECUTE] = PG_RO;
		kp[VM_PROT_NONE|VM_PROT_WRITE|VM_PROT_NONE] = PG_RW;
		kp[VM_PROT_NONE|VM_PROT_WRITE|VM_PROT_EXECUTE] = PG_RW;
		kp[VM_PROT_READ|VM_PROT_WRITE|VM_PROT_NONE] = PG_RW;
		kp[VM_PROT_READ|VM_PROT_WRITE|VM_PROT_EXECUTE] = PG_RW;
	}

	/*
	 * Kernel page/segment table allocated in locore,
	 * just initialize pointers.
	 */
	{
		struct pmap *kpm = &RELOC(kernel_pmap_store, struct pmap);

		kpm->pm_stab = RELOC(Sysseg, st_entry_t *);
		kpm->pm_ptab = RELOC(Sysmap, pt_entry_t *);
		simple_lock_init(&kpm->pm_lock);
		kpm->pm_count = 1;
		kpm->pm_stpa = (st_entry_t *)kstpa;
		/*
		 * For the 060 we also initialize the free level 2
		 * descriptor mask noting that we have used:
		 *	           0:	level 1 table
		 *	  1 to `num':	map page tables
		 *	MAXKL2SIZE-1:	maps last-page page table
		 */
		{
			register int num;

			kpm->pm_stfree = ~l2tobm(0);
			num = roundup((nptpages + 1) * (NPTEPG / SG4_LEV3SIZE),
							  SG4_LEV2SIZE) / SG4_LEV2SIZE;
			while (num)
				kpm->pm_stfree &= ~l2tobm(num--);
			kpm->pm_stfree &= ~l2tobm(MAXKL2SIZE-1);
			for (num = MAXKL2SIZE;
				 num < sizeof(kpm->pm_stfree)*NBBY;
				 num++)
				kpm->pm_stfree &= ~l2tobm(num);
		}
	}

	/*
	 * Allocate some fixed, special purpose kernel virtual addresses
	 */
	{
		vm_offset_t va = RELOC(virtual_avail, vm_offset_t);

		RELOC(CADDR1, caddr_t) = (caddr_t)va;
		va += NBPG;
		RELOC(CADDR2, caddr_t) = (caddr_t)va;
		va += NBPG;
		RELOC(vmmap, caddr_t) = (caddr_t)va;
		va += NBPG;
		RELOC(ledbase, caddr_t) = (caddr_t)va;
		va += NBPG;
		RELOC(msgbufp, struct msgbuf *) = (struct msgbuf *)va;
		va += MSGBUFSIZE;
		RELOC(virtual_avail, vm_offset_t) = va;
	}
}
d135 2
a136 2
vm_offset_t nextpa;
register vm_offset_t firstpa;
d138 1
a138 1
	vm_offset_t kstpa, kptpa, iiopa, eiopa, kptmpa, lkptpa, p0upa;
d140 2
a141 2
	register st_entry_t protoste, *ste;
	register pt_entry_t protopte, *pte, *epte;
d146 2
a147 2
	 *	kstpa		kernel segment table	1 page (!040)
	 *						N pages (040)
d153 1
a153 1
	 *			PT pages		iiomapsize pages
d158 1
a158 1
	 * [ Sysptsize is the number of pages of PT, iiomapsize and
d171 1
a171 1
	if (RELOC(mmutype, int) == MMU_68040)
d179 1
a179 1
      (RELOC(iiomapsize, int) + EIOMAPSIZE + NPTEPG - 1) / NPTEPG;
d182 1
a182 1
	iiopa = eiopa - RELOC(iiomapsize, int) * sizeof(pt_entry_t);
d198 1
a198 1
	 * same values.  On the 68040, which has a mandatory 3-level
d221 2
a222 2
	if (RELOC(mmutype, int) == MMU_68040) {
		register int num;
d289 1
a289 1
		 * Invalidate all but the last remaining entries in both.
d293 1
a293 1
			*pte++ = PG_NV;
d295 4
a298 1
		pte = &((u_int *)kptmpa)[NPTEPG-1];
d342 4
a345 1
	/* tmp double-map for cpu's with physmem at the end of memory */
d356 1
d358 2
a359 1
	 * Validate PTEs for kernel text (RO)
d362 1
a362 1
	epte = &pte[m68k_btop(m68k_trunc_page(&etext))];
d368 1
a368 1
	*pte++ = firstpa | PG_NV;		/* make *NULL fail in the kernel */
d382 2
a383 1
	 * Enable copy-back caching of data pages
d387 2
d396 4
a399 8
	if (RELOC(mmutype, int) == MMU_68040)
		while (pte < epte) {
			*pte = (*pte & ~PG_CMASK) | PG_CIS | PG_U;
			pte++;
		} else
		while (pte < epte) {
			*pte++ |= PG_CI;
		}
d404 4
d411 1
a411 1
	protopte = RELOC(iiomapbase, int) | PG_RW | PG_CI | PG_V | PG_U;
d424 1
a424 1
	(st_entry_t *)(kstpa - firstpa);
d429 1
a429 1
	(pt_entry_t *)(kptmpa - firstpa);
d435 1
a435 1
	(pt_entry_t *)m68k_ptob(nptpages * NPTEPG);
d438 2
a439 2
	 * iiomapsize pages prior to external IO space at end of static
	 * kernel page table.
d441 4
a444 4
	RELOC(intiobase, char *) = (char *)
										m68k_ptob(nptpages*NPTEPG - (RELOC(iiomapsize, int)+EIOMAPSIZE));
	RELOC(intiolimit, char *) = (char *)
										 m68k_ptob(nptpages*NPTEPG - EIOMAPSIZE);
d450 1
a450 1
	(char *)m68k_ptob(nptpages*NPTEPG - EIOMAPSIZE);
d472 29
a500 9
	 */
	RELOC(avail_start, vm_offset_t) = nextpa;
	RELOC(avail_end, vm_offset_t) = m68k_ptob(RELOC(maxmem, int))
	   /* XXX allow for msgbuf */
	   - m68k_round_page(sizeof(struct msgbuf));
	RELOC(mem_size, vm_size_t) = m68k_ptob(RELOC(physmem, int));
	RELOC(virtual_avail, vm_offset_t) =
	VM_MIN_KERNEL_ADDRESS + (nextpa - firstpa);
	RELOC(virtual_end, vm_offset_t) = VM_MAX_KERNEL_ADDRESS;
d534 1
a534 1
		 * For the 040 we also initialize the free level 2
d540 3
a542 3
		if (RELOC(mmutype, int) == MMU_68040) {
			register int num;

d545 1
a545 1
							  SG4_LEV2SIZE) / SG4_LEV2SIZE;
d550 2
a551 2
				 num < sizeof(kpm->pm_stfree)*NBBY;
				 num++)
d560 1
a560 1
		vm_offset_t va = RELOC(virtual_avail, vm_offset_t);
a567 2
		RELOC(ledbase, caddr_t) = (caddr_t)va;
		va += NBPG;
d569 2
a570 2
		va += NBPG;
		RELOC(virtual_avail, vm_offset_t) = va;
@


1.11
log
@Remove the ugly protection_codes[] array, only used by the pte_prot()
macro, by a different version of the aforementioned macro.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap_bootstrap.c,v 1.10 2001/11/30 20:58:18 miod Exp $ */
d94 1
d403 19
d826 19
a896 19
}

void
pmap_init_md()
{
	vaddr_t		addr;

	/*
	 * mark as unavailable the regions which we have mapped in
	 * pmap_bootstrap().
	 */
	addr = (vaddr_t) intiobase;
	if (uvm_map(kernel_map, &addr,
		    m68k_ptob(iiomapsize+EIOMAPSIZE),
		    NULL, UVM_UNKNOWN_OFFSET, 0,
		    UVM_MAPFLAG(UVM_PROT_NONE, UVM_PROT_NONE,
				UVM_INH_NONE, UVM_ADV_RANDOM,
				UVM_FLAG_FIXED)))
		panic("pmap_init: bogons in the VM system!\n");
@


1.11.2.1
log
@Merge in -current, builds on i386, otherwise untested
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap_bootstrap.c,v 1.12 2001/12/20 19:02:29 miod Exp $ */
a93 1
extern int protection_codes[];
a401 19
	 * Initialize protection array.
	 * XXX don't use a switch statement, it might produce an
	 * absolute "jmp" table.
	 */
	{
		register int *kp;

		kp = &RELOC(protection_codes, int);
		kp[VM_PROT_NONE|VM_PROT_NONE|VM_PROT_NONE] = 0;
		kp[VM_PROT_READ|VM_PROT_NONE|VM_PROT_NONE] = PG_RO;
		kp[VM_PROT_READ|VM_PROT_NONE|VM_PROT_EXECUTE] = PG_RO;
		kp[VM_PROT_NONE|VM_PROT_NONE|VM_PROT_EXECUTE] = PG_RO;
		kp[VM_PROT_NONE|VM_PROT_WRITE|VM_PROT_NONE] = PG_RW;
		kp[VM_PROT_NONE|VM_PROT_WRITE|VM_PROT_EXECUTE] = PG_RW;
		kp[VM_PROT_READ|VM_PROT_WRITE|VM_PROT_NONE] = PG_RW;
		kp[VM_PROT_READ|VM_PROT_WRITE|VM_PROT_EXECUTE] = PG_RW;
	}

	/*
a805 19
	 * Initialize protection array.
	 * XXX don't use a switch statement, it might produce an
	 * absolute "jmp" table.
	 */
	{
		register int *kp;

		kp = &RELOC(protection_codes, int);
		kp[VM_PROT_NONE|VM_PROT_NONE|VM_PROT_NONE] = 0;
		kp[VM_PROT_READ|VM_PROT_NONE|VM_PROT_NONE] = PG_RO;
		kp[VM_PROT_READ|VM_PROT_NONE|VM_PROT_EXECUTE] = PG_RO;
		kp[VM_PROT_NONE|VM_PROT_NONE|VM_PROT_EXECUTE] = PG_RO;
		kp[VM_PROT_NONE|VM_PROT_WRITE|VM_PROT_NONE] = PG_RW;
		kp[VM_PROT_NONE|VM_PROT_WRITE|VM_PROT_EXECUTE] = PG_RW;
		kp[VM_PROT_READ|VM_PROT_WRITE|VM_PROT_NONE] = PG_RW;
		kp[VM_PROT_READ|VM_PROT_WRITE|VM_PROT_EXECUTE] = PG_RW;
	}

	/*
d858 19
@


1.11.2.2
log
@Sync UBC branch to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap_bootstrap.c,v 1.11.2.1 2002/01/31 22:55:16 niklas Exp $ */
a73 3

#include <machine/cpu.h>
#include <machine/frame.h>
d76 2
d81 5
d88 79
a166 56
#define	ETHERPAGES	16
void *etherbuf;
int etherlen;

extern char *extiobase;
extern int maxmem;

#define	RELOC(v, t)	*((t*)((u_int)&(v) + firstpa))
#define	PA2VA(v, t)	*((t*)((u_int)&(v)))

#define	MACHINE_IIOMAPSIZE	RELOC(iiomapsize, int)
#define	MACHINE_INTIOBASE	RELOC(iiomapbase, int)
#define	MACHINE_EIOMAPSIZE	EIOMAPSIZE

#define	PMAP_MD_LOCALS		/* nothing */

#define	PMAP_MD_RELOC1() \
do { \
	RELOC(etherbuf, void *) = (void *)nextpa; \
	nextpa += ETHERPAGES * NBPG; \
} while (0)

#define	PMAP_MD_MAPIOSPACE() \
do { \
	pte = &((u_int *)kptpa)[m68k_btop(etherbuf)]; \
	epte = pte + ETHERPAGES; \
	while (pte < epte) { \
		*pte = (*pte & ~PG_CMASK) | PG_CIS | PG_U; \
		pte++; \
	} \
	RELOC(etherlen, int) = ETHERPAGES * NBPG; \
} while (0)

	/*
	 * intiobase, intiolimit: base and end of internal IO space.
	 * MACHINE_IIOMAPSIZE pages prior to external IO space at end of
	 * static kernel page table.
	 * extiobase: base of external IO space.
	 * MACHINE_EIOMAPSIZE pages at the end of the static kernel page table.
	 */
#define	PMAP_MD_RELOC2() \
do { \
	RELOC(intiobase, char *) = \
	    (char *)m68k_ptob(nptpages * NPTEPG - \
	        (MACHINE_IIOMAPSIZE + MACHINE_EIOMAPSIZE)); \
	RELOC(intiolimit, char *) = \
	    (char *)m68k_ptob(nptpages * NPTEPG - MACHINE_EIOMAPSIZE); \
	RELOC(extiobase, char *) = \
	    (char *)m68k_ptob(nptpages * NPTEPG - MACHINE_EIOMAPSIZE); \
} while (0)

#define	PMAP_MD_MEMSIZE() \
do { \
	RELOC(avail_end, paddr_t) = m68k_ptob(RELOC(maxmem, int)) - \
	    (round_page(MSGBUFSIZE) + m68k_ptob(1)); \
} while (0)
d168 259
a426 1
#define	PMAP_MD_RELOC3()	/* nothing */
d428 27
a454 1
#include <m68k/m68k/pmap_bootstrap.c>
d456 31
d488 3
a490 1
pmap_init_md()
d492 332
a823 1
	vaddr_t         addr;
d826 3
a828 2
	 * mark as unavailable the regions which we have mapped in
	 * pmap_bootstrap().
d830 67
a896 6
	addr = (vaddr_t) intiobase;
	if (uvm_map(kernel_map, &addr, m68k_ptob(iiomapsize+EIOMAPSIZE),
	    NULL, UVM_UNKNOWN_OFFSET, 0,
	    UVM_MAPFLAG(UVM_PROT_NONE, UVM_PROT_NONE,
	      UVM_INH_NONE, UVM_ADV_RANDOM, UVM_FLAG_FIXED)))
		panic("pmap_init: bogons in the VM system!\n");
@


1.11.2.3
log
@sync to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap_bootstrap.c,v 1.11.2.2 2002/06/11 03:36:50 art Exp $ */
d159 1
a159 1
		panic("pmap_init: bogons in the VM system!");
@


1.10
log
@Switch to pmap_motorola.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap_bootstrap.c,v 1.9 2001/11/25 18:13:37 miod Exp $ */
a93 1
extern int protection_codes[];
a401 19
	 * Initialize protection array.
	 * XXX don't use a switch statement, it might produce an
	 * absolute "jmp" table.
	 */
	{
		register int *kp;

		kp = &RELOC(protection_codes, int);
		kp[VM_PROT_NONE|VM_PROT_NONE|VM_PROT_NONE] = 0;
		kp[VM_PROT_READ|VM_PROT_NONE|VM_PROT_NONE] = PG_RO;
		kp[VM_PROT_READ|VM_PROT_NONE|VM_PROT_EXECUTE] = PG_RO;
		kp[VM_PROT_NONE|VM_PROT_NONE|VM_PROT_EXECUTE] = PG_RO;
		kp[VM_PROT_NONE|VM_PROT_WRITE|VM_PROT_NONE] = PG_RW;
		kp[VM_PROT_NONE|VM_PROT_WRITE|VM_PROT_EXECUTE] = PG_RW;
		kp[VM_PROT_READ|VM_PROT_WRITE|VM_PROT_NONE] = PG_RW;
		kp[VM_PROT_READ|VM_PROT_WRITE|VM_PROT_EXECUTE] = PG_RW;
	}

	/*
a803 19

	/*
	 * Initialize protection array.
	 * XXX don't use a switch statement, it might produce an
	 * absolute "jmp" table.
	 */
	{
		register int *kp;

		kp = &RELOC(protection_codes, int);
		kp[VM_PROT_NONE|VM_PROT_NONE|VM_PROT_NONE] = 0;
		kp[VM_PROT_READ|VM_PROT_NONE|VM_PROT_NONE] = PG_RO;
		kp[VM_PROT_READ|VM_PROT_NONE|VM_PROT_EXECUTE] = PG_RO;
		kp[VM_PROT_NONE|VM_PROT_NONE|VM_PROT_EXECUTE] = PG_RO;
		kp[VM_PROT_NONE|VM_PROT_WRITE|VM_PROT_NONE] = PG_RW;
		kp[VM_PROT_NONE|VM_PROT_WRITE|VM_PROT_EXECUTE] = PG_RW;
		kp[VM_PROT_READ|VM_PROT_WRITE|VM_PROT_NONE] = PG_RW;
		kp[VM_PROT_READ|VM_PROT_WRITE|VM_PROT_EXECUTE] = PG_RW;
	}
@


1.9
log
@Remove comments which only apply to the HP MMU found on HP300 models
318, 319, 320 and 350, which bear no sense in the mvme68k world.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap_bootstrap.c,v 1.8 2001/11/06 19:53:15 miod Exp $ */
d363 2
a364 4
	RELOC(intiobase, char *) = (char *)
										m68k_ptob(nptpages*NPTEPG - (RELOC(iiomapsize, int)+EIOMAPSIZE));
	RELOC(intiolimit, char *) = (char *)
										 m68k_ptob(nptpages*NPTEPG - EIOMAPSIZE);
d897 19
@


1.8
log
@Replace inclusion of <vm/foo.h> with the correct <uvm/bar.h> when necessary.
(Look ma, I might have broken the tree)
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap_bootstrap.c,v 1.7 2001/04/05 20:39:40 deraadt Exp $ */
a329 4
	 * We do this here since the 320/350 MMU registers (also
	 * used, but to a lesser extent, on other models) are mapped
	 * in this range and it would be nice to be able to access
	 * them after the MMU is turned on.
a752 4
	 * We do this here since the 320/350 MMU registers (also
	 * used, but to a lesser extent, on other models) are mapped
	 * in this range and it would be nice to be able to access
	 * them after the MMU is turned on.
@


1.7
log
@undo changes which did not even compile
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap_bootstrap.c,v 1.5 2000/02/22 19:27:54 deraadt Exp $ */
d79 1
a79 1
#include <vm/vm.h>
@


1.6
log
@Initial code for UVM.  not tested yet...
@
text
@d367 4
a370 4
	RELOC(intiobase, char *) = 
		(char *)m68k_ptob(nptpages*NPTEPG - (RELOC(iiomapsize, int)+EIOMAPSIZE));
	RELOC(intiolimit, char *) = 
		(char *)m68k_ptob(nptpages*NPTEPG - EIOMAPSIZE);
@


1.5
log
@enlarge msgbuf, somewhat line netbsd did
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap_bootstrap.c,v 1.4 2000/01/06 03:21:43 smurph Exp $ */
d367 4
a370 4
	RELOC(intiobase, char *) = (char *)
										m68k_ptob(nptpages*NPTEPG - (RELOC(iiomapsize, int)+EIOMAPSIZE));
	RELOC(intiolimit, char *) = (char *)
										 m68k_ptob(nptpages*NPTEPG - EIOMAPSIZE);
@


1.4
log
@Added support for MVME177 (mc68060)
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap_bootstrap.c,v 1.3 1996/04/28 10:59:08 deraadt Exp $ */
a105 1
struct msgbuf  *msgbufp;
d402 1
a402 1
	   - m68k_round_page(sizeof(struct msgbuf));
d477 1
a477 1
		va += NBPG;
@


1.4.2.1
log
@Sync with -current
@
text
@d1 1
a1 1
/*	$OpenBSD$ */
d106 1
d403 1
a403 1
	   - m68k_round_page(MSGBUFSIZE);
d478 1
a478 1
		va += MSGBUFSIZE;
@


1.4.2.2
log
@Update the SMP branch to -current, this breaks the SMP branch though.
But it will be fixed soonish.  Note, nothing new has happened, this is just
a merge of the trunk into this branch.
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap_bootstrap.c,v 1.7 2001/04/05 20:39:40 deraadt Exp $ */
@


1.4.2.3
log
@Merge in -current
@
text
@d1 1
a1 1
/*	$OpenBSD$ */
d79 1
a79 1
#include <uvm/uvm_extern.h>
@


1.4.2.4
log
@Merge in -current
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap_bootstrap.c,v 1.4.2.3 2001/11/13 21:04:14 niklas Exp $ */
d330 4
d367 4
a370 2
	RELOC(intiobase, char *) = (char *)m68k_ptob(nptpages*NPTEPG - (RELOC(iiomapsize, int)+EIOMAPSIZE));
	RELOC(intiolimit, char *) = (char *)m68k_ptob(nptpages*NPTEPG - EIOMAPSIZE);
d757 4
a906 19
}

void
pmap_init_md()
{
	vaddr_t		addr;

	/*
	 * mark as unavailable the regions which we have mapped in
	 * pmap_bootstrap().
	 */
	addr = (vaddr_t) intiobase;
	if (uvm_map(kernel_map, &addr,
		    m68k_ptob(iiomapsize+EIOMAPSIZE),
		    NULL, UVM_UNKNOWN_OFFSET, 0,
		    UVM_MAPFLAG(UVM_PROT_NONE, UVM_PROT_NONE,
				UVM_INH_NONE, UVM_ADV_RANDOM,
				UVM_FLAG_FIXED)))
		panic("pmap_init: bogons in the VM system!\n");
@


1.4.2.5
log
@Merge in trunk
@
text
@d1 1
a1 1
/*	$OpenBSD$ */
a73 3

#include <machine/cpu.h>
#include <machine/frame.h>
d76 2
d81 5
d88 250
a337 56
#define	ETHERPAGES	16
void *etherbuf;
int etherlen;

extern char *extiobase;
extern int maxmem;

#define	RELOC(v, t)	*((t*)((u_int)&(v) + firstpa))
#define	PA2VA(v, t)	*((t*)((u_int)&(v)))

#define	MACHINE_IIOMAPSIZE	RELOC(iiomapsize, int)
#define	MACHINE_INTIOBASE	RELOC(iiomapbase, int)
#define	MACHINE_EIOMAPSIZE	EIOMAPSIZE

#define	PMAP_MD_LOCALS		/* nothing */

#define	PMAP_MD_RELOC1() \
do { \
	RELOC(etherbuf, void *) = (void *)nextpa; \
	nextpa += ETHERPAGES * NBPG; \
} while (0)

#define	PMAP_MD_MAPIOSPACE() \
do { \
	pte = &((u_int *)kptpa)[m68k_btop(etherbuf)]; \
	epte = pte + ETHERPAGES; \
	while (pte < epte) { \
		*pte = (*pte & ~PG_CMASK) | PG_CIS | PG_U; \
		pte++; \
	} \
	RELOC(etherlen, int) = ETHERPAGES * NBPG; \
} while (0)

	/*
	 * intiobase, intiolimit: base and end of internal IO space.
	 * MACHINE_IIOMAPSIZE pages prior to external IO space at end of
	 * static kernel page table.
	 * extiobase: base of external IO space.
	 * MACHINE_EIOMAPSIZE pages at the end of the static kernel page table.
	 */
#define	PMAP_MD_RELOC2() \
do { \
	RELOC(intiobase, char *) = \
	    (char *)m68k_ptob(nptpages * NPTEPG - \
	        (MACHINE_IIOMAPSIZE + MACHINE_EIOMAPSIZE)); \
	RELOC(intiolimit, char *) = \
	    (char *)m68k_ptob(nptpages * NPTEPG - MACHINE_EIOMAPSIZE); \
	RELOC(extiobase, char *) = \
	    (char *)m68k_ptob(nptpages * NPTEPG - MACHINE_EIOMAPSIZE); \
} while (0)

#define	PMAP_MD_MEMSIZE() \
do { \
	RELOC(avail_end, paddr_t) = m68k_ptob(RELOC(maxmem, int)) - \
	    (round_page(MSGBUFSIZE) + m68k_ptob(1)); \
} while (0)
d339 545
a883 1
#define	PMAP_MD_RELOC3()	/* nothing */
d885 13
a897 1
#include <m68k/m68k/pmap_bootstrap.c>
d902 1
a902 1
	vaddr_t         addr;
d909 6
a914 4
	if (uvm_map(kernel_map, &addr, m68k_ptob(iiomapsize+EIOMAPSIZE),
	    NULL, UVM_UNKNOWN_OFFSET, 0,
	    UVM_MAPFLAG(UVM_PROT_NONE, UVM_PROT_NONE,
	      UVM_INH_NONE, UVM_ADV_RANDOM, UVM_FLAG_FIXED)))
@


1.4.2.6
log
@Sync the SMP branch with 3.3
@
text
@d159 1
a159 1
		panic("pmap_init: bogons in the VM system!");
@


1.4.2.7
log
@Sync SMP branch to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: pmap_bootstrap.c,v 1.4.2.6 2003/03/27 23:32:17 niklas Exp $ */
d15 6
d49 5
a53 1
 * 3. Neither the name of the University nor the names of its contributors
@


1.3
log
@add OpenBSD header
@
text
@d1 1
a1 1
/*	$OpenBSD$ */
d5 1
d105 2
a106 2
caddr_t		CADDR1, CADDR2, vmmap, ledbase;
struct msgbuf	*msgbufp;
d108 374
a481 2
void	*etherbuf;
int	etherlen;
d496 2
a497 2
	vm_offset_t nextpa;
	register vm_offset_t firstpa;
d540 1
a540 1
		(RELOC(iiomapsize, int) + EIOMAPSIZE + NPTEPG - 1) / NPTEPG;
d644 1
a644 1
		protopte = kptpa | PG_RW | PG_CI | PG_V;
d657 1
a657 1
		*pte = lkptpa | PG_RW | PG_CI | PG_V;
d701 1
a701 1
	*pte = MAXADDR | PG_RW | PG_CI | PG_V;
d710 1
a710 1
		*pte++ = PG_NV;
d717 1
a717 1
	protopte = firstpa | PG_RW | PG_V;	/* XXX RW for now */
d719 1
a719 1
	protopte = firstpa | PG_RO | PG_V;
d733 1
a733 1
	protopte = (protopte & ~PG_PROT) | PG_RW;
d748 1
a748 1
			*pte = (*pte & ~PG_CMASK) | PG_CIS;
d750 1
a750 2
		}
	else
d765 1
a765 1
	protopte = RELOC(iiomapbase, int) | PG_RW | PG_CI | PG_V;
d778 1
a778 1
		(st_entry_t *)(kstpa - firstpa);
d783 1
a783 1
		(pt_entry_t *)(kptmpa - firstpa);
d789 1
a789 1
		(pt_entry_t *)m68k_ptob(nptpages * NPTEPG);
d796 1
a796 1
		m68k_ptob(nptpages*NPTEPG - (RELOC(iiomapsize, int)+EIOMAPSIZE));
d798 1
a798 1
		m68k_ptob(nptpages*NPTEPG - EIOMAPSIZE);
d804 1
a804 1
		(char *)m68k_ptob(nptpages*NPTEPG - EIOMAPSIZE);
d828 3
a830 4
	RELOC(avail_end, vm_offset_t) =
		m68k_ptob(RELOC(maxmem, int))
			/* XXX allow for msgbuf */
			- m68k_round_page(sizeof(struct msgbuf));
d833 1
a833 1
		VM_MIN_KERNEL_ADDRESS + (nextpa - firstpa);
d876 1
a876 1
			
d879 1
a879 1
				      SG4_LEV2SIZE) / SG4_LEV2SIZE;
d884 2
a885 2
			     num < sizeof(kpm->pm_stfree)*NBBY;
			     num++)
@


1.2
log
@$Id$ throughout
update many copyrights
@
text
@d1 1
a1 1
/*	$Id$ */
@


1.1
log
@Initial revision
@
text
@d1 1
a1 1
/*	$NetBSD: pmap_bootstrap.c,v 1.1.1.1 1995/07/25 23:12:02 chuck Exp $	*/
d4 29
a73 1
#include <mvme68k/mvme68k/clockreg.h>
d76 1
d85 2
a93 3
#ifdef HAVEVAC
extern int pmap_aliasmask;
#endif
d106 3
a108 1
extern void *ledatabuf; /* XXXCDC */
d141 1
a141 1
	 *			PT pages		IIOMAPSIZE pages
d146 1
a146 1
	 * [ Sysptsize is the number of pages of PT, IIOMAPSIZE and
d167 1
a167 1
		(IIOMAPSIZE + EIOMAPSIZE + NPTEPG - 1) / NPTEPG;
d170 1
a170 1
	iiopa = eiopa - IIOMAPSIZE * sizeof(pt_entry_t);
d177 3
a179 4
	{ /* XXXCDC */
		ledatabuf = (void *)nextpa;
		nextpa += 4 * NBPG;
	} /* XXXCDC */
d276 7
d348 2
a369 2
	{ /* XXXCDC -- uncache lebuf */
		u_int *lepte = &((u_int *)kptpa)[m68k_btop(ledatabuf)];
d371 12
a382 5
		lepte[0] = lepte[0] | PG_CI;
		lepte[1] = lepte[1] | PG_CI;
		lepte[2] = lepte[2] | PG_CI;
		lepte[3] = lepte[3] | PG_CI;
	} /* XXXCDC yuck */
d393 1
a393 1
	protopte = INTIOBASE | PG_RW | PG_CI | PG_V;
d420 1
a420 1
	 * IIOMAPSIZE pages prior to external IO space at end of static
d423 4
a426 4
	RELOC(intiobase, char *) =
		(char *)m68k_ptob(nptpages*NPTEPG - (IIOMAPSIZE+EIOMAPSIZE));
	RELOC(intiolimit, char *) =
		(char *)m68k_ptob(nptpages*NPTEPG - EIOMAPSIZE);
a463 11

#ifdef HAVEVAC
	/*
	 * Determine VA aliasing distance if any
	 */
	if (RELOC(ectype, int) == EC_VIRT)
		if (RELOC(machineid, int) == HP_320)
			RELOC(pmap_aliasmask, int) = 0x3fff;	/* 16k */
		else if (RELOC(machineid, int) == HP_350)
			RELOC(pmap_aliasmask, int) = 0x7fff;	/* 32k */
#endif
@


1.1.1.1
log
@initial import of NetBSD tree
@
text
@@


1.1.1.2
log
@mvme68k port by me. some parts by dale rahn.
@
text
@d1 1
a1 1
/*	$NetBSD: pmap_bootstrap.c,v 1.6 1995/05/12 12:54:56 mycroft Exp $	*/
a3 1
 * Copyright (c) 1995 Theo de Raadt
d45 1
a47 1
#include <machine/autoconf.h>
a55 2
char *iiomapbase;
int iiomapsize;
d63 3
d78 1
a78 3
#define ETHERPAGES 16
void	*etherbuf;
int	etherlen;
d111 1
a111 1
	 *			PT pages		iiomapsize pages
d116 1
a116 1
	 * [ Sysptsize is the number of pages of PT, iiomapsize and
d137 1
a137 1
		(RELOC(iiomapsize, int) + EIOMAPSIZE + NPTEPG - 1) / NPTEPG;
d140 1
a140 1
	iiopa = eiopa - RELOC(iiomapsize, int) * sizeof(pt_entry_t);
d147 4
a150 3

	RELOC(etherbuf, void *) = (void *)nextpa;
	nextpa += ETHERPAGES * NBPG;
a246 7
		/*
		 * Invalidate all but the last remaining entries in both.
		 */
		epte = &((u_int *)kptmpa)[NPTEPG-1];
		while (pte < epte) {
			*pte++ = PG_NV;
		}
a311 2
	*pte++ = firstpa | PG_NV;		/* make *NULL fail in the kernel */
	protopte += NBPG;
d332 2
d335 5
a339 12
	pte = &((u_int *)kptpa)[m68k_btop(etherbuf)];
	epte = pte + ETHERPAGES;
	if (RELOC(mmutype, int) == MMU_68040)
		while (pte < epte) {
			*pte = (*pte & ~PG_CMASK) | PG_CIS;
			pte++;
		}
	else
		while (pte < epte) {
			*pte++ |= PG_CI;
		}
	RELOC(etherlen, int) = ETHERPAGES * NBPG;
d350 1
a350 1
	protopte = RELOC(iiomapbase, int) | PG_RW | PG_CI | PG_V;
d377 1
a377 1
	 * iiomapsize pages prior to external IO space at end of static
d380 4
a383 4
	RELOC(intiobase, char *) = (char *)
		m68k_ptob(nptpages*NPTEPG - (RELOC(iiomapsize, int)+EIOMAPSIZE));
	RELOC(intiolimit, char *) = (char *)
		m68k_ptob(nptpages*NPTEPG - EIOMAPSIZE);
d421 11
@
