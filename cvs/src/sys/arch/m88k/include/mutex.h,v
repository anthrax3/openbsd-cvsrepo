head	1.4;
access;
symbols
	OPENBSD_6_1:1.4.0.8
	OPENBSD_6_1_BASE:1.4
	OPENBSD_6_0:1.4.0.6
	OPENBSD_6_0_BASE:1.4
	OPENBSD_5_9:1.4.0.2
	OPENBSD_5_9_BASE:1.4
	OPENBSD_5_8:1.4.0.4
	OPENBSD_5_8_BASE:1.4
	OPENBSD_5_7:1.2.0.2
	OPENBSD_5_7_BASE:1.2
	OPENBSD_5_6:1.2.0.6
	OPENBSD_5_6_BASE:1.2
	OPENBSD_5_5:1.2.0.4
	OPENBSD_5_5_BASE:1.2
	OPENBSD_5_4:1.1.0.32
	OPENBSD_5_4_BASE:1.1
	OPENBSD_5_3:1.1.0.30
	OPENBSD_5_3_BASE:1.1
	OPENBSD_5_2:1.1.0.28
	OPENBSD_5_2_BASE:1.1
	OPENBSD_5_1_BASE:1.1
	OPENBSD_5_1:1.1.0.26
	OPENBSD_5_0:1.1.0.24
	OPENBSD_5_0_BASE:1.1
	OPENBSD_4_9:1.1.0.22
	OPENBSD_4_9_BASE:1.1
	OPENBSD_4_8:1.1.0.20
	OPENBSD_4_8_BASE:1.1
	OPENBSD_4_7:1.1.0.14
	OPENBSD_4_7_BASE:1.1
	OPENBSD_4_6:1.1.0.18
	OPENBSD_4_6_BASE:1.1
	OPENBSD_4_5:1.1.0.16
	OPENBSD_4_5_BASE:1.1
	OPENBSD_4_4:1.1.0.12
	OPENBSD_4_4_BASE:1.1
	OPENBSD_4_3:1.1.0.10
	OPENBSD_4_3_BASE:1.1
	OPENBSD_4_2:1.1.0.8
	OPENBSD_4_2_BASE:1.1
	OPENBSD_4_1:1.1.0.6
	OPENBSD_4_1_BASE:1.1
	OPENBSD_4_0:1.1.0.4
	OPENBSD_4_0_BASE:1.1
	OPENBSD_3_9:1.1.0.2
	OPENBSD_3_9_BASE:1.1;
locks; strict;
comment	@ * @;


1.4
date	2015.07.03.15.12.49;	author miod;	state Exp;
branches;
next	1.3;
commitid	aKraD4sjb5ya2ZKN;

1.3
date	2015.07.02.08.58.16;	author dlg;	state Exp;
branches;
next	1.2;
commitid	eovibuKlujaJOO7o;

1.2
date	2014.02.02.20.31.10;	author kettenis;	state Exp;
branches;
next	1.1;

1.1
date	2005.12.03.19.01.14;	author miod;	state Exp;
branches;
next	;


desc
@@


1.4
log
@Rename mtx_cpu to mtx_owner for consistency with the other platforms.
@
text
@#ifndef _M88K_MUTEX_H_
#define _M88K_MUTEX_H_
/*	$OpenBSD: mutex.h,v 1.3 2015/07/02 08:58:16 dlg Exp $	*/

/*
 * Copyright (c) 2005, Miodrag Vallat.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 *
 * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR
 * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
 * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 * DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT,
 * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
 * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,
 * STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN
 * ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
 * POSSIBILITY OF SUCH DAMAGE.
 */

struct mutex {
	volatile int mtx_lock;	/* mutex.S relies upon this field being first */
	int mtx_wantipl;
	int mtx_oldipl;
	void *mtx_owner;
};

/*
 * To prevent lock ordering problems with the kernel lock, we need to
 * make sure we block all interrupts that can grab the kernel lock.
 * The simplest way to achieve this is to make sure mutexes always
 * raise the interrupt priority level to the highest level that has
 * interrupts that grab the kernel lock.
 */
#ifdef MULTIPROCESSOR
#define __MUTEX_IPL(ipl) \
    (((ipl) > IPL_NONE && (ipl) < IPL_TTY) ? IPL_TTY : (ipl))
#else
#define __MUTEX_IPL(ipl) (ipl)
#endif

#define	MUTEX_INITIALIZER(ipl)	{ 0, __MUTEX_IPL((ipl)), IPL_NONE, NULL }

void __mtx_init(struct mutex *, int);
#define mtx_init(mtx, ipl) __mtx_init((mtx), __MUTEX_IPL((ipl)))

#ifdef DIAGNOSTIC

#define MUTEX_ASSERT_LOCKED(mtx) do {					\
	if ((mtx)->mtx_owner != curcpu())				\
		panic("mutex %p not held in %s", (mtx), __func__);	\
} while (0)

#define MUTEX_ASSERT_UNLOCKED(mtx) do {					\
	if ((mtx)->mtx_owner == curcpu())				\
		panic("mutex %p held in %s", (mtx), __func__);		\
} while (0)

#else

#define	MUTEX_ASSERT_LOCKED(mtx)	do { /* nothing */ } while (0)
#define	MUTEX_ASSERT_UNLOCKED(mtx)	do { /* nothing */ } while (0)

#endif

#define MUTEX_OLDIPL(mtx)	(mtx)->mtx_oldipl

#endif	/* _M88K_MUTEX_H_ */
@


1.3
log
@copy MUTEX_ASSERT_LOCKED and MUTEX_ASSERT_UNLOCKED from alpha.

the previous asserts checked if the mutex was locked by any cpu or
not when they should have been checking if the current cpu has the
lock or not.

found by miod after i enabled pool_gc again.
ok miod@@
@
text
@d3 1
a3 1
/*	$OpenBSD: mutex.h,v 1.2 2014/02/02 20:31:10 kettenis Exp $	*/
d34 1
a34 1
	void *mtx_cpu;
@


1.2
log
@To prevent lock ordering problems with the kernel lock, we need to make sure
we block all interrupts that can grab the kernel lock.  The simplest way to
achieve this is to make sure mutexes always raise the ipl to the highest
level that has interrupts that grab the kernel lock.  This will allow us
to have "mpsafe" interrupt handlers at lower priority levels.

No change for non-MULTIPROCESSOR kernels.

ok miod@@
@
text
@d3 1
a3 1
/*	$OpenBSD: mutex.h,v 1.1 2005/12/03 19:01:14 miod Exp $	*/
d58 2
a59 3
#define	MUTEX_ASSERT_LOCKED(mtx)					\
do {									\
	if ((mtx)->mtx_lock == 0 || (mtx)->mtx_cpu != curcpu())		\
d63 2
a64 3
#define	MUTEX_ASSERT_UNLOCKED(mtx)					\
do {									\
	if ((mtx)->mtx_lock != 0)					\
@


1.1
log
@Fast __HAVE_MUTEX implementation for m88k platforms.
@
text
@d3 1
a3 1
/*	$OpenBSD$	*/
d37 18
a54 1
#define	MUTEX_INITIALIZER(ipl)		{ 0, (ipl), IPL_NONE, NULL }
@

