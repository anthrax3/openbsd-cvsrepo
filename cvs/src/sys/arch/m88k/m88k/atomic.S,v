head	1.6;
access;
symbols
	OPENBSD_6_0:1.6.0.10
	OPENBSD_6_0_BASE:1.6
	OPENBSD_5_9:1.6.0.6
	OPENBSD_5_9_BASE:1.6
	OPENBSD_5_8:1.6.0.8
	OPENBSD_5_8_BASE:1.6
	OPENBSD_5_7:1.6.0.2
	OPENBSD_5_7_BASE:1.6
	OPENBSD_5_6:1.6.0.4
	OPENBSD_5_6_BASE:1.6
	OPENBSD_5_5:1.4.0.6
	OPENBSD_5_5_BASE:1.4
	OPENBSD_5_4:1.4.0.2
	OPENBSD_5_4_BASE:1.4
	OPENBSD_5_3:1.3.0.2
	OPENBSD_5_3_BASE:1.3
	OPENBSD_5_2:1.2.0.16
	OPENBSD_5_2_BASE:1.2
	OPENBSD_5_1_BASE:1.2
	OPENBSD_5_1:1.2.0.14
	OPENBSD_5_0:1.2.0.12
	OPENBSD_5_0_BASE:1.2
	OPENBSD_4_9:1.2.0.10
	OPENBSD_4_9_BASE:1.2
	OPENBSD_4_8:1.2.0.8
	OPENBSD_4_8_BASE:1.2
	OPENBSD_4_7:1.2.0.2
	OPENBSD_4_7_BASE:1.2
	OPENBSD_4_6:1.2.0.6
	OPENBSD_4_6_BASE:1.2
	OPENBSD_4_5:1.2.0.4
	OPENBSD_4_5_BASE:1.2;
locks; strict;
comment	@# @;


1.6
date	2014.07.15.16.26.28;	author miod;	state Exp;
branches;
next	1.5;
commitid	SiPU1AgIqgtBqoaJ;

1.5
date	2014.07.13.08.13.07;	author miod;	state Exp;
branches;
next	1.4;
commitid	lmSSnHelCasYljEs;

1.4
date	2013.06.04.22.11.51;	author tedu;	state Exp;
branches;
next	1.3;

1.3
date	2013.01.05.11.20.56;	author miod;	state Exp;
branches;
next	1.2;

1.2
date	2009.02.20.23.35.32;	author miod;	state Exp;
branches;
next	1.1;

1.1
date	2009.02.20.20.40.01;	author miod;	state Exp;
branches;
next	;


desc
@@


1.6
log
@Fix stupid bug in atomic_{add,sub}_int_nv_mp, and stupider bug in
atomic_cas_uint_mp.
Also, make the interprocessor interlock the only thing on its cache line.
@
text
@/*	$OpenBSD: atomic.S,v 1.5 2014/07/13 08:13:07 miod Exp $	*/

/*
 * Copyright (c) 2009 Miodrag Vallat.
 *
 * Permission to use, copy, modify, and distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 */

#include <machine/asm.h>

#ifdef M88110
#define	CACHE_LINE	32
#else
#define	CACHE_LINE	16
#endif
	.data

/*
 * A __cpu_simple_lock_t used to provide the inter-processor interlock,
 * alone on its cache line.
 */
	.balign	CACHE_LINE
ASLOCAL(__atomic_interlock)
	.word	0
	.balign	CACHE_LINE

	.text

/*
 * Register usage in this file:
 *
 * r2 data address
 * r3 bits to set or clear
 * r4 argument / scratch
 * r5 return address
 * r6 interlock address
 * r7 psr upon entry
 * r8 active psr
 * r9 scratch
 */

ENTRY(atomic_setbits_int)
	or	%r5, %r1, %r0		/* save return address */
	bsr	_C_LABEL(__atomic_lock)

	ld	%r4, %r2, %r0
	or	%r4, %r4, %r3
	st	%r4, %r2, %r0

	br	_C_LABEL(__atomic_unlock)

ENTRY(atomic_clearbits_int)
	or	%r5, %r1, %r0		/* save return address */
	bsr	_C_LABEL(__atomic_lock)

	ld	%r4, %r2, %r0
	or	%r4, %r4, %r3
	xor	%r4, %r4, %r3		/* r4 &= ~r3 */
	st	%r4, %r2, %r0

	br	_C_LABEL(__atomic_unlock)

ENTRY(atomic_add_int_nv_mp)
	or	%r5, %r1, %r0		/* save return address */
	bsr	_C_LABEL(__atomic_lock)

	or	%r9, %r2, %r0
	ld	%r2, %r9, %r0
	addu	%r2, %r2, %r3
	st	%r2, %r9, %r0

	br	_C_LABEL(__atomic_unlock)

ENTRY(atomic_sub_int_nv_mp)
	or	%r5, %r1, %r0		/* save return address */
	bsr	_C_LABEL(__atomic_lock)

	or	%r9, %r2, %r0
	ld	%r2, %r9, %r0
	subu	%r2, %r2, %r3
	st	%r2, %r9, %r0

	br	_C_LABEL(__atomic_unlock)

ENTRY(atomic_cas_uint_mp)
	or	%r5, %r1, %r0		/* save return address */
	bsr	_C_LABEL(__atomic_lock)

	ld	%r9, %r2, %r0
	cmp	%r3, %r3, %r9
	bb0	eq,  %r3, 1f
	st	%r4, %r2, %r0
1:
	or	%r2, %r9, %r0

	br	_C_LABEL(__atomic_unlock)

ENTRY(atomic_swap_uint_mp)
	or	%r5, %r1, %r0		/* save return address */
	bsr	_C_LABEL(__atomic_lock)

	ld	%r4, %r2, %r0
	st	%r3, %r2, %r0
	or	%r2, %r4, %r0

	br	_C_LABEL(__atomic_unlock)

GLOBAL(__atomic_lock)

/*
 * If running a kernel with support for both 88100 and 88110 compiled-in
 * on a 88100 machine, the 88100 code (shorter) will be copied over in
 * vector_init().
 */

#ifdef M88110
ASLOCAL(__atomic_lock_88110)
	/*
	 * This is the 88110 version: disable shadowing and interrupts,
	 * then grab the interlock.
	 */

	or.u	%r6, %r0, %hi16(_ASM_LABEL(__atomic_interlock))
	or	%r6, %r6, %lo16(_ASM_LABEL(__atomic_interlock))

	ldcr	%r7, PSR
	set	%r8, %r7, 1<PSR_INTERRUPT_DISABLE_BIT>
	set	%r8, %r8, 1<PSR_SHADOW_FREEZE_BIT>
	stcr	%r8, PSR
	FLUSH_PIPELINE
1:
	or	%r9, %r0, 1	/* __SIMPLELOCK_LOCKED */
	xmem	%r9, %r6, %r0
	bcnd	eq0, %r9, 3f
2:
	ld	%r9, %r6, %r0
	bcnd	eq0, %r9, 1b
	br	2b
3:
	jmp	%r1
#endif

#ifdef M88100
GLOBAL(__atomic_lock_88100)
	/*
	 * This is the 88100 version: disable interrupts, then grab
	 * the interlock.
	 */

	or.u	%r6, %r0, %hi16(_ASM_LABEL(__atomic_interlock))
	or	%r6, %r6, %lo16(_ASM_LABEL(__atomic_interlock))

	ldcr	%r7, PSR
	set	%r8, %r7, 1<PSR_INTERRUPT_DISABLE_BIT>
	stcr	%r8, PSR
	FLUSH_PIPELINE

1:
	or	%r9, %r0, 1	/* __SIMPLELOCK_LOCKED */
	xmem	%r9, %r6, %r0
	bcnd	eq0, %r9, 3f
2:
	ld	%r9, %r6, %r0
	bcnd	eq0, %r9, 1b
	br	2b
3:
	jmp	%r1
GLOBAL(__atomic_lock_88100_end)
#endif

GLOBAL(__atomic_unlock)

/*
 * If running a kernel with support for both 88100 and 88110 compiled-in
 * on a 88100 machine, the 88100 code (shorter) will be copied over in
 * vector_init().
 */

#ifdef M88110
ASLOCAL(__atomic_unlock_88110)
	/*
	 * This is the 88110 version: release the interlock, set up
	 * exception registers to return to our caller with initial
	 * psr restored.
	 */

	st	%r0, %r6, %r0	/* release interlock */

	stcr	%r5, EXIP	/* return address */
	stcr	%r7, EPSR	/* original PSR */

	/*
	 * No need to workaround errata #18 (see m88110_user_rte in
	 * eh_common.S), as we are not returning to user mode.
	 */
	RTE
#endif

#ifdef M88100
GLOBAL(__atomic_unlock_88100)
	/*
	 * This is the 88100 version: release the interlock,
	 * restore psr and return to the caller.
	 */

	st	%r0, %r6, %r0	/* release interlock */

	stcr	%r7, PSR
	FLUSH_PIPELINE
	
	jmp	%r5
GLOBAL(__atomic_unlock_88100_end)
#endif
@


1.5
log
@Add missing atomic primitives and __sync_synchronize to let the kernel
compile again; tested by aoyama@@
@
text
@d1 1
a1 1
/*	$OpenBSD: atomic.S,v 1.4 2013/06/04 22:11:51 tedu Exp $	*/
d21 5
d29 2
a30 1
 * A __cpu_simple_lock_t used to provide the inter-processor interlock.
d32 1
d35 1
d79 1
a79 1
	addu	%r2, %r2, %r4
d90 1
a90 1
	subu	%r2, %r2, %r4
d101 1
a101 1
	bcnd	ne0, %r3, 1f
d133 3
a140 3

	or.u	%r6, %r0, %hi16(_ASM_LABEL(__atomic_interlock))
	or	%r6, %r6, %lo16(_ASM_LABEL(__atomic_interlock))
d160 3
a167 2
	or.u	%r6, %r0, %hi16(_ASM_LABEL(__atomic_interlock))
	or	%r6, %r6, %lo16(_ASM_LABEL(__atomic_interlock))
@


1.4
log
@comment fix: actually called __cpu_simple_lock_t
@
text
@d1 1
a1 1
/*	$OpenBSD: atomic.S,v 1.3 2013/01/05 11:20:56 miod Exp $	*/
d36 2
a37 2
 * r4 return address
 * r5 scratch
d41 1
d45 1
a45 1
	or	%r4, %r1, %r0		/* save return address */
d48 3
a50 3
	ld	%r5, %r2, %r0
	or	%r5, %r5, %r3
	st	%r5, %r2, %r0
d55 1
a55 1
	or	%r4, %r1, %r0		/* save return address */
d58 49
a106 4
	ld	%r5, %r2, %r0
	or	%r5, %r5, %r3
	xor	%r5, %r5, %r3		/* r5 &= ~r3 */
	st	%r5, %r2, %r0
d134 3
a136 3
	or	%r5, %r0, 1	/* __SIMPLELOCK_LOCKED */
	xmem	%r5, %r6, %r0
	bcnd	eq0, %r5, 3f
d138 2
a139 2
	ld	%r5, %r6, %r0
	bcnd	eq0, %r5, 1b
d160 3
a162 3
	or	%r5, %r0, 1	/* __SIMPLELOCK_LOCKED */
	xmem	%r5, %r6, %r0
	bcnd	eq0, %r5, 3f
d164 2
a165 2
	ld	%r5, %r6, %r0
	bcnd	eq0, %r5, 1b
d190 1
a190 1
	stcr	%r4, EXIP	/* return address */
d212 1
a212 1
	jmp	%r4
@


1.3
log
@Switch m88k ports to ELF.
@
text
@d1 1
a1 1
/*	$OpenBSD: atomic.S,v 1.2 2009/02/20 23:35:32 miod Exp $	*/
d24 1
a24 1
 * A __cpu_simplelock_t used to provide the inter-processor interlock.
@


1.2
log
@This should get me nominated for the ``stupidest bug of the year'' award.
@
text
@d1 1
a1 1
/*	$OpenBSD: atomic.S,v 1.1 2009/02/20 20:40:01 miod Exp $	*/
d44 1
a44 1
	or	r4, r1, r0		/* save return address */
d47 3
a49 3
	ld	r5, r2, r0
	or	r5, r5, r3
	st	r5, r2, r0
d54 1
a54 1
	or	r4, r1, r0		/* save return address */
d57 4
a60 4
	ld	r5, r2, r0
	or	r5, r5, r3
	xor	r5, r5, r3		/* r5 &= ~r3 */
	st	r5, r2, r0
d79 4
a82 4
	ldcr	r7, PSR
	set	r8, r7, 1<PSR_INTERRUPT_DISABLE_BIT>
	set	r8, r8, 1<PSR_SHADOW_FREEZE_BIT>
	stcr	r8, PSR
d85 2
a86 2
	or.u	r6, r0, hi16(_ASM_LABEL(__atomic_interlock))
	or	r6, r6, lo16(_ASM_LABEL(__atomic_interlock))
d88 3
a90 3
	or	r5, r0, 1	/* __SIMPLELOCK_LOCKED */
	xmem	r5, r6, r0
	bcnd	eq0, r5, 3f
d92 2
a93 2
	ld	r5, r6, r0
	bcnd	eq0, r5, 1b
d96 1
a96 1
	jmp	r1
d106 3
a108 3
	ldcr	r7, PSR
	set	r8, r7, 1<PSR_INTERRUPT_DISABLE_BIT>
	stcr	r8, PSR
d111 2
a112 2
	or.u	r6, r0, hi16(_ASM_LABEL(__atomic_interlock))
	or	r6, r6, lo16(_ASM_LABEL(__atomic_interlock))
d114 3
a116 3
	or	r5, r0, 1	/* __SIMPLELOCK_LOCKED */
	xmem	r5, r6, r0
	bcnd	eq0, r5, 3f
d118 2
a119 2
	ld	r5, r6, r0
	bcnd	eq0, r5, 1b
d122 1
a122 1
	jmp	r1
d142 1
a142 1
	st	r0, r6, r0	/* release interlock */
d144 2
a145 2
	stcr	r4, EXIP	/* return address */
	stcr	r7, EPSR	/* original PSR */
d161 1
a161 1
	st	r0, r6, r0	/* release interlock */
d163 1
a163 1
	stcr	r7, PSR
d166 1
a166 1
	jmp	r4
@


1.1
log
@atomic_{set,clear}bits_int were not safe enough on 88110 systems, as they
can be interrupted by NMI; move the SMP version of these routines from
inlines to a separate file (kernel text shrinks 20KB...).

Since the implementation for 88110 becomes really hairy, the pre-main() code
is responsible for copying the appropriate code over for kernels configured
for both 88100 and 88110 cpus, to avoid having to choose the atomicity
strategy at runtime. Hairy, I said.

This gets GENERIC.MP run much further on 197DP. Not enough to reach multiuser
mode, but boots up to starting sshd and then panics.
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d87 1
a88 1
1:
d113 1
a114 1
1:
@

