head	1.16;
access;
symbols
	OPENBSD_6_2_BASE:1.16
	OPENBSD_6_1:1.15.0.6
	OPENBSD_6_1_BASE:1.15
	OPENBSD_6_0:1.15.0.2
	OPENBSD_6_0_BASE:1.15
	OPENBSD_5_9:1.14.0.2
	OPENBSD_5_9_BASE:1.14
	OPENBSD_5_8:1.14.0.4
	OPENBSD_5_8_BASE:1.14
	OPENBSD_5_7:1.13.0.2
	OPENBSD_5_7_BASE:1.13
	OPENBSD_5_6:1.13.0.6
	OPENBSD_5_6_BASE:1.13
	OPENBSD_5_5:1.13.0.4
	OPENBSD_5_5_BASE:1.13
	OPENBSD_5_4:1.12.0.4
	OPENBSD_5_4_BASE:1.12
	OPENBSD_5_3:1.12.0.2
	OPENBSD_5_3_BASE:1.12
	OPENBSD_5_2:1.11.0.6
	OPENBSD_5_2_BASE:1.11
	OPENBSD_5_1_BASE:1.11
	OPENBSD_5_1:1.11.0.4
	OPENBSD_5_0:1.11.0.2
	OPENBSD_5_0_BASE:1.11
	OPENBSD_4_9:1.9.0.2
	OPENBSD_4_9_BASE:1.9
	OPENBSD_4_8:1.8.0.4
	OPENBSD_4_8_BASE:1.8
	OPENBSD_4_7:1.8.0.2
	OPENBSD_4_7_BASE:1.8
	OPENBSD_4_6:1.7.0.4
	OPENBSD_4_6_BASE:1.7
	OPENBSD_4_5:1.5.0.8
	OPENBSD_4_5_BASE:1.5
	OPENBSD_4_4:1.5.0.4
	OPENBSD_4_4_BASE:1.5
	OPENBSD_4_3:1.5.0.2
	OPENBSD_4_3_BASE:1.5
	OPENBSD_4_2:1.4.0.2
	OPENBSD_4_2_BASE:1.4
	OPENBSD_4_1:1.2.0.2
	OPENBSD_4_1_BASE:1.2
	OPENBSD_4_0:1.1.0.4
	OPENBSD_4_0_BASE:1.1
	OPENBSD_3_9:1.1.0.2
	OPENBSD_3_9_BASE:1.1;
locks; strict;
comment	@# @;


1.16
date	2017.04.20.13.57.30;	author visa;	state Exp;
branches;
next	1.15;
commitid	RHJVP52IiQkInZzu;

1.15
date	2016.06.13.23.51.59;	author dlg;	state Exp;
branches;
next	1.14;
commitid	pePIrytkQAoqTKCZ;

1.14
date	2015.07.03.15.12.49;	author miod;	state Exp;
branches;
next	1.13;
commitid	aKraD4sjb5ya2ZKN;

1.13
date	2014.02.02.20.31.10;	author kettenis;	state Exp;
branches;
next	1.12;

1.12
date	2013.01.05.11.20.56;	author miod;	state Exp;
branches;
next	1.11;

1.11
date	2011.04.21.04.34.12;	author miod;	state Exp;
branches;
next	1.10;

1.10
date	2011.04.03.18.46.40;	author miod;	state Exp;
branches;
next	1.9;

1.9
date	2010.09.28.20.27.55;	author miod;	state Exp;
branches;
next	1.8;

1.8
date	2009.08.13.13.24.55;	author weingart;	state Exp;
branches;
next	1.7;

1.7
date	2009.04.27.21.48.56;	author kettenis;	state Exp;
branches;
next	1.6;

1.6
date	2009.04.25.20.14.43;	author weingart;	state Exp;
branches;
next	1.5;

1.5
date	2007.10.16.04.56.12;	author miod;	state Exp;
branches;
next	1.4;

1.4
date	2007.05.18.16.34.31;	author miod;	state Exp;
branches;
next	1.3;

1.3
date	2007.05.14.16.58.42;	author miod;	state Exp;
branches;
next	1.2;

1.2
date	2006.11.18.22.48.15;	author miod;	state Exp;
branches;
next	1.1;

1.1
date	2005.12.03.19.01.14;	author miod;	state Exp;
branches;
next	;


desc
@@


1.16
log
@Hook up mutex(9) to witness(4).
@
text
@/*	$OpenBSD: mutex.S,v 1.15 2016/06/13 23:51:59 dlg Exp $	*/

/*
 * Copyright (c) 2005, Miodrag Vallat.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 *
 * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR
 * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
 * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 * DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT,
 * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
 * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,
 * STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN
 * ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
 * POSSIBILITY OF SUCH DAMAGE.
 */

#include "assym.h"
#if MTX_LOCK != 0
#error	Lack of Humppa in mutex code
#endif

#include <machine/asm.h>

/*
 * void mtx_init(struct mutex *mtx, int ipl)
 */
ENTRY(__mtx_init)
	st	%r0, %r2, MTX_LOCK	/* mtx->mtx_lock = 0 */
	st	%r0, %r2, MTX_OLDIPL	/* mtx->mtx_oldipl = IPL_NONE */
	st	%r3, %r2, MTX_WANTIPL	/* mtx->mtx_wantipl = ipl */
	jmp.n	%r1
	 st	%r0, %r2, MTX_OWNER	/* mtx->mtx_owner = NULL */

/*
 * void mtx_enter(struct mutex *mtx)
 */
ENTRY(__mtx_enter)
	subu	%r31, %r31, 8
	st	%r1,  %r31, 4		/* save return address */

#ifdef MULTIPROCESSOR

	st	%r2,  %r31, 0		/* save mtx */
enter_again:
	ld	%r2,  %r2,  MTX_WANTIPL
	bcnd	eq0,  %r2,  1f
	bsr	_C_LABEL(splraise)	/* splraise(mtx->mtx_wantipl) */
1:
	ld	%r4,  %r31, 0
	or	%r3,  %r0,  1
	xmem	%r3,  %r4,  %r0		/* attempt to claim the lock, old */
	bcnd	ne0,  %r3,  enter_failed /* mtx->mtx_lock is 0 if successful */

	ldcr	%r3,  CPU
	st	%r2,  %r4,  MTX_OLDIPL	/* save into mtx_oldipl */
	st	%r3,  %r4,  MTX_OWNER	/* mtx->mtx_owner = curcpu() */
#ifdef DIAGNOSTIC
	ld	%r2,  %r3,  CI_MUTEX_LEVEL
	addu	%r2,  %r2,  1		/* curcpu()->ci_mutex_level++ */
	st	%r2,  %r3,  CI_MUTEX_LEVEL
#endif

	ld	%r1,  %r31, 4
	jmp.n	%r1
	 addu	%r31, %r31, 8

enter_failed:	/* the lock is not ours... */
	ld	%r3,  %r4,  MTX_WANTIPL
	bcnd	eq0,  %r3,  2f
	bcnd	ne0,  %r2,  1f		/* splx(oldipl) */
	bsr.n	_C_LABEL(spl0)
	 addu	%r1,  %r1,  2f - . - 4
1:
	bsr	_C_LABEL(setipl)
2:
	ld	%r2,  %r31, 0		/* restore mtx */
enter_spin:
#ifdef DIAGNOSTIC
	ldcr	%r3,  CPU
	ld	%r4,  %r2,  MTX_OWNER
	cmp	%r5,  %r3,  %r4
	bcnd	eq0,  %r5,  enter_panic
#endif
	ld	%r3,  %r2,  MTX_LOCK
	bcnd	eq0,  %r3,  enter_again
	br	enter_spin

#ifdef DIAGNOSTIC
enter_panic:
	or.u	%r2,  %r0,  %hi16(9f)
	bsr.n	_C_LABEL(panic)
	 or	%r2,  %r2,  %lo16(9f)

	.data
9:
	.string	"mtx_enter: humpaan itsekseni"
#endif

#else	/* MULTIPROCESSOR */

	st	%r2,  %r31, 0		/* save mtx */
	ld	%r2,  %r2,  MTX_WANTIPL
	bcnd	eq0,  %r2,  1f
	bsr	_C_LABEL(splraise)	/* splraise(mtx->mtx_wantipl) */
1:
	ld	%r4,  %r31, 0
	ldcr	%r3,  CPU
	st	%r3,  %r4,  MTX_LOCK	/* locked! */

	st	%r2,  %r4,  MTX_OLDIPL	/* save into mtx_oldipl */

#ifdef DIAGNOSTIC
	/* necessary for MUTEX_ASSERT_LOCKED */
	st	%r3,  %r4,  MTX_OWNER	/* mtx->mtx_owner = curcpu() */

	ld	%r2,  %r3,  CI_MUTEX_LEVEL
	addu	%r2,  %r2,  1		/* curcpu()->ci_mutex_level++ */
	st	%r2,  %r3,  CI_MUTEX_LEVEL
#endif

	ld	%r1,  %r31, 4
	jmp.n	%r1
	 addu	%r31, %r31, 8

#endif	/* MULTIPROCESSOR */
	
/*
 * int mtx_enter_try(struct mutex *mtx)
 */
ENTRY(__mtx_enter_try)
	subu	%r31, %r31, 8
	st	%r1,  %r31, 4		/* save return address */

#ifdef MULTIPROCESSOR

	st	%r2,  %r31, 0		/* save mtx */
enter_try_again:
	ld	%r2,  %r2,  MTX_WANTIPL
	bcnd	eq0,  %r2,  1f
	bsr	_C_LABEL(splraise)	/* splraise(mtx->mtx_wantipl) */
1:
	ld	%r4,  %r31, 0
	or	%r3,  %r0,  1
	xmem	%r3,  %r4,  %r0		/* attempt to claim the lock, old */
	bcnd	ne0,  %r3,  enter_try_failed /* mtx->mtx_lock is 0 if successful*/

	ldcr	%r3,  CPU
	st	%r2,  %r4,  MTX_OLDIPL	/* save into mtx_oldipl */
	st	%r3,  %r4,  MTX_OWNER	/* mtx->mtx_owner = curcpu() */
#ifdef DIAGNOSTIC
	ld	%r2,  %r3,  CI_MUTEX_LEVEL
	addu	%r2,  %r2,  1		/* curcpu()->ci_mutex_level++ */
	st	%r2,  %r3,  CI_MUTEX_LEVEL
#endif

	ld	%r1,  %r31, 4
	or	%r2,  %r0,  1		/* return nonzero */
	jmp.n	%r1
	 addu	%r31, %r31, 8

enter_try_failed:	/* the lock is not ours... */
	ld	%r3,  %r4,  MTX_WANTIPL
	bcnd	eq0,  %r3,  2f
	bcnd	ne0,  %r2,  1f		/* splx(oldipl) */
	bsr.n	_C_LABEL(spl0)
	 addu	%r1,  %r1,  2f - . - 4
1:
	bsr	_C_LABEL(setipl)
2:
#ifdef DIAGNOSTIC
	ld	%r2,  %r31, 0		/* restore mtx */
	ldcr	%r3,  CPU
	ld	%r4,  %r2,  MTX_OWNER
	cmp	%r5,  %r3,  %r4
	bcnd	eq0,  %r5,  enter_try_panic
#endif
	or	%r2,  %r0,  %r0		/* return zero */
	jmp.n	%r1
	 addu	%r31, %r31, 8

#ifdef DIAGNOSTIC
enter_try_panic:
	or.u	%r2,  %r0,  %hi16(9f)
	bsr.n	_C_LABEL(panic)
	 or	%r2,  %r2,  %lo16(9f)

	.data
9:
	.string	"mtx_enter_try: humpaan itsekseni"
#endif

#else	/* MULTIPROCESSOR */

	st	%r2,  %r31, 0		/* save mtx */
	ld	%r2,  %r2,  MTX_WANTIPL
	bcnd	eq0,  %r2,  1f
	bsr	_C_LABEL(splraise)	/* splraise(mtx->mtx_wantipl) */
1:
	ld	%r4,  %r31, 0
	ldcr	%r3,  CPU
	st	%r3,  %r4,  MTX_LOCK	/* locked! */

	st	%r2,  %r4,  MTX_OLDIPL	/* save into mtx_oldipl */

#ifdef DIAGNOSTIC
	/* necessary for MUTEX_ASSERT_LOCKED */
	st	%r3,  %r4,  MTX_OWNER	/* mtx->mtx_owner = curcpu() */

	ld	%r2,  %r3,  CI_MUTEX_LEVEL
	addu	%r2,  %r2,  1		/* curcpu()->ci_mutex_level++ */
	st	%r2,  %r3,  CI_MUTEX_LEVEL
#endif

	ld	%r1,  %r31, 4
	or	%r2,  %r0,  1		/* return nonzero */
	jmp.n	%r1
	 addu	%r31, %r31, 8

#endif	/* MULTIPROCESSOR */
	
/*
 * void mtx_leave(struct mutex *mtx)
 */
ENTRY(__mtx_leave)
	ld	%r3,  %r2,  MTX_OLDIPL
	ld	%r4,  %r2,  MTX_WANTIPL
#ifdef DIAGNOSTIC
	ld	%r5,  %r2,  MTX_OWNER
	ld	%r6,  %r5,  CI_MUTEX_LEVEL
	subu	%r6,  %r6,  1		/* curcpu()->ci_mutex_level++ */
	st	%r6,  %r5,  CI_MUTEX_LEVEL
#endif
	st	%r0,  %r2,  MTX_OWNER		/* mtx->mtx_owner = NULL */
	bcnd.n	eq0,  %r4,  2f
	 st	%r0,  %r2,  MTX_LOCK		/* mtx->mtx_lock = 0 */

	bcnd	ne0, %r3,  1f			/* splx(mtx->mtx_oldipl) */
	br	_C_LABEL(spl0)
1:
	br.n	_C_LABEL(setipl)
	 or	%r2,  %r3,  %r0
2:
	jmp	%r1
@


1.15
log
@rename raiseipl to splraise()

another step toward making splraise an MI api.

ok aoyama@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mutex.S,v 1.14 2015/07/03 15:12:49 miod Exp $	*/
d48 1
a48 1
ENTRY(mtx_enter)
d141 1
a141 1
ENTRY(mtx_enter_try)
d235 1
a235 1
ENTRY(mtx_leave)
@


1.14
log
@Rename mtx_cpu to mtx_owner for consistency with the other platforms.
@
text
@d1 1
a1 1
/*	$OpenBSD: mutex.S,v 1.13 2014/02/02 20:31:10 kettenis Exp $	*/
d58 1
a58 1
	bsr	_C_LABEL(raiseipl)	/* raiseipl(mtx->mtx_wantipl) */
d115 1
a115 1
	bsr	_C_LABEL(raiseipl)	/* raiseipl(mtx->mtx_wantipl) */
d151 1
a151 1
	bsr	_C_LABEL(raiseipl)	/* raiseipl(mtx->mtx_wantipl) */
d208 1
a208 1
	bsr	_C_LABEL(raiseipl)	/* raiseipl(mtx->mtx_wantipl) */
@


1.13
log
@To prevent lock ordering problems with the kernel lock, we need to make sure
we block all interrupts that can grab the kernel lock.  The simplest way to
achieve this is to make sure mutexes always raise the ipl to the highest
level that has interrupts that grab the kernel lock.  This will allow us
to have "mpsafe" interrupt handlers at lower priority levels.

No change for non-MULTIPROCESSOR kernels.

ok miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mutex.S,v 1.12 2013/01/05 11:20:56 miod Exp $	*/
d43 1
a43 1
	 st	%r0, %r2, MTX_CPU	/* mtx->mtx_cpu = NULL */
d67 1
a67 1
	st	%r3,  %r4,  MTX_CPU	/* mtx->mtx_cpu = curcpu() */
d91 1
a91 1
	ld	%r4,  %r2,  MTX_CPU
d125 1
a125 1
	st	%r3,  %r4,  MTX_CPU	/* mtx->mtx_cpu = curcpu() */
d160 1
a160 1
	st	%r3,  %r4,  MTX_CPU	/* mtx->mtx_cpu = curcpu() */
d184 1
a184 1
	ld	%r4,  %r2,  MTX_CPU
d218 1
a218 1
	st	%r3,  %r4,  MTX_CPU	/* mtx->mtx_cpu = curcpu() */
d239 1
a239 1
	ld	%r5,  %r2,  MTX_CPU
d244 1
a244 1
	st	%r0,  %r2,  MTX_CPU		/* mtx->mtx_cpu = NULL */
@


1.12
log
@Switch m88k ports to ELF.
@
text
@d1 1
a1 1
/*	$OpenBSD: mutex.S,v 1.11 2011/04/21 04:34:12 miod Exp $	*/
d38 1
a38 1
ENTRY(mtx_init)
@


1.11
log
@Revert the ``remove the `skip splraise/splx for IPL_NONE mutexes' optimization''
change. It seems to have unexpected side effects, especially on MP systems,
and drahn@@ disagrees with the way this change has been done and think there
is a better way to solve the original problem of msleep() fiddling with
mutex internals.
@
text
@d1 1
a1 1
/*	$OpenBSD: mutex.S,v 1.9 2010/09/28 20:27:55 miod Exp $	*/
d39 5
a43 5
	st	r0, r2, MTX_LOCK	/* mtx->mtx_lock = 0 */
	st	r0, r2, MTX_OLDIPL	/* mtx->mtx_oldipl = IPL_NONE */
	st	r3, r2, MTX_WANTIPL	/* mtx->mtx_wantipl = ipl */
	jmp.n	r1
	 st	r0, r2, MTX_CPU		/* mtx->mtx_cpu = NULL */
d49 2
a50 2
	subu	r31, r31, 8
	st	r1,  r31, 4		/* save return address */
d54 1
a54 1
	st	r2,  r31, 0		/* save mtx */
d56 2
a57 2
	ld	r2,  r2,  MTX_WANTIPL
	bcnd	eq0, r2,  1f
d60 17
a76 17
	ld	r4,  r31, 0
	or	r3,  r0,  1
	xmem	r3,  r4,  r0		/* attempt to claim the lock, old */
	bcnd	ne0, r3,  enter_failed	/* mtx->mtx_lock is 0 if successful */

	ldcr	r3,  CPU
	st	r2,  r4,  MTX_OLDIPL	/* save into mtx_oldipl */
	st	r3,  r4,  MTX_CPU	/* mtx->mtx_cpu = curcpu() */
#ifdef DIAGNOSTIC
	ld	r2,  r3,  CI_MUTEX_LEVEL
	addu	r2,  r2,  1		/* curcpu()->ci_mutex_level++ */
	st	r2,  r3,  CI_MUTEX_LEVEL
#endif

	ld	r1,  r31, 4
	jmp.n	r1
	 addu	r31, r31, 8
d79 3
a81 3
	ld	r3,  r4,  MTX_WANTIPL
	bcnd	eq0, r3,  2f
	bcnd	ne0, r2,  1f		/* splx(oldipl) */
d83 1
a83 1
	 addu	r1,  r1,  2f - . - 4
d87 1
a87 1
	ld	r2,  r31, 0		/* restore mtx */
d90 4
a93 4
	ldcr	r3,  CPU
	ld	r4,  r2,  MTX_CPU
	cmp	r5,  r3,  r4
	bcnd	eq0, r5,  enter_panic
d95 2
a96 2
	ld	r3,  r2,  MTX_LOCK
	bcnd	eq0, r3,  enter_again
d101 1
a101 1
	or.u	r2,  r0,  hi16(9f)
d103 1
a103 1
	 or	r2,  r2,  lo16(9f)
d105 1
a105 1
	data
d107 1
a107 1
	string	"mtx_enter: humpaan itsekseni"
d112 3
a114 3
	st	r2,  r31, 0		/* save mtx */
	ld	r2,  r2,  MTX_WANTIPL
	bcnd	eq0, r2,  1f
d117 3
a119 3
	ld	r4,  r31, 0
	ldcr	r3,  CPU
	st	r3,  r4,  MTX_LOCK	/* locked! */
d121 1
a121 1
	st	r2,  r4,  MTX_OLDIPL	/* save into mtx_oldipl */
d125 1
a125 1
	st	r3,  r4,  MTX_CPU	/* mtx->mtx_cpu = curcpu() */
d127 3
a129 3
	ld	r2,  r3,  CI_MUTEX_LEVEL
	addu	r2,  r2,  1		/* curcpu()->ci_mutex_level++ */
	st	r2,  r3,  CI_MUTEX_LEVEL
d132 3
a134 3
	ld	r1,  r31, 4
	jmp.n	r1
	 addu	r31, r31, 8
d142 2
a143 2
	subu	r31, r31, 8
	st	r1,  r31, 4		/* save return address */
d147 1
a147 1
	st	r2,  r31, 0		/* save mtx */
d149 2
a150 2
	ld	r2,  r2,  MTX_WANTIPL
	bcnd	eq0, r2,  1f
d153 18
a170 18
	ld	r4,  r31, 0
	or	r3,  r0,  1
	xmem	r3,  r4,  r0		/* attempt to claim the lock, old */
	bcnd	ne0, r3,  enter_try_failed /* mtx->mtx_lock is 0 if successful*/

	ldcr	r3,  CPU
	st	r2,  r4,  MTX_OLDIPL	/* save into mtx_oldipl */
	st	r3,  r4,  MTX_CPU	/* mtx->mtx_cpu = curcpu() */
#ifdef DIAGNOSTIC
	ld	r2,  r3,  CI_MUTEX_LEVEL
	addu	r2,  r2,  1		/* curcpu()->ci_mutex_level++ */
	st	r2,  r3,  CI_MUTEX_LEVEL
#endif

	ld	r1,  r31, 4
	or	r2,  r0,  1		/* return nonzero */
	jmp.n	r1
	 addu	r31, r31, 8
d173 3
a175 3
	ld	r3,  r4,  MTX_WANTIPL
	bcnd	eq0, r3,  2f
	bcnd	ne0, r2,  1f		/* splx(oldipl) */
d177 1
a177 1
	 addu	r1,  r1,  2f - . - 4
d182 9
a190 9
	ld	r2,  r31, 0		/* restore mtx */
	ldcr	r3,  CPU
	ld	r4,  r2,  MTX_CPU
	cmp	r5,  r3,  r4
	bcnd	eq0, r5,  enter_try_panic
#endif
	or	r2,  r0,  r0		/* return zero */
	jmp.n	r1
	 addu	r31, r31, 8
d194 1
a194 1
	or.u	r2,  r0,  hi16(9f)
d196 1
a196 1
	 or	r2,  r2,  lo16(9f)
d198 1
a198 1
	data
d200 1
a200 1
	string	"mtx_enter_try: humpaan itsekseni"
d205 3
a207 3
	st	r2,  r31, 0		/* save mtx */
	ld	r2,  r2,  MTX_WANTIPL
	bcnd	eq0, r2,  1f
d210 3
a212 3
	ld	r4,  r31, 0
	ldcr	r3,  CPU
	st	r3,  r4,  MTX_LOCK	/* locked! */
d214 1
a214 1
	st	r2,  r4,  MTX_OLDIPL	/* save into mtx_oldipl */
d218 1
a218 1
	st	r3,  r4,  MTX_CPU	/* mtx->mtx_cpu = curcpu() */
d220 3
a222 3
	ld	r2,  r3,  CI_MUTEX_LEVEL
	addu	r2,  r2,  1		/* curcpu()->ci_mutex_level++ */
	st	r2,  r3,  CI_MUTEX_LEVEL
d225 4
a228 4
	ld	r1,  r31, 4
	or	r2,  r0,  1		/* return nonzero */
	jmp.n	r1
	 addu	r31, r31, 8
d236 2
a237 2
	ld	r3,  r2,  MTX_OLDIPL
	ld	r4,  r2,  MTX_WANTIPL
d239 8
a246 8
	ld	r5,  r2,  MTX_CPU
	ld	r6,  r5,  CI_MUTEX_LEVEL
	subu	r6,  r6,  1		/* curcpu()->ci_mutex_level++ */
	st	r6,  r5,  CI_MUTEX_LEVEL
#endif
	st	r0,  r2,  MTX_CPU		/* mtx->mtx_cpu = NULL */
	bcnd.n	eq0, r4,  2f
	 st	r0,  r2,  MTX_LOCK		/* mtx->mtx_lock = 0 */
d248 1
a248 1
	bcnd	ne0, r3,  1f			/* splx(mtx->mtx_oldipl) */
d252 1
a252 1
	 or	r2,  r3,  r0
d254 1
a254 1
	jmp	r1
@


1.10
log
@Remove the `skip splraise/splx for IPL_NONE mutexes' optimizations. It is not
always gaining anything, and msleep() implementation depends upon mtx_leave()
invoking splx().
@
text
@d57 1
d59 1
d79 2
d114 1
d116 1
d150 1
d152 1
d173 2
d207 1
d209 1
d237 1
d245 2
a246 1
	st	r0,  r2,  MTX_LOCK		/* mtx->mtx_lock = 0 */
d253 2
@


1.9
log
@Implement a per-cpu held mutex counter if DIAGNOSTIC on all non-x86 platforms,
to complete matthew@@'s commit of a few days ago, and drop __HAVE_CPU_MUTEX_LEVEL
define. With help from, and ok deraadt@@.
@
text
@d1 1
a1 1
/*	$OpenBSD: mutex.S,v 1.8 2009/08/13 13:24:55 weingart Exp $	*/
a56 1
	bcnd	eq0, r2,  1f
a57 1
1:
a76 2
	ld	r3,  r4,  MTX_WANTIPL
	bcnd	eq0, r3,  2f
a109 1
	bcnd	eq0, r2,  1f
a110 1
1:
a143 1
	bcnd	eq0, r2,  1f
a144 1
1:
a164 2
	ld	r3,  r4,  MTX_WANTIPL
	bcnd	eq0, r3,  2f
a196 1
	bcnd	eq0, r2,  1f
a197 1
1:
a224 1
	ld	r4,  r2,  MTX_WANTIPL
d232 1
a232 2
	bcnd.n	eq0, r4,  2f
	 st	r0,  r2,  MTX_LOCK		/* mtx->mtx_lock = 0 */
a238 2
2:
	jmp	r1
@


1.8
log
@A new(er) mtx_enter_try().

Ok oga@@, "the time is now" deraadt@@.
@
text
@d1 1
a1 1
/*	$OpenBSD: mutex.S,v 1.7 2009/04/27 21:48:56 kettenis Exp $	*/
d68 5
d123 2
a124 1
#ifdef DIAGNOSTIC	/* necessary for MUTEX_ASSERT_LOCKED */
d126 4
d161 5
d216 2
a217 1
#ifdef DIAGNOSTIC	/* necessary for MUTEX_ASSERT_LOCKED */
d219 4
d238 6
@


1.7
log
@Revert mtx_enter_try.  It didn't compile on hppa, it doesn't compile on
landisk, and the sparc implementation is obviously wrong.  That's where I
stopped looking, so who knows what else was broken.  A simple comparison of
the existing mtx_enter with the new mtx_enter_try would have told anybody.
@
text
@d1 1
a1 1
/*	$OpenBSD: mutex.S,v 1.5 2007/10/16 04:56:12 miod Exp $	*/
d123 84
@


1.6
log
@Enter mtx_enter_try.  In part for completeness, things may start
using this soon(ish).  Ok oga@@, sorta yes kettenis@@.
@
text
@a128 84
 * int mtx_enter_try(struct mutex *mtx)
 */
ENTRY(mtx_enter_try)
	subu	r31, r31, 8
	st	r1,  r31, 4		/* save return address */

#ifdef MULTIPROCESSOR

	st	r2,  r31, 0		/* save mtx */
enter_try_again:
	ld	r2,  r2,  MTX_WANTIPL
	bcnd	eq0, r2,  1f
	bsr	_C_LABEL(raiseipl)	/* raiseipl(mtx->mtx_wantipl) */
1:
	ld	r4,  r31, 0
	or	r3,  r0,  1
	xmem	r3,  r4,  r0		/* attempt to claim the lock, old */
	bcnd	ne0, r3,  enter_try_failed /* mtx->mtx_lock is 0 if successful*/

	ldcr	r3,  CPU
	st	r2,  r4,  MTX_OLDIPL	/* save into mtx_oldipl */
	st	r3,  r4,  MTX_CPU	/* mtx->mtx_cpu = curcpu() */

	ld	r1,  r31, 4
	or	r2,  r0,  1		/* return nonzero */
	jmp.n	r1
	 addu	r31, r31, 8

enter_try_failed:	/* the lock is not ours... */
	ld	r3,  r4,  MTX_WANTIPL
	bcnd	eq0, r3,  2f
	bcnd	ne0, r2,  1f		/* splx(oldipl) */
	bsr.n	_C_LABEL(spl0)
	 addu	r1,  r1,  2f - . - 4
1:
	bsr	_C_LABEL(setipl)
2:
#ifdef DIAGNOSTIC
	ld	r2,  r31, 0		/* restore mtx */
	ldcr	r3,  CPU
	ld	r4,  r2,  MTX_CPU
	cmp	r5,  r3,  r4
	bcnd	eq0, r5,  enter_try_panic
#endif
	or	r2,  r0,  r0		/* return zero */
	jmp.n	r1
	 addu	r31, r31, 8

#ifdef DIAGNOSTIC
enter_try_panic:
	or.u	r2,  r0,  hi16(9f)
	bsr.n	_C_LABEL(panic)
	 or	r2,  r2,  lo16(9f)

	data
9:
	string	"mtx_enter_try: humpaan itsekseni"
#endif

#else	/* MULTIPROCESSOR */

	st	r2,  r31, 0		/* save mtx */
	ld	r2,  r2,  MTX_WANTIPL
	bcnd	eq0, r2,  1f
	bsr	_C_LABEL(raiseipl)	/* raiseipl(mtx->mtx_wantipl) */
1:
	ld	r4,  r31, 0
	ldcr	r3,  CPU
	st	r3,  r4,  MTX_LOCK	/* locked! */

	st	r2,  r4,  MTX_OLDIPL	/* save into mtx_oldipl */

#ifdef DIAGNOSTIC	/* necessary for MUTEX_ASSERT_LOCKED */
	st	r3,  r4,  MTX_CPU	/* mtx->mtx_cpu = curcpu() */
#endif

	ld	r1,  r31, 4
	or	r2,  r0,  1		/* return nonzero */
	jmp.n	r1
	 addu	r31, r31, 8

#endif	/* MULTIPROCESSOR */
	
/*
@


1.5
log
@Fix the mtx_wantipl != IPL_NONE comparison in the ``have to spin''
MULTIPROCESSOR case in mtx_enter.
@
text
@d1 1
a1 1
/*	$OpenBSD: mutex.S,v 1.4 2007/05/18 16:34:31 miod Exp $	*/
d123 84
@


1.4
log
@Revert previous revision, and do it again correctly.
@
text
@d1 1
a1 1
/*	$OpenBSD: mutex.S,v 1.2 2006/11/18 22:48:15 miod Exp $	*/
d75 1
a75 1
	bcnd	eq0, r4,  2f
@


1.3
log
@Oops, correctly handle spl-less mutexes.
@
text
@a50 1
	st	r2,  r31, 0		/* save mtx */
d53 2
d56 5
d62 22
a83 2
	xmem	r3,  r2,  r0		/* attempt to claim the lock, old */
	bcnd	eq0, r3,  enter_success	/* mtx->mtx_lock is 0 if successful */
d88 1
a88 1
	bcnd	eq0, r5,  enter_panic	/* ... unless it is, oops */
a89 2
enter_spin:
	/* Avoid clogging the bus with xmem, wait until the mutex is released */
d93 1
d101 2
a102 2
9:	string	"mtx_enter: humpaan itsekseni"
	text
d104 1
a104 1
enter_success:
a105 2
	st	r2,  r2,  MTX_LOCK	/* locked! */
#endif	/* MULTIPROCESSOR */
d107 1
a107 2
	ldcr	r3,  CPU
	st	r3,  r2,  MTX_CPU	/* mtx->mtx_cpu = curcpu() */
d109 1
a109 1
	bcnd	eq0, r2,  1f		/* if mtx_wantipl == IPL_NONE, skip */
d113 3
d118 4
d126 2
@


1.2
log
@In mtx_leave(), jump to the leaf splx() instead of building a frame and
calling it.
@
text
@d1 1
a1 1
/*	$OpenBSD: mutex.S,v 1.1 2005/12/03 19:01:14 miod Exp $	*/
d51 1
a53 2

	st	r2,  r31, 0		/* save mtx */
a54 4
	bsr.n	_C_LABEL(raiseipl)	/* raiseipl(mtx->mtx_wantipl) */
	 ld	r2,  r2,  MTX_WANTIPL

	ld	r4,  r31, 0
d56 2
a57 20
	xmem	r3,  r4,  r0		/* attempt to claim the lock, old */
	bcnd	ne0, r3,  enter_failed	/* mtx->mtx_lock is 0 if successful */

	st	r2,  r4,  MTX_OLDIPL	/* save into mtx_oldipl */
	ldcr	r3,  CPU
	st	r3,  r4,  MTX_CPU	/* mtx->mtx_cpu = curcpu() */

	ld	r1,  r31, 4
	jmp.n	r1
	 addu	r31, r31, 8

enter_failed:	/* the lock is not ours... */
	bcnd	ne0, r2,  1f		/* splx(oldipl) */
	bsr.n	_C_LABEL(spl0)
	 addu	r1,  r1,  2f - . - 4
1:
	bsr	_C_LABEL(setipl)
2:
	ld	r2,  r31, 0		/* restore mtx */
enter_spin:
d62 1
a62 1
	bcnd	eq0, r5,  enter_panic
d64 2
a68 1

d76 2
a77 2
9:
	string	"mtx_enter: humpaan itsekseni"
d79 1
a79 1

d81 2
d84 6
a89 4
	st	r2,  r31, 0		/* save mtx */
	bsr.n	_C_LABEL(raiseipl)	/* raiseipl(mtx->mtx_wantipl) */
	 ld	r2,  r2,  MTX_WANTIPL

a90 3
	ldcr	r3,  CPU
	st	r3,  r4,  MTX_LOCK	/* locked! */

a92 4
#ifdef DIAGNOSTIC	/* necessary for MUTEX_ASSERT_LOCKED */
	st	r3,  r4,  MTX_CPU	/* mtx->mtx_cpu = curcpu() */
#endif

a96 2
#endif	/* MULTIPROCESSOR */
	
d102 1
d104 2
a105 3
#ifdef DEBUG
	st	r0,  r2,  MTX_OLDIPL		/* mtx->mtx_oldipl = IPL_NONE */
#endif
d107 1
a107 2
	bcnd.n	ne0, r3,  1f			/* splx(mtx->mtx_oldipl) */
	 st	r0,  r2,  MTX_LOCK		/* mtx->mtx_lock = 0 */
d112 2
@


1.1
log
@Fast __HAVE_MUTEX implementation for m88k platforms.
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d109 1
a109 1
	or	r3,  r0,  1
a114 1
	ldcr	r3,  CPU
a127 3
	subu	r31, r31, 8
	st	r1,  r31, 0

d136 1
a136 2
	bsr.n	_C_LABEL(spl0)
	 addu	r1,  r1,  2f - . - 4
d138 1
a138 1
	bsr.n	_C_LABEL(setipl)
a139 4
2:
	ld	r1,  r31, 0
	jmp.n	r1
	 addu	r31, r31, 8
@

