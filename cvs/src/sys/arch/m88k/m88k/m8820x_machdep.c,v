head	1.61;
access;
symbols
	OPENBSD_6_0:1.61.0.12
	OPENBSD_6_0_BASE:1.61
	OPENBSD_5_9:1.61.0.8
	OPENBSD_5_9_BASE:1.61
	OPENBSD_5_8:1.61.0.10
	OPENBSD_5_8_BASE:1.61
	OPENBSD_5_7:1.61.0.2
	OPENBSD_5_7_BASE:1.61
	OPENBSD_5_6:1.61.0.6
	OPENBSD_5_6_BASE:1.61
	OPENBSD_5_5:1.61.0.4
	OPENBSD_5_5_BASE:1.61
	OPENBSD_5_4:1.56.0.2
	OPENBSD_5_4_BASE:1.56
	OPENBSD_5_3:1.52.0.2
	OPENBSD_5_3_BASE:1.52
	OPENBSD_5_2:1.50.0.4
	OPENBSD_5_2_BASE:1.50
	OPENBSD_5_1_BASE:1.50
	OPENBSD_5_1:1.50.0.2
	OPENBSD_5_0:1.47.0.4
	OPENBSD_5_0_BASE:1.47
	OPENBSD_4_9:1.47.0.2
	OPENBSD_4_9_BASE:1.47
	OPENBSD_4_8:1.40.0.2
	OPENBSD_4_8_BASE:1.40
	OPENBSD_4_7:1.38.0.2
	OPENBSD_4_7_BASE:1.38
	OPENBSD_4_6:1.38.0.4
	OPENBSD_4_6_BASE:1.38
	OPENBSD_4_5:1.37.0.4
	OPENBSD_4_5_BASE:1.37
	OPENBSD_4_4:1.35.0.4
	OPENBSD_4_4_BASE:1.35
	OPENBSD_4_3:1.35.0.2
	OPENBSD_4_3_BASE:1.35
	OPENBSD_4_2:1.26.0.2
	OPENBSD_4_2_BASE:1.26
	OPENBSD_4_1:1.24.0.2
	OPENBSD_4_1_BASE:1.24
	OPENBSD_4_0:1.23.0.2
	OPENBSD_4_0_BASE:1.23
	OPENBSD_3_9:1.19.0.2
	OPENBSD_3_9_BASE:1.19
	OPENBSD_3_8:1.6.0.2
	OPENBSD_3_8_BASE:1.6
	OPENBSD_3_7:1.3.0.4
	OPENBSD_3_7_BASE:1.3
	OPENBSD_3_6:1.3.0.2
	OPENBSD_3_6_BASE:1.3;
locks; strict;
comment	@ * @;


1.61
date	2013.11.16.18.45.20;	author miod;	state Exp;
branches;
next	1.60;

1.60
date	2013.11.03.09.42.55;	author miod;	state Exp;
branches;
next	1.59;

1.59
date	2013.11.02.23.10.30;	author miod;	state Exp;
branches;
next	1.58;

1.58
date	2013.09.23.04.47.09;	author miod;	state Exp;
branches;
next	1.57;

1.57
date	2013.08.15.19.32.12;	author miod;	state Exp;
branches;
next	1.56;

1.56
date	2013.06.30.10.04.40;	author aoyama;	state Exp;
branches;
next	1.55;

1.55
date	2013.05.25.17.49.54;	author miod;	state Exp;
branches;
next	1.54;

1.54
date	2013.05.17.22.33.25;	author miod;	state Exp;
branches;
next	1.53;

1.53
date	2013.05.14.21.58.09;	author miod;	state Exp;
branches;
next	1.52;

1.52
date	2013.02.19.21.02.06;	author miod;	state Exp;
branches;
next	1.51;

1.51
date	2013.02.17.18.07.36;	author miod;	state Exp;
branches;
next	1.50;

1.50
date	2011.10.25.18.38.06;	author miod;	state Exp;
branches;
next	1.49;

1.49
date	2011.10.09.17.02.14;	author miod;	state Exp;
branches;
next	1.48;

1.48
date	2011.10.09.17.01.34;	author miod;	state Exp;
branches;
next	1.47;

1.47
date	2011.01.05.22.16.16;	author miod;	state Exp;
branches;
next	1.46;

1.46
date	2011.01.05.22.14.29;	author miod;	state Exp;
branches;
next	1.45;

1.45
date	2011.01.01.22.09.33;	author miod;	state Exp;
branches;
next	1.44;

1.44
date	2010.12.31.21.16.31;	author miod;	state Exp;
branches;
next	1.43;

1.43
date	2010.12.31.21.12.16;	author miod;	state Exp;
branches;
next	1.42;

1.42
date	2010.12.31.20.54.21;	author miod;	state Exp;
branches;
next	1.41;

1.41
date	2010.12.27.19.18.37;	author miod;	state Exp;
branches;
next	1.40;

1.40
date	2010.04.25.21.03.53;	author miod;	state Exp;
branches;
next	1.39;

1.39
date	2010.04.18.22.04.39;	author miod;	state Exp;
branches;
next	1.38;

1.38
date	2009.04.19.17.56.13;	author miod;	state Exp;
branches;
next	1.37;

1.37
date	2009.02.16.23.03.33;	author miod;	state Exp;
branches;
next	1.36;

1.36
date	2009.02.01.00.52.19;	author miod;	state Exp;
branches;
next	1.35;

1.35
date	2007.12.15.19.33.34;	author miod;	state Exp;
branches;
next	1.34;

1.34
date	2007.12.05.22.09.55;	author miod;	state Exp;
branches;
next	1.33;

1.33
date	2007.11.24.11.12.55;	author miod;	state Exp;
branches;
next	1.32;

1.32
date	2007.11.22.05.47.46;	author miod;	state Exp;
branches;
next	1.31;

1.31
date	2007.11.22.05.42.50;	author miod;	state Exp;
branches;
next	1.30;

1.30
date	2007.11.14.23.12.46;	author miod;	state Exp;
branches;
next	1.29;

1.29
date	2007.11.11.13.05.28;	author miod;	state Exp;
branches;
next	1.28;

1.28
date	2007.11.09.22.47.21;	author miod;	state Exp;
branches;
next	1.27;

1.27
date	2007.10.29.19.58.57;	author miod;	state Exp;
branches;
next	1.26;

1.26
date	2007.05.20.20.12.32;	author miod;	state Exp;
branches;
next	1.25;

1.25
date	2007.03.22.18.49.18;	author miod;	state Exp;
branches;
next	1.24;

1.24
date	2007.02.11.12.49.37;	author miod;	state Exp;
branches;
next	1.23;

1.23
date	2006.05.08.14.36.09;	author miod;	state Exp;
branches;
next	1.22;

1.22
date	2006.04.17.16.08.01;	author miod;	state Exp;
branches;
next	1.21;

1.21
date	2006.04.15.15.44.06;	author miod;	state Exp;
branches;
next	1.20;

1.20
date	2006.04.09.12.11.11;	author miod;	state Exp;
branches;
next	1.19;

1.19
date	2005.12.21.22.15.24;	author miod;	state Exp;
branches;
next	1.18;

1.18
date	2005.12.11.21.45.30;	author miod;	state Exp;
branches;
next	1.17;

1.17
date	2005.12.10.22.31.38;	author miod;	state Exp;
branches;
next	1.16;

1.16
date	2005.12.04.15.00.26;	author miod;	state Exp;
branches;
next	1.15;

1.15
date	2005.12.04.12.20.19;	author miod;	state Exp;
branches;
next	1.14;

1.14
date	2005.12.03.19.06.11;	author miod;	state Exp;
branches;
next	1.13;

1.13
date	2005.12.03.16.52.16;	author miod;	state Exp;
branches;
next	1.12;

1.12
date	2005.12.02.21.16.45;	author miod;	state Exp;
branches;
next	1.11;

1.11
date	2005.11.25.22.20.45;	author miod;	state Exp;
branches;
next	1.10;

1.10
date	2005.11.25.22.17.14;	author miod;	state Exp;
branches;
next	1.9;

1.9
date	2005.10.13.19.48.33;	author miod;	state Exp;
branches;
next	1.8;

1.8
date	2005.09.25.22.41.14;	author miod;	state Exp;
branches;
next	1.7;

1.7
date	2005.09.25.20.55.14;	author miod;	state Exp;
branches;
next	1.6;

1.6
date	2005.07.01.14.09.26;	author miod;	state Exp;
branches;
next	1.5;

1.5
date	2005.04.27.14.09.45;	author miod;	state Exp;
branches;
next	1.4;

1.4
date	2005.04.27.14.07.38;	author miod;	state Exp;
branches;
next	1.3;

1.3
date	2004.08.08.21.19.18;	author miod;	state Exp;
branches;
next	1.2;

1.2
date	2004.08.08.21.14.04;	author miod;	state Exp;
branches;
next	1.1;

1.1
date	2004.08.06.13.23.49;	author miod;	state Exp;
branches;
next	;


desc
@@


1.61
log
@Allow initial device mappings (from pmap_table) to be backed up by BATC.
Use this on luna88k to map the bitmap planes of the frame buffer used by
the driver. 10% speedup under X.
@
text
@/*	$OpenBSD: m8820x_machdep.c,v 1.60 2013/11/03 09:42:55 miod Exp $	*/
/*
 * Copyright (c) 2004, 2007, 2010, 2011, 2013, Miodrag Vallat.
 *
 * Permission to use, copy, modify, and distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 */
/*
 * Copyright (c) 2001 Steve Murphree, Jr.
 * Copyright (c) 1996 Nivas Madhur
 * All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *      This product includes software developed by Nivas Madhur.
 * 4. The name of the author may not be used to endorse or promote products
 *    derived from this software without specific prior written permission
 *
 * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR
 * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
 * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
 * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,
 * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
 * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
 * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
 * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF
 * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 *
 */
/*
 * Mach Operating System
 * Copyright (c) 1993-1991 Carnegie Mellon University
 * Copyright (c) 1991 OMRON Corporation
 * All Rights Reserved.
 *
 * Permission to use, copy, modify and distribute this software and its
 * documentation is hereby granted, provided that both the copyright
 * notice and this permission notice appear in all copies of the
 * software, derivative works or modified versions, and any portions
 * thereof, and that both notices appear in supporting documentation.
 *
 * CARNEGIE MELLON AND OMRON ALLOW FREE USE OF THIS SOFTWARE IN ITS "AS IS"
 * CONDITION.  CARNEGIE MELLON AND OMRON DISCLAIM ANY LIABILITY OF ANY KIND
 * FOR ANY DAMAGES WHATSOEVER RESULTING FROM THE USE OF THIS SOFTWARE.
 *
 * Carnegie Mellon requests users of this software to return to
 *
 *  Software Distribution Coordinator  or  Software.Distribution@@CS.CMU.EDU
 *  School of Computer Science
 *  Carnegie Mellon University
 *  Pittsburgh PA 15213-3890
 *
 * any improvements or extensions that they make and grant Carnegie the
 * rights to redistribute these changes.
 */

#include <sys/param.h>
#include <sys/systm.h>

#include <uvm/uvm_extern.h>

#include <machine/asm_macro.h>
#include <machine/cmmu.h>
#include <machine/cpu.h>
#include <machine/lock.h>
#include <machine/m8820x.h>
#include <machine/psl.h>

extern	void m8820x_zeropage(vaddr_t);
extern	void m8820x_copypage(vaddr_t, vaddr_t);

cpuid_t	m8820x_init(void);
void	m8820x_batc_setup(cpuid_t, apr_t);
void	m8820x_cpu_configuration_print(int);
void	m8820x_shutdown(void);
apr_t	m8820x_apr_cmode(void);
apr_t	m8820x_pte_cmode(void);
void	m8820x_set_sapr(apr_t);
void	m8820x_set_uapr(apr_t);
void	m8820x_tlbis(cpuid_t, vaddr_t, pt_entry_t);
void	m8820x_tlbiu(cpuid_t, vaddr_t, pt_entry_t);
void	m8820x_tlbia(cpuid_t);
void	m8820x_cache_wbinv(cpuid_t, paddr_t, psize_t);
void	m8820x_dcache_wb(cpuid_t, paddr_t, psize_t);
void	m8820x_icache_inv(cpuid_t, paddr_t, psize_t);
void	m8820x_dma_cachectl(paddr_t, psize_t, int);
void	m8820x_dma_cachectl_local(paddr_t, psize_t, int);
void	m8820x_initialize_cpu(cpuid_t);

const struct cmmu_p cmmu8820x = {
	m8820x_init,
	m8820x_batc_setup,
	m8820x_setup_board_config,
	m8820x_cpu_configuration_print,
	m8820x_shutdown,
	m8820x_cpu_number,
	m8820x_apr_cmode,
	m8820x_pte_cmode,
	m8820x_set_sapr,
	m8820x_set_uapr,
	m8820x_tlbis,
	m8820x_tlbiu,
	m8820x_tlbia,
	m8820x_cache_wbinv,
	m8820x_dcache_wb,
	m8820x_icache_inv,
	m8820x_dma_cachectl,
#ifdef MULTIPROCESSOR
	m8820x_dma_cachectl_local,
	m8820x_initialize_cpu,
#endif
};

/*
 * Systems with more than 2 CMMUs per CPU use split schemes, which sometimes
 * are programmable (well, no more than having a few hardwired choices).
 *
 * The following schemes are available on MVME188 boards:
 * - split on A12 address bit (A14 for 88204)
 * - split on supervisor/user access
 * - split on SRAM/non-SRAM addresses, with either supervisor-only or all
 *   access to SRAM.
 *
 * MVME188 configuration 6, with 4 CMMUs par CPU, also forces a split on
 * A14 address bit (A16 for 88204).
 *
 * Under OpenBSD, we will only split on A12 and A14 address bits, since we
 * do not want to waste CMMU resources on the SRAM, and user/supervisor
 * splits seem less efficient.
 *
 * The really nasty part of this choice is in the exception handling code,
 * when it needs to get error information from up to 4 CMMUs. See eh.S for
 * the gory details.
 */

struct m8820x_cmmu m8820x_cmmu[MAX_CMMUS]
    __attribute__ ((__section__(".rodata")));
u_int max_cmmus
    __attribute__ ((__section__(".rodata")));
u_int cmmu_shift
    __attribute__ ((__section__(".rodata")));

/* local prototypes */
void	m8820x_cmmu_configuration_print(int, int);
void	m8820x_cmmu_set_reg(int, u_int, int);
void	m8820x_cmmu_set_reg_if_mode(int, u_int, int, int);
void	m8820x_cmmu_set_cmd(u_int, int, vaddr_t);
void	m8820x_cmmu_set_cmd_if_addr(u_int, int, vaddr_t);
void	m8820x_cmmu_set_cmd_if_mode(u_int, int, vaddr_t, int);
void	m8820x_cmmu_wait(int);
void	m8820x_cmmu_wb_locked(int, paddr_t, psize_t);
void	m8820x_cmmu_wbinv_locked(int, paddr_t, psize_t);
void	m8820x_cmmu_inv_locked(int, paddr_t, psize_t);
#if defined(__luna88k__) && !defined(MULTIPROCESSOR)
void	m8820x_enable_other_cmmu_cache(void);
#endif

static inline
void	m8820x_dbatc_set(cpuid_t, uint, batc_t);
static inline
void	m8820x_ibatc_set(cpuid_t, uint, batc_t);

/* Flags passed to m8820x_cmmu_set_*() */
#define MODE_VAL		0x01
#define ADDR_VAL		0x02

/*
 * Helper functions to poke values into the appropriate CMMU registers.
 */

void
m8820x_cmmu_set_reg(int reg, u_int val, int cpu)
{
	struct m8820x_cmmu *cmmu;
	int mmu, cnt;

	mmu = cpu << cmmu_shift;
	cmmu = m8820x_cmmu + mmu;

	/*
	 * We scan all CMMUs to find the matching ones and store the
	 * values there.
	 */
	for (cnt = 1 << cmmu_shift; cnt != 0; cnt--, mmu++, cmmu++) {
#ifdef M88200_HAS_ASYMMETRICAL_ASSOCIATION
		if (cmmu->cmmu_regs == NULL)
			continue;
#endif
		cmmu->cmmu_regs[reg] = val;
	}
}

void
m8820x_cmmu_set_reg_if_mode(int reg, u_int val, int cpu, int mode)
{
	struct m8820x_cmmu *cmmu;
	int mmu, cnt;

	mmu = cpu << cmmu_shift;
	cmmu = m8820x_cmmu + mmu;

	/*
	 * We scan all CMMUs to find the matching ones and store the
	 * values there.
	 */
	for (cnt = 1 << cmmu_shift; cnt != 0; cnt--, mmu++, cmmu++) {
#ifdef M88200_HAS_ASYMMETRICAL_ASSOCIATION
		if (cmmu->cmmu_regs == NULL)
			continue;
#endif
		if (CMMU_MODE(mmu) != mode)
			continue;
		cmmu->cmmu_regs[reg] = val;
	}
}

void
m8820x_cmmu_set_cmd(u_int cmd, int cpu, vaddr_t addr)
{
	struct m8820x_cmmu *cmmu;
	int mmu, cnt;

	mmu = cpu << cmmu_shift;
	cmmu = m8820x_cmmu + mmu;

	/*
	 * We scan all CMMUs to find the matching ones and store the
	 * values there.
	 */
	for (cnt = 1 << cmmu_shift; cnt != 0; cnt--, mmu++, cmmu++) {
#ifdef M88200_HAS_ASYMMETRICAL_ASSOCIATION
		if (cmmu->cmmu_regs == NULL)
			continue;
#endif
		cmmu->cmmu_regs[CMMU_SAR] = addr;
		cmmu->cmmu_regs[CMMU_SCR] = cmd;
	}
}

void
m8820x_cmmu_set_cmd_if_mode(u_int cmd, int cpu, vaddr_t addr, int mode)
{
	struct m8820x_cmmu *cmmu;
	int mmu, cnt;

	mmu = cpu << cmmu_shift;
	cmmu = m8820x_cmmu + mmu;

	/*
	 * We scan all CMMUs to find the matching ones and store the
	 * values there.
	 */
	for (cnt = 1 << cmmu_shift; cnt != 0; cnt--, mmu++, cmmu++) {
#ifdef M88200_HAS_ASYMMETRICAL_ASSOCIATION
		if (cmmu->cmmu_regs == NULL)
			continue;
#endif
		if (CMMU_MODE(mmu) != mode)
			continue;
		cmmu->cmmu_regs[CMMU_SAR] = addr;
		cmmu->cmmu_regs[CMMU_SCR] = cmd;
	}
}

#ifdef M88200_HAS_SPLIT_ADDRESS
void
m8820x_cmmu_set_cmd_if_addr(u_int cmd, int cpu, vaddr_t addr)
{
	struct m8820x_cmmu *cmmu;
	int mmu, cnt;

	mmu = cpu << cmmu_shift;
	cmmu = m8820x_cmmu + mmu;

	/*
	 * We scan all CMMUs to find the matching ones and store the
	 * values there.
	 */
	for (cnt = 1 << cmmu_shift; cnt != 0; cnt--, mmu++, cmmu++) {
#ifdef M88200_HAS_ASYMMETRICAL_ASSOCIATION
		if (cmmu->cmmu_regs == NULL)
			continue;
#endif
		if (cmmu->cmmu_addr_mask != 0) {
			if ((addr & cmmu->cmmu_addr_mask) != cmmu->cmmu_addr)
				continue;
		}
		cmmu->cmmu_regs[CMMU_SAR] = addr;
		cmmu->cmmu_regs[CMMU_SCR] = cmd;
	}
}
#else
#define	m8820x_cmmu_set_cmd_if_addr	m8820x_cmmu_set_cmd
#endif

/*
 * Force a read from the CMMU status register, thereby forcing execution to
 * stop until all pending CMMU operations are finished.
 * This is used by the various cache invalidation functions.
 */
void
m8820x_cmmu_wait(int cpu)
{
	struct m8820x_cmmu *cmmu;
	int mmu, cnt;

	mmu = cpu << cmmu_shift;
	cmmu = m8820x_cmmu + mmu;

	/*
	 * We scan all related CMMUs and read their status register.
	 */
	for (cnt = 1 << cmmu_shift; cnt != 0; cnt--, mmu++, cmmu++) {
#ifdef M88200_HAS_ASYMMETRICAL_ASSOCIATION
		if (cmmu->cmmu_regs == NULL)
			continue;
#endif
#ifdef DEBUG
		if (cmmu->cmmu_regs[CMMU_SSR] & CMMU_SSR_BE) {
			panic("cache flush failed!");
		}
#else
		(void)cmmu->cmmu_regs[CMMU_SSR];
#endif
	}
}

/*
 * BATC routines
 */

static inline
void
m8820x_dbatc_set(cpuid_t cpu, uint batcno, batc_t batc)
{
	m8820x_cmmu_set_reg_if_mode(CMMU_BWP(batcno), batc, cpu, DATA_CMMU);
}

static inline
void
m8820x_ibatc_set(cpuid_t cpu, uint batcno, batc_t batc)
{
	m8820x_cmmu_set_reg_if_mode(CMMU_BWP(batcno), batc, cpu, INST_CMMU);
}

void
m8820x_batc_setup(cpuid_t cpu, apr_t cmode)
{
	paddr_t s_text, e_text, s_data, e_data,	e_rodata;
	uint batcno;
	batc_t batc, proto;
	extern caddr_t kernelstart;
	extern caddr_t etext;
	extern caddr_t erodata;
	extern caddr_t end;

	proto = BATC_SO | BATC_V;
	if (cmode & CACHE_WT)
		proto |= BATC_WT;
	if (cmode & CACHE_INH)
		proto |= BATC_INH;

	s_text = round_batc((paddr_t)&kernelstart);
	s_data = e_text = round_batc((paddr_t)&etext);
	e_rodata = round_batc((paddr_t)&erodata);
#if 0 /* not until pmap makes sure kvm starts on a BATC boundary */
	e_data = round_batc((paddr_t)&end);
#else
	e_data = trunc_batc((paddr_t)&end);
#endif

	/* map s_text..e_text with IBATC */
	batcno = 0;
	while (s_text != e_text) {
		batc = (s_text >> BATC_BLKSHIFT) << BATC_VSHIFT;
		batc |= (s_text >> BATC_BLKSHIFT) << BATC_PSHIFT;
		batc |= proto;
#ifdef DEBUG
		printf("cpu%d ibat%d %p(%08x)\n", cpu, batcno, s_text, batc);
#endif
		global_ibatc[batcno] = batc;
		s_text += BATC_BLKBYTES;
		if (++batcno == BATC_MAX)
			break;
	}

	/* map e_text..e_data with DBATC */
	if (cmode & CACHE_GLOBAL)
		proto |= BATC_GLOBAL;
	batcno = 0;
	while (s_data != e_data) {
		batc = (s_data >> BATC_BLKSHIFT) << BATC_VSHIFT;
		batc |= (s_data >> BATC_BLKSHIFT) << BATC_PSHIFT;
		batc |= proto;
		if (s_data < e_rodata)
			batc |= BATC_PROT;
#if defined(MULTIPROCESSOR)	/* XXX */
		else
			break;
#endif
#ifdef DEBUG
		printf("cpu%d dbat%d %p(%08x)\n", cpu, batcno, s_data, batc);
#endif
		global_dbatc[batcno] = batc;
		s_data += BATC_BLKBYTES;
		if (++batcno == BATC_MAX)
			break;
	}

	for (batcno = 0; batcno < BATC_MAX; batcno++) {
		m8820x_dbatc_set(cpu, batcno, global_dbatc[batcno]);
		m8820x_ibatc_set(cpu, batcno, global_ibatc[batcno]);
	}
}

/*
 * Should only be called after the calling cpus knows its cpu
 * number and main/secondary status. Should be called first
 * by the main processor, before the others are started.
*/
void
m8820x_cpu_configuration_print(int main)
{
#ifdef M88200_HAS_ASYMMETRICAL_ASSOCIATION
	struct m8820x_cmmu *cmmu;
#endif
	int pid = get_cpu_pid();
	int proctype = (pid & PID_ARN) >> ARN_SHIFT;
	int procvers = (pid & PID_VN) >> VN_SHIFT;
	int kind, nmmu, mmuno, cnt, cpu = cpu_number();

	printf("cpu%d: ", cpu);
	switch (proctype) {
	default:
		printf("unknown model arch 0x%x rev 0x%x\n",
		    proctype, procvers);
		break;
	case ARN_88100:
		printf("M88100 rev 0x%x", procvers);
#ifdef MULTIPROCESSOR
		if (main == 0)
			printf(", secondary");
#endif
		nmmu = 1 << cmmu_shift;
#ifdef M88200_HAS_ASYMMETRICAL_ASSOCIATION
		cmmu = m8820x_cmmu + (cpu << cmmu_shift);
		for (cnt = 1 << cmmu_shift; cnt != 0; cnt--, cmmu++)
			if (cmmu->cmmu_regs == NULL)
				nmmu--;
#endif
		printf(", %d CMMU\n", nmmu);

		for (kind = INST_CMMU; kind <= DATA_CMMU; kind++) {
			mmuno = (cpu << cmmu_shift) + kind;
			for (cnt = 1 << cmmu_shift; cnt != 0;
			    cnt -= 2, mmuno += 2)
				m8820x_cmmu_configuration_print(cpu, mmuno);
		}
		break;
	}

#ifndef ERRATA__XXX_USR
	{
		static int errata_warn = 0;

		if (proctype == ARN_88100 && procvers <= 10) {
			if (!errata_warn++)
				printf("WARNING: M88100 bug workaround code "
				    "not enabled.\nPlease recompile the kernel "
				    "with option ERRATA__XXX_USR !\n");
		}
	}
#endif
}

void
m8820x_cmmu_configuration_print(int cpu, int mmuno)
{
	struct m8820x_cmmu *cmmu;
	int mmuid, cssp;
	u_int line;
	uint32_t linestatus;
#ifdef M88200_HAS_SPLIT_ADDRESS
	int aline, abit, amask;
#endif

	cmmu = m8820x_cmmu + mmuno;
#ifdef M88200_HAS_ASYMMETRICAL_ASSOCIATION
	if (cmmu->cmmu_regs == NULL)
		return;
#endif

	mmuid = CMMU_TYPE(cmmu->cmmu_idr);

	printf("cpu%d: ", cpu);
	switch (mmuid) {
	case M88200_ID:
		printf("M88200 (16K)");
		break;
	case M88204_ID:
		printf("M88204 (64K)");
		break;
	default:
		printf("unknown CMMU id 0x%x", mmuid);
		break;
	}
	printf(" rev 0x%x,", CMMU_VERSION(cmmu->cmmu_idr));
#ifdef M88200_HAS_SPLIT_ADDRESS
	/*
	 * Print address lines
	 */
	amask = cmmu->cmmu_addr_mask;
	if (amask != 0) {
		aline = 0;
		while (amask != 0) {
			abit = ff1(amask);
			if ((cmmu->cmmu_addr & (1 << abit)) != 0)
				printf("%cA%02d",
				    aline != 0 ? '/' : ' ', abit);
			else
				printf("%cA%02d*",
				    aline != 0 ? '/' : ' ', abit);
			amask ^= 1 << abit;
		}
	} else if (cmmu_shift != 1) {
		/* unknown split scheme */
		printf(" split");
	} else
#endif
		printf(" full");
	printf(" %ccache\n", CMMU_MODE(mmuno) == INST_CMMU ? 'I' : 'D');

	/*
	 * Report disabled cache lines.
	 */
	for (cssp = mmuid == M88204_ID ? 3 : 0; cssp >= 0; cssp--)
		for (line = 0; line <= 255; line++) {
			cmmu->cmmu_regs[CMMU_SAR] =
			    line << MC88200_CACHE_SHIFT;
			linestatus = cmmu->cmmu_regs[CMMU_CSSP(cssp)];
			if (linestatus & (CMMU_CSSP_D3 | CMMU_CSSP_D2 |
			     CMMU_CSSP_D1 | CMMU_CSSP_D0)) {
				printf("cpu%d: cache line 0x%03x disabled\n",
				    cpu, (cssp << 8) | line);
				}
			}
}

/*
 * CMMU initialization routine
 */
cpuid_t
m8820x_init()
{
	cpuid_t cpu;

	cpu = m8820x_cpu_number();
	m8820x_initialize_cpu(cpu);
#if defined(__luna88k__) && !defined(MULTIPROCESSOR)
	m8820x_enable_other_cmmu_cache();
#endif
	return (cpu);
}

/*
 * Initialize the set of CMMUs tied to a particular CPU.
 */
void
m8820x_initialize_cpu(cpuid_t cpu)
{
	struct cpu_info *ci;
	struct m8820x_cmmu *cmmu;
	int mmuid, cssp;
	u_int line, cnt;
	uint32_t linestatus;
	apr_t apr;

	apr = ((0x00000 << PG_BITS) | CACHE_GLOBAL | CACHE_INH) & ~APR_V;

	cmmu = m8820x_cmmu + (cpu << cmmu_shift);

	/*
	 * Setup CMMU pointers for faster exception processing.
	 * This relies on the board-dependent code putting instruction
	 * CMMUs and data CMMUs interleaved with instruction CMMUs first.
	 */
	ci = &m88k_cpus[cpu];
	switch (cmmu_shift) {
	default:
		/* exception code may not use ci_pfsr fields, compute anyway */
		/* FALLTHROUGH */
	case 2:
		ci->ci_pfsr_d1 = (u_int)cmmu[3].cmmu_regs + CMMU_PFSR * 4;
		ci->ci_pfsr_i1 = (u_int)cmmu[2].cmmu_regs + CMMU_PFSR * 4;
		/* FALLTHROUGH */
	case 1:
		ci->ci_pfsr_d0 = (u_int)cmmu[1].cmmu_regs + CMMU_PFSR * 4;
		ci->ci_pfsr_i0 = (u_int)cmmu[0].cmmu_regs + CMMU_PFSR * 4;
		break;
	}

	for (cnt = 1 << cmmu_shift; cnt != 0; cnt--, cmmu++) {
#ifdef M88200_HAS_ASYMMETRICAL_ASSOCIATION
		if (cmmu->cmmu_regs == NULL)
			continue;
#endif
		cmmu->cmmu_idr = cmmu->cmmu_regs[CMMU_IDR];
		mmuid = CMMU_TYPE(cmmu->cmmu_idr);

		/*
		 * Reset cache, but keep disabled lines disabled.
		 *
		 * Note that early Luna88k PROM apparently forget to
		 * initialize the last line (#255) correctly, and the
		 * CMMU initializes with whatever its state upon powerup
		 * happens to be.
		 *
		 * It is then unlikely that these particular cache lines
		 * have been exercized by the self-tests; better disable
		 * the whole line.
		 */
		for (cssp = mmuid == M88204_ID ? 3 : 0; cssp >= 0; cssp--)
			for (line = 0; line <= 255; line++) {
				cmmu->cmmu_regs[CMMU_SAR] =
				    line << MC88200_CACHE_SHIFT;
				linestatus = cmmu->cmmu_regs[CMMU_CSSP(cssp)];
				if (linestatus & (CMMU_CSSP_D3 | CMMU_CSSP_D2 |
				     CMMU_CSSP_D1 | CMMU_CSSP_D0))
					linestatus =
					    CMMU_CSSP_D3 | CMMU_CSSP_D2 |
					    CMMU_CSSP_D1 | CMMU_CSSP_D0;
				else
					linestatus = 0;
				cmmu->cmmu_regs[CMMU_CSSP(cssp)] = linestatus |
				    CMMU_CSSP_L5 | CMMU_CSSP_L4 |
				    CMMU_CSSP_L3 | CMMU_CSSP_L2 |
				    CMMU_CSSP_L1 | CMMU_CSSP_L0 |
				    CMMU_CSSP_VV(3, CMMU_VV_INVALID) |
				    CMMU_CSSP_VV(2, CMMU_VV_INVALID) |
				    CMMU_CSSP_VV(1, CMMU_VV_INVALID) |
				    CMMU_CSSP_VV(0, CMMU_VV_INVALID);
			}

		/*
		 * Set the SCTR, SAPR, and UAPR to some known state.
		 * Snooping is always enabled, so that we do not need to
		 * writeback userland code pages when they first get filled
		 * as data pages.
		 */
		cmmu->cmmu_regs[CMMU_SCTR] = CMMU_SCTR_SE;

		cmmu->cmmu_regs[CMMU_SAPR] = cmmu->cmmu_regs[CMMU_UAPR] = apr;

		cmmu->cmmu_regs[CMMU_BWP0] = cmmu->cmmu_regs[CMMU_BWP1] =
		cmmu->cmmu_regs[CMMU_BWP2] = cmmu->cmmu_regs[CMMU_BWP3] =
		cmmu->cmmu_regs[CMMU_BWP4] = cmmu->cmmu_regs[CMMU_BWP5] =
		cmmu->cmmu_regs[CMMU_BWP6] = cmmu->cmmu_regs[CMMU_BWP7] = 0;
		cmmu->cmmu_regs[CMMU_SCR] = CMMU_FLUSH_CACHE_INV_ALL;
		(void)cmmu->cmmu_regs[CMMU_SSR];
		cmmu->cmmu_regs[CMMU_SCR] = CMMU_FLUSH_SUPER_ALL;
		cmmu->cmmu_regs[CMMU_SCR] = CMMU_FLUSH_USER_ALL;
	}

	/*
	 * Enable instruction cache.
	 */
	apr &= ~CACHE_INH;
	m8820x_cmmu_set_reg_if_mode(CMMU_SAPR, apr, cpu, INST_CMMU);

	/*
	 * Data cache will be enabled at pmap_bootstrap_cpu() time,
	 * because the PROM won't likely expect its work area in memory
	 * to be cached. On at least aviion, starting secondary processors
	 * returns an error code although the processor has correctly spun
	 * up, if the PROM work area is cached.
	 */
#ifdef dont_do_this_at_home
	apr |= CACHE_WT;
	m8820x_cmmu_set_reg_if_mode(CMMU_SAPR, apr, cpu, DATA_CMMU);
#endif

	ci->ci_zeropage = m8820x_zeropage;
	ci->ci_copypage = m8820x_copypage;
}

/*
 * Just before poweroff or reset....
 */
void
m8820x_shutdown()
{
	u_int cmmu_num;
	struct m8820x_cmmu *cmmu;

	CMMU_LOCK;

	cmmu = m8820x_cmmu;
	for (cmmu_num = 0; cmmu_num < max_cmmus; cmmu_num++, cmmu++) {
#ifdef M88200_HAS_ASYMMETRICAL_ASSOCIATION
		if (cmmu->cmmu_regs == NULL)
			continue;
#endif
		cmmu->cmmu_regs[CMMU_SAPR] = cmmu->cmmu_regs[CMMU_UAPR] =
		    ((0x00000 << PG_BITS) | CACHE_INH) &
		    ~(CACHE_WT | CACHE_GLOBAL | APR_V);
	}

	CMMU_UNLOCK;
}

/*
 * Older systems do not xmem correctly on writeback cache lines, causing
 * the remainder of the cache line to be corrupted.
 * This behaviour has been observed on a system with 88100 rev 8 and
 * 88200 rev 5; it is unknown whether the culprit is the 88100 or the 88200;
 * however we can rely upon 88100 rev 10 onwards and 88200 rev 7 onwards
 * (as well as all 88204 revs) to be safe.
 */
apr_t
m8820x_apr_cmode()
{
	u_int cmmu_num;
	struct m8820x_cmmu *cmmu;

	cmmu = m8820x_cmmu;
	for (cmmu_num = max_cmmus; cmmu_num != 0; cmmu_num--, cmmu++) {
#ifdef M88200_HAS_ASYMMETRICAL_ASSOCIATION
		if (cmmu->cmmu_regs == NULL)
			continue;
#endif
		/*
		 * XXX 88200 v6 could not be tested. Do 88200 ever have
		 * XXX even version numbers anyway?
		 */
		if (CMMU_TYPE(cmmu->cmmu_idr) == M88200_ID &&
		    CMMU_VERSION(cmmu->cmmu_idr) <= 6)
			return CACHE_WT;
	}
	/*
	 * XXX 88100 v9 could not be tested. Might be unaffected, but
	 * XXX better be safe than sorry.
	 */
	if (((get_cpu_pid() & PID_VN) >> VN_SHIFT) <= 9)
		return CACHE_WT;

	return CACHE_DFL;
}

/*
 * Older systems require page tables to be cache inhibited (write-through
 * won't even cut it).
 * We can rely upon 88200 rev 9 onwards to be safe (as well as all 88204
 * revs).
 */
apr_t
m8820x_pte_cmode()
{
	u_int cmmu_num;
	struct m8820x_cmmu *cmmu;

	cmmu = m8820x_cmmu;
	for (cmmu_num = max_cmmus; cmmu_num != 0; cmmu_num--, cmmu++) {
#ifdef M88200_HAS_ASYMMETRICAL_ASSOCIATION
		if (cmmu->cmmu_regs == NULL)
			continue;
#endif
		/*
		 * XXX 88200 v8 could not be tested. Do 88200 ever have
		 * XXX even version numbers anyway?
		 */
		if (CMMU_TYPE(cmmu->cmmu_idr) == M88200_ID &&
		    CMMU_VERSION(cmmu->cmmu_idr) <= 8)
			return CACHE_INH;
	}

	return CACHE_WT;
}

void
m8820x_set_sapr(apr_t ap)
{
	int cpu = cpu_number();

	CMMU_LOCK;

	m8820x_cmmu_set_reg(CMMU_SAPR, ap, cpu);

	CMMU_UNLOCK;
}

void
m8820x_set_uapr(apr_t ap)
{
	u_int32_t psr;
	int cpu = cpu_number();

	psr = get_psr();
	set_psr(psr | PSR_IND);
	CMMU_LOCK;

	m8820x_cmmu_set_reg(CMMU_UAPR, ap, cpu);

	CMMU_UNLOCK;
	set_psr(psr);
}

/*
 * Functions that invalidate TLB entries.
 */

void
m8820x_tlbis(cpuid_t cpu, vaddr_t va, pt_entry_t pte)
{
	u_int32_t psr;

	psr = get_psr();
	set_psr(psr | PSR_IND);
	CMMU_LOCK;
	m8820x_cmmu_set_cmd_if_addr(CMMU_FLUSH_SUPER_PAGE, cpu, va);
	CMMU_UNLOCK;
	set_psr(psr);
}

void
m8820x_tlbiu(cpuid_t cpu, vaddr_t va, pt_entry_t pte)
{
	u_int32_t psr;

	psr = get_psr();
	set_psr(psr | PSR_IND);
	CMMU_LOCK;
	m8820x_cmmu_set_cmd_if_addr(CMMU_FLUSH_USER_PAGE, cpu, va);
	CMMU_UNLOCK;
	set_psr(psr);
}

void
m8820x_tlbia(cpuid_t cpu)
{
	u_int32_t psr;

	psr = get_psr();
	set_psr(psr | PSR_IND);
	CMMU_LOCK;
	m8820x_cmmu_set_reg(CMMU_SCR, CMMU_FLUSH_USER_ALL, cpu);
	CMMU_UNLOCK;
	set_psr(psr);
}

/*
 * Functions that invalidate caches.
 *
 * Cache operations require physical addresses. 
 *
 * We don't writeback instruction caches prior to invalidate because they
 * are never modified.
 *
 * Note that on systems with more than two CMMUs per CPU, we can not benefit
 * from the address split - the split is done on virtual (not translated yet)
 * addresses, but caches are physically indexed.
 */

#define	trunc_cache_line(a)	((a) & ~(MC88200_CACHE_LINE - 1))
#define	round_cache_line(a)	trunc_cache_line((a) + MC88200_CACHE_LINE - 1)

/*
 * invalidate I$, writeback and invalidate D$
 */
void
m8820x_cache_wbinv(cpuid_t cpu, paddr_t pa, psize_t size)
{
	u_int32_t psr;
	psize_t count;

	size = round_cache_line(pa + size) - trunc_cache_line(pa);
	pa = trunc_cache_line(pa);

	psr = get_psr();
	set_psr(psr | PSR_IND);
	CMMU_LOCK;

	while (size != 0) {
		if ((pa & PAGE_MASK) == 0 && size >= PAGE_SIZE) {
			m8820x_cmmu_set_cmd(CMMU_FLUSH_CACHE_CBI_PAGE, cpu, pa);
			count = PAGE_SIZE;
		} else {
			m8820x_cmmu_set_cmd(CMMU_FLUSH_CACHE_CBI_LINE, cpu, pa);
			count = MC88200_CACHE_LINE;
		}
		pa += count;
		size -= count;
		m8820x_cmmu_wait(cpu);
	}

	CMMU_UNLOCK;
	set_psr(psr);
}

/*
 * writeback D$
 */
void
m8820x_dcache_wb(cpuid_t cpu, paddr_t pa, psize_t size)
{
	u_int32_t psr;
	psize_t count;

	size = round_cache_line(pa + size) - trunc_cache_line(pa);
	pa = trunc_cache_line(pa);

	psr = get_psr();
	set_psr(psr | PSR_IND);
	CMMU_LOCK;

	while (size != 0) {
		if ((pa & PAGE_MASK) == 0 && size >= PAGE_SIZE) {
			m8820x_cmmu_set_cmd_if_mode(CMMU_FLUSH_CACHE_CB_PAGE,
			    cpu, pa, DATA_CMMU);
			count = PAGE_SIZE;
		} else {
			m8820x_cmmu_set_cmd_if_mode(CMMU_FLUSH_CACHE_CB_LINE,
			    cpu, pa, DATA_CMMU);
			count = MC88200_CACHE_LINE;
		}
		pa += count;
		size -= count;
		m8820x_cmmu_wait(cpu);
	}

	CMMU_UNLOCK;
	set_psr(psr);
}

/*
 * invalidate I$
 */
void
m8820x_icache_inv(cpuid_t cpu, paddr_t pa, psize_t size)
{
	u_int32_t psr;
	psize_t count;

	size = round_cache_line(pa + size) - trunc_cache_line(pa);
	pa = trunc_cache_line(pa);

	psr = get_psr();
	set_psr(psr | PSR_IND);
	CMMU_LOCK;

	while (size != 0) {
		if ((pa & PAGE_MASK) == 0 && size >= PAGE_SIZE) {
			m8820x_cmmu_set_cmd_if_mode(CMMU_FLUSH_CACHE_INV_PAGE,
			    cpu, pa, INST_CMMU);
			count = PAGE_SIZE;
		} else {
			m8820x_cmmu_set_cmd_if_mode(CMMU_FLUSH_CACHE_INV_LINE,
			    cpu, pa, INST_CMMU);
			count = MC88200_CACHE_LINE;
		}
		pa += count;
		size -= count;
		m8820x_cmmu_wait(cpu);
	}

	CMMU_UNLOCK;
	set_psr(psr);
}

/*
 * writeback D$
 */
void
m8820x_cmmu_wb_locked(int cpu, paddr_t pa, psize_t size)
{
	if (size <= MC88200_CACHE_LINE) {
		m8820x_cmmu_set_cmd_if_mode(CMMU_FLUSH_CACHE_CB_LINE,
		    cpu, pa, DATA_CMMU);
	} else {
		m8820x_cmmu_set_cmd_if_mode(CMMU_FLUSH_CACHE_CB_PAGE,
		    cpu, pa, DATA_CMMU);
	}
}

/*
 * invalidate I$, writeback and invalidate D$
 */
void
m8820x_cmmu_wbinv_locked(int cpu, paddr_t pa, psize_t size)
{
	if (size <= MC88200_CACHE_LINE)
		m8820x_cmmu_set_cmd(CMMU_FLUSH_CACHE_CBI_LINE, cpu, pa);
	else
		m8820x_cmmu_set_cmd(CMMU_FLUSH_CACHE_CBI_PAGE, cpu, pa);
}

/*
 * invalidate I$ and D$
 */
void
m8820x_cmmu_inv_locked(int cpu, paddr_t pa, psize_t size)
{
	if (size <= MC88200_CACHE_LINE)
		m8820x_cmmu_set_cmd(CMMU_FLUSH_CACHE_INV_LINE, cpu, pa);
	else
		m8820x_cmmu_set_cmd(CMMU_FLUSH_CACHE_INV_PAGE, cpu, pa);
}

/*
 * High level cache handling functions (used by bus_dma).
 *
 * On multiprocessor systems, since the CMMUs snoop each other, they
 * all have a coherent view of the data. Thus, we only need to writeback
 * on a single CMMU. However, invalidations need to be done on all CMMUs.
 */

void
m8820x_dma_cachectl(paddr_t _pa, psize_t _size, int op)
{
	u_int32_t psr;
	int cpu;
#ifdef MULTIPROCESSOR
	struct cpu_info *ci = curcpu();
#endif
	paddr_t pa;
	psize_t size, count;
	void (*flusher)(int, paddr_t, psize_t);
	uint8_t lines[2 * MC88200_CACHE_LINE];
	paddr_t pa1, pa2;
	psize_t sz1, sz2;

	pa = trunc_cache_line(_pa);
	size = round_cache_line(_pa + _size) - pa;
	sz1 = sz2 = 0;

	switch (op) {
	case DMA_CACHE_SYNC:
		flusher = m8820x_cmmu_wb_locked;
		break;
	case DMA_CACHE_SYNC_INVAL:
		flusher = m8820x_cmmu_wbinv_locked;
		break;
	default:
	case DMA_CACHE_INV:
		pa1 = pa;
		sz1 = _pa - pa1;
		pa2 = _pa + _size;
		sz2 = pa + size - pa2;
		flusher = m8820x_cmmu_inv_locked;
		break;
	}

#ifndef MULTIPROCESSOR
	cpu = cpu_number();
#endif

	psr = get_psr();
	set_psr(psr | PSR_IND);
	CMMU_LOCK;

	/*
	 * Preserve the data from incomplete cache lines about to be
	 * invalidated, if necessary.
	 */
	if (sz1 != 0)
		bcopy((void *)pa1, lines, sz1);
	if (sz2 != 0)
		bcopy((void *)pa2, lines + MC88200_CACHE_LINE, sz2);

	while (size != 0) {
		count = (pa & PAGE_MASK) == 0 && size >= PAGE_SIZE ?
		    PAGE_SIZE : MC88200_CACHE_LINE;

#ifdef MULTIPROCESSOR
		/*
		 * Theoretically, it should be possible to issue the writeback
		 * operation only on the CMMU which has the affected cache
		 * lines in its memory; snooping would force the other CMMUs
		 * to invalidate their own copy of the line, if any.
		 *
		 * Unfortunately, there is no cheap way to figure out
		 * which CMMU has the lines (and has them as dirty).
		 */
		for (cpu = 0; cpu < MAX_CPUS; cpu++) {
			if (!ISSET(m88k_cpus[cpu].ci_flags, CIF_ALIVE))
				continue;
			(*flusher)(cpu, pa, count);
		}
		for (cpu = 0; cpu < MAX_CPUS; cpu++) {
			if (!ISSET(m88k_cpus[cpu].ci_flags, CIF_ALIVE))
				continue;
			m8820x_cmmu_wait(cpu);
		}
#else	/* MULTIPROCESSOR */
		(*flusher)(cpu, pa, count);
		m8820x_cmmu_wait(cpu);
#endif	/* MULTIPROCESSOR */

		pa += count;
		size -= count;
	}

	/*
	 * Restore data from incomplete cache lines having been invalidated,
	 * if necessary, write them back, and invalidate them again.
	 * (Note that these lines have been invalidated from all processors
	 *  in the loop above, so there is no need to remote invalidate them
	 *  again.)
	 */
	if (sz1 != 0)
		bcopy(lines, (void *)pa1, sz1);
	if (sz2 != 0)
		bcopy(lines + MC88200_CACHE_LINE, (void *)pa2, sz2);
	if (sz1 != 0) {
#ifdef MULTIPROCESSOR
		m8820x_cmmu_wbinv_locked(ci->ci_cpuid, pa1, MC88200_CACHE_LINE);
		m8820x_cmmu_wait(ci->ci_cpuid);
#else
		m8820x_cmmu_wbinv_locked(cpu, pa1, MC88200_CACHE_LINE);
		m8820x_cmmu_wait(cpu);
#endif
	}
	if (sz2 != 0) {
		pa2 = trunc_cache_line(pa2);
#ifdef MULTIPROCESSOR
		m8820x_cmmu_wbinv_locked(ci->ci_cpuid, pa2, MC88200_CACHE_LINE);
		m8820x_cmmu_wait(ci->ci_cpuid);
#else
		m8820x_cmmu_wbinv_locked(cpu, pa2, MC88200_CACHE_LINE);
		m8820x_cmmu_wait(cpu);
#endif
	}

	CMMU_UNLOCK;
	set_psr(psr);
}

#ifdef MULTIPROCESSOR
void
m8820x_dma_cachectl_local(paddr_t pa, psize_t size, int op)
{
	/* This function is not used on 88100 systems */
}
#endif

#if defined(__luna88k__) && !defined(MULTIPROCESSOR)
/*
 * On luna88k, secondary processors are not disabled while the kernel
 * is initializing.  They are running an infinite loop in
 * locore.S:secondary_init on non-MULTIPROCESSOR kernel.  Then, after
 * initializing the CMMUs tied to the currently-running processor, we
 * turn on the instruction cache of other processors to make them
 * happier.
 */
void
m8820x_enable_other_cmmu_cache()
{
	int cpu, master_cpu = cpu_number();

	for (cpu = 0; cpu < ncpusfound; cpu++) {
		if (cpu == master_cpu)
			continue;
		/* Enable other processor's instruction cache */
		m8820x_cmmu_set_reg_if_mode(CMMU_SAPR, CACHE_GLOBAL,
			cpu, INST_CMMU);
	}
}
#endif
@


1.60
log
@Even saner kernel layout, so that .rodata can be batc mapped by a read-only
dbatc. Add batc mapping support for 88110 systems as well.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.59 2013/11/02 23:10:30 miod Exp $	*/
d176 4
a179 2
void	m8820x_dbatc_set(cpuid_t, uint, uint32_t);
void	m8820x_ibatc_set(cpuid_t, uint, uint32_t);
d350 1
d352 1
a352 1
m8820x_dbatc_set(cpuid_t cpu, uint batcno, uint32_t batc)
d357 1
d359 1
a359 1
m8820x_ibatc_set(cpuid_t cpu, uint batcno, uint32_t batc)
d369 1
a369 1
	uint32_t batc, proto;
d399 1
a399 1
		m8820x_ibatc_set(cpu, batcno, batc);
d422 1
a422 1
		m8820x_dbatc_set(cpu, batcno, batc);
d426 5
@


1.59
log
@Create the initial page tables in the area between the end of the firmware
data area and the kernel image, whenever possible.

On 88100/88200 systems, use BATC mappings to map the kernel text (and the
kernel data for non-MULTIPROCESSOR kernels). 88110 to follow soon.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.58 2013/09/23 04:47:09 miod Exp $	*/
d363 1
a363 1
	paddr_t s_text, e_text, s_data, e_data;
d368 1
d378 2
a379 2
	e_text = round_batc((paddr_t)&etext);
	s_data = trunc_batc((paddr_t)&etext);
d401 1
a401 2
#if !defined(MULTIPROCESSOR)	/* XXX */
	/* map s_data..e_data with DBATC */
d409 6
a422 1
#endif
@


1.58
log
@- change m8820x_cmmu_set_reg() and m8820x_cmmu_set_cmd() to perform
  unconditional actions. Introduce _if_addr() and _if_mode() variants of these
  to act on a given cmmu type only, or on a matching address line only.
  This makes the code slightly larger but easier to read and a tad faster.
- report each cmmu on its own line in dmesg, sorted by type (I$ first, then D$).
  make sure disabled line information ends up in dmesg, rather than in the
  early bootstrap messages.
- fix the multiprocessor writeback logic in m8820x_dma_cachectl() again to be
  more reliable; also only rendezvous the cmmus after all cmmu operation have
  been issued, instead of doing a rendezvous per cpu.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.57 2013/08/15 19:32:12 miod Exp $	*/
d91 1
d110 1
d176 3
d342 76
@


1.57
log
@Be sure to always invoke cache routines with properly rounded addresses;
the bus_dmamap_sync() bowels would sometimes use incorrectly rounded
addresses, which has been apparently harmless so far, but better be safe
than sorry.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.56 2013/06/30 10:04:40 aoyama Exp $	*/
d3 1
a3 1
 * Copyright (c) 2004, 2007, 2010, 2011, Miodrag Vallat.
d160 6
a165 2
void	m8820x_cmmu_set_reg(int, u_int, int, int, int);
void	m8820x_cmmu_set_cmd(u_int, int, int, int, vaddr_t);
d183 1
a183 1
m8820x_cmmu_set_reg(int reg, u_int val, int flags, int cpu, int mode)
a199 4
		if ((flags & MODE_VAL) != 0) {
			if (CMMU_MODE(mmu) != mode)
				continue;
		}
d205 25
a229 1
m8820x_cmmu_set_cmd(u_int cmd, int flags, int cpu, int mode, vaddr_t addr)
d246 30
a275 4
		if ((flags & MODE_VAL) != 0) {
			if (CMMU_MODE(mmu) != mode)
				continue;
		}
d277 19
a295 1
		if ((flags & ADDR_VAL) != 0 && cmmu->cmmu_addr_mask != 0) {
a298 1
#endif
d303 3
d347 1
d349 1
d353 1
a353 4
	int reported, nmmu, mmu, cnt, cpu = cpu_number();
#ifdef M88200_HAS_SPLIT_ADDRESS
	int aline, abit, amask;
#endif
d358 1
a358 1
		printf("unknown model arch 0x%x rev 0x%x",
d369 2
a370 3
		mmu = cpu << cmmu_shift;
		cmmu = m8820x_cmmu + mmu;
		for (cnt = 1 << cmmu_shift; cnt != 0; cnt--, mmu++, cmmu++)
d374 1
a374 7
		printf(", %d CMMU", nmmu);

		mmu = cpu << cmmu_shift;
		cmmu = m8820x_cmmu + mmu;
		reported = 0;
		for (cnt = 1 << cmmu_shift; cnt != 0; cnt--, mmu++, cmmu++) {
			int mmuid;
d376 5
a380 52
#ifdef M88200_HAS_ASYMMETRICAL_ASSOCIATION
			if (cmmu->cmmu_regs == NULL)
				continue;
#endif

			mmuid = CMMU_TYPE(cmmu->cmmu_idr);

			if (reported++ % 2 == 0)
				printf("\ncpu%d: ", cpu);
			else
				printf(", ");

			switch (mmuid) {
			case M88200_ID:
				printf("M88200 (16K)");
				break;
			case M88204_ID:
				printf("M88204 (64K)");
				break;
			default:
				printf("unknown CMMU id 0x%x", mmuid);
				break;
			}
			printf(" rev 0x%x,", CMMU_VERSION(cmmu->cmmu_idr));
#ifdef M88200_HAS_SPLIT_ADDRESS
			/*
			 * Print address lines
			 */
			amask = cmmu->cmmu_addr_mask;
			if (amask != 0) {
				aline = 0;
				while (amask != 0) {
					abit = ff1(amask);
					if ((cmmu->cmmu_addr &
					    (1 << abit)) != 0)
						printf("%cA%02d",
						    aline != 0 ? '/' : ' ',
						    abit);
					else
						printf("%cA%02d*",
						    aline != 0 ? '/' : ' ',
						    abit);
					amask ^= 1 << abit;
				}
			} else if (cmmu_shift != 1) {
				/* unknown split scheme */
				printf(" split");
			} else
#endif
				printf(" full");
			printf(" %ccache",
			    CMMU_MODE(mmu) == INST_CMMU ? 'I' : 'D');
a383 1
	printf("\n");
d399 73
d496 1
d498 1
a498 1
	int cssp, type;
d531 1
a531 1
		type = CMMU_TYPE(cmmu->cmmu_idr);
d534 10
a543 1
		 * Reset cache
d545 1
a545 1
		for (cssp = type == M88204_ID ? 3 : 0; cssp >= 0; cssp--)
d549 9
a557 14
				if (cmmu->cmmu_regs[CMMU_CSSP(cssp)] &
				    (CMMU_CSSP_D3 | CMMU_CSSP_D2 |
				     CMMU_CSSP_D1 | CMMU_CSSP_D0)) {
					printf("cpu%d: CMMU@@%p has disabled"
					    " cache lines in set 0x%03x,"
					    " cssp %08x\n",
					    cpu, cmmu->cmmu_regs,
					    (cssp << 8) | line,
					    cmmu->cmmu_regs[CMMU_CSSP(cssp)]);
				}
				cmmu->cmmu_regs[CMMU_CSSP(cssp)] =
				    (cmmu->cmmu_regs[CMMU_CSSP(cssp)] &
				     ~(CMMU_CSSP_D3 | CMMU_CSSP_D2 |
				       CMMU_CSSP_D1 | CMMU_CSSP_D0)) |
d591 1
a591 1
	m8820x_cmmu_set_reg(CMMU_SAPR, apr, MODE_VAL, cpu, INST_CMMU);
d602 1
a602 1
	m8820x_cmmu_set_reg(CMMU_SAPR, apr, MODE_VAL, cpu, DATA_CMMU);
d709 1
a709 1
	m8820x_cmmu_set_reg(CMMU_SAPR, ap, 0, cpu, 0);
d724 1
a724 1
	m8820x_cmmu_set_reg(CMMU_UAPR, ap, 0, cpu, 0);
d742 1
a742 1
	m8820x_cmmu_set_cmd(CMMU_FLUSH_SUPER_PAGE, ADDR_VAL, cpu, 0, va);
d755 1
a755 1
	m8820x_cmmu_set_cmd(CMMU_FLUSH_USER_PAGE, ADDR_VAL, cpu, 0, va);
d768 1
a768 1
	m8820x_cmmu_set_reg(CMMU_SCR, CMMU_FLUSH_USER_ALL, 0, cpu, 0);
d807 1
a807 2
			m8820x_cmmu_set_cmd(CMMU_FLUSH_CACHE_CBI_PAGE,
			    0, cpu, 0, pa);
d810 1
a810 2
			m8820x_cmmu_set_cmd(CMMU_FLUSH_CACHE_CBI_LINE,
			    0, cpu, 0, pa);
d840 2
a841 2
			m8820x_cmmu_set_cmd(CMMU_FLUSH_CACHE_CB_PAGE,
			    MODE_VAL, cpu, DATA_CMMU, pa);
d844 2
a845 2
			m8820x_cmmu_set_cmd(CMMU_FLUSH_CACHE_CB_LINE,
			    MODE_VAL, cpu, DATA_CMMU, pa);
d875 2
a876 2
			m8820x_cmmu_set_cmd(CMMU_FLUSH_CACHE_INV_PAGE,
			    MODE_VAL, cpu, INST_CMMU, pa);
d879 2
a880 2
			m8820x_cmmu_set_cmd(CMMU_FLUSH_CACHE_INV_LINE,
			    MODE_VAL, cpu, INST_CMMU, pa);
d899 2
a900 2
		m8820x_cmmu_set_cmd(CMMU_FLUSH_CACHE_CB_LINE,
		    MODE_VAL, cpu, DATA_CMMU, pa);
d902 2
a903 2
		m8820x_cmmu_set_cmd(CMMU_FLUSH_CACHE_CB_PAGE,
		    MODE_VAL, cpu, DATA_CMMU, pa);
a904 1
	m8820x_cmmu_wait(cpu);
d913 4
a916 8
	if (size <= MC88200_CACHE_LINE) {
		m8820x_cmmu_set_cmd(CMMU_FLUSH_CACHE_CBI_LINE,
		    0, cpu, 0, pa);
	} else {
		m8820x_cmmu_set_cmd(CMMU_FLUSH_CACHE_CBI_PAGE,
		    0, cpu, 0, pa);
	}
	m8820x_cmmu_wait(cpu);
d925 4
a928 6
	if (size <= MC88200_CACHE_LINE) {
		m8820x_cmmu_set_cmd(CMMU_FLUSH_CACHE_INV_LINE, 0, cpu, 0, pa);
	} else {
		m8820x_cmmu_set_cmd(CMMU_FLUSH_CACHE_INV_PAGE, 0, cpu, 0, pa);
	}
	m8820x_cmmu_wait(cpu);
d997 18
a1014 12
		/* writeback on a single cpu... */
		(*flusher)(ci->ci_cpuid, pa, count);

		/* invalidate on all... */
		if (flusher != m8820x_cmmu_wb_locked) {
			for (cpu = 0; cpu < MAX_CPUS; cpu++) {
				if (!ISSET(m88k_cpus[cpu].ci_flags, CIF_ALIVE))
					continue;
				if (cpu == ci->ci_cpuid)
					continue;
				m8820x_cmmu_inv_locked(cpu, pa, count);
			}
d1018 1
d1039 1
d1042 1
d1049 1
d1052 1
d1086 2
a1087 2
		m8820x_cmmu_set_reg(CMMU_SAPR, CACHE_GLOBAL,
			MODE_VAL, cpu, INST_CMMU);
@


1.56
log
@Add a luna88k-specific function to initialize the instruction cmmu
SAPR register.

On luna88k, secondary processors are not disabled while the kernel is
initializing.  They are running an infinite loop in
locore.S:secondary_init on non-MULTIPROCESSOR kernel.  Then, after
initializing the CMMUs tied to the currently-running processor, we
turn on the instruction cache of other processors to make them
happier.

As a bonus, on non-MULTIPROCESSOR kernel, the power switch LED of
luna88k is blinking green and orange again.  According to the hardware
manual, it indicates processors' cache hit status.

suggested and ok miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.55 2013/05/25 17:49:54 miod Exp $	*/
d954 1
@


1.55
log
@Fix wbinv routine used by bus_dmamap_sync() to correctly operate on all cmmus,
instead of I$ cmmu only.

This longstanding bug has been introduced in r1.44, which commit message was
right mentioning that it `fixes some bugs, probably introduces new ones as
well'.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.54 2013/05/17 22:33:25 miod Exp $	*/
d166 3
d395 3
d970 24
@


1.54
log
@Extend cmmu routines to return the caching mode to use for page tables.

Alter the 88200-specific code to enforce cache-inhibited page tables for
extremely old 88200 versions, and to disable write-back caching on systems
where xmem instructions do not behave correctly when applied to write-back
cached addresses.

No change introduced on 88110 systems, as well as most 88100 systems; the
affected systems are 88100 systems with 88100 revision < 10 and/or 88200
revision < 7; that is, only early MVME181 and MVME188 (not 188A) systems.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.53 2013/05/14 21:58:09 miod Exp $	*/
d745 1
a745 1
			    0, cpu, 0, pa);
d749 1
a749 1
			    0, cpu, 0, pa);
d820 1
a820 1
		    MODE_VAL, cpu, 0, pa);
d823 1
a823 1
		    MODE_VAL, cpu, 0, pa);
@


1.53
log
@Declare the cmmu-related variables which are set early in the kernel life,
before pmap_bootstrap(), as located in .rodata. This will get them
write-protected after pmap has initialized, for free.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.52 2013/02/19 21:02:06 miod Exp $	*/
d94 1
d114 1
d309 1
a309 1
			int idr, mmuid;
d316 1
a316 2
			idr = cmmu->cmmu_regs[CMMU_IDR];
			mmuid = CMMU_TYPE(idr);
d334 1
a334 1
			printf(" rev 0x%x,", CMMU_VERSION(idr));
d436 2
a437 1
		type = CMMU_TYPE(cmmu->cmmu_regs[CMMU_IDR]);
d536 8
a543 1
/* not used */
d547 24
d572 30
@


1.52
log
@Introduce a new cmmu method to return the preferred cache mode bits for the
kernel APR. Return write-back for every design but those involving 88410,
where write through is returned.

Apparently the use of writeback on single-processor kernels using 88410 (197SP,
197DP) has only been working by fat chance, and the last two years of uvm
changes, as well as the switch to ELF (causing kernel rodata to move `up')
exposes silent memory corruption on (88410-size) aliased addresses.
(I am guilty of not using my 197DP board much after making 197LE write-back
capable, as 197LE turned out to be faster and more stable, for I would have
noticed this earlier).

Further thought needs to happen about this. It might be possible to switch to
writeback by default again as long as bus_dma maps things write-through on
88410 designs, and perhaps with a part of the kernel mapped with a write-through
BATC, since BATC have precedence upon page tables. Right now I'm trying to get
a stable release out of the door.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.51 2013/02/17 18:07:36 miod Exp $	*/
d150 6
a155 3
struct m8820x_cmmu m8820x_cmmu[MAX_CMMUS];
u_int max_cmmus;
u_int cmmu_shift;
@


1.51
log
@Constify struct cmmu.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.50 2011/10/25 18:38:06 miod Exp $	*/
d93 1
d112 1
d529 7
@


1.50
log
@Replace the naive 88110 tlb update code, which would always invalidate the
whole tlb (32 of 'em), with smarter `tlb probe and update with new pte if tlb
match found' code. This makes the 88110-specific pmap_update() unnecessary, as
updates are no longer aggregated to avoid the number of flushes. This also
makes tlb handling similar between 88100 and 88110, from the pmap's point of
view, so there is no need to use different routines.

No impact on 88100, no user-noticeable performance change on 88100 GENERIC,
slight improvement on 88110 GENERIC.MP.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.49 2011/10/09 17:02:14 miod Exp $	*/
d105 1
a105 1
struct cmmu_p cmmu8820x = {
@


1.49
log
@Correctly handle invalidate of partial cache lines, for the Nth time.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.48 2011/10/09 17:01:34 miod Exp $	*/
d95 3
a97 2
void	m8820x_tlb_inv(cpuid_t, u_int, vaddr_t);
void	m8820x_tlb_inv_all(cpuid_t);
d113 3
a115 2
	m8820x_tlb_inv,
	m8820x_tlb_inv_all,
d562 1
a562 1
m8820x_tlb_inv(cpuid_t cpu, u_int kernel, vaddr_t vaddr)
d569 1
a569 2
	m8820x_cmmu_set_cmd(kernel ? CMMU_FLUSH_SUPER_PAGE :
	    CMMU_FLUSH_USER_PAGE, ADDR_VAL, cpu, 0, vaddr);
d575 14
a588 1
m8820x_tlb_inv_all(cpuid_t cpu)
@


1.48
log
@Rework secondary processor initialization. cmmu initialization is now
performed much earlier in the processor startup.
No visible change, paves the way for the much important diff three commits
from here.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.47 2011/01/05 22:16:16 miod Exp $	*/
d842 4
a845 1
	 * if necessary.
d851 14
@


1.47
log
@Make copypage() and zeropage() per-cpu function pointers, and use a
different version on 88110, which does load allocate of
to-be-completely-overwritten cache lines.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.46 2011/01/05 22:14:29 miod Exp $	*/
d399 1
a399 2
	apr = ((0x00000 << PG_BITS) | CACHE_WT | CACHE_GLOBAL | CACHE_INH) &
	    ~APR_V;
a481 1
	 * Data cache will be enabled later.
d485 12
@


1.46
log
@Now that pmap_copy_page() no longer needs to flush a couple contiguous tlb
entries, drop the count parameter to cmmu_tlb_inv(), and introduce
cmmu_tlb_inv_all() to drop all user tlb entries (to be used during context
switches).
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.45 2011/01/01 22:09:33 miod Exp $	*/
d87 3
d487 3
@


1.45
log
@Now that we __HAVE_PMAP_DIRECT, it gets easy to simply save partial cache
lines and restore them after invalidating rounded-to-cacheline-boundary ranges.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.44 2010/12/31 21:16:31 miod Exp $	*/
d92 2
a93 1
void	m8820x_tlb_inv(cpuid_t, u_int, vaddr_t, u_int);
d110 1
d544 1
a544 1
m8820x_tlb_inv(cpuid_t cpu, u_int kernel, vaddr_t vaddr, u_int count)
d551 5
d557 4
a560 26
	/*
	 * Since segment operations are horribly expensive, don't
	 * do any here. Invalidations of up to three pages are performed
	 * as page invalidations, otherwise the entire tlb is flushed.
	 *
	 * Note that this code relies upon vaddr being page-aligned.
	 */
	switch (count) {
	default:
		m8820x_cmmu_set_reg(CMMU_SCR,
		    kernel ? CMMU_FLUSH_SUPER_ALL : CMMU_FLUSH_USER_ALL,
		    0, cpu, 0);
		break;
	case 2:
		m8820x_cmmu_set_cmd(
		    kernel ? CMMU_FLUSH_SUPER_PAGE : CMMU_FLUSH_USER_PAGE,
		    ADDR_VAL, cpu, 0, vaddr);
		vaddr += PAGE_SIZE;
		/* FALLTHROUGH */
	case 1:			/* most frequent situation */
	case 0:
		m8820x_cmmu_set_cmd(
		    kernel ? CMMU_FLUSH_SUPER_PAGE : CMMU_FLUSH_USER_PAGE,
		    ADDR_VAL, cpu, 0, vaddr);
		break;
	}
d562 4
@


1.44
log
@Yet another rework of the cache flushing routines. Fixes some bugs, probably
introduces new ones as well. Main highlights are:
- 88200 lines which got marked as unusable by the BUG selftests will not be
  reenabled at CMMU initialization time.
- better granularity in the 88110/88410 routines, to operate on ranges closer
  to the actual requested area, errata permitting.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.43 2010/12/31 21:12:16 miod Exp $	*/
d3 1
a3 1
 * Copyright (c) 2004, 2007, 2010, Miodrag Vallat.
d767 3
a769 6
	struct {
		paddr_t pa;
		psize_t size;
		void (*flusher)(int, paddr_t, psize_t);
	} ops[3], *curop;
	uint nops;
d773 1
a773 2
	nops = 0;
	curop = ops;
d777 1
a777 35
		/*
		 * If the range does not span complete cache lines,
		 * force invalidation of the incomplete lines.  The
		 * rationale behind this is that these incomplete lines
		 * will probably need to be invalidated later, and
		 * we do not want to risk having stale data in the way.
		 */
		if (pa != _pa) {
			curop->pa = pa;
			curop->size = MC88200_CACHE_LINE;
			curop->flusher = m8820x_cmmu_wbinv_locked;
			curop++;
			pa += MC88200_CACHE_LINE;
			size -= MC88200_CACHE_LINE;
			if (size == 0)
				break;
		}
		if (pa + size == _pa + _size) {
			curop->pa = pa;
			curop->size = size;
			curop->flusher = m8820x_cmmu_wb_locked;
			curop++;
		} else {
			if (size != MC88200_CACHE_LINE) {
				curop->pa = pa;
				curop->size = size - MC88200_CACHE_LINE;
				curop->flusher = m8820x_cmmu_wb_locked;
				pa += curop->size;
				curop++;
			}
			curop->pa = pa;
			curop->size = MC88200_CACHE_LINE;
			curop->flusher = m8820x_cmmu_wbinv_locked;
			curop++;
		}
d780 1
a780 4
		curop->pa = pa;
		curop->size = size;
		curop->flusher = m8820x_cmmu_wbinv_locked;
		curop++;
d784 5
a788 45
#if 0
		/*
		 * Preserve the data from the incomplete cache lines (up to
		 * two), and discard the lines in-between (if any).
		 */
		if (pa != _pa) {
			curop->pa = pa;
			curop->size = MC88200_CACHE_LINE;
			curop->flusher = m8820x_cmmu_wbinv_locked;
			curop++;
			pa += MC88200_CACHE_LINE;
			size -= MC88200_CACHE_LINE;
			if (size == 0)
				break;
		}
		if (pa + size == _pa + _size) {
			curop->pa = pa;
			curop->size = size;
			curop->flusher = m8820x_cmmu_inv_locked;
			curop++;
		} else {
			if (size != MC88200_CACHE_LINE) {
				curop->pa = pa;
				curop->size = size - MC88200_CACHE_LINE;
				curop->flusher = m8820x_cmmu_inv_locked;
				pa += curop->size;
				curop++;
			}
			curop->pa = pa;
			curop->size = MC88200_CACHE_LINE;
			curop->flusher = m8820x_cmmu_wbinv_locked;
			curop++;
		}
#else
		/*
		 * Even if there are incomplete cache lines affected, assume
		 * they were evicted earlier.
		 * XXX We ought to save the partial cache lines, invalidate,
		 * XXX and put outside-the-range bytes back...
		 */
		curop->pa = pa;
		curop->size = size;
		curop->flusher = m8820x_cmmu_inv_locked;
		curop++;
#endif
a791 2
	nops = curop - ops;

d800 11
a810 6
	for (curop = ops; nops != 0; curop++, nops--) {
		pa = curop->pa;
		size = curop->size;
		flusher = curop->flusher;
		while (size != 0) {
			count = (pa & PAGE_MASK) == 0 && size >= PAGE_SIZE ?
d814 2
a815 2
			/* writeback on a single cpu... */
			(*flusher)(ci->ci_cpuid, pa, count);
d817 8
a824 10
			/* invalidate on all... */
			if (flusher != m8820x_cmmu_wb_locked) {
				for (cpu = 0; cpu < MAX_CPUS; cpu++) {
					if (!ISSET(m88k_cpus[cpu].ci_flags,
					    CIF_ALIVE))
						continue;
					if (cpu == ci->ci_cpuid)
						continue;
					m8820x_cmmu_inv_locked(cpu, pa, count);
				}
d826 1
d828 1
a828 1
			(*flusher)(cpu, pa, count);
d831 2
a832 3
			pa += count;
			size -= count;
		}
d834 9
@


1.43
log
@Introduce a new cmmu routine, for page writebacks without invalidate. Will be
used two commits from now.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.42 2010/12/31 20:54:21 miod Exp $	*/
d3 1
a3 1
 * Copyright (c) 2004, 2007, Miodrag Vallat.
d5 11
a15 20
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 *
 * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR
 * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
 * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 * DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT,
 * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
 * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,
 * STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN
 * ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
 * POSSIBILITY OF SUCH DAMAGE.
d120 2
a121 1
 * Systems with more than 2 CMMUs per CPU use programmable split schemes.
d137 2
a138 2
 * when it needs to get error information from up to 4 CMMUs. See eh.S on
 * mvme88k for the gory details, luna88k is more sane.
d149 3
a151 3
void	m8820x_cmmu_sync_cache(int, paddr_t, psize_t);
void	m8820x_cmmu_sync_inval_cache(int, paddr_t, psize_t);
void	m8820x_cmmu_inval_cache(int, paddr_t, psize_t);
d153 1
a153 1
/* Flags passed to m8820x_cmmu_set() */
d247 1
a247 3
		/* force the read access, but do not issue this statement... */
		__asm__ __volatile__ ("|or r0, r0, %0" ::
		    "r" (cmmu->cmmu_regs[CMMU_SSR]));
d391 1
a391 1
	int cssp, sctr, type;
d433 10
d444 3
d458 3
a460 3
		 * Snooping is enabled as soon as the system uses more than
		 * two CMMUs; for instruction CMMUs as well so that we can
		 * share breakpoints.
d462 1
a462 8
		sctr = 0;
		if (cmmu_shift > 1)
			sctr |= CMMU_SCTR_SE;
#ifdef MULTIPROCESSOR
		if (ncpusfound > 1)
			sctr |= CMMU_SCTR_SE;
#endif
		cmmu->cmmu_regs[CMMU_SCTR] = sctr;
d471 1
a471 2
		__asm__ __volatile__ ("|or r0, r0, %0" ::
		    "r" (cmmu->cmmu_regs[CMMU_SSR]));
a540 3
/*
 *	flush any tlb
 */
d584 1
a584 1
 * Cache invalidates require physical addresses. 
d586 2
a587 3
 * We don't push Instruction Caches prior to invalidate because they are not
 * snooped and never modified (I guess it doesn't matter then which form
 * of the command we use then).
d598 1
a598 1
 *	flush both Instruction and Data caches
d703 1
a703 1
 * sync dcache - icache is never dirty but needs to be invalidated as well.
d706 1
a706 1
m8820x_cmmu_sync_cache(int cpu, paddr_t pa, psize_t size)
d718 3
d722 1
a722 1
m8820x_cmmu_sync_inval_cache(int cpu, paddr_t pa, psize_t size)
a724 2
		m8820x_cmmu_set_cmd(CMMU_FLUSH_CACHE_INV_LINE,
		    MODE_VAL, cpu, INST_CMMU, pa);
d726 1
a726 1
		    MODE_VAL, cpu, DATA_CMMU, pa);
a727 2
		m8820x_cmmu_set_cmd(CMMU_FLUSH_CACHE_INV_PAGE,
		    MODE_VAL, cpu, INST_CMMU, pa);
d729 1
a729 1
		    MODE_VAL, cpu, DATA_CMMU, pa);
d734 3
d738 1
a738 1
m8820x_cmmu_inval_cache(int cpu, paddr_t pa, psize_t size)
d767 6
d776 2
d781 35
a815 1
		flusher = m8820x_cmmu_sync_cache;
d818 4
a821 1
		flusher = m8820x_cmmu_sync_inval_cache;
d824 33
a856 8
		if (pa != _pa || size != _size) {
			/*
			 * Theoretically, we should preserve the data from
			 * the two incomplete cache lines.
			 * However, callers are expected to have asked
			 * for a cache sync before, so we do not risk too
			 * much by not doing this.
			 */
d858 12
a869 1
		flusher = m8820x_cmmu_inval_cache;
d873 2
d883 6
a888 2
	while (size != 0) {
		count = (pa & PAGE_MASK) == 0 && size >= PAGE_SIZE ?
d892 2
a893 2
		/* writeback on a single cpu... */
		(*flusher)(ci->ci_cpuid, pa, count);
d895 10
a904 9
		/* invalidate on all... */
		if (flusher != m8820x_cmmu_sync_cache) {
			for (cpu = 0; cpu < MAX_CPUS; cpu++) {
				if (!ISSET(m88k_cpus[cpu].ci_flags,
				    CIF_ALIVE))
					continue;
				if (cpu == ci->ci_cpuid)
					continue;
				m8820x_cmmu_inval_cache(cpu, pa, count);
a905 1
		}
d907 1
a907 1
		(*flusher)(cpu, pa, count);
d910 3
a912 2
		pa += count;
		size -= count;
@


1.42
log
@Standardize cache handling functions and defines to use wb/wbinv/inv instead
of flush/sync/inval. No functional change.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.41 2010/12/27 19:18:37 miod Exp $	*/
d103 1
a108 1
/* This is the function table for the MC8820x CMMUs */
d119 1
d642 36
a677 1
 *	flush Instruction caches
@


1.41
log
@Do not issue a cache maintainance operation until the last one is not
completed; this used to be the case, but revision 1.25 of this file, close
to four years ago, changed this behaviour by mistake. The side effects of this
mishandling of the cache did not show up until the kernel memory allocation
strategy moved towards fast reuse of freed pages.
Took me a while to track this down, maybe I'm getting too old to write code,
I probably should write backdoors instead.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.40 2010/04/25 21:03:53 miod Exp $	*/
d101 3
a103 3
void	m8820x_flush_tlb(cpuid_t, u_int, vaddr_t, u_int);
void	m8820x_flush_cache(cpuid_t, paddr_t, psize_t);
void	m8820x_flush_inst_cache(cpuid_t, paddr_t, psize_t);
d117 3
a119 3
	m8820x_flush_tlb,
	m8820x_flush_cache,
	m8820x_flush_inst_cache,
d549 1
a549 1
m8820x_flush_tlb(cpuid_t cpu, u_int kernel, vaddr_t vaddr, u_int count)
d609 1
a609 1
m8820x_flush_cache(cpuid_t cpu, paddr_t pa, psize_t size)
d644 1
a644 1
m8820x_flush_inst_cache(cpuid_t cpu, paddr_t pa, psize_t size)
@


1.40
log
@Update various comments.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.39 2010/04/18 22:04:39 miod Exp $	*/
d622 5
a626 4
		count = (pa & PAGE_MASK) == 0 && size >= PAGE_SIZE ?
		    PAGE_SIZE : MC88200_CACHE_LINE;

		if (count <= MC88200_CACHE_LINE)
d629 2
a630 4
		else
			m8820x_cmmu_set_cmd(CMMU_FLUSH_CACHE_CBI_PAGE,
			    0, cpu, 0, pa);

d633 1
a634 1
	m8820x_cmmu_wait(cpu);
d657 5
a661 4
		count = (pa & PAGE_MASK) == 0 && size >= PAGE_SIZE ?
		    PAGE_SIZE : MC88200_CACHE_LINE;

		if (count <= MC88200_CACHE_LINE)
d664 2
a665 4
		else
			m8820x_cmmu_set_cmd(CMMU_FLUSH_CACHE_INV_PAGE,
			    MODE_VAL, cpu, INST_CMMU, pa);

d668 1
a669 1
	m8820x_cmmu_wait(cpu);
@


1.39
log
@Work in progress support for AViiON models 4600 and 530.
Also features support for {awkw,bast}ard 6:1 CMMU:CPU configurations (4I2D).
Tested on model 4605, which runs up to cpu_initclocks(), which is not written
for this system family yet. No regression on model 4300.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.38 2009/04/19 17:56:13 miod Exp $	*/
d454 3
a456 4
		 * Snooping is enabled on multiprocessor systems; for
		 * instruction CMMUs as well so that we can share breakpoints.
		 * XXX Investigate why enabling parity at this point
		 * doesn't work.
d459 2
d494 1
a494 1
	unsigned cmmu_num;
d549 1
a549 1
m8820x_flush_tlb(cpuid_t cpu, unsigned kernel, vaddr_t vaddr, u_int count)
d597 3
a599 2
 * XXX On systems with more than two CMMUs per CPU, we do not honor the
 * address split - this does not seem to work...
d627 1
a627 1
			    0 /* ADDR_VAL */, cpu, 0, pa);
d630 1
a630 1
			    0 /* ADDR_VAL */, cpu, 0, pa);
d663 1
a663 1
			    MODE_VAL /* | ADDR_VAL */, cpu, INST_CMMU, pa);
d666 1
a666 1
			    MODE_VAL /* | ADDR_VAL */, cpu, INST_CMMU, pa);
d685 1
a685 1
		    MODE_VAL /* | ADDR_VAL */, cpu, DATA_CMMU, pa);
d688 1
a688 1
		    MODE_VAL /* | ADDR_VAL */, cpu, DATA_CMMU, pa);
d698 1
a698 1
		    MODE_VAL /* | ADDR_VAL */, cpu, INST_CMMU, pa);
d700 1
a700 1
		    MODE_VAL /* | ADDR_VAL */, cpu, DATA_CMMU, pa);
d703 1
a703 1
		    MODE_VAL /* | ADDR_VAL */, cpu, INST_CMMU, pa);
d705 1
a705 1
		    MODE_VAL /* | ADDR_VAL */, cpu, DATA_CMMU, pa);
d714 1
a714 2
		m8820x_cmmu_set_cmd(CMMU_FLUSH_CACHE_INV_LINE,
		    0 /* ADDR_VAL */, cpu, 0, pa);
d716 1
a716 2
		m8820x_cmmu_set_cmd(CMMU_FLUSH_CACHE_INV_PAGE,
		    0 /* ADDR_VAL */, cpu, 0, pa);
d752 10
a761 4
		if (pa != _pa || size != _size)
			flusher = m8820x_cmmu_sync_inval_cache;
		else
			flusher = m8820x_cmmu_inval_cache;
@


1.38
log
@Rename max_cpus to ncpusfound and compute it regardless of option
MULTIPROCESSOR.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.37 2009/02/16 23:03:33 miod Exp $	*/
d182 4
d208 4
d245 4
d273 1
a273 1
	int mmu, cnt, cpu = cpu_number();
d290 9
a298 1
		printf(", %d CMMU", 1 << cmmu_shift);
d302 1
d304 6
a309 2
			int idr = cmmu->cmmu_regs[CMMU_IDR];
			int mmuid = CMMU_TYPE(idr);
d311 4
a314 1
			if (mmu % 2 == 0)
d351 3
d416 2
a417 2
		/* exception code does not use ci_pfsr_* fields */
		break;
d429 4
d500 4
d597 1
a597 1
 * address split - this does not work...
@


1.37
log
@More 88110 SMP work. Contains, horribly entangled:
- dma_cachectl() split into a ``local cpu only'' and ``all cpus'', and an ipi
  to broadcast ``local dma_cachectl'' is added.
- cpu_info fields are rearranged, to have the 88100-specific information
  and the 88110-specific information overlap, and has many more 88110
  ugly things.
- more ipi handling in the 197-specific area. Since it is not possible to
  have the second processor receive any hardware interrupt (selection
  is done on a level basis via ISEL, and we definitely do not want the
  main cpu to lose interrupts), the best we can do is to inflict ourselves
  a soft interrupt for late ipi processing. It gets used for softclock and
  hardclock on the secondary processor, but since the soft interrupt
  dispatcher doesn't have an exception frame, we have to remember parts
  of it to build a fake clockframe from the soft ipi handler (ugly but
  works).

This now lets GENERIC.MP run a few userland binaries before bugs trigger.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.36 2009/02/01 00:52:19 miod Exp $	*/
d426 1
a426 1
		if (max_cpus > 1)
@


1.36
log
@Remove dma_cachectl() and rename dma_cachectl_pa() to dma_cachectl() now that
the old vs(4) code is gone.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.35 2007/12/15 19:33:34 miod Exp $	*/
d105 1
d122 1
d758 8
@


1.35
log
@Move the cmmu lock back from 8820x-specific code to global, and use it on
MVME197DP to serialize 88410 operations.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.34 2007/12/05 22:09:55 miod Exp $	*/
d104 1
a104 2
void	m8820x_dma_cachectl(pmap_t, vaddr_t, vsize_t, int);
void	m8820x_dma_cachectl_pa(paddr_t, psize_t, int);
a119 1
	m8820x_dma_cachectl_pa,
d689 1
a689 77
m8820x_dma_cachectl(pmap_t pmap, vaddr_t _va, vsize_t _size, int op)
{
	u_int32_t psr;
	int cpu;
#ifdef MULTIPROCESSOR
	struct cpu_info *ci = curcpu();
#endif
	vaddr_t va;
	paddr_t pa;
	psize_t size, count;
	void (*flusher)(int, paddr_t, psize_t);

	va = trunc_cache_line(_va);
	size = round_cache_line(_va + _size) - va;

	switch (op) {
	case DMA_CACHE_SYNC:
		flusher = m8820x_cmmu_sync_cache;
		break;
	case DMA_CACHE_SYNC_INVAL:
		flusher = m8820x_cmmu_sync_inval_cache;
		break;
	default:
		if (va != _va || size != _size)
			flusher = m8820x_cmmu_sync_inval_cache;
		else
			flusher = m8820x_cmmu_inval_cache;
		break;
	}

#ifndef MULTIPROCESSOR
	cpu = cpu_number();
#endif

	psr = get_psr();
	set_psr(psr | PSR_IND);
	CMMU_LOCK;

	pa = 0;
	while (size != 0) {
		count = (va & PAGE_MASK) == 0 && size >= PAGE_SIZE ?
		    PAGE_SIZE : MC88200_CACHE_LINE;

		if ((va & PAGE_MASK) == 0 || pa == 0) {
			if (pmap_extract(pmap, va, &pa) == FALSE)
				panic("pmap_extract(%p, %p) failed", pmap, va);
		}

#ifdef MULTIPROCESSOR
		/* writeback on a single cpu... */
		(*flusher)(ci->ci_cpuid, pa, count);

		/* invalidate on all... */
		if (flusher != m8820x_cmmu_sync_cache) {
			for (cpu = 0; cpu < MAX_CPUS; cpu++) {
				if (!ISSET(m88k_cpus[cpu].ci_flags, CIF_ALIVE))
					continue;
				if (cpu == ci->ci_cpuid)
					continue;
				m8820x_cmmu_inval_cache(cpu, pa, count);
			}
		}
#else	/* MULTIPROCESSOR */
		(*flusher)(cpu, pa, count);
#endif	/* MULTIPROCESSOR */

		va += count;
		pa += count;
		size -= count;
	}

	CMMU_UNLOCK;
	set_psr(psr);
}

void
m8820x_dma_cachectl_pa(paddr_t _pa, psize_t _size, int op)
@


1.34
log
@In dma_cachectl(), when flushing line by line, only invoke pmap_extract()
once per page and cache the result.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.33 2007/11/24 11:12:55 miod Exp $	*/
a126 13
#ifdef MULTIPROCESSOR
/*
 * This lock protects the cmmu SAR and SCR's; other ports
 * can be accessed without locking it.
 */
__cpu_simple_lock_t cmmu_cpu_lock = __SIMPLELOCK_UNLOCKED;
#define CMMU_LOCK   __cpu_simple_lock(&cmmu_cpu_lock)
#define CMMU_UNLOCK __cpu_simple_unlock(&cmmu_cpu_lock)
#else
#define	CMMU_LOCK	do { /* nothing */ } while (0)
#define	CMMU_UNLOCK	do { /* nothing */ } while (0)
#endif	/* MULTIPROCESSOR */

d491 2
a492 1
	disable_interrupt(psr);
d513 2
a514 1
	disable_interrupt(psr);
d576 2
a577 1
	disable_interrupt(psr);
d612 2
a613 1
	disable_interrupt(psr);
d725 2
a726 1
	disable_interrupt(psr);
d800 2
a801 1
	disable_interrupt(psr);
@


1.33
log
@Slightly faster cache flushing operations on MP systems.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.32 2007/11/22 05:47:46 miod Exp $	*/
d737 1
d742 5
a746 1
		if (pmap_extract(pmap, va, &pa) != FALSE) {
d748 2
a749 2
			/* writeback on a single cpu... */
			(*flusher)(ci->ci_cpuid, pa, count);
d751 8
a758 10
			/* invalidate on all... */
			if (flusher != m8820x_cmmu_sync_cache) {
				for (cpu = 0; cpu < MAX_CPUS; cpu++) {
					if (!ISSET(m88k_cpus[cpu].ci_flags,
					    CIF_ALIVE))
						continue;
					if (cpu == ci->ci_cpuid)
						continue;
					m8820x_cmmu_inval_cache(cpu, pa, count);
				}
d760 1
d762 1
a762 1
			(*flusher)(cpu, pa, count);
a763 1
		}
d766 1
@


1.32
log
@Remove the cpu parameter from cmmu_set_sapr(), since it is only invoked
for the current processor. And remove now unused cmmu_flush_data_page().
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.31 2007/11/22 05:42:50 miod Exp $	*/
d3 1
a3 1
 * Copyright (c) 2004, Miodrag Vallat.
d744 1
a744 2
			if (flusher != m8820x_cmmu_inval_cache)
				(*flusher)(ci->ci_cpuid, pa, count);
d752 3
a754 1
					(*flusher)(cpu, pa, count);
d813 1
a813 2
		if (flusher != m8820x_cmmu_inval_cache)
			(*flusher)(ci->ci_cpuid, pa, count);
d821 3
a823 1
				(*flusher)(cpu, pa, count);
@


1.31
log
@Move the cmmu lock to 88200-specific code. 88110 MP code will use ipis
and will not require such a lock.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.30 2007/11/14 23:12:46 miod Exp $	*/
d99 1
a99 1
void	m8820x_set_sapr(cpuid_t, apr_t);
a103 1
void	m8820x_flush_data_page(cpuid_t, paddr_t);
a119 1
	m8820x_flush_data_page,
d487 1
a487 1
m8820x_set_sapr(cpuid_t cpu, apr_t ap)
d489 2
a540 6
	case 3:
		m8820x_cmmu_set_cmd(
		    kernel ? CMMU_FLUSH_SUPER_PAGE : CMMU_FLUSH_USER_PAGE,
		    ADDR_VAL, cpu, 0, vaddr);
		vaddr += PAGE_SIZE;
		/* FALLTHROUGH */
a638 16
	m8820x_cmmu_wait(cpu);

	CMMU_UNLOCK;
	set_psr(psr);
}

void
m8820x_flush_data_page(cpuid_t cpu, paddr_t pa)
{
	u_int32_t psr;

	disable_interrupt(psr);
	CMMU_LOCK;

	m8820x_cmmu_set_cmd(CMMU_FLUSH_CACHE_CBI_PAGE,
	    MODE_VAL /* | ADDR_VAL */, cpu, DATA_CMMU, pa);
@


1.30
log
@Merge the ci_alive and ci_primary boolean values of struct cpu_info into
a single ci_flags bitfield.

Also, set_cpu_number() will no longer set CIF_PRIMARY on the primary processor,
it's up to the initialization code to do this.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.29 2007/11/11 13:05:28 miod Exp $	*/
d128 13
@


1.29
log
@In dma_cachectl(), flush unconditionnaly on all processors, regardless of the
cpu bitmask of the pmap.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.28 2007/11/09 22:47:21 miod Exp $	*/
d759 2
a760 1
					if (m88k_cpus[cpu].ci_alive == 0)
d827 2
a828 1
				if (m88k_cpus[cpu].ci_alive == 0)
@


1.28
log
@In dma_cachectl*(), try and perform fewer remote processor operations whenever
possible.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.27 2007/10/29 19:58:57 miod Exp $	*/
a714 1
	u_int32_t cpumask;
d739 1
a739 3
#ifdef MULTIPROCESSOR
	cpumask = pmap->pm_cpus & ~(1 << ci->ci_cpuid);
#else
d758 2
a759 2
				for (cpu = 0; cpumask != 0; cpu++) {
					if (((1 << cpu) & cpumask) == 0)
a760 1
					cpumask ^= 1 << cpu;
@


1.27
log
@Make sure the dma_cachectl*() functions actually do their work on all
affected processors if option MULTIPROCESSOR. It's amazing bsd.mp could
boot multiuser without this.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.26 2007/05/20 20:12:32 miod Exp $	*/
d426 1
a426 2
		sctr = cmmu->cmmu_regs[CMMU_SCTR] &
		    ~(CMMU_SCTR_PE | CMMU_SCTR_SE | CMMU_SCTR_PR);
a466 2
		cmmu->cmmu_regs[CMMU_SCTR] &=
		    ~(CMMU_SCTR_PE | CMMU_SCTR_SE | CMMU_SCTR_PR);
d700 8
d714 1
d741 1
a741 1
	cpumask = pmap->pm_cpus;
d755 12
a766 9
			for (cpu = 0; cpumask != 0; cpu++) {
				if (((1 << cpu) & cpumask) == 0)
					continue;
				cpumask ^= 1 << cpu;
#ifdef DIAGNOSTIC
				if (m88k_cpus[cpu].ci_alive == 0)
					continue;
#endif
				(*flusher)(cpu, pa, count);
d786 3
d823 9
a831 3
		for (cpu = 0; cpu < MAX_CPUS; cpu++)
			if (m88k_cpus[cpu].ci_alive != 0)
#endif
d833 5
@


1.26
log
@Since we no longer use 3 bits but the whole 7 to get the processor revision
number, we should test for 10, not 2, as the revision for which the xxx.usr
errata applies; also, going through the errata, revision 2/10 (1010x) _is_
affected.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.25 2007/03/22 18:49:18 miod Exp $	*/
d707 4
a710 1
	int cpu = cpu_number();
d734 6
d747 13
a759 1
		if (pmap_extract(pmap, va, &pa) != FALSE)
d761 2
d776 1
a776 1
	int cpu = cpu_number();
d799 4
d810 5
a814 1
		(*flusher)(cpu, pa, count);
@


1.25
log
@In cmmu routines, replace splhigh() with disable_interrupts(), saves a function
pointer indirection for a similar result; also move the interrupt disabling
code to the public routines, so that we do not end altering the psr more
than necessary.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.24 2007/02/11 12:49:37 miod Exp $	*/
d339 1
a339 1
		if (proctype == ARN_88100 && procvers < 2) {
@


1.24
log
@Rework the cache handling routines again. We now try to operate on the exact
address range we've been given, rounded to cache line boundaries, instead
of being lazy and operating on pages as soon as the range was large enough.

Also, since the ranges we'll be invoked for are reasonably small, it does
not make sense to check for segment sizes - we're always smaller, really.

While there, hardcode the size in cmmu_flush_data_cache(), which becomes
cmmu_flush_data_page(), since it was always invoked for complete pages.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.23 2006/05/08 14:36:09 miod Exp $	*/
d158 3
a160 3
void	m8820x_cmmu_sync_cache(paddr_t, psize_t);
void	m8820x_cmmu_sync_inval_cache(paddr_t, psize_t);
void	m8820x_cmmu_inval_cache(paddr_t, psize_t);
d465 1
d474 1
d482 1
d484 1
d491 1
a491 1
	int s = splhigh();
d494 1
d496 1
d498 1
d500 1
a500 1
	splx(s);
d513 1
a513 1
	int s = splhigh();
d515 1
d552 1
a552 1
	splx(s);
d558 1
a558 5
 * Cache invalidates require physical addresses.  Care must be exercised when
 * using segment invalidates.  This implies that the starting physical address
 * plus the segment length should be invalidated.  A typical mistake is to
 * extract the first physical page of a segment from a virtual address, and
 * then expecting to invalidate when the pages are not physically contiguous.
d577 2
a578 2
	int s = splhigh();
	CMMU_LOCK;
d583 16
a598 12
	if (size > NBSG) {
		m8820x_cmmu_set_reg(CMMU_SCR, CMMU_FLUSH_CACHE_CBI_ALL, 0,
		    cpu, 0);
	} else if (size <= MC88200_CACHE_LINE) {
		m8820x_cmmu_set_cmd(CMMU_FLUSH_CACHE_CBI_LINE, 0 /* ADDR_VAL */,
		    cpu, 0, pa);
	} else if (size <= PAGE_SIZE) {
		m8820x_cmmu_set_cmd(CMMU_FLUSH_CACHE_CBI_PAGE, 0 /* ADDR_VAL */,
		    cpu, 0, pa);
	} else {
		m8820x_cmmu_set_cmd(CMMU_FLUSH_CACHE_CBI_SEGMENT, 0,
		    cpu, 0, pa);
a599 1

d603 1
a603 1
	splx(s);
d612 2
a613 2
	int s = splhigh();
	CMMU_LOCK;
d618 16
a633 12
	if (size > NBSG) {
		m8820x_cmmu_set_reg(CMMU_SCR, CMMU_FLUSH_CACHE_CBI_ALL,
		    MODE_VAL, cpu, INST_CMMU);
	} else if (size <= MC88200_CACHE_LINE) {
		m8820x_cmmu_set_cmd(CMMU_FLUSH_CACHE_CBI_LINE,
		    MODE_VAL /* | ADDR_VAL */, cpu, INST_CMMU, pa);
	} else if (size <= PAGE_SIZE) {
		m8820x_cmmu_set_cmd(CMMU_FLUSH_CACHE_CBI_PAGE,
		    MODE_VAL /* | ADDR_VAL */, cpu, INST_CMMU, pa);
	} else {
		m8820x_cmmu_set_cmd(CMMU_FLUSH_CACHE_CBI_SEGMENT,
		    MODE_VAL, cpu, INST_CMMU, pa);
a634 1

d638 1
a638 1
	splx(s);
d644 3
a646 1
	int s = splhigh();
d654 1
a654 1
	splx(s);
d661 1
a661 1
m8820x_cmmu_sync_cache(paddr_t pa, psize_t size)
a662 5
	int s = splhigh();
	int cpu = cpu_number();

	CMMU_LOCK;

a669 1

a670 3

	CMMU_UNLOCK;
	splx(s);
d674 1
a674 1
m8820x_cmmu_sync_inval_cache(paddr_t pa, psize_t size)
a675 5
	int s = splhigh();
	int cpu = cpu_number();

	CMMU_LOCK;

a686 1

a687 3

	CMMU_UNLOCK;
	splx(s);
d691 1
a691 1
m8820x_cmmu_inval_cache(paddr_t pa, psize_t size)
a692 5
	int s = splhigh();
	int cpu = cpu_number();

	CMMU_LOCK;

a699 1

a700 3

	CMMU_UNLOCK;
	splx(s);
d704 1
a704 1
m8820x_dma_cachectl(pmap_t pmap, vaddr_t va, vsize_t size, int op)
d706 3
d710 2
a711 2
	psize_t count;
	void (*flusher)(paddr_t, psize_t);
d713 2
a714 2
	size = round_cache_line(va + size) - trunc_cache_line(va);
	va = trunc_cache_line(va);
d724 4
a727 1
		flusher = m8820x_cmmu_inval_cache;
d731 3
d739 1
a739 1
			(*flusher)(pa, count);
d744 3
d750 1
a750 1
m8820x_dma_cachectl_pa(paddr_t pa, psize_t size, int op)
d752 5
a756 2
	psize_t count;
	void (*flusher)(paddr_t, psize_t);
d758 2
a759 2
	size = round_cache_line(pa + size) - trunc_cache_line(pa);
	pa = trunc_cache_line(pa);
d769 4
a772 1
		flusher = m8820x_cmmu_inval_cache;
d776 3
d783 1
a783 1
		(*flusher)(pa, count);
d788 3
@


1.23
log
@Replace gazillions of badvaddr() or badwordaddr() calls with badaddr() calls.
With a few prototype declarations shuffling, this finally allows
<machine/locore.h> to die.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.22 2006/04/17 16:08:01 miod Exp $	*/
d104 3
a106 3
void	m8820x_flush_data_cache(cpuid_t, paddr_t, psize_t);
int	m8820x_dma_cachectl(pmap_t, vaddr_t, vsize_t, int);
int	m8820x_dma_cachectl_pa(paddr_t, psize_t, int);
d121 1
a121 1
	m8820x_flush_data_cache,
d158 3
a160 3
int	m8820x_cmmu_sync_cache(paddr_t, psize_t);
int	m8820x_cmmu_sync_inval_cache(paddr_t, psize_t);
int	m8820x_cmmu_inval_cache(paddr_t, psize_t);
d564 3
d571 1
a571 1
m8820x_flush_cache(cpuid_t cpu, paddr_t physaddr, psize_t size)
d576 3
d584 1
a584 1
		    cpu, 0, physaddr);
d587 1
a587 1
		    cpu, 0, physaddr);
d590 1
a590 1
		    cpu, 0, physaddr);
d603 1
a603 1
m8820x_flush_inst_cache(cpuid_t cpu, paddr_t physaddr, psize_t size)
d608 3
d616 1
a616 1
		    MODE_VAL /* | ADDR_VAL */, cpu, INST_CMMU, physaddr);
d619 1
a619 1
		    MODE_VAL /* | ADDR_VAL */, cpu, INST_CMMU, physaddr);
d622 1
a622 1
		    MODE_VAL, cpu, INST_CMMU, physaddr);
d632 1
a632 1
m8820x_flush_data_cache(cpuid_t cpu, paddr_t physaddr, psize_t size)
d637 2
a638 14
	if (size > NBSG) {
		m8820x_cmmu_set_reg(CMMU_SCR, CMMU_FLUSH_CACHE_CBI_ALL,
		    MODE_VAL, cpu, DATA_CMMU);
	} else if (size <= MC88200_CACHE_LINE) {
		m8820x_cmmu_set_cmd(CMMU_FLUSH_CACHE_CBI_LINE,
		    MODE_VAL /* | ADDR_VAL */, cpu, DATA_CMMU, physaddr);
	} else if (size <= PAGE_SIZE) {
		m8820x_cmmu_set_cmd(CMMU_FLUSH_CACHE_CBI_PAGE,
		    MODE_VAL /* | ADDR_VAL */, cpu, DATA_CMMU, physaddr);
	} else {
		m8820x_cmmu_set_cmd(CMMU_FLUSH_CACHE_CBI_SEGMENT,
		    MODE_VAL, cpu, DATA_CMMU, physaddr);
	}

d648 2
a649 2
int
m8820x_cmmu_sync_cache(paddr_t physaddr, psize_t size)
a652 1
	int rc;
d656 1
a656 5
	if (size > NBSG) {
		m8820x_cmmu_set_reg(CMMU_SCR, CMMU_FLUSH_CACHE_CB_ALL,
		    MODE_VAL, cpu, DATA_CMMU);
		rc = 1;
	} else if (size <= MC88200_CACHE_LINE) {
d658 2
a659 3
		    MODE_VAL /* | ADDR_VAL */, cpu, DATA_CMMU, physaddr);
		rc = 0;
	} else if (size <= PAGE_SIZE) {
d661 1
a661 6
		    MODE_VAL /* | ADDR_VAL */, cpu, DATA_CMMU, physaddr);
		rc = 0;
	} else {
		m8820x_cmmu_set_cmd(CMMU_FLUSH_CACHE_CB_SEGMENT,
		    MODE_VAL, cpu, DATA_CMMU, physaddr);
		rc = 0;
a667 1
	return (rc);
d670 2
a671 2
int
m8820x_cmmu_sync_inval_cache(paddr_t physaddr, psize_t size)
a674 1
	int rc;
d678 1
a678 7
	if (size > NBSG) {
		m8820x_cmmu_set_reg(CMMU_SCR, CMMU_FLUSH_CACHE_INV_ALL,
		    MODE_VAL, cpu, INST_CMMU);
		m8820x_cmmu_set_reg(CMMU_SCR, CMMU_FLUSH_CACHE_CBI_ALL,
		    MODE_VAL, cpu, DATA_CMMU);
		rc = 1;
	} else if (size <= MC88200_CACHE_LINE) {
d680 1
a680 1
		    MODE_VAL /* | ADDR_VAL */, cpu, INST_CMMU, physaddr);
d682 2
a683 3
		    MODE_VAL /* | ADDR_VAL */, cpu, DATA_CMMU, physaddr);
		rc = 0;
	} else if (size <= PAGE_SIZE) {
d685 1
a685 1
		    MODE_VAL /* | ADDR_VAL */, cpu, INST_CMMU, physaddr);
d687 1
a687 8
		    MODE_VAL /* | ADDR_VAL */, cpu, DATA_CMMU, physaddr);
		rc = 0;
	} else {
		m8820x_cmmu_set_cmd(CMMU_FLUSH_CACHE_INV_SEGMENT,
		    MODE_VAL, cpu, INST_CMMU, physaddr);
		m8820x_cmmu_set_cmd(CMMU_FLUSH_CACHE_CBI_SEGMENT,
		    MODE_VAL, cpu, DATA_CMMU, physaddr);
		rc = 0;
a693 1
	return (rc);
d696 2
a697 2
int
m8820x_cmmu_inval_cache(paddr_t physaddr, psize_t size)
a700 1
	int rc;
d704 1
a704 5
	if (size > NBSG) {
		m8820x_cmmu_set_reg(CMMU_SCR, CMMU_FLUSH_CACHE_INV_ALL, 0,
		    cpu, 0);
		rc = 1;
	} else if (size <= MC88200_CACHE_LINE) {
d706 2
a707 3
		    0 /* ADDR_VAL */, cpu, 0, physaddr);
		rc = 0;
	} else if (size <= PAGE_SIZE) {
d709 1
a709 6
		    0 /* ADDR_VAL */, cpu, 0, physaddr);
		rc = 0;
	} else {
		m8820x_cmmu_set_cmd(CMMU_FLUSH_CACHE_INV_SEGMENT,
		    0, cpu, 0, physaddr);
		rc = 0;
a715 1
	return (rc);
d718 1
a718 1
int
d723 4
a726 1
	int rc = 0;
d728 11
a738 2
	size = round_page(va + size) - trunc_page(va);
	va = trunc_page(va);
d740 3
a742 2
	while (size != 0 && rc == 0) {
		count = min(size, PAGE_SIZE);
d744 2
a745 13
		if (pmap_extract(pmap, va, &pa) != FALSE) {
			switch (op) {
			case DMA_CACHE_SYNC:
				rc |= m8820x_cmmu_sync_cache(pa, count);
				break;
			case DMA_CACHE_SYNC_INVAL:
				rc |= m8820x_cmmu_sync_inval_cache(pa, count);
				break;
			default:
				rc |= m8820x_cmmu_inval_cache(pa, count);
				break;
			}
		}
a749 1
	return (rc);
d752 1
a752 1
int
d756 1
a756 1
	int rc = 0;
d758 2
a759 2
	size = round_page(pa + size) - trunc_page(pa);
	pa = trunc_page(pa);
d761 15
a775 2
	while (size != 0 && rc == 0) {
		count = min(size, PAGE_SIZE);
d777 1
a777 11
		switch (op) {
		case DMA_CACHE_SYNC:
			rc |= m8820x_cmmu_sync_cache(pa, count);
			break;
		case DMA_CACHE_SYNC_INVAL:
			rc |= m8820x_cmmu_sync_inval_cache(pa, count);
			break;
		default:
			rc |= m8820x_cmmu_inval_cache(pa, count);
			break;
		}
a781 1
	return (rc);
@


1.22
log
@Save pointers to up to four CMMU PFSR registers into the cpu_info structure.
This allows the exception handling code to skip the PFSR address computations.

The net result is that the PFSR_SAVE code becomes much simpler and smaller,
and that all processors will now spend time in PFSR_SAVE - previously, cpu0
was favored and other processors took a bit more time.

Note that 8:1 configurations do not use these fields - but then this is a
fixed monoprocessor configuration, for which the existing code was already
doing The Right Thing.

Tested on luna88k (2:1) by aoyama@@, and on mvme88k (2:1 and 4:1) by me.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.21 2006/04/15 15:44:06 miod Exp $	*/
a91 1
#include <machine/locore.h>
@


1.21
log
@Simplify MMU type printing.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.20 2006/04/09 12:11:11 miod Exp $	*/
d369 1
d379 21
@


1.20
log
@On MVME188 systems with more than two CMMUs par CPU, do not honor the
address split scheme when operating on caches, as this does not work
(probably for some snooping needs?); TLB operations are still honoring
the split and are not affected.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.19 2005/12/21 22:15:24 miod Exp $	*/
a251 11
const char *mmutypes[8] = {
	NULL,
	NULL,
	NULL,
	NULL,
	NULL,
	"M88200 (16K)",
	"M88204 (64K)",
	NULL
};

d294 11
a304 4
			if (mmutypes[mmuid] == NULL)
				printf("unknown model id 0x%x", mmuid);
			else
				printf("%s", mmutypes[mmuid]);
@


1.19
log
@No need to store description lines for unrecognized CMMUs...
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.18 2005/12/11 21:45:30 miod Exp $	*/
d156 2
a157 1
void	m8820x_cmmu_set(int, u_int, int, int, int, vaddr_t);
d168 1
a168 2
 * This function is called by the MMU module and pokes values
 * into the CMMU's registers.
d170 1
d172 23
a194 1
m8820x_cmmu_set(int reg, u_int val, int flags, int cpu, int mode, vaddr_t addr)
d212 2
a213 3
		if ((flags & ADDR_VAL) != 0) {
			if (cmmu->cmmu_addr_mask != 0 &&
			    (addr & cmmu->cmmu_addr_mask) != cmmu->cmmu_addr)
d217 2
a218 1
		cmmu->cmmu_regs[reg] = val;
d435 1
a435 1
	m8820x_cmmu_set(CMMU_SAPR, apr, MODE_VAL, cpu, INST_CMMU, 0);
d463 1
a463 1
	m8820x_cmmu_set(CMMU_SAPR, ap, 0, cpu, 0, 0);
d474 1
a474 1
	m8820x_cmmu_set(CMMU_UAPR, ap, 0, cpu, 0, 0);
d502 1
a502 1
		m8820x_cmmu_set(CMMU_SCR,
d504 1
a504 1
		    0, cpu, 0, 0);
d507 1
a507 2
		m8820x_cmmu_set(CMMU_SAR, vaddr, ADDR_VAL, cpu, 0, vaddr);
		m8820x_cmmu_set(CMMU_SCR,
d513 1
a513 2
		m8820x_cmmu_set(CMMU_SAR, vaddr, ADDR_VAL, cpu, 0, vaddr);
		m8820x_cmmu_set(CMMU_SCR,
d520 1
a520 2
		m8820x_cmmu_set(CMMU_SAR, vaddr, ADDR_VAL, cpu, 0, vaddr);
		m8820x_cmmu_set(CMMU_SCR,
d542 3
d557 2
a558 2
		m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_CBI_ALL, 0,
		    cpu, 0, 0);
d560 1
a560 3
		m8820x_cmmu_set(CMMU_SAR, physaddr, ADDR_VAL,
		    cpu, 0, physaddr);
		m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_CBI_LINE, ADDR_VAL,
d563 1
a563 1
		m8820x_cmmu_set(CMMU_SAR, physaddr, ADDR_VAL,
d565 2
a566 1
		m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_CBI_PAGE, ADDR_VAL,
a567 5
	} else {
		m8820x_cmmu_set(CMMU_SAR, physaddr, 0,
		    cpu, 0, 0);
		m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_CBI_SEGMENT, 0,
		    cpu, 0, 0);
d586 2
a587 2
		m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_CBI_ALL, MODE_VAL,
		    cpu, INST_CMMU, 0);
d589 2
a590 4
		m8820x_cmmu_set(CMMU_SAR, physaddr,
		    MODE_VAL | ADDR_VAL, cpu, INST_CMMU, physaddr);
		m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_CBI_LINE,
		    MODE_VAL | ADDR_VAL, cpu, INST_CMMU, physaddr);
d592 2
a593 4
		m8820x_cmmu_set(CMMU_SAR, physaddr,
		    MODE_VAL | ADDR_VAL, cpu, INST_CMMU, physaddr);
		m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_CBI_PAGE,
		    MODE_VAL | ADDR_VAL, cpu, INST_CMMU, physaddr);
d595 2
a596 4
		m8820x_cmmu_set(CMMU_SAR, physaddr,
		    MODE_VAL, cpu, INST_CMMU, 0);
		m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_CBI_SEGMENT,
		    MODE_VAL, cpu, INST_CMMU, 0);
d612 2
a613 2
		m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_CBI_ALL, MODE_VAL,
		    cpu, DATA_CMMU, 0);
d615 2
a616 4
		m8820x_cmmu_set(CMMU_SAR, physaddr,
		    MODE_VAL | ADDR_VAL, cpu, DATA_CMMU, physaddr);
		m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_CBI_LINE,
		    MODE_VAL | ADDR_VAL, cpu, DATA_CMMU, physaddr);
d618 2
a619 4
		m8820x_cmmu_set(CMMU_SAR, physaddr,
		    MODE_VAL | ADDR_VAL, cpu, DATA_CMMU, physaddr);
		m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_CBI_PAGE,
		    MODE_VAL | ADDR_VAL, cpu, DATA_CMMU, physaddr);
d621 2
a622 4
		m8820x_cmmu_set(CMMU_SAR, physaddr,
		    MODE_VAL, cpu, DATA_CMMU, 0);
		m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_CBI_SEGMENT,
		    MODE_VAL, cpu, DATA_CMMU, 0);
d644 2
a645 2
		m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_CB_ALL, MODE_VAL,
		    cpu, DATA_CMMU, 0);
d648 2
a649 4
		m8820x_cmmu_set(CMMU_SAR, physaddr,
		    MODE_VAL | ADDR_VAL, cpu, DATA_CMMU, physaddr);
		m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_CB_LINE,
		    MODE_VAL | ADDR_VAL, cpu, DATA_CMMU, physaddr);
d652 2
a653 4
		m8820x_cmmu_set(CMMU_SAR, physaddr,
		    MODE_VAL | ADDR_VAL, cpu, DATA_CMMU, physaddr);
		m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_CB_PAGE,
		    MODE_VAL | ADDR_VAL, cpu, DATA_CMMU, physaddr);
d656 2
a657 4
		m8820x_cmmu_set(CMMU_SAR, physaddr,
		    MODE_VAL | ADDR_VAL, cpu, DATA_CMMU, physaddr);
		m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_CB_SEGMENT,
		    MODE_VAL | ADDR_VAL, cpu, DATA_CMMU, physaddr);
d678 4
a681 4
		m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_INV_ALL, MODE_VAL,
		    cpu, INST_CMMU, 0);
		m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_CBI_ALL, MODE_VAL,
		    cpu, DATA_CMMU, 0);
d684 4
a687 6
		m8820x_cmmu_set(CMMU_SAR, physaddr,
		    ADDR_VAL, cpu, 0, physaddr);
		m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_INV_LINE,
		    MODE_VAL | ADDR_VAL, cpu, INST_CMMU, physaddr);
		m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_CBI_LINE,
		    MODE_VAL | ADDR_VAL, cpu, DATA_CMMU, physaddr);
d690 4
a693 6
		m8820x_cmmu_set(CMMU_SAR, physaddr,
		    ADDR_VAL, cpu, 0, physaddr);
		m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_INV_PAGE,
		    MODE_VAL | ADDR_VAL, cpu, INST_CMMU, physaddr);
		m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_CBI_PAGE,
		    MODE_VAL | ADDR_VAL, cpu, DATA_CMMU, physaddr);
d696 4
a699 6
		m8820x_cmmu_set(CMMU_SAR, physaddr,
		    ADDR_VAL, cpu, 0, physaddr);
		m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_INV_SEGMENT,
		    MODE_VAL | ADDR_VAL, cpu, INST_CMMU, physaddr);
		m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_CBI_SEGMENT,
		    MODE_VAL | ADDR_VAL, cpu, DATA_CMMU, physaddr);
d720 2
a721 2
		m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_INV_ALL, 0,
		    cpu, 0, 0);
d724 2
a725 4
		m8820x_cmmu_set(CMMU_SAR, physaddr,
		    ADDR_VAL, cpu, 0, physaddr);
		m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_INV_LINE,
		    ADDR_VAL, cpu, 0, physaddr);
d728 2
a729 4
		m8820x_cmmu_set(CMMU_SAR, physaddr,
		    ADDR_VAL, cpu, 0, physaddr);
		m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_INV_PAGE,
		    ADDR_VAL, cpu, 0, physaddr);
d732 2
a733 4
		m8820x_cmmu_set(CMMU_SAR, physaddr,
		    ADDR_VAL, cpu, 0, physaddr);
		m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_INV_SEGMENT,
		    ADDR_VAL, cpu, 0, physaddr);
@


1.18
log
@Work in progress SMP code; mvme88k boards can spin up secondary CPUs,
kernel boots single user. Still a lot of polishing and bugfixing to do.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.17 2005/12/10 22:31:38 miod Exp $	*/
d230 5
a234 5
	"Unknown (0)",
	"Unknown (1)",
	"Unknown (2)",
	"Unknown (3)",
	"Unknown (4)",
d237 1
a237 1
	"Unknown (7)"
d282 1
a282 1
			if (mmutypes[mmuid][0] == 'U')
@


1.17
log
@Only initialize the CMMUs tied to our running CPU on startup.
Tested on luna88k and mvme88k.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.16 2005/12/04 15:00:26 miod Exp $	*/
d124 4
a127 1
	m8820x_dma_cachectl_pa
a252 1
	static __cpu_simple_lock_t print_lock;
a256 5
	if (main)
		__cpu_simple_lock_init(&print_lock);

	__cpu_simple_lock(&print_lock);

d266 2
a267 2
		if (max_cpus > 1)
			printf(", %s", master ? "master" : "slave");
a328 2

	__cpu_simple_unlock(&print_lock);
d388 1
d391 1
@


1.16
log
@Let cmmu_init() now return the cpuid of the master cpu.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.15 2005/12/04 12:20:19 miod Exp $	*/
d97 12
a108 11
cpuid_t m8820x_init(void);
void m8820x_cpu_configuration_print(int);
void m8820x_shutdown(void);
void m8820x_set_sapr(cpuid_t, apr_t);
void m8820x_set_uapr(apr_t);
void m8820x_flush_tlb(cpuid_t, u_int, vaddr_t, u_int);
void m8820x_flush_cache(cpuid_t, paddr_t, psize_t);
void m8820x_flush_inst_cache(cpuid_t, paddr_t, psize_t);
void m8820x_flush_data_cache(cpuid_t, paddr_t, psize_t);
int m8820x_dma_cachectl(pmap_t, vaddr_t, vsize_t, int);
int m8820x_dma_cachectl_pa(paddr_t, psize_t, int);
d110 1
a110 1
/* This is the function table for the mc8820x CMMUs */
d239 2
a240 2
 * number and master/slave status . Should be called first
 * by the master, before the slaves are started.
d243 1
a243 1
m8820x_cpu_configuration_print(int master)
d255 1
a255 1
	if (master)
d342 13
d356 2
a357 2
	unsigned int line, cmmu_num;
	int cssp, type;
a358 1
	cpuid_t cpu;
d363 2
a364 2
	cmmu = m8820x_cmmu;
	for (cmmu_num = 0; cmmu_num < max_cmmus; cmmu_num++, cmmu++) {
d386 2
d391 1
a391 1
		cmmu->cmmu_regs[CMMU_SCTR] &=
d393 3
a410 19
	 * Enable snooping on multiprocessor systems.
	 * Snooping is enabled for instruction cmmus as well so that
	 * we can share breakpoints.
	 */
	if (max_cpus > 1) {
		for (cpu = 0; cpu < max_cpus; cpu++) {
			m8820x_cmmu_set(CMMU_SCTR, CMMU_SCTR_SE, MODE_VAL, cpu,
			    DATA_CMMU, 0);
			m8820x_cmmu_set(CMMU_SCTR, CMMU_SCTR_SE, MODE_VAL, cpu,
			    INST_CMMU, 0);

			m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_SUPER_ALL,
			    0, cpu, 0, 0);
			m8820x_cmmu_wait(cpu);
			/* Icache gets flushed just below */
		}
	}

	/*
d412 1
a412 3
	 * Data cache can not be enabled at this point, because some device
	 * addresses can never be cached, and the no-caching zones are not
	 * set up yet.
d415 1
a415 8
	for (cpu = 0; cpu < max_cpus; cpu++) {
		m8820x_cmmu_set(CMMU_SAPR, apr, MODE_VAL, cpu, INST_CMMU, 0);
		m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_SUPER_ALL,
		    0, cpu, 0, 0);
		m8820x_cmmu_wait(cpu);
	}

	return (m8820x_cpu_number());
@


1.15
log
@Slight cmmu code cleanup; use shorter function names, remove parity_enable
and the DDB and DEBUG helpers which are of questionable usefulness, some
stylistic changes.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.14 2005/12/03 19:06:11 miod Exp $	*/
d97 1
a97 1
void m8820x_init(void);
a107 3
void m8820x_dump_config(void);
void m8820x_show_translation(vaddr_t, u_int, u_int, int);
void m8820x_show_apr(apr_t);
d262 1
a262 1
		printf("unknown model arch 0x%x rev 0x%x\n",
d312 2
a313 1
			printf(" %ccache", CMMU_MODE(mmu) == INST_CMMU ? 'I' : 'D');
d338 1
a338 1
void
d424 2
@


1.14
log
@Replace simplelocks with __cpu_simple_locks for cmmu and pmap locking,
for the MULTIPROCESSOR case.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.13 2005/12/03 16:52:16 miod Exp $	*/
d91 1
d95 1
d97 1
a97 5
#ifdef DDB
#include <ddb/db_output.h>		/* db_printf()		*/
#endif

void m8820x_cmmu_init(void);
d99 7
a105 8
void m8820x_cmmu_shutdown_now(void);
void m8820x_cmmu_parity_enable(void);
void m8820x_cmmu_set_sapr(cpuid_t, apr_t);
void m8820x_cmmu_set_uapr(apr_t);
void m8820x_cmmu_flush_tlb(cpuid_t, unsigned, vaddr_t, u_int);
void m8820x_cmmu_flush_cache(cpuid_t, paddr_t, psize_t);
void m8820x_cmmu_flush_inst_cache(cpuid_t, paddr_t, psize_t);
void m8820x_cmmu_flush_data_cache(cpuid_t, paddr_t, psize_t);
d108 2
a109 2
void m8820x_cmmu_dump_config(void);
void m8820x_cmmu_show_translation(unsigned, unsigned, unsigned, int);
d114 1
a114 1
	m8820x_cmmu_init,
d117 8
a124 9
	m8820x_cmmu_shutdown_now,
	m8820x_cmmu_parity_enable,
	m8820x_cmmu_cpu_number,
	m8820x_cmmu_set_sapr,
	m8820x_cmmu_set_uapr,
	m8820x_cmmu_flush_tlb,
	m8820x_cmmu_flush_cache,
	m8820x_cmmu_flush_inst_cache,
	m8820x_cmmu_flush_data_cache,
d126 1
a126 13
	m8820x_dma_cachectl_pa,
#ifdef DDB
	m8820x_cmmu_dump_config,
	m8820x_cmmu_show_translation,
#else
	NULL,
	NULL,
#endif
#ifdef DEBUG
	m8820x_show_apr,
#else
	NULL,
#endif
d155 5
a159 5
void m8820x_cmmu_set(int, unsigned, int, int, int, vaddr_t);
void m8820x_cmmu_wait(int);
int m8820x_cmmu_sync_cache(paddr_t, psize_t);
int m8820x_cmmu_sync_inval_cache(paddr_t, psize_t);
int m8820x_cmmu_inval_cache(paddr_t, psize_t);
d170 1
a170 2
m8820x_cmmu_set(int reg, unsigned val, int flags, int cpu, int mode,
    vaddr_t addr)
d263 2
a264 1
	if (proctype != ARN_88100) {
d267 14
a280 3
		__cpu_simple_unlock(&print_lock);
		return;
	}
d282 4
a285 6
	printf("M88100 rev 0x%x", procvers);
#if 0	/* not useful yet */
	if (max_cpus > 1)
		printf(", %s", master ? "master" : "slave");
#endif
	printf(", %d CMMU", 1 << cmmu_shift);
d287 5
a291 16
	mmu = cpu << cmmu_shift;
	cmmu = m8820x_cmmu + mmu;
	for (cnt = 1 << cmmu_shift; cnt != 0; cnt--, mmu++, cmmu++) {
		int idr = cmmu->cmmu_regs[CMMU_IDR];
		int mmuid = CMMU_TYPE(idr);

		if (mmu % 2 == 0)
			printf("\ncpu%d: ", cpu);
		else
			printf(", ");

		if (mmutypes[mmuid][0] == 'U')
			printf("unknown model id 0x%x", mmuid);
		else
			printf("%s", mmutypes[mmuid]);
		printf(" rev 0x%x,", CMMU_VERSION(idr));
d293 20
a312 17
		/*
		 * Print address lines
		 */
		amask = cmmu->cmmu_addr_mask;
		if (amask != 0) {
			aline = 0;
			while (amask != 0) {
				abit = ff1(amask);
				if ((cmmu->cmmu_addr & (1 << abit)) != 0)
					printf("%cA%02d",
					    aline != 0 ? '/' : ' ', abit);
				else
					printf("%cA%02d*",
					    aline != 0 ? '/' : ' ', abit);
				amask ^= 1 << abit;
			}
		} else
d314 4
a317 2
			printf(" full");
		printf(" %ccache", CMMU_MODE(mmu) == INST_CMMU ? 'I' : 'D');
d341 1
a341 1
m8820x_cmmu_init()
d345 6
a350 2
	int cssp, cpu, type;
	u_int32_t apr;
d374 3
a376 1
		 * Set the SCTR, SAPR, and UAPR to some known state
d380 2
a381 3
		cmmu->cmmu_regs[CMMU_SAPR] = cmmu->cmmu_regs[CMMU_UAPR] =
		    ((0x00000 << PG_BITS) | CACHE_WT | CACHE_GLOBAL |
		    CACHE_INH) & ~APR_V;
d419 1
a420 3
		apr = ((0x00000 << PG_BITS) | CACHE_WT | CACHE_GLOBAL)
		    & ~(CACHE_INH | APR_V);

d432 1
a432 1
m8820x_cmmu_shutdown_now()
a448 16
/*
 * enable parity
 */
void
m8820x_cmmu_parity_enable()
{
	unsigned cmmu_num;
	struct m8820x_cmmu *cmmu;

	cmmu = m8820x_cmmu;
	CMMU_LOCK;
	for (cmmu_num = 0; cmmu_num < max_cmmus; cmmu_num++, cmmu++)
		cmmu->cmmu_regs[CMMU_SCTR] |= CMMU_SCTR_PE;
	CMMU_UNLOCK;
}

d450 1
a450 1
m8820x_cmmu_set_sapr(cpuid_t cpu, apr_t ap)
d458 1
a458 1
m8820x_cmmu_set_uapr(apr_t ap)
d477 1
a477 1
m8820x_cmmu_flush_tlb(cpuid_t cpu, unsigned kernel, vaddr_t vaddr, u_int count)
d541 1
a541 1
m8820x_cmmu_flush_cache(cpuid_t cpu, paddr_t physaddr, psize_t size)
d576 1
a576 1
m8820x_cmmu_flush_inst_cache(cpuid_t cpu, paddr_t physaddr, psize_t size)
d608 1
a608 1
m8820x_cmmu_flush_data_cache(cpuid_t cpu, paddr_t physaddr, psize_t size)
a831 297

#ifdef DDB
void
m8820x_cmmu_dump_config()
{
	struct m8820x_cmmu *cmmu;
	int cmmu_num;

	db_printf("Current CPU/CMMU configuration:\n");
	cmmu = m8820x_cmmu;
	for (cmmu_num = 0; cmmu_num < max_cmmus; cmmu_num++, cmmu++) {
#ifdef M88200_HAS_SPLIT_ADDRESS
		db_printf("CMMU #%d: %s CMMU for CPU %d, addr 0x%08lx mask 0x%08lx\n",
		    cmmu_num,
		    CMMU_MODE(cmmu_num) == INST_CMMU ? "inst" : "data",
		    cmmu_num >> cmmu_shift,
		    cmmu->cmmu_addr, cmmu->cmmu_addr_mask);
#else
		db_printf("CMMU #%d: %s CMMU for CPU %d",
		    cmmu_num,
		    CMMU_MODE(cmmu_num) == INST_CMMU ? "inst" : "data",
		    cmmu_num >> cmmu_shift);
#endif
	}
}

/*
 * Show (for debugging) how the current CPU translates the given ADDRESS
 * (as DATA).
 */
void
m8820x_cmmu_show_translation(unsigned address, unsigned supervisor_flag,
    unsigned verbose_flag, int unused __attribute__ ((unused)))
{
	struct m8820x_cmmu *cmmu;
	int cpu = cpu_number();
	vaddr_t va = address;
	int cmmu_num, cnt;
	u_int32_t value;

	/*
	 * Find the correct data CMMU.
	 */
	cmmu_num = cpu << cmmu_shift;
	cmmu = m8820x_cmmu + cmmu_num;
	for (cnt = 1 << cmmu_shift; cnt != 0; cnt--, cmmu_num++, cmmu++) {
		if (CMMU_MODE(cmmu_num) == INST_CMMU)
			continue;
#ifdef M88200_HAS_SPLIT_ADDRESS
		if (cmmu->cmmu_addr_mask == 0 ||
		    (va & cmmu->cmmu_addr_mask) ==
		     cmmu->cmmu_addr)
#endif
			break;
	}
	if (cnt == 0) {
		db_printf("No matching cmmu for VA %08x\n", address);
		return;
	}

	if (verbose_flag != 0)
		db_printf("VA %08x is managed by CMMU#%d.\n",
		    address, cmmu_num);

	/*
	 * Perform some sanity checks.
	 */
	if (verbose_flag == 0) {
		if ((cmmu->cmmu_regs[CMMU_SCTR] &
		    CMMU_SCTR_SE) == 0)
			db_printf("WARNING: snooping not enabled for CMMU#%d.\n",
			    cmmu_num);
	} else {
		int i;

		cmmu = m8820x_cmmu;
		for (i = 0; i < max_cmmus; i++, cmmu++)
			if (verbose_flag > 1 ||
			    (cmmu->cmmu_regs[CMMU_SCTR] & CMMU_SCTR_SE) == 0) {
				db_printf("CMMU#%d (cpu %d %s) snooping %s\n",
				    i, i >> cmmu_shift,
				    CMMU_MODE(i) == INST_CMMU ? "inst" : "data",
				    (cmmu->cmmu_regs[CMMU_SCTR] &
				     CMMU_SCTR_SE) ? "on" : "OFF");
			}
		cmmu = m8820x_cmmu + cmmu_num;
	}

	/*
	 * Ask for a CMMU probe and report its result.
	 */
	{
		u_int32_t ssr;

		cmmu->cmmu_regs[CMMU_SAR] = address;
		cmmu->cmmu_regs[CMMU_SCR] =
		    supervisor_flag ? CMMU_PROBE_SUPER : CMMU_PROBE_USER;
		ssr = cmmu->cmmu_regs[CMMU_SSR];

		switch (verbose_flag) {
		case 2:
			db_printf("probe of 0x%08x returns ssr=0x%08x\n",
			    address, ssr);
			/* FALLTHROUGH */
		case 1:
			if (ssr & CMMU_SSR_V)
				db_printf("PROBE of 0x%08x returns phys=0x%x",
				    address, cmmu->cmmu_regs[CMMU_SAR]);
			else
				db_printf("PROBE fault at 0x%x",
				    cmmu->cmmu_regs[CMMU_PFAR]);
			if (ssr & CMMU_SSR_CE)
				db_printf(", copyback err");
			if (ssr & CMMU_SSR_BE)
				db_printf(", bus err");
			if (ssr & CACHE_WT)
				db_printf(", writethrough");
			if (ssr & CMMU_SSR_SO)
				db_printf(", sup prot");
			if (ssr & CACHE_GLOBAL)
				db_printf(", global");
			if (ssr & CACHE_INH)
				db_printf(", cache inhibit");
			if (ssr & CMMU_SSR_M)
				db_printf(", modified");
			if (ssr & CMMU_SSR_U)
				db_printf(", used");
			if (ssr & CMMU_SSR_PROT)
				db_printf(", write prot");
			if (ssr & CMMU_SSR_BH)
				db_printf(", BATC");
			db_printf(".\n");
			break;
		}
	}

	/*
	 * Interpret area descriptor.
	 */

	if (supervisor_flag)
		value = cmmu->cmmu_regs[CMMU_SAPR];
	else
		value = cmmu->cmmu_regs[CMMU_UAPR];

	switch (verbose_flag) {
	case 2:
		db_printf("CMMU#%d", cmmu_num);
		db_printf(" %cAPR is 0x%08x\n",
		    supervisor_flag ? 'S' : 'U', value);
		/* FALLTHROUGH */
	case 1:
		db_printf("CMMU#%d", cmmu_num);
		db_printf(" %cAPR: SegTbl: 0x%x000p",
		    supervisor_flag ? 'S' : 'U', PG_PFNUM(value));
		if (value & CACHE_WT)
			db_printf(", WTHRU");
		if (value & CACHE_GLOBAL)
			db_printf(", GLOBAL");
		if (value & CACHE_INH)
			db_printf(", INHIBIT");
		if (value & APR_V)
			db_printf(", VALID");
		db_printf("\n");
		break;
	}

	if ((value & APR_V) == 0) {
		db_printf("VA 0x%08x -> apr 0x%08x not valid\n", va, value);
		return;
	}

	value &= PG_FRAME;	/* now point to seg page */

	/*
	 * Walk segment and page tables to find our page.
	 */
	{
		sdt_entry_t sdt;

		if (verbose_flag)
			db_printf("will follow to entry %d of page at 0x%x...\n",
			    SDTIDX(va), value);
		value |= SDTIDX(va) * sizeof(sdt_entry_t);

		if (badwordaddr((vaddr_t)value)) {
			db_printf("VA 0x%08x -> segment table @@0x%08x not accessible\n",
			    va, value);
			return;
		}

		sdt = *(sdt_entry_t *)value;
		switch (verbose_flag) {
		case 2:
			db_printf("SEG DESC @@0x%x is 0x%08x\n", value, sdt);
			/* FALLTHROUGH */
		case 1:
			db_printf("SEG DESC @@0x%x: PgTbl: 0x%x000",
			    value, PG_PFNUM(sdt));
			if (sdt & CACHE_WT)
				db_printf(", WTHRU");
			if (sdt & SG_SO)
				db_printf(", S-PROT");
			if (sdt & CACHE_GLOBAL)
				db_printf(", GLOBAL");
			if (sdt & CACHE_INH)
				db_printf(", $INHIBIT");
			if (sdt & SG_PROT)
				db_printf(", W-PROT");
			if (sdt & SG_V)
				db_printf(", VALID");
			db_printf(".\n");
			break;
		}

		if ((sdt & SG_V) == 0) {
			db_printf("VA 0x%08x -> segment entry 0x%8x @@0x%08x not valid\n",
			    va, sdt, value);
			return;
		}

		value = ptoa(PG_PFNUM(sdt));
	}

	{
		pt_entry_t pte;

		if (verbose_flag)
			db_printf("will follow to entry %d of page at 0x%x...\n",
			    PDTIDX(va), value);
		value |= PDTIDX(va) * sizeof(pt_entry_t);

		if (badwordaddr((vaddr_t)value)) {
			db_printf("VA 0x%08x -> page table entry @@0x%08x not accessible\n",
			    va, value);
			return;
		}

		pte = *(pt_entry_t *)value;
		switch (verbose_flag) {
		case 2:
			db_printf("PAGE DESC @@0x%x is 0x%08x.\n", value, pte);
			/* FALLTHROUGH */
		case 1:
			db_printf("PAGE DESC @@0x%x: page @@%x000",
			    value, PG_PFNUM(pte));
			if (pte & PG_W)
				db_printf(", WIRE");
			if (pte & CACHE_WT)
				db_printf(", WTHRU");
			if (pte & PG_SO)
				db_printf(", S-PROT");
			if (pte & CACHE_GLOBAL)
				db_printf(", GLOBAL");
			if (pte & CACHE_INH)
				db_printf(", $INHIBIT");
			if (pte & PG_M)
				db_printf(", MOD");
			if (pte & PG_U)
				db_printf(", USED");
			if (pte & PG_PROT)
				db_printf(", W-PROT");
			if (pte & PG_V)
				db_printf(", VALID");
			db_printf(".\n");
			break;
		}

		if ((pte & PG_V) == 0) {
			db_printf("VA 0x%08x -> page table entry 0x%08x @@0x%08x not valid\n",
			    va, pte, value);
			return;
		}

		value = ptoa(PG_PFNUM(pte)) | (va & PAGE_MASK);
	}

	db_printf("VA 0x%08x -> PA 0x%08x\n", va, value);
}
#endif /* DDB */

#ifdef DEBUG
void
m8820x_show_apr(apr_t value)
{
	printf("table @@ 0x%x000", PG_PFNUM(value));
	if (value & CACHE_WT)
		printf(", writethrough");
	if (value & CACHE_GLOBAL)
		printf(", global");
	if (value & CACHE_INH)
		printf(", cache inhibit");
	if (value & APR_V)
		printf(", valid");
	printf("\n");
}
#endif
@


1.13
log
@Turn read_processor_identification_register() into a simple macro with a
much, much, much shorter name. It is only used to print cpu revision anyway...
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.12 2005/12/02 21:16:45 miod Exp $	*/
a85 1
#include <sys/simplelock.h>
d92 1
d269 1
a269 1
	struct simplelock print_lock;
d275 1
a275 1
		simple_lock_init(&print_lock);
d277 1
a277 1
	simple_lock(&print_lock);
d283 1
a283 1
		simple_unlock(&print_lock);
d347 1
a347 1
	simple_unlock(&print_lock);
@


1.12
log
@Better choice of types for struct pmap members and cmmu functions;
no functional change.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.11 2005/11/25 22:20:45 miod Exp $	*/
d265 1
a265 1
	int pid = read_processor_identification_register();
@


1.11
log
@Get rid of BROKEN_MMU_MASK, unnecessary now that bus_dmamap_sync() behaves
correctly.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.10 2005/11/25 22:17:14 miod Exp $	*/
d103 6
a108 6
void m8820x_cmmu_set_sapr(unsigned, unsigned);
void m8820x_cmmu_set_uapr(unsigned);
void m8820x_cmmu_flush_tlb(unsigned, unsigned, vaddr_t, u_int);
void m8820x_cmmu_flush_cache(int, paddr_t, psize_t);
void m8820x_cmmu_flush_inst_cache(int, paddr_t, psize_t);
void m8820x_cmmu_flush_data_cache(int, paddr_t, psize_t);
d113 1
a113 1
void m8820x_show_apr(unsigned);
d476 1
a476 1
m8820x_cmmu_set_sapr(unsigned cpu, unsigned ap)
d484 1
a484 1
m8820x_cmmu_set_uapr(unsigned ap)
d503 1
a503 1
m8820x_cmmu_flush_tlb(unsigned cpu, unsigned kernel, vaddr_t vaddr, u_int count)
d567 1
a567 1
m8820x_cmmu_flush_cache(int cpu, paddr_t physaddr, psize_t size)
d602 1
a602 1
m8820x_cmmu_flush_inst_cache(int cpu, paddr_t physaddr, psize_t size)
d634 1
a634 1
m8820x_cmmu_flush_data_cache(int cpu, paddr_t physaddr, psize_t size)
d1141 1
a1141 1
m8820x_show_apr(unsigned value)
@


1.10
log
@Let the cache synchronization and invalidation functions report whether
they caused the entire cache to be processed.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.9 2005/10/13 19:48:33 miod Exp $	*/
a98 8
/*
 * On some versions of the 88200, page size flushes don't work. I am using
 * sledge hammer approach till I find for sure which ones are bad XXX nivas
 *
 * Looks like 88204 are affected as well... So better keep this -- miod
 */
#define BROKEN_MMU_MASK

a571 1
#if !defined(BROKEN_MMU_MASK)
a590 3
#else
	m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_CBI_ALL, 0, cpu, 0, 0);
#endif /* !BROKEN_MMU_MASK */
a606 1
#if !defined(BROKEN_MMU_MASK)
a625 4
#else
	m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_CBI_ALL, MODE_VAL,
	    cpu, INST_CMMU, 0);
#endif /* !BROKEN_MMU_MASK */
a638 1
#if !defined(BROKEN_MMU_MASK)
a657 4
#else
	m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_CBI_ALL, MODE_VAL,
	    cpu, DATA_CMMU, 0);
#endif /* !BROKEN_MMU_MASK */
a676 1
#if !defined(BROKEN_MMU_MASK)
a699 5
#else
	m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_CB_ALL, MODE_VAL,
	    cpu, DATA_CMMU, 0);
	rc = 1;
#endif /* !BROKEN_MMU_MASK */
a716 1
#if !defined(BROKEN_MMU_MASK)
a747 7
#else
	m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_INV_ALL, MODE_VAL,
	    cpu, INST_CMMU, 0);
	m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_CBI_ALL, MODE_VAL,
	    cpu, DATA_CMMU, 0);
	rc = 1;
#endif /* !BROKEN_MMU_MASK */
a764 1
#if !defined(BROKEN_MMU_MASK)
a787 5
#else
	m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_INV_ALL, 0,
	    cpu, 0, 0);
	rc = 1;
#endif /* !BROKEN_MMU_MASK */
a799 1
#if !defined(BROKEN_MMU_MASK)
a801 1
#endif
a805 1
#if !defined(BROKEN_MMU_MASK)
a826 21
#else
	/*
	 * This assumes the space is also physically contiguous... but this
	 * really doesn't matter as we flush/sync/invalidate the whole cache
	 * anyway...
	 */
	if (pmap_extract(pmap, va, &pa) != FALSE) {
		switch (op) {
		case DMA_CACHE_SYNC:
			m8820x_cmmu_sync_cache(pa, size);
			break;
		case DMA_CACHE_SYNC_INVAL:
			m8820x_cmmu_sync_inval_cache(pa, size);
			break;
		default:
			m8820x_cmmu_inval_cache(pa, size);
			break;
		}
	}
	return (1);
#endif /* !BROKEN_MMU_MASK */
a831 1
#if !defined(BROKEN_MMU_MASK)
a833 1
#endif
a837 1
#if !defined(BROKEN_MMU_MASK)
a856 14
#else
	switch (op) {
	case DMA_CACHE_SYNC:
		m8820x_cmmu_sync_cache(pa, size);
		break;
	case DMA_CACHE_SYNC_INVAL:
		m8820x_cmmu_sync_inval_cache(pa, size);
		break;
	default:
		m8820x_cmmu_inval_cache(pa, size);
		break;
	}
	return (1);
#endif /* !BROKEN_MMU_MASK */
@


1.9
log
@Merge <machine/cpu_number.h> into <machine/cpu.h>, preparing for intrusive
changes.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.8 2005/09/25 22:41:14 miod Exp $	*/
d117 2
a118 2
void m8820x_dma_cachectl(pmap_t, vaddr_t, vsize_t, int);
void m8820x_dma_cachectl_pa(paddr_t, psize_t, int);
d181 3
a183 3
void m8820x_cmmu_sync_cache(paddr_t, psize_t);
void m8820x_cmmu_sync_inval_cache(paddr_t, psize_t);
void m8820x_cmmu_inval_cache(paddr_t, psize_t);
d690 1
a690 1
void
d695 1
d703 1
d709 1
d715 1
d721 1
d726 1
d733 1
d736 1
a736 1
void
d741 1
d751 1
d759 1
d767 1
d775 1
d782 1
d789 1
d792 1
a792 1
void
d797 1
d805 1
d811 1
d817 1
d823 1
d828 1
d835 1
d838 1
a838 1
void
d844 1
d851 1
a851 1
	while (size != 0) {
d857 1
a857 1
				m8820x_cmmu_sync_cache(pa, count);
d860 1
a860 1
				m8820x_cmmu_sync_inval_cache(pa, count);
d863 1
a863 1
				m8820x_cmmu_inval_cache(pa, count);
d871 1
d891 1
d895 1
a895 1
void
d900 1
d907 1
a907 1
	while (size != 0) {
d912 1
a912 1
			m8820x_cmmu_sync_cache(pa, count);
d915 1
a915 1
			m8820x_cmmu_sync_inval_cache(pa, count);
d918 1
a918 1
			m8820x_cmmu_inval_cache(pa, count);
d925 1
d938 1
@


1.8
log
@Define symbolic constants for the processor identification register fields
and use them. No functional change.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.7 2005/09/25 20:55:14 miod Exp $	*/
a91 1
#include <machine/cpu_number.h>
@


1.7
log
@Change the size parameter of cmmu_flush_tlb() from bytes to pages. This makes
things easier for the callers, and allows us to inline the "fewer than 4 pages"
situation for speed.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.6 2005/07/01 14:09:26 miod Exp $	*/
d275 2
a276 2
	int proctype = (pid & 0xff00) >> 8;
	int procvers = (pid & 0xe) >> 1;
d289 1
a289 1
	if (proctype != 0) {
d347 1
a347 1
		if (proctype == 0 && procvers < 2) {
@


1.6
log
@Fix logic botch in !ERRATA__XXX_USR kernels.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.5 2005/04/27 14:09:45 miod Exp $	*/
d114 1
a114 1
void m8820x_cmmu_flush_tlb(unsigned, unsigned, vaddr_t, vsize_t);
d164 1
a164 1
 * A14 address bit.
d512 1
a512 2
m8820x_cmmu_flush_tlb(unsigned cpu, unsigned kernel, vaddr_t vaddr,
    vsize_t size)
d523 1
a523 2
	 * Note that this code relies upon size being a multiple of
	 * a page and vaddr being page-aligned.
d525 8
a532 3
	if (size == PAGE_SIZE) {	/* most frequent situation */
		m8820x_cmmu_set(CMMU_SAR, vaddr,
		    ADDR_VAL, cpu, 0, vaddr);
d536 4
a539 1
	} else if (size > 3 * PAGE_SIZE) {
d541 1
a541 5
		    kernel ? CMMU_FLUSH_SUPER_ALL : CMMU_FLUSH_USER_ALL,
		    0, cpu, 0, 0);
	} else
	while (size != 0) {
		m8820x_cmmu_set(CMMU_SAR, vaddr,
d543 5
d551 1
a551 3

		size -= PAGE_SIZE;
		vaddr += PAGE_SIZE;
@


1.5
log
@Allow userland to cause the data cache to be flushed for any arbitrary address
range in the current process, using trap #451.

This is necessary for proper gcc trampolines operation, and, later, ld.so...
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.4 2005/04/27 14:07:38 miod Exp $	*/
d347 1
a347 1
		if (proctype != 0 && procvers < 2) {
@


1.4
log
@Always include <uvm/uvm_extern.h> before <machine/cmmu.h>.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.3 2004/08/08 21:19:18 miod Exp $	*/
d118 1
a118 1
void m8820x_dma_cachectl(vaddr_t, vsize_t, int);
d814 1
a814 1
m8820x_dma_cachectl(vaddr_t va, vsize_t size, int op)
d828 1
a828 1
		if (pmap_extract(pmap_kernel(), va, &pa) != FALSE) {
d846 6
a851 2
	/* XXX This assumes the space is also physically contiguous */
	if (pmap_extract(pmap_kernel(), va, &pa) != FALSE) {
@


1.3
log
@Since the I-cache can never be dirty, ignore copyback operations, and only
perform invalidations when appropriate.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.2 2004/08/08 21:14:04 miod Exp $	*/
d88 2
d91 1
a93 2

#include <machine/cmmu.h>
a94 2

#include <uvm/uvm_extern.h>
@


1.2
log
@Print address lines split scheme if necessary.
@
text
@d1 1
a1 1
/*	$OpenBSD: m8820x_machdep.c,v 1.1 2004/08/06 13:23:49 miod Exp $	*/
d104 2
d582 2
a583 2
		m8820x_cmmu_set(CMMU_SAR, (unsigned)physaddr, ADDR_VAL,
		    cpu, 0, (unsigned)physaddr);
d585 4
a588 4
		    cpu, 0, (unsigned)physaddr);
	} else if (size <= NBPG) {
		m8820x_cmmu_set(CMMU_SAR, (unsigned)physaddr, ADDR_VAL,
		    cpu, 0, (unsigned)physaddr);
d590 1
a590 1
		    cpu, 0, (unsigned)physaddr);
d592 1
a592 1
		m8820x_cmmu_set(CMMU_SAR, (unsigned)physaddr, 0,
d621 2
a622 2
		m8820x_cmmu_set(CMMU_SAR, (unsigned)physaddr,
		    MODE_VAL | ADDR_VAL, cpu, INST_CMMU, (unsigned)physaddr);
d624 4
a627 4
		    MODE_VAL | ADDR_VAL, cpu, INST_CMMU, (unsigned)physaddr);
	} else if (size <= NBPG) {
		m8820x_cmmu_set(CMMU_SAR, (unsigned)physaddr,
		    MODE_VAL | ADDR_VAL, cpu, INST_CMMU, (unsigned)physaddr);
d629 1
a629 1
		    MODE_VAL | ADDR_VAL, cpu, INST_CMMU, (unsigned)physaddr);
d631 1
a631 1
		m8820x_cmmu_set(CMMU_SAR, (unsigned)physaddr,
d658 2
a659 2
		m8820x_cmmu_set(CMMU_SAR, (unsigned)physaddr,
		    MODE_VAL | ADDR_VAL, cpu, DATA_CMMU, (unsigned)physaddr);
d661 4
a664 4
		    MODE_VAL | ADDR_VAL, cpu, DATA_CMMU, (unsigned)physaddr);
	} else if (size <= NBPG) {
		m8820x_cmmu_set(CMMU_SAR, (unsigned)physaddr,
		    MODE_VAL | ADDR_VAL, cpu, DATA_CMMU, (unsigned)physaddr);
d666 1
a666 1
		    MODE_VAL | ADDR_VAL, cpu, DATA_CMMU, (unsigned)physaddr);
d668 1
a668 1
		m8820x_cmmu_set(CMMU_SAR, (unsigned)physaddr,
d685 1
a685 1
 * sync dcache (and icache too)
a698 2
		m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_CB_ALL, MODE_VAL,
		    cpu, INST_CMMU, 0);
d700 2
a701 6
		m8820x_cmmu_set(CMMU_SAR, (unsigned)physaddr,
		    MODE_VAL | ADDR_VAL, cpu, INST_CMMU, (unsigned)physaddr);
		m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_CB_LINE,
		    MODE_VAL, cpu, INST_CMMU, 0);
		m8820x_cmmu_set(CMMU_SAR, (unsigned)physaddr,
		    MODE_VAL | ADDR_VAL, cpu, DATA_CMMU, (unsigned)physaddr);
d703 4
a706 8
		    MODE_VAL, cpu, DATA_CMMU, 0);
	} else if (size <= NBPG) {
		m8820x_cmmu_set(CMMU_SAR, (unsigned)physaddr,
		    MODE_VAL | ADDR_VAL, cpu, INST_CMMU, (unsigned)physaddr);
		m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_CB_PAGE,
		    MODE_VAL, cpu, INST_CMMU, 0);
		m8820x_cmmu_set(CMMU_SAR, (unsigned)physaddr,
		    MODE_VAL | ADDR_VAL, cpu, DATA_CMMU, (unsigned)physaddr);
d708 1
a708 1
		    MODE_VAL, cpu, DATA_CMMU, 0);
d710 2
a711 6
		m8820x_cmmu_set(CMMU_SAR, (unsigned)physaddr,
		    MODE_VAL | ADDR_VAL, cpu, INST_CMMU, (unsigned)physaddr);
		m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_CB_SEGMENT,
		    MODE_VAL, cpu, INST_CMMU, 0);
		m8820x_cmmu_set(CMMU_SAR, (unsigned)physaddr,
		    MODE_VAL | ADDR_VAL, cpu, DATA_CMMU, (unsigned)physaddr);
d713 1
a713 1
		    MODE_VAL, cpu, DATA_CMMU, 0);
a717 2
	m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_CB_ALL, MODE_VAL,
	    cpu, INST_CMMU, 0);
d736 2
a739 2
		m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_CBI_ALL, MODE_VAL,
		    cpu, INST_CMMU, 0);
d741 4
a744 2
		m8820x_cmmu_set(CMMU_SAR, (unsigned)physaddr,
		    MODE_VAL | ADDR_VAL, cpu, INST_CMMU, (unsigned)physaddr);
d746 6
a751 8
		    MODE_VAL, cpu, INST_CMMU, 0);
		m8820x_cmmu_set(CMMU_SAR, (unsigned)physaddr,
		    MODE_VAL | ADDR_VAL, cpu, DATA_CMMU, (unsigned)physaddr);
		m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_CBI_LINE,
		    MODE_VAL, cpu, DATA_CMMU, 0);
	} else if (size <= NBPG) {
		m8820x_cmmu_set(CMMU_SAR, (unsigned)physaddr,
		    MODE_VAL | ADDR_VAL, cpu, INST_CMMU, (unsigned)physaddr);
d753 1
a753 5
		    MODE_VAL, cpu, INST_CMMU, 0);
		m8820x_cmmu_set(CMMU_SAR, (unsigned)physaddr,
		    MODE_VAL | ADDR_VAL, cpu, DATA_CMMU, (unsigned)physaddr);
		m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_CBI_PAGE,
		    MODE_VAL, cpu, DATA_CMMU, 0);
d755 4
a758 2
		m8820x_cmmu_set(CMMU_SAR, (unsigned)physaddr,
		    MODE_VAL | ADDR_VAL, cpu, INST_CMMU, (unsigned)physaddr);
d760 1
a760 5
		    MODE_VAL, cpu, INST_CMMU, 0);
		m8820x_cmmu_set(CMMU_SAR, (unsigned)physaddr,
		    MODE_VAL | ADDR_VAL, cpu, DATA_CMMU, (unsigned)physaddr);
		m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_CBI_SEGMENT,
		    MODE_VAL, cpu, DATA_CMMU, 0);
d763 2
a766 2
	m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_CBI_ALL, MODE_VAL,
	    cpu, INST_CMMU, 0);
d785 2
a786 4
		m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_INV_ALL, MODE_VAL,
		    cpu, DATA_CMMU, 0);
		m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_INV_ALL, MODE_VAL,
		    cpu, INST_CMMU, 0);
d788 2
a789 6
		m8820x_cmmu_set(CMMU_SAR, (unsigned)physaddr,
		    MODE_VAL | ADDR_VAL, cpu, INST_CMMU, (unsigned)physaddr);
		m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_INV_LINE,
		    MODE_VAL, cpu, INST_CMMU, 0);
		m8820x_cmmu_set(CMMU_SAR, (unsigned)physaddr,
		    MODE_VAL | ADDR_VAL, cpu, DATA_CMMU, (unsigned)physaddr);
d791 4
a794 4
		    MODE_VAL, cpu, DATA_CMMU, 0);
	} else if (size <= NBPG) {
		m8820x_cmmu_set(CMMU_SAR, (unsigned)physaddr,
		    MODE_VAL | ADDR_VAL, cpu, INST_CMMU, (unsigned)physaddr);
d796 1
a796 5
		    MODE_VAL, cpu, INST_CMMU, 0);
		m8820x_cmmu_set(CMMU_SAR, (unsigned)physaddr,
		    MODE_VAL | ADDR_VAL, cpu, DATA_CMMU, (unsigned)physaddr);
		m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_INV_PAGE,
		    MODE_VAL, cpu, DATA_CMMU, 0);
d798 2
a799 2
		m8820x_cmmu_set(CMMU_SAR, (unsigned)physaddr,
		    MODE_VAL | ADDR_VAL, cpu, INST_CMMU, (unsigned)physaddr);
d801 1
a801 5
		    MODE_VAL, cpu, INST_CMMU, 0);
		m8820x_cmmu_set(CMMU_SAR, (unsigned)physaddr,
		    MODE_VAL | ADDR_VAL, cpu, DATA_CMMU, (unsigned)physaddr);
		m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_INV_SEGMENT,
		    MODE_VAL, cpu, DATA_CMMU, 0);
d804 2
a805 4
	m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_INV_ALL, MODE_VAL,
	    cpu, DATA_CMMU, 0);
	m8820x_cmmu_set(CMMU_SCR, CMMU_FLUSH_CACHE_INV_ALL, MODE_VAL,
	    cpu, INST_CMMU, 0);
d820 1
d822 4
d827 1
a827 4
		count = NBPG - (va & PGOFSET);

		if (size < count)
			count = size;
d869 1
d871 4
d876 1
a876 4
		count = NBPG - (va & PGOFSET);

		if (size < count)
			count = size;
@


1.1
log
@Merge Luna88k and mvme88k M88200 management code. Features:
- simpler structures (no more redundant or easily computable information).
- split scheme configuration (for 4:1 and 8:1 designs) is only compiled in
  if necessary (read: only on a mvme88k kernel configured for MVME188 support),
  which speeds up CMMU operations on the Luna88k.
- will not enable bus snopping on a monoprocessor system.

Tested on Luna88k-2, MVME187 and various MVME188 by aoyama@@ and I.
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d278 3
d317 22
a338 3
		/* XXX print address lines */
		printf(" rev 0x%x, %ccache",
		    CMMU_VERSION(idr), CMMU_MODE(mmu) == INST_CMMU ? 'I' : 'D');
a416 5
#ifdef DIAGNOSTIC
			if (cpu_sets[cpu] == 0)
				continue;
#endif

a435 5
#ifdef DIAGNOSTIC
		if (cpu_sets[cpu] == 0)
			continue;
#endif

@

