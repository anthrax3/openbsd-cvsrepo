head	1.15;
access;
symbols
	OPENBSD_6_2_BASE:1.15
	OPENBSD_6_1:1.13.0.14
	OPENBSD_6_1_BASE:1.13
	OPENBSD_6_0:1.13.0.10
	OPENBSD_6_0_BASE:1.13
	OPENBSD_5_9:1.13.0.6
	OPENBSD_5_9_BASE:1.13
	OPENBSD_5_8:1.13.0.8
	OPENBSD_5_8_BASE:1.13
	OPENBSD_5_7:1.13.0.2
	OPENBSD_5_7_BASE:1.13
	OPENBSD_5_6:1.13.0.4
	OPENBSD_5_6_BASE:1.13
	OPENBSD_5_5:1.9.0.4
	OPENBSD_5_5_BASE:1.9
	OPENBSD_5_4:1.7.0.10
	OPENBSD_5_4_BASE:1.7
	OPENBSD_5_3:1.7.0.8
	OPENBSD_5_3_BASE:1.7
	OPENBSD_5_2:1.7.0.6
	OPENBSD_5_2_BASE:1.7
	OPENBSD_5_1_BASE:1.7
	OPENBSD_5_1:1.7.0.4
	OPENBSD_5_0:1.7.0.2
	OPENBSD_5_0_BASE:1.7
	OPENBSD_4_9:1.6.0.4
	OPENBSD_4_9_BASE:1.6
	OPENBSD_4_8:1.6.0.2
	OPENBSD_4_8_BASE:1.6
	OPENBSD_4_7:1.5.0.8
	OPENBSD_4_7_BASE:1.5
	OPENBSD_4_6:1.5.0.10
	OPENBSD_4_6_BASE:1.5
	OPENBSD_4_5:1.5.0.6
	OPENBSD_4_5_BASE:1.5
	OPENBSD_4_4:1.5.0.4
	OPENBSD_4_4_BASE:1.5
	OPENBSD_4_3:1.5.0.2
	OPENBSD_4_3_BASE:1.5
	OPENBSD_4_2:1.3.0.2
	OPENBSD_4_2_BASE:1.3
	OPENBSD_4_1:1.2.0.2
	OPENBSD_4_1_BASE:1.2;
locks; strict;
comment	@ * @;


1.15
date	2017.07.04.09.00.12;	author mpi;	state Exp;
branches;
next	1.14;
commitid	K7b7irKcwIwnZRSy;

1.14
date	2017.05.25.03.19.39;	author dlg;	state Exp;
branches;
next	1.13;
commitid	gx8rjMxrMcqYnydg;

1.13
date	2014.07.18.12.44.53;	author dlg;	state Exp;
branches;
next	1.12;
commitid	qXA1lsFTcHP46l96;

1.12
date	2014.07.18.10.40.14;	author dlg;	state Exp;
branches;
next	1.11;
commitid	GoJdpESN6XUgaZcc;

1.11
date	2014.03.29.18.09.30;	author guenther;	state Exp;
branches;
next	1.10;

1.10
date	2014.03.15.06.18.00;	author dlg;	state Exp;
branches;
next	1.9;

1.9
date	2014.01.30.12.27.10;	author kettenis;	state Exp;
branches;
next	1.8;

1.8
date	2014.01.30.00.51.13;	author dlg;	state Exp;
branches;
next	1.7;

1.7
date	2011.03.23.16.54.37;	author pirofti;	state Exp;
branches;
next	1.6;

1.6
date	2010.07.07.15.36.18;	author kettenis;	state Exp;
branches;
next	1.5;

1.5
date	2007.11.28.12.31.49;	author kettenis;	state Exp;
branches;
next	1.4;

1.4
date	2007.11.27.23.29.57;	author kettenis;	state Exp;
branches;
next	1.3;

1.3
date	2007.03.13.08.34.03;	author art;	state Exp;
branches;
next	1.2;

1.2
date	2007.02.19.17.18.43;	author deraadt;	state Exp;
branches;
next	1.1;

1.1
date	2007.02.06.17.13.33;	author art;	state Exp;
branches;
next	;


desc
@@


1.15
log
@Export our atomic definitions to userland instead of gcc builtins.

ok kettenis@@, dlg@@
@
text
@/*	$OpenBSD: atomic.h,v 1.14 2017/05/25 03:19:39 dlg Exp $	*/
/*
 * Copyright (c) 2007 Artur Grabowski <art@@openbsd.org>
 *
 * Permission to use, copy, modify, and distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 */

#ifndef _MACHINE_ATOMIC_H_
#define _MACHINE_ATOMIC_H_

static inline unsigned int
_atomic_cas_uint(volatile unsigned int *p, unsigned int e, unsigned int n)
{
	__asm volatile("cas [%2], %3, %0"
	    : "+r" (n), "=m" (*p)
	    : "r" (p), "r" (e), "m" (*p));

	return (n);
}
#define atomic_cas_uint(_p, _e, _n) _atomic_cas_uint((_p), (_e), (_n))

static inline unsigned long
_atomic_cas_ulong(volatile unsigned long *p, unsigned long e, unsigned long n)
{
	__asm volatile("casx [%2], %3, %0"
	    : "+r" (n), "=m" (*p)
	    : "r" (p), "r" (e), "m" (*p));

	return (n);
}
#define atomic_cas_ulong(_p, _e, _n) _atomic_cas_ulong((_p), (_e), (_n))

static inline void *
_atomic_cas_ptr(volatile void *p, void *e, void *n)
{
	__asm volatile("casx [%2], %3, %0"
	    : "+r" (n), "=m" (*(volatile unsigned long *)p)
	    : "r" (p), "r" (e), "m" (*(volatile unsigned long *)p));

	return (n);
}
#define atomic_cas_ptr(_p, _e, _n) _atomic_cas_ptr((_p), (_e), (_n))

#define _def_atomic_swap(_f, _t, _c)					\
static inline _t							\
_f(volatile _t *p, _t v)						\
{									\
	_t e;								\
	_t r;								\
									\
	r = (_t)*p;							\
	do {								\
		e = r;							\
		r = _c(p, e, v);					\
	} while (r != e);						\
									\
	return (r);							\
}

_def_atomic_swap(_atomic_swap_uint, unsigned int, atomic_cas_uint)
_def_atomic_swap(_atomic_swap_ulong, unsigned long, atomic_cas_ulong)
#undef _def_atomic_swap

static inline void *
_atomic_swap_ptr(volatile void *p, void *v)
{
	void *e, *r;

	r = *(void **)p;
	do {
		e = r;
		r = atomic_cas_ptr(p, e, v);
	} while (r != e);

	return (r);
}

#define atomic_swap_uint(_p, _v)  _atomic_swap_uint(_p, _v)
#define atomic_swap_ulong(_p, _v)  _atomic_swap_ulong(_p, _v)
#define atomic_swap_ptr(_p, _v)  _atomic_swap_ptr(_p, _v)

#define _def_atomic_op_nv(_f, _t, _c, _op)				\
static inline _t							\
_f(volatile _t *p, _t v)						\
{									\
	_t e, r, f;							\
									\
	r = *p;								\
	do {								\
		e = r;							\
		f = e _op v;						\
		r = _c(p, e, f);					\
	} while (r != e);						\
									\
	return (f);							\
}

_def_atomic_op_nv(_atomic_add_int_nv, unsigned int, atomic_cas_uint, +)
_def_atomic_op_nv(_atomic_add_long_nv, unsigned long, atomic_cas_ulong, +)
_def_atomic_op_nv(_atomic_sub_int_nv, unsigned int, atomic_cas_uint, -)
_def_atomic_op_nv(_atomic_sub_long_nv, unsigned long, atomic_cas_ulong, -)
#undef _def_atomic_op_nv

#define atomic_add_int_nv(_p, _v)  _atomic_add_int_nv(_p, _v)
#define atomic_add_long_nv(_p, _v)  _atomic_add_long_nv(_p, _v)
#define atomic_sub_int_nv(_p, _v)  _atomic_sub_int_nv(_p, _v)
#define atomic_sub_long_nv(_p, _v)  _atomic_sub_long_nv(_p, _v)

#define __membar(_m)		__asm volatile("membar " _m ::: "memory")

#define membar_enter()		__membar("#StoreLoad|#StoreStore")
#define membar_exit()		__membar("#LoadStore|#StoreStore")
#define membar_producer()	__membar("#StoreStore")
#define membar_consumer()	__membar("#LoadLoad")
#define membar_sync()		__membar("#Sync")

#if defined(_KERNEL)

static __inline void
atomic_setbits_int(volatile unsigned int *uip, unsigned int v)
{
	unsigned int e, r;

	r = *uip;
	do {
		e = r;
		r = atomic_cas_uint(uip, e, e | v);
	} while (r != e);
}

static __inline void
atomic_clearbits_int(volatile unsigned int *uip, unsigned int v)
{
	unsigned int e, r;

	r = *uip;
	do {
		e = r;
		r = atomic_cas_uint(uip, e, e & ~v);
	} while (r != e);
}

#endif /* defined(_KERNEL) */
#endif /* _MACHINE_ATOMIC_H_ */
@


1.14
log
@tweak sparc64 membars as a step toward making them usable in userland.

specifically, dont rely on magic in ctlreg to implement membars. moving
that to atomic.h would add a lot of pollution to the namespace, so
move to passing the membar options to a single __membar macro.

this tweaks everything that was using the ctlreg backend to either use
an appropriate membar_foo(), or to use __membar() in the MD code.

ok kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: atomic.h,v 1.13 2014/07/18 12:44:53 dlg Exp $	*/
a20 2
#if defined(_KERNEL)

d54 1
a54 1
#define def_atomic_swap(_f, _t, _c)					\
d70 3
a72 3
def_atomic_swap(_atomic_swap_uint, unsigned int, atomic_cas_uint)
def_atomic_swap(_atomic_swap_ulong, unsigned long, atomic_cas_ulong)
#undef def_atomic_swap
d92 1
a92 1
#define def_atomic_op_nv(_f, _t, _c, _op)				\
d108 5
a112 5
def_atomic_op_nv(_atomic_add_int_nv, unsigned int, atomic_cas_uint, +)
def_atomic_op_nv(_atomic_add_long_nv, unsigned long, atomic_cas_ulong, +)
def_atomic_op_nv(_atomic_sub_int_nv, unsigned int, atomic_cas_uint, -)
def_atomic_op_nv(_atomic_sub_long_nv, unsigned long, atomic_cas_ulong, -)
#undef def_atomic_op_nv
d119 10
a151 8

#define __membar(_m)		__asm volatile("membar " _m ::: "memory")

#define membar_enter()		__membar("#StoreLoad|#StoreStore")
#define membar_exit()		__membar("#LoadStore|#StoreStore")
#define membar_producer()	__membar("#StoreStore")
#define membar_consumer()	__membar("#LoadLoad")
#define membar_sync()		__membar("#Sync")
@


1.13
log
@atomic_swap_ptr is special.

for jmatthew@@
@
text
@d1 1
a1 1
/*	$OpenBSD: atomic.h,v 1.12 2014/07/18 10:40:14 dlg Exp $	*/
d145 7
a151 5
#define membar_enter()		membar(StoreLoad|StoreStore)
#define membar_exit()		membar(LoadStore|StoreStore)
#define membar_producer()	membar(StoreStore)
#define membar_consumer()	membar(LoadLoad)
#define membar_sync()		membar(Sync)
@


1.12
log
@pass atomic_{cas,swap}_uint a volatile void * instead of a volatile
void **. the latter is really hard to cast for, and not what what
solaris does.

ok kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: atomic.h,v 1.11 2014/03/29 18:09:30 guenther Exp $	*/
a73 1
def_atomic_swap(_atomic_swap_ptr, void *, atomic_cas_ptr)
d75 14
@


1.11
log
@It's been a quarter century: we can assume volatile is present with that name.

ok dlg@@ mpi@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: atomic.h,v 1.10 2014/03/15 06:18:00 dlg Exp $	*/
d46 1
a46 1
_atomic_cas_ptr(volatile void **p, void *e, void *n)
d49 2
a50 2
	    : "+r" (n), "=m" (*p)
	    : "r" (p), "r" (e), "m" (*p));
@


1.10
log
@make the membars look more correct for any memory ordering mode.

ok kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: atomic.h,v 1.9 2014/01/30 12:27:10 kettenis Exp $	*/
d26 1
a26 1
	__asm __volatile("cas [%2], %3, %0"
d37 1
a37 1
	__asm __volatile("casx [%2], %3, %0"
d48 1
a48 1
	__asm __volatile("casx [%2], %3, %0"
@


1.9
log
@Undef def_atomic_op_nv instead of def_atomic_opf.
@
text
@d1 1
a1 1
/*	$OpenBSD: atomic.h,v 1.8 2014/01/30 00:51:13 dlg Exp $	*/
d132 3
a134 7
#if KERN_MM != PSTATE_MM_TSO
#error membar operations only support KERN_MM = PSTATE_MM_TSO
#endif

#define membar_enter()		membar(LoadLoad)
#define membar_exit()		membar(LoadLoad)
#define membar_producer()	membar(0)
d136 1
a136 1
#define membar_sync()		membar(LoadLoad)
@


1.8
log
@move sparc64 behind the MI atomic api.

this basically replaces sparc64_cas and sparc64_casx with atomic_cas_uint
and atomic_cas_ulong respectively. it then builds atomic_add and
atomic_sub out of those. this avoids the gcc atomic builtins that
the MI atomic_foo api uses by default, so we dont get the extra
membars that the builtins do but the atomic_foo api doesnt promise.

it also fixes up the code that used to use sparc64_{cas,casx} to
use the atomic_cas api instead.

use of the sparc64 membar() macros are left untouched for now.

ok kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: atomic.h,v 1.7 2011/03/23 16:54:37 pirofti Exp $	*/
d101 1
a101 1
#undef def_atomic_opf
@


1.7
log
@Normalize sentinel. Use _MACHINE_*_H_ and _<ARCH>_*_H_ properly and consitently.

Discussed and okay drahn@@. Okay deraadt@@.
@
text
@d1 1
a1 1
/*	$OpenBSD: atomic.h,v 1.6 2010/07/07 15:36:18 kettenis Exp $	*/
d23 2
a24 2
static __inline unsigned int
sparc64_cas(volatile unsigned int *uip, unsigned int expect, unsigned int new)
d27 2
a28 2
	    : "+r" (new), "=m" (*uip)
	    : "r" (uip), "r" (expect), "m" (*uip));
d30 1
a30 1
	return (new);
d32 1
d34 2
a35 3
static __inline unsigned long
sparc64_casx(volatile unsigned long *uip, unsigned long expect,
    unsigned long new)
d38 2
a39 2
	    : "+r" (new), "=m" (*uip)
	    : "r" (uip), "r" (expect), "m" (*uip));
d41 1
a41 1
	return (new);
d43 64
d111 1
a111 1
	volatile unsigned int e, r;
d116 1
a116 1
		r = sparc64_cas(uip, e, e | v);
d123 1
a123 1
	volatile unsigned int e, r;
d128 1
a128 1
		r = sparc64_cas(uip, e, e & ~v);
d132 9
a140 11
static __inline void
atomic_add_ulong(volatile unsigned long *ulp, unsigned long v)
{
	volatile unsigned long e, r;

	r = *ulp;
	do {
		e = r;
		r = sparc64_casx(ulp, e, e + v);
	} while (r != e);
}
@


1.6
log
@Implement atomic_add_ulong.

ok art@@
@
text
@d1 1
a1 1
/*	$OpenBSD: atomic.h,v 1.5 2007/11/28 12:31:49 kettenis Exp $	*/
d18 2
a19 2
#ifndef _SPARC64_ATOMIC_H_
#define _SPARC64_ATOMIC_H_
d81 1
a81 1
#endif /* _SPARC64_ATOMIC_H_ */
@


1.5
log
@Use cas/casx instead of casa/casxa.
@
text
@d1 1
a1 1
/*	$OpenBSD: atomic.h,v 1.4 2007/11/27 23:29:57 kettenis Exp $	*/
d65 12
@


1.4
log
@Like i386 and amd64 - make the __mp_lock not spin at splhigh.

help from & ok art@@
@
text
@d1 1
a1 1
/*	$OpenBSD: atomic.h,v 1.3 2007/03/13 08:34:03 art Exp $	*/
d26 1
a26 1
	__asm __volatile("casa [%2] %3, %4, %0"
d28 1
a28 1
	    : "r" (uip), "n" (ASI_N), "r" (expect), "m" (*uip));
d37 1
a37 1
	__asm __volatile("casxa [%2] %3, %4, %0"
d39 1
a39 1
	    : "r" (uip), "n" (ASI_N), "r" (expect), "m" (*uip));
@


1.3
log
@Implement proper atomic.h for sparc64.

ok kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d24 1
a24 1
sparc64_casa(volatile unsigned int *uip, unsigned int expect, unsigned int new)
d33 11
d52 1
a52 1
		r = sparc64_casa(uip, e, e | v);
d64 1
a64 1
		r = sparc64_casa(uip, e, e & ~v);
@


1.2
log
@only make this interface available to the kernel for now, discussed witha
rt and such; tested and ok miod drahn
@
text
@d1 16
a16 1
/*	$OpenBSD: atomic.h,v 1.1 2007/02/06 17:13:33 art Exp $	*/
d18 2
a19 1
/* Public Domain */
d21 8
a28 2
#ifndef __SPARC64_ATOMIC_H__
#define __SPARC64_ATOMIC_H__
d30 2
a31 1
#if defined(_KERNEL)
d34 1
a34 1
atomic_setbits_int(__volatile unsigned int *uip, unsigned int v)
d36 7
a42 1
	*uip |= v;
d46 1
a46 1
atomic_clearbits_int(__volatile unsigned int *uip, unsigned int v)
d48 7
a54 1
	*uip &= ~v;
d58 1
a58 1
#endif /* __SPARC64_ATOMIC_H__ */
@


1.1
log
@Add machine/atomic.h to all architectures and define two operations
right now that are supposed to be atomic with respect to interrupts and
SMP: atomic_setbits_int and atomic_clearbits_int.

All architectures other than i386 and amd64 get dummy implementations
since at first we'll be replacing operations that are done with
"a |= bit" and "a &= ~bit" today. More proper implementations will follow

kettenis@@, miod@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d8 2
d22 2
a23 1
#endif
@

