head	1.58;
access;
symbols
	OPENBSD_6_2:1.58.0.2
	OPENBSD_6_2_BASE:1.58
	OPENBSD_6_1:1.58.0.4
	OPENBSD_6_1_BASE:1.58
	OPENBSD_6_0:1.56.0.2
	OPENBSD_6_0_BASE:1.56
	OPENBSD_5_9:1.53.0.2
	OPENBSD_5_9_BASE:1.53
	OPENBSD_5_8:1.46.0.4
	OPENBSD_5_8_BASE:1.46
	OPENBSD_5_7:1.38.0.2
	OPENBSD_5_7_BASE:1.38
	OPENBSD_5_6:1.33.0.4
	OPENBSD_5_6_BASE:1.33
	OPENBSD_5_5:1.29.0.4
	OPENBSD_5_5_BASE:1.29
	OPENBSD_5_4:1.28.0.4
	OPENBSD_5_4_BASE:1.28
	OPENBSD_5_3:1.28.0.2
	OPENBSD_5_3_BASE:1.28
	OPENBSD_5_2:1.25.0.10
	OPENBSD_5_2_BASE:1.25
	OPENBSD_5_1_BASE:1.25
	OPENBSD_5_1:1.25.0.8
	OPENBSD_5_0:1.25.0.6
	OPENBSD_5_0_BASE:1.25
	OPENBSD_4_9:1.25.0.4
	OPENBSD_4_9_BASE:1.25
	OPENBSD_4_8:1.25.0.2
	OPENBSD_4_8_BASE:1.25
	OPENBSD_4_7:1.24.0.2
	OPENBSD_4_7_BASE:1.24
	OPENBSD_4_6:1.16.0.4
	OPENBSD_4_6_BASE:1.16
	OPENBSD_4_5:1.13.0.2
	OPENBSD_4_5_BASE:1.13;
locks; strict;
comment	@ * @;


1.58
date	2017.01.22.10.17.37;	author dlg;	state Exp;
branches;
next	1.57;
commitid	VyLWTsbepAOk7VQM;

1.57
date	2016.09.15.02.00.17;	author dlg;	state Exp;
branches;
next	1.56;
commitid	RlO92XR575sygHqm;

1.56
date	2016.04.13.11.34.00;	author mpi;	state Exp;
branches;
next	1.55;
commitid	RI1iBTF6Zaycxppg;

1.55
date	2016.03.21.00.18.54;	author stsp;	state Exp;
branches;
next	1.54;
commitid	lb2FUhEpKiQQdEYP;

1.54
date	2016.02.26.13.41.51;	author kettenis;	state Exp;
branches;
next	1.53;
commitid	avI6w6jY3IiQcvic;

1.53
date	2015.12.05.13.10.03;	author kettenis;	state Exp;
branches;
next	1.52;
commitid	kkb2y8Ti1Rt4zSic;

1.52
date	2015.12.04.15.18.03;	author kettenis;	state Exp;
branches;
next	1.51;
commitid	0DfRHQjZlK3lEMNw;

1.51
date	2015.11.25.03.09.58;	author dlg;	state Exp;
branches;
next	1.50;
commitid	B0kwmVGiD5DVx4kv;

1.50
date	2015.11.24.17.11.38;	author mpi;	state Exp;
branches;
next	1.49;
commitid	5gdEnqVoJuTuwdTu;

1.49
date	2015.11.24.13.33.18;	author mpi;	state Exp;
branches;
next	1.48;
commitid	5DvsamK0GblTp8ww;

1.48
date	2015.11.20.03.35.22;	author dlg;	state Exp;
branches;
next	1.47;
commitid	eYnPulzvLjDImPCa;

1.47
date	2015.10.25.13.22.09;	author mpi;	state Exp;
branches;
next	1.46;
commitid	n8mxDftG1cK0Rpp7;

1.46
date	2015.06.24.09.40.53;	author mpi;	state Exp;
branches;
next	1.45;
commitid	MVWrtktB46JRxFWT;

1.45
date	2015.06.21.20.04.30;	author kettenis;	state Exp;
branches;
next	1.44;
commitid	chQ72KGHsqE5NyGG;

1.44
date	2015.04.13.08.45.48;	author mpi;	state Exp;
branches;
next	1.43;
commitid	aiRvgNOa4qke9vft;

1.43
date	2015.04.02.09.46.48;	author kettenis;	state Exp;
branches;
next	1.42;
commitid	3JJmGLzG7QXMO7Cu;

1.42
date	2015.04.01.15.23.32;	author kettenis;	state Exp;
branches;
next	1.41;
commitid	F4aNtG6OXAFFvTgM;

1.41
date	2015.03.29.14.08.25;	author kettenis;	state Exp;
branches;
next	1.40;
commitid	7AaFSPomZ594nKpt;

1.40
date	2015.03.21.18.11.18;	author kettenis;	state Exp;
branches;
next	1.39;
commitid	mchzat4Y4B4eq6ot;

1.39
date	2015.03.10.09.26.24;	author mpi;	state Exp;
branches;
next	1.38;
commitid	2V9ARZWiLaMxkDdw;

1.38
date	2015.02.11.04.15.50;	author kettenis;	state Exp;
branches;
next	1.37;
commitid	cE8hWFZpaFGJAy50;

1.37
date	2015.01.25.21.42.13;	author kettenis;	state Exp;
branches;
next	1.36;
commitid	ZoO3iubG0jt8mq0g;

1.36
date	2014.12.22.02.26.54;	author tedu;	state Exp;
branches;
next	1.35;
commitid	2Ez9mHW0jDzojG4V;

1.35
date	2014.09.15.08.16.21;	author kettenis;	state Exp;
branches;
next	1.34;
commitid	6WK0lWMMGMygVGrL;

1.34
date	2014.08.18.13.29.13;	author dlg;	state Exp;
branches;
next	1.33;
commitid	FSwNXPjN2dW2iTm5;

1.33
date	2014.07.12.18.44.43;	author tedu;	state Exp;
branches;
next	1.32;
commitid	uKVPYMN2MLxdZxzH;

1.32
date	2014.07.08.02.59.51;	author dlg;	state Exp;
branches;
next	1.31;
commitid	f6COHImtINzHFiA0;

1.31
date	2014.05.10.11.49.31;	author kettenis;	state Exp;
branches;
next	1.30;

1.30
date	2014.04.03.09.15.06;	author mpi;	state Exp;
branches;
next	1.29;

1.29
date	2013.08.21.05.21.42;	author dlg;	state Exp;
branches;
next	1.28;

1.28
date	2012.12.07.21.56.06;	author kettenis;	state Exp;
branches;
next	1.27;

1.27
date	2012.11.24.23.06.16;	author kettenis;	state Exp;
branches;
next	1.26;

1.26
date	2012.10.26.20.57.08;	author kettenis;	state Exp;
branches;
next	1.25;

1.25
date	2010.04.15.19.47.32;	author kettenis;	state Exp;
branches;
next	1.24;

1.24
date	2010.02.21.14.48.42;	author kettenis;	state Exp;
branches;
next	1.23;

1.23
date	2010.02.21.12.01.42;	author kettenis;	state Exp;
branches;
next	1.22;

1.22
date	2009.12.26.18.54.56;	author kettenis;	state Exp;
branches;
next	1.21;

1.21
date	2009.12.14.22.38.03;	author kettenis;	state Exp;
branches;
next	1.20;

1.20
date	2009.12.14.21.08.45;	author kettenis;	state Exp;
branches;
next	1.19;

1.19
date	2009.12.14.20.50.46;	author kettenis;	state Exp;
branches;
next	1.18;

1.18
date	2009.12.14.20.01.11;	author kettenis;	state Exp;
branches;
next	1.17;

1.17
date	2009.08.09.11.40.58;	author deraadt;	state Exp;
branches;
next	1.16;

1.16
date	2009.05.12.21.33.38;	author kettenis;	state Exp;
branches;
next	1.15;

1.15
date	2009.05.12.21.13.37;	author kettenis;	state Exp;
branches;
next	1.14;

1.14
date	2009.05.10.12.59.12;	author kettenis;	state Exp;
branches;
next	1.13;

1.13
date	2009.02.20.17.50.22;	author kettenis;	state Exp;
branches;
next	1.12;

1.12
date	2009.01.17.22.18.14;	author kettenis;	state Exp;
branches;
next	1.11;

1.11
date	2009.01.17.20.18.16;	author kettenis;	state Exp;
branches;
next	1.10;

1.10
date	2009.01.16.16.51.30;	author kettenis;	state Exp;
branches;
next	1.9;

1.9
date	2009.01.12.19.10.52;	author kettenis;	state Exp;
branches;
next	1.8;

1.8
date	2009.01.11.15.06.52;	author kettenis;	state Exp;
branches;
next	1.7;

1.7
date	2009.01.10.20.32.37;	author kettenis;	state Exp;
branches;
next	1.6;

1.6
date	2009.01.10.17.13.28;	author kettenis;	state Exp;
branches;
next	1.5;

1.5
date	2009.01.10.14.23.59;	author kettenis;	state Exp;
branches;
next	1.4;

1.4
date	2009.01.07.21.12.35;	author kettenis;	state Exp;
branches;
next	1.3;

1.3
date	2009.01.06.22.49.46;	author kettenis;	state Exp;
branches;
next	1.2;

1.2
date	2009.01.05.22.09.51;	author kettenis;	state Exp;
branches;
next	1.1;

1.1
date	2009.01.04.17.20.44;	author kettenis;	state Exp;
branches;
next	;


desc
@@


1.58
log
@move counting if_opackets next to counting if_obytes in if_enqueue.

this means packets are consistently counted in one place, unlike the
many and various ways that drivers thought they should do it.

ok mpi@@ deraadt@@
@
text
@/*	$OpenBSD: vnet.c,v 1.57 2016/09/15 02:00:17 dlg Exp $	*/
/*
 * Copyright (c) 2009, 2015 Mark Kettenis
 *
 * Permission to use, copy, modify, and distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 */

#include "bpfilter.h"

#include <sys/param.h>
#include <sys/atomic.h>
#include <sys/device.h>
#include <sys/malloc.h>
#include <sys/pool.h>
#include <sys/mbuf.h>
#include <sys/socket.h>
#include <sys/sockio.h>
#include <sys/systm.h>
#include <sys/timeout.h>

#include <machine/autoconf.h>
#include <machine/hypervisor.h>
#include <machine/openfirm.h>

#include <net/if.h>
#include <net/if_media.h>

#include <netinet/in.h>
#include <netinet/if_ether.h>

#if NBPFILTER > 0
#include <net/bpf.h>
#endif

#include <uvm/uvm_extern.h>

#include <sparc64/dev/cbusvar.h>
#include <sparc64/dev/ldcvar.h>
#include <sparc64/dev/viovar.h>

#ifdef VNET_DEBUG
#define DPRINTF(x)	printf x
#else
#define DPRINTF(x)
#endif

#define VNET_TX_ENTRIES		32
#define VNET_RX_ENTRIES		32

struct vnet_attr_info {
	struct vio_msg_tag	tag;
	uint8_t			xfer_mode;
	uint8_t			addr_type;
	uint16_t		ack_freq;
	uint32_t		_reserved1;
	uint64_t		addr;
	uint64_t		mtu;
	uint64_t		_reserved2[3];
};

/* Address types. */
#define VNET_ADDR_ETHERMAC	0x01

/* Sub-Type envelopes. */
#define VNET_MCAST_INFO		0x0101

#define VNET_NUM_MCAST		7

struct vnet_mcast_info {
	struct vio_msg_tag	tag;
	uint8_t			set;
	uint8_t			count;
	uint8_t			mcast_addr[VNET_NUM_MCAST][ETHER_ADDR_LEN];
	uint32_t		_reserved;
};

struct vnet_desc {
	struct vio_dring_hdr	hdr;
	uint32_t		nbytes;
	uint32_t		ncookies;
	struct ldc_cookie	cookie[2];
};

struct vnet_desc_msg {
	struct vio_msg_tag	tag;
	uint64_t		seq_no;
	uint64_t		desc_handle;
	uint32_t		nbytes;
	uint32_t		ncookies;
	struct ldc_cookie	cookie[1];
};

struct vnet_dring {
	bus_dmamap_t		vd_map;
	bus_dma_segment_t	vd_seg;
	struct vnet_desc	*vd_desc;
	int			vd_nentries;
};

struct vnet_dring *vnet_dring_alloc(bus_dma_tag_t, int);
void	vnet_dring_free(bus_dma_tag_t, struct vnet_dring *);

/*
 * For now, we only support vNet 1.0.
 */
#define VNET_MAJOR	1
#define VNET_MINOR	0

/*
 * The vNet protocol wants the IP header to be 64-bit aligned, so
 * define out own variant of ETHER_ALIGN.
 */
#define VNET_ETHER_ALIGN	6

struct vnet_soft_desc {
	int		vsd_map_idx;
	caddr_t		vsd_buf;
};

struct vnet_softc {
	struct device	sc_dv;
	bus_space_tag_t	sc_bustag;
	bus_dma_tag_t	sc_dmatag;

	uint64_t	sc_tx_ino;
	uint64_t	sc_rx_ino;
	void		*sc_tx_ih;
	void		*sc_rx_ih;

	struct ldc_conn	sc_lc;

	uint16_t	sc_vio_state;
#define VIO_SND_VER_INFO	0x0001
#define VIO_ACK_VER_INFO	0x0002
#define VIO_RCV_VER_INFO	0x0004
#define VIO_SND_ATTR_INFO	0x0008
#define VIO_ACK_ATTR_INFO	0x0010
#define VIO_RCV_ATTR_INFO	0x0020
#define VIO_SND_DRING_REG	0x0040
#define VIO_ACK_DRING_REG	0x0080
#define VIO_RCV_DRING_REG	0x0100
#define VIO_SND_RDX		0x0200
#define VIO_ACK_RDX		0x0400
#define VIO_RCV_RDX		0x0800

	struct timeout	sc_handshake_to;

	uint8_t		sc_xfer_mode;

	uint32_t	sc_local_sid;
	uint64_t	sc_dring_ident;
	uint64_t	sc_seq_no;

	u_int		sc_tx_prod;
	u_int		sc_tx_cons;

	u_int		sc_peer_state;

	struct ldc_map	*sc_lm;
	struct vnet_dring *sc_vd;
	struct vnet_soft_desc *sc_vsd;
#define VNET_NUM_SOFT_DESC	128

	size_t		sc_peer_desc_size;
	struct ldc_cookie sc_peer_dring_cookie;
	int		sc_peer_dring_nentries;

	struct pool	sc_pool;

	struct arpcom	sc_ac;
	struct ifmedia	sc_media;
};

int	vnet_match(struct device *, void *, void *);
void	vnet_attach(struct device *, struct device *, void *);

struct cfattach vnet_ca = {
	sizeof(struct vnet_softc), vnet_match, vnet_attach
};

struct cfdriver vnet_cd = {
	NULL, "vnet", DV_IFNET
};

int	vnet_tx_intr(void *);
int	vnet_rx_intr(void *);
void	vnet_handshake(void *);

void	vio_rx_data(struct ldc_conn *, struct ldc_pkt *);
void	vnet_rx_vio_ctrl(struct vnet_softc *, struct vio_msg *);
void	vnet_rx_vio_ver_info(struct vnet_softc *, struct vio_msg_tag *);
void	vnet_rx_vio_attr_info(struct vnet_softc *, struct vio_msg_tag *);
void	vnet_rx_vio_dring_reg(struct vnet_softc *, struct vio_msg_tag *);
void	vnet_rx_vio_rdx(struct vnet_softc *sc, struct vio_msg_tag *);
void	vnet_rx_vio_data(struct vnet_softc *sc, struct vio_msg *);
void	vnet_rx_vio_desc_data(struct vnet_softc *sc, struct vio_msg_tag *);
void	vnet_rx_vio_dring_data(struct vnet_softc *sc, struct vio_msg_tag *);

void	vnet_ldc_reset(struct ldc_conn *);
void	vnet_ldc_start(struct ldc_conn *);

void	vnet_sendmsg(struct vnet_softc *, void *, size_t);
void	vnet_send_ver_info(struct vnet_softc *, uint16_t, uint16_t);
void	vnet_send_attr_info(struct vnet_softc *);
void	vnet_send_dring_reg(struct vnet_softc *);
void	vio_send_rdx(struct vnet_softc *);
void	vnet_send_dring_data(struct vnet_softc *, uint32_t);

void	vnet_start(struct ifnet *);
void	vnet_start_desc(struct ifnet *);
int	vnet_ioctl(struct ifnet *, u_long, caddr_t);
void	vnet_watchdog(struct ifnet *);

int	vnet_media_change(struct ifnet *);
void	vnet_media_status(struct ifnet *, struct ifmediareq *);

void	vnet_link_state(struct vnet_softc *sc);

void	vnet_setmulti(struct vnet_softc *, int);

void	vnet_init(struct ifnet *);
void	vnet_stop(struct ifnet *);

int
vnet_match(struct device *parent, void *match, void *aux)
{
	struct cbus_attach_args *ca = aux;

	if (strcmp(ca->ca_name, "network") == 0)
		return (1);

	return (0);
}

void
vnet_attach(struct device *parent, struct device *self, void *aux)
{
	struct vnet_softc *sc = (struct vnet_softc *)self;
	struct cbus_attach_args *ca = aux;
	struct ldc_conn *lc;
	struct ifnet *ifp;

	sc->sc_bustag = ca->ca_bustag;
	sc->sc_dmatag = ca->ca_dmatag;
	sc->sc_tx_ino = ca->ca_tx_ino;
	sc->sc_rx_ino = ca->ca_rx_ino;

	printf(": ivec 0x%llx, 0x%llx", sc->sc_tx_ino, sc->sc_rx_ino);

	/*
	 * Un-configure queues before registering interrupt handlers,
	 * such that we dont get any stale LDC packets or events.
	 */
	hv_ldc_tx_qconf(ca->ca_id, 0, 0);
	hv_ldc_rx_qconf(ca->ca_id, 0, 0);

	sc->sc_tx_ih = bus_intr_establish(ca->ca_bustag, sc->sc_tx_ino,
	    IPL_NET, BUS_INTR_ESTABLISH_MPSAFE, vnet_tx_intr,
	    sc, sc->sc_dv.dv_xname);
	sc->sc_rx_ih = bus_intr_establish(ca->ca_bustag, sc->sc_rx_ino,
	    IPL_NET, BUS_INTR_ESTABLISH_MPSAFE, vnet_rx_intr,
	    sc, sc->sc_dv.dv_xname);
	if (sc->sc_tx_ih == NULL || sc->sc_rx_ih == NULL) {
		printf(", can't establish interrupt\n");
		return;
	}

	lc = &sc->sc_lc;
	lc->lc_id = ca->ca_id;
	lc->lc_sc = sc;
	lc->lc_reset = vnet_ldc_reset;
	lc->lc_start = vnet_ldc_start;
	lc->lc_rx_data = vio_rx_data;

	timeout_set(&sc->sc_handshake_to, vnet_handshake, sc);
	sc->sc_peer_state = VIO_DP_STOPPED;

	lc->lc_txq = ldc_queue_alloc(sc->sc_dmatag, VNET_TX_ENTRIES);
	if (lc->lc_txq == NULL) {
		printf(", can't allocate tx queue\n");
		return;
	}

	lc->lc_rxq = ldc_queue_alloc(sc->sc_dmatag, VNET_RX_ENTRIES);
	if (lc->lc_rxq == NULL) {
		printf(", can't allocate rx queue\n");
		goto free_txqueue;
	}

	if (OF_getprop(ca->ca_node, "local-mac-address",
	    sc->sc_ac.ac_enaddr, ETHER_ADDR_LEN) > 0)
		printf(", address %s", ether_sprintf(sc->sc_ac.ac_enaddr));

	/*
	 * Each interface gets its own pool.
	 */
	pool_init(&sc->sc_pool, 2048, 0, IPL_NET, 0, sc->sc_dv.dv_xname, NULL);

	ifp = &sc->sc_ac.ac_if;
	ifp->if_softc = sc;
	ifp->if_flags = IFF_BROADCAST | IFF_SIMPLEX | IFF_MULTICAST;
	ifp->if_link_state = LINK_STATE_DOWN;
	ifp->if_ioctl = vnet_ioctl;
	ifp->if_start = vnet_start;
	ifp->if_watchdog = vnet_watchdog;
	strlcpy(ifp->if_xname, sc->sc_dv.dv_xname, IFNAMSIZ);
	IFQ_SET_MAXLEN(&ifp->if_snd, 31); /* XXX */

	ifmedia_init(&sc->sc_media, 0, vnet_media_change, vnet_media_status);
	ifmedia_add(&sc->sc_media, IFM_ETHER | IFM_AUTO, 0, NULL);
	ifmedia_set(&sc->sc_media, IFM_ETHER | IFM_AUTO);

	if_attach(ifp);
	ether_ifattach(ifp);

	printf("\n");
	return;

free_txqueue:
	ldc_queue_free(sc->sc_dmatag, lc->lc_txq);
}

int
vnet_tx_intr(void *arg)
{
	struct vnet_softc *sc = arg;
	struct ldc_conn *lc = &sc->sc_lc;
	uint64_t tx_head, tx_tail, tx_state;

	hv_ldc_tx_get_state(lc->lc_id, &tx_head, &tx_tail, &tx_state);
	if (tx_state != lc->lc_tx_state) {
		switch (tx_state) {
		case LDC_CHANNEL_DOWN:
			DPRINTF(("Tx link down\n"));
			break;
		case LDC_CHANNEL_UP:
			DPRINTF(("Tx link up\n"));
			break;
		case LDC_CHANNEL_RESET:
			DPRINTF(("Tx link reset\n"));
			break;
		}
		lc->lc_tx_state = tx_state;
	}

	return (1);
}

int
vnet_rx_intr(void *arg)
{
	struct vnet_softc *sc = arg;
	struct ldc_conn *lc = &sc->sc_lc;
	uint64_t rx_head, rx_tail, rx_state;
	struct ldc_pkt *lp;
	int err;

	err = hv_ldc_rx_get_state(lc->lc_id, &rx_head, &rx_tail, &rx_state);
	if (err == H_EINVAL)
		return (0);
	if (err != H_EOK) {
		printf("hv_ldc_rx_get_state %d\n", err);
		return (0);
	}

	if (rx_state != lc->lc_rx_state) {
		switch (rx_state) {
		case LDC_CHANNEL_DOWN:
			DPRINTF(("Rx link down\n"));
			lc->lc_tx_seqid = 0;
			lc->lc_state = 0;
			lc->lc_reset(lc);
			break;
		case LDC_CHANNEL_UP:
			DPRINTF(("Rx link up\n"));
			timeout_add_msec(&sc->sc_handshake_to, 500);
			break;
		case LDC_CHANNEL_RESET:
			DPRINTF(("Rx link reset\n"));
			lc->lc_tx_seqid = 0;
			lc->lc_state = 0;
			lc->lc_reset(lc);
			timeout_add_msec(&sc->sc_handshake_to, 500);
			break;
		}
		lc->lc_rx_state = rx_state;
		return (1);
	}

	if (rx_head == rx_tail)
		return (0);

	lp = (struct ldc_pkt *)(lc->lc_rxq->lq_va + rx_head);
	switch (lp->type) {
	case LDC_CTRL:
		ldc_rx_ctrl(lc, lp);
		break;

	case LDC_DATA:
		ldc_rx_data(lc, lp);
		break;

	default:
		DPRINTF(("%0x02/%0x02/%0x02\n", lp->type, lp->stype,
		    lp->ctrl));
		ldc_reset(lc);
		break;
	}

	if (lc->lc_state == 0)
		return (1);

	rx_head += sizeof(*lp);
	rx_head &= ((lc->lc_rxq->lq_nentries * sizeof(*lp)) - 1);
	err = hv_ldc_rx_set_qhead(lc->lc_id, rx_head);
	if (err != H_EOK)
		printf("%s: hv_ldc_rx_set_qhead %d\n", __func__, err);

	return (1);
}

void
vnet_handshake(void *arg)
{
	struct vnet_softc *sc = arg;

	ldc_send_vers(&sc->sc_lc);
}

void
vio_rx_data(struct ldc_conn *lc, struct ldc_pkt *lp)
{
	struct vio_msg *vm = (struct vio_msg *)lp;

	switch (vm->type) {
	case VIO_TYPE_CTRL:
		if ((lp->env & LDC_FRAG_START) == 0 &&
		    (lp->env & LDC_FRAG_STOP) == 0)
			return;
		vnet_rx_vio_ctrl(lc->lc_sc, vm);
		break;

	case VIO_TYPE_DATA:
		if((lp->env & LDC_FRAG_START) == 0)
			return;
		vnet_rx_vio_data(lc->lc_sc, vm);
		break;

	default:
		DPRINTF(("Unhandled packet type 0x%02x\n", vm->type));
		ldc_reset(lc);
		break;
	}
}

void
vnet_rx_vio_ctrl(struct vnet_softc *sc, struct vio_msg *vm)
{
	struct vio_msg_tag *tag = (struct vio_msg_tag *)&vm->type;

	switch (tag->stype_env) {
	case VIO_VER_INFO:
		vnet_rx_vio_ver_info(sc, tag);
		break;
	case VIO_ATTR_INFO:
		vnet_rx_vio_attr_info(sc, tag);
		break;
	case VIO_DRING_REG:
		vnet_rx_vio_dring_reg(sc, tag);
		break;
	case VIO_RDX:
		vnet_rx_vio_rdx(sc, tag);
		break;
	default:
		DPRINTF(("CTRL/0x%02x/0x%04x\n", tag->stype, tag->stype_env));
		break;
	}
}

void
vnet_rx_vio_ver_info(struct vnet_softc *sc, struct vio_msg_tag *tag)
{
	struct vio_ver_info *vi = (struct vio_ver_info *)tag;

	switch (vi->tag.stype) {
	case VIO_SUBTYPE_INFO:
		DPRINTF(("CTRL/INFO/VER_INFO\n"));

		/* Make sure we're talking to a virtual network device. */
		if (vi->dev_class != VDEV_NETWORK &&
		    vi->dev_class != VDEV_NETWORK_SWITCH) {
			/* Huh, we're not talking to a network device? */
			printf("Not a network device\n");
			vi->tag.stype = VIO_SUBTYPE_NACK;
			vnet_sendmsg(sc, vi, sizeof(*vi));
			return;
		}

		if (vi->major != VNET_MAJOR) {
			vi->tag.stype = VIO_SUBTYPE_NACK;
			vi->major = VNET_MAJOR;
			vi->minor = VNET_MINOR;
			vnet_sendmsg(sc, vi, sizeof(*vi));
			return;
		}

		vi->tag.stype = VIO_SUBTYPE_ACK;
		vi->tag.sid = sc->sc_local_sid;
		vi->minor = VNET_MINOR;
		vnet_sendmsg(sc, vi, sizeof(*vi));
		sc->sc_vio_state |= VIO_RCV_VER_INFO;
		break;

	case VIO_SUBTYPE_ACK:
		DPRINTF(("CTRL/ACK/VER_INFO\n"));
		if (!ISSET(sc->sc_vio_state, VIO_SND_VER_INFO)) {
			ldc_reset(&sc->sc_lc);
			break;
		}
		sc->sc_vio_state |= VIO_ACK_VER_INFO;
		break;

	default:
		DPRINTF(("CTRL/0x%02x/VER_INFO\n", vi->tag.stype));
		break;
	}

	if (ISSET(sc->sc_vio_state, VIO_RCV_VER_INFO) &&
	    ISSET(sc->sc_vio_state, VIO_ACK_VER_INFO))
		vnet_send_attr_info(sc);
}

void
vnet_rx_vio_attr_info(struct vnet_softc *sc, struct vio_msg_tag *tag)
{
	struct vnet_attr_info *ai = (struct vnet_attr_info *)tag;

	switch (ai->tag.stype) {
	case VIO_SUBTYPE_INFO:
		DPRINTF(("CTRL/INFO/ATTR_INFO\n"));
		sc->sc_xfer_mode = ai->xfer_mode;

		ai->tag.stype = VIO_SUBTYPE_ACK;
		ai->tag.sid = sc->sc_local_sid;
		vnet_sendmsg(sc, ai, sizeof(*ai));
		sc->sc_vio_state |= VIO_RCV_ATTR_INFO;
		break;

	case VIO_SUBTYPE_ACK:
		DPRINTF(("CTRL/ACK/ATTR_INFO\n"));
		if (!ISSET(sc->sc_vio_state, VIO_SND_ATTR_INFO)) {
			ldc_reset(&sc->sc_lc);
			break;
		}
		sc->sc_vio_state |= VIO_ACK_ATTR_INFO;
		break;

	default:
		DPRINTF(("CTRL/0x%02x/ATTR_INFO\n", ai->tag.stype));
		break;
	}

	if (ISSET(sc->sc_vio_state, VIO_RCV_ATTR_INFO) &&
	    ISSET(sc->sc_vio_state, VIO_ACK_ATTR_INFO)) {
		if (sc->sc_xfer_mode == VIO_DRING_MODE)
			vnet_send_dring_reg(sc);
		else
			vio_send_rdx(sc);
	}
}

void
vnet_rx_vio_dring_reg(struct vnet_softc *sc, struct vio_msg_tag *tag)
{
	struct vio_dring_reg *dr = (struct vio_dring_reg *)tag;

	switch (dr->tag.stype) {
	case VIO_SUBTYPE_INFO:
		DPRINTF(("CTRL/INFO/DRING_REG\n"));

		sc->sc_peer_dring_nentries = dr->num_descriptors;
		sc->sc_peer_desc_size = dr->descriptor_size;
		sc->sc_peer_dring_cookie = dr->cookie[0];

		dr->tag.stype = VIO_SUBTYPE_ACK;
		dr->tag.sid = sc->sc_local_sid;
		vnet_sendmsg(sc, dr, sizeof(*dr));
		sc->sc_vio_state |= VIO_RCV_DRING_REG;
		break;

	case VIO_SUBTYPE_ACK:
		DPRINTF(("CTRL/ACK/DRING_REG\n"));
		if (!ISSET(sc->sc_vio_state, VIO_SND_DRING_REG)) {
			ldc_reset(&sc->sc_lc);
			break;
		}

		sc->sc_dring_ident = dr->dring_ident;
		sc->sc_seq_no = 1;

		sc->sc_vio_state |= VIO_ACK_DRING_REG;
		break;

	default:
		DPRINTF(("CTRL/0x%02x/DRING_REG\n", dr->tag.stype));
		break;
	}

	if (ISSET(sc->sc_vio_state, VIO_RCV_DRING_REG) &&
	    ISSET(sc->sc_vio_state, VIO_ACK_DRING_REG))
		vio_send_rdx(sc);
}

void
vnet_rx_vio_rdx(struct vnet_softc *sc, struct vio_msg_tag *tag)
{
	struct ifnet *ifp = &sc->sc_ac.ac_if;

	switch(tag->stype) {
	case VIO_SUBTYPE_INFO:
		DPRINTF(("CTRL/INFO/RDX\n"));

		tag->stype = VIO_SUBTYPE_ACK;
		tag->sid = sc->sc_local_sid;
		vnet_sendmsg(sc, tag, sizeof(*tag));
		sc->sc_vio_state |= VIO_RCV_RDX;
		break;

	case VIO_SUBTYPE_ACK:
		DPRINTF(("CTRL/ACK/RDX\n"));
		if (!ISSET(sc->sc_vio_state, VIO_SND_RDX)) {
			ldc_reset(&sc->sc_lc);
			break;
		}
		sc->sc_vio_state |= VIO_ACK_RDX;
		break;

	default:
		DPRINTF(("CTRL/0x%02x/RDX (VIO)\n", tag->stype));
		break;
	}

	if (ISSET(sc->sc_vio_state, VIO_RCV_RDX) &&
	    ISSET(sc->sc_vio_state, VIO_ACK_RDX)) {
		/* Link is up! */
		vnet_link_state(sc);

		/* Configure multicast now that we can. */
		vnet_setmulti(sc, 1);

		KERNEL_LOCK();
		ifq_clr_oactive(&ifp->if_snd);
		vnet_start(ifp);
		KERNEL_UNLOCK();
	}
}

void
vnet_rx_vio_data(struct vnet_softc *sc, struct vio_msg *vm)
{
	struct vio_msg_tag *tag = (struct vio_msg_tag *)&vm->type;

	if (!ISSET(sc->sc_vio_state, VIO_RCV_RDX) ||
	    !ISSET(sc->sc_vio_state, VIO_ACK_RDX)) {
		DPRINTF(("Spurious DATA/0x%02x/0x%04x\n", tag->stype,
		    tag->stype_env));
		return;
	}

	switch(tag->stype_env) {
	case VIO_DESC_DATA:
		vnet_rx_vio_desc_data(sc, tag);
		break;

	case VIO_DRING_DATA:
		vnet_rx_vio_dring_data(sc, tag);
		break;

	default:
		DPRINTF(("DATA/0x%02x/0x%04x\n", tag->stype, tag->stype_env));
		break;
	}
}

void
vnet_rx_vio_desc_data(struct vnet_softc *sc, struct vio_msg_tag *tag)
{
	struct vnet_desc_msg *dm = (struct vnet_desc_msg *)tag;
	struct ldc_conn *lc = &sc->sc_lc;
	struct ldc_map *map = sc->sc_lm;
	struct ifnet *ifp = &sc->sc_ac.ac_if;
	struct mbuf_list ml = MBUF_LIST_INITIALIZER();
	struct mbuf *m;
	caddr_t buf;
	paddr_t pa;
	psize_t nbytes;
	u_int cons;
	int err;

	switch(tag->stype) {
	case VIO_SUBTYPE_INFO:
		buf = pool_get(&sc->sc_pool, PR_NOWAIT|PR_ZERO);
		if (buf == NULL) {
			ifp->if_ierrors++;
			goto skip;
		}
		nbytes = roundup(dm->nbytes, 8);

		if (dm->nbytes > (ETHER_MAX_LEN - ETHER_CRC_LEN)) {
			ifp->if_ierrors++;
			goto skip;
		}

		pmap_extract(pmap_kernel(), (vaddr_t)buf, &pa);
		err = hv_ldc_copy(lc->lc_id, LDC_COPY_IN,
		    dm->cookie[0].addr, pa, nbytes, &nbytes);
		if (err != H_EOK) {
			pool_put(&sc->sc_pool, buf);
			ifp->if_ierrors++;
			goto skip;
		}

		/* Stupid OBP doesn't align properly. */
                m = m_devget(buf, dm->nbytes, ETHER_ALIGN);
		pool_put(&sc->sc_pool, buf);
		if (m == NULL) {
			ifp->if_ierrors++;
			goto skip;
		}

		/* Pass it on. */
		ml_enqueue(&ml, m);
		if_input(ifp, &ml);

	skip:
		dm->tag.stype = VIO_SUBTYPE_ACK;
		dm->tag.sid = sc->sc_local_sid;
		vnet_sendmsg(sc, dm, sizeof(*dm));
		break;

	case VIO_SUBTYPE_ACK:
		DPRINTF(("DATA/ACK/DESC_DATA\n"));

		if (dm->desc_handle != sc->sc_tx_cons) {
			printf("out of order\n");
			return;
		}

		cons = sc->sc_tx_cons & (sc->sc_vd->vd_nentries - 1);

		map->lm_slot[sc->sc_vsd[cons].vsd_map_idx].entry = 0;
		atomic_dec_int(&map->lm_count);

		pool_put(&sc->sc_pool, sc->sc_vsd[cons].vsd_buf);
		sc->sc_vsd[cons].vsd_buf = NULL;

		sc->sc_tx_cons++;
		break;

	case VIO_SUBTYPE_NACK:
		DPRINTF(("DATA/NACK/DESC_DATA\n"));
		break;

	default:
		DPRINTF(("DATA/0x%02x/DESC_DATA\n", tag->stype));
		break;
	}
}

void
vnet_rx_vio_dring_data(struct vnet_softc *sc, struct vio_msg_tag *tag)
{
	struct vio_dring_msg *dm = (struct vio_dring_msg *)tag;
	struct ldc_conn *lc = &sc->sc_lc;
	struct ifnet *ifp = &sc->sc_ac.ac_if;
	struct mbuf *m;
	paddr_t pa;
	psize_t nbytes;
	int err;

	switch(tag->stype) {
	case VIO_SUBTYPE_INFO:
	{
		struct vnet_desc desc;
		uint64_t cookie;
		paddr_t desc_pa;
		int idx, ack_end_idx = -1;
		struct mbuf_list ml = MBUF_LIST_INITIALIZER();

		idx = dm->start_idx;
		for (;;) {
			cookie = sc->sc_peer_dring_cookie.addr;
			cookie += idx * sc->sc_peer_desc_size;
			nbytes = sc->sc_peer_desc_size;
			pmap_extract(pmap_kernel(), (vaddr_t)&desc, &desc_pa);
			err = hv_ldc_copy(lc->lc_id, LDC_COPY_IN, cookie,
			    desc_pa, nbytes, &nbytes);
			if (err != H_EOK) {
				printf("hv_ldc_copy_in %d\n", err);
				break;
			}

			if (desc.hdr.dstate != VIO_DESC_READY)
				break;

			if (desc.nbytes > (ETHER_MAX_LEN - ETHER_CRC_LEN)) {
				ifp->if_ierrors++;
				goto skip;
			}

			m = MCLGETI(NULL, M_DONTWAIT, NULL, desc.nbytes);
			if (!m)
				break;
			m->m_len = m->m_pkthdr.len = desc.nbytes;
			nbytes = roundup(desc.nbytes + VNET_ETHER_ALIGN, 8);

			pmap_extract(pmap_kernel(), (vaddr_t)m->m_data, &pa);
			err = hv_ldc_copy(lc->lc_id, LDC_COPY_IN,
			    desc.cookie[0].addr, pa, nbytes, &nbytes);
			if (err != H_EOK) {
				m_freem(m);
				goto skip;
			}
			m->m_data += VNET_ETHER_ALIGN;

			ml_enqueue(&ml, m);

		skip:
			desc.hdr.dstate = VIO_DESC_DONE;
			nbytes = sc->sc_peer_desc_size;
			err = hv_ldc_copy(lc->lc_id, LDC_COPY_OUT, cookie,
			    desc_pa, nbytes, &nbytes);
			if (err != H_EOK)
				printf("hv_ldc_copy_out %d\n", err);

			ack_end_idx = idx;
			if (++idx == sc->sc_peer_dring_nentries)
				idx = 0;
		}

		if_input(ifp, &ml);

		if (ack_end_idx == -1) {
			dm->tag.stype = VIO_SUBTYPE_NACK;
		} else {
			dm->tag.stype = VIO_SUBTYPE_ACK;
			dm->end_idx = ack_end_idx;
		}
		dm->tag.sid = sc->sc_local_sid;
		dm->proc_state = VIO_DP_STOPPED;
		vnet_sendmsg(sc, dm, sizeof(*dm));
		break;
	}

	case VIO_SUBTYPE_ACK:
	{
		struct ldc_map *map = sc->sc_lm;
		u_int cons, count;

		sc->sc_peer_state = dm->proc_state;

		cons = sc->sc_tx_cons & (sc->sc_vd->vd_nentries - 1);
		while (sc->sc_vd->vd_desc[cons].hdr.dstate == VIO_DESC_DONE) {
			map->lm_slot[sc->sc_vsd[cons].vsd_map_idx].entry = 0;
			atomic_dec_int(&map->lm_count);

			pool_put(&sc->sc_pool, sc->sc_vsd[cons].vsd_buf);
			sc->sc_vsd[cons].vsd_buf = NULL;

			sc->sc_vd->vd_desc[cons].hdr.dstate = VIO_DESC_FREE;
			sc->sc_tx_cons++;
			cons = sc->sc_tx_cons & (sc->sc_vd->vd_nentries - 1);
		}

		count = sc->sc_tx_prod - sc->sc_tx_cons;
		if (count > 0 && sc->sc_peer_state != VIO_DP_ACTIVE)
			vnet_send_dring_data(sc, cons);

		KERNEL_LOCK();
		if (count < (sc->sc_vd->vd_nentries - 1))
			ifq_clr_oactive(&ifp->if_snd);
		if (count == 0)
			ifp->if_timer = 0;

		vnet_start(ifp);
		KERNEL_UNLOCK();
		break;
	}

	case VIO_SUBTYPE_NACK:
		DPRINTF(("DATA/NACK/DRING_DATA\n"));
		sc->sc_peer_state = VIO_DP_STOPPED;
		break;

	default:
		DPRINTF(("DATA/0x%02x/DRING_DATA\n", tag->stype));
		break;
	}
}

void
vnet_ldc_reset(struct ldc_conn *lc)
{
	struct vnet_softc *sc = lc->lc_sc;
	int i;

	timeout_del(&sc->sc_handshake_to);
	sc->sc_tx_prod = sc->sc_tx_cons = 0;
	sc->sc_peer_state = VIO_DP_STOPPED;
	sc->sc_vio_state = 0;
	vnet_link_state(sc);

	sc->sc_lm->lm_next = 1;
	sc->sc_lm->lm_count = 1;
	for (i = 1; i < sc->sc_lm->lm_nentries; i++)
		sc->sc_lm->lm_slot[i].entry = 0;

	for (i = 0; i < sc->sc_vd->vd_nentries; i++) {
		if (sc->sc_vsd[i].vsd_buf) {
			pool_put(&sc->sc_pool, sc->sc_vsd[i].vsd_buf);
			sc->sc_vsd[i].vsd_buf = NULL;
		}
		sc->sc_vd->vd_desc[i].hdr.dstate = VIO_DESC_FREE;
	}
}

void
vnet_ldc_start(struct ldc_conn *lc)
{
	struct vnet_softc *sc = lc->lc_sc;

	timeout_del(&sc->sc_handshake_to);
	vnet_send_ver_info(sc, VNET_MAJOR, VNET_MINOR);
}

void
vnet_sendmsg(struct vnet_softc *sc, void *msg, size_t len)
{
	struct ldc_conn *lc = &sc->sc_lc;
	int err;

	err = ldc_send_unreliable(lc, msg, len);
	if (err)
		printf("%s: ldc_send_unreliable: %d\n", __func__, err);
}

void
vnet_send_ver_info(struct vnet_softc *sc, uint16_t major, uint16_t minor)
{
	struct vio_ver_info vi;

	bzero(&vi, sizeof(vi));
	vi.tag.type = VIO_TYPE_CTRL;
	vi.tag.stype = VIO_SUBTYPE_INFO;
	vi.tag.stype_env = VIO_VER_INFO;
	vi.tag.sid = sc->sc_local_sid;
	vi.major = major;
	vi.minor = minor;
	vi.dev_class = VDEV_NETWORK;
	vnet_sendmsg(sc, &vi, sizeof(vi));

	sc->sc_vio_state |= VIO_SND_VER_INFO;
}

void
vnet_send_attr_info(struct vnet_softc *sc)
{
	struct vnet_attr_info ai;
	int i;

	bzero(&ai, sizeof(ai));
	ai.tag.type = VIO_TYPE_CTRL;
	ai.tag.stype = VIO_SUBTYPE_INFO;
	ai.tag.stype_env = VIO_ATTR_INFO;
	ai.tag.sid = sc->sc_local_sid;
	ai.xfer_mode = VIO_DRING_MODE;
	ai.addr_type = VNET_ADDR_ETHERMAC;
	ai.ack_freq = 0;
	ai.addr = 0;
	for (i = 0; i < ETHER_ADDR_LEN; i++) {
		ai.addr <<= 8;
		ai.addr |= sc->sc_ac.ac_enaddr[i];
	}
	ai.mtu = ETHER_MAX_LEN - ETHER_CRC_LEN;
	vnet_sendmsg(sc, &ai, sizeof(ai));

	sc->sc_vio_state |= VIO_SND_ATTR_INFO;
}

void
vnet_send_dring_reg(struct vnet_softc *sc)
{
	struct vio_dring_reg dr;

	bzero(&dr, sizeof(dr));
	dr.tag.type = VIO_TYPE_CTRL;
	dr.tag.stype = VIO_SUBTYPE_INFO;
	dr.tag.stype_env = VIO_DRING_REG;
	dr.tag.sid = sc->sc_local_sid;
	dr.dring_ident = 0;
	dr.num_descriptors = sc->sc_vd->vd_nentries;
	dr.descriptor_size = sizeof(struct vnet_desc);
	dr.options = VIO_TX_RING;
	dr.ncookies = 1;
	dr.cookie[0].addr = 0;
	dr.cookie[0].size = PAGE_SIZE;
	vnet_sendmsg(sc, &dr, sizeof(dr));

	sc->sc_vio_state |= VIO_SND_DRING_REG;
};

void
vio_send_rdx(struct vnet_softc *sc)
{
	struct vio_msg_tag tag;

	tag.type = VIO_TYPE_CTRL;
	tag.stype = VIO_SUBTYPE_INFO;
	tag.stype_env = VIO_RDX;
	tag.sid = sc->sc_local_sid;
	vnet_sendmsg(sc, &tag, sizeof(tag));

	sc->sc_vio_state |= VIO_SND_RDX;
}

void
vnet_send_dring_data(struct vnet_softc *sc, uint32_t start_idx)
{
	struct vio_dring_msg dm;
	u_int peer_state;

	peer_state = atomic_swap_uint(&sc->sc_peer_state, VIO_DP_ACTIVE);
	if (peer_state == VIO_DP_ACTIVE)
		return;

	bzero(&dm, sizeof(dm));
	dm.tag.type = VIO_TYPE_DATA;
	dm.tag.stype = VIO_SUBTYPE_INFO;
	dm.tag.stype_env = VIO_DRING_DATA;
	dm.tag.sid = sc->sc_local_sid;
	dm.seq_no = sc->sc_seq_no++;
	dm.dring_ident = sc->sc_dring_ident;
	dm.start_idx = start_idx;
	dm.end_idx = -1;
	vnet_sendmsg(sc, &dm, sizeof(dm));
}

void
vnet_start(struct ifnet *ifp)
{
	struct vnet_softc *sc = ifp->if_softc;
	struct ldc_conn *lc = &sc->sc_lc;
	struct ldc_map *map = sc->sc_lm;
	struct mbuf *m;
	paddr_t pa;
	caddr_t buf;
	uint64_t tx_head, tx_tail, tx_state;
	u_int start, prod, count;
	int err;

	if (!(ifp->if_flags & IFF_RUNNING) || ifq_is_oactive(&ifp->if_snd))
		return;

	if (IFQ_IS_EMPTY(&ifp->if_snd))
		return;

	/*
	 * We cannot transmit packets until a VIO connection has been
	 * established.
	 */
	if (!ISSET(sc->sc_vio_state, VIO_RCV_RDX) ||
	    !ISSET(sc->sc_vio_state, VIO_ACK_RDX))
		return;

	/*
	 * Make sure there is room in the LDC transmit queue to send a
	 * DRING_DATA message.
	 */
	err = hv_ldc_tx_get_state(lc->lc_id, &tx_head, &tx_tail, &tx_state);
	if (err != H_EOK)
		return;
	tx_tail += sizeof(struct ldc_pkt);
	tx_tail &= ((lc->lc_txq->lq_nentries * sizeof(struct ldc_pkt)) - 1);
	if (tx_tail == tx_head) {
		ifq_set_oactive(&ifp->if_snd);
		return;
	}

	if (sc->sc_xfer_mode == VIO_DESC_MODE) {
		vnet_start_desc(ifp);
		return;
	}

	start = prod = sc->sc_tx_prod & (sc->sc_vd->vd_nentries - 1);
	while (sc->sc_vd->vd_desc[prod].hdr.dstate == VIO_DESC_FREE) {
		count = sc->sc_tx_prod - sc->sc_tx_cons;
		if (count >= (sc->sc_vd->vd_nentries - 1) ||
		    map->lm_count >= map->lm_nentries) {
			ifq_set_oactive(&ifp->if_snd);
			break;
		}

		buf = pool_get(&sc->sc_pool, PR_NOWAIT|PR_ZERO);
		if (buf == NULL) {
			ifq_set_oactive(&ifp->if_snd);
			break;
		}

		IFQ_DEQUEUE(&ifp->if_snd, m);
		if (m == NULL) {
			pool_put(&sc->sc_pool, buf);
			break;
		}

		m_copydata(m, 0, m->m_pkthdr.len, buf + VNET_ETHER_ALIGN);

#if NBPFILTER > 0
		/*
		 * If BPF is listening on this interface, let it see the
		 * packet before we commit it to the wire.
		 */
		if (ifp->if_bpf)
			bpf_mtap(ifp->if_bpf, m, BPF_DIRECTION_OUT);
#endif

		pmap_extract(pmap_kernel(), (vaddr_t)buf, &pa);
		KASSERT((pa & ~PAGE_MASK) == (pa & LDC_MTE_RA_MASK));
		while (map->lm_slot[map->lm_next].entry != 0) {
			map->lm_next++;
			map->lm_next &= (map->lm_nentries - 1);
		}
		map->lm_slot[map->lm_next].entry = (pa & LDC_MTE_RA_MASK);
		map->lm_slot[map->lm_next].entry |= LDC_MTE_CPR;
		atomic_inc_int(&map->lm_count);

		sc->sc_vd->vd_desc[prod].nbytes = max(m->m_pkthdr.len, 60);
		sc->sc_vd->vd_desc[prod].ncookies = 1;
		sc->sc_vd->vd_desc[prod].cookie[0].addr =
		    map->lm_next << PAGE_SHIFT | (pa & PAGE_MASK);
		sc->sc_vd->vd_desc[prod].cookie[0].size = 2048;
		membar_producer();
		sc->sc_vd->vd_desc[prod].hdr.dstate = VIO_DESC_READY;

		sc->sc_vsd[prod].vsd_map_idx = map->lm_next;
		sc->sc_vsd[prod].vsd_buf = buf;

		sc->sc_tx_prod++;
		prod = sc->sc_tx_prod & (sc->sc_vd->vd_nentries - 1);

		m_freem(m);
	}

	membar_producer();

	if (start != prod && sc->sc_peer_state != VIO_DP_ACTIVE) {
		vnet_send_dring_data(sc, start);
		ifp->if_timer = 5;
	}
}

void
vnet_start_desc(struct ifnet *ifp)
{
	struct vnet_softc *sc = ifp->if_softc;
	struct ldc_map *map = sc->sc_lm;
	struct vnet_desc_msg dm;
	struct mbuf *m;
	paddr_t pa;
	caddr_t buf;
	u_int prod, count;

	for (;;) {
		count = sc->sc_tx_prod - sc->sc_tx_cons;
		if (count >= (sc->sc_vd->vd_nentries - 1) ||
		    map->lm_count >= map->lm_nentries) {
			ifq_set_oactive(&ifp->if_snd);
			return;
		}

		buf = pool_get(&sc->sc_pool, PR_NOWAIT|PR_ZERO);
		if (buf == NULL) {
			ifq_set_oactive(&ifp->if_snd);
			return;
		}

		IFQ_DEQUEUE(&ifp->if_snd, m);
		if (m == NULL) {
			pool_put(&sc->sc_pool, buf);
			return;
		}

		m_copydata(m, 0, m->m_pkthdr.len, buf);

#if NBPFILTER > 0
		/*
		 * If BPF is listening on this interface, let it see the
		 * packet before we commit it to the wire.
		 */
		if (ifp->if_bpf)
			bpf_mtap(ifp->if_bpf, m, BPF_DIRECTION_OUT);
#endif

		pmap_extract(pmap_kernel(), (vaddr_t)buf, &pa);
		KASSERT((pa & ~PAGE_MASK) == (pa & LDC_MTE_RA_MASK));
		while (map->lm_slot[map->lm_next].entry != 0) {
			map->lm_next++;
			map->lm_next &= (map->lm_nentries - 1);
		}
		map->lm_slot[map->lm_next].entry = (pa & LDC_MTE_RA_MASK);
		map->lm_slot[map->lm_next].entry |= LDC_MTE_CPR;
		atomic_inc_int(&map->lm_count);

		prod = sc->sc_tx_prod & (sc->sc_vd->vd_nentries - 1);
		sc->sc_vsd[prod].vsd_map_idx = map->lm_next;
		sc->sc_vsd[prod].vsd_buf = buf;

		bzero(&dm, sizeof(dm));
		dm.tag.type = VIO_TYPE_DATA;
		dm.tag.stype = VIO_SUBTYPE_INFO;
		dm.tag.stype_env = VIO_DESC_DATA;
		dm.tag.sid = sc->sc_local_sid;
		dm.seq_no = sc->sc_seq_no++;
		dm.desc_handle = sc->sc_tx_prod;
		dm.nbytes = max(m->m_pkthdr.len, 60);
		dm.ncookies = 1;
		dm.cookie[0].addr =
			map->lm_next << PAGE_SHIFT | (pa & PAGE_MASK);
		dm.cookie[0].size = 2048;
		vnet_sendmsg(sc, &dm, sizeof(dm));

		sc->sc_tx_prod++;
		sc->sc_tx_prod &= (sc->sc_vd->vd_nentries - 1);

		m_freem(m);
	}
}

int
vnet_ioctl(struct ifnet *ifp, u_long cmd, caddr_t data)
{
	struct vnet_softc *sc = ifp->if_softc;
	struct ifreq *ifr = (struct ifreq *)data;
	int s, error = 0;

	s = splnet();

	switch (cmd) {
	case SIOCSIFADDR:
		ifp->if_flags |= IFF_UP;
		/* FALLTHROUGH */
	case SIOCSIFFLAGS:
		if (ifp->if_flags & IFF_UP) {
			if ((ifp->if_flags & IFF_RUNNING) == 0)
				vnet_init(ifp);
		} else {
			if (ifp->if_flags & IFF_RUNNING)
				vnet_stop(ifp);
		}
		break;

	case SIOCGIFMEDIA:
	case SIOCSIFMEDIA:
		error = ifmedia_ioctl(ifp, ifr, &sc->sc_media, cmd);
		break;

	case SIOCADDMULTI:
	case SIOCDELMULTI:
		/*
		 * XXX Removing all multicast addresses and adding
		 * most of them back, is somewhat retarded.
		 */
		vnet_setmulti(sc, 0);
		error = ether_ioctl(ifp, &sc->sc_ac, cmd, data);
		vnet_setmulti(sc, 1);
		if (error == ENETRESET)
			error = 0;
		break;

	default:
		error = ether_ioctl(ifp, &sc->sc_ac, cmd, data);
	}

	splx(s);
	return (error);
}

void
vnet_watchdog(struct ifnet *ifp)
{
	struct vnet_softc *sc = ifp->if_softc;

	printf("%s: watchdog timeout\n", sc->sc_dv.dv_xname);
}

int
vnet_media_change(struct ifnet *ifp)
{
	return (0);
}

void
vnet_media_status(struct ifnet *ifp, struct ifmediareq *imr)
{
	imr->ifm_active = IFM_ETHER | IFM_AUTO;
	imr->ifm_status = IFM_AVALID;

	if (LINK_STATE_IS_UP(ifp->if_link_state) &&
	    ifp->if_flags & IFF_UP)
		imr->ifm_status |= IFM_ACTIVE;
}

void
vnet_link_state(struct vnet_softc *sc)
{
	struct ifnet *ifp = &sc->sc_ac.ac_if;
	int link_state = LINK_STATE_DOWN;

	KERNEL_LOCK();
	if (ISSET(sc->sc_vio_state, VIO_RCV_RDX) &&
	    ISSET(sc->sc_vio_state, VIO_ACK_RDX))
		link_state = LINK_STATE_FULL_DUPLEX;
	if (ifp->if_link_state != link_state) {
		ifp->if_link_state = link_state;
		if_link_state_change(ifp);
	}
	KERNEL_UNLOCK();
}

void
vnet_setmulti(struct vnet_softc *sc, int set)
{
	struct arpcom *ac = &sc->sc_ac;
	struct ether_multi *enm;
	struct ether_multistep step;
	struct vnet_mcast_info mi;
	int count = 0;

	if (!ISSET(sc->sc_vio_state, VIO_RCV_RDX) ||
	    !ISSET(sc->sc_vio_state, VIO_ACK_RDX))
		return;

	bzero(&mi, sizeof(mi));
	mi.tag.type = VIO_TYPE_CTRL;
	mi.tag.stype = VIO_SUBTYPE_INFO;
	mi.tag.stype_env = VNET_MCAST_INFO;
	mi.tag.sid = sc->sc_local_sid;
	mi.set = set ? 1 : 0;
	KERNEL_LOCK();
	ETHER_FIRST_MULTI(step, ac, enm);
	while (enm != NULL) {
		/* XXX What about multicast ranges? */
		bcopy(enm->enm_addrlo, mi.mcast_addr[count], ETHER_ADDR_LEN);
		ETHER_NEXT_MULTI(step, enm);

		count++;
		if (count < VNET_NUM_MCAST)
			continue;

		mi.count = VNET_NUM_MCAST;
		vnet_sendmsg(sc, &mi, sizeof(mi));
		count = 0;
	}

	if (count > 0) {
		mi.count = count;
		vnet_sendmsg(sc, &mi, sizeof(mi));
	}
	KERNEL_UNLOCK();
}

void
vnet_init(struct ifnet *ifp)
{
	struct vnet_softc *sc = ifp->if_softc;
	struct ldc_conn *lc = &sc->sc_lc;
	int err;

	sc->sc_lm = ldc_map_alloc(sc->sc_dmatag, 2048);
	if (sc->sc_lm == NULL)
		return;

	err = hv_ldc_set_map_table(lc->lc_id,
	    sc->sc_lm->lm_map->dm_segs[0].ds_addr, sc->sc_lm->lm_nentries);
	if (err != H_EOK) {
		printf("hv_ldc_set_map_table %d\n", err);
		return;
	}

	sc->sc_vd = vnet_dring_alloc(sc->sc_dmatag, VNET_NUM_SOFT_DESC);
	if (sc->sc_vd == NULL)
		return;
	sc->sc_vsd = malloc(VNET_NUM_SOFT_DESC * sizeof(*sc->sc_vsd), M_DEVBUF,
	    M_NOWAIT|M_ZERO);
	if (sc->sc_vsd == NULL)
		return;

	sc->sc_lm->lm_slot[0].entry = sc->sc_vd->vd_map->dm_segs[0].ds_addr;
	sc->sc_lm->lm_slot[0].entry &= LDC_MTE_RA_MASK;
	sc->sc_lm->lm_slot[0].entry |= LDC_MTE_CPR | LDC_MTE_CPW;
	sc->sc_lm->lm_next = 1;
	sc->sc_lm->lm_count = 1;

	err = hv_ldc_tx_qconf(lc->lc_id,
	    lc->lc_txq->lq_map->dm_segs[0].ds_addr, lc->lc_txq->lq_nentries);
	if (err != H_EOK)
		printf("hv_ldc_tx_qconf %d\n", err);

	err = hv_ldc_rx_qconf(lc->lc_id,
	    lc->lc_rxq->lq_map->dm_segs[0].ds_addr, lc->lc_rxq->lq_nentries);
	if (err != H_EOK)
		printf("hv_ldc_rx_qconf %d\n", err);

	cbus_intr_setenabled(sc->sc_bustag, sc->sc_tx_ino, INTR_ENABLED);
	cbus_intr_setenabled(sc->sc_bustag, sc->sc_rx_ino, INTR_ENABLED);

	ldc_send_vers(lc);

	ifp->if_flags |= IFF_RUNNING;
}

void
vnet_stop(struct ifnet *ifp)
{
	struct vnet_softc *sc = ifp->if_softc;
	struct ldc_conn *lc = &sc->sc_lc;

	ifp->if_flags &= ~IFF_RUNNING;
	ifq_clr_oactive(&ifp->if_snd);
	ifp->if_timer = 0;

	cbus_intr_setenabled(sc->sc_bustag, sc->sc_tx_ino, INTR_DISABLED);
	cbus_intr_setenabled(sc->sc_bustag, sc->sc_rx_ino, INTR_DISABLED);

	intr_barrier(sc->sc_tx_ih);
	intr_barrier(sc->sc_rx_ih);

	hv_ldc_tx_qconf(lc->lc_id, 0, 0);
	hv_ldc_rx_qconf(lc->lc_id, 0, 0);
	lc->lc_tx_seqid = 0;
	lc->lc_state = 0;
	lc->lc_tx_state = lc->lc_rx_state = LDC_CHANNEL_DOWN;
	vnet_ldc_reset(lc);

	free(sc->sc_vsd, M_DEVBUF, VNET_NUM_SOFT_DESC * sizeof(*sc->sc_vsd));

	vnet_dring_free(sc->sc_dmatag, sc->sc_vd);

	hv_ldc_set_map_table(lc->lc_id, 0, 0);
	ldc_map_free(sc->sc_dmatag, sc->sc_lm);
}

struct vnet_dring *
vnet_dring_alloc(bus_dma_tag_t t, int nentries)
{
	struct vnet_dring *vd;
	bus_size_t size;
	caddr_t va;
	int nsegs;
	int i;

	vd = malloc(sizeof(struct vnet_dring), M_DEVBUF, M_NOWAIT);
	if (vd == NULL)
		return NULL;

	size = roundup(nentries * sizeof(struct vnet_desc), PAGE_SIZE);

	if (bus_dmamap_create(t, size, 1, size, 0,
	    BUS_DMA_NOWAIT | BUS_DMA_ALLOCNOW, &vd->vd_map) != 0)
		return (NULL);

	if (bus_dmamem_alloc(t, size, PAGE_SIZE, 0, &vd->vd_seg, 1,
	    &nsegs, BUS_DMA_NOWAIT) != 0)
		goto destroy;

	if (bus_dmamem_map(t, &vd->vd_seg, 1, size, &va,
	    BUS_DMA_NOWAIT) != 0)
		goto free;

	if (bus_dmamap_load(t, vd->vd_map, va, size, NULL,
	    BUS_DMA_NOWAIT) != 0)
		goto unmap;

	vd->vd_desc = (struct vnet_desc *)va;
	vd->vd_nentries = nentries;
	bzero(vd->vd_desc, nentries * sizeof(struct vnet_desc));
	for (i = 0; i < vd->vd_nentries; i++)
		vd->vd_desc[i].hdr.dstate = VIO_DESC_FREE;
	return (vd);

unmap:
	bus_dmamem_unmap(t, va, size);
free:
	bus_dmamem_free(t, &vd->vd_seg, 1);
destroy:
	bus_dmamap_destroy(t, vd->vd_map);

	return (NULL);
}

void
vnet_dring_free(bus_dma_tag_t t, struct vnet_dring *vd)
{
	bus_size_t size;

	size = vd->vd_nentries * sizeof(struct vnet_desc);
	size = roundup(size, PAGE_SIZE);

	bus_dmamap_unload(t, vd->vd_map);
	bus_dmamem_unmap(t, (caddr_t)vd->vd_desc, size);
	bus_dmamem_free(t, &vd->vd_seg, 1);
	bus_dmamap_destroy(t, vd->vd_map);
	free(vd, M_DEVBUF, 0);
}
@


1.57
log
@all pools have their ipl set via pool_setipl, so fold it into pool_init.

the ioff argument to pool_init() is unused and has been for many
years, so this replaces it with an ipl argument. because the ipl
will be set on init we no longer need pool_setipl.

most of these changes have been done with coccinelle using the spatch
below. cocci sucks at formatting code though, so i fixed that by hand.

the manpage and subr_pool.c bits i did myself.

ok tedu@@ jmatthew@@

@@ipl@@
expression pp;
expression ipl;
expression s, a, o, f, m, p;
@@@@
-pool_init(pp, s, a, o, f, m, p);
-pool_setipl(pp, ipl);
+pool_init(pp, s, a, ipl, f, m, p);
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.56 2016/04/13 11:34:00 mpi Exp $	*/
a765 1
		ifp->if_opackets++;
a878 1
			ifp->if_opackets++;
@


1.56
log
@G/C IFQ_SET_READY().
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.55 2016/03/21 00:18:54 stsp Exp $	*/
d307 1
a307 2
	pool_init(&sc->sc_pool, 2048, 0, 0, 0, sc->sc_dv.dv_xname, NULL);
	pool_setipl(&sc->sc_pool, IPL_NET);
@


1.55
log
@Plug a memory leak in vnet(4) ioctl code path.
ok kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.54 2016/02/26 13:41:51 kettenis Exp $	*/
a318 1
	IFQ_SET_READY(&ifp->if_snd);
@


1.54
log
@Prevent memory leak when the ldc gets reset.
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.53 2015/12/05 13:10:03 kettenis Exp $	*/
d172 1
d1403 1
a1403 1
	sc->sc_vd = vnet_dring_alloc(sc->sc_dmatag, 128);
d1406 1
a1406 1
	sc->sc_vsd = malloc(128 * sizeof(*sc->sc_vsd), M_DEVBUF,
d1457 2
@


1.53
log
@Avoid using ifq_deq_rollback().
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.52 2015/12/04 15:18:03 kettenis Exp $	*/
d766 1
d880 1
d931 5
a935 1
	for (i = 0; i < sc->sc_vd->vd_nentries; i++)
d937 1
d1405 2
a1406 1
	sc->sc_vsd = malloc(128 * sizeof(*sc->sc_vsd), M_DEVBUF, M_NOWAIT);
@


1.52
log
@Add intr_barrier() just in case...
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.51 2015/11/25 03:09:58 dlg Exp $	*/
a1101 4
		m = ifq_deq_begin(&ifp->if_snd);
		if (m == NULL)
			break;

a1104 1
			ifq_deq_rollback(&ifp->if_snd, m);
a1110 1
			ifq_deq_rollback(&ifp->if_snd, m);
d1114 7
a1121 1
		ifq_deq_commit(&ifp->if_snd, m);
a1178 4
		m = ifq_deq_begin(&ifp->if_snd);
		if (m == NULL)
			break;

a1181 1
			ifq_deq_rollback(&ifp->if_snd, m);
a1187 1
			ifq_deq_rollback(&ifp->if_snd, m);
d1191 7
a1198 1
		ifq_deq_commit(&ifp->if_snd, m);
@


1.51
log
@replace IFF_OACTIVE manipulation with mpsafe operations.

there are two things shared between the network stack and drivers
in the send path: the send queue and the IFF_OACTIVE flag. the send
queue is now protected by a mutex. this diff makes the oactive
functionality mpsafe too.

IFF_OACTIVE is part of if_flags. there are two problems with that.
firstly, if_flags is a short and we dont have any MI atomic operations
to manipulate a short. secondly, while we could make the IFF_OACTIVE
operates mpsafe, all changes to other flags would have to be made
safe at the same time, otherwise a read-modify-write cycle on their
updates could clobber the oactive change.

instead, this moves the oactive mark into struct ifqueue and provides
an API for changing it. there's ifq_set_oactive, ifq_clr_oactive,
and ifq_is_oactive. these are modelled on ifsq_set_oactive,
ifsq_clr_oactive, and ifsq_is_oactive in dragonflybsd.

this diff includes changes to all the drivers manipulating IFF_OACTIVE
to now use the ifsq_{set,clr_is}_oactive API too.

ok kettenis@@ mpi@@ jmatthew@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.50 2015/11/24 17:11:38 mpi Exp $	*/
d1438 3
@


1.50
log
@You only need <net/if_dl.h> if you're using LLADDR() or a sockaddr_dl.
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.49 2015/11/24 13:33:18 mpi Exp $	*/
d663 1
a663 1
		ifp->if_flags &= ~IFF_OACTIVE;
d892 1
a892 1
			ifp->if_flags &= ~IFF_OACTIVE;
d1067 1
a1067 1
	if ((ifp->if_flags & (IFF_RUNNING | IFF_OACTIVE)) != IFF_RUNNING)
d1091 1
a1091 1
		ifp->if_flags |= IFF_OACTIVE;
d1110 1
a1110 1
			ifp->if_flags |= IFF_OACTIVE;
d1117 1
a1117 1
			ifp->if_flags |= IFF_OACTIVE;
d1187 1
a1187 1
			ifp->if_flags |= IFF_OACTIVE;
d1194 1
a1194 1
			ifp->if_flags |= IFF_OACTIVE;
d1432 2
a1433 1
	ifp->if_flags &= ~(IFF_RUNNING | IFF_OACTIVE);
@


1.49
log
@The only network driver needing <net/if_types.h> is upl(4) for IFT_OTHER.
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.48 2015/11/20 03:35:22 dlg Exp $	*/
a35 1
#include <net/if_dl.h>
@


1.48
log
@shuffle struct ifqueue so in flight mbufs are protected by a mutex.

the code is refactored so the IFQ macros call newly implemented ifq
functions. the ifq code is split so each discipline (priq and hfsc
in our case) is an opaque set of operations that the common ifq
code can call. the common code does the locking, accounting (ifq_len
manipulation), and freeing of the mbuf if the disciplines enqueue
function rejects it. theyre kind of like bufqs in the block layer
with their fifo and nscan disciplines.

the new api also supports atomic switching of disciplines at runtime.
the hfsc setup in pf_ioctl.c has been tweaked to build a complete
hfsc_if structure which it attaches to the send queue in a single
operation, rather than attaching to the interface up front and
building up a list of queues.

the send queue is now mutexed, which raises the expectation that
packets can be enqueued or purged on one cpu while another cpu is
dequeueing them in a driver for transmission. a lot of drivers use
IFQ_POLL to peek at an mbuf and attempt to fit it on the ring before
committing to it with a later IFQ_DEQUEUE operation. if the mbuf
gets freed in between the POLL and DEQUEUE operations, fireworks
will ensue.

to avoid this, the ifq api introduces ifq_deq_begin, ifq_deq_rollback,
and ifq_deq_commit. ifq_deq_begin allows a driver to take the ifq
mutex and get a reference to the mbuf they wish to try and tx. if
there's space, they can ifq_deq_commit it to remove the mbuf and
release the mutex. if there's no space, ifq_deq_rollback simply
releases the mutex. this api was developed to make updating the
drivers using IFQ_POLL easy, instead of having to do significant
semantic changes to avoid POLL that we cannot test on all the
hardware.

the common code has been tested pretty hard, and all the driver
modifications are straightforward except for de(4). if that breaks
it can be dealt with later.

ok mpi@@ jmatthew@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.47 2015/10/25 13:22:09 mpi Exp $	*/
a37 1
#include <net/if_types.h>
@


1.47
log
@arp_ifinit() is no longer needed.
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.46 2015/06/24 09:40:53 mpi Exp $	*/
d1104 1
a1104 1
		IFQ_POLL(&ifp->if_snd, m);
d1111 1
d1118 1
d1123 1
a1123 1
		IFQ_DEQUEUE(&ifp->if_snd, m);
d1181 1
a1181 1
		IFQ_POLL(&ifp->if_snd, m);
d1188 1
d1195 1
d1200 1
a1200 1
		IFQ_DEQUEUE(&ifp->if_snd, m);
@


1.46
log
@Increment if_ipackets in if_input().

Note that pseudo-drivers not using if_input() are not affected by this
conversion.

ok mikeb@@, kettenis@@, claudio@@, dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.45 2015/06/21 20:04:30 kettenis Exp $	*/
a1245 1
	struct ifaddr *ifa = (struct ifaddr *)data;
a1253 2
		if (ifa->ifa_addr->sa_family == AF_INET)
			arp_ifinit(&sc->sc_ac, ifa);
@


1.45
log
@Count transmitted packets.
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.44 2015/04/13 08:45:48 mpi Exp $	*/
a743 2
		ifp->if_ipackets++;

a826 1
			ifp->if_ipackets++;
@


1.44
log
@Now that if_input() set the receiving interface pointer on mbufs for us
there's no need to do it in m_devget(9).

Stop passing an ``ifp'' will help for upcoming interface pointer -> index
conversion.

While here remove unused ``ifp'' argument from m_clget(9) and kill two
birds^W layer violations in one commit.

ok henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.43 2015/04/02 09:46:48 kettenis Exp $	*/
d770 1
d884 1
@


1.43
log
@Call if_input() without grabbing the kernel lock first.
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.42 2015/04/01 15:23:32 kettenis Exp $	*/
d737 1
a737 1
                m = m_devget(buf, dm->nbytes, ETHER_ALIGN, ifp);
@


1.42
log
@Run most of the interrupt handler without holding the kernel lock.
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.41 2015/03/29 14:08:25 kettenis Exp $	*/
a747 1
		KERNEL_LOCK();
a748 1
		KERNEL_UNLOCK();
a855 1
		KERNEL_LOCK();
a856 1
		KERNEL_UNLOCK();
@


1.41
log
@Reject packets that are too large.
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.40 2015/03/21 18:11:18 kettenis Exp $	*/
d269 2
a270 1
	    IPL_NET, 0, vnet_tx_intr, sc, sc->sc_dv.dv_xname);
d272 2
a273 1
	    IPL_NET, 0, vnet_rx_intr, sc, sc->sc_dv.dv_xname);
d664 1
d667 1
d748 1
d750 1
a750 1

d858 1
d860 1
d897 1
d904 1
d1330 1
d1338 1
d1360 1
d1380 1
@


1.40
log
@Make sure we reset all relevant state when resetting or stopping an interface.
Our reset function did not reset the ring and LDC map and our stop function
did not reset the LDC channel state and the some of the ring state.  Also
make sure we clear IFF_OACTIVE whenever we re-establish a connection on the
LDC channel.  Finally, initialize the link state to LINK_STATE_DOWN such
that interfaces that have not been configured yet, don't show up as active.

This should improve the reliability of re-establishing network connections
between domains after some sort of hickup considerably.
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.39 2015/03/10 09:26:24 mpi Exp $	*/
d718 5
d816 5
@


1.39
log
@Convert to if_input(), tested an ok kettenis@@.
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.38 2015/02/11 04:15:50 kettenis Exp $	*/
d312 1
d394 1
d661 2
d904 1
d911 8
a1406 1
	ifp->if_flags &= ~IFF_OACTIVE;
d1423 2
d1426 1
@


1.38
log
@Eliminate sc_tx_cnt.  Instead use an unsigned integer for sc_tx_prod and
sc_tx_cont and let them wrap around.  Make sure we don't fill the last
descriptor on the ring such that we don't confuse a completely filled ring
with a completely empty one.  Also make sure we don't post the same
descriptors twice.
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.37 2015/01/25 21:42:13 kettenis Exp $	*/
d697 1
d733 3
a735 4
#if NBPFILTER > 0
		if (ifp->if_bpf)
			bpf_mtap(ifp->if_bpf, m, BPF_DIRECTION_IN);
#endif /* NBPFILTER > 0 */
a736 2
		/* Pass it on. */
		ether_input_mbuf(ifp, m);
d790 1
a811 1
			m->m_pkthdr.rcvif = ifp;
d824 1
a824 7
#if NBPFILTER > 0
			if (ifp->if_bpf)
				bpf_mtap(ifp->if_bpf, m, BPF_DIRECTION_IN);
#endif /* NBPFILTER > 0 */

			/* Pass it on. */
			ether_input_mbuf(ifp, m);
d838 2
@


1.37
log
@Rework cbus(4) interrupt support a bit.  Instead of merging devhandle and
devino into a pseudo-sysino, directly use the devino as the ihandle.  The
devhandle is stored in the cbus softc, and accessed through the bus space
tag.  This allows us to have more than 256 interrupts on a single cbus, and
avoids relying on the lower bits of the devhandle being zero.
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.36 2014/12/22 02:26:54 tedu Exp $	*/
d3 1
a3 1
 * Copyright (c) 2009 Mark Kettenis
d21 1
d166 2
a167 3
	int		sc_tx_cnt;
	int		sc_tx_prod;
	int		sc_tx_cons;
d169 1
a169 1
	uint8_t		sc_peer_state;
d285 1
d307 1
d701 1
d754 1
a754 2
		map->lm_slot[sc->sc_vsd[sc->sc_tx_cons].vsd_map_idx].entry = 0;
		map->lm_count--;
d756 4
a759 1
		pool_put(&sc->sc_pool, sc->sc_vsd[sc->sc_tx_cons].vsd_buf);
a761 2
		sc->sc_tx_cons &= (sc->sc_vd->vd_nentries - 1);
		sc->sc_tx_cnt--;
d862 1
a862 1
		int cons;
d866 1
a866 1
		cons = sc->sc_tx_cons;
d869 1
a869 1
			map->lm_count--;
d873 3
a875 3
			sc->sc_vd->vd_desc[cons++].hdr.dstate = VIO_DESC_FREE;
			cons &= (sc->sc_vd->vd_nentries - 1);
			sc->sc_tx_cnt--;
a876 1
		sc->sc_tx_cons = cons;
d878 3
a880 2
		if (sc->sc_tx_cnt > 0 && sc->sc_peer_state != VIO_DP_ACTIVE)
			vnet_send_dring_data(sc, sc->sc_tx_cons);
d882 1
a882 1
		if (sc->sc_tx_cnt < sc->sc_vd->vd_nentries)
d884 1
a884 1
		if (sc->sc_tx_cnt == 0)
d893 1
d908 2
a909 1
	sc->sc_tx_cnt = sc->sc_tx_prod = sc->sc_tx_cons = 0;
d1017 5
a1032 2

	sc->sc_peer_state = VIO_DP_ACTIVE;
d1045 2
a1046 1
	int err, desc;
d1081 2
a1082 2
	desc = sc->sc_tx_prod;
	while (sc->sc_vd->vd_desc[desc].hdr.dstate == VIO_DESC_FREE) {
d1087 2
a1088 1
		if (sc->sc_tx_cnt >= sc->sc_vd->vd_nentries ||
d1119 1
a1119 1
		map->lm_count++;
d1121 3
a1123 3
		sc->sc_vd->vd_desc[desc].nbytes = max(m->m_pkthdr.len, 60);
		sc->sc_vd->vd_desc[desc].ncookies = 1;
		sc->sc_vd->vd_desc[desc].cookie[0].addr =
d1125 9
a1133 10
		sc->sc_vd->vd_desc[desc].cookie[0].size = 2048;
		membar(Sync);
		sc->sc_vd->vd_desc[desc].hdr.dstate = VIO_DESC_READY;

		sc->sc_vsd[desc].vsd_map_idx = map->lm_next;
		sc->sc_vsd[desc].vsd_buf = buf;

		desc++;
		desc &= (sc->sc_vd->vd_nentries - 1);
		sc->sc_tx_cnt++;
d1138 4
a1141 2
	if (sc->sc_tx_cnt > 0 && sc->sc_peer_state != VIO_DP_ACTIVE) {
		vnet_send_dring_data(sc, sc->sc_tx_prod);
a1143 2

	sc->sc_tx_prod = desc;
d1155 1
d1162 2
a1163 1
		if (sc->sc_tx_cnt >= sc->sc_vd->vd_nentries ||
d1194 1
a1194 1
		map->lm_count++;
d1196 3
a1198 2
		sc->sc_vsd[sc->sc_tx_prod].vsd_map_idx = map->lm_next;
		sc->sc_vsd[sc->sc_tx_prod].vsd_buf = buf;
a1215 1
		sc->sc_tx_cnt++;
@


1.36
log
@unifdef INET
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.35 2014/09/15 08:16:21 kettenis Exp $	*/
d136 2
a137 2
	uint64_t	sc_tx_sysino;
	uint64_t	sc_rx_sysino;
d256 2
d259 1
a259 6
	if (cbus_intr_map(ca->ca_node, ca->ca_tx_ino, &sc->sc_tx_sysino) ||
	    cbus_intr_map(ca->ca_node, ca->ca_rx_ino, &sc->sc_rx_sysino)) {
		printf(": can't map interrupt\n");
		return;
	}
	printf(": ivec 0x%llx, 0x%llx", sc->sc_tx_sysino, sc->sc_rx_sysino);
d268 1
a268 1
	sc->sc_tx_ih = bus_intr_establish(ca->ca_bustag, sc->sc_tx_sysino,
d270 1
a270 1
	sc->sc_rx_ih = bus_intr_establish(ca->ca_bustag, sc->sc_rx_sysino,
d1383 2
a1384 2
	cbus_intr_setenabled(sc->sc_tx_sysino, INTR_ENABLED);
	cbus_intr_setenabled(sc->sc_rx_sysino, INTR_ENABLED);
d1401 2
a1402 2
	cbus_intr_setenabled(sc->sc_tx_sysino, INTR_DISABLED);
	cbus_intr_setenabled(sc->sc_rx_sysino, INTR_DISABLED);
@


1.35
log
@Call ldc_send_unreliable() insteaf of duplicating the code to send an ldc
packet.  Rename vio_sendmsg() to vnet_sendmsg().
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.34 2014/08/18 13:29:13 dlg Exp $	*/
a1225 1
#ifdef INET
a1227 1
#endif
@


1.34
log
@this uses pools, but relied on mbuf.h to provide them.

found by benoit@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.33 2014/07/12 18:44:43 tedu Exp $	*/
d213 1
a213 1
void	vio_sendmsg(struct vnet_softc *, void *, size_t);
d505 1
a505 1
			vio_sendmsg(sc, vi, sizeof(*vi));
d513 1
a513 1
			vio_sendmsg(sc, vi, sizeof(*vi));
d520 1
a520 1
		vio_sendmsg(sc, vi, sizeof(*vi));
d555 1
a555 1
		vio_sendmsg(sc, ai, sizeof(*ai));
d597 1
a597 1
		vio_sendmsg(sc, dr, sizeof(*dr));
d635 1
a635 1
		vio_sendmsg(sc, tag, sizeof(*tag));
d743 1
a743 1
		vio_sendmsg(sc, dm, sizeof(*dm));
d855 1
a855 1
		vio_sendmsg(sc, dm, sizeof(*dm));
d922 1
a922 1
vio_sendmsg(struct vnet_softc *sc, void *msg, size_t len)
a924 2
	struct ldc_pkt *lp;
	uint64_t tx_head, tx_tail, tx_state;
d927 3
a929 18
	err = hv_ldc_tx_get_state(lc->lc_id, &tx_head, &tx_tail, &tx_state);
	if (err != H_EOK)
		return;

	lp = (struct ldc_pkt *)(lc->lc_txq->lq_va + tx_tail);
	bzero(lp, sizeof(struct ldc_pkt));
	lp->type = LDC_DATA;
	lp->stype = LDC_INFO;
	KASSERT((len & ~LDC_LEN_MASK) == 0);
	lp->env = len | LDC_FRAG_STOP | LDC_FRAG_START;
	lp->seqid = lc->lc_tx_seqid++;
	bcopy(msg, &lp->major, len);

	tx_tail += sizeof(*lp);
	tx_tail &= ((lc->lc_txq->lq_nentries * sizeof(*lp)) - 1);
	err = hv_ldc_tx_set_qtail(lc->lc_id, tx_tail);
	if (err != H_EOK)
		printf("%s: hv_ldc_tx_set_qtail: %d\n", __func__, err);
d945 1
a945 1
	vio_sendmsg(sc, &vi, sizeof(vi));
d970 1
a970 1
	vio_sendmsg(sc, &ai, sizeof(ai));
d992 1
a992 1
	vio_sendmsg(sc, &dr, sizeof(dr));
d1006 1
a1006 1
	vio_sendmsg(sc, &tag, sizeof(tag));
d1025 1
a1025 1
	vio_sendmsg(sc, &dm, sizeof(dm));
d1203 1
a1203 1
		vio_sendmsg(sc, &dm, sizeof(dm));
d1337 1
a1337 1
		vio_sendmsg(sc, &mi, sizeof(mi));
d1343 1
a1343 1
		vio_sendmsg(sc, &mi, sizeof(mi));
@


1.33
log
@add a size argument to free. will be used soon, but for now default to 0.
after discussions with beck deraadt kettenis.
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.32 2014/07/08 02:59:51 dlg Exp $	*/
d23 1
@


1.32
log
@the way vnet works means mclgeti cant do its job. remove hte ifp
argument to MCLGETI to make that clear.
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.31 2014/05/10 11:49:31 kettenis Exp $	*/
d1495 1
a1495 1
	free(vd, M_DEVBUF);
@


1.31
log
@Some straightforward format string fixes.  Also, print both the tx and rx
interrupt vector numbers instead of printing rx; pointed out by florian@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.30 2014/04/03 09:15:06 mpi Exp $	*/
d808 1
a808 2
			m = MCLGETI(NULL, M_DONTWAIT, &sc->sc_ac.ac_if,
			    MCLBYTES);
@


1.30
log
@Use <uvm/uvm_extern.h> if it's enough.
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.29 2013/08/21 05:21:42 dlg Exp $	*/
d261 1
a261 1
	printf(": ivec 0x%lx, 0x%lx", sc->sc_tx_sysino, sc->sc_rx_sysino);
@


1.29
log
@get rid of the copy argument in m_devget that let you provide an
alternative to bcopy since noone uses it.

while there use memcpy instead of bcopy because we know the memory cannot
overlap.

ok henning@@ matthew@@ mikeb@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.28 2012/12/07 21:56:06 kettenis Exp $	*/
d45 1
a45 1
#include <uvm/uvm.h>
@


1.28
log
@Use a timeout to do a delayed handshake if the receive queue of the LDC
channel transitions into the "up" state.
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.27 2012/11/24 23:06:16 kettenis Exp $	*/
d722 1
a722 1
                m = m_devget(buf, dm->nbytes, ETHER_ALIGN, ifp, NULL);
@


1.27
log
@Do not assign the "host" MAC address to virtual switch ports.  Don't print the
address for those ports either.
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.26 2012/10/26 20:57:08 kettenis Exp $	*/
d27 1
d156 2
d197 1
d286 2
d386 1
d399 3
d432 8
d906 1
d917 1
@


1.26
log
@Turns out that for devices that attach to cbus(4), it is better to disable
interrupts up-front and explicitly enabling them later than the other way
around.
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.25 2010/04/15 19:47:32 kettenis Exp $	*/
a49 3
/* XXX the following declaration should be elsewhere */
extern void myetheraddr(u_char *);

a251 4
	if (OF_getprop(ca->ca_node, "local-mac-address", sc->sc_ac.ac_enaddr,
	    ETHER_ADDR_LEN) <= 0)
		myetheraddr(sc->sc_ac.ac_enaddr);

d294 4
d320 1
a320 1
	printf(", address %s\n", ether_sprintf(sc->sc_ac.ac_enaddr));
@


1.25
log
@Print both the tx and the rx interrup vector numbers instead of the tx number
twice.

From Ted Patterson.
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.24 2010/02/21 14:48:42 kettenis Exp $	*/
a280 8

	/*
	 * Disable interrupts while we have no queues allocated.
	 * Otherwise we may end up with an interrupt storm as soon as
	 * our peer places a packet in their transmit queue.
	 */
	cbus_intr_setenabled(sc->sc_tx_sysino, INTR_DISABLED);
	cbus_intr_setenabled(sc->sc_rx_sysino, INTR_DISABLED);
@


1.24
log
@Make sure we only request our peer to start processing descriptors if it
isn't currently doing so.  Fixes hangs on large data transfers.
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.23 2010/02/21 12:01:42 kettenis Exp $	*/
d264 1
a264 1
	printf(": ivec 0x%lx, 0x%lx", sc->sc_tx_sysino, sc->sc_tx_sysino);
@


1.23
log
@Start and stop watchdog timer in the appropriate places, and print a message
if it fires.
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.22 2009/12/26 18:54:56 kettenis Exp $	*/
d168 2
d216 1
d857 2
d872 3
d1020 19
a1043 1
	struct vio_dring_msg dm;
d1140 2
a1141 12
	if (desc != sc->sc_tx_prod) {
		bzero(&dm, sizeof(dm));
		dm.tag.type = VIO_TYPE_DATA;
		dm.tag.stype = VIO_SUBTYPE_INFO;
		dm.tag.stype_env = VIO_DRING_DATA;
		dm.tag.sid = sc->sc_local_sid;
		dm.seq_no = sc->sc_seq_no++;
		dm.dring_ident = sc->sc_dring_ident;
		dm.start_idx = sc->sc_tx_prod;
		dm.end_idx = -1;
		vio_sendmsg(sc, &dm, sizeof(dm));

@


1.22
log
@Remove unused variable.
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.21 2009/12/14 22:38:03 kettenis Exp $	*/
d869 2
d1125 2
d1262 3
d1396 1
@


1.21
log
@Sanitize the code that resets the state when the LDC channel link state
changes.  Don't initiate the handshake when the LDC channel link state comes
up, to avoid a race where both sides initiate the handshake simultaniously,
which leads to a guaranteed failure.  Instead rely on the handshake done as
a result of ifconfig up on the interface to succeed.  Some retry logic may
be needed there...

This makes it possible to run OpenBSD (diskless) in a guest domain on a
machine running OpenBSD in its control domain.
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.20 2009/12/14 21:08:45 kettenis Exp $	*/
a367 1
	uint64_t *msg;
a399 1
	msg = (uint64_t *)(lc->lc_rxq->lq_va + rx_head);
@


1.20
log
@Fix previous commit.  I left out a small fragment and accidentally committed
a change we're not readdy for yet.
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.19 2009/12/14 20:50:46 kettenis Exp $	*/
a379 4
		sc->sc_tx_cnt = sc->sc_tx_prod = sc->sc_tx_cons = 0;
		sc->sc_vio_state = 0;
		lc->lc_tx_seqid = 0;
		lc->lc_state = 0;
d383 3
a388 1
			ldc_send_vers(lc);
d392 3
d891 1
@


1.19
log
@Support for in-band descriptor mode (VIO_DESC_MODE) used by OBP.
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.18 2009/12/14 20:01:11 kettenis Exp $	*/
d961 1
a961 1
	ai.ack_freq = 1;
d1047 5
@


1.18
log
@Make sure interrupts are disabled when we don't have queues configured.  This
prevents interrupt storms I'm hitting when running OpenBSD as a control domain.
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.17 2009/08/09 11:40:58 deraadt Exp $	*/
d96 9
d157 2
a158 1
#define VIO_ESTABLISHED		0x0fff
d203 1
d216 1
d541 1
d564 6
a569 2
	    ISSET(sc->sc_vio_state, VIO_ACK_ATTR_INFO))
		vnet_send_dring_reg(sc);
d643 2
a644 1
	if (sc->sc_vio_state == VIO_ESTABLISHED) {
d659 2
a660 1
	if (sc->sc_vio_state != VIO_ESTABLISHED) {
d667 4
d682 83
d961 1
a961 1
	ai.ack_freq = 0;
d1032 2
a1033 1
	if (sc->sc_vio_state != VIO_ESTABLISHED)
d1123 73
d1278 2
a1279 1
	if (sc->sc_vio_state == VIO_ESTABLISHED)
d1296 2
a1297 1
	if (sc->sc_vio_state != VIO_ESTABLISHED)
@


1.17
log
@MCLGETI() will now allocate a mbuf header if it is not provided, thus
reducing the amount of splnet/splx dancing required.. especially in the
worst case (of m_cldrop)
ok dlg kettenis damien
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.16 2009/05/12 21:33:38 kettenis Exp $	*/
d128 2
a235 1
	uint64_t sysino[2];
d244 2
a245 2
	if (cbus_intr_map(ca->ca_node, ca->ca_tx_ino, &sysino[0]) ||
	    cbus_intr_map(ca->ca_node, ca->ca_rx_ino, &sysino[1])) {
d249 1
a249 1
	printf(": ivec 0x%lx, 0x%lx", sysino[0], sysino[1]);
d258 4
a261 4
	sc->sc_tx_ih = bus_intr_establish(ca->ca_bustag, sysino[0], IPL_NET,
	    0, vnet_tx_intr, sc, sc->sc_dv.dv_xname);
	sc->sc_rx_ih = bus_intr_establish(ca->ca_bustag, sysino[1], IPL_NET,
	    0, vnet_rx_intr, sc, sc->sc_dv.dv_xname);
d267 8
d1186 3
d1202 3
@


1.16
log
@Don't throw away ldc packets if the ldc link went just up, otherwise we may
miss the initial handshake from OBP.
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.15 2009/05/12 21:13:37 kettenis Exp $	*/
d684 3
a686 2
			MGETHDR(m, M_DONTWAIT, MT_DATA);
			if(m == NULL)
a687 5
			MCLGETI(m, M_DONTWAIT, &sc->sc_ac.ac_if, MCLBYTES);
			if ((m->m_flags & M_EXT) == 0) {
				m_freem(m);
				break;
			}
@


1.15
log
@Add padding to ATTR_INFO message structure; OBP seems to insist on it
being there.
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.14 2009/05/10 12:59:12 kettenis Exp $	*/
a375 1
		hv_ldc_rx_set_qhead(lc->lc_id, rx_tail);
@


1.14
log
@Remove a dead variable and some unneeded returns.
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.13 2009/02/20 17:50:22 kettenis Exp $	*/
d67 1
a67 1
	uint32_t		_reserved;
d70 1
@


1.13
log
@Make sure we have enough space in the LDC transmit queue to send a DRING_DATA
message and bail out early instead of dropping packets to be transmitted.
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.12 2009/01/17 22:18:14 kettenis Exp $	*/
a310 1
	return;
@


1.12
log
@Clean things up a bit, and be a bit more fussy about the proper sequence in
which we should receive messages from our peer.
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.11 2009/01/17 20:18:16 kettenis Exp $	*/
d817 1
a817 1
		printf("hv_ldc_tx_set_qtail: %d\n", err);
d903 1
d909 2
a910 1
	int desc;
d924 14
@


1.11
log
@Sync vio_sendmsg() with equivalent code in vdsk(4).
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.10 2009/01/16 16:51:30 kettenis Exp $	*/
d132 14
a145 10
	uint8_t		sc_vio_state;
#define VIO_ACK_VER_INFO	0x01
#define VIO_RCV_VER_INFO	0x02
#define VIO_ACK_ATTR_INFO	0x04
#define VIO_RCV_ATTR_INFO	0x08
#define VIO_ACK_DRING_REG	0x10
#define VIO_RCV_DRING_REG	0x20
#define VIO_ACK_RDX		0x40
#define VIO_RCV_RDX		0x80
#define VIO_ESTABLISHED		0xff
a380 10
#if 0
{
	int i;

	printf("%s: rx intr, head %lx, tail %lx\n", sc->sc_dv.dv_xname,
	    rx_head, rx_tail);
	for (i = 0; i < 8; i++)
		printf("word %d: 0x%016lx\n", i, msg[i]);
}
#endif
d496 4
d530 4
d568 4
d606 4
a701 10
#if 0
				printf("hv_ldc_copy_in data %d\n", err);
				printf("start_idx %d, end_idx %d, idx %d\n",
				    dm->start_idx, dm->end_idx, idx);
				printf("nbytes %d ncookies %d\n",
				    desc.nbytes, desc.ncookies);
				printf("cookie 0x%llx, size %lld\n",
				    desc.cookie[0].addr, desc.cookie[0].size);
				printf("pa 0x%llx\n", pa);
#endif
d834 2
d859 2
d881 2
d895 2
a957 3
		/* Don't take slot 0; it's used by our descriptor ring. */
		if (map->lm_next == 0)
			map->lm_next++;
@


1.10
log
@Improve VIO state machine, and initiate VIO handshake ourselves.  Makes this
work with newer versions of Solaris.
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.9 2009/01/12 19:10:52 kettenis Exp $	*/
a799 3
#if 0
	printf("%s\n", __func__);
#endif
d808 2
a809 1
	lp->env = 56 | LDC_FRAG_STOP | LDC_FRAG_START;
a811 10

#if 0
{
	uint64_t *p = (uint64_t *)(sc->sc_txq->lq_va + tx_tail);
	int i;

	for (i = 0; i < 8; i++)
		printf("word %d: 0x%016lx\n", i, p[i]);
}
#endif
@


1.9
log
@As recommended by the Sun Virtual IO specification, use tick() to generate
session ID instead of arc4random().
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.8 2009/01/11 15:06:52 kettenis Exp $	*/
d133 9
a141 1
#define VIO_ESTABLISHED	8
d188 2
a189 1
void	vnet_reset(struct ldc_conn *);
d192 1
a192 1
void	vio_send_ver_info(struct vnet_softc *, uint16_t, uint16_t);
d264 2
a265 1
	lc->lc_reset = vnet_reset;
a492 3
		/* Allocate new session ID. */
		sc->sc_local_sid = tick();

d497 1
a497 2

		vio_send_ver_info(sc, VNET_MAJOR, VNET_MINOR);
d502 1
d509 4
d527 1
a527 2

		vnet_send_attr_info(sc);
d532 1
d539 4
d561 1
a561 2

		vnet_send_dring_reg(sc);
d570 1
a570 1
		vio_send_rdx(sc);
d577 4
d595 1
d600 7
d608 1
a609 1
		sc->sc_vio_state = VIO_ESTABLISHED;
a614 5
		break;

	default:
		DPRINTF(("CTRL/0x%02x/RDX (VIO)\n", tag->stype));
		break;
d776 1
a776 1
vnet_reset(struct ldc_conn *lc)
d785 8
d833 1
a833 1
vio_send_ver_info(struct vnet_softc *sc, uint16_t major, uint16_t minor)
@


1.8
log
@Fix pasto in debug message.
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.7 2009/01/10 20:32:37 kettenis Exp $	*/
a45 2
#include <dev/rndvar.h>

d484 1
a484 1
		sc->sc_local_sid = arc4random();
@


1.7
log
@Split off VIO definitions into their own file.
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.6 2009/01/10 17:13:28 kettenis Exp $	*/
d527 1
a527 1
		DPRINTF(("CTRL/0x%02x/VER_INFO\n", ai->tag.stype));
@


1.6
log
@Split off LDC support code into its own file.
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.5 2009/01/10 14:23:59 kettenis Exp $	*/
d50 1
a63 25
struct vio_msg_tag {
	uint8_t		type;
	uint8_t		stype;
	uint16_t	stype_env;
	uint32_t	sid;
};

struct vio_msg {
	uint64_t 	ldc;
	uint8_t		type;
	uint8_t		stype;
	uint16_t	stype_env;
	uint32_t	sid;
	uint16_t	major;
	uint16_t	minor;
	uint8_t		dev_class;
};

struct vio_ver_info {
	struct vio_msg_tag	tag;
	uint16_t		major;
	uint16_t		minor;
	uint8_t			dev_class;
};

d74 7
a80 10
struct vio_dring_reg {
	struct vio_msg_tag	tag;
	uint64_t		dring_ident;
	uint32_t		num_descriptors;
	uint32_t		descriptor_size;
	uint16_t		options;
	uint16_t		_reserved;
	uint32_t		ncookies;
	struct ldc_cookie	cookie[1];
};
d86 1
a86 1
	uint8_t			mcast_addr[7][ETHER_ADDR_LEN];
a89 60
#define VNET_NUM_MCAST		7

#define VIO_TYPE_CTRL		0x01
#define VIO_TYPE_DATA		0x02
#define VIO_TYPE_ERR		0x04

#define VIO_SUBTYPE_INFO	0x01
#define VIO_SUBTYPE_ACK		0x02
#define VIO_SUBTYPE_NACK	0x04

#define VIO_VER_INFO		0x0001
#define VIO_ATTR_INFO		0x0002
#define VIO_DRING_REG		0x0003
#define VIO_DRING_UNREG		0x0004
#define VIO_RDX			0x0005

#define VIO_PKT_DATA		0x0040
#define VIO_DESC_DATA		0x0041
#define VIO_DRING_DATA		0x0042

#define VNET_MCAST_INFO		0x0101

#define VDEV_NETWORK		0x01
#define VDEV_NETWORK_SWITCH	0x02
#define VDEV_DISK		0x03
#define VDEV_DISK_SERVER	0x04

#define VIO_TX_RING		0x0001
#define VIO_RX_RING		0x0002

#define VIO_PKT_MODE		0x01
#define VIO_DESC_MODE		0x02
#define VIO_DRING_MODE		0x03

#define VNET_ADDR_ETHERMAC	0x01

struct vnet_dring_msg {
	struct vio_msg_tag	tag;
	uint64_t		seq_no;
	uint64_t		dring_ident;
	uint32_t		start_idx;
	uint32_t		end_idx;
	uint8_t			proc_state;
	uint8_t			_reserved[7];
};

#define VIO_DP_ACTIVE	0x01
#define VIO_DP_STOPPED	0x02

struct vio_dring_hdr {
	uint8_t		dstate;
	uint8_t		ack: 1;
	uint16_t	_reserved[3];
};

#define VIO_DESC_FREE		0x01
#define VIO_DESC_READY		0x02
#define VIO_DESC_ACCEPTED	0x03
#define VIO_DESC_DONE		0x04

d624 1
a624 1
	struct vnet_dring_msg *dm = (struct vnet_dring_msg *)tag;
d881 1
a881 1
	struct vnet_dring_msg dm;
@


1.5
log
@Add multicast support.  Doesn't handle multicast ranges yet, but inet6 seems
to work fine.
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.4 2009/01/07 21:12:35 kettenis Exp $	*/
d49 1
a59 77
struct ldc_msg {
	uint8_t type;
	uint8_t stype;
	uint8_t ctrl;
	uint8_t env;
	uint32_t seqid;

	uint16_t major;
	uint16_t minor;
	uint32_t _reserved[13];
};

#define LDC_MSGSZ	sizeof(struct ldc_msg)

#define LDC_CTRL	0x01
#define LDC_DATA	0x02
#define LDC_ERR		0x10

#define LDC_INFO	0x01
#define LDC_ACK		0x02
#define LDC_NACK	0x04

#define LDC_VERS	0x01
#define LDC_RTS		0x02
#define LDC_RTR		0x03
#define LDC_RDX		0x04

#define LDC_MODE_RAW		0x00
#define LDC_MODE_UNRELIABLE	0x01
#define LDC_MODE_RELIABLE	0x03

#define LDC_LEN_MASK	0x3f
#define LDC_FRAG_MASK	0xc0
#define LDC_FRAG_START	0x40
#define LDC_FRAG_STOP	0x80

struct ldc_queue {
	bus_dmamap_t	lq_map;
	bus_dma_segment_t lq_seg;
	caddr_t		lq_va;
	int		lq_nentries;
};

struct ldc_cookie {
	uint64_t	addr;
	uint64_t	size;
};

struct ldc_queue *ldc_queue_alloc(bus_dma_tag_t, int);
void	ldc_queue_free(bus_dma_tag_t, struct ldc_queue *);

struct ldc_map_slot {
	uint64_t	entry;
	uint64_t	cookie;
};

#define LDC_MTE_R	0x0000000000000010ULL
#define LDC_MTE_W	0x0000000000000020ULL
#define LDC_MTE_X	0x0000000000000040ULL
#define LDC_MTE_IOR	0x0000000000000080ULL
#define LDC_MTE_IOW	0x0000000000000100ULL
#define LDC_MTE_CPR	0x0000000000000200ULL
#define LDC_MTE_CPW	0x0000000000000400ULL
#define LDC_MTE_RA_MASK	0x007fffffffffe000ULL

struct ldc_map {
	bus_dmamap_t		lm_map;
	bus_dma_segment_t	lm_seg;
	struct ldc_map_slot	*lm_slot;
	int			lm_nentries;
	int			lm_next;
	int			lm_count;
};

struct ldc_map *ldc_map_alloc(bus_dma_tag_t, int);
void	ldc_map_free(bus_dma_tag_t, struct ldc_map *);

a215 2
	uint64_t	sc_id;

d219 1
a219 14
	struct ldc_queue *sc_txq;
	struct ldc_queue *sc_rxq;

	uint64_t	sc_tx_state;
	uint64_t	sc_rx_state;

	uint32_t	sc_tx_seqid;

	uint8_t		sc_ldc_state;
#define LDC_SND_VERS	1
#define LDC_RCV_VERS	2
#define LDC_SND_RTS	3
#define LDC_SND_RTR	4
#define LDC_SND_RDX	5
d260 1
a260 6
void	vnet_rx_ctrl(struct vnet_softc *, struct ldc_msg *);
void	vnet_rx_ctrl_vers(struct vnet_softc *, struct ldc_msg *);
void	vnet_rx_ctrl_rtr(struct vnet_softc *, struct ldc_msg *);
void	vnet_rx_ctrl_rts(struct vnet_softc *, struct ldc_msg *);

void	vnet_rx_data(struct vnet_softc *, struct ldc_msg *);
d269 1
a269 5
void	ldc_send_vers(struct vnet_softc *);
void	ldc_send_rtr(struct vnet_softc *);
void	ldc_send_rts(struct vnet_softc *);
void	ldc_send_rdx(struct vnet_softc *);
void	ldc_reset(struct vnet_softc *);
d307 1
a313 2
	sc->sc_id = ca->ca_id;

d329 2
a330 2
	hv_ldc_tx_qconf(sc->sc_id, 0, 0);
	hv_ldc_rx_qconf(sc->sc_id, 0, 0);
d341 8
a348 2
	sc->sc_txq = ldc_queue_alloc(sc->sc_dmatag, VNET_TX_ENTRIES);
	if (sc->sc_txq == NULL) {
d353 2
a354 2
	sc->sc_rxq = ldc_queue_alloc(sc->sc_dmatag, VNET_RX_ENTRIES);
	if (sc->sc_rxq == NULL) {
d385 1
a385 1
	ldc_queue_free(sc->sc_dmatag, sc->sc_txq);
d393 1
d396 2
a397 2
	hv_ldc_tx_get_state(sc->sc_id, &tx_head, &tx_tail, &tx_state);
	if (tx_state != sc->sc_tx_state) {
d409 1
a409 1
		sc->sc_tx_state = tx_state;
d419 1
d421 1
a421 1
	struct ldc_msg *lm;
d425 1
a425 1
	err = hv_ldc_rx_get_state(sc->sc_id, &rx_head, &rx_tail, &rx_state);
d433 1
a433 1
	if (rx_state != sc->sc_rx_state) {
a434 2
		sc->sc_tx_seqid = 0;
		sc->sc_ldc_state = 0;
d436 2
d444 1
a444 1
			ldc_send_vers(sc);
d450 2
a451 2
		sc->sc_rx_state = rx_state;
		hv_ldc_rx_set_qhead(sc->sc_id, rx_tail);
d455 1
a455 1
	msg = (uint64_t *)(sc->sc_rxq->lq_va + rx_head);
d466 2
a467 2
	lm = (struct ldc_msg *)(sc->sc_rxq->lq_va + rx_head);
	switch (lm->type) {
d469 1
a469 1
		vnet_rx_ctrl(sc, lm);
d473 1
a473 1
		vnet_rx_data(sc, lm);
d477 3
a479 3
		DPRINTF(("%0x02/%0x02/%0x02\n", lm->type, lm->stype,
		    lm->ctrl));
		ldc_reset(sc);
d483 1
a483 1
	if (sc->sc_ldc_state == 0)
d486 3
a488 3
	rx_head += LDC_MSGSZ;
	rx_head &= ((sc->sc_rxq->lq_nentries * LDC_MSGSZ) - 1);
	err = hv_ldc_rx_set_qhead(sc->sc_id, rx_head);
d496 1
a496 87
vnet_rx_ctrl(struct vnet_softc *sc, struct ldc_msg *lm)
{
	switch (lm->ctrl) {
	case LDC_VERS:
		vnet_rx_ctrl_vers(sc, lm);
		break;

	case LDC_RTS:
		vnet_rx_ctrl_rts(sc, lm);
		break;

	case LDC_RTR:
		vnet_rx_ctrl_rtr(sc, lm);
		break;

	default:
		DPRINTF(("CTRL/0x%02x/0x%02x\n", lm->stype, lm->ctrl));
		ldc_reset(sc);
		break;
	}
}

void
vnet_rx_ctrl_vers(struct vnet_softc *sc, struct ldc_msg *lm)
{
	switch (lm->stype) {
	case LDC_INFO:
		/* XXX do nothing for now. */
		break;

	case LDC_ACK:
		if (sc->sc_ldc_state != LDC_SND_VERS) {
			DPRINTF(("Spurious CTRL/ACK/VERS: state %d\n",
			    sc->sc_ldc_state));
			ldc_reset(sc);
			return;
		}
		DPRINTF(("CTRL/ACK/VERS\n"));
		ldc_send_rts(sc);
		break;

	case LDC_NACK:
		DPRINTF(("CTRL/NACK/VERS\n"));
		ldc_reset(sc);
		break;

	default:
		DPRINTF(("CTRL/0x%02x/VERS\n", lm->stype));
		ldc_reset(sc);
		break;
	}
}

void
vnet_rx_ctrl_rts(struct vnet_softc *sc, struct ldc_msg *lm)
{
	switch (lm->stype) {
	case LDC_INFO:
		if (sc->sc_ldc_state != LDC_RCV_VERS) {
			DPRINTF(("Suprious CTRL/INFO/RTS: state %d\n",
			    sc->sc_ldc_state));
			ldc_reset(sc);
			return;
		}
		DPRINTF(("CTRL/INFO/RTS\n"));
		ldc_send_rtr(sc);
		break;

	case LDC_ACK:
		DPRINTF(("CTRL/ACK/RTS\n"));
		ldc_reset(sc);
		break;

	case LDC_NACK:
		DPRINTF(("CTRL/NACK/RTS\n"));
		ldc_reset(sc);
		break;

	default:
		DPRINTF(("CTRL/0x%02x/RTS\n", lm->stype));
		ldc_reset(sc);
		break;
	}
}

void
vnet_rx_ctrl_rtr(struct vnet_softc *sc, struct ldc_msg *lm)
d498 1
a498 11
	switch (lm->stype) {
	case LDC_INFO:
		if (sc->sc_ldc_state != LDC_SND_RTS) {
			DPRINTF(("Spurious CTRL/INFO/RTR: state %d\n",
			    sc->sc_ldc_state));
			ldc_reset(sc);
			return;
		}
		DPRINTF(("CTRL/INFO/RTR\n"));
		ldc_send_rdx(sc);
		break;
a499 36
	case LDC_ACK:
		DPRINTF(("CTRL/ACK/RTR\n"));
		ldc_reset(sc);
		break;

	case LDC_NACK:
		DPRINTF(("CTRL/NACK/RTR\n"));
		ldc_reset(sc);
		break;

	default:
		DPRINTF(("CTRL/0x%02x/RTR\n", lm->stype));
		ldc_reset(sc);
		break;
	}
}

void
vnet_rx_data(struct vnet_softc *sc, struct ldc_msg *lm)
{
	struct vio_msg *vm;

	if (lm->stype != LDC_INFO) {
		DPRINTF(("DATA/0x%02x\n", lm->stype));
		ldc_reset(sc);
		return;
	}

	if (sc->sc_ldc_state != LDC_SND_RTR &&
	    sc->sc_ldc_state != LDC_SND_RDX) {
		DPRINTF(("Spurious DATA/INFO: state %d\n", sc->sc_ldc_state));
		ldc_reset(sc);
		return;
	}

	vm = (struct vio_msg *)lm;
d502 2
a503 2
		if ((lm->env & LDC_FRAG_START) == 0 &&
		    (lm->env & LDC_FRAG_STOP) == 0)
d505 1
a505 1
		vnet_rx_vio_ctrl(sc, vm);
d509 1
a509 1
		if((lm->env & LDC_FRAG_START) == 0)
d511 1
a511 1
		vnet_rx_vio_data(sc, vm);
d516 1
a516 1
		ldc_reset(sc);
d712 1
d733 1
a733 1
			err = hv_ldc_copy(sc->sc_id, LDC_COPY_IN, cookie,
d757 1
a757 1
			err = hv_ldc_copy(sc->sc_id, LDC_COPY_IN,
d786 1
a786 1
			err = hv_ldc_copy(sc->sc_id, LDC_COPY_OUT, cookie,
d844 1
a844 61
ldc_send_vers(struct vnet_softc *sc)
{
	struct ldc_msg *lm;
	uint64_t tx_head, tx_tail, tx_state;
	int err;

	err = hv_ldc_tx_get_state(sc->sc_id, &tx_head, &tx_tail, &tx_state);
	if (err != H_EOK || tx_state != LDC_CHANNEL_UP)
		return;

	lm = (struct ldc_msg *)(sc->sc_txq->lq_va + tx_tail);
	bzero(lm, sizeof(struct ldc_msg));
	lm->type = LDC_CTRL;
	lm->stype = LDC_INFO;
	lm->ctrl = LDC_VERS;
	lm->major = 1;
	lm->minor = 0;

	tx_tail += LDC_MSGSZ;
	tx_tail &= ((sc->sc_txq->lq_nentries * LDC_MSGSZ) - 1);
	err = hv_ldc_tx_set_qtail(sc->sc_id, tx_tail);
	if (err != H_EOK) {
		printf("%s: hv_ldc_tx_set_qtail: %d\n", __func__, err);
		return;
	}

	sc->sc_ldc_state = LDC_SND_VERS;
}

void
ldc_send_rts(struct vnet_softc *sc)
{
	struct ldc_msg *lm;
	uint64_t tx_head, tx_tail, tx_state;
	int err;

	err = hv_ldc_tx_get_state(sc->sc_id, &tx_head, &tx_tail, &tx_state);
	if (err != H_EOK || tx_state != LDC_CHANNEL_UP)
		return;

	lm = (struct ldc_msg *)(sc->sc_txq->lq_va + tx_tail);
	bzero(lm, sizeof(struct ldc_msg));
	lm->type = LDC_CTRL;
	lm->stype = LDC_INFO;
	lm->ctrl = LDC_RTS;
	lm->env = LDC_MODE_UNRELIABLE;
	lm->seqid = sc->sc_tx_seqid++;

	tx_tail += LDC_MSGSZ;
	tx_tail &= ((sc->sc_txq->lq_nentries * LDC_MSGSZ) - 1);
	err = hv_ldc_tx_set_qtail(sc->sc_id, tx_tail);
	if (err != H_EOK) {
		printf("%s: hv_ldc_tx_set_qtail: %d\n", __func__, err);
		return;
	}

	sc->sc_ldc_state = LDC_SND_RTS;
}

void
ldc_send_rtr(struct vnet_softc *sc)
d846 1
a846 72
	struct ldc_msg *lm;
	uint64_t tx_head, tx_tail, tx_state;
	int err;

	err = hv_ldc_tx_get_state(sc->sc_id, &tx_head, &tx_tail, &tx_state);
	if (err != H_EOK || tx_state != LDC_CHANNEL_UP)
		return;

	lm = (struct ldc_msg *)(sc->sc_txq->lq_va + tx_tail);
	bzero(lm, sizeof(struct ldc_msg));
	lm->type = LDC_CTRL;
	lm->stype = LDC_INFO;
	lm->ctrl = LDC_RTR;
	lm->env = LDC_MODE_UNRELIABLE;
	lm->seqid = sc->sc_tx_seqid++;

	tx_tail += LDC_MSGSZ;
	tx_tail &= ((sc->sc_txq->lq_nentries * LDC_MSGSZ) - 1);
	err = hv_ldc_tx_set_qtail(sc->sc_id, tx_tail);
	if (err != H_EOK)
		printf("%s: hv_ldc_tx_set_qtail: %d\n", __func__, err);

	sc->sc_ldc_state = LDC_SND_RTR;
}

void
ldc_send_rdx(struct vnet_softc *sc)
{
	struct ldc_msg *lm;
	uint64_t tx_head, tx_tail, tx_state;
	int err;

	err = hv_ldc_tx_get_state(sc->sc_id, &tx_head, &tx_tail, &tx_state);
	if (err != H_EOK || tx_state != LDC_CHANNEL_UP)
		return;

	lm = (struct ldc_msg *)(sc->sc_txq->lq_va + tx_tail);
	bzero(lm, sizeof(struct ldc_msg));
	lm->type = LDC_CTRL;
	lm->stype = LDC_INFO;
	lm->ctrl = LDC_RDX;
	lm->env = LDC_MODE_UNRELIABLE;
	lm->seqid = sc->sc_tx_seqid++;

	tx_tail += LDC_MSGSZ;
	tx_tail &= ((sc->sc_txq->lq_nentries * LDC_MSGSZ) - 1);
	err = hv_ldc_tx_set_qtail(sc->sc_id, tx_tail);
	if (err != H_EOK)
		printf("%s: hv_ldc_tx_set_qtail: %d\n", __func__, err);

	sc->sc_ldc_state = LDC_SND_RDX;
}

void
ldc_reset(struct vnet_softc *sc)
{
	int err;

	DPRINTF(("Resetting connection\n"));
	hv_ldc_tx_qconf(sc->sc_id, 0, 0);
	hv_ldc_rx_qconf(sc->sc_id, 0, 0);
	sc->sc_tx_state = sc->sc_rx_state = LDC_CHANNEL_DOWN;

	err = hv_ldc_tx_qconf(sc->sc_id,
	    sc->sc_txq->lq_map->dm_segs[0].ds_addr, sc->sc_txq->lq_nentries);
	if (err != H_EOK)
		printf("%s: hv_ldc_tx_qconf %d\n", __func__, err);

	err = hv_ldc_rx_qconf(sc->sc_id,
	    sc->sc_rxq->lq_map->dm_segs[0].ds_addr, sc->sc_rxq->lq_nentries);
	if (err != H_EOK)
		printf("%s: hv_ldc_rx_qconf %d\n", __func__, err);
a848 3
	sc->sc_ldc_state = 0;
	sc->sc_tx_seqid = 0;

d855 2
a856 1
	struct ldc_msg *lm;
d863 1
a863 1
	err = hv_ldc_tx_get_state(sc->sc_id, &tx_head, &tx_tail, &tx_state);
d867 7
a873 7
	lm = (struct ldc_msg *)(sc->sc_txq->lq_va + tx_tail);
	bzero(lm, sizeof(struct ldc_msg));
	lm->type = LDC_DATA;
	lm->stype = LDC_INFO;
	lm->env = 56 | LDC_FRAG_STOP | LDC_FRAG_START;
	lm->seqid = sc->sc_tx_seqid++;
	bcopy(msg, &lm->major, len);
d885 3
a887 3
	tx_tail += LDC_MSGSZ;
	tx_tail &= ((sc->sc_txq->lq_nentries * LDC_MSGSZ) - 1);
	err = hv_ldc_tx_set_qtail(sc->sc_id, tx_tail);
d1196 1
d1203 1
a1203 1
	err = hv_ldc_set_map_table(sc->sc_id,
d1223 2
a1224 2
	err = hv_ldc_tx_qconf(sc->sc_id,
	    sc->sc_txq->lq_map->dm_segs[0].ds_addr, sc->sc_txq->lq_nentries);
d1228 2
a1229 2
	err = hv_ldc_rx_qconf(sc->sc_id,
	    sc->sc_rxq->lq_map->dm_segs[0].ds_addr, sc->sc_rxq->lq_nentries);
d1233 1
a1233 1
	ldc_send_vers(sc);
d1243 1
d1247 3
a1249 3
	hv_ldc_tx_qconf(sc->sc_id, 0, 0);
	hv_ldc_rx_qconf(sc->sc_id, 0, 0);
	sc->sc_tx_state = sc->sc_rx_state = LDC_CHANNEL_DOWN;
d1253 1
a1253 1
	hv_ldc_set_map_table(sc->sc_id, 0, 0);
a1256 58
struct ldc_queue *
ldc_queue_alloc(bus_dma_tag_t t, int nentries)
{
	struct ldc_queue *lq;
	bus_size_t size;
	caddr_t va;
	int nsegs;

	lq = malloc(sizeof(struct ldc_queue), M_DEVBUF, M_NOWAIT);
	if (lq == NULL)
		return NULL;

	size = roundup(nentries * LDC_MSGSZ, PAGE_SIZE);

	if (bus_dmamap_create(t, size, 1, size, 0,
	    BUS_DMA_NOWAIT | BUS_DMA_ALLOCNOW, &lq->lq_map) != 0)
		return (NULL);

	if (bus_dmamem_alloc(t, size, PAGE_SIZE, 0, &lq->lq_seg, 1,
	    &nsegs, BUS_DMA_NOWAIT) != 0)
		goto destroy;

	if (bus_dmamem_map(t, &lq->lq_seg, 1, size, &va,
	    BUS_DMA_NOWAIT) != 0)
		goto free;

	if (bus_dmamap_load(t, lq->lq_map, va, size, NULL,
	    BUS_DMA_NOWAIT) != 0)
		goto unmap;

	lq->lq_va = va;
	lq->lq_nentries = nentries;
	return (lq);

unmap:
	bus_dmamem_unmap(t, va, size);
free:
	bus_dmamem_free(t, &lq->lq_seg, 1);
destroy:
	bus_dmamap_destroy(t, lq->lq_map);

	return (NULL);
}

void
ldc_queue_free(bus_dma_tag_t t, struct ldc_queue *lq)
{
	bus_size_t size;

	size = roundup(lq->lq_nentries * LDC_MSGSZ, PAGE_SIZE);

	bus_dmamap_unload(t, lq->lq_map);
	bus_dmamem_unmap(t, lq->lq_va, size);
	bus_dmamem_free(t, &lq->lq_seg, 1);
	bus_dmamap_destroy(t, lq->lq_map);
	free(lq, M_DEVBUF);
}

a1317 60
}

struct ldc_map *
ldc_map_alloc(bus_dma_tag_t t, int nentries)
{
	struct ldc_map *lm;
	bus_size_t size;
	caddr_t va;
	int nsegs;

	lm = malloc(sizeof(struct ldc_map), M_DEVBUF, M_NOWAIT);
	if (lm == NULL)
		return NULL;

	size = roundup(nentries * sizeof(struct ldc_map_slot), PAGE_SIZE);

	if (bus_dmamap_create(t, size, 1, size, 0,
	    BUS_DMA_NOWAIT | BUS_DMA_ALLOCNOW, &lm->lm_map) != 0)
		return (NULL);

	if (bus_dmamem_alloc(t, size, PAGE_SIZE, 0, &lm->lm_seg, 1,
	    &nsegs, BUS_DMA_NOWAIT) != 0)
		goto destroy;

	if (bus_dmamem_map(t, &lm->lm_seg, 1, size, &va,
	    BUS_DMA_NOWAIT) != 0)
		goto free;

	if (bus_dmamap_load(t, lm->lm_map, va, size, NULL,
	    BUS_DMA_NOWAIT) != 0)
		goto unmap;

	lm->lm_slot = (struct ldc_map_slot *)va;
	lm->lm_nentries = nentries;
	bzero(lm->lm_slot, nentries * sizeof(struct ldc_map_slot));
	return (lm);

unmap:
	bus_dmamem_unmap(t, va, size);
free:
	bus_dmamem_free(t, &lm->lm_seg, 1);
destroy:
	bus_dmamap_destroy(t, lm->lm_map);

	return (NULL);
}

void
ldc_map_free(bus_dma_tag_t t, struct ldc_map *lm)
{
	bus_size_t size;

	size = lm->lm_nentries * sizeof(struct ldc_map_slot);
	size = roundup(size, PAGE_SIZE);

	bus_dmamap_unload(t, lm->lm_map);
	bus_dmamem_unmap(t, (caddr_t)lm->lm_slot, size);
	bus_dmamem_free(t, &lm->lm_seg, 1);
	bus_dmamap_destroy(t, lm->lm_map);
	free(lm, M_DEVBUF);
@


1.4
log
@Set IFF_OACTIVE when we run out of resources transmitting packets.
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.3 2009/01/06 22:49:46 kettenis Exp $	*/
d185 10
d213 2
d386 2
a512 1
	struct ifnet *ifp = &sc->sc_ac.ac_if;
d530 1
a530 1
		ifp->if_flags &= ~IFF_RUNNING;
d882 2
d899 4
d1453 13
d1507 39
@


1.3
log
@Properly report link state and don't abuse IFF_RUNNING.
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.2 2009/01/05 22:09:51 kettenis Exp $	*/
a101 5
struct ldc_chan {
	struct ldc_queue	lc_txq;
	struct ldc_queue	lc_rxq;
};

d307 1
a310 2
	int		sc_state;

d514 1
a514 1
		sc->sc_tx_prod = sc->sc_tx_cons = 0;
d1027 1
d1030 5
d1305 1
a1306 1
	struct ldc_map *map;
d1331 6
d1338 2
a1339 1
		if (buf == NULL)
d1341 1
a1353 1
		map = sc->sc_lm;
a1355 2
		if (map->lm_count == map->lm_nentries)
			panic("out of LDC map entries\n");
d1380 1
d1521 1
d1529 1
a1529 1
	ifp->if_flags &= ~IFF_RUNNING;
@


1.2
log
@Hide many debug printfs behind DPRINTF, and remove most others.  Remove some
stray bits of code, and properly clear the Rx queue upon link state changes.
@
text
@d1 1
a1 1
/*	$OpenBSD: vnet.c,v 1.1 2009/01/04 17:20:44 kettenis Exp $	*/
d378 2
a874 2
	struct ifnet *ifp = &sc->sc_ac.ac_if;

d889 1
a889 1
		ifp->if_flags |= IFF_RUNNING;
d1187 2
d1304 1
a1305 1
	struct vnet_softc *sc;
d1312 1
a1312 1
	if (!(ifp->if_flags & IFF_RUNNING))
d1315 1
a1315 1
	if (ifp->if_flags & IFF_OACTIVE)
d1318 5
a1322 1
	if (IFQ_IS_EMPTY(&ifp->if_snd))
a1324 2
	sc = ifp->if_softc;

d1452 18
d1514 1
a1514 2
//	ifp->if_flags |= IFF_RUNNING;
//	ifp->if_flags |= IFF_OACTIVE; /* XXX */
@


1.1
log
@Initial stab at a driver for virtual network devices found on sun4v logical
domains.  Still needs a lot of work, but good enough for an nfs root.
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d50 1
a50 1
/* XXX the following declarations should be elsewhere */
d53 6
d269 6
a380 2
struct pool vnetpl;

d484 1
a484 1
			printf("Tx link down\n");
d487 1
a487 1
			printf("Tx link up\n");
d490 1
a490 1
			printf("Tx link reset\n");
d524 1
a524 1
			printf("Rx link down\n");
d527 1
a527 1
			printf("Rx link up\n");
d531 1
a531 2
			printf("Rx link reset\n");
//			ldc_send_vers(sc);
a533 1
		printf("rx_head %lld rx_tail %lld\n", rx_head, rx_tail);
d535 1
a535 1
		hv_ldc_rx_set_qhead(sc->sc_id, rx_head);
d561 2
a562 1
		printf("%0x02/%0x02/%0x02\n", lm->type, lm->stype, lm->ctrl);
d596 1
a596 1
		printf("CTRL/0x%02x/0x%02x\n", lm->stype, lm->ctrl);
d612 2
a613 2
			printf("Spurious CTRL/ACK/VERS: state %d\n",
			    sc->sc_ldc_state);
d617 1
a617 1
		printf("CTRL/ACK/VERS\n");
d622 1
a622 1
		printf("CTRL/NACK/VERS\n");
d627 1
a627 1
		printf("CTRL/0x%02x/VERS\n", lm->stype);
d639 2
a640 2
			printf("Suprious CTRL/INFO/RTS: state %d\n",
			    sc->sc_ldc_state);
d644 1
a644 1
		printf("CTRL/INFO/RTS\n");
d649 1
a649 1
		printf("CTRL/ACK/RTS\n");
d654 1
a654 1
		printf("CTRL/NACK/RTS\n");
d659 1
a659 1
		printf("CTRL/0x%02x/RTS\n", lm->stype);
d671 2
a672 2
			printf("Spurious CTRL/INFO/RTR: state %d\n",
			    sc->sc_ldc_state);
d676 1
a676 1
		printf("CTRL/INFO/RTR\n");
d681 1
a681 1
		printf("CTRL/ACK/RTR\n");
d686 1
a686 1
		printf("CTRL/NACK/RTR\n");
d691 1
a691 1
		printf("CTRL/0x%02x/RTR\n", lm->stype);
d703 1
a703 1
		printf("DATA/0x%02x\n", lm->stype);
d710 1
a710 1
		printf("Spurious DATA/INFO: state %d\n", sc->sc_ldc_state);
d731 1
a731 1
		printf("Unhandled packet type 0x%02x\n", vm->type);
d756 1
a756 1
		printf("CTRL/0x%02x/0x%04x\n", tag->stype, tag->stype_env);
d768 1
a768 1
		printf("CTRL/INFO/VER_INFO\n");
d800 1
a800 1
		printf("CTRL/ACK/VER_INFO\n");
d804 1
a804 1
		printf("CTRL/0x%02x/VER_INFO\n", vi->tag.stype);
d816 1
a816 1
		printf("CTRL/INFO/ATTR_INFO\n");
d826 1
a826 1
		printf("CTRL/ACK/ATTR_INFO\n");
d830 1
a830 1
		printf("CTRL/0x%02x/VER_INFO\n", ai->tag.stype);
d842 1
a842 1
		printf("CTRL/INFO/DRING_REG\n");
d856 1
a856 1
		printf("CTRL/ACK/DRING_REG\n");
d865 1
a865 1
		printf("CTRL/0x%02x/DRING_REG\n", dr->tag.stype);
d877 1
a877 1
		printf("CTRL/INFO/RDX\n");
d885 1
a885 1
		printf("CTRL/ACK/RDX\n");
a887 1
		printf("succesful handshake\n");
d893 1
a893 1
		printf("CTRL/0x%02x/RDX (VIO)\n", tag->stype);
d904 2
a905 1
		printf("Spurious DATA/0x%02x/0x%04x\n", tag->stype, tag->stype_env);
d915 1
a915 1
		printf("DATA/0x%02x/0x%04x\n", tag->stype, tag->stype_env);
a950 9
#if 0
			{
				uint64_t *p = (uint64_t *)&desc;
				int i;
				for (i = 0; i < 4; i++)
					printf(" 0x%016llx\n", p[i]);
				printf("\n");
			}
#endif
d965 1
a965 1
			nbytes = roundup(desc.nbytes + 6, 8);
d984 1
a984 11
			m->m_data += 6;

#if 0
			{
				uint8_t *p = m->m_data;
				int i;
				for (i = 0; i < m->m_len; i++)
					printf(" 0x%02x", p[i]);
				printf("\n");
			}
#endif
a1023 6
#if 0
		if (sc->sc_tx_cons != dm->start_idx)
			printf("ACK out of sequence: cons %d start_idx %d\n",
			    sc->sc_tx_cons, dm->start_idx);
#endif

d1039 1
a1039 1
		printf("DATA/NACK/DRING_DATA\n");
d1043 1
a1043 1
		printf("DATA/0x%02x/DRING_DATA\n", tag->stype);
d1169 1
a1169 1
	printf("Resetting connection\n");
d1330 1
a1330 1
		m_copydata(m, 0, m->m_pkthdr.len, buf + 6);
a1357 9
#if 0
		{
			uint8_t *p = buf;
			int i;
			for (i = 0; i < (m->m_pkthdr.len + 6); i++)
				printf(" 0x%02x", p[i]);
			printf("\n");
		}
#endif
a1475 1
//	sc->sc_lm->lm_slot[0].entry |= LDC_MTE_R | LDC_MTE_W;
@

