head	1.186;
access;
symbols
	OPENBSD_6_2_BASE:1.186
	OPENBSD_6_1:1.184.0.4
	OPENBSD_6_1_BASE:1.184
	OPENBSD_6_0:1.183.0.2
	OPENBSD_6_0_BASE:1.183
	OPENBSD_5_9:1.181.0.2
	OPENBSD_5_9_BASE:1.181
	OPENBSD_5_8:1.180.0.4
	OPENBSD_5_8_BASE:1.180
	OPENBSD_5_7:1.179.0.2
	OPENBSD_5_7_BASE:1.179
	OPENBSD_5_6:1.175.0.8
	OPENBSD_5_6_BASE:1.175
	OPENBSD_5_5:1.175.0.6
	OPENBSD_5_5_BASE:1.175
	OPENBSD_5_4:1.175.0.2
	OPENBSD_5_4_BASE:1.175
	OPENBSD_5_3:1.169.0.2
	OPENBSD_5_3_BASE:1.169
	OPENBSD_5_2:1.164.0.4
	OPENBSD_5_2_BASE:1.164
	OPENBSD_5_1_BASE:1.164
	OPENBSD_5_1:1.164.0.2
	OPENBSD_5_0:1.163.0.4
	OPENBSD_5_0_BASE:1.163
	OPENBSD_4_9:1.163.0.2
	OPENBSD_4_9_BASE:1.163
	OPENBSD_4_8:1.162.0.2
	OPENBSD_4_8_BASE:1.162
	OPENBSD_4_7:1.159.0.2
	OPENBSD_4_7_BASE:1.159
	OPENBSD_4_6:1.158.0.4
	OPENBSD_4_6_BASE:1.158
	OPENBSD_4_5:1.157.0.2
	OPENBSD_4_5_BASE:1.157
	OPENBSD_4_4:1.149.0.2
	OPENBSD_4_4_BASE:1.149
	OPENBSD_4_3:1.111.0.2
	OPENBSD_4_3_BASE:1.111
	OPENBSD_4_2:1.78.0.2
	OPENBSD_4_2_BASE:1.78
	OPENBSD_4_1:1.70.0.2
	OPENBSD_4_1_BASE:1.70
	OPENBSD_4_0:1.61.0.2
	OPENBSD_4_0_BASE:1.61
	OPENBSD_3_9:1.54.0.2
	OPENBSD_3_9_BASE:1.54
	OPENBSD_3_8:1.52.0.2
	OPENBSD_3_8_BASE:1.52
	OPENBSD_3_7:1.48.0.2
	OPENBSD_3_7_BASE:1.48
	OPENBSD_3_6:1.47.0.2
	OPENBSD_3_6_BASE:1.47
	SMP_SYNC_A:1.44
	SMP_SYNC_B:1.44
	OPENBSD_3_5:1.43.0.2
	OPENBSD_3_5_BASE:1.43
	OPENBSD_3_4:1.42.0.2
	OPENBSD_3_4_BASE:1.42
	UBC_SYNC_A:1.34
	OPENBSD_3_3:1.31.0.2
	OPENBSD_3_3_BASE:1.31
	OPENBSD_3_2:1.25.0.2
	OPENBSD_3_2_BASE:1.25
	OPENBSD_3_1:1.13.0.2
	OPENBSD_3_1_BASE:1.13
	UBC_SYNC_B:1.25
	UBC:1.9.0.6
	UBC_BASE:1.9
	SMP:1.9.0.4
	OPENBSD_3_0:1.9.0.2
	OPENBSD_3_0_BASE:1.9;
locks; strict;
comment	@# @;


1.186
date	2017.05.16.20.53.42;	author kettenis;	state Exp;
branches;
next	1.185;
commitid	qf7KXaLhjf8Q2jPU;

1.185
date	2017.04.30.16.45.45;	author mpi;	state Exp;
branches;
next	1.184;
commitid	2Gtqjzrin9LL2yHk;

1.184
date	2016.10.18.00.43.57;	author guenther;	state Exp;
branches;
next	1.183;
commitid	ViMtDmKg8K8fZjQi;

1.183
date	2016.05.23.20.11.49;	author deraadt;	state Exp;
branches;
next	1.182;
commitid	0oWSDXhpPUnuLpPD;

1.182
date	2016.05.10.18.39.49;	author deraadt;	state Exp;
branches;
next	1.181;
commitid	qfOifNidEGDB2jL1;

1.181
date	2015.08.28.23.28.39;	author kettenis;	state Exp;
branches;
next	1.180;
commitid	IIvmUURykkPFbth0;

1.180
date	2015.06.24.18.41.58;	author miod;	state Exp;
branches;
next	1.179;
commitid	7YxgnHkaZDcxhYGa;

1.179
date	2014.11.30.22.26.14;	author kettenis;	state Exp;
branches;
next	1.178;
commitid	SuwbTdviYcmeB8QU;

1.178
date	2014.11.24.10.55.49;	author kettenis;	state Exp;
branches;
next	1.177;
commitid	JCHmMLfSZzUClLUT;

1.177
date	2014.11.20.08.47.00;	author kettenis;	state Exp;
branches;
next	1.176;
commitid	tzSJLx54M95WKQTn;

1.176
date	2014.11.20.07.50.45;	author deraadt;	state Exp;
branches;
next	1.175;
commitid	1e8e22cyIJ9IGa0l;

1.175
date	2013.06.15.10.05.58;	author kettenis;	state Exp;
branches;
next	1.174;

1.174
date	2013.06.13.20.03.59;	author kettenis;	state Exp;
branches;
next	1.173;

1.173
date	2013.06.13.19.33.04;	author kettenis;	state Exp;
branches;
next	1.172;

1.172
date	2013.06.13.19.11.13;	author kettenis;	state Exp;
branches;
next	1.171;

1.171
date	2013.06.09.12.42.22;	author tedu;	state Exp;
branches;
next	1.170;

1.170
date	2013.05.12.18.48.53;	author kettenis;	state Exp;
branches;
next	1.169;

1.169
date	2013.02.05.09.33.29;	author mpi;	state Exp;
branches;
next	1.168;

1.168
date	2012.11.07.16.31.03;	author kettenis;	state Exp;
branches;
next	1.167;

1.167
date	2012.11.06.21.39.02;	author kettenis;	state Exp;
branches;
next	1.166;

1.166
date	2012.08.30.20.53.09;	author kettenis;	state Exp;
branches;
next	1.165;

1.165
date	2012.08.29.20.33.16;	author kettenis;	state Exp;
branches;
next	1.164;

1.164
date	2011.10.12.18.30.09;	author miod;	state Exp;
branches;
next	1.163;

1.163
date	2010.11.27.18.04.23;	author miod;	state Exp;
branches;
next	1.162;

1.162
date	2010.03.27.23.12.48;	author kettenis;	state Exp;
branches;
next	1.161;

1.161
date	2010.03.22.18.49.25;	author kettenis;	state Exp;
branches;
next	1.160;

1.160
date	2010.03.21.22.23.03;	author kettenis;	state Exp;
branches;
next	1.159;

1.159
date	2009.08.28.13.04.40;	author jsing;	state Exp;
branches;
next	1.158;

1.158
date	2009.04.30.11.36.57;	author kettenis;	state Exp;
branches;
next	1.157;

1.157
date	2009.01.23.19.16.39;	author kettenis;	state Exp;
branches;
next	1.156;

1.156
date	2008.12.22.23.01.31;	author kettenis;	state Exp;
branches;
next	1.155;

1.155
date	2008.12.22.18.08.25;	author kettenis;	state Exp;
branches;
next	1.154;

1.154
date	2008.12.13.23.39.30;	author kettenis;	state Exp;
branches;
next	1.153;

1.153
date	2008.08.17.14.25.19;	author kettenis;	state Exp;
branches;
next	1.152;

1.152
date	2008.08.10.14.13.05;	author kettenis;	state Exp;
branches;
next	1.151;

1.151
date	2008.08.07.21.25.47;	author kettenis;	state Exp;
branches;
next	1.150;

1.150
date	2008.08.07.18.46.04;	author kettenis;	state Exp;
branches;
next	1.149;

1.149
date	2008.07.28.19.08.46;	author miod;	state Exp;
branches;
next	1.148;

1.148
date	2008.07.25.14.53.38;	author kettenis;	state Exp;
branches;
next	1.147;

1.147
date	2008.07.21.13.30.05;	author art;	state Exp;
branches;
next	1.146;

1.146
date	2008.07.12.15.05.51;	author kettenis;	state Exp;
branches;
next	1.145;

1.145
date	2008.07.10.09.29.33;	author kettenis;	state Exp;
branches;
next	1.144;

1.144
date	2008.07.05.20.53.33;	author kettenis;	state Exp;
branches;
next	1.143;

1.143
date	2008.07.05.19.30.44;	author kettenis;	state Exp;
branches;
next	1.142;

1.142
date	2008.06.01.21.29.48;	author kettenis;	state Exp;
branches;
next	1.141;

1.141
date	2008.06.01.12.13.47;	author kettenis;	state Exp;
branches;
next	1.140;

1.140
date	2008.05.23.13.19.43;	author kettenis;	state Exp;
branches;
next	1.139;

1.139
date	2008.05.22.22.29.14;	author kettenis;	state Exp;
branches;
next	1.138;

1.138
date	2008.05.21.19.42.07;	author miod;	state Exp;
branches;
next	1.137;

1.137
date	2008.04.20.10.35.57;	author kettenis;	state Exp;
branches;
next	1.136;

1.136
date	2008.04.20.09.18.52;	author kettenis;	state Exp;
branches;
next	1.135;

1.135
date	2008.04.16.12.56.04;	author kettenis;	state Exp;
branches;
next	1.134;

1.134
date	2008.04.15.22.39.26;	author kettenis;	state Exp;
branches;
next	1.133;

1.133
date	2008.04.14.21.04.56;	author kettenis;	state Exp;
branches;
next	1.132;

1.132
date	2008.04.13.16.32.55;	author kettenis;	state Exp;
branches;
next	1.131;

1.131
date	2008.04.12.14.59.30;	author kettenis;	state Exp;
branches;
next	1.130;

1.130
date	2008.04.02.20.23.22;	author kettenis;	state Exp;
branches;
next	1.129;

1.129
date	2008.03.31.22.14.01;	author kettenis;	state Exp;
branches;
next	1.128;

1.128
date	2008.03.30.13.39.53;	author kettenis;	state Exp;
branches;
next	1.127;

1.127
date	2008.03.30.12.30.01;	author kettenis;	state Exp;
branches;
next	1.126;

1.126
date	2008.03.23.21.49.48;	author kettenis;	state Exp;
branches;
next	1.125;

1.125
date	2008.03.23.12.03.50;	author miod;	state Exp;
branches;
next	1.124;

1.124
date	2008.03.22.21.10.29;	author kettenis;	state Exp;
branches;
next	1.123;

1.123
date	2008.03.22.17.15.42;	author kettenis;	state Exp;
branches;
next	1.122;

1.122
date	2008.03.22.16.41.49;	author kettenis;	state Exp;
branches;
next	1.121;

1.121
date	2008.03.22.16.01.32;	author kettenis;	state Exp;
branches;
next	1.120;

1.120
date	2008.03.22.12.49.53;	author kettenis;	state Exp;
branches;
next	1.119;

1.119
date	2008.03.22.10.53.15;	author kettenis;	state Exp;
branches;
next	1.118;

1.118
date	2008.03.20.22.22.47;	author kettenis;	state Exp;
branches;
next	1.117;

1.117
date	2008.03.19.23.16.19;	author kettenis;	state Exp;
branches;
next	1.116;

1.116
date	2008.03.19.20.42.05;	author kettenis;	state Exp;
branches;
next	1.115;

1.115
date	2008.03.18.20.00.40;	author kettenis;	state Exp;
branches;
next	1.114;

1.114
date	2008.03.17.23.10.21;	author kettenis;	state Exp;
branches;
next	1.113;

1.113
date	2008.03.13.20.37.46;	author kettenis;	state Exp;
branches;
next	1.112;

1.112
date	2008.03.12.20.52.36;	author kettenis;	state Exp;
branches;
next	1.111;

1.111
date	2008.02.24.19.16.08;	author kettenis;	state Exp;
branches;
next	1.110;

1.110
date	2008.02.14.19.07.56;	author kettenis;	state Exp;
branches;
next	1.109;

1.109
date	2008.01.16.20.55.36;	author kettenis;	state Exp;
branches;
next	1.108;

1.108
date	2008.01.12.14.18.46;	author kettenis;	state Exp;
branches;
next	1.107;

1.107
date	2008.01.03.17.09.42;	author kettenis;	state Exp;
branches;
next	1.106;

1.106
date	2007.12.23.15.33.41;	author kettenis;	state Exp;
branches;
next	1.105;

1.105
date	2007.12.05.19.43.15;	author kettenis;	state Exp;
branches;
next	1.104;

1.104
date	2007.11.11.19.47.34;	author kettenis;	state Exp;
branches;
next	1.103;

1.103
date	2007.11.10.10.46.59;	author kettenis;	state Exp;
branches;
next	1.102;

1.102
date	2007.11.09.16.15.28;	author kettenis;	state Exp;
branches;
next	1.101;

1.101
date	2007.11.06.22.20.59;	author kettenis;	state Exp;
branches;
next	1.100;

1.100
date	2007.10.31.21.29.04;	author kettenis;	state Exp;
branches;
next	1.99;

1.99
date	2007.10.31.20.20.39;	author kettenis;	state Exp;
branches;
next	1.98;

1.98
date	2007.10.31.20.14.33;	author kettenis;	state Exp;
branches;
next	1.97;

1.97
date	2007.10.29.21.27.25;	author kettenis;	state Exp;
branches;
next	1.96;

1.96
date	2007.10.27.20.04.28;	author miod;	state Exp;
branches;
next	1.95;

1.95
date	2007.10.27.17.17.23;	author kettenis;	state Exp;
branches;
next	1.94;

1.94
date	2007.10.20.21.08.31;	author kettenis;	state Exp;
branches;
next	1.93;

1.93
date	2007.10.20.16.54.52;	author miod;	state Exp;
branches;
next	1.92;

1.92
date	2007.10.20.16.41.46;	author miod;	state Exp;
branches;
next	1.91;

1.91
date	2007.10.17.21.39.44;	author kettenis;	state Exp;
branches;
next	1.90;

1.90
date	2007.10.17.21.30.08;	author kettenis;	state Exp;
branches;
next	1.89;

1.89
date	2007.10.17.21.23.28;	author kettenis;	state Exp;
branches;
next	1.88;

1.88
date	2007.10.17.20.16.11;	author kettenis;	state Exp;
branches;
next	1.87;

1.87
date	2007.10.17.19.25.22;	author kettenis;	state Exp;
branches;
next	1.86;

1.86
date	2007.10.16.21.44.25;	author kettenis;	state Exp;
branches;
next	1.85;

1.85
date	2007.10.16.19.22.49;	author kettenis;	state Exp;
branches;
next	1.84;

1.84
date	2007.10.10.15.53.53;	author art;	state Exp;
branches;
next	1.83;

1.83
date	2007.09.30.21.34.20;	author kettenis;	state Exp;
branches;
next	1.82;

1.82
date	2007.09.22.20.04.51;	author kettenis;	state Exp;
branches;
next	1.81;

1.81
date	2007.09.10.21.33.16;	author kettenis;	state Exp;
branches;
next	1.80;

1.80
date	2007.09.09.08.55.27;	author kettenis;	state Exp;
branches;
next	1.79;

1.79
date	2007.09.08.17.13.18;	author kettenis;	state Exp;
branches;
next	1.78;

1.78
date	2007.05.28.23.10.10;	author beck;	state Exp;
branches;
next	1.77;

1.77
date	2007.05.15.21.00.05;	author kettenis;	state Exp;
branches;
next	1.76;

1.76
date	2007.05.15.20.30.11;	author kettenis;	state Exp;
branches;
next	1.75;

1.75
date	2007.05.14.21.38.08;	author kettenis;	state Exp;
branches;
next	1.74;

1.74
date	2007.05.14.19.20.11;	author kettenis;	state Exp;
branches;
next	1.73;

1.73
date	2007.05.11.20.25.26;	author kettenis;	state Exp;
branches;
next	1.72;

1.72
date	2007.05.02.18.46.07;	author kettenis;	state Exp;
branches;
next	1.71;

1.71
date	2007.03.20.12.47.46;	author todd;	state Exp;
branches;
next	1.70;

1.70
date	2007.01.12.22.09.08;	author kettenis;	state Exp;
branches;
next	1.69;

1.69
date	2007.01.06.23.07.13;	author kettenis;	state Exp;
branches;
next	1.68;

1.68
date	2007.01.04.23.08.16;	author kettenis;	state Exp;
branches;
next	1.67;

1.67
date	2006.12.29.00.14.28;	author kettenis;	state Exp;
branches;
next	1.66;

1.66
date	2006.12.27.19.12.49;	author kettenis;	state Exp;
branches;
next	1.65;

1.65
date	2006.12.23.12.28.11;	author kettenis;	state Exp;
branches;
next	1.64;

1.64
date	2006.12.12.20.15.13;	author kettenis;	state Exp;
branches;
next	1.63;

1.63
date	2006.11.14.20.18.51;	author jasper;	state Exp;
branches;
next	1.62;

1.62
date	2006.10.25.20.15.59;	author kettenis;	state Exp;
branches;
next	1.61;

1.61
date	2006.08.27.21.19.02;	author kettenis;	state Exp;
branches;
next	1.60;

1.60
date	2006.07.01.16.24.17;	author miod;	state Exp;
branches;
next	1.59;

1.59
date	2006.06.07.16.57.43;	author deraadt;	state Exp;
branches;
next	1.58;

1.58
date	2006.06.02.01.07.25;	author kettenis;	state Exp;
branches;
next	1.57;

1.57
date	2006.05.31.06.51.25;	author kettenis;	state Exp;
branches;
next	1.56;

1.56
date	2006.05.31.02.43.05;	author kettenis;	state Exp;
branches;
next	1.55;

1.55
date	2006.03.23.02.29.36;	author ray;	state Exp;
branches;
next	1.54;

1.54
date	2006.02.22.22.17.07;	author miod;	state Exp;
branches;
next	1.53;

1.53
date	2006.01.03.20.57.36;	author kettenis;	state Exp;
branches;
next	1.52;

1.52
date	2005.08.08.19.48.37;	author kettenis;	state Exp;
branches;
next	1.51;

1.51
date	2005.07.18.14.50.11;	author deraadt;	state Exp;
branches;
next	1.50;

1.50
date	2005.07.14.01.46.13;	author deraadt;	state Exp;
branches;
next	1.49;

1.49
date	2005.03.29.19.34.07;	author kettenis;	state Exp;
branches;
next	1.48;

1.48
date	2004.12.24.22.50.31;	author miod;	state Exp;
branches;
next	1.47;

1.47
date	2004.06.28.01.47.41;	author aaron;	state Exp;
branches;
next	1.46;

1.46
date	2004.06.20.04.30.34;	author aaron;	state Exp;
branches;
next	1.45;

1.45
date	2004.06.13.21.49.21;	author niklas;	state Exp;
branches;
next	1.44;

1.44
date	2004.04.23.04.18.17;	author marc;	state Exp;
branches;
next	1.43;

1.43
date	2004.01.08.17.14.04;	author pvalchev;	state Exp;
branches;
next	1.42;

1.42
date	2003.07.24.18.17.50;	author jason;	state Exp;
branches;
next	1.41;

1.41
date	2003.07.09.15.52.53;	author jason;	state Exp;
branches;
next	1.40;

1.40
date	2003.07.09.02.18.09;	author jason;	state Exp;
branches;
next	1.39;

1.39
date	2003.05.17.19.30.55;	author art;	state Exp;
branches;
next	1.38;

1.38
date	2003.05.17.07.48.19;	author mdw;	state Exp;
branches;
next	1.37;

1.37
date	2003.05.17.07.45.54;	author mdw;	state Exp;
branches;
next	1.36;

1.36
date	2003.05.17.07.24.11;	author art;	state Exp;
branches;
next	1.35;

1.35
date	2003.05.17.07.09.08;	author art;	state Exp;
branches;
next	1.34;

1.34
date	2003.05.16.00.40.36;	author mdw;	state Exp;
branches;
next	1.33;

1.33
date	2003.05.16.00.38.45;	author mdw;	state Exp;
branches;
next	1.32;

1.32
date	2003.05.13.01.33.06;	author jason;	state Exp;
branches;
next	1.31;

1.31
date	2003.03.21.22.59.10;	author jason;	state Exp;
branches;
next	1.30;

1.30
date	2003.03.20.23.05.30;	author henric;	state Exp;
branches;
next	1.29;

1.29
date	2003.02.28.21.27.42;	author jason;	state Exp;
branches;
next	1.28;

1.28
date	2003.02.17.01.29.20;	author henric;	state Exp;
branches;
next	1.27;

1.27
date	2003.01.11.07.07.49;	author jason;	state Exp;
branches;
next	1.26;

1.26
date	2003.01.09.22.27.10;	author miod;	state Exp;
branches;
next	1.25;

1.25
date	2002.09.10.18.29.44;	author art;	state Exp;
branches;
next	1.24;

1.24
date	2002.07.31.01.40.17;	author jason;	state Exp;
branches;
next	1.23;

1.23
date	2002.07.24.00.48.25;	author art;	state Exp;
branches;
next	1.22;

1.22
date	2002.07.23.13.58.23;	author art;	state Exp;
branches;
next	1.21;

1.21
date	2002.07.20.22.39.00;	author art;	state Exp;
branches;
next	1.20;

1.20
date	2002.07.20.22.30.35;	author art;	state Exp;
branches;
next	1.19;

1.19
date	2002.07.20.20.19.10;	author art;	state Exp;
branches;
next	1.18;

1.18
date	2002.06.15.00.38.37;	author art;	state Exp;
branches;
next	1.17;

1.17
date	2002.06.09.05.55.24;	author art;	state Exp;
branches;
next	1.16;

1.16
date	2002.06.08.21.54.49;	author mdw;	state Exp;
branches;
next	1.15;

1.15
date	2002.06.08.08.06.46;	author art;	state Exp;
branches;
next	1.14;

1.14
date	2002.05.23.23.11.15;	author deraadt;	state Exp;
branches;
next	1.13;

1.13
date	2002.04.03.17.22.41;	author jason;	state Exp;
branches;
next	1.12;

1.12
date	2002.03.14.01.26.45;	author millert;	state Exp;
branches;
next	1.11;

1.11
date	2002.02.19.03.15.27;	author jason;	state Exp;
branches;
next	1.10;

1.10
date	2002.02.19.03.04.41;	author jason;	state Exp;
branches;
next	1.9;

1.9
date	2001.09.17.04.20.27;	author jason;	state Exp;
branches
	1.9.4.1
	1.9.6.1;
next	1.8;

1.8
date	2001.09.10.22.40.21;	author art;	state Exp;
branches;
next	1.7;

1.7
date	2001.09.06.10.45.41;	author art;	state Exp;
branches;
next	1.6;

1.6
date	2001.09.04.16.51.18;	author jason;	state Exp;
branches;
next	1.5;

1.5
date	2001.09.04.16.49.00;	author jason;	state Exp;
branches;
next	1.4;

1.4
date	2001.09.04.16.44.02;	author jason;	state Exp;
branches;
next	1.3;

1.3
date	2001.08.30.17.58.27;	author deraadt;	state Exp;
branches;
next	1.2;

1.2
date	2001.08.30.12.20.04;	author art;	state Exp;
branches;
next	1.1;

1.1
date	2001.08.19.05.21.38;	author jason;	state Exp;
branches;
next	;

1.9.4.1
date	2001.10.31.03.07.59;	author nate;	state Exp;
branches;
next	1.9.4.2;

1.9.4.2
date	2002.03.06.02.04.47;	author niklas;	state Exp;
branches;
next	1.9.4.3;

1.9.4.3
date	2002.03.28.11.23.52;	author niklas;	state Exp;
branches;
next	1.9.4.4;

1.9.4.4
date	2003.03.27.23.42.37;	author niklas;	state Exp;
branches;
next	1.9.4.5;

1.9.4.5
date	2003.05.16.00.29.40;	author niklas;	state Exp;
branches;
next	1.9.4.6;

1.9.4.6
date	2003.06.07.11.14.45;	author ho;	state Exp;
branches;
next	1.9.4.7;

1.9.4.7
date	2004.02.19.10.50.00;	author niklas;	state Exp;
branches;
next	1.9.4.8;

1.9.4.8
date	2004.06.05.23.11.00;	author niklas;	state Exp;
branches;
next	1.9.4.9;

1.9.4.9
date	2004.06.07.01.00.12;	author tedu;	state Exp;
branches;
next	;

1.9.6.1
date	2002.06.11.03.38.43;	author art;	state Exp;
branches;
next	1.9.6.2;

1.9.6.2
date	2002.10.29.00.28.12;	author art;	state Exp;
branches;
next	1.9.6.3;

1.9.6.3
date	2003.05.19.21.46.57;	author tedu;	state Exp;
branches;
next	;


desc
@@


1.186
log
@Implement copyin32(9).

ok mpi@@, visa@@
@
text
@/*	$OpenBSD: locore.s,v 1.185 2017/04/30 16:45:45 mpi Exp $	*/
/*	$NetBSD: locore.s,v 1.137 2001/08/13 06:10:10 jdolecek Exp $	*/

/*
 * Copyright (c) 1996-2001 Eduardo Horvath
 * Copyright (c) 1996 Paul Kranenburg
 * Copyright (c) 1996
 * 	The President and Fellows of Harvard College.
 *	All rights reserved.
 * Copyright (c) 1992, 1993
 *	The Regents of the University of California.
 *	All rights reserved.
 *
 * This software was developed by the Computer Systems Engineering group
 * at Lawrence Berkeley Laboratory under DARPA contract BG 91-66 and
 * contributed to Berkeley.
 *
 * All advertising materials mentioning features or use of this software
 * must display the following acknowledgement:
 *	This product includes software developed by the University of
 *	California, Lawrence Berkeley Laboratory.
 *	This product includes software developed by Harvard University.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the
 *    distribution.
 * 3. All advertising materials mentioning features or use of this
 *    software must display the following acknowledgement:
 *	This product includes software developed by the University of
 *	California, Berkeley and its contributors.
 *	This product includes software developed by Harvard University.
 *	This product includes software developed by Paul Kranenburg.
 * 4. Neither the name of the University nor the names of its
 *    contributors may be used to endorse or promote products derived
 *    from this software without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS''
 * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,
 * THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A
 * PARTICULAR PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR
 * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
 * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
 * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
 * ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR
 * TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF
 * THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
 * DAMAGE.
 *
 *	@@(#)locore.s	8.4 (Berkeley) 12/10/93
 */

#define HORRID_III_HACK

#undef	NO_VCACHE		/* Map w/D$ disabled */
#undef	DCACHE_BUG		/* Flush D$ around ASI_PHYS accesses */
#undef	NO_TSB			/* Don't use TSB */

.register %g2,
.register %g3,

#include "assym.h"
#include "ksyms.h"
#include <machine/param.h>
#include <sparc64/sparc64/intreg.h>
#include <sparc64/sparc64/timerreg.h>
#include <machine/ctlreg.h>
#include <machine/psl.h>
#include <machine/signal.h>
#include <machine/trap.h>
#include <machine/frame.h>
#include <machine/pmap.h>
#include <machine/asm.h>

#undef	CURPROC
#undef	CPCB
#undef	FPPROC

/* Let us use same syntax as C code */
#define db_enter()	ta	1; nop

/* use as needed to align things on longword boundaries */
#define	_ALIGN	.align 8
#define ICACHE_ALIGN	.align	32

/* Give this real authority: reset the machine */
#if 1
#define NOTREACHED	sir
#else	/* 1 */
#define NOTREACHED
#endif	/* 1 */

	.section	.sun4v_patch, "ax"
	.globl _C_LABEL(sun4v_patch)
_C_LABEL(sun4v_patch):
	.previous

	.section	.sun4v_patch_end, "ax"
	.globl _C_LABEL(sun4v_patch_end)
_C_LABEL(sun4v_patch_end):
	.previous

	.section	.sun4v_pause_patch, "ax"
	.globl _C_LABEL(sun4v_pause_patch)
_C_LABEL(sun4v_pause_patch):
	.previous

	.section	.sun4v_pause_patch_end, "ax"
	.globl _C_LABEL(sun4v_pause_patch_end)
_C_LABEL(sun4v_pause_patch_end):
	.previous

#ifdef MULTIPROCESSOR
	.section	.sun4v_mp_patch, "ax"
	.globl _C_LABEL(sun4v_mp_patch)
_C_LABEL(sun4v_mp_patch):
	.previous

	.section	.sun4v_mp_patch_end, "ax"
	.globl _C_LABEL(sun4v_mp_patch_end)
_C_LABEL(sun4v_mp_patch_end):
	.previous

	.section	.sun4u_mtp_patch, "ax"
	.globl _C_LABEL(sun4u_mtp_patch)
_C_LABEL(sun4u_mtp_patch):
	.previous

	.section	.sun4u_mtp_patch_end, "ax"
	.globl _C_LABEL(sun4u_mtp_patch_end)
_C_LABEL(sun4u_mtp_patch_end):
	.previous
#endif

/*
 * The UltraSPARC T1 has a "feature" where a LDXA/STXA to ASI_SCRATCHPAD
 * registers may corrupt an unrelated integer register file register.
 * To prevent this, it is required to have a non-store or NOP instruction
 * before any LDXA/STXA to this register.
 */
#define GET_CPUINFO_VA(ci) \
	nop					;\
999:	set	CPUINFO_VA, ci			;\
	.section	.sun4v_mp_patch, "ax"	;\
	.word	999b				;\
	ldxa	[%g0] ASI_SCRATCHPAD, ci	;\
	.previous				;\
	.section	.sun4u_mtp_patch, "ax"	;\
	.word	999b				;\
	ldxa	[%g0] ASI_SCRATCH, ci		;\
	.previous

#define GET_CPCB(pcb) \
	GET_CPUINFO_VA(pcb)			;\
	ldx	[pcb + CI_CPCB], pcb

#define GET_CURPROC(curproc) \
	GET_CPUINFO_VA(curproc)			;\
	ldx	[curproc + CI_CURPROC], curproc

#ifdef SUN4V

#define GET_CPUINFO_PA(ci) \
	mov	0x10, ci				;\
	ldxa	[ci] ASI_SCRATCHPAD, ci

#define GET_MMFSA(mmfsa) \
	GET_CPUINFO_PA(mmfsa)			;\
	add	mmfsa, CI_MMFSA, mmfsa		;\
	ldxa	[mmfsa] ASI_PHYS_CACHED, mmfsa

#endif

#define GET_MMU_CONTEXTID(ctxid, ctx) \
999:	ldxa	[ctx] ASI_DMMU, ctxid 		;\
	.section	.sun4v_patch, "ax" 	;\
	.word	999b				;\
	ldxa	[ctx] ASI_MMU_CONTEXTID, ctxid 	;\
	.previous

#define SET_MMU_CONTEXTID(ctxid, ctx) \
999:	stxa	ctxid, [ctx] ASI_DMMU 		;\
	.section	.sun4v_patch, "ax" 	;\
	.word	999b				;\
	stxa	ctxid, [ctx] ASI_MMU_CONTEXTID 	;\
	.previous

#define NORMAL_GLOBALS() \
999:	wrpr	%g0, PSTATE_KERN, %pstate	;\
	.section	.sun4v_patch, "ax"	;\
	.word	999b				;\
	wrpr	%g0, 0, %gl			;\
	.previous

#define ALTERNATE_GLOBALS() \
999:	wrpr	%g0, PSTATE_KERN|PSTATE_AG, %pstate	;\
	.section	.sun4v_patch, "ax"	;\
	.word	999b				;\
	wrpr	%g0, 1, %gl			;\
	.previous


/*
 * This macro will clear out a cache line before an explicit
 * access to that location.  It's mostly used to make certain
 * loads bypassing the D$ do not get stale D$ data.
 *
 * It uses a register with the address to clear and a temporary
 * which is destroyed.
 */
	.macro DLFLUSH a,t
#ifdef DCACHE_BUG
	andn	\a, 0x1f, \t
	stxa	%g0, [ \t ] ASI_DCACHE_TAG
	membar	#Sync
#endif	/* DCACHE_BUG */
	.endm
/* The following can be used if the pointer is 16-byte aligned */
	.macro DLFLUSH2 t
#ifdef DCACHE_BUG
	stxa	%g0, [ \t ] ASI_DCACHE_TAG
	membar	#Sync
#endif	/* DCACHE_BUG */
	.endm

/*
 * A handy macro for maintaining instrumentation counters.
 * Note that this clobbers %o0, %o1 and %o2.  Normal usage is
 * something like:
 *	foointr:
 *		TRAP_SETUP ...		! makes %o registers safe
 *		INCR _C_LABEL(cnt)+V_FOO	! count a foo
 */
	.macro INCR what
	sethi	%hi(\what), %o0
	or	%o0, %lo(\what), %o0
99:
	lduw	[%o0], %o1
	add	%o1, 1, %o2
	casa	[%o0] ASI_P, %o1, %o2
	cmp	%o1, %o2
	bne,pn	%icc, 99b
	 nop
	.endm

/*
 * A couple of handy macros to save and restore globals to/from
 * locals.  Since udivrem uses several globals, and it's called
 * from vsprintf, we need to do this before and after doing a printf.
 */
	.macro GLOBTOLOC
	.irpc n,1234567
		mov	%g\n, %l\n
	.endr
	.endm

	.macro LOCTOGLOB
	.irpc n,1234567
		mov	%l\n, %g\n
	.endr
	.endm

/*
 * some macros to load and store a register window
 */
	.macro	SPILL storer,base,size,asi

	.irpc n,01234567
		\storer %l\n, [\base + (\n * \size)] \asi
	.endr
	.irpc n,01234567
		\storer %i\n, [\base + ((8+\n) * \size)] \asi
	.endr
	.endm

	.macro FILL loader, base, size, asi
	.irpc n,01234567
		\loader [\base + (\n * \size)] \asi, %l\n
	.endr

	.irpc n,01234567
		\loader [\base + ((8+\n) * \size)] \asi, %i\n
	.endr
	.endm

/* Load strings address into register; NOTE: hidden local label 99 */
#define LOAD_ASCIZ(reg, s)	\
	set	99f, reg ;	\
	.data ;			\
99:	.asciz	s ;		\
	_ALIGN ;		\
	.text

/*
 * Handy stack conversion macros.
 * Correctly switch to a 64-bit stack
 * regardless of the current stack.
 */

	.macro STACKFRAME size
	save	%sp, \size, %sp
	add	%sp, -BIAS, %o0		! Convert to 64-bits
	andcc	%sp, 1, %g0		! 64-bit stack?
	movz	%icc, %o0, %sp
	.endm


	.data
	.globl	_C_LABEL(data_start)
_C_LABEL(data_start):					! Start of data segment
#define DATA_START	_C_LABEL(data_start)

/*
 * Process 0's u.
 *
 * This must be aligned on an 8 byte boundary.
 */
	.globl	_C_LABEL(u0)
_C_LABEL(u0):	.xword	0
estack0:	.xword	0

/*
 * This stack is used for bootstrapping and spinning up CPUs.
 */
	.space	4096
	.align	16
tmpstack:

#ifdef DEBUG
/*
 * This stack is used when we detect kernel stack corruption.
 */
	.space	USPACE
	.align	16
panicstack:
#endif	/* DEBUG */

/*
 * romp is the prom entry pointer
 */
	.globl	romp
romp:	.xword	0

/*
 * cputyp is the current cpu type, used to distinguish between
 * the many variations of different sun4* machines. It contains
 * the value CPU_SUN4U or CPU_SUN4V.
 */
	.globl	_C_LABEL(cputyp)
_C_LABEL(cputyp):
	.word	CPU_SUN4U

	.globl _C_LABEL(cold)
_C_LABEL(cold):
	.word 1

	_ALIGN

	.text

/*
 * The v9 trap frame is stored in the special trap registers.  The
 * register window is only modified on window overflow, underflow,
 * and clean window traps, where it points to the register window
 * needing service.  Traps have space for 8 instructions, except for
 * the window overflow, underflow, and clean window traps which are
 * 32 instructions long, large enough to in-line.
 *
 * The spitfire CPU (Ultra I) has 4 different sets of global registers.
 * (blah blah...)
 *
 * I used to generate these numbers by address arithmetic, but gas's
 * expression evaluator has about as much sense as your average slug
 * (oddly enough, the code looks about as slimy too).  Thus, all the
 * trap numbers are given as arguments to the trap macros.  This means
 * there is one line per trap.  Sigh.
 *
 * Hardware interrupt vectors can be `linked'---the linkage is to regular
 * C code---or rewired to fast in-window handlers.  The latter are good
 * for unbuffered hardware like the Zilog serial chip and the AMD audio
 * chip, where many interrupts can be handled trivially with pseudo-DMA
 * or similar.  Only one `fast' interrupt can be used per level, however,
 * and direct and `fast' interrupts are incompatible.  Routines in intr.c
 * handle setting these, with optional paranoia.
 */

/*
 *	TA8 -- trap align for 8 instruction traps
 *	TA32 -- trap align for 32 instruction traps
 */
	.macro TA8
	.align 32
	.endm

	.macro TA32
	.align 128
	.endm

/*
 * v9 trap macros:
 *
 *	We have a problem with v9 traps; we have no registers to put the
 *	trap type into.  But we do have a %tt register which already has
 *	that information.  Trap types in these macros are all dummys.
 */
	/* regular vectored traps */
#ifdef DEBUG
	.macro VTRAP type, label
	sethi	%hi(DATA_START),%g1
	rdpr	%tt,%g2
	or	%g1,0x28,%g1
	b	\label
	stx	%g2,[%g1]
	NOTREACHED
	TA8
	.endm
#else	/* DEBUG */
	.macro VTRAP type, label
	ba,a,pt	%icc,\label
	nop
	NOTREACHED
	TA8
	.endm
#endif	/* DEBUG */
	/* hardware interrupts (can be linked or made `fast') */
	.macro HARDINT4U lev
	VTRAP \lev, _C_LABEL(sparc_interrupt)
	.endm

	/* software interrupts (may not be made direct, sorry---but you
	   should not be using them trivially anyway) */
	.macro SOFTINT4U lev, bit
	HARDINT4U lev
	.endm

	/* traps that just call trap() */
	.macro TRAP type
	VTRAP \type, slowtrap
	.endm

	/* architecturally undefined traps (cause panic) */
	.macro	UTRAP type
#ifndef DEBUG
	sir
#endif	/* DEBUG */
	VTRAP \type, slowtrap
	.endm

	/* software undefined traps (may be replaced) */
	.macro STRAP type
	VTRAP \type, slowtrap
	.endm

#define	SYSCALL		VTRAP 0x100, syscall_setup
#define	ZS_INTERRUPT4U	HARDINT4U 12

/*
 * Macro to clear %tt so we don't get confused with old traps.
 */
	.macro CLRTT n
#ifdef DEBUG
#if 0	/* for henric, but not yet */
	wrpr	%g0, 0x1ff - \n, %tt
#else	/* 0 */
	wrpr	%g0, 0x1ff, %tt
#endif	/* 0 */
#endif	/* DEBUG */
	.endm

	.macro UCLEANWIN
	rdpr %cleanwin, %o7		! 024-027 = clean window trap
	inc %o7				!	This handler is in-lined and cannot fault
#ifdef DEBUG
	set	0xbadcafe, %l0		! DEBUG -- compiler should not rely on zero-ed registers.
#else	/* DEBUG */
	clr	%l0
#endif	/* DEBUG */
	wrpr %g0, %o7, %cleanwin	!       Nucleus (trap&IRQ) code does not need clean windows

	mov %l0,%l1; mov %l0,%l2	!	Clear out %l0-%l8 and %o0-%o8 and inc %cleanwin and done
	mov %l0,%l3; mov %l0,%l4
	mov %l0, %l5
	mov %l0, %l6; mov %l0, %l7; mov %l0, %o0; mov %l0, %o1

	mov %l0, %o2; mov %l0, %o3; mov %l0, %o4; mov %l0, %o5;
	mov %l0, %o6; mov %l0, %o7
	CLRTT 5
	retry; nop; NOTREACHED; TA32
	.endm

	.macro KCLEANWIN
	clr	%l0
#ifdef DEBUG
	set	0xbadbeef, %l0		! DEBUG
#endif	/* DEBUG */
	mov %l0, %l1; mov %l0, %l2	! 024-027 = clean window trap
	rdpr %cleanwin, %o7		!	This handler is in-lined and cannot fault
	inc %o7; mov %l0, %l3	!       Nucleus (trap&IRQ) code does not need clean windows
	wrpr %g0, %o7, %cleanwin	!	Clear out %l0-%l8 and %o0-%o8 and inc %cleanwin and done
	mov %l0, %l4; mov %l0, %l5; mov %l0, %l6; mov %l0, %l7
	mov %l0, %o0; mov %l0, %o1; mov %l0, %o2; mov %l0, %o3

	mov %l0, %o4; mov %l0, %o5; mov %l0, %o6; mov %l0, %o7
	CLRTT 8
	retry; nop; TA32
	.endm

	.macro IMMU_MISS n
	ldxa	[%g0] ASI_IMMU_8KPTR, %g2!	Load IMMU 8K TSB pointer
	ldxa	[%g0] ASI_IMMU, %g1	!	Load IMMU tag target register
	ldda	[%g2] ASI_NUCLEUS_QUAD_LDD, %g4!Load TSB tag:data into %g4
	brgez,pn %g5, instr_miss	!	Entry invalid?  Punt
	 cmp	%g1, %g4		!	Compare TLB tags
	bne,pn %xcc, instr_miss		!	Got right tag?
	 nop
	CLRTT \n
	stxa	%g5, [%g0] ASI_IMMU_DATA_IN!	Enter new mapping
	retry				!	Try new mapping
1:
	sir
	TA32
	.endm

	.macro DMMU_MISS n
	ldxa	[%g0] ASI_DMMU_8KPTR, %g2!	Load DMMU 8K TSB pointer
	ldxa	[%g0] ASI_DMMU, %g1	!	Load DMMU tag target register
	ldda	[%g2] ASI_NUCLEUS_QUAD_LDD, %g4!Load TSB tag:data into %g4
	brgez,pn %g5, data_miss		!	Entry invalid?  Punt
	 xor	%g1, %g4, %g4		!	Compare TLB tags
	brnz,pn	%g4, data_miss		!	Got right tag?
	 nop
	CLRTT \n
	stxa	%g5, [%g0] ASI_DMMU_DATA_IN!	Enter new mapping
	retry				!	Try new mapping
1:
	sir
	TA32
	.endm

	.macro DMMU_PROT dprot
	ba,a,pt	%xcc, dmmu_write_fault
	nop
	TA32
	.endm
/*
 * Here are some often repeated traps as macros.
 */

	! spill a 64-bit user register window
	.macro USPILL64 label, as
\label:
	wr	%g0, \as, %asi
	stxa	%l0, [%sp + BIAS + ( 0*8)] %asi
	stxa	%l1, [%sp + BIAS + ( 1*8)] %asi
	stxa	%l2, [%sp + BIAS + ( 2*8)] %asi
	stxa	%l3, [%sp + BIAS + ( 3*8)] %asi
	stxa	%l4, [%sp + BIAS + ( 4*8)] %asi
	stxa	%l5, [%sp + BIAS + ( 5*8)] %asi
	stxa	%l6, [%sp + BIAS + ( 6*8)] %asi
	stxa	%l7, [%sp + BIAS + ( 7*8)] %asi
	stxa	%i0, [%sp + BIAS + ( 8*8)] %asi
	stxa	%i1, [%sp + BIAS + ( 9*8)] %asi
	stxa	%i2, [%sp + BIAS + (10*8)] %asi
	stxa	%i3, [%sp + BIAS + (11*8)] %asi
	stxa	%i4, [%sp + BIAS + (12*8)] %asi
	stxa	%i5, [%sp + BIAS + (13*8)] %asi
	stxa	%i6, [%sp + BIAS + (14*8)] %asi
	GET_CPCB(%g5)
	ldx	[%g5 + PCB_WCOOKIE], %g5
	xor	%g5, %i7, %g5		! stackghost
	stxa	%g5, [%sp + BIAS + (15*8)] %asi
	saved
	CLRTT 1
	retry
	NOTREACHED
	TA32
	.endm

	! spill a 64-bit kernel register window
	.macro SPILL64 label, as
\label:
	wr	%g0, \as, %asi
	SPILL	stxa, %sp+BIAS, 8, %asi
	saved
	CLRTT 1
	retry
	NOTREACHED
	TA32
	.endm

	! spill a 32-bit register window
	.macro SPILL32 label, as
\label:
	wr	%g0, \as, %asi
	srl	%sp, 0, %sp ! fixup 32-bit pointers
	SPILL	stwa, %sp, 4, %asi
	saved
	CLRTT 2
	retry
	NOTREACHED
	TA32
	.endm

	! Spill either 32-bit or 64-bit register window.
	.macro SPILLBOTH label64,label32, as
	andcc	%sp, 1, %g0
	bnz,pt	%xcc, \label64+4	! Is it a v9 or v8 stack?
	 wr	%g0, \as, %asi
	ba,pt	%xcc, \label32+8
	 srl	%sp, 0, %sp ! fixup 32-bit pointers
	NOTREACHED
	TA32
	.endm

	! fill a 64-bit user register window
	.macro UFILL64 label, as
\label:
	wr	%g0, \as, %asi
	FILL	ldxa, %sp+BIAS, 8, %asi
	GET_CPCB(%g5)
	ldx	[%g5 + PCB_WCOOKIE], %g5
	xor	%g5, %i7, %i7		! stackghost
	restored
	CLRTT 3
	retry
	NOTREACHED
	TA32
	.endm

	! fill a 64-bit kernel register window
	.macro FILL64 label, as
\label:
	wr	%g0, \as, %asi
	FILL	ldxa, %sp+BIAS, 8, %asi
	restored
	CLRTT 3
	retry
	NOTREACHED
	TA32
	.endm

	! fill a 32-bit register window
	.macro FILL32 label, as
\label:
	wr	%g0, \as, %asi
	srl	%sp, 0, %sp ! fixup 32-bit pointers
	FILL	lda, %sp, 4, %asi
	restored
	CLRTT 4
	retry
	NOTREACHED
	TA32
	.endm

	! fill either 32-bit or 64-bit register window.
	.macro FILLBOTH label64,label32, as
	andcc	%sp, 1, %i0
	bnz	(\label64)+4 ! See if it's a v9 stack or v8
	 wr	%g0, \as, %asi
	ba	(\label32)+8
	 srl	%sp, 0, %sp ! fixup 32-bit pointers
	NOTREACHED
	TA32
	.endm

#ifdef SUN4V

	.macro	sun4v_tl0_reserved	count
	.rept	\count
	ba,a,pt	%xcc, slowtrap
	 nop
	.align	32
	.endr
	.endm

#define sun4v_tl0_unused sun4v_tl0_reserved

	.macro	sun4v_tl1_reserved	count
	.rept	\count
	ba,a,pt	%xcc, slowtrap
	 nop
	.align	32
	.endr
	.endm

#define sun4v_tl1_unused sun4v_tl1_reserved

	.macro sun4v_tl1_kspill_normal
	ba,a,pt	%xcc,kspill_normal
	 nop
	.align 128
	.endm

	.macro sun4v_tl1_uspill_normal
	ba,a,pt	%xcc,pcbspill_normals
	 nop
	.align 128
	.endm

	.macro sun4v_tl1_uspill_other
	ba,a,pt	%xcc,pcbspill_others
	 nop
	.align 128
	.endm

#endif

	.globl	start, _C_LABEL(kernel_text)
	_C_LABEL(kernel_text) = start		! for kvm_mkdb(8)
start:
	/* Traps from TL=0 -- traps from user mode */
	.globl	_C_LABEL(trapbase)
_C_LABEL(trapbase):
	b dostart; nop; TA8	! 000 = reserved -- Use it to boot
	/* We should not get the next 5 traps */
	UTRAP 0x001		! 001 = POR Reset -- ROM should get this
	UTRAP 0x002		! 002 = WDR -- ROM should get this
	UTRAP 0x003		! 003 = XIR -- ROM should get this
	UTRAP 0x004		! 004 = SIR -- ROM should get this
	UTRAP 0x005		! 005 = RED state exception
	UTRAP 0x006; UTRAP 0x007
	VTRAP T_INST_EXCEPT, textfault	! 008 = instr. access exept
	VTRAP T_TEXTFAULT, textfault	! 009 = instr. access MMU miss
	VTRAP T_INST_ERROR, textfault	! 00a = instr. access err
	UTRAP 0x00b; UTRAP 0x00c; UTRAP 0x00d; UTRAP 0x00e; UTRAP 0x00f
	TRAP T_ILLINST			! 010 = illegal instruction
	TRAP T_PRIVINST		! 011 = privileged instruction
	UTRAP 0x012			! 012 = unimplemented LDD
	UTRAP 0x013			! 013 = unimplemented STD
	UTRAP 0x014; UTRAP 0x015; UTRAP 0x016; UTRAP 0x017; UTRAP 0x018
	UTRAP 0x019; UTRAP 0x01a; UTRAP 0x01b; UTRAP 0x01c; UTRAP 0x01d
	UTRAP 0x01e; UTRAP 0x01f
	TRAP T_FPDISABLED		! 020 = fp instr, but EF bit off in psr
	TRAP T_FP_IEEE_754		! 021 = ieee 754 exception
	TRAP T_FP_OTHER			! 022 = other fp exception
	TRAP T_TAGOF			! 023 = tag overflow
	UCLEANWIN			! 024-027 = clean window trap
	TRAP T_DIV0			! 028 = divide by zero
	UTRAP 0x029			! 029 = internal processor error
	UTRAP 0x02a; UTRAP 0x02b; UTRAP 0x02c; UTRAP 0x02d; UTRAP 0x02e; UTRAP 0x02f
	VTRAP T_DATAFAULT, datafault	! 030 = data fetch fault
	UTRAP 0x031			! 031 = data MMU miss -- no MMU
	VTRAP T_DATA_ERROR, datafault	! 032 = data access error
	VTRAP T_DATA_PROT, datafault	! 033 = data protection fault
	TRAP T_ALIGN			! 034 = address alignment error -- we could fix it inline...
	TRAP T_LDDF_ALIGN		! 035 = LDDF address alignment error -- we could fix it inline...
	TRAP T_STDF_ALIGN		! 036 = STDF address alignment error -- we could fix it inline...
	TRAP T_PRIVACT			! 037 = privileged action
	TRAP T_LDQF_ALIGN		! 038 = LDDF address alignment error
	TRAP T_STQF_ALIGN		! 039 = STQF address alignment error
	UTRAP 0x03a; UTRAP 0x03b; UTRAP 0x03c;
	UTRAP 0x03d; UTRAP 0x03e; UTRAP 0x03f;
	VTRAP T_ASYNC_ERROR, datafault	! 040 = data fetch fault
	SOFTINT4U 1, IE_L1		! 041 = level 1 interrupt
	HARDINT4U 2			! 042 = level 2 interrupt
	HARDINT4U 3			! 043 = level 3 interrupt
	SOFTINT4U 4, IE_L4		! 044 = level 4 interrupt
	HARDINT4U 5			! 045 = level 5 interrupt
	SOFTINT4U 6, IE_L6		! 046 = level 6 interrupt
	HARDINT4U 7			! 047 = level 7 interrupt
	HARDINT4U 8			! 048 = level 8 interrupt
	HARDINT4U 9			! 049 = level 9 interrupt
	HARDINT4U 10			! 04a = level 10 interrupt
	HARDINT4U 11			! 04b = level 11 interrupt
	ZS_INTERRUPT4U			! 04c = level 12 (zs) interrupt
	HARDINT4U 13			! 04d = level 13 interrupt
	HARDINT4U 14			! 04e = level 14 interrupt
	HARDINT4U 15			! 04f = nonmaskable interrupt
	UTRAP 0x050; UTRAP 0x051; UTRAP 0x052; UTRAP 0x053; UTRAP 0x054; UTRAP 0x055
	UTRAP 0x056; UTRAP 0x057; UTRAP 0x058; UTRAP 0x059; UTRAP 0x05a; UTRAP 0x05b
	UTRAP 0x05c; UTRAP 0x05d; UTRAP 0x05e; UTRAP 0x05f
	VTRAP 0x060, interrupt_vector; ! 060 = interrupt vector
	TRAP T_PA_WATCHPT		! 061 = physical address data watchpoint
	TRAP T_VA_WATCHPT		! 062 = virtual address data watchpoint
	VTRAP T_ECCERR, cecc_catch	! 063 = Correctable ECC error
ufast_IMMU_miss:			! 064 = fast instr access MMU miss
	IMMU_MISS 6
ufast_DMMU_miss:			! 068 = fast data access MMU miss
	DMMU_MISS 7
ufast_DMMU_protection:			! 06c = fast data access MMU protection
	DMMU_PROT udprot
	UTRAP 0x070			! Implementation dependent traps
	UTRAP 0x071; UTRAP 0x072; UTRAP 0x073; UTRAP 0x074; UTRAP 0x075; UTRAP 0x076
	UTRAP 0x077; UTRAP 0x078; UTRAP 0x079; UTRAP 0x07a; UTRAP 0x07b; UTRAP 0x07c
	UTRAP 0x07d; UTRAP 0x07e; UTRAP 0x07f
user_uspill:
	USPILL64 uspill8,ASI_AIUS	! 0x080 spill_0_normal -- used to save user windows in user mode
	SPILL32 uspill4,ASI_AIUS	! 0x084 spill_1_normal
	SPILLBOTH uspill8,uspill4,ASI_AIUS		! 0x088 spill_2_normal
#ifdef DEBUG
	sir
#endif	/* DEBUG */
	UTRAP 0x08c; TA32	! 0x08c spill_3_normal
user_kspill:
	UTRAP 0x090; TA32	! 0x090 spill_4_normal -- used to save supervisor windows
	SPILL64 kspill8,ASI_N	! 0x094 spill_5_normal
	SPILL32 kspill4,ASI_N	! 0x098 spill_6_normal
	SPILLBOTH kspill8,kspill4,ASI_N	! 0x09c spill_7_normal
user_uspillk:
	USPILL64 uspillk8,ASI_AIUS	! 0x0a0 spill_0_other -- used to save user windows in supervisor mode
	SPILL32 uspillk4,ASI_AIUS	! 0x0a4 spill_1_other
	SPILLBOTH uspillk8,uspillk4,ASI_AIUS	! 0x0a8 spill_2_other
	UTRAP 0x0ac; TA32	! 0x0ac spill_3_other
	UTRAP 0x0b0; TA32	! 0x0b0 spill_4_other
	UTRAP 0x0b4; TA32	! 0x0b4 spill_5_other
	UTRAP 0x0b8; TA32	! 0x0b8 spill_6_other
	UTRAP 0x0bc; TA32	! 0x0bc spill_7_other
user_ufill:
	UFILL64 ufill8,ASI_AIUS ! 0x0c0 fill_0_normal -- used to fill windows when running user mode
	FILL32 ufill4,ASI_AIUS	! 0x0c4 fill_1_normal
	FILLBOTH ufill8,ufill4,ASI_AIUS	! 0x0c8 fill_2_normal
	UTRAP 0x0cc; TA32	! 0x0cc fill_3_normal
user_kfill:
	UTRAP 0x0d0; TA32	! 0x0d0 fill_4_normal -- used to fill windows when running supervisor mode
	FILL64 kfill8,ASI_N	! 0x0d4 fill_5_normal
	FILL32 kfill4,ASI_N	! 0x0d8 fill_6_normal
	FILLBOTH kfill8,kfill4,ASI_N	! 0x0dc fill_7_normal
user_ufillk:
	UFILL64 ufillk8,ASI_AIUS	! 0x0e0 fill_0_other
	FILL32 ufillk4,ASI_AIUS	! 0x0e4 fill_1_other
	FILLBOTH ufillk8,ufillk4,ASI_AIUS	! 0x0e8 fill_2_other
	UTRAP 0x0ec; TA32	! 0x0ec fill_3_other
	UTRAP 0x0f0; TA32	! 0x0f0 fill_4_other
	UTRAP 0x0f4; TA32	! 0x0f4 fill_5_other
	UTRAP 0x0f8; TA32	! 0x0f8 fill_6_other
	UTRAP 0x0fc; TA32	! 0x0fc fill_7_other
user_syscall:
	SYSCALL			! 0x100 = sun syscall
	TRAP T_BREAKPOINT	! 0x101 = pseudo breakpoint instruction
	STRAP 0x102; STRAP 0x103; STRAP 0x104; STRAP 0x105; STRAP 0x106; STRAP 0x107
	SYSCALL			! 0x108 = svr4 syscall
	SYSCALL			! 0x109 = bsd syscall
	TRAP T_KGDB_EXEC	! 0x10a = enter kernel gdb on kernel startup
	STRAP 0x10b; STRAP 0x10c; STRAP 0x10d; STRAP 0x10e; STRAP 0x10f;
	STRAP 0x110; STRAP 0x111; STRAP 0x112; STRAP 0x113; STRAP 0x114; STRAP 0x115; STRAP 0x116; STRAP 0x117
	STRAP 0x118; STRAP 0x119; STRAP 0x11a; STRAP 0x11b; STRAP 0x11c; STRAP 0x11d; STRAP 0x11e; STRAP 0x11f
	STRAP 0x120; STRAP 0x121; STRAP 0x122; STRAP 0x123; STRAP 0x124; STRAP 0x125; STRAP 0x126; STRAP 0x127
	STRAP 0x128; STRAP 0x129; STRAP 0x12a; STRAP 0x12b; STRAP 0x12c; STRAP 0x12d; STRAP 0x12e; STRAP 0x12f
	STRAP 0x130; STRAP 0x131; STRAP 0x132; STRAP 0x133; STRAP 0x134; STRAP 0x135; STRAP 0x136; STRAP 0x137
	STRAP 0x138; STRAP 0x139; STRAP 0x13a; STRAP 0x13b; STRAP 0x13c; STRAP 0x13d; STRAP 0x13e; STRAP 0x13f
	SYSCALL			! 0x140 SVID syscall (Solaris 2.7)
	SYSCALL			! 0x141 SPARC International syscall
	SYSCALL			! 0x142	OS Vendor syscall
	SYSCALL			! 0x143 HW OEM syscall
	STRAP 0x144; STRAP 0x145; STRAP 0x146; STRAP 0x147
	STRAP 0x148; STRAP 0x149; STRAP 0x14a; STRAP 0x14b; STRAP 0x14c; STRAP 0x14d; STRAP 0x14e; STRAP 0x14f
	STRAP 0x150; STRAP 0x151; STRAP 0x152; STRAP 0x153; STRAP 0x154; STRAP 0x155; STRAP 0x156; STRAP 0x157
	STRAP 0x158; STRAP 0x159; STRAP 0x15a; STRAP 0x15b; STRAP 0x15c; STRAP 0x15d; STRAP 0x15e; STRAP 0x15f
	STRAP 0x160; STRAP 0x161; STRAP 0x162; STRAP 0x163; STRAP 0x164; STRAP 0x165; STRAP 0x166; STRAP 0x167
	STRAP 0x168; STRAP 0x169; STRAP 0x16a; STRAP 0x16b; STRAP 0x16c; STRAP 0x16d; STRAP 0x16e; STRAP 0x16f
	STRAP 0x170; STRAP 0x171; STRAP 0x172; STRAP 0x173; STRAP 0x174; STRAP 0x175; STRAP 0x176; STRAP 0x177
	STRAP 0x178; STRAP 0x179; STRAP 0x17a; STRAP 0x17b; STRAP 0x17c; STRAP 0x17d; STRAP 0x17e; STRAP 0x17f
	! Traps beyond 0x17f are reserved
	UTRAP 0x180; UTRAP 0x181; UTRAP 0x182; UTRAP 0x183; UTRAP 0x184; UTRAP 0x185; UTRAP 0x186; UTRAP 0x187
	UTRAP 0x188; UTRAP 0x189; UTRAP 0x18a; UTRAP 0x18b; UTRAP 0x18c; UTRAP 0x18d; UTRAP 0x18e; UTRAP 0x18f
	UTRAP 0x190; UTRAP 0x191; UTRAP 0x192; UTRAP 0x193; UTRAP 0x194; UTRAP 0x195; UTRAP 0x196; UTRAP 0x197
	UTRAP 0x198; UTRAP 0x199; UTRAP 0x19a; UTRAP 0x19b; UTRAP 0x19c; UTRAP 0x19d; UTRAP 0x19e; UTRAP 0x19f
	UTRAP 0x1a0; UTRAP 0x1a1; UTRAP 0x1a2; UTRAP 0x1a3; UTRAP 0x1a4; UTRAP 0x1a5; UTRAP 0x1a6; UTRAP 0x1a7
	UTRAP 0x1a8; UTRAP 0x1a9; UTRAP 0x1aa; UTRAP 0x1ab; UTRAP 0x1ac; UTRAP 0x1ad; UTRAP 0x1ae; UTRAP 0x1af
	UTRAP 0x1b0; UTRAP 0x1b1; UTRAP 0x1b2; UTRAP 0x1b3; UTRAP 0x1b4; UTRAP 0x1b5; UTRAP 0x1b6; UTRAP 0x1b7
	UTRAP 0x1b8; UTRAP 0x1b9; UTRAP 0x1ba; UTRAP 0x1bb; UTRAP 0x1bc; UTRAP 0x1bd; UTRAP 0x1be; UTRAP 0x1bf
	UTRAP 0x1c0; UTRAP 0x1c1; UTRAP 0x1c2; UTRAP 0x1c3; UTRAP 0x1c4; UTRAP 0x1c5; UTRAP 0x1c6; UTRAP 0x1c7
	UTRAP 0x1c8; UTRAP 0x1c9; UTRAP 0x1ca; UTRAP 0x1cb; UTRAP 0x1cc; UTRAP 0x1cd; UTRAP 0x1ce; UTRAP 0x1cf
	UTRAP 0x1d0; UTRAP 0x1d1; UTRAP 0x1d2; UTRAP 0x1d3; UTRAP 0x1d4; UTRAP 0x1d5; UTRAP 0x1d6; UTRAP 0x1d7
	UTRAP 0x1d8; UTRAP 0x1d9; UTRAP 0x1da; UTRAP 0x1db; UTRAP 0x1dc; UTRAP 0x1dd; UTRAP 0x1de; UTRAP 0x1df
	UTRAP 0x1e0; UTRAP 0x1e1; UTRAP 0x1e2; UTRAP 0x1e3; UTRAP 0x1e4; UTRAP 0x1e5; UTRAP 0x1e6; UTRAP 0x1e7
	UTRAP 0x1e8; UTRAP 0x1e9; UTRAP 0x1ea; UTRAP 0x1eb; UTRAP 0x1ec; UTRAP 0x1ed; UTRAP 0x1ee; UTRAP 0x1ef
	UTRAP 0x1f0; UTRAP 0x1f1; UTRAP 0x1f2; UTRAP 0x1f3; UTRAP 0x1f4; UTRAP 0x1f5; UTRAP 0x1f6; UTRAP 0x1f7
	UTRAP 0x1f8; UTRAP 0x1f9; UTRAP 0x1fa; UTRAP 0x1fb; UTRAP 0x1fc; UTRAP 0x1fd; UTRAP 0x1fe; UTRAP 0x1ff

	/* Traps from TL>0 -- traps from supervisor mode */
trapbase_priv:
	UTRAP 0x000		! 000 = reserved -- Use it to boot
	/* We should not get the next 5 traps */
	UTRAP 0x001		! 001 = POR Reset -- ROM should get this
	UTRAP 0x002		! 002 = WDR Watchdog -- ROM should get this
	UTRAP 0x003		! 003 = XIR -- ROM should get this
	UTRAP 0x004		! 004 = SIR -- ROM should get this
	UTRAP 0x005		! 005 = RED state exception
	UTRAP 0x006; UTRAP 0x007
ktextfault:
	VTRAP T_INST_EXCEPT, textfault	! 008 = instr. access exept
	VTRAP T_TEXTFAULT, textfault	! 009 = instr. access MMU miss -- no MMU
	VTRAP T_INST_ERROR, textfault	! 00a = instr. access err
	UTRAP 0x00b; UTRAP 0x00c; UTRAP 0x00d; UTRAP 0x00e; UTRAP 0x00f
	TRAP T_ILLINST			! 010 = illegal instruction
	TRAP T_PRIVINST		! 011 = privileged instruction
	UTRAP 0x012			! 012 = unimplemented LDD
	UTRAP 0x013			! 013 = unimplemented STD
	UTRAP 0x014; UTRAP 0x015; UTRAP 0x016; UTRAP 0x017; UTRAP 0x018
	UTRAP 0x019; UTRAP 0x01a; UTRAP 0x01b; UTRAP 0x01c; UTRAP 0x01d
	UTRAP 0x01e; UTRAP 0x01f
	TRAP T_FPDISABLED		! 020 = fp instr, but EF bit off in psr
	TRAP T_FP_IEEE_754		! 021 = ieee 754 exception
	TRAP T_FP_OTHER			! 022 = other fp exception
	TRAP T_TAGOF			! 023 = tag overflow
	KCLEANWIN			! 024-027 = clean window trap
	TRAP T_DIV0			! 028 = divide by zero
	UTRAP 0x029			! 029 = internal processor error
	UTRAP 0x02a; UTRAP 0x02b; UTRAP 0x02c; UTRAP 0x02d; UTRAP 0x02e; UTRAP 0x02f
kdatafault:
	VTRAP T_DATAFAULT, winfault	! 030 = data fetch fault
	UTRAP 0x031			! 031 = data MMU miss -- no MMU
	VTRAP T_DATA_ERROR, winfault	! 032 = data fetch fault
	VTRAP T_DATA_PROT, winfault	! 033 = data fetch fault
	VTRAP T_ALIGN, checkalign	! 034 = address alignment error -- we could fix it inline...
!	sir; nop; TA8	! DEBUG -- trap all kernel alignment errors
	TRAP T_LDDF_ALIGN		! 035 = LDDF address alignment error -- we could fix it inline...
	TRAP T_STDF_ALIGN		! 036 = STDF address alignment error -- we could fix it inline...
	TRAP T_PRIVACT			! 037 = privileged action
	UTRAP 0x038; UTRAP 0x039; UTRAP 0x03a; UTRAP 0x03b; UTRAP 0x03c;
	UTRAP 0x03d; UTRAP 0x03e; UTRAP 0x03f;
	VTRAP T_ASYNC_ERROR, winfault	! 040 = data fetch fault
	SOFTINT4U 1, IE_L1		! 041 = level 1 interrupt
	HARDINT4U 2			! 042 = level 2 interrupt
	HARDINT4U 3			! 043 = level 3 interrupt
	SOFTINT4U 4, IE_L4		! 044 = level 4 interrupt
	HARDINT4U 5			! 045 = level 5 interrupt
	SOFTINT4U 6, IE_L6		! 046 = level 6 interrupt
	HARDINT4U 7			! 047 = level 7 interrupt
	HARDINT4U 8			! 048 = level 8 interrupt
	HARDINT4U 9			! 049 = level 9 interrupt
	HARDINT4U 10			! 04a = level 10 interrupt
	HARDINT4U 11			! 04b = level 11 interrupt
	ZS_INTERRUPT4U			! 04c = level 12 (zs) interrupt
	HARDINT4U 13			! 04d = level 13 interrupt
	HARDINT4U 14			! 04e = level 14 interrupt
	HARDINT4U 15			! 04f = nonmaskable interrupt
	UTRAP 0x050; UTRAP 0x051; UTRAP 0x052; UTRAP 0x053; UTRAP 0x054; UTRAP 0x055
	UTRAP 0x056; UTRAP 0x057; UTRAP 0x058; UTRAP 0x059; UTRAP 0x05a; UTRAP 0x05b
	UTRAP 0x05c; UTRAP 0x05d; UTRAP 0x05e; UTRAP 0x05f
	VTRAP 0x060, interrupt_vector; ! 060 = interrupt vector
	TRAP T_PA_WATCHPT		! 061 = physical address data watchpoint
	TRAP T_VA_WATCHPT		! 062 = virtual address data watchpoint
	VTRAP T_ECCERR, cecc_catch	! 063 = Correctable ECC error
kfast_IMMU_miss:			! 064 = fast instr access MMU miss
	IMMU_MISS 9
kfast_DMMU_miss:			! 068 = fast data access MMU miss
	DMMU_MISS 10
kfast_DMMU_protection:			! 06c = fast data access MMU protection
	DMMU_PROT kdprot
	UTRAP 0x070			! Implementation dependent traps
	UTRAP 0x071; UTRAP 0x072; UTRAP 0x073; UTRAP 0x074; UTRAP 0x075; UTRAP 0x076
	UTRAP 0x077; UTRAP 0x078; UTRAP 0x079; UTRAP 0x07a; UTRAP 0x07b; UTRAP 0x07c
	UTRAP 0x07d; UTRAP 0x07e; UTRAP 0x07f
nucleus_uspill:
	USPILL64 1,ASI_AIUS	! 0x080 spill_0_normal -- used to save user windows
	SPILL32 2,ASI_AIUS	! 0x084 spill_1_normal
	SPILLBOTH 1b,2b,ASI_AIUS	! 0x088 spill_2_normal
	UTRAP 0x08c; TA32	! 0x08c spill_3_normal
nucleus_kspill:
	UTRAP 0x090; TA32	! 0x090 spill_4_normal -- used to save supervisor windows
	SPILL64 1,ASI_N		! 0x094 spill_5_normal
	SPILL32 2,ASI_N		! 0x098 spill_6_normal
	SPILLBOTH 1b,2b,ASI_N	! 0x09c spill_7_normal
nucleus_uspillk:
	USPILL64 1,ASI_AIUS	! 0x0a0 spill_0_other -- used to save user windows in nucleus mode
	SPILL32 2,ASI_AIUS	! 0x0a4 spill_1_other
	SPILLBOTH 1b,2b,ASI_AIUS	! 0x0a8 spill_2_other
	UTRAP 0x0ac; TA32	! 0x0ac spill_3_other
	UTRAP 0x0b0; TA32	! 0x0b0 spill_4_other
	UTRAP 0x0b4; TA32	! 0x0b4 spill_5_other
	UTRAP 0x0b8; TA32	! 0x0b8 spill_6_other
	UTRAP 0x0bc; TA32	! 0x0bc spill_7_other
nucleus_ufill:
	UFILL64 1,ASI_AIUS	! 0x0c0 fill_0_normal -- used to fill windows when running nucleus mode from user
	FILL32 2,ASI_AIUS	! 0x0c4 fill_1_normal
	FILLBOTH 1b,2b,ASI_AIUS	! 0x0c8 fill_2_normal
	UTRAP 0x0cc; TA32	! 0x0cc fill_3_normal
nucleus_sfill:
	UTRAP 0x0d0; TA32	! 0x0d0 fill_4_normal -- used to fill windows when running nucleus mode from supervisor
	FILL64 1,ASI_N		! 0x0d4 fill_5_normal
	FILL32 2,ASI_N		! 0x0d8 fill_6_normal
	FILLBOTH 1b,2b,ASI_N	! 0x0dc fill_7_normal
nucleus_kfill:
	UFILL64 1,ASI_AIUS	! 0x0e0 fill_0_other -- used to fill user windows when running nucleus mode -- will we ever use this?
	FILL32 2,ASI_AIUS	! 0x0e4 fill_1_other
	FILLBOTH 1b,2b,ASI_AIUS	! 0x0e8 fill_2_other
	UTRAP 0x0ec; TA32	! 0x0ec fill_3_other
	UTRAP 0x0f0; TA32	! 0x0f0 fill_4_other
	UTRAP 0x0f4; TA32	! 0x0f4 fill_5_other
	UTRAP 0x0f8; TA32	! 0x0f8 fill_6_other
	UTRAP 0x0fc; TA32	! 0x0fc fill_7_other
nucleus_syscall:
	SYSCALL			! 0x100 = sun syscall
	TRAP T_BREAKPOINT	! 0x101 = pseudo breakpoint instruction
	STRAP 0x102; STRAP 0x103; STRAP 0x104; STRAP 0x105; STRAP 0x106; STRAP 0x107
	SYSCALL			! 0x108 = svr4 syscall
	SYSCALL			! 0x109 = bsd syscall
	TRAP T_KGDB_EXEC	! 0x10a = enter kernel gdb on kernel startup
	STRAP 0x10b; STRAP 0x10c; STRAP 0x10d; STRAP 0x10e; STRAP 0x10f;
	STRAP 0x110; STRAP 0x111; STRAP 0x112; STRAP 0x113; STRAP 0x114; STRAP 0x115; STRAP 0x116; STRAP 0x117
	STRAP 0x118; STRAP 0x119; STRAP 0x11a; STRAP 0x11b; STRAP 0x11c; STRAP 0x11d; STRAP 0x11e; STRAP 0x11f
	STRAP 0x120; STRAP 0x121; STRAP 0x122; STRAP 0x123; STRAP 0x124; STRAP 0x125; STRAP 0x126; STRAP 0x127
	STRAP 0x128; STRAP 0x129; STRAP 0x12a; STRAP 0x12b; STRAP 0x12c; STRAP 0x12d; STRAP 0x12e; STRAP 0x12f
	STRAP 0x130; STRAP 0x131; STRAP 0x132; STRAP 0x133; STRAP 0x134; STRAP 0x135; STRAP 0x136; STRAP 0x137
	STRAP 0x138; STRAP 0x139; STRAP 0x13a; STRAP 0x13b; STRAP 0x13c; STRAP 0x13d; STRAP 0x13e; STRAP 0x13f
	STRAP 0x140; STRAP 0x141; STRAP 0x142; STRAP 0x143; STRAP 0x144; STRAP 0x145; STRAP 0x146; STRAP 0x147
	STRAP 0x148; STRAP 0x149; STRAP 0x14a; STRAP 0x14b; STRAP 0x14c; STRAP 0x14d; STRAP 0x14e; STRAP 0x14f
	STRAP 0x150; STRAP 0x151; STRAP 0x152; STRAP 0x153; STRAP 0x154; STRAP 0x155; STRAP 0x156; STRAP 0x157
	STRAP 0x158; STRAP 0x159; STRAP 0x15a; STRAP 0x15b; STRAP 0x15c; STRAP 0x15d; STRAP 0x15e; STRAP 0x15f
	STRAP 0x160; STRAP 0x161; STRAP 0x162; STRAP 0x163; STRAP 0x164; STRAP 0x165; STRAP 0x166; STRAP 0x167
	STRAP 0x168; STRAP 0x169; STRAP 0x16a; STRAP 0x16b; STRAP 0x16c; STRAP 0x16d; STRAP 0x16e; STRAP 0x16f
	STRAP 0x170; STRAP 0x171; STRAP 0x172; STRAP 0x173; STRAP 0x174; STRAP 0x175; STRAP 0x176; STRAP 0x177
	STRAP 0x178; STRAP 0x179; STRAP 0x17a; STRAP 0x17b; STRAP 0x17c; STRAP 0x17d; STRAP 0x17e; STRAP 0x17f
	! Traps beyond 0x17f are reserved
	UTRAP 0x180; UTRAP 0x181; UTRAP 0x182; UTRAP 0x183; UTRAP 0x184; UTRAP 0x185; UTRAP 0x186; UTRAP 0x187
	UTRAP 0x188; UTRAP 0x189; UTRAP 0x18a; UTRAP 0x18b; UTRAP 0x18c; UTRAP 0x18d; UTRAP 0x18e; UTRAP 0x18f
	UTRAP 0x190; UTRAP 0x191; UTRAP 0x192; UTRAP 0x193; UTRAP 0x194; UTRAP 0x195; UTRAP 0x196; UTRAP 0x197
	UTRAP 0x198; UTRAP 0x199; UTRAP 0x19a; UTRAP 0x19b; UTRAP 0x19c; UTRAP 0x19d; UTRAP 0x19e; UTRAP 0x19f
	UTRAP 0x1a0; UTRAP 0x1a1; UTRAP 0x1a2; UTRAP 0x1a3; UTRAP 0x1a4; UTRAP 0x1a5; UTRAP 0x1a6; UTRAP 0x1a7
	UTRAP 0x1a8; UTRAP 0x1a9; UTRAP 0x1aa; UTRAP 0x1ab; UTRAP 0x1ac; UTRAP 0x1ad; UTRAP 0x1ae; UTRAP 0x1af
	UTRAP 0x1b0; UTRAP 0x1b1; UTRAP 0x1b2; UTRAP 0x1b3; UTRAP 0x1b4; UTRAP 0x1b5; UTRAP 0x1b6; UTRAP 0x1b7
	UTRAP 0x1b8; UTRAP 0x1b9; UTRAP 0x1ba; UTRAP 0x1bb; UTRAP 0x1bc; UTRAP 0x1bd; UTRAP 0x1be; UTRAP 0x1bf
	UTRAP 0x1c0; UTRAP 0x1c1; UTRAP 0x1c2; UTRAP 0x1c3; UTRAP 0x1c4; UTRAP 0x1c5; UTRAP 0x1c6; UTRAP 0x1c7
	UTRAP 0x1c8; UTRAP 0x1c9; UTRAP 0x1ca; UTRAP 0x1cb; UTRAP 0x1cc; UTRAP 0x1cd; UTRAP 0x1ce; UTRAP 0x1cf
	UTRAP 0x1d0; UTRAP 0x1d1; UTRAP 0x1d2; UTRAP 0x1d3; UTRAP 0x1d4; UTRAP 0x1d5; UTRAP 0x1d6; UTRAP 0x1d7
	UTRAP 0x1d8; UTRAP 0x1d9; UTRAP 0x1da; UTRAP 0x1db; UTRAP 0x1dc; UTRAP 0x1dd; UTRAP 0x1de; UTRAP 0x1df
	UTRAP 0x1e0; UTRAP 0x1e1; UTRAP 0x1e2; UTRAP 0x1e3; UTRAP 0x1e4; UTRAP 0x1e5; UTRAP 0x1e6; UTRAP 0x1e7
	UTRAP 0x1e8; UTRAP 0x1e9; UTRAP 0x1ea; UTRAP 0x1eb; UTRAP 0x1ec; UTRAP 0x1ed; UTRAP 0x1ee; UTRAP 0x1ef
	UTRAP 0x1f0; UTRAP 0x1f1; UTRAP 0x1f2; UTRAP 0x1f3; UTRAP 0x1f4; UTRAP 0x1f5; UTRAP 0x1f6; UTRAP 0x1f7
	UTRAP 0x1f8; UTRAP 0x1f9; UTRAP 0x1fa; UTRAP 0x1fb; UTRAP 0x1fc; UTRAP 0x1fd; UTRAP 0x1fe; UTRAP 0x1ff

#ifdef SUN4V

	.align	0x8000
	.globl	_C_LABEL(trapbase_sun4v)
_C_LABEL(trapbase_sun4v):
	sun4v_tl0_reserved 8				! 0x0-0x7
	VTRAP T_INST_EXCEPT, sun4v_tl0_itsb_miss	! 0x8
	VTRAP T_TEXTFAULT, sun4v_tl0_itsb_miss		! 0x9
	sun4v_tl0_reserved 6				! 0xa-0xf
	TRAP T_ILLINST					! 0x10
	TRAP T_PRIVINST					! 0x11
	sun4v_tl0_reserved 14				! 0x12-0x1f
	TRAP T_FPDISABLED				! 0x20
	TRAP T_FP_IEEE_754				! 0x21
	TRAP T_FP_OTHER					! 0x22
	TRAP T_TAGOF					! 0x23
	UCLEANWIN					! 0x24-0x27
	TRAP T_DIV0					! 0x28
	sun4v_tl0_reserved 7				! 0x29-0x2f
	VTRAP T_DATAFAULT, sun4v_datatrap		! 0x30
	VTRAP T_DATA_MMU_MISS, sun4v_tl0_dtsb_miss	! 0x31
	sun4v_tl0_reserved 2				! 0x32-0x33
	TRAP T_ALIGN					! 0x34
	TRAP T_LDDF_ALIGN				! 0x35
	TRAP T_STDF_ALIGN				! 0x36
	TRAP T_PRIVACT					! 0x37
	TRAP T_LDQF_ALIGN				! 0x38
	TRAP T_STQF_ALIGN				! 0x39
	sun4v_tl0_reserved 7				! 0x3a-0x40
	HARDINT4U 1					! 0x41
	HARDINT4U 2					! 0x42
	HARDINT4U 3					! 0x43
	HARDINT4U 4					! 0x44
	HARDINT4U 5					! 0x45
	HARDINT4U 6					! 0x46
	HARDINT4U 7					! 0x47
	HARDINT4U 8					! 0x48
	HARDINT4U 9					! 0x49
	HARDINT4U 10					! 0x4a
	HARDINT4U 11					! 0x4b
	HARDINT4U 12					! 0x4c
	HARDINT4U 13					! 0x4d
	HARDINT4U 14					! 0x4e
	HARDINT4U 15					! 0x4f
	sun4v_tl0_reserved 18				! 0x50-0x61
	TRAP T_VA_WATCHPT				! 0x62
	sun4v_tl0_reserved 9				! 0x63-0x6b
	VTRAP 0x6c, sun4v_tl0_dtsb_prot			! 0x6c
	sun4v_tl0_reserved 15				! 0x6d-0x7b
	VTRAP 0x7c, sun4v_cpu_mondo			! 0x7c
	VTRAP 0x7c, sun4v_dev_mondo			! 0x7d
	TRAP 0x7e					! 0x7e
	TRAP 0x7f					! 0x7f
	USPILL64 uspill8v, ASI_AIUS			! 0x80
	SPILL32 uspill4v, ASI_AIUS			! 0x84
	SPILLBOTH uspill8v,uspill4v, ASI_AIUS		! 0x88
	sun4v_tl0_unused 4				! 0x8c
	sun4v_tl0_unused 4				! 0x90
	SPILL64 kspill8v, ASI_N				! 0x94
	SPILL32 kspill4v, ASI_N				! 0x98
	SPILLBOTH kspill8v, kspill4v, ASI_N		! 0x9c
	USPILL64 uspillk8v, ASI_AIUS			! 0xa0
	SPILL32 uspillk4v, ASI_AIUS			! 0xa4
	SPILLBOTH uspillk8v, uspillk4v, ASI_AIUS	! 0xa8
	sun4v_tl0_unused 4				! 0xac
	sun4v_tl0_unused 16				! 0xb0-0xbc
	UFILL64 ufill8v, ASI_AIUS			! 0xc0
	FILL32 ufill4v, ASI_AIUS			! 0xc4
	FILLBOTH ufill8v, ufill4v, ASI_AIUS		! 0xc8
	sun4v_tl0_unused 4				! 0xcc
	sun4v_tl0_unused 4				! 0xd0
	FILL64 kfill8v, ASI_N				! 0xd4
	FILL32 kfill4v, ASI_N				! 0xd8
	FILLBOTH kfill8v, kfill4v, ASI_N		! 0xdc
	UFILL64 ufillk8v, ASI_AIUS			! 0xe0
	FILL32 ufillk4v, ASI_AIUS			! 0xe4
	FILLBOTH ufillk8v, ufillk4v, ASI_AIUS		! 0xe8
	sun4v_tl0_unused 4				! 0xef
	sun4v_tl0_unused 16				! 0xf0-0xfc
	SYSCALL						! 0x100
	TRAP T_BREAKPOINT				! 0x101
	sun4v_tl0_unused 6				! 0x102-0x107
	SYSCALL						! 0x108
	SYSCALL						! 0x109
	sun4v_tl0_unused 54				! 0x10a-0x13f
	SYSCALL						! 0x140
	SYSCALL						! 0x141
	SYSCALL						! 0x142
	SYSCALL						! 0x143
	sun4v_tl0_unused 60				! 0x144-0x17f
	sun4v_tl0_reserved 128				! 0x180-0x1ff

	sun4v_tl1_reserved 8				! 0x0-0x7
	TRAP T_INST_EXCEPT				! 0x8
	TRAP T_TEXTFAULT				! 0x9
	sun4v_tl1_reserved 6				! 0xa-0xf
	TRAP T_ILLINST					! 0x10
	TRAP T_PRIVINST					! 0x11
	sun4v_tl1_reserved 14				! 0x12-0x1f
	TRAP T_FPDISABLED				! 0x20
	TRAP T_FP_IEEE_754				! 0x21
	TRAP T_FP_OTHER					! 0x22
	TRAP T_TAGOF					! 0x23
	KCLEANWIN					! 0x24-0x27
	TRAP T_DIV0					! 0x28
	sun4v_tl1_reserved 7				! 0x29-0x2f
	VTRAP T_DATAFAULT, sun4v_tl1_ptbl_miss		! 0x30
	VTRAP T_DATA_MMU_MISS, sun4v_tl1_dtsb_miss	! 0x31
	VTRAP T_DATA_ERROR, sun4v_tl1_ptbl_miss
	VTRAP T_DATA_PROT, sun4v_tl1_ptbl_miss
!	sun4v_tl1_reserved 2				! 0x32-0x33
	VTRAP T_ALIGN, sun4v_tl1_ptbl_miss		! 0x34
	TRAP T_LDDF_ALIGN				! 0x35
	TRAP T_STDF_ALIGN				! 0x36
	TRAP T_PRIVACT					! 0x37
	TRAP T_LDQF_ALIGN				! 0x38
	TRAP T_STQF_ALIGN				! 0x39
	sun4v_tl1_reserved 40				! 0x3a-0x61
	TRAP T_VA_WATCHPT				! 0x62
	sun4v_tl1_reserved 9				! 0x63-0x6b
	VTRAP 0x6c, sun4v_tl1_dtsb_prot			! 0x6c
	sun4v_tl1_reserved 19				! 0x6d-0x7f
	sun4v_tl1_uspill_normal				! 0x80
	sun4v_tl1_uspill_normal				! 0x84
	sun4v_tl1_uspill_normal				! 0x88
	sun4v_tl1_unused 4				! 0x8c
	sun4v_tl1_unused 4				! 0x90
	sun4v_tl1_kspill_normal				! 0x94
	sun4v_tl1_kspill_normal				! 0x98
	sun4v_tl1_kspill_normal				! 0x9c
	sun4v_tl1_uspill_other				! 0xa0
	sun4v_tl1_uspill_other				! 0xa4
	sun4v_tl1_uspill_other				! 0xa8
	sun4v_tl1_unused 4				! 0xac
	sun4v_tl1_unused 16				! 0xb0-0xbc
	sun4v_tl1_unused 64				! 0xc0-0xfc
	sun4v_tl1_unused 128
	sun4v_tl1_reserved 128

#endif

#ifdef DEBUG
	.macro CHKREG r
	ldx	[%o0 + 8*1], %o1
	cmp	\r, %o1
	stx	%o0, [%o0]
	tne	1
	.endm
	.data
globreg_debug:
	.xword	-1, 0, 0, 0, 0, 0, 0, 0
	.text
globreg_set:
	save	%sp, -CC64FSZ, %sp
	set	globreg_debug, %o0
	.irpc n,01234567
		stx	%g\n, [%o0 + 8*\n]
	.endr
	ret
	 restore
globreg_check:
	save	%sp, -CC64FSZ, %sp
	rd	%pc, %o7
	set	globreg_debug, %o0
	ldx	[%o0], %o1
	brnz,pn	%o1, 1f		! Don't re-execute this
	.irpc n,1234567
		CHKREG %g\n
	.endr
	nop
1:	ret
	 restore

	/*
	 * Checkpoint:	 store a byte value at DATA_START+0x21
	 *		uses two temp regs
	 */
	.macro CHKPT r1,r2,val
	sethi	%hi(DATA_START), \r1
	mov	\val, \r2
	stb	\r2, [\r1 + 0x21]
	.endm

	/*
	 * Debug routine:
	 *
	 * If datafault manages to get an unaligned pmap entry
	 * we come here.  We want to save as many regs as we can.
	 * %g3 has the sfsr, and %g7 the result of the wstate
	 * both of which we can toast w/out much lossage.
	 *
	 */
	.data
pmap_dumpflag:
	.xword	0		! semaphore
	.globl	pmap_dumparea	! Get this into the kernel syms
pmap_dumparea:
	.space	(32*8)		! room to save 32 registers
pmap_edumparea:
	.text
pmap_screwup:
	rd	%pc, %g3
	sub	%g3, (pmap_edumparea-pmap_dumparea), %g3	! pc relative addressing 8^)
	ldstub	[%g3+( 0*0x8)], %g3
	tst	%g3		! Semaphore set?
	tnz	%xcc, 1; nop		! Then trap
	set	pmap_dumparea, %g3
	stx	%g3, [%g3+( 0*0x8)]	! set semaphore
	stx	%g1, [%g3+( 1*0x8)]	! Start saving regs
	stx	%g2, [%g3+( 2*0x8)]
	stx	%g3, [%g3+( 3*0x8)]	! Redundant, I know...
	stx	%g4, [%g3+( 4*0x8)]
	stx	%g5, [%g3+( 5*0x8)]
	stx	%g6, [%g3+( 6*0x8)]
	stx	%g7, [%g3+( 7*0x8)]
	stx	%i0, [%g3+( 8*0x8)]
	stx	%i1, [%g3+( 9*0x8)]
	stx	%i2, [%g3+(10*0x8)]
	stx	%i3, [%g3+(11*0x8)]
	stx	%i4, [%g3+(12*0x8)]
	stx	%i5, [%g3+(13*0x8)]
	stx	%i6, [%g3+(14*0x8)]
	stx	%i7, [%g3+(15*0x8)]
	stx	%l0, [%g3+(16*0x8)]
	stx	%l1, [%g3+(17*0x8)]
	stx	%l2, [%g3+(18*0x8)]
	stx	%l3, [%g3+(19*0x8)]
	stx	%l4, [%g3+(20*0x8)]
	stx	%l5, [%g3+(21*0x8)]
	stx	%l6, [%g3+(22*0x8)]
	stx	%l7, [%g3+(23*0x8)]
	stx	%o0, [%g3+(24*0x8)]
	stx	%o1, [%g3+(25*0x8)]
	stx	%o2, [%g3+(26*0x8)]
	stx	%o3, [%g3+(27*0x8)]
	stx	%o4, [%g3+(28*0x8)]
	stx	%o5, [%g3+(29*0x8)]
	stx	%o6, [%g3+(30*0x8)]
	stx	%o7, [%g3+(31*0x8)]
	ta	1; nop		! Break into the debugger

#else	/* DEBUG */
	.macro CHKPT r1,r2,val
	.endm
#endif	/* DEBUG */

#ifdef DEBUG_NOTDEF
/*
 * A hardware red zone is impossible.  We simulate one in software by
 * keeping a `red zone' pointer; if %sp becomes less than this, we panic.
 * This is expensive and is only enabled when debugging.
 */
#define	REDSIZE	(USIZ)		/* Mark used portion of user structure out of bounds */
#define	REDSTACK 2048		/* size of `panic: stack overflow' region */
	.data
	_ALIGN
redzone:
	.xword	0
redstack:
	.space	REDSTACK
eredstack:
Lpanic_red:
	.asciz	"kernel stack overflow"
	_ALIGN
	.text

	! set stack pointer redzone to base+minstack; alters base
.macro	SET_SP_REDZONE base, tmp
	add	\base, REDSIZE, \base
	sethi	%hi(_C_LABEL(redzone)), \tmp
	stx	\base, [\tmp + %lo(_C_LABEL(redzone))]
	.endm

	! variant with a constant
.macro	SET_SP_REDZONE_CONST const,  tmp1,  tmp2
	set	(\const) + REDSIZE, \tmp1
	sethi	%hi(_C_LABEL(redzone)), \tmp2
	stx	\tmp1, [\tmp2 + %lo(_C_LABEL(redzone))]
	.endm

	! check stack pointer against redzone (uses two temps)
.macro	CHECK_SP_REDZONE t1,  t2
	sethi	KERNBASE, \t1
	cmp	%sp, \t1
	blu,pt	%xcc, 7f
	 sethi	%hi(_C_LABEL(redzone)), \t1
	ldx	[\t1 + %lo(_C_LABEL(redzone))], \t2
	cmp	%sp, \t2	! if sp >= \t2, not in red zone
	blu	panic_red
	nop	! and can continue normally
7:
	.endm

panic_red:
	/* move to panic stack */
	stx	%g0, [t1 + %lo(_C_LABEL(redzone))];
	set	eredstack - BIAS, %sp;
	/* prevent panic() from lowering ipl */
	sethi	%hi(_C_LABEL(panicstr)), t2;
	set	Lpanic_red, t2;
	st	t2, [t1 + %lo(_C_LABEL(panicstr))];
	wrpr	g0, 15, %pil		/* t1 = splhigh() */
	save	%sp, -CCF64SZ, %sp;	/* preserve current window */
	sethi	%hi(Lpanic_red), %o0;
	call	_C_LABEL(panic);
	 or %o0, %lo(Lpanic_red), %o0;


#else	/* DEBUG_NOTDEF */

.macro	SET_SP_REDZONE base, tmp
.endm
.macro	SET_SP_REDZONE_CONST const, t1, t2
.endm
.macro	CHECK_SP_REDZONE t1, t2
.endm
#endif	/* DEBUG_NOTDEF */

/*
 * v9 machines do not have a trap window.
 *
 * When we take a trap the trap state is pushed on to the stack of trap
 * registers, interrupts are disabled, then we switch to an alternate set
 * of global registers.
 *
 * The trap handling code needs to allocate a trap frame on the kernel, or
 * for interrupts, the interrupt stack, save the out registers to the trap
 * frame, then switch to the normal globals and save them to the trap frame
 * too.
 *
 * XXX it would be good to save the interrupt stack frame to the kernel
 * stack so we wouldn't have to copy it later if we needed to handle a AST.
 *
 * Since kernel stacks are all on one page and the interrupt stack is entirely
 * within the locked TLB, we can use physical addressing to save out our
 * trap frame so we don't trap during the TRAP_SETUP operation.  There
 * is unfortunately no supportable method for issuing a non-trapping save.
 *
 * However, if we use physical addresses to save our trapframe, we will need
 * to clear out the data cache before continuing much further.
 *
 * In short, what we need to do is:
 *
 *	all preliminary processing is done using the alternate globals
 *
 *	When we allocate our trap windows we must give up our globals because
 *	their state may have changed during the save operation
 *
 *	we need to save our normal globals as soon as we have a stack
 *
 * Finally, we may now call C code.
 *
 * This macro will destroy %g5-%g7.  %g0-%g4 remain unchanged.
 *
 * In order to properly handle nested traps without lossage, alternate
 * global %g6 is used as a kernel stack pointer.  It is set to the last
 * allocated stack pointer (trapframe) and the old value is stored in
 * tf_kstack.  It is restored when returning from a trap.  It is cleared
 * on entering user mode.
 */

 /*
  * Other misc. design criteria:
  *
  * When taking an address fault, fault info is in the sfsr, sfar,
  * TLB_TAG_ACCESS registers.  If we take another address fault
  * while trying to handle the first fault then that information,
  * the only information that tells us what address we trapped on,
  * can potentially be lost.  This trap can be caused when allocating
  * a register window with which to handle the trap because the save
  * may try to store or restore a register window that corresponds
  * to part of the stack that is not mapped.  Preventing this trap,
  * while possible, is much too complicated to do in a trap handler,
  * and then we will need to do just as much work to restore the processor
  * window state.
  *
  * Possible solutions to the problem:
  *
  * Since we have separate AG, MG, and IG, we could have all traps
  * above level-1 preserve AG and use other registers.  This causes
  * a problem for the return from trap code which is coded to use
  * alternate globals only.
  *
  * We could store the trapframe and trap address info to the stack
  * using physical addresses.  Then we need to read it back using
  * physical addressing, or flush the D$.
  *
  * We could identify certain registers to hold address fault info.
  * This means that these registers need to be preserved across all
  * fault handling.  But since we only have 7 useable globals, that
  * really puts a cramp in our style.
  *
  * Finally, there is the issue of returning from kernel mode to user
  * mode.  If we need to issue a restore of a user window in kernel
  * mode, we need the window control registers in a user mode setup.
  * If the trap handlers notice the register windows are in user mode,
  * they will allocate a trapframe at the bottom of the kernel stack,
  * overwriting the frame we were trying to return to.  This means that
  * we must complete the restoration of all registers *before* switching
  * to a user-mode window configuration.
  *
  * Essentially we need to be able to write re-entrant code w/no stack.
  */
	.data
trap_setup_msg:
	.asciz	"TRAP_SETUP: tt=%x osp=%x nsp=%x tl=%x tpc=%x\n"
	_ALIGN
intr_setup_msg:
	.asciz	"INTR_SETUP: tt=%x osp=%x nsp=%x tl=%x tpc=%x\n"
	_ALIGN
	.text

	.macro	TRAP_SETUP stackspace
	GET_CPCB(%g6)
	sethi	%hi((\stackspace)), %g5
	sethi	%hi(USPACE), %g7		! Always multiple of page size
	or	%g5, %lo((\stackspace)), %g5

	sra	%g5, 0, %g5			! Sign extend the damn thing

	add	%g6, %g7, %g6
	rdpr	%wstate, %g7			! Find if we're from user mode

	sub	%g7, WSTATE_KERN, %g7		! Compare & leave in register
	movrz	%g7, %sp, %g6			! Select old (kernel) stack or base of kernel stack
	btst	1, %g6				! Fixup 64-bit stack if necessary
	bnz,pt	%icc, 1f
	 add	%g6, %g5, %g6			! Allocate a stack frame
	inc	-BIAS, %g6
	nop
	nop
1:
	SPILL stx, %g6 + CC64FSZ + BIAS + TF_L, 8, ! save local + in
	save	%g6, 0, %sp			! If we fault we should come right back here
	stx	%i0, [%sp + CC64FSZ + BIAS + TF_O + (0*8)] ! Save out registers to trap frame
	stx	%i1, [%sp + CC64FSZ + BIAS + TF_O + (1*8)]
	stx	%i2, [%sp + CC64FSZ + BIAS + TF_O + (2*8)]
	stx	%i3, [%sp + CC64FSZ + BIAS + TF_O + (3*8)]
	stx	%i4, [%sp + CC64FSZ + BIAS + TF_O + (4*8)]
	stx	%i5, [%sp + CC64FSZ + BIAS + TF_O + (5*8)]

	stx	%i6, [%sp + CC64FSZ + BIAS + TF_O + (6*8)]
	brz,pt	%g7, 1f			! If we were in kernel mode start saving globals
	 stx	%i7, [%sp + CC64FSZ + BIAS + TF_O + (7*8)]

	! came from user mode -- switch to kernel mode stack
	rdpr	%canrestore, %g5		! Fixup register window state registers
	wrpr	%g0, 0, %canrestore
	wrpr	%g0, %g5, %otherwin
	wrpr	%g0, WSTATE_KERN, %wstate	! Enable kernel mode window traps -- now we can trap again

	mov	CTX_PRIMARY, %g7
	SET_MMU_CONTEXTID(%g0, %g7)		! Switch MMU to kernel primary context
	sethi	%hi(KERNBASE), %g5
	membar	#Sync				! XXXX Should be taken care of by flush
	flush	%g5				! Some convenient address that won't trap
1:
	.endm
	
/*
 * Interrupt setup is almost exactly like trap setup, but we need to
 * go to the interrupt stack if (a) we came from user mode or (b) we
 * came from kernel mode on the kernel stack.
 *
 * We don't guarantee that any registers are preserved during this operation,
 * so we can be more efficient.
 */
	.macro	INTR_SETUP stackspace
	rdpr	%wstate, %g7			! Find if we're from user mode

	GET_CPUINFO_VA(%g6)
	sethi	%hi(EINTSTACK-INTSTACK), %g4
	sub	%g6, BIAS, %g6			! Base of interrupt stack
	dec	%g4				! Make it into a mask

	sub	%g6, %sp, %g1			! Offset from interrupt stack
	sethi	%hi((\stackspace)), %g5

	or	%g5, %lo((\stackspace)), %g5

	andn	%g1, %g4, %g4			! Are we out of the interrupt stack range?
	xor	%g7, WSTATE_KERN, %g3

	sra	%g5, 0, %g5			! Sign extend the damn thing
	or	%g3, %g4, %g4			! Definitely not off the interrupt stack

	movrz	%g4, %sp, %g6

	add	%g6, %g5, %g5			! Allocate a stack frame
	btst	1, %g6
	bnz,pt	%icc, 1f
	 mov	%g5, %g6

	add	%g5, -BIAS, %g6

1:
	SPILL stx, %g6 + CC64FSZ + BIAS + TF_L, 8,  ! save local+in to trap frame
	save	%g6, 0, %sp			! If we fault we should come right back here
	stx	%i0, [%sp + CC64FSZ + BIAS + TF_O + (0*8)] ! Save out registers to trap frame
	stx	%i1, [%sp + CC64FSZ + BIAS + TF_O + (1*8)]
	stx	%i2, [%sp + CC64FSZ + BIAS + TF_O + (2*8)]
	stx	%i3, [%sp + CC64FSZ + BIAS + TF_O + (3*8)]
	stx	%i4, [%sp + CC64FSZ + BIAS + TF_O + (4*8)]

	stx	%i5, [%sp + CC64FSZ + BIAS + TF_O + (5*8)]
	stx	%i6, [%sp + CC64FSZ + BIAS + TF_O + (6*8)]
	brz,pt	%g3, 1f				! If we were in kernel mode start saving globals
	 stx	%i7, [%sp + CC64FSZ + BIAS + TF_O + (7*8)]

	! came from user mode -- switch to kernel mode stack
	rdpr	%canrestore, %g5		! Fixup register window state registers
	wrpr	%g0, 0, %canrestore
	wrpr	%g0, %g5, %otherwin
	wrpr	%g0, WSTATE_KERN, %wstate	! Enable kernel mode window traps -- now we can trap again

	mov	CTX_PRIMARY, %g7
	SET_MMU_CONTEXTID(%g0, %g7)		! Switch MMU to kernel primary context
	sethi	%hi(KERNBASE), %g5
	membar	#Sync				! XXXX Should be taken care of by flush
	flush	%g5				! Some convenient address that won't trap
1:
	.endm

/*
 * This is the MMU protection handler.  It's too big to fit
 * in the trap table so I moved it here.  It's relatively simple.
 * It looks up the page mapping in the page table associated with
 * the trapping context.  It checks to see if the S/W writable bit
 * is set.  If so, it sets the H/W write bit, marks the tte modified,
 * and enters the mapping into the MMU.  Otherwise it does a regular
 * data fault.
 *
 *
 */
	ICACHE_ALIGN
dmmu_write_fault:
	mov	TLB_TAG_ACCESS, %g3
	sethi	%hi(0x1fff), %g6			! 8K context mask
	ldxa	[%g3] ASI_DMMU, %g3			! Get fault addr from Tag Target
	sethi	%hi(_C_LABEL(ctxbusy)), %g4
	or	%g6, %lo(0x1fff), %g6
	ldx	[%g4 + %lo(_C_LABEL(ctxbusy))], %g4
	srax	%g3, HOLESHIFT, %g5			! Check for valid address
	and	%g3, %g6, %g6				! Isolate context
	
	inc	%g5					! (0 or -1) -> (1 or 0)
	sllx	%g6, 3, %g6				! Make it into an offset into ctxbusy
	ldx	[%g4+%g6], %g4				! Load up our page table.
	srlx	%g3, STSHIFT, %g6
	cmp	%g5, 1
	bgu,pn %xcc, winfix				! Error!
	 srlx	%g3, PDSHIFT, %g5
	and	%g6, STMASK, %g6
	sll	%g6, 3, %g6
	
	and	%g5, PDMASK, %g5
	sll	%g5, 3, %g5
	add	%g6, %g4, %g4
	DLFLUSH %g4,%g6
	ldxa	[%g4] ASI_PHYS_CACHED, %g4
	DLFLUSH2 %g6
	srlx	%g3, PTSHIFT, %g6			! Convert to ptab offset
	and	%g6, PTMASK, %g6
	add	%g5, %g4, %g5
	brz,pn	%g4, winfix				! NULL entry? check somewhere else
	
	 nop	
	ldxa	[%g5] ASI_PHYS_CACHED, %g4
	sll	%g6, 3, %g6
	brz,pn	%g4, winfix				! NULL entry? check somewhere else
	 add	%g6, %g4, %g6
1:
	ldxa	[%g6] ASI_PHYS_CACHED, %g4
	brgez,pn %g4, winfix				! Entry invalid?  Punt
	 or	%g4, SUN4U_TLB_MODIFY|SUN4U_TLB_ACCESS|SUN4U_TLB_W, %g7
		! Update the modified bit
	
	btst	SUN4U_TLB_REAL_W|SUN4U_TLB_W, %g4	! Is it a ref fault?
	bz,pn	%xcc, winfix				! No -- really fault
#ifdef DEBUG
	/* Make sure we don't try to replace a kernel translation */
	/* This should not be necessary */
	sllx	%g3, 64-13, %g2				! Isolate context bits
	sethi	%hi(KERNBASE), %g5			! Don't need %lo
	brnz,pt	%g2, 0f					! Ignore context != 0
	 set	0x0800000, %g2				! 8MB
	sub	%g3, %g5, %g5
	cmp	%g5, %g2
	tlu	%xcc, 1; nop
	blu,pn	%xcc, winfix				! Next instruction in delay slot is unimportant
0:
#endif	/* DEBUG */
	/* Need to check for and handle large pages. */
	 srlx	%g4, 61, %g5				! Isolate the size bits
	ldxa	[%g0] ASI_DMMU_8KPTR, %g2		! Load DMMU 8K TSB pointer
	andcc	%g5, 0x3, %g5				! 8K?
	bnz,pn	%icc, winfix				! We punt to the pmap code since we can't handle policy
	 ldxa	[%g0] ASI_DMMU, %g1			! Hard coded for unified 8K TSB		Load DMMU tag target register
	casxa	[%g6] ASI_PHYS_CACHED, %g4, %g7		!  and write it out
	
	membar	#StoreLoad
	cmp	%g4, %g7
	bne,pn	%xcc, 1b
	 or	%g4, SUN4U_TLB_MODIFY|SUN4U_TLB_ACCESS|SUN4U_TLB_W, %g4
		! Update the modified bit

1:
#ifdef MULTIPROCESSOR
	ld	[%g2], %g6
	btst	(TSB_TAG_LOCKED >> 32), %g6
	bnz,pn	%icc, 1b
	 or	%g6, (TSB_TAG_LOCKED >> 32), %g5
	casa	[%g2] ASI_NUCLEUS, %g6, %g5
	cmp	%g6, %g5
	bne,pn	%icc, 1b
	 nop
	membar  #StoreStore
#endif
	stx	%g4, [%g2 + 8]				! Update TSB entry data
	mov	SFSR, %g7
	stx	%g1, [%g2]				! Update TSB entry tag
	nop
#ifdef DEBUG
	set	DATA_START, %g6	! debug
	stx	%g1, [%g6+0x40]	! debug
	set	0x88, %g5	! debug
	stx	%g4, [%g6+0x48]	! debug -- what we tried to enter in TLB
	stb	%g5, [%g6+0x8]	! debug
#endif	/* DEBUG */
	mov	DEMAP_PAGE_SECONDARY, %g1		! Secondary flush
	mov	DEMAP_PAGE_NUCLEUS, %g5			! Nucleus flush
	stxa	%g0, [%g7] ASI_DMMU			! clear out the fault
	membar	#Sync
	sllx	%g3, (64-13), %g7			! Need to demap old entry first
	andn	%g3, 0xfff, %g6
	movrz	%g7, %g5, %g1				! Pick one
	or	%g6, %g1, %g6
	stxa	%g6, [%g6] ASI_DMMU_DEMAP		! Do the demap
	membar	#Sync					! No real reason for this XXXX
	
	stxa	%g4, [%g0] ASI_DMMU_DATA_IN		! Enter new mapping
	membar	#Sync
	retry

/*
 * Each memory data access fault from a fast access miss handler comes here.
 * We will quickly check if this is an original prom mapping before going
 * to the generic fault handler
 *
 * We will assume that %pil is not lost so we won't bother to save it
 * unless we're in an interrupt handler.
 *
 * On entry:
 *	We are on one of the alternate set of globals
 *	%g1 = MMU tag target
 *	%g2 = 8Kptr
 *	%g3 = TLB TAG ACCESS
 *
 * On return:
 *
 */
	ICACHE_ALIGN
data_miss:
	mov	TLB_TAG_ACCESS, %g3			! Get real fault page
	sethi	%hi(0x1fff), %g6			! 8K context mask
	ldxa	[%g3] ASI_DMMU, %g3			! from tag access register
	sethi	%hi(_C_LABEL(ctxbusy)), %g4
	or	%g6, %lo(0x1fff), %g6
	ldx	[%g4 + %lo(_C_LABEL(ctxbusy))], %g4
	srax	%g3, HOLESHIFT, %g5			! Check for valid address
	and	%g3, %g6, %g6				! Isolate context
	
	inc	%g5					! (0 or -1) -> (1 or 0)
	sllx	%g6, 3, %g6				! Make it into an offset into ctxbusy
	ldx	[%g4+%g6], %g4				! Load up our page table.
#ifdef DEBUG
	/* Make sure we don't try to replace a kernel translation */
	/* This should not be necessary */
	brnz,pt	%g6, 1f			! If user context continue miss
	sethi	%hi(KERNBASE), %g7			! Don't need %lo
	set	0x0800000, %g6				! 8MB
	sub	%g3, %g7, %g7
	cmp	%g7, %g6
	sethi	%hi(DATA_START), %g7
	mov	6, %g6		! debug
	stb	%g6, [%g7+0x20]	! debug
	tlu	%xcc, 1; nop
	blu,pn	%xcc, winfix				! Next instruction in delay slot is unimportant
	 mov	7, %g6		! debug
	stb	%g6, [%g7+0x20]	! debug
1:	
#endif	/* DEBUG */
	srlx	%g3, STSHIFT, %g6
	cmp	%g5, 1
	bgu,pn %xcc, winfix				! Error!
	 srlx	%g3, PDSHIFT, %g5
	and	%g6, STMASK, %g6
	
	sll	%g6, 3, %g6
	and	%g5, PDMASK, %g5
	sll	%g5, 3, %g5
	add	%g6, %g4, %g4
	ldxa	[%g4] ASI_PHYS_CACHED, %g4
	srlx	%g3, PTSHIFT, %g6			! Convert to ptab offset
	and	%g6, PTMASK, %g6
	add	%g5, %g4, %g5
	brz,pn	%g4, data_nfo				! NULL entry? check somewhere else
	
	 nop
	ldxa	[%g5] ASI_PHYS_CACHED, %g4
	sll	%g6, 3, %g6
	brz,pn	%g4, data_nfo				! NULL entry? check somewhere else
	 add	%g6, %g4, %g6
1:
	ldxa	[%g6] ASI_PHYS_CACHED, %g4
	brgez,pn %g4, data_nfo				! Entry invalid?  Punt
	 or	%g4, SUN4U_TLB_ACCESS, %g7		! Update the access bit
	
	btst	SUN4U_TLB_ACCESS, %g4			! Need to update access git?
	bne,pt	%xcc, 1f
	 nop
	casxa	[%g6] ASI_PHYS_CACHED, %g4, %g7		!  and write it out
	cmp	%g4, %g7
	bne,pn	%xcc, 1b
	 or	%g4, SUN4U_TLB_ACCESS, %g4		! Update the modified bit

1:
#ifdef MULTIPROCESSOR
	ld	[%g2], %g6
	btst	(TSB_TAG_LOCKED >> 32), %g6
	bnz,pn	%icc, 1b
	 or	%g6, (TSB_TAG_LOCKED >> 32), %g5
	casa	[%g2] ASI_NUCLEUS, %g6, %g5
	cmp	%g6, %g5
	bne,pn	%icc, 1b
	 nop
	membar  #StoreStore
#endif
	stx	%g4, [%g2 + 8]				! Update TSB entry data
	stx	%g1, [%g2]				! Update TSB entry tag

#ifdef DEBUG
	set	DATA_START, %g6	! debug
	stx	%g3, [%g6+8]	! debug
	set	0xa, %g5	! debug
	stx	%g4, [%g6]	! debug -- what we tried to enter in TLB
	stb	%g5, [%g6+0x20]	! debug
#endif	/* DEBUG */
#if 0
	/* This was a miss -- should be nothing to demap. */
	sllx	%g3, (64-13), %g6			! Need to demap old entry first
	mov	DEMAP_PAGE_SECONDARY, %g1		! Secondary flush
	mov	DEMAP_PAGE_NUCLEUS, %g5			! Nucleus flush
	movrz	%g6, %g5, %g1				! Pick one
	andn	%g3, 0xfff, %g6
	or	%g6, %g1, %g6
	stxa	%g6, [%g6] ASI_DMMU_DEMAP		! Do the demap
	membar	#Sync					! No real reason for this XXXX
#endif	/* 0 */
	stxa	%g4, [%g0] ASI_DMMU_DATA_IN		! Enter new mapping
	membar	#Sync
	CLRTT
	retry
	NOTREACHED
/*
 * We had a data miss but did not find a mapping.  Insert
 * a NFO mapping to satisfy speculative loads and return.
 * If this had been a real load, it will re-execute and
 * result in a data fault or protection fault rather than
 * a TLB miss.  We insert an 8K TTE with the valid and NFO
 * bits set.  All others should zero.  The TTE looks like this:
 *
 *	0x9000000000000000
 *
 */
data_nfo:
	sethi	%hi(0x90000000), %g4			! V(0x8)|NFO(0x1)
	sllx	%g4, 32, %g4
	stxa	%g4, [%g0] ASI_DMMU_DATA_IN		! Enter new mapping
	membar	#Sync
	CLRTT
	retry	

/*
 * Handler for making the trap window shiny clean.
 *
 * If the store that trapped was to a kernel address, panic.
 *
 * If the store that trapped was to a user address, stick it in the PCB.
 * Since we don't want to force user code to use the standard register
 * convention if we don't have to, we will not assume that %fp points to
 * anything valid.
 *
 * On entry:
 *	We are on one of the alternate set of globals
 *	%g1 = %tl - 1, tstate[tl-1], scratch	- local
 *	%g2 = %tl				- local
 *	%g3 = MMU tag access			- in
 *	%g4 = %cwp				- local
 *	%g5 = scratch				- local
 *	%g6 = cpcb				- local
 *	%g7 = scratch				- local
 *
 * On return:
 *
 * NB:	 remove most of this from main codepath & cleanup I$
 */
winfault:
#ifdef DEBUG
	sethi	%hi(DATA_START), %g7			! debug
!	stx	%g0, [%g7]				! debug This is a real fault -- prevent another trap from watchdoging
	set	0x10, %g4				! debug
	stb	%g4, [%g7 + 0x20]			! debug
	CHKPT %g4,%g7,0x19
#endif	/* DEBUG */
	mov	TLB_TAG_ACCESS, %g3	! Get real fault page from tag access register
	ldxa	[%g3] ASI_DMMU, %g3	! And put it into the non-MMU alternate regs
winfix:
	rdpr	%tl, %g2
	subcc	%g2, 1, %g1
	brlez,pt	%g1, datafault	! Don't go below trap level 1
	 nop

	CHKPT %g4,%g7,0x20
	wrpr	%g1, 0, %tl		! Pop a trap level
	rdpr	%tt, %g7		! Read type of prev. trap
	rdpr	%tstate, %g4		! Try to restore prev %cwp if we were executing a restore
	andn	%g7, 0x3f, %g5		!   window fill traps are all 0b 0000 11xx xxxx

#if 1
	cmp	%g7, 0x68		! If we took a datafault just before this trap
	bne,pt	%icc, winfixfill	! our stack's probably bad so we need to switch somewhere else
	 nop

	!!
	!! Double data fault -- bad stack?
	!!
	wrpr	%g2, %tl	! Restore trap level.
	sir			! Just issue a reset and don't try to recover.
	mov	%fp, %l6		! Save the frame pointer
	set	EINTSTACK+USPACE+CC64FSZ-BIAS, %fp ! Set the frame pointer to the middle of the idle stack
	add	%fp, -CC64FSZ, %sp	! Create a stackframe
	wrpr	%g0, 15, %pil		! Disable interrupts, too
	wrpr	%g0, %g0, %canrestore	! Our stack is hozed and our PCB
	wrpr	%g0, 7, %cansave	!  probably is too, so blow away
	ba	slowtrap		!  all our register windows.
	 wrpr	%g0, 0x101, %tt
#endif	/* 1 */

winfixfill:
	cmp	%g5, 0x0c0		!   so we mask lower bits & compare to 0b 0000 1100 0000
	bne,pt	%icc, winfixspill	! Dump our trap frame -- we will retry the fill when the page is loaded
	 cmp	%g5, 0x080		!   window spill traps are all 0b 0000 10xx xxxx

	!!
	!! This was a fill
	!!
	btst	TSTATE_PRIV, %g4	! User mode?
	and	%g4, CWP, %g5		! %g4 = %cwp of trap
	wrpr	%g7, 0, %tt
	bz,a,pt	%icc, datafault		! We were in user mode -- normal fault
	 wrpr	%g5, %cwp		! Restore cwp from before fill trap -- regs should now be consistent

	/*
	 * We're in a pickle here.  We were trying to return to user mode
	 * and the restore of the user window failed, so now we have one valid
	 * kernel window and a user window state.  If we do a TRAP_SETUP now,
	 * our kernel window will be considered a user window and cause a
	 * fault when we try to save it later due to an invalid user address.
	 * If we return to where we faulted, our window state will not be valid
	 * and we will fault trying to enter user with our primary context of zero.
	 *
	 * What we'll do is arrange to have us return to return_from_trap so we will
	 * start the whole business over again.  But first, switch to a kernel window
	 * setup.  Let's see, canrestore and otherwin are zero.  Set WSTATE_KERN and
	 * make sure we're in kernel context and we're done.
	 */

#if 0 /* Need to switch over to new stuff to fix WDR bug */
	wrpr	%g5, %cwp				! Restore cwp from before fill trap -- regs should now be consistent
	wrpr	%g2, %g0, %tl				! Restore trap level -- we need to reuse it
	set	return_from_trap, %g4
	set	CTX_PRIMARY, %g7
	wrpr	%g4, 0, %tpc
	stxa	%g0, [%g7] ASI_DMMU
	inc	4, %g4
	membar	#Sync
	flush	%g4					! Isn't this convenient?
	wrpr	%g0, WSTATE_KERN, %wstate
	wrpr	%g0, 0, %canrestore			! These should be zero but
	wrpr	%g0, 0, %otherwin			! clear them just in case
	rdpr	%ver, %g5
	and	%g5, CWP, %g5
	wrpr	%g0, 0, %cleanwin
	dec	1, %g5					! NWINDOWS-1-1
	wrpr	%g5, 0, %cansave			! Invalidate all windows
	CHKPT %g5,%g7,0xe
!	flushw						! DEBUG
	ba,pt	%icc, datafault
	 wrpr	%g4, 0, %tnpc
#else	/* 0 - Need to switch over to new stuff to fix WDR bug */
	wrpr	%g2, %g0, %tl				! Restore trap level
	cmp	%g2, 3
	tne	%icc, 1
	rdpr	%tt, %g5
	wrpr	%g0, 1, %tl				! Revert to TL==1 XXX what if this wasn't in rft_user? Oh well.
	wrpr	%g5, %g0, %tt				! Set trap type correctly
	CHKPT %g5,%g7,0xe
/*
 * Here we need to implement the beginning of datafault.
 * TRAP_SETUP expects to come from either kernel mode or
 * user mode with at least one valid register window.  It
 * will allocate a trap frame, save the out registers, and
 * fix the window registers to think we have one user
 * register window.
 *
 * However, under these circumstances we don't have any
 * valid register windows, so we need to clean up the window
 * registers to prevent garbage from being saved to either
 * the user stack or the PCB before calling the datafault
 * handler.
 *
 * We could simply jump to datafault if we could somehow
 * make the handler issue a `saved' instruction immediately
 * after creating the trapframe.
 *
 * The fillowing is duplicated from datafault:
 */
	wrpr	%g0, PSTATE_KERN|PSTATE_AG, %pstate	! We need to save volatile stuff to AG regs
#ifdef DEBUG
	set	DATA_START, %g7				! debug
	set	0x20, %g6				! debug
	stx	%g0, [%g7]				! debug
	stb	%g6, [%g7 + 0x20]			! debug
	CHKPT %g4,%g7,0xf
#endif	/* DEBUG */
	wr	%g0, ASI_DMMU, %asi			! We need to re-load trap info
	ldxa	[%g0 + TLB_TAG_ACCESS] %asi, %g1	! Get fault address from tag access register
	ldxa	[SFAR] %asi, %g2			! sync virt addr; must be read first
	ldxa	[SFSR] %asi, %g3			! get sync fault status register
	stxa	%g0, [SFSR] %asi			! Clear out fault now
	membar	#Sync					! No real reason for this XXXX

	TRAP_SETUP -CC64FSZ-TF_SIZE
	saved						! Blow away that one register window we didn't ever use.
	ba,a,pt	%icc, Ldatafault_internal		! Now we should return directly to user mode
	 nop
#endif	/* 0 - Need to switch over to new stuff to fix WDR bug */
winfixspill:
	bne,a,pt	%xcc, datafault				! Was not a spill -- handle it normally
	 wrpr	%g2, 0, %tl				! Restore trap level for now XXXX

	!!
	!! This was a spill
	!!
#if 1
	btst	TSTATE_PRIV, %g4			! From user mode?
!	cmp	%g2, 2					! From normal execution? take a fault.
	wrpr	%g2, 0, %tl				! We need to load the fault type so we can
	rdpr	%tt, %g5				! overwrite the lower trap and get it to the fault handler
	wrpr	%g1, 0, %tl
	wrpr	%g5, 0, %tt				! Copy over trap type for the fault handler
	and	%g4, CWP, %g5				! find %cwp from trap

	be,a,pt	%xcc, datafault				! Let's do a regular datafault.  When we try a save in datafault we'll
	 wrpr	%g5, 0, %cwp				!  return here and write out all dirty windows.
#endif	/* 1 */
	wrpr	%g2, 0, %tl				! Restore trap level for now XXXX
	GET_CPCB(%g6)
#ifdef DEBUG
	set	0x12, %g5				! debug
	sethi	%hi(DATA_START), %g7			! debug
	stb	%g5, [%g7 + 0x20]			! debug
	CHKPT %g5,%g7,0x11
#endif	/* DEBUG */

	/*
	 * Traverse kernel map to find paddr of cpcb and only us ASI_PHYS_CACHED to
	 * prevent any faults while saving the windows.  BTW if it isn't mapped, we
	 * will trap and hopefully panic.
	 */

!	ba	0f					! DEBUG -- don't use phys addresses
	 wr	%g0, ASI_NUCLEUS, %asi			! In case of problems finding PA
	sethi	%hi(_C_LABEL(ctxbusy)), %g1
	ldx	[%g1 + %lo(_C_LABEL(ctxbusy))], %g1	! Load start of ctxbusy
#ifdef DEBUG
	srax	%g6, HOLESHIFT, %g7			! Check for valid address
	brz,pt	%g7, 1f					! Should be zero or -1
	 addcc	%g7, 1, %g7					! Make -1 -> 0
	tnz	%xcc, 1					! Invalid address??? How did this happen?
1:
#endif	/* DEBUG */
	srlx	%g6, STSHIFT, %g7
	ldx	[%g1], %g1				! Load pointer to kernel_pmap
	and	%g7, STMASK, %g7
	sll	%g7, 3, %g7
	add	%g7, %g1, %g1
	DLFLUSH %g1,%g7
	ldxa	[%g1] ASI_PHYS_CACHED, %g1		! Load pointer to directory
	DLFLUSH2 %g7

	srlx	%g6, PDSHIFT, %g7			! Do page directory
	and	%g7, PDMASK, %g7
	sll	%g7, 3, %g7
	brz,pn	%g1, 0f
	 add	%g7, %g1, %g1
	DLFLUSH %g1,%g7
	ldxa	[%g1] ASI_PHYS_CACHED, %g1
	DLFLUSH2 %g7

	srlx	%g6, PTSHIFT, %g7			! Convert to ptab offset
	and	%g7, PTMASK, %g7
	brz	%g1, 0f
	 sll	%g7, 3, %g7
	add	%g1, %g7, %g7
	DLFLUSH %g7,%g1
	ldxa	[%g7] ASI_PHYS_CACHED, %g7		! This one is not
	DLFLUSH2 %g1
	brgez	%g7, 0f
	 srlx	%g7, PGSHIFT, %g7			! Isolate PA part
	sll	%g6, 32-PGSHIFT, %g6			! And offset
	sllx	%g7, PGSHIFT+17, %g7			! There are 17 bits to the left of the PA in the TTE
	srl	%g6, 32-PGSHIFT, %g6
	srax	%g7, 17, %g7
	or	%g7, %g6, %g6				! Then combine them to form PA

	wr	%g0, ASI_PHYS_CACHED, %asi		! Use ASI_PHYS_CACHED to prevent possible page faults
0:
	/*
	 * Now save all user windows to cpcb.
	 */
	CHKPT %g5,%g7,0x12
	rdpr	%otherwin, %g7
	brnz,pt	%g7, 1f
	 rdpr	%canrestore, %g5
	rdpr	%cansave, %g1
	add	%g5, 1, %g7				! add the %cwp window to the list to save
!	movrnz	%g1, %g5, %g7				! If we're issuing a save
!	mov	%g5, %g7				! DEBUG
	wrpr	%g0, 0, %canrestore
	wrpr	%g7, 0, %otherwin			! Still in user mode -- need to switch to kernel mode
1:
	mov	%g7, %g1
	CHKPT %g5,%g7,0x13
	add	%g6, PCB_NSAVED, %g7
	DLFLUSH %g7,%g5
	lduba	[%g6 + PCB_NSAVED] %asi, %g7		! Start incrementing pcb_nsaved
	DLFLUSH2 %g5

#ifdef DEBUG
	wrpr	%g0, 5, %tl
#endif	/* DEBUG */
	mov	%g6, %g5
	brz,pt	%g7, winfixsave				! If it's in use, panic
	 saved						! frob window registers

	/* PANIC */
!	CHKPT %g4,%g7,0x10	! Checkpoint
!	sir						! Force a watchdog
#ifdef DEBUG
	wrpr	%g2, 0, %tl
#endif	/* DEBUG */
	mov	%g7, %o2
	rdpr	%ver, %o1
	sethi	%hi(2f), %o0
	and	%o1, CWP, %o1
	wrpr	%g0, %o1, %cleanwin
	dec	1, %o1
	wrpr	%g0, %o1, %cansave			! kludge away any more window problems
	wrpr	%g0, 0, %canrestore
	wrpr	%g0, 0, %otherwin
	or	%lo(2f), %o0, %o0
	wrpr	%g0, WSTATE_KERN, %wstate
#ifdef DEBUG
	set	panicstack-CC64FSZ-BIAS, %sp		! Use panic stack.
#else	/* DEBUG */
	set	estack0, %sp
	ldx	[%sp], %sp
	add	%sp, -CC64FSZ-BIAS, %sp			! Overwrite proc 0's stack.
#endif	/* DEBUG */
	ta	1; nop					! This helps out traptrace.
	call	_C_LABEL(panic)				! This needs to be fixed properly but we should panic here
	 mov	%g1, %o1
	NOTREACHED
	.data
2:
	.asciz	"winfault: double invalid window at %p, nsaved=%d"
	_ALIGN
	.text
3:
	saved
	save
winfixsave:
	sllx	%g7, 7, %g5
	add	%g6, %g5, %g5
	SPILL	stxa, %g5 + PCB_RW, 8, %asi	! Save the window in the pcb

	sllx	%g7, 3, %g5
	add	%g6, %g5, %g5
	stxa	%sp, [%g5 + PCB_RWSP] %asi

!	rdpr	%otherwin, %g1	! Check to see if we's done
	dec	%g1
	wrpr	%g0, 7, %cleanwin			! BUGBUG -- we should not hardcode this, but I have no spare globals
	brnz,pt	%g1, 3b
	 inc	%g7					! inc pcb_nsaved

	/* fix up pcb fields */
	stba	%g7, [%g6 + PCB_NSAVED] %asi		! cpcb->pcb_nsaved = n
	CHKPT %g5,%g1,0x14
#if 0
	mov	%g7, %g5				! fixup window registers
5:
	dec	%g5
	brgz,a,pt	%g5, 5b
	 restore
#else	/* 0 */
	/*
	 * We just issued a bunch of saves, so %cansave is now 0,
	 * probably (if we were doing a flushw then we may have
	 * come in with only partially full register windows and
	 * it may not be 0).
	 *
	 * %g7 contains the count of the windows we just finished
	 * saving.
	 *
	 * What we need to do now is move some of the windows from
	 * %canrestore to %cansave.  What we should do is take
	 * min(%canrestore, %g7) and move that over to %cansave.
	 *
	 * %g7 is the number of windows we flushed, so we should
	 * use that as a base.  Clear out %otherwin, set %cansave
	 * to min(%g7, NWINDOWS - 2), set %cleanwin to %canrestore
	 * + %cansave and the rest follows:
	 *
	 * %otherwin = 0
	 * %cansave = NWINDOWS - 2 - %canrestore
	 */
	wrpr	%g0, 0, %otherwin
	rdpr	%canrestore, %g1
	sub	%g1, %g7, %g1				! Calculate %canrestore - %g7
	movrlz	%g1, %g0, %g1				! Clamp at zero
	wrpr	%g1, 0, %canrestore			! This is the new canrestore
	rdpr	%ver, %g5
	and	%g5, CWP, %g5				! NWINDOWS-1
	dec	%g5					! NWINDOWS-2
	wrpr	%g5, 0, %cleanwin			! Set cleanwin to max, since we're in-kernel
	sub	%g5, %g1, %g5				! NWINDOWS-2-%canrestore
	wrpr	%g5, 0, %cansave
#endif	/* 0 */

	CHKPT %g5,%g1,0x15
!	rdpr	%tl, %g2				! DEBUG DEBUG -- did we trap somewhere?
	sub	%g2, 1, %g1
	rdpr	%tt, %g2
	wrpr	%g1, 0, %tl				! We will not attempt to re-execute the spill, so dump our trap frame permanently
	wrpr	%g2, 0, %tt				! Move trap type from fault frame here, overwriting spill
	CHKPT %g2,%g5,0x16

	/* Did we save a user or kernel window ? */
!	srax	%g3, 48, %g7				! User or kernel store? (TAG TARGET)
	sllx	%g3, (64-13), %g7			! User or kernel store? (TAG ACCESS)
	sethi	%hi((2*NBPG)-8), %g7
	brnz,pt	%g7, 1f					! User fault -- save windows to pcb
	 or	%g7, %lo((2*NBPG)-8), %g7

	and	%g4, CWP, %g4				! %g4 = %cwp of trap
	wrpr	%g4, 0, %cwp				! Kernel fault -- restore %cwp and force and trap to debugger
#ifdef DEBUG
	set	DATA_START, %g7				! debug
	set	0x11, %g6				! debug
	stb	%g6, [%g7 + 0x20]			! debug
	CHKPT %g2,%g1,0x17
!	sir
#endif	/* DEBUG */
	!!
	!! Here we managed to fault trying to access a kernel window
	!! This is a bug.  Switch to the interrupt stack if we aren't
	!! there already and then trap into the debugger or panic.
	!!
	sethi	%hi(EINTSTACK-BIAS), %g6
	btst	1, %sp
	bnz,pt	%icc, 0f
	 mov	%sp, %g1
	add	%sp, -BIAS, %g1
0:
	or	%g6, %lo(EINTSTACK-BIAS), %g6
	set	(EINTSTACK-INTSTACK), %g7	! XXXXXXXXXX This assumes kernel addresses are unique from user addresses
	sub	%g6, %g1, %g2				! Determine if we need to switch to intr stack or not
	dec	%g7					! Make it into a mask
	andncc	%g2, %g7, %g0				! XXXXXXXXXX This assumes kernel addresses are unique from user addresses */ \
	movz	%xcc, %g1, %g6				! Stay on interrupt stack?
	add	%g6, -CCFSZ, %g6			! Allocate a stack frame
	mov	%sp, %l6				! XXXXX Save old stack pointer
	mov	%g6, %sp
	ta	1; nop					! Enter debugger
	NOTREACHED
1:
#if 1
	/* Now we need to blast away the D$ to make sure we're in sync */
dlflush1:
	stxa	%g0, [%g7] ASI_DCACHE_TAG
	brnz,pt	%g7, 1b
	 dec	8, %g7
#endif	/* 1 */

#ifdef DEBUG
	CHKPT %g2,%g1,0x18
	set	DATA_START, %g7				! debug
	set	0x19, %g6				! debug
	stb	%g6, [%g7 + 0x20]			! debug
#endif	/* DEBUG */
	/*
	 * If we had WSTATE_KERN then we had at least one valid kernel window.
	 * We should re-execute the trapping save.
	 */
	rdpr	%wstate, %g3
	mov	%g3, %g3
	cmp	%g3, WSTATE_KERN
	bne,pt	%icc, 1f
	 nop
	retry						! Now we can complete the save
1:
	/*
	 * Since we had a WSTATE_USER, we had no valid kernel windows.  This should
	 * only happen inside TRAP_SETUP or INTR_SETUP. Emulate
	 * the instruction, clean up the register windows, then done.
	 */
	rdpr	%cwp, %g1
	inc	%g1
	rdpr	%tstate, %g2
	wrpr	%g1, %cwp
	andn	%g2, CWP, %g2
	wrpr	%g1, %g2, %tstate
	wrpr	%g0, PSTATE_KERN|PSTATE_AG, %pstate
	mov	%g6, %sp
	done

/*
 * Each memory data access fault, from user or kernel mode,
 * comes here.
 *
 * We will assume that %pil is not lost so we won't bother to save it
 * unless we're in an interrupt handler.
 *
 * On entry:
 *	We are on one of the alternate set of globals
 *	%g1 = MMU tag target
 *	%g2 = %tl
 *
 * On return:
 *
 */
datafault:
	wrpr	%g0, PSTATE_KERN|PSTATE_AG, %pstate	! We need to save volatile stuff to AG regs
#ifdef DEBUG
	set	DATA_START, %g7				! debug
	set	0x20, %g6				! debug
	stx	%g0, [%g7]				! debug
	stb	%g6, [%g7 + 0x20]			! debug
	CHKPT %g4,%g7,0xf
#endif	/* DEBUG */
	wr	%g0, ASI_DMMU, %asi			! We need to re-load trap info
	ldxa	[%g0 + TLB_TAG_ACCESS] %asi, %g1	! Get fault address from tag access register
	ldxa	[SFAR] %asi, %g2			! sync virt addr; must be read first
	ldxa	[SFSR] %asi, %g3			! get sync fault status register
	stxa	%g0, [SFSR] %asi			! Clear out fault now
	membar	#Sync					! No real reason for this XXXX

	TRAP_SETUP -CC64FSZ-TF_SIZE
Ldatafault_internal:
	INCR _C_LABEL(uvmexp)+V_FAULTS			! cnt.v_faults++ (clobbers %o0,%o1,%o2) should not fault
!	ldx	[%sp + CC64FSZ + BIAS + TF_FAULT], %g1		! DEBUG make sure this has not changed
	mov	%g1, %o0				! Move these to the out regs so we can save the globals
	mov	%g2, %o4
	mov	%g3, %o5

	ldxa	[%g0] ASI_AFAR, %o2			! get async fault address
	ldxa	[%g0] ASI_AFSR, %o3			! get async fault status
	mov	-1, %g7
	stxa	%g7, [%g0] ASI_AFSR			! And clear this out, too
	membar	#Sync					! No real reason for this XXXX

	wrpr	%g0, PSTATE_KERN, %pstate		! Get back to normal globals

	stx	%g1, [%sp + CC64FSZ + BIAS + TF_G + (1*8)]	! save g1
	rdpr	%tt, %o1				! find out what trap brought us here
	stx	%g2, [%sp + CC64FSZ + BIAS + TF_G + (2*8)]	! save g2
	rdpr	%tstate, %g1
	stx	%g3, [%sp + CC64FSZ + BIAS + TF_G + (3*8)]	! (sneak g3 in here)
	rdpr	%tpc, %g2
	stx	%g4, [%sp + CC64FSZ + BIAS + TF_G + (4*8)]	! sneak in g4
	rdpr	%tnpc, %g3
	stx	%g5, [%sp + CC64FSZ + BIAS + TF_G + (5*8)]	! sneak in g5
	rd	%y, %g4					! save y
	stx	%g6, [%sp + CC64FSZ + BIAS + TF_G + (6*8)]	! sneak in g6
	mov	%g2, %o7				! Make the fault address look like the return address
	stx	%g7, [%sp + CC64FSZ + BIAS + TF_G + (7*8)]	! sneak in g7

#ifdef DEBUG
	set	DATA_START, %g7				! debug
	set	0x21, %g6				! debug
	stb	%g6, [%g7 + 0x20]			! debug
#endif	/* DEBUG */
	sth	%o1, [%sp + CC64FSZ + BIAS + TF_TT]
	stx	%g1, [%sp + CC64FSZ + BIAS + TF_TSTATE]		! set tf.tf_psr, tf.tf_pc
	stx	%g2, [%sp + CC64FSZ + BIAS + TF_PC]		! set tf.tf_npc
	stx	%g3, [%sp + CC64FSZ + BIAS + TF_NPC]

	rdpr	%pil, %g5
	stb	%g5, [%sp + CC64FSZ + BIAS + TF_PIL]
	stb	%g5, [%sp + CC64FSZ + BIAS + TF_OLDPIL]

#if 1
	rdpr	%tl, %g7
	dec	%g7
	movrlz	%g7, %g0, %g7
	CHKPT %g1,%g3,0x21
	wrpr	%g0, %g7, %tl		! Revert to kernel mode
#else	/* 1 */
	CHKPT %g1,%g3,0x21
	wrpr	%g0, 0, %tl		! Revert to kernel mode
#endif	/* 1 */
	/* Finish stackframe, call C trap handler */
	flushw						! Get this clean so we won't take any more user faults

	GET_CPUINFO_VA(%g7)

	/*
	 * Right now the registers have the following values:
	 *
	 *	%o0 -- MMU_TAG_ACCESS
	 *	%o1 -- TT
	 *	%o2 -- afar
	 *	%o3 -- afsr
	 *	%o4 -- sfar
	 *	%o5 -- sfsr
	 */
	
	cmp	%o1, T_DATA_ERROR
	st	%g4, [%sp + CC64FSZ + BIAS + TF_Y]
	wr	%g0, ASI_PRIMARY_NOFAULT, %asi	! Restore default ASI
	be,pn	%icc, data_error
	 wrpr	%g0, PSTATE_INTR, %pstate	! reenable interrupts

	mov	%o0, %o3			! (argument: trap address)
	mov	%g2, %o2			! (argument: trap pc)
	call	_C_LABEL(data_access_fault)	! data_access_fault(&tf, type, 
						!	pc, addr, sfva, sfsr)
	 add	%sp, CC64FSZ + BIAS, %o0	! (argument: &tf)

data_recover:
	CHKPT %o1,%o2,1
	wrpr	%g0, PSTATE_KERN, %pstate		! disable interrupts
	b	return_from_trap			! go return
	 ldx	[%sp + CC64FSZ + BIAS + TF_TSTATE], %g1		! Load this for return_from_trap
	NOTREACHED

data_error:
	call	_C_LABEL(data_access_error)	! data_access_error(&tf, type, 
						!	afva, afsr, sfva, sfsr)
	 add	%sp, CC64FSZ + BIAS, %o0	! (argument: &tf)
	ba	data_recover
	 nop
	NOTREACHED

/*
 * Each memory instruction access fault from a fast access handler comes here.
 * We will quickly check if this is an original prom mapping before going
 * to the generic fault handler
 *
 * We will assume that %pil is not lost so we won't bother to save it
 * unless we're in an interrupt handler.
 *
 * On entry:
 *	We are on one of the alternate set of globals
 *	%g1 = MMU tag target
 *	%g2 = TSB entry ptr
 *	%g3 = TLB Tag Access
 *
 * On return:
 *
 */

	ICACHE_ALIGN
instr_miss:
	mov	TLB_TAG_ACCESS, %g3			! Get real fault page
	sethi	%hi(0x1fff), %g7			! 8K context mask
	ldxa	[%g3] ASI_IMMU, %g3			! from tag access register
	sethi	%hi(_C_LABEL(ctxbusy)), %g4
	or	%g7, %lo(0x1fff), %g7
	ldx	[%g4 + %lo(_C_LABEL(ctxbusy))], %g4
	srax	%g3, HOLESHIFT, %g5			! Check for valid address
	and	%g3, %g7, %g6				! Isolate context
	sllx	%g6, 3, %g6				! Make it into an offset into ctxbusy
	inc	%g5					! (0 or -1) -> (1 or 0)
	
	ldx	[%g4+%g6], %g4				! Load up our page table.
#ifdef DEBUG
	/* Make sure we don't try to replace a kernel translation */
	/* This should not be necessary */
	brnz,pt	%g6, 1f					! If user context continue miss
	sethi	%hi(KERNBASE), %g7			! Don't need %lo
	set	0x0800000, %g6				! 8MB
	sub	%g3, %g7, %g7
	cmp	%g7, %g6
	mov	6, %g6		! debug
	sethi	%hi(DATA_START), %g7
	stb	%g6, [%g7+0x30]	! debug
	tlu	%xcc, 1; nop
	blu,pn	%xcc, textfault				! Next instruction in delay slot is unimportant
	 mov	7, %g6		! debug
	stb	%g6, [%g7+0x30]	! debug
1:	
#endif	/* DEBUG */
	srlx	%g3, STSHIFT, %g6
	cmp	%g5, 1
	bgu,pn %xcc, textfault				! Error!
	 srlx	%g3, PDSHIFT, %g5
	and	%g6, STMASK, %g6
	sll	%g6, 3, %g6
	and	%g5, PDMASK, %g5
	nop

	sll	%g5, 3, %g5
	add	%g6, %g4, %g4
	ldxa	[%g4] ASI_PHYS_CACHED, %g4
	srlx	%g3, PTSHIFT, %g6			! Convert to ptab offset
	and	%g6, PTMASK, %g6
	add	%g5, %g4, %g5
	brz,pn	%g4, textfault				! NULL entry? check somewhere else
	 nop
	
	ldxa	[%g5] ASI_PHYS_CACHED, %g4
	sll	%g6, 3, %g6
	brz,pn	%g4, textfault				! NULL entry? check somewhere else
	 add	%g6, %g4, %g6		
1:
	ldxa	[%g6] ASI_PHYS_CACHED, %g4
	brgez,pn %g4, textfault
	 nop

	/* Check if it's an executable mapping. */
	andcc	%g4, SUN4U_TLB_EXEC, %g0
	bz,pn	%xcc, textfault
	 nop


	or	%g4, SUN4U_TLB_ACCESS, %g7		! Update accessed bit
	btst	SUN4U_TLB_ACCESS, %g4			! Need to update access bit?
	bne,pt	%xcc, 1f
	 nop
	casxa	[%g6] ASI_PHYS_CACHED, %g4, %g7		!  and store it
	cmp	%g4, %g7
	bne,pn	%xcc, 1b
	 or	%g4, SUN4U_TLB_ACCESS, %g4		! Update accessed bit

1:
#ifdef MULTIPROCESSOR
	ld	[%g2], %g6
	btst	(TSB_TAG_LOCKED >> 32), %g6
	bnz,pn	%icc, 1b
	 or	%g6, (TSB_TAG_LOCKED >> 32), %g5
	casa	[%g2] ASI_NUCLEUS, %g6, %g5
	cmp	%g6, %g5
	bne,pn	%icc, 1b
	 nop
	membar	#StoreStore
#endif
	stx	%g4, [%g2 + 8]				! Update TSB entry data
	stx	%g1, [%g2]				! Update TSB entry tag
#ifdef DEBUG
	set	DATA_START, %g6	! debug
	stx	%g3, [%g6+8]	! debug
	set	0xaa, %g3	! debug
	stx	%g4, [%g6]	! debug -- what we tried to enter in TLB
	stb	%g3, [%g6+0x20]	! debug
#endif	/* DEBUG */
#if 1
	/* This was a miss -- should be nothing to demap. */
	sllx	%g3, (64-13), %g6			! Need to demap old entry first
	mov	DEMAP_PAGE_SECONDARY, %g1		! Secondary flush
	mov	DEMAP_PAGE_NUCLEUS, %g5			! Nucleus flush
	movrz	%g6, %g5, %g1				! Pick one
	andn	%g3, 0xfff, %g6
	or	%g6, %g1, %g6
	stxa	%g6, [%g6] ASI_DMMU_DEMAP		! Do the demap
	membar	#Sync					! No real reason for this XXXX
#endif	/* 1 */
	stxa	%g4, [%g0] ASI_IMMU_DATA_IN		! Enter new mapping
	membar	#Sync
	CLRTT
	retry
	NOTREACHED
	!!
	!!  Check our prom mappings -- temporary
	!!

/*
 * Each memory text access fault, from user or kernel mode,
 * comes here.
 *
 * We will assume that %pil is not lost so we won't bother to save it
 * unless we're in an interrupt handler.
 *
 * On entry:
 *	We are on one of the alternate set of globals
 *	%g1 = MMU tag target
 *	%g2 = %tl
 *	%g3 = %tl - 1
 *
 * On return:
 *
 */


textfault:
	wrpr	%g0, PSTATE_KERN|PSTATE_AG, %pstate	! We need to save volatile stuff to AG regs
	wr	%g0, ASI_IMMU, %asi
	ldxa	[%g0 + TLB_TAG_ACCESS] %asi, %g1	! Get fault address from tag access register
	ldxa	[SFSR] %asi, %g3			! get sync fault status register
	membar	#LoadStore
	stxa	%g0, [SFSR] %asi			! Clear out old info
	membar	#Sync					! No real reason for this XXXX

	TRAP_SETUP -CC64FSZ-TF_SIZE
	INCR _C_LABEL(uvmexp)+V_FAULTS			! cnt.v_faults++ (clobbers %o0,%o1,%o2)

	mov	%g3, %o3

	wrpr	%g0, PSTATE_KERN, %pstate		! Switch to normal globals
	ldxa	[%g0] ASI_AFSR, %o4			! get async fault status
	ldxa	[%g0] ASI_AFAR, %o5			! get async fault address
	mov	-1, %o0
	stxa	%o0, [%g0] ASI_AFSR			! Clear this out
	membar	#Sync					! No real reason for this XXXX
	stx	%g1, [%sp + CC64FSZ + BIAS + TF_G + (1*8)]	! save g1
	stx	%g2, [%sp + CC64FSZ + BIAS + TF_G + (2*8)]	! save g2
	stx	%g3, [%sp + CC64FSZ + BIAS + TF_G + (3*8)]	! (sneak g3 in here)
	rdpr	%tt, %o1				! Find out what caused this trap
	stx	%g4, [%sp + CC64FSZ + BIAS + TF_G + (4*8)]	! sneak in g4
	rdpr	%tstate, %g1
	stx	%g5, [%sp + CC64FSZ + BIAS + TF_G + (5*8)]	! sneak in g5
	rdpr	%tpc, %o2				! sync virt addr; must be read first
	stx	%g6, [%sp + CC64FSZ + BIAS + TF_G + (6*8)]	! sneak in g6
	rdpr	%tnpc, %g3
	stx	%g7, [%sp + CC64FSZ + BIAS + TF_G + (7*8)]	! sneak in g7
	rd	%y, %g4					! save y

	/* Finish stackframe, call C trap handler */
	stx	%g1, [%sp + CC64FSZ + BIAS + TF_TSTATE]		! set tf.tf_psr, tf.tf_pc
	sth	%o1, [%sp + CC64FSZ + BIAS + TF_TT]! debug

	stx	%o2, [%sp + CC64FSZ + BIAS + TF_PC]
	stx	%g3, [%sp + CC64FSZ + BIAS + TF_NPC]		! set tf.tf_npc

	rdpr	%pil, %g5
	stb	%g5, [%sp + CC64FSZ + BIAS + TF_PIL]
	stb	%g5, [%sp + CC64FSZ + BIAS + TF_OLDPIL]

	rdpr	%tl, %g7
	dec	%g7
	movrlz	%g7, %g0, %g7
	CHKPT %g1,%g3,0x22
	wrpr	%g0, %g7, %tl		! Revert to kernel mode

	wr	%g0, ASI_PRIMARY_NOFAULT, %asi		! Restore default ASI
	flushw						! Get rid of any user windows so we don't deadlock

	GET_CPUINFO_VA(%g7)

	/* Use trap type to see what handler to call */
	cmp	%o1, T_INST_ERROR
	be,pn	%xcc, text_error
	 st	%g4, [%sp + CC64FSZ + BIAS + TF_Y]		! set tf.tf_y

	wrpr	%g0, PSTATE_INTR, %pstate	! reenable interrupts
	call	_C_LABEL(text_access_fault)	! mem_access_fault(&tf, type, pc, sfsr)
	 add	%sp, CC64FSZ + BIAS, %o0	! (argument: &tf)
text_recover:
	CHKPT %o1,%o2,2
	wrpr	%g0, PSTATE_KERN, %pstate	! disable interrupts
	b	return_from_trap		! go return
	 ldx	[%sp + CC64FSZ + BIAS + TF_TSTATE], %g1	! Load this for return_from_trap
	NOTREACHED

text_error:
	wrpr	%g0, PSTATE_INTR, %pstate	! reenable interrupts
	call	_C_LABEL(text_access_error)	! mem_access_fault(&tfm type, sfva [pc], sfsr,
						!		afva, afsr);
	 add	%sp, CC64FSZ + BIAS, %o0	! (argument: &tf)
	ba	text_recover
	 nop
	NOTREACHED

#ifdef SUN4V

/*
 * Traps for sun4v.
 */

sun4v_tl1_dtsb_miss:
	GET_MMFSA(%g1)
	add	%g1, 0x48, %g3
	ldxa	[%g3] ASI_PHYS_CACHED, %g3
	add	%g1, 0x50, %g6
	ldxa	[%g6] ASI_PHYS_CACHED, %g6
	sethi	%hi(_C_LABEL(ctxbusy)), %g4
	ldx	[%g4 + %lo(_C_LABEL(ctxbusy))], %g4

	sllx	%g6, 3, %g6				! Make it into an offset into ctxbusy
	ldx	[%g4 + %g6], %g4			! Load up our page table.

	srax	%g3, HOLESHIFT, %g5			! Check for valid address
	brz,pt	%g5, 0f					! Should be zero or -1
	 inc	%g5					! Make -1 -> 0
	brnz,pn	%g5, sun4v_tl1_ptbl_miss		! Error! In hole!
0:
	srlx	%g3, STSHIFT, %g6
	and	%g6, STMASK, %g6			! Index into pm_segs
	sll	%g6, 3, %g6
	add	%g4, %g6, %g4
	ldxa	[%g4] ASI_PHYS_CACHED, %g4		! Load page directory pointer

	srlx	%g3, PDSHIFT, %g6
	and	%g6, PDMASK, %g6
	sll	%g6, 3, %g6
	brz,pn	%g4, sun4v_tl1_ptbl_miss		! NULL entry? check somewhere else
	 add	%g4, %g6, %g4
	ldxa	[%g4] ASI_PHYS_CACHED, %g4		! Load page table pointer

	srlx	%g3, PTSHIFT, %g6			! Convert to ptab offset
	and	%g6, PTMASK, %g6
	sll	%g6, 3, %g6
	brz,pn	%g4, sun4v_tl1_ptbl_miss		! NULL entry? check somewhere else
	 add	%g4, %g6, %g6
1:
	ldxa	[%g6] ASI_PHYS_CACHED, %g4
	brgez,pn %g4, sun4v_tl1_ptbl_miss		! Entry invalid?  Punt
	 or	%g4, SUN4V_TLB_ACCESS, %g7		! Update the access bit

	btst	SUN4V_TLB_ACCESS, %g4			! Need to update access git?
	bne,pt	%xcc, 2f
	 nop
	casxa	[%g6] ASI_PHYS_CACHED, %g4, %g7		!  and write it out
	cmp	%g4, %g7
	bne,pn	%xcc, 1b
	 or	%g4, SUN4V_TLB_ACCESS, %g4		! Update the modified bit
2:
	sethi	%hi(_C_LABEL(tsb_dmmu)), %g2
	ldx	[%g2 + %lo(_C_LABEL(tsb_dmmu))], %g2

	mov	%g1, %g7
	/* Construct TSB tag word. */
	add	%g1, 0x50, %g6
	ldxa	[%g6] ASI_PHYS_CACHED, %g6
	mov	%g3, %g1
	srlx	%g1, 22, %g1
	sllx	%g6, 48, %g6
	or	%g1, %g6, %g1

	srlx	%g3, PTSHIFT, %g3
	sethi	%hi(_C_LABEL(tsbsize)), %g5
	mov	512, %g6
	ld	[%g5 + %lo(_C_LABEL(tsbsize))], %g5
	sllx	%g6, %g5, %g5
	sub	%g5, 1, %g5
	and	%g3, %g5, %g3
	sllx	%g3, 4, %g3
	add	%g2, %g3, %g2

3:
	ld	[%g2], %g3
	btst	(TSB_TAG_LOCKED >> 32), %g3
	bnz,pn	%icc, 3b
	 or	%g3, (TSB_TAG_LOCKED >> 32), %g5
	casa	[%g2] ASI_NUCLEUS, %g3, %g5
	cmp	%g3, %g5
	bne,pn	%icc, 3b
	 nop
	membar	#StoreStore
	stx	%g4, [%g2 + 8]
	stx	%g1, [%g2]		! unlock

	retry
	NOTREACHED

sun4v_tl1_dtsb_prot:
	GET_MMFSA(%g1)
	add	%g1, 0x48, %g3
	ldxa	[%g3] ASI_PHYS_CACHED, %g3
	add	%g1, 0x50, %g6
	ldxa	[%g6] ASI_PHYS_CACHED, %g6
	sethi	%hi(_C_LABEL(ctxbusy)), %g4
	ldx	[%g4 + %lo(_C_LABEL(ctxbusy))], %g4

	sllx	%g6, 3, %g6				! Make it into an offset into ctxbusy
	ldx	[%g4 + %g6], %g4			! Load up our page table.

	srax	%g3, HOLESHIFT, %g5			! Check for valid address
	brz,pt	%g5, 0f					! Should be zero or -1
	 inc	%g5					! Make -1 -> 0
	brnz,pn	%g5, sun4v_tl1_ptbl_miss		! Error! In hole!
0:
	srlx	%g3, STSHIFT, %g6
	and	%g6, STMASK, %g6			! Index into pm_segs
	sll	%g6, 3, %g6
	add	%g4, %g6, %g4
	ldxa	[%g4] ASI_PHYS_CACHED, %g4		! Load page directory pointer

	srlx	%g3, PDSHIFT, %g6
	and	%g6, PDMASK, %g6
	sll	%g6, 3, %g6
	brz,pn	%g4, sun4v_tl1_ptbl_miss		! NULL entry? check somewhere else
	 add	%g4, %g6, %g4
	ldxa	[%g4] ASI_PHYS_CACHED, %g4		! Load page table pointer

	srlx	%g3, PTSHIFT, %g6			! Convert to ptab offset
	and	%g6, PTMASK, %g6
	sll	%g6, 3, %g6
	brz,pn	%g4, sun4v_tl1_ptbl_miss		! NULL entry? check somewhere else
	 add	%g4, %g6, %g6
1:
	ldxa	[%g6] ASI_PHYS_CACHED, %g4
	brgez,pn %g4, sun4v_tl1_ptbl_miss		! Entry invalid?  Punt
	 or	%g4, SUN4V_TLB_MODIFY|SUN4V_TLB_ACCESS|SUN4V_TLB_W, %g7
		! Update the modified bit

#	btst	SUN4V_TLB_REAL_W|SUN4V_TLB_W, %g4	! Is it a ref fault?
	mov	1, %g2
	sllx	%g2, 61, %g2
	or	%g2, SUN4V_TLB_W, %g2
	btst	%g2, %g4
	bz,pn	%xcc, sun4v_tl1_ptbl_miss		! No -- really fault
	 nop
	casxa	[%g6] ASI_PHYS_CACHED, %g4, %g7		!  and write it out
	cmp	%g4, %g7
	bne,pn	%xcc, 1b
	 or	%g4, SUN4V_TLB_MODIFY|SUN4V_TLB_ACCESS|SUN4V_TLB_W, %g4
		! Update the modified bit
2:
	sethi	%hi(_C_LABEL(tsb_dmmu)), %g2
	ldx	[%g2 + %lo(_C_LABEL(tsb_dmmu))], %g2

	mov	%g1, %g7
	/* Construct TSB tag word. */
	add	%g1, 0x50, %g6
	ldxa	[%g6] ASI_PHYS_CACHED, %g6
	mov	%g3, %g1
	srlx	%g1, 22, %g1
	sllx	%g6, 48, %g6
	or	%g1, %g6, %g1

	srlx	%g3, PTSHIFT, %g3
	sethi	%hi(_C_LABEL(tsbsize)), %g5
	mov	512, %g6
	ld	[%g5 + %lo(_C_LABEL(tsbsize))], %g5
	sllx	%g6, %g5, %g5
	sub	%g5, 1, %g5
	and	%g3, %g5, %g3
	sllx	%g3, 4, %g3
	add	%g2, %g3, %g2

3:
	ld	[%g2], %g3
	btst	(TSB_TAG_LOCKED >> 32), %g3
	bnz,pn	%icc, 3b
	 or	%g3, (TSB_TAG_LOCKED >> 32), %g5
	casa	[%g2] ASI_NUCLEUS, %g3, %g5
	cmp	%g3, %g5
	bne,pn	%icc, 3b
	 nop
	membar	#StoreStore
	stx	%g4, [%g2 + 8]
	stx	%g1, [%g2]		! unlock

	mov	%o0, %g1
	mov	%o1, %g2
	mov	%o2, %g3

#define MAP_DTLB	0x1
#define MAP_ITLB	0x2
#define MMU_UNMAP_ADDR	0x84
	add	%g7, 0x48, %o0
	ldxa	[%o0] ASI_PHYS_CACHED, %o0
	add	%g7, 0x50, %o1
	ldxa	[%o1] ASI_PHYS_CACHED, %o1
	mov	MAP_DTLB, %o2
	ta	MMU_UNMAP_ADDR

	mov	%g1, %o0
	mov	%g2, %o1
	mov	%g3, %o2

	retry
	NOTREACHED


sun4v_tl1_ptbl_miss:
	rdpr	%tpc, %g1

	set	rft_user_fault_start, %g2
	cmp	%g1, %g2
	blu,pt	%xcc, 1f
	 set	rft_user_fault_end, %g2
	cmp	%g1, %g2
	bgeu,pt	%xcc, 1f
	 nop

	/* Fixup %cwp. */
	rdpr	%cwp, %g1
	inc	%g1
	wrpr	%g1, %cwp

	rdpr	%tt, %g1
	wrpr	1, %tl
	wrpr	%g1, %tt
	rdpr	%cwp, %g1
	set	TSTATE_KERN, %g2
	wrpr	%g1, %g2, %tstate
	set	return_from_trap, %g1
	wrpr	%g1, %tpc
	add	%g1, 4, %g1
	wrpr	%g1, %tnpc
	wrpr	%g0, 1, %gl

	ba,pt %xcc, sun4v_datatrap
	 wrpr	WSTATE_KERN, %wstate

1:
	rdpr	%tstate, %g3
	rdpr	%tt, %g4

	rdpr	%tl, %g1
	dec	%g1
	wrpr	%g1, %tl
	rdpr	%tt, %g2
	inc	%g1
	wrpr	%g1, %tl

	wrpr	%g0, %g3, %tstate
	wrpr	%g0, %g4, %tt

	andn	%g2, 0x00f, %g3
	cmp	%g3, 0x080
	be,pn	%icc, flush_normals
	 nop
	cmp	%g3, 0x0a0
	be,pn	%icc, flush_others
	 nop
	cmp	%g3, 0x0c0
	be,pn	%icc, ufill_trap
	 nop

	db_enter()
	NOTREACHED

flush_others:
	set	pcbspill_others, %g1
	wrpr	%g1, %tnpc
	done
	NOTREACHED

flush_normals:
ufill_trap:
	/*
	 * Rearrange our trap state such that it appears as if we got
	 * this trap directly from user mode.  Then process it at TL = 1.
	 * We'll take the spill/fill trap again once we return to user mode.
	 */
	rdpr	%tt, %g1
	rdpr	%tstate, %g3
	wrpr	%g0, 1, %tl
	wrpr	%g0, %g1, %tt
	rdpr	%tstate, %g2
	wrpr	%g0, 2, %tl
	and	%g2, TSTATE_CWP, %g2
	andn	%g3, TSTATE_CWP, %g3
	wrpr	%g2, %g3, %tstate
	set	sun4v_datatrap, %g4
	wrpr	%g0, %g4, %tnpc
	done

sun4v_tl0_dtsb_miss:
	GET_MMFSA(%g1)
	add	%g1, 0x48, %g3
	ldxa	[%g3] ASI_PHYS_CACHED, %g3
	add	%g1, 0x50, %g6
	ldxa	[%g6] ASI_PHYS_CACHED, %g6
	sethi	%hi(_C_LABEL(ctxbusy)), %g4
	ldx	[%g4 + %lo(_C_LABEL(ctxbusy))], %g4

	sllx	%g6, 3, %g6				! Make it into an offset into ctxbusy
	ldx	[%g4 + %g6], %g4			! Load up our page table.

	srax	%g3, HOLESHIFT, %g5			! Check for valid address
	brz,pt	%g5, 0f					! Should be zero or -1
	 inc	%g5					! Make -1 -> 0
	brnz,pn	%g5, sun4v_datatrap			! Error! In hole!
0:
	srlx	%g3, STSHIFT, %g6
	and	%g6, STMASK, %g6			! Index into pm_segs
	sll	%g6, 3, %g6
	add	%g4, %g6, %g4
	ldxa	[%g4] ASI_PHYS_CACHED, %g4		! Load page directory pointer

	srlx	%g3, PDSHIFT, %g6
	and	%g6, PDMASK, %g6
	sll	%g6, 3, %g6
	brz,pn	%g4, sun4v_datatrap			! NULL entry? check somewhere else
	 add	%g4, %g6, %g4
	ldxa	[%g4] ASI_PHYS_CACHED, %g4		! Load page table pointer

	srlx	%g3, PTSHIFT, %g6			! Convert to ptab offset
	and	%g6, PTMASK, %g6
	sll	%g6, 3, %g6
	brz,pn	%g4, sun4v_datatrap			! NULL entry? check somewhere else
	 add	%g4, %g6, %g6
1:
	ldxa	[%g6] ASI_PHYS_CACHED, %g4
	brgez,pn %g4, sun4v_datatrap			! Entry invalid?  Punt
	 or	%g4, SUN4V_TLB_ACCESS, %g7		! Update the access bit

	btst	SUN4V_TLB_ACCESS, %g4			! Need to update access git?
	bne,pt	%xcc, 2f
	 nop
	casxa	[%g6] ASI_PHYS_CACHED, %g4, %g7		!  and write it out
	cmp	%g4, %g7
	bne,pn	%xcc, 1b
	 or	%g4, SUN4V_TLB_ACCESS, %g4		! Update the modified bit
2:
	sethi	%hi(_C_LABEL(tsb_dmmu)), %g2
	ldx	[%g2 + %lo(_C_LABEL(tsb_dmmu))], %g2

	mov	%g1, %g7
	/* Construct TSB tag word. */
	add	%g1, 0x50, %g6
	ldxa	[%g6] ASI_PHYS_CACHED, %g6
	mov	%g3, %g1
	srlx	%g1, 22, %g1
	sllx	%g6, 48, %g6
	or	%g1, %g6, %g1

	srlx	%g3, PTSHIFT, %g3
	sethi	%hi(_C_LABEL(tsbsize)), %g5
	mov	512, %g6
	ld	[%g5 + %lo(_C_LABEL(tsbsize))], %g5
	sllx	%g6, %g5, %g5
	sub	%g5, 1, %g5
	and	%g3, %g5, %g3
	sllx	%g3, 4, %g3
	add	%g2, %g3, %g2

3:
	ld	[%g2], %g3
	btst	(TSB_TAG_LOCKED >> 32), %g3
	bnz,pn	%icc, 3b
	 or	%g3, (TSB_TAG_LOCKED >> 32), %g5
	casa	[%g2] ASI_NUCLEUS, %g3, %g5
	cmp	%g3, %g5
	bne,pn	%icc, 3b
	 nop
	membar	#StoreStore
	stx	%g4, [%g2 + 8]
	stx	%g1, [%g2]		! unlock

	retry
	NOTREACHED

sun4v_tl0_dtsb_prot:
	GET_MMFSA(%g1)
	add	%g1, 0x48, %g3
	ldxa	[%g3] ASI_PHYS_CACHED, %g3
	add	%g1, 0x50, %g6
	ldxa	[%g6] ASI_PHYS_CACHED, %g6
	sethi	%hi(_C_LABEL(ctxbusy)), %g4
	ldx	[%g4 + %lo(_C_LABEL(ctxbusy))], %g4

	sllx	%g6, 3, %g6				! Make it into an offset into ctxbusy
	ldx	[%g4 + %g6], %g4			! Load up our page table.

	srax	%g3, HOLESHIFT, %g5			! Check for valid address
	brz,pt	%g5, 0f					! Should be zero or -1
	 inc	%g5					! Make -1 -> 0
	brnz,pn	%g5, sun4v_datatrap			! Error! In hole!
0:
	srlx	%g3, STSHIFT, %g6
	and	%g6, STMASK, %g6			! Index into pm_segs
	sll	%g6, 3, %g6
	add	%g4, %g6, %g4
	ldxa	[%g4] ASI_PHYS_CACHED, %g4		! Load page directory pointer

	srlx	%g3, PDSHIFT, %g6
	and	%g6, PDMASK, %g6
	sll	%g6, 3, %g6
	brz,pn	%g4, sun4v_datatrap			! NULL entry? check somewhere else
	 add	%g4, %g6, %g4
	ldxa	[%g4] ASI_PHYS_CACHED, %g4		! Load page table pointer

	srlx	%g3, PTSHIFT, %g6			! Convert to ptab offset
	and	%g6, PTMASK, %g6
	sll	%g6, 3, %g6
	brz,pn	%g4, sun4v_datatrap			! NULL entry? check somewhere else
	 add	%g4, %g6, %g6
1:
	ldxa	[%g6] ASI_PHYS_CACHED, %g4
	brgez,pn %g4, sun4v_datatrap			! Entry invalid?  Punt
	 or	%g4, SUN4V_TLB_MODIFY|SUN4V_TLB_ACCESS|SUN4V_TLB_W, %g7
		! Update the modified bit

#	btst	SUN4V_TLB_REAL_W|SUN4V_TLB_W, %g4	! Is it a ref fault?
	mov	1, %g2
	sllx	%g2, 61, %g2
	or	%g2, SUN4V_TLB_W, %g2
	btst	%g2, %g4
	bz,pn	%xcc, sun4v_datatrap			! No -- really fault
	 nop
	casxa	[%g6] ASI_PHYS_CACHED, %g4, %g7		!  and write it out
	cmp	%g4, %g7
	bne,pn	%xcc, 1b
	 or	%g4, SUN4V_TLB_MODIFY|SUN4V_TLB_ACCESS|SUN4V_TLB_W, %g4
		! Update the modified bit
2:
	sethi	%hi(_C_LABEL(tsb_dmmu)), %g2
	ldx	[%g2 + %lo(_C_LABEL(tsb_dmmu))], %g2

	mov	%g1, %g7
	/* Construct TSB tag word. */
	add	%g1, 0x50, %g6
	ldxa	[%g6] ASI_PHYS_CACHED, %g6
	mov	%g3, %g1
	srlx	%g1, 22, %g1
	sllx	%g6, 48, %g6
	or	%g1, %g6, %g1

	srlx	%g3, PTSHIFT, %g3
	sethi	%hi(_C_LABEL(tsbsize)), %g5
	mov	512, %g6
	ld	[%g5 + %lo(_C_LABEL(tsbsize))], %g5
	sllx	%g6, %g5, %g5
	sub	%g5, 1, %g5
	and	%g3, %g5, %g3
	sllx	%g3, 4, %g3
	add	%g2, %g3, %g2

3:
	ld	[%g2], %g3
	btst	(TSB_TAG_LOCKED >> 32), %g3
	bnz,pn	%icc, 3b
	 or	%g3, (TSB_TAG_LOCKED >> 32), %g5
	casa	[%g2] ASI_NUCLEUS, %g3, %g5
	cmp	%g3, %g5
	bne,pn	%icc, 3b
	 nop
	membar	#StoreStore
	stx	%g4, [%g2 + 8]
	stx	%g1, [%g2]		! unlock

	mov	%o0, %g1
	mov	%o1, %g2
	mov	%o2, %g3

#define MAP_DTLB	0x1
#define MMU_UNMAP_ADDR	0x84
	add	%g7, 0x48, %o0
	ldxa	[%o0] ASI_PHYS_CACHED, %o0
	add	%g7, 0x50, %o1
	ldxa	[%o1] ASI_PHYS_CACHED, %o1
	mov	MAP_DTLB, %o2
	ta	MMU_UNMAP_ADDR

	mov	%g1, %o0
	mov	%g2, %o1
	mov	%g3, %o2

	retry
	NOTREACHED

sun4v_tl0_itsb_miss:
	GET_MMFSA(%g1)
	add	%g1, 0x8, %g3
	ldxa	[%g3] ASI_PHYS_CACHED, %g3
	add	%g1, 0x10, %g6
	ldxa	[%g6] ASI_PHYS_CACHED, %g6
	sethi	%hi(_C_LABEL(ctxbusy)), %g4
	ldx	[%g4 + %lo(_C_LABEL(ctxbusy))], %g4

	sllx	%g6, 3, %g6				! Make it into an offset into ctxbusy
	ldx	[%g4 + %g6], %g4			! Load up our page table.

	srax	%g3, HOLESHIFT, %g5			! Check for valid address
	brz,pt	%g5, 0f					! Should be zero or -1
	 inc	%g5					! Make -1 -> 0
	brnz,pn	%g5, sun4v_texttrap			! Error! In hole!
0:
	srlx	%g3, STSHIFT, %g6
	and	%g6, STMASK, %g6			! Index into pm_segs
	sll	%g6, 3, %g6
	add	%g4, %g6, %g4
	ldxa	[%g4] ASI_PHYS_CACHED, %g4		! Load page directory pointer

	srlx	%g3, PDSHIFT, %g6
	and	%g6, PDMASK, %g6
	sll	%g6, 3, %g6
	brz,pn	%g4, sun4v_texttrap			! NULL entry? check somewhere else
	 add	%g4, %g6, %g4
	ldxa	[%g4] ASI_PHYS_CACHED, %g4		! Load page table pointer

	srlx	%g3, PTSHIFT, %g6			! Convert to ptab offset
	and	%g6, PTMASK, %g6
	sll	%g6, 3, %g6
	brz,pn	%g4, sun4v_texttrap			! NULL entry? check somewhere else
	 add	%g4, %g6, %g6
1:
	ldxa	[%g6] ASI_PHYS_CACHED, %g4
	brgez,pn %g4, sun4v_texttrap			! Entry invalid?  Punt
	 or	%g4, SUN4V_TLB_ACCESS, %g7		! Update the access bit

	btst	SUN4V_TLB_EXEC, %g4
	bz,pn	%xcc, sun4v_texttrap
	 nop
	btst	SUN4V_TLB_ACCESS, %g4			! Need to update access git?
	bne,pt	%xcc, 2f
	 nop
	casxa	[%g6] ASI_PHYS_CACHED, %g4, %g7		!  and write it out
	cmp	%g4, %g7
	bne,pn	%xcc, 1b
	 or	%g4, SUN4V_TLB_ACCESS, %g4		! Update the modified bit
2:
	sethi	%hi(_C_LABEL(tsb_dmmu)), %g2
	ldx	[%g2 + %lo(_C_LABEL(tsb_dmmu))], %g2

	mov	%g1, %g7
	/* Construct TSB tag word. */
	add	%g1, 0x10, %g6
	ldxa	[%g6] ASI_PHYS_CACHED, %g6
	mov	%g3, %g1
	srlx	%g1, 22, %g1
	sllx	%g6, 48, %g6
	or	%g1, %g6, %g1

	srlx	%g3, PTSHIFT, %g3
	sethi	%hi(_C_LABEL(tsbsize)), %g5
	mov	512, %g6
	ld	[%g5 + %lo(_C_LABEL(tsbsize))], %g5
	sllx	%g6, %g5, %g5
	sub	%g5, 1, %g5
	and	%g3, %g5, %g3
	sllx	%g3, 4, %g3
	add	%g2, %g3, %g2

3:
	ld	[%g2], %g3
	btst	(TSB_TAG_LOCKED >> 32), %g3
	bnz,pn	%icc, 3b
	 or	%g3, (TSB_TAG_LOCKED >> 32), %g5
	casa	[%g2] ASI_NUCLEUS, %g3, %g5
	cmp	%g3, %g5
	bne,pn	%icc, 3b
	 nop
	membar	#StoreStore
	stx	%g4, [%g2 + 8]
	stx	%g1, [%g2]		! unlock

	retry
	NOTREACHED

kspill_normal:
	wrpr	0x90, %tt

	GET_CPUINFO_PA(%g1)
	wr	%g0, ASI_PHYS_CACHED, %asi

	SPILL	stxa, %g1 + CI_RW, 8, %asi
	saved

	stxa	%sp, [%g1 + CI_RWSP] %asi

	retry
	NOTREACHED

/*
 * Spill user windows into the PCB.
 */
pcbspill_normals:
	ba,pt	%xcc, pcbspill
	 wrpr	0x80, %tt

pcbspill_others:
	wrpr	0xa0, %tt

pcbspill:
	GET_CPUINFO_PA(%g6)
	wr	%g0, ASI_PHYS_CACHED, %asi
	ldxa	[%g6 + CI_CPCB] %asi, %g6

	sethi	%hi(_C_LABEL(ctxbusy)), %g1
	ldx	[%g1 + %lo(_C_LABEL(ctxbusy))], %g1
	ldx	[%g1], %g1

	srlx	%g6, STSHIFT, %g7
	and	%g7, STMASK, %g7
	sll	%g7, 3, %g7
	add	%g7, %g1, %g1
	ldxa	[%g1] ASI_PHYS_CACHED, %g1		! Load pointer to directory

	srlx	%g6, PDSHIFT, %g7			! Do page directory
	and	%g7, PDMASK, %g7
	sll	%g7, 3, %g7
	brz,pn	%g1, pcbspill_fail
	 add	%g7, %g1, %g1
	ldxa	[%g1] ASI_PHYS_CACHED, %g1

	srlx	%g6, PTSHIFT, %g7			! Convert to ptab offset
	and	%g7, PTMASK, %g7
	brz	%g1, pcbspill_fail
	 sll	%g7, 3, %g7
	add	%g1, %g7, %g7
	ldxa	[%g7] ASI_PHYS_CACHED, %g7		! This one is not
	brgez	%g7, pcbspill_fail
	 srlx	%g7, PGSHIFT, %g7			! Isolate PA part
	sll	%g6, 32-PGSHIFT, %g6			! And offset
	sllx	%g7, PGSHIFT+8, %g7			! There are 8 bits to the left of the PA in the TTE
	srl	%g6, 32-PGSHIFT, %g6
	srax	%g7, 8, %g7
	or	%g7, %g6, %g6				! Then combine them to form PA

!	wr	%g0, ASI_PHYS_CACHED, %asi		! Use ASI_PHYS_CACHED to prevent possible page faults
	
	lduba	[%g6 + PCB_NSAVED] %asi, %g7
	sllx	%g7, 7, %g5
	add	%g6, %g5, %g5
	SPILL	stxa, %g5 + PCB_RW, 8, %asi
	saved

	sllx	%g7, 3, %g5
	add	%g6, %g5, %g5
	stxa	%sp, [%g5 + PCB_RWSP] %asi

	inc	%g7
	stba	%g7, [%g6 + PCB_NSAVED] %asi

	retry
	NOTREACHED

pcbspill_fail:
	db_enter()
	NOTREACHED


sun4v_datatrap:
	GET_MMFSA(%g3)
	add	%g3, 0x48, %g1
	ldxa	[%g1] ASI_PHYS_CACHED, %g1
	add	%g3, 0x50, %g2
	ldxa	[%g2] ASI_PHYS_CACHED, %g2

	TRAP_SETUP -CC64FSZ-TF_SIZE
	or	%g1, %g2, %o3
	mov	%g1, %o4

	rdpr	%tt, %g4
	rdpr	%tstate, %g1
	rdpr	%tpc, %g2
	rdpr	%tnpc, %g3

	stx	%g1, [%sp + CC64FSZ + BIAS + TF_TSTATE]
	mov	%g4, %o1		! (type)
	stx	%g2, [%sp + CC64FSZ + BIAS + TF_PC]
	rd	%y, %g5
	stx	%g3, [%sp + CC64FSZ + BIAS + TF_NPC]
	st	%g5, [%sp + CC64FSZ + BIAS + TF_Y]
	mov	%g2, %o2		! (pc)
	sth	%o1, [%sp + CC64FSZ + BIAS + TF_TT]! debug

	cmp	%o1, T_FDMMU_PROT
	bne,pn	%icc, 1f
	 mov	SFSR_FV, %o5
	or	%o5, SFSR_W, %o5

1:
	wrpr	%g0, PSTATE_KERN, %pstate		! Get back to normal globals
	wrpr	%g0, 0, %gl

	stx	%g1, [%sp + CC64FSZ + BIAS + TF_G + (1*8)]
	stx	%g2, [%sp + CC64FSZ + BIAS + TF_G + (2*8)]
	add	%sp, CC64FSZ + BIAS, %o0		! (&tf)
	stx	%g3, [%sp + CC64FSZ + BIAS + TF_G + (3*8)]
	stx	%g4, [%sp + CC64FSZ + BIAS + TF_G + (4*8)]
	stx	%g5, [%sp + CC64FSZ + BIAS + TF_G + (5*8)]
	rdpr	%pil, %g5
	stx	%g6, [%sp + CC64FSZ + BIAS + TF_G + (6*8)]
	stx	%g7, [%sp + CC64FSZ + BIAS + TF_G + (7*8)]
	stb	%g5, [%sp + CC64FSZ + BIAS + TF_PIL]
	stb	%g5, [%sp + CC64FSZ + BIAS + TF_OLDPIL]

	/*
	 * Phew, ready to enable traps and call C code.
	 */
	wrpr	%g0, 0, %tl

	GET_CPUINFO_VA(%g7)
	ldx	[%g7 + CI_RWSP], %g2
	brz,pt	%g2, 1f
	 nop

	ldx	[%g7 + CI_RW + (0*8)], %l0
	ldx	[%g7 + CI_RW + (1*8)], %l1
	ldx	[%g7 + CI_RW + (2*8)], %l2
	ldx	[%g7 + CI_RW + (3*8)], %l3
	ldx	[%g7 + CI_RW + (4*8)], %l4
	ldx	[%g7 + CI_RW + (5*8)], %l5
	ldx	[%g7 + CI_RW + (6*8)], %l6
	ldx	[%g7 + CI_RW + (7*8)], %l7
	stx	%l0, [%g2 + BIAS + (0*8)]
	stx	%l1, [%g2 + BIAS + (1*8)]
	stx	%l2, [%g2 + BIAS + (2*8)]
	stx	%l3, [%g2 + BIAS + (3*8)]
	stx	%l4, [%g2 + BIAS + (4*8)]
	stx	%l5, [%g2 + BIAS + (5*8)]
	stx	%l6, [%g2 + BIAS + (6*8)]
	stx	%l7, [%g2 + BIAS + (7*8)]
	ldx	[%g7 + CI_RW + (8*8)], %l0
	ldx	[%g7 + CI_RW + (9*8)], %l1
	ldx	[%g7 + CI_RW + (10*8)], %l2
	ldx	[%g7 + CI_RW + (11*8)], %l3
	ldx	[%g7 + CI_RW + (12*8)], %l4
	ldx	[%g7 + CI_RW + (13*8)], %l5
	ldx	[%g7 + CI_RW + (14*8)], %l6
	ldx	[%g7 + CI_RW + (15*8)], %l7
	stx	%l0, [%g2 + BIAS + (8*8)]
	stx	%l1, [%g2 + BIAS + (9*8)]
	stx	%l2, [%g2 + BIAS + (10*8)]
	stx	%l3, [%g2 + BIAS + (11*8)]
	stx	%l4, [%g2 + BIAS + (12*8)]
	stx	%l5, [%g2 + BIAS + (13*8)]
	stx	%l6, [%g2 + BIAS + (14*8)]
	stx	%l7, [%g2 + BIAS + (15*8)]

	stx	%g0, [%g7 + CI_RWSP]
1:

	wr	%g0, ASI_PRIMARY_NOFAULT, %asi	! Restore default ASI
	wrpr	%g0, PSTATE_INTR, %pstate	! traps on again
	call	_C_LABEL(data_access_fault)	! data_acces_fault(tf, type, ...)
	 nop

	ba,a,pt	%icc, return_from_trap
	 nop
	NOTREACHED

sun4v_texttrap:
	GET_MMFSA(%g3)
	add	%g3, 0x08, %g1
	ldxa	[%g1] ASI_PHYS_CACHED, %g1
	add	%g3, 0x10, %g2
	ldxa	[%g2] ASI_PHYS_CACHED, %g2

	TRAP_SETUP -CC64FSZ-TF_SIZE

	or	%g1, %g2, %o2
	clr	%o3

	rdpr	%tt, %g4
	rdpr	%tstate, %g1
	rdpr	%tpc, %g2
	rdpr	%tnpc, %g3

	stx	%g1, [%sp + CC64FSZ + BIAS + TF_TSTATE]
	mov	%g4, %o1		! (type)
	stx	%g2, [%sp + CC64FSZ + BIAS + TF_PC]
	rd	%y, %g5
	stx	%g3, [%sp + CC64FSZ + BIAS + TF_NPC]
	st	%g5, [%sp + CC64FSZ + BIAS + TF_Y]
	sth	%o1, [%sp + CC64FSZ + BIAS + TF_TT]! debug

	wrpr	%g0, PSTATE_KERN, %pstate		! Get back to normal globals
	wrpr	%g0, 0, %gl

	stx	%g1, [%sp + CC64FSZ + BIAS + TF_G + (1*8)]
	stx	%g2, [%sp + CC64FSZ + BIAS + TF_G + (2*8)]
	add	%sp, CC64FSZ + BIAS, %o0		! (&tf)
	stx	%g3, [%sp + CC64FSZ + BIAS + TF_G + (3*8)]
	stx	%g4, [%sp + CC64FSZ + BIAS + TF_G + (4*8)]
	stx	%g5, [%sp + CC64FSZ + BIAS + TF_G + (5*8)]
	rdpr	%pil, %g5
	stx	%g6, [%sp + CC64FSZ + BIAS + TF_G + (6*8)]
	stx	%g7, [%sp + CC64FSZ + BIAS + TF_G + (7*8)]
	stb	%g5, [%sp + CC64FSZ + BIAS + TF_PIL]
	stb	%g5, [%sp + CC64FSZ + BIAS + TF_OLDPIL]

	/*
	 * Phew, ready to enable traps and call C code.
	 */
	wrpr	%g0, 0, %tl

	GET_CPUINFO_VA(%g7)
	ldx	[%g7 + CI_RWSP], %g2
	brz,pt	%g2, 1f
	 nop

	ldx	[%g7 + CI_RW + (0*8)], %l0
	ldx	[%g7 + CI_RW + (1*8)], %l1
	ldx	[%g7 + CI_RW + (2*8)], %l2
	ldx	[%g7 + CI_RW + (3*8)], %l3
	ldx	[%g7 + CI_RW + (4*8)], %l4
	ldx	[%g7 + CI_RW + (5*8)], %l5
	ldx	[%g7 + CI_RW + (6*8)], %l6
	ldx	[%g7 + CI_RW + (7*8)], %l7
	stx	%l0, [%g2 + BIAS + (0*8)]
	stx	%l1, [%g2 + BIAS + (1*8)]
	stx	%l2, [%g2 + BIAS + (2*8)]
	stx	%l3, [%g2 + BIAS + (3*8)]
	stx	%l4, [%g2 + BIAS + (4*8)]
	stx	%l5, [%g2 + BIAS + (5*8)]
	stx	%l6, [%g2 + BIAS + (6*8)]
	stx	%l7, [%g2 + BIAS + (7*8)]
	ldx	[%g7 + CI_RW + (8*8)], %l0
	ldx	[%g7 + CI_RW + (9*8)], %l1
	ldx	[%g7 + CI_RW + (10*8)], %l2
	ldx	[%g7 + CI_RW + (11*8)], %l3
	ldx	[%g7 + CI_RW + (12*8)], %l4
	ldx	[%g7 + CI_RW + (13*8)], %l5
	ldx	[%g7 + CI_RW + (14*8)], %l6
	ldx	[%g7 + CI_RW + (15*8)], %l7
	stx	%l0, [%g2 + BIAS + (8*8)]
	stx	%l1, [%g2 + BIAS + (9*8)]
	stx	%l2, [%g2 + BIAS + (10*8)]
	stx	%l3, [%g2 + BIAS + (11*8)]
	stx	%l4, [%g2 + BIAS + (12*8)]
	stx	%l5, [%g2 + BIAS + (13*8)]
	stx	%l6, [%g2 + BIAS + (14*8)]
	stx	%l7, [%g2 + BIAS + (15*8)]

	stx	%g0, [%g7 + CI_RWSP]
1:

	wr	%g0, ASI_PRIMARY_NOFAULT, %asi	! Restore default ASI
	wrpr	%g0, PSTATE_INTR, %pstate	! traps on again
	call	_C_LABEL(text_access_fault)	! text_access_fault(tf, type, ...)
	 nop

	ba,a,pt	%icc, return_from_trap
	 nop
	NOTREACHED

#endif

/*
 * We're here because we took an alignment fault in NUCLEUS context.
 * This could be a kernel bug or it could be due to saving or restoring
 * a user window to/from an invalid stack pointer.
 * 
 * If the latter is the case, we could try to emulate unaligned accesses, 
 * but we really don't know where to store the registers since we can't 
 * determine if there's a stack bias.  Or we could store all the regs 
 * into the PCB and punt, until the user program uses up all the CPU's
 * register windows and we run out of places to store them.  So for
 * simplicity we'll just blow them away and enter the trap code which
 * will generate a bus error.  Debugging the problem will be a bit
 * complicated since lots of register windows will be lost, but what
 * can we do?
 * 
 * XXX The trap code generates SIGKILL for now.
 */
checkalign:
	rdpr	%tl, %g2
	subcc	%g2, 1, %g1
	bneg,pn	%icc, slowtrap		! Huh?
	 nop

	wrpr	%g1, 0, %tl
	rdpr	%tt, %g7
	rdpr	%tstate, %g4
	andn	%g7, 0x07f, %g5		! Window spill traps are all 0b 0000 10xx xxxx
	cmp	%g5, 0x080		! Window fill traps are all 0b 0000 11xx xxxx
	bne,a,pn %icc, slowtrap
	 nop

	/*
         * %g1 -- current tl
	 * %g2 -- original tl
	 * %g4 -- tstate
         * %g7 -- tt
	 */

	and	%g4, CWP, %g5
	wrpr	%g5, %cwp		! Go back to the original register window

	rdpr	%otherwin, %g6
	rdpr	%cansave, %g5
	add	%g5, %g6, %g5
	wrpr	%g0, 0, %otherwin	! Just blow away all user windows
	wrpr	%g5, 0, %cansave
	rdpr	%canrestore, %g5
	wrpr	%g5, 0, %cleanwin

	wrpr	%g0, T_ALIGN, %tt	! This was an alignment fault 
	/*
	 * Now we need to determine if this was a userland store/load or not.
	 * Userland stores occur in anything other than the kernel spill/fill
	 * handlers (trap type 0x9x/0xdx).
	 */
	and	%g7, 0xff0, %g5
	cmp	%g5, 0x90
	bz,pn	%icc, slowtrap
	 nop
	cmp	%g5, 0xd0
	bz,pn	%icc, slowtrap
	 nop
	and	%g7, 0xfc0, %g5
	wrpr	%g5, 0, %tt
	ba,a,pt	%icc, slowtrap
	 nop

/*
 * slowtrap() builds a trap frame and calls trap().
 * This is called `slowtrap' because it *is*....
 * We have to build a full frame for ptrace(), for instance.
 *
 * Registers:
 *
 */
slowtrap:
	TRAP_SETUP -CC64FSZ-TF_SIZE

	rdpr	%tt, %g4
	rdpr	%tstate, %g1
	rdpr	%tpc, %g2
	rdpr	%tnpc, %g3

Lslowtrap_reenter:
	stx	%g1, [%sp + CC64FSZ + BIAS + TF_TSTATE]
	mov	%g4, %o1		! (type)
	stx	%g2, [%sp + CC64FSZ + BIAS + TF_PC]
	rd	%y, %g5
	stx	%g3, [%sp + CC64FSZ + BIAS + TF_NPC]
	mov	%g1, %o3		! (pstate)
	st	%g5, [%sp + CC64FSZ + BIAS + TF_Y]
	mov	%g2, %o2		! (pc)
	sth	%o1, [%sp + CC64FSZ + BIAS + TF_TT]! debug

	NORMAL_GLOBALS()

	stx	%g1, [%sp + CC64FSZ + BIAS + TF_G + (1*8)]
	stx	%g2, [%sp + CC64FSZ + BIAS + TF_G + (2*8)]
	add	%sp, CC64FSZ + BIAS, %o0		! (&tf)
	stx	%g3, [%sp + CC64FSZ + BIAS + TF_G + (3*8)]
	stx	%g4, [%sp + CC64FSZ + BIAS + TF_G + (4*8)]
	stx	%g5, [%sp + CC64FSZ + BIAS + TF_G + (5*8)]
	rdpr	%pil, %g5
	stx	%g6, [%sp + CC64FSZ + BIAS + TF_G + (6*8)]
	stx	%g7, [%sp + CC64FSZ + BIAS + TF_G + (7*8)]
	stb	%g5, [%sp + CC64FSZ + BIAS + TF_PIL]
	stb	%g5, [%sp + CC64FSZ + BIAS + TF_OLDPIL]

	/*
	 * Phew, ready to enable traps and call C code.
	 */
	wrpr	%g0, 0, %tl

	GET_CPUINFO_VA(%g7)
#ifdef SUN4V
	ldx	[%g7 + CI_RWSP], %g2
	brz,pt	%g2, 1f
	 nop

	ldx	[%g7 + CI_RW + (0*8)], %l0
	ldx	[%g7 + CI_RW + (1*8)], %l1
	ldx	[%g7 + CI_RW + (2*8)], %l2
	ldx	[%g7 + CI_RW + (3*8)], %l3
	ldx	[%g7 + CI_RW + (4*8)], %l4
	ldx	[%g7 + CI_RW + (5*8)], %l5
	ldx	[%g7 + CI_RW + (6*8)], %l6
	ldx	[%g7 + CI_RW + (7*8)], %l7
	stx	%l0, [%g2 + BIAS + (0*8)]
	stx	%l1, [%g2 + BIAS + (1*8)]
	stx	%l2, [%g2 + BIAS + (2*8)]
	stx	%l3, [%g2 + BIAS + (3*8)]
	stx	%l4, [%g2 + BIAS + (4*8)]
	stx	%l5, [%g2 + BIAS + (5*8)]
	stx	%l6, [%g2 + BIAS + (6*8)]
	stx	%l7, [%g2 + BIAS + (7*8)]
	ldx	[%g7 + CI_RW + (8*8)], %l0
	ldx	[%g7 + CI_RW + (9*8)], %l1
	ldx	[%g7 + CI_RW + (10*8)], %l2
	ldx	[%g7 + CI_RW + (11*8)], %l3
	ldx	[%g7 + CI_RW + (12*8)], %l4
	ldx	[%g7 + CI_RW + (13*8)], %l5
	ldx	[%g7 + CI_RW + (14*8)], %l6
	ldx	[%g7 + CI_RW + (15*8)], %l7
	stx	%l0, [%g2 + BIAS + (8*8)]
	stx	%l1, [%g2 + BIAS + (9*8)]
	stx	%l2, [%g2 + BIAS + (10*8)]
	stx	%l3, [%g2 + BIAS + (11*8)]
	stx	%l4, [%g2 + BIAS + (12*8)]
	stx	%l5, [%g2 + BIAS + (13*8)]
	stx	%l6, [%g2 + BIAS + (14*8)]
	stx	%l7, [%g2 + BIAS + (15*8)]

	stx	%g0, [%g7 + CI_RWSP]
1:
#endif

	wr	%g0, ASI_PRIMARY_NOFAULT, %asi		! Restore default ASI
	wrpr	%g0, PSTATE_INTR, %pstate	! traps on again
	call	_C_LABEL(trap)			! trap(tf, type, pc, pstate)
	 nop

	ba,a,pt	%icc, return_from_trap
	 nop
	NOTREACHED

/*
 * Do a `software' trap by re-entering the trap code, possibly first
 * switching from interrupt stack to kernel stack.  This is used for
 * scheduling and signal ASTs (which generally occur from softclock or
 * tty or net interrupts).
 *
 * We enter with the trap type in %g1.  All we have to do is jump to
 * Lslowtrap_reenter above, but maybe after switching stacks....
 *
 * We should be running alternate globals.  The normal globals and
 * out registers were just loaded from the old trap frame.
 *
 *	Input Params:
 *	%g1 = tstate
 *	%g2 = tpc
 *	%g3 = tnpc
 *	%g4 = tt == T_AST
 */
softtrap:
	GET_CPUINFO_VA(%g5)
	sethi	%hi(EINTSTACK-INTSTACK), %g7
	sub	%g5, BIAS, %g5
	dec	%g7

	sub	%g5, %sp, %g5
	andncc	%g5, %g7, %g0
	bnz,pt	%xcc, Lslowtrap_reenter
	 nop
	GET_CPCB(%g7)
	set	USPACE-CC64FSZ-TF_SIZE-BIAS, %g5
	add	%g7, %g5, %g6
	stx	%g1, [%g6 + CC64FSZ + BIAS + TF_FAULT]		! Generate a new trapframe
	stx	%i0, [%g6 + CC64FSZ + BIAS + TF_O + (0*8)]	!	but don't bother with
	stx	%i1, [%g6 + CC64FSZ + BIAS + TF_O + (1*8)]	!	locals and ins
	stx	%i2, [%g6 + CC64FSZ + BIAS + TF_O + (2*8)]
	stx	%i3, [%g6 + CC64FSZ + BIAS + TF_O + (3*8)]
	stx	%i4, [%g6 + CC64FSZ + BIAS + TF_O + (4*8)]
	stx	%i5, [%g6 + CC64FSZ + BIAS + TF_O + (5*8)]
	stx	%i6, [%g6 + CC64FSZ + BIAS + TF_O + (6*8)]
	stx	%i7, [%g6 + CC64FSZ + BIAS + TF_O + (7*8)]
#ifdef DEBUG
	ldx	[%sp + CC64FSZ + BIAS + TF_I + (0*8)], %l0	! Copy over the rest of the regs
	ldx	[%sp + CC64FSZ + BIAS + TF_I + (1*8)], %l1	! But just dirty the locals
	ldx	[%sp + CC64FSZ + BIAS + TF_I + (2*8)], %l2
	ldx	[%sp + CC64FSZ + BIAS + TF_I + (3*8)], %l3
	ldx	[%sp + CC64FSZ + BIAS + TF_I + (4*8)], %l4
	ldx	[%sp + CC64FSZ + BIAS + TF_I + (5*8)], %l5
	ldx	[%sp + CC64FSZ + BIAS + TF_I + (6*8)], %l6
	ldx	[%sp + CC64FSZ + BIAS + TF_I + (7*8)], %l7
	stx	%l0, [%g6 + CC64FSZ + BIAS + TF_I + (0*8)]
	stx	%l1, [%g6 + CC64FSZ + BIAS + TF_I + (1*8)]
	stx	%l2, [%g6 + CC64FSZ + BIAS + TF_I + (2*8)]
	stx	%l3, [%g6 + CC64FSZ + BIAS + TF_I + (3*8)]
	stx	%l4, [%g6 + CC64FSZ + BIAS + TF_I + (4*8)]
	stx	%l5, [%g6 + CC64FSZ + BIAS + TF_I + (5*8)]
	stx	%l6, [%g6 + CC64FSZ + BIAS + TF_I + (6*8)]
	stx	%l7, [%g6 + CC64FSZ + BIAS + TF_I + (7*8)]
	ldx	[%sp + CC64FSZ + BIAS + TF_L + (0*8)], %l0
	ldx	[%sp + CC64FSZ + BIAS + TF_L + (1*8)], %l1
	ldx	[%sp + CC64FSZ + BIAS + TF_L + (2*8)], %l2
	ldx	[%sp + CC64FSZ + BIAS + TF_L + (3*8)], %l3
	ldx	[%sp + CC64FSZ + BIAS + TF_L + (4*8)], %l4
	ldx	[%sp + CC64FSZ + BIAS + TF_L + (5*8)], %l5
	ldx	[%sp + CC64FSZ + BIAS + TF_L + (6*8)], %l6
	ldx	[%sp + CC64FSZ + BIAS + TF_L + (7*8)], %l7
	stx	%l0, [%g6 + CC64FSZ + BIAS + TF_L + (0*8)]
	stx	%l1, [%g6 + CC64FSZ + BIAS + TF_L + (1*8)]
	stx	%l2, [%g6 + CC64FSZ + BIAS + TF_L + (2*8)]
	stx	%l3, [%g6 + CC64FSZ + BIAS + TF_L + (3*8)]
	stx	%l4, [%g6 + CC64FSZ + BIAS + TF_L + (4*8)]
	stx	%l5, [%g6 + CC64FSZ + BIAS + TF_L + (5*8)]
	stx	%l6, [%g6 + CC64FSZ + BIAS + TF_L + (6*8)]
	stx	%l7, [%g6 + CC64FSZ + BIAS + TF_L + (7*8)]
#endif	/* DEBUG */
	ba,pt	%xcc, Lslowtrap_reenter
	 mov	%g6, %sp

/*
 * syscall_setup() builds a trap frame and calls syscall().
 * sun_syscall is same but delivers sun system call number
 * XXX	should not have to save&reload ALL the registers just for
 *	ptrace...
 */
syscall_setup:
	TRAP_SETUP -CC64FSZ-TF_SIZE

#ifdef DEBUG
	rdpr	%tt, %o1	! debug
	sth	%o1, [%sp + CC64FSZ + BIAS + TF_TT]! debug
#endif	/* DEBUG */

	NORMAL_GLOBALS()

	stx	%g1, [%sp + CC64FSZ + BIAS + TF_G + ( 1*8)]
	mov	%g1, %o1			! code
	rdpr	%tpc, %o2			! (pc)
	stx	%g2, [%sp + CC64FSZ + BIAS + TF_G + ( 2*8)]
	rdpr	%tstate, %g1
	stx	%g3, [%sp + CC64FSZ + BIAS + TF_G + ( 3*8)]
	rdpr	%tnpc, %o3
	stx	%g4, [%sp + CC64FSZ + BIAS + TF_G + ( 4*8)]
	rd	%y, %o4
	stx	%g5, [%sp + CC64FSZ + BIAS + TF_G + ( 5*8)]
	stx	%g6, [%sp + CC64FSZ + BIAS + TF_G + ( 6*8)]
	wrpr	%g0, 0, %tl			! return to tl=0
	stx	%g7, [%sp + CC64FSZ + BIAS + TF_G + ( 7*8)]
	add	%sp, CC64FSZ + BIAS, %o0	! (&tf)

	stx	%g1, [%sp + CC64FSZ + BIAS + TF_TSTATE]
	stx	%o2, [%sp + CC64FSZ + BIAS + TF_PC]
	stx	%o3, [%sp + CC64FSZ + BIAS + TF_NPC]
	st	%o4, [%sp + CC64FSZ + BIAS + TF_Y]

	rdpr	%pil, %g5
	stb	%g5, [%sp + CC64FSZ + BIAS + TF_PIL]
	stb	%g5, [%sp + CC64FSZ + BIAS + TF_OLDPIL]

	wr	%g0, ASI_PRIMARY_NOFAULT, %asi	! Restore default ASI

	GET_CPUINFO_VA(%g7)
	call	_C_LABEL(syscall)		! syscall(&tf, code, pc)
	 wrpr	%g0, PSTATE_INTR, %pstate	! turn on interrupts

	/* see `proc_trampoline' for the reason for this label */
return_from_syscall:
	wrpr	%g0, PSTATE_KERN, %pstate	! Disable intterrupts
	wrpr	%g0, 0, %tl			! Return to tl==0
	ba,a,pt	%icc, return_from_trap
	 nop
	NOTREACHED

/*
 * interrupt_vector:
 *
 * Spitfire chips never get level interrupts directly from H/W.
 * Instead, all interrupts come in as interrupt_vector traps.
 * The interrupt number or handler address is an 11 bit number
 * encoded in the first interrupt data word.  Additional words
 * are application specific and used primarily for cross-calls.
 *
 * The interrupt vector handler then needs to identify the
 * interrupt source from the interrupt number and arrange to
 * invoke the interrupt handler.  This can either be done directly
 * from here, or a softint at a particular level can be issued.
 *
 * To call an interrupt directly and not overflow the trap stack,
 * the trap registers should be saved on the stack, registers
 * cleaned, trap-level decremented, the handler called, and then
 * the process must be reversed.
 *
 * To simplify life all we do here is issue an appropriate softint.
 *
 * Note:	It is impossible to identify or change a device's
 *		interrupt number until it is probed.  That's the
 *		purpose for all the funny interrupt acknowledge
 *		code.
 *
 */

/*
 * Vectored interrupts:
 *
 * When an interrupt comes in, interrupt_vector uses the interrupt
 * vector number to lookup the appropriate intrhand from the intrlev
 * array.  It then looks up the interrupt level from the intrhand
 * structure.  It uses the level to index the intrpending array,
 * which is 8 slots for each possible interrupt level (so we can
 * shift instead of multiply for address calculation).  It hunts for
 * any available slot at that level.  Available slots are NULL.
 *
 * NOTE: If no slots are available, we issue an un-vectored interrupt,
 * but it will probably be lost anyway.
 *
 * Then interrupt_vector uses the interrupt level in the intrhand
 * to issue a softint of the appropriate level.  The softint handler
 * figures out what level interrupt it's handling and pulls the first
 * intrhand pointer out of the intrpending array for that interrupt
 * level, puts a NULL in its place, clears the interrupt generator,
 * and invokes the interrupt handler.
 */

#ifdef DEBUG
#define INTRDEBUG_VECTOR	0x1
#define INTRDEBUG_LEVEL		0x2
#define INTRDEBUG_FUNC		0x4
#define INTRDEBUG_SPUR		0x8
	.globl	_C_LABEL(intrdebug)
_C_LABEL(intrdebug):	.word 0x0
/*
 * Note: we use the local label `97' to branch forward to, to skip
 * actual debugging code following a `intrdebug' bit test.
 */
#endif	/* DEBUG */
	.text
interrupt_vector:
	ldxa	[%g0] ASI_IRSR, %g1
	mov	IRDR_0H, %g2
	ldxa	[%g2] ASI_IRDR, %g2	! Get interrupt number
	membar	#Sync

	sethi	%hi(KERNBASE), %g3
	btst	IRSR_BUSY, %g1
	bz,pn	%icc, 3f		! Spurious interrupt
	 cmp	%g2, %g3
#ifdef MULTIPROCESSOR
	blu,pt	%xcc, Lsoftint_regular
	 and	%g2, MAXINTNUM-1, %g5	! XXX make sun4us work
	mov	IRDR_1H, %g3
	ldxa	[%g3] ASI_IRDR, %g3     ! Get IPI handler arg0
	mov	IRDR_2H, %g5
	ldxa	[%g5] ASI_IRDR, %g5     ! Get IPI handler arg1

	stxa	%g0, [%g0] ASI_IRSR	! Ack IRQ
	membar	#Sync			! Should not be needed due to retry

	jmpl	%g2, %g0
	 nop
	db_enter()
	NOTREACHED
#else
	bgeu,pn	%xcc, 3f
	 and	%g2, MAXINTNUM-1, %g5	! XXX make sun4us work
#endif

Lsoftint_regular:
	stxa	%g0, [%g0] ASI_IRSR	! Ack IRQ
	membar	#Sync			! Should not be needed due to retry

	sethi	%hi(_C_LABEL(intrlev)), %g3
	or	%g3, %lo(_C_LABEL(intrlev)), %g3
	sllx	%g5, 3, %g5		! Calculate entry number
	ldx	[%g3 + %g5], %g5	! We have a pointer to the handler
#ifdef DEBUG
	brnz,pt %g5, 1f
	 nop
	STACKFRAME -CC64FSZ		! Get a clean register window
	mov	%g2, %o1

	LOAD_ASCIZ(%o0, "interrupt_vector: vector %lx NULL\r\n")
	GLOBTOLOC
	call	prom_printf
	 clr	%g4
	LOCTOGLOB
	restore
	 nop
1:	
#endif	/* DEBUG */
	
	brz,pn	%g5, 3f			! NULL means it isn't registered yet.  Skip it.
	 nop

setup_sparcintr:
	ldx	[%g5+IH_PEND], %g6	! Check if already in use
	brnz,pn	%g6, ret_from_intr_vector ! Skip it if it's running
	 ldub	[%g5+IH_PIL], %g6	! Read interrupt mask
	GET_CPUINFO_VA(%g1)
	sll	%g6, 3+3, %g3	! Find start of table for this IPL
	add	%g1, CI_INTRPENDING, %g1
	add	%g1, %g3, %g1
1:
	ldx	[%g1], %g3		! Load list head
	add	%g5, IH_PEND, %g7
	casxa	[%g7] ASI_N, %g0, %g3
	brnz,pn	%g3, ret_from_intr_vector
	 nop
	stx	%g5, [%g1]

#ifdef DEBUG
	set	_C_LABEL(intrdebug), %g7
	ld	[%g7], %g7
	btst	INTRDEBUG_VECTOR, %g7
	bz,pt	%icc, 97f
	 nop

	STACKFRAME -CC64FSZ		! Get a clean register window
	LOAD_ASCIZ(%o0,\
	    "interrupt_vector: number %lx softint mask %lx pil %lu slot %p\r\n")
	mov	%g2, %o1
	rdpr	%pil, %o3
	mov	%g1, %o4
	GLOBTOLOC
	clr	%g4
	call	prom_printf
	 mov	%g6, %o2
	LOCTOGLOB
	restore
97:
#endif	/* DEBUG */	/* DEBUG */
	mov	1, %g7
	sll	%g7, %g6, %g6
	wr	%g6, 0, SET_SOFTINT	! Invoke a softint

ret_from_intr_vector:
	CLRTT
	retry
	NOTREACHED

3:
#ifdef DEBUG
	set	_C_LABEL(intrdebug), %g7
	ld	[%g7], %g7
	btst	INTRDEBUG_SPUR, %g7
	bz,pt	%icc, 97f
	 nop
#endif	/* DEBUG */
	STACKFRAME -CC64FSZ		! Get a clean register window
	LOAD_ASCIZ(%o0, "interrupt_vector: spurious vector %lx at pil %d\r\n")
	mov	%g2, %o1
	GLOBTOLOC
	clr	%g4
	call	prom_printf
	 rdpr	%pil, %o2
	LOCTOGLOB
	restore
97:
	ba,a	ret_from_intr_vector
	 nop				! XXX spitfire bug?

#ifdef SUN4V

sun4v_cpu_mondo:
	mov	0x3c0, %g1
	ldxa	[%g1] ASI_QUEUE, %g2

	GET_CPUINFO_PA(%g3)
	add	%g3, CI_CPUMQ, %g3
	ldxa	[%g3] ASI_PHYS_CACHED, %g3
	ldxa	[%g3 + %g2] ASI_PHYS_CACHED, %g4
	add	%g2, 8, %g5
	ldxa	[%g3 + %g5] ASI_PHYS_CACHED, %g5
	add	%g2, 16, %g6
	ldxa	[%g3 + %g6] ASI_PHYS_CACHED, %g6
	add	%g2, 64, %g2
	and	%g2, 0x7ff, %g2
	stxa	%g2, [%g1] ASI_QUEUE
	membar	#Sync

	mov	%g4, %g2
	mov	%g5, %g3
	mov	%g6, %g5
	jmpl	%g2, %g0
	 nop			! No store here!
	retry
	NOTREACHED

sun4v_dev_mondo:
	mov	0x3d0, %g1
	ldxa	[%g1] ASI_QUEUE, %g2

	GET_CPUINFO_PA(%g3)
	add	%g3, CI_DEVMQ, %g3
	ldxa	[%g3] ASI_PHYS_CACHED, %g3
	ldxa	[%g3 + %g2] ASI_PHYS_CACHED, %g5
	add	%g2, 64, %g2
	and	%g2, 0x7ff, %g2
	stxa	%g2, [%g1] ASI_QUEUE
	membar	#Sync

	cmp	%g5, MAXINTNUM
	bgeu,pt	%xcc, 1f
	 nop

	sethi	%hi(_C_LABEL(intrlev)), %g3
	or	%g3, %lo(_C_LABEL(intrlev)), %g3
	sllx	%g5, 3, %g5		! Calculate entry number
	ldx	[%g3 + %g5], %g5	! We have a pointer to the handler
1:
	brnz,pt	%g5, setup_sparcintr
	 nop

	ba,a	3b
	 nop

#endif

#ifdef MULTIPROCESSOR
NENTRY(sun4u_ipi_tlb_page_demap)
	rdpr	%pstate, %g1
	andn	%g1, PSTATE_IE, %g2
	wrpr	%g2, %pstate				! disable interrupts

	rdpr	%tl, %g2
	brnz	%g2, 1f
	 add	%g2, 1, %g4
	wrpr	%g0, %g4, %tl				! Switch to traplevel > 0
1:
	mov	CTX_PRIMARY, %g4
	andn	%g3, 0xfff, %g3				! drop unused va bits
	ldxa	[%g4] ASI_DMMU, %g6			! Save primary context
	sethi	%hi(KERNBASE), %g7
	membar	#LoadStore
	stxa	%g5, [%g4] ASI_DMMU			! Insert context to demap
	membar	#Sync
	or	%g3, DEMAP_PAGE_PRIMARY, %g3
	stxa	%g0, [%g3] ASI_DMMU_DEMAP
	stxa	%g0, [%g3] ASI_IMMU_DEMAP
	membar	#Sync
	flush	%g7
	stxa	%g6, [%g4] ASI_DMMU
	membar	#Sync
	flush	%g7

	wrpr	%g2, %tl
	wrpr	%g1, %pstate
	ba,a	ret_from_intr_vector
	 nop

NENTRY(sun4u_ipi_tlb_context_demap)
	rdpr	%pstate, %g1
	andn	%g1, PSTATE_IE, %g2
	wrpr	%g2, %pstate				! disable interrupts

	rdpr	%tl, %g2
	brnz	%g2, 1f
	 add	%g2, 1, %g4
	wrpr	%g0, %g4, %tl				! Switch to traplevel > 0
1:
	mov	CTX_PRIMARY, %g4
	sethi	%hi(KERNBASE), %g7
	ldxa	[%g4] ASI_DMMU, %g6			! Save primary context
	membar	#LoadStore
	stxa	%g3, [%g4] ASI_DMMU			! Insert context to demap
	membar	#Sync
	set	DEMAP_CTX_PRIMARY, %g3
	stxa	%g0, [%g3] ASI_DMMU_DEMAP
	stxa	%g0, [%g3] ASI_IMMU_DEMAP
	membar	#Sync
	flush	%g7
	stxa	%g6, [%g4] ASI_DMMU
	membar	#Sync
	flush	%g7

	wrpr	%g2, %tl
	wrpr	%g1, %pstate
	ba,a	ret_from_intr_vector
	 nop

#ifdef SUN4V
NENTRY(sun4v_ipi_tlb_page_demap)
	mov	%o0, %g1
	mov	%o1, %g2
	mov	%o2, %g4
	mov	%g3, %o0
	mov	%g5, %o1
	mov	MAP_DTLB|MAP_ITLB, %o2
	ta	MMU_UNMAP_ADDR
	mov	%g1, %o0
	mov	%g2, %o1
	mov	%g4, %o2

	retry

NENTRY(sun4v_ipi_tlb_context_demap)
	NOTREACHED
#endif

NENTRY(ipi_save_fpstate)
	GET_CPUINFO_VA(%g1)
	ldx	[%g1 + CI_FPPROC], %g2
	cmp	%g2, %g3
	bne,pn	%xcc, 3f

	 mov	CTX_SECONDARY, %g2
	GET_MMU_CONTEXTID(%g6, %g2)
	membar	#LoadStore
	SET_MMU_CONTEXTID(%g0, %g2)
	membar	#Sync

	ldx	[%g3 + P_FPSTATE], %g3

	rdpr	%pstate, %g2		! enable FP before we begin
	rd	%fprs, %g4
	wr	%g0, FPRS_FEF, %fprs
	or	%g2, PSTATE_PEF, %g2
	wrpr	%g2, 0, %pstate

	stx	%fsr, [%g3 + FS_FSR]	! f->fs_fsr = getfsr();

	rd	%gsr, %g2		! Save %gsr
	st	%g2, [%g3 + FS_GSR]

	add	%g3, FS_REGS, %g3	! This is zero...
	btst	FPRS_DL, %g4		! Lower FPU clean?
	bz,a,pt	%icc, 1f		! Then skip it
	 add	%g3, 128, %g3		! Skip a block

	membar	#Sync
	stda	%f0, [%g3] ASI_BLK_S	! f->fs_f0 = etc;
	inc	BLOCK_SIZE, %g3
	stda	%f16, [%g3] ASI_BLK_S
	inc	BLOCK_SIZE, %g3
1:
	btst	FPRS_DU, %g4		! Upper FPU clean?
	bz,pt	%icc, 2f		! Then skip it
	 nop

	membar	#Sync
	stda	%f32, [%g3] ASI_BLK_S
	inc	BLOCK_SIZE, %g3
	stda	%f48, [%g3] ASI_BLK_S
2:
	membar	#Sync			! Finish operation so we can
	wr	%g0, FPRS_FEF, %fprs	! Mark FPU clean

	stx	%g0, [%g1 + CI_FPPROC]	! fpproc = NULL
	mov	CTX_SECONDARY, %g2
	SET_MMU_CONTEXTID(%g6, %g2)
	membar	#Sync
3:
	ba	ret_from_intr_vector
	 nop

NENTRY(ipi_drop_fpstate)
	rdpr	%pstate, %g1
	wr	%g0, FPRS_FEF, %fprs
	or	%g1, PSTATE_PEF, %g1
	wrpr	%g1, 0, %pstate
	GET_CPUINFO_VA(%g1)
	ldx	[%g1 + CI_FPPROC], %g5
	cmp	%g5, %g3
	bne,pn	%xcc, 1f
	 nop
	stx	%g0, [%g1 + CI_FPPROC]		! fpproc = NULL
1:
	ba	ret_from_intr_vector
	 nop

NENTRY(ipi_softint)
	ba	ret_from_intr_vector
	 wr	%g3, 0, SET_SOFTINT

NENTRY(ipi_db)
	ba	slowtrap
	 wrpr	%g0, T_BREAKPOINT, %tt

#endif

/*
 * Ultra1 and Ultra2 CPUs use soft interrupts for everything.  What we do
 * on a soft interrupt, is we should check which bits in ASR_SOFTINT(0x16)
 * are set, handle those interrupts, then clear them by setting the
 * appropriate bits in ASR_CLEAR_SOFTINT(0x15).
 *
 * We have an array of 8 interrupt vector slots for each of 15 interrupt
 * levels.  If a vectored interrupt can be dispatched, the dispatch
 * routine will place a pointer to an intrhand structure in one of
 * the slots.  The interrupt handler will go through the list to look
 * for an interrupt to dispatch.  If it finds one it will pull it off
 * the list, free the entry, and call the handler.  The code is like
 * this:
 *
 *	for (i=0; i<8; i++)
 *		if (ih = intrpending[intlev][i]) {
 *			intrpending[intlev][i] = NULL;
 *			if ((*ih->ih_fun)(ih->ih_arg ? ih->ih_arg : &frame))
 *				return;
 *			strayintr(&frame);
 *			return;
 *		}
 *
 * Otherwise we go back to the old style of polled interrupts.
 *
 * After preliminary setup work, the interrupt is passed to each
 * registered handler in turn.  These are expected to return nonzero if
 * they took care of the interrupt.  If a handler claims the interrupt,
 * we exit (hardware interrupts are latched in the requestor so we'll
 * just take another interrupt in the unlikely event of simultaneous
 * interrupts from two different devices at the same level).  If we go
 * through all the registered handlers and no one claims it, we report a
 * stray interrupt.  This is more or less done as:
 *
 *	for (ih = intrhand[intlev]; ih; ih = ih->ih_next)
 *		if ((*ih->ih_fun)(ih->ih_arg ? ih->ih_arg : &frame))
 *			return;
 *	strayintr(&frame);
 *
 * Inputs:
 *	%l0 = %tstate
 *	%l1 = return pc
 *	%l2 = return npc
 *	%l3 = interrupt level
 *	(software interrupt only) %l4 = bits to clear in interrupt register
 *
 * Internal:
 *	%l4, %l5: local variables
 *	%l6 = %y
 *	%l7 = %g1
 *	%g2..%g7 go to stack
 *
 * An interrupt frame is built in the space for a full trapframe;
 * this contains the psr, pc, npc, and interrupt level.
 *
 * The level of this interrupt is determined by:
 *
 *       IRQ# = %tt - 0x40
 */

	.globl _C_LABEL(sparc_interrupt)	! This is for interrupt debugging
_C_LABEL(sparc_interrupt):
	/*
	 * If this is a %tick softint, clear it then call interrupt_vector.
	 */
	rd	SOFTINT, %g1
	set	(TICK_INT|STICK_INT), %g2
	andcc	%g2, %g1, %g2
	bz,pt	%icc, 0f
	 GET_CPUINFO_VA(%g7)
	wr	%g2, 0, CLEAR_SOFTINT
	ba,pt	%icc, setup_sparcintr
	 add	%g7, CI_TICKINTR, %g5
0:
	INTR_SETUP -CC64FSZ-TF_SIZE-8

	NORMAL_GLOBALS()

	/* Save normal globals */
	stx	%g1, [%sp + CC64FSZ + BIAS + TF_G + ( 1*8)]
	stx	%g2, [%sp + CC64FSZ + BIAS + TF_G + ( 2*8)]
	stx	%g3, [%sp + CC64FSZ + BIAS + TF_G + ( 3*8)]
	stx	%g4, [%sp + CC64FSZ + BIAS + TF_G + ( 4*8)]
	stx	%g5, [%sp + CC64FSZ + BIAS + TF_G + ( 5*8)]
	stx	%g6, [%sp + CC64FSZ + BIAS + TF_G + ( 6*8)]
	stx	%g7, [%sp + CC64FSZ + BIAS + TF_G + ( 7*8)]

999:	flushw			! Do not remove this instruction -- causes interrupt loss
	.section	.sun4v_patch, "ax"
	.word	999b
	nop
	.previous

	GET_CPUINFO_VA(%g7)
#ifdef SUN4V
	ldx	[%g7 + CI_RWSP], %g2
	brz,pt	%g2, 1f
	 nop

	ldx	[%g7 + CI_RW + (0*8)], %l0
	ldx	[%g7 + CI_RW + (1*8)], %l1
	ldx	[%g7 + CI_RW + (2*8)], %l2
	ldx	[%g7 + CI_RW + (3*8)], %l3
	ldx	[%g7 + CI_RW + (4*8)], %l4
	ldx	[%g7 + CI_RW + (5*8)], %l5
	ldx	[%g7 + CI_RW + (6*8)], %l6
	ldx	[%g7 + CI_RW + (7*8)], %l7
	stx	%l0, [%g2 + BIAS + (0*8)]
	stx	%l1, [%g2 + BIAS + (1*8)]
	stx	%l2, [%g2 + BIAS + (2*8)]
	stx	%l3, [%g2 + BIAS + (3*8)]
	stx	%l4, [%g2 + BIAS + (4*8)]
	stx	%l5, [%g2 + BIAS + (5*8)]
	stx	%l6, [%g2 + BIAS + (6*8)]
	stx	%l7, [%g2 + BIAS + (7*8)]
	ldx	[%g7 + CI_RW + (8*8)], %l0
	ldx	[%g7 + CI_RW + (9*8)], %l1
	ldx	[%g7 + CI_RW + (10*8)], %l2
	ldx	[%g7 + CI_RW + (11*8)], %l3
	ldx	[%g7 + CI_RW + (12*8)], %l4
	ldx	[%g7 + CI_RW + (13*8)], %l5
	ldx	[%g7 + CI_RW + (14*8)], %l6
	ldx	[%g7 + CI_RW + (15*8)], %l7
	stx	%l0, [%g2 + BIAS + (8*8)]
	stx	%l1, [%g2 + BIAS + (9*8)]
	stx	%l2, [%g2 + BIAS + (10*8)]
	stx	%l3, [%g2 + BIAS + (11*8)]
	stx	%l4, [%g2 + BIAS + (12*8)]
	stx	%l5, [%g2 + BIAS + (13*8)]
	stx	%l6, [%g2 + BIAS + (14*8)]
	stx	%l7, [%g2 + BIAS + (15*8)]

	stx	%g0, [%g7 + CI_RWSP]
1:
#endif

	rd	%y, %l6
	INCR _C_LABEL(uvmexp)+V_INTR	! cnt.v_intr++; (clobbers %o0,%o1,%o2)
	rdpr	%tt, %l5		! Find out our current IPL
	rdpr	%tstate, %l0
	rdpr	%tpc, %l1
	rdpr	%tnpc, %l2
	wrpr	%g0, 0, %tl

	! Dump our trap frame now we have taken the IRQ
	stw	%l6, [%sp + CC64FSZ + BIAS + TF_Y]	! Silly, but we need to save this for rft
	sth	%l5, [%sp + CC64FSZ + BIAS + TF_TT]! debug
	stx	%l0, [%sp + CC64FSZ + BIAS + TF_TSTATE]	! set up intrframe/clockframe
	stx	%l1, [%sp + CC64FSZ + BIAS + TF_PC]
	btst	TSTATE_PRIV, %l0		! User mode?
	stx	%l2, [%sp + CC64FSZ + BIAS + TF_NPC]
	stx	%fp, [%sp + CC64FSZ + BIAS + TF_KSTACK]	!  old frame pointer
	
	sub	%l5, 0x40, %l6			! Convert to interrupt level
	stb	%l6, [%sp + CC64FSZ + BIAS + TF_PIL]	! set up intrframe/clockframe
	rdpr	%pil, %o1
	stb	%o1, [%sp + CC64FSZ + BIAS + TF_OLDPIL]	! old %pil
	clr	%l5			! Zero handled count
	mov	1, %l3			! Ack softint
	sll	%l3, %l6, %l3		! Generate IRQ mask

	wrpr	%l6, %pil

	/*
	 * Set handled_intr_level and save the old one so we can restore it
	 * later.
	 */
	ld	[%g7 + CI_HANDLED_INTR_LEVEL], %l7
	st	%l6, [%g7 + CI_HANDLED_INTR_LEVEL]
	st	%l7, [%sp + CC64FSZ + BIAS + TF_SIZE]

sparc_intr_retry:
	wr	%l3, 0, CLEAR_SOFTINT	! (don't clear possible %tick IRQ)
	wrpr	%g0, PSTATE_INTR, %pstate	! Reenable interrupts
	sll	%l6, 3+3, %l2
	add	%g7, CI_INTRPENDING, %l4
	mov	8, %l7
	add	%l2, %l4, %l4

1:
	membar	#StoreLoad		! Make sure any failed casxa instructions complete
	ldx	[%l4], %l2		! Check a slot
	brz,pn	%l2, intrcmplt		! Empty list?

	 clr	%l7
	membar	#LoadStore
	casxa	[%l4] ASI_N, %l2, %l7	! Grab the entire list
	cmp	%l7, %l2
	bne,pn	%icc, 1b
	 nop

2:
	ldx	[%l2 + IH_PEND], %l7	! Load next pending
	add	%l2, IH_PEND, %l3
	clr	%l4
	casxa	[%l3] ASI_N, %l7, %l4	! Unlink from list
	cmp	%l7, %l4
	bne,pn	%xcc, 2b		! Retry?
	 add	%sp, CC64FSZ+BIAS, %o0	! tf = %sp + CC64FSZ + BIAS

	ldx	[%l2 + IH_ACK], %l1	! ih->ih_ack

	! At this point, the current ih could already be added
	! back to the pending table.

	call	_C_LABEL(intr_handler)
	 mov	%l2, %o1

	brz,pn	%l1, 0f
	 add	%l5, %o0, %l5		! Add handler return value
	ldx	[%l2 + IH_COUNT], %o0	! ih->ih_count.ec_count++;
	inc	%o0
	stx	%o0, [%l2 + IH_COUNT]

	jmpl	%l1, %o7		! (*ih->ih_ack)(ih)
	 mov	%l2, %o0
0:
	brnz,pn	%l7, 2b			! 'Nother?
	 mov	%l7, %l2

intrcmplt:
	/*
	 * Re-read SOFTINT to see if any new  pending interrupts
	 * at this level.
	 */
	mov	1, %l3			! Ack softint
	rd	SOFTINT, %l7		! %l5 contains #intr handled.
	sll	%l3, %l6, %l3		! Generate IRQ mask
	btst	%l3, %l7		! leave mask in %l3 for retry code
	bnz,pn	%icc, sparc_intr_retry
	 mov	1, %l5			! initialize intr count for next run

#ifdef DEBUG
	set	_C_LABEL(intrdebug), %o2
	ld	[%o2], %o2
	btst	INTRDEBUG_FUNC, %o2
	bz,a,pt	%icc, 97f
	 nop

	STACKFRAME -CC64FSZ		! Get a clean register window
	LOAD_ASCIZ(%o0, "sparc_interrupt:  done\r\n")
	GLOBTOLOC
	call	prom_printf
	 nop
	LOCTOGLOB
	restore
97:
#endif	/* DEBUG */

	/* Restore old handled_intr_level */
	ld	[%sp + CC64FSZ + BIAS + TF_SIZE], %l7
	st	%l7, [%g7 + CI_HANDLED_INTR_LEVEL]

	ldub	[%sp + CC64FSZ + BIAS + TF_OLDPIL], %l3	! restore old %pil
	wrpr	%g0, PSTATE_KERN, %pstate	! Disable interrupts
	wrpr	%l3, 0, %pil

	CHKPT %o1,%o2,5
	ba,a,pt	%icc, return_from_trap
	 nop

	.globl	return_from_trap, rft_kernel, rft_user
	.globl	softtrap, slowtrap
	.globl	syscall

/*
 * Various return-from-trap routines (see return_from_trap).
 */

/*
 * Return from trap.
 * registers are:
 *
 *	[%sp + CC64FSZ + BIAS] => trap frame
 *
 * We must load all global, out, and trap registers from the trap frame.
 *
 * If returning to kernel, we should be at the proper trap level because
 * we don't touch %tl.
 *
 * When returning to user mode, the trap level does not matter, as it
 * will be set explicitly.
 *
 * If we are returning to user code, we must:
 *  1.  Check for register windows in the pcb that belong on the stack.
 *	If there are any, reload them
 */
return_from_trap:
#ifdef DEBUG
	!! Make sure we don't have pc == npc == 0 or we suck.
	ldx	[%sp + CC64FSZ + BIAS + TF_PC], %g2
	ldx	[%sp + CC64FSZ + BIAS + TF_NPC], %g3
	orcc	%g2, %g3, %g0
	tz	%icc, 1
#endif	/* DEBUG */
	ldx	[%sp + CC64FSZ + BIAS + TF_TSTATE], %g1
	btst	TSTATE_PRIV, %g1			! returning to userland?
	!!
	!! Let all pending interrupts drain before returning to userland
	!!
	bnz,pn	%icc, 1f				! Returning to userland?
	 nop
	wrpr	%g0, PSTATE_INTR, %pstate
	wrpr	%g0, %g0, %pil				! Lower IPL
1:
	wrpr	%g0, PSTATE_KERN, %pstate		! Disable IRQs

	/* Restore normal globals */
	ldx	[%sp + CC64FSZ + BIAS + TF_G + (1*8)], %g1
	ldx	[%sp + CC64FSZ + BIAS + TF_G + (2*8)], %g2
	ldx	[%sp + CC64FSZ + BIAS + TF_G + (3*8)], %g3
	ldx	[%sp + CC64FSZ + BIAS + TF_G + (4*8)], %g4
	ldx	[%sp + CC64FSZ + BIAS + TF_G + (5*8)], %g5
	ldx	[%sp + CC64FSZ + BIAS + TF_G + (6*8)], %g6
	bnz,pn	%icc, 2f
	 nop
	ldx	[%sp + CC64FSZ + BIAS + TF_G + (7*8)], %g7
2:
	ALTERNATE_GLOBALS()

	/* Restore outs */
	ldx	[%sp + CC64FSZ + BIAS + TF_O + (0*8)], %i0
	ldx	[%sp + CC64FSZ + BIAS + TF_O + (1*8)], %i1
	ldx	[%sp + CC64FSZ + BIAS + TF_O + (2*8)], %i2
	ldx	[%sp + CC64FSZ + BIAS + TF_O + (3*8)], %i3
	ldx	[%sp + CC64FSZ + BIAS + TF_O + (4*8)], %i4
	ldx	[%sp + CC64FSZ + BIAS + TF_O + (5*8)], %i5
	ldx	[%sp + CC64FSZ + BIAS + TF_O + (6*8)], %i6
	ldx	[%sp + CC64FSZ + BIAS + TF_O + (7*8)], %i7
	/* Now load trap registers into alternate globals */
	ld	[%sp + CC64FSZ + BIAS + TF_Y], %g4
	ldx	[%sp + CC64FSZ + BIAS + TF_TSTATE], %g1		! load new values
	wr	%g4, 0, %y
	ldx	[%sp + CC64FSZ + BIAS + TF_PC], %g2
	ldx	[%sp + CC64FSZ + BIAS + TF_NPC], %g3

	/* Returning to user mode or kernel mode? */
	btst	TSTATE_PRIV, %g1		! returning to userland?
	bz,pt	%icc, rft_user
	 nop

/*
 * Return from trap, to kernel.
 *
 * We will assume, for the moment, that all kernel traps are properly stacked
 * in the trap registers, so all we have to do is insert the (possibly modified)
 * register values into the trap registers then do a retry.
 *
 */
rft_kernel:
	rdpr	%tl, %g4			! Grab a set of trap registers
	inc	%g4
	wrpr	%g4, %g0, %tl
	wrpr	%g3, 0, %tnpc
	wrpr	%g2, 0, %tpc
	wrpr	%g1, 0, %tstate

	rdpr	%canrestore, %g2
	brnz	%g2, 1f
	 nop

	wr	%g0, ASI_NUCLEUS, %asi
	rdpr	%cwp, %g1
	dec	%g1
	wrpr	%g1, %cwp
	FILL	ldxa, %sp+BIAS, 8, %asi
	restored
	inc	%g1
	wrpr	%g1, %cwp
1:
	restore

	rdpr	%tstate, %g1			! Since we may have trapped our regs may be toast
	rdpr	%cwp, %g2
	andn	%g1, CWP, %g1
	wrpr	%g1, %g2, %tstate		! Put %cwp in %tstate
	retry					! We should allow some way to distinguish retry/done
	NOTREACHED

/*
 * Return from trap, to user.  Checks for scheduling trap (`ast') first;
 * will re-enter trap() if set.  Note that we may have to switch from
 * the interrupt stack to the kernel stack in this case.
 *	%g1 = %tstate
 *	%g2 = return %pc
 *	%g3 = return %npc
 * If returning to a valid window, just set psr and return.
 */
rft_user:
	GET_CURPROC(%g7)
	lduw	[%g7 + P_MD_ASTPENDING], %g7	! want AST trap?
	brnz,pn	%g7, softtrap			! yes, re-enter trap with type T_AST
	 mov	T_AST, %g4

	/*
	 * NB: only need to do this after a cache miss
	 */
	/*
	 * Now check to see if any regs are saved in the pcb and restore them.
	 *
	 * Here we need to undo the damage caused by switching to a kernel 
	 * stack.
	 *
	 * We will use alternate globals %g4..%g7 because %g1..%g3 are used
	 * by the data fault trap handlers and we don't want possible conflict.
	 */

	GET_CPCB(%g6)
 	ldub	[%g6 + PCB_NSAVED], %g7		! Any saved reg windows?
	brnz,pn	%g7, softtrap
	 mov	T_RWRET, %g4

	/*
	 * Set up our return trapframe so we can recover if we trap from here
	 * on in.
	 */
	wrpr	%g0, 1, %tl			! Set up the trap state
	wrpr	%g2, 0, %tpc
	wrpr	%g3, 0, %tnpc
	rdpr	%cwp, %g7
	andn	%g1, CWP, %g1
	wrpr	%g1, %g7, %tstate

	/* XXX Rewrite sun4u code to handle faults like sun4v. */
	sethi	%hi(_C_LABEL(cputyp)), %g2
	ld	[%g2 + %lo(_C_LABEL(cputyp))], %g2
	cmp	%g2, CPU_SUN4V
	bne,pt	%icc, 1f
	 nop

	rdpr	%otherwin, %g2
	brnz	%g2, 1f
	 nop

	wr	%g0, ASI_AIUS, %asi
	rdpr	%cwp, %g1
	dec	%g1
	wrpr	%g1, 0, %cwp
rft_user_fault_start:
	FILL	ldxa, %sp+BIAS, 8, %asi
	ldx	[%g6 + PCB_WCOOKIE], %g7
	xor	%g7, %i7, %i7		! stackghost
rft_user_fault_end:
	restored
	inc	%g1
	wrpr	%g1, 0, %cwp

	rdpr	%canrestore, %g7
	wrpr	%g7, 0, %otherwin
	wrpr	%g0, 0, %canrestore
1:
	rdpr	%otherwin, %g7			! restore register window controls
	wrpr	%g7, 0, %canrestore
	wrpr	%g0, 0, %otherwin
	wrpr	WSTATE_USER, %wstate		! Need to know where our sp points
	wrpr	%g7, 0, %cleanwin		! Force cleanup of kernel windows

	restore

	rdpr	%tstate, %g1
	rdpr	%cwp, %g7			! Find our cur window
	andn	%g1, CWP, %g1			! Clear it from %tstate
	wrpr	%g1, %g7, %tstate		! Set %tstate with %cwp

	mov	CTX_SECONDARY, %g1		! Restore the user context
	GET_MMU_CONTEXTID(%g4, %g1)
	mov	CTX_PRIMARY, %g2
	SET_MMU_CONTEXTID(%g4, %g2)
	sethi	%hi(KERNBASE), %g7		! Should not be needed due to retry
	membar	#Sync				! Should not be needed due to retry
	flush	%g7				! Should not be needed due to retry

#ifdef DEBUG
	GET_CPCB(%g5)
	ldub	[%g5 + PCB_NSAVED], %g5		! Any saved reg windows?
	tst	%g5
	tnz	%icc, 1; nop			! Debugger if we still have saved windows!
#endif	/* DEBUG */
	wrpr	%g0, 0, %pil			! Enable all interrupts
	retry

! exported end marker for kernel gdb
	.globl	_C_LABEL(endtrapcode)
_C_LABEL(endtrapcode):

#ifdef DDB
!!!
!!! Dump the DTLB to phys address in %o0 and print it
!!!
!!! Only toast a few %o registers
!!!
	.globl	dump_dtlb
dump_dtlb:
	clr	%o1
	add	%o1, (64*8), %o3
1:
	ldxa	[%o1] ASI_DMMU_TLB_TAG, %o2
	membar	#Sync
	stx	%o2, [%o0]
	membar	#Sync
	inc	8, %o0
	ldxa	[%o1] ASI_DMMU_TLB_DATA, %o4
	membar	#Sync
	inc	8, %o1
	stx	%o4, [%o0]
	cmp	%o1, %o3
	membar	#Sync
	bl	1b
	 inc	8, %o0

	retl
	 nop
#endif /* DDB */	/* DDB */
#if defined(DDB)
	.globl	print_dtlb
print_dtlb:
	save	%sp, -CC64FSZ, %sp
	clr	%l1
	add	%l1, (64*8), %l3
	clr	%l2
1:
	ldxa	[%l1] ASI_DMMU_TLB_TAG, %o2
	membar	#Sync
	mov	%l2, %o1
	ldxa	[%l1] ASI_DMMU_TLB_DATA, %o3
	membar	#Sync
	inc	%l2
	set	2f, %o0
	call	_C_LABEL(db_printf)
	 inc	8, %l1

	ldxa	[%l1] ASI_DMMU_TLB_TAG, %o2
	membar	#Sync
	mov	%l2, %o1
	ldxa	[%l1] ASI_DMMU_TLB_DATA, %o3
	membar	#Sync
	inc	%l2
	set	3f, %o0
	call	_C_LABEL(db_printf)
	 inc	8, %l1

	cmp	%l1, %l3
	bl	1b
	 inc	8, %l0

	ret
	 restore
	.data
2:
	.asciz	"%2d:%016lx %016lx "
3:
	.asciz	"%2d:%016lx %016lx\r\n"
	.text
#endif	/* defined(DDB) */

	.align	8
dostart:
	/*
	 * Startup.
	 *
	 * The Sun FCODE bootloader is nice and loads us where we want
	 * to be.  We have a full set of mappings already set up for us.
	 *
	 * I think we end up having an entire 16M allocated to us.
	 *
	 * We enter with the prom entry vector in %o0, dvec in %o1,
	 * and the bootops vector in %o2.
	 *
	 * All we need to do is:
	 *
	 *	1:	Save the prom vector
	 *
	 *	2:	Create a decent stack for ourselves
	 *
	 *	3:	Install the permanent 4MB kernel mapping
	 *
	 *	4:	Call the C language initialization code
	 *
	 */

	/*
	 * Set the psr into a known state:
	 * Set supervisor mode, interrupt level >= 13, traps enabled
	 */
	wrpr	%g0, 13, %pil
	wrpr	%g0, PSTATE_INTR|PSTATE_PEF, %pstate
	wr	%g0, FPRS_FEF, %fprs		! Turn on FPU

#if defined(DDB) || NKSYMS > 0
	/*
	 * First, check for DDB arguments.  A pointer to an argument
	 * is passed in %o1 who's length is passed in %o2.  Our
	 * bootloader passes in a magic number as the first argument,
	 * followed by esym as argument 2, and ssym as argument 3,
	 * so check that %o3 >= 12.
	 */
	cmp	%o2, 12
	blt	1f			! Not enough args
	 nop
	
	set	0x44444230, %l3
	ldx	[%o1], %l4
	cmp	%l3, %l4		! chk magic
	bne	%xcc, 1f
	 nop

	ldx	[%o1+8], %l4
	sethi	%hi(_C_LABEL(esym)), %l3	! store esym
	stx	%l4, [%l3 + %lo(_C_LABEL(esym))]

	ldx	[%o1+16], %l4
	sethi	%hi(_C_LABEL(ssym)), %l3	! store ssym
	stx	%l4, [%l3 + %lo(_C_LABEL(ssym))]
1:
#endif	/* defined(DDB) || NKSYMS > 0 */
	/*
	 * Step 1: Save rom entry pointer
	 */

	mov	%o4, %g7	! save prom vector pointer
	set	romp, %o5
	stx	%o4, [%o5]	! It's initialized data, I hope

#if 0
	/*
	 * Disable the DCACHE entirely for debug.
	 */
	ldxa	[%g0] ASI_MCCR, %o1
	andn	%o1, MCCR_DCACHE_EN, %o1
	stxa	%o1, [%g0] ASI_MCCR
	membar	#Sync
#endif	/* 0 */

	/*
	 * Switch to temporary stack.
	 */
	set	tmpstack-CC64FSZ-BIAS, %sp

	/*
	 * Ready to run C code; finish bootstrap.
	 */
1:
	set	0x2000, %o0			! fixed: 8192 contexts
	call	_C_LABEL(bootstrap)
	 clr	%g4				! Clear data segment pointer

	/*
	 * pmap_bootstrap should have allocated a stack for proc 0 and
	 * stored the start and end in u0 and estack0.  Switch to that
	 * stack now.
	 */

	sethi	%hi(_C_LABEL(cpus)), %g2
	ldx	[%g2 + %lo(_C_LABEL(cpus))], %g2
	ldx	[%g2 + CI_PADDR], %g2		! Load the interrupt stack's PA

/*
 * Initialize a CPU.  This is used both for bootstrapping the first CPU
 * and spinning up each subsequent CPU.  Basically:
 *
 *	Install trap table.
 *	Switch to the initial stack.
 *	Call the routine passed in in cpu_info->ci_spinup.
 */

_C_LABEL(cpu_initialize):

	wrpr	%g0, 0, %tl			! Make sure we're not in NUCLEUS mode
	flushw

	/* Change the trap base register */
	set	_C_LABEL(trapbase), %l1
#ifdef SUN4V
	sethi	%hi(_C_LABEL(cputyp)), %l0
	ld	[%l0 + %lo(_C_LABEL(cputyp))], %l0
	cmp	%l0, CPU_SUN4V
	bne,pt	%icc, 1f
	 nop
	set	_C_LABEL(trapbase_sun4v), %l1
	GET_MMFSA(%o1)
1:
#endif
	call	_C_LABEL(prom_set_trap_table)	! Now we should be running 100% from our handlers
	 mov	%l1, %o0
	wrpr	%l1, 0, %tba			! Make sure the PROM didn't foul up.
	wrpr	%g0, WSTATE_KERN, %wstate

	/*
	 * Switch to our initial stack.
	 */

	GET_CPUINFO_VA(%g7)
	ldx	[%g7 + CI_INITSTACK], %l0
	add	%l0, -BIAS-CC64FSZ, %sp

	/*
	 * Call our startup routine.
	 */

	ldx	[%g7 + CI_SPINUP], %o1
	call	%o1				! Call routine
	 nop
	NOTREACHED

	set	1f, %o0				! Main should never come back here
	call	_C_LABEL(panic)
	 nop
	.data
1:
	.asciz	"main() returned\r\n"
	_ALIGN
	.text

ENTRY(sun4u_set_tsbs)

	/* Set the dmmu tsb */
	sethi	%hi(0x1fff), %o2
	set	_C_LABEL(tsb_dmmu), %o0
	ldx	[%o0], %o0
	set	_C_LABEL(tsbsize), %o1
	or	%o2, %lo(0x1fff), %o2
	ld	[%o1], %o1
	andn	%o0, %o2, %o0			! Mask off size and split bits
	or	%o0, %o1, %o0			! Make a TSB pointer
	set	TSB, %o2
	stxa	%o0, [%o2] ASI_DMMU		! Install data TSB pointer
	membar	#Sync

	/* Set the immu tsb */
	sethi	%hi(0x1fff), %o2
	set	_C_LABEL(tsb_immu), %o0
	ldx	[%o0], %o0
	set	_C_LABEL(tsbsize), %o1
	or	%o2, %lo(0x1fff), %o2
	ld	[%o1], %o1
	andn	%o0, %o2, %o0			! Mask off size and split bits
	or	%o0, %o1, %o0			! Make a TSB pointer
	set	TSB, %o2
	stxa	%o0, [%o2] ASI_IMMU		! Install insn TSB pointer
	membar	#Sync

	retl
	 nop


#ifdef MULTIPROCESSOR
ENTRY(cpu_mp_startup)
	mov	%o0, %g2

	wrpr	%g0, 13, %pil
	wrpr	%g0, PSTATE_INTR|PSTATE_PEF, %pstate
	wr	%g0, FPRS_FEF, %fprs		! Turn on FPU

	set	tmpstack-CC64FSZ-BIAS, %sp

	call	_C_LABEL(pmap_bootstrap_cpu)
	 nop

	ba,a,pt	%xcc, cpu_initialize
	 nop
#endif

/*
 * openfirmware(cell* param);
 *
 * OpenFirmware entry point
 */
	.align 8
	.globl	_C_LABEL(openfirmware)
	.proc 1
	FTYPE(openfirmware)
_C_LABEL(openfirmware):
	sethi	%hi(romp), %o4
	ldx	[%o4+%lo(romp)], %o4
	save	%sp, -CC64FSZ, %sp
	rdpr	%pil, %i2
	mov	PIL_HIGH, %i3
	cmp	%i3, %i2
	movle	%icc, %i2, %i3
	wrpr	%g0, %i3, %pil
	mov	%i0, %o0
	mov	%g1, %l1
	mov	%g2, %l2
	mov	%g3, %l3
	mov	%g4, %l4
	mov	%g5, %l5
	mov	%g6, %l6
	mov	%g7, %l7
	rdpr	%pstate, %l0
	jmpl	%i4, %o7
	 wrpr	%g0, PSTATE_PROM|PSTATE_IE, %pstate
	wrpr	%l0, %g0, %pstate
	mov	%l1, %g1
	mov	%l2, %g2
	mov	%l3, %g3
	mov	%l4, %g4
	mov	%l5, %g5
	mov	%l6, %g6
	mov	%l7, %g7
	wrpr	%i2, 0, %pil
	ret
	 restore	%o0, %g0, %o0

/*
 * tlb_flush_pte(vaddr_t va, int ctx)
 *
 * Flush tte from both IMMU and DMMU.
 *
 */
	.align 8
	.globl	_C_LABEL(sp_tlb_flush_pte)
	.proc 1
	FTYPE(sp_tlb_flush_pte)
_C_LABEL(sp_tlb_flush_pte):
#ifdef DEBUG
	set	DATA_START, %o4				! Forget any recent TLB misses
	stx	%g0, [%o4]
	stx	%g0, [%o4+16]
#endif	/* DEBUG */
#ifdef DEBUG
	set	pmapdebug, %o3
	lduw	[%o3], %o3
!	movrz	%o1, -1, %o3				! Print on either pmapdebug & PDB_DEMAP or ctx == 0
	btst	0x0020, %o3
	bz,pt	%icc, 2f
	 nop
	save	%sp, -CC64FSZ, %sp
	set	1f, %o0
	mov	%i1, %o1
	andn	%i0, 0xfff, %o3
	or	%o3, 0x010, %o3
	call	_C_LABEL(printf)
	 mov	%i0, %o2
	restore
	.data
1:
	.asciz	"tlb_flush_pte:	demap ctx=%x va=%08x res=%x\r\n"
	_ALIGN
	.text
2:
#endif	/* DEBUG */
#ifdef HORRID_III_HACK
	rdpr	%pstate, %o5
	andn	%o5, PSTATE_IE, %o4
	wrpr	%o4, %pstate				! disable interrupts

	rdpr	%tl, %o3
	brnz	%o3, 1f
	 add	%o3, 1, %g2
	wrpr	%g0, %g2, %tl				! Switch to traplevel > 0
1:	
	mov	CTX_PRIMARY, %o2
	andn	%o0, 0xfff, %g2				! drop unused va bits
	ldxa	[%o2] ASI_DMMU, %g1			! Save primary context
	sethi	%hi(KERNBASE), %o4
	membar	#LoadStore
	stxa	%o1, [%o2] ASI_DMMU			! Insert context to demap
	membar	#Sync
	or	%g2, DEMAP_PAGE_PRIMARY, %g2		! Demap page from primary context only
#else
	mov	CTX_SECONDARY, %o2
	andn	%o0, 0xfff, %g2				! drop unused va bits
	ldxa	[%o2] ASI_DMMU, %g1			! Save secondary context
	sethi	%hi(KERNBASE), %o4
	membar	#LoadStore
	stxa	%o1, [%o2] ASI_DMMU			! Insert context to demap
	membar	#Sync
	or	%g2, DEMAP_PAGE_SECONDARY, %g2		! Demap page from secondary context only
#endif
	stxa	%g2, [%g2] ASI_DMMU_DEMAP		! Do the demap
	membar	#Sync
	stxa	%g2, [%g2] ASI_IMMU_DEMAP		! to both TLBs
	membar	#Sync					! No real reason for this XXXX
	flush	%o4
	stxa	%g1, [%o2] ASI_DMMU			! Restore asi
	membar	#Sync					! No real reason for this XXXX
	flush	%o4
#ifdef HORRID_III_HACK
	wrpr	%g0, %o3, %tl				! Restore traplevel
	wrpr	%o5, %pstate				! Restore interrupts
#endif
	retl
	 nop

/*
 * tlb_flush_ctx(int ctx)
 *
 * Flush entire context from both IMMU and DMMU.
 *
 */
	.align 8
	.globl	_C_LABEL(sp_tlb_flush_ctx)
	.proc 1
	FTYPE(sp_tlb_flush_ctx)
_C_LABEL(sp_tlb_flush_ctx):
#ifdef DEBUG
	set	DATA_START, %o4				! Forget any recent TLB misses
	stx	%g0, [%o4]
#endif	/* DEBUG */
#ifdef DIAGNOSTIC
	brnz,pt	%o0, 2f
	 nop
	set	1f, %o0
	call	panic
	 nop
	.data
1:
	.asciz	"tlb_flush_ctx:	attempted demap of NUCLEUS context\r\n"
	_ALIGN
	.text
2:
#endif	/* DIAGNOSTIC */
#ifdef HORRID_III_HACK
	rdpr	%pstate, %o5
	andn	%o5, PSTATE_IE, %o4
	wrpr	%o4, %pstate				! disable interrupts

	rdpr	%tl, %o3
	brnz	%o3, 1f
	 add	%o3, 1, %g2
	wrpr	%g0, %g2, %tl				! Switch to traplevel > 0
1:	
	mov	CTX_PRIMARY, %o2
	sethi	%hi(KERNBASE), %o4
	ldxa	[%o2] ASI_DMMU, %g1		! Save primary context
	membar	#LoadStore
	stxa	%o0, [%o2] ASI_DMMU		! Insert context to demap
	membar	#Sync
	set	DEMAP_CTX_PRIMARY, %g2		! Demap context from primary context only
#else
	mov	CTX_SECONDARY, %o2
	sethi	%hi(KERNBASE), %o4
	ldxa	[%o2] ASI_DMMU, %g1		! Save secondary context
	membar	#LoadStore
	stxa	%o0, [%o2] ASI_DMMU		! Insert context to demap
	membar	#Sync
	set	DEMAP_CTX_SECONDARY, %g2	! Demap context from secondary context only
#endif
	stxa	%g2, [%g2] ASI_DMMU_DEMAP		! Do the demap
	membar	#Sync					! No real reason for this XXXX
	stxa	%g2, [%g2] ASI_IMMU_DEMAP		! Do the demap
	membar	#Sync
	stxa	%g1, [%o2] ASI_DMMU		! Restore secondary asi
	membar	#Sync					! No real reason for this XXXX
	flush	%o4
#ifdef HORRID_III_HACK
	wrpr	%g0, %o3, %tl				! Restore traplevel
	wrpr	%o5, %pstate				! Restore interrupts
#endif
	retl
	 nop

/*
 * dcache_flush_page(paddr_t pa)
 *
 * Clear one page from D$.
 *
 */
	.align 8
	.globl	_C_LABEL(us_dcache_flush_page)
	.proc 1
	FTYPE(us_dcache_flush_page)
_C_LABEL(us_dcache_flush_page):

	!! Try using cache_flush_phys for a change.

	mov	-1, %o1		! Generate mask for tag: bits [29..2]
	srlx	%o0, 13-2, %o2	! Tag is VA bits <40:13> in bits <29:2>
	clr	%o4
	srl	%o1, 2, %o1	! Now we have bits <29:0> set
	set	(2*NBPG), %o5
	ba,pt	%icc, 1f
	 andn	%o1, 3, %o1	! Now we have bits <29:2> set
	
	.align 8
1:
	ldxa	[%o4] ASI_DCACHE_TAG, %o3
	mov	%o4, %o0
	deccc	16, %o5
	bl,pn	%icc, 2f
	
	 inc	16, %o4
	xor	%o3, %o2, %o3
	andcc	%o3, %o1, %g0
	bne,pt	%xcc, 1b
	 membar	#LoadStore
	
dlflush2:
	stxa	%g0, [%o0] ASI_DCACHE_TAG
	ba,pt	%icc, 1b
	 membar	#StoreLoad
2:

	wr	%g0, ASI_PRIMARY_NOFAULT, %asi
	sethi	%hi(KERNBASE), %o5
	flush	%o5
	retl
	 membar	#Sync

	.align 8
	.globl  _C_LABEL(us3_dcache_flush_page)
	.proc 1
	FTYPE(us3_dcache_flush_page)
_C_LABEL(us3_dcache_flush_page):
	ldxa    [%g0] ASI_MCCR, %o1
	btst    MCCR_DCACHE_EN, %o1
	bz,pn   %icc, 1f
	 nop
	sethi   %hi(PAGE_SIZE), %o4
	or      %g0, (PAGE_SIZE - 1), %o3
	andn    %o0, %o3, %o0
2:
	subcc   %o4, 32, %o4
	stxa    %g0, [%o0 + %o4] ASI_DCACHE_INVALIDATE
	membar  #Sync
	bne,pt  %icc, 2b
	 nop
1:
	retl
	 nop

	.globl no_dcache_flush_page
ENTRY(no_dcache_flush_page)
	retl
	 nop

/*
 * cache_flush_virt(va, len)
 *
 * Clear everything in that va range from D$.
 *
 */
	.align 8
	.globl	_C_LABEL(cache_flush_virt)
	.proc 1
	FTYPE(cache_flush_virt)
_C_LABEL(cache_flush_virt):
	brz,pn	%o1, 2f		! What? nothing to clear?
	 add	%o0, %o1, %o2
	mov	0x1ff, %o3
	sllx	%o3, 5, %o3	! Generate mask for VA bits
	and	%o0, %o3, %o0
	and	%o2, %o3, %o2
	sub	%o2, %o1, %o4	! End < start? need to split flushes.
	brlz,pn	%o4, 1f
	 movrz	%o4, %o3, %o4	! If start == end we need to wrap

	!! Clear from start to end
1:
dlflush3:
	stxa	%g0, [%o0] ASI_DCACHE_TAG
	dec	16, %o4
	brgz,pt	%o4, 1b
	 inc	16, %o0
2:
	sethi	%hi(KERNBASE), %o5
	flush	%o5
	membar	#Sync
	retl
	 nop

/*
 *	cache_flush_phys(paddr_t, psize_t, int);
 *
 *	Clear a set of paddrs from the D$ and if param3 is
 *	non-zero, E$.  (E$ is not supported yet).
 */

		.align 8
	.globl	_C_LABEL(cache_flush_phys)
	.proc 1
	FTYPE(cache_flush_phys)
_C_LABEL(cache_flush_phys):
#ifdef DEBUG
	tst	%o2		! Want to clear E$?
	tnz	1		! Error!
#endif	/* DEBUG */
	add	%o0, %o1, %o1	! End PA

	!!
	!! D$ tags match pa bits 40-13.
	!! Generate a mask for them.
	!!

	mov	-1, %o2		! Generate mask for tag: bits [40..13]
	srl	%o2, 5, %o2	! 32-5 = [27..0]
	sllx	%o2, 13, %o2	! 27+13 = [40..13]

	and	%o2, %o0, %o0	! Mask away uninteresting bits
	and	%o2, %o1, %o1	! (probably not necessary)

	set	(2*NBPG), %o5
	clr	%o4
1:
	ldxa	[%o4] ASI_DCACHE_TAG, %o3
	sllx	%o3, 40-29, %o3	! Shift D$ tag into place
	and	%o3, %o2, %o3	! Mask out trash
	cmp	%o0, %o3
	blt,pt	%xcc, 2f	! Too low
	cmp	%o1, %o3
	bgt,pt	%xcc, 2f	! Too high
	 nop

	membar	#LoadStore
dlflush4:
	stxa	%g0, [%o4] ASI_DCACHE_TAG ! Just right
2:
	membar	#StoreLoad
	dec	16, %o5
	brgz,pt	%o5, 1b
	 inc	16, %o4

	sethi	%hi(KERNBASE), %o5
	flush	%o5
	membar	#Sync
	retl
	 nop

/*
 * XXXXX Still needs lotsa cleanup after sendsig is complete and offsets are known
 *
 * The following code is copied to the top of the user stack when each
 * process is exec'ed, and signals are `trampolined' off it.
 *
 * When this code is run, the stack looks like:
 *	[%sp]			128 bytes to which registers can be dumped
 *	[%sp + 128]		signal number (goes in %o0)
 *	[%sp + 128 + 4]		signal code (ignored)
 *	[%sp + 128 + 8]		siginfo pointer(goes in %o1)
 *	[%sp + 128 + 16]	first word of saved state (sigcontext)
 *	    .
 *	    .
 *	    .
 *	[%sp + NNN]		last word of saved state
 *	[%sp + ...]		siginfo structure
 * (followed by previous stack contents or top of signal stack).
 * The address of the function to call is in %g1; the old %g1 and %o0
 * have already been saved in the sigcontext.  We are running in a clean
 * window, all previous windows now being saved to the stack.
 *
 * XXX this is bullshit
 * Note that [%sp + 128 + 8] == %sp + 128 + 16.  The copy at %sp+128+8
 * will eventually be removed, with a hole left in its place, if things
 * work out.
 */
	.section .rodata
	.globl	_C_LABEL(sigcode)
_C_LABEL(sigcode):
	/*
	 * XXX  the `save' and `restore' below are unnecessary: should
	 *	replace with simple arithmetic on %sp
	 *
	 * Make room on the stack for 64 %f registers + %fsr.  This comes
	 * out to 64*4+8 or 264 bytes, but this must be aligned to a multiple
	 * of 64, or 320 bytes.
	 */
	save	%sp, -CC64FSZ - 320, %sp
	mov	%g2, %l2		! save globals in %l registers
	mov	%g3, %l3
	mov	%g4, %l4
	mov	%g5, %l5
	mov	%g6, %l6
	mov	%g7, %l7
	/*
	 * Saving the fpu registers is expensive, so do it iff it is
	 * enabled and dirty.
	 */
	rd	%fprs, %l0
	btst	FPRS_DL|FPRS_DU, %l0	! All clean?
	bz,pt	%icc, 2f
	 btst	FPRS_DL, %l0		! test dl
	bz,pt	%icc, 1f
	 btst	FPRS_DU, %l0		! test du

	! fpu is enabled, oh well
	stx	%fsr, [%sp + CC64FSZ + BIAS + 0]
	add	%sp, BIAS+CC64FSZ+BLOCK_SIZE, %l0	! Generate a pointer so we can
	andn	%l0, BLOCK_ALIGN, %l0	! do a block store
	stda	%f0, [%l0] ASI_BLK_P
	inc	BLOCK_SIZE, %l0
	stda	%f16, [%l0] ASI_BLK_P
1:
	bz,pt	%icc, 2f
	 add	%sp, BIAS+CC64FSZ+BLOCK_SIZE, %l0	! Generate a pointer so we can
	andn	%l0, BLOCK_ALIGN, %l0	! do a block store
	add	%l0, 2*BLOCK_SIZE, %l0	! and skip what we already stored
	stda	%f32, [%l0] ASI_BLK_P
	inc	BLOCK_SIZE, %l0
	stda	%f48, [%l0] ASI_BLK_P
2:
	membar	#Sync
	rd	%fprs, %l0		! reload fprs copy, for checking after
	rd	%y, %l1			! in any case, save %y
	lduw	[%fp + BIAS + 128], %o0	! sig
	ldx	[%fp + BIAS + 128 + 8], %o1	! siginfo
	call	%g1			! (*sa->sa_handler)(sig, sip, scp)
	 add	%fp, BIAS + 128 + 16, %o2	! scp
	wr	%l1, %g0, %y		! in any case, restore %y

	/*
	 * Now that the handler has returned, re-establish all the state
	 * we just saved above, then do a sigreturn.
	 */
	btst	FPRS_DL|FPRS_DU, %l0	! All clean?
	bz,pt	%icc, 2f
	 btst	FPRS_DL, %l0		! test dl
	bz,pt	%icc, 1f
	 btst	FPRS_DU, %l0		! test du

	ldx	[%sp + CC64FSZ + BIAS + 0], %fsr
	add	%sp, BIAS+CC64FSZ+BLOCK_SIZE, %l0	! Generate a pointer so we can
	andn	%l0, BLOCK_ALIGN, %l0	! do a block load
	ldda	[%l0] ASI_BLK_P, %f0
	inc	BLOCK_SIZE, %l0
	ldda	[%l0] ASI_BLK_P, %f16
1:
	bz,pt	%icc, 2f
	 nop
	add	%sp, BIAS+CC64FSZ+BLOCK_SIZE, %l0	! Generate a pointer so we can
	andn	%l0, BLOCK_ALIGN, %l0	! do a block load
	inc	2*BLOCK_SIZE, %l0	! and skip what we already loaded
	ldda	[%l0] ASI_BLK_P, %f32
	inc	BLOCK_SIZE, %l0
	ldda	[%l0] ASI_BLK_P, %f48
2:
	mov	%l2, %g2
	mov	%l3, %g3
	mov	%l4, %g4
	mov	%l5, %g5
	mov	%l6, %g6
	mov	%l7, %g7
	membar	#Sync

	restore	%g0, SYS_sigreturn, %g1 ! get registers back & set syscall #
	add	%sp, BIAS + 128 + 16, %o0	! compute scp
!	andn	%o0, 0x0f, %o0
	.globl  _C_LABEL(sigcoderet)
_C_LABEL(sigcoderet):
	t	ST_SYSCALL		! sigreturn(scp)
	! sigreturn does not return unless it fails
	mov	SYS_exit, %g1		! exit(errno)
	t	ST_SYSCALL
	.globl	_C_LABEL(esigcode)
_C_LABEL(esigcode):

	.globl	_C_LABEL(sigfill)
_C_LABEL(sigfill):
	unimp
_C_LABEL(esigfill):

	.globl	_C_LABEL(sigfillsiz)
_C_LABEL(sigfillsiz):
	.word	_C_LABEL(esigfill) - _C_LABEL(sigfill)

	.text

/*
 * Primitives
 */
#ifdef ENTRY
#undef ENTRY
#endif	/* ENTRY */

#ifdef GPROF
	.globl	_mcount
#define	ENTRY(x) \
	.globl _C_LABEL(x); _C_LABEL(x): ; \
	.data; \
	.align 8; \
0:	.uaword 0; .uaword 0; \
	.text;	\
	save	%sp, -CC64FSZ, %sp; \
	sethi	%hi(0b), %o0; \
	call	_mcount; \
	or	%o0, %lo(0b), %o0; \
	restore
#else	/* GPROF */
#define	ENTRY(x)	.globl _C_LABEL(x); _C_LABEL(x):
#endif	/* GPROF */
#define	ALTENTRY(x)	.globl _C_LABEL(x); _C_LABEL(x):

/*
 * getfp() - get stack frame pointer
 */
ENTRY(getfp)
	retl
	 mov %fp, %o0

/*
 * copyinstr(fromaddr, toaddr, maxlength, &lencopied)
 *
 * Copy a null terminated string from the user address space into
 * the kernel address space.
 */
ENTRY(copyinstr)
	! %o0 = fromaddr, %o1 = toaddr, %o2 = maxlen, %o3 = &lencopied
	brgz,pt	%o2, 1f					! Make sure len is valid
	 nop
	retl
	 mov	ENAMETOOLONG, %o0
1:
	GET_CPCB(%o4)			! catch faults
	set	Lcsfault, %o5
	membar	#Sync
	stx	%o5, [%o4 + PCB_ONFAULT]

	mov	%o1, %o5		!	save = toaddr;
! XXX should do this in bigger chunks when possible
0:					! loop:
	ldsba	[%o0] ASI_AIUS, %g1	!	c = *fromaddr;
	stb	%g1, [%o1]		!	*toaddr++ = c;
	inc	%o1
	brz,a,pn	%g1, Lcsdone	!	if (c == NULL)
	 clr	%o0			!		{ error = 0; done; }
	deccc	%o2			!	if (--len > 0) {
	bg,pt	%icc, 0b		!		fromaddr++;
	 inc	%o0			!		goto loop;
	ba,pt	%xcc, Lcsdone		!	}
	 mov	ENAMETOOLONG, %o0	!	error = ENAMETOOLONG;
	NOTREACHED

/*
 * copyoutstr(fromaddr, toaddr, maxlength, &lencopied)
 *
 * Copy a null terminated string from the kernel
 * address space to the user address space.
 */
ENTRY(copyoutstr)
	! %o0 = fromaddr, %o1 = toaddr, %o2 = maxlen, %o3 = &lencopied
	brgz,pt	%o2, 1f					! Make sure len is valid
	 nop
	retl
	 mov	ENAMETOOLONG, %o0
1:
	GET_CPCB(%o4)			! catch faults
	set	Lcsfault, %o5
	membar	#Sync
	stx	%o5, [%o4 + PCB_ONFAULT]

	mov	%o1, %o5		!	save = toaddr;
! XXX should do this in bigger chunks when possible
0:					! loop:
	ldsb	[%o0], %g1		!	c = *fromaddr;
	stba	%g1, [%o1] ASI_AIUS	!	*toaddr++ = c;
	inc	%o1
	brz,a,pn	%g1, Lcsdone	!	if (c == NULL)
	 clr	%o0			!		{ error = 0; done; }
	deccc	%o2			!	if (--len > 0) {
	bg,pt	%icc, 0b		!		fromaddr++;
	 inc	%o0			!		goto loop;
					!	}
	mov	ENAMETOOLONG, %o0	!	error = ENAMETOOLONG;
Lcsdone:				! done:
	sub	%o1, %o5, %o1		!	len = to - save;
	brnz,a	%o3, 1f			!	if (lencopied)
	 stx	%o1, [%o3]		!		*lencopied = len;
1:
	retl				! cpcb->pcb_onfault = 0;
	 stx	%g0, [%o4 + PCB_ONFAULT]! return (error);

Lcsfault:
	b	Lcsdone			! error = EFAULT;
	 mov	EFAULT, %o0		! goto ret;

/*
 * copystr(fromaddr, toaddr, maxlength, &lencopied)
 *
 * Copy a null terminated string from one point to another in
 * the kernel address space.  (This is a leaf procedure, but
 * it does not seem that way to the C compiler.)
 */
ENTRY(copystr)
	brgz,pt	%o2, 0f	! Make sure len is valid
	 mov	%o1, %o5		!	to0 = to;
	retl
	 mov	ENAMETOOLONG, %o0
0:					! loop:
	ldsb	[%o0], %o4		!	c = *from;
	tst	%o4
	stb	%o4, [%o1]		!	*to++ = c;
	be	1f			!	if (c == 0)
	 inc	%o1			!		goto ok;
	deccc	%o2			!	if (--len > 0) {
	bg,a	0b			!		from++;
	 inc	%o0			!		goto loop;
	b	2f			!	}
	 mov	ENAMETOOLONG, %o0	!	ret = ENAMETOOLONG; goto done;
1:					! ok:
	clr	%o0			!	ret = 0;
2:
	sub	%o1, %o5, %o1		!	len = to - to0;
	tst	%o3			!	if (lencopied)
	bnz,a	3f
	 stx	%o1, [%o3]		!		*lencopied = len;
3:
	retl
	 nop
#ifdef DIAGNOSTIC
4:
	sethi	%hi(5f), %o0
	call	_C_LABEL(panic)
	 or	%lo(5f), %o0, %o0
	.data
5:
	.asciz	"copystr"
	_ALIGN
	.text
#endif	/* DIAGNOSTIC */

/*
 * copyin(src, dst, len)
 *
 * Copy specified amount of data from user space into the kernel.
 *
 * This is a modified version of bcopy that uses ASI_AIUS.  When
 * bcopy is optimized to use block copy ASIs, this should be also.
 */

#define	BCOPY_SMALL	32	/* if < 32, copy by bytes */

ENTRY(copyin)
!	flushw			! Make sure we don't have stack probs & lose hibits of %o
	GET_CPCB(%o3)
	wr	%g0, ASI_AIUS, %asi
	set	Lcopyfault, %o4
!	mov	%o7, %g7		! save return address
	membar	#Sync
	stx	%o4, [%o3 + PCB_ONFAULT]
	cmp	%o2, BCOPY_SMALL
Lcopyin_start:
	bge,a	Lcopyin_fancy	! if >= this many, go be fancy.
	 btst	7, %o0		! (part of being fancy)

	/*
	 * Not much to copy, just do it a byte at a time.
	 */
	deccc	%o2		! while (--len >= 0)
	bl	1f
0:
	 inc	%o0
	ldsba	[%o0 - 1] %asi, %o4!	*dst++ = (++src)[-1];
	stb	%o4, [%o1]
	deccc	%o2
	bge	0b
	 inc	%o1
1:
	ba	Lcopyin_done
	 clr	%o0
	NOTREACHED

	/*
	 * Plenty of data to copy, so try to do it optimally.
	 */
Lcopyin_fancy:
	! check for common case first: everything lines up.
!	btst	7, %o0		! done already
	bne	1f
!	 XXX check no delay slot
	btst	7, %o1
	be,a	Lcopyin_doubles
	 dec	8, %o2		! if all lined up, len -= 8, goto copyin_doubes

	! If the low bits match, we can make these line up.
1:
	xor	%o0, %o1, %o3	! t = src ^ dst;
	btst	1, %o3		! if (t & 1) {
	be,a	1f
	 btst	1, %o0		! [delay slot: if (src & 1)]

	! low bits do not match, must copy by bytes.
0:
	ldsba	[%o0] %asi, %o4	!	do {
	inc	%o0		!		(++dst)[-1] = *src++;
	inc	%o1
	deccc	%o2
	bnz	0b		!	} while (--len != 0);
	 stb	%o4, [%o1 - 1]
	ba	Lcopyin_done
	 clr	%o0
	NOTREACHED

	! lowest bit matches, so we can copy by words, if nothing else
1:
	be,a	1f		! if (src & 1) {
	 btst	2, %o3		! [delay slot: if (t & 2)]

	! although low bits match, both are 1: must copy 1 byte to align
	ldsba	[%o0] %asi, %o4	!	*dst++ = *src++;
	stb	%o4, [%o1]
	inc	%o0
	inc	%o1
	dec	%o2		!	len--;
	btst	2, %o3		! } [if (t & 2)]
1:
	be,a	1f		! if (t & 2) {
	 btst	2, %o0		! [delay slot: if (src & 2)]
	dec	2, %o2		!	len -= 2;
0:
	ldsha	[%o0] %asi, %o4	!	do {
	sth	%o4, [%o1]	!		*(short *)dst = *(short *)src;
	inc	2, %o0		!		dst += 2, src += 2;
	deccc	2, %o2		!	} while ((len -= 2) >= 0);
	bge	0b
	 inc	2, %o1
	b	Lcopyin_mopb	!	goto mop_up_byte;
	 btst	1, %o2		! } [delay slot: if (len & 1)]
	NOTREACHED

	! low two bits match, so we can copy by longwords
1:
	be,a	1f		! if (src & 2) {
	 btst	4, %o3		! [delay slot: if (t & 4)]

	! although low 2 bits match, they are 10: must copy one short to align
	ldsha	[%o0] %asi, %o4	!	(*short *)dst = *(short *)src;
	sth	%o4, [%o1]
	inc	2, %o0		!	dst += 2;
	inc	2, %o1		!	src += 2;
	dec	2, %o2		!	len -= 2;
	btst	4, %o3		! } [if (t & 4)]
1:
	be,a	1f		! if (t & 4) {
	 btst	4, %o0		! [delay slot: if (src & 4)]
	dec	4, %o2		!	len -= 4;
0:
	lduwa	[%o0] %asi, %o4	!	do {
	st	%o4, [%o1]	!		*(int *)dst = *(int *)src;
	inc	4, %o0		!		dst += 4, src += 4;
	deccc	4, %o2		!	} while ((len -= 4) >= 0);
	bge	0b
	 inc	4, %o1
	b	Lcopyin_mopw	!	goto mop_up_word_and_byte;
	 btst	2, %o2		! } [delay slot: if (len & 2)]
	NOTREACHED

	! low three bits match, so we can copy by doublewords
1:
	be	1f		! if (src & 4) {
	 dec	8, %o2		! [delay slot: len -= 8]
	lduwa	[%o0] %asi, %o4	!	*(int *)dst = *(int *)src;
	st	%o4, [%o1]
	inc	4, %o0		!	dst += 4, src += 4, len -= 4;
	inc	4, %o1
	dec	4, %o2		! }
1:
Lcopyin_doubles:
	ldxa	[%o0] %asi, %g1	! do {
	stx	%g1, [%o1]	!	*(double *)dst = *(double *)src;
	inc	8, %o0		!	dst += 8, src += 8;
	deccc	8, %o2		! } while ((len -= 8) >= 0);
	bge	Lcopyin_doubles
	 inc	8, %o1

	! check for a usual case again (save work)
	btst	7, %o2		! if ((len & 7) == 0)
	be	Lcopyin_done	!	goto copyin_done;

	 btst	4, %o2		! if ((len & 4) == 0)
	be,a	Lcopyin_mopw	!	goto mop_up_word_and_byte;
	 btst	2, %o2		! [delay slot: if (len & 2)]
	lduwa	[%o0] %asi, %o4	!	*(int *)dst = *(int *)src;
	st	%o4, [%o1]
	inc	4, %o0		!	dst += 4;
	inc	4, %o1		!	src += 4;
	btst	2, %o2		! } [if (len & 2)]

1:
	! mop up trailing word (if present) and byte (if present).
Lcopyin_mopw:
	be	Lcopyin_mopb	! no word, go mop up byte
	 btst	1, %o2		! [delay slot: if (len & 1)]
	ldsha	[%o0] %asi, %o4	! *(short *)dst = *(short *)src;
	be	Lcopyin_done	! if ((len & 1) == 0) goto done;
	 sth	%o4, [%o1]
	ldsba	[%o0 + 2] %asi, %o4	! dst[2] = src[2];
	stb	%o4, [%o1 + 2]
	ba	Lcopyin_done
	 clr	%o0
	NOTREACHED

	! mop up trailing byte (if present).
Lcopyin_mopb:
	be,a	Lcopyin_done
	 nop
	ldsba	[%o0] %asi, %o4
	stb	%o4, [%o1]

Lcopyin_done:
	GET_CPCB(%o3)
	membar	#Sync
	stx	%g0, [%o3 + PCB_ONFAULT]
	wr	%g0, ASI_PRIMARY_NOFAULT, %asi		! Restore ASI
	retl
	 clr	%o0			! return 0

/*
 * copyout(src, dst, len)
 *
 * Copy specified amount of data from kernel to user space.
 * Just like copyin, except that the `dst' addresses are user space
 * rather than the `src' addresses.
 *
 * This is a modified version of bcopy that uses ASI_AIUS.  When
 * bcopy is optimized to use block copy ASIs, this should be also.
 */
 /*
  * This needs to be reimplemented to really do the copy.
  */
ENTRY(copyout)
	/*
	 * ******NOTE****** this depends on bcopy() not using %g7
	 */
Ldocopy:
	GET_CPCB(%o3)
	wr	%g0, ASI_AIUS, %asi
	set	Lcopyfault, %o4
!	mov	%o7, %g7		! save return address
	membar	#Sync
	stx	%o4, [%o3 + PCB_ONFAULT]
	cmp	%o2, BCOPY_SMALL
Lcopyout_start:
	membar	#StoreStore
	bge,a	Lcopyout_fancy	! if >= this many, go be fancy.
	 btst	7, %o0		! (part of being fancy)

	/*
	 * Not much to copy, just do it a byte at a time.
	 */
	deccc	%o2		! while (--len >= 0)
	bl	1f
!	 XXX check no delay slot
0:
	inc	%o0
	ldsb	[%o0 - 1], %o4!	(++dst)[-1] = *src++;
	stba	%o4, [%o1] %asi
	deccc	%o2
	bge	0b
	 inc	%o1
1:
	ba	Lcopyout_done
	 clr	%o0
	NOTREACHED

	/*
	 * Plenty of data to copy, so try to do it optimally.
	 */
Lcopyout_fancy:
	! check for common case first: everything lines up.
!	btst	7, %o0		! done already
	bne	1f
!	 XXX check no delay slot
	btst	7, %o1
	be,a	Lcopyout_doubles
	 dec	8, %o2		! if all lined up, len -= 8, goto copyout_doubes

	! If the low bits match, we can make these line up.
1:
	xor	%o0, %o1, %o3	! t = src ^ dst;
	btst	1, %o3		! if (t & 1) {
	be,a	1f
	 btst	1, %o0		! [delay slot: if (src & 1)]

	! low bits do not match, must copy by bytes.
0:
	ldsb	[%o0], %o4	!	do {
	inc	%o0		!		(++dst)[-1] = *src++;
	inc	%o1
	deccc	%o2
	bnz	0b		!	} while (--len != 0);
	 stba	%o4, [%o1 - 1] %asi
	ba	Lcopyout_done
	 clr	%o0
	NOTREACHED

	! lowest bit matches, so we can copy by words, if nothing else
1:
	be,a	1f		! if (src & 1) {
	 btst	2, %o3		! [delay slot: if (t & 2)]

	! although low bits match, both are 1: must copy 1 byte to align
	ldsb	[%o0], %o4	!	*dst++ = *src++;
	stba	%o4, [%o1] %asi
	inc	%o0
	inc	%o1
	dec	%o2		!	len--;
	btst	2, %o3		! } [if (t & 2)]
1:
	be,a	1f		! if (t & 2) {
	 btst	2, %o0		! [delay slot: if (src & 2)]
	dec	2, %o2		!	len -= 2;
0:
	ldsh	[%o0], %o4	!	do {
	stha	%o4, [%o1] %asi	!		*(short *)dst = *(short *)src;
	inc	2, %o0		!		dst += 2, src += 2;
	deccc	2, %o2		!	} while ((len -= 2) >= 0);
	bge	0b
	 inc	2, %o1
	b	Lcopyout_mopb	!	goto mop_up_byte;
	 btst	1, %o2		! } [delay slot: if (len & 1)]
	NOTREACHED

	! low two bits match, so we can copy by longwords
1:
	be,a	1f		! if (src & 2) {
	 btst	4, %o3		! [delay slot: if (t & 4)]

	! although low 2 bits match, they are 10: must copy one short to align
	ldsh	[%o0], %o4	!	(*short *)dst = *(short *)src;
	stha	%o4, [%o1] %asi
	inc	2, %o0		!	dst += 2;
	inc	2, %o1		!	src += 2;
	dec	2, %o2		!	len -= 2;
	btst	4, %o3		! } [if (t & 4)]
1:
	be,a	1f		! if (t & 4) {
	 btst	4, %o0		! [delay slot: if (src & 4)]
	dec	4, %o2		!	len -= 4;
0:
	lduw	[%o0], %o4	!	do {
	sta	%o4, [%o1] %asi	!		*(int *)dst = *(int *)src;
	inc	4, %o0		!		dst += 4, src += 4;
	deccc	4, %o2		!	} while ((len -= 4) >= 0);
	bge	0b
	 inc	4, %o1
	b	Lcopyout_mopw	!	goto mop_up_word_and_byte;
	 btst	2, %o2		! } [delay slot: if (len & 2)]
	NOTREACHED

	! low three bits match, so we can copy by doublewords
1:
	be	1f		! if (src & 4) {
	 dec	8, %o2		! [delay slot: len -= 8]
	lduw	[%o0], %o4	!	*(int *)dst = *(int *)src;
	sta	%o4, [%o1] %asi
	inc	4, %o0		!	dst += 4, src += 4, len -= 4;
	inc	4, %o1
	dec	4, %o2		! }
1:
Lcopyout_doubles:
	ldx	[%o0], %g1	! do {
	stxa	%g1, [%o1] %asi	!	*(double *)dst = *(double *)src;
	inc	8, %o0		!	dst += 8, src += 8;
	deccc	8, %o2		! } while ((len -= 8) >= 0);
	bge	Lcopyout_doubles
	 inc	8, %o1

	! check for a usual case again (save work)
	btst	7, %o2		! if ((len & 7) == 0)
	be	Lcopyout_done	!	goto copyout_done;

	 btst	4, %o2		! if ((len & 4) == 0)
	be,a	Lcopyout_mopw	!	goto mop_up_word_and_byte;
	 btst	2, %o2		! [delay slot: if (len & 2)]
	lduw	[%o0], %o4	!	*(int *)dst = *(int *)src;
	sta	%o4, [%o1] %asi
	inc	4, %o0		!	dst += 4;
	inc	4, %o1		!	src += 4;
	btst	2, %o2		! } [if (len & 2)]

1:
	! mop up trailing word (if present) and byte (if present).
Lcopyout_mopw:
	be	Lcopyout_mopb	! no word, go mop up byte
	 btst	1, %o2		! [delay slot: if (len & 1)]
	ldsh	[%o0], %o4	! *(short *)dst = *(short *)src;
	be	Lcopyout_done	! if ((len & 1) == 0) goto done;
	 stha	%o4, [%o1] %asi
	ldsb	[%o0 + 2], %o4	! dst[2] = src[2];
	stba	%o4, [%o1 + 2] %asi
	ba	Lcopyout_done
	 clr	%o0
	NOTREACHED

	! mop up trailing byte (if present).
Lcopyout_mopb:
	be,a	Lcopyout_done
	 nop
	ldsb	[%o0], %o4
	stba	%o4, [%o1] %asi

Lcopyout_done:
	GET_CPCB(%o3)
	membar	#Sync
	stx	%g0, [%o3 + PCB_ONFAULT]
!	jmp	%g7 + 8		! Original instr
	wr	%g0, ASI_PRIMARY_NOFAULT, %asi		! Restore ASI
	membar	#StoreStore|#StoreLoad
	retl			! New instr
	 clr	%o0			! return 0

ENTRY(copyin32)
	andcc	%o0, 0x3, %g0
	bnz,pn	%xcc, Lcopyfault
	 nop
	GET_CPCB(%o3)
	set	Lcopyfault, %o4
	membar	#Sync
	stx	%o4, [%o3 + PCB_ONFAULT]
	lduwa	[%o0] ASI_AIUS, %o2
	stw	%o2, [%o1]
	membar	#Sync
	stx	%g0, [%o3 + PCB_ONFAULT]
	retl
	 clr	%o0

! Copyin or copyout fault.  Clear cpcb->pcb_onfault and return EFAULT.
! Note that although we were in bcopy, there is no state to clean up;
! the only special thing is that we have to return to [g7 + 8] rather than
! [o7 + 8].
Lcopyfault:
	GET_CPCB(%o3)
	stx	%g0, [%o3 + PCB_ONFAULT]
	membar	#StoreStore|#StoreLoad
	wr	%g0, ASI_PRIMARY_NOFAULT, %asi		! Restore ASI
	retl
	 mov	EFAULT, %o0

/*
 * cpu_switchto(struct proc *old, struct proc *new)
 *
 * Save the context of "old" and switch to "new".
 */
ENTRY(cpu_switchto)
	save	%sp, -CC64FSZ, %sp
	rdpr	%pstate, %o1		! oldpstate = %pstate;
	wrpr	%g0, PSTATE_INTR, %pstate ! make sure we're on normal globals

	ldx	[%g7 + CI_CPCB], %l5

	/*
	 * Register usage:
	 *
	 *	%i0 = oldproc
	 *	%i1 = newproc
	 *	%l1 = newpcb
	 *	%l2 = newpstate
	 *	%l5 = cpcb
	 *	%o0 = tmp 1
	 *	%o1 = oldpstate
	 *	%o2 = tmp 2
	 *	%o3 = vm
	 *	%o4 = sswap
	 *	%o5 = <free>
	 */

	/*
	 * Committed to running process p.
	 */
#if defined(MULTIPROCESSOR)
	/*
	 * p->p_cpu = curcpu();
	 */
	ldx	[%g7 + CI_SELF], %o0
	stx	%o0, [%i1 + P_CPU]
#endif	/* defined(MULTIPROCESSOR) */
	mov	SONPROC, %o0			! newproc->p_stat = SONPROC
	stb	%o0, [%i1 + P_STAT]
	ldx	[%i1 + P_ADDR], %l1		! newpcb = newpeoc->p_addr;

	flushw				! save all register windows except this one

	/*
	 * Not the old process.  Save the old process, if any;
	 * then load p.
	 */
	brz,pn	%i0, Lsw_load		! if no old process, go load
	 wrpr	%g0, PSTATE_KERN, %pstate

	stx	%i6, [%l5 + PCB_SP]	! cpcb->pcb_sp = sp;
	stx	%i7, [%l5 + PCB_PC]	! cpcb->pcb_pc = pc;
	sth	%o1, [%l5 + PCB_PSTATE]	! cpcb->pcb_pstate = oldpstate;
	rdpr	%cwp, %o2		! Useless
	stb	%o2, [%l5 + PCB_CWP]

	/*
	 * Load the new process.  To load, we must change stacks and
	 * alter cpcb and the window control registers, hence we must
	 * disable interrupts.
	 *
	 * We also must load up the `in' and `local' registers.
	 */
Lsw_load:
	/* set new cpcb */
	stx	%i1, [%g7 + CI_CURPROC]	! curproc = newproc;
	stx	%l1, [%g7 + CI_CPCB]	! cpcb = newpcb;

	ldx	[%l1 + PCB_SP], %i6
	ldx	[%l1 + PCB_PC], %i7

	/* finally, enable traps */
	wrpr	%g0, PSTATE_INTR, %pstate

	/*
	 * Now running p.  Make sure it has a context so that it
	 * can talk about user space stuff.  (Its pcb_uw is currently
	 * zero so it is safe to have interrupts going here.)
	 */
	ldx	[%i1 + P_VMSPACE], %o3		! vm = newproc->p_vmspace;
	sethi	%hi(_C_LABEL(kernel_pmap_)), %o1
	mov	CTX_SECONDARY, %l5		! Recycle %l5
	ldx	[%o3 + VM_PMAP], %o2		! if (vm->vm_pmap != kernel_pmap_)
	or	%o1, %lo(_C_LABEL(kernel_pmap_)), %o1
	cmp	%o2, %o1
	bz,pn	%xcc, Lsw_havectx		! Don't replace kernel context!
	 ld	[%o2 + PM_CTX], %o0
	brnz,pt	%o0, Lsw_havectx		!	goto havecontext;
	 nop
	
	/* p does not have a context: call ctx_alloc to get one */
	call	_C_LABEL(ctx_alloc)		! ctx_alloc(&vm->vm_pmap);
	 mov	%o2, %o0

	set	DEMAP_CTX_SECONDARY, %o1	! This context has been recycled
	stxa	%o0, [%l5] ASI_DMMU		! so we need to invalidate
	membar	#Sync
	stxa	%o1, [%o1] ASI_DMMU_DEMAP	! whatever bits of it may
	stxa	%o1, [%o1] ASI_IMMU_DEMAP	! be left in the TLB
	membar	#Sync
	/* p does have a context: just switch to it */
Lsw_havectx:
	! context is in %o0
	/*
	 * We probably need to flush the cache here.
	 */
	SET_MMU_CONTEXTID(%o0, %l5)		! Maybe we should invalidate the old context?
	membar	#Sync				! Maybe we should use flush here?
	flush	%sp

!	wrpr	%g0, 0, %cleanwin	! DEBUG
	clr	%g4		! This needs to point to the base of the data segment
	wr	%g0, ASI_PRIMARY_NOFAULT, %asi		! Restore default ASI
	wrpr	%g0, PSTATE_INTR, %pstate
	ret
	 restore

/*
 * Snapshot the current process so that stack frames are up to date.
 * Only used just before a crash dump.
 */
ENTRY(snapshot)
	rdpr	%pstate, %o1		! save psr
	stx	%o6, [%o0 + PCB_SP]	! save sp
	rdpr	%pil, %o2
	sth	%o1, [%o0 + PCB_PSTATE]
	rdpr	%cwp, %o3
	stb	%o2, [%o0 + PCB_PIL]
	stb	%o3, [%o0 + PCB_CWP]

	flushw
	save	%sp, -CC64FSZ, %sp
	flushw
	ret
	 restore

/*
 * cpu_set_kpc() and cpu_fork() arrange for proc_trampoline() to run
 * after after a process gets chosen in switch(). The stack frame will
 * contain a function pointer in %l0, and an argument to pass to it in %l2.
 *
 * If the function *(%l0) returns, we arrange for an immediate return
 * to user mode. This happens in two known cases: after execve(2) of init,
 * and when returning a child to user mode after a fork(2).
 */
ENTRY(proc_trampoline)
#ifdef MULTIPROCESSOR
	save	%sp, -CC64FSZ, %sp
	call	_C_LABEL(proc_trampoline_mp)
	 nop
	restore
#endif
	wrpr	%g0, 0, %pil		! Reset interrupt level
	call	%l0			! re-use current frame
	 mov	%l1, %o0

	/*
	 * Here we finish up as in syscall, but simplified.  We need to
	 * fiddle pc and npc a bit, as execve() / setregs() /cpu_set_kpc()
	 * have only set npc, in anticipation that trap.c will advance past
	 * the trap instruction; but we bypass that, so we must do it manually.
	 */
!	save	%sp, -CC64FSZ, %sp		! Save a kernel frame to emulate a syscall
#if 0
	/* This code doesn't seem to work, but it should. */
	ldx	[%sp + CC64FSZ + BIAS + TF_TSTATE], %g1
	ldx	[%sp + CC64FSZ + BIAS + TF_NPC], %g2	! pc = tf->tf_npc from execve/fork
	andn	%g1, CWP, %g1			! Clear the CWP bits
	add	%g2, 4, %g3			! npc = pc+4
	rdpr	%cwp, %g5			! Fixup %cwp in %tstate
	stx	%g3, [%sp + CC64FSZ + BIAS + TF_NPC]
	or	%g1, %g5, %g1
	stx	%g2, [%sp + CC64FSZ + BIAS + TF_PC]
	stx	%g1, [%sp + CC64FSZ + BIAS + TF_TSTATE]
#else	/* 0 */
	mov	PSTATE_USER, %g1		! XXXX user pstate (no need to load it)
	sllx	%g1, TSTATE_PSTATE_SHIFT, %g1	! Shift it into place
	rdpr	%cwp, %g5			! Fixup %cwp in %tstate
	or	%g1, %g5, %g1
	stx	%g1, [%sp + CC64FSZ + BIAS + TF_TSTATE]
#endif	/* 0 */
	CHKPT %o3,%o4,0x35
	ba,a,pt	%icc, return_from_trap
	 nop

#ifdef DDB

/*
 * The following probably need to be changed, but to what I don't know.
 */

/*
 * u_int64_t
 * probeget(addr, asi, size)
 *	paddr_t addr;
 *	int asi;
 *	int size;
 *
 * Read a (byte,short,int,long) from the given address.
 * Like copyin but our caller is supposed to know what he is doing...
 * the address can be anywhere.
 *
 * We optimize for space, rather than time, here.
 */
ENTRY(probeget)
	mov	%o2, %o4
	! %o0 = addr, %o1 = asi, %o4 = (1,2,4)
	GET_CPCB(%o2)			! cpcb->pcb_onfault = Lfsprobe;
	set	_C_LABEL(Lfsprobe), %o5
	stx	%o5, [%o2 + PCB_ONFAULT]
	or	%o0, 0x9, %o3		! if (PHYS_ASI(asi)) {
	sub	%o3, 0x1d, %o3
	brz,a	%o3, 0f
	 mov	%g0, %o5
	DLFLUSH %o0,%o5		!	flush cache line
					! }
0:
	btst	1, %o4
	wr	%o1, 0, %asi
	membar	#Sync
	bz	0f			! if (len & 1)
	 btst	2, %o4
	ba,pt	%icc, 1f
	 lduba	[%o0] %asi, %o0		!	value = *(char *)addr;
0:
	bz	0f			! if (len & 2)
	 btst	4, %o4
	ba,pt	%icc, 1f
	 lduha	[%o0] %asi, %o0		!	value = *(short *)addr;
0:
	bz	0f			! if (len & 4)
	 btst	8, %o4
	ba,pt	%icc, 1f
	 lda	[%o0] %asi, %o0		!	value = *(int *)addr;
0:
	ldxa	[%o0] %asi, %o0		!	value = *(long *)addr;
1:	
	membar	#Sync
	brz	%o5, 1f			! if (cache flush addr != 0)
	 nop
	DLFLUSH2 %o5			!	flush cache line again
1:
	wr	%g0, ASI_PRIMARY_NOFAULT, %asi		! Restore default ASI	
	stx	%g0, [%o2 + PCB_ONFAULT]
	retl				! made it, clear onfault and return
	 membar	#StoreStore|#StoreLoad

	/*
	 * Fault handler for probeget
	 */
	.globl	_C_LABEL(Lfsprobe)
_C_LABEL(Lfsprobe):
	stx	%g0, [%o2 + PCB_ONFAULT]! error in r/w, clear pcb_onfault
	mov	-1, %o1
	wr	%g0, ASI_PRIMARY_NOFAULT, %asi		! Restore default ASI	
	membar	#StoreStore|#StoreLoad
	retl				! and return error indicator
	 mov	-1, %o0

#endif	/* DDB */

/*
 * pmap_zero_page(pa)
 *
 * Zero one page physically addressed
 *
 * Block load/store ASIs do not exist for physical addresses,
 * so we won't use them.
 *
 * While we do the zero operation, we also need to blast away
 * the contents of the D$.  We will execute a flush at the end
 * to sync the I$.
 */
	.data
paginuse:
	.word	0
	.text
ENTRY(pmap_zero_phys)
	set	NBPG, %o2		! Loop count
	clr	%o1
1:
	dec	8, %o2
	stxa	%g0, [%o0] ASI_PHYS_CACHED
	inc	8, %o0
dlflush5:
	stxa	%g0, [%o1] ASI_DCACHE_TAG
	brgz	%o2, 1b
	 inc	16, %o1

	sethi	%hi(KERNBASE), %o3
	flush	%o3
	retl
	 nop
/*
 * pmap_copy_page(src, dst)
 *
 * Copy one page physically addressed
 *
 * We also need to blast the D$ and flush like
 * pmap_zero_page.
 */
ENTRY(pmap_copy_phys)
	set	NBPG, %o3
	add	%o3, %o0, %o3
1:
	ldxa	[%o0] ASI_PHYS_CACHED, %o4
	inc	8, %o0
	cmp	%o0, %o3
	stxa	%o4, [%o1] ASI_PHYS_CACHED
	blu,pt	%xcc, 1b
	 inc	8, %o1
	retl
	 nop

/*
 * extern int64_t pseg_get(struct pmap* %o0, vaddr_t addr %o1);
 *
 * Return TTE at addr in pmap.  Uses physical addressing only.
 * pmap->pm_physaddr must by the physical address of pm_segs
 *
 */
ENTRY(pseg_get)
	ldx	[%o0 + PM_PHYS], %o2			! pmap->pm_segs

	srax	%o1, HOLESHIFT, %o3			! Check for valid address
	brz,pt	%o3, 0f					! Should be zero or -1
	 inc	%o3					! Make -1 -> 0
	brnz,pn	%o3, 1f					! Error! In hole!
0:
	srlx	%o1, STSHIFT, %o3
	and	%o3, STMASK, %o3			! Index into pm_segs
	sll	%o3, 3, %o3
	add	%o2, %o3, %o2
	DLFLUSH %o2,%o3
	ldxa	[%o2] ASI_PHYS_CACHED, %o2		! Load page directory pointer
	DLFLUSH2 %o3

	srlx	%o1, PDSHIFT, %o3
	and	%o3, PDMASK, %o3
	sll	%o3, 3, %o3
	brz,pn	%o2, 1f					! NULL entry? check somewhere else
	 add	%o2, %o3, %o2
	DLFLUSH %o2,%o3
	ldxa	[%o2] ASI_PHYS_CACHED, %o2		! Load page table pointer
	DLFLUSH2 %o3

	srlx	%o1, PTSHIFT, %o3			! Convert to ptab offset
	and	%o3, PTMASK, %o3
	sll	%o3, 3, %o3
	brz,pn	%o2, 1f					! NULL entry? check somewhere else
	 add	%o2, %o3, %o2
	DLFLUSH %o2,%o3
	ldxa	[%o2] ASI_PHYS_CACHED, %o0
	DLFLUSH2 %o3
	brgez,pn %o0, 1f				! Entry invalid?  Punt
	 nop
	retl
	 nop
1:
	retl
	 clr	%o0

/*
 * extern int pseg_set(struct pmap* %o0, vaddr_t addr %o1, int64_t tte %o2,
 *			paddr_t spare %o3);
 *
 * Set a pseg entry to a particular TTE value.  Returns 0 on success,
 * 1 if it needs to fill a pseg, 2 if it succeeded but didn't need the
 * spare page, and -1 if the address is in the virtual hole.
 * (NB: nobody in pmap checks for the virtual hole, so the system will hang.)
 * Allocate a page, pass the phys addr in as the spare, and try again.
 * If spare is not NULL it is assumed to be the address of a zeroed physical
 * page that can be used to generate a directory table or page table if needed.
 *
 */
ENTRY(pseg_set)
	!!
	!! However we managed to get here we now have:
	!!
	!! %o0 = *pmap
	!! %o1 = addr
	!! %o2 = tte
	!! %o3 = spare
	!!
	srax	%o1, HOLESHIFT, %o4			! Check for valid address
	brz,pt	%o4, 0f					! Should be zero or -1
	 inc	%o4					! Make -1 -> 0
	brz,pt	%o4, 0f
	 nop
#ifdef DEBUG
	ta	1					! Break into debugger
#endif	/* DEBUG */
	mov	-1, %o0					! Error -- in hole!
	retl
	 mov	-1, %o1
0:
	ldx	[%o0 + PM_PHYS], %o4			! pmap->pm_segs
	srlx	%o1, STSHIFT, %o5
	and	%o5, STMASK, %o5
	sll	%o5, 3, %o5
	add	%o4, %o5, %o4
2:
	DLFLUSH %o4,%g1
	ldxa	[%o4] ASI_PHYS_CACHED, %o5		! Load page directory pointer
	DLFLUSH2 %g1

	brnz,a,pt	%o5, 0f				! Null pointer?
	 mov	%o5, %o4
	brz,pn	%o3, 1f					! Have a spare?
	 mov	%o3, %o5
	casxa	[%o4] ASI_PHYS_CACHED, %g0, %o5
	brnz,pn	%o5, 2b					! Something changed?
	DLFLUSH %o4, %o5
	mov	%o3, %o4
	clr	%o3					! Mark spare as used
0:
	srlx	%o1, PDSHIFT, %o5
	and	%o5, PDMASK, %o5
	sll	%o5, 3, %o5
	add	%o4, %o5, %o4
2:
	DLFLUSH %o4,%g1
	ldxa	[%o4] ASI_PHYS_CACHED, %o5		! Load table directory pointer
	DLFLUSH2 %g1

	brnz,a,pt	%o5, 0f				! Null pointer?
	 mov	%o5, %o4
	brz,pn	%o3, 1f					! Have a spare?
	 mov	%o3, %o5
	casxa	[%o4] ASI_PHYS_CACHED, %g0, %o5
	brnz,pn	%o5, 2b					! Something changed?
	DLFLUSH %o4, %o4
	mov	%o3, %o4
	clr	%o3					! Mark spare as used
0:
	srlx	%o1, PTSHIFT, %o5			! Convert to ptab offset
	and	%o5, PTMASK, %o5
	sll	%o5, 3, %o5
	add	%o5, %o4, %o4
	stxa	%o2, [%o4] ASI_PHYS_CACHED		! Easier than shift+or
	DLFLUSH %o4, %o4
	mov	2, %o0					! spare unused?
	retl
	 movrz	%o3, %g0, %o0				! No. return 0
1:
	retl
	 mov	1, %o0


/*
 * memcpy(dst, src, len) - always copies forward.
 *
 * Must not use %g7 (see copyin/copyout above).
 */
ENTRY(memcpy) /* dest, src, size */
	cmp	%o2, BCOPY_SMALL! (check length for doublecopy first)
Lmemcpy_start:
	bge,pt	%xcc, 2f	! if >= this many, go be fancy.
	 nop

	mov	%o0, %o5	! Save memcpy return value
	/*
	 * Not much to copy, just do it a byte at a time.
	 */
	deccc	%o2		! while (--len >= 0)
	bl	1f
!	 XXX check no delay slot
0:
	inc	%o1
	ldsb	[%o1 - 1], %o4	!	(++dst)[-1] = *src++;
	stb	%o4, [%o0]
	deccc	%o2
	bge	0b
	 inc	%o0
1:
	retl
	 mov	%o5, %o0
	NOTREACHED

	/*
	 * Plenty of data to copy, so try to do it optimally.
	 */
2:
Lbcopy_fancy:

	!!
	!! First align the output to a 8-byte entity
	!! 

	save	%sp, -CC64FSZ, %sp
	
	mov	%i1, %l0
	mov	%i0, %l1
	
	mov	%i2, %l2
	btst	1, %l1
	
	bz,pt	%icc, 4f
	 btst	2, %l1
	ldub	[%l0], %l4				! Load 1st byte
	
	deccc	1, %l2
	ble,pn	%xcc, Lbcopy_finish			! XXXX
	 inc	1, %l0
	
	stb	%l4, [%l1]				! Store 1st byte
	inc	1, %l1					! Update address
	btst	2, %l1
4:	
	bz,pt	%icc, 4f
	
	 btst	1, %l0
	bz,a	1f
	 lduh	[%l0], %l4				! Load short

	ldub	[%l0], %l4				! Load bytes
	
	ldub	[%l0+1], %l3
	sllx	%l4, 8, %l4
	or	%l3, %l4, %l4
	
1:	
	deccc	2, %l2
	ble,pn	%xcc, Lbcopy_finish			! XXXX
	 inc	2, %l0
	sth	%l4, [%l1]				! Store 1st short
	
	inc	2, %l1
4:
	btst	4, %l1
	bz,pt	%xcc, 4f
	
	 btst	3, %l0
	bz,a,pt	%xcc, 1f
	 lduw	[%l0], %l4				! Load word -1

	btst	1, %l0
	bz,a,pt	%icc, 2f
	 lduh	[%l0], %l4
	
	ldub	[%l0], %l4
	
	lduh	[%l0+1], %l3
	sllx	%l4, 16, %l4
	or	%l4, %l3, %l4
	
	ldub	[%l0+3], %l3
	sllx	%l4, 8, %l4
	ba,pt	%icc, 1f
	 or	%l4, %l3, %l4
	
2:
	lduh	[%l0+2], %l3
	sllx	%l4, 16, %l4
	or	%l4, %l3, %l4
	
1:	
	deccc	4, %l2
	ble,pn	%xcc, Lbcopy_finish		! XXXX
	 inc	4, %l0
	
	st	%l4, [%l1]				! Store word
	inc	4, %l1
4:
	!!
	!! We are now 32-bit aligned in the dest.
	!!
Lbcopy_common:	

	and	%l0, 7, %l4				! Shift amount
	andn	%l0, 7, %l0				! Source addr
	
	brz,pt	%l4, Lbcopy_noshift8			! No shift version...

	 sllx	%l4, 3, %l4				! In bits
	mov	8<<3, %l3
	
	ldx	[%l0], %o0				! Load word -1
	sub	%l3, %l4, %l3				! Reverse shift
	deccc	12*8, %l2				! Have enough room?
	
	sllx	%o0, %l4, %o0
	bl,pn	%xcc, 2f
	 and	%l3, 0x38, %l3
Lbcopy_unrolled8:

	/*
	 * This is about as close to optimal as you can get, since
	 * the shifts require EU0 and cannot be paired, and you have
	 * 3 dependent operations on the data.
	 */ 

!	ldx	[%l0+0*8], %o0				! Already done
!	sllx	%o0, %l4, %o0				! Already done
	ldx	[%l0+1*8], %o1
	ldx	[%l0+2*8], %o2
	ldx	[%l0+3*8], %o3
	ldx	[%l0+4*8], %o4
	ba,pt	%icc, 1f
	 ldx	[%l0+5*8], %o5
	.align	8
1:
	srlx	%o1, %l3, %g1
	inc	6*8, %l0
	
	sllx	%o1, %l4, %o1
	or	%g1, %o0, %g6
	ldx	[%l0+0*8], %o0
	
	stx	%g6, [%l1+0*8]
	srlx	%o2, %l3, %g1

	sllx	%o2, %l4, %o2
	or	%g1, %o1, %g6
	ldx	[%l0+1*8], %o1
	
	stx	%g6, [%l1+1*8]
	srlx	%o3, %l3, %g1
	
	sllx	%o3, %l4, %o3
	or	%g1, %o2, %g6
	ldx	[%l0+2*8], %o2
	
	stx	%g6, [%l1+2*8]
	srlx	%o4, %l3, %g1
	
	sllx	%o4, %l4, %o4	
	or	%g1, %o3, %g6
	ldx	[%l0+3*8], %o3
	
	stx	%g6, [%l1+3*8]
	srlx	%o5, %l3, %g1
	
	sllx	%o5, %l4, %o5
	or	%g1, %o4, %g6
	ldx	[%l0+4*8], %o4

	stx	%g6, [%l1+4*8]
	srlx	%o0, %l3, %g1
	deccc	6*8, %l2				! Have enough room?

	sllx	%o0, %l4, %o0				! Next loop
	or	%g1, %o5, %g6
	ldx	[%l0+5*8], %o5
	
	stx	%g6, [%l1+5*8]
	bge,pt	%xcc, 1b
	 inc	6*8, %l1

Lbcopy_unrolled8_cleanup:	
	!!
	!! Finished 8 byte block, unload the regs.
	!! 
	srlx	%o1, %l3, %g1
	inc	5*8, %l0
	
	sllx	%o1, %l4, %o1
	or	%g1, %o0, %g6
		
	stx	%g6, [%l1+0*8]
	srlx	%o2, %l3, %g1
	
	sllx	%o2, %l4, %o2
	or	%g1, %o1, %g6
		
	stx	%g6, [%l1+1*8]
	srlx	%o3, %l3, %g1
	
	sllx	%o3, %l4, %o3
	or	%g1, %o2, %g6
		
	stx	%g6, [%l1+2*8]
	srlx	%o4, %l3, %g1
	
	sllx	%o4, %l4, %o4	
	or	%g1, %o3, %g6
		
	stx	%g6, [%l1+3*8]
	srlx	%o5, %l3, %g1
	
	sllx	%o5, %l4, %o5
	or	%g1, %o4, %g6
		
	stx	%g6, [%l1+4*8]
	inc	5*8, %l1
	
	mov	%o5, %o0				! Save our unused data
	dec	5*8, %l2
2:
	inccc	12*8, %l2
	bz,pn	%icc, Lbcopy_complete
	
	!! Unrolled 8 times
Lbcopy_aligned8:	
!	ldx	[%l0], %o0				! Already done
!	sllx	%o0, %l4, %o0				! Shift high word
	
	 deccc	8, %l2					! Pre-decrement
	bl,pn	%xcc, Lbcopy_finish
1:
	ldx	[%l0+8], %o1				! Load word 0
	inc	8, %l0
	
	srlx	%o1, %l3, %g6
	or	%g6, %o0, %g6				! Combine
	
	stx	%g6, [%l1]				! Store result
	 inc	8, %l1
	
	deccc	8, %l2
	bge,pn	%xcc, 1b
	 sllx	%o1, %l4, %o0	

	btst	7, %l2					! Done?
	bz,pt	%xcc, Lbcopy_complete

	!!
	!! Loadup the last dregs into %o0 and shift it into place
	!! 
	 srlx	%l3, 3, %g6				! # bytes in %o0
	dec	8, %g6					!  - 8
	!! n-8 - (by - 8) -> n - by
	subcc	%l2, %g6, %g0				! # bytes we need
	ble,pt	%icc, Lbcopy_finish
	 nop
	ldx	[%l0+8], %o1				! Need another word
	srlx	%o1, %l3, %o1
	ba,pt	%icc, Lbcopy_finish
	 or	%o0, %o1, %o0				! All loaded up.
	
Lbcopy_noshift8:
	deccc	6*8, %l2				! Have enough room?
	bl,pn	%xcc, 2f
	 nop
	ba,pt	%icc, 1f
	 nop
	.align	32
1:	
	ldx	[%l0+0*8], %o0
	ldx	[%l0+1*8], %o1
	ldx	[%l0+2*8], %o2
	stx	%o0, [%l1+0*8]
	stx	%o1, [%l1+1*8]
	stx	%o2, [%l1+2*8]

	
	ldx	[%l0+3*8], %o3
	ldx	[%l0+4*8], %o4
	ldx	[%l0+5*8], %o5
	inc	6*8, %l0
	stx	%o3, [%l1+3*8]
	deccc	6*8, %l2
	stx	%o4, [%l1+4*8]
	stx	%o5, [%l1+5*8]
	bge,pt	%xcc, 1b
	 inc	6*8, %l1
2:
	inc	6*8, %l2
1:	
	deccc	8, %l2
	bl,pn	%icc, 1f				! < 0 --> sub word
	 nop
	ldx	[%l0], %g6
	inc	8, %l0
	stx	%g6, [%l1]
	bg,pt	%icc, 1b				! Exactly 0 --> done
	 inc	8, %l1
1:
	btst	7, %l2					! Done?
	bz,pt	%xcc, Lbcopy_complete
	 clr	%l4
	ldx	[%l0], %o0
Lbcopy_finish:
	
	brz,pn	%l2, 2f					! 100% complete?
	 cmp	%l2, 8					! Exactly 8 bytes?
	bz,a,pn	%xcc, 2f
	 stx	%o0, [%l1]

	btst	4, %l2					! Word store?
	bz	%xcc, 1f
	 srlx	%o0, 32, %g6				! Shift high word down
	stw	%g6, [%l1]
	inc	4, %l1
	mov	%o0, %g6				! Operate on the low bits
1:
	btst	2, %l2
	mov	%g6, %o0
	bz	1f
	 srlx	%o0, 16, %g6
	
	sth	%g6, [%l1]				! Store short
	inc	2, %l1
	mov	%o0, %g6				! Operate on low bytes
1:
	mov	%g6, %o0
	btst	1, %l2					! Byte aligned?
	bz	2f
	 srlx	%o0, 8, %g6

	stb	%g6, [%l1]				! Store last byte
	inc	1, %l1					! Update address
2:	
Lbcopy_complete:
	ret
	 restore %i0, %g0, %o0
	
/*
 * bzero(addr, len)
 *
 * XXXXX To produce more efficient code, we do not allow lengths
 * greater than 0x80000000000000000, which are negative numbers.
 * This should not really be an issue since the VA hole should
 * cause any such ranges to fail anyway.
 */
ENTRY(bzero)
	! %o0 = addr, %o1 = len
	mov	%o1, %o2
	clr	%o1			! Initialize our pattern
/*
 * memset(addr, c, len)
 */
ENTRY(memset)
	! %o0 = addr, %o1 = pattern, %o2 = len
	mov	%o0, %o4		! Save original pointer

Lbzero_internal:
	btst	7, %o0			! Word aligned?
	bz,pn	%xcc, 0f
	 nop
	inc	%o0
	deccc	%o2			! Store up to 7 bytes
	bge,a,pt	%xcc, Lbzero_internal
	 stb	%o1, [%o0 - 1]

	retl				! Duplicate Lbzero_done
	 mov	%o4, %o0
0:
	/*
	 * Duplicate the pattern so it fills 64-bits.
	 */
	andcc	%o1, 0x0ff, %o1		! No need to extend zero
	bz,pt	%icc, 1f
	 sllx	%o1, 8, %o3		! sigh.  all dependent instructions.
	or	%o1, %o3, %o1
	sllx	%o1, 16, %o3
	or	%o1, %o3, %o1
	sllx	%o1, 32, %o3
	 or	%o1, %o3, %o1
1:	
	 deccc	8, %o2
Lbzero_longs:
	bl,pn	%xcc, Lbzero_cleanup	! Less than 8 bytes left
	 nop
3:	
	inc	8, %o0
	deccc	8, %o2
	bge,pt	%xcc, 3b
	 stx	%o1, [%o0 - 8]		! Do 1 longword at a time

	/*
	 * Len is in [-8..-1] where -8 => done, -7 => 1 byte to zero,
	 * -6 => two bytes, etc.  Mop up this remainder, if any.
	 */
Lbzero_cleanup:	
	btst	4, %o2
	bz,pt	%xcc, 5f		! if (len & 4) {
	 nop
	stw	%o1, [%o0]		!	*(int *)addr = 0;
	inc	4, %o0			!	addr += 4;
5:	
	btst	2, %o2
	bz,pt	%xcc, 7f		! if (len & 2) {
	 nop
	sth	%o1, [%o0]		!	*(short *)addr = 0;
	inc	2, %o0			!	addr += 2;
7:	
	btst	1, %o2
	bnz,a	%icc, Lbzero_done	! if (len & 1)
	 stb	%o1, [%o0]		!	*addr = 0;
Lbzero_done:
	retl
	 mov	%o4, %o0		! Restore pointer for memset (ugh)

/*
 * kcopy() is exactly like bcopy except that it set pcb_onfault such that
 * when a fault occurs, it is able to return EFAULT to indicate this to the
 * caller.
 */
ENTRY(kcopy)
	GET_CPCB(%o5)			! cpcb->pcb_onfault = Lkcerr;
	set	Lkcerr, %o3
	ldx	[%o5 + PCB_ONFAULT], %g1! save current onfault handler
	membar	#LoadStore
	stx	%o3, [%o5 + PCB_ONFAULT]
	membar	#StoreStore|#StoreLoad

	cmp	%o2, BCOPY_SMALL
Lkcopy_start:
	bge,a	Lkcopy_fancy	! if >= this many, go be fancy.
	 btst	7, %o0		! (part of being fancy)

	/*
	 * Not much to copy, just do it a byte at a time.
	 */
	deccc	%o2		! while (--len >= 0)
	bl	1f
!	 XXX check no delay slot
0:
	ldsb	[%o0], %o4	!	*dst++ = *src++;
	inc	%o0
	stb	%o4, [%o1]
	deccc	%o2
	bge	0b
	 inc	%o1
1:
	membar	#Sync		! Make sure all faults are processed
	stx	%g1, [%o5 + PCB_ONFAULT]! restore fault handler
	membar	#StoreStore|#StoreLoad
	retl
	 clr	%o0
	NOTREACHED

	/*
	 * Plenty of data to copy, so try to do it optimally.
	 */
Lkcopy_fancy:
	! check for common case first: everything lines up.
!	btst	7, %o0		! done already
	bne	1f
!	 XXX check no delay slot
	btst	7, %o1
	be,a	Lkcopy_doubles
	 dec	8, %o2		! if all lined up, len -= 8, goto kcopy_doubes

	! If the low bits match, we can make these line up.
1:
	xor	%o0, %o1, %o3	! t = src ^ dst;
	btst	1, %o3		! if (t & 1) {
	be,a	1f
	 btst	1, %o0		! [delay slot: if (src & 1)]

	! low bits do not match, must copy by bytes.
0:
	ldsb	[%o0], %o4	!	do {
	inc	%o0		!		*dst++ = *src++;
	stb	%o4, [%o1]
	deccc	%o2
	bnz	0b		!	} while (--len != 0);
	 inc	%o1
	membar	#Sync		! Make sure all traps are taken
	stx	%g1, [%o5 + PCB_ONFAULT]! restore fault handler
	membar	#StoreStore|#StoreLoad
	retl
	 clr	%o0
	NOTREACHED

	! lowest bit matches, so we can copy by words, if nothing else
1:
	be,a	1f		! if (src & 1) {
	 btst	2, %o3		! [delay slot: if (t & 2)]

	! although low bits match, both are 1: must copy 1 byte to align
	ldsb	[%o0], %o4	!	*dst++ = *src++;
	inc	%o0
	stb	%o4, [%o1]
	dec	%o2		!	len--;
	inc	%o1
	btst	2, %o3		! } [if (t & 2)]
1:
	be,a	1f		! if (t & 2) {
	 btst	2, %o0		! [delay slot: if (src & 2)]
	dec	2, %o2		!	len -= 2;
0:
	ldsh	[%o0], %o4	!	do {
	inc	2, %o0		!		dst += 2, src += 2;
	sth	%o4, [%o1]	!		*(short *)dst = *(short *)src;
	deccc	2, %o2		!	} while ((len -= 2) >= 0);
	bge	0b
	 inc	2, %o1
	b	Lkcopy_mopb	!	goto mop_up_byte;
	 btst	1, %o2		! } [delay slot: if (len & 1)]
	NOTREACHED

	! low two bits match, so we can copy by longwords
1:
	be,a	1f		! if (src & 2) {
	 btst	4, %o3		! [delay slot: if (t & 4)]

	! although low 2 bits match, they are 10: must copy one short to align
	ldsh	[%o0], %o4	!	(*short *)dst = *(short *)src;
	inc	2, %o0		!	dst += 2;
	sth	%o4, [%o1]
	dec	2, %o2		!	len -= 2;
	inc	2, %o1		!	src += 2;
	btst	4, %o3		! } [if (t & 4)]
1:
	be,a	1f		! if (t & 4) {
	 btst	4, %o0		! [delay slot: if (src & 4)]
	dec	4, %o2		!	len -= 4;
0:
	ld	[%o0], %o4	!	do {
	inc	4, %o0		!		dst += 4, src += 4;
	st	%o4, [%o1]	!		*(int *)dst = *(int *)src;
	deccc	4, %o2		!	} while ((len -= 4) >= 0);
	bge	0b
	 inc	4, %o1
	b	Lkcopy_mopw	!	goto mop_up_word_and_byte;
	 btst	2, %o2		! } [delay slot: if (len & 2)]
	NOTREACHED

	! low three bits match, so we can copy by doublewords
1:
	be	1f		! if (src & 4) {
	 dec	8, %o2		! [delay slot: len -= 8]
	ld	[%o0], %o4	!	*(int *)dst = *(int *)src;
	inc	4, %o0		!	dst += 4, src += 4, len -= 4;
	st	%o4, [%o1]
	dec	4, %o2		! }
	inc	4, %o1
1:
Lkcopy_doubles:
	ldx	[%o0], %g5	! do {
	inc	8, %o0		!	dst += 8, src += 8;
	stx	%g5, [%o1]	!	*(double *)dst = *(double *)src;
	deccc	8, %o2		! } while ((len -= 8) >= 0);
	bge	Lkcopy_doubles
	 inc	8, %o1

	! check for a usual case again (save work)
	btst	7, %o2		! if ((len & 7) == 0)
	be	Lkcopy_done	!	goto kcopy_done;

	 btst	4, %o2		! if ((len & 4) == 0)
	be,a	Lkcopy_mopw	!	goto mop_up_word_and_byte;
	 btst	2, %o2		! [delay slot: if (len & 2)]
	ld	[%o0], %o4	!	*(int *)dst = *(int *)src;
	inc	4, %o0		!	dst += 4;
	st	%o4, [%o1]
	inc	4, %o1		!	src += 4;
	btst	2, %o2		! } [if (len & 2)]

1:
	! mop up trailing word (if present) and byte (if present).
Lkcopy_mopw:
	be	Lkcopy_mopb	! no word, go mop up byte
	 btst	1, %o2		! [delay slot: if (len & 1)]
	ldsh	[%o0], %o4	! *(short *)dst = *(short *)src;
	be	Lkcopy_done	! if ((len & 1) == 0) goto done;
	 sth	%o4, [%o1]
	ldsb	[%o0 + 2], %o4	! dst[2] = src[2];
	stb	%o4, [%o1 + 2]
	membar	#Sync		! Make sure all traps are taken
	stx	%g1, [%o5 + PCB_ONFAULT]! restore fault handler
	membar	#StoreStore|#StoreLoad
	retl
	 clr	%o0
	NOTREACHED

	! mop up trailing byte (if present).
Lkcopy_mopb:
	bne,a	1f
	 ldsb	[%o0], %o4

Lkcopy_done:
	membar	#Sync		! Make sure all traps are taken
	stx	%g1, [%o5 + PCB_ONFAULT]! restore fault handler
	membar	#StoreStore|#StoreLoad
	retl
	 clr	%o0
	NOTREACHED

1:
	stb	%o4, [%o1]
	membar	#Sync		! Make sure all traps are taken
	stx	%g1, [%o5 + PCB_ONFAULT]! restore fault handler
	membar	#StoreStore|#StoreLoad
	retl
	 clr	%o0
	NOTREACHED

Lkcerr:
	stx	%g1, [%o5 + PCB_ONFAULT]! restore fault handler
	membar	#StoreStore|#StoreLoad
	retl				! and return error indicator
	 mov	EFAULT, %o0
	NOTREACHED

/*
 * bcopy(src, dest, size - overlaps detected and copied in reverse
 */
ENTRY(bcopy)
	/*
	 * Swap args and continue to memmove.
	 */
	mov	%o0, %o3
	mov	%o1, %o0
	mov	%o3, %o1
/*
 * memmove(dst, src, len) - overlaps detected and copied in reverse
 */
ENTRY(memmove)
	mov	%o0, %o5	! Save memcpy return value

	cmp	%o1, %o0	! src < dst?
	bgeu	Lmemcpy_start	! no, go copy forwards as via memcpy
	 cmp	%o2, BCOPY_SMALL! (check length for doublecopy first)

	/*
	 * Since src comes before dst, and the regions might overlap,
	 * we have to do the copy starting at the end and working backwards.
	 */
	add	%o2, %o1, %o1	! src += len
	add	%o2, %o0, %o0	! dst += len
	bge,a	Lback_fancy	! if len >= BCOPY_SMALL, go be fancy
	 btst	3, %o1

	/*
	 * Not much to copy, just do it a byte at a time.
	 */
	deccc	%o2		! while (--len >= 0)
	bl	1f
!	 XXX check no delay slot
0:
	dec	%o1		!	*--dst = *--src;
	ldsb	[%o1], %o4
	dec	%o0
	deccc	%o2
	bge	0b
	 stb	%o4, [%o0]
1:
	retl
	 mov	%o5, %o0
	NOTREACHED

	/*
	 * Plenty to copy, try to be optimal.
	 * We only bother with word/halfword/byte copies here.
	 */
Lback_fancy:
!	btst	3, %o1		! done already
	bnz	1f		! if ((src & 3) == 0 &&
	 btst	3, %o0		!     (dst & 3) == 0)
	bz,a	Lback_words	!	goto words;
	 dec	4, %o2		! (done early for word copy)

1:
	/*
	 * See if the low bits match.
	 */
	xor	%o1, %o0, %o3	! t = src ^ dst;
	btst	1, %o3
	bz,a	3f		! if (t & 1) == 0, can do better
	 btst	1, %o1

	/*
	 * Nope; gotta do byte copy.
	 */
2:
	dec	%o1		! do {
	ldsb	[%o1], %o4	!	*--dst = *--src;
	dec	%o0
	deccc	%o2		! } while (--len != 0);
	bnz	2b
	 stb	%o4, [%o0]
	retl
	 nop

3:
	/*
	 * Can do halfword or word copy, but might have to copy 1 byte first.
	 */
!	btst	1, %o1		! done earlier
	bz,a	4f		! if (src & 1) {	/* copy 1 byte */
	 btst	2, %o3		! (done early)
	dec	%o1		!	*--dst = *--src;
	ldsb	[%o1], %o4
	dec	%o0
	stb	%o4, [%o0]
	dec	%o2		!	len--;
	btst	2, %o3		! }

4:
	/*
	 * See if we can do a word copy ((t&2) == 0).
	 */
!	btst	2, %o3		! done earlier
	bz,a	6f		! if (t & 2) == 0, can do word copy
	 btst	2, %o1		! (src&2, done early)

	/*
	 * Gotta do halfword copy.
	 */
	dec	2, %o2		! len -= 2;
5:
	dec	2, %o1		! do {
	ldsh	[%o1], %o4	!	src -= 2;
	dec	2, %o0		!	dst -= 2;
	deccc	2, %o2		!	*(short *)dst = *(short *)src;
	bge	5b		! } while ((len -= 2) >= 0);
	 sth	%o4, [%o0]
	b	Lback_mopb	! goto mop_up_byte;
	 btst	1, %o2		! (len&1, done early)

6:
	/*
	 * We can do word copies, but we might have to copy
	 * one halfword first.
	 */
!	btst	2, %o1		! done already
	bz	7f		! if (src & 2) {
	 dec	4, %o2		! (len -= 4, done early)
	dec	2, %o1		!	src -= 2, dst -= 2;
	ldsh	[%o1], %o4	!	*(short *)dst = *(short *)src;
	dec	2, %o0
	sth	%o4, [%o0]
	dec	2, %o2		!	len -= 2;
				! }

7:
Lback_words:
	/*
	 * Do word copies (backwards), then mop up trailing halfword
	 * and byte if any.
	 */
!	dec	4, %o2		! len -= 4, done already
0:				! do {
	dec	4, %o1		!	src -= 4;
	dec	4, %o0		!	src -= 4;
	ld	[%o1], %o4	!	*(int *)dst = *(int *)src;
	deccc	4, %o2		! } while ((len -= 4) >= 0);
	bge	0b
	 st	%o4, [%o0]

	/*
	 * Check for trailing shortword.
	 */
	btst	2, %o2		! if (len & 2) {
	bz,a	1f
	 btst	1, %o2		! (len&1, done early)
	dec	2, %o1		!	src -= 2, dst -= 2;
	ldsh	[%o1], %o4	!	*(short *)dst = *(short *)src;
	dec	2, %o0
	sth	%o4, [%o0]	! }
	btst	1, %o2

	/*
	 * Check for trailing byte.
	 */
1:
Lback_mopb:
!	btst	1, %o2		! (done already)
	bnz,a	1f		! if (len & 1) {
	 ldsb	[%o1 - 1], %o4	!	b = src[-1];
	retl
	 mov	%o5, %o0
	NOTREACHED

1:
	stb	%o4, [%o0 - 1]	! }
	retl			!	dst[-1] = b;
	 mov	%o5, %o0
	NOTREACHED

/*
 * clearfpstate()
 *
 * Drops the current fpu state, without saving it.
 */
ENTRY(clearfpstate)
	rdpr	%pstate, %o1		! enable FPU
	wr	%g0, FPRS_FEF, %fprs
	or	%o1, PSTATE_PEF, %o1
	retl
	 wrpr	%o1, 0, %pstate

/*
 * savefpstate(struct fpstate *f)
 *
 * Store the current FPU state.
 *
 * Since the kernel may need to use the FPU and we have problems atomically
 * testing and enabling the FPU, we leave here with the FPRS_FEF bit set.
 * Normally this should be turned on in loadfpstate().
 */
 /* XXXXXXXXXX  Assume caller created a proper stack frame */
ENTRY(savefpstate)
	rdpr	%pstate, %o1		! enable FP before we begin
	rd	%fprs, %o5
	wr	%g0, FPRS_FEF, %fprs
	or	%o1, PSTATE_PEF, %o1
	wrpr	%o1, 0, %pstate

	stx	%fsr, [%o0 + FS_FSR]	! f->fs_fsr = getfsr();

	rd	%gsr, %o4		! Save %gsr
	st	%o4, [%o0 + FS_GSR]

	add	%o0, FS_REGS, %o2	! This is zero...
	btst	FPRS_DL, %o5		! Lower FPU clean?
	bz,a,pt	%icc, 1f		! Then skip it
	 add	%o2, 128, %o2		! Skip a block

	membar	#Sync
	stda	%f0, [%o2] ASI_BLK_P	! f->fs_f0 = etc;
	inc	BLOCK_SIZE, %o2
	stda	%f16, [%o2] ASI_BLK_P
	inc	BLOCK_SIZE, %o2
1:
	btst	FPRS_DU, %o5		! Upper FPU clean?
	bz,pt	%icc, 2f		! Then skip it
	 nop

	membar	#Sync
	stda	%f32, [%o2] ASI_BLK_P
	inc	BLOCK_SIZE, %o2
	stda	%f48, [%o2] ASI_BLK_P
2:
	membar	#Sync			! Finish operation so we can
	retl
	 wr	%g0, FPRS_FEF, %fprs	! Mark FPU clean

/*
 * Load FPU state.
 */
 /* XXXXXXXXXX  Should test to see if we only need to do a partial restore */
ENTRY(loadfpstate)
	rdpr	%pstate, %o1		! enable FP before we begin
	ld	[%o0 + FS_GSR], %o4	! Restore %gsr
	set	PSTATE_PEF, %o2
	wr	%g0, FPRS_FEF, %fprs
	or	%o1, %o2, %o1
	wrpr	%o1, 0, %pstate
	ldx	[%o0 + FS_FSR], %fsr	! setfsr(f->fs_fsr);
	add	%o0, FS_REGS, %o3	! This is zero...
	wr	%o4, %g0, %gsr
	membar	#Sync
	ldda	[%o3] ASI_BLK_P, %f0
	inc	BLOCK_SIZE, %o3
	ldda	[%o3] ASI_BLK_P, %f16
	inc	BLOCK_SIZE, %o3
	ldda	[%o3] ASI_BLK_P, %f32
	inc	BLOCK_SIZE, %o3
	ldda	[%o3] ASI_BLK_P, %f48
	membar	#Sync			! Make sure loads are complete
	retl
	 wr	%g0, FPRS_FEF, %fprs	! Clear dirty bits

/* XXX belongs elsewhere (ctlreg.h?) */
#define	AFSR_CECC_ERROR		0x100000	/* AFSR Correctable ECC err */
#define	DATAPATH_CE		0x100		/* Datapath Correctable Err */

	.data
	_ALIGN
	.globl	_C_LABEL(cecclast), _C_LABEL(ceccerrs)
_C_LABEL(cecclast):
	.xword 0
_C_LABEL(ceccerrs):
	.word 0
	_ALIGN
	.text

/*
 * ECC Correctable Error handler - this doesn't do much except intercept
 * the error and reset the status bits.
 */
ENTRY(cecc_catch)
	ldxa	[%g0] ASI_AFSR, %g1			! g1 = AFSR
	ldxa	[%g0] ASI_AFAR, %g2			! g2 = AFAR

	sethi	%hi(cecclast), %g1			! cecclast = AFAR
	or	%g1, %lo(cecclast), %g1
	stx	%g2, [%g1]

	sethi	%hi(ceccerrs), %g1			! get current count
	or	%g1, %lo(ceccerrs), %g1
	lduw	[%g1], %g2				! g2 = ceccerrs

	ldxa	[%g0] ASI_DATAPATH_ERR_REG_READ, %g3	! Read UDB-Low status
	andcc	%g3, DATAPATH_CE, %g4			! Check CE bit
	be,pn	%xcc, 1f				! Don't clear unless
	 nop						!  necessary
	stxa	%g4, [%g0] ASI_DATAPATH_ERR_REG_WRITE	! Clear CE bit in UDBL
	membar	#Sync					! sync store
	inc	%g2					! ceccerrs++
1:	mov	0x18, %g5
	ldxa	[%g5] ASI_DATAPATH_ERR_REG_READ, %g3	! Read UDB-High status
	andcc	%g3, DATAPATH_CE, %g4			! Check CE bit
	be,pn	%xcc, 1f				! Don't clear unless
	 nop						!  necessary
	stxa	%g4, [%g5] ASI_DATAPATH_ERR_REG_WRITE	! Clear CE bit in UDBH
	membar	#Sync					! sync store
	inc	%g2					! ceccerrs++
1:	set	AFSR_CECC_ERROR, %g3
	stxa	%g3, [%g0] ASI_AFSR			! Clear CE in AFSR
	stw	%g2, [%g1]				! set ceccerrs
	membar	#Sync					! sync store
        CLRTT
        retry
        NOTREACHED

/*
 * send_softint(cpu, level, intrhand)
 *
 * Send a softint with an intrhand pointer so we can cause a vectored
 * interrupt instead of a polled interrupt.  This does pretty much the
 * same as interrupt_vector.  If intrhand is NULL then it just sends
 * a polled interrupt.  If cpu is -1 then send it to this CPU, if it's
 * -2 send it to any CPU, otherwise send it to a particular CPU.
 *
 * XXXX Dispatching to different CPUs is not implemented yet.
 */
ENTRY(send_softint)
	rdpr	%pstate, %g1
	andn	%g1, PSTATE_IE, %o3
	wrpr	%o3, 0, %pstate

	brz,pn	%o2, 1f
	 add	%g7, CI_INTRPENDING, %o3

	ldx	[%o2 + IH_PEND], %o5
	brnz,pn	%o5, 1f
	 sll	%o1, 3+3, %o5	! Find start of table for this IPL
	add	%o3, %o5, %o3

	ldx	[%o3], %o5		! Load list head
	add	%o2, IH_PEND, %o4
	casxa	[%o4] ASI_N, %g0, %o5
	brnz,pn	%o5, 1f
	 nop
	stx	%o2, [%o3]

	mov	1, %o3			! Change from level to bitmask
	sllx	%o3, %o1, %o3
	wr	%o3, 0, SET_SOFTINT	! SET_SOFTINT
1:
	retl
	 wrpr	%g1, 0, %pstate		! restore interrupts

/*
 * Flush user windows to memory.
 */
ENTRY(write_user_windows)
	rdpr	%otherwin, %g1
	brz	%g1, 3f
	clr	%g2
1:
	save	%sp, -CC64FSZ, %sp
	rdpr	%otherwin, %g1
	brnz	%g1, 1b
	 inc	%g2
2:
	dec	%g2
	brnz	%g2, 2b
	 restore
3:
	retl
	 nop

/*
 * Clear the Nonpriviliged Trap (NPT( bit of %tick such that it can be
 * read from userland.  This requires us to read the current value and
 * write it back with the bit cleared.  As a result we will lose a
 * couple of ticks.  In order to limit the number of lost ticks, we
 * block interrupts and make sure the instructions to read and write
 * %tick live in the same cache line.  We tag on an extra read to work
 * around a Blackbird (UltraSPARC-II) errata (see below).
 */
ENTRY(tick_enable)
	rdpr	%pstate, %o0
	andn	%o0, PSTATE_IE, %o1
	wrpr	%o1, 0, %pstate		! disable interrupts
	rdpr	%tick, %o2
	brgez,pn %o2, 1f
	 clr	%o1
	mov	1, %o1
	sllx	%o1, 63, %o1
	ba,pt	%xcc, 1f
	 nop
	.align	64
1:	rdpr	%tick, %o2
	wrpr	%o2, %o1, %tick
	rdpr	%tick, %g0

	retl
	 wrpr	%o0, 0, %pstate		! restore interrupts

/*
 * On Blackbird (UltraSPARC-II) CPUs, writes to %tick_cmpr may fail.
 * The workaround is to do a read immediately after the write and make
 * sure those two instructions are in the same cache line.
 */
ENTRY(tickcmpr_set)
	ba	1f
	 mov	8, %o2			! Initial step size
	.align	64
1:	wr	%o0, 0, %tick_cmpr
	rd	%tick_cmpr, %g0

	rd	%tick, %o1		! Read current %tick
	sllx	%o1, 1, %o1
	srlx	%o1, 1, %o1

	cmp	%o0, %o1		! Make sure the value we wrote to
	bg,pt	%xcc, 2f		!   %tick_cmpr was in the future.
	 add	%o0, %o2, %o0		! If not, add the step size, double
	ba,pt	%xcc, 1b		!   the step size and try again.
	 sllx	%o2, 1, %o2
2:
	retl
	 nop

ENTRY(sys_tickcmpr_set)
	ba	1f
	 mov	8, %o2			! Initial step size
	.align	64
1:	wr	%o0, 0, %sys_tick_cmpr
	rd	%sys_tick_cmpr, %g0

	rd	%sys_tick, %o1		! Read current %sys_tick
	sllx	%o1, 1, %o1
	srlx	%o1, 1, %o1

	cmp	%o0, %o1		! Make sure the value we wrote to
	bg,pt	%xcc, 2f		!   %sys_tick_cmpr was in the future.
	 add	%o0, %o2, %o0		! If not, add the step size, double
	ba,pt	%xcc, 1b		!   the step size and try again.
	 sllx	%o2, 1, %o2
2:
	retl
	 nop

/*
 * Support for the STICK logic found on the integrated PCI host bridge
 * of Hummingbird (UltraSPARC-IIe).  The chip designers made the
 * brilliant decision to split the 64-bit counters into two 64-bit
 * aligned 32-bit registers, making atomic access impossible.  This
 * means we have to check for wraparound in various places.  Sigh.
 */

#define STICK_CMP_LOW	0x1fe0000f060
#define STICK_CMP_HIGH	0x1fe0000f068
#define STICK_REG_LOW	0x1fe0000f070
#define STICK_REG_HIGH	0x1fe0000f078

ENTRY(stick)
	setx	STICK_REG_LOW, %o1, %o3
0:
	ldxa	[%o3] ASI_PHYS_NON_CACHED, %o0
	add	%o3, (STICK_REG_HIGH - STICK_REG_LOW), %o4
	ldxa	[%o4] ASI_PHYS_NON_CACHED, %o1
	ldxa	[%o3] ASI_PHYS_NON_CACHED, %o2
	cmp	%o2, %o0		! Check for wraparound
	blu,pn	%icc, 0b
	 sllx	%o1, 33, %o1		! Clear the MSB
	srlx	%o1, 1, %o1
	retl
	 or	%o2, %o1, %o0

ENTRY(stickcmpr_set)
	setx	STICK_CMP_HIGH, %o1, %o3
	mov	8, %o2			! Initial step size
1:
	srlx	%o0, 32, %o1
	stxa	%o1, [%o3] ASI_PHYS_NON_CACHED
	add	%o3, (STICK_CMP_LOW - STICK_CMP_HIGH), %o4
	stxa	%o0, [%o4] ASI_PHYS_NON_CACHED

	add	%o3, (STICK_REG_LOW - STICK_CMP_HIGH), %o4
	ldxa	[%o4] ASI_PHYS_NON_CACHED, %o1
	add	%o3, (STICK_REG_HIGH - STICK_CMP_HIGH), %o4
	ldxa	[%o4] ASI_PHYS_NON_CACHED, %o5
	sllx	%o5, 32, %o5
	or	%o1, %o5, %o1

	cmp	%o0, %o1		! Make sure the value we wrote
	bg,pt	%xcc, 2f		!   was in the future
	 add	%o0, %o2, %o0		! If not, add the step size, double
	ba,pt	%xcc, 1b		!   the step size and try again.
	 sllx	%o2, 1, %o2
2:
	retl
	 nop

#define MICROPERSEC	(1000000)
	.data
	.align	16
	.globl	_C_LABEL(cpu_clockrate)
_C_LABEL(cpu_clockrate):
	!! Pretend we have a 200MHz clock -- cpu_attach will fix this
	.xword	200000000
	!! Here we'll store cpu_clockrate/1000000 so we can calculate usecs
	.xword	0
	.text

/*
 * delay function
 *
 * void delay(N)  -- delay N microseconds
 *
 * Register usage: %o0 = "N" number of usecs to go (counts down to zero)
 *		   %o1 = "timerblurb" (stays constant)
 *		   %o2 = counter for 1 usec (counts down from %o1 to zero)
 *
 *
 *	cpu_clockrate should be tuned during CPU probe to the CPU clockrate in Hz
 *
 */
ENTRY(delay)			! %o0 = n
	rdpr	%tick, %o1					! Take timer snapshot
	sethi	%hi(_C_LABEL(cpu_clockrate)), %o2
	sethi	%hi(MICROPERSEC), %o3
	ldx	[%o2 + %lo(_C_LABEL(cpu_clockrate) + 8)], %o4	! Get scale factor
	brnz,pt	%o4, 0f
	 or	%o3, %lo(MICROPERSEC), %o3

	!! Calculate ticks/usec
	ldx	[%o2 + %lo(_C_LABEL(cpu_clockrate))], %o4	! No, we need to calculate it
	udivx	%o4, %o3, %o4
	stx	%o4, [%o2 + %lo(_C_LABEL(cpu_clockrate) + 8)]	! Save it so we don't need to divide again
0:

	mulx	%o0, %o4, %o0					! Convert usec -> ticks
	rdpr	%tick, %o2					! Top of next itr
1:
	sub	%o2, %o1, %o3					! How many ticks have gone by?
	sub	%o0, %o3, %o4					! Decrement count by that much
	movrgz	%o3, %o4, %o0					! But only if we're decrementing
	mov	%o2, %o1					! Remember last tick
	brgz,pt	%o0, 1b						! Done?
	 rdpr	%tick, %o2					! Get new tick

	retl
	 nop

ENTRY(setjmp)
	save	%sp, -CC64FSZ, %sp	! Need a frame to return to.
	flushw
	stx	%fp, [%i0+0]	! 64-bit stack pointer
	stx	%i7, [%i0+8]	! 64-bit return pc
	ret
	 restore	%g0, 0, %o0

ENTRY(longjmp)
	save	%sp, -CC64FSZ, %sp	! prepare to restore to (old) frame
	flushw
	mov	1, %i2
	ldx	[%i0+0], %fp	! get return stack
	ldx	[%i0+8], %i7	! get rpc
	ret
	 restore	%i2, 0, %o0

#ifdef DDB
	/*
	 * Debug stuff.  Dump the trap registers into buffer & set tl=0.
	 *
	 *  %o0 = *ts
	 */
	ENTRY(savetstate)
	mov	%o0, %o1
	CHKPT %o4,%o3,0x28
	rdpr	%tl, %o0
	brz	%o0, 2f
	 mov	%o0, %o2
1:
	rdpr	%tstate, %o3
	stx	%o3, [%o1]
	deccc	%o2
	inc	8, %o1
	rdpr	%tpc, %o4
	stx	%o4, [%o1]
	inc	8, %o1
	rdpr	%tnpc, %o5
	stx	%o5, [%o1]
	inc	8, %o1
	rdpr	%tt, %o4
	stx	%o4, [%o1]
	inc	8, %o1
	bnz	1b
	 wrpr	%o2, 0, %tl
2:
	retl
	 nop

	/*
	 * Debug stuff.  Resore trap registers from buffer.
	 *
	 *  %o0 = %tl
	 *  %o1 = *ts
	 *
	 * Maybe this should be re-written to increment tl instead of decrementing.
	 */
	ENTRY(restoretstate)
	CHKPT %o4,%o3,0x36
	flushw			! Make sure we don't have stack probs & lose hibits of %o
	brz,pn	%o0, 2f
	 mov	%o0, %o2
	CHKPT %o4,%o3,0x29
	wrpr	%o0, 0, %tl
1:
	ldx	[%o1], %o3
	deccc	%o2
	inc	8, %o1
	wrpr	%o3, 0, %tstate
	ldx	[%o1], %o4
	inc	8, %o1
	wrpr	%o4, 0, %tpc
	ldx	[%o1], %o5
	inc	8, %o1
	wrpr	%o5, 0, %tnpc
	ldx	[%o1], %o4
	inc	8, %o1
	wrpr	%o4, 0, %tt
	bnz	1b
	 wrpr	%o2, 0, %tl
2:
	CHKPT %o4,%o3,0x30
	retl
	 wrpr	%o0, 0, %tl

	/*
	 * Switch to context in %o0
	 */
	ENTRY(switchtoctx)
	set	DEMAP_CTX_SECONDARY, %o3
	stxa	%o3, [%o3] ASI_DMMU_DEMAP
	membar	#Sync
	mov	CTX_SECONDARY, %o4
	stxa	%o3, [%o3] ASI_IMMU_DEMAP
	membar	#Sync
	stxa	%o0, [%o4] ASI_DMMU		! Maybe we should invalidate the old context?
	membar	#Sync				! No real reason for this XXXX
	sethi	%hi(KERNBASE), %o2
	flush	%o2
	retl
	 nop

#endif /* DDB */	/* DDB */

	.data
	_ALIGN
#if defined(DDB) || NKSYMS > 0
	.globl	_C_LABEL(esym)
_C_LABEL(esym):
	.xword	0
	.globl	_C_LABEL(ssym)
_C_LABEL(ssym):
	.xword	0
#endif	/* defined(DDB) || NKSYMS > 0 */
	.globl	_C_LABEL(proc0paddr)
_C_LABEL(proc0paddr):
	.xword	_C_LABEL(u0)		! KVA of proc0 uarea

#ifdef DEBUG
	.comm	_C_LABEL(trapdebug), 4
	.comm	_C_LABEL(pmapdebug), 4
#endif	/* DEBUG */

	.globl	_C_LABEL(dlflush_start)
_C_LABEL(dlflush_start):
	.xword	dlflush1
	.xword	dlflush2
	.xword	dlflush3
	.xword	dlflush4
	.xword	dlflush5
	.xword	0
@


1.185
log
@Rename Debugger() into db_enter().

Using a name with the 'db_' prefix makes it invisible from the dynamic
profiler.

ok deraadt@@, kettenis@@, visa@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.184 2016/10/18 00:43:57 guenther Exp $	*/
d5970 15
@


1.184
log
@Delete remnants of "traptrace" support

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.183 2016/05/23 20:11:49 deraadt Exp $	*/
d86 1
a86 1
#define Debugger()	ta	1; nop
d2885 1
a2885 1
	Debugger()
d3277 1
a3277 1
	Debugger()
d3861 1
a3861 1
	Debugger()
@


1.183
log
@Place a cpu-dependent trap/illegal instruction over the remainder of the
sigtramp page, so that it will generate a nice kernel fault if touched.
While here, move most of the sigtramps to the .rodata segment, because
they are not executed in the kernel.
Also some preparation for sliding the actual sigtramp forward (will need
some gdb changes)
ok mlarkin kettenis
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.182 2016/05/10 18:39:49 deraadt Exp $	*/
a1346 15

#define TRACESIZ	0x01000
	.globl	_C_LABEL(trap_trace)
	.globl	_C_LABEL(trap_trace_ptr)
	.globl	_C_LABEL(trap_trace_end)
	.globl	_C_LABEL(trap_trace_dis)
	.data
_C_LABEL(trap_trace_dis):
	.word	1, 1		! Starts disabled.  DDB turns it on.
_C_LABEL(trap_trace_ptr):
	.word	0, 0, 0, 0
_C_LABEL(trap_trace):
	.space	TRACESIZ
_C_LABEL(trap_trace_end):
	.space	0x20		! safety margin
@


1.182
log
@SROP mitigation.  sendsig() stores a (per-process ^ &sigcontext) cookie
inside the sigcontext.  sigreturn(2) checks syscall entry was from the
exact PC addr in the (per-process ASLR) sigtramp, verifies the cookie,
and clears it to prevent sigcontext reuse.
not yet tested on landisk, sparc, *88k, socppc.
ok kettenis
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.181 2015/08/28 23:28:39 kettenis Exp $	*/
d5341 1
a5342 1
	.globl	_C_LABEL(esigcode)
d5438 1
d5441 10
@


1.181
log
@Add support for switching CPUs in ddb on sparc64.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.180 2015/06/24 18:41:58 miod Exp $	*/
d5432 2
@


1.180
log
@fauls -> faults
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.179 2014/11/30 22:26:14 kettenis Exp $	*/
d4189 5
@


1.179
log
@SPARC T4 and later have a pause instruction to voluntarily pause a virtual
processor in order to give other strands a chance to run.  Use it in
__mp_lock_spin_hook() to avoid wasting CPU cycles if we're waiting for
the kernel or scheduler locks.  This is instruction is patched in, just like
we already do for the sleep instruction on SPARC64 VI processors.  We look
at the hwcap-list property of the cpu nodes in the machine description to
decide whether the pause instruction is available.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.178 2014/11/24 10:55:49 kettenis Exp $	*/
d6897 1
a6897 1
	membar	#Sync		! Make sure all fauls are processed
@


1.178
log
@On sun4v, interpret the first data word of a device interrupt message as a
pointer to "struct intrhand" if it is larger than MAXINTNUM.  To be used
with the cookie based "vintr" scheme.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.177 2014/11/20 08:47:00 kettenis Exp $	*/
d107 10
@


1.177
log
@Don't attempt to clear/disable %tick_cmpr.  This register is no longer present
on newer sun4v implementations (possibly SPARC T3 and later, definitely not
there on SPARC T5) and it should not be necessary on older systems.

Tested by dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.176 2014/11/20 07:50:45 deraadt Exp $	*/
d4001 1
a4001 1
	ldxa	[%g3 + %g2] ASI_PHYS_CACHED, %g4
d4007 3
a4009 2
	and	%g4, 0x7ff, %g4
	sllx	%g4, 3, %g5
d4013 1
d4015 1
a4015 1

@


1.176
log
@Disentagle bcopy/memcpy/memmove.

The situation was:  memcpy swaps registers and drops into bcopy, which does
the overlap check, before getting around to business.  But memcpy is not
supposed to handle overlapped arguments special, so we don't need all this
complex register swapping and tests up front -- when memcpy is the most
common operation.  Refactor all these upside downupside down.

Survived multiple make builds, so probably good, and faster.
ok dlg
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.175 2013/06/15 10:05:58 kettenis Exp $	*/
a4735 3
	mov	1, %g1
	sllx	%g1, 63, %g1
	wr	%g1, TICK_CMPR	! Clear and disable %tick_cmpr
@


1.175
log
@Stop handling overlapping copies in memcpy() by jumping straight into the
forward copy path.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.174 2013/06/13 20:03:59 kettenis Exp $	*/
d6422 1
a6422 2
 * kernel bcopy/memcpy
 * Assumes regions do not overlap; has no useful return value.
d6427 2
a6428 22
	/*
	 * Swap args for bcopy.  Gcc generates calls to memcpy for
	 * structure assignments.
	 */
	mov	%o0, %o3
	mov	%o1, %o0
	mov	%o3, %o1
	ba,pt	%xcc, Lbcopy_start
	 cmp	%o2, BCOPY_SMALL
ENTRY(bcopy) /* src, dest, size */
	/*
	 * Check for overlaps and punt.
	 *
	 * If src <= dest <= src+len we have a problem.
	 */

	sub	%o1, %o0, %o3

	cmp	%o3, %o2
	blu,pn	%xcc, Lovbcopy
	 cmp	%o2, BCOPY_SMALL
Lbcopy_start:
d6432 1
a6432 1
	mov	%o1, %o5	! Save memcpy return value
d6440 3
a6442 3
	inc	%o0
	ldsb	[%o0 - 1], %o4	!	(++dst)[-1] = *src++;
	stb	%o4, [%o1]
d6445 1
a6445 1
	 inc	%o1
a6451 30
	 * Overlapping bcopies -- punt.
	 */
Lovbcopy:

	/*
	 * Since src comes before dst, and the regions might overlap,
	 * we have to do the copy starting at the end and working backwards.
	 *
	 * We could optimize this, but it almost never happens.
	 */
	mov	%o1, %o5	! Retval
	add	%o2, %o0, %o0	! src += len
	add	%o2, %o1, %o1	! dst += len
	
	deccc	%o2
	bl,pn	%xcc, 1f
	 dec	%o0
0:
	dec	%o1
	ldsb	[%o0], %o4
	dec	%o0
	
	deccc	%o2
	bge,pt	%xcc, 0b
	 stb	%o4, [%o1]
1:
	retl
	 mov	%o5, %o0

	/*
d6463 2
a6464 2
	mov	%i0, %l0
	mov	%i1, %l1
d6777 1
a6777 1
	 restore %i1, %g0, %o0
a6792 1
 *
d7060 4
a7063 1
ENTRY(memmove) /* dest, src, size */
d7065 1
a7065 1
	 * Swap args and continue to ovbcopy.
d7071 1
a7071 1
 * ovbcopy(src, dst, len): like bcopy, but regions may overlap.
d7073 5
a7077 3
ENTRY(ovbcopy)
	cmp	%o0, %o1	! src < dst?
	bgeu	Lbcopy_start	! no, go copy forwards as via bcopy
d7084 2
a7085 2
	add	%o2, %o0, %o0	! src += len
	add	%o2, %o1, %o1	! dst += len
d7087 1
a7087 1
	 btst	3, %o0
d7096 3
a7098 3
	dec	%o0		!	*--dst = *--src;
	ldsb	[%o0], %o4
	dec	%o1
d7101 1
a7101 1
	 stb	%o4, [%o1]
d7104 2
a7105 1
	 nop
d7112 1
a7112 1
!	btst	3, %o0		! done already
d7114 1
a7114 1
	 btst	3, %o1		!     (dst & 3) == 0)
d7122 1
a7122 1
	xor	%o0, %o1, %o3	! t = src ^ dst;
d7125 1
a7125 1
	 btst	1, %o0
d7131 3
a7133 3
	dec	%o0		! do {
	ldsb	[%o0], %o4	!	*--dst = *--src;
	dec	%o1
d7136 1
a7136 1
	 stb	%o4, [%o1]
d7144 1
a7144 1
!	btst	1, %o0		! done earlier
d7147 4
a7150 4
	dec	%o0		!	*--dst = *--src;
	ldsb	[%o0], %o4
	dec	%o1
	stb	%o4, [%o1]
d7160 1
a7160 1
	 btst	2, %o0		! (src&2, done early)
d7167 3
a7169 3
	dec	2, %o0		! do {
	ldsh	[%o0], %o4	!	src -= 2;
	dec	2, %o1		!	dst -= 2;
d7172 1
a7172 1
	 sth	%o4, [%o1]
d7181 1
a7181 1
!	btst	2, %o0		! done already
d7184 4
a7187 4
	dec	2, %o0		!	src -= 2, dst -= 2;
	ldsh	[%o0], %o4	!	*(short *)dst = *(short *)src;
	dec	2, %o1
	sth	%o4, [%o1]
d7199 1
d7201 1
a7201 2
	dec	4, %o1		!	src -= 4;
	ld	[%o0], %o4	!	*(int *)dst = *(int *)src;
d7204 1
a7204 1
	 st	%o4, [%o1]
d7212 4
a7215 4
	dec	2, %o0		!	src -= 2, dst -= 2;
	ldsh	[%o0], %o4	!	*(short *)dst = *(short *)src;
	dec	2, %o1
	sth	%o4, [%o1]	! }
d7225 1
a7225 1
	 ldsb	[%o0 - 1], %o4	!	b = src[-1];
d7227 3
a7229 1
	 nop
d7231 1
d7233 2
a7234 2
	 stb	%o4, [%o1 - 1]	! }

@


1.174
log
@Remove a remnant of the VIS optimized bcopy code that was hiding in a delay
slot.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.173 2013/06/13 19:33:04 kettenis Exp $	*/
a6420 1
#if 1
d6435 2
a6436 1
#endif	/* 1 */
@


1.173
log
@Get rid of the VIS-optimized bcopy/bzero code.  This has never been enabled,
but did get compiled in.  Made locore.s even more intimidating.

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.172 2013/06/13 19:11:13 kettenis Exp $	*/
d6451 1
a6451 1
	 cmp	%o2, 256
@


1.172
log
@Remove some disabled debugging code that hasn't been used for ages.
No binary change.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.171 2013/06/09 12:42:22 tedu Exp $	*/
a302 63
/*
 * The following routines allow fpu use in the kernel.
 *
 * They allocate a stack frame and use all local regs.  Extra
 * local storage can be requested by setting the siz parameter,
 * and can be accessed at %sp+CC64FSZ.
 */

	.macro ENABLE_FPU siz
	save	%sp, -(CC64FSZ), %sp;		! Allocate a stack frame
	GET_CPUINFO_VA(%l1);
	add	%fp, BIAS-FS_SIZE, %l0;		! Allocate a fpstate
	ldx	[%l1 + CI_FPPROC], %l2;		! Load fpproc
	andn	%l0, BLOCK_SIZE, %l0;		! Align it
	clr	%l3;				! NULL fpstate
	brz,pt	%l2, 1f;			! fpproc == NULL?
	 add	%l0, -BIAS-CC64FSZ-(\siz), %sp;	! Set proper %sp
	ldx	[%l2 + P_FPSTATE], %l3;
	brz,pn	%l3, 1f;			! Make sure we have an fpstate
	 mov	%l3, %o0;
	call	_C_LABEL(savefpstate);		! Save the old fpstate
1:
	 set	EINTSTACK-BIAS, %l4;		! Are we on intr stack?
	cmp	%sp, %l4;
	bgu,pt	%xcc, 1f;
	 set	INTSTACK-BIAS, %l4;
	cmp	%sp, %l4;
	blu	%xcc, 1f;
0:
	 sethi	%hi(_C_LABEL(proc0)), %l4;	! Yes, use proc0
	ba,pt	%xcc, 2f;			! XXXX needs to change to CPUs idle proc
	 or	%l4, %lo(_C_LABEL(proc0)), %l5;
1:
	GET_CURPROC(%l5);			! Use curproc
	brz,pn	%l5, 0b; nop;			! If curproc is NULL need to use proc0
2:
	ldx	[%l5 + P_FPSTATE], %l6;		! Save old fpstate
	stx	%l0, [%l5 + P_FPSTATE];		! Insert new fpstate
	stx	%l5, [%l1 + CI_FPPROC];		! Set new fpproc
	wr	%g0, FPRS_FEF, %fprs		! Enable FPU
	.endm

/*
 * We've saved our possible fpstate, now disable the fpu
 * and continue with life.
 */

	.macro RESTORE_FPU
#ifdef DEBUG
	ldx	[%l5 + P_FPSTATE], %l7
	cmp	%l7, %l0
	tnz	1
#endif	/* DEBUG */
	stx	%l2, [%l1 + CI_FPPROC]		! Restore old fproc
	wr	%g0, 0, %fprs			! Disable fpu
	brz,pt	%l3, 1f				! Skip if no fpstate
	 stx	%l6, [%l5 + P_FPSTATE]		! Restore old fpstate

	call	_C_LABEL(loadfpstate)		! Reload orig fpstate
	 mov	%l3, %o0
1:
	.endm
	
a6420 16
/*
 * Use block_disable to turn off block instructions for
 * bcopy/memset
 */
	.data
	.align	8
	.globl	block_disable
block_disable:	.xword	1
	.text

#if 0
#define ASI_STORE	ASI_BLK_COMMIT_P
#else	/* 0 */
#define ASI_STORE	ASI_BLK_P
#endif	/* 0 */
	
a6505 5
#if 0
	! If it is big enough, use VIS instructions
	bge	Lbcopy_block
	 nop
#endif	/* 0 */
a6828 878

#if 1

/*
 * Block copy.  Useful for >256 byte copies.
 *
 * Benchmarking has shown this always seems to be slower than
 * the integer version, so this is disabled.  Maybe someone will
 * figure out why sometime.
 */
	
Lbcopy_block:
	sethi	%hi(block_disable), %o3
	ldx	[ %o3 + %lo(block_disable) ], %o3
	brnz,pn	%o3, Lbcopy_fancy
	!! Make sure our trap table is installed
	set	_C_LABEL(trapbase), %o5
	rdpr	%tba, %o3
	sub	%o3, %o5, %o3
	brnz,pn	%o3, Lbcopy_fancy	! No, then don't use block load/store
	 nop
#ifdef _KERNEL
/*
 * Kernel:
 *
 * Here we use VIS instructions to do a block clear of a page.
 * But before we can do that we need to save and enable the FPU.
 * The last owner of the FPU registers is fpproc, and
 * fpproc->p_md.md_fpstate is the current fpstate.  If that's not
 * null, call savefpstate() with it to store our current fp state.
 *
 * Next, allocate an aligned fpstate on the stack.  We will properly
 * nest calls on a particular stack so this should not be a problem.
 *
 * Now we grab either curproc (or if we're on the interrupt stack
 * proc0).  We stash its existing fpstate in a local register and
 * put our new fpstate in curproc->p_md.md_fpstate.  We point
 * fpproc at curproc (or proc0) and enable the FPU.
 *
 * If we are ever preempted, our FPU state will be saved in our
 * fpstate.  Then, when we're resumed and we take an FPDISABLED
 * trap, the trap handler will be able to fish our FPU state out
 * of curproc (or proc0).
 *
 * On exiting this routine we undo the damage: restore the original
 * pointer to curproc->p_md.md_fpstate, clear our fpproc, and disable
 * the MMU.
 *
 *
 * Register usage, Kernel only (after save):
 *
 * %i0		src
 * %i1		dest
 * %i2		size
 *
 * %l0		XXXX DEBUG old fpstate
 * %l1		fpproc (hi bits only)
 * %l2		orig fpproc
 * %l3		orig fpstate
 * %l5		curproc
 * %l6		old fpstate
 *
 * Register ussage, Kernel and user:
 *
 * %g1		src (retval for memcpy)
 *
 * %o0		src
 * %o1		dest
 * %o2		end dest
 * %o5		last safe fetchable address
 */

	ENABLE_FPU 0
	mov	%i0, %o0				! Src addr.
	mov	%i1, %o1				! Store our dest ptr here.
	mov	%i2, %o2				! Len counter
#endif	/* _KERNEL */

	!!
	!! First align the output to a 64-bit entity
	!! 

	mov	%o1, %g1				! memcpy retval
	add	%o0, %o2, %o5				! End of source block

	andn	%o0, 7, %o3				! Start of block
	dec	%o5
	fzero	%f0

	andn	%o5, BLOCK_ALIGN, %o5			! Last safe addr.
	ldd	[%o3], %f2				! Load 1st word

	dec	8, %o3					! Move %o3 1 word back
	btst	1, %o1
	bz	4f
	
	 mov	-7, %o4					! Lowest src addr possible
	alignaddr %o0, %o4, %o4				! Base addr for load.

	cmp	%o3, %o4
	be,pt	%xcc, 1f				! Already loaded?
	 mov	%o4, %o3
	fmovd	%f2, %f0				! No. Shift
	ldd	[%o3+8], %f2				! And load
1:	

	faligndata	%f0, %f2, %f4			! Isolate 1st byte

	stda	%f4, [%o1] ASI_FL8_P			! Store 1st byte
	inc	1, %o1					! Update address
	inc	1, %o0
	dec	1, %o2
4:	
	btst	2, %o1
	bz	4f

	 mov	-6, %o4					! Calculate src - 6
	alignaddr %o0, %o4, %o4				! calculate shift mask and dest.

	cmp	%o3, %o4				! Addresses same?
	be,pt	%xcc, 1f
	 mov	%o4, %o3
	fmovd	%f2, %f0				! Shuffle data
	ldd	[%o3+8], %f2				! Load word 0
1:	
	faligndata %f0, %f2, %f4			! Move 1st short low part of f8

	stda	%f4, [%o1] ASI_FL16_P			! Store 1st short
	dec	2, %o2
	inc	2, %o1
	inc	2, %o0
4:
	brz,pn	%o2, Lbcopy_blockfinish			! XXXX

	 btst	4, %o1
	bz	4f

	mov	-4, %o4
	alignaddr %o0, %o4, %o4				! calculate shift mask and dest.

	cmp	%o3, %o4				! Addresses same?
	beq,pt	%xcc, 1f
	 mov	%o4, %o3
	fmovd	%f2, %f0				! Shuffle data
	ldd	[%o3+8], %f2				! Load word 0
1:	
	faligndata %f0, %f2, %f4			! Move 1st short low part of f8

	st	%f5, [%o1]				! Store word
	dec	4, %o2
	inc	4, %o1
	inc	4, %o0
4:
	brz,pn	%o2, Lbcopy_blockfinish			! XXXX
	!!
	!! We are now 32-bit aligned in the dest.
	!!
Lbcopy_block_common:	

	 mov	-0, %o4
	alignaddr %o0, %o4, %o4				! base - shift

	cmp	%o3, %o4				! Addresses same?
	beq,pt	%xcc, 1f
	 mov	%o4, %o3
	fmovd	%f2, %f0				! Shuffle data
	ldd	[%o3+8], %f2				! Load word 0
1:	
	add	%o3, 8, %o0				! now use %o0 for src
	
	!!
	!! Continue until our dest is block aligned
	!! 
Lbcopy_block_aligned8:	
1:
	brz	%o2, Lbcopy_blockfinish
	 btst	BLOCK_ALIGN, %o1			! Block aligned?
	bz	1f
	
	 faligndata %f0, %f2, %f4			! Generate result
	deccc	8, %o2
	ble,pn	%icc, Lbcopy_blockfinish		! Should never happen
	 fmovd	%f4, %f48
	
	std	%f4, [%o1]				! Store result
	inc	8, %o1
	
	fmovd	%f2, %f0
	inc	8, %o0
	ba,pt	%xcc, 1b				! Not yet.
	 ldd	[%o0], %f2				! Load next part
Lbcopy_block_aligned64:	
1:

/*
 * 64-byte aligned -- ready for block operations.
 *
 * Here we have the destination block aligned, but the
 * source pointer may not be.  Sub-word alignment will
 * be handled by faligndata instructions.  But the source
 * can still be potentially aligned to 8 different words
 * in our 64-bit block, so we have 8 different copy routines.
 *
 * Once we figure out our source alignment, we branch
 * to the appropriate copy routine, which sets up the
 * alignment for faligndata and loads (sets) the values
 * into the source registers and does the copy loop.
 *
 * When were down to less than 1 block to store, we
 * exit the copy loop and execute cleanup code.
 *
 * Block loads and stores are not properly interlocked.
 * Stores save one reg/cycle, so you can start overwriting
 * registers the cycle after the store is issued.  
 * 
 * Block loads require a block load to a different register
 * block or a membar #Sync before accessing the loaded
 * data.
 *	
 * Since the faligndata instructions may be offset as far
 * as 7 registers into a block (if you are shifting source 
 * 7 -> dest 0), you need 3 source register blocks for full 
 * performance: one you are copying, one you are loading, 
 * and one for interlocking.  Otherwise, we would need to
 * sprinkle the code with membar #Sync and lose the advantage
 * of running faligndata in parallel with block stores.  This 
 * means we are fetching a full 128 bytes ahead of the stores.  
 * We need to make sure the prefetch does not inadvertently 
 * cross a page boundary and fault on data that we will never 
 * store.
 *
 */
#if 1
	and	%o0, BLOCK_ALIGN, %o3
	srax	%o3, 3, %o3				! Isolate the offset

	brz	%o3, L100				! 0->0
	 btst	4, %o3
	bnz	%xcc, 4f
	 btst	2, %o3
	bnz	%xcc, 2f
	 btst	1, %o3
	ba,pt	%xcc, L101				! 0->1
	 nop	/* XXX spitfire bug */
2:
	bz	%xcc, L102				! 0->2
	 nop
	ba,pt	%xcc, L103				! 0->3
	 nop	/* XXX spitfire bug */
4:	
	bnz	%xcc, 2f
	 btst	1, %o3
	bz	%xcc, L104				! 0->4
	 nop
	ba,pt	%xcc, L105				! 0->5
	 nop	/* XXX spitfire bug */
2:
	bz	%xcc, L106				! 0->6
	 nop
	ba,pt	%xcc, L107				! 0->7
	 nop	/* XXX spitfire bug */
#else	/* 1 */

	!!
	!! Isolate the word offset, which just happens to be
	!! the slot in our jump table.
	!!
	!! This is 6 instructions, most of which cannot be paired,
	!! which is about the same as the above version.
	!!
	rd	%pc, %o4
1:	
	and	%o0, 0x31, %o3
	add	%o3, (Lbcopy_block_jmp - 1b), %o3
	jmpl	%o4 + %o3, %g0
	 nop

	!!
	!! Jump table
	!!
	
Lbcopy_block_jmp:
	ba,a,pt	%xcc, L100
	 nop
	ba,a,pt	%xcc, L101
	 nop
	ba,a,pt	%xcc, L102
	 nop
	ba,a,pt	%xcc, L103
	 nop
	ba,a,pt	%xcc, L104
	 nop
	ba,a,pt	%xcc, L105
	 nop
	ba,a,pt	%xcc, L106
	 nop
	ba,a,pt	%xcc, L107
	 nop
#endif	/* 1 */

	!!
	!! Source is block aligned.
	!!
	!! Just load a block and go.
	!!
L100:
#ifdef RETURN_NAME
	sethi	%hi(1f), %g1
	ba,pt	%icc, 2f
	 or	%g1, %lo(1f), %g1
1:	
	.asciz	"L100"
	.align	8
2:	
#endif	/* RETURN_NAME */
	fmovd	%f0 , %f62
	ldda	[%o0] ASI_BLK_P, %f0
	inc	BLOCK_SIZE, %o0
	cmp	%o0, %o5
	bleu,a,pn	%icc, 3f
	 ldda	[%o0] ASI_BLK_P, %f16
	ba,pt	%icc, 3f
	 membar #Sync
	
	.align	32					! ICache align.
3:
	faligndata	%f62, %f0, %f32
	inc	BLOCK_SIZE, %o0
	faligndata	%f0, %f2, %f34
	dec	BLOCK_SIZE, %o2
	faligndata	%f2, %f4, %f36
	cmp	%o0, %o5
	faligndata	%f4, %f6, %f38
	faligndata	%f6, %f8, %f40
	faligndata	%f8, %f10, %f42
	faligndata	%f10, %f12, %f44
	brlez,pn	%o2, Lbcopy_blockdone
	 faligndata	%f12, %f14, %f46
	
	bleu,a,pn	%icc, 2f
	 ldda	[%o0] ASI_BLK_P, %f48
	membar	#Sync
2:	
	stda	%f32, [%o1] ASI_STORE
	faligndata	%f14, %f16, %f32
	inc	BLOCK_SIZE, %o0
	faligndata	%f16, %f18, %f34
	inc	BLOCK_SIZE, %o1
	faligndata	%f18, %f20, %f36
	dec	BLOCK_SIZE, %o2
	faligndata	%f20, %f22, %f38
	cmp	%o0, %o5
	faligndata	%f22, %f24, %f40
	faligndata	%f24, %f26, %f42
	faligndata	%f26, %f28, %f44
	brlez,pn	%o2, Lbcopy_blockdone
	 faligndata	%f28, %f30, %f46
	
	bleu,a,pn	%icc, 2f
	 ldda	[%o0] ASI_BLK_P, %f0
	membar	#Sync
2:
	stda	%f32, [%o1] ASI_STORE
	faligndata	%f30, %f48, %f32
	inc	BLOCK_SIZE, %o0
	faligndata	%f48, %f50, %f34
	inc	BLOCK_SIZE, %o1
	faligndata	%f50, %f52, %f36
	dec	BLOCK_SIZE, %o2
	faligndata	%f52, %f54, %f38
	cmp	%o0, %o5
	faligndata	%f54, %f56, %f40
	faligndata	%f56, %f58, %f42
	faligndata	%f58, %f60, %f44
	brlez,pn	%o2, Lbcopy_blockdone
	 faligndata	%f60, %f62, %f46
	bleu,a,pn	%icc, 2f
	 ldda	[%o0] ASI_BLK_P, %f16			! Increment is at top
	membar	#Sync
2:	
	stda	%f32, [%o1] ASI_STORE
	ba	3b
	 inc	BLOCK_SIZE, %o1
	
	!!
	!! Source at BLOCK_ALIGN+8
	!!
	!! We need to load almost 1 complete block by hand.
	!! 
L101:
#ifdef RETURN_NAME
	sethi	%hi(1f), %g1
	ba,pt	%icc, 2f
	 or	%g1, %lo(1f), %g1
1:	
	.asciz	"L101"
	.align	8
2:	
#endif	/* RETURN_NAME */
!	fmovd	%f0, %f0				! Hoist fmovd
	ldd	[%o0], %f2
	inc	8, %o0
	ldd	[%o0], %f4
	inc	8, %o0
	ldd	[%o0], %f6
	inc	8, %o0
	ldd	[%o0], %f8
	inc	8, %o0
	ldd	[%o0], %f10
	inc	8, %o0
	ldd	[%o0], %f12
	inc	8, %o0
	ldd	[%o0], %f14
	inc	8, %o0
	
	cmp	%o0, %o5
	bleu,a,pn	%icc, 3f
	 ldda	[%o0] ASI_BLK_P, %f16
	membar #Sync
3:	
	faligndata	%f0, %f2, %f32
	inc	BLOCK_SIZE, %o0
	faligndata	%f2, %f4, %f34
	cmp	%o0, %o5
	faligndata	%f4, %f6, %f36
	dec	BLOCK_SIZE, %o2
	faligndata	%f6, %f8, %f38
	faligndata	%f8, %f10, %f40
	faligndata	%f10, %f12, %f42
	faligndata	%f12, %f14, %f44
	bleu,a,pn	%icc, 2f
	 ldda	[%o0] ASI_BLK_P, %f48
	membar	#Sync
2:
	brlez,pn	%o2, Lbcopy_blockdone
	 faligndata	%f14, %f16, %f46

	stda	%f32, [%o1] ASI_STORE
	
	faligndata	%f16, %f18, %f32
	inc	BLOCK_SIZE, %o0
	faligndata	%f18, %f20, %f34
	inc	BLOCK_SIZE, %o1
	faligndata	%f20, %f22, %f36
	cmp	%o0, %o5
	faligndata	%f22, %f24, %f38
	dec	BLOCK_SIZE, %o2
	faligndata	%f24, %f26, %f40
	faligndata	%f26, %f28, %f42
	faligndata	%f28, %f30, %f44
	bleu,a,pn	%icc, 2f
	 ldda	[%o0] ASI_BLK_P, %f0
	membar	#Sync
2:	
	brlez,pn	%o2, Lbcopy_blockdone
	 faligndata	%f30, %f48, %f46

	stda	%f32, [%o1] ASI_STORE

	faligndata	%f48, %f50, %f32
	inc	BLOCK_SIZE, %o0
	faligndata	%f50, %f52, %f34
	inc	BLOCK_SIZE, %o1
	faligndata	%f52, %f54, %f36
	cmp	%o0, %o5
	faligndata	%f54, %f56, %f38
	dec	BLOCK_SIZE, %o2
	faligndata	%f56, %f58, %f40
	faligndata	%f58, %f60, %f42
	faligndata	%f60, %f62, %f44
	bleu,a,pn	%icc, 2f
	 ldda	[%o0] ASI_BLK_P, %f16
	membar	#Sync
2:	
	brlez,pn	%o2, Lbcopy_blockdone
	 faligndata	%f62, %f0, %f46

	stda	%f32, [%o1] ASI_STORE
	ba	3b
	 inc	BLOCK_SIZE, %o1

	!!
	!! Source at BLOCK_ALIGN+16
	!!
	!! We need to load 6 doubles by hand.
	!! 
L102:
#ifdef RETURN_NAME
	sethi	%hi(1f), %g1
	ba,pt	%icc, 2f
	 or	%g1, %lo(1f), %g1
1:	
	.asciz	"L102"
	.align	8
2:	
#endif	/* RETURN_NAME */
	ldd	[%o0], %f4
	inc	8, %o0
	fmovd	%f0, %f2				! Hoist fmovd
	ldd	[%o0], %f6
	inc	8, %o0
	
	ldd	[%o0], %f8
	inc	8, %o0
	ldd	[%o0], %f10
	inc	8, %o0
	ldd	[%o0], %f12
	inc	8, %o0
	ldd	[%o0], %f14
	inc	8, %o0
	
	cmp	%o0, %o5
	bleu,a,pn	%icc, 3f
	 ldda	[%o0] ASI_BLK_P, %f16
	membar #Sync
3:	
	faligndata	%f2, %f4, %f32
	inc	BLOCK_SIZE, %o0
	faligndata	%f4, %f6, %f34
	cmp	%o0, %o5
	faligndata	%f6, %f8, %f36
	dec	BLOCK_SIZE, %o2
	faligndata	%f8, %f10, %f38
	faligndata	%f10, %f12, %f40
	faligndata	%f12, %f14, %f42
	bleu,a,pn	%icc, 2f
	 ldda	[%o0] ASI_BLK_P, %f48
	membar	#Sync
2:
	faligndata	%f14, %f16, %f44

	brlez,pn	%o2, Lbcopy_blockdone
	 faligndata	%f16, %f18, %f46
	
	stda	%f32, [%o1] ASI_STORE

	faligndata	%f18, %f20, %f32
	inc	BLOCK_SIZE, %o0
	faligndata	%f20, %f22, %f34
	inc	BLOCK_SIZE, %o1
	faligndata	%f22, %f24, %f36
	cmp	%o0, %o5
	faligndata	%f24, %f26, %f38
	dec	BLOCK_SIZE, %o2
	faligndata	%f26, %f28, %f40
	faligndata	%f28, %f30, %f42
	bleu,a,pn	%icc, 2f
	 ldda	[%o0] ASI_BLK_P, %f0
	membar	#Sync
2:	
	faligndata	%f30, %f48, %f44
	brlez,pn	%o2, Lbcopy_blockdone
	 faligndata	%f48, %f50, %f46

	stda	%f32, [%o1] ASI_STORE

	faligndata	%f50, %f52, %f32
	inc	BLOCK_SIZE, %o0
	faligndata	%f52, %f54, %f34
	inc	BLOCK_SIZE, %o1
	faligndata	%f54, %f56, %f36
	cmp	%o0, %o5
	faligndata	%f56, %f58, %f38
	dec	BLOCK_SIZE, %o2
	faligndata	%f58, %f60, %f40
	faligndata	%f60, %f62, %f42
	bleu,a,pn	%icc, 2f
	 ldda	[%o0] ASI_BLK_P, %f16
	membar	#Sync
2:	
	faligndata	%f62, %f0, %f44
	brlez,pn	%o2, Lbcopy_blockdone
	 faligndata	%f0, %f2, %f46

	stda	%f32, [%o1] ASI_STORE
	ba	3b
	 inc	BLOCK_SIZE, %o1
	
	!!
	!! Source at BLOCK_ALIGN+24
	!!
	!! We need to load 5 doubles by hand.
	!! 
L103:
#ifdef RETURN_NAME
	sethi	%hi(1f), %g1
	ba,pt	%icc, 2f
	 or	%g1, %lo(1f), %g1
1:	
	.asciz	"L103"
	.align	8
2:	
#endif	/* RETURN_NAME */
	fmovd	%f0, %f4
	ldd	[%o0], %f6
	inc	8, %o0
	ldd	[%o0], %f8
	inc	8, %o0
	ldd	[%o0], %f10
	inc	8, %o0
	ldd	[%o0], %f12
	inc	8, %o0
	ldd	[%o0], %f14
	inc	8, %o0

	cmp	%o0, %o5
	bleu,a,pn	%icc, 2f
	 ldda	[%o0] ASI_BLK_P, %f16
	membar #Sync
2:	
	inc	BLOCK_SIZE, %o0
3:	
	faligndata	%f4, %f6, %f32
	cmp	%o0, %o5
	faligndata	%f6, %f8, %f34
	dec	BLOCK_SIZE, %o2
	faligndata	%f8, %f10, %f36
	faligndata	%f10, %f12, %f38
	faligndata	%f12, %f14, %f40
	bleu,a,pn	%icc, 2f
	 ldda	[%o0] ASI_BLK_P, %f48
	membar	#Sync
2:
	faligndata	%f14, %f16, %f42
	inc	BLOCK_SIZE, %o0
	faligndata	%f16, %f18, %f44
	brlez,pn	%o2, Lbcopy_blockdone
	 faligndata	%f18, %f20, %f46
	
	stda	%f32, [%o1] ASI_STORE

	faligndata	%f20, %f22, %f32
	cmp	%o0, %o5
	faligndata	%f22, %f24, %f34
	dec	BLOCK_SIZE, %o2
	faligndata	%f24, %f26, %f36
	inc	BLOCK_SIZE, %o1
	faligndata	%f26, %f28, %f38
	faligndata	%f28, %f30, %f40
	ble,a,pn	%icc, 2f
	 ldda	[%o0] ASI_BLK_P, %f0
	membar	#Sync
2:	
	faligndata	%f30, %f48, %f42
	inc	BLOCK_SIZE, %o0
	faligndata	%f48, %f50, %f44
	brlez,pn	%o2, Lbcopy_blockdone
	 faligndata	%f50, %f52, %f46

	stda	%f32, [%o1] ASI_STORE

	faligndata	%f52, %f54, %f32
	cmp	%o0, %o5
	faligndata	%f54, %f56, %f34
	dec	BLOCK_SIZE, %o2
	faligndata	%f56, %f58, %f36
	faligndata	%f58, %f60, %f38
	inc	BLOCK_SIZE, %o1
	faligndata	%f60, %f62, %f40
	bleu,a,pn	%icc, 2f
	 ldda	[%o0] ASI_BLK_P, %f16
	membar	#Sync
2:	
	faligndata	%f62, %f0, %f42
	inc	BLOCK_SIZE, %o0
	faligndata	%f0, %f2, %f44
	brlez,pn	%o2, Lbcopy_blockdone
	 faligndata	%f2, %f4, %f46

	stda	%f32, [%o1] ASI_STORE
	ba	3b
	 inc	BLOCK_SIZE, %o1

	!!
	!! Source at BLOCK_ALIGN+32
	!!
	!! We need to load 4 doubles by hand.
	!! 
L104:
#ifdef RETURN_NAME
	sethi	%hi(1f), %g1
	ba,pt	%icc, 2f
	 or	%g1, %lo(1f), %g1
1:	
	.asciz	"L104"
	.align	8
2:	
#endif	/* RETURN_NAME */
	fmovd	%f0, %f6
	ldd	[%o0], %f8
	inc	8, %o0
	ldd	[%o0], %f10
	inc	8, %o0
	ldd	[%o0], %f12
	inc	8, %o0
	ldd	[%o0], %f14
	inc	8, %o0
	
	cmp	%o0, %o5
	bleu,a,pn	%icc, 2f
	 ldda	[%o0] ASI_BLK_P, %f16
	membar #Sync
2:	
	inc	BLOCK_SIZE, %o0
3:	
	faligndata	%f6, %f8, %f32
	cmp	%o0, %o5
	faligndata	%f8, %f10, %f34
	dec	BLOCK_SIZE, %o2
	faligndata	%f10, %f12, %f36
	faligndata	%f12, %f14, %f38
	bleu,a,pn	%icc, 2f
	 ldda	[%o0] ASI_BLK_P, %f48
	membar	#Sync
2:
	faligndata	%f14, %f16, %f40
	faligndata	%f16, %f18, %f42
	inc	BLOCK_SIZE, %o0
	faligndata	%f18, %f20, %f44
	brlez,pn	%o2, Lbcopy_blockdone
	 faligndata	%f20, %f22, %f46
	
	stda	%f32, [%o1] ASI_STORE

	faligndata	%f22, %f24, %f32
	cmp	%o0, %o5
	faligndata	%f24, %f26, %f34
	faligndata	%f26, %f28, %f36
	inc	BLOCK_SIZE, %o1
	faligndata	%f28, %f30, %f38
	bleu,a,pn	%icc, 2f
	 ldda	[%o0] ASI_BLK_P, %f0
	membar	#Sync
2:	
	faligndata	%f30, %f48, %f40
	dec	BLOCK_SIZE, %o2
	faligndata	%f48, %f50, %f42
	inc	BLOCK_SIZE, %o0
	faligndata	%f50, %f52, %f44
	brlez,pn	%o2, Lbcopy_blockdone
	 faligndata	%f52, %f54, %f46

	stda	%f32, [%o1] ASI_STORE

	faligndata	%f54, %f56, %f32
	cmp	%o0, %o5
	faligndata	%f56, %f58, %f34
	faligndata	%f58, %f60, %f36
	inc	BLOCK_SIZE, %o1
	faligndata	%f60, %f62, %f38
	bleu,a,pn	%icc, 2f
	 ldda	[%o0] ASI_BLK_P, %f16
	membar	#Sync
2:	
	faligndata	%f62, %f0, %f40
	dec	BLOCK_SIZE, %o2
	faligndata	%f0, %f2, %f42
	inc	BLOCK_SIZE, %o0
	faligndata	%f2, %f4, %f44
	brlez,pn	%o2, Lbcopy_blockdone
	 faligndata	%f4, %f6, %f46

	stda	%f32, [%o1] ASI_STORE
	ba	3b
	 inc	BLOCK_SIZE, %o1

	!!
	!! Source at BLOCK_ALIGN+40
	!!
	!! We need to load 3 doubles by hand.
	!! 
L105:
#ifdef RETURN_NAME
	sethi	%hi(1f), %g1
	ba,pt	%icc, 2f
	 or	%g1, %lo(1f), %g1
1:	
	.asciz	"L105"
	.align	8
2:	
#endif	/* RETURN_NAME */
	fmovd	%f0, %f8
	ldd	[%o0], %f10
	inc	8, %o0
	ldd	[%o0], %f12
	inc	8, %o0
	ldd	[%o0], %f14
	inc	8, %o0
	
	cmp	%o0, %o5
	bleu,a,pn	%icc, 2f
	 ldda	[%o0] ASI_BLK_P, %f16
	membar #Sync
2:	
	inc	BLOCK_SIZE, %o0
3:	
	faligndata	%f8, %f10, %f32
	cmp	%o0, %o5
	faligndata	%f10, %f12, %f34
	faligndata	%f12, %f14, %f36
	bleu,a,pn	%icc, 2f
	 ldda	[%o0] ASI_BLK_P, %f48
	membar	#Sync
2:
	faligndata	%f14, %f16, %f38
	dec	BLOCK_SIZE, %o2
	faligndata	%f16, %f18, %f40
	inc	BLOCK_SIZE, %o0
	faligndata	%f18, %f20, %f42
	faligndata	%f20, %f22, %f44
	brlez,pn	%o2, Lbcopy_blockdone
	 faligndata	%f22, %f24, %f46
	
	stda	%f32, [%o1] ASI_STORE

	faligndata	%f24, %f26, %f32
	cmp	%o0, %o5
	faligndata	%f26, %f28, %f34
	dec	BLOCK_SIZE, %o2
	faligndata	%f28, %f30, %f36
	bleu,a,pn	%icc, 2f
	 ldda	[%o0] ASI_BLK_P, %f0
	membar	#Sync
2:
	faligndata	%f30, %f48, %f38
	inc	BLOCK_SIZE, %o1
	faligndata	%f48, %f50, %f40
	inc	BLOCK_SIZE, %o0
	faligndata	%f50, %f52, %f42
	faligndata	%f52, %f54, %f44
	brlez,pn	%o2, Lbcopy_blockdone
	 faligndata	%f54, %f56, %f46

	stda	%f32, [%o1] ASI_STORE

	faligndata	%f56, %f58, %f32
	cmp	%o0, %o5
	faligndata	%f58, %f60, %f34
	dec	BLOCK_SIZE, %o2
	faligndata	%f60, %f62, %f36
	bleu,a,pn	%icc, 2f
	 ldda	[%o0] ASI_BLK_P, %f16
	membar	#Sync
2:
	faligndata	%f62, %f0, %f38
	inc	BLOCK_SIZE, %o1
	faligndata	%f0, %f2, %f40
	inc	BLOCK_SIZE, %o0
	faligndata	%f2, %f4, %f42
	faligndata	%f4, %f6, %f44
	brlez,pn	%o2, Lbcopy_blockdone
	 faligndata	%f6, %f8, %f46

	stda	%f32, [%o1] ASI_STORE
	ba	3b
	 inc	BLOCK_SIZE, %o1


	!!
	!! Source at BLOCK_ALIGN+48
	!!
	!! We need to load 2 doubles by hand.
	!! 
L106:
#ifdef RETURN_NAME
	sethi	%hi(1f), %g1
	ba,pt	%icc, 2f
	 or	%g1, %lo(1f), %g1
1:	
	.asciz	"L106"
	.align	8
2:	
#endif	/* RETURN_NAME */
	fmovd	%f0, %f10
	ldd	[%o0], %f12
	inc	8, %o0
	ldd	[%o0], %f14
	inc	8, %o0
a6829 240
	cmp	%o0, %o5
	bleu,a,pn	%icc, 2f
	 ldda	[%o0] ASI_BLK_P, %f16
	membar #Sync
2:	
	inc	BLOCK_SIZE, %o0
3:	
	faligndata	%f10, %f12, %f32
	cmp	%o0, %o5
	faligndata	%f12, %f14, %f34
	bleu,a,pn	%icc, 2f
	 ldda	[%o0] ASI_BLK_P, %f48
	membar	#Sync
2:
	faligndata	%f14, %f16, %f36
	dec	BLOCK_SIZE, %o2
	faligndata	%f16, %f18, %f38
	inc	BLOCK_SIZE, %o0
	faligndata	%f18, %f20, %f40
	faligndata	%f20, %f22, %f42
	faligndata	%f22, %f24, %f44
	brlez,pn	%o2, Lbcopy_blockdone
	 faligndata	%f24, %f26, %f46
	
	stda	%f32, [%o1] ASI_STORE

	faligndata	%f26, %f28, %f32
	cmp	%o0, %o5
	faligndata	%f28, %f30, %f34
	bleu,a,pn	%icc, 2f
	 ldda	[%o0] ASI_BLK_P, %f0
	membar	#Sync
2:
	faligndata	%f30, %f48, %f36
	dec	BLOCK_SIZE, %o2
	faligndata	%f48, %f50, %f38
	inc	BLOCK_SIZE, %o1
	faligndata	%f50, %f52, %f40
	faligndata	%f52, %f54, %f42
	inc	BLOCK_SIZE, %o0
	faligndata	%f54, %f56, %f44
	brlez,pn	%o2, Lbcopy_blockdone
	 faligndata	%f56, %f58, %f46

	stda	%f32, [%o1] ASI_STORE

	faligndata	%f58, %f60, %f32
	cmp	%o0, %o5
	faligndata	%f60, %f62, %f34
	bleu,a,pn	%icc, 2f
	 ldda	[%o0] ASI_BLK_P, %f16
	membar	#Sync
2:
	faligndata	%f62, %f0, %f36
	dec	BLOCK_SIZE, %o2
	faligndata	%f0, %f2, %f38
	inc	BLOCK_SIZE, %o1
	faligndata	%f2, %f4, %f40
	faligndata	%f4, %f6, %f42
	inc	BLOCK_SIZE, %o0
	faligndata	%f6, %f8, %f44
	brlez,pn	%o2, Lbcopy_blockdone
	 faligndata	%f8, %f10, %f46

	stda	%f32, [%o1] ASI_STORE
	ba	3b
	 inc	BLOCK_SIZE, %o1


	!!
	!! Source at BLOCK_ALIGN+56
	!!
	!! We need to load 1 double by hand.
	!! 
L107:
#ifdef RETURN_NAME
	sethi	%hi(1f), %g1
	ba,pt	%icc, 2f
	 or	%g1, %lo(1f), %g1
1:	
	.asciz	"L107"
	.align	8
2:	
#endif	/* RETURN_NAME */
	fmovd	%f0, %f12
	ldd	[%o0], %f14
	inc	8, %o0

	cmp	%o0, %o5
	bleu,a,pn	%icc, 2f
	 ldda	[%o0] ASI_BLK_P, %f16
	membar #Sync
2:	
	inc	BLOCK_SIZE, %o0
3:	
	faligndata	%f12, %f14, %f32
	cmp	%o0, %o5
	bleu,a,pn	%icc, 2f
	 ldda	[%o0] ASI_BLK_P, %f48
	membar	#Sync
2:
	faligndata	%f14, %f16, %f34
	dec	BLOCK_SIZE, %o2
	faligndata	%f16, %f18, %f36
	inc	BLOCK_SIZE, %o0
	faligndata	%f18, %f20, %f38
	faligndata	%f20, %f22, %f40
	faligndata	%f22, %f24, %f42
	faligndata	%f24, %f26, %f44
	brlez,pn	%o2, Lbcopy_blockdone
	 faligndata	%f26, %f28, %f46
	
	stda	%f32, [%o1] ASI_STORE

	faligndata	%f28, %f30, %f32
	cmp	%o0, %o5
	bleu,a,pn	%icc, 2f
	 ldda	[%o0] ASI_BLK_P, %f0
	membar	#Sync
2:
	faligndata	%f30, %f48, %f34
	dec	BLOCK_SIZE, %o2
	faligndata	%f48, %f50, %f36
	inc	BLOCK_SIZE, %o1
	faligndata	%f50, %f52, %f38
	faligndata	%f52, %f54, %f40
	inc	BLOCK_SIZE, %o0
	faligndata	%f54, %f56, %f42
	faligndata	%f56, %f58, %f44
	brlez,pn	%o2, Lbcopy_blockdone
	 faligndata	%f58, %f60, %f46
	
	stda	%f32, [%o1] ASI_STORE

	faligndata	%f60, %f62, %f32
	cmp	%o0, %o5
	bleu,a,pn	%icc, 2f
	 ldda	[%o0] ASI_BLK_P, %f16
	membar	#Sync
2:
	faligndata	%f62, %f0, %f34
	dec	BLOCK_SIZE, %o2
	faligndata	%f0, %f2, %f36
	inc	BLOCK_SIZE, %o1
	faligndata	%f2, %f4, %f38
	faligndata	%f4, %f6, %f40
	inc	BLOCK_SIZE, %o0
	faligndata	%f6, %f8, %f42
	faligndata	%f8, %f10, %f44

	brlez,pn	%o2, Lbcopy_blockdone
	 faligndata	%f10, %f12, %f46

	stda	%f32, [%o1] ASI_STORE
	ba	3b
	 inc	BLOCK_SIZE, %o1
	
Lbcopy_blockdone:
	inc	BLOCK_SIZE, %o2				! Fixup our overcommit
	membar	#Sync					! Finish any pending loads
#define	FINISH_REG(f)				\
	deccc	8, %o2;				\
	bl,a	Lbcopy_blockfinish;		\
	 fmovd	f, %f48;			\
	std	f, [%o1];			\
	inc	8, %o1

	FINISH_REG(%f32)
	FINISH_REG(%f34)
	FINISH_REG(%f36)
	FINISH_REG(%f38)
	FINISH_REG(%f40)
	FINISH_REG(%f42)
	FINISH_REG(%f44)
	FINISH_REG(%f46)
	FINISH_REG(%f48)
#undef FINISH_REG
	!! 
	!! The low 3 bits have the sub-word bits needed to be
	!! stored [because (x-8)&0x7 == x].
	!!
Lbcopy_blockfinish:
	brz,pn	%o2, 2f					! 100% complete?
	 fmovd	%f48, %f4
	cmp	%o2, 8					! Exactly 8 bytes?
	bz,a,pn	%xcc, 2f
	 std	%f4, [%o1]

	btst	4, %o2					! Word store?
	bz	%xcc, 1f
	 nop
	st	%f4, [%o1]
	inc	4, %o1
1:
	btst	2, %o2
	fzero	%f0
	bz	1f

	 mov	-6, %o4
	alignaddr %o1, %o4, %g0

	faligndata %f0, %f4, %f8
	
	stda	%f8, [%o1] ASI_FL16_P			! Store short
	inc	2, %o1
1:
	btst	1, %o2					! Byte aligned?
	bz	2f

	 mov	-7, %o0					! Calculate dest - 7
	alignaddr %o1, %o0, %g0				! Calculate shift mask and dest.

	faligndata %f0, %f4, %f8			! Move 1st byte to low part of f8

	stda	%f8, [%o1] ASI_FL8_P			! Store 1st byte
	inc	1, %o1					! Update address
2:
	membar	#Sync
#ifdef _KERNEL		

/*
 * Weve saved our possible fpstate, now disable the fpu
 * and continue with life.
 */
	RESTORE_FPU
	ret
	 restore	%g1, 0, %o0			! Return DEST for memcpy
#endif	/* _KERNEL		 */
 	retl
	 mov	%g1, %o0
#endif	/* 1 */

	
#if 1
/*
 * XXXXXXXXXXXXXXXXXXXX
 * We need to make sure that this doesn't use floating point
 * before our trap handlers are installed or we could panic
 * XXXXXXXXXXXXXXXXXXXX
 */
a6832 6
 * We want to use VIS instructions if we're clearing out more than
 * 256 bytes, but to do that we need to properly save and restore the
 * FP registers.  Unfortunately the code to do that in the kernel needs
 * to keep track of the current owner of the FPU, hence the different
 * code.
 *
a6873 5
#if 0
	!! Now we are 64-bit aligned
	cmp	%o2, 256		! Use block clear if len > 256
	bge,pt	%xcc, Lbzero_block	! use block store instructions
#endif	/* 0 */
a6906 88

#if 1
Lbzero_block:
	sethi	%hi(block_disable), %o3
	ldx	[ %o3 + %lo(block_disable) ], %o3
	brnz,pn	%o3, Lbzero_longs
	!! Make sure our trap table is installed
	set	_C_LABEL(trapbase), %o5
	rdpr	%tba, %o3
	sub	%o3, %o5, %o3
	brnz,pn	%o3, Lbzero_longs	! No, then don't use block load/store
	 nop
/*
 * Kernel:
 *
 * Here we use VIS instructions to do a block clear of a page.
 * But before we can do that we need to save and enable the FPU.
 * The last owner of the FPU registers is fpproc, and
 * fpproc->p_md.md_fpstate is the current fpstate.  If that's not
 * null, call savefpstate() with it to store our current fp state.
 *
 * Next, allocate an aligned fpstate on the stack.  We will properly
 * nest calls on a particular stack so this should not be a problem.
 *
 * Now we grab either curproc (or if we're on the interrupt stack
 * proc0).  We stash its existing fpstate in a local register and
 * put our new fpstate in curproc->p_md.md_fpstate.  We point
 * fpproc at curproc (or proc0) and enable the FPU.
 *
 * If we are ever preempted, our FPU state will be saved in our
 * fpstate.  Then, when we're resumed and we take an FPDISABLED
 * trap, the trap handler will be able to fish our FPU state out
 * of curproc (or proc0).
 *
 * On exiting this routine we undo the damage: restore the original
 * pointer to curproc->p_md.md_fpstate, clear our fpproc, and disable
 * the MMU.
 *
 */

	ENABLE_FPU 0
	!! We are now 8-byte aligned.  We need to become 64-byte aligned.
	btst	63, %i0
	bz,pt	%xcc, 2f
	 nop
1:
	stx	%i1, [%i0]
	inc	8, %i0
	btst	63, %i0
	bnz,pt	%xcc, 1b
	 dec	8, %i2

2:
	brz	%i1, 3f					! Skip the memory op
	 fzero	%f0					! for bzero

	stx	%i1, [%i0]				! Flush this puppy to RAM
	membar	#StoreLoad
	ldd	[%i0], %f0
	
3:	
	fmovd	%f0, %f2				! Duplicate the pattern
	fmovd	%f0, %f4
	fmovd	%f0, %f6
	fmovd	%f0, %f8
	fmovd	%f0, %f10
	fmovd	%f0, %f12
	fmovd	%f0, %f14

	!! Remember: we were 8 bytes too far
	dec	56, %i2					! Go one iteration too far
5:
	stda	%f0, [%i0] ASI_BLK_P			! Store 64 bytes
	deccc	BLOCK_SIZE, %i2
	bg,pt	%icc, 5b
	 inc	BLOCK_SIZE, %i0

	membar	#Sync
/*
 * We've saved our possible fpstate, now disable the fpu
 * and continue with life.
 */
	RESTORE_FPU
	addcc	%i2, 56, %i2	! Restore the count
	ba,pt	%xcc, Lbzero_longs	! Finish up the remainder
	 restore
#endif	/* 1 */
#endif	/* 1 */
@


1.171
log
@the kernel is supposed to provide memmove, but some archs are missing it.
add i386 sparc and sparc64. ok deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.170 2013/05/12 18:48:53 kettenis Exp $	*/
a6516 20
#ifdef DEBUG
	set	pmapdebug, %o4
	ld	[%o4], %o4
	btst	0x80, %o4	! PDB_COPY
	bz,pt	%icc, 3f
	 nop
	save	%sp, -CC64FSZ, %sp
	mov	%i0, %o1
	set	2f, %o0
	mov	%i1, %o2
	call	printf
	 mov	%i2, %o3
!	ta	1; nop
	restore
	.data
2:	.asciz	"bcopy(%p->%p,%x)\n"
	_ALIGN
	.text
3:
#endif	/* DEBUG */
a6910 38
#if 0
	!!
	!! verify copy success.
	!! 

	mov	%i0, %o2
	mov	%i1, %o4
	mov	%i2, %l4
0:	
	ldub	[%o2], %o1
	inc	%o2
	ldub	[%o4], %o3
	inc	%o4
	cmp	%o3, %o1
	bnz	1f
	 dec	%l4
	brnz	%l4, 0b
	 nop
	ba	2f
	 nop

1:
	set	0f, %o0
	call	printf
	 sub	%i2, %l4, %o5
	set	1f, %o0
	mov	%i0, %o1
	mov	%i1, %o2
	call	printf
	 mov	%i2, %o3
	ta	1
	.data
0:	.asciz	"bcopy failed: %x@@%p != %x@@%p byte %d\n"
1:	.asciz	"bcopy(%p, %p, %lx)\n"
	.align 8
	.text
2:	
#endif	/* 0 */
a8009 42
#if 0
	!!
	!! verify copy success.
	!! 

	mov	%i0, %o2
	mov	%i1, %o4
	mov	%i2, %l4
0:	
	ldub	[%o2], %o1
	inc	%o2
	ldub	[%o4], %o3
	inc	%o4
	cmp	%o3, %o1
	bnz	1f
	 dec	%l4
	brnz	%l4, 0b
	 nop
	ba	2f
	 nop

1:
	set	block_disable, %o0
	stx	%o0, [%o0]
	
	set	0f, %o0
	call	prom_printf
	 sub	%i2, %l4, %o5
	set	1f, %o0
	mov	%i0, %o1
	mov	%i1, %o2
	call	prom_printf
	 mov	%i2, %o3
	ta	1
	.data
	_ALIGN
0:	.asciz	"block bcopy failed: %x@@%p != %x@@%p byte %d\r\n"
1:	.asciz	"bcopy(%p, %p, %lx)\r\n"
	_ALIGN
	.text
2:	
#endif	/* 0 */
a8214 20
#ifdef DEBUG
	set	pmapdebug, %o4
	ld	[%o4], %o4
	btst	0x80, %o4	! PDB_COPY
	bz,pt	%icc, 3f
	 nop
	save	%sp, -CC64FSZ, %sp
	mov	%i0, %o1
	set	2f, %o0
	mov	%i1, %o2
	call	printf
	 mov	%i2, %o3
!	ta	1; nop
	restore
	.data
2:	.asciz	"kcopy(%p->%p,%x)\n"
	_ALIGN
	.text
3:
#endif	/* DEBUG */
a8406 18
#ifdef DEBUG
	set	pmapdebug, %o4
	ld	[%o4], %o4
	btst	0x80, %o4	! PDB_COPY
	bz,pt	%icc, 3f
	 nop
	save	%sp, -CC64FSZ, %sp
	set	2f, %o0
	call	printf
	 nop
!	ta	1; nop
	restore
	.data
2:	.asciz	"kcopy error\n"
	_ALIGN
	.text
3:
#endif	/* DEBUG */
@


1.170
log
@Take the kernel lock and call the actual interrupt handler from a
single C function.  Inspired by the change made to amd64/i386 by ratchov@@.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.169 2013/02/05 09:33:29 mpi Exp $	*/
d8551 7
@


1.169
log
@Do not profile the various ipi functions. This is a requirement for the
upcoming per-CPU profiling modifications and it does not make much sense
to profile such low-level functions anyway.

ok kettenis@@, miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.168 2012/11/07 16:31:03 kettenis Exp $	*/
a4432 5
#ifdef MULTIPROCESSOR
	call	_C_LABEL(sparc64_intlock)
	 add	%sp, CC64FSZ+BIAS, %o0	! tf = %sp + CC64FSZ + BIAS
#endif

d4440 1
a4440 1
	 add	%sp, CC64FSZ+BIAS, %o2	! tf = %sp + CC64FSZ + BIAS
a4441 2
	ldx	[%l2 + IH_FUN], %o4	! ih->ih_fun
	ldx	[%l2 + IH_ARG], %o0	! ih->ih_arg
d4447 2
a4448 2
	jmpl	%o4, %o7		! handled = (*ih->ih_fun)(...)
	 movrz	%o0, %o2, %o0		! arg = (arg == 0) ? arg : tf
a4460 5

#ifdef MULTIPROCESSOR
	call	_C_LABEL(sparc64_intunlock)
	 add	%sp, CC64FSZ+BIAS, %o0	! tf = %sp + CC64FSZ + BIAS
#endif
@


1.168
log
@Enable %tick access for userland on sun4u systems (sun4v systems already have
this enabled).

ok pirofti@@, mikeb@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.167 2012/11/06 21:39:02 kettenis Exp $	*/
d4086 1
a4086 1
ENTRY(sun4u_ipi_tlb_page_demap)
d4095 1
a4095 1
1:	
d4117 1
a4117 1
ENTRY(sun4u_ipi_tlb_context_demap)
d4126 1
a4126 1
1:	
d4141 1
a4141 1
	
d4148 1
a4148 1
ENTRY(sun4v_ipi_tlb_page_demap)
d4162 1
a4162 1
ENTRY(sun4v_ipi_tlb_context_demap)
d4166 1
a4166 1
ENTRY(ipi_save_fpstate)
d4222 1
a4222 1
ENTRY(ipi_drop_fpstate)
d4237 1
a4237 1
ENTRY(ipi_softint)
@


1.167
log
@Fix comment.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.166 2012/08/30 20:53:09 kettenis Exp $	*/
d8917 28
@


1.166
log
@Slightly tweak the way we set up the code patch sections such that we can
use them to patch inline assembly in C code as well.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.165 2012/08/29 20:33:16 kettenis Exp $	*/
d8921 1
a8921 1
 * sure the same cache line.
@


1.165
log
@The low-level guts to support MTP (Multi-Threaded Processing) on the
Fujitsu SPARC64-VI and SPARC64-VII CPUs.  Since the two threads on each core
share the TLBs of the core we cannot enter different mappings for the same
virtual address.  Instead we use a scratch register to store the per-cpu
pointer.  This is very similar to what we do on sun4v.

For now we still only attach the first thread of each SPARC64-VI/VII core
since we currently don't handle the VMT (Vertical Multi-Threading) of the
SPARC64-VI very well.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.164 2011/10/12 18:30:09 miod Exp $	*/
d104 5
d115 5
d124 5
a9196 17

	.section	.sun4v_patch, "ax"
	.globl _C_LABEL(sun4v_patch_end)
_C_LABEL(sun4v_patch_end):
	.previous

#ifdef MULTIPROCESSOR
	.section	.sun4v_mp_patch, "ax"
	.globl _C_LABEL(sun4v_mp_patch_end)
_C_LABEL(sun4v_mp_patch_end):
	.previous

	.section	.sun4u_mtp_patch, "ax"
	.globl _C_LABEL(sun4u_mtp_patch_end)
_C_LABEL(sun4u_mtp_patch_end):
	.previous
#endif
@


1.164
log
@Remove all MD diagnostics in cpu_switchto(), and move them to MI code if
they apply.

ok oga@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.163 2010/11/27 18:04:23 miod Exp $	*/
d109 5
d128 4
d9192 5
@


1.163
log
@Make sure kcopy() returns EFAULT instead of -1 upon failure on vax, and
fix outdated comments suggesting kcopy() will return -1.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.162 2010/03/27 23:12:48 kettenis Exp $	*/
a6021 13
Lsw_panic_wchan:
        sethi   %hi(1f), %o0
        call    _C_LABEL(panic)
         or     %lo(1f), %o0, %o0
Lsw_panic_srun:
        sethi   %hi(2f), %o0
        call    _C_LABEL(panic)
         or     %lo(2f), %o0, %o0
        .data
1:      .asciz  "switch wchan"
2:      .asciz  "switch SRUN"

	.text
a6048 9

	/* firewalls */
	ldx	[%i1 + P_WCHAN], %o0	! if (newproc->p_wchan)
	brnz,pn	%o0, Lsw_panic_wchan	!	panic("switch wchan");
!	 XXX check no delay slot
	ldsb	[%i1 + P_STAT], %o0	! if (newproc->p_stat != SRUN)
	cmp	%o0, SRUN
	bne	Lsw_panic_srun		!	panic("switch SRUN");
!	 XXX check no delay slot
@


1.162
log
@At tl==0 call datafault directly instead of going through winfault.  It is
impossible that there is a pending register window trap that we need to
fix up in this case.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.161 2010/03/22 18:49:25 kettenis Exp $	*/
d8321 1
a8321 1
 * when a fault occurs, it is able to return -1 to indicate this to the
@


1.161
log
@Read trap registers after setting up the stack frame in the slowtrap handler.
This will free up %g4 for tl>0 handling.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.160 2010/03/21 22:23:03 kettenis Exp $	*/
d776 1
a776 1
	VTRAP T_DATAFAULT, winfault	! 030 = data fetch fault
d778 2
a779 2
	VTRAP T_DATA_ERROR, winfault	! 032 = data access error
	VTRAP T_DATA_PROT, winfault	! 033 = data protection fault
d788 1
a788 1
	VTRAP T_ASYNC_ERROR, winfault	! 040 = data fetch fault
@


1.160
log
@Remove some left over debugging code, shaving off two instructions from
sun4v_datatrap.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.159 2009/08/28 13:04:40 jsing Exp $	*/
d3599 2
a3605 1
	TRAP_SETUP -CC64FSZ-TF_SIZE
@


1.159
log
@Use fixed labels rather than generating them using defines. This allows
the code to be compiled without -traditional-cpp (and is arguably easier
to read).

ok kettenis@@ jsg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.157 2009/01/23 19:16:39 kettenis Exp $	*/
a3330 2
	add	%g3, 0x60, %g4
	stxa	%sp, [%g4] ASI_PHYS_CACHED
@


1.158
log
@Work around UltraSPARC T1 "feature" that may cause random integer register
file register corruption as found out the hard way by art@@.
@
text
@a746 1
#define TABLE	user_
d821 1
a821 1
TABLE/**/uspill:
d829 1
a829 1
TABLE/**/kspill:
d834 1
a834 1
TABLE/**/uspillk:
d843 1
a843 1
TABLE/**/ufill:
d848 1
a848 1
TABLE/**/kfill:
d853 1
a853 1
TABLE/**/ufillk:
d862 1
a862 1
TABLE/**/syscall:
a906 2
#undef TABLE
#define TABLE	nucleus_
d981 1
a981 1
TABLE/**/uspill:
d986 1
a986 1
TABLE/**/kspill:
d991 1
a991 1
TABLE/**/uspillk:
d1000 1
a1000 1
TABLE/**/ufill:
d1005 1
a1005 1
TABLE/**/sfill:
d1010 1
a1010 1
TABLE/**/kfill:
d1019 1
a1019 1
TABLE/**/syscall:
@


1.157
log
@Make write_user_windows() do what the name suggests: flush user windows instead
of all windows.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.156 2008/12/22 23:01:31 kettenis Exp $	*/
d111 6
d118 1
@


1.156
log
@We never actually rely on storing %fp in tf_global[0] for clockframes.  So
save ourselves an instruction and remove the pretty misleading comments.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.155 2008/12/22 18:08:25 kettenis Exp $	*/
d8892 20
@


1.155
log
@If we ever get an interrupt from userland with %otherwin set, we have a serious
bug.  Don't try to fix things up; it's doomed to fail anyhow.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.154 2008/12/13 23:39:30 kettenis Exp $	*/
a1575 1
	stx	%i6, [%sp + CC64FSZ + BIAS + TF_G + (0*8)]	! Save fp in clockframe->cf_fp
@


1.154
log
@Properly restore PSTATE_IE when returning from send_softint().

Fixes "ipi_send: couldn't send ipi" panics.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.153 2008/08/17 14:25:19 kettenis Exp $	*/
d1581 1
a1581 4
	rdpr	%otherwin, %g5			! Has this already been done?
	brnz,pn	%g5, 1f				! Don't set this twice

	 rdpr	%canrestore, %g5		! Fixup register window state registers
@


1.153
log
@Garbage collect stupid delay loop.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.152 2008/08/10 14:13:05 kettenis Exp $	*/
d8872 2
a8873 2
	andn	%g1, PSTATE_IE, %g1
	wrpr	%g1, 0, %pstate
@


1.152
log
@Use the STICK logic on UltraSPARC-IIe to generate clock interrupts.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.151 2008/08/07 21:25:47 kettenis Exp $	*/
a9041 14
	retl
	 nop

	/*
	 * If something's wrong with the standard setup do this stupid loop
	 * calibrated for a 143MHz processor.
	 */
Lstupid_delay:
	set	142857143/MICROPERSEC, %o1
Lstupid_loop:
	brnz,pt	%o1, Lstupid_loop
	 dec	%o1
	brnz,pt	%o0, Lstupid_delay
	 dec	%o0
@


1.151
log
@Use %sys_tick to generate clock interrupts on systems that have it.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.150 2008/08/07 18:46:04 kettenis Exp $	*/
d8935 52
@


1.150
log
@Give each CPU its own `struct intrhand' for %tick interrupts.  Fixes a
problem where the clock would stop ticking on some CPUs because of lost
ticks.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.149 2008/07/28 19:08:46 miod Exp $	*/
d4285 2
a4286 1
	btst	TICK_INT, %g1
d4289 1
a4289 1
	wr	%g0, TICK_INT, CLEAR_SOFTINT
d8915 20
@


1.149
log
@No longer clear ci_want_resched within cpu_switchto(), now that it's done
in the MI code.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.148 2008/07/25 14:53:38 kettenis Exp $	*/
d4285 1
a4285 1
	btst	1, %g1
d4287 2
a4288 2
	 set	_C_LABEL(intrlev), %g3
	wr	%g0, 1, CLEAR_SOFTINT
d4290 1
a4290 1
	 ldx	[%g3 + 8], %g5	! intrlev[1] is reserved for %tick intr.
@


1.148
log
@Switch to a temporary stack early on such that we don't lose if the stack
provided by the PROM gets flushed out of the TLB before we install our own
trap table.  Makes RAMDISK kernels work on T2 systems.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.147 2008/07/21 13:30:05 art Exp $	*/
a6083 1
	st	%g0, [%g7 + CI_WANT_RESCHED]	! want_resched = 0;
@


1.147
log
@Implement the cpu_yield hypervisor call. Use it in the idle loop for
SUN4V to let it suspend strands (why does everyone invent own words for
hyperthreads?). This gives a huge performance boost when most of the
cpus are idle.

kettenis@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.146 2008/07/12 15:05:51 kettenis Exp $	*/
d350 7
d4867 5
a4978 6
	.data
	.space 2048
	_ALIGN
tmpstack:
	.text

@


1.146
log
@Shave off a few instructions from cpu_switchto().
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.145 2008/07/10 09:29:33 kettenis Exp $	*/
a6155 12

ENTRY(cpu_idle_enter)
	retl
	 nop

ENTRY(cpu_idle_cycle)
	retl
	 nop

ENTRY(cpu_idle_leave)
	retl
	 nop
@


1.145
log
@Add support for Fujitsu SPARC64-VI CPUs.

UltraSPARC I/II has a 41-bit physical address space, UltraSPARC III/IV has a
43-bit physical address space.  The Fujitsu SPARC64-VI extends this to 46 bits.
Adjust the TTE masks to take this into account and adjust some locore code
that truncated physical addresses to 41 bits (fixing a potential bug for
UltraSPARC III/IV too).

While there, fix the locore code for UltraSPARC Architecture 2007 CPUs, which
may support up to 56 bits of physical address space.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.143 2008/07/05 19:30:44 kettenis Exp $	*/
a6038 3
	mov	%i0, %l4		! oldproc
	mov	%i1, %l3		! newproc

d6044 2
a6047 2
	 *	%l3 = p
	 *	%l4 = lastproc
d6058 1
a6058 1
	ldx	[%l3 + P_WCHAN], %o0	! if (p->p_wchan)
d6061 1
a6061 1
	ldsb	[%l3 + P_STAT], %o0	! if (p->p_stat != SRUN)
d6074 1
a6074 1
	stx	%o0, [%l3 + P_CPU]
d6076 2
a6077 2
	mov	SONPROC, %o0			! p->p_stat = SONPROC
	stb	%o0, [%l3 + P_STAT]
d6079 1
a6079 2
	ldx	[%l3 + P_ADDR], %l1		! newpcb = p->p_addr;
	stx	%l4, [%g7 + CI_CURPROC]		! restore old proc so we can save it
d6087 1
a6087 1
	brz,pn	%l4, Lsw_load		! if no old process, go load
d6105 1
a6105 1
	stx	%l3, [%g7 + CI_CURPROC]	! curproc = p;
d6119 1
a6119 1
	ldx	[%l3 + P_VMSPACE], %o3	! vm = p->p_vmspace;
@


1.144
log
@The firmware on the v1280 changes %wstate behind our back.  Work around this
problem by adopting the same encoding used by Solaris for the kernel windows.
Note that this involves rearranging the trap vector tables, both fur sun4u and
for sun4v.
@
text
@d2089 1
a2089 1
	sllx	%g7, PGSHIFT+23, %g7			! There are 23 bits to the left of the PA in the TTE
d2091 1
a2091 1
	srax	%g7, 23, %g7
d3290 1
a3290 1
	sllx	%g7, PGSHIFT+23, %g7			! There are 23 bits to the left of the PA in the TTE
d3292 1
a3292 1
	srax	%g7, 23, %g7
@


1.143
log
@Don't play games with %cleanwin when spinning up secondary CPUs.  The firmware
on the v1280 doesn't like it if we change it behind its back.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.142 2008/06/01 21:29:48 kettenis Exp $	*/
d817 4
a820 4
	SPILL64 kspill8,ASI_N	! 0x090 spill_4_normal -- used to save supervisor windows
	SPILL32 kspill4,ASI_N	! 0x094 spill_5_normal
	SPILLBOTH kspill8,kspill4,ASI_N	! 0x098 spill_6_normal
	UTRAP 0x09c; TA32	! 0x09c spill_7_normal
d836 4
a839 4
	FILL64 kfill8,ASI_N	! 0x0d0 fill_4_normal -- used to fill windows when running supervisor mode
	FILL32 kfill4,ASI_N	! 0x0d4 fill_5_normal
	FILLBOTH kfill8,kfill4,ASI_N	! 0x0d8 fill_6_normal
	UTRAP 0x0dc; TA32	! 0x0dc fill_7_normal
d976 4
a979 4
	SPILL64 1,ASI_N	! 0x090 spill_4_normal -- used to save supervisor windows
	SPILL32 2,ASI_N	! 0x094 spill_5_normal
	SPILLBOTH 1b,2b,ASI_N	! 0x098 spill_6_normal
	UTRAP 0x09c; TA32	! 0x09c spill_7_normal
d995 4
a998 4
	FILL64 1,ASI_N		! 0x0d0 fill_4_normal -- used to fill windows when running nucleus mode from supervisor
	FILL32 2,ASI_N		! 0x0d4 fill_5_normal
	FILLBOTH 1b,2b,ASI_N	! 0x0d8 fill_6_normal
	UTRAP 0x0dc; TA32	! 0x0dc fill_7_normal
d1105 4
a1108 4
	SPILL64 kspill8v, ASI_N				! 0x90
	SPILL32 kspill4v, ASI_N				! 0x94
	SPILLBOTH kspill8v, kspill4v, ASI_N		! 0x98
	sun4v_tl0_unused 4				! 0x9c
d1117 5
a1121 5
	sun4v_tl0_unused 4				! 0xcf
	FILL64 kfill8v, ASI_N				! 0xd0
	FILL32 kfill4v, ASI_N				! 0xd4
	FILLBOTH kfill8v, kfill4v, ASI_N		! 0xd8
	sun4v_tl0_unused 4				! 0xdf
d1174 1
a1174 1
	sun4v_tl1_kspill_normal				! 0x90
d1177 1
a1177 1
	sun4v_tl1_unused 4				! 0x9c
@


1.142
log
@Unlink handled interrupts from the list of pending interrupts atomically.
Fixes a problem where softclock would stop running under heavy load.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.141 2008/06/01 12:13:47 kettenis Exp $	*/
a4975 1
	wrpr	%g0, 0, %cleanwin
@


1.141
log
@Remove iobviously untrue comment.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.140 2008/05/23 13:19:43 kettenis Exp $	*/
d4406 1
a4406 1
	
a4407 2
	add	%sp, CC64FSZ+BIAS, %o2	! tf = %sp + CC64FSZ + BIAS
	
d4409 7
a4418 2

	stx	%g0, [%l2 + IH_PEND]	! Unlink from list
@


1.140
log
@Make GENERIC.MP work on sun4us too.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.139 2008/05/22 22:29:14 kettenis Exp $	*/
a8876 4
 *
 * XXXX We do not block interrupts here so it's possible that another
 *	interrupt of the same level is dispatched before we get to
 *	enable the softint, causing a spurious interrupt.
@


1.139
log
@Quick hack to make non-MULTIPROCESSOR kernels work by restricting
interrupt vectors to 11 bits.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.138 2008/05/21 19:42:07 miod Exp $	*/
d3882 1
a3882 3
#ifndef MULTIPROCESSOR
	and	%g2, MAXINTNUM-1,%g2	! XXX make sun4us work
#endif
d3885 1
a3885 1
	 cmp	%g2, MAXINTNUM
d3888 1
a3888 1
	 sllx	%g2, 3, %g5		! Calculate entry number
d3903 1
a3903 1
	 sllx	%g2, 3, %g5		! Calculate entry number
d3912 1
@


1.138
log
@ddb expects the kernel longjmp() to only take a single parameter and always
return 1 since 12+ years, it's about time to fix the offending ports.

Reported by Pierre Riteau (firstname.lastname at gmail)
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.137 2008/04/20 10:35:57 kettenis Exp $	*/
d3882 3
@


1.137
log
@Remove the random() function from locore.s (which used sparcv7 instructions,
including mulscc to do multiplications) and switch to the generic random.c
code.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.136 2008/04/20 09:18:52 kettenis Exp $	*/
a9004 6
	.data
Lpanic_ljmp:
	.asciz	"longjmp botch"
	_ALIGN
	.text

a9009 1
	movrz	%i1, %i1, %i2	! compute v ? v : 1
@


1.136
log
@Implement locking of sun4u TSB entries for MULTIPROCESSOR kernels.
Make sun4v code use the new TSB_TAG_LOCKED define.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.135 2008/04/16 12:56:04 kettenis Exp $	*/
a8907 66
 * Here is a very good random number generator.  This implementation is
 * based on _Two Fast Implementations of the `Minimal Standard' Random
 * Number Generator_, David G. Carta, Communications of the ACM, Jan 1990,
 * Vol 33 No 1.
 */
/*
 * This should be rewritten using the mulx instr. if I ever understand what it
 * does.
 */
	.data
randseed:
	.word	1
	.text
ENTRY(random)
	sethi	%hi(16807), %o1
	wr	%o1, %lo(16807), %y
	 sethi	%hi(randseed), %o5
	 ld	[%o5 + %lo(randseed)], %o0
	 andcc	%g0, 0, %o2
	mulscc  %o2, %o0, %o2
	mulscc  %o2, %o0, %o2
	mulscc  %o2, %o0, %o2
	mulscc  %o2, %o0, %o2
	mulscc  %o2, %o0, %o2
	mulscc  %o2, %o0, %o2
	mulscc  %o2, %o0, %o2
	mulscc  %o2, %o0, %o2
	mulscc  %o2, %o0, %o2
	mulscc  %o2, %o0, %o2
	mulscc  %o2, %o0, %o2
	mulscc  %o2, %o0, %o2
	mulscc  %o2, %o0, %o2
	mulscc  %o2, %o0, %o2
	mulscc  %o2, %o0, %o2
	mulscc  %o2, %g0, %o2
	rd	%y, %o3
	srl	%o2, 16, %o1
	set	0xffff, %o4
	and	%o4, %o2, %o0
	sll	%o0, 15, %o0
	srl	%o3, 17, %o3
	or	%o3, %o0, %o0
	addcc	%o0, %o1, %o0
	bneg	1f
	 sethi	%hi(0x7fffffff), %o1
	retl
	 st	%o0, [%o5 + %lo(randseed)]
1:
	or	%o1, %lo(0x7fffffff), %o1
	add	%o0, 1, %o0
	and	%o1, %o0, %o0
	retl
	 st	%o0, [%o5 + %lo(randseed)]

#define MICROPERSEC	(1000000)
	.data
	.align	16
	.globl	_C_LABEL(cpu_clockrate)
_C_LABEL(cpu_clockrate):
	!! Pretend we have a 200MHz clock -- cpu_attach will fix this
	.xword	200000000
	!! Here we'll store cpu_clockrate/1000000 so we can calculate usecs
	.xword	0
	.text

/*
d8931 11
@


1.135
log
@Make sure tickcmpr_set() always writes a time in the future.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.134 2008/04/15 22:39:26 kettenis Exp $	*/
d1672 15
a1687 2
	mov	SFSR, %g7
	stx	%g4, [%g2+8]				! Update TSB entry data
d1792 14
a1805 1
1:	
d1807 1
a1807 2
	
	stx	%g4, [%g2+8]				! Update TSB entry data
d2524 14
a2537 1
1:	
a2538 1
	stx	%g4, [%g2+8]				! Update TSB entry data
a2738 1
#define TSBTAG_LOCKED	0x400
d2741 1
a2741 1
	btst	TSBTAG_LOCKED, %g3
d2743 1
a2743 1
	 or	%g3, TSBTAG_LOCKED, %g5
a2830 1
#define TSBTAG_LOCKED	0x400
d2833 1
a2833 1
	btst	TSBTAG_LOCKED, %g3
d2835 1
a2835 1
	 or	%g3, TSBTAG_LOCKED, %g5
a3020 1
#define TSBTAG_LOCKED	0x400
d3023 1
a3023 1
	btst	TSBTAG_LOCKED, %g3
d3025 1
a3025 1
	 or	%g3, TSBTAG_LOCKED, %g5
a3112 1
#define TSBTAG_LOCKED	0x400
d3115 1
a3115 1
	btst	TSBTAG_LOCKED, %g3
d3117 1
a3117 1
	 or	%g3, TSBTAG_LOCKED, %g5
a3218 1
#define TSBTAG_LOCKED	0x400
d3221 1
a3221 1
	btst	TSBTAG_LOCKED, %g3
d3223 1
a3223 1
	 or	%g3, TSBTAG_LOCKED, %g5
@


1.134
log
@Add workaround for UltraSPARC-II errata, where writes to %tick_cmpr would
sometimes fail, which would result in the periodic clock interrupts on a CPU
stop.

Spotted in a NetBSD commit message, loosely based on code in OpenSolaris.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.133 2008/04/14 21:04:56 kettenis Exp $	*/
d8947 2
a8948 1
	ba,a	1f
d8952 11
@


1.133
log
@Introduce macros to switch to normal and alternate globals and switch to
use the .section based mechanism to patch them up for sun4v.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.132 2008/04/13 16:32:55 kettenis Exp $	*/
d8940 13
@


1.132
log
@Use %g7 to store a pointer `struct cpu_info', and use it whereever possible.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.131 2008/04/12 14:59:30 kettenis Exp $	*/
d153 14
d3579 1
a3579 2
	wrpr	%g0, PSTATE_KERN, %pstate		! Get back to normal globals
gl0_1:	nop
d3741 1
a3741 2
	wrpr	%g0, PSTATE_KERN, %pstate	! Get back to normal globals
gl0_2:	nop
a4251 3
	! Switch to normal globals so we can save them
	wrpr	%g0, PSTATE_KERN, %pstate
gl0_3:	nop
d4253 3
d4264 5
a4268 2
gl0_x:
	flushw			! Do not remove this instruction -- causes interrupt loss
d4491 1
a4491 2
	wrpr	%g0, PSTATE_KERN, %pstate		! Make sure we have normal globals & no IRQs
gl0_4:	nop
d4500 1
a4500 1
	bnz	%icc, 2f
d4504 3
a4506 3
	/* Switch to alternate globals and load outs */
gl1_1:
	wrpr	%g0, PSTATE_KERN|PSTATE_AG, %pstate
a9132 16

#ifdef SUN4V
	.globl	_C_LABEL(gl0_start)
_C_LABEL(gl0_start):
	.xword	gl0_1
	.xword	gl0_2
	.xword	gl0_3
	.xword	gl0_4
	.xword	gl0_x
	.xword	0

	.globl	_C_LABEL(gl1_start)
_C_LABEL(gl1_start):
	.xword	gl1_1
	.xword	0
#endif
@


1.131
log
@Introduce macros to get and set the MMU context ID in asm code and switch to
use the .section based mechanism to patch them up for sun4v.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.130 2008/04/02 20:23:22 kettenis Exp $	*/
d2355 2
d2585 3
a2587 1
	
d3325 2
a3326 3
#ifdef SUN4V
	GET_CPUINFO_VA(%g1)
	ldx	[%g1 + CI_RWSP], %g2
d3330 8
a3337 8
	ldx	[%g1 + CI_RW + (0*8)], %l0
	ldx	[%g1 + CI_RW + (1*8)], %l1
	ldx	[%g1 + CI_RW + (2*8)], %l2
	ldx	[%g1 + CI_RW + (3*8)], %l3
	ldx	[%g1 + CI_RW + (4*8)], %l4
	ldx	[%g1 + CI_RW + (5*8)], %l5
	ldx	[%g1 + CI_RW + (6*8)], %l6
	ldx	[%g1 + CI_RW + (7*8)], %l7
d3346 8
a3353 8
	ldx	[%g1 + CI_RW + (8*8)], %l0
	ldx	[%g1 + CI_RW + (9*8)], %l1
	ldx	[%g1 + CI_RW + (10*8)], %l2
	ldx	[%g1 + CI_RW + (11*8)], %l3
	ldx	[%g1 + CI_RW + (12*8)], %l4
	ldx	[%g1 + CI_RW + (13*8)], %l5
	ldx	[%g1 + CI_RW + (14*8)], %l6
	ldx	[%g1 + CI_RW + (15*8)], %l7
d3363 1
a3363 1
	stx	%g0, [%g1 + CI_RWSP]
a3364 1
#endif
d3420 2
a3421 3
#ifdef SUN4V
	GET_CPUINFO_VA(%g1)
	ldx	[%g1 + CI_RWSP], %g2
d3425 8
a3432 8
	ldx	[%g1 + CI_RW + (0*8)], %l0
	ldx	[%g1 + CI_RW + (1*8)], %l1
	ldx	[%g1 + CI_RW + (2*8)], %l2
	ldx	[%g1 + CI_RW + (3*8)], %l3
	ldx	[%g1 + CI_RW + (4*8)], %l4
	ldx	[%g1 + CI_RW + (5*8)], %l5
	ldx	[%g1 + CI_RW + (6*8)], %l6
	ldx	[%g1 + CI_RW + (7*8)], %l7
d3441 8
a3448 8
	ldx	[%g1 + CI_RW + (8*8)], %l0
	ldx	[%g1 + CI_RW + (9*8)], %l1
	ldx	[%g1 + CI_RW + (10*8)], %l2
	ldx	[%g1 + CI_RW + (11*8)], %l3
	ldx	[%g1 + CI_RW + (12*8)], %l4
	ldx	[%g1 + CI_RW + (13*8)], %l5
	ldx	[%g1 + CI_RW + (14*8)], %l6
	ldx	[%g1 + CI_RW + (15*8)], %l7
d3458 1
a3458 1
	stx	%g0, [%g1 + CI_RWSP]
a3459 1
#endif
d3585 1
d3587 1
a3587 2
	GET_CPUINFO_VA(%g1)
	ldx	[%g1 + CI_RWSP], %g2
d3591 8
a3598 8
	ldx	[%g1 + CI_RW + (0*8)], %l0
	ldx	[%g1 + CI_RW + (1*8)], %l1
	ldx	[%g1 + CI_RW + (2*8)], %l2
	ldx	[%g1 + CI_RW + (3*8)], %l3
	ldx	[%g1 + CI_RW + (4*8)], %l4
	ldx	[%g1 + CI_RW + (5*8)], %l5
	ldx	[%g1 + CI_RW + (6*8)], %l6
	ldx	[%g1 + CI_RW + (7*8)], %l7
d3607 8
a3614 8
	ldx	[%g1 + CI_RW + (8*8)], %l0
	ldx	[%g1 + CI_RW + (9*8)], %l1
	ldx	[%g1 + CI_RW + (10*8)], %l2
	ldx	[%g1 + CI_RW + (11*8)], %l3
	ldx	[%g1 + CI_RW + (12*8)], %l4
	ldx	[%g1 + CI_RW + (13*8)], %l5
	ldx	[%g1 + CI_RW + (14*8)], %l6
	ldx	[%g1 + CI_RW + (15*8)], %l7
d3624 1
a3624 1
	stx	%g0, [%g1 + CI_RWSP]
d3757 1
d4255 1
d4257 1
a4257 2
	GET_CPUINFO_VA(%g1)
	ldx	[%g1 + CI_RWSP], %g2
d4261 8
a4268 8
	ldx	[%g1 + CI_RW + (0*8)], %l0
	ldx	[%g1 + CI_RW + (1*8)], %l1
	ldx	[%g1 + CI_RW + (2*8)], %l2
	ldx	[%g1 + CI_RW + (3*8)], %l3
	ldx	[%g1 + CI_RW + (4*8)], %l4
	ldx	[%g1 + CI_RW + (5*8)], %l5
	ldx	[%g1 + CI_RW + (6*8)], %l6
	ldx	[%g1 + CI_RW + (7*8)], %l7
d4277 8
a4284 8
	ldx	[%g1 + CI_RW + (8*8)], %l0
	ldx	[%g1 + CI_RW + (9*8)], %l1
	ldx	[%g1 + CI_RW + (10*8)], %l2
	ldx	[%g1 + CI_RW + (11*8)], %l3
	ldx	[%g1 + CI_RW + (12*8)], %l4
	ldx	[%g1 + CI_RW + (13*8)], %l5
	ldx	[%g1 + CI_RW + (14*8)], %l6
	ldx	[%g1 + CI_RW + (15*8)], %l7
d4294 1
a4294 1
	stx	%g0, [%g1 + CI_RWSP]
a4322 2
	GET_CPUINFO_VA(%l4)

d4329 2
a4330 2
	ld	[%l4 + CI_HANDLED_INTR_LEVEL], %l7
	st	%l6, [%l4 + CI_HANDLED_INTR_LEVEL]
d4337 1
a4337 2
	GET_CPUINFO_VA(%l4)
	add	%l4, CI_INTRPENDING, %l4
a4420 1
	GET_CPUINFO_VA(%l4)
d4422 1
a4422 1
	st	%l7, [%l4 + CI_HANDLED_INTR_LEVEL]
d4486 2
d4489 1
d4861 2
a4862 2
	GET_CPUINFO_VA(%l0)
	ldx	[%l0 + CI_INITSTACK], %l0
d4869 1
a4869 2
	GET_CPUINFO_VA(%l0)
	ldx	[%l0 + CI_SPINUP], %o1
d5992 1
a5992 2
	GET_CPUINFO_VA(%l6)
	ldx	[%l6 + CI_CPCB], %l5
a6001 1
	 *	%l6 = curcpu
d6026 1
a6026 1
	ldx	[%l6 + CI_SELF], %o0
d6031 1
a6031 1
	st	%g0, [%l6 + CI_WANT_RESCHED]	! want_resched = 0;
d6033 1
a6033 1
	stx	%l4, [%l6 + CI_CURPROC]		! restore old proc so we can save it
d6059 2
a6060 2
	stx	%l3, [%l6 + CI_CURPROC]	! curproc = p;
	stx	%l1, [%l6 + CI_CPCB]	! cpcb = newpcb;
d8840 1
a8840 3
	 nop
	GET_CPUINFO_VA(%o3)
	add	%o3, CI_INTRPENDING, %o3
a9140 2
	/* XXX This is in mutex.S for now */
#if 0
a9145 1
#endif
@


1.130
log
@For some reason using the ASI_SCRATCHPAD register at offset 0x08 makes the
t1k freak out upon reboot/halt/powerdown.  Use the register at offset 0x10
instead.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.129 2008/03/31 22:14:01 kettenis Exp $	*/
d99 5
d139 15
d1461 1
a1461 1
	.macro	TRAP_SETUP stackspace, label
d1501 1
a1501 2
\label:
	stxa	%g0, [%g7] ASI_DMMU		! Switch MMU to kernel primary context
d1516 1
a1516 1
	.macro	INTR_SETUP stackspace, label
d1569 1
a1569 2
\label:
	stxa	%g0, [%g7] ASI_DMMU		! Switch MMU to kernel primary context
d1971 1
a1971 1
	TRAP_SETUP -CC64FSZ-TF_SIZE, 99
d2298 1
a2298 1
	TRAP_SETUP -CC64FSZ-TF_SIZE, 99
d2540 1
a2540 1
	TRAP_SETUP -CC64FSZ-TF_SIZE, 99
d3277 1
a3277 1
	TRAP_SETUP -CC64FSZ-TF_SIZE, ctxid_1
d3380 1
a3380 1
	TRAP_SETUP -CC64FSZ-TF_SIZE, ctxid_2
d3553 1
a3553 1
	TRAP_SETUP -CC64FSZ-TF_SIZE, ctxid_3
d3721 1
a3721 1
	TRAP_SETUP -CC64FSZ-TF_SIZE, ctxid_4
d4096 1
a4096 2
ctxid_9:
	ldxa	[%g2] ASI_DMMU, %g6
d4098 1
a4098 2
ctxid_10:
	stxa	%g0, [%g2] ASI_DMMU
d4139 1
a4139 2
ctxid_11:
	stxa	%g6, [%g2] ASI_DMMU
d4238 1
a4238 1
	INTR_SETUP -CC64FSZ-TF_SIZE-8, ctxid_5
d4637 1
a4637 2
ctxid_6:
	ldxa	[%g1] ASI_DMMU, %g4
d4639 1
a4639 2
ctxid_7:
	stxa	%g4, [%g2] ASI_DMMU
d6103 1
a6103 2
ctxid_8:
	stxa	%o0, [%l5] ASI_DMMU		! Maybe we should invalidate the old context?
d9139 1
d9141 4
a9144 17
	.globl	_C_LABEL(ctxid_start)
_C_LABEL(ctxid_start):
	.xword	ctxid_1
	.xword	ctxid_2
	.xword	ctxid_3
	.xword	ctxid_4
	.xword	ctxid_5
	.xword	ctxid_6
	.xword	ctxid_7
	.xword	ctxid_8
#ifdef MULTIPROCESSOR
	.xword	ctxid_9
	.xword	ctxid_10
	.xword	ctxid_11
#endif
	.xword	0	
#endif
@


1.129
log
@Make MULTIPROCESSOR kernels work on sun4v.  Won't gracefully halt, powerdown
or reboot yet, but that will (hopefully) be fixed in the near future.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.128 2008/03/30 13:39:53 kettenis Exp $	*/
d124 1
a124 1
	mov	8, ci				;\
@


1.128
log
@Remove for #if 0'ed out code I left behind with the previous commit.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.127 2008/03/30 12:30:01 kettenis Exp $	*/
d99 7
d107 5
a111 1
	set CPUINFO_VA, ci
d124 2
a125 2
	nop					;\
	ldxa	[%g0] ASI_SCRATCHPAD, ci
d128 3
a130 2
	GET_CPUINFO_VA(mmfsa)			;\
	ldx	[mmfsa + CI_MMFSA], mmfsa
d1500 1
a1500 1
	sethi	%hi(EINTSTACK-BIAS), %g6
d1502 1
a1502 2

	or	%g6, %lo(EINTSTACK-BIAS), %g6	! Base of interrupt stack
d3638 1
a3638 1
	sethi	%hi(EINTSTACK-BIAS), %g5
d3640 1
a3640 1
	or	%g5, %lo(EINTSTACK-BIAS), %g5
d3991 1
a3991 1
ENTRY(ipi_tlb_page_demap)
d4022 1
a4022 1
ENTRY(ipi_tlb_context_demap)
d4052 19
d4078 1
d4081 1
d4123 1
d4836 1
a4836 2
	GET_CPUINFO_VA(%o1)
	ldx	[%o1 + CI_MMFSA], %o1
d9138 16
a9153 1
	.xword	0
@


1.127
log
@More sun4v support.  GENERIC and RAMDISK kernels will now boot on both
sun4u and sun4v.  GENERIC.MP won't work yet though.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.126 2008/03/23 21:49:48 kettenis Exp $	*/
a4254 6
#if 0
	rdpr	%tl, %l3		! Dump our trap frame now we have taken the IRQ
	stw	%l6, [%sp + CC64FSZ + BIAS + TF_Y]	! Silly, but we need to save this for rft
	dec	%l3
	wrpr	%g0, %l3, %tl
#else
a4258 1
#endif
@


1.126
log
@Sigh!  The sun4v TTEs have a different layout than sun4u TTEs.  Rename the
existing sun4u defines and add sun4v.  For now, decide which set to use
at compile time.  Change the sun4u-specific code in locore.s to use the sun4u
defines.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.125 2008/03/23 12:03:50 miod Exp $	*/
d110 12
d641 42
d1002 141
d1429 1
a1429 1
	.macro	TRAP_SETUP stackspace
a1460 1
	mov	CTX_PRIMARY, %g7
a1463 1

a1464 1

a1465 1

d1468 2
d1485 1
a1485 1
	.macro	INTR_SETUP stackspace
a1509 1

d1528 1
d1530 2
a1531 4
	 rdpr	%otherwin, %g5			! Has this already been done?

!	tst %g5; tnz %xcc, 1; nop; ! DEBUG -- this should _NEVER_ happen
	brnz,pn	%g5, 1f			! Don't set this twice
a1533 1

a1534 1

d1536 1
a1537 1
	sethi	%hi(KERNBASE), %g5
d1539 1
a1539 3

	wrpr	%g0, WSTATE_KERN, %wstate	! Enable kernel mode window traps -- now we can trap again

d1541 1
a1542 1

a1545 55
	

#ifdef DEBUG

	/* Look up kpte to test algorithm */
	.globl	asmptechk
asmptechk:
	mov	%o0, %g4	! pmap->pm_segs
	mov	%o1, %g3	! Addr to lookup -- mind the context

	srax	%g3, HOLESHIFT, %g5			! Check for valid address
	brz,pt	%g5, 0f					! Should be zero or -1
	 inc	%g5					! Make -1 -> 0
	brnz,pn	%g5, 1f					! Error!
0:
	 srlx	%g3, STSHIFT, %g5
	and	%g5, STMASK, %g5
	sll	%g5, 3, %g5
	add	%g4, %g5, %g4
	DLFLUSH %g4,%g5
	ldxa	[%g4] ASI_PHYS_CACHED, %g4		! Remember -- UNSIGNED
	DLFLUSH2 %g5
	brz,pn	%g4, 1f					! NULL entry? check somewhere else

	 srlx	%g3, PDSHIFT, %g5
	and	%g5, PDMASK, %g5
	sll	%g5, 3, %g5
	add	%g4, %g5, %g4
	DLFLUSH %g4,%g5
	ldxa	[%g4] ASI_PHYS_CACHED, %g4		! Remember -- UNSIGNED
	DLFLUSH2 %g5
	brz,pn	%g4, 1f					! NULL entry? check somewhere else

	 srlx	%g3, PTSHIFT, %g5			! Convert to ptab offset
	and	%g5, PTMASK, %g5
	sll	%g5, 3, %g5
	add	%g4, %g5, %g4
	DLFLUSH %g4,%g5
	ldxa	[%g4] ASI_PHYS_CACHED, %g6
	DLFLUSH2 %g5
	brgez,pn %g6, 1f				! Entry invalid?  Punt
	 srlx	%g6, 32, %o0
	retl
	 srl	%g6, 0, %o1
1:
	mov	%g0, %o1
	retl
	 mov	%g0, %o0

	.data
2:
	.asciz	"asmptechk: %x %x %x %x:%x\r\n"
	_ALIGN
	.text
#endif	/* DEBUG */
d1942 1
a1942 1
	TRAP_SETUP -CC64FSZ-TF_SIZE
d2269 1
a2269 1
	TRAP_SETUP -CC64FSZ-TF_SIZE
d2458 876
a3333 25
	set	DATA_START, %g6	! debug
	stx	%g3, [%g6+8]	! debug
	set	0xaa, %g3	! debug
	stx	%g4, [%g6]	! debug -- what we tried to enter in TLB
	stb	%g3, [%g6+0x20]	! debug
#endif	/* DEBUG */
#if 1
	/* This was a miss -- should be nothing to demap. */
	sllx	%g3, (64-13), %g6			! Need to demap old entry first
	mov	DEMAP_PAGE_SECONDARY, %g1		! Secondary flush
	mov	DEMAP_PAGE_NUCLEUS, %g5			! Nucleus flush
	movrz	%g6, %g5, %g1				! Pick one
	andn	%g3, 0xfff, %g6
	or	%g6, %g1, %g6
	stxa	%g6, [%g6] ASI_DMMU_DEMAP		! Do the demap
	membar	#Sync					! No real reason for this XXXX
#endif	/* 1 */
	stxa	%g4, [%g0] ASI_IMMU_DATA_IN		! Enter new mapping
	membar	#Sync
	CLRTT
	retry
	NOTREACHED
	!!
	!!  Check our prom mappings -- temporary
	!!
d3335 4
a3338 16
/*
 * Each memory text access fault, from user or kernel mode,
 * comes here.
 *
 * We will assume that %pil is not lost so we won't bother to save it
 * unless we're in an interrupt handler.
 *
 * On entry:
 *	We are on one of the alternate set of globals
 *	%g1 = MMU tag target
 *	%g2 = %tl
 *	%g3 = %tl - 1
 *
 * On return:
 *
 */
d3340 3
d3344 6
a3349 8
textfault:
	wrpr	%g0, PSTATE_KERN|PSTATE_AG, %pstate	! We need to save volatile stuff to AG regs
	wr	%g0, ASI_IMMU, %asi
	ldxa	[%g0 + TLB_TAG_ACCESS] %asi, %g1	! Get fault address from tag access register
	ldxa	[SFSR] %asi, %g3			! get sync fault status register
	membar	#LoadStore
	stxa	%g0, [SFSR] %asi			! Clear out old info
	membar	#Sync					! No real reason for this XXXX
d3351 1
a3351 2
	TRAP_SETUP -CC64FSZ-TF_SIZE
	INCR _C_LABEL(uvmexp)+V_FAULTS			! cnt.v_faults++ (clobbers %o0,%o1,%o2)
d3353 2
a3354 1
	mov	%g3, %o3
d3356 1
a3356 11
	wrpr	%g0, PSTATE_KERN, %pstate		! Switch to normal globals
	ldxa	[%g0] ASI_AFSR, %o4			! get async fault status
	ldxa	[%g0] ASI_AFAR, %o5			! get async fault address
	mov	-1, %o0
	stxa	%o0, [%g0] ASI_AFSR			! Clear this out
	membar	#Sync					! No real reason for this XXXX
	stx	%g1, [%sp + CC64FSZ + BIAS + TF_G + (1*8)]	! save g1
	stx	%g2, [%sp + CC64FSZ + BIAS + TF_G + (2*8)]	! save g2
	stx	%g3, [%sp + CC64FSZ + BIAS + TF_G + (3*8)]	! (sneak g3 in here)
	rdpr	%tt, %o1				! Find out what caused this trap
	stx	%g4, [%sp + CC64FSZ + BIAS + TF_G + (4*8)]	! sneak in g4
d3358 1
a3358 3
	stx	%g5, [%sp + CC64FSZ + BIAS + TF_G + (5*8)]	! sneak in g5
	rdpr	%tpc, %o2				! sync virt addr; must be read first
	stx	%g6, [%sp + CC64FSZ + BIAS + TF_G + (6*8)]	! sneak in g6
a3359 2
	stx	%g7, [%sp + CC64FSZ + BIAS + TF_G + (7*8)]	! sneak in g7
	rd	%y, %g4					! save y
d3361 6
a3366 2
	/* Finish stackframe, call C trap handler */
	stx	%g1, [%sp + CC64FSZ + BIAS + TF_TSTATE]		! set tf.tf_psr, tf.tf_pc
d3369 2
a3370 2
	stx	%o2, [%sp + CC64FSZ + BIAS + TF_PC]
	stx	%g3, [%sp + CC64FSZ + BIAS + TF_NPC]		! set tf.tf_npc
d3372 6
d3379 2
d3384 43
a3426 5
	rdpr	%tl, %g7
	dec	%g7
	movrlz	%g7, %g0, %g7
	CHKPT %g1,%g3,0x22
	wrpr	%g0, %g7, %tl		! Revert to kernel mode
d3428 3
a3430 7
	wr	%g0, ASI_PRIMARY_NOFAULT, %asi		! Restore default ASI
	flushw						! Get rid of any user windows so we don't deadlock
	
	/* Use trap type to see what handler to call */
	cmp	%o1, T_INST_ERROR
	be,pn	%xcc, text_error
	 st	%g4, [%sp + CC64FSZ + BIAS + TF_Y]		! set tf.tf_y
d3432 4
a3435 9
	wrpr	%g0, PSTATE_INTR, %pstate	! reenable interrupts
	call	_C_LABEL(text_access_fault)	! mem_access_fault(&tf, type, pc, sfsr)
	 add	%sp, CC64FSZ + BIAS, %o0	! (argument: &tf)
text_recover:
	CHKPT %o1,%o2,2
	wrpr	%g0, PSTATE_KERN, %pstate	! disable interrupts
	b	return_from_trap		! go return
	 ldx	[%sp + CC64FSZ + BIAS + TF_TSTATE], %g1	! Load this for return_from_trap
	NOTREACHED
d3437 1
a3437 6
text_error:
	wrpr	%g0, PSTATE_INTR, %pstate	! reenable interrupts
	call	_C_LABEL(text_access_error)	! mem_access_fault(&tfm type, sfva [pc], sfsr,
						!		afva, afsr);
	 add	%sp, CC64FSZ + BIAS, %o0	! (argument: &tf)
	ba	text_recover
d3441 2
a3518 20
#ifdef DIAGNOSTIC
	/* Make sure kernel stack is aligned */
	btst	0x03, %sp		! 32-bit stack OK?
	and	%sp, 0x07, %g4		! 64-bit stack OK?
	bz,pt	%icc, 1f
	cmp	%g4, 0x1		! Must end in 0b001
	be,pt	%icc, 1f
	 rdpr	%wstate, %g4
	cmp	%g7, WSTATE_KERN
	bnz,pt	%icc, 1f		! User stack -- we'll blow it away
	 nop
#ifdef DEBUG
	set	panicstack, %sp		! Kernel stack corrupt -- use panicstack
#else	/* DEBUG */
	set	estack0, %sp
	ldx	[%sp], %sp
	add	%sp, -CC64FSZ-BIAS, %sp	! Overwrite proc 0's stack.
#endif	/* DEBUG */
1:
#endif	/* DIAGNOSTIC */
d3524 1
a3524 1
	TRAP_SETUP -CC64FSZ-TF_SIZE
d3537 2
d3554 44
a3597 4
	rdpr	%tl, %g1
	dec	%g1
	movrlz	%g1, %g0, %g1
	wrpr	%g0, %g1, %tl		! Revert to kernel mode
d3692 1
a3692 1
	TRAP_SETUP -CC64FSZ-TF_SIZE
d3700 2
d3924 55
a4186 1
	DLFLUSH %g3, %g2
d4190 1
a4190 1
	INTR_SETUP -CC64FSZ-TF_SIZE-8
d4193 2
d4203 1
d4205 44
d4255 1
a4258 1
	CHKPT %l4,%l7,0x26
d4260 6
d4280 1
a4280 1
	
a4397 1

d4439 1
d4450 1
d4488 13
a4518 4
	.data
rft_wcnt:	.word 0
	.text

a4542 7
	rdpr	%otherwin, %g7			! restore register window controls
	wrpr	%g0, %g7, %canrestore
	wrpr	%g0, 0, %otherwin

	CHKPT %g4,%g7,9
	wrpr	%g0, WSTATE_USER, %wstate	! Need to know where our sp points

d4550 38
a4587 1
	wrpr	%g1, %g0, %tstate
a4589 4
	CHKPT %g4,%g7,0xa
	rdpr	%canrestore, %g5
	wrpr	%g5, 0, %cleanwin			! Force cleanup of kernel windows

d4595 6
a4600 2
	wr	%g0, ASI_DMMU, %asi		! restore the user context
	ldxa	[CTX_SECONDARY] %asi, %g4
a4601 1
	stxa	%g4, [CTX_PRIMARY] %asi
d4604 1
a4604 2
	CLRTT
	CHKPT %g4,%g7,0xd
d4803 11
a4832 1

d4834 1
a4834 1
	 clr	%o0				! our frame arg is ignored
d5161 5
d6065 1
d9086 29
a9114 1
	.xword 0
@


1.125
log
@Fix ovbcopy() operation when copying shorts backwards, similar to sparc
locore.s r1.76
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.124 2008/03/22 21:10:29 kettenis Exp $	*/
d1466 2
a1467 1
	 or	%g4, TLB_MODIFY|TLB_ACCESS|TLB_W, %g7	! Update the modified bit
d1469 1
a1469 1
	btst	TLB_REAL_W|TLB_W, %g4			! Is it a ref fault?
d1495 2
a1496 1
	 or	%g4, TLB_MODIFY|TLB_ACCESS|TLB_W, %g4	! Update the modified bit
d1595 1
a1595 1
	 or	%g4, TLB_ACCESS, %g7			! Update the access bit
d1597 1
a1597 1
	btst	TLB_ACCESS, %g4				! Need to update access git?
d1603 1
a1603 1
	 or	%g4, TLB_ACCESS, %g4				! Update the modified bit
d2309 1
a2309 1
	andcc	%g4, TLB_EXEC, %g0
d2314 2
a2315 2
	or	%g4, TLB_ACCESS, %g7			! Update accessed bit
	btst	TLB_ACCESS, %g4				! Need to update access bit?
d2321 1
a2321 1
	 or	%g4, TLB_ACCESS, %g4			! Update accessed bit
@


1.124
log
@Reintroduce the cputyp variable, and use it to distinguish between sun4u and
sun4v.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.123 2008/03/22 17:15:42 kettenis Exp $	*/
d7402 1
a7402 1
	deccc	2, %o0		!	*(short *)dst = *(short *)src;
@


1.123
log
@Simplify cpu_switchto() such that it doesn't need to know the number of
register windows provided by the hardware; this number is not readily
available on sun4v.

This removes the optimization that skips flushing register windows if
a process exits.  We can add that back later if it turns out to make a
significant impact.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.122 2008/03/22 16:41:49 kettenis Exp $	*/
d306 9
@


1.122
log
@Remove TRAPS_USE_IG code.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.121 2008/03/22 16:01:32 kettenis Exp $	*/
d4764 1
a4764 1
	set	CPUINFO_VA, %l6
d4809 2
a4817 1
	flushw				! save all register windows except this one
a4837 8
	wrpr	%g0, 0, %otherwin
	wrpr	%g0, 0, %canrestore
	rdpr	%ver, %l7
	and	%l7, CWP, %l7
	wrpr	%g0, %l7, %cleanwin
!	wrpr	%g0, 0, %cleanwin	! DEBUG
	dec	1, %l7					! NWINDOWS-1-1
	wrpr	%l7, %cansave
@


1.121
log
@Split out the code that sets the TSB registers and call it from
pmap_bootstrap_cpu().
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.120 2008/03/22 12:49:53 kettenis Exp $	*/
a60 1
#undef	TRAPS_USE_IG		/* Use Interrupt Globals for all traps */
a1784 3
#ifdef TRAPS_USE_IG
	wrpr	%g0, PSTATE_KERN|PSTATE_IG, %pstate	! We need to save volatile stuff to AG regs
#endif	/* TRAPS_USE_IG */
a2091 3
#ifdef TRAPS_USE_IG
	wrpr	%g0, PSTATE_KERN|PSTATE_IG, %pstate	! DEBUG
#endif	/* TRAPS_USE_IG */
a2111 3
#ifdef TRAPS_USE_IG
	wrpr	%g0, PSTATE_KERN|PSTATE_IG, %pstate	! We need to save volatile stuff to AG regs
#endif	/* TRAPS_USE_IG */
a2360 3
#ifdef TRAPS_USE_IG
	wrpr	%g0, PSTATE_KERN|PSTATE_IG, %pstate	! We need to save volatile stuff to AG regs
#endif	/* TRAPS_USE_IG */
a2511 3
#ifdef TRAPS_USE_IG
	wrpr	%g0, PSTATE_KERN|PSTATE_IG, %pstate	! DEBUG
#endif	/* TRAPS_USE_IG */
a2662 3
#ifdef TRAPS_USE_IG
	wrpr	%g0, PSTATE_KERN|PSTATE_IG, %pstate	! DEBUG
#endif	/* TRAPS_USE_IG */
a3092 3
#ifdef TRAPS_USE_IG
	wrpr	%g0, PSTATE_KERN|PSTATE_IG, %pstate	! DEBUG
#endif	/* TRAPS_USE_IG */
a3312 3
#ifdef TRAPS_USE_IG
	wrpr	%g0, PSTATE_KERN|PSTATE_IG, %pstate	! DEBUG
#endif	/* TRAPS_USE_IG */
@


1.120
log
@Use ASI_BLK_P instead of ASI_BLK_COMMIT_P when saving floating point
registers.  UltraSPARC T1 doesn't support ASI_BLK_COMMIT_P, and I can't see
why this code needs commit force.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.119 2008/03/22 10:53:15 kettenis Exp $	*/
d3640 1
a3640 2
 *	Locate the cpu_info structure for this CPU.
 *	Establish a locked mapping for interrupt stack.
d3642 1
a3642 1
 *	Call the routine passed in in cpu_info->ci_spinup
a3644 1

a3649 31
	/*
	 * Step 7: change the trap base register, and install our TSBs
	 */

	/* Set the dmmu tsb */
	sethi	%hi(0x1fff), %l2
	set	_C_LABEL(tsb_dmmu), %l0
	ldx	[%l0], %l0
	set	_C_LABEL(tsbsize), %l1
	or	%l2, %lo(0x1fff), %l2
	ld	[%l1], %l1
	andn	%l0, %l2, %l0			! Mask off size and split bits
	or	%l0, %l1, %l0			! Make a TSB pointer
	set	TSB, %l2
	stxa	%l0, [%l2] ASI_DMMU		! Install data TSB pointer
	membar	#Sync


	/* Set the immu tsb */
	sethi	%hi(0x1fff), %l2
	set	_C_LABEL(tsb_immu), %l0
	ldx	[%l0], %l0
	set	_C_LABEL(tsbsize), %l1
	or	%l2, %lo(0x1fff), %l2
	ld	[%l1], %l1
	andn	%l0, %l2, %l0			! Mask off size and split bits
	or	%l0, %l1, %l0			! Make a TSB pointer
	set	TSB, %l2
	stxa	%l0, [%l2] ASI_IMMU		! Install instruction TSB pointer
	membar	#Sync				! We may need more membar #Sync in here

d3684 32
@


1.119
log
@Switch to our initial stack after switching over to our own trap table.  This
removes the need to lock the stack (and cpuinfo) into the TLB on sun4v.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.118 2008/03/20 22:22:47 kettenis Exp $	*/
d7529 1
a7529 1
	stda	%f0, [%o2] ASI_BLK_COMMIT_P	! f->fs_f0 = etc;
d7531 1
a7531 1
	stda	%f16, [%o2] ASI_BLK_COMMIT_P
d7539 1
a7539 1
	stda	%f32, [%o2] ASI_BLK_COMMIT_P
d7541 1
a7541 1
	stda	%f48, [%o2] ASI_BLK_COMMIT_P
@


1.118
log
@Introduce GET_CPUINFO_VA(), GET_CPCB() and GET_CURPROC() macros to get
some important members of 'struct cpuinfo'.  Preparation for sun4v.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.117 2008/03/19 23:16:19 kettenis Exp $	*/
a3649 14
	
	/*
	 * Step 6: map cpu_info struct and interrupt stack and 
	 * switch to our initial stack.
	 */

!!! Make sure our stack's OK.
	flushw
	GET_CPUINFO_VA(%l0)
	ldx	[%l0 + CI_INITSTACK], %l0
 	add	%l0, - CC64FSZ - 80, %l0	! via syscall(boot_me_up) or somesuch
	andn	%l0, 0x0f, %l0			! Needs to be 16-byte aligned
	sub	%l0, BIAS, %l0			! and biased
	mov	%l0, %sp
d3689 8
@


1.117
log
@Establish per-cpu locked mappings for `struct cpuinfo' through the PROM as
well.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.116 2008/03/19 20:42:05 kettenis Exp $	*/
a84 3
#define	CURPROC	(CPUINFO_VA+CI_CURPROC)
#define CPCB	(CPUINFO_VA+CI_CPCB)
#define	FPPROC	(CPUINFO_VA+CI_FPPROC)
d100 11
d225 1
a225 1
	sethi	%hi(FPPROC), %l1;
d227 1
a227 1
	ldx	[%l1 + %lo(FPPROC)], %l2;	! Load fpproc
d248 1
a248 2
	sethi	%hi(CURPROC), %l4;		! Use curproc
	ldx	[%l4 + %lo(CURPROC)], %l5;
d253 1
a253 1
	stx	%l5, [%l1 + %lo(FPPROC)];	! Set new fpproc
d268 1
a268 1
	stx	%l2, [%l1 + %lo(FPPROC)]	! Restore old fproc
d523 1
a523 2
	sethi	%hi(CPCB), %g5
	ldx	[%g5 + %lo(CPCB)], %g5
d575 1
a575 2
	sethi	%hi(CPCB), %g5
	ldx	[%g5 + %lo(CPCB)], %g5
d1227 1
a1227 1
	sethi	%hi(CPCB), %g6
a1228 2

	ldx	[%g6 + %lo(CPCB)], %g6
d1678 1
a1678 2
	 sethi	%hi(CPCB), %g6		! get current pcb

d1828 1
a1828 1
	ldx	[%g6 + %lo(CPCB)], %g6	! This is in the locked TLB and should not fault
d2470 1
a2470 1
	 sethi	%hi(CPCB), %g6		! Get current pcb
d2577 1
a2583 1
	CHKPT %g2,%g3,0x24
a2590 1
	CHKPT %o1,%o2,3
d2618 1
a2619 1
	sethi	%hi(CPCB), %g6
d2622 2
a2623 1
	 ldx	[%g6 + %lo(CPCB)], %g7
a2625 1
	SET_SP_REDZONE %g7, %g5
a2700 1
	CHKPT %g5,%g6,0x31
a2721 1
	CHKPT %o1,%o2,0x32
a2722 1
	CHKPT %o1,%o2,4
d2849 1
a2849 1
	sethi	%hi(CPUINFO_VA+CI_INTRPENDING), %g1
d2851 2
a2852 2
	or	%g1, %lo(CPUINFO_VA+CI_INTRPENDING), %g1
	 add	%g1, %g3, %g1
d2975 2
a2976 2
	sethi	%hi(FPPROC), %g1
	ldx	[%g1 + %lo(FPPROC)], %g2
d3022 1
a3022 1
	stx	%g0, [%g1 + %lo(FPPROC)] ! fpproc = NULL
d3035 2
a3036 2
	sethi	%hi(FPPROC), %g1
	ldx	[%g1 + %lo(FPPROC)], %g5
d3040 1
a3040 1
	stx	%g0, [%g1 + %lo(FPPROC)]	! fpproc = NULL
d3165 1
a3165 1
	sethi	%hi(CPUINFO_VA+CI_HANDLED_INTR_LEVEL), %l4
d3173 2
a3174 2
	ld	[%l4 + %lo(CPUINFO_VA+CI_HANDLED_INTR_LEVEL)], %l7
	st	%l6, [%l4 + %lo(CPUINFO_VA+CI_HANDLED_INTR_LEVEL)]
d3181 2
a3182 2
	sethi	%hi(CPUINFO_VA+CI_INTRPENDING), %l4
	or	%l4, %lo(CPUINFO_VA+CI_INTRPENDING), %l4
d3266 1
a3266 1
	sethi	%hi(CPUINFO_VA+CI_HANDLED_INTR_LEVEL), %l4
d3268 1
a3268 1
	st	%l7, [%l4 + %lo(CPUINFO_VA+CI_HANDLED_INTR_LEVEL)]
a3352 7
#ifdef DEBUG
	tst	%g2
	tz	1		! tpc NULL? Panic
	tst	%i6
	tz	1		! %fp NULL? Panic
#endif	/* DEBUG */

a3354 1
	CHKPT %g4, %g7, 6
d3356 1
a3356 1
	 sethi	%hi(CURPROC), %g7		! first instr of rft_user
d3367 1
a3367 1
	rdpr	%tl, %g4				! Grab a set of trap registers
d3373 1
a3373 1
	CHKPT %g1,%g2,7
d3375 1
a3375 1
	CHKPT %g1,%g2,0			! Clear this out
a3379 4
	CLRTT
#if	0
	wrpr	%g0, 0, %cleanwin	! DEBUG
#endif	/* 0 */
d3382 1
d3397 2
a3398 3
!	sethi	%hi(CURPROC), %g7		! (done above)
	ldx	[%g7 + %lo(CURPROC)], %g7
	lduw	[%g7 + %lo(P_MD_ASTPENDING)], %g7! want AST trap?
a3401 2
	CHKPT %g4,%g7,8

d3415 2
a3416 3
	sethi	%hi(CPCB), %g6
	ldx	[%g6 + %lo(CPCB)], %g6
	ldub	[%g6 + PCB_NSAVED], %g7
a3444 1
	CHKPT %g4,%g7,0xb
d3455 1
a3455 2
	sethi	%hi(CPCB), %g5
	ldx	[%g5 + %lo(CPCB)], %g5
d3621 1
a3621 1
1:	
d3650 1
a3650 1

d3658 2
a3659 2
	sethi	%hi(CPUINFO_VA+CI_INITSTACK), %l0
	ldx	[%l0 + %lo(CPUINFO_VA+CI_INITSTACK)], %l0
d3708 2
a3709 2
	sethi	%hi(CPUINFO_VA+CI_SPINUP), %l0
	ldx	[%l0 + %lo(CPUINFO_VA+CI_SPINUP)], %o1
d3732 2
d4265 1
a4265 1
	 sethi	%hi(CPCB), %o4		! (first instr of copy)
d4269 1
a4269 1
	ldx	[%o4 + %lo(CPCB)], %o4	! catch faults
d4298 1
a4298 1
	 sethi	%hi(CPCB), %o4		! (first instr of copy)
d4302 1
a4302 1
	ldx	[%o4 + %lo(CPCB)], %o4	! catch faults
d4390 1
a4390 1
	sethi	%hi(CPCB), %o3
a4391 1
	ldx	[%o3 + %lo(CPCB)], %o3
d4556 1
a4556 3
	sethi	%hi(CPCB), %o3
!	stb	%o4,[%o1]	! Store last byte -- should not be needed
	ldx	[%o3 + %lo(CPCB)], %o3
d4581 1
a4581 1
	sethi	%hi(CPCB), %o3
a4582 1
	ldx	[%o3 + %lo(CPCB)], %o3
d4749 1
a4749 2
	sethi	%hi(CPCB), %o3
	ldx	[%o3 + %lo(CPCB)], %o3
d4763 1
a4763 2
	sethi	%hi(CPCB), %o3
	ldx	[%o3 + %lo(CPCB)], %o3
d4796 2
a4797 3
	sethi	%hi(CPCB), %l6
	ldx	[%l6 + %lo(CPCB)], %l5
	sethi   %hi(CURPROC), %l7
d4807 1
a4807 2
	 *	%l6 = %hi(_cpcb)
	 *	%l7 = %hi(_curproc)
d4832 1
a4832 2
	sethi	%hi(CPUINFO_VA+CI_SELF), %o0
	ldx	[%o0 + %lo(CPUINFO_VA+CI_SELF)], %o0
d4837 1
a4837 2
	sethi	%hi(CPUINFO_VA+CI_WANT_RESCHED), %o0
	st	%g0, [%o0 + %lo(CPUINFO_VA+CI_WANT_RESCHED)]	! want_resched = 0;
d4839 1
a4839 1
	stx	%l4, [%l7 + %lo(CURPROC)]	! restore old proc so we can save it
d4864 2
a4865 2
	stx	%l3, [%l7 + %lo(CURPROC)]	! curproc = p;
	stx	%l1, [%l6 + %lo(CPCB)]	! cpcb = newpcb;
d4877 1
a4877 11
#ifdef DEBUG
	wrpr	%g0, 4, %tl				! DEBUG -- force watchdog
	flushw						! DEBUG
	wrpr	%g0, 0, %tl				! DEBUG
	/* load window */
!	restore				! The logic is just too complicated to handle here.  Let the traps deal with the problem
!	flushw						! DEBUG
	mov	%l1, %o0
	SET_SP_REDZONE %o0, %o1
	CHECK_SP_REDZONE %o0, %o1
#endif	/* DEBUG */
d4889 1
a4889 1
	ldx	[%o3 + VM_PMAP], %o2		! if (vm->vm_pmap.pm_ctx != NULL)
d5026 1
a5026 2
	sethi	%hi(CPCB), %o2
	ldx	[%o2 + %lo(CPCB)], %o2	! cpcb->pcb_onfault = Lfsprobe;
d7119 1
a7119 2
	sethi	%hi(CPCB), %o5		! cpcb->pcb_onfault = Lkcerr;
	ldx	[%o5 + %lo(CPCB)], %o5
d7653 3
a7655 1
	 set	CPUINFO_VA+CI_INTRPENDING, %o3
@


1.116
log
@Use PROM calls to enter locked kernel text and data mappings into the TLB.
Gets rid of a big chunk of nasty asm code and makes us boot on the e10k with
multi-systemboard domains.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.115 2008/03/18 20:00:40 kettenis Exp $	*/
a3674 30
	mov	%g2, %l1			! Load the interrupt stack's PA

	sethi	%hi(0xa0000000), %l2		! V=1|SZ=01|NFO=0|IE=0
	sllx	%l2, 32, %l2			! Shift it into place

	mov	-1, %l3				! Create a nice mask
	sllx	%l3, 41, %l4			! Mask off high bits
	or	%l4, 0xfff, %l4			! We can just load this in 12 (of 13) bits

	andn	%l1, %l4, %l1			! Mask the phys page number

	or	%l2, %l1, %l1			! Now take care of the high bits
#ifdef NO_VCACHE
	or	%l1, TLB_L|TLB_CP|TLB_P|TLB_W, %l2	! And low bits:	L=1|CP=1|CV=0|E=0|P=1|W=0|G=0
#else	/* NO_VCACHE */
	or	%l1, TLB_L|TLB_CP|TLB_CV|TLB_P|TLB_W, %l2	! And low bits:	L=1|CP=1|CV=1|E=0|P=1|W=0|G=0
#endif	/* NO_VCACHE */

	!!
	!!  Now, map in the interrupt stack as context==0
	!!
	set	TLB_TAG_ACCESS, %l5
	sethi	%hi(INTSTACK), %l0
	stxa	%l0, [%l5] ASI_DMMU		! Make DMMU point to it
	membar	#Sync				! We may need more membar #Sync in here
	stxa	%l2, [%g0] ASI_DMMU_DATA_IN	! Store it
	membar	#Sync				! We may need more membar #Sync in here
	sethi	%hi(KERNBASE), %o5
	flush	%o5

d3759 1
a3759 1
	 mov	%o0, %l0
d3761 2
a3762 2
	ba,pt	%xcc, cpu_initialize
	 mov	%l0, %g2
@


1.115
log
@Get rid of some dead wood.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.114 2008/03/17 23:10:21 kettenis Exp $	*/
a3658 1
 *	Establish the 4MB locked mappings for kernel data and text.
a3666 24
	/*
	 * Step 5: install the permanent 4MB kernel mapping in both the
	 * immu and dmmu.  We will clear out other mappings later.
	 *
	 * Register usage in this section:
	 *
	 *	%l0 = ktext (also KERNBASE)
	 *	%l1 = ektext
	 *	%l2 = ktextp/TTE Data for text w/o low bits
	 *	%l3 = kdata (also DATA_START)
	 *	%l4 = ekdata
	 *	%l5 = kdatap/TTE Data for data w/o low bits
	 *	%l6 = 4MB
	 *	%l7 = 4MB-1
	 *	%o0-%o5 = tmp
	 */

#ifdef	NO_VCACHE
	!! Turn off D$ in LSU
	ldxa	[%g0] ASI_LSU_CONTROL_REGISTER, %g1
	bclr	MCCR_DCACHE_EN, %g1
	stxa	%g1, [%g0] ASI_LSU_CONTROL_REGISTER
	membar	#Sync
#endif	/* NO_VCACHE */
a3668 106
	sethi	%hi(KERNBASE), %l0		! Find our xlation
	sethi	%hi(DATA_START), %l3

	set	_C_LABEL(ktextp), %l2		! Find phys addr
	ldx	[%l2], %l2			! The following gets ugly:	We need to load the following mask
	set	_C_LABEL(kdatap), %l5
	ldx	[%l5], %l5

	set	_C_LABEL(ektext), %l1		! And the ends...
	ldx	[%l1], %l1
	set	_C_LABEL(ekdata), %l4
	ldx	[%l4], %l4

	sethi	%hi(0xe0000000), %o0		! V=1|SZ=11|NFO=0|IE=0
	sllx	%o0, 32, %o0			! Shift it into place

	sethi	%hi(0x400000), %l6		! Create a 4MB mask
	add	%l6, -1, %l7

	mov	-1, %o1				! Create a nice mask
	sllx	%o1, 41, %o1			! Mask off high bits
	or	%o1, 0xfff, %o1			! We can just load this in 12 (of 13) bits

	andn	%l2, %o1, %l2			! Mask the phys page number
	andn	%l5, %o1, %l5			! Mask the phys page number

	or	%l2, %o0, %l2			! Now take care of the high bits
	or	%l5, %o0, %l5			! Now take care of the high bits

	wrpr	%g0, PSTATE_KERN, %pstate	! Disable interrupts

#ifdef DEBUG
	set	1f, %o0		! Debug printf for TEXT page
	srlx	%l0, 32, %o1
	srl	%l0, 0, %o2
	or	%l2, TLB_L|TLB_CP|TLB_CV|TLB_P, %o4	! And low bits:	L=1|CP=1|CV=1|E=0|P=1|W=1(ugh)|G=0
	srlx	%o4, 32, %o3
	call	_C_LABEL(prom_printf)
	 srl	%o4, 0, %o4

	set	1f, %o0		! Debug printf for DATA page
	srlx	%l3, 32, %o1
	srl	%l3, 0, %o2
	or	%l5, TLB_L|TLB_CP|TLB_CV|TLB_P|TLB_W, %o4	! And low bits:	L=1|CP=1|CV=1|E=0|P=1|W=1(ugh)|G=0
	srlx	%o4, 32, %o3
	call	_C_LABEL(prom_printf)
	 srl	%o4, 0, %o4
	.data
1:
	.asciz	"Setting DTLB entry %08x %08x data %08x %08x\r\n"
	_ALIGN
	.text
#endif	/* DEBUG */
	mov	%l0, %o0			! Demap all of kernel dmmu text segment
	mov	%l3, %o1
	set	0x2000, %o2			! 8K page size
	add	%l1, %l7, %o5			! Extend to 4MB boundary
	andn	%o5, %l7, %o5
0:
	stxa	%o0, [%o0] ASI_DMMU_DEMAP	! Demap text segment
	membar	#Sync
	cmp	%o0, %o5
	bleu	0b
	 add	%o0, %o2, %o0

	add	%l4, %l7, %o5			! Extend to 4MB boundary
	andn	%o5, %l7, %o5
0:	
	stxa	%o1, [%o1] ASI_DMMU_DEMAP	! Demap data segment
	membar	#Sync
	cmp	%o1, %o5
	bleu	0b
	 add	%o1, %o2, %o1

	set	(1<<14)-8, %o0			! Clear out DCACHE
1:
dlflush2:
	stxa	%g0, [%o0] ASI_DCACHE_TAG	! clear DCACHE line
	membar	#Sync
	brnz,pt	%o0, 1b
	 dec	8, %o0

	/*
	 * First map data segment into the DMMU.
	 */
	set	TLB_TAG_ACCESS, %o0		! Now map it back in with a locked TTE
	mov	%l3, %o1
#ifdef NO_VCACHE
	! And low bits:	L=1|CP=1|CV=0(ugh)|E=0|P=1|W=1|G=0
	or	%l5, TLB_L|TLB_CP|TLB_P|TLB_W, %o2
#else	/* NO_VCACHE */
	! And low bits:	L=1|CP=1|CV=1|E=0|P=1|W=1|G=0
	or	%l5, TLB_L|TLB_CP|TLB_CV|TLB_P|TLB_W, %o2
#endif	/* NO_VCACHE */
	set	1f, %o5
2:	
	stxa	%o1, [%o0] ASI_DMMU		! Set VA for DSEG
	membar	#Sync				! We may need more membar #Sync in here
	stxa	%o2, [%g0] ASI_DMMU_DATA_IN	! Store TTE for DSEG
	membar	#Sync				! We may need more membar #Sync in here
	flush	%o5				! Make IMMU see this too
1:
	add	%o1, %l6, %o1			! increment VA
	cmp	%o1, %l4			! Next 4MB mapping....
	blu,pt	%xcc, 2b
	 add	%o2, %l6, %o2			! Increment tag
a3670 164
	 * Next map the text segment into the DMMU so we can get at RODATA.
	 */
	mov	%l0, %o1
#ifdef NO_VCACHE
	! And low bits:	L=1|CP=1|CV=0(ugh)|E=0|P=1|W=0|G=0
	or	%l2, TLB_L|TLB_CP|TLB_P, %o2
#else	/* NO_VCACHE */
	! And low bits:	L=1|CP=1|CV=1|E=0|P=1|W=0|G=0
	or	%l2, TLB_L|TLB_CP|TLB_CV|TLB_P, %o2
#endif	/* NO_VCACHE */
2:	
	stxa	%o1, [%o0] ASI_DMMU		! Set VA for DSEG
	membar	#Sync				! We may need more membar #Sync in here
	stxa	%o2, [%g0] ASI_DMMU_DATA_IN	! Store TTE for DSEG
	membar	#Sync				! We may need more membar #Sync in here
	flush	%o5				! Make IMMU see this too
	add	%o1, %l6, %o1			! increment VA
	cmp	%o1, %l1			! Next 4MB mapping....
	blu,pt	%xcc, 2b
	 add	%o2, %l6, %o2			! Increment tag
	
#ifdef DEBUG
	set	1f, %o0		! Debug printf
	srlx	%l0, 32, %o1
	srl	%l0, 0, %o2
	or	%l2, TLB_L|TLB_CP|TLB_CV|TLB_P, %o4
	srlx	%o4, 32, %o3
	call	_C_LABEL(prom_printf)
	 srl	%o4, 0, %o4
	.data
1:
	.asciz	"Setting ITLB entry %08x %08x data %08x %08x\r\n"
	_ALIGN
	.text
#endif	/* DEBUG */
	/*
	 * Finished the DMMU, now we need to do the IMMU which is more
	 * difficult because we're execting instructions through the IMMU
	 * while we're flushing it.  We need to remap the entire kernel
	 * to a new context, flush the entire context 0 IMMU, map it back
	 * into context 0, switch to context 0, and flush context 1.
	 *
	 * Another interesting issue is that the flush instructions are
	 * translated through the DMMU, therefore we need to enter the
	 * mappings both in the IMMU and the DMMU so we can flush them
	 * correctly.
	 *
	 *  Start by mapping in the kernel text as context==1
	 */
	set	TLB_TAG_ACCESS, %o0
	or	%l0, 1, %o1			! Context = 1
	or	%l2, TLB_CP|TLB_P, %o2		! And low bits:	L=0|CP=1|CV=0|E=0|P=1|G=0
2:	
	stxa	%o1, [%o0] ASI_DMMU		! Make DMMU point to it
	membar	#Sync				! We may need more membar #Sync in here
	stxa	%o2, [%g0] ASI_DMMU_DATA_IN	! Store it
	membar	#Sync				! We may need more membar #Sync in here
	stxa	%o1, [%o0] ASI_IMMU		! Make IMMU point to it
	membar	#Sync				! We may need more membar #Sync in here
	flush	%o1-1				! Make IMMU see this too
	stxa	%o2, [%g0] ASI_IMMU_DATA_IN	! Store it
	membar	#Sync				! We may need more membar #Sync in here
	flush	%o5				! Make IMMU see this too
	add	%o1, %l6, %o1			! increment VA
	cmp	%o1, %l1			! Next 4MB mapping....
	blu,pt	%xcc, 2b
	 add	%o2, %l6, %o2			! Increment tag

	!!
	!! Load 1 as primary context
	!!
	mov	1, %o0
	mov	CTX_PRIMARY, %o1
	stxa	%o0, [%o1] ASI_DMMU
	wrpr	%g0, 0, %tl			! Make SURE we're nucleus mode
	membar	#Sync				! This probably should be a flush, but it works
	flush	%o5				! This should be KERNBASE

	!!
	!! Demap entire context 0 kernel
	!!
	or	%l0, DEMAP_PAGE_NUCLEUS, %o0	! Context = Nucleus
	add	%l1, %l7, %o1			! Demap all of kernel text seg
	andn	%o1, %l7, %o1			! rounded up to 4MB.
	set	0x2000, %o2			! 8K page size
0:
	stxa	%o0, [%o0] ASI_IMMU_DEMAP	! Demap it
	membar	#Sync
	flush	%o5				! Assume low bits are benign
	cmp	%o0, %o1
	bleu,pt	%xcc, 0b			! Next page
	 add	%o0, %o2, %o0

	or	%l3, DEMAP_PAGE_NUCLEUS, %o0	! Context = Nucleus
	add	%l4, %l7, %o1			! Demap all of kernel data seg
	andn	%o1, %l7, %o1			! rounded up to 4MB.
0:
	stxa	%o0, [%o0] ASI_IMMU_DEMAP	! Demap it
	membar	#Sync
	flush	%o5				! Assume low bits are benign
	cmp	%o0, %o1
	bleu,pt	%xcc, 0b			! Next page
	 add	%o0, %o2, %o0

	!!
	!!  Now, map in the kernel text as context==0
	!!
	set	TLB_TAG_ACCESS, %o0
	mov	%l0, %o1			! Context = 0
#ifdef NO_VCACHE
	! And low bits:	L=1|CP=1|CV=0(ugh)|E=0|P=1|W=1|G=0
	or	%l2, TLB_L|TLB_CP|TLB_P, %o2
#else	/* NO_VCACHE */
	! And low bits:	L=1|CP=1|CV=1|E=0|P=1|W=1|G=0
	or	%l2, TLB_L|TLB_CP|TLB_CV|TLB_P, %o2
#endif	/* NO_VCACHE */
2:	
	stxa	%o1, [%o0] ASI_IMMU		! Make IMMU point to it
	membar	#Sync				! We may need more membar #Sync in here
	stxa	%o2, [%g0] ASI_IMMU_DATA_IN	! Store it
	membar	#Sync				! We may need more membar #Sync in here
	flush	%o5				! Make IMMU see this too
	add	%o1, %l6, %o1			! increment VA
	cmp	%o1, %l1			! Next 4MB mapping....
	blu,pt	%xcc, 2b
	 add	%o2, %l6, %o2			! Increment tag

	!!
	!! Restore 0 as primary context
	!!
	mov	CTX_PRIMARY, %o0
	stxa	%g0, [%o0] ASI_DMMU
	membar	#Sync					! No real reason for this XXXX
	flush	%o5
	
	!!
	!! Demap context 1
	!!
	mov	1, %o1
	mov	CTX_SECONDARY, %o0
	stxa	%o1, [%o0] ASI_DMMU
	membar	#Sync				! This probably should be a flush, but it works
	flush	%l0
	mov	DEMAP_CTX_SECONDARY, %o4
	stxa	%o4, [%o4] ASI_DMMU_DEMAP
	membar	#Sync
	stxa	%o4, [%o4] ASI_IMMU_DEMAP
	membar	#Sync
	flush	%l0
	stxa	%g0, [%o0] ASI_DMMU
	membar	#Sync
	flush	%l0

#ifdef DEBUG
	set	1f, %o0		! Debug printf
	call	_C_LABEL(prom_printf)
	.data
1:
	.asciz	"Setting CPUINFO mappings...\r\n"
	_ALIGN
	.text
#endif	/* DEBUG */
	
	/*
d3702 1
d3774 6
a3780 2
	mov	%o0, %g2

d3786 7
a3792 2
	ba	cpu_initialize
	 nop
d4020 1
a4020 1
dlflush3:
d4077 1
a4077 1
dlflush4:
d4132 1
a4132 1
dlflush5:
d5171 1
a5171 1
dlflush6:
a7999 1
	.xword	dlflush6
@


1.114
log
@Remove KGDB code.  It was never converted to 64-bit, and just makes locore.s
even more unreadable.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.113 2008/03/13 20:37:46 kettenis Exp $	*/
a429 24
#if 0
#ifdef DIAGNOSTIC
	!!
	!! Check the sp redzone
	!!
	!! Since we can't spill the current window, we'll just keep
	!! track of the frame pointer.  Problems occur when the routine
	!! allocates and uses stack storage.
	!!
!	rdpr	%wstate, %l5	! User stack?
!	cmp	%l5, WSTATE_KERN
!	bne,pt	%icc, 7f
	 sethi	%hi(CPCB), %l5
	ldx	[%l5 + %lo(CPCB)], %l5	! If pcb < fp < pcb+sizeof(pcb)
	inc	PCB_SIZE, %l5		! then we have a stack overflow
	btst	%fp, 1			! 64-bit stack?
	sub	%fp, %l5, %l7
	bnz,a,pt	%icc, 1f
	 inc	BIAS, %l7		! Remove BIAS
1:
	cmp	%l7, PCB_SIZE
	blu	%xcc, cleanwin_overflow
#endif	/* DIAGNOSTIC */
#endif	/* 0 */
a934 26
/*
 * If the cleanwin trap handler detects an overflow we come here.
 * We need to fix up the window registers, switch to the interrupt
 * stack, and then trap to the debugger.
 */
cleanwin_overflow:
	!! We've already incremented %cleanwin
	!! So restore %cwp
	rdpr	%cwp, %l0
	dec	%l0
	wrpr	%l0, %g0, %cwp
	set	EINTSTACK-BIAS-CC64FSZ, %l0
	save	%l0, 0, %sp

	ta	1		! Enter debugger
	sethi	%hi(1f), %o0
	call	_C_LABEL(panic)
	 or	%o0, %lo(1f), %o0
	restore
	retry
	.data
1:
	.asciz	"Kernel stack overflow!"
	_ALIGN
	.text

a2670 63
#if 0
/*
 * breakpoint:	capture as much info as possible and then call DDB
 * or trap, as the case may be.
 *
 * First, we switch to interrupt globals, and blow away %g7.  Then
 * switch down one stackframe -- just fiddle w/cwp, don't save or
 * we'll trap.  Then slowly save all the globals into our static
 * register buffer.  etc. etc.
 */

breakpoint:
	wrpr	%g0, PSTATE_KERN|PSTATE_IG, %pstate	! Get IG to use
	rdpr	%cwp, %g7
	inc	1, %g7					! Equivalent of save
	wrpr	%g7, 0, %cwp				! Now we have some unused locals to fiddle with
	set	_C_LABEL(ddb_regs), %l0
	stx	%g1, [%l0+DBR_IG+(1*8)]			! Save IGs
	stx	%g2, [%l0+DBR_IG+(2*8)]
	stx	%g3, [%l0+DBR_IG+(3*8)]
	stx	%g4, [%l0+DBR_IG+(4*8)]
	stx	%g5, [%l0+DBR_IG+(5*8)]
	stx	%g6, [%l0+DBR_IG+(6*8)]
	stx	%g7, [%l0+DBR_IG+(7*8)]
	wrpr	%g0, PSTATE_KERN|PSTATE_MG, %pstate	! Get MG to use
	stx	%g1, [%l0+DBR_MG+(1*8)]			! Save MGs
	stx	%g2, [%l0+DBR_MG+(2*8)]
	stx	%g3, [%l0+DBR_MG+(3*8)]
	stx	%g4, [%l0+DBR_MG+(4*8)]
	stx	%g5, [%l0+DBR_MG+(5*8)]
	stx	%g6, [%l0+DBR_MG+(6*8)]
	stx	%g7, [%l0+DBR_MG+(7*8)]
	wrpr	%g0, PSTATE_KERN|PSTATE_AG, %pstate	! Get AG to use
	stx	%g1, [%l0+DBR_AG+(1*8)]			! Save AGs
	stx	%g2, [%l0+DBR_AG+(2*8)]
	stx	%g3, [%l0+DBR_AG+(3*8)]
	stx	%g4, [%l0+DBR_AG+(4*8)]
	stx	%g5, [%l0+DBR_AG+(5*8)]
	stx	%g6, [%l0+DBR_AG+(6*8)]
	stx	%g7, [%l0+DBR_AG+(7*8)]
	wrpr	%g0, PSTATE_KERN, %pstate	! Get G to use
	stx	%g1, [%l0+DBR_G+(1*8)]			! Save Gs
	stx	%g2, [%l0+DBR_G+(2*8)]
	stx	%g3, [%l0+DBR_G+(3*8)]
	stx	%g4, [%l0+DBR_G+(4*8)]
	stx	%g5, [%l0+DBR_G+(5*8)]
	stx	%g6, [%l0+DBR_G+(6*8)]
	stx	%g7, [%l0+DBR_G+(7*8)]
	rdpr	%canrestore, %l1
	stb	%l1, [%l0+DBR_CANRESTORE]
	rdpr	%cansave, %l2
	stb	%l2, [%l0+DBR_CANSAVE]
	rdpr	%cleanwin, %l3
	stb	%l3, [%l0+DBR_CLEANWIN]
	rdpr	%wstate, %l4
	stb	%l4, [%l0+DBR_WSTATE]
	rd	%y, %l5
	stw	%l5, [%l0+DBR_Y]
	rdpr	%tl, %l6
	stb	%l6, [%l0+DBR_TL]
	dec	1, %g7
#endif	/* 0 */

a3279 19
#ifdef notyet
/*
 * Level 12 (ZS serial) interrupt.  Handle it quickly, schedule a
 * software interrupt, and get out.  Do the software interrupt directly
 * if we would just take it on the way out.
 *
 * Input:
 *	%l0 = %psr
 *	%l1 = return pc
 *	%l2 = return npc
 * Internal:
 *	%l3 = zs device
 *	%l4, %l5 = temporary
 *	%l6 = rr3 (or temporary data) + 0x100 => need soft int
 *	%l7 = zs soft status
 */
zshard:
#endif /* notyet */	/* notyet */

a3314 3
	!!
	!! We'll make sure we flush our pcb here, rather than later.
	!!
a3316 7
#if 0
	bnz,pt	%icc, 0f
	 sethi	%hi(CURPROC), %o1
	call	_C_LABEL(rwindow_save)			! Flush out our pcb
	 ldx	[%o1 + %lo(CURPROC)], %o0
0:
#endif	/* 0 */
a4046 8
#ifdef DEBUG
	wrpr	%g0, 1, %tl			! Debug -- start at tl==3 so we'll watchdog
	wrpr	%g0, 0x1ff, %tt			! Debug -- clear out unused trap regs
	wrpr	%g0, 0, %tpc
	wrpr	%g0, 0, %tnpc
	wrpr	%g0, 0, %tstate
#endif	/* DEBUG */

a6179 1
#if 1
a6180 32
#else	/* 1 */
	save	%sp, -(CC64FSZ+FS_SIZE+BLOCK_SIZE), %sp	! Allocate an fpstate
	sethi	%hi(FPPROC), %l1
	ldx	[%l1 + %lo(FPPROC)], %l2		! Load fpproc
	add	%sp, (CC64FSZ+BIAS+BLOCK_SIZE-1), %l0	! Calculate pointer to fpstate
	brz,pt	%l2, 1f					! fpproc == NULL?
	 andn	%l0, BLOCK_ALIGN, %l0			! And make it block aligned
	ldx	[%l2 + P_FPSTATE], %l3
	brz,pn	%l3, 1f					! Make sure we have an fpstate
	 mov	%l3, %o0
	call	_C_LABEL(savefpstate)			! Save the old fpstate
	 set	EINTSTACK-BIAS, %l4			! Are we on intr stack?
	cmp	%sp, %l4
	bgu,pt	%xcc, 1f
	 set	INTSTACK-BIAS, %l4
	cmp	%sp, %l4
	blu	%xcc, 1f
0:
	 sethi	%hi(_C_LABEL(proc0)), %l4		! Yes, use proc0
	ba,pt	%xcc, 2f				! XXXX needs to change to CPUs idle proc
	 or	%l4, %lo(_C_LABEL(proc0)), %l5
1:
	sethi	%hi(CURPROC), %l4			! Use curproc
	ldx	[%l4 + %lo(CURPROC)], %l5
	brz,pn	%l5, 0b					! If curproc is NULL need to use proc0
	 nop
2:
	ldx	[%l5 + P_FPSTATE], %l6			! Save old fpstate
	stx	%l0, [%l5 + P_FPSTATE]			! Insert new fpstate
	stx	%l5, [%l1 + %lo(FPPROC)]		! Set new fpproc
	wr	%g0, FPRS_FEF, %fprs			! Enable FPU
#endif	/* 1 */
a7252 1
#if 1
a7253 18
#else	/* 1 */
#ifdef DEBUG
	ldx	[%l1 + %lo(FPPROC)], %l7
	cmp	%l7, %l5
!	tnz	1		! fpproc has changed!
	ldx	[%l5 + P_FPSTATE], %l7
	cmp	%l7, %l0
	tnz	1		! fpstate has changed!
#endif	/* DEBUG */
	andcc	%l2, %l3, %g0				! If (fpproc && fpstate)
	stx	%l2, [%l1 + %lo(FPPROC)]		! Restore old fproc
	bz,pt	%xcc, 1f				! Skip if no fpstate
	 stx	%l6, [%l5 + P_FPSTATE]			! Restore old fpstate
	
	call	_C_LABEL(loadfpstate)			! Re-load orig fpstate
	 mov	%l3, %o0
1:
#endif	/* 1 */
a7396 1
#if 1
a7397 38
#else	/* 1 */
	!!
	!! This code will allow us to save the fpstate around this
	!! routine and nest FP use in the kernel
	!!
	save	%sp, -(CC64FSZ+FS_SIZE+BLOCK_SIZE), %sp	! Allocate an fpstate
	sethi	%hi(FPPROC), %l1
	ldx	[%l1 + %lo(FPPROC)], %l2		! Load fpproc
	add	%sp, (CC64FSZ+BIAS+BLOCK_SIZE-1), %l0	! Calculate pointer to fpstate
	brz,pt	%l2, 1f					! fpproc == NULL?
	 andn	%l0, BLOCK_ALIGN, %l0			! And make it block aligned
	ldx	[%l2 + P_FPSTATE], %l3
	brz,pn	%l3, 1f					! Make sure we have an fpstate
	 mov	%l3, %o0
	call	_C_LABEL(savefpstate)			! Save the old fpstate
	 set	EINTSTACK-BIAS, %l4			! Are we on intr stack?
	cmp	%sp, %l4
	bgu,pt	%xcc, 1f
	 set	INTSTACK-BIAS, %l4
	cmp	%sp, %l4
	blu	%xcc, 1f
0:
	 sethi	%hi(_C_LABEL(proc0)), %l4		! Yes, use proc0
	ba,pt	%xcc, 2f				! XXXX needs to change to CPU's idle proc
	 or	%l4, %lo(_C_LABEL(proc0)), %l5
1:
	sethi	%hi(CURPROC), %l4			! Use curproc
	ldx	[%l4 + %lo(CURPROC)], %l5
	brz,pn	%l5, 0b					! If curproc is NULL need to use proc0
2:
	mov	%i0, %o0
	mov	%i2, %o2
	ldx	[%l5 + P_FPSTATE], %l6			! Save old fpstate
	mov	%i3, %o3
	stx	%l0, [%l5 + P_FPSTATE]			! Insert new fpstate
	stx	%l5, [%l1 + %lo(FPPROC)]		! Set new fpproc
	wr	%g0, FPRS_FEF, %fprs			! Enable FPU
#endif	/* 1 */
a7438 1
#if 1
a7442 16
#else	/* 1 */
#ifdef DEBUG
	ldx	[%l1 + %lo(FPPROC)], %l7
	cmp	%l7, %l5
!	tnz	1		! fpproc has changed!
	ldx	[%l5 + P_FPSTATE], %l7
	cmp	%l7, %l0
	tnz	1		! fpstate has changed!
#endif	/* DEBUG */
	stx	%g0, [%l1 + %lo(FPPROC)]		! Clear fpproc
	stx	%l6, [%l5 + P_FPSTATE]			! Restore old fpstate
	wr	%g0, 0, %fprs				! Disable FPU
	addcc	%i2, 56, %i2	! Restore the count
	ba,pt	%xcc, Lbzero_longs	! Finish up the remainder
	 restore
#endif	/* 1 */
@


1.113
log
@Remove code to set mmu context to 0.  It should already be set to 0 at that
point; this code is probably a leftover from some code that tried to find
out the number of available context dynamically.

tested by ckuethe@@, jsg@@, sthen@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.112 2008/03/12 20:52:36 kettenis Exp $	*/
a285 10
#ifdef KGDB
/*
 * Another item that must be aligned, easiest to put it here.
 */
KGDB_STACK_SIZE = 2048
	.globl	_C_LABEL(kgdb_stack)
_C_LABEL(kgdb_stack):
	.space	KGDB_STACK_SIZE		! hope this is enough
#endif	/* KGDB */

a401 9
/* breakpoint acts differently under kgdb */
#ifdef KGDB
#define	BPT		VTRAP T_BREAKPOINT, bpt
#define	BPT_KGDB_EXEC	VTRAP T_KGDB_EXEC, bpt
#else	/* KGDB */
#define	BPT		TRAP T_BREAKPOINT
#define	BPT_KGDB_EXEC	TRAP T_KGDB_EXEC
#endif	/* KGDB */

d762 1
a762 1
	BPT			! 0x101 = pseudo breakpoint instruction
d766 1
a766 1
	BPT_KGDB_EXEC		! 0x10a = enter kernel gdb on kernel startup
d921 1
a921 1
	BPT			! 0x101 = pseudo breakpoint instruction
d925 1
a925 1
	BPT_KGDB_EXEC		! 0x10a = enter kernel gdb on kernel startup
a2782 181

/*
 * I will not touch any of the DDB or KGDB stuff until I know what's going
 * on with the symbol table.  This is all still v7/v8 code and needs to be fixed.
 */
#ifdef KGDB
/*
 * bpt is entered on all breakpoint traps.
 * If this is a kernel breakpoint, we do not want to call trap().
 * Among other reasons, this way we can set breakpoints in trap().
 */
bpt:
	set	TSTATE_PRIV, %l4
	andcc	%l4, %l0, %g0		! breakpoint from kernel?
	bz	slowtrap		! no, go do regular trap
	 nop

	/*
	 * Build a trap frame for kgdb_trap_glue to copy.
	 * Enable traps but set ipl high so that we will not
	 * see interrupts from within breakpoints.
	 */
	save	%sp, -CCFSZ-TF_SIZE, %sp		! allocate a trap frame
	TRAP_SETUP -CCFSZ-TF_SIZE
	or	%l0, PSR_PIL, %l4	! splhigh()
	wr	%l4, 0, %psr		! the manual claims that this
	wr	%l4, PSR_ET, %psr	! song and dance is necessary
	std	%l0, [%sp + CCFSZ + 0]	! tf.tf_psr, tf.tf_pc
	mov	%l3, %o0		! trap type arg for kgdb_trap_glue
	rd	%y, %l3
	std	%l2, [%sp + CCFSZ + 8]	! tf.tf_npc, tf.tf_y
	rd	%wim, %l3
	st	%l3, [%sp + CCFSZ + 16]	! tf.tf_wim (a kgdb-only r/o field)
	st	%g1, [%sp + CCFSZ + 20]	! tf.tf_global[1]
	std	%g2, [%sp + CCFSZ + 24]	! etc
	std	%g4, [%sp + CCFSZ + 32]
	std	%g6, [%sp + CCFSZ + 40]
	std	%i0, [%sp + CCFSZ + 48]	! tf.tf_in[0..1]
	std	%i2, [%sp + CCFSZ + 56]	! etc
	std	%i4, [%sp + CCFSZ + 64]
	std	%i6, [%sp + CCFSZ + 72]

	/*
	 * Now call kgdb_trap_glue(); if it returns, call trap().
	 */
	mov	%o0, %l3		! gotta save trap type
	call	_C_LABEL(kgdb_trap_glue)		! kgdb_trap_glue(type, &trapframe)
	 add	%sp, CCFSZ, %o1		! (&trapframe)

	/*
	 * Use slowtrap to call trap---but first erase our tracks
	 * (put the registers back the way they were).
	 */
	mov	%l3, %o0		! slowtrap will need trap type
	ld	[%sp + CCFSZ + 12], %l3
	wr	%l3, 0, %y
	ld	[%sp + CCFSZ + 20], %g1
	ldd	[%sp + CCFSZ + 24], %g2
	ldd	[%sp + CCFSZ + 32], %g4
	b	Lslowtrap_reenter
	 ldd	[%sp + CCFSZ + 40], %g6

/*
 * Enter kernel breakpoint.  Write all the windows (not including the
 * current window) into the stack, so that backtrace works.  Copy the
 * supplied trap frame to the kgdb stack and switch stacks.
 *
 * kgdb_trap_glue(type, tf0)
 *	int type;
 *	struct trapframe *tf0;
 */
	.globl	_C_LABEL(kgdb_trap_glue)
_C_LABEL(kgdb_trap_glue):
	save	%sp, -CCFSZ, %sp

	flushw				! flush all windows
	mov	%sp, %l4		! %l4 = current %sp

	/* copy trapframe to top of kgdb stack */
	set	_C_LABEL(kgdb_stack) + KGDB_STACK_SIZE - 80, %l0
					! %l0 = tfcopy -> end_of_kgdb_stack
	mov	80, %l1
1:	ldd	[%i1], %l2
	inc	8, %i1
	deccc	8, %l1
	std	%l2, [%l0]
	bg	1b
	 inc	8, %l0

#ifdef DEBUG
	/* save old red zone and then turn it off */
	sethi	%hi(_C_LABEL(redzone)), %l7
	ld	[%l7 + %lo(_C_LABEL(redzone))], %l6
	st	%g0, [%l7 + %lo(_C_LABEL(redzone))]
#endif	/* DEBUG */
	/* switch to kgdb stack */
	add	%l0, -CCFSZ-TF_SIZE, %sp

	/* if (kgdb_trap(type, tfcopy)) kgdb_rett(tfcopy); */
	mov	%i0, %o0
	call	_C_LABEL(kgdb_trap)
	add	%l0, -80, %o1
	tst	%o0
	bnz,a	kgdb_rett
	 add	%l0, -80, %g1

	/*
	 * kgdb_trap() did not handle the trap at all so the stack is
	 * still intact.  A simple `restore' will put everything back,
	 * after we reset the stack pointer.
	 */
	mov	%l4, %sp
#ifdef DEBUG
	st	%l6, [%l7 + %lo(_C_LABEL(redzone))]	! restore red zone
#endif	/* DEBUG */
	ret
	 restore

/*
 * Return from kgdb trap.  This is sort of special.
 *
 * We know that kgdb_trap_glue wrote the window above it, so that we will
 * be able to (and are sure to have to) load it up.  We also know that we
 * came from kernel land and can assume that the %fp (%i6) we load here
 * is proper.  We must also be sure not to lower ipl (it is at splhigh())
 * until we have traps disabled, due to the SPARC taking traps at the
 * new ipl before noticing that PSR_ET has been turned off.  We are on
 * the kgdb stack, so this could be disastrous.
 *
 * Note that the trapframe argument in %g1 points into the current stack
 * frame (current window).  We abandon this window when we move %g1->tf_psr
 * into %psr, but we will not have loaded the new %sp yet, so again traps
 * must be disabled.
 */
kgdb_rett:
	rd	%psr, %g4		! turn off traps
	wr	%g4, PSR_ET, %psr
	/* use the three-instruction delay to do something useful */
	ld	[%g1], %g2		! pick up new %psr
	ld	[%g1 + 12], %g3		! set %y
	wr	%g3, 0, %y
#ifdef DEBUG
	st	%l6, [%l7 + %lo(_C_LABEL(redzone))] ! and restore red zone
#endif	/* DEBUG */
	wr	%g0, 0, %wim		! enable window changes
	nop; nop; nop
	/* now safe to set the new psr (changes CWP, leaves traps disabled) */
	wr	%g2, 0, %psr		! set rett psr (including cond codes)
	/* 3 instruction delay before we can use the new window */
/*1*/	ldd	[%g1 + 24], %g2		! set new %g2, %g3
/*2*/	ldd	[%g1 + 32], %g4		! set new %g4, %g5
/*3*/	ldd	[%g1 + 40], %g6		! set new %g6, %g7

	/* now we can use the new window */
	mov	%g1, %l4
	ld	[%l4 + 4], %l1		! get new pc
	ld	[%l4 + 8], %l2		! get new npc
	ld	[%l4 + 20], %g1		! set new %g1

	/* set up returnee's out registers, including its %sp */
	ldd	[%l4 + 48], %i0
	ldd	[%l4 + 56], %i2
	ldd	[%l4 + 64], %i4
	ldd	[%l4 + 72], %i6

	/* load returnee's window, making the window above it be invalid */
	restore
	restore	%g0, 1, %l1		! move to inval window and set %l1 = 1
	rd	%psr, %l0
	srl	%l1, %l0, %l1
	wr	%l1, 0, %wim		! %wim = 1 << (%psr & 31)
	sethi	%hi(CPCB), %l1
	ldx	[%l1 + %lo(CPCB)], %l1
	and	%l0, 31, %l0		! CWP = %psr & 31;
	st	%l0, [%l1 + PCB_WIM]	! cpcb->pcb_wim = CWP;
	save	%g0, %g0, %g0		! back to window to reload
	LOADWIN(%sp)
	save	%g0, %g0, %g0		! back to trap window
	/* note, we have not altered condition codes; safe to just rett */
	RETT
#endif	/* KGDB */
@


1.112
log
@Introduce a per-handler interrupt acknowledgement function.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.111 2008/02/24 19:16:08 kettenis Exp $	*/
d3983 1
a3983 4
	set	CTX_SECONDARY, %o1		! Store -1 in the context register
	set	0x2000,%o0			! fixed: 8192 contexts
	stxa	%g0, [%o1] ASI_DMMU
	membar	#Sync
@


1.111
log
@Remove some bogus 32-bit compatibiliy code and comments.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.110 2008/02/14 19:07:56 kettenis Exp $	*/
d3524 1
a3524 1
	ldx	[%l2 + IH_CLR], %l1	! ih->ih_clear
a3536 1
	stx	%g0, [%l1]		! Clear intr source
d3539 3
@


1.110
log
@Make sure an interrupt handler does not get on the per-cpu list of pending
interrupts twice, with one exception: interrupt handlers are allowed to be on
the tail of said lists (needed for clock interrupts on MP kernels).
Prevents losing interrupts.  Makes usb keyboard as console work on Sun Blade
1000/2000 with MP kernels.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.109 2008/01/16 20:55:36 kettenis Exp $	*/
a5800 4
	!!
	!! If we have 64-bit physical addresses (and we do now)
	!! we need to move the pointer from %o0:%o1 to %o0
	!!
a5819 5
 * We need to use a global reg for ldxa/stxa
 * so the top 32-bits cannot be lost if we take
 * a trap and need to save our stack frame to a
 * 32-bit stack.  We will unroll the loop by 8 to
 * improve performance.
a5824 5
	!!
	!! If we have 64-bit physical addresses (and we do now)
	!! we need to move the pointer from %o0:%o1 to %o0 and
	!! %o2:%o3 to %o1
	!!
a5826 1
	mov	%g1, %o4		! Save g1
d5828 1
a5828 2
	DLFLUSH %o0,%g1
	ldxa	[%o0] ASI_PHYS_CACHED, %g1
d5831 2
a5832 3
	stxa	%g1, [%o1] ASI_PHYS_CACHED
	DLFLUSH %o1,%g1
	bl,pt	%icc, 1b		! We don't care about pages >4GB
d5835 1
a5835 1
	 mov	%o4, %g1		! Restore g1
@


1.109
log
@Simplify spilling register windows into the pcb by storing the stack pointer
seperately from the window and copying out data back to the stack by using the
T_RWRET softtrap and rwindow_save().
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.108 2008/01/12 14:18:46 kettenis Exp $	*/
d3161 1
a3161 3
#ifndef MULTIPROCESSOR
	ldstub  [%g5+IH_BUSY], %g6	! Check if already in use
	membar #LoadLoad | #LoadStore
a3162 1
#endif
a3164 1
	mov	8, %g7			! Number of slots to search
d3170 3
a3172 5
	stx	%g3, [%g5+IH_PEND]	! Link our intrhand node in
	mov	%g5, %g7
	casxa	[%g1] ASI_N, %g3, %g7
	cmp	%g7, %g3		! Did it work?
	bne,pn	%xcc, 1b		! No, try again
d3174 1
a3527 15
	! Note that the function handler itself or an interrupt
	! may add handlers to the pending pending. This includes
	! the current entry in %l2 and entries held on our local
	! pending list in %l7.  The former is ok because we are
	! done with it now and the latter because they are still
	! marked busy. We may also be able to do this by having
	! the soft interrupts use a variation of the hardware
	! interrupts' ih_clr scheme.  Note:  The busy flag does
	! not itself prevent the handler from being entered
	! recursively.  It only indicates that the handler is
	! about to be invoked and that it should not be added
	! to the pending table.
	membar	#StoreStore | #LoadStore
	stb	%g0, [%l2 + IH_BUSY]	! Allow the ih to be reused

d8478 4
a8481 6
	rdpr	%pil, %g1	! s = splx(level)
	!cmp	%g1, %o1
	!bge,pt	%icc, 1f
	! nop
	wrpr	%g0, PIL_HIGH, %pil
1:
d8483 1
a8483 2
	 mov	8, %o4			! Number of slots to search
	set	CPUINFO_VA+CI_INTRPENDING, %o3
d8485 2
a8486 3
	ldstub	[%o2 + IH_BUSY], %o5
	membar #LoadLoad | #LoadStore
	brnz	%o5, 1f
d8489 1
a8489 1
2:
d8491 3
a8493 5
	stx	%o5, [%o2+IH_PEND]	! Link our intrhand node in
	mov	%o2, %o4
	casxa	[%o3] ASI_N, %o5, %o4
	cmp	%o4, %o5		! Did it work?
	bne,pn	%xcc, 2b		! No, try again
d8495 2
a8496 1
1:
d8500 1
d8502 1
a8502 1
	 wrpr	%g1, 0, %pil		! restore IPL
@


1.108
log
@Don't steal a register window in ipi_save_fpstate; it could have bad
consequences if it forces a register window to be spilled into the pcb.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.107 2008/01/03 17:09:42 kettenis Exp $	*/
d2021 7
a2027 17
	stxa	%l0, [%g5 + PCB_RW + ( 0*8)] %asi	! Save the window in the pcb, we can schedule other stuff in here
	stxa	%l1, [%g5 + PCB_RW + ( 1*8)] %asi
	stxa	%l2, [%g5 + PCB_RW + ( 2*8)] %asi
	stxa	%l3, [%g5 + PCB_RW + ( 3*8)] %asi
	stxa	%l4, [%g5 + PCB_RW + ( 4*8)] %asi
	stxa	%l5, [%g5 + PCB_RW + ( 5*8)] %asi
	stxa	%l6, [%g5 + PCB_RW + ( 6*8)] %asi
	stxa	%l7, [%g5 + PCB_RW + ( 7*8)] %asi

	stxa	%i0, [%g5 + PCB_RW + ( 8*8)] %asi
	stxa	%i1, [%g5 + PCB_RW + ( 9*8)] %asi
	stxa	%i2, [%g5 + PCB_RW + (10*8)] %asi
	stxa	%i3, [%g5 + PCB_RW + (11*8)] %asi
	stxa	%i4, [%g5 + PCB_RW + (12*8)] %asi
	stxa	%i5, [%g5 + PCB_RW + (13*8)] %asi
	stxa	%i6, [%g5 + PCB_RW + (14*8)] %asi
	stxa	%i7, [%g5 + PCB_RW + (15*8)] %asi
a2031 2
	inc	16*8, %g5				! Move to next window
	inc	%g7					! inc pcb_nsaved
d2033 1
a2033 1
	 stxa	%o6, [%g5 + PCB_RW + (14*8)] %asi	! Save %sp so we can write these all out
d3792 5
a3797 7
#ifdef DEBUG
	rdpr	%canrestore, %g5		! DEBUG
	tst	%g5				! DEBUG
	tnz	%icc, 1; nop			! DEBUG
!	mov	%g0, %g5			! There shoud be *NO* %canrestore
	add	%g7, %g5, %g7			! DEBUG
#endif	/* DEBUG */
a3798 1
	ldx	[%g6 + %lo(CPCB)], %g6
a3801 1
	ldub	[%g6 + PCB_NSAVED], %g7		! Any saved reg windows?
a3803 109
#ifdef DEBUG
	set	rft_wcnt, %g4	! Keep track of all the windows we restored
	stw	%g7, [%g4]
#endif	/* DEBUG */

	brz,pt	%g7, 5f				! No saved reg wins
	 nop
	dec	%g7				! We can do this now or later.  Move to last entry

#ifdef DEBUG
	rdpr	%canrestore, %g4			! DEBUG Make sure we've restored everything
	brnz,a,pn	%g4, 0f				! DEBUG
	 sir						! DEBUG we should NOT have any usable windows here
0:							! DEBUG
	wrpr	%g0, 5, %tl
#endif	/* DEBUG */
	rdpr	%otherwin, %g4
	sll	%g7, 7, %g5			! calculate ptr into rw64 array 8*16 == 128 or 7 bits
	brz,pt	%g4, 6f				! We should not have any user windows left
	 add	%g5, %g6, %g5

	set	1f, %o0
	mov	%g7, %o1
	mov	%g4, %o2
	call	printf
	 wrpr	%g0, PSTATE_KERN, %pstate
	set	2f, %o0
	call	panic
	 nop
	NOTREACHED
	.data
1:	.asciz	"pcb_nsaved=%x and otherwin=%x\n"
2:	.asciz	"rft_user\n"
	_ALIGN
	.text
6:
3:
	restored					! Load in the window
	restore						! This should not trap!
	ldx	[%g5 + PCB_RW + ( 0*8)], %l0		! Load the window from the pcb
	ldx	[%g5 + PCB_RW + ( 1*8)], %l1
	ldx	[%g5 + PCB_RW + ( 2*8)], %l2
	ldx	[%g5 + PCB_RW + ( 3*8)], %l3
	ldx	[%g5 + PCB_RW + ( 4*8)], %l4
	ldx	[%g5 + PCB_RW + ( 5*8)], %l5
	ldx	[%g5 + PCB_RW + ( 6*8)], %l6
	ldx	[%g5 + PCB_RW + ( 7*8)], %l7

	ldx	[%g5 + PCB_RW + ( 8*8)], %i0
	ldx	[%g5 + PCB_RW + ( 9*8)], %i1
	ldx	[%g5 + PCB_RW + (10*8)], %i2
	ldx	[%g5 + PCB_RW + (11*8)], %i3
	ldx	[%g5 + PCB_RW + (12*8)], %i4
	ldx	[%g5 + PCB_RW + (13*8)], %i5
	ldx	[%g5 + PCB_RW + (14*8)], %i6
	ldx	[%g5 + PCB_RW + (15*8)], %i7

#ifdef DEBUG
	stx	%g0, [%g5 + PCB_RW + (14*8)]		! DEBUG mark that we've saved this one
#endif	/* DEBUG */

	cmp	%g5, %g6
	bgu,pt	%xcc, 3b				! Next one?
	 dec	8*16, %g5

	rdpr	%ver, %g5
	stb	%g0, [%g6 + PCB_NSAVED]			! Clear them out so we won't do this again
	and	%g5, CWP, %g5
	add	%g5, %g7, %g4
	dec	1, %g5					! NWINDOWS-1-1
	wrpr	%g5, 0, %cansave
	wrpr	%g0, 0, %canrestore			! Make sure we have no freeloaders XXX
	wrpr	%g0, WSTATE_USER, %wstate		! Save things to user space
	mov	%g7, %g5				! We already did one restore
4:
	rdpr	%canrestore, %g4
	inc	%g4
	deccc	%g5
	wrpr	%g4, 0, %cleanwin			! Make *sure* we don't trap to cleanwin
	bge,a,pt	%xcc, 4b				! return to starting regwin
	 save	%g0, %g0, %g0				! This may force a datafault

#ifdef DEBUG
	wrpr	%g0, 0, %tl
#endif	/* DEBUG */
	!!
	!! We can't take any save faults in here 'cause they will never be serviced
	!!

#ifdef DEBUG
	sethi	%hi(CPCB), %g5
	ldx	[%g5 + %lo(CPCB)], %g5
	ldub	[%g5 + PCB_NSAVED], %g5		! Any saved reg windows?
	tst	%g5
	tnz	%icc, 1; nop			! Debugger if we still have saved windows
	bne,a	rft_user			! Try starting over again
	 sethi	%hi(CURPROC), %g7
#endif	/* DEBUG */
	/*
	 * Set up our return trapframe so we can recover if we trap from here
	 * on in.
	 */
	wrpr	%g0, 1, %tl			! Set up the trap state
	wrpr	%g2, 0, %tpc
	wrpr	%g3, 0, %tnpc
	ba,pt	%icc, 6f
	 wrpr	%g1, %g0, %tstate

5:
d3813 1
a3813 1
6:
@


1.107
log
@Make slowtrap check the real stack pointer instead of whatever is in %g6.
Should fix PR 5617, 5637 and 5657.

Remove bogus comment as pointed out by miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.106 2007/12/23 15:33:41 kettenis Exp $	*/
d3307 7
a3313 3
	save	%sp, -CC64FSZ, %sp
	mov	CTX_PRIMARY, %o2
	ldxa	[%o2] ASI_DMMU, %g7
d3315 1
a3315 1
	stxa	%g0, [%o2] ASI_DMMU
d3317 24
a3340 9
	sethi	%hi(FPPROC), %o0
	ldx	[%o0 + %lo(FPPROC)], %o0
	cmp	%o0, %g3
	bne,pn	%xcc, 1f
	 nop
	call	savefpstate
	 ldx	[%o0 + P_FPSTATE], %o0
	sethi	%hi(FPPROC), %o0
	stx	%g0, [%o0 + %lo(FPPROC)]	! fpproc = NULL
d3342 15
a3356 2
	mov	CTX_PRIMARY, %o2
	stxa	%g7, [%o2] ASI_DMMU
d3358 1
d3360 1
a3360 1
	 restore
@


1.106
log
@Remove DMMU_MISS_2; it's identical to DMMU_MISS.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.105 2007/12/05 19:43:15 kettenis Exp $	*/
d2674 1
a2674 4
#if 1
/*
 * This code is no longer needed.
 */
d2698 1
a2698 1
	sub	%g5, %g6, %g5
a2750 1
#endif	/* 1 */
@


1.105
log
@Remove some 32-bit compatibility code in pseg_get().
Completely remove pseg_find() since it isn't used.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.104 2007/11/11 19:47:34 kettenis Exp $	*/
d500 1
a500 1
	ldxa	[%g0] ASI_IMMU_8KPTR, %g2	! Load IMMU 8K TSB pointer
d502 1
a502 1
	ldda	[%g2] ASI_NUCLEUS_QUAD_LDD, %g4	!Load TSB tag:data into %g4:%g5
d518 2
a519 2
	ldda	[%g2] ASI_NUCLEUS_QUAD_LDD, %g4	! Load TSB tag:data into %g4:%g5
	brgez,pn %g5, data_miss		!	Entry invalid?  Punt	XXX should be 2f
a530 18
!! this can be just DMMU_MISS -- the only difference
!! between that & this is instruction ordering and #if 0 code -mdw
	.macro DMMU_MISS_2
	ldxa	[%g0] ASI_DMMU_8KPTR, %g2 !	Load DMMU 8K TSB pointer
	ldxa	[%g0] ASI_DMMU, %g1	!	Load DMMU tag target register
	ldda	[%g2] ASI_NUCLEUS_QUAD_LDD, %g4	! Load TSB tag:data into %g4:%g5
	brgez,pn %g5, data_miss		!	Entry invalid?  Punt
	 xor	%g1, %g4, %g4		!	Compare TLB tags
	brnz,pn	%g4, data_miss		!	Got right tag?
	 nop
	CLRTT 10
	stxa	%g5, [%g0] ASI_DMMU_DATA_IN!	Enter new mapping
	retry				!	Try new mapping
1:
	sir
	TA32
	.endm

d893 1
a893 1
	DMMU_MISS_2
@


1.104
log
@Replace next_tick() with simpler C code that I can actually understand.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.103 2007/11/10 10:46:59 kettenis Exp $	*/
a5995 1
!	flushw			! Make sure we don't have stack probs & lose hibits of %o
a6028 2
	 btst	1, %sp
	bz,pn	%icc, 0f				! 64-bit mode?
d6030 1
a6030 12
	retl						! Yes, return full value
	 nop
0:
#if 1
	srl	%o0, 0, %o1
	retl						! No, generate a %o0:%o1 double
	 srlx	%o0, 32, %o0
#else	/* 1 */
	DLFLUSH %o2,%o3
	ldda	[%o2] ASI_PHYS_CACHED, %o0
	DLFLUSH2 %o3
	retl						! No, generate a %o0:%o1 double
a6031 1
#endif	/* 1 */
a6032 1
	clr	%o1
a6117 87
1:
	retl
	 mov	1, %o0

/*
 * extern void pseg_find(struct pmap* %o0, vaddr_t addr %o1, paddr_t spare %o2);
 *
 * Get the paddr for a particular TTE entry.  Returns the TTE's PA on success,
 * 1 if it needs to fill a pseg, and -1 if the address is in the virtual hole.
 * (NB: nobody in pmap checks for the virtual hole, so the system will hang.)
 *  Allocate a page, pass the phys addr in as the spare, and try again.
 * If spare is not NULL it is assumed to be the address of a zeroed physical
 * page that can be used to generate a directory table or page table if needed.
 *
 */
ENTRY(pseg_find)
	!!
	!! However we managed to get here we now have:
	!!
	!! %o0 = *pmap
	!! %o1 = addr
	!! %o2 = spare
	!!
	srax	%o1, HOLESHIFT, %o4			! Check for valid address
	brz,pt	%o4, 0f					! Should be zero or -1
	 inc	%o4					! Make -1 -> 0
	brz,pt	%o4, 0f
	 nop
#ifdef DEBUG
	ta	1					! Break into debugger
#endif	/* DEBUG */
	mov	-1, %o0					! Error -- in hole!
	retl
	 mov	-1, %o1
0:
	ldx	[%o0 + PM_PHYS], %o4			! pmap->pm_segs
	srlx	%o1, STSHIFT, %o5
	and	%o5, STMASK, %o5
	sll	%o5, 3, %o5
	add	%o4, %o5, %o4
2:
	DLFLUSH %o4,%o3
	ldxa	[%o4] ASI_PHYS_CACHED, %o5		! Load page directory pointer
	DLFLUSH2 %o3

	brnz,a,pt	%o5, 0f				! Null pointer?
	 mov	%o5, %o4
	brz,pn	%o2, 1f					! Have a spare?
	 mov	%o2, %o5
	casxa	[%o4] ASI_PHYS_CACHED, %g0, %o5
	brnz,pn	%o5, 2b					! Something changed?
	DLFLUSH %o4, %o5
	mov	%o2, %o4
	clr	%o2					! Mark spare as used
0:
	srlx	%o1, PDSHIFT, %o5
	and	%o5, PDMASK, %o5
	sll	%o5, 3, %o5
	add	%o4, %o5, %o4
2:
	DLFLUSH %o4,%o3
	ldxa	[%o4] ASI_PHYS_CACHED, %o5		! Load table directory pointer
	DLFLUSH2 %o3

	brnz,a,pt	%o5, 0f				! Null pointer?
	 mov	%o5, %o4
	brz,pn	%o2, 1f					! Have a spare?
	 mov	%o2, %o5
	casxa	[%o4] ASI_PHYS_CACHED, %g0, %o5
	brnz,pn	%o5, 2b					! Something changed?
	DLFLUSH %o4, %o4
	mov	%o2, %o4
	clr	%o2					! Mark spare as used
0:
	srlx	%o1, PTSHIFT, %o5			! Convert to ptab offset
	btst	1, %sp
	and	%o5, PTMASK, %o5
	sll	%o5, 3, %o5
	bz,pn	%icc, 0f				! 64-bit mode?
	 add	%o5, %o4, %o0
	retl
	 clr	%o0
0:
	srl	%o0, 0, %o1
	retl						! No, generate a %o0:%o1 double
	 srlx	%o0, 32, %o0

@


1.103
log
@Remove a fair amount of duplicated code by making cpu_mp_startup call
cpu_initialize.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.102 2007/11/09 16:15:28 kettenis Exp $	*/
a8863 65

/*
 * next_tick(long increment)
 *
 * Sets the %tick_cmpr register to fire off in `increment' machine
 * cycles in the future.  Also handles %tick wraparound.  In 32-bit
 * mode we're limited to a 32-bit increment.
 */
	.data
	.align	8
tlimit:
	.xword	0
	.text
ENTRY(next_tick)
	rd	TICK_CMPR, %o2
	rdpr	%tick, %o1

	mov	1, %o3		! Mask off high bits of these registers
	sllx	%o3, 63, %o3
	andn	%o1, %o3, %o1
	andn	%o2, %o3, %o2
	cmp	%o1, %o2	! Did we wrap?  (tick < tick_cmpr)
	bgt,pt	%icc, 1f
	 add	%o1, 1000, %o1	! Need some slack so we don't lose intrs.

	/*
	 * Handle the unlikely case of %tick wrapping.
	 *
	 * This should only happen every 10 years or more.
	 *
	 * We need to increment the time base by the size of %tick in
	 * microseconds.  This will require some divides and multiplies
	 * which can take time.  So we re-read %tick.
	 *
	 */

	/* XXXXX NOT IMPLEMENTED */



1:
	add	%o2, %o0, %o2
	andn	%o2, %o3, %o4
	brlz,pn	%o4, Ltick_ovflw
	 cmp	%o2, %o1	! Has this tick passed?
	blt,pn	%xcc, 1b	! Yes
	 nop

	retl
	 wr	%o2, TICK_CMPR

Ltick_ovflw:
/*
 * When we get here tick_cmpr has wrapped, but we don't know if %tick
 * has wrapped.  If bit 62 is set then we have not wrapped and we can
 * use the current value of %o4 as %tick.  Otherwise we need to return
 * to our loop with %o4 as %tick_cmpr (%o2).
 */
	srlx	%o3, 1, %o5
	btst	%o5, %o1
	bz,pn	%xcc, 1b
	 mov	%o4, %o2
	retl
	 wr	%o2, TICK_CMPR

@


1.102
log
@Call prom_set_trap_table for secondary CPUs too.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.101 2007/11/06 22:20:59 kettenis Exp $	*/
d4064 1
a4064 1
	wr	%o0, FPRS_FEF, %fprs		! Turn on FPU
d4128 4
d4443 2
a4444 2
	 * Step 6: hunt through cpus list and find the one that
	 * matches our UPAID.
a4445 10
	sethi	%hi(_C_LABEL(cpus)), %l1
	ldxa	[%g0] ASI_MID_REG, %l2
	ldx	[%l1 + %lo(_C_LABEL(cpus))], %l1
	srax	%l2, 17, %l2			! Isolate UPAID from CPU reg
	and	%l2, 0x1f, %l2
0:
	ld	[%l1 + CI_UPAID], %l3		! Load UPAID
	cmp	%l3, %l2			! Does it match?
	bne,a,pt	%icc, 0b		! no
	 ldx	[%l1 + CI_NEXT], %l1		! Load next cpu_info pointer
d4447 1
a4447 6

	/*
	 * Get pointer to our cpu_info struct
	 */

	ldx	[%l1 + CI_PADDR], %l1		! Load the interrupt stack's PA
d4555 1
d4559 1
a4559 227
	wr	%o0, FPRS_FEF, %fprs		! Turn on FPU

	wrpr	%g0, 0, %tl			! Make sure we're not in NUCLEUS mode

	flushw

#if 0
	/*
	 * Disable the DCACHE entirely for debug.
	 */
	ldxa	[%g0] ASI_MCCR, %o1
	andn	%o1, MCCR_DCACHE_EN, %o1
	stxa	%o1, [%g0] ASI_MCCR
	membar	#Sync
#endif	/* 0 */

	sethi	%hi(KERNBASE), %l0		! Find our xlation
	sethi	%hi(DATA_START), %l3

	set	_C_LABEL(ktextp), %l2		! Find phys addr
	ldx	[%l2], %l2			! The following gets ugly:	We need to load the following mask
	set	_C_LABEL(kdatap), %l5
	ldx	[%l5], %l5

	set	_C_LABEL(ektext), %l1		! And the ends...
	ldx	[%l1], %l1
	set	_C_LABEL(ekdata), %l4
	ldx	[%l4], %l4

	sethi	%hi(0xe0000000), %o0		! V=1|SZ=11|NFO=0|IE=0
	sllx	%o0, 32, %o0			! Shift it into place

	sethi	%hi(0x400000), %l6		! Create a 4MB mask
	add	%l6, -1, %l7

	mov	-1, %o1				! Create a nice mask
	sllx	%o1, 41, %o1			! Mask off high bits
	or	%o1, 0xfff, %o1			! We can just load this in 12 (of 13) bits

	andn	%l2, %o1, %l2			! Mask the phys page number
	andn	%l5, %o1, %l5			! Mask the phys page number

	or	%l2, %o0, %l2			! Now take care of the high bits
	or	%l5, %o0, %l5			! Now take care of the high bits

	wrpr	%g0, PSTATE_KERN, %pstate	! Disable interrupts

#ifdef DEBUG
	set	1f, %o0		! Debug printf for TEXT page
	srlx	%l0, 32, %o1
	srl	%l0, 0, %o2
	or	%l2, TLB_L|TLB_CP|TLB_CV|TLB_P, %o4	! And low bits:	L=1|CP=1|CV=1|E=0|P=1|W=1(ugh)|G=0
	srlx	%o4, 32, %o3
	call	_C_LABEL(prom_printf)
	 srl	%o4, 0, %o4

	set	1f, %o0		! Debug printf for DATA page
	srlx	%l3, 32, %o1
	srl	%l3, 0, %o2
	or	%l5, TLB_L|TLB_CP|TLB_CV|TLB_P|TLB_W, %o4	! And low bits:	L=1|CP=1|CV=1|E=0|P=1|W=1(ugh)|G=0
	srlx	%o4, 32, %o3
	call	_C_LABEL(prom_printf)
	 srl	%o4, 0, %o4
	.data
1:
	.asciz	"Setting DTLB entry %08x %08x data %08x %08x\r\n"
	_ALIGN
	.text
#endif	/* DEBUG */
	mov	%l0, %o0			! Demap all of kernel dmmu text segment
	mov	%l3, %o1
	set	0x2000, %o2			! 8K page size
	add	%l1, %l7, %o5			! Extend to 4MB boundary
	andn	%o5, %l7, %o5
0:
	stxa	%o0, [%o0] ASI_DMMU_DEMAP	! Demap text segment
	membar	#Sync
	cmp	%o0, %o5
	bleu	0b
	 add	%o0, %o2, %o0

	add	%l4, %l7, %o5			! Extend to 4MB boundary
	andn	%o5, %l7, %o5
0:	
	stxa	%o1, [%o1] ASI_DMMU_DEMAP	! Demap data segment
	membar	#Sync
	cmp	%o1, %o5
	bleu	0b
	 add	%o1, %o2, %o1

	set	(1<<14)-8, %o0			! Clear out DCACHE
1:
dlflush2a:
	stxa	%g0, [%o0] ASI_DCACHE_TAG	! clear DCACHE line
	membar	#Sync
	brnz,pt	%o0, 1b
	 dec	8, %o0

	/*
	 * First map data segment into the DMMU.
	 */
	set	TLB_TAG_ACCESS, %o0		! Now map it back in with a locked TTE
	mov	%l3, %o1
#ifdef NO_VCACHE
	! And low bits:	L=1|CP=1|CV=0(ugh)|E=0|P=1|W=1|G=0
	or	%l5, TLB_L|TLB_CP|TLB_P|TLB_W, %o2
#else	/* NO_VCACHE */
	! And low bits:	L=1|CP=1|CV=1|E=0|P=1|W=1|G=0
	or	%l5, TLB_L|TLB_CP|TLB_CV|TLB_P|TLB_W, %o2
#endif	/* NO_VCACHE */
	set	1f, %o5
2:	
	stxa	%o1, [%o0] ASI_DMMU		! Set VA for DSEG
	membar	#Sync				! We may need more membar #Sync in here
	stxa	%o2, [%g0] ASI_DMMU_DATA_IN	! Store TTE for DSEG
	membar	#Sync				! We may need more membar #Sync in here
	flush	%o5				! Make IMMU see this too
1:
	add	%o1, %l6, %o1			! increment VA
	cmp	%o1, %l4			! Next 4MB mapping....
	blu,pt	%xcc, 2b
	 add	%o2, %l6, %o2			! Increment tag

	/*
	 * Next map the text segment into the DMMU so we can get at RODATA.
	 */
	mov	%l0, %o1
#ifdef NO_VCACHE
	! And low bits:	L=1|CP=1|CV=0(ugh)|E=0|P=1|W=0|G=0
	or	%l2, TLB_L|TLB_CP|TLB_P, %o2
#else	/* NO_VCACHE */
	! And low bits:	L=1|CP=1|CV=1|E=0|P=1|W=0|G=0
	or	%l2, TLB_L|TLB_CP|TLB_CV|TLB_P, %o2
#endif	/* NO_VCACHE */
2:	
	stxa	%o1, [%o0] ASI_DMMU		! Set VA for DSEG
	membar	#Sync				! We may need more membar #Sync in here
	stxa	%o2, [%g0] ASI_DMMU_DATA_IN	! Store TTE for DSEG
	membar	#Sync				! We may need more membar #Sync in here
	flush	%o5				! Make IMMU see this too
	add	%o1, %l6, %o1			! increment VA
	cmp	%o1, %l1			! Next 4MB mapping....
	blu,pt	%xcc, 2b
	 add	%o2, %l6, %o2			! Increment tag
	
#ifdef DEBUG
	set	1f, %o0		! Debug printf
	srlx	%l0, 32, %o1
	srl	%l0, 0, %o2
	or	%l2, TLB_L|TLB_CP|TLB_CV|TLB_P, %o4
	srlx	%o4, 32, %o3
	call	_C_LABEL(prom_printf)
	 srl	%o4, 0, %o4
	.data
1:
	.asciz	"Setting ITLB entry %08x %08x data %08x %08x\r\n"
	_ALIGN
	.text
#endif	/* DEBUG */
	/*
	 * Finished the DMMU, now we need to do the IMMU which is more
	 * difficult because we're execting instructions through the IMMU
	 * while we're flushing it.  We need to remap the entire kernel
	 * to a new context, flush the entire context 0 IMMU, map it back
	 * into context 0, switch to context 0, and flush context 1.
	 *
	 * Another interesting issue is that the flush instructions are
	 * translated through the DMMU, therefore we need to enter the
	 * mappings both in the IMMU and the DMMU so we can flush them
	 * correctly.
	 *
	 *  Start by mapping in the kernel text as context==1
	 */
	set	TLB_TAG_ACCESS, %o0
	or	%l0, 1, %o1			! Context = 1
	or	%l2, TLB_CP|TLB_P, %o2		! And low bits:	L=0|CP=1|CV=0|E=0|P=1|G=0
2:	
	stxa	%o1, [%o0] ASI_DMMU		! Make DMMU point to it
	membar	#Sync				! We may need more membar #Sync in here
	stxa	%o2, [%g0] ASI_DMMU_DATA_IN	! Store it
	membar	#Sync				! We may need more membar #Sync in here
	stxa	%o1, [%o0] ASI_IMMU		! Make IMMU point to it
	membar	#Sync				! We may need more membar #Sync in here
	flush	%o1-1				! Make IMMU see this too
	stxa	%o2, [%g0] ASI_IMMU_DATA_IN	! Store it
	membar	#Sync				! We may need more membar #Sync in here
	flush	%o5				! Make IMMU see this too
	add	%o1, %l6, %o1			! increment VA
	cmp	%o1, %l1			! Next 4MB mapping....
	blu,pt	%xcc, 2b
	 add	%o2, %l6, %o2			! Increment tag

	!!
	!! Load 1 as primary context
	!!
	mov	1, %o0
	mov	CTX_PRIMARY, %o1
	stxa	%o0, [%o1] ASI_DMMU
	wrpr	%g0, 0, %tl			! Make SURE we're nucleus mode
	membar	#Sync				! This probably should be a flush, but it works
	flush	%o5				! This should be KERNBASE

	!!
	!! Demap entire context 0 kernel
	!!
	or	%l0, DEMAP_PAGE_NUCLEUS, %o0	! Context = Nucleus
	add	%l1, %l7, %o1			! Demap all of kernel text seg
	andn	%o1, %l7, %o1			! rounded up to 4MB.
	set	0x2000, %o2			! 8K page size
0:
	stxa	%o0, [%o0] ASI_IMMU_DEMAP	! Demap it
	membar	#Sync
	flush	%o5				! Assume low bits are benign
	cmp	%o0, %o1
	bleu,pt	%xcc, 0b			! Next page
	 add	%o0, %o2, %o0

	or	%l3, DEMAP_PAGE_NUCLEUS, %o0	! Context = Nucleus
	add	%l4, %l7, %o1			! Demap all of kernel data seg
	andn	%o1, %l7, %o1			! rounded up to 4MB.
0:
	stxa	%o0, [%o0] ASI_IMMU_DEMAP	! Demap it
	membar	#Sync
	flush	%o5				! Assume low bits are benign
	cmp	%o0, %o1
	bleu,pt	%xcc, 0b			! Next page
	 add	%o0, %o2, %o0
d4561 1
a4561 148
	!!
	!!  Now, map in the kernel text as context==0
	!!
	set	TLB_TAG_ACCESS, %o0
	mov	%l0, %o1			! Context = 0
#ifdef NO_VCACHE
	! And low bits:	L=1|CP=1|CV=0(ugh)|E=0|P=1|W=1|G=0
	or	%l2, TLB_L|TLB_CP|TLB_P, %o2
#else	/* NO_VCACHE */
	! And low bits:	L=1|CP=1|CV=1|E=0|P=1|W=1|G=0
	or	%l2, TLB_L|TLB_CP|TLB_CV|TLB_P, %o2
#endif	/* NO_VCACHE */
2:	
	stxa	%o1, [%o0] ASI_IMMU		! Make IMMU point to it
	membar	#Sync				! We may need more membar #Sync in here
	stxa	%o2, [%g0] ASI_IMMU_DATA_IN	! Store it
	membar	#Sync				! We may need more membar #Sync in here
	flush	%o5				! Make IMMU see this too
	add	%o1, %l6, %o1			! increment VA
	cmp	%o1, %l1			! Next 4MB mapping....
	blu,pt	%xcc, 2b
	 add	%o2, %l6, %o2			! Increment tag

	!!
	!! Restore 0 as primary context
	!!
	mov	CTX_PRIMARY, %o0
	stxa	%g0, [%o0] ASI_DMMU
	membar	#Sync					! No real reason for this XXXX
	flush	%o5
	
	!!
	!! Demap context 1
	!!
	mov	1, %o1
	mov	CTX_SECONDARY, %o0
	stxa	%o1, [%o0] ASI_DMMU
	membar	#Sync				! This probably should be a flush, but it works
	flush	%l0
	mov	DEMAP_CTX_SECONDARY, %o4
	stxa	%o4, [%o4] ASI_DMMU_DEMAP
	membar	#Sync
	stxa	%o4, [%o4] ASI_IMMU_DEMAP
	membar	#Sync
	flush	%l0
	stxa	%g0, [%o0] ASI_DMMU
	membar	#Sync
	flush	%l0

#ifdef DEBUG
	set	1f, %o0		! Debug printf
	call	_C_LABEL(prom_printf)
	.data
1:
	.asciz	"Setting CPUINFO mappings...\r\n"
	_ALIGN
	.text
#endif	/* DEBUG */
	
	/*
	 * Get pointer to our cpu_info struct
	 */

	mov	%g2, %l1			! Load the interrupt stack's PA

	sethi	%hi(0xa0000000), %l2		! V=1|SZ=01|NFO=0|IE=0
	sllx	%l2, 32, %l2			! Shift it into place

	mov	-1, %l3				! Create a nice mask
	sllx	%l3, 41, %l4			! Mask off high bits
	or	%l4, 0xfff, %l4			! We can just load this in 12 (of 13) bits

	andn	%l1, %l4, %l1			! Mask the phys page number

	or	%l2, %l1, %l1			! Now take care of the high bits
#ifdef NO_VCACHE
	or	%l1, TLB_L|TLB_CP|TLB_P|TLB_W, %l2	! And low bits:	L=1|CP=1|CV=0|E=0|P=1|W=0|G=0
#else	/* NO_VCACHE */
	or	%l1, TLB_L|TLB_CP|TLB_CV|TLB_P|TLB_W, %l2	! And low bits:	L=1|CP=1|CV=1|E=0|P=1|W=0|G=0
#endif	/* NO_VCACHE */

	!!
	!!  Now, map in the interrupt stack as context==0
	!!
	set	TLB_TAG_ACCESS, %l5
	sethi	%hi(INTSTACK), %l0
	stxa	%l0, [%l5] ASI_DMMU		! Make DMMU point to it
	membar	#Sync				! We may need more membar #Sync in here
	stxa	%l2, [%g0] ASI_DMMU_DATA_IN	! Store it
	membar	#Sync				! We may need more membar #Sync in here
	flush	%o5

	!!
	!! Set 0 as primary context XXX
	!!
	mov	CTX_PRIMARY, %o0
	stxa	%g0, [%o0] ASI_DMMU
	flush	%o5

!!! Make sure our stack's OK.
	sethi	%hi(CPUINFO_VA+CI_INITSTACK), %l0
	ldx	[%l0 + %lo(CPUINFO_VA+CI_INITSTACK)], %l0
 	add	%l0, - CC64FSZ - 80, %l0
	andn	%l0, 0x0f, %l0			! Needs to be 16-byte aligned
	sub	%l0, BIAS, %l0			! and biased
	mov	%l0, %sp
	set	1, %fp
	clr	%i7

	/*
	 * Step 7: change the trap base register, and install our TSBs
	 */

	/* Set the dmmu tsb */
	sethi	%hi(0x1fff), %l2
	set	_C_LABEL(tsb_dmmu), %l0
	ldx	[%l0], %l0
	set	_C_LABEL(tsbsize), %l1
	or	%l2, %lo(0x1fff), %l2
	ld	[%l1], %l1
	andn	%l0, %l2, %l0			! Mask off size and split bits
	or	%l0, %l1, %l0			! Make a TSB pointer
	set	TSB, %l2
	stxa	%l0, [%l2] ASI_DMMU		! Install data TSB pointer
	membar	#Sync


	/* Set the immu tsb */
	sethi	%hi(0x1fff), %l2
	set	_C_LABEL(tsb_immu), %l0
	ldx	[%l0], %l0
	set	_C_LABEL(tsbsize), %l1
	or	%l2, %lo(0x1fff), %l2
	ld	[%l1], %l1
	andn	%l0, %l2, %l0			! Mask off size and split bits
	or	%l0, %l1, %l0			! Make a TSB pointer
	set	TSB, %l2
	stxa	%l0, [%l2] ASI_IMMU		! Install instruction TSB pointer
	membar	#Sync				! We may need more membar #Sync in here

	/* Change the trap base register */
	set	_C_LABEL(trapbase), %l1
	call	_C_LABEL(prom_set_trap_table)	! Now we should be running 100% from our handlers
	 mov	%l1, %o0
	wrpr	%l1, 0, %tba			! Make sure the PROM didn't foul up.
	wrpr	%g0, WSTATE_KERN, %wstate

	call	_C_LABEL(cpu_hatch)
a4562 1
	NOTREACHED
a9063 3
#ifdef MULTIPROCESSOR
	.xword	dlflush2a
#endif
@


1.101
log
@Close a race where we might save/drop the fpu state of the wrong process in
the ipi handlers.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.100 2007/10/31 21:29:04 kettenis Exp $	*/
d4939 2
a4940 2
	!call	_C_LABEL(prom_set_trap_table)	! Now we should be running 100% from our handlers
	! mov	%l1, %o0
@


1.100
log
@Remove idle_u; it's been unused for a while.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.99 2007/10/31 20:20:39 kettenis Exp $	*/
d3337 2
a3338 1
	brz,pn	%o0, 1f
d3357 6
d3364 1
a3364 1
	 stx	%g0, [%g1 + %lo(FPPROC)]	! fpproc = NULL
@


1.99
log
@Remove some comments about 32-bit mode.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.98 2007/10/31 20:14:33 kettenis Exp $	*/
a277 12
 * When a process exits and its u. area goes away, we set cpcb to point
 * to this `u.', leaving us with something to use for an interrupt stack,
 * and letting all the register save code have a pcb_uw to examine.
 * This is also carefully arranged (to come just before u0, so that
 * process 0's kernel stack can quietly overrun into it during bootup, if
 * we feel like doing that).
 */
	.globl	_C_LABEL(idle_u)
_C_LABEL(idle_u):
	.space	USPACE

/*
d1138 1
a1138 1
	.xword	_C_LABEL(idle_u) + REDSIZE
@


1.98
log
@Garbage collect ienab_bis() and ienab_bic().

Suggested by miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.97 2007/10/29 21:27:25 kettenis Exp $	*/
a6441 7
 * In 32-bit mode:
 *
 * extern int pseg_set(struct pmap* %o0, vaddr_t addr %o1, int64_t tte %o2:%o3,
 *			 paddr_t spare %o4:%o5);
 *
 * In 64-bit mode:
 *
a6527 7
 * In 32-bit mode:
 *
 * extern void pseg_find(struct pmap* %o0, vaddr_t addr %o1,
 *			 paddr_t spare %o2:%o3);
 *
 * In 64-bit mode:
 *
@


1.97
log
@UltraSPARC CPUs (and other SPARC V9 implementations) don't have a
floating-point deferred-trap queue.  Remove redundant code inherited from
sparc that deals with this.  Also remove the code dealing with saving and
restoring the FPU state from unaligned memory; we always allocate properly
aligned memory for storing the FPU state.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.96 2007/10/27 20:04:28 miod Exp $	*/
a9100 18

/*
 * ienab_bis(bis) int bis;
 * ienab_bic(bic) int bic;
 *
 * Set and clear bits in the interrupt register.
 */

/*
 * sun4u has separate asr's for clearing/setting the interrupt mask.
 */
ENTRY(ienab_bis)
	retl
	 wr	%o0, 0, SET_SOFTINT	! SET_SOFTINT

ENTRY(ienab_bic)
	retl
	 wr	%o0, 0, CLEAR_SOFTINT	! CLEAR_SOFTINT
@


1.96
log
@Since ipis are not synchronous, make sure that ci_fpproc is not NULL before
invoking savefpstate in ipi_save_fpstate. ok kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.95 2007/10/27 17:17:23 kettenis Exp $	*/
d716 2
a717 2
	VTRAP T_FP_IEEE_754, fp_exception		! 021 = ieee 754 exception
	VTRAP T_FP_OTHER, fp_exception		! 022 = other fp exception
d878 2
a879 2
	VTRAP T_FP_IEEE_754, fp_exception		! 021 = ieee 754 exception
	VTRAP T_FP_OTHER, fp_exception		! 022 = other fp exception
a2558 23
 * fp_exception has to check to see if we are trying to save
 * the FP state, and if so, continue to save the FP state.
 *
 * We do not even bother checking to see if we were in kernel mode,
 * since users have no access to the special_fp_store instruction.
 *
 * This whole idea was stolen from Sprite.
 */
/*
 * XXX I don't think this is at all revelent for V9.
 */
fp_exception:
	rdpr	%tpc, %g1
	set	special_fp_store, %g4	! see if we came from the special one
	cmp	%g1, %g4		! pc == special_fp_store?
	bne	slowtrap		! no, go handle per usual
	 sethi	%hi(savefpcont), %g4	! yes, "return" to the special code
	or	%lo(savefpcont), %g4, %g4
	wrpr	%g0, %g4, %tnpc
	 done
	NOTREACHED

/*
d8978 1
a8978 1
 * savefpstate(f) struct fpstate *f;
d8980 1
a8980 2
 * Store the current FPU state.  The first `st %fsr' may cause a trap;
 * our trap handler knows how to recover (by `returning' to savefpcont).
a8987 1
!	flushw			! Make sure we don't have stack probs & lose hibits of %o
d8993 1
a8993 5
	/* do some setup work while we wait for PSR_EF to turn on */
	set	FSR_QNE, %o2		! QNE = 0x2000, too big for immediate
	clr	%o3			! qsize = 0;
special_fp_store:
	/* This may need to be done w/rdpr/stx combo */
d8995 1
a8995 8
	/*
	 * Even if the preceding instruction did not trap, the queue
	 * is not necessarily empty: this state save might be happening
	 * because user code tried to store %fsr and took the FPU
	 * from `exception pending' mode to `exception' mode.
	 * So we still have to check the blasted QNE bit.
	 * With any luck it will usually not be set.
	 */
d8999 1
a8999 8
	ldx	[%o0 + FS_FSR], %o4	! if (f->fs_fsr & QNE)
	btst	%o2, %o4
	add	%o0, FS_REGS, %o2
	bnz	Lfp_storeq		!	goto storeq;
Lfp_finish:
	 btst	BLOCK_ALIGN, %o2	! Needs to be re-executed
	bnz,pn	%icc, 3f		! Check alignment
	 st	%o3, [%o0 + FS_QSIZE]	! f->fs_qsize = qsize;
a9021 90
3:
#ifdef DIAGNOSTIC
	btst	7, %o2			! 32-bit aligned!?!?
	bnz,pn	%icc, 6f
#endif	/* DIAGNOSTIC */
	 btst	FPRS_DL, %o5		! Lower FPU clean?
	bz,a,pt	%icc, 4f		! Then skip it
	 add	%o0, 128, %o0

	membar	#Sync
	std	%f0, [%o0 + FS_REGS + (4*0)]	! f->fs_f0 = etc;
	std	%f2, [%o0 + FS_REGS + (4*2)]
	std	%f4, [%o0 + FS_REGS + (4*4)]
	std	%f6, [%o0 + FS_REGS + (4*6)]
	std	%f8, [%o0 + FS_REGS + (4*8)]
	std	%f10, [%o0 + FS_REGS + (4*10)]
	std	%f12, [%o0 + FS_REGS + (4*12)]
	std	%f14, [%o0 + FS_REGS + (4*14)]
	std	%f16, [%o0 + FS_REGS + (4*16)]
	std	%f18, [%o0 + FS_REGS + (4*18)]
	std	%f20, [%o0 + FS_REGS + (4*20)]
	std	%f22, [%o0 + FS_REGS + (4*22)]
	std	%f24, [%o0 + FS_REGS + (4*24)]
	std	%f26, [%o0 + FS_REGS + (4*26)]
	std	%f28, [%o0 + FS_REGS + (4*28)]
	std	%f30, [%o0 + FS_REGS + (4*30)]
4:
	btst	FPRS_DU, %o5		! Upper FPU clean?
	bz,pt	%icc, 5f		! Then skip it
	 nop

	membar	#Sync
	std	%f32, [%o0 + FS_REGS + (4*32)]
	std	%f34, [%o0 + FS_REGS + (4*34)]
	std	%f36, [%o0 + FS_REGS + (4*36)]
	std	%f38, [%o0 + FS_REGS + (4*38)]
	std	%f40, [%o0 + FS_REGS + (4*40)]
	std	%f42, [%o0 + FS_REGS + (4*42)]
	std	%f44, [%o0 + FS_REGS + (4*44)]
	std	%f46, [%o0 + FS_REGS + (4*46)]
	std	%f48, [%o0 + FS_REGS + (4*48)]
	std	%f50, [%o0 + FS_REGS + (4*50)]
	std	%f52, [%o0 + FS_REGS + (4*52)]
	std	%f54, [%o0 + FS_REGS + (4*54)]
	std	%f56, [%o0 + FS_REGS + (4*56)]
	std	%f58, [%o0 + FS_REGS + (4*58)]
	std	%f60, [%o0 + FS_REGS + (4*60)]
	std	%f62, [%o0 + FS_REGS + (4*62)]
5:
	membar	#Sync
	retl
	 wr	%g0, FPRS_FEF, %fprs		! Mark FPU clean

	!!
	!! Damn thing is *NOT* aligned on a 64-bit boundary
	!! 
6:
	wr	%g0, FPRS_FEF, %fprs
	ta	1
	retl
	 nop
	
/*
 * Store the (now known nonempty) FP queue.
 * We have to reread the fsr each time in order to get the new QNE bit.
 *
 * UltraSPARCs don't have floating point queues.
 */
Lfp_storeq:
	add	%o0, FS_QUEUE, %o1	! q = &f->fs_queue[0];
1:
	rdpr	%fq, %o4
	stx	%o4, [%o1 + %o3]	! q[qsize++] = fsr_qfront();
	stx	%fsr, [%o0 + FS_FSR] 	! reread fsr
	ldx	[%o0 + FS_FSR], %o4	! if fsr & QNE, loop
	btst	%o5, %o4
	bnz	1b
	 inc	8, %o3
	b	Lfp_finish		! set qsize and finish storing fregs
	 srl	%o3, 3, %o3		! (but first fix qsize)

/*
 * The fsr store trapped.  Do it again; this time it will not trap.
 * We could just have the trap handler return to the `st %fsr', but
 * if for some reason it *does* trap, that would lock us into a tight
 * loop.  This way we panic instead.  Whoopee.
 */
savefpcont:
	b	special_fp_store + 4	! continue
	 stx	%fsr, [%o0 + FS_FSR]	! but first finish the %fsr store
a9027 1
	flushw			! Make sure we don't have stack probs & lose hibits of %o
d9036 1
a9036 3
	btst	BLOCK_ALIGN, %o3
	bne,pt	%icc, 1f	! Only use block loads on aligned blocks
	 wr	%o4, %g0, %gsr
a9047 49
1:
#ifdef DIAGNOSTIC
	btst	7, %o3
	bne,pn	%icc, 1f
	 nop
#endif	/* DIAGNOSTIC */
	/* Unaligned -- needs to be done the long way
	membar	#Sync
	ldd	[%o3 + (4*0)], %f0
	ldd	[%o3 + (4*2)], %f2
	ldd	[%o3 + (4*4)], %f4
	ldd	[%o3 + (4*6)], %f6
	ldd	[%o3 + (4*8)], %f8
	ldd	[%o3 + (4*10)], %f10
	ldd	[%o3 + (4*12)], %f12
	ldd	[%o3 + (4*14)], %f14
	ldd	[%o3 + (4*16)], %f16
	ldd	[%o3 + (4*18)], %f18
	ldd	[%o3 + (4*20)], %f20
	ldd	[%o3 + (4*22)], %f22
	ldd	[%o3 + (4*24)], %f24
	ldd	[%o3 + (4*26)], %f26
	ldd	[%o3 + (4*28)], %f28
	ldd	[%o3 + (4*30)], %f30
	ldd	[%o3 + (4*32)], %f32
	ldd	[%o3 + (4*34)], %f34
	ldd	[%o3 + (4*36)], %f36
	ldd	[%o3 + (4*38)], %f38
	ldd	[%o3 + (4*40)], %f40
	ldd	[%o3 + (4*42)], %f42
	ldd	[%o3 + (4*44)], %f44
	ldd	[%o3 + (4*46)], %f46
	ldd	[%o3 + (4*48)], %f48
	ldd	[%o3 + (4*50)], %f50
	ldd	[%o3 + (4*52)], %f52
	ldd	[%o3 + (4*54)], %f54
	ldd	[%o3 + (4*56)], %f56
	ldd	[%o3 + (4*58)], %f58
	ldd	[%o3 + (4*60)], %f60
 	ldd	[%o3 + (4*62)], %f62
	membar	#Sync
	retl
	 wr	%g0, FPRS_FEF, %fprs	! Clear dirty bits

1:
	wr	%g0, FPRS_FEF, %fprs	! Clear dirty bits
	ta	1
	retl
	 nop
@


1.95
log
@Don't do unecessary work in cpu_switchto().
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.94 2007/10/20 21:08:31 kettenis Exp $	*/
d3372 2
d3378 1
@


1.94
log
@Ack IRQ *after* fetching IPI args.  From NetBSD.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.93 2007/10/20 16:54:52 miod Exp $	*/
a6021 1
	flushw				! We don't have anything else to run, so why not flush
a6030 2
	stx	%o7, [%l5 + PCB_PC]	! cpcb->pcb_pc = pc;
	sth	%o1, [%l5 + PCB_PSTATE]	! cpcb->pcb_pstate = oldpstate;
d6033 2
a6034 1
	 * PHASE TWO: NEW REGISTER USAGE:
d6043 2
a6044 2
	 *	%o1 = tmp 2
	 *	%o2 = tmp 3
a6080 1
	flushw				! DEBUG -- make sure we don't hold on to any garbage
a6083 1
wb1:
d6085 3
a6087 2
	stx	%i7, [%l5 + PCB_PC]	! Save rpc
	stx	%i6, [%l5 + PCB_SP]
d6105 1
a6105 1
	wrpr	%g0, 0, %otherwin	! These two instructions should be redundant
@


1.93
log
@Make sure to send an ipi to the processor a given proc runs on in signotify(),
in the MULTIPROCESOR case.
ok kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.92 2007/10/20 16:41:46 miod Exp $	*/
a3178 2
	stxa	%g0, [%g0] ASI_IRSR	! Ack IRQ
	membar	#Sync			! Should not be needed due to retry
d3187 1
a3187 1
        ldxa    [%g3] ASI_IRDR, %g3     ! Get IPI handler arg0
d3189 5
d3195 1
a3195 1
         ldxa   [%g5] ASI_IRDR, %g5     ! Get IPI handler arg1
d3204 3
@


1.92
log
@enuf -> enough
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.91 2007/10/17 21:39:44 kettenis Exp $	*/
d3384 4
@


1.91
log
@Use ldx (instead of ld) to load a pointer.

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.90 2007/10/17 21:30:08 kettenis Exp $	*/
d4090 1
a4090 1
	blt	1f			! Not enuff args
@


1.90
log
@MULTIPROCESSOR kernels need clock interrupts on secondary CPUs too, so don't
mark interrupts as busy.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.89 2007/10/17 21:23:28 kettenis Exp $	*/
d4466 1
a4466 1
	 ld	[%l1 + CI_NEXT], %l1		! Load next cpu_info pointer
@


1.89
log
@Spin up secondary CPUs on MULTIPROCESSOR kernels.  Works on UltraSPARC-III
CPUs.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.88 2007/10/17 20:16:11 kettenis Exp $	*/
d3224 1
d3228 1
@


1.88
log
@Get proc_trampoline() ready for MULTIPROCESSOR.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.87 2007/10/17 19:25:22 kettenis Exp $	*/
d4576 386
d9658 3
@


1.87
log
@Proper TLB flushing for MULTIPROCESSOR kernels.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.86 2007/10/16 21:44:25 kettenis Exp $	*/
d5816 6
@


1.86
log
@For MULTIPROCESSOR kernels, make cpu_switchto() set p->p_cpu.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.85 2007/10/16 19:22:49 kettenis Exp $	*/
d4624 1
a4624 1
	.globl	_C_LABEL(tlb_flush_pte)
d4626 2
a4627 2
	FTYPE(tlb_flush_pte)
_C_LABEL(tlb_flush_pte):
d4705 1
a4705 1
	.globl	_C_LABEL(tlb_flush_ctx)
d4707 2
a4708 2
	FTYPE(tlb_flush_ctx)
_C_LABEL(tlb_flush_ctx):
@


1.85
log
@Make lazy fpu context switching work for MULTIPROCESSOR kernels.  Tested by
many.

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.84 2007/10/10 15:53:53 art Exp $	*/
a5667 1
	 * XXXSMP
d5670 3
@


1.84
log
@Make context switching much more MI:
 - Move the functionality of choosing a process from cpu_switch into
   a much simpler function: cpu_switchto. Instead of having the locore
   code walk the run queues, let the MI code choose the process we
   want to run and only implement the context switching itself in MD
   code.
 - Let MD context switching run without worrying about spls or locks.
 - Instead of having the idle loop implemented with special contexts
   in MD code, implement one idle proc for each cpu. make the idle
   loop MI with MD hooks.
 - Change the proc lists from the old style vax queues to TAILQs.
 - Change the sleep queue from vax queues to TAILQs. This makes
   wakeup() go from O(n^2) to O(n)

there will be some MD fallout, but it will be fixed shortly.
There's also a few cleanups to be done after this.

deraadt@@, kettenis@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.83 2007/09/30 21:34:20 kettenis Exp $	*/
d3354 28
d8581 12
@


1.83
log
@Move intrpending array into 'struct cpu_info'.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.82 2007/09/22 20:04:51 kettenis Exp $	*/
a5575 188

	.data
	_ALIGN
/*
 * Switch statistics (for later tweaking):
 *	nswitchdiff = p1 => p2 (i.e., chose different process)
 *	nswitchexit = number of calls to switchexit()
 *	_cnt.v_swtch = total calls to swtch+swtchexit
 */
	.comm	_C_LABEL(nswitchdiff), 4
	.comm	_C_LABEL(nswitchexit), 4
	.text
/*
 * REGISTER USAGE IN cpu_switch AND switchexit:
 * This is split into two phases, more or less
 * `before we locate a new proc' and `after'.
 * Some values are the same in both phases.
 * Note that the %o0-registers are not preserved across
 * the psr change when entering a new process, since this
 * usually changes the CWP field (hence heavy usage of %g's).
 *
 *	%l1 = <free>; newpcb
 *	%l2 = %hi(_whichqs); newpsr
 *	%l3 = p
 *	%l4 = lastproc
 *	%l5 = oldpsr (excluding ipl bits)
 *	%l6 = %hi(cpcb)
 *	%l7 = %hi(curproc)
 *	%o0 = tmp 1
 *	%o1 = tmp 2
 *	%o2 = tmp 3
 *	%o3 = tmp 4; whichqs; vm
 *	%o4 = tmp 4; which; sswap
 *	%o5 = tmp 5; q; <free>
 */

/*
 * switchexit is called only from cpu_exit() before the current process
 * has freed its vmspace and kernel stack; we must schedule them to be
 * freed.  (curproc is already NULL.)
 *
 * We lay the process to rest by changing to the `idle' kernel stack,
 * and note that the `last loaded process' is nonexistent.
 */
ENTRY(switchexit)
	/*
	 * Since we're exiting we don't need to save locals or ins, so
	 * we won't need the next instruction.
	 */
!	save	%sp, -CC64FSZ, %sp
	flushw				! We don't have anything else to run, so why not
#ifdef DEBUG
	save	%sp, -CC64FSZ, %sp
	flushw
	restore
#endif	/* DEBUG */
	wrpr	%g0, PSTATE_KERN, %pstate ! Make sure we're on the right globals
	mov	%o0, %l2		! save proc arg for exit2() call XXXXX

	/*
	 * Change pcb to idle u. area, i.e., set %sp to top of stack
	 * and %psr to PSR_S|PSR_ET, and set cpcb to point to _idle_u.
	 * Once we have left the old stack, we can call kmem_free to
	 * destroy it.  Call it any sooner and the register windows
	 * go bye-bye.
	 */
	set	_C_LABEL(idle_u), %l1
	sethi	%hi(CPCB), %l6
#if 0
	/* Get rid of the stack	*/
	rdpr	%ver, %o0
	wrpr	%g0, 0, %canrestore	! Fixup window state regs
	and	%o0, 0x0f, %o0
	wrpr	%g0, 0, %otherwin
	wrpr	%g0, %o0, %cleanwin	! kernel don't care, but user does
	dec	1, %o0			! What happens if we don't subtract 2?
	wrpr	%g0, %o0, %cansave
	flushw						! DEBUG
#endif	/* 0 */

	stx	%l1, [%l6 + %lo(CPCB)]	! cpcb = &idle_u
	set	_C_LABEL(idle_u) + USPACE - CC64FSZ, %o0	! set new %sp
	sub	%o0, BIAS, %sp		! Maybe this should be a save?
	wrpr	%g0, 0, %canrestore
	wrpr	%g0, 0, %otherwin
	rdpr	%ver, %l7
	and	%l7, CWP, %l7
	wrpr	%l7, 0, %cleanwin
	dec	1, %l7					! NWINDOWS-1-1
	wrpr	%l7, %cansave
	clr	%fp			! End of stack.
#ifdef DEBUG
	flushw						! DEBUG
	set	_C_LABEL(idle_u), %l6
	SET_SP_REDZONE %l6, %l5
#endif	/* DEBUG */
	wrpr	%g0, PSTATE_INTR, %pstate	! and then enable traps
	call	_C_LABEL(exit2)			! exit2(p)
	 mov	%l2, %o0

#if defined(MULTIPROCESSOR) || defined(LOCKDEBUG)
	call	_C_LABEL(sched_lock_idle)	! Acquire sched_lock
#endif	/* defined(MULTIPROCESSOR) || defined(LOCKDEBUG) */
	 wrpr	%g0, PIL_SCHED, %pil		! Set splsched()

	/*
	 * Now fall through to `the last switch'.  %g6 was set to
	 * %hi(cpcb), but may have been clobbered in kmem_free,
	 * so all the registers described below will be set here.
	 *
	 * Since the process has exited we can blow its context
	 * out of the MMUs now to free up those TLB entries rather
	 * than have more useful ones replaced.
	 *
	 * REGISTER USAGE AT THIS POINT:
	 *	%l2 = %hi(_whichqs)
	 *	%l4 = lastproc
	 *	%l5 = oldpsr (excluding ipl bits)
	 *	%l6 = %hi(cpcb)
	 *	%l7 = %hi(curproc)
	 *	%o0 = tmp 1
	 *	%o1 = tmp 2
	 *	%o3 = whichqs
	 */

	INCR _C_LABEL(nswitchexit)		! nswitchexit++;
	INCR _C_LABEL(uvmexp)+V_SWTCH		! cnt.v_switch++;

	mov	CTX_SECONDARY, %o0
	sethi	%hi(_C_LABEL(whichqs)), %l2
	sethi	%hi(CPCB), %l6
	sethi	%hi(CURPROC), %l7
	ldxa	[%o0] ASI_DMMU, %l1		! Don't demap the kernel
	ldx	[%l6 + %lo(CPCB)], %l5
	clr	%l4				! lastproc = NULL;
	brz,pn	%l1, 1f
	 set	DEMAP_CTX_SECONDARY, %l1	! Demap secondary context
	stxa	%g1, [%l1] ASI_DMMU_DEMAP
	stxa	%g1, [%l1] ASI_IMMU_DEMAP
	membar	#Sync
1:
	stxa	%g0, [%o0] ASI_DMMU		! Clear out our context
	membar	#Sync
	/* FALLTHROUGH */

/*
 * When no processes are on the runq, switch
 * idles here waiting for something to come ready.
 * The registers are set up as noted above.
 */
	.globl	idle
idle:
#if defined(MULTIPROCESSOR) || defined(LOCKDEBUG)
	call	_C_LABEL(sched_unlock_idle)	! Release sched_lock
#endif	/* defined(MULTIPROCESSOR) || defined(LOCKDEBUG) */
	 stx	%g0, [%l7 + %lo(CURPROC)] ! curproc = NULL;
1:					! spin reading _whichqs until nonzero
	wrpr	%g0, PSTATE_INTR, %pstate		! Make sure interrupts are enabled
	wrpr	%g0, 0, %pil		! (void) spl0();
	ld	[%l2 + %lo(_C_LABEL(whichqs))], %o3
	brnz,pt	%o3, notidle		! Something to run
	 nop
#ifdef UVM_PAGE_IDLE_ZERO
	! Check uvm.page_idle_zero
	sethi	%hi(_C_LABEL(uvm) + UVM_PAGE_IDLE_ZERO), %o3
	ld	[%o3 + %lo(_C_LABEL(uvm) + UVM_PAGE_IDLE_ZERO)], %o3
	brz,pn	%o3, 1b
	 nop

	! zero some pages
	call	_C_LABEL(uvm_pageidlezero)
	 nop
#endif	/* UVM_PAGE_IDLE_ZERO */
	ba,a,pt	%xcc, 1b
	 nop				! spitfire bug
notidle:
	wrpr	%g0, PIL_SCHED, %pil	! (void) splhigh();
#if defined(MULTIPROCESSOR) || defined(LOCKDEBUG)
	call	_C_LABEL(sched_lock_idle)	! Grab sched_lock
	 add	%o7, (Lsw_scan-.-4), %o7	! Return to Lsw_scan directly
#endif	/* defined(MULTIPROCESSOR) || defined(LOCKDEBUG) */
	ba,a,pt	%xcc, Lsw_scan
	 nop				! spitfire bug

Lsw_panic_rq:
	sethi	%hi(1f), %o0
	call	_C_LABEL(panic)
	 or	%lo(1f), %o0, %o0
d5577 3
a5579 3
	sethi	%hi(2f), %o0
	call	_C_LABEL(panic)
	 or	%lo(2f), %o0, %o0
d5581 7
a5587 10
	sethi	%hi(3f), %o0
	call	_C_LABEL(panic)
	 or	%lo(3f), %o0, %o0
	.data
1:	.asciz	"switch rq"
2:	.asciz	"switch wchan"
3:	.asciz	"switch SRUN"
idlemsg:	.asciz	"idle %x %x %x %x"
idlemsg1:	.asciz	" %x %x %x\r\n"
	_ALIGN
d5590 1
a5590 11
 * cpu_switch() picks a process to run and runs it, saving the current
 * one away.  On the assumption that (since most workstations are
 * single user machines) the chances are quite good that the new
 * process will turn out to be the current process, we defer saving
 * it here until we have found someone to load.  If that someone
 * is the current process we avoid both store and load.
 *
 * cpu_switch() is always entered at splstatclock or splhigh.
 *
 * IT MIGHT BE WORTH SAVING BEFORE ENTERING idle TO AVOID HAVING TO
 * SAVE LATER WHEN SOMEONE ELSE IS READY ... MUST MEASURE!
d5592 1
a5592 2
 * Apparently cpu_switch() is called with curproc as the first argument,
 * but no port seems to make use of that parameter.
d5594 1
a5594 2
	.globl	_C_LABEL(time)
ENTRY(cpu_switch)
a5595 31
	/*
	 * REGISTER USAGE AT THIS POINT:
	 *	%l1 = tmp 0
	 *	%l2 = %hi(_C_LABEL(whichqs))
	 *	%l3 = p
	 *	%l4 = lastproc
	 *	%l5 = cpcb
	 *	%l6 = %hi(CPCB)
	 *	%l7 = %hi(CURPROC)
	 *	%o0 = tmp 1
	 *	%o1 = tmp 2
	 *	%o2 = tmp 3
	 *	%o3 = tmp 4, then at Lsw_scan, whichqs
	 *	%o4 = tmp 5, then at Lsw_scan, which
	 *	%o5 = tmp 6, then at Lsw_scan, q
	 */
#ifdef DEBUG
	set	swdebug, %o1
	ld	[%o1], %o1
	brz,pt	%o1, 2f
	 set	1f, %o0
	call	printf
	 nop
	.data
1:	.asciz	"s"
	_ALIGN
	.globl	swdebug
swdebug:	.word 0
	.text
2:
#endif	/* DEBUG */
a5596 5
#ifdef DEBUG
	save	%sp, -CC64FSZ, %sp
	flushw
	restore
#endif	/* DEBUG */
d5599 4
a5603 1
	sethi	%hi(_C_LABEL(whichqs)), %l2	! set up addr regs
d5605 1
a5605 1
	sethi	%hi(CURPROC), %l7
a5606 1
	ldx	[%l7 + %lo(CURPROC)], %l4	! lastproc = curproc;
a5608 74
	stx	%g0, [%l7 + %lo(CURPROC)]	! curproc = NULL;

Lsw_scan:
	ld	[%l2 + %lo(_C_LABEL(whichqs))], %o3

#ifndef POPC
	.globl	_C_LABEL(__ffstab)
	/*
	 * Optimized inline expansion of `which = ffs(whichqs) - 1';
	 * branches to idle if ffs(whichqs) was 0.
	 */
	set	_C_LABEL(__ffstab), %o2
	andcc	%o3, 0xff, %o1		! byte 0 zero?
	bz,a,pn	%icc, 1f		! yes, try byte 1
	 srl	%o3, 8, %o0
	ba,pt	%icc, 2f		! ffs = ffstab[byte0]; which = ffs - 1;
	 ldsb	[%o2 + %o1], %o0
1:	andcc	%o0, 0xff, %o1		! byte 1 zero?
	bz,a,pn	%icc, 1f		! yes, try byte 2
	 srl	%o0, 8, %o0
	ldsb	[%o2 + %o1], %o0	! which = ffstab[byte1] + 7;
	ba,pt	%icc, 3f
	 add	%o0, 7, %o4
1:	andcc	%o0, 0xff, %o1		! byte 2 zero?
	bz,a,pn	%icc, 1f		! yes, try byte 3
	 srl	%o0, 8, %o0
	ldsb	[%o2 + %o1], %o0	! which = ffstab[byte2] + 15;
	ba,pt	%icc, 3f
	 add	%o0, 15, %o4
1:	ldsb	[%o2 + %o0], %o0	! ffs = ffstab[byte3] + 24
	addcc	%o0, 24, %o0		! (note that ffstab[0] == -24)
	bz,pn	%icc, idle		! if answer was 0, go idle
!	 XXX check no delay slot
2:	sub	%o0, 1, %o4
3:	/* end optimized inline expansion */

#else	/* POPC */
	/*
	 * Optimized inline expansion of `which = ffs(whichqs) - 1';
	 * branches to idle if ffs(whichqs) was 0.
	 *
	 * This version uses popc.
	 *
	 * XXXX spitfires and blackbirds don't implement popc.
	 *
	 */
	brz,pn	%o3, idle				! Don't bother if queues are empty
	 neg	%o3, %o1				! %o1 = -zz
	xnor	%o3, %o1, %o2				! %o2 = zz ^ ~ -zz
	popc	%o2, %o4				! which = popc(whichqs)
	dec	%o4					! which = ffs(whichqs) - 1

#endif	/* POPC */
	/*
	 * We found a nonempty run queue.  Take its first process.
	 */
	set	_C_LABEL(qs), %o5	! q = &qs[which];
	sll	%o4, 3+1, %o0
	add	%o0, %o5, %o5
	ldx	[%o5], %l3		! p = q->ph_link;
	cmp	%l3, %o5		! if (p == q)
	be,pn	%icc, Lsw_panic_rq	!	panic("switch rq");
!	 XXX check no delay slot
	ldx	[%l3], %o0		! tmp0 = p->p_forw;
	stx	%o0, [%o5]		! q->ph_link = tmp0;
	stx	%o5, [%o0 + 8]	! tmp0->p_back = q;
	cmp	%o0, %o5		! if (tmp0 == q)
	bne	1f
!	 XXX check no delay slot
	mov	1, %o1			!	whichqs &= ~(1 << which);
	sll	%o1, %o4, %o1
	andn	%o3, %o1, %o3
	st	%o3, [%l2 + %lo(_C_LABEL(whichqs))]
1:
a5636 1
	 * It may be the same as the one we were running before.
d5649 1
a5649 13
	stx	%g0, [%l3 + 8]		! p->p_back = NULL;
#if defined(MULTIPROCESSOR) || defined(LOCKDEBUG)
	/*
	 * Done mucking with the run queues, release the
	 * scheduler lock, but keep interrupts out.
	 */
	call	_C_LABEL(sched_unlock_idle)
#endif	/* defined(MULTIPROCESSOR) || defined(LOCKDEBUG) */
	 stx	%l4, [%l7 + %lo(CURPROC)]	! restore old proc so we can save it

	cmp	%l3, %l4			! p == lastproc?
	be,pt	%xcc, Lsw_sameproc		! yes, go return 0
	 nop
a5658 1
	INCR _C_LABEL(nswitchdiff)	! clobbers %o0,%o1,%o2
a5737 5
Lsw_sameproc:
	/*
	 * We are resuming the process that was running at the
	 * call to switch().  Just set psr ipl and return.
	 */
d5744 12
@


1.82
log
@Add kernel locking.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.81 2007/09/10 21:33:16 kettenis Exp $	*/
a3160 5
	.data
	.globl	intrpending
intrpending:
	.space	16 * 8 * 8

d3228 1
a3228 1
	sethi	%hi(intrpending), %g1
d3231 1
a3231 1
	or	%g1, %lo(intrpending), %g1
d3487 2
a3488 2
	sethi	%hi(intrpending), %l4
	or	%l4, %lo(intrpending), %l4
d9201 1
a9201 1
	set	intrpending, %o3
@


1.81
log
@IPI implementation.  Bits and pieces from NetBSD, but the interface has been
changed to free up another 64-bit word in the interrupt transaction.  This
means we have two 64-bit words available for arguments, which means we
probably don't need to pass arguments through structures.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.80 2007/09/09 08:55:27 kettenis Exp $	*/
d3507 7
a3513 1
	 add	%sp, CC64FSZ+BIAS, %o2	! tf = %sp + CC64FSZ + BIAS
d3515 2
d3554 5
@


1.80
log
@Make handled_intr_level per-cpu.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.79 2007/09/08 17:13:18 kettenis Exp $	*/
d3186 20
a3206 1
	btst	IRSR_BUSY, %g1
a3207 9
	bz,pn	%icc, 3f		! spurious interrupt
	 sllx	%g2, 3, %g5	! Calculate entry number
	cmp	%g2, MAXINTNUM

#ifdef DEBUG
	tgeu	55
#endif	/* DEBUG */
	bgeu,pn	%xcc, 3f
	 nop
d3297 63
@


1.79
log
@Make the ast on sparc64 per-process instead of global.  Necessary to make
signal delivery more reliable once we go smp (although the code for that
is still missing).

"in principle, this looks good" art@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.78 2007/05/28 23:10:10 beck Exp $	*/
d3403 1
a3403 1
	sethi	%hi(_C_LABEL(handled_intr_level)), %l4
d3411 2
a3412 2
	ld	[%l4 + %lo(_C_LABEL(handled_intr_level))], %l7
	st	%l6, [%l4 + %lo(_C_LABEL(handled_intr_level))]
d3504 1
a3504 1
	sethi	%hi(_C_LABEL(handled_intr_level)), %l4
d3506 1
a3506 1
	st	%l7, [%l4 + %lo(_C_LABEL(handled_intr_level))]
@


1.78
log
@Maintaining a broken compatibility layer for a broken OS is not a productive
activity for anyone. Bye bye COMPAT_NETBSD. ok tedu@@, deraadt@@, and many others
in the hackathon room.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.77 2007/05/15 21:00:05 kettenis Exp $	*/
d3631 1
a3631 1
	 sethi	%hi(_C_LABEL(want_ast)), %g7	! first instr of rft_user
d3675 3
a3677 2
!	sethi	%hi(_C_LABEL(want_ast)), %g7	! (done above)
	lduw	[%g7 + %lo(_C_LABEL(want_ast))], %g7! want AST trap?
d3809 1
a3809 1
	 sethi	%hi(_C_LABEL(want_ast)), %g7
@


1.77
log
@Remove unused variable.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.76 2007/05/15 20:30:11 kettenis Exp $	*/
a4939 4

#ifdef COMPAT_NETBSD
#include "sigcode_netbsd.s"
#endif	/* COMPAT_NETBSD */
@


1.76
log
@We will never call OpenFirmware from 32-bit code.

ok art@@, deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.75 2007/05/14 21:38:08 kettenis Exp $	*/
a9453 2

	.comm	_C_LABEL(nwindows), 4
@


1.75
log
@Move want_resched into struct cpu_info.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.74 2007/05/14 19:20:11 kettenis Exp $	*/
a4469 3
 *
 * If we're running in 32-bit mode we need to convert to a 64-bit stack
 * and 64-bit cells.  The cells we'll allocate off the stack for simplicity.
d4477 1
a4477 3
	andcc	%sp, 1, %g0
	bz,pt	%icc, 1f
	 ldx	[%o4+%lo(romp)], %o4		! v9 stack, just load the addr and call it
a4503 33
	ret
	 restore	%o0, %g0, %o0

1:	! v8 -- need to screw with stack & params
	save	%sp, -CC64FSZ, %sp		! Get a new 64-bit stack frame
	add	%sp, -BIAS, %sp
	rdpr	%pstate, %l0
	srl	%sp, 0, %sp
	rdpr	%pil, %i2	! s = splx(level)
	mov	%i0, %o0
	mov	PIL_HIGH, %i3
	mov	%g1, %l1
	mov	%g2, %l2
	cmp	%i3, %i2
	mov	%g3, %l3
	mov	%g4, %l4
	mov	%g5, %l5
	movle	%icc, %i2, %i3
	mov	%g6, %l6
	mov	%g7, %l7
	wrpr	%i3, %g0, %pil
	jmpl	%i4, %o7
	! Enable 64-bit addresses for the prom
	 wrpr	%g0, PSTATE_PROM, %pstate
	wrpr	%l0, 0, %pstate
	wrpr	%i2, 0, %pil
	mov	%l1, %g1
	mov	%l2, %g2
	mov	%l3, %g3
	mov	%l4, %g4
	mov	%l5, %g5
	mov	%l6, %g6
	mov	%l7, %g7
@


1.74
log
@Nuke code to support the Solaris bootloader and old 32-bit bootloaders.
Remove bits of code that repeat what the bootloader already did for us,
like setting up the stack and clearing .bss.

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.73 2007/05/11 20:25:26 kettenis Exp $	*/
a5538 2
	.comm	_C_LABEL(want_resched),4

d5918 2
a5919 2
	sethi	%hi(_C_LABEL(want_resched)), %o0
	st	%g0, [%o0 + %lo(_C_LABEL(want_resched))]	! want_resched = 0;
@


1.73
log
@Don't clear %tick register.  Should not be necessary and undesirable since
%tick is hyperprivileged on sun4v.

ok jason@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.72 2007/05/02 18:46:07 kettenis Exp $	*/
a91 15
#if 1
/*
 * Try to issue an elf note to ask the Solaris
 * bootloader to align the kernel properly.
 */
	.section	.note
	.word	0x0d
	.word	4		! Dunno why
	.word	1
0:	.asciz	"SUNW Solaris"
1:
	.align	4
	.word	0x0400000
#endif	/* 1 */

d3968 1
d3974 2
a3975 4
	 * followed by esym as argument 2, so check that %o2 == 8,
	 * then extract esym and check the magic number.
	 *
	 *  Oh, yeah, start of elf symtab is arg 3.
d3977 1
a3977 1
	cmp	%o2, 8
d3979 3
a3981 8

	/*
	 * First we'll see if we were loaded by a 64-bit bootloader
	 */
	 btst	0x7, %o1		! Check alignment
	bne	0f
	 set	0x44444230, %l3

d3984 1
a3984 1
	bne	%xcc, 0f
d3988 1
a3988 1
	sethi	%hi(_C_LABEL(esym)), %l3	! store _esym
a3990 4
	cmp	%o2, 12
	blt	1f
	 nop

d3992 1
a3992 26
	sethi	%hi(_C_LABEL(ssym)), %l3	! store _esym
	ba	1f
	 stx	%l4, [%l3 + %lo(_C_LABEL(ssym))]
0:
	/*
	 * Now we can try again with for a 32-bit bootloader
	 */
	cmp	%o2, 8
	blt	1f			! Not enuff args

	 set	0x44444230, %l3
	ld	[%o1], %l4
	cmp	%l3, %l4		! chk magic
	bne	1f
	 nop

	ld	[%o1+4], %l4
	sethi	%hi(_C_LABEL(esym)), %l3	! store _esym
	stx	%l4, [%l3 + %lo(_C_LABEL(esym))]

	cmp	%o2, 12
	blt	1f
	 nop

	ld	[%o1+8], %l4
	sethi	%hi(_C_LABEL(ssym)), %l3	! store _esym
a4002 30

	/*
	 * Step 2: Set up a v8-like stack if we need to
	 */

	btst	1, %sp
	bnz,pt	%icc, 0f
	 nop
	add	%sp, -BIAS, %sp
0:
	/*
	 * Step 3: clear BSS.  This may just be paranoia; the boot
	 * loader might already do it for us; but what the hell.
	 */
	set	_C_LABEL(edata), %o0		! bzero(edata, end - edata)
	set	_C_LABEL(end), %o1
	call	_C_LABEL(bzero)
	 sub	%o1, %o0, %o1

	/*
	 * Step 4: compute number of windows and set up tables.
	 * We could do some of this later.
	 *
	 * XXX I forget: why are we doing this?
	 */
	rdpr	%ver, %g1
	and	%g1, 0x0f, %g1		! want just the CWP bits
	add	%g1, 1, %o0		! compute nwindows
	sethi	%hi(_C_LABEL(nwindows)), %o1	! may as well tell everyone
	st	%o0, [%o1 + %lo(_C_LABEL(nwindows))]
@


1.72
log
@Move sparc64 to __HAVE_CPUINFO.

ok miod@@, deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.71 2007/03/20 12:47:46 todd Exp $	*/
a3949 1
	wrpr	%g0, 0, %tick	! XXXXXXX clear %tick register for now
d3952 1
a3952 1
	wr	%g1, TICK_CMPR	! XXXXXXX clear and disable %tick_cmpr as well
@


1.71
log
@typo in comment
ok jmc@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.70 2007/01/12 22:09:08 kettenis Exp $	*/
a84 5
#ifndef MULTIPROCESSOR
#define	CURPROC	_C_LABEL(curproc)
#define CPCB	_C_LABEL(cpcb)
#define	FPPROC	_C_LABEL(fpproc)
#else	/* MULTIPROCESSOR */
a87 1
#endif	/* MULTIPROCESSOR */
a330 7

/*
 * _cpcb points to the current pcb (and hence u. area).
 * Initially this is the special one.
 */
	.globl	_C_LABEL(cpcb)
_C_LABEL(cpcb):	.xword	_C_LABEL(u0)
@


1.70
log
@Get rid of some dead code.
ok miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.69 2007/01/06 23:07:13 kettenis Exp $	*/
d8379 1
a8379 1
	 mov	%o4, %o0		! Restore ponter for memset (ugh)
@


1.69
log
@Remove bogus code for flushing 32-bit tlb entries.  This makes it possible to
go to more than 4G va space.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.68 2007/01/04 23:08:16 kettenis Exp $	*/
a4788 29
 * blast_vcache()
 *
 * Clear out all of D$ regardless of contents
 * Does not modify %o0
 *
 */
	.align 8
	.globl	_C_LABEL(blast_vcache)
	.proc 1
	FTYPE(blast_vcache)
_C_LABEL(blast_vcache):
/*
 * We turn off interrupts for the duration to prevent RED exceptions.
 */
	rdpr	%pstate, %o3
	set	(2*NBPG)-8, %o1
	andn	%o3, PSTATE_IE, %o4			! Turn off PSTATE_IE bit
	wrpr	%o4, 0, %pstate
1:
dlflush3:
	stxa	%g0, [%o1] ASI_DCACHE_TAG
	brnz,pt	%o1, 1b
	 dec	8, %o1
	sethi	%hi(KERNBASE), %o2
	flush	%o2
	retl
	 wrpr	%o3, %pstate

/*
d4823 1
a4823 1
dlflush4:
d4880 1
a4880 1
dlflush5:
d4935 1
a4935 1
dlflush6:
d6297 1
a6297 1
dlflush7:
a9603 1
	.xword	dlflush7
@


1.68
log
@Remove some unreachable code.

ok jason@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.67 2006/12/29 00:14:28 kettenis Exp $	*/
a4707 6
	membar	#Sync					! No real reason for this XXXX
	flush	%o4
	srl	%g2, 0, %g2				! and make sure it's both 32- and 64-bit entries
	stxa	%g2, [%g2] ASI_DMMU_DEMAP		! Do the demap
	membar	#Sync
	stxa	%g2, [%g2] ASI_IMMU_DEMAP		! Do the demap
@


1.67
log
@Give the UltraSPARC-III its own version of dcache_flush_page().  Fixes problems
with svnd(4).  Now you can do a full mkr on a v210 (and a blade1k if you're
lucky).
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.66 2006/12/27 19:12:49 kettenis Exp $	*/
a4926 14
	!! We got a hole.  Clear from start to hole
	clr	%o4
3:
dlflush6:
	stxa	%g0, [%o4] ASI_DCACHE_TAG
	dec	16, %o1
	brgz,pt	%o1, 3b
	 inc	16, %o4

	!! Now clear to the end.
	sub	%o3, %o2, %o4	! Size to clear (NBPG - end)
	ba,pt	%icc, 1b
	 mov	%o2, %o0	! Start of clear

d4970 1
a4970 1
dlflush7:
d6332 1
a6332 1
dlflush8:
a9639 1
	.xword	dlflush8
@


1.66
log
@Patch a few more D-cache flush instructions on UltraSPARC-III.

ok miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.65 2006/12/23 12:28:11 kettenis Exp $	*/
d4830 1
a4830 1
	.globl	_C_LABEL(dcache_flush_page)
d4832 2
a4833 2
	FTYPE(dcache_flush_page)
_C_LABEL(dcache_flush_page):
d4869 22
@


1.65
log
@On UltraSPARC-III, patch some crucial D-cache flush instructions, and
enable the cache.

ok jason@@, miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.64 2006/12/12 20:15:13 kettenis Exp $	*/
d4814 1
d4858 1
d4893 1
d4908 1
d4962 1
d6324 1
d9627 6
@


1.64
log
@Fix typo in comment.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.63 2006/11/14 20:18:51 jasper Exp $	*/
d2198 1
d4098 1
a4098 11
#if defined(HORRID_III_HACK)
	/*
	 * Check for UltraSPARC III
	 */
	rdpr	%ver, %g1
	srlx	%g1, 32, %g1
	sll	%g1, 16, %g1
	srl	%g1, 16, %g1
	cmp	%g1, 0x0014
	bl,pt	%icc, 1f
	 nop
d4240 1
d9616 6
@


1.63
log
@fix a comment (wording from mark)

ok kettenis
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.62 2006/10/25 20:15:59 kettenis Exp $	*/
d4831 1
a4831 1
 * dcache_flush_page(vaddr_t pa)
@


1.62
log
@Make sure we actually flush the I-TLB on UltraSPARC-III by doing it from
the primary context instead of the secondary context.

ok miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.61 2006/08/27 21:19:02 kettenis Exp $	*/
d9595 1
a9595 1
	stxa	%o0, [%o4] ASI_DMMU		! Maybe we should invali
@


1.61
log
@Enable HORRID_III_HACK, but make sure we only disable the data cache on
UltraSPARC III and up.  That way it isn't really that horrid and doesn't really
affect UltraSPARC I & II.  This gives us a GENERIC that runs on UltraSPARC III.

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.60 2006/07/01 16:24:17 miod Exp $	*/
d4762 18
d4787 1
d4795 4
@


1.60
log
@Make probeget() and related code in trap.c #ifdef DDB
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.59 2006/06/07 16:57:43 deraadt Exp $	*/
d59 1
a59 3
#ifdef HORRID_III_HACK
#define	NO_VCACHE		/* Map w/D$ disabled */
#endif /* HORRID_III_HACK */
d62 1
d4099 10
d4120 1
@


1.59
log
@do not #undef HORRID_III_HACK
This means that for now a config file can build us3 kernels
ok jason
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.58 2006/06/02 01:07:25 kettenis Exp $	*/
d6190 1
a6190 5
Lfserr:
	stx	%g0, [%o2 + PCB_ONFAULT]! error in r/w, clear pcb_onfault
	membar	#StoreStore|#StoreLoad
	retl				! and return error indicator
	 mov	-1, %o0
a6191 13
	/*
	 * This is just like Lfserr, but it's a global label that allows
	 * mem_access_fault() to check to see that we don't want to try to
	 * page in the fault.  It's used by fuswintr() etc.
	 */
	.globl	_C_LABEL(Lfsbail)
_C_LABEL(Lfsbail):
	stx	%g0, [%o2 + PCB_ONFAULT]! error in r/w, clear pcb_onfault
	membar	#StoreStore|#StoreLoad
	retl				! and return error indicator
	 mov	-1, %o0

/* probeget is meant to be used during autoconfiguration */
d6213 2
a6214 2
	ldx	[%o2 + %lo(CPCB)], %o2	! cpcb->pcb_onfault = Lfserr;
	set	_C_LABEL(Lfsbail), %o5
d6256 1
d6264 2
@


1.58
log
@The I-cache seems to work fine on the UltraSPARC III, so never disable it,
even if HORRID_III_HACK is defined.
ok jason@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.57 2006/05/31 06:51:25 kettenis Exp $	*/
a58 1
#undef HORRID_III_HACK	/* define this to make a locore.s for usIII */
d61 2
a62 3
#else	/* HORRID_III_HACK */
#undef	NO_VCACHE		/* Map w/D$ disabled */
#endif	/* HORRID_III_HACK */
d4098 1
a4098 1
#if 0 || defined(HORRID_III_HACK)
@


1.57
log
@The bright people at Sun removed the secondary context from the IMMU in the
UltraSPARC III.  Hack around it by temporarily switching to nucleus context
when flushing TLBs.  Put this hack under HORRID_III_HACK for now.

Compiling with HORRID_III_HACK results in a kernel that runs on the Blade
2000 "at the speed of a 140MHz UltraSPARC I".

ok jason@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.56 2006/05/31 02:43:05 kettenis Exp $	*/
a4105 3
#ifdef HORRID_III_HACK
	andn	%o1, MCCR_ICACHE_EN, %o1	! and Icache...
#endif	/* HORRID_III_HACK */
a4159 3
#ifdef HORRID_III_HACK
	andn	%o1, MCCR_ICACHE_EN, %o1	! and Icache...
#endif	/* HORRID_III_HACK */
@


1.56
log
@Use symbolic constants for TLB demapping operations.
This fixes a few cases where the hardcoded constant indicated a reserved
operation instead of the intended secundary context flush.
ok jason@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.55 2006/03/23 02:29:36 ray Exp $	*/
d4683 19
d4710 1
d4722 1
a4722 1
	stxa	%g1, [%o2] ASI_DMMU			! Restore secondary asi
d4725 4
@


1.55
log
@Extra parentheses in comments.

From Alexey Dobriyan.

OK miod@@ and otto@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.54 2006/02/22 22:17:07 miod Exp $	*/
d1625 2
a1626 2
	mov	0x010, %g1				! Secondary flush
	mov	0x020, %g5				! Nucleus flush
d1735 2
a1736 2
	mov	0x010, %g1				! Secondary flush
	mov	0x020, %g5				! Nucleus flush
d2473 2
a2474 2
	mov	0x010, %g1				! Secondary flush
	mov	0x020, %g5				! Nucleus flush
d4359 1
a4359 1
	or	%l0, 0x020, %o0			! Context = Nucleus
d4371 1
a4371 1
	or	%l3, 0x020, %o0			! Context = Nucleus
d4421 1
a4421 1
	mov	0x050, %o4
d4690 1
a4690 1
	or	%g2, 0x010, %g2				! Demap page from secondary context only
d4742 1
a4742 1
	set	0x030, %g2				! Demap context from secondary context only
d5749 1
a5749 1
	 set	0x030, %l1			! Demap secondary context
d6084 1
a6084 1
	set	0x030, %o1			! This context has been recycled
d9554 1
a9554 1
	set	0x030, %o3
@


1.54
log
@Remove unused probeset() function.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.53 2006/01/03 20:57:36 kettenis Exp $	*/
d5361 1
a5361 1
	 btst	4, %o2		! if ((len & 4)) == 0)
d5557 1
a5557 1
	 btst	4, %o2		! if ((len & 4)) == 0)
d8689 1
a8689 1
	 btst	4, %o2		! if ((len & 4)) == 0)
@


1.53
log
@Try to prevent red stating the machine on a misaligned user space stack by
SIGKILLing the process.
ok miod@@, henric@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.52 2005/08/08 19:48:37 kettenis Exp $	*/
d6192 1
a6192 1
/* probeget and probeset are meant to be used during autoconfiguration */
d6204 3
a6206 3
 * Read or write a (byte,word,longword) from the given address.
 * Like {fu,su}{byte,halfword,word} but our caller is supposed
 * to know what he is doing... the address can be anywhere.
a6263 44

/*
 * probeset(addr, asi, size, val)
 *	paddr_t addr;
 *	int asi;
 *	int size;
 *	long val;
 *
 * As above, but we return 0 on success.
 */
ENTRY(probeset)
	mov	%o2, %o4
	! %o0 = addr, %o1 = asi, %o4 = (1,2,4), %o3 = val
	sethi	%hi(CPCB), %o2		! Lfserr requires CPCB in %o2
	ldx	[%o2 + %lo(CPCB)], %o2	! cpcb->pcb_onfault = Lfserr;
	set	_C_LABEL(Lfsbail), %o5
	stx	%o5, [%o2 + PCB_ONFAULT]
	btst	1, %o4
	wr	%o1, 0, %asi
	membar	#Sync
	bz	0f			! if (len & 1)
	 btst	2, %o4
	ba,pt	%icc, 1f
	 stba	%o3, [%o0] %asi		!	*(char *)addr = value;
0:
	bz	0f			! if (len & 2)
	 btst	4, %o4
	ba,pt	%icc, 1f
	 stha	%o3, [%o0] %asi		!	*(short *)addr = value;
0:
	bz	0f			! if (len & 4)
	 btst	8, %o4
	ba,pt	%icc, 1f
	 sta	%o3, [%o0] %asi		!	*(int *)addr = value;
0:
	bz	Lfserr			! if (len & 8)
	ba,pt	%icc, 1f
	 sta	%o3, [%o0] %asi		!	*(int *)addr = value;
1:	membar	#Sync
	clr	%o0			! made it, clear onfault and return 0
	wr	%g0, ASI_PRIMARY_NOFAULT, %asi		! Restore default ASI	
	stx	%g0, [%o2 + PCB_ONFAULT]
	retl
	 membar	#StoreStore|#StoreLoad
@


1.52
log
@Skip (trap) instruction in cpu_fork() instead of proc_trampoline().
Fixes returning from fork(2) in the child with a pending signal.
tested by otto@@, krw@@, sturm@@
ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.51 2005/07/18 14:50:11 deraadt Exp $	*/
d921 1
a921 1
	TRAP T_ALIGN			! 034 = address alignment error -- we could fix it inline...
d2610 67
@


1.51
log
@cache a copy of the fprs so we know what fp restore we should do after
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.50 2005/07/14 01:46:13 deraadt Exp $	*/
a6097 1
	ldx	[%sp + CC64FSZ + BIAS + TF_NPC], %g2	! pc = tf->tf_npc from execve/fork
a6098 1
	add	%g2, 4, %g3			! npc = pc+4
a6099 1
	stx	%g3, [%sp + CC64FSZ + BIAS + TF_NPC]
a6100 1
	stx	%g2, [%sp + CC64FSZ + BIAS + TF_PC]
@


1.50
log
@use symbolic names for checking in %fprs, as above
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.49 2005/03/29 19:34:07 kettenis Exp $	*/
d4936 1
@


1.49
log
@sparc64 StackGhost.
ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.48 2004/12/24 22:50:31 miod Exp $	*/
d4947 1
a4947 1
	btst	3, %l0			! All clean?
d4949 1
a4949 1
	 btst	1, %l0			! test dl
d4951 1
a4951 1
	 btst	2, %l0			! test du
@


1.48
log
@{e,}intr{cnt,names} bye-bye.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.47 2004/06/28 01:47:41 aaron Exp $	*/
d601 32
a632 1
	! spill a 64-bit register window
d668 17
a684 1
	! fill a 64-bit register window
d800 1
a800 1
	SPILL64 uspill8,ASI_AIUS	! 0x080 spill_0_normal -- used to save user windows in user mode
d813 1
a813 1
	SPILL64 uspillk8,ASI_AIUS	! 0x0a0 spill_0_other -- used to save user windows in supervisor mode
d822 1
a822 1
	FILL64 ufill8,ASI_AIUS ! 0x0c0 fill_0_normal -- used to fill windows when running user mode
d832 1
a832 1
	FILL64 ufillk8,ASI_AIUS	! 0x0e0 fill_0_other
d962 1
a962 1
	SPILL64 1,ASI_AIUS	! 0x080 spill_0_normal -- used to save user windows
d972 1
a972 1
	SPILL64 1,ASI_AIUS	! 0x0a0 spill_0_other -- used to save user windows in nucleus mode
d981 1
a981 1
	FILL64 1,ASI_AIUS	! 0x0c0 fill_0_normal -- used to fill windows when running nucleus mode from user
d991 1
a991 1
	FILL64 1,ASI_AIUS	! 0x0e0 fill_0_other -- used to fill user windows when running nucleus mode -- will we ever use this?
@


1.47
log
@Use new event counter API for interrupt counting on sparc64.  deraadt@@ tholo@@
drahn@@ millert@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.46 2004/06/20 04:30:34 aaron Exp $	*/
a9514 10

/* Some bogus data, to keep vmstat happy, for now. */
	.globl	_C_LABEL(intrnames), _C_LABEL(eintrnames)
	.globl	_C_LABEL(intrcnt), _C_LABEL(eintrcnt)
_C_LABEL(intrnames):
	.long	0
_C_LABEL(eintrnames):
_C_LABEL(intrcnt):
	.long	0
_C_LABEL(eintrcnt):
@


1.46
log
@It's supposed to be #ifdef DIAGNOSTIC, not #ifdef DIAGONSTIC.  miod@@ tested+ok
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.45 2004/06/13 21:49:21 niklas Exp $	*/
a3311 1
	sethi	%hi(_C_LABEL(intrcnt)), %l4
a3313 2
	sll	%l6, 2, %l3
	or	%l4, %lo(_C_LABEL(intrcnt)), %l4	! intrcnt[intlev]++;
a3314 2
	ld	[%l4 + %l3], %o0
	add	%l4, %l3, %l4
a3316 2
	inc	%o0	
	st	%o0, [%l4]
d3382 1
d3384 2
d9516 2
a9517 1
/* interrupt counters	XXX THESE BELONG ELSEWHERE (if anywhere) */
a9518 5
	.globl _C_LABEL(intrnames), _C_LABEL(eintrnames)
	OTYPE(intrcnt)
	OTYPE(eintrcnt)
	OTYPE(intrnames)
	OTYPE(eintrnames)
d9520 1
a9520 16
	.asciz	"spur"
	.asciz	"lev1"
	.asciz	"lev2"
	.asciz	"lev3"
	.asciz	"lev4"
	.asciz	"lev5"
	.asciz	"lev6"
	.asciz	"lev7"
	.asciz  "lev8"
	.asciz	"lev9"
	.asciz	"clock"
	.asciz	"lev11"
	.asciz	"lev12"
	.asciz	"lev13"
	.asciz	"prof"
	.asciz  "lev15"
a9521 1
	_ALIGN
d9523 1
a9523 1
	.space	16 * 4
@


1.45
log
@debranch SMP, have fun
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d8925 1
a8925 1
#ifdef DIAGONSTIC
d8928 1
a8928 1
#endif	/* DIAGONSTIC */
@


1.44
log
@
fix a couple of %y register save/restore errors
1) don't save %y in a register that is later used before restoring %y
2) always restore %y after calling a signal handler
tested by drahn@@, OK pval
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.43 2004/01/08 17:14:04 pvalchev Exp $	*/
a5881 1
#ifdef notyet
a5883 1
#endif	/* notyet */
@


1.43
log
@gcc3 does not seem to like comments inside comments - zap a couple; ok miod
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.42 2003/07/24 18:17:50 jason Exp $	*/
d2495 1
a2495 1
	rd	%y, %g7					! save y
d2520 1
a2520 1
	 st	%g7, [%sp + CC64FSZ + BIAS + TF_Y]		! set tf.tf_y
d4898 1
d4918 1
a4918 1
	 wr	%l1, %g0, %y		! in any case, restore %y
@


1.42
log
@a whole bunch of tyop fixes from Andrey Smagin
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.41 2003/07/09 15:52:53 jason Exp $	*/
d1838 1
a1838 1
#else	/* 0 /* Need to switch over to new stuff to fix WDR bug */ */
d1888 1
a1888 1
#endif	/* 0 /* Need to switch over to new stuff to fix WDR bug */ */
@


1.41
log
@add trap entries for LDQF/STQF alignment faults, but handle them as
SIGILL for now.  Also split out T_INST_EXCEPT and T_TEXTFAULT from
T_ILLINST pending handling of LDQF/STQF illegal instruction faults.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.40 2003/07/09 02:18:09 jason Exp $	*/
d62 1
a62 1
#else
d64 1
a64 1
#endif
d275 1
a275 1
 * Weve saved our possible fpstate, now disable the fpu
d290 1
a290 1
	call	_C_LABEL(loadfpstate)		! Re-load orig fpstate
d474 1
a474 1
#else
d476 1
a476 1
#endif
d598 1
a598 1
 * Here are some oft repeated traps as macros.
d689 1
a689 1
	VTRAP T_TEXTFAULT, textfault	! 009 = instr access MMU miss
d851 1
a851 1
	VTRAP T_TEXTFAULT, textfault	! 009 = instr access MMU miss -- no MMU
d946 1
a946 1
	FILLBOTH 1b,2b,ASI_AIUS! 0x0e8 fill_2_other
d993 1
a993 1
 * If the cleanwin trap handler detects an overfow we come here.
d1079 1
a1079 1
	sub	%g3, (pmap_edumparea-pmap_dumparea), %g3! pc relative addressing 8^)
d1280 1
a1280 1
  * this means that these registers need to be preserved across all
d1361 2
a1362 2
 * We don't guarantee any registers are preserved during this operation.
 * So we can be more efficient.
d1552 1
a1552 1
	blu,pn	%xcc, winfix				! Next insn in delay slot is unimportant
d1636 1
a1636 1
	blu,pn	%xcc, winfix				! Next insn in delay slot is unimportant
d1799 1
a1799 1
	 wrpr	%g5, %cwp		! Restore cwp from before fill trap -- regs should now be consisent
d1817 1
a1817 1
	wrpr	%g5, %cwp				! Restore cwp from before fill trap -- regs should now be consisent
d2367 1
a2367 1
	blu,pn	%xcc, textfault				! Next insn in delay slot is unimportant
d3292 1
a3292 1
	flushw			! Do not remove this insn -- causes interrupt loss
d3348 1
a3348 1
	membar	#StoreLoad		! Make sure any failed casxa insns complete
d3578 1
a3578 1
#endif	/*  */
d3998 1
a3998 1
#endif
d4055 1
a4055 1
#endif
d4058 1
a4058 1
#endif	/*  */
d4418 1
a4418 1
	stxa	%l0, [%l2] ASI_IMMU		! Install insn TSB pointer
d4472 1
a4472 1
	 ldx	[%o4+%lo(romp)], %o4		! v9 stack, just load the addr and callit
d4934 1
a4934 1
	add	%sp, BIAS + 128 + 16, %o0! compute scp
d5932 1
a5932 1
	wrpr	%g0, 0, %otherwin	! These two insns should be redundant
d6525 1
a6525 1
 * Use block_disable to turn off block insns for
d7311 1
a7311 1
	!! This is 6 insns, most of which cannot be paired,
d8267 1
a8267 1
	 sllx	%o1, 8, %o3		! sigh.  all dependent insns.
d8277 2
a8278 2
	bge,pt	%xcc, Lbzero_block	! use block store insns
#endif		/* 0 */
@


1.40
log
@s/Tryap/Trap
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.39 2003/05/17 19:30:55 art Exp $	*/
d715 3
a717 1
	UTRAP 0x038; UTRAP 0x039; UTRAP 0x03a; UTRAP 0x03b; UTRAP 0x03c;
@


1.39
log
@No need to duplicate TLB_ defines manually with TTE_ defines.
assym.h can do that for us.

mdw@@ henric@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.38 2003/05/17 07:48:19 mdw Exp $	*/
d405 1
a405 1
 *	that information.  Tryap types in these macros are all dummys.
@


1.38
log
@HORRID_III_HACK disables D$ and I$, and with this, the ramdisk
kernel boots on blade 1000 (ultrasparc III) and 280R (ultrasparc IIIcu)
to single user.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.36 2003/05/17 07:24:11 art Exp $	*/
a81 1
#include <machine/pte.h>
d1536 1
a1536 1
	 or	%g4, TTE_MODIFY|TTE_ACCESS|TTE_W, %g7	! Update the modified bit
d1538 1
a1538 1
	btst	TTE_REAL_W|TTE_W, %g4			! Is it a ref fault?
d1564 1
a1564 1
	 or	%g4, TTE_MODIFY|TTE_ACCESS|TTE_W, %g4	! Update the modified bit
d1663 1
a1663 1
	 or	%g4, TTE_ACCESS, %g7			! Update the access bit
d1665 1
a1665 1
	btst	TTE_ACCESS, %g4				! Need to update access git?
d1671 1
a1671 1
	 or	%g4, TTE_ACCESS, %g4				! Update the modified bit
d2398 1
a2398 1
	andcc	%g4, TTE_EXEC, %g0
d2403 2
a2404 2
	or	%g4, TTE_ACCESS, %g7			! Update accessed bit
	btst	TTE_ACCESS, %g4				! Need to update access bit?
d2410 1
a2410 1
	 or	%g4, TTE_ACCESS, %g4			! Update accessed bit
d4094 1
a4094 1
	or	%l2, TTE_L|TTE_CP|TTE_CV|TTE_P, %o4	! And low bits:	L=1|CP=1|CV=1|E=0|P=1|W=1(ugh)|G=0
d4102 1
a4102 1
	or	%l5, TTE_L|TTE_CP|TTE_CV|TTE_P|TTE_W, %o4	! And low bits:	L=1|CP=1|CV=1|E=0|P=1|W=1(ugh)|G=0
d4147 1
a4147 1
	or	%l5, TTE_L|TTE_CP|TTE_P|TTE_W, %o2
d4150 1
a4150 1
	or	%l5, TTE_L|TTE_CP|TTE_CV|TTE_P|TTE_W, %o2
d4171 1
a4171 1
	or	%l2, TTE_L|TTE_CP|TTE_P, %o2
d4174 1
a4174 1
	or	%l2, TTE_L|TTE_CP|TTE_CV|TTE_P, %o2
d4191 1
a4191 1
	or	%l2, TTE_L|TTE_CP|TTE_CV|TTE_P, %o4
d4217 1
a4217 1
	or	%l2, TTE_CP|TTE_P, %o2		! And low bits:	L=0|CP=1|CV=0|E=0|P=1|G=0
d4277 1
a4277 1
	or	%l2, TTE_L|TTE_CP|TTE_P, %o2
d4280 1
a4280 1
	or	%l2, TTE_L|TTE_CP|TTE_CV|TTE_P, %o2
d4362 1
a4362 1
	or	%l1, TTE_L|TTE_CP|TTE_P|TTE_W, %l2	! And low bits:	L=1|CP=1|CV=0|E=0|P=1|W=0|G=0
d4364 1
a4364 1
	or	%l1, TTE_L|TTE_CP|TTE_CV|TTE_P|TTE_W, %l2	! And low bits:	L=1|CP=1|CV=1|E=0|P=1|W=0|G=0
@


1.37
log
@All sun ultrasparcs have 8192 contexts.
ultrasparc IIIcu puts other stuff in formerly reserved fields of context registers.
@
text
@d59 4
d64 1
d3989 1
a3989 1
#if 0
d3995 3
d4052 3
@


1.36
log
@remove more ifdefs. Kill the VIS instruction pmap_{copy,zero}_page.
We haven't used them ever, they are hairy and if we want them back,
we'll readd them in some other file.

mdw@@ henric@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.35 2003/05/17 07:09:08 art Exp $	*/
d3998 1
a3998 5
	mov	-1, %o2
	stxa	%o2, [%o1] ASI_DMMU
	membar	#Sync
	ldxa	[%o1] ASI_DMMU, %o0		! then read it back
	membar	#Sync
a4000 1
	clr	%g4				! Clear data segment pointer
d4002 1
a4002 1
	 inc	%o0				! and add 1 to discover maxctx
@


1.35
log
@Get rid of lots of hairy ifdefs that we'll most likely never use.
TRAPTRACE, TRAPSTATS, FLTTRACE and SCHED_DEBUG.

mdw@@ henric@@ ok.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.34 2003/05/16 00:40:36 mdw Exp $	*/
a60 3
#undef	PMAP_FPSTATE		/* Allow nesting of VIS pmap copy/zero */
#define	NEW_FPSTATE
#define	PMAP_PHYS_PAGE		/* Use phys ASIs for pmap copy/zero */
a6216 221
#ifdef DEBUG
	set	pmapdebug, %o4
	ld	[%o4], %o4
	btst	0x80, %o4	! PDB_COPY
	bz,pt	%icc, 3f
	 nop
	save	%sp, -CC64FSZ, %sp
	set	2f, %o0
	call	printf
	 mov	%i0, %o1
!	ta	1; nop
	restore
	.data
2:	.asciz	"pmap_zero_page(%p)\n"
	_ALIGN
	.text
3:
#endif	/* DEBUG */
#ifndef PMAP_PHYS_PAGE
/*
 * Here we use VIS instructions to do a block clear of a page.
 * First we will tickle the FPU.  If is was not not enabled this
 * should cause a trap.  The trap will check if they belong to a
 * user process and if so save them and clear %fprs.  It will
 * also enable FP in PSTATE.
 *
 * We may now check the contents of %fprs.  If either the upper
 * or lower FPU is dirty then that means some other kernel routine
 * is using the FPU and we should use the slow routine.
 *
 * Otherwise, we zero out the FP registers we'll use.  Then we map
 * the page into the special VA we use for this purpose.  When we're
 * done, we clear %fprs, so we'll know we can use it the nest time.
 */
	sethi	%hi(_C_LABEL(vmmap)), %o2	! Get VA
	ldx	[%o2 + %lo(_C_LABEL(vmmap))], %o2
	brz,pn	%o2, pmap_zero_phys		! Only do VIS if traps are enabled
	 or	%o2, 0x020, %o3			! Nucleus flush page

#ifdef PMAP_FPSTATE
#ifndef NEW_FPSTATE
	!!
	!! This code will allow us to save the fpstate around this
	!! routine and nest FP use in the kernel
	!!
	save	%sp, -(CC64FSZ+FS_SIZE+BLOCK_SIZE), %sp	! Allocate an fpstate
	add	%sp, (CC64FSZ+BIAS+BLOCK_SIZE-1), %l0	! Calculate pointer to fpstate
	rd	%fprs, %l1			! Save old fprs so we can restore it later
	andn	%l0, BLOCK_ALIGN, %l0		! And make it block aligned
	call	_C_LABEL(savefpstate)
	 mov	%l0, %o0
	mov	%i0, %o0
	mov	%i2, %o2
	mov	%i3, %o3
	wr	%g0, FPRS_FEF, %fprs
#else	/* NEW_FPSTATE */	/* NEW_FPSTATE */
/*
 * New version, new scheme:
 *
 * Here we use VIS instructions to do a block clear of a page.
 * But before we can do that we need to save and enable the FPU.
 * The last owner of the FPU registers is fpproc, and
 * fpproc->p_md.md_fpstate is the current fpstate.  If that's not
 * null, call savefpstate() with it to store our current fp state.
 *
 * Next, allocate an aligned fpstate on the stack.  We will properly
 * nest calls on a particular stack so this should not be a problem.
 *
 * Now we grab either curproc (or if we're on the interrupt stack
 * proc0).  We stash its existing fpstate in a local register and
 * put our new fpstate in curproc->p_md.md_fpstate.  We point
 * fpproc at curproc (or proc0) and enable the FPU.
 *
 * If we are ever preempted, our FPU state will be saved in our
 * fpstate.  Then, when we're resumed and we take an FPDISABLED
 * trap, the trap handler will be able to fish our FPU state out
 * of curproc (or proc0).
 *
 * On exiting this routine we undo the damage: restore the original
 * pointer to curproc->p_md.md_fpstate, clear our fpproc, and disable
 * the MMU.
 *
 */
	!!
	!! This code will allow us to save the fpstate around this
	!! routine and nest FP use in the kernel
	!!
	save	%sp, -(CC64FSZ+FS_SIZE+BLOCK_SIZE), %sp	! Allocate an fpstate
	sethi	%hi(FPPROC), %l1
	ldx	[%l1 + %lo(FPPROC)], %l2		! Load fpproc
	add	%sp, (CC64FSZ+BIAS+BLOCK_SIZE-1), %l0	! Calculate pointer to fpstate
	brz,pt	%l2, 1f					! fpproc == NULL?
	 andn	%l0, BLOCK_ALIGN, %l0			! And make it block aligned
	ldx	[%l2 + P_FPSTATE], %l3
	brz,pn	%l3, 1f					! Make sure we have an fpstate
	 mov	%l3, %o0
	call	_C_LABEL(savefpstate)			! Save the old fpstate
	 set	EINTSTACK-BIAS, %l4			! Are we on intr stack?
	cmp	%sp, %l4
	bgu,pt	%xcc, 1f
	 set	INTSTACK-BIAS, %l4
	cmp	%sp, %l4
	blu	%xcc, 1f
0:
	 sethi	%hi(_C_LABEL(proc0)), %l4		! Yes, use proc0
	ba,pt	%xcc, 2f
	 or	%l4, %lo(_C_LABEL(proc0)), %l5
1:
	sethi	%hi(CURPROC), %l4			! Use curproc
	ldx	[%l4 + %lo(CURPROC)], %l5
	brz,pn	%l5, 0b					! If curproc is NULL need to use proc0
2:
	mov	%i0, %o0
	mov	%i2, %o2
	ldx	[%l5 + P_FPSTATE], %l6			! Save old fpstate
	mov	%i3, %o3
	stx	%l0, [%l5 + P_FPSTATE]			! Insert new fpstate
	stx	%l5, [%l1 + %lo(FPPROC)]		! Set new fpproc
	wr	%g0, FPRS_FEF, %fprs			! Enable FPU
#endif	/* NEW_FPSTATE */	/* NEW_FPSTATE */
#else	/* PMAP_FPSTATE */	/* PMAP_FPSTATE */
	!!
	!! Don't use FP regs if the kernel's already using them
	!!
	rd	%fprs, %o1			! Read old %fprs
	sethi	%hi(FPPROC), %o4		! Also load fpproc
	btst	FPRS_DU|FPRS_DL, %o1		! Is it dirty?
	ldx	[%o4 + %lo(FPPROC)], %o4
	bz,pt	%icc, 1f			! No, use fpregs
	 bset	FPRS_FEF, %o1
	brz,pn	%o4, pmap_zero_phys		! No userland fpstate so do this the slow way
1:
	 wr	%o1, 0, %fprs			! Enable the FPU
#endif	/* PMAP_FPSTATE */	/* PMAP_FPSTATE */

#ifdef DEBUG
	sethi	%hi(paginuse), %o4		! Prevent this from nesting
	lduw	[%o4 + %lo(paginuse)], %o5
	tst	%o5
	tnz	%icc, 1
	bnz,pn	%icc, pmap_zero_phys
	 inc	%o5
	stw	%o5, [%o4 + %lo(paginuse)]
#endif	/* DEBUG */

	rdpr	%pil, %g1
	wrpr	%g0, PIL_HIGH, %pil			! s = splhigh()

	fzero	%f0				! Set up FPU
	fzero	%f2
	fzero	%f4
	fzero	%f6
	fzero	%f8
	fzero	%f10
	fzero	%f12
	fzero	%f14

	stxa	%o3, [%o3] ASI_DMMU_DEMAP	! Do the demap
	membar	#Sync				! No real reason for this XXXX

	sethi	%hi(0x80000000), %o4		! Setup TTE:
	sllx	%o4, 32, %o4			!  V = 1
	or	%o4, TTE_CP|TTE_P|TTE_W|TTE_L, %o4	!  CP=1|P=1|W=1|L=1
	or	%o4, %o0, %o4			!  PA

	mov	TLB_TAG_ACCESS, %o5
	stxa	%o2, [%o5] ASI_DMMU		! Store new address for mapping
	membar	#Sync				! No real reason for this XXXX
	stxa	%o4, [%g0] ASI_DMMU_DATA_IN	! Store TTE for new mapping
	membar	#Sync

	set	NBPG, %o4
1:
	stda	%f0, [%o2] ASI_BLK_COMMIT_P		! Store 64 bytes
	add	%o2, 64, %o2
	dec	128, %o4
	stda	%f0, [%o2] ASI_BLK_COMMIT_P		! Store 64 bytes
	brgz,pt %o4, 1b
	 add	%o2, 64, %o2

	membar	#Sync				! Finish the operation
	stxa	%o3, [%o3] ASI_DMMU_DEMAP	! Demap the page again
	membar	#Sync				! No real reason for this XXXX


	wrpr	%g1, 0, %pil			! splx(s)

#ifdef PMAP_FPSTATE
#ifndef NEW_FPSTATE
	btst	FPRS_DU|FPRS_DL, %l1		! Anything to restore?
	bz,pt	%icc, 1f
	 nop
	call	_C_LABEL(loadfpstate)
	 mov	%l0, %o0
1:
!	return			! Does this work?
	 wr	%l1, 0, %fprs
	ret
	 restore
#else /* NEW_FPSTATE */	/* NEW_FPSTATE */
#ifdef DEBUG
	ldx	[%l1 + %lo(FPPROC)], %l7
	cmp	%l7, %l5
	tnz	1		! fpproc has changed!
	ldx	[%l5 + P_FPSTATE], %l7
	cmp	%l7, %l0
	tnz	1		! fpstate has changed!
#endif	/* DEBUG */
	stx	%g0, [%l1 + %lo(FPPROC)]		! Clear fpproc
	stx	%l6, [%l5 + P_FPSTATE]			! Restore old fpstate
	wr	%g0, 0, %fprs				! Disable FPU
	ret
	 restore
#endif /* NEW_FPSTATE */	/* NEW_FPSTATE */
#else /* PMAP_FPSTATE */	/* PMAP_FPSTATE */
	retl					! Any other mappings have inconsistent D$
	 wr	%g0, 0, %fprs			! Turn off FPU and mark as clean
#endif /* PMAP_FPSTATE */	/* PMAP_FPSTATE */
pmap_zero_phys:
#endif /* PMAP_PHYS_PAGE */	/* PMAP_PHYS_PAGE */
#if 1
a6230 13
#else	/* 1 */
	set	NBPG-8, %o1
	add	%o1, %o0, %o1
1:
	stxa	%g0, [%o0] ASI_PHYS_CACHED
	cmp	%o0, %o1
	blt	1b
	 inc	8, %o0
	ba	_C_LABEL(blast_vcache)	! Clear out D$ and return
	 nop
	retl
	 nop
#endif	/* 1 */
a6249 288
#ifdef DEBUG
	set	pmapdebug, %o4
	ld	[%o4], %o4
	btst	0x80, %o4	! PDB_COPY
	bz,pt	%icc, 3f
	 nop
	save	%sp, -CC64FSZ, %sp
	mov	%i0, %o1
	set	2f, %o0
	call	printf
	 mov	%i1, %o2
!	ta	1; nop
	restore
	.data
2:	.asciz	"pmap_copy_page(%p,%p)\n"
	_ALIGN
	.text
3:
#endif	/* DEBUG */
#ifndef PMAP_PHYS_PAGE
/*
 * Here we use VIS instructions to do a block clear of a page.
 * First we zero out the FP registers we'll use.  If they were
 * dirty this should cause a trap to save them.
 * Then we need to turn off interrupts so we don't have to deal
 * with possibly saving or restoring state.  Then we map the page
 * into the special VA we use for this purpose.
 *
 * NB:	 THIS WILL ALWAYS ENABLE INTERRUPTS IN PSTATE ON EXIT
 */
	sethi	%hi(_C_LABEL(vmmap)), %o2	! Get VA
	ldx	[%o2 + %lo(_C_LABEL(vmmap))], %o2
	brz,pn	%o2, pmap_copy_phys
	 or	%o2, 0x020, %o3			! Nucleus flush page

#ifdef PMAP_FPSTATE
#ifndef NEW_FPSTATE
	!!
	!! This code will allow us to save the fpstate around this
	!! routine and nest FP use in the kernel
	!!
	save	%sp, -(CC64FSZ+FS_SIZE+BLOCK_SIZE), %sp	! Allocate an fpstate
	add	%sp, (CC64FSZ+BIAS+BLOCK_SIZE-1), %l0	! Calculate pointer to fpstate
	andn	%l0, BLOCK_ALIGN, %l0		! And make it block aligned
	rd	%fprs, %l1			! Save old fprs so we can restore it later
	call	_C_LABEL(savefpstate)
	 mov	%l0, %o0
	mov	%i0, %o0
	mov	%i1, %o1
	mov	%i2, %o2
	mov	%i3, %o3
	wr	%g0, FPRS_FEF, %fprs
#else	/* NEW_FPSTATE */	/* NEW_FPSTATE */
/*
 * New version, new scheme:
 *
 * Here we use VIS instructions to do a block clear of a page.
 * But before we can do that we need to save and enable the FPU.
 * The last owner of the FPU registers is fpproc, and
 * fpproc->p_md.md_fpstate is the current fpstate.  If that's not
 * null, call savefpstate() with it to store our current fp state.
 *
 * Next, allocate an aligned fpstate on the stack.  We will properly
 * nest calls on a particular stack so this should not be a problem.
 *
 * Now we grab either curproc (or if we're on the interrupt stack
 * proc0).  We stash its existing fpstate in a local register and
 * put our new fpstate in curproc->p_md.md_fpstate.  We point
 * fpproc at curproc (or proc0) and enable the FPU.
 *
 * If we are ever preempted, our FPU state will be saved in our
 * fpstate.  Then, when we're resumed and we take an FPDISABLED
 * trap, the trap handler will be able to fish our FPU state out
 * of curproc (or proc0).
 *
 * On exiting this routine we undo the damage: restore the original
 * pointer to curproc->p_md.md_fpstate, clear our fpproc, and disable
 * the MMU.
 *
 */
	!!
	!! This code will allow us to save the fpstate around this
	!! routine and nest FP use in the kernel
	!!
	save	%sp, -(CC64FSZ+FS_SIZE+BLOCK_SIZE), %sp	! Allocate an fpstate
	sethi	%hi(FPPROC), %l1
	ldx	[%l1 + %lo(FPPROC)], %l2		! Load fpproc
	add	%sp, (CC64FSZ+BIAS+BLOCK_SIZE-1), %l0	! Calculate pointer to fpstate
	brz,pt	%l2, 1f					! fpproc == NULL?
	 andn	%l0, BLOCK_ALIGN, %l0			! And make it block aligned
	ldx	[%l2 + P_FPSTATE], %l3
	brz,pn	%l3, 1f					! Make sure we have an fpstate
	 mov	%l3, %o0
	call	_C_LABEL(savefpstate)			! Save the old fpstate
	 set	EINTSTACK-BIAS, %l4			! Are we on intr stack?
	cmp	%sp, %l4
	bgu,pt	%xcc, 1f
	 set	INTSTACK-BIAS, %l4
	cmp	%sp, %l4
	blu	%xcc, 1f
0:
	 sethi	%hi(_C_LABEL(proc0)), %l4		! Yes, use proc0
	ba,pt	%xcc, 2f
	 or	%l4, %lo(_C_LABEL(proc0)), %l5
1:
	sethi	%hi(CURPROC), %l4			! No, use curproc
	ldx	[%l4 + %lo(CURPROC)], %l5
	brz,pn	%l5, 0b					! If curproc is NULL need to use proc0
2:
	mov	%i0, %o0
	mov	%i2, %o2
	ldx	[%l5 + P_FPSTATE], %l6			! Save old fpstate
	mov	%i3, %o3
	stx	%l0, [%l5 + P_FPSTATE]			! Insert new fpstate
	stx	%l5, [%l1 + %lo(FPPROC)]		! Set new fpproc
	wr	%g0, FPRS_FEF, %fprs			! Enable FPU
#endif	/* NEW_FPSTATE */	/* NEW_FPSTATE */
#else	/* PMAP_FPSTATE */	/* PMAP_FPSTATE */
	!!
	!! Don't use FP regs if the kernel's already using them
	!!
	rd	%fprs, %o5			! Read old %fprs
	sethi	%hi(FPPROC), %o4		! Also load fpproc
	btst	FPRS_DU|FPRS_DL, %o5		! Is it dirty?
	ldx	[%o4 + %lo(FPPROC)], %o4
	bz,pt	%icc, 1f			! No, use fpregs
	 bset	FPRS_FEF, %o5
	brz,pn	%o4, pmap_copy_phys		! No userland fpstate so do this the slow way
1:
	 wr	%o5, 0, %fprs			! Enable the FPU
#endif	/* PMAP_FPSTATE */	/* PMAP_FPSTATE */

#ifdef DEBUG
	sethi	%hi(paginuse), %o4		! Prevent this from nesting
	lduw	[%o4 + %lo(paginuse)], %o5
	tst	%o5
	tnz	%icc, 1
	bnz,pn	%icc, pmap_copy_phys
	 inc	%o5
	stw	%o5, [%o4 + %lo(paginuse)]
#endif	/*  DEBUG */	/* DEBUG */

	rdpr	%pil, %g1
	wrpr	%g0, 15, %pil			! s = splhigh();

	stxa	%o3, [%o3] ASI_DMMU_DEMAP	! Do the demap
	sethi	%hi(NBPG), %o4
	membar	#Sync				! No real reason for this XXXX
	add	%o3, %o4, %o3
	stxa	%o3, [%o3] ASI_DMMU_DEMAP	! Demap the next page too
	membar	#Sync				! No real reason for this XXXX

	sethi	%hi(0x80000000), %o4		! Setup TTE:
	sllx	%o4, 32, %o4			!  V = 1
	or	%o4, TTE_CP|TTE_P|TTE_W|TTE_L, %o4	!  CP=1|P=1|W=1|L=1
	or	%o4, %o0, %o0			! TTE for source page XXX Should be RO
	or	%o4, %o1, %o1			! TTE for dest page

	mov	TLB_TAG_ACCESS, %o5
	stxa	%o2, [%o5] ASI_DMMU		! Store new address for mapping
	membar	#Sync				! No real reason for this XXXX
	stxa	%o0, [%g0] ASI_DMMU_DATA_IN	! Store TTE for new mapping
	membar	#Sync

	sethi	%hi(NBPG), %o4
	add	%o2, %o4, %o4			! %o4 point to dest
	stxa	%o4, [%o5] ASI_DMMU		! Store new address for mapping
	membar	#Sync				! No real reason for this XXXX
	stxa	%o1, [%g0] ASI_DMMU_DATA_IN	! Store TTE for new mapping
	membar	#Sync

	set	NBPG, %o5			! # bytes to move

	ldda	[%o2] ASI_BLK_P, %f0		! Load 1st bank
	dec	BLOCK_SIZE, %o5
	add	%o2, BLOCK_SIZE, %o2
1:
	membar	#StoreLoad
	ldda	[%o2] ASI_BLK_P, %f16		! Load 2nd bank
	dec	BLOCK_SIZE, %o5
	add	%o2, BLOCK_SIZE, %o2

	membar	#LoadStore
	fmovd	%f14, %f14			! Sync 1st bank
	stda	%f0, [%o4] ASI_BLK_COMMIT_P	! Store 1st bank
	brlez,pn	%o5, 1f			! Finished?
	 add	%o4, BLOCK_SIZE, %o4

	membar	#StoreLoad
	ldda	[%o2] ASI_BLK_P, %f0		! Load 1st bank
	dec	BLOCK_SIZE, %o5
	add	%o2, BLOCK_SIZE, %o2

	membar	#LoadStore
	fmovd	%f30, %f30			! Sync 2nd bank
	stda	%f16, [%o4] ASI_BLK_COMMIT_P	! Store 2nd bank
	brgz,pt	%o5, 1b				! Finished?
	 add	%o4, BLOCK_SIZE, %o4

	!!
	!! If we got here we have loaded bank 1 and stored bank 2
	!!
	membar	#Sync
	fmovd	%f14, %f14			! Sync 1st bank
	stda	%f0, [%o4] ASI_BLK_COMMIT_P	! Store 1st bank
	ba,pt	%icc, 2f			! Finished?
	 add	%o4, BLOCK_SIZE, %o4

1:
	!!
	!! If we got here we have loaded bank 2 and stored bank 1
	!!
	membar	#Sync
	fmovd	%f30, %f30			! Sync 2nd bank
	stda	%f16, [%o4] ASI_BLK_COMMIT_P	! Store 2nd bank
	add	%o4, BLOCK_SIZE, %o4

2:
	membar	#Sync				! Finish the operation
	stxa	%o3, [%o3] ASI_DMMU_DEMAP	! Demap the dest page again
	sethi	%hi(NBPG), %o4
	membar	#Sync				! No real reason for this XXXX
	sub	%o3, %o4, %o3
	stxa	%o3, [%o3] ASI_DMMU_DEMAP	! Demap the source page again
	membar	#Sync				! No real reason for this XXXX


	wrpr	%g1, 0, %pil			! splx(s)

#ifdef PMAP_FPSTATE
#ifndef NEW_FPSTATE
	btst	FPRS_DU|FPRS_DL, %l1		! Anything to restore?
	bz,pt	%icc, 1f
	 nop
	call	_C_LABEL(loadfpstate)
	 mov	%l0, %o0
1:
!	return			! Does this work?
	 wr	%l1, 0, %fprs
	ret
	 restore
#else	/* NEW_FPSTATE */	/* NEW_FPSTATE */
#ifdef DEBUG
	ldx	[%l1 + %lo(FPPROC)], %l7
	cmp	%l7, %l5
	tnz	1		! fpproc has changed!
	ldx	[%l5 + P_FPSTATE], %l7
	cmp	%l7, %l0
	tnz	1		! fpstate has changed!
#endif	/* DEBUG */	/* DEBUG */
	stx	%g0, [%l1 + %lo(FPPROC)]		! Clear fpproc
	stx	%l6, [%l5 + P_FPSTATE]			! Save old fpstate
	wr	%g0, 0, %fprs				! Disable FPU
	ret
	 restore
#endif	/* NEW_FPSTATE */	/* NEW_FPSTATE */
#else	/* PMAP_FPSTATE */	/* PMAP_FPSTATE */
	ba	_C_LABEL(blast_vcache)
	 wr	%g0, 0, %fprs			! Turn off FPU and mark as clean

	retl					! Any other mappings have inconsistent D$
	 wr	%g0, 0, %fprs			! Turn off FPU and mark as clean
#endif	/* PMAP_FPSTATE */	/* PMAP_FPSTATE */
pmap_copy_phys:
#endif	/* PMAP_PHYS_PAGE */	/* PMAP_PHYS_PAGE */
#if 0
	/* This is the short, slow, safe version that uses %g1 */

	set	NBPG, %o3
	clr	%o2
	mov	%g1, %o4		! Save g1
1:
	DLFLUSH %o0,%g1
	ldxa	[%o0] ASI_PHYS_CACHED, %g1
	inc	8, %o0
	stxa	%g1, [%o1] ASI_PHYS_CACHED
	inc	8, %o1

	dec	8, %o3
	stxa	%g0, [%o2] ASI_DCACHE_TAG! Blast away at the D$
	brnz,pt	%o3, 1b
	 inc	16, %o2
	mov	%o4, %g1
	sethi	%hi(KERNBASE), %o5
	flush	%o5
	retl
	 nop
#else	/* 0 */
a6261 4
#if 0
	ba	_C_LABEL(blast_vcache)	! Clear out D$ and return
	 mov	%o4, %g1		! Restore g1
#endif	/* 0 */
a6263 1
#endif	/* 0 */
@


1.34
log
@removed INTRLIST (always do this)
removed PARANOID (never do this)
removed TRAPTRACE (never do this)
removes more LP64 stuff
changes a whole bunch of multi-line #defines to macros
moves all random code into macros for the trap table
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.32 2003/05/13 01:33:06 jason Exp $	*/
a59 2
#undef	FLTRACE			/* Keep history of all page faults */
#undef	TRAPSTATS		/* Count traps */
a65 1
#undef	SCHED_DEBUG
a407 35
#ifdef TRAPTRACE
#define TRACEME		sethi %hi(1f), %g1; ba,pt %icc,traceit;\
 or %g1, %lo(1f), %g1; 1:
#if 0
#define TRACEWIN	sethi %hi(9f), %l6; ba,pt %icc,traceitwin;\
 or %l6, %lo(9f), %l6; 9:
#endif	/* 0 */
#ifdef TRAPS_USE_IG
#define TRACEWIN	wrpr %g0, PSTATE_KERN|PSTATE_AG, %pstate;\
 sethi %hi(9f), %g1; ba,pt %icc,traceit; or %g1, %lo(9f), %g1; 9:
#else	/* TRAPS_USE_IG */
#define TRACEWIN	wrpr %g0, PSTATE_KERN|PSTATE_IG, %pstate;\
 sethi %hi(9f), %g1; ba,pt %icc,traceit; or %g1, %lo(9f), %g1; 9:
#endif	/* TRAPS_USE_IG */
#define TRACERELOAD32	ba reload32; nop;
#define TRACERELOAD64	ba reload64; nop;
#define TRACEFLT	TRACEME
	.macro VTRAP type, label 
	sethi	%hi(\label), %g1
	ba,pt	%icc,traceit
	or	%g1, %lo(\label), %g1
	NOTREACHED
	TA8
	.endm
#else	/* TRAPTRACE */
#define TRACEME
#define TRACEWIN	TRACEME
#define TRACERELOAD32
#define TRACERELOAD64
#ifdef FLTRACE
#define TRACEFLT	sethi %hi(1f), %g1; ba,pt %icc,traceit;\
 or %g1, %lo(1f), %g1; 1:
#else	/* FLTRACE */
#define TRACEFLT	TRACEME
#endif	/* FLTRACE */
a416 1
#endif	/* TRAPTRACE */
a417 36
#ifdef TRAPTRACE
#define TRACEME		sethi %hi(1f), %g1; ba,pt %icc,traceit;\
 or %g1, %lo(1f), %g1; 1:
#if 0
/* Can't use this 'cause we have no clean registers during a spill */
#define TRACEWIN	sethi %hi(9f), %l6; ba,pt %icc,traceitwin;\
 or %l6, %lo(9f), %l6; 9:
#endif	/* 0 */
#ifdef TRAPS_USE_IG
#define TRACEWIN	wrpr %g0, PSTATE_KERN|PSTATE_AG, %pstate;\
 sethi %hi(9f), %g1; ba,pt %icc,traceit; or %g1, %lo(9f), %g1; 9:
#else	/* TRAPS_USE_IG */
#define TRACEWIN	wrpr %g0, PSTATE_KERN|PSTATE_IG, %pstate;\
 sethi %hi(9f), %g1; ba,pt %icc,traceit; or %g1, %lo(9f), %g1; 9:
#endif	/* TRAPS_USE_IG */
#define TRACERELOAD32	ba reload32; nop;
#define TRACERELOAD64	ba reload64; nop;
#define TRACEFLT	TRACEME
	.macro VTRAP type, label
	sethi	%hi(\label), %g1
	ba,pt	%icc,traceit
	or	%g1, %lo(\label), %g1
	NOTREACHED
	TA8
	.endm
#else	/* TRAPTRACE */
#define TRACEME
#define TRACEWIN	TRACEME
#define TRACERELOAD32
#define TRACERELOAD64
#ifdef FLTRACE
#define TRACEFLT	sethi %hi(1f), %g1; ba,pt %icc,traceit;\
 or %g1, %lo(1f), %g1; 1:
#else	/* FLTRACE */
#define TRACEFLT	TRACEME
#endif	/* FLTRACE */
a423 1
#endif	/* TRAPTRACE */
a479 1
	TRACEWIN			! DEBUG -- 4 insns
a524 1
	TRACEWIN			! DEBUG
a532 13
#ifdef NOT_DEBUG
	!!
	!! Check the sp redzone
	!!
	rdpr	%wstate, t1
	cmp	t1, WSTATE_KERN
	bne,pt	icc, 7f
	 sethi	%hi(_C_LABEL(redzone)), t1
	ldx	[t1 + %lo(_C_LABEL(redzone))], t2
	cmp	%sp, t2			! if sp >= t2, not in red zone
	blu	panic_red		! and can continue normally
7:
#endif	/* NOT_DEBUG */
a541 1
	TRACEFLT			! DEBUG
a557 1
	TRACEFLT			! DEBUG
a565 6
#ifdef TRAPSTATS
	sethi	%hi(_C_LABEL(udhit)), %g1
	lduw	[%g1+%lo(_C_LABEL(udhit))], %g2
	inc	%g2
	stw	%g2, [%g1+%lo(_C_LABEL(udhit))]
#endif	/* TRAPSTATS */
a575 1
	TRACEFLT			! DEBUG
a591 7
	TRACEFLT			! DEBUG -- we're perilously close to 32 insns
#ifdef TRAPSTATS
	sethi	%hi(_C_LABEL(\dprot)), %g1
	lduw	[%g1+%lo(_C_LABEL(\dprot))], %g2
	inc	%g2
	stw	%g2, [%g1+%lo(_C_LABEL(\dprot))]
#endif	/* TRAPSTATS */
a601 1
	TRACEWIN
a613 1
	TRACEWIN
a626 1
	TRACEWIN
a637 1
	TRACEWIN
a649 1
	TRACEWIN
a662 1
	TRACEWIN
a1205 155
#if	defined(TRAPTRACE)||defined(FLTRACE)
#define TRACEPTR	(_C_LABEL(trap_trace_ptr)-_C_LABEL(trap_trace))
#define TRACEDIS	(_C_LABEL(trap_trace_dis)-_C_LABEL(trap_trace))
! hm.  nothing uses this right now... mdw
	.macro TRACEIT tt,r3,r4,r2,r6,r7
	set	trap_trace, \r2
	lduw	[\r2+TRACEDIS], \r4
	brnz,pn	\r4, 1f
	 lduw	[\r2+TRACEPTR], \r3
	rdpr	%tl, \r4
	cmp	\r4, 1
	sllx	\r4, 13, \r4
	rdpr	%pil, \r6
	or	\r4, %g5, \r4
	mov	%g0, %g5
	andncc	\r3, (TRACESIZ-1), %g0	! At end of buffer?
	sllx	\r6, 9, \r6
	or	\r6, \r4, \r4
	movnz	%icc, %g0, \r3		! Wrap buffer if needed
	rdpr	%tstate, \r6
	rdpr	%tpc, \r7
	sth	\r4, [\r2+\r3]
	inc	2, \r3
	sth	%g5, [\r2+\r3]
	inc	2, \r3
	stw	\r6, [\r2+\r3]
	inc	4, \r3
	stw	%sp, [\r2+\r3]
	inc	4, \r3
	stw	\r7, [\r2+\r3]
	inc	4, \r3
	mov	TLB_TAG_ACCESS, \r7
	ldxa	[\r7] ASI_DMMU, \r7
	stw	\r7, [\r2+\r3]
	inc	4, \r3
	stw	\r3, [\r2+TRACEPTR]
1:
.endm


	.text
traceit:
	set	trap_trace, %g2
	lduw	[%g2+TRACEDIS], %g4
	brnz,pn	%g4, 1f
	 lduw	[%g2+TRACEPTR], %g3
	rdpr	%tl, %g4
	rdpr	%tt, %g5
	set	CURPROC, %g6
	cmp	%g4, 1
	sllx	%g4, 13, %g4
	bnz,a,pt	%icc, 3f
	 clr	%g6
	cmp	%g5, 0x68
	bnz,a,pt	%icc, 3f
	 clr	%g6
	cmp	%g5, 0x64
	bnz,a,pt	%icc, 3f
	 clr	%g6
	cmp	%g5, 0x6c
	bnz,a,pt	%icc, 3f
	 clr	%g6
	ldx	[%g6], %g6
3:
	or	%g4, %g5, %g4
	mov	%g0, %g5
	brz,pn	%g6, 2f
	 andncc	%g3, (TRACESIZ-1), %g0	! At end of buffer? wrap
	ldx	[%g6+P_PID], %g5	! Load PID

	set	CPCB, %g6	! Load up nsaved
	ldx	[%g6], %g6
	ldub	[%g6 + PCB_NSAVED], %g6
	sllx	%g6, 9, %g6
	or	%g6, %g4, %g4
2:

	movnz	%icc, %g0, %g3		! Wrap buffer if needed
	rdpr	%tstate, %g6
	rdpr	%tpc, %g7
	sth	%g4, [%g2+%g3]
	inc	2, %g3
	sth	%g5, [%g2+%g3]
	inc	2, %g3
	stw	%g6, [%g2+%g3]
	inc	4, %g3
	stw	%sp, [%g2+%g3]
	inc	4, %g3
	stw	%g7, [%g2+%g3]
	inc	4, %g3
	mov	TLB_TAG_ACCESS, %g7
	ldxa	[%g7] ASI_DMMU, %g7
	stw	%g7, [%g2+%g3]
	inc	4, %g3
1:
	jmpl	%g1, %g0
	 stw	%g3, [%g2+TRACEPTR]
traceitwin:
	set	trap_trace, %l2
	lduw	[%l2+TRACEDIS], %l4
	brnz,pn	%l4, 1f
	 nop
	lduw	[%l2+TRACEPTR], %l3
	rdpr	%tl, %l4
	rdpr	%tt, %l5
	sllx	%l4, 13, %l4
	or	%l4, %l5, %l4
	clr	%l5		! Don't load PID
	andncc	%l3, (TRACESIZ-1), %g0
	movnz	%icc, %g0, %l3	! Wrap?

	clr	%l0		! Don't load nsaved
	sllx	%l0, 9, %l1
	or	%l1, %l4, %l4
	rdpr	%tpc, %l7

	sth	%l4, [%l2+%l3]
	inc	2, %l3
	sth	%l5, [%l2+%l3]
	inc	2, %l3
	stw	%l0, [%l2+%l3]
	inc	4, %l3
	stw	%sp, [%l2+%l3]
	inc	4, %l3
	stw	%l7, [%l2+%l3]
	inc	4, %l3
	stw	%g0, [%l2+%l3]
	inc	4, %l3
	stw	%l3, [%l2+TRACEPTR]
1:
	jmpl	%l6, %g0
	 nop
reload64:
	ldxa	[%sp+BIAS+0x00]%asi, %l0
	ldxa	[%sp+BIAS+0x08]%asi, %l1
	ldxa	[%sp+BIAS+0x10]%asi, %l2
	ldxa	[%sp+BIAS+0x18]%asi, %l3
	ldxa	[%sp+BIAS+0x20]%asi, %l4
	ldxa	[%sp+BIAS+0x28]%asi, %l5
	ldxa	[%sp+BIAS+0x30]%asi, %l6
	ldxa	[%sp+BIAS+0x38]%asi, %l7
	CLRTT
	retry
reload32:
	lda	[%sp+0x00]%asi, %l0
	lda	[%sp+0x04]%asi, %l1
	lda	[%sp+0x08]%asi, %l2
	lda	[%sp+0x0c]%asi, %l3
	lda	[%sp+0x10]%asi, %l4
	lda	[%sp+0x14]%asi, %l5
	lda	[%sp+0x18]%asi, %l6
	lda	[%sp+0x1c]%asi, %l7
	CLRTT
	retry
#endif	/*  */
a1574 6
#ifdef TRAPSTATS
	sethi	%hi(_C_LABEL(protfix)), %g1
	lduw	[%g1+%lo(_C_LABEL(protfix))], %g2
	inc	%g2
	stw	%g2, [%g1+%lo(_C_LABEL(protfix))]
#endif	/* TRAPSTATS */
a1608 10
#ifdef TRAPSTATS
	set	_C_LABEL(kdmiss), %g3
	set	_C_LABEL(udmiss), %g4
	rdpr	%tl, %g6
	dec	%g6
	movrz	%g6, %g4, %g3
	lduw	[%g3], %g4
	inc	%g4
	stw	%g4, [%g3]
#endif	/* TRAPSTATS */
a1791 6
#ifdef TRAPSTATS
	set	_C_LABEL(wfill), %g1
	lduw	[%g1], %g5
	inc	%g5
	stw	%g5, [%g1]
#endif	/* TRAPSTATS */
a1812 6
#ifdef TRAPSTATS
	set	_C_LABEL(kwfill), %g4
	lduw	[%g4], %g7
	inc	%g7
	stw	%g7, [%g4]
#endif	/* TRAPSTATS */
a1906 6
#ifdef TRAPSTATS
	set	_C_LABEL(wspill), %g7
	lduw	[%g7], %g5
	inc	%g5
	stw	%g5, [%g7]
#endif	/* TRAPSTATS */
a1969 11
#ifdef NOTDEF_DEBUG
	add	%g6, PCB_NSAVED, %g7
	DLFLUSH %g7,%g5
	lduba	[%g6 + PCB_NSAVED] %asi, %g7		! make sure that pcb_nsaved
	DLFLUSH2 %g5
	brz,pt	%g7, 1f					! is zero, else
	 nop
	wrpr	%g0, 4, %tl
	sir						! Force a watchdog
1:
#endif	/* NOTDEF_DEBUG */
a2066 10
#ifdef NOT_DEBUG
	rdpr	%wstate, %g5				! DEBUG
	wrpr	%g0, WSTATE_KERN, %wstate		! DEBUG
	wrpr	%g0, 4, %tl
	rdpr	%cansave, %g7
	rdpr	%canrestore, %g6
	flushw						! DEBUG
	wrpr	%g2, 0, %tl
	wrpr	%g5, 0, %wstate				! DEBUG
#endif	/* NOT_DEBUG */
a2099 8
#ifdef NOT_DEBUG
	rdpr	%wstate, %g5				! DEBUG
	wrpr	%g0, WSTATE_KERN, %wstate		! DEBUG
	wrpr	%g0, 4, %tl
	flushw						! DEBUG
	wrpr	%g2, 0, %tl
	wrpr	%g5, 0, %wstate				! DEBUG
#endif	/* NOT_DEBUG */
a2101 19
#ifdef NOTDEF_DEBUG
	set	panicstack-CC64FSZ, %g1
	save	%g1, 0, %sp
	GLOBTOLOC
	rdpr	%wstate, %l0
	wrpr	%g0, WSTATE_KERN, %wstate
	set	8f, %o0
	mov	%g7, %o1
	call	printf
	 mov	%g5, %o2
	wrpr	%l0, 0, %wstate
	LOCTOGLOB
	restore
	.data
8:
	.asciz	"winfix: spill fixup\n"
	_ALIGN
	.text
#endif	/* NOTDEF_DEBUG */
a2161 24
#ifdef NOTDEF_DEBUG
	set	panicstack-CC64FSZ, %g5
	save	%g5, 0, %sp
	GLOBTOLOC
	rdpr	%wstate, %l0
	wrpr	%g0, WSTATE_KERN, %wstate
	set	8f, %o0
	call	printf
	 mov	%fp, %o1
	wrpr	%l0, 0, %wstate
	LOCTOGLOB
	restore
	.data
8:
	.asciz	"winfix: kernel spill retry\n"
	_ALIGN
	.text
#endif	/* NOTDEF_DEBUG */
#ifdef TRAPSTATS
	set	_C_LABEL(wspillskip), %g4
	lduw	[%g4], %g5
	inc	%g5
	stw	%g5, [%g4]
#endif	/* TRAPSTATS */
a2280 18
#ifdef NOTDEF_DEBUG
	set	CPCB, %o7
	ldx	[%o7], %o7
	ldub	[%o7 + PCB_NSAVED], %o7
	brz,pt	%o7, 2f
	 nop
	save	%sp, -CC64FSZ, %sp
	set	1f, %o0
	call printf
	 mov	%i7, %o1
	ta	1; nop
	 restore
	.data
1:	.asciz	"datafault: nsaved = %d\n"
	_ALIGN
	.text
2:
#endif	/* NOTDEF_DEBUG */
a2307 6
#ifdef TRAPSTATS
	set	_C_LABEL(uintrcnt), %g1
	stw	%g0, [%g1]
	set	_C_LABEL(iveccnt), %g1
	stw	%g0, [%g1]
#endif	/* TRAPSTATS */
a2339 10
#ifdef TRAPSTATS
	set	_C_LABEL(ktmiss), %g3
	set	_C_LABEL(utmiss), %g4
	rdpr	%tl, %g6
	dec	%g6
	movrz	%g6, %g4, %g3
	lduw	[%g3], %g4
	inc	%g4
	stw	%g4, [%g3]
#endif	/* TRAPSTATS */
a3092 10
#ifdef TRAPSTATS
	set	_C_LABEL(kiveccnt), %g1
	set	_C_LABEL(iveccnt), %g2
	rdpr	%tl, %g3
	dec	%g3
	movrz	%g3, %g2, %g1
	lduw	[%g1], %g2
	inc	%g2
	stw	%g2, [%g1]
#endif	/* TRAPSTATS */
a3098 13
#if NOT_DEBUG
	STACKFRAME -CC64FSZ		! Get a clean register window
	mov	%g1, %o1
	mov	%g2, %o2

	LOAD_ASCIZ(%o0, "interrupt_vector: ASI_IRSR %lx ASI_IRDR(0x40) %lx\r\n")
	GLOBTOLOC
	call	prom_printf
	 clr	%g4
	LOCTOGLOB
	restore
	 nop
#endif	/* NOT_DEBUG */
a3126 4
#ifdef NOT_DEBUG
	tst	%g5
	tz	56
#endif	/* NOT_DEBUG */
a3277 27
#ifdef TRAPSTATS
	sethi	%hi(_C_LABEL(kintrcnt)), %g1
	sethi	%hi(_C_LABEL(uintrcnt)), %g2
	or	%g1, %lo(_C_LABEL(kintrcnt)), %g1
	or	%g1, %lo(_C_LABEL(uintrcnt)), %g2
	rdpr	%tl, %g3
	dec	%g3
	movrz	%g3, %g2, %g1
	lduw	[%g1], %g2
	inc	%g2
	stw	%g2, [%g1]
	/* See if we're on the interrupt stack already. */
	set	EINTSTACK, %g2
	set	(EINTSTACK-INTSTACK), %g1
	btst	1, %sp
	add	%sp, BIAS, %g3
	movz	%icc, %sp, %g3
	srl	%g3, 0, %g3
	sub	%g2, %g3, %g3
	cmp	%g3, %g1
	bgu	1f
	 set	_C_LABEL(intristk), %g1
	lduw	[%g1], %g2
	inc	%g2
	stw	%g2, [%g1]
1:
#endif	/* TRAPSTATS */
a3486 49
#ifdef NOTDEF_DEBUG
	mov	%i6, %o1
	save	%sp, -CC64FSZ, %sp
	set	1f, %o0
	mov	%i1, %o1
	ldx	[%fp + CC64FSZ + BIAS + TF_PC], %o3
	ldx	[%fp + CC64FSZ + BIAS + TF_NPC], %o4
	GLOBTOLOC
	call	printf
	 mov	%i6, %o2
	LOCTOGLOB
	restore
	.data
1:	.asciz	"rft[%x,%x,%p,%p]"
3:	.asciz	"return_from_trap: fp=%x sp=%x pc=%x\n"
	_ALIGN
	.text
2:
#endif	/* NOTDEF_DEBUG */

#ifdef NOTDEF_DEBUG
	ldx	[%sp + CC64FSZ + BIAS + TF_TSTATE], %g2
	set	TSTATE_AG, %g3
	set	4f, %g4
	and	%g2, %g3, %g3
	clr	%o1
	movrnz	%g3, %g4, %o1
	set	TSTATE_MG, %g3
	set	3f, %g4
	and	%g2, %g3, %g3
	movrnz	%g3, %g4, %o1
	set	TSTATE_IG, %g3
	set	5f, %g4
	and	%g2, %g3, %g3
	movrnz	%g3, %g4, %o1
	brz,pt	%o1, 2f
	 set	1f, %o0
	call	printf
	 nop
	ta	1; nop
	.data
1:	.asciz	"Returning to trap from %s globals\n"
3:	.asciz	"MMU"
4:	.asciz	"Altermate"
5:	.asciz	"Interrupt"
	_ALIGN
	.text
2:
#endif	/* NOTDEF_DEBUG */
a3543 5
#ifdef NOTDEF_DEBUG
	ldub	[%sp + CC64FSZ + BIAS + TF_PIL], %g5		! restore %pil
	wrpr	%g5, %pil				! DEBUG
#endif	/* NOTDEF_DEBUG */

a3572 9
#ifdef TRAPSTATS
	rdpr	%tl, %g2
	set	_C_LABEL(rftkcnt), %g1
	sllx	%g2, 2, %g2
	add	%g1, %g2, %g1
	lduw	[%g1], %g2
	inc	%g2
	stw	%g2, [%g1]
#endif	/* TRAPSTATS */
a3597 25
#ifdef NOTDEF_DEBUG
	sethi	%hi(CPCB), %g4
	ldx	[%g4 + %lo(CPCB)], %g4
	ldub	[%g4 + PCB_NSAVED], %g4		! nsaved
	brz,pt	%g4, 2f		! Only print if nsaved <> 0
	 nop

	set	1f, %o0
	mov	%g4, %o1
	mov	%g2, %o2			! pc
	wr	%g0, ASI_DMMU, %asi		! restore the user context
	ldxa	[CTX_SECONDARY] %asi, %o3	! ctx
	GLOBTOLOC
	mov	%g3, %o5
	call	printf
	 mov	%i6, %o4			! sp
!	wrpr	%g0, PSTATE_INTR, %pstate		! Allow IRQ service
!	wrpr	%g0, PSTATE_KERN, %pstate		! DenyIRQ service
	LOCTOGLOB
1:
	.data
	.asciz	"rft_user: nsaved=%x pc=%d ctx=%x sp=%x npc=%p\n"
	_ALIGN
	.text
#endif	/* NOTDEF_DEBUG */
a3601 6
#ifdef TRAPSTATS
	set	_C_LABEL(rftucnt), %g6
	lduw	[%g6], %g7
	inc	%g7
	stw	%g7, [%g6]
#endif	/* TRAPSTATS */
a3713 6
#ifdef TRAPSTATS
	set	_C_LABEL(rftuld), %g5
	lduw	[%g5], %g4
	inc	%g4
	stw	%g4, [%g5]
#endif	/* TRAPSTATS */
a3751 42
#ifdef NOTDEF_DEBUG
	ldx	[%g6 + CC64FSZ + BIAS + TF_L + (0*8)], %g5! DEBUG -- get proper value for %l0
	cmp	%l0, %g5
	be,a,pt %icc, 1f
	 nop
!	sir			! WATCHDOG
	set	badregs, %g1	! Save the suspect regs
	stw	%l0, [%g1+(4*0)]
	stw	%l1, [%g1+(4*1)]
	stw	%l2, [%g1+(4*2)]
	stw	%l3, [%g1+(4*3)]
	stw	%l4, [%g1+(4*4)]
	stw	%l5, [%g1+(4*5)]
	stw	%l6, [%g1+(4*6)]
	stw	%l7, [%g1+(4*7)]
	stw	%i0, [%g1+(4*8)+(4*0)]
	stw	%i1, [%g1+(4*8)+(4*1)]
	stw	%i2, [%g1+(4*8)+(4*2)]
	stw	%i3, [%g1+(4*8)+(4*3)]
	stw	%i4, [%g1+(4*8)+(4*4)]
	stw	%i5, [%g1+(4*8)+(4*5)]
	stw	%i6, [%g1+(4*8)+(4*6)]
	stw	%i7, [%g1+(4*8)+(4*7)]
	save
	inc	%g7
	wrpr	%g7, 0, %otherwin
	wrpr	%g0, 0, %canrestore
	wrpr	%g0, WSTATE_KERN, %wstate	! Need to know where our sp points
	set	rft_wcnt, %g4	! Restore nsaved before trapping
	sethi	%hi(CPCB), %g6
	ldx	[%g6 + %lo(CPCB)], %g6
	lduw	[%g4], %g4
	stb	%g4, [%g6 + PCB_NSAVED]
	ta	1
	sir
	.data
badregs:
	.space	16*4
	.text
1:
#endif	/* NOTDEF_DEBUG */

a3765 6
#ifdef TRAPSTATS
	set	_C_LABEL(rftudone), %g1
	lduw	[%g1], %g2
	inc	%g2
	stw	%g2, [%g1]
#endif	/* TRAPSTATS */
a4431 11
#ifdef NOTDEF_DEBUG
	set	1f, %o0		! Debug printf
	srax	%l0, 32, %o1
	call	_C_LABEL(prom_printf)
	 srl	%l0, 0, %o2
	.data
1:
	.asciz	"Our trap handler is enabled\r\n"
	_ALIGN
	.text
#endif	/* NOTDEF_DEBUG */
a4498 6
#ifdef NOTDEF_DEBUG
	mov	%o7, %o5
	call	globreg_check
	 nop
	mov	%o5, %o7
#endif	/* NOTDEF_DEBUG */
a4608 12
#ifdef NOTDEF_DEBUG
	save	%sp, -CC64FSZ, %sp
	set	1f, %o0
	call	printf
	 mov	%i0, %o1
	restore
	.data
1:
	.asciz	"tlb_flush_ctx:	context flush of %d attempted\r\n"
	_ALIGN
	.text
#endif	/* NOTDEF_DEBUG */
a4982 14
#ifdef NOTDEF_DEBUG
	save	%sp, -CC64FSZ, %sp
	set	8f, %o0
	mov	%i0, %o1
	mov	%i1, %o2
	mov	%i2, %o3
	call	printf
	 mov	%i3, %o4
	restore
	.data
8:	.asciz	"copyinstr: from=%x to=%x max=%x &len=%x\n"
	_ALIGN
	.text
#endif	/* NOTDEF_DEBUG */
a5015 14
#ifdef NOTDEF_DEBUG
	save	%sp, -CC64FSZ, %sp
	set	8f, %o0
	mov	%i0, %o1
	mov	%i1, %o2
	mov	%i2, %o3
	call	printf
	 mov	%i3, %o4
	restore
	.data
8:	.asciz	"copyoutstr: from=%x to=%x max=%x &len=%x\n"
	_ALIGN
	.text
#endif	/* NOTDEF_DEBUG */
a5047 11
#ifdef NOTDEF_DEBUG
	save	%sp, -CC64FSZ, %sp
	set	5f, %o0
	call	printf
	 nop
	restore
	.data
5:	.asciz	"Lcsfault: recovering\n"
	_ALIGN
	.text
#endif	/* NOTDEF_DEBUG */
a5108 13
#ifdef NOTDEF_DEBUG
	save	%sp, -CC64FSZ, %sp
	set	1f, %o0
	mov	%i0, %o1
	mov	%i1, %o2
	call	printf
	 mov	%i2, %o3
	restore
	.data
1:	.asciz	"copyin: src=%x dest=%x len=%x\n"
	_ALIGN
	.text
#endif	/* NOTDEF_DEBUG */
a5301 15
#ifdef NOTDEF_DEBUG
	save	%sp, -CC64FSZ, %sp
	set	1f, %o0
	mov	%i0, %o1
	set	CTX_SECONDARY, %o4
	mov	%i1, %o2
	ldxa	[%o4] ASI_DMMU, %o4
	call	printf
	 mov	%i2, %o3
	restore
	.data
1:	.asciz	"copyout: src=%x dest=%x len=%x ctx=%d\n"
	_ALIGN
	.text
#endif	/* NOTDEF_DEBUG */
a5490 11
#ifdef NOTDEF_DEBUG
	save	%sp, -CC64FSZ, %sp
	set	1f, %o0
	call	printf
	 nop
	restore
	.data
1:	.asciz	"copyfault: fault occurred\n"
	_ALIGN
	.text
#endif	/* NOTDEF_DEBUG */
a5555 13
#ifdef SCHED_DEBUG
	save	%sp, -CC64FSZ, %sp
	GLOBTOLOC
	set	1f, %o0
	call	printf
	 nop
	LOCTOGLOB
	restore
	.data
1:	.asciz	"switchexit()\r\n"
	_ALIGN
	.text
#endif	/* SCHED_DEBUG */
a5655 20
#ifdef NOTDEF_DEBUG
	save	%sp, -CC64FSZ, %sp
	GLOBTOLOC
	set	idlemsg, %o0
	mov	%g1, %o1
	mov	%g2, %o2
	mov	%g3, %o3
	mov	%g5, %l5
	mov	%g6, %l6
	mov	%g7, %l7
	call	_C_LABEL(prom_printf)
	 mov	%g4, %o4
	set	idlemsg1, %o0
	mov	%l5, %o1
	mov	%l6, %o2
	call	_C_LABEL(prom_printf)
	 mov	%l7, %o3
	LOCTOGLOB
	restore
#endif	/* NOTDEF_DEBUG */
a5750 5
#ifdef NOTDEF_DEBUG
	set	_C_LABEL(intrdebug), %l1
	mov	INTRDEBUG_FUNC, %o1
	st	%o1, [%l1]
#endif	/* NOTDEF_DEBUG */
a5901 19
#ifdef SCHED_DEBUG
	mov	%l4, %g1
	mov	%l3, %g2
	save	%sp, -CC64FSZ, %sp
	set	1f, %o0
	mov	%g1, %o1
	ld	[%o1+P_PID], %o2
	mov	%g2, %o3
	call	printf
	 ld	[%o3+P_PID], %o4
	ba	2f
	 restore
	.data
1:	.asciz	"cpu_switch: %x(%d)->%x(%d)\r\n"
	_ALIGN
	.text
	Debugger();
2:
#endif	/* SCHED_DEBUG */
a5921 13
#ifdef SCHED_DEBUG
	save	%sp, -CC64FSZ, %sp
	GLOBTOLOC
	set	1f, %o0
	call	printf
	 nop
	LOCTOGLOB
	restore
	.data
1:	.asciz	"cpu_switch: loading the new process:\r\n"
	_ALIGN
	.text
#endif	/* SCHED_DEBUG */
a5925 21
#ifdef SCHED_DEBUG
	ldx	[%l1 + PCB_SP], %o0
	btst	1, %o0
	add	%o0, BIAS, %o1
	movnz	%icc, %o1, %o0
	brnz,pt	%o0, 2f
	 ldx	[%o0], %o0			! Force a fault if needed
	save	%sp, -CC64FSZ, %sp
	GLOBTOLOC
	set	1f, %o0
	call	printf
	 nop
	LOCTOGLOB
	restore
	ta 1
	.data
1:	.asciz	"cpu_switch: NULL %sp\r\n"
	_ALIGN
	.text
2:
#endif	/* SCHED_DEBUG */
a5942 16
#endif	/* DEBUG */
#ifdef SCHED_DEBUG
	mov	%fp, %i1
	save	%sp, -CC64FSZ, %sp
	GLOBTOLOC
	set	1f, %o0
	call	printf
	 mov	%i1, %o1
	LOCTOGLOB
	restore
	.data
1:	.asciz	"cpu_switch: setup new process stack regs at %08x\r\n"
	_ALIGN
	.text
#endif	/* SCHED_DEBUG */
#ifdef DEBUG
a5975 14
#ifdef SCHED_DEBUG
	mov	%o0, %g1
	save	%sp, -CC64FSZ, %sp
	GLOBTOLOC
	set	1f, %o0
	call	printf
 	 mov	%g1, %o1
	LOCTOGLOB
	restore
	.data
1:	.asciz	"cpu_switch: got new ctx %d in new process\r\n"
	_ALIGN
	.text
#endif	/* SCHED_DEBUG */
a5985 18
#ifdef SCHED_DEBUG
	mov	%o0, %g1
	mov	%i7, %g1
	save	%sp, -CC64FSZ, %sp
	GLOBTOLOC
	set	1f, %o0
	mov	%g1, %o2
	call	printf
	 mov	%g2, %o1
	LOCTOGLOB
	restore
	.data
1:	.asciz	"cpu_switch: in new process pc=%08x ctx %d\r\n"
	_ALIGN
	.text
#endif	/* SCHED_DEBUG */


a5990 33
#ifdef SCHED_DEBUG
	mov	%l0, %o0		! XXXXX
	save	%sp, -CC64FSZ, %sp
	GLOBTOLOC
	set	1f, %o0
	mov	%i0, %o2
	set	CURPROC, %o3
	ldx	[%o3], %o3
	ld	[%o3 + P_VMSPACE], %o3
	call	printf
	 mov	%i7, %o1
#ifdef DEBUG
	set	swtchdelay, %o0
	call	delay
	 ld	[%o0], %o0
	set	pmapdebug, %o0
	ld	[%o0], %o0
	tst	%o0
	tnz	%icc, 1; nop	! Call debugger if we're in pmapdebug
#endif	/* DEBUG */
	LOCTOGLOB
	ba	2f		! Skip debugger
	 restore
	.data
1:	.asciz	"cpu_switch: vectoring to pc=%08x thru %08x vmspace=%p\r\n"
	_ALIGN
	.globl	swtchdelay
swtchdelay:
	.word	1000
	.text
	Debugger();
2:
#endif	/* SCHED_DEBUG */
a6026 17
#ifdef SCHED_DEBUG
	nop; nop; nop; nop				! Try to make sure we don't vector into the wrong instr
	mov	%l0, %o0
	save	%sp, -CC64FSZ, %sp
	set	1f, %o0
	mov	%i6, %o2
	call	printf
	 mov	%i0, %o1
	ba	2f
	 restore
	.data
1:	.asciz	"proc_trampoline: calling %x sp %x\r\n"
	_ALIGN
	.text
	Debugger()
2:
#endif	/* SCHED_DEBUG */
a6059 30
#ifdef SCHED_DEBUG
!	set	panicstack-CC64FSZ-BIAS, %o0! DEBUG
!	save	%g0, %o0, %sp	! DEBUG
	save	%sp, -CC64FSZ, %sp
	set	1f, %o0
	ldx	[%fp + CC64FSZ + BIAS + TF_O + ( 6*8)], %o2
	mov	%fp, %o2
	add	%fp, CC64FSZ + BIAS, %o3
	GLOBTOLOC
	call	printf
	 mov	%g2, %o1
	LOCTOGLOB
	set	3f, %o0
	mov	%g1, %o1
	mov	%g2, %o2
	mov	CTX_SECONDARY, %o4
	ldxa	[%o4] ASI_DMMU, %o4
	call	printf
	 mov	%g3, %o3
	LOCTOGLOB
	ba 2f
	restore
	.data
1:	.asciz	"proc_trampoline: returning to %p, sp=%p, tf=%p\r\n"
3:	.asciz	"tstate=%p tpc=%p tnpc=%p ctx=%x\r\n"
	_ALIGN
	.text
	Debugger()
2:
#endif	/* SCHED_DEBUG */
a6879 10
#ifdef NOT_DEBUG
	!! Trap any changes to pmap_kernel below 0xf0000000
	set	_C_LABEL(kernel_pmap_), %o5
	cmp	%o0, %o5
	bne	0f
	 sethi	%hi(0xf0000000), %o5
	cmp	%o1, %o5
	tlu	1
0:
#endif	/* NOT_DEBUG */
a6970 10
#ifdef NOT_DEBUG
	!! Trap any changes to pmap_kernel below 0xf0000000
	set	_C_LABEL(kernel_pmap_), %o5
	cmp	%o0, %o5
	bne	0f
	 sethi	%hi(0xf0000000), %o5
	cmp	%o1, %o5
	tlu	1
0:
#endif	/* NOT_DEBUG */
@


1.33
log
@Removed not LP64 case -- only 64 bit kernels supported
@
text
@a57 1
#define INTRLIST
a58 2
#define	INTR_INTERLOCK		/* Use IH_PEND field to interlock interrupts */
#undef	PARANOID		/* Extremely expensive consistency checks */
a59 1
#undef	TRAPTRACE		/* Keep history of all traps (unsafe) */
a117 37
/*
 * Here are some defines to try to maintain consistency but still
 * support 32-and 64-bit compilers.
 */
/* reg that points to base of data/text segment */
#define	BASEREG	%g4
/* first constants for storage allocation */
#define LNGSZ		8
#define LNGSHFT		3
#define PTRSZ		8
#define PTRSHFT		3
#define	POINTER		.xword
/* Now instructions to load/store pointers & long ints */
#define LDLNG		ldx
#define LDULNG		ldx
#define STLNG		stx
#define STULNG		stx
#define LDPTR		ldx
#define LDPTRA		ldxa
#define STPTR		stx
#define STPTRA		stxa
#define	CASPTR		casxa
/* Now something to calculate the stack bias */
#define STKB		BIAS

/*
 * GNU assembler does not understand `.empty' directive; Sun assembler
 * gripes about labels without it.  To allow cross-compilation using
 * the Sun assembler, and because .empty directives are useful
 * documentation, we use this trick.
 */
#ifdef SUN_AS
#define	EMPTY	.empty
#else	/* SUN_AS */
#define	EMPTY	/* .empty */
#endif	/* SUN_AS */

d137 1
d139 2
a140 3
#define DLFLUSH(a,t) \
	andn	a, 0x1f, t; \
	stxa	%g0, [ t ] ASI_DCACHE_TAG; \
d142 2
d145 3
a147 2
#define DLFLUSH2(t) \
	stxa	%g0, [ t ] ASI_DCACHE_TAG; \
a148 3
#else	/* DCACHE_BUG */
#define DLFLUSH(a,t)
#define DLFLUSH2(t)
d150 1
a150 1

d157 2
a158 2
 *		TRAP_SETUP(...)		! makes %o registers safe
 *		INCR(_C_LABEL(cnt)+V_FOO)	! count a foo
d160 9
a168 9
#define INCR(what) \
	sethi	%hi(what), %o0; \
	or	%o0, %lo(what), %o0; \
99:	\
	lduw	[%o0], %o1; \
	add	%o1, 1, %o2; \
	casa	[%o0] ASI_P, %o1, %o2; \
	cmp	%o1, %o2; \
	bne,pn	%icc, 99b; \
d170 1
d177 34
a210 17
#define GLOBTOLOC \
	mov	%g1, %l1; \
	mov	%g2, %l2; \
	mov	%g3, %l3; \
	mov	%g4, %l4; \
	mov	%g5, %l5; \
	mov	%g6, %l6; \
	mov	%g7, %l7

#define LOCTOGLOB \
	mov	%l1, %g1; \
	mov	%l2, %g2; \
	mov	%l3, %g3; \
	mov	%l4, %g4; \
	mov	%l5, %g5; \
	mov	%l6, %g6; \
	mov	%l7, %g7
d222 1
a222 1
 * They correctly switch to requested stack type
d226 4
a229 4
#define TO_STACK64(size)					\
	save	%sp, size, %sp;					\
	add	%sp, -BIAS, %o0; /* Convert to 64-bits */	\
	andcc	%sp, 1, %g0; /* 64-bit stack? */		\
d231 1
a231 8

#define TO_STACK32(size)					\
	save	%sp, size, %sp;					\
	add	%sp, +BIAS, %o0; /* Convert to 32-bits */	\
	andcc	%sp, 1, %g0; /* 64-bit stack? */		\
	movnz	%icc, %o0, %sp

#define	STACKFRAME(size)	TO_STACK64(size)
d241 34
a274 33
#define ENABLE_FPU(siz)									     \
	save	%sp, -(CC64FSZ), %sp;		/* Allocate a stack frame */		     \
	sethi	%hi(FPPROC), %l1;							     \
	add	%fp, STKB-FS_SIZE, %l0;		/* Allocate a fpstate */		     \
	LDPTR	[%l1 + %lo(FPPROC)], %l2;	/* Load fpproc */			     \
	andn	%l0, BLOCK_SIZE, %l0;		/* Align it */				     \
	clr	%l3;				/* NULL fpstate */			     \
	brz,pt	%l2, 1f;			/* fpproc == NULL? */			     \
	 add	%l0, -STKB-CC64FSZ-(siz), %sp;	/* Set proper %sp */			     \
	LDPTR	[%l2 + P_FPSTATE], %l3;							     \
	brz,pn	%l3, 1f;			/* Make sure we have an fpstate */	     \
	 mov	%l3, %o0;								     \
	call	_C_LABEL(savefpstate);		/* Save the old fpstate */		     \
1:	\
	 set	EINTSTACK-STKB, %l4;		/* Are we on intr stack? */		     \
	cmp	%sp, %l4;								     \
	bgu,pt	%xcc, 1f;								     \
	 set	INTSTACK-STKB, %l4;							     \
	cmp	%sp, %l4;								     \
	blu	%xcc, 1f;								     \
0:											     \
	 sethi	%hi(_C_LABEL(proc0)), %l4;	/* Yes, use proc0 */			     \
	ba,pt	%xcc, 2f;			/* XXXX needs to change to CPUs idle proc */ \
	 or	%l4, %lo(_C_LABEL(proc0)), %l5;						     \
1:											     \
	sethi	%hi(CURPROC), %l4;		/* Use curproc */			     \
	LDPTR	[%l4 + %lo(CURPROC)], %l5;						     \
	brz,pn	%l5, 0b; nop;			/* If curproc is NULL need to use proc0 */   \
2:											     \
	LDPTR	[%l5 + P_FPSTATE], %l6;		/* Save old fpstate */			     \
	STPTR	%l0, [%l5 + P_FPSTATE];		/* Insert new fpstate */		     \
	STPTR	%l5, [%l1 + %lo(FPPROC)];	/* Set new fpproc */			     \
	wr	%g0, FPRS_FEF, %fprs		/* Enable FPU */
d280 2
d283 3
a285 6
#define __CHECK_FPU				\
	LDPTR	[%l5 + P_FPSTATE], %l7;		\
	cmp	%l7, %l0;			\
	tnz	1;
#else	/* DEBUG */
#define	__CHECK_FPU
d287 7
a293 10
	
#define RESTORE_FPU							     \
	__CHECK_FPU							     \
	STPTR	%l2, [%l1 + %lo(FPPROC)];	/* Restore old fproc */	     \
	wr	%g0, 0, %fprs;			/* Disable fpu */	     \
	brz,pt	%l3, 1f;			/* Skip if no fpstate */     \
	 STPTR	%l6, [%l5 + P_FPSTATE];		/* Restore old fpstate */    \
									     \
	call	_C_LABEL(loadfpstate);		/* Re-load orig fpstate */   \
	 mov	%l3, %o0;						     \
d295 1
d321 2
a322 2
_C_LABEL(u0):	POINTER	0
estack0:	POINTER	0
d348 1
a348 1
_C_LABEL(cpcb):	POINTER	_C_LABEL(u0)
d354 1
a354 1
romp:	POINTER	0
d394 7
a400 2
#define TA8	.align 32
#define TA32	.align 128
d428 7
a434 3
#define	VTRAP(type, label) \
	sethi %hi(label), %g1; ba,pt %icc,traceit;\
 or %g1, %lo(label), %g1; NOTREACHED; TA8
d446 9
a454 3
#define	VTRAP(type, label) \
	sethi %hi(DATA_START),%g1; rdpr %tt,%g2; or %g1,0x28,%g1; b label;\
 stx %g2,[%g1]; NOTREACHED; TA8
d475 7
a481 3
#define	VTRAP(type, label) \
	sethi %hi(label), %g1; ba,pt %icc,traceit;\
 or %g1, %lo(label), %g1; NOTREACHED; TA8
d493 6
a498 2
#define	VTRAP(type, label) \
	ba,a,pt	%icc,label; nop; NOTREACHED; TA8
d502 3
a504 2
#define	HARDINT4U(lev) \
	VTRAP(lev, _C_LABEL(sparc_interrupt))
d508 3
a510 2
#define	SOFTINT4U(lev, bit) \
	HARDINT4U(lev)
d513 3
a515 1
#define	TRAP(type)	VTRAP(type, slowtrap)
d518 1
d520 1
a520 3
#define	UTRAP(type)	sir; VTRAP(type, slowtrap)
#else	/* DEBUG */
#define	UTRAP(type)	VTRAP(type, slowtrap)
d522 2
d526 3
a528 1
#define	STRAP(type)	VTRAP(type, slowtrap)
d532 2
a533 2
#define	BPT		VTRAP(T_BREAKPOINT, bpt)
#define	BPT_KGDB_EXEC	VTRAP(T_KGDB_EXEC, bpt)
d535 2
a536 2
#define	BPT		TRAP(T_BREAKPOINT)
#define	BPT_KGDB_EXEC	TRAP(T_KGDB_EXEC)
d539 2
a540 7
#define	SYSCALL		VTRAP(0x100, syscall_setup)
#ifdef notyet
#define	ZS_INTERRUPT	ba,a,pt %icc, zshard; nop; TA8
#else	/* notyet */
#define	ZS_INTERRUPT4U	HARDINT4U(12)
#endif	/* notyet */

d545 1
d547 5
a551 3
#define CLRTT	wrpr	%g0,0x1ff,%tt
#else	/* DEBUG */
#define CLRTT
d553 1
a553 3
/*
 * Here are some oft repeated traps as macros.
 */
d555 1
a555 170
	/* spill a 64-bit register window */
#define SPILL64(label,as) \
	TRACEWIN; \
label:	\
	wr	%g0, as, %asi; \
	stxa	%l0, [%sp+BIAS+0x00]%asi; \
	stxa	%l1, [%sp+BIAS+0x08]%asi; \
	stxa	%l2, [%sp+BIAS+0x10]%asi; \
	stxa	%l3, [%sp+BIAS+0x18]%asi; \
	stxa	%l4, [%sp+BIAS+0x20]%asi; \
	stxa	%l5, [%sp+BIAS+0x28]%asi; \
	stxa	%l6, [%sp+BIAS+0x30]%asi; \
	\
	stxa	%l7, [%sp+BIAS+0x38]%asi; \
	stxa	%i0, [%sp+BIAS+0x40]%asi; \
	stxa	%i1, [%sp+BIAS+0x48]%asi; \
	stxa	%i2, [%sp+BIAS+0x50]%asi; \
	stxa	%i3, [%sp+BIAS+0x58]%asi; \
	stxa	%i4, [%sp+BIAS+0x60]%asi; \
	stxa	%i5, [%sp+BIAS+0x68]%asi; \
	stxa	%i6, [%sp+BIAS+0x70]%asi; \
	\
	stxa	%i7, [%sp+BIAS+0x78]%asi; \
	saved; \
	CLRTT; \
	retry; \
	NOTREACHED; \
	TA32

	/* spill a 32-bit register window */
#define SPILL32(label,as) \
	TRACEWIN; \
label:	\
	wr	%g0, as, %asi; \
	srl	%sp, 0, %sp; /* fixup 32-bit pointers */ \
	stwa	%l0, [%sp+0x00]%asi; \
	stwa	%l1, [%sp+0x04]%asi; \
	stwa	%l2, [%sp+0x08]%asi; \
	stwa	%l3, [%sp+0x0c]%asi; \
	stwa	%l4, [%sp+0x10]%asi; \
	stwa	%l5, [%sp+0x14]%asi; \
	\
	stwa	%l6, [%sp+0x18]%asi; \
	stwa	%l7, [%sp+0x1c]%asi; \
	stwa	%i0, [%sp+0x20]%asi; \
	stwa	%i1, [%sp+0x24]%asi; \
	stwa	%i2, [%sp+0x28]%asi; \
	stwa	%i3, [%sp+0x2c]%asi; \
	stwa	%i4, [%sp+0x30]%asi; \
	stwa	%i5, [%sp+0x34]%asi; \
	\
	stwa	%i6, [%sp+0x38]%asi; \
	stwa	%i7, [%sp+0x3c]%asi; \
	saved; \
	CLRTT; \
	retry; \
	NOTREACHED; \
	TA32

	/* Spill either 32-bit or 64-bit register window. */
#define SPILLBOTH(label64,label32,as) \
	TRACEWIN; \
	andcc	%sp, 1, %g0; \
	bnz,pt	%xcc, label64+4;	/* Is it a v9 or v8 stack? */ \
	 wr	%g0, as, %asi; \
	ba,pt	%xcc, label32+8; \
	 srl	%sp, 0, %sp; /* fixup 32-bit pointers */ \
	NOTREACHED; \
	TA32

	/* fill a 64-bit register window */
#define FILL64(label,as) \
	TRACEWIN; \
label: \
	wr	%g0, as, %asi; \
	ldxa	[%sp+BIAS+0x00]%asi, %l0; \
	ldxa	[%sp+BIAS+0x08]%asi, %l1; \
	ldxa	[%sp+BIAS+0x10]%asi, %l2; \
	ldxa	[%sp+BIAS+0x18]%asi, %l3; \
	ldxa	[%sp+BIAS+0x20]%asi, %l4; \
	ldxa	[%sp+BIAS+0x28]%asi, %l5; \
	ldxa	[%sp+BIAS+0x30]%asi, %l6; \
	\
	ldxa	[%sp+BIAS+0x38]%asi, %l7; \
	ldxa	[%sp+BIAS+0x40]%asi, %i0; \
	ldxa	[%sp+BIAS+0x48]%asi, %i1; \
	ldxa	[%sp+BIAS+0x50]%asi, %i2; \
	ldxa	[%sp+BIAS+0x58]%asi, %i3; \
	ldxa	[%sp+BIAS+0x60]%asi, %i4; \
	ldxa	[%sp+BIAS+0x68]%asi, %i5; \
	ldxa	[%sp+BIAS+0x70]%asi, %i6; \
	\
	ldxa	[%sp+BIAS+0x78]%asi, %i7; \
	restored; \
	CLRTT; \
	retry; \
	NOTREACHED; \
	TA32

	/* fill a 32-bit register window */
#define FILL32(label,as) \
	TRACEWIN; \
label:	\
	wr	%g0, as, %asi; \
	srl	%sp, 0, %sp; /* fixup 32-bit pointers */ \
	lda	[%sp+0x00]%asi, %l0; \
	lda	[%sp+0x04]%asi, %l1; \
	lda	[%sp+0x08]%asi, %l2; \
	lda	[%sp+0x0c]%asi, %l3; \
	lda	[%sp+0x10]%asi, %l4; \
	lda	[%sp+0x14]%asi, %l5; \
	\
	lda	[%sp+0x18]%asi, %l6; \
	lda	[%sp+0x1c]%asi, %l7; \
	lda	[%sp+0x20]%asi, %i0; \
	lda	[%sp+0x24]%asi, %i1; \
	lda	[%sp+0x28]%asi, %i2; \
	lda	[%sp+0x2c]%asi, %i3; \
	lda	[%sp+0x30]%asi, %i4; \
	lda	[%sp+0x34]%asi, %i5; \
	\
	lda	[%sp+0x38]%asi, %i6; \
	lda	[%sp+0x3c]%asi, %i7; \
	restored; \
	CLRTT; \
	retry; \
	NOTREACHED; \
	TA32

	/* fill either 32-bit or 64-bit register window. */
#define FILLBOTH(label64,label32,as) \
	TRACEWIN; \
	andcc	%sp, 1, %i0; \
	bnz	(label64)+4; /* See if it's a v9 stack or v8 */ \
	 wr	%g0, as, %asi; \
	ba	(label32)+8; \
	 srl	%sp, 0, %sp; /* fixup 32-bit pointers */ \
	NOTREACHED; \
	TA32

	.globl	start, _C_LABEL(kernel_text)
	_C_LABEL(kernel_text) = start		! for kvm_mkdb(8)
start:
	/* Traps from TL=0 -- traps from user mode */
#define TABLE	user_
	.globl	_C_LABEL(trapbase)
_C_LABEL(trapbase):
	b dostart; nop; TA8	! 000 = reserved -- Use it to boot
	/* We should not get the next 5 traps */
	UTRAP(0x001)		! 001 = POR Reset -- ROM should get this
	UTRAP(0x002)		! 002 = WDR -- ROM should get this
	UTRAP(0x003)		! 003 = XIR -- ROM should get this
	UTRAP(0x004)		! 004 = SIR -- ROM should get this
	UTRAP(0x005)		! 005 = RED state exception
	UTRAP(0x006); UTRAP(0x007)
	VTRAP(T_INST_EXCEPT, textfault)	! 008 = instr. access exept
	VTRAP(T_TEXTFAULT, textfault)	! 009 = instr access MMU miss
	VTRAP(T_INST_ERROR, textfault)	! 00a = instr. access err
	UTRAP(0x00b); UTRAP(0x00c); UTRAP(0x00d); UTRAP(0x00e); UTRAP(0x00f)
	TRAP(T_ILLINST)			! 010 = illegal instruction
	TRAP(T_PRIVINST)		! 011 = privileged instruction
	UTRAP(0x012)			! 012 = unimplemented LDD
	UTRAP(0x013)			! 013 = unimplemented STD
	UTRAP(0x014); UTRAP(0x015); UTRAP(0x016); UTRAP(0x017); UTRAP(0x018)
	UTRAP(0x019); UTRAP(0x01a); UTRAP(0x01b); UTRAP(0x01c); UTRAP(0x01d)
	UTRAP(0x01e); UTRAP(0x01f)
	TRAP(T_FPDISABLED)		! 020 = fp instr, but EF bit off in psr
	VTRAP(T_FP_IEEE_754, fp_exception)		! 021 = ieee 754 exception
	VTRAP(T_FP_OTHER, fp_exception)		! 022 = other fp exception
	TRAP(T_TAGOF)			! 023 = tag overflow
d581 1
a581 1
	LDPTR	[%l5 + %lo(CPCB)], %l5	! If pcb < fp < pcb+sizeof(pcb)
d597 1
a597 1
	CLRTT
d599 34
a632 37
	TRAP(T_DIV0)			! 028 = divide by zero
	UTRAP(0x029)			! 029 = internal processor error
	UTRAP(0x02a); UTRAP(0x02b); UTRAP(0x02c); UTRAP(0x02d); UTRAP(0x02e); UTRAP(0x02f)
	VTRAP(T_DATAFAULT, winfault)	! 030 = data fetch fault
	UTRAP(0x031)			! 031 = data MMU miss -- no MMU
	VTRAP(T_DATA_ERROR, winfault)	! 032 = data access error
	VTRAP(T_DATA_PROT, winfault)	! 033 = data protection fault
	TRAP(T_ALIGN)			! 034 = address alignment error -- we could fix it inline...
	TRAP(T_LDDF_ALIGN)		! 035 = LDDF address alignment error -- we could fix it inline...
	TRAP(T_STDF_ALIGN)		! 036 = STDF address alignment error -- we could fix it inline...
	TRAP(T_PRIVACT)			! 037 = privileged action
	UTRAP(0x038); UTRAP(0x039); UTRAP(0x03a); UTRAP(0x03b); UTRAP(0x03c);
	UTRAP(0x03d); UTRAP(0x03e); UTRAP(0x03f);
	VTRAP(T_ASYNC_ERROR, winfault)	! 040 = data fetch fault
	SOFTINT4U(1, IE_L1)		! 041 = level 1 interrupt
	HARDINT4U(2)			! 042 = level 2 interrupt
	HARDINT4U(3)			! 043 = level 3 interrupt
	SOFTINT4U(4, IE_L4)		! 044 = level 4 interrupt
	HARDINT4U(5)			! 045 = level 5 interrupt
	SOFTINT4U(6, IE_L6)		! 046 = level 6 interrupt
	HARDINT4U(7)			! 047 = level 7 interrupt
	HARDINT4U(8)			! 048 = level 8 interrupt
	HARDINT4U(9)			! 049 = level 9 interrupt
	HARDINT4U(10)			! 04a = level 10 interrupt
	HARDINT4U(11)			! 04b = level 11 interrupt
	ZS_INTERRUPT4U			! 04c = level 12 (zs) interrupt
	HARDINT4U(13)			! 04d = level 13 interrupt
	HARDINT4U(14)			! 04e = level 14 interrupt
	HARDINT4U(15)			! 04f = nonmaskable interrupt
	UTRAP(0x050); UTRAP(0x051); UTRAP(0x052); UTRAP(0x053); UTRAP(0x054); UTRAP(0x055)
	UTRAP(0x056); UTRAP(0x057); UTRAP(0x058); UTRAP(0x059); UTRAP(0x05a); UTRAP(0x05b)
	UTRAP(0x05c); UTRAP(0x05d); UTRAP(0x05e); UTRAP(0x05f)
	VTRAP(0x060, interrupt_vector); ! 060 = interrupt vector
	TRAP(T_PA_WATCHPT)		! 061 = physical address data watchpoint
	TRAP(T_VA_WATCHPT)		! 062 = virtual address data watchpoint
	VTRAP(T_ECCERR, cecc_catch)	! 063 = Correctable ECC error
ufast_IMMU_miss:			! 064 = fast instr access MMU miss
a634 3
#ifdef NO_TSB
	ba,a	%icc, instr_miss;
#endif	/* NO_TSB */
d641 1
a641 1
	CLRTT
d647 3
a649 1
ufast_DMMU_miss:			! 068 = fast data access MMU miss
d651 6
a656 9
	ldxa	[%g0] ASI_DMMU_8KPTR, %g2!					Load DMMU 8K TSB pointer
#ifdef NO_TSB
	ba,a	%icc, data_miss;
#endif	/* NO_TSB */
	ldxa	[%g0] ASI_DMMU, %g1	! Hard coded for unified 8K TSB		Load DMMU tag target register
	ldda	[%g2] ASI_NUCLEUS_QUAD_LDD, %g4	!				Load TSB tag and data into %g4 and %g5
	brgez,pn %g5, data_miss		!					Entry invalid?  Punt
	 xor	%g1, %g4, %g4		!					Compare TLB tags
	brnz,pn	%g4, data_miss		!					Got right tag?
d658 1
a658 1
	CLRTT
d665 2
a666 2
	stxa	%g5, [%g0] ASI_DMMU_DATA_IN!					Enter new mapping
	retry				!					Try new mapping
d670 22
a691 1
ufast_DMMU_protection:			! 06c = fast data access MMU protection
d694 2
a695 2
	sethi	%hi(_C_LABEL(udprot)), %g1
	lduw	[%g1+%lo(_C_LABEL(udprot))], %g2
d697 1
a697 1
	stw	%g2, [%g1+%lo(_C_LABEL(udprot))]
d702 160
a861 4
	UTRAP(0x070)			! Implementation dependent traps
	UTRAP(0x071); UTRAP(0x072); UTRAP(0x073); UTRAP(0x074); UTRAP(0x075); UTRAP(0x076)
	UTRAP(0x077); UTRAP(0x078); UTRAP(0x079); UTRAP(0x07a); UTRAP(0x07b); UTRAP(0x07c)
	UTRAP(0x07d); UTRAP(0x07e); UTRAP(0x07f)
d863 3
a865 3
	SPILL64(uspill8,ASI_AIUS)	! 0x080 spill_0_normal -- used to save user windows in user mode
	SPILL32(uspill4,ASI_AIUS)	! 0x084 spill_1_normal
	SPILLBOTH(uspill8,uspill4,ASI_AIUS)		! 0x088 spill_2_normal
d869 1
a869 1
	UTRAP(0x08c); TA32	! 0x08c spill_3_normal
d871 4
a874 4
	SPILL64(kspill8,ASI_N)	! 0x090 spill_4_normal -- used to save supervisor windows
	SPILL32(kspill4,ASI_N)	! 0x094 spill_5_normal
	SPILLBOTH(kspill8,kspill4,ASI_N)	! 0x098 spill_6_normal
	UTRAP(0x09c); TA32	! 0x09c spill_7_normal
d876 8
a883 8
	SPILL64(uspillk8,ASI_AIUS)	! 0x0a0 spill_0_other -- used to save user windows in supervisor mode
	SPILL32(uspillk4,ASI_AIUS)	! 0x0a4 spill_1_other
	SPILLBOTH(uspillk8,uspillk4,ASI_AIUS)	! 0x0a8 spill_2_other
	UTRAP(0x0ac); TA32	! 0x0ac spill_3_other
	UTRAP(0x0b0); TA32	! 0x0b0 spill_4_other
	UTRAP(0x0b4); TA32	! 0x0b4 spill_5_other
	UTRAP(0x0b8); TA32	! 0x0b8 spill_6_other
	UTRAP(0x0bc); TA32	! 0x0bc spill_7_other
d885 4
a888 4
	FILL64(ufill8,ASI_AIUS) ! 0x0c0 fill_0_normal -- used to fill windows when running user mode
	FILL32(ufill4,ASI_AIUS)	! 0x0c4 fill_1_normal
	FILLBOTH(ufill8,ufill4,ASI_AIUS)	! 0x0c8 fill_2_normal
	UTRAP(0x0cc); TA32	! 0x0cc fill_3_normal
d890 4
a893 4
	FILL64(kfill8,ASI_N)	! 0x0d0 fill_4_normal -- used to fill windows when running supervisor mode
	FILL32(kfill4,ASI_N)	! 0x0d4 fill_5_normal
	FILLBOTH(kfill8,kfill4,ASI_N)	! 0x0d8 fill_6_normal
	UTRAP(0x0dc); TA32	! 0x0dc fill_7_normal
d895 8
a902 8
	FILL64(ufillk8,ASI_AIUS)	! 0x0e0 fill_0_other
	FILL32(ufillk4,ASI_AIUS)	! 0x0e4 fill_1_other
	FILLBOTH(ufillk8,ufillk4,ASI_AIUS)	! 0x0e8 fill_2_other
	UTRAP(0x0ec); TA32	! 0x0ec fill_3_other
	UTRAP(0x0f0); TA32	! 0x0f0 fill_4_other
	UTRAP(0x0f4); TA32	! 0x0f4 fill_5_other
	UTRAP(0x0f8); TA32	! 0x0f8 fill_6_other
	UTRAP(0x0fc); TA32	! 0x0fc fill_7_other
d906 1
a906 1
	STRAP(0x102); STRAP(0x103); STRAP(0x104); STRAP(0x105); STRAP(0x106); STRAP(0x107)
d910 7
a916 7
	STRAP(0x10b); STRAP(0x10c); STRAP(0x10d); STRAP(0x10e); STRAP(0x10f);
	STRAP(0x110); STRAP(0x111); STRAP(0x112); STRAP(0x113); STRAP(0x114); STRAP(0x115); STRAP(0x116); STRAP(0x117)
	STRAP(0x118); STRAP(0x119); STRAP(0x11a); STRAP(0x11b); STRAP(0x11c); STRAP(0x11d); STRAP(0x11e); STRAP(0x11f)
	STRAP(0x120); STRAP(0x121); STRAP(0x122); STRAP(0x123); STRAP(0x124); STRAP(0x125); STRAP(0x126); STRAP(0x127)
	STRAP(0x128); STRAP(0x129); STRAP(0x12a); STRAP(0x12b); STRAP(0x12c); STRAP(0x12d); STRAP(0x12e); STRAP(0x12f)
	STRAP(0x130); STRAP(0x131); STRAP(0x132); STRAP(0x133); STRAP(0x134); STRAP(0x135); STRAP(0x136); STRAP(0x137)
	STRAP(0x138); STRAP(0x139); STRAP(0x13a); STRAP(0x13b); STRAP(0x13c); STRAP(0x13d); STRAP(0x13e); STRAP(0x13f)
d921 8
a928 8
	STRAP(0x144); STRAP(0x145); STRAP(0x146); STRAP(0x147)
	STRAP(0x148); STRAP(0x149); STRAP(0x14a); STRAP(0x14b); STRAP(0x14c); STRAP(0x14d); STRAP(0x14e); STRAP(0x14f)
	STRAP(0x150); STRAP(0x151); STRAP(0x152); STRAP(0x153); STRAP(0x154); STRAP(0x155); STRAP(0x156); STRAP(0x157)
	STRAP(0x158); STRAP(0x159); STRAP(0x15a); STRAP(0x15b); STRAP(0x15c); STRAP(0x15d); STRAP(0x15e); STRAP(0x15f)
	STRAP(0x160); STRAP(0x161); STRAP(0x162); STRAP(0x163); STRAP(0x164); STRAP(0x165); STRAP(0x166); STRAP(0x167)
	STRAP(0x168); STRAP(0x169); STRAP(0x16a); STRAP(0x16b); STRAP(0x16c); STRAP(0x16d); STRAP(0x16e); STRAP(0x16f)
	STRAP(0x170); STRAP(0x171); STRAP(0x172); STRAP(0x173); STRAP(0x174); STRAP(0x175); STRAP(0x176); STRAP(0x177)
	STRAP(0x178); STRAP(0x179); STRAP(0x17a); STRAP(0x17b); STRAP(0x17c); STRAP(0x17d); STRAP(0x17e); STRAP(0x17f)
d930 16
a945 16
	UTRAP(0x180); UTRAP(0x181); UTRAP(0x182); UTRAP(0x183); UTRAP(0x184); UTRAP(0x185); UTRAP(0x186); UTRAP(0x187)
	UTRAP(0x188); UTRAP(0x189); UTRAP(0x18a); UTRAP(0x18b); UTRAP(0x18c); UTRAP(0x18d); UTRAP(0x18e); UTRAP(0x18f)
	UTRAP(0x190); UTRAP(0x191); UTRAP(0x192); UTRAP(0x193); UTRAP(0x194); UTRAP(0x195); UTRAP(0x196); UTRAP(0x197)
	UTRAP(0x198); UTRAP(0x199); UTRAP(0x19a); UTRAP(0x19b); UTRAP(0x19c); UTRAP(0x19d); UTRAP(0x19e); UTRAP(0x19f)
	UTRAP(0x1a0); UTRAP(0x1a1); UTRAP(0x1a2); UTRAP(0x1a3); UTRAP(0x1a4); UTRAP(0x1a5); UTRAP(0x1a6); UTRAP(0x1a7)
	UTRAP(0x1a8); UTRAP(0x1a9); UTRAP(0x1aa); UTRAP(0x1ab); UTRAP(0x1ac); UTRAP(0x1ad); UTRAP(0x1ae); UTRAP(0x1af)
	UTRAP(0x1b0); UTRAP(0x1b1); UTRAP(0x1b2); UTRAP(0x1b3); UTRAP(0x1b4); UTRAP(0x1b5); UTRAP(0x1b6); UTRAP(0x1b7)
	UTRAP(0x1b8); UTRAP(0x1b9); UTRAP(0x1ba); UTRAP(0x1bb); UTRAP(0x1bc); UTRAP(0x1bd); UTRAP(0x1be); UTRAP(0x1bf)
	UTRAP(0x1c0); UTRAP(0x1c1); UTRAP(0x1c2); UTRAP(0x1c3); UTRAP(0x1c4); UTRAP(0x1c5); UTRAP(0x1c6); UTRAP(0x1c7)
	UTRAP(0x1c8); UTRAP(0x1c9); UTRAP(0x1ca); UTRAP(0x1cb); UTRAP(0x1cc); UTRAP(0x1cd); UTRAP(0x1ce); UTRAP(0x1cf)
	UTRAP(0x1d0); UTRAP(0x1d1); UTRAP(0x1d2); UTRAP(0x1d3); UTRAP(0x1d4); UTRAP(0x1d5); UTRAP(0x1d6); UTRAP(0x1d7)
	UTRAP(0x1d8); UTRAP(0x1d9); UTRAP(0x1da); UTRAP(0x1db); UTRAP(0x1dc); UTRAP(0x1dd); UTRAP(0x1de); UTRAP(0x1df)
	UTRAP(0x1e0); UTRAP(0x1e1); UTRAP(0x1e2); UTRAP(0x1e3); UTRAP(0x1e4); UTRAP(0x1e5); UTRAP(0x1e6); UTRAP(0x1e7)
	UTRAP(0x1e8); UTRAP(0x1e9); UTRAP(0x1ea); UTRAP(0x1eb); UTRAP(0x1ec); UTRAP(0x1ed); UTRAP(0x1ee); UTRAP(0x1ef)
	UTRAP(0x1f0); UTRAP(0x1f1); UTRAP(0x1f2); UTRAP(0x1f3); UTRAP(0x1f4); UTRAP(0x1f5); UTRAP(0x1f6); UTRAP(0x1f7)
	UTRAP(0x1f8); UTRAP(0x1f9); UTRAP(0x1fa); UTRAP(0x1fb); UTRAP(0x1fc); UTRAP(0x1fd); UTRAP(0x1fe); UTRAP(0x1ff)
d951 1
a951 1
	UTRAP(0x000)		! 000 = reserved -- Use it to boot
d953 6
a958 6
	UTRAP(0x001)		! 001 = POR Reset -- ROM should get this
	UTRAP(0x002)		! 002 = WDR Watchdog -- ROM should get this
	UTRAP(0x003)		! 003 = XIR -- ROM should get this
	UTRAP(0x004)		! 004 = SIR -- ROM should get this
	UTRAP(0x005)		! 005 = RED state exception
	UTRAP(0x006); UTRAP(0x007)
d960 19
a978 46
	VTRAP(T_INST_EXCEPT, textfault)	! 008 = instr. access exept
	VTRAP(T_TEXTFAULT, textfault)	! 009 = instr access MMU miss -- no MMU
	VTRAP(T_INST_ERROR, textfault)	! 00a = instr. access err
	UTRAP(0x00b); UTRAP(0x00c); UTRAP(0x00d); UTRAP(0x00e); UTRAP(0x00f)
	TRAP(T_ILLINST)			! 010 = illegal instruction
	TRAP(T_PRIVINST)		! 011 = privileged instruction
	UTRAP(0x012)			! 012 = unimplemented LDD
	UTRAP(0x013)			! 013 = unimplemented STD
	UTRAP(0x014); UTRAP(0x015); UTRAP(0x016); UTRAP(0x017); UTRAP(0x018)
	UTRAP(0x019); UTRAP(0x01a); UTRAP(0x01b); UTRAP(0x01c); UTRAP(0x01d)
	UTRAP(0x01e); UTRAP(0x01f)
	TRAP(T_FPDISABLED)		! 020 = fp instr, but EF bit off in psr
	VTRAP(T_FP_IEEE_754, fp_exception)		! 021 = ieee 754 exception
	VTRAP(T_FP_OTHER, fp_exception)		! 022 = other fp exception
	TRAP(T_TAGOF)			! 023 = tag overflow
	TRACEWIN			! DEBUG
	clr	%l0
#ifdef DEBUG
	set	0xbadbeef, %l0		! DEBUG
#endif	/* DEBUG */
	mov %l0, %l1; mov %l0, %l2	! 024-027 = clean window trap
	rdpr %cleanwin, %o7		!	This handler is in-lined and cannot fault
	inc %o7; mov %l0, %l3	!       Nucleus (trap&IRQ) code does not need clean windows
	wrpr %g0, %o7, %cleanwin	!	Clear out %l0-%l8 and %o0-%o8 and inc %cleanwin and done
#ifdef NOT_DEBUG
	!!
	!! Check the sp redzone
	!!
	rdpr	%wstate, t1
	cmp	t1, WSTATE_KERN
	bne,pt	icc, 7f
	 sethi	%hi(_C_LABEL(redzone)), t1
	ldx	[t1 + %lo(_C_LABEL(redzone))], t2
	cmp	%sp, t2			! if sp >= t2, not in red zone
	blu	panic_red		! and can continue normally
7:
#endif	/* NOT_DEBUG */
	mov %l0, %l4; mov %l0, %l5; mov %l0, %l6; mov %l0, %l7
	mov %l0, %o0; mov %l0, %o1; mov %l0, %o2; mov %l0, %o3

	mov %l0, %o4; mov %l0, %o5; mov %l0, %o6; mov %l0, %o7
	CLRTT
	retry; nop; TA32
	TRAP(T_DIV0)			! 028 = divide by zero
	UTRAP(0x029)			! 029 = internal processor error
	UTRAP(0x02a); UTRAP(0x02b); UTRAP(0x02c); UTRAP(0x02d); UTRAP(0x02e); UTRAP(0x02f)
d980 5
a984 5
	VTRAP(T_DATAFAULT, winfault)	! 030 = data fetch fault
	UTRAP(0x031)			! 031 = data MMU miss -- no MMU
	VTRAP(T_DATA_ERROR, winfault)	! 032 = data fetch fault
	VTRAP(T_DATA_PROT, winfault)	! 033 = data fetch fault
	TRAP(T_ALIGN)			! 034 = address alignment error -- we could fix it inline...
d986 17
a1002 17
	TRAP(T_LDDF_ALIGN)		! 035 = LDDF address alignment error -- we could fix it inline...
	TRAP(T_STDF_ALIGN)		! 036 = STDF address alignment error -- we could fix it inline...
	TRAP(T_PRIVACT)			! 037 = privileged action
	UTRAP(0x038); UTRAP(0x039); UTRAP(0x03a); UTRAP(0x03b); UTRAP(0x03c);
	UTRAP(0x03d); UTRAP(0x03e); UTRAP(0x03f);
	VTRAP(T_ASYNC_ERROR, winfault)	! 040 = data fetch fault
	SOFTINT4U(1, IE_L1)		! 041 = level 1 interrupt
	HARDINT4U(2)			! 042 = level 2 interrupt
	HARDINT4U(3)			! 043 = level 3 interrupt
	SOFTINT4U(4, IE_L4)		! 044 = level 4 interrupt
	HARDINT4U(5)			! 045 = level 5 interrupt
	SOFTINT4U(6, IE_L6)		! 046 = level 6 interrupt
	HARDINT4U(7)			! 047 = level 7 interrupt
	HARDINT4U(8)			! 048 = level 8 interrupt
	HARDINT4U(9)			! 049 = level 9 interrupt
	HARDINT4U(10)			! 04a = level 10 interrupt
	HARDINT4U(11)			! 04b = level 11 interrupt
d1004 10
a1013 10
	HARDINT4U(13)			! 04d = level 13 interrupt
	HARDINT4U(14)			! 04e = level 14 interrupt
	HARDINT4U(15)			! 04f = nonmaskable interrupt
	UTRAP(0x050); UTRAP(0x051); UTRAP(0x052); UTRAP(0x053); UTRAP(0x054); UTRAP(0x055)
	UTRAP(0x056); UTRAP(0x057); UTRAP(0x058); UTRAP(0x059); UTRAP(0x05a); UTRAP(0x05b)
	UTRAP(0x05c); UTRAP(0x05d); UTRAP(0x05e); UTRAP(0x05f)
	VTRAP(0x060, interrupt_vector); ! 060 = interrupt vector
	TRAP(T_PA_WATCHPT)		! 061 = physical address data watchpoint
	TRAP(T_VA_WATCHPT)		! 062 = virtual address data watchpoint
	VTRAP(T_ECCERR, cecc_catch)	! 063 = Correctable ECC error
d1015 1
a1015 17
	TRACEFLT			! DEBUG
	ldxa	[%g0] ASI_IMMU_8KPTR, %g2	! Load IMMU 8K TSB pointer
#ifdef NO_TSB
	ba,a	%icc, instr_miss;
#endif	/* NO_TSB */
	ldxa	[%g0] ASI_IMMU, %g1	!	Load IMMU tag target register
	ldda	[%g2] ASI_NUCLEUS_QUAD_LDD, %g4	!Load TSB tag:data into %g4:%g5
	brgez,pn %g5, instr_miss	!	Entry invalid?  Punt
	 cmp	%g1, %g4		!	Compare TLB tags
	bne,pn %xcc, instr_miss		!	Got right tag?
	 nop
	CLRTT
	stxa	%g5, [%g0] ASI_IMMU_DATA_IN!	Enter new mapping
	retry				!	Try new mapping
1:
	sir
	TA32
d1017 1
a1017 23
	TRACEFLT			! DEBUG
	ldxa	[%g0] ASI_DMMU_8KPTR, %g2!					Load DMMU 8K TSB pointer
#ifdef NO_TSB
	ba,a	%icc, data_miss;
#endif	/* NO_TSB */
	ldxa	[%g0] ASI_DMMU, %g1	! Hard coded for unified 8K TSB		Load DMMU tag target register
	ldda	[%g2] ASI_NUCLEUS_QUAD_LDD, %g4	!				Load TSB tag and data into %g4 and %g5
	brgez,pn %g5, data_miss		!					Entry invalid?  Punt
	 xor	%g1, %g4, %g4		!					Compare TLB tags
	brnz,pn	%g4, data_miss		!					Got right tag?
	 nop
	CLRTT
#ifdef TRAPSTATS
	sethi	%hi(_C_LABEL(kdhit)), %g1
	lduw	[%g1+%lo(_C_LABEL(kdhit))], %g2
	inc	%g2
	stw	%g2, [%g1+%lo(_C_LABEL(kdhit))]
#endif	/* TRAPSTATS */
	stxa	%g5, [%g0] ASI_DMMU_DATA_IN!					Enter new mapping
	retry				!					Try new mapping
1:
	sir
	TA32
d1019 5
a1023 14
	TRACEFLT			! DEBUG
#ifdef TRAPSTATS
	sethi	%hi(_C_LABEL(kdprot)), %g1
	lduw	[%g1+%lo(_C_LABEL(kdprot))], %g2
	inc	%g2
	stw	%g2, [%g1+%lo(_C_LABEL(kdprot))]
#endif	/* TRAPSTATS */
	ba,a,pt	%xcc, dmmu_write_fault
	nop
	TA32
	UTRAP(0x070)			! Implementation dependent traps
	UTRAP(0x071); UTRAP(0x072); UTRAP(0x073); UTRAP(0x074); UTRAP(0x075); UTRAP(0x076)
	UTRAP(0x077); UTRAP(0x078); UTRAP(0x079); UTRAP(0x07a); UTRAP(0x07b); UTRAP(0x07c)
	UTRAP(0x07d); UTRAP(0x07e); UTRAP(0x07f)
d1025 4
a1028 4
	SPILL64(1,ASI_AIUS)	! 0x080 spill_0_normal -- used to save user windows
	SPILL32(2,ASI_AIUS)	! 0x084 spill_1_normal
	SPILLBOTH(1b,2b,ASI_AIUS)	! 0x088 spill_2_normal
	UTRAP(0x08c); TA32	! 0x08c spill_3_normal
d1030 4
a1033 4
	SPILL64(1,ASI_N)	! 0x090 spill_4_normal -- used to save supervisor windows
	SPILL32(2,ASI_N)	! 0x094 spill_5_normal
	SPILLBOTH(1b,2b,ASI_N)	! 0x098 spill_6_normal
	UTRAP(0x09c); TA32	! 0x09c spill_7_normal
d1035 8
a1042 8
	SPILL64(1,ASI_AIUS)	! 0x0a0 spill_0_other -- used to save user windows in nucleus mode
	SPILL32(2,ASI_AIUS)	! 0x0a4 spill_1_other
	SPILLBOTH(1b,2b,ASI_AIUS)	! 0x0a8 spill_2_other
	UTRAP(0x0ac); TA32	! 0x0ac spill_3_other
	UTRAP(0x0b0); TA32	! 0x0b0 spill_4_other
	UTRAP(0x0b4); TA32	! 0x0b4 spill_5_other
	UTRAP(0x0b8); TA32	! 0x0b8 spill_6_other
	UTRAP(0x0bc); TA32	! 0x0bc spill_7_other
d1044 4
a1047 4
	FILL64(1,ASI_AIUS)	! 0x0c0 fill_0_normal -- used to fill windows when running nucleus mode from user
	FILL32(2,ASI_AIUS)	! 0x0c4 fill_1_normal
	FILLBOTH(1b,2b,ASI_AIUS)	! 0x0c8 fill_2_normal
	UTRAP(0x0cc); TA32	! 0x0cc fill_3_normal
d1049 4
a1052 4
	FILL64(1,ASI_N)		! 0x0d0 fill_4_normal -- used to fill windows when running nucleus mode from supervisor
	FILL32(2,ASI_N)		! 0x0d4 fill_5_normal
	FILLBOTH(1b,2b,ASI_N)	! 0x0d8 fill_6_normal
	UTRAP(0x0dc); TA32	! 0x0dc fill_7_normal
d1054 8
a1061 8
	FILL64(1,ASI_AIUS)	! 0x0e0 fill_0_other -- used to fill user windows when running nucleus mode -- will we ever use this?
	FILL32(2,ASI_AIUS)	! 0x0e4 fill_1_other
	FILLBOTH(1b,2b,ASI_AIUS)! 0x0e8 fill_2_other
	UTRAP(0x0ec); TA32	! 0x0ec fill_3_other
	UTRAP(0x0f0); TA32	! 0x0f0 fill_4_other
	UTRAP(0x0f4); TA32	! 0x0f4 fill_5_other
	UTRAP(0x0f8); TA32	! 0x0f8 fill_6_other
	UTRAP(0x0fc); TA32	! 0x0fc fill_7_other
d1065 1
a1065 1
	STRAP(0x102); STRAP(0x103); STRAP(0x104); STRAP(0x105); STRAP(0x106); STRAP(0x107)
d1069 15
a1083 15
	STRAP(0x10b); STRAP(0x10c); STRAP(0x10d); STRAP(0x10e); STRAP(0x10f);
	STRAP(0x110); STRAP(0x111); STRAP(0x112); STRAP(0x113); STRAP(0x114); STRAP(0x115); STRAP(0x116); STRAP(0x117)
	STRAP(0x118); STRAP(0x119); STRAP(0x11a); STRAP(0x11b); STRAP(0x11c); STRAP(0x11d); STRAP(0x11e); STRAP(0x11f)
	STRAP(0x120); STRAP(0x121); STRAP(0x122); STRAP(0x123); STRAP(0x124); STRAP(0x125); STRAP(0x126); STRAP(0x127)
	STRAP(0x128); STRAP(0x129); STRAP(0x12a); STRAP(0x12b); STRAP(0x12c); STRAP(0x12d); STRAP(0x12e); STRAP(0x12f)
	STRAP(0x130); STRAP(0x131); STRAP(0x132); STRAP(0x133); STRAP(0x134); STRAP(0x135); STRAP(0x136); STRAP(0x137)
	STRAP(0x138); STRAP(0x139); STRAP(0x13a); STRAP(0x13b); STRAP(0x13c); STRAP(0x13d); STRAP(0x13e); STRAP(0x13f)
	STRAP(0x140); STRAP(0x141); STRAP(0x142); STRAP(0x143); STRAP(0x144); STRAP(0x145); STRAP(0x146); STRAP(0x147)
	STRAP(0x148); STRAP(0x149); STRAP(0x14a); STRAP(0x14b); STRAP(0x14c); STRAP(0x14d); STRAP(0x14e); STRAP(0x14f)
	STRAP(0x150); STRAP(0x151); STRAP(0x152); STRAP(0x153); STRAP(0x154); STRAP(0x155); STRAP(0x156); STRAP(0x157)
	STRAP(0x158); STRAP(0x159); STRAP(0x15a); STRAP(0x15b); STRAP(0x15c); STRAP(0x15d); STRAP(0x15e); STRAP(0x15f)
	STRAP(0x160); STRAP(0x161); STRAP(0x162); STRAP(0x163); STRAP(0x164); STRAP(0x165); STRAP(0x166); STRAP(0x167)
	STRAP(0x168); STRAP(0x169); STRAP(0x16a); STRAP(0x16b); STRAP(0x16c); STRAP(0x16d); STRAP(0x16e); STRAP(0x16f)
	STRAP(0x170); STRAP(0x171); STRAP(0x172); STRAP(0x173); STRAP(0x174); STRAP(0x175); STRAP(0x176); STRAP(0x177)
	STRAP(0x178); STRAP(0x179); STRAP(0x17a); STRAP(0x17b); STRAP(0x17c); STRAP(0x17d); STRAP(0x17e); STRAP(0x17f)
d1085 16
a1100 16
	UTRAP(0x180); UTRAP(0x181); UTRAP(0x182); UTRAP(0x183); UTRAP(0x184); UTRAP(0x185); UTRAP(0x186); UTRAP(0x187)
	UTRAP(0x188); UTRAP(0x189); UTRAP(0x18a); UTRAP(0x18b); UTRAP(0x18c); UTRAP(0x18d); UTRAP(0x18e); UTRAP(0x18f)
	UTRAP(0x190); UTRAP(0x191); UTRAP(0x192); UTRAP(0x193); UTRAP(0x194); UTRAP(0x195); UTRAP(0x196); UTRAP(0x197)
	UTRAP(0x198); UTRAP(0x199); UTRAP(0x19a); UTRAP(0x19b); UTRAP(0x19c); UTRAP(0x19d); UTRAP(0x19e); UTRAP(0x19f)
	UTRAP(0x1a0); UTRAP(0x1a1); UTRAP(0x1a2); UTRAP(0x1a3); UTRAP(0x1a4); UTRAP(0x1a5); UTRAP(0x1a6); UTRAP(0x1a7)
	UTRAP(0x1a8); UTRAP(0x1a9); UTRAP(0x1aa); UTRAP(0x1ab); UTRAP(0x1ac); UTRAP(0x1ad); UTRAP(0x1ae); UTRAP(0x1af)
	UTRAP(0x1b0); UTRAP(0x1b1); UTRAP(0x1b2); UTRAP(0x1b3); UTRAP(0x1b4); UTRAP(0x1b5); UTRAP(0x1b6); UTRAP(0x1b7)
	UTRAP(0x1b8); UTRAP(0x1b9); UTRAP(0x1ba); UTRAP(0x1bb); UTRAP(0x1bc); UTRAP(0x1bd); UTRAP(0x1be); UTRAP(0x1bf)
	UTRAP(0x1c0); UTRAP(0x1c1); UTRAP(0x1c2); UTRAP(0x1c3); UTRAP(0x1c4); UTRAP(0x1c5); UTRAP(0x1c6); UTRAP(0x1c7)
	UTRAP(0x1c8); UTRAP(0x1c9); UTRAP(0x1ca); UTRAP(0x1cb); UTRAP(0x1cc); UTRAP(0x1cd); UTRAP(0x1ce); UTRAP(0x1cf)
	UTRAP(0x1d0); UTRAP(0x1d1); UTRAP(0x1d2); UTRAP(0x1d3); UTRAP(0x1d4); UTRAP(0x1d5); UTRAP(0x1d6); UTRAP(0x1d7)
	UTRAP(0x1d8); UTRAP(0x1d9); UTRAP(0x1da); UTRAP(0x1db); UTRAP(0x1dc); UTRAP(0x1dd); UTRAP(0x1de); UTRAP(0x1df)
	UTRAP(0x1e0); UTRAP(0x1e1); UTRAP(0x1e2); UTRAP(0x1e3); UTRAP(0x1e4); UTRAP(0x1e5); UTRAP(0x1e6); UTRAP(0x1e7)
	UTRAP(0x1e8); UTRAP(0x1e9); UTRAP(0x1ea); UTRAP(0x1eb); UTRAP(0x1ec); UTRAP(0x1ed); UTRAP(0x1ee); UTRAP(0x1ef)
	UTRAP(0x1f0); UTRAP(0x1f1); UTRAP(0x1f2); UTRAP(0x1f3); UTRAP(0x1f4); UTRAP(0x1f5); UTRAP(0x1f6); UTRAP(0x1f7)
	UTRAP(0x1f8); UTRAP(0x1f9); UTRAP(0x1fa); UTRAP(0x1fb); UTRAP(0x1fc); UTRAP(0x1fd); UTRAP(0x1fe); UTRAP(0x1ff)
d1113 1
a1113 1
	set	EINTSTACK-STKB-CC64FSZ, %l0
d1129 4
a1132 4
#define CHKREG(r) \
	ldx	[%o0 + 8*1], %o1; \
	cmp	r, %o1; \
	stx	%o0, [%o0]; \
d1134 1
d1142 3
a1144 8
	stx	%g0, [%o0]
	stx	%g1, [%o0 + 8*1]
	stx	%g2, [%o0 + 8*2]
	stx	%g3, [%o0 + 8*3]
	stx	%g4, [%o0 + 8*4]
	stx	%g5, [%o0 + 8*5]
	stx	%g6, [%o0 + 8*6]
	stx	%g7, [%o0 + 8*7]
d1153 3
a1155 7
	CHKREG(%g1)
	CHKREG(%g2)
	CHKREG(%g3)
	CHKREG(%g4)
	CHKREG(%g5)
	CHKREG(%g6)
	CHKREG(%g7)
d1164 5
a1168 4
#define CHKPT(r1,r2,val) \
	sethi	%hi(DATA_START), r1; \
	mov	val, r2; \
	stb	r2, [r1 + 0x21]
d1229 2
a1230 2
#define	CHKPT(r1,r2,val)
#define CHKREG(r)
d1253 24
a1276 21
	/* set stack pointer redzone to base+minstack; alters base */
#define	SET_SP_REDZONE(base, tmp) \
	add	base, REDSIZE, base; \
	sethi	%hi(_C_LABEL(redzone)), tmp; \
	stx	base, [tmp + %lo(_C_LABEL(redzone))]

	/* variant with a constant */
#define	SET_SP_REDZONE_CONST(const, tmp1, tmp2) \
	set	(const) + REDSIZE, tmp1; \
	sethi	%hi(_C_LABEL(redzone)), tmp2; \
	stx	tmp1, [tmp2 + %lo(_C_LABEL(redzone))]

	/* check stack pointer against redzone (uses two temps) */
#define	CHECK_SP_REDZONE(t1, t2) \
	sethi	KERNBASE, t1;	\
	cmp	%sp, t1;	\
	blu,pt	%xcc, 7f;	\
	 sethi	%hi(_C_LABEL(redzone)), t1; \
	ldx	[t1 + %lo(_C_LABEL(redzone))], t2; \
	cmp	%sp, t2;	/* if sp >= t2, not in red zone */ \
	blu	panic_red; nop;	/* and can continue normally */ \
d1278 1
d1297 6
a1302 3
#define	SET_SP_REDZONE(base, tmp)
#define	SET_SP_REDZONE_CONST(const, t1, t2)
#define	CHECK_SP_REDZONE(t1, t2)
d1322 33
a1354 32
#define	TRACEIT(tt,r3,r4,r2,r6,r7)					\
	set	trap_trace, r2;						\
	lduw	[r2+TRACEDIS], r4;					\
	brnz,pn	r4, 1f;							\
	 lduw	[r2+TRACEPTR], r3;					\
	rdpr	%tl, r4;						\
	cmp	r4, 1;							\
	sllx	r4, 13, r4;						\
	rdpr	%pil, r6;						\
	or	r4, %g5, r4;						\
	mov	%g0, %g5;						\
	andncc	r3, (TRACESIZ-1), %g0;	/* At end of buffer? */		\
	sllx	r6, 9, r6;						\
	or	r6, r4, r4;						\
	movnz	%icc, %g0, r3;		/* Wrap buffer if needed */	\
	rdpr	%tstate, r6;						\
	rdpr	%tpc, r7;						\
	sth	r4, [r2+r3];						\
	inc	2, r3;							\
	sth	%g5, [r2+r3];						\
	inc	2, r3;							\
	stw	r6, [r2+r3];						\
	inc	4, r3;							\
	stw	%sp, [r2+r3];						\
	inc	4, r3;							\
	stw	r7, [r2+r3];						\
	inc	4, r3;							\
	mov	TLB_TAG_ACCESS, r7;					\
	ldxa	[r7] ASI_DMMU, r7;					\
	stw	r7, [r2+r3];						\
	inc	4, r3;							\
	stw	r3, [r2+TRACEPTR];					\
d1356 1
d1381 1
a1381 1
	LDPTR	[%g6], %g6
d1387 1
a1387 1
	LDPTR	[%g6+P_PID], %g5	! Load PID
d1390 1
a1390 1
	LDPTR	[%g6], %g6
d1492 1
a1492 1
 * trap frame so we don't trap during the TRAP_SETUP() operation.  There
d1569 21
a1589 74
#define	TRAP_SETUP(stackspace) \
	sethi	%hi(CPCB), %g6; \
	sethi	%hi((stackspace)), %g5; \
	\
	ldx	[%g6 + %lo(CPCB)], %g6; \
	sethi	%hi(USPACE), %g7;				/* Always multiple of page size */ \
	or	%g5, %lo((stackspace)), %g5; \
	\
	sra	%g5, 0, %g5;					/* Sign extend the damn thing */ \
	\
	add	%g6, %g7, %g6; \
	rdpr	%wstate, %g7;					/* Find if we're from user mode */ \
\
	\
	\
	\
	sub	%g7, WSTATE_KERN, %g7;				/* Compare & leave in register */ \
	\
	movrz	%g7, %sp, %g6;					/* Select old (kernel) stack or base of kernel stack */ \
	\
	\
	btst	1, %g6;						/* Fixup 64-bit stack if necessary */ \
	bnz,pt	%icc, 1f; \
	\
	 add	%g6, %g5, %g6;					/* Allocate a stack frame */ \
	\
	inc	-BIAS, %g6; \
	nop; \
	nop; \
\
1:	stx	%l0, [%g6 + CC64FSZ + BIAS + TF_L + (0*8)];		/* Save local registers to trap frame */ \
	stx	%l1, [%g6 + CC64FSZ + BIAS + TF_L + (1*8)]; \
	stx	%l2, [%g6 + CC64FSZ + BIAS + TF_L + (2*8)]; \
	stx	%l3, [%g6 + CC64FSZ + BIAS + TF_L + (3*8)]; \
	stx	%l4, [%g6 + CC64FSZ + BIAS + TF_L + (4*8)]; \
	stx	%l5, [%g6 + CC64FSZ + BIAS + TF_L + (5*8)]; \
	stx	%l6, [%g6 + CC64FSZ + BIAS + TF_L + (6*8)]; \
\
	stx	%l7, [%g6 + CC64FSZ + BIAS + TF_L + (7*8)]; \
	stx	%i0, [%g6 + CC64FSZ + BIAS + TF_I + (0*8)];		/* Save in registers to trap frame */ \
	stx	%i1, [%g6 + CC64FSZ + BIAS + TF_I + (1*8)]; \
	stx	%i2, [%g6 + CC64FSZ + BIAS + TF_I + (2*8)]; \
	stx	%i3, [%g6 + CC64FSZ + BIAS + TF_I + (3*8)]; \
	stx	%i4, [%g6 + CC64FSZ + BIAS + TF_I + (4*8)]; \
	stx	%i5, [%g6 + CC64FSZ + BIAS + TF_I + (5*8)]; \
	stx	%i6, [%g6 + CC64FSZ + BIAS + TF_I + (6*8)]; \
\
	stx	%i7, [%g6 + CC64FSZ + BIAS + TF_I + (7*8)]; \
	save	%g6, 0, %sp;					/* If we fault we should come right back here */ \
	stx	%i0, [%sp + CC64FSZ + BIAS + TF_O + (0*8)];		/* Save out registers to trap frame */ \
	stx	%i1, [%sp + CC64FSZ + BIAS + TF_O + (1*8)]; \
	stx	%i2, [%sp + CC64FSZ + BIAS + TF_O + (2*8)]; \
	stx	%i3, [%sp + CC64FSZ + BIAS + TF_O + (3*8)]; \
	stx	%i4, [%sp + CC64FSZ + BIAS + TF_O + (4*8)]; \
	stx	%i5, [%sp + CC64FSZ + BIAS + TF_O + (5*8)]; \
\
	stx	%i6, [%sp + CC64FSZ + BIAS + TF_O + (6*8)]; \
	brz,pt	%g7, 1f;					/* If we were in kernel mode start saving globals */ \
	 stx	%i7, [%sp + CC64FSZ + BIAS + TF_O + (7*8)]; \
	mov	CTX_PRIMARY, %g7; \
	\
	/* came from user mode -- switch to kernel mode stack */ \
	rdpr	%canrestore, %g5;				/* Fixup register window state registers */ \
	\
	wrpr	%g0, 0, %canrestore; \
	\
	wrpr	%g0, %g5, %otherwin; \
	\
	wrpr	%g0, WSTATE_KERN, %wstate;			/* Enable kernel mode window traps -- now we can trap again */ \
\
	stxa	%g0, [%g7] ASI_DMMU; 				/* Switch MMU to kernel primary context */ \
	sethi	%hi(KERNBASE), %g5; \
	membar	#Sync;						/* XXXX Should be taken care of by flush */ \
	flush	%g5;						/* Some convenient address that won't trap */ \
d1591 29
d1629 65
a1693 81
#define	INTR_SETUP(stackspace) \
	rdpr	%wstate, %g7;					/* Find if we're from user mode */ \
	\
	sethi	%hi(EINTSTACK-BIAS), %g6; \
	sethi	%hi(EINTSTACK-INTSTACK), %g4; \
	\
	or	%g6, %lo(EINTSTACK-BIAS), %g6;			/* Base of interrupt stack */ \
	dec	%g4;						/* Make it into a mask */ \
	\
	sub	%g6, %sp, %g1;					/* Offset from interrupt stack */ \
	sethi	%hi((stackspace)), %g5; \
	\
	or	%g5, %lo((stackspace)), %g5; \
\
	andn	%g1, %g4, %g4;					/* Are we out of the interrupt stack range? */ \
	xor	%g7, WSTATE_KERN, %g3;				/* Are we on the user stack ? */ \
	\
	sra	%g5, 0, %g5;					/* Sign extend the damn thing */ \
	or	%g3, %g4, %g4;					/* Definitely not off the interrupt stack */ \
	\
	movrz	%g4, %sp, %g6; \
	\
	add	%g6, %g5, %g5;					/* Allocate a stack frame */ \
	btst	1, %g6; \
	bnz,pt	%icc, 1f; \
\
	 mov	%g5, %g6; \
	\
	add	%g5, -BIAS, %g6; \
	\
1:	stx	%l0, [%g6 + CC64FSZ + BIAS + TF_L + (0*8)];		/* Save local registers to trap frame */ \
	stx	%l1, [%g6 + CC64FSZ + BIAS + TF_L + (1*8)]; \
	stx	%l2, [%g6 + CC64FSZ + BIAS + TF_L + (2*8)]; \
	stx	%l3, [%g6 + CC64FSZ + BIAS + TF_L + (3*8)]; \
	stx	%l4, [%g6 + CC64FSZ + BIAS + TF_L + (4*8)]; \
	stx	%l5, [%g6 + CC64FSZ + BIAS + TF_L + (5*8)]; \
\
	stx	%l6, [%g6 + CC64FSZ + BIAS + TF_L + (6*8)]; \
	stx	%l7, [%g6 + CC64FSZ + BIAS + TF_L + (7*8)]; \
	stx	%i0, [%g6 + CC64FSZ + BIAS + TF_I + (0*8)];		/* Save in registers to trap frame */ \
	stx	%i1, [%g6 + CC64FSZ + BIAS + TF_I + (1*8)]; \
	stx	%i2, [%g6 + CC64FSZ + BIAS + TF_I + (2*8)]; \
	stx	%i3, [%g6 + CC64FSZ + BIAS + TF_I + (3*8)]; \
	stx	%i4, [%g6 + CC64FSZ + BIAS + TF_I + (4*8)]; \
	stx	%i5, [%g6 + CC64FSZ + BIAS + TF_I + (5*8)]; \
\
	stx	%i6, [%g6 + CC64FSZ + BIAS + TF_I + (6*8)]; \
	stx	%i7, [%g6 + CC64FSZ + BIAS + TF_I + (7*8)]; \
	save	%g6, 0, %sp;					/* If we fault we should come right back here */ \
	stx	%i0, [%sp + CC64FSZ + BIAS + TF_O + (0*8)];		/* Save out registers to trap frame */ \
	stx	%i1, [%sp + CC64FSZ + BIAS + TF_O + (1*8)]; \
	stx	%i2, [%sp + CC64FSZ + BIAS + TF_O + (2*8)]; \
	stx	%i3, [%sp + CC64FSZ + BIAS + TF_O + (3*8)]; \
	stx	%i4, [%sp + CC64FSZ + BIAS + TF_O + (4*8)]; \
\
	stx	%i5, [%sp + CC64FSZ + BIAS + TF_O + (5*8)]; \
	stx	%i6, [%sp + CC64FSZ + BIAS + TF_O + (6*8)]; \
	stx	%i6, [%sp + CC64FSZ + BIAS + TF_G + (0*8)];		/* Save fp in clockframe->cf_fp */ \
	brz,pt	%g3, 1f;					/* If we were in kernel mode start saving globals */ \
	 stx	%i7, [%sp + CC64FSZ + BIAS + TF_O + (7*8)]; \
	/* came from user mode -- switch to kernel mode stack */ \
	 rdpr	%otherwin, %g5;					/* Has this already been done? */ \
	\
/*	tst %g5; tnz %xcc, 1; nop; /* DEBUG -- this should _NEVER_ happen */ \
	brnz,pn	%g5, 1f;					/* Don't set this twice */ \
	\
	 rdpr	%canrestore, %g5;				/* Fixup register window state registers */ \
\
	wrpr	%g0, 0, %canrestore; \
	\
	wrpr	%g0, %g5, %otherwin; \
	\
	sethi	%hi(KERNBASE), %g5; \
	mov	CTX_PRIMARY, %g7; \
	\
	wrpr	%g0, WSTATE_KERN, %wstate;			/* Enable kernel mode window traps -- now we can trap again */ \
	\
	stxa	%g0, [%g7] ASI_DMMU; 				/* Switch MMU to kernel primary context */ \
	membar	#Sync;						/* XXXX Should be taken care of by flush */ \
	\
	flush	%g5;						/* Some convenient address that won't trap */ \
d1695 1
d1715 1
a1715 1
	DLFLUSH(%g4,%g5)
d1717 1
a1717 1
	DLFLUSH2(%g5)
d1724 1
a1724 1
	DLFLUSH(%g4,%g5)
d1726 1
a1726 1
	DLFLUSH2(%g5)
d1733 1
a1733 1
	DLFLUSH(%g4,%g5)
d1735 1
a1735 1
	DLFLUSH2(%g5)
d1770 1
a1770 1
	LDPTR	[%g4 + %lo(_C_LABEL(ctxbusy))], %g4
d1787 1
a1787 1
	DLFLUSH(%g4,%g6)
d1789 1
a1789 1
	DLFLUSH2(%g6)
d1898 1
a1898 1
	LDPTR	[%g4 + %lo(_C_LABEL(ctxbusy))], %g4
d2031 1
a2031 1
	CHKPT(%g4,%g7,0x19)
d2042 1
a2042 1
	CHKPT(%g4,%g7,0x20)
d2059 1
a2059 1
	set	EINTSTACK+USPACE+CC64FSZ-STKB, %fp ! Set the frame pointer to the middle of the idle stack
d2091 1
a2091 1
	 * kernel window and a user window state.  If we do a TRAP_SETUP() now,
d2127 1
a2127 1
	CHKPT(%g5,%g7,0xe)
d2138 1
a2138 1
	CHKPT(%g5,%g7,0xe)
d2168 1
a2168 1
	CHKPT(%g4,%g7,0xf)
d2177 1
a2177 1
	TRAP_SETUP(-CC64FSZ-TF_SIZE)
d2197 1
a2197 1
#ifndef TRAPTRACE
a2199 52
#else	/* TRAPTRACE */
	bne,pt	%xcc, 3f				! Let's do a regular datafault.  When we try a save in datafault we'll
	 nop
	wrpr	%g5, 0, %cwp				!  return here and write out all dirty windows.
	set	trap_trace, %g2
	lduw	[%g2+TRACEDIS], %g4
	brnz,pn	%g4, 1f
	 nop
	lduw	[%g2+TRACEPTR], %g3
	rdpr	%tl, %g4
	mov	2, %g5
	set	CURPROC, %g6
	sllx	%g4, 13, %g4
!	LDPTR	[%g6], %g6	! Never touch PID
	clr	%g6		! DISABLE PID
	or	%g4, %g5, %g4
	mov	%g0, %g5
	brz,pn	%g6, 2f
	 andncc	%g3, (TRACESIZ-1), %g0
!	ldsw	[%g6+P_PID], %g5	! Load PID
2:
	movnz	%icc, %g0, %g3		! Wrap if needed
	ba,a,pt	%xcc, 4f

	set	CPCB, %g6	! Load up nsaved
	LDPTR	[%g6], %g6
	ldub	[%g6 + PCB_NSAVED], %g6
	sllx	%g6, 9, %g6
	or	%g6, %g4, %g4
4:
	rdpr	%tstate, %g6
	rdpr	%tpc, %g7
	sth	%g4, [%g2+%g3]
	inc	2, %g3
	sth	%g5, [%g2+%g3]
	inc	2, %g3
	stw	%g6, [%g2+%g3]
	inc	4, %g3
	stw	%sp, [%g2+%g3]
	inc	4, %g3
	stw	%g7, [%g2+%g3]
	inc	4, %g3
	mov	TLB_TAG_ACCESS, %g7
	ldxa	[%g7] ASI_DMMU, %g7
	stw	%g7, [%g2+%g3]
	inc	4, %g3
	stw	%g3, [%g2+TRACEPTR]
1:
	ba	datafault
	 nop
3:
#endif	/* TRAPTRACE */
d2202 1
a2202 1
	LDPTR	[%g6 + %lo(CPCB)], %g6	! This is in the locked TLB and should not fault
d2213 1
a2213 1
	CHKPT(%g5,%g7,0x11)
d2225 1
a2225 1
	LDPTR	[%g1 + %lo(_C_LABEL(ctxbusy))], %g1	! Load start of ctxbusy
d2238 1
a2238 1
	DLFLUSH(%g1,%g7)
d2240 1
a2240 1
	DLFLUSH2(%g7)
d2247 1
a2247 1
	DLFLUSH(%g1,%g7)
d2249 1
a2249 1
	DLFLUSH2(%g7)
d2256 1
a2256 1
	DLFLUSH(%g7,%g1)
d2258 1
a2258 1
	DLFLUSH2(%g1)
d2274 1
a2274 1
	DLFLUSH(%g7,%g5)
d2276 1
a2276 1
	DLFLUSH2(%g5)
d2283 1
a2283 1
	CHKPT(%g5,%g7,0x12)
d2295 1
a2295 1
	CHKPT(%g5,%g7,0x13)
d2297 1
a2297 1
	DLFLUSH(%g7,%g5)
d2299 1
a2299 1
	DLFLUSH2(%g5)
d2309 1
a2309 1
!	CHKPT(%g4,%g7,0x10)	! Checkpoint
d2326 1
a2326 1
	set	panicstack-CC64FSZ-STKB, %sp		! Use panic stack.
d2329 2
a2330 2
	LDPTR	[%sp], %sp
	add	%sp, -CC64FSZ-STKB, %sp			! Overwrite proc 0's stack.
d2373 1
a2373 1
	CHKPT(%g5,%g1,0x14)
a2421 3
#ifdef xTRAPTRACE
	wrpr	%g5, 0, %cleanwin			! Force cleanwindow faults
#endif	/* xTRAPTRACE */
d2452 1
a2452 1
	CHKPT(%g5,%g1,0x15)
d2458 1
a2458 1
	CHKPT(%g2,%g5,0x16)
d2473 1
a2473 1
	CHKPT(%g2,%g1,0x17)
d2507 1
a2507 1
	CHKPT(%g2,%g1,0x18)
a2529 49
#ifdef TRAPTRACE
	and	%g4, CWP, %g2	! Point our regwin at right place
	wrpr	%g2, %cwp

	set	trap_trace, %g2
	lduw	[%g2+TRACEDIS], %g4
	brnz,pn	%g4, 1f
	 nop
	lduw	[%g2+TRACEPTR], %g3
	rdpr	%tl, %g4
	mov	3, %g5
	set	CURPROC, %g6
	sllx	%g4, 13, %g4
!	LDPTR	[%g6], %g6	! Never do faultable loads
	clr	%g6		! DISABLE PID
	or	%g4, %g5, %g4
	mov	%g0, %g5
	brz,pn	%g6, 2f
	 andncc	%g3, (TRACESIZ-1), %g0
!	ldsw	[%g6+P_PID], %g5	! Load PID
2:
	movnz	%icc, %g0, %g3	! Wrap if needed

	set	CPCB, %g6	! Load up nsaved
	LDPTR	[%g6], %g6
	clr	%g6
!	ldub	[%g6 + PCB_NSAVED], %g6! this could fault
	sllx	%g6, 9, %g6
	or	%g6, %g4, %g4

	rdpr	%tstate, %g6
	rdpr	%tpc, %g7
	sth	%g4, [%g2+%g3]
	inc	2, %g3
	sth	%g5, [%g2+%g3]
	inc	2, %g3
	stw	%g6, [%g2+%g3]
	inc	4, %g3
	stw	%sp, [%g2+%g3]
	inc	4, %g3
	stw	%g7, [%g2+%g3]
	inc	4, %g3
	mov	TLB_TAG_ACCESS, %g7
	ldxa	[%g7] ASI_DMMU, %g7
	stw	%g7, [%g2+%g3]
	inc	4, %g3
	stw	%g3, [%g2+TRACEPTR]
1:
#endif	/* TRAPTRACE */
d2590 1
a2590 1
	CHKPT(%g4,%g7,0xf)
d2599 1
a2599 1
	TRAP_SETUP(-CC64FSZ-TF_SIZE)
d2601 2
a2602 2
	INCR(_C_LABEL(uvmexp)+V_FAULTS)			! cnt.v_faults++ (clobbers %o0,%o1,%o2) should not fault
!	ldx	[%sp + CC64FSZ + STKB + TF_FAULT], %g1		! DEBUG make sure this has not changed
a2612 8
#ifdef TRAPTRACE
	rdpr	%tt, %o1				! find out what trap brought us here
	wrpr	%g0, 0x69, %tt	! We claim to be trap type 69, not a valid trap
	TRACEME
	wrpr	%g0, PSTATE_KERN, %pstate		! Get back to normal globals

	stx	%g1, [%sp + CC64FSZ + STKB + TF_G + (1*8)]	! save g1
#else	/* TRAPTRACE */
d2615 1
a2615 1
	stx	%g1, [%sp + CC64FSZ + STKB + TF_G + (1*8)]	! save g1
d2617 1
a2617 2
#endif	/* TRAPTRACE */
	stx	%g2, [%sp + CC64FSZ + STKB + TF_G + (2*8)]	! save g2
d2619 1
a2619 1
	stx	%g3, [%sp + CC64FSZ + STKB + TF_G + (3*8)]	! (sneak g3 in here)
d2621 1
a2621 1
	stx	%g4, [%sp + CC64FSZ + STKB + TF_G + (4*8)]	! sneak in g4
d2623 1
a2623 1
	stx	%g5, [%sp + CC64FSZ + STKB + TF_G + (5*8)]	! sneak in g5
d2625 1
a2625 1
	stx	%g6, [%sp + CC64FSZ + STKB + TF_G + (6*8)]	! sneak in g6
d2627 1
a2627 1
	stx	%g7, [%sp + CC64FSZ + STKB + TF_G + (7*8)]	! sneak in g7
d2634 4
a2637 4
	sth	%o1, [%sp + CC64FSZ + STKB + TF_TT]
	stx	%g1, [%sp + CC64FSZ + STKB + TF_TSTATE]		! set tf.tf_psr, tf.tf_pc
	stx	%g2, [%sp + CC64FSZ + STKB + TF_PC]		! set tf.tf_npc
	stx	%g3, [%sp + CC64FSZ + STKB + TF_NPC]
d2640 2
a2641 2
	stb	%g5, [%sp + CC64FSZ + STKB + TF_PIL]
	stb	%g5, [%sp + CC64FSZ + STKB + TF_OLDPIL]
d2647 1
a2647 1
	CHKPT(%g1,%g3,0x21)
d2650 1
a2650 1
	CHKPT(%g1,%g3,0x21)
d2657 1
a2657 1
	LDPTR	[%o7], %o7
d2686 1
a2686 1
	st	%g4, [%sp + CC64FSZ + STKB + TF_Y]
d2695 1
a2695 1
	 add	%sp, CC64FSZ + STKB, %o0	! (argument: &tf)
d2698 1
a2698 1
	CHKPT(%o1,%o2,1)
d2707 1
a2707 1
	 ldx	[%sp + CC64FSZ + STKB + TF_TSTATE], %g1		! Load this for return_from_trap
d2713 1
a2713 1
	 add	%sp, CC64FSZ + STKB, %o0	! (argument: &tf)
d2753 1
a2753 1
	LDPTR	[%g4 + %lo(_C_LABEL(ctxbusy))], %g4
d2878 2
a2879 2
	TRAP_SETUP(-CC64FSZ-TF_SIZE)
	INCR(_C_LABEL(uvmexp)+V_FAULTS)			! cnt.v_faults++ (clobbers %o0,%o1,%o2)
d2889 3
a2891 3
	stx	%g1, [%sp + CC64FSZ + STKB + TF_G + (1*8)]	! save g1
	stx	%g2, [%sp + CC64FSZ + STKB + TF_G + (2*8)]	! save g2
	stx	%g3, [%sp + CC64FSZ + STKB + TF_G + (3*8)]	! (sneak g3 in here)
d2893 1
a2893 1
	stx	%g4, [%sp + CC64FSZ + STKB + TF_G + (4*8)]	! sneak in g4
d2895 1
a2895 1
	stx	%g5, [%sp + CC64FSZ + STKB + TF_G + (5*8)]	! sneak in g5
d2897 1
a2897 1
	stx	%g6, [%sp + CC64FSZ + STKB + TF_G + (6*8)]	! sneak in g6
d2899 1
a2899 1
	stx	%g7, [%sp + CC64FSZ + STKB + TF_G + (7*8)]	! sneak in g7
d2903 2
a2904 2
	stx	%g1, [%sp + CC64FSZ + STKB + TF_TSTATE]		! set tf.tf_psr, tf.tf_pc
	sth	%o1, [%sp + CC64FSZ + STKB + TF_TT]! debug
d2906 2
a2907 2
	stx	%o2, [%sp + CC64FSZ + STKB + TF_PC]
	stx	%g3, [%sp + CC64FSZ + STKB + TF_NPC]		! set tf.tf_npc
d2910 2
a2911 2
	stb	%g5, [%sp + CC64FSZ + STKB + TF_PIL]
	stb	%g5, [%sp + CC64FSZ + STKB + TF_OLDPIL]
d2916 1
a2916 1
	CHKPT(%g1,%g3,0x22)
d2925 1
a2925 1
	 st	%g7, [%sp + CC64FSZ + STKB + TF_Y]		! set tf.tf_y
d2929 1
a2929 1
	 add	%sp, CC64FSZ + STKB, %o0	! (argument: &tf)
d2931 1
a2931 1
	CHKPT(%o1,%o2,2)
d2934 1
a2934 1
	 ldx	[%sp + CC64FSZ + STKB + TF_TSTATE], %g1	! Load this for return_from_trap
d2941 1
a2941 1
	 add	%sp, CC64FSZ + STKB, %o0	! (argument: &tf)
d2996 2
a2997 2
	LDPTR	[%sp], %sp
	add	%sp, -CC64FSZ-STKB, %sp	! Overwrite proc 0's stack.
d3006 1
a3006 1
	TRAP_SETUP(-CC64FSZ-TF_SIZE)
d3008 1
a3008 1
	stx	%g1, [%sp + CC64FSZ + STKB + TF_TSTATE]
d3010 1
a3010 1
	stx	%g2, [%sp + CC64FSZ + STKB + TF_PC]
d3012 1
a3012 1
	stx	%g3, [%sp + CC64FSZ + STKB + TF_NPC]
d3014 1
a3014 1
	st	%g5, [%sp + CC64FSZ + STKB + TF_Y]
d3016 1
a3016 1
	sth	%o1, [%sp + CC64FSZ + STKB + TF_TT]! debug
d3019 6
a3024 6
	stx	%g1, [%sp + CC64FSZ + STKB + TF_G + (1*8)]
	stx	%g2, [%sp + CC64FSZ + STKB + TF_G + (2*8)]
	add	%sp, CC64FSZ + STKB, %o0		! (&tf)
	stx	%g3, [%sp + CC64FSZ + STKB + TF_G + (3*8)]
	stx	%g4, [%sp + CC64FSZ + STKB + TF_G + (4*8)]
	stx	%g5, [%sp + CC64FSZ + STKB + TF_G + (5*8)]
d3026 4
a3029 4
	stx	%g6, [%sp + CC64FSZ + STKB + TF_G + (6*8)]
	stx	%g7, [%sp + CC64FSZ + STKB + TF_G + (7*8)]
	stb	%g5, [%sp + CC64FSZ + STKB + TF_PIL]
	stb	%g5, [%sp + CC64FSZ + STKB + TF_OLDPIL]
d3036 1
a3036 1
	CHKPT(%g2,%g3,0x24)
d3044 1
a3044 1
	CHKPT(%o1,%o2,3)
d3079 2
a3080 2
	 LDPTR	[%g6 + %lo(CPCB)], %g7
	set	USPACE-CC64FSZ-TF_SIZE-STKB, %g5
d3082 43
a3124 43
	SET_SP_REDZONE(%g7, %g5)
	stx	%g1, [%g6 + CC64FSZ + STKB + TF_FAULT]		! Generate a new trapframe
	stx	%i0, [%g6 + CC64FSZ + STKB + TF_O + (0*8)]	!	but don't bother with
	stx	%i1, [%g6 + CC64FSZ + STKB + TF_O + (1*8)]	!	locals and ins
	stx	%i2, [%g6 + CC64FSZ + STKB + TF_O + (2*8)]
	stx	%i3, [%g6 + CC64FSZ + STKB + TF_O + (3*8)]
	stx	%i4, [%g6 + CC64FSZ + STKB + TF_O + (4*8)]
	stx	%i5, [%g6 + CC64FSZ + STKB + TF_O + (5*8)]
	stx	%i6, [%g6 + CC64FSZ + STKB + TF_O + (6*8)]
	stx	%i7, [%g6 + CC64FSZ + STKB + TF_O + (7*8)]
#ifdef DEBUG
	ldx	[%sp + CC64FSZ + STKB + TF_I + (0*8)], %l0	! Copy over the rest of the regs
	ldx	[%sp + CC64FSZ + STKB + TF_I + (1*8)], %l1	! But just dirty the locals
	ldx	[%sp + CC64FSZ + STKB + TF_I + (2*8)], %l2
	ldx	[%sp + CC64FSZ + STKB + TF_I + (3*8)], %l3
	ldx	[%sp + CC64FSZ + STKB + TF_I + (4*8)], %l4
	ldx	[%sp + CC64FSZ + STKB + TF_I + (5*8)], %l5
	ldx	[%sp + CC64FSZ + STKB + TF_I + (6*8)], %l6
	ldx	[%sp + CC64FSZ + STKB + TF_I + (7*8)], %l7
	stx	%l0, [%g6 + CC64FSZ + STKB + TF_I + (0*8)]
	stx	%l1, [%g6 + CC64FSZ + STKB + TF_I + (1*8)]
	stx	%l2, [%g6 + CC64FSZ + STKB + TF_I + (2*8)]
	stx	%l3, [%g6 + CC64FSZ + STKB + TF_I + (3*8)]
	stx	%l4, [%g6 + CC64FSZ + STKB + TF_I + (4*8)]
	stx	%l5, [%g6 + CC64FSZ + STKB + TF_I + (5*8)]
	stx	%l6, [%g6 + CC64FSZ + STKB + TF_I + (6*8)]
	stx	%l7, [%g6 + CC64FSZ + STKB + TF_I + (7*8)]
	ldx	[%sp + CC64FSZ + STKB + TF_L + (0*8)], %l0
	ldx	[%sp + CC64FSZ + STKB + TF_L + (1*8)], %l1
	ldx	[%sp + CC64FSZ + STKB + TF_L + (2*8)], %l2
	ldx	[%sp + CC64FSZ + STKB + TF_L + (3*8)], %l3
	ldx	[%sp + CC64FSZ + STKB + TF_L + (4*8)], %l4
	ldx	[%sp + CC64FSZ + STKB + TF_L + (5*8)], %l5
	ldx	[%sp + CC64FSZ + STKB + TF_L + (6*8)], %l6
	ldx	[%sp + CC64FSZ + STKB + TF_L + (7*8)], %l7
	stx	%l0, [%g6 + CC64FSZ + STKB + TF_L + (0*8)]
	stx	%l1, [%g6 + CC64FSZ + STKB + TF_L + (1*8)]
	stx	%l2, [%g6 + CC64FSZ + STKB + TF_L + (2*8)]
	stx	%l3, [%g6 + CC64FSZ + STKB + TF_L + (3*8)]
	stx	%l4, [%g6 + CC64FSZ + STKB + TF_L + (4*8)]
	stx	%l5, [%g6 + CC64FSZ + STKB + TF_L + (5*8)]
	stx	%l6, [%g6 + CC64FSZ + STKB + TF_L + (6*8)]
	stx	%l7, [%g6 + CC64FSZ + STKB + TF_L + (7*8)]
d3215 1
a3215 1
	TRAP_SETUP(-CCFSZ-TF_SIZE)
d3364 1
a3364 1
	LDPTR	[%l1 + %lo(CPCB)], %l1
d3384 1
a3384 1
	TRAP_SETUP(-CC64FSZ-TF_SIZE)
d3388 1
a3388 1
	sth	%o1, [%sp + CC64FSZ + STKB + TF_TT]! debug
d3392 1
a3392 1
	stx	%g1, [%sp + CC64FSZ + STKB + TF_G + ( 1*8)]
d3395 1
a3395 1
	stx	%g2, [%sp + CC64FSZ + STKB + TF_G + ( 2*8)]
d3397 1
a3397 1
	stx	%g3, [%sp + CC64FSZ + STKB + TF_G + ( 3*8)]
d3399 1
a3399 1
	stx	%g4, [%sp + CC64FSZ + STKB + TF_G + ( 4*8)]
d3401 3
a3403 3
	stx	%g5, [%sp + CC64FSZ + STKB + TF_G + ( 5*8)]
	stx	%g6, [%sp + CC64FSZ + STKB + TF_G + ( 6*8)]
	CHKPT(%g5,%g6,0x31)
d3405 2
a3406 2
	stx	%g7, [%sp + CC64FSZ + STKB + TF_G + ( 7*8)]
	add	%sp, CC64FSZ + STKB, %o0	! (&tf)
d3408 4
a3411 4
	stx	%g1, [%sp + CC64FSZ + STKB + TF_TSTATE]
	stx	%o2, [%sp + CC64FSZ + STKB + TF_PC]
	stx	%o3, [%sp + CC64FSZ + STKB + TF_NPC]
	st	%o4, [%sp + CC64FSZ + STKB + TF_Y]
d3414 2
a3415 2
	stb	%g5, [%sp + CC64FSZ + STKB + TF_PIL]
	stb	%g5, [%sp + CC64FSZ + STKB + TF_OLDPIL]
d3425 1
a3425 1
	CHKPT(%o1,%o2,0x32)
d3427 1
a3427 1
	CHKPT(%o1,%o2,4)
d3485 1
a3485 1
	.space	16 * 8 * PTRSZ
d3518 1
a3518 1
	STACKFRAME(-CC64FSZ)		! Get a clean register window
d3534 1
a3534 1
	 sllx	%g2, PTRSHFT, %g5	! Calculate entry number
d3542 1
a3542 1
	LDPTR	[%g3 + %g5], %g5	! We have a pointer to the handler
d3546 1
a3546 1
	STACKFRAME(-CC64FSZ)		! Get a clean register window
a3566 1
#ifdef	INTR_INTERLOCK
a3569 1
#endif	/*  */
d3573 1
a3573 1
	sll	%g6, PTRSHFT+3, %g3	! Find start of table for this IPL
d3577 2
a3578 3
#ifdef INTRLIST
	LDPTR	[%g1], %g3		! Load list head
	STPTR	%g3, [%g5+IH_PEND]	! Link our intrhand node in
d3580 1
a3580 1
	CASPTR	[%g1] ASI_N, %g3, %g7
a3583 47
#else	/* INTRLIST */	/* INTRLIST */
	mov	%g5, %g3
	CASPTR	[%g1] ASI_N, %g0, %g3	! Try a slot -- MPU safe
	brz,pt	%g3, 2f			! Available?
#ifdef DEBUG
	 cmp	%g5, %g3		! if these are the same
	bne,pt	%icc, 97f		! then we aleady have the
	 nop				! interrupt registered
	set	_C_LABEL(intrdebug), %g4
	ld	[%g4], %g4
	btst	INTRDEBUG_VECTOR, %g4
	bz,pt	%icc, 97f
	 nop

	STACKFRAME(-CC64FSZ)		! Get a clean register window
	LOAD_ASCIZ(%o0, "interrupt_vector: duplicate handler %p\r\n")
	GLOBTOLOC
	clr	%g4
	call	prom_printf
	 mov	%g3, %o1
	LOCTOGLOB
	 restore
97:
#endif	/* DEBUG */ 	/* DEBUG */
	 dec	%g7
	brgz,pt	%g7, 1b
	 inc	PTRSZ, %g1		! Next slot

	!! If we get here we have a problem.
	!! There were no available slots and the interrupt was lost.
	!! We'll resort to polling in this case.
#ifdef DIAGNOSTIC
	STACKFRAME(-CC64FSZ)		! Get a clean register window
	LOAD_ASCIZ(%o0, "interrupt_vector: level %d out of slots\r\n")
	mov	%g6, %o1
	GLOBTOLOC
	clr	%g4
	rdpr	%pil, %l0
	call	prom_printf
	 mov	%l0, %o2
	wrpr	%g0, 15, %pil
	ta	1
	LOCTOGLOB
	restore
2:
#endif	/* DIAGNOSTIC */	/* DIAGNOSTIC */
#endif	/* INTRLIST */	/* INTRLIST */
d3592 1
a3592 1
	STACKFRAME(-CC64FSZ)		! Get a clean register window
d3623 1
a3623 1
	STACKFRAME(-CC64FSZ)		! Get a clean register window
d3709 1
a3709 1
	DLFLUSH(%g3, %g2)
d3711 1
a3711 1
	 LDPTR	[%g3 + PTRSZ], %g5	! intrlev[1] is reserved for %tick intr.
d3740 1
a3740 1
	INTR_SETUP(-CC64FSZ-TF_SIZE-8)
d3743 7
a3749 7
	stx	%g1, [%sp + CC64FSZ + STKB + TF_G + ( 1*8)]
	stx	%g2, [%sp + CC64FSZ + STKB + TF_G + ( 2*8)]
	stx	%g3, [%sp + CC64FSZ + STKB + TF_G + ( 3*8)]
	stx	%g4, [%sp + CC64FSZ + STKB + TF_G + ( 4*8)]
	stx	%g5, [%sp + CC64FSZ + STKB + TF_G + ( 5*8)]
	stx	%g6, [%sp + CC64FSZ + STKB + TF_G + ( 6*8)]
	stx	%g7, [%sp + CC64FSZ + STKB + TF_G + ( 7*8)]
d3753 1
a3753 1
	INCR(_C_LABEL(uvmexp)+V_INTR)	! cnt.v_intr++; (clobbers %o0,%o1,%o2)
d3759 1
a3759 1
	stw	%l6, [%sp + CC64FSZ + STKB + TF_Y]	! Silly, but we need to save this for rft
d3761 1
a3761 1
	CHKPT(%l4,%l7,0x26)
d3763 3
a3765 3
	sth	%l5, [%sp + CC64FSZ + STKB + TF_TT]! debug
	stx	%l0, [%sp + CC64FSZ + STKB + TF_TSTATE]	! set up intrframe/clockframe
	stx	%l1, [%sp + CC64FSZ + STKB + TF_PC]
d3767 2
a3768 2
	stx	%l2, [%sp + CC64FSZ + STKB + TF_NPC]
	stx	%fp, [%sp + CC64FSZ + STKB + TF_KSTACK]	!  old frame pointer
d3772 1
a3772 1
	stb	%l6, [%sp + CC64FSZ + STKB + TF_PIL]	! set up intrframe/clockframe
d3776 1
a3776 1
	stb	%o1, [%sp + CC64FSZ + STKB + TF_OLDPIL]	! old %pil
d3795 1
a3795 1
	st	%l7, [%sp + CC64FSZ + STKB + TF_SIZE]
d3800 1
a3800 1
	sll	%l6, PTRSHFT+3, %l2
a3805 1
#ifdef INTRLIST
d3808 1
a3808 1
	LDPTR	[%l4], %l2		! Check a slot
d3813 1
a3813 1
	CASPTR	[%l4] ASI_N, %l2, %l7	! Grab the entire list
d3816 1
a3816 1
	 add	%sp, CC64FSZ+STKB, %o2	! tf = %sp + CC64FSZ + STKB
d3818 4
a3821 4
	LDPTR	[%l2 + IH_PEND], %l7	! Load next pending
	LDPTR	[%l2 + IH_FUN], %o4	! ih->ih_fun
	LDPTR	[%l2 + IH_ARG], %o0	! ih->ih_arg
	LDPTR	[%l2 + IH_CLR], %l1	! ih->ih_clear
d3823 1
a3823 1
	STPTR	%g0, [%l2 + IH_PEND]	! Unlink from list
a3852 97
#else /* INTRLIST */	/* INTRLIST */
	/*
	 * Register usage at this point:
	 *	%l4 - current slot at intrpending[PIL]
	 *	%l5 - sum of interrupt handler return values
	 *	%l6 - PIL
	 */
sparc_intr_check_slot:
	LDPTR	[%l4], %l2		! Check a slot
	dec	%l7
	brnz,pt	%l2, 1f			! Pending?
	 nop
	brgz,pt	%l7, sparc_intr_check_slot
	 inc	PTRSZ, %l4		! Next slot

	ba,a,pt	%icc, intrcmplt		! Only handle vectors -- don't poll XXXX
	 nop				! XXX spitfire bug?

1:
	/*
	 * We have a pending interrupt; prepare to call handler
	 */
!	DLFLUSH(%l2, %o3)
	LDPTR	[%l2 + IH_CLR], %l1
	add	%sp, CC64FSZ+STKB, %o2	! tf = %sp + CC64FSZ + STKB
	LDPTR	[%l2 + IH_FUN], %o4	! ih->ih_fun
	LDPTR	[%l2 + IH_ARG], %o0	! ih->ih_arg

#ifdef DEBUG
	set	_C_LABEL(intrdebug), %o3
	ld	[%o3], %o3
	btst	INTRDEBUG_FUNC, %o3
	bz,a,pt	%icc, 97f
	 nop

	STACKFRAME(-CC64FSZ)		! Get a clean register window
	LOAD_ASCIZ(%o0, "sparc_interrupt:  calling %lx(%lx) sp = %p\r\n")
	mov	%i0, %o2		! arg
	mov	%i6, %o3		! sp
	GLOBTOLOC
	call	prom_printf
	 mov	%i4, %o1		! fun
	LOCTOGLOB
	restore
97:
	mov	%l4, %o1	! XXXXXXX DEBUGGGGGG!
#endif	/* DEBUG */	/* DEBUG */

!	STPTR	%g0, [%l4]		! Clear the slot
	jmpl	%o4, %o7		! handled = (*ih->ih_fun)(...)
	 movrz	%o0, %o2, %o0		! arg = (arg == 0) ? arg : tf
	STPTR	%g0, [%l2 + IH_PEND]	! Clear pending flag
	STPTR	%g0, [%l4]		! Clear the slot

#ifdef DEBUG
	set	_C_LABEL(intrdebug), %o3
	ld	[%o3], %o3
	btst	INTRDEBUG_FUNC, %o3
	bz,a,pt	%icc, 97f
	 nop
#if 0
	brnz,pt	%l1, 97f
	 nop
#endif	/* 0 */

	mov	%l4, %o5
	mov	%l1, %o3
	STACKFRAME(-CC64FSZ)		! Get a clean register window
	mov	%i5, %o1
	mov	%i3, %o3
	LOAD_ASCIZ(%o0, "sparc_interrupt:  ih %p fun %p has %p clear\r\n")
	GLOBTOLOC
	call	prom_printf
	 mov	%i4, %o2		! fun
	LOCTOGLOB
	restore
97:
#endif	/* DEBUG */	/* DEBUG */
	brz,pn	%l1, 0f
	 add	%l5, %o0, %l5
	stx	%g0, [%l1]		! Clear intr source
	membar	#Sync			! Should not be needed
0:
	brnz,pt	%o0, sparc_intr_check_slot	! Handle any others
	 nop

	/*
	 * Interrupt not claimed by handler at this vector entry;
	 * report that.
	 */
	mov	1, %o1
	call	_C_LABEL(strayintr)		! strayintr(&intrframe, 1)
	 add	%sp, CC64FSZ + STKB, %o0

	ba,a,pt	%icc, sparc_intr_check_slot	! Try another
	 nop					! XXX spitfire bug?
#endif /* INTRLIST */	/* INTRLIST */
d3872 1
a3872 1
	STACKFRAME(-CC64FSZ)		! Get a clean register window
d3884 1
a3884 1
	ld	[%sp + CC64FSZ + STKB + TF_SIZE], %l7
d3887 1
a3887 1
	ldub	[%sp + CC64FSZ + STKB + TF_OLDPIL], %l3	! restore old %pil
d3891 1
a3891 1
	CHKPT(%o1,%o2,5)
d3927 1
a3927 1
 *	[%sp + CC64FSZ + STKB] => trap frame
d3944 2
a3945 2
	ldx	[%sp + CC64FSZ + STKB + TF_PC], %g2
	ldx	[%sp + CC64FSZ + STKB + TF_NPC], %g3
d3954 2
a3955 2
	ldx	[%fp + CC64FSZ + STKB + TF_PC], %o3
	ldx	[%fp + CC64FSZ + STKB + TF_NPC], %o4
d3970 1
a3970 1
	ldx	[%sp + CC64FSZ + STKB + TF_TSTATE], %g2
d4001 1
a4001 1
	ldx	[%sp + CC64FSZ + STKB + TF_TSTATE], %g1
d4007 1
a4007 1
	 LDPTR	[%o1 + %lo(CURPROC)], %o0
d4021 7
a4027 7
	ldx	[%sp + CC64FSZ + STKB + TF_G + (1*8)], %g1
	ldx	[%sp + CC64FSZ + STKB + TF_G + (2*8)], %g2
	ldx	[%sp + CC64FSZ + STKB + TF_G + (3*8)], %g3
	ldx	[%sp + CC64FSZ + STKB + TF_G + (4*8)], %g4
	ldx	[%sp + CC64FSZ + STKB + TF_G + (5*8)], %g5
	ldx	[%sp + CC64FSZ + STKB + TF_G + (6*8)], %g6
	ldx	[%sp + CC64FSZ + STKB + TF_G + (7*8)], %g7
d4033 8
a4040 8
	ldx	[%sp + CC64FSZ + STKB + TF_O + (0*8)], %i0
	ldx	[%sp + CC64FSZ + STKB + TF_O + (1*8)], %i1
	ldx	[%sp + CC64FSZ + STKB + TF_O + (2*8)], %i2
	ldx	[%sp + CC64FSZ + STKB + TF_O + (3*8)], %i3
	ldx	[%sp + CC64FSZ + STKB + TF_O + (4*8)], %i4
	ldx	[%sp + CC64FSZ + STKB + TF_O + (5*8)], %i5
	ldx	[%sp + CC64FSZ + STKB + TF_O + (6*8)], %i6
	ldx	[%sp + CC64FSZ + STKB + TF_O + (7*8)], %i7
d4042 2
a4043 2
	ld	[%sp + CC64FSZ + STKB + TF_Y], %g4
	ldx	[%sp + CC64FSZ + STKB + TF_TSTATE], %g1		! load new values
d4045 2
a4046 2
	ldx	[%sp + CC64FSZ + STKB + TF_PC], %g2
	ldx	[%sp + CC64FSZ + STKB + TF_NPC], %g3
d4056 1
a4056 1
	ldub	[%sp + CC64FSZ + STKB + TF_PIL], %g5		! restore %pil
d4062 1
a4062 1
	CHKPT(%g4, %g7, 6)
d4081 1
a4081 1
	CHKPT(%g1,%g2,7)
d4083 1
a4083 1
	CHKPT(%g1,%g2,0)			! Clear this out
a4088 43
#ifdef TRAPTRACE
	set	trap_trace, %g2
	lduw	[%g2+TRACEDIS], %g4
	brnz,pn	%g4, 1f
	 nop
	lduw	[%g2+TRACEPTR], %g3
	rdpr	%tl, %g4
	set	CURPROC, %g6
	sllx	%g4, 13, %g4
	LDPTR	[%g6], %g6
	clr	%g6		! DISABLE PID
	mov	%g0, %g5
	brz,pn	%g6, 2f
	 andncc	%g3, (TRACESIZ-1), %g0
!	ldsw	[%g6+P_PID], %g5	! Load PID
2:

	set	CPCB, %g6	! Load up nsaved
	LDPTR	[%g6], %g6
	ldub	[%g6 + PCB_NSAVED], %g6
	sllx	%g6, 9, %g6
	or	%g6, %g4, %g4

	movnz	%icc, %g0, %g3	! Wrap if needed
	rdpr	%tstate, %g6
	rdpr	%tpc, %g7
	sth	%g4, [%g2+%g3]
	inc	2, %g3
	sth	%g5, [%g2+%g3]
	inc	2, %g3
	stw	%g6, [%g2+%g3]
	inc	4, %g3
	stw	%sp, [%g2+%g3]
	inc	4, %g3
	stw	%g7, [%g2+%g3]
	inc	4, %g3
	mov	TLB_TAG_ACCESS, %g7
	ldxa	[%g7] ASI_DMMU, %g7
	stw	%g7, [%g2+%g3]
	inc	4, %g3
	stw	%g3, [%g2+TRACEPTR]
1:
#endif	/* TRAPTRACE */
d4122 1
a4122 1
	CHKPT(%g4,%g7,8)
d4125 1
a4125 1
	LDPTR	[%g4 + %lo(CPCB)], %g4
d4178 1
a4178 1
	LDPTR	[%g6 + %lo(CPCB)], %g6
d4181 1
a4181 1
	CHKPT(%g4,%g7,9)
d4282 1
a4282 1
	LDPTR	[%g5 + %lo(CPCB)], %g5
d4310 1
a4310 1
	CHKPT(%g4,%g7,0xa)
d4315 1
a4315 1
	ldx	[%g6 + CC64FSZ + STKB + TF_L + (0*8)], %g5! DEBUG -- get proper value for %l0
d4344 1
a4344 1
	LDPTR	[%g6 + %lo(CPCB)], %g6
d4360 1
a4360 1
	CHKPT(%g4,%g7,0xb)
d4369 1
a4369 46
	CHKPT(%g4,%g7,0xd)
#ifdef TRAPTRACE
	set	trap_trace, %g2
	lduw	[%g2+TRACEDIS], %g4
	brnz,pn	%g4, 1f
	 nop
	lduw	[%g2+TRACEPTR], %g3
	rdpr	%tl, %g4
	mov	1, %g5
	set	CURPROC, %g6
	sllx	%g4, 13, %g4
	LDPTR	[%g6], %g6
!	clr	%g6		! DISABLE PID
	or	%g4, %g5, %g4
	mov	%g0, %g5
	brz,pn	%g6, 2f
	 andncc	%g3, (TRACESIZ-1), %g0
!	ldsw	[%g6+P_PID], %g5	! Load PID
2:

	set	CPCB, %g6	! Load up nsaved
	LDPTR	[%g6], %g6
	ldub	[%g6 + PCB_NSAVED], %g6
	sllx	%g6, 9, %g6
	or	%g6, %g4, %g4

	movnz	%icc, %g0, %g3	! Wrap if needed
	rdpr	%tstate, %g6
	rdpr	%tpc, %g7
	sth	%g4, [%g2+%g3]
	inc	2, %g3
	sth	%g5, [%g2+%g3]
	inc	2, %g3
	stw	%g6, [%g2+%g3]
	inc	4, %g3
	stw	%sp, [%g2+%g3]
	inc	4, %g3
	stw	%g7, [%g2+%g3]
	inc	4, %g3
	mov	TLB_TAG_ACCESS, %g7
	ldxa	[%g7] ASI_DMMU, %g7
	stw	%g7, [%g2+%g3]
	inc	4, %g3
	stw	%g3, [%g2+TRACEPTR]
1:
#endif	/* TRAPTRACE */
d4378 1
a4378 1
	LDPTR	[%g5 + %lo(CPCB)], %g5
d4523 1
a4523 1
	STPTR	%l4, [%l3 + %lo(_C_LABEL(esym))]
d4532 1
a4532 1
	 STPTR	%l4, [%l3 + %lo(_C_LABEL(ssym))]
d4548 1
a4548 1
	STPTR	%l4, [%l3 + %lo(_C_LABEL(esym))]
d4556 1
a4556 1
	STPTR	%l4, [%l3 + %lo(_C_LABEL(ssym))]
d4565 1
a4565 1
	STPTR	%o4, [%o5]	! It's initialized data, I hope
d4676 1
a4676 1
	LDPTR	[%l1], %l1
d4678 1
a4678 1
	LDPTR	[%l4], %l4
d4943 1
a4943 1
	LDPTR	[%l1 + %lo(_C_LABEL(cpus))], %l1
d4989 1
a4989 1
	LDPTR	[%l0 + %lo(CPUINFO_VA+CI_INITSTACK)], %l0
d5003 1
a5003 1
	LDPTR	[%l0], %l0
d5017 1
a5017 1
	LDPTR	[%l0], %l0
d5058 1
a5058 1
	LDPTR	[%l0 + %lo(CPUINFO_VA+CI_SPINUP)], %o1
d5089 1
a5089 1
	 LDPTR	[%o4+%lo(romp)], %o4		! v9 stack, just load the addr and callit
a5105 3
#if defined(TRAPTRACE)
	 wrpr	%g0, PSTATE_PROM, %pstate
#else	/* defined(TRAPTRACE) */
a5106 1
#endif	/* defined(TRAPTRACE) */
d5641 1
a5641 1
	LDPTR	[%o4 + %lo(CPCB)], %o4	! catch faults
d5644 1
a5644 1
	STPTR	%o5, [%o4 + PCB_ONFAULT]
d5688 1
a5688 1
	LDPTR	[%o4 + %lo(CPCB)], %o4	! catch faults
d5691 1
a5691 1
	STPTR	%o5, [%o4 + PCB_ONFAULT]
d5709 1
a5709 1
	 STPTR	%o1, [%o3]		!		*lencopied = len;
d5712 1
a5712 1
	 STPTR	%g0, [%o4 + PCB_ONFAULT]! return (error);
d5758 1
a5758 1
	 STPTR	%o1, [%o3]		!		*lencopied = len;
d5802 1
a5802 1
	LDPTR	[%o3 + %lo(CPCB)], %o3
d5806 1
a5806 1
	STPTR	%o4, [%o3 + PCB_ONFAULT]
d5836 1
a5836 1
	 EMPTY
d5969 1
a5969 1
	LDPTR	[%o3 + %lo(CPCB)], %o3
d5971 1
a5971 1
	STPTR	%g0, [%o3 + PCB_ONFAULT]
d6011 1
a6011 1
	LDPTR	[%o3 + %lo(CPCB)], %o3
d6015 1
a6015 1
	STPTR	%o4, [%o3 + PCB_ONFAULT]
d6027 1
a6027 1
	 EMPTY
d6047 1
a6047 1
	 EMPTY
d6179 1
a6179 1
	LDPTR	[%o3 + %lo(CPCB)], %o3
d6181 1
a6181 1
	STPTR	%g0, [%o3 + PCB_ONFAULT]
d6194 2
a6195 2
	LDPTR	[%o3 + %lo(CPCB)], %o3
	STPTR	%g0, [%o3 + PCB_ONFAULT]
d6307 1
a6307 1
	STPTR	%l1, [%l6 + %lo(CPCB)]	! cpcb = &idle_u
d6321 1
a6321 1
	SET_SP_REDZONE(%l6, %l5)
d6352 2
a6353 2
	INCR(_C_LABEL(nswitchexit))		! nswitchexit++;
	INCR(_C_LABEL(uvmexp)+V_SWTCH)		! cnt.v_switch++;
d6360 1
a6360 1
	LDPTR	[%l6 + %lo(CPCB)], %l5
d6382 1
a6382 1
	 STPTR	%g0, [%l7 + %lo(CURPROC)] ! curproc = NULL;
d6516 1
a6516 1
	LDPTR	[%l6 + %lo(CPCB)], %l5
d6519 1
a6519 1
	LDPTR	[%l7 + %lo(CURPROC)], %l4	! lastproc = curproc;
d6522 1
a6522 1
	STPTR	%g0, [%l7 + %lo(CURPROC)]	! curproc = NULL;
d6554 1
a6554 1
	 EMPTY
d6579 1
a6579 1
	sll	%o4, PTRSHFT+1, %o0
d6581 1
a6581 1
	LDPTR	[%o5], %l3		! p = q->ph_link;
d6584 4
a6587 4
	 EMPTY
	LDPTR	[%l3], %o0		! tmp0 = p->p_forw;
	STPTR	%o0, [%o5]		! q->ph_link = tmp0;
	STPTR	%o5, [%o0 + PTRSZ]	! tmp0->p_back = q;
d6590 1
a6590 1
	 EMPTY
d6614 1
a6614 1
	LDPTR	[%l3 + P_WCHAN], %o0	! if (p->p_wchan)
d6616 1
a6616 1
	 EMPTY
d6620 1
a6620 1
	 EMPTY
d6638 2
a6639 2
	LDPTR	[%l3 + P_ADDR], %l1		! newpcb = p->p_addr;
	STPTR	%g0, [%l3 + PTRSZ]		! p->p_back = NULL;
d6647 1
a6647 1
	 STPTR	%l4, [%l7 + %lo(CURPROC)]	! restore old proc so we can save it
d6680 1
a6680 1
	INCR(_C_LABEL(nswitchdiff))	! clobbers %o0,%o1,%o2
d6710 2
a6711 2
	STPTR	%l3, [%l7 + %lo(CURPROC)]	! curproc = p;
	STPTR	%l1, [%l6 + %lo(CPCB)]	! cpcb = newpcb;
d6768 2
a6769 2
	SET_SP_REDZONE(%o0, %o1)
	CHECK_SP_REDZONE(%o0, %o1)
d6779 1
a6779 1
	LDPTR	[%l3 + P_VMSPACE], %o3	! vm = p->p_vmspace;
d6782 1
a6782 1
	LDPTR	[%o3 + VM_PMAP], %o2		! if (vm->vm_pmap.pm_ctx != NULL)
a6839 43
#ifdef TRAPTRACE
	set	trap_trace, %o2
	lduw	[%o2+TRACEDIS], %o4
	brnz,pn	%o4, 1f
	 nop
	lduw	[%o2+TRACEPTR], %o3
	rdpr	%tl, %o4
	mov	4, %o5
	set	CURPROC, %o0
	sllx	%o4, 13, %o4
	LDPTR	[%o0], %o0
!	clr	%o0		! DISABLE PID
	or	%o4, %o5, %o4
	mov	%g0, %o5
	brz,pn	%o0, 2f
	 andncc	%o3, (TRACESIZ-1), %g0
!	ldsw	[%o0+P_PID], %o5	!  Load PID
2:
	movnz	%icc, %g0, %o3	! Wrap if needed

	set	CPCB, %o0	! Load up nsaved
	LDPTR	[%o0], %o0
	ldub	[%o0 + PCB_NSAVED], %o0
	sllx	%o0, 9, %o1
	or	%o1, %o4, %o4

	sth	%o4, [%o2+%o3]
	inc	2, %o3
	sth	%o5, [%o2+%o3]
	inc	2, %o3
	stw	%o0, [%o2+%o3]
	inc	4, %o3
	stw	%sp, [%o2+%o3]
	inc	4, %o3
	stw	%o7, [%o2+%o3]
	inc	4, %o3
	mov	TLB_TAG_ACCESS, %o4
	ldxa	[%o4] ASI_DMMU, %o4
	stw	%o4, [%o2+%o3]
	inc	4, %o3
	stw	%o3, [%o2+TRACEPTR]
1:
#endif	/* TRAPTRACE */
d6854 1
a6854 1
	LDPTR	[%o3], %o3
d6946 2
a6947 2
	ldx	[%sp + CC64FSZ + STKB + TF_TSTATE], %g1
	ldx	[%sp + CC64FSZ + STKB + TF_NPC], %g2	! pc = tf->tf_npc from execve/fork
d6951 1
a6951 1
	stx	%g3, [%sp + CC64FSZ + STKB + TF_NPC]
d6953 2
a6954 2
	stx	%g2, [%sp + CC64FSZ + STKB + TF_PC]
	stx	%g1, [%sp + CC64FSZ + STKB + TF_TSTATE]
d6957 1
a6957 1
	ldx	[%sp + CC64FSZ + STKB + TF_NPC], %g2	! pc = tf->tf_npc from execve/fork
d6961 1
a6961 1
	stx	%g3, [%sp + CC64FSZ + STKB + TF_NPC]
d6963 2
a6964 2
	stx	%g2, [%sp + CC64FSZ + STKB + TF_PC]
	stx	%g1, [%sp + CC64FSZ + STKB + TF_TSTATE]
d6967 1
a6967 1
!	set	panicstack-CC64FSZ-STKB, %o0! DEBUG
d6971 1
a6971 1
	ldx	[%fp + CC64FSZ + STKB + TF_O + ( 6*8)], %o2
d6973 1
a6973 1
	add	%fp, CC64FSZ + STKB, %o3
d6996 1
a6996 1
	CHKPT(%o3,%o4,0x35)
d7001 1
a7001 1
	STPTR	%g0, [%o2 + PCB_ONFAULT]! error in r/w, clear pcb_onfault
d7013 1
a7013 1
	STPTR	%g0, [%o2 + PCB_ONFAULT]! error in r/w, clear pcb_onfault
d7040 1
a7040 1
	LDPTR	[%o2 + %lo(CPCB)], %o2	! cpcb->pcb_onfault = Lfserr;
d7042 1
a7042 1
	STPTR	%o5, [%o2 + PCB_ONFAULT]
d7047 1
a7047 1
	DLFLUSH(%o0,%o5)		!	flush cache line
d7073 1
a7073 1
	DLFLUSH2(%o5)			!	flush cache line again
d7076 1
a7076 1
	STPTR	%g0, [%o2 + PCB_ONFAULT]
d7084 1
a7084 1
	STPTR	%g0, [%o2 + PCB_ONFAULT]! error in r/w, clear pcb_onfault
d7104 1
a7104 1
	LDPTR	[%o2 + %lo(CPCB)], %o2	! cpcb->pcb_onfault = Lfserr;
d7106 1
a7106 1
	STPTR	%o5, [%o2 + PCB_ONFAULT]
d7131 1
a7131 1
	STPTR	%g0, [%o2 + PCB_ONFAULT]
d7191 1
a7191 1
	LDPTR	[%o2 + %lo(_C_LABEL(vmmap))], %o2
d7202 1
a7202 1
	add	%sp, (CC64FSZ+STKB+BLOCK_SIZE-1), %l0	! Calculate pointer to fpstate
d7245 2
a7246 2
	LDPTR	[%l1 + %lo(FPPROC)], %l2		! Load fpproc
	add	%sp, (CC64FSZ+STKB+BLOCK_SIZE-1), %l0	! Calculate pointer to fpstate
d7249 1
a7249 1
	LDPTR	[%l2 + P_FPSTATE], %l3
d7253 1
a7253 1
	 set	EINTSTACK-STKB, %l4			! Are we on intr stack?
d7256 1
a7256 1
	 set	INTSTACK-STKB, %l4
d7265 1
a7265 1
	LDPTR	[%l4 + %lo(CURPROC)], %l5
d7270 1
a7270 1
	LDPTR	[%l5 + P_FPSTATE], %l6			! Save old fpstate
d7272 2
a7273 2
	STPTR	%l0, [%l5 + P_FPSTATE]			! Insert new fpstate
	STPTR	%l5, [%l1 + %lo(FPPROC)]		! Set new fpproc
d7283 1
a7283 1
	LDPTR	[%o4 + %lo(FPPROC)], %o4
a7339 19
#ifdef PARANOID
	!!
	!! Use phys accesses to verify page is clear
	!!
	set	NBPG, %o4
1:
	DLFLUSH(%o0,%o2)
	ldxa	[%o0] ASI_PHYS_CACHED, %o1
	DLFLUSH2(%o2)
	dec	8, %o4
	tst	%o1
	tnz	%icc, 1
	brnz,pt	%o4, 1b
	 inc	8, %o0

	sethi	%hi(paginuse), %o4		! Prevent this from nesting
	stw	%g0, [%o4 + %lo(paginuse)]

#endif	/* PARANOID */
d7357 1
a7357 1
	LDPTR	[%l1 + %lo(FPPROC)], %l7
d7360 1
a7360 1
	LDPTR	[%l5 + P_FPSTATE], %l7
d7364 2
a7365 2
	STPTR	%g0, [%l1 + %lo(FPPROC)]		! Clear fpproc
	STPTR	%l6, [%l5 + P_FPSTATE]			! Restore old fpstate
d7454 1
a7454 1
	LDPTR	[%o2 + %lo(_C_LABEL(vmmap))], %o2
d7465 1
a7465 1
	add	%sp, (CC64FSZ+STKB+BLOCK_SIZE-1), %l0	! Calculate pointer to fpstate
d7509 2
a7510 2
	LDPTR	[%l1 + %lo(FPPROC)], %l2		! Load fpproc
	add	%sp, (CC64FSZ+STKB+BLOCK_SIZE-1), %l0	! Calculate pointer to fpstate
d7513 1
a7513 1
	LDPTR	[%l2 + P_FPSTATE], %l3
d7517 1
a7517 1
	 set	EINTSTACK-STKB, %l4			! Are we on intr stack?
d7520 1
a7520 1
	 set	INTSTACK-STKB, %l4
d7529 1
a7529 1
	LDPTR	[%l4 + %lo(CURPROC)], %l5
d7534 1
a7534 1
	LDPTR	[%l5 + P_FPSTATE], %l6			! Save old fpstate
d7536 2
a7537 2
	STPTR	%l0, [%l5 + P_FPSTATE]			! Insert new fpstate
	STPTR	%l5, [%l1 + %lo(FPPROC)]		! Set new fpproc
d7547 1
a7547 1
	LDPTR	[%o4 + %lo(FPPROC)], %o4
a7648 29
#ifdef PARANOID
	!!
	!! Use phys accesses to verify copy
	!!
	sethi	%hi(0x80000000), %o4		! Setup TTE:
	sllx	%o4, 32, %o4			!  V = 1
	or	%o4, TTE_CP|TTE_P|TTE_W|TTE_L, %o4	!  CP=1|P=1|W=1|L=1
	andn	%o1, %o4, %o0			! Clear out TTE to get PADDR
	andn	%o1, %o4, %o1			! Clear out TTE to get PADDR

	set	NBPG, %o3

1:
	DLFLUSH(%o0,%o2)
	ldxa	[%o0] ASI_PHYS_CACHED, %o4
	DLFLUSH2(%o2)
	DLFLUSH(%o1,%o2)
	ldxa	[%o1] ASI_PHYS_CACHED, %o5
	DLFLUSH2(%o2)
	dec	8, %o3
	cmp	%o4, %o5
	tne	%icc, 1
	inc	8, %o0
	brnz,pt	%o4, 1b
	 inc	8, %o1

	sethi	%hi(paginuse), %o4		! Prevent this from nesting
	stw	%g0, [%o4 + %lo(paginuse)]
#endif	/* PARANOID */	/* PARANOID */
d7666 1
a7666 1
	LDPTR	[%l1 + %lo(FPPROC)], %l7
d7669 1
a7669 1
	LDPTR	[%l5 + P_FPSTATE], %l7
d7673 2
a7674 2
	STPTR	%g0, [%l1 + %lo(FPPROC)]		! Clear fpproc
	STPTR	%l6, [%l5 + P_FPSTATE]			! Save old fpstate
d7695 1
a7695 1
	DLFLUSH(%o0,%g1)
d7715 1
a7715 1
	DLFLUSH(%o0,%g1)
d7720 1
a7720 1
	DLFLUSH(%o1,%g1)
d7751 1
a7751 1
	DLFLUSH(%o2,%o3)
d7753 1
a7753 1
	DLFLUSH2(%o3)
d7760 1
a7760 1
	DLFLUSH(%o2,%o3)
d7762 1
a7762 1
	DLFLUSH2(%o3)
d7769 1
a7769 1
	DLFLUSH(%o2,%o3)
d7771 1
a7771 1
	DLFLUSH2(%o3)
d7784 1
a7784 1
	DLFLUSH(%o2,%o3)
d7786 1
a7786 1
	DLFLUSH2(%o3)
d7852 1
a7852 1
	DLFLUSH(%o4,%g1)
d7854 1
a7854 1
	DLFLUSH2(%g1)
d7862 1
a7862 1
	DLFLUSH(%o4, %o5)
d7871 1
a7871 1
	DLFLUSH(%o4,%g1)
d7873 1
a7873 1
	DLFLUSH2(%g1)
d7881 1
a7881 1
	DLFLUSH(%o4, %o4)
d7890 1
a7890 10
	DLFLUSH(%o4, %o4)
#ifdef PARANOID
	!! Try pseg_get to verify we did this right
	mov	%o7, %o4
	call	pseg_get
	 mov	%o2, %o5
	cmp	%o0, %o5
	tne	1
	mov	%o4, %o7
#endif	/* PARANOID */
d7952 1
a7952 1
	DLFLUSH(%o4,%o3)
d7954 1
a7954 1
	DLFLUSH2(%o3)
d7962 1
a7962 1
	DLFLUSH(%o4, %o5)
d7971 1
a7971 1
	DLFLUSH(%o4,%o3)
d7973 1
a7973 1
	DLFLUSH2(%o3)
d7981 1
a7981 1
	DLFLUSH(%o4, %o4)
d8077 1
a8077 1
	 EMPTY
d8563 1
a8563 1
	ENABLE_FPU(0)
d8567 2
a8568 2
	LDPTR	[%l1 + %lo(FPPROC)], %l2		! Load fpproc
	add	%sp, (CC64FSZ+STKB+BLOCK_SIZE-1), %l0	! Calculate pointer to fpstate
d8571 1
a8571 1
	LDPTR	[%l2 + P_FPSTATE], %l3
d8575 1
a8575 1
	 set	EINTSTACK-STKB, %l4			! Are we on intr stack?
d8578 1
a8578 1
	 set	INTSTACK-STKB, %l4
d8587 1
a8587 1
	LDPTR	[%l4 + %lo(CURPROC)], %l5
d8591 3
a8593 3
	LDPTR	[%l5 + P_FPSTATE], %l6			! Save old fpstate
	STPTR	%l0, [%l5 + P_FPSTATE]			! Insert new fpstate
	STPTR	%l5, [%l1 + %lo(FPPROC)]		! Set new fpproc
d9672 1
a9672 1
	LDPTR	[%l1 + %lo(FPPROC)], %l7
d9675 1
a9675 1
	LDPTR	[%l5 + P_FPSTATE], %l7
d9680 1
a9680 1
	STPTR	%l2, [%l1 + %lo(FPPROC)]		! Restore old fproc
d9682 1
a9682 1
	 STPTR	%l6, [%l5 + P_FPSTATE]			! Restore old fpstate
d9832 1
a9832 1
	ENABLE_FPU(0)
d9840 2
a9841 2
	LDPTR	[%l1 + %lo(FPPROC)], %l2		! Load fpproc
	add	%sp, (CC64FSZ+STKB+BLOCK_SIZE-1), %l0	! Calculate pointer to fpstate
d9844 1
a9844 1
	LDPTR	[%l2 + P_FPSTATE], %l3
d9848 1
a9848 1
	 set	EINTSTACK-STKB, %l4			! Are we on intr stack?
d9851 1
a9851 1
	 set	INTSTACK-STKB, %l4
d9860 1
a9860 1
	LDPTR	[%l4 + %lo(CURPROC)], %l5
d9865 1
a9865 1
	LDPTR	[%l5 + P_FPSTATE], %l6			! Save old fpstate
d9867 2
a9868 2
	STPTR	%l0, [%l5 + P_FPSTATE]			! Insert new fpstate
	STPTR	%l5, [%l1 + %lo(FPPROC)]		! Set new fpproc
d9919 1
a9919 1
	LDPTR	[%l1 + %lo(FPPROC)], %l7
d9922 1
a9922 1
	LDPTR	[%l5 + P_FPSTATE], %l7
d9926 2
a9927 2
	STPTR	%g0, [%l1 + %lo(FPPROC)]		! Clear fpproc
	STPTR	%l6, [%l5 + P_FPSTATE]			! Restore old fpstate
d9963 1
a9963 1
	LDPTR	[%o5 + %lo(CPCB)], %o5
d9965 1
a9965 1
	LDPTR	[%o5 + PCB_ONFAULT], %g1! save current onfault handler
d9967 1
a9967 1
	STPTR	%o3, [%o5 + PCB_ONFAULT]
d9980 1
a9980 1
	 EMPTY
d9990 1
a9990 1
	STPTR	%g1, [%o5 + PCB_ONFAULT]! restore fault handler
d10003 1
a10003 1
	 EMPTY
d10024 1
a10024 1
	STPTR	%g1, [%o5 + PCB_ONFAULT]! restore fault handler
d10126 1
a10126 1
	STPTR	%g1, [%o5 + PCB_ONFAULT]! restore fault handler
d10139 1
a10139 1
	STPTR	%g1, [%o5 + PCB_ONFAULT]! restore fault handler
d10148 1
a10148 1
	STPTR	%g1, [%o5 + PCB_ONFAULT]! restore fault handler
d10173 1
a10173 1
	STPTR	%g1, [%o5 + PCB_ONFAULT]! restore fault handler
d10201 1
a10201 1
	 EMPTY
a10671 1
#ifdef INTR_INTERLOCK
d10673 1
a10673 2
#endif	/* INTR_INTERLOCK */
	 sll	%o1, PTRSHFT+3, %o5	! Find start of table for this IPL
d10676 2
a10677 3
#ifdef INTRLIST
	LDPTR	[%o3], %o5		! Load list head
	STPTR	%o5, [%o2+IH_PEND]	! Link our intrhand node in
d10679 1
a10679 1
	CASPTR	[%o3] ASI_N, %o5, %o4
a10682 22
#else	/* INTRLIST */	/* INTRLIST */
#if 1
	DLFLUSH(%o3, %o5)
	mov	%o2, %o5
	CASPTR	[%o3] ASI_N, %g0, %o5	! Try a slot -- MPU safe
	brz,pt	%o5, 4f			! Available?
#else	/* 1 */
	DLFLUSH(%o3, %o5)
	LDPTR	[%o3], %o5		! Try a slog
	brz,a	%o5, 4f			! Available?
	 STPTR	%o2, [%o3]		! Grab it
#endif	/* 1 */
	 dec	%o4
	brgz,pt	%o4, 2b
	 inc	PTRSZ, %o3		! Next slot

	!! If we get here we have a problem.
	!! There were no available slots and the interrupt was lost.
	!! We'll resort to polling in this case.
4:
	 DLFLUSH(%o3, %o3)		! Prevent D$ pollution
#endif /* INTRLIST */	/* INTRLIST */
d10907 1
a10907 1
	CHKPT(%o4,%o3,0x28)
d10940 1
a10940 1
	CHKPT(%o4,%o3,0x36)
d10944 1
a10944 1
	CHKPT(%o4,%o3,0x29)
d10963 1
a10963 1
	CHKPT(%o4,%o3,0x30)
d10991 1
a10991 1
	POINTER	0
d10994 1
a10994 1
	POINTER	0
d10998 1
a10998 1
	POINTER	_C_LABEL(u0)		! KVA of proc0 uarea
@


1.32
log
@nuke curproc common (yes this will need revisiting in smp land, but what
doesn't).
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.31 2003/03/21 22:59:10 jason Exp $	*/
d98 1
a98 1
#else
d102 1
a102 1
#endif
d120 1
a120 1
#endif
a125 1
#ifdef _LP64
a145 19
#else
#define	BASEREG		%g0
#define LNGSZ		4
#define LNGSHFT		2
#define PTRSZ		4
#define PTRSHFT		2
#define POINTER		.word
/* Instructions to load/store pointers & long ints */
#define LDLNG		ldsw
#define LDULNG		lduw
#define STLNG		stw
#define STULNG		stw
#define LDPTR		lduw
#define LDPTRA		lduwa
#define STPTR		stw
#define STPTRA		stwa
#define	CASPTR		casa
#define STKB	0
#endif
d155 1
a155 1
#else
d157 1
a157 1
#endif
d166 1
a166 1
#else
d168 1
a168 1
#endif
d187 1
a187 1
#else
d190 1
a190 18
#endif


/*
 * Combine 2 regs -- used to convert 64-bit ILP32
 * values to LP64.
 */
#define	COMBINE(r1, r2, d)	\
	sllx	r1, 32, d;	\
	or	d, r2, d

/*
 * Split 64-bit value in 1 reg into high and low halves.
 * Used for ILP32 return values.
 */
#define	SPLIT(r0, r1)		\
	srl	r0, 0, r1;	\
	srlx	r0, 32, r0
a260 1
#ifdef _LP64
a261 3
#else
#define	STACKFRAME(size)	TO_STACK32(size)
#endif
d314 1
a314 1
#else
d316 1
a316 1
#endif
d364 1
a364 1
#endif
d373 1
a373 1
#endif
d444 1
a444 1
#endif
d448 1
a448 1
#else
d451 1
a451 1
#endif
d458 1
a458 1
#else
d466 1
a466 1
#else
d468 1
a468 1
#endif
d472 2
a473 2
#endif
#else
d481 1
a481 1
#endif
d485 1
a485 1
#else
d488 1
a488 1
#endif
d495 1
a495 1
#else
d503 1
a503 1
#else
d505 1
a505 1
#endif
d508 2
a509 2
#endif
#endif
d525 1
a525 1
#else
d527 1
a527 1
#endif
d536 1
a536 1
#else
d539 1
a539 1
#endif
d544 1
a544 1
#else
d546 1
a546 1
#endif
d554 1
a554 1
#else
d556 1
a556 1
#endif
d736 1
a736 1
#else
d738 1
a738 1
#endif
d765 2
a766 2
#endif
#endif
d815 1
a815 1
#endif
d833 1
a833 1
#endif
d846 1
a846 1
#endif
d859 1
a859 1
#endif
d873 1
a873 1
#endif
d984 1
a984 1
#endif
d1001 1
a1001 1
#endif
d1051 1
a1051 1
#endif
d1069 1
a1069 1
#endif
d1082 1
a1082 1
#endif
d1095 1
a1095 1
#endif
d1314 1
a1314 1
#else
d1317 1
a1317 1
#endif
d1377 1
a1377 1
#else
d1382 1
a1382 1
#endif
d1550 1
a1550 1
#endif
a1645 1
#ifdef _LP64
a1812 135
#else
#define	TRAP_SETUP(stackspace) \
	sethi	%hi(USPACE), %g7; \
	sethi	%hi(CPCB), %g6; \
	or	%g7, %lo(USPACE), %g7; \
	sethi	%hi((stackspace)), %g5; \
	lduw	[%g6 + %lo(CPCB)], %g6; \
	or	%g5, %lo((stackspace)), %g5; \
	add	%g6, %g7, %g6; \
	rdpr	%wstate, %g7;					/* Find if we're from user mode */ \
	\
	sra	%g5, 0, %g5;					/* Sign extend the damn thing */ \
	subcc	%g7, WSTATE_KERN, %g7;				/* Compare & leave in register */ \
	movz	%icc, %sp, %g6;					/* Select old (kernel) stack or base of kernel stack */ \
	srl	%g6, 0, %g6;					/* truncate at 32-bits */ \
	btst	1, %g6;						/* Fixup 64-bit stack if necessary */ \
	add	%g6, %g5, %g6;					/* Allocate a stack frame */ \
	add	%g6, BIAS, %g5; \
	movne	%icc, %g5, %g6; \
	\
	stx	%g1, [%g6 + CC64FSZ + STKB + TF_FAULT]; \
	stx	%l0, [%g6 + CC64FSZ + STKB + TF_L + (0*8)];		/* Save local registers to trap frame */ \
	stx	%l1, [%g6 + CC64FSZ + STKB + TF_L + (1*8)]; \
	stx	%l2, [%g6 + CC64FSZ + STKB + TF_L + (2*8)]; \
	stx	%l3, [%g6 + CC64FSZ + STKB + TF_L + (3*8)]; \
	stx	%l4, [%g6 + CC64FSZ + STKB + TF_L + (4*8)]; \
	stx	%l5, [%g6 + CC64FSZ + STKB + TF_L + (5*8)]; \
	stx	%l6, [%g6 + CC64FSZ + STKB + TF_L + (6*8)]; \
	\
	stx	%l7, [%g6 + CC64FSZ + STKB + TF_L + (7*8)]; \
	stx	%i0, [%g6 + CC64FSZ + STKB + TF_I + (0*8)];		/* Save in registers to trap frame */ \
	stx	%i1, [%g6 + CC64FSZ + STKB + TF_I + (1*8)]; \
	stx	%i2, [%g6 + CC64FSZ + STKB + TF_I + (2*8)]; \
	stx	%i3, [%g6 + CC64FSZ + STKB + TF_I + (3*8)]; \
	stx	%i4, [%g6 + CC64FSZ + STKB + TF_I + (4*8)]; \
	stx	%i5, [%g6 + CC64FSZ + STKB + TF_I + (5*8)]; \
	stx	%i6, [%g6 + CC64FSZ + STKB + TF_I + (6*8)]; \
	\
	stx	%i7, [%g6 + CC64FSZ + STKB + TF_I + (7*8)]; \
	save	%g6, 0, %sp;					/* If we fault we should come right back here */ \
	stx	%i0, [%sp + CC64FSZ + STKB + TF_O + (0*8)];		/* Save out registers to trap frame */ \
	stx	%i1, [%sp + CC64FSZ + STKB + TF_O + (1*8)]; \
	stx	%i2, [%sp + CC64FSZ + STKB + TF_O + (2*8)]; \
	stx	%i3, [%sp + CC64FSZ + STKB + TF_O + (3*8)]; \
	stx	%i4, [%sp + CC64FSZ + STKB + TF_O + (4*8)]; \
	stx	%i5, [%sp + CC64FSZ + STKB + TF_O + (5*8)]; \
	stx	%i6, [%sp + CC64FSZ + STKB + TF_O + (6*8)]; \
	\
	stx	%i7, [%sp + CC64FSZ + STKB + TF_O + (7*8)]; \
/*	rdpr	%wstate, %g7; sub %g7, WSTATE_KERN, %g7; /* DEBUG */ \
	brz,pn	%g7, 1f;					/* If we were in kernel mode start saving globals */ \
	 rdpr	%canrestore, %g5;				/* Fixup register window state registers */ \
	/* came from user mode -- switch to kernel mode stack */ \
	wrpr	%g0, 0, %canrestore; \
	wrpr	%g0, %g5, %otherwin; \
	mov	CTX_PRIMARY, %g7; \
	wrpr	%g0, WSTATE_KERN, %wstate;			/* Enable kernel mode window traps -- now we can trap again */ \
	\
	stxa	%g0, [%g7] ASI_DMMU; 				/* Switch MMU to kernel primary context */ \
	sethi	%hi(KERNBASE), %g5; \
	membar	#Sync;						/* XXXX Should be taken care of by flush */ \
	flush	%g5;						/* Some convenient address that won't trap */ \
1:

/*
 * Interrupt setup is almost exactly like trap setup, but we need to
 * go to the interrupt stack if (a) we came from user mode or (b) we
 * came from kernel mode on the kernel stack.
 *
 * We don't guarantee any registers are preserved during this operation.
 */
#define	INTR_SETUP(stackspace) \
	sethi	%hi(EINTSTACK), %g1; \
	sethi	%hi((stackspace)), %g5; \
	btst	1, %sp; \
	add	%sp, BIAS, %g6; \
	movz	%icc, %sp, %g6; \
	or	%g1, %lo(EINTSTACK), %g1; \
	srl	%g6, 0, %g6;					/* truncate at 32-bits */ \
	set	(EINTSTACK-INTSTACK), %g7; \
	or	%g5, %lo((stackspace)), %g5; \
	sub	%g1, %g6, %g2;					/* Determine if we need to switch to intr stack or not */ \
	dec	%g7;						/* Make it into a mask */ \
	andncc	%g2, %g7, %g0;					/* XXXXXXXXXX This assumes kernel addresses are unique from user addresses */ \
	rdpr	%wstate, %g7;					/* Find if we're from user mode */ \
	sra	%g5, 0, %g5;					/* Sign extend the damn thing */ \
	movnz	%xcc, %g1, %g6;					/* Stay on interrupt stack? */ \
	cmp	%g7, WSTATE_KERN;				/* User or kernel sp? */ \
	movnz	%icc, %g1, %g6;					/* Stay on interrupt stack? */ \
	add	%g6, %g5, %g6;					/* Allocate a stack frame */ \
	\
	stx	%l0, [%g6 + CC64FSZ + STKB + TF_L + (0*8)];		/* Save local registers to trap frame */ \
	stx	%l1, [%g6 + CC64FSZ + STKB + TF_L + (1*8)]; \
	stx	%l2, [%g6 + CC64FSZ + STKB + TF_L + (2*8)]; \
	stx	%l3, [%g6 + CC64FSZ + STKB + TF_L + (3*8)]; \
	stx	%l4, [%g6 + CC64FSZ + STKB + TF_L + (4*8)]; \
	stx	%l5, [%g6 + CC64FSZ + STKB + TF_L + (5*8)]; \
	stx	%l6, [%g6 + CC64FSZ + STKB + TF_L + (6*8)]; \
	stx	%l7, [%g6 + CC64FSZ + STKB + TF_L + (7*8)]; \
	stx	%i0, [%g6 + CC64FSZ + STKB + TF_I + (0*8)];		/* Save in registers to trap frame */ \
	stx	%i1, [%g6 + CC64FSZ + STKB + TF_I + (1*8)]; \
	stx	%i2, [%g6 + CC64FSZ + STKB + TF_I + (2*8)]; \
	stx	%i3, [%g6 + CC64FSZ + STKB + TF_I + (3*8)]; \
	stx	%i4, [%g6 + CC64FSZ + STKB + TF_I + (4*8)]; \
	stx	%i5, [%g6 + CC64FSZ + STKB + TF_I + (5*8)]; \
	stx	%i6, [%g6 + CC64FSZ + STKB + TF_I + (6*8)]; \
	stx	%i7, [%g6 + CC64FSZ + STKB + TF_I + (7*8)]; \
	save	%g6, 0, %sp;					/* If we fault we should come right back here */ \
	stx	%i0, [%sp + CC64FSZ + STKB + TF_O + (0*8)];		/* Save out registers to trap frame */ \
	stx	%i1, [%sp + CC64FSZ + STKB + TF_O + (1*8)]; \
	stx	%i2, [%sp + CC64FSZ + STKB + TF_O + (2*8)]; \
	stx	%i3, [%sp + CC64FSZ + STKB + TF_O + (3*8)]; \
	stx	%i4, [%sp + CC64FSZ + STKB + TF_O + (4*8)]; \
	stx	%i5, [%sp + CC64FSZ + STKB + TF_O + (5*8)]; \
	stx	%i6, [%sp + CC64FSZ + STKB + TF_O + (6*8)]; \
	stx	%i6, [%sp + CC64FSZ + STKB + TF_G + (0*8)];		/* Save fp in clockframe->cf_fp */ \
	rdpr	%wstate, %g7;					/* Find if we're from user mode */ \
	stx	%i7, [%sp + CC64FSZ + STKB + TF_O + (7*8)]; \
	cmp	%g7, WSTATE_KERN;				/* Compare & leave in register */ \
	be,pn	%icc, 1f;					/* If we were in kernel mode start saving globals */ \
	/* came from user mode -- switch to kernel mode stack */ \
	 rdpr	%otherwin, %g5;					/* Has this already been done? */ \
	tst	%g5; tnz %xcc, 1; nop; /* DEBUG -- this should _NEVER_ happen */ \
	brnz,pn	%g5, 1f;					/* Don't set this twice */ \
	 rdpr	%canrestore, %g5;				/* Fixup register window state registers */ \
	wrpr	%g0, 0, %canrestore; \
	mov	CTX_PRIMARY, %g7; \
	wrpr	%g0, %g5, %otherwin; \
	sethi	%hi(KERNBASE), %g5; \
	wrpr	%g0, WSTATE_KERN, %wstate;			/* Enable kernel mode window traps -- now we can trap again */ \
	stxa	%g0, [%g7] ASI_DMMU; 				/* Switch MMU to kernel primary context */ \
	membar	#Sync;						/* XXXX Should be taken care of by flush */ \
	flush	%g5;						/* Some convenient address that won't trap */ \
1:
#endif /* _LP64 */
d1866 1
a1866 1
#endif
d1935 1
a1935 1
#endif
d1958 1
a1958 1
#endif
d1964 1
a1964 1
#endif
d2008 1
a2008 1
#endif
d2037 1
a2037 1
#endif
d2081 1
a2081 1
#endif
d2092 1
a2092 1
#endif
d2148 1
a2148 1
#endif
d2182 1
a2182 1
#endif
d2197 1
a2197 1
#endif
d2224 1
a2224 1
#endif
d2247 1
a2247 1
#else
d2278 1
a2278 1
#endif
d2285 1
a2285 1
#endif
d2297 1
a2297 1
#endif
d2316 1
a2316 1
#else
d2367 2
a2368 2
#endif
#endif
d2376 1
a2376 1
#endif
d2382 1
a2382 1
#endif
d2400 1
a2400 1
#endif
d2450 1
a2450 1
#endif
d2471 1
a2471 1
#endif
d2481 1
a2481 1
#endif
d2495 1
a2495 1
#else
d2499 1
a2499 1
#endif
d2557 2
a2558 2
#endif
#else
d2592 1
a2592 1
#endif
d2601 2
a2602 2
#endif
#endif
d2622 1
a2622 1
#endif
d2646 1
a2646 1
#endif
d2675 1
a2675 1
#endif
d2682 1
a2682 1
#endif
d2700 1
a2700 1
#endif
d2749 1
a2749 1
#endif
d2755 1
a2755 1
#endif
d2781 1
a2781 1
#endif
d2804 1
a2804 1
#endif
d2811 1
a2811 1
#endif
d2840 1
a2840 1
#else
d2845 1
a2845 1
#endif
d2862 1
a2862 1
#endif
d2878 1
a2878 1
#else
d2881 1
a2881 1
#endif
d2901 1
a2901 1
#endif
d2934 1
a2934 1
#endif
d2976 1
a2976 1
#endif
d3005 1
a3005 1
#endif
d3056 1
a3056 1
#endif
d3067 1
a3067 1
#endif
d3099 1
a3099 1
#endif
d3209 1
a3209 1
#endif
d3223 1
a3223 1
#else
d3227 1
a3227 1
#endif
d3229 1
a3229 1
#endif
d3354 1
a3354 1
#endif
d3357 1
a3357 1
#endif
d3420 1
a3420 1
#endif
d3515 1
a3515 1
#endif
d3535 1
a3535 1
#endif
d3564 1
a3564 1
#endif
d3601 1
a3601 1
#endif
d3612 1
a3612 1
#endif
d3618 1
a3618 1
#endif
d3727 1
a3727 1
#endif
d3739 1
a3739 1
#endif
d3758 1
a3758 1
#endif
d3768 1
a3768 1
#endif
d3786 1
a3786 1
#endif
d3790 1
a3790 1
#endif
d3800 1
a3800 1
#endif
d3816 1
a3816 1
#else	/* INTRLIST */
d3839 1
a3839 1
#endif	/* DEBUG */ 
d3861 2
a3862 2
#endif	/* DIAGNOSTIC */
#endif	/* INTRLIST */
d3884 1
a3884 1
#endif	/* DEBUG */
d3901 1
a3901 1
#endif
d3979 1
a3979 1
#endif
d4018 1
a4018 1
#endif
d4133 1
a4133 1
#else /* INTRLIST */
d4179 1
a4179 1
#endif	/* DEBUG */
d4196 1
a4196 1
#endif
d4210 1
a4210 1
#endif	/* DEBUG */
d4229 1
a4229 1
#endif /* INTRLIST */
d4257 1
a4257 1
#endif
d4289 1
a4289 1
#endif /* notyet */
d4325 1
a4325 1
#endif
d4344 1
a4344 1
#endif
d4374 1
a4374 1
#endif
d4386 1
a4386 1
#endif
d4409 1
a4409 1
#endif
d4430 1
a4430 1
#endif
d4435 1
a4435 1
#endif
d4508 1
a4508 1
#endif
d4517 1
a4517 1
#endif
d4520 1
a4520 1
#endif
d4567 1
a4567 1
#endif
d4577 1
a4577 1
#endif
d4596 1
a4596 1
#endif
d4608 1
a4608 1
#endif
d4620 1
a4620 1
#endif
d4664 1
a4664 1
#endif
d4689 1
a4689 1
#endif
d4695 1
a4695 1
#endif
d4708 1
a4708 1
#endif
d4774 1
a4774 1
#endif
d4834 1
a4834 1
#endif
d4840 1
a4840 1
#endif
d4847 1
a4847 1
#endif
d4882 1
a4882 1
#endif /* DDB */
a4885 1
#ifdef _LP64
d4923 1
a4923 48
#else
	save	%sp, -CC64FSZ, %sp
	clr	%l1
	add	%l1, (64*8), %l3
	clr	%l2
1:
	ldxa	[%l1] ASI_DMMU_TLB_TAG, %o2
	membar	#Sync
	srl	%o2, 0, %o3
	mov	%l2, %o1
	srax	%o2, 32, %o2
	ldxa	[%l1] ASI_DMMU_TLB_DATA, %o4
	membar	#Sync
	srl	%o4, 0, %o5
	inc	%l2
	srax	%o4, 32, %o4
	set	2f, %o0
	call	_C_LABEL(db_printf)
	 inc	8, %l1

	ldxa	[%l1] ASI_DMMU_TLB_TAG, %o2
	membar	#Sync
	srl	%o2, 0, %o3
	mov	%l2, %o1
	srax	%o2, 32, %o2
	ldxa	[%l1] ASI_DMMU_TLB_DATA, %o4
	membar	#Sync
	srl	%o4, 0, %o5
	inc	%l2
	srax	%o4, 32, %o4
	set	3f, %o0
	call	_C_LABEL(db_printf)
	 inc	8, %l1

	cmp	%l1, %l3
	bl	1b
	 inc	8, %l0

	ret
	 restore
	.data
2:
	.asciz	"%2d:%08x:%08x %08x:%08x "
3:
	.asciz	"%2d:%08x:%08x %08x:%08x\r\n"
	.text
#endif
#endif
d5023 1
a5023 1
#endif
a5035 1
#ifdef _LP64
a5039 6
#else
	btst	1, %sp
	bz,pt	%icc, 0f
	 nop
	add	%sp, BIAS, %sp
#endif
d5070 1
a5070 1
#endif
d5129 1
a5129 1
#endif
d5184 1
a5184 1
#endif
d5221 1
a5221 1
#else
d5224 1
a5224 1
#endif
d5245 1
a5245 1
#else
d5248 1
a5248 1
#endif
d5273 1
a5273 1
#endif
d5351 1
a5351 1
#else
d5354 1
a5354 1
#endif
d5400 1
a5400 1
#endif
d5436 1
a5436 1
#else
d5438 1
a5438 1
#endif
a5455 1
#ifdef _LP64
a5457 1
#endif
d5505 1
a5505 1
#endif
d5517 1
a5517 1
#endif
d5571 1
a5571 1
#if !defined(_LP64) || defined(TRAPTRACE)
d5573 1
a5573 1
#else
d5575 1
a5575 1
#endif
d5594 1
a5594 1
#endif
a5613 1
#if defined(_LP64) || defined(TRAPTRACE)
a5614 3
#else
	 wrpr	%g0, PSTATE_PROM|PSTATE_IE, %pstate
#endif
d5642 1
a5642 1
#endif
d5664 1
a5664 1
#endif
d5704 1
a5704 1
#endif
d5716 1
a5716 1
#endif
d5729 1
a5729 1
#endif
a5785 3
#ifndef _LP64
	COMBINE(%o0, %o1, %o0)
#endif
a5879 5
#ifndef _LP64
	COMBINE(%o0, %o1, %o0)
	COMBINE(%o2, %o3, %o1)
	mov	%o4, %o2
#endif
d5883 1
a5883 1
#endif
a5923 1
#ifdef _LP64
a6044 1
#endif
d6048 1
a6048 3
#endif

#if !defined(_LP64)
a6049 8
#define SIGCODE_NAME		sigcode
#define ESIGCODE_NAME		esigcode
#define SIGRETURN_NAME		SYS_sigreturn
#define EXIT_NAME		SYS_exit

#include "sigcode32.s"

#endif
d6056 1
a6056 1
#endif
d6071 1
a6071 1
#else
d6073 1
a6073 1
#endif
d6104 1
a6104 1
#endif
d6151 1
a6151 1
#endif
d6194 1
a6194 1
#endif
d6241 1
a6241 1
#endif
d6268 1
a6268 1
#endif
d6476 1
a6476 1
#endif
d6676 1
a6676 1
#endif
d6738 1
a6738 1
#endif
d6754 1
a6754 1
#endif
d6774 1
a6774 1
#endif
a6777 1
#ifdef _LP64
a6778 3
#else
	mov	%o0, %sp		! Maybe this should be a save?
#endif
d6791 1
a6791 1
#endif
d6798 1
a6798 1
#endif
d6850 1
a6850 1
#endif
d6874 1
a6874 1
#endif
d6888 1
a6888 1
#endif
d6896 1
a6896 1
#endif
d6969 1
a6969 1
#endif
d6974 1
a6974 1
#endif
d6980 1
a6980 1
#endif
d7027 1
a7027 1
#else
d7043 1
a7043 1
#endif
d7100 1
a7100 1
#endif
d7104 1
a7104 1
#endif
d7115 1
a7115 1
#endif
d7144 1
a7144 1
#endif
d7177 1
a7177 1
#endif
d7202 1
a7202 1
#endif
d7220 1
a7220 1
#endif
d7234 1
a7234 1
#endif
d7239 1
a7239 1
#endif
d7282 1
a7282 1
#endif
d7308 1
a7308 1
#endif
d7351 1
a7351 1
#endif
d7378 1
a7378 1
#endif
d7391 1
a7391 1
#endif
d7444 1
a7444 1
#endif
d7467 1
a7467 1
#else
d7477 1
a7477 1
#endif
d7507 1
a7507 1
#endif
a7514 3
#ifndef _LP64
	mov	-1, %o1
#endif
a7548 6
#ifndef _LP64
	!! Shuffle the args around into LP64 format
	COMBINE(%o0, %o1, %o0)
	mov	%o2, %o1
	mov	%o3, %o2
#endif
a7552 1
#ifdef _LP64
a7553 3
#else
	set	_C_LABEL(Lfsprobe), %o5
#endif
a7561 4
#ifndef _LP64
	rdpr	%pstate, %g1
	wrpr	%g1, PSTATE_AM, %pstate
#endif
d7582 1
a7582 7
#ifndef _LP64
	SPLIT(%o0, %o1)
#endif
	membar	#Sync
#ifndef _LP64
	wrpr	%g1, 0, %pstate
#endif
a7595 3
#ifndef _LP64
	wrpr	%g1, 0, %pstate
#endif
a7612 7
#ifndef _LP64
	!! Shuffle the args around into LP64 format
	COMBINE(%o0, %o1, %o0)
	mov	%o2, %o1
	mov	%o3, %o2
	COMBINE(%o4, %o5, %o3)
#endif
a7667 5
#ifndef _LP64
#if PADDRT == 8
	COMBINE(%o0, %o1, %o0)
#endif
#endif
d7685 1
a7685 1
#endif
d7723 1
a7723 1
#else	/* NEW_FPSTATE */
d7787 2
a7788 2
#endif	/* NEW_FPSTATE */
#else	/* PMAP_FPSTATE */
d7801 1
a7801 1
#endif	/* PMAP_FPSTATE */
d7811 1
a7811 1
#endif
d7870 1
a7870 1
#endif
d7886 1
a7886 1
#else /* NEW_FPSTATE */
d7894 1
a7894 1
#endif
d7900 2
a7901 2
#endif /* NEW_FPSTATE */
#else /* PMAP_FPSTATE */
d7904 1
a7904 1
#endif /* PMAP_FPSTATE */
d7906 1
a7906 1
#endif /* PMAP_PHYS_PAGE */
d7922 1
a7922 1
#else
d7934 1
a7934 1
#endif
a7953 6
#ifndef _LP64
#if PADDRT == 8
	COMBINE(%o0, %o1, %o0)
	COMBINE(%o2, %o3, %o1)
#endif
#endif
d7972 1
a7972 1
#endif
d8006 1
a8006 1
#else	/* NEW_FPSTATE */
d8070 2
a8071 2
#endif	/* NEW_FPSTATE */
#else	/* PMAP_FPSTATE */
d8084 1
a8084 1
#endif	/* PMAP_FPSTATE */
d8094 1
a8094 1
#endif	/*  DEBUG */
d8208 1
a8208 1
#endif	/* PARANOID */
d8224 1
a8224 1
#else	/* NEW_FPSTATE */
d8232 1
a8232 1
#endif	/* DEBUG */
d8238 2
a8239 2
#endif	/* NEW_FPSTATE */
#else	/* PMAP_FPSTATE */
d8245 1
a8245 1
#endif	/* PMAP_FPSTATE */
d8247 1
a8247 1
#endif	/* PMAP_PHYS_PAGE */
d8270 1
a8270 1
#else
d8286 1
a8286 1
#endif
d8289 1
a8289 1
#endif
d8343 1
a8343 1
#else
d8349 1
a8349 1
#endif
a8375 13
#ifndef _LP64
	btst	1, %sp					! 64-bit mode?
	bnz,pt	%icc, 0f
	 sllx	%o4, 32, %o4				! Put args into 64-bit format

	sllx	%o2, 32, %o2				! Shift to high 32-bits
	sll	%o3, 0, %o3				! Zero extend
	sll	%o5, 0, %o5
	sll	%o1, 0, %o1
	or	%o2, %o3, %o2
	or	%o4, %o5, %o3
0:
#endif
d8385 1
a8385 1
#endif
d8401 1
a8401 1
#endif
a8455 3
#ifndef _LP64
	COMBINE(%o0, %o1, %o0)
#endif
d8459 1
a8459 1
#endif
a8485 9
#ifndef _LP64
	btst	1, %sp					! 64-bit mode?
	bnz,pt	%icc, 0f
	 sllx	%o2, 32, %o2				! Shift to high 32-bits
	sll	%o3, 0, %o3				! Zero extend
	sll	%o1, 0, %o1
	or	%o2, %o3, %o2
0:
#endif
d8495 1
a8495 1
#endif
d8510 1
a8510 1
#endif
d8584 1
a8584 1
#else
d8586 1
a8586 1
#endif
d8603 1
a8603 1
#endif
d8624 1
a8624 1
#endif
d8697 1
a8697 1
#endif
d9056 1
a9056 1
#endif
d9133 1
a9133 1
#else
d9164 1
a9164 1
#endif
d9168 1
a9168 1
#endif
d9353 1
a9353 1
#else
d9390 1
a9390 1
#endif
d9406 1
a9406 1
#endif
d9490 1
a9490 1
#endif
d9587 1
a9587 1
#endif
d9684 1
a9684 1
#endif
d9779 1
a9779 1
#endif
d9872 1
a9872 1
#endif
d9964 1
a9964 1
#endif
d10054 1
a10054 1
#endif
d10230 1
a10230 1
#endif
d10239 1
a10239 1
#else
d10247 1
a10247 1
#endif
d10256 1
a10256 1
#endif
d10259 1
a10259 1
#endif
d10262 1
a10262 1
#endif
d10326 1
a10326 1
#endif	
d10402 1
a10402 1
#else
d10439 1
a10439 1
#endif
a10454 1
#ifdef _LP64
a10457 6
#else
	stw	%i1, [%i0]				! Flush this puppy to RAM
	membar	#StoreLoad
	ld	[%i0], %f0
	fmovsa	%icc, %f0, %f1
#endif
d10486 1
a10486 1
#else
d10494 1
a10494 1
#endif
d10501 3
a10503 3
#endif
#endif
#endif
d10530 1
a10530 1
#endif
d10741 1
a10741 1
#endif
d10977 1
a10977 1
#endif
d11097 1
a11097 1
#endif
d11243 1
a11243 1
#endif
d11255 1
a11255 1
#else	/* INTRLIST */
d11261 1
a11261 1
#else
d11266 1
a11266 1
#endif
d11276 1
a11276 1
#endif /* INTRLIST */
d11578 1
a11578 34
#ifndef _LP64
	/*
	 * Convert to 32-bit stack then call OF_sym2val()
	 */
	ENTRY(_C_LABEL(OF_sym2val32))
	save	%sp, -CC64FSZ, %sp
	btst	7, %i0
	bnz,pn	%icc, 1f
	 add	%sp, BIAS, %o1
	btst	1, %sp
	movnz	%icc, %o1, %sp
	call	_C_LABEL(OF_sym2val)
	 mov	%i0, %o0
1:
	ret
	 restore	%o0, 0, %o0

	/*
	 * Convert to 32-bit stack then call OF_val2sym()
	 */
	ENTRY(_C_LABEL(OF_val2sym32))
	save	%sp, -CC64FSZ, %sp
	btst	7, %i0
	bnz,pn	%icc, 1f
	 add	%sp, BIAS, %o1
	btst	1, %sp
	movnz	%icc, %o1, %sp
	call	_C_LABEL(OF_val2sym)
	 mov	%i0, %o0
1:
	ret
	 restore	%o0, 0, %o0
#endif /* _LP64 */
#endif /* DDB */
d11589 1
a11589 1
#endif
d11629 1
a11629 1
#endif
@


1.31
log
@install a real handler for correctable ECC errors and make a count of
them available via sysctl (doc update in a bit); ok millert.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.30 2003/03/20 23:05:30 henric Exp $	*/
a11994 1
	.comm	_C_LABEL(curproc), PTRSZ
@


1.30
log
@The current code tries to use the same field in the interrupt handler as
both a "next" pointer for a singly-linked list and as an in-use flag.
This obviously does not work all that well.  This change adds a separate
ih_busy flag to mark the handler as in-use, leaving ih_pending for use by
the list code.

Testing by *many* (thanks).

ok miod jason
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.29 2003/02/28 21:27:42 jason Exp $	*/
d850 1
a850 1
	UTRAP(T_ECCERR)			! We'll implement this one later
d1086 1
a1086 1
	UTRAP(T_ECCERR)			! We'll implement this one later
d11479 54
@


1.29
log
@make intrcnt[n] an int to fit with the kern.intrcnt changes in January
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.28 2003/02/17 01:29:20 henric Exp $	*/
d2811 1
d2813 1
a2813 1
	 set	(2*NBPG)-8, %g7
d3974 2
a3975 1
	LDPTR	[%g5+IH_PEND], %g6	! Read pending flag
d4016 1
a4016 1
#endif
d4037 2
a4038 1
#endif
d4040 1
a4040 1
2:
d4061 1
a4061 1
#endif
d4275 1
d4278 21
a4301 5
	LDPTR	[%l2 + IH_PEND], %l7	! Clear pending flag
	LDPTR	[%l2 + IH_CLR], %l1
	membar	#LoadStore
	STPTR	%g0, [%l2 + IH_PEND]	! Clear pending flag
	membar	#Sync
d4304 1
a4304 1
	 add	%l5, %o0, %l5
a4305 1
	membar	#Sync			! Should not be needed
d11514 4
a11517 4
	cmp	%g1, %o1
	bge,pt	%icc, 1f
	 nop
	wrpr	%o1, 0, %pil
d11520 5
a11524 3
	 set	intrpending, %o3
	LDPTR	[%o2 + IH_PEND], %o5
	mov	8, %o4			! Number of slots to search
@


1.28
log
@
Add support for the Sun Enterprise 450
Reduce the size of a GENERIC kernel by ~190k
Remove the nasty pointer/bus_space_handle_t casts
Adds debug bus_space code including the ability to trace
    bus operations (it actually works now).

The following rules are now followed (and verfified by the debug
code):

1.  A "bus_space_handle_t" may only be used with the
    "bus_space_tag_t" that created it.
2.  Only "bus_space_map()" may create "bus_space_handle_t"s.
3.  A "bus_space_handle_t" may not be modified after it has
    been created (other than being destroyed by "bus_space_unmap()").


Thanks to help from mcbride, marc, jason, drahn, to anyone that might
have slipped my mind at the moment.

ok jason@@, deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.27 2003/01/11 07:07:49 jason Exp $	*/
d4227 1
a4227 1
	sll	%l6, LNGSHFT, %l3
d4230 1
a4230 1
	LDULNG	[%l4 + %l3], %o0
d4235 1
a4235 1
	STULNG	%o0, [%l4]
d11917 1
a11917 1
	.space	16 * LNGSZ
@


1.27
log
@add back fserr and fsbail deleted in previous commit
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.26 2003/01/09 22:27:10 miod Exp $	*/
d73 3
@


1.26
log
@Remove fetch(9) and store(9) functions from the kernel, and replace the few
remaining instances of them with appropriate copy(9) usage.

ok art@@, tested on all arches unless my memory is non-ECC
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.25 2002/09/10 18:29:44 art Exp $	*/
d7751 21
@


1.25
log
@Change the pmap_zero_page and pmap_copy_page API to take the struct vm_page *
instead of the pa. Most callers already had it handy and those who didn't
only called it for managed pages and were outside time-critical code.

This will allow us to make those functions clean and fast on sparc and
sparc64 letting us to avoid unnecessary cache flushes.

deraadt@@ miod@@ drahn@@ ok.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.24 2002/07/31 01:40:17 jason Exp $	*/
a7750 140

/*
 * {fu,su}{,i}{byte,word}
 */
ALTENTRY(fuiword)
ENTRY(fuword)
	btst	3, %o0			! has low bits set...
	bnz	Lfsbadaddr		!	go return -1
	EMPTY
	sethi	%hi(CPCB), %o2		! cpcb->pcb_onfault = Lfserr;
	set	Lfserr, %o3
	LDPTR	[%o2 + %lo(CPCB)], %o2
	membar	#LoadStore
	STPTR	%o3, [%o2 + PCB_ONFAULT]
	membar	#Sync
	LDPTRA	[%o0] ASI_AIUS, %o0	! fetch the word
	membar	#Sync
	STPTR	%g0, [%o2 + PCB_ONFAULT]! but first clear onfault
	retl				! phew, made it, return the word
	 membar	#StoreStore|#StoreLoad

Lfserr:
	STPTR	%g0, [%o2 + PCB_ONFAULT]! error in r/w, clear pcb_onfault
	membar	#StoreStore|#StoreLoad
Lfsbadaddr:
#ifndef _LP64
	mov	-1, %o1
#endif
	retl				! and return error indicator
	 mov	-1, %o0

	/*
	 * This is just like Lfserr, but it's a global label that allows
	 * mem_access_fault() to check to see that we don't want to try to
	 * page in the fault.  It's used by fuswintr() etc.
	 */
	.globl	_C_LABEL(Lfsbail)
_C_LABEL(Lfsbail):
	STPTR	%g0, [%o2 + PCB_ONFAULT]! error in r/w, clear pcb_onfault
	membar	#StoreStore|#StoreLoad
	retl				! and return error indicator
	 mov	-1, %o0

	/*
	 * Like fusword but callable from interrupt context.
	 * Fails if data isn't resident.
	 */
ENTRY(fuswintr)
	sethi	%hi(CPCB), %o2		! cpcb->pcb_onfault = _Lfsbail;
	LDPTR	[%o2 + %lo(CPCB)], %o2
	set	_C_LABEL(Lfsbail), %o3
	STPTR	%o3, [%o2 + PCB_ONFAULT]
	membar	#Sync
	lduha	[%o0] ASI_AIUS, %o0	! fetch the halfword
	membar	#Sync
	STPTR	%g0, [%o2 + PCB_ONFAULT]! but first clear onfault
	retl				! made it
	 membar	#StoreStore|#StoreLoad

ENTRY(fusword)
	sethi	%hi(CPCB), %o2		! cpcb->pcb_onfault = Lfserr;
	LDPTR	[%o2 + %lo(CPCB)], %o2
	set	Lfserr, %o3
	STPTR	%o3, [%o2 + PCB_ONFAULT]
	membar	#Sync
	lduha	[%o0] ASI_AIUS, %o0		! fetch the halfword
	membar	#Sync
	STPTR	%g0, [%o2 + PCB_ONFAULT]! but first clear onfault
	retl				! made it
	 membar	#StoreStore|#StoreLoad

ALTENTRY(fuibyte)
ENTRY(fubyte)
	sethi	%hi(CPCB), %o2		! cpcb->pcb_onfault = Lfserr;
	LDPTR	[%o2 + %lo(CPCB)], %o2
	set	Lfserr, %o3
	STPTR	%o3, [%o2 + PCB_ONFAULT]
	membar	#Sync
	lduba	[%o0] ASI_AIUS, %o0	! fetch the byte
	membar	#Sync
	STPTR	%g0, [%o2 + PCB_ONFAULT]! but first clear onfault
	retl				! made it
	 membar	#StoreStore|#StoreLoad

ALTENTRY(suiword)
ENTRY(suword)
	btst	3, %o0			! or has low bits set ...
	bnz	Lfsbadaddr		!	go return error
	EMPTY
	sethi	%hi(CPCB), %o2		! cpcb->pcb_onfault = Lfserr;
	LDPTR	[%o2 + %lo(CPCB)], %o2
	set	Lfserr, %o3
	STPTR	%o3, [%o2 + PCB_ONFAULT]
	membar	#Sync
	STPTRA	%o1, [%o0] ASI_AIUS	! store the word
	membar	#Sync
	STPTR	%g0, [%o2 + PCB_ONFAULT]! made it, clear onfault
	membar	#StoreStore|#StoreLoad
	retl				! and return 0
	 clr	%o0

ENTRY(suswintr)
	sethi	%hi(CPCB), %o2		! cpcb->pcb_onfault = _Lfsbail;
	LDPTR	[%o2 + %lo(CPCB)], %o2
	set	_C_LABEL(Lfsbail), %o3
	STPTR	%o3, [%o2 + PCB_ONFAULT]
	membar	#Sync
	stha	%o1, [%o0] ASI_AIUS	! store the halfword
	membar	#Sync
	STPTR	%g0, [%o2 + PCB_ONFAULT]! made it, clear onfault
	membar	#StoreStore|#StoreLoad
	retl				! and return 0
	 clr	%o0

ENTRY(susword)
	sethi	%hi(CPCB), %o2		! cpcb->pcb_onfault = Lfserr;
	LDPTR	[%o2 + %lo(CPCB)], %o2
	set	Lfserr, %o3
	STPTR	%o3, [%o2 + PCB_ONFAULT]
	membar	#Sync
	stha	%o1, [%o0] ASI_AIUS	! store the halfword
	membar	#Sync
	STPTR	%g0, [%o2 + PCB_ONFAULT]! made it, clear onfault
	membar	#StoreStore|#StoreLoad
	retl				! and return 0
	 clr	%o0

ALTENTRY(suibyte)
ENTRY(subyte)
	sethi	%hi(CPCB), %o2		! cpcb->pcb_onfault = Lfserr;
	LDPTR	[%o2 + %lo(CPCB)], %o2
	set	Lfserr, %o3
	STPTR	%o3, [%o2 + PCB_ONFAULT]
	membar	#Sync
	stba	%o1, [%o0] ASI_AIUS	! store the byte
	membar	#Sync
	STPTR	%g0, [%o2 + PCB_ONFAULT]! made it, clear onfault
	membar	#StoreStore|#StoreLoad
	retl				! and return 0
	 clr	%o0
@


1.24
log
@Don't need to reserve space for promvec, we don't use it.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.23 2002/07/24 00:48:25 art Exp $	*/
d8055 1
a8055 1
ENTRY(pmap_zero_page)
d8345 1
a8345 1
ENTRY(pmap_copy_page)
@


1.23
log
@Support for non-exec page mappings.
 - split the one TSB into two - one for dmmu, one for immu.
 - don't load pages without PG_EXEC into the immu TSB.
 - support for setting correct permissions on exec faults.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.22 2002/07/23 13:58:23 art Exp $	*/
a12036 1
	.comm	_C_LABEL(promvec), PTRSZ
@


1.22
log
@When handling an interrupt record the interrupt level we're handling
in a global variable (not mp safe!). Use that value for the reverse
splassert check.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.21 2002/07/20 22:39:00 art Exp $	*/
d3204 9
a3212 1
	 or	%g4, TTE_ACCESS, %g7			! Update accessed bit
d5674 1
a5674 3
	 * Step 7: change the trap base register, and install our TSB
	 *
	 * XXXX -- move this to CPUINFO_VA+32KB?
d5676 2
d5679 1
a5679 1
	set	_C_LABEL(tsb), %l0
d5686 3
a5688 1
!	srl	%l0, 0, %l0	! DEBUG -- make sure this is a valid pointer by zeroing the high bits
a5689 11
#ifdef DEBUG
	set	1f, %o0		! Debug printf
	srlx	%l0, 32, %o1
	call	_C_LABEL(prom_printf)
	 srl	%l0, 0, %o2
	.data
1:
	.asciz	"Setting TSB pointer %08x %08x\r\n"
	_ALIGN
	.text
#endif
d5691 9
d5703 2
a5704 2
	stxa	%l0, [%l2] ASI_DMMU		! Install data TSB pointer
	membar	#Sync
@


1.21
log
@unconfuse indentation.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.20 2002/07/20 22:30:35 art Exp $	*/
d4182 1
a4182 1
	INTR_SETUP(-CC64FSZ-TF_SIZE)
d4227 2
d4231 8
d4405 5
@


1.20
log
@typo
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.19 2002/07/20 20:19:10 art Exp $	*/
d3378 1
a3378 1
	 and	%sp, 0x07, %g4		! 64-bit stack OK?
@


1.19
log
@Always HWREF. Don't have it as an option because the slow-slow version
doesn't make any sense (slow and doesn't work follow the rules).
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.18 2002/06/15 00:38:37 art Exp $	*/
d3205 1
a3205 1
	btst	TTE_ACCESS, %g4				! Need to update access git?
@


1.18
log
@gc some leftovers from sparc.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.17 2002/06/09 05:55:24 art Exp $	*/
a66 1
#define	HWREF			/* Track ref/mod bits in trap handlers */
a897 1
#ifdef HWREF
a898 3
#else
	ba,a,pt	%xcc, winfault
#endif
a1133 1
#ifdef HWREF
a1134 3
#else
	ba,a,pt	%xcc, winfault
#endif
@


1.17
log
@zap EMBMEDANY leftovers (all the comments were wrong).
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.16 2002/06/08 21:54:49 mdw Exp $	*/
a426 27

/* NB:	 Do we really need the following around? */
/*
 * _cputyp is the current cpu type, used to distinguish between
 * the many variations of different sun4* machines. It contains
 * the value CPU_SUN4, CPU_SUN4C, or CPU_SUN4M.
 */
	.globl	_C_LABEL(cputyp)
_C_LABEL(cputyp):
	.word	1
/*
 * _cpumod is the current cpu model, used to distinguish between variants
 * in the Sun4 and Sun4M families. See /sys/arch/sparc64/include/param.h
 * for possible values.
 */
	.globl	_C_LABEL(cpumod)
_C_LABEL(cpumod):
	.word	1
/*
 * _mmumod is the current mmu model, used to distinguish between the
 * various implementations of the SRMMU in the sun4m family of machines.
 * See /sys/arch/sparc64/include/param.h for possible values.
 */
	.globl	_C_LABEL(mmumod)
_C_LABEL(mmumod):
	.word	0

a429 12

/*
 * There variables are pointed to by the cpp symbols PGSHIFT, NBPG,
 * and PGOFSET.
 */
	.globl	_C_LABEL(pgshift), _C_LABEL(nbpg), _C_LABEL(pgofset)
_C_LABEL(pgshift):
	.word	0
_C_LABEL(nbpg):
	.word	0
_C_LABEL(pgofset):
	.word	0
@


1.16
log
@Netbsd cache flush speedup to dcache_flush_page.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.15 2002/06/08 08:06:46 art Exp $	*/
a3122 3
	!! In the EMBEDANY memory model %g4 points to the start of the data segment.
	!! In our case we need to clear it before calling any C-code
	clr	%g4
a3363 4
	!! In the EMBEDANY memory model %g4 points to the start of the data segment.
	!! In our case we need to clear it before calling any C-code
	clr	%g4

a3479 3
	!! In the EMBEDANY memory model %g4 points to the start of the data segment.
	!! In our case we need to clear it before calling any C-code
	clr	%g4
a3858 3
	!! In the EMBEDANY memory model %g4 points to the start of the data segment.
	!! In our case we need to clear it before calling any C-code
	clr	%g4
a4239 7

	/*
	 * In the EMBEDANY memory model %g4 points to the start of the
	 * data segment.  In our case we need to clear it before calling
	 * any C-code.
	 */
	clr	%g4
@


1.15
log
@Provide type information for some symbols. Should fix vmstat -i.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.14 2002/05/23 23:11:15 deraadt Exp $	*/
d6058 4
a6061 2
	andn	%o1, 3, %o1	! Now we have bits <29:2> set

d6064 5
d6071 6
a6076 5
	bne,pt	%xcc, 2f
	 dec	16, %o5
	membar	#LoadStore
	stxa	%g0, [%o4] ASI_DCACHE_TAG
	membar	#StoreLoad
a6077 2
	brnz,pt	%o5, 1b
	 inc	16, %o4
d6079 1
a6081 1
	membar	#Sync
d6083 1
a6083 1
	 nop
@


1.14
log
@remove unneccesary icache flushes; mdw@@umich.edu
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.13 2002/04/03 17:22:41 jason Exp $	*/
d12046 6
a12051 1
	.globl	_C_LABEL(intrcnt), _C_LABEL(eintrcnt), _C_LABEL(intrnames), _C_LABEL(eintrnames)
@


1.13
log
@Replace the implementation of microtime with one written in C that doesn't go backwards on machines w/out counter-timer
Remove a bunch of uncessary code (#if 0, #undef, etc)
[still exhibits bad behavior on counter-timer machines, but it's the same
behavior as the assembler version]
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.12 2002/03/14 01:26:45 millert Exp $	*/
d6011 1
a6011 1
 * Clear out all of both I$ and D$ regardless of contents
a6027 1
	stxa	%g0, [%o1] ASI_ICACHE_TAG
a6035 31

/*
 * blast_icache()
 *
 * Clear out all of I$ regardless of contents
 * Does not modify %o0
 *
 */
	.align 8
	.globl	_C_LABEL(blast_icache)
	.proc 1
	FTYPE(blast_icache)
_C_LABEL(blast_icache):
/*
 * We turn off interrupts for the duration to prevent RED exceptions.
 */
	rdpr	%pstate, %o3
	set	(2*NBPG)-8, %o1
	andn	%o3, PSTATE_IE, %o4			! Turn off PSTATE_IE bit
	wrpr	%o4, 0, %pstate
1:
	stxa	%g0, [%o1] ASI_ICACHE_TAG
	brnz,pt	%o1, 1b
	 dec	8, %o1
	sethi	%hi(KERNBASE), %o2
	flush	%o2
	retl
	 wrpr	%o3, %pstate



d6039 1
a6039 1
 * Clear one page from D$ and I$.
a6061 1
	dec	16, %o5
d6065 2
a6066 1
	 membar	#LoadStore
a6072 21
	!! Now do the I$
	srlx	%o0, 13-8, %o2
	mov	-1, %o1		! Generate mask for tag: bits [35..8]
	srl	%o1, 32-35+7, %o1
	clr	%o4
	sll	%o1, 7, %o1	! Mask
	set	(2*NBPG), %o5
	
1:
	ldda	[%o4] ASI_ICACHE_TAG, %g0	! Tag goes in %g1
	dec	16, %o5
	xor	%g1, %o2, %g1
	andcc	%g1, %o1, %g0
	bne,pt	%xcc, 2f
	 membar	#LoadStore
	stxa	%g0, [%o4] ASI_ICACHE_TAG
	membar	#StoreLoad
2:
	brnz,pt	%o5, 1b
	 inc	16, %o4

d6082 1
a6082 1
 * Clear everything in that va range from D$ and I$.
a6096 1
	sethi	%hi((1<<13)), %o5
a6103 3
	xor	%o5, %o0, %o3	! Second way
	stxa	%g0, [%o0] ASI_ICACHE_TAG
	stxa	%g0, [%o3] ASI_ICACHE_TAG
a6117 3
	xor	%o5, %o4, %g1	! Second way
	stxa	%g0, [%o4] ASI_ICACHE_TAG
	stxa	%g0, [%g1] ASI_ICACHE_TAG
d6129 1
a6129 1
 *	Clear a set of paddrs from the D$, I$ and if param3 is
d6150 2
a6151 3
	!! Both D$ and I$ tags match pa bits 40-13, but
	!! they are shifted different amounts.  So we'll
	!! generate a mask for bits 40-13.
a6164 1
	ldda	[%o4] ASI_ICACHE_TAG, %g0	! Tag goes in %g1
a6168 1
	 sllx	%g1, 40-35, %g1	! Shift I$ tag into place
a6175 7
	cmp	%o0, %g1
	blt,pt	%xcc, 3f
	 cmp	%o1, %g1
	bgt,pt	%icc, 3f
	 nop
	stxa	%g0, [%o4] ASI_ICACHE_TAG
3:
@


1.12
log
@First round of __P removal in sys
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.11 2002/02/19 03:15:27 jason Exp $	*/
a72 1
#define	TICK_IS_TIME		/* Keep %tick synchronized with time */
a11826 24
/*
 * void microtime(struct timeval *tv)
 *
 * LBL's sparc bsd 'microtime': We don't need to spl (so this routine
 * can be a leaf routine) and we don't keep a 'last' timeval (there
 * can't be two calls to this routine in a microsecond).  This seems to
 * be about 20 times faster than the Sun code on an SS-2. - vj
 *
 * Read time values from slowest-changing to fastest-changing,
 * then re-read out to slowest.  If the values read before
 * the innermost match those read after, the innermost value
 * is consistent with the outer values.  If not, it may not
 * be and we must retry.  Typically this loop runs only once;
 * occasionally it runs twice, and only rarely does it run longer.
 *
 * If we used the %tick register we could go into the nano-seconds,
 * and it must run for at least 10 years according to the v9 spec.
 *
 * For some insane reason timeval structure members are `long's so
 * we need to change this code depending on the memory model.
 *
 * NB: if somehow time was 128-bit aligned we could use an atomic
 * quad load to read it in and not bother de-bouncing it.
 */
a11827 1

d11829 1
a11829 1
	.align	8
a11837 107
ENTRY(microtime)
	sethi	%hi(timerreg_4u), %g3
	sethi	%hi(_C_LABEL(time)), %g2
	LDPTR	[%g3+%lo(timerreg_4u)], %g3			! usec counter
	brz,pn	%g3, microtick					! If we have no counter-timer use %tick
2:
	!!  NB: if we could guarantee 128-bit alignment of these values we could do an atomic read
	LDPTR	[%g2+%lo(_C_LABEL(time))], %o2			! time.tv_sec & time.tv_usec
	LDPTR	[%g2+%lo(_C_LABEL(time)+PTRSZ)], %o3		! time.tv_sec & time.tv_usec
	ldx	[%g3], %o4					! Load usec timer valuse
	LDPTR	[%g2+%lo(_C_LABEL(time))], %g1			! see if time values changed
	LDPTR	[%g2+%lo(_C_LABEL(time)+PTRSZ)], %g5		! see if time values changed
	cmp	%g1, %o2
	bne	2b						! if time.tv_sec changed
	 cmp	%g5, %o3
	bne	2b						! if time.tv_usec changed
	 add	%o4, %o3, %o3					! Our timers have 1usec resolution

	set	MICROPERSEC, %o5				! normalize usec value
	sub	%o3, %o5, %o5					! Did we overflow?
	brlz,pn	%o5, 4f
	 nop
	add	%o2, 1, %o2					! overflow
	mov	%o5, %o3
4:
	STPTR	%o2, [%o0]					! (should be able to std here)
	retl
	 STPTR	%o3, [%o0+PTRSZ]

microtick:
#ifndef TICK_IS_TIME
/*
 * The following code only works if %tick is reset each interrupt.
 */
2:
	!!  NB: if we could guarantee 128-bit alignment of these values we could do an atomic read
	LDPTR	[%g2+%lo(_C_LABEL(time))], %o2			! time.tv_sec & time.tv_usec
	LDPTR	[%g2+%lo(_C_LABEL(time)+PTRSZ)], %o3		! time.tv_sec & time.tv_usec
	rdpr	%tick, %o4					! Load usec timer value
	LDPTR	[%g2+%lo(_C_LABEL(time))], %g1			! see if time values changed
	LDPTR	[%g2+%lo(_C_LABEL(time)+PTRSZ)], %g5		! see if time values changed
	cmp	%g1, %o2
	bne	2b						! if time.tv_sec changed
	 cmp	%g5, %o3
	bne	2b						! if time.tv_usec changed
	 sethi	%hi(_C_LABEL(cpu_clockrate)), %g1
	ldx	[%g1 + %lo(_C_LABEL(cpu_clockrate) + 8)], %o1
	sethi	%hi(MICROPERSEC), %o5
	brnz,pt	%o1, 3f
	 or	%o5, %lo(MICROPERSEC), %o5

	!! Calculate ticks/usec
	ldx	[%g1 + %lo(_C_LABEL(cpu_clockrate))], %o1	! No, we need to calculate it
	udivx	%o1, %o5, %o1
	stx	%o1, [%g1 + %lo(_C_LABEL(cpu_clockrate) + 8)]	! Save it so we don't need to divide again
3:
	udivx	%o4, %o1, %o4					! Convert to usec
	add	%o4, %o3, %o3

	sub	%o3, %o5, %o5					! Did we overflow?
	brlz,pn	%o5, 4f
	 nop
	add	%o2, 1, %o2					! overflow
	mov	%o5, %o3
4:
	STPTR	%o2, [%o0]					! (should be able to std here)
	retl
	 STPTR	%o3, [%o0+PTRSZ]
#else
/*
 * The following code only works if %tick is synchronized with time.
 */
2:
	LDPTR	[%g2+%lo(_C_LABEL(time))], %o2			! time.tv_sec & time.tv_usec
	LDPTR	[%g2+%lo(_C_LABEL(time)+PTRSZ)], %o3		! time.tv_sec & time.tv_usec
	rdpr	%tick, %o4					! Load usec timer value
	LDPTR	[%g2+%lo(_C_LABEL(time))], %g1			! see if time values changed
	LDPTR	[%g2+%lo(_C_LABEL(time)+PTRSZ)], %g5		! see if time values changed
	cmp	%g1, %o2
	bne	2b						! if time.tv_sec changed
	 cmp	%g5, %o3
	bne	2b						! if time.tv_usec changed

	 sethi	%hi(_C_LABEL(cpu_clockrate)), %o1
	ldx	[%o1 + %lo(_C_LABEL(cpu_clockrate) + 8)], %g1	! Get scale factor
	sethi	%hi(MICROPERSEC), %o5
	brnz,pt	%g1, 1f						! Already scaled?
	 or	%o5, %lo(MICROPERSEC), %o5

	!! Calculate ticks/usec
	ldx	[%o1 + %lo(_C_LABEL(cpu_clockrate))], %g1	! No, we need to calculate it
	udivx	%g1, %o5, %g1					! Hz / 10^6 = MHz
	stx	%g1, [%o1 + %lo(_C_LABEL(cpu_clockrate) + 8)]	! Save it so we don't need to divide again
1:

	STPTR	%o2, [%o0]					! Store seconds.
	udivx	%o4, %g1, %o4					! Scale it: ticks / MHz = usec

	udivx	%o4, %o5, %o2					! Now %o2 has seconds

	mulx	%o2, %o5, %o5					! Now calculate usecs -- damn no remainder insn
	sub	%o4, %o5, %o1					! %o1 has the remainder

	retl
	 STPTR	%o1, [%o0+PTRSZ]				! Save time_t low word
#endif

a11851 1
#if 1
a11876 19
#else
/* This code only works if %tick does not wrap */
	rdpr	%tick, %g1					! Take timer snapshot
	sethi	%hi(_C_LABEL(cpu_clockrate)), %g2
	sethi	%hi(MICROPERSEC), %o2
	ldx	[%g2 + %lo(_C_LABEL(cpu_clockrate))], %g2	! Get scale factor
	or	%o2, %lo(MICROPERSEC), %o2
!	sethi	%hi(_C_LABEL(timerblurb), %o5			! This is if we plan to tune the clock
!	ld	[%o5 + %lo(_C_LABEL(timerblurb))], %o5		!  with respect to the counter/timer
	mulx	%o0, %g2, %g2					! Scale it: (usec * Hz) / 1 x 10^6 = ticks
	udivx	%g2, %o2, %g2
	add	%g1, %g2, %g2
!	add	%o5, %g2, %g2			5, %g2, %g2					! But this gets complicated
	rdpr	%tick, %g1					! Top of next itr
	mov	%g1, %g1	! Erratum 50
1:
	cmp	%g1, %g2
	bl,a,pn %xcc, 1b					! Done?
	 rdpr	%tick, %g1
a11877 3
	retl
	 nop
#endif
@


1.11
log
@From NetBSD:
Shift the UPAID in the correct direction.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.10 2002/02/19 03:04:41 jason Exp $	*/
d6188 1
a6188 1
 *	cache_flush_phys __P((paddr_t, psize_t, int));
@


1.10
log
@From NetBSD:
Fix microsecond calculation in microtime.
Fix register allocation in microtime().
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.9 2001/09/17 04:20:27 jason Exp $	*/
d5665 1
a5665 1
	sllx	%l2, 17, %l2			! Isolate UPAID from CPU reg
@


1.9
log
@stuff for ksyms (doesn't quite work yet, tho)
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.8 2001/09/10 22:40:21 art Exp $	*/
d11948 1
a11948 1
	ldx	[%o1 + %lo(_C_LABEL(cpu_clockrate) + 8)], %o4	! Get scale factor
d11950 2
a11951 2
	brnz,pt	%o4, 1f						! Already scaled?
	 or	%o2, %lo(MICROPERSEC), %o5
d11954 3
a11956 3
	ldx	[%o1 + %lo(_C_LABEL(cpu_clockrate))], %o4	! No, we need to calculate it
	udivx	%o4, %o5, %o4					! Hz / 10^6 = MHz
	stx	%o4, [%o1 + %lo(_C_LABEL(cpu_clockrate) + 8)]	! Save it so we don't need to divide again
d11960 1
a11960 1
	udivx	%o4, %o1, %o4					! Scale it: ticks / MHz = usec
a11966 1
	add	%o1, %o3, %o1	! I think this is wrong
@


1.9.6.1
log
@Sync UBC branch to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.9 2001/09/17 04:20:27 jason Exp $	*/
d73 1
d3124 3
d3368 4
d3488 3
d3870 3
d4255 7
d5665 1
a5665 1
	srax	%l2, 17, %l2			! Isolate UPAID from CPU reg
d6012 1
a6012 1
 * Clear out all of D$ regardless of contents
d6029 1
d6038 31
d6072 1
a6072 1
 * Clear one page from D$.
d6091 2
a6092 4
	ba,pt	%icc, 1f
	 andn	%o1, 3, %o1	! Now we have bits <29:2> set
	
	.align 8
d6095 1
a6095 5
	mov	%o4, %o0
	deccc	16, %o5
	bl,pn	%icc, 2f
	
	 inc	16, %o4
d6098 1
a6098 1
	bne,pt	%xcc, 1b
d6100 13
d6114 9
a6122 3
	stxa	%g0, [%o0] ASI_DCACHE_TAG
	ba,pt	%icc, 1b
	 membar	#StoreLoad
d6124 2
a6126 1
	wr	%g0, ASI_PRIMARY_NOFAULT, %asi
d6129 1
d6131 1
a6131 1
	 membar	#Sync
d6136 1
a6136 1
 * Clear everything in that va range from D$.
d6151 1
d6159 3
d6176 3
d6188 1
a6188 1
 *	cache_flush_phys(paddr_t, psize_t, int);
d6190 1
a6190 1
 *	Clear a set of paddrs from the D$ and if param3 is
d6211 3
a6213 2
	!! D$ tags match pa bits 40-13.
	!! Generate a mask for them.
d6227 1
d6232 1
d6240 7
d11828 24
d11853 1
d11855 1
a11855 1
	.align	16
d11864 108
d11986 1
d12012 19
d12032 3
d12273 1
a12273 6
	.globl	_C_LABEL(intrcnt), _C_LABEL(eintrcnt)
	.globl _C_LABEL(intrnames), _C_LABEL(eintrnames)
	OTYPE(intrcnt)
	OTYPE(eintrcnt)
	OTYPE(intrnames)
	OTYPE(eintrnames)
@


1.9.6.2
log
@sync to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.9.6.1 2002/06/11 03:38:43 art Exp $	*/
d67 1
d427 27
d458 12
d938 1
d940 3
d1178 1
d1180 3
d3252 2
a3253 10
	 nop

	/* Check if it's an executable mapping. */
	andcc	%g4, TTE_EXEC, %g0
	bz,pn	%xcc, textfault
	 nop


	or	%g4, TTE_ACCESS, %g7			! Update accessed bit
	btst	TTE_ACCESS, %g4				! Need to update access bit?
d3426 1
a3426 1
	and	%sp, 0x07, %g4		! 64-bit stack OK?
d4230 1
a4230 1
	INTR_SETUP(-CC64FSZ-TF_SIZE-8)
a4274 2
	sethi	%hi(_C_LABEL(handled_intr_level)), %l4

a4276 8
	/*
	 * Set handled_intr_level and save the old one so we can restore it
	 * later.
	 */
	ld	[%l4 + %lo(_C_LABEL(handled_intr_level))], %l7
	st	%l6, [%l4 + %lo(_C_LABEL(handled_intr_level))]
	st	%l7, [%sp + CC64FSZ + STKB + TF_SIZE]

a4443 5
	/* Restore old handled_intr_level */
	sethi	%hi(_C_LABEL(handled_intr_level)), %l4
	ld	[%sp + CC64FSZ + STKB + TF_SIZE], %l7
	st	%l7, [%l4 + %lo(_C_LABEL(handled_intr_level))]

d5699 3
a5701 1
	 * Step 7: change the trap base register, and install our TSBs
a5702 2

	/* Set the dmmu tsb */
d5704 1
a5704 1
	set	_C_LABEL(tsb_dmmu), %l0
d5711 1
a5711 3
	set	TSB, %l2
	stxa	%l0, [%l2] ASI_DMMU		! Install data TSB pointer
	membar	#Sync
d5713 11
a5724 9
	/* Set the immu tsb */
	sethi	%hi(0x1fff), %l2
	set	_C_LABEL(tsb_immu), %l0
	LDPTR	[%l0], %l0
	set	_C_LABEL(tsbsize), %l1
	or	%l2, %lo(0x1fff), %l2
	ld	[%l1], %l1
	andn	%l0, %l2, %l0			! Mask off size and split bits
	or	%l0, %l1, %l0			! Make a TSB pointer
d5728 2
a5729 2

	/* Change the trap base register */
d8080 1
a8080 1
ENTRY(pmap_zero_phys)
d8370 1
a8370 1
ENTRY(pmap_copy_phys)
d12062 1
@


1.9.6.3
log
@sync
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d58 1
d60 2
d63 1
a73 3
.register %g2,
.register %g3,

d95 1
a95 1
#else	/* MULTIPROCESSOR */
d99 1
a99 1
#endif	/* MULTIPROCESSOR */
d117 58
a174 1
#endif	/* 1 */
d183 1
a183 1
#else	/* 1 */
d185 1
a185 1
#endif	/* 1 */
a194 1
	.macro DLFLUSH a,t
d196 3
a198 2
	andn	\a, 0x1f, \t
	stxa	%g0, [ \t ] ASI_DCACHE_TAG
a199 2
#endif	/* DCACHE_BUG */
	.endm
d201 2
a202 3
	.macro DLFLUSH2 t
#ifdef DCACHE_BUG
	stxa	%g0, [ \t ] ASI_DCACHE_TAG
d204 22
a225 2
#endif	/* DCACHE_BUG */
	.endm
d232 2
a233 2
 *		TRAP_SETUP ...		! makes %o registers safe
 *		INCR _C_LABEL(cnt)+V_FOO	! count a foo
d235 9
a243 9
	.macro INCR what
	sethi	%hi(\what), %o0
	or	%o0, %lo(\what), %o0
99:
	lduw	[%o0], %o1
	add	%o1, 1, %o2
	casa	[%o0] ASI_P, %o1, %o2
	cmp	%o1, %o2
	bne,pn	%icc, 99b
a244 1
	.endm
d251 17
a267 34
	.macro GLOBTOLOC
	.irpc n,1234567
		mov	%g\n, %l\n
	.endr
	.endm

	.macro LOCTOGLOB
	.irpc n,1234567
		mov	%l\n, %g\n
	.endr
	.endm

/*
 * some macros to load and store a register window
 */
	.macro	SPILL storer,base,size,asi

	.irpc n,01234567
		\storer %l\n, [\base + (\n * \size)] \asi
	.endr
	.irpc n,01234567
		\storer %i\n, [\base + ((8+\n) * \size)] \asi
	.endr
	.endm

	.macro FILL loader, base, size, asi
	.irpc n,01234567
		\loader [\base + (\n * \size)] \asi, %l\n
	.endr

	.irpc n,01234567
		\loader [\base + ((8+\n) * \size)] \asi, %i\n
	.endr
	.endm
d279 1
a279 1
 * Correctly switch to a 64-bit stack
d283 4
a286 4
	.macro STACKFRAME size
	save	%sp, \size, %sp
	add	%sp, -BIAS, %o0		! Convert to 64-bits
	andcc	%sp, 1, %g0		! 64-bit stack?
d288 12
a299 1
	.endm
d309 33
a341 34
	.macro ENABLE_FPU siz
	save	%sp, -(CC64FSZ), %sp;		! Allocate a stack frame
	sethi	%hi(FPPROC), %l1;
	add	%fp, BIAS-FS_SIZE, %l0;		! Allocate a fpstate
	ldx	[%l1 + %lo(FPPROC)], %l2;	! Load fpproc
	andn	%l0, BLOCK_SIZE, %l0;		! Align it
	clr	%l3;				! NULL fpstate
	brz,pt	%l2, 1f;			! fpproc == NULL?
	 add	%l0, -BIAS-CC64FSZ-(\siz), %sp;	! Set proper %sp
	ldx	[%l2 + P_FPSTATE], %l3;
	brz,pn	%l3, 1f;			! Make sure we have an fpstate
	 mov	%l3, %o0;
	call	_C_LABEL(savefpstate);		! Save the old fpstate
1:
	 set	EINTSTACK-BIAS, %l4;		! Are we on intr stack?
	cmp	%sp, %l4;
	bgu,pt	%xcc, 1f;
	 set	INTSTACK-BIAS, %l4;
	cmp	%sp, %l4;
	blu	%xcc, 1f;
0:
	 sethi	%hi(_C_LABEL(proc0)), %l4;	! Yes, use proc0
	ba,pt	%xcc, 2f;			! XXXX needs to change to CPUs idle proc
	 or	%l4, %lo(_C_LABEL(proc0)), %l5;
1:
	sethi	%hi(CURPROC), %l4;		! Use curproc
	ldx	[%l4 + %lo(CURPROC)], %l5;
	brz,pn	%l5, 0b; nop;			! If curproc is NULL need to use proc0
2:
	ldx	[%l5 + P_FPSTATE], %l6;		! Save old fpstate
	stx	%l0, [%l5 + P_FPSTATE];		! Insert new fpstate
	stx	%l5, [%l1 + %lo(FPPROC)];	! Set new fpproc
	wr	%g0, FPRS_FEF, %fprs		! Enable FPU
	.endm
a346 2

	.macro RESTORE_FPU
d348 17
a364 11
	ldx	[%l5 + P_FPSTATE], %l7
	cmp	%l7, %l0
	tnz	1
#endif	/* DEBUG */
	stx	%l2, [%l1 + %lo(FPPROC)]	! Restore old fproc
	wr	%g0, 0, %fprs			! Disable fpu
	brz,pt	%l3, 1f				! Skip if no fpstate
	 stx	%l6, [%l5 + P_FPSTATE]		! Restore old fpstate

	call	_C_LABEL(loadfpstate)		! Re-load orig fpstate
	 mov	%l3, %o0
a365 1
	.endm
d391 2
a392 2
_C_LABEL(u0):	.xword	0
estack0:	.xword	0
d402 1
a402 1
#endif	/* KGDB */
d411 1
a411 1
#endif	/* DEBUG */
d418 1
a418 1
_C_LABEL(cpcb):	.xword	_C_LABEL(u0)
d424 1
a424 1
romp:	.xword	0
d464 2
a465 7
	.macro TA8
	.align 32
	.endm

	.macro TA32
	.align 128
	.endm
d482 1
a482 1
#endif	/* 0 */
d486 1
a486 1
#else	/* TRAPS_USE_IG */
d489 1
a489 1
#endif	/* TRAPS_USE_IG */
d493 4
a496 8
	.macro VTRAP type, label 
	sethi	%hi(\label), %g1
	ba,pt	%icc,traceit
	or	%g1, %lo(\label), %g1
	NOTREACHED
	TA8
	.endm
#else	/* TRAPTRACE */
d504 1
a504 1
#else	/* FLTRACE */
d506 6
a511 12
#endif	/* FLTRACE */
	.macro VTRAP type, label
	sethi	%hi(DATA_START),%g1
	rdpr	%tt,%g2
	or	%g1,0x28,%g1
	b	\label
	stx	%g2,[%g1]
	NOTREACHED
	TA8
	.endm
#endif	/* TRAPTRACE */
#else	/* DEBUG */
d519 1
a519 1
#endif	/* 0 */
d523 1
a523 1
#else	/* TRAPS_USE_IG */
d526 1
a526 1
#endif	/* TRAPS_USE_IG */
d530 4
a533 8
	.macro VTRAP type, label
	sethi	%hi(\label), %g1
	ba,pt	%icc,traceit
	or	%g1, %lo(\label), %g1
	NOTREACHED
	TA8
	.endm
#else	/* TRAPTRACE */
d541 1
a541 1
#else	/* FLTRACE */
d543 5
a547 9
#endif	/* FLTRACE */
	.macro VTRAP type, label
	ba,a,pt	%icc,\label
	nop
	NOTREACHED
	TA8
	.endm
#endif	/* TRAPTRACE */
#endif	/* DEBUG */
d549 2
a550 3
	.macro HARDINT4U lev
	VTRAP \lev, _C_LABEL(sparc_interrupt)
	.endm
d554 2
a555 3
	.macro SOFTINT4U lev, bit
	HARDINT4U lev
	.endm
d558 1
a558 3
	.macro TRAP type
	VTRAP \type, slowtrap
	.endm
a560 1
	.macro	UTRAP type
d562 4
a565 4
	sir
#endif	/* DEBUG */
	VTRAP \type, slowtrap
	.endm
d568 1
a568 3
	.macro STRAP type
	VTRAP \type, slowtrap
	.endm
d572 13
a584 6
#define	BPT		VTRAP T_BREAKPOINT, bpt
#define	BPT_KGDB_EXEC	VTRAP T_KGDB_EXEC, bpt
#else	/* KGDB */
#define	BPT		TRAP T_BREAKPOINT
#define	BPT_KGDB_EXEC	TRAP T_KGDB_EXEC
#endif	/* KGDB */
a585 2
#define	SYSCALL		VTRAP 0x100, syscall_setup
#define	ZS_INTERRUPT4U	HARDINT4U 12
a589 1
	.macro CLRTT n
d591 1
a591 2
#if 0	/* for henric, but not yet */
	wrpr	%g0, 0x1ff - \n, %tt
d593 1
a593 1
	wrpr	%g0, 0x1ff, %tt
d595 143
a737 2
#endif	/* DEBUG */
	.endm
d739 30
a768 1
	.macro UCLEANWIN
d774 1
a774 1
#else	/* DEBUG */
d776 1
a776 1
#endif	/* DEBUG */
d794 1
a794 1
	ldx	[%l5 + %lo(CPCB)], %l5	! If pcb < fp < pcb+sizeof(pcb)
d803 2
a804 2
#endif	/* DIAGNOSTIC */
#endif	/* 0 */
d810 1
a810 1
	CLRTT 5
d812 37
a848 34
	.endm

	.macro KCLEANWIN
	TRACEWIN			! DEBUG
	clr	%l0
#ifdef DEBUG
	set	0xbadbeef, %l0		! DEBUG
#endif	/* DEBUG */
	mov %l0, %l1; mov %l0, %l2	! 024-027 = clean window trap
	rdpr %cleanwin, %o7		!	This handler is in-lined and cannot fault
	inc %o7; mov %l0, %l3	!       Nucleus (trap&IRQ) code does not need clean windows
	wrpr %g0, %o7, %cleanwin	!	Clear out %l0-%l8 and %o0-%o8 and inc %cleanwin and done
#ifdef NOT_DEBUG
	!!
	!! Check the sp redzone
	!!
	rdpr	%wstate, t1
	cmp	t1, WSTATE_KERN
	bne,pt	icc, 7f
	 sethi	%hi(_C_LABEL(redzone)), t1
	ldx	[t1 + %lo(_C_LABEL(redzone))], t2
	cmp	%sp, t2			! if sp >= t2, not in red zone
	blu	panic_red		! and can continue normally
7:
#endif	/* NOT_DEBUG */
	mov %l0, %l4; mov %l0, %l5; mov %l0, %l6; mov %l0, %l7
	mov %l0, %o0; mov %l0, %o1; mov %l0, %o2; mov %l0, %o3

	mov %l0, %o4; mov %l0, %o5; mov %l0, %o6; mov %l0, %o7
	CLRTT 8
	retry; nop; TA32
	.endm

	.macro IMMU_MISS n
d851 3
d860 1
a860 1
	CLRTT \n
d866 1
a866 3
	.endm

	.macro DMMU_MISS n
d868 9
a876 6
	ldxa	[%g0] ASI_DMMU_8KPTR, %g2!	Load DMMU 8K TSB pointer
	ldxa	[%g0] ASI_DMMU, %g1	!	Load DMMU tag target register
	ldda	[%g2] ASI_NUCLEUS_QUAD_LDD, %g4	! Load TSB tag:data into %g4:%g5
	brgez,pn %g5, data_miss		!	Entry invalid?  Punt	XXX should be 2f
	 xor	%g1, %g4, %g4		!	Compare TLB tags
	brnz,pn	%g4, data_miss		!	Got right tag?
d878 1
a878 1
	CLRTT \n
d884 3
a886 3
#endif	/* TRAPSTATS */
	stxa	%g5, [%g0] ASI_DMMU_DATA_IN!	Enter new mapping
	retry				!	Try new mapping
d890 1
a890 22
	.endm

!! this can be just DMMU_MISS -- the only difference
!! between that & this is instruction ordering and #if 0 code -mdw
	.macro DMMU_MISS_2
	TRACEFLT			! DEBUG
	ldxa	[%g0] ASI_DMMU_8KPTR, %g2 !	Load DMMU 8K TSB pointer
	ldxa	[%g0] ASI_DMMU, %g1	!	Load DMMU tag target register
	ldda	[%g2] ASI_NUCLEUS_QUAD_LDD, %g4	! Load TSB tag:data into %g4:%g5
	brgez,pn %g5, data_miss		!	Entry invalid?  Punt
	 xor	%g1, %g4, %g4		!	Compare TLB tags
	brnz,pn	%g4, data_miss		!	Got right tag?
	 nop
	CLRTT 10
	stxa	%g5, [%g0] ASI_DMMU_DATA_IN!	Enter new mapping
	retry				!	Try new mapping
1:
	sir
	TA32
	.endm

	.macro DMMU_PROT dprot
d893 2
a894 2
	sethi	%hi(_C_LABEL(\dprot)), %g1
	lduw	[%g1+%lo(_C_LABEL(\dprot))], %g2
d896 2
a897 2
	stw	%g2, [%g1+%lo(_C_LABEL(\dprot))]
#endif	/* TRAPSTATS */
d901 4
a904 160
	.endm
/*
 * Here are some oft repeated traps as macros.
 */

	! spill a 64-bit register window
	.macro SPILL64 label, as
	TRACEWIN
\label:
	wr	%g0, \as, %asi
	SPILL	stxa, %sp+BIAS, 8, %asi
	saved
	CLRTT 1
	retry
	NOTREACHED
	TA32
	.endm

	! spill a 32-bit register window
	.macro SPILL32 label, as
	TRACEWIN
\label:
	wr	%g0, \as, %asi
	srl	%sp, 0, %sp ! fixup 32-bit pointers
	SPILL	stwa, %sp, 4, %asi
	saved
	CLRTT 2
	retry
	NOTREACHED
	TA32
	.endm

	! Spill either 32-bit or 64-bit register window.
	.macro SPILLBOTH label64,label32, as
	TRACEWIN
	andcc	%sp, 1, %g0
	bnz,pt	%xcc, \label64+4	! Is it a v9 or v8 stack?
	 wr	%g0, \as, %asi
	ba,pt	%xcc, \label32+8
	 srl	%sp, 0, %sp ! fixup 32-bit pointers
	NOTREACHED
	TA32
	.endm

	! fill a 64-bit register window
	.macro FILL64 label, as
	TRACEWIN
\label:
	wr	%g0, \as, %asi
	FILL	ldxa, %sp+BIAS, 8, %asi
	restored
	CLRTT 3
	retry
	NOTREACHED
	TA32
	.endm

	! fill a 32-bit register window
	.macro FILL32 label, as
	TRACEWIN
\label:
	wr	%g0, \as, %asi
	srl	%sp, 0, %sp ! fixup 32-bit pointers
	FILL	lda, %sp, 4, %asi
	restored
	CLRTT 4
	retry
	NOTREACHED
	TA32
	.endm

	! fill either 32-bit or 64-bit register window.
	.macro FILLBOTH label64,label32, as
	TRACEWIN
	andcc	%sp, 1, %i0
	bnz	(\label64)+4 ! See if it's a v9 stack or v8
	 wr	%g0, \as, %asi
	ba	(\label32)+8
	 srl	%sp, 0, %sp ! fixup 32-bit pointers
	NOTREACHED
	TA32
	.endm

	.globl	start, _C_LABEL(kernel_text)
	_C_LABEL(kernel_text) = start		! for kvm_mkdb(8)
start:
	/* Traps from TL=0 -- traps from user mode */
#define TABLE	user_
	.globl	_C_LABEL(trapbase)
_C_LABEL(trapbase):
	b dostart; nop; TA8	! 000 = reserved -- Use it to boot
	/* We should not get the next 5 traps */
	UTRAP 0x001		! 001 = POR Reset -- ROM should get this
	UTRAP 0x002		! 002 = WDR -- ROM should get this
	UTRAP 0x003		! 003 = XIR -- ROM should get this
	UTRAP 0x004		! 004 = SIR -- ROM should get this
	UTRAP 0x005		! 005 = RED state exception
	UTRAP 0x006; UTRAP 0x007
	VTRAP T_INST_EXCEPT, textfault	! 008 = instr. access exept
	VTRAP T_TEXTFAULT, textfault	! 009 = instr access MMU miss
	VTRAP T_INST_ERROR, textfault	! 00a = instr. access err
	UTRAP 0x00b; UTRAP 0x00c; UTRAP 0x00d; UTRAP 0x00e; UTRAP 0x00f
	TRAP T_ILLINST			! 010 = illegal instruction
	TRAP T_PRIVINST		! 011 = privileged instruction
	UTRAP 0x012			! 012 = unimplemented LDD
	UTRAP 0x013			! 013 = unimplemented STD
	UTRAP 0x014; UTRAP 0x015; UTRAP 0x016; UTRAP 0x017; UTRAP 0x018
	UTRAP 0x019; UTRAP 0x01a; UTRAP 0x01b; UTRAP 0x01c; UTRAP 0x01d
	UTRAP 0x01e; UTRAP 0x01f
	TRAP T_FPDISABLED		! 020 = fp instr, but EF bit off in psr
	VTRAP T_FP_IEEE_754, fp_exception		! 021 = ieee 754 exception
	VTRAP T_FP_OTHER, fp_exception		! 022 = other fp exception
	TRAP T_TAGOF			! 023 = tag overflow
	UCLEANWIN			! 024-027 = clean window trap
	TRAP T_DIV0			! 028 = divide by zero
	UTRAP 0x029			! 029 = internal processor error
	UTRAP 0x02a; UTRAP 0x02b; UTRAP 0x02c; UTRAP 0x02d; UTRAP 0x02e; UTRAP 0x02f
	VTRAP T_DATAFAULT, winfault	! 030 = data fetch fault
	UTRAP 0x031			! 031 = data MMU miss -- no MMU
	VTRAP T_DATA_ERROR, winfault	! 032 = data access error
	VTRAP T_DATA_PROT, winfault	! 033 = data protection fault
	TRAP T_ALIGN			! 034 = address alignment error -- we could fix it inline...
	TRAP T_LDDF_ALIGN		! 035 = LDDF address alignment error -- we could fix it inline...
	TRAP T_STDF_ALIGN		! 036 = STDF address alignment error -- we could fix it inline...
	TRAP T_PRIVACT			! 037 = privileged action
	UTRAP 0x038; UTRAP 0x039; UTRAP 0x03a; UTRAP 0x03b; UTRAP 0x03c;
	UTRAP 0x03d; UTRAP 0x03e; UTRAP 0x03f;
	VTRAP T_ASYNC_ERROR, winfault	! 040 = data fetch fault
	SOFTINT4U 1, IE_L1		! 041 = level 1 interrupt
	HARDINT4U 2			! 042 = level 2 interrupt
	HARDINT4U 3			! 043 = level 3 interrupt
	SOFTINT4U 4, IE_L4		! 044 = level 4 interrupt
	HARDINT4U 5			! 045 = level 5 interrupt
	SOFTINT4U 6, IE_L6		! 046 = level 6 interrupt
	HARDINT4U 7			! 047 = level 7 interrupt
	HARDINT4U 8			! 048 = level 8 interrupt
	HARDINT4U 9			! 049 = level 9 interrupt
	HARDINT4U 10			! 04a = level 10 interrupt
	HARDINT4U 11			! 04b = level 11 interrupt
	ZS_INTERRUPT4U			! 04c = level 12 (zs) interrupt
	HARDINT4U 13			! 04d = level 13 interrupt
	HARDINT4U 14			! 04e = level 14 interrupt
	HARDINT4U 15			! 04f = nonmaskable interrupt
	UTRAP 0x050; UTRAP 0x051; UTRAP 0x052; UTRAP 0x053; UTRAP 0x054; UTRAP 0x055
	UTRAP 0x056; UTRAP 0x057; UTRAP 0x058; UTRAP 0x059; UTRAP 0x05a; UTRAP 0x05b
	UTRAP 0x05c; UTRAP 0x05d; UTRAP 0x05e; UTRAP 0x05f
	VTRAP 0x060, interrupt_vector; ! 060 = interrupt vector
	TRAP T_PA_WATCHPT		! 061 = physical address data watchpoint
	TRAP T_VA_WATCHPT		! 062 = virtual address data watchpoint
	VTRAP T_ECCERR, cecc_catch	! 063 = Correctable ECC error
ufast_IMMU_miss:			! 064 = fast instr access MMU miss
	IMMU_MISS 6
ufast_DMMU_miss:			! 068 = fast data access MMU miss
	DMMU_MISS 7
ufast_DMMU_protection:			! 06c = fast data access MMU protection
	DMMU_PROT udprot
	UTRAP 0x070			! Implementation dependent traps
	UTRAP 0x071; UTRAP 0x072; UTRAP 0x073; UTRAP 0x074; UTRAP 0x075; UTRAP 0x076
	UTRAP 0x077; UTRAP 0x078; UTRAP 0x079; UTRAP 0x07a; UTRAP 0x07b; UTRAP 0x07c
	UTRAP 0x07d; UTRAP 0x07e; UTRAP 0x07f
d906 3
a908 3
	SPILL64 uspill8,ASI_AIUS	! 0x080 spill_0_normal -- used to save user windows in user mode
	SPILL32 uspill4,ASI_AIUS	! 0x084 spill_1_normal
	SPILLBOTH uspill8,uspill4,ASI_AIUS		! 0x088 spill_2_normal
d911 2
a912 2
#endif	/* DEBUG */
	UTRAP 0x08c; TA32	! 0x08c spill_3_normal
d914 4
a917 4
	SPILL64 kspill8,ASI_N	! 0x090 spill_4_normal -- used to save supervisor windows
	SPILL32 kspill4,ASI_N	! 0x094 spill_5_normal
	SPILLBOTH kspill8,kspill4,ASI_N	! 0x098 spill_6_normal
	UTRAP 0x09c; TA32	! 0x09c spill_7_normal
d919 8
a926 8
	SPILL64 uspillk8,ASI_AIUS	! 0x0a0 spill_0_other -- used to save user windows in supervisor mode
	SPILL32 uspillk4,ASI_AIUS	! 0x0a4 spill_1_other
	SPILLBOTH uspillk8,uspillk4,ASI_AIUS	! 0x0a8 spill_2_other
	UTRAP 0x0ac; TA32	! 0x0ac spill_3_other
	UTRAP 0x0b0; TA32	! 0x0b0 spill_4_other
	UTRAP 0x0b4; TA32	! 0x0b4 spill_5_other
	UTRAP 0x0b8; TA32	! 0x0b8 spill_6_other
	UTRAP 0x0bc; TA32	! 0x0bc spill_7_other
d928 4
a931 4
	FILL64 ufill8,ASI_AIUS ! 0x0c0 fill_0_normal -- used to fill windows when running user mode
	FILL32 ufill4,ASI_AIUS	! 0x0c4 fill_1_normal
	FILLBOTH ufill8,ufill4,ASI_AIUS	! 0x0c8 fill_2_normal
	UTRAP 0x0cc; TA32	! 0x0cc fill_3_normal
d933 4
a936 4
	FILL64 kfill8,ASI_N	! 0x0d0 fill_4_normal -- used to fill windows when running supervisor mode
	FILL32 kfill4,ASI_N	! 0x0d4 fill_5_normal
	FILLBOTH kfill8,kfill4,ASI_N	! 0x0d8 fill_6_normal
	UTRAP 0x0dc; TA32	! 0x0dc fill_7_normal
d938 8
a945 8
	FILL64 ufillk8,ASI_AIUS	! 0x0e0 fill_0_other
	FILL32 ufillk4,ASI_AIUS	! 0x0e4 fill_1_other
	FILLBOTH ufillk8,ufillk4,ASI_AIUS	! 0x0e8 fill_2_other
	UTRAP 0x0ec; TA32	! 0x0ec fill_3_other
	UTRAP 0x0f0; TA32	! 0x0f0 fill_4_other
	UTRAP 0x0f4; TA32	! 0x0f4 fill_5_other
	UTRAP 0x0f8; TA32	! 0x0f8 fill_6_other
	UTRAP 0x0fc; TA32	! 0x0fc fill_7_other
d949 1
a949 1
	STRAP 0x102; STRAP 0x103; STRAP 0x104; STRAP 0x105; STRAP 0x106; STRAP 0x107
d953 7
a959 7
	STRAP 0x10b; STRAP 0x10c; STRAP 0x10d; STRAP 0x10e; STRAP 0x10f;
	STRAP 0x110; STRAP 0x111; STRAP 0x112; STRAP 0x113; STRAP 0x114; STRAP 0x115; STRAP 0x116; STRAP 0x117
	STRAP 0x118; STRAP 0x119; STRAP 0x11a; STRAP 0x11b; STRAP 0x11c; STRAP 0x11d; STRAP 0x11e; STRAP 0x11f
	STRAP 0x120; STRAP 0x121; STRAP 0x122; STRAP 0x123; STRAP 0x124; STRAP 0x125; STRAP 0x126; STRAP 0x127
	STRAP 0x128; STRAP 0x129; STRAP 0x12a; STRAP 0x12b; STRAP 0x12c; STRAP 0x12d; STRAP 0x12e; STRAP 0x12f
	STRAP 0x130; STRAP 0x131; STRAP 0x132; STRAP 0x133; STRAP 0x134; STRAP 0x135; STRAP 0x136; STRAP 0x137
	STRAP 0x138; STRAP 0x139; STRAP 0x13a; STRAP 0x13b; STRAP 0x13c; STRAP 0x13d; STRAP 0x13e; STRAP 0x13f
d964 8
a971 8
	STRAP 0x144; STRAP 0x145; STRAP 0x146; STRAP 0x147
	STRAP 0x148; STRAP 0x149; STRAP 0x14a; STRAP 0x14b; STRAP 0x14c; STRAP 0x14d; STRAP 0x14e; STRAP 0x14f
	STRAP 0x150; STRAP 0x151; STRAP 0x152; STRAP 0x153; STRAP 0x154; STRAP 0x155; STRAP 0x156; STRAP 0x157
	STRAP 0x158; STRAP 0x159; STRAP 0x15a; STRAP 0x15b; STRAP 0x15c; STRAP 0x15d; STRAP 0x15e; STRAP 0x15f
	STRAP 0x160; STRAP 0x161; STRAP 0x162; STRAP 0x163; STRAP 0x164; STRAP 0x165; STRAP 0x166; STRAP 0x167
	STRAP 0x168; STRAP 0x169; STRAP 0x16a; STRAP 0x16b; STRAP 0x16c; STRAP 0x16d; STRAP 0x16e; STRAP 0x16f
	STRAP 0x170; STRAP 0x171; STRAP 0x172; STRAP 0x173; STRAP 0x174; STRAP 0x175; STRAP 0x176; STRAP 0x177
	STRAP 0x178; STRAP 0x179; STRAP 0x17a; STRAP 0x17b; STRAP 0x17c; STRAP 0x17d; STRAP 0x17e; STRAP 0x17f
d973 16
a988 16
	UTRAP 0x180; UTRAP 0x181; UTRAP 0x182; UTRAP 0x183; UTRAP 0x184; UTRAP 0x185; UTRAP 0x186; UTRAP 0x187
	UTRAP 0x188; UTRAP 0x189; UTRAP 0x18a; UTRAP 0x18b; UTRAP 0x18c; UTRAP 0x18d; UTRAP 0x18e; UTRAP 0x18f
	UTRAP 0x190; UTRAP 0x191; UTRAP 0x192; UTRAP 0x193; UTRAP 0x194; UTRAP 0x195; UTRAP 0x196; UTRAP 0x197
	UTRAP 0x198; UTRAP 0x199; UTRAP 0x19a; UTRAP 0x19b; UTRAP 0x19c; UTRAP 0x19d; UTRAP 0x19e; UTRAP 0x19f
	UTRAP 0x1a0; UTRAP 0x1a1; UTRAP 0x1a2; UTRAP 0x1a3; UTRAP 0x1a4; UTRAP 0x1a5; UTRAP 0x1a6; UTRAP 0x1a7
	UTRAP 0x1a8; UTRAP 0x1a9; UTRAP 0x1aa; UTRAP 0x1ab; UTRAP 0x1ac; UTRAP 0x1ad; UTRAP 0x1ae; UTRAP 0x1af
	UTRAP 0x1b0; UTRAP 0x1b1; UTRAP 0x1b2; UTRAP 0x1b3; UTRAP 0x1b4; UTRAP 0x1b5; UTRAP 0x1b6; UTRAP 0x1b7
	UTRAP 0x1b8; UTRAP 0x1b9; UTRAP 0x1ba; UTRAP 0x1bb; UTRAP 0x1bc; UTRAP 0x1bd; UTRAP 0x1be; UTRAP 0x1bf
	UTRAP 0x1c0; UTRAP 0x1c1; UTRAP 0x1c2; UTRAP 0x1c3; UTRAP 0x1c4; UTRAP 0x1c5; UTRAP 0x1c6; UTRAP 0x1c7
	UTRAP 0x1c8; UTRAP 0x1c9; UTRAP 0x1ca; UTRAP 0x1cb; UTRAP 0x1cc; UTRAP 0x1cd; UTRAP 0x1ce; UTRAP 0x1cf
	UTRAP 0x1d0; UTRAP 0x1d1; UTRAP 0x1d2; UTRAP 0x1d3; UTRAP 0x1d4; UTRAP 0x1d5; UTRAP 0x1d6; UTRAP 0x1d7
	UTRAP 0x1d8; UTRAP 0x1d9; UTRAP 0x1da; UTRAP 0x1db; UTRAP 0x1dc; UTRAP 0x1dd; UTRAP 0x1de; UTRAP 0x1df
	UTRAP 0x1e0; UTRAP 0x1e1; UTRAP 0x1e2; UTRAP 0x1e3; UTRAP 0x1e4; UTRAP 0x1e5; UTRAP 0x1e6; UTRAP 0x1e7
	UTRAP 0x1e8; UTRAP 0x1e9; UTRAP 0x1ea; UTRAP 0x1eb; UTRAP 0x1ec; UTRAP 0x1ed; UTRAP 0x1ee; UTRAP 0x1ef
	UTRAP 0x1f0; UTRAP 0x1f1; UTRAP 0x1f2; UTRAP 0x1f3; UTRAP 0x1f4; UTRAP 0x1f5; UTRAP 0x1f6; UTRAP 0x1f7
	UTRAP 0x1f8; UTRAP 0x1f9; UTRAP 0x1fa; UTRAP 0x1fb; UTRAP 0x1fc; UTRAP 0x1fd; UTRAP 0x1fe; UTRAP 0x1ff
d994 1
a994 1
	UTRAP 0x000		! 000 = reserved -- Use it to boot
d996 6
a1001 6
	UTRAP 0x001		! 001 = POR Reset -- ROM should get this
	UTRAP 0x002		! 002 = WDR Watchdog -- ROM should get this
	UTRAP 0x003		! 003 = XIR -- ROM should get this
	UTRAP 0x004		! 004 = SIR -- ROM should get this
	UTRAP 0x005		! 005 = RED state exception
	UTRAP 0x006; UTRAP 0x007
d1003 46
a1048 19
	VTRAP T_INST_EXCEPT, textfault	! 008 = instr. access exept
	VTRAP T_TEXTFAULT, textfault	! 009 = instr access MMU miss -- no MMU
	VTRAP T_INST_ERROR, textfault	! 00a = instr. access err
	UTRAP 0x00b; UTRAP 0x00c; UTRAP 0x00d; UTRAP 0x00e; UTRAP 0x00f
	TRAP T_ILLINST			! 010 = illegal instruction
	TRAP T_PRIVINST		! 011 = privileged instruction
	UTRAP 0x012			! 012 = unimplemented LDD
	UTRAP 0x013			! 013 = unimplemented STD
	UTRAP 0x014; UTRAP 0x015; UTRAP 0x016; UTRAP 0x017; UTRAP 0x018
	UTRAP 0x019; UTRAP 0x01a; UTRAP 0x01b; UTRAP 0x01c; UTRAP 0x01d
	UTRAP 0x01e; UTRAP 0x01f
	TRAP T_FPDISABLED		! 020 = fp instr, but EF bit off in psr
	VTRAP T_FP_IEEE_754, fp_exception		! 021 = ieee 754 exception
	VTRAP T_FP_OTHER, fp_exception		! 022 = other fp exception
	TRAP T_TAGOF			! 023 = tag overflow
	KCLEANWIN			! 024-027 = clean window trap
	TRAP T_DIV0			! 028 = divide by zero
	UTRAP 0x029			! 029 = internal processor error
	UTRAP 0x02a; UTRAP 0x02b; UTRAP 0x02c; UTRAP 0x02d; UTRAP 0x02e; UTRAP 0x02f
d1050 5
a1054 5
	VTRAP T_DATAFAULT, winfault	! 030 = data fetch fault
	UTRAP 0x031			! 031 = data MMU miss -- no MMU
	VTRAP T_DATA_ERROR, winfault	! 032 = data fetch fault
	VTRAP T_DATA_PROT, winfault	! 033 = data fetch fault
	TRAP T_ALIGN			! 034 = address alignment error -- we could fix it inline...
d1056 17
a1072 17
	TRAP T_LDDF_ALIGN		! 035 = LDDF address alignment error -- we could fix it inline...
	TRAP T_STDF_ALIGN		! 036 = STDF address alignment error -- we could fix it inline...
	TRAP T_PRIVACT			! 037 = privileged action
	UTRAP 0x038; UTRAP 0x039; UTRAP 0x03a; UTRAP 0x03b; UTRAP 0x03c;
	UTRAP 0x03d; UTRAP 0x03e; UTRAP 0x03f;
	VTRAP T_ASYNC_ERROR, winfault	! 040 = data fetch fault
	SOFTINT4U 1, IE_L1		! 041 = level 1 interrupt
	HARDINT4U 2			! 042 = level 2 interrupt
	HARDINT4U 3			! 043 = level 3 interrupt
	SOFTINT4U 4, IE_L4		! 044 = level 4 interrupt
	HARDINT4U 5			! 045 = level 5 interrupt
	SOFTINT4U 6, IE_L6		! 046 = level 6 interrupt
	HARDINT4U 7			! 047 = level 7 interrupt
	HARDINT4U 8			! 048 = level 8 interrupt
	HARDINT4U 9			! 049 = level 9 interrupt
	HARDINT4U 10			! 04a = level 10 interrupt
	HARDINT4U 11			! 04b = level 11 interrupt
d1074 10
a1083 10
	HARDINT4U 13			! 04d = level 13 interrupt
	HARDINT4U 14			! 04e = level 14 interrupt
	HARDINT4U 15			! 04f = nonmaskable interrupt
	UTRAP 0x050; UTRAP 0x051; UTRAP 0x052; UTRAP 0x053; UTRAP 0x054; UTRAP 0x055
	UTRAP 0x056; UTRAP 0x057; UTRAP 0x058; UTRAP 0x059; UTRAP 0x05a; UTRAP 0x05b
	UTRAP 0x05c; UTRAP 0x05d; UTRAP 0x05e; UTRAP 0x05f
	VTRAP 0x060, interrupt_vector; ! 060 = interrupt vector
	TRAP T_PA_WATCHPT		! 061 = physical address data watchpoint
	TRAP T_VA_WATCHPT		! 062 = virtual address data watchpoint
	VTRAP T_ECCERR, cecc_catch	! 063 = Correctable ECC error
d1085 17
a1101 1
	IMMU_MISS 9
d1103 23
a1125 1
	DMMU_MISS_2
d1127 14
a1140 5
	DMMU_PROT kdprot
	UTRAP 0x070			! Implementation dependent traps
	UTRAP 0x071; UTRAP 0x072; UTRAP 0x073; UTRAP 0x074; UTRAP 0x075; UTRAP 0x076
	UTRAP 0x077; UTRAP 0x078; UTRAP 0x079; UTRAP 0x07a; UTRAP 0x07b; UTRAP 0x07c
	UTRAP 0x07d; UTRAP 0x07e; UTRAP 0x07f
d1142 4
a1145 4
	SPILL64 1,ASI_AIUS	! 0x080 spill_0_normal -- used to save user windows
	SPILL32 2,ASI_AIUS	! 0x084 spill_1_normal
	SPILLBOTH 1b,2b,ASI_AIUS	! 0x088 spill_2_normal
	UTRAP 0x08c; TA32	! 0x08c spill_3_normal
d1147 4
a1150 4
	SPILL64 1,ASI_N	! 0x090 spill_4_normal -- used to save supervisor windows
	SPILL32 2,ASI_N	! 0x094 spill_5_normal
	SPILLBOTH 1b,2b,ASI_N	! 0x098 spill_6_normal
	UTRAP 0x09c; TA32	! 0x09c spill_7_normal
d1152 8
a1159 8
	SPILL64 1,ASI_AIUS	! 0x0a0 spill_0_other -- used to save user windows in nucleus mode
	SPILL32 2,ASI_AIUS	! 0x0a4 spill_1_other
	SPILLBOTH 1b,2b,ASI_AIUS	! 0x0a8 spill_2_other
	UTRAP 0x0ac; TA32	! 0x0ac spill_3_other
	UTRAP 0x0b0; TA32	! 0x0b0 spill_4_other
	UTRAP 0x0b4; TA32	! 0x0b4 spill_5_other
	UTRAP 0x0b8; TA32	! 0x0b8 spill_6_other
	UTRAP 0x0bc; TA32	! 0x0bc spill_7_other
d1161 4
a1164 4
	FILL64 1,ASI_AIUS	! 0x0c0 fill_0_normal -- used to fill windows when running nucleus mode from user
	FILL32 2,ASI_AIUS	! 0x0c4 fill_1_normal
	FILLBOTH 1b,2b,ASI_AIUS	! 0x0c8 fill_2_normal
	UTRAP 0x0cc; TA32	! 0x0cc fill_3_normal
d1166 4
a1169 4
	FILL64 1,ASI_N		! 0x0d0 fill_4_normal -- used to fill windows when running nucleus mode from supervisor
	FILL32 2,ASI_N		! 0x0d4 fill_5_normal
	FILLBOTH 1b,2b,ASI_N	! 0x0d8 fill_6_normal
	UTRAP 0x0dc; TA32	! 0x0dc fill_7_normal
d1171 8
a1178 8
	FILL64 1,ASI_AIUS	! 0x0e0 fill_0_other -- used to fill user windows when running nucleus mode -- will we ever use this?
	FILL32 2,ASI_AIUS	! 0x0e4 fill_1_other
	FILLBOTH 1b,2b,ASI_AIUS! 0x0e8 fill_2_other
	UTRAP 0x0ec; TA32	! 0x0ec fill_3_other
	UTRAP 0x0f0; TA32	! 0x0f0 fill_4_other
	UTRAP 0x0f4; TA32	! 0x0f4 fill_5_other
	UTRAP 0x0f8; TA32	! 0x0f8 fill_6_other
	UTRAP 0x0fc; TA32	! 0x0fc fill_7_other
d1182 1
a1182 1
	STRAP 0x102; STRAP 0x103; STRAP 0x104; STRAP 0x105; STRAP 0x106; STRAP 0x107
d1186 15
a1200 15
	STRAP 0x10b; STRAP 0x10c; STRAP 0x10d; STRAP 0x10e; STRAP 0x10f;
	STRAP 0x110; STRAP 0x111; STRAP 0x112; STRAP 0x113; STRAP 0x114; STRAP 0x115; STRAP 0x116; STRAP 0x117
	STRAP 0x118; STRAP 0x119; STRAP 0x11a; STRAP 0x11b; STRAP 0x11c; STRAP 0x11d; STRAP 0x11e; STRAP 0x11f
	STRAP 0x120; STRAP 0x121; STRAP 0x122; STRAP 0x123; STRAP 0x124; STRAP 0x125; STRAP 0x126; STRAP 0x127
	STRAP 0x128; STRAP 0x129; STRAP 0x12a; STRAP 0x12b; STRAP 0x12c; STRAP 0x12d; STRAP 0x12e; STRAP 0x12f
	STRAP 0x130; STRAP 0x131; STRAP 0x132; STRAP 0x133; STRAP 0x134; STRAP 0x135; STRAP 0x136; STRAP 0x137
	STRAP 0x138; STRAP 0x139; STRAP 0x13a; STRAP 0x13b; STRAP 0x13c; STRAP 0x13d; STRAP 0x13e; STRAP 0x13f
	STRAP 0x140; STRAP 0x141; STRAP 0x142; STRAP 0x143; STRAP 0x144; STRAP 0x145; STRAP 0x146; STRAP 0x147
	STRAP 0x148; STRAP 0x149; STRAP 0x14a; STRAP 0x14b; STRAP 0x14c; STRAP 0x14d; STRAP 0x14e; STRAP 0x14f
	STRAP 0x150; STRAP 0x151; STRAP 0x152; STRAP 0x153; STRAP 0x154; STRAP 0x155; STRAP 0x156; STRAP 0x157
	STRAP 0x158; STRAP 0x159; STRAP 0x15a; STRAP 0x15b; STRAP 0x15c; STRAP 0x15d; STRAP 0x15e; STRAP 0x15f
	STRAP 0x160; STRAP 0x161; STRAP 0x162; STRAP 0x163; STRAP 0x164; STRAP 0x165; STRAP 0x166; STRAP 0x167
	STRAP 0x168; STRAP 0x169; STRAP 0x16a; STRAP 0x16b; STRAP 0x16c; STRAP 0x16d; STRAP 0x16e; STRAP 0x16f
	STRAP 0x170; STRAP 0x171; STRAP 0x172; STRAP 0x173; STRAP 0x174; STRAP 0x175; STRAP 0x176; STRAP 0x177
	STRAP 0x178; STRAP 0x179; STRAP 0x17a; STRAP 0x17b; STRAP 0x17c; STRAP 0x17d; STRAP 0x17e; STRAP 0x17f
d1202 16
a1217 16
	UTRAP 0x180; UTRAP 0x181; UTRAP 0x182; UTRAP 0x183; UTRAP 0x184; UTRAP 0x185; UTRAP 0x186; UTRAP 0x187
	UTRAP 0x188; UTRAP 0x189; UTRAP 0x18a; UTRAP 0x18b; UTRAP 0x18c; UTRAP 0x18d; UTRAP 0x18e; UTRAP 0x18f
	UTRAP 0x190; UTRAP 0x191; UTRAP 0x192; UTRAP 0x193; UTRAP 0x194; UTRAP 0x195; UTRAP 0x196; UTRAP 0x197
	UTRAP 0x198; UTRAP 0x199; UTRAP 0x19a; UTRAP 0x19b; UTRAP 0x19c; UTRAP 0x19d; UTRAP 0x19e; UTRAP 0x19f
	UTRAP 0x1a0; UTRAP 0x1a1; UTRAP 0x1a2; UTRAP 0x1a3; UTRAP 0x1a4; UTRAP 0x1a5; UTRAP 0x1a6; UTRAP 0x1a7
	UTRAP 0x1a8; UTRAP 0x1a9; UTRAP 0x1aa; UTRAP 0x1ab; UTRAP 0x1ac; UTRAP 0x1ad; UTRAP 0x1ae; UTRAP 0x1af
	UTRAP 0x1b0; UTRAP 0x1b1; UTRAP 0x1b2; UTRAP 0x1b3; UTRAP 0x1b4; UTRAP 0x1b5; UTRAP 0x1b6; UTRAP 0x1b7
	UTRAP 0x1b8; UTRAP 0x1b9; UTRAP 0x1ba; UTRAP 0x1bb; UTRAP 0x1bc; UTRAP 0x1bd; UTRAP 0x1be; UTRAP 0x1bf
	UTRAP 0x1c0; UTRAP 0x1c1; UTRAP 0x1c2; UTRAP 0x1c3; UTRAP 0x1c4; UTRAP 0x1c5; UTRAP 0x1c6; UTRAP 0x1c7
	UTRAP 0x1c8; UTRAP 0x1c9; UTRAP 0x1ca; UTRAP 0x1cb; UTRAP 0x1cc; UTRAP 0x1cd; UTRAP 0x1ce; UTRAP 0x1cf
	UTRAP 0x1d0; UTRAP 0x1d1; UTRAP 0x1d2; UTRAP 0x1d3; UTRAP 0x1d4; UTRAP 0x1d5; UTRAP 0x1d6; UTRAP 0x1d7
	UTRAP 0x1d8; UTRAP 0x1d9; UTRAP 0x1da; UTRAP 0x1db; UTRAP 0x1dc; UTRAP 0x1dd; UTRAP 0x1de; UTRAP 0x1df
	UTRAP 0x1e0; UTRAP 0x1e1; UTRAP 0x1e2; UTRAP 0x1e3; UTRAP 0x1e4; UTRAP 0x1e5; UTRAP 0x1e6; UTRAP 0x1e7
	UTRAP 0x1e8; UTRAP 0x1e9; UTRAP 0x1ea; UTRAP 0x1eb; UTRAP 0x1ec; UTRAP 0x1ed; UTRAP 0x1ee; UTRAP 0x1ef
	UTRAP 0x1f0; UTRAP 0x1f1; UTRAP 0x1f2; UTRAP 0x1f3; UTRAP 0x1f4; UTRAP 0x1f5; UTRAP 0x1f6; UTRAP 0x1f7
	UTRAP 0x1f8; UTRAP 0x1f9; UTRAP 0x1fa; UTRAP 0x1fb; UTRAP 0x1fc; UTRAP 0x1fd; UTRAP 0x1fe; UTRAP 0x1ff
d1230 1
a1230 1
	set	EINTSTACK-BIAS-CC64FSZ, %l0
d1246 4
a1249 4
	.macro CHKREG r
	ldx	[%o0 + 8*1], %o1
	cmp	\r, %o1
	stx	%o0, [%o0]
a1250 1
	.endm
d1258 8
a1265 3
	.irpc n,01234567
		stx	%g\n, [%o0 + 8*\n]
	.endr
d1274 7
a1280 3
	.irpc n,1234567
		CHKREG %g\n
	.endr
d1289 4
a1292 5
	.macro CHKPT r1,r2,val
	sethi	%hi(DATA_START), \r1
	mov	\val, \r2
	stb	\r2, [\r1 + 0x21]
	.endm
d1352 4
a1355 4
#else	/* DEBUG */
	.macro CHKPT r1,r2,val
	.endm
#endif	/* DEBUG */
d1377 21
a1397 24
	! set stack pointer redzone to base+minstack; alters base
.macro	SET_SP_REDZONE base, tmp
	add	\base, REDSIZE, \base
	sethi	%hi(_C_LABEL(redzone)), \tmp
	stx	\base, [\tmp + %lo(_C_LABEL(redzone))]
	.endm

	! variant with a constant
.macro	SET_SP_REDZONE_CONST const,  tmp1,  tmp2
	set	(\const) + REDSIZE, \tmp1
	sethi	%hi(_C_LABEL(redzone)), \tmp2
	stx	\tmp1, [\tmp2 + %lo(_C_LABEL(redzone))]
	.endm

	! check stack pointer against redzone (uses two temps)
.macro	CHECK_SP_REDZONE t1,  t2
	sethi	KERNBASE, \t1
	cmp	%sp, \t1
	blu,pt	%xcc, 7f
	 sethi	%hi(_C_LABEL(redzone)), \t1
	ldx	[\t1 + %lo(_C_LABEL(redzone))], \t2
	cmp	%sp, \t2	! if sp >= \t2, not in red zone
	blu	panic_red
	nop	! and can continue normally
a1398 1
	.endm
d1415 1
a1415 1
#else	/* DEBUG_NOTDEF */
d1417 4
a1420 7
.macro	SET_SP_REDZONE base, tmp
.endm
.macro	SET_SP_REDZONE_CONST const, t1, t2
.endm
.macro	CHECK_SP_REDZONE t1, t2
.endm
#endif	/* DEBUG_NOTDEF */
d1439 32
a1470 33
! hm.  nothing uses this right now... mdw
	.macro TRACEIT tt,r3,r4,r2,r6,r7
	set	trap_trace, \r2
	lduw	[\r2+TRACEDIS], \r4
	brnz,pn	\r4, 1f
	 lduw	[\r2+TRACEPTR], \r3
	rdpr	%tl, \r4
	cmp	\r4, 1
	sllx	\r4, 13, \r4
	rdpr	%pil, \r6
	or	\r4, %g5, \r4
	mov	%g0, %g5
	andncc	\r3, (TRACESIZ-1), %g0	! At end of buffer?
	sllx	\r6, 9, \r6
	or	\r6, \r4, \r4
	movnz	%icc, %g0, \r3		! Wrap buffer if needed
	rdpr	%tstate, \r6
	rdpr	%tpc, \r7
	sth	\r4, [\r2+\r3]
	inc	2, \r3
	sth	%g5, [\r2+\r3]
	inc	2, \r3
	stw	\r6, [\r2+\r3]
	inc	4, \r3
	stw	%sp, [\r2+\r3]
	inc	4, \r3
	stw	\r7, [\r2+\r3]
	inc	4, \r3
	mov	TLB_TAG_ACCESS, \r7
	ldxa	[\r7] ASI_DMMU, \r7
	stw	\r7, [\r2+\r3]
	inc	4, \r3
	stw	\r3, [\r2+TRACEPTR]
a1471 1
.endm
d1496 1
a1496 1
	ldx	[%g6], %g6
d1502 1
a1502 1
	ldx	[%g6+P_PID], %g5	! Load PID
d1505 1
a1505 1
	ldx	[%g6], %g6
d1588 1
a1588 1
#endif	/*  */
d1607 1
a1607 1
 * trap frame so we don't trap during the TRAP_SETUP operation.  There
d1684 75
a1758 21
	.macro	TRAP_SETUP stackspace
	sethi	%hi(CPCB), %g6
	sethi	%hi((\stackspace)), %g5

	ldx	[%g6 + %lo(CPCB)], %g6
	sethi	%hi(USPACE), %g7		! Always multiple of page size
	or	%g5, %lo((\stackspace)), %g5

	sra	%g5, 0, %g5			! Sign extend the damn thing

	add	%g6, %g7, %g6
	rdpr	%wstate, %g7			! Find if we're from user mode

	sub	%g7, WSTATE_KERN, %g7		! Compare & leave in register
	movrz	%g7, %sp, %g6			! Select old (kernel) stack or base of kernel stack
	btst	1, %g6				! Fixup 64-bit stack if necessary
	bnz,pt	%icc, 1f
	 add	%g6, %g5, %g6			! Allocate a stack frame
	inc	-BIAS, %g6
	nop
	nop
a1759 29
	SPILL stx, %g6 + CC64FSZ + BIAS + TF_L, 8, ! save local + in
	save	%g6, 0, %sp			! If we fault we should come right back here
	stx	%i0, [%sp + CC64FSZ + BIAS + TF_O + (0*8)] ! Save out registers to trap frame
	stx	%i1, [%sp + CC64FSZ + BIAS + TF_O + (1*8)]
	stx	%i2, [%sp + CC64FSZ + BIAS + TF_O + (2*8)]
	stx	%i3, [%sp + CC64FSZ + BIAS + TF_O + (3*8)]
	stx	%i4, [%sp + CC64FSZ + BIAS + TF_O + (4*8)]
	stx	%i5, [%sp + CC64FSZ + BIAS + TF_O + (5*8)]

	stx	%i6, [%sp + CC64FSZ + BIAS + TF_O + (6*8)]
	brz,pt	%g7, 1f			! If we were in kernel mode start saving globals
	 stx	%i7, [%sp + CC64FSZ + BIAS + TF_O + (7*8)]
	mov	CTX_PRIMARY, %g7

	! came from user mode -- switch to kernel mode stack
	rdpr	%canrestore, %g5		! Fixup register window state registers

	wrpr	%g0, 0, %canrestore

	wrpr	%g0, %g5, %otherwin

	wrpr	%g0, WSTATE_KERN, %wstate	! Enable kernel mode window traps -- now we can trap again

	stxa	%g0, [%g7] ASI_DMMU		! Switch MMU to kernel primary context
	sethi	%hi(KERNBASE), %g5
	membar	#Sync				! XXXX Should be taken care of by flush
	flush	%g5				! Some convenient address that won't trap
1:
	.endm
d1769 145
a1913 30
	.macro	INTR_SETUP stackspace
	rdpr	%wstate, %g7			! Find if we're from user mode

	sethi	%hi(EINTSTACK-BIAS), %g6
	sethi	%hi(EINTSTACK-INTSTACK), %g4

	or	%g6, %lo(EINTSTACK-BIAS), %g6	! Base of interrupt stack
	dec	%g4				! Make it into a mask

	sub	%g6, %sp, %g1			! Offset from interrupt stack
	sethi	%hi((\stackspace)), %g5

	or	%g5, %lo((\stackspace)), %g5

	andn	%g1, %g4, %g4			! Are we out of the interrupt stack range?
	xor	%g7, WSTATE_KERN, %g3

	sra	%g5, 0, %g5			! Sign extend the damn thing
	or	%g3, %g4, %g4			! Definitely not off the interrupt stack

	movrz	%g4, %sp, %g6

	add	%g6, %g5, %g5			! Allocate a stack frame
	btst	1, %g6
	bnz,pt	%icc, 1f

	 mov	%g5, %g6

	add	%g5, -BIAS, %g6

a1914 7
	SPILL stx, %g6 + CC64FSZ + BIAS + TF_L, 8,  ! save local+in to trap frame
	save	%g6, 0, %sp			! If we fault we should come right back here
	stx	%i0, [%sp + CC64FSZ + BIAS + TF_O + (0*8)] ! Save out registers to trap frame
	stx	%i1, [%sp + CC64FSZ + BIAS + TF_O + (1*8)]
	stx	%i2, [%sp + CC64FSZ + BIAS + TF_O + (2*8)]
	stx	%i3, [%sp + CC64FSZ + BIAS + TF_O + (3*8)]
	stx	%i4, [%sp + CC64FSZ + BIAS + TF_O + (4*8)]
d1916 69
a1984 26
	stx	%i5, [%sp + CC64FSZ + BIAS + TF_O + (5*8)]
	stx	%i6, [%sp + CC64FSZ + BIAS + TF_O + (6*8)]
	stx	%i6, [%sp + CC64FSZ + BIAS + TF_G + (0*8)]	! Save fp in clockframe->cf_fp
	brz,pt	%g3, 1f				! If we were in kernel mode start saving globals
	 stx	%i7, [%sp + CC64FSZ + BIAS + TF_O + (7*8)]
	! came from user mode -- switch to kernel mode stack
	 rdpr	%otherwin, %g5			! Has this already been done?

!	tst %g5; tnz %xcc, 1; nop; ! DEBUG -- this should _NEVER_ happen
	brnz,pn	%g5, 1f			! Don't set this twice

	 rdpr	%canrestore, %g5		! Fixup register window state registers

	wrpr	%g0, 0, %canrestore

	wrpr	%g0, %g5, %otherwin

	sethi	%hi(KERNBASE), %g5
	mov	CTX_PRIMARY, %g7

	wrpr	%g0, WSTATE_KERN, %wstate	! Enable kernel mode window traps -- now we can trap again

	stxa	%g0, [%g7] ASI_DMMU		! Switch MMU to kernel primary context
	membar	#Sync				! XXXX Should be taken care of by flush

	flush	%g5				! Some convenient address that won't trap
d1986 1
a1986 2
	.endm
	
d2005 1
a2005 1
	DLFLUSH %g4,%g5
d2007 1
a2007 1
	DLFLUSH2 %g5
d2014 1
a2014 1
	DLFLUSH %g4,%g5
d2016 1
a2016 1
	DLFLUSH2 %g5
d2023 1
a2023 1
	DLFLUSH %g4,%g5
d2025 1
a2025 1
	DLFLUSH2 %g5
d2040 1
a2040 1
#endif	/* DEBUG */
d2060 1
a2060 1
	ldx	[%g4 + %lo(_C_LABEL(ctxbusy))], %g4
d2077 1
a2077 1
	DLFLUSH %g4,%g6
d2079 1
a2079 1
	DLFLUSH2 %g6
d2109 1
a2109 1
#endif	/* DEBUG */
d2132 1
a2132 1
#endif	/* DEBUG */
d2138 1
a2138 1
#endif	/* TRAPSTATS */
d2182 1
a2182 1
#endif	/* TRAPSTATS */
d2188 1
a2188 1
	ldx	[%g4 + %lo(_C_LABEL(ctxbusy))], %g4
d2211 1
a2211 1
#endif	/* DEBUG */
d2255 1
a2255 1
#endif	/* DEBUG */
d2266 1
a2266 1
#endif	/* 0 */
d2321 2
a2322 2
	CHKPT %g4,%g7,0x19
#endif	/* DEBUG */
d2332 1
a2332 1
	CHKPT %g4,%g7,0x20
d2349 1
a2349 1
	set	EINTSTACK+USPACE+CC64FSZ-BIAS, %fp ! Set the frame pointer to the middle of the idle stack
d2356 1
a2356 1
#endif	/* 1 */
d2371 1
a2371 1
#endif	/* TRAPSTATS */
d2381 1
a2381 1
	 * kernel window and a user window state.  If we do a TRAP_SETUP now,
d2398 1
a2398 1
#endif	/* TRAPSTATS */
d2417 1
a2417 1
	CHKPT %g5,%g7,0xe
d2421 1
a2421 1
#else	/* 0 /* Need to switch over to new stuff to fix WDR bug */ */
d2428 1
a2428 1
	CHKPT %g5,%g7,0xe
d2452 1
a2452 1
#endif	/* TRAPS_USE_IG */
d2458 2
a2459 2
	CHKPT %g4,%g7,0xf
#endif	/* DEBUG */
d2467 1
a2467 1
	TRAP_SETUP -CC64FSZ-TF_SIZE
d2471 1
a2471 1
#endif	/* 0 /* Need to switch over to new stuff to fix WDR bug */ */
d2487 1
a2487 1

d2490 53
a2542 1
#endif	/* 1 */
d2544 1
a2544 1
	ldx	[%g6 + %lo(CPCB)], %g6	! This is in the locked TLB and should not fault
d2550 1
a2550 1
#endif	/* TRAPSTATS */
d2555 2
a2556 2
	CHKPT %g5,%g7,0x11
#endif	/* DEBUG */
d2567 1
a2567 1
	ldx	[%g1 + %lo(_C_LABEL(ctxbusy))], %g1	! Load start of ctxbusy
d2574 1
a2574 1
#endif	/* DEBUG */
d2580 1
a2580 1
	DLFLUSH %g1,%g7
d2582 1
a2582 1
	DLFLUSH2 %g7
d2589 1
a2589 1
	DLFLUSH %g1,%g7
d2591 1
a2591 1
	DLFLUSH2 %g7
d2598 1
a2598 1
	DLFLUSH %g7,%g1
d2600 1
a2600 1
	DLFLUSH2 %g1
d2616 1
a2616 1
	DLFLUSH %g7,%g5
d2618 1
a2618 1
	DLFLUSH2 %g5
d2624 2
a2625 2
#endif	/* NOTDEF_DEBUG */
	CHKPT %g5,%g7,0x12
d2637 1
a2637 1
	CHKPT %g5,%g7,0x13
d2639 1
a2639 1
	DLFLUSH %g7,%g5
d2641 1
a2641 1
	DLFLUSH2 %g5
d2645 1
a2645 1
#endif	/* DEBUG */
d2651 1
a2651 1
!	CHKPT %g4,%g7,0x10	! Checkpoint
d2655 1
a2655 1
#endif	/* DEBUG */
d2668 2
a2669 2
	set	panicstack-CC64FSZ-BIAS, %sp		! Use panic stack.
#else	/* DEBUG */
d2671 3
a2673 3
	ldx	[%sp], %sp
	add	%sp, -CC64FSZ-BIAS, %sp			! Overwrite proc 0's stack.
#endif	/* DEBUG */
d2715 1
a2715 1
	CHKPT %g5,%g1,0x14
d2731 2
a2732 2
#endif	/* NOT_DEBUG */
#else	/* 0 */
d2764 3
d2775 2
a2776 2
#endif	/* NOT_DEBUG */
#endif	/* 0 */
d2796 2
a2797 2
#endif	/* NOTDEF_DEBUG */
	CHKPT %g5,%g1,0x15
d2803 1
a2803 1
	CHKPT %g2,%g5,0x16
a2807 1
	sethi	%hi((2*NBPG)-8), %g7
d2809 1
a2809 1
	 or	%g7, %lo((2*NBPG)-8), %g7
d2817 1
a2817 1
	CHKPT %g2,%g1,0x17
d2819 1
a2819 1
#endif	/* DEBUG */
d2848 1
a2848 1
#endif	/* 1 */
d2851 1
a2851 1
	CHKPT %g2,%g1,0x18
d2855 1
a2855 1
#endif	/* DEBUG */
d2873 50
a2922 1
#endif	/* NOTDEF_DEBUG */
d2928 1
a2928 1
#endif	/* TRAPSTATS */
d2954 1
a2954 1
#endif	/* TRAPS_USE_IG */
d2977 1
a2977 1
#endif	/* TRAPS_USE_IG */
d2983 2
a2984 2
	CHKPT %g4,%g7,0xf
#endif	/* DEBUG */
d2992 1
a2992 1
	TRAP_SETUP -CC64FSZ-TF_SIZE
d2994 2
a2995 2
	INCR _C_LABEL(uvmexp)+V_FAULTS			! cnt.v_faults++ (clobbers %o0,%o1,%o2) should not fault
!	ldx	[%sp + CC64FSZ + BIAS + TF_FAULT], %g1		! DEBUG make sure this has not changed
d3006 4
d3012 5
a3016 1
	stx	%g1, [%sp + CC64FSZ + BIAS + TF_G + (1*8)]	! save g1
d3018 2
a3019 1
	stx	%g2, [%sp + CC64FSZ + BIAS + TF_G + (2*8)]	! save g2
d3021 1
a3021 1
	stx	%g3, [%sp + CC64FSZ + BIAS + TF_G + (3*8)]	! (sneak g3 in here)
d3023 1
a3023 1
	stx	%g4, [%sp + CC64FSZ + BIAS + TF_G + (4*8)]	! sneak in g4
d3025 1
a3025 1
	stx	%g5, [%sp + CC64FSZ + BIAS + TF_G + (5*8)]	! sneak in g5
d3027 1
a3027 1
	stx	%g6, [%sp + CC64FSZ + BIAS + TF_G + (6*8)]	! sneak in g6
d3029 1
a3029 1
	stx	%g7, [%sp + CC64FSZ + BIAS + TF_G + (7*8)]	! sneak in g7
d3035 5
a3039 5
#endif	/* DEBUG */
	sth	%o1, [%sp + CC64FSZ + BIAS + TF_TT]
	stx	%g1, [%sp + CC64FSZ + BIAS + TF_TSTATE]		! set tf.tf_psr, tf.tf_pc
	stx	%g2, [%sp + CC64FSZ + BIAS + TF_PC]		! set tf.tf_npc
	stx	%g3, [%sp + CC64FSZ + BIAS + TF_NPC]
d3042 2
a3043 2
	stb	%g5, [%sp + CC64FSZ + BIAS + TF_PIL]
	stb	%g5, [%sp + CC64FSZ + BIAS + TF_OLDPIL]
d3049 1
a3049 1
	CHKPT %g1,%g3,0x21
d3051 2
a3052 2
#else	/* 1 */
	CHKPT %g1,%g3,0x21
d3054 1
a3054 1
#endif	/* 1 */
d3059 1
a3059 1
	ldx	[%o7], %o7
d3074 1
a3074 1
#endif	/* NOTDEF_DEBUG */
d3088 1
a3088 1
	st	%g4, [%sp + CC64FSZ + BIAS + TF_Y]
d3097 1
a3097 1
	 add	%sp, CC64FSZ + BIAS, %o0	! (argument: &tf)
d3100 1
a3100 1
	CHKPT %o1,%o2,1
d3107 1
a3107 1
#endif	/* TRAPSTATS */
d3109 1
a3109 1
	 ldx	[%sp + CC64FSZ + BIAS + TF_TSTATE], %g1		! Load this for return_from_trap
d3115 1
a3115 1
	 add	%sp, CC64FSZ + BIAS, %o0	! (argument: &tf)
d3149 1
a3149 1
#endif	/* TRAPSTATS */
d3155 1
a3155 1
	ldx	[%g4 + %lo(_C_LABEL(ctxbusy))], %g4
d3178 1
a3178 1
#endif	/* DEBUG */
d3229 1
a3229 1
#endif	/* DEBUG */
d3240 1
a3240 1
#endif	/* 1 */
d3272 1
a3272 1
#endif	/* TRAPS_USE_IG */
d3280 2
a3281 2
	TRAP_SETUP -CC64FSZ-TF_SIZE
	INCR _C_LABEL(uvmexp)+V_FAULTS			! cnt.v_faults++ (clobbers %o0,%o1,%o2)
d3291 3
a3293 3
	stx	%g1, [%sp + CC64FSZ + BIAS + TF_G + (1*8)]	! save g1
	stx	%g2, [%sp + CC64FSZ + BIAS + TF_G + (2*8)]	! save g2
	stx	%g3, [%sp + CC64FSZ + BIAS + TF_G + (3*8)]	! (sneak g3 in here)
d3295 1
a3295 1
	stx	%g4, [%sp + CC64FSZ + BIAS + TF_G + (4*8)]	! sneak in g4
d3297 1
a3297 1
	stx	%g5, [%sp + CC64FSZ + BIAS + TF_G + (5*8)]	! sneak in g5
d3299 1
a3299 1
	stx	%g6, [%sp + CC64FSZ + BIAS + TF_G + (6*8)]	! sneak in g6
d3301 1
a3301 1
	stx	%g7, [%sp + CC64FSZ + BIAS + TF_G + (7*8)]	! sneak in g7
d3305 2
a3306 2
	stx	%g1, [%sp + CC64FSZ + BIAS + TF_TSTATE]		! set tf.tf_psr, tf.tf_pc
	sth	%o1, [%sp + CC64FSZ + BIAS + TF_TT]! debug
d3308 2
a3309 2
	stx	%o2, [%sp + CC64FSZ + BIAS + TF_PC]
	stx	%g3, [%sp + CC64FSZ + BIAS + TF_NPC]		! set tf.tf_npc
d3312 2
a3313 2
	stb	%g5, [%sp + CC64FSZ + BIAS + TF_PIL]
	stb	%g5, [%sp + CC64FSZ + BIAS + TF_OLDPIL]
d3318 1
a3318 1
	CHKPT %g1,%g3,0x22
d3327 1
a3327 1
	 st	%g7, [%sp + CC64FSZ + BIAS + TF_Y]		! set tf.tf_y
d3331 1
a3331 1
	 add	%sp, CC64FSZ + BIAS, %o0	! (argument: &tf)
d3333 1
a3333 1
	CHKPT %o1,%o2,2
d3336 1
a3336 1
	 ldx	[%sp + CC64FSZ + BIAS + TF_TSTATE], %g1	! Load this for return_from_trap
d3343 1
a3343 1
	 add	%sp, CC64FSZ + BIAS, %o0	! (argument: &tf)
d3382 1
a3382 1
#endif	/* TRAPS_USE_IG */
d3396 1
a3396 1
#else	/* DEBUG */
d3398 3
a3400 3
	ldx	[%sp], %sp
	add	%sp, -CC64FSZ-BIAS, %sp	! Overwrite proc 0's stack.
#endif	/* DEBUG */
d3402 1
a3402 1
#endif	/* DIAGNOSTIC */
d3408 1
a3408 1
	TRAP_SETUP -CC64FSZ-TF_SIZE
d3410 1
a3410 1
	stx	%g1, [%sp + CC64FSZ + BIAS + TF_TSTATE]
d3412 1
a3412 1
	stx	%g2, [%sp + CC64FSZ + BIAS + TF_PC]
d3414 1
a3414 1
	stx	%g3, [%sp + CC64FSZ + BIAS + TF_NPC]
d3416 1
a3416 1
	st	%g5, [%sp + CC64FSZ + BIAS + TF_Y]
d3418 1
a3418 1
	sth	%o1, [%sp + CC64FSZ + BIAS + TF_TT]! debug
d3421 6
a3426 6
	stx	%g1, [%sp + CC64FSZ + BIAS + TF_G + (1*8)]
	stx	%g2, [%sp + CC64FSZ + BIAS + TF_G + (2*8)]
	add	%sp, CC64FSZ + BIAS, %o0		! (&tf)
	stx	%g3, [%sp + CC64FSZ + BIAS + TF_G + (3*8)]
	stx	%g4, [%sp + CC64FSZ + BIAS + TF_G + (4*8)]
	stx	%g5, [%sp + CC64FSZ + BIAS + TF_G + (5*8)]
d3428 4
a3431 4
	stx	%g6, [%sp + CC64FSZ + BIAS + TF_G + (6*8)]
	stx	%g7, [%sp + CC64FSZ + BIAS + TF_G + (7*8)]
	stb	%g5, [%sp + CC64FSZ + BIAS + TF_PIL]
	stb	%g5, [%sp + CC64FSZ + BIAS + TF_OLDPIL]
d3438 1
a3438 1
	CHKPT %g2,%g3,0x24
d3446 1
a3446 1
	CHKPT %o1,%o2,3
d3481 2
a3482 2
	 ldx	[%g6 + %lo(CPCB)], %g7
	set	USPACE-CC64FSZ-TF_SIZE-BIAS, %g5
d3484 44
a3527 44
	SET_SP_REDZONE %g7, %g5
	stx	%g1, [%g6 + CC64FSZ + BIAS + TF_FAULT]		! Generate a new trapframe
	stx	%i0, [%g6 + CC64FSZ + BIAS + TF_O + (0*8)]	!	but don't bother with
	stx	%i1, [%g6 + CC64FSZ + BIAS + TF_O + (1*8)]	!	locals and ins
	stx	%i2, [%g6 + CC64FSZ + BIAS + TF_O + (2*8)]
	stx	%i3, [%g6 + CC64FSZ + BIAS + TF_O + (3*8)]
	stx	%i4, [%g6 + CC64FSZ + BIAS + TF_O + (4*8)]
	stx	%i5, [%g6 + CC64FSZ + BIAS + TF_O + (5*8)]
	stx	%i6, [%g6 + CC64FSZ + BIAS + TF_O + (6*8)]
	stx	%i7, [%g6 + CC64FSZ + BIAS + TF_O + (7*8)]
#ifdef DEBUG
	ldx	[%sp + CC64FSZ + BIAS + TF_I + (0*8)], %l0	! Copy over the rest of the regs
	ldx	[%sp + CC64FSZ + BIAS + TF_I + (1*8)], %l1	! But just dirty the locals
	ldx	[%sp + CC64FSZ + BIAS + TF_I + (2*8)], %l2
	ldx	[%sp + CC64FSZ + BIAS + TF_I + (3*8)], %l3
	ldx	[%sp + CC64FSZ + BIAS + TF_I + (4*8)], %l4
	ldx	[%sp + CC64FSZ + BIAS + TF_I + (5*8)], %l5
	ldx	[%sp + CC64FSZ + BIAS + TF_I + (6*8)], %l6
	ldx	[%sp + CC64FSZ + BIAS + TF_I + (7*8)], %l7
	stx	%l0, [%g6 + CC64FSZ + BIAS + TF_I + (0*8)]
	stx	%l1, [%g6 + CC64FSZ + BIAS + TF_I + (1*8)]
	stx	%l2, [%g6 + CC64FSZ + BIAS + TF_I + (2*8)]
	stx	%l3, [%g6 + CC64FSZ + BIAS + TF_I + (3*8)]
	stx	%l4, [%g6 + CC64FSZ + BIAS + TF_I + (4*8)]
	stx	%l5, [%g6 + CC64FSZ + BIAS + TF_I + (5*8)]
	stx	%l6, [%g6 + CC64FSZ + BIAS + TF_I + (6*8)]
	stx	%l7, [%g6 + CC64FSZ + BIAS + TF_I + (7*8)]
	ldx	[%sp + CC64FSZ + BIAS + TF_L + (0*8)], %l0
	ldx	[%sp + CC64FSZ + BIAS + TF_L + (1*8)], %l1
	ldx	[%sp + CC64FSZ + BIAS + TF_L + (2*8)], %l2
	ldx	[%sp + CC64FSZ + BIAS + TF_L + (3*8)], %l3
	ldx	[%sp + CC64FSZ + BIAS + TF_L + (4*8)], %l4
	ldx	[%sp + CC64FSZ + BIAS + TF_L + (5*8)], %l5
	ldx	[%sp + CC64FSZ + BIAS + TF_L + (6*8)], %l6
	ldx	[%sp + CC64FSZ + BIAS + TF_L + (7*8)], %l7
	stx	%l0, [%g6 + CC64FSZ + BIAS + TF_L + (0*8)]
	stx	%l1, [%g6 + CC64FSZ + BIAS + TF_L + (1*8)]
	stx	%l2, [%g6 + CC64FSZ + BIAS + TF_L + (2*8)]
	stx	%l3, [%g6 + CC64FSZ + BIAS + TF_L + (3*8)]
	stx	%l4, [%g6 + CC64FSZ + BIAS + TF_L + (4*8)]
	stx	%l5, [%g6 + CC64FSZ + BIAS + TF_L + (5*8)]
	stx	%l6, [%g6 + CC64FSZ + BIAS + TF_L + (6*8)]
	stx	%l7, [%g6 + CC64FSZ + BIAS + TF_L + (7*8)]
#endif	/* DEBUG */
d3530 1
a3530 1
#endif	/* 1 */
d3593 1
a3593 1
#endif	/* 0 */
d3617 1
a3617 1
	TRAP_SETUP -CCFSZ-TF_SIZE
d3688 1
a3688 1
#endif	/* DEBUG */
d3708 1
a3708 1
#endif	/* DEBUG */
d3737 1
a3737 1
#endif	/* DEBUG */
d3766 1
a3766 1
	ldx	[%l1 + %lo(CPCB)], %l1
d3774 1
a3774 1
#endif	/* KGDB */
d3785 2
a3786 2
#endif	/* TRAPS_USE_IG */
	TRAP_SETUP -CC64FSZ-TF_SIZE
d3790 2
a3791 2
	sth	%o1, [%sp + CC64FSZ + BIAS + TF_TT]! debug
#endif	/* DEBUG */
d3794 1
a3794 1
	stx	%g1, [%sp + CC64FSZ + BIAS + TF_G + ( 1*8)]
d3797 1
a3797 1
	stx	%g2, [%sp + CC64FSZ + BIAS + TF_G + ( 2*8)]
d3799 1
a3799 1
	stx	%g3, [%sp + CC64FSZ + BIAS + TF_G + ( 3*8)]
d3801 1
a3801 1
	stx	%g4, [%sp + CC64FSZ + BIAS + TF_G + ( 4*8)]
d3803 3
a3805 3
	stx	%g5, [%sp + CC64FSZ + BIAS + TF_G + ( 5*8)]
	stx	%g6, [%sp + CC64FSZ + BIAS + TF_G + ( 6*8)]
	CHKPT %g5,%g6,0x31
d3807 2
a3808 2
	stx	%g7, [%sp + CC64FSZ + BIAS + TF_G + ( 7*8)]
	add	%sp, CC64FSZ + BIAS, %o0	! (&tf)
d3810 4
a3813 4
	stx	%g1, [%sp + CC64FSZ + BIAS + TF_TSTATE]
	stx	%o2, [%sp + CC64FSZ + BIAS + TF_PC]
	stx	%o3, [%sp + CC64FSZ + BIAS + TF_NPC]
	st	%o4, [%sp + CC64FSZ + BIAS + TF_Y]
d3816 2
a3817 2
	stb	%g5, [%sp + CC64FSZ + BIAS + TF_PIL]
	stb	%g5, [%sp + CC64FSZ + BIAS + TF_OLDPIL]
d3827 1
a3827 1
	CHKPT %o1,%o2,0x32
d3829 1
a3829 1
	CHKPT %o1,%o2,4
d3887 1
a3887 1
	.space	16 * 8 * 8
d3900 1
a3900 1
#endif	/* DEBUG */
d3912 1
a3912 1
#endif	/* TRAPSTATS */
d3920 1
a3920 1
	STACKFRAME -CC64FSZ		! Get a clean register window
d3931 1
a3931 1
#endif	/* NOT_DEBUG */
d3936 1
a3936 1
	 sllx	%g2, 3, %g5	! Calculate entry number
d3941 1
a3941 1
#endif	/* DEBUG */
d3944 1
a3944 1
	ldx	[%g3 + %g5], %g5	! We have a pointer to the handler
d3948 1
a3948 1
	STACKFRAME -CC64FSZ		! Get a clean register window
d3959 1
a3959 1
#endif	/* DEBUG */
d3963 1
a3963 1
#endif	/* NOT_DEBUG */
d3969 2
a3970 2
	ldstub  [%g5+IH_BUSY], %g6	! Check if already in use
	membar #LoadLoad | #LoadStore
d3972 1
d3976 1
a3976 1
	sll	%g6, 3+3, %g3	! Find start of table for this IPL
d3980 3
a3982 2
	ldx	[%g1], %g3		! Load list head
	stx	%g3, [%g5+IH_PEND]	! Link our intrhand node in
d3984 1
a3984 1
	casxa	[%g1] ASI_N, %g3, %g7
d3988 13
d4002 33
d4042 1
a4042 1
	STACKFRAME -CC64FSZ		! Get a clean register window
d4055 1
a4055 1
#endif	/* DEBUG */	/* DEBUG */
d4072 2
a4073 2
#endif	/* DEBUG */
	STACKFRAME -CC64FSZ		! Get a clean register window
d4150 1
a4150 1
#endif	/* TRAPS_USE_IG */
d4159 1
a4159 1
	DLFLUSH %g3, %g2
d4161 1
a4161 1
	 ldx	[%g3 + 8], %g5	! intrlev[1] is reserved for %tick intr.
d4189 2
a4190 2
#endif	/* TRAPSTATS */
	INTR_SETUP -CC64FSZ-TF_SIZE-8
d4193 7
a4199 7
	stx	%g1, [%sp + CC64FSZ + BIAS + TF_G + ( 1*8)]
	stx	%g2, [%sp + CC64FSZ + BIAS + TF_G + ( 2*8)]
	stx	%g3, [%sp + CC64FSZ + BIAS + TF_G + ( 3*8)]
	stx	%g4, [%sp + CC64FSZ + BIAS + TF_G + ( 4*8)]
	stx	%g5, [%sp + CC64FSZ + BIAS + TF_G + ( 5*8)]
	stx	%g6, [%sp + CC64FSZ + BIAS + TF_G + ( 6*8)]
	stx	%g7, [%sp + CC64FSZ + BIAS + TF_G + ( 7*8)]
d4203 1
a4203 1
	INCR _C_LABEL(uvmexp)+V_INTR	! cnt.v_intr++; (clobbers %o0,%o1,%o2)
d4209 1
a4209 1
	stw	%l6, [%sp + CC64FSZ + BIAS + TF_Y]	! Silly, but we need to save this for rft
d4211 1
a4211 1
	CHKPT %l4,%l7,0x26
d4213 3
a4215 3
	sth	%l5, [%sp + CC64FSZ + BIAS + TF_TT]! debug
	stx	%l0, [%sp + CC64FSZ + BIAS + TF_TSTATE]	! set up intrframe/clockframe
	stx	%l1, [%sp + CC64FSZ + BIAS + TF_PC]
d4217 2
a4218 2
	stx	%l2, [%sp + CC64FSZ + BIAS + TF_NPC]
	stx	%fp, [%sp + CC64FSZ + BIAS + TF_KSTACK]	!  old frame pointer
d4222 1
a4222 1
	stb	%l6, [%sp + CC64FSZ + BIAS + TF_PIL]	! set up intrframe/clockframe
d4224 1
a4224 1
	sll	%l6, 2, %l3
d4226 2
a4227 2
	stb	%o1, [%sp + CC64FSZ + BIAS + TF_OLDPIL]	! old %pil
	ld	[%l4 + %l3], %o0
d4232 1
a4232 1
	st	%o0, [%l4]
d4245 1
a4245 1
	st	%l7, [%sp + CC64FSZ + BIAS + TF_SIZE]
d4250 1
a4250 1
	sll	%l6, 3+3, %l2
d4256 1
d4259 1
a4259 1
	ldx	[%l4], %l2		! Check a slot
d4264 1
a4264 1
	casxa	[%l4] ASI_N, %l2, %l7	! Grab the entire list
d4267 1
a4267 1
	 add	%sp, CC64FSZ+BIAS, %o2	! tf = %sp + CC64FSZ + BIAS
d4269 2
a4270 24
	ldx	[%l2 + IH_PEND], %l7	! Load next pending
	ldx	[%l2 + IH_FUN], %o4	! ih->ih_fun
	ldx	[%l2 + IH_ARG], %o0	! ih->ih_arg
	ldx	[%l2 + IH_CLR], %l1	! ih->ih_clear

	stx	%g0, [%l2 + IH_PEND]	! Unlink from list

	! Note that the function handler itself or an interrupt
	! may add handlers to the pending pending. This includes
	! the current entry in %l2 and entries held on our local
	! pending list in %l7.  The former is ok because we are
	! done with it now and the latter because they are still
	! marked busy. We may also be able to do this by having
	! the soft interrupts use a variation of the hardware
	! interrupts' ih_clr scheme.  Note:  The busy flag does
	! not itself prevent the handler from being entered
	! recursively.  It only indicates that the handler is
	! about to be invoked and that it should not be added
	! to the pending table.
	membar	#StoreStore | #LoadStore
	stb	%g0, [%l2 + IH_BUSY]	! Allow the ih to be reused

	! At this point, the current ih could already be added
	! back to the pending table.
d4274 5
d4281 1
a4281 1
	 add	%l5, %o0, %l5		! Add handler return value
d4283 1
d4288 97
d4404 1
a4404 1
	STACKFRAME -CC64FSZ		! Get a clean register window
d4412 1
a4412 1
#endif	/* DEBUG */
d4416 1
a4416 1
	ld	[%sp + CC64FSZ + BIAS + TF_SIZE], %l7
d4419 1
a4419 1
	ldub	[%sp + CC64FSZ + BIAS + TF_OLDPIL], %l3	! restore old %pil
d4423 1
a4423 1
	CHKPT %o1,%o2,5
d4444 1
a4444 1
#endif /* notyet */	/* notyet */
d4459 1
a4459 1
 *	[%sp + CC64FSZ + BIAS] => trap frame
d4476 2
a4477 2
	ldx	[%sp + CC64FSZ + BIAS + TF_PC], %g2
	ldx	[%sp + CC64FSZ + BIAS + TF_NPC], %g3
d4480 1
a4480 1
#endif	/* DEBUG */
d4486 2
a4487 2
	ldx	[%fp + CC64FSZ + BIAS + TF_PC], %o3
	ldx	[%fp + CC64FSZ + BIAS + TF_NPC], %o4
d4499 1
a4499 1
#endif	/* NOTDEF_DEBUG */
d4502 1
a4502 1
	ldx	[%sp + CC64FSZ + BIAS + TF_TSTATE], %g2
d4529 1
a4529 1
#endif	/* NOTDEF_DEBUG */
d4533 1
a4533 1
	ldx	[%sp + CC64FSZ + BIAS + TF_TSTATE], %g1
d4539 1
a4539 1
	 ldx	[%o1 + %lo(CURPROC)], %o0
d4541 1
a4541 1
#endif	/* 0 */
d4553 7
a4559 7
	ldx	[%sp + CC64FSZ + BIAS + TF_G + (1*8)], %g1
	ldx	[%sp + CC64FSZ + BIAS + TF_G + (2*8)], %g2
	ldx	[%sp + CC64FSZ + BIAS + TF_G + (3*8)], %g3
	ldx	[%sp + CC64FSZ + BIAS + TF_G + (4*8)], %g4
	ldx	[%sp + CC64FSZ + BIAS + TF_G + (5*8)], %g5
	ldx	[%sp + CC64FSZ + BIAS + TF_G + (6*8)], %g6
	ldx	[%sp + CC64FSZ + BIAS + TF_G + (7*8)], %g7
d4564 9
a4572 9
#endif	/* TRAPS_USE_IG */
	ldx	[%sp + CC64FSZ + BIAS + TF_O + (0*8)], %i0
	ldx	[%sp + CC64FSZ + BIAS + TF_O + (1*8)], %i1
	ldx	[%sp + CC64FSZ + BIAS + TF_O + (2*8)], %i2
	ldx	[%sp + CC64FSZ + BIAS + TF_O + (3*8)], %i3
	ldx	[%sp + CC64FSZ + BIAS + TF_O + (4*8)], %i4
	ldx	[%sp + CC64FSZ + BIAS + TF_O + (5*8)], %i5
	ldx	[%sp + CC64FSZ + BIAS + TF_O + (6*8)], %i6
	ldx	[%sp + CC64FSZ + BIAS + TF_O + (7*8)], %i7
d4574 2
a4575 2
	ld	[%sp + CC64FSZ + BIAS + TF_Y], %g4
	ldx	[%sp + CC64FSZ + BIAS + TF_TSTATE], %g1		! load new values
d4577 2
a4578 2
	ldx	[%sp + CC64FSZ + BIAS + TF_PC], %g2
	ldx	[%sp + CC64FSZ + BIAS + TF_NPC], %g3
d4585 1
a4585 1
#endif	/* DEBUG */
d4588 1
a4588 1
	ldub	[%sp + CC64FSZ + BIAS + TF_PIL], %g5		! restore %pil
d4590 1
a4590 1
#endif	/* NOTDEF_DEBUG */
d4594 1
a4594 1
	CHKPT %g4, %g7, 6
d4613 1
a4613 1
	CHKPT %g1,%g2,7
d4615 1
a4615 1
	CHKPT %g1,%g2,0			! Clear this out
d4621 43
d4672 1
a4672 1
#endif	/* TRAPSTATS */
d4675 1
a4675 1
#endif	/*  */
d4697 1
a4697 1
	CHKPT %g4,%g7,8
d4700 1
a4700 1
	ldx	[%g4 + %lo(CPCB)], %g4
d4722 1
a4722 1
#endif	/* NOTDEF_DEBUG */
d4732 1
a4732 1
#endif	/* TRAPSTATS */
d4751 1
a4751 1
#endif	/* DEBUG */
d4753 1
a4753 1
	ldx	[%g6 + %lo(CPCB)], %g6
d4756 1
a4756 1
	CHKPT %g4,%g7,9
d4763 1
a4763 1
#endif	/* DEBUG */
d4775 1
a4775 1
#endif	/* DEBUG */
d4819 1
a4819 1
#endif	/* DEBUG */
d4844 1
a4844 1
#endif	/* DEBUG */
d4850 1
a4850 1
#endif	/* TRAPSTATS */
d4857 1
a4857 1
	ldx	[%g5 + %lo(CPCB)], %g5
d4863 1
a4863 1
#endif	/* DEBUG */
d4885 1
a4885 1
	CHKPT %g4,%g7,0xa
d4890 1
a4890 1
	ldx	[%g6 + CC64FSZ + BIAS + TF_L + (0*8)], %g5! DEBUG -- get proper value for %l0
d4919 1
a4919 1
	ldx	[%g6 + %lo(CPCB)], %g6
d4929 1
a4929 1
#endif	/* NOTDEF_DEBUG */
d4935 1
a4935 1
	CHKPT %g4,%g7,0xb
d4944 46
a4989 1
	CHKPT %g4,%g7,0xd
d4995 1
a4995 1
#endif	/* TRAPSTATS */
d4998 1
a4998 1
	ldx	[%g5 + %lo(CPCB)], %g5
d5002 1
a5002 1
#endif	/* DEBUG */
d5037 1
a5037 1
#endif /* DDB */	/* DDB */
d5041 1
d5079 48
a5126 1
#endif	/* defined(DDB) */
d5191 1
a5191 1
	stx	%l4, [%l3 + %lo(_C_LABEL(esym))]
d5200 1
a5200 1
	 stx	%l4, [%l3 + %lo(_C_LABEL(ssym))]
d5216 1
a5216 1
	stx	%l4, [%l3 + %lo(_C_LABEL(esym))]
d5224 1
a5224 1
	stx	%l4, [%l3 + %lo(_C_LABEL(ssym))]
d5226 1
a5226 1
#endif	/* defined(DDB) || NKSYMS > 0 */
d5233 1
a5233 1
	stx	%o4, [%o5]	! It's initialized data, I hope
d5239 1
d5244 6
d5280 1
a5280 1
#endif	/* 0 */
d5339 1
a5339 1
#endif	/*  */
d5351 1
a5351 1
	ldx	[%l1], %l1
d5353 1
a5353 1
	ldx	[%l4], %l4
d5394 1
a5394 1
#endif	/* DEBUG */
d5431 1
a5431 1
#else	/* NO_VCACHE */
d5434 1
a5434 1
#endif	/* NO_VCACHE */
d5455 1
a5455 1
#else	/* NO_VCACHE */
d5458 1
a5458 1
#endif	/* NO_VCACHE */
d5483 1
a5483 1
#endif	/* DEBUG */
d5561 1
a5561 1
#else	/* NO_VCACHE */
d5564 1
a5564 1
#endif	/* NO_VCACHE */
d5610 1
a5610 1
#endif	/* DEBUG */
d5618 1
a5618 1
	ldx	[%l1 + %lo(_C_LABEL(cpus))], %l1
d5646 1
a5646 1
#else	/* NO_VCACHE */
d5648 1
a5648 1
#endif	/* NO_VCACHE */
d5664 1
a5664 1
	ldx	[%l0 + %lo(CPUINFO_VA+CI_INITSTACK)], %l0
d5666 1
d5669 1
d5680 1
a5680 1
	ldx	[%l0], %l0
d5694 1
a5694 1
	ldx	[%l0], %l0
d5717 1
a5717 1
#endif	/* DEBUG */
d5729 1
a5729 1
#endif	/* NOTDEF_DEBUG */
d5735 1
a5735 1
	ldx	[%l0 + %lo(CPUINFO_VA+CI_SPINUP)], %o1
d5766 1
a5766 1
	 ldx	[%o4+%lo(romp)], %o4		! v9 stack, just load the addr and callit
d5783 3
d5787 1
d5806 1
a5806 1
#endif	/* NOTDEF_DEBUG */
d5826 1
d5828 3
d5858 1
a5858 1
#endif	/* DEBUG */
d5880 1
a5880 1
#endif	/* DEBUG */
d5920 1
a5920 1
#endif	/* DEBUG */
d5932 1
a5932 1
#endif	/* NOTDEF_DEBUG */
d5945 1
a5945 1
#endif	/* DIAGNOSTIC */
d6002 3
d6099 5
d6107 1
a6107 1
#endif	/* DEBUG */
d6148 1
d6270 1
d6274 3
a6276 1
#endif	/* COMPAT_NETBSD */
d6278 8
d6292 1
a6292 1
#endif	/* ENTRY */
d6307 1
a6307 1
#else	/* GPROF */
d6309 1
a6309 1
#endif	/* GPROF */
d6340 1
a6340 1
#endif	/* NOTDEF_DEBUG */
d6346 1
a6346 1
	ldx	[%o4 + %lo(CPCB)], %o4	! catch faults
d6349 1
a6349 1
	stx	%o5, [%o4 + PCB_ONFAULT]
d6387 1
a6387 1
#endif	/* NOTDEF_DEBUG */
d6393 1
a6393 1
	ldx	[%o4 + %lo(CPCB)], %o4	! catch faults
d6396 1
a6396 1
	stx	%o5, [%o4 + PCB_ONFAULT]
d6414 1
a6414 1
	 stx	%o1, [%o3]		!		*lencopied = len;
d6417 1
a6417 1
	 stx	%g0, [%o4 + PCB_ONFAULT]! return (error);
d6430 1
a6430 1
#endif	/* NOTDEF_DEBUG */
d6463 1
a6463 1
	 stx	%o1, [%o3]		!		*lencopied = len;
d6477 1
a6477 1
#endif	/* DIAGNOSTIC */
d6504 1
a6504 1
#endif	/* NOTDEF_DEBUG */
d6507 1
a6507 1
	ldx	[%o3 + %lo(CPCB)], %o3
d6511 1
a6511 1
	stx	%o4, [%o3 + PCB_ONFAULT]
d6541 1
a6541 1
!	 XXX check no delay slot
d6674 1
a6674 1
	ldx	[%o3 + %lo(CPCB)], %o3
d6676 1
a6676 1
	stx	%g0, [%o3 + PCB_ONFAULT]
d6712 1
a6712 1
#endif	/* NOTDEF_DEBUG */
d6716 1
a6716 1
	ldx	[%o3 + %lo(CPCB)], %o3
d6720 1
a6720 1
	stx	%o4, [%o3 + PCB_ONFAULT]
d6732 1
a6732 1
!	 XXX check no delay slot
d6752 1
a6752 1
!	 XXX check no delay slot
d6884 1
a6884 1
	ldx	[%o3 + %lo(CPCB)], %o3
d6886 1
a6886 1
	stx	%g0, [%o3 + PCB_ONFAULT]
d6899 2
a6900 2
	ldx	[%o3 + %lo(CPCB)], %o3
	stx	%g0, [%o3 + PCB_ONFAULT]
d6912 1
a6912 1
#endif	/* NOTDEF_DEBUG */
d6974 1
a6974 1
#endif	/* DEBUG */
d6990 1
a6990 1
#endif	/* SCHED_DEBUG */
d7010 1
a7010 1
#endif	/* 0 */
d7012 1
a7012 1
	stx	%l1, [%l6 + %lo(CPCB)]	! cpcb = &idle_u
d7014 1
d7016 3
d7030 2
a7031 2
	SET_SP_REDZONE %l6, %l5
#endif	/* DEBUG */
d7038 1
a7038 1
#endif	/* defined(MULTIPROCESSOR) || defined(LOCKDEBUG) */
d7061 2
a7062 2
	INCR _C_LABEL(nswitchexit)		! nswitchexit++;
	INCR _C_LABEL(uvmexp)+V_SWTCH		! cnt.v_switch++;
d7069 1
a7069 1
	ldx	[%l6 + %lo(CPCB)], %l5
d7090 2
a7091 2
#endif	/* defined(MULTIPROCESSOR) || defined(LOCKDEBUG) */
	 stx	%g0, [%l7 + %lo(CURPROC)] ! curproc = NULL;
d7114 1
a7114 1
#endif	/* NOTDEF_DEBUG */
d7128 1
a7128 1
#endif	/* UVM_PAGE_IDLE_ZERO */
d7136 1
a7136 1
#endif	/* defined(MULTIPROCESSOR) || defined(LOCKDEBUG) */
d7209 1
a7209 1
#endif	/* DEBUG */
d7214 1
a7214 1
#endif	/* NOTDEF_DEBUG */
d7220 1
a7220 1
#endif	/* DEBUG */
d7225 1
a7225 1
	ldx	[%l6 + %lo(CPCB)], %l5
d7228 1
a7228 1
	ldx	[%l7 + %lo(CURPROC)], %l4	! lastproc = curproc;
d7231 1
a7231 1
	stx	%g0, [%l7 + %lo(CURPROC)]	! curproc = NULL;
d7263 1
a7263 1
!	 XXX check no delay slot
d7267 1
a7267 1
#else	/* POPC */
d7283 1
a7283 1
#endif	/* POPC */
d7288 1
a7288 1
	sll	%o4, 3+1, %o0
d7290 1
a7290 1
	ldx	[%o5], %l3		! p = q->ph_link;
d7293 4
a7296 4
!	 XXX check no delay slot
	ldx	[%l3], %o0		! tmp0 = p->p_forw;
	stx	%o0, [%o5]		! q->ph_link = tmp0;
	stx	%o5, [%o0 + 8]	! tmp0->p_back = q;
d7299 1
a7299 1
!	 XXX check no delay slot
d7323 1
a7323 1
	ldx	[%l3 + P_WCHAN], %o0	! if (p->p_wchan)
d7325 1
a7325 1
!	 XXX check no delay slot
d7329 1
a7329 1
!	 XXX check no delay slot
d7340 1
a7340 1
#endif	/* defined(MULTIPROCESSOR) */
d7344 1
a7344 1
#endif	/* notyet */
d7347 2
a7348 2
	ldx	[%l3 + P_ADDR], %l1		! newpcb = p->p_addr;
	stx	%g0, [%l3 + 8]		! p->p_back = NULL;
d7355 2
a7356 2
#endif	/* defined(MULTIPROCESSOR) || defined(LOCKDEBUG) */
	 stx	%l4, [%l7 + %lo(CURPROC)]	! restore old proc so we can save it
d7384 1
a7384 1
#endif	/* SCHED_DEBUG */
d7389 1
a7389 1
	INCR _C_LABEL(nswitchdiff)	! clobbers %o0,%o1,%o2
d7417 1
a7417 1
#endif	/* SCHED_DEBUG */
d7419 2
a7420 2
	stx	%l3, [%l7 + %lo(CURPROC)]	! curproc = p;
	stx	%l1, [%l6 + %lo(CPCB)]	! cpcb = newpcb;
d7442 1
a7442 1
#endif	/* SCHED_DEBUG */
d7460 1
a7460 1
#endif	/* DEBUG */
d7474 1
a7474 1
#endif	/* SCHED_DEBUG */
d7477 3
a7479 3
	SET_SP_REDZONE %o0, %o1
	CHECK_SP_REDZONE %o0, %o1
#endif	/* DEBUG */
d7488 1
a7488 1
	ldx	[%l3 + P_VMSPACE], %o3	! vm = p->p_vmspace;
d7491 1
a7491 1
	ldx	[%o3 + VM_PMAP], %o2		! if (vm->vm_pmap.pm_ctx != NULL)
d7522 1
a7522 1
#endif	/* SCHED_DEBUG */
d7548 44
a7591 1
#endif	/* SCHED_DEBUG */
d7606 1
a7606 1
	ldx	[%o3], %o3
d7618 1
a7618 1
#endif	/* DEBUG */
d7631 1
a7631 1
#endif	/* SCHED_DEBUG */
d7684 1
a7684 1
#endif	/* SCHED_DEBUG */
d7698 2
a7699 2
	ldx	[%sp + CC64FSZ + BIAS + TF_TSTATE], %g1
	ldx	[%sp + CC64FSZ + BIAS + TF_NPC], %g2	! pc = tf->tf_npc from execve/fork
d7703 1
a7703 1
	stx	%g3, [%sp + CC64FSZ + BIAS + TF_NPC]
d7705 3
a7707 3
	stx	%g2, [%sp + CC64FSZ + BIAS + TF_PC]
	stx	%g1, [%sp + CC64FSZ + BIAS + TF_TSTATE]
#else	/* 0 */
d7709 1
a7709 1
	ldx	[%sp + CC64FSZ + BIAS + TF_NPC], %g2	! pc = tf->tf_npc from execve/fork
d7713 1
a7713 1
	stx	%g3, [%sp + CC64FSZ + BIAS + TF_NPC]
d7715 3
a7717 3
	stx	%g2, [%sp + CC64FSZ + BIAS + TF_PC]
	stx	%g1, [%sp + CC64FSZ + BIAS + TF_TSTATE]
#endif	/* 0 */
d7719 1
a7719 1
!	set	panicstack-CC64FSZ-BIAS, %o0! DEBUG
d7723 1
a7723 1
	ldx	[%fp + CC64FSZ + BIAS + TF_O + ( 6*8)], %o2
d7725 1
a7725 1
	add	%fp, CC64FSZ + BIAS, %o3
d7747 2
a7748 2
#endif	/* SCHED_DEBUG */
	CHKPT %o3,%o4,0x35
d7752 20
d7773 1
a7773 1
	stx	%g0, [%o2 + PCB_ONFAULT]! error in r/w, clear pcb_onfault
d7775 4
d7789 1
a7789 1
	stx	%g0, [%o2 + PCB_ONFAULT]! error in r/w, clear pcb_onfault
d7794 98
d7911 6
d7920 2
a7921 1
	ldx	[%o2 + %lo(CPCB)], %o2	! cpcb->pcb_onfault = Lfserr;
d7923 4
a7926 1
	stx	%o5, [%o2 + PCB_ONFAULT]
d7931 1
a7931 1
	DLFLUSH %o0,%o5		!	flush cache line
d7934 4
d7958 3
d7962 3
d7967 1
a7967 1
	DLFLUSH2 %o5			!	flush cache line again
d7970 1
a7970 1
	stx	%g0, [%o2 + PCB_ONFAULT]
d7978 4
a7981 1
	stx	%g0, [%o2 + PCB_ONFAULT]! error in r/w, clear pcb_onfault
d7998 7
d8008 1
a8008 1
	ldx	[%o2 + %lo(CPCB)], %o2	! cpcb->pcb_onfault = Lfserr;
d8010 1
a8010 1
	stx	%o5, [%o2 + PCB_ONFAULT]
d8035 1
a8035 1
	stx	%g0, [%o2 + PCB_ONFAULT]
d8060 5
d8082 1
a8082 1
#endif	/* DEBUG */
d8100 1
a8100 1
	ldx	[%o2 + %lo(_C_LABEL(vmmap))], %o2
d8111 1
a8111 1
	add	%sp, (CC64FSZ+BIAS+BLOCK_SIZE-1), %l0	! Calculate pointer to fpstate
d8120 1
a8120 1
#else	/* NEW_FPSTATE */	/* NEW_FPSTATE */
d8154 2
a8155 2
	ldx	[%l1 + %lo(FPPROC)], %l2		! Load fpproc
	add	%sp, (CC64FSZ+BIAS+BLOCK_SIZE-1), %l0	! Calculate pointer to fpstate
d8158 1
a8158 1
	ldx	[%l2 + P_FPSTATE], %l3
d8162 1
a8162 1
	 set	EINTSTACK-BIAS, %l4			! Are we on intr stack?
d8165 1
a8165 1
	 set	INTSTACK-BIAS, %l4
d8174 1
a8174 1
	ldx	[%l4 + %lo(CURPROC)], %l5
d8179 1
a8179 1
	ldx	[%l5 + P_FPSTATE], %l6			! Save old fpstate
d8181 2
a8182 2
	stx	%l0, [%l5 + P_FPSTATE]			! Insert new fpstate
	stx	%l5, [%l1 + %lo(FPPROC)]		! Set new fpproc
d8184 2
a8185 2
#endif	/* NEW_FPSTATE */	/* NEW_FPSTATE */
#else	/* PMAP_FPSTATE */	/* PMAP_FPSTATE */
d8192 1
a8192 1
	ldx	[%o4 + %lo(FPPROC)], %o4
d8198 1
a8198 1
#endif	/* PMAP_FPSTATE */	/* PMAP_FPSTATE */
d8208 1
a8208 1
#endif	/* DEBUG */
d8249 19
d8283 1
a8283 1
#else /* NEW_FPSTATE */	/* NEW_FPSTATE */
d8285 1
a8285 1
	ldx	[%l1 + %lo(FPPROC)], %l7
d8288 1
a8288 1
	ldx	[%l5 + P_FPSTATE], %l7
d8291 3
a8293 3
#endif	/* DEBUG */
	stx	%g0, [%l1 + %lo(FPPROC)]		! Clear fpproc
	stx	%l6, [%l5 + P_FPSTATE]			! Restore old fpstate
d8297 2
a8298 2
#endif /* NEW_FPSTATE */	/* NEW_FPSTATE */
#else /* PMAP_FPSTATE */	/* PMAP_FPSTATE */
d8301 1
a8301 1
#endif /* PMAP_FPSTATE */	/* PMAP_FPSTATE */
d8303 1
a8303 1
#endif /* PMAP_PHYS_PAGE */	/* PMAP_PHYS_PAGE */
d8319 1
a8319 1
#else	/* 1 */
d8331 1
a8331 1
#endif	/* 1 */
d8351 6
d8375 1
a8375 1
#endif	/* DEBUG */
d8388 1
a8388 1
	ldx	[%o2 + %lo(_C_LABEL(vmmap))], %o2
d8399 1
a8399 1
	add	%sp, (CC64FSZ+BIAS+BLOCK_SIZE-1), %l0	! Calculate pointer to fpstate
d8409 1
a8409 1
#else	/* NEW_FPSTATE */	/* NEW_FPSTATE */
d8443 2
a8444 2
	ldx	[%l1 + %lo(FPPROC)], %l2		! Load fpproc
	add	%sp, (CC64FSZ+BIAS+BLOCK_SIZE-1), %l0	! Calculate pointer to fpstate
d8447 1
a8447 1
	ldx	[%l2 + P_FPSTATE], %l3
d8451 1
a8451 1
	 set	EINTSTACK-BIAS, %l4			! Are we on intr stack?
d8454 1
a8454 1
	 set	INTSTACK-BIAS, %l4
d8463 1
a8463 1
	ldx	[%l4 + %lo(CURPROC)], %l5
d8468 1
a8468 1
	ldx	[%l5 + P_FPSTATE], %l6			! Save old fpstate
d8470 2
a8471 2
	stx	%l0, [%l5 + P_FPSTATE]			! Insert new fpstate
	stx	%l5, [%l1 + %lo(FPPROC)]		! Set new fpproc
d8473 2
a8474 2
#endif	/* NEW_FPSTATE */	/* NEW_FPSTATE */
#else	/* PMAP_FPSTATE */	/* PMAP_FPSTATE */
d8481 1
a8481 1
	ldx	[%o4 + %lo(FPPROC)], %o4
d8487 1
a8487 1
#endif	/* PMAP_FPSTATE */	/* PMAP_FPSTATE */
d8497 1
a8497 1
#endif	/*  DEBUG */	/* DEBUG */
d8583 29
d8627 1
a8627 1
#else	/* NEW_FPSTATE */	/* NEW_FPSTATE */
d8629 1
a8629 1
	ldx	[%l1 + %lo(FPPROC)], %l7
d8632 1
a8632 1
	ldx	[%l5 + P_FPSTATE], %l7
d8635 3
a8637 3
#endif	/* DEBUG */	/* DEBUG */
	stx	%g0, [%l1 + %lo(FPPROC)]		! Clear fpproc
	stx	%l6, [%l5 + P_FPSTATE]			! Save old fpstate
d8641 2
a8642 2
#endif	/* NEW_FPSTATE */	/* NEW_FPSTATE */
#else	/* PMAP_FPSTATE */	/* PMAP_FPSTATE */
d8648 1
a8648 1
#endif	/* PMAP_FPSTATE */	/* PMAP_FPSTATE */
d8650 1
a8650 1
#endif	/* PMAP_PHYS_PAGE */	/* PMAP_PHYS_PAGE */
d8658 1
a8658 1
	DLFLUSH %o0,%g1
d8673 1
a8673 1
#else	/* 0 */
d8678 1
a8678 1
	DLFLUSH %o0,%g1
d8683 1
a8683 1
	DLFLUSH %o1,%g1
d8689 1
a8689 1
#endif	/* 0 */
d8692 1
a8692 1
#endif	/* 0 */
d8714 1
a8714 1
	DLFLUSH %o2,%o3
d8716 1
a8716 1
	DLFLUSH2 %o3
d8723 1
a8723 1
	DLFLUSH %o2,%o3
d8725 1
a8725 1
	DLFLUSH2 %o3
d8732 1
a8732 1
	DLFLUSH %o2,%o3
d8734 1
a8734 1
	DLFLUSH2 %o3
d8746 2
a8747 2
#else	/* 1 */
	DLFLUSH %o2,%o3
d8749 1
a8749 1
	DLFLUSH2 %o3
d8752 1
a8752 1
#endif	/* 1 */
d8779 13
d8801 1
a8801 1
#endif	/* NOT_DEBUG */
d8817 1
a8817 1
#endif	/* DEBUG */
d8828 1
a8828 1
	DLFLUSH %o4,%g1
d8830 1
a8830 1
	DLFLUSH2 %g1
d8838 1
a8838 1
	DLFLUSH %o4, %o5
d8847 1
a8847 1
	DLFLUSH %o4,%g1
d8849 1
a8849 1
	DLFLUSH2 %g1
d8857 1
a8857 1
	DLFLUSH %o4, %o4
d8866 13
a8878 1
	DLFLUSH %o4, %o4
d8905 9
d8923 1
a8923 1
#endif	/* NOT_DEBUG */
d8938 1
a8938 1
#endif	/* DEBUG */
d8949 1
a8949 1
	DLFLUSH %o4,%o3
d8951 1
a8951 1
	DLFLUSH2 %o3
d8959 1
a8959 1
	DLFLUSH %o4, %o5
d8968 1
a8968 1
	DLFLUSH %o4,%o3
d8970 1
a8970 1
	DLFLUSH2 %o3
d8978 1
a8978 1
	DLFLUSH %o4, %o4
d9012 1
a9012 1
#else	/* 0 */
d9014 1
a9014 1
#endif	/* 0 */
d9031 1
a9031 1
#endif	/* 1 */
d9052 1
a9052 1
#endif	/* DEBUG */
d9074 1
a9074 1
!	 XXX check no delay slot
d9125 1
a9125 1
#endif	/* 0 */
d9484 1
a9484 1
#endif	/* 0 */
d9560 2
a9561 2
	ENABLE_FPU 0
#else	/* 1 */
d9564 2
a9565 2
	ldx	[%l1 + %lo(FPPROC)], %l2		! Load fpproc
	add	%sp, (CC64FSZ+BIAS+BLOCK_SIZE-1), %l0	! Calculate pointer to fpstate
d9568 1
a9568 1
	ldx	[%l2 + P_FPSTATE], %l3
d9572 1
a9572 1
	 set	EINTSTACK-BIAS, %l4			! Are we on intr stack?
d9575 1
a9575 1
	 set	INTSTACK-BIAS, %l4
d9584 1
a9584 1
	ldx	[%l4 + %lo(CURPROC)], %l5
d9588 3
a9590 3
	ldx	[%l5 + P_FPSTATE], %l6			! Save old fpstate
	stx	%l0, [%l5 + P_FPSTATE]			! Insert new fpstate
	stx	%l5, [%l1 + %lo(FPPROC)]		! Set new fpproc
d9592 1
a9592 1
#endif	/* 1 */
d9596 1
a9596 1
#endif	/* _KERNEL */
d9781 1
a9781 1
#else	/* 1 */
d9818 1
a9818 1
#endif	/* 1 */
d9834 1
a9834 1
#endif	/* RETURN_NAME */
d9918 1
a9918 1
#endif	/* RETURN_NAME */
d10015 1
a10015 1
#endif	/* RETURN_NAME */
d10112 1
a10112 1
#endif	/* RETURN_NAME */
d10207 1
a10207 1
#endif	/* RETURN_NAME */
d10300 1
a10300 1
#endif	/* RETURN_NAME */
d10392 1
a10392 1
#endif	/* RETURN_NAME */
d10482 1
a10482 1
#endif	/* RETURN_NAME */
d10658 1
a10658 1
#endif	/* 0 */
d10667 1
a10667 1
#else	/* 1 */
d10669 1
a10669 1
	ldx	[%l1 + %lo(FPPROC)], %l7
d10672 1
a10672 1
	ldx	[%l5 + P_FPSTATE], %l7
d10675 1
a10675 1
#endif	/* DEBUG */
d10677 1
a10677 1
	stx	%l2, [%l1 + %lo(FPPROC)]		! Restore old fproc
d10679 1
a10679 1
	 stx	%l6, [%l5 + P_FPSTATE]			! Restore old fpstate
d10684 1
a10684 1
#endif	/* 1 */
d10687 1
a10687 1
#endif	/* _KERNEL		 */
d10690 1
a10690 1
#endif	/* 1 */
d10754 1
a10754 1
#endif		/* 0 */
d10829 2
a10830 2
	ENABLE_FPU 0
#else	/* 1 */
d10837 2
a10838 2
	ldx	[%l1 + %lo(FPPROC)], %l2		! Load fpproc
	add	%sp, (CC64FSZ+BIAS+BLOCK_SIZE-1), %l0	! Calculate pointer to fpstate
d10841 1
a10841 1
	ldx	[%l2 + P_FPSTATE], %l3
d10845 1
a10845 1
	 set	EINTSTACK-BIAS, %l4			! Are we on intr stack?
d10848 1
a10848 1
	 set	INTSTACK-BIAS, %l4
d10857 1
a10857 1
	ldx	[%l4 + %lo(CURPROC)], %l5
d10862 1
a10862 1
	ldx	[%l5 + P_FPSTATE], %l6			! Save old fpstate
d10864 2
a10865 2
	stx	%l0, [%l5 + P_FPSTATE]			! Insert new fpstate
	stx	%l5, [%l1 + %lo(FPPROC)]		! Set new fpproc
d10867 1
a10867 1
#endif	/* 1 */
d10883 1
d10887 6
d10921 1
a10921 1
#else	/* 1 */
d10923 1
a10923 1
	ldx	[%l1 + %lo(FPPROC)], %l7
d10926 1
a10926 1
	ldx	[%l5 + P_FPSTATE], %l7
d10929 3
a10931 3
#endif	/* DEBUG */
	stx	%g0, [%l1 + %lo(FPPROC)]		! Clear fpproc
	stx	%l6, [%l5 + P_FPSTATE]			! Restore old fpstate
d10936 3
a10938 3
#endif	/* 1 */
#endif	/* 1 */
#endif	/* 1 */
d10965 1
a10965 1
#endif	/* DEBUG */
d10967 1
a10967 1
	ldx	[%o5 + %lo(CPCB)], %o5
d10969 1
a10969 1
	ldx	[%o5 + PCB_ONFAULT], %g1! save current onfault handler
d10971 1
a10971 1
	stx	%o3, [%o5 + PCB_ONFAULT]
d10984 1
a10984 1
!	 XXX check no delay slot
d10994 1
a10994 1
	stx	%g1, [%o5 + PCB_ONFAULT]! restore fault handler
d11007 1
a11007 1
!	 XXX check no delay slot
d11028 1
a11028 1
	stx	%g1, [%o5 + PCB_ONFAULT]! restore fault handler
d11130 1
a11130 1
	stx	%g1, [%o5 + PCB_ONFAULT]! restore fault handler
d11143 1
a11143 1
	stx	%g1, [%o5 + PCB_ONFAULT]! restore fault handler
d11152 1
a11152 1
	stx	%g1, [%o5 + PCB_ONFAULT]! restore fault handler
d11176 2
a11177 2
#endif	/* DEBUG */
	stx	%g1, [%o5 + PCB_ONFAULT]! restore fault handler
d11205 1
a11205 1
!	 XXX check no delay slot
d11412 1
a11412 1
#endif	/* DIAGONSTIC */
d11532 1
a11532 1
#endif	/* DIAGNOSTIC */
a11575 54

/* XXX belongs elsewhere (ctlreg.h?) */
#define	AFSR_CECC_ERROR		0x100000	/* AFSR Correctable ECC err */
#define	DATAPATH_CE		0x100		/* Datapath Correctable Err */

	.data
	_ALIGN
	.globl	_C_LABEL(cecclast), _C_LABEL(ceccerrs)
_C_LABEL(cecclast):
	.xword 0
_C_LABEL(ceccerrs):
	.word 0
	_ALIGN
	.text

/*
 * ECC Correctable Error handler - this doesn't do much except intercept
 * the error and reset the status bits.
 */
ENTRY(cecc_catch)
	ldxa	[%g0] ASI_AFSR, %g1			! g1 = AFSR
	ldxa	[%g0] ASI_AFAR, %g2			! g2 = AFAR

	sethi	%hi(cecclast), %g1			! cecclast = AFAR
	or	%g1, %lo(cecclast), %g1
	stx	%g2, [%g1]

	sethi	%hi(ceccerrs), %g1			! get current count
	or	%g1, %lo(ceccerrs), %g1
	lduw	[%g1], %g2				! g2 = ceccerrs

	ldxa	[%g0] ASI_DATAPATH_ERR_REG_READ, %g3	! Read UDB-Low status
	andcc	%g3, DATAPATH_CE, %g4			! Check CE bit
	be,pn	%xcc, 1f				! Don't clear unless
	 nop						!  necessary
	stxa	%g4, [%g0] ASI_DATAPATH_ERR_REG_WRITE	! Clear CE bit in UDBL
	membar	#Sync					! sync store
	inc	%g2					! ceccerrs++
1:	mov	0x18, %g5
	ldxa	[%g5] ASI_DATAPATH_ERR_REG_READ, %g3	! Read UDB-High status
	andcc	%g3, DATAPATH_CE, %g4			! Check CE bit
	be,pn	%xcc, 1f				! Don't clear unless
	 nop						!  necessary
	stxa	%g4, [%g5] ASI_DATAPATH_ERR_REG_WRITE	! Clear CE bit in UDBH
	membar	#Sync					! sync store
	inc	%g2					! ceccerrs++
1:	set	AFSR_CECC_ERROR, %g3
	stxa	%g3, [%g0] ASI_AFSR			! Clear CE in AFSR
	stw	%g2, [%g1]				! set ceccerrs
	membar	#Sync					! sync store
        CLRTT
        retry
        NOTREACHED

d11611 4
a11614 4
	!cmp	%g1, %o1
	!bge,pt	%icc, 1f
	! nop
	wrpr	%g0, PIL_HIGH, %pil
d11617 4
a11620 5
	 mov	8, %o4			! Number of slots to search
	set	intrpending, %o3

	ldstub	[%o2 + IH_BUSY], %o5
	membar #LoadLoad | #LoadStore
d11622 2
a11623 1
	 sll	%o1, 3+3, %o5	! Find start of table for this IPL
d11626 3
a11628 2
	ldx	[%o3], %o5		! Load list head
	stx	%o5, [%o2+IH_PEND]	! Link our intrhand node in
d11630 1
a11630 1
	casxa	[%o3] ASI_N, %o5, %o4
d11634 22
d11880 1
a11880 1
	CHKPT %o4,%o3,0x28
d11913 1
a11913 1
	CHKPT %o4,%o3,0x36
d11917 1
a11917 1
	CHKPT %o4,%o3,0x29
d11936 1
a11936 1
	CHKPT %o4,%o3,0x30
d11957 34
a11990 1
#endif /* DDB */	/* DDB */
d11997 1
a11997 1
	.xword	0
d12000 2
a12001 2
	.xword	0
#endif	/* defined(DDB) || NKSYMS > 0 */
d12004 1
a12004 1
	.xword	_C_LABEL(u0)		! KVA of proc0 uarea
d12033 1
a12033 1
	.space	16 * 4
d12036 1
d12042 1
a12042 1
#endif	/* DEBUG */
@


1.9.4.1
log
@Sync the SMP branch to something just after 3.0
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
@


1.9.4.2
log
@Merge in trunk
@
text
@d5665 1
a5665 1
	srax	%l2, 17, %l2			! Isolate UPAID from CPU reg
d11948 1
a11948 1
	ldx	[%o1 + %lo(_C_LABEL(cpu_clockrate) + 8)], %g1	! Get scale factor
d11950 2
a11951 2
	brnz,pt	%g1, 1f						! Already scaled?
	 or	%o5, %lo(MICROPERSEC), %o5
d11954 3
a11956 3
	ldx	[%o1 + %lo(_C_LABEL(cpu_clockrate))], %g1	! No, we need to calculate it
	udivx	%g1, %o5, %g1					! Hz / 10^6 = MHz
	stx	%g1, [%o1 + %lo(_C_LABEL(cpu_clockrate) + 8)]	! Save it so we don't need to divide again
d11960 1
a11960 1
	udivx	%o4, %g1, %o4					! Scale it: ticks / MHz = usec
d11967 1
@


1.9.4.3
log
@Merge in -current from about a week ago
@
text
@d6188 1
a6188 1
 *	cache_flush_phys(paddr_t, psize_t, int);
@


1.9.4.4
log
@Sync the SMP branch with 3.3
@
text
@d67 1
d73 1
a75 3
.register %g2,
.register %g3,

d428 27
d459 12
d888 1
a888 1
	VTRAP(T_ECCERR, cecc_catch)	! 063 = Correctable ECC error
d939 1
d941 3
d1128 1
a1128 1
	VTRAP(T_ECCERR, cecc_catch)	! 063 = Correctable ECC error
d1179 1
d1181 3
a2856 1
	sethi	%hi((2*NBPG)-8), %g7
d2858 1
a2858 1
	 or	%g7, %lo((2*NBPG)-8), %g7
d3124 3
d3256 2
a3257 10
	 nop

	/* Check if it's an executable mapping. */
	andcc	%g4, TTE_EXEC, %g0
	bz,pn	%xcc, textfault
	 nop


	or	%g4, TTE_ACCESS, %g7			! Update accessed bit
	btst	TTE_ACCESS, %g4				! Need to update access bit?
d3368 4
d3434 1
a3434 1
	and	%sp, 0x07, %g4		! 64-bit stack OK?
d3488 3
d3870 3
d4024 1
a4024 2
	ldstub  [%g5+IH_BUSY], %g6	! Check if already in use
	membar #LoadLoad | #LoadStore
d4065 1
a4065 1
#endif	/* DEBUG */ 
d4086 2
a4088 3
#endif	/* DIAGNOSTIC */
#endif	/* INTRLIST */

d4109 1
a4109 1
#endif	/* DEBUG */
d4244 1
a4244 1
	INTR_SETUP(-CC64FSZ-TF_SIZE-8)
d4255 7
d4285 1
a4285 1
	sll	%l6, 2, %l3
d4288 1
a4288 1
	ld	[%l4 + %l3], %o0
d4293 1
a4293 1
	st	%o0, [%l4]
a4295 2
	sethi	%hi(_C_LABEL(handled_intr_level)), %l4

a4297 8
	/*
	 * Set handled_intr_level and save the old one so we can restore it
	 * later.
	 */
	ld	[%l4 + %lo(_C_LABEL(handled_intr_level))], %l7
	st	%l6, [%l4 + %lo(_C_LABEL(handled_intr_level))]
	st	%l7, [%sp + CC64FSZ + STKB + TF_SIZE]

a4319 1
	LDPTR	[%l2 + IH_PEND], %l7	! Load next pending
a4321 21
	LDPTR	[%l2 + IH_CLR], %l1	! ih->ih_clear

	STPTR	%g0, [%l2 + IH_PEND]	! Unlink from list

	! Note that the function handler itself or an interrupt
	! may add handlers to the pending pending. This includes
	! the current entry in %l2 and entries held on our local
	! pending list in %l7.  The former is ok because we are
	! done with it now and the latter because they are still
	! marked busy. We may also be able to do this by having
	! the soft interrupts use a variation of the hardware
	! interrupts' ih_clr scheme.  Note:  The busy flag does
	! not itself prevent the handler from being entered
	! recursively.  It only indicates that the handler is
	! about to be invoked and that it should not be added
	! to the pending table.
	membar	#StoreStore | #LoadStore
	stb	%g0, [%l2 + IH_BUSY]	! Allow the ih to be reused

	! At this point, the current ih could already be added
	! back to the pending table.
d4325 5
d4332 1
a4332 1
	 add	%l5, %o0, %l5		! Add handler return value
d4334 1
a4464 5
	/* Restore old handled_intr_level */
	sethi	%hi(_C_LABEL(handled_intr_level)), %l4
	ld	[%sp + CC64FSZ + STKB + TF_SIZE], %l7
	st	%l7, [%l4 + %lo(_C_LABEL(handled_intr_level))]

d5720 3
a5722 1
	 * Step 7: change the trap base register, and install our TSBs
a5723 2

	/* Set the dmmu tsb */
d5725 1
a5725 1
	set	_C_LABEL(tsb_dmmu), %l0
d5732 1
a5732 3
	set	TSB, %l2
	stxa	%l0, [%l2] ASI_DMMU		! Install data TSB pointer
	membar	#Sync
d5734 11
a5745 9
	/* Set the immu tsb */
	sethi	%hi(0x1fff), %l2
	set	_C_LABEL(tsb_immu), %l0
	LDPTR	[%l0], %l0
	set	_C_LABEL(tsbsize), %l1
	or	%l2, %lo(0x1fff), %l2
	ld	[%l1], %l1
	andn	%l0, %l2, %l0			! Mask off size and split bits
	or	%l0, %l1, %l0			! Make a TSB pointer
d5749 2
a5750 2

	/* Change the trap base register */
d6012 1
a6012 1
 * Clear out all of D$ regardless of contents
d6029 1
d6038 31
d6072 1
a6072 1
 * Clear one page from D$.
d6091 2
a6092 4
	ba,pt	%icc, 1f
	 andn	%o1, 3, %o1	! Now we have bits <29:2> set
	
	.align 8
d6095 1
a6095 5
	mov	%o4, %o0
	deccc	16, %o5
	bl,pn	%icc, 2f
	
	 inc	16, %o4
d6098 1
a6098 1
	bne,pt	%xcc, 1b
d6100 13
d6114 9
a6122 3
	stxa	%g0, [%o0] ASI_DCACHE_TAG
	ba,pt	%icc, 1b
	 membar	#StoreLoad
d6124 2
a6126 1
	wr	%g0, ASI_PRIMARY_NOFAULT, %asi
d6129 1
d6131 1
a6131 1
	 membar	#Sync
d6136 1
a6136 1
 * Clear everything in that va range from D$.
d6151 1
d6159 3
d6176 3
d6190 1
a6190 1
 *	Clear a set of paddrs from the D$ and if param3 is
d6211 3
a6213 2
	!! D$ tags match pa bits 40-13.
	!! Generate a mask for them.
d6227 1
d6232 1
d6240 7
d7862 20
d7885 1
d7904 98
d8165 1
a8165 1
ENTRY(pmap_zero_phys)
d8455 1
a8455 1
ENTRY(pmap_copy_phys)
a11685 54

/* XXX belongs elsewhere (ctlreg.h?) */
#define	AFSR_CECC_ERROR		0x100000	/* AFSR Correctable ECC err */
#define	DATAPATH_CE		0x100		/* Datapath Correctable Err */

	.data
	_ALIGN
	.globl	_C_LABEL(cecclast), _C_LABEL(ceccerrs)
_C_LABEL(cecclast):
	.xword 0
_C_LABEL(ceccerrs):
	.word 0
	_ALIGN
	.text

/*
 * ECC Correctable Error handler - this doesn't do much except intercept
 * the error and reset the status bits.
 */
ENTRY(cecc_catch)
	ldxa	[%g0] ASI_AFSR, %g1			! g1 = AFSR
	ldxa	[%g0] ASI_AFAR, %g2			! g2 = AFAR

	sethi	%hi(cecclast), %g1			! cecclast = AFAR
	or	%g1, %lo(cecclast), %g1
	stx	%g2, [%g1]

	sethi	%hi(ceccerrs), %g1			! get current count
	or	%g1, %lo(ceccerrs), %g1
	lduw	[%g1], %g2				! g2 = ceccerrs

	ldxa	[%g0] ASI_DATAPATH_ERR_REG_READ, %g3	! Read UDB-Low status
	andcc	%g3, DATAPATH_CE, %g4			! Check CE bit
	be,pn	%xcc, 1f				! Don't clear unless
	 nop						!  necessary
	stxa	%g4, [%g0] ASI_DATAPATH_ERR_REG_WRITE	! Clear CE bit in UDBL
	membar	#Sync					! sync store
	inc	%g2					! ceccerrs++
1:	mov	0x18, %g5
	ldxa	[%g5] ASI_DATAPATH_ERR_REG_READ, %g3	! Read UDB-High status
	andcc	%g3, DATAPATH_CE, %g4			! Check CE bit
	be,pn	%xcc, 1f				! Don't clear unless
	 nop						!  necessary
	stxa	%g4, [%g5] ASI_DATAPATH_ERR_REG_WRITE	! Clear CE bit in UDBH
	membar	#Sync					! sync store
	inc	%g2					! ceccerrs++
1:	set	AFSR_CECC_ERROR, %g3
	stxa	%g3, [%g0] ASI_AFSR			! Clear CE in AFSR
	stw	%g2, [%g1]				! set ceccerrs
	membar	#Sync					! sync store
        CLRTT
        retry
        NOTREACHED

d11721 4
a11724 4
	!cmp	%g1, %o1
	!bge,pt	%icc, 1f
	! nop
	wrpr	%g0, PIL_HIGH, %pil
d11727 3
a11729 5
	 mov	8, %o4			! Number of slots to search
	set	intrpending, %o3

	ldstub	[%o2 + IH_BUSY], %o5
	membar #LoadLoad | #LoadStore
d11828 24
d11853 1
d11855 1
a11855 1
	.align	16
d11864 107
d11985 1
d12011 19
d12031 3
d12272 1
a12272 6
	.globl	_C_LABEL(intrcnt), _C_LABEL(eintrcnt)
	.globl _C_LABEL(intrnames), _C_LABEL(eintrnames)
	OTYPE(intrcnt)
	OTYPE(eintrcnt)
	OTYPE(intrnames)
	OTYPE(eintrnames)
d12293 1
a12293 1
	.space	16 * 4
d12297 1
@


1.9.4.5
log
@merge the trunk so we will get the genfs and locking fixes
@
text
@d11995 1
@


1.9.4.6
log
@Sync SMP branch to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.9.4.5 2003/05/16 00:29:40 niklas Exp $	*/
d58 1
d60 2
a61 4
#undef HORRID_III_HACK	/* define this to make a locore.s for usIII */
#ifdef HORRID_III_HACK
#define	NO_VCACHE		/* Map w/D$ disabled */
#else
d63 3
a65 1
#endif
d67 3
d72 1
d87 1
d98 1
a98 1
#else	/* MULTIPROCESSOR */
d102 1
a102 1
#endif	/* MULTIPROCESSOR */
d120 58
a177 1
#endif	/* 1 */
d186 1
a186 1
#else	/* 1 */
d188 1
a188 1
#endif	/* 1 */
a197 1
	.macro DLFLUSH a,t
d199 3
a201 2
	andn	\a, 0x1f, \t
	stxa	%g0, [ \t ] ASI_DCACHE_TAG
a202 2
#endif	/* DCACHE_BUG */
	.endm
d204 2
a205 3
	.macro DLFLUSH2 t
#ifdef DCACHE_BUG
	stxa	%g0, [ \t ] ASI_DCACHE_TAG
d207 22
a228 2
#endif	/* DCACHE_BUG */
	.endm
d235 2
a236 2
 *		TRAP_SETUP ...		! makes %o registers safe
 *		INCR _C_LABEL(cnt)+V_FOO	! count a foo
d238 9
a246 9
	.macro INCR what
	sethi	%hi(\what), %o0
	or	%o0, %lo(\what), %o0
99:
	lduw	[%o0], %o1
	add	%o1, 1, %o2
	casa	[%o0] ASI_P, %o1, %o2
	cmp	%o1, %o2
	bne,pn	%icc, 99b
a247 1
	.endm
d254 17
a270 34
	.macro GLOBTOLOC
	.irpc n,1234567
		mov	%g\n, %l\n
	.endr
	.endm

	.macro LOCTOGLOB
	.irpc n,1234567
		mov	%l\n, %g\n
	.endr
	.endm

/*
 * some macros to load and store a register window
 */
	.macro	SPILL storer,base,size,asi

	.irpc n,01234567
		\storer %l\n, [\base + (\n * \size)] \asi
	.endr
	.irpc n,01234567
		\storer %i\n, [\base + ((8+\n) * \size)] \asi
	.endr
	.endm

	.macro FILL loader, base, size, asi
	.irpc n,01234567
		\loader [\base + (\n * \size)] \asi, %l\n
	.endr

	.irpc n,01234567
		\loader [\base + ((8+\n) * \size)] \asi, %i\n
	.endr
	.endm
d282 1
a282 1
 * Correctly switch to a 64-bit stack
d286 4
a289 4
	.macro STACKFRAME size
	save	%sp, \size, %sp
	add	%sp, -BIAS, %o0		! Convert to 64-bits
	andcc	%sp, 1, %g0		! 64-bit stack?
d291 12
a302 1
	.endm
d312 33
a344 34
	.macro ENABLE_FPU siz
	save	%sp, -(CC64FSZ), %sp;		! Allocate a stack frame
	sethi	%hi(FPPROC), %l1;
	add	%fp, BIAS-FS_SIZE, %l0;		! Allocate a fpstate
	ldx	[%l1 + %lo(FPPROC)], %l2;	! Load fpproc
	andn	%l0, BLOCK_SIZE, %l0;		! Align it
	clr	%l3;				! NULL fpstate
	brz,pt	%l2, 1f;			! fpproc == NULL?
	 add	%l0, -BIAS-CC64FSZ-(\siz), %sp;	! Set proper %sp
	ldx	[%l2 + P_FPSTATE], %l3;
	brz,pn	%l3, 1f;			! Make sure we have an fpstate
	 mov	%l3, %o0;
	call	_C_LABEL(savefpstate);		! Save the old fpstate
1:
	 set	EINTSTACK-BIAS, %l4;		! Are we on intr stack?
	cmp	%sp, %l4;
	bgu,pt	%xcc, 1f;
	 set	INTSTACK-BIAS, %l4;
	cmp	%sp, %l4;
	blu	%xcc, 1f;
0:
	 sethi	%hi(_C_LABEL(proc0)), %l4;	! Yes, use proc0
	ba,pt	%xcc, 2f;			! XXXX needs to change to CPUs idle proc
	 or	%l4, %lo(_C_LABEL(proc0)), %l5;
1:
	sethi	%hi(CURPROC), %l4;		! Use curproc
	ldx	[%l4 + %lo(CURPROC)], %l5;
	brz,pn	%l5, 0b; nop;			! If curproc is NULL need to use proc0
2:
	ldx	[%l5 + P_FPSTATE], %l6;		! Save old fpstate
	stx	%l0, [%l5 + P_FPSTATE];		! Insert new fpstate
	stx	%l5, [%l1 + %lo(FPPROC)];	! Set new fpproc
	wr	%g0, FPRS_FEF, %fprs		! Enable FPU
	.endm
a349 2

	.macro RESTORE_FPU
d351 17
a367 11
	ldx	[%l5 + P_FPSTATE], %l7
	cmp	%l7, %l0
	tnz	1
#endif	/* DEBUG */
	stx	%l2, [%l1 + %lo(FPPROC)]	! Restore old fproc
	wr	%g0, 0, %fprs			! Disable fpu
	brz,pt	%l3, 1f				! Skip if no fpstate
	 stx	%l6, [%l5 + P_FPSTATE]		! Restore old fpstate

	call	_C_LABEL(loadfpstate)		! Re-load orig fpstate
	 mov	%l3, %o0
a368 1
	.endm
d394 2
a395 2
_C_LABEL(u0):	.xword	0
estack0:	.xword	0
d405 1
a405 1
#endif	/* KGDB */
d414 1
a414 1
#endif	/* DEBUG */
d421 1
a421 1
_C_LABEL(cpcb):	.xword	_C_LABEL(u0)
d427 1
a427 1
romp:	.xword	0
d467 2
a468 7
	.macro TA8
	.align 32
	.endm

	.macro TA32
	.align 128
	.endm
d479 72
a550 17
	.macro VTRAP type, label
	sethi	%hi(DATA_START),%g1
	rdpr	%tt,%g2
	or	%g1,0x28,%g1
	b	\label
	stx	%g2,[%g1]
	NOTREACHED
	TA8
	.endm
#else	/* DEBUG */
	.macro VTRAP type, label
	ba,a,pt	%icc,\label
	nop
	NOTREACHED
	TA8
	.endm
#endif	/* DEBUG */
d552 2
a553 3
	.macro HARDINT4U lev
	VTRAP \lev, _C_LABEL(sparc_interrupt)
	.endm
d557 2
a558 3
	.macro SOFTINT4U lev, bit
	HARDINT4U lev
	.endm
d561 1
a561 3
	.macro TRAP type
	VTRAP \type, slowtrap
	.endm
a563 1
	.macro	UTRAP type
d565 4
a568 4
	sir
#endif	/* DEBUG */
	VTRAP \type, slowtrap
	.endm
d571 1
a571 3
	.macro STRAP type
	VTRAP \type, slowtrap
	.endm
d575 13
a587 6
#define	BPT		VTRAP T_BREAKPOINT, bpt
#define	BPT_KGDB_EXEC	VTRAP T_KGDB_EXEC, bpt
#else	/* KGDB */
#define	BPT		TRAP T_BREAKPOINT
#define	BPT_KGDB_EXEC	TRAP T_KGDB_EXEC
#endif	/* KGDB */
a588 2
#define	SYSCALL		VTRAP 0x100, syscall_setup
#define	ZS_INTERRUPT4U	HARDINT4U 12
a592 1
	.macro CLRTT n
d594 1
a594 2
#if 0	/* for henric, but not yet */
	wrpr	%g0, 0x1ff - \n, %tt
d596 1
a596 1
	wrpr	%g0, 0x1ff, %tt
d598 143
a740 2
#endif	/* DEBUG */
	.endm
d742 31
a772 1
	.macro UCLEANWIN
d777 1
a777 1
#else	/* DEBUG */
d779 1
a779 1
#endif	/* DEBUG */
d797 1
a797 1
	ldx	[%l5 + %lo(CPCB)], %l5	! If pcb < fp < pcb+sizeof(pcb)
d806 2
a807 2
#endif	/* DIAGNOSTIC */
#endif	/* 0 */
d813 1
a813 1
	CLRTT 5
d815 38
a852 20
	.endm

	.macro KCLEANWIN
	clr	%l0
#ifdef DEBUG
	set	0xbadbeef, %l0		! DEBUG
#endif	/* DEBUG */
	mov %l0, %l1; mov %l0, %l2	! 024-027 = clean window trap
	rdpr %cleanwin, %o7		!	This handler is in-lined and cannot fault
	inc %o7; mov %l0, %l3	!       Nucleus (trap&IRQ) code does not need clean windows
	wrpr %g0, %o7, %cleanwin	!	Clear out %l0-%l8 and %o0-%o8 and inc %cleanwin and done
	mov %l0, %l4; mov %l0, %l5; mov %l0, %l6; mov %l0, %l7
	mov %l0, %o0; mov %l0, %o1; mov %l0, %o2; mov %l0, %o3

	mov %l0, %o4; mov %l0, %o5; mov %l0, %o6; mov %l0, %o7
	CLRTT 8
	retry; nop; TA32
	.endm

	.macro IMMU_MISS n
d854 3
d863 1
a863 1
	CLRTT \n
d869 11
a879 9
	.endm

	.macro DMMU_MISS n
	ldxa	[%g0] ASI_DMMU_8KPTR, %g2!	Load DMMU 8K TSB pointer
	ldxa	[%g0] ASI_DMMU, %g1	!	Load DMMU tag target register
	ldda	[%g2] ASI_NUCLEUS_QUAD_LDD, %g4	! Load TSB tag:data into %g4:%g5
	brgez,pn %g5, data_miss		!	Entry invalid?  Punt	XXX should be 2f
	 xor	%g1, %g4, %g4		!	Compare TLB tags
	brnz,pn	%g4, data_miss		!	Got right tag?
d881 9
a889 3
	CLRTT \n
	stxa	%g5, [%g0] ASI_DMMU_DATA_IN!	Enter new mapping
	retry				!	Try new mapping
d893 8
a900 21
	.endm

!! this can be just DMMU_MISS -- the only difference
!! between that & this is instruction ordering and #if 0 code -mdw
	.macro DMMU_MISS_2
	ldxa	[%g0] ASI_DMMU_8KPTR, %g2 !	Load DMMU 8K TSB pointer
	ldxa	[%g0] ASI_DMMU, %g1	!	Load DMMU tag target register
	ldda	[%g2] ASI_NUCLEUS_QUAD_LDD, %g4	! Load TSB tag:data into %g4:%g5
	brgez,pn %g5, data_miss		!	Entry invalid?  Punt
	 xor	%g1, %g4, %g4		!	Compare TLB tags
	brnz,pn	%g4, data_miss		!	Got right tag?
	 nop
	CLRTT 10
	stxa	%g5, [%g0] ASI_DMMU_DATA_IN!	Enter new mapping
	retry				!	Try new mapping
1:
	sir
	TA32
	.endm

	.macro DMMU_PROT dprot
d904 4
a907 154
	.endm
/*
 * Here are some oft repeated traps as macros.
 */

	! spill a 64-bit register window
	.macro SPILL64 label, as
\label:
	wr	%g0, \as, %asi
	SPILL	stxa, %sp+BIAS, 8, %asi
	saved
	CLRTT 1
	retry
	NOTREACHED
	TA32
	.endm

	! spill a 32-bit register window
	.macro SPILL32 label, as
\label:
	wr	%g0, \as, %asi
	srl	%sp, 0, %sp ! fixup 32-bit pointers
	SPILL	stwa, %sp, 4, %asi
	saved
	CLRTT 2
	retry
	NOTREACHED
	TA32
	.endm

	! Spill either 32-bit or 64-bit register window.
	.macro SPILLBOTH label64,label32, as
	andcc	%sp, 1, %g0
	bnz,pt	%xcc, \label64+4	! Is it a v9 or v8 stack?
	 wr	%g0, \as, %asi
	ba,pt	%xcc, \label32+8
	 srl	%sp, 0, %sp ! fixup 32-bit pointers
	NOTREACHED
	TA32
	.endm

	! fill a 64-bit register window
	.macro FILL64 label, as
\label:
	wr	%g0, \as, %asi
	FILL	ldxa, %sp+BIAS, 8, %asi
	restored
	CLRTT 3
	retry
	NOTREACHED
	TA32
	.endm

	! fill a 32-bit register window
	.macro FILL32 label, as
\label:
	wr	%g0, \as, %asi
	srl	%sp, 0, %sp ! fixup 32-bit pointers
	FILL	lda, %sp, 4, %asi
	restored
	CLRTT 4
	retry
	NOTREACHED
	TA32
	.endm

	! fill either 32-bit or 64-bit register window.
	.macro FILLBOTH label64,label32, as
	andcc	%sp, 1, %i0
	bnz	(\label64)+4 ! See if it's a v9 stack or v8
	 wr	%g0, \as, %asi
	ba	(\label32)+8
	 srl	%sp, 0, %sp ! fixup 32-bit pointers
	NOTREACHED
	TA32
	.endm

	.globl	start, _C_LABEL(kernel_text)
	_C_LABEL(kernel_text) = start		! for kvm_mkdb(8)
start:
	/* Traps from TL=0 -- traps from user mode */
#define TABLE	user_
	.globl	_C_LABEL(trapbase)
_C_LABEL(trapbase):
	b dostart; nop; TA8	! 000 = reserved -- Use it to boot
	/* We should not get the next 5 traps */
	UTRAP 0x001		! 001 = POR Reset -- ROM should get this
	UTRAP 0x002		! 002 = WDR -- ROM should get this
	UTRAP 0x003		! 003 = XIR -- ROM should get this
	UTRAP 0x004		! 004 = SIR -- ROM should get this
	UTRAP 0x005		! 005 = RED state exception
	UTRAP 0x006; UTRAP 0x007
	VTRAP T_INST_EXCEPT, textfault	! 008 = instr. access exept
	VTRAP T_TEXTFAULT, textfault	! 009 = instr access MMU miss
	VTRAP T_INST_ERROR, textfault	! 00a = instr. access err
	UTRAP 0x00b; UTRAP 0x00c; UTRAP 0x00d; UTRAP 0x00e; UTRAP 0x00f
	TRAP T_ILLINST			! 010 = illegal instruction
	TRAP T_PRIVINST		! 011 = privileged instruction
	UTRAP 0x012			! 012 = unimplemented LDD
	UTRAP 0x013			! 013 = unimplemented STD
	UTRAP 0x014; UTRAP 0x015; UTRAP 0x016; UTRAP 0x017; UTRAP 0x018
	UTRAP 0x019; UTRAP 0x01a; UTRAP 0x01b; UTRAP 0x01c; UTRAP 0x01d
	UTRAP 0x01e; UTRAP 0x01f
	TRAP T_FPDISABLED		! 020 = fp instr, but EF bit off in psr
	VTRAP T_FP_IEEE_754, fp_exception		! 021 = ieee 754 exception
	VTRAP T_FP_OTHER, fp_exception		! 022 = other fp exception
	TRAP T_TAGOF			! 023 = tag overflow
	UCLEANWIN			! 024-027 = clean window trap
	TRAP T_DIV0			! 028 = divide by zero
	UTRAP 0x029			! 029 = internal processor error
	UTRAP 0x02a; UTRAP 0x02b; UTRAP 0x02c; UTRAP 0x02d; UTRAP 0x02e; UTRAP 0x02f
	VTRAP T_DATAFAULT, winfault	! 030 = data fetch fault
	UTRAP 0x031			! 031 = data MMU miss -- no MMU
	VTRAP T_DATA_ERROR, winfault	! 032 = data access error
	VTRAP T_DATA_PROT, winfault	! 033 = data protection fault
	TRAP T_ALIGN			! 034 = address alignment error -- we could fix it inline...
	TRAP T_LDDF_ALIGN		! 035 = LDDF address alignment error -- we could fix it inline...
	TRAP T_STDF_ALIGN		! 036 = STDF address alignment error -- we could fix it inline...
	TRAP T_PRIVACT			! 037 = privileged action
	UTRAP 0x038; UTRAP 0x039; UTRAP 0x03a; UTRAP 0x03b; UTRAP 0x03c;
	UTRAP 0x03d; UTRAP 0x03e; UTRAP 0x03f;
	VTRAP T_ASYNC_ERROR, winfault	! 040 = data fetch fault
	SOFTINT4U 1, IE_L1		! 041 = level 1 interrupt
	HARDINT4U 2			! 042 = level 2 interrupt
	HARDINT4U 3			! 043 = level 3 interrupt
	SOFTINT4U 4, IE_L4		! 044 = level 4 interrupt
	HARDINT4U 5			! 045 = level 5 interrupt
	SOFTINT4U 6, IE_L6		! 046 = level 6 interrupt
	HARDINT4U 7			! 047 = level 7 interrupt
	HARDINT4U 8			! 048 = level 8 interrupt
	HARDINT4U 9			! 049 = level 9 interrupt
	HARDINT4U 10			! 04a = level 10 interrupt
	HARDINT4U 11			! 04b = level 11 interrupt
	ZS_INTERRUPT4U			! 04c = level 12 (zs) interrupt
	HARDINT4U 13			! 04d = level 13 interrupt
	HARDINT4U 14			! 04e = level 14 interrupt
	HARDINT4U 15			! 04f = nonmaskable interrupt
	UTRAP 0x050; UTRAP 0x051; UTRAP 0x052; UTRAP 0x053; UTRAP 0x054; UTRAP 0x055
	UTRAP 0x056; UTRAP 0x057; UTRAP 0x058; UTRAP 0x059; UTRAP 0x05a; UTRAP 0x05b
	UTRAP 0x05c; UTRAP 0x05d; UTRAP 0x05e; UTRAP 0x05f
	VTRAP 0x060, interrupt_vector; ! 060 = interrupt vector
	TRAP T_PA_WATCHPT		! 061 = physical address data watchpoint
	TRAP T_VA_WATCHPT		! 062 = virtual address data watchpoint
	VTRAP T_ECCERR, cecc_catch	! 063 = Correctable ECC error
ufast_IMMU_miss:			! 064 = fast instr access MMU miss
	IMMU_MISS 6
ufast_DMMU_miss:			! 068 = fast data access MMU miss
	DMMU_MISS 7
ufast_DMMU_protection:			! 06c = fast data access MMU protection
	DMMU_PROT udprot
	UTRAP 0x070			! Implementation dependent traps
	UTRAP 0x071; UTRAP 0x072; UTRAP 0x073; UTRAP 0x074; UTRAP 0x075; UTRAP 0x076
	UTRAP 0x077; UTRAP 0x078; UTRAP 0x079; UTRAP 0x07a; UTRAP 0x07b; UTRAP 0x07c
	UTRAP 0x07d; UTRAP 0x07e; UTRAP 0x07f
d909 3
a911 3
	SPILL64 uspill8,ASI_AIUS	! 0x080 spill_0_normal -- used to save user windows in user mode
	SPILL32 uspill4,ASI_AIUS	! 0x084 spill_1_normal
	SPILLBOTH uspill8,uspill4,ASI_AIUS		! 0x088 spill_2_normal
d914 2
a915 2
#endif	/* DEBUG */
	UTRAP 0x08c; TA32	! 0x08c spill_3_normal
d917 4
a920 4
	SPILL64 kspill8,ASI_N	! 0x090 spill_4_normal -- used to save supervisor windows
	SPILL32 kspill4,ASI_N	! 0x094 spill_5_normal
	SPILLBOTH kspill8,kspill4,ASI_N	! 0x098 spill_6_normal
	UTRAP 0x09c; TA32	! 0x09c spill_7_normal
d922 8
a929 8
	SPILL64 uspillk8,ASI_AIUS	! 0x0a0 spill_0_other -- used to save user windows in supervisor mode
	SPILL32 uspillk4,ASI_AIUS	! 0x0a4 spill_1_other
	SPILLBOTH uspillk8,uspillk4,ASI_AIUS	! 0x0a8 spill_2_other
	UTRAP 0x0ac; TA32	! 0x0ac spill_3_other
	UTRAP 0x0b0; TA32	! 0x0b0 spill_4_other
	UTRAP 0x0b4; TA32	! 0x0b4 spill_5_other
	UTRAP 0x0b8; TA32	! 0x0b8 spill_6_other
	UTRAP 0x0bc; TA32	! 0x0bc spill_7_other
d931 4
a934 4
	FILL64 ufill8,ASI_AIUS ! 0x0c0 fill_0_normal -- used to fill windows when running user mode
	FILL32 ufill4,ASI_AIUS	! 0x0c4 fill_1_normal
	FILLBOTH ufill8,ufill4,ASI_AIUS	! 0x0c8 fill_2_normal
	UTRAP 0x0cc; TA32	! 0x0cc fill_3_normal
d936 4
a939 4
	FILL64 kfill8,ASI_N	! 0x0d0 fill_4_normal -- used to fill windows when running supervisor mode
	FILL32 kfill4,ASI_N	! 0x0d4 fill_5_normal
	FILLBOTH kfill8,kfill4,ASI_N	! 0x0d8 fill_6_normal
	UTRAP 0x0dc; TA32	! 0x0dc fill_7_normal
d941 8
a948 8
	FILL64 ufillk8,ASI_AIUS	! 0x0e0 fill_0_other
	FILL32 ufillk4,ASI_AIUS	! 0x0e4 fill_1_other
	FILLBOTH ufillk8,ufillk4,ASI_AIUS	! 0x0e8 fill_2_other
	UTRAP 0x0ec; TA32	! 0x0ec fill_3_other
	UTRAP 0x0f0; TA32	! 0x0f0 fill_4_other
	UTRAP 0x0f4; TA32	! 0x0f4 fill_5_other
	UTRAP 0x0f8; TA32	! 0x0f8 fill_6_other
	UTRAP 0x0fc; TA32	! 0x0fc fill_7_other
d952 1
a952 1
	STRAP 0x102; STRAP 0x103; STRAP 0x104; STRAP 0x105; STRAP 0x106; STRAP 0x107
d956 7
a962 7
	STRAP 0x10b; STRAP 0x10c; STRAP 0x10d; STRAP 0x10e; STRAP 0x10f;
	STRAP 0x110; STRAP 0x111; STRAP 0x112; STRAP 0x113; STRAP 0x114; STRAP 0x115; STRAP 0x116; STRAP 0x117
	STRAP 0x118; STRAP 0x119; STRAP 0x11a; STRAP 0x11b; STRAP 0x11c; STRAP 0x11d; STRAP 0x11e; STRAP 0x11f
	STRAP 0x120; STRAP 0x121; STRAP 0x122; STRAP 0x123; STRAP 0x124; STRAP 0x125; STRAP 0x126; STRAP 0x127
	STRAP 0x128; STRAP 0x129; STRAP 0x12a; STRAP 0x12b; STRAP 0x12c; STRAP 0x12d; STRAP 0x12e; STRAP 0x12f
	STRAP 0x130; STRAP 0x131; STRAP 0x132; STRAP 0x133; STRAP 0x134; STRAP 0x135; STRAP 0x136; STRAP 0x137
	STRAP 0x138; STRAP 0x139; STRAP 0x13a; STRAP 0x13b; STRAP 0x13c; STRAP 0x13d; STRAP 0x13e; STRAP 0x13f
d967 8
a974 8
	STRAP 0x144; STRAP 0x145; STRAP 0x146; STRAP 0x147
	STRAP 0x148; STRAP 0x149; STRAP 0x14a; STRAP 0x14b; STRAP 0x14c; STRAP 0x14d; STRAP 0x14e; STRAP 0x14f
	STRAP 0x150; STRAP 0x151; STRAP 0x152; STRAP 0x153; STRAP 0x154; STRAP 0x155; STRAP 0x156; STRAP 0x157
	STRAP 0x158; STRAP 0x159; STRAP 0x15a; STRAP 0x15b; STRAP 0x15c; STRAP 0x15d; STRAP 0x15e; STRAP 0x15f
	STRAP 0x160; STRAP 0x161; STRAP 0x162; STRAP 0x163; STRAP 0x164; STRAP 0x165; STRAP 0x166; STRAP 0x167
	STRAP 0x168; STRAP 0x169; STRAP 0x16a; STRAP 0x16b; STRAP 0x16c; STRAP 0x16d; STRAP 0x16e; STRAP 0x16f
	STRAP 0x170; STRAP 0x171; STRAP 0x172; STRAP 0x173; STRAP 0x174; STRAP 0x175; STRAP 0x176; STRAP 0x177
	STRAP 0x178; STRAP 0x179; STRAP 0x17a; STRAP 0x17b; STRAP 0x17c; STRAP 0x17d; STRAP 0x17e; STRAP 0x17f
d976 16
a991 16
	UTRAP 0x180; UTRAP 0x181; UTRAP 0x182; UTRAP 0x183; UTRAP 0x184; UTRAP 0x185; UTRAP 0x186; UTRAP 0x187
	UTRAP 0x188; UTRAP 0x189; UTRAP 0x18a; UTRAP 0x18b; UTRAP 0x18c; UTRAP 0x18d; UTRAP 0x18e; UTRAP 0x18f
	UTRAP 0x190; UTRAP 0x191; UTRAP 0x192; UTRAP 0x193; UTRAP 0x194; UTRAP 0x195; UTRAP 0x196; UTRAP 0x197
	UTRAP 0x198; UTRAP 0x199; UTRAP 0x19a; UTRAP 0x19b; UTRAP 0x19c; UTRAP 0x19d; UTRAP 0x19e; UTRAP 0x19f
	UTRAP 0x1a0; UTRAP 0x1a1; UTRAP 0x1a2; UTRAP 0x1a3; UTRAP 0x1a4; UTRAP 0x1a5; UTRAP 0x1a6; UTRAP 0x1a7
	UTRAP 0x1a8; UTRAP 0x1a9; UTRAP 0x1aa; UTRAP 0x1ab; UTRAP 0x1ac; UTRAP 0x1ad; UTRAP 0x1ae; UTRAP 0x1af
	UTRAP 0x1b0; UTRAP 0x1b1; UTRAP 0x1b2; UTRAP 0x1b3; UTRAP 0x1b4; UTRAP 0x1b5; UTRAP 0x1b6; UTRAP 0x1b7
	UTRAP 0x1b8; UTRAP 0x1b9; UTRAP 0x1ba; UTRAP 0x1bb; UTRAP 0x1bc; UTRAP 0x1bd; UTRAP 0x1be; UTRAP 0x1bf
	UTRAP 0x1c0; UTRAP 0x1c1; UTRAP 0x1c2; UTRAP 0x1c3; UTRAP 0x1c4; UTRAP 0x1c5; UTRAP 0x1c6; UTRAP 0x1c7
	UTRAP 0x1c8; UTRAP 0x1c9; UTRAP 0x1ca; UTRAP 0x1cb; UTRAP 0x1cc; UTRAP 0x1cd; UTRAP 0x1ce; UTRAP 0x1cf
	UTRAP 0x1d0; UTRAP 0x1d1; UTRAP 0x1d2; UTRAP 0x1d3; UTRAP 0x1d4; UTRAP 0x1d5; UTRAP 0x1d6; UTRAP 0x1d7
	UTRAP 0x1d8; UTRAP 0x1d9; UTRAP 0x1da; UTRAP 0x1db; UTRAP 0x1dc; UTRAP 0x1dd; UTRAP 0x1de; UTRAP 0x1df
	UTRAP 0x1e0; UTRAP 0x1e1; UTRAP 0x1e2; UTRAP 0x1e3; UTRAP 0x1e4; UTRAP 0x1e5; UTRAP 0x1e6; UTRAP 0x1e7
	UTRAP 0x1e8; UTRAP 0x1e9; UTRAP 0x1ea; UTRAP 0x1eb; UTRAP 0x1ec; UTRAP 0x1ed; UTRAP 0x1ee; UTRAP 0x1ef
	UTRAP 0x1f0; UTRAP 0x1f1; UTRAP 0x1f2; UTRAP 0x1f3; UTRAP 0x1f4; UTRAP 0x1f5; UTRAP 0x1f6; UTRAP 0x1f7
	UTRAP 0x1f8; UTRAP 0x1f9; UTRAP 0x1fa; UTRAP 0x1fb; UTRAP 0x1fc; UTRAP 0x1fd; UTRAP 0x1fe; UTRAP 0x1ff
d997 1
a997 1
	UTRAP 0x000		! 000 = reserved -- Use it to boot
d999 6
a1004 6
	UTRAP 0x001		! 001 = POR Reset -- ROM should get this
	UTRAP 0x002		! 002 = WDR Watchdog -- ROM should get this
	UTRAP 0x003		! 003 = XIR -- ROM should get this
	UTRAP 0x004		! 004 = SIR -- ROM should get this
	UTRAP 0x005		! 005 = RED state exception
	UTRAP 0x006; UTRAP 0x007
d1006 46
a1051 19
	VTRAP T_INST_EXCEPT, textfault	! 008 = instr. access exept
	VTRAP T_TEXTFAULT, textfault	! 009 = instr access MMU miss -- no MMU
	VTRAP T_INST_ERROR, textfault	! 00a = instr. access err
	UTRAP 0x00b; UTRAP 0x00c; UTRAP 0x00d; UTRAP 0x00e; UTRAP 0x00f
	TRAP T_ILLINST			! 010 = illegal instruction
	TRAP T_PRIVINST		! 011 = privileged instruction
	UTRAP 0x012			! 012 = unimplemented LDD
	UTRAP 0x013			! 013 = unimplemented STD
	UTRAP 0x014; UTRAP 0x015; UTRAP 0x016; UTRAP 0x017; UTRAP 0x018
	UTRAP 0x019; UTRAP 0x01a; UTRAP 0x01b; UTRAP 0x01c; UTRAP 0x01d
	UTRAP 0x01e; UTRAP 0x01f
	TRAP T_FPDISABLED		! 020 = fp instr, but EF bit off in psr
	VTRAP T_FP_IEEE_754, fp_exception		! 021 = ieee 754 exception
	VTRAP T_FP_OTHER, fp_exception		! 022 = other fp exception
	TRAP T_TAGOF			! 023 = tag overflow
	KCLEANWIN			! 024-027 = clean window trap
	TRAP T_DIV0			! 028 = divide by zero
	UTRAP 0x029			! 029 = internal processor error
	UTRAP 0x02a; UTRAP 0x02b; UTRAP 0x02c; UTRAP 0x02d; UTRAP 0x02e; UTRAP 0x02f
d1053 5
a1057 5
	VTRAP T_DATAFAULT, winfault	! 030 = data fetch fault
	UTRAP 0x031			! 031 = data MMU miss -- no MMU
	VTRAP T_DATA_ERROR, winfault	! 032 = data fetch fault
	VTRAP T_DATA_PROT, winfault	! 033 = data fetch fault
	TRAP T_ALIGN			! 034 = address alignment error -- we could fix it inline...
d1059 17
a1075 17
	TRAP T_LDDF_ALIGN		! 035 = LDDF address alignment error -- we could fix it inline...
	TRAP T_STDF_ALIGN		! 036 = STDF address alignment error -- we could fix it inline...
	TRAP T_PRIVACT			! 037 = privileged action
	UTRAP 0x038; UTRAP 0x039; UTRAP 0x03a; UTRAP 0x03b; UTRAP 0x03c;
	UTRAP 0x03d; UTRAP 0x03e; UTRAP 0x03f;
	VTRAP T_ASYNC_ERROR, winfault	! 040 = data fetch fault
	SOFTINT4U 1, IE_L1		! 041 = level 1 interrupt
	HARDINT4U 2			! 042 = level 2 interrupt
	HARDINT4U 3			! 043 = level 3 interrupt
	SOFTINT4U 4, IE_L4		! 044 = level 4 interrupt
	HARDINT4U 5			! 045 = level 5 interrupt
	SOFTINT4U 6, IE_L6		! 046 = level 6 interrupt
	HARDINT4U 7			! 047 = level 7 interrupt
	HARDINT4U 8			! 048 = level 8 interrupt
	HARDINT4U 9			! 049 = level 9 interrupt
	HARDINT4U 10			! 04a = level 10 interrupt
	HARDINT4U 11			! 04b = level 11 interrupt
d1077 10
a1086 10
	HARDINT4U 13			! 04d = level 13 interrupt
	HARDINT4U 14			! 04e = level 14 interrupt
	HARDINT4U 15			! 04f = nonmaskable interrupt
	UTRAP 0x050; UTRAP 0x051; UTRAP 0x052; UTRAP 0x053; UTRAP 0x054; UTRAP 0x055
	UTRAP 0x056; UTRAP 0x057; UTRAP 0x058; UTRAP 0x059; UTRAP 0x05a; UTRAP 0x05b
	UTRAP 0x05c; UTRAP 0x05d; UTRAP 0x05e; UTRAP 0x05f
	VTRAP 0x060, interrupt_vector; ! 060 = interrupt vector
	TRAP T_PA_WATCHPT		! 061 = physical address data watchpoint
	TRAP T_VA_WATCHPT		! 062 = virtual address data watchpoint
	VTRAP T_ECCERR, cecc_catch	! 063 = Correctable ECC error
d1088 17
a1104 1
	IMMU_MISS 9
d1106 23
a1128 1
	DMMU_MISS_2
d1130 14
a1143 5
	DMMU_PROT kdprot
	UTRAP 0x070			! Implementation dependent traps
	UTRAP 0x071; UTRAP 0x072; UTRAP 0x073; UTRAP 0x074; UTRAP 0x075; UTRAP 0x076
	UTRAP 0x077; UTRAP 0x078; UTRAP 0x079; UTRAP 0x07a; UTRAP 0x07b; UTRAP 0x07c
	UTRAP 0x07d; UTRAP 0x07e; UTRAP 0x07f
d1145 4
a1148 4
	SPILL64 1,ASI_AIUS	! 0x080 spill_0_normal -- used to save user windows
	SPILL32 2,ASI_AIUS	! 0x084 spill_1_normal
	SPILLBOTH 1b,2b,ASI_AIUS	! 0x088 spill_2_normal
	UTRAP 0x08c; TA32	! 0x08c spill_3_normal
d1150 4
a1153 4
	SPILL64 1,ASI_N	! 0x090 spill_4_normal -- used to save supervisor windows
	SPILL32 2,ASI_N	! 0x094 spill_5_normal
	SPILLBOTH 1b,2b,ASI_N	! 0x098 spill_6_normal
	UTRAP 0x09c; TA32	! 0x09c spill_7_normal
d1155 8
a1162 8
	SPILL64 1,ASI_AIUS	! 0x0a0 spill_0_other -- used to save user windows in nucleus mode
	SPILL32 2,ASI_AIUS	! 0x0a4 spill_1_other
	SPILLBOTH 1b,2b,ASI_AIUS	! 0x0a8 spill_2_other
	UTRAP 0x0ac; TA32	! 0x0ac spill_3_other
	UTRAP 0x0b0; TA32	! 0x0b0 spill_4_other
	UTRAP 0x0b4; TA32	! 0x0b4 spill_5_other
	UTRAP 0x0b8; TA32	! 0x0b8 spill_6_other
	UTRAP 0x0bc; TA32	! 0x0bc spill_7_other
d1164 4
a1167 4
	FILL64 1,ASI_AIUS	! 0x0c0 fill_0_normal -- used to fill windows when running nucleus mode from user
	FILL32 2,ASI_AIUS	! 0x0c4 fill_1_normal
	FILLBOTH 1b,2b,ASI_AIUS	! 0x0c8 fill_2_normal
	UTRAP 0x0cc; TA32	! 0x0cc fill_3_normal
d1169 4
a1172 4
	FILL64 1,ASI_N		! 0x0d0 fill_4_normal -- used to fill windows when running nucleus mode from supervisor
	FILL32 2,ASI_N		! 0x0d4 fill_5_normal
	FILLBOTH 1b,2b,ASI_N	! 0x0d8 fill_6_normal
	UTRAP 0x0dc; TA32	! 0x0dc fill_7_normal
d1174 8
a1181 8
	FILL64 1,ASI_AIUS	! 0x0e0 fill_0_other -- used to fill user windows when running nucleus mode -- will we ever use this?
	FILL32 2,ASI_AIUS	! 0x0e4 fill_1_other
	FILLBOTH 1b,2b,ASI_AIUS! 0x0e8 fill_2_other
	UTRAP 0x0ec; TA32	! 0x0ec fill_3_other
	UTRAP 0x0f0; TA32	! 0x0f0 fill_4_other
	UTRAP 0x0f4; TA32	! 0x0f4 fill_5_other
	UTRAP 0x0f8; TA32	! 0x0f8 fill_6_other
	UTRAP 0x0fc; TA32	! 0x0fc fill_7_other
d1185 1
a1185 1
	STRAP 0x102; STRAP 0x103; STRAP 0x104; STRAP 0x105; STRAP 0x106; STRAP 0x107
d1189 15
a1203 15
	STRAP 0x10b; STRAP 0x10c; STRAP 0x10d; STRAP 0x10e; STRAP 0x10f;
	STRAP 0x110; STRAP 0x111; STRAP 0x112; STRAP 0x113; STRAP 0x114; STRAP 0x115; STRAP 0x116; STRAP 0x117
	STRAP 0x118; STRAP 0x119; STRAP 0x11a; STRAP 0x11b; STRAP 0x11c; STRAP 0x11d; STRAP 0x11e; STRAP 0x11f
	STRAP 0x120; STRAP 0x121; STRAP 0x122; STRAP 0x123; STRAP 0x124; STRAP 0x125; STRAP 0x126; STRAP 0x127
	STRAP 0x128; STRAP 0x129; STRAP 0x12a; STRAP 0x12b; STRAP 0x12c; STRAP 0x12d; STRAP 0x12e; STRAP 0x12f
	STRAP 0x130; STRAP 0x131; STRAP 0x132; STRAP 0x133; STRAP 0x134; STRAP 0x135; STRAP 0x136; STRAP 0x137
	STRAP 0x138; STRAP 0x139; STRAP 0x13a; STRAP 0x13b; STRAP 0x13c; STRAP 0x13d; STRAP 0x13e; STRAP 0x13f
	STRAP 0x140; STRAP 0x141; STRAP 0x142; STRAP 0x143; STRAP 0x144; STRAP 0x145; STRAP 0x146; STRAP 0x147
	STRAP 0x148; STRAP 0x149; STRAP 0x14a; STRAP 0x14b; STRAP 0x14c; STRAP 0x14d; STRAP 0x14e; STRAP 0x14f
	STRAP 0x150; STRAP 0x151; STRAP 0x152; STRAP 0x153; STRAP 0x154; STRAP 0x155; STRAP 0x156; STRAP 0x157
	STRAP 0x158; STRAP 0x159; STRAP 0x15a; STRAP 0x15b; STRAP 0x15c; STRAP 0x15d; STRAP 0x15e; STRAP 0x15f
	STRAP 0x160; STRAP 0x161; STRAP 0x162; STRAP 0x163; STRAP 0x164; STRAP 0x165; STRAP 0x166; STRAP 0x167
	STRAP 0x168; STRAP 0x169; STRAP 0x16a; STRAP 0x16b; STRAP 0x16c; STRAP 0x16d; STRAP 0x16e; STRAP 0x16f
	STRAP 0x170; STRAP 0x171; STRAP 0x172; STRAP 0x173; STRAP 0x174; STRAP 0x175; STRAP 0x176; STRAP 0x177
	STRAP 0x178; STRAP 0x179; STRAP 0x17a; STRAP 0x17b; STRAP 0x17c; STRAP 0x17d; STRAP 0x17e; STRAP 0x17f
d1205 16
a1220 16
	UTRAP 0x180; UTRAP 0x181; UTRAP 0x182; UTRAP 0x183; UTRAP 0x184; UTRAP 0x185; UTRAP 0x186; UTRAP 0x187
	UTRAP 0x188; UTRAP 0x189; UTRAP 0x18a; UTRAP 0x18b; UTRAP 0x18c; UTRAP 0x18d; UTRAP 0x18e; UTRAP 0x18f
	UTRAP 0x190; UTRAP 0x191; UTRAP 0x192; UTRAP 0x193; UTRAP 0x194; UTRAP 0x195; UTRAP 0x196; UTRAP 0x197
	UTRAP 0x198; UTRAP 0x199; UTRAP 0x19a; UTRAP 0x19b; UTRAP 0x19c; UTRAP 0x19d; UTRAP 0x19e; UTRAP 0x19f
	UTRAP 0x1a0; UTRAP 0x1a1; UTRAP 0x1a2; UTRAP 0x1a3; UTRAP 0x1a4; UTRAP 0x1a5; UTRAP 0x1a6; UTRAP 0x1a7
	UTRAP 0x1a8; UTRAP 0x1a9; UTRAP 0x1aa; UTRAP 0x1ab; UTRAP 0x1ac; UTRAP 0x1ad; UTRAP 0x1ae; UTRAP 0x1af
	UTRAP 0x1b0; UTRAP 0x1b1; UTRAP 0x1b2; UTRAP 0x1b3; UTRAP 0x1b4; UTRAP 0x1b5; UTRAP 0x1b6; UTRAP 0x1b7
	UTRAP 0x1b8; UTRAP 0x1b9; UTRAP 0x1ba; UTRAP 0x1bb; UTRAP 0x1bc; UTRAP 0x1bd; UTRAP 0x1be; UTRAP 0x1bf
	UTRAP 0x1c0; UTRAP 0x1c1; UTRAP 0x1c2; UTRAP 0x1c3; UTRAP 0x1c4; UTRAP 0x1c5; UTRAP 0x1c6; UTRAP 0x1c7
	UTRAP 0x1c8; UTRAP 0x1c9; UTRAP 0x1ca; UTRAP 0x1cb; UTRAP 0x1cc; UTRAP 0x1cd; UTRAP 0x1ce; UTRAP 0x1cf
	UTRAP 0x1d0; UTRAP 0x1d1; UTRAP 0x1d2; UTRAP 0x1d3; UTRAP 0x1d4; UTRAP 0x1d5; UTRAP 0x1d6; UTRAP 0x1d7
	UTRAP 0x1d8; UTRAP 0x1d9; UTRAP 0x1da; UTRAP 0x1db; UTRAP 0x1dc; UTRAP 0x1dd; UTRAP 0x1de; UTRAP 0x1df
	UTRAP 0x1e0; UTRAP 0x1e1; UTRAP 0x1e2; UTRAP 0x1e3; UTRAP 0x1e4; UTRAP 0x1e5; UTRAP 0x1e6; UTRAP 0x1e7
	UTRAP 0x1e8; UTRAP 0x1e9; UTRAP 0x1ea; UTRAP 0x1eb; UTRAP 0x1ec; UTRAP 0x1ed; UTRAP 0x1ee; UTRAP 0x1ef
	UTRAP 0x1f0; UTRAP 0x1f1; UTRAP 0x1f2; UTRAP 0x1f3; UTRAP 0x1f4; UTRAP 0x1f5; UTRAP 0x1f6; UTRAP 0x1f7
	UTRAP 0x1f8; UTRAP 0x1f9; UTRAP 0x1fa; UTRAP 0x1fb; UTRAP 0x1fc; UTRAP 0x1fd; UTRAP 0x1fe; UTRAP 0x1ff
d1233 1
a1233 1
	set	EINTSTACK-BIAS-CC64FSZ, %l0
d1249 4
a1252 4
	.macro CHKREG r
	ldx	[%o0 + 8*1], %o1
	cmp	\r, %o1
	stx	%o0, [%o0]
a1253 1
	.endm
d1261 8
a1268 3
	.irpc n,01234567
		stx	%g\n, [%o0 + 8*\n]
	.endr
d1277 7
a1283 3
	.irpc n,1234567
		CHKREG %g\n
	.endr
d1292 4
a1295 5
	.macro CHKPT r1,r2,val
	sethi	%hi(DATA_START), \r1
	mov	\val, \r2
	stb	\r2, [\r1 + 0x21]
	.endm
d1355 4
a1358 4
#else	/* DEBUG */
	.macro CHKPT r1,r2,val
	.endm
#endif	/* DEBUG */
d1380 21
a1400 24
	! set stack pointer redzone to base+minstack; alters base
.macro	SET_SP_REDZONE base, tmp
	add	\base, REDSIZE, \base
	sethi	%hi(_C_LABEL(redzone)), \tmp
	stx	\base, [\tmp + %lo(_C_LABEL(redzone))]
	.endm

	! variant with a constant
.macro	SET_SP_REDZONE_CONST const,  tmp1,  tmp2
	set	(\const) + REDSIZE, \tmp1
	sethi	%hi(_C_LABEL(redzone)), \tmp2
	stx	\tmp1, [\tmp2 + %lo(_C_LABEL(redzone))]
	.endm

	! check stack pointer against redzone (uses two temps)
.macro	CHECK_SP_REDZONE t1,  t2
	sethi	KERNBASE, \t1
	cmp	%sp, \t1
	blu,pt	%xcc, 7f
	 sethi	%hi(_C_LABEL(redzone)), \t1
	ldx	[\t1 + %lo(_C_LABEL(redzone))], \t2
	cmp	%sp, \t2	! if sp >= \t2, not in red zone
	blu	panic_red
	nop	! and can continue normally
a1401 1
	.endm
d1418 1
a1418 1
#else	/* DEBUG_NOTDEF */
d1420 4
a1423 7
.macro	SET_SP_REDZONE base, tmp
.endm
.macro	SET_SP_REDZONE_CONST const, t1, t2
.endm
.macro	CHECK_SP_REDZONE t1, t2
.endm
#endif	/* DEBUG_NOTDEF */
d1439 153
d1610 1
a1610 1
 * trap frame so we don't trap during the TRAP_SETUP operation.  There
d1687 75
a1761 21
	.macro	TRAP_SETUP stackspace
	sethi	%hi(CPCB), %g6
	sethi	%hi((\stackspace)), %g5

	ldx	[%g6 + %lo(CPCB)], %g6
	sethi	%hi(USPACE), %g7		! Always multiple of page size
	or	%g5, %lo((\stackspace)), %g5

	sra	%g5, 0, %g5			! Sign extend the damn thing

	add	%g6, %g7, %g6
	rdpr	%wstate, %g7			! Find if we're from user mode

	sub	%g7, WSTATE_KERN, %g7		! Compare & leave in register
	movrz	%g7, %sp, %g6			! Select old (kernel) stack or base of kernel stack
	btst	1, %g6				! Fixup 64-bit stack if necessary
	bnz,pt	%icc, 1f
	 add	%g6, %g5, %g6			! Allocate a stack frame
	inc	-BIAS, %g6
	nop
	nop
d1763 1
a1763 30
	SPILL stx, %g6 + CC64FSZ + BIAS + TF_L, 8, ! save local + in
	save	%g6, 0, %sp			! If we fault we should come right back here
	stx	%i0, [%sp + CC64FSZ + BIAS + TF_O + (0*8)] ! Save out registers to trap frame
	stx	%i1, [%sp + CC64FSZ + BIAS + TF_O + (1*8)]
	stx	%i2, [%sp + CC64FSZ + BIAS + TF_O + (2*8)]
	stx	%i3, [%sp + CC64FSZ + BIAS + TF_O + (3*8)]
	stx	%i4, [%sp + CC64FSZ + BIAS + TF_O + (4*8)]
	stx	%i5, [%sp + CC64FSZ + BIAS + TF_O + (5*8)]

	stx	%i6, [%sp + CC64FSZ + BIAS + TF_O + (6*8)]
	brz,pt	%g7, 1f			! If we were in kernel mode start saving globals
	 stx	%i7, [%sp + CC64FSZ + BIAS + TF_O + (7*8)]
	mov	CTX_PRIMARY, %g7

	! came from user mode -- switch to kernel mode stack
	rdpr	%canrestore, %g5		! Fixup register window state registers

	wrpr	%g0, 0, %canrestore

	wrpr	%g0, %g5, %otherwin

	wrpr	%g0, WSTATE_KERN, %wstate	! Enable kernel mode window traps -- now we can trap again

	stxa	%g0, [%g7] ASI_DMMU		! Switch MMU to kernel primary context
	sethi	%hi(KERNBASE), %g5
	membar	#Sync				! XXXX Should be taken care of by flush
	flush	%g5				! Some convenient address that won't trap
1:
	.endm
	
d1772 145
a1916 30
	.macro	INTR_SETUP stackspace
	rdpr	%wstate, %g7			! Find if we're from user mode

	sethi	%hi(EINTSTACK-BIAS), %g6
	sethi	%hi(EINTSTACK-INTSTACK), %g4

	or	%g6, %lo(EINTSTACK-BIAS), %g6	! Base of interrupt stack
	dec	%g4				! Make it into a mask

	sub	%g6, %sp, %g1			! Offset from interrupt stack
	sethi	%hi((\stackspace)), %g5

	or	%g5, %lo((\stackspace)), %g5

	andn	%g1, %g4, %g4			! Are we out of the interrupt stack range?
	xor	%g7, WSTATE_KERN, %g3

	sra	%g5, 0, %g5			! Sign extend the damn thing
	or	%g3, %g4, %g4			! Definitely not off the interrupt stack

	movrz	%g4, %sp, %g6

	add	%g6, %g5, %g5			! Allocate a stack frame
	btst	1, %g6
	bnz,pt	%icc, 1f

	 mov	%g5, %g6

	add	%g5, -BIAS, %g6

a1917 7
	SPILL stx, %g6 + CC64FSZ + BIAS + TF_L, 8,  ! save local+in to trap frame
	save	%g6, 0, %sp			! If we fault we should come right back here
	stx	%i0, [%sp + CC64FSZ + BIAS + TF_O + (0*8)] ! Save out registers to trap frame
	stx	%i1, [%sp + CC64FSZ + BIAS + TF_O + (1*8)]
	stx	%i2, [%sp + CC64FSZ + BIAS + TF_O + (2*8)]
	stx	%i3, [%sp + CC64FSZ + BIAS + TF_O + (3*8)]
	stx	%i4, [%sp + CC64FSZ + BIAS + TF_O + (4*8)]
d1919 69
a1987 26
	stx	%i5, [%sp + CC64FSZ + BIAS + TF_O + (5*8)]
	stx	%i6, [%sp + CC64FSZ + BIAS + TF_O + (6*8)]
	stx	%i6, [%sp + CC64FSZ + BIAS + TF_G + (0*8)]	! Save fp in clockframe->cf_fp
	brz,pt	%g3, 1f				! If we were in kernel mode start saving globals
	 stx	%i7, [%sp + CC64FSZ + BIAS + TF_O + (7*8)]
	! came from user mode -- switch to kernel mode stack
	 rdpr	%otherwin, %g5			! Has this already been done?

!	tst %g5; tnz %xcc, 1; nop; ! DEBUG -- this should _NEVER_ happen
	brnz,pn	%g5, 1f			! Don't set this twice

	 rdpr	%canrestore, %g5		! Fixup register window state registers

	wrpr	%g0, 0, %canrestore

	wrpr	%g0, %g5, %otherwin

	sethi	%hi(KERNBASE), %g5
	mov	CTX_PRIMARY, %g7

	wrpr	%g0, WSTATE_KERN, %wstate	! Enable kernel mode window traps -- now we can trap again

	stxa	%g0, [%g7] ASI_DMMU		! Switch MMU to kernel primary context
	membar	#Sync				! XXXX Should be taken care of by flush

	flush	%g5				! Some convenient address that won't trap
d1989 1
a1989 2
	.endm
	
d2008 1
a2008 1
	DLFLUSH %g4,%g5
d2010 1
a2010 1
	DLFLUSH2 %g5
d2017 1
a2017 1
	DLFLUSH %g4,%g5
d2019 1
a2019 1
	DLFLUSH2 %g5
d2026 1
a2026 1
	DLFLUSH %g4,%g5
d2028 1
a2028 1
	DLFLUSH2 %g5
d2043 1
a2043 1
#endif	/* DEBUG */
d2063 1
a2063 1
	ldx	[%g4 + %lo(_C_LABEL(ctxbusy))], %g4
d2080 1
a2080 1
	DLFLUSH %g4,%g6
d2082 1
a2082 1
	DLFLUSH2 %g6
d2096 1
a2096 1
	 or	%g4, TLB_MODIFY|TLB_ACCESS|TLB_W, %g7	! Update the modified bit
d2098 1
a2098 1
	btst	TLB_REAL_W|TLB_W, %g4			! Is it a ref fault?
d2112 1
a2112 1
#endif	/* DEBUG */
d2124 1
a2124 1
	 or	%g4, TLB_MODIFY|TLB_ACCESS|TLB_W, %g4	! Update the modified bit
d2135 7
a2141 1
#endif	/* DEBUG */
d2176 10
d2191 1
a2191 1
	ldx	[%g4 + %lo(_C_LABEL(ctxbusy))], %g4
d2214 1
a2214 1
#endif	/* DEBUG */
d2239 1
a2239 1
	 or	%g4, TLB_ACCESS, %g7			! Update the access bit
d2241 1
a2241 1
	btst	TLB_ACCESS, %g4				! Need to update access git?
d2247 1
a2247 1
	 or	%g4, TLB_ACCESS, %g4				! Update the modified bit
d2258 1
a2258 1
#endif	/* DEBUG */
d2269 1
a2269 1
#endif	/* 0 */
d2324 2
a2325 2
	CHKPT %g4,%g7,0x19
#endif	/* DEBUG */
d2335 1
a2335 1
	CHKPT %g4,%g7,0x20
d2352 1
a2352 1
	set	EINTSTACK+USPACE+CC64FSZ-BIAS, %fp ! Set the frame pointer to the middle of the idle stack
d2359 1
a2359 1
#endif	/* 1 */
d2369 6
d2384 1
a2384 1
	 * kernel window and a user window state.  If we do a TRAP_SETUP now,
d2396 6
d2420 1
a2420 1
	CHKPT %g5,%g7,0xe
d2424 1
a2424 1
#else	/* 0 /* Need to switch over to new stuff to fix WDR bug */ */
d2431 1
a2431 1
	CHKPT %g5,%g7,0xe
d2455 1
a2455 1
#endif	/* TRAPS_USE_IG */
d2461 2
a2462 2
	CHKPT %g4,%g7,0xf
#endif	/* DEBUG */
d2470 1
a2470 1
	TRAP_SETUP -CC64FSZ-TF_SIZE
d2474 1
a2474 1
#endif	/* 0 /* Need to switch over to new stuff to fix WDR bug */ */
d2490 1
a2490 1

d2493 53
a2545 1
#endif	/* 1 */
d2547 7
a2553 1
	ldx	[%g6 + %lo(CPCB)], %g6	! This is in the locked TLB and should not fault
d2558 2
a2559 2
	CHKPT %g5,%g7,0x11
#endif	/* DEBUG */
d2570 1
a2570 1
	ldx	[%g1 + %lo(_C_LABEL(ctxbusy))], %g1	! Load start of ctxbusy
d2577 1
a2577 1
#endif	/* DEBUG */
d2583 1
a2583 1
	DLFLUSH %g1,%g7
d2585 1
a2585 1
	DLFLUSH2 %g7
d2592 1
a2592 1
	DLFLUSH %g1,%g7
d2594 1
a2594 1
	DLFLUSH2 %g7
d2601 1
a2601 1
	DLFLUSH %g7,%g1
d2603 1
a2603 1
	DLFLUSH2 %g1
d2617 12
a2628 1
	CHKPT %g5,%g7,0x12
d2640 1
a2640 1
	CHKPT %g5,%g7,0x13
d2642 1
a2642 1
	DLFLUSH %g7,%g5
d2644 1
a2644 1
	DLFLUSH2 %g5
d2648 1
a2648 1
#endif	/* DEBUG */
d2654 1
a2654 1
!	CHKPT %g4,%g7,0x10	! Checkpoint
d2658 1
a2658 1
#endif	/* DEBUG */
d2671 2
a2672 2
	set	panicstack-CC64FSZ-BIAS, %sp		! Use panic stack.
#else	/* DEBUG */
d2674 3
a2676 3
	ldx	[%sp], %sp
	add	%sp, -CC64FSZ-BIAS, %sp			! Overwrite proc 0's stack.
#endif	/* DEBUG */
d2718 1
a2718 1
	CHKPT %g5,%g1,0x14
d2725 11
a2735 1
#else	/* 0 */
d2767 3
d2771 9
a2779 1
#endif	/* 0 */
d2781 20
a2800 1
	CHKPT %g5,%g1,0x15
d2806 1
a2806 1
	CHKPT %g2,%g5,0x16
d2821 1
a2821 1
	CHKPT %g2,%g1,0x17
d2823 1
a2823 1
#endif	/* DEBUG */
d2852 1
a2852 1
#endif	/* 1 */
d2855 1
a2855 1
	CHKPT %g2,%g1,0x18
d2859 74
a2932 1
#endif	/* DEBUG */
d2958 1
a2958 1
#endif	/* TRAPS_USE_IG */
d2981 1
a2981 1
#endif	/* TRAPS_USE_IG */
d2987 2
a2988 2
	CHKPT %g4,%g7,0xf
#endif	/* DEBUG */
d2996 1
a2996 1
	TRAP_SETUP -CC64FSZ-TF_SIZE
d2998 2
a2999 2
	INCR _C_LABEL(uvmexp)+V_FAULTS			! cnt.v_faults++ (clobbers %o0,%o1,%o2) should not fault
!	ldx	[%sp + CC64FSZ + BIAS + TF_FAULT], %g1		! DEBUG make sure this has not changed
d3010 8
d3020 1
a3020 1
	stx	%g1, [%sp + CC64FSZ + BIAS + TF_G + (1*8)]	! save g1
d3022 2
a3023 1
	stx	%g2, [%sp + CC64FSZ + BIAS + TF_G + (2*8)]	! save g2
d3025 1
a3025 1
	stx	%g3, [%sp + CC64FSZ + BIAS + TF_G + (3*8)]	! (sneak g3 in here)
d3027 1
a3027 1
	stx	%g4, [%sp + CC64FSZ + BIAS + TF_G + (4*8)]	! sneak in g4
d3029 1
a3029 1
	stx	%g5, [%sp + CC64FSZ + BIAS + TF_G + (5*8)]	! sneak in g5
d3031 1
a3031 1
	stx	%g6, [%sp + CC64FSZ + BIAS + TF_G + (6*8)]	! sneak in g6
d3033 1
a3033 1
	stx	%g7, [%sp + CC64FSZ + BIAS + TF_G + (7*8)]	! sneak in g7
d3039 5
a3043 5
#endif	/* DEBUG */
	sth	%o1, [%sp + CC64FSZ + BIAS + TF_TT]
	stx	%g1, [%sp + CC64FSZ + BIAS + TF_TSTATE]		! set tf.tf_psr, tf.tf_pc
	stx	%g2, [%sp + CC64FSZ + BIAS + TF_PC]		! set tf.tf_npc
	stx	%g3, [%sp + CC64FSZ + BIAS + TF_NPC]
d3046 2
a3047 2
	stb	%g5, [%sp + CC64FSZ + BIAS + TF_PIL]
	stb	%g5, [%sp + CC64FSZ + BIAS + TF_OLDPIL]
d3053 1
a3053 1
	CHKPT %g1,%g3,0x21
d3055 2
a3056 2
#else	/* 1 */
	CHKPT %g1,%g3,0x21
d3058 1
a3058 1
#endif	/* 1 */
d3061 18
d3092 1
a3092 1
	st	%g4, [%sp + CC64FSZ + BIAS + TF_Y]
d3101 1
a3101 1
	 add	%sp, CC64FSZ + BIAS, %o0	! (argument: &tf)
d3104 1
a3104 1
	CHKPT %o1,%o2,1
d3106 6
d3113 1
a3113 1
	 ldx	[%sp + CC64FSZ + BIAS + TF_TSTATE], %g1		! Load this for return_from_trap
d3119 1
a3119 1
	 add	%sp, CC64FSZ + BIAS, %o0	! (argument: &tf)
d3144 10
d3159 1
a3159 1
	ldx	[%g4 + %lo(_C_LABEL(ctxbusy))], %g4
d3182 1
a3182 1
#endif	/* DEBUG */
d3211 1
a3211 1
	andcc	%g4, TLB_EXEC, %g0
d3216 2
a3217 2
	or	%g4, TLB_ACCESS, %g7			! Update accessed bit
	btst	TLB_ACCESS, %g4				! Need to update access bit?
d3223 1
a3223 1
	 or	%g4, TLB_ACCESS, %g4			! Update accessed bit
d3233 1
a3233 1
#endif	/* DEBUG */
d3244 1
a3244 1
#endif	/* 1 */
d3276 1
a3276 1
#endif	/* TRAPS_USE_IG */
d3284 2
a3285 2
	TRAP_SETUP -CC64FSZ-TF_SIZE
	INCR _C_LABEL(uvmexp)+V_FAULTS			! cnt.v_faults++ (clobbers %o0,%o1,%o2)
d3295 3
a3297 3
	stx	%g1, [%sp + CC64FSZ + BIAS + TF_G + (1*8)]	! save g1
	stx	%g2, [%sp + CC64FSZ + BIAS + TF_G + (2*8)]	! save g2
	stx	%g3, [%sp + CC64FSZ + BIAS + TF_G + (3*8)]	! (sneak g3 in here)
d3299 1
a3299 1
	stx	%g4, [%sp + CC64FSZ + BIAS + TF_G + (4*8)]	! sneak in g4
d3301 1
a3301 1
	stx	%g5, [%sp + CC64FSZ + BIAS + TF_G + (5*8)]	! sneak in g5
d3303 1
a3303 1
	stx	%g6, [%sp + CC64FSZ + BIAS + TF_G + (6*8)]	! sneak in g6
d3305 1
a3305 1
	stx	%g7, [%sp + CC64FSZ + BIAS + TF_G + (7*8)]	! sneak in g7
d3309 2
a3310 2
	stx	%g1, [%sp + CC64FSZ + BIAS + TF_TSTATE]		! set tf.tf_psr, tf.tf_pc
	sth	%o1, [%sp + CC64FSZ + BIAS + TF_TT]! debug
d3312 2
a3313 2
	stx	%o2, [%sp + CC64FSZ + BIAS + TF_PC]
	stx	%g3, [%sp + CC64FSZ + BIAS + TF_NPC]		! set tf.tf_npc
d3316 2
a3317 2
	stb	%g5, [%sp + CC64FSZ + BIAS + TF_PIL]
	stb	%g5, [%sp + CC64FSZ + BIAS + TF_OLDPIL]
d3322 1
a3322 1
	CHKPT %g1,%g3,0x22
d3331 1
a3331 1
	 st	%g7, [%sp + CC64FSZ + BIAS + TF_Y]		! set tf.tf_y
d3335 1
a3335 1
	 add	%sp, CC64FSZ + BIAS, %o0	! (argument: &tf)
d3337 1
a3337 1
	CHKPT %o1,%o2,2
d3340 1
a3340 1
	 ldx	[%sp + CC64FSZ + BIAS + TF_TSTATE], %g1	! Load this for return_from_trap
d3347 1
a3347 1
	 add	%sp, CC64FSZ + BIAS, %o0	! (argument: &tf)
d3386 1
a3386 1
#endif	/* TRAPS_USE_IG */
d3400 1
a3400 1
#else	/* DEBUG */
d3402 3
a3404 3
	ldx	[%sp], %sp
	add	%sp, -CC64FSZ-BIAS, %sp	! Overwrite proc 0's stack.
#endif	/* DEBUG */
d3406 1
a3406 1
#endif	/* DIAGNOSTIC */
d3412 1
a3412 1
	TRAP_SETUP -CC64FSZ-TF_SIZE
d3414 1
a3414 1
	stx	%g1, [%sp + CC64FSZ + BIAS + TF_TSTATE]
d3416 1
a3416 1
	stx	%g2, [%sp + CC64FSZ + BIAS + TF_PC]
d3418 1
a3418 1
	stx	%g3, [%sp + CC64FSZ + BIAS + TF_NPC]
d3420 1
a3420 1
	st	%g5, [%sp + CC64FSZ + BIAS + TF_Y]
d3422 1
a3422 1
	sth	%o1, [%sp + CC64FSZ + BIAS + TF_TT]! debug
d3425 6
a3430 6
	stx	%g1, [%sp + CC64FSZ + BIAS + TF_G + (1*8)]
	stx	%g2, [%sp + CC64FSZ + BIAS + TF_G + (2*8)]
	add	%sp, CC64FSZ + BIAS, %o0		! (&tf)
	stx	%g3, [%sp + CC64FSZ + BIAS + TF_G + (3*8)]
	stx	%g4, [%sp + CC64FSZ + BIAS + TF_G + (4*8)]
	stx	%g5, [%sp + CC64FSZ + BIAS + TF_G + (5*8)]
d3432 4
a3435 4
	stx	%g6, [%sp + CC64FSZ + BIAS + TF_G + (6*8)]
	stx	%g7, [%sp + CC64FSZ + BIAS + TF_G + (7*8)]
	stb	%g5, [%sp + CC64FSZ + BIAS + TF_PIL]
	stb	%g5, [%sp + CC64FSZ + BIAS + TF_OLDPIL]
d3442 1
a3442 1
	CHKPT %g2,%g3,0x24
d3450 1
a3450 1
	CHKPT %o1,%o2,3
d3485 2
a3486 2
	 ldx	[%g6 + %lo(CPCB)], %g7
	set	USPACE-CC64FSZ-TF_SIZE-BIAS, %g5
d3488 44
a3531 44
	SET_SP_REDZONE %g7, %g5
	stx	%g1, [%g6 + CC64FSZ + BIAS + TF_FAULT]		! Generate a new trapframe
	stx	%i0, [%g6 + CC64FSZ + BIAS + TF_O + (0*8)]	!	but don't bother with
	stx	%i1, [%g6 + CC64FSZ + BIAS + TF_O + (1*8)]	!	locals and ins
	stx	%i2, [%g6 + CC64FSZ + BIAS + TF_O + (2*8)]
	stx	%i3, [%g6 + CC64FSZ + BIAS + TF_O + (3*8)]
	stx	%i4, [%g6 + CC64FSZ + BIAS + TF_O + (4*8)]
	stx	%i5, [%g6 + CC64FSZ + BIAS + TF_O + (5*8)]
	stx	%i6, [%g6 + CC64FSZ + BIAS + TF_O + (6*8)]
	stx	%i7, [%g6 + CC64FSZ + BIAS + TF_O + (7*8)]
#ifdef DEBUG
	ldx	[%sp + CC64FSZ + BIAS + TF_I + (0*8)], %l0	! Copy over the rest of the regs
	ldx	[%sp + CC64FSZ + BIAS + TF_I + (1*8)], %l1	! But just dirty the locals
	ldx	[%sp + CC64FSZ + BIAS + TF_I + (2*8)], %l2
	ldx	[%sp + CC64FSZ + BIAS + TF_I + (3*8)], %l3
	ldx	[%sp + CC64FSZ + BIAS + TF_I + (4*8)], %l4
	ldx	[%sp + CC64FSZ + BIAS + TF_I + (5*8)], %l5
	ldx	[%sp + CC64FSZ + BIAS + TF_I + (6*8)], %l6
	ldx	[%sp + CC64FSZ + BIAS + TF_I + (7*8)], %l7
	stx	%l0, [%g6 + CC64FSZ + BIAS + TF_I + (0*8)]
	stx	%l1, [%g6 + CC64FSZ + BIAS + TF_I + (1*8)]
	stx	%l2, [%g6 + CC64FSZ + BIAS + TF_I + (2*8)]
	stx	%l3, [%g6 + CC64FSZ + BIAS + TF_I + (3*8)]
	stx	%l4, [%g6 + CC64FSZ + BIAS + TF_I + (4*8)]
	stx	%l5, [%g6 + CC64FSZ + BIAS + TF_I + (5*8)]
	stx	%l6, [%g6 + CC64FSZ + BIAS + TF_I + (6*8)]
	stx	%l7, [%g6 + CC64FSZ + BIAS + TF_I + (7*8)]
	ldx	[%sp + CC64FSZ + BIAS + TF_L + (0*8)], %l0
	ldx	[%sp + CC64FSZ + BIAS + TF_L + (1*8)], %l1
	ldx	[%sp + CC64FSZ + BIAS + TF_L + (2*8)], %l2
	ldx	[%sp + CC64FSZ + BIAS + TF_L + (3*8)], %l3
	ldx	[%sp + CC64FSZ + BIAS + TF_L + (4*8)], %l4
	ldx	[%sp + CC64FSZ + BIAS + TF_L + (5*8)], %l5
	ldx	[%sp + CC64FSZ + BIAS + TF_L + (6*8)], %l6
	ldx	[%sp + CC64FSZ + BIAS + TF_L + (7*8)], %l7
	stx	%l0, [%g6 + CC64FSZ + BIAS + TF_L + (0*8)]
	stx	%l1, [%g6 + CC64FSZ + BIAS + TF_L + (1*8)]
	stx	%l2, [%g6 + CC64FSZ + BIAS + TF_L + (2*8)]
	stx	%l3, [%g6 + CC64FSZ + BIAS + TF_L + (3*8)]
	stx	%l4, [%g6 + CC64FSZ + BIAS + TF_L + (4*8)]
	stx	%l5, [%g6 + CC64FSZ + BIAS + TF_L + (5*8)]
	stx	%l6, [%g6 + CC64FSZ + BIAS + TF_L + (6*8)]
	stx	%l7, [%g6 + CC64FSZ + BIAS + TF_L + (7*8)]
#endif	/* DEBUG */
d3534 1
a3534 1
#endif	/* 1 */
d3597 1
a3597 1
#endif	/* 0 */
d3621 1
a3621 1
	TRAP_SETUP -CCFSZ-TF_SIZE
d3692 1
a3692 1
#endif	/* DEBUG */
d3712 1
a3712 1
#endif	/* DEBUG */
d3741 1
a3741 1
#endif	/* DEBUG */
d3770 1
a3770 1
	ldx	[%l1 + %lo(CPCB)], %l1
d3778 1
a3778 1
#endif	/* KGDB */
d3789 2
a3790 2
#endif	/* TRAPS_USE_IG */
	TRAP_SETUP -CC64FSZ-TF_SIZE
d3794 2
a3795 2
	sth	%o1, [%sp + CC64FSZ + BIAS + TF_TT]! debug
#endif	/* DEBUG */
d3798 1
a3798 1
	stx	%g1, [%sp + CC64FSZ + BIAS + TF_G + ( 1*8)]
d3801 1
a3801 1
	stx	%g2, [%sp + CC64FSZ + BIAS + TF_G + ( 2*8)]
d3803 1
a3803 1
	stx	%g3, [%sp + CC64FSZ + BIAS + TF_G + ( 3*8)]
d3805 1
a3805 1
	stx	%g4, [%sp + CC64FSZ + BIAS + TF_G + ( 4*8)]
d3807 3
a3809 3
	stx	%g5, [%sp + CC64FSZ + BIAS + TF_G + ( 5*8)]
	stx	%g6, [%sp + CC64FSZ + BIAS + TF_G + ( 6*8)]
	CHKPT %g5,%g6,0x31
d3811 2
a3812 2
	stx	%g7, [%sp + CC64FSZ + BIAS + TF_G + ( 7*8)]
	add	%sp, CC64FSZ + BIAS, %o0	! (&tf)
d3814 4
a3817 4
	stx	%g1, [%sp + CC64FSZ + BIAS + TF_TSTATE]
	stx	%o2, [%sp + CC64FSZ + BIAS + TF_PC]
	stx	%o3, [%sp + CC64FSZ + BIAS + TF_NPC]
	st	%o4, [%sp + CC64FSZ + BIAS + TF_Y]
d3820 2
a3821 2
	stb	%g5, [%sp + CC64FSZ + BIAS + TF_PIL]
	stb	%g5, [%sp + CC64FSZ + BIAS + TF_OLDPIL]
d3831 1
a3831 1
	CHKPT %o1,%o2,0x32
d3833 1
a3833 1
	CHKPT %o1,%o2,4
d3891 1
a3891 1
	.space	16 * 8 * 8
d3904 1
a3904 1
#endif	/* DEBUG */
d3907 10
d3923 13
d3940 1
a3940 1
	 sllx	%g2, 3, %g5	! Calculate entry number
d3945 1
a3945 1
#endif	/* DEBUG */
d3948 1
a3948 1
	ldx	[%g3 + %g5], %g5	! We have a pointer to the handler
d3952 1
a3952 1
	STACKFRAME -CC64FSZ		! Get a clean register window
d3963 5
a3967 1
#endif	/* DEBUG */
d3973 1
d3977 1
d3981 1
a3981 1
	sll	%g6, 3+3, %g3	! Find start of table for this IPL
d3985 3
a3987 2
	ldx	[%g1], %g3		! Load list head
	stx	%g3, [%g5+IH_PEND]	! Link our intrhand node in
d3989 1
a3989 1
	casxa	[%g1] ASI_N, %g3, %g7
d3993 47
d4048 1
a4048 1
	STACKFRAME -CC64FSZ		! Get a clean register window
d4061 1
a4061 1
#endif	/* DEBUG */	/* DEBUG */
d4078 2
a4079 2
#endif	/* DEBUG */
	STACKFRAME -CC64FSZ		! Get a clean register window
d4156 1
a4156 1
#endif	/* TRAPS_USE_IG */
d4165 1
a4165 1
	DLFLUSH %g3, %g2
d4167 1
a4167 1
	 ldx	[%g3 + 8], %g5	! intrlev[1] is reserved for %tick intr.
d4169 28
a4196 1
	INTR_SETUP -CC64FSZ-TF_SIZE-8
d4199 7
a4205 7
	stx	%g1, [%sp + CC64FSZ + BIAS + TF_G + ( 1*8)]
	stx	%g2, [%sp + CC64FSZ + BIAS + TF_G + ( 2*8)]
	stx	%g3, [%sp + CC64FSZ + BIAS + TF_G + ( 3*8)]
	stx	%g4, [%sp + CC64FSZ + BIAS + TF_G + ( 4*8)]
	stx	%g5, [%sp + CC64FSZ + BIAS + TF_G + ( 5*8)]
	stx	%g6, [%sp + CC64FSZ + BIAS + TF_G + ( 6*8)]
	stx	%g7, [%sp + CC64FSZ + BIAS + TF_G + ( 7*8)]
d4209 1
a4209 1
	INCR _C_LABEL(uvmexp)+V_INTR	! cnt.v_intr++; (clobbers %o0,%o1,%o2)
d4215 1
a4215 1
	stw	%l6, [%sp + CC64FSZ + BIAS + TF_Y]	! Silly, but we need to save this for rft
d4217 1
a4217 1
	CHKPT %l4,%l7,0x26
d4219 3
a4221 3
	sth	%l5, [%sp + CC64FSZ + BIAS + TF_TT]! debug
	stx	%l0, [%sp + CC64FSZ + BIAS + TF_TSTATE]	! set up intrframe/clockframe
	stx	%l1, [%sp + CC64FSZ + BIAS + TF_PC]
d4223 2
a4224 2
	stx	%l2, [%sp + CC64FSZ + BIAS + TF_NPC]
	stx	%fp, [%sp + CC64FSZ + BIAS + TF_KSTACK]	!  old frame pointer
d4228 1
a4228 1
	stb	%l6, [%sp + CC64FSZ + BIAS + TF_PIL]	! set up intrframe/clockframe
d4232 1
a4232 1
	stb	%o1, [%sp + CC64FSZ + BIAS + TF_OLDPIL]	! old %pil
d4251 1
a4251 1
	st	%l7, [%sp + CC64FSZ + BIAS + TF_SIZE]
d4256 1
a4256 1
	sll	%l6, 3+3, %l2
d4262 1
d4265 1
a4265 1
	ldx	[%l4], %l2		! Check a slot
d4270 1
a4270 1
	casxa	[%l4] ASI_N, %l2, %l7	! Grab the entire list
d4273 1
a4273 1
	 add	%sp, CC64FSZ+BIAS, %o2	! tf = %sp + CC64FSZ + BIAS
d4275 4
a4278 4
	ldx	[%l2 + IH_PEND], %l7	! Load next pending
	ldx	[%l2 + IH_FUN], %o4	! ih->ih_fun
	ldx	[%l2 + IH_ARG], %o0	! ih->ih_arg
	ldx	[%l2 + IH_CLR], %l1	! ih->ih_clear
d4280 1
a4280 1
	stx	%g0, [%l2 + IH_PEND]	! Unlink from list
d4310 19
a4328 1
intrcmplt:
d4330 1
a4330 2
	 * Re-read SOFTINT to see if any new  pending interrupts
	 * at this level.
d4332 5
a4336 6
	mov	1, %l3			! Ack softint
	rd	SOFTINT, %l7		! %l5 contains #intr handled.
	sll	%l3, %l6, %l3		! Generate IRQ mask
	btst	%l3, %l7		! leave mask in %l3 for retry code
	bnz,pn	%icc, sparc_intr_retry
	 mov	1, %l5			! initialize intr count for next run
d4339 3
a4341 3
	set	_C_LABEL(intrdebug), %o2
	ld	[%o2], %o2
	btst	INTRDEBUG_FUNC, %o2
d4345 4
a4348 2
	STACKFRAME -CC64FSZ		! Get a clean register window
	LOAD_ASCIZ(%o0, "sparc_interrupt:  done\r\n")
d4351 1
a4351 1
	 nop
d4355 1
d4358 5
a4362 4
	/* Restore old handled_intr_level */
	sethi	%hi(_C_LABEL(handled_intr_level)), %l4
	ld	[%sp + CC64FSZ + BIAS + TF_SIZE], %l7
	st	%l7, [%l4 + %lo(_C_LABEL(handled_intr_level))]
d4364 83
a4446 6
	ldub	[%sp + CC64FSZ + BIAS + TF_OLDPIL], %l3	! restore old %pil
	wrpr	%g0, PSTATE_KERN, %pstate	! Disable interrupts
	wrpr	%l3, 0, %pil

	CHKPT %o1,%o2,5
	ba,a,pt	%icc, return_from_trap
d4466 1
a4466 1
#endif /* notyet */	/* notyet */
d4481 1
a4481 1
 *	[%sp + CC64FSZ + BIAS] => trap frame
d4498 2
a4499 2
	ldx	[%sp + CC64FSZ + BIAS + TF_PC], %g2
	ldx	[%sp + CC64FSZ + BIAS + TF_NPC], %g3
d4502 50
a4551 1
#endif	/* DEBUG */
d4555 1
a4555 1
	ldx	[%sp + CC64FSZ + BIAS + TF_TSTATE], %g1
d4561 1
a4561 1
	 ldx	[%o1 + %lo(CURPROC)], %o0
d4563 1
a4563 1
#endif	/* 0 */
d4575 7
a4581 7
	ldx	[%sp + CC64FSZ + BIAS + TF_G + (1*8)], %g1
	ldx	[%sp + CC64FSZ + BIAS + TF_G + (2*8)], %g2
	ldx	[%sp + CC64FSZ + BIAS + TF_G + (3*8)], %g3
	ldx	[%sp + CC64FSZ + BIAS + TF_G + (4*8)], %g4
	ldx	[%sp + CC64FSZ + BIAS + TF_G + (5*8)], %g5
	ldx	[%sp + CC64FSZ + BIAS + TF_G + (6*8)], %g6
	ldx	[%sp + CC64FSZ + BIAS + TF_G + (7*8)], %g7
d4586 9
a4594 9
#endif	/* TRAPS_USE_IG */
	ldx	[%sp + CC64FSZ + BIAS + TF_O + (0*8)], %i0
	ldx	[%sp + CC64FSZ + BIAS + TF_O + (1*8)], %i1
	ldx	[%sp + CC64FSZ + BIAS + TF_O + (2*8)], %i2
	ldx	[%sp + CC64FSZ + BIAS + TF_O + (3*8)], %i3
	ldx	[%sp + CC64FSZ + BIAS + TF_O + (4*8)], %i4
	ldx	[%sp + CC64FSZ + BIAS + TF_O + (5*8)], %i5
	ldx	[%sp + CC64FSZ + BIAS + TF_O + (6*8)], %i6
	ldx	[%sp + CC64FSZ + BIAS + TF_O + (7*8)], %i7
d4596 2
a4597 2
	ld	[%sp + CC64FSZ + BIAS + TF_Y], %g4
	ldx	[%sp + CC64FSZ + BIAS + TF_TSTATE], %g1		! load new values
d4599 2
a4600 2
	ldx	[%sp + CC64FSZ + BIAS + TF_PC], %g2
	ldx	[%sp + CC64FSZ + BIAS + TF_NPC], %g3
d4607 6
a4612 1
#endif	/* DEBUG */
d4616 1
a4616 1
	CHKPT %g4, %g7, 6
d4635 1
a4635 1
	CHKPT %g1,%g2,7
d4637 1
a4637 1
	CHKPT %g1,%g2,0			! Clear this out
d4643 52
d4697 1
a4697 1
#endif	/*  */
d4719 26
a4744 1
	CHKPT %g4,%g7,8
d4749 6
d4773 1
a4773 1
#endif	/* DEBUG */
d4775 1
a4775 1
	ldx	[%g6 + %lo(CPCB)], %g6
d4778 1
a4778 1
	CHKPT %g4,%g7,9
d4785 1
a4785 1
#endif	/* DEBUG */
d4797 1
a4797 1
#endif	/* DEBUG */
d4841 1
a4841 1
#endif	/* DEBUG */
d4866 7
a4872 1
#endif	/* DEBUG */
d4879 1
a4879 1
	ldx	[%g5 + %lo(CPCB)], %g5
d4885 1
a4885 1
#endif	/* DEBUG */
d4907 1
a4907 1
	CHKPT %g4,%g7,0xa
d4911 42
d4957 1
a4957 1
	CHKPT %g4,%g7,0xb
d4966 52
a5017 1
	CHKPT %g4,%g7,0xd
d5020 1
a5020 1
	ldx	[%g5 + %lo(CPCB)], %g5
d5024 1
a5024 1
#endif	/* DEBUG */
d5059 1
a5059 1
#endif /* DDB */	/* DDB */
d5063 1
d5101 48
a5148 1
#endif	/* defined(DDB) */
d5213 1
a5213 1
	stx	%l4, [%l3 + %lo(_C_LABEL(esym))]
d5222 1
a5222 1
	 stx	%l4, [%l3 + %lo(_C_LABEL(ssym))]
d5238 1
a5238 1
	stx	%l4, [%l3 + %lo(_C_LABEL(esym))]
d5246 1
a5246 1
	stx	%l4, [%l3 + %lo(_C_LABEL(ssym))]
d5248 1
a5248 1
#endif	/* defined(DDB) || NKSYMS > 0 */
d5255 1
a5255 1
	stx	%o4, [%o5]	! It's initialized data, I hope
d5261 1
d5266 6
d5294 1
a5294 1
#if 0 || defined(HORRID_III_HACK)
a5299 3
#ifdef HORRID_III_HACK
	andn	%o1, MCCR_ICACHE_EN, %o1	! and Icache...
#endif
d5302 1
a5302 1
#endif	/* 0 */
d5308 5
a5312 1
	set	0x2000,%o0			! fixed: 8192 contexts
d5315 1
d5317 1
a5317 1
	 clr	%g4				! Clear data segment pointer
a5358 3
#ifdef HORRID_III_HACK
	andn	%o1, MCCR_ICACHE_EN, %o1	! and Icache...
#endif
d5361 1
a5361 1
#endif	/*  */
d5373 1
a5373 1
	ldx	[%l1], %l1
d5375 1
a5375 1
	ldx	[%l4], %l4
d5399 1
a5399 1
	or	%l2, TLB_L|TLB_CP|TLB_CV|TLB_P, %o4	! And low bits:	L=1|CP=1|CV=1|E=0|P=1|W=1(ugh)|G=0
d5407 1
a5407 1
	or	%l5, TLB_L|TLB_CP|TLB_CV|TLB_P|TLB_W, %o4	! And low bits:	L=1|CP=1|CV=1|E=0|P=1|W=1(ugh)|G=0
d5416 1
a5416 1
#endif	/* DEBUG */
d5452 2
a5453 2
	or	%l5, TLB_L|TLB_CP|TLB_P|TLB_W, %o2
#else	/* NO_VCACHE */
d5455 2
a5456 2
	or	%l5, TLB_L|TLB_CP|TLB_CV|TLB_P|TLB_W, %o2
#endif	/* NO_VCACHE */
d5476 2
a5477 2
	or	%l2, TLB_L|TLB_CP|TLB_P, %o2
#else	/* NO_VCACHE */
d5479 2
a5480 2
	or	%l2, TLB_L|TLB_CP|TLB_CV|TLB_P, %o2
#endif	/* NO_VCACHE */
d5496 1
a5496 1
	or	%l2, TLB_L|TLB_CP|TLB_CV|TLB_P, %o4
d5505 1
a5505 1
#endif	/* DEBUG */
d5522 1
a5522 1
	or	%l2, TLB_CP|TLB_P, %o2		! And low bits:	L=0|CP=1|CV=0|E=0|P=1|G=0
d5582 2
a5583 2
	or	%l2, TLB_L|TLB_CP|TLB_P, %o2
#else	/* NO_VCACHE */
d5585 2
a5586 2
	or	%l2, TLB_L|TLB_CP|TLB_CV|TLB_P, %o2
#endif	/* NO_VCACHE */
d5632 1
a5632 1
#endif	/* DEBUG */
d5640 1
a5640 1
	ldx	[%l1 + %lo(_C_LABEL(cpus))], %l1
d5667 4
a5670 4
	or	%l1, TLB_L|TLB_CP|TLB_P|TLB_W, %l2	! And low bits:	L=1|CP=1|CV=0|E=0|P=1|W=0|G=0
#else	/* NO_VCACHE */
	or	%l1, TLB_L|TLB_CP|TLB_CV|TLB_P|TLB_W, %l2	! And low bits:	L=1|CP=1|CV=1|E=0|P=1|W=0|G=0
#endif	/* NO_VCACHE */
d5686 1
a5686 1
	ldx	[%l0 + %lo(CPUINFO_VA+CI_INITSTACK)], %l0
d5688 1
d5691 1
d5702 1
a5702 1
	ldx	[%l0], %l0
d5716 1
a5716 1
	ldx	[%l0], %l0
d5739 1
a5739 1
#endif	/* DEBUG */
d5741 11
d5757 1
a5757 1
	ldx	[%l0 + %lo(CPUINFO_VA+CI_SPINUP)], %o1
d5788 1
a5788 1
	 ldx	[%o4+%lo(romp)], %o4		! v9 stack, just load the addr and callit
d5805 3
d5809 1
d5823 6
d5848 1
d5850 3
d5880 1
a5880 1
#endif	/* DEBUG */
d5902 1
a5902 1
#endif	/* DEBUG */
d5942 13
a5954 1
#endif	/* DEBUG */
d5967 1
a5967 1
#endif	/* DIAGNOSTIC */
d6024 3
d6121 5
d6129 1
a6129 1
#endif	/* DEBUG */
d6170 1
d6292 1
d6296 3
a6298 1
#endif	/* COMPAT_NETBSD */
d6300 8
d6314 1
a6314 1
#endif	/* ENTRY */
d6329 1
a6329 1
#else	/* GPROF */
d6331 1
a6331 1
#endif	/* GPROF */
d6349 14
d6368 1
a6368 1
	ldx	[%o4 + %lo(CPCB)], %o4	! catch faults
d6371 1
a6371 1
	stx	%o5, [%o4 + PCB_ONFAULT]
d6396 14
d6415 1
a6415 1
	ldx	[%o4 + %lo(CPCB)], %o4	! catch faults
d6418 1
a6418 1
	stx	%o5, [%o4 + PCB_ONFAULT]
d6436 1
a6436 1
	 stx	%o1, [%o3]		!		*lencopied = len;
d6439 1
a6439 1
	 stx	%g0, [%o4 + PCB_ONFAULT]! return (error);
d6442 11
d6485 1
a6485 1
	 stx	%o1, [%o3]		!		*lencopied = len;
d6499 1
a6499 1
#endif	/* DIAGNOSTIC */
d6514 13
d6529 1
a6529 1
	ldx	[%o3 + %lo(CPCB)], %o3
d6533 1
a6533 1
	stx	%o4, [%o3 + PCB_ONFAULT]
d6563 1
a6563 1
!	 XXX check no delay slot
d6696 1
a6696 1
	ldx	[%o3 + %lo(CPCB)], %o3
d6698 1
a6698 1
	stx	%g0, [%o3 + PCB_ONFAULT]
d6720 15
d6738 1
a6738 1
	ldx	[%o3 + %lo(CPCB)], %o3
d6742 1
a6742 1
	stx	%o4, [%o3 + PCB_ONFAULT]
d6754 1
a6754 1
!	 XXX check no delay slot
d6774 1
a6774 1
!	 XXX check no delay slot
d6906 1
a6906 1
	ldx	[%o3 + %lo(CPCB)], %o3
d6908 1
a6908 1
	stx	%g0, [%o3 + PCB_ONFAULT]
d6921 2
a6922 2
	ldx	[%o3 + %lo(CPCB)], %o3
	stx	%g0, [%o3 + PCB_ONFAULT]
d6924 11
d6996 1
a6996 1
#endif	/* DEBUG */
d7000 13
d7032 1
a7032 1
#endif	/* 0 */
d7034 1
a7034 1
	stx	%l1, [%l6 + %lo(CPCB)]	! cpcb = &idle_u
d7036 1
d7038 3
d7052 2
a7053 2
	SET_SP_REDZONE %l6, %l5
#endif	/* DEBUG */
d7060 1
a7060 1
#endif	/* defined(MULTIPROCESSOR) || defined(LOCKDEBUG) */
d7083 2
a7084 2
	INCR _C_LABEL(nswitchexit)		! nswitchexit++;
	INCR _C_LABEL(uvmexp)+V_SWTCH		! cnt.v_switch++;
d7091 1
a7091 1
	ldx	[%l6 + %lo(CPCB)], %l5
d7112 2
a7113 2
#endif	/* defined(MULTIPROCESSOR) || defined(LOCKDEBUG) */
	 stx	%g0, [%l7 + %lo(CURPROC)] ! curproc = NULL;
d7117 20
d7150 1
a7150 1
#endif	/* UVM_PAGE_IDLE_ZERO */
d7158 1
a7158 1
#endif	/* defined(MULTIPROCESSOR) || defined(LOCKDEBUG) */
d7231 6
a7236 1
#endif	/* DEBUG */
d7242 1
a7242 1
#endif	/* DEBUG */
d7247 1
a7247 1
	ldx	[%l6 + %lo(CPCB)], %l5
d7250 1
a7250 1
	ldx	[%l7 + %lo(CURPROC)], %l4	! lastproc = curproc;
d7253 1
a7253 1
	stx	%g0, [%l7 + %lo(CURPROC)]	! curproc = NULL;
d7285 1
a7285 1
!	 XXX check no delay slot
d7289 1
a7289 1
#else	/* POPC */
d7305 1
a7305 1
#endif	/* POPC */
d7310 1
a7310 1
	sll	%o4, 3+1, %o0
d7312 1
a7312 1
	ldx	[%o5], %l3		! p = q->ph_link;
d7315 4
a7318 4
!	 XXX check no delay slot
	ldx	[%l3], %o0		! tmp0 = p->p_forw;
	stx	%o0, [%o5]		! q->ph_link = tmp0;
	stx	%o5, [%o0 + 8]	! tmp0->p_back = q;
d7321 1
a7321 1
!	 XXX check no delay slot
d7345 1
a7345 1
	ldx	[%l3 + P_WCHAN], %o0	! if (p->p_wchan)
d7347 1
a7347 1
!	 XXX check no delay slot
d7351 1
a7351 1
!	 XXX check no delay slot
d7362 1
a7362 1
#endif	/* defined(MULTIPROCESSOR) */
d7366 1
a7366 1
#endif	/* notyet */
d7369 2
a7370 2
	ldx	[%l3 + P_ADDR], %l1		! newpcb = p->p_addr;
	stx	%g0, [%l3 + 8]		! p->p_back = NULL;
d7377 2
a7378 2
#endif	/* defined(MULTIPROCESSOR) || defined(LOCKDEBUG) */
	 stx	%l4, [%l7 + %lo(CURPROC)]	! restore old proc so we can save it
d7388 19
d7411 1
a7411 1
	INCR _C_LABEL(nswitchdiff)	! clobbers %o0,%o1,%o2
d7427 13
d7441 2
a7442 2
	stx	%l3, [%l7 + %lo(CURPROC)]	! curproc = p;
	stx	%l1, [%l6 + %lo(CPCB)]	! cpcb = newpcb;
d7444 21
d7482 16
d7499 3
a7501 3
	SET_SP_REDZONE %o0, %o1
	CHECK_SP_REDZONE %o0, %o1
#endif	/* DEBUG */
d7510 1
a7510 1
	ldx	[%l3 + P_VMSPACE], %o3	! vm = p->p_vmspace;
d7513 1
a7513 1
	ldx	[%o3 + VM_PMAP], %o2		! if (vm->vm_pmap.pm_ctx != NULL)
d7531 14
d7555 61
d7621 33
d7690 17
d7720 2
a7721 2
	ldx	[%sp + CC64FSZ + BIAS + TF_TSTATE], %g1
	ldx	[%sp + CC64FSZ + BIAS + TF_NPC], %g2	! pc = tf->tf_npc from execve/fork
d7725 1
a7725 1
	stx	%g3, [%sp + CC64FSZ + BIAS + TF_NPC]
d7727 3
a7729 3
	stx	%g2, [%sp + CC64FSZ + BIAS + TF_PC]
	stx	%g1, [%sp + CC64FSZ + BIAS + TF_TSTATE]
#else	/* 0 */
d7731 1
a7731 1
	ldx	[%sp + CC64FSZ + BIAS + TF_NPC], %g2	! pc = tf->tf_npc from execve/fork
d7735 1
a7735 1
	stx	%g3, [%sp + CC64FSZ + BIAS + TF_NPC]
d7737 34
a7770 4
	stx	%g2, [%sp + CC64FSZ + BIAS + TF_PC]
	stx	%g1, [%sp + CC64FSZ + BIAS + TF_TSTATE]
#endif	/* 0 */
	CHKPT %o3,%o4,0x35
d7775 1
a7775 1
	stx	%g0, [%o2 + PCB_ONFAULT]! error in r/w, clear pcb_onfault
d7777 3
d7790 1
a7790 1
	stx	%g0, [%o2 + PCB_ONFAULT]! error in r/w, clear pcb_onfault
d7814 6
d7823 2
a7824 1
	ldx	[%o2 + %lo(CPCB)], %o2	! cpcb->pcb_onfault = Lfserr;
d7826 4
a7829 1
	stx	%o5, [%o2 + PCB_ONFAULT]
d7834 1
a7834 1
	DLFLUSH %o0,%o5		!	flush cache line
d7837 4
d7855 574
a8428 6
	 btst	8, %o4
	ba,pt	%icc, 1f
	 lda	[%o0] %asi, %o0		!	value = *(int *)addr;
0:
	ldxa	[%o0] %asi, %o0		!	value = *(long *)addr;
1:	
d8430 6
a8435 3
	brz	%o5, 1f			! if (cache flush addr != 0)
	 nop
	DLFLUSH2 %o5			!	flush cache line again
d8437 21
a8457 4
	wr	%g0, ASI_PRIMARY_NOFAULT, %asi		! Restore default ASI	
	stx	%g0, [%o2 + PCB_ONFAULT]
	retl				! made it, clear onfault and return
	 membar	#StoreStore|#StoreLoad
d8459 8
a8466 10
	/*
	 * Fault handler for probeget
	 */
_C_LABEL(Lfsprobe):
	stx	%g0, [%o2 + PCB_ONFAULT]! error in r/w, clear pcb_onfault
	mov	-1, %o1
	wr	%g0, ASI_PRIMARY_NOFAULT, %asi		! Restore default ASI	
	membar	#StoreStore|#StoreLoad
	retl				! and return error indicator
	 mov	-1, %o0
d8468 4
a8471 18
/*
 * probeset(addr, asi, size, val)
 *	paddr_t addr;
 *	int asi;
 *	int size;
 *	long val;
 *
 * As above, but we return 0 on success.
 */
ENTRY(probeset)
	mov	%o2, %o4
	! %o0 = addr, %o1 = asi, %o4 = (1,2,4), %o3 = val
	sethi	%hi(CPCB), %o2		! Lfserr requires CPCB in %o2
	ldx	[%o2 + %lo(CPCB)], %o2	! cpcb->pcb_onfault = Lfserr;
	set	_C_LABEL(Lfsbail), %o5
	stx	%o5, [%o2 + PCB_ONFAULT]
	btst	1, %o4
	wr	%o1, 0, %asi
d8473 12
a8484 24
	bz	0f			! if (len & 1)
	 btst	2, %o4
	ba,pt	%icc, 1f
	 stba	%o3, [%o0] %asi		!	*(char *)addr = value;
0:
	bz	0f			! if (len & 2)
	 btst	4, %o4
	ba,pt	%icc, 1f
	 stha	%o3, [%o0] %asi		!	*(short *)addr = value;
0:
	bz	0f			! if (len & 4)
	 btst	8, %o4
	ba,pt	%icc, 1f
	 sta	%o3, [%o0] %asi		!	*(int *)addr = value;
0:
	bz	Lfserr			! if (len & 8)
	ba,pt	%icc, 1f
	 sta	%o3, [%o0] %asi		!	*(int *)addr = value;
1:	membar	#Sync
	clr	%o0			! made it, clear onfault and return 0
	wr	%g0, ASI_PRIMARY_NOFAULT, %asi		! Restore default ASI	
	stx	%g0, [%o2 + PCB_ONFAULT]
	retl
	 membar	#StoreStore|#StoreLoad
d8486 1
a8486 17
/*
 * pmap_zero_page(pa)
 *
 * Zero one page physically addressed
 *
 * Block load/store ASIs do not exist for physical addresses,
 * so we won't use them.
 *
 * While we do the zero operation, we also need to blast away
 * the contents of the D$.  We will execute a flush at the end
 * to sync the I$.
 */
	.data
paginuse:
	.word	0
	.text
ENTRY(pmap_zero_phys)
d8488 1
a8488 2
	!! If we have 64-bit physical addresses (and we do now)
	!! we need to move the pointer from %o0:%o1 to %o0
d8490 70
a8559 2
	set	NBPG, %o2		! Loop count
	clr	%o1
d8561 2
a8562 2
	dec	8, %o2
	stxa	%g0, [%o0] ASI_PHYS_CACHED
d8564 2
a8565 3
	stxa	%g0, [%o1] ASI_DCACHE_TAG
	brgz	%o2, 1b
	 inc	16, %o1
d8567 7
a8573 2
	sethi	%hi(KERNBASE), %o3
	flush	%o3
d8576 1
a8576 19
/*
 * pmap_copy_page(src, dst)
 *
 * Copy one page physically addressed
 * We need to use a global reg for ldxa/stxa
 * so the top 32-bits cannot be lost if we take
 * a trap and need to save our stack frame to a
 * 32-bit stack.  We will unroll the loop by 8 to
 * improve performance.
 *
 * We also need to blast the D$ and flush like
 * pmap_zero_page.
 */
ENTRY(pmap_copy_phys)
	!!
	!! If we have 64-bit physical addresses (and we do now)
	!! we need to move the pointer from %o0:%o1 to %o0 and
	!! %o2:%o3 to %o1
	!!
d8581 1
a8581 1
	DLFLUSH %o0,%g1
d8586 1
a8586 1
	DLFLUSH %o1,%g1
d8589 4
d8595 1
d8617 1
a8617 1
	DLFLUSH %o2,%o3
d8619 1
a8619 1
	DLFLUSH2 %o3
d8626 1
a8626 1
	DLFLUSH %o2,%o3
d8628 1
a8628 1
	DLFLUSH2 %o3
d8635 1
a8635 1
	DLFLUSH %o2,%o3
d8637 1
a8637 1
	DLFLUSH2 %o3
d8649 2
a8650 2
#else	/* 1 */
	DLFLUSH %o2,%o3
d8652 1
a8652 1
	DLFLUSH2 %o3
d8655 1
a8655 1
#endif	/* 1 */
d8682 23
d8720 1
a8720 1
#endif	/* DEBUG */
d8731 1
a8731 1
	DLFLUSH %o4,%g1
d8733 1
a8733 1
	DLFLUSH2 %g1
d8741 1
a8741 1
	DLFLUSH %o4, %o5
d8750 1
a8750 1
	DLFLUSH %o4,%g1
d8752 1
a8752 1
	DLFLUSH2 %g1
d8760 1
a8760 1
	DLFLUSH %o4, %o4
d8769 13
a8781 1
	DLFLUSH %o4, %o4
d8808 19
d8841 1
a8841 1
#endif	/* DEBUG */
d8852 1
a8852 1
	DLFLUSH %o4,%o3
d8854 1
a8854 1
	DLFLUSH2 %o3
d8862 1
a8862 1
	DLFLUSH %o4, %o5
d8871 1
a8871 1
	DLFLUSH %o4,%o3
d8873 1
a8873 1
	DLFLUSH2 %o3
d8881 1
a8881 1
	DLFLUSH %o4, %o4
d8915 1
a8915 1
#else	/* 0 */
d8917 1
a8917 1
#endif	/* 0 */
d8934 1
a8934 1
#endif	/* 1 */
d8955 1
a8955 1
#endif	/* DEBUG */
d8977 1
a8977 1
!	 XXX check no delay slot
d9028 1
a9028 1
#endif	/* 0 */
d9387 1
a9387 1
#endif	/* 0 */
d9463 2
a9464 2
	ENABLE_FPU 0
#else	/* 1 */
d9467 2
a9468 2
	ldx	[%l1 + %lo(FPPROC)], %l2		! Load fpproc
	add	%sp, (CC64FSZ+BIAS+BLOCK_SIZE-1), %l0	! Calculate pointer to fpstate
d9471 1
a9471 1
	ldx	[%l2 + P_FPSTATE], %l3
d9475 1
a9475 1
	 set	EINTSTACK-BIAS, %l4			! Are we on intr stack?
d9478 1
a9478 1
	 set	INTSTACK-BIAS, %l4
d9487 1
a9487 1
	ldx	[%l4 + %lo(CURPROC)], %l5
d9491 3
a9493 3
	ldx	[%l5 + P_FPSTATE], %l6			! Save old fpstate
	stx	%l0, [%l5 + P_FPSTATE]			! Insert new fpstate
	stx	%l5, [%l1 + %lo(FPPROC)]		! Set new fpproc
d9495 1
a9495 1
#endif	/* 1 */
d9499 1
a9499 1
#endif	/* _KERNEL */
d9684 1
a9684 1
#else	/* 1 */
d9721 1
a9721 1
#endif	/* 1 */
d9737 1
a9737 1
#endif	/* RETURN_NAME */
d9821 1
a9821 1
#endif	/* RETURN_NAME */
d9918 1
a9918 1
#endif	/* RETURN_NAME */
d10015 1
a10015 1
#endif	/* RETURN_NAME */
d10110 1
a10110 1
#endif	/* RETURN_NAME */
d10203 1
a10203 1
#endif	/* RETURN_NAME */
d10295 1
a10295 1
#endif	/* RETURN_NAME */
d10385 1
a10385 1
#endif	/* RETURN_NAME */
d10561 1
a10561 1
#endif	/* 0 */
d10570 1
a10570 1
#else	/* 1 */
d10572 1
a10572 1
	ldx	[%l1 + %lo(FPPROC)], %l7
d10575 1
a10575 1
	ldx	[%l5 + P_FPSTATE], %l7
d10578 1
a10578 1
#endif	/* DEBUG */
d10580 1
a10580 1
	stx	%l2, [%l1 + %lo(FPPROC)]		! Restore old fproc
d10582 1
a10582 1
	 stx	%l6, [%l5 + P_FPSTATE]			! Restore old fpstate
d10587 1
a10587 1
#endif	/* 1 */
d10590 1
a10590 1
#endif	/* _KERNEL		 */
d10593 1
a10593 1
#endif	/* 1 */
d10657 1
a10657 1
#endif		/* 0 */
d10732 2
a10733 2
	ENABLE_FPU 0
#else	/* 1 */
d10740 2
a10741 2
	ldx	[%l1 + %lo(FPPROC)], %l2		! Load fpproc
	add	%sp, (CC64FSZ+BIAS+BLOCK_SIZE-1), %l0	! Calculate pointer to fpstate
d10744 1
a10744 1
	ldx	[%l2 + P_FPSTATE], %l3
d10748 1
a10748 1
	 set	EINTSTACK-BIAS, %l4			! Are we on intr stack?
d10751 1
a10751 1
	 set	INTSTACK-BIAS, %l4
d10760 1
a10760 1
	ldx	[%l4 + %lo(CURPROC)], %l5
d10765 1
a10765 1
	ldx	[%l5 + P_FPSTATE], %l6			! Save old fpstate
d10767 2
a10768 2
	stx	%l0, [%l5 + P_FPSTATE]			! Insert new fpstate
	stx	%l5, [%l1 + %lo(FPPROC)]		! Set new fpproc
d10770 1
a10770 1
#endif	/* 1 */
d10786 1
d10790 6
d10824 1
a10824 1
#else	/* 1 */
d10826 1
a10826 1
	ldx	[%l1 + %lo(FPPROC)], %l7
d10829 1
a10829 1
	ldx	[%l5 + P_FPSTATE], %l7
d10832 3
a10834 3
#endif	/* DEBUG */
	stx	%g0, [%l1 + %lo(FPPROC)]		! Clear fpproc
	stx	%l6, [%l5 + P_FPSTATE]			! Restore old fpstate
d10839 3
a10841 3
#endif	/* 1 */
#endif	/* 1 */
#endif	/* 1 */
d10868 1
a10868 1
#endif	/* DEBUG */
d10870 1
a10870 1
	ldx	[%o5 + %lo(CPCB)], %o5
d10872 1
a10872 1
	ldx	[%o5 + PCB_ONFAULT], %g1! save current onfault handler
d10874 1
a10874 1
	stx	%o3, [%o5 + PCB_ONFAULT]
d10887 1
a10887 1
!	 XXX check no delay slot
d10897 1
a10897 1
	stx	%g1, [%o5 + PCB_ONFAULT]! restore fault handler
d10910 1
a10910 1
!	 XXX check no delay slot
d10931 1
a10931 1
	stx	%g1, [%o5 + PCB_ONFAULT]! restore fault handler
d11033 1
a11033 1
	stx	%g1, [%o5 + PCB_ONFAULT]! restore fault handler
d11046 1
a11046 1
	stx	%g1, [%o5 + PCB_ONFAULT]! restore fault handler
d11055 1
a11055 1
	stx	%g1, [%o5 + PCB_ONFAULT]! restore fault handler
d11079 2
a11080 2
#endif	/* DEBUG */
	stx	%g1, [%o5 + PCB_ONFAULT]! restore fault handler
d11108 1
a11108 1
!	 XXX check no delay slot
d11315 1
a11315 1
#endif	/* DIAGONSTIC */
d11435 1
a11435 1
#endif	/* DIAGNOSTIC */
d11579 1
d11581 2
a11582 1
	 sll	%o1, 3+3, %o5	! Find start of table for this IPL
d11585 3
a11587 2
	ldx	[%o3], %o5		! Load list head
	stx	%o5, [%o2+IH_PEND]	! Link our intrhand node in
d11589 1
a11589 1
	casxa	[%o3] ASI_N, %o5, %o4
d11593 22
d11839 1
a11839 1
	CHKPT %o4,%o3,0x28
d11872 1
a11872 1
	CHKPT %o4,%o3,0x36
d11876 1
a11876 1
	CHKPT %o4,%o3,0x29
d11895 1
a11895 1
	CHKPT %o4,%o3,0x30
d11916 34
a11949 1
#endif /* DDB */	/* DDB */
d11956 1
a11956 1
	.xword	0
d11959 2
a11960 2
	.xword	0
#endif	/* defined(DDB) || NKSYMS > 0 */
d11963 1
a11963 1
	.xword	_C_LABEL(u0)		! KVA of proc0 uarea
d12000 1
a12000 1
#endif	/* DEBUG */
@


1.9.4.7
log
@Merge of current from two weeks agointo the SMP branch
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d62 1
a62 1
#else	/* HORRID_III_HACK */
d64 1
a64 1
#endif	/* HORRID_III_HACK */
d275 1
a275 1
 * We've saved our possible fpstate, now disable the fpu
d290 1
a290 1
	call	_C_LABEL(loadfpstate)		! Reload orig fpstate
d405 1
a405 1
 *	that information.  Trap types in these macros are all dummys.
d474 1
a474 1
#else	/* 0 */
d476 1
a476 1
#endif	/* 0 */
d598 1
a598 1
 * Here are some often repeated traps as macros.
d689 1
a689 1
	VTRAP T_TEXTFAULT, textfault	! 009 = instr. access MMU miss
d715 1
a715 3
	TRAP T_LDQF_ALIGN		! 038 = LDDF address alignment error
	TRAP T_STQF_ALIGN		! 039 = STQF address alignment error
	UTRAP 0x03a; UTRAP 0x03b; UTRAP 0x03c;
d849 1
a849 1
	VTRAP T_TEXTFAULT, textfault	! 009 = instr. access MMU miss -- no MMU
d944 1
a944 1
	FILLBOTH 1b,2b,ASI_AIUS	! 0x0e8 fill_2_other
d991 1
a991 1
 * If the cleanwin trap handler detects an overflow we come here.
d1077 1
a1077 1
	sub	%g3, (pmap_edumparea-pmap_dumparea), %g3	! pc relative addressing 8^)
d1278 1
a1278 1
  * This means that these registers need to be preserved across all
d1359 2
a1360 2
 * We don't guarantee that any registers are preserved during this operation,
 * so we can be more efficient.
d1550 1
a1550 1
	blu,pn	%xcc, winfix				! Next instruction in delay slot is unimportant
d1634 1
a1634 1
	blu,pn	%xcc, winfix				! Next instruction in delay slot is unimportant
d1797 1
a1797 1
	 wrpr	%g5, %cwp		! Restore cwp from before fill trap -- regs should now be consistent
d1815 1
a1815 1
	wrpr	%g5, %cwp				! Restore cwp from before fill trap -- regs should now be consistent
d1836 1
a1836 1
#else	/* 0 - Need to switch over to new stuff to fix WDR bug */
d1886 1
a1886 1
#endif	/* 0 - Need to switch over to new stuff to fix WDR bug */
d2365 1
a2365 1
	blu,pn	%xcc, textfault				! Next instruction in delay slot is unimportant
d3290 1
a3290 1
	flushw			! Do not remove this instruction -- causes interrupt loss
d3346 1
a3346 1
	membar	#StoreLoad		! Make sure any failed casxa instructions complete
d3576 1
a3576 1
#endif	/* 0 */
d3996 1
a3996 1
#endif	/* HORRID_III_HACK */
d4053 1
a4053 1
#endif	/* HORRID_III_HACK */
d4056 1
a4056 1
#endif	/* NO_VCACHE */
d4416 1
a4416 1
	stxa	%l0, [%l2] ASI_IMMU		! Install instruction TSB pointer
d4470 1
a4470 1
	 ldx	[%o4+%lo(romp)], %o4		! v9 stack, just load the addr and call it
d4932 1
a4932 1
	add	%sp, BIAS + 128 + 16, %o0	! compute scp
d5930 1
a5930 1
	wrpr	%g0, 0, %otherwin	! These two instructions should be redundant
d6523 1
a6523 1
 * Use block_disable to turn off block instructions for
d7309 1
a7309 1
	!! This is 6 instructions, most of which cannot be paired,
d8265 1
a8265 1
	 sllx	%o1, 8, %o3		! sigh.  all dependent instructions.
d8275 2
a8276 2
	bge,pt	%xcc, Lbzero_block	! use block store instructions
#endif	/* 0 */
@


1.9.4.8
log
@Merge with the trunk
@
text
@d2495 1
a2495 1
	rd	%y, %g4					! save y
d2520 1
a2520 1
	 st	%g4, [%sp + CC64FSZ + BIAS + TF_Y]		! set tf.tf_y
a4897 1
	wr	%l1, %g0, %y		! in any case, restore %y
d4917 1
a4917 1
	 nop
@


1.9.4.9
log
@p_pstat = SONPROC
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.9.4.8 2004/06/05 23:11:00 niklas Exp $	*/
d5882 1
d5885 1
@


1.8
log
@Don't use the VIS instructions for bcopy and bzero.
We have enough floating point problems without multimedia in the kernel.
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.7 2001/09/06 10:45:41 art Exp $	*/
d77 1
d5210 1
a5210 1
#ifdef DDB
d12260 1
a12260 1
#ifdef DDB
@


1.7
log
@Some glue for COMPAT_NETBSD
@
text
@d1 1
a1 1
/*	$OpenBSD: locore.s,v 1.6 2001/09/04 16:51:18 jason Exp $	*/
d9230 1
a9230 1
#if 1
d10859 1
a10859 1
#if 1
@


1.6
log
@rcsid
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d6379 4
@


1.5
log
@better still, remove definition from here; suggest by drahn
@
text
@d1 1
@


1.4
log
@increase size of intrhand in here, too.
@
text
@a4197 1
	.comm	_C_LABEL(intrhand), 16 * PTRSZ	! intrhand[0..14]; 0 => error
@


1.3
log
@correctly deal with layout of sigframe
@
text
@d4198 1
a4198 1
	.comm	_C_LABEL(intrhand), 15 * PTRSZ	! intrhand[0..14]; 0 => error
@


1.2
log
@disable TRAPTRACE and fix a compile error with DEBUG.
@
text
@d6267 3
a6269 2
 *	[%sp + 128 + 4]		signal code (goes in %o1)
 *	[%sp + 128 + 8]		first word of saved state (sigcontext)
d6273 2
a6274 1
 *	[%sp + NNN]	last word of saved state
d6280 1
d6333 3
a6335 3
	lduw	[%fp + BIAS + 128 + 4], %o1	! code
	call	%g1			! (*sa->sa_handler)(sig,code,scp)
	 add	%fp, BIAS + 128 + 8, %o2	! scp
d6372 1
a6372 1
	add	%sp, BIAS + 128 + 8, %o0! compute scp
@


1.1
log
@Lot of stuff... Some from NetBSD, some from OpenBSD, minor modifications
@
text
@d62 1
a62 1
#define	TRAPTRACE		/* Keep history of all traps (unsafe) */
d3997 1
a3997 1
#if DEBUG
@

