head	1.102;
access;
symbols
	OPENBSD_6_2:1.102.0.4
	OPENBSD_6_2_BASE:1.102
	OPENBSD_6_1:1.101.0.4
	OPENBSD_6_1_BASE:1.101
	OPENBSD_6_0:1.100.0.4
	OPENBSD_6_0_BASE:1.100
	OPENBSD_5_9:1.100.0.2
	OPENBSD_5_9_BASE:1.100
	OPENBSD_5_8:1.96.0.4
	OPENBSD_5_8_BASE:1.96
	OPENBSD_5_7:1.93.0.2
	OPENBSD_5_7_BASE:1.93
	OPENBSD_5_6:1.90.0.4
	OPENBSD_5_6_BASE:1.90
	OPENBSD_5_5:1.87.0.4
	OPENBSD_5_5_BASE:1.87
	OPENBSD_5_4:1.86.0.4
	OPENBSD_5_4_BASE:1.86
	OPENBSD_5_3:1.86.0.2
	OPENBSD_5_3_BASE:1.86
	OPENBSD_5_2:1.85.0.2
	OPENBSD_5_2_BASE:1.85
	OPENBSD_5_1_BASE:1.84
	OPENBSD_5_1:1.84.0.2
	OPENBSD_5_0:1.82.0.2
	OPENBSD_5_0_BASE:1.82
	OPENBSD_4_9:1.78.0.2
	OPENBSD_4_9_BASE:1.78
	OPENBSD_4_8:1.72.0.2
	OPENBSD_4_8_BASE:1.72
	OPENBSD_4_7:1.67.0.2
	OPENBSD_4_7_BASE:1.67
	OPENBSD_4_6:1.33.0.2
	OPENBSD_4_6_BASE:1.33
	OPENBSD_4_5:1.4.0.2
	OPENBSD_4_5_BASE:1.4
	OPENBSD_4_4:1.3.0.2
	OPENBSD_4_4_BASE:1.3;
locks; strict;
comment	@ * @;


1.102
date	2017.05.11.15.47.45;	author visa;	state Exp;
branches;
next	1.101;
commitid	3ClMEjcZRCcA0l1P;

1.101
date	2017.02.11.03.44.22;	author visa;	state Exp;
branches;
next	1.100;
commitid	xjkuO7IpWLYltL4L;

1.100
date	2015.12.03.15.38.06;	author visa;	state Exp;
branches;
next	1.99;
commitid	jmiNsLfhVIieiJDL;

1.99
date	2015.09.27.10.12.09;	author semarie;	state Exp;
branches;
next	1.98;
commitid	1dIhYMDj5NezOASM;

1.98
date	2015.09.12.08.40.02;	author miod;	state Exp;
branches;
next	1.97;
commitid	VOB17QiarLCSqMAH;

1.97
date	2015.09.08.10.21.50;	author deraadt;	state Exp;
branches;
next	1.96;
commitid	PXEPkjFX0KqqXu7Y;

1.96
date	2015.06.24.16.52.52;	author miod;	state Exp;
branches;
next	1.95;
commitid	c91ZupxCXx0z2BRF;

1.95
date	2015.06.16.18.24.38;	author miod;	state Exp;
branches;
next	1.94;
commitid	GYwJoWxw2NUyueuh;

1.94
date	2015.03.23.20.50.21;	author miod;	state Exp;
branches;
next	1.93;
commitid	iEVv90OcxfRVdhFy;

1.93
date	2014.12.04.21.52.08;	author miod;	state Exp;
branches;
next	1.92;
commitid	UFCZ5sn3WKAdzAdi;

1.92
date	2014.09.30.06.51.58;	author jmatthew;	state Exp;
branches;
next	1.91;
commitid	pUEUpP9FlbomZUiI;

1.91
date	2014.08.19.19.04.07;	author miod;	state Exp;
branches;
next	1.90;
commitid	Bqi6dmJx3KoUAcSD;

1.90
date	2014.07.12.18.44.42;	author tedu;	state Exp;
branches;
next	1.89;
commitid	uKVPYMN2MLxdZxzH;

1.89
date	2014.05.19.21.18.42;	author miod;	state Exp;
branches;
next	1.88;

1.88
date	2014.04.03.08.07.16;	author mpi;	state Exp;
branches;
next	1.87;

1.87
date	2014.01.22.00.03.06;	author jsg;	state Exp;
branches;
next	1.86;

1.86
date	2012.09.29.18.54.39;	author miod;	state Exp;
branches;
next	1.85;

1.85
date	2012.05.20.11.41.11;	author miod;	state Exp;
branches;
next	1.84;

1.84
date	2011.10.10.19.49.17;	author miod;	state Exp;
branches;
next	1.83;

1.83
date	2011.10.10.19.42.36;	author miod;	state Exp;
branches;
next	1.82;

1.82
date	2011.04.17.17.44.24;	author miod;	state Exp;
branches;
next	1.81;

1.81
date	2011.04.05.14.43.11;	author miod;	state Exp;
branches;
next	1.80;

1.80
date	2011.04.05.01.17.41;	author miod;	state Exp;
branches;
next	1.79;

1.79
date	2011.03.13.20.45.51;	author miod;	state Exp;
branches;
next	1.78;

1.78
date	2010.12.04.17.06.32;	author miod;	state Exp;
branches;
next	1.77;

1.77
date	2010.11.27.18.21.05;	author miod;	state Exp;
branches;
next	1.76;

1.76
date	2010.09.22.02.28.37;	author jsg;	state Exp;
branches;
next	1.75;

1.75
date	2010.09.20.06.33.47;	author matthew;	state Exp;
branches;
next	1.74;

1.74
date	2010.08.23.16.56.18;	author miod;	state Exp;
branches;
next	1.73;

1.73
date	2010.08.23.16.55.07;	author miod;	state Exp;
branches;
next	1.72;

1.72
date	2010.05.09.18.36.07;	author miod;	state Exp;
branches;
next	1.71;

1.71
date	2010.04.21.03.03.26;	author deraadt;	state Exp;
branches;
next	1.70;

1.70
date	2010.04.06.19.12.34;	author miod;	state Exp;
branches;
next	1.69;

1.69
date	2010.04.02.12.11.55;	author jsg;	state Exp;
branches;
next	1.68;

1.68
date	2010.03.28.17.12.41;	author miod;	state Exp;
branches;
next	1.67;

1.67
date	2010.03.07.13.39.00;	author miod;	state Exp;
branches;
next	1.66;

1.66
date	2009.12.26.20.16.19;	author miod;	state Exp;
branches;
next	1.65;

1.65
date	2009.12.25.21.02.18;	author miod;	state Exp;
branches;
next	1.64;

1.64
date	2009.11.25.11.23.30;	author miod;	state Exp;
branches;
next	1.63;

1.63
date	2009.11.19.06.07.05;	author miod;	state Exp;
branches;
next	1.62;

1.62
date	2009.11.18.19.05.53;	author miod;	state Exp;
branches;
next	1.61;

1.61
date	2009.11.11.15.29.31;	author miod;	state Exp;
branches;
next	1.60;

1.60
date	2009.11.07.18.56.55;	author miod;	state Exp;
branches;
next	1.59;

1.59
date	2009.11.07.14.49.02;	author miod;	state Exp;
branches;
next	1.58;

1.58
date	2009.10.26.18.37.13;	author miod;	state Exp;
branches;
next	1.57;

1.57
date	2009.10.26.18.13.34;	author miod;	state Exp;
branches;
next	1.56;

1.56
date	2009.10.26.18.11.27;	author miod;	state Exp;
branches;
next	1.55;

1.55
date	2009.10.22.22.08.54;	author miod;	state Exp;
branches;
next	1.54;

1.54
date	2009.10.22.19.55.45;	author miod;	state Exp;
branches;
next	1.53;

1.53
date	2009.10.16.14.07.31;	author miod;	state Exp;
branches;
next	1.52;

1.52
date	2009.10.15.23.40.49;	author miod;	state Exp;
branches;
next	1.51;

1.51
date	2009.10.10.19.59.28;	author miod;	state Exp;
branches;
next	1.50;

1.50
date	2009.10.08.19.14.23;	author miod;	state Exp;
branches;
next	1.49;

1.49
date	2009.10.08.19.10.53;	author miod;	state Exp;
branches;
next	1.48;

1.48
date	2009.10.07.20.39.14;	author miod;	state Exp;
branches;
next	1.47;

1.47
date	2009.10.07.04.19.30;	author miod;	state Exp;
branches;
next	1.46;

1.46
date	2009.08.22.02.54.51;	author mk;	state Exp;
branches;
next	1.45;

1.45
date	2009.08.18.19.31.59;	author miod;	state Exp;
branches;
next	1.44;

1.44
date	2009.07.27.17.49.55;	author miod;	state Exp;
branches;
next	1.43;

1.43
date	2009.07.26.19.56.45;	author miod;	state Exp;
branches;
next	1.42;

1.42
date	2009.07.26.18.48.55;	author miod;	state Exp;
branches;
next	1.41;

1.41
date	2009.07.23.19.24.03;	author miod;	state Exp;
branches;
next	1.40;

1.40
date	2009.07.21.21.25.19;	author miod;	state Exp;
branches;
next	1.39;

1.39
date	2009.07.18.16.38.49;	author miod;	state Exp;
branches;
next	1.38;

1.38
date	2009.07.17.19.40.12;	author miod;	state Exp;
branches;
next	1.37;

1.37
date	2009.07.17.18.06.51;	author miod;	state Exp;
branches;
next	1.36;

1.36
date	2009.07.17.07.14.00;	author miod;	state Exp;
branches;
next	1.35;

1.35
date	2009.07.16.21.02.58;	author miod;	state Exp;
branches;
next	1.34;

1.34
date	2009.07.13.21.19.28;	author miod;	state Exp;
branches;
next	1.33;

1.33
date	2009.07.06.22.46.43;	author miod;	state Exp;
branches;
next	1.32;

1.32
date	2009.07.03.19.28.47;	author miod;	state Exp;
branches;
next	1.31;

1.31
date	2009.07.01.21.56.38;	author miod;	state Exp;
branches;
next	1.30;

1.30
date	2009.06.28.21.52.54;	author miod;	state Exp;
branches;
next	1.29;

1.29
date	2009.06.27.22.23.17;	author miod;	state Exp;
branches;
next	1.28;

1.28
date	2009.06.27.16.34.50;	author miod;	state Exp;
branches;
next	1.27;

1.27
date	2009.06.21.18.03.16;	author miod;	state Exp;
branches;
next	1.26;

1.26
date	2009.06.13.21.48.03;	author miod;	state Exp;
branches;
next	1.25;

1.25
date	2009.06.13.16.28.11;	author miod;	state Exp;
branches;
next	1.24;

1.24
date	2009.05.28.19.20.06;	author miod;	state Exp;
branches;
next	1.23;

1.23
date	2009.05.27.19.04.47;	author miod;	state Exp;
branches;
next	1.22;

1.22
date	2009.05.27.18.58.52;	author miod;	state Exp;
branches;
next	1.21;

1.21
date	2009.05.24.17.33.12;	author miod;	state Exp;
branches;
next	1.20;

1.20
date	2009.05.21.16.26.15;	author miod;	state Exp;
branches;
next	1.19;

1.19
date	2009.05.15.17.18.16;	author miod;	state Exp;
branches;
next	1.18;

1.18
date	2009.05.15.06.29.39;	author miod;	state Exp;
branches;
next	1.17;

1.17
date	2009.05.14.21.10.33;	author miod;	state Exp;
branches;
next	1.16;

1.16
date	2009.05.08.18.37.28;	author miod;	state Exp;
branches;
next	1.15;

1.15
date	2009.05.06.20.08.47;	author miod;	state Exp;
branches;
next	1.14;

1.14
date	2009.05.03.19.44.28;	author miod;	state Exp;
branches;
next	1.13;

1.13
date	2009.05.02.21.30.13;	author miod;	state Exp;
branches;
next	1.12;

1.12
date	2009.04.19.18.37.31;	author miod;	state Exp;
branches;
next	1.11;

1.11
date	2009.04.19.12.52.33;	author miod;	state Exp;
branches;
next	1.10;

1.10
date	2009.04.18.19.26.33;	author miod;	state Exp;
branches;
next	1.9;

1.9
date	2009.04.18.19.26.18;	author miod;	state Exp;
branches;
next	1.8;

1.8
date	2009.04.15.18.45.41;	author miod;	state Exp;
branches;
next	1.7;

1.7
date	2009.04.13.21.17.54;	author miod;	state Exp;
branches;
next	1.6;

1.6
date	2009.04.12.17.55.20;	author miod;	state Exp;
branches;
next	1.5;

1.5
date	2009.03.30.09.41.00;	author kettenis;	state Exp;
branches;
next	1.4;

1.4
date	2008.08.25.13.35.34;	author jsing;	state Exp;
branches;
next	1.3;

1.3
date	2008.07.30.17.37.46;	author miod;	state Exp;
branches;
next	1.2;

1.2
date	2008.07.28.18.50.59;	author miod;	state Exp;
branches;
next	1.1;

1.1
date	2008.04.07.22.47.40;	author miod;	state Exp;
branches;
next	;


desc
@@


1.102
log
@The device_to_pa routine really isn't needed. We always have physical
addresses. While there, pave the way for BUS_DMA_64BIT (not working
yet).

Diff from miod@@; OK dlg@@
@
text
@/*	$OpenBSD: xbridge.c,v 1.101 2017/02/11 03:44:22 visa Exp $	*/

/*
 * Copyright (c) 2008, 2009, 2011  Miodrag Vallat.
 *
 * Permission to use, copy, modify, and distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 */

/*
 * XBow Bridge (as well as XBridge and PIC) Widget driver.
 */

/*
 * IMPORTANT AUTHOR'S NOTE: I did not write any of this code under the
 * influence of drugs.  Looking back at that particular piece of hardware,
 * I wonder if this hasn't been a terrible mistake.
 */

/*

  xbridge 101
  ===========

  There are three ASIC using this model:

  - Bridge, used on Octane and maybe early Origin 200 and 2000 systems.
  - XBridge, used on later Origin 200/2000 and Origin 300/3000 systems.
  - PIC, used on Origin 350/3500 systems.

  (for the record, Fuel is Origin 300 like and Tezro is Origin 350 like).

  Bridge and XBridge each appear as a single widget, supporting 8 PCI devices,
  while PIC appears as two contiguous widgets, each supporting 2 PCI-X devices.

- - address space

  Each widget has a 36-bit address space.  xbridge widgets only use 33 bits
  though.

  On Octane systems, the whole 36 bit address space is fully available.  On
  all other systems, the low 16MB (24 bit) address space is always available,
  and access to arbitrary areas of the address space can be achieved by
  programming the Crossbow's IOTTE (I/O Translation Table Entries).

  IMPORTANT! there is a limited number of IOTTE per Crossbow: 7, of which the
  seventh is used to workaround a hardware bug, leaving only 6 entries
  available accross all widgets.

  Each IOTTE opens a contiguous window of 28 or 29 bits, depending on the
  particular system model and configuration.  On Origin 300/3000 and 350/3500,
  this will always be 29 bit (512MB), while on Origin 200/2000 systems, this
  depends on the ``M mode vs N mode'' configuration.  Most systems run in M
  mode (which is the default) which also allows for 29 bit; systems in N mode
  (allowing more than 64 nodes to be connected) can only provide 28 bit IOTTE
  windows (256MB).

  The widget address space is as follows:

   offset         size           description
  0##0000##0000  0##0003##0000  registers
  0##4000##0000  0##4000##0000  PCI memory space
  1##0000##0000  1##0000##0000  PCI I/O space

  Note the PCI memory space is limited to 30 bit; this is supposedly hardware
  enforced, i.e. one may set the top two bits of 32-bit memory BAR and they
  would be ignored.  The xbridge driver doesn't try this though (-:

  IMPORTANT! On Bridge (not XBridge) revision up to 3, the I/O space is not
  available (apparently this would be because of a hardware issue in the
  byteswap logic, causing it to return unpredictable values when accessing
  this address range).
  
- - PCI resource mapping

  Each BAR value is an offset within the memory or I/O space (with the memory
  space being limited to 30 bits, or 1GB), *EXCEPT* when the value fits in one
  of the ``devio'' slots.

  So now is a good time to introduce the devio.

  There are 8 devio registers, one per device; theses registers contain various
  device-global flags (such as byte swapping and coherency), as well as the
  location of a ``devio window'' in one of the address spaces, selected on a
  per-devio basis.

  The devio register only programs the upper 12 bits of the 32 window base
  address, the low 20 bits being zero; the window size are fixed and depend on
  the given device: devices 0 and 1 have ``large'' windows of 2MB (0020##0000),
  while devices 2 to 7 have ``small'' windows of 1MB (0010##0000).

  Apparently there are some hidden rules about the upper 12 bits, though, and
  the rules differ on Octane vs Origin systems.

  This is why the address space, from the pci driver point of view, is split
  in three parts: there is the ``devio black hole'' where we must make sure
  that no BAR allocation crosses a devio boundary, and the rest of the address
  space (under the devio zone and above it).

  I am slowly moving away from the devio mappings the PROM leaves us in, and
  eventually I expect to be able to have more flexibility in their position.
  However there is the console uart mapping I don't want to change now, and -
  of course - we inherit it from the prom as a devio register for the IOC3 or
  IOC4 device.

  So currently, the extents I provide the MI code with span the 0->ffff##ffff
  address space, with only the following areas available:
  - each devio range, if configured for the given address space
  - on Octane, the whole memory or I/O space minus the 16MB area in which all
    devio mappings take place
  - on Origin, if we have an IOTTE mapping a part of the memory or I/O address
    space, the whole window minus the 16MB area in which all devio mappings
    take place.

  Now I need to make sure that the MI code will never allocate mappings
  crossing devio ranges.  So during the Bridge setup, I am initializing
  ALL BAR on a device-by-device basis, working with smaller extents:
  - if the device can have all its resources of a given type (I/O or mem)
    fitting in a devio area, I configure a devio, and make it allocate from
    an extent spanning only the devio range.
  - if there are not enough devio (because the device might need two devio
    ranges, one for I/O resources and one for memory resources, and there are
    only 8 devio, and if the bus is populated there might not be enough unused
    devio slots to hijack), then allocation is done on the larger address space
    (granted on Octane, or provided with an IOTTE window on Origin), using an
    extent covering this area minus the 16MB area in which all devio mappings
    take place.
  So in either case, I am now sure that there are no resources crossing the
  devio boundaries, which are invisible to the MI code.

  This also explains why I am making sure that the devio ranges are close to
  each other - it makes the creation of the temporary resource extents simpler
  (bear in mind that a device might need resources from the IOTTE window before
  all devio ranges are set up).

  And of course to make things even less simple, the IOTTE allocation may fail
  (e.g. on a P-Brick with 6 XBridge chips on the same Crossbow), and if we are
  using an old revision Bridge, all I/O resources need to be allocated with
  devio (so we can't decide to get rid of them anyway).

  So, when it's time to configure further devices (for ppb and pccbb), I need
  the same trick to prevent resource allocation to cross devio boundaries.

  Actually, as far as pccbb is concerned, I give up entirely on resources if
  all I have is a devio to map within - at least for now, because the devio do
  not cover the 0000..ffff range in I/O space needed for pcmcia.  So for the
  I/O resources, I give rbus the low 16 bits of the I/O extent (if available);
  as for the memory resources, I need to exclude the devio area, and since rbus
  currently only supports a single contiguous area, I give it the area starting
  after the devio range (which is, by far, the largest part of the
  at-least-256MB region).

  Do you need aspirin yet?

- - DMA

  Device DMA addresses can be constructed in three ways:
  - direct 64 bit address
  - 32 bit address within a programmable 31 bit ``direct DMA'' window
  - 32 bit translated address using ATE (Address Translation Entries)

  direct 64 bit address:
    These are easy to construct (pick your memory address, set bit 56, and
    you're done), but these can only work with pci devices aware of 64 bit
    addresses.

  direct DMA window:
    There is a Bridge global register to define the base address of the window,
    and then we have 2GB available.  This is what I am currently using, and
    convenient for PCI devices unable to use 64 bit DMA addresses.

  translated DMA:
    There is another 2GB window in which accesses are indirected through ATE,
    which can point anywhere in memory.

    ATE are IOMMU translation entries.  PCI addresses in the translated window
    transparently map to the address their ATE point to.

    Bridge chip have 128 so-called `internal' entries, and can use their
    optional `external' SSRAM to provide more (up to 65536 entries with 512KB
    SSRAM).  However, due to chip bugs, those `external' entries can not be
    updated while there is DMA in progress using external entries, even if the
    updated entries are not related to those used by the DMA transfer.

    XBridge chip extend the internal entries to 1024, but do not provide
    support for external entries.

    All ATE share the same page size, which is configurable as 4KB or 16KB.

    Due to the small number of ATE entries, and since you can not use part of
    the system's RAM to add entries as you need them (unlike hppa or sparc64),
    the driver no longer uses them, as there is nothing we can do when we run
    out of ATE.

- - interrupts

  This is easy, for a change.  There are 8 interrupt sources, one per device;
  pins A and C map of devices 0-7 map to interrupt sources 0-7, and pins B and
  D of devices 0-7 map to interrupt sources 4-7 then 0-3 (i.e. device# ^ 4).

  All interrupts occuring on the Bridge cause an XIO interrupt packet to be
  sent to the XIO interrupt address programmed at Bridge initialization time;
  packets can be configured as self-clearing or not on an interrupt source
  basis.

  Due to silicon bugs, interrupts can be lost if two interrupt sources
  interrupt within a too short interval; there is a documented workaround for
  this which consists of recognizing this situation and self-inflicting
  ourselves the lost interrupt (see details in xbridge_intr_handler() ).

- - endianness

  Endianness control is quite finegrained and quite complex at first glance:
  - memory and I/O accesses not occuring within devio ranges have their
    endianness controlled by the endianness flags in the (global) Bridge
    configuration register...
  - ... to which adds the per-device endianness flag in the device devio
    register...
  - and accesses occuring through devio register only use the
    per-device devio register mentioned above, even if the devio
    range is defined in a different register!

  i.e.

  devio 0 = endianness control C0, devio range R0
  devio 1 = endianness control C1, devio range R1
  global Bridge = endianness control C2

  1. access from device 0 to R0 uses C2^C0
  2. access from device 0 to R1 uses C2^C0
  3. access from device 0 outside R0 and R1 uses C2
  4. access from device 1 to R0 uses C2^C1
  5. access from device 1 to R1 uses C2^C1
  6. access from device 1 outside R0 and R1 uses C1

  (note that, the way I set up devio registers, cases 2 and 4 can never
   occur if both device 0 and device 1 are present)

  Now for DMA:
  - i don't remember what 64 bit DMA uses
  - direct DMA (within the 2GB window) uses a per-device bit in devio
  - translated DMA (using ATE) uses a per-device bit in devio if the
    chip is a Bridge, while XBridge and PIC use different DMA addresses
    (i.e. with a given ATE, there is one address pointing to it in
     non-swapped mode, and another address pointing to it in swapped
     mode).

 */

#include <sys/param.h>
#include <sys/systm.h>
#include <sys/kernel.h>
#include <sys/device.h>
#include <sys/evcount.h>
#include <sys/malloc.h>
#include <sys/proc.h>
#include <sys/extent.h>
#include <sys/mbuf.h>
#include <sys/mutex.h>
#include <sys/queue.h>
#include <sys/atomic.h>

#include <machine/autoconf.h>
#include <machine/bus.h>
#include <machine/cpu.h>
#include <machine/intr.h>
#include <machine/mnode.h>

#include <uvm/uvm_extern.h>

#include <dev/pci/pcireg.h>
#include <dev/pci/pcivar.h>
#include <dev/pci/pcidevs.h>
#include <dev/pci/ppbreg.h>

#include <dev/cardbus/rbus.h>

#include <mips64/archtype.h>
#include <sgi/xbow/xbow.h>
#include <sgi/xbow/xbowdevs.h>

#include <sgi/xbow/widget.h>
#include <sgi/xbow/xbridgereg.h>

#ifdef TGT_OCTANE
#include <sgi/sgi/ip30.h>
#endif

#include "cardbus.h"

int	xbridge_match(struct device *, void *, void *);
void	xbridge_attach(struct device *, struct device *, void *);
int	xbridge_print(void *, const char *);
int	xbridge_submatch(struct device *, void *, void *);
int	xbpci_match(struct device *, void *, void *);
void	xbpci_attach(struct device *, struct device *, void *);
int	xbpci_print(void *, const char *);

struct xbridge_intr;

struct xbpci_attach_args {
	uint	xaa_busno;

	int	xaa_flags;
	int16_t	xaa_nasid;
	int	xaa_widget;
	uint	xaa_devio_skew;
	int	xaa_revision;

	bus_space_tag_t	xaa_regt;
	bus_addr_t	xaa_offset;
};

struct xbpci_softc {
	struct device	xb_dev;
	struct device	*xb_bow;

	/*
	 * Bridge register accessors.
	 * Due to hardware bugs, PIC registers can only be accessed
	 * with 64 bit operations, although the hardware was supposed
	 * to be directly compatible with XBridge on that aspect.
	 */
	uint64_t	(*xb_read_reg)(bus_space_tag_t, bus_space_handle_t,
			    bus_addr_t);
	void		(*xb_write_reg)(bus_space_tag_t, bus_space_handle_t,
			    bus_addr_t, uint64_t);

	uint		xb_busno;
	uint		xb_nslots;

	int		xb_flags;
#define	XF_XBRIDGE		0x01	/* is either PIC or XBridge */
#define	XF_PIC			0x02	/* is PIC */
#define	XF_NO_DIRECT_IO		0x04	/* no direct I/O mapping */
#define	XF_PCIX			0x08	/* bus in PCIX mode */
	int16_t		xb_nasid;
	int		xb_widget;
	uint		xb_devio_skew;	/* upper bits of devio ARCS mappings */
	int		xb_revision;

	struct mips_pci_chipset xb_pc;

	bus_space_tag_t	xb_regt;
	bus_space_handle_t xb_regh;

	struct mips_bus_space *xb_mem_bus_space;
	struct mips_bus_space *xb_mem_bus_space_sw;
	struct mips_bus_space *xb_io_bus_space;
	struct mips_bus_space *xb_io_bus_space_sw;
	struct machine_bus_dma_tag *xb_dmat;

	struct xbridge_intr	*xb_intr[BRIDGE_NINTRS];
	char	xb_intrstr[BRIDGE_NINTRS][sizeof("irq #, xbow irq ###")];

	int		xb_err_intrsrc;
	int		(*xb_pci_intr_handler)(void *);

	uint64_t	xb_ier;		/* copy of BRIDGE_IER value */

	/*
	 * Device information.
	 */
	struct {
		pcireg_t	id;
		uint32_t	devio;
	} xb_devices[MAX_SLOTS];
	uint		xb_devio_usemask;

	/*
	 * Large resource view sizes
	 */
	bus_addr_t	xb_iostart, xb_ioend;
	bus_addr_t	xb_memstart, xb_memend;

	/*
	 * Resource extents for the large resource views, used during
	 * resource setup, then cleaned up for the MI code.
	 */
	char		xb_ioexname[32];
	struct extent	*xb_ioex;
	char		xb_memexname[32];
	struct extent	*xb_memex;
};

struct xbridge_softc {
	struct device	sc_dev;
	uint		sc_nbuses;

	struct mips_bus_space	sc_regt;
};

#define	DEVNAME(xb)	((xb)->xb_dev.dv_xname)

#define	PCI_ID_EMPTY		PCI_ID_CODE(PCI_VENDOR_INVALID, 0xffff);
#define	SLOT_EMPTY(xb,dev) \
	(PCI_VENDOR((xb)->xb_devices[dev].id) == PCI_VENDOR_INVALID || \
	 PCI_VENDOR((xb)->xb_devices[dev].id) == 0)

const struct cfattach xbridge_ca = {
	sizeof(struct xbridge_softc), xbridge_match, xbridge_attach
};

struct cfdriver xbridge_cd = {
	NULL, "xbridge", DV_DULL
};

const struct cfattach xbpci_ca = {
	sizeof(struct xbpci_softc), xbpci_match, xbpci_attach
};

struct cfdriver xbpci_cd = {
	NULL, "xbpci", DV_DULL
};

void	xbridge_attach_hook(struct device *, struct device *,
				struct pcibus_attach_args *);
int	xbridge_bus_maxdevs(void *, int);
pcitag_t xbridge_make_tag(void *, int, int, int);
void	xbridge_decompose_tag(void *, pcitag_t, int *, int *, int *);
int	xbridge_conf_size(void *, pcitag_t);
pcireg_t xbridge_conf_read(void *, pcitag_t, int);
void	xbridge_conf_write(void *, pcitag_t, int, pcireg_t);
int	xbridge_intr_map(struct pci_attach_args *, pci_intr_handle_t *);
const char *xbridge_intr_string(void *, pci_intr_handle_t);
void	*xbridge_intr_establish(void *, pci_intr_handle_t, int,
	    int (*func)(void *), void *, const char *);
void	xbridge_intr_disestablish(void *, void *);
int	xbridge_intr_line(void *, pci_intr_handle_t);
int	xbridge_ppb_setup(void *, pcitag_t, bus_addr_t *, bus_addr_t *,
	    bus_addr_t *, bus_addr_t *);
int	xbridge_probe_device_hook(void *, struct pci_attach_args *);
void	*xbridge_rbus_parent_io(struct pci_attach_args *);
void	*xbridge_rbus_parent_mem(struct pci_attach_args *);
int	xbridge_get_widget(void *);
int	xbridge_get_dl(void *, pcitag_t, struct sgi_device_location *);

int	xbridge_pci_intr_handler(void *);
int	xbridge_picv1_pci_intr_handler(void *);
int	xbridge_err_intr_handler(void *);

uint8_t xbridge_read_1(bus_space_tag_t, bus_space_handle_t, bus_size_t);
uint16_t xbridge_read_2(bus_space_tag_t, bus_space_handle_t, bus_size_t);
void	xbridge_write_1(bus_space_tag_t, bus_space_handle_t, bus_size_t,
	    uint8_t);
void	xbridge_write_2(bus_space_tag_t, bus_space_handle_t, bus_size_t,
	    uint16_t);
void	xbridge_read_raw_2(bus_space_tag_t, bus_space_handle_t, bus_addr_t,
	    uint8_t *, bus_size_t);
void	xbridge_write_raw_2(bus_space_tag_t, bus_space_handle_t, bus_addr_t,
	    const uint8_t *, bus_size_t);
void	xbridge_read_raw_4(bus_space_tag_t, bus_space_handle_t, bus_addr_t,
	    uint8_t *, bus_size_t);
void	xbridge_write_raw_4(bus_space_tag_t, bus_space_handle_t, bus_addr_t,
	    const uint8_t *, bus_size_t);
void	xbridge_read_raw_8(bus_space_tag_t, bus_space_handle_t, bus_addr_t,
	    uint8_t *, bus_size_t);
void	xbridge_write_raw_8(bus_space_tag_t, bus_space_handle_t, bus_addr_t,
	    const uint8_t *, bus_size_t);

int	xbridge_space_map_devio(bus_space_tag_t, bus_addr_t, bus_size_t, int,
	    bus_space_handle_t *);
int	xbridge_space_map_io(bus_space_tag_t, bus_addr_t, bus_size_t, int,
	    bus_space_handle_t *);
int	xbridge_space_map_mem(bus_space_tag_t, bus_addr_t, bus_size_t, int,
	    bus_space_handle_t *);
int	xbridge_space_region_devio(bus_space_tag_t, bus_space_handle_t,
	    bus_size_t, bus_size_t, bus_space_handle_t *);
int	xbridge_space_region_io(bus_space_tag_t, bus_space_handle_t,
	    bus_size_t, bus_size_t, bus_space_handle_t *);
int	xbridge_space_region_mem(bus_space_tag_t, bus_space_handle_t,
	    bus_size_t, bus_size_t, bus_space_handle_t *);

void	xbridge_space_barrier(bus_space_tag_t, bus_space_handle_t,
	    bus_size_t, bus_size_t, int);

bus_addr_t xbridge_pa_to_device(paddr_t, int);

int	xbridge_rbus_space_map(bus_space_tag_t, bus_addr_t, bus_size_t,
	    int, bus_space_handle_t *);
void	xbridge_rbus_space_unmap(bus_space_tag_t, bus_space_handle_t,
	    bus_size_t, bus_addr_t *);

void	xbridge_err_clear(struct xbpci_softc *, uint64_t);
void	xbridge_err_handle(struct xbpci_softc *, uint64_t);

int	xbridge_allocate_devio(struct xbpci_softc *, int, int);
void	xbridge_set_devio(struct xbpci_softc *, int, uint32_t, int);

int	xbridge_resource_explore(struct xbpci_softc *, pcitag_t,
	    struct extent *, struct extent *);
void	xbridge_resource_manage(struct xbpci_softc *, pcitag_t,
	    struct extent *, struct extent *);

void	xbridge_device_setup(struct xbpci_softc *, int, int, uint32_t);
int	xbridge_extent_chomp(struct xbpci_softc *, struct extent *);
void	xbridge_extent_setup(struct xbpci_softc *);
struct extent *
	xbridge_mapping_setup(struct xbpci_softc *, int);
void	xbridge_resource_setup(struct xbpci_softc *);
void	xbridge_rrb_setup(struct xbpci_softc *, int);
const char *
	xbridge_setup(struct xbpci_softc *);

uint64_t bridge_read_reg(bus_space_tag_t, bus_space_handle_t, bus_addr_t);
void	bridge_write_reg(bus_space_tag_t, bus_space_handle_t, bus_addr_t,
	    uint64_t);
uint64_t pic_read_reg(bus_space_tag_t, bus_space_handle_t, bus_addr_t);
void	pic_write_reg(bus_space_tag_t, bus_space_handle_t, bus_addr_t,
	    uint64_t);

static __inline__ uint64_t
xbridge_read_reg(struct xbpci_softc *xb, bus_addr_t a)
{
	return (*xb->xb_read_reg)(xb->xb_regt, xb->xb_regh, a);
}
static __inline__ void
xbridge_write_reg(struct xbpci_softc *xb, bus_addr_t a, uint64_t v)
{
	(*xb->xb_write_reg)(xb->xb_regt, xb->xb_regh, a, v);
}

static __inline__ void
xbridge_wbflush(struct xbpci_softc *xb, uint d)
{
	while (xbridge_read_reg(xb, BRIDGE_DEVICE_WBFLUSH(d)) != 0) ;
}

static const struct machine_bus_dma_tag xbridge_dma_tag = {
	NULL,			/* _cookie */
	_dmamap_create,
	_dmamap_destroy,
	_dmamap_load,
	_dmamap_load_mbuf,
	_dmamap_load_uio,
	_dmamap_load_raw,
	_dmamap_load_buffer,
	_dmamap_unload,
	_dmamap_sync,
	_dmamem_alloc,
	_dmamem_free,
	_dmamem_map,
	_dmamem_unmap,
	_dmamem_mmap,
	xbridge_pa_to_device,
	BRIDGE_DMA_DIRECT_LENGTH - 1
};

static const struct mips_pci_chipset xbridge_pci_chipset = {
	.pc_attach_hook = xbridge_attach_hook,
	.pc_bus_maxdevs = xbridge_bus_maxdevs,
	.pc_make_tag = xbridge_make_tag,
	.pc_decompose_tag = xbridge_decompose_tag,
	.pc_conf_size = xbridge_conf_size,
	.pc_conf_read = xbridge_conf_read,
	.pc_conf_write = xbridge_conf_write,
	.pc_probe_device_hook = xbridge_probe_device_hook,
	.pc_get_widget = xbridge_get_widget,
	.pc_get_dl = xbridge_get_dl,
	.pc_intr_map = xbridge_intr_map,
	.pc_intr_string = xbridge_intr_string,
	.pc_intr_establish = xbridge_intr_establish,
	.pc_intr_disestablish = xbridge_intr_disestablish,
	.pc_intr_line = xbridge_intr_line,
	.pc_ppb_setup = xbridge_ppb_setup,
#if NCARDBUS > 0
	.pc_rbus_parent_io = xbridge_rbus_parent_io,
	.pc_rbus_parent_mem = xbridge_rbus_parent_mem
#endif
};

/*
 ********************* Autoconf glue.
 */

static const struct {
	uint32_t vendor;
	uint32_t product;
	int	flags;
} xbridge_devices[] = {
	/* original Bridge */
	{ XBOW_VENDOR_SGI4, XBOW_PRODUCT_SGI4_BRIDGE,	0 },
	/* XBridge */
	{ XBOW_VENDOR_SGI3, XBOW_PRODUCT_SGI3_XBRIDGE,	XF_XBRIDGE },
	/* PIC */
	{ XBOW_VENDOR_SGI3, XBOW_PRODUCT_SGI3_PIC,	XF_PIC }
};

int
xbridge_match(struct device *parent, void *match, void *aux)
{
	struct xbow_attach_args *xaa = aux;
	uint i;

	for (i = 0; i < nitems(xbridge_devices); i++)
		if (xaa->xaa_vendor == xbridge_devices[i].vendor &&
		    xaa->xaa_product == xbridge_devices[i].product)
			return 1;

	return 0;
}

void
xbridge_attach(struct device *parent, struct device *self, void *aux)
{
	struct xbridge_softc *sc = (struct xbridge_softc *)self;
	struct xbow_attach_args *xaa = aux;
	struct xbpci_attach_args xbpa;
	int flags;
	uint devio_skew;
	uint i;

	printf(" revision %d\n", xaa->xaa_revision);

	for (i = 0; i < nitems(xbridge_devices); i++)
		if (xaa->xaa_vendor == xbridge_devices[i].vendor &&
		    xaa->xaa_product == xbridge_devices[i].product) {
			flags = xbridge_devices[i].flags;
			break;
		}

	/* PICs are XBridges without an I/O window */
	if (ISSET(flags, XF_PIC))
		SET(flags, XF_XBRIDGE | XF_NO_DIRECT_IO);
	/* Bridge < D lacks an I/O window */
	if (!ISSET(flags, XF_XBRIDGE) && xaa->xaa_revision < 4)
		SET(flags, XF_NO_DIRECT_IO);

	/*
	 * Figure out where the ARCS devio mappings will go.
	 * ARCS configures all the devio in a contiguous 16MB area
	 * (i.e. the upper 8 bits of the DEVIO_BASE field of the
	 * devio registers are the same).
	 *
	 * In order to make our life simpler, on widgets where we may
	 * want to keep some of the ARCS mappings (because that's where
	 * our console device lives), we will use the same 16MB area.
	 *
	 * Otherwise, we can use whatever values we want; to keep the
	 * code simpler, we will nevertheless use a 16MB area as well,
	 * making sure it does not start at zero so that pcmcia bridges
	 * can be used.
	 *
	 * On Octane, the upper bits of ARCS mappings are zero, and thus
	 * point to the start of the widget. On Origin, they match the
	 * widget number.
	 */
#ifdef TGT_OCTANE
	if (sys_config.system_type == SGI_OCTANE &&
	    xaa->xaa_widget == IP30_BRIDGE_WIDGET)
		devio_skew = 0;
	else
#endif
		devio_skew = xaa->xaa_widget;

	sc->sc_nbuses = ISSET(flags, XF_PIC) ? PIC_NBUSES : BRIDGE_NBUSES;

	/* make a permanent copy of the on-stack bus_space_tag */
	bcopy(xaa->xaa_iot, &sc->sc_regt, sizeof(struct mips_bus_space));

	/* configure and attach PCI buses */
	for (i = 0; i < sc->sc_nbuses; i++) {
		xbpa.xaa_busno = i;
		xbpa.xaa_flags = flags;
		xbpa.xaa_nasid = xaa->xaa_nasid;
		xbpa.xaa_widget = xaa->xaa_widget;
		xbpa.xaa_devio_skew = devio_skew;
		xbpa.xaa_revision = xaa->xaa_revision;
		xbpa.xaa_regt = &sc->sc_regt;
		xbpa.xaa_offset = i != 0 ? BRIDGE_BUS_OFFSET : 0;

		config_found_sm(&sc->sc_dev, &xbpa, xbridge_print,
		    xbridge_submatch);
	}
}

int
xbridge_submatch(struct device *parent, void *vcf, void *aux)
{
	struct cfdata *cf = vcf;
	struct xbpci_attach_args *xaa = aux;

	if (cf->cf_loc[0] != -1 && cf->cf_loc[0] != xaa->xaa_busno)
		return 0;

	return (*cf->cf_attach->ca_match)(parent, vcf, aux);
}

int
xbridge_print(void *aux, const char *pnp)
{
	struct xbpci_attach_args *xaa = aux;

	if (pnp)
		printf("xbpci at %s", pnp);
	printf(" bus %d", xaa->xaa_busno);

	return UNCONF;
}

int
xbpci_match(struct device *parent, void *vcf, void *aux)
{
	return 1;
}

void
xbpci_attach(struct device *parent, struct device *self, void *aux)
{
	struct xbpci_softc *xb = (struct xbpci_softc *)self;
	struct xbpci_attach_args *xaa = (struct xbpci_attach_args *)aux;
	struct pcibus_attach_args pba;
	const char *errmsg = NULL;

	printf(": ");

	/* xbow -> xbridge -> xbpci: xbow device is our grandfather */
	xb->xb_bow = parent->dv_parent;
	xb->xb_busno = xaa->xaa_busno;
	xb->xb_flags = xaa->xaa_flags;
	xb->xb_nasid = xaa->xaa_nasid;
	xb->xb_widget = xaa->xaa_widget;
	xb->xb_devio_skew = xaa->xaa_devio_skew;
	xb->xb_revision = xaa->xaa_revision;

	if (ISSET(xb->xb_flags, XF_PIC)) {
		xb->xb_nslots = PIC_NSLOTS;

		xb->xb_read_reg = pic_read_reg;
		xb->xb_write_reg = pic_write_reg;
	} else {
		xb->xb_nslots = BRIDGE_NSLOTS;

		xb->xb_read_reg = bridge_read_reg;
		xb->xb_write_reg = bridge_write_reg;
	}

	/*
	 * Revision 1 of PIC requires a wrapper around
	 * xbridge_pci_intr_handler().
	 */
	if (ISSET(xb->xb_flags, XF_PIC) && xb->xb_revision <= 1)
		xb->xb_pci_intr_handler = xbridge_picv1_pci_intr_handler;
	else
		xb->xb_pci_intr_handler = xbridge_pci_intr_handler;

	/*
	 * Map Bridge registers.
	 */

	xb->xb_regt = xaa->xaa_regt;
	if (bus_space_map(xaa->xaa_regt, xaa->xaa_offset,
	    BRIDGE_REGISTERS_SIZE, 0, &xb->xb_regh)) {
		printf("unable to map control registers\n");
		return;
	}

	/*
	 * Create bus_space accessors... we inherit them from xbow, but
	 * need to overwrite mapping routines, and set up byteswapping
	 * versions.
	 */

	xb->xb_mem_bus_space = malloc(sizeof (*xb->xb_mem_bus_space),
	    M_DEVBUF, M_NOWAIT);
	xb->xb_mem_bus_space_sw = malloc(sizeof (*xb->xb_mem_bus_space_sw),
	    M_DEVBUF, M_NOWAIT);
	xb->xb_io_bus_space = malloc(sizeof (*xb->xb_io_bus_space),
	    M_DEVBUF, M_NOWAIT);
	xb->xb_io_bus_space_sw = malloc(sizeof (*xb->xb_io_bus_space_sw),
	    M_DEVBUF, M_NOWAIT);
	if (xb->xb_mem_bus_space == NULL || xb->xb_mem_bus_space_sw == NULL ||
	    xb->xb_io_bus_space == NULL || xb->xb_io_bus_space_sw == NULL)
		goto fail1;

	bcopy(xb->xb_regt, xb->xb_mem_bus_space, sizeof(*xb->xb_mem_bus_space));
	xb->xb_mem_bus_space->bus_private = xb;
	xb->xb_mem_bus_space->_space_map = xbridge_space_map_devio;
	xb->xb_mem_bus_space->_space_subregion = xbridge_space_region_devio;
	xb->xb_mem_bus_space->_space_barrier = xbridge_space_barrier;

	bcopy(xb->xb_mem_bus_space, xb->xb_mem_bus_space_sw,
	    sizeof(*xb->xb_mem_bus_space));
	xb->xb_mem_bus_space_sw->_space_read_1 = xbridge_read_1;
	xb->xb_mem_bus_space_sw->_space_write_1 = xbridge_write_1;
	xb->xb_mem_bus_space_sw->_space_read_2 = xbridge_read_2;
	xb->xb_mem_bus_space_sw->_space_write_2 = xbridge_write_2;
	xb->xb_mem_bus_space_sw->_space_read_raw_2 = xbridge_read_raw_2;
	xb->xb_mem_bus_space_sw->_space_write_raw_2 = xbridge_write_raw_2;
	xb->xb_mem_bus_space_sw->_space_read_raw_4 = xbridge_read_raw_4;
	xb->xb_mem_bus_space_sw->_space_write_raw_4 = xbridge_write_raw_4;
	xb->xb_mem_bus_space_sw->_space_read_raw_8 = xbridge_read_raw_8;
	xb->xb_mem_bus_space_sw->_space_write_raw_8 = xbridge_write_raw_8;

	bcopy(xb->xb_regt, xb->xb_io_bus_space, sizeof(*xb->xb_io_bus_space));
	xb->xb_io_bus_space->bus_private = xb;
	xb->xb_io_bus_space->_space_map = xbridge_space_map_devio;
	xb->xb_io_bus_space->_space_subregion = xbridge_space_region_devio;
	xb->xb_io_bus_space->_space_barrier = xbridge_space_barrier;

	bcopy(xb->xb_io_bus_space, xb->xb_io_bus_space_sw,
	    sizeof(*xb->xb_io_bus_space));
	xb->xb_io_bus_space_sw->_space_read_1 = xbridge_read_1;
	xb->xb_io_bus_space_sw->_space_write_1 = xbridge_write_1;
	xb->xb_io_bus_space_sw->_space_read_2 = xbridge_read_2;
	xb->xb_io_bus_space_sw->_space_write_2 = xbridge_write_2;
	xb->xb_io_bus_space_sw->_space_read_raw_2 = xbridge_read_raw_2;
	xb->xb_io_bus_space_sw->_space_write_raw_2 = xbridge_write_raw_2;
	xb->xb_io_bus_space_sw->_space_read_raw_4 = xbridge_read_raw_4;
	xb->xb_io_bus_space_sw->_space_write_raw_4 = xbridge_write_raw_4;
	xb->xb_io_bus_space_sw->_space_read_raw_8 = xbridge_read_raw_8;
	xb->xb_io_bus_space_sw->_space_write_raw_8 = xbridge_write_raw_8;

	xb->xb_dmat = malloc(sizeof (*xb->xb_dmat), M_DEVBUF, M_NOWAIT);
	if (xb->xb_dmat == NULL)
		goto fail1;
	memcpy(xb->xb_dmat, &xbridge_dma_tag, sizeof(*xb->xb_dmat));
	xb->xb_dmat->_cookie = xb;

	/*
	 * Initialize PCI methods.
	 */

	bcopy(&xbridge_pci_chipset, &xb->xb_pc, sizeof(xbridge_pci_chipset));
	xb->xb_pc.pc_conf_v = xb;
	xb->xb_pc.pc_intr_v = xb;

	/*
	 * Configure Bridge for proper operation (DMA, I/O mappings,
	 * RRB allocation, etc).
	 */

	if ((errmsg = xbridge_setup(xb)) != NULL)
		goto fail2;
	printf("\n");

	/*
	 * Attach children.
	 */

	xbridge_extent_setup(xb);

	bzero(&pba, sizeof(pba));
	pba.pba_busname = "pci";
	/*
	 * XXX pba_iot and pba_memt ought to be irrelevant, since we
	 * XXX return the tags a device needs in probe_device_hook();
	 * XXX however the pci(4) device needs a valid pba_memt for the
	 * XXX PCIOCGETROM* ioctls.
	 * XXX
	 * XXX Since most devices will need the byteswap tags, and those
	 * XXX which don't do not have PCI roms, let's pass the byteswap
	 * XXX versions by default.
	 */
	pba.pba_iot = xb->xb_io_bus_space_sw;
	pba.pba_memt = xb->xb_mem_bus_space_sw;
	pba.pba_dmat = xb->xb_dmat;
	pba.pba_ioex = xb->xb_ioex;
	pba.pba_memex = xb->xb_memex;
#ifdef DEBUG
	if (xb->xb_ioex != NULL)
		extent_print(xb->xb_ioex);
	if (xb->xb_memex != NULL)
		extent_print(xb->xb_memex);
#endif
	pba.pba_pc = &xb->xb_pc;
	pba.pba_domain = pci_ndomains++;
	pba.pba_bus = 0;

	config_found(self, &pba, xbpci_print);
	return;

fail2:
	free(xb->xb_dmat, M_DEVBUF, 0);
fail1:
	free(xb->xb_io_bus_space_sw, M_DEVBUF,
	    sizeof (*xb->xb_io_bus_space_sw));
	free(xb->xb_io_bus_space, M_DEVBUF, sizeof (*xb->xb_io_bus_space));
	free(xb->xb_mem_bus_space_sw, M_DEVBUF,
	    sizeof (*xb->xb_mem_bus_space_sw));
	free(xb->xb_mem_bus_space, M_DEVBUF, sizeof (*xb->xb_mem_bus_space));
	if (errmsg == NULL)
		errmsg = "not enough memory to build bus access structures";
	printf("%s\n", errmsg);
}

int
xbpci_print(void *aux, const char *pnp)
{
	struct pcibus_attach_args *pba = aux;

	if (pnp)
		printf("%s at %s", pba->pba_busname, pnp);
	printf(" bus %d", pba->pba_bus);

	return UNCONF;
}

/*
 ********************* PCI glue.
 */

void
xbridge_attach_hook(struct device *parent, struct device *self,
    struct pcibus_attach_args *pba)
{
}

pcitag_t
xbridge_make_tag(void *cookie, int bus, int dev, int func)
{
	return (bus << 16) | (dev << 11) | (func << 8);
}

void
xbridge_decompose_tag(void *cookie, pcitag_t tag, int *busp, int *devp,
    int *funcp)
{
	if (busp != NULL)
		*busp = (tag >> 16) & 0xff;
	if (devp != NULL)
		*devp = (tag >> 11) & 0x1f;
	if (funcp != NULL)
		*funcp = (tag >> 8) & 0x7;
}

int
xbridge_bus_maxdevs(void *cookie, int busno)
{
	struct xbpci_softc *xb = cookie;

	return busno == 0 ? xb->xb_nslots : 32;
}

int
xbridge_conf_size(void *cookie, pcitag_t tag)
{
#if 0
	struct xbpci_softc *xb = cookie;
	int bus, dev, fn;

	xbridge_decompose_tag(cookie, tag, &bus, &dev, &fn);

	/*
	 * IOC3 devices only implement a subset of the PCI configuration
	 * registers. Although xbridge_conf_{read,write} correctly
	 * handle the unimplemented registers, better provide a limited
	 * configuration space to userland.
	 */

	if (bus == 0 && xb->xb_devices[dev].id ==
	    PCI_ID_CODE(PCI_VENDOR_SGI, PCI_PRODUCT_SGI_IOC3))
		return PCI_INTERRUPT_REG + 4;
#endif

	return PCI_CONFIG_SPACE_SIZE;
}

pcireg_t
xbridge_conf_read(void *cookie, pcitag_t tag, int offset)
{
	struct xbpci_softc *xb = cookie;
	pcireg_t data;
	int bus, dev, fn;
	paddr_t pa;
	int skip;
	int s;

	xbridge_decompose_tag(cookie, tag, &bus, &dev, &fn);

	/*
	 * IOC3 devices only implement a subset of the PCI configuration
	 * registers (supposedly only the first 0x20 bytes, however
	 * writing to the second BAR also writes to the first).
	 *
	 * Depending on which particular model we encounter, things may
	 * seem to work, or write access to nonexisting registers would
	 * completely freeze the machine.
	 *
	 * We thus check for the device type here, and handle the non
	 * existing registers ourselves.
	 */

	skip = 0;
	if (bus == 0 && xb->xb_devices[dev].id ==
	    PCI_ID_CODE(PCI_VENDOR_SGI, PCI_PRODUCT_SGI_IOC3)) {
		switch (offset) {
		case PCI_ID_REG:
		case PCI_COMMAND_STATUS_REG:
		case PCI_CLASS_REG:
		case PCI_BHLC_REG:
		case PCI_MAPREG_START:
			/* These registers are implemented. Go ahead. */
			break;
		case PCI_INTERRUPT_REG:
			/* This register is not implemented. Fake it. */
			data = (PCI_INTERRUPT_PIN_A <<
			    PCI_INTERRUPT_PIN_SHIFT) |
			    (dev << PCI_INTERRUPT_LINE_SHIFT);
			skip = 1;
			break;
		default:
			/* These registers are not implemented. */
			data = 0;
			skip = 1;
			break;
		}
	}

	if (skip == 0) {
		/*
		 * Disable interrupts on this bridge (especially error
		 * interrupts).
		 */
		s = splhigh();
		xbridge_write_reg(xb, BRIDGE_IER, 0);
		(void)xbridge_read_reg(xb, WIDGET_TFLUSH);

		if (bus != 0) {
			xbridge_write_reg(xb, BRIDGE_PCI_CFG,
			    (bus << 16) | (dev << 11));
			pa = xb->xb_regh + BRIDGE_PCI_CFG1_SPACE;
		} else {
			/*
			 * On PIC, device 0 in configuration space is the
			 * PIC itself, device slots are offset by one.
			 */
			if (ISSET(xb->xb_flags, XF_PIC))
				dev++;
			pa = xb->xb_regh + BRIDGE_PCI_CFG_SPACE + (dev << 12);
		}

		pa += (fn << 8) + offset;
		if (guarded_read_4(pa, &data) != 0)
			data = 0xffffffff;

		xbridge_write_reg(xb, BRIDGE_IER, xb->xb_ier);
		(void)xbridge_read_reg(xb, WIDGET_TFLUSH);
		splx(s);
	}

	return data;
}

void
xbridge_conf_write(void *cookie, pcitag_t tag, int offset, pcireg_t data)
{
	struct xbpci_softc *xb = cookie;
	int bus, dev, fn;
	paddr_t pa;
	int skip;
	int s;

	xbridge_decompose_tag(cookie, tag, &bus, &dev, &fn);

	/*
	 * IOC3 devices only implement a subset of the PCI configuration
	 * registers.
	 * Depending on which particular model we encounter, things may
	 * seem to work, or write access to nonexisting registers would
	 * completely freeze the machine.
	 *
	 * We thus check for the device type here, and handle the non
	 * existing registers ourselves.
	 */

	skip = 0;
	if (bus == 0 && xb->xb_devices[dev].id ==
	    PCI_ID_CODE(PCI_VENDOR_SGI, PCI_PRODUCT_SGI_IOC3)) {
		switch (offset) {
		case PCI_COMMAND_STATUS_REG:
			/*
			 * Some IOC3 models do not support having this bit
			 * cleared (which is what pci_mapreg_probe() will
			 * do), so we set it unconditionnaly.
			 */
			data |= PCI_COMMAND_MEM_ENABLE;
			/* FALLTHROUGH */
		case PCI_ID_REG:
		case PCI_CLASS_REG:
		case PCI_BHLC_REG:
		case PCI_MAPREG_START:
			/* These registers are implemented. Go ahead. */
			break;
		default:
			/* These registers are not implemented. */
			skip = 1;
			break;
		}
	}

	if (skip == 0) {
		/*
		 * Disable interrupts on this bridge (especially error
		 * interrupts).
		 */
		s = splhigh();
		xbridge_write_reg(xb, BRIDGE_IER, 0);
		(void)xbridge_read_reg(xb, WIDGET_TFLUSH);

		if (bus != 0) {
			xbridge_write_reg(xb, BRIDGE_PCI_CFG,
			    (bus << 16) | (dev << 11));
			pa = xb->xb_regh + BRIDGE_PCI_CFG1_SPACE;
		} else {
			/*
			 * On PIC, device 0 in configuration space is the
			 * PIC itself, device slots are offset by one.
			 */
			if (ISSET(xb->xb_flags, XF_PIC))
				dev++;
			pa = xb->xb_regh + BRIDGE_PCI_CFG_SPACE + (dev << 12);
		}

		pa += (fn << 8) + offset;
		guarded_write_4(pa, data);

		xbridge_write_reg(xb, BRIDGE_IER, xb->xb_ier);
		(void)xbridge_read_reg(xb, WIDGET_TFLUSH);
		splx(s);
	}
}

int
xbridge_probe_device_hook(void *cookie, struct pci_attach_args *pa)
{
	struct xbpci_softc *xb = cookie;

	/*
	 * Check for the hardware byteswap setting of the device we are
	 * interested in, and pick bus_space_tag accordingly.
	 * Note that the device list here must match xbridge_resource_setup().
	 */
	if (pa->pa_id == PCI_ID_CODE(PCI_VENDOR_SGI, PCI_PRODUCT_SGI_IOC3) ||
	    pa->pa_id == PCI_ID_CODE(PCI_VENDOR_SGI, PCI_PRODUCT_SGI_IOC4) ||
	    pa->pa_id == PCI_ID_CODE(PCI_VENDOR_SGI, PCI_PRODUCT_SGI_RAD1)) {
		pa->pa_iot = xb->xb_io_bus_space;
		pa->pa_memt = xb->xb_mem_bus_space;
	} else {
		pa->pa_iot = xb->xb_io_bus_space_sw;
		pa->pa_memt = xb->xb_mem_bus_space_sw;
	}

	return 0;
}

int
xbridge_get_widget(void *cookie)
{
	struct xbpci_softc *xb = cookie;

	return xb->xb_widget;
}

int
xbridge_get_dl(void *cookie, pcitag_t tag, struct sgi_device_location *sdl)
{
	int bus, device, fn;
	struct xbpci_softc *xb = cookie;

	xbridge_decompose_tag(cookie, tag, &bus, &device, &fn);
	if (bus != 0)
		return 0;

	sdl->nasid = xb->xb_nasid;
	sdl->widget = xb->xb_widget;

	sdl->bus = xb->xb_busno;
	sdl->device = device;
	sdl->fn = fn;

	return 1;
}

/*
 ********************* Interrupt handling.
 */

/*
 * We map each slot to its own interrupt bit, which will in turn be routed to
 * the Heart or Hub widget in charge of interrupt processing.
 */

struct xbridge_intrhandler {
	LIST_ENTRY(xbridge_intrhandler)	xih_nxt;
	struct xbridge_intr *xih_main;
	int	(*xih_func)(void *);
	void	*xih_arg;
	struct evcount	xih_count;
	int	 xih_flags;
#define	XIH_MPSAFE	0x01
	int	 xih_level;
	int	 xih_device;	/* device slot number */
};

struct xbridge_intr {
	struct	xbpci_softc	*xi_bus;
	int	xi_intrsrc;	/* interrupt source on interrupt widget */
	int	xi_intrbit;	/* interrupt source on BRIDGE */
	LIST_HEAD(, xbridge_intrhandler) xi_handlers;
};

/* how our pci_intr_handle_t are constructed... */
#define	XBRIDGE_INTR_VALID		0x100
#define	XBRIDGE_INTR_HANDLE(d,b)	(XBRIDGE_INTR_VALID | ((d) << 3) | (b))
#define	XBRIDGE_INTR_DEVICE(h)		(((h) >> 3) & 07)
#define	XBRIDGE_INTR_BIT(h)		((h) & 07)

int
xbridge_intr_map(struct pci_attach_args *pa, pci_intr_handle_t *ihp)
{
	struct xbpci_softc *xb = pa->pa_pc->pc_conf_v;
	int bus, device, intr;
	int pin;

	*ihp = 0;

	if (pa->pa_intrpin == 0) {
		/* No IRQ used. */
		return 1;
	}

#ifdef DIAGNOSTIC
	if (pa->pa_intrpin > 4) {
		printf("%s: bad interrupt pin %d\n", __func__, pa->pa_intrpin);
		return 1;
	}
#endif

	pci_decompose_tag(pa->pa_pc, pa->pa_tag, &bus, &device, NULL);

	if (pa->pa_bridgetag) {
		pin = PPB_INTERRUPT_SWIZZLE(pa->pa_rawintrpin, device);
		if (!ISSET(pa->pa_bridgeih[pin - 1], XBRIDGE_INTR_VALID))
			return 0;
		intr = XBRIDGE_INTR_BIT(pa->pa_bridgeih[pin - 1]);
	} else {
		/*
		 * For IOC3 devices, pin A is always the regular PCI interrupt,
		 * but wiring of interrupt pin B may vary.
		 * We rely upon ioc(4) being able to figure out whether it's
		 * an onboard chip or not, and to require interrupt pin D
		 * instead of B in the former case.
		 */
		intr = -1;
		if (xb->xb_devices[device].id ==
		    PCI_ID_CODE(PCI_VENDOR_SGI, PCI_PRODUCT_SGI_IOC3)) {

			switch (pa->pa_intrpin) {
			case PCI_INTERRUPT_PIN_A:
			case PCI_INTERRUPT_PIN_B:
				break;
			case PCI_INTERRUPT_PIN_D:
				/*
				 * If this device is an onboard IOC3,
				 * interrupt pin B is wired as pin A of
				 * the first empty PCI slot...
				 */
				for (intr = 0; intr < MAX_SLOTS; intr++)
					if (SLOT_EMPTY(xb, intr))
						break;
				/* should not happen, but fallback anyway */
				if (intr >= MAX_SLOTS)
					intr = -1;
				break;
			default:
				return 1;
			}
		}
		if (intr < 0) {
			if (pa->pa_intrpin & 1)
				intr = device;
			else
				intr = device ^ 4;
		}
	}

	*ihp = XBRIDGE_INTR_HANDLE(device, intr);

	return 0;
}

const char *
xbridge_intr_string(void *cookie, pci_intr_handle_t ih)
{
	struct xbpci_softc *xb = (struct xbpci_softc *)cookie;
	int intrbit = XBRIDGE_INTR_BIT(ih);

	if (xb->xb_intrstr[intrbit][0] == '\0')
		snprintf(xb->xb_intrstr[intrbit],
		    sizeof xb->xb_intrstr[intrbit], "irq %ld", ih);
	return xb->xb_intrstr[intrbit];
}

void *
xbridge_intr_establish(void *cookie, pci_intr_handle_t ih, int level,
    int (*func)(void *), void *arg, const char *name)
{
	struct xbpci_softc *xb = (struct xbpci_softc *)cookie;
	struct xbridge_intr *xi;
	struct xbridge_intrhandler *xih;
	uint64_t int_addr;
	int device = XBRIDGE_INTR_DEVICE(ih);
	int intrbit = XBRIDGE_INTR_BIT(ih);
	int flags;
	int intrsrc;
	int new;

	flags = (level & IPL_MPSAFE) ? XIH_MPSAFE : 0;
	level &= ~IPL_MPSAFE;

	/*
	 * Allocate bookkeeping structure if this is the
	 * first time we're using this interrupt source.
	 */
	if ((xi = xb->xb_intr[intrbit]) == NULL) {
		xi = (struct xbridge_intr *)
		    malloc(sizeof(*xi), M_DEVBUF, M_NOWAIT);
		if (xi == NULL)
			return NULL;

		xi->xi_bus = xb;
		xi->xi_intrbit = intrbit;
		LIST_INIT(&xi->xi_handlers);

		if (xbow_intr_register(xb->xb_widget, level, &intrsrc) != 0) {
			free(xi, M_DEVBUF, sizeof *xi);
			return NULL;
		}

		xi->xi_intrsrc = intrsrc;
		xb->xb_intr[intrbit] = xi;
		snprintf(xb->xb_intrstr[intrbit],
		    sizeof xb->xb_intrstr[intrbit],
		    "irq %d, xbow irq %d", intrbit, intrsrc);
	} else
		intrsrc = xi->xi_intrsrc;
	
	/*
	 * Register the interrupt at the Heart or Hub level if this is the
	 * first time we're using this interrupt source.
	 */
	new = LIST_EMPTY(&xi->xi_handlers);
	if (new) {
		/*
		 * XXX The interrupt dispatcher is always registered
		 * XXX at IPL_BIO, in case the interrupt will be shared
		 * XXX between devices of different levels.
		 */
		if (xbow_intr_establish(xb->xb_pci_intr_handler, xi, intrsrc,
		    IPL_BIO | IPL_MPSAFE, NULL, NULL)) {
			printf("%s: unable to register interrupt handler\n",
			    DEVNAME(xb));
			return NULL;
		}
	}

	xih = (struct xbridge_intrhandler *)
	    malloc(sizeof(*xih), M_DEVBUF, M_NOWAIT);
	if (xih == NULL)
		return NULL;

	xih->xih_main = xi;
	xih->xih_func = func;
	xih->xih_arg = arg;
	xih->xih_flags = flags;
	xih->xih_level = level;
	xih->xih_device = device;
	evcount_attach(&xih->xih_count, name, &xi->xi_intrsrc);
	LIST_INSERT_HEAD(&xi->xi_handlers, xih, xih_nxt);

	if (new) {
		/*
		 * Note that, while PIC uses a complete XIO address,
		 * Bridge will only store the interrupt source and high
		 * bits of the address, and will reuse the widget interrupt
		 * address for the low 38 bits of the XIO address.
		 */
		if (ISSET(xb->xb_flags, XF_PIC))
			int_addr = ((uint64_t)intrsrc << 48) |
			    (xbow_intr_address & ((1UL << 48) - 1));
		else
			int_addr = ((xbow_intr_address >> 30) &
			    0x0003ff00) | intrsrc;
		xb->xb_ier |= 1L << intrbit;

		xbridge_write_reg(xb, BRIDGE_INT_ADDR(intrbit), int_addr);
		xbridge_write_reg(xb, BRIDGE_IER, xb->xb_ier);
		/*
		 * INT_MODE register controls which interrupt pins cause
		 * ``interrupt clear'' packets to be sent for high->low
		 * transition.
		 * We enable such packets to be sent in order not to have to
		 * clear interrupts ourselves.
		 */
		xbridge_write_reg(xb, BRIDGE_INT_MODE,
		    xbridge_read_reg(xb, BRIDGE_INT_MODE) | (1 << intrbit));
		xbridge_write_reg(xb, BRIDGE_INT_DEV,
		    xbridge_read_reg(xb, BRIDGE_INT_DEV) |
		    (device << (intrbit * 3)));
		(void)xbridge_read_reg(xb, WIDGET_TFLUSH);
	}

	return (void *)xih;
}

void
xbridge_intr_disestablish(void *cookie, void *vih)
{
	struct xbpci_softc *xb = cookie;
	struct xbridge_intrhandler *xih = (struct xbridge_intrhandler *)vih;
	struct xbridge_intr *xi = xih->xih_main;
	int intrbit = xi->xi_intrbit;

	evcount_detach(&xih->xih_count);
	LIST_REMOVE(xih, xih_nxt);

	if (LIST_EMPTY(&xi->xi_handlers)) {
		xb->xb_ier &= ~(1 << intrbit);
		xbridge_write_reg(xb, BRIDGE_INT_ADDR(intrbit), 0);
		xbridge_write_reg(xb, BRIDGE_IER, xb->xb_ier);
		xbridge_write_reg(xb, BRIDGE_INT_MODE,
		    xbridge_read_reg(xb, BRIDGE_INT_MODE) & ~(1 << intrbit));
		xbridge_write_reg(xb, BRIDGE_INT_DEV,
		    xbridge_read_reg(xb, BRIDGE_INT_DEV) &
		    ~(7 << (intrbit * 3)));
		(void)xbridge_read_reg(xb, WIDGET_TFLUSH);

		xbow_intr_disestablish(xi->xi_intrsrc);
		/*
		 * Note we could free xb->xb_intr[intrbit] at this point,
		 * but it's not really worth doing.
		 */
	}

	free(xih, M_DEVBUF, sizeof *xih);
}

int
xbridge_intr_line(void *cookie, pci_intr_handle_t ih)
{
	return XBRIDGE_INTR_BIT(ih);
}

int
xbridge_err_intr_handler(void *v)
{
	struct xbpci_softc *xb = (struct xbpci_softc *)v;
	uint64_t isr;

	isr = xbridge_read_reg(xb, BRIDGE_ISR) & ~BRIDGE_ISR_HWINTR_MASK;
	xbridge_err_handle(xb, isr);

	xbow_intr_clear(xb->xb_err_intrsrc);

	return 1;
}

int
xbridge_pci_intr_handler(void *v)
{
	struct xbridge_intr *xi = (struct xbridge_intr *)v;
	struct xbpci_softc *xb = xi->xi_bus;
	struct xbridge_intrhandler *xih;
	uint64_t isr;
	int rc;
#ifdef MULTIPROCESSOR
	int need_lock;
#endif

	/* XXX shouldn't happen, and assumes interrupt is not shared */
	if (LIST_EMPTY(&xi->xi_handlers)) {
		printf("%s: spurious irq %d\n", DEVNAME(xb), xi->xi_intrbit);
		return 0;
	}

	/*
	 * Flush PCI write buffers before servicing the interrupt.
	 */
	LIST_FOREACH(xih, &xi->xi_handlers, xih_nxt)
		xbridge_wbflush(xb, xih->xih_device);

	isr = xbridge_read_reg(xb, BRIDGE_ISR);
	if ((isr & ~BRIDGE_ISR_HWINTR_MASK) != 0) {
		/*
		 * This is an error interrupt triggered by a particular
		 * device.
		 */
		xbridge_err_handle(xb, isr & ~BRIDGE_ISR_HWINTR_MASK);
		if ((isr &= BRIDGE_ISR_HWINTR_MASK) == 0)
			return 1;
	}

	if ((isr & (1L << xi->xi_intrbit)) == 0) {
		/*
		 * May be a result of the lost interrupt workaround (see
		 * near the end of this function); don't complain in that
		 * case.
		 */
		rc = -1;
#ifdef DEBUG
		printf("%s: irq %d but not pending in ISR %08llx\n",
		    DEVNAME(xb), xi->xi_intrbit, isr);
#endif
	} else {
		rc = 0;
		LIST_FOREACH(xih, &xi->xi_handlers, xih_nxt) {
			splraise(xih->xih_level);
#ifdef MULTIPROCESSOR
			if (ISSET(xih->xih_flags, XIH_MPSAFE))
				need_lock = 0;
			else
				need_lock = xih->xih_flags < IPL_CLOCK;
			if (need_lock)
				__mp_lock(&kernel_lock);
#endif
			if ((*xih->xih_func)(xih->xih_arg) != 0) {
				xih->xih_count.ec_count++;
				rc = 1;
			}
#ifdef MULTIPROCESSOR
			if (need_lock)
				__mp_unlock(&kernel_lock);
#endif
			/*
			 * No need to lower spl here, as our caller will
			 * lower spl upon our return.
			 * However that splraise() is necessary so that
			 * interrupt handler code calling splx() will not
			 * cause our interrupt source to be unmasked.
			 */
		}
		/* XXX assumes interrupt is not shared */
		if (rc == 0)
			printf("%s: spurious irq %d\n",
			    DEVNAME(xb), xi->xi_intrbit);
	}

	/*
	 * There is a known BRIDGE race in which, if two interrupts
	 * on two different pins occur within 60nS of each other,
	 * further interrupts on the first pin do not cause an
	 * interrupt to be sent.
	 *
	 * The workaround against this is to check if our interrupt
	 * source is still active (i.e. another interrupt is pending),
	 * in which case we force an interrupt anyway.
	 *
	 * The XBridge even has a nice facility to do this, where we
	 * do not even have to check if our interrupt is pending.
	 */

	if (ISSET(xb->xb_flags, XF_XBRIDGE)) {
		xbridge_write_reg(xb, BRIDGE_INT_FORCE_PIN(xi->xi_intrbit), 1);
		(void)xbridge_read_reg(xb, WIDGET_TFLUSH);
	} else {
		if (xbridge_read_reg(xb, BRIDGE_ISR) & (1 << xi->xi_intrbit))
			xbow_intr_set(xi->xi_intrsrc);
	}

	return rc;
}

int
xbridge_picv1_pci_intr_handler(void *v)
{
	struct xbridge_intr *xi = (struct xbridge_intr *)v;
	struct xbpci_softc *xb = xi->xi_bus;

	/*
	 * Revision 1 of PIC is supposed to need the interrupt enable bit
	 * to be toggled to prevent loss of interrupt.
	 */
	xbridge_write_reg(xb, BRIDGE_IER, xb->xb_ier & ~(1L << xi->xi_intrbit));
	(void)xbridge_read_reg(xb, WIDGET_TFLUSH);
	xbridge_write_reg(xb, BRIDGE_IER, xb->xb_ier);
	(void)xbridge_read_reg(xb, WIDGET_TFLUSH);

	return xbridge_pci_intr_handler(v);
}

/*
 ********************* chip register access.
 */

uint64_t
bridge_read_reg(bus_space_tag_t t, bus_space_handle_t h, bus_addr_t a)
{
	return (uint64_t)widget_read_4(t, h, a);
}
void
bridge_write_reg(bus_space_tag_t t, bus_space_handle_t h, bus_addr_t a,
    uint64_t v)
{
	widget_write_4(t, h, a, (uint32_t)v);
}

uint64_t
pic_read_reg(bus_space_tag_t t, bus_space_handle_t h, bus_addr_t a)
{
	return widget_read_8(t, h, a);
}

void
pic_write_reg(bus_space_tag_t t, bus_space_handle_t h, bus_addr_t a,
    uint64_t v)
{
	widget_write_8(t, h, a, v);
}

/*
 ********************* bus_space glue.
 */

uint8_t
xbridge_read_1(bus_space_tag_t t, bus_space_handle_t h, bus_size_t o)
{
	return *(volatile uint8_t *)((h + o) ^ 3);
}

uint16_t
xbridge_read_2(bus_space_tag_t t, bus_space_handle_t h, bus_size_t o)
{
	return *(volatile uint16_t *)((h + o) ^ 2);
}

void
xbridge_write_1(bus_space_tag_t t, bus_space_handle_t h, bus_size_t o,
    uint8_t v)
{
	*(volatile uint8_t *)((h + o) ^ 3) = v;
}

void
xbridge_write_2(bus_space_tag_t t, bus_space_handle_t h, bus_size_t o,
    uint16_t v)
{
	*(volatile uint16_t *)((h + o) ^ 2) = v;
}

void
xbridge_read_raw_2(bus_space_tag_t t, bus_space_handle_t h, bus_addr_t o,
    uint8_t *buf, bus_size_t len)
{
	volatile uint16_t *addr = (volatile uint16_t *)((h + o) ^ 2);
	len >>= 1;
	while (len-- != 0) {
		*(uint16_t *)buf = letoh16(*addr);
		buf += 2;
	}
}

void
xbridge_write_raw_2(bus_space_tag_t t, bus_space_handle_t h, bus_addr_t o,
    const uint8_t *buf, bus_size_t len)
{
	volatile uint16_t *addr = (volatile uint16_t *)((h + o) ^ 2);
	len >>= 1;
	while (len-- != 0) {
		*addr = htole16(*(uint16_t *)buf);
		buf += 2;
	}
}

void
xbridge_read_raw_4(bus_space_tag_t t, bus_space_handle_t h, bus_addr_t o,
    uint8_t *buf, bus_size_t len)
{
	volatile uint32_t *addr = (volatile uint32_t *)(h + o);
	len >>= 2;
	while (len-- != 0) {
		*(uint32_t *)buf = letoh32(*addr);
		buf += 4;
	}
}

void
xbridge_write_raw_4(bus_space_tag_t t, bus_space_handle_t h, bus_addr_t o,
    const uint8_t *buf, bus_size_t len)
{
	volatile uint32_t *addr = (volatile uint32_t *)(h + o);
	len >>= 2;
	while (len-- != 0) {
		*addr = htole32(*(uint32_t *)buf);
		buf += 4;
	}
}

void
xbridge_read_raw_8(bus_space_tag_t t, bus_space_handle_t h, bus_addr_t o,
    uint8_t *buf, bus_size_t len)
{
	volatile uint64_t *addr = (volatile uint64_t *)(h + o);
	len >>= 3;
	while (len-- != 0) {
		*(uint64_t *)buf = letoh64(*addr);
		buf += 8;
	}
}

void
xbridge_write_raw_8(bus_space_tag_t t, bus_space_handle_t h, bus_addr_t o,
    const uint8_t *buf, bus_size_t len)
{
	volatile uint64_t *addr = (volatile uint64_t *)(h + o);
	len >>= 3;
	while (len-- != 0) {
		*addr = htole64(*(uint64_t *)buf);
		buf += 8;
	}
}

int
xbridge_space_map_devio(bus_space_tag_t t, bus_addr_t offs, bus_size_t size,
    int flags, bus_space_handle_t *bshp)
{
	struct xbpci_softc *xb = (struct xbpci_softc *)t->bus_private;
	bus_addr_t bpa;
#ifdef DIAGNOSTIC
	bus_addr_t start, end;
	uint d;
#endif

	if ((offs >> 24) != xb->xb_devio_skew)
		return EINVAL;	/* not a devio mapping */

	/*
	 * Figure out which devio `slot' we are using, and make sure
	 * we do not overrun it.
	 */
	bpa = offs & ((1UL << 24) - 1);
#ifdef DIAGNOSTIC
	for (d = 0; d < xb->xb_nslots; d++) {
		start = PIC_DEVIO_OFFS(xb->xb_busno, d);
		end = start + BRIDGE_DEVIO_SIZE(d);
		if (bpa >= start && bpa < end) {
			if (bpa + size > end)
				return EINVAL;
			else
				break;
		}
	}
	if (d == xb->xb_nslots)
		return EINVAL;
#endif

	/*
	 * Note we can not use our own bus_base because it might not point
	 * to our small window. Instead, use the one used by the xbridge
	 * driver itself, which _always_ points to the short window.
	 */
	*bshp = xb->xb_regt->bus_base + bpa;
	return 0;
}

int
xbridge_space_map_io(bus_space_tag_t t, bus_addr_t offs, bus_size_t size,
    int flags, bus_space_handle_t *bshp)
{
	struct xbpci_softc *xb = (struct xbpci_softc *)t->bus_private;

	/*
	 * Base address is either within the devio area, or our direct
	 * window.
	 */

	if ((offs >> 24) == xb->xb_devio_skew)
		return xbridge_space_map_devio(t, offs, size, flags, bshp);

#ifdef DIAGNOSTIC
	/* check that this does not overflow the mapping */
	if (offs < xb->xb_iostart || offs + size - 1 > xb->xb_ioend)
		return EINVAL;
#endif

	*bshp = (t->bus_base + offs);
	return 0;
}

int
xbridge_space_map_mem(bus_space_tag_t t, bus_addr_t offs, bus_size_t size,
    int flags, bus_space_handle_t *bshp)
{
#if defined(TGT_ORIGIN) || defined(DIAGNOSTIC)
	struct xbpci_softc *xb = (struct xbpci_softc *)t->bus_private;
#endif

	/*
	 * Base address is either within the devio area, or our direct
	 * window.  Except on Octane where we never setup devio memory
	 * mappings, because the large mapping is always available.
	 */

#ifdef TGT_ORIGIN
	if (sys_config.system_type != SGI_OCTANE &&
	    (offs >> 24) == xb->xb_devio_skew)
		return xbridge_space_map_devio(t, offs, size, flags, bshp);
#endif

#ifdef DIAGNOSTIC
	/* check that this does not overflow the mapping */
	if (offs < xb->xb_memstart || offs + size - 1 > xb->xb_memend)
		return EINVAL;
#endif

	*bshp = (t->bus_base + offs);
	return 0;
}

int
xbridge_space_region_devio(bus_space_tag_t t , bus_space_handle_t bsh,
    bus_size_t offset, bus_size_t size, bus_space_handle_t *nbshp)
{
#ifdef DIAGNOSTIC
	struct xbpci_softc *xb = (struct xbpci_softc *)t->bus_private;
	bus_addr_t bpa;
	bus_addr_t start, end;
	uint d;
#endif

#ifdef DIAGNOSTIC
	/*
	 * Note we can not use our own bus_base because it might not point
	 * to our small window. Instead, use the one used by the xbridge
	 * driver itself, which _always_ points to the short window.
	 */
	bpa = (bus_addr_t)bsh - xb->xb_regt->bus_base;

	if ((bpa >> 24) != 0)
		return EINVAL;	/* not a devio mapping */

	/*
	 * Figure out which devio `slot' we are using, and make sure
	 * we do not overrun it.
	 */
	for (d = 0; d < xb->xb_nslots; d++) {
		start = PIC_DEVIO_OFFS(xb->xb_busno, d);
		end = start + BRIDGE_DEVIO_SIZE(d);
		if (bpa >= start && bpa < end) {
			if (bpa + offset + size > end)
				return EINVAL;
			else
				break;
		}
	}
	if (d == xb->xb_nslots)
		return EINVAL;
#endif

	*nbshp = bsh + offset;
	return 0;
}

int
xbridge_space_region_io(bus_space_tag_t t, bus_space_handle_t bsh,
    bus_size_t offset, bus_size_t size, bus_space_handle_t *nbshp)
{
	struct xbpci_softc *xb = (struct xbpci_softc *)t->bus_private;
	bus_addr_t bpa;

	/*
	 * Note we can not use our own bus_base because it might not point
	 * to our small window. Instead, use the one used by the xbridge
	 * driver itself, which _always_ points to the short window.
	 */
	bpa = (bus_addr_t)bsh - xb->xb_regt->bus_base;

	if ((bpa >> 24) == 0)
		return xbridge_space_region_devio(t, bsh, offset, size, nbshp);

#ifdef DIAGNOSTIC
	/* check that this does not overflow the mapping */
	bpa = (bus_addr_t)bsh - t->bus_base;
	if (bpa + offset + size - 1 > xb->xb_ioend)
		return EINVAL;
#endif

	*nbshp = bsh + offset;
	return 0;
}

int
xbridge_space_region_mem(bus_space_tag_t t, bus_space_handle_t bsh,
    bus_size_t offset, bus_size_t size, bus_space_handle_t *nbshp)
{
#if defined(TGT_ORIGIN) || defined(DIAGNOSTIC)
	struct xbpci_softc *xb = (struct xbpci_softc *)t->bus_private;
	bus_addr_t bpa;
#endif

	/*
	 * Base address is either within the devio area, or our direct
	 * window.  Except on Octane where we never setup devio memory
	 * mappings, because the large mapping is always available.
	 */

#ifdef TGT_ORIGIN
	if (sys_config.system_type != SGI_OCTANE) {
		/*
		 * Note we can not use our own bus_base because it might not
		 * point to our small window. Instead, use the one used by
		 * the xbridge driver itself, which _always_ points to the
		 * short window.
		 */
		bpa = (bus_addr_t)bsh - xb->xb_regt->bus_base;

		if ((bpa >> 24) == 0)
			return xbridge_space_region_devio(t, bsh, offset, size,
			    nbshp);
	}
#endif

#ifdef DIAGNOSTIC
	/* check that this does not overflow the mapping */
	bpa = (bus_addr_t)bsh - t->bus_base;
	if (bpa + offset + size - 1 > xb->xb_memend)
		return EINVAL;
#endif

	*nbshp = bsh + offset;
	return 0;
}

void
xbridge_space_barrier(bus_space_tag_t t, bus_space_handle_t h, bus_size_t offs,
    bus_size_t len, int flags)
{
	struct xbpci_softc *xb = (struct xbpci_softc *)t->bus_private;
	bus_addr_t bpa, start, end;
	uint d, devmin, devmax;

	mips_sync();

	if (flags & BUS_SPACE_BARRIER_WRITE) {
		/*
		 * Try to figure out which device we are working for, and
		 * flush its PCI write buffer.
		 * This is ugly; we really need to be able to provide a
		 * different bus_space_tag_t to each slot, to be able
		 * to tell them apart.
		 */
		if (t->_space_map == xbridge_space_map_devio) {
			bpa = (bus_addr_t)h - xb->xb_regt->bus_base;
			for (d = 0; d < xb->xb_nslots; d++) {
				start = PIC_DEVIO_OFFS(xb->xb_busno, d);
				end = start + BRIDGE_DEVIO_SIZE(d);
				if (bpa >= start && bpa < end)
					break;
			}
			devmin = d;
			devmax = d + 1;
			/* should not happen */
			if (d == xb->xb_nslots) {
				devmin = 0;
				devmax = xb->xb_nslots;
			}
		} else {
			/* nothing better came up my sleeve... */
			devmin = 0;
			devmax = xb->xb_nslots;
		}
		for (d = devmin; d < devmax; d++)
			xbridge_wbflush(xb, d);
		(void)xbridge_read_reg(xb, WIDGET_TFLUSH);
	}
}

/*
 ********************* bus_dma helpers
 */

/*
 * Since the common bus_dma code makes sure DMA-able memory is allocated
 * within the dma_constraint limits, which are set to the direct DMA
 * window, we do not need to check for addresses outside this range here.
 */

bus_addr_t
xbridge_pa_to_device(paddr_t pa, int flags)
{
	KASSERTMSG(pa - dma_constraint.ucr_low < BRIDGE_DMA_DIRECT_LENGTH,
	    "pa 0x%lx not in dma constraint range! (0x%lx-0x%lx)",
	    pa, dma_constraint.ucr_low, dma_constraint.ucr_high);
	return (pa - dma_constraint.ucr_low) + BRIDGE_DMA_DIRECT_BASE;
}

/*
 ********************* Bridge configuration code.
 */

const char *
xbridge_setup(struct xbpci_softc *xb)
{
	bus_addr_t ba;
	paddr_t pa;
	uint64_t status, ctrl, int_addr, dirmap;
	int mode, speed, dev;

	status = xbridge_read_reg(xb, WIDGET_STATUS);
	ctrl = xbridge_read_reg(xb, WIDGET_CONTROL);

	/*
	 * Print bus mode and speed.
	 */

	mode = ISSET(xb->xb_flags, XF_PIC) &&
	    ISSET(status, PIC_WIDGET_STATUS_PCIX_MODE);
	if (mode != 0) {
		SET(xb->xb_flags, XF_PCIX);
		speed = (status & PIC_WIDGET_STATUS_PCIX_SPEED_MASK) >>
		    PIC_WIDGET_STATUS_PCIX_SPEED_SHIFT;
	} else if (ISSET(xb->xb_flags, XF_XBRIDGE)) {
		speed = (ctrl & BRIDGE_WIDGET_CONTROL_SPEED_MASK) >>
		    BRIDGE_WIDGET_CONTROL_SPEED_SHIFT;
	} else
		speed = 0;
	/* 0 = 33 MHz, 1 = 66 MHz, 2 = 100 MHz, 3 = 133 MHz */
	speed = (speed & 2 ? 100 : 33) + (speed & 1 ? 33 : 0);
	printf("%d MHz %s bus", speed, mode ? "PCIX" : "PCI");

	/*
	 * Gather device identification for all slots.
	 * We need this to be able to allocate RRBs correctly, and also
	 * to be able to check quickly whether a given device is an IOC3.
	 */

	for (dev = 0; dev < xb->xb_nslots; dev++) {
		if (ISSET(xb->xb_flags, XF_PIC))
			pa = xb->xb_regh + BRIDGE_PCI_CFG_SPACE +
			    ((dev + 1) << 12) + PCI_ID_REG;
		else
			pa = xb->xb_regh + BRIDGE_PCI_CFG_SPACE +
			    (dev << 12) + PCI_ID_REG;
		if (guarded_read_4(pa, &xb->xb_devices[dev].id) != 0)
			xb->xb_devices[dev].id = PCI_ID_EMPTY;
	}

	/*
	 * Configure the direct DMA window to access the 2GB memory
	 * window selected as our DMA memory range.
	 */
	dirmap = (dma_constraint.ucr_low >> BRIDGE_DIRMAP_BASE_SHIFT) &
	     BRIDGE_DIRMAP_BASE_MASK;
	switch (sys_config.system_type) {
	default:
#ifdef TGT_ORIGIN
		dirmap |= kl_hub_widget[
		    IP27_PHYS_TO_NODE(dma_constraint.ucr_low)] <<
		      BRIDGE_DIRMAP_WIDGET_SHIFT;
		break;
#endif
#ifdef TGT_OCTANE
	case SGI_OCTANE:
		dirmap |= IP30_HEART_WIDGET << BRIDGE_DIRMAP_WIDGET_SHIFT;
		break;
#endif
	}
	xbridge_write_reg(xb, BRIDGE_DIR_MAP, dirmap);

	/*
	 * Allocate RRB for the existing devices.
	 */

	xbridge_rrb_setup(xb, 0);
	xbridge_rrb_setup(xb, 1);

	/*
	 * Enable(?) snooping and disable relaxed order on PIC.
	 */

	if (ISSET(xb->xb_flags, XF_PIC)) {
		ctrl &= ~PIC_WIDGET_CONTROL_NO_SNOOP;
		ctrl &= ~PIC_WIDGET_CONTROL_RELAX_ORDER;
	}

	/*
	 * Disable byteswapping on PIO accesses through the large window
	 * (we handle this at the bus_space level). It should not have
	 * been enabled by ARCS, since IOC serial console relies on this,
	 * but better enforce this anyway.
	 */

	ctrl &= ~BRIDGE_WIDGET_CONTROL_IO_SWAP;
	ctrl &= ~BRIDGE_WIDGET_CONTROL_MEM_SWAP;
	xbridge_write_reg(xb, WIDGET_CONTROL, ctrl);
	(void)xbridge_read_reg(xb, WIDGET_TFLUSH);

	/*
	 * The PROM will only configure the onboard devices. Set up
	 * any other device we might encounter.
	 */

	xbridge_resource_setup(xb);

	/*
	 * Older Bridge chips needs to run with pci timeouts
	 * disabled.
	 */

	if (!ISSET(xb->xb_flags, XF_XBRIDGE) && xb->xb_revision < 4) {
		xbridge_write_reg(xb, BRIDGE_BUS_TIMEOUT,
		    xbridge_read_reg(xb, BRIDGE_BUS_TIMEOUT) &
		    ~BRIDGE_BUS_PCI_RETRY_CNT_MASK);
	}

	/*
	 * AT&T/Lucent USS-302 and USS-312 USB controllers require
	 * a larger PCI retry hold interval for proper operation.
	 */

	for (dev = 0; dev < xb->xb_nslots; dev++) {
		if (xb->xb_devices[dev].id ==
		    PCI_ID_CODE(PCI_VENDOR_LUCENT, PCI_PRODUCT_LUCENT_USBHC) ||
		    xb->xb_devices[dev].id ==
		    PCI_ID_CODE(PCI_VENDOR_LUCENT, PCI_PRODUCT_LUCENT_USBHC2)) {
			ctrl = xbridge_read_reg(xb, BRIDGE_BUS_TIMEOUT);
			ctrl &= ~BRIDGE_BUS_PCI_RETRY_HOLD_MASK;
			ctrl |= (4 << BRIDGE_BUS_PCI_RETRY_HOLD_SHIFT);
			xbridge_write_reg(xb, BRIDGE_BUS_TIMEOUT, ctrl);

			break;
		}
	}

	/*
	 * Clear the write request memory in PIC, to avoid risking
	 * spurious parity errors if it is not clean.
	 */
	if (ISSET(xb->xb_flags, XF_PIC)) {
		for (ba = PIC_WR_REQ_LOWER(0);
		    ba != PIC_WR_REQ_LOWER(PIC_WR_REQ_ENTRIES); ba += 8)
			xbridge_write_reg(xb, ba, 0ULL);
		for (ba = PIC_WR_REQ_UPPER(0);
		    ba != PIC_WR_REQ_UPPER(PIC_WR_REQ_ENTRIES); ba += 8)
			xbridge_write_reg(xb, ba, 0ULL);
		for (ba = PIC_WR_REQ_PARITY(0);
		    ba != PIC_WR_REQ_PARITY(PIC_WR_REQ_ENTRIES); ba += 8)
			xbridge_write_reg(xb, ba, 0ULL);
	}

	/*
	 * Setup interrupt handling.
	 *
	 * Note that, on PIC, the `lower address' register is a 64 bit
	 * register and thus need to be initialized with the whole 64 bit
	 * address; the `upper address' register is hardwired to zero and
	 * ignores writes, so we can use the same logic on Bridge and PIC.
	 *
	 * Also, on Octane, we need to keep otherwise unused interrupt source
	 * #6 enabled on the obio widget, as it controls routing of the
	 * power button interrupt (and to make things more complicated than
	 * necessary, this pin is wired to a particular Heart interrupt
	 * register bit, so interrupts on this pin will never be seen at the
	 * Bridge level).
	 */

#ifdef TGT_OCTANE
	if (sys_config.system_type == SGI_OCTANE &&
	    xb->xb_widget == IP30_BRIDGE_WIDGET)
		xb->xb_ier = 1L << 6;
	else
#endif
		xb->xb_ier = 0;
	xbridge_write_reg(xb, BRIDGE_IER, 0);
	xbridge_write_reg(xb, BRIDGE_INT_MODE, 0);
	xbridge_write_reg(xb, BRIDGE_INT_DEV, 0);
	int_addr = xbow_intr_address & ((1UL << 48) - 1);
	switch (sys_config.system_type) {
	default:
#ifdef TGT_ORIGIN
		int_addr |= (uint64_t)kl_hub_widget[masternasid] << 48;
		break;
#endif
#ifdef TGT_OCTANE
	case SGI_OCTANE:
		int_addr |= (uint64_t)IP30_HEART_WIDGET << 48;
		break;
#endif
	}
	xbridge_write_reg(xb, WIDGET_INTDEST_ADDR_LOWER, int_addr);
	xbridge_write_reg(xb, WIDGET_INTDEST_ADDR_UPPER, int_addr >> 32);

	(void)xbridge_read_reg(xb, WIDGET_TFLUSH);

	/*
	 * Register an error interrupt handler.
	 */

	if (xbow_intr_register(xb->xb_widget, IPL_HIGH,
	    &xb->xb_err_intrsrc) != 0)
		return "can't allocate error interrupt source";
	if (xbow_intr_establish(xbridge_err_intr_handler, xb,
	    xb->xb_err_intrsrc, IPL_HIGH, DEVNAME(xb), NULL))
		return "unable to register error interrupt handler";

	xbridge_err_clear(xb, 0);
	xbridge_write_reg(xb, BRIDGE_INT_HOST_ERR, xb->xb_err_intrsrc);

	/*
	 * Enable as many error interrupt sources as possible; older
	 * Bridge chips need to have a few of them kept masked to
	 * avoid hitting hardware issues.
	 */
	xb->xb_ier |= (ISSET(xb->xb_flags, XF_PIC) ?
	    PIC_ISR_ERRMASK : BRIDGE_ISR_ERRMASK) &
	      ~(BRIDGE_ISR_MULTIPLE_ERR | BRIDGE_ISR_SSRAM_PERR |
		BRIDGE_ISR_GIO_BENABLE_ERR);
	if (xb->xb_busno != 0) {
		/* xtalk errors will only show up on bus #0 */
		xb->xb_ier &= ~(BRIDGE_ISR_UNSUPPORTED_XOP |
		    BRIDGE_ISR_LLP_REC_SNERR | BRIDGE_ISR_LLP_REC_CBERR |
		    BRIDGE_ISR_LLP_RCTY | BRIDGE_ISR_LLP_TX_RETRY |
		    BRIDGE_ISR_LLP_TCTY);
	}
	if (!ISSET(xb->xb_flags, XF_XBRIDGE)) {
		if (xb->xb_revision < 2)
			xb->xb_ier &= ~(BRIDGE_ISR_UNEXPECTED_RESP |
			    BRIDGE_ISR_PCI_MASTER_TMO |
			    BRIDGE_ISR_RESP_XTALK_ERR |
			    BRIDGE_ISR_LLP_TX_RETRY | BRIDGE_ISR_XREAD_REQ_TMO);
		if (xb->xb_revision < 3)
			xb->xb_ier &= ~BRIDGE_ISR_BAD_XRESP_PACKET;
	}

	xbridge_write_reg(xb, BRIDGE_IER, xb->xb_ier);

	(void)xbridge_read_reg(xb, WIDGET_TFLUSH);

	return NULL;
}

/*
 * Handle PCI errors.
 */
void
xbridge_err_handle(struct xbpci_softc *xb, uint64_t isr)
{
	uint64_t pci_err, wid_err, resp_err;

	wid_err = xbridge_read_reg(xb, WIDGET_ERR_ADDR_LOWER);
	if (!ISSET(xb->xb_flags, XF_PIC))
		wid_err |= xbridge_read_reg(xb, WIDGET_ERR_ADDR_UPPER) << 32;
	pci_err = xbridge_read_reg(xb, BRIDGE_PCI_ERR_LOWER);
	if (!ISSET(xb->xb_flags, XF_PIC))
		pci_err |= xbridge_read_reg(xb, BRIDGE_PCI_ERR_UPPER) << 32;
	resp_err = xbridge_read_reg(xb, BRIDGE_WIDGET_RESP_LOWER);
	if (!ISSET(xb->xb_flags, XF_PIC))
		resp_err |=
		    xbridge_read_reg(xb, BRIDGE_WIDGET_RESP_UPPER) << 32;

	/* XXX give more detailed information */
	printf("%s: error interrupt, isr %llx wid %llx pci %llx resp %llx\n",
	    DEVNAME(xb), isr, wid_err, pci_err, resp_err);

	xbridge_err_clear(xb, isr);
}

/*
 * Clear any error condition.
 */
void
xbridge_err_clear(struct xbpci_softc *xb, uint64_t isr)
{
	if (ISSET(xb->xb_flags, XF_PIC)) {
		if (isr == 0)
			isr = xbridge_read_reg(xb, BRIDGE_ISR) &
			    ~BRIDGE_ISR_HWINTR_MASK;
		xbridge_write_reg(xb, BRIDGE_ICR, isr);
	} else
		xbridge_write_reg(xb, BRIDGE_ICR, BRIDGE_ICR_ALL);

	(void)xbridge_read_reg(xb, WIDGET_TFLUSH);
}

/*
 * Build a not-so-pessimistic RRB allocation register value.
 */
void
xbridge_rrb_setup(struct xbpci_softc *xb, int odd)
{
	uint rrb[MAX_SLOTS / 2];	/* tentative rrb assignment */
	uint total;			/* rrb count */
	uint32_t proto;			/* proto rrb value */
	int dev, i, j;

	/*
	 * First, try to allocate as many RRBs per device as possible.
	 */

	total = 0;
	for (i = 0; i < nitems(rrb); i++) {
		dev = (i << 1) + !!odd;
		if (dev >= xb->xb_nslots || SLOT_EMPTY(xb, dev))
			rrb[i] = 0;
		else {
			rrb[i] = 4;	/* optimistic value */
			total += 4;
		}
	}

	/*
	 * Then, try to reduce greed until we do not claim more than
	 * the 8 RRBs we can afford.
	 */

	if (total > 8) {
		/*
		 * All devices should be able to live with 3 RRBs, so
		 * reduce their allocation from 4 to 3.
		 */
		for (i = 0; i < nitems(rrb); i++) {
			if (rrb[i] == 4) {
				rrb[i]--;
				if (--total == 8)
					break;
			}
		}
	}

	if (total > 8) {
		/*
		 * There are too many devices for 3 RRBs per device to
		 * be possible. Attempt to reduce from 3 to 2, except
		 * for isp(4) devices.
		 */
		for (i = 0; i < nitems(rrb); i++) {
			if (rrb[i] == 3) {
				dev = (i << 1) + !!odd;
				if (PCI_VENDOR(xb->xb_devices[dev].id) !=
				    PCI_VENDOR_QLOGIC) {
					rrb[i]--;
					if (--total == 8)
						break;
				}
			}
		}
	}

	if (total > 8) {
		/*
		 * Too bad, we need to shrink the RRB allocation for
		 * isp devices too. We'll try to favour the lowest
		 * slots, though, hence the reversed loop order.
		 */
		for (i = nitems(rrb) - 1; i >= 0; i--) {
			if (rrb[i] == 3) {
				rrb[i]--;
				if (--total == 8)
					break;
			}
		}
	}

	/*
	 * Now build the RRB register value proper.
	 */

	proto = 0;
	for (i = 0; i < nitems(rrb); i++) {
		for (j = 0; j < rrb[i]; j++)
			proto = (proto << RRB_SHIFT) | (RRB_VALID | i);
	}

	xbridge_write_reg(xb, odd ? BRIDGE_RRB_ODD : BRIDGE_RRB_EVEN, proto);
}

/*
 * Configure PCI resources for all devices.
 */
void
xbridge_resource_setup(struct xbpci_softc *xb)
{
	pci_chipset_tag_t pc = &xb->xb_pc;
	int dev, nfuncs;
	pcitag_t tag;
	pcireg_t id, bhlcr;
	uint32_t devio;
	int need_setup;
	uint secondary, nppb, npccbb, ppbstride;
	const struct pci_quirkdata *qd;

	/*
	 * On Octane, we will want to map everything through the large
	 * windows, whenever possible.
	 *
	 * Set up these mappings now.
	 */

	if (sys_config.system_type == SGI_OCTANE) {
		xb->xb_ioex = xbridge_mapping_setup(xb, 1);
		xb->xb_memex = xbridge_mapping_setup(xb, 0);
	}

	/*
	 * Configure all regular PCI devices.
	 */

#ifdef DEBUG
	for (dev = 0; dev < xb->xb_nslots; dev++)
		printf("device %d: devio %08llx\n",
		    dev, xbridge_read_reg(xb, BRIDGE_DEVICE(dev)));
#endif
	nppb = npccbb = 0;
	for (dev = 0; dev < xb->xb_nslots; dev++) {
		if (SLOT_EMPTY(xb, dev))
			continue;

		/*
		 * Count ppb and pccbb devices, we will need their number later.
		 */

		tag = pci_make_tag(pc, 0, dev, 0);
		bhlcr = pci_conf_read(pc, tag, PCI_BHLC_REG);
		if (PCI_HDRTYPE_TYPE(bhlcr) == 1)
			nppb++;
		if (PCI_HDRTYPE_TYPE(bhlcr) == 2)
			npccbb++;

		/*
		 * We want to avoid changing mapping configuration for
		 * devices which have been setup by ARCS.
		 *
		 * On Octane, the whole on-board I/O widget has been
		 * set up, with direct mappings into widget space.
		 *
		 * On Origin, since direct mappings are expensive,
		 * everything set up by ARCS has a valid devio
		 * mapping; those can be identified as they sport the
		 * widget number in the high address bits.
		 *
		 * We will only fix the device-global devio flags on
		 * devices which have been set up by ARCS.  Otherwise,
		 * we'll need to perform proper PCI resource allocation.
		 */

		id = xb->xb_devices[dev].id;
		devio = xbridge_read_reg(xb, BRIDGE_DEVICE(dev));
		if (id != PCI_ID_CODE(PCI_VENDOR_SGI, PCI_PRODUCT_SGI_IOC3) &&
		    id != PCI_ID_CODE(PCI_VENDOR_SGI, PCI_PRODUCT_SGI_IOC4))
			need_setup = 1;
		else
			need_setup = xb->xb_busno != 0 || xb->xb_devio_skew !=
			    ((devio & BRIDGE_DEVICE_BASE_MASK) >>
			     (24 - BRIDGE_DEVICE_BASE_SHIFT));

		/*
		 * Enable byte swapping for DMA, except on IOC3, IOC4 and
		 * RAD1 devices.
		 */
		if (id == PCI_ID_CODE(PCI_VENDOR_SGI, PCI_PRODUCT_SGI_IOC3) ||
		    id == PCI_ID_CODE(PCI_VENDOR_SGI, PCI_PRODUCT_SGI_IOC4) ||
		    id == PCI_ID_CODE(PCI_VENDOR_SGI, PCI_PRODUCT_SGI_RAD1))
			devio &=
			    ~(BRIDGE_DEVICE_SWAP_PMU | BRIDGE_DEVICE_SWAP_DIR);
		else
			devio |=
			    BRIDGE_DEVICE_SWAP_PMU | BRIDGE_DEVICE_SWAP_DIR;

		/*
		 * Disable write gathering.
		 */
		devio &=
		    ~(BRIDGE_DEVICE_WGATHER_PMU | BRIDGE_DEVICE_WGATHER_DIR);

		/*
		 * Disable prefetching - on-board isp(4) controllers on
		 * Octane are set up with this, but this confuses the
		 * driver.
		 */
		devio &= ~BRIDGE_DEVICE_PREFETCH;

		/*
		 * Force cache coherency.
		 */
		devio |= BRIDGE_DEVICE_COHERENT;

		if (need_setup == 0) {
			xbridge_set_devio(xb, dev, devio, 1);
			continue;
		}

		/*
		 * Clear any residual devio mapping.
		 */
		devio &= ~BRIDGE_DEVICE_BASE_MASK;
		devio &= ~BRIDGE_DEVICE_IO_MEM;
		xbridge_set_devio(xb, dev, devio, 0);

		/*
		 * We now need to perform the resource allocation for this
		 * device, which has not been setup by ARCS.
		 */

		qd = pci_lookup_quirkdata(PCI_VENDOR(id), PCI_PRODUCT(id));
		if (PCI_HDRTYPE_MULTIFN(bhlcr) ||
		    (qd != NULL && (qd->quirks & PCI_QUIRK_MULTIFUNCTION) != 0))
			nfuncs = 8;
		else
			nfuncs = 1;

		xbridge_device_setup(xb, dev, nfuncs, devio);
	}

	/*
	 * Configure PCI-PCI and PCI-CardBus bridges, if any.
	 *
	 * We do this after all the other PCI devices have been configured
	 * in order to favour them during resource allocation.
	 */

	if (npccbb != 0) {
		/*
		 * If there are PCI-CardBus bridges, we really want to be
		 * able to have large resource spaces...
		 */
		if (xb->xb_ioex == NULL)
			xb->xb_ioex = xbridge_mapping_setup(xb, 1);
		if (xb->xb_memex == NULL)
			xb->xb_memex = xbridge_mapping_setup(xb, 0);
	}

	secondary = 1;
	ppbstride = nppb == 0 ? 0 : (255 - npccbb) / nppb;
	for (dev = 0; dev < xb->xb_nslots; dev++) {
		if (SLOT_EMPTY(xb, dev))
			continue;

		tag = pci_make_tag(pc, 0, dev, 0);
		bhlcr = pci_conf_read(pc, tag, PCI_BHLC_REG);

		switch (PCI_HDRTYPE_TYPE(bhlcr)) {
		case 1:	/* PCI-PCI bridge */
			ppb_initialize(pc, tag, 0, secondary,
			    secondary + ppbstride - 1);
			secondary += ppbstride;
			break;
		case 2:	/* PCI-CardBus bridge */
			/*
			 * We do not expect cardbus devices to sport
			 * PCI-PCI bridges themselves, so only one
			 * PCI bus will do.
			 */
			pccbb_initialize(pc, tag, 0, secondary, secondary);
			secondary++;
			break;
		}
	}

	if (xb->xb_ioex != NULL) {
		extent_destroy(xb->xb_ioex);
		xb->xb_ioex = NULL;
	}
	if (xb->xb_memex != NULL) {
		extent_destroy(xb->xb_memex);
		xb->xb_memex = NULL;
	}
}

/*
 * Make the Octane flash area unavailable in the PCI space extents, so
 * that we do not try to map devices in its area.
 */
int
xbridge_extent_chomp(struct xbpci_softc *xb, struct extent *ex)
{
#ifdef TGT_OCTANE
	/*
	 * On Octane, the boot PROM is part of the onboard IOC3
	 * device, and is accessible through the PCI memory space
	 * (and maybe through the PCI I/O space as well).
	 *
	 * To avoid undebuggable surprises, make sure we never use
	 * this space.
	 */
	if (sys_config.system_type == SGI_OCTANE &&
	    xb->xb_widget == IP30_BRIDGE_WIDGET) {
		u_long fmin, fmax;

		/*
		 * This relies upon the knowledge that both flash bases
		 * are contiguous, to perform only one extent operation.
		 * I don't think we need to be pedantic to the point of
		 * doing this in two steps, really -- miod
		 */
		fmin = max(IP30_FLASH_BASE, ex->ex_start);
		fmax = min(IP30_FLASH_ALT + IP30_FLASH_SIZE - 1, ex->ex_end);
		if (fmax >= fmin)
			return extent_alloc_region(ex, fmin, fmax + 1 - fmin,
			    EX_NOWAIT | EX_MALLOCOK);
	}
#endif

	return 0;
}

/*
 * Build resource extents for the MI PCI code to play with.
 * These extents cover the configured devio areas, and the large resource
 * views, if applicable.
 */
void
xbridge_extent_setup(struct xbpci_softc *xb)
{
	int dev;
	int errors;
	bus_addr_t start, end;
	uint32_t devio;

	snprintf(xb->xb_ioexname, sizeof(xb->xb_ioexname), "%s_io",
	    DEVNAME(xb));
	xb->xb_ioex = extent_create(xb->xb_ioexname, 0, 0xffffffff,
	    M_DEVBUF, NULL, 0, EX_NOWAIT | EX_FILLED);

	if (xb->xb_ioex != NULL) {
		errors = 0;
		/* make all configured devio ranges available... */
		for (dev = 0; dev < xb->xb_nslots; dev++) {
			devio = xb->xb_devices[dev].devio;
			if (devio == 0 || ISSET(devio, BRIDGE_DEVICE_IO_MEM))
				continue;
			start = (devio & BRIDGE_DEVICE_BASE_MASK) <<
			    BRIDGE_DEVICE_BASE_SHIFT;
			if (start == 0)
				continue;
			if (extent_free(xb->xb_ioex, start,
			    BRIDGE_DEVIO_SIZE(dev), EX_NOWAIT) != 0) {
				errors++;
				break;
			}
		}
		/* ...as well as the large views, if any */
		if (xb->xb_ioend != 0) {
			start = xb->xb_iostart;
			if (start == 0)
				start = 1;
			end = xb->xb_devio_skew << 24;
			if (start < end)
				if (extent_free(xb->xb_ioex, start,
				    end, EX_NOWAIT) != 0)
					errors++;
			
			start = (xb->xb_devio_skew + 1) << 24;
			if (start < xb->xb_iostart)
				start = xb->xb_iostart;
			if (extent_free(xb->xb_ioex, start,
			    xb->xb_ioend + 1 - start, EX_NOWAIT) != 0)
				errors++;
		}

		if (xbridge_extent_chomp(xb, xb->xb_ioex) != 0)
			errors++;

		if (errors != 0) {
			extent_destroy(xb->xb_ioex);
			xb->xb_ioex = NULL;
		}
	}

	snprintf(xb->xb_memexname, sizeof(xb->xb_memexname), "%s_mem",
	    DEVNAME(xb));
	xb->xb_memex = extent_create(xb->xb_memexname, 0, 0xffffffff,
	    M_DEVBUF, NULL, 0, EX_NOWAIT | EX_FILLED);

	if (xb->xb_memex != NULL) {
		errors = 0;
		/* make all configured devio ranges available... */
		for (dev = 0; dev < xb->xb_nslots; dev++) {
			devio = xb->xb_devices[dev].devio;
			if (devio == 0 || !ISSET(devio, BRIDGE_DEVICE_IO_MEM))
				continue;
			start = (devio & BRIDGE_DEVICE_BASE_MASK) <<
			    BRIDGE_DEVICE_BASE_SHIFT;
			if (start == 0)
				continue;
			if (extent_free(xb->xb_memex, start,
			    BRIDGE_DEVIO_SIZE(dev), EX_NOWAIT) != 0) {
				errors++;
				break;
			}
		}
		/* ...as well as the large views, if any */
		if (xb->xb_memend != 0) {
			start = xb->xb_memstart;
			if (start == 0)
				start = 1;
			end = xb->xb_devio_skew << 24;
			if (start < end)
				if (extent_free(xb->xb_memex, start,
				    end, EX_NOWAIT) != 0)
					errors++;

			start = (xb->xb_devio_skew + 1) << 24;
			if (start < xb->xb_memstart)
				start = xb->xb_memstart;
			if (extent_free(xb->xb_memex, start,
			    xb->xb_memend + 1 - start, EX_NOWAIT) != 0)
				errors++;
		}

		if (xbridge_extent_chomp(xb, xb->xb_memex) != 0)
			errors++;

		if (errors != 0) {
			extent_destroy(xb->xb_memex);
			xb->xb_memex = NULL;
		}
	}
}

struct extent *
xbridge_mapping_setup(struct xbpci_softc *xb, int io)
{
	bus_addr_t membase, offs;
	bus_size_t len;
	paddr_t base;
	u_long start, end;
	struct extent *ex = NULL;

	if (io) {
		/*
		 * I/O mappings are available in the widget at offset
		 * BRIDGE_PCI_IO_SPACE_BASE onwards, but weren't working
		 * correctly until Bridge revision 4 (apparently, what
		 * didn't work was the byteswap logic).
		 *
		 * Also, this direct I/O space is not supported on PIC
		 * widgets.
		 */

		if (!ISSET(xb->xb_flags, XF_NO_DIRECT_IO)) {
			offs = BRIDGE_PCI_IO_SPACE_BASE;
			len = BRIDGE_PCI_IO_SPACE_LENGTH;
			base = xbow_widget_map_space(xb->xb_bow,
			    xb->xb_widget, &offs, &len);
		} else
			base = 0;

		if (base != 0) {
			if (offs + len > BRIDGE_PCI_IO_SPACE_BASE +
			    BRIDGE_PCI_IO_SPACE_LENGTH)
				len = BRIDGE_PCI_IO_SPACE_BASE +
				    BRIDGE_PCI_IO_SPACE_LENGTH - offs;

#ifdef DEBUG
			printf("direct io %#lx-%#lx base %#lx\n",
			    offs, offs + len - 1, base);
#endif
			offs -= BRIDGE_PCI_IO_SPACE_BASE;

			ex = extent_create("xbridge_direct_io",
			    offs == 0 ? 1 : offs, offs + len - 1,
			    M_DEVBUF, NULL, 0, EX_NOWAIT);

			/*
			 * Note that we do not need to invoke
			 * xbridge_extent_chomp() here since we will
			 * reserve the whole devio area.
			 */

			if (ex != NULL) {
				xb->xb_io_bus_space->bus_base = base - offs;
				xb->xb_io_bus_space->_space_map =
				    xbridge_space_map_io;
				xb->xb_io_bus_space->_space_subregion =
				    xbridge_space_region_io;

				xb->xb_io_bus_space_sw->bus_base = base - offs;
				xb->xb_io_bus_space_sw->_space_map =
				    xbridge_space_map_io;
				xb->xb_io_bus_space_sw->_space_subregion =
				    xbridge_space_region_io;

				xb->xb_iostart = offs;
				xb->xb_ioend = offs + len - 1;
			}
		}
	} else {
		/*
		 * Memory mappings are available in the widget at offset
		 * BRIDGE_PCI#_MEM_SPACE_BASE onwards.
		 */

		membase = xb->xb_busno == 0 ? BRIDGE_PCI0_MEM_SPACE_BASE :
		    BRIDGE_PCI1_MEM_SPACE_BASE;
		offs = membase;
		len = BRIDGE_PCI_MEM_SPACE_LENGTH;
		base = xbow_widget_map_space(xb->xb_bow,
		    xb->xb_widget, &offs, &len);

		if (base != 0) {
			/*
			 * Only the low 30 bits of memory BAR are honoured
			 * by the hardware, thus restricting memory mappings
			 * to 1GB.
			 */
			if (offs + len > membase + BRIDGE_PCI_MEM_SPACE_LENGTH)
				len = membase + BRIDGE_PCI_MEM_SPACE_LENGTH -
				    offs;

#ifdef DEBUG
			printf("direct mem %#lx-%#lx base %#lx\n",
			    offs, offs + len - 1, base);
#endif
			offs -= membase;

			ex = extent_create("xbridge_direct_mem",
			    offs == 0 ? 1 : offs, offs + len - 1,
			    M_DEVBUF, NULL, 0, EX_NOWAIT);

			/*
			 * Note that we do not need to invoke
			 * xbridge_extent_chomp() here since we will
			 * reserve the whole devio area.
			 */

			if (ex != NULL) {
				xb->xb_mem_bus_space->bus_base = base - offs;
				xb->xb_mem_bus_space->_space_map =
				    xbridge_space_map_mem;
				xb->xb_mem_bus_space->_space_subregion =
				    xbridge_space_region_mem;

				xb->xb_mem_bus_space_sw->bus_base = base - offs;
				xb->xb_mem_bus_space_sw->_space_map =
				    xbridge_space_map_mem;
				xb->xb_mem_bus_space_sw->_space_subregion =
				    xbridge_space_region_mem;

				xb->xb_memstart = offs;
				xb->xb_memend = offs + len - 1;
			}
		}
	}

	if (ex != NULL) {
		/*
		 * Remove the devio mapping range from the extent
		 * to avoid ambiguous mappings.
		 *
		 * Note that xbow_widget_map_space() may have returned
		 * a range in which the devio area does not appear.
		 */
		start = xb->xb_devio_skew << 24;
		end = (xb->xb_devio_skew + 1) << 24;

		if (end >= ex->ex_start && start <= ex->ex_end) {
			if (start < ex->ex_start)
				start = ex->ex_start;
			if (end > ex->ex_end + 1)
				end = ex->ex_end + 1;
			if (extent_alloc_region(ex, start, end - start,
			    EX_NOWAIT | EX_MALLOCOK) != 0) {
				printf("%s: failed to expurge devio range"
				    " from %s large extent\n",
				    DEVNAME(xb), io ? "i/o" : "mem");
				extent_destroy(ex);
				ex = NULL;
			}
		}
	}

	return ex;
}

/*
 * Flags returned by xbridge_resource_explore()
 */
#define	XR_IO		0x01	/* needs I/O mappings */
#define	XR_MEM		0x02	/* needs memory mappings */
#define	XR_IO_OFLOW_S	0x04	/* can't fit I/O in a short devio */
#define	XR_MEM_OFLOW_S	0x08	/* can't fit memory in a short devio */
#define	XR_IO_OFLOW	0x10	/* can't fit I/O in a large devio */
#define	XR_MEM_OFLOW	0x20	/* can't fit memory in a large devio */

int
xbridge_resource_explore(struct xbpci_softc *xb, pcitag_t tag,
    struct extent *ioex, struct extent *memex)
{
	pci_chipset_tag_t pc = &xb->xb_pc;
	pcireg_t bhlc, type, addr, mask;
	bus_addr_t base;
	bus_size_t size;
	int reg, reg_start, reg_end, reg_rom;
	int rc = 0;

	bhlc = pci_conf_read(pc, tag, PCI_BHLC_REG);
	switch (PCI_HDRTYPE_TYPE(bhlc)) {
	case 0:
		reg_start = PCI_MAPREG_START;
		reg_end = PCI_MAPREG_END;
		reg_rom = PCI_ROM_REG;
		break;
	case 1:	/* PCI-PCI bridge */
		reg_start = PCI_MAPREG_START;
		reg_end = PCI_MAPREG_PPB_END;
		reg_rom = 0;	/* 0x38 */
		break;
	case 2:	/* PCI-CardBus bridge */
		reg_start = PCI_MAPREG_START;
		reg_end = PCI_MAPREG_PCB_END;
		reg_rom = 0;
		break;
	default:
		return rc;
	}

	for (reg = reg_start; reg < reg_end; reg += 4) {
		if (pci_mapreg_probe(pc, tag, reg, &type) == 0)
			continue;

		if (pci_mapreg_info(pc, tag, reg, type, NULL, &size, NULL))
			continue;

		switch (type) {
		case PCI_MAPREG_TYPE_MEM | PCI_MAPREG_MEM_TYPE_64BIT:
			reg += 4;
			/* FALLTHROUGH */
		case PCI_MAPREG_TYPE_MEM | PCI_MAPREG_MEM_TYPE_32BIT:
			rc |= XR_MEM;
			if (memex != NULL) {
				if (size > memex->ex_end - memex->ex_start)
					rc |= XR_MEM_OFLOW | XR_MEM_OFLOW_S;
				else if (extent_alloc(memex, size, size,
				    0, 0, 0, &base) != 0)
					rc |= XR_MEM_OFLOW | XR_MEM_OFLOW_S;
				else if (base >= BRIDGE_DEVIO_SHORT)
					rc |= XR_MEM_OFLOW_S;
			} else
				rc |= XR_MEM_OFLOW | XR_MEM_OFLOW_S;
			break;
		case PCI_MAPREG_TYPE_IO:
			rc |= XR_IO;
			if (ioex != NULL) {
				if (size > ioex->ex_end - ioex->ex_start)
					rc |= XR_IO_OFLOW | XR_IO_OFLOW_S;
				else if (extent_alloc(ioex, size, size,
				    0, 0, 0, &base) != 0)
					rc |= XR_IO_OFLOW | XR_IO_OFLOW_S;
				else if (base >= BRIDGE_DEVIO_SHORT)
					rc |= XR_IO_OFLOW_S;
			} else
				rc |= XR_IO_OFLOW | XR_IO_OFLOW_S;
			break;
		}
	}

	if (reg_rom != 0) {
		addr = pci_conf_read(pc, tag, reg_rom);
		pci_conf_write(pc, tag, reg_rom, ~PCI_ROM_ENABLE);
		mask = pci_conf_read(pc, tag, reg_rom);
		pci_conf_write(pc, tag, reg_rom, addr);
		size = PCI_ROM_SIZE(mask);

		if (size != 0) {
			rc |= XR_MEM;
			if (memex != NULL) {
				if (size > memex->ex_end - memex->ex_start)
					rc |= XR_MEM_OFLOW | XR_MEM_OFLOW_S;
				else if (extent_alloc(memex, size, size,
				    0, 0, 0, &base) != 0)
					rc |= XR_MEM_OFLOW | XR_MEM_OFLOW_S;
				else if (base >= BRIDGE_DEVIO_SHORT)
					rc |= XR_MEM_OFLOW_S;
			} else
				rc |= XR_MEM_OFLOW | XR_MEM_OFLOW_S;
		}
	}

	return rc;
}

void
xbridge_resource_manage(struct xbpci_softc *xb, pcitag_t tag,
    struct extent *ioex, struct extent *memex)
{
	pci_chipset_tag_t pc = &xb->xb_pc;
	pcireg_t bhlc, type, mask;
	bus_addr_t base;
	bus_size_t size;
	int reg, reg_start, reg_end, reg_rom;

	bhlc = pci_conf_read(pc, tag, PCI_BHLC_REG);
	switch (PCI_HDRTYPE_TYPE(bhlc)) {
	case 0:
		reg_start = PCI_MAPREG_START;
		reg_end = PCI_MAPREG_END;
		reg_rom = PCI_ROM_REG;
		break;
	case 1:	/* PCI-PCI bridge */
		reg_start = PCI_MAPREG_START;
		reg_end = PCI_MAPREG_PPB_END;
		reg_rom = 0;	/* 0x38 */
		break;
	case 2:	/* PCI-CardBus bridge */
		reg_start = PCI_MAPREG_START;
		reg_end = PCI_MAPREG_PCB_END;
		reg_rom = 0;
		break;
	default:
		return;
	}

	for (reg = reg_start; reg < reg_end; reg += 4) {
		if (pci_mapreg_probe(pc, tag, reg, &type) == 0)
			continue;

		if (pci_mapreg_info(pc, tag, reg, type, &base, &size, NULL))
			continue;

		/*
		 * Note that we do not care about the existing BAR values,
		 * since these devices either have not been setup by ARCS
		 * or do not matter for early system setup (such as
		 * optional IOC3 PCI boards, which will get setup by
		 * ARCS but can be reinitialized as we see fit).
		 */
#ifdef DEBUG
		printf("tag %04lx bar %02x type %d base %#lx size %#lx",
		    tag, reg, type, base, size);
#endif
		switch (type) {
		case PCI_MAPREG_TYPE_MEM | PCI_MAPREG_MEM_TYPE_64BIT:
			/*
			 * Since our mapping ranges are restricted to
			 * at most 30 bits, the upper part of the 64 bit
			 * BAR registers is always zero.
			 */
			pci_conf_write(pc, tag, reg + 4, 0);
			/* FALLTHROUGH */
		case PCI_MAPREG_TYPE_MEM | PCI_MAPREG_MEM_TYPE_32BIT:
			if (memex != NULL) {
				if (extent_alloc(memex, size, size, 0, 0, 0,
				    &base) != 0)
					base = 0;
			} else
				base = 0;
			break;
		case PCI_MAPREG_TYPE_IO:
			if (ioex != NULL) {
				if (extent_alloc(ioex, size, size, 0, 0, 0,
				    &base) != 0)
					base = 0;
			} else
				base = 0;
			break;
		}

#ifdef DEBUG
		printf(" setup at %#lx\n", base);
#endif
		pci_conf_write(pc, tag, reg, base);

		if (type == (PCI_MAPREG_TYPE_MEM | PCI_MAPREG_MEM_TYPE_64BIT))
			reg += 4;
	}

	if (reg_rom != 0) {
		base = (bus_addr_t)pci_conf_read(pc, tag, reg_rom);
		pci_conf_write(pc, tag, reg_rom, ~PCI_ROM_ENABLE);
		mask = pci_conf_read(pc, tag, reg_rom);
		size = PCI_ROM_SIZE(mask);

		if (size != 0) {
#ifdef DEBUG
			printf("bar %02x type rom base %#lx size %#lx",
			    reg_rom, base, size);
#endif
			if (memex != NULL) {
				if (extent_alloc(memex, size, size, 0, 0, 0,
				    &base) != 0)
					base = 0;
			} else
				base = 0;
#ifdef DEBUG
			printf(" setup at %#lx\n", base);
#endif
		} else
			base = 0;

		/* ROM intentionally left disabled */
		pci_conf_write(pc, tag, reg_rom, base);
	}
}

void
xbridge_device_setup(struct xbpci_softc *xb, int dev, int nfuncs,
    uint32_t devio)
{
	pci_chipset_tag_t pc = &xb->xb_pc;
	int function;
	pcitag_t tag;
	pcireg_t id, csr;
	uint32_t baseio;
	int resources;
	int io_devio, mem_devio;
	struct extent *ioex, *memex;

	/*
	 * In a first step, we enumerate all the requested resources,
	 * and check if they could fit within devio mappings.
	 *
	 * If devio can't afford us the mappings we need, we'll
	 * try and allocate a large window.
	 */

	/*
	 * Allocate extents to use for devio mappings if necessary.
	 * This can fail; in that case we'll try to use a large mapping
	 * whenever possible, or silently fail to configure the device.
	 */
	if (xb->xb_ioex != NULL)
		ioex = NULL;
	else {
		ioex = extent_create("xbridge_io",
		    0, BRIDGE_DEVIO_LARGE - 1,
		    M_DEVBUF, NULL, 0, EX_NOWAIT);
#ifdef DEBUG
		if (ioex == NULL)
			printf("%s: ioex extent_create failed\n", __func__);
#endif
	}
	if (xb->xb_memex != NULL)
		memex = NULL;
	else {
		memex = extent_create("xbridge_mem",
		    0, BRIDGE_DEVIO_LARGE - 1,
		    M_DEVBUF, NULL, 0, EX_NOWAIT);
#ifdef DEBUG
		if (memex == NULL)
			printf("%s: memex extent_create failed\n", __func__);
#endif
	}

	resources = 0;
	for (function = 0; function < nfuncs; function++) {
		tag = pci_make_tag(pc, 0, dev, function);
		id = pci_conf_read(pc, tag, PCI_ID_REG);

		if (PCI_VENDOR(id) == PCI_VENDOR_INVALID ||
		    PCI_VENDOR(id) == 0)
			continue;

		csr = pci_conf_read(pc, tag, PCI_COMMAND_STATUS_REG);
		pci_conf_write(pc, tag, PCI_COMMAND_STATUS_REG, csr &
		    ~(PCI_COMMAND_IO_ENABLE | PCI_COMMAND_MEM_ENABLE));

		resources |= xbridge_resource_explore(xb, tag, ioex, memex);
	}
#ifdef DEBUG
	printf("resources mask: %02x\n", resources);
#endif

	if (memex != NULL) {
		extent_destroy(memex);
		memex = NULL;
	}
	if (ioex != NULL) {
		extent_destroy(ioex);
		ioex = NULL;
	}

	/*
	 * In a second step, if resources can be mapped using devio slots,
	 * allocate them. Otherwise, or if we can't get a devio slot
	 * big enough for the resources we need to map, we'll need
	 * to get a large window mapping.
	 *
	 * Note that, on Octane, we try to avoid using devio whenever
	 * possible.
	 */

	io_devio = -1;
	if (ISSET(resources, XR_IO)) {
		if (!ISSET(resources, XR_IO_OFLOW) &&
		    (sys_config.system_type != SGI_OCTANE ||
		     xb->xb_ioex == NULL))
			io_devio = xbridge_allocate_devio(xb, dev,
			    ISSET(resources, XR_IO_OFLOW_S));
		if (io_devio >= 0) {
			baseio = (xb->xb_devio_skew << 24) |
			    PIC_DEVIO_OFFS(xb->xb_busno, io_devio);
			xbridge_set_devio(xb, io_devio, devio |
			    (baseio >> BRIDGE_DEVICE_BASE_SHIFT), 1);

			ioex = extent_create("xbridge_io", baseio,
			    baseio + BRIDGE_DEVIO_SIZE(io_devio) - 1,
			    M_DEVBUF, NULL, 0, EX_NOWAIT);
		} else {
			/*
			 * Try to get a large window mapping if we don't
			 * have one already.
			 */
			if (xb->xb_ioex == NULL)
				xb->xb_ioex = xbridge_mapping_setup(xb, 1);
		}
	}

	mem_devio = -1;
	if (ISSET(resources, XR_MEM)) {
		if (!ISSET(resources, XR_MEM_OFLOW) &&
		    sys_config.system_type != SGI_OCTANE)
			mem_devio = xbridge_allocate_devio(xb, dev,
			    ISSET(resources, XR_MEM_OFLOW_S));
		if (mem_devio >= 0) {
			baseio = (xb->xb_devio_skew << 24) |
			    PIC_DEVIO_OFFS(xb->xb_busno, mem_devio);
			xbridge_set_devio(xb, mem_devio, devio |
			    BRIDGE_DEVICE_IO_MEM |
			    (baseio >> BRIDGE_DEVICE_BASE_SHIFT), 1);

			memex = extent_create("xbridge_mem", baseio,
			    baseio + BRIDGE_DEVIO_SIZE(mem_devio) - 1,
			    M_DEVBUF, NULL, 0, EX_NOWAIT);
		} else {
			/*
			 * Try to get a large window mapping if we don't
			 * have one already.
			 */
			if (xb->xb_memex == NULL)
				xb->xb_memex = xbridge_mapping_setup(xb, 0);
		}
	}

	/*
	 * Finally allocate the resources proper and update the
	 * device BARs accordingly.
	 */

	for (function = 0; function < nfuncs; function++) {
		tag = pci_make_tag(pc, 0, dev, function);
		id = pci_conf_read(pc, tag, PCI_ID_REG);

		if (PCI_VENDOR(id) == PCI_VENDOR_INVALID ||
		    PCI_VENDOR(id) == 0)
			continue;

		xbridge_resource_manage(xb, tag,
		    ioex != NULL ? ioex : xb->xb_ioex,
		    memex != NULL ?  memex : xb->xb_memex);
	}

	if (memex != NULL)
		extent_destroy(memex);
	if (ioex != NULL)
		extent_destroy(ioex);
}

int
xbridge_ppb_setup(void *cookie, pcitag_t tag, bus_addr_t *iostart,
    bus_addr_t *ioend, bus_addr_t *memstart, bus_addr_t *memend)
{
	struct xbpci_softc *xb = cookie;
	pci_chipset_tag_t pc = &xb->xb_pc;
	uint32_t base, devio;
	bus_size_t exsize;
	u_long exstart;
	int dev, devio_idx, tries;

	pci_decompose_tag(pc, tag, NULL, &dev, NULL);
	devio = xbridge_read_reg(xb, BRIDGE_DEVICE(dev));

	/*
	 * Since our caller computes resource needs starting at zero, we
	 * can ignore the start values when computing the amount of
	 * resources we'll need.
	 */

	/*
	 * Try and allocate I/O resources first, as we may not be able
	 * to use a large I/O mapping, in which case we want to use our
	 * reserved devio for this purpose.
	 */

	exsize = *ioend;
	*iostart = 0xffffffff;
	*ioend = 0;
	if (exsize++ != 0) {
		/* try to allocate through a devio slot whenever possible... */
		if (exsize < BRIDGE_DEVIO_SHORT)
			devio_idx = xbridge_allocate_devio(xb, dev, 0);
		else if (exsize < BRIDGE_DEVIO_LARGE)
			devio_idx = xbridge_allocate_devio(xb, dev, 1);
		else
			devio_idx = -1;

		/* ...if it fails, try the large view.... */
		if (devio_idx < 0 && xb->xb_ioex == NULL)
			xb->xb_ioex = xbridge_mapping_setup(xb, 1);

		/* ...if it is not available, try to get a devio slot anyway. */
		if (devio_idx < 0 && xb->xb_ioex == NULL) {
			if (exsize > BRIDGE_DEVIO_SHORT)
				devio_idx = xbridge_allocate_devio(xb, dev, 1);
			if (devio_idx < 0)
				devio_idx = xbridge_allocate_devio(xb, dev, 0);
		}

		if (devio_idx >= 0) {
			base = (xb->xb_devio_skew << 24) |
			    PIC_DEVIO_OFFS(xb->xb_busno, devio_idx);
			xbridge_set_devio(xb, devio_idx, devio |
			    (base >> BRIDGE_DEVICE_BASE_SHIFT), 1);
			*iostart = base;
			*ioend = base + BRIDGE_DEVIO_SIZE(devio_idx) - 1;
		} else if (xb->xb_ioex != NULL) {
			/*
			 * We know that the direct I/O resource range fits
			 * within the 32 bit address space, so our allocation,
			 * if successful, will work as a 32 bit i/o range.
			 */
			if (exsize < 1UL << 12)
				exsize = 1UL << 12;
			for (tries = 0; tries < 5; tries++) {
				if (extent_alloc(xb->xb_ioex, exsize,
				    1UL << 12, 0, 0, EX_NOWAIT | EX_MALLOCOK,
				    &exstart) == 0) {
					*iostart = exstart;
					*ioend = exstart + exsize - 1;
					break;
				}
				exsize >>= 1;
				if (exsize < 1UL << 12)
					break;
			}
		}
	}

	exsize = *memend;
	*memstart = 0xffffffff;
	*memend = 0;
	if (exsize++ != 0) {
		/* try to allocate through a devio slot whenever possible... */
		if (exsize < BRIDGE_DEVIO_SHORT)
			devio_idx = xbridge_allocate_devio(xb, dev, 0);
		else if (exsize < BRIDGE_DEVIO_LARGE)
			devio_idx = xbridge_allocate_devio(xb, dev, 1);
		else
			devio_idx = -1;

		/* ...if it fails, try the large view.... */
		if (devio_idx < 0 && xb->xb_memex == NULL)
			xb->xb_memex = xbridge_mapping_setup(xb, 0);

		/* ...if it is not available, try to get a devio slot anyway. */
		if (devio_idx < 0 && xb->xb_memex == NULL) {
			if (exsize > BRIDGE_DEVIO_SHORT)
				devio_idx = xbridge_allocate_devio(xb, dev, 1);
			if (devio_idx < 0)
				devio_idx = xbridge_allocate_devio(xb, dev, 0);
		}

		if (devio_idx >= 0) {
			base = (xb->xb_devio_skew << 24) |
			    PIC_DEVIO_OFFS(xb->xb_busno, devio_idx);
			xbridge_set_devio(xb, devio_idx, devio |
			    BRIDGE_DEVICE_IO_MEM |
			    (base >> BRIDGE_DEVICE_BASE_SHIFT), 1);
			*memstart = base;
			*memend = base + BRIDGE_DEVIO_SIZE(devio_idx) - 1;
		} else if (xb->xb_memex != NULL) {
			/*
			 * We know that the direct memory resource range fits
			 * within the 32 bit address space, and is limited to
			 * 30 bits, so our allocation, if successful, will
			 * work as a 32 bit memory range.
			 */
			if (exsize < 1UL << 20)
				exsize = 1UL << 20;
			for (tries = 0; tries < 5; tries++) {
				if (extent_alloc(xb->xb_memex, exsize,
				    1UL << 20, 0, 0, EX_NOWAIT | EX_MALLOCOK,
				    &exstart) == 0) {
					*memstart = exstart;
					*memend = exstart + exsize - 1;
					break;
				}
				exsize >>= 1;
				if (exsize < 1UL << 20)
					break;
			}
		}
	}

	return 0;
}

#if NCARDBUS > 0

static struct rb_md_fnptr xbridge_rb_md_fn = {
	xbridge_rbus_space_map,
	xbridge_rbus_space_unmap
};

int
xbridge_rbus_space_map(bus_space_tag_t t, bus_addr_t addr, bus_size_t size,
    int flags, bus_space_handle_t *bshp)
{
	return bus_space_map(t, addr, size, flags, bshp);
}

void
xbridge_rbus_space_unmap(bus_space_tag_t t, bus_space_handle_t h,
    bus_size_t size, bus_addr_t *addrp)
{
	bus_space_unmap(t, h, size);
	*addrp = h - t->bus_base;
}

void *
xbridge_rbus_parent_io(struct pci_attach_args *pa)
{
	struct extent *ex = pa->pa_ioex;
	bus_addr_t start, end;
	rbus_tag_t rb = NULL;

	/*
	 * We want to force I/O mappings to lie in the low 16 bits
	 * area.  This is mandatory for 16-bit pcmcia devices; and
	 * although 32-bit cardbus devices could use a larger range,
	 * the pccbb driver doesn't enable the large I/O windows.
	 */
	if (ex != NULL) {
		start = 0;
		end = 0x10000;
		if (start < ex->ex_start)
			start = ex->ex_start;
		if (end > ex->ex_end)
			end = ex->ex_end;

		if (start < end) {
			rb = rbus_new_root_share(pa->pa_iot, ex,
			    start, end - start);
			if (rb != NULL)
				rb->rb_md = &xbridge_rb_md_fn;
		}
	}

	/*
	 * We are not allowed to return NULL. If we can't provide
	 * resources, return a valid body which will fail requests.
	 */
	if (rb == NULL)
		rb = rbus_new_body(pa->pa_iot, NULL, 0, 0, RBUS_SPACE_INVALID);

	return rb;
}

void *
xbridge_rbus_parent_mem(struct pci_attach_args *pa)
{
	struct xbpci_softc *xb = pa->pa_pc->pc_conf_v;
	struct extent *ex = pa->pa_memex;
	bus_addr_t start;
	rbus_tag_t rb = NULL;

	/*
	 * There is no restriction for the memory mappings,
	 * however we need to make sure these won't hit the
	 * devio range (for md_space_unmap to work correctly).
	 */
	if (ex != NULL) {
		start = (xb->xb_devio_skew + 1) << 24;
		if (start < ex->ex_start)
			start = ex->ex_start;

		if (start < ex->ex_end) {
			rb = rbus_new_root_share(pa->pa_memt, ex,
			    start, ex->ex_end - start);
			if (rb != NULL)
				rb->rb_md = &xbridge_rb_md_fn;
		}
	}

	/*
	 * We are not allowed to return NULL. If we can't provide
	 * resources, return a valid body which will fail requests.
	 */
	if (rb == NULL)
		rb = rbus_new_body(pa->pa_iot, NULL, 0, 0, RBUS_SPACE_INVALID);

	return rb;
}

#endif	/* NCARDBUS > 0 */

int
xbridge_allocate_devio(struct xbpci_softc *xb, int dev, int wantlarge)
{
#ifdef DEBUG
	int orig_dev = dev;
#endif

	/*
	 * If the preferred slot is available and matches the size requested,
	 * use it.
	 */

	if (!ISSET(xb->xb_devio_usemask, 1 << dev)) {
		if (BRIDGE_DEVIO_SIZE(dev) >=
		    wantlarge ? BRIDGE_DEVIO_LARGE : BRIDGE_DEVIO_SHORT) {
#ifdef DEBUG
			printf("%s(%d,%d): using reserved entry\n",
			    __func__, dev, wantlarge);
#endif
			return dev;
		}
	}

	/*
	 * Otherwise pick the smallest available devio matching our size
	 * request.
	 */

	for (dev = 0; dev < xb->xb_nslots; dev++) {
		if (ISSET(xb->xb_devio_usemask, 1 << dev))
			continue;	/* devio in use */

		if (!SLOT_EMPTY(xb, dev))
			continue;	/* devio to be used soon */

		if (BRIDGE_DEVIO_SIZE(dev) >=
		    wantlarge ? BRIDGE_DEVIO_LARGE : BRIDGE_DEVIO_SHORT) {
#ifdef DEBUG
			printf("%s(%d,%d): using unused entry %d\n",
			    __func__, orig_dev, wantlarge, dev);
#endif
			return dev;
		}
	}

#ifdef DEBUG
	printf("%s(%d,%d): no entry available\n",
	    __func__, orig_dev, wantlarge);
#endif
	return -1;
}

void
xbridge_set_devio(struct xbpci_softc *xb, int dev, uint32_t devio, int final)
{
	xbridge_write_reg(xb, BRIDGE_DEVICE(dev), devio);
	(void)xbridge_read_reg(xb, WIDGET_TFLUSH);
	xb->xb_devices[dev].devio = devio;
	if (final)
		SET(xb->xb_devio_usemask, 1 << dev);
#ifdef DEBUG
	printf("device %d: new %sdevio %08x\n",
	    dev, final ? "final " : "", devio);
#endif
}

#ifdef DDB
void xbridge_ddb(void);
void
xbridge_ddb()
{
	struct xbpci_softc *xb;
	unsigned int n, intrbit;

	for (n = 0; n < xbpci_cd.cd_ndevs; n++) {
		xb = xbpci_cd.cd_devs[n];
		if (xb == NULL)
			continue;

		printf("%s: ISR %p IER %p xb_ier %p\n",
		    xb->xb_dev.dv_xname,
		    (void *)xbridge_read_reg(xb, BRIDGE_ISR),
		    (void *)xbridge_read_reg(xb, BRIDGE_IER),
		    (void *)xb->xb_ier);

		printf("mode %p dev %p\n",
		    (void *)xbridge_read_reg(xb, BRIDGE_INT_MODE),
		    (void *)xbridge_read_reg(xb, BRIDGE_INT_DEV));

		for (intrbit = 0; intrbit < 8; intrbit++)
			printf("IRQ%u to %p\n", intrbit,
			    (void *)xbridge_read_reg(xb,
			      BRIDGE_INT_ADDR(intrbit)));

		printf("%s: PCICFG %08llx ERR %08llx:%08llx\n",
		    xb->xb_dev.dv_xname,
		    xbridge_read_reg(xb, BRIDGE_PCI_CFG),
		    xbridge_read_reg(xb, BRIDGE_PCI_ERR_UPPER),
		    xbridge_read_reg(xb, BRIDGE_PCI_ERR_LOWER));
	}
}
#endif
@


1.101
log
@Let MP-safe interrupt handlers run without the kernel lock on sgi.

OK miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.100 2015/12/03 15:38:06 visa Exp $	*/
d486 1
a486 2
bus_addr_t xbridge_pa_to_device(paddr_t);
paddr_t	xbridge_device_to_pa(bus_addr_t);
a554 1
	xbridge_device_to_pa,
d1988 1
a1988 1
xbridge_pa_to_device(paddr_t pa)
d1990 3
a1993 6
}

paddr_t
xbridge_device_to_pa(bus_addr_t addr)
{
	return (addr - BRIDGE_DMA_DIRECT_BASE) + dma_constraint.ucr_low;
@


1.100
log
@Let the IP27 kernel build with DEBUG.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.99 2015/09/27 10:12:09 semarie Exp $	*/
d1201 2
d1314 1
d1316 1
a1316 1
	int device = XBRIDGE_INTR_DEVICE(ih);
d1320 3
d1362 1
a1362 1
		    IPL_BIO, NULL, NULL)) {
d1377 1
d1476 1
d1478 3
a1480 1
	uint64_t isr;
d1520 8
d1532 4
@


1.99
log
@free(x, 0) cleanup:
  - set size argument of free()
  - remove pointless if expression around free() call

ok guenther@@
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.98 2015/09/12 08:40:02 miod Exp $	*/
d1503 1
a1503 1
		printf("%s: irq %d but not pending in ISR %08x\n",
d2392 1
a2392 1
		printf("device %d: devio %08x\n",
d2737 1
a2737 1
			printf("direct io %p-%p base %p\n",
d2793 1
a2793 1
			printf("direct mem %p-%p base %p\n",
d3010 1
a3010 1
		printf("tag %04x bar %02x type %d base %p size %p",
d3041 1
a3041 1
		printf(" setup at %p\n", base);
d3057 1
a3057 1
			printf("bar %02x type rom base %p size %p",
d3067 1
a3067 1
			printf(" setup at %p\n", base);
@


1.98
log
@Also print the error registers in the ddb callback.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.97 2015/09/08 10:21:50 deraadt Exp $	*/
d887 6
a892 8
	if (xb->xb_io_bus_space_sw != NULL)
		free(xb->xb_io_bus_space_sw, M_DEVBUF, 0);
	if (xb->xb_io_bus_space != NULL)
		free(xb->xb_io_bus_space, M_DEVBUF, 0);
	if (xb->xb_mem_bus_space_sw != NULL)
		free(xb->xb_mem_bus_space_sw, M_DEVBUF, 0);
	if (xb->xb_mem_bus_space != NULL)
		free(xb->xb_mem_bus_space, M_DEVBUF, 0);
@


1.97
log
@sizes for free(); ok semarie
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.96 2015/06/24 16:52:52 miod Exp $	*/
d3573 6
@


1.96
log
@Attempt to explain how this device works. Based upon a private mail I wrote
6 years ago when asked about this.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.95 2015/06/16 18:24:38 miod Exp $	*/
d1334 1
a1334 1
			free(xi, M_DEVBUF, 0);
d1442 1
a1442 1
	free(xih, M_DEVBUF, 0);
@


1.95
log
@Clear the PIC `write request' memory at initialization time. There is
apparently a risk of spurious parity errors if we don't.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.94 2015/03/23 20:50:21 miod Exp $	*/
d27 230
@


1.94
log
@Add an helper routine if defined(DDB), which might help figuring out why
PIC sometimes loses isp^Wqlw interrupts.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.93 2014/12/04 21:52:08 miod Exp $	*/
d1758 1
d1887 16
@


1.93
log
@Move the PIC revision 1 interrupt workaround from xbridge_pci_intr_handler()
to a dedicated wrapper function, and register either xbridge_pci_intr_handler()
or the wrapper as the interrupt handler, depending upon which chip we run on.

Saves the cost of the workaround on non-affected chips, which are a large
majority.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.92 2014/09/30 06:51:58 jmatthew Exp $	*/
d3298 31
@


1.92
log
@implement atomic operations using ll/sc, and convert rw_cas and callers of the
pre-existing atomics to match.

tested on sgi (octane) and octeon (erl)
ok miod@@ dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.91 2014/08/19 19:04:07 miod Exp $	*/
d136 1
d218 1
d520 9
d1127 1
a1127 1
		if (xbow_intr_establish(xbridge_pci_intr_handler, xi, intrsrc,
a1243 12
	/*
	 * Revision 1 of PIC is supposed to need the interrupt enable bit
	 * to be toggled to prevent loss of interrupt.
	 */
	if (ISSET(xb->xb_flags, XF_PIC) && xb->xb_revision <= 1) {
		xbridge_write_reg(xb, BRIDGE_IER,
		    xb->xb_ier & ~(1L << xi->xi_intrbit));
		(void)xbridge_read_reg(xb, WIDGET_TFLUSH);
		xbridge_write_reg(xb, BRIDGE_IER, xb->xb_ier);
		(void)xbridge_read_reg(xb, WIDGET_TFLUSH);
	}

d1323 18
@


1.91
log
@More PIC programming magic, as well as a specific workaround for lost
interrupts in PIC rev 1; from IRIX via Linux 2.5.69.

This doesn't fix the lost SCSI interrupts jasper@@ eventually experiences on
Origin 350 systems, but this can't hurt anyway.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.90 2014/07/12 18:44:42 tedu Exp $	*/
d40 1
a41 1
#include <machine/atomic.h>
@


1.90
log
@add a size argument to free. will be used soon, but for now default to 0.
after discussions with beck deraadt kettenis.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.89 2014/05/19 21:18:42 miod Exp $	*/
d1150 1
a1150 1
		xb->xb_ier |= 1 << intrbit;
d1233 12
d1315 1
a1315 1
	if (ISSET(xb->xb_flags, XF_XBRIDGE))
d1317 2
a1318 1
	else {
d1814 9
d1890 1
a1890 1
		xb->xb_ier = 1 << 6;
@


1.89
log
@Format string fixes and removal of -Wno-format for sgi. Based upon an
initial diff from jasper@@
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.88 2014/04/03 08:07:16 mpi Exp $	*/
d644 1
a644 1
	free(xb->xb_dmat, M_DEVBUF);
d647 1
a647 1
		free(xb->xb_io_bus_space_sw, M_DEVBUF);
d649 1
a649 1
		free(xb->xb_io_bus_space, M_DEVBUF);
d651 1
a651 1
		free(xb->xb_mem_bus_space_sw, M_DEVBUF);
d653 1
a653 1
		free(xb->xb_mem_bus_space, M_DEVBUF);
d1093 1
a1093 1
			free(xi, M_DEVBUF);
d1201 1
a1201 1
	free(xih, M_DEVBUF);
@


1.88
log
@Moar <uvm/uvm.h> -> <uvm/uvm_extern.h> love.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.87 2014/01/22 00:03:06 jsg Exp $	*/
d1061 1
a1061 1
		    sizeof xb->xb_intrstr[intrbit], "irq %d", ih);
d1960 1
a1960 1
	printf("%s: error interrupt, isr %p wid %p pci %p resp %p\n",
@


1.87
log
@add missing arguments to debug printfs
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.86 2012/09/29 18:54:39 miod Exp $	*/
d48 1
a48 1
#include <uvm/uvm.h>
@


1.86
log
@Proide a mips_sync() macro to wrap asm("sync"), and replace gazillions of
such statements with it.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.85 2012/05/20 11:41:11 miod Exp $	*/
d2827 1
a2827 1
			printf("%s: ioex extent_create failed\n");
d2838 1
a2838 1
			printf("%s: memex extent_create failed\n");
@


1.85
log
@Make sure the generic bus_dmamem_alloc() routine restricts its allocation to
the dma_constraint range. This allows the xbridge(4) bus_dma_tag_t to use the
generic routines instead of rolling its own, now that the ATE code has been
removed.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.84 2011/10/10 19:49:17 miod Exp $	*/
d1663 1
a1663 1
	__asm__ __volatile__ ("sync" ::: "memory");
@


1.84
log
@Extend pci_probe_device_hook() on sgi xbridge(4) to return either the straight
accessors or the byte-swapped accessors, depending upon the byteswap setting
of the device we are trying to attach.

This allows for the removal of byteswap knowledge from ioc(4) and iof(4)
drivers.

While there, build pci_chipset_t md structs by bcopy'ing a template and
filling the few runtime fields, instead of assigning every field of them.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.82 2011/04/17 17:44:24 miod Exp $	*/
a253 5
int	xbridge_dmamap_load_buffer(bus_dma_tag_t, bus_dmamap_t, void *,
	    bus_size_t, struct proc *, int, paddr_t *, int *, int);
void	xbridge_dmamap_unload(bus_dma_tag_t, bus_dmamap_t);
int	xbridge_dmamem_alloc(bus_dma_tag_t, bus_size_t, bus_size_t, bus_size_t,
	    bus_dma_segment_t *, int, int *, int);
d315 2
a316 2
	xbridge_dmamap_load_buffer,
	xbridge_dmamap_unload,
d318 1
a318 1
	xbridge_dmamem_alloc,
d1704 3
a1706 173
 * bus_dmamap_loadXXX() bowels implementation.
 */
int
xbridge_dmamap_load_buffer(bus_dma_tag_t t, bus_dmamap_t map, void *buf,
    bus_size_t buflen, struct proc *p, int flags, paddr_t *lastaddrp,
    int *segp, int first)
{
	/* struct xbpci_softc *xb = t->_cookie; */
	bus_size_t sgsize;
	bus_addr_t lastaddr, baddr, bmask;
	bus_addr_t busaddr, endaddr;
	paddr_t pa;
	vaddr_t vaddr = (vaddr_t)buf;
	int seg;
	pmap_t pmap;
	int rc;

	if (first) {
		for (seg = 0; seg < map->_dm_segcnt; seg++)
			map->dm_segs[seg].ds_addr = 0;
	}

	if (p != NULL)
		pmap = p->p_vmspace->vm_map.pmap;
	else
		pmap = pmap_kernel();

	lastaddr = *lastaddrp;
	bmask  = ~(map->_dm_boundary - 1);
	if (t->_dma_mask != 0)
		bmask &= t->_dma_mask;

	for (seg = *segp; buflen > 0; ) {
		/*
		 * Get the physical address for this segment.
		 */
		if (pmap_extract(pmap, vaddr, &pa) == FALSE)
			panic("%s: pmap_extract(%x, %x) failed",
			    __func__, pmap, vaddr);

#ifdef DIAGNOSTIC
		if (pa > dma_constraint.ucr_high ||
		    pa < dma_constraint.ucr_low) {
			panic("Non DMA-reachable buffer at pa %p (raw)", pa);
			/* rc = ENOMEM;
			goto fail_unmap; */
		}
#endif

		/*
		 * Compute the DMA address and the physical range 
		 * this mapping can cover.
		 */
		busaddr = pa - dma_constraint.ucr_low + BRIDGE_DMA_DIRECT_BASE;
		endaddr = BRIDGE_DMA_DIRECT_LENGTH + BRIDGE_DMA_DIRECT_BASE;

		/*
		 * Compute the segment size, and adjust counts.
		 * Note that we do not min() against (endaddr - busaddr)
		 * as the initial sgsize computation is <= (endaddr - busaddr).
		 */
		sgsize = PAGE_SIZE - ((u_long)vaddr & PGOFSET);
		if (buflen < sgsize)
			sgsize = buflen;

		/*
		 * Make sure we don't cross any boundaries.
		 */
		if (map->_dm_boundary > 0) {
			baddr = (busaddr + map->_dm_boundary) & bmask;
			if (sgsize > (baddr - busaddr))
				sgsize = baddr - busaddr;
		}

		/*
		 * Insert chunk into a segment, coalescing with
		 * previous segment if possible.
		 */
		if (first) {
			map->dm_segs[seg].ds_addr = busaddr;
			map->dm_segs[seg].ds_len = sgsize;
			map->dm_segs[seg]._ds_paddr = pa;
			map->dm_segs[seg]._ds_vaddr = vaddr;
			first = 0;
		} else {
			if (busaddr == lastaddr &&
			    (map->dm_segs[seg].ds_len + sgsize) <=
			     map->_dm_maxsegsz &&
			     (map->_dm_boundary == 0 ||
			     (map->dm_segs[seg].ds_addr & bmask) ==
			     (busaddr & bmask)))
				map->dm_segs[seg].ds_len += sgsize;
			else {
				if (++seg >= map->_dm_segcnt)
					break;
				map->dm_segs[seg].ds_addr = busaddr;
				map->dm_segs[seg].ds_len = sgsize;
				map->dm_segs[seg]._ds_paddr = pa;
				map->dm_segs[seg]._ds_vaddr = vaddr;
			}
		}

		lastaddr = busaddr + sgsize;
		if (lastaddr == endaddr)
			lastaddr = ~0;	/* can't coalesce */
		vaddr += sgsize;
		buflen -= sgsize;
	}

	*segp = seg;
	*lastaddrp = lastaddr;

	/*
	 * Did we fit?
	 */
	if (buflen != 0) {
		rc = EFBIG;
		goto fail_unmap;
	}

	return 0;

fail_unmap:
	for (seg = 0; seg < map->_dm_segcnt; seg++)
		map->dm_segs[seg].ds_addr = 0;

	return rc;
}

/*
 * bus_dmamap_unload() implementation.
 */
void
xbridge_dmamap_unload(bus_dma_tag_t t, bus_dmamap_t map)
{
	/* struct xbpci_softc *xb = t->_cookie; */
	int seg;

	for (seg = 0; seg < map->_dm_segcnt; seg++)
		map->dm_segs[seg].ds_addr = 0;
	map->dm_nsegs = 0;
	map->dm_mapsize = 0;
}

/*
 * bus_dmamem_alloc() implementation.
 */
int
xbridge_dmamem_alloc(bus_dma_tag_t t, bus_size_t size, bus_size_t alignment,
    bus_size_t boundary, bus_dma_segment_t *segs, int nsegs, int *rsegs,
    int flags)
{
	paddr_t low, high;

	/*
	 * Limit bus_dma'able memory to the direct DMA window.
	 * XXX This should be lifted if flags & BUS_DMA_64BIT for drivers
	 * XXX which do not need to restrict themselves to 32 bit DMA
	 * XXX addresses.
	 */
	low = dma_constraint.ucr_low;
	high = dma_constraint.ucr_high;

	return _dmamem_alloc_range(t, size, alignment, boundary,
	    segs, nsegs, rsegs, flags, low, high);
}

/*
 * Since we override the various bus_dmamap_load*() functions, the only
 * caller of pa_to_device() and device_to_pa() is _dmamem_alloc_range(),
 * invoked by xbridge_dmamem_alloc() above. Since we make sure this
 * function can only return memory fitting in the direct DMA window, we do
 * not need to check for other cases.
@


1.83
log
@Introduce pci_probe_device_hook(pci_chipset_tag_t, struct pci_attach_args *).
This mandatory function will get invoked in pci_probe_device(), and allows
a pci host driver to alter the pci_attach_args passed to a device when
attaching.

This function will also, if returning non-zero, cause the device to be
skipped completely during all the phases of the PCI device discovery
(i.e. ressource enumeration, ressource assignment, and actual attachment).
This particular feature is experimental and might be reverted in the future
(or the scope narrowed to device attachment only).

A dummy #define pci_probe_device_hook() 0 is added to all platforms except
sgi, where real functions (currently only returning 0) are added; real meat
will be added shortly.

Discussed at s2k11, no objection from the usual suspects.
@
text
@d127 1
d129 1
d312 1
a312 1
const struct machine_bus_dma_tag xbridge_dma_tag = {
d333 23
d535 2
a536 2
	 * it is necessary to perform endianness conversion for the
	 * low-order address bits.
d541 2
a542 2
	if (xb->xb_mem_bus_space == NULL)
		goto fail1;
d545 5
a549 2
	if (xb->xb_io_bus_space == NULL)
		goto fail2;
a554 10
	xb->xb_mem_bus_space->_space_read_1 = xbridge_read_1;
	xb->xb_mem_bus_space->_space_write_1 = xbridge_write_1;
	xb->xb_mem_bus_space->_space_read_2 = xbridge_read_2;
	xb->xb_mem_bus_space->_space_write_2 = xbridge_write_2;
	xb->xb_mem_bus_space->_space_read_raw_2 = xbridge_read_raw_2;
	xb->xb_mem_bus_space->_space_write_raw_2 = xbridge_write_raw_2;
	xb->xb_mem_bus_space->_space_read_raw_4 = xbridge_read_raw_4;
	xb->xb_mem_bus_space->_space_write_raw_4 = xbridge_write_raw_4;
	xb->xb_mem_bus_space->_space_read_raw_8 = xbridge_read_raw_8;
	xb->xb_mem_bus_space->_space_write_raw_8 = xbridge_write_raw_8;
d557 13
a573 10
	xb->xb_io_bus_space->_space_read_1 = xbridge_read_1;
	xb->xb_io_bus_space->_space_write_1 = xbridge_write_1;
	xb->xb_io_bus_space->_space_read_2 = xbridge_read_2;
	xb->xb_io_bus_space->_space_write_2 = xbridge_write_2;
	xb->xb_io_bus_space->_space_read_raw_2 = xbridge_read_raw_2;
	xb->xb_io_bus_space->_space_write_raw_2 = xbridge_write_raw_2;
	xb->xb_io_bus_space->_space_read_raw_4 = xbridge_read_raw_4;
	xb->xb_io_bus_space->_space_write_raw_4 = xbridge_write_raw_4;
	xb->xb_io_bus_space->_space_read_raw_8 = xbridge_read_raw_8;
	xb->xb_io_bus_space->_space_write_raw_8 = xbridge_write_raw_8;
d576 13
d591 1
a591 1
		goto fail3;
d599 1
a600 10
	xb->xb_pc.pc_attach_hook = xbridge_attach_hook;
	xb->xb_pc.pc_make_tag = xbridge_make_tag;
	xb->xb_pc.pc_decompose_tag = xbridge_decompose_tag;
	xb->xb_pc.pc_bus_maxdevs = xbridge_bus_maxdevs;
	xb->xb_pc.pc_conf_size = xbridge_conf_size;
	xb->xb_pc.pc_conf_read = xbridge_conf_read;
	xb->xb_pc.pc_conf_write = xbridge_conf_write;
	xb->xb_pc.pc_probe_device_hook = xbridge_probe_device_hook;
	xb->xb_pc.pc_get_widget = xbridge_get_widget;
	xb->xb_pc.pc_get_dl = xbridge_get_dl;
a601 10
	xb->xb_pc.pc_intr_map = xbridge_intr_map;
	xb->xb_pc.pc_intr_string = xbridge_intr_string;
	xb->xb_pc.pc_intr_establish = xbridge_intr_establish;
	xb->xb_pc.pc_intr_disestablish = xbridge_intr_disestablish;
	xb->xb_pc.pc_intr_line = xbridge_intr_line;
	xb->xb_pc.pc_ppb_setup = xbridge_ppb_setup;
#if NCARDBUS > 0
	xb->xb_pc.pc_rbus_parent_io = xbridge_rbus_parent_io;
	xb->xb_pc.pc_rbus_parent_mem = xbridge_rbus_parent_mem;
#endif
d609 1
a609 1
		goto fail4;
d620 12
a631 2
	pba.pba_iot = xb->xb_io_bus_space;
	pba.pba_memt = xb->xb_mem_bus_space;
d648 1
a648 1
fail4:
a649 4
fail3:
	free(xb->xb_io_bus_space, M_DEVBUF);
fail2:
	free(xb->xb_mem_bus_space, M_DEVBUF);
d651 8
a903 1
#if 0
d905 15
a919 1
#endif
d2650 6
d2704 6
@


1.82
log
@On IP27 systems, fill the array of node hub widget numbers early, so that all
hubs are known during autoconf. Then, pick the most populated 2GB window
as our DMA memory window. xbridge(4) can thus program the correct settings
regardless of the order in which the xbow(4) attach.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.81 2011/04/05 14:43:11 miod Exp $	*/
d208 1
d573 1
d870 10
@


1.81
log
@Rename a few xbow global variable names to make them less ambiguous.
Remember the hub widget number of each node, instead of only the master node.
Use this in xbridge to compute the proper direct DMA map configuration
register value (it needs to embed the hub widget number matching the
physical address range).
This should allow us to pick memory from a different node than the one
we booted from, as the DMA window, if wanted.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.80 2011/04/05 01:17:41 miod Exp $	*/
d4 1
a4 1
 * Copyright (c) 2008, 2009  Miodrag Vallat.
d1901 1
a1901 1
		dirmap |= xbow_node_hub_widget[
d1908 1
a1908 2
		dirmap |= xbow_node_hub_widget[0/*masternasid*/] <<
		    BRIDGE_DIRMAP_WIDGET_SHIFT;
d1996 13
a2008 2
	int_addr = ((uint64_t)xbow_node_hub_widget[masternasid] << 48) |
	    (xbow_intr_address & ((1UL << 48) - 1));
@


1.80
log
@Get rid of the ATE code, and do not assume the direct DMA window is set up
at physical address zero onwards, but instead assume it is controlled by
the dma_constraints range.
This will eventually allow a different window to be selected.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.79 2011/03/13 20:45:51 miod Exp $	*/
d1097 1
a1097 1
			    (xbow_intr_widget_register & ((1UL << 48) - 1));
d1099 1
a1099 1
			int_addr = ((xbow_intr_widget_register >> 30) &
d1850 1
a1850 1
	uint64_t status, ctrl, int_addr;
d1893 21
a1913 8
	 * Configure the direct DMA window to access the low 2GB of memory.
	 * XXX assumes the window is on the same node we are handling
	 * XXX interrupt upon (because of xbow_intr_widget)
	 */
	xbridge_write_reg(xb, BRIDGE_DIR_MAP,
	    (xbow_intr_widget << BRIDGE_DIRMAP_WIDGET_SHIFT) |
	    ((dma_constraint.ucr_low >> BRIDGE_DIRMAP_BASE_SHIFT) &
	     BRIDGE_DIRMAP_BASE_MASK));
d1997 2
a1998 2
	int_addr = ((uint64_t)xbow_intr_widget << 48) |
	    (xbow_intr_widget_register & ((1UL << 48) - 1));
@


1.79
log
@Disable write gathering on devio settings we inherit from ARCS.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.78 2010/12/04 17:06:32 miod Exp $	*/
d48 1
a48 1
#include <uvm/uvm_extern.h>
a77 1
struct xbridge_ate;
a146 9
	 * ATE management.
	 */
	struct mutex	xb_atemtx;
	uint		xb_atecnt;
	struct xbridge_ate	*xb_ate;
	LIST_HEAD(, xbridge_ate) xb_free_ate;
	LIST_HEAD(, xbridge_ate) xb_used_ate;

	/*
a263 10
int	xbridge_address_map(struct xbpci_softc *, paddr_t, bus_addr_t *,
	    bus_addr_t *);
void	xbridge_address_unmap(struct xbpci_softc *, bus_addr_t, bus_size_t);
uint	xbridge_ate_add(struct xbpci_softc *, paddr_t);
void	xbridge_ate_dump(struct xbpci_softc *);
uint	xbridge_ate_find(struct xbpci_softc *, paddr_t);
uint64_t xbridge_ate_read(struct xbpci_softc *, uint);
void	xbridge_ate_unref(struct xbpci_softc *, uint, uint);
void	xbridge_ate_write(struct xbpci_softc *, uint, uint64_t);

a274 1
void	xbridge_ate_setup(struct xbpci_softc *);
a1654 365
 * ATE primer:
 *
 * ATE are iommu translation entries. PCI addresses in the translated
 * window transparently map to the address their ATE point to.
 *
 * Bridge chip have 128 so-called `internal' entries, and can use their
 * optional SSRAM to provide more (up to 65536 entries with 512KB SSRAM).
 * However, due to chip bugs, those `external' entries can not be updated
 * while there is DMA in progress using external entries, even if the
 * updated entries are disjoint from those used by the DMA transfer.
 *
 * XBridge chip extend the internal entries to 1024, and do not provide
 * support for external entries.
 *
 * We limit ourselves to internal entries only. Due to the way we force
 * bus_dmamem_alloc() to use the direct window, there won't hopefully be
 * many concurrent consumers of ATE at once.
 *
 * All ATE share the same page size, which is configurable as 4KB or 16KB.
 *
 * ATE management:
 *
 * An array of internal ATE management structures is allocated, and
 * provides reference counters (since various dma maps could overlap
 * the same 16KB ATE pages).
 *
 * When using ATE in the various bus_dmamap_load*() functions, we try
 * to coalesce individual contiguous pages sharing the same I/O page
 * (and thus the same ATE). However, no attempt is made to optimize
 * entries using contiguous ATEs.
 *
 * ATE are organized in lists of in-use and free entries.
 */

struct xbridge_ate {
	LIST_ENTRY(xbridge_ate)	 xa_nxt;
	uint			 xa_refcnt;
	paddr_t			 xa_pa;
};

#ifdef ATE_DEBUG
void
xbridge_ate_dump(struct xbpci_softc *xb)
{
	struct xbridge_ate *ate;
	uint a;

	printf("%s ATE list (in array order)\n", DEVNAME(xb));
	for (a = 0, ate = xb->xb_ate; a < xb->xb_atecnt; a++, ate++) {
		printf("%03x %p %02u", a, ate->xa_pa, ate->xa_refcnt);
		if ((a % 3) == 2)
			printf("\n");
		else
			printf("  ");
	}
	if ((a % 3) != 0)
		printf("\n");

	printf("%s USED ATE list (in link order)\n", DEVNAME(xb));
	a = 0;
	LIST_FOREACH(ate, &xb->xb_used_ate, xa_nxt) {
		printf("%03x %p %02u",
		    ate - xb->xb_ate, ate->xa_pa, ate->xa_refcnt);
		if ((a % 3) == 2)
			printf("\n");
		else
			printf("  ");
		a++;
	}
	if ((a % 3) != 0)
		printf("\n");

	printf("%s FREE ATE list (in link order)\n", DEVNAME(xb));
	a = 0;
	LIST_FOREACH(ate, &xb->xb_free_ate, xa_nxt) {
		printf("%03x %p %02u",
		    ate - xb->xb_ate, ate->xa_pa, ate->xa_refcnt);
		if ((a % 3) == 2)
			printf("\n");
		else
			printf("  ");
		a++;
	}
	if ((a % 3) != 0)
		printf("\n");
}
#endif

void
xbridge_ate_setup(struct xbpci_softc *xb)
{
	uint64_t ctrl;
	uint a;
	struct xbridge_ate *ate;

	mtx_init(&xb->xb_atemtx, IPL_HIGH);

	if (ISSET(xb->xb_flags, XF_XBRIDGE))
		xb->xb_atecnt = XBRIDGE_INTERNAL_ATE;
	else
		xb->xb_atecnt = BRIDGE_INTERNAL_ATE;

	xb->xb_ate = (struct xbridge_ate *)malloc(xb->xb_atecnt *
	    sizeof(struct xbridge_ate), M_DEVBUF, M_ZERO | M_NOWAIT);
	if (xb->xb_ate == NULL) {
		/* we could run without, but this would be a PITA */
		panic("%s: no memory for ATE management", __func__);
	}

	/*
	 * Setup the ATE lists.
	 */
	LIST_INIT(&xb->xb_free_ate);
	LIST_INIT(&xb->xb_used_ate);
	for (ate = xb->xb_ate; ate != xb->xb_ate + xb->xb_atecnt; ate++)
		LIST_INSERT_HEAD(&xb->xb_free_ate, ate, xa_nxt);

	/*
	 * Switch to 16KB pages.
	 */
	ctrl = xbridge_read_reg(xb, WIDGET_CONTROL);
	xbridge_write_reg(xb, WIDGET_CONTROL,
	    ctrl | BRIDGE_WIDGET_CONTROL_LARGE_PAGES);
	(void)xbridge_read_reg(xb, WIDGET_TFLUSH);

	/*
	 * Initialize all ATE entries to invalid.
	 */
	for (a = 0; a < xb->xb_atecnt; a++)
		xbridge_ate_write(xb, a, ATE_NV);
}

#ifdef unused
uint64_t
xbridge_ate_read(struct xbpci_softc *xb, uint a)
{
	uint32_t lo, hi;
	uint64_t ate;

	/*
	 * ATE can not be read as a whole, and need two 32 bit accesses.
	 */
	hi = xbridge_read_reg(xb, BRIDGE_ATE(a) + 4);
	if (ISSET(xb->xb_flags, XF_XBRIDGE))
		lo = xbridge_read_reg(xb, BRIDGE_ATE(a + 1024) + 4);
	else
		lo = xbridge_read_reg(xb, BRIDGE_ATE(a + 512) + 4);

	ate = (uint64_t)hi;
	ate <<= 32;
	ate |= lo;

	return ate;
}
#endif

void
xbridge_ate_write(struct xbpci_softc *xb, uint a, uint64_t ate)
{
	widget_write_8(xb->xb_regt, xb->xb_regh, BRIDGE_ATE(a), ate);
}

uint
xbridge_ate_find(struct xbpci_softc *xb, paddr_t pa)
{
	uint a;
	struct xbridge_ate *ate;

	/* round to ATE page */
	pa &= ~BRIDGE_ATE_LMASK;

	/*
	 * XXX Might want to build a tree to make this faster than
	 * XXX that stupid linear search. On the other hand there
	 * XXX aren't many ATE entries.
	 */
	LIST_FOREACH(ate, &xb->xb_used_ate, xa_nxt)
		if (ate->xa_pa == pa) {
			a = ate - xb->xb_ate;
#ifdef ATE_DEBUG
			printf("%s: pa %p ate %u (r %u)\n",
			    __func__, pa, a, ate->xa_refcnt);
#endif
			return a;
		}

	return (uint)-1;
}

uint
xbridge_ate_add(struct xbpci_softc *xb, paddr_t pa)
{
	uint a;
	struct xbridge_ate *ate;

	/* round to ATE page */
	pa &= ~BRIDGE_ATE_LMASK;

	if (LIST_EMPTY(&xb->xb_free_ate)) {
#ifdef ATE_DEBUG
		printf("%s: out of ATEs\n", DEVNAME(xb));
#endif
		return (uint)-1;
	}

	ate = LIST_FIRST(&xb->xb_free_ate);
	LIST_REMOVE(ate, xa_nxt);
	LIST_INSERT_HEAD(&xb->xb_used_ate, ate, xa_nxt);
	ate->xa_refcnt = 1;
	ate->xa_pa = pa;

	a = ate - xb->xb_ate;
#ifdef ATE_DEBUG
	printf("%s: pa %p ate %u\n", __func__, pa, a);
#endif

	xbridge_ate_write(xb, a, ate->xa_pa |
	    (xbow_intr_widget << ATE_WIDGET_SHIFT) | ATE_COH | ATE_V);

	return a;
}

void
xbridge_ate_unref(struct xbpci_softc *xb, uint a, uint ref)
{
	struct xbridge_ate *ate;

	ate = xb->xb_ate + a;
#ifdef DIAGNOSTIC
	if (ref > ate->xa_refcnt)
		panic("%s: ate #%u %p has only %u refs but needs to drop %u",
		    DEVNAME(xb), a, ate, ate->xa_refcnt, ref);
#endif
	ate->xa_refcnt -= ref;
	if (ate->xa_refcnt == 0) {
#ifdef ATE_DEBUG
		printf("%s: free ate %u\n", __func__, a);
#endif
		xbridge_ate_write(xb, a, ATE_NV);
		LIST_REMOVE(ate, xa_nxt);
		LIST_INSERT_HEAD(&xb->xb_free_ate, ate, xa_nxt);
	} else {
#ifdef ATE_DEBUG
		printf("%s: unref ate %u (r %u)\n", __func__, a, ate->xa_refcnt);
#endif
	}
}

/*
 * Attempt to map the given address, either through the direct map, or
 * using an ATE.
 */
int
xbridge_address_map(struct xbpci_softc *xb, paddr_t pa, bus_addr_t *mapping,
    bus_addr_t *limit)
{
#if 0
	struct xbridge_ate *ate;
	uint a;
#endif
	bus_addr_t ba;

	/*
	 * Try the direct DMA window first.
	 */

	ba = (bus_addr_t)pa;

	if (ba < BRIDGE_DMA_DIRECT_LENGTH) {
		*mapping = ba + BRIDGE_DMA_DIRECT_BASE;
		*limit = BRIDGE_DMA_DIRECT_LENGTH + BRIDGE_DMA_DIRECT_BASE;
		return 0;
	}

#if 0
	/*
	 * Did not fit, so now we need to use an ATE.
	 * Check if an existing ATE would do the job; if not, try and
	 * allocate a new one.
	 */

	mtx_enter(&xb->xb_atemtx);

	a = xbridge_ate_find(xb, pa);
	if (a != (uint)-1) {
		ate = xb->xb_ate + a;
		ate->xa_refcnt++;
	} else
		a = xbridge_ate_add(xb, pa);

	if (a != (uint)-1) {
		ba = ATE_ADDRESS(a, BRIDGE_ATE_LSHIFT);
		/*
		 * Ask for byteswap during DMA. On Bridge (i.e non-XBridge),
		 * this setting is device-global and is enforced by
		 * BRIDGE_DEVICE_SWAP_PMU set in the devio register.
		 */
		if (ISSET(xb->xb_flags, XF_XBRIDGE))
			ba |= XBRIDGE_DMA_TRANSLATED_SWAP;
#ifdef ATE_DEBUG
		printf("%s: ate %u through %p\n", __func__, a, ba);
#endif
		*mapping = ba + (pa & BRIDGE_ATE_LMASK);
		*limit = ba + BRIDGE_ATE_LSIZE;
		mtx_leave(&xb->xb_atemtx);
		return 0;
	}

	printf("%s: out of ATE\n", DEVNAME(xb));
#ifdef ATE_DEBUG
	xbridge_ate_dump(xb);
#endif

	mtx_leave(&xb->xb_atemtx);
#endif

	/*
	 * We could try allocating a bounce buffer here.
	 * Maybe once there is a MI interface for this...
	 */

	return EINVAL;
}

void
xbridge_address_unmap(struct xbpci_softc *xb, bus_addr_t ba, bus_size_t len)
{
#if 0
	uint a;
	uint refs;
#endif

	/*
	 * If this address matches an ATE, unref it, and make it
	 * available again if the reference count drops to zero.
	 */
	if (ba < BRIDGE_DMA_TRANSLATED_BASE || ba >= BRIDGE_DMA_DIRECT_BASE)
		return;

#if 0
	if (ba & XBRIDGE_DMA_TRANSLATED_SWAP)
		ba &= ~XBRIDGE_DMA_TRANSLATED_SWAP;

	a = ATE_INDEX(ba, BRIDGE_ATE_LSHIFT);
#ifdef DIAGNOSTIC
	if (a >= xb->xb_atecnt)
		panic("%s: bus address %p references nonexisting ATE %u/%u",
		    __func__, ba, a, xb->xb_atecnt);
#endif

	/*
	 * Since we only coalesce contiguous pages or page fragments in
	 * the maps, and we made sure not to cross I/O page boundaries,
	 * we have one reference per cpu page the range [ba, ba+len-1]
	 * hits.
	 */
	refs = 1 + atop(ba + len - 1) - atop(ba);

	mtx_enter(&xb->xb_atemtx);
	xbridge_ate_unref(xb, a, refs);
	mtx_leave(&xb->xb_atemtx);
#endif
}

/*
d1662 1
a1662 1
	struct xbpci_softc *xb = t->_cookie;
d1695 9
d1708 2
a1709 4
		if (xbridge_address_map(xb, pa, &busaddr, &endaddr) != 0) {
			rc = ENOMEM;
			goto fail_unmap;
		}
d1748 1
a1748 4
				if (++seg >= map->_dm_segcnt) {
					/* drop partial ATE reference */
					xbridge_address_unmap(xb, busaddr,
					    sgsize);
a1749 1
				}
d1778 1
a1778 6
	/*
	 * If control goes there, we need to unref all our ATE, if any.
	 */
	for (seg = 0; seg < map->_dm_segcnt; seg++) {
		xbridge_address_unmap(xb, map->dm_segs[seg].ds_addr,
		    map->dm_segs[seg].ds_len);
a1779 1
	}
d1790 1
a1790 1
	struct xbpci_softc *xb = t->_cookie;
d1793 1
a1793 3
	for (seg = 0; seg < map->_dm_segcnt; seg++) {
		xbridge_address_unmap(xb, map->dm_segs[seg].ds_addr,
		    map->dm_segs[seg].ds_len);
a1794 1
	}
d1810 1
a1810 1
	 * Limit bus_dma'able memory to the first 2GB of physical memory.
d1815 2
a1816 2
	low = 0;
	high = low + BRIDGE_DMA_DIRECT_LENGTH - 1;
d1833 1
a1833 1
	return pa + BRIDGE_DMA_DIRECT_BASE;
d1839 1
a1839 1
	return addr - BRIDGE_DMA_DIRECT_BASE;
d1894 2
a1895 1
	 * XXX assumes masternasid is 0
a1896 1

d1898 3
a1900 8
	    xbow_intr_widget << BRIDGE_DIRMAP_WIDGET_SHIFT);

	/*
	 * Figure out how many ATE we can use for non-direct DMA, and
	 * setup our ATE management code.
	 */

	xbridge_ate_setup(xb);
@


1.78
log
@Introduce a new pci routine, pci_conf_size(), which returns the size of a
given pcitag_t configuration address space. Currently, all pci controllers
will return the usual 0x100 bytes of PCI configuration space, but this will
eventually change on PCIe-capable controlers.
ok kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.77 2010/11/27 18:21:05 miod Exp $	*/
d324 6
d1215 1
a1215 1
		xbridge_read_reg(xb, BRIDGE_DEVICE_WBFLUSH(xih->xih_device));
d1666 1
a1666 1
			xbridge_read_reg(xb, BRIDGE_DEVICE_WBFLUSH(d));
a1694 3
 * In order to minimize the number of ATE used by the various drivers,
 * we use 16KB pages, at the expense of trickier code to account for
 * ATE shared by various dma maps.
d2368 1
a2368 1
	 * Bridge level.
d2498 1
a2498 1
		else
d2500 2
a2501 1
		total += rrb[i];
a2652 5
		if (ISSET(xb->xb_flags, XF_XBRIDGE))
			devio &= ~BRIDGE_DEVICE_SWAP_PMU;
		else
			devio |= BRIDGE_DEVICE_SWAP_PMU;
		devio |= BRIDGE_DEVICE_SWAP_DIR;
d2657 10
a2666 1
			    ~(BRIDGE_DEVICE_SWAP_DIR | BRIDGE_DEVICE_SWAP_PMU);
d3500 1
a3500 1
			 * if successfull, will work as a 32 bit i/o range.
d3555 1
a3555 1
			 * 30 bits, so our allocation, if successfull, will
@


1.77
log
@Missed one rbus_new_body() call in previous change.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.76 2010/09/22 02:28:37 jsg Exp $	*/
d207 1
d584 1
d694 24
@


1.76
log
@remove unused offset argument to rbus functions
ok krw@@ kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.75 2010/09/20 06:33:47 matthew Exp $	*/
d3600 1
a3600 2
		rb = rbus_new_body(pa->pa_iot, NULL, 0, 0,
		    RBUS_SPACE_INVALID);
d3636 1
a3636 2
		rb = rbus_new_body(pa->pa_iot, NULL, 0, 0, 0,
		    RBUS_SPACE_INVALID);
@


1.75
log
@Get rid of evcount's support for arranging counters in a tree
hierarchy.  Everything attached to a single root node anyway, so at
best we had a bush.

"i think it is good" deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.74 2010/08/23 16:56:18 miod Exp $	*/
d3589 1
a3589 1
			    start, end - start, 0);
d3600 1
a3600 1
		rb = rbus_new_body(pa->pa_iot, NULL, 0, 0, 0,
d3626 1
a3626 1
			    start, ex->ex_end - start, 0);
@


1.74
log
@Implement bus_space_barrier() on sgi; on xbridge, this will also flush
the pci write buffers.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.73 2010/08/23 16:55:07 miod Exp $	*/
d1074 1
a1074 1
	evcount_attach(&xih->xih_count, name, &xi->xi_intrsrc, &evcount_intr);
@


1.73
log
@Rework the logic of xbridge pci_conf_{read,write} to avoid doing the disable
bridge interrupts dance when trying to access an uninplemented ioc3 register.
Makes PIC handling simpler as a bonus.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.72 2010/05/09 18:36:07 miod Exp $	*/
d257 3
d550 1
d566 1
d1593 44
@


1.72
log
@Program a larger PCI retry hold interval if there is a Lucent USB controller
on the bus, to workaround timeout problems, according to IRIX knowledge which
made its way to Linux.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.71 2010/04/21 03:03:26 deraadt Exp $	*/
a698 5
	/* Disable interrupts on this bridge (especially error interrupts) */
	xbridge_write_reg(xb, BRIDGE_IER, 0);
	(void)xbridge_read_reg(xb, WIDGET_TFLUSH);
	s = splhigh();

a699 15
	if (bus != 0) {
		xbridge_write_reg(xb, BRIDGE_PCI_CFG,
		    (bus << 16) | (dev << 11));
		pa = xb->xb_regh + BRIDGE_PCI_CFG1_SPACE;
	} else {
		if (ISSET(xb->xb_flags, XF_PIC)) {
			/*
			 * On PIC, device 0 in configuration space is the
			 * PIC itself, device slots are offset by one.
			 */
			pa = xb->xb_regh + BRIDGE_PCI_CFG_SPACE +
			    ((dev + 1) << 12);
		} else
			pa = xb->xb_regh + BRIDGE_PCI_CFG_SPACE + (dev << 12);
	}
d741 22
d766 4
a771 3
	splx(s);
	xbridge_write_reg(xb, BRIDGE_IER, xb->xb_ier);
	(void)xbridge_read_reg(xb, WIDGET_TFLUSH);
a783 5
	/* Disable interrupts on this bridge (especially error interrupts) */
	xbridge_write_reg(xb, BRIDGE_IER, 0);
	(void)xbridge_read_reg(xb, WIDGET_TFLUSH);
	s = splhigh();

a784 15
	if (bus != 0) {
		xbridge_write_reg(xb, BRIDGE_PCI_CFG,
		    (bus << 16) | (dev << 11));
		pa = xb->xb_regh + BRIDGE_PCI_CFG1_SPACE;
	} else {
		if (ISSET(xb->xb_flags, XF_PIC)) {
			/*
			 * On PIC, device 0 in configuration space is the
			 * PIC itself, device slots are offset by one.
			 */
			pa = xb->xb_regh + BRIDGE_PCI_CFG_SPACE +
			    ((dev + 1) << 12);
		} else
			pa = xb->xb_regh + BRIDGE_PCI_CFG_SPACE + (dev << 12);
	}
d823 22
d847 4
a851 4

	splx(s);
	xbridge_write_reg(xb, BRIDGE_IER, xb->xb_ier);
	(void)xbridge_read_reg(xb, WIDGET_TFLUSH);
d3588 1
a3588 1
		rb = rbus_new_body(pa->pa_iot, NULL, NULL, 0, 0, 0,
@


1.71
log
@more cleanup to cope with the change that tries to make proc.h not act
like it is everything.h
ok tedu
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.70 2010/04/06 19:12:34 miod Exp $	*/
d2251 19
@


1.70
log
@Obtain struct sgi_device_location for the console input and output devices,
and compare against them when attaching potential console drivers, to figure
out whether they indeed are acting are console devices or not.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.69 2010/04/02 12:11:55 jsg Exp $	*/
d35 1
@


1.69
log
@Remove parent/slave mode of rbus as nothing uses it.
ok kettenis, sgi usage of rbus_new_body() pointed out by miod
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.68 2010/03/28 17:12:41 miod Exp $	*/
a217 1
int16_t	xbridge_get_nasid(void *);
d219 1
a578 1
	xb->xb_pc.pc_get_nasid = xbridge_get_nasid;
d580 1
d848 2
a849 2
int16_t
xbridge_get_nasid(void *cookie)
d853 1
a853 1
	return xb->xb_nasid;
d857 1
a857 1
xbridge_get_widget(void *cookie)
d859 1
d862 12
a873 1
	return xb->xb_widget;
@


1.68
log
@Correctly account devio usage, instead of relying upon unused devio registers
being set to zero; this allows a full PIC bus to correctly configure I/O
resources.

While there, when initializing a ppb, setup I/O resources before memory
resources; without this a ppb connected to a PIC could not get I/O resources
if devices behind it would use both I/O and memory resources.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.67 2010/03/07 13:39:00 miod Exp $	*/
d3514 1
a3514 1
		rb = rbus_new_body(pa->pa_iot, NULL, NULL, 0, 0, 0,
@


1.67
log
@Add an MD interface for PCI drivers to be able to retrieve the node and widget
number the PCI bus they are on is connected to. Will be used shortly to help
the console device selection logic.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.66 2009/12/26 20:16:19 miod Exp $	*/
d144 1
d283 1
a283 1
void	xbridge_set_devio(struct xbpci_softc *, int, uint32_t);
d2534 1
a2534 1
		 * Enable byte swapping for DMA, except on IOC3 and
d2561 1
a2561 1
			xbridge_set_devio(xb, dev, devio);
d2570 1
a2570 1
		xbridge_set_devio(xb, dev, devio);
d2702 1
a2702 3
			if (devio == 0)
				continue;
			if (ISSET(devio, BRIDGE_DEVICE_IO_MEM))
d2808 3
d2990 1
a2991 1
				rc |= XR_MEM;
d3000 1
a3000 1
				rc |= XR_MEM | XR_MEM_OFLOW | XR_MEM_OFLOW_S;
d3003 1
a3004 1
				rc |= XR_IO;
d3013 1
a3013 1
				rc |= XR_IO | XR_IO_OFLOW | XR_IO_OFLOW_S;
d3026 1
a3027 1
				rc |= XR_MEM;
d3036 1
a3036 1
				rc |= XR_MEM | XR_MEM_OFLOW | XR_MEM_OFLOW_S;
d3184 1
a3184 1
	else
d3188 5
d3195 1
a3195 1
	else
d3199 5
d3220 3
d3254 1
a3254 1
			    (baseio >> BRIDGE_DEVICE_BASE_SHIFT));
d3280 1
a3280 1
			    (baseio >> BRIDGE_DEVICE_BASE_SHIFT));
d3339 9
a3347 3
	exsize = *memend;
	*memstart = 0xffffffff;
	*memend = 0;
d3358 2
a3359 2
		if (devio_idx < 0 && xb->xb_memex == NULL)
			xb->xb_memex = xbridge_mapping_setup(xb, 0);
d3362 1
a3362 1
		if (devio_idx < 0 && xb->xb_memex == NULL) {
d3373 4
a3376 5
			    BRIDGE_DEVICE_IO_MEM |
			    (base >> BRIDGE_DEVICE_BASE_SHIFT));
			*memstart = base;
			*memend = base + BRIDGE_DEVIO_SIZE(devio_idx) - 1;
		} else if (xb->xb_memex != NULL) {
d3378 3
a3380 4
			 * We know that the direct memory resource range fits
			 * within the 32 bit address space, and is limited to
			 * 30 bits, so our allocation, if successfull, will
			 * work as a 32 bit memory range.
d3382 2
a3383 2
			if (exsize < 1UL << 20)
				exsize = 1UL << 20;
d3385 2
a3386 2
				if (extent_alloc(xb->xb_memex, exsize,
				    1UL << 20, 0, 0, EX_NOWAIT | EX_MALLOCOK,
d3388 2
a3389 2
					*memstart = exstart;
					*memend = exstart + exsize - 1;
d3393 1
a3393 1
				if (exsize < 1UL << 20)
d3399 3
a3401 3
	exsize = *ioend;
	*iostart = 0xffffffff;
	*ioend = 0;
d3412 2
a3413 2
		if (devio_idx < 0 && xb->xb_ioex == NULL)
			xb->xb_ioex = xbridge_mapping_setup(xb, 1);
d3416 1
a3416 1
		if (devio_idx < 0 && xb->xb_ioex == NULL) {
d3427 5
a3431 4
			    (base >> BRIDGE_DEVICE_BASE_SHIFT));
			*iostart = base;
			*ioend = base + BRIDGE_DEVIO_SIZE(devio_idx) - 1;
		} else if (xb->xb_ioex != NULL) {
d3433 4
a3436 3
			 * We know that the direct I/O resource range fits
			 * within the 32 bit address space, so our allocation,
			 * if successfull, will work as a 32 bit i/o range.
d3438 2
a3439 2
			if (exsize < 1UL << 12)
				exsize = 1UL << 12;
d3441 2
a3442 2
				if (extent_alloc(xb->xb_ioex, exsize,
				    1UL << 12, 0, 0, EX_NOWAIT | EX_MALLOCOK,
d3444 2
a3445 2
					*iostart = exstart;
					*ioend = exstart + exsize - 1;
d3449 1
a3449 1
				if (exsize < 1UL << 12)
d3562 4
d3571 1
a3571 1
	if (xb->xb_devices[dev].devio == 0) {
d3573 5
a3577 1
		    wantlarge ? BRIDGE_DEVIO_LARGE : BRIDGE_DEVIO_SHORT)
d3579 1
d3588 1
a3588 1
		if (xb->xb_devices[dev].devio != 0)
d3595 5
a3599 1
		    wantlarge ? BRIDGE_DEVIO_LARGE : BRIDGE_DEVIO_SHORT)
d3601 1
d3604 4
d3612 1
a3612 1
xbridge_set_devio(struct xbpci_softc *xb, int dev, uint32_t devio)
d3617 2
d3620 2
a3621 1
	printf("device %d: new devio %08x\n", dev, devio);
@


1.66
log
@Register an interrupt handler for PCI error conditions (as well as xtalk
errors at the widget level). Extremely crude for now.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.65 2009/12/25 21:02:18 miod Exp $	*/
d217 2
d578 2
d845 16
@


1.65
log
@Pass both the virtual address and the physical address of the memory range
when invoking the cache functions. The physical address is needed when
operating on physically-indexed caches, such as the L2 cache on Loongson
processors.

Preprocessor abuse makes sure that the physical address computation gets
compiled out when running on a kernel compiled for virtually-indexed
caches only, such as the sgi kernel.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.64 2009/11/25 11:23:30 miod Exp $	*/
d87 1
d119 1
d123 1
a123 1
	bus_space_tag_t xb_regt;
d133 4
d218 2
a219 1
int	xbridge_intr_handler(void *);
d276 3
d295 2
a296 1
void	xbridge_setup(struct xbpci_softc *);
d433 1
d478 1
d489 1
d593 2
a594 1
	xbridge_setup(xb);
d623 2
d630 3
a632 2
	printf("not enough memory to build bus access structures\n");
	return;
d693 3
a695 1
	/* XXX should actually disable interrupts? */
d761 3
a763 1
	return(data);
d775 3
a777 1
	/* XXX should actually disable interrupts? */
d839 2
d1012 1
a1012 1
		if (xbow_intr_establish(xbridge_intr_handler, xi, intrsrc,
d1046 1
d1049 1
a1049 2
		xbridge_write_reg(xb, BRIDGE_IER,
		    xbridge_read_reg(xb, BRIDGE_IER) | (1 << intrbit));
d1080 1
d1082 1
a1082 2
		xbridge_write_reg(xb, BRIDGE_IER,
		    xbridge_read_reg(xb, BRIDGE_IER) & ~(1 << intrbit));
d1107 15
a1121 1
xbridge_intr_handler(void *v)
d1142 10
d2121 1
a2121 1
void
d2209 11
d2238 1
a2238 1
		xbridge_write_reg(xb, BRIDGE_IER, 1 << 6);
d2241 2
a2242 1
		xbridge_write_reg(xb, BRIDGE_IER, 0);
d2249 89
@


1.64
log
@Allow xbow_intr_establish() callers to provide optional storage for the
struct intrhand, instead of having it malloc()'ed.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.63 2009/11/19 06:07:05 miod Exp $	*/
d870 1
a870 1
	xbridge_decompose_tag(pa->pa_pc, pa->pa_tag, &bus, &device, NULL);
d1936 3
a1938 3
			baddr = (pa + map->_dm_boundary) & bmask;
			if (sgsize > (baddr - pa))
				sgsize = baddr - pa;
d1948 2
a1949 1
			map->dm_segs[seg]._ds_vaddr = (vaddr_t)vaddr;
d1968 2
a1969 1
				map->dm_segs[seg]._ds_vaddr = (vaddr_t)vaddr;
@


1.63
log
@It turns out that the 2GB contiguous DMA direct map window also needs
to be aligned on a 2GB boundary. Therefore the `add 512MB' bit used on
Octane does not give us a 0.5GB-2.5GB usable DMA range, but a 0.5GB-2GB
range; trying to use address in the 2GB-2.5GB range would cause PCI
DMA errors at the xbridge level.

There is no real benefit in using it, since this required us to keep
subtracting or adding 0.5GB when converting DMA address to physical
memory address or the other way around.

So stop using it; this makes a few parts of the code simpler (and until
bounce buffers are implemented, Octane systems will not use more than
1.5GB of memory).
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.62 2009/11/18 19:05:53 miod Exp $	*/
d987 1
a987 1
		    IPL_BIO, NULL)) {
@


1.62
log
@Move widget register information apart from xbow software interface, and
update #include needs. No functional change.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.61 2009/11/11 15:29:31 miod Exp $	*/
d1765 1
d1767 2
a1769 1
	uint a;
d1775 1
a1775 6
#ifdef TGT_OCTANE
	if (sys_config.system_type == SGI_OCTANE)
		ba = (bus_addr_t)pa - IP30_MEMORY_BASE;
	else
#endif
		ba = (bus_addr_t)pa;
d1783 1
d1823 1
d1836 1
d1839 1
d1848 1
d1870 1
d2038 1
a2038 14
	switch (sys_config.system_type) {
	default:
#ifdef TGT_ORIGIN
	case SGI_IP27:
	case SGI_IP35:
		low = 0;
		break;
#endif
#ifdef TGT_OCTANE
	case SGI_OCTANE:
		low = IP30_MEMORY_BASE;
		break;
#endif
	}
a2055 5
#ifdef TGT_OCTANE
	if (sys_config.system_type == SGI_OCTANE)
		pa -= IP30_MEMORY_BASE;
#endif

d2062 1
a2062 8
	paddr_t pa = addr - BRIDGE_DMA_DIRECT_BASE;

#ifdef TGT_OCTANE
	if (sys_config.system_type == SGI_OCTANE)
		pa += IP30_MEMORY_BASE;
#endif

	return pa;
d2120 2
a2121 6
	if (sys_config.system_type == SGI_OCTANE)
		xbridge_write_reg(xb, BRIDGE_DIR_MAP, BRIDGE_DIRMAP_ADD_512MB |
		    (xbow_intr_widget << BRIDGE_DIRMAP_WIDGET_SHIFT));
	else
		xbridge_write_reg(xb, BRIDGE_DIR_MAP,
		    xbow_intr_widget << BRIDGE_DIRMAP_WIDGET_SHIFT);
@


1.61
log
@It turns out PCI IOC3 card which embed both the Ethernet controller and the
superio chip interrupt on two different pins (yet do not advertize
themselves as a multi-function device, of course).

So, on one hand, this makes the ioc attachment code simpler, because it
simply needs to map interrupt pins A and B, and another hand, this moves
all the interrupt knowledge to the PCI bridge driver, since routing of pin
B differs whether the device is the onboard IOC3 chip (and able to use
any of the 8 bridge interrupt sources...) or on a PCI board (with pin
mapping sane, since controlled by the bridge).

This makes superio interrupts on CADduo boards work. Tested to cause
no regressions on Origin 200, Octane and Fuel.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.60 2009/11/07 18:56:55 miod Exp $	*/
d60 1
@


1.60
log
@Replace option TGT_ORIGIN200 and TGT_ORIGIN2000 with a single option,
TGT_ORIGIN, which enables support for all IP27 and IP35 systems. The original
two options have always been used together, and go back to when pefo thought
supporting multiple nodes would be significant work. Since an Origin 200
can be a dual-node system, making a distinction between single node and
multiple node systems is a moot point anyway.

Be sure to rerun config(8) before rebuilding a kernel.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.59 2009/11/07 14:49:02 miod Exp $	*/
d172 5
d789 1
a789 1
			 * Some IOC models do not support having this bit
d878 5
a882 1
		 * For IOC devices, the real information is in pa_intrline.
d884 1
d887 23
a909 2
			intr = pa->pa_intrline;
		} else {
d2133 1
a2133 2
			xb->xb_devices[dev].id =
			    PCI_ID_CODE(PCI_VENDOR_INVALID, 0xffff);
d2232 1
a2232 2
		if (dev >= xb->xb_nslots ||
		    PCI_VENDOR(xb->xb_devices[dev].id) == PCI_VENDOR_INVALID)
d2343 1
a2343 3
		id = xb->xb_devices[dev].id;

		if (PCI_VENDOR(id) == PCI_VENDOR_INVALID || PCI_VENDOR(id) == 0)
d2374 1
d2459 1
a2459 3
		id = xb->xb_devices[dev].id;

		if (PCI_VENDOR(id) == PCI_VENDOR_INVALID || PCI_VENDOR(id) == 0)
a3392 2
	pcireg_t id;

d3413 1
a3413 2
		id = xb->xb_devices[dev].id;
		if (PCI_VENDOR(id) != PCI_VENDOR_INVALID && PCI_VENDOR(id) != 0)
@


1.59
log
@Change sgi system identification from a single system type list, to a smaller
system type list (which really is the system family) and a subsystem type.

No functional change yet.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.58 2009/10/26 18:37:13 miod Exp $	*/
d1329 1
a1329 1
#if defined(TGT_ORIGIN200) || defined(TGT_ORIGIN2000) || defined(DIAGNOSTIC)
d1339 1
a1339 1
#if defined(TGT_ORIGIN200) || defined(TGT_ORIGIN2000)
d1431 1
a1431 1
#if defined(TGT_ORIGIN200) || defined(TGT_ORIGIN2000) || defined(DIAGNOSTIC)
d1442 1
a1442 1
#if defined(TGT_ORIGIN200) || defined(TGT_ORIGIN2000)
d2005 1
a2005 1
#if defined(TGT_ORIGIN200) || defined(TGT_ORIGIN2000)
d2011 1
a2011 1
#if defined(TGT_OCTANE)
@


1.58
log
@Make pci_intr_string() on xbridge return both the xbridge irq and the crossbow
irq we route it to; this makes clear that devices connected to different
xbridges but using the same xbridge irq are actually not shared at all; and
this also helps figure out which device cause spurious interrupts.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.57 2009/10/26 18:13:34 miod Exp $	*/
d2006 2
a2007 2
	case SGI_O200:
	case SGI_O300:
@


1.57
log
@Add support for the Octane power button to power(4). Took me a while to
figure out how the interrupt was routed from xbridge to xheart... (it bypasses
the regular `have xbridge send a xio interrupt packet' mechanism)
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.56 2009/10/26 18:11:27 miod Exp $	*/
d128 1
d894 2
a895 1
	static char str[16];
d897 4
a900 2
	snprintf(str, sizeof(str), "irq %d", XBRIDGE_INTR_BIT(ih));
	return(str);
d937 3
d972 1
a972 1
	evcount_attach(&xih->xih_count, name, &xi->xi_intrbit, &evcount_intr);
d1054 2
a1055 3
	int rc = 0;
	int spurious;
	uint32_t isr;
d1057 1
d1070 7
a1076 2
	if ((isr & (1 << xi->xi_intrbit)) == 0) {
		spurious = 1;
d1081 15
a1095 8
	} else
		spurious = 0;

	LIST_FOREACH(xih, &xi->xi_handlers, xih_nxt) {
		splraise(xih->xih_level);
		if ((*xih->xih_func)(xih->xih_arg) != 0) {
			xih->xih_count.ec_count++;
			rc = 1;
d1097 4
a1100 7
		/*
		 * No need to lower spl here, as our caller will lower
		 * spl upon our return.
		 * However that splraise() is necessary so that interrupt
		 * handler code calling splx() will not cause our interrupt
		 * source to be unmasked.
		 */
a1101 2
	if (rc == 0 && spurious == 0)
		printf("%s: spurious irq %d\n", DEVNAME(xb), xi->xi_intrbit);
d1124 1
a1124 1
	return 1;
@


1.56
log
@Add new xbow routines to explicitely trigger or clear an interrupt source,
instead of embedding that knowledge in xbridge(4); will be used elsewhere
shortly.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.55 2009/10/22 22:08:54 miod Exp $	*/
d2139 1
d2144 7
d2153 9
a2163 3
	xbridge_write_reg(xb, BRIDGE_IER, 0);
	xbridge_write_reg(xb, BRIDGE_INT_MODE, 0);
	xbridge_write_reg(xb, BRIDGE_INT_DEV, 0);
@


1.55
log
@Completely overhaul interrupt handling on sgi. Cpu state now only stores a
logical IPL level, and per-platform (IP27/IP30/IP32) code will from the
necessary hardware mask registers.

This allows the use of more than one interrupt mask register. Also, the
generic (platform independent) interrupt code shrinks a lot, and the actual
interrupt handler chains and masking information is now per-platform private
data.

Interrupt dispatching is generated from a template; more routines will be
added to the template to reduce platform-specific changes and share as much
code as possible.

Tested on IP27, IP30, IP32 and IP35.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.54 2009/10/22 19:55:45 miod Exp $	*/
a56 1
#include <sgi/xbow/hub.h>
a63 1
#include <sgi/xbow/xheartreg.h>
d1106 2
a1107 21
		if (xbridge_read_reg(xb, BRIDGE_ISR) & (1 << xi->xi_intrbit)) {
			switch (sys_config.system_type) {
#if defined(TGT_OCTANE)
			case SGI_OCTANE:
			    {
				paddr_t heart;
				heart = PHYS_TO_XKPHYS(HEART_PIU_BASE, CCA_NC);
				*(volatile uint64_t *)(heart + HEART_ISR_SET) =
				    xi->xi_intrsrc;
			    }
				break;
#endif
#if defined(TGT_ORIGIN200) || defined(TGT_ORIGIN2000)
			case SGI_O200:
			case SGI_O300:
				IP27_RHUB_PI_S(xb->xb_nasid, 0, HUBPI_IR_CHANGE,
				    PI_IR_SET | xi->xi_intrsrc);
				break;
#endif
			}
		}
@


1.54
log
@Introduce a logical xbpci(4) device between xbridge and pci, since more than
one pci bus can attach to an xbridge (if PIC) and both being `bus 0' would
make dmesg confusing.
While there, seize the opportunity of this new dmesg line to display the
bus mode (PCI or PCIX) and speed.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.53 2009/10/16 14:07:31 miod Exp $	*/
d1075 1
a1075 1
		splraise(imask[xih->xih_level]);
d1080 7
@


1.53
log
@Make Octane kernels compile again after recent changes. My bad.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.52 2009/10/15 23:40:49 miod Exp $	*/
d73 4
a79 1
struct xbridge_softc;
d81 15
a95 2
struct xbridge_bus {
	struct xbridge_softc *xb_sc;
d111 8
a118 4
	int		xb_flags;	/* copy of xbridge_softc value */
	int16_t		xb_nasid;	/* copy of xbridge_softc value */
	int		xb_widget;	/* copy of xbridge_softc value */
	uint		xb_devio_skew;	/* copy of xbridge_softc value */
a165 7
	int		sc_flags;
#define	XF_XBRIDGE		0x01	/* is either PIC or XBridge */
#define	XF_PIC			0x02	/* is PIC */
#define	XF_NO_DIRECT_IO		0x04	/* no direct I/O mapping */
	int16_t		sc_nasid;
	int		sc_widget;
	uint		sc_devio_skew;	/* upper bits of devio ARCS mappings */
a168 1
	struct xbridge_bus	sc_bus[MAX_BUSES];
d171 1
a171 1
#define	DEVNAME(xb)	((xb)->xb_sc->sc_dev.dv_xname)
d174 1
a174 1
	sizeof(struct xbridge_softc), xbridge_match, xbridge_attach,
d178 5
a182 1
	NULL, "xbridge", DV_DULL,
d185 3
a187 1
void	xbridge_attach_bus(struct xbridge_softc *, uint, bus_space_tag_t);
d254 1
a254 1
int	xbridge_address_map(struct xbridge_bus *, paddr_t, bus_addr_t *,
d256 7
a262 7
void	xbridge_address_unmap(struct xbridge_bus *, bus_addr_t, bus_size_t);
uint	xbridge_ate_add(struct xbridge_bus *, paddr_t);
void	xbridge_ate_dump(struct xbridge_bus *);
uint	xbridge_ate_find(struct xbridge_bus *, paddr_t);
uint64_t xbridge_ate_read(struct xbridge_bus *, uint);
void	xbridge_ate_unref(struct xbridge_bus *, uint, uint);
void	xbridge_ate_write(struct xbridge_bus *, uint, uint64_t);
d264 2
a265 2
int	xbridge_allocate_devio(struct xbridge_bus *, int, int);
void	xbridge_set_devio(struct xbridge_bus *, int, uint32_t);
d267 1
a267 1
int	xbridge_resource_explore(struct xbridge_bus *, pcitag_t,
d269 1
a269 1
void	xbridge_resource_manage(struct xbridge_bus *, pcitag_t,
d272 4
a275 4
void	xbridge_ate_setup(struct xbridge_bus *);
void	xbridge_device_setup(struct xbridge_bus *, int, int, uint32_t);
int	xbridge_extent_chomp(struct xbridge_bus *, struct extent *);
void	xbridge_extent_setup(struct xbridge_bus *);
d277 4
a280 4
	xbridge_mapping_setup(struct xbridge_bus *, int);
void	xbridge_resource_setup(struct xbridge_bus *);
void	xbridge_rrb_setup(struct xbridge_bus *, int);
void	xbridge_setup(struct xbridge_bus *);
d290 1
a290 1
xbridge_read_reg(struct xbridge_bus *xb, bus_addr_t a)
d295 1
a295 1
xbridge_write_reg(struct xbridge_bus *xb, bus_addr_t a, uint64_t v)
d357 3
a361 3
	sc->sc_nasid = xaa->xaa_nasid;
	sc->sc_widget = xaa->xaa_widget;

d367 1
a367 1
			sc->sc_flags = xbridge_devices[i].flags;
d372 2
a373 2
	if (ISSET(sc->sc_flags, XF_PIC))
		SET(sc->sc_flags, XF_XBRIDGE | XF_NO_DIRECT_IO);
d375 2
a376 2
	if (!ISSET(sc->sc_flags, XF_XBRIDGE) && xaa->xaa_revision < 4)
		SET(sc->sc_flags, XF_NO_DIRECT_IO);
d399 2
a400 2
	    sc->sc_widget == IP30_BRIDGE_WIDGET)
		sc->sc_devio_skew = 0;
d403 1
a403 1
		sc->sc_devio_skew = sc->sc_widget;
d405 1
a405 2
	sc->sc_nbuses =
	    ISSET(sc->sc_flags, XF_PIC) ? PIC_NBUSES : BRIDGE_NBUSES;
d411 42
a452 2
	for (i = 0; i < sc->sc_nbuses; i++)
		xbridge_attach_bus(sc, i, &sc->sc_regt);
d456 1
a456 1
xbridge_attach_bus(struct xbridge_softc *sc, uint busno, bus_space_tag_t regt)
d458 2
a459 1
	struct xbridge_bus *xb = &sc->sc_bus[busno];
d462 9
a470 6
	xb->xb_sc = sc;
	xb->xb_busno = busno;
	xb->xb_flags = sc->sc_flags;
	xb->xb_nasid = sc->sc_nasid;
	xb->xb_widget = sc->sc_widget;
	xb->xb_devio_skew = sc->sc_devio_skew;
d472 1
a472 1
	if (ISSET(sc->sc_flags, XF_PIC)) {
d488 2
a489 2
	xb->xb_regt = regt;
	if (bus_space_map(regt, busno != 0 ? BRIDGE_BUS_OFFSET : 0,
d491 1
a491 2
		printf("%s: unable to map control registers for bus %u\n",
		    DEVNAME(xb), busno);
d510 1
a510 1
	bcopy(regt, xb->xb_mem_bus_space, sizeof(*xb->xb_mem_bus_space));
d525 1
a525 1
	bcopy(regt, xb->xb_io_bus_space, sizeof(*xb->xb_io_bus_space));
d575 1
d600 1
a600 1
	config_found(&sc->sc_dev, &pba, xbridge_print);
d608 1
a608 2
	printf("%s: not enough memory to build bus %u access structures\n",
	    DEVNAME(xb), busno);
d613 1
a613 1
xbridge_print(void *aux, const char *pnp)
d655 1
a655 1
	struct xbridge_bus *xb = cookie;
d663 1
a663 1
	struct xbridge_bus *xb = cookie;
d742 1
a742 1
	struct xbridge_bus *xb = cookie;
d832 1
a832 1
	struct	xbridge_bus	*xi_bus;
d847 1
a847 1
	struct xbridge_bus *xb = pa->pa_pc->pc_conf_v;
d905 1
a905 1
	struct xbridge_bus *xb = (struct xbridge_bus *)cookie;
d1008 1
a1008 1
	struct xbridge_bus *xb = cookie;
d1047 1
a1047 1
	struct xbridge_bus *xb = xi->xi_bus;
d1262 1
a1262 1
	struct xbridge_bus *xb = (struct xbridge_bus *)t->bus_private;
d1305 1
a1305 1
	struct xbridge_bus *xb = (struct xbridge_bus *)t->bus_private;
d1330 1
a1330 1
	struct xbridge_bus *xb = (struct xbridge_bus *)t->bus_private;
d1360 1
a1360 1
	struct xbridge_bus *xb = (struct xbridge_bus *)t->bus_private;
d1403 1
a1403 1
	struct xbridge_bus *xb = (struct xbridge_bus *)t->bus_private;
d1432 1
a1432 1
	struct xbridge_bus *xb = (struct xbridge_bus *)t->bus_private;
d1519 1
a1519 1
xbridge_ate_dump(struct xbridge_bus *xb)
d1566 1
a1566 1
xbridge_ate_setup(struct xbridge_bus *xb)
d1611 1
a1611 1
xbridge_ate_read(struct xbridge_bus *xb, uint a)
d1634 1
a1634 1
xbridge_ate_write(struct xbridge_bus *xb, uint a, uint64_t ate)
d1640 1
a1640 1
xbridge_ate_find(struct xbridge_bus *xb, paddr_t pa)
d1667 1
a1667 1
xbridge_ate_add(struct xbridge_bus *xb, paddr_t pa)
d1700 1
a1700 1
xbridge_ate_unref(struct xbridge_bus *xb, uint a, uint ref)
d1730 1
a1730 1
xbridge_address_map(struct xbridge_bus *xb, paddr_t pa, bus_addr_t *mapping,
d1803 1
a1803 1
xbridge_address_unmap(struct xbridge_bus *xb, bus_addr_t ba, bus_size_t len)
d1846 1
a1846 1
	struct xbridge_bus *xb = t->_cookie;
d1975 1
a1975 1
	struct xbridge_bus *xb = t->_cookie;
d2060 1
a2060 1
xbridge_setup(struct xbridge_bus *xb)
d2063 24
a2086 2
	uint64_t ctrl, int_addr;
	int dev;
a2138 1
	ctrl = xbridge_read_reg(xb, WIDGET_CONTROL);
d2174 1
a2174 1
xbridge_rrb_setup(struct xbridge_bus *xb, int odd)
d2266 1
a2266 1
xbridge_resource_setup(struct xbridge_bus *xb)
d2338 1
a2338 1
			need_setup = xb->xb_devio_skew !=
d2458 1
a2458 1
xbridge_extent_chomp(struct xbridge_bus *xb, struct extent *ex)
d2464 1
a2464 1
	 * (and maybe through the PCI I/O space as well.
d2496 1
a2496 1
xbridge_extent_setup(struct xbridge_bus *xb)
d2503 2
a2504 2
	snprintf(xb->xb_ioexname, sizeof(xb->xb_ioexname), "%s_io%d",
	    DEVNAME(xb), xb->xb_busno);
d2555 2
a2556 2
	snprintf(xb->xb_memexname, sizeof(xb->xb_memexname), "%s_mem%d",
	    DEVNAME(xb), xb->xb_busno);
d2607 1
a2607 1
xbridge_mapping_setup(struct xbridge_bus *xb, int io)
d2626 1
a2626 1
			base = xbow_widget_map_space(xb->xb_sc->sc_dev.dv_parent,
d2674 1
a2674 1
		base = xbow_widget_map_space(xb->xb_sc->sc_dev.dv_parent,
d2757 1
a2757 1
xbridge_resource_explore(struct xbridge_bus *xb, pcitag_t tag,
d2854 1
a2854 1
xbridge_resource_manage(struct xbridge_bus *xb, pcitag_t tag,
d2967 1
a2967 1
xbridge_device_setup(struct xbridge_bus *xb, int dev, int nfuncs,
d3120 1
a3120 1
	struct xbridge_bus *xb = cookie;
d3314 1
a3314 1
	struct xbridge_bus *xb = pa->pa_pc->pc_conf_v;
d3351 1
a3351 1
xbridge_allocate_devio(struct xbridge_bus *xb, int dev, int wantlarge)
d3388 1
a3388 1
xbridge_set_devio(struct xbridge_bus *xb, int dev, uint32_t devio)
@


1.52
log
@The Octane boot PROM is accessible through the PCI space of the on-board i/o
widget; make sure we reserve its address span so that no device risks
having its resources overlap the PROM.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.51 2009/10/10 19:59:28 miod Exp $	*/
d1269 1
d1271 1
d1371 1
d1374 1
@


1.51
log
@Simplify interrupt address programming to avoid the need to act differently
on PIC; no functional change.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.50 2009/10/08 19:14:23 miod Exp $	*/
d63 1
d65 2
d152 1
a152 1
	uint		sc_devio_skew;
d256 1
d361 17
a377 3
	 * Figure out where the devio mappings will go.
	 * On Octane, they are relative to the start of the widget.
	 * On Origin, they are computed from the widget number.
d379 3
a381 1
	if (sys_config.system_type == SGI_OCTANE)
d384 1
d1045 6
a1050 1
				/* XXX what to do there? */
d1277 1
d1281 1
d1377 2
d1392 1
d2369 37
d2461 3
d2511 3
d2562 6
d2611 6
@


1.50
log
@Program the widget interrupt address register as a whole 64 bit register
instead of two 32 bit halves, as the supposedly `upper 32 bits' register
ignores writes; makes interrupt on PIC route correctly.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.49 2009/10/08 19:10:53 miod Exp $	*/
d890 6
d1473 1
a1473 1
	uint32_t ctrl;
d1968 1
a1968 1
	uint32_t ctrl;
d2037 4
d2043 2
d2048 2
a2049 12

	if (ISSET(xb->xb_flags, XF_PIC)) {
		xbridge_write_reg(xb, WIDGET_INTDEST_ADDR_LOWER,
		    ((uint64_t)xbow_intr_widget << 48) |
		    (xbow_intr_widget_register & ((1UL << 48) - 1)));
	} else {
		xbridge_write_reg(xb, WIDGET_INTDEST_ADDR_UPPER,
		    (xbow_intr_widget_register >> 32) |
		    (xbow_intr_widget << 16));
		xbridge_write_reg(xb, WIDGET_INTDEST_ADDR_LOWER,
		    (uint32_t)xbow_intr_widget_register);
	}
@


1.49
log
@PIC actually comes with two sets of widget registers, with different IDs,
but we only care about the first for matching, so don't bother listing the
second one in xbowdevs, and fix the description.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.48 2009/10/07 20:39:14 miod Exp $	*/
d854 2
a855 1
	}
d2037 11
a2047 4
	xbridge_write_reg(xb, WIDGET_INTDEST_ADDR_UPPER,
	    (xbow_intr_widget_register >> 32) | (xbow_intr_widget << 16));
	xbridge_write_reg(xb, WIDGET_INTDEST_ADDR_LOWER,
	    (uint32_t)xbow_intr_widget_register);
@


1.48
log
@Do not truncate bridge register values to 32 bits, allows the few 64 bit PIC
registers to be programmed correctly.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.47 2009/10/07 04:19:30 miod Exp $	*/
d312 2
a313 4
	/* PIC first half */
	{ XBOW_VENDOR_SGI3, XBOW_PRODUCT_SGI3_PIC0,	XF_PIC },
	/* PIC second half */
	{ XBOW_VENDOR_SGI3, XBOW_PRODUCT_SGI3_PIC1,	XF_PIC }
@


1.47
log
@Try to keep existing IOC4 mappings, the same way we do on IOC3, in case
this is a console device.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.46 2009/08/22 02:54:51 mk Exp $	*/
d84 1
a84 1
	uint32_t	(*xb_read_reg)(bus_space_tag_t, bus_space_handle_t,
d87 1
a87 1
			    bus_addr_t, uint32_t);
d260 1
a260 1
uint32_t bridge_read_reg(bus_space_tag_t, bus_space_handle_t, bus_addr_t);
d262 2
a263 2
	    uint32_t);
uint32_t pic_read_reg(bus_space_tag_t, bus_space_handle_t, bus_addr_t);
d265 1
a265 1
	    uint32_t);
d267 1
a267 1
static __inline__ uint32_t
d273 1
a273 1
xbridge_write_reg(struct xbridge_bus *xb, bus_addr_t a, uint32_t v)
d829 1
a829 1
	uint32_t int_addr;
d1040 1
a1040 1
uint32_t
d1043 1
a1043 1
	return widget_read_4(t, h, a);
d1047 1
a1047 1
    uint32_t v)
d1049 1
a1049 1
	widget_write_4(t, h, a, v);
d1052 1
a1052 1
uint32_t
d1055 1
a1055 1
	return (uint32_t)widget_read_8(t, h, a);
d1060 1
a1060 1
    uint32_t v)
d1062 1
a1062 1
	widget_write_8(t, h, a, (uint64_t)v);
@


1.46
log
@Constify the what/name parameter of pci_intr_establish().

Tested by myself, sthen, oga, kettenis, and jasper.
Input from sthen and jasper.

ok kettenis

(Manpage follows shortly.)
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.45 2009/08/18 19:31:59 miod Exp $	*/
d510 6
d1973 6
a1978 2
		pa = xb->xb_regh + BRIDGE_PCI_CFG_SPACE +
		    (dev << 12) + PCI_ID_REG;
d2169 5
d2210 2
a2211 4
#ifdef DEBUG
		printf("device %d: devio %08x\n", dev, devio);
#endif
		if (id != PCI_ID_CODE(PCI_VENDOR_SGI, PCI_PRODUCT_SGI_IOC3))
d2228 1
d2342 2
a2343 2
	snprintf(xb->xb_ioexname, sizeof(xb->xb_ioexname), "%s_io",
	    DEVNAME(xb));
d2391 2
a2392 2
	snprintf(xb->xb_memexname, sizeof(xb->xb_memexname), "%s_mem",
	    DEVNAME(xb));
d2720 2
a2721 2
		printf("bar %02x type %d base %p size %p",
		    reg, type, base, size);
@


1.45
log
@Blind support for SGI PIC PCI-X controller found on Origin 350 and Tezro
systems. PIC was supposed to be mostly XBridge compatible, but a silicon
bug prevents it from working correctly if 32 bit register writes are used,
so the xbridge(4) code now needs to issue 64 bit writes.

In order to make this a bit more transparent, rebase all widget registers to
a 8 byte boundary, and provide a few inline accessors which will do the right
thing if you want 32 bit writes.

Tested to not cause regressions on Octane, Origin 200 and Fuel; covering
Bridge < 4, Bridge >= 4 and XBridge flavours.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.44 2009/07/27 17:49:55 miod Exp $	*/
d178 1
a178 1
	    int (*func)(void *), void *, char *);
d818 1
a818 1
    int (*func)(void *), void *arg, char *name)
@


1.44
log
@Unbreak non-DIAGNOSTIC kernels (i.e. RAMDISK-IP27)
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.43 2009/07/26 19:56:45 miod Exp $	*/
d20 1
a20 1
 * XBow Bridge (and XBridge) Widget driver.
d71 1
d73 23
a95 1
struct xbridge_ate;
d97 1
a97 9
struct xbridge_softc {
	struct device	sc_dev;
	int		sc_flags;
#define	XBRIDGE_FLAGS_XBRIDGE		0x01	/* is XBridge vs Bridge */
#define	XBRIDGE_FLAGS_NO_DIRECT_IO	0x02	/* no direct I/O mapping */
	int16_t		sc_nasid;
	int		sc_widget;
	uint		sc_devio_skew;
	struct mips_pci_chipset sc_pc;
d99 2
a100 2
	bus_space_tag_t sc_iot;
	bus_space_handle_t sc_regh;
d102 3
a104 3
	struct mips_bus_space *sc_mem_bus_space;
	struct mips_bus_space *sc_io_bus_space;
	struct machine_bus_dma_tag *sc_dmat;
d106 1
a106 1
	struct xbridge_intr	*sc_intr[BRIDGE_NINTRS];
d114 1
a114 1
	} sc_devices[BRIDGE_NSLOTS];
d119 5
a123 5
	struct mutex	sc_atemtx;
	uint		sc_atecnt;
	struct xbridge_ate	*sc_ate;
	LIST_HEAD(, xbridge_ate) sc_free_ate;
	LIST_HEAD(, xbridge_ate) sc_used_ate;
d128 2
a129 2
	bus_addr_t	sc_iostart, sc_ioend;
	bus_addr_t	sc_memstart, sc_memend;
d135 4
a138 4
	char		sc_ioexname[32];
	struct extent	*sc_ioex;
	char		sc_memexname[32];
	struct extent	*sc_memex;
d141 17
d166 2
d233 1
a233 1
int	xbridge_address_map(struct xbridge_softc *, paddr_t, bus_addr_t *,
d235 7
a241 7
void	xbridge_address_unmap(struct xbridge_softc *, bus_addr_t, bus_size_t);
uint	xbridge_ate_add(struct xbridge_softc *, paddr_t);
void	xbridge_ate_dump(struct xbridge_softc *);
uint	xbridge_ate_find(struct xbridge_softc *, paddr_t);
uint64_t xbridge_ate_read(struct xbridge_softc *, uint);
void	xbridge_ate_unref(struct xbridge_softc *, uint, uint);
void	xbridge_ate_write(struct xbridge_softc *, uint, uint64_t);
d243 2
a244 2
int	xbridge_allocate_devio(struct xbridge_softc *, int, int);
void	xbridge_set_devio(struct xbridge_softc *, int, uint32_t);
d246 1
a246 1
int	xbridge_resource_explore(struct xbridge_softc *, pcitag_t,
d248 1
a248 1
void	xbridge_resource_manage(struct xbridge_softc *, pcitag_t,
d251 3
a253 3
void	xbridge_ate_setup(struct xbridge_softc *);
void	xbridge_device_setup(struct xbridge_softc *, int, int, uint32_t);
void	xbridge_extent_setup(struct xbridge_softc *);
d255 22
a276 4
	xbridge_mapping_setup(struct xbridge_softc *, int);
void	xbridge_resource_setup(struct xbridge_softc *);
void	xbridge_rrb_setup(struct xbridge_softc *, int);
void	xbridge_setup(struct xbridge_softc *);
d303 15
d322 1
d324 4
a327 7
	if (xaa->xaa_vendor == XBOW_VENDOR_SGI4 &&
	    xaa->xaa_product == XBOW_PRODUCT_SGI4_BRIDGE)
		return 1;

	if (xaa->xaa_vendor == XBOW_VENDOR_SGI3 &&
	    xaa->xaa_product == XBOW_PRODUCT_SGI3_XBRIDGE)
		return 1;
a335 1
	struct pcibus_attach_args pba;
d337 1
d343 60
a402 5
	if (xaa->xaa_vendor == XBOW_VENDOR_SGI3 &&
	    xaa->xaa_product == XBOW_PRODUCT_SGI3_XBRIDGE)
		sc->sc_flags |= XBRIDGE_FLAGS_XBRIDGE;
	else if (xaa->xaa_revision < 4)
		sc->sc_flags |= XBRIDGE_FLAGS_NO_DIRECT_IO;
d408 5
a412 8
	sc->sc_iot = malloc(sizeof (*sc->sc_iot), M_DEVBUF, M_NOWAIT);
	if (sc->sc_iot == NULL)
		goto fail0;
	bcopy(xaa->xaa_iot, sc->sc_iot, sizeof (*sc->sc_iot));
	if (bus_space_map(sc->sc_iot, 0, BRIDGE_REGISTERS_SIZE, 0,
	    &sc->sc_regh)) {
		printf("%s: unable to map control registers\n", self->dv_xname);
		free(sc->sc_iot, M_DEVBUF);
d422 1
a422 1
	sc->sc_mem_bus_space = malloc(sizeof (*sc->sc_mem_bus_space),
d424 1
a424 1
	if (sc->sc_mem_bus_space == NULL)
d426 1
a426 1
	sc->sc_io_bus_space = malloc(sizeof (*sc->sc_io_bus_space),
d428 1
a428 1
	if (sc->sc_io_bus_space == NULL)
d431 29
a459 31
	bcopy(xaa->xaa_iot, sc->sc_mem_bus_space,
	    sizeof(*sc->sc_mem_bus_space));
	sc->sc_mem_bus_space->bus_private = sc;
	sc->sc_mem_bus_space->_space_map = xbridge_space_map_devio;
	sc->sc_mem_bus_space->_space_subregion = xbridge_space_region_devio;
	sc->sc_mem_bus_space->_space_read_1 = xbridge_read_1;
	sc->sc_mem_bus_space->_space_write_1 = xbridge_write_1;
	sc->sc_mem_bus_space->_space_read_2 = xbridge_read_2;
	sc->sc_mem_bus_space->_space_write_2 = xbridge_write_2;
	sc->sc_mem_bus_space->_space_read_raw_2 = xbridge_read_raw_2;
	sc->sc_mem_bus_space->_space_write_raw_2 = xbridge_write_raw_2;
	sc->sc_mem_bus_space->_space_read_raw_4 = xbridge_read_raw_4;
	sc->sc_mem_bus_space->_space_write_raw_4 = xbridge_write_raw_4;
	sc->sc_mem_bus_space->_space_read_raw_8 = xbridge_read_raw_8;
	sc->sc_mem_bus_space->_space_write_raw_8 = xbridge_write_raw_8;

	bcopy(xaa->xaa_iot, sc->sc_io_bus_space,
	    sizeof(*sc->sc_io_bus_space));
	sc->sc_io_bus_space->bus_private = sc;
	sc->sc_io_bus_space->_space_map = xbridge_space_map_devio;
	sc->sc_io_bus_space->_space_subregion = xbridge_space_region_devio;
	sc->sc_io_bus_space->_space_read_1 = xbridge_read_1;
	sc->sc_io_bus_space->_space_write_1 = xbridge_write_1;
	sc->sc_io_bus_space->_space_read_2 = xbridge_read_2;
	sc->sc_io_bus_space->_space_write_2 = xbridge_write_2;
	sc->sc_io_bus_space->_space_read_raw_2 = xbridge_read_raw_2;
	sc->sc_io_bus_space->_space_write_raw_2 = xbridge_write_raw_2;
	sc->sc_io_bus_space->_space_read_raw_4 = xbridge_read_raw_4;
	sc->sc_io_bus_space->_space_write_raw_4 = xbridge_write_raw_4;
	sc->sc_io_bus_space->_space_read_raw_8 = xbridge_read_raw_8;
	sc->sc_io_bus_space->_space_write_raw_8 = xbridge_write_raw_8;
d461 2
a462 2
	sc->sc_dmat = malloc(sizeof (*sc->sc_dmat), M_DEVBUF, M_NOWAIT);
	if (sc->sc_dmat == NULL)
d464 2
a465 2
	memcpy(sc->sc_dmat, &xbridge_dma_tag, sizeof(*sc->sc_dmat));
	sc->sc_dmat->_cookie = sc;
d471 14
a484 14
	sc->sc_pc.pc_conf_v = sc;
	sc->sc_pc.pc_attach_hook = xbridge_attach_hook;
	sc->sc_pc.pc_make_tag = xbridge_make_tag;
	sc->sc_pc.pc_decompose_tag = xbridge_decompose_tag;
	sc->sc_pc.pc_bus_maxdevs = xbridge_bus_maxdevs;
	sc->sc_pc.pc_conf_read = xbridge_conf_read;
	sc->sc_pc.pc_conf_write = xbridge_conf_write;
	sc->sc_pc.pc_intr_v = sc;
	sc->sc_pc.pc_intr_map = xbridge_intr_map;
	sc->sc_pc.pc_intr_string = xbridge_intr_string;
	sc->sc_pc.pc_intr_establish = xbridge_intr_establish;
	sc->sc_pc.pc_intr_disestablish = xbridge_intr_disestablish;
	sc->sc_pc.pc_intr_line = xbridge_intr_line;
	sc->sc_pc.pc_ppb_setup = xbridge_ppb_setup;
d486 2
a487 2
	sc->sc_pc.pc_rbus_parent_io = xbridge_rbus_parent_io;
	sc->sc_pc.pc_rbus_parent_mem = xbridge_rbus_parent_mem;
d495 1
a495 1
	xbridge_setup(sc);
d501 1
a501 1
	xbridge_extent_setup(sc);
d505 6
a510 6
	pba.pba_iot = sc->sc_io_bus_space;
	pba.pba_memt = sc->sc_mem_bus_space;
	pba.pba_dmat = sc->sc_dmat;
	pba.pba_ioex = sc->sc_ioex;
	pba.pba_memex = sc->sc_memex;
	pba.pba_pc = &sc->sc_pc;
d514 1
a514 1
	config_found(self, &pba, xbridge_print);
d518 1
a518 1
	free(sc->sc_io_bus_space, M_DEVBUF);
d520 1
a520 1
	free(sc->sc_mem_bus_space, M_DEVBUF);
d522 2
a523 4
	free(sc->sc_iot, M_DEVBUF);
fail0:
	printf("%s: not enough memory to build access structures\n",
	    self->dv_xname);
d570 3
a572 1
	return busno == 0 ? BRIDGE_NSLOTS : 32;
d578 1
a578 1
	struct xbridge_softc *sc = cookie;
d590 1
a590 1
		bus_space_write_4(sc->sc_iot, sc->sc_regh, BRIDGE_PCI_CFG,
d592 12
a603 3
		pa = sc->sc_regh + BRIDGE_PCI_CFG1_SPACE;
	} else
		pa = sc->sc_regh + BRIDGE_PCI_CFG_SPACE + (dev << 12);
d619 1
a619 1
	if (bus == 0 && sc->sc_devices[dev].id ==
d657 1
a657 1
	struct xbridge_softc *sc = cookie;
d668 1
a668 1
		bus_space_write_4(sc->sc_iot, sc->sc_regh, BRIDGE_PCI_CFG,
d670 12
a681 3
		pa = sc->sc_regh + BRIDGE_PCI_CFG1_SPACE;
	} else
		pa = sc->sc_regh + BRIDGE_PCI_CFG_SPACE + (dev << 12);
d695 1
a695 1
	if (bus == 0 && sc->sc_devices[dev].id ==
d747 1
a747 1
	struct	xbridge_softc	*xi_bridge;
d762 1
a762 1
	struct xbridge_softc *sc = pa->pa_pc->pc_conf_v;
d791 1
a791 1
		if (sc->sc_devices[device].id ==
d820 1
a820 1
	struct xbridge_softc *sc = (struct xbridge_softc *)cookie;
d833 1
a833 1
	if ((xi = sc->sc_intr[intrbit]) == NULL) {
d839 1
a839 1
		xi->xi_bridge = sc;
d843 1
a843 1
		if (xbow_intr_register(sc->sc_widget, level, &intrsrc) != 0) {
d849 1
a849 1
		sc->sc_intr[intrbit] = xi;
d866 1
a866 1
			    sc->sc_dev.dv_xname);
d885 6
a890 2
		int_addr =
		    ((xbow_intr_widget_register >> 30) & 0x0003ff00) | intrsrc;
d892 3
a894 5
		bus_space_write_4(sc->sc_iot, sc->sc_regh,
		    BRIDGE_INT_ADDR(intrbit), int_addr);
		bus_space_write_4(sc->sc_iot, sc->sc_regh, BRIDGE_IER,
		    bus_space_read_4(sc->sc_iot, sc->sc_regh, BRIDGE_IER) |
		    (1 << intrbit));
d902 4
a905 5
		bus_space_write_4(sc->sc_iot, sc->sc_regh, BRIDGE_INT_MODE,
		    bus_space_read_4(sc->sc_iot, sc->sc_regh, BRIDGE_INT_MODE) |
		    (1 << intrbit));
		bus_space_write_4(sc->sc_iot, sc->sc_regh, BRIDGE_INT_DEV,
		    bus_space_read_4(sc->sc_iot, sc->sc_regh, BRIDGE_INT_DEV) |
d907 1
a907 1
		(void)bus_space_read_4(sc->sc_iot, sc->sc_regh, WIDGET_TFLUSH);
d916 1
a916 1
	struct xbridge_softc *sc = cookie;
d925 7
a931 10
		bus_space_write_4(sc->sc_iot, sc->sc_regh,
		    BRIDGE_INT_ADDR(intrbit), 0);
		bus_space_write_4(sc->sc_iot, sc->sc_regh, BRIDGE_IER,
		    bus_space_read_4(sc->sc_iot, sc->sc_regh, BRIDGE_IER) &
		    ~(1 << intrbit));
		bus_space_write_4(sc->sc_iot, sc->sc_regh, BRIDGE_INT_MODE,
		    bus_space_read_4(sc->sc_iot, sc->sc_regh, BRIDGE_INT_MODE) &
		    ~(1 << intrbit));
		bus_space_write_4(sc->sc_iot, sc->sc_regh, BRIDGE_INT_DEV,
		    bus_space_read_4(sc->sc_iot, sc->sc_regh, BRIDGE_INT_DEV) &
d933 1
a933 1
		(void)bus_space_read_4(sc->sc_iot, sc->sc_regh, WIDGET_TFLUSH);
d937 1
a937 1
		 * Note we could free sc->sc_intr[intrbit] at this point,
d955 1
a955 1
	struct xbridge_softc *sc = xi->xi_bridge;
d959 1
d962 1
a962 2
		printf("%s: spurious irq %d\n",
		    sc->sc_dev.dv_xname, xi->xi_intrbit);
d970 1
a970 2
		bus_space_read_4(sc->sc_iot, sc->sc_regh,
		    BRIDGE_DEVICE_WBFLUSH(xih->xih_device));
d972 2
a973 2
	if ((bus_space_read_4(sc->sc_iot, sc->sc_regh, BRIDGE_ISR) &
	    (1 << xi->xi_intrbit)) == 0) {
d977 1
a977 2
		    sc->sc_dev.dv_xname, xi->xi_intrbit,
		    bus_space_read_4(sc->sc_iot, sc->sc_regh, BRIDGE_ISR));
d990 1
a990 2
		printf("%s: spurious irq %d\n",
		    sc->sc_dev.dv_xname, xi->xi_intrbit);
d1006 4
a1009 6
	if (ISSET(sc->sc_flags, XBRIDGE_FLAGS_XBRIDGE)) {
		bus_space_write_4(sc->sc_iot, sc->sc_regh,
		    BRIDGE_INT_FORCE_PIN(xi->xi_intrbit), 1);
	} else {
		if (bus_space_read_4(sc->sc_iot, sc->sc_regh,
		    BRIDGE_ISR) & (1 << xi->xi_intrbit)) {
d1019 1
a1019 1
				IP27_RHUB_PI_S(sc->sc_nasid, 0, HUBPI_IR_CHANGE,
d1031 29
d1165 1
a1165 1
	struct xbridge_softc *sc = (struct xbridge_softc *)t->bus_private;
d1172 1
a1172 1
	if ((offs >> 24) != sc->sc_devio_skew)
d1181 2
a1182 2
	for (d = 0; d < BRIDGE_NSLOTS; d++) {
		start = BRIDGE_DEVIO_OFFS(d);
d1191 1
a1191 1
	if (d == BRIDGE_NSLOTS)
d1200 1
a1200 1
	*bshp = sc->sc_iot->bus_base + bpa;
d1208 1
a1208 1
	struct xbridge_softc *sc = (struct xbridge_softc *)t->bus_private;
d1215 1
a1215 1
	if ((offs >> 24) == sc->sc_devio_skew)
d1220 1
a1220 1
	if (offs < sc->sc_iostart || offs + size - 1 > sc->sc_ioend)
d1232 1
a1232 1
	struct xbridge_softc *sc = (struct xbridge_softc *)t->bus_private;
d1241 1
a1241 1
	    (offs >> 24) == sc->sc_devio_skew)
d1246 1
a1246 1
	if (offs < sc->sc_memstart || offs + size - 1 > sc->sc_memend)
d1259 1
a1259 1
	struct xbridge_softc *sc = (struct xbridge_softc *)t->bus_private;
d1271 1
a1271 1
	bpa = (bus_addr_t)bsh - sc->sc_iot->bus_base;
d1280 2
a1281 2
	for (d = 0; d < BRIDGE_NSLOTS; d++) {
		start = BRIDGE_DEVIO_OFFS(d);
d1290 1
a1290 1
	if (d == BRIDGE_NSLOTS)
d1302 1
a1302 1
	struct xbridge_softc *sc = (struct xbridge_softc *)t->bus_private;
d1310 1
a1310 1
	bpa = (bus_addr_t)bsh - sc->sc_iot->bus_base;
d1318 1
a1318 1
	if (bpa + offset + size - 1 > sc->sc_ioend)
d1330 1
a1330 1
	struct xbridge_softc *sc = (struct xbridge_softc *)t->bus_private;
d1345 1
a1345 1
		bpa = (bus_addr_t)bsh - sc->sc_iot->bus_base;
d1355 1
a1355 1
	if (bpa + offset + size - 1 > sc->sc_memend)
d1413 1
a1413 1
xbridge_ate_dump(struct xbridge_softc *sc)
d1418 2
a1419 2
	printf("%s ATE list (in array order)\n", sc->sc_dev.dv_xname);
	for (a = 0, ate = sc->sc_ate; a < sc->sc_atecnt; a++, ate++) {
d1429 1
a1429 1
	printf("%s USED ATE list (in link order)\n", sc->sc_dev.dv_xname);
d1431 1
a1431 1
	LIST_FOREACH(ate, &sc->sc_used_ate, xa_nxt) {
d1433 1
a1433 1
		    ate - sc->sc_ate, ate->xa_pa, ate->xa_refcnt);
d1443 1
a1443 1
	printf("%s FREE ATE list (in link order)\n", sc->sc_dev.dv_xname);
d1445 1
a1445 1
	LIST_FOREACH(ate, &sc->sc_free_ate, xa_nxt) {
d1447 1
a1447 1
		    ate - sc->sc_ate, ate->xa_pa, ate->xa_refcnt);
d1460 1
a1460 1
xbridge_ate_setup(struct xbridge_softc *sc)
d1466 1
a1466 1
	mtx_init(&sc->sc_atemtx, IPL_HIGH);
d1468 2
a1469 2
	if (ISSET(sc->sc_flags, XBRIDGE_FLAGS_XBRIDGE))
		sc->sc_atecnt = XBRIDGE_INTERNAL_ATE;
d1471 1
a1471 1
		sc->sc_atecnt = BRIDGE_INTERNAL_ATE;
d1473 1
a1473 1
	sc->sc_ate = (struct xbridge_ate *)malloc(sc->sc_atecnt *
d1475 1
a1475 1
	if (sc->sc_ate == NULL) {
d1483 4
a1486 4
	LIST_INIT(&sc->sc_free_ate);
	LIST_INIT(&sc->sc_used_ate);
	for (ate = sc->sc_ate; ate != sc->sc_ate + sc->sc_atecnt; ate++)
		LIST_INSERT_HEAD(&sc->sc_free_ate, ate, xa_nxt);
d1491 2
a1492 2
	ctrl = bus_space_read_4(sc->sc_iot, sc->sc_regh, WIDGET_CONTROL);
	bus_space_write_4(sc->sc_iot, sc->sc_regh, WIDGET_CONTROL,
d1494 1
a1494 1
	(void)bus_space_read_4(sc->sc_iot, sc->sc_regh, WIDGET_TFLUSH);
d1499 2
a1500 2
	for (a = 0; a < sc->sc_atecnt; a++)
		xbridge_ate_write(sc, a, ATE_NV);
d1505 1
a1505 1
xbridge_ate_read(struct xbridge_softc *sc, uint a)
d1513 3
a1515 4
	hi = bus_space_read_4(sc->sc_iot, sc->sc_regh, BRIDGE_ATE(a) + 4);
	if (ISSET(sc->sc_flags, XBRIDGE_FLAGS_XBRIDGE))
		lo = bus_space_read_4(sc->sc_iot, sc->sc_regh,
		    BRIDGE_ATE(a + 1024) + 4);
d1517 1
a1517 2
		lo = bus_space_read_4(sc->sc_iot, sc->sc_regh,
		    BRIDGE_ATE(a + 512) + 4);
d1528 1
a1528 1
xbridge_ate_write(struct xbridge_softc *sc, uint a, uint64_t ate)
d1530 1
a1530 1
	bus_space_write_8(sc->sc_iot, sc->sc_regh, BRIDGE_ATE(a), ate);
d1534 1
a1534 1
xbridge_ate_find(struct xbridge_softc *sc, paddr_t pa)
d1547 1
a1547 1
	LIST_FOREACH(ate, &sc->sc_used_ate, xa_nxt)
d1549 1
a1549 1
			a = ate - sc->sc_ate;
d1561 1
a1561 1
xbridge_ate_add(struct xbridge_softc *sc, paddr_t pa)
d1569 1
a1569 1
	if (LIST_EMPTY(&sc->sc_free_ate)) {
d1571 1
a1571 1
		printf("%s: out of ATEs\n", sc->sc_dev.dv_xname);
d1576 1
a1576 1
	ate = LIST_FIRST(&sc->sc_free_ate);
d1578 1
a1578 1
	LIST_INSERT_HEAD(&sc->sc_used_ate, ate, xa_nxt);
d1582 1
a1582 1
	a = ate - sc->sc_ate;
d1587 1
a1587 1
	xbridge_ate_write(sc, a, ate->xa_pa |
d1594 1
a1594 1
xbridge_ate_unref(struct xbridge_softc *sc, uint a, uint ref)
d1598 1
a1598 1
	ate = sc->sc_ate + a;
d1602 1
a1602 1
		    sc->sc_dev.dv_xname, a, ate, ate->xa_refcnt, ref);
d1609 1
a1609 1
		xbridge_ate_write(sc, a, ATE_NV);
d1611 1
a1611 1
		LIST_INSERT_HEAD(&sc->sc_free_ate, ate, xa_nxt);
d1624 1
a1624 1
xbridge_address_map(struct xbridge_softc *sc, paddr_t pa, bus_addr_t *mapping,
d1654 1
a1654 1
	mtx_enter(&sc->sc_atemtx);
d1656 1
a1656 1
	a = xbridge_ate_find(sc, pa);
d1658 1
a1658 1
		ate = sc->sc_ate + a;
d1661 1
a1661 1
		a = xbridge_ate_add(sc, pa);
d1670 1
a1670 1
		if (ISSET(sc->sc_flags, XBRIDGE_FLAGS_XBRIDGE))
d1677 1
a1677 1
		mtx_leave(&sc->sc_atemtx);
d1681 1
a1681 1
	printf("%s: out of ATE\n", sc->sc_dev.dv_xname);
d1683 1
a1683 1
	xbridge_ate_dump(sc);
d1686 1
a1686 1
	mtx_leave(&sc->sc_atemtx);
d1697 1
a1697 1
xbridge_address_unmap(struct xbridge_softc *sc, bus_addr_t ba, bus_size_t len)
d1714 1
a1714 1
	if (a >= sc->sc_atecnt)
d1716 1
a1716 1
		    __func__, ba, a, sc->sc_atecnt);
d1727 3
a1729 3
	mtx_enter(&sc->sc_atemtx);
	xbridge_ate_unref(sc, a, refs);
	mtx_leave(&sc->sc_atemtx);
d1740 1
a1740 1
	struct xbridge_softc *sc = t->_cookie;
d1777 1
a1777 1
		if (xbridge_address_map(sc, pa, &busaddr, &endaddr) != 0) {
d1820 1
a1820 1
					xbridge_address_unmap(sc, busaddr,
d1855 1
a1855 1
		xbridge_address_unmap(sc, map->dm_segs[seg].ds_addr,
d1869 1
a1869 1
	struct xbridge_softc *sc = t->_cookie;
d1873 1
a1873 1
		xbridge_address_unmap(sc, map->dm_segs[seg].ds_addr,
d1954 1
a1954 1
xbridge_setup(struct xbridge_softc *sc)
d1966 2
a1967 2
	for (dev = 0; dev < BRIDGE_NSLOTS; dev++) {
		pa = sc->sc_regh + BRIDGE_PCI_CFG_SPACE +
d1969 2
a1970 2
		if (guarded_read_4(pa, &sc->sc_devices[dev].id) != 0)
			sc->sc_devices[dev].id =
d1980 2
a1981 3
		bus_space_write_4(sc->sc_iot, sc->sc_regh, BRIDGE_DIR_MAP,
		    (xbow_intr_widget << BRIDGE_DIRMAP_WIDGET_SHIFT) |
		    BRIDGE_DIRMAP_ADD_512MB);
d1983 1
a1983 1
		bus_space_write_4(sc->sc_iot, sc->sc_regh, BRIDGE_DIR_MAP,
d1991 1
a1991 1
	xbridge_ate_setup(sc);
d1997 2
a1998 2
	xbridge_rrb_setup(sc, 0);
	xbridge_rrb_setup(sc, 1);
d2007 1
a2007 1
	ctrl = bus_space_read_4(sc->sc_iot, sc->sc_regh, WIDGET_CONTROL);
d2010 2
a2011 2
	bus_space_write_4(sc->sc_iot, sc->sc_regh, WIDGET_CONTROL, ctrl);
	(void)bus_space_read_4(sc->sc_iot, sc->sc_regh, WIDGET_TFLUSH);
d2018 1
a2018 1
	xbridge_resource_setup(sc);
d2024 3
a2026 3
	bus_space_write_4(sc->sc_iot, sc->sc_regh, BRIDGE_IER, 0);
	bus_space_write_4(sc->sc_iot, sc->sc_regh, BRIDGE_INT_MODE, 0);
	bus_space_write_4(sc->sc_iot, sc->sc_regh, BRIDGE_INT_DEV, 0);
d2028 1
a2028 1
	bus_space_write_4(sc->sc_iot, sc->sc_regh, WIDGET_INTDEST_ADDR_UPPER,
d2030 1
a2030 1
	bus_space_write_4(sc->sc_iot, sc->sc_regh, WIDGET_INTDEST_ADDR_LOWER,
d2033 1
a2033 1
	(void)bus_space_read_4(sc->sc_iot, sc->sc_regh, WIDGET_TFLUSH);
d2040 1
a2040 1
xbridge_rrb_setup(struct xbridge_softc *sc, int odd)
d2042 1
a2042 1
	uint rrb[BRIDGE_NSLOTS / 2];	/* tentative rrb assignment */
d2052 1
a2052 1
	for (i = 0; i < BRIDGE_NSLOTS / 2; i++) {
d2054 2
a2055 1
		if (PCI_VENDOR(sc->sc_devices[dev].id) == PCI_VENDOR_INVALID)
d2072 1
a2072 1
		for (i = 0; i < BRIDGE_NSLOTS / 2; i++) {
d2087 1
a2087 1
		for (i = 0; i < BRIDGE_NSLOTS / 2; i++) {
d2090 1
a2090 1
				if (PCI_VENDOR(sc->sc_devices[dev].id) !=
d2106 1
a2106 1
		for (i = BRIDGE_NSLOTS / 2 - 1; i >= 0; i--) {
d2120 1
a2120 1
	for (i = 0; i < BRIDGE_NSLOTS / 2; i++) {
d2125 1
a2125 2
	bus_space_write_4(sc->sc_iot, sc->sc_regh,
	    odd ? BRIDGE_RRB_ODD : BRIDGE_RRB_EVEN, proto);
d2132 1
a2132 1
xbridge_resource_setup(struct xbridge_softc *sc)
d2134 1
a2134 1
	pci_chipset_tag_t pc = &sc->sc_pc;
a2143 11
	 * Figure out where the devio mappings will go.
	 * On Octane, they are relative to the start of the widget.
	 * On Origin, they are computed from the widget number.
	 */

	if (sys_config.system_type == SGI_OCTANE)
		sc->sc_devio_skew = 0;
	else
		sc->sc_devio_skew = sc->sc_widget;

	/*
d2151 2
a2152 2
		sc->sc_ioex = xbridge_mapping_setup(sc, 1);
		sc->sc_memex = xbridge_mapping_setup(sc, 0);
d2160 2
a2161 2
	for (dev = 0; dev < BRIDGE_NSLOTS; dev++) {
		id = sc->sc_devices[dev].id;
d2194 1
a2194 2
		devio = bus_space_read_4(sc->sc_iot, sc->sc_regh,
		    BRIDGE_DEVICE(dev));
d2201 1
a2201 1
			need_setup = sc->sc_devio_skew !=
d2209 1
a2209 1
		if (ISSET(sc->sc_flags, XBRIDGE_FLAGS_XBRIDGE))
d2232 1
a2232 1
			xbridge_set_devio(sc, dev, devio);
d2241 1
a2241 1
		xbridge_set_devio(sc, dev, devio);
d2255 1
a2255 1
		xbridge_device_setup(sc, dev, nfuncs, devio);
d2270 4
a2273 4
		if (sc->sc_ioex == NULL)
			sc->sc_ioex = xbridge_mapping_setup(sc, 1);
		if (sc->sc_memex == NULL)
			sc->sc_memex = xbridge_mapping_setup(sc, 0);
d2278 2
a2279 2
	for (dev = 0; dev < BRIDGE_NSLOTS; dev++) {
		id = sc->sc_devices[dev].id;
d2305 7
a2311 7
	if (sc->sc_ioex != NULL) {
		extent_destroy(sc->sc_ioex);
		sc->sc_ioex = NULL;
	}
	if (sc->sc_memex != NULL) {
		extent_destroy(sc->sc_memex);
		sc->sc_memex = NULL;
d2321 1
a2321 1
xbridge_extent_setup(struct xbridge_softc *sc)
d2328 3
a2330 3
	snprintf(sc->sc_ioexname, sizeof(sc->sc_ioexname), "%s_io",
	    sc->sc_dev.dv_xname);
	sc->sc_ioex = extent_create(sc->sc_ioexname, 0, 0xffffffff,
d2333 1
a2333 1
	if (sc->sc_ioex != NULL) {
d2336 2
a2337 2
		for (dev = 0; dev < BRIDGE_NSLOTS; dev++) {
			devio = sc->sc_devices[dev].devio;
d2346 1
a2346 1
			if (extent_free(sc->sc_ioex, start,
d2353 2
a2354 2
		if (sc->sc_ioend != 0) {
			start = sc->sc_iostart;
d2357 1
a2357 1
			end = sc->sc_devio_skew << 24;
d2359 1
a2359 1
				if (extent_free(sc->sc_ioex, start,
d2363 5
a2367 5
			start = (sc->sc_devio_skew + 1) << 24;
			if (start < sc->sc_iostart)
				start = sc->sc_iostart;
			if (extent_free(sc->sc_ioex, start,
			    sc->sc_ioend + 1 - start, EX_NOWAIT) != 0)
d2372 2
a2373 2
			extent_destroy(sc->sc_ioex);
			sc->sc_ioex = NULL;
d2377 3
a2379 3
	snprintf(sc->sc_memexname, sizeof(sc->sc_memexname), "%s_mem",
	    sc->sc_dev.dv_xname);
	sc->sc_memex = extent_create(sc->sc_memexname, 0, 0xffffffff,
d2382 1
a2382 1
	if (sc->sc_memex != NULL) {
d2385 2
a2386 2
		for (dev = 0; dev < BRIDGE_NSLOTS; dev++) {
			devio = sc->sc_devices[dev].devio;
d2393 1
a2393 1
			if (extent_free(sc->sc_memex, start,
d2400 2
a2401 2
		if (sc->sc_memend != 0) {
			start = sc->sc_memstart;
d2404 1
a2404 1
			end = sc->sc_devio_skew << 24;
d2406 1
a2406 1
				if (extent_free(sc->sc_memex, start,
d2410 5
a2414 5
			start = (sc->sc_devio_skew + 1) << 24;
			if (start < sc->sc_memstart)
				start = sc->sc_memstart;
			if (extent_free(sc->sc_memex, start,
			    sc->sc_memend + 1 - start, EX_NOWAIT) != 0)
d2419 2
a2420 2
			extent_destroy(sc->sc_memex);
			sc->sc_memex = NULL;
d2426 1
a2426 1
xbridge_mapping_setup(struct xbridge_softc *sc, int io)
d2428 1
a2428 1
	bus_addr_t offs;
d2442 1
a2442 1
		if (!ISSET(sc->sc_flags, XBRIDGE_FLAGS_NO_DIRECT_IO)) {
d2445 2
a2446 2
			base = xbow_widget_map_space(sc->sc_dev.dv_parent,
			    sc->sc_widget, &offs, &len);
d2467 2
a2468 2
				sc->sc_io_bus_space->bus_base = base - offs;
				sc->sc_io_bus_space->_space_map =
d2470 1
a2470 1
				sc->sc_io_bus_space->_space_subregion =
d2473 2
a2474 2
				sc->sc_iostart = offs;
				sc->sc_ioend = offs + len - 1;
d2480 1
a2480 1
		 * BRIDGE_PCI_MEM_SPACE_BASE onwards.
d2483 3
a2485 1
		offs = BRIDGE_PCI_MEM_SPACE_BASE;
d2487 2
a2488 2
		base = xbow_widget_map_space(sc->sc_dev.dv_parent,
		    sc->sc_widget, &offs, &len);
d2496 3
a2498 4
			if (offs + len > BRIDGE_PCI_MEM_SPACE_BASE +
			    BRIDGE_PCI_MEM_SPACE_LENGTH)
				len = BRIDGE_PCI_MEM_SPACE_BASE +
				    BRIDGE_PCI_MEM_SPACE_LENGTH - offs;
d2504 1
a2504 1
			offs -= BRIDGE_PCI_MEM_SPACE_BASE;
d2511 2
a2512 2
				sc->sc_mem_bus_space->bus_base = base - offs;
				sc->sc_mem_bus_space->_space_map =
d2514 1
a2514 1
				sc->sc_mem_bus_space->_space_subregion =
d2517 2
a2518 2
				sc->sc_memstart = offs;
				sc->sc_memend = offs + len - 1;
d2531 2
a2532 2
		start = sc->sc_devio_skew << 24;
		end = (sc->sc_devio_skew + 1) << 24;
d2543 1
a2543 2
				    sc->sc_dev.dv_xname,
				    io ? "i/o" : "mem");
d2564 1
a2564 1
xbridge_resource_explore(struct xbridge_softc *sc, pcitag_t tag,
d2567 1
a2567 1
	pci_chipset_tag_t pc = &sc->sc_pc;
d2661 1
a2661 1
xbridge_resource_manage(struct xbridge_softc *sc, pcitag_t tag,
d2664 1
a2664 1
	pci_chipset_tag_t pc = &sc->sc_pc;
d2774 1
a2774 1
xbridge_device_setup(struct xbridge_softc *sc, int dev, int nfuncs,
d2777 1
a2777 1
	pci_chipset_tag_t pc = &sc->sc_pc;
d2781 1
a2781 1
	uint32_t basewin;
d2799 1
a2799 1
	if (sc->sc_ioex != NULL)
d2805 1
a2805 1
	if (sc->sc_memex != NULL)
d2825 1
a2825 1
		resources |= xbridge_resource_explore(sc, tag, ioex, memex);
d2851 2
a2852 2
		     sc->sc_ioex == NULL))
			io_devio = xbridge_allocate_devio(sc, dev,
d2855 4
a2858 4
			basewin = (sc->sc_devio_skew << 24) |
			    BRIDGE_DEVIO_OFFS(io_devio);
			xbridge_set_devio(sc, io_devio, devio |
			    (basewin >> BRIDGE_DEVICE_BASE_SHIFT));
d2860 2
a2861 2
			ioex = extent_create("xbridge_io", basewin,
			    basewin + BRIDGE_DEVIO_SIZE(io_devio) - 1,
d2868 2
a2869 2
			if (sc->sc_ioex == NULL)
				sc->sc_ioex = xbridge_mapping_setup(sc, 1);
d2877 1
a2877 1
			mem_devio = xbridge_allocate_devio(sc, dev,
d2880 3
a2882 3
			basewin = (sc->sc_devio_skew << 24) |
			    BRIDGE_DEVIO_OFFS(mem_devio);
			xbridge_set_devio(sc, mem_devio, devio |
d2884 1
a2884 1
			    (basewin >> BRIDGE_DEVICE_BASE_SHIFT));
d2886 2
a2887 2
			memex = extent_create("xbridge_mem", basewin,
			    basewin + BRIDGE_DEVIO_SIZE(mem_devio) - 1,
d2894 2
a2895 2
			if (sc->sc_memex == NULL)
				sc->sc_memex = xbridge_mapping_setup(sc, 0);
d2912 3
a2914 3
		xbridge_resource_manage(sc, tag,
		    ioex != NULL ? ioex : sc->sc_ioex,
		    memex != NULL ?  memex : sc->sc_memex);
d2927 2
a2928 2
	struct xbridge_softc *sc = cookie;
	pci_chipset_tag_t pc = &sc->sc_pc;
d2935 1
a2935 1
	devio = bus_space_read_4(sc->sc_iot, sc->sc_regh, BRIDGE_DEVICE(dev));
d2949 1
a2949 1
			devio_idx = xbridge_allocate_devio(sc, dev, 0);
d2951 1
a2951 1
			devio_idx = xbridge_allocate_devio(sc, dev, 1);
d2956 2
a2957 2
		if (devio_idx < 0 && sc->sc_memex == NULL)
			sc->sc_memex = xbridge_mapping_setup(sc, 0);
d2960 1
a2960 1
		if (devio_idx < 0 && sc->sc_memex == NULL) {
d2962 1
a2962 1
				devio_idx = xbridge_allocate_devio(sc, dev, 1);
d2964 1
a2964 1
				devio_idx = xbridge_allocate_devio(sc, dev, 0);
d2968 3
a2970 3
			base = (sc->sc_devio_skew << 24) |
			    BRIDGE_DEVIO_OFFS(devio_idx);
			xbridge_set_devio(sc, devio_idx, devio |
d2975 1
a2975 1
		} else if (sc->sc_memex != NULL) {
d2985 1
a2985 1
				if (extent_alloc(sc->sc_memex, exsize,
d3005 1
a3005 1
			devio_idx = xbridge_allocate_devio(sc, dev, 0);
d3007 1
a3007 1
			devio_idx = xbridge_allocate_devio(sc, dev, 1);
d3012 2
a3013 2
		if (devio_idx < 0 && sc->sc_ioex == NULL)
			sc->sc_ioex = xbridge_mapping_setup(sc, 1);
d3016 1
a3016 1
		if (devio_idx < 0 && sc->sc_ioex == NULL) {
d3018 1
a3018 1
				devio_idx = xbridge_allocate_devio(sc, dev, 1);
d3020 1
a3020 1
				devio_idx = xbridge_allocate_devio(sc, dev, 0);
d3024 3
a3026 3
			base = (sc->sc_devio_skew << 24) |
			    BRIDGE_DEVIO_OFFS(devio_idx);
			xbridge_set_devio(sc, devio_idx, devio |
d3030 1
a3030 1
		} else if (sc->sc_ioex != NULL) {
d3039 1
a3039 1
				if (extent_alloc(sc->sc_ioex, exsize,
d3121 1
a3121 1
	struct xbridge_softc *sc = pa->pa_pc->pc_conf_v;
d3132 1
a3132 1
		start = (sc->sc_devio_skew + 1) << 24;
d3158 1
a3158 1
xbridge_allocate_devio(struct xbridge_softc *sc, int dev, int wantlarge)
d3167 1
a3167 1
	if (sc->sc_devices[dev].devio == 0) {
d3178 2
a3179 2
	for (dev = 0; dev < BRIDGE_NSLOTS; dev++) {
		if (sc->sc_devices[dev].devio != 0)
d3182 1
a3182 1
		id = sc->sc_devices[dev].id;
d3195 1
a3195 1
xbridge_set_devio(struct xbridge_softc *sc, int dev, uint32_t devio)
d3197 3
a3199 3
	bus_space_write_4(sc->sc_iot, sc->sc_regh, BRIDGE_DEVICE(dev), devio);
	(void)bus_space_read_4(sc->sc_iot, sc->sc_regh, WIDGET_TFLUSH);
	sc->sc_devices[dev].devio = devio;
@


1.43
log
@A better implementation of bus_space_subregion() for xbridge, with boundary
checks if option DIAGNOSTIC.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.42 2009/07/26 18:48:55 miod Exp $	*/
d1103 1
a1104 1
#ifdef DIAGNOSTIC
@


1.42
log
@Make sure all platforms understand the flags argument of bus_space_map() and
bus_space_alloc() as a bitmask of flags, and not a boolean controlling
cacheability; and make sure the three MI BUS_SPACE_MAP_xxx values documented
in the manual page are defined on all platforms as well.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.41 2009/07/23 19:24:03 miod Exp $	*/
d179 6
d318 1
d334 1
d1063 6
d1089 6
d1099 109
d2330 2
d2373 2
@


1.41
log
@When configuring devices on the bridge, try and provide resources to map
their ROM if they have any.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.40 2009/07/21 21:25:19 miod Exp $	*/
d1000 1
a1000 1
    int cacheable, bus_space_handle_t *bshp)
d1043 1
a1043 1
    int cacheable, bus_space_handle_t *bshp)
d1053 1
a1053 1
		return xbridge_space_map_devio(t, offs, size, cacheable, bshp);
d1061 1
a1061 1
    int cacheable, bus_space_handle_t *bshp)
d1073 1
a1073 1
		return xbridge_space_map_devio(t, offs, size, cacheable, bshp);
@


1.40
log
@PCI-Cardbus bridge support for both O2 (macepcibr) and Octane/Origin (xbridge)
class systems. Tested on O2 and Origin 200 with wi@@pcmcia and xl@@cardbus,
using a Ricoh 5C475-based cbb(4) board.

acx@@cardbus doesn't work reliably yet, so your mileage may vary until more
bugs are fixed.

Thanks to matthieu@@ for lending me some cardbus devices for testing.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.39 2009/07/18 16:38:49 miod Exp $	*/
d2295 1
a2295 1
	pcireg_t bhlc, type;
d2298 1
a2298 1
	int reg, reg_start, reg_end;
d2306 1
d2311 1
d2316 1
d2362 22
d2392 1
a2392 1
	pcireg_t bhlc, type;
d2395 1
a2395 1
	int reg, reg_start, reg_end;
d2402 1
d2407 1
d2412 1
d2470 27
@


1.39
log
@Reconfigure all onboard devices, ignoring the existing mappings set up by
ARCS, except for IOC3 devices (which might be our console). This allows
us to build resource accounting extents to pass the MI code (for more magic).
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.38 2009/07/17 19:40:12 miod Exp $	*/
d54 2
d65 2
d146 1
d149 2
d188 5
d360 1
d362 4
d807 6
d1859 1
a1859 1
	uint secondary, nppb, ppbstride;
d1889 1
a1889 1
	nppb = 0;
d1897 1
a1897 1
		 * Count ppb devices, we will need their number later.
d1904 2
d1990 1
a1990 1
	 * Configure PCI-PCI bridges, if any.
d1996 11
d2008 3
d2012 2
a2013 4
	if (nppb != 0) {
		ppbstride = (256 - secondary) / nppb;
		for (dev = 0; dev < BRIDGE_NSLOTS; dev++) {
			id = sc->sc_devices[dev].id;
d2015 2
a2016 3
			if (PCI_VENDOR(id) == PCI_VENDOR_INVALID ||
			    PCI_VENDOR(id) == 0)
				continue;
d2018 15
a2032 8
			tag = pci_make_tag(pc, 0, dev, 0);
			bhlcr = pci_conf_read(pc, tag, PCI_BHLC_REG);

			if (PCI_HDRTYPE_TYPE(bhlcr) == 1) {
				ppb_initialize(pc, tag, secondary,
				    secondary + ppbstride - 1);
				secondary += ppbstride;
			}
d2056 1
a2056 1
	bus_addr_t start;
d2085 9
d2132 9
d2252 1
a2252 2
		 * to avoid ambiguous mappings (all addresses under
		 * the devio area need to be expelled).
d2257 2
a2258 2
		start = 0;
		end = ((sc->sc_devio_skew + 1) << 24) - 1;
d2263 3
a2265 3
			if (end > ex->ex_end)
				end = ex->ex_end;
			if (extent_alloc_region(ex, start, end - start + 1,
d2727 101
@


1.38
log
@Proper bus_space_{read,write}_raw_[248] functions for xbridge, makes wi@@pci
work on systems with xbridge.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.37 2009/07/17 18:06:51 miod Exp $	*/
d107 6
d114 1
a114 1
	 * resource setup and destroyed afterwards.
d116 1
d118 1
d201 1
d361 2
d368 2
a369 2
	pba.pba_ioex = NULL;
	pba.pba_memex = NULL;
d823 1
d1836 1
a1836 1
	uint curppb, nppb;
d1860 1
a1860 1
	} else
d1866 1
a1866 1
	curppb = nppb = 0;
d1904 2
a1905 3
		if (sys_config.system_type == SGI_OCTANE &&
		    sc->sc_widget == WIDGET_MAX)
			need_setup = 0;
d1937 2
a1938 3
		xbridge_set_devio(sc, dev, devio);

		if (need_setup == 0)
d1940 1
d1971 21
a1991 2
	for (dev = 0; dev < BRIDGE_NSLOTS; dev++) {
		id = sc->sc_devices[dev].id;
d1993 9
a2001 2
		if (PCI_VENDOR(id) == PCI_VENDOR_INVALID || PCI_VENDOR(id) == 0)
			continue;
d2003 12
a2014 2
		tag = pci_make_tag(pc, 0, dev, 0);
		bhlcr = pci_conf_read(pc, tag, PCI_BHLC_REG);
d2016 39
a2054 2
		if (PCI_HDRTYPE_TYPE(bhlcr) != 1)
			continue;
d2056 31
a2086 8
		/*
		 * Being PCI bus #0, we can allocate #1-#255 bus numbers
		 * to the PCI-PCI bridges.
		 * We'll simply split this 255 bus number space accross
		 * all bridges.
		 * Thus, given N bridges on the bus, bridge #M will get
		 * 1 + M * (255/N) .. (M + 1) * (255 / N).
		 */
d2088 4
a2091 3
		ppb_initialize(pc, tag, 1 + curppb * (255 / nppb),
		    (curppb + 1) * (255 / nppb));
		curppb++;
a2092 5

	if (sc->sc_ioex != NULL)
		extent_destroy(sc->sc_ioex);
	if (sc->sc_memex != NULL)
		extent_destroy(sc->sc_memex);
d2140 3
d2181 3
d2191 2
a2192 1
		 * to avoid ambiguous mappings.
a2196 8
#if 0
		start = sc->sc_devio_skew << 24;
		end = start + (1 << 24) - 1;
#else
		/*
		 * Apparently, all addresses under devio need to be
		 * expelled...
		 */
a2198 1
#endif
d2587 1
a2587 1
		} else {
d2642 1
a2642 1
		} else {
@


1.37
log
@Update bus_dma to the better codebase found on almost all other platforms,
where the common part to all bus_dmamap_load*() functions is implemented in
in an internal load_buffer routine.

This allows the xbridge-specific dma code to only provide this function,
instead of three; and this also brings us a working bus_dmamap_load_uio()
on all supported sgi machines, which in turns make crpyto(4) devices really
work. Tested with hifn(4).
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.36 2009/07/17 07:14:00 miod Exp $	*/
d149 8
d297 4
d312 4
d898 1
a898 1
		*(uint16_t *)buf = *addr;
d910 1
a910 1
		*addr = *(uint16_t *)buf;
d912 48
@


1.36
log
@Revert a not-thoroughly tested change part of a larger work in progress diff,
which crept in the previous commit.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.35 2009/07/16 21:02:58 miod Exp $	*/
d157 2
a158 5
int	xbridge_dmamap_load(bus_dma_tag_t, bus_dmamap_t, void *, bus_size_t,
	    struct proc *, int);
int	xbridge_dmamap_load_mbuf(bus_dma_tag_t, bus_dmamap_t, struct mbuf *,
	    int);
int	xbridge_dmamap_load_uio(bus_dma_tag_t, bus_dmamap_t, struct uio *, int);
d195 3
a197 3
	xbridge_dmamap_load,
	xbridge_dmamap_load_mbuf,
	xbridge_dmamap_load_uio,
d199 1
d1352 1
a1352 1
 * bus_dmamap_load() implementation.
d1355 3
a1357 2
xbridge_dmamap_load(bus_dma_tag_t t, bus_dmamap_t map, void *buf,
    bus_size_t buflen, struct proc *p, int flags)
d1360 3
d1364 2
a1365 5
	bus_addr_t lastaddr, busaddr, endaddr;
	bus_size_t sgsize;
	bus_addr_t baddr, bmask;
	caddr_t vaddr = buf;
	int first, seg;
a1366 1
	bus_size_t saved_buflen;
d1369 4
a1372 10
	/*
	 * Make sure that on error condition we return "no valid mappings".
	 */
	map->dm_nsegs = 0;
	map->dm_mapsize = 0;
	for (seg = 0; seg < map->_dm_segcnt; seg++)
		map->dm_segs[seg].ds_addr = 0;

	if (buflen > map->_dm_size)
		return EINVAL;
d1379 1
d1384 1
a1384 2
	saved_buflen = buflen;
	for (first = 1, seg = 0; buflen > 0; ) {
d1388 1
a1388 1
		if (pmap_extract(pmap, (vaddr_t)vaddr, &pa) == FALSE)
d1456 3
a1466 98
	map->dm_nsegs = seg + 1;
	map->dm_mapsize = saved_buflen;
	return 0;

fail_unmap:
	/*
	 * If control goes there, we need to unref all our ATE, if any.
	 */
	for (seg = 0; seg < map->_dm_segcnt; seg++) {
		xbridge_address_unmap(sc, map->dm_segs[seg].ds_addr,
		    map->dm_segs[seg].ds_len);
		map->dm_segs[seg].ds_addr = 0;
	}

	return rc;
}

/*
 * bus_dmamap_load_mbuf() implementation.
 */
int
xbridge_dmamap_load_mbuf(bus_dma_tag_t t, bus_dmamap_t map, struct mbuf *m,
    int flags)
{
	struct xbridge_softc *sc = t->_cookie;
	bus_addr_t lastaddr, busaddr, endaddr;
	bus_size_t sgsize;
	paddr_t pa;
	vaddr_t lastva;
	int seg;
	size_t len;
	int rc;

	map->dm_nsegs = 0;
	map->dm_mapsize = 0;
	for (seg = 0; seg < map->_dm_segcnt; seg++)
		map->dm_segs[seg].ds_addr = 0;

	seg = 0;
	len = 0;
	while (m != NULL) {
		vaddr_t vaddr = mtod(m, vaddr_t);
		long buflen = (long)m->m_len;

		len += buflen;
		while (buflen > 0 && seg < map->_dm_segcnt) {
			if (pmap_extract(pmap_kernel(), vaddr, &pa) == FALSE)
				panic("%s: pmap_extract(%x, %x) failed",
				    __func__, pmap_kernel(), vaddr);

			/*
			 * Compute the DMA address and the physical range
			 * this mapping can cover.
			 */
			if (xbridge_address_map(sc, pa, &busaddr,
			    &endaddr) != 0) {
				rc = ENOMEM;
				goto fail_unmap;
			}

			sgsize = PAGE_SIZE - ((u_long)vaddr & PGOFSET);
			sgsize = min(buflen, sgsize);
			sgsize = min(endaddr - busaddr, sgsize);

			/*
			 * Try to coalesce with previous entry.
			 * We need both the physical addresses and
			 * the virtual address to be contiguous, for
			 * bus_dmamap_sync() to behave correctly.
			 */
			if (seg > 0 &&
			    busaddr == lastaddr && vaddr == lastva &&
			    (map->dm_segs[seg - 1].ds_len + sgsize <=
			     map->_dm_maxsegsz))
				map->dm_segs[seg - 1].ds_len += sgsize;
			else {
				map->dm_segs[seg].ds_addr = busaddr;
				map->dm_segs[seg].ds_len = sgsize;
				map->dm_segs[seg]._ds_vaddr = vaddr;
				seg++;
			}

			lastaddr = busaddr + sgsize;
			if (lastaddr == endaddr)
				lastaddr = ~0;	/* can't coalesce */
			vaddr += sgsize;
			lastva = vaddr;
			buflen -= sgsize;
		}
		m = m->m_next;
		if (m && seg >= map->_dm_segcnt) {
			/* Exceeded the size of our dmamap */
			rc = EFBIG;
			goto fail_unmap;
		}
	}
	map->dm_nsegs = seg;
	map->dm_mapsize = len;
a1479 10
}

/*
 * bus_dmamap_load_uio() non-implementation.
 */
int
xbridge_dmamap_load_uio(bus_dma_tag_t t, bus_dmamap_t map, struct uio *uio,
    int flags)
{
	return EOPNOTSUPP;
@


1.35
log
@Make the PCI-PCI bridge initialization code bus-independent, relying on a
per-pci_chipset_t function to perform actual resource allocation.
Add the necessary bits to macepcibr(4), and enable ppb(4) on O2 kernels now.

Joint effort with kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.34 2009/07/13 21:19:28 miod Exp $	*/
d677 1
a677 1
		 * XXX at IPL_TTY, in case the interrupt will be shared
d681 1
a681 1
		    IPL_TTY, NULL)) {
@


1.34
log
@Extend xbridge to support shared interrupt handlers, and perform PCI-PCI
bridge initialization if necessary; enable ppb on IP27 and IP30 kernels.
With feedback from kettenis@@; macepcibr to gain the same functionality soon.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.33 2009/07/06 22:46:43 miod Exp $	*/
d89 3
d97 3
d105 7
d124 1
a126 1
int	xbridge_bus_maxdevs(void *, int);
a128 1

d134 3
d187 1
a187 2
void	xbridge_device_setup(struct xbridge_softc *, int, int, uint32_t,
	    struct extent **, struct extent **);
a189 2
void	xbridge_ppb_setup(struct xbridge_softc *, int, uint, uint,
	    struct extent **, struct extent **);
d325 1
d407 1
a407 1
	return BRIDGE_NSLOTS;
d677 1
a677 1
		 * XXX at IPL_BIO, in case the interrupt will be shared
d681 1
a681 1
		    IPL_BIO, NULL)) {
a1874 1
	struct extent *io_ex = NULL, *mem_ex = NULL;
d1895 3
a1897 3
		io_ex = xbridge_mapping_setup(sc, 1);
		mem_ex = xbridge_mapping_setup(sc, 0);
	}
d1916 1
a1916 1
		if (PCI_HDRTYPE(bhlcr) == 1)
d1999 1
a1999 1
		xbridge_device_setup(sc, dev, nfuncs, devio, &io_ex, &mem_ex);
d2018 1
a2018 1
		if (PCI_HDRTYPE(bhlcr) != 1)
d2030 2
a2031 2
		xbridge_ppb_setup(sc, dev, 1 + curppb * (255 / nppb),
		    (curppb + 1) * (255 / nppb), &io_ex, &mem_ex);
d2035 4
a2038 4
	if (io_ex != NULL)
		extent_destroy(io_ex);
	if (mem_ex != NULL)
		extent_destroy(mem_ex);
d2136 1
d2139 8
d2190 1
a2190 1
	switch (PCI_HDRTYPE(bhlc)) {
d2261 1
a2261 1
	switch (PCI_HDRTYPE(bhlc)) {
d2335 1
a2335 1
    uint32_t devio, struct extent **large_ioex, struct extent **large_memex)
d2340 1
a2340 1
	pcireg_t id;
d2359 1
a2359 1
	if (*large_ioex != NULL)
d2365 1
a2365 1
	if (*large_memex != NULL)
d2381 4
d2411 1
a2411 1
		     *large_ioex == NULL))
d2428 2
a2429 2
			if (*large_ioex == NULL)
				*large_ioex = xbridge_mapping_setup(sc, 1);
d2454 2
a2455 2
			if (*large_memex == NULL)
				*large_memex = xbridge_mapping_setup(sc, 0);
d2473 2
a2474 2
		    ioex != NULL ? ioex : *large_ioex,
		    memex != NULL ?  memex : *large_memex);
d2483 3
a2485 3
void
xbridge_ppb_setup(struct xbridge_softc *sc, int dev, uint secondary,
    uint subordinate, struct extent **large_ioex, struct extent **large_memex)
d2487 1
d2489 1
a2489 5
	pcitag_t tag;
	uint32_t devio;
	uint32_t base;
	bus_addr_t iostart, ioend;
	bus_addr_t memstart, memend;
d2492 1
a2492 2
	int devio_idx;
	int tries;
d2494 1
a2494 2
	iostart = memstart = 0;
	ioend = memend = 0xffffffff;
d2498 3
a2500 8
	 * Since we can't know in advance how much resource space will be
	 * needed by the devices behind the bridge, try to be generous.
	 *
	 * We'll try to get large mappings, and provide 1/8 of the range
	 * to the bridge.  If this isn't possible, we'll try to allocate
	 * the largest possible devio range.  This can still fail since
	 * we want to provide both I/O and memory resources and might
	 * not have enough devio slots available.
d2503 6
a2508 5
	if (*large_memex == NULL)
		*large_memex = xbridge_mapping_setup(sc, 0);
	if (*large_memex == NULL) {
		devio_idx = xbridge_allocate_devio(sc, dev, 1);
		if (devio_idx < 0)
d2510 18
a2527 3
		if (devio_idx < 0) {
			/* no resources */
		} else {
d2533 22
a2554 23
			memstart = base;
			memend = base + BRIDGE_DEVIO_SIZE(devio_idx) - 1;
		}
	} else {
		/*
		 * We know that the direct memory resource range fits
		 * within the 32 bit address space, and is limited to
		 * 30 bits, so our allocation, if successfull, will work
		 * as a 32 bit memory range.
		 */
		exsize = (*large_memex)->ex_end + 1 - (*large_memex)->ex_start;
		if ((*large_memex)->ex_start == 1)
			exsize++;
		exsize /= BRIDGE_NSLOTS;
		/* no need to round, exsize is >= 1 << 25 */

		for (tries = 0; tries < 5; tries++) {
			if (extent_alloc(*large_memex, exsize,
			    1UL << 20, 0, 0, EX_NOWAIT | EX_MALLOCOK,
			    &exstart) == 0) {
				memstart = exstart;
				memend = exstart + exsize - 1;
				break;
a2555 1
			exsize >>= 1;
d2559 6
a2564 5
	if (*large_ioex == NULL)
		*large_ioex = xbridge_mapping_setup(sc, 1);
	if (*large_ioex == NULL) {
		devio_idx = xbridge_allocate_devio(sc, dev, 1);
		if (devio_idx < 0)
d2566 18
a2583 3
		if (devio_idx < 0) {
			/* no resources */
		} else {
d2588 21
a2608 22
			iostart = base;
			ioend = base + BRIDGE_DEVIO_SIZE(devio_idx) - 1;
		}
	} else {
		/*
		 * We know that the direct I/O resource range fits
		 * within the 32 bit address space, so our allocation,
		 * if successfull, will work as a 32 bit i/o range.
		 */
		exsize = (*large_ioex)->ex_end + 1 - (*large_ioex)->ex_start;
		if ((*large_ioex)->ex_start == 1)
			exsize++;
		exsize /= BRIDGE_NSLOTS;
		/* no need to round, exsize is >= 1 << 25 */

		for (tries = 0; tries < 5; tries++) {
			if (extent_alloc(*large_ioex, exsize,
			    1UL << 12, 0, 0, EX_NOWAIT | EX_MALLOCOK,
			    &exstart) == 0) {
				iostart = exstart;
				ioend = exstart + exsize - 1;
				break;
a2609 1
			exsize >>= 1;
d2613 1
a2613 10
	/*
	 * Finally program the bridge registers.
	 *
	 * We do not expect PCI-PCI bridges to be multifunction
	 * devices, so we'll only configure function #0.
	 */

	tag = pci_make_tag(pc, 0, dev, 0);
	ppb_initialize(pc, tag, secondary, subordinate, iostart, ioend,
	    memstart, memend);
@


1.33
log
@Almost rewrite xbridge PCI resource allocation:
- introduce an interface for widget drivers to ask the xbow to map arbitrary
  views of their address space, in addition to the low 16MB. This operation
  may fail or map a subset range of what the caller asked for, depending on
  the platform we're running on.
- use this in xbridge to set up views on the direct memory and i/o spaces,
  to map devices resources when they don't fit in one of the devio small
  ranges (limited to 2MB anyway). These views are only allocated when
  devio can't do the job, so as not to consume too many resources on
  Origin family systems where such views are scarce resources (and
  shared accross the whole crossbow).

This makes pci devices with large resource needs configure correctly.

While there, fix programming of 64 bit memory BAR; this makes bge(4)
work.

Tested on Octane (with Bridge revision < 4 and >= 4), Origin 200 (Bridge >= 4)
and Fuel (XBridge).

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.32 2009/07/03 19:28:47 miod Exp $	*/
d52 1
a71 1
	int		sc_revision;
d73 2
a74 1
#define	XBRIDGE_FLAGS_XBRIDGE	0x01	/* is XBridge vs Bridge */
a86 1
	int		sc_intrbit[BRIDGE_NINTRS];
d157 1
d176 2
a230 1
	sc->sc_revision = xaa->xaa_revision;
d236 2
d384 1
a384 1
		*busp = (tag >> 16) & 0x7;
d540 10
d554 1
a554 7
	int	xi_device;	/* device slot number */

	int	(*xi_func)(void *);
	void	*xi_arg;

	struct evcount	xi_count;
	int	 xi_level;
d558 2
a559 1
#define	XBRIDGE_INTR_HANDLE(d,b)	(0x100 | ((d) << 3) | (b))
d568 1
d570 1
a570 1
	*ihp = -1;
d586 5
a590 6
	/*
	 * For IOC devices, the real information is in pa_intrline.
	 */
	if (sc->sc_devices[device].id ==
	    PCI_ID_CODE(PCI_VENDOR_SGI, PCI_PRODUCT_SGI_IOC3)) {
		intr = pa->pa_intrline;
d592 12
a603 4
		if (pa->pa_intrpin & 1)
			intr = device;
		else
			intr = device ^ 4;
d624 1
a624 1
	struct xbridge_softc *sc = cookie;
d626 1
d631 1
d634 2
a635 2
	 * XXX At worst, there can only be two interrupt handlers registered
	 * XXX on the same pin.
d637 9
a645 4
	if (sc->sc_intr[intrbit] != NULL) {
		printf("%s: nested interrupts are not supported\n", __func__);
		return NULL;
	}
d647 4
a650 3
	xi = (struct xbridge_intr *)malloc(sizeof(*xi), M_DEVBUF, M_NOWAIT);
	if (xi == NULL)
		return NULL;
d652 4
d657 1
a657 1
	 * Register the interrupt at the Heart or Hub level if it's the
d660 2
a661 4
	if ((intrsrc = sc->sc_intrbit[intrbit]) == -1) {
		if (xbow_intr_register(sc->sc_widget, level, &intrsrc) != 0)
			return NULL;
	
d663 3
a665 3
		 * We can afford registering this interrupt at `level'
		 * IPL since we do not support nested interrupt on a
		 * given source, yet.
d668 2
a669 3
		    level, NULL)) {
			printf("%s: unable to register interrupt handler, "
			    "did xheart or xhub attach?\n",
d673 6
d680 31
a710 1
		sc->sc_intrbit[intrbit] = intrsrc;
d713 1
a713 33
	xi->xi_bridge = sc;
	xi->xi_intrsrc = intrsrc;
	xi->xi_intrbit = intrbit;
	xi->xi_device = device;
	xi->xi_func = func;
	xi->xi_arg = arg;
	xi->xi_level = level;
	evcount_attach(&xi->xi_count, name, &xi->xi_level, &evcount_intr);
	sc->sc_intr[intrbit] = xi;

	int_addr = ((xbow_intr_widget_register >> 30) & 0x0003ff00) | intrsrc;

	bus_space_write_4(sc->sc_iot, sc->sc_regh, BRIDGE_INT_ADDR(intrbit),
	    int_addr);
	bus_space_write_4(sc->sc_iot, sc->sc_regh, BRIDGE_IER,
	    bus_space_read_4(sc->sc_iot, sc->sc_regh, BRIDGE_IER) |
	    (1 << intrbit));
	/*
	 * INT_MODE register controls which interrupt pins cause
	 * ``interrupt clear'' packets to be sent for high->low
	 * transition.
	 * We enable such packets to be sent in order not to have to
	 * clear interrupts ourselves.
	 */
	bus_space_write_4(sc->sc_iot, sc->sc_regh, BRIDGE_INT_MODE,
	    bus_space_read_4(sc->sc_iot, sc->sc_regh, BRIDGE_INT_MODE) |
	    (1 << intrbit));
	bus_space_write_4(sc->sc_iot, sc->sc_regh, BRIDGE_INT_DEV,
	    bus_space_read_4(sc->sc_iot, sc->sc_regh, BRIDGE_INT_DEV) |
	    (device << (intrbit * 3)));
	(void)bus_space_read_4(sc->sc_iot, sc->sc_regh, WIDGET_TFLUSH);

	return (void *)((uint64_t)ih);
d720 3
a722 3
	struct xbridge_intr *xi;
	pci_intr_handle_t ih = (pci_intr_handle_t)(uint64_t)vih;
	int intrbit = XBRIDGE_INTR_BIT(ih);
d724 2
a725 3
	/* should not happen */
	if ((xi = sc->sc_intr[intrbit]) == NULL)
		return;
d727 13
a739 11
	bus_space_write_4(sc->sc_iot, sc->sc_regh, BRIDGE_INT_ADDR(intrbit), 0);
	bus_space_write_4(sc->sc_iot, sc->sc_regh, BRIDGE_IER,
	    bus_space_read_4(sc->sc_iot, sc->sc_regh, BRIDGE_IER) &
	    ~(1 << intrbit));
	bus_space_write_4(sc->sc_iot, sc->sc_regh, BRIDGE_INT_MODE,
	    bus_space_read_4(sc->sc_iot, sc->sc_regh, BRIDGE_INT_MODE) &
	    ~(1 << intrbit));
	bus_space_write_4(sc->sc_iot, sc->sc_regh, BRIDGE_INT_DEV,
	    bus_space_read_4(sc->sc_iot, sc->sc_regh, BRIDGE_INT_DEV) &
	    ~(7 << (intrbit * 3)));
	(void)bus_space_read_4(sc->sc_iot, sc->sc_regh, WIDGET_TFLUSH);
d741 6
a746 3
	evcount_detach(&xi->xi_count);

	xbow_intr_disestablish(xi->xi_intrsrc);
d748 1
a748 2
	sc->sc_intr[intrbit] = NULL;
	free(xi, M_DEVBUF);
d754 1
a754 1
	struct xbridge_intr *xi = v;
d756 2
a757 1
	int rc;
d760 1
a760 1
	if (xi == NULL) {
d769 3
a771 2
	bus_space_read_4(sc->sc_iot, sc->sc_regh,
	    BRIDGE_DEVICE_WBFLUSH(xi->xi_device));
d784 6
a789 2
	if ((rc = (*xi->xi_func)(xi->xi_arg)) != 0)
		xi->xi_count.ec_count++;
d1017 48
d1196 1
a1196 1
	    (xbow_intr_widget << ATE_WIDGET_SHIFT) | ATE_V);
d1289 5
d1677 1
a1677 1
	int dev, i;
a1753 3

	for (i = 0; i < BRIDGE_NINTRS; i++)
		sc->sc_intrbit[i] = -1;
d1860 1
d1887 5
d1899 9
d1958 5
a1980 3
		tag = pci_make_tag(pc, 0, dev, 0);
		bhlcr = pci_conf_read(pc, tag, PCI_BHLC_REG);

d1990 33
d2046 1
a2046 2
		if (ISSET(sc->sc_flags, XBRIDGE_FLAGS_XBRIDGE) ||
		    sc->sc_revision >= 4) {
d2458 124
d2589 1
a2589 1
	 * use it (we do n.
@


1.32
log
@Try to be smarter when allocating pci resources, and use unused devio slots
whenever possible for devices with both i/o and memory resources; still
doesn't allow more than 2MB of mappings per device in each space, though.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.31 2009/07/01 21:56:38 miod Exp $	*/
d71 1
a161 2
void	xbridge_setup(struct xbridge_softc *);

a164 1
void	xbridge_ate_setup(struct xbridge_softc *);
d169 6
d177 1
d228 1
a264 14
#ifdef notyet
	/*
	 * Memory mappings are available in the widget at
	 * offset BRIDGE_PCI_MEM_SPACE_BASE onwards.
	 */
	bcopy(xaa->xaa_iot, sc->sc_mem_bus_space,
	    sizeof(*sc->sc_mem_bus_space));
	sc->sc_mem_bus_space->bus_base = ...
	sc->sc_mem_ex = extent_create("pcimem",
	    0, BRIDGE_PCI_MEM_SPACE_LENGTH - 1,
	    M_DEVBUF, NULL, 0, EX_NOWAIT);
	sc->sc_mem_bus_space->_space_map = xbridge_space_map_mem;
#else
	/* Programmable memory mappings in the small window */
d267 1
a268 3
#endif

	sc->sc_mem_bus_space->bus_private = sc;
d276 2
a277 25
#ifdef notyet
	/*
	 * I/O mappings are available in the widget at
	 * offset BRIDGE_PCI_IO_SPACE_BASE onwards, but
	 * weren't working correctly until Bridge revision 4.
	 */
	if (ISSET(sc->sc_flags, XBRIDGE_FLAGS_XBRIDGE) ||
	    xaa->xaa_revision >= 4) {
		/* Unrestricted I/O mappings in the large window */
		bcopy(xaa->xaa_iot, sc->sc_io_bus_space,
		    sizeof(*sc->sc_io_bus_space));
		sc->sc_io_bus_space->bus_base = ...
		sc->sc_io_ex = extent_create("pciio",
		    0, BRIDGE_PCI_IO_SPACE_LENGTH - 1,
		    M_DEVBUF, NULL, 0, EX_NOWAIT);
		sc->sc_io_bus_space->_space_map = xbridge_space_map_io;
	} else
#endif
	       {
		/* Programmable I/O mappings in the small window */
		bcopy(xaa->xaa_iot, sc->sc_io_bus_space,
		    sizeof(*sc->sc_io_bus_space));
		sc->sc_io_bus_space->_space_map = xbridge_space_map_devio;
	}

d279 1
d854 3
a856 1
	bus_addr_t bpa, start, end;
d858 1
d868 1
d881 1
a891 1
#ifdef notyet
d906 1
a906 5
	/* check that this doesn't overflow the window */
	if (offs + size > BRIDGE_PCI_IO_SPACE_LENGTH || offs + size < offs)
		return EINVAL;

	*bshp = t->bus_base + BRIDGE_PCI_IO_SPACE_BASE + offs;
d918 2
a919 1
	 * window.
d922 2
a923 1
	if ((offs >> 24) == sc->sc_devio_skew)
d926 1
a926 5
	/* check that this doesn't overflow the window */
	if (offs + size > BRIDGE_PCI_MEM_SPACE_LENGTH || offs + size < offs)
		return EINVAL;

	*bshp = t->bus_base + BRIDGE_PCI_MEM_SPACE_BASE + offs;
a928 1
#endif
d1186 5
d1427 2
a1428 1
			sgsize = min(buflen, PAGE_SIZE);
d1584 1
a1627 1
#ifdef notyet
d1629 11
a1639 17
	 * Enable byteswapping on accesses through the large window,
	 * except on the main I/O widget on Octane, where the default
	 * mappings require them to be disabled (which doesn't matter,
	 * since the contents of the PCI bus are immutable and well-known).
	 */

	if (sys_config.system_type != SGI_OCTANE ||
	    sc->sc_widget != WIDGET_MAX) {
		uint32_t ctrl = bus_space_read_4(sc->sc_iot, sc->sc_regh,
		    WIDGET_CONTROL);
		ctrl |= BRIDGE_WIDGET_CONTROL_IO_SWAP;
		ctrl |= BRIDGE_WIDGET_CONTROL_MEM_SWAP;
		bus_space_write_4(sc->sc_iot, sc->sc_regh, WIDGET_CONTROL,
		    ctrl);
		(void)bus_space_read_4(sc->sc_iot, sc->sc_regh, WIDGET_TFLUSH);
	}
#endif
d1760 1
a1760 1
 * Flags returned by xbridge_resource_explore()
a1761 7
#define	XR_IO		0x01	/* needs I/O mappings */
#define	XR_MEM		0x02	/* needs memory mappings */
#define	XR_IO_OFLOW_S	0x04	/* can't fit I/O in a short devio */
#define	XR_MEM_OFLOW_S	0x08	/* can't fit memory in a short devio */
#define	XR_IO_OFLOW	0x10	/* can't fit I/O in a large devio */
#define	XR_MEM_OFLOW	0x20	/* can't fit memory in a large devio */

d1766 1
a1766 1
	int dev, function, nfuncs;
d1769 2
d1772 12
a1783 5
	uint32_t devio, basewin;
	int need_setup;
	int resources;
	int io_devio, mem_devio;
	struct extent *ioex, *memex;
d1786 2
a1787 5
	 * Figure out where the devio mappings will lie in the widget.
	 * On Octane (at least for the on-board devices widget), they are
	 * relative to the beginning of the widget.
	 * On other systems, they are offset an address multiple of the
	 * widget number.
d1789 1
a1789 3
	 * We could remap everything to the beginning of the widget, but
	 * since we need serial console mappings early, we can not afford
	 * changing how ARCS maps the IOC device.
a1791 1
	sc->sc_devio_skew = sc->sc_widget;
d1793 2
a1794 4
#if 0 /* no reason not to expect all octane xbridge to behave the same way */
		if (sc->sc_widget == WIDGET_MAX)
#endif
			sc->sc_devio_skew = 0;
d1804 14
a1817 4
		 * Devices which have been configured by the firmware
		 * have their I/O window pointing to the bridge widget.
		 * XXX We only need to preserve IOC3 devio settings if
		 * XXX it is the console.
d1819 1
d1822 3
a1824 8
		need_setup = ((devio & BRIDGE_DEVICE_BASE_MASK) >>
		    (24 - BRIDGE_DEVICE_BASE_SHIFT)) != sc->sc_devio_skew;

		/*
		 * On Octane, the firmware will setup the I/O registers
		 * correctly for the on-board devices, except for byteswap.
		 * Other PCI buses, and other systems, need more attention.
		 */
d1828 4
d1837 3
a1839 3
		devio &= ~(BRIDGE_DEVICE_SWAP_DIR | BRIDGE_DEVICE_SWAP_PMU);
		if (id != PCI_ID_CODE(PCI_VENDOR_SGI, PCI_PRODUCT_SGI_IOC3) &&
		    id != PCI_ID_CODE(PCI_VENDOR_SGI, PCI_PRODUCT_SGI_RAD1))
d1841 12
d1854 3
a1856 2
		if (need_setup == 0) {
			xbridge_set_devio(sc, dev, devio);
a1857 1
		}
d1860 1
a1860 1
		 * Setup our proto devio value.
a1861 1

d1864 1
d1881 19
d1901 4
a1904 6
		 * In a first step, we enumerate all the requested resources,
		 * and check if they can fit within a devio mapping.
		 *
		 * Note that this is tricky, because if the device has both
		 * I/O and memory resources to map, we might not be able
		 * to get a second devio, or to get one of the same size.
d1907 14
a1920 4
		ioex = extent_create("xbridge_io", 0, BRIDGE_DEVIO_LARGE - 1,
		    M_DEVBUF, NULL, 0, EX_NOWAIT);
		memex = extent_create("xbridge_mem", 0, BRIDGE_DEVIO_LARGE - 1,
		    M_DEVBUF, NULL, 0, EX_NOWAIT);
d1922 5
a1926 8
		resources = 0;
		for (function = 0; function < nfuncs; function++) {
			tag = pci_make_tag(pc, 0, dev, function);
			id = pci_conf_read(pc, tag, PCI_ID_REG);

			if (PCI_VENDOR(id) == PCI_VENDOR_INVALID ||
			    PCI_VENDOR(id) == 0)
				continue;
d1928 9
a1936 2
			resources |= xbridge_resource_explore(sc, tag,
			    ioex, memex);
d1938 5
d1944 4
a1947 4
		extent_destroy(memex);
		memex = NULL;
		extent_destroy(ioex);
		ioex = NULL;
d1949 10
a1958 6
		/*
		 * If resources can be mapped using devio slots, allocate
		 * them. Otherwise, or if we can't get a devio slot
		 * big enough for the resources we need to map, we'll need
		 * to get a large window mapping.
		 */
d1960 5
a1964 17
		io_devio = -1;
		if (ISSET(resources, XR_IO)) {
			if (!ISSET(resources, XR_IO_OFLOW))
				io_devio = xbridge_allocate_devio(sc, dev,
				    ISSET(resources, XR_IO_OFLOW_S));
			if (io_devio >= 0) {
				basewin = (sc->sc_widget << 24) |
				    BRIDGE_DEVIO_OFFS(io_devio);
				xbridge_set_devio(sc, io_devio, devio |
				    (basewin >> BRIDGE_DEVICE_BASE_SHIFT));

				ioex = extent_create("xbridge_io", basewin,
				    basewin + BRIDGE_DEVIO_SIZE(io_devio) - 1,
				    M_DEVBUF, NULL, 0, EX_NOWAIT);
			}
			/* XXX else get a large window mapping */
		}
d1966 8
a1973 15
		mem_devio = -1;
		if (ISSET(resources, XR_MEM)) {
			if (!ISSET(resources, XR_MEM_OFLOW))
				mem_devio = xbridge_allocate_devio(sc, dev,
				    ISSET(resources, XR_MEM_OFLOW_S));
			if (mem_devio >= 0) {
				basewin = (sc->sc_widget << 24) |
				    BRIDGE_DEVIO_OFFS(mem_devio);
				xbridge_set_devio(sc, mem_devio, devio |
				    BRIDGE_DEVICE_IO_MEM |
				    (basewin >> BRIDGE_DEVICE_BASE_SHIFT));

				memex = extent_create("xbridge_mem", basewin,
				    basewin + BRIDGE_DEVIO_SIZE(mem_devio) - 1,
				    M_DEVBUF, NULL, 0, EX_NOWAIT);
a1974 1
			/* XXX else get a large window mapping */
d1976 1
d1978 10
a1987 3
		for (function = 0; function < nfuncs; function++) {
			tag = pci_make_tag(pc, 0, dev, function);
			id = pci_conf_read(pc, tag, PCI_ID_REG);
d1989 14
a2002 5
			if (PCI_VENDOR(id) == PCI_VENDOR_INVALID ||
			    PCI_VENDOR(id) == 0)
				continue;

			xbridge_resource_manage(sc, tag, ioex, memex);
d2004 1
d2006 1
a2006 5
		if (memex != NULL)
			extent_destroy(memex);
		if (ioex != NULL)
			extent_destroy(ioex);
	}
d2009 10
d2069 2
a2070 1
			}
d2082 2
a2083 1
			}
d2133 4
d2138 8
a2146 1
		case PCI_MAPREG_TYPE_MEM | PCI_MAPREG_MEM_TYPE_64BIT:
d2164 3
d2169 1
a2169 1
		if (type & PCI_MAPREG_MEM_TYPE_64BIT)
d2174 146
d2363 3
@


1.31
log
@The widget mapping code has been written back when I was only working on
Octane support. The Octane being a single-node system, address space is
ludicrous enough to allow the whole address space of every widget to be
directly accessible in whole, using the address bits reserved to nasid.

However, on IP27 and IP35, things do not work this way - while we still have
the low 16MB address space of each widget available (the so-called
``short window''), access to other parts of the wiget address space is done
through translation slots (IOTTE) at the Hub I/O space level, on a per-node
basis.

Given the imminent release lock, give up completely on ``large'' mappings
of widgets, and restrict ourselves to short window operation, all the time
(thus reinforcing the use of devio registers to map pci resources on xbridge).
A proper interface to request mappings of specific widget areas, either
directly on Octane, or through IOTTE if available on Origin, will appear
post-release.

No functional change (except from silently repairing Octane support which the
previous xbridge commit silently broke).
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.30 2009/06/28 21:52:54 miod Exp $	*/
d20 7
a26 1
 * XBow Bridge Widget driver.
d88 4
a91 1
	pcireg_t	sc_devices[BRIDGE_NSLOTS];
d163 3
d167 2
a168 2
void	xbridge_resource_explore(struct xbridge_softc *, pcitag_t,
	    uint *, uint *);
d170 1
a170 1
	    struct extent *, int);
d460 1
a460 1
	if (bus == 0 && sc->sc_devices[dev] ==
d527 1
a527 1
	if (bus == 0 && sc->sc_devices[dev] ==
d611 1
a611 1
	if (sc->sc_devices[device] ==
d1624 2
a1625 2
		if (guarded_read_4(pa, &sc->sc_devices[dev]) != 0)
			sc->sc_devices[dev] =
d1720 1
a1720 1
		if (PCI_VENDOR(sc->sc_devices[dev]) == PCI_VENDOR_INVALID)
d1755 1
a1755 1
				if (PCI_VENDOR(sc->sc_devices[dev]) !=
d1794 10
a1812 1
	uint io, mem;
d1814 3
a1816 1
	struct extent *ex;
d1839 1
a1839 1
		id = sc->sc_devices[dev];
a1851 1
		basewin = (sc->sc_widget << 24) | BRIDGE_DEVIO_OFFS(dev);
a1863 13
		if (need_setup) {
			devio &= ~BRIDGE_DEVICE_BASE_MASK;

			/*
			 * Default to I/O resources only for now.
			 * If we setup memory resources, this bit
			 * will be flipped later on.
			 */
			devio &= ~BRIDGE_DEVICE_IO_MEM;

			devio |= (basewin >> BRIDGE_DEVICE_BASE_SHIFT);
		}

d1873 8
a1880 3
		bus_space_write_4(sc->sc_iot, sc->sc_regh, BRIDGE_DEVICE(dev),
		    devio);
		(void)bus_space_read_4(sc->sc_iot, sc->sc_regh, WIDGET_TFLUSH);
d1882 2
a1883 2
		if (need_setup == 0)
			continue;
a1889 6
		ex = extent_create("pcires",
		    basewin, basewin + BRIDGE_DEVIO_SIZE(dev) - 1,
		    M_DEVBUF, NULL, 0, EX_NOWAIT);
		if (ex == NULL)
			continue;

d1901 6
a1906 1
		 * Count how many I/O and memory mappings are necessary.
d1909 6
a1914 1
		io = mem = 0;
d1923 2
a1924 1
			xbridge_resource_explore(sc, tag, &io, &mem);
d1927 5
d1933 4
a1936 4
		 * For devices having both I/O and memory resources, we
		 * favour the I/O resources so far. Eventually this code
		 * should attempt to steal a devio from an unpopulated
		 * slot.
d1939 36
a1974 9
		if (io == 0 && mem != 0) {
			/* swap devio type */
			devio |= BRIDGE_DEVICE_IO_MEM;
			bus_space_write_4(sc->sc_iot, sc->sc_regh,
			    BRIDGE_DEVICE(dev), devio);
			(void)bus_space_read_4(sc->sc_iot, sc->sc_regh,
			    WIDGET_TFLUSH);
		} else
			mem = 0;
d1984 1
a1984 1
			xbridge_resource_manage(sc, tag, ex, mem != 0);
d1987 4
a1990 1
		extent_destroy(ex);
d1994 1
a1994 1
void
d1996 1
a1996 1
    uint *nio, uint *nmem)
d2000 2
d2003 1
d2020 1
a2020 1
		return;
d2027 1
a2027 1
		if (pci_mapreg_info(pc, tag, reg, type, NULL, NULL, NULL))
d2031 3
d2035 10
a2044 2
		case PCI_MAPREG_TYPE_MEM | PCI_MAPREG_MEM_TYPE_64BIT:
			(*nmem)++;
d2047 10
a2056 1
			(*nio)++;
d2059 1
d2061 1
a2061 3
		if (type & PCI_MAPREG_MEM_TYPE_64BIT)
			reg += 4;
	}
d2066 1
a2066 1
    struct extent *ex, int prefer_mem)
d2109 2
a2110 2
			if (prefer_mem != 0) {
				if (extent_alloc(ex, size, size, 0, 0, 0,
d2117 2
a2118 2
			if (prefer_mem == 0) {
				if (extent_alloc(ex, size, size, 0, 0, 0,
d2131 45
@


1.30
log
@Attempt to map memory resources of unconfigured devices, if they do not have
I/O resources, via devio.

Unfortunately it works as badly as when using the large window, so the bugs
I am hunting must come from elsewhere.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.29 2009/06/27 22:23:17 miod Exp $	*/
d69 1
d72 3
a77 5
	struct extent	*sc_mem_ex;
	struct extent	*sc_io_ex;

	bus_space_tag_t sc_iot;
	bus_space_handle_t sc_regh;
d156 1
a156 1
	    int *, int *);
a207 1
	int direct_io_avail = 0;
d221 4
a224 1
	sc->sc_iot = xaa->xaa_short_tag;
d228 1
d248 5
a252 2
	/* Unrestricted memory mappings in the large window */
	bcopy(xaa->xaa_long_tag, sc->sc_mem_bus_space,
d254 1
d261 1
a261 1
	bcopy(xaa->xaa_short_tag, sc->sc_mem_bus_space,
d266 14
a281 25
		switch (sys_config.system_type) {
		default:
#if defined(TGT_ORIGIN200) || defined(TGT_ORIGIN2000)
		case SGI_O200:
		case SGI_O300:
			/*
			 * In N mode, the large window is truncated and the
			 * direct I/O area is not accessible.
			 */
			if (kl_n_mode == 0)
				direct_io_avail = 1;
			break;
#endif
#if defined(TGT_OCTANE)
		case SGI_OCTANE:
			direct_io_avail = 1;
			break;
#endif
		}
	}
#ifdef notyet
	if (direct_io_avail) {
#else
	if (0) {
#endif
d283 1
a283 1
		bcopy(xaa->xaa_long_tag, sc->sc_io_bus_space,
d285 1
d290 3
a292 1
	} else {
d294 1
a294 1
		bcopy(xaa->xaa_short_tag, sc->sc_io_bus_space,
a306 8
	sc->sc_mem_bus_space->bus_private = sc;
	sc->sc_mem_bus_space->_space_read_1 = xbridge_read_1;
	sc->sc_mem_bus_space->_space_write_1 = xbridge_write_1;
	sc->sc_mem_bus_space->_space_read_2 = xbridge_read_2;
	sc->sc_mem_bus_space->_space_write_2 = xbridge_write_2;
	sc->sc_mem_bus_space->_space_read_raw_2 = xbridge_read_raw_2;
	sc->sc_mem_bus_space->_space_write_raw_2 = xbridge_write_raw_2;

d346 2
a347 2
	pba.pba_ioex = sc->sc_io_ex;
	pba.pba_memex = sc->sc_mem_ex;
d360 2
d877 1
a877 1
	if ((offs >> 24) != sc->sc_widget)
d907 1
d919 1
a919 1
	if ((offs >> 24) == sc->sc_widget)
d941 1
a941 1
	if ((offs >> 24) == sc->sc_widget)
d951 1
d1791 1
a1791 1
	int io, mem;
d1795 20
d1829 1
d1831 1
a1831 1
		    (24 - BRIDGE_DEVICE_BASE_SHIFT)) != sc->sc_widget;
a1842 3
			basewin =
			    (sc->sc_widget << 24) | BRIDGE_DEVIO_OFFS(dev);

d1846 3
a1848 5
			 * XXX This defaults to I/O resources only.
			 * XXX However some devices may carry only
			 * XXX memory mappings.
			 * XXX This code should assign devio in a more
			 * XXX flexible way...
d1868 1
a1868 7
		/*
		 * If we can manage I/O and memory resource allocation in
		 * the MI code, we do not need to do anything more at this
		 * stage...
		 */

		if (sc->sc_io_ex != NULL && sc->sc_mem_ex != NULL)
d1872 2
a1873 4
		 * ...otherwise, we need to perform the resource allocation
		 * ourselves, within the devio window we have configured
		 * above, for the devices which have not been setup by the
		 * firmware already.
a1875 3
		if (need_setup == 0)
			continue;

a1896 1

a1908 4
		 * As long as the memory area in the large window 
		 * isn't working as well as we'd like it to,
		 * we can only use devio mappings in the short window.
		 *
d1942 1
a1942 1
    int *nio, int *nmem)
d2023 7
d2033 1
a2033 1
			if (sc->sc_mem_ex == NULL && prefer_mem != 0) {
d2041 4
a2044 14
			if (sc->sc_io_ex == NULL && prefer_mem == 0) {
				if (base != 0 && base >= ex->ex_start &&
				    base + size - 1 <= ex->ex_end) {
					if (extent_alloc_region(ex, base, size,
					    EX_NOWAIT)) {
						printf("io address conflict"
						    " 0x%x/0x%x\n", base, size);
						base = 0;
					}
				} else {
					if (extent_alloc(ex, size, size, 0, 0,
					    0, &base) != 0)
						base = 0;
				}
@


1.29
log
@Preliminary cleanup work in order to help the PCI resource management code.

As long as I can't figure out what endianness knobs I need to frob to make
I/O and memory accesses through the large window work as intended, we are
stuck to devio I/O mappings only...
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.28 2009/06/27 16:34:50 miod Exp $	*/
d156 2
d159 1
a159 1
	    struct extent *);
d209 1
a259 1
#ifdef notyet
d262 22
d1797 1
d1799 1
a1799 1
	struct extent *ioex;
d1859 3
a1861 2
		 * If we can manage I/O resource allocation in the MI code,
		 * we do not need to do anything more at this stage...
d1864 1
a1864 1
		if (sc->sc_io_ex != NULL)
d1877 1
a1877 1
		ioex = extent_create("pciio",
d1880 1
a1880 1
		if (ioex == NULL)
d1893 6
d1907 1
a1907 1
			xbridge_resource_manage(sc, tag, ioex);
d1910 81
a1990 1
		extent_destroy(ioex);
d1996 1
a1996 1
    struct extent *ioex)
d2032 6
a2037 4
			/*
			 * XXX Eventually do something if sc->sc_mem_ex is
			 * XXX NULL...
			 */
d2040 16
a2055 12
			if (base != 0 && base >= ioex->ex_start &&
			    base + size - 1 <= ioex->ex_end) {
				if (extent_alloc_region(ioex, base, size,
				    EX_NOWAIT))
					printf("io address conflict"
					    " 0x%x/0x%x\n", base, size);
			} else {
				if (extent_alloc(ioex, size, size, 0, 0, 0,
				    &base) == 0)
					pci_conf_write(pc, tag, reg, base);
				/* otherwise the resource remains disabled */
			}
d2058 2
@


1.28
log
@If a device which has not been initialized by ARCS has a non-zero BAR, ignore
it if it does not fit in our extent, and force a suitable address. Prevents
extent sanity check panics with some cards.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.27 2009/06/21 18:03:16 miod Exp $	*/
a124 8
void	xbridge_read_raw_4(bus_space_tag_t, bus_space_handle_t, bus_addr_t,
	    uint8_t *, bus_size_t);
void	xbridge_write_raw_4(bus_space_tag_t, bus_space_handle_t, bus_addr_t,
	    const uint8_t *, bus_size_t);
void	xbridge_read_raw_8(bus_space_tag_t, bus_space_handle_t, bus_addr_t,
	    uint8_t *, bus_size_t);
void	xbridge_write_raw_8(bus_space_tag_t, bus_space_handle_t, bus_addr_t,
	    const uint8_t *, bus_size_t);
d126 5
a130 1
int	xbridge_space_map_short(bus_space_tag_t, bus_addr_t, bus_size_t, int,
d242 26
a267 7
	if (sys_config.system_type == SGI_OCTANE) {
		/* Unrestricted memory mappings in the large window */
		bcopy(xaa->xaa_long_tag, sc->sc_mem_bus_space,
		    sizeof(*sc->sc_mem_bus_space));
		sc->sc_mem_bus_space->bus_base += BRIDGE_PCI_MEM_SPACE_BASE;
		sc->sc_mem_ex = extent_create("pcimem",
		    0, BRIDGE_PCI_MEM_SPACE_LENGTH - 1,
d269 1
a269 17

		if (ISSET(sc->sc_flags, XBRIDGE_FLAGS_XBRIDGE) ||
		    xaa->xaa_revision >= 4) {
			/* Unrestricted I/O mappings in the large window */
			bcopy(xaa->xaa_long_tag, sc->sc_io_bus_space,
			    sizeof(*sc->sc_io_bus_space));
			sc->sc_io_bus_space->bus_base +=
			    BRIDGE_PCI_IO_SPACE_BASE;

			sc->sc_io_ex = extent_create("pciio",
			    0, BRIDGE_PCI_IO_SPACE_LENGTH - 1,
			    M_DEVBUF, NULL, 0, EX_NOWAIT);
		} else {
			/* Programmable I/O mappings in the small window */
			bcopy(xaa->xaa_short_tag, sc->sc_io_bus_space,
			    sizeof(*sc->sc_io_bus_space));
		}
d271 1
a271 7
		/* Limited memory mappings in the small window */
		bcopy(xaa->xaa_short_tag, sc->sc_mem_bus_space,
		    sizeof(*sc->sc_mem_bus_space));
		sc->sc_mem_bus_space->bus_private = sc;
		sc->sc_mem_bus_space->_space_map = xbridge_space_map_short;

		/* Limited I/O mappings in the small window */
d274 1
a274 2
		sc->sc_io_bus_space->bus_private = sc;
		sc->sc_io_bus_space->_space_map = xbridge_space_map_short;
d277 1
a283 4
	sc->sc_io_bus_space->_space_read_raw_4 = xbridge_read_raw_4;
	sc->sc_io_bus_space->_space_write_raw_4 = xbridge_write_raw_4;
	sc->sc_io_bus_space->_space_read_raw_8 = xbridge_read_raw_8;
	sc->sc_io_bus_space->_space_write_raw_8 = xbridge_write_raw_8;
d285 1
a291 4
	sc->sc_mem_bus_space->_space_read_raw_4 = xbridge_read_raw_4;
	sc->sc_mem_bus_space->_space_write_raw_4 = xbridge_write_raw_4;
	sc->sc_mem_bus_space->_space_read_raw_8 = xbridge_read_raw_8;
	sc->sc_mem_bus_space->_space_write_raw_8 = xbridge_write_raw_8;
d853 3
a855 3
void
xbridge_read_raw_4(bus_space_tag_t t, bus_space_handle_t h, bus_addr_t o,
    uint8_t *buf, bus_size_t len)
d857 21
a877 5
	volatile uint32_t *addr = (volatile uint32_t *)(h + o);
	len >>= 2;
	while (len-- != 0) {
		*(uint32_t *)buf = *addr;
		buf += 4;
d879 10
d891 3
a893 3
void
xbridge_write_raw_4(bus_space_tag_t t, bus_space_handle_t h, bus_addr_t o,
    const uint8_t *buf, bus_size_t len)
d895 9
a903 7
	volatile uint32_t *addr = (volatile uint32_t *)(h + o);
	len >>= 2;
	while (len-- != 0) {
		*addr = *(uint32_t *)buf;
		buf += 4;
	}
}
d905 3
a907 11
void
xbridge_read_raw_8(bus_space_tag_t t, bus_space_handle_t h, bus_addr_t o,
    uint8_t *buf, bus_size_t len)
{
	volatile uint64_t *addr = (volatile uint64_t *)(h + o);
	len >>= 3;
	while (len-- != 0) {
		*(uint64_t *)buf = *addr;
		buf += 8;
	}
}
d909 2
a910 10
void
xbridge_write_raw_8(bus_space_tag_t t, bus_space_handle_t h, bus_addr_t o,
    const uint8_t *buf, bus_size_t len)
{
	volatile uint64_t *addr = (volatile uint64_t *)(h + o);
	len >>= 3;
	while (len-- != 0) {
		*addr = *(uint64_t *)buf;
		buf += 8;
	}
a912 4
/*
 * On IP27 and IP35, we can not use the default xbow space_map_short
 * because of the games we play with bus addresses.
 */
d914 1
a914 1
xbridge_space_map_short(bus_space_tag_t t, bus_addr_t offs, bus_size_t size,
a917 1
	bus_addr_t bpa;
d919 4
a922 1
	bpa = t->bus_base - (sc->sc_widget << 24) + offs;
d924 6
a929 4
	/* check that this neither underflows nor overflows the window */
	if (((bpa + size - 1) >> 24) != (t->bus_base >> 24) ||
	    (bpa >> 24) != (t->bus_base >> 24))
		return (EINVAL);
d931 1
a931 1
	*bshp = bpa;
d1625 20
@


1.27
log
@Remove the ioc interrupt probe code, the heuristic is correct; origin 300
is still unhappy due to ``interferences'' between the L1 console and the
brick's serial ports, unfortunately.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.26 2009/06/13 21:48:03 miod Exp $	*/
d1908 2
a1909 1
			if (base != 0) {
@


1.26
log
@Enumerate all available nodes for hardware on IP27/IP35 systems; works to some
extent, but isp(4) on other nodes do not work correctly yet.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.25 2009/06/13 16:28:11 miod Exp $	*/
a83 1
	pcireg_t	sc_ier_ignore;
a415 1
	uint32_t ier;
a462 35
		case PCI_INTERRUPT_REG + 4:
			/*
			 * This is a kluge to help the IOC driver figure
			 * out which second interrupt line it uses.
			 *
			 * The ioc driver will attempt to trigger that
			 * interrupt, and then read that sort-of second
			 * interrupt register.  Here we check the pending
			 * interrupts, and see if a bit has changed.
			 *
			 * Unfortunately, this does not work on all
			 * platforms (e.g. IP30).  The ioc driver falls
			 * back to heuristics in that case.
			 */

			ier = bus_space_read_4(sc->sc_iot, sc->sc_regh,
			    BRIDGE_IER) & 0xff;
			ier &= ~sc->sc_ier_ignore;
			sc->sc_ier_ignore |= ier;

			/* we expect only one bit to trigger */
			if (ier != 0 && (ier & (ier - 1)) != 0)
				ier = 0;

			if (ier != 0) {
				/* compute interrupt line */
				for (data = 0; ier != 1; ier >>= 1, data++) ;

				data = (PCI_INTERRUPT_PIN_A <<
				    PCI_INTERRUPT_PIN_SHIFT) |
				    (data << PCI_INTERRUPT_LINE_SHIFT);
			} else
				data = 0;
			skip = 1;
			break;
a666 1
		sc->sc_ier_ignore |= 1 << intrbit;
d1517 1
a1517 1
	vaddr_t low, high;
a1651 3

	sc->sc_ier_ignore = bus_space_read_4(sc->sc_iot, sc->sc_regh,
	    BRIDGE_IER) & 0xff;
@


1.25
log
@Shuffle and rename HUB defines for consistency, no functional change yet.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.24 2009/05/28 19:20:06 miod Exp $	*/
d67 1
d213 1
a778 1
	uint16_t nasid = 0;	/* XXX */
d831 3
a833 1
			if (sys_config.system_type == SGI_OCTANE) {
d835 6
a840 2
			} else {
				IP27_RHUB_PI_S(nasid, 0, HUBPI_IR_CHANGE,
d842 2
d1641 1
@


1.24
log
@Be more paranoid in the IOC3 interrupt kluge
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.23 2009/05/27 19:04:47 miod Exp $	*/
d833 2
a834 2
				IP27_RHUB_PI_S(nasid, 0, HUB_IR_CHANGE,
				    HUB_IR_SET | xi->xi_intrsrc);
@


1.23
log
@Yet another attempt at a more reliable detection of the second interrupt
used by onboard IOC chips, by forcing the IOC to trigger this interrupt,
and some help from the PCI bridge driver to report which interrupt has
fired through a fake PCI configuration register.

This works nicely on IP27 and IP35, but on IP30 the interrupt doesn't
happen, for some reason; so keep the existing heuristic in case the above
trick did not give us a valid interrupt number.

In case we got an interrupt, this will also detect IOC configurations where
there is actually one interrupt, should such configurations exist.

<rant style="beck">
I probably deserve to rot in hell for this abomination, but I won't mind
as long as the IOC designers who came with the bright ``let's use more than
one interrupt and defecate on the pci spec'' ideas are there, too.
</rant>
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.22 2009/05/27 18:58:52 miod Exp $	*/
d702 1
@


1.22
log
@Make sure onboard devices on Octane get their DMA byteswap settings correct.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.21 2009/05/24 17:33:12 miod Exp $	*/
d83 1
d415 1
d458 38
a495 1
			data = PCI_INTERRUPT_PIN_A << PCI_INTERRUPT_PIN_SHIFT;
d610 1
d628 13
a640 4
	if (pa->pa_intrpin & 1)
		intr = device;
	else
		intr = device ^ 4;
d1679 3
@


1.21
log
@Provide more xbridge-specific functions in the bus_dma_tag_t we use for
PCI buses on xbridge.

In addition to this, we now support the limited IOMMU, allowing memory
outside of the 2GB direct window to be used for DMA.

Only tested on XBridge chip so far; this lets an IP35 machine with
physical memory after the 2GB boundary run stable again.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.20 2009/05/21 16:26:15 miod Exp $	*/
a1735 8
	/*
	 * On Octane, the firmware will setup the I/O registers
	 * correctly for the on-board devices. Other PCI buses,
	 * and other systems, need more attention.
	 */
	if (sys_config.system_type == SGI_OCTANE && sc->sc_widget == WIDGET_MAX)
		return;

d1752 9
@


1.20
log
@Do not attempt the interrupt deadlock workaround on IP30 yet, since the
IP27 logic will obviously not work there.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.19 2009/05/15 17:18:16 miod Exp $	*/
d30 3
d41 2
d61 1
d72 1
d83 6
d136 8
d147 9
d157 2
d164 1
a164 1
struct machine_bus_dma_tag xbridge_dma_tag = {
d168 3
a170 3
	_dmamap_load,
	_dmamap_load_mbuf,
	_dmamap_load_uio,
d172 1
a172 1
	_dmamap_unload,
d174 1
a174 1
	_dmamem_alloc,
d184 4
d305 6
d343 1
a343 1
	pba.pba_dmat = &xbridge_dma_tag;
d353 2
d375 4
d542 4
a545 1
 * Interrupt handling.
d618 4
d793 1
a793 1
 * bus_space helpers
d917 1
a917 1
 * bus_dma helpers
d920 213
a1132 2
bus_addr_t
xbridge_pa_to_device(paddr_t pa)
d1134 4
d1139 1
a1139 6
	 * Try to use the direct DMA window whenever possible; this
	 * allows hardware limited to 32 bit DMA addresses to work.
	 *
	 * XXX There ought to be a specific bus_dma flag to let the
	 * XXX code know whether the given device can handle 64 bit
	 * XXX dma addresses or not.
d1142 1
d1144 379
a1522 1
		pa -= IP30_MEMORY_BASE;
d1524 7
a1530 2
	if (pa < BRIDGE_DMA_DIRECT_LENGTH)
		return pa + BRIDGE_DMA_DIRECT_BASE;
d1532 7
a1538 1
	pa += ((uint64_t)xbow_intr_widget << 60) | (1UL << 56);
d1540 1
a1540 1
	return pa;
d1546 1
a1546 5
	paddr_t pa;

	pa = addr & ((1UL << 56) - 1);
	if (pa == (paddr_t)addr)	/* was in direct DMA window */
		pa = addr - BRIDGE_DMA_DIRECT_BASE;
d1548 1
d1551 1
d1557 1
a1557 1
 * Bridge configuration code.
d1591 7
@


1.19
log
@Forgot to remove that now unused function in previous commit.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.18 2009/05/15 06:29:39 miod Exp $	*/
d217 1
a217 1
		if (!ISSET(sc->sc_flags, XBRIDGE_FLAGS_XBRIDGE) &&
d724 8
a731 3
		    BRIDGE_ISR) & (1 << xi->xi_intrbit))
			IP27_RHUB_PI_S(nasid, 0, HUB_IR_CHANGE,
			    HUB_IR_SET | xi->xi_intrsrc);
@


1.18
log
@Do not explicitely clear interrupt sources in the interrupt handler, but
ask the Bridge to do this for us; this makes the initial interrupt deadlock
workaround functional again.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.17 2009/05/14 21:10:33 miod Exp $	*/
a729 15
}

/*
 * Bridge (not XBridge) ugly workaround for the interrupt deadlock
 * problem mentioned above.
 */
void
xbridge_timeout(void *v)
{
	struct xbridge_intr *xi = v;
	struct xbridge_softc *sc = xi->xi_bridge;

	if ((bus_space_read_4(sc->sc_iot, sc->sc_regh, BRIDGE_ISR) &
	    (1 << xi->xi_intrbit)) != 0)
		xbridge_intr_handler(v);
@


1.17
log
@More interrupt deadlock tomfoolery; turns out the non-XBridge workaround
doesn't appear to trigger the expected interrupt, so use a fugly nanotimeout
instead.

This makes Origin 200 disks not stall as soon as some serious I/O is intended.
They now run multiuser.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.16 2009/05/08 18:37:28 miod Exp $	*/
a29 1
#include <sys/timeout.h>
d209 1
a509 2

	struct timeout xi_tmo;	/* XXX deadlock bad workaround */
a511 2
void	xbridge_timeout(void *);	/* XXX */

a607 1
	timeout_set(&xi->xi_tmo, xbridge_timeout, xi);
d621 2
a622 3
	 * We do not want such packets to be sent because we clear
	 * interrupts ourselves and this would cause interrupts to
	 * be missed.
a623 1
#if 0
a626 1
#endif
a671 1
#if 0
a672 1
#endif
a681 3
	if (!ISSET(sc->sc_flags, XBRIDGE_FLAGS_XBRIDGE))
		timeout_del(&xi->xi_tmo);

d724 1
a724 3
		    BRIDGE_ISR) & (1 << xi->xi_intrbit)) {
#if 0
			/* XXX This doesn't appear to work */
a726 4
#else
			timeout_add(&xi->xi_tmo, 1);
#endif
		}
@


1.16
log
@Fix devio byteswap, this makes isp(4) happy on IP27 and IP35.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.15 2009/05/06 20:08:47 miod Exp $	*/
d30 1
d503 1
d510 2
d514 7
d546 1
a546 1
	*ihp = intr;
d556 1
a556 1
	snprintf(str, sizeof(str), "irq %d", ih);
d567 2
a568 1
	int intrbit = ih & 0x07;
d607 1
d612 1
d622 9
d634 1
d637 1
a637 1
	    (intrbit << (intrbit * 3)));
d640 1
a640 1
	return (void *)((uint64_t)ih | 8);	/* XXX don't return zero */
d644 1
a644 1
xbridge_intr_disestablish(void *cookie, void *ih)
d648 2
a649 1
	int intrbit = (uint64_t)ih & 0x07;
d680 1
d682 1
d684 1
d687 2
a688 2
		printf("%s: spurious interrupt on source %d\n",
		    sc->sc_dev.dv_xname, xi->xi_intrsrc);
d692 20
d714 3
d721 2
a722 2
	 * further interrupts on the first pin do not cause an interrupt
	 * to be sent.
d724 3
a726 3
	 * The workaround against this is to check if our interrupt source
	 * is still active (i.e. another interrupt is pending), in which
	 * case we force an interrupt anyway.
d728 2
a729 2
	 * The XBridge even has a nice facility to do this, where we do not
	 * even have to check if our interrupt is pending.
d736 4
a739 2
		if (bus_space_read_4(sc->sc_iot, sc->sc_regh, BRIDGE_ISR) &
		    (1 << xi->xi_intrbit))
d742 4
d748 16
a763 1
	return rc;
@


1.15
log
@Workaround a bridge deadlock, as advised by comments found in the linux sn1
code.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.14 2009/05/03 19:44:28 miod Exp $	*/
d582 1
a582 1
		    level, sc->sc_dev.dv_xname)) {
d685 4
a688 1
		IP27_RHUB_PI_S(nasid, 0, HUB_IR_CHANGE, xi->xi_intrsrc);
a1036 5
	 *
	 * XXX Another reason not to enter the loop below on the Octane
	 * XXX main Bridge widget is that it uses a sligthly different
	 * XXX devio window allocation scheme, with only one large devio
	 * XXX (used by the first isp controller).
d1050 2
d1077 1
a1077 1
		 * Enable byte swapping for PIO and DMA, except on IOC3 and
d1080 4
a1083 7
		if (id == PCI_ID_CODE(PCI_VENDOR_SGI, PCI_PRODUCT_SGI_IOC3) ||
		    id == PCI_ID_CODE(PCI_VENDOR_SGI, PCI_PRODUCT_SGI_RAD1))
			devio &= ~(BRIDGE_DEVICE_SWAP_DIR |
			    BRIDGE_DEVICE_SWAP_PMU);
		else
			devio |= BRIDGE_DEVICE_SWAP_DIR |
			    BRIDGE_DEVICE_SWAP_PMU;
@


1.14
log
@Complete overhaul of the PCI bridge initialization. It will now allocate
resources to cards not configured by the PROM. There are still some
shortcomings, but this is a good start.

Tested on IP35 with an fxp(4).
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.13 2009/05/02 21:30:13 miod Exp $	*/
d36 1
d43 1
d500 2
a501 1
	int	xi_intrsrc;
d594 1
d655 1
d666 21
@


1.13
log
@More progress taming the xbow and the pci bridge; still needs code to write,
but (currently commented out) code makes isp happier on IP27 and IP35, to the
point of seeing disks (but considering them offline so far).
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.12 2009/04/19 18:37:31 miod Exp $	*/
d4 1
a4 1
 * Copyright (c) 2008 Miodrag Vallat.
d29 1
a29 1
#include <sys/proc.h>
d64 2
a65 1
	struct machine_bus_dma_tag sc_dmatag;
d117 1
d124 7
a130 1
const struct machine_bus_dma_tag xbridge_dma_tag = {
d147 1
a147 1
	0ULL	/* no mask */
a171 1
	int i;
d210 3
d221 4
d284 2
a285 61
	 * Configure the direct DMA window to access the low 2GB of memory.
	 */

	if (sys_config.system_type == SGI_OCTANE)
		bus_space_write_4(sc->sc_iot, sc->sc_regh, BRIDGE_DIR_MAP,
		    (xbow_intr_widget << BRIDGE_DIRMAP_WIDGET_SHIFT) |
		    BRIDGE_DIRMAP_ADD_512MB);
	else
		bus_space_write_4(sc->sc_iot, sc->sc_regh, BRIDGE_DIR_MAP,
		    xbow_intr_widget << BRIDGE_DIRMAP_WIDGET_SHIFT);

	/*
	 * Gather device identification for all slots.
	 * We need this to be able to allocate RRBs correctly, and also
	 * to be able to check quickly whether a given device is an IOC3.
	 */

	for (i = 0; i < BRIDGE_NSLOTS; i++) {
		paddr_t pa;

		pa = sc->sc_regh + BRIDGE_PCI_CFG_SPACE +
		    (i << 12) + PCI_ID_REG;
		if (guarded_read_4(pa, &sc->sc_devices[i]) != 0)
			sc->sc_devices[i] = 0xffffffff;
	}

#if 0	/* XXX write proper RRB allocation code */
	if (sys_config.system_type == SGI_OCTANE) {
		bus_space_write_4(sc->sc_iot, sc->sc_regh, BRIDGE_RRB_EVEN,
		    0x99889988 | 0x44440000);
		bus_space_write_4(sc->sc_iot, sc->sc_regh, BRIDGE_RRB_ODD,
		    0x99889988 | 0x44440000);
	} else {
		bus_space_write_4(sc->sc_iot, sc->sc_regh, BRIDGE_RRB_EVEN,
		    0xba98ba98 | 0x44440000);
		bus_space_write_4(sc->sc_iot, sc->sc_regh, BRIDGE_RRB_ODD,
		    0xba98ba98 | 0x44440000);
	}
#endif

#if 0	/* XXX write proper I/O mapping allocation code */
	for (i = 0; i < BRIDGE_NSLOTS; i++) {
		uint32_t dio;

		if (sc->sc_devices[i] ==
		    PCI_ID_CODE(PCI_VENDOR_SGI, PCI_PRODUCT_SGI_IOC3))
			continue;

		dio = bus_space_read_4(sc->sc_iot, sc->sc_regh,
		    BRIDGE_DEVICE(i));
		dio |= BRIDGE_DEVICE_SWAP_PMU | BRIDGE_DEVICE_SWAP_DIR |
		    BRIDGE_DEVICE_COHERENT | BRIDGE_DEVICE_BARRIER;
		bus_space_write_4(sc->sc_iot, sc->sc_regh, BRIDGE_DEVICE(i),
		    dio);
	}
#endif

	(void)bus_space_read_4(sc->sc_iot, sc->sc_regh, WIDGET_TFLUSH);

	/*
	 * Setup interrupt handling.
d288 1
a288 13
	bus_space_write_4(sc->sc_iot, sc->sc_regh, BRIDGE_IER, 0);
	bus_space_write_4(sc->sc_iot, sc->sc_regh, BRIDGE_INT_MODE, 0);
	bus_space_write_4(sc->sc_iot, sc->sc_regh, BRIDGE_INT_DEV, 0);

	bus_space_write_4(sc->sc_iot, sc->sc_regh, WIDGET_INTDEST_ADDR_UPPER,
	    (xbow_intr_widget_register >> 32) | (xbow_intr_widget << 16));
	bus_space_write_4(sc->sc_iot, sc->sc_regh, WIDGET_INTDEST_ADDR_LOWER,
	    (uint32_t)xbow_intr_widget_register);

	(void)bus_space_read_4(sc->sc_iot, sc->sc_regh, WIDGET_TFLUSH);

	for (i = 0; i < BRIDGE_NINTRS; i++)
		sc->sc_intrbit[i] = -1;
a293 9
	bcopy(&xbridge_dma_tag, &sc->sc_dmatag, sizeof(xbridge_dma_tag));
	if (sys_config.system_type == SGI_OCTANE) {
		/*
		 * Make sure we do not risk crossing the direct mapping
		 * window.
		 */
		sc->sc_dmatag._dma_mask = BRIDGE_DMA_DIRECT_LENGTH - 1;
	}

d298 3
a300 1
	pba.pba_dmat = &sc->sc_dmatag;
d768 2
a769 2
 * On IP27, we can not use the default xbow space_map_short because
 * of the games we play with bus addresses.
d829 347
@


1.12
log
@On Octane, force a nonzero _dma_mask value so that we do not risk trying to
handle a mapping partly in, and partly out the direct DMA window, on
systems with > 2GB physical memory.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.11 2009/04/19 12:52:33 miod Exp $	*/
d57 2
a58 1
	int		sc_rev;
d71 2
a165 1
	sc->sc_rev = xaa->xaa_revision;
d168 4
a171 1
	printf(" revision %d\n", sc->sc_rev);
d204 2
a205 1
		if (sc->sc_rev >= 4) {
d270 15
a284 2
	 * XXX The following magic sequence is supposedly needed for DMA
	 * XXX to work correctly.  I have no idea what it really does.
d286 11
d298 1
a298 4
		bus_space_write_4(sc->sc_iot, sc->sc_regh, BRIDGE_DIR_MAP,
		    (xbow_intr_widget << 20) | (1 << 17));
#if 0
		bus_space_write_4(sc->sc_iot, sc->sc_regh, 0x284,
d300 1
a300 1
		bus_space_write_4(sc->sc_iot, sc->sc_regh, 0x28c,
a301 1
#endif
d303 1
a303 4
		bus_space_write_4(sc->sc_iot, sc->sc_regh, BRIDGE_DIR_MAP,
		    xbow_intr_widget << 20);
#if 0
		bus_space_write_4(sc->sc_iot, sc->sc_regh, 0x284,
d305 1
a305 1
		bus_space_write_4(sc->sc_iot, sc->sc_regh, 0x28c,
d307 1
d309 15
d325 1
d336 1
d338 1
a338 1
	    (xbow_intr_widget_register  >> 32) | (xbow_intr_widget << 16));
d426 1
a426 1
	pcireg_t id, data;
d429 1
d445 3
a447 1
	 * registers.
d456 3
a458 6
	if (guarded_read_4(pa + PCI_ID_REG, &id) != 0) {
		splx(s);
		return 0xffffffff;
	}

	if (id == PCI_ID_CODE(PCI_VENDOR_SGI, PCI_PRODUCT_SGI_IOC3)) {
a465 1
			id = 0;
d470 1
d475 1
d478 1
a478 2
	} else
		id = 0;
d480 1
a480 1
	if (id == 0) {
a493 1
	pcireg_t id;
d496 1
d521 3
a523 6
	if (guarded_read_4(pa + PCI_ID_REG, &id) != 0) {
		splx(s);
		return;
	}

	if (id == PCI_ID_CODE(PCI_VENDOR_SGI, PCI_PRODUCT_SGI_IOC3)) {
a537 1
			id = 0;
d541 1
d544 1
a544 2
	} else
		id = 0;
d546 1
a546 1
	if (id == 0) {
a618 1
	int16_t nasid = 0;	/* XXX */
d661 1
a661 10
	switch (sys_config.system_type) {
	case SGI_OCTANE:
		int_addr = intrsrc;
		break;
	default:
	case SGI_O200:
	case SGI_O300:
		int_addr = 0x20000 | intrsrc | (nasid << 8);
		break;
	}
d861 6
a866 3
	 * On the Octane, we try to use the direct DMA window whenever
	 * possible; this allows hardware limited to 32 bit DMA addresses
	 * to work.
d869 1
a869 1
	if (sys_config.system_type == SGI_OCTANE) {
d871 3
a873 3
		if (pa < BRIDGE_DMA_DIRECT_LENGTH)
			return pa + BRIDGE_DMA_DIRECT_BASE;
	}
d886 1
a886 1
	if (sys_config.system_type == SGI_OCTANE && pa == (paddr_t)addr)
@


1.11
log
@Add heuristics to tell IP27 and IP35 apart, as they will need to be handled
differently at times.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.10 2009/04/18 19:26:33 miod Exp $	*/
d63 1
d119 1
a119 1
struct machine_bus_dma_tag xbridge_dma_tag = {
d310 9
d323 1
a323 1
	pba.pba_dmat = &xbridge_dma_tag;
d646 1
a646 1
	    (7 << (intrbit * 3)));
@


1.10
log
@Attach to IP35 Xbridge too.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.9 2009/04/18 19:26:18 miod Exp $	*/
d621 1
@


1.9
log
@Attach pci busses with pba_bus being zero, and not our bridge unit number,
these are completely unrelated as long as there is only one pci bus per
bridge.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.8 2009/04/15 18:45:41 miod Exp $	*/
d145 4
@


1.8
log
@Change the way the widget interrupt register is computed and have it become
a complete physical address. Also add proper cpu pa<->device pa for dma
on Origin 200.

This lets xbridge work and route interrupts correctly on Origin 200.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.7 2009/04/13 21:17:54 miod Exp $	*/
d312 1
a312 1
	pba.pba_bus = sc->sc_dev.dv_unit;
@


1.7
log
@The start of Origin 200 support. Based on some code contributed by pefo@@
some years ago for KL enumeration, building on the existing XBow support
to limit ourselves to a single node for now.

This is a work-in-progress; it currently lacks complete interrupt code,
as well as PCI resource management. And there are likely bugs creeping
inside.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.6 2009/04/12 17:55:20 miod Exp $	*/
a216 1
		sc->sc_io_bus_space->bus_base += 0xa00000;
d220 1
a221 1
	sc->sc_io_bus_space->_space_write_1 = xbridge_write_1;
d231 1
a232 1
	sc->sc_mem_bus_space->_space_write_1 = xbridge_write_1;
d267 1
a267 1
		    0xddcc9988);
d269 1
a269 1
		    0xddcc9988);
d274 6
d292 1
a292 1
	    xbow_intr_widget << 16);
d294 2
a295 1
	    xbow_intr_widget_register);
d297 1
a683 5
#if 0
	/* Clear PCI interrupts. */
	bus_space_write_4(sc->sc_iot, sc->sc_regh, BRIDGE_ICR, 1 << 0);
#endif

d818 5
a822 11
	switch (sys_config.system_type) {
	case SGI_OCTANE:
		/*
		 * On Octane, direct DMA is not possible on memory
		 * above 2GB.  Until _dmamem_alloc() is modified to
		 * make sure it doesn't use memory above this limit,
		 * add a check there.  Otherwise I'll never come back
		 * and fix _dmamem_alloc().
		 */
		if (pa > IP30_MEMORY_BASE + BRIDGE_DMA_DIRECT_LENGTH)
			panic("dma above 2GB");
d824 5
a828 1
		return (pa - IP30_MEMORY_BASE) + BRIDGE_DMA_DIRECT_BASE;
d830 1
a830 3
	case SGI_O200:
		break;	/* XXX likely wrong */
	}
d838 5
a842 3
	switch (sys_config.system_type) {
	case SGI_OCTANE:
		return (addr - BRIDGE_DMA_DIRECT_BASE) + IP30_MEMORY_BASE;
d844 2
a845 3
	case SGI_O200:
		break;
	}
d847 1
a847 1
	return addr;
@


1.6
log
@Add code to prevent the MI pci code to cause IOC3 devices to freeze and
hog the bus, and also to fake a valid interrupt register. The IOC3 device
is not a PCI device at all, but pretends to be one. Except its own
registers overlap the PCI configuration space, and some flavours do not
support disabling memory space in the control register, violating the PCI
specs. Fun.
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.5 2009/03/30 09:41:00 kettenis Exp $	*/
d112 2
d189 16
a204 11
	bcopy(xaa->xaa_long_tag, sc->sc_mem_bus_space,
	    sizeof(*sc->sc_mem_bus_space));
	sc->sc_mem_bus_space->bus_base = xaa->xaa_long_tag->bus_base +
	    BRIDGE_PCI_MEM_SPACE_BASE;

	if (sc->sc_rev >= 4) {
		/* Unrestricted I/O mappings in the large window */
		bcopy(xaa->xaa_long_tag, sc->sc_io_bus_space,
		    sizeof(*sc->sc_io_bus_space));
		sc->sc_io_bus_space->bus_base +=
		    BRIDGE_PCI_IO_SPACE_BASE;
d206 7
a212 1
		/* Programmable I/O mappings in the small window */
d215 3
d785 22
@


1.5
log
@bzero pci attach args
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.4 2008/08/25 13:35:34 jsing Exp $	*/
d39 1
d348 1
a348 1
	pcireg_t data;
d364 43
a406 3
	pa += (fn << 8) + offset;
	if (guarded_read_4(pa, &data) != 0)
		data = 0xffffffff;
d416 1
d432 44
a475 2
	pa += (fn << 8) + offset;
	guarded_write_4(pa, data);
@


1.4
log
@Unbreak.

ok miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.2 2008/07/28 18:50:59 miod Exp $	*/
d281 1
a288 1
	pba.pba_bridgetag = NULL;
@


1.3
log
@Implement bus_space_{read,write}_raw_mult_[248] correctly, it needs
endianness conversion on pci bridges.
ok deraadt@@ jsing@@
@
text
@d99 1
a99 1
void	xbow_read_raw_2(bus_space_tag_t, bus_space_handle_t, bus_addr_t,
d101 1
a101 1
void	xbow_write_raw_2(bus_space_tag_t, bus_space_handle_t, bus_addr_t,
d103 1
a103 1
void	xbow_read_raw_4(bus_space_tag_t, bus_space_handle_t, bus_addr_t,
d105 1
a105 1
void	xbow_write_raw_4(bus_space_tag_t, bus_space_handle_t, bus_addr_t,
d107 1
a107 1
void	xbow_read_raw_8(bus_space_tag_t, bus_space_handle_t, bus_addr_t,
d109 1
a109 1
void	xbow_write_raw_8(bus_space_tag_t, bus_space_handle_t, bus_addr_t,
@


1.2
log
@Put XBOW in the generated constants, not PCI...
@
text
@d1 1
a1 1
/*	$OpenBSD: xbridge.c,v 1.1 2008/04/07 22:47:40 miod Exp $	*/
d99 12
d207 6
d218 6
d613 72
@


1.1
log
@A first cut at XBow bus support, very minimal, limited to a local bus only;
HUB driver (for IP27) is a stub, and interrupt support is a shoot in the dark
and will need some serious debugging until it is sane, but I want to reduce
the weight of these diffs first.

Based on a lot of tinkering and experiments, as well as knowledge extracted
from the Linux source code.
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d128 2
a129 2
	if (xaa->xaa_vendor == PCI_VENDOR_SGI4 &&
	    xaa->xaa_product == PCI_PRODUCT_SGI4_BRIDGE)
@

