head	1.54;
access;
symbols
	OPENBSD_6_1:1.53.0.4
	OPENBSD_6_1_BASE:1.53
	OPENBSD_6_0:1.52.0.4
	OPENBSD_6_0_BASE:1.52
	OPENBSD_5_9:1.52.0.2
	OPENBSD_5_9_BASE:1.52
	OPENBSD_5_8:1.51.0.4
	OPENBSD_5_8_BASE:1.51
	OPENBSD_5_7:1.50.0.2
	OPENBSD_5_7_BASE:1.50
	OPENBSD_5_6:1.48.0.4
	OPENBSD_5_6_BASE:1.48
	OPENBSD_5_5:1.44.0.4
	OPENBSD_5_5_BASE:1.44
	OPENBSD_5_4:1.43.0.2
	OPENBSD_5_4_BASE:1.43
	OPENBSD_5_3:1.40.0.8
	OPENBSD_5_3_BASE:1.40
	OPENBSD_5_2:1.40.0.6
	OPENBSD_5_2_BASE:1.40
	OPENBSD_5_1_BASE:1.40
	OPENBSD_5_1:1.40.0.4
	OPENBSD_5_0:1.40.0.2
	OPENBSD_5_0_BASE:1.40
	OPENBSD_4_9:1.39.0.2
	OPENBSD_4_9_BASE:1.39
	OPENBSD_4_8:1.38.0.2
	OPENBSD_4_8_BASE:1.38
	OPENBSD_4_7:1.37.0.2
	OPENBSD_4_7_BASE:1.37
	OPENBSD_4_6:1.35.0.4
	OPENBSD_4_6_BASE:1.35
	OPENBSD_4_5:1.28.0.6
	OPENBSD_4_5_BASE:1.28
	OPENBSD_4_4:1.28.0.4
	OPENBSD_4_4_BASE:1.28
	OPENBSD_4_3:1.28.0.2
	OPENBSD_4_3_BASE:1.28
	OPENBSD_4_2:1.27.0.6
	OPENBSD_4_2_BASE:1.27
	OPENBSD_4_1:1.27.0.4
	OPENBSD_4_1_BASE:1.27
	OPENBSD_4_0:1.27.0.2
	OPENBSD_4_0_BASE:1.27
	OPENBSD_3_9:1.25.0.2
	OPENBSD_3_9_BASE:1.25
	OPENBSD_3_8:1.24.0.8
	OPENBSD_3_8_BASE:1.24
	OPENBSD_3_7:1.24.0.6
	OPENBSD_3_7_BASE:1.24
	OPENBSD_3_6:1.24.0.4
	OPENBSD_3_6_BASE:1.24
	SMP_SYNC_A:1.24
	SMP_SYNC_B:1.24
	OPENBSD_3_5:1.24.0.2
	OPENBSD_3_5_BASE:1.24
	OPENBSD_3_4:1.23.0.4
	OPENBSD_3_4_BASE:1.23
	UBC_SYNC_A:1.23
	OPENBSD_3_3:1.23.0.2
	OPENBSD_3_3_BASE:1.23
	OPENBSD_3_2:1.22.0.4
	OPENBSD_3_2_BASE:1.22
	OPENBSD_3_1:1.22.0.2
	OPENBSD_3_1_BASE:1.22
	UBC_SYNC_B:1.22
	UBC:1.20.0.2
	UBC_BASE:1.20
	OPENBSD_3_0:1.12.0.2
	OPENBSD_3_0_BASE:1.12
	OPENBSD_2_9_BASE:1.7
	OPENBSD_2_9:1.7.0.2
	OPENBSD_2_8:1.5.0.4
	OPENBSD_2_8_BASE:1.5
	OPENBSD_2_7:1.5.0.2
	OPENBSD_2_7_BASE:1.5
	SMP:1.4.0.4
	SMP_BASE:1.4
	kame_19991208:1.4
	OPENBSD_2_6:1.4.0.2
	OPENBSD_2_6_BASE:1.4
	OPENBSD_2_5:1.2.0.2
	OPENBSD_2_5_BASE:1.2;
locks; strict;
comment	@ * @;


1.54
date	2017.05.21.13.00.53;	author visa;	state Exp;
branches;
next	1.53;
commitid	CQbxXzxDtYW7UvJn;

1.53
date	2016.09.16.02.35.42;	author dlg;	state Exp;
branches;
next	1.52;
commitid	Fei4687v68qad1tP;

1.52
date	2015.08.28.00.03.54;	author deraadt;	state Exp;
branches;
next	1.51;
commitid	NdgfPIGUgJxQPnT7;

1.51
date	2015.03.14.03.38.53;	author jsg;	state Exp;
branches;
next	1.50;
commitid	p4LJxGKbi0BU2cG6;

1.50
date	2014.11.16.12.31.00;	author deraadt;	state Exp;
branches;
next	1.49;
commitid	yv0ECmCdICvq576h;

1.49
date	2014.09.14.14.17.27;	author jsg;	state Exp;
branches;
next	1.48;
commitid	uzzBR7hz9ncd4O6G;

1.48
date	2014.07.12.18.44.01;	author tedu;	state Exp;
branches;
next	1.47;
commitid	bDGgAR6yEQVcVl5u;

1.47
date	2014.07.11.16.35.40;	author jsg;	state Exp;
branches;
next	1.46;
commitid	7NtJNW9udCOFtDNM;

1.46
date	2014.07.02.06.09.49;	author matthew;	state Exp;
branches;
next	1.45;
commitid	mswsoyQHeu5M87iU;

1.45
date	2014.04.13.23.14.15;	author tedu;	state Exp;
branches;
next	1.44;

1.44
date	2013.08.13.06.56.41;	author kettenis;	state Exp;
branches;
next	1.43;

1.43
date	2013.06.07.20.46.14;	author kettenis;	state Exp;
branches;
next	1.42;

1.42
date	2013.05.30.16.29.46;	author tedu;	state Exp;
branches;
next	1.41;

1.41
date	2013.05.30.15.17.59;	author tedu;	state Exp;
branches;
next	1.40;

1.40
date	2011.07.03.18.34.14;	author oga;	state Exp;
branches;
next	1.39;

1.39
date	2010.12.26.15.41.00;	author miod;	state Exp;
branches;
next	1.38;

1.38
date	2010.04.30.21.56.39;	author oga;	state Exp;
branches;
next	1.37;

1.37
date	2009.08.14.16.27.34;	author oga;	state Exp;
branches;
next	1.36;

1.36
date	2009.08.06.15.28.14;	author oga;	state Exp;
branches;
next	1.35;

1.35
date	2009.06.16.23.54.57;	author oga;	state Exp;
branches;
next	1.34;

1.34
date	2009.06.16.00.11.29;	author oga;	state Exp;
branches;
next	1.33;

1.33
date	2009.06.02.23.00.19;	author oga;	state Exp;
branches;
next	1.32;

1.32
date	2009.05.12.20.49.56;	author oga;	state Exp;
branches;
next	1.31;

1.31
date	2009.05.08.13.50.15;	author ariane;	state Exp;
branches;
next	1.30;

1.30
date	2009.03.23.19.23.43;	author oga;	state Exp;
branches;
next	1.29;

1.29
date	2009.03.20.15.19.04;	author oga;	state Exp;
branches;
next	1.28;

1.28
date	2007.10.29.17.08.08;	author chl;	state Exp;
branches;
next	1.27;

1.27
date	2006.07.31.11.51.29;	author mickey;	state Exp;
branches;
next	1.26;

1.26
date	2006.07.26.23.15.55;	author mickey;	state Exp;
branches;
next	1.25;

1.25
date	2006.01.16.13.11.05;	author mickey;	state Exp;
branches;
next	1.24;

1.24
date	2004.02.23.06.19.32;	author drahn;	state Exp;
branches;
next	1.23;

1.23
date	2002.11.06.00.17.28;	author art;	state Exp;
branches;
next	1.22;

1.22
date	2002.03.14.01.27.18;	author millert;	state Exp;
branches;
next	1.21;

1.21
date	2001.12.19.08.58.07;	author art;	state Exp;
branches;
next	1.20;

1.20
date	2001.12.04.23.22.42;	author art;	state Exp;
branches
	1.20.2.1;
next	1.19;

1.19
date	2001.11.28.19.28.14;	author art;	state Exp;
branches;
next	1.18;

1.18
date	2001.11.28.13.47.39;	author art;	state Exp;
branches;
next	1.17;

1.17
date	2001.11.07.02.55.50;	author art;	state Exp;
branches;
next	1.16;

1.16
date	2001.11.06.01.35.04;	author art;	state Exp;
branches;
next	1.15;

1.15
date	2001.11.05.22.14.54;	author art;	state Exp;
branches;
next	1.14;

1.14
date	2001.11.01.14.31.25;	author art;	state Exp;
branches;
next	1.13;

1.13
date	2001.11.01.12.13.47;	author art;	state Exp;
branches;
next	1.12;

1.12
date	2001.09.11.20.05.26;	author miod;	state Exp;
branches;
next	1.11;

1.11
date	2001.08.11.10.57.22;	author art;	state Exp;
branches;
next	1.10;

1.10
date	2001.08.06.14.03.04;	author art;	state Exp;
branches;
next	1.9;

1.9
date	2001.07.25.13.25.33;	author art;	state Exp;
branches;
next	1.8;

1.8
date	2001.07.18.14.31.27;	author art;	state Exp;
branches;
next	1.7;

1.7
date	2001.03.22.03.05.54;	author smart;	state Exp;
branches;
next	1.6;

1.6
date	2001.01.29.02.07.43;	author niklas;	state Exp;
branches;
next	1.5;

1.5
date	2000.03.15.15.50.19;	author art;	state Exp;
branches;
next	1.4;

1.4
date	99.09.03.18.02.20;	author art;	state Exp;
branches
	1.4.4.1;
next	1.3;

1.3
date	99.08.23.08.13.23;	author art;	state Exp;
branches;
next	1.2;

1.2
date	99.02.26.05.32.06;	author art;	state Exp;
branches;
next	1.1;

1.1
date	99.02.26.01.30.11;	author art;	state Exp;
branches;
next	;

1.4.4.1
date	2000.03.24.09.09.48;	author niklas;	state Exp;
branches;
next	1.4.4.2;

1.4.4.2
date	2001.05.14.22.47.45;	author niklas;	state Exp;
branches;
next	1.4.4.3;

1.4.4.3
date	2001.10.31.03.32.14;	author nate;	state Exp;
branches;
next	1.4.4.4;

1.4.4.4
date	2001.11.13.23.02.31;	author niklas;	state Exp;
branches;
next	1.4.4.5;

1.4.4.5
date	2001.12.05.01.23.58;	author niklas;	state Exp;
branches;
next	1.4.4.6;

1.4.4.6
date	2002.03.06.02.17.14;	author niklas;	state Exp;
branches;
next	1.4.4.7;

1.4.4.7
date	2002.03.28.14.54.26;	author niklas;	state Exp;
branches;
next	1.4.4.8;

1.4.4.8
date	2003.03.28.00.08.48;	author niklas;	state Exp;
branches;
next	1.4.4.9;

1.4.4.9
date	2004.06.05.23.13.12;	author niklas;	state Exp;
branches;
next	;

1.20.2.1
date	2002.02.02.03.28.26;	author art;	state Exp;
branches;
next	1.20.2.2;

1.20.2.2
date	2002.06.11.03.33.03;	author art;	state Exp;
branches;
next	1.20.2.3;

1.20.2.3
date	2002.11.04.18.02.32;	author art;	state Exp;
branches;
next	;


desc
@@


1.54
log
@Enable radeondrm(4) on loongson to get accelerated graphics
with the RS780E chipset.

OK kettenis@@, jsg@@
@
text
@/*	$OpenBSD: uvm_device.c,v 1.53 2016/09/16 02:35:42 dlg Exp $	*/
/*	$NetBSD: uvm_device.c,v 1.30 2000/11/25 06:27:59 chs Exp $	*/

/*
 * Copyright (c) 1997 Charles D. Cranor and Washington University.
 * All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 *
 * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR
 * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
 * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
 * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,
 * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
 * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
 * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
 * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF
 * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 *
 * from: Id: uvm_device.c,v 1.1.2.9 1998/02/06 05:11:47 chs Exp
 */

/*
 * uvm_device.c: the device pager.
 */

#include <sys/param.h>
#include <sys/systm.h>
#include <sys/conf.h>
#include <sys/malloc.h>
#include <sys/mutex.h>

#include <uvm/uvm.h>
#include <uvm/uvm_device.h>

#if defined(__amd64__) || defined(__i386__) || \
    defined(__loongson__) || defined(__macppc__) || \
    defined(__sparc64__)
#include "drm.h"
#endif

/*
 * private global data structure
 *
 * we keep a list of active device objects in the system.
 */

LIST_HEAD(, uvm_device) udv_list = LIST_HEAD_INITIALIZER(udv_list);
struct mutex udv_lock = MUTEX_INITIALIZER(IPL_NONE);

/*
 * functions
 */
static void             udv_reference(struct uvm_object *);
static void             udv_detach(struct uvm_object *);
static int		udv_fault(struct uvm_faultinfo *, vaddr_t,
				       vm_page_t *, int, int, vm_fault_t,
				       vm_prot_t, int);
static boolean_t        udv_flush(struct uvm_object *, voff_t, voff_t,
				       int);

/*
 * master pager structure
 */
struct uvm_pagerops uvm_deviceops = {
	NULL,		/* inited statically */
	udv_reference,
	udv_detach,
	udv_fault,
	udv_flush,
};

/*
 * udv_attach
 *
 * get a VM object that is associated with a device.   allocate a new
 * one if needed.
 *
 * => nothing should be locked so that we can sleep here.
 *
 * The last two arguments (off and size) are only used for access checking.
 */
struct uvm_object *
udv_attach(dev_t device, vm_prot_t accessprot, voff_t off, vsize_t size)
{
	struct uvm_device *udv, *lcv;
	paddr_t (*mapfn)(dev_t, off_t, int);
#if NDRM > 0
	struct uvm_object *obj;
#endif

	/* before we do anything, ensure this device supports mmap */
	mapfn = cdevsw[major(device)].d_mmap;
	if (mapfn == NULL ||
	    mapfn == (paddr_t (*)(dev_t, off_t, int)) enodev ||
	    mapfn == (paddr_t (*)(dev_t, off_t, int)) nullop)
		return(NULL);

	/* Negative offsets on the object are not allowed. */
	if (off < 0)
		return(NULL);

#if NDRM > 0
	obj = udv_attach_drm(device, accessprot, off, size);
	if (obj)
		return(obj);
#endif

	/*
	 * Check that the specified range of the device allows the
	 * desired protection.
	 * 
	 * XXX clobbers off and size, but nothing else here needs them.
	 */
	while (size != 0) {
		if ((*mapfn)(device, off, accessprot) == -1)
			return (NULL);
		off += PAGE_SIZE; size -= PAGE_SIZE;
	}

	/* keep looping until we get it */
	for (;;) {
		/* first, attempt to find it on the main list */
		mtx_enter(&udv_lock);
		LIST_FOREACH(lcv, &udv_list, u_list) {
			if (device == lcv->u_device)
				break;
		}

		/* got it on main list.  put a hold on it and unlock udv_lock. */
		if (lcv) {
			/*
			 * if someone else has a hold on it, sleep and start
			 * over again. Else, we need take HOLD flag so we
			 * don't have to re-order locking here.
			 */
			if (lcv->u_flags & UVM_DEVICE_HOLD) {
				lcv->u_flags |= UVM_DEVICE_WANTED;
				msleep(lcv, &udv_lock, PVM | PNORELOCK,
				    "udv_attach", 0);
				continue;
			}

			/* we are now holding it */
			lcv->u_flags |= UVM_DEVICE_HOLD;
			mtx_leave(&udv_lock);

			/* bump reference count, unhold, return. */
			lcv->u_obj.uo_refs++;

			mtx_enter(&udv_lock);
			if (lcv->u_flags & UVM_DEVICE_WANTED)
				wakeup(lcv);
			lcv->u_flags &= ~(UVM_DEVICE_WANTED|UVM_DEVICE_HOLD);
			mtx_leave(&udv_lock);
			return(&lcv->u_obj);
		}

		/* did not find it on main list.   need to malloc a new one. */
		mtx_leave(&udv_lock);
		/* NOTE: we could sleep in the following malloc() */
		udv = malloc(sizeof(*udv), M_TEMP, M_WAITOK);
		mtx_enter(&udv_lock);

		/*
		 * now we have to double check to make sure no one added it
		 * to the list while we were sleeping...
		 */
		LIST_FOREACH(lcv, &udv_list, u_list) {
			if (device == lcv->u_device)
				break;
		}

		/*
		 * did we lose a race to someone else?
		 * free our memory and retry.
		 */
		if (lcv) {
			mtx_leave(&udv_lock);
			free(udv, M_TEMP, sizeof(*udv));
			continue;
		}

		/*
		 * we have it!   init the data structures, add to list
		 * and return.
		 */
		uvm_objinit(&udv->u_obj, &uvm_deviceops, 1);
		udv->u_flags = 0;
		udv->u_device = device;
		LIST_INSERT_HEAD(&udv_list, udv, u_list);
		mtx_leave(&udv_lock);
		return(&udv->u_obj);
	}
	/*NOTREACHED*/
}
	
/*
 * udv_reference
 *
 * add a reference to a VM object.   Note that the reference count must
 * already be one (the passed in reference) so there is no chance of the
 * udv being released or locked out here.
 */
static void
udv_reference(struct uvm_object *uobj)
{

	uobj->uo_refs++;
}

/*
 * udv_detach
 *
 * remove a reference to a VM object.
 */
static void
udv_detach(struct uvm_object *uobj)
{
	struct uvm_device *udv = (struct uvm_device *)uobj;

	/* loop until done */
again:
	if (uobj->uo_refs > 1) {
		uobj->uo_refs--;
		return;
	}
	KASSERT(uobj->uo_npages == 0 && RBT_EMPTY(uvm_objtree, &uobj->memt));

	/* is it being held?   if so, wait until others are done. */
	mtx_enter(&udv_lock);
	if (udv->u_flags & UVM_DEVICE_HOLD) {
		udv->u_flags |= UVM_DEVICE_WANTED;
		/*
		 * lock interleaving. -- this is ok in this case since the
		 * locks are both IPL_NONE
		 */
		msleep(udv, &udv_lock, PVM | PNORELOCK, "udv_detach", 0);
		goto again;
	}

	/* got it!   nuke it now. */
	LIST_REMOVE(udv, u_list);
	if (udv->u_flags & UVM_DEVICE_WANTED)
		wakeup(udv);
	mtx_leave(&udv_lock);
	free(udv, M_TEMP, sizeof(*udv));
}


/*
 * udv_flush
 *
 * flush pages out of a uvm object.   a no-op for devices.
 */
static boolean_t
udv_flush(struct uvm_object *uobj, voff_t start, voff_t stop, int flags)
{

	return(TRUE);
}

/*
 * udv_fault: non-standard fault routine for device "pages"
 *
 * => rather than having a "get" function, we have a fault routine
 *	since we don't return vm_pages we need full control over the
 *	pmap_enter map in
 * => on return, we unlock all fault data structures
 * => flags: PGO_ALLPAGES: get all of the pages
 *	     PGO_LOCKED: fault data structures are locked
 *    XXX: currently PGO_LOCKED is always required ... consider removing
 *	it as a flag
 * => NOTE: vaddr is the VA of pps[0] in ufi->entry, _NOT_ pps[centeridx]
 */
static int
udv_fault(struct uvm_faultinfo *ufi, vaddr_t vaddr, vm_page_t *pps, int npages,
    int centeridx, vm_fault_t fault_type, vm_prot_t access_type, int flags)
{
	struct vm_map_entry *entry = ufi->entry;
	struct uvm_object *uobj = entry->object.uvm_obj;
	struct uvm_device *udv = (struct uvm_device *)uobj;
	vaddr_t curr_va;
	off_t curr_offset;
	paddr_t paddr;
	int lcv, retval;
	dev_t device;
	paddr_t (*mapfn)(dev_t, off_t, int);
	vm_prot_t mapprot;

	/*
	 * we do not allow device mappings to be mapped copy-on-write
	 * so we kill any attempt to do so here.
	 */
	if (UVM_ET_ISCOPYONWRITE(entry)) {
		uvmfault_unlockall(ufi, ufi->entry->aref.ar_amap, uobj, NULL);
		return(VM_PAGER_ERROR);
	}

	/* get device map function. */
	device = udv->u_device;
	mapfn = cdevsw[major(device)].d_mmap;

	/*
	 * now we must determine the offset in udv to use and the VA to
	 * use for pmap_enter.  note that we always use orig_map's pmap
	 * for pmap_enter (even if we have a submap).   since virtual
	 * addresses in a submap must match the main map, this is ok.
	 */
	/* udv offset = (offset from start of entry) + entry's offset */
	curr_offset = entry->offset + (vaddr - entry->start);
	/* pmap va = vaddr (virtual address of pps[0]) */
	curr_va = vaddr;
	
	/* loop over the page range entering in as needed */
	retval = VM_PAGER_OK;
	for (lcv = 0 ; lcv < npages ; lcv++, curr_offset += PAGE_SIZE,
	    curr_va += PAGE_SIZE) {
		if ((flags & PGO_ALLPAGES) == 0 && lcv != centeridx)
			continue;

		if (pps[lcv] == PGO_DONTCARE)
			continue;

		paddr = (*mapfn)(device, curr_offset, access_type);
		if (paddr == -1) {
			retval = VM_PAGER_ERROR;
			break;
		}
		mapprot = ufi->entry->protection;
		if (pmap_enter(ufi->orig_map->pmap, curr_va, paddr,
		    mapprot, PMAP_CANFAIL | mapprot) != 0) {
			/*
			 * pmap_enter() didn't have the resource to
			 * enter this mapping.  Unlock everything,
			 * wait for the pagedaemon to free up some
			 * pages, and then tell uvm_fault() to start
			 * the fault again.
			 *
			 * XXX Needs some rethinking for the PGO_ALLPAGES
			 * XXX case.
			 */
			uvmfault_unlockall(ufi, ufi->entry->aref.ar_amap,
			    uobj, NULL);

			/* sync what we have so far */
			pmap_update(ufi->orig_map->pmap);      
			uvm_wait("udv_fault");
			return (VM_PAGER_REFAULT);
		}
	}

	uvmfault_unlockall(ufi, ufi->entry->aref.ar_amap, uobj, NULL);
	pmap_update(ufi->orig_map->pmap);
	return (retval);
}
@


1.53
log
@move the vm_page struct from being stored in RB macro trees to RBT functions

vm_page structs go into three trees, uvm_objtree, uvm_pmr_addr, and
uvm_pmr_size. all these have been moved to RBT code.

this should give us a decent chunk of code space back.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_device.c,v 1.52 2015/08/28 00:03:54 deraadt Exp $	*/
d45 2
a46 1
    defined(__macppc__) || defined(__sparc64__)
@


1.52
log
@fairly simple sizes for free(); ok tedu
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_device.c,v 1.51 2015/03/14 03:38:53 jsg Exp $	*/
d235 1
a235 1
	KASSERT(uobj->uo_npages == 0 && RB_EMPTY(&uobj->memt));
@


1.51
log
@Remove some includes include-what-you-use claims don't
have any direct symbols used.  Tested for indirect use by compiling
amd64/i386/sparc64 kernels.

ok tedu@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_device.c,v 1.50 2014/11/16 12:31:00 deraadt Exp $	*/
d187 1
a187 1
			free(udv, M_TEMP, 0);
d254 1
a254 1
	free(udv, M_TEMP, 0);
@


1.50
log
@Replace a plethora of historical protection options with just
PROT_NONE, PROT_READ, PROT_WRITE, and PROT_EXEC from mman.h.
PROT_MASK is introduced as the one true way of extracting those bits.
Remove UVM_ADV_* wrapper, using the standard names.
ok doug guenther kettenis
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_device.c,v 1.49 2014/09/14 14:17:27 jsg Exp $	*/
a39 1
#include <sys/vnode.h>
@


1.49
log
@remove uneeded proc.h includes
ok mpi@@ kspillner@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_device.c,v 1.48 2014/07/12 18:44:01 tedu Exp $	*/
a120 1
	 * XXX assumes VM_PROT_* == PROT_*
@


1.48
log
@add a size argument to free. will be used soon, but for now default to 0.
after discussions with beck deraadt kettenis.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_device.c,v 1.47 2014/07/11 16:35:40 jsg Exp $	*/
a37 1
#include <sys/proc.h>
@


1.47
log
@Chuck Cranor rescinded clauses in his license
on the 2nd of February 2011 in NetBSD.

http://marc.info/?l=netbsd-source-changes&m=129658899212732&w=2
http://marc.info/?l=netbsd-source-changes&m=129659095515558&w=2
http://marc.info/?l=netbsd-source-changes&m=129659157916514&w=2
http://marc.info/?l=netbsd-source-changes&m=129665962324372&w=2
http://marc.info/?l=netbsd-source-changes&m=129666033625342&w=2
http://marc.info/?l=netbsd-source-changes&m=129666052825545&w=2
http://marc.info/?l=netbsd-source-changes&m=129666922906480&w=2
http://marc.info/?l=netbsd-source-changes&m=129667725518082&w=2
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_device.c,v 1.46 2014/07/02 06:09:49 matthew Exp $	*/
d190 1
a190 1
			free(udv, M_TEMP);
d257 1
a257 1
	free(udv, M_TEMP);
@


1.46
log
@Use real parameter types for u{dv,vn}_attach() instead of void *

ok guenther
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_device.c,v 1.45 2014/04/13 23:14:15 tedu Exp $	*/
a4 1
 *
a15 6
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *      This product includes software developed by Charles D. Cranor and
 *      Washington University.
 * 4. The name of the author may not be used to endorse or promote products
 *    derived from this software without specific prior written permission.
@


1.45
log
@compress code by turning four line comments into one line comments.
emphatic ok usual suspects, grudging ok miod
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_device.c,v 1.44 2013/08/13 06:56:41 kettenis Exp $	*/
d100 1
a100 1
udv_attach(void *arg, vm_prot_t accessprot, voff_t off, vsize_t size)
a101 1
	dev_t device = *((dev_t *)arg);
d120 1
a120 1
	obj = udv_attach_drm(arg, accessprot, off, size);
@


1.44
log
@Make the tree compile again on architectures without drm(4).

ok maja@@, miod@@, jsg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_device.c,v 1.43 2013/06/07 20:46:14 kettenis Exp $	*/
a69 1

a80 1

a89 5
 * the ops.
 */


/*
d109 1
a109 4
	/*
	 * before we do anything, ensure this device supports mmap
	 */

d116 1
a116 4
	/*
	 * Negative offsets on the object are not allowed.
	 */

a132 1

d139 1
a139 4
	/*
	 * keep looping until we get it
	 */

d141 1
a141 5

		/*
		 * first, attempt to find it on the main list 
		 */

d148 1
a148 4
		/*
		 * got it on main list.  put a hold on it and unlock udv_lock.
		 */

a149 1

a154 1

d166 1
a166 4
			/*
			 * bump reference count, unhold, return.
			 */

d177 1
a177 4
		/*
		 * did not find it on main list.   need to malloc a new one.
		 */

a186 1

a195 1

a205 1

a222 1

a234 1

d240 1
a240 3
	/*
	 * loop until done
	 */
d248 1
a248 4
	/*
	 * is it being held?   if so, wait until others are done.
	 */

d260 1
a260 4
	/*
	 * got it!   nuke it now.
	 */

a273 1

a293 1

a312 1
	
d318 1
a318 4
	/*
	 * get device map function.   
	 */

a327 1

d333 1
a333 4
	/*
	 * loop over the page range entering in as needed
	 */

@


1.43
log
@Add proper mmap(2) support for drm(4)/inteldrm(4).  This changes the
DRM_I915_GEM_MMAP and DRM_I915_GEM_MMAP_GTT ioctls to be compatible with
Linux.  This also is the first step that moves us away from accessing all
graphics memory through the GTT, which should make things faster.

ok tedu@@ (for the uvm bits)
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_device.c,v 1.42 2013/05/30 16:29:46 tedu Exp $	*/
d53 2
d56 1
@


1.42
log
@remove lots of comments about locking per beck's request
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_device.c,v 1.41 2013/05/30 15:17:59 tedu Exp $	*/
d53 2
d109 3
d129 6
@


1.41
log
@remove simple_locks from uvm code. ok beck deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_device.c,v 1.40 2011/07/03 18:34:14 oga Exp $	*/
d97 1
a97 2
 * => caller must _not_ already be holding the lock on the uvm_object.
 * => in fact, nothing should be locked so that we can sleep here.
a242 2
 *
 * => caller must call with object unlocked.
a255 2
 *
 * => caller must call with object unlocked and map locked.
a318 2
 * => all the usual fault data structured are locked by the caller
 *	(i.e. maps(read), amap (if any), uobj)
@


1.40
log
@Rip out and burn support for UVM_HIST.

The vm hackers don't use it, don't maintain it and have to look at it all the
time. About time this 800 lines of code hit /dev/null.

``never liked it'' tedu@@. ariane@@ was very happy when i told her i wrote
this diff.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_device.c,v 1.39 2010/12/26 15:41:00 miod Exp $	*/
a182 1
			simple_lock(&lcv->u_obj.vmobjlock);
a183 1
			simple_unlock(&lcv->u_obj.vmobjlock);
a251 1
	simple_lock(&uobj->vmobjlock);
a252 1
	simple_unlock(&uobj->vmobjlock);
a271 1
	simple_lock(&uobj->vmobjlock);
a273 1
		simple_unlock(&uobj->vmobjlock);
a288 1
		simple_unlock(&uobj->vmobjlock);
a300 1
	simple_unlock(&uobj->vmobjlock);
@


1.39
log
@Kill pmap_phys_address(), and force every driver's mmap() routine to return
a physical address [more precisely, something suitable to pass to pmap_enter()'sphysical address argument].

This allows MI drivers to implement mmap() routines without having to know
about the pmap_phys_address() implementation and #ifdef obfuscation.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_device.c,v 1.38 2010/04/30 21:56:39 oga Exp $	*/
a107 3
	UVMHIST_FUNC("udv_attach"); UVMHIST_CALLED(maphist);

	UVMHIST_LOG(maphist, "(device=0x%lx)", device,0,0,0);
a252 1
	UVMHIST_FUNC("udv_reference"); UVMHIST_CALLED(maphist);
a255 2
	UVMHIST_LOG(maphist, "<- done (uobj=%p, ref = %ld)", 
		    uobj, uobj->uo_refs,0,0);
a270 1
	UVMHIST_FUNC("udv_detach"); UVMHIST_CALLED(maphist);
a279 2
		UVMHIST_LOG(maphist," <- done, uobj=%p, ref=%ld", 
			  uobj,uobj->uo_refs,0,0);
a309 1
	UVMHIST_LOG(maphist," <- done, freed uobj=%p", uobj,0,0,0);
a355 2
	UVMHIST_FUNC("udv_fault"); UVMHIST_CALLED(maphist);
	UVMHIST_LOG(maphist,"  flags=%ld", flags,0,0,0);
a362 2
		UVMHIST_LOG(maphist, "<- failed -- COW entry (etype=0x%lx)", 
		    entry->etype, 0,0,0);
a404 3
		UVMHIST_LOG(maphist,
		    "  MAPPING: device: pm=%p, va=0x%lx, pa=0x%lx, at=%ld",
		    ufi->orig_map->pmap, curr_va, (u_long)paddr, mapprot);
@


1.38
log
@Right now, if anything internal changes with a uvm object, diverse
places in the tree need to be touched to update the object
initialisation with respect to that.

So, make a function (uvm_initobj) that takes the refcount, object and
pager ops and does this initialisation for us. This should save on
maintainance in the future.

looked good to fgs@@. Tedu complained about the British spelling but OKed
it anyway.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_device.c,v 1.37 2009/08/14 16:27:34 oga Exp $	*/
d361 1
a361 1
	paddr_t paddr, mdpgno;
d413 2
a414 2
		mdpgno = (*mapfn)(device, curr_offset, access_type);
		if (mdpgno == -1) {
a417 1
		paddr = pmap_phys_address(mdpgno);
@


1.37
log
@make the uvm device lock a mutex.

This is the same diff that was backed out after c2k9 in the date-based
revert.

ok ariane@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_device.c,v 1.36 2009/08/06 15:28:14 oga Exp $	*/
d233 1
a233 5
		simple_lock_init(&udv->u_obj.vmobjlock);
		udv->u_obj.pgops = &uvm_deviceops;
		RB_INIT(&udv->u_obj.memt);
		udv->u_obj.uo_npages = 0;
		udv->u_obj.uo_refs = 1;
@


1.36
log
@reintroduce the uvm_tree commit.

Now instead of the global object hashtable, we have a per object tree.

Testing shows no performance difference and a slight code shrink. OTOH when
locking is more fine grained this should be faster due to lock contention on
uvm.hashlock.

ok thib@@, art@@.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_device.c,v 1.35 2009/06/16 23:54:57 oga Exp $	*/
d47 1
d59 2
a60 3
LIST_HEAD(udv_list_struct, uvm_device);
static struct udv_list_struct udv_list;
static simple_lock_data_t udv_lock;
a65 1
static void		udv_init(void);
d79 1
a79 1
	udv_init,
d87 1
a87 1
 * the ops!
a89 13
/*
 * udv_init
 *
 * init pager private data structures.
 */

void
udv_init(void)
{

	LIST_INIT(&udv_list);
	simple_lock_init(&udv_lock);
}
d153 1
a153 1
		simple_lock(&udv_lock);
d167 2
a168 1
			 * over again.
d173 2
a174 2
				UVM_UNLOCK_AND_WAIT(lcv, &udv_lock, FALSE,
				    "udv_attach",0);
d180 1
a180 1
			simple_unlock(&udv_lock);
d190 1
a190 1
			simple_lock(&udv_lock);
d194 1
a194 1
			simple_unlock(&udv_lock);
d202 1
a202 1
		simple_unlock(&udv_lock);
d205 1
a205 1
		simple_lock(&udv_lock);
d223 1
a223 1
			simple_unlock(&udv_lock);
d241 1
a241 1
		simple_unlock(&udv_lock);
d301 1
a301 1
	simple_lock(&udv_lock);
d304 4
d309 1
a309 1
		UVM_UNLOCK_AND_WAIT(udv, &udv_lock, FALSE, "udv_detach",0);
d320 1
a320 1
	simple_unlock(&udv_lock);
@


1.35
log
@date based reversion of uvm to the 4th May.

We still have no idea why this stops the crashes. but it does.

a machine forced to 64mb of ram cycled 10GB through swap with this diff
and is still running as I type this. Other tests by ariane@@ and thib@@
also seem to show that it's alright.

ok deraadt@@, thib@@, ariane@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_device.c,v 1.30 2009/03/23 19:23:43 oga Exp $	*/
d248 1
a248 1
		TAILQ_INIT(&udv->u_obj.memq);
d308 1
a308 1
	KASSERT(uobj->uo_npages == 0 && TAILQ_EMPTY(&uobj->memq));
@


1.34
log
@Backout all changes to uvm after pmemrange (which will be backed out
separately).

a change at or just before the hackathon has either exposed or added a
very very nasty memory corruption bug that is giving us hell right now.
So in the interest of kernel stability these diffs are being backed out
until such a time as that corruption bug has been found and squashed,
then the ones that are proven good may slowly return.

a quick hitlist of the main commits this backs out:

mine:
uvm_objwire
the lock change in uvm_swap.c
using trees for uvm objects instead of the hash
removing the pgo_releasepg callback.

art@@'s:
putting pmap_page_protect(VM_PROT_NONE) in uvm_pagedeactivate() since
all callers called that just prior anyway.

ok beck@@, ariane@@.

prompted by deraadt@@.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_device.c,v 1.32 2009/05/12 20:49:56 oga Exp $	*/
d58 3
a60 2
LIST_HEAD(udvlist, uvm_device) udv_list = LIST_HEAD_INITIALIZER(udv_list);
struct mutex udv_lock = MUTEX_INITIALIZER(IPL_NONE);
d66 8
a73 5
void		udv_reference(struct uvm_object *);
void		udv_detach(struct uvm_object *);
boolean_t	udv_flush(struct uvm_object *, voff_t, voff_t, int);
int		udv_fault(struct uvm_faultinfo *, vaddr_t, vm_page_t *,
		    int, int, vm_fault_t, vm_prot_t, int);
d80 1
a80 1
	NULL,		/* lock and list already initialized */
d92 14
d167 1
a167 1
		mtx_enter(&udv_lock);
d181 1
a181 2
			 * over again. Else, we need the HOLD flag so we
			 * don't have to re-order locking here.
d183 1
d186 2
a187 2
				msleep(lcv, &udv_lock, PVM | PNORELOCK,
				    "udv_attach", 0);
d193 1
a193 1
			mtx_leave(&udv_lock);
d203 1
a203 1
			mtx_enter(&udv_lock);
d207 1
a207 1
			mtx_leave(&udv_lock);
d215 1
a215 1
		mtx_leave(&udv_lock);
d218 1
a218 1
		mtx_enter(&udv_lock);
d236 1
a236 1
			mtx_leave(&udv_lock);
d254 1
a254 1
		mtx_leave(&udv_lock);
d270 1
a270 1
void
d290 1
a290 1
void
a311 1
	 * It is probably about to be referenced.
d314 1
a314 1
	mtx_enter(&udv_lock);
d318 1
a318 1
		msleep(udv, &udv_lock, PVM | PNORELOCK, "udv_detach", 0);
d329 1
a329 1
	mtx_leave(&udv_lock);
d342 1
a342 1
boolean_t
d365 1
a365 1
int
@


1.33
log
@Instead of the global hash table with the terrible hashfunction and a
global lock, switch the uvm object pages to being kept in a per-object
RB_TREE. Right now this is approximately the same speed, but cleaner.
When biglock usage is reduced this will improve concurrency due to lock
contention..

ok beck@@ art@@. Thanks to jasper for the speed testing.
@
text
@d230 1
a230 1
		RB_INIT(&udv->u_obj.memt);
d290 1
a290 1
	KASSERT(uobj->uo_npages == 0 && RB_EMPTY(&uobj->memt));
@


1.32
log
@Convert the udv_lock for the list of uvm_device objects over to a mutex.

ok thib@@, weingart@@.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_device.c,v 1.31 2009/05/08 13:50:15 ariane Exp $	*/
d230 1
a230 1
		TAILQ_INIT(&udv->u_obj.memq);
d290 1
a290 1
	KASSERT(uobj->uo_npages == 0 && TAILQ_EMPTY(&uobj->memq));
@


1.31
log
@Remove static qualifier of functions that are not inline.
Makes trace in ddb useful.

ok oga
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_device.c,v 1.30 2009/03/23 19:23:43 oga Exp $	*/
d58 2
a59 3
LIST_HEAD(udv_list_struct, uvm_device);
static struct udv_list_struct udv_list;
static simple_lock_data_t udv_lock;
a64 1
void		udv_init(void);
a66 3
int		udv_fault(struct uvm_faultinfo *, vaddr_t,
				       vm_page_t *, int, int, vm_fault_t,
				       vm_prot_t, int);
d68 2
d76 1
a76 1
	udv_init,
a87 14
 * udv_init
 *
 * init pager private data structures.
 */

void
udv_init(void)
{

	LIST_INIT(&udv_list);
	simple_lock_init(&udv_lock);
}

/*
d149 1
a149 1
		simple_lock(&udv_lock);
d163 2
a164 1
			 * over again.
a165 1

d168 2
a169 2
				UVM_UNLOCK_AND_WAIT(lcv, &udv_lock, FALSE,
				    "udv_attach",0);
d175 1
a175 1
			simple_unlock(&udv_lock);
d185 1
a185 1
			simple_lock(&udv_lock);
d189 1
a189 1
			simple_unlock(&udv_lock);
d197 1
a197 1
		simple_unlock(&udv_lock);
d200 1
a200 1
		simple_lock(&udv_lock);
d218 1
a218 1
			simple_unlock(&udv_lock);
d236 1
a236 1
		simple_unlock(&udv_lock);
d294 1
d297 1
a297 1
	simple_lock(&udv_lock);
d301 1
a301 1
		UVM_UNLOCK_AND_WAIT(udv, &udv_lock, FALSE, "udv_detach",0);
d312 1
a312 1
	simple_unlock(&udv_lock);
@


1.30
log
@Remove space added in last commit. Pointed out by miod@@.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_device.c,v 1.29 2009/03/20 15:19:04 oga Exp $	*/
d66 4
a69 4
static void		udv_init(void);
static void             udv_reference(struct uvm_object *);
static void             udv_detach(struct uvm_object *);
static int		udv_fault(struct uvm_faultinfo *, vaddr_t,
d72 1
a72 2
static boolean_t        udv_flush(struct uvm_object *, voff_t, voff_t,
				       int);
d269 1
a269 1
static void
d289 1
a289 1
static void
d341 1
a341 1
static boolean_t
d364 1
a364 1
static int
@


1.29
log
@While working on some stuff in uvm I've gotten REALLY sick of reading
K&R function declarations, so switch them all over to ansi-style, in
accordance with the prophesy.

"go for it" art@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_device.c,v 1.28 2007/10/29 17:08:08 chl Exp $	*/
d366 1
a366 1
udv_fault( struct uvm_faultinfo *ufi, vaddr_t vaddr, vm_page_t *pps, int npages,
@


1.28
log
@MALLOC/FREE -> malloc/free

ok krw@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_device.c,v 1.27 2006/07/31 11:51:29 mickey Exp $	*/
d98 1
a98 1
udv_init()
d113 2
d117 1
a117 5
udv_attach(arg, accessprot, off, size)
	void *arg;
	vm_prot_t accessprot;
	voff_t off;			/* used only for access check */
	vsize_t size;			/* used only for access check */
d271 1
a271 2
udv_reference(uobj)
	struct uvm_object *uobj;
d291 1
a291 2
udv_detach(uobj)
	struct uvm_object *uobj;
d343 1
a343 4
udv_flush(uobj, start, stop, flags)
	struct uvm_object *uobj;
	voff_t start, stop;
	int flags;
d366 2
a367 7
udv_fault(ufi, vaddr, pps, npages, centeridx, fault_type, access_type, flags)
	struct uvm_faultinfo *ufi;
	vaddr_t vaddr;
	vm_page_t *pps;
	int npages, centeridx, flags;
	vm_fault_t fault_type;
	vm_prot_t access_type;
@


1.27
log
@fix uvmhist #2: args are always u_long so fix missing %d and %x and no %ll; no change for normal code
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_device.c,v 1.26 2006/07/26 23:15:55 mickey Exp $	*/
d219 1
a219 2
		MALLOC(udv, struct uvm_device *, sizeof(*udv), M_TEMP,
		       M_WAITOK);
d239 1
a239 1
			FREE(udv, M_TEMP);
d335 1
a335 1
	FREE(udv, M_TEMP);
@


1.26
log
@fix fmts for UVMHIST_LOG() entries making it more useful on 64bit archs; miod@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_device.c,v 1.25 2006/01/16 13:11:05 mickey Exp $	*/
d126 1
a126 1
	UVMHIST_LOG(maphist, "(device=0x%x)", device,0,0,0);
d281 1
a281 1
	UVMHIST_LOG(maphist, "<- done (uobj=%p, ref = %d)", 
d309 1
a309 1
		UVMHIST_LOG(maphist," <- done, uobj=%p, ref=%d", 
d393 1
a393 1
	UVMHIST_LOG(maphist,"  flags=%d", flags,0,0,0);
d401 1
a401 1
		UVMHIST_LOG(maphist, "<- failed -- COW entry (etype=0x%x)", 
d447 2
a448 2
		    "  MAPPING: device: pm=%p, va=0x%lx, pa=0x%llx, at=%d",
		    ufi->orig_map->pmap, curr_va, (long long)paddr, mapprot);
@


1.25
log
@add another uvm histroy for physpage alloc/free and propagate a debugging pgfree check into pglist; no functional change for normal kernels; make histories uncommon
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_device.c,v 1.24 2004/02/23 06:19:32 drahn Exp $	*/
d281 1
a281 1
	UVMHIST_LOG(maphist, "<- done (uobj=0x%x, ref = %d)", 
d309 1
a309 1
		UVMHIST_LOG(maphist," <- done, uobj=0x%x, ref=%d", 
d337 1
a337 1
	UVMHIST_LOG(maphist," <- done, freed uobj=0x%x", uobj,0,0,0);
d402 1
a402 1
		entry->etype, 0,0,0);
d447 1
a447 1
		    "  MAPPING: device: pm=0x%x, va=0x%x, pa=0x%llx, at=%d",
@


1.24
log
@sync of pmap_update() calls with NetBSD. pmap_update is defined away on
all architectures but arm, where it is needed.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_device.c,v 1.23 2002/11/06 00:17:28 art Exp $	*/
d447 2
a448 2
		    "  MAPPING: device: pm=0x%x, va=0x%x, pa=0x%lx, at=%d",
		    ufi->orig_map->pmap, curr_va, paddr, mapprot);
@


1.23
log
@Eliminate the use of KERN_SUCCESS outside of uvm/

Also uvm_map returns KERN_* codes that are directly mapped to
errnos, so we can return them instead of doing some attempt to
translation.

drahn@@ "I see no problem" pval@@ "makes sense"
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_device.c,v 1.22 2002/03/14 01:27:18 millert Exp $	*/
d463 3
d472 1
@


1.22
log
@First round of __P removal in sys
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_device.c,v 1.21 2001/12/19 08:58:07 art Exp $	*/
d450 1
a450 1
		    mapprot, PMAP_CANFAIL | mapprot) != KERN_SUCCESS) {
@


1.21
log
@UBC was a disaster. It worked very good when it worked, but on some
machines or some configurations or in some phase of the moon (we actually
don't know when or why) files disappeared. Since we've not been able to
track down the problem in two weeks intense debugging and we need -current
to be stable, back out everything to a state it had before UBC.

We apologise for the inconvenience.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_device.c,v 1.17 2001/11/07 02:55:50 art Exp $	*/
d66 4
a69 4
static void		udv_init __P((void));
static void             udv_reference __P((struct uvm_object *));
static void             udv_detach __P((struct uvm_object *));
static int		udv_fault __P((struct uvm_faultinfo *, vaddr_t,
d71 3
a73 3
				       vm_prot_t, int));
static boolean_t        udv_flush __P((struct uvm_object *, voff_t, voff_t,
				       int));
d123 1
a123 1
	paddr_t (*mapfn) __P((dev_t, off_t, int));
d134 2
a135 2
	    mapfn == (paddr_t (*) __P((dev_t, off_t, int))) enodev ||
	    mapfn == (paddr_t (*) __P((dev_t, off_t, int))) nullop)
d390 1
a390 1
	paddr_t (*mapfn) __P((dev_t, off_t, int));
@


1.20
log
@Yet another sync to NetBSD uvm.
Today we add a pmap argument to pmap_update() and allocate map entries for
kernel_map from kmem_map instead of using the static entries. This should
get rid of MAX_KMAPENT panics. Also some uvm_loan problems are fixed.
@
text
@d1 2
a2 2
/*	$OpenBSD: uvm_device.c,v 1.19 2001/11/28 19:28:14 art Exp $	*/
/*	$NetBSD: uvm_device.c,v 1.37 2001/09/10 21:19:42 chris Exp $	*/
d60 1
a60 1
static struct simplelock udv_lock;
d70 1
a70 1
				       struct vm_page **, int, int, vm_fault_t,
d148 1
a148 1
	 *
d166 1
a166 1
		 * first, attempt to find it on the main list
d262 1
a262 1

d281 1
a281 1
	UVMHIST_LOG(maphist, "<- done (uobj=0x%x, ref = %d)",
d309 1
a309 1
		UVMHIST_LOG(maphist," <- done, uobj=0x%x, ref=%d",
d377 1
a377 1
	struct vm_page **pps;
d399 1
a399 1

d401 1
a401 1
		UVMHIST_LOG(maphist, "<- failed -- COW entry (etype=0x%x)",
d404 1
a404 1
		return(EIO);
d408 1
a408 1
	 * get device map function.
d425 1
a425 1

d430 1
a430 1
	retval = 0;
d441 1
a441 1
			retval = EIO;
d450 1
a450 1
		    mapprot, PMAP_CANFAIL | mapprot) != 0) {
a462 1
			pmap_update(ufi->orig_map->pmap);	/* sync what we have so far */
d464 1
a464 1
			return (ERESTART);
a468 1
	pmap_update(ufi->orig_map->pmap);
@


1.20.2.1
log
@Merge in UBC performance changes from NetBSD.
Fix a bunch of merge errors from yesterday.
@
text
@d1 2
a2 2
/*	$OpenBSD: uvm_device.c,v 1.20 2001/12/04 23:22:42 art Exp $	*/
/*	$NetBSD: uvm_device.c,v 1.39 2001/11/10 07:36:59 lukem Exp $	*/
d66 8
a73 5
static void	udv_init __P((void));
static void	udv_reference __P((struct uvm_object *));
static void	udv_detach __P((struct uvm_object *));
static int	udv_fault __P((struct uvm_faultinfo *, vaddr_t,
    struct vm_page **, int, int, vm_fault_t, vm_prot_t, int));
d84 1
d97 2
a98 2
static void
udv_init(void)
d100 1
a113 1

d313 1
d338 17
@


1.20.2.2
log
@Sync UBC branch to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_device.c,v 1.20.2.1 2002/02/02 03:28:26 art Exp $	*/
d66 5
a70 5
static void	udv_init(void);
static void	udv_reference(struct uvm_object *);
static void	udv_detach(struct uvm_object *);
static int	udv_fault(struct uvm_faultinfo *, vaddr_t,
    struct vm_page **, int, int, vm_fault_t, vm_prot_t, int);
d119 1
a119 1
	paddr_t (*mapfn)(dev_t, off_t, int);
d130 2
a131 2
	    mapfn == (paddr_t (*)(dev_t, off_t, int)) enodev ||
	    mapfn == (paddr_t (*)(dev_t, off_t, int)) nullop)
d368 1
a368 1
	paddr_t (*mapfn)(dev_t, off_t, int);
@


1.20.2.3
log
@Huge sync to NetBSD plus lots of bugfixes.
 - uvm is as in netbsd-current minus uvm_map forward merge.
 - various locking bugfixes in nfs.
 - make sure that all specops and fifoops are correct in all vnodeop vectors.
 - make the filesystem code more like filsystem code and less like vm code.
@
text
@d1 2
a2 2
/*	$OpenBSD: uvm_device.c,v 1.20.2.2 2002/06/11 03:33:03 art Exp $	*/
/*	$NetBSD: uvm_device.c,v 1.41 2002/09/06 13:24:12 gehenna Exp $	*/
d119 1
a119 1
	dev_type_mmap((*mapfn));
d130 2
a131 2
	    mapfn == (dev_type_mmap((*))) enodev ||
	    mapfn == (dev_type_mmap((*))) nullop)
@


1.19
log
@Sync in more uvm from NetBSD. Mostly just cosmetic stuff.
Contains also support for page coloring.
@
text
@d1 2
a2 2
/*	$OpenBSD: uvm_device.c,v 1.18 2001/11/28 13:47:39 art Exp $	*/
/*	$NetBSD: uvm_device.c,v 1.36 2001/05/26 21:27:21 chs Exp $	*/
d463 1
a463 1
			pmap_update();	/* sync what we have so far */
d470 1
a470 1
	pmap_update();
@


1.18
log
@Sync in more uvm changes from NetBSD.
This time we're getting rid of KERN_* and VM_PAGER_* error codes and
use errnos instead.
@
text
@d1 2
a2 2
/*	$OpenBSD: uvm_device.c,v 1.17 2001/11/07 02:55:50 art Exp $	*/
/*	$NetBSD: uvm_device.c,v 1.32 2001/03/15 06:10:56 chs Exp $	*/
d60 1
a60 1
static simple_lock_data_t udv_lock;
d70 1
a70 1
				       vm_page_t *, int, int, vm_fault_t,
d148 1
a148 1
	 * 
d166 1
a166 1
		 * first, attempt to find it on the main list 
d262 1
a262 1
	
d281 1
a281 1
	UVMHIST_LOG(maphist, "<- done (uobj=0x%x, ref = %d)", 
d309 1
a309 1
		UVMHIST_LOG(maphist," <- done, uobj=0x%x, ref=%d", 
d377 1
a377 1
	vm_page_t *pps;
d399 1
a399 1
	
d401 1
a401 1
		UVMHIST_LOG(maphist, "<- failed -- COW entry (etype=0x%x)", 
d408 1
a408 1
	 * get device map function.   
d425 1
a425 1
	
d463 1
d470 1
@


1.17
log
@Another sync of uvm to NetBSD. Just minor fiddling, no major changes.
@
text
@d1 2
a2 2
/*	$OpenBSD: uvm_device.c,v 1.16 2001/11/06 01:35:04 art Exp $	*/
/*	$NetBSD: uvm_device.c,v 1.30 2000/11/25 06:27:59 chs Exp $	*/
d404 1
a404 1
		return(VM_PAGER_ERROR);
d430 1
a430 1
	retval = VM_PAGER_OK;
d441 1
a441 1
			retval = VM_PAGER_ERROR;
d450 1
a450 1
		    mapprot, PMAP_CANFAIL | mapprot) != KERN_SUCCESS) {
d464 1
a464 1
			return (VM_PAGER_REFAULT);
@


1.16
log
@Move the last content from vm/ to uvm/
The only thing left in vm/ are just dumb wrappers.
vm/vm.h includes uvm/uvm_extern.h
vm/pmap.h includes uvm/uvm_pmap.h
vm/vm_page.h includes uvm/uvm_page.h
@
text
@d1 2
a2 2
/*	$OpenBSD: uvm_device.c,v 1.15 2001/11/05 22:14:54 art Exp $	*/
/*	$NetBSD: uvm_device.c,v 1.28 2000/06/27 17:29:20 mrg Exp $	*/
a71 2
static int		udv_asyncget __P((struct uvm_object *, voff_t,
				       int));
a73 2
static int		udv_put __P((struct uvm_object *, vm_page_t *,
					int, boolean_t));
a84 7
	NULL,		/* no get function since we have udv_fault */
	udv_asyncget,
	udv_put,
	NULL,		/* no cluster function */
	NULL,		/* no put cluster function */
	NULL,		/* no AIO-DONE function since no async i/o */
	NULL,		/* no releasepg function since no normal pages */
d121 1
a121 1
	dev_t device = *((dev_t *) arg);
d134 2
a135 2
			mapfn == (paddr_t (*) __P((dev_t, off_t, int))) enodev ||
			mapfn == (paddr_t (*) __P((dev_t, off_t, int))) nullop)
d141 1
d163 1
a163 1
	while (1) {
d170 1
a170 1
		for (lcv = udv_list.lh_first ; lcv != NULL ; lcv = lcv->u_list.le_next) {
d204 1
a204 1
			
d219 2
a220 1
		MALLOC(udv, struct uvm_device *, sizeof(*udv), M_TEMP, M_WAITOK);
d228 1
a228 2
		for (lcv = udv_list.lh_first ; lcv != NULL ;
		    lcv = lcv->u_list.le_next) {
d234 2
a235 1
		 * did we lose a race to someone else?   free our memory and retry.
d251 1
a251 1
		TAILQ_INIT(&udv->u_obj.memq);	/* not used, but be safe */
a257 1

d259 1
a259 3

	}  /* while(1) loop */

d282 1
a282 1
	uobj, uobj->uo_refs,0,0);
d298 1
a298 1
	struct uvm_device *udv = (struct uvm_device *) uobj;
a300 1

a305 1
	
d307 1
a307 1
		uobj->uo_refs--;			/* drop ref! */
d313 1
a313 5

#ifdef DIAGNOSTIC
	if (uobj->uo_npages || !TAILQ_EMPTY(&uobj->memq))
		panic("udv_detach: pages in a device object?");
#endif
d316 1
a316 1
	 * now lock udv_lock
d318 1
a319 4

	/*
	 * is it being held?   if so, wait until others are done.
	 */
d330 1
a336 1

a337 1
	return;
d347 2
a348 1
static boolean_t udv_flush(uobj, start, stop, flags)
a395 7
	 * XXX: !PGO_LOCKED calls are currently not allowed (or used)
	 */

	if ((flags & PGO_LOCKED) == 0)
		panic("udv_fault: !PGO_LOCKED fault");

	/*
d410 1
d420 1
a469 34
}

/*
 * udv_asyncget: start async I/O to bring pages into ram
 *
 * => caller must lock object(???XXX: see if this is best)
 * => a no-op for devices
 */

static int
udv_asyncget(uobj, offset, npages)
	struct uvm_object *uobj;
	voff_t offset;
	int npages;
{

	return(KERN_SUCCESS);
}

/*
 * udv_put: flush page data to backing store.
 *
 * => this function should never be called (since we never have any
 *	page structures to "put")
 */

static int
udv_put(uobj, pps, npages, flags)
	struct uvm_object *uobj;
	struct vm_page **pps;
	int npages, flags;
{

	panic("udv_put: trying to page out to a device!");
@


1.15
log
@Minor sync to NetBSD.
@
text
@d1 2
a2 2
/*	$OpenBSD: uvm_device.c,v 1.12 2001/09/11 20:05:26 miod Exp $	*/
/*	$NetBSD: uvm_device.c,v 1.26 2000/06/26 14:21:17 mrg Exp $	*/
a48 2
#include <vm/vm.h>

d407 1
a407 1
	int curr_offset;
d448 1
a448 1
	curr_offset = (int)((vaddr - entry->start) + entry->offset);
d473 2
a474 2
		    "  MAPPING: device: pm=0x%x, va=0x%x, pa=0x%x, at=%d",
		    ufi->orig_map->pmap, curr_va, (int)paddr, mapprot);
@


1.14
log
@Don't allow negative offsets. Some type confusion.
@
text
@d2 1
a2 1
/*	$NetBSD: uvm_device.c,v 1.22 2000/05/28 10:21:55 drochner Exp $	*/
a49 1
#include <vm/vm_page.h>
d147 2
a148 2
			mapfn == (paddr_t (*) __P((dev_t, off_t, int)))enodev ||
			mapfn == (paddr_t (*) __P((dev_t, off_t, int)))nullop)
d151 3
d155 1
a155 1
		return (NULL);
d315 1
d319 10
a328 11

	while (1) {
		simple_lock(&uobj->vmobjlock);
		
		if (uobj->uo_refs > 1) {
			uobj->uo_refs--;			/* drop ref! */
			simple_unlock(&uobj->vmobjlock);
			UVMHIST_LOG(maphist," <- done, uobj=0x%x, ref=%d", 
				  uobj,uobj->uo_refs,0,0);
			return;
		}
d331 2
a332 2
		if (uobj->uo_npages || uobj->memq.tqh_first)
			panic("udv_detach: pages in a device object?");
d335 4
a338 4
		/*
		 * now lock udv_lock
		 */
		simple_lock(&udv_lock);
d340 9
a348 4
		/*
		 * is it being held?   if so, wait until others are done.
		 */
		if (udv->u_flags & UVM_DEVICE_HOLD) {
d350 9
a358 20
			/*
			 * want it
			 */
			udv->u_flags |= UVM_DEVICE_WANTED;
			simple_unlock(&uobj->vmobjlock);
			UVM_UNLOCK_AND_WAIT(udv, &udv_lock, FALSE, "udv_detach",0);
			continue;
		}

		/*
		 * got it!   nuke it now.
		 */

		LIST_REMOVE(udv, u_list);
		if (udv->u_flags & UVM_DEVICE_WANTED)
			wakeup(udv);
		FREE(udv, M_TEMP);
		break;	/* DONE! */

	}	/* while (1) loop */
@


1.13
log
@Change d_mmap in struct cdevsw from:
        int     (*d_mmap)       __P((dev_t, int, int));
to:
	paddr_t	(*d_mmap)	__P((dev_t, off_t, int));

This allows us to mmap devices past 4GB offsets.
@
text
@d152 3
d414 2
a415 2
	paddr_t paddr;
	int lcv, retval, mdpgno;
@


1.12
log
@Don't include <vm/vm_kern.h> if you don't need foo_map.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_device.c,v 1.11 2001/08/11 10:57:22 art Exp $	*/
d137 1
a137 1
	int (*mapfn) __P((dev_t, int, int));
d148 2
a149 2
			mapfn == (int (*) __P((dev_t, int, int))) enodev ||
			mapfn == (int (*) __P((dev_t, int, int))) nullop)
a152 9
	 * As long as the device d_mmap interface gets an "int"
	 * offset, we have to watch out not to overflow its
	 * numeric range. (assuming it will be interpreted as
	 * "unsigned")
	 */
	if (((off + size - 1) & (u_int)-1) != off + size - 1)
		return (0);

	/*
d414 1
a414 1
	int (*mapfn) __P((dev_t, int, int));
@


1.11
log
@Various random fixes from NetBSD.
Including support for zeroing pages in the idle loop (not enabled yet).
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_device.c,v 1.10 2001/08/06 14:03:04 art Exp $	*/
a50 1
#include <vm/vm_kern.h>
@


1.10
log
@Add a new type voff_t (right now it's typedefed as off_t) used for offsets
into objects.

Gives the possibilty to mmap beyond the size of vaddr_t.

From NetBSD.
@
text
@d1 2
a2 2
/*	$OpenBSD: uvm_device.c,v 1.9 2001/07/25 13:25:33 art Exp $	*/
/*	$NetBSD: uvm_device.c,v 1.20 2000/03/26 20:54:46 kleink Exp $	*/
a97 1
	NULL,		/* no share protect.   no share maps for us */
d133 1
a133 1
	vaddr_t off;			/* used only for access check */
d152 9
@


1.9
log
@Change the pmap_enter interface to merge access_type and the wired boolean
and arbitrary flags into one argument.

One new flag is PMAP_CANFAIL that tells pmap_enter that it can fail if there
are not enough resources to satisfy the request. If this flag is not passed,
pmap_enter should panic as it should have done before this change (XXX - many
pmaps are still not doing that).

Only i386 and alpha implement CANFAIL for now.

Includes uvm updates from NetBSD.
@
text
@d1 2
a2 2
/*	$OpenBSD: uvm_device.c,v 1.8 2001/07/18 14:31:27 art Exp $	*/
/*	$NetBSD: uvm_device.c,v 1.18 1999/11/13 00:24:38 thorpej Exp $	*/
a70 1
struct uvm_object 	*udv_attach __P((void *, vm_prot_t, vaddr_t, vsize_t));
d76 4
a79 4
static boolean_t        udv_flush __P((struct uvm_object *, vaddr_t, 
					 vaddr_t, int));
static int		udv_asyncget __P((struct uvm_object *, vaddr_t,
					    int));
d376 1
a376 1
	vaddr_t start, stop;
d411 2
a412 1
	vaddr_t curr_offset, curr_va;
d453 1
a453 1
	curr_offset = (vaddr - entry->start) + entry->offset;	
d470 1
a470 1
		mdpgno = (*mapfn)(device, (int)curr_offset, access_type);
d513 1
a513 1
	vaddr_t offset;
@


1.8
log
@Sync in more from NetBSD.
Original commit message:
Patch from chuq for uvm r/w map oscillation bug.
Fixes the XalphaNetBSD slowdown.
@
text
@d1 2
a2 2
/*	$OpenBSD: uvm_device.c,v 1.7 2001/03/22 03:05:54 smart Exp $	*/
/*	$NetBSD: uvm_device.c,v 1.17 1999/10/24 16:29:23 ross Exp $	*/
d480 17
a496 2
		pmap_enter(ufi->orig_map->pmap, curr_va, paddr, mapprot, 0,
		    mapprot);
@


1.7
log
@Sync style, typo, and comments a little closer to NetBSD.  art@@ ok
@
text
@d1 2
a2 2
/*	$OpenBSD: uvm_device.c,v 1.6 2001/01/29 02:07:43 niklas Exp $	*/
/*	$NetBSD: uvm_device.c,v 1.16 1999/04/08 10:26:21 drochner Exp $	*/
d417 1
d476 1
d479 3
a481 3
		    ufi->orig_map->pmap, curr_va, (int)paddr, access_type);
		pmap_enter(ufi->orig_map->pmap, curr_va, paddr, access_type, 0,
		    access_type);
@


1.6
log
@$OpenBSD$
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_device.c,v 1.16 1999/04/08 10:26:21 drochner Exp $	*/
a479 1

d483 1
a483 1
	return(retval);
@


1.5
log
@Fix the NetBSD id strings.
@
text
@d1 1
@


1.4
log
@Change the pmap_enter api to pass down an argument that indicates
the access type that caused this mapping. This is to simplify pmaps
with mod/ref emulation (none for the moment) and in some cases speed
up pmap_is_{referenced,modified}.
At the same time, clean up some mappings that had too high protection.

XXX - the access type is incorrect in old vm, it's only used by uvm and MD code.
The actual use of this in pmap_enter implementations is not in this commit.
@
text
@d1 1
a1 1
/*	$NetBSD: uvm_device.c,v 1.15 1999/03/26 21:58:39 mycroft Exp $	*/
@


1.4.4.1
log
@Sync with -current
@
text
@d1 1
a1 1
/*	$NetBSD: uvm_device.c,v 1.16 1999/04/08 10:26:21 drochner Exp $	*/
@


1.4.4.2
log
@merge in approximately 2.9 into SMP branch
@
text
@a0 1
/*	$OpenBSD: uvm_device.c,v 1.7 2001/03/22 03:05:54 smart Exp $	*/
d479 1
d483 1
a483 1
	return (retval);
@


1.4.4.3
log
@Sync the SMP branch to something just after 3.0
@
text
@d1 2
a2 2
/*	$OpenBSD$	*/
/*	$NetBSD: uvm_device.c,v 1.22 2000/05/28 10:21:55 drochner Exp $	*/
d51 1
d71 1
d77 4
a80 4
static int		udv_asyncget __P((struct uvm_object *, voff_t,
				       int));
static boolean_t        udv_flush __P((struct uvm_object *, voff_t, voff_t,
				       int));
d99 1
d135 1
a135 1
	voff_t off;			/* used only for access check */
a155 9
	 * As long as the device d_mmap interface gets an "int"
	 * offset, we have to watch out not to overflow its
	 * numeric range. (assuming it will be interpreted as
	 * "unsigned")
	 */
	if (((off + size - 1) & (u_int)-1) != off + size - 1)
		return (0);

	/*
d377 1
a377 1
	voff_t start, stop;
d412 1
a412 2
	vaddr_t curr_va;
	int curr_offset;
a416 1
	vm_prot_t mapprot;
d452 1
a452 1
	curr_offset = (int)((vaddr - entry->start) + entry->offset);
d469 1
a469 1
		mdpgno = (*mapfn)(device, curr_offset, access_type);
a474 1
		mapprot = ufi->entry->protection;
d477 3
a479 18
		    ufi->orig_map->pmap, curr_va, (int)paddr, mapprot);
		if (pmap_enter(ufi->orig_map->pmap, curr_va, paddr,
		    mapprot, PMAP_CANFAIL | mapprot) != KERN_SUCCESS) {
			/*
			 * pmap_enter() didn't have the resource to
			 * enter this mapping.  Unlock everything,
			 * wait for the pagedaemon to free up some
			 * pages, and then tell uvm_fault() to start
			 * the fault again.
			 *
			 * XXX Needs some rethinking for the PGO_ALLPAGES
			 * XXX case.
			 */
			uvmfault_unlockall(ufi, ufi->entry->aref.ar_amap,
			    uobj, NULL);
			uvm_wait("udv_fault");
			return (VM_PAGER_REFAULT);
		}
d496 1
a496 1
	voff_t offset;
@


1.4.4.4
log
@merge in -current
@
text
@d2 1
a2 1
/*	$NetBSD: uvm_device.c,v 1.30 2000/11/25 06:27:59 chs Exp $	*/
d49 3
d75 2
d79 2
d92 7
d135 1
a135 1
	dev_t device = *((dev_t *)arg);
d137 1
a137 1
	paddr_t (*mapfn) __P((dev_t, off_t, int));
d148 2
a149 2
	    mapfn == (paddr_t (*) __P((dev_t, off_t, int))) enodev ||
	    mapfn == (paddr_t (*) __P((dev_t, off_t, int))) nullop)
d153 4
a156 1
	 * Negative offsets on the object are not allowed.
d158 2
a159 3

	if (off < 0)
		return(NULL);
d179 1
a179 1
	for (;;) {
d186 1
a186 1
		LIST_FOREACH(lcv, &udv_list, u_list) {
d220 1
a220 1

d235 1
a235 2
		MALLOC(udv, struct uvm_device *, sizeof(*udv), M_TEMP,
		       M_WAITOK);
d243 2
a244 1
		LIST_FOREACH(lcv, &udv_list, u_list) {
d250 1
a250 2
		 * did we lose a race to someone else?
		 * free our memory and retry.
d266 1
a266 1
		TAILQ_INIT(&udv->u_obj.memq);
d273 1
d275 3
a277 1
	}
d300 1
a300 1
		    uobj, uobj->uo_refs,0,0);
d316 1
a316 1
	struct uvm_device *udv = (struct uvm_device *)uobj;
a321 10
again:
	simple_lock(&uobj->vmobjlock);
	if (uobj->uo_refs > 1) {
		uobj->uo_refs--;
		simple_unlock(&uobj->vmobjlock);
		UVMHIST_LOG(maphist," <- done, uobj=0x%x, ref=%d", 
			  uobj,uobj->uo_refs,0,0);
		return;
	}
	KASSERT(uobj->uo_npages == 0 && TAILQ_EMPTY(&uobj->memq));
d323 38
a360 3
	/*
	 * is it being held?   if so, wait until others are done.
	 */
d362 5
a366 7
	simple_lock(&udv_lock);
	if (udv->u_flags & UVM_DEVICE_HOLD) {
		udv->u_flags |= UVM_DEVICE_WANTED;
		simple_unlock(&uobj->vmobjlock);
		UVM_UNLOCK_AND_WAIT(udv, &udv_lock, FALSE, "udv_detach",0);
		goto again;
	}
d368 1
a368 3
	/*
	 * got it!   nuke it now.
	 */
a369 6
	LIST_REMOVE(udv, u_list);
	if (udv->u_flags & UVM_DEVICE_WANTED)
		wakeup(udv);
	simple_unlock(&udv_lock);
	simple_unlock(&uobj->vmobjlock);
	FREE(udv, M_TEMP);
d371 1
d381 1
a381 2
static boolean_t
udv_flush(uobj, start, stop, flags)
d419 3
a421 3
	off_t curr_offset;
	paddr_t paddr, mdpgno;
	int lcv, retval;
d423 1
a423 1
	paddr_t (*mapfn) __P((dev_t, off_t, int));
d429 7
a449 1

a458 1

d460 1
a460 1
	curr_offset = entry->offset + (vaddr - entry->start);
d485 2
a486 2
		    "  MAPPING: device: pm=0x%x, va=0x%x, pa=0x%lx, at=%d",
		    ufi->orig_map->pmap, curr_va, paddr, mapprot);
d508 34
@


1.4.4.5
log
@Merge in -current
@
text
@d2 1
a2 1
/*	$NetBSD: uvm_device.c,v 1.36 2001/05/26 21:27:21 chs Exp $	*/
d60 1
a60 1
static struct simplelock udv_lock;
d70 1
a70 1
				       struct vm_page **, int, int, vm_fault_t,
d148 1
a148 1
	 *
d166 1
a166 1
		 * first, attempt to find it on the main list
d262 1
a262 1

d281 1
a281 1
	UVMHIST_LOG(maphist, "<- done (uobj=0x%x, ref = %d)",
d309 1
a309 1
		UVMHIST_LOG(maphist," <- done, uobj=0x%x, ref=%d",
d377 1
a377 1
	struct vm_page **pps;
d399 1
a399 1

d401 1
a401 1
		UVMHIST_LOG(maphist, "<- failed -- COW entry (etype=0x%x)",
d404 1
a404 1
		return(EIO);
d408 1
a408 1
	 * get device map function.
d425 1
a425 1

d430 1
a430 1
	retval = 0;
d441 1
a441 1
			retval = EIO;
d450 1
a450 1
		    mapprot, PMAP_CANFAIL | mapprot) != 0) {
a462 1
			pmap_update();	/* sync what we have so far */
d464 1
a464 1
			return (ERESTART);
a468 1
	pmap_update();
@


1.4.4.6
log
@Merge in trunk
@
text
@d2 1
a2 1
/*	$NetBSD: uvm_device.c,v 1.30 2000/11/25 06:27:59 chs Exp $	*/
d60 1
a60 1
static simple_lock_data_t udv_lock;
d70 1
a70 1
				       vm_page_t *, int, int, vm_fault_t,
d148 1
a148 1
	 * 
d166 1
a166 1
		 * first, attempt to find it on the main list 
d262 1
a262 1
	
d281 1
a281 1
	UVMHIST_LOG(maphist, "<- done (uobj=0x%x, ref = %d)", 
d309 1
a309 1
		UVMHIST_LOG(maphist," <- done, uobj=0x%x, ref=%d", 
d377 1
a377 1
	vm_page_t *pps;
d399 1
a399 1
	
d401 1
a401 1
		UVMHIST_LOG(maphist, "<- failed -- COW entry (etype=0x%x)", 
d404 1
a404 1
		return(VM_PAGER_ERROR);
d408 1
a408 1
	 * get device map function.   
d425 1
a425 1
	
d430 1
a430 1
	retval = VM_PAGER_OK;
d441 1
a441 1
			retval = VM_PAGER_ERROR;
d450 1
a450 1
		    mapprot, PMAP_CANFAIL | mapprot) != KERN_SUCCESS) {
d463 1
d465 1
a465 1
			return (VM_PAGER_REFAULT);
d470 1
@


1.4.4.7
log
@Merge in -current from roughly a week ago
@
text
@d66 4
a69 4
static void		udv_init(void);
static void             udv_reference(struct uvm_object *);
static void             udv_detach(struct uvm_object *);
static int		udv_fault(struct uvm_faultinfo *, vaddr_t,
d71 3
a73 3
				       vm_prot_t, int);
static boolean_t        udv_flush(struct uvm_object *, voff_t, voff_t,
				       int);
d123 1
a123 1
	paddr_t (*mapfn)(dev_t, off_t, int);
d134 2
a135 2
	    mapfn == (paddr_t (*)(dev_t, off_t, int)) enodev ||
	    mapfn == (paddr_t (*)(dev_t, off_t, int)) nullop)
d390 1
a390 1
	paddr_t (*mapfn)(dev_t, off_t, int);
@


1.4.4.8
log
@Sync the SMP branch with 3.3
@
text
@d450 1
a450 1
		    mapprot, PMAP_CANFAIL | mapprot) != 0) {
@


1.4.4.9
log
@Merge with the trunk
@
text
@a462 3

			/* sync what we have so far */
			pmap_update(ufi->orig_map->pmap);      
a468 1
	pmap_update(ufi->orig_map->pmap);
@


1.3
log
@sync with NetBSD from 1999.05.24 (there is a reason for this date)
 Mostly cleanups, but also a few improvements to pagedaemon for better
 handling of low memory and/or low swap conditions.
@
text
@d477 2
a478 1
		pmap_enter(ufi->orig_map->pmap, curr_va, paddr, access_type, 0);
@


1.2
log
@add OpenBSD tags
@
text
@d1 1
a1 7
/*	$OpenBSD$	*/
/*	$NetBSD: uvm_device.c,v 1.11 1998/11/19 05:23:26 mrg Exp $	*/

/*
 * XXXCDC: "ROUGH DRAFT" QUALITY UVM PRE-RELEASE FILE!   
 *	   >>>USE AT YOUR OWN RISK, WORK IS NOT FINISHED<<<
 */
d70 1
a70 1
struct uvm_object 	*udv_attach __P((void *, vm_prot_t));
a88 1
	udv_attach,
d131 1
a131 1
udv_attach(arg, accessprot)
d134 2
d153 14
@


1.1
log
@Import of uvm from NetBSD. Some local changes, some code disabled
@
text
@d1 1
@

