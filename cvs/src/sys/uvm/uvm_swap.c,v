head	1.141;
access;
symbols
	OPENBSD_6_1:1.140.0.4
	OPENBSD_6_1_BASE:1.140
	OPENBSD_6_0:1.139.0.4
	OPENBSD_6_0_BASE:1.139
	OPENBSD_5_9:1.139.0.2
	OPENBSD_5_9_BASE:1.139
	OPENBSD_5_8:1.135.0.4
	OPENBSD_5_8_BASE:1.135
	OPENBSD_5_7:1.134.0.2
	OPENBSD_5_7_BASE:1.134
	OPENBSD_5_6:1.128.0.4
	OPENBSD_5_6_BASE:1.128
	OPENBSD_5_5:1.124.0.4
	OPENBSD_5_5_BASE:1.124
	OPENBSD_5_4:1.115.0.2
	OPENBSD_5_4_BASE:1.115
	OPENBSD_5_3:1.110.0.2
	OPENBSD_5_3_BASE:1.110
	OPENBSD_5_2:1.109.0.2
	OPENBSD_5_2_BASE:1.109
	OPENBSD_5_1_BASE:1.104
	OPENBSD_5_1:1.104.0.4
	OPENBSD_5_0:1.104.0.2
	OPENBSD_5_0_BASE:1.104
	OPENBSD_4_9:1.100.0.2
	OPENBSD_4_9_BASE:1.100
	OPENBSD_4_8:1.94.0.2
	OPENBSD_4_8_BASE:1.94
	OPENBSD_4_7:1.92.0.2
	OPENBSD_4_7_BASE:1.92
	OPENBSD_4_6:1.92.0.4
	OPENBSD_4_6_BASE:1.92
	OPENBSD_4_5:1.85.0.2
	OPENBSD_4_5_BASE:1.85
	OPENBSD_4_4:1.82.0.2
	OPENBSD_4_4_BASE:1.82
	OPENBSD_4_3:1.76.0.2
	OPENBSD_4_3_BASE:1.76
	OPENBSD_4_2:1.72.0.2
	OPENBSD_4_2_BASE:1.72
	OPENBSD_4_1:1.67.0.2
	OPENBSD_4_1_BASE:1.67
	OPENBSD_4_0:1.65.0.2
	OPENBSD_4_0_BASE:1.65
	OPENBSD_3_9:1.61.0.2
	OPENBSD_3_9_BASE:1.61
	OPENBSD_3_8:1.60.0.4
	OPENBSD_3_8_BASE:1.60
	OPENBSD_3_7:1.60.0.2
	OPENBSD_3_7_BASE:1.60
	OPENBSD_3_6:1.58.0.4
	OPENBSD_3_6_BASE:1.58
	SMP_SYNC_A:1.58
	SMP_SYNC_B:1.58
	OPENBSD_3_5:1.58.0.2
	OPENBSD_3_5_BASE:1.58
	OPENBSD_3_4:1.56.0.2
	OPENBSD_3_4_BASE:1.56
	UBC_SYNC_A:1.55
	OPENBSD_3_3:1.55.0.2
	OPENBSD_3_3_BASE:1.55
	OPENBSD_3_2:1.54.0.2
	OPENBSD_3_2_BASE:1.54
	OPENBSD_3_1:1.51.0.2
	OPENBSD_3_1_BASE:1.51
	UBC_SYNC_B:1.55
	UBC:1.46.0.2
	UBC_BASE:1.46
	OPENBSD_3_0:1.36.0.2
	OPENBSD_3_0_BASE:1.36
	OPENBSD_2_9_BASE:1.26
	OPENBSD_2_9:1.26.0.2
	OPENBSD_2_8:1.20.0.2
	OPENBSD_2_8_BASE:1.20
	OPENBSD_2_7:1.17.0.2
	OPENBSD_2_7_BASE:1.17
	SMP:1.13.0.2
	SMP_BASE:1.13
	kame_19991208:1.11
	OPENBSD_2_6:1.9.0.2
	OPENBSD_2_6_BASE:1.9
	OPENBSD_2_5:1.2.0.2
	OPENBSD_2_5_BASE:1.2;
locks; strict;
comment	@ * @;


1.141
date	2017.04.09.18.14.39;	author dhill;	state Exp;
branches;
next	1.140;
commitid	r1B5dC4Dgny4umVd;

1.140
date	2016.09.15.02.00.18;	author dlg;	state Exp;
branches;
next	1.139;
commitid	RlO92XR575sygHqm;

1.139
date	2015.11.01.19.03.33;	author semarie;	state Exp;
branches;
next	1.138;
commitid	VKRkUfXZQNJ8UQeY;

1.138
date	2015.10.23.01.10.01;	author deraadt;	state Exp;
branches;
next	1.137;
commitid	KqW7FHnhlWUon4U2;

1.137
date	2015.09.06.17.06.43;	author deraadt;	state Exp;
branches;
next	1.136;
commitid	hRJP2P5vaejV6wgP;

1.136
date	2015.08.23.04.58.37;	author deraadt;	state Exp;
branches;
next	1.135;
commitid	lCtiED4dlOtEWDHm;

1.135
date	2015.05.04.10.21.15;	author dlg;	state Exp;
branches;
next	1.134;
commitid	dd7E1ky1UwQRrLhI;

1.134
date	2015.01.27.03.17.37;	author dlg;	state Exp;
branches;
next	1.133;
commitid	MyKPm9Q3dQu92BiX;

1.133
date	2015.01.13.02.24.26;	author dlg;	state Exp;
branches;
next	1.132;
commitid	6IMGN5OMfnhqKzcc;

1.132
date	2014.12.23.04.47.30;	author tedu;	state Exp;
branches;
next	1.131;
commitid	ApOppvPa858v3c88;

1.131
date	2014.11.18.02.37.31;	author tedu;	state Exp;
branches;
next	1.130;
commitid	Z1vcFtHO8wRH0yRt;

1.130
date	2014.11.17.00.15.38;	author tedu;	state Exp;
branches;
next	1.129;
commitid	RNxnJJuvDs1AuJsK;

1.129
date	2014.11.13.03.56.51;	author tedu;	state Exp;
branches;
next	1.128;
commitid	GvoaXsptw10wVpzO;

1.128
date	2014.07.12.18.44.01;	author tedu;	state Exp;
branches;
next	1.127;
commitid	bDGgAR6yEQVcVl5u;

1.127
date	2014.05.08.20.08.50;	author kettenis;	state Exp;
branches;
next	1.126;

1.126
date	2014.04.29.09.55.28;	author kettenis;	state Exp;
branches;
next	1.125;

1.125
date	2014.04.13.23.14.15;	author tedu;	state Exp;
branches;
next	1.124;

1.124
date	2013.11.24.15.44.26;	author jsing;	state Exp;
branches;
next	1.123;

1.123
date	2013.11.21.00.13.33;	author dlg;	state Exp;
branches;
next	1.122;

1.122
date	2013.11.20.23.57.07;	author miod;	state Exp;
branches;
next	1.121;

1.121
date	2013.11.06.07.46.31;	author dlg;	state Exp;
branches;
next	1.120;

1.120
date	2013.11.05.06.02.45;	author deraadt;	state Exp;
branches;
next	1.119;

1.119
date	2013.11.04.19.42.47;	author deraadt;	state Exp;
branches;
next	1.118;

1.118
date	2013.11.04.19.41.17;	author deraadt;	state Exp;
branches;
next	1.117;

1.117
date	2013.11.02.04.14.13;	author deraadt;	state Exp;
branches;
next	1.116;

1.116
date	2013.11.02.00.08.17;	author krw;	state Exp;
branches;
next	1.115;

1.115
date	2013.06.11.16.42.19;	author deraadt;	state Exp;
branches;
next	1.114;

1.114
date	2013.05.30.15.17.59;	author tedu;	state Exp;
branches;
next	1.113;

1.113
date	2013.05.03.13.57.46;	author florian;	state Exp;
branches;
next	1.112;

1.112
date	2013.04.17.16.22.24;	author florian;	state Exp;
branches;
next	1.111;

1.111
date	2013.03.28.03.39.22;	author deraadt;	state Exp;
branches;
next	1.110;

1.110
date	2012.09.20.20.20.11;	author miod;	state Exp;
branches;
next	1.109;

1.109
date	2012.07.12.10.39.53;	author mlarkin;	state Exp;
branches;
next	1.108;

1.108
date	2012.07.11.16.00.15;	author mlarkin;	state Exp;
branches;
next	1.107;

1.107
date	2012.07.11.12.31.28;	author mlarkin;	state Exp;
branches;
next	1.106;

1.106
date	2012.07.11.10.07.40;	author mlarkin;	state Exp;
branches;
next	1.105;

1.105
date	2012.06.14.15.53.38;	author jasper;	state Exp;
branches;
next	1.104;

1.104
date	2011.07.04.20.35.35;	author deraadt;	state Exp;
branches;
next	1.103;

1.103
date	2011.07.03.18.34.14;	author oga;	state Exp;
branches;
next	1.102;

1.102
date	2011.04.17.19.19.47;	author deraadt;	state Exp;
branches;
next	1.101;

1.101
date	2011.04.04.11.29.39;	author thib;	state Exp;
branches;
next	1.100;

1.100
date	2010.12.21.20.14.44;	author thib;	state Exp;
branches;
next	1.99;

1.99
date	2010.12.04.05.18.10;	author jsing;	state Exp;
branches;
next	1.98;

1.98
date	2010.09.26.12.53.27;	author thib;	state Exp;
branches;
next	1.97;

1.97
date	2010.09.10.16.34.09;	author thib;	state Exp;
branches;
next	1.96;

1.96
date	2010.09.06.23.44.11;	author thib;	state Exp;
branches;
next	1.95;

1.95
date	2010.09.06.16.33.41;	author thib;	state Exp;
branches;
next	1.94;

1.94
date	2010.07.03.20.28.51;	author miod;	state Exp;
branches;
next	1.93;

1.93
date	2010.07.01.19.48.05;	author oga;	state Exp;
branches;
next	1.92;

1.92
date	2009.06.17.00.13.59;	author oga;	state Exp;
branches;
next	1.91;

1.91
date	2009.06.16.00.11.29;	author oga;	state Exp;
branches;
next	1.90;

1.90
date	2009.06.04.02.56.14;	author oga;	state Exp;
branches;
next	1.89;

1.89
date	2009.06.03.22.09.30;	author thib;	state Exp;
branches;
next	1.88;

1.88
date	2009.05.08.13.50.15;	author ariane;	state Exp;
branches;
next	1.87;

1.87
date	2009.03.23.22.07.41;	author oga;	state Exp;
branches;
next	1.86;

1.86
date	2009.03.20.15.19.04;	author oga;	state Exp;
branches;
next	1.85;

1.85
date	2009.01.25.17.30.49;	author miod;	state Exp;
branches;
next	1.84;

1.84
date	2008.09.16.18.52.52;	author chl;	state Exp;
branches;
next	1.83;

1.83
date	2008.09.13.12.33.52;	author chl;	state Exp;
branches;
next	1.82;

1.82
date	2008.06.12.06.58.40;	author deraadt;	state Exp;
branches;
next	1.81;

1.81
date	2008.06.11.12.35.47;	author deraadt;	state Exp;
branches;
next	1.80;

1.80
date	2008.06.10.20.50.23;	author beck;	state Exp;
branches;
next	1.79;

1.79
date	2008.06.02.15.42.21;	author miod;	state Exp;
branches;
next	1.78;

1.78
date	2008.04.12.20.37.36;	author miod;	state Exp;
branches;
next	1.77;

1.77
date	2008.04.12.20.36.38;	author miod;	state Exp;
branches;
next	1.76;

1.76
date	2007.12.18.11.05.52;	author thib;	state Exp;
branches;
next	1.75;

1.75
date	2007.11.27.18.01.02;	author deraadt;	state Exp;
branches;
next	1.74;

1.74
date	2007.10.29.17.08.08;	author chl;	state Exp;
branches;
next	1.73;

1.73
date	2007.09.07.15.00.20;	author art;	state Exp;
branches;
next	1.72;

1.72
date	2007.06.18.21.51.15;	author pedro;	state Exp;
branches;
next	1.71;

1.71
date	2007.06.06.17.15.14;	author deraadt;	state Exp;
branches;
next	1.70;

1.70
date	2007.06.01.07.35.35;	author deraadt;	state Exp;
branches;
next	1.69;

1.69
date	2007.05.29.00.17.33;	author thib;	state Exp;
branches;
next	1.68;

1.68
date	2007.04.13.18.57.49;	author art;	state Exp;
branches;
next	1.67;

1.67
date	2007.01.12.07.41.31;	author art;	state Exp;
branches;
next	1.66;

1.66
date	2006.10.03.19.49.06;	author pedro;	state Exp;
branches;
next	1.65;

1.65
date	2006.07.31.11.51.29;	author mickey;	state Exp;
branches;
next	1.64;

1.64
date	2006.07.26.23.15.55;	author mickey;	state Exp;
branches;
next	1.63;

1.63
date	2006.07.13.22.51.26;	author deraadt;	state Exp;
branches;
next	1.62;

1.62
date	2006.06.21.16.20.05;	author mickey;	state Exp;
branches;
next	1.61;

1.61
date	2005.11.19.02.18.02;	author pedro;	state Exp;
branches;
next	1.60;

1.60
date	2004.12.26.21.22.14;	author miod;	state Exp;
branches;
next	1.59;

1.59
date	2004.09.23.06.31.35;	author tedu;	state Exp;
branches;
next	1.58;

1.58
date	2003.12.10.07.34.03;	author itojun;	state Exp;
branches;
next	1.57;

1.57
date	2003.12.02.01.52.32;	author mickey;	state Exp;
branches;
next	1.56;

1.56
date	2003.08.15.20.32.21;	author tedu;	state Exp;
branches;
next	1.55;

1.55
date	2002.10.12.01.09.45;	author krw;	state Exp;
branches;
next	1.54;

1.54
date	2002.07.02.19.38.55;	author nate;	state Exp;
branches;
next	1.53;

1.53
date	2002.05.24.13.10.53;	author art;	state Exp;
branches;
next	1.52;

1.52
date	2002.05.24.08.58.41;	author art;	state Exp;
branches;
next	1.51;

1.51
date	2002.03.14.01.27.19;	author millert;	state Exp;
branches;
next	1.50;

1.50
date	2002.01.28.03.16.27;	author art;	state Exp;
branches;
next	1.49;

1.49
date	2002.01.23.00.39.48;	author art;	state Exp;
branches;
next	1.48;

1.48
date	2002.01.02.22.23.25;	author miod;	state Exp;
branches;
next	1.47;

1.47
date	2001.12.19.08.58.07;	author art;	state Exp;
branches;
next	1.46;

1.46
date	2001.12.04.23.22.42;	author art;	state Exp;
branches
	1.46.2.1;
next	1.45;

1.45
date	2001.11.30.05.45.33;	author csapuntz;	state Exp;
branches;
next	1.44;

1.44
date	2001.11.28.19.28.15;	author art;	state Exp;
branches;
next	1.43;

1.43
date	2001.11.28.13.47.40;	author art;	state Exp;
branches;
next	1.42;

1.42
date	2001.11.27.05.27.12;	author art;	state Exp;
branches;
next	1.41;

1.41
date	2001.11.15.23.15.15;	author art;	state Exp;
branches;
next	1.40;

1.40
date	2001.11.12.01.26.10;	author art;	state Exp;
branches;
next	1.39;

1.39
date	2001.11.10.18.42.32;	author art;	state Exp;
branches;
next	1.38;

1.38
date	2001.11.07.02.55.50;	author art;	state Exp;
branches;
next	1.37;

1.37
date	2001.11.06.01.35.04;	author art;	state Exp;
branches;
next	1.36;

1.36
date	2001.09.05.19.22.23;	author deraadt;	state Exp;
branches;
next	1.35;

1.35
date	2001.08.31.15.26.18;	author mickey;	state Exp;
branches;
next	1.34;

1.34
date	2001.08.11.10.57.22;	author art;	state Exp;
branches;
next	1.33;

1.33
date	2001.08.06.22.34.44;	author mickey;	state Exp;
branches;
next	1.32;

1.32
date	2001.07.31.13.34.46;	author art;	state Exp;
branches;
next	1.31;

1.31
date	2001.07.26.19.37.13;	author art;	state Exp;
branches;
next	1.30;

1.30
date	2001.07.25.14.47.59;	author art;	state Exp;
branches;
next	1.29;

1.29
date	2001.07.18.14.28.01;	author art;	state Exp;
branches;
next	1.28;

1.28
date	2001.07.05.10.00.49;	author art;	state Exp;
branches;
next	1.27;

1.27
date	2001.06.23.15.26.29;	author art;	state Exp;
branches;
next	1.26;

1.26
date	2001.03.26.05.37.03;	author aaron;	state Exp;
branches;
next	1.25;

1.25
date	2001.03.09.03.13.47;	author deraadt;	state Exp;
branches;
next	1.24;

1.24
date	2001.03.08.15.21.37;	author smart;	state Exp;
branches;
next	1.23;

1.23
date	2001.02.24.19.07.12;	author csapuntz;	state Exp;
branches;
next	1.22;

1.22
date	2001.01.29.02.07.49;	author niklas;	state Exp;
branches;
next	1.21;

1.21
date	2001.01.25.03.50.54;	author todd;	state Exp;
branches;
next	1.20;

1.20
date	2000.09.07.20.15.28;	author art;	state Exp;
branches;
next	1.19;

1.19
date	2000.05.27.21.06.08;	author provos;	state Exp;
branches;
next	1.18;

1.18
date	2000.05.26.15.18.29;	author provos;	state Exp;
branches;
next	1.17;

1.17
date	2000.03.21.17.51.00;	author provos;	state Exp;
branches;
next	1.16;

1.16
date	2000.03.18.20.51.32;	author provos;	state Exp;
branches;
next	1.15;

1.15
date	2000.03.18.19.34.24;	author provos;	state Exp;
branches;
next	1.14;

1.14
date	2000.03.15.15.50.21;	author art;	state Exp;
branches;
next	1.13;

1.13
date	2000.01.05.08.49.06;	author art;	state Exp;
branches
	1.13.2.1;
next	1.12;

1.12
date	99.12.30.18.21.55;	author provos;	state Exp;
branches;
next	1.11;

1.11
date	99.12.02.20.42.10;	author art;	state Exp;
branches;
next	1.10;

1.10
date	99.11.26.10.22.07;	author art;	state Exp;
branches;
next	1.9;

1.9
date	99.08.23.08.13.25;	author art;	state Exp;
branches;
next	1.8;

1.8
date	99.07.08.00.54.28;	author deraadt;	state Exp;
branches;
next	1.7;

1.7
date	99.06.24.11.37.02;	author art;	state Exp;
branches;
next	1.6;

1.6
date	99.06.17.15.40.54;	author art;	state Exp;
branches;
next	1.5;

1.5
date	99.06.04.00.23.17;	author art;	state Exp;
branches;
next	1.4;

1.4
date	99.06.04.00.15.42;	author art;	state Exp;
branches;
next	1.3;

1.3
date	99.06.02.13.23.22;	author mickey;	state Exp;
branches;
next	1.2;

1.2
date	99.02.26.05.32.08;	author art;	state Exp;
branches;
next	1.1;

1.1
date	99.02.26.01.30.18;	author art;	state Exp;
branches;
next	;

1.13.2.1
date	2000.03.24.09.09.52;	author niklas;	state Exp;
branches;
next	1.13.2.2;

1.13.2.2
date	2001.05.14.22.47.48;	author niklas;	state Exp;
branches;
next	1.13.2.3;

1.13.2.3
date	2001.07.04.11.01.09;	author niklas;	state Exp;
branches;
next	1.13.2.4;

1.13.2.4
date	2001.10.31.03.32.14;	author nate;	state Exp;
branches;
next	1.13.2.5;

1.13.2.5
date	2001.11.13.23.02.31;	author niklas;	state Exp;
branches;
next	1.13.2.6;

1.13.2.6
date	2001.12.05.01.23.58;	author niklas;	state Exp;
branches;
next	1.13.2.7;

1.13.2.7
date	2002.03.06.02.17.14;	author niklas;	state Exp;
branches;
next	1.13.2.8;

1.13.2.8
date	2002.03.28.14.54.27;	author niklas;	state Exp;
branches;
next	1.13.2.9;

1.13.2.9
date	2003.03.28.00.08.48;	author niklas;	state Exp;
branches;
next	1.13.2.10;

1.13.2.10
date	2004.02.19.11.01.45;	author niklas;	state Exp;
branches;
next	;

1.46.2.1
date	2002.01.31.22.55.51;	author niklas;	state Exp;
branches;
next	1.46.2.2;

1.46.2.2
date	2002.02.02.03.28.27;	author art;	state Exp;
branches;
next	1.46.2.3;

1.46.2.3
date	2002.06.11.03.33.04;	author art;	state Exp;
branches;
next	1.46.2.4;

1.46.2.4
date	2002.10.29.00.36.50;	author art;	state Exp;
branches;
next	1.46.2.5;

1.46.2.5
date	2002.11.04.18.02.33;	author art;	state Exp;
branches;
next	;


desc
@@


1.141
log
@Convert a malloc(9) to mallocarray(9)

ok deraadt@@
@
text
@/*	$OpenBSD: uvm_swap.c,v 1.140 2016/09/15 02:00:18 dlg Exp $	*/
/*	$NetBSD: uvm_swap.c,v 1.40 2000/11/17 11:39:39 mrg Exp $	*/

/*
 * Copyright (c) 1995, 1996, 1997 Matthew R. Green
 * All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. The name of the author may not be used to endorse or promote products
 *    derived from this software without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR
 * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
 * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
 * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,
 * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,
 * BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
 * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED
 * AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
 *
 * from: NetBSD: vm_swap.c,v 1.52 1997/12/02 13:47:37 pk Exp
 * from: Id: uvm_swap.c,v 1.1.2.42 1998/02/02 20:38:06 chuck Exp
 */

#include <sys/param.h>
#include <sys/systm.h>
#include <sys/buf.h>
#include <sys/conf.h>
#include <sys/proc.h>
#include <sys/namei.h>
#include <sys/disklabel.h>
#include <sys/errno.h>
#include <sys/kernel.h>
#include <sys/malloc.h>
#include <sys/vnode.h>
#include <sys/file.h>
#include <sys/extent.h>
#include <sys/mount.h>
#include <sys/pool.h>
#include <sys/syscallargs.h>
#include <sys/swap.h>
#include <sys/disk.h>
#include <sys/task.h>
#include <sys/pledge.h>
#if defined(NFSCLIENT)
#include <sys/socket.h>
#include <sys/domain.h>
#include <netinet/in.h>
#include <nfs/nfsproto.h>
#include <nfs/nfsdiskless.h>
#endif

#include <uvm/uvm.h>
#ifdef UVM_SWAP_ENCRYPT
#include <uvm/uvm_swap_encrypt.h>
#endif

#include <sys/specdev.h>

#include "vnd.h"

/*
 * uvm_swap.c: manage configuration and i/o to swap space.
 */

/*
 * swap space is managed in the following way:
 *
 * each swap partition or file is described by a "swapdev" structure.
 * each "swapdev" structure contains a "swapent" structure which contains
 * information that is passed up to the user (via system calls).
 *
 * each swap partition is assigned a "priority" (int) which controls
 * swap partition usage.
 *
 * the system maintains a global data structure describing all swap
 * partitions/files.   there is a sorted LIST of "swappri" structures
 * which describe "swapdev"'s at that priority.   this LIST is headed
 * by the "swap_priority" global var.    each "swappri" contains a 
 * TAILQ of "swapdev" structures at that priority.
 *
 * locking:
 *  - swap_syscall_lock (sleep lock): this lock serializes the swapctl
 *    system call and prevents the swap priority list from changing
 *    while we are in the middle of a system call (e.g. SWAP_STATS).
 *
 * each swap device has the following info:
 *  - swap device in use (could be disabled, preventing future use)
 *  - swap enabled (allows new allocations on swap)
 *  - map info in /dev/drum
 *  - vnode pointer
 * for swap files only:
 *  - block size
 *  - max byte count in buffer
 *  - buffer
 *  - credentials to use when doing i/o to file
 *
 * userland controls and configures swap with the swapctl(2) system call.
 * the sys_swapctl performs the following operations:
 *  [1] SWAP_NSWAP: returns the number of swap devices currently configured
 *  [2] SWAP_STATS: given a pointer to an array of swapent structures 
 *	(passed in via "arg") of a size passed in via "misc" ... we load
 *	the current swap config into the array.
 *  [3] SWAP_ON: given a pathname in arg (could be device or file) and a
 *	priority in "misc", start swapping on it.
 *  [4] SWAP_OFF: as SWAP_ON, but stops swapping to a device
 *  [5] SWAP_CTL: changes the priority of a swap device (new priority in
 *	"misc")
 */

/*
 * swapdev: describes a single swap partition/file
 *
 * note the following should be true:
 * swd_inuse <= swd_nblks  [number of blocks in use is <= total blocks]
 * swd_nblks <= swd_mapsize [because mapsize includes disklabel]
 */
struct swapdev {
	struct swapent	swd_se;
#define	swd_dev		swd_se.se_dev		/* device id */
#define	swd_flags	swd_se.se_flags		/* flags:inuse/enable/fake */
#define	swd_priority	swd_se.se_priority	/* our priority */
#define	swd_inuse	swd_se.se_inuse		/* blocks used */
#define	swd_nblks	swd_se.se_nblks		/* total blocks */
	char			*swd_path;	/* saved pathname of device */
	int			swd_pathlen;	/* length of pathname */
	int			swd_npages;	/* #pages we can use */
	int			swd_npginuse;	/* #pages in use */
	int			swd_npgbad;	/* #pages bad */
	int			swd_drumoffset;	/* page0 offset in drum */
	int			swd_drumsize;	/* #pages in drum */
	struct extent		*swd_ex;	/* extent for this swapdev */
	char			swd_exname[12];	/* name of extent above */
	struct vnode		*swd_vp;	/* backing vnode */
	TAILQ_ENTRY(swapdev)	swd_next;	/* priority tailq */

	int			swd_bsize;	/* blocksize (bytes) */
	int			swd_maxactive;	/* max active i/o reqs */
	int			swd_active;	/* # of active i/o reqs */
	struct bufq		swd_bufq;
	struct ucred		*swd_cred;	/* cred for file access */
#ifdef UVM_SWAP_ENCRYPT
#define SWD_KEY_SHIFT		7		/* One key per 0.5 MByte */
#define SWD_KEY(x,y)		&((x)->swd_keys[((y) - (x)->swd_drumoffset) >> SWD_KEY_SHIFT])
#define	SWD_KEY_SIZE(x)	(((x) + (1 << SWD_KEY_SHIFT) - 1) >> SWD_KEY_SHIFT)

#define SWD_DCRYPT_SHIFT	5
#define SWD_DCRYPT_BITS		32
#define SWD_DCRYPT_MASK		(SWD_DCRYPT_BITS - 1)
#define SWD_DCRYPT_OFF(x)	((x) >> SWD_DCRYPT_SHIFT)
#define SWD_DCRYPT_BIT(x)	((x) & SWD_DCRYPT_MASK)
#define SWD_DCRYPT_SIZE(x)	(SWD_DCRYPT_OFF((x) + SWD_DCRYPT_MASK) * sizeof(u_int32_t))
	u_int32_t		*swd_decrypt;	/* bitmap for decryption */
	struct swap_key		*swd_keys;	/* keys for different parts */
#endif
};

/*
 * swap device priority entry; the list is kept sorted on `spi_priority'.
 */
struct swappri {
	int			spi_priority;     /* priority */
	TAILQ_HEAD(spi_swapdev, swapdev)	spi_swapdev;
	/* tailq of swapdevs at this priority */
	LIST_ENTRY(swappri)	spi_swappri;      /* global list of pri's */
};

/*
 * The following two structures are used to keep track of data transfers
 * on swap devices associated with regular files.
 * NOTE: this code is more or less a copy of vnd.c; we use the same
 * structure names here to ease porting..
 */
struct vndxfer {
	struct buf	*vx_bp;		/* Pointer to parent buffer */
	struct swapdev	*vx_sdp;
	int		vx_error;
	int		vx_pending;	/* # of pending aux buffers */
	int		vx_flags;
#define VX_BUSY		1
#define VX_DEAD		2
};

struct vndbuf {
	struct buf	vb_buf;
	struct vndxfer	*vb_vnx;
	struct task	vb_task;
};

/*
 * We keep a of pool vndbuf's and vndxfer structures.
 */
struct pool vndxfer_pool;
struct pool vndbuf_pool;


/*
 * local variables
 */
struct extent *swapmap;		/* controls the mapping of /dev/drum */

/* list of all active swap devices [by priority] */
LIST_HEAD(swap_priority, swappri);
struct swap_priority swap_priority;

/* locks */
struct rwlock swap_syscall_lock = RWLOCK_INITIALIZER("swplk");

/*
 * prototypes
 */
void		 swapdrum_add(struct swapdev *, int);
struct swapdev	*swapdrum_getsdp(int);

struct swapdev	*swaplist_find(struct vnode *, int);
void		 swaplist_insert(struct swapdev *, 
 				     struct swappri *, int);
void		 swaplist_trim(void);

int swap_on(struct proc *, struct swapdev *);
int swap_off(struct proc *, struct swapdev *);

void sw_reg_strategy(struct swapdev *, struct buf *, int);
void sw_reg_iodone(struct buf *);
void sw_reg_iodone_internal(void *);
void sw_reg_start(struct swapdev *);

int uvm_swap_io(struct vm_page **, int, int, int);

void swapmount(void);
boolean_t uvm_swap_allocpages(struct vm_page **, int);

#ifdef UVM_SWAP_ENCRYPT
/* for swap encrypt */
void uvm_swap_markdecrypt(struct swapdev *, int, int, int);
boolean_t uvm_swap_needdecrypt(struct swapdev *, int);
void uvm_swap_initcrypt(struct swapdev *, int);
#endif

/*
 * uvm_swap_init: init the swap system data structures and locks
 *
 * => called at boot time from init_main.c after the filesystems
 *	are brought up (which happens after uvm_init())
 */
void
uvm_swap_init(void)
{
	/*
	 * first, init the swap list, its counter, and its lock.
	 * then get a handle on the vnode for /dev/drum by using
	 * the its dev_t number ("swapdev", from MD conf.c).
	 */
	LIST_INIT(&swap_priority);
	uvmexp.nswapdev = 0;

	if (!swapdev_vp && bdevvp(swapdev, &swapdev_vp))
		panic("uvm_swap_init: can't get vnode for swap device");

	/*
	 * create swap block extent to map /dev/drum. The extent spans
	 * 1 to INT_MAX allows 2 gigablocks of swap space.  Note that
	 * block 0 is reserved (used to indicate an allocation failure,
	 * or no allocation).
	 */
	swapmap = extent_create("swapmap", 1, INT_MAX,
				M_VMSWAP, 0, 0, EX_NOWAIT);
	if (swapmap == 0)
		panic("uvm_swap_init: extent_create failed");

	/* allocate pools for structures used for swapping to files. */
	pool_init(&vndxfer_pool, sizeof(struct vndxfer), 0, IPL_BIO, 0,
	    "swp vnx", NULL);
	pool_init(&vndbuf_pool, sizeof(struct vndbuf), 0, IPL_BIO, 0,
	    "swp vnd", NULL);

	/* Setup the initial swap partition */
	swapmount();
}

#ifdef UVM_SWAP_ENCRYPT
void
uvm_swap_initcrypt_all(void)
{
	struct swapdev *sdp;
	struct swappri *spp;
	int npages;


	LIST_FOREACH(spp, &swap_priority, spi_swappri) {
		TAILQ_FOREACH(sdp, &spp->spi_swapdev, swd_next) {
			if (sdp->swd_decrypt == NULL) {
				npages = dbtob((uint64_t)sdp->swd_nblks) >>
				    PAGE_SHIFT;
				uvm_swap_initcrypt(sdp, npages);
			}
		}
	}
}

void
uvm_swap_initcrypt(struct swapdev *sdp, int npages)
{
	/*
	 * keep information if a page needs to be decrypted when we get it
	 * from the swap device.
	 * We cannot chance a malloc later, if we are doing ASYNC puts,
	 * we may not call malloc with M_WAITOK.  This consumes only
	 * 8KB memory for a 256MB swap partition.
	 */
	sdp->swd_decrypt = malloc(SWD_DCRYPT_SIZE(npages), M_VMSWAP,
	    M_WAITOK|M_ZERO);
	sdp->swd_keys = mallocarray(SWD_KEY_SIZE(npages),
	    sizeof(struct swap_key), M_VMSWAP, M_WAITOK|M_ZERO);
}

#endif /* UVM_SWAP_ENCRYPT */

boolean_t
uvm_swap_allocpages(struct vm_page **pps, int npages)
{
	struct pglist	pgl;
	int i;
	boolean_t fail;

	/* Estimate if we will succeed */
	uvm_lock_fpageq();

	fail = uvmexp.free - npages < uvmexp.reserve_kernel;

	uvm_unlock_fpageq();

	if (fail)
		return FALSE;

	TAILQ_INIT(&pgl);
	if (uvm_pglistalloc(npages * PAGE_SIZE, dma_constraint.ucr_low,
	    dma_constraint.ucr_high, 0, 0, &pgl, npages, UVM_PLA_NOWAIT))
		return FALSE;

	for (i = 0; i < npages; i++) {
		pps[i] = TAILQ_FIRST(&pgl);
		/* *sigh* */
		atomic_setbits_int(&pps[i]->pg_flags, PG_BUSY);
		TAILQ_REMOVE(&pgl, pps[i], pageq);
	}

	return TRUE;
}

void
uvm_swap_freepages(struct vm_page **pps, int npages)
{
	int i;

	uvm_lock_pageq();
	for (i = 0; i < npages; i++)
		uvm_pagefree(pps[i]);
	uvm_unlock_pageq();
}

#ifdef UVM_SWAP_ENCRYPT
/*
 * Mark pages on the swap device for later decryption
 */

void
uvm_swap_markdecrypt(struct swapdev *sdp, int startslot, int npages,
    int decrypt)
{
	int pagestart, i;
	int off, bit;

	if (!sdp)
		return;

	pagestart = startslot - sdp->swd_drumoffset;
	for (i = 0; i < npages; i++, pagestart++) {
		off = SWD_DCRYPT_OFF(pagestart);
		bit = SWD_DCRYPT_BIT(pagestart);
		if (decrypt)
			/* pages read need decryption */
			sdp->swd_decrypt[off] |= 1 << bit;
		else
			/* pages read do not need decryption */
			sdp->swd_decrypt[off] &= ~(1 << bit);
	}
}

/*
 * Check if the page that we got from disk needs to be decrypted
 */

boolean_t
uvm_swap_needdecrypt(struct swapdev *sdp, int off)
{
	if (!sdp)
		return FALSE;

	off -= sdp->swd_drumoffset;
	return sdp->swd_decrypt[SWD_DCRYPT_OFF(off)] & (1 << SWD_DCRYPT_BIT(off)) ?
		TRUE : FALSE;
}

void
uvm_swap_finicrypt_all(void)
{
	struct swapdev *sdp;
	struct swappri *spp;
	struct swap_key *key;
	unsigned int nkeys;

	LIST_FOREACH(spp, &swap_priority, spi_swappri) {
		TAILQ_FOREACH(sdp, &spp->spi_swapdev, swd_next) {
			if (sdp->swd_decrypt == NULL)
				continue;

			nkeys = dbtob((uint64_t)sdp->swd_nblks) >> PAGE_SHIFT;
			key = sdp->swd_keys + (SWD_KEY_SIZE(nkeys) - 1);
			do {
				if (key->refcount != 0)
					swap_key_delete(key);
			} while (key-- != sdp->swd_keys);
		}
	}
}
#endif /* UVM_SWAP_ENCRYPT */

/*
 * swaplist functions: functions that operate on the list of swap
 * devices on the system.
 */

/*
 * swaplist_insert: insert swap device "sdp" into the global list
 *
 * => caller must hold both swap_syscall_lock and uvm.swap_data_lock
 * => caller must provide a newly malloc'd swappri structure (we will
 *	FREE it if we don't need it... this it to prevent malloc blocking
 *	here while adding swap)
 */
void
swaplist_insert(struct swapdev *sdp, struct swappri *newspp, int priority)
{
	struct swappri *spp, *pspp;

	/*
	 * find entry at or after which to insert the new device.
	 */
	for (pspp = NULL, spp = LIST_FIRST(&swap_priority); spp != NULL;
	     spp = LIST_NEXT(spp, spi_swappri)) {
		if (priority <= spp->spi_priority)
			break;
		pspp = spp;
	}

	/*
	 * new priority?
	 */
	if (spp == NULL || spp->spi_priority != priority) {
		spp = newspp;  /* use newspp! */

		spp->spi_priority = priority;
		TAILQ_INIT(&spp->spi_swapdev);

		if (pspp)
			LIST_INSERT_AFTER(pspp, spp, spi_swappri);
		else
			LIST_INSERT_HEAD(&swap_priority, spp, spi_swappri);
	} else {
	  	/* we don't need a new priority structure, free it */
		free(newspp, M_VMSWAP, sizeof(*newspp));
	}

	/*
	 * priority found (or created).   now insert on the priority's
	 * tailq list and bump the total number of swapdevs.
	 */
	sdp->swd_priority = priority;
	TAILQ_INSERT_TAIL(&spp->spi_swapdev, sdp, swd_next);
	uvmexp.nswapdev++;
}

/*
 * swaplist_find: find and optionally remove a swap device from the
 *	global list.
 *
 * => caller must hold both swap_syscall_lock and uvm.swap_data_lock
 * => we return the swapdev we found (and removed)
 */
struct swapdev *
swaplist_find(struct vnode *vp, boolean_t remove)
{
	struct swapdev *sdp;
	struct swappri *spp;

	/*
	 * search the lists for the requested vp
	 */
	LIST_FOREACH(spp, &swap_priority, spi_swappri) {
		TAILQ_FOREACH(sdp, &spp->spi_swapdev, swd_next) {
			if (sdp->swd_vp != vp)
				continue;
			if (remove) {
				TAILQ_REMOVE(&spp->spi_swapdev, sdp, swd_next);
				uvmexp.nswapdev--;
			}
			return (sdp);
		}
	}
	return (NULL);
}


/*
 * swaplist_trim: scan priority list for empty priority entries and kill
 *	them.
 *
 * => caller must hold both swap_syscall_lock and uvm.swap_data_lock
 */
void
swaplist_trim(void)
{
	struct swappri *spp, *nextspp;

	LIST_FOREACH_SAFE(spp, &swap_priority, spi_swappri, nextspp) {
		if (!TAILQ_EMPTY(&spp->spi_swapdev))
			continue;
		LIST_REMOVE(spp, spi_swappri);
		free(spp, M_VMSWAP, sizeof(*spp));
	}
}

/*
 * swapdrum_add: add a "swapdev"'s blocks into /dev/drum's area.
 *
 * => caller must hold swap_syscall_lock
 * => uvm.swap_data_lock should be unlocked (we may sleep)
 */
void
swapdrum_add(struct swapdev *sdp, int npages)
{
	u_long result;

	if (extent_alloc(swapmap, npages, EX_NOALIGN, 0, EX_NOBOUNDARY,
	    EX_WAITOK, &result))
		panic("swapdrum_add");

	sdp->swd_drumoffset = result;
	sdp->swd_drumsize = npages;
}

/*
 * swapdrum_getsdp: given a page offset in /dev/drum, convert it back
 *	to the "swapdev" that maps that section of the drum.
 *
 * => each swapdev takes one big contig chunk of the drum
 * => caller must hold uvm.swap_data_lock
 */
struct swapdev *
swapdrum_getsdp(int pgno)
{
	struct swapdev *sdp;
	struct swappri *spp;

	LIST_FOREACH(spp, &swap_priority, spi_swappri) {
		TAILQ_FOREACH(sdp, &spp->spi_swapdev, swd_next) {
			if (pgno >= sdp->swd_drumoffset &&
			    pgno < (sdp->swd_drumoffset + sdp->swd_drumsize)) {
				return sdp;
			}
		}
	}
	return NULL;
}


/*
 * sys_swapctl: main entry point for swapctl(2) system call
 * 	[with two helper functions: swap_on and swap_off]
 */
int
sys_swapctl(struct proc *p, void *v, register_t *retval)
{
	struct sys_swapctl_args /* {
		syscallarg(int) cmd;
		syscallarg(void *) arg;
		syscallarg(int) misc;
	} */ *uap = (struct sys_swapctl_args *)v;
	struct vnode *vp;
	struct nameidata nd;
	struct swappri *spp;
	struct swapdev *sdp;
	struct swapent *sep;
	char	userpath[MAXPATHLEN];
	size_t	len;
	int	count, error, misc;
	int	priority;

	misc = SCARG(uap, misc);

	/*
	 * ensure serialized syscall access by grabbing the swap_syscall_lock
	 */
	rw_enter_write(&swap_syscall_lock);

	/*
	 * we handle the non-priv NSWAP and STATS request first.
	 *
	 * SWAP_NSWAP: return number of config'd swap devices
	 * [can also be obtained with uvmexp sysctl]
	 */
	if (SCARG(uap, cmd) == SWAP_NSWAP) {
		*retval = uvmexp.nswapdev;
		error = 0;
		goto out;
	}

	/*
	 * SWAP_STATS: get stats on current # of configured swap devs
	 *
	 * note that the swap_priority list can't change as long
	 * as we are holding the swap_syscall_lock.  we don't want
	 * to grab the uvm.swap_data_lock because we may fault&sleep during
	 * copyout() and we don't want to be holding that lock then!
	 */
	if (SCARG(uap, cmd) == SWAP_STATS) {
		sep = (struct swapent *)SCARG(uap, arg);
		count = 0;

		LIST_FOREACH(spp, &swap_priority, spi_swappri) {
			TAILQ_FOREACH(sdp, &spp->spi_swapdev, swd_next) {
				if (count >= misc)
					continue;

				sdp->swd_inuse = 
				    btodb((u_int64_t)sdp->swd_npginuse <<
				    PAGE_SHIFT);
				error = copyout(&sdp->swd_se, sep,
				    sizeof(struct swapent));
				if (error)
					goto out;

				/* now copy out the path if necessary */
				error = copyoutstr(sdp->swd_path,
				    sep->se_path, sizeof(sep->se_path), NULL);
				if (error)
					goto out;

				count++;
				sep++;
			}
		}

		*retval = count;
		error = 0;
		goto out;
	}

	/* all other requests require superuser privs.   verify. */
	if ((error = suser(p, 0)) || (error = pledge_swapctl(p)))
		goto out;

	/*
	 * at this point we expect a path name in arg.   we will
	 * use namei() to gain a vnode reference (vref), and lock
	 * the vnode (VOP_LOCK).
	 */
	error = copyinstr(SCARG(uap, arg), userpath, sizeof(userpath), &len);
	if (error)
		goto out;
	disk_map(userpath, userpath, sizeof(userpath), DM_OPENBLCK);
	NDINIT(&nd, LOOKUP, FOLLOW|LOCKLEAF, UIO_SYSSPACE, userpath, p);
	if ((error = namei(&nd)))
		goto out;
	vp = nd.ni_vp;
	/* note: "vp" is referenced and locked */

	error = 0;		/* assume no error */
	switch(SCARG(uap, cmd)) {
	case SWAP_DUMPDEV:
		if (vp->v_type != VBLK) {
			error = ENOTBLK;
			break;
		}
		dumpdev = vp->v_rdev;
		break;
	case SWAP_CTL:
		/*
		 * get new priority, remove old entry (if any) and then
		 * reinsert it in the correct place.  finally, prune out
		 * any empty priority structures.
		 */
		priority = SCARG(uap, misc);
		spp = malloc(sizeof *spp, M_VMSWAP, M_WAITOK);
		if ((sdp = swaplist_find(vp, 1)) == NULL) {
			error = ENOENT;
		} else {
			swaplist_insert(sdp, spp, priority);
			swaplist_trim();
		}
		if (error)
			free(spp, M_VMSWAP, sizeof(*spp));
		break;
	case SWAP_ON:
		/*
		 * check for duplicates.   if none found, then insert a
		 * dummy entry on the list to prevent someone else from
		 * trying to enable this device while we are working on
		 * it.
		 */
		priority = SCARG(uap, misc);
		if ((sdp = swaplist_find(vp, 0)) != NULL) {
			error = EBUSY;
			break;
		}
		sdp = malloc(sizeof *sdp, M_VMSWAP, M_WAITOK|M_ZERO);
		spp = malloc(sizeof *spp, M_VMSWAP, M_WAITOK);
		sdp->swd_flags = SWF_FAKE;	/* placeholder only */
		sdp->swd_vp = vp;
		sdp->swd_dev = (vp->v_type == VBLK) ? vp->v_rdev : NODEV;

		/*
		 * XXX Is NFS elaboration necessary?
		 */
		if (vp->v_type == VREG) {
			sdp->swd_cred = crdup(p->p_ucred);
		}

		swaplist_insert(sdp, spp, priority);

		sdp->swd_pathlen = len;
		sdp->swd_path = malloc(sdp->swd_pathlen, M_VMSWAP, M_WAITOK);
		strlcpy(sdp->swd_path, userpath, len);

		/*
		 * we've now got a FAKE placeholder in the swap list.
		 * now attempt to enable swap on it.  if we fail, undo
		 * what we've done and kill the fake entry we just inserted.
		 * if swap_on is a success, it will clear the SWF_FAKE flag
		 */

		if ((error = swap_on(p, sdp)) != 0) {
			(void) swaplist_find(vp, 1);  /* kill fake entry */
			swaplist_trim();
			if (vp->v_type == VREG) {
				crfree(sdp->swd_cred);
			}
			free(sdp->swd_path, M_VMSWAP, sdp->swd_pathlen);
			free(sdp, M_VMSWAP, sizeof(*sdp));
			break;
		}
		break;
	case SWAP_OFF:
		if ((sdp = swaplist_find(vp, 0)) == NULL) {
			error = ENXIO;
			break;
		}

		/*
		 * If a device isn't in use or enabled, we
		 * can't stop swapping from it (again).
		 */
		if ((sdp->swd_flags & (SWF_INUSE|SWF_ENABLE)) == 0) {
			error = EBUSY;
			break;
		}

		/*
		 * do the real work.
		 */
		error = swap_off(p, sdp);
		break;
	default:
		error = EINVAL;
	}

	/* done!  release the ref gained by namei() and unlock. */
	vput(vp);

out:
	rw_exit_write(&swap_syscall_lock);

	return (error);
}

/*
 * swap_on: attempt to enable a swapdev for swapping.   note that the
 *	swapdev is already on the global list, but disabled (marked
 *	SWF_FAKE).
 *
 * => we avoid the start of the disk (to protect disk labels)
 * => caller should leave uvm.swap_data_lock unlocked, we may lock it
 *	if needed.
 */
int
swap_on(struct proc *p, struct swapdev *sdp)
{
	static int count = 0;	/* static */
	struct vnode *vp;
	int error, npages, nblocks, size;
	long addr;
	struct vattr va;
#if defined(NFSCLIENT)
	extern struct vops nfs_vops;
#endif /* defined(NFSCLIENT) */
	dev_t dev;

	/*
	 * we want to enable swapping on sdp.   the swd_vp contains
	 * the vnode we want (locked and ref'd), and the swd_dev
	 * contains the dev_t of the file, if it a block device.
	 */

	vp = sdp->swd_vp;
	dev = sdp->swd_dev;

#if NVND > 0
	/* no swapping to vnds. */
	if (bdevsw[major(dev)].d_strategy == vndstrategy)
		return (EOPNOTSUPP);
#endif

	/*
	 * open the swap file (mostly useful for block device files to
	 * let device driver know what is up).
	 *
	 * we skip the open/close for root on swap because the root
	 * has already been opened when root was mounted (mountroot).
	 */
	if (vp != rootvp) {
		if ((error = VOP_OPEN(vp, FREAD|FWRITE, p->p_ucred, p)))
			return (error);
	}

	/* XXX this only works for block devices */
	/*
	 * we now need to determine the size of the swap area.   for
	 * block specials we can call the d_psize function.
	 * for normal files, we must stat [get attrs].
	 *
	 * we put the result in nblks.
	 * for normal files, we also want the filesystem block size
	 * (which we get with statfs).
	 */
	switch (vp->v_type) {
	case VBLK:
		if (bdevsw[major(dev)].d_psize == 0 ||
		    (nblocks = (*bdevsw[major(dev)].d_psize)(dev)) == -1) {
			error = ENXIO;
			goto bad;
		}
		break;

	case VREG:
		if ((error = VOP_GETATTR(vp, &va, p->p_ucred, p)))
			goto bad;
		nblocks = (int)btodb(va.va_size);
		if ((error =
		     VFS_STATFS(vp->v_mount, &vp->v_mount->mnt_stat, p)) != 0)
			goto bad;

		sdp->swd_bsize = vp->v_mount->mnt_stat.f_iosize;
		/*
		 * limit the max # of outstanding I/O requests we issue
		 * at any one time.   take it easy on NFS servers.
		 */
#if defined(NFSCLIENT)
		if (vp->v_op == &nfs_vops)
			sdp->swd_maxactive = 2; /* XXX */
		else
#endif /* defined(NFSCLIENT) */
			sdp->swd_maxactive = 8; /* XXX */
		bufq_init(&sdp->swd_bufq, BUFQ_FIFO);
		break;

	default:
		error = ENXIO;
		goto bad;
	}

	/*
	 * save nblocks in a safe place and convert to pages.
	 */

	sdp->swd_nblks = nblocks;
	npages = dbtob((u_int64_t)nblocks) >> PAGE_SHIFT;

	/*
	 * for block special files, we want to make sure that leave
	 * the disklabel and bootblocks alone, so we arrange to skip
	 * over them (arbitrarily choosing to skip PAGE_SIZE bytes).
	 * note that because of this the "size" can be less than the
	 * actual number of blocks on the device.
	 */
	if (vp->v_type == VBLK) {
		/* we use pages 1 to (size - 1) [inclusive] */
		size = npages - 1;
		addr = 1;
	} else {
		/* we use pages 0 to (size - 1) [inclusive] */
		size = npages;
		addr = 0;
	}

	/*
	 * make sure we have enough blocks for a reasonable sized swap
	 * area.   we want at least one page.
	 */

	if (size < 1) {
		error = EINVAL;
		goto bad;
	}

	/*
	 * now we need to allocate an extent to manage this swap device
	 */
	snprintf(sdp->swd_exname, sizeof(sdp->swd_exname), "swap0x%04x",
	    count++);

	/* note that extent_create's 3rd arg is inclusive, thus "- 1" */
	sdp->swd_ex = extent_create(sdp->swd_exname, 0, npages - 1, M_VMSWAP,
				    0, 0, EX_WAITOK);
	/* allocate the `saved' region from the extent so it won't be used */
	if (addr) {
		if (extent_alloc_region(sdp->swd_ex, 0, addr, EX_WAITOK))
			panic("disklabel reserve");
		/* XXX: is extent synchronized with swd_npginuse? */
	}
#ifdef HIBERNATE
	/*
	 * Lock down the last region of primary disk swap, in case
	 * hibernate needs to place a signature there.
	 */
	if (dev == swdevt[0].sw_dev && vp->v_type == VBLK && size > 3 ) {
		if (extent_alloc_region(sdp->swd_ex,
		    npages - 1 - 1, 1, EX_WAITOK))
			panic("hibernate reserve");
		/* XXX: is extent synchronized with swd_npginuse? */
	}
#endif

	/* add a ref to vp to reflect usage as a swap device. */
	vref(vp);

#ifdef UVM_SWAP_ENCRYPT
	if (uvm_doswapencrypt)
		uvm_swap_initcrypt(sdp, npages);
#endif
	/* now add the new swapdev to the drum and enable. */
	swapdrum_add(sdp, npages);
	sdp->swd_npages = size;
	sdp->swd_flags &= ~SWF_FAKE;	/* going live */
	sdp->swd_flags |= (SWF_INUSE|SWF_ENABLE);
	uvmexp.swpages += size;
	return (0);

bad:
	/* failure: close device if necessary and return error. */
	if (vp != rootvp)
		(void)VOP_CLOSE(vp, FREAD|FWRITE, p->p_ucred, p);
	return (error);
}

/*
 * swap_off: stop swapping on swapdev
 *
 * => swap data should be locked, we will unlock.
 */
int
swap_off(struct proc *p, struct swapdev *sdp)
{
	int error = 0;

	/* disable the swap area being removed */
	sdp->swd_flags &= ~SWF_ENABLE;

	/*
	 * the idea is to find all the pages that are paged out to this
	 * device, and page them all in.  in uvm, swap-backed pageable
	 * memory can take two forms: aobjs and anons.  call the
	 * swapoff hook for each subsystem to bring in pages.
	 */

	if (uao_swap_off(sdp->swd_drumoffset,
			 sdp->swd_drumoffset + sdp->swd_drumsize) ||
	    amap_swap_off(sdp->swd_drumoffset,
			  sdp->swd_drumoffset + sdp->swd_drumsize)) {

		error = ENOMEM;
	} else if (sdp->swd_npginuse > sdp->swd_npgbad) {
		error = EBUSY;
	}

	if (error) {
		sdp->swd_flags |= SWF_ENABLE;
		return (error);
	}

	/*
	 * done with the vnode and saved creds.
	 * drop our ref on the vnode before calling VOP_CLOSE()
	 * so that spec_close() can tell if this is the last close.
	 */
	if (sdp->swd_vp->v_type == VREG) {
		crfree(sdp->swd_cred);
	}
	vrele(sdp->swd_vp);
	if (sdp->swd_vp != rootvp) {
		(void) VOP_CLOSE(sdp->swd_vp, FREAD|FWRITE, p->p_ucred, p);
	}

	uvmexp.swpages -= sdp->swd_npages;

	if (swaplist_find(sdp->swd_vp, 1) == NULL)
		panic("swap_off: swapdev not in list");
	swaplist_trim();

	/*
	 * free all resources!
	 */
	extent_free(swapmap, sdp->swd_drumoffset, sdp->swd_drumsize,
		    EX_WAITOK);
	extent_destroy(sdp->swd_ex);
	/* free sdp->swd_path ? */
	free(sdp, M_VMSWAP, sizeof(*sdp));
	return (0);
}

/*
 * /dev/drum interface and i/o functions
 */

/*
 * swstrategy: perform I/O on the drum
 *
 * => we must map the i/o request from the drum to the correct swapdev.
 */
void
swstrategy(struct buf *bp)
{
	struct swapdev *sdp;
	int s, pageno, bn;

	/*
	 * convert block number to swapdev.   note that swapdev can't
	 * be yanked out from under us because we are holding resources
	 * in it (i.e. the blocks we are doing I/O on).
	 */
	pageno = dbtob((u_int64_t)bp->b_blkno) >> PAGE_SHIFT;
	sdp = swapdrum_getsdp(pageno);
	if (sdp == NULL) {
		bp->b_error = EINVAL;
		bp->b_flags |= B_ERROR;
		s = splbio();
		biodone(bp);
		splx(s);
		return;
	}

	/* convert drum page number to block number on this swapdev. */
	pageno -= sdp->swd_drumoffset;	/* page # on swapdev */
	bn = btodb((u_int64_t)pageno << PAGE_SHIFT); /* convert to diskblock */

	/*
	 * for block devices we finish up here.
	 * for regular files we have to do more work which we delegate
	 * to sw_reg_strategy().
	 */
	switch (sdp->swd_vp->v_type) {
	default:
		panic("swstrategy: vnode type 0x%x", sdp->swd_vp->v_type);
	case VBLK:
		/*
		 * must convert "bp" from an I/O on /dev/drum to an I/O
		 * on the swapdev (sdp).
		 */
		s = splbio();
		buf_replacevnode(bp, sdp->swd_vp);

		bp->b_blkno = bn;
      		splx(s);
		VOP_STRATEGY(bp);
		return;
	case VREG:
		/* delegate to sw_reg_strategy function. */
		sw_reg_strategy(sdp, bp, bn);
		return;
	}
	/* NOTREACHED */
}

/*
 * sw_reg_strategy: handle swap i/o to regular files
 */
void
sw_reg_strategy(struct swapdev *sdp, struct buf *bp, int bn)
{
	struct vnode	*vp;
	struct vndxfer	*vnx;
	daddr_t	nbn;
	caddr_t		addr;
	off_t		byteoff;
	int		s, off, nra, error, sz, resid;

	/*
	 * allocate a vndxfer head for this transfer and point it to
	 * our buffer.
	 */
	vnx = pool_get(&vndxfer_pool, PR_WAITOK);
	vnx->vx_flags = VX_BUSY;
	vnx->vx_error = 0;
	vnx->vx_pending = 0;
	vnx->vx_bp = bp;
	vnx->vx_sdp = sdp;

	/*
	 * setup for main loop where we read filesystem blocks into
	 * our buffer.
	 */
	error = 0;
	bp->b_resid = bp->b_bcount;	/* nothing transferred yet! */
	addr = bp->b_data;		/* current position in buffer */
	byteoff = dbtob((u_int64_t)bn);

	for (resid = bp->b_resid; resid; resid -= sz) {
		struct vndbuf	*nbp;
		/*
		 * translate byteoffset into block number.  return values:
		 *   vp = vnode of underlying device
		 *  nbn = new block number (on underlying vnode dev)
		 *  nra = num blocks we can read-ahead (excludes requested
		 *	block)
		 */
		nra = 0;
		error = VOP_BMAP(sdp->swd_vp, byteoff / sdp->swd_bsize,
				 	&vp, &nbn, &nra);

		if (error == 0 && nbn == -1) {
			/*
			 * this used to just set error, but that doesn't
			 * do the right thing.  Instead, it causes random
			 * memory errors.  The panic() should remain until
			 * this condition doesn't destabilize the system.
			 */
#if 1
			panic("sw_reg_strategy: swap to sparse file");
#else
			error = EIO;	/* failure */
#endif
		}

		/*
		 * punt if there was an error or a hole in the file.
		 * we must wait for any i/o ops we have already started
		 * to finish before returning.
		 *
		 * XXX we could deal with holes here but it would be
		 * a hassle (in the write case).
		 */
		if (error) {
			s = splbio();
			vnx->vx_error = error;	/* pass error up */
			goto out;
		}

		/*
		 * compute the size ("sz") of this transfer (in bytes).
		 */
		off = byteoff % sdp->swd_bsize;
		sz = (1 + nra) * sdp->swd_bsize - off;
		if (sz > resid)
			sz = resid;

		/*
		 * now get a buf structure.   note that the vb_buf is
		 * at the front of the nbp structure so that you can
		 * cast pointers between the two structure easily.
		 */
		nbp = pool_get(&vndbuf_pool, PR_WAITOK);
		nbp->vb_buf.b_flags    = bp->b_flags | B_CALL;
		nbp->vb_buf.b_bcount   = sz;
		nbp->vb_buf.b_bufsize  = sz;
		nbp->vb_buf.b_error    = 0;
		nbp->vb_buf.b_data     = addr;
		nbp->vb_buf.b_bq       = NULL;
		nbp->vb_buf.b_blkno    = nbn + btodb(off);
		nbp->vb_buf.b_proc     = bp->b_proc;
		nbp->vb_buf.b_iodone   = sw_reg_iodone;
		nbp->vb_buf.b_vp       = NULLVP;
		nbp->vb_buf.b_vnbufs.le_next = NOLIST;
		LIST_INIT(&nbp->vb_buf.b_dep);

		/*
		 * set b_dirtyoff/end and b_validoff/end.   this is
		 * required by the NFS client code (otherwise it will
		 * just discard our I/O request).
		 */
		if (bp->b_dirtyend == 0) {
			nbp->vb_buf.b_dirtyoff = 0;
			nbp->vb_buf.b_dirtyend = sz;
		} else {
			nbp->vb_buf.b_dirtyoff =
			    max(0, bp->b_dirtyoff - (bp->b_bcount-resid));
			nbp->vb_buf.b_dirtyend =
			    min(sz,
				max(0, bp->b_dirtyend - (bp->b_bcount-resid)));
		}
		if (bp->b_validend == 0) {
			nbp->vb_buf.b_validoff = 0;
			nbp->vb_buf.b_validend = sz;
		} else {
			nbp->vb_buf.b_validoff =
			    max(0, bp->b_validoff - (bp->b_bcount-resid));
			nbp->vb_buf.b_validend =
			    min(sz,
				max(0, bp->b_validend - (bp->b_bcount-resid)));
		}

		/* patch it back to the vnx */
		nbp->vb_vnx = vnx;
		task_set(&nbp->vb_task, sw_reg_iodone_internal, nbp);

		s = splbio();
		if (vnx->vx_error != 0) {
			pool_put(&vndbuf_pool, nbp);
			goto out;
		}
		vnx->vx_pending++;

		/* assoc new buffer with underlying vnode */
		bgetvp(vp, &nbp->vb_buf);

		/* start I/O if we are not over our limit */
		bufq_queue(&sdp->swd_bufq, &nbp->vb_buf);
		sw_reg_start(sdp);
		splx(s);

		/*
		 * advance to the next I/O
		 */
		byteoff += sz;
		addr += sz;
	}

	s = splbio();

out: /* Arrive here at splbio */
	vnx->vx_flags &= ~VX_BUSY;
	if (vnx->vx_pending == 0) {
		if (vnx->vx_error != 0) {
			bp->b_error = vnx->vx_error;
			bp->b_flags |= B_ERROR;
		}
		pool_put(&vndxfer_pool, vnx);
		biodone(bp);
	}
	splx(s);
}

/* sw_reg_start: start an I/O request on the requested swapdev. */
void
sw_reg_start(struct swapdev *sdp)
{
	struct buf	*bp;

	/* XXX: recursion control */
	if ((sdp->swd_flags & SWF_BUSY) != 0)
		return;

	sdp->swd_flags |= SWF_BUSY;

	while (sdp->swd_active < sdp->swd_maxactive) {
		bp = bufq_dequeue(&sdp->swd_bufq);
		if (bp == NULL)
			break;

		sdp->swd_active++;

		if ((bp->b_flags & B_READ) == 0)
			bp->b_vp->v_numoutput++;

		VOP_STRATEGY(bp);
	}
	sdp->swd_flags &= ~SWF_BUSY;
}

/*
 * sw_reg_iodone: one of our i/o's has completed and needs post-i/o cleanup
 *
 * => note that we can recover the vndbuf struct by casting the buf ptr
 *
 * XXX:
 * We only put this onto a taskq here, because of the maxactive game since
 * it basically requires us to call back into VOP_STRATEGY() (where we must
 * be able to sleep) via sw_reg_start().
 */
void
sw_reg_iodone(struct buf *bp)
{
	struct vndbuf *vbp = (struct vndbuf *)bp;
	task_add(systq, &vbp->vb_task);
}

void
sw_reg_iodone_internal(void *xvbp)
{
	struct vndbuf *vbp = xvbp;
	struct vndxfer *vnx = vbp->vb_vnx;
	struct buf *pbp = vnx->vx_bp;		/* parent buffer */
	struct swapdev	*sdp = vnx->vx_sdp;
	int resid, s;

	s = splbio();

	resid = vbp->vb_buf.b_bcount - vbp->vb_buf.b_resid;
	pbp->b_resid -= resid;
	vnx->vx_pending--;

	/* pass error upward */
	if (vbp->vb_buf.b_error)
		vnx->vx_error = vbp->vb_buf.b_error;

	/* disassociate this buffer from the vnode (if any). */
	if (vbp->vb_buf.b_vp != NULL) {
		brelvp(&vbp->vb_buf);
	}

	/* kill vbp structure */
	pool_put(&vndbuf_pool, vbp);

	/*
	 * wrap up this transaction if it has run to completion or, in
	 * case of an error, when all auxiliary buffers have returned.
	 */
	if (vnx->vx_error != 0) {
		/* pass error upward */
		pbp->b_flags |= B_ERROR;
		pbp->b_error = vnx->vx_error;
		if ((vnx->vx_flags & VX_BUSY) == 0 && vnx->vx_pending == 0) {
			pool_put(&vndxfer_pool, vnx);
			biodone(pbp);
		}
	} else if (pbp->b_resid == 0) {
		KASSERT(vnx->vx_pending == 0);
		if ((vnx->vx_flags & VX_BUSY) == 0) {
			pool_put(&vndxfer_pool, vnx);
			biodone(pbp);
		}
	}

	/*
	 * done!   start next swapdev I/O if one is pending
	 */
	sdp->swd_active--;
	sw_reg_start(sdp);
	splx(s);
}


/*
 * uvm_swap_alloc: allocate space on swap
 *
 * => allocation is done "round robin" down the priority list, as we
 *	allocate in a priority we "rotate" the tail queue.
 * => space can be freed with uvm_swap_free
 * => we return the page slot number in /dev/drum (0 == invalid slot)
 * => we lock uvm.swap_data_lock
 * => XXXMRG: "LESSOK" INTERFACE NEEDED TO EXTENT SYSTEM
 */
int
uvm_swap_alloc(int *nslots, boolean_t lessok)
{
	struct swapdev *sdp;
	struct swappri *spp;
	u_long	result;

	/*
	 * no swap devices configured yet?   definite failure.
	 */
	if (uvmexp.nswapdev < 1)
		return 0;

	/*
	 * lock data lock, convert slots into blocks, and enter loop
	 */

ReTry:	/* XXXMRG */
	LIST_FOREACH(spp, &swap_priority, spi_swappri) {
		TAILQ_FOREACH(sdp, &spp->spi_swapdev, swd_next) {
			/* if it's not enabled, then we can't swap from it */
			if ((sdp->swd_flags & SWF_ENABLE) == 0)
				continue;
			if (sdp->swd_npginuse + *nslots > sdp->swd_npages)
				continue;
			if (extent_alloc(sdp->swd_ex, *nslots, EX_NOALIGN, 0,
					 EX_NOBOUNDARY, EX_MALLOCOK|EX_NOWAIT,
					 &result) != 0) {
				continue;
			}

			/*
			 * successful allocation!  now rotate the tailq.
			 */
			TAILQ_REMOVE(&spp->spi_swapdev, sdp, swd_next);
			TAILQ_INSERT_TAIL(&spp->spi_swapdev, sdp, swd_next);
			sdp->swd_npginuse += *nslots;
			uvmexp.swpginuse += *nslots;
			/* done!  return drum slot number */
			return(result + sdp->swd_drumoffset);
		}
	}

	/* XXXMRG: BEGIN HACK */
	if (*nslots > 1 && lessok) {
		*nslots = 1;
		goto ReTry;	/* XXXMRG: ugh!  extent should support this for us */
	}
	/* XXXMRG: END HACK */

	return 0;		/* failed */
}

/*
 * uvm_swap_markbad: keep track of swap ranges where we've had i/o errors
 *
 * => we lock uvm.swap_data_lock
 */
void
uvm_swap_markbad(int startslot, int nslots)
{
	struct swapdev *sdp;

	sdp = swapdrum_getsdp(startslot);
	if (sdp != NULL) {
		/*
		 * we just keep track of how many pages have been marked bad
		 * in this device, to make everything add up in swap_off().
		 * we assume here that the range of slots will all be within
		 * one swap device.
		 */
		sdp->swd_npgbad += nslots;
	}
}

/*
 * uvm_swap_free: free swap slots
 *
 * => this can be all or part of an allocation made by uvm_swap_alloc
 * => we lock uvm.swap_data_lock
 */
void
uvm_swap_free(int startslot, int nslots)
{
	struct swapdev *sdp;

	/*
	 * ignore attempts to free the "bad" slot.
	 */

	if (startslot == SWSLOT_BAD) {
		return;
	}

	/*
	 * convert drum slot offset back to sdp, free the blocks
	 * in the extent, and return.   must hold pri lock to do
	 * lookup and access the extent.
	 */

	sdp = swapdrum_getsdp(startslot);
	KASSERT(uvmexp.nswapdev >= 1);
	KASSERT(sdp != NULL);
	KASSERT(sdp->swd_npginuse >= nslots);
	if (extent_free(sdp->swd_ex, startslot - sdp->swd_drumoffset, nslots,
			EX_MALLOCOK|EX_NOWAIT) != 0) {
		printf("warning: resource shortage: %d pages of swap lost\n",
			nslots);
	}

	sdp->swd_npginuse -= nslots;
	uvmexp.swpginuse -= nslots;
#ifdef UVM_SWAP_ENCRYPT
	{
		int i;
		if (swap_encrypt_initialized) {
			/* Dereference keys */
			for (i = 0; i < nslots; i++)
				if (uvm_swap_needdecrypt(sdp, startslot + i)) {
					struct swap_key *key;

					key = SWD_KEY(sdp, startslot + i);
					if (key->refcount != 0)
						SWAP_KEY_PUT(sdp, key);
				}

			/* Mark range as not decrypt */
			uvm_swap_markdecrypt(sdp, startslot, nslots, 0);
		}
	}
#endif /* UVM_SWAP_ENCRYPT */
}

/*
 * uvm_swap_put: put any number of pages into a contig place on swap
 *
 * => can be sync or async
 */
int
uvm_swap_put(int swslot, struct vm_page **ppsp, int npages, int flags)
{
	int	result;

	result = uvm_swap_io(ppsp, swslot, npages, B_WRITE |
	    ((flags & PGO_SYNCIO) ? 0 : B_ASYNC));

	return (result);
}

/*
 * uvm_swap_get: get a single page from swap
 *
 * => usually a sync op (from fault)
 */
int
uvm_swap_get(struct vm_page *page, int swslot, int flags)
{
	int	result;

	uvmexp.nswget++;
	KASSERT(flags & PGO_SYNCIO);
	if (swslot == SWSLOT_BAD) {
		return VM_PAGER_ERROR;
	}

	/* this page is (about to be) no longer only in swap. */
	uvmexp.swpgonly--;

	result = uvm_swap_io(&page, swslot, 1, B_READ |
	    ((flags & PGO_SYNCIO) ? 0 : B_ASYNC));

	if (result != VM_PAGER_OK && result != VM_PAGER_PEND) {
		/* oops, the read failed so it really is still only in swap. */
		uvmexp.swpgonly++;
	}

	return (result);
}

/*
 * uvm_swap_io: do an i/o operation to swap
 */

int
uvm_swap_io(struct vm_page **pps, int startslot, int npages, int flags)
{
	daddr_t startblk;
	struct	buf *bp;
	vaddr_t kva;
	int	result, s, mapinflags, pflag, bounce = 0, i;
	boolean_t write, async;
	vaddr_t bouncekva;
	struct vm_page *tpps[MAXBSIZE >> PAGE_SHIFT];
#ifdef UVM_SWAP_ENCRYPT
	struct swapdev *sdp;
	int	encrypt = 0;
#endif

	write = (flags & B_READ) == 0;
	async = (flags & B_ASYNC) != 0;

	/* convert starting drum slot to block number */
	startblk = btodb((u_int64_t)startslot << PAGE_SHIFT);

	/*
	 * first, map the pages into the kernel (XXX: currently required
	 * by buffer system).
	 */
	mapinflags = !write ? UVMPAGER_MAPIN_READ : UVMPAGER_MAPIN_WRITE;
	if (!async)
		mapinflags |= UVMPAGER_MAPIN_WAITOK;
	kva = uvm_pagermapin(pps, npages, mapinflags);
	if (kva == 0)
		return (VM_PAGER_AGAIN);

#ifdef UVM_SWAP_ENCRYPT
	if (write) {
		/*
		 * Check if we need to do swap encryption on old pages.
		 * Later we need a different scheme, that swap encrypts
		 * all pages of a process that had at least one page swap
		 * encrypted.  Then we might not need to copy all pages
		 * in the cluster, and avoid the memory overheard in
		 * swapping.
		 */
		if (uvm_doswapencrypt)
			encrypt = 1;
	}

	if (swap_encrypt_initialized || encrypt) {
		/*
		 * we need to know the swap device that we are swapping to/from
		 * to see if the pages need to be marked for decryption or
		 * actually need to be decrypted.
		 * XXX - does this information stay the same over the whole
		 * execution of this function?
		 */
		sdp = swapdrum_getsdp(startslot);
	}

	/*
	 * Check that we are dma capable for read (write always bounces
	 * through the swapencrypt anyway...
	 */
	if (write && encrypt) {
		bounce = 1; /* bounce through swapencrypt always */
	} else {
#else
	{
#endif

		for (i = 0; i < npages; i++) {
			if (VM_PAGE_TO_PHYS(pps[i]) < dma_constraint.ucr_low ||
			   VM_PAGE_TO_PHYS(pps[i]) > dma_constraint.ucr_high) {
				bounce = 1;
				break;
			}
		}
	}

	if (bounce)  {
		int swmapflags;

		/* We always need write access. */
		swmapflags = UVMPAGER_MAPIN_READ;
		if (!async)
			swmapflags |= UVMPAGER_MAPIN_WAITOK;

		if (!uvm_swap_allocpages(tpps, npages)) {
			uvm_pagermapout(kva, npages);
			return (VM_PAGER_AGAIN);
		}

		bouncekva = uvm_pagermapin(tpps, npages, swmapflags);
		if (bouncekva == 0) {
			uvm_pagermapout(kva, npages);
			uvm_swap_freepages(tpps, npages);
			return (VM_PAGER_AGAIN);
		}
	}

	/* encrypt to swap */
	if (write && bounce) {
		int i, opages;
		caddr_t src, dst;
		u_int64_t block;

		src = (caddr_t) kva;
		dst = (caddr_t) bouncekva;
		block = startblk;
		for (i = 0; i < npages; i++) {
#ifdef UVM_SWAP_ENCRYPT
			struct swap_key *key;

			if (encrypt) {
				key = SWD_KEY(sdp, startslot + i);
				SWAP_KEY_GET(sdp, key);	/* add reference */

				swap_encrypt(key, src, dst, block, PAGE_SIZE);
				block += btodb(PAGE_SIZE);
			} else {
#else
			{
#endif /* UVM_SWAP_ENCRYPT */
				memcpy(dst, src, PAGE_SIZE);
			}
			/* this just tells async callbacks to free */
			atomic_setbits_int(&tpps[i]->pg_flags, PQ_ENCRYPT);
			src += PAGE_SIZE;
			dst += PAGE_SIZE;
		}

		uvm_pagermapout(kva, npages);

		/* dispose of pages we dont use anymore */
		opages = npages;
		uvm_pager_dropcluster(NULL, NULL, pps, &opages,
				      PGO_PDFREECLUST);

		kva = bouncekva;
	}

	/*
	 * now allocate a buf for the i/o.
	 * [make sure we don't put the pagedaemon to sleep...]
	 */
	pflag = (async || curproc == uvm.pagedaemon_proc) ? PR_NOWAIT :
	    PR_WAITOK;
	bp = pool_get(&bufpool, pflag | PR_ZERO);

	/*
	 * if we failed to get a swapbuf, return "try again"
	 */
	if (bp == NULL) {
		if (write && bounce) {
#ifdef UVM_SWAP_ENCRYPT
			int i;

			/* swap encrypt needs cleanup */
			if (encrypt)
				for (i = 0; i < npages; i++)
					SWAP_KEY_PUT(sdp, SWD_KEY(sdp,
					    startslot + i));
#endif

			uvm_pagermapout(kva, npages);
			uvm_swap_freepages(tpps, npages);
		}
		return (VM_PAGER_AGAIN);
	}

	/*
	 * prevent ASYNC reads.
	 * uvm_swap_io is only called from uvm_swap_get, uvm_swap_get
	 * assumes that all gets are SYNCIO.  Just make sure here.
	 * XXXARTUBC - might not be true anymore.
	 */
	if (!write) {
		flags &= ~B_ASYNC;
		async = 0;
	}

	/*
	 * fill in the bp.   we currently route our i/o through
	 * /dev/drum's vnode [swapdev_vp].
	 */
	bp->b_flags = B_BUSY | B_NOCACHE | B_RAW | (flags & (B_READ|B_ASYNC));
	bp->b_proc = &proc0;	/* XXX */
	bp->b_vnbufs.le_next = NOLIST;
	if (bounce)
		bp->b_data = (caddr_t)bouncekva;
	else
		bp->b_data = (caddr_t)kva;
	bp->b_bq = NULL;
	bp->b_blkno = startblk;
	LIST_INIT(&bp->b_dep);
	s = splbio();
	bp->b_vp = NULL;
	buf_replacevnode(bp, swapdev_vp);
	splx(s);
	bp->b_bufsize = bp->b_bcount = (long)npages << PAGE_SHIFT;

	/*
	 * for pageouts we must set "dirtyoff" [NFS client code needs it].
	 * and we bump v_numoutput (counter of number of active outputs).
	 */
	if (write) {
		bp->b_dirtyoff = 0;
		bp->b_dirtyend = npages << PAGE_SHIFT;
#ifdef UVM_SWAP_ENCRYPT
		/* mark the pages in the drum for decryption */
		if (swap_encrypt_initialized)
			uvm_swap_markdecrypt(sdp, startslot, npages, encrypt);
#endif
		s = splbio();
		swapdev_vp->v_numoutput++;
		splx(s);
	}

	/* for async ops we must set up the iodone handler. */
	if (async) {
		bp->b_flags |= B_CALL | (curproc == uvm.pagedaemon_proc ?
					 B_PDAEMON : 0);
		bp->b_iodone = uvm_aio_biodone;
	}

	/* now we start the I/O, and if async, return. */
	VOP_STRATEGY(bp);
	if (async)
		return (VM_PAGER_PEND);

	/* must be sync i/o.   wait for it to finish */
	(void) biowait(bp);
	result = (bp->b_flags & B_ERROR) ? VM_PAGER_ERROR : VM_PAGER_OK;

	/* decrypt swap */
	if (!write && !(bp->b_flags & B_ERROR)) {
		int i;
		caddr_t data = (caddr_t)kva;
		caddr_t dst = (caddr_t)kva;
		u_int64_t block = startblk;

		if (bounce)
			data = (caddr_t)bouncekva;

		for (i = 0; i < npages; i++) {
#ifdef UVM_SWAP_ENCRYPT
			struct swap_key *key;

			/* Check if we need to decrypt */
			if (swap_encrypt_initialized &&
			    uvm_swap_needdecrypt(sdp, startslot + i)) {
				key = SWD_KEY(sdp, startslot + i);
				if (key->refcount == 0) {
					result = VM_PAGER_ERROR;
					break;
				}
				swap_decrypt(key, data, dst, block, PAGE_SIZE);
			} else if (bounce) {
#else
			if (bounce) {
#endif
				memcpy(dst, data, PAGE_SIZE);
			}
			data += PAGE_SIZE;
			dst += PAGE_SIZE;
			block += btodb(PAGE_SIZE);
		}
		if (bounce)
			uvm_pagermapout(bouncekva, npages);
	}
	/* kill the pager mapping */
	uvm_pagermapout(kva, npages);

	/*  Not anymore needed, free after encryption/bouncing */
	if (!write && bounce)
		uvm_swap_freepages(tpps, npages);

	/* now dispose of the buf */
	s = splbio();
	if (bp->b_vp)
		brelvp(bp);

	if (write && bp->b_vp)
		vwakeup(bp->b_vp);
	pool_put(&bufpool, bp);
	splx(s);

	/* finally return. */
	return (result);
}

void
swapmount(void)
{
	struct swapdev *sdp;
	struct swappri *spp;
	struct vnode *vp;
	dev_t swap_dev = swdevt[0].sw_dev;
	char *nam;
	char path[MNAMELEN + 1];

	/*
	 * No locking here since we happen to know that we will just be called
	 * once before any other process has forked.
	 */
	if (swap_dev == NODEV)
		return;

#if defined(NFSCLIENT)
	if (swap_dev == NETDEV) {
		extern struct nfs_diskless nfs_diskless;

		snprintf(path, sizeof(path), "%s",
		    nfs_diskless.nd_swap.ndm_host);
		vp = nfs_diskless.sw_vp;
		goto gotit;
	} else
#endif
	if (bdevvp(swap_dev, &vp))
		return;

	/* Construct a potential path to swap */
	if ((nam = findblkname(major(swap_dev))))
		snprintf(path, sizeof(path), "/dev/%s%d%c", nam,
		    DISKUNIT(swap_dev), 'a' + DISKPART(swap_dev));
	else
		snprintf(path, sizeof(path), "blkdev0x%x",
		    swap_dev);

#if defined(NFSCLIENT)
gotit:
#endif
	sdp = malloc(sizeof(*sdp), M_VMSWAP, M_WAITOK|M_ZERO);
	spp = malloc(sizeof(*spp), M_VMSWAP, M_WAITOK);

	sdp->swd_flags = SWF_FAKE;
	sdp->swd_dev = swap_dev;

	sdp->swd_pathlen = strlen(path) + 1;
	sdp->swd_path = malloc(sdp->swd_pathlen, M_VMSWAP, M_WAITOK | M_ZERO);
	strlcpy(sdp->swd_path, path, sdp->swd_pathlen);

	sdp->swd_vp = vp;

	swaplist_insert(sdp, spp, 0);

	if (swap_on(curproc, sdp)) {
		swaplist_find(vp, 1);
		swaplist_trim();
		vput(sdp->swd_vp);
		free(sdp->swd_path, M_VMSWAP, sdp->swd_pathlen);
		free(sdp, M_VMSWAP, sizeof(*sdp));
		return;
	}
}

#ifdef HIBERNATE
int
uvm_hibswap(dev_t dev, u_long *sp, u_long *ep)
{
	struct swapdev *sdp, *swd = NULL;
	struct swappri *spp;
	struct extent_region *exr, *exrn;
	u_long start = 0, end = 0, size = 0;

	/* no swap devices configured yet? */
	if (uvmexp.nswapdev < 1 || dev != swdevt[0].sw_dev)
		return (1);

	LIST_FOREACH(spp, &swap_priority, spi_swappri) {
		TAILQ_FOREACH(sdp, &spp->spi_swapdev, swd_next) {
			if (sdp->swd_dev == dev)
				swd = sdp;
		}
	}

	if (swd == NULL || (swd->swd_flags & SWF_ENABLE) == 0)
		return (1);

	LIST_FOREACH(exr, &swd->swd_ex->ex_regions, er_link) {
		u_long gapstart, gapend, gapsize;
	
		gapstart = exr->er_end + 1;
		exrn = LIST_NEXT(exr, er_link);
		if (!exrn)
			break;
		gapend = exrn->er_start - 1;
		gapsize = gapend - gapstart;
		if (gapsize > size) {
			start = gapstart;
			end = gapend;
			size = gapsize;
		}
	}

	if (size) {
		*sp = start;
		*ep = end;
		return (0);
	}
	return (1);
}
#endif /* HIBERNATE */
@


1.140
log
@all pools have their ipl set via pool_setipl, so fold it into pool_init.

the ioff argument to pool_init() is unused and has been for many
years, so this replaces it with an ipl argument. because the ipl
will be set on init we no longer need pool_setipl.

most of these changes have been done with coccinelle using the spatch
below. cocci sucks at formatting code though, so i fixed that by hand.

the manpage and subr_pool.c bits i did myself.

ok tedu@@ jmatthew@@

@@ipl@@
expression pp;
expression ipl;
expression s, a, o, f, m, p;
@@@@
-pool_init(pp, s, a, o, f, m, p);
-pool_setipl(pp, ipl);
+pool_init(pp, s, a, ipl, f, m, p);
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.139 2015/11/01 19:03:33 semarie Exp $	*/
d323 2
a324 2
	sdp->swd_keys = malloc(SWD_KEY_SIZE(npages) * sizeof(struct swap_key),
	    M_VMSWAP, M_WAITOK|M_ZERO);
@


1.139
log
@refactor pledge_*_check and pledge_fail functions

- rename _check function without suffix: a "pledge" function called from
  anywhere is a "check" function.

- makes pledge_fail call the responsability to the _check function. remove it
  from caller.

- make proper use of (potential) returned error of _check() functions.

- adds pledge_kill() and pledge_protexec()

with and OK deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.138 2015/10/23 01:10:01 deraadt Exp $	*/
d282 4
a285 6
	pool_init(&vndxfer_pool, sizeof(struct vndxfer), 0, 0, 0, "swp vnx",
	    NULL);
	pool_setipl(&vndxfer_pool, IPL_BIO);
	pool_init(&vndbuf_pool, sizeof(struct vndbuf), 0, 0, 0, "swp vnd",
	    NULL);
	pool_setipl(&vndbuf_pool, IPL_BIO);
@


1.138
log
@Add 3 new pledge requests.  "ps" exposes enough sysctl information for
ps-style programs (there are quite a few in the tree, including tmux).
"vminfo" exposes a bit more system operation information, which many
observation programs want (such as top).  settime allows setting the system
time, and will be used to pledge-protect the last ntpd process.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.137 2015/09/06 17:06:43 deraadt Exp $	*/
d673 1
a673 1
	if ((error = suser(p, 0)) || pledge_swapctl_check(p))
@


1.137
log
@sizes for free(); ok semarie
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.136 2015/08/23 04:58:37 deraadt Exp $	*/
d54 1
d673 1
a673 1
	if ((error = suser(p, 0)))
@


1.136
log
@"XXXMRG: consider making it an inline or macro"
no way.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.135 2015/05/04 10:21:15 dlg Exp $	*/
d760 1
a760 1
			free(sdp->swd_path, M_VMSWAP, 0);
d1914 1
a1914 1
		free(sdp->swd_path, M_VMSWAP, 0);
@


1.135
log
@reduce the scope of things that include uvm_swap_encrypt.h.

uvm_meter.c needs it to route the sysctl, uvm_swap.c needs it to
use the functionality, and uvm_swap_encrypt.c needs it to for obvious
reasons. userland sysctl already includes it explicitely.

everything else doesnt and shouldnt care.

ok miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.134 2015/01/27 03:17:37 dlg Exp $	*/
a1519 1
 * => XXXMRG: consider making it an inline or macro
a1535 1
 * => XXXMRG: consider making it an inline or macro
@


1.134
log
@remove the second void * argument on tasks.

when workqs were introduced, we provided a second argument so you
could pass a thing and some context to work on it in. there were
very few things that took advantage of the second argument, so when
i introduced pools i suggested removing it. since tasks were meant
to replace workqs, it was requested that we keep the second argument
to make porting from workqs to tasks easier.

now that workqs are gone, i had a look at the use of the second
argument again and found only one good use of it (vdsp(4) on sparc64
if you're interested) and a tiny handful of questionable uses. the
vast majority of tasks only used a single argument. i have since
modified all tasks that used two args to only use one, so now we
can remove the second argument.

so this is a mechanical change. all tasks only passed NULL as their
second argument, so we can just remove it.

ok krw@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.133 2015/01/13 02:24:26 dlg Exp $	*/
d64 1
a64 1
#include <sys/syslog.h>
@


1.133
log
@pass the vnd xfer pointer to the tasks callback as part of the
vndbuf allocation.

luke-warm support and ok krw@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.132 2014/12/23 04:47:30 tedu Exp $	*/
d234 1
a234 1
void sw_reg_iodone_internal(void *, void *);
d1234 1
a1234 1
		task_set(&nbp->vb_task, sw_reg_iodone_internal, nbp, NULL);
d1318 1
a1318 1
sw_reg_iodone_internal(void *xvbp, void *null)
@


1.132
log
@I don't like these macros, they obscure the code.
We can use pool_setipl instead of doing the dance ourselves.
The bufpool is already setipl, we don't need to dance at all. We
should zero the buf.
ok deraadt dlg
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.131 2014/11/18 02:37:31 tedu Exp $	*/
d195 1
d1233 2
a1234 1
		task_set(&nbp->vb_task, sw_reg_iodone_internal, nbp, vnx);
d1318 1
a1318 1
sw_reg_iodone_internal(void *xvbp, void *xvnx)
d1321 1
a1321 1
	struct vndxfer *vnx = xvnx;
@


1.131
log
@move arc4random prototype to systm.h. more appropriate for most code
to include that than rdnvar.h. ok deraadt dlg
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.130 2014/11/17 00:15:38 tedu Exp $	*/
a203 19
#define	getvndxfer(vnx)	do {						\
	int s = splbio();						\
	vnx = pool_get(&vndxfer_pool, PR_WAITOK);			\
	splx(s);							\
} while (0)

#define putvndxfer(vnx) {						\
	pool_put(&vndxfer_pool, (void *)(vnx));				\
}

#define	getvndbuf(vbp)	do {						\
	int s = splbio();						\
	vbp = pool_get(&vndbuf_pool, PR_WAITOK);			\
	splx(s);							\
} while (0)

#define putvndbuf(vbp) {						\
	pool_put(&vndbuf_pool, (void *)(vbp));				\
}
d282 1
d285 1
d1121 1
a1121 1
	getvndxfer(vnx);
d1191 1
a1191 1
		getvndbuf(nbp);
d1236 1
a1236 1
			putvndbuf(nbp);
d1265 1
a1265 1
		putvndxfer(vnx);
d1340 1
a1340 1
	putvndbuf(vbp);
d1351 1
a1351 1
			putvndxfer(vnx);
d1357 1
a1357 1
			putvndxfer(vnx);
a1708 1
	s = splbio();
d1711 1
a1711 2
	bp = pool_get(&bufpool, pflag);
	splx(s);
@


1.130
log
@convert a copystr to strlcpy.
rearrange things in mountswap to delay malloc and always allocate
needed size.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.129 2014/11/13 03:56:51 tedu Exp $	*/
a63 1
#include <dev/rndvar.h>
@


1.129
log
@sizes for simple frees. new diff without the bug spotted by deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.128 2014/07/12 18:44:01 tedu Exp $	*/
d762 1
a762 2
		if (copystr(userpath, sdp->swd_path, sdp->swd_pathlen, 0) != 0)
			panic("swapctl: copystr");
d1883 1
a1888 1

a1891 9
	sdp = malloc(sizeof(*sdp), M_VMSWAP, M_WAITOK|M_ZERO);
	spp = malloc(sizeof(*spp), M_VMSWAP, M_WAITOK);

	sdp->swd_flags = SWF_FAKE;
	sdp->swd_dev = swap_dev;

	/* Construct a potential path to swap */
	sdp->swd_pathlen = MNAMELEN + 1;
	sdp->swd_path = malloc(sdp->swd_pathlen, M_VMSWAP, M_WAITOK | M_ZERO);
d1896 1
a1896 1
		snprintf(sdp->swd_path, sdp->swd_pathlen, "%s",
d1902 1
a1902 4
	if (bdevvp(swap_dev, &vp)) {
		free(sdp->swd_path, M_VMSWAP, 0);
		free(sdp, M_VMSWAP, sizeof(*sdp));
		free(spp, M_VMSWAP, sizeof(*spp));
a1903 1
	}
d1905 1
d1907 1
a1907 1
		snprintf(sdp->swd_path, sdp->swd_pathlen, "/dev/%s%d%c", nam,
d1910 1
a1910 1
		snprintf(sdp->swd_path, sdp->swd_pathlen, "blkdev0x%x",
d1916 10
a1925 1
	sdp->swd_pathlen = strlen(sdp->swd_path) + 1;
@


1.128
log
@add a size argument to free. will be used soon, but for now default to 0.
after discussions with beck deraadt kettenis.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.127 2014/05/08 20:08:50 kettenis Exp $	*/
d500 1
a500 1
		free(newspp, M_VMSWAP, 0);
d558 1
a558 1
		free(spp, M_VMSWAP, 0);
d731 1
a731 1
			free(spp, M_VMSWAP, 0);
d779 1
a779 1
			free(sdp, M_VMSWAP, 0);
d1055 2
a1056 1
	free(sdp, M_VMSWAP, 0);
d1914 2
a1915 2
		free(sdp, M_VMSWAP, 0);
		free(spp, M_VMSWAP, 0);
d1939 1
a1939 1
		free(sdp, M_VMSWAP, 0);
@


1.127
log
@Fix some potential integer overflows caused by converting a page number into
an offset/size/address by shifting by PAGE_SHIFT.  Make uvm_objwrire/unwire
use voff_t instead of off_t.  The former is the right type here even if it is
equivalent to the latter.

Inspired by a somewhat similar changes in Bitrig.

ok deraadt@@, guenther@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.126 2014/04/29 09:55:28 kettenis Exp $	*/
d500 1
a500 1
		free(newspp, M_VMSWAP);
d558 1
a558 1
		free(spp, M_VMSWAP);
d731 1
a731 1
			free(spp, M_VMSWAP);
d778 2
a779 2
			free(sdp->swd_path, M_VMSWAP);
			free(sdp, M_VMSWAP);
d1055 1
a1055 1
	free(sdp, M_VMSWAP);
d1912 3
a1914 3
		free(sdp->swd_path, M_VMSWAP);
		free(sdp, M_VMSWAP);
		free(spp, M_VMSWAP);
d1937 2
a1938 2
		free(sdp->swd_path, M_VMSWAP);
		free(sdp, M_VMSWAP);
@


1.126
log
@Replace 1 << PAGE_SHIFT with PAGE_SIZE.

ok beck@@, miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.125 2014/04/13 23:14:15 tedu Exp $	*/
d1783 1
a1783 1
	bp->b_bufsize = bp->b_bcount = npages << PAGE_SHIFT;
@


1.125
log
@compress code by turning four line comments into one line comments.
emphatic ok usual suspects, grudging ok miod
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.124 2013/11/24 15:44:26 jsing Exp $	*/
d1699 2
a1700 3
				swap_encrypt(key, src, dst, block,
				    1 << PAGE_SHIFT);
				block += btodb(1 << PAGE_SHIFT);
d1709 2
a1710 2
			src += 1 << PAGE_SHIFT;
			dst += 1 << PAGE_SHIFT;
d1840 1
a1840 2
				swap_decrypt(key, data, dst, block,
					     1 << PAGE_SHIFT);
d1845 1
a1845 1
				memcpy(dst, data, 1 << PAGE_SHIFT);
d1847 3
a1849 3
			data += 1 << PAGE_SHIFT;
			dst += 1 << PAGE_SHIFT;
			block += btodb(1 << PAGE_SHIFT);
@


1.124
log
@Replace the swapdev CIRCLEQ with a TAILQ and replace the manually rolled
list traversals with LIST_FOREACH.

ok beck@@ krw@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.123 2013/11/21 00:13:33 dlg Exp $	*/
a198 1

a281 1

d299 1
a299 5
	/*
	 * allocate pools for structures used for swapping to files.
	 */


a301 1

d305 1
a305 3
	/*
	 * Setup the initial swap partition
	 */
a306 4

	/*
	 * done!
	 */
d688 1
a688 3
	/*
	 * all other requests require superuser privs.   verify.
	 */
a708 1

a715 1

a732 1

a733 1

a739 1

a782 1

a802 1

d807 1
a807 3
	/*
	 * done!  release the ref gained by namei() and unlock.
	 */
d973 1
a973 3
	/*
	 * add a ref to vp to reflect usage as a swap device.
	 */
d980 1
a980 3
	/*
	 * now add the new swapdev to the drum and enable.
	 */
d989 1
a989 3
	/*
	 * failure: close device if necessary and return error.
	 */
d1090 1
a1090 4
	/*
	 * convert drum page number to block number on this swapdev.
	 */

a1098 1

a1101 1

a1102 1

a1113 1

d1115 1
a1115 3
		/*
		 * delegate to sw_reg_strategy function.
		 */
a1156 1

d1352 1
a1352 3
	/*
	 * disassociate this buffer from the vnode (if any).
	 */
d1357 1
a1357 3
	/*
	 * kill vbp structure
	 */
d1566 1
a1566 3
	/*
	 * this page is (about to be) no longer only in swap.
	 */
d1573 1
a1573 3
		/*
		 * oops, the read failed so it really is still only in swap.
		 */
d1602 1
a1602 3
	/*
	 * convert starting drum slot to block number
	 */
d1682 1
a1682 3
	/*
	 * encrypt to swap
	 */
d1803 1
a1803 3
	/*
	 * for async ops we must set up the iodone handler.
	 */
d1810 1
a1810 3
	/*
	 * now we start the I/O, and if async, return.
	 */
d1815 1
a1815 3
	/*
	 * must be sync i/o.   wait for it to finish
	 */
d1819 1
a1819 3
	/* 
	 * decrypt swap
	 */
d1856 1
a1856 3
	/*
	 * kill the pager mapping
	 */
d1859 1
a1859 3
	/*
	 *  Not anymore needed, free after encryption/bouncing
	 */
d1863 1
a1863 3
	/*
	 * now dispose of the buf
	 */
d1873 1
a1873 3
	/*
	 * finally return.
	 */
@


1.123
log
@remove the #define b_cylinder b_resid from bufs. i hated the
overloading of that thing.

the only hardware that seems to care about cylinders in our tree
are floppy drives, and the drivers for those calculate their own
cylinders from logical block addresses and ignore whatever the rest
of the kernel thought b_cylinders should be.

most of this diff is moving the floppy drivers to using b_resid as
a resid and using that as part of the calculation for real cylinder
values.

the rest of the diff is getting rid of the useless assignments to
b_cylinder that dont get used by anything (now that disksort is
gone).

ok miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.122 2013/11/20 23:57:07 miod Exp $	*/
d90 1
a90 1
 * CIRCLEQ of "swapdev" structures at that priority.
d145 1
a145 1
	CIRCLEQ_ENTRY(swapdev)	swd_next;	/* priority circleq */
d173 2
a174 2
	CIRCLEQ_HEAD(spi_swapdev, swapdev)	spi_swapdev;
	/* circleq of swapdevs at this priority */
d332 1
a332 1
		CIRCLEQ_FOREACH(sdp, &spp->spi_swapdev, swd_next)
d338 1
d455 1
a455 1
		CIRCLEQ_FOREACH(sdp, &spp->spi_swapdev, swd_next) {
d505 1
a505 1
		CIRCLEQ_INIT(&spp->spi_swapdev);
d518 1
a518 1
	 * circleq list and bump the total number of swapdevs.
d521 1
a521 1
	CIRCLEQ_INSERT_TAIL(&spp->spi_swapdev, sdp, swd_next);
d541 7
a547 12
	for (spp = LIST_FIRST(&swap_priority); spp != NULL;
	     spp = LIST_NEXT(spp, spi_swappri)) {
		for (sdp = CIRCLEQ_FIRST(&spp->spi_swapdev);
		     sdp != (void *)&spp->spi_swapdev;
		     sdp = CIRCLEQ_NEXT(sdp, swd_next))
			if (sdp->swd_vp == vp) {
				if (remove) {
					CIRCLEQ_REMOVE(&spp->spi_swapdev,
					    sdp, swd_next);
					uvmexp.nswapdev--;
				}
				return(sdp);
d549 2
d567 2
a568 4
	for (spp = LIST_FIRST(&swap_priority); spp != NULL; spp = nextspp) {
		nextspp = LIST_NEXT(spp, spi_swappri);
		if (CIRCLEQ_FIRST(&spp->spi_swapdev) !=
		    (void *)&spp->spi_swapdev)
d607 2
a608 5
	for (spp = LIST_FIRST(&swap_priority); spp != NULL;
	     spp = LIST_NEXT(spp, spi_swappri))
		for (sdp = CIRCLEQ_FIRST(&spp->spi_swapdev);
		     sdp != (void *)&spp->spi_swapdev;
		     sdp = CIRCLEQ_NEXT(sdp, swd_next))
d613 2
d672 5
a676 5
		for (spp = LIST_FIRST(&swap_priority); spp != NULL;
		    spp = LIST_NEXT(spp, spi_swappri)) {
			for (sdp = CIRCLEQ_FIRST(&spp->spi_swapdev);
			     sdp != (void *)&spp->spi_swapdev && misc-- > 0;
			     sdp = CIRCLEQ_NEXT(sdp, swd_next)) {
d682 2
d686 2
a687 5
				if (error == 0)
					error = copyoutstr(sdp->swd_path,
					    sep->se_path, sizeof(sep->se_path),
					    NULL);

d690 1
d1437 1
a1437 1
 *	allocate in a priority we "rotate" the circle queue.
d1461 2
a1462 5
	for (spp = LIST_FIRST(&swap_priority); spp != NULL;
	     spp = LIST_NEXT(spp, spi_swappri)) {
		for (sdp = CIRCLEQ_FIRST(&spp->spi_swapdev);
		     sdp != (void *)&spp->spi_swapdev;
		     sdp = CIRCLEQ_NEXT(sdp,swd_next)) {
d1475 1
a1475 1
			 * successful allocation!  now rotate the circleq.
d1477 2
a1478 2
			CIRCLEQ_REMOVE(&spp->spi_swapdev, sdp, swd_next);
			CIRCLEQ_INSERT_TAIL(&spp->spi_swapdev, sdp, swd_next);
d2026 2
a2027 5
	for (spp = LIST_FIRST(&swap_priority); spp != NULL;
	     spp = LIST_NEXT(spp, spi_swappri))
		for (sdp = CIRCLEQ_FIRST(&spp->spi_swapdev);
		     sdp != (void *)&spp->spi_swapdev;
		     sdp = CIRCLEQ_NEXT(sdp,swd_next)) {
d2031 1
@


1.122
log
@Update comments mentioning `resource maps' to mention `extents' instead.
Resource maps have been removed more than 10 years ago, it's about time to
update comments to better match reality.
No functional change.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.121 2013/11/06 07:46:31 dlg Exp $	*/
a1295 3

		/* XXX: In case the underlying bufq is disksort: */
		nbp->vb_buf.b_cylinder = nbp->vb_buf.b_blkno;
@


1.121
log
@remove some abuse of bufqs where they were overloaded to store workq_tasks
for completing swap io against files. this in turn bloated struct buf.

this moves from using workq_tasks to the task api, but stores the task
handler in vndbuf which is allocated specially for every io in this path
anyway.

ok kettenis@@ beck@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.120 2013/11/05 06:02:45 deraadt Exp $	*/
d291 4
a294 4
	 * create swap block resource map to map /dev/drum.   the range
	 * from 1 to INT_MAX allows 2 gigablocks of swap space.  note
	 * that block 0 is reserved (used to indicate an allocation
	 * failure, or no allocation).
@


1.120
log
@new function uvm_hibswap() finds a the largest free zone in swap, which
hibernate can use place the data.
ok mlarkin
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.119 2013/11/04 19:42:47 deraadt Exp $	*/
d53 1
d196 1
a196 1
	struct vndxfer	*vb_xfer;
d1294 2
a1295 1
		nbp->vb_xfer = vnx;	/* patch it back in to vnx */
d1370 1
a1370 1
 * We only put this onto a workq here, because of the maxactive game since
d1377 2
a1378 6
	struct bufq_swapreg	*bq;

	bq = (struct bufq_swapreg *)&bp->b_bufq;

	workq_queue_task(NULL, &bq->bqf_wqtask, 0,
	    (workq_fn)sw_reg_iodone_internal, bp, NULL);
d1382 1
a1382 1
sw_reg_iodone_internal(void *arg0, void *unused)
d1384 2
a1385 2
	struct vndbuf *vbp = (struct vndbuf *)arg0;
	struct vndxfer *vnx = vbp->vb_xfer;
@


1.119
log
@If compiled for hibernate, reserve the last page of the primary swap
space (in case we need to place a hibernate signature there)
ok miod
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.118 2013/11/04 19:41:17 deraadt Exp $	*/
a2026 4
/*
 * Check if free swap available at end of swap dev swdev.
 * Used by hibernate to check for usable swap area before writing the image
 */
d2028 1
a2028 1
uvm_swap_check_range(dev_t swdev, size_t size)
d2032 2
a2033 3
	struct extent *ex;
	struct extent_region *exr;
	int r = 0, start,  npages = size / PAGE_SIZE;
d2036 1
a2036 1
	if (uvmexp.nswapdev < 1)
d2044 1
a2044 1
			if (sdp->swd_dev == swdev)
d2048 1
a2048 1
	if (swd == NULL)
d2051 13
a2063 13
	if ((swd->swd_flags & SWF_ENABLE) == 0)
		return (1);

	ex = swd->swd_ex;
	start = swd->swd_drumsize-npages;

	if (npages > swd->swd_drumsize)
		return (1); 

	LIST_FOREACH(exr, &ex->ex_regions, er_link)
		{
			if (exr->er_end >= start)
				r = 1;
d2065 1
d2067 6
a2072 1
	return (r);
@


1.118
log
@improve a panic message
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.117 2013/11/02 04:14:13 deraadt Exp $	*/
d986 1
d988 12
@


1.117
log
@fix some comments
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.116 2013/11/02 00:08:17 krw Exp $	*/
d985 1
a985 1
			panic("disklabel region");
@


1.116
log
@No need to cast constants or simple variables to (daddr_t). Use
(u_int64_t) instead of (daddr_t) when casting a variable in an
expression passed to DL_SETDSIZE().

Change a variable counting open files from daddr_t to int64_t.

ok deraadt@@ with the tweak to fix that pesky expression.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.115 2013/06/11 16:42:19 deraadt Exp $	*/
d132 2
a133 2
#define	swd_inuse	swd_se.se_inuse		/* our priority */
#define	swd_nblks	swd_se.se_nblks		/* our priority */
@


1.115
log
@final removal of daddr64_t.  daddr_t has been 64 bit for a long enough
test period; i think 3 years ago the last bugs fell out.
ok otto beck others
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.114 2013/05/30 15:17:59 tedu Exp $	*/
d1199 1
a1199 1
		if (error == 0 && nbn == (daddr_t)-1) {
@


1.114
log
@remove simple_locks from uvm code. ok beck deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.113 2013/05/03 13:57:46 florian Exp $	*/
d1160 1
a1160 1
	daddr64_t	nbn;
d1199 1
a1199 1
		if (error == 0 && nbn == (daddr64_t)-1) {
d1635 1
a1635 1
	daddr64_t startblk;
@


1.113
log
@fix mem leak in swapmount

pointed out by jsg@@
ok tedu@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.112 2013/04/17 16:22:24 florian Exp $	*/
a94 3
 *  - uvm.swap_data_lock (simple_lock): this lock protects all swap data
 *    structures including the priority list, the swapdev structures,
 *    and the swapmap extent.
a284 1
	simple_lock_init(&uvm.swap_data_lock);
a328 1
	simple_lock(&uvm.swap_data_lock);
a337 1
	simple_unlock(&uvm.swap_data_lock);
a451 2
	simple_lock(&uvm.swap_data_lock);

a464 1
	simple_unlock(&uvm.swap_data_lock);
a744 1
		simple_lock(&uvm.swap_data_lock);
a750 1
		simple_unlock(&uvm.swap_data_lock);
a764 1
		simple_lock(&uvm.swap_data_lock);
a766 1
			simple_unlock(&uvm.swap_data_lock);
a782 1
		simple_unlock(&uvm.swap_data_lock);
a796 1
			simple_lock(&uvm.swap_data_lock);
a798 1
			simple_unlock(&uvm.swap_data_lock);
a808 1
		simple_lock(&uvm.swap_data_lock);
a809 1
			simple_unlock(&uvm.swap_data_lock);
a818 1
			simple_unlock(&uvm.swap_data_lock);
a999 1
	simple_lock(&uvm.swap_data_lock);
a1004 1
	simple_unlock(&uvm.swap_data_lock);
a1027 1
	simple_unlock(&uvm.swap_data_lock);
a1046 1
		simple_lock(&uvm.swap_data_lock);
a1047 1
		simple_unlock(&uvm.swap_data_lock);
a1063 1
	simple_lock(&uvm.swap_data_lock);
a1076 1
	simple_unlock(&uvm.swap_data_lock);
a1100 1
	simple_lock(&uvm.swap_data_lock);
a1101 1
	simple_unlock(&uvm.swap_data_lock);
a1455 1
	simple_lock(&uvm.swap_data_lock);
a1480 1
			simple_unlock(&uvm.swap_data_lock);
a1492 1
	simple_unlock(&uvm.swap_data_lock);
a1505 1
	simple_lock(&uvm.swap_data_lock);
a1515 1
	simple_unlock(&uvm.swap_data_lock);
a1542 1
	simple_lock(&uvm.swap_data_lock);
a1573 1
	simple_unlock(&uvm.swap_data_lock);
a1612 1
	simple_lock(&uvm.swap_data_lock);
a1613 1
	simple_unlock(&uvm.swap_data_lock);
a1621 1
		simple_lock(&uvm.swap_data_lock);
a1622 1
		simple_unlock(&uvm.swap_data_lock);
a1687 1
		simple_lock(&uvm.swap_data_lock);
a1688 1
		simple_unlock(&uvm.swap_data_lock);
@


1.112
log
@Unbreak and cleanup diskless swap automount.

Initial diff to replace unclear short variable name "nd" by
"nfs_diskless" and to display the real nfs path to swap in pstat -s by
deraadt@@

Testing by me revealed diskless swap automount was broken since some
time.  Fix this by passing and using the correct vnode in nfs_diskless
to swapmount().

Lots of input / help deraadt@@, tweaks by deraadt@@
OK deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.111 2013/03/28 03:39:22 deraadt Exp $	*/
d2025 1
@


1.111
log
@do not copy additional kernel memory into the swapent.se_path[]
ok tedu
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.110 2012/09/20 20:20:11 miod Exp $	*/
d53 7
d2000 1
a2000 2
	if (swap_dev == NODEV) {
		printf("swapmount: no device\n");
a2001 6
	}

	if (bdevvp(swap_dev, &vp)) {
		printf("swapmount: no device 2\n");
		return;
	}
a2007 1
	sdp->swd_vp = vp;
d2011 1
a2011 1
	sdp->swd_path = malloc(sdp->swd_pathlen, M_VMSWAP, M_WAITOK);
d2013 8
a2020 3
	if (swap_dev == NETDEV)
		snprintf(sdp->swd_path, sdp->swd_pathlen, "/swap");
	else
d2022 6
d2034 4
d2039 1
a2050 2

	VOP_UNLOCK(vp, 0, curproc);
@


1.110
log
@Now that none of our installation media runs off the swap area, don't bother
accounting for an hyperthetical miniroot filesystem in swap.
ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.109 2012/07/12 10:39:53 mlarkin Exp $	*/
d691 3
a693 2
					error = copyout(sdp->swd_path,
					    &sep->se_path, sdp->swd_pathlen);
@


1.109
log
@

Three cases that should be failures, not successes when checking for avail
swap region for hibernate.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.108 2012/07/11 16:00:15 mlarkin Exp $	*/
d121 1
a121 1
 * swd_nblks <= swd_mapsize [because mapsize includes miniroot+disklabel]
a715 3
	 *
	 * XXX: a NULL arg means use the root vnode pointer (e.g. for
	 * miniroot)
d717 8
a724 21
	if (SCARG(uap, arg) == NULL) {
		vp = rootvp;		/* miniroot */
		if (vget(vp, LK_EXCLUSIVE, p)) {
			error = EBUSY;
			goto out;
		}
		if (SCARG(uap, cmd) == SWAP_ON &&
		    copystr("miniroot", userpath, sizeof userpath, &len))
			panic("swapctl: miniroot copy failed");
	} else {
		error = copyinstr(SCARG(uap, arg), userpath,
		    sizeof(userpath), &len);
		if (error)
			goto out;
		disk_map(userpath, userpath, sizeof(userpath),
		    DM_OPENBLCK);
		NDINIT(&nd, LOOKUP, FOLLOW|LOCKLEAF, UIO_SYSSPACE, userpath, p);
		if ((error = namei(&nd)))
			goto out;
		vp = nd.ni_vp;
	}
a860 1
 * => we also avoid the miniroot, if we are swapping to root.
a996 28
	}

	/*
	 * if the vnode we are swapping to is the root vnode
	 * (i.e. we are swapping to the miniroot) then we want
	 * to make sure we don't overwrite it.   do a statfs to
	 * find its size and skip over it.
	 */
	if (vp == rootvp) {
		struct mount *mp;
		struct statfs *sp;
		int rootblocks, rootpages;

		mp = rootvnode->v_mount;
		sp = &mp->mnt_stat;
		rootblocks = sp->f_blocks * btodb(sp->f_bsize);
		rootpages = round_page(dbtob((u_int64_t)rootblocks))
		    >> PAGE_SHIFT;
		if (rootpages >= size)
			panic("swap_on: miniroot larger than swap?");

		if (extent_alloc_region(sdp->swd_ex, addr,
					rootpages, EX_WAITOK))
			panic("swap_on: unable to preserve miniroot");

		size -= rootpages;
		printf("Preserved %d pages of miniroot ", rootpages);
		printf("leaving %d pages of swap\n", size);
@


1.108
log
@

#ifdef the uvm swap checker fn for hibernate only, to save space in kernels
that don't use hibernate

requested by and ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.107 2012/07/11 12:31:28 mlarkin Exp $	*/
d2098 1
a2098 1
	/* no swap devices configured yet? then range is not in use */
d2100 1
a2100 1
		return (0);
d2112 1
a2112 1
		return (0);
d2115 1
a2115 1
		return (0);
@


1.107
log
@

add a check for the total size of swap, abort if too small.
used by the hibernate code.

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.106 2012/07/11 10:07:40 mlarkin Exp $	*/
d2084 1
d2131 1
@


1.106
log
@

add uvm_swap_check_range to scan for contig free space at end of swap.
will be needed shortly for hibernate.

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.105 2012/06/14 15:53:38 jasper Exp $	*/
d2118 3
@


1.105
log
@whitespace cleanup

ok ariane@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.104 2011/07/04 20:35:35 deraadt Exp $	*/
d2082 44
@


1.104
log
@move the specfs code to a place people can see it; ok guenther thib krw
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.103 2011/07/03 18:34:14 oga Exp $	*/
d70 1
a70 1
 * 
d267 1
a267 1
 * => called at boot time from init_main.c after the filesystems 
d289 1
a289 1
	 * that block 0 is reserved (used to indicate an allocation 
d378 1
a378 1
		
d411 1
a411 1
	
d422 1
a422 1
		else 
d611 1
a611 1
	
d653 1
a653 1
	
d657 1
a657 1
	 * SWAP_NSWAP: return number of config'd swap devices 
d669 1
a669 1
	 * note that the swap_priority list can't change as long 
d671 1
a671 1
	 * to grab the uvm.swap_data_lock because we may fault&sleep during 
d704 1
a704 1
	} 
d903 1
a903 1
#if NVND > 0 
d1017 1
a1017 1
	 * if the vnode we are swapping to is the root vnode 
d1019 1
a1019 1
	 * to make sure we don't overwrite it.   do a statfs to 
d1035 1
a1035 1
		if (extent_alloc_region(sdp->swd_ex, addr, 
d1099 1
a1099 1
		
d1265 1
a1265 1
			/* 
d1319 1
a1319 1
		/* 
d1517 1
a1517 1
	
d1608 2
a1609 2
	 * convert drum slot offset back to sdp, free the blocks 
	 * in the extent, and return.   must hold pri lock to do 
d1689 1
a1689 1
	result = uvm_swap_io(&page, swslot, 1, B_READ | 
d1749 1
a1749 1
		 * in the cluster, and avoid the memory overheard in 
d1756 1
a1756 1
	if (swap_encrypt_initialized || encrypt) { 
d1761 1
a1761 1
		 * XXX - does this information stay the same over the whole 
d1801 1
a1801 1
		
d1810 1
a1810 1
	/* 
d1848 1
a1848 1
		uvm_pager_dropcluster(NULL, NULL, pps, &opages, 
d1854 1
a1854 1
	/* 
d1884 2
a1885 2
	
	/* 
d1916 1
a1916 1
	/* 
@


1.103
log
@Rip out and burn support for UVM_HIST.

The vm hackers don't use it, don't maintain it and have to look at it all the
time. About time this 800 lines of code hit /dev/null.

``never liked it'' tedu@@. ariane@@ was very happy when i told her i wrote
this diff.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.102 2011/04/17 19:19:47 deraadt Exp $	*/
d60 1
a60 1
#include <miscfs/specfs/specdev.h>
@


1.102
log
@construct a better path to the swapdevice (as seen in pstat/swapctl output)
ok miod
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.101 2011/04/04 11:29:39 thib Exp $	*/
a272 3
	UVMHIST_FUNC("uvm_swap_init");

	UVMHIST_CALLED(pdhist);
a315 1
	UVMHIST_LOG(pdhist, "<- done", 0, 0, 0, 0);
a486 1
	UVMHIST_FUNC("swaplist_insert"); UVMHIST_CALLED(pdhist);
a502 2
		UVMHIST_LOG(pdhist, "created new swappri = %ld",
			    priority, 0, 0, 0);
a645 1
	UVMHIST_FUNC("sys_swapctl"); UVMHIST_CALLED(pdhist);
a660 2
		UVMHIST_LOG(pdhist, "<- done SWAP_NSWAP=%ld", uvmexp.nswapdev,
		    0, 0, 0);
a700 2
		UVMHIST_LOG(pdhist, "<- done SWAP_STATS", 0, 0, 0, 0);

a867 1
	UVMHIST_LOG(pdhist, "<- done!  error=%ld", error, 0, 0, 0);
a892 1
	UVMHIST_FUNC("swap_on"); UVMHIST_CALLED(pdhist);
a921 2
	UVMHIST_LOG(pdhist, "  dev=%ld, major(dev)=%ld", dev, major(dev), 0,0);

a996 1
		UVMHIST_LOG(pdhist, "  size <= 1!!", 0, 0, 0, 0);
a1000 3
	UVMHIST_LOG(pdhist, "  dev=%lx: size=%ld addr=0x%lx\n",
	    dev, size, addr, 0);

a1082 2
	UVMHIST_FUNC("swap_off"); UVMHIST_CALLED(pdhist);
	UVMHIST_LOG(pdhist, "  dev=%lx", sdp->swd_dev,0,0,0);
a1156 1
	UVMHIST_FUNC("swstrategy"); UVMHIST_CALLED(pdhist);
a1172 1
		UVMHIST_LOG(pdhist, "  failed to get swap device", 0, 0, 0, 0);
a1182 4
	UVMHIST_LOG(pdhist, "  %s: mapoff=%lx bn=0x%lx bcount=%ld",
		((bp->b_flags & B_READ) == 0) ? "write" : "read",
		sdp->swd_drumoffset, bn, bp->b_bcount);

a1228 1
	UVMHIST_FUNC("sw_reg_strategy"); UVMHIST_CALLED(pdhist);
a1299 4
		UVMHIST_LOG(pdhist, "sw_reg_strategy: "
			    "vp %p/%p offset 0x%lx/0x%llx",
			    sdp->swd_vp, vp, (u_long)byteoff, nbn);

a1391 1
	UVMHIST_FUNC("sw_reg_start"); UVMHIST_CALLED(pdhist);
a1405 3
		UVMHIST_LOG(pdhist,
		    "sw_reg_start:  bp %p vp %p blkno 0x%lx cnt 0x%lx",
		    bp, bp->b_vp, bp->b_blkno, bp->b_bcount);
a1442 6
	UVMHIST_FUNC("sw_reg_iodone"); UVMHIST_CALLED(pdhist);

	UVMHIST_LOG(pdhist, "  vbp=%p vp=%p blkno=0x%lx addr=%p",
	    vbp, vbp->vb_buf.b_vp, vbp->vb_buf.b_blkno, vbp->vb_buf.b_data);
	UVMHIST_LOG(pdhist, "  cnt=%lx resid=%lx",
	    vbp->vb_buf.b_bcount, vbp->vb_buf.b_resid, 0, 0);
d1450 2
a1451 5
	if (vbp->vb_buf.b_error) {
		UVMHIST_LOG(pdhist, "  got error=%ld !",
		    vbp->vb_buf.b_error, 0, 0, 0);

		/* pass error upward */
a1452 1
	}
a1480 2
			UVMHIST_LOG(pdhist, "  iodone error=%ld !",
			    pbp, vnx->vx_error, 0, 0);
a1510 1
	UVMHIST_FUNC("uvm_swap_alloc"); UVMHIST_CALLED(pdhist);
a1548 3
			UVMHIST_LOG(pdhist,
			    "success!  returning %ld slots starting at %ld",
			    *nslots, result + sdp->swd_drumoffset, 0, 0);
a1572 1
	UVMHIST_FUNC("uvm_swap_markbad"); UVMHIST_CALLED(pdhist);
a1583 1
		UVMHIST_LOG(pdhist, "now %ld bad", sdp->swd_npgbad, 0,0,0);
a1597 4
	UVMHIST_FUNC("uvm_swap_free"); UVMHIST_CALLED(pdhist);

	UVMHIST_LOG(pdhist, "freeing %ld slots starting at %ld", nslots,
	    startslot, 0, 0);
a1721 4
	UVMHIST_FUNC("uvm_swap_io"); UVMHIST_CALLED(pdhist);

	UVMHIST_LOG(pdhist, "<- called, startslot=%ld, npages=%ld, flags=%ld",
	    startslot, npages, flags, 0);
a1939 1
		UVMHIST_LOG(pdhist, "doing async!", 0, 0, 0, 0);
a1940 3
	UVMHIST_LOG(pdhist,
	    "about to start io: data = %p blkno = 0x%lx, bcount = %ld",
	    bp->b_data, bp->b_blkno, bp->b_bcount, 0);
a2019 1
	UVMHIST_LOG(pdhist, "<- done (sync)  result=%ld", result, 0, 0, 0);
@


1.101
log
@Disallow swapping to vnd's and return ENOTSUPP back
to userland.

Wrap the checking code in #if NVND > 0 as pointed out
by miod.

ok beck@@
ok deraadt@@, krw@@ (on an earlier diff)
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.99 2010/12/04 05:18:10 jsing Exp $	*/
d2098 1
d2121 17
a2138 4
	sdp->swd_pathlen = strlen("swap_device") + 1;
	sdp->swd_path = malloc(sdp->swd_pathlen, M_VMSWAP, M_WAITOK);
	if (copystr("swap_device", sdp->swd_path, sdp->swd_pathlen, 0))
		panic("swapmount: copystr");
@


1.100
log
@Bring back the "End the VOP experiment." diff, naddy's issues where
unrelated, and his alpha is much happier now.

OK deraadt@@
@
text
@d62 2
d916 6
@


1.99
log
@Teach swapctl(2) about DUIDs.

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.97 2010/09/10 16:34:09 thib Exp $	*/
d901 1
a901 1
	extern int (**nfsv2_vnodeop_p)(void *);
d962 1
a962 1
		if (vp->v_op == nfsv2_vnodeop_p)
@


1.98
log
@remove static so things show up in ddb.

ok miod@@, oga@@, tedu@@
@
text
@d52 1
d740 7
a746 14
		int	space;
		char	*where;

		if (SCARG(uap, cmd) == SWAP_ON) {
			if ((error = copyinstr(SCARG(uap, arg), userpath,
			    sizeof userpath, &len)))
				goto out;
			space = UIO_SYSSPACE;
			where = userpath;
		} else {
			space = UIO_USERSPACE;
			where = (char *)SCARG(uap, arg);
		}
		NDINIT(&nd, LOOKUP, FOLLOW|LOCKLEAF, space, where, p);
@


1.97
log
@Backout the VOP diff until the issues naddy was seeing on alpha (gcc3)
have been resolved.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.96 2010/09/06 23:44:11 thib Exp $	*/
d221 1
a221 1
static struct extent *swapmap;		/* controls the mapping of /dev/drum */
d225 1
a225 1
static struct swap_priority swap_priority;
d233 2
a234 2
static void		 swapdrum_add(struct swapdev *, int);
static struct swapdev	*swapdrum_getsdp(int);
d236 4
a239 4
static struct swapdev	*swaplist_find(struct vnode *, int);
static void		 swaplist_insert(struct swapdev *, 
					     struct swappri *, int);
static void		 swaplist_trim(void);
d241 2
a242 2
static int swap_on(struct proc *, struct swapdev *);
static int swap_off(struct proc *, struct swapdev *);
d244 1
a244 1
static void sw_reg_strategy(struct swapdev *, struct buf *, int);
d247 1
a247 1
static void sw_reg_start(struct swapdev *);
d249 1
a249 1
static int uvm_swap_io(struct vm_page **, int, int, int);
d251 1
a251 1
static void swapmount(void);
d484 1
a484 1
static void
d536 1
a536 1
static struct swapdev *
d569 1
a569 1
static void
d590 1
a590 1
static void
d610 1
a610 1
static struct swapdev *
d898 1
a898 1
static int
d1097 1
a1097 1
static int
d1246 1
a1246 1
static void
d1419 1
a1419 1
static void
d1765 1
a1765 1
static int
d2089 1
a2089 1
static void
@


1.96
log
@End the VOP experiment. Instead of the ridicolusly complicated operation
vector setup that has questionable features (that have, as far as I can
tell never been used in practice, atleast not in OpenBSD), remove all
the gunk and favor a simple struct full of function pointers that get
set directly by each of the filesystems.

Removes gobs of ugly code and makes things simpler by a magnitude.

The only downside of this is that we loose the vnoperate feature so
the spec/fifo operations of the filesystems need to be kept in sync
with specfs and fifofs, this is no big deal as the API it self is pretty
static.

Many thanks to armani@@ who pulled an earlier version of this diff to
current after c2k10 and Gabriel Kihlman on tech@@ for testing.

Liked by many. "come on, find your balls" deraadt@@.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.95 2010/09/06 16:33:41 thib Exp $	*/
d907 1
a907 1
	extern struct vops nfs_vops;
d968 1
a968 1
		if (vp->v_op == &nfs_vops)
@


1.95
log
@cut swapping to file over from disksort to bufq fifo's and
instead of doing work in the biodone callback for swapping
to file I/O, schedule the work to be done by the system
workq as it will call VOP_STRATEGY() in which we must be
allowed to sleep.

Thanks to Gabriel Kihlman for testing and spotting a bug in
the first version of this diff!

OK beck@@, oga@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.94 2010/07/03 20:28:51 miod Exp $	*/
d907 1
a907 1
	extern int (**nfsv2_vnodeop_p)(void *);
d968 1
a968 1
		if (vp->v_op == nfsv2_vnodeop_p)
@


1.94
log
@Be sure to initialize b_bq member of struct buf not allocated through the
regular buf routines; and now we can swap again.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.93 2010/07/01 19:48:05 oga Exp $	*/
d141 2
a142 1
	struct buf		swd_tab;	/* buffer list */
d245 2
a246 1
static void sw_reg_iodone(struct buf *);
d973 1
d1378 1
a1378 3
		/*
		 * Just sort by block number
		 */
d1380 1
d1391 2
a1392 2
		/* sort it in and start I/O if we are not over our limit */
		disksort(&sdp->swd_tab, &nbp->vb_buf);
d1418 1
a1418 5
/*
 * sw_reg_start: start an I/O request on the requested swapdev
 *
 * => reqs are sorted by disksort (above)
 */
d1425 1
a1425 1
	/* recursion control */
d1431 2
a1432 2
	while (sdp->swd_tab.b_active < sdp->swd_maxactive) {
		bp = sdp->swd_tab.b_actf;
d1435 2
a1436 2
		sdp->swd_tab.b_actf = bp->b_actf;
		sdp->swd_tab.b_active++;
d1453 5
d1459 1
a1459 1
static void
d1462 12
a1473 1
	struct vndbuf *vbp = (struct vndbuf *) bp;
d1477 1
a1477 1
	int resid;
d1485 1
a1485 1
	splassert(IPL_BIO);
d1536 1
a1536 1
	sdp->swd_tab.b_active--;
d1538 1
@


1.93
log
@Allow swapping to happen in the case where where we have more memory
than we can realistically dma to.

In the swap encrypt case we already bounce through a intermediate buffer
for pageout, so just make sure that that buffer is constrained to
dmaable memory. In the other cases we check to see if the memory is
dmaable, then if not we bounce it.

ok beck@@, art@@, thib@@.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.92 2009/06/17 00:13:59 oga Exp $	*/
d1339 1
d1953 1
@


1.92
log
@date based reversion of uvm to the 4th May.

More backouts in line with previous ones, this appears to bring us back to a
stable condition.

A machine forced to 64mb of ram cycled 10GB through swap with this diff
and is still running as I type this. Other tests by ariane@@ and thib@@
also seem to show that it's alright.

ok deraadt@@, thib@@, ariane@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.87 2009/03/23 22:07:41 oga Exp $	*/
d250 1
a253 1
boolean_t uvm_swap_allocpages(struct vm_page **, int);
d354 2
d359 1
d373 5
a377 1
	/* Get new pages */
d379 4
a382 9
		pps[i] = uvm_pagealloc(NULL, 0, NULL, 0);
		if (pps[i] == NULL)
			break;
	}

	/* On failure free and return */
	if (i < npages) {
		uvm_swap_freepages(pps, i);
		return FALSE;
d399 1
d1755 1
a1755 1
	int	result, s, mapinflags, pflag;
d1757 2
a1759 2
	vaddr_t dstkva;
	struct vm_page *tpps[MAXBSIZE >> PAGE_SHIFT];
d1801 1
a1801 1
	if (swap_encrypt_initialized  || encrypt) { 
d1814 3
a1816 2
	/* 
	 * encrypt to swap
d1819 16
a1834 4
		int i, opages;
		caddr_t src, dst;
		struct swap_key *key;
		u_int64_t block;
d1847 2
a1848 2
		dstkva = uvm_pagermapin(tpps, npages, swmapflags);
		if (dstkva == 0) {
d1853 9
d1864 1
a1864 1
		dst = (caddr_t) dstkva;
d1867 2
a1868 2
			key = SWD_KEY(sdp, startslot + i);
			SWAP_KEY_GET(sdp, key);	/* add reference */
d1870 14
a1883 1
			/* mark for async writes */
a1884 1
			swap_encrypt(key, src, dst, block, 1 << PAGE_SHIFT);
a1886 1
			block += btodb(1 << PAGE_SHIFT);
d1896 1
a1896 1
		kva = dstkva;
a1897 1
#endif /* UVM_SWAP_ENCRYPT */
d1904 2
a1905 1
	pflag = (async || curproc == uvm.pagedaemon_proc) ? 0 : PR_WAITOK;
d1913 1
a1914 1
		if (write && encrypt) {
d1918 5
a1922 2
			for (i = 0; i < npages; i++)
				SWAP_KEY_PUT(sdp, SWD_KEY(sdp, startslot + i));
a1926 1
#endif
a1929 1
#ifdef UVM_SWAP_ENCRYPT
d1940 1
a1940 1
#endif
d1948 4
a1951 1
	bp->b_data = (caddr_t)kva;
a2002 1
#ifdef UVM_SWAP_ENCRYPT
d2006 1
a2006 2
	if (swap_encrypt_initialized &&
	    (bp->b_flags & B_READ) && !(bp->b_flags & B_ERROR)) {
d2008 2
a2009 1
		caddr_t data = bp->b_data;
d2011 3
a2013 1
		struct swap_key *key;
d2016 3
d2020 2
a2021 1
			if (uvm_swap_needdecrypt(sdp, startslot + i)) {
d2027 1
a2027 1
				swap_decrypt(key, data, data, block,
d2029 5
d2036 1
d2039 2
a2041 1
#endif
a2046 1
#ifdef UVM_SWAP_ENCRYPT
d2048 1
a2048 1
	 *  Not anymore needed, free after encryption
d2050 1
a2050 1
	if ((bp->b_flags & B_READ) == 0 && encrypt)
d2052 1
a2052 1
#endif
@


1.91
log
@Backout all changes to uvm after pmemrange (which will be backed out
separately).

a change at or just before the hackathon has either exposed or added a
very very nasty memory corruption bug that is giving us hell right now.
So in the interest of kernel stability these diffs are being backed out
until such a time as that corruption bug has been found and squashed,
then the ones that are proven good may slowly return.

a quick hitlist of the main commits this backs out:

mine:
uvm_objwire
the lock change in uvm_swap.c
using trees for uvm objects instead of the hash
removing the pgo_releasepg callback.

art@@'s:
putting pmap_page_protect(VM_PROT_NONE) in uvm_pagedeactivate() since
all callers called that just prior anyway.

ok beck@@, ariane@@.

prompted by deraadt@@.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.89 2009/06/03 22:09:30 thib Exp $	*/
d141 1
a141 2
	int			swd_active;	/* i/o reqs in progress */
	struct bufq		*swd_bufq;	/* buffer queue */
d232 2
a233 2
void		 swapdrum_add(struct swapdev *, int);
struct swapdev	*swapdrum_getsdp(int);
d235 4
a238 3
struct swapdev	*swaplist_find(struct vnode *, int);
void		 swaplist_insert(struct swapdev *, struct swappri *, int);
void		 swaplist_trim(void);
d240 2
a241 2
int swap_on(struct proc *, struct swapdev *);
int swap_off(struct proc *, struct swapdev *);
d243 3
a245 3
void sw_reg_strategy(struct swapdev *, struct buf *, int);
void sw_reg_iodone(struct buf *);
void sw_reg_start(struct swapdev *);
d247 1
a247 1
int uvm_swap_io(struct vm_page **, int, int, int);
d249 1
a249 1
void swapmount(void);
d479 1
a479 1
void
d531 1
a531 1
struct swapdev *
d564 1
a564 1
void
d585 1
a585 1
void
d605 1
a605 1
struct swapdev *
a805 1
		sdp->swd_bufq = bufq_init(BUFQ_DEFAULT);
d893 1
a893 1
int
d1091 1
a1091 1
int
a1151 1
	bufq_destroy(sdp->swd_bufq);
d1240 1
a1240 1
void
d1386 1
a1386 1
		BUFQ_ADD(sdp->swd_bufq, &nbp->vb_buf);
d1417 1
a1417 1
void
d1429 2
a1430 2
	while (sdp->swd_active < sdp->swd_maxactive) {
		bp = BUFQ_GET(sdp->swd_bufq);
d1433 2
a1434 1
		sdp->swd_active++;
d1452 1
a1452 1
void
d1518 1
a1518 1
	sdp->swd_active--;
d1746 1
a1746 1
int
d2021 1
a2021 1
void
@


1.90
log
@don't grab the lock just to read uvmexp.free.

"that's retarded" art@@.
@
text
@d361 2
d364 2
@


1.89
log
@add a flexible buffer queue (bufq) api, based on the never used
one by tedu@@. It doesn't do anything smart yet, it just uses
plain old disksort. we also keep the old method of queueing bufs
since some miods have crazy MD drivers that need some love.

ok beck@@, art@@
tested by many on many archs.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.87 2009/03/23 22:07:41 oga Exp $	*/
a360 2
	uvm_lock_fpageq();

a361 2

	uvm_unlock_fpageq();
@


1.88
log
@Remove static qualifier of functions that are not inline.
Makes trace in ddb useful.

ok oga
@
text
@d141 2
a142 1
	struct buf		swd_tab;	/* buffer list */
d806 1
d1153 1
d1388 1
a1388 1
		disksort(&sdp->swd_tab, &nbp->vb_buf);
d1431 2
a1432 2
	while (sdp->swd_tab.b_active < sdp->swd_maxactive) {
		bp = sdp->swd_tab.b_actf;
d1435 1
a1435 2
		sdp->swd_tab.b_actf = bp->b_actf;
		sdp->swd_tab.b_active++;
d1519 1
a1519 1
	sdp->swd_tab.b_active--;
@


1.87
log
@turn a for (i = 0; i < size; i++) arc4random(); loop into arc4random_buf().

Since that function is now so small (2 lines), inline it into it's only user.

Shaves some bytes (104 on amd64).

ok deraadt@@, blambert@@. djm@@ liked an earlier diff.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.86 2009/03/20 15:19:04 oga Exp $	*/
d232 2
a233 2
static void		 swapdrum_add(struct swapdev *, int);
static struct swapdev	*swapdrum_getsdp(int);
d235 3
a237 4
static struct swapdev	*swaplist_find(struct vnode *, int);
static void		 swaplist_insert(struct swapdev *, 
					     struct swappri *, int);
static void		 swaplist_trim(void);
d239 2
a240 2
static int swap_on(struct proc *, struct swapdev *);
static int swap_off(struct proc *, struct swapdev *);
d242 3
a244 3
static void sw_reg_strategy(struct swapdev *, struct buf *, int);
static void sw_reg_iodone(struct buf *);
static void sw_reg_start(struct swapdev *);
d246 1
a246 1
static int uvm_swap_io(struct vm_page **, int, int, int);
d248 1
a248 1
static void swapmount(void);
d478 1
a478 1
static void
d530 1
a530 1
static struct swapdev *
d563 1
a563 1
static void
d584 1
a584 1
static void
d604 1
a604 1
static struct swapdev *
d892 1
a892 1
static int
d1090 1
a1090 1
static int
d1239 1
a1239 1
static void
d1416 1
a1416 1
static void
d1451 1
a1451 1
static void
d1745 1
a1745 1
static int
d2020 1
a2020 1
static void
@


1.86
log
@While working on some stuff in uvm I've gotten REALLY sick of reading
K&R function declarations, so switch them all over to ansi-style, in
accordance with the prophesy.

"go for it" art@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.85 2009/01/25 17:30:49 miod Exp $	*/
d55 1
@


1.85
log
@Remove /dev/drum and related code.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.84 2008/09/16 18:52:52 chl Exp $	*/
d265 1
a265 1
uvm_swap_init()
d402 1
a402 1
		     int decrypt)
d479 1
a479 4
swaplist_insert(sdp, newspp, priority)
	struct swapdev *sdp;
	struct swappri *newspp;
	int priority;
d531 1
a531 3
swaplist_find(vp, remove)
	struct vnode *vp;
	boolean_t remove;
d564 1
a564 1
swaplist_trim()
d585 1
a585 3
swapdrum_add(sdp, npages)
	struct swapdev *sdp;
	int	npages;
d605 1
a605 2
swapdrum_getsdp(pgno)
	int pgno;
d628 1
a628 4
sys_swapctl(p, v, retval)
	struct proc *p;
	void *v;
	register_t *retval;
d893 1
a893 3
swap_on(p, sdp)
	struct proc *p;
	struct swapdev *sdp;
d1091 1
a1091 3
swap_off(p, sdp)
	struct proc *p;
	struct swapdev *sdp;
d1166 1
a1166 2
swstrategy(bp)
	struct buf *bp;
d1240 1
a1240 4
sw_reg_strategy(sdp, bp, bn)
	struct swapdev	*sdp;
	struct buf	*bp;
	int		bn;
d1417 1
a1417 2
sw_reg_start(sdp)
	struct swapdev	*sdp;
d1452 1
a1452 2
sw_reg_iodone(bp)
	struct buf *bp;
d1533 1
a1533 3
uvm_swap_alloc(nslots, lessok)
	int *nslots;	/* IN/OUT */
	boolean_t lessok;
d1601 1
a1601 3
uvm_swap_markbad(startslot, nslots)
	int startslot;
	int nslots;
d1628 1
a1628 3
uvm_swap_free(startslot, nslots)
	int startslot;
	int nslots;
d1692 1
a1692 5
uvm_swap_put(swslot, ppsp, npages, flags)
	int swslot;
	struct vm_page **ppsp;
	int	npages;
	int	flags;
d1709 1
a1709 3
uvm_swap_get(page, swslot, flags)
	struct vm_page *page;
	int swslot, flags;
d1746 1
a1746 3
uvm_swap_io(pps, startslot, npages, flags)
	struct vm_page **pps;
	int startslot, npages, flags;
d2021 1
a2021 1
swapmount()
@


1.84
log
@remove dead stores and newly created unused variables.

Found by LLVM/Clang Static Analyzer.

ok miod@@ art@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.83 2008/09/13 12:33:52 chl Exp $	*/
a215 4
/* /dev/drum */
bdev_decl(sw);
cdev_decl(sw);

a1173 34

/*
 * swread: the read function for the drum (just a call to physio)
 */
/*ARGSUSED*/
int
swread(dev, uio, ioflag)
	dev_t dev;
	struct uio *uio;
	int ioflag;
{
	UVMHIST_FUNC("swread"); UVMHIST_CALLED(pdhist);

	UVMHIST_LOG(pdhist, "  dev=%lx offset=%lx",
	    dev, (u_long)uio->uio_offset, 0, 0);
	return (physio(swstrategy, NULL, dev, B_READ, minphys, uio));
}

/*
 * swwrite: the write function for the drum (just a call to physio)
 */
/*ARGSUSED*/
int
swwrite(dev, uio, ioflag)
	dev_t dev;
	struct uio *uio;
	int ioflag;
{
	UVMHIST_FUNC("swwrite"); UVMHIST_CALLED(pdhist);

	UVMHIST_LOG(pdhist, "  dev=%lx offset=%lx",
	    dev, (u_long)uio->uio_offset, 0, 0);
	return (physio(swstrategy, NULL, dev, B_WRITE, minphys, uio));
}
@


1.83
log
@fix potential use of uninitialized value

Found by LLVM/Clang Static Analyzer.

"Right." miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.82 2008/06/12 06:58:40 deraadt Exp $	*/
a360 1
	int minus, reserve;
a365 2
	minus = uvmexp.free - npages;
	reserve = uvmexp.reserve_kernel;
@


1.82
log
@Bring biomem diff back into the tree after the nfs_bio.c fix went in.
ok thib beck art
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.80 2008/06/10 20:50:23 beck Exp $	*/
d1115 1
a1115 1
	int error;
@


1.81
log
@back out biomem diff since it is not right yet.  Doing very large
file copies to nfsv2 causes the system to eventually peg the console.
On the console ^T indicates that the load is increasing rapidly, ddb
indicates many calls to getbuf, there is some very slow nfs traffic
making none (or extremely slow) progress.  Eventually some machines
seize up entirely.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.79 2008/06/02 15:42:21 miod Exp $	*/
d1983 1
a1983 1
	bp->b_flags = B_BUSY | B_NOCACHE | (flags & (B_READ|B_ASYNC));
@


1.80
log
@Fix buffer cache pending read statistics by ensuring we can identify
biowait() reads that do *not* come from the buffer cache - we use the
B_RAW flag to identify these at art's suggestion - since it makes sense
and the flag was not being used. this just flags all these buffers with
B_RAW - biodone already ignores returned buffers marked B_RAW.
ok art@@
@
text
@d1983 1
a1983 1
	bp->b_flags = B_BUSY | B_NOCACHE | B_RAW | (flags & (B_READ|B_ASYNC));
@


1.79
log
@Round up the numbers of keys to allocate, so that the last 128 page area
gets correctly encrypted if the swap isn't a multiple of 128 pages.

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.78 2008/04/12 20:37:36 miod Exp $	*/
d1983 1
a1983 1
	bp->b_flags = B_BUSY | B_NOCACHE | (flags & (B_READ|B_ASYNC));
@


1.78
log
@Prune the in-use swap encryption keys in uvm_shutdown(), per deraadt@@'s idea.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.77 2008/04/12 20:36:38 miod Exp $	*/
d145 1
d353 1
a353 1
	sdp->swd_keys = malloc((npages >> SWD_KEY_SHIFT) * sizeof(struct swap_key),
d461 1
a461 1
			key = sdp->swd_keys + ((nkeys  >> SWD_KEY_SHIFT) - 1);
@


1.77
log
@When enabling swap encryption, pass the correct number of swap pages to
uvm_swap_initcrypt. The number of available pages may not match, if we
are using a miniroot in the swap partition.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.76 2007/12/18 11:05:52 thib Exp $	*/
a153 1
	int			swd_nkeys;	/* active keys */
a353 1
	sdp->swd_nkeys = 0;
d443 26
d470 1
d1736 7
a1742 2
				if (uvm_swap_needdecrypt(sdp, startslot + i))
					SWAP_KEY_PUT(sdp, SWD_KEY(sdp, startslot + i));
d2046 1
a2046 1
		struct swap_key *key = NULL;
d2052 4
@


1.76
log
@Turn the uvm_{lock/unlock}_fpageq() inlines into
macros that just expand into the mutex functions
to keep the abstraction, do assorted cleanup.

ok miod@@,art@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.75 2007/11/27 18:01:02 deraadt Exp $	*/
d326 1
d332 5
a336 2
			if (sdp->swd_decrypt == NULL)
				uvm_swap_initcrypt(sdp, sdp->swd_npages);
d1035 3
a1037 2
		rootpages = round_page(dbtob(rootblocks)) >> PAGE_SHIFT;
		if (rootpages > size)
d1208 1
a1208 1
	pageno = dbtob((int64_t)bp->b_blkno) >> PAGE_SHIFT;
@


1.75
log
@Shoot old netbsd compat code from almost 20 years ago; ok art
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.74 2007/10/29 17:08:08 chl Exp $	*/
d357 1
a357 1
	int i, s;
d362 1
a362 1
	s = uvm_lock_fpageq();
d368 1
a368 1
	uvm_unlock_fpageq(s);
@


1.74
log
@MALLOC/FREE -> malloc/free

ok krw@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.73 2007/09/07 15:00:20 art Exp $	*/
d663 1
a663 5
	if (SCARG(uap, cmd) == SWAP_STATS
#if defined(COMPAT_13)
	    || SCARG(uap, cmd) == SWAP_OSTATS
#endif
	    ) {
a678 3
#if defined(COMPAT_13)
				if (error == 0 && SCARG(uap, cmd) == SWAP_STATS)
#else
a679 1
#endif
d686 1
a686 6
#if defined(COMPAT_13)
				if (SCARG(uap, cmd) == SWAP_OSTATS)
					((struct oswapent *)sep)++;
				else
#endif
					sep++;
@


1.73
log
@Use M_ZERO in a few more places to shave bytes from the kernel.

eyeballed and ok dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.72 2007/06/18 21:51:15 pedro Exp $	*/
d491 1
a491 1
		FREE(newspp, M_VMSWAP);
@


1.72
log
@Bring back Mickey's UVM anon change. Testing by thib@@, beck@@ and
ckuethe@@ for a while. Okay beck@@, "it is good timing" deraadt@@.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.71 2007/06/06 17:15:14 deraadt Exp $	*/
d347 2
a348 2
	sdp->swd_decrypt = malloc(SWD_DCRYPT_SIZE(npages), M_VMSWAP, M_WAITOK);
	memset(sdp->swd_decrypt, 0, SWD_DCRYPT_SIZE(npages));
d350 1
a350 2
			       M_VMSWAP, M_WAITOK);
	memset(sdp->swd_keys, 0, (npages >> SWD_KEY_SHIFT) * sizeof(struct swap_key));
d801 1
a801 1
		sdp = malloc(sizeof *sdp, M_VMSWAP, M_WAITOK);
a802 1
		memset(sdp, 0, sizeof(*sdp));
d2092 1
a2092 1
	sdp = malloc(sizeof(*sdp), M_VMSWAP, M_WAITOK);
a2093 1
	memset(sdp, 0, sizeof(*sdp));
@


1.71
log
@now that all partition size/offsets are potentially 64-bit, change the
type of all variables to daddr64_t.  this includes the APIs for XXsize()
and XXdump(), all range checks inside bio drivers, internal variables
for disklabel handling, and even uvm's swap offsets.  re-read numerous
times by otto, miod, krw, thib to look for errors
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.70 2007/06/01 07:35:35 deraadt Exp $	*/
a1063 5
  	/*
	 * add anons to reflect the new swap space
	 */
	uvm_anon_add(size);

d1099 1
d1116 1
a1116 1
	    anon_swap_off(sdp->swd_drumoffset,
d1119 6
d1128 1
a1128 1
		return ENOMEM;
a1129 1
	KASSERT(sdp->swd_npginuse == sdp->swd_npgbad);
a1142 3

	/* remove anons from the system */
	uvm_anon_remove(sdp->swd_npages);
@


1.70
log
@wrong cast checking for VOP_BMAP return value; ok miod
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.69 2007/05/29 00:17:33 thib Exp $	*/
d1367 1
a1367 1
			    "vp %p/%p offset 0x%lx/0x%lx",
d1805 1
a1805 1
	daddr_t startblk;
@


1.69
log
@Add a name argument to the RWLOCK_INITIALIZER macro.
Pick reasonble names for the locks involved..

ok tedu@@, art@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.68 2007/04/13 18:57:49 art Exp $	*/
d1330 1
a1330 1
		if (error == 0 && nbn == (daddr_t)-1) {
@


1.68
log
@While splitting flags and pqflags might have been a good idea in theory
to separate locking, on most modern machines this is not enough
since operations on short types touch other short types that share the
same word in memory.

Merge pg_flags and pqflags again and now use atomic operations to change
the flags. Also bump wire_count to an int and pg_version might go
int as well, just for alignment.

tested by many, many. ok miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.67 2007/01/12 07:41:31 art Exp $	*/
d230 1
a230 1
struct rwlock swap_syscall_lock = RWLOCK_INITIALIZER;
@


1.67
log
@Switch some lockmgr locks to rwlocks.
In this commit:
 - gdt lock on amd64
 - sysctl lock
 - malloc sysctl lock
 - disk sysctl lock
 - swap syscall lock

miod@@, pedro@@ ok (and "looks good" others@@)
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.66 2006/10/03 19:49:06 pedro Exp $	*/
d1902 1
a1902 1
			tpps[i]->pqflags |= PQ_ENCRYPT;
@


1.66
log
@Introduce daddr64_t and use it for physical block numbers
Okay weingart@@, "I'm game with putting my name on it" dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.65 2006/07/31 11:51:29 mickey Exp $	*/
d230 1
a230 1
lock_data_t swap_syscall_lock;
a281 1
	lockinit(&swap_syscall_lock, PVM, "swapsys", 0, 0);
d640 1
a640 1
	lockmgr(&swap_syscall_lock, LK_EXCLUSIVE, NULL);
d879 1
a879 1
	lockmgr(&swap_syscall_lock, LK_RELEASE, NULL);
@


1.65
log
@fix uvmhist #2: args are always u_long so fix missing %d and %x and no %ll; no change for normal code
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.64 2006/07/26 23:15:55 mickey Exp $	*/
d1291 1
a1291 1
	daddr_t		nbn;
@


1.64
log
@fix fmts for UVMHIST_LOG() entries making it more useful on 64bit archs; miod@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.63 2006/07/13 22:51:26 deraadt Exp $	*/
d481 1
a481 1
		UVMHIST_LOG(pdhist, "created new swappri = %d",
d650 1
a650 1
		UVMHIST_LOG(pdhist, "<- done SWAP_NSWAP=%d", uvmexp.nswapdev,
d882 1
a882 1
	UVMHIST_LOG(pdhist, "<- done!  error=%d", error, 0, 0, 0);
d934 1
a934 1
	UVMHIST_LOG(pdhist, "  dev=%d, major(dev)=%d", dev, major(dev), 0,0);
d1015 1
a1015 1
	UVMHIST_LOG(pdhist, "  dev=%x: size=%d addr=0x%lx\n",
d1106 1
a1106 1
	UVMHIST_LOG(pdhist, "  dev=%x", sdp->swd_dev,0,0,0);
d1181 2
a1182 1
	UVMHIST_LOG(pdhist, "  dev=%x offset=%llx", dev, uio->uio_offset, 0, 0);
d1198 2
a1199 1
	UVMHIST_LOG(pdhist, "  dev=%x offset=%llx", dev, uio->uio_offset, 0, 0);
d1242 1
a1242 1
	UVMHIST_LOG(pdhist, "  %s: mapoff=%x bn=0x%x bcount=%ld",
d1368 2
a1369 2
			    "vp %p/%p offset 0x%llx/0x%x",
			    sdp->swd_vp, vp, byteoff, nbn);
d1484 1
a1484 1
		    "sw_reg_start:  bp %p vp %p blkno 0x%x cnt 0x%lx",
d1510 1
a1510 1
	UVMHIST_LOG(pdhist, "  vbp=%p vp=%p blkno=0x%x addr=%p",
d1522 1
a1522 1
		UVMHIST_LOG(pdhist, "  got error=%d !",
d1556 1
a1556 1
			UVMHIST_LOG(pdhist, "  iodone error=%d !",
d1629 1
a1629 1
			    "success!  returning %d slots starting at %d",
d1669 1
a1669 1
		UVMHIST_LOG(pdhist, "now %d bad", sdp->swd_npgbad, 0,0,0);
d1688 1
a1688 1
	UVMHIST_LOG(pdhist, "freeing %d slots starting at %d", nslots,
d1819 1
a1819 1
	UVMHIST_LOG(pdhist, "<- called, startslot=%d, npages=%d, flags=%d",
d2004 1
a2004 1
	    "about to start io: data = %p blkno = 0x%x, bcount = %ld",
d2070 1
a2070 1
	UVMHIST_LOG(pdhist, "<- done (sync)  result=%d", result, 0, 0, 0);
@


1.63
log
@Back out the anon change.  Apparently it was tested by a few, but most of
us did not see it or get a chance to test it before it was commited. It
broke cvs, in the ami driver, making it not succeed at seeing it's devices.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.61 2005/11/19 02:18:02 pedro Exp $	*/
d1015 2
a1016 1
	UVMHIST_LOG(pdhist, "  dev=%x: size=%d addr=%ld\n", dev, size, addr, 0);
d1240 1
a1240 1
	UVMHIST_LOG(pdhist, "  %s: mapoff=%x bn=%x bcount=%ld",
d1366 1
a1366 1
			    "vp %p/%p offset 0x%x/0x%x",
d1482 1
a1482 1
		    "sw_reg_start:  bp %p vp %p blkno %p cnt %lx",
d1508 1
a1508 1
	UVMHIST_LOG(pdhist, "  vbp=%p vp=%p blkno=%x addr=%p",
@


1.62
log
@from netbsd: make anons dynamically allocated from pool.
this results in lesse kva waste due to static preallocation of those
for every phys page and also every swap page.
tested by beck krw miod
@
text
@d1064 5
a1103 1
	int error;
d1120 1
a1120 1
	    amap_swap_off(sdp->swd_drumoffset,
a1122 6
		error = ENOMEM;
	} else if (sdp->swd_npginuse > sdp->swd_npgbad) {
		error = EBUSY;
	}

	if (error) {
d1126 1
a1126 1
		return (error);
d1128 1
d1142 3
@


1.61
log
@Remove unnecessary lockmgr() archaism that was costing too much in terms
of panics and bugfixes. Access curproc directly, do not expect a process
pointer as an argument. Should fix many "process context required" bugs.
Incentive and okay millert@@, okay marc@@. Various testing, thanks.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.60 2004/12/26 21:22:14 miod Exp $	*/
a1063 5
  	/*
	 * add anons to reflect the new swap space
	 */
	uvm_anon_add(size);

d1099 1
d1116 1
a1116 1
	    anon_swap_off(sdp->swd_drumoffset,
d1119 6
d1128 1
a1128 1
		return ENOMEM;
a1129 1
	KASSERT(sdp->swd_npginuse == sdp->swd_npgbad);
a1142 3

	/* remove anons from the system */
	uvm_anon_remove(sdp->swd_npages);
@


1.60
log
@Use list and queue macros where applicable to make the code easier to read;
no change in compiler assembly output.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.59 2004/09/23 06:31:35 tedu Exp $	*/
d641 1
a641 1
	lockmgr(&swap_syscall_lock, LK_EXCLUSIVE, NULL, p);
d880 1
a880 1
	lockmgr(&swap_syscall_lock, LK_RELEASE, NULL, p);
@


1.59
log
@vput on all paths after vget (currently unused code). from patrick latifi
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.58 2003/12/10 07:34:03 itojun Exp $	*/
d330 2
a331 5
	for (spp = swap_priority.lh_first; spp != NULL;
	     spp = spp->spi_swappri.le_next) {
		for (sdp = spp->spi_swapdev.cqh_first;
		     sdp != (void *)&spp->spi_swapdev;
		     sdp = sdp->swd_next.cqe_next)
@


1.58
log
@dstkva is not a pointer, so comparison with NULL is inappropriate.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.57 2003/12/02 01:52:32 mickey Exp $	*/
d765 1
a765 1
			goto out;
d870 1
a870 3
		if ((error = swap_off(p, sdp)) != 0)
			goto out;

@


1.57
log
@do not deref null ptr in uvm_markbad() returned from swapdrum_getsdp() as others callers do
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.56 2003/08/15 20:32:21 tedu Exp $	*/
d1891 1
a1891 1
		if (dstkva == NULL) {
@


1.56
log
@change arguments to suser.  suser now takes the process, and a flags
argument.  old cred only calls user suser_ucred.  this will allow future
work to more flexibly implement the idea of a root process.  looks like
something i saw in freebsd, but a little different.
use of suser_ucred vs suser in file system code should be looked at again,
for the moment semantics remain unchanged.
review and input from art@@  testing and further review miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.55 2002/10/12 01:09:45 krw Exp $	*/
d1663 10
a1672 10

	/*
	 * we just keep track of how many pages have been marked bad
	 * in this device, to make everything add up in swap_off().
	 * we assume here that the range of slots will all be within
	 * one swap device.
	 */

	sdp->swd_npgbad += nslots;
	UVMHIST_LOG(pdhist, "now %d bad", sdp->swd_npgbad, 0,0,0);
@


1.55
log
@Remove more '\n's from panic() statements. Both trailing and leading.

Diff generated by Chris Kuethe.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.54 2002/07/02 19:38:55 nate Exp $	*/
d718 1
a718 1
	if ((error = suser(p->p_ucred, &p->p_acflag)))
@


1.54
log
@inital -> initial
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.53 2002/05/24 13:10:53 art Exp $	*/
d1155 1
a1155 1
		panic("swap_off: swapdev not in list\n");
@


1.53
log
@Make sure that b_iodone handlers are called at splbio (and splassert(IPL_BIO) in all known callers, just to make sure).
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.52 2002/05/24 08:58:41 art Exp $	*/
d1723 1
a1723 1
		if (swap_encrypt_initalized) {
d1857 1
a1857 1
	if (swap_encrypt_initalized  || encrypt) { 
d1988 1
a1988 1
		if (swap_encrypt_initalized)
d2026 1
a2026 1
	if (swap_encrypt_initalized &&
@


1.52
log
@Protect biodone with splbio.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.51 2002/03/14 01:27:19 millert Exp $	*/
d1509 1
a1509 1
	int		s, resid;
d1517 1
a1517 3
	/*
	 * protect vbp at splbio and update.
	 */
a1518 1
	s = splbio();
a1569 1
	splx(s);
@


1.51
log
@First round of __P removal in sys
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.50 2002/01/28 03:16:27 art Exp $	*/
d1230 1
d1232 1
@


1.50
log
@PR_MALLOCOK is not necessary.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.49 2002/01/23 00:39:48 art Exp $	*/
d235 2
a236 2
static void		 swapdrum_add __P((struct swapdev *, int));
static struct swapdev	*swapdrum_getsdp __P((int));
d238 4
a241 4
static struct swapdev	*swaplist_find __P((struct vnode *, int));
static void		 swaplist_insert __P((struct swapdev *, 
					     struct swappri *, int));
static void		 swaplist_trim __P((void));
d243 2
a244 2
static int swap_on __P((struct proc *, struct swapdev *));
static int swap_off __P((struct proc *, struct swapdev *));
d246 3
a248 3
static void sw_reg_strategy __P((struct swapdev *, struct buf *, int));
static void sw_reg_iodone __P((struct buf *));
static void sw_reg_start __P((struct swapdev *));
d250 1
a250 1
static int uvm_swap_io __P((struct vm_page **, int, int, int));
d252 1
a252 1
static void swapmount __P((void));
d256 4
a259 4
boolean_t uvm_swap_allocpages __P((struct vm_page **, int));
void uvm_swap_markdecrypt __P((struct swapdev *, int, int, int));
boolean_t uvm_swap_needdecrypt __P((struct swapdev *, int));
void uvm_swap_initcrypt __P((struct swapdev *, int));
d912 1
a912 1
	extern int (**nfsv2_vnodeop_p) __P((void *));
@


1.49
log
@Pool deals fairly well with physical memory shortage, but it doesn't deal
well (not at all) with shortages of the vm_map where the pages are mapped
(usually kmem_map).

Try to deal with it:
 - group all information the backend allocator for a pool in a separate
   struct. The pool will only have a pointer to that struct.
 - change the pool_init API to reflect that.
 - link all pools allocating from the same allocator on a linked list.
 - Since an allocator is responsible to wait for physical memory it will
   only fail (waitok) when it runs out of its backing vm_map, carefully
   drain pools using the same allocator so that va space is freed.
   (see comments in code for caveats and details).
 - change pool_reclaim to return if it actually succeeded to free some
   memory, use that information to make draining easier and more efficient.
 - get rid of PR_URGENT, noone uses it.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.48 2002/01/02 22:23:25 miod Exp $	*/
d198 1
a198 1
	vnx = pool_get(&vndxfer_pool, PR_MALLOCOK|PR_WAITOK);		\
d208 1
a208 1
	vbp = pool_get(&vndbuf_pool, PR_MALLOCOK|PR_WAITOK);		\
@


1.48
log
@Back out a few more uvm changes, especially wrt swap usage.
This unbreaks m68k m88k sparc and perhaps others, which eventually froze
when hitting swap.
Tested by various people on various platforms.
ok art@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.39 2001/11/10 18:42:32 art Exp $	*/
d305 1
a305 1
			    0, NULL, NULL, 0);
d307 2
a308 2
	pool_init(&vndbuf_pool, sizeof(struct vndbuf), 0, 0, 0, "swp vnd", 0,
			    NULL, NULL, 0);
@


1.47
log
@UBC was a disaster. It worked very good when it worked, but on some
machines or some configurations or in some phase of the moon (we actually
don't know when or why) files disappeared. Since we've not been able to
track down the problem in two weeks intense debugging and we need -current
to be stable, back out everything to a state it had before UBC.

We apologise for the inconvenience.
@
text
@d1 2
a2 2
/*	$OpenBSD: uvm_swap.c,v 1.41 2001/11/15 23:15:15 art Exp $	*/
/*	$NetBSD: uvm_swap.c,v 1.46 2001/02/18 21:19:08 chs Exp $	*/
d765 1
a765 1
			break;
d870 3
a872 1
		error = swap_off(p, sdp);
a1063 9
  	/*
	 * try to add anons to reflect the new swap space.
	 */

	error = uvm_anon_add(size);
	if (error) {
		goto bad;
	}

d1069 5
d1090 1
d1092 1
a1092 1
	 * failure: clean up and return error.
d1094 1
a1094 6

bad:
	if (sdp->swd_ex) {
		extent_destroy(sdp->swd_ex);
	}
	if (vp != rootvp) {
a1095 1
	}
@


1.46
log
@Yet another sync to NetBSD uvm.
Today we add a pmap argument to pmap_update() and allocate map entries for
kernel_map from kmem_map instead of using the static entries. This should
get rid of MAX_KMAPENT panics. Also some uvm_loan problems are fixed.
@
text
@d1 2
a2 2
/*	$OpenBSD: uvm_swap.c,v 1.45 2001/11/30 05:45:33 csapuntz Exp $	*/
/*	$NetBSD: uvm_swap.c,v 1.53 2001/08/26 00:43:53 chs Exp $	*/
d66 1
a66 1
 *
d77 1
a77 1
 * by the "swap_priority" global var.    each "swappri" contains a
d102 1
a102 1
 *  [2] SWAP_STATS: given a pointer to an array of swapent structures
d230 1
a230 1
struct lock swap_syscall_lock;
d235 1
d239 1
a239 1
static void		 swaplist_insert __P((struct swapdev *,
d265 1
a265 1
 * => called at boot time from init_main.c after the filesystems
d291 1
a291 1
	 * that block 0 is reserved (used to indicate an allocation
d566 21
d599 1
a599 1

d604 1
a604 3
		     sdp = CIRCLEQ_NEXT(sdp, swd_next)) {
			if (sdp->swd_flags & SWF_FAKE)
				continue;
a608 1
		}
d649 1
a649 1
	 * SWAP_NSWAP: return number of config'd swap devices
d663 1
a663 1
	 * note that the swap_priority list can't change as long
d665 1
a665 1
	 * to grab the uvm.swap_data_lock because we may fault&sleep during
d681 1
a681 1
				sdp->swd_inuse =
d701 1
a701 2
					sep = (struct swapent *)
					    ((struct oswapent *)sep + 1);
d713 1
a713 1
	}
a799 2
		sdp = malloc(sizeof *sdp, M_VMSWAP, M_WAITOK);
		spp = malloc(sizeof *spp, M_VMSWAP, M_WAITOK);
d801 1
a801 1
		if (swaplist_find(vp, 0) != NULL) {
a803 2
			free(sdp, M_VMSWAP);
			free(spp, M_VMSWAP);
d806 2
a907 1
	u_long result;
d1036 1
a1036 1
	 * if the vnode we are swapping to is the root vnode
d1038 1
a1038 1
	 * to make sure we don't overwrite it.   do a statfs to
d1053 1
a1053 1
		if (extent_alloc_region(sdp->swd_ex, addr,
d1083 2
a1084 6
	if (extent_alloc(swapmap, npages, EX_NOALIGN, 0, EX_NOBOUNDARY,
	    EX_WAITOK, &result))
		panic("swapdrum_add");

	sdp->swd_drumoffset = (int)result;
	sdp->swd_drumsize = npages;
a1085 1
	simple_lock(&uvm.swap_data_lock);
d1134 1
a1134 1

a1163 1
	simple_unlock(&uvm.swap_data_lock);
d1172 1
d1339 1
a1339 1
			/*
d1396 26
d1542 3
a1544 1
	(void) buf_cleanout(&vbp->vb_buf);
d1607 1
a1607 1

d1711 2
a1712 2
	 * convert drum slot offset back to sdp, free the blocks
	 * in the extent, and return.   must hold pri lock to do
d1783 1
a1783 1
		return EIO;
a1788 1

d1793 1
a1793 1
	result = uvm_swap_io(&page, swslot, 1, B_READ |
d1796 1
a1796 2
	if (result != 0) {

a1799 1

d1820 1
a1820 1
	int	error, s, mapinflags, pflag;
d1850 1
a1850 1
		return (EAGAIN);
d1896 1
a1896 1
			return (EAGAIN);
d1903 1
a1903 1
			return (EAGAIN);
d1932 1
a1932 1
	/*
d1957 1
a1957 1
		return (EAGAIN);
d1988 3
a1990 2
	/*
	 * bump v_numoutput (counter of number of active outputs).
d1993 2
d2023 1
a2023 1
		return 0;
d2028 2
a2029 1
	error = biowait(bp);
d2070 3
a2074 2

	(void) buf_cleanout(bp);
d2081 2
a2082 2
	UVMHIST_LOG(pdhist, "<- done (sync)  error=%d", error, 0, 0, 0);
	return (error);
@


1.46.2.1
log
@Merge in -current, builds on i386, otherwise untested
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.50 2002/01/28 03:16:27 art Exp $	*/
d198 1
a198 1
	vnx = pool_get(&vndxfer_pool, PR_WAITOK);			\
d208 1
a208 1
	vbp = pool_get(&vndbuf_pool, PR_WAITOK);			\
d304 1
a304 1
	    NULL);
d306 2
a307 2
	pool_init(&vndbuf_pool, sizeof(struct vndbuf), 0, 0, 0, "swp vnd",
	    NULL);
d747 1
a747 1
			goto out;
d854 1
a854 3
		if ((error = swap_off(p, sdp)) != 0)
			goto out;

d1047 9
a1060 5
  	/*
	 * add anons to reflect the new swap space
	 */
	uvm_anon_add(size);

a1081 1
bad:
d1083 1
a1083 1
	 * failure: close device if necessary and return error.
d1085 6
a1090 1
	if (vp != rootvp)
d1092 1
@


1.46.2.2
log
@Merge in UBC performance changes from NetBSD.
Fix a bunch of merge errors from yesterday.
@
text
@d1 2
a2 2
/*	$OpenBSD: uvm_swap.c,v 1.46.2.1 2002/01/31 22:55:51 niklas Exp $	*/
/*	$NetBSD: uvm_swap.c,v 1.57 2001/11/10 07:37:01 lukem Exp $	*/
d193 2
a194 2
static struct pool vndxfer_pool;
static struct pool vndbuf_pool;
d303 2
a304 2
	pool_init(&vndxfer_pool, sizeof(struct vndxfer), 0, 0, 0,
	    "swp vnx", NULL);
d306 2
a307 2
	pool_init(&vndbuf_pool, sizeof(struct vndbuf), 0, 0, 0,
	    "swp vnd", NULL);
d471 2
a472 2
	pspp = NULL;
	LIST_FOREACH(spp, &swap_priority, spi_swappri) {
d525 5
a529 3

	LIST_FOREACH(spp, &swap_priority, spi_swappri) {
		CIRCLEQ_FOREACH(sdp, &spp->spi_swapdev, swd_next) {
a537 1
		}
d578 5
a582 2
	LIST_FOREACH(spp, &swap_priority, spi_swappri) {
		CIRCLEQ_FOREACH(sdp, &spp->spi_swapdev, swd_next) {
a589 1
	}
d657 2
a658 1
		LIST_FOREACH(spp, &swap_priority, spi_swappri) {
a1048 9
 	/*
	 * try to add anons to reflect the new swap space.
	 */

	error = uvm_anon_add(size);
	if (error) {
		goto bad;
	}

d1054 5
d1080 1
d1082 1
a1082 1
	 * failure: clean up and return error.
d1084 1
a1084 6

bad:
	if (sdp->swd_ex) {
		extent_destroy(sdp->swd_ex);
	}
	if (vp != rootvp) {
a1085 1
	}
d1569 5
a1573 2
	LIST_FOREACH(spp, &swap_priority, spi_swappri) {
		CIRCLEQ_FOREACH(sdp, &spp->spi_swapdev, swd_next) {
d1597 1
a1597 1
			return (result + sdp->swd_drumoffset);
d1609 1
a1609 1
	return 0;
d1705 1
a1706 1

d1711 2
a1712 2
	int npages;
	int flags;
d1714 1
a1714 1
	int error;
d1716 1
a1716 1
	error = uvm_swap_io(ppsp, swslot, npages, B_WRITE |
d1718 2
a1719 1
	return error;
d1726 1
a1727 1

d1733 1
a1733 1
	int error;
d1740 10
a1749 1
	error = uvm_swap_io(&page, swslot, 1, B_READ |
d1751 2
a1752 1
	if (error == 0) {
d1755 1
a1755 1
		 * this page is no longer only in swap.
d1759 1
a1759 2
		KASSERT(uvmexp.swpgonly > 0);
		uvmexp.swpgonly--;
d1762 2
a1763 1
	return error;
d1778 1
a1778 1
	int	error, s, mapinflags;
a1796 1

d1800 2
a1801 1
	 * first, map the pages into the kernel.
d1803 3
a1805 4

	mapinflags = !write ?
		UVMPAGER_MAPIN_WAITOK|UVMPAGER_MAPIN_READ :
		UVMPAGER_MAPIN_WAITOK|UVMPAGER_MAPIN_WRITE;
d1807 2
d1811 26
a1882 1
#ifdef XXXART
d1885 1
a1885 1
#endif
d1892 1
a1893 1

d1895 2
a1896 1
	bp = pool_get(&bufpool, PR_WAITOK);
d1899 19
d1920 1
a1920 1
	 * ASYNC reads and swap encryption don't work together.
d1922 2
a1923 3
	 * assumes that all gets are SYNCIO. Just make sure here.
	 * XXX - We can't really remove the async flag, so just panic and
	 * hopefully this will be catched before being comitted.
d1925 3
a1927 2
	if (!write && (flags & B_ASYNC) != 0) {
		panic("uvm_swap_io: async read");
d1931 1
a1931 1
	 * fill in the bp/sbp.   we currently route our i/o through
a1933 1

a1938 1
	bp->b_bufsize = bp->b_bcount = npages << PAGE_SHIFT;
d1944 1
a1948 1

d1950 5
a1962 1

d1964 2
a1965 1
		bp->b_flags |= B_CALL;
a1975 1

a1982 1

a2010 1

d2021 1
a2021 1
	 * now dispose of the buf and we're done.
a2022 1

d2026 1
d2031 3
@


1.46.2.3
log
@Sync UBC branch to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.46.2.2 2002/02/02 03:28:27 art Exp $	*/
d235 1
a235 1
static struct swapdev	*swapdrum_getsdp(int);
d242 2
a243 2
static int swap_on(struct proc *, struct swapdev *);
static int swap_off(struct proc *, struct swapdev *);
d245 3
a247 3
static void sw_reg_strategy(struct swapdev *, struct buf *, int);
static void sw_reg_iodone(struct buf *);
static void sw_reg_start(struct swapdev *);
d249 1
a249 1
static int uvm_swap_io(struct vm_page **, int, int, int);
d251 1
a251 1
static void swapmount(void);
d255 4
a258 4
boolean_t uvm_swap_allocpages(struct vm_page **, int);
void uvm_swap_markdecrypt(struct swapdev *, int, int, int);
boolean_t uvm_swap_needdecrypt(struct swapdev *, int);
void uvm_swap_initcrypt(struct swapdev *, int);
d893 1
a893 1
	extern int (**nfsv2_vnodeop_p)(void *);
a1224 1
		s = splbio();
a1225 1
		splx(s);
d1476 1
a1476 1
	int resid;
d1484 3
a1486 1
	splassert(IPL_BIO);
d1488 1
d1538 1
@


1.46.2.4
log
@sync to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.46.2.3 2002/06/11 03:33:04 art Exp $	*/
d1150 1
a1150 1
		panic("swap_off: swapdev not in list");
d1687 1
a1687 1
		if (swap_encrypt_initialized) {
d1931 1
a1931 1
	if (swap_encrypt_initialized &&
@


1.46.2.5
log
@Huge sync to NetBSD plus lots of bugfixes.
 - uvm is as in netbsd-current minus uvm_map forward merge.
 - various locking bugfixes in nfs.
 - make sure that all specops and fifoops are correct in all vnodeop vectors.
 - make the filesystem code more like filsystem code and less like vm code.
@
text
@d1 2
a2 2
/*	$OpenBSD: uvm_swap.c,v 1.46.2.4 2002/10/29 00:36:50 art Exp $	*/
/*	$NetBSD: uvm_swap.c,v 1.73 2002/11/02 07:40:49 perry Exp $	*/
d97 1
d104 1
a104 2
 *	the current swap config into the array. The actual work is done 
 *	in the uvm_swap_stats(9) function.
d200 1
a200 1
} while (/*CONSTCOND*/ 0)
d210 1
a210 1
} while (/*CONSTCOND*/ 0)
d613 1
a613 1
	int	error, misc;
d646 26
a671 4
	if (SCARG(uap, cmd) == SWAP_STATS) {
		misc = MIN(uvmexp.nswapdev, misc);
		len = sizeof(struct swapent) * misc;
		sep = (struct swapent *)malloc(len, M_TEMP, M_WAITOK);
d673 12
a684 2
		uvm_swap_stats(SCARG(uap, cmd), sep, misc, retval);
		error = copyout(sep, (void *)SCARG(uap, arg), len);
a685 1
		free(sep, M_TEMP);
d687 3
a779 4
		memset(sdp, 0, sizeof(*sdp));
		sdp->swd_flags = SWF_FAKE;
		sdp->swd_vp = vp;
		sdp->swd_dev = (vp->v_type == VBLK) ? vp->v_rdev : NODEV;
d788 4
a870 52
/* 
 * swap_stats: implements swapctl(SWAP_STATS). The function is kept
 * away from sys_swapctl() in order to allow COMPAT_* swapctl() 
 * emulation to use it directly without going through sys_swapctl().
 * The problem with using sys_swapctl() there is that it involves
 * copying the swapent array to the stackgap, and this array's size
 * is not known at build time. Hence it would not be possible to 
 * ensure it would fit in the stackgap in any case.
 */
void
uvm_swap_stats(cmd, sep, sec, retval)
	int cmd;
	struct swapent *sep;
	int sec;
	register_t *retval;
{
	struct swappri *spp;
	struct swapdev *sdp;
	int count = 0;

	LIST_FOREACH(spp, &swap_priority, spi_swappri) {
		for (sdp = CIRCLEQ_FIRST(&spp->spi_swapdev);
		     sdp != (void *)&spp->spi_swapdev && sec-- > 0;
		     sdp = CIRCLEQ_NEXT(sdp, swd_next)) {
		  	/*
			 * backwards compatibility for system call.
			 * note that we use 'struct oswapent' as an
			 * overlay into both 'struct swapdev' and
			 * the userland 'struct swapent', as we
			 * want to retain backwards compatibility
			 * with NetBSD 1.3.
			 */
			sdp->swd_inuse =
			    btodb((u_int64_t)sdp->swd_npginuse <<
			    PAGE_SHIFT);
			(void)memcpy(sep, &sdp->swd_se,
			    sizeof(struct swapent));
			
			/* now copy out the path if necessary */
			if (cmd == SWAP_STATS)
				(void)memcpy(&sep->se_path, sdp->swd_path,
				    sdp->swd_pathlen);

			count++;
			sep++;
		}
	}

	*retval = count;
	return;
}

a1031 14
		/*
		 * XXX: sp->f_blocks isn't the total number of
		 * blocks in the filesystem, it's the number of
		 * data blocks.  so, our rootblocks almost
		 * definitely underestimates the total size 
		 * of the filesystem - how badly depends on the
		 * details of the filesystem type.  there isn't 
		 * an obvious way to deal with this cleanly
		 * and perfectly, so for now we just pad our 
		 * rootblocks estimate with an extra 5 percent.
		 */
		rootblocks += (rootblocks >> 5) +
			(rootblocks >> 6) +
			(rootblocks >> 7);
d1131 1
a1131 1
	 * done with the vnode.
d1432 1
a1432 1
 * => reqs are sorted by b_rawblkno (above)
d1478 1
a1478 1
	int resid, error;
d1492 4
a1495 1
	if (vbp->vb_buf.b_flags & B_ERROR) {
d1497 1
a1497 3
		error = vbp->vb_buf.b_error ? vbp->vb_buf.b_error : EIO;
		UVMHIST_LOG(pdhist, "  got error=%d !", error, 0, 0, 0);
		vnx->vx_error = error;
@


1.45
log
@Call buf_cleanout, which handles wakeups
@
text
@d1 2
a2 2
/*	$OpenBSD: uvm_swap.c,v 1.44 2001/11/28 19:28:15 art Exp $	*/
/*	$NetBSD: uvm_swap.c,v 1.52 2001/05/26 16:32:47 chs Exp $	*/
@


1.44
log
@Sync in more uvm from NetBSD. Mostly just cosmetic stuff.
Contains also support for page coloring.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.43 2001/11/28 13:47:40 art Exp $	*/
d1506 1
a1506 3
	if (vbp->vb_buf.b_vp != NULL) {
		brelvp(&vbp->vb_buf);
	}
a2030 3
	if (bp->b_vp)
		brelvp(bp);

d2033 2
@


1.43
log
@Sync in more uvm changes from NetBSD.
This time we're getting rid of KERN_* and VM_PAGER_* error codes and
use errnos instead.
@
text
@d1 2
a2 2
/*	$OpenBSD: uvm_swap.c,v 1.42 2001/11/27 05:27:12 art Exp $	*/
/*	$NetBSD: uvm_swap.c,v 1.47 2001/03/10 22:46:51 chs Exp $	*/
d66 1
a66 1
 * 
d77 1
a77 1
 * by the "swap_priority" global var.    each "swappri" contains a 
d102 1
a102 1
 *  [2] SWAP_STATS: given a pointer to an array of swapent structures 
d230 1
a230 1
lock_data_t swap_syscall_lock;
a234 1
static void		 swapdrum_add __P((struct swapdev *, int));
d238 1
a238 1
static void		 swaplist_insert __P((struct swapdev *, 
d264 1
a264 1
 * => called at boot time from init_main.c after the filesystems 
d290 1
a290 1
	 * that block 0 is reserved (used to indicate an allocation 
a564 21
 * swapdrum_add: add a "swapdev"'s blocks into /dev/drum's area.
 *
 * => caller must hold swap_syscall_lock
 * => uvm.swap_data_lock should be unlocked (we may sleep)
 */
static void
swapdrum_add(sdp, npages)
	struct swapdev *sdp;
	int	npages;
{
	u_long result;

	if (extent_alloc(swapmap, npages, EX_NOALIGN, 0, EX_NOBOUNDARY,
	    EX_WAITOK, &result))
		panic("swapdrum_add");

	sdp->swd_drumoffset = result;
	sdp->swd_drumsize = npages;
}

/*
d577 1
a577 1
	
d582 3
a584 1
		     sdp = CIRCLEQ_NEXT(sdp, swd_next))
d589 1
d630 1
a630 1
	 * SWAP_NSWAP: return number of config'd swap devices 
d644 1
a644 1
	 * note that the swap_priority list can't change as long 
d646 1
a646 1
	 * to grab the uvm.swap_data_lock because we may fault&sleep during 
d662 1
a662 1
				sdp->swd_inuse = 
d682 2
a683 1
					((struct oswapent *)sep)++;
d695 1
a695 1
	} 
d782 2
d785 1
a785 1
		if ((sdp = swaplist_find(vp, 0)) != NULL) {
d788 2
a791 2
		sdp = malloc(sizeof *sdp, M_VMSWAP, M_WAITOK);
		spp = malloc(sizeof *spp, M_VMSWAP, M_WAITOK);
d892 1
d1021 1
a1021 1
	 * if the vnode we are swapping to is the root vnode 
d1023 1
a1023 1
	 * to make sure we don't overwrite it.   do a statfs to 
d1038 1
a1038 1
		if (extent_alloc_region(sdp->swd_ex, addr, 
d1068 7
a1075 2
	swapdrum_add(sdp, npages);
	sdp->swd_npages = size;
d1124 1
a1124 1
		
d1154 1
a1162 1
	simple_unlock(&uvm.swap_data_lock);
d1329 1
a1329 1
			/* 
d1571 1
a1571 1
	
d1675 2
a1676 2
	 * convert drum slot offset back to sdp, free the blocks 
	 * in the extent, and return.   must hold pri lock to do 
d1758 1
a1758 1
	result = uvm_swap_io(&page, swslot, 1, B_READ | 
d1899 1
a1899 1
	/* 
d1955 2
a1956 3
	/* 
	 * for pageouts we must set "dirtyoff" [NFS client code needs it].
	 * and we bump v_numoutput (counter of number of active outputs).
@


1.42
log
@Merge in the unified buffer cache code as found in NetBSD 2001/03/10. The
code is written mostly by Chuck Silvers <chuq@@chuq.com>/<chs@@netbsd.org>.

Tested for the past few weeks by many developers, should be in a pretty stable
state, but will require optimizations and additional cleanups.
@
text
@d1 2
a2 2
/*	$OpenBSD: uvm_swap.c,v 1.41 2001/11/15 23:15:15 art Exp $	*/
/*	$NetBSD: uvm_swap.c,v 1.46 2001/02/18 21:19:08 chs Exp $	*/
d1757 1
a1757 1
		return VM_PAGER_ERROR;
d1763 1
d1771 2
a1772 1
	if (result != VM_PAGER_OK && result != VM_PAGER_PEND) {
d1776 1
d1797 1
a1797 1
	int	result, s, mapinflags, pflag;
d1827 1
a1827 1
		return (VM_PAGER_AGAIN);
d1873 1
a1873 1
			return (VM_PAGER_AGAIN);
d1880 1
a1880 1
			return (VM_PAGER_AGAIN);
d1934 1
a1934 1
		return (VM_PAGER_AGAIN);
d1998 1
a1998 1
		return (VM_PAGER_PEND);
d2003 1
a2003 2
	(void) biowait(bp);
	result = (bp->b_flags & B_ERROR) ? VM_PAGER_ERROR : VM_PAGER_OK;
d2055 2
a2056 2
	UVMHIST_LOG(pdhist, "<- done (sync)  result=%d", result, 0, 0, 0);
	return (result);
@


1.41
log
@Remove creds from struct buf, move the creds that nfs need into the nfs node.
While in the area, convert nfs node allocation from malloc to pool and do
some cleanups.
Based on the UBC changes in NetBSD. niklas@@ ok.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.40 2001/11/12 01:26:10 art Exp $	*/
a1395 26
		/* 
		 * set b_dirtyoff/end and b_validoff/end.   this is
		 * required by the NFS client code (otherwise it will
		 * just discard our I/O request).
		 */
		if (bp->b_dirtyend == 0) {
			nbp->vb_buf.b_dirtyoff = 0;
			nbp->vb_buf.b_dirtyend = sz;
		} else {
			nbp->vb_buf.b_dirtyoff =
			    max(0, bp->b_dirtyoff - (bp->b_bcount-resid));
			nbp->vb_buf.b_dirtyend =
			    min(sz,
				max(0, bp->b_dirtyend - (bp->b_bcount-resid)));
		}
		if (bp->b_validend == 0) {
			nbp->vb_buf.b_validoff = 0;
			nbp->vb_buf.b_validend = sz;
		} else {
			nbp->vb_buf.b_validoff =
			    max(0, bp->b_validoff - (bp->b_bcount-resid));
			nbp->vb_buf.b_validend =
			    min(sz,
				max(0, bp->b_validend - (bp->b_bcount-resid)));
		}

a1966 2
		bp->b_dirtyoff = 0;
		bp->b_dirtyend = npages << PAGE_SHIFT;
@


1.40
log
@Bring in more changes from NetBSD. Mostly pagedaemon improvements.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.39 2001/11/10 18:42:32 art Exp $	*/
a1393 2
		nbp->vb_buf.b_rcred    = sdp->swd_cred;
		nbp->vb_buf.b_wcred    = sdp->swd_cred;
a1977 1
	bp->b_rcred = bp->b_wcred = proc0.p_ucred;
@


1.39
log
@Merge in some parts of the ubc work that has been done in NetBSD that are not
UBC, but prerequsites for it.

- Create a daemon that processes async I/O (swap and paging in the future)
  requests that need processing in process context and that were processed
  in the pagedaemon before.
- Convert some ugly ifdef DIAGNOSTIC code to less intrusive KASSERTs.
- misc other cleanups.
@
text
@d1 2
a2 2
/*	$OpenBSD: uvm_swap.c,v 1.38 2001/11/07 02:55:50 art Exp $	*/
/*	$NetBSD: uvm_swap.c,v 1.40 2000/11/17 11:39:39 mrg Exp $	*/
d134 1
d682 2
a683 1
				    btodb(sdp->swd_npginuse << PAGE_SHIFT);
d765 1
a765 1
			goto out;
a767 1
		
d870 1
a870 3
		if ((error = swap_off(p, sdp)) != 0)
			goto out;

a912 1
	char *name;
d1023 2
a1024 2
	name = malloc(12, M_VMSWAP, M_WAITOK);
	sprintf(name, "swap0x%04x", count++);
d1027 1
a1027 1
	sdp->swd_ex = extent_create(name, 0, npages - 1, M_VMSWAP,
d1062 9
a1075 5
  	/*
	 * add anons to reflect the new swap space
	 */
	uvm_anon_add(size);

a1091 1
bad:
d1093 1
a1093 1
	 * failure: close device if necessary and return error.
d1095 6
a1100 1
	if (vp != rootvp)
d1102 1
a1115 1
	void *name;
d1140 1
a1140 7

#ifdef DIAGNOSTIC
	if (sdp->swd_npginuse != sdp->swd_npgbad) {
		panic("swap_off: sdp %p - %d pages still in use (%d bad)\n",
		      sdp, sdp->swd_npginuse, sdp->swd_npgbad);
	}
#endif
a1169 1
	name = (void *)sdp->swd_ex->ex_name;
a1170 1
	free(name, M_VMSWAP);
d1247 1
a1247 1
	bn = btodb(pageno << PAGE_SHIFT);	/* convert to diskblock */
d1298 1
a1298 1
	daddr_t		nbn, byteoff;
d1300 1
d1322 1
a1322 1
	byteoff = dbtob(bn);
d1566 1
a1566 5
#ifdef DIAGNOSTIC
		if (vnx->vx_pending != 0)
			panic("sw_reg_iodone: vnx pending: %d",vnx->vx_pending);
#endif

d1707 1
d1717 1
d1720 3
a1722 10

#ifdef DIAGNOSTIC
	if (uvmexp.nswapdev < 1)
		panic("uvm_swap_free: uvmexp.nswapdev < 1\n");
	if (sdp == NULL) {
		printf("uvm_swap_free: startslot %d, nslots %d\n", startslot,
		    nslots);
		panic("uvm_swap_free: unmapped address\n");
	}
#endif
a1730 4
#ifdef DIAGNOSTIC
	if (sdp->swd_npginuse < 0)
		panic("uvm_swap_free: inuse < 0");
#endif
d1783 1
a1783 5
#ifdef DIAGNOSTIC
	if ((flags & PGO_SYNCIO) == 0)
		printf("uvm_swap_get: ASYNC get requested?\n");
#endif

d1841 1
a1841 1
	startblk = btodb(startslot << PAGE_SHIFT);
@


1.38
log
@Another sync of uvm to NetBSD. Just minor fiddling, no major changes.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.37 2001/11/06 01:35:04 art Exp $	*/
a79 5
 * the system maintains a fixed pool of "swapbuf" structures for use
 * at swap i/o time.  a swapbuf includes a "buf" structure and an 
 * "aiodone" [we want to avoid malloc()'ing anything at swapout time
 * since memory may be low].
 *
a86 2
 *  - swap_buf_lock (simple_lock): this lock protects the free swapbuf
 *    pool.
a167 9
 * swapbuf, swapbuffer plus async i/o info
 */
struct swapbuf {
	struct buf sw_buf;		/* a buffer structure */
	struct uvm_aiodesc sw_aio;	/* aiodesc structure, used if ASYNC */
	SIMPLEQ_ENTRY(swapbuf) sw_sq;	/* free list pointer */
};

/*
a222 2
SIMPLEQ_HEAD(swapbufhead, swapbuf);
struct pool swapbuf_pool;
a248 2
static void uvm_swap_aiodone __P((struct uvm_aiodesc *));
static void uvm_swap_bufdone __P((struct buf *));
a255 1
void uvm_swap_freepages __P((struct vm_page **, int));
d299 1
a299 3
	 * allocate our private pool of "swapbuf" structures (includes
	 * a "buf" structure).  ["nswbuf" comes from param.c and can
	 * be adjusted by MD code before we get here].
a302 4
	pool_init(&swapbuf_pool, sizeof(struct swapbuf), 0, 0, 0, "swp buf", 0,
			    NULL, NULL, 0);
	/* XXX - set a maximum on swapbuf_pool? */

d1232 1
a1232 1
	pageno = dbtob(bp->b_blkno) >> PAGE_SHIFT;
d1251 1
a1251 1
	UVMHIST_LOG(pdhist, "  %s: mapoff=%x bn=%x bcount=%ld\n",
a1368 1
		 * XXXCDC: ignores read-ahead for non-zero offset
d1370 3
a1372 6
		if ((off = (byteoff % sdp->swd_bsize)) != 0)
			sz = sdp->swd_bsize - off;
		else
			sz = (1 + nra) * sdp->swd_bsize;

		if (resid < sz)
d1375 3
a1377 2
		UVMHIST_LOG(pdhist, "sw_reg_strategy: vp %p/%p offset 0x%x/0x%x",
				sdp->swd_vp, vp, byteoff, nbn);
d1439 1
a1439 1
		bgetvp(vp, &nbp->vb_buf);	
d1498 1
d1545 1
a1545 8
	if (vbp->vb_buf.b_vp != NULLVP) {
		brelvp(&vbp->vb_buf);
	}

	/*
	 * disassociate this buffer from the vnode (if any).
	 */
	if (vbp->vb_buf.b_vp != NULLVP) {
d1686 1
d1688 1
a1688 1

a1837 1
	struct swapbuf *sbp;
d1841 1
d1853 3
d1863 4
a1866 7
	 * by buffer system).   note that we don't let pagermapin alloc
	 * an aiodesc structure because we don't want to chance a malloc.
	 * we've got our own pool of aiodesc structures (in swapbuf).
	 */
	mapinflags = (flags & B_READ) ? UVMPAGER_MAPIN_READ :
	    UVMPAGER_MAPIN_WRITE;
	if ((flags & B_ASYNC) == 0)
d1868 1
a1868 1
	kva = uvm_pagermapin(pps, npages, NULL, mapinflags);
d1873 1
a1873 1
	if ((flags & B_READ) == 0) {
d1902 1
a1902 1
	if ((flags & B_READ) == 0 && encrypt) {
d1911 1
a1911 1
		if ((flags & B_ASYNC) == 0)
d1919 1
a1919 1
		dstkva = uvm_pagermapin(tpps, npages, NULL, swmapflags);
d1953 1
a1953 1
	 * now allocate a swap buffer off of freesbufs
d1957 3
a1959 5
	pflag = ((flags & B_ASYNC) != 0 || curproc == uvm.pagedaemon_proc)
		? 0
		: PR_WAITOK;
	sbp = pool_get(&swapbuf_pool, pflag);
	splx(s);		/* drop splbio */
d1964 1
a1964 1
	if (sbp == NULL) {
d1966 1
a1966 1
		if ((flags & B_READ) == 0 && encrypt) {
d1985 1
d1987 1
a1987 1
	if (flags & B_READ)
d1989 2
d1993 1
a1993 1
	 * fill in the bp/sbp.   we currently route our i/o through
a1995 1
	bp = &sbp->sw_buf;
d2007 1
a2007 1
	bp->b_bcount = npages << PAGE_SHIFT;
d2013 1
a2013 1
	if ((bp->b_flags & B_READ) == 0) {
d2027 1
a2027 2
	 * for async ops we must set up the aiodesc and setup the callback
	 * XXX: we expect no async-reads, but we don't prevent it here.
d2029 4
a2032 7
	if (flags & B_ASYNC) {
		sbp->sw_aio.aiodone = uvm_swap_aiodone;
		sbp->sw_aio.kva = kva;
		sbp->sw_aio.npages = npages;
		sbp->sw_aio.pd_ptr = sbp;	/* backpointer */
		bp->b_flags |= B_CALL;		/* set callback */
		bp->b_iodone = uvm_swap_bufdone;/* "buf" iodone function */
d2036 1
a2036 1
	    "about to start io: data = 0x%p blkno = 0x%x, bcount = %ld",
d2043 1
a2043 1
	if (flags & B_ASYNC)
d2049 1
a2049 1
	bp->b_error = biowait(bp);
d2088 1
a2088 1
	 * now dispose of the swap buffer
d2094 3
a2096 1
	pool_put(&swapbuf_pool, sbp);
a2103 106
}

/*
 * uvm_swap_bufdone: called from the buffer system when the i/o is done
 */
static void
uvm_swap_bufdone(bp)
	struct buf *bp;
{
	struct swapbuf *sbp = (struct swapbuf *) bp;
	int	s = splbio();
	UVMHIST_FUNC("uvm_swap_bufdone"); UVMHIST_CALLED(pdhist);

	UVMHIST_LOG(pdhist, "cleaning buf %p", buf, 0, 0, 0);
#ifdef DIAGNOSTIC
	/*
	 * sanity check: swapbufs are private, so they shouldn't be wanted
	 */
	if (bp->b_flags & B_WANTED)
		panic("uvm_swap_bufdone: private buf wanted");
#endif

	/*
	 * drop the buffer's reference to the vnode.
	 */
	if (bp->b_vp)
		brelvp(bp);

	/*
	 * now put the aio on the uvm.aio_done list and wake the
	 * pagedaemon (which will finish up our job in its context).
	 */
	simple_lock(&uvm.pagedaemon_lock);	/* locks uvm.aio_done */
	TAILQ_INSERT_TAIL(&uvm.aio_done, &sbp->sw_aio, aioq);
	simple_unlock(&uvm.pagedaemon_lock);

	wakeup(&uvm.pagedaemon);
	splx(s);
}

/*
 * uvm_swap_aiodone: aiodone function for anonymous memory
 *
 * => this is called in the context of the pagedaemon (but with the
 *	page queues unlocked!)
 * => our "aio" structure must be part of a "swapbuf"
 */
static void
uvm_swap_aiodone(aio)
	struct uvm_aiodesc *aio;
{
	struct swapbuf *sbp = aio->pd_ptr;
	struct vm_page *pps[MAXBSIZE >> PAGE_SHIFT];
	int lcv, s;
	vaddr_t addr;
	UVMHIST_FUNC("uvm_swap_aiodone"); UVMHIST_CALLED(pdhist);

	UVMHIST_LOG(pdhist, "done with aio %p", aio, 0, 0, 0);
#ifdef DIAGNOSTIC
	/*
	 * sanity check
	 */
	if (aio->npages > (MAXBSIZE >> PAGE_SHIFT))
		panic("uvm_swap_aiodone: aio too big!");
#endif

	/*
	 * first, we have to recover the page pointers (pps) by poking in the
	 * kernel pmap (XXX: should be saved in the buf structure).
	 */
	for (addr = aio->kva, lcv = 0 ; lcv < aio->npages ; 
		addr += PAGE_SIZE, lcv++) {
		pps[lcv] = uvm_pageratop(addr);
	}

	/*
	 * now we can dispose of the kernel mappings of the buffer
	 */
	uvm_pagermapout(aio->kva, aio->npages);

	/*
	 * now we can dispose of the pages by using the dropcluster function
	 * [note that we have no "page of interest" so we pass in null]
	 */

#ifdef UVM_SWAP_ENCRYPT
	/*
	 * XXX - assumes that we only get ASYNC writes. used to be above.
	 */
	if (pps[0]->pqflags & PQ_ENCRYPT)
		uvm_swap_freepages(pps, aio->npages);
	else
#endif /* UVM_SWAP_ENCRYPT */
	uvm_pager_dropcluster(NULL, NULL, pps, &aio->npages, 
			      PGO_PDFREECLUST);

	/*
	 * finally, we can dispose of the swapbuf
	 */
	s = splbio();
	pool_put(&swapbuf_pool, sbp);
	splx(s);

	/*
	 * done!
	 */
@


1.37
log
@Move the last content from vm/ to uvm/
The only thing left in vm/ are just dumb wrappers.
vm/vm.h includes uvm/uvm_extern.h
vm/pmap.h includes uvm/uvm_pmap.h
vm/vm_page.h includes uvm/uvm_page.h
@
text
@d1 2
a2 2
/*	$OpenBSD: uvm_swap.c,v 1.36 2001/09/05 19:22:23 deraadt Exp $	*/
/*	$NetBSD: uvm_swap.c,v 1.38 2000/06/27 17:29:35 mrg Exp $	*/
d786 1
a872 6

		/*
		 * got it!   now add a second reference to vp so that
		 * we keep a reference to the vnode after we return.
		 */
		vref(vp);
d906 1
a906 1
	 * done!   use vput to drop our reference and unlock
d909 1
d1091 5
d1113 1
a1114 2
	uvmexp.swpages += size;

d1170 3
a1172 1
	 * done with the vnode.
d1177 1
a1179 3
	}
	if (sdp->swd_vp) {
		vrele(sdp->swd_vp);
@


1.36
log
@use %ll instead of %q
@
text
@d1 2
a2 2
/*	$OpenBSD: uvm_swap.c,v 1.35 2001/08/31 15:26:18 mickey Exp $	*/
/*	$NetBSD: uvm_swap.c,v 1.37 2000/05/19 03:45:04 thorpej Exp $	*/
a52 1
#include <vm/vm.h>
@


1.35
log
@do not init swapdev_vp if it's already done elsewhere; art@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.34 2001/08/11 10:57:22 art Exp $	*/
d1222 1
a1222 1
	UVMHIST_LOG(pdhist, "  dev=%x offset=%qx", dev, uio->uio_offset, 0, 0);
d1238 1
a1238 1
	UVMHIST_LOG(pdhist, "  dev=%x offset=%qx", dev, uio->uio_offset, 0, 0);
@


1.34
log
@Various random fixes from NetBSD.
Including support for zeroing pages in the idle loop (not enabled yet).
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.33 2001/08/06 22:34:44 mickey Exp $	*/
d306 1
a306 1
	if (bdevvp(swapdev, &swapdev_vp))
@


1.33
log
@remove vm_conf.h; art@@ ok
@
text
@d1 2
a2 2
/*	$OpenBSD: uvm_swap.c,v 1.32 2001/07/31 13:34:46 art Exp $	*/
/*	$NetBSD: uvm_swap.c,v 1.34 2000/02/07 20:16:59 thorpej Exp $	*/
d38 1
a51 1
#include <sys/conf.h>
a53 1

d232 3
d1580 7
d1877 1
a1877 1
	int	result, s, waitf, pflag;
d1900 6
a1905 3
	waitf = (flags & B_ASYNC) ? M_NOWAIT : M_WAITOK;
	kva = uvm_pagermapin(pps, npages, NULL, waitf);
	if (kva == NULL)
d1943 6
d1955 1
a1955 1
		dstkva = uvm_pagermapin(tpps, npages, NULL, waitf);
@


1.32
log
@minor sync to NetBSD.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.31 2001/07/26 19:37:13 art Exp $	*/
d51 1
a53 1
#include <vm/vm_conf.h>
@


1.31
log
@Add support for disabling swap devices (swapctl -d).
Improve error handling on I/O errors to swap.
From NetBSD
@
text
@d1 2
a2 2
/*	$OpenBSD: uvm_swap.c,v 1.30 2001/07/25 14:47:59 art Exp $	*/
/*	$NetBSD: uvm_swap.c,v 1.32 2000/01/11 06:57:51 chs Exp $	*/
@


1.30
log
@Some updates to UVM from NetBSD. Nothing really critical, just a sync.
@
text
@d1 2
a2 2
/*	$OpenBSD: uvm_swap.c,v 1.29 2001/07/18 14:28:01 art Exp $	*/
/*	$NetBSD: uvm_swap.c,v 1.31 2000/01/04 21:37:54 wrstuden Exp $	*/
a121 6
 * SWAP_TO_FILES: allows swapping to plain files.
 */

#define SWAP_TO_FILES

/*
d139 1
a145 1
#ifdef SWAP_TO_FILES
a149 1
#endif
d215 1
a215 2
	vnx = (struct vndxfer *)					\
		pool_get(&vndxfer_pool, PR_MALLOCOK|PR_WAITOK);		\
d225 1
a225 2
	vbp = (struct vndbuf *)						\
		pool_get(&vndbuf_pool, PR_MALLOCOK|PR_WAITOK);		\
a259 1
#ifdef SWAP_OFF_WORKS
a260 1
#endif
a261 1
#ifdef SWAP_TO_FILES
a264 1
#endif
d497 2
a498 2
	for (pspp = NULL, spp = swap_priority.lh_first; spp != NULL;
	     spp = spp->spi_swappri.le_next) {
d509 2
a510 1
		UVMHIST_LOG(pdhist, "created new swappri = %d", priority, 0, 0, 0);
a530 4

	/*
	 * done!
	 */
d551 3
a553 3
	for (spp = swap_priority.lh_first; spp != NULL;
	     spp = spp->spi_swappri.le_next) {
		for (sdp = spp->spi_swapdev.cqh_first;
d555 1
a555 1
		     sdp = sdp->swd_next.cqe_next)
d580 4
a583 3
	for (spp = swap_priority.lh_first; spp != NULL; spp = nextspp) {
		nextspp = spp->spi_swappri.le_next;
		if (spp->spi_swapdev.cqh_first != (void *)&spp->spi_swapdev)
d586 1
a586 1
		free((caddr_t)spp, M_VMSWAP);
d625 3
a627 3
	for (spp = swap_priority.lh_first; spp != NULL;
	     spp = spp->spi_swappri.le_next)
		for (sdp = spp->spi_swapdev.cqh_first;
d629 1
a629 1
		     sdp = sdp->swd_next.cqe_next)
d669 1
a669 1
	lockmgr(&swap_syscall_lock, LK_EXCLUSIVE, (void *)0, p);
d701 3
a703 3
		for (spp = swap_priority.lh_first; spp != NULL;
		    spp = spp->spi_swappri.le_next) {
			for (sdp = spp->spi_swapdev.cqh_first;
d705 1
a705 9
			     sdp = sdp->swd_next.cqe_next) {
			  	/*
				 * backwards compatibility for system call.
				 * note that we use 'struct oswapent' as an
				 * overlay into both 'struct swapdev' and
				 * the userland 'struct swapent', as we
				 * want to retain backwards compatibility
				 * with NetBSD 1.3.
				 */
d708 2
a709 2
				error = copyout((caddr_t)&sdp->swd_se,
				    (caddr_t)sep, sizeof(struct swapent));
d717 2
a718 3
					error = copyout((caddr_t)sdp->swd_path,
					    (caddr_t)&sep->se_path,
					    sdp->swd_pathlen);
d801 1
a801 2
		spp = (struct swappri *)
			malloc(sizeof *spp, M_VMSWAP, M_WAITOK);
d815 1
d822 1
d830 2
a831 4
		sdp = (struct swapdev *)
			malloc(sizeof *sdp, M_VMSWAP, M_WAITOK);
		spp = (struct swappri *)
			malloc(sizeof *spp, M_VMSWAP, M_WAITOK);
d836 1
a836 1
#ifdef SWAP_TO_FILES
d840 1
a840 1
		if (vp->v_type == VREG)
d842 2
a843 1
#endif
d851 1
d858 1
d864 1
a864 2
#ifdef SWAP_TO_FILES
			if (vp->v_type == VREG)
d866 1
a866 1
#endif
d868 1
a868 1
			free((caddr_t)sdp, M_VMSWAP);
a879 5
		UVMHIST_LOG(pdhist, "someone is using SWAP_OFF...??", 0,0,0,0);
#ifdef SWAP_OFF_WORKS
		/*
		 * find the entry of interest and ensure it is enabled.
		 */
d886 1
a895 4
		/* XXXCDC: should we call with list locked or unlocked? */
		if ((error = swap_off(p, sdp)) != 0)
			break;
		/* XXXCDC: might need relock here */
d898 1
a898 1
		 * now we can kill the entry.
d900 3
a902 9
		if ((sdp = swaplist_find(vp, 1)) == NULL) {
			error = ENXIO;
			break;
		}
		simple_unlock(&uvm.swap_data_lock);
		free((caddr_t)sdp, M_VMSWAP);
#else
		error = EINVAL;
#endif
a905 2
		UVMHIST_LOG(pdhist, "unhandled command: %#x",
		    SCARG(uap, cmd), 0, 0, 0);
d914 1
a914 1
	lockmgr(&swap_syscall_lock, LK_RELEASE, (void *)0, p);
a938 1
#ifdef SWAP_TO_FILES
a939 1
#endif
a988 1
#ifdef SWAP_TO_FILES
a1008 1
#endif
d1025 1
a1025 1
	 * over them (randomly choosing to skip PAGE_SIZE bytes).
a1064 5
		sdp->swd_npginuse += addr;
		simple_lock(&uvm.swap_data_lock);
		uvmexp.swpginuse += addr;
		uvmexp.swpgonly += addr;
		simple_unlock(&uvm.swap_data_lock);
d1082 1
a1082 1
		if (rootpages > npages)
d1089 1
a1089 6
		simple_lock(&uvm.swap_data_lock);
		sdp->swd_npginuse += (rootpages - addr);
		uvmexp.swpginuse += (rootpages - addr);
		uvmexp.swpgonly += (rootpages - addr);
		simple_unlock(&uvm.swap_data_lock);

d1091 1
a1091 1
		printf("leaving %d pages of swap\n", size - rootpages);
d1094 5
d1108 1
a1108 1
	sdp->swd_npages = npages;
d1112 1
a1112 39
	uvmexp.swpages += npages;

	/*
	 * add anon's to reflect the swap space we added
	 */
	uvm_anon_add(size);

#if 0
	/*
	 * At this point we could arrange to reserve memory for the
	 * swap buffer pools.
	 *
	 * I don't think this is necessary, since swapping starts well
	 * ahead of serious memory deprivation and the memory resource
	 * pools hold on to actively used memory. This should ensure
	 * we always have some resources to continue operation.
	 */

	int s = splbio();
	int n = 8 * sdp->swd_maxactive;

	(void)pool_prime(&swapbuf_pool, n, 0);

	if (vp->v_type == VREG) {
		/* Allocate additional vnx and vnd buffers */
		/*
		 * Allocation Policy:
		 *	(8  * swd_maxactive) vnx headers per swap dev
		 *	(16 * swd_maxactive) vnd buffers per swap dev
		 */

		n = 8 * sdp->swd_maxactive;
		(void)pool_prime(&vndxfer_pool, n, 0);

		n = 16 * sdp->swd_maxactive;
		(void)pool_prime(&vndbuf_pool, n, 0);
	}
	splx(s);
#endif
a1124 1
#ifdef SWAP_OFF_WORKS
d1128 1
a1128 1
 * XXXCDC: what conditions go here?
d1135 1
a1135 1
	char	*name;
d1137 1
d1139 1
a1139 1
	/* turn off the enable flag */
d1141 1
a1141 2

	UVMHIST_LOG(pdhist, "  dev=%x", sdp->swd_dev);
d1144 4
a1147 15
	 * XXX write me
	 *
	 * the idea is to find out which processes are using this swap
	 * device, and page them all in.
	 *
	 * eventually, we should try to move them out to other swap areas
	 * if available.
	 *
	 * The alternative is to create a redirection map for this swap
	 * device.  This should work by moving all the pages of data from
	 * the ex-swap device to another one, and making an entry in the
	 * redirection map for it.  locking is going to be important for
	 * this!
	 *
	 * XXXCDC: also need to shrink anon pool
d1150 10
a1159 2
	/* until the above code is written, we must ENODEV */
	return ENODEV;
d1161 4
a1164 5
#ifdef UVM_SWAP_ENCRYPT
	if (sdp->swd_decrypt) {
		free(sdp->swd_decrypt);
		memset(sdp->swd_keys, 0, (sdp->swd_npages >> SWD_KEY_SHIFT) * sizeof(struct swap_key));
		free(sdp->swd_keys);
d1167 30
a1196 2
	extent_free(swapmap, sdp->swd_mapoffset, sdp->swd_mapsize, EX_WAITOK);
	name = sdp->swd_ex->ex_name;
d1199 2
a1200 6
	free((caddr_t)sdp->swd_ex, M_VMSWAP);
	if (sdp->swp_vp != rootvp)
		(void) VOP_CLOSE(sdp->swd_vp, FREAD|FWRITE, p->p_ucred, p);
	if (sdp->swd_vp)
		vrele(sdp->swd_vp);
	free((caddr_t)sdp, M_VMSWAP);
a1202 1
#endif
d1274 1
a1274 1
	pageno = pageno - sdp->swd_drumoffset;	/* page # on swapdev */
a1280 1

d1283 1
a1283 1
	 * for regular files we have to do more work which we deligate
d1290 1
d1304 1
a1304 1
#ifdef SWAP_TO_FILES
d1307 1
a1307 1
		 * deligate to sw_reg_strategy function.
a1310 1
#endif
a1314 1
#ifdef SWAP_TO_FILES
d1365 1
a1365 1
		if (error == 0 && (long)nbn == -1) {
a1415 3
#if 0
		nbp->vb_buf.b_bufsize  = bp->b_bufsize; /* XXXCDC: really? */
#endif
d1571 1
a1571 2
	 * drop "hold" reference to vnode (if one)
	 * XXXCDC: always set to NULLVP, this is useless, right?
d1573 1
a1573 1
	if (vbp->vb_buf.b_vp != NULLVP)
d1575 1
a1612 1

a1614 1
#endif /* SWAP_TO_FILES */
d1649 3
a1651 3
	for (spp = swap_priority.lh_first; spp != NULL;
	     spp = spp->spi_swappri.le_next) {
		for (sdp = spp->spi_swapdev.cqh_first;
d1653 1
a1653 1
		     sdp = sdp->swd_next.cqe_next) {
d1693 27
d1735 8
d1761 2
a1762 2
			EX_MALLOCOK|EX_NOWAIT) != 0)
		printf("warning: resource shortage: %d slots of swap lost\n",
d1764 1
a1803 4
#if 0
	flags |= PGO_SYNCIO; /* XXXMRG: tmp, force sync */
#endif

d1829 4
d1964 1
a1964 1
				      PGO_PDFREECLUST, 0);
d2039 3
d2218 1
a2218 1
			      PGO_PDFREECLUST, 0);
@


1.29
log
@minor sync to NetBSD, nothing changed.
@
text
@d1 2
a2 2
/*	$OpenBSD: uvm_swap.c,v 1.28 2001/07/05 10:00:49 art Exp $	*/
/*	$NetBSD: uvm_swap.c,v 1.29 1999/10/16 23:53:29 wrstuden Exp $	*/
d1206 1
a1206 1
	if (vp != rootvp) {
a1207 1
	}
d1263 1
a1263 1
	if (sdp->swp_vp != rootvp) {
a1264 1
	}
@


1.28
log
@Get rid of the wrapper macros around extent_alloc*1
Pass the right amount of arguments and rename them back to their right names.
@
text
@d1 2
a2 2
/*	$OpenBSD: uvm_swap.c,v 1.27 2001/06/23 15:26:29 art Exp $	*/
/*	$NetBSD: uvm_swap.c,v 1.28 1999/07/22 22:58:39 thorpej Exp $	*/
d1206 1
a1206 1
	if (vp != rootvp)
d1208 1
d1264 1
a1264 1
	if (sdp->swp_vp != rootvp)
d1266 1
@


1.27
log
@convert to use pool_init.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.26 2001/03/26 05:37:03 aaron Exp $	*/
d618 1
a618 1
	if (extent_alloc(swapmap, npages, EX_NOALIGN, EX_NOBOUNDARY,
d1734 1
a1734 1
			if (extent_alloc(sdp->swd_ex, *nslots, EX_NOALIGN,
@


1.26
log
@Typo: parition -> partition
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.25 2001/03/09 03:13:47 deraadt Exp $	*/
d217 2
a218 2
struct pool *vndxfer_pool;
struct pool *vndbuf_pool;
d223 1
a223 1
		pool_get(vndxfer_pool, PR_MALLOCOK|PR_WAITOK);		\
d228 1
a228 1
	pool_put(vndxfer_pool, (void *)(vnx));				\
d234 1
a234 1
		pool_get(vndbuf_pool, PR_MALLOCOK|PR_WAITOK);		\
d239 1
a239 1
	pool_put(vndbuf_pool, (void *)(vbp));				\
d248 1
a248 1
struct pool *swapbuf_pool;
d337 2
a338 2
	swapbuf_pool =
		pool_create(sizeof(struct swapbuf), 0, 0, 0, "swp buf", 0,
a339 2
	if (swapbuf_pool == NULL)
		panic("swapinit: pool_create failed");
d342 2
a343 5
	vndxfer_pool =
		pool_create(sizeof(struct vndxfer), 0, 0, 0, "swp vnx", 0,
			    NULL, NULL, 0);
	if (vndxfer_pool == NULL)
		panic("swapinit: pool_create failed");
d345 1
a345 2
	vndbuf_pool =
		pool_create(sizeof(struct vndbuf), 0, 0, 0, "swp vnd", 0,
a346 2
	if (vndbuf_pool == NULL)
		panic("swapinit: pool_create failed");
d1181 1
a1181 1
	(void)pool_prime(swapbuf_pool, n, 0);
d1192 1
a1192 1
		(void)pool_prime(vndxfer_pool, n, 0);
d1195 1
a1195 1
		(void)pool_prime(vndbuf_pool, n, 0);
d2017 1
a2017 1
	sbp = pool_get(swapbuf_pool, pflag);
d2152 1
a2152 1
	pool_put(swapbuf_pool, sbp);
d2260 1
a2260 1
	pool_put(swapbuf_pool, sbp);
@


1.25
log
@PATH_MAX+1 is wrong.  Not cranking libc/libc_r majors over this, since they just got cranked a little while ago. discussion with millert
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.24 2001/03/08 15:21:37 smart Exp $	*/
d74 1
a74 1
 * swap parition usage.
@


1.24
log
@Replace thread_wakeup() with wakeup().  It is defined in vm_extern.h as a
wrapper, so this removes a dependence on the old VM system.  From NetBSD.
art@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.23 2001/02/24 19:07:12 csapuntz Exp $	*/
d681 1
a681 1
	char	userpath[PATH_MAX + 1];
@


1.23
log
@

Cleanup of vnode interface continues. Get rid of VHOLD/HOLDRELE.
Change VM/UVM to use buf_replacevnode to change the vnode associated
with a buffer.

Addition v_bioflag for flags written in interrupt handlers
(and read at splbio, though not strictly necessary)

Add vwaitforio and use it instead of a while loop of v_numoutput.

Fix race conditions when manipulation vnode free list
@
text
@d1 2
a2 2
/*	$OpenBSD: uvm_swap.c,v 1.22 2001/01/29 02:07:49 niklas Exp $	*/
/*	$NetBSD: uvm_swap.c,v 1.27 1999/03/30 16:07:47 chs Exp $	*/
d2204 1
a2204 1
	thread_wakeup(&uvm.pagedaemon);
@


1.22
log
@$OpenBSD$
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.27 1999/03/30 16:07:47 chs Exp $	*/
a1325 1
	struct vnode *vp;
d1374 1
a1374 20
		bp->b_blkno = bn;		/* swapdev block number */
		vp = sdp->swd_vp;		/* swapdev vnode pointer */
		bp->b_dev = sdp->swd_dev;	/* swapdev dev_t */
		VHOLD(vp);			/* "hold" swapdev vp for i/o */

		/*
		 * if we are doing a write, we have to redirect the i/o on
		 * drum's v_numoutput counter to the swapdevs.
		 */
		if ((bp->b_flags & B_READ) == 0) {
			vwakeup(bp);	/* kills one 'v_numoutput' on drum */
			vp->v_numoutput++;	/* put it on swapdev */
		}

		/* 
		 * dissassocate buffer with /dev/drum vnode 
		 * [could be null if buf was from physio]
		 */
		if (bp->b_vp != NULLVP)
			brelvp(bp);
d1376 2
a1377 5
		/* 
		 * finally plug in swapdev vnode and start I/O
		 */
		bp->b_vp = vp;
		splx(s);
d2069 2
a2070 2
	VHOLD(swapdev_vp);
	bp->b_vp = swapdev_vp;
a2071 4
	/* XXXCDC: isn't swapdev_vp always a VCHR? */
	/* XXXMRG: probably -- this is obviously something inherited... */
	if (swapdev_vp->v_type == VBLK)
		bp->b_dev = swapdev_vp->v_rdev;
a2080 3
		s = splbio();
		swapdev_vp->v_numoutput++;
		splx(s);
@


1.21
log
@spelling
@
text
@d1 1
@


1.20
log
@Convert bzero to memset(X, 0..) and bcopy to memcpy.
This is to match (make diffs smaller) the code in NetBSD.
new gcc inlines those functions, so this could also be a performance win.
@
text
@d1447 1
a1447 1
	bp->b_resid = bp->b_bcount;	/* nothing transfered yet! */
@


1.19
log
@use rijndael instead of blowfish because of faster key setup.
break swap paritions into sections, each section has own
encryption key.  if a section's key becomes unreferenced, erase it.
@
text
@d397 1
a397 1
	bzero(sdp->swd_decrypt, SWD_DCRYPT_SIZE(npages));
d400 1
a400 1
	bzero(sdp->swd_keys, (npages >> SWD_KEY_SHIFT) * sizeof(struct swap_key));
d864 1
a864 1
		bzero(sdp, sizeof(*sdp));
d1261 1
a1261 1
		bzero(sdp->swd_keys, (sdp->swd_npages >> SWD_KEY_SHIFT) * sizeof(struct swap_key));
d1854 1
a1854 1
#endif UVM_SWAP_ENCRYPT
d2076 1
a2076 1
	  flags &= ~B_ASYNC;
d2330 1
a2330 1
	bzero(sdp, sizeof(*sdp));
@


1.18
log
@use encrypted blocknumber as IV
@
text
@d56 1
a56 1
#include <uvm/uvm_swap_encrypt.h>
d157 3
d167 2
d398 4
d1259 1
a1259 1
	if (sdp->swd_decrypt)
d1261 3
d1841 14
a1965 3
	/* 
	 * encrypt to swap
	 */
a1966 4
		int i, opages;
		caddr_t src, dst;
		u_int64_t block;

d1975 25
a1999 2
		if (!uvm_doswapencrypt)
				goto noswapencrypt;
d2017 3
d2022 1
a2022 1
			swap_encrypt(src, dst, block, 1 << PAGE_SHIFT);
a2035 3

		encrypt = 1;
	noswapencrypt:
d2056 2
d2059 3
a2099 15
#ifdef UVM_SWAP_ENCRYPT
	if (swap_encrypt_initalized) { 
		/*
		 * we need to know the swap device that we are swapping to/from
		 * to see if the pages need to be marked for decryption or
		 * actually need to be decrypted.
		 * XXX - does this information stay the same over the whole 
		 * execution of this function?
		 */
		simple_lock(&uvm.swap_data_lock);
		sdp = swapdrum_getsdp(startslot);
		simple_unlock(&uvm.swap_data_lock);
	}
#endif

d2156 2
d2160 3
a2162 2
			if (uvm_swap_needdecrypt(sdp, startslot + i))
				swap_decrypt(data, data, block,
d2164 1
@


1.17
log
@only free in swap_off if allocated.
@
text
@d1946 1
d1973 1
d1977 1
a1977 1
			swap_encrypt(src, dst, 1 << PAGE_SHIFT);
d1980 1
d2123 1
d2127 2
a2128 1
				swap_decrypt(data, data, 1 << PAGE_SHIFT);
d2130 1
@


1.16
log
@postpone memory allocation for uvm swap encryption until it is turned on with
sysctl.
@
text
@d1250 2
a1251 1
	free(sdp->swd_decrypt);
@


1.15
log
@make uvm swap encrypt compile again, from markus@@
@
text
@d285 1
d362 33
d1146 2
a1147 9
	/*
	 * keep information if a page needs to be decrypted when we get it
	 * from the swap device.
	 * We cannot chance a malloc later, if we are doing ASYNC puts,
	 * we may not call malloc with M_WAITOK.  This takes consumes only
	 * 8KB memory for a 256MB swap partition.
	 */
	sdp->swd_decrypt = malloc(SWD_DCRYPT_SIZE(npages), M_VMSWAP, M_WAITOK);
	bzero(sdp->swd_decrypt, SWD_DCRYPT_SIZE(npages));
@


1.14
log
@Fix the NetBSD id strings.
@
text
@d369 1
a369 2
	s = splimp();
	uvm_lock_fpageq();
d375 1
a375 2
	uvm_unlock_fpageq();
	splx(s);
@


1.13
log
@nfs vnodeops are only defined with NFSCLIENT, not NFSSERVER.
@
text
@d1 1
a1 1
/*	$NetBSD: uvm_swap.c,v 1.26 1999/03/26 17:34:16 chs Exp $	*/
@


1.13.2.1
log
@Sync with -current
@
text
@d1 1
a1 1
/*	$NetBSD: uvm_swap.c,v 1.27 1999/03/30 16:07:47 chs Exp $	*/
a284 1
void uvm_swap_initcrypt __P((struct swapdev *, int));
a360 33
void
uvm_swap_initcrypt_all(void)
{
	struct swapdev *sdp;
	struct swappri *spp;

	simple_lock(&uvm.swap_data_lock);

	for (spp = swap_priority.lh_first; spp != NULL;
	     spp = spp->spi_swappri.le_next) {
		for (sdp = spp->spi_swapdev.cqh_first;
		     sdp != (void *)&spp->spi_swapdev;
		     sdp = sdp->swd_next.cqe_next)
			if (sdp->swd_decrypt == NULL)
				uvm_swap_initcrypt(sdp, sdp->swd_npages);
	}
	simple_unlock(&uvm.swap_data_lock);
}

void
uvm_swap_initcrypt(struct swapdev *sdp, int npages)
{
	/*
	 * keep information if a page needs to be decrypted when we get it
	 * from the swap device.
	 * We cannot chance a malloc later, if we are doing ASYNC puts,
	 * we may not call malloc with M_WAITOK.  This consumes only
	 * 8KB memory for a 256MB swap partition.
	 */
	sdp->swd_decrypt = malloc(SWD_DCRYPT_SIZE(npages), M_VMSWAP, M_WAITOK);
	bzero(sdp->swd_decrypt, SWD_DCRYPT_SIZE(npages));
}

d369 2
a370 1
	s = uvm_lock_fpageq();
d376 2
a377 1
	uvm_unlock_fpageq(s);
d1114 9
a1122 2
	if (uvm_doswapencrypt)
		uvm_swap_initcrypt(sdp, npages);
d1225 1
a1225 2
	if (sdp->swd_decrypt)
		free(sdp->swd_decrypt);
@


1.13.2.2
log
@merge in approximately 2.9 into SMP branch
@
text
@d1 1
a1 2
/*	$OpenBSD: uvm_swap.c,v 1.26 2001/03/26 05:37:03 aaron Exp $	*/
/*	$NetBSD: uvm_swap.c,v 1.28 1999/07/22 22:58:39 thorpej Exp $	*/
d56 1
a56 1
#include <sys/syslog.h>
d73 1
a73 1
 * swap partition usage.
a156 3
#define SWD_KEY_SHIFT		7		/* One key per 0.5 MByte */
#define SWD_KEY(x,y)		&((x)->swd_keys[((y) - (x)->swd_drumoffset) >> SWD_KEY_SHIFT])

a163 2
	struct swap_key		*swd_keys;	/* keys for different parts */
	int			swd_nkeys;	/* active keys */
d392 1
a392 5
	memset(sdp->swd_decrypt, 0, SWD_DCRYPT_SIZE(npages));
	sdp->swd_keys = malloc((npages >> SWD_KEY_SHIFT) * sizeof(struct swap_key),
			       M_VMSWAP, M_WAITOK);
	memset(sdp->swd_keys, 0, (npages >> SWD_KEY_SHIFT) * sizeof(struct swap_key));
	sdp->swd_nkeys = 0;
d671 1
a671 1
	char	userpath[MAXPATHLEN];
d855 1
a855 1
		memset(sdp, 0, sizeof(*sdp));
d1250 1
a1250 1
	if (sdp->swd_decrypt) {
a1251 3
		memset(sdp->swd_keys, 0, (sdp->swd_npages >> SWD_KEY_SHIFT) * sizeof(struct swap_key));
		free(sdp->swd_keys);
	}
d1313 1
d1362 20
a1381 1
		buf_replacevnode(bp, sdp->swd_vp);
d1383 5
a1387 2
		bp->b_blkno = bn;
      		splx(s);
d1435 1
a1435 1
	bp->b_resid = bp->b_bcount;	/* nothing transferred yet! */
a1828 14
#ifdef UVM_SWAP_ENCRYPT
	{
		int i;
		if (swap_encrypt_initalized) {
			/* Dereference keys */
			for (i = 0; i < nslots; i++)
				if (uvm_swap_needdecrypt(sdp, startslot + i))
					SWAP_KEY_PUT(sdp, SWD_KEY(sdp, startslot + i));

			/* Mark range as not decrypt */
			uvm_swap_markdecrypt(sdp, startslot, nslots, 0);
		}
	}
#endif /* UVM_SWAP_ENCRYPT */
d1940 3
d1944 3
d1955 2
a1956 25
		if (uvm_doswapencrypt)
			encrypt = 1;
	}

	if (swap_encrypt_initalized  || encrypt) { 
		/*
		 * we need to know the swap device that we are swapping to/from
		 * to see if the pages need to be marked for decryption or
		 * actually need to be decrypted.
		 * XXX - does this information stay the same over the whole 
		 * execution of this function?
		 */
		simple_lock(&uvm.swap_data_lock);
		sdp = swapdrum_getsdp(startslot);
		simple_unlock(&uvm.swap_data_lock);
	}

	/* 
	 * encrypt to swap
	 */
	if ((flags & B_READ) == 0 && encrypt) {
		int i, opages;
		caddr_t src, dst;
		struct swap_key *key;
		u_int64_t block;
a1971 1
		block = startblk;
a1972 3
			key = SWD_KEY(sdp, startslot + i);
			SWAP_KEY_GET(sdp, key);	/* add reference */

d1975 1
a1975 1
			swap_encrypt(key, src, dst, block, 1 << PAGE_SHIFT);
a1977 1
			block += btodb(1 << PAGE_SHIFT);
d1988 3
a2010 2
			int i;

a2011 3
			for (i = 0; i < npages; i++)
				SWAP_KEY_PUT(sdp, SWD_KEY(sdp, startslot + i));

d2026 1
a2026 1
		flags &= ~B_ASYNC;
d2041 2
a2042 2
	bp->b_vp = NULL;
	buf_replacevnode(bp, swapdev_vp);
d2044 4
d2050 15
d2072 3
a2119 3
		u_int64_t block = startblk;
		struct swap_key *key = NULL;

d2122 2
a2123 5
			if (uvm_swap_needdecrypt(sdp, startslot + i)) {
				key = SWD_KEY(sdp, startslot + i);
				swap_decrypt(key, data, data, block,
					     1 << PAGE_SHIFT);
			}
a2124 1
			block += btodb(1 << PAGE_SHIFT);
d2191 1
a2191 1
	wakeup(&uvm.pagedaemon);
d2288 1
a2288 1
	memset(sdp, 0, sizeof(*sdp));
@


1.13.2.3
log
@Merge in -current from two days ago in the SMP branch.
As usual with merges, they do not indicate progress, so do not hold
your breath for working SMP, and do not mail me and ask about the
state of it.  It has not changed.  There is work ongoing, but very, very
slowly.  The commit is done in parts as to not lock up the tree in too
big chunks at a time.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.13.2.2 2001/05/14 22:47:48 niklas Exp $	*/
d217 2
a218 2
struct pool vndxfer_pool;
struct pool vndbuf_pool;
d223 1
a223 1
		pool_get(&vndxfer_pool, PR_MALLOCOK|PR_WAITOK);		\
d228 1
a228 1
	pool_put(&vndxfer_pool, (void *)(vnx));				\
d234 1
a234 1
		pool_get(&vndbuf_pool, PR_MALLOCOK|PR_WAITOK);		\
d239 1
a239 1
	pool_put(&vndbuf_pool, (void *)(vbp));				\
d248 1
a248 1
struct pool swapbuf_pool;
d337 2
a338 2

	pool_init(&swapbuf_pool, sizeof(struct swapbuf), 0, 0, 0, "swp buf", 0,
d340 2
d344 5
a348 2
	pool_init(&vndxfer_pool, sizeof(struct vndxfer), 0, 0, 0, "swp vnx",
			    0, NULL, NULL, 0);
d350 2
a351 1
	pool_init(&vndbuf_pool, sizeof(struct vndbuf), 0, 0, 0, "swp vnd", 0,
d353 2
d1189 1
a1189 1
	(void)pool_prime(&swapbuf_pool, n, 0);
d1200 1
a1200 1
		(void)pool_prime(&vndxfer_pool, n, 0);
d1203 1
a1203 1
		(void)pool_prime(&vndbuf_pool, n, 0);
d2025 1
a2025 1
	sbp = pool_get(&swapbuf_pool, pflag);
d2160 1
a2160 1
	pool_put(&swapbuf_pool, sbp);
d2268 1
a2268 1
	pool_put(&swapbuf_pool, sbp);
@


1.13.2.4
log
@Sync the SMP branch to something just after 3.0
@
text
@d1 2
a2 2
/*	$OpenBSD$	*/
/*	$NetBSD: uvm_swap.c,v 1.37 2000/05/19 03:45:04 thorpej Exp $	*/
a37 1
#include <sys/conf.h>
d53 2
d122 6
a144 1
	int			swd_npgbad;	/* #pages bad */
d151 1
d156 1
d222 2
a223 1
	vnx = pool_get(&vndxfer_pool, PR_MALLOCOK|PR_WAITOK);		\
d233 2
a234 1
	vbp = pool_get(&vndbuf_pool, PR_MALLOCOK|PR_WAITOK);		\
a241 3
/* /dev/drum */
bdev_decl(sw);
cdev_decl(sw);
d269 1
d271 1
d273 1
d277 1
d317 1
a317 1
	if (!swapdev_vp && bdevvp(swapdev, &swapdev_vp))
d510 2
a511 2
	for (pspp = NULL, spp = LIST_FIRST(&swap_priority); spp != NULL;
	     spp = LIST_NEXT(spp, spi_swappri)) {
d522 1
a522 2
		UVMHIST_LOG(pdhist, "created new swappri = %d",
			    priority, 0, 0, 0);
d543 4
d567 3
a569 3
	for (spp = LIST_FIRST(&swap_priority); spp != NULL;
	     spp = LIST_NEXT(spp, spi_swappri)) {
		for (sdp = CIRCLEQ_FIRST(&spp->spi_swapdev);
d571 1
a571 1
		     sdp = CIRCLEQ_NEXT(sdp, swd_next))
d596 3
a598 4
	for (spp = LIST_FIRST(&swap_priority); spp != NULL; spp = nextspp) {
		nextspp = LIST_NEXT(spp, spi_swappri);
		if (CIRCLEQ_FIRST(&spp->spi_swapdev) !=
		    (void *)&spp->spi_swapdev)
d601 1
a601 1
		free(spp, M_VMSWAP);
d618 1
a618 1
	if (extent_alloc(swapmap, npages, EX_NOALIGN, 0, EX_NOBOUNDARY,
d640 3
a642 3
	for (spp = LIST_FIRST(&swap_priority); spp != NULL;
	     spp = LIST_NEXT(spp, spi_swappri))
		for (sdp = CIRCLEQ_FIRST(&spp->spi_swapdev);
d644 1
a644 1
		     sdp = CIRCLEQ_NEXT(sdp, swd_next))
d684 1
a684 1
	lockmgr(&swap_syscall_lock, LK_EXCLUSIVE, NULL, p);
d716 3
a718 3
		for (spp = LIST_FIRST(&swap_priority); spp != NULL;
		    spp = LIST_NEXT(spp, spi_swappri)) {
			for (sdp = CIRCLEQ_FIRST(&spp->spi_swapdev);
d720 9
a728 1
			     sdp = CIRCLEQ_NEXT(sdp, swd_next)) {
d731 2
a732 2
				error = copyout(&sdp->swd_se, sep,
				    sizeof(struct swapent));
d740 3
a742 2
					error = copyout(sdp->swd_path,
					    &sep->se_path, sdp->swd_pathlen);
d825 2
a826 1
		spp = malloc(sizeof *spp, M_VMSWAP, M_WAITOK);
a839 1

a845 1

d853 4
a856 2
		sdp = malloc(sizeof *sdp, M_VMSWAP, M_WAITOK);
		spp = malloc(sizeof *spp, M_VMSWAP, M_WAITOK);
d861 1
a861 1

d865 1
a865 1
		if (vp->v_type == VREG) {
d867 1
a867 2
		}

a874 1

a880 1

d886 2
a887 1
			if (vp->v_type == VREG) {
d889 1
a889 1
			}
d891 1
a891 1
			free(sdp, M_VMSWAP);
d903 5
a913 1

d923 4
d929 1
a929 1
		 * do the real work.
d931 9
a939 3
		if ((error = swap_off(p, sdp)) != 0)
			goto out;

d943 2
d953 1
a953 1
	lockmgr(&swap_syscall_lock, LK_RELEASE, NULL, p);
d978 1
d980 1
d1030 1
d1051 1
d1068 1
a1068 1
	 * over them (arbitrarily choosing to skip PAGE_SIZE bytes).
d1108 5
d1130 1
a1130 1
		if (rootpages > size)
d1137 6
a1142 1
		size -= rootpages;
d1144 1
a1144 1
		printf("leaving %d pages of swap\n", size);
a1146 5
  	/*
	 * add anons to reflect the new swap space
	 */
	uvm_anon_add(size);

d1156 1
a1156 1
	sdp->swd_npages = size;
d1160 39
a1198 1
	uvmexp.swpages += size;
d1211 1
d1215 1
a1215 1
 * => swap data should be locked, we will unlock.
d1222 1
a1222 1
	void *name;
a1223 1
	UVMHIST_LOG(pdhist, "  dev=%x", sdp->swd_dev,0,0,0);
d1225 1
a1225 1
	/* disable the swap area being removed */
d1227 2
a1228 1
	simple_unlock(&uvm.swap_data_lock);
d1231 15
a1245 4
	 * the idea is to find all the pages that are paged out to this
	 * device, and page them all in.  in uvm, swap-backed pageable
	 * memory can take two forms: aobjs and anons.  call the
	 * swapoff hook for each subsystem to bring in pages.
d1248 2
a1249 10
	if (uao_swap_off(sdp->swd_drumoffset,
			 sdp->swd_drumoffset + sdp->swd_drumsize) ||
	    anon_swap_off(sdp->swd_drumoffset,
			  sdp->swd_drumoffset + sdp->swd_drumsize)) {
		
		simple_lock(&uvm.swap_data_lock);
		sdp->swd_flags |= SWF_ENABLE;
		simple_unlock(&uvm.swap_data_lock);
		return ENOMEM;
	}
d1251 5
a1255 4
#ifdef DIAGNOSTIC
	if (sdp->swd_npginuse != sdp->swd_npgbad) {
		panic("swap_off: sdp %p - %d pages still in use (%d bad)\n",
		      sdp, sdp->swd_npginuse, sdp->swd_npgbad);
d1258 6
a1263 8

	/*
	 * done with the vnode.
	 */
	if (sdp->swd_vp->v_type == VREG) {
		crfree(sdp->swd_cred);
	}
	if (sdp->swd_vp != rootvp) {
d1265 1
a1265 2
	}
	if (sdp->swd_vp) {
d1267 1
a1267 22
	}

	/* remove anons from the system */
	uvm_anon_remove(sdp->swd_npages);

	simple_lock(&uvm.swap_data_lock);
	uvmexp.swpages -= sdp->swd_npages;

	if (swaplist_find(sdp->swd_vp, 1) == NULL)
		panic("swap_off: swapdev not in list\n");
	swaplist_trim();

	/*
	 * free all resources!
	 */
	extent_free(swapmap, sdp->swd_drumoffset, sdp->swd_drumsize,
		    EX_WAITOK);
	name = (void *)sdp->swd_ex->ex_name;
	extent_destroy(sdp->swd_ex);
	free(name, M_VMSWAP);
	free(sdp, M_VMSWAP);
	simple_unlock(&uvm.swap_data_lock);
d1270 1
d1288 1
a1288 1
	UVMHIST_LOG(pdhist, "  dev=%x offset=%llx", dev, uio->uio_offset, 0, 0);
d1304 1
a1304 1
	UVMHIST_LOG(pdhist, "  dev=%x offset=%llx", dev, uio->uio_offset, 0, 0);
d1342 1
a1342 1
	pageno -= sdp->swd_drumoffset;	/* page # on swapdev */
d1349 1
d1352 1
a1352 1
	 * for regular files we have to do more work which we delegate
a1358 1

d1372 1
a1372 1

d1375 1
a1375 1
		 * delegate to sw_reg_strategy function.
d1379 1
d1384 1
d1435 1
a1435 1
		if (error == 0 && nbn == (daddr_t)-1) {
d1486 3
d1644 2
a1645 8
	 * disassociate this buffer from the vnode (if any).
	 */
	if (vbp->vb_buf.b_vp != NULLVP) {
		brelvp(&vbp->vb_buf);
	}

	/*
	 * disassociate this buffer from the vnode (if any).
d1647 1
a1647 1
	if (vbp->vb_buf.b_vp != NULLVP) {
a1648 1
	}
d1686 1
d1689 1
d1724 3
a1726 3
	for (spp = LIST_FIRST(&swap_priority); spp != NULL;
	     spp = LIST_NEXT(spp, spi_swappri)) {
		for (sdp = CIRCLEQ_FIRST(&spp->spi_swapdev);
d1728 1
a1728 1
		     sdp = CIRCLEQ_NEXT(sdp,swd_next)) {
d1734 1
a1734 1
			if (extent_alloc(sdp->swd_ex, *nslots, EX_NOALIGN, 0,
a1767 27
 * uvm_swap_markbad: keep track of swap ranges where we've had i/o errors
 *
 * => we lock uvm.swap_data_lock
 */
void
uvm_swap_markbad(startslot, nslots)
	int startslot;
	int nslots;
{
	struct swapdev *sdp;
	UVMHIST_FUNC("uvm_swap_markbad"); UVMHIST_CALLED(pdhist);

	simple_lock(&uvm.swap_data_lock);
	sdp = swapdrum_getsdp(startslot);

	/*
	 * we just keep track of how many pages have been marked bad
	 * in this device, to make everything add up in swap_off().
	 * we assume here that the range of slots will all be within
	 * one swap device.
	 */
	sdp->swd_npgbad += nslots;

	simple_unlock(&uvm.swap_data_lock);
}

/*
a1782 8

	/*
	 * ignore attempts to free the "bad" slot.
	 */
	if (startslot == SWSLOT_BAD) {
		return;
	}

d1801 2
a1802 2
			EX_MALLOCOK|EX_NOWAIT) != 0) {
		printf("warning: resource shortage: %d pages of swap lost\n",
a1803 1
	}
d1843 4
a1871 4
	if (swslot == SWSLOT_BAD) {
		return VM_PAGER_ERROR;
	}

d1907 1
a1907 1
	int	result, s, mapinflags, pflag;
d1930 3
a1932 6
	mapinflags = (flags & B_READ) ? UVMPAGER_MAPIN_READ :
	    UVMPAGER_MAPIN_WRITE;
	if ((flags & B_ASYNC) == 0)
		mapinflags |= UVMPAGER_MAPIN_WAITOK;
	kva = uvm_pagermapin(pps, npages, NULL, mapinflags);
	if (kva == 0)
a1969 6
		int swmapflags;

		/* We always need write access. */
		swmapflags = UVMPAGER_MAPIN_READ;
		if ((flags & B_ASYNC) == 0)
			swmapflags |= UVMPAGER_MAPIN_WAITOK;
d1976 1
a1976 1
		dstkva = uvm_pagermapin(tpps, npages, NULL, swmapflags);
d2003 1
a2003 1
				      PGO_PDFREECLUST);
a2077 3
		s = splbio();
		swapdev_vp->v_numoutput++;
		splx(s);
d2254 1
a2254 1
			      PGO_PDFREECLUST);
@


1.13.2.5
log
@merge in -current
@
text
@d2 1
a2 1
/*	$NetBSD: uvm_swap.c,v 1.46 2001/02/18 21:19:08 chs Exp $	*/
d53 1
d81 5
d93 2
a141 1
	char			swd_exname[12];	/* name of extent above */
d176 9
d240 2
d268 2
d277 1
d321 3
a323 1
	 * allocate pools for structures used for swapping to files.
d327 4
d709 1
a709 2
				    btodb((u_int64_t)sdp->swd_npginuse <<
				    PAGE_SHIFT);
a786 1

d790 1
a790 1
			break;
d793 1
d873 6
d902 3
a904 1
		error = swap_off(p, sdp);
d912 1
a912 1
	 * done!  release the ref gained by namei() and unlock.
a914 1

d946 1
d1057 2
a1058 2
	snprintf(sdp->swd_exname, sizeof(sdp->swd_exname), "swap0x%04x",
	    count++);
d1061 1
a1061 1
	sdp->swd_ex = extent_create(sdp->swd_exname, 0, npages - 1, M_VMSWAP,
d1097 1
a1097 10
	 * try to add anons to reflect the new swap space.
	 */

	error = uvm_anon_add(size);
	if (error) {
		goto bad;
	}

	/*
	 * add a ref to vp to reflect usage as a swap device.
d1099 1
a1099 1
	vref(vp);
d1113 1
d1115 1
a1115 1
	simple_unlock(&uvm.swap_data_lock);
d1118 1
d1120 1
a1120 1
	 * failure: clean up and return error.
d1122 1
a1122 6

bad:
	if (sdp->swd_ex) {
		extent_destroy(sdp->swd_ex);
	}
	if (vp != rootvp) {
a1123 1
	}
d1137 1
d1162 7
a1168 1
	KASSERT(sdp->swd_npginuse == sdp->swd_npgbad);
d1171 1
a1171 3
	 * done with the vnode and saved creds.
	 * drop our ref on the vnode before calling VOP_CLOSE()
	 * so that spec_close() can tell if this is the last close.
a1175 1
	vrele(sdp->swd_vp);
d1179 3
d1198 1
d1200 1
d1260 1
a1260 1
	pageno = dbtob((int64_t)bp->b_blkno) >> PAGE_SHIFT;
d1277 1
a1277 1
	bn = btodb((u_int64_t)pageno << PAGE_SHIFT); /* convert to diskblock */
d1279 1
a1279 1
	UVMHIST_LOG(pdhist, "  %s: mapoff=%x bn=%x bcount=%ld",
d1328 1
a1328 1
	daddr_t		nbn;
a1329 1
	off_t		byteoff;
d1351 1
a1351 1
	byteoff = dbtob((u_int64_t)bn);
d1397 1
d1399 6
a1404 3
		off = byteoff % sdp->swd_bsize;
		sz = (1 + nra) * sdp->swd_bsize - off;
		if (sz > resid)
d1407 2
a1408 3
		UVMHIST_LOG(pdhist, "sw_reg_strategy: "
			    "vp %p/%p offset 0x%x/0x%x",
			    sdp->swd_vp, vp, byteoff, nbn);
d1470 1
a1470 1
		bgetvp(vp, &nbp->vb_buf);
a1528 1

d1575 8
a1582 1
	if (vbp->vb_buf.b_vp != NULL) {
d1604 5
a1608 1
		KASSERT(vnx->vx_pending == 0);
d1723 1
a1724 2
	sdp->swd_npgbad += nslots;
	UVMHIST_LOG(pdhist, "now %d bad", sdp->swd_npgbad, 0,0,0);
a1747 1

a1756 1

d1759 10
a1768 3
	KASSERT(uvmexp.nswapdev >= 1);
	KASSERT(sdp != NULL);
	KASSERT(sdp->swd_npginuse >= nslots);
d1777 4
d1833 5
a1837 1
	KASSERT(flags & PGO_SYNCIO);
d1874 1
a1877 1
	boolean_t write, async;
a1888 3
	write = (flags & B_READ) == 0;
	async = (flags & B_ASYNC) != 0;

d1892 1
a1892 1
	startblk = btodb((u_int64_t)startslot << PAGE_SHIFT);
d1896 7
a1902 4
	 * by buffer system).
	 */
	mapinflags = !write ? UVMPAGER_MAPIN_READ : UVMPAGER_MAPIN_WRITE;
	if (!async)
d1904 1
a1904 1
	kva = uvm_pagermapin(pps, npages, mapinflags);
d1909 1
a1909 1
	if (write) {
d1938 1
a1938 1
	if (write && encrypt) {
d1947 1
a1947 1
		if (!async)
d1955 1
a1955 1
		dstkva = uvm_pagermapin(tpps, npages, swmapflags);
d1989 1
a1989 1
	 * now allocate a buf for the i/o.
d1993 5
a1997 3
	pflag = (async || curproc == uvm.pagedaemon_proc) ? 0 : PR_WAITOK;
	bp = pool_get(&bufpool, pflag);
	splx(s);
d2002 1
a2002 1
	if (bp == NULL) {
d2004 1
a2004 1
		if (write && encrypt) {
a2022 1
	 * XXXARTUBC - might not be true anymore.
d2024 1
a2024 1
	if (!write) {
a2025 2
		async = 0;
	}
d2028 1
a2028 1
	 * fill in the bp.   we currently route our i/o through
d2031 1
d2043 1
a2043 1
	bp->b_bufsize = bp->b_bcount = npages << PAGE_SHIFT;
d2049 1
a2049 1
	if (write) {
d2063 2
a2064 1
	 * for async ops we must set up the iodone handler.
d2066 7
a2072 4
	if (async) {
		bp->b_flags |= B_CALL | (curproc == uvm.pagedaemon_proc ?
					 B_PDAEMON : 0);
		bp->b_iodone = uvm_aio_biodone;
d2076 1
a2076 1
	    "about to start io: data = %p blkno = 0x%x, bcount = %ld",
d2083 1
a2083 1
	if (async)
d2089 1
a2089 1
	(void) biowait(bp);
d2128 1
a2128 1
	 * now dispose of the buf
d2134 1
a2134 3
	if (write && bp->b_vp)
		vwakeup(bp->b_vp);
	pool_put(&bufpool, bp);
d2142 106
@


1.13.2.6
log
@Merge in -current
@
text
@d2 1
a2 1
/*	$NetBSD: uvm_swap.c,v 1.52 2001/05/26 16:32:47 chs Exp $	*/
d66 1
a66 1
 *
d77 1
a77 1
 * by the "swap_priority" global var.    each "swappri" contains a
d102 1
a102 1
 *  [2] SWAP_STATS: given a pointer to an array of swapent structures
d230 1
a230 1
struct lock swap_syscall_lock;
d235 1
d239 1
a239 1
static void		 swaplist_insert __P((struct swapdev *,
d265 1
a265 1
 * => called at boot time from init_main.c after the filesystems
d291 1
a291 1
	 * that block 0 is reserved (used to indicate an allocation
d566 21
d599 1
a599 1

d604 1
a604 3
		     sdp = CIRCLEQ_NEXT(sdp, swd_next)) {
			if (sdp->swd_flags & SWF_FAKE)
				continue;
a608 1
		}
d649 1
a649 1
	 * SWAP_NSWAP: return number of config'd swap devices
d663 1
a663 1
	 * note that the swap_priority list can't change as long
d665 1
a665 1
	 * to grab the uvm.swap_data_lock because we may fault&sleep during
d681 1
a681 1
				sdp->swd_inuse =
d701 1
a701 2
					sep = (struct swapent *)
					    ((struct oswapent *)sep + 1);
d713 1
a713 1
	}
a799 2
		sdp = malloc(sizeof *sdp, M_VMSWAP, M_WAITOK);
		spp = malloc(sizeof *spp, M_VMSWAP, M_WAITOK);
d801 1
a801 1
		if (swaplist_find(vp, 0) != NULL) {
a803 2
			free(sdp, M_VMSWAP);
			free(spp, M_VMSWAP);
d806 2
a907 1
	u_long result;
d1036 1
a1036 1
	 * if the vnode we are swapping to is the root vnode
d1038 1
a1038 1
	 * to make sure we don't overwrite it.   do a statfs to
d1053 1
a1053 1
		if (extent_alloc_region(sdp->swd_ex, addr,
d1083 2
a1084 6
	if (extent_alloc(swapmap, npages, EX_NOALIGN, 0, EX_NOBOUNDARY,
	    EX_WAITOK, &result))
		panic("swapdrum_add");

	sdp->swd_drumoffset = (int)result;
	sdp->swd_drumsize = npages;
a1085 1
	simple_lock(&uvm.swap_data_lock);
d1134 1
a1134 1

a1163 1
	simple_unlock(&uvm.swap_data_lock);
d1172 1
d1339 1
a1339 1
			/*
d1394 2
d1398 26
d1544 3
a1546 1
	(void) buf_cleanout(&vbp->vb_buf);
d1609 1
a1609 1

d1713 2
a1714 2
	 * convert drum slot offset back to sdp, free the blocks
	 * in the extent, and return.   must hold pri lock to do
d1785 1
a1785 1
		return EIO;
a1790 1

d1795 1
a1795 1
	result = uvm_swap_io(&page, swslot, 1, B_READ |
d1798 1
a1798 2
	if (result != 0) {

a1801 1

d1822 1
a1822 1
	int	error, s, mapinflags, pflag;
d1852 1
a1852 1
		return (EAGAIN);
d1898 1
a1898 1
			return (EAGAIN);
d1905 1
a1905 1
			return (EAGAIN);
d1934 1
a1934 1
	/*
d1959 1
a1959 1
		return (EAGAIN);
d1980 1
d1991 3
a1993 2
	/*
	 * bump v_numoutput (counter of number of active outputs).
d1996 2
d2026 1
a2026 1
		return 0;
d2031 2
a2032 1
	error = biowait(bp);
d2073 3
a2077 2

	(void) buf_cleanout(bp);
d2084 2
a2085 2
	UVMHIST_LOG(pdhist, "<- done (sync)  error=%d", error, 0, 0, 0);
	return (error);
@


1.13.2.7
log
@Merge in trunk
@
text
@d2 1
a2 1
/*	$NetBSD: uvm_swap.c,v 1.40 2000/11/17 11:39:39 mrg Exp $	*/
d66 1
a66 1
 * 
d77 1
a77 1
 * by the "swap_priority" global var.    each "swappri" contains a 
d102 1
a102 1
 *  [2] SWAP_STATS: given a pointer to an array of swapent structures 
d198 1
a198 1
	vnx = pool_get(&vndxfer_pool, PR_WAITOK);			\
d208 1
a208 1
	vbp = pool_get(&vndbuf_pool, PR_WAITOK);			\
d230 1
a230 1
lock_data_t swap_syscall_lock;
a234 1
static void		 swapdrum_add __P((struct swapdev *, int));
d238 1
a238 1
static void		 swaplist_insert __P((struct swapdev *, 
d264 1
a264 1
 * => called at boot time from init_main.c after the filesystems 
d290 1
a290 1
	 * that block 0 is reserved (used to indicate an allocation 
d304 1
a304 1
	    NULL);
d306 2
a307 2
	pool_init(&vndbuf_pool, sizeof(struct vndbuf), 0, 0, 0, "swp vnd",
	    NULL);
a564 21
 * swapdrum_add: add a "swapdev"'s blocks into /dev/drum's area.
 *
 * => caller must hold swap_syscall_lock
 * => uvm.swap_data_lock should be unlocked (we may sleep)
 */
static void
swapdrum_add(sdp, npages)
	struct swapdev *sdp;
	int	npages;
{
	u_long result;

	if (extent_alloc(swapmap, npages, EX_NOALIGN, 0, EX_NOBOUNDARY,
	    EX_WAITOK, &result))
		panic("swapdrum_add");

	sdp->swd_drumoffset = result;
	sdp->swd_drumsize = npages;
}

/*
d577 1
a577 1
	
d582 3
a584 1
		     sdp = CIRCLEQ_NEXT(sdp, swd_next))
d589 1
d630 1
a630 1
	 * SWAP_NSWAP: return number of config'd swap devices 
d644 1
a644 1
	 * note that the swap_priority list can't change as long 
d646 1
a646 1
	 * to grab the uvm.swap_data_lock because we may fault&sleep during 
d662 1
a662 1
				sdp->swd_inuse = 
d682 2
a683 1
					((struct oswapent *)sep)++;
d695 1
a695 1
	} 
d747 1
a747 1
			goto out;
d782 2
d785 1
a785 1
		if ((sdp = swaplist_find(vp, 0)) != NULL) {
d788 2
a791 2
		sdp = malloc(sizeof *sdp, M_VMSWAP, M_WAITOK);
		spp = malloc(sizeof *spp, M_VMSWAP, M_WAITOK);
d854 1
a854 3
		if ((error = swap_off(p, sdp)) != 0)
			goto out;

d892 1
d1021 1
a1021 1
	 * if the vnode we are swapping to is the root vnode 
d1023 1
a1023 1
	 * to make sure we don't overwrite it.   do a statfs to 
d1038 1
a1038 1
		if (extent_alloc_region(sdp->swd_ex, addr, 
d1047 9
a1060 5
  	/*
	 * add anons to reflect the new swap space
	 */
	uvm_anon_add(size);

d1068 7
a1075 2
	swapdrum_add(sdp, npages);
	sdp->swd_npages = size;
a1081 1
bad:
d1083 1
a1083 1
	 * failure: close device if necessary and return error.
d1085 6
a1090 1
	if (vp != rootvp)
d1092 1
d1124 1
a1124 1
		
d1154 1
a1162 1
	simple_unlock(&uvm.swap_data_lock);
d1329 1
a1329 1
			/* 
a1385 26
		/* 
		 * set b_dirtyoff/end and b_validoff/end.   this is
		 * required by the NFS client code (otherwise it will
		 * just discard our I/O request).
		 */
		if (bp->b_dirtyend == 0) {
			nbp->vb_buf.b_dirtyoff = 0;
			nbp->vb_buf.b_dirtyend = sz;
		} else {
			nbp->vb_buf.b_dirtyoff =
			    max(0, bp->b_dirtyoff - (bp->b_bcount-resid));
			nbp->vb_buf.b_dirtyend =
			    min(sz,
				max(0, bp->b_dirtyend - (bp->b_bcount-resid)));
		}
		if (bp->b_validend == 0) {
			nbp->vb_buf.b_validoff = 0;
			nbp->vb_buf.b_validend = sz;
		} else {
			nbp->vb_buf.b_validoff =
			    max(0, bp->b_validoff - (bp->b_bcount-resid));
			nbp->vb_buf.b_validend =
			    min(sz,
				max(0, bp->b_validend - (bp->b_bcount-resid)));
		}

d1506 1
a1506 3
	if (vbp->vb_buf.b_vp != NULL) {
		brelvp(&vbp->vb_buf);
	}
d1569 1
a1569 1
	
d1673 2
a1674 2
	 * convert drum slot offset back to sdp, free the blocks 
	 * in the extent, and return.   must hold pri lock to do 
d1745 1
a1745 1
		return VM_PAGER_ERROR;
d1751 1
d1756 1
a1756 1
	result = uvm_swap_io(&page, swslot, 1, B_READ | 
d1759 2
a1760 1
	if (result != VM_PAGER_OK && result != VM_PAGER_PEND) {
d1764 1
d1785 1
a1785 1
	int	result, s, mapinflags, pflag;
d1815 1
a1815 1
		return (VM_PAGER_AGAIN);
d1861 1
a1861 1
			return (VM_PAGER_AGAIN);
d1868 1
a1868 1
			return (VM_PAGER_AGAIN);
d1897 1
a1897 1
	/* 
d1922 1
a1922 1
		return (VM_PAGER_AGAIN);
d1953 2
a1954 3
	/* 
	 * for pageouts we must set "dirtyoff" [NFS client code needs it].
	 * and we bump v_numoutput (counter of number of active outputs).
a1956 2
		bp->b_dirtyoff = 0;
		bp->b_dirtyend = npages << PAGE_SHIFT;
d1985 1
a1985 1
		return (VM_PAGER_PEND);
d1990 1
a1990 2
	(void) biowait(bp);
	result = (bp->b_flags & B_ERROR) ? VM_PAGER_ERROR : VM_PAGER_OK;
a2030 3
	if (bp->b_vp)
		brelvp(bp);

d2033 2
d2041 2
a2042 2
	UVMHIST_LOG(pdhist, "<- done (sync)  result=%d", result, 0, 0, 0);
	return (result);
@


1.13.2.8
log
@Merge in -current from roughly a week ago
@
text
@d235 2
a236 2
static void		 swapdrum_add(struct swapdev *, int);
static struct swapdev	*swapdrum_getsdp(int);
d238 4
a241 4
static struct swapdev	*swaplist_find(struct vnode *, int);
static void		 swaplist_insert(struct swapdev *, 
					     struct swappri *, int);
static void		 swaplist_trim(void);
d243 2
a244 2
static int swap_on(struct proc *, struct swapdev *);
static int swap_off(struct proc *, struct swapdev *);
d246 3
a248 3
static void sw_reg_strategy(struct swapdev *, struct buf *, int);
static void sw_reg_iodone(struct buf *);
static void sw_reg_start(struct swapdev *);
d250 1
a250 1
static int uvm_swap_io(struct vm_page **, int, int, int);
d252 1
a252 1
static void swapmount(void);
d256 4
a259 4
boolean_t uvm_swap_allocpages(struct vm_page **, int);
void uvm_swap_markdecrypt(struct swapdev *, int, int, int);
boolean_t uvm_swap_needdecrypt(struct swapdev *, int);
void uvm_swap_initcrypt(struct swapdev *, int);
d912 1
a912 1
	extern int (**nfsv2_vnodeop_p)(void *);
@


1.13.2.9
log
@Sync the SMP branch with 3.3
@
text
@d1155 1
a1155 1
		panic("swap_off: swapdev not in list");
a1229 1
		s = splbio();
a1230 1
		splx(s);
d1507 1
a1507 1
	int resid;
d1515 3
a1517 1
	splassert(IPL_BIO);
d1519 1
d1571 1
d1725 1
a1725 1
		if (swap_encrypt_initialized) {
d1859 1
a1859 1
	if (swap_encrypt_initialized  || encrypt) { 
d1990 1
a1990 1
		if (swap_encrypt_initialized)
d2028 1
a2028 1
	if (swap_encrypt_initialized &&
@


1.13.2.10
log
@Merge of current from two weeks agointo the SMP branch
@
text
@d718 1
a718 1
	if ((error = suser(p, 0)))
d1663 10
a1672 10
	if (sdp != NULL) {
		/*
		 * we just keep track of how many pages have been marked bad
		 * in this device, to make everything add up in swap_off().
		 * we assume here that the range of slots will all be within
		 * one swap device.
		 */
		sdp->swd_npgbad += nslots;
		UVMHIST_LOG(pdhist, "now %d bad", sdp->swd_npgbad, 0,0,0);
	}
d1891 1
a1891 1
		if (dstkva == 0) {
@


1.12
log
@swap encryption for UVM, option UVM_SWAP_ENCRYPT.  needs to be enabled
via sysctl.
Pages are encrypted with the Blowfish encryption algorithm, the key
is initialized randomly on first swap out, ensuring that entropy has
accumulated in the kernel randomness pool.  Eventually, swap encryption
will be decided on a process by process basis, e.g. a process that reads from
a cryptographic filesystem will enable swap encrypt for its pages. okay
art@@ and deraadt@@.
@
text
@d947 1
a947 1
#if defined(NFSSERVER) || defined(NFSCLIENT)
d949 1
a949 1
#endif /* defined(NFSSERVER) || defined(NFSCLIENT) */
d1010 1
a1010 1
#if defined(NFSSERVER) || defined(NFSCLIENT)
d1014 1
a1014 1
#endif /* defined(NFSSERVER) || defined(NFSCLIENT) */
@


1.11
log
@Init the buffer dependency list.
@
text
@d55 3
d156 9
d279 8
d360 91
d1113 11
d1224 3
d1886 6
d1896 1
d1913 55
d1982 8
a1989 1
	if (sbp == NULL)
d1991 11
a2001 1

d2024 15
d2049 5
d2086 16
d2107 7
d2213 9
d2223 1
a2223 1
				PGO_PDFREECLUST, 0);
@


1.10
log
@Remove unnecessary printfs. From deraadt@@
@
text
@d1366 1
d1809 1
@


1.9
log
@sync with NetBSD from 1999.05.24 (there is a reason for this date)
 Mostly cleanups, but also a few improvements to pagedaemon for better
 handling of low memory and/or low swap conditions.
@
text
@a2014 2
	printf("Adding swap(%d, %d):", major(swap_dev), minor(swap_dev));

a2015 1
		printf(" failed!\n");
a2022 2

	printf(" ok.\n");
@


1.8
log
@NFS -> NFSSERVER|NFSCLIENT
@
text
@d1 1
a1 2
/*	$OpenBSD: uvm_swap.c,v 1.7 1999/06/24 11:37:02 art Exp $	*/
/*	$NetBSD: uvm_swap.c,v 1.23 1998/12/26 06:25:59 marc Exp $	*/
d87 1
a87 1
 *  - swap_data_lock (simple_lock): this lock protects all swap data
a237 1
static simple_lock_data_t swap_data_lock;
d288 1
a288 1
	simple_lock_init(&swap_data_lock);
d348 1
a348 1
 * => caller must hold both swap_syscall_lock and swap_data_lock
d408 1
a408 1
 * => caller must hold both swap_syscall_lock and swap_data_lock
d444 1
a444 1
 * => caller must hold both swap_syscall_lock and swap_data_lock
d464 1
a464 1
 * => swap_data_lock should be unlocked (we may sleep)
d486 1
a486 1
 * => caller must hold swap_data_lock
d507 1
d560 1
a560 1
	 * to grab the swap_data_lock because we may fault&sleep during 
d664 9
d682 1
a682 1
		simple_lock(&swap_data_lock);
d689 1
a689 1
		simple_unlock(&swap_data_lock);
d702 1
a702 1
		simple_lock(&swap_data_lock);
d705 1
a705 1
			simple_unlock(&swap_data_lock);
d724 1
a724 1
		simple_unlock(&swap_data_lock);
d737 1
a737 1
			simple_lock(&swap_data_lock);
d740 1
a740 1
			simple_unlock(&swap_data_lock);
d763 1
a763 1
		simple_lock(&swap_data_lock);
d765 1
a765 1
			simple_unlock(&swap_data_lock);
d774 1
a774 1
			simple_unlock(&swap_data_lock);
d790 1
a790 1
		simple_unlock(&swap_data_lock);
d821 1
a821 1
 * => caller should leave swap_data_lock unlocked, we may lock it
d964 1
d966 2
a968 1
	
d992 1
d995 2
d1005 1
a1005 1
	simple_lock(&swap_data_lock);
d1010 1
a1010 1
	simple_unlock(&swap_data_lock);
d1163 1
a1163 2
	int	pageno;
	int	bn;
d1172 1
a1172 1
	simple_lock(&swap_data_lock);
d1174 1
a1174 1
	simple_unlock(&swap_data_lock);
d1210 1
a1220 1
			int s = splbio();
a1222 1
			splx(s);
d1236 1
d1565 1
a1565 1
 * => we lock swap_data_lock
d1587 1
a1587 1
	simple_lock(&swap_data_lock);
d1613 1
a1613 1
			simple_unlock(&swap_data_lock);
a1617 12
#if 0
{
	struct swapdev *sdp2;

	sdp2 = swapdrum_getsdp(result + sdp->swd_drumoffset);
	if (sdp2 == NULL) {
printf("uvm_swap_alloc:  nslots=%d, dev=%x, drumoff=%d, result=%ld",
    *nslots, sdp->swd_dev, sdp->swd_drumoffset, result);
panic("uvm_swap_alloc:  allocating unmapped swap block!");
	}
}
#endif
d1629 1
a1629 1
	simple_unlock(&swap_data_lock);
d1637 1
a1637 1
 * => we lock swap_data_lock
d1654 1
a1654 1
	simple_lock(&swap_data_lock);
d1677 1
a1677 1
	simple_unlock(&swap_data_lock);
d1724 7
d1734 9
d1808 1
d1811 1
a1868 1
	bp->b_flags &= ~(B_BUSY|B_WANTED|B_PHYS|B_PAGET|B_UAREA|B_DIRTY|B_NOCACHE);
d1903 1
a1903 1
	 * drop buffers reference to the vnode and its flags.
a1904 1
	bp->b_flags &= ~(B_BUSY|B_WANTED|B_PHYS|B_PAGET|B_UAREA|B_DIRTY|B_NOCACHE);
@


1.7
log
@don't free spp in swapmount, someone else does that for us. From: mickey@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.6 1999/06/17 15:40:54 art Exp $	*/
d828 1
a828 1
#ifdef NFS
d830 1
a830 1
#endif /* NFS */
d891 1
a891 1
#ifdef NFS
d895 1
a895 1
#endif /* NFS */
@


1.6
log
@This is embarassing. (I have to start testing the code that I retype from the diffs)
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.5 1999/06/04 00:23:17 art Exp $	*/
a2007 1
		free(spp, M_VMSWAP);
@


1.5
log
@start swapping on the first swap device after initialization
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.3 1999/06/02 13:23:22 mickey Exp $	*/
d330 6
a1956 5

	/*
	 * Setup the initial swap partition
	 */
	swapmount();
@


1.4
log
@remove sys_swapon, it's in already in compat. (how did this ever link?)
@
text
@d267 2
d1953 5
d1962 53
@


1.3
log
@enable sys_swapctl() implementation
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_swap.c,v 1.2 1999/02/26 05:32:08 art Exp $	*/
a500 13

/*XXX
 *XXX
 *XXX*/
int
sys_swapon(p, v, retval)
	struct proc *p;
	void *v;
	register_t *retval;
{
	return EINVAL;
}

d1954 1
@


1.2
log
@add OpenBSD tags
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d132 6
a137 5
	struct oswapent swd_ose;
#define	swd_dev		swd_ose.ose_dev		/* device id */
#define	swd_flags	swd_ose.ose_flags	/* flags:inuse/enable/fake */
#define	swd_priority	swd_ose.ose_priority	/* our priority */
	/* also: swd_ose.ose_nblks, swd_ose.ose_inuse */
a243 1
#ifdef notyet
a244 1
#endif
a246 1
#ifdef notyet /* swapctl */
a252 1
#endif
a346 1
#ifdef notyet /* used by swapctl */
a396 1
#endif
a397 1
#ifdef notyet /* used by swapctl */
a473 1
#endif
a513 1
#ifdef notyet /* XXXXXXXXXXXXXXXX (it has other bugs beside the fact that I don't want to change syscalls.master) */
d590 1
a590 1
				sdp->swd_ose.ose_inuse = 
d592 2
a593 2
				error = copyout((caddr_t)&sdp->swd_ose,
				    (caddr_t)sep, sizeof(struct oswapent));
d640 1
a640 1
		if (vget(vp, LK_EXCLUSIVE)) {
a809 2
#endif

a820 1
#ifdef notyet /* used by swapctl */
d914 1
a914 1
	sdp->swd_ose.ose_nblks = nblocks;
a1052 1
#endif
@


1.1
log
@Import of uvm from NetBSD. Some local changes, some code disabled
@
text
@d1 1
@

