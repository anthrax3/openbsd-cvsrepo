head	1.24;
access;
symbols
	OPENBSD_4_5:1.22.0.6
	OPENBSD_4_5_BASE:1.22
	OPENBSD_4_4:1.22.0.4
	OPENBSD_4_4_BASE:1.22
	OPENBSD_4_3:1.22.0.2
	OPENBSD_4_3_BASE:1.22
	OPENBSD_4_2:1.21.0.2
	OPENBSD_4_2_BASE:1.21
	OPENBSD_4_1:1.18.0.4
	OPENBSD_4_1_BASE:1.18
	OPENBSD_4_0:1.18.0.2
	OPENBSD_4_0_BASE:1.18
	OPENBSD_3_9:1.17.0.4
	OPENBSD_3_9_BASE:1.17
	OPENBSD_3_8:1.17.0.2
	OPENBSD_3_8_BASE:1.17
	OPENBSD_3_7:1.16.0.10
	OPENBSD_3_7_BASE:1.16
	OPENBSD_3_6:1.16.0.8
	OPENBSD_3_6_BASE:1.16
	SMP_SYNC_A:1.16
	SMP_SYNC_B:1.16
	OPENBSD_3_5:1.16.0.6
	OPENBSD_3_5_BASE:1.16
	OPENBSD_3_4:1.16.0.4
	OPENBSD_3_4_BASE:1.16
	UBC_SYNC_A:1.16
	OPENBSD_3_3:1.16.0.2
	OPENBSD_3_3_BASE:1.16
	OPENBSD_3_2:1.15.0.4
	OPENBSD_3_2_BASE:1.15
	OPENBSD_3_1:1.15.0.2
	OPENBSD_3_1_BASE:1.15
	UBC_SYNC_B:1.15
	UBC:1.11.0.2
	UBC_BASE:1.11
	OPENBSD_3_0:1.8.0.2
	OPENBSD_3_0_BASE:1.8
	OPENBSD_2_9_BASE:1.6
	OPENBSD_2_9:1.6.0.2
	OPENBSD_2_8:1.4.0.4
	OPENBSD_2_8_BASE:1.4
	OPENBSD_2_7:1.4.0.2
	OPENBSD_2_7_BASE:1.4
	SMP:1.3.0.4
	SMP_BASE:1.3
	kame_19991208:1.3
	OPENBSD_2_6:1.3.0.2
	OPENBSD_2_6_BASE:1.3
	OPENBSD_2_5:1.2.0.2
	OPENBSD_2_5_BASE:1.2;
locks; strict;
comment	@ * @;


1.24
date	2009.03.25.20.00.18;	author oga;	state dead;
branches;
next	1.23;

1.23
date	2009.03.20.15.19.04;	author oga;	state Exp;
branches;
next	1.22;

1.22
date	2007.10.29.17.08.08;	author chl;	state Exp;
branches;
next	1.21;

1.21
date	2007.04.11.12.10.42;	author art;	state Exp;
branches;
next	1.20;

1.20
date	2007.04.04.18.02.59;	author art;	state Exp;
branches;
next	1.19;

1.19
date	2007.03.25.13.02.51;	author thib;	state Exp;
branches;
next	1.18;

1.18
date	2006.07.26.23.15.55;	author mickey;	state Exp;
branches;
next	1.17;

1.17
date	2005.05.24.21.11.47;	author tedu;	state Exp;
branches;
next	1.16;

1.16
date	2002.10.29.18.30.21;	author art;	state Exp;
branches;
next	1.15;

1.15
date	2002.02.28.18.50.26;	author provos;	state Exp;
branches;
next	1.14;

1.14
date	2002.02.25.05.38.50;	author provos;	state Exp;
branches;
next	1.13;

1.13
date	2002.02.25.00.20.45;	author provos;	state Exp;
branches;
next	1.12;

1.12
date	2001.12.19.08.58.07;	author art;	state Exp;
branches;
next	1.11;

1.11
date	2001.11.28.19.28.15;	author art;	state Exp;
branches
	1.11.2.1;
next	1.10;

1.10
date	2001.11.28.13.47.40;	author art;	state Exp;
branches;
next	1.9;

1.9
date	2001.11.09.03.32.23;	author art;	state Exp;
branches;
next	1.8;

1.8
date	2001.08.11.10.57.22;	author art;	state Exp;
branches;
next	1.7;

1.7
date	2001.05.10.07.59.06;	author art;	state Exp;
branches;
next	1.6;

1.6
date	2001.03.09.14.20.51;	author art;	state Exp;
branches;
next	1.5;

1.5
date	2001.01.29.02.07.46;	author niklas;	state Exp;
branches;
next	1.4;

1.4
date	2000.03.16.22.11.04;	author art;	state Exp;
branches;
next	1.3;

1.3
date	99.08.23.08.13.24;	author art;	state Exp;
branches
	1.3.4.1;
next	1.2;

1.2
date	99.02.26.05.32.07;	author art;	state Exp;
branches;
next	1.1;

1.1
date	99.02.26.01.30.15;	author art;	state Exp;
branches;
next	;

1.3.4.1
date	2000.03.24.09.09.50;	author niklas;	state Exp;
branches;
next	1.3.4.2;

1.3.4.2
date	2001.05.14.22.47.46;	author niklas;	state Exp;
branches;
next	1.3.4.3;

1.3.4.3
date	2001.07.04.11.01.06;	author niklas;	state Exp;
branches;
next	1.3.4.4;

1.3.4.4
date	2001.10.31.03.32.14;	author nate;	state Exp;
branches;
next	1.3.4.5;

1.3.4.5
date	2001.11.13.23.02.31;	author niklas;	state Exp;
branches;
next	1.3.4.6;

1.3.4.6
date	2001.12.05.01.23.58;	author niklas;	state Exp;
branches;
next	1.3.4.7;

1.3.4.7
date	2002.03.06.02.17.14;	author niklas;	state Exp;
branches;
next	1.3.4.8;

1.3.4.8
date	2003.03.28.00.08.48;	author niklas;	state Exp;
branches;
next	;

1.11.2.1
date	2002.06.11.03.33.03;	author art;	state Exp;
branches;
next	1.11.2.2;

1.11.2.2
date	2002.11.04.18.02.33;	author art;	state Exp;
branches;
next	;


desc
@@


1.24
log
@Move all of the pseudo-inline functions in uvm into C files.

By pseudo-inline, I mean that if a certain macro was defined, they would
be inlined. However, no architecture defines that, and none has for a
very very long time. Therefore mainly this just makes the code a damned
sight easier to read. Some k&r -> ansi declarations while I'm in there.

"just commit it" art@@. ok weingart@@.
@
text
@/*	$OpenBSD: uvm_map_i.h,v 1.23 2009/03/20 15:19:04 oga Exp $	*/
/*	$NetBSD: uvm_map_i.h,v 1.18 2000/11/27 08:40:04 chs Exp $	*/

/* 
 * Copyright (c) 1997 Charles D. Cranor and Washington University.
 * Copyright (c) 1991, 1993, The Regents of the University of California.  
 *
 * All rights reserved.
 *
 * This code is derived from software contributed to Berkeley by
 * The Mach Operating System project at Carnegie-Mellon University.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *	This product includes software developed by Charles D. Cranor,
 *      Washington University, the University of California, Berkeley and 
 *      its contributors.
 * 4. Neither the name of the University nor the names of its contributors
 *    may be used to endorse or promote products derived from this software
 *    without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE
 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
 *
 *	@@(#)vm_map.c    8.3 (Berkeley) 1/12/94
 * from: Id: uvm_map_i.h,v 1.1.2.1 1997/08/14 19:10:50 chuck Exp
 *
 *
 * Copyright (c) 1987, 1990 Carnegie-Mellon University.
 * All rights reserved.
 * 
 * Permission to use, copy, modify and distribute this software and
 * its documentation is hereby granted, provided that both the copyright
 * notice and this permission notice appear in all copies of the
 * software, derivative works or modified versions, and any portions
 * thereof, and that both notices appear in supporting documentation.
 * 
 * CARNEGIE MELLON ALLOWS FREE USE OF THIS SOFTWARE IN ITS "AS IS" 
 * CONDITION.  CARNEGIE MELLON DISCLAIMS ANY LIABILITY OF ANY KIND 
 * FOR ANY DAMAGES WHATSOEVER RESULTING FROM THE USE OF THIS SOFTWARE.
 * 
 * Carnegie Mellon requests users of this software to return to
 *
 *  Software Distribution Coordinator  or  Software.Distribution@@CS.CMU.EDU
 *  School of Computer Science
 *  Carnegie Mellon University
 *  Pittsburgh PA 15213-3890
 *
 * any improvements or extensions that they make and grant Carnegie the
 * rights to redistribute these changes.
 */

#ifndef _UVM_UVM_MAP_I_H_
#define _UVM_UVM_MAP_I_H_

/*
 * uvm_map_i.h
 */

/*
 * inline functions [maybe]
 */

#if defined(UVM_MAP_INLINE) || defined(UVM_MAP)

/*
 * uvm_map_create: create map
 */

MAP_INLINE vm_map_t
uvm_map_create(pmap_t pmap, vaddr_t min, vaddr_t max, int flags)
{
	vm_map_t result;

	result = malloc(sizeof(struct vm_map), M_VMMAP, M_WAITOK);
	uvm_map_setup(result, min, max, flags);
	result->pmap = pmap;
	return(result);
}

/*
 * uvm_map_setup: init map
 *
 * => map must not be in service yet.
 */

MAP_INLINE void
uvm_map_setup(vm_map_t map, vaddr_t min, vaddr_t max, int flags)
{

	RB_INIT(&map->rbhead);
	map->header.next = map->header.prev = &map->header;
	map->nentries = 0;
	map->size = 0;
	map->ref_count = 1;
	map->min_offset = min;
	map->max_offset = max;
	map->flags = flags;
	map->first_free = &map->header;
	map->hint = &map->header;
	map->timestamp = 0;
	rw_init(&map->lock, "vmmaplk");
	simple_lock_init(&map->ref_lock);
	simple_lock_init(&map->hint_lock);
}


/*
 *   U N M A P   -   m a i n   e n t r y   p o i n t
 */

/*
 * uvm_unmap: remove mappings from a vm_map (from "start" up to "stop")
 *
 * => caller must check alignment and size 
 * => map must be unlocked (we will lock it)
 */

MAP_INLINE void
uvm_unmap_p(vm_map_t map, vaddr_t start, vaddr_t end, struct proc *p)
{
	vm_map_entry_t dead_entries;
	UVMHIST_FUNC("uvm_unmap"); UVMHIST_CALLED(maphist);

	UVMHIST_LOG(maphist, "  (map=%p, start=0x%lx, end=0x%lx)",
	    map, start, end, 0);
	/*
	 * work now done by helper functions.   wipe the pmap's and then
	 * detach from the dead entries...
	 */
	vm_map_lock(map);
	uvm_unmap_remove(map, start, end, &dead_entries, p);
	vm_map_unlock(map);

	if (dead_entries != NULL)
		uvm_unmap_detach(dead_entries, 0);

	UVMHIST_LOG(maphist, "<- done", 0,0,0,0);
}


/*
 * uvm_map_reference: add reference to a map
 *
 * => map need not be locked (we use ref_lock).
 */

MAP_INLINE void
uvm_map_reference(vm_map_t map)
{
	simple_lock(&map->ref_lock);
	map->ref_count++; 
	simple_unlock(&map->ref_lock);
}

/*
 * uvm_map_deallocate: drop reference to a map
 *
 * => caller must not lock map
 * => we will zap map if ref count goes to zero
 */

MAP_INLINE void
uvm_map_deallocate(vm_map_t map)
{
	int c;

	simple_lock(&map->ref_lock);
	c = --map->ref_count;
	simple_unlock(&map->ref_lock);
	if (c > 0) {
		return;
	}

	/*
	 * all references gone.   unmap and free.
	 */

	uvm_unmap(map, map->min_offset, map->max_offset);
	pmap_destroy(map->pmap);
	free(map, M_VMMAP);
}

#endif /* defined(UVM_MAP_INLINE) || defined(UVM_MAP) */

#endif /* _UVM_UVM_MAP_I_H_ */
@


1.23
log
@While working on some stuff in uvm I've gotten REALLY sick of reading
K&R function declarations, so switch them all over to ansi-style, in
accordance with the prophesy.

"go for it" art@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_map_i.h,v 1.22 2007/10/29 17:08:08 chl Exp $	*/
@


1.22
log
@MALLOC/FREE -> malloc/free

ok krw@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_map_i.h,v 1.21 2007/04/11 12:10:42 art Exp $	*/
d88 1
a88 4
uvm_map_create(pmap, min, max, flags)
	pmap_t pmap;
	vaddr_t min, max;
	int flags;
d105 1
a105 4
uvm_map_setup(map, min, max, flags)
	vm_map_t map;
	vaddr_t min, max;
	int flags;
d137 1
a137 4
uvm_unmap_p(map, start, end, p)
	vm_map_t map;
	vaddr_t start,end;
	struct proc *p;
d166 1
a166 2
uvm_map_reference(map)
	vm_map_t map;
d181 1
a181 2
uvm_map_deallocate(map)
	vm_map_t map;
@


1.21
log
@Instead of managing pages for intrsafe maps in special objects (aka.
kmem_object) just so that we can remove them, just use pmap_extract
to get the pages to free and simplify a lot of code to not deal with
the list of intrsafe maps, intrsafe objects, etc.

miod@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_map_i.h,v 1.20 2007/04/04 18:02:59 art Exp $	*/
d95 1
a95 1
	MALLOC(result, vm_map_t, sizeof(struct vm_map), M_VMMAP, M_WAITOK);
d209 1
a209 1
	FREE(map, M_VMMAP);
@


1.20
log
@Switch vm_map lock to rwlock.
Use a simple "rw_exit_read(); rw_enter_write();" for lock upgrade, since
that's what lockmgr did anyway.

deraadt@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_map_i.h,v 1.19 2007/03/25 13:02:51 thib Exp $	*/
d95 1
a95 4
	MALLOC(result, vm_map_t,
	    (flags & VM_MAP_INTRSAFE) ? sizeof(struct vm_map_intrsafe) :
					sizeof(struct vm_map),
	    M_VMMAP, M_WAITOK);
a127 17

	/*
	 * If the map is interrupt safe, place it on the list
	 * of interrupt safe maps, for uvm_fault().
	 *
	 * We almost never set up an interrupt-safe map, but we set
	 * up quite a few regular ones (at every fork!), so put
	 * interrupt-safe map setup in the slow path.
	 */
	if (__predict_false(flags & VM_MAP_INTRSAFE)) {
		struct vm_map_intrsafe *vmi = (struct vm_map_intrsafe *)map;
		int s;

		s = vmi_list_lock();
		LIST_INSERT_HEAD(&vmi_list, vmi, vmi_list);
		vmi_list_unlock(s);
	}
@


1.19
log
@Remove the flags_lock simplelock from struct vm_map;
Cleanup the code accordingly.

ok pedro@@, art@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_map_i.h,v 1.18 2006/07/26 23:15:55 mickey Exp $	*/
d128 1
a128 1
	lockinit(&map->lock, PVM, "vmmaplk", 0, 0);
@


1.18
log
@fix fmts for UVMHIST_LOG() entries making it more useful on 64bit archs; miod@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_map_i.h,v 1.17 2005/05/24 21:11:47 tedu Exp $	*/
a130 1
	simple_lock_init(&map->flags_lock);
@


1.17
log
@add a new field to vm_space and use it to track the number of anon
pages a process uses.  this is now the userland "data size" value.
ok art deraadt tdeval.  thanks testers.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_map_i.h,v 1.16 2002/10/29 18:30:21 art Exp $	*/
d172 1
a172 1
	UVMHIST_LOG(maphist, "  (map=0x%x, start=0x%x, end=0x%x)",
@


1.16
log
@Since memory deallocation can't fail, remove the error return from
uvm_unmap, uvm_deallocate and a few other functions.
Simplifies some code and reduces diff to the UBC branch.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_map_i.h,v 1.15 2002/02/28 18:50:26 provos Exp $	*/
d164 1
a164 1
uvm_unmap(map, start, end)
d167 1
d179 1
a179 1
	uvm_unmap_remove(map, start, end, &dead_entries);
@


1.15
log
@use red-black tree for lookup_entry.  the red-black tree case for
map_findspace is still broken on alpha.  this will make debugging easier.
okay millert@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_map_i.h,v 1.13 2002/02/25 00:20:45 provos Exp $	*/
d163 1
a163 1
MAP_INLINE int
a167 1
	int result;
d178 1
a178 1
	result = uvm_unmap_remove(map, start, end, &dead_entries);
a184 1
	return(result);
@


1.14
log
@back out red-black tree. they are very fast but alpha UVM is broken and
the tree triggers the bug, PMAP_PREFER case was broken also.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_map_i.h,v 1.12 2001/12/19 08:58:07 art Exp $	*/
d117 1
@


1.13
log
@use a red-black tree to find entries in the vm_map. augment the red-black
tree to find free space between entries.  speeds up memory allocation,
etc...
@
text
@a116 1
	RB_INIT(&map->rbhead);
@


1.12
log
@UBC was a disaster. It worked very good when it worked, but on some
machines or some configurations or in some phase of the moon (we actually
don't know when or why) files disappeared. Since we've not been able to
track down the problem in two weeks intense debugging and we need -current
to be stable, back out everything to a state it had before UBC.

We apologise for the inconvenience.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_map_i.h,v 1.9 2001/11/09 03:32:23 art Exp $	*/
d117 1
@


1.11
log
@Sync in more uvm from NetBSD. Mostly just cosmetic stuff.
Contains also support for page coloring.
@
text
@d1 2
a2 2
/*	$OpenBSD: uvm_map_i.h,v 1.10 2001/11/28 13:47:40 art Exp $	*/
/*	$NetBSD: uvm_map_i.h,v 1.22 2001/06/26 17:55:15 thorpej Exp $	*/
d4 1
a4 1
/*
d6 1
a6 1
 * Copyright (c) 1991, 1993, The Regents of the University of California.
d24 1
a24 1
 *      Washington University, the University of California, Berkeley and
d48 1
a48 1
 *
d54 3
a56 3
 *
 * CARNEGIE MELLON ALLOWS FREE USE OF THIS SOFTWARE IN ITS "AS IS"
 * CONDITION.  CARNEGIE MELLON DISCLAIMS ANY LIABILITY OF ANY KIND
d58 1
a58 1
 *
d87 1
a87 1
MAP_INLINE struct vm_map *
d93 1
a93 1
	struct vm_map *result;
d95 3
a97 1
	MALLOC(result, struct vm_map *, sizeof(struct vm_map),
d112 1
a112 1
	struct vm_map *map;
d131 17
d158 1
a158 1
 * => caller must check alignment and size
d162 1
a162 1
MAP_INLINE void
d164 1
a164 1
	struct vm_map *map;
d167 2
a168 1
	struct vm_map_entry *dead_entries;
d178 1
a178 1
	uvm_unmap_remove(map, start, end, &dead_entries);
d185 1
d197 1
a197 1
	struct vm_map *map;
d200 1
a200 1
	map->ref_count++;
d213 1
a213 1
	struct vm_map *map;
@


1.11.2.1
log
@Sync UBC branch to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm_map_i.h,v 1.11 2001/11/28 19:28:15 art Exp $	*/
a114 1
	RB_INIT(&map->rbhead);
@


1.11.2.2
log
@Huge sync to NetBSD plus lots of bugfixes.
 - uvm is as in netbsd-current minus uvm_map forward merge.
 - various locking bugfixes in nfs.
 - make sure that all specops and fifoops are correct in all vnodeop vectors.
 - make the filesystem code more like filsystem code and less like vm code.
@
text
@d1 2
a2 2
/*	$OpenBSD: uvm_map_i.h,v 1.11.2.1 2002/06/11 03:33:03 art Exp $	*/
/*	$NetBSD: uvm_map_i.h,v 1.23 2002/09/22 07:21:31 chs Exp $	*/
d183 30
@


1.10
log
@Sync in more uvm changes from NetBSD.
This time we're getting rid of KERN_* and VM_PAGER_* error codes and
use errnos instead.
@
text
@d1 2
a2 2
/*	$OpenBSD: uvm_map_i.h,v 1.9 2001/11/09 03:32:23 art Exp $	*/
/*	$NetBSD: uvm_map_i.h,v 1.19 2001/03/15 06:10:57 chs Exp $	*/
d4 1
a4 1
/* 
d6 1
a6 1
 * Copyright (c) 1991, 1993, The Regents of the University of California.  
d24 1
a24 1
 *      Washington University, the University of California, Berkeley and 
d48 1
a48 1
 * 
d54 3
a56 3
 * 
 * CARNEGIE MELLON ALLOWS FREE USE OF THIS SOFTWARE IN ITS "AS IS" 
 * CONDITION.  CARNEGIE MELLON DISCLAIMS ANY LIABILITY OF ANY KIND 
d58 1
a58 1
 * 
d87 1
a87 1
MAP_INLINE vm_map_t
d93 1
a93 1
	vm_map_t result;
d95 1
a95 3
	MALLOC(result, vm_map_t,
	    (flags & VM_MAP_INTRSAFE) ? sizeof(struct vm_map_intrsafe) :
					sizeof(struct vm_map),
d110 1
a110 1
	vm_map_t map;
a128 17

	/*
	 * If the map is interrupt safe, place it on the list
	 * of interrupt safe maps, for uvm_fault().
	 *
	 * We almost never set up an interrupt-safe map, but we set
	 * up quite a few regular ones (at every fork!), so put
	 * interrupt-safe map setup in the slow path.
	 */
	if (__predict_false(flags & VM_MAP_INTRSAFE)) {
		struct vm_map_intrsafe *vmi = (struct vm_map_intrsafe *)map;
		int s;

		s = vmi_list_lock();
		LIST_INSERT_HEAD(&vmi_list, vmi, vmi_list);
		vmi_list_unlock(s);
	}
d139 1
a139 1
 * => caller must check alignment and size 
d145 1
a145 1
	vm_map_t map;
d148 1
a148 1
	vm_map_entry_t dead_entries;
d176 1
a176 1
	vm_map_t map;
d179 1
a179 1
	map->ref_count++; 
d192 1
a192 1
	vm_map_t map;
@


1.9
log
@minor sync to NetBSD.
@
text
@d1 2
a2 2
/*	$OpenBSD: uvm_map_i.h,v 1.8 2001/08/11 10:57:22 art Exp $	*/
/*	$NetBSD: uvm_map_i.h,v 1.18 2000/11/27 08:40:04 chs Exp $	*/
d162 1
a162 1
MAP_INLINE int
a166 1
	int result;
d177 1
a177 1
	result = uvm_unmap_remove(map, start, end, &dead_entries);
a183 1
	return(result);
@


1.8
log
@Various random fixes from NetBSD.
Including support for zeroing pages in the idle loop (not enabled yet).
@
text
@d1 2
a2 2
/*	$OpenBSD: uvm_map_i.h,v 1.7 2001/05/10 07:59:06 art Exp $	*/
/*	$NetBSD: uvm_map_i.h,v 1.17 2000/05/08 22:59:35 thorpej Exp $	*/
a198 10
	if (__predict_false(map == NULL)) {
#ifdef DIAGNOSTIC
		printf("uvm_map_reference: reference to NULL map\n");
#ifdef DDB
		Debugger();
#endif
#endif
		return;
	}

a216 10
	if (__predict_false(map == NULL)) {
#ifdef DIAGNOSTIC
		printf("uvm_map_deallocate: reference to NULL map\n");
#ifdef DDB
		Debugger();
#endif
#endif
		return;
	}

a219 1

a229 1

@


1.7
log
@Some locking protocol fixes and better enforcement of wiring limits.

From NetBSD.
@
text
@d1 2
a2 2
/*	$OpenBSD: uvm_map_i.h,v 1.6 2001/03/09 14:20:51 art Exp $	*/
/*	$NetBSD: uvm_map_i.h,v 1.16 1999/07/01 20:07:05 thorpej Exp $	*/
d135 4
d140 1
a140 1
	if (flags & VM_MAP_INTRSAFE) {
d199 1
a199 1
	if (map == NULL) {
d227 1
a227 1
	if (map == NULL) {
@


1.6
log
@More syncing to NetBSD.

Implements mincore(2), mlockall(2) and munlockall(2). mlockall and munlockall
are disabled for the moment.

The rest is mostly cosmetic.
@
text
@d1 2
a2 2
/*	$OpenBSD: uvm_map_i.h,v 1.5 2001/01/29 02:07:46 niklas Exp $	*/
/*	$NetBSD: uvm_map_i.h,v 1.15 1999/06/14 22:05:23 thorpej Exp $	*/
d130 1
@


1.5
log
@$OpenBSD$
@
text
@d1 2
a2 2
/*	$OpenBSD: uvm_map_i.h,v 1.14 1999/06/04 23:38:42 thorpej Exp $	*/
/*	$NetBSD: uvm_map_i.h,v 1.14 1999/06/04 23:38:42 thorpej Exp $	*/
d127 1
a127 1
	lockinit(&map->lock, PVM, "thrd_sleep", 0, 0);
@


1.4
log
@Bring in some new UVM code from NetBSD (not current).

 - Introduce a new type of map that are interrupt safe and never allow faults
   in them. mb_map and kmem_map are made intrsafe.
 - Add "access protection" to uvm_vslock (to be passed down to uvm_fault and
   later to pmap_enter).
 - madvise(2) now works.
 - various cleanups.
@
text
@d1 1
@


1.3
log
@sync with NetBSD from 1999.05.24 (there is a reason for this date)
 Mostly cleanups, but also a few improvements to pagedaemon for better
 handling of low memory and/or low swap conditions.
@
text
@d1 1
a1 1
/*	$NetBSD: uvm_map_i.h,v 1.11 1999/03/25 18:48:53 mrg Exp $	*/
d87 1
a87 1
uvm_map_create(pmap, min, max, pageable)
d90 1
a90 1
	boolean_t pageable;
d94 5
a98 2
	MALLOC(result, vm_map_t, sizeof(struct vm_map), M_VMMAP, M_WAITOK);
	uvm_map_setup(result, min, max, pageable);
d110 1
a110 1
uvm_map_setup(map, min, max, pageable)
d113 1
a113 1
	boolean_t pageable;
d122 1
a122 1
	map->entries_pageable = pageable;
d129 13
@


1.3.4.1
log
@Sync with -current
@
text
@d1 1
a1 1
/*	$NetBSD: uvm_map_i.h,v 1.14 1999/06/04 23:38:42 thorpej Exp $	*/
d87 1
a87 1
uvm_map_create(pmap, min, max, flags)
d90 1
a90 1
	int flags;
d94 2
a95 5
	MALLOC(result, vm_map_t,
	    (flags & VM_MAP_INTRSAFE) ? sizeof(struct vm_map_intrsafe) :
					sizeof(struct vm_map),
	    M_VMMAP, M_WAITOK);
	uvm_map_setup(result, min, max, flags);
d107 1
a107 1
uvm_map_setup(map, min, max, flags)
d110 1
a110 1
	int flags;
d119 1
a119 1
	map->flags = flags;
a125 13

	/*
	 * If the map is interrupt safe, place it on the list
	 * of interrupt safe maps, for uvm_fault().
	 */
	if (flags & VM_MAP_INTRSAFE) {
		struct vm_map_intrsafe *vmi = (struct vm_map_intrsafe *)map;
		int s;

		s = vmi_list_lock();
		LIST_INSERT_HEAD(&vmi_list, vmi, vmi_list);
		vmi_list_unlock(s);
	}
@


1.3.4.2
log
@merge in approximately 2.9 into SMP branch
@
text
@d1 1
a1 2
/*	$OpenBSD: uvm_map_i.h,v 1.6 2001/03/09 14:20:51 art Exp $	*/
/*	$NetBSD: uvm_map_i.h,v 1.15 1999/06/14 22:05:23 thorpej Exp $	*/
d126 1
a126 1
	lockinit(&map->lock, PVM, "vmmaplk", 0, 0);
@


1.3.4.3
log
@Merge in -current from two days ago in the SMP branch.
As usual with merges, they do not indicate progress, so do not hold
your breath for working SMP, and do not mail me and ask about the
state of it.  It has not changed.  There is work ongoing, but very, very
slowly.  The commit is done in parts as to not lock up the tree in too
big chunks at a time.
@
text
@d1 2
a2 2
/*	$OpenBSD$	*/
/*	$NetBSD: uvm_map_i.h,v 1.16 1999/07/01 20:07:05 thorpej Exp $	*/
a129 1
	simple_lock_init(&map->flags_lock);
@


1.3.4.4
log
@Sync the SMP branch to something just after 3.0
@
text
@d2 1
a2 1
/*	$NetBSD: uvm_map_i.h,v 1.17 2000/05/08 22:59:35 thorpej Exp $	*/
a134 4
	 *
	 * We almost never set up an interrupt-safe map, but we set
	 * up quite a few regular ones (at every fork!), so put
	 * interrupt-safe map setup in the slow path.
d136 1
a136 1
	if (__predict_false(flags & VM_MAP_INTRSAFE)) {
d195 1
a195 1
	if (__predict_false(map == NULL)) {
d223 1
a223 1
	if (__predict_false(map == NULL)) {
@


1.3.4.5
log
@merge in -current
@
text
@d2 1
a2 1
/*	$NetBSD: uvm_map_i.h,v 1.18 2000/11/27 08:40:04 chs Exp $	*/
d199 10
d227 10
d240 1
d251 1
@


1.3.4.6
log
@Merge in -current
@
text
@d2 1
a2 1
/*	$NetBSD: uvm_map_i.h,v 1.22 2001/06/26 17:55:15 thorpej Exp $	*/
d4 1
a4 1
/*
d6 1
a6 1
 * Copyright (c) 1991, 1993, The Regents of the University of California.
d24 1
a24 1
 *      Washington University, the University of California, Berkeley and
d48 1
a48 1
 *
d54 3
a56 3
 *
 * CARNEGIE MELLON ALLOWS FREE USE OF THIS SOFTWARE IN ITS "AS IS"
 * CONDITION.  CARNEGIE MELLON DISCLAIMS ANY LIABILITY OF ANY KIND
d58 1
a58 1
 *
d87 1
a87 1
MAP_INLINE struct vm_map *
d93 1
a93 1
	struct vm_map *result;
d95 3
a97 1
	MALLOC(result, struct vm_map *, sizeof(struct vm_map),
d112 1
a112 1
	struct vm_map *map;
d131 17
d158 1
a158 1
 * => caller must check alignment and size
d162 1
a162 1
MAP_INLINE void
d164 1
a164 1
	struct vm_map *map;
d167 2
a168 1
	struct vm_map_entry *dead_entries;
d178 1
a178 1
	uvm_unmap_remove(map, start, end, &dead_entries);
d185 1
d197 1
a197 1
	struct vm_map *map;
d200 1
a200 1
	map->ref_count++;
d213 1
a213 1
	struct vm_map *map;
@


1.3.4.7
log
@Merge in trunk
@
text
@d2 1
a2 1
/*	$NetBSD: uvm_map_i.h,v 1.18 2000/11/27 08:40:04 chs Exp $	*/
d4 1
a4 1
/* 
d6 1
a6 1
 * Copyright (c) 1991, 1993, The Regents of the University of California.  
d24 1
a24 1
 *      Washington University, the University of California, Berkeley and 
d48 1
a48 1
 * 
d54 3
a56 3
 * 
 * CARNEGIE MELLON ALLOWS FREE USE OF THIS SOFTWARE IN ITS "AS IS" 
 * CONDITION.  CARNEGIE MELLON DISCLAIMS ANY LIABILITY OF ANY KIND 
d58 1
a58 1
 * 
d87 1
a87 1
MAP_INLINE vm_map_t
d93 1
a93 1
	vm_map_t result;
d95 1
a95 3
	MALLOC(result, vm_map_t,
	    (flags & VM_MAP_INTRSAFE) ? sizeof(struct vm_map_intrsafe) :
					sizeof(struct vm_map),
d110 1
a110 1
	vm_map_t map;
a114 1
	RB_INIT(&map->rbhead);
a128 17

	/*
	 * If the map is interrupt safe, place it on the list
	 * of interrupt safe maps, for uvm_fault().
	 *
	 * We almost never set up an interrupt-safe map, but we set
	 * up quite a few regular ones (at every fork!), so put
	 * interrupt-safe map setup in the slow path.
	 */
	if (__predict_false(flags & VM_MAP_INTRSAFE)) {
		struct vm_map_intrsafe *vmi = (struct vm_map_intrsafe *)map;
		int s;

		s = vmi_list_lock();
		LIST_INSERT_HEAD(&vmi_list, vmi, vmi_list);
		vmi_list_unlock(s);
	}
d139 1
a139 1
 * => caller must check alignment and size 
d143 1
a143 1
MAP_INLINE int
d145 1
a145 1
	vm_map_t map;
d148 1
a148 2
	int result;
	vm_map_entry_t dead_entries;
d158 1
a158 1
	result = uvm_unmap_remove(map, start, end, &dead_entries);
a164 1
	return(result);
d176 1
a176 1
	vm_map_t map;
d179 1
a179 1
	map->ref_count++; 
d192 1
a192 1
	vm_map_t map;
@


1.3.4.8
log
@Sync the SMP branch with 3.3
@
text
@d163 1
a163 1
MAP_INLINE void
d168 1
d179 1
a179 1
	uvm_unmap_remove(map, start, end, &dead_entries);
d186 1
@


1.2
log
@add OpenBSD tags
@
text
@d1 1
a1 2
/*	$OpenBSD$	*/
/*	$NetBSD: uvm_map_i.h,v 1.10 1998/10/11 23:14:48 chuck Exp $	*/
a2 4
/*
 * XXXCDC: "ROUGH DRAFT" QUALITY UVM PRE-RELEASE FILE!
 *         >>>USE AT YOUR OWN RISK, WORK IS NOT FINISHED<<<
 */
a137 4
 * => if the "start"/"stop" range lie within a mapping of a share map,
 *    then the unmap takes place within the context of that share map
 *    rather than in the main map, unless the "mainonly" flag is set.
 *    (e.g. the "exit" system call would want to set "mainonly").
d150 1
a150 1
	map, start, end, 0);
@


1.1
log
@Import of uvm from NetBSD. Some local changes, some code disabled
@
text
@d1 1
@

