head	1.61;
access;
symbols
	OPENBSD_6_2:1.61.0.6
	OPENBSD_6_2_BASE:1.61
	OPENBSD_6_1:1.61.0.4
	OPENBSD_6_1_BASE:1.61
	OPENBSD_6_0:1.60.0.4
	OPENBSD_6_0_BASE:1.60
	OPENBSD_5_9:1.60.0.2
	OPENBSD_5_9_BASE:1.60
	OPENBSD_5_8:1.59.0.4
	OPENBSD_5_8_BASE:1.59
	OPENBSD_5_7:1.57.0.2
	OPENBSD_5_7_BASE:1.57
	OPENBSD_5_6:1.56.0.4
	OPENBSD_5_6_BASE:1.56
	OPENBSD_5_5:1.52.0.4
	OPENBSD_5_5_BASE:1.52
	OPENBSD_5_4:1.51.0.2
	OPENBSD_5_4_BASE:1.51
	OPENBSD_5_3:1.47.0.4
	OPENBSD_5_3_BASE:1.47
	OPENBSD_5_2:1.47.0.2
	OPENBSD_5_2_BASE:1.47
	OPENBSD_5_1_BASE:1.46
	OPENBSD_5_1:1.46.0.4
	OPENBSD_5_0:1.46.0.2
	OPENBSD_5_0_BASE:1.46
	OPENBSD_4_9:1.41.0.4
	OPENBSD_4_9_BASE:1.41
	OPENBSD_4_8:1.41.0.2
	OPENBSD_4_8_BASE:1.41
	OPENBSD_4_7:1.37.0.2
	OPENBSD_4_7_BASE:1.37
	OPENBSD_4_6:1.37.0.4
	OPENBSD_4_6_BASE:1.37
	OPENBSD_4_5:1.25.0.2
	OPENBSD_4_5_BASE:1.25
	OPENBSD_4_4:1.24.0.2
	OPENBSD_4_4_BASE:1.24
	OPENBSD_4_3:1.22.0.2
	OPENBSD_4_3_BASE:1.22
	OPENBSD_4_2:1.21.0.2
	OPENBSD_4_2_BASE:1.21
	OPENBSD_4_1:1.20.0.4
	OPENBSD_4_1_BASE:1.20
	OPENBSD_4_0:1.20.0.2
	OPENBSD_4_0_BASE:1.20
	OPENBSD_3_9:1.18.0.2
	OPENBSD_3_9_BASE:1.18
	OPENBSD_3_8:1.17.0.10
	OPENBSD_3_8_BASE:1.17
	OPENBSD_3_7:1.17.0.8
	OPENBSD_3_7_BASE:1.17
	OPENBSD_3_6:1.17.0.6
	OPENBSD_3_6_BASE:1.17
	SMP_SYNC_A:1.17
	SMP_SYNC_B:1.17
	OPENBSD_3_5:1.17.0.4
	OPENBSD_3_5_BASE:1.17
	OPENBSD_3_4:1.17.0.2
	OPENBSD_3_4_BASE:1.17
	UBC_SYNC_A:1.17
	OPENBSD_3_3:1.16.0.6
	OPENBSD_3_3_BASE:1.16
	OPENBSD_3_2:1.16.0.4
	OPENBSD_3_2_BASE:1.16
	OPENBSD_3_1:1.16.0.2
	OPENBSD_3_1_BASE:1.16
	UBC_SYNC_B:1.16
	UBC:1.15.0.2
	UBC_BASE:1.15
	OPENBSD_3_0:1.12.0.2
	OPENBSD_3_0_BASE:1.12
	OPENBSD_2_9_BASE:1.9
	OPENBSD_2_9:1.9.0.2
	OPENBSD_2_8:1.5.0.2
	OPENBSD_2_8_BASE:1.5
	OPENBSD_2_7:1.4.0.2
	OPENBSD_2_7_BASE:1.4
	SMP:1.3.0.4
	SMP_BASE:1.3
	kame_19991208:1.3
	OPENBSD_2_6:1.3.0.2
	OPENBSD_2_6_BASE:1.3
	OPENBSD_2_5:1.2.0.2
	OPENBSD_2_5_BASE:1.2;
locks; strict;
comment	@ * @;


1.61
date	2016.08.11.01.17.33;	author dlg;	state Exp;
branches;
next	1.60;
commitid	3Fyaahd7uscMQePg;

1.60
date	2015.10.08.15.58.38;	author kettenis;	state Exp;
branches;
next	1.59;
commitid	wmnQpRj0rGJ31TDS;

1.59
date	2015.05.04.10.21.15;	author dlg;	state Exp;
branches;
next	1.58;
commitid	dd7E1ky1UwQRrLhI;

1.58
date	2015.04.23.09.56.23;	author dlg;	state Exp;
branches;
next	1.57;
commitid	lsqyb9bvESnxS0Z9;

1.57
date	2014.10.03.17.41.00;	author kettenis;	state Exp;
branches;
next	1.56;
commitid	h8HwsnqXqpePzqXu;

1.56
date	2014.07.11.16.35.40;	author jsg;	state Exp;
branches;
next	1.55;
commitid	7NtJNW9udCOFtDNM;

1.55
date	2014.07.08.17.19.26;	author deraadt;	state Exp;
branches;
next	1.54;
commitid	EF98ch02VpFassUi;

1.54
date	2014.07.08.14.22.43;	author deraadt;	state Exp;
branches;
next	1.53;
commitid	PyhPLhZjcZiJOjlr;

1.53
date	2014.03.28.17.57.11;	author mpi;	state Exp;
branches;
next	1.52;

1.52
date	2013.11.09.06.52.15;	author guenther;	state Exp;
branches;
next	1.51;

1.51
date	2013.05.30.16.39.26;	author tedu;	state Exp;
branches;
next	1.50;

1.50
date	2013.05.30.16.29.46;	author tedu;	state Exp;
branches;
next	1.49;

1.49
date	2013.05.30.15.17.59;	author tedu;	state Exp;
branches;
next	1.48;

1.48
date	2013.05.29.22.23.01;	author tedu;	state Exp;
branches;
next	1.47;

1.47
date	2012.03.09.13.01.29;	author ariane;	state Exp;
branches;
next	1.46;

1.46
date	2011.07.06.19.50.38;	author beck;	state Exp;
branches;
next	1.45;

1.45
date	2011.07.03.18.36.49;	author oga;	state Exp;
branches;
next	1.44;

1.44
date	2011.07.03.18.34.14;	author oga;	state Exp;
branches;
next	1.43;

1.43
date	2011.05.30.22.25.24;	author oga;	state Exp;
branches;
next	1.42;

1.42
date	2011.04.15.21.30.02;	author oga;	state Exp;
branches;
next	1.41;

1.41
date	2010.06.29.20.39.27;	author thib;	state Exp;
branches;
next	1.40;

1.40
date	2010.06.27.03.03.49;	author thib;	state Exp;
branches;
next	1.39;

1.39
date	2010.06.09.08.26.21;	author thib;	state Exp;
branches;
next	1.38;

1.38
date	2010.04.22.19.02.55;	author oga;	state Exp;
branches;
next	1.37;

1.37
date	2009.06.16.23.54.57;	author oga;	state Exp;
branches;
next	1.36;

1.36
date	2009.06.16.16.42.41;	author ariane;	state Exp;
branches;
next	1.35;

1.35
date	2009.06.16.00.11.29;	author oga;	state Exp;
branches;
next	1.34;

1.34
date	2009.06.02.23.00.19;	author oga;	state Exp;
branches;
next	1.33;

1.33
date	2009.06.01.17.42.33;	author ariane;	state Exp;
branches;
next	1.32;

1.32
date	2009.05.04.18.08.06;	author oga;	state Exp;
branches;
next	1.31;

1.31
date	2009.04.28.16.06.07;	author miod;	state Exp;
branches;
next	1.30;

1.30
date	2009.04.14.20.12.05;	author oga;	state Exp;
branches;
next	1.29;

1.29
date	2009.04.13.22.17.54;	author oga;	state Exp;
branches;
next	1.28;

1.28
date	2009.04.06.12.02.52;	author oga;	state Exp;
branches;
next	1.27;

1.27
date	2009.03.26.13.38.45;	author oga;	state Exp;
branches;
next	1.26;

1.26
date	2009.03.25.20.00.17;	author oga;	state Exp;
branches;
next	1.25;

1.25
date	2009.01.27.22.14.13;	author miod;	state Exp;
branches;
next	1.24;

1.24
date	2008.06.09.20.30.23;	author miod;	state Exp;
branches;
next	1.23;

1.23
date	2008.05.05.15.37.41;	author thib;	state Exp;
branches;
next	1.22;

1.22
date	2007.11.29.00.26.41;	author tedu;	state Exp;
branches;
next	1.21;

1.21
date	2007.06.18.21.51.15;	author pedro;	state Exp;
branches;
next	1.20;

1.20
date	2006.07.13.22.51.26;	author deraadt;	state Exp;
branches;
next	1.19;

1.19
date	2006.06.21.16.20.05;	author mickey;	state Exp;
branches;
next	1.18;

1.18
date	2006.01.16.13.11.05;	author mickey;	state Exp;
branches;
next	1.17;

1.17
date	2003.03.29.01.13.57;	author mickey;	state Exp;
branches;
next	1.16;

1.16
date	2001.12.19.08.58.07;	author art;	state Exp;
branches;
next	1.15;

1.15
date	2001.11.28.19.28.14;	author art;	state Exp;
branches
	1.15.2.1;
next	1.14;

1.14
date	2001.11.10.18.42.31;	author art;	state Exp;
branches;
next	1.13;

1.13
date	2001.11.05.22.14.54;	author art;	state Exp;
branches;
next	1.12;

1.12
date	2001.08.11.10.57.22;	author art;	state Exp;
branches;
next	1.11;

1.11
date	2001.07.18.15.19.12;	author art;	state Exp;
branches;
next	1.10;

1.10
date	2001.06.23.19.24.33;	author smart;	state Exp;
branches;
next	1.9;

1.9
date	2001.04.10.06.59.12;	author niklas;	state Exp;
branches;
next	1.8;

1.8
date	2001.03.22.03.05.54;	author smart;	state Exp;
branches;
next	1.7;

1.7
date	2001.03.09.05.34.38;	author smart;	state Exp;
branches;
next	1.6;

1.6
date	2001.01.29.02.07.41;	author niklas;	state Exp;
branches;
next	1.5;

1.5
date	2000.05.27.21.06.08;	author provos;	state Exp;
branches;
next	1.4;

1.4
date	2000.03.15.15.50.18;	author art;	state Exp;
branches;
next	1.3;

1.3
date	99.08.23.08.13.22;	author art;	state Exp;
branches
	1.3.4.1;
next	1.2;

1.2
date	99.02.26.05.32.05;	author art;	state Exp;
branches;
next	1.1;

1.1
date	99.02.26.01.30.10;	author art;	state Exp;
branches;
next	;

1.3.4.1
date	2000.03.24.09.09.47;	author niklas;	state Exp;
branches;
next	1.3.4.2;

1.3.4.2
date	2001.05.14.22.47.44;	author niklas;	state Exp;
branches;
next	1.3.4.3;

1.3.4.3
date	2001.07.04.11.00.59;	author niklas;	state Exp;
branches;
next	1.3.4.4;

1.3.4.4
date	2001.10.31.03.32.14;	author nate;	state Exp;
branches;
next	1.3.4.5;

1.3.4.5
date	2001.11.13.23.02.31;	author niklas;	state Exp;
branches;
next	1.3.4.6;

1.3.4.6
date	2001.12.05.01.19.55;	author niklas;	state Exp;
branches;
next	1.3.4.7;

1.3.4.7
date	2002.03.06.02.17.14;	author niklas;	state Exp;
branches;
next	1.3.4.8;

1.3.4.8
date	2003.05.13.19.36.57;	author ho;	state Exp;
branches;
next	;

1.15.2.1
date	2002.02.02.03.28.26;	author art;	state Exp;
branches;
next	1.15.2.2;

1.15.2.2
date	2002.11.04.18.02.32;	author art;	state Exp;
branches;
next	;


desc
@@


1.61
log
@replace abuse of the static map entries RB_ENTRY pointers with an SLIST

free static entries are kept in a simple linked list, so use SLIST
to make this obvious. the RB_PARENT manipulations are ugly and
confusing.

ok kettenis@@
@
text
@/*	$OpenBSD: uvm.h,v 1.60 2015/10/08 15:58:38 kettenis Exp $	*/
/*	$NetBSD: uvm.h,v 1.24 2000/11/27 08:40:02 chs Exp $	*/

/*
 * Copyright (c) 1997 Charles D. Cranor and Washington University.
 * All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 *
 * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR
 * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
 * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
 * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,
 * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
 * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
 * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
 * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF
 * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 *
 * from: Id: uvm.h,v 1.1.2.14 1998/02/02 20:07:19 chuck Exp
 */

#ifndef _UVM_UVM_H_
#define _UVM_UVM_H_

#include <uvm/uvm_extern.h>
#include <uvm/uvm_amap.h>
#include <uvm/uvm_aobj.h>
#include <uvm/uvm_fault.h>
#include <uvm/uvm_glue.h>
#include <uvm/uvm_km.h>
#include <uvm/uvm_swap.h>

#include <uvm/uvm_pmemrange.h>

/*
 * uvm structure (vm global state: collected in one structure for ease
 * of reference...)
 */

struct uvm {
	/* vm_page related parameters */

	/* vm_page queues */
	struct pglist page_active;	/* allocated pages, in use */
	struct pglist page_inactive_swp;/* pages inactive (reclaim or free) */
	struct pglist page_inactive_obj;/* pages inactive (reclaim or free) */
	/* Lock order: pageqlock, then fpageqlock. */
	struct mutex pageqlock;		/* lock for active/inactive page q */
	struct mutex fpageqlock;	/* lock for free page q  + pdaemon */
	boolean_t page_init_done;	/* TRUE if uvm_page_init() finished */
	struct uvm_pmr_control pmr_control; /* pmemrange data */

		/* page daemon trigger */
	int pagedaemon;			/* daemon sleeps on this */
	struct proc *pagedaemon_proc;	/* daemon's pid */

		/* aiodone daemon trigger */
	int aiodoned;			/* daemon sleeps on this */
	struct proc *aiodoned_proc;	/* daemon's pid */
	struct mutex aiodoned_lock;

	/* static kernel map entry pool */
	SLIST_HEAD(, vm_map_entry) kentry_free; /* free page pool */

	/* aio_done is locked by uvm.aiodoned_lock. */
	TAILQ_HEAD(, buf) aio_done;		/* done async i/o reqs */

	/* kernel object: to support anonymous pageable kernel memory */
	struct uvm_object *kernel_object;
};

/*
 * vm_map_entry etype bits:
 */

#define UVM_ET_OBJ		0x01	/* it is a uvm_object */
#define UVM_ET_SUBMAP		0x02	/* it is a vm_map submap */
#define UVM_ET_COPYONWRITE 	0x04	/* copy_on_write */
#define UVM_ET_NEEDSCOPY	0x08	/* needs_copy */
#define UVM_ET_HOLE		0x10	/* no backend */
#define UVM_ET_NOFAULT		0x20	/* don't fault */
#define UVM_ET_FREEMAPPED	0x80	/* map entry is on free list (DEBUG) */

#define UVM_ET_ISOBJ(E)		(((E)->etype & UVM_ET_OBJ) != 0)
#define UVM_ET_ISSUBMAP(E)	(((E)->etype & UVM_ET_SUBMAP) != 0)
#define UVM_ET_ISCOPYONWRITE(E)	(((E)->etype & UVM_ET_COPYONWRITE) != 0)
#define UVM_ET_ISNEEDSCOPY(E)	(((E)->etype & UVM_ET_NEEDSCOPY) != 0)
#define UVM_ET_ISHOLE(E)	(((E)->etype & UVM_ET_HOLE) != 0)
#define UVM_ET_ISNOFAULT(E)	(((E)->etype & UVM_ET_NOFAULT) != 0)

#ifdef _KERNEL

/*
 * holds all the internal UVM data
 */
extern struct uvm uvm;

/*
 * UVM_WAIT: wait... wrapper around the tsleep() function.
 */

#define	UVM_WAIT(event, intr, msg, timo)				\
do {									\
	tsleep(event, PVM|(intr ? PCATCH : 0), msg, timo);		\
} while (0)

/*
 * UVM_PAGE_OWN: track page ownership (only if UVM_PAGE_TRKOWN)
 */

#if defined(UVM_PAGE_TRKOWN)
#define UVM_PAGE_OWN(PG, TAG) uvm_page_own(PG, TAG)
#else
#define UVM_PAGE_OWN(PG, TAG) /* nothing */
#endif /* UVM_PAGE_TRKOWN */

/*
 * uvm_map internal functions.
 * Used by uvm_map address selectors.
 */
struct vm_map_entry	*uvm_map_entrybyaddr(struct uvm_map_addr *, vaddr_t);
int			 uvm_map_isavail(struct vm_map *,
			    struct uvm_addr_state *,
			    struct vm_map_entry **, struct vm_map_entry**,
			    vaddr_t, vsize_t);
struct uvm_addr_state	*uvm_map_uaddr(struct vm_map *, vaddr_t);
struct uvm_addr_state	*uvm_map_uaddr_e(struct vm_map *, struct vm_map_entry *);

#define VMMAP_FREE_START(_entry)	((_entry)->end + (_entry)->guard)
#define VMMAP_FREE_END(_entry)		((_entry)->end + (_entry)->guard + \
					    (_entry)->fspace)

#endif /* _KERNEL */

#endif /* _UVM_UVM_H_ */
@


1.60
log
@Lock the page queues by turning uvm_lock_pageq() and uvm_unlock_pageq() into
mtx_enter() and mtx_leave() operations.  Not 100% this won't blow up but
there is only one way to find out, and we need this to make progress on
further unlocking uvm.

prodded by deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm.h,v 1.59 2015/05/04 10:21:15 dlg Exp $	*/
d72 1
a72 1
	vm_map_entry_t kentry_free;	/* free page pool */
@


1.59
log
@reduce the scope of things that include uvm_swap_encrypt.h.

uvm_meter.c needs it to route the sysctl, uvm_swap.c needs it to
use the functionality, and uvm_swap_encrypt.c needs it to for obvious
reasons. userland sysctl already includes it explicitely.

everything else doesnt and shouldnt care.

ok miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm.h,v 1.58 2015/04/23 09:56:23 dlg Exp $	*/
d57 1
@


1.58
log
@tedu remnants of the previous attempt to implement page zeroing in
the idle thread.

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm.h,v 1.57 2014/10/03 17:41:00 kettenis Exp $	*/
a40 3
#ifdef UVM_SWAP_ENCRYPT
#include <uvm/uvm_swap_encrypt.h>
#endif
@


1.57
log
@Introduce __MAP_NOFAULT, a mmap(2) flag that makes sure a mapping will not
cause a SIGSEGV or SIGBUS when a mapped file gets truncated.  Access to
pages that are not backed by a file on such a mapping will be replaced by
zero-filled anonymous pages.  Makes passing file descriptors of mapped files
usable without having to play tricks with signal handlers.

"steal your mmap flag" deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm.h,v 1.56 2014/07/11 16:35:40 jsg Exp $	*/
a61 2
	boolean_t page_idle_zero;	/* TRUE if we should try to zero
					   pages in the idle loop */
@


1.56
log
@Chuck Cranor rescinded clauses in his license
on the 2nd of February 2011 in NetBSD.

http://marc.info/?l=netbsd-source-changes&m=129658899212732&w=2
http://marc.info/?l=netbsd-source-changes&m=129659095515558&w=2
http://marc.info/?l=netbsd-source-changes&m=129659157916514&w=2
http://marc.info/?l=netbsd-source-changes&m=129665962324372&w=2
http://marc.info/?l=netbsd-source-changes&m=129666033625342&w=2
http://marc.info/?l=netbsd-source-changes&m=129666052825545&w=2
http://marc.info/?l=netbsd-source-changes&m=129666922906480&w=2
http://marc.info/?l=netbsd-source-changes&m=129667725518082&w=2
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm.h,v 1.55 2014/07/08 17:19:26 deraadt Exp $	*/
d93 2
a94 1
#define	UVM_ET_HOLE		0x10	/* no backend */
d102 1
@


1.55
log
@decouple struct uvmexp into a new file, so that uvm_extern.h and sysctl.h
don't need to be married.
ok guenther miod beck jsing kettenis
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm.h,v 1.54 2014/07/08 14:22:43 deraadt Exp $	*/
a4 1
 *
a15 6
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *      This product includes software developed by Charles D. Cranor and
 *      Washington University.
 * 4. The name of the author may not be used to endorse or promote products
 *    derived from this software without specific prior written permission.
@


1.54
log
@white space repairs
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm.h,v 1.53 2014/03/28 17:57:11 mpi Exp $	*/
a47 1
#include <uvm/uvm_pmemrange.h>
d51 2
@


1.53
log
@Reduce uvm include madness.  Use <uvm/uvm_extern.h> instead of
<uvm/uvm.h> if possible and remove double inclusions.

ok beck@@, mlarkin@@, deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm.h,v 1.52 2013/11/09 06:52:15 guenther Exp $	*/
d138 4
a141 5

struct vm_map_entry	*uvm_map_entrybyaddr(struct uvm_map_addr*, vaddr_t);
int			 uvm_map_isavail(struct vm_map*,
			    struct uvm_addr_state*,
			    struct vm_map_entry**, struct vm_map_entry**,
d143 2
a144 2
struct uvm_addr_state	*uvm_map_uaddr(struct vm_map*, vaddr_t);
struct uvm_addr_state	*uvm_map_uaddr_e(struct vm_map*, struct vm_map_entry*);
@


1.52
log
@Add KASSERT()s to tsleep() and msleep() to verify that bogus flags
aren't being passed to them.  Fix UVM_WAIT() to not pass PNORELOCK to
tsleep(), as that flag only does something with msleep().

ok beck@@ dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm.h,v 1.51 2013/05/30 16:39:26 tedu Exp $	*/
a41 5

/*
 * pull in prototypes
 */

a46 4
#include <uvm/uvm_map.h>
#include <uvm/uvm_object.h>
#include <uvm/uvm_page.h>
#include <uvm/uvm_pager.h>
a51 8

#include <machine/vmparam.h>

/* Constraint ranges, set by MD code. */
extern struct uvm_constraint_range  isa_constraint;
extern struct uvm_constraint_range  dma_constraint;
extern struct uvm_constraint_range  no_constraint;
extern struct uvm_constraint_range *uvm_md_constraints[];
@


1.51
log
@UVM_UNLOCK_AND_WAIT no longer unlocks, so rename it to UVM_WAIT.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm.h,v 1.50 2013/05/30 16:29:46 tedu Exp $	*/
d136 1
a136 1
#define	UVM_WAIT(event, intr, msg, timo)		\
d138 1
a138 1
	tsleep(event, PVM|PNORELOCK|(intr ? PCATCH : 0), msg, timo);	\
@


1.50
log
@remove lots of comments about locking per beck's request
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm.h,v 1.49 2013/05/30 15:17:59 tedu Exp $	*/
d133 1
a133 2
 * UVM_UNLOCK_AND_WAIT: atomic unlock+wait... wrapper around the
 * interlocked tsleep() function.
d136 1
a136 1
#define	UVM_UNLOCK_AND_WAIT(event, slock, intr, msg, timo)		\
@


1.49
log
@remove simple_locks from uvm code. ok beck deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm.h,v 1.48 2013/05/29 22:23:01 tedu Exp $	*/
d82 1
a82 1
	/* Lock order: object lock,  pageqlock, then fpageqlock. */
@


1.48
log
@uvm_loan has not (ever) been compiled or used.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm.h,v 1.47 2012/03/09 13:01:29 ariane Exp $	*/
a82 1
	simple_lock_data_t pageqlock;	/* lock for active/inactive page q */
a99 1
	simple_lock_data_t kentry_lock;
a102 3

	/* swap-related items */
	simple_lock_data_t swap_data_lock;
@


1.47
log
@New vmmap implementation.

no oks (it is really a pain to review properly)
extensively tested, I'm confident it'll be stable
'now is the time' from several icb inhabitants

Diff provides:
- ability to specify different allocators for different regions/maps
- a simpler implementation of the current allocator
- currently in compatibility mode: it will generate similar addresses
  as the old allocator
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm.h,v 1.46 2011/07/06 19:50:38 beck Exp $	*/
a51 1
#include <uvm/uvm_loan.h>
@


1.46
log
@
uvm changes for buffer cache improvements.
1) Make the pagedaemon aware of the memory ranges and size of allocations
where memory is being requested, and pass this information on to
bufbackoff(), which will later (not yet) be used to ensure that the
buffer cache gets out of the way in the right area of memory.

Note that this commit does not yet make it *do* that - as currently
the buffer cache is all in dma-able memory and it will simply back
off.

2) Add uvm_pagerealloc_multi - to be used by the buffer cache code
for reallocating pages to particular regions.

much of this work by ariane, with smatterings of me, art,and oga

ok oga@@, thib@@, ariane@@, deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm.h,v 1.45 2011/07/03 18:36:49 oga Exp $	*/
d123 1
d157 17
@


1.45
log
@endodoify UVM_CNT too.

``beat it'' tedu@@ the deleteotron
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm.h,v 1.44 2011/07/03 18:34:14 oga Exp $	*/
a63 18

/*
 * uvm_constraint_range's:
 * MD code is allowed to setup constraint ranges for memory allocators, the
 * primary use for this is to keep allocation for certain memory consumers
 * such as mbuf pools withing address ranges that are reachable by devices
 * that perform DMA.
 *
 * It is also to discourge memory allocations from being satisfied from ranges
 * such as the ISA memory range, if they can be satisfied with allocation
 * from other ranges.
 *
 * the MD ranges are defined in arch/ARCH/ARCH/machdep.c
 */
struct uvm_constraint_range {
	paddr_t	ucr_low;
	paddr_t ucr_high;
};
@


1.44
log
@Rip out and burn support for UVM_HIST.

The vm hackers don't use it, don't maintain it and have to look at it all the
time. About time this 800 lines of code hit /dev/null.

``never liked it'' tedu@@. ariane@@ was very happy when i told her i wrote
this diff.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm.h,v 1.43 2011/05/30 22:25:24 oga Exp $	*/
a41 2

#include <uvm/uvm_stat.h>
@


1.43
log
@Remove the freelist member from vm_physseg

The new world order of pmemrange makes this data completely redundant
(being dealt with by the pmemrange constraints instead). Remove all code
that messes with the freelist.

While touching every caller of uvm_page_physload() anyway, add the flags
argument to all callers (all but one is 0 and that one already used
PHYSLOAD_DEVICE) and remove the macro magic to allow callers to continue
without it.

Should shrink the code a bit, as well.

matthew@@ pointed out some mistakes i'd made.
``freelist death, I like. Ok.' ariane@@
`I agree with the general direction, go ahead and i'll fix any fallout
shortly'' miod@@ (68k 88k and vax i could not check would build)
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm.h,v 1.42 2011/04/15 21:30:02 oga Exp $	*/
a155 9

/*
 * historys
 */
#ifdef UVMHIST
extern UVMHIST_DECL(maphist);
extern UVMHIST_DECL(pdhist);
extern UVMHIST_DECL(pghist);
#endif
@


1.42
log
@When I switched uvm objects to use a per-object page tree instead of the
global hash I forgot to remove the has declarations from struct uvm. So
remove them now.

pointed out by blambert@@, ok beck@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm.h,v 1.41 2010/06/29 20:39:27 thib Exp $	*/
a64 3
/*
 * pull in VM_NFREELIST
 */
@


1.41
log
@Add a no_constraint uvm_constraint_range; use it in the pool code.

ok tedu@@, beck@@, oga@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm.h,v 1.40 2010/06/27 03:03:49 thib Exp $	*/
a121 6

		/* page hash */
	struct pglist *page_hash;	/* page hash table (vp/off->page) */
	int page_nhash;			/* number of buckets */
	int page_hashmask;		/* hash mask */
	struct mutex hashlock;		/* lock on page_hash array */
@


1.40
log
@uvm constraints. Add two mandatory MD symbols, uvm_md_constraints
which contains the constraints for DMA/memory allocation for each
architecture, and dma_constraints which contains the range of addresses
that are dma accessable by the system.

This is based on ariane@@'s physcontig diff, with lots of bugfixes and
additions the following additions by my self:

Introduce a new function pool_set_constraints() which sets the address
range for which we allocate pages for the pool from, this is now used
for the mbuf/mbuf cluster pools to keep them dma accessible.

The !direct archs no longer stuff pages into the kernel object in
uvm_km_getpage_pla but rather do a pmap_extract() in uvm_km_putpages.

Tested heavily by my self on i386, amd64 and sparc64. Some tests on
alpha and SGI.

"commit it" beck, art, oga, deraadt
"i like the diff" deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm.h,v 1.38 2010/04/22 19:02:55 oga Exp $	*/
d91 1
@


1.39
log
@Move the prototype for uvm_wait() to uvm_extern.h and remove
uvm_pdaemon.h has it was only holding that one prototype.

OK art@@, oga@@, miod@@, deraadt@@
@
text
@d71 5
a75 4
 * UVM_IO_RANGES: paddr_t pairs, describing the lowest and highest address
 * that should be reserved. These ranges (which may overlap) will have their
 * use counter increased, causing them to be avoided if an allocation can be
 * satisfied from another range of memory.
d77 3
a79 3
 * UVM_IO_RANGES actually results into a call to uvm_pmr_use_inc() per range
 * at uvm initialization. uvm_pmr_use_inc() can also be called after uvm_init()
 * has completed.
d81 1
a81 3
 * Note: the upper bound is specified in the same way as to uvm_pglistalloc.
 * Ex: a memory range of 16 bit is specified as: { 0, 0xffff }.
 * Default: no special ranges in use.
d83 4
a86 7
#ifndef UVM_IO_RANGES
#define UVM_IO_RANGES							\
	{								\
		{ 0, 0x00ffffffUL }, /* ISA memory */			\
		{ 0, 0xffffffffUL }, /* 32-bit PCI memory */		\
	}
#endif
d88 4
a91 5
/* UVM IO ranges are described in an array of struct uvm_io_ranges. */
struct uvm_io_ranges {
	paddr_t low;
	paddr_t high;
};
d101 1
a101 1
		/* vm_page queues */
@


1.38
log
@Committing on behalf or ariane@@.

recommit pmemrange:
        physmem allocator: change the view of free memory from single
        free pages to free ranges.  Classify memory based on region with
        associated use-counter (which is used to construct a priority
        list of where to allocate memory).

	Based on code from tedu@@, help from many.

Useable now that bugs have been found and fixed in most architecture's
pmap.c

ok by everyone who has done a pmap or uvm commit in the last year.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm.h,v 1.37 2009/06/16 23:54:57 oga Exp $	*/
a58 1
#include <uvm/uvm_pdaemon.h>
@


1.37
log
@date based reversion of uvm to the 4th May.

We still have no idea why this stops the crashes. but it does.

a machine forced to 64mb of ram cycled 10GB through swap with this diff
and is still running as I type this. Other tests by ariane@@ and thib@@
also seem to show that it's alright.

ok deraadt@@, thib@@, ariane@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm.h,v 1.31 2009/04/28 16:06:07 miod Exp $	*/
d61 1
d72 28
a107 1
	struct pgfreelist page_free[VM_NFREELIST]; /* unallocated pages */
d117 1
@


1.36
log
@Backout pmemrange (which to most people is more well known as physmem
allocator).

"i can't see any obvious problems" oga
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm.h,v 1.32 2009/05/04 18:08:06 oga Exp $	*/
d90 7
a96 5
	/* page daemon's pid, we sleep on the pointer to this. */
	struct proc *pagedaemon_proc;

	/* aiodone daemon's pid, we sleep on the pointer to this. */
	struct proc *aiodoned_proc;
@


1.35
log
@Backout all changes to uvm after pmemrange (which will be backed out
separately).

a change at or just before the hackathon has either exposed or added a
very very nasty memory corruption bug that is giving us hell right now.
So in the interest of kernel stability these diffs are being backed out
until such a time as that corruption bug has been found and squashed,
then the ones that are proven good may slowly return.

a quick hitlist of the main commits this backs out:

mine:
uvm_objwire
the lock change in uvm_swap.c
using trees for uvm objects instead of the hash
removing the pgo_releasepg callback.

art@@'s:
putting pmap_page_protect(VM_PROT_NONE) in uvm_pagedeactivate() since
all callers called that just prior anyway.

ok beck@@, ariane@@.

prompted by deraadt@@.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm.h,v 1.33 2009/06/01 17:42:33 ariane Exp $	*/
a59 1
#include <uvm/uvm_pmemrange.h>
a70 26
 * UVM_IO_RANGES: paddr_t pairs, describing the lowest and highest address
 * that should be reserved. These ranges (which may overlap) will have their
 * use counter increased, causing them to be avoided if an allocation can be
 * satisfied from another range of memory.
 *
 * IO ranges need not overlap with physmem ranges: the uvm code splits ranges
 * on demand to satisfy requests.
 *
 * UVM_IO_RANGES specified here actually translates into a call to
 * uvm_pmr_use_inc() at uvm initialization time. uvm_pmr_use_inc() can also
 * be called after uvm_init() has completed.
 *
 * Note: the upper bound is specified in the same way as to uvm_pglistalloc.
 * Ex: a memory range of 16 bit is specified as: { 0, 0xffff }.
 */
#ifndef UVM_IO_RANGES
#define UVM_IO_RANGES		{}
#endif

/* UVM IO ranges are described in an array of uvm_io_ranges. */
struct uvm_io_ranges {
	paddr_t low;
	paddr_t high;
};

/*
d79 1
a79 1
	struct uvm_pmr_control pmr_control; /* pmemrange control data */
@


1.34
log
@Instead of the global hash table with the terrible hashfunction and a
global lock, switch the uvm object pages to being kept in a per-object
RB_TREE. Right now this is approximately the same speed, but cleaner.
When biglock usage is reduced this will improve concurrency due to lock
contention..

ok beck@@ art@@. Thanks to jasper for the speed testing.
@
text
@d124 6
@


1.33
log
@physmem allocator: change the view of free memory from single free pages
to free ranges.
Classify memory based on region with associated use-counter (which is used
to construct a priority list of where to allocate memory).

Based on code from tedu@@, help from many.
Ok art@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm.h,v 1.32 2009/05/04 18:08:06 oga Exp $	*/
a122 6

		/* page hash */
	struct pglist *page_hash;	/* page hash table (vp/off->page) */
	int page_nhash;			/* number of buckets */
	int page_hashmask;		/* hash mask */
	struct mutex hashlock;		/* lock on page_hash array */
@


1.32
log
@Instead of keeping two ints in the uvm structure specifically just to
sleep on them (and otherwise ignore them) sleep on the pointer to the
{aiodoned,pagedaemon}_proc members, and nuke the two extra words.

"no objections" art@@, ok beck@@.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm.h,v 1.31 2009/04/28 16:06:07 miod Exp $	*/
d60 1
d72 26
d106 1
a106 1
	struct pgfreelist page_free[VM_NFREELIST]; /* unallocated pages */
@


1.31
log
@Revert pageqlock back from a mutex to a simple_lock, as it needs to be
recursive in some cases (mostly involving swapping). A proper fix is in
the works, but this will unbreak kernels for now.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm.h,v 1.30 2009/04/14 20:12:05 oga Exp $	*/
d90 5
a94 7
		/* page daemon trigger */
	int pagedaemon;			/* daemon sleeps on this */
	struct proc *pagedaemon_proc;	/* daemon's pid */

		/* aiodone daemon trigger */
	int aiodoned;			/* daemon sleeps on this */
	struct proc *aiodoned_proc;	/* daemon's pid */
@


1.30
log
@The use of uvm.pagedaemon_lock is incredibly inconsistent. only a
fraction of the wakeups and sleeps involved here actually grab that
lock. The remainder, on the other hand, always have the fpageq_lock
locked.

So, make this locking correct by switching the other users over to
fpageq_lock, too.

This would probably be better off being a semaphore, but for now at
least it's correct.

"ok, unless you want to implement semaphores" art@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm.h,v 1.29 2009/04/13 22:17:54 oga Exp $	*/
d84 1
a84 1
	struct mutex pageqlock;		/* lock for active/inactive page q */
@


1.29
log
@Convert the page queue lock to a mutex instead of a simplelock.

Fix up the one case of lock recursion (which blatantly ignored the
comment right above it saying that we don't need to lock). The rest of
the lock usage has been checked and appears to be correct.

ok ariane@@.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm.h,v 1.28 2009/04/06 12:02:52 oga Exp $	*/
d84 2
a85 2
	struct mutex pageqlock;	/* lock for active/inactive page q */
	struct mutex fpageqlock;	/* lock for free page q */
a92 1
	simple_lock_data_t pagedaemon_lock;
@


1.28
log
@Instead of doing splbio(); simple_lock(&uvm.aiodoned_lock); just replace
the simple lock with a real lock - a IPL_BIO mutex. While i'm here, make
the sleeping condition one hell of a lot simpler in the aio daemon.

some ideas from and ok art@@.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm.h,v 1.27 2009/03/26 13:38:45 oga Exp $	*/
d83 2
a84 1
	simple_lock_data_t pageqlock;	/* lock for active/inactive page q */
@


1.27
log
@Convert splvm() + simplelock(&uvm.hashlock); around the page hash table
into a IPL_VM blocking mutex, also slightly extend the locked area so
that it actually protects access to the page array (as the comment on
the lock declaration says it should).

ansify a few functions while i'm in the file.

"ok, even though you're sneaking in ansification in a diff. You dirty
you." art@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm.h,v 1.26 2009/03/25 20:00:17 oga Exp $	*/
d97 1
a97 1
	simple_lock_data_t aiodoned_lock;
d109 1
a109 1
	/* aio_done is locked by uvm.pagedaemon_lock and splbio! */
@


1.26
log
@Move all of the pseudo-inline functions in uvm into C files.

By pseudo-inline, I mean that if a certain macro was defined, they would
be inlined. However, no architecture defines that, and none has for a
very very long time. Therefore mainly this just makes the code a damned
sight easier to read. Some k&r -> ansi declarations while I'm in there.

"just commit it" art@@. ok weingart@@.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm.h,v 1.25 2009/01/27 22:14:13 miod Exp $	*/
d103 1
a103 1
	simple_lock_data_t hashlock;	/* lock on page_hash array */
@


1.25
log
@Get rid of the last traces of uvm.pager_[se]va
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm.h,v 1.24 2008/06/09 20:30:23 miod Exp $	*/
a169 10

/*
 * pull in inlines
 */

#include <uvm/uvm_amap_i.h>
#include <uvm/uvm_fault_i.h>
#include <uvm/uvm_map_i.h>
#include <uvm/uvm_page_i.h>
#include <uvm/uvm_pager_i.h>
@


1.24
log
@Define a new flag, UVM_FLAG_HOLE, for uvm_map to create a vm_map_entry of
a new etype, UVM_ET_HOLE, meaning it has no backend.

UVM_ET_HOLE entries (which should be created as UVM_PROT_NONE and with
UVM_FLAG_NOMERGE and UVM_FLAG_HOLE) are skipped in uvm_unmap_remove(), so
that pmap_{k,}remove() is not called on the entry.

This is intended to save time, and behave better, on pmaps with MMU holes
at process exit time.

ok art@@, kettenis@@ provided feedback as well.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm.h,v 1.23 2008/05/05 15:37:41 thib Exp $	*/
a110 4

	/* pager VM area bounds */
	vaddr_t pager_sva;		/* start of pager VA area */
	vaddr_t pager_eva;		/* end of pager VA area */
@


1.23
log
@retire ltsleep(); The only refrence left too it is in an
ifdef netbsd block in drm code, but oga@@ says he'll remove
it soon...

OK art@@, oga@@;
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm.h,v 1.22 2007/11/29 00:26:41 tedu Exp $	*/
d131 1
d137 1
@


1.22
log
@use a working mutex for the freepage list. ok art deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm.h,v 1.21 2007/06/18 21:51:15 pedro Exp $	*/
d160 1
a160 2
	(void) ltsleep(event, PVM | PNORELOCK | (intr ? PCATCH : 0),	\
	    msg, timo, slock);						\
@


1.21
log
@Bring back Mickey's UVM anon change. Testing by thib@@, beck@@ and
ckuethe@@ for a while. Okay beck@@, "it is good timing" deraadt@@.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm.h,v 1.20 2006/07/13 22:51:26 deraadt Exp $	*/
d84 1
a84 1
	simple_lock_data_t fpageqlock;	/* lock for free page q */
@


1.20
log
@Back out the anon change.  Apparently it was tested by a few, but most of
us did not see it or get a chance to test it before it was commited. It
broke cvs, in the ami driver, making it not succeed at seeing it's devices.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm.h,v 1.18 2006/01/16 13:11:05 mickey Exp $	*/
a103 4

	/* anon stuff */
	struct vm_anon *afree;		/* anon free list */
	simple_lock_data_t afreelock; 	/* lock on anon free list */
@


1.19
log
@from netbsd: make anons dynamically allocated from pool.
this results in lesse kva waste due to static preallocation of those
for every phys page and also every swap page.
tested by beck krw miod
@
text
@d105 4
@


1.18
log
@add another uvm histroy for physpage alloc/free and propagate a debugging pgfree check into pglist; no functional change for normal kernels; make histories uncommon
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm.h,v 1.17 2003/03/29 01:13:57 mickey Exp $	*/
a103 4

	/* anon stuff */
	struct vm_anon *afree;		/* anon free list */
	simple_lock_data_t afreelock; 	/* lock on anon free list */
@


1.17
log
@ubchist is not a fully cooked kadaver and though use the other well formed pdhist one until ubc gaets back. art@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm.h,v 1.16 2001/12/19 08:58:07 art Exp $	*/
d151 5
a155 3

UVMHIST_DECL(maphist);
UVMHIST_DECL(pdhist);
@


1.16
log
@UBC was a disaster. It worked very good when it worked, but on some
machines or some configurations or in some phase of the moon (we actually
don't know when or why) files disappeared. Since we've not been able to
track down the problem in two weeks intense debugging and we need -current
to be stable, back out everything to a state it had before UBC.

We apologise for the inconvenience.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm.h,v 1.14 2001/11/10 18:42:31 art Exp $	*/
a153 1
UVMHIST_DECL(ubchist);
@


1.15
log
@Sync in more uvm from NetBSD. Mostly just cosmetic stuff.
Contains also support for page coloring.
@
text
@d2 1
a2 1
/*	$NetBSD: uvm.h,v 1.30 2001/06/27 21:18:34 thorpej Exp $	*/
a40 6
#if defined(_KERNEL_OPT)
#include "opt_lockdebug.h"
#include "opt_multiprocessor.h"
#include "opt_uvmhist.h"
#endif

a79 1
	int page_free_nextcolor;	/* next color to allocate from */
d81 4
a84 3
	struct pglist page_inactive;	/* pages between the clock hands */
	struct simplelock pageqlock;	/* lock for active/inactive page q */
	struct simplelock fpageqlock;	/* lock for free page q */
d92 1
a92 1
	struct simplelock pagedaemon_lock;
d97 1
a97 1
	struct simplelock aiodoned_lock;
d103 1
a103 1
	struct simplelock hashlock;	/* lock on page_hash array */
d107 1
a107 1
	struct simplelock afreelock; 	/* lock on anon free list */
d110 2
a111 2
	struct vm_map_entry *kentry_free;	/* free page pool */
	struct simplelock kentry_lock;
d121 1
a121 1
	struct simplelock swap_data_lock;
a165 14

/*
 * UVM_KICK_PDAEMON: perform checks to determine if we need to
 * give the pagedaemon a nudge, and do so if necessary.
 */

#define	UVM_KICK_PDAEMON()						\
do {									\
	if (uvmexp.free + uvmexp.paging < uvmexp.freemin ||		\
	    (uvmexp.free + uvmexp.paging < uvmexp.freetarg &&		\
	     uvmexp.inactive < uvmexp.inactarg)) {			\
		wakeup(&uvm.pagedaemon);				\
	}								\
} while (/*CONSTCOND*/0)
@


1.15.2.1
log
@Merge in UBC performance changes from NetBSD.
Fix a bunch of merge errors from yesterday.
@
text
@d1 2
a2 2
/*	$OpenBSD: uvm.h,v 1.15 2001/11/28 19:28:14 art Exp $	*/
/*	$NetBSD: uvm.h,v 1.31 2001/09/15 20:36:44 chs Exp $	*/
d121 4
@


1.15.2.2
log
@Huge sync to NetBSD plus lots of bugfixes.
 - uvm is as in netbsd-current minus uvm_map forward merge.
 - various locking bugfixes in nfs.
 - make sure that all specops and fifoops are correct in all vnodeop vectors.
 - make the filesystem code more like filsystem code and less like vm code.
@
text
@d1 2
a2 2
/*	$OpenBSD: uvm.h,v 1.15.2.1 2002/02/02 03:28:26 art Exp $	*/
/*	$NetBSD: uvm.h,v 1.34 2002/11/02 16:50:18 perry Exp $	*/
a70 2
#ifdef _KERNEL

a128 2
#endif /* _KERNEL */

a153 1
#ifdef UVMHIST
a156 1
#endif
d167 1
a167 1
} while (/*CONSTCOND*/ 0)
@


1.14
log
@Merge in some parts of the ubc work that has been done in NetBSD that are not
UBC, but prerequsites for it.

- Create a daemon that processes async I/O (swap and paging in the future)
  requests that need processing in process context and that were processed
  in the pagedaemon before.
- Convert some ugly ifdef DIAGNOSTIC code to less intrusive KASSERTs.
- misc other cleanups.
@
text
@d1 2
a2 2
/*	$OpenBSD: uvm.h,v 1.13 2001/11/05 22:14:54 art Exp $	*/
/*	$NetBSD: uvm.h,v 1.24 2000/11/27 08:40:02 chs Exp $	*/
d41 6
d86 1
d88 3
a90 4
	struct pglist page_inactive_swp;/* pages inactive (reclaim or free) */
	struct pglist page_inactive_obj;/* pages inactive (reclaim or free) */
	simple_lock_data_t pageqlock;	/* lock for active/inactive page q */
	simple_lock_data_t fpageqlock;	/* lock for free page q */
d98 1
a98 1
	simple_lock_data_t pagedaemon_lock;
d103 1
a103 1
	simple_lock_data_t aiodoned_lock;
d109 1
a109 1
	simple_lock_data_t hashlock;	/* lock on page_hash array */
d113 1
a113 1
	simple_lock_data_t afreelock; 	/* lock on anon free list */
d116 2
a117 2
	vm_map_entry_t kentry_free;	/* free page pool */
	simple_lock_data_t kentry_lock;
d127 1
a127 1
	simple_lock_data_t swap_data_lock;
d172 14
@


1.13
log
@Minor sync to NetBSD.
@
text
@d1 2
a2 2
/*	$OpenBSD: uvm.h,v 1.12 2001/08/11 10:57:22 art Exp $	*/
/*	$NetBSD: uvm.h,v 1.23 2000/06/26 14:21:16 mrg Exp $	*/
d77 1
d88 1
d93 6
d114 1
a114 1
	struct uvm_aiohead aio_done;	/* done async i/o reqs */
d154 1
@


1.12
log
@Various random fixes from NetBSD.
Including support for zeroing pages in the idle loop (not enabled yet).
@
text
@d1 2
a2 2
/*	$OpenBSD: uvm.h,v 1.11 2001/07/18 15:19:12 art Exp $	*/
/*	$NetBSD: uvm.h,v 1.22 2000/06/08 05:52:34 thorpej Exp $	*/
d133 2
d136 1
a136 1
 * macros
a137 3

#ifdef _KERNEL

@


1.11
log
@Unconfuse UVM_UNLOCK_AND_WAIT. From NetBSD.
@
text
@d1 2
a2 2
/*	$OpenBSD: uvm.h,v 1.10 2001/06/23 19:24:33 smart Exp $	*/
/*	$NetBSD: uvm.h,v 1.18 1999/11/13 00:21:17 thorpej Exp $	*/
d78 1
a78 1
	struct pglist page_free[VM_NFREELIST];	/* unallocated pages */
d85 2
a118 11
extern struct uvm uvm;

/*
 * historys
 */

#ifdef _KERNEL
UVMHIST_DECL(maphist);
UVMHIST_DECL(pdhist);
#endif /* _KERNEL */

d139 9
d149 2
a150 2
 * UVM_UNLOCK_AND_WAIT: atomic unlock+wait... front end for the 
 * uvm_sleep() function.
d153 5
a157 2
#define UVM_UNLOCK_AND_WAIT(event, lock, intr, msg, timo) \
	uvm_sleep(event, lock, intr, msg, timo)
@


1.10
log
@Sync with NetBSD 19990911 (just before PMAP_NEW was required)
  - thread_sleep_msg() -> uvm_sleep()
  - initialize reference count lock in uvm_anon_{init,add}()
  - add uao_flush()
  - replace boolean 'islocked' with 'lockflags'
  - in uvm_fault() change FALSE to TRUE to in 'wide' fault handling
  - get rid of uvm_km_get()
  - various bug fixes
@
text
@d1 2
a2 2
/*	$OpenBSD: uvm.h,v 1.9 2001/04/10 06:59:12 niklas Exp $	*/
/*	$NetBSD: uvm.h,v 1.17 1999/07/22 22:58:38 thorpej Exp $	*/
d153 1
a153 2
#if defined(MULTIPROCESSOR) || defined(LOCKDEBUG)
#define UVM_UNLOCK_AND_WAIT(event, lock, intr ,msg, timo) \
a154 5

#else
#define UVM_UNLOCK_AND_WAIT(event, lock, intr, msg, timo) \
	uvm_sleep(event, NULL, intr, msg, timo)
#endif /* MULTIPROCESSOR || LOCKDEBUG */
@


1.9
log
@Fix for machines which need to enlarge the kernel address space, at least
1GB i386 machines needs this.  The fix is heavily based on Jason Thorpe's
found in NetBSD.  Here is his original commit message:

Instead of checking vm_physmem[<physseg>].pgs to determine if
uvm_page_init() has completed, add a boolean uvm.page_init_done,
and test against that.  Use this same boolean (rather than
pmap_initialized) in pmap_growkernel() to determine if we are
being called via uvm_page_init() to grow the kernel address space.

This fixes a problem on some i386 configurations where pmap_init()
itself was needing to have the kernel page table grown, and since
pmap_initialized was not yet set to TRUE, pmap_growkernel() was
choosing the wrong code path.
@
text
@d1 2
a2 2
/*	$OpenBSD: uvm.h,v 1.8 2001/03/22 03:05:54 smart Exp $	*/
/*	$NetBSD: uvm.h,v 1.16 1999/06/21 17:25:11 thorpej Exp $	*/
d150 1
a150 1
 * (poorly named) thread_sleep_msg function.
d154 3
a156 2
#define UVM_UNLOCK_AND_WAIT(event,lock,intr,msg, timo) \
	thread_sleep_msg(event,lock,intr,msg, timo)
d158 3
a160 3
#define UVM_UNLOCK_AND_WAIT(event,lock,intr,msg, timo) \
	thread_sleep_msg(event,NULL,intr,msg, timo)
#endif
@


1.8
log
@Sync style, typo, and comments a little closer to NetBSD.  art@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm.h,v 1.7 2001/03/09 05:34:38 smart Exp $	*/
d84 1
@


1.7
log
@Protect protypes, certain macros, and inlines from userland.  Checked userland
with a 'make build'.  From NetBSD.  art@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm.h,v 1.6 2001/01/29 02:07:41 niklas Exp $	*/
a152 1

a154 1

a155 1

a157 1

a164 1

d166 1
a166 3

#else /* UVM_PAGE_TRKOWN */

a167 1

@


1.6
log
@$OpenBSD$
@
text
@d1 2
a2 2
/*	$OpenBSD: uvm.h,v 1.15 1999/03/26 17:34:15 chs Exp $	*/
/*	$NetBSD: uvm.h,v 1.15 1999/03/26 17:34:15 chs Exp $	*/
d122 1
d125 1
d145 2
d187 2
@


1.5
log
@use rijndael instead of blowfish because of faster key setup.
break swap paritions into sections, each section has own
encryption key.  if a section's key becomes unreferenced, erase it.
@
text
@d1 1
@


1.4
log
@Fix the NetBSD id strings.
@
text
@d60 3
@


1.3
log
@sync with NetBSD from 1999.05.24 (there is a reason for this date)
 Mostly cleanups, but also a few improvements to pagedaemon for better
 handling of low memory and/or low swap conditions.
@
text
@d1 1
a1 1
/*	$NetBSD: uvm.h,v 1.14 1999/03/25 18:48:49 mrg Exp $	*/
@


1.3.4.1
log
@Sync with -current
@
text
@d1 1
a1 1
/*	$NetBSD: uvm.h,v 1.15 1999/03/26 17:34:15 chs Exp $	*/
@


1.3.4.2
log
@merge in approximately 2.9 into SMP branch
@
text
@d1 1
a1 2
/*	$OpenBSD: uvm.h,v 1.9 2001/04/10 06:59:12 niklas Exp $	*/
/*	$NetBSD: uvm.h,v 1.16 1999/06/21 17:25:11 thorpej Exp $	*/
a59 3
#ifdef UVM_SWAP_ENCRYPT
#include <uvm/uvm_swap_encrypt.h>
#endif
a79 1
	boolean_t page_init_done;	/* TRUE if uvm_page_init() finished */
a117 1
#ifdef _KERNEL
a119 1
#endif /* _KERNEL */
a138 2
#ifdef _KERNEL

d145 1
d148 1
d150 1
d153 1
d161 1
d163 3
a165 1
#else
d167 1
a178 2

#endif /* _KERNEL */
@


1.3.4.3
log
@Merge in -current from two days ago in the SMP branch.
As usual with merges, they do not indicate progress, so do not hold
your breath for working SMP, and do not mail me and ask about the
state of it.  It has not changed.  There is work ongoing, but very, very
slowly.  The commit is done in parts as to not lock up the tree in too
big chunks at a time.
@
text
@d1 2
a2 2
/*	$OpenBSD$	*/
/*	$NetBSD: uvm.h,v 1.17 1999/07/22 22:58:38 thorpej Exp $	*/
d150 1
a150 1
 * uvm_sleep() function.
d154 2
a155 3
#define UVM_UNLOCK_AND_WAIT(event, lock, intr ,msg, timo) \
	uvm_sleep(event, lock, intr, msg, timo)

d157 3
a159 3
#define UVM_UNLOCK_AND_WAIT(event, lock, intr, msg, timo) \
	uvm_sleep(event, NULL, intr, msg, timo)
#endif /* MULTIPROCESSOR || LOCKDEBUG */
@


1.3.4.4
log
@Sync the SMP branch to something just after 3.0
@
text
@d1 2
a2 2
/*	$OpenBSD: uvm.h,v 1.3.4.3 2001/07/04 11:00:59 niklas Exp $	*/
/*	$NetBSD: uvm.h,v 1.22 2000/06/08 05:52:34 thorpej Exp $	*/
d78 1
a78 1
	struct pgfreelist page_free[VM_NFREELIST]; /* unallocated pages */
a84 2
	boolean_t page_idle_zero;	/* TRUE if we should try to zero
					   pages in the idle loop */
d117 11
a147 9
extern struct uvm uvm;

/*
 * historys
 */

UVMHIST_DECL(maphist);
UVMHIST_DECL(pdhist);

d149 2
a150 2
 * UVM_UNLOCK_AND_WAIT: atomic unlock+wait... wrapper around the
 * interlocked tsleep() function.
d153 8
a160 5
#define	UVM_UNLOCK_AND_WAIT(event, slock, intr, msg, timo)		\
do {									\
	(void) ltsleep(event, PVM | PNORELOCK | (intr ? PCATCH : 0),	\
	    msg, timo, slock);						\
} while (0)
@


1.3.4.5
log
@merge in -current
@
text
@d1 2
a2 2
/*	$OpenBSD$	*/
/*	$NetBSD: uvm.h,v 1.24 2000/11/27 08:40:02 chs Exp $	*/
a76 1

a86 1

a90 6

		/* aiodone daemon trigger */
	int aiodoned;			/* daemon sleeps on this */
	struct proc *aiodoned_proc;	/* daemon's pid */
	simple_lock_data_t aiodoned_lock;

d106 1
a106 1
	TAILQ_HEAD(, buf) aio_done;		/* done async i/o reqs */
d133 4
a138 3
/*
 * holds all the internal UVM data
 */
a146 1
UVMHIST_DECL(ubchist);
@


1.3.4.6
log
@Merge in -current
@
text
@d2 1
a2 1
/*	$NetBSD: uvm.h,v 1.30 2001/06/27 21:18:34 thorpej Exp $	*/
a40 6
#if defined(_KERNEL_OPT)
#include "opt_lockdebug.h"
#include "opt_multiprocessor.h"
#include "opt_uvmhist.h"
#endif

a79 1
	int page_free_nextcolor;	/* next color to allocate from */
d81 4
a84 3
	struct pglist page_inactive;	/* pages between the clock hands */
	struct simplelock pageqlock;	/* lock for active/inactive page q */
	struct simplelock fpageqlock;	/* lock for free page q */
d92 1
a92 1
	struct simplelock pagedaemon_lock;
d97 1
a97 1
	struct simplelock aiodoned_lock;
d103 1
a103 1
	struct simplelock hashlock;	/* lock on page_hash array */
d107 1
a107 1
	struct simplelock afreelock; 	/* lock on anon free list */
d110 2
a111 2
	struct vm_map_entry *kentry_free;	/* free page pool */
	struct simplelock kentry_lock;
d121 1
a121 1
	struct simplelock swap_data_lock;
a165 14

/*
 * UVM_KICK_PDAEMON: perform checks to determine if we need to
 * give the pagedaemon a nudge, and do so if necessary.
 */

#define	UVM_KICK_PDAEMON()						\
do {									\
	if (uvmexp.free + uvmexp.paging < uvmexp.freemin ||		\
	    (uvmexp.free + uvmexp.paging < uvmexp.freetarg &&		\
	     uvmexp.inactive < uvmexp.inactarg)) {			\
		wakeup(&uvm.pagedaemon);				\
	}								\
} while (/*CONSTCOND*/0)
@


1.3.4.7
log
@Merge in trunk
@
text
@d2 1
a2 1
/*	$NetBSD: uvm.h,v 1.24 2000/11/27 08:40:02 chs Exp $	*/
d41 6
d86 1
d88 3
a90 4
	struct pglist page_inactive_swp;/* pages inactive (reclaim or free) */
	struct pglist page_inactive_obj;/* pages inactive (reclaim or free) */
	simple_lock_data_t pageqlock;	/* lock for active/inactive page q */
	simple_lock_data_t fpageqlock;	/* lock for free page q */
d98 1
a98 1
	simple_lock_data_t pagedaemon_lock;
d103 1
a103 1
	simple_lock_data_t aiodoned_lock;
d109 1
a109 1
	simple_lock_data_t hashlock;	/* lock on page_hash array */
d113 1
a113 1
	simple_lock_data_t afreelock; 	/* lock on anon free list */
d116 2
a117 2
	vm_map_entry_t kentry_free;	/* free page pool */
	simple_lock_data_t kentry_lock;
d127 1
a127 1
	simple_lock_data_t swap_data_lock;
d172 14
@


1.3.4.8
log
@Sync the SMP branch to -current. This includes moving to ELF.
@
text
@d1 1
a1 1
/*	$OpenBSD: uvm.h,v 1.3.4.7 2002/03/06 02:17:14 niklas Exp $	*/
d154 1
@


1.2
log
@add OpenBSD tags
@
text
@d1 1
a1 7
/*	$OpenBSD$	*/
/*	$NetBSD: uvm.h,v 1.13 1998/10/11 22:59:53 chuck Exp $	*/

/*
 * XXXCDC: "ROUGH DRAFT" QUALITY UVM PRE-RELEASE FILE!   
 *	   >>>USE AT YOUR OWN RISK, WORK IS NOT FINISHED<<<
 */
d89 1
d104 3
@


1.1
log
@Import of uvm from NetBSD. Some local changes, some code disabled
@
text
@d1 1
@

