head	1.27;
access;
symbols
	OPENBSD_6_1_BASE:1.27
	OPENBSD_6_0:1.27.0.2
	OPENBSD_6_0_BASE:1.27
	OPENBSD_5_9:1.26.0.2
	OPENBSD_5_9_BASE:1.26
	OPENBSD_5_8:1.25.0.6
	OPENBSD_5_8_BASE:1.25
	OPENBSD_5_7:1.25.0.2
	OPENBSD_5_7_BASE:1.25
	OPENBSD_5_6:1.23.0.4
	OPENBSD_5_6_BASE:1.23
	OPENBSD_5_5:1.22.0.6
	OPENBSD_5_5_BASE:1.22
	OPENBSD_5_4:1.22.0.2
	OPENBSD_5_4_BASE:1.22
	OPENBSD_5_3:1.21.0.12
	OPENBSD_5_3_BASE:1.21
	OPENBSD_5_2:1.21.0.10
	OPENBSD_5_2_BASE:1.21
	OPENBSD_5_1_BASE:1.21
	OPENBSD_5_1:1.21.0.8
	OPENBSD_5_0:1.21.0.6
	OPENBSD_5_0_BASE:1.21
	OPENBSD_4_9:1.21.0.4
	OPENBSD_4_9_BASE:1.21
	OPENBSD_4_8:1.21.0.2
	OPENBSD_4_8_BASE:1.21
	OPENBSD_4_7:1.19.0.2
	OPENBSD_4_7_BASE:1.19
	OPENBSD_4_6:1.19.0.4
	OPENBSD_4_6_BASE:1.19
	OPENBSD_4_5:1.18.0.8
	OPENBSD_4_5_BASE:1.18
	OPENBSD_4_4:1.18.0.6
	OPENBSD_4_4_BASE:1.18
	OPENBSD_4_3:1.18.0.4
	OPENBSD_4_3_BASE:1.18
	OPENBSD_4_2:1.18.0.2
	OPENBSD_4_2_BASE:1.18
	OPENBSD_4_1:1.16.0.2
	OPENBSD_4_1_BASE:1.16
	OPENBSD_4_0:1.15.0.4
	OPENBSD_4_0_BASE:1.15
	OPENBSD_3_9:1.15.0.2
	OPENBSD_3_9_BASE:1.15
	OPENBSD_3_8:1.14.0.2
	OPENBSD_3_8_BASE:1.14
	OPENBSD_3_7:1.12.0.4
	OPENBSD_3_7_BASE:1.12
	OPENBSD_3_6:1.12.0.2
	OPENBSD_3_6_BASE:1.12
	SMP_SYNC_A:1.11
	SMP_SYNC_B:1.11
	OPENBSD_3_5:1.11.0.4
	OPENBSD_3_5_BASE:1.11
	OPENBSD_3_4:1.11.0.2
	OPENBSD_3_4_BASE:1.11
	UBC_SYNC_A:1.10
	OPENBSD_3_3:1.10.0.6
	OPENBSD_3_3_BASE:1.10
	OPENBSD_3_2:1.10.0.4
	OPENBSD_3_2_BASE:1.10
	OPENBSD_3_1:1.10.0.2
	OPENBSD_3_1_BASE:1.10
	UBC_SYNC_B:1.10
	UBC:1.9.0.2
	UBC_BASE:1.9
	OPENBSD_3_0:1.6.0.2
	OPENBSD_3_0_BASE:1.6
	OPENBSD_2_9_BASE:1.5
	OPENBSD_2_9:1.5.0.12
	OPENBSD_2_8:1.5.0.10
	OPENBSD_2_8_BASE:1.5
	OPENBSD_2_7:1.5.0.8
	OPENBSD_2_7_BASE:1.5
	SMP:1.5.0.6
	SMP_BASE:1.5
	kame_19991208:1.5
	OPENBSD_2_6:1.5.0.4
	OPENBSD_2_6_BASE:1.5
	OPENBSD_2_5:1.5.0.2
	OPENBSD_2_5_BASE:1.5
	OPENBSD_2_4:1.4.0.4
	OPENBSD_2_4_BASE:1.4
	OPENBSD_2_3:1.4.0.2
	OPENBSD_2_3_BASE:1.4;
locks; strict;
comment	@ * @;


1.27
date	2016.06.19.11.54.33;	author natano;	state Exp;
branches;
next	1.26;
commitid	wHLNY5GFNXJSFYaC;

1.26
date	2015.09.23.15.37.26;	author tedu;	state Exp;
branches;
next	1.25;
commitid	xTdRXaXuj71z4icR;

1.25
date	2015.02.11.07.22.15;	author dlg;	state Exp;
branches;
next	1.24;
commitid	9jgJyghs6EilQ1fL;

1.24
date	2015.01.30.17.51.11;	author deraadt;	state Exp;
branches;
next	1.23;
commitid	BGx6Bx6YQ8R2FL4e;

1.23
date	2014.07.09.13.32.00;	author guenther;	state Exp;
branches;
next	1.22;
commitid	ZU9xQk5IchFd0Jm2;

1.22
date	2013.05.01.17.13.05;	author tedu;	state Exp;
branches;
next	1.21;

1.21
date	2010.04.26.05.48.19;	author deraadt;	state Exp;
branches;
next	1.20;

1.20
date	2010.04.23.21.34.40;	author deraadt;	state Exp;
branches;
next	1.19;

1.19
date	2009.03.25.21.20.26;	author oga;	state Exp;
branches;
next	1.18;

1.18
date	2007.04.12.22.20.14;	author thib;	state Exp;
branches;
next	1.17;

1.17
date	2007.04.11.12.06.37;	author miod;	state Exp;
branches;
next	1.16;

1.16
date	2007.02.03.16.48.23;	author miod;	state Exp;
branches;
next	1.15;

1.15
date	2005.11.19.02.18.01;	author pedro;	state Exp;
branches;
next	1.14;

1.14
date	2005.05.29.03.20.42;	author deraadt;	state Exp;
branches;
next	1.13;

1.13
date	2005.05.25.23.17.47;	author niklas;	state Exp;
branches;
next	1.12;

1.12
date	2004.06.13.21.49.28;	author niklas;	state Exp;
branches;
next	1.11;

1.11
date	2003.06.02.23.28.21;	author millert;	state Exp;
branches;
next	1.10;

1.10
date	2002.03.14.01.27.14;	author millert;	state Exp;
branches;
next	1.9;

1.9
date	2001.11.11.00.25.47;	author art;	state Exp;
branches
	1.9.2.1;
next	1.8;

1.8
date	2001.11.07.02.44.10;	author art;	state Exp;
branches;
next	1.7;

1.7
date	2001.10.26.02.28.47;	author art;	state Exp;
branches;
next	1.6;

1.6
date	2001.06.27.04.51.48;	author art;	state Exp;
branches;
next	1.5;

1.5
date	99.02.26.02.28.58;	author art;	state Exp;
branches
	1.5.6.1;
next	1.4;

1.4
date	97.11.07.10.25.42;	author niklas;	state Exp;
branches;
next	1.3;

1.3
date	97.11.06.05.59.08;	author csapuntz;	state Exp;
branches;
next	1.2;

1.2
date	97.10.06.20.21.06;	author deraadt;	state dead;
branches;
next	1.1;

1.1
date	97.10.06.15.25.32;	author csapuntz;	state Exp;
branches;
next	;

1.5.6.1
date	2001.07.04.11.00.21;	author niklas;	state Exp;
branches;
next	1.5.6.2;

1.5.6.2
date	2001.07.14.10.02.47;	author ho;	state Exp;
branches;
next	1.5.6.3;

1.5.6.3
date	2001.07.15.13.34.19;	author ho;	state Exp;
branches;
next	1.5.6.4;

1.5.6.4
date	2001.10.31.03.30.30;	author nate;	state Exp;
branches;
next	1.5.6.5;

1.5.6.5
date	2001.11.13.23.02.30;	author niklas;	state Exp;
branches;
next	1.5.6.6;

1.5.6.6
date	2002.03.28.14.52.01;	author niklas;	state Exp;
branches;
next	1.5.6.7;

1.5.6.7
date	2003.05.15.04.08.03;	author niklas;	state Exp;
branches;
next	1.5.6.8;

1.5.6.8
date	2003.05.15.16.45.54;	author niklas;	state Exp;
branches;
next	1.5.6.9;

1.5.6.9
date	2003.05.18.17.41.16;	author niklas;	state Exp;
branches;
next	1.5.6.10;

1.5.6.10
date	2003.05.18.18.25.03;	author niklas;	state Exp;
branches;
next	1.5.6.11;

1.5.6.11
date	2003.06.07.11.09.07;	author ho;	state Exp;
branches;
next	1.5.6.12;

1.5.6.12
date	2004.02.19.11.01.33;	author niklas;	state Exp;
branches;
next	1.5.6.13;

1.5.6.13
date	2004.02.20.12.43.05;	author niklas;	state Exp;
branches;
next	1.5.6.14;

1.5.6.14
date	2004.03.14.17.40.32;	author niklas;	state Exp;
branches;
next	1.5.6.15;

1.5.6.15
date	2004.03.18.02.05.23;	author niklas;	state Exp;
branches;
next	;

1.9.2.1
date	2002.06.11.03.32.33;	author art;	state Exp;
branches;
next	;


desc
@@


1.27
log
@Remove the lockmgr() API. It is only used by filesystems, where it is a
trivial change to use rrw locks instead. All it needs is LK_* defines
for the RW_* flags.

tested by naddy and sthen on package building infrastructure
input and ok jmc mpi tedu
@
text
@/*	$OpenBSD: lock.h,v 1.26 2015/09/23 15:37:26 tedu Exp $	*/

/* 
 * Copyright (c) 1995
 *	The Regents of the University of California.  All rights reserved.
 *
 * This code contains ideas from software contributed to Berkeley by
 * Avadis Tevanian, Jr., Michael Wayne Young, and the Mach Operating
 * System project at Carnegie-Mellon University.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. Neither the name of the University nor the names of its contributors
 *    may be used to endorse or promote products derived from this software
 *    without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE
 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
 *
 *	@@(#)lock.h	8.12 (Berkeley) 5/19/95
 */

#ifndef	_LOCK_H_
#define	_LOCK_H_

#include <sys/rwlock.h>

#define LK_EXCLUSIVE	RW_WRITE	/* exclusive lock */
#define LK_SHARED	RW_READ		/* shared lock */
#define LK_TYPE_MASK	(RW_WRITE|RW_READ) /* type of lock sought */
#define LK_NOWAIT	RW_NOSLEEP	/* do not sleep to await lock */
#define LK_RECURSEFAIL	RW_RECURSEFAIL	/* fail if recursive exclusive lock */
#define LK_EXCLOTHER	RW_WRITE_OTHER	/* exclusive lock held by some other thread */
#define LK_RWFLAGS	(RW_WRITE|RW_READ|RW_NOSLEEP|RW_RECURSEFAIL|RW_WRITE_OTHER)

/* LK_ specific */
#define LK_DRAIN	0x1000UL	/* wait for all lock activity to end */
#define LK_RETRY	0x2000UL	/* vn_lock: retry until locked */

#endif /* !_LOCK_H_ */
@


1.26
log
@remove lockmgr_printinfo stubs. from Martin Natano
@
text
@d1 1
a1 1
/*	$OpenBSD: lock.h,v 1.25 2015/02/11 07:22:15 dlg Exp $	*/
d43 11
a53 20
struct lock {
	struct rrwlock	lk_lck;
};

#define LK_SHARED	0x01	/* shared lock */
#define LK_EXCLUSIVE	0x02	/* exclusive lock */
#define LK_TYPE_MASK	0x03	/* type of lock sought */
#define LK_DRAIN	0x04	/* wait for all lock activity to end */
#define LK_RELEASE	0x08	/* release any type of lock */
#define LK_NOWAIT	0x10	/* do not sleep to await lock */
#define LK_CANRECURSE	0x20	/* allow recursive exclusive lock */
#define LK_RECURSEFAIL	0x40	/* fail if recursive exclusive lock */
#define LK_RETRY	0x80	/* vn_lock: retry until locked */

/* for lockstatus() only */
#define LK_EXCLOTHER	0x100	/* exclusive lock held by some other thread */

void	lockinit(struct lock *, int, char *, int, int);
int	lockmgr(struct lock *, u_int flags, void *);
int	lockstatus(struct lock *);
@


1.25
log
@things that use sys/lock.h want lockmgr locks. things that use
machine/lock.h are architectures for their MD specific things.

sys/lock.h users dont want the MD bits, so dont have it include
machine/lock.h.

ok miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: lock.h,v 1.24 2015/01/30 17:51:11 deraadt Exp $	*/
a62 2

#define	lockmgr_printinfo(lkp)
@


1.24
log
@simple_lock can finally be removed!
@
text
@d1 1
a1 1
/*	$OpenBSD: lock.h,v 1.23 2014/07/09 13:32:00 guenther Exp $	*/
a39 4

#ifdef _KERNEL
#include <machine/lock.h>
#endif
@


1.23
log
@Teach rw_status() and rrw_status() to return LK_EXCLOTHER if it's write
locked by a different thread.  Teach lockstatus() to return LK_EXCLUSIVE
if an exclusive lock is held by some other thread.

ok beck@@ tedu@@
@
text
@d1 1
a1 1
/*	$OpenBSD: lock.h,v 1.22 2013/05/01 17:13:05 tedu Exp $	*/
a45 14

struct simplelock {
};

typedef struct simplelock       simple_lock_data_t;
typedef struct simplelock       *simple_lock_t;

#ifdef _KERNEL
#define	simple_lock(lkp)
#define	simple_lock_try(lkp)	(1)	/* always succeeds */
#define	simple_unlock(lkp)
#define simple_lock_assert(lkp)
#define simple_lock_init(lkp)
#endif /* _KERNEL */
@


1.22
log
@exorcise lockmgr. the api remains, but is now backed by recursive rwlocks.
originally by thib.
ok deraadt jsing and anyone who tested
@
text
@d1 1
a1 1
/*	$OpenBSD: lock.h,v 1.21 2010/04/26 05:48:19 deraadt Exp $	*/
d74 3
@


1.21
log
@cut down simple locks (so simple that they don't even lock) to the point
where there is almost nothing left to them, so that we can continue getting
rid of them
ok oga
@
text
@d1 1
a1 1
/*	$OpenBSD: lock.h,v 1.20 2010/04/23 21:34:40 deraadt Exp $	*/
d45 2
d58 1
a58 5

static __inline void simple_lock_init(struct simplelock *lkp)
{
}

a60 8
typedef struct lock             lock_data_t;
typedef struct lock             *lock_t;

/*
 * The general lock structure.  Provides for multiple shared locks,
 * upgrading from shared to exclusive, and sleeping until the lock
 * can be gained. The simple locks are defined in <machine/param.h>.
 */
d62 1
a62 19
	u_int	lk_flags;		/* see below */
	int	lk_sharecount;		/* # of accepted shared locks */
	int	lk_waitcount;		/* # of processes sleeping for lock */
	int	lk_exclusivecount;	/* # of recursive exclusive locks */

	/*
	 * This is the sleep message for sleep locks, and a simple name
	 * for spin locks.
	 */
	char	*lk_wmesg;		/* resource sleeping (for tsleep) */

	/* pid of exclusive lock holder */
	pid_t lk_lockholder;

	/* priority at which to sleep */
	int lk_prio;

	/* maximum sleep time (for tsleep) */
	int lk_timo;
d65 9
a73 50
/*
 * Lock request types:
 *   LK_SHARED - get one of many possible shared locks. If a process
 *	holding an exclusive lock requests a shared lock, the exclusive
 *	lock(s) will be downgraded to shared locks.
 *   LK_EXCLUSIVE - stop further shared locks, when they are cleared,
 *	grant a pending upgrade if it exists, then grant an exclusive
 *	lock. Only one exclusive lock may exist at a time, except that
 *	a process holding an exclusive lock may get additional exclusive
 *	locks if it explicitly sets the LK_CANRECURSE flag in the lock
 *	request, or if the LK_CANRECUSE flag was set when the lock was
 *	initialized.
 *   LK_RELEASE - release one instance of a lock.
 *   LK_DRAIN - wait for all activity on the lock to end, then mark it
 *	decommissioned. This feature is used before freeing a lock that
 *	is part of a piece of memory that is about to be freed.
 *
 * These are flags that are passed to the lockmgr routine.
 */
#define LK_TYPE_MASK	0x0000000f	/* type of lock sought */
#define LK_SHARED	0x00000001	/* shared lock */
#define LK_EXCLUSIVE	0x00000002	/* exclusive lock */
#define LK_RELEASE	0x00000006	/* release any type of lock */
#define LK_DRAIN	0x00000007	/* wait for all lock activity to end */
/*
 * External lock flags.
 *
 * The first three flags may be set in lock_init to set their mode permanently,
 * or passed in as arguments to the lock manager.
 */
#define LK_EXTFLG_MASK	0x00200070	/* mask of external flags */
#define LK_NOWAIT	0x00000010	/* do not sleep to await lock */
#define LK_CANRECURSE	0x00000040	/* allow recursive exclusive lock */
#define LK_RECURSEFAIL	0x00200000	/* fail if recursive exclusive lock */
/*
 * Internal lock flags.
 *
 * These flags are used internally to the lock manager.
 */
#define LK_WANT_EXCL	0x00002000	/* exclusive lock sought */
#define LK_HAVE_EXCL	0x00004000	/* exclusive lock obtained */
#define LK_WAITDRAIN	0x00008000	/* process waiting for lock to drain */
#define LK_DRAINING	0x00040000	/* lock is being drained */
#define LK_DRAINED	0x00080000	/* lock has been decommissioned */
/*
 * Control flags
 *
 * Non-persistent external flags.
 */
#define LK_RETRY	0x00020000	/* vn_lock: retry until locked */
d75 2
a76 24
/*
 * Lock return status.
 *
 * Successfully obtained locks return 0. Locks will always succeed
 * unless one of the following is true:
 *	LK_NOWAIT is set and a sleep would be required (returns EBUSY).
 *	PCATCH is set in lock priority and a signal arrives (returns
 *	    either EINTR or ERESTART if system calls is to be restarted).
 *	Non-null lock timeout and timeout expires (returns EWOULDBLOCK).
 * A failed lock attempt always returns a non-zero error value. No lock
 * is held after an error return.
 */

/*
 * Indicator that no process holds exclusive lock
 */
#define LK_KERNPROC ((pid_t) -2)
#define LK_NOPROC ((pid_t) -1)
#define LK_NOCPU ((cpuid_t) -1)

void	lockinit(struct lock *, int prio, char *wmesg, int timo,
			int flags);
int	lockmgr(__volatile struct lock *, u_int flags, void *);
void	lockmgr_printinfo(__volatile struct lock *);
d79 1
a79 4
int	spinlock_release_all(__volatile struct lock *);
void	spinlock_acquire_count(__volatile struct lock *, int);

#define LOCK_ASSERT(x)	/* nothing */
@


1.20
log
@Merge the only relevant (for now) parts of simplelock.h into lock.h
since it is time to start transitioning away from the no-op behaviour.
ok oga kettenis
@
text
@d1 1
a1 1
/*	$OpenBSD: lock.h,v 1.19 2009/03/25 21:20:26 oga Exp $	*/
d43 1
a43 1
#endif /* _KERNEL */
a44 9
/*
 * A simple spin lock.
 *
 * This structure only sets one bit of data, but is sized based on the
 * minimum word size that can be operated on by the hardware test-and-set
 * instruction. It is only needed for multiprocessors, as uniprocessors
 * will always run to completion or a sleep. It is an error to hold one
 * of these locks while a process is sleeping.
 */
a45 5
#ifdef MULTIPROCESSOR
	__cpu_simple_lock_t lock_data;
#else
	int	lock_data;
#endif
d48 3
a51 4

#define SLOCK_LOCKED 1
#define SLOCK_UNLOCKED 0

a58 2

	lkp->lock_data = SLOCK_UNLOCKED;
a62 2
typedef struct simplelock       simple_lock_data_t;
typedef struct simplelock       *simple_lock_t;
a90 7

#if defined(LOCKDEBUG)
	const char *lk_lock_file;
	const char *lk_unlock_file;
	int lk_lock_line;
	int lk_unlock_line;
#endif
a163 2
struct proc;

d166 1
a166 1
int	lockmgr(__volatile struct lock *, u_int flags, struct simplelock *);
a169 9
#if defined(LOCKDEBUG)
int	_spinlock_release_all(__volatile struct lock *, const char *, int);
void	_spinlock_acquire_count(__volatile struct lock *, int, const char *,
	    int);

#define	spinlock_release_all(l)	_spinlock_release_all((l), __FILE__, __LINE__)
#define	spinlock_acquire_count(l, c) _spinlock_acquire_count((l), (c),	\
					__FILE__, __LINE__)
#else
a171 1
#endif
a172 3
#ifdef LOCKDEBUG
#define LOCK_ASSERT(x)	KASSERT(x)
#else
a173 11
#endif

#if !defined(MULTIPROCESSOR)
/*
 * XXX Simplelock macros used at "trusted" places.
 */
#define	SIMPLELOCK		simplelock
#define	SIMPLE_LOCK_INIT	simple_lock_init
#define	SIMPLE_LOCK		simple_lock
#define	SIMPLE_UNLOCK		simple_unlock
#endif
@


1.19
log
@ntfs was the last user, LK_SLEEFAIL can die now.

ok blambert@@
@
text
@d1 1
a1 1
/*	$OpenBSD: lock.h,v 1.18 2007/04/12 22:20:14 thib Exp $	*/
d41 38
a78 1
#include <sys/simplelock.h>
@


1.18
log
@Remove the lk_interlock from struct lock; Also remove the LK_INTERLOCK
flag. This effectively makes the simplelock argument to lockmgr() fluff.

ok miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: lock.h,v 1.17 2007/04/11 12:06:37 miod Exp $	*/
a113 1
#define LK_SLEEPFAIL	0x00000020	/* sleep, then return failure */
a138 1
 *	LK_SLEEPFAIL is set and a sleep was done (returns ENOLCK).
@


1.17
log
@lockmgr keeps losing code, call 911!

ok pedro@@ art@@
@
text
@d1 1
a1 1
/*	$OpenBSD: lock.h,v 1.16 2007/02/03 16:48:23 miod Exp $	*/
a53 1
	struct	simplelock lk_interlock; /* lock on remaining fields */
a131 2
#define LK_INTERLOCK	0x00010000	/* unlock passed simple lock after
					   getting lk_interlock */
@


1.16
log
@Remove unused functionality from lockmgr():
- LK_EXCLUPGRADE is never used.
- LK_REENABLE is never used.
- LK_SETRECURSE is never used. Because of this, the lk_recurselevel
  field is always zero, so it can be removed to.
- the spinlock version (and LK_SPIN) is never used, since it was decided
  to use different locking structure for MP-safe protection.

Tested by many
@
text
@d1 1
a1 1
/*	$OpenBSD: lock.h,v 1.15 2005/11/19 02:18:01 pedro Exp $	*/
a94 8
 *   LK_UPGRADE - the process must hold a shared lock that it wants to
 *	have upgraded to an exclusive lock. Other processes may get
 *	exclusive access to the resource between the time that the upgrade
 *	is requested and the time that it is granted.
 *   LK_DOWNGRADE - the process must hold an exclusive lock that it wants
 *	to have downgraded to a shared lock. If the process holds multiple
 *	(recursive) exclusive locks, they will all be downgraded to shared
 *	locks.
a104 2
#define LK_UPGRADE	0x00000003	/* shared-to-exclusive upgrade */
#define LK_DOWNGRADE	0x00000005	/* exclusive-to-shared downgrade */
d113 1
a113 1
#define LK_EXTFLG_MASK	0x00700070	/* mask of external flags */
a122 1
#define LK_WANT_UPGRADE	0x00001000	/* waiting for share-to-excl upgrade */
a141 2
 *	LK_FORCEUPGRADE is requested and some other process has already
 *	    requested a lock upgrade (returns EBUSY).
d148 1
a148 2
 * is held after an error return (in particular, a failed LK_UPGRADE
 * or LK_FORCEUPGRADE will have released its shared access lock).
@


1.15
log
@Remove unnecessary lockmgr() archaism that was costing too much in terms
of panics and bugfixes. Access curproc directly, do not expect a process
pointer as an argument. Should fix many "process context required" bugs.
Incentive and okay millert@@, okay marc@@. Various testing, thanks.
@
text
@d1 1
a1 1
/*	$OpenBSD: lock.h,v 1.14 2005/05/29 03:20:42 deraadt Exp $	*/
d58 1
a58 2
	short	lk_exclusivecount;	/* # of recursive exclusive locks */
	short	lk_recurselevel;	/* lvl above which recursion ok */
d66 2
a67 19
	union {
		struct {
			/* pid of exclusive lock holder */
			pid_t lk_sleep_lockholder;

			/* priority at which to sleep */
			int lk_sleep_prio;

			/* maximum sleep time (for tsleep) */
			int lk_sleep_timo;
		} lk_un_sleep;
		struct {
			/* CPU ID of exclusive lock holder */
			cpuid_t lk_spin_cpu;
#if defined(LOCKDEBUG)
			TAILQ_ENTRY(lock) lk_spin_list;
#endif
		} lk_un_spin;
	} lk_un;
d69 2
a70 3
#define	lk_lockholder	lk_un.lk_un_sleep.lk_sleep_lockholder
#define	lk_prio		lk_un.lk_un_sleep.lk_sleep_prio
#define	lk_timo		lk_un.lk_un_sleep.lk_sleep_timo
d72 2
a73 4
#define	lk_cpu		lk_un.lk_un_spin.lk_spin_cpu
#if defined(LOCKDEBUG)
#define	lk_list		lk_un.lk_un_spin.lk_spin_list
#endif
a98 6
 *   LK_EXCLUPGRADE - the process must hold a shared lock that it wants to
 *	have upgraded to an exclusive lock. If the request succeeds, no
 *	other processes will have gotten exclusive access to the resource
 *	between the time that the upgrade is requested and the time that
 *	it is granted. However, if another process has already requested
 *	an upgrade, the request will fail (see error returns below).
a113 1
#define LK_EXCLUPGRADE	0x00000004	/* first shared-to-exclusive upgrade */
d121 1
a121 2
 * or passed in as arguments to the lock manager. The LK_REENABLE flag may be
 * set only at the release of a lock obtained by drain.
a126 2
#define LK_REENABLE	0x00000080	/* lock is be reenabled after drain */
#define LK_SETRECURSE	0x00100000	/* other locks while we have it OK */
a127 1
#define LK_SPIN		0x00400000	/* lock spins instead of sleeps */
a179 10
#if (0 && defined(MULTIPROCESSOR)) || defined(LOCKDEBUG)
#define spinlockinit(lkp, name, flags)					\
	lockinit((lkp), 0, (name), 0, (flags) | LK_SPIN)
#define spinlockmgr(lkp, flags, intrlk)					\
	lockmgr((lkp), (flags) | LK_SPIN, (intrlk))
#else
#define spinlockinit(lkp, name, flags)	(void)(lkp)
#define spinlockmgr(lkp, flags, intrlk)	(0)
#endif

d199 1
a199 23
#if defined(MULTIPROCESSOR)
/*
 * XXX Instead of using struct lock for the kernel lock and thus requiring us
 * XXX to implement simplelocks, causing all sorts of fine-grained locks all
 * XXX over our tree getting activated consuming both time and potentially
 * XXX introducing locking protocol bugs.
 */
#ifdef notyet

extern struct lock kernel_lock;

/*
 * XXX Simplelock macros used at "trusted" places.
 */
#define SIMPLELOCK		simplelock
#define SIMPLE_LOCK_INIT	simple_lock_init
#define SIMPLE_LOCK		simple_lock
#define SIMPLE_UNLOCK		simple_unlock

#endif

#else

d203 4
a206 5
#define SIMPLELOCK		simplelock
#define SIMPLE_LOCK_INIT	simple_lock_init
#define SIMPLE_LOCK		simple_lock
#define SIMPLE_UNLOCK		simple_unlock

@


1.14
log
@sched work by niklas and art backed out; causes panics
@
text
@d1 1
a1 1
/*	$OpenBSD: lock.h,v 1.12 2004/06/13 21:49:28 niklas Exp $	*/
d208 1
a208 2
int	lockmgr(__volatile struct lock *, u_int flags,
			struct simplelock *, struct proc *p);
d216 1
a216 1
	lockmgr((lkp), (flags) | LK_SPIN, (intrlk), curproc)
@


1.13
log
@This patch is mortly art's work and was done *a year* ago.  Art wants to thank
everyone for the prompt review and ok of this work ;-)  Yeah, that includes me
too, or maybe especially me.  I am sorry.

Change the sched_lock to a mutex. This fixes, among other things, the infamous
"telnet localhost &" problem.  The real bug in that case was that the sched_lock
which is by design a non-recursive lock, was recursively acquired, and not
enough releases made us hold the lock in the idle loop, blocking scheduling
on the other processors.  Some of the other processors would hold the biglock though,
which made it impossible for cpu 0 to enter the kernel...  A nice deadlock.
Let me just say debugging this for days just to realize that it was all fixed
in an old diff noone ever ok'd was somewhat of an anti-climax.

This diff also changes splsched to be correct for all our architectures.
@
text
@d242 33
@


1.12
log
@debranch SMP, have fun
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
a239 33
#endif

#if defined(MULTIPROCESSOR)
/*
 * XXX Instead of using struct lock for the kernel lock and thus requiring us
 * XXX to implement simplelocks, causing all sorts of fine-grained locks all
 * XXX over our tree getting activated consuming both time and potentially
 * XXX introducing locking protocol bugs.
 */
#ifdef notyet

extern struct lock kernel_lock;

/*
 * XXX Simplelock macros used at "trusted" places.
 */
#define SIMPLELOCK		simplelock
#define SIMPLE_LOCK_INIT	simple_lock_init
#define SIMPLE_LOCK		simple_lock
#define SIMPLE_UNLOCK		simple_unlock

#endif

#else

/*
 * XXX Simplelock macros used at "trusted" places.
 */
#define SIMPLELOCK		simplelock
#define SIMPLE_LOCK_INIT	simple_lock_init
#define SIMPLE_LOCK		simple_lock
#define SIMPLE_UNLOCK		simple_unlock

@


1.11
log
@Remove the advertising clause in the UCB license which Berkeley
rescinded 22 July 1999.  Proofed by myself and Theo.
@
text
@d1 1
a1 1
/*	$OpenBSD: lock.h,v 1.10 2002/03/14 01:27:14 millert Exp $	*/
d59 6
a64 1
	short	lk_prio;		/* priority at which to sleep */
d66 36
a101 2
	int	lk_timo;		/* maximum sleep time (for tsleep) */
	pid_t	lk_lockholder;		/* pid of exclusive lock holder */
d103 1
d152 1
a152 1
#define LK_EXTFLG_MASK	0x00000770	/* mask of external flags */
d157 3
a159 1
#define LK_RECURSEFAIL	0x00000100	/* fail if recursive exclusive lock */
d176 1
a176 1
#define LK_INTERLOCK	0x00100000	/* unlock passed simple lock after
d178 1
a178 1
#define LK_RETRY	0x00200000	/* vn_lock: retry until locked */
d202 1
d210 1
a210 1
void    lockmgr_printinfo(struct lock *);
d213 23
d242 33
a275 1

@


1.10
log
@First round of __P removal in sys
@
text
@d1 1
a1 1
/*	$OpenBSD: lock.h,v 1.9 2001/11/11 00:25:47 art Exp $	*/
d19 1
a19 5
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *	This product includes software developed by the University of
 *	California, Berkeley and its contributors.
 * 4. Neither the name of the University nor the names of its contributors
@


1.9
log
@LOCK_ASSERT - like KASSERT but ifdef LOCKDEBUG
@
text
@d1 1
a1 1
/*	$OpenBSD: lock.h,v 1.8 2001/11/07 02:44:10 art Exp $	*/
d167 6
a172 6
void	lockinit __P((struct lock *, int prio, char *wmesg, int timo,
			int flags));
int	lockmgr __P((__volatile struct lock *, u_int flags,
			struct simplelock *, struct proc *p));
void    lockmgr_printinfo __P((struct lock *));
int	lockstatus __P((struct lock *));
@


1.9.2.1
log
@Sync UBC branch to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: lock.h,v 1.9 2001/11/11 00:25:47 art Exp $	*/
d167 6
a172 6
void	lockinit(struct lock *, int prio, char *wmesg, int timo,
			int flags);
int	lockmgr(__volatile struct lock *, u_int flags,
			struct simplelock *, struct proc *p);
void    lockmgr_printinfo(struct lock *);
int	lockstatus(struct lock *);
@


1.8
log
@new flag to lockmgr. LK_RECURSEFAIL - even if the lock can recurse fail.
@
text
@d1 1
a1 1
/*	$OpenBSD: lock.h,v 1.7 2001/10/26 02:28:47 art Exp $	*/
d173 6
@


1.7
log
@Typo in comment.
@
text
@d1 1
a1 1
/*	$OpenBSD: lock.h,v 1.6 2001/06/27 04:51:48 art Exp $	*/
d116 1
a116 1
#define LK_EXTFLG_MASK	0x00000070	/* mask of external flags */
d121 1
d127 6
a132 6
#define LK_WANT_UPGRADE	0x00000100	/* waiting for share-to-excl upgrade */
#define LK_WANT_EXCL	0x00000200	/* exclusive lock sought */
#define LK_HAVE_EXCL	0x00000400	/* exclusive lock obtained */
#define LK_WAITDRAIN	0x00000800	/* process waiting for lock to drain */
#define LK_DRAINING	0x00004000	/* lock is being drained */
#define LK_DRAINED	0x00008000	/* lock has been decommissioned */
d138 1
a138 1
#define LK_INTERLOCK	0x00010000	/* unlock passed simple lock after
d140 1
a140 1
#define LK_RETRY	0x00020000	/* vn_lock: retry until locked */
@


1.6
log
@kill old vm
@
text
@d1 1
a1 1
/*	$OpenBSD: lock.h,v 1.5 1999/02/26 02:28:58 art Exp $	*/
d148 1
a148 1
 *	LK_WAIT is set and a sleep would be required (returns EBUSY).
@


1.5
log
@some typedefs used by uvm
@
text
@d1 1
a1 1
/*	$OpenBSD: lock.h,v 1.4 1997/11/07 10:25:42 niklas Exp $	*/
a46 1
#if defined(UVM) /* XXXCDC: kill typedefs later? */
d51 1
a51 1
#endif
@


1.5.6.1
log
@Merge in -current from two days ago in the SMP branch.
As usual with merges, they do not indicate progress, so do not hold
your breath for working SMP, and do not mail me and ask about the
state of it.  It has not changed.  There is work ongoing, but very, very
slowly.  The commit is done in parts as to not lock up the tree in too
big chunks at a time.
@
text
@d1 1
a1 1
/*	$OpenBSD: lock.h,v 1.5 1999/02/26 02:28:58 art Exp $	*/
d47 1
d52 1
a52 1

@


1.5.6.2
log
@Initial import of some SMP code from NetBSD.
Not really working here yet, but there is some work in progress.
@
text
@d1 1
a1 1
/*	$OpenBSD: lock.h,v 1.5.6.1 2001/07/04 11:00:21 niklas Exp $	*/
a120 3
#define LK_SETRECURSE	0x00100000	/* other locks while we have it OK */
#define LK_RECURSEFAIL	0x00200000	/* attempt at recursive lock fails */
#define LK_SPIN		0x00400000	/* lock spins instead of sleeps */
a162 1
#define LK_NOCPU ((cpuid_t) -1)
a171 8

#if defined(MULTIPROCESSOR) || defined(LOCKDEBUG)
#define spinlockinit(lkp, name, flags)
#define spinlockmgr(lkp, flags, intrlk)
#else
#define spinlockinit(lkp, name, flags)          (void)(lkp)
#define spinlockmgr(lkp, flags, intrlk)         (0)
#endif
@


1.5.6.3
log
@spinlock{mgr,init} macro definitions. From assar@@'s recent commit to pmap.c
@
text
@d1 1
a1 1
/*	$OpenBSD: lock.h,v 1.5.6.2 2001/07/14 10:02:47 ho Exp $	*/
d178 2
a179 2
#define spinlockinit(lkp, name, flags)	lockinit(lkp, 0, name, 0, flags)
#define spinlockmgr(lkp, flags, intrlk)	lockmgr(lkp, flags, intrlk, curproc)
d181 2
a182 2
#define spinlockinit(lkp, name, flags)	(void)(lkp)
#define spinlockmgr(lkp, flags, intrlk)	(0)
@


1.5.6.4
log
@Sync the SMP branch to something just after 3.0
@
text
@d1 1
a1 1
/*	$OpenBSD: lock.h,v 1.5.6.3 2001/07/15 13:34:19 ho Exp $	*/
d151 1
a151 1
 *	LK_NOWAIT is set and a sleep would be required (returns EBUSY).
@


1.5.6.5
log
@merge in -current
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d116 1
a116 1
#define LK_EXTFLG_MASK	0x00000770	/* mask of external flags */
a120 1
#define LK_RECURSEFAIL	0x00000100	/* fail if recursive exclusive lock */
d122 1
d129 6
a134 6
#define LK_WANT_UPGRADE	0x00001000	/* waiting for share-to-excl upgrade */
#define LK_WANT_EXCL	0x00002000	/* exclusive lock sought */
#define LK_HAVE_EXCL	0x00004000	/* exclusive lock obtained */
#define LK_WAITDRAIN	0x00008000	/* process waiting for lock to drain */
#define LK_DRAINING	0x00040000	/* lock is being drained */
#define LK_DRAINED	0x00080000	/* lock has been decommissioned */
d140 1
a140 1
#define LK_INTERLOCK	0x00100000	/* unlock passed simple lock after
d142 1
a142 1
#define LK_RETRY	0x00200000	/* vn_lock: retry until locked */
a182 6
#endif

#ifdef LOCKDEBUG
#define LOCK_ASSERT(x)	KASSERT(x)
#else
#define LOCK_ASSERT(x)	/* nothing */
@


1.5.6.6
log
@Merge in -current from roughly a week ago
@
text
@d170 6
a175 6
void	lockinit(struct lock *, int prio, char *wmesg, int timo,
			int flags);
int	lockmgr(__volatile struct lock *, u_int flags,
			struct simplelock *, struct proc *p);
void    lockmgr_printinfo(struct lock *);
int	lockstatus(struct lock *);
@


1.5.6.7
log
@Biglock!  Most of the logic
comes from NetBSD.
Also a lot of fixes, enough to get a dual cpu machine actually run MP for a
very short while (we are just talking about seconds) before starving out one
of the cpus.  More coming very soon.
@
text
@d1 1
a1 1
/*	$OpenBSD: lock.h,v 1.5.6.6 2002/03/28 14:52:01 niklas Exp $	*/
d63 1
a63 5

	/*
	 * This is the sleep message for sleep locks, and a simple name
	 * for spin locks.
	 */
d65 2
a66 37

	union {
		struct {
			/* pid of exclusive lock holder */
			pid_t lk_sleep_lockholder;

			/* priority at which to sleep */
			int lk_sleep_prio;

			/* maximum sleep time (for tsleep) */
			int lk_sleep_timo;
		} lk_un_sleep;
		struct {
			/* CPU ID of exclusive lock holder */
			cpuid_t lk_spin_cpu;
#if defined(LOCKDEBUG)
			TAILQ_ENTRY(lock) lk_spin_list;
#endif
		} lk_un_spin;
	} lk_un;

#define	lk_lockholder	lk_un.lk_un_sleep.lk_sleep_lockholder
#define	lk_locklwp	lk_un.lk_un_sleep.lk_sleep_locklwp
#define	lk_prio		lk_un.lk_un_sleep.lk_sleep_prio
#define	lk_timo		lk_un.lk_un_sleep.lk_sleep_timo

#define	lk_cpu		lk_un.lk_un_spin.lk_spin_cpu
#if defined(LOCKDEBUG)
#define	lk_list		lk_un.lk_un_spin.lk_spin_list
#endif

#if defined(LOCKDEBUG)
	const char *lk_lock_file;
	const char *lk_unlock_file;
	int lk_lock_line;
	int lk_unlock_line;
#endif
a67 1

d116 1
a116 1
#define LK_EXTFLG_MASK	0x00700070	/* mask of external flags */
d121 1
a122 1
#define LK_RECURSEFAIL	0x00200000	/* fail if recursive exclusive lock */
d178 2
a179 4
#define spinlockinit(lkp, name, flags)					\
	lockinit((lkp), 0, (name), 0, (flags) | LK_SPIN)
#define spinlockmgr(lkp, flags, intrlk)					\
	lockmgr((lkp), (flags) | LK_SPIN, (intrlk), curproc)
a188 4
#endif

#if defined(MULTIPROCESSOR)
extern struct lock kernel_lock;
@


1.5.6.8
log
@merge netbsd lockmgr better, makes us halfway through rc
@
text
@d1 1
a1 1
/*	$OpenBSD: lock.h,v 1.5.6.7 2003/05/15 04:08:03 niklas Exp $	*/
a62 1
	short	lk_recurselevel;	/* lvl above which recursion ok */
d91 1
d214 1
a214 1
void	lockmgr_printinfo(__volatile struct lock *);
a224 13
#endif

#if defined(LOCKDEBUG)
int	_spinlock_release_all(__volatile struct lock *, const char *, int);
void	_spinlock_acquire_count(__volatile struct lock *, int, const char *,
	    int);

#define	spinlock_release_all(l)	_spinlock_release_all((l), __FILE__, __LINE__)
#define	spinlock_acquire_count(l, c) _spinlock_acquire_count((l), (c),	\
					__FILE__, __LINE__)
#else
int	spinlock_release_all(__volatile struct lock *);
void	spinlock_acquire_count(__volatile struct lock *, int);
@


1.5.6.9
log
@Go back to defining simplelocks as noops, even if MULTIPROCESSOR.  Instead use
a new real simple recursive-lock capable lock implementation for the few
necessary locks (kernel, scheduler, tlb shootdown, printf and ddb MP).
This because we cannot trust the old fine-grained locks spread out all over
our kernel, and not really tested.
@
text
@d1 1
a1 1
/*	$OpenBSD: lock.h,v 1.5.6.8 2003/05/15 16:45:54 niklas Exp $	*/
d217 1
a217 1
#if (0 && defined(MULTIPROCESSOR)) || defined(LOCKDEBUG)
a246 8
/*
 * XXX Instead of using struct lock for the kernel lock and thus requiring us
 * XXX to implement simplelocks, causing all sorts of fine-grained locks all
 * XXX over our tree getting activated consuming both time and potentially
 * XXX introducing locking protocol bugs.
 */
#ifdef notyet

a247 48

/*
 * XXX Simplelock macros used at "trusted" places.
 */
#define SIMPLELOCK		simplelock
#define SIMPLE_LOCK_INIT	simple_lock_init
#define SIMPLE_LOCK		simple_lock
#define SIMPLE_UNLOCK		simple_unlock

#else

/*
 * Really simple spinlock implementation with recursive capabilities.
 * Correctness is paramount, no fancyness allowed.
 */

struct __mp_lock {
	__cpu_simple_lock_t mpl_lock;
	cpuid_t	mpl_cpu;
	int	mpl_count;
};

static __inline void __mp_lock_init(struct __mp_lock *);
static __inline void __mp_lock(struct __mp_lock *);
static __inline void __mp_unlock(struct __mp_lock *);
static __inline int __mp_release_all(struct __mp_lock *);
static __inline void __mp_acquire_count(struct __mp_lock *, int);
static __inline int __mp_lock_held(struct __mp_lock *);

/*
 * XXX Simplelocks macros used at "trusted" places.
 */
#define SIMPLELOCK		__mp_lock
#define SIMPLE_LOCK_INIT	__mp_lock_init
#define SIMPLE_LOCK		__mp_lock
#define SIMPLE_UNLOCK		__mp_unlock

static __inline void
__mp_lock_init(struct __mp_lock *lock)
{
	__cpu_simple_lock_init(&lock->mpl_lock);
	lock->mpl_cpu = LK_NOCPU;
	lock->mpl_count = 0;
}

#if defined(MP_LOCKDEBUG)
#ifndef DDB
#error "MP_LOCKDEBUG requires DDB"
d250 1
a250 50
extern void Debugger(void);
extern int db_printf(const char *, ...)
    __kprintf_attribute__((__format__(__kprintf__,1,2)));

/* CPU-dependent timing, needs this to be settable from ddb. */
int __mp_lock_spinout = 200000000;
#endif

static __inline void
__mp_lock(struct __mp_lock *lock)
{
	int s = spllock();

	if (lock->mpl_cpu != cpu_number()) {
#ifndef MP_LOCKDEBUG
		__cpu_simple_lock(&lock->mpl_lock);
#else
		{
			int got_it;
			int ticks = __mp_lock_spinout;

			do {
				got_it =
				    __cpu_simple_lock_try(&lock->mpl_lock);
			} while (!got_it && ticks-- > 0);
			if (!got_it) {
 				db_printf("__mp_lock(0x%x): lock spun out",
				    lock);
				Debugger();
			}
		}
#endif
		lock->mpl_cpu = cpu_number();
	}
	lock->mpl_count++;
	splx(s);
}

static __inline void
__mp_unlock(struct __mp_lock *lock)
{
	int s = spllock();

#ifdef mp_LOCKDEBUG
	if (lock->mpl_count == 0 || lock->mpl_cpu == LK_NOCPU) {
		db_printf("__mp_unlock(0x%x): releasing not locked lock\n",
		    lock);
		Debugger();
	}
#endif
a251 60
	if (--lock->mpl_count == 0) {
		lock->mpl_cpu = LK_NOCPU;
		__cpu_simple_unlock(&lock->mpl_lock);
	}
	splx(s);
}

static __inline int
__mp_release_all(struct __mp_lock *lock) {
	int s = spllock();
	int rv = lock->mpl_count;

#ifdef MP_LOCKDEBUG
	if (lock->mpl_count == 0 || lock->mpl_cpu == LK_NOCPU) {
		db_printf(
		    "__mp_release_all(0x%x): releasing not locked lock\n",
		    lock);
		Debugger();
	}
#endif

	lock->mpl_cpu = LK_NOCPU;
	lock->mpl_count = 0;
	__cpu_simple_unlock(&lock->mpl_lock);
	splx(s);
	return (rv);
}

static __inline void
__mp_acquire_count(struct __mp_lock *lock, int count) {
	int s = spllock();

	__cpu_simple_lock(&lock->mpl_lock);
	lock->mpl_cpu = cpu_number();
	lock->mpl_count = count;
	splx(s);
}

static __inline int
__mp_lock_held(struct __mp_lock *lock) {
	return lock->mpl_count;
}

extern struct __mp_lock kernel_lock;

#endif

#else

/*
 * XXX Simplelock macros used at "trusted" places.
 */
#define SIMPLELOCK		simplelock
#define SIMPLE_LOCK_INIT	simple_lock_init
#define SIMPLE_LOCK		simple_lock
#define SIMPLE_UNLOCK		simple_unlock

#endif

#endif /* !_LOCK_H_ */
@


1.5.6.10
log
@do not create new commons
@
text
@d1 1
a1 1
/*	$OpenBSD: lock.h,v 1.5.6.9 2003/05/18 17:41:16 niklas Exp $	*/
d311 1
a311 1
extern int __mp_lock_spinout;
@


1.5.6.11
log
@Sync SMP branch to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: lock.h,v 1.5.6.10 2003/05/18 18:25:03 niklas Exp $	*/
d19 5
a23 1
 * 3. Neither the name of the University nor the names of its contributors
@


1.5.6.12
log
@Merge of current from two weeks agointo the SMP branch
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d304 1
a304 1
    __attribute__((__format__(__kprintf__,1,2)));
d345 1
a345 1
#ifdef MP_LOCKDEBUG
@


1.5.6.13
log
@Merge error, LK_RETRY ended up with LK_RECURSEFAIL value, not good.  With this
fix SMP runs multiuser for a short while :-)
@
text
@d176 1
a176 1
#define LK_INTERLOCK	0x00010000	/* unlock passed simple lock after
d178 1
a178 1
#define LK_RETRY	0x00020000	/* vn_lock: retry until locked */
@


1.5.6.14
log
@reload spinout counter if continuation from ddb
@
text
@d1 1
a1 1
/*	$OpenBSD: lock.h,v 1.5.6.13 2004/02/20 12:43:05 niklas Exp $	*/
d321 2
d324 8
a331 13
				int ticks = __mp_lock_spinout;

				do {
					got_it = __cpu_simple_lock_try(
					    &lock->mpl_lock);
				} while (!got_it && ticks-- > 0);
				if (!got_it) {
 					db_printf(
					    "__mp_lock(0x%x): lock spun out",
					    lock);
					Debugger();
				}
			} while (!got_it);
@


1.5.6.15
log
@move out the mplock stuff to its own header
@
text
@d1 1
a1 1
/*	$OpenBSD: lock.h,v 1.5.6.14 2004/03/14 17:40:32 niklas Exp $	*/
d260 140
@


1.4
log
@$OpenBSD$
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d47 6
@


1.3
log
@Updates for VFS Lite 2 + soft update.
@
text
@d1 2
@


1.2
log
@back out vfs lite2 till after 2.2
@
text
@@


1.1
log
@VFS Lite2 Changes
@
text
@@
