head	1.13;
access;
symbols
	OPENBSD_6_2:1.13.0.2
	OPENBSD_6_2_BASE:1.13
	OPENBSD_6_1:1.13.0.4
	OPENBSD_6_1_BASE:1.13
	OPENBSD_6_0:1.11.0.2
	OPENBSD_6_0_BASE:1.11
	OPENBSD_5_9:1.7.0.2
	OPENBSD_5_9_BASE:1.7
	OPENBSD_5_8:1.1.0.4
	OPENBSD_5_8_BASE:1.1;
locks; strict;
comment	@ * @;


1.13
date	2016.11.20.11.40.58;	author mpi;	state Exp;
branches;
next	1.12;
commitid	3UWH2O8lhF8HTUbi;

1.12
date	2016.10.21.06.27.50;	author dlg;	state Exp;
branches;
next	1.11;
commitid	D5WUiCvZ665NhpbX;

1.11
date	2016.06.07.07.53.33;	author mpi;	state Exp;
branches;
next	1.10;
commitid	P20voeFmD7sc85LW;

1.10
date	2016.06.01.03.34.32;	author dlg;	state Exp;
branches;
next	1.9;
commitid	PIzWjVZVk1r0yDGW;

1.9
date	2016.05.18.03.58.13;	author dlg;	state Exp;
branches;
next	1.8;
commitid	ti6TjacQuFYBXsPy;

1.8
date	2016.05.18.03.46.03;	author dlg;	state Exp;
branches;
next	1.7;
commitid	q5zkugIMulsP5tHa;

1.7
date	2015.12.03.16.27.32;	author mpi;	state Exp;
branches;
next	1.6;
commitid	wK6td35Fr7xdNzh3;

1.6
date	2015.11.26.12.17.19;	author mpi;	state Exp;
branches;
next	1.5;
commitid	DyrVkgzpNqiGgH3X;

1.5
date	2015.09.18.08.30.23;	author dlg;	state Exp;
branches;
next	1.4;
commitid	gVrgkfO910C8RmZI;

1.4
date	2015.09.11.19.22.37;	author dlg;	state Exp;
branches;
next	1.3;
commitid	MvBLHlwTZChYgi41;

1.3
date	2015.09.09.11.21.51;	author dlg;	state Exp;
branches;
next	1.2;
commitid	ro0JXFZlprcZI1rg;

1.2
date	2015.09.01.03.47.58;	author dlg;	state Exp;
branches;
next	1.1;
commitid	l5lNCKsqAztANagW;

1.1
date	2015.07.02.01.34.00;	author dlg;	state Exp;
branches;
next	;
commitid	HBmwORlhlW47BLMN;


desc
@@


1.13
log
@Rename SRPL_ENTER() to SRPL_FIRST() and SRPL_NEXT() to SRPL_FOLLOW().

This allows us to introduce SRPL_NEXT() that can be used to start
iterating on an arbitrary member of an srp list, hence without calling
SRPL_ENTER().

ok dlg@@, jmatthew@@
@
text
@/*	$OpenBSD: srp.h,v 1.12 2016/10/21 06:27:50 dlg Exp $ */

/*
 * Copyright (c) 2014 Jonathan Matthew <jmatthew@@openbsd.org>
 *
 * Permission to use, copy, modify, and distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 */

#ifndef _SYS_SRP_H_
#define _SYS_SRP_H_

#include <sys/refcnt.h>

#ifndef __upunused
#ifdef MULTIPROCESSOR
#define __upunused
#else
#define __upunused __attribute__((__unused__))
#endif
#endif /* __upunused */

struct srp {
	void			*ref;
};

#define SRP_INITIALIZER() { NULL }

struct srp_hazard {
	struct srp		*sh_p;
	void			*sh_v;
};

struct srp_ref {
	struct srp_hazard	*hz;
} __upunused;

#define SRP_HAZARD_NUM 16

struct srp_gc {
	void			(*srp_gc_dtor)(void *, void *);
	void			*srp_gc_cookie;
	struct refcnt		srp_gc_refcnt;
};

#define SRP_GC_INITIALIZER(_d, _c) { (_d), (_c), REFCNT_INITIALIZER() }

/*
 * singly linked list built by following srps
 */

struct srpl_rc {
	void			(*srpl_ref)(void *, void *);
	struct srp_gc		srpl_gc;
};
#define srpl_cookie		srpl_gc.srp_gc_cookie

#define SRPL_RC_INITIALIZER(_r, _u, _c) { _r, SRP_GC_INITIALIZER(_u, _c) }

struct srpl {
	struct srp		sl_head;
};

#ifdef _KERNEL

void		 srp_startup(void);
void		 srp_gc_init(struct srp_gc *, void (*)(void *, void *), void *);
void		*srp_swap_locked(struct srp *, void *);
void		 srp_update_locked(struct srp_gc *, struct srp *, void *);
void		*srp_get_locked(struct srp *);
void		 srp_gc_finalize(struct srp_gc *);

void		 srp_init(struct srp *);

#ifdef MULTIPROCESSOR
void		*srp_swap(struct srp *, void *);
void		 srp_update(struct srp_gc *, struct srp *, void *);
void		 srp_finalize(void *, const char *);
void		*srp_enter(struct srp_ref *, struct srp *);
void		*srp_follow(struct srp_ref *, struct srp *);
void		 srp_leave(struct srp_ref *);
#else /* MULTIPROCESSOR */
#define srp_swap(_srp, _v)		srp_swap_locked((_srp), (_v))
#define srp_update(_gc, _srp, _v)	srp_update_locked((_gc), (_srp), (_v))
#define srp_finalize(_v, _wchan)	((void)0)
#define srp_enter(_sr, _srp)		((_srp)->ref)
#define srp_follow(_sr, _srp)		((_srp)->ref)
#define srp_leave(_sr)			do { } while (0)
#endif /* MULTIPROCESSOR */


void		srpl_rc_init(struct srpl_rc *, void (*)(void *, void *),
		    void (*)(void *, void *), void *);

#define SRPL_INIT(_sl)			srp_init(&(_sl)->sl_head)

#define SRPL_HEAD(name, type)		struct srpl

#define SRPL_ENTRY(type)						\
struct {								\
	struct srp		se_next;				\
}

#define SRPL_FIRST(_sr, _sl)		srp_enter((_sr), &(_sl)->sl_head)
#define SRPL_NEXT(_sr, _e, _ENTRY)	srp_enter((_sr), &(_e)->_ENTRY.se_next)
#define SRPL_FOLLOW(_sr, _e, _ENTRY)	srp_follow((_sr), &(_e)->_ENTRY.se_next)

#define SRPL_FOREACH(_c, _sr, _sl, _ENTRY)				\
	for ((_c) = SRPL_FIRST(_sr, _sl);				\
	    (_c) != NULL; 						\
	    (_c) = SRPL_FOLLOW(_sr, _c, _ENTRY))

#define SRPL_LEAVE(_sr)			srp_leave((_sr))

#define SRPL_FIRST_LOCKED(_sl)		srp_get_locked(&(_sl)->sl_head)
#define SRPL_EMPTY_LOCKED(_sl)		(SRPL_FIRST_LOCKED(_sl) == NULL)

#define SRPL_NEXT_LOCKED(_e, _ENTRY)					\
	srp_get_locked(&(_e)->_ENTRY.se_next)

#define SRPL_FOREACH_LOCKED(_c, _sl, _ENTRY)				\
	for ((_c) = SRPL_FIRST_LOCKED(_sl);				\
	    (_c) != NULL;						\
	    (_c) = SRPL_NEXT_LOCKED((_c), _ENTRY))

#define SRPL_FOREACH_SAFE_LOCKED(_c, _sl, _ENTRY, _tc)			\
	for ((_c) = SRPL_FIRST_LOCKED(_sl);				\
	    (_c) && ((_tc) = SRPL_NEXT_LOCKED(_c, _ENTRY), 1);		\
	    (_c) = (_tc))

#define SRPL_INSERT_HEAD_LOCKED(_rc, _sl, _e, _ENTRY) do {		\
	void *head;							\
									\
	srp_init(&(_e)->_ENTRY.se_next);				\
									\
	head = SRPL_FIRST_LOCKED(_sl);					\
	if (head != NULL) {						\
		(_rc)->srpl_ref(&(_rc)->srpl_cookie, head);		\
		srp_update_locked(&(_rc)->srpl_gc,			\
		    &(_e)->_ENTRY.se_next, head);	 		\
	}								\
									\
	(_rc)->srpl_ref(&(_rc)->srpl_cookie, _e);			\
	srp_update_locked(&(_rc)->srpl_gc, &(_sl)->sl_head, (_e));	\
} while (0)

#define SRPL_INSERT_AFTER_LOCKED(_rc, _se, _e, _ENTRY) do {		\
	void *next;							\
									\
	srp_init(&(_e)->_ENTRY.se_next);				\
									\
	next = SRPL_NEXT_LOCKED(_se, _ENTRY);				\
	if (next != NULL) {						\
		(_rc)->srpl_ref(&(_rc)->srpl_cookie, next);		\
		srp_update_locked(&(_rc)->srpl_gc,			\
		    &(_e)->_ENTRY.se_next, next);	 		\
	}								\
									\
	(_rc)->srpl_ref(&(_rc)->srpl_cookie, _e);			\
	srp_update_locked(&(_rc)->srpl_gc,				\
	    &(_se)->_ENTRY.se_next, (_e));				\
} while (0)

#define SRPL_REMOVE_LOCKED(_rc, _sl, _e, _type, _ENTRY) do {		\
	struct srp *ref;						\
	struct _type *c, *n;						\
									\
	ref = &(_sl)->sl_head;						\
	while ((c = srp_get_locked(ref)) != (_e))			\
		ref = &c->_ENTRY.se_next;				\
									\
	n = SRPL_NEXT_LOCKED(c, _ENTRY);				\
	if (n != NULL)							\
		(_rc)->srpl_ref(&(_rc)->srpl_cookie, n);		\
	srp_update_locked(&(_rc)->srpl_gc, ref, n);			\
	srp_update_locked(&(_rc)->srpl_gc, &c->_ENTRY.se_next, NULL);	\
} while (0)

#endif /* _KERNEL */

#endif /* _SYS_SRP_H_ */
@


1.12
log
@add generalised access to per cpu data structures and counters.

both the cpumem and counters api simply allocates memory for each cpu in
the system that can be used for arbitrary per cpu data (via cpumem), or
a versioned set of counters per cpu (counters).

there is an alternate backend for uniprocessor systems that basically
turns the percpu data access into an immediate access to a single
allocation.

there is also support for percpu data structures that are available at
boot time by providing an allocation for the boot cpu. after autoconf,
these allocations have to be resized to provide for all cpus that were
enumerated by boot.

ok mpi@@
@
text
@d1 1
a1 1
/*	$OpenBSD: srp.h,v 1.11 2016/06/07 07:53:33 mpi Exp $ */
d113 3
a115 4
#define SRPL_ENTER(_sr, _sl)		srp_enter((_sr), &(_sl)->sl_head)

#define SRPL_NEXT(_sr, _e, _ENTRY)	\
	srp_follow((_sr), &(_e)->_ENTRY.se_next)
d118 1
a118 1
	for ((_c) = SRPL_ENTER(_sr, _sl);				\
d120 1
a120 1
	    (_c) = SRPL_NEXT(_sr, _c, _ENTRY))
@


1.11
log
@Move initialization macro outside of #define _KERNEL to use them in
ART regression tests.

ok dlg@@, jmatthew@@
@
text
@d1 1
a1 1
/*	$OpenBSD: srp.h,v 1.10 2016/06/01 03:34:32 dlg Exp $ */
d24 1
d30 1
@


1.10
log
@add support for using SRPs without the garbage collection machinery.

the gc machinery may sleep during srp_update, which makes it hard
to use from an interrupt context. srp_swap simply swaps the references
in an srp and relies ont he caller to schedule work in a process
context where it may sleep with srp_finalise until the reference
is no longer in use.

our network stack currently modifies routing tables in an interrupt
context, so this is built to be used to support rtable updates in
our current stack while supporting concurrent lookups.

ok jmatthew@@ mpi@@
@
text
@d1 1
a1 1
/*	$OpenBSD: srp.h,v 1.9 2016/05/18 03:58:13 dlg Exp $ */
d34 2
d46 1
a46 1
	
d53 18
a72 3
#define SRP_INITIALIZER() { NULL }
#define SRP_GC_INITIALIZER(_d, _c) { (_d), (_c), REFCNT_INITIALIZER() }

a97 17
#endif /* _KERNEL */

/*
 * singly linked list built by following srps
 */

struct srpl_rc {
	void			(*srpl_ref)(void *, void *);
	struct srp_gc		srpl_gc;
};
#define srpl_cookie		srpl_gc.srp_gc_cookie

struct srpl {
	struct srp		sl_head;
};

#ifdef _KERNEL
a100 2

#define SRPL_RC_INITIALIZER(_r, _u, _c) { _r, SRP_GC_INITIALIZER(_u, _c) }
@


1.9
log
@rename srp_finalize to srp_gc_finalize
@
text
@d1 1
a1 1
/*	$OpenBSD: srp.h,v 1.8 2016/05/18 03:46:03 dlg Exp $ */
d58 1
d66 1
d68 1
d73 1
d75 1
@


1.8
log
@rework the srp api so it takes an srp_ref struct that the caller provides.

the srp_ref struct is used to track the location of the callers
hazard pointer so later calls to srp_follow and srp_enter already
know what to clear. this in turn means most of the caveats around
using srps go away. specifically, you can now:

- switch cpus while holding an srp ref
  - ie, you can sleep while holding an srp ref
- you can take and release srp refs in any order

the original intent was to simplify use of the api when dealing
with complicated data structures. the caller now no longer has to
track the location of the srp a value was fetched from, the srp_ref
effectively does that for you.

srp lists have been refactored to use srp_refs instead of srpl_iter
structs.

this is in preparation of using srps inside the ART code. ART is a
complicated data structure, and lookups require overlapping holds
of srp references.

ok mpi@@ jmatthew@@
@
text
@d1 1
a1 1
/*	$OpenBSD: srp.h,v 1.7 2015/12/03 16:27:32 mpi Exp $ */
d60 1
a60 1
void		 srp_finalize(struct srp_gc *);
@


1.7
log
@Use SRPL_HEAD() and SRPL_ENTRY() to be consistent with and allow to
fallback to a SLIST.

ok dlg@@, jasper@@
@
text
@d1 1
a1 1
/*	$OpenBSD: srp.h,v 1.6 2015/11/26 12:17:19 mpi Exp $ */
d24 6
d39 4
d66 3
a68 3
void		*srp_enter(struct srp *);
void		*srp_follow(struct srp *, void *, struct srp *);
void		 srp_leave(struct srp *, void *);
d71 3
a73 3
#define srp_enter(_srp)			((_srp)->ref)
#define srp_follow(_srp, _v, _next)	((_next)->ref)
#define srp_leave(_srp, _v)		do { } while (0)
a91 4
struct srpl_iter {
	struct srp *		si_ref;
};

d108 1
a108 11
static inline void *
_srpl_enter(struct srpl *sl, struct srpl_iter *si)
{
	si->si_ref = &sl->sl_head;
	return (srp_enter(si->si_ref));
}

static inline void *
_srpl_next(struct srpl_iter *si, void *elm, struct srp *nref)
{
	void *n;
d110 2
a111 2
	n = srp_follow(si->si_ref, elm, nref);
	si->si_ref = nref;
d113 2
a114 10
	return (n);
}

#define SRPL_ENTER(_sl, _si)		_srpl_enter(_sl, _si)

#define SRPL_NEXT(_si, _e, _ENTRY)					\
	 _srpl_next(_si, _e, &(_e)->_ENTRY.se_next)

#define SRPL_FOREACH(_c, _sl, _si, _ENTRY)				\
	for ((_c) = SRPL_ENTER(_sl, _si);				\
d116 1
a116 1
	    (_c) = SRPL_NEXT(_si, _c, _ENTRY))
d118 1
a118 1
#define SRPL_LEAVE(_si, _c)		srp_leave((_si)->si_ref, (_c))
d120 1
a121 1
#define SRPL_FIRST_LOCKED(_sl)		srp_get_locked(&(_sl)->sl_head)
d124 1
a124 1
    srp_get_locked(&(_e)->_ENTRY.se_next)
@


1.6
log
@Add SRPL_FOREACH_SAFE_LOCKED(9), needed to turn the single list of
multipath route entries mpsafe.

ok dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: srp.h,v 1.5 2015/09/18 08:30:23 dlg Exp $ */
a81 4
struct srpl_entry {
	struct srp		se_next;
};

d94 7
@


1.5
log
@implement SRPL_INSERT_AFTER_LOCKED.

i thought id committed this at l2k15. sorry for the delay.
@
text
@d1 1
a1 1
/*	$OpenBSD: srp.h,v 1.4 2015/09/11 19:22:37 dlg Exp $ */
d139 5
@


1.4
log
@make srp use refcnts so it can use refcnt_finalize instead of
sleep_setup/sleep_finish.
@
text
@d1 1
a1 1
/*	$OpenBSD: srp.h,v 1.3 2015/09/09 11:21:51 dlg Exp $ */
d154 17
@


1.3
log
@implement a singly linked list built with SRPs.

this allows us to build lists of things that can be followed by
multiple cpus.

ok mpi@@ claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: srp.h,v 1.2 2015/09/01 03:47:58 dlg Exp $ */
d22 2
d38 1
a38 1
	u_int			srp_gc_refcount;
d44 1
a44 1
#define SRP_GC_INITIALIZER(_d, _c) { (_d), (_c), 1 }
@


1.2
log
@mattieu baptiste reported a problem with bpf+srps where the per cpu
hazard pointers were becoming corrupt and therefore panics.

the problem turned out to be that bridge_input calls if_input on
behalf of a hardware interface which then calls bpf_mtap at splsoftnet,
while the actual hardware nic calls if_input and bpf_mtap at splnet.
the hardware interrupts ran in the middle of the bpf calls bridge
runs at softnet. this means the same srps are being entered and
left on the same cpu at different ipls, which led to races because
of the order of operations on the per cpu hazard pointers.

after a lot of experimentation, jmatthew@@ figured out how to deal
with this problem without introducing per cpu critical sections
(ie, splhigh) calls in srp_enter and srp_leave, and without introducing
atomic operations.

the solution is to iterate forward through the array of hazard
pointers in srp_enter, and backward in srp_leave to clear. if you
guarantee that you leave srps in the reverse order to entering them,
then you can use the same set of SRPs at different IPLs on the same
CPU.

the ordering requirement is a problem if we want to build linked
data structures out of srps because you need to hold a ref to the
current element containing the next srp to use it, before giving
up the current ref. we're adding srp_follow() to support taking the
next ref and giving up the current one while preserving the structure
of the hazard pointer list. srp_follow() does this by reusing the
hazard pointer for the current reference for the next ref.

both mattieu baptiste and jmatthew@@ have been hitting this pretty
hard with a tweaked version of srp+bpf that uses srp_follow instead
of interleaved srp_enter/srp_leave sequences. neither can reproduce
the panics anymore.

thanks to mattieu for the report and tests
ok jmatthew@@
@
text
@d1 1
a1 1
/*	$OpenBSD: srp.h,v 1.1 2015/07/02 01:34:00 dlg Exp $ */
d63 105
@


1.1
log
@introduce srp, which according to the manpage i wrote is short for
"shared reference pointers".

srp allows concurrent access to a data structure by multiple cpus
while avoiding interlocking cpu opcodes. it manages its own reference
counts and the garbage collection of those data structure to avoid
use after frees.

internally srp is a twisted version of hazard pointers, which are
a relative of RCU.

jmatthew wrote the bulk of a hazard pointer implementation and
changed bpf to use it to allow mpsafe access to bpfilters. however,
at s2k15 we were trying to apply it to other data structures but
the memory overhead of every hazard pointer would have blown out
significantly in several uses cases. a bulk of our time at s2k15
was spent reworking hazard pointers into srp.

this diff adds the srp api and adds the necessary metadata to struct
cpuinfo on our MP architectures. srp on uniprocessor platforms has
alternate code that is optimised because it knows there'll be no
concurrent access to data by multiple cpus.

srp is made available to the system via param.h, so it should be
available everywhere in the kernel.

the docs likely need improvement cos im too close to the implementation.

ok mpi@@
@
text
@d1 1
a1 1
/*	$OpenBSD$ */
d55 1
d60 1
@

