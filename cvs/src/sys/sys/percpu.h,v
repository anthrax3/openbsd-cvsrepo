head	1.7;
access;
symbols
	OPENBSD_6_1_BASE:1.7;
locks; strict;
comment	@ * @;


1.7
date	2017.02.23.00.15.12;	author dlg;	state Exp;
branches;
next	1.6;
commitid	zJOWtu4wRcqRwFJg;

1.6
date	2017.02.05.16.23.38;	author jca;	state Exp;
branches;
next	1.5;
commitid	b4PzKhPOLWkSDY9t;

1.5
date	2016.12.20.12.07.14;	author bluhm;	state Exp;
branches;
next	1.4;
commitid	HS9IeMp5BEXUmPfX;

1.4
date	2016.11.14.03.26.31;	author dlg;	state Exp;
branches;
next	1.3;
commitid	0ISNxjArfSgH9K4U;

1.3
date	2016.10.24.23.58.33;	author dlg;	state Exp;
branches;
next	1.2;
commitid	3TeGbJaxAzwxTMGK;

1.2
date	2016.10.24.03.15.35;	author deraadt;	state Exp;
branches;
next	1.1;
commitid	IwNyiJ0JM3Lxbhzy;

1.1
date	2016.10.21.06.27.50;	author dlg;	state Exp;
branches;
next	;
commitid	D5WUiCvZ665NhpbX;


desc
@@


1.7
log
@be nicer to 32bit strict alignment archs that can do 64bit loads/stores.

ie, align boot memory to the size of uint64_ts.

there's an argument to be made that we should align this to 16 bytes
to be consistent with malloc and pools.
@
text
@/*	$OpenBSD: percpu.h,v 1.6 2017/02/05 16:23:38 jca Exp $ */

/*
 * Copyright (c) 2016 David Gwynne <dlg@@openbsd.org>
 *
 * Permission to use, copy, modify, and distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 */

#ifndef _SYS_PERCPU_H_
#define _SYS_PERCPU_H_

#ifndef CACHELINESIZE
#define CACHELINESIZE 64
#endif

#ifndef __upunused /* this should go in param.h */
#ifdef MULTIPROCESSOR
#define __upunused
#else
#define __upunused __attribute__((__unused__))
#endif
#endif

struct cpumem {
	void		*mem;
};

struct cpumem_iter {
	unsigned int	cpu;
} __upunused;

struct counters_ref {
	uint64_t	 g;
	uint64_t	*c;
};

#ifdef _KERNEL

#include <sys/atomic.h>

struct pool;

struct cpumem	*cpumem_get(struct pool *);
void		 cpumem_put(struct pool *, struct cpumem *);

struct cpumem	*cpumem_malloc(size_t, int);
struct cpumem	*cpumem_malloc_ncpus(struct cpumem *, size_t, int);
void		 cpumem_free(struct cpumem *, int, size_t);

void		*cpumem_first(struct cpumem_iter *, struct cpumem *);
void		*cpumem_next(struct cpumem_iter *, struct cpumem *);

static inline void *
cpumem_enter(struct cpumem *cm)
{
#ifdef MULTIPROCESSOR
	return (cm[cpu_number()].mem);
#else
	return (cm);
#endif
}

static inline void
cpumem_leave(struct cpumem *cm, void *mem)
{
	/* KDASSERT? */
}

#ifdef MULTIPROCESSOR

#define CPUMEM_BOOT_MEMORY(_name, _sz)					\
static struct {								\
	unsigned char	mem[_sz];					\
	struct cpumem	cpumem;						\
} __aligned(CACHELINESIZE) _name##_boot_cpumem = {			\
	.cpumem = { _name##_boot_cpumem.mem }				\
}

#define CPUMEM_BOOT_INITIALIZER(_name)					\
	{ &_name##_boot_cpumem.cpumem }

#else /* MULTIPROCESSOR */

#define CPUMEM_BOOT_MEMORY(_name, _sz)					\
static struct {								\
	unsigned char	mem[_sz];					\
} __aligned(sizeof(uint64_t)) _name##_boot_cpumem

#define CPUMEM_BOOT_INITIALIZER(_name)					\
	{ (struct cpumem *)&_name##_boot_cpumem.mem }

#endif /* MULTIPROCESSOR */

#define CPUMEM_FOREACH(_var, _iter, _cpumem)				\
	for ((_var) = cpumem_first((_iter), (_cpumem));			\
	    (_var) != NULL;						\
	    (_var) = cpumem_next((_iter), (_cpumem)))

/*
 * per cpu counters
 */

struct cpumem	*counters_alloc(unsigned int);
struct cpumem	*counters_alloc_ncpus(struct cpumem *, unsigned int);
void		 counters_free(struct cpumem *, unsigned int);
void		 counters_read(struct cpumem *, uint64_t *, unsigned int);
void		 counters_zero(struct cpumem *, unsigned int);

static inline uint64_t *
counters_enter(struct counters_ref *ref, struct cpumem *cm)
{
	ref->c = cpumem_enter(cm);
#ifdef MULTIPROCESSOR
	ref->g = ++(*ref->c); /* make the generation number odd */
	membar_producer();
	return (ref->c + 1);
#else
	return (ref->c);
#endif
}

static inline void
counters_leave(struct counters_ref *ref, struct cpumem *cm)
{
#ifdef MULTIPROCESSOR
	membar_producer();
	(*ref->c) = ++ref->g; /* make the generation number even again */
#endif
	cpumem_leave(cm, ref->c);
}

static inline void
counters_inc(struct cpumem *cm, unsigned int c)
{
	struct counters_ref ref;
	uint64_t *counters;

	counters = counters_enter(&ref, cm);
	counters[c]++;
	counters_leave(&ref, cm);
}

static inline void
counters_add(struct cpumem *cm, unsigned int c, uint64_t v)
{
	struct counters_ref ref;
	uint64_t *counters;

	counters = counters_enter(&ref, cm);
	counters[c] += v;
	counters_leave(&ref, cm);
}

static inline void
counters_pkt(struct cpumem *cm, unsigned int c, unsigned int b, uint64_t v)
{
	struct counters_ref ref;
	uint64_t *counters;

	counters = counters_enter(&ref, cm);
	counters[c]++;
	counters[b] += v;
	counters_leave(&ref, cm);
}

#ifdef MULTIPROCESSOR
#define COUNTERS_BOOT_MEMORY(_name, _n)					\
	CPUMEM_BOOT_MEMORY(_name, ((_n) + 1) * sizeof(uint64_t))
#else
#define COUNTERS_BOOT_MEMORY(_name, _n)					\
	CPUMEM_BOOT_MEMORY(_name, (_n) * sizeof(uint64_t))
#endif

#define COUNTERS_BOOT_INITIALIZER(_name)	CPUMEM_BOOT_INITIALIZER(_name)

#endif /* _KERNEL */
#endif /* _SYS_PERCPU_H_ */
@


1.6
log
@Always allocate counters memory using type M_COUNTERS.

This makes the API simpler, and is probably more useful than spreading
counters memory other several types, making it harder to track.

Prodded by mpi, ok mpi@@ stsp@@
@
text
@d1 1
a1 1
/*	$OpenBSD: percpu.h,v 1.5 2016/12/20 12:07:14 bluhm Exp $ */
d97 1
a97 1
} __aligned(sizeof(unsigned long)) _name##_boot_cpumem
@


1.5
log
@Put a write memory barrier into counters_enter().  This ensures
that the generation number increment is written before the function
returns and anything else is written.
OK patrick@@ mpi@@ dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: percpu.h,v 1.4 2016/11/14 03:26:31 dlg Exp $ */
d113 3
a115 3
struct cpumem	*counters_alloc(unsigned int, int);
struct cpumem	*counters_alloc_ncpus(struct cpumem *, unsigned int, int);
void		 counters_free(struct cpumem *, int, unsigned int);
@


1.4
log
@add wrappers around common operations on counters.

specifically, counters_inc, counters_add, and counters_pkt. the latter
increments both a packet counter and adds to byte counter instead of just
one counter at a time.

part of a bigger diff thats ok mpi@@ mikeb@@
@
text
@d1 1
a1 1
/*	$OpenBSD: percpu.h,v 1.3 2016/10/24 23:58:33 dlg Exp $ */
d125 1
@


1.3
log
@avoid using realloc in the name of things that dont work like realloc.

cpumem_realloc and counters_realloc actually allocated new per cpu data
for new cpus, they didnt resize the existing allocation.

specifically, this renames cpumem_reallod to cpumem_malloc_ncpus, and
counters_realloc to counters_alloc_ncpus.

ok (and with some fixes by) bluhm@@
@
text
@d1 1
a1 1
/*	$OpenBSD: percpu.h,v 1.2 2016/10/24 03:15:35 deraadt Exp $ */
d139 34
@


1.2
log
@non-MP vs MP codepaths were confusingly split between the .c and .h file.
Unify these by placing #ifdef MULTIPROCESSOR inside the functions, then
collapse further to reduce _KERNEL blocks
ok dlg
@
text
@d1 1
a1 1
/*	$OpenBSD: percpu.h,v 1.1 2016/10/21 06:27:50 dlg Exp $ */
d57 1
a57 1
struct cpumem	*cpumem_realloc(struct cpumem *, size_t, int);
d114 1
a114 1
struct cpumem	*counters_realloc(struct cpumem *, unsigned int, int);
@


1.1
log
@add generalised access to per cpu data structures and counters.

both the cpumem and counters api simply allocates memory for each cpu in
the system that can be used for arbitrary per cpu data (via cpumem), or
a versioned set of counters per cpu (counters).

there is an alternate backend for uniprocessor systems that basically
turns the percpu data access into an immediate access to a single
allocation.

there is also support for percpu data structures that are available at
boot time by providing an allocation for the boot cpu. after autoconf,
these allocations have to be resized to provide for all cpus that were
enumerated by boot.

ok mpi@@
@
text
@d1 1
a1 1
/*	$OpenBSD$ */
d60 3
a62 1
#ifdef MULTIPROCESSOR
d66 1
d68 3
d79 1
a79 2
void		*cpumem_first(struct cpumem_iter *, struct cpumem *);
void		*cpumem_next(struct cpumem_iter *, struct cpumem *);
a92 23
static inline void *
cpumem_enter(struct cpumem *cm)
{
	return (cm);
}

static inline void
cpumem_leave(struct cpumem *cm, void *mem)
{
	/* KDASSERT? */
}

static inline void *
cpumem_first(struct cpumem_iter *i, struct cpumem *cm)
{
	return (cm);
}

static inline void *
cpumem_next(struct cpumem_iter *i, struct cpumem *cm)
{
	return (NULL);
}
d97 1
a97 1
} _name##_boot_cpumem
d109 4
a118 1
#ifdef MULTIPROCESSOR
d123 1
d126 3
d134 1
d137 1
d140 2
a144 13
static inline uint64_t *
counters_enter(struct counters_ref *r, struct cpumem *cm)
{
	r->c = cpumem_enter(cm);
	return (r->c);
}

static inline void
counters_leave(struct counters_ref *r, struct cpumem *cm)
{
	cpumem_leave(cm, r->c);
}

@

