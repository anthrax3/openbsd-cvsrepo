head	1.9;
access;
symbols
	OPENBSD_6_2:1.9.0.42
	OPENBSD_6_2_BASE:1.9
	OPENBSD_6_1:1.9.0.40
	OPENBSD_6_1_BASE:1.9
	OPENBSD_6_0:1.9.0.36
	OPENBSD_6_0_BASE:1.9
	OPENBSD_5_9:1.9.0.32
	OPENBSD_5_9_BASE:1.9
	OPENBSD_5_8:1.9.0.34
	OPENBSD_5_8_BASE:1.9
	OPENBSD_5_7:1.9.0.26
	OPENBSD_5_7_BASE:1.9
	OPENBSD_5_6:1.9.0.30
	OPENBSD_5_6_BASE:1.9
	OPENBSD_5_5:1.9.0.28
	OPENBSD_5_5_BASE:1.9
	OPENBSD_5_4:1.9.0.24
	OPENBSD_5_4_BASE:1.9
	OPENBSD_5_3:1.9.0.22
	OPENBSD_5_3_BASE:1.9
	OPENBSD_5_2:1.9.0.20
	OPENBSD_5_2_BASE:1.9
	OPENBSD_5_1_BASE:1.9
	OPENBSD_5_1:1.9.0.18
	OPENBSD_5_0:1.9.0.16
	OPENBSD_5_0_BASE:1.9
	OPENBSD_4_9:1.9.0.14
	OPENBSD_4_9_BASE:1.9
	OPENBSD_4_8:1.9.0.12
	OPENBSD_4_8_BASE:1.9
	OPENBSD_4_7:1.9.0.8
	OPENBSD_4_7_BASE:1.9
	OPENBSD_4_6:1.9.0.10
	OPENBSD_4_6_BASE:1.9
	OPENBSD_4_5:1.9.0.6
	OPENBSD_4_5_BASE:1.9
	OPENBSD_4_4:1.9.0.4
	OPENBSD_4_4_BASE:1.9
	OPENBSD_4_3:1.9.0.2
	OPENBSD_4_3_BASE:1.9
	OPENBSD_4_2:1.8.0.10
	OPENBSD_4_2_BASE:1.8
	OPENBSD_4_1:1.8.0.8
	OPENBSD_4_1_BASE:1.8
	OPENBSD_4_0:1.8.0.6
	OPENBSD_4_0_BASE:1.8
	OPENBSD_3_9:1.8.0.4
	OPENBSD_3_9_BASE:1.8
	OPENBSD_3_8:1.8.0.2
	OPENBSD_3_8_BASE:1.8
	OPENBSD_3_7:1.4.0.4
	OPENBSD_3_7_BASE:1.4
	OPENBSD_3_6:1.4.0.2
	OPENBSD_3_6_BASE:1.4
	SMP_SYNC_A:1.1
	SMP_SYNC_B:1.1
	SMP:1.1.0.2;
locks; strict;
comment	@ * @;


1.9
date	2007.11.26.17.15.29;	author art;	state Exp;
branches;
next	1.8;

1.8
date	2005.06.17.22.33.34;	author niklas;	state Exp;
branches;
next	1.7;

1.7
date	2005.05.29.03.20.42;	author deraadt;	state Exp;
branches;
next	1.6;

1.6
date	2005.05.27.20.46.59;	author niklas;	state Exp;
branches;
next	1.5;

1.5
date	2005.05.25.23.17.47;	author niklas;	state Exp;
branches;
next	1.4;

1.4
date	2004.07.22.15.42.11;	author art;	state Exp;
branches;
next	1.3;

1.3
date	2004.06.20.17.46.11;	author pedro;	state Exp;
branches;
next	1.2;

1.2
date	2004.06.13.21.49.28;	author niklas;	state Exp;
branches;
next	1.1;

1.1
date	2004.03.18.02.05.23;	author niklas;	state dead;
branches
	1.1.2.1;
next	;

1.1.2.1
date	2004.03.18.02.05.23;	author niklas;	state Exp;
branches;
next	1.1.2.2;

1.1.2.2
date	2004.04.21.09.40.50;	author niklas;	state Exp;
branches;
next	;


desc
@@


1.9
log
@Move the implementation of __mp_lock (biglock) into machine dependent
code. At this moment all architectures get the copy of the old code
except i386 which gets a new shiny implementation that doesn't spin
at splhigh (doh!) and doesn't try to grab the biglock when releasing
the biglock (double doh!).

Shaves 10% of system time during kernel compile and might solve a few
bugs as a bonus.

Other architectures coming shortly.

miod@@ deraadt@@ ok
@
text
@/*	$OpenBSD: mplock.h,v 1.8 2005/06/17 22:33:34 niklas Exp $	*/

/*
 * Copyright (c) 2004 Niklas Hallqvist.  All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 *
 * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR
 * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
 * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
 * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,
 * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
 * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
 * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
 * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF
 * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

#ifndef _MPLOCK_H_
#define _MPLOCK_H_

#ifdef notyet
/*
 * Enable the prototypes once the architectures stop playing around
 * with inlines.
 */
void __mp_lock_init(struct __mp_lock *);
void __mp_lock(struct __mp_lock *);
void __mp_unlock(struct __mp_lock *);
int __mp_release_all(struct __mp_lock *);
int __mp_release_all_but_one(struct __mp_lock *);
void __mp_acquire_count(struct __mp_lock *, int);
int __mp_lock_held(struct __mp_lock *);
#endif

#include <machine/mplock.h>

extern struct __mp_lock kernel_lock;

#endif /* !_MPLOCK_H */
@


1.8
log
@A second approach at fixing the telnet localhost & problem
(but I tend to call it ssh localhost & now when telnetd is
history).  This is more localized patch, but leaves us with
a recursive lock for protecting scheduling and signal state.
Better care is taken to actually be symmetric over mi_switch.
Also, the dolock cruft in psignal can go with this solution.
Better test runs by more people for longer time has been
carried out compared to the c2k5 patch.

Long term the current mess with interruptible sleep, the
default action on stop signals and wakeup interactions need
to be revisited.  ok deraadt@@, art@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mplock.h,v 1.7 2005/05/29 03:20:42 deraadt Exp $	*/
d30 1
d32 2
a33 2
 * Really simple spinlock implementation with recursive capabilities.
 * Correctness is paramount, no fancyness allowed.
d35 7
a41 151

struct __mp_lock {
	__cpu_simple_lock_t mpl_lock;
	cpuid_t	mpl_cpu;
	int	mpl_count;
};

static __inline void __mp_lock_init(struct __mp_lock *);
static __inline void __mp_lock(struct __mp_lock *);
static __inline void __mp_unlock(struct __mp_lock *);
static __inline int __mp_release_all(struct __mp_lock *);
static __inline void __mp_acquire_count(struct __mp_lock *, int);
static __inline int __mp_lock_held(struct __mp_lock *);

/*
 * XXX Simplelocks macros used at "trusted" places.
 */
#define SIMPLELOCK		__mp_lock
#define SIMPLE_LOCK_INIT	__mp_lock_init
#define SIMPLE_LOCK		__mp_lock
#define SIMPLE_UNLOCK		__mp_unlock

static __inline void
__mp_lock_init(struct __mp_lock *lock)
{
	__cpu_simple_lock_init(&lock->mpl_lock);
	lock->mpl_cpu = LK_NOCPU;
	lock->mpl_count = 0;
}

#if defined(MP_LOCKDEBUG)
#ifndef DDB
#error "MP_LOCKDEBUG requires DDB"
#endif

extern void Debugger(void);
extern int db_printf(const char *, ...)
    __attribute__((__format__(__kprintf__,1,2)));

/* CPU-dependent timing, needs this to be settable from ddb. */
extern int __mp_lock_spinout;
#endif

static __inline void
__mp_lock(struct __mp_lock *lock)
{
	int s = spllock();

	if (lock->mpl_cpu != cpu_number()) {
#ifndef MP_LOCKDEBUG
		__cpu_simple_lock(&lock->mpl_lock);
#else
		{
			int got_it;
			do {
				int ticks = __mp_lock_spinout;

				do {
					got_it = __cpu_simple_lock_try(
					    &lock->mpl_lock);
				} while (!got_it && ticks-- > 0);
				if (!got_it) {
 					db_printf(
					    "__mp_lock(0x%x): lock spun out",
					    lock);
					Debugger();
				}
			} while (!got_it);
		}
#endif
		lock->mpl_cpu = cpu_number();
	}
	lock->mpl_count++;
	splx(s);
}

/*
 * Try to acquire the lock, if another cpu has it, fill it in the
 * call-by-reference cpu parameter.  Return true if acquired.
 */
static __inline int
__mp_lock_try(struct __mp_lock *lock, cpuid_t *cpu)
{
	int s = spllock();

	if (lock->mpl_cpu != cpu_number()) {
		if (!__cpu_simple_lock_try(&lock->mpl_lock)) {
			*cpu = lock->mpl_cpu;
			splx(s);
			return 0;
		}
		lock->mpl_cpu = cpu_number();
	}
	lock->mpl_count++;
	splx(s);
	return 1;
}

static __inline void
__mp_unlock(struct __mp_lock *lock)
{
	int s = spllock();

#ifdef MP_LOCKDEBUG
	if (lock->mpl_count == 0 || lock->mpl_cpu == LK_NOCPU) {
		db_printf("__mp_unlock(0x%x): releasing not locked lock\n",
		    lock);
		Debugger();
	}
#endif

	if (--lock->mpl_count == 0) {
		lock->mpl_cpu = LK_NOCPU;
		__cpu_simple_unlock(&lock->mpl_lock);
	}
	splx(s);
}

static __inline int
__mp_release_all(struct __mp_lock *lock) {
	int s = spllock();
	int rv = lock->mpl_count;

#ifdef MP_LOCKDEBUG
	if (lock->mpl_count == 0 || lock->mpl_cpu == LK_NOCPU) {
		db_printf(
		    "__mp_release_all(0x%x): releasing not locked lock\n",
		    lock);
		Debugger();
	}
#endif

	lock->mpl_cpu = LK_NOCPU;
	lock->mpl_count = 0;
	__cpu_simple_unlock(&lock->mpl_lock);
	splx(s);
	return (rv);
}

static __inline int
__mp_release_all_but_one(struct __mp_lock *lock) {
	int s = spllock();
	int rv = lock->mpl_count - 1;

#ifdef MP_LOCKDEBUG
	if (lock->mpl_count == 0 || lock->mpl_cpu == LK_NOCPU) {
		db_printf(
		    "__mp_release_all_but_one(0x%x): releasing not locked lock\n",
		    lock);
		Debugger();
	}
d44 1
a44 18
	lock->mpl_count = 1;
	splx(s);
	return (rv);
}

static __inline void
__mp_acquire_count(struct __mp_lock *lock, int count) {
	int s = spllock();

	while (count--)
		__mp_lock(lock);
	splx(s);
}

static __inline int
__mp_lock_held(struct __mp_lock *lock) {
	return lock->mpl_count && lock->mpl_cpu == cpu_number();
}
@


1.7
log
@sched work by niklas and art backed out; causes panics
@
text
@d1 1
a1 1
/*	$OpenBSD: mplock.h,v 1.4 2004/07/22 15:42:11 art Exp $	*/
d173 19
d196 2
a197 3
	__cpu_simple_lock(&lock->mpl_lock);
	lock->mpl_cpu = cpu_number();
	lock->mpl_count = count;
d203 1
a203 1
	return lock->mpl_count;
@


1.6
log
@add a __mp_lock_try implementation.  ok art@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mplock.h,v 1.5 2005/05/25 23:17:47 niklas Exp $	*/
d47 8
@


1.5
log
@This patch is mortly art's work and was done *a year* ago.  Art wants to thank
everyone for the prompt review and ok of this work ;-)  Yeah, that includes me
too, or maybe especially me.  I am sorry.

Change the sched_lock to a mutex. This fixes, among other things, the infamous
"telnet localhost &" problem.  The real bug in that case was that the sched_lock
which is by design a non-recursive lock, was recursively acquired, and not
enough releases made us hold the lock in the idle loop, blocking scheduling
on the other processors.  Some of the other processors would hold the biglock though,
which made it impossible for cpu 0 to enter the kernel...  A nice deadlock.
Let me just say debugging this for days just to realize that it was all fixed
in an old diff noone ever ok'd was somewhat of an anti-climax.

This diff also changes splsched to be correct for all our architectures.
@
text
@d1 1
a1 1
/*	$OpenBSD: mplock.h,v 1.4 2004/07/22 15:42:11 art Exp $	*/
d100 22
@


1.4
log
@SIMPLELOCK -> mutex for the lock around deadproc list.
Also move the whole deadproc infrastructure to kern_exit, it's only used
there.

miod@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: mplock.h,v 1.3 2004/06/20 17:46:11 pedro Exp $	*/
a46 8

/*
 * XXX Simplelocks macros used at "trusted" places.
 */
#define SIMPLELOCK		__mp_lock
#define SIMPLE_LOCK_INIT	__mp_lock_init
#define SIMPLE_LOCK		__mp_lock
#define SIMPLE_UNLOCK		__mp_unlock
@


1.3
log
@$OpenBSD$, ok niklas@@
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
a166 3

/* XXX Should really be in proc.h but then __mp_lock is not defined. */
extern struct SIMPLELOCK deadproc_slock;
@


1.2
log
@debranch SMP, have fun
@
text
@d1 2
@


1.1
log
@file mplock.h was initially added on branch SMP.
@
text
@d1 169
@


1.1.2.1
log
@move out the mplock stuff to its own header
@
text
@a0 166
/*
 * Copyright (c) 2004 Niklas Hallqvist.  All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 *
 * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR
 * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
 * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
 * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,
 * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
 * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
 * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
 * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF
 * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

#ifndef _MPLOCK_H_
#define _MPLOCK_H_

/*
 * Really simple spinlock implementation with recursive capabilities.
 * Correctness is paramount, no fancyness allowed.
 */

struct __mp_lock {
	__cpu_simple_lock_t mpl_lock;
	cpuid_t	mpl_cpu;
	int	mpl_count;
};

static __inline void __mp_lock_init(struct __mp_lock *);
static __inline void __mp_lock(struct __mp_lock *);
static __inline void __mp_unlock(struct __mp_lock *);
static __inline int __mp_release_all(struct __mp_lock *);
static __inline void __mp_acquire_count(struct __mp_lock *, int);
static __inline int __mp_lock_held(struct __mp_lock *);

/*
 * XXX Simplelocks macros used at "trusted" places.
 */
#define SIMPLELOCK		__mp_lock
#define SIMPLE_LOCK_INIT	__mp_lock_init
#define SIMPLE_LOCK		__mp_lock
#define SIMPLE_UNLOCK		__mp_unlock

static __inline void
__mp_lock_init(struct __mp_lock *lock)
{
	__cpu_simple_lock_init(&lock->mpl_lock);
	lock->mpl_cpu = LK_NOCPU;
	lock->mpl_count = 0;
}

#if defined(MP_LOCKDEBUG)
#ifndef DDB
#error "MP_LOCKDEBUG requires DDB"
#endif

extern void Debugger(void);
extern int db_printf(const char *, ...)
    __attribute__((__format__(__kprintf__,1,2)));

/* CPU-dependent timing, needs this to be settable from ddb. */
extern int __mp_lock_spinout;
#endif

static __inline void
__mp_lock(struct __mp_lock *lock)
{
	int s = spllock();

	if (lock->mpl_cpu != cpu_number()) {
#ifndef MP_LOCKDEBUG
		__cpu_simple_lock(&lock->mpl_lock);
#else
		{
			int got_it;
			do {
				int ticks = __mp_lock_spinout;

				do {
					got_it = __cpu_simple_lock_try(
					    &lock->mpl_lock);
				} while (!got_it && ticks-- > 0);
				if (!got_it) {
 					db_printf(
					    "__mp_lock(0x%x): lock spun out",
					    lock);
					Debugger();
				}
			} while (!got_it);
		}
#endif
		lock->mpl_cpu = cpu_number();
	}
	lock->mpl_count++;
	splx(s);
}

static __inline void
__mp_unlock(struct __mp_lock *lock)
{
	int s = spllock();

#ifdef MP_LOCKDEBUG
	if (lock->mpl_count == 0 || lock->mpl_cpu == LK_NOCPU) {
		db_printf("__mp_unlock(0x%x): releasing not locked lock\n",
		    lock);
		Debugger();
	}
#endif

	if (--lock->mpl_count == 0) {
		lock->mpl_cpu = LK_NOCPU;
		__cpu_simple_unlock(&lock->mpl_lock);
	}
	splx(s);
}

static __inline int
__mp_release_all(struct __mp_lock *lock) {
	int s = spllock();
	int rv = lock->mpl_count;

#ifdef MP_LOCKDEBUG
	if (lock->mpl_count == 0 || lock->mpl_cpu == LK_NOCPU) {
		db_printf(
		    "__mp_release_all(0x%x): releasing not locked lock\n",
		    lock);
		Debugger();
	}
#endif

	lock->mpl_cpu = LK_NOCPU;
	lock->mpl_count = 0;
	__cpu_simple_unlock(&lock->mpl_lock);
	splx(s);
	return (rv);
}

static __inline void
__mp_acquire_count(struct __mp_lock *lock, int count) {
	int s = spllock();

	__cpu_simple_lock(&lock->mpl_lock);
	lock->mpl_cpu = cpu_number();
	lock->mpl_count = count;
	splx(s);
}

static __inline int
__mp_lock_held(struct __mp_lock *lock) {
	return lock->mpl_count;
}

extern struct __mp_lock kernel_lock;

#endif /* !_MPLOCK_H */
@


1.1.2.2
log
@deadproc mgmt is outside biglock, make its lock a real one
@
text
@a165 3
/* XXX Should really be in proc.h but then __mp_lock is not defined. */
extern struct SIMPLELOCK deadproc_slock;

@


