head	1.10;
access;
symbols
	OPENBSD_6_2:1.10.0.2
	OPENBSD_6_2_BASE:1.10
	OPENBSD_6_1:1.7.0.32
	OPENBSD_6_1_BASE:1.7
	OPENBSD_6_0:1.7.0.28
	OPENBSD_6_0_BASE:1.7
	OPENBSD_5_9:1.7.0.24
	OPENBSD_5_9_BASE:1.7
	OPENBSD_5_8:1.7.0.26
	OPENBSD_5_8_BASE:1.7
	OPENBSD_5_7:1.7.0.18
	OPENBSD_5_7_BASE:1.7
	OPENBSD_5_6:1.7.0.22
	OPENBSD_5_6_BASE:1.7
	OPENBSD_5_5:1.7.0.20
	OPENBSD_5_5_BASE:1.7
	OPENBSD_5_4:1.7.0.16
	OPENBSD_5_4_BASE:1.7
	OPENBSD_5_3:1.7.0.14
	OPENBSD_5_3_BASE:1.7
	OPENBSD_5_2:1.7.0.12
	OPENBSD_5_2_BASE:1.7
	OPENBSD_5_1_BASE:1.7
	OPENBSD_5_1:1.7.0.10
	OPENBSD_5_0:1.7.0.8
	OPENBSD_5_0_BASE:1.7
	OPENBSD_4_9:1.7.0.6
	OPENBSD_4_9_BASE:1.7
	OPENBSD_4_8:1.7.0.4
	OPENBSD_4_8_BASE:1.7
	OPENBSD_4_7:1.7.0.2
	OPENBSD_4_7_BASE:1.7
	OPENBSD_4_6:1.6.0.4
	OPENBSD_4_6_BASE:1.6
	OPENBSD_4_5:1.4.0.8
	OPENBSD_4_5_BASE:1.4
	OPENBSD_4_4:1.4.0.6
	OPENBSD_4_4_BASE:1.4
	OPENBSD_4_3:1.4.0.4
	OPENBSD_4_3_BASE:1.4
	OPENBSD_4_2:1.4.0.2
	OPENBSD_4_2_BASE:1.4
	OPENBSD_4_1:1.3.0.8
	OPENBSD_4_1_BASE:1.3
	OPENBSD_4_0:1.3.0.6
	OPENBSD_4_0_BASE:1.3
	OPENBSD_3_9:1.3.0.4
	OPENBSD_3_9_BASE:1.3
	OPENBSD_3_8:1.3.0.2
	OPENBSD_3_8_BASE:1.3
	OPENBSD_3_7:1.2.0.2
	OPENBSD_3_7_BASE:1.2
	OPENBSD_3_6:1.1.0.2
	OPENBSD_3_6_BASE:1.1;
locks; strict;
comment	@ * @;


1.10
date	2017.08.12.16.28.01;	author guenther;	state Exp;
branches;
next	1.9;
commitid	U4ys17UOfWiXGISn;

1.9
date	2017.05.16.13.30.48;	author dlg;	state Exp;
branches;
next	1.8;
commitid	4wIR6Kw7NDbvJbTD;

1.8
date	2017.04.20.13.57.30;	author visa;	state Exp;
branches;
next	1.7;
commitid	RHJVP52IiQkInZzu;

1.7
date	2009.08.13.13.24.55;	author weingart;	state Exp;
branches;
next	1.6;

1.6
date	2009.04.27.21.48.56;	author kettenis;	state Exp;
branches;
next	1.5;

1.5
date	2009.04.25.20.14.43;	author weingart;	state Exp;
branches;
next	1.4;

1.4
date	2007.05.15.15.23.36;	author art;	state Exp;
branches;
next	1.3;

1.3
date	2005.07.18.02.43.27;	author fgsch;	state Exp;
branches;
next	1.2;

1.2
date	2004.10.01.04.08.46;	author jsg;	state Exp;
branches;
next	1.1;

1.1
date	2004.07.20.20.15.13;	author art;	state Exp;
branches;
next	;


desc
@@


1.10
log
@Always provide _mtx_* APIs, the use those to simplify the WITNESS wrappers
elsewhere

ok visa@@ kettenis@@
@
text
@/*	$OpenBSD: mutex.h,v 1.9 2017/05/16 13:30:48 dlg Exp $	*/

/*
 * Copyright (c) 2004 Artur Grabowski <art@@openbsd.org>
 * All rights reserved. 
 *
 * Redistribution and use in source and binary forms, with or without 
 * modification, are permitted provided that the following conditions 
 * are met: 
 *
 * 1. Redistributions of source code must retain the above copyright 
 *    notice, this list of conditions and the following disclaimer. 
 * 2. The name of the author may not be used to endorse or promote products
 *    derived from this software without specific prior written permission. 
 *
 * THIS SOFTWARE IS PROVIDED ``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES,
 * INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY
 * AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL
 * THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
 * EXEMPLARY, OR CONSEQUENTIAL  DAMAGES (INCLUDING, BUT NOT LIMITED TO,
 * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS;
 * OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
 * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR
 * OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF
 * ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. 
 */

#ifndef _SYS_MUTEX_H_
#define _SYS_MUTEX_H_

/*
 * A mutex is:
 *  - owned by a cpu.
 *  - non-recursive.
 *  - spinning.
 *  - not providing mutual exclusion between processes, only cpus.
 *  - providing interrupt blocking when necessary.
 *
 * Different mutexes can be nested, but not interleaved. This is ok:
 * "mtx_enter(foo); mtx_enter(bar); mtx_leave(bar); mtx_leave(foo);"
 * This is _not_ ok:
 * "mtx_enter(foo); mtx_enter(bar); mtx_leave(foo); mtx_leave(bar);"
 */

#include <machine/mutex.h>

#define MTX_LO_FLAGS(flags) \
	((!((flags) & MTX_NOWITNESS) ? LO_WITNESS : 0) | \
	 ((flags) & MTX_DUPOK ? LO_DUPOK : 0) | \
	 LO_INITIALIZED | (LO_CLASS_MUTEX << LO_CLASSSHIFT))

#define __MTX_S(x) #x
#define __MTX_LINE __MTX_S(__LINE__)
#define __MTX_NAME __FILE__ ":" __MTX_S(__LINE__)

#define MTX_LO_INITIALIZER(name, flags) \
	{ .lo_type = &(struct lock_type){ .lt_name = __MTX_NAME }, \
	  .lo_name = (name) != NULL ? (name) : __MTX_NAME, \
	  .lo_flags = MTX_LO_FLAGS(flags) }

#define MTX_NOWITNESS	0x01
#define MTX_DUPOK	0x02

#define MUTEX_INITIALIZER(ipl) \
	MUTEX_INITIALIZER_FLAGS(ipl, NULL, 0)

/*
 * Some architectures need to do magic for the ipl, so they need a macro.
 */
#ifndef _mtx_init
void _mtx_init(struct mutex *, int);
#endif

void	__mtx_enter(struct mutex *);
int	__mtx_enter_try(struct mutex *);
void	__mtx_leave(struct mutex *);

#define mtx_init(m, ipl)	mtx_init_flags(m, ipl, NULL, 0)
#define mtx_enter(m)		_mtx_enter(m LOCK_FILE_LINE)
#define mtx_enter_try(m)	_mtx_enter_try(m LOCK_FILE_LINE)
#define mtx_leave(m)		_mtx_leave(m LOCK_FILE_LINE)

#ifdef WITNESS

void	_mtx_init_flags(struct mutex *, int, const char *, int,
	    struct lock_type *);

void	_mtx_enter(struct mutex *, const char *, int);
int	_mtx_enter_try(struct mutex *, const char *, int);
void	_mtx_leave(struct mutex *, const char *, int);

#define mtx_init_flags(m, ipl, name, flags) do {			\
	static struct lock_type __lock_type = { .lt_name = #m };	\
	_mtx_init_flags(m, ipl, name, flags, &__lock_type);		\
} while (0)

#else /* WITNESS */

#define mtx_init_flags(m, ipl, name, flags) do {			\
	(void)(name); (void)(flags);					\
	_mtx_init(m, ipl);						\
} while (0)

#define _mtx_init_flags(m,i,n,f,t)	_mtx_init(m,i)
#define _mtx_enter(m)			__mtx_enter(m)
#define _mtx_enter_try(m)		__mtx_enter_try(m)
#define _mtx_leave(m)			__mtx_leave(m)

#endif /* WITNESS */

#endif
@


1.9
log
@use _mtx_init instead of __mtx_init inside mtx_init on !WITNESS kernels

_mtx_init uses __MUTEX_IPL to wrap the ipl argument to __mtx_init.
without this, mutexes were initted below the mp floor, which allowed
deadlocks with the kernel lock to occur.

reported by hrvoje popovski and pinpointed by mikeb@@
tweaks from phessler@@
ok mpi@@ visa@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mutex.h,v 1.8 2017/04/20 13:57:30 visa Exp $	*/
d78 5
a96 5
#define mtx_init(m, ipl)	mtx_init_flags(m, ipl, NULL, 0)
#define mtx_enter(m)		_mtx_enter(m, __FILE__, __LINE__)
#define mtx_enter_try(m)	_mtx_enter_try(m, __FILE__, __LINE__)
#define mtx_leave(m)		_mtx_leave(m, __FILE__, __LINE__)

a98 2
#define mtx_init(m, ipl)	_mtx_init(m, ipl)

d104 4
a107 3
#define mtx_enter __mtx_enter
#define mtx_leave __mtx_leave
#define mtx_enter_try __mtx_enter_try
@


1.8
log
@Hook up mutex(9) to witness(4).
@
text
@d1 1
a1 1
/*	$OpenBSD: mutex.h,v 1.7 2009/08/13 13:24:55 weingart Exp $	*/
d99 1
a99 1
#define mtx_init(m, ipl)	__mtx_init(m, ipl)
d103 1
a103 1
	__mtx_init(m, ipl);						\
@


1.7
log
@A new(er) mtx_enter_try().

Ok oga@@, "the time is now" deraadt@@.
@
text
@d1 1
a1 1
/*	$OpenBSD: mutex.h,v 1.6 2009/04/27 21:48:56 kettenis Exp $	*/
d47 20
d70 2
a71 2
#ifndef mtx_init
void mtx_init(struct mutex *, int);
d73 38
a110 3
void mtx_enter(struct mutex *);
void mtx_leave(struct mutex *);
int mtx_enter_try(struct mutex *);
@


1.6
log
@Revert mtx_enter_try.  It didn't compile on hppa, it doesn't compile on
landisk, and the sparc implementation is obviously wrong.  That's where I
stopped looking, so who knows what else was broken.  A simple comparison of
the existing mtx_enter with the new mtx_enter_try would have told anybody.
@
text
@d1 1
a1 1
/*	$OpenBSD: mutex.h,v 1.4 2007/05/15 15:23:36 art Exp $	*/
d55 1
@


1.5
log
@Enter mtx_enter_try.  In part for completeness, things may start
using this soon(ish).  Ok oga@@, sorta yes kettenis@@.
@
text
@a54 1
int mtx_enter_try(struct mutex *);
@


1.4
log
@Remove the MI implementation of mutexes and remove the __HAVE_MUTEX
option. Every architecture implements mutexes now.
@
text
@d1 1
a1 1
/*	$OpenBSD: mutex.h,v 1.3 2005/07/18 02:43:27 fgsch Exp $	*/
d55 1
@


1.3
log
@remove trailing newline in panic(9); ok millert@@ and deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mutex.h,v 1.2 2004/10/01 04:08:46 jsg Exp $	*/
a44 1
#ifdef __HAVE_MUTEX
a45 54
#else

/*
 * Simple non-mp implementation.
 */
struct mutex {
	int mtx_lock;
	int mtx_wantipl;
	int mtx_oldipl;
};

/*
 * Since the alpha IPL levels are so messed up, we have to do magic to get
 * this right.
 */
#define MUTEX_IPL(ipl) MUTEX_##ipl
#define MUTEX_IPL_NONE		0
#define MUTEX_IPL_SOFTSERIAL	1
#define MUTEX_IPL_SOFTCLOCK	2
#define MUTEX_IPL_SOFTNET	3
#define MUTEX_IPL_NET		4
#define MUTEX_IPL_BIO		5
#define MUTEX_IPL_VM		6
#define MUTEX_IPL_TTY		7
#define MUTEX_IPL_SERIAL	8
#define MUTEX_IPL_AUDIO		9
#define MUTEX_IPL_CLOCK		10
#define MUTEX_IPL_STATCLOCK	11
#define MUTEX_IPL_SCHED		12
#define MUTEX_IPL_HIGH		13

void mtx_init1(struct mutex *, int);
#define mtx_init(mtx, ipl) mtx_init1(mtx, MUTEX_##ipl)

#define MUTEX_INITIALIZER(ipl) { 0, MUTEX_##ipl, 0 }

#ifdef DIAGNOSTIC
#define MUTEX_ASSERT_LOCKED(mtx) do {					\
	if ((mtx)->mtx_lock == 0)					\
		panic("mutex %p not held in %s", (mtx), __func__);	\
} while (0)

#define MUTEX_ASSERT_UNLOCKED(mtx) do {					\
	if ((mtx)->mtx_lock != 0)					\
		panic("mutex %p held in %s", (mtx), __func__);		\
} while (0)
#else
#define MUTEX_ASSERT_LOCKED(mtx) do { } while (0)
#define MUTEX_ASSERT_UNLOCKED(mtx) do { } while (0)
#endif

#define MUTEX_OLDIPL(mtx)	(mtx)->mtx_oldipl

#endif
@


1.2
log
@add some missing $, ok djm@@ 'That looks fine to me' millert@@
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d86 1
a86 1
		panic("mutex %p not held in %s\n", (mtx), __func__);	\
d91 1
a91 1
		panic("mutex %p held in %s\n", (mtx), __func__);	\
@


1.1
log
@Introducing mutexes - cpu-owned spinning locks with spl semantics.

This is the MI (slightly inefficient and not MP safe) implementation.

deraadt@@ ok Tested by many. (this and following commits)
@
text
@d1 2
@

