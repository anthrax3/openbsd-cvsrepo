head	1.18;
access;
symbols
	OPENBSD_3_7:1.17.0.4
	OPENBSD_3_7_BASE:1.17
	OPENBSD_3_6:1.17.0.2
	OPENBSD_3_6_BASE:1.17
	SMP_SYNC_A:1.17
	SMP_SYNC_B:1.17
	OPENBSD_3_5:1.14.0.4
	OPENBSD_3_5_BASE:1.14
	OPENBSD_3_4:1.14.0.2
	OPENBSD_3_4_BASE:1.14
	UBC_SYNC_A:1.13
	OPENBSD_3_3:1.12.0.4
	OPENBSD_3_3_BASE:1.12
	OPENBSD_3_2:1.12.0.2
	OPENBSD_3_2_BASE:1.12
	OPENBSD_3_1:1.11.0.2
	OPENBSD_3_1_BASE:1.11
	UBC_SYNC_B:1.12
	UBC:1.10.0.2
	UBC_BASE:1.10
	OPENBSD_3_0:1.9.0.2
	OPENBSD_3_0_BASE:1.9
	OPENBSD_2_9_BASE:1.8
	OPENBSD_2_9:1.8.0.12
	OPENBSD_2_8:1.8.0.10
	OPENBSD_2_8_BASE:1.8
	OPENBSD_2_7:1.8.0.8
	OPENBSD_2_7_BASE:1.8
	SMP:1.8.0.6
	SMP_BASE:1.8
	kame_19991208:1.8
	OPENBSD_2_6:1.8.0.4
	OPENBSD_2_6_BASE:1.8
	OPENBSD_2_5:1.8.0.2
	OPENBSD_2_5_BASE:1.8
	OPENBSD_2_4:1.7.0.4
	OPENBSD_2_4_BASE:1.7
	OPENBSD_2_3:1.7.0.2
	OPENBSD_2_3_BASE:1.7
	OPENBSD_2_2:1.6.0.2
	OPENBSD_2_2_BASE:1.6
	OPENBSD_2_1:1.4.0.2
	OPENBSD_2_1_BASE:1.4
	OPENBSD_2_0:1.2.0.2
	OPENBSD_2_0_BASE:1.2
	netbsd_1_1:1.1.1.1;
locks; strict;
comment	@ * @;


1.18
date	2005.05.26.00.38.50;	author pedro;	state dead;
branches;
next	1.17;

1.17
date	2004.05.14.04.00.34;	author tedu;	state Exp;
branches;
next	1.16;

1.16
date	2004.04.25.19.46.40;	author tedu;	state Exp;
branches;
next	1.15;

1.15
date	2004.04.25.19.00.29;	author tedu;	state Exp;
branches;
next	1.14;

1.14
date	2003.06.02.23.28.11;	author millert;	state Exp;
branches;
next	1.13;

1.13
date	2003.05.12.21.45.35;	author tedu;	state Exp;
branches;
next	1.12;

1.12
date	2002.06.08.18.43.34;	author art;	state Exp;
branches;
next	1.11;

1.11
date	2002.03.14.01.27.08;	author millert;	state Exp;
branches;
next	1.10;

1.10
date	2001.11.06.19.53.20;	author miod;	state Exp;
branches
	1.10.2.1;
next	1.9;

1.9
date	2001.06.27.04.58.44;	author art;	state Exp;
branches;
next	1.8;

1.8
date	99.02.26.03.32.22;	author art;	state Exp;
branches
	1.8.6.1;
next	1.7;

1.7
date	97.11.06.05.58.51;	author csapuntz;	state Exp;
branches;
next	1.6;

1.6
date	97.10.06.21.04.49;	author deraadt;	state Exp;
branches;
next	1.5;

1.5
date	97.10.06.15.19.17;	author csapuntz;	state Exp;
branches;
next	1.4;

1.4
date	97.01.02.12.20.43;	author mickey;	state Exp;
branches;
next	1.3;

1.3
date	96.12.07.13.00.16;	author deraadt;	state Exp;
branches;
next	1.2;

1.2
date	96.02.27.08.09.00;	author niklas;	state Exp;
branches;
next	1.1;

1.1
date	95.10.18.08.53.03;	author deraadt;	state Exp;
branches
	1.1.1.1;
next	;

1.1.1.1
date	95.10.18.08.53.03;	author deraadt;	state Exp;
branches;
next	;

1.8.6.1
date	2001.07.04.10.49.20;	author niklas;	state Exp;
branches;
next	1.8.6.2;

1.8.6.2
date	2001.11.13.23.04.24;	author niklas;	state Exp;
branches;
next	1.8.6.3;

1.8.6.3
date	2002.03.28.15.02.01;	author niklas;	state Exp;
branches;
next	1.8.6.4;

1.8.6.4
date	2003.03.28.00.00.21;	author niklas;	state Exp;
branches;
next	1.8.6.5;

1.8.6.5
date	2003.05.16.00.29.43;	author niklas;	state Exp;
branches;
next	1.8.6.6;

1.8.6.6
date	2003.06.07.11.06.06;	author ho;	state Exp;
branches;
next	1.8.6.7;

1.8.6.7
date	2004.06.05.23.13.06;	author niklas;	state Exp;
branches;
next	;

1.10.2.1
date	2002.06.11.03.30.21;	author art;	state Exp;
branches;
next	1.10.2.2;

1.10.2.2
date	2003.05.19.22.36.12;	author tedu;	state Exp;
branches;
next	;


desc
@@


1.18
log
@bye bye, rest in attic ad infinitum, amen
@
text
@/*	$OpenBSD: union_subr.c,v 1.17 2004/05/14 04:00:34 tedu Exp $ */
/*	$NetBSD: union_subr.c,v 1.41 2001/11/10 13:33:45 lukem Exp $	*/

/*
 * Copyright (c) 1994 Jan-Simon Pendry
 * Copyright (c) 1994
 *	The Regents of the University of California.  All rights reserved.
 *
 * This code is derived from software contributed to Berkeley by
 * Jan-Simon Pendry.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. Neither the name of the University nor the names of its contributors
 *    may be used to endorse or promote products derived from this software
 *    without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE
 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
 *
 *	@@(#)union_subr.c	8.20 (Berkeley) 5/20/95
 */


#include <sys/param.h>
#include <sys/systm.h>
#include <sys/proc.h>
#include <sys/time.h>
#include <sys/kernel.h>
#include <sys/vnode.h>
#include <sys/namei.h>
#include <sys/malloc.h>
#include <sys/pool.h>
#include <sys/file.h>
#include <sys/filedesc.h>
#include <sys/queue.h>
#include <sys/mount.h>
#include <sys/stat.h>

#include <uvm/uvm_extern.h>

#include <miscfs/union/union.h>

#ifdef DIAGNOSTIC
#include <sys/proc.h>
#endif

/* must be power of two, otherwise change UNION_HASH() */
#define NHASH 32

/* unsigned int ... */
#define UNION_HASH(u, l) \
	(((((unsigned long) (u)) + ((unsigned long) l)) >> 8) & (NHASH-1))

static LIST_HEAD(unhead, union_node) unhead[NHASH];
static int unvplock[NHASH];

static int union_list_lock(int);
static void union_list_unlock(int);
void union_updatevp(struct union_node *, struct vnode *, struct vnode *);
static int union_relookup(struct union_mount *, struct vnode *,
	struct vnode **, struct componentname *,
	struct componentname *, const char *, int);
int union_vn_close(struct vnode *, int, struct ucred *, struct proc *);
static void union_dircache_r(struct vnode *, struct vnode ***, int *);
struct vnode *union_dircache(struct vnode *, struct proc *);

/*
 * This variable is used to hold a pointer to a function
 * that is called from vfs_syscalls.c and vfs_syscalls_43.c
 * - by keeping a pointer to the function we enable the real
 * union filesystem code to replace the stub value provided
 * by vfs_syscalls.c and thus vfs_syscalls.c no longer needs
 * to know if UNION is built in, lkm'ed, or not even there.
 */
extern
int (*union_check_p)(struct proc *, struct vnode **,
    struct file *, struct uio, int *);

int union_check(struct proc *, struct vnode **, struct file *,
    struct uio, int *);

int union_check(p, vpp, fp, auio, error)
	struct proc	*p;
	struct vnode	**vpp;
	struct file	*fp;
	struct uio	auio;
	int		*error;
{
	if ((*vpp)->v_op == union_vnodeop_p) {
		struct vnode *lvp;

		lvp = union_dircache(*vpp, p);
		if (lvp != NULLVP) {
			struct vattr va;

			/*
			 * If the directory is opaque,
			 * then don't show lower entries
			 */
			*error = VOP_GETATTR(*vpp, &va, fp->f_cred, p);
			if (va.va_flags & OPAQUE) {
				vput(lvp);
				lvp = NULL;
			}
		}

		if (lvp != NULLVP) {
			*error = VOP_OPEN(lvp, FREAD, fp->f_cred, p);
			VOP_UNLOCK(lvp, 0, p);

			if (*error) {
				vrele(lvp);
				return (0);
			}
			fp->f_data = lvp;
			fp->f_offset = 0;
			*error = vn_close(*vpp, FREAD, fp->f_cred, p);
			if (*error)
				return (0);
			*vpp = lvp;
			return (1);
		}
	}
	return (0);
};

int
union_init(struct vfsconf *vfsp)
{
	int i;

	for (i = 0; i < NHASH; i++)
		LIST_INIT(&unhead[i]);
	union_check_p = union_check;
	return (0);
}

static int
union_list_lock(ix)
	int ix;
{

	if (unvplock[ix] & UN_LOCKED) {
		unvplock[ix] |= UN_WANTED;
		tsleep(&unvplock[ix], PINOD, "unionlk", 0);
		return (1);
	}

	unvplock[ix] |= UN_LOCKED;

	return (0);
}

static void
union_list_unlock(ix)
	int ix;
{

	unvplock[ix] &= ~UN_LOCKED;

	if (unvplock[ix] & UN_WANTED) {
		unvplock[ix] &= ~UN_WANTED;
		wakeup(&unvplock[ix]);
	}
}

void
union_updatevp(un, uppervp, lowervp)
	struct union_node *un;
	struct vnode *uppervp;
	struct vnode *lowervp;
{
	int ohash = UNION_HASH(un->un_uppervp, un->un_lowervp);
	int nhash = UNION_HASH(uppervp, lowervp);
	int docache = (lowervp != NULLVP || uppervp != NULLVP);
	int lhash, uhash;

	/*
	 * Ensure locking is ordered from lower to higher
	 * to avoid deadlocks.
	 */
	if (nhash < ohash) {
		lhash = nhash;
		uhash = ohash;
	} else {
		lhash = ohash;
		uhash = nhash;
	}

	if (lhash != uhash)
		while (union_list_lock(lhash))
			continue;

	while (union_list_lock(uhash))
		continue;

	if (ohash != nhash || !docache) {
		if (un->un_flags & UN_CACHED) {
			un->un_flags &= ~UN_CACHED;
			LIST_REMOVE(un, un_cache);
		}
	}

	if (ohash != nhash)
		union_list_unlock(ohash);

	if (un->un_lowervp != lowervp) {
		if (un->un_lowervp) {
			vrele(un->un_lowervp);
			if (un->un_path) {
				free(un->un_path, M_TEMP);
				un->un_path = 0;
			}
			if (un->un_dirvp) {
				vrele(un->un_dirvp);
				un->un_dirvp = NULLVP;
			}
		}
		un->un_lowervp = lowervp;
		un->un_lowersz = VNOVAL;
	}

	if (un->un_uppervp != uppervp) {
		if (un->un_uppervp)
			vrele(un->un_uppervp);

		un->un_uppervp = uppervp;
		un->un_uppersz = VNOVAL;
	}

	if (docache && (ohash != nhash)) {
		LIST_INSERT_HEAD(&unhead[nhash], un, un_cache);
		un->un_flags |= UN_CACHED;
	}

	union_list_unlock(nhash);
}

void
union_newlower(un, lowervp)
	struct union_node *un;
	struct vnode *lowervp;
{

	union_updatevp(un, un->un_uppervp, lowervp);
}

void
union_newupper(un, uppervp)
	struct union_node *un;
	struct vnode *uppervp;
{

	union_updatevp(un, uppervp, un->un_lowervp);
}

/*
 * Keep track of size changes in the underlying vnodes.
 * If the size changes, then callback to the vm layer
 * giving priority to the upper layer size.
 */
void
union_newsize(vp, uppersz, lowersz)
	struct vnode *vp;
	off_t uppersz, lowersz;
{
	struct union_node *un;
	off_t sz;

	/* only interested in regular files */
	if (vp->v_type != VREG)
		return;

	un = VTOUNION(vp);
	sz = VNOVAL;

	if ((uppersz != VNOVAL) && (un->un_uppersz != uppersz)) {
		un->un_uppersz = uppersz;
		if (sz == VNOVAL)
			sz = un->un_uppersz;
	}

	if ((lowersz != VNOVAL) && (un->un_lowersz != lowersz)) {
		un->un_lowersz = lowersz;
		if (sz == VNOVAL)
			sz = un->un_lowersz;
	}

	if (sz != VNOVAL) {
#ifdef UNION_DIAGNOSTIC
		printf("union: %s size now %qd\n",
		    uppersz != VNOVAL ? "upper" : "lower", sz);
#endif
		uvm_vnp_setsize(vp, sz);
	}
}

/*
 * allocate a union_node/vnode pair.  the vnode is
 * referenced and locked.  the new vnode is returned
 * via (vpp).  (mp) is the mountpoint of the union filesystem,
 * (dvp) is the parent directory where the upper layer object
 * should exist (but doesn't) and (cnp) is the componentname
 * information which is partially copied to allow the upper
 * layer object to be created at a later time.  (uppervp)
 * and (lowervp) reference the upper and lower layer objects
 * being mapped.  either, but not both, can be nil.
 * if supplied, (uppervp) is locked.
 * the reference is either maintained in the new union_node
 * object which is allocated, or they are vrele'd.
 *
 * all union_nodes are maintained on a singly-linked
 * list.  new nodes are only allocated when they cannot
 * be found on this list.  entries on the list are
 * removed when the vfs reclaim entry is called.
 *
 * a single lock is kept for the entire list.  this is
 * needed because the getnewvnode() function can block
 * waiting for a vnode to become free, in which case there
 * may be more than one process trying to get the same
 * vnode.  this lock is only taken if we are going to
 * call getnewvnode, since the kernel itself is single-threaded.
 *
 * if an entry is found on the list, then call vget() to
 * take a reference.  this is done because there may be
 * zero references to it and so it needs to removed from
 * the vnode free list.
 */
int
union_allocvp(vpp, mp, undvp, dvp, cnp, uppervp, lowervp, docache)
	struct vnode **vpp;
	struct mount *mp;
	struct vnode *undvp;		/* parent union vnode */
	struct vnode *dvp;		/* may be null */
	struct componentname *cnp;	/* may be null */
	struct vnode *uppervp;		/* may be null */
	struct vnode *lowervp;		/* may be null */
	int docache;
{
	int error;
	struct union_node *un = NULL;
	struct vnode *xlowervp = NULLVP;
	struct union_mount *um = MOUNTTOUNIONMOUNT(mp);
	int hash = 0;
	int vflag;
	int try;

	if (uppervp == NULLVP && lowervp == NULLVP)
		panic("union: unidentifiable allocation");

	if (uppervp && lowervp && (uppervp->v_type != lowervp->v_type)) {
		xlowervp = lowervp;
		lowervp = NULLVP;
	}

	/* detect the root vnode (and aliases) */
	vflag = VLAYER;
	if ((uppervp == um->um_uppervp) &&
	    ((lowervp == NULLVP) || lowervp == um->um_lowervp)) {
		if (lowervp == NULLVP) {
			lowervp = um->um_lowervp;
			if (lowervp != NULLVP)
				VREF(lowervp);
		}
		vflag = VROOT;
	}

loop:
	if (!docache) {
		un = 0;
	} else for (try = 0; try < 3; try++) {
		switch (try) {
		case 0:
			if (lowervp == NULLVP)
				continue;
			hash = UNION_HASH(uppervp, lowervp);
			break;

		case 1:
			if (uppervp == NULLVP)
				continue;
			hash = UNION_HASH(uppervp, NULLVP);
			break;

		case 2:
			if (lowervp == NULLVP)
				continue;
			hash = UNION_HASH(NULLVP, lowervp);
			break;
		}

		while (union_list_lock(hash))
			continue;

		for (un = unhead[hash].lh_first; un != 0;
					un = un->un_cache.le_next) {
			if ((un->un_lowervp == lowervp ||
			     un->un_lowervp == NULLVP) &&
			    (un->un_uppervp == uppervp ||
			     un->un_uppervp == NULLVP) &&
			    (UNIONTOV(un)->v_mount == mp)) {
				if (vget(UNIONTOV(un), 0, curproc)) {
					union_list_unlock(hash);
					goto loop;
				}
				break;
			}
		}

		union_list_unlock(hash);

		if (un)
			break;
	}

	if (un) {
		/*
		 * Obtain a lock on the union_node.
		 * uppervp is locked, though un->un_uppervp
		 * may not be.  this doesn't break the locking
		 * hierarchy since in the case that un->un_uppervp
		 * is not yet locked it will be vrele'd and replaced
		 * with uppervp.
		 */

		if ((dvp != NULLVP) && (uppervp == dvp)) {
			/*
			 * Access ``.'', so (un) will already
			 * be locked.  Since this process has
			 * the lock on (uppervp) no other
			 * process can hold the lock on (un).
			 */
#ifdef DIAGNOSTIC
			if ((un->un_flags & UN_LOCKED) == 0)
				panic("union: . not locked");
			else if (curproc && un->un_pid != curproc->p_pid &&
			    un->un_pid > -1 && curproc->p_pid > -1)
				panic("union: allocvp not lock owner");
#endif
		} else {
			if (un->un_flags & UN_LOCKED) {
				vrele(UNIONTOV(un));
				un->un_flags |= UN_WANTED;
				tsleep(&un->un_flags, PINOD, "unionalloc", 0);
				goto loop;
			}
			un->un_flags |= UN_LOCKED;

#ifdef DIAGNOSTIC
			if (curproc)
				un->un_pid = curproc->p_pid;
			else
				un->un_pid = -1;
#endif
		}

		/*
		 * At this point, the union_node is locked,
		 * un->un_uppervp may not be locked, and uppervp
		 * is locked or nil.
		 */

		/*
		 * Save information about the upper layer.
		 */
		if (uppervp != un->un_uppervp) {
			union_newupper(un, uppervp);
		} else if (uppervp) {
			vrele(uppervp);
		}

		if (un->un_uppervp) {
			un->un_flags |= UN_ULOCK;
			un->un_flags &= ~UN_KLOCK;
		}

		/*
		 * Save information about the lower layer.
		 * This needs to keep track of pathname
		 * and directory information which union_vn_create
		 * might need.
		 */
		if (lowervp != un->un_lowervp) {
			union_newlower(un, lowervp);
			if (cnp && (lowervp != NULLVP)) {
				un->un_hash = cnp->cn_hash;
				un->un_path = malloc(cnp->cn_namelen+1,
						M_TEMP, M_WAITOK);
				memcpy(un->un_path, cnp->cn_nameptr,
						cnp->cn_namelen);
				un->un_path[cnp->cn_namelen] = '\0';
				VREF(dvp);
				un->un_dirvp = dvp;
			}
		} else if (lowervp) {
			vrele(lowervp);
		}
		*vpp = UNIONTOV(un);
		return (0);
	}

	if (docache) {
		/*
		 * otherwise lock the vp list while we call getnewvnode
		 * since that can block.
		 */
		hash = UNION_HASH(uppervp, lowervp);

		if (union_list_lock(hash))
			goto loop;
	}

	error = getnewvnode(VT_UNION, mp, union_vnodeop_p, vpp);
	if (error) {
		if (uppervp) {
			if (dvp == uppervp)
				vrele(uppervp);
			else
				vput(uppervp);
		}
		if (lowervp)
			vrele(lowervp);

		goto out;
	}

	MALLOC((*vpp)->v_data, void *, sizeof(struct union_node),
		M_TEMP, M_WAITOK);

	(*vpp)->v_flag |= vflag;
	if (uppervp)
		(*vpp)->v_type = uppervp->v_type;
	else
		(*vpp)->v_type = lowervp->v_type;
	un = VTOUNION(*vpp);
	un->un_vnode = *vpp;
	un->un_uppervp = uppervp;
	un->un_uppersz = VNOVAL;
	un->un_lowervp = lowervp;
	un->un_lowersz = VNOVAL;
	un->un_pvp = undvp;
	if (undvp != NULLVP)
		VREF(undvp);
	un->un_dircache = 0;
	un->un_openl = 0;
	un->un_flags = UN_LOCKED;
	if (un->un_uppervp)
		un->un_flags |= UN_ULOCK;
#ifdef DIAGNOSTIC
	if (curproc)
		un->un_pid = curproc->p_pid;
	else
		un->un_pid = -1;
#endif
	if (cnp && (lowervp != NULLVP)) {
		un->un_hash = cnp->cn_hash;
		un->un_path = malloc(cnp->cn_namelen+1, M_TEMP, M_WAITOK);
		memcpy(un->un_path, cnp->cn_nameptr, cnp->cn_namelen);
		un->un_path[cnp->cn_namelen] = '\0';
		VREF(dvp);
		un->un_dirvp = dvp;
	} else {
		un->un_hash = 0;
		un->un_path = 0;
		un->un_dirvp = 0;
	}

	if (docache) {
		LIST_INSERT_HEAD(&unhead[hash], un, un_cache);
		un->un_flags |= UN_CACHED;
	}

	if (xlowervp)
		vrele(xlowervp);

out:
	if (docache)
		union_list_unlock(hash);

	return (error);
}

int
union_freevp(vp)
	struct vnode *vp;
{
	struct union_node *un = VTOUNION(vp);

	if (un->un_flags & UN_CACHED) {
		un->un_flags &= ~UN_CACHED;
		LIST_REMOVE(un, un_cache);
	}

	if (un->un_pvp != NULLVP)
		vrele(un->un_pvp);
	if (un->un_uppervp != NULLVP)
		vrele(un->un_uppervp);
	if (un->un_lowervp != NULLVP)
		vrele(un->un_lowervp);
	if (un->un_dirvp != NULLVP)
		vrele(un->un_dirvp);
	if (un->un_path)
		free(un->un_path, M_TEMP);

	FREE(vp->v_data, M_TEMP);
	vp->v_data = 0;

	return (0);
}

/*
 * copyfile.  copy the vnode (fvp) to the vnode (tvp)
 * using a sequence of reads and writes.  both (fvp)
 * and (tvp) are locked on entry and exit.
 */
int
union_copyfile(fvp, tvp, cred, p)
	struct vnode *fvp;
	struct vnode *tvp;
	struct ucred *cred;
	struct proc *p;
{
	char *buf;
	struct uio uio;
	struct iovec iov;
	int error = 0;

	/*
	 * strategy:
	 * allocate a buffer of size MAXBSIZE.
	 * loop doing reads and writes, keeping track
	 * of the current uio offset.
	 * give up at the first sign of trouble.
	 */

	uio.uio_procp = p;
	uio.uio_segflg = UIO_SYSSPACE;
	uio.uio_offset = 0;

	VOP_UNLOCK(fvp, 0, p);				/* XXX */
	VOP_LEASE(fvp, p, cred, LEASE_READ);
	vn_lock(fvp, LK_EXCLUSIVE | LK_RETRY, p);	/* XXX */
	VOP_UNLOCK(tvp, 0, p);				/* XXX */
	VOP_LEASE(tvp, p, cred, LEASE_WRITE);
	vn_lock(tvp, LK_EXCLUSIVE | LK_RETRY, p);	/* XXX */

	buf = malloc(MAXBSIZE, M_TEMP, M_WAITOK);

	/* ugly loop follows... */
	do {
		off_t offset = uio.uio_offset;

		uio.uio_iov = &iov;
		uio.uio_iovcnt = 1;
		iov.iov_base = buf;
		iov.iov_len = MAXBSIZE;
		uio.uio_resid = iov.iov_len;
		uio.uio_rw = UIO_READ;
		error = VOP_READ(fvp, &uio, 0, cred);

		if (error == 0) {
			uio.uio_iov = &iov;
			uio.uio_iovcnt = 1;
			iov.iov_base = buf;
			iov.iov_len = MAXBSIZE - uio.uio_resid;
			uio.uio_offset = offset;
			uio.uio_rw = UIO_WRITE;
			uio.uio_resid = iov.iov_len;

			if (uio.uio_resid == 0)
				break;

			do {
				error = VOP_WRITE(tvp, &uio, 0, cred);
			} while ((uio.uio_resid > 0) && (error == 0));
		}

	} while (error == 0);

	free(buf, M_TEMP);
	return (error);
}

/*
 * (un) is assumed to be locked on entry and remains
 * locked on exit.
 */
int
union_copyup(un, docopy, cred, p)
	struct union_node *un;
	int docopy;
	struct ucred *cred;
	struct proc *p;
{
	int error;
	struct vnode *lvp, *uvp;
	struct vattr lvattr, uvattr;

	error = union_vn_create(&uvp, un, p);
	if (error)
		return (error);

	/* at this point, uppervp is locked */
	union_newupper(un, uvp);
	un->un_flags |= UN_ULOCK;

	lvp = un->un_lowervp;

	if (docopy) {
		/*
		 * XX - should not ignore errors
		 * from VOP_CLOSE
		 */
		vn_lock(lvp, LK_EXCLUSIVE | LK_RETRY, p);

		error = VOP_GETATTR(lvp, &lvattr, cred, p);
		if (error == 0)
			error = VOP_OPEN(lvp, FREAD, cred, p);
		if (error == 0) {
			error = union_copyfile(lvp, uvp, cred, p);
			(void) VOP_CLOSE(lvp, FREAD, cred, p);
		}
		if (error == 0) {
			/* Copy permissions up too */
			VATTR_NULL(&uvattr);
			uvattr.va_mode = lvattr.va_mode;
			uvattr.va_flags = lvattr.va_flags;
			error = VOP_SETATTR(uvp, &uvattr, cred, p);
		}
		VOP_UNLOCK(lvp, 0, p);
#ifdef UNION_DIAGNOSTIC
		if (error == 0)
			uprintf("union: copied up %s\n", un->un_path);
#endif

	}
	union_vn_close(uvp, FWRITE, cred, p);

	/*
	 * Subsequent IOs will go to the top layer, so
	 * call close on the lower vnode and open on the
	 * upper vnode to ensure that the filesystem keeps
	 * its references counts right.  This doesn't do
	 * the right thing with (cred) and (FREAD) though.
	 * Ignoring error returns is not right, either.
	 */
	if (error == 0) {
		int i;

		vn_lock(lvp, LK_EXCLUSIVE | LK_RETRY, p);
		for (i = 0; i < un->un_openl; i++) {
			(void) VOP_CLOSE(lvp, FREAD, cred, p);
			(void) VOP_OPEN(uvp, FREAD, cred, p);
		}
		un->un_openl = 0;
		VOP_UNLOCK(lvp, 0, p);
	}

	return (error);

}

static int
union_relookup(um, dvp, vpp, cnp, cn, path, pathlen)
	struct union_mount *um;
	struct vnode *dvp;
	struct vnode **vpp;
	struct componentname *cnp;
	struct componentname *cn;
	const char *path;
	int pathlen;
{
	int error;

	/*
	 * A new componentname structure must be faked up because
	 * there is no way to know where the upper level cnp came
	 * from or what it is being used for.  This must duplicate
	 * some of the work done by NDINIT, some of the work done
	 * by namei, some of the work done by lookup and some of
	 * the work done by VOP_LOOKUP when given a CREATE flag.
	 * Conclusion: Horrible.
	 */
	cn->cn_namelen = pathlen;
	if ((cn->cn_namelen + 1) > MAXPATHLEN)
		return (ENAMETOOLONG);
	cn->cn_pnbuf = pool_get(&namei_pool, PR_WAITOK);
	memcpy(cn->cn_pnbuf, path, cn->cn_namelen);
	cn->cn_pnbuf[cn->cn_namelen] = '\0';

	cn->cn_nameiop = CREATE;
	cn->cn_flags = (LOCKPARENT|HASBUF|SAVENAME|SAVESTART|ISLASTCN);
	cn->cn_proc = cnp->cn_proc;
	if (um->um_op == UNMNT_BELOW && cnp->cn_nameiop == LOOKUP)
		cn->cn_cred = um->um_cred;	/* XXX */
	else
		cn->cn_cred = cnp->cn_cred;

	cn->cn_nameptr = cn->cn_pnbuf;
	cn->cn_hash = cnp->cn_hash;
	cn->cn_consume = cnp->cn_consume;

	VREF(dvp);
	error = relookup(dvp, vpp, cn);
	if (!error)
		vrele(dvp);
	else {
		pool_put(&namei_pool, cn->cn_pnbuf);
		cn->cn_pnbuf = 0;
	}

	return (error);
}

/*
 * Create a shadow directory in the upper layer.
 * The new vnode is returned locked.
 *
 * (um) points to the union mount structure for access to the
 * the mounting process's credentials.
 * (dvp) is the directory in which to create the shadow directory.
 * it is unlocked on entry and exit.
 * (cnp) is the componentname to be created.
 * (vpp) is the returned newly created shadow directory, which
 * is returned locked.
 *
 * N.B. We still attempt to create shadow directories even if the union
 * is mounted read-only, which is a little nonintuitive.
 */
int
union_mkshadow(um, dvp, cnp, vpp)
	struct union_mount *um;
	struct vnode *dvp;
	struct componentname *cnp;
	struct vnode **vpp;
{
	int error;
	struct vattr va;
	struct proc *p = cnp->cn_proc;
	struct componentname cn;

	error = union_relookup(um, dvp, vpp, cnp, &cn,
			cnp->cn_nameptr, cnp->cn_namelen);
	if (error)
		return (error);

	if (*vpp) {
		VOP_ABORTOP(dvp, &cn);
		VOP_UNLOCK(dvp, 0, p);
		vrele(*vpp);
		*vpp = NULLVP;
		return (EEXIST);
	}

	/*
	 * policy: when creating the shadow directory in the
	 * upper layer, create it owned by the user who did
	 * the mount, group from parent directory, and mode
	 * 777 modified by umask (ie mostly identical to the
	 * mkdir syscall).  (jsp, kb)
	 */

	VATTR_NULL(&va);
	va.va_type = VDIR;
	va.va_mode = um->um_cmode;

	/* VOP_LEASE: dvp is locked */
	VOP_LEASE(dvp, p, cn.cn_cred, LEASE_WRITE);

	error = VOP_MKDIR(dvp, vpp, &cn, &va);
	return (error);
}

/*
 * Create a whiteout entry in the upper layer.
 *
 * (um) points to the union mount structure for access to the
 * the mounting process's credentials.
 * (dvp) is the directory in which to create the whiteout.
 * it is locked on entry and exit.
 * (cnp) is the componentname to be created.
 */
int
union_mkwhiteout(um, dvp, cnp, path)
	struct union_mount *um;
	struct vnode *dvp;
	struct componentname *cnp;
	char *path;
{
	int error;
	struct proc *p = cnp->cn_proc;
	struct vnode *wvp;
	struct componentname cn;

	VOP_UNLOCK(dvp, 0, p);
	error = union_relookup(um, dvp, &wvp, cnp, &cn, path, strlen(path));
	if (error) {
		vn_lock(dvp, LK_EXCLUSIVE | LK_RETRY, p);
		return (error);
	}

	if (wvp) {
		VOP_ABORTOP(dvp, &cn);
		vrele(dvp);
		vrele(wvp);
		return (EEXIST);
	}

	/* VOP_LEASE: dvp is locked */
	VOP_LEASE(dvp, p, p->p_ucred, LEASE_WRITE);

	error = VOP_WHITEOUT(dvp, &cn, CREATE);
	if (error)
		VOP_ABORTOP(dvp, &cn);

	vrele(dvp);

	return (error);
}

/*
 * union_vn_create: creates and opens a new shadow file
 * on the upper union layer.  this function is similar
 * in spirit to calling vn_open but it avoids calling namei().
 * the problem with calling namei is that a) it locks too many
 * things, and b) it doesn't start at the "right" directory,
 * whereas relookup is told where to start.
 */
int
union_vn_create(vpp, un, p)
	struct vnode **vpp;
	struct union_node *un;
	struct proc *p;
{
	struct vnode *vp;
	struct ucred *cred = p->p_ucred;
	struct vattr vat;
	struct vattr *vap = &vat;
	int fmode = FFLAGS(O_WRONLY|O_CREAT|O_TRUNC|O_EXCL);
	int error;
	int cmode = UN_FILEMODE & ~p->p_fd->fd_cmask;
	struct componentname cn;

	*vpp = NULLVP;

	/*
	 * Build a new componentname structure (for the same
	 * reasons outlines in union_mkshadow).
	 * The difference here is that the file is owned by
	 * the current user, rather than by the person who
	 * did the mount, since the current user needs to be
	 * able to write the file (that's why it is being
	 * copied in the first place).
	 */
	cn.cn_namelen = strlen(un->un_path);
	if ((cn.cn_namelen + 1) > MAXPATHLEN)
		return (ENAMETOOLONG);
	cn.cn_pnbuf = pool_get(&namei_pool, PR_WAITOK);
	memcpy(cn.cn_pnbuf, un->un_path, cn.cn_namelen+1);
	cn.cn_nameiop = CREATE;
	cn.cn_flags = (LOCKPARENT|HASBUF|SAVENAME|SAVESTART|ISLASTCN);
	cn.cn_proc = p;
	cn.cn_cred = p->p_ucred;
	cn.cn_nameptr = cn.cn_pnbuf;
	cn.cn_hash = un->un_hash;
	cn.cn_consume = 0;

	VREF(un->un_dirvp);
	if ((error = relookup(un->un_dirvp, &vp, &cn)) != 0)
		return (error);
	vrele(un->un_dirvp);

	if (vp) {
		VOP_ABORTOP(un->un_dirvp, &cn);
		if (un->un_dirvp == vp)
			vrele(un->un_dirvp);
		else
			vput(un->un_dirvp);
		vrele(vp);
		return (EEXIST);
	}

	/*
	 * Good - there was no race to create the file
	 * so go ahead and create it.  The permissions
	 * on the file will be 0666 modified by the
	 * current user's umask.  Access to the file, while
	 * it is unioned, will require access to the top *and*
	 * bottom files.  Access when not unioned will simply
	 * require access to the top-level file.
	 * TODO: confirm choice of access permissions.
	 */
	VATTR_NULL(vap);
	vap->va_type = VREG;
	vap->va_mode = cmode;
	VOP_LEASE(un->un_dirvp, p, cred, LEASE_WRITE);
	if ((error = VOP_CREATE(un->un_dirvp, &vp, &cn, vap)) != 0)
		return (error);

	if ((error = VOP_OPEN(vp, fmode, cred, p)) != 0) {
		vput(vp);
		return (error);
	}

	vp->v_writecount++;
	*vpp = vp;
	return (0);
}

int
union_vn_close(vp, fmode, cred, p)
	struct vnode *vp;
	int fmode;
	struct ucred *cred;
	struct proc *p;
{

	if (fmode & FWRITE)
		--vp->v_writecount;
	return (VOP_CLOSE(vp, fmode, cred, p));
}

void
union_removed_upper(un)
	struct union_node *un;
{
#if 1
	/*
	 * We do not set the uppervp to NULLVP here, because lowervp
	 * may also be NULLVP, so this routine would end up creating
	 * a bogus union node with no upper or lower VP (that causes
	 * pain in many places that assume at least one VP exists).
	 * Since we've removed this node from the cache hash chains,
	 * it won't be found again.  When all current holders
	 * release it, union_inactive() will vgone() it.
	 */
	union_diruncache(un);
#else
	union_newupper(un, NULLVP);
#endif

	if (un->un_flags & UN_CACHED) {
		un->un_flags &= ~UN_CACHED;
		LIST_REMOVE(un, un_cache);
	}

	if (un->un_flags & UN_ULOCK) {
		un->un_flags &= ~UN_ULOCK;
		VOP_UNLOCK(un->un_uppervp, 0, curproc);
	}
}

#if 0
struct vnode *
union_lowervp(vp)
	struct vnode *vp;
{
	struct union_node *un = VTOUNION(vp);

	if ((un->un_lowervp != NULLVP) &&
	    (vp->v_type == un->un_lowervp->v_type)) {
		if (vget(un->un_lowervp, 0) == 0)
			return (un->un_lowervp);
	}

	return (NULLVP);
}
#endif

/*
 * determine whether a whiteout is needed
 * during a remove/rmdir operation.
 */
int
union_dowhiteout(un, cred, p)
	struct union_node *un;
	struct ucred *cred;
	struct proc *p;
{
	struct vattr va;

	if (un->un_lowervp != NULLVP)
		return (1);

	if (VOP_GETATTR(un->un_uppervp, &va, cred, p) == 0 &&
	    (va.va_flags & OPAQUE))
		return (1);

	return (0);
}

static void
union_dircache_r(vp, vppp, cntp)
	struct vnode *vp;
	struct vnode ***vppp;
	int *cntp;
{
	struct union_node *un;

	if (vp->v_op != union_vnodeop_p) {
		if (vppp) {
			VREF(vp);
			*(*vppp)++ = vp;
			if (--(*cntp) == 0)
				panic("union: dircache table too small");
		} else {
			(*cntp)++;
		}

		return;
	}

	un = VTOUNION(vp);
	if (un->un_uppervp != NULLVP)
		union_dircache_r(un->un_uppervp, vppp, cntp);
	if (un->un_lowervp != NULLVP)
		union_dircache_r(un->un_lowervp, vppp, cntp);
}

struct vnode *
union_dircache(vp, p)
	struct vnode *vp;
	struct proc *p;
{
	int cnt;
	struct vnode *nvp = NULLVP;
	struct vnode **vpp;
	struct vnode **dircache;
	int error;

	vn_lock(vp, LK_EXCLUSIVE | LK_RETRY, p);
	dircache = VTOUNION(vp)->un_dircache;

	nvp = NULLVP;

	if (dircache == 0) {
		cnt = 0;
		union_dircache_r(vp, 0, &cnt);
		cnt++;
		dircache = malloc(cnt * sizeof(struct vnode *),
					M_TEMP, M_WAITOK);
		vpp = dircache;
		union_dircache_r(vp, &vpp, &cnt);
		VTOUNION(vp)->un_dircache = dircache;
		*vpp = NULLVP;
		vpp = dircache + 1;
	} else {
		vpp = dircache;
		do {
			if (*vpp++ == VTOUNION(vp)->un_uppervp)
				break;
		} while (*vpp != NULLVP);
	}

	if (*vpp == NULLVP)
		goto out;

	vn_lock(*vpp, LK_EXCLUSIVE | LK_RETRY, p);
	VREF(*vpp);
	error = union_allocvp(&nvp, vp->v_mount, NULLVP, NULLVP, 0, *vpp, NULLVP, 0);
	if (!error) {
		VTOUNION(vp)->un_dircache = 0;
		VTOUNION(nvp)->un_dircache = dircache;
	}

out:
	VOP_UNLOCK(vp, 0, p);
	return (nvp);
}

void
union_diruncache(un)
	struct union_node *un;
{
	struct vnode **vpp;

	if (un->un_dircache != 0) {
		for (vpp = un->un_dircache; *vpp != NULLVP; vpp++)
			vrele(*vpp);
		free(un->un_dircache, M_TEMP);
		un->un_dircache = 0;
	}
}
@


1.17
log
@use pool for namei pathbuf.  testing ok millert@@ tdeval@@
@
text
@d1 1
a1 1
/*	$OpenBSD: union_subr.c,v 1.16 2004/04/25 19:46:40 tedu Exp $ */
@


1.16
log
@useless casts
@
text
@d1 1
a1 1
/*	$OpenBSD: union_subr.c,v 1.15 2004/04/25 19:00:29 tedu Exp $ */
d48 1
d803 1
a803 1
	cn->cn_pnbuf = malloc(cn->cn_namelen+1, M_NAMEI, M_WAITOK);
d824 1
a824 1
		free(cn->cn_pnbuf, M_NAMEI);
d974 1
a974 1
	cn.cn_pnbuf = malloc(cn.cn_namelen+1, M_NAMEI, M_WAITOK);
@


1.15
log
@only use um_cred for lookups, fixes pr 745.
from pedro martelletto
@
text
@d1 1
a1 1
/*	$OpenBSD: union_subr.c,v 1.14 2003/06/02 23:28:11 millert Exp $ */
d130 1
a130 1
			fp->f_data = (caddr_t) lvp;
d178 1
a178 1
		wakeup((caddr_t) &unvplock[ix]);
d973 1
a973 1
	cn.cn_pnbuf = (caddr_t) malloc(cn.cn_namelen+1, M_NAMEI, M_WAITOK);
d1155 1
a1155 2
		dircache = (struct vnode **)
				malloc(cnt * sizeof(struct vnode *),
@


1.14
log
@Remove the advertising clause in the UCB license which Berkeley
rescinded 22 July 1999.  Proofed by myself and Theo.
@
text
@d1 1
a1 1
/*	$OpenBSD: union_subr.c,v 1.13 2003/05/12 21:45:35 tedu Exp $ */
d809 3
a811 1
	if (um->um_op == UNMNT_ABOVE)
d813 1
a813 2
	else
		cn->cn_cred = um->um_cred;
@


1.13
log
@fix up locking and some issues with union.  derived from netbsd
@
text
@d1 1
a1 1
/*	$OpenBSD$ */
d20 1
a20 5
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *	This product includes software developed by the University of
 *	California, Berkeley and its contributors.
 * 4. Neither the name of the University nor the names of its contributors
@


1.12
log
@Use tsleep instead of sleep.
@
text
@d1 2
a2 2
/*	$OpenBSD: union_subr.c,v 1.11 2002/03/14 01:27:08 millert Exp $	*/
/*	$NetBSD: union_subr.c,v 1.18 1996/02/09 22:41:10 christos Exp $	*/
d40 1
a40 1
 *	@@(#)union_subr.c	8.16 (Berkeley) 12/10/94
d43 1
d57 3
a59 1
#include <uvm/uvm_extern.h>		/* for vnode_pager_setsize */
d80 2
a81 2
			       struct vnode **, struct componentname *,
			       struct componentname *, char *, int);
d88 1
a88 1
 * that is called from vfs_syscalls.c and vfs_syscalls_43.c 
d95 2
a96 2
int (*union_check_p)(struct proc *, struct vnode **, 
			   struct file *, struct uio, int *);
d99 1
a99 1
		 struct uio, int *);
d147 1
a147 2
union_init(vfsp)
	struct vfsconf *vfsp;
a152 1
	bzero((caddr_t) unvplock, sizeof(unvplock));
d164 1
a164 1
		tsleep((caddr_t) &unvplock[ix], PINOD, "unlstlk", 0);
d195 1
d201 10
a210 2
	if (nhash < ohash)
		while (union_list_lock(nhash))
d212 2
a213 1
	while (union_list_lock(ohash))
a214 3
	if (nhash > ohash)
		while (union_list_lock(nhash))
			continue;
d310 2
a311 2
		printf("union: %s size now %ld\n",
			uppersz != VNOVAL ? "upper" : "lower", (long) sz);
d376 1
a376 1
	vflag = 0;
d421 1
a421 2
				if (vget(UNIONTOV(un), 0,
				    cnp ? cnp->cn_proc : NULL)) {
d456 1
a456 1
				    un->un_pid > -1 && curproc->p_pid > -1)
d463 1
a463 1
				tsleep((caddr_t)un, PINOD, "unallvp", 0);
d508 1
a508 1
				bcopy(cnp->cn_nameptr, un->un_path,
d525 1
a525 1
		 */ 
d577 1
a577 1
		bcopy(cnp->cn_nameptr, un->un_path, cnp->cn_namelen);
d661 1
a661 1
	vn_lock(fvp, LK_EXCLUSIVE | LK_RETRY, p);
d664 1
a664 1
	vn_lock(tvp, LK_EXCLUSIVE | LK_RETRY, p);
d716 1
d734 4
a737 1
		error = VOP_OPEN(lvp, FREAD, cred, p);
a739 1
			VOP_UNLOCK(lvp, 0, p);
d742 8
a755 2
	un->un_flags &= ~UN_ULOCK;
	VOP_UNLOCK(uvp, 0, p);
a756 2
	vn_lock(uvp, LK_EXCLUSIVE | LK_RETRY, p);
	 un->un_flags |= UN_ULOCK;
d758 160
a917 155
	 /*
	  * Subsequent IOs will go to the top layer, so
	  * call close on the lower vnode and open on the
	  * upper vnode to ensure that the filesystem keeps
	  * its references counts right.  This doesn't do
	  * the right thing with (cred) and (FREAD) though.
	  * Ignoring error returns is not right, either.
	  */
	 if (error == 0) {
		 int i;

		 for (i = 0; i < un->un_openl; i++) {
			 (void) VOP_CLOSE(lvp, FREAD, cred, p);
			 (void) VOP_OPEN(uvp, FREAD, cred, p);
		 }
		 un->un_openl = 0;
	 }

	 return (error);

 }

 static int
 union_relookup(um, dvp, vpp, cnp, cn, path, pathlen)
	 struct union_mount *um;
	 struct vnode *dvp;
	 struct vnode **vpp;
	 struct componentname *cnp;
	 struct componentname *cn;
	 char *path;
	 int pathlen;
 {
	 int error;

	 /*
	  * A new componentname structure must be faked up because
	  * there is no way to know where the upper level cnp came
	  * from or what it is being used for.  This must duplicate
	  * some of the work done by NDINIT, some of the work done
	  * by namei, some of the work done by lookup and some of
	  * the work done by VOP_LOOKUP when given a CREATE flag.
	  * Conclusion: Horrible.
	  *
	  * The pathname buffer will be FREEed by VOP_MKDIR.
	  */
	 cn->cn_namelen = pathlen;
	 cn->cn_pnbuf = malloc(cn->cn_namelen+1, M_NAMEI, M_WAITOK);
	 bcopy(path, cn->cn_pnbuf, cn->cn_namelen);
	 cn->cn_pnbuf[cn->cn_namelen] = '\0';

	 cn->cn_nameiop = CREATE;
	 cn->cn_flags = (LOCKPARENT|HASBUF|SAVENAME|SAVESTART|ISLASTCN);
	 cn->cn_proc = cnp->cn_proc;
	 if (um->um_op == UNMNT_ABOVE)
		 cn->cn_cred = cnp->cn_cred;
	 else
		 cn->cn_cred = um->um_cred;
	 cn->cn_nameptr = cn->cn_pnbuf;
	 cn->cn_hash = cnp->cn_hash;
	 cn->cn_consume = cnp->cn_consume;

	 VREF(dvp);
	 error = relookup(dvp, vpp, cn);
	 if (!error)
		 vrele(dvp);
	 else {
		 free(cn->cn_pnbuf, M_NAMEI);
		 cn->cn_pnbuf = 0;
	 }

	 return (error);
 }

 /*
  * Create a shadow directory in the upper layer.
  * The new vnode is returned locked.
  *
  * (um) points to the union mount structure for access to the
  * the mounting process's credentials.
  * (dvp) is the directory in which to create the shadow directory.
  * it is unlocked on entry and exit.
  * (cnp) is the componentname to be created.
  * (vpp) is the returned newly created shadow directory, which
  * is returned locked.
  */
 int
 union_mkshadow(um, dvp, cnp, vpp)
	 struct union_mount *um;
	 struct vnode *dvp;
	 struct componentname *cnp;
	 struct vnode **vpp;
 {
	 int error;
	 struct vattr va;
	 struct proc *p = cnp->cn_proc;
	 struct componentname cn;

	 error = union_relookup(um, dvp, vpp, cnp, &cn,
			 cnp->cn_nameptr, cnp->cn_namelen);
	 if (error)
		 return (error);

	 if (*vpp) {
		 VOP_ABORTOP(dvp, &cn);
		 VOP_UNLOCK(dvp, 0, p);
		 vrele(*vpp);
		 *vpp = NULLVP;
		 return (EEXIST);
	 }

	 /*
	  * policy: when creating the shadow directory in the
	  * upper layer, create it owned by the user who did
	  * the mount, group from parent directory, and mode
	  * 777 modified by umask (ie mostly identical to the
	  * mkdir syscall).  (jsp, kb)
	  */

	 VATTR_NULL(&va);
	 va.va_type = VDIR;
	 va.va_mode = um->um_cmode;

	 /* VOP_LEASE: dvp is locked */
	 VOP_LEASE(dvp, p, cn.cn_cred, LEASE_WRITE);

	 error = VOP_MKDIR(dvp, vpp, &cn, &va);
	 return (error);
 }

 /*
  * Create a whiteout entry in the upper layer.
  *
  * (um) points to the union mount structure for access to the
  * the mounting process's credentials.
  * (dvp) is the directory in which to create the whiteout.
  * it is locked on entry and exit.
  * (cnp) is the componentname to be created.
  */
 int
 union_mkwhiteout(um, dvp, cnp, path)
	 struct union_mount *um;
	 struct vnode *dvp;
	 struct componentname *cnp;
	 char *path;
 {
	 int error;
	 struct proc *p = cnp->cn_proc;
	 struct vnode *wvp;
	 struct componentname cn;

	 VOP_UNLOCK(dvp, 0, p);
	 error = union_relookup(um, dvp, &wvp, cnp, &cn, path, strlen(path));
	 if (error) {
		 vn_lock(dvp, LK_EXCLUSIVE | LK_RETRY, p);
		 return (error);
d974 2
d977 1
a977 1
	bcopy(un->un_path, cn.cn_pnbuf, cn.cn_namelen+1);
d1045 1
a1045 2
	struct proc *p = curproc;

d1056 3
d1067 1
a1067 1
		VOP_UNLOCK(un->un_uppervp, 0, p);
d1151 3
@


1.11
log
@First round of __P removal in sys
@
text
@d1 1
a1 1
/*	$OpenBSD: union_subr.c,v 1.10 2001/11/06 19:53:20 miod Exp $	*/
d163 1
a163 1
		sleep((caddr_t) &unvplock[ix], PINOD);
d456 1
a456 1
				sleep((caddr_t)un, PINOD);
@


1.10
log
@Replace inclusion of <vm/foo.h> with the correct <uvm/bar.h> when necessary.
(Look ma, I might have broken the tree)
@
text
@d1 1
a1 1
/*	$OpenBSD: union_subr.c,v 1.9 2001/06/27 04:58:44 art Exp $	*/
d73 4
a76 4
static int union_list_lock __P((int));
static void union_list_unlock __P((int));
void union_updatevp __P((struct union_node *, struct vnode *, struct vnode *));
static int union_relookup __P((struct union_mount *, struct vnode *,
d78 4
a81 4
			       struct componentname *, char *, int));
int union_vn_close __P((struct vnode *, int, struct ucred *, struct proc *));
static void union_dircache_r __P((struct vnode *, struct vnode ***, int *));
struct vnode *union_dircache __P((struct vnode *, struct proc *));
d92 2
a93 2
int (*union_check_p) __P((struct proc *, struct vnode **, 
			   struct file *, struct uio, int *));
@


1.10.2.1
log
@Sync UBC branch to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: union_subr.c,v 1.10 2001/11/06 19:53:20 miod Exp $	*/
d73 4
a76 4
static int union_list_lock(int);
static void union_list_unlock(int);
void union_updatevp(struct union_node *, struct vnode *, struct vnode *);
static int union_relookup(struct union_mount *, struct vnode *,
d78 4
a81 4
			       struct componentname *, char *, int);
int union_vn_close(struct vnode *, int, struct ucred *, struct proc *);
static void union_dircache_r(struct vnode *, struct vnode ***, int *);
struct vnode *union_dircache(struct vnode *, struct proc *);
d92 2
a93 2
int (*union_check_p)(struct proc *, struct vnode **, 
			   struct file *, struct uio, int *);
d163 1
a163 1
		tsleep((caddr_t) &unvplock[ix], PINOD, "unlstlk", 0);
d456 1
a456 1
				tsleep((caddr_t)un, PINOD, "unallvp", 0);
@


1.10.2.2
log
@sync
@
text
@d1 2
a2 2
/*	$OpenBSD$ */
/*	$NetBSD: union_subr.c,v 1.41 2001/11/10 13:33:45 lukem Exp $	*/
d40 1
a40 1
 *	@@(#)union_subr.c	8.20 (Berkeley) 5/20/95
a42 1

d56 1
a56 3

#include <uvm/uvm_extern.h>

d77 2
a78 2
	struct vnode **, struct componentname *,
	struct componentname *, const char *, int);
d85 1
a85 1
 * that is called from vfs_syscalls.c and vfs_syscalls_43.c
d92 2
a93 2
int (*union_check_p)(struct proc *, struct vnode **,
    struct file *, struct uio, int *);
d96 1
a96 1
    struct uio, int *);
d144 2
a145 1
union_init(struct vfsconf *vfsp)
d151 1
d163 1
a163 1
		tsleep(&unvplock[ix], PINOD, "unionlk", 0);
a193 1
	int lhash, uhash;
d199 2
a200 10
	if (nhash < ohash) {
		lhash = nhash;
		uhash = ohash;
	} else {
		lhash = ohash;
		uhash = nhash;
	}

	if (lhash != uhash)
		while (union_list_lock(lhash))
d202 1
a202 2

	while (union_list_lock(uhash))
d204 3
d302 2
a303 2
		printf("union: %s size now %qd\n",
		    uppersz != VNOVAL ? "upper" : "lower", sz);
d368 1
a368 1
	vflag = VLAYER;
d413 2
a414 1
				if (vget(UNIONTOV(un), 0, curproc)) {
d449 1
a449 1
			    un->un_pid > -1 && curproc->p_pid > -1)
d456 1
a456 1
				tsleep(&un->un_flags, PINOD, "unionalloc", 0);
d501 1
a501 1
				memcpy(un->un_path, cnp->cn_nameptr,
d518 1
a518 1
		 */
d570 1
a570 1
		memcpy(un->un_path, cnp->cn_nameptr, cnp->cn_namelen);
d654 1
a654 1
	vn_lock(fvp, LK_EXCLUSIVE | LK_RETRY, p);	/* XXX */
d657 1
a657 1
	vn_lock(tvp, LK_EXCLUSIVE | LK_RETRY, p);	/* XXX */
a708 1
	struct vattr lvattr, uvattr;
d726 1
a726 4

		error = VOP_GETATTR(lvp, &lvattr, cred, p);
		if (error == 0)
			error = VOP_OPEN(lvp, FREAD, cred, p);
d729 1
a731 8
		if (error == 0) {
			/* Copy permissions up too */
			VATTR_NULL(&uvattr);
			uvattr.va_mode = lvattr.va_mode;
			uvattr.va_flags = lvattr.va_flags;
			error = VOP_SETATTR(uvp, &uvattr, cred, p);
		}
		VOP_UNLOCK(lvp, 0, p);
d738 2
d741 2
d744 155
a898 160
	/*
	 * Subsequent IOs will go to the top layer, so
	 * call close on the lower vnode and open on the
	 * upper vnode to ensure that the filesystem keeps
	 * its references counts right.  This doesn't do
	 * the right thing with (cred) and (FREAD) though.
	 * Ignoring error returns is not right, either.
	 */
	if (error == 0) {
		int i;

		vn_lock(lvp, LK_EXCLUSIVE | LK_RETRY, p);
		for (i = 0; i < un->un_openl; i++) {
			(void) VOP_CLOSE(lvp, FREAD, cred, p);
			(void) VOP_OPEN(uvp, FREAD, cred, p);
		}
		un->un_openl = 0;
		VOP_UNLOCK(lvp, 0, p);
	}

	return (error);

}

static int
union_relookup(um, dvp, vpp, cnp, cn, path, pathlen)
	struct union_mount *um;
	struct vnode *dvp;
	struct vnode **vpp;
	struct componentname *cnp;
	struct componentname *cn;
	const char *path;
	int pathlen;
{
	int error;

	/*
	 * A new componentname structure must be faked up because
	 * there is no way to know where the upper level cnp came
	 * from or what it is being used for.  This must duplicate
	 * some of the work done by NDINIT, some of the work done
	 * by namei, some of the work done by lookup and some of
	 * the work done by VOP_LOOKUP when given a CREATE flag.
	 * Conclusion: Horrible.
	 */
	cn->cn_namelen = pathlen;
	if ((cn->cn_namelen + 1) > MAXPATHLEN)
		return (ENAMETOOLONG);
	cn->cn_pnbuf = malloc(cn->cn_namelen+1, M_NAMEI, M_WAITOK);
	memcpy(cn->cn_pnbuf, path, cn->cn_namelen);
	cn->cn_pnbuf[cn->cn_namelen] = '\0';

	cn->cn_nameiop = CREATE;
	cn->cn_flags = (LOCKPARENT|HASBUF|SAVENAME|SAVESTART|ISLASTCN);
	cn->cn_proc = cnp->cn_proc;
	if (um->um_op == UNMNT_ABOVE)
		cn->cn_cred = cnp->cn_cred;
	else
		cn->cn_cred = um->um_cred;
	cn->cn_nameptr = cn->cn_pnbuf;
	cn->cn_hash = cnp->cn_hash;
	cn->cn_consume = cnp->cn_consume;

	VREF(dvp);
	error = relookup(dvp, vpp, cn);
	if (!error)
		vrele(dvp);
	else {
		free(cn->cn_pnbuf, M_NAMEI);
		cn->cn_pnbuf = 0;
	}

	return (error);
}

/*
 * Create a shadow directory in the upper layer.
 * The new vnode is returned locked.
 *
 * (um) points to the union mount structure for access to the
 * the mounting process's credentials.
 * (dvp) is the directory in which to create the shadow directory.
 * it is unlocked on entry and exit.
 * (cnp) is the componentname to be created.
 * (vpp) is the returned newly created shadow directory, which
 * is returned locked.
 *
 * N.B. We still attempt to create shadow directories even if the union
 * is mounted read-only, which is a little nonintuitive.
 */
int
union_mkshadow(um, dvp, cnp, vpp)
	struct union_mount *um;
	struct vnode *dvp;
	struct componentname *cnp;
	struct vnode **vpp;
{
	int error;
	struct vattr va;
	struct proc *p = cnp->cn_proc;
	struct componentname cn;

	error = union_relookup(um, dvp, vpp, cnp, &cn,
			cnp->cn_nameptr, cnp->cn_namelen);
	if (error)
		return (error);

	if (*vpp) {
		VOP_ABORTOP(dvp, &cn);
		VOP_UNLOCK(dvp, 0, p);
		vrele(*vpp);
		*vpp = NULLVP;
		return (EEXIST);
	}

	/*
	 * policy: when creating the shadow directory in the
	 * upper layer, create it owned by the user who did
	 * the mount, group from parent directory, and mode
	 * 777 modified by umask (ie mostly identical to the
	 * mkdir syscall).  (jsp, kb)
	 */

	VATTR_NULL(&va);
	va.va_type = VDIR;
	va.va_mode = um->um_cmode;

	/* VOP_LEASE: dvp is locked */
	VOP_LEASE(dvp, p, cn.cn_cred, LEASE_WRITE);

	error = VOP_MKDIR(dvp, vpp, &cn, &va);
	return (error);
}

/*
 * Create a whiteout entry in the upper layer.
 *
 * (um) points to the union mount structure for access to the
 * the mounting process's credentials.
 * (dvp) is the directory in which to create the whiteout.
 * it is locked on entry and exit.
 * (cnp) is the componentname to be created.
 */
int
union_mkwhiteout(um, dvp, cnp, path)
	struct union_mount *um;
	struct vnode *dvp;
	struct componentname *cnp;
	char *path;
{
	int error;
	struct proc *p = cnp->cn_proc;
	struct vnode *wvp;
	struct componentname cn;

	VOP_UNLOCK(dvp, 0, p);
	error = union_relookup(um, dvp, &wvp, cnp, &cn, path, strlen(path));
	if (error) {
		vn_lock(dvp, LK_EXCLUSIVE | LK_RETRY, p);
		return (error);
a954 2
	if ((cn.cn_namelen + 1) > MAXPATHLEN)
		return (ENAMETOOLONG);
d956 1
a956 1
	memcpy(cn.cn_pnbuf, un->un_path, cn.cn_namelen+1);
d1024 2
a1025 1
#if 1
a1035 3
#else
	union_newupper(un, NULLVP);
#endif
d1044 1
a1044 1
		VOP_UNLOCK(un->un_uppervp, 0, curproc);
a1127 3

	nvp = NULLVP;

@


1.9
log
@Remove old vm.
@
text
@d1 1
a1 1
/*	$OpenBSD: union_subr.c,v 1.8 1999/02/26 03:32:22 art Exp $	*/
d56 1
a56 1
#include <vm/vm.h>		/* for vnode_pager_setsize */
@


1.8
log
@compat with uvm vnode pager
@
text
@d1 1
a1 1
/*	$OpenBSD: union_subr.c,v 1.7 1997/11/06 05:58:51 csapuntz Exp $	*/
a304 1
#if defined(UVM)
a305 3
#else
		vnode_pager_setsize(vp, sz);
#endif
@


1.8.6.1
log
@Merge in -current from two days ago in the SMP branch.
As usual with merges, they do not indicate progress, so do not hold
your breath for working SMP, and do not mail me and ask about the
state of it.  It has not changed.  There is work ongoing, but very, very
slowly.  The commit is done in parts as to not lock up the tree in too
big chunks at a time.
@
text
@d1 1
a1 1
/*	$OpenBSD: union_subr.c,v 1.8 1999/02/26 03:32:22 art Exp $	*/
d305 1
d307 3
@


1.8.6.2
log
@merge in -current
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d56 1
a56 1
#include <uvm/uvm_extern.h>		/* for vnode_pager_setsize */
@


1.8.6.3
log
@Merge in -current from roughly a week ago
@
text
@d73 4
a76 4
static int union_list_lock(int);
static void union_list_unlock(int);
void union_updatevp(struct union_node *, struct vnode *, struct vnode *);
static int union_relookup(struct union_mount *, struct vnode *,
d78 4
a81 4
			       struct componentname *, char *, int);
int union_vn_close(struct vnode *, int, struct ucred *, struct proc *);
static void union_dircache_r(struct vnode *, struct vnode ***, int *);
struct vnode *union_dircache(struct vnode *, struct proc *);
d92 2
a93 2
int (*union_check_p)(struct proc *, struct vnode **, 
			   struct file *, struct uio, int *);
@


1.8.6.4
log
@Sync the SMP branch with 3.3
@
text
@d163 1
a163 1
		tsleep((caddr_t) &unvplock[ix], PINOD, "unlstlk", 0);
d456 1
a456 1
				tsleep((caddr_t)un, PINOD, "unallvp", 0);
@


1.8.6.5
log
@merge the trunk so we will get the genfs and locking fixes
@
text
@d1 2
a2 2
/*	$OpenBSD$ */
/*	$NetBSD: union_subr.c,v 1.41 2001/11/10 13:33:45 lukem Exp $	*/
d40 1
a40 1
 *	@@(#)union_subr.c	8.20 (Berkeley) 5/20/95
a42 1

d56 1
a56 3

#include <uvm/uvm_extern.h>

d77 2
a78 2
	struct vnode **, struct componentname *,
	struct componentname *, const char *, int);
d85 1
a85 1
 * that is called from vfs_syscalls.c and vfs_syscalls_43.c
d92 2
a93 2
int (*union_check_p)(struct proc *, struct vnode **,
    struct file *, struct uio, int *);
d96 1
a96 1
    struct uio, int *);
d144 2
a145 1
union_init(struct vfsconf *vfsp)
d151 1
d163 1
a163 1
		tsleep(&unvplock[ix], PINOD, "unionlk", 0);
a193 1
	int lhash, uhash;
d199 2
a200 10
	if (nhash < ohash) {
		lhash = nhash;
		uhash = ohash;
	} else {
		lhash = ohash;
		uhash = nhash;
	}

	if (lhash != uhash)
		while (union_list_lock(lhash))
d202 1
a202 2

	while (union_list_lock(uhash))
d204 3
d302 2
a303 2
		printf("union: %s size now %qd\n",
		    uppersz != VNOVAL ? "upper" : "lower", sz);
d368 1
a368 1
	vflag = VLAYER;
d413 2
a414 1
				if (vget(UNIONTOV(un), 0, curproc)) {
d449 1
a449 1
			    un->un_pid > -1 && curproc->p_pid > -1)
d456 1
a456 1
				tsleep(&un->un_flags, PINOD, "unionalloc", 0);
d501 1
a501 1
				memcpy(un->un_path, cnp->cn_nameptr,
d518 1
a518 1
		 */
d570 1
a570 1
		memcpy(un->un_path, cnp->cn_nameptr, cnp->cn_namelen);
d654 1
a654 1
	vn_lock(fvp, LK_EXCLUSIVE | LK_RETRY, p);	/* XXX */
d657 1
a657 1
	vn_lock(tvp, LK_EXCLUSIVE | LK_RETRY, p);	/* XXX */
a708 1
	struct vattr lvattr, uvattr;
d726 1
a726 4

		error = VOP_GETATTR(lvp, &lvattr, cred, p);
		if (error == 0)
			error = VOP_OPEN(lvp, FREAD, cred, p);
d729 1
a731 8
		if (error == 0) {
			/* Copy permissions up too */
			VATTR_NULL(&uvattr);
			uvattr.va_mode = lvattr.va_mode;
			uvattr.va_flags = lvattr.va_flags;
			error = VOP_SETATTR(uvp, &uvattr, cred, p);
		}
		VOP_UNLOCK(lvp, 0, p);
d738 2
d741 2
d744 155
a898 160
	/*
	 * Subsequent IOs will go to the top layer, so
	 * call close on the lower vnode and open on the
	 * upper vnode to ensure that the filesystem keeps
	 * its references counts right.  This doesn't do
	 * the right thing with (cred) and (FREAD) though.
	 * Ignoring error returns is not right, either.
	 */
	if (error == 0) {
		int i;

		vn_lock(lvp, LK_EXCLUSIVE | LK_RETRY, p);
		for (i = 0; i < un->un_openl; i++) {
			(void) VOP_CLOSE(lvp, FREAD, cred, p);
			(void) VOP_OPEN(uvp, FREAD, cred, p);
		}
		un->un_openl = 0;
		VOP_UNLOCK(lvp, 0, p);
	}

	return (error);

}

static int
union_relookup(um, dvp, vpp, cnp, cn, path, pathlen)
	struct union_mount *um;
	struct vnode *dvp;
	struct vnode **vpp;
	struct componentname *cnp;
	struct componentname *cn;
	const char *path;
	int pathlen;
{
	int error;

	/*
	 * A new componentname structure must be faked up because
	 * there is no way to know where the upper level cnp came
	 * from or what it is being used for.  This must duplicate
	 * some of the work done by NDINIT, some of the work done
	 * by namei, some of the work done by lookup and some of
	 * the work done by VOP_LOOKUP when given a CREATE flag.
	 * Conclusion: Horrible.
	 */
	cn->cn_namelen = pathlen;
	if ((cn->cn_namelen + 1) > MAXPATHLEN)
		return (ENAMETOOLONG);
	cn->cn_pnbuf = malloc(cn->cn_namelen+1, M_NAMEI, M_WAITOK);
	memcpy(cn->cn_pnbuf, path, cn->cn_namelen);
	cn->cn_pnbuf[cn->cn_namelen] = '\0';

	cn->cn_nameiop = CREATE;
	cn->cn_flags = (LOCKPARENT|HASBUF|SAVENAME|SAVESTART|ISLASTCN);
	cn->cn_proc = cnp->cn_proc;
	if (um->um_op == UNMNT_ABOVE)
		cn->cn_cred = cnp->cn_cred;
	else
		cn->cn_cred = um->um_cred;
	cn->cn_nameptr = cn->cn_pnbuf;
	cn->cn_hash = cnp->cn_hash;
	cn->cn_consume = cnp->cn_consume;

	VREF(dvp);
	error = relookup(dvp, vpp, cn);
	if (!error)
		vrele(dvp);
	else {
		free(cn->cn_pnbuf, M_NAMEI);
		cn->cn_pnbuf = 0;
	}

	return (error);
}

/*
 * Create a shadow directory in the upper layer.
 * The new vnode is returned locked.
 *
 * (um) points to the union mount structure for access to the
 * the mounting process's credentials.
 * (dvp) is the directory in which to create the shadow directory.
 * it is unlocked on entry and exit.
 * (cnp) is the componentname to be created.
 * (vpp) is the returned newly created shadow directory, which
 * is returned locked.
 *
 * N.B. We still attempt to create shadow directories even if the union
 * is mounted read-only, which is a little nonintuitive.
 */
int
union_mkshadow(um, dvp, cnp, vpp)
	struct union_mount *um;
	struct vnode *dvp;
	struct componentname *cnp;
	struct vnode **vpp;
{
	int error;
	struct vattr va;
	struct proc *p = cnp->cn_proc;
	struct componentname cn;

	error = union_relookup(um, dvp, vpp, cnp, &cn,
			cnp->cn_nameptr, cnp->cn_namelen);
	if (error)
		return (error);

	if (*vpp) {
		VOP_ABORTOP(dvp, &cn);
		VOP_UNLOCK(dvp, 0, p);
		vrele(*vpp);
		*vpp = NULLVP;
		return (EEXIST);
	}

	/*
	 * policy: when creating the shadow directory in the
	 * upper layer, create it owned by the user who did
	 * the mount, group from parent directory, and mode
	 * 777 modified by umask (ie mostly identical to the
	 * mkdir syscall).  (jsp, kb)
	 */

	VATTR_NULL(&va);
	va.va_type = VDIR;
	va.va_mode = um->um_cmode;

	/* VOP_LEASE: dvp is locked */
	VOP_LEASE(dvp, p, cn.cn_cred, LEASE_WRITE);

	error = VOP_MKDIR(dvp, vpp, &cn, &va);
	return (error);
}

/*
 * Create a whiteout entry in the upper layer.
 *
 * (um) points to the union mount structure for access to the
 * the mounting process's credentials.
 * (dvp) is the directory in which to create the whiteout.
 * it is locked on entry and exit.
 * (cnp) is the componentname to be created.
 */
int
union_mkwhiteout(um, dvp, cnp, path)
	struct union_mount *um;
	struct vnode *dvp;
	struct componentname *cnp;
	char *path;
{
	int error;
	struct proc *p = cnp->cn_proc;
	struct vnode *wvp;
	struct componentname cn;

	VOP_UNLOCK(dvp, 0, p);
	error = union_relookup(um, dvp, &wvp, cnp, &cn, path, strlen(path));
	if (error) {
		vn_lock(dvp, LK_EXCLUSIVE | LK_RETRY, p);
		return (error);
a954 2
	if ((cn.cn_namelen + 1) > MAXPATHLEN)
		return (ENAMETOOLONG);
d956 1
a956 1
	memcpy(cn.cn_pnbuf, un->un_path, cn.cn_namelen+1);
d1024 2
a1025 1
#if 1
a1035 3
#else
	union_newupper(un, NULLVP);
#endif
d1044 1
a1044 1
		VOP_UNLOCK(un->un_uppervp, 0, curproc);
a1127 3

	nvp = NULLVP;

@


1.8.6.6
log
@Sync SMP branch to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: union_subr.c,v 1.8.6.5 2003/05/16 00:29:43 niklas Exp $ */
d20 5
a24 1
 * 3. Neither the name of the University nor the names of its contributors
@


1.8.6.7
log
@Merge with the trunk
@
text
@d1 1
a1 1
/*	$OpenBSD$ */
a47 1
#include <sys/pool.h>
d130 1
a130 1
			fp->f_data = lvp;
d178 1
a178 1
		wakeup(&unvplock[ix]);
d802 1
a802 1
	cn->cn_pnbuf = pool_get(&namei_pool, PR_WAITOK);
d809 2
a810 2
	if (um->um_op == UNMNT_BELOW && cnp->cn_nameiop == LOOKUP)
		cn->cn_cred = um->um_cred;	/* XXX */
d812 1
a812 2
		cn->cn_cred = cnp->cn_cred;

d822 1
a822 1
		pool_put(&namei_pool, cn->cn_pnbuf);
d972 1
a972 1
	cn.cn_pnbuf = pool_get(&namei_pool, PR_WAITOK);
d1154 2
a1155 1
		dircache = malloc(cnt * sizeof(struct vnode *),
@


1.7
log
@Updates for VFS Lite 2 + soft update.
@
text
@d1 1
a1 1
/*	$OpenBSD: union_subr.c,v 1.6 1997/10/06 21:04:49 deraadt Exp $	*/
d305 3
d309 1
@


1.6
log
@back out vfs lite2 till after 2.2
@
text
@d1 1
a1 1
/*	$OpenBSD: union_subr.c,v 1.4 1997/01/02 12:20:43 mickey Exp $	*/
d81 1
a81 1
struct vnode *union_dircache __P((struct vnode *));
d108 1
a108 1
		lvp = union_dircache(*vpp);
d125 1
a125 1
			VOP_UNLOCK(lvp);
d143 3
a145 2
void
union_init()
d153 1
d413 2
a414 1
				if (vget(UNIONTOV(un), 0)) {
d652 1
a652 1
	VOP_UNLOCK(fvp);				/* XXX */
d654 2
a655 2
	VOP_LOCK(fvp);					/* XXX */
	VOP_UNLOCK(tvp);				/* XXX */
d657 1
a657 1
	VOP_LOCK(tvp);					/* XXX */
d725 1
a725 1
		VOP_LOCK(lvp);
d729 1
a729 1
			VOP_UNLOCK(lvp);
d739 1
a739 1
	VOP_UNLOCK(uvp);
d741 2
a742 124
	VOP_LOCK(uvp);
	un->un_flags |= UN_ULOCK;

	/*
	 * Subsequent IOs will go to the top layer, so
	 * call close on the lower vnode and open on the
	 * upper vnode to ensure that the filesystem keeps
	 * its references counts right.  This doesn't do
	 * the right thing with (cred) and (FREAD) though.
	 * Ignoring error returns is not right, either.
	 */
	if (error == 0) {
		int i;

		for (i = 0; i < un->un_openl; i++) {
			(void) VOP_CLOSE(lvp, FREAD, cred, p);
			(void) VOP_OPEN(uvp, FREAD, cred, p);
		}
		un->un_openl = 0;
	}

	return (error);

}

static int
union_relookup(um, dvp, vpp, cnp, cn, path, pathlen)
	struct union_mount *um;
	struct vnode *dvp;
	struct vnode **vpp;
	struct componentname *cnp;
	struct componentname *cn;
	char *path;
	int pathlen;
{
	int error;

	/*
	 * A new componentname structure must be faked up because
	 * there is no way to know where the upper level cnp came
	 * from or what it is being used for.  This must duplicate
	 * some of the work done by NDINIT, some of the work done
	 * by namei, some of the work done by lookup and some of
	 * the work done by VOP_LOOKUP when given a CREATE flag.
	 * Conclusion: Horrible.
	 *
	 * The pathname buffer will be FREEed by VOP_MKDIR.
	 */
	cn->cn_namelen = pathlen;
	cn->cn_pnbuf = malloc(cn->cn_namelen+1, M_NAMEI, M_WAITOK);
	bcopy(path, cn->cn_pnbuf, cn->cn_namelen);
	cn->cn_pnbuf[cn->cn_namelen] = '\0';

	cn->cn_nameiop = CREATE;
	cn->cn_flags = (LOCKPARENT|HASBUF|SAVENAME|SAVESTART|ISLASTCN);
	cn->cn_proc = cnp->cn_proc;
	if (um->um_op == UNMNT_ABOVE)
		cn->cn_cred = cnp->cn_cred;
	else
		cn->cn_cred = um->um_cred;
	cn->cn_nameptr = cn->cn_pnbuf;
	cn->cn_hash = cnp->cn_hash;
	cn->cn_consume = cnp->cn_consume;

	VREF(dvp);
	error = relookup(dvp, vpp, cn);
	if (!error)
		vrele(dvp);
	else {
		free(cn->cn_pnbuf, M_NAMEI);
		cn->cn_pnbuf = 0;
	}

	return (error);
}

/*
 * Create a shadow directory in the upper layer.
 * The new vnode is returned locked.
 *
 * (um) points to the union mount structure for access to the
 * the mounting process's credentials.
 * (dvp) is the directory in which to create the shadow directory.
 * it is unlocked on entry and exit.
 * (cnp) is the componentname to be created.
 * (vpp) is the returned newly created shadow directory, which
 * is returned locked.
 */
int
union_mkshadow(um, dvp, cnp, vpp)
	struct union_mount *um;
	struct vnode *dvp;
	struct componentname *cnp;
	struct vnode **vpp;
{
	int error;
	struct vattr va;
	struct proc *p = cnp->cn_proc;
	struct componentname cn;

	error = union_relookup(um, dvp, vpp, cnp, &cn,
			cnp->cn_nameptr, cnp->cn_namelen);
	if (error)
		return (error);

	if (*vpp) {
		VOP_ABORTOP(dvp, &cn);
		VOP_UNLOCK(dvp);
		vrele(*vpp);
		*vpp = NULLVP;
		return (EEXIST);
	}

	/*
	 * policy: when creating the shadow directory in the
	 * upper layer, create it owned by the user who did
	 * the mount, group from parent directory, and mode
	 * 777 modified by umask (ie mostly identical to the
	 * mkdir syscall).  (jsp, kb)
	 */

	VATTR_NULL(&va);
	va.va_type = VDIR;
	va.va_mode = um->um_cmode;
d744 155
a898 33
	/* VOP_LEASE: dvp is locked */
	VOP_LEASE(dvp, p, cn.cn_cred, LEASE_WRITE);

	error = VOP_MKDIR(dvp, vpp, &cn, &va);
	return (error);
}

/*
 * Create a whiteout entry in the upper layer.
 *
 * (um) points to the union mount structure for access to the
 * the mounting process's credentials.
 * (dvp) is the directory in which to create the whiteout.
 * it is locked on entry and exit.
 * (cnp) is the componentname to be created.
 */
int
union_mkwhiteout(um, dvp, cnp, path)
	struct union_mount *um;
	struct vnode *dvp;
	struct componentname *cnp;
	char *path;
{
	int error;
	struct proc *p = cnp->cn_proc;
	struct vnode *wvp;
	struct componentname cn;

	VOP_UNLOCK(dvp);
	error = union_relookup(um, dvp, &wvp, cnp, &cn, path, strlen(path));
	if (error) {
		VOP_LOCK(dvp);
		return (error);
d1024 1
d1044 1
a1044 1
		VOP_UNLOCK(un->un_uppervp);
d1116 1
a1116 1
union_dircache(vp)
d1118 1
d1126 1
a1126 2
	VOP_LOCK(vp);

d1151 1
a1151 1
	VOP_LOCK(*vpp);
d1160 1
a1160 1
	VOP_UNLOCK(vp);
@


1.5
log
@VFS Lite2 Changes
@
text
@d81 1
a81 1
struct vnode *union_dircache __P((struct vnode *, struct proc *));
d108 1
a108 1
		lvp = union_dircache(*vpp, p);
d125 1
a125 1
			VOP_UNLOCK(lvp, 0, p);
d143 2
a144 3
int
union_init(vfsp)
	struct vfsconf *vfsp;
a151 1
	return (0);
d411 1
a411 2
				if (vget(UNIONTOV(un), 0,
				    cnp ? cnp->cn_proc : NULL)) {
d649 1
a649 1
	VOP_UNLOCK(fvp, 0, p);				/* XXX */
d651 2
a652 2
	vn_lock(fvp, LK_EXCLUSIVE | LK_RETRY, p);
	VOP_UNLOCK(tvp, 0, p);				/* XXX */
d654 1
a654 1
	vn_lock(tvp, LK_EXCLUSIVE | LK_RETRY, p);
d722 1
a722 1
		vn_lock(lvp, LK_EXCLUSIVE | LK_RETRY, p);
d726 1
a726 1
			VOP_UNLOCK(lvp, 0, p);
d736 1
a736 1
	VOP_UNLOCK(uvp, 0, p);
d738 124
a861 2
	vn_lock(uvp, LK_EXCLUSIVE | LK_RETRY, p);
	 un->un_flags |= UN_ULOCK;
d863 33
a895 155
	 /*
	  * Subsequent IOs will go to the top layer, so
	  * call close on the lower vnode and open on the
	  * upper vnode to ensure that the filesystem keeps
	  * its references counts right.  This doesn't do
	  * the right thing with (cred) and (FREAD) though.
	  * Ignoring error returns is not right, either.
	  */
	 if (error == 0) {
		 int i;

		 for (i = 0; i < un->un_openl; i++) {
			 (void) VOP_CLOSE(lvp, FREAD, cred, p);
			 (void) VOP_OPEN(uvp, FREAD, cred, p);
		 }
		 un->un_openl = 0;
	 }

	 return (error);

 }

 static int
 union_relookup(um, dvp, vpp, cnp, cn, path, pathlen)
	 struct union_mount *um;
	 struct vnode *dvp;
	 struct vnode **vpp;
	 struct componentname *cnp;
	 struct componentname *cn;
	 char *path;
	 int pathlen;
 {
	 int error;

	 /*
	  * A new componentname structure must be faked up because
	  * there is no way to know where the upper level cnp came
	  * from or what it is being used for.  This must duplicate
	  * some of the work done by NDINIT, some of the work done
	  * by namei, some of the work done by lookup and some of
	  * the work done by VOP_LOOKUP when given a CREATE flag.
	  * Conclusion: Horrible.
	  *
	  * The pathname buffer will be FREEed by VOP_MKDIR.
	  */
	 cn->cn_namelen = pathlen;
	 cn->cn_pnbuf = malloc(cn->cn_namelen+1, M_NAMEI, M_WAITOK);
	 bcopy(path, cn->cn_pnbuf, cn->cn_namelen);
	 cn->cn_pnbuf[cn->cn_namelen] = '\0';

	 cn->cn_nameiop = CREATE;
	 cn->cn_flags = (LOCKPARENT|HASBUF|SAVENAME|SAVESTART|ISLASTCN);
	 cn->cn_proc = cnp->cn_proc;
	 if (um->um_op == UNMNT_ABOVE)
		 cn->cn_cred = cnp->cn_cred;
	 else
		 cn->cn_cred = um->um_cred;
	 cn->cn_nameptr = cn->cn_pnbuf;
	 cn->cn_hash = cnp->cn_hash;
	 cn->cn_consume = cnp->cn_consume;

	 VREF(dvp);
	 error = relookup(dvp, vpp, cn);
	 if (!error)
		 vrele(dvp);
	 else {
		 free(cn->cn_pnbuf, M_NAMEI);
		 cn->cn_pnbuf = 0;
	 }

	 return (error);
 }

 /*
  * Create a shadow directory in the upper layer.
  * The new vnode is returned locked.
  *
  * (um) points to the union mount structure for access to the
  * the mounting process's credentials.
  * (dvp) is the directory in which to create the shadow directory.
  * it is unlocked on entry and exit.
  * (cnp) is the componentname to be created.
  * (vpp) is the returned newly created shadow directory, which
  * is returned locked.
  */
 int
 union_mkshadow(um, dvp, cnp, vpp)
	 struct union_mount *um;
	 struct vnode *dvp;
	 struct componentname *cnp;
	 struct vnode **vpp;
 {
	 int error;
	 struct vattr va;
	 struct proc *p = cnp->cn_proc;
	 struct componentname cn;

	 error = union_relookup(um, dvp, vpp, cnp, &cn,
			 cnp->cn_nameptr, cnp->cn_namelen);
	 if (error)
		 return (error);

	 if (*vpp) {
		 VOP_ABORTOP(dvp, &cn);
		 VOP_UNLOCK(dvp, 0, p);
		 vrele(*vpp);
		 *vpp = NULLVP;
		 return (EEXIST);
	 }

	 /*
	  * policy: when creating the shadow directory in the
	  * upper layer, create it owned by the user who did
	  * the mount, group from parent directory, and mode
	  * 777 modified by umask (ie mostly identical to the
	  * mkdir syscall).  (jsp, kb)
	  */

	 VATTR_NULL(&va);
	 va.va_type = VDIR;
	 va.va_mode = um->um_cmode;

	 /* VOP_LEASE: dvp is locked */
	 VOP_LEASE(dvp, p, cn.cn_cred, LEASE_WRITE);

	 error = VOP_MKDIR(dvp, vpp, &cn, &va);
	 return (error);
 }

 /*
  * Create a whiteout entry in the upper layer.
  *
  * (um) points to the union mount structure for access to the
  * the mounting process's credentials.
  * (dvp) is the directory in which to create the whiteout.
  * it is locked on entry and exit.
  * (cnp) is the componentname to be created.
  */
 int
 union_mkwhiteout(um, dvp, cnp, path)
	 struct union_mount *um;
	 struct vnode *dvp;
	 struct componentname *cnp;
	 char *path;
 {
	 int error;
	 struct proc *p = cnp->cn_proc;
	 struct vnode *wvp;
	 struct componentname cn;

	 VOP_UNLOCK(dvp, 0, p);
	 error = union_relookup(um, dvp, &wvp, cnp, &cn, path, strlen(path));
	 if (error) {
		 vn_lock(dvp, LK_EXCLUSIVE | LK_RETRY, p);
		 return (error);
a1020 1
	struct proc *p = curproc;
d1040 1
a1040 1
		VOP_UNLOCK(un->un_uppervp, 0, p);
d1112 1
a1112 1
union_dircache(vp, p)
a1113 1
	struct proc *p;
d1121 2
a1122 1
	vn_lock(vp, LK_EXCLUSIVE | LK_RETRY, p);
d1147 1
a1147 1
	vn_lock(*vpp, LK_EXCLUSIVE | LK_RETRY, p);
d1156 1
a1156 1
	VOP_UNLOCK(vp, 0, p);
@


1.4
log
@pulled out the duplicated, conditional code from both kern/vfs_syscalls.c
and compat/common/vfs_syscalls_43.c and placed a single copy of that code
into miscfs/union/union_subr.c (seemed like a good place to put it, since
it's union-fs related).
as a side effect you can build unionfs in lkm.
(netbsd pr#2950, Paul Goyette <paul@@pgoyette.bdt.com>)
@
text
@d1 1
a1 1
/*	$OpenBSD: union_subr.c,v 1.3 1996/12/07 13:00:16 deraadt Exp $	*/
d81 1
a81 1
struct vnode *union_dircache __P((struct vnode *));
d108 1
a108 1
		lvp = union_dircache(*vpp);
d125 1
a125 1
			VOP_UNLOCK(lvp);
d143 3
a145 2
void
union_init()
d153 1
d413 2
a414 1
				if (vget(UNIONTOV(un), 0)) {
d652 1
a652 1
	VOP_UNLOCK(fvp);				/* XXX */
d654 2
a655 2
	VOP_LOCK(fvp);					/* XXX */
	VOP_UNLOCK(tvp);				/* XXX */
d657 1
a657 1
	VOP_LOCK(tvp);					/* XXX */
d725 1
a725 1
		VOP_LOCK(lvp);
d729 1
a729 1
			VOP_UNLOCK(lvp);
d739 1
a739 1
	VOP_UNLOCK(uvp);
d741 2
a742 124
	VOP_LOCK(uvp);
	un->un_flags |= UN_ULOCK;

	/*
	 * Subsequent IOs will go to the top layer, so
	 * call close on the lower vnode and open on the
	 * upper vnode to ensure that the filesystem keeps
	 * its references counts right.  This doesn't do
	 * the right thing with (cred) and (FREAD) though.
	 * Ignoring error returns is not right, either.
	 */
	if (error == 0) {
		int i;

		for (i = 0; i < un->un_openl; i++) {
			(void) VOP_CLOSE(lvp, FREAD, cred, p);
			(void) VOP_OPEN(uvp, FREAD, cred, p);
		}
		un->un_openl = 0;
	}

	return (error);

}

static int
union_relookup(um, dvp, vpp, cnp, cn, path, pathlen)
	struct union_mount *um;
	struct vnode *dvp;
	struct vnode **vpp;
	struct componentname *cnp;
	struct componentname *cn;
	char *path;
	int pathlen;
{
	int error;

	/*
	 * A new componentname structure must be faked up because
	 * there is no way to know where the upper level cnp came
	 * from or what it is being used for.  This must duplicate
	 * some of the work done by NDINIT, some of the work done
	 * by namei, some of the work done by lookup and some of
	 * the work done by VOP_LOOKUP when given a CREATE flag.
	 * Conclusion: Horrible.
	 *
	 * The pathname buffer will be FREEed by VOP_MKDIR.
	 */
	cn->cn_namelen = pathlen;
	cn->cn_pnbuf = malloc(cn->cn_namelen+1, M_NAMEI, M_WAITOK);
	bcopy(path, cn->cn_pnbuf, cn->cn_namelen);
	cn->cn_pnbuf[cn->cn_namelen] = '\0';

	cn->cn_nameiop = CREATE;
	cn->cn_flags = (LOCKPARENT|HASBUF|SAVENAME|SAVESTART|ISLASTCN);
	cn->cn_proc = cnp->cn_proc;
	if (um->um_op == UNMNT_ABOVE)
		cn->cn_cred = cnp->cn_cred;
	else
		cn->cn_cred = um->um_cred;
	cn->cn_nameptr = cn->cn_pnbuf;
	cn->cn_hash = cnp->cn_hash;
	cn->cn_consume = cnp->cn_consume;

	VREF(dvp);
	error = relookup(dvp, vpp, cn);
	if (!error)
		vrele(dvp);
	else {
		free(cn->cn_pnbuf, M_NAMEI);
		cn->cn_pnbuf = 0;
	}

	return (error);
}

/*
 * Create a shadow directory in the upper layer.
 * The new vnode is returned locked.
 *
 * (um) points to the union mount structure for access to the
 * the mounting process's credentials.
 * (dvp) is the directory in which to create the shadow directory.
 * it is unlocked on entry and exit.
 * (cnp) is the componentname to be created.
 * (vpp) is the returned newly created shadow directory, which
 * is returned locked.
 */
int
union_mkshadow(um, dvp, cnp, vpp)
	struct union_mount *um;
	struct vnode *dvp;
	struct componentname *cnp;
	struct vnode **vpp;
{
	int error;
	struct vattr va;
	struct proc *p = cnp->cn_proc;
	struct componentname cn;

	error = union_relookup(um, dvp, vpp, cnp, &cn,
			cnp->cn_nameptr, cnp->cn_namelen);
	if (error)
		return (error);

	if (*vpp) {
		VOP_ABORTOP(dvp, &cn);
		VOP_UNLOCK(dvp);
		vrele(*vpp);
		*vpp = NULLVP;
		return (EEXIST);
	}

	/*
	 * policy: when creating the shadow directory in the
	 * upper layer, create it owned by the user who did
	 * the mount, group from parent directory, and mode
	 * 777 modified by umask (ie mostly identical to the
	 * mkdir syscall).  (jsp, kb)
	 */

	VATTR_NULL(&va);
	va.va_type = VDIR;
	va.va_mode = um->um_cmode;
d744 155
a898 33
	/* VOP_LEASE: dvp is locked */
	VOP_LEASE(dvp, p, cn.cn_cred, LEASE_WRITE);

	error = VOP_MKDIR(dvp, vpp, &cn, &va);
	return (error);
}

/*
 * Create a whiteout entry in the upper layer.
 *
 * (um) points to the union mount structure for access to the
 * the mounting process's credentials.
 * (dvp) is the directory in which to create the whiteout.
 * it is locked on entry and exit.
 * (cnp) is the componentname to be created.
 */
int
union_mkwhiteout(um, dvp, cnp, path)
	struct union_mount *um;
	struct vnode *dvp;
	struct componentname *cnp;
	char *path;
{
	int error;
	struct proc *p = cnp->cn_proc;
	struct vnode *wvp;
	struct componentname cn;

	VOP_UNLOCK(dvp);
	error = union_relookup(um, dvp, &wvp, cnp, &cn, path, strlen(path));
	if (error) {
		VOP_LOCK(dvp);
		return (error);
d1024 1
d1044 1
a1044 1
		VOP_UNLOCK(un->un_uppervp);
d1116 1
a1116 1
union_dircache(vp)
d1118 1
d1126 1
a1126 2
	VOP_LOCK(vp);

d1151 1
a1151 1
	VOP_LOCK(*vpp);
d1160 1
a1160 1
	VOP_UNLOCK(vp);
@


1.3
log
@mem leak, short malloc; netbsd pr#3000, minoura@@kw.netlaputa.or.jp
@
text
@d1 1
a1 1
/*	$OpenBSD: union_subr.c,v 1.2 1996/02/27 08:09:00 niklas Exp $	*/
d83 60
d151 1
@


1.2
log
@From NetBSD: update to 960217 sources
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d745 4
d891 1
a891 1
	cn.cn_pnbuf = (caddr_t) malloc(cn.cn_namelen, M_NAMEI, M_WAITOK);
@


1.1
log
@Initial revision
@
text
@d1 2
a2 1
/*	$NetBSD: union_subr.c,v 1.17 1995/10/05 06:26:12 mycroft Exp $	*/
d73 11
a83 1
int
d289 1
a289 2
	struct union_node *un;
	struct union_node **pp;
d292 1
a292 1
	int hash;
a821 1
	struct vattr va;
a872 1
	char *cp;
d898 1
a898 1
	if (error = relookup(un->un_dirvp, &vp, &cn))
d926 1
a926 1
	if (error = VOP_CREATE(un->un_dirvp, &vp, &cn, vap))
d929 1
a929 1
	if (error = VOP_OPEN(vp, fmode, cred, p)) {
@


1.1.1.1
log
@initial import of NetBSD tree
@
text
@@
