head	1.54;
access;
symbols
	OPENBSD_6_0:1.49.0.4
	OPENBSD_6_0_BASE:1.49
	OPENBSD_5_9:1.48.0.6
	OPENBSD_5_9_BASE:1.48
	OPENBSD_5_8:1.48.0.8
	OPENBSD_5_8_BASE:1.48
	OPENBSD_5_7:1.48.0.2
	OPENBSD_5_7_BASE:1.48
	OPENBSD_5_6:1.48.0.4
	OPENBSD_5_6_BASE:1.48
	OPENBSD_5_5:1.47.0.4
	OPENBSD_5_5_BASE:1.47
	OPENBSD_5_4:1.46.0.10
	OPENBSD_5_4_BASE:1.46
	OPENBSD_5_3:1.46.0.8
	OPENBSD_5_3_BASE:1.46
	OPENBSD_5_2:1.46.0.6
	OPENBSD_5_2_BASE:1.46
	OPENBSD_5_1_BASE:1.46
	OPENBSD_5_1:1.46.0.4
	OPENBSD_5_0:1.46.0.2
	OPENBSD_5_0_BASE:1.46
	OPENBSD_4_9:1.45.0.4
	OPENBSD_4_9_BASE:1.45
	OPENBSD_4_8:1.45.0.2
	OPENBSD_4_8_BASE:1.45
	OPENBSD_4_7:1.44.0.2
	OPENBSD_4_7_BASE:1.44
	OPENBSD_4_6:1.43.0.4
	OPENBSD_4_6_BASE:1.43
	OPENBSD_4_5:1.42.0.6
	OPENBSD_4_5_BASE:1.42
	OPENBSD_4_4:1.42.0.4
	OPENBSD_4_4_BASE:1.42
	OPENBSD_4_3:1.42.0.2
	OPENBSD_4_3_BASE:1.42
	OPENBSD_4_2:1.39.0.2
	OPENBSD_4_2_BASE:1.39
	OPENBSD_4_1:1.38.0.6
	OPENBSD_4_1_BASE:1.38
	OPENBSD_4_0:1.38.0.4
	OPENBSD_4_0_BASE:1.38
	OPENBSD_3_9:1.38.0.2
	OPENBSD_3_9_BASE:1.38
	OPENBSD_3_8:1.37.0.2
	OPENBSD_3_8_BASE:1.37
	OPENBSD_3_7:1.36.0.2
	OPENBSD_3_7_BASE:1.36
	OPENBSD_3_6:1.34.0.4
	OPENBSD_3_6_BASE:1.34
	SMP_SYNC_A:1.34
	SMP_SYNC_B:1.34
	OPENBSD_3_5:1.34.0.2
	OPENBSD_3_5_BASE:1.34
	OPENBSD_3_4:1.33.0.2
	OPENBSD_3_4_BASE:1.33
	UBC_SYNC_A:1.32
	OPENBSD_3_3:1.32.0.2
	OPENBSD_3_3_BASE:1.32
	OPENBSD_3_2:1.30.0.2
	OPENBSD_3_2_BASE:1.30
	OPENBSD_3_1:1.28.0.2
	OPENBSD_3_1_BASE:1.28
	UBC_SYNC_B:1.30
	UBC:1.22.0.4
	UBC_BASE:1.22
	OPENBSD_3_0:1.22.0.2
	OPENBSD_3_0_BASE:1.22
	OPENBSD_2_9_BASE:1.20
	OPENBSD_2_9:1.20.0.2
	OPENBSD_2_8:1.17.0.2
	OPENBSD_2_8_BASE:1.17
	OPENBSD_2_7:1.16.0.4
	OPENBSD_2_7_BASE:1.16
	SMP:1.16.0.2
	SMP_BASE:1.16
	kame_19991208:1.15
	OPENBSD_2_6:1.14.0.2
	OPENBSD_2_6_BASE:1.14
	OPENBSD_2_5:1.11.0.2
	OPENBSD_2_5_BASE:1.11
	OPENBSD_2_4:1.8.0.6
	OPENBSD_2_4_BASE:1.8
	OPENBSD_2_3:1.8.0.4
	OPENBSD_2_3_BASE:1.8
	OPENBSD_2_2:1.8.0.2
	OPENBSD_2_2_BASE:1.8
	OPENBSD_2_1:1.7.0.2
	OPENBSD_2_1_BASE:1.7
	OPENBSD_2_0:1.6.0.2
	OPENBSD_2_0_BASE:1.6
	netbsd_1_1:1.1.1.1;
locks; strict;
comment	@ * @;


1.54
date	2017.02.09.15.19.32;	author jca;	state Exp;
branches;
next	1.53;
commitid	Hew5AYIxyEp5lNbI;

1.53
date	2016.12.19.08.36.49;	author mpi;	state Exp;
branches;
next	1.52;
commitid	QqHqT2WhCBWqYgGJ;

1.52
date	2016.11.28.11.12.45;	author mpi;	state Exp;
branches;
next	1.51;
commitid	pr5LCKF5IZsR2oy7;

1.51
date	2016.11.07.09.08.06;	author mpi;	state Exp;
branches;
next	1.50;
commitid	A6se4kFGvoRfJVfQ;

1.50
date	2016.09.24.14.51.37;	author naddy;	state Exp;
branches;
next	1.49;
commitid	B9MFucENkVbjvRxm;

1.49
date	2016.03.07.18.44.00;	author naddy;	state Exp;
branches;
next	1.48;
commitid	Z6e4eqr6FuYFPnlL;

1.48
date	2014.07.22.11.06.10;	author mpi;	state Exp;
branches;
next	1.47;
commitid	DQakU8LLWV6Iwx84;

1.47
date	2013.08.08.14.29.29;	author mpi;	state Exp;
branches;
next	1.46;

1.46
date	2011.07.06.23.44.20;	author sthen;	state Exp;
branches;
next	1.45;

1.45
date	2010.07.03.04.44.51;	author guenther;	state Exp;
branches;
next	1.44;

1.44
date	2009.11.13.20.54.05;	author claudio;	state Exp;
branches;
next	1.43;

1.43
date	2009.06.05.00.05.22;	author claudio;	state Exp;
branches;
next	1.42;

1.42
date	2008.02.20.11.24.03;	author markus;	state Exp;
branches;
next	1.41;

1.41
date	2007.11.27.17.23.23;	author deraadt;	state Exp;
branches;
next	1.40;

1.40
date	2007.09.01.18.49.28;	author henning;	state Exp;
branches;
next	1.39;

1.39
date	2007.06.15.18.23.07;	author markus;	state Exp;
branches
	1.39.2.1;
next	1.38;

1.38
date	2005.11.15.21.09.46;	author miod;	state Exp;
branches
	1.38.6.1;
next	1.37;

1.37
date	2005.06.30.08.51.31;	author markus;	state Exp;
branches;
next	1.36;

1.36
date	2004.12.13.12.01.49;	author espie;	state Exp;
branches;
next	1.35;

1.35
date	2004.11.25.15.32.08;	author markus;	state Exp;
branches;
next	1.34;

1.34
date	2003.12.10.07.22.43;	author itojun;	state Exp;
branches;
next	1.33;

1.33
date	2003.06.02.23.28.14;	author millert;	state Exp;
branches;
next	1.32;

1.32
date	2003.02.21.20.52.06;	author tedu;	state Exp;
branches;
next	1.31;

1.31
date	2002.11.06.01.52.08;	author kjc;	state Exp;
branches;
next	1.30;

1.30
date	2002.06.09.16.26.11;	author itojun;	state Exp;
branches
	1.30.2.1;
next	1.29;

1.29
date	2002.05.16.14.10.51;	author kjc;	state Exp;
branches;
next	1.28;

1.28
date	2002.03.08.03.49.58;	author provos;	state Exp;
branches;
next	1.27;

1.27
date	2002.03.01.22.29.29;	author provos;	state Exp;
branches;
next	1.26;

1.26
date	2002.01.15.19.18.01;	author provos;	state Exp;
branches;
next	1.25;

1.25
date	2002.01.14.20.13.45;	author provos;	state Exp;
branches;
next	1.24;

1.24
date	2002.01.14.03.11.55;	author provos;	state Exp;
branches;
next	1.23;

1.23
date	2002.01.02.20.35.40;	author deraadt;	state Exp;
branches;
next	1.22;

1.22
date	2001.06.08.03.53.47;	author angelos;	state Exp;
branches
	1.22.4.1;
next	1.21;

1.21
date	2001.05.31.16.27.08;	author provos;	state Exp;
branches;
next	1.20;

1.20
date	2000.12.13.09.47.08;	author provos;	state Exp;
branches
	1.20.2.1;
next	1.19;

1.19
date	2000.12.12.08.12.04;	author provos;	state Exp;
branches;
next	1.18;

1.18
date	2000.12.11.19.12.22;	author provos;	state Exp;
branches;
next	1.17;

1.17
date	2000.09.18.22.06.38;	author provos;	state Exp;
branches;
next	1.16;

1.16
date	99.12.21.17.49.28;	author provos;	state Exp;
branches
	1.16.2.1;
next	1.15;

1.15
date	99.11.15.05.50.59;	author hugh;	state Exp;
branches;
next	1.14;

1.14
date	99.09.01.21.38.21;	author provos;	state Exp;
branches;
next	1.13;

1.13
date	99.07.02.20.39.08;	author cmetz;	state Exp;
branches;
next	1.12;

1.12
date	99.04.21.21.38.58;	author provos;	state Exp;
branches;
next	1.11;

1.11
date	99.01.27.16.47.29;	author provos;	state Exp;
branches;
next	1.10;

1.10
date	98.11.25.05.44.37;	author millert;	state Exp;
branches;
next	1.9;

1.9
date	98.11.17.19.23.02;	author provos;	state Exp;
branches;
next	1.8;

1.8
date	97.08.26.20.02.34;	author deraadt;	state Exp;
branches;
next	1.7;

1.7
date	97.02.05.15.48.26;	author deraadt;	state Exp;
branches;
next	1.6;

1.6
date	96.09.12.06.19.57;	author tholo;	state Exp;
branches;
next	1.5;

1.5
date	96.07.29.22.01.51;	author niklas;	state Exp;
branches;
next	1.4;

1.4
date	96.07.29.06.22.14;	author tholo;	state Exp;
branches;
next	1.3;

1.3
date	96.03.14.08.09.49;	author tholo;	state Exp;
branches;
next	1.2;

1.2
date	96.03.03.22.30.48;	author niklas;	state Exp;
branches;
next	1.1;

1.1
date	95.10.18.08.53.12;	author deraadt;	state Exp;
branches
	1.1.1.1;
next	;

1.1.1.1
date	95.10.18.08.53.12;	author deraadt;	state Exp;
branches;
next	;

1.16.2.1
date	2001.05.14.22.40.15;	author niklas;	state Exp;
branches;
next	1.16.2.2;

1.16.2.2
date	2001.07.04.10.55.09;	author niklas;	state Exp;
branches;
next	1.16.2.3;

1.16.2.3
date	2002.03.06.02.15.08;	author niklas;	state Exp;
branches;
next	1.16.2.4;

1.16.2.4
date	2002.03.28.14.56.46;	author niklas;	state Exp;
branches;
next	1.16.2.5;

1.16.2.5
date	2003.03.28.00.06.55;	author niklas;	state Exp;
branches;
next	1.16.2.6;

1.16.2.6
date	2003.06.07.11.06.08;	author ho;	state Exp;
branches;
next	1.16.2.7;

1.16.2.7
date	2004.02.19.10.57.24;	author niklas;	state Exp;
branches;
next	;

1.20.2.1
date	2001.06.06.22.35.11;	author jason;	state Exp;
branches;
next	;

1.22.4.1
date	2002.01.31.22.55.45;	author niklas;	state Exp;
branches;
next	1.22.4.2;

1.22.4.2
date	2002.06.11.03.31.37;	author art;	state Exp;
branches;
next	1.22.4.3;

1.22.4.3
date	2002.10.29.00.36.47;	author art;	state Exp;
branches;
next	1.22.4.4;

1.22.4.4
date	2003.05.19.22.40.41;	author tedu;	state Exp;
branches;
next	;

1.30.2.1
date	2003.02.01.20.52.24;	author margarida;	state Exp;
branches;
next	;

1.38.6.1
date	2008.02.21.17.34.26;	author henning;	state Exp;
branches;
next	;

1.39.2.1
date	2008.02.21.15.53.16;	author henning;	state Exp;
branches;
next	;


desc
@@


1.54
log
@percpu counters for TCP stats

ok mpi@@ bluhm@@
@
text
@/*	$OpenBSD: tcp_timer.c,v 1.53 2016/12/19 08:36:49 mpi Exp $	*/
/*	$NetBSD: tcp_timer.c,v 1.14 1996/02/13 23:44:09 christos Exp $	*/

/*
 * Copyright (c) 1982, 1986, 1988, 1990, 1993
 *	The Regents of the University of California.  All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. Neither the name of the University nor the names of its contributors
 *    may be used to endorse or promote products derived from this software
 *    without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE
 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
 *
 *	@@(#)tcp_timer.c	8.1 (Berkeley) 6/10/93
 */

#include <sys/param.h>
#include <sys/systm.h>
#include <sys/mbuf.h>
#include <sys/socket.h>
#include <sys/socketvar.h>
#include <sys/protosw.h>
#include <sys/kernel.h>
#include <sys/pool.h>

#include <net/route.h>

#include <netinet/in.h>
#include <netinet/ip.h>
#include <netinet/in_pcb.h>
#include <netinet/ip_var.h>
#include <netinet/tcp.h>
#include <netinet/tcp_fsm.h>
#include <netinet/tcp_timer.h>
#include <netinet/tcp_var.h>
#include <netinet/ip_icmp.h>
#include <netinet/tcp_seq.h>

int	tcp_always_keepalive;
int	tcp_keepidle;
int	tcp_keepintvl;
int	tcp_maxpersistidle;	/* max idle time in persist */
int	tcp_maxidle;

/*
 * Time to delay the ACK.  This is initialized in tcp_init(), unless
 * its patched.
 */
int	tcp_delack_ticks;

void	tcp_timer_rexmt(void *);
void	tcp_timer_persist(void *);
void	tcp_timer_keep(void *);
void	tcp_timer_2msl(void *);

const tcp_timer_func_t tcp_timer_funcs[TCPT_NTIMERS] = {
	tcp_timer_rexmt,
	tcp_timer_persist,
	tcp_timer_keep,
	tcp_timer_2msl,
};

/*
 * Timer state initialization, called from tcp_init().
 */
void
tcp_timer_init(void)
{

	if (tcp_keepidle == 0)
		tcp_keepidle = TCPTV_KEEP_IDLE;

	if (tcp_keepintvl == 0)
		tcp_keepintvl = TCPTV_KEEPINTVL;

	if (tcp_maxpersistidle == 0)
		tcp_maxpersistidle = TCPTV_KEEP_IDLE;

	if (tcp_delack_ticks == 0)
		tcp_delack_ticks = TCP_DELACK_TICKS;
}

/*
 * Callout to process delayed ACKs for a TCPCB.
 */
void
tcp_delack(void *arg)
{
	struct tcpcb *tp = arg;
	int s;

	/*
	 * If tcp_output() wasn't able to transmit the ACK
	 * for whatever reason, it will restart the delayed
	 * ACK callout.
	 */
	NET_LOCK(s);
	if (tp->t_flags & TF_DEAD)
		goto out;
	tp->t_flags |= TF_ACKNOW;
	(void) tcp_output(tp);
 out:
	NET_UNLOCK(s);
}

/*
 * Tcp protocol timeout routine called every 500 ms.
 * Updates the timers in all active tcb's and
 * causes finite state machine actions if timers expire.
 */
void
tcp_slowtimo(void)
{
	splsoftassert(IPL_SOFTNET);

	tcp_maxidle = TCPTV_KEEPCNT * tcp_keepintvl;
	tcp_iss += TCP_ISSINCR2/PR_SLOWHZ;		/* increment iss */
	tcp_now++;					/* for timestamps */
}

/*
 * Cancel all timers for TCP tp.
 */
void
tcp_canceltimers(struct tcpcb *tp)
{
	int i;

	for (i = 0; i < TCPT_NTIMERS; i++)
		TCP_TIMER_DISARM(tp, i);
}

int	tcp_backoff[TCP_MAXRXTSHIFT + 1] =
    { 1, 2, 4, 8, 16, 32, 64, 64, 64, 64, 64, 64, 64 };

int tcp_totbackoff = 511;	/* sum of tcp_backoff[] */

/*
 * TCP timer processing.
 */

#ifdef TCP_SACK
void	tcp_timer_freesack(struct tcpcb *);

void
tcp_timer_freesack(struct tcpcb *tp)
{
	struct sackhole *p, *q;
	/*
	 * Free SACK holes for 2MSL and REXMT timers.
	 */
	q = tp->snd_holes;
	while (q != NULL) {
		p = q;
		q = q->next;
		pool_put(&sackhl_pool, p);
	}
	tp->snd_holes = 0;
#ifdef TCP_FACK
	tp->snd_fack = tp->snd_una;
	tp->retran_data = 0;
	tp->snd_awnd = 0;
#endif /* TCP_FACK */
}
#endif /* TCP_SACK */

void
tcp_timer_rexmt(void *arg)
{
	struct tcpcb *tp = arg;
	uint32_t rto;
	int s;

	NET_LOCK(s);
	if (tp->t_flags & TF_DEAD)
		goto out;

	if ((tp->t_flags & TF_PMTUD_PEND) && tp->t_inpcb &&
	    SEQ_GEQ(tp->t_pmtud_th_seq, tp->snd_una) &&
	    SEQ_LT(tp->t_pmtud_th_seq, (int)(tp->snd_una + tp->t_maxseg))) {
		struct sockaddr_in sin;
		struct icmp icmp;

		tp->t_flags &= ~TF_PMTUD_PEND;

		/* XXX create fake icmp message with relevant entries */
		icmp.icmp_nextmtu = tp->t_pmtud_nextmtu;
		icmp.icmp_ip.ip_len = tp->t_pmtud_ip_len;
		icmp.icmp_ip.ip_hl = tp->t_pmtud_ip_hl;
		icmp.icmp_ip.ip_dst = tp->t_inpcb->inp_faddr;
		icmp_mtudisc(&icmp, tp->t_inpcb->inp_rtableid);

		/*
		 * Notify all connections to the same peer about
		 * new mss and trigger retransmit.
		 */
		bzero(&sin, sizeof(sin));
		sin.sin_len = sizeof(sin);
		sin.sin_family = AF_INET;
		sin.sin_addr = tp->t_inpcb->inp_faddr;
		in_pcbnotifyall(&tcbtable, sintosa(&sin),
		    tp->t_inpcb->inp_rtableid, EMSGSIZE, tcp_mtudisc);
		goto out;
	}

#ifdef TCP_SACK
	tcp_timer_freesack(tp);
#endif
	if (++tp->t_rxtshift > TCP_MAXRXTSHIFT) {
		tp->t_rxtshift = TCP_MAXRXTSHIFT;
		tcpstat_inc(tcps_timeoutdrop);
		(void)tcp_drop(tp, tp->t_softerror ?
		    tp->t_softerror : ETIMEDOUT);
		goto out;
	}
	tcpstat_inc(tcps_rexmttimeo);
	rto = TCP_REXMTVAL(tp);
	if (rto < tp->t_rttmin)
		rto = tp->t_rttmin;
	TCPT_RANGESET(tp->t_rxtcur,
	    rto * tcp_backoff[tp->t_rxtshift],
	    tp->t_rttmin, TCPTV_REXMTMAX);
	TCP_TIMER_ARM(tp, TCPT_REXMT, tp->t_rxtcur);

	/*
	 * If we are losing and we are trying path MTU discovery,
	 * try turning it off.  This will avoid black holes in
	 * the network which suppress or fail to send "packet
	 * too big" ICMP messages.  We should ideally do
	 * lots more sophisticated searching to find the right
	 * value here...
	 */
	if (ip_mtudisc && tp->t_inpcb &&
	    TCPS_HAVEESTABLISHED(tp->t_state) &&
	    tp->t_rxtshift > TCP_MAXRXTSHIFT / 6) {
		struct inpcb *inp = tp->t_inpcb;
		struct rtentry *rt = NULL;

		/* No data to send means path mtu is not a problem */
		if (!inp->inp_socket->so_snd.sb_cc)
			goto leave;

		rt = in_pcbrtentry(inp);
		/* Check if path MTU discovery is disabled already */
		if (rt && (rt->rt_flags & RTF_HOST) &&
		    (rt->rt_rmx.rmx_locks & RTV_MTU))
			goto leave;

		rt = NULL;
		switch(tp->pf) {
#ifdef INET6
		case PF_INET6:
			/*
			 * We can not turn off path MTU for IPv6.
			 * Do nothing for now, maybe lower to
			 * minimum MTU.
			 */
			break;
#endif
		case PF_INET:
			rt = icmp_mtudisc_clone(inp->inp_faddr,
			    inp->inp_rtableid);
			break;
		}
		if (rt != NULL) {
			/* Disable path MTU discovery */
			if ((rt->rt_rmx.rmx_locks & RTV_MTU) == 0) {
				rt->rt_rmx.rmx_locks |= RTV_MTU;
				in_rtchange(inp, 0);
			}

			rtfree(rt);
		}
	leave:
		;
	}

	/*
	 * If losing, let the lower level know and try for
	 * a better route.  Also, if we backed off this far,
	 * our srtt estimate is probably bogus.  Clobber it
	 * so we'll take the next rtt measurement as our srtt;
	 * move the current srtt into rttvar to keep the current
	 * retransmit times until then.
	 */
	if (tp->t_rxtshift > TCP_MAXRXTSHIFT / 4) {
		in_losing(tp->t_inpcb);
		tp->t_rttvar += (tp->t_srtt >> TCP_RTT_SHIFT);
		tp->t_srtt = 0;
	}
	tp->snd_nxt = tp->snd_una;
#if defined(TCP_SACK)
	/*
	 * Note:  We overload snd_last to function also as the
	 * snd_last variable described in RFC 2582
	 */
	tp->snd_last = tp->snd_max;
#endif /* TCP_SACK */
	/*
	 * If timing a segment in this window, stop the timer.
	 */
	tp->t_rtttime = 0;
#ifdef TCP_ECN
	/*
	 * if ECN is enabled, there might be a broken firewall which
	 * blocks ecn packets.  fall back to non-ecn.
	 */
	if ((tp->t_state == TCPS_SYN_SENT || tp->t_state == TCPS_SYN_RECEIVED)
	    && tcp_do_ecn && !(tp->t_flags & TF_DISABLE_ECN))
		tp->t_flags |= TF_DISABLE_ECN;
#endif
	/*
	 * Close the congestion window down to one segment
	 * (we'll open it by one segment for each ack we get).
	 * Since we probably have a window's worth of unacked
	 * data accumulated, this "slow start" keeps us from
	 * dumping all that data as back-to-back packets (which
	 * might overwhelm an intermediate gateway).
	 *
	 * There are two phases to the opening: Initially we
	 * open by one mss on each ack.  This makes the window
	 * size increase exponentially with time.  If the
	 * window is larger than the path can handle, this
	 * exponential growth results in dropped packet(s)
	 * almost immediately.  To get more time between
	 * drops but still "push" the network to take advantage
	 * of improving conditions, we switch from exponential
	 * to linear window opening at some threshold size.
	 * For a threshold, we use half the current window
	 * size, truncated to a multiple of the mss.
	 *
	 * (the minimum cwnd that will give us exponential
	 * growth is 2 mss.  We don't allow the threshold
	 * to go below this.)
	 */
	{
		u_long win = ulmin(tp->snd_wnd, tp->snd_cwnd) / 2 / tp->t_maxseg;
		if (win < 2)
			win = 2;
		tp->snd_cwnd = tp->t_maxseg;
		tp->snd_ssthresh = win * tp->t_maxseg;
		tp->t_dupacks = 0;
#ifdef TCP_ECN
		tp->snd_last = tp->snd_max;
		tp->t_flags |= TF_SEND_CWR;
#endif
#if 1 /* TCP_ECN */
		tcpstat_inc(tcps_cwr_timeout);
#endif
	}
	(void) tcp_output(tp);

 out:
	NET_UNLOCK(s);
}

void
tcp_timer_persist(void *arg)
{
	struct tcpcb *tp = arg;
	uint32_t rto;
	int s;

	NET_LOCK(s);
	if ((tp->t_flags & TF_DEAD) ||
            TCP_TIMER_ISARMED(tp, TCPT_REXMT)) {
		goto out;
	}
	tcpstat_inc(tcps_persisttimeo);
	/*
	 * Hack: if the peer is dead/unreachable, we do not
	 * time out if the window is closed.  After a full
	 * backoff, drop the connection if the idle time
	 * (no responses to probes) reaches the maximum
	 * backoff that we would use if retransmitting.
	 */
	rto = TCP_REXMTVAL(tp);
	if (rto < tp->t_rttmin)
		rto = tp->t_rttmin;
	if (tp->t_rxtshift == TCP_MAXRXTSHIFT &&
	    ((tcp_now - tp->t_rcvtime) >= tcp_maxpersistidle ||
	    (tcp_now - tp->t_rcvtime) >= rto * tcp_totbackoff)) {
		tcpstat_inc(tcps_persistdrop);
		tp = tcp_drop(tp, ETIMEDOUT);
		goto out;
	}
	tcp_setpersist(tp);
	tp->t_force = 1;
	(void) tcp_output(tp);
	tp->t_force = 0;
 out:
	NET_UNLOCK(s);
}

void
tcp_timer_keep(void *arg)
{
	struct tcpcb *tp = arg;
	int s;

	NET_LOCK(s);
	if (tp->t_flags & TF_DEAD)
		goto out;

	tcpstat_inc(tcps_keeptimeo);
	if (TCPS_HAVEESTABLISHED(tp->t_state) == 0)
		goto dropit;
	if ((tcp_always_keepalive ||
	    tp->t_inpcb->inp_socket->so_options & SO_KEEPALIVE) &&
	    tp->t_state <= TCPS_CLOSING) {
		if ((tcp_maxidle > 0) &&
		    ((tcp_now - tp->t_rcvtime) >= tcp_keepidle + tcp_maxidle))
			goto dropit;
		/*
		 * Send a packet designed to force a response
		 * if the peer is up and reachable:
		 * either an ACK if the connection is still alive,
		 * or an RST if the peer has closed the connection
		 * due to timeout or reboot.
		 * Using sequence number tp->snd_una-1
		 * causes the transmitted zero-length segment
		 * to lie outside the receive window;
		 * by the protocol spec, this requires the
		 * correspondent TCP to respond.
		 */
		tcpstat_inc(tcps_keepprobe);
		tcp_respond(tp, mtod(tp->t_template, caddr_t),
		    NULL, tp->rcv_nxt, tp->snd_una - 1, 0, 0);
		TCP_TIMER_ARM(tp, TCPT_KEEP, tcp_keepintvl);
	} else
		TCP_TIMER_ARM(tp, TCPT_KEEP, tcp_keepidle);
 out:
	NET_UNLOCK(s);
	return;

 dropit:
	tcpstat_inc(tcps_keepdrops);
	tp = tcp_drop(tp, ETIMEDOUT);
	NET_UNLOCK(s);
}

void
tcp_timer_2msl(void *arg)
{
	struct tcpcb *tp = arg;
	int s;

	NET_LOCK(s);
	if (tp->t_flags & TF_DEAD)
		goto out;

#ifdef TCP_SACK
	tcp_timer_freesack(tp);
#endif

	if (tp->t_state != TCPS_TIME_WAIT &&
	    ((tcp_maxidle == 0) || ((tcp_now - tp->t_rcvtime) <= tcp_maxidle)))
		TCP_TIMER_ARM(tp, TCPT_2MSL, tcp_keepintvl);
	else
		tp = tcp_close(tp);

 out:
	NET_UNLOCK(s);
}
@


1.53
log
@Introduce the NET_LOCK() a rwlock used to serialize accesses to the parts
of the network stack that are not yet ready to be executed in parallel or
where new sleeping points are not possible.

This first pass replace all the entry points leading to ip_output(). This
is done to not introduce new sleeping points when trying to acquire ART's
write lock, needed when a new L2 entry is created via the RT_RESOLVE.

Inputs from and ok bluhm@@, ok dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.52 2016/11/28 11:12:45 mpi Exp $	*/
d229 1
a229 1
		tcpstat.tcps_timeoutdrop++;
d234 1
a234 1
	tcpstat.tcps_rexmttimeo++;
d366 1
a366 1
		tcpstat.tcps_cwr_timeout++;
d387 1
a387 1
	tcpstat.tcps_persisttimeo++;
d401 1
a401 1
		tcpstat.tcps_persistdrop++;
d423 1
a423 1
	tcpstat.tcps_keeptimeo++;
d444 1
a444 1
		tcpstat.tcps_keepprobe++;
d455 1
a455 1
	tcpstat.tcps_keepdrops++;
@


1.52
log
@Assert that every slow/fast timeout routine is called at IPL_SOFTNET.

This removes multipe recursive splsoftnet()/splx() dances.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.51 2016/11/07 09:08:06 mpi Exp $	*/
d115 1
a115 1
	s = splsoftnet();
d121 1
a121 1
	splx(s);
d192 1
a192 1
	s = splsoftnet();
d372 1
a372 1
	splx(s);
d382 1
a382 1
	s = splsoftnet();
d410 1
a410 1
	splx(s);
d419 1
a419 1
	s = splsoftnet();
d451 1
a451 1
	splx(s);
d457 1
a457 1
	splx(s);
d466 1
a466 1
	s = splsoftnet();
d481 1
a481 1
	splx(s);
@


1.51
log
@Use goto for consistently instead of splx() and return.

This will allow to have a single lock/unlock dance per timer.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.50 2016/09/24 14:51:37 naddy Exp $	*/
d132 1
a132 1
	int s;
a133 1
	s = splsoftnet();
a136 1
	splx(s);
@


1.50
log
@ANSIfy netinet/; from David Hill
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.49 2016/03/07 18:44:00 naddy Exp $	*/
a114 1

d116 2
a117 4
	if (tp->t_flags & TF_DEAD) {
		splx(s);
		return;
	}
d120 1
d195 2
a196 4
	if (tp->t_flags & TF_DEAD) {
		splx(s);
		return;
	}
d223 1
a223 2
		splx(s);
		return;
d387 1
a387 2
		splx(s);
		return;
d422 2
a423 4
	if (tp->t_flags & TF_DEAD) {
		splx(s);
		return;
	}
d452 1
a452 1

a458 1

d469 2
a470 4
	if (tp->t_flags & TF_DEAD) {
		splx(s);
		return;
	}
d482 1
@


1.49
log
@Sync no-argument function declaration and definition by adding (void).
ok mpi@@ millert@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.48 2014/07/22 11:06:10 mpi Exp $	*/
d147 1
a147 2
tcp_canceltimers(tp)
	struct tcpcb *tp;
@


1.48
log
@Fewer <netinet/in_systm.h> !
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.47 2013/08/08 14:29:29 mpi Exp $	*/
d132 1
a132 1
tcp_slowtimo()
@


1.47
log
@Change MTU discovery functions to not abuse the global icmpsrc variable
to pass the destination address of the route to clone.

ok markus@@, mikeb@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.46 2011/07/06 23:44:20 sthen Exp $	*/
a46 1
#include <netinet/in_systm.h>
@


1.46
log
@Add sysctl net.inet.tcp.always_keepalive, when this is set the system
behaves as if SO_KEEPALIVE was set on all TCP sockets, forcing keepalives
to be sent every net.inet.tcp.keepidle half-seconds.

In conjunction with a keepidle value greatly reduced from the default,
this can be useful for keeping sessions open if you are stuck on a network
with short NAT or firewall timeouts.

Feedback from various people, ok henning@@ claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.45 2010/07/03 04:44:51 guenther Exp $	*/
d207 1
a207 1
		extern struct sockaddr_in icmpsrc;
d216 1
a216 1
		icmpsrc.sin_addr = tp->t_inpcb->inp_faddr;
d223 5
a227 1
		in_pcbnotifyall(&tcbtable, sintosa(&icmpsrc),
a264 1
		struct sockaddr_in sin;
d288 1
a288 5
			bzero(&sin, sizeof(struct sockaddr_in));
			sin.sin_family = AF_INET;
			sin.sin_len = sizeof(struct sockaddr_in);
			sin.sin_addr = inp->inp_faddr;
			rt = icmp_mtudisc_clone(sintosa(&sin), 
@


1.45
log
@Fix the naming of interfaces and variables for rdomains and rtables
and make it possible to bind sockets (including listening sockets!)
to rtables and not just rdomains.  This changes the name of the
system calls, socket option, and ioctl.  After building with this
you should remove the files /usr/share/man/cat2/[gs]etrdomain.0.

Since this removes the existing [gs]etrdomain() system calls, the
libc major is bumped.

Written by claudio@@, criticized^Wcritiqued by me
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.44 2009/11/13 20:54:05 claudio Exp $	*/
d58 1
d439 2
a440 1
	if (tp->t_inpcb->inp_socket->so_options & SO_KEEPALIVE &&
@


1.44
log
@Extend the protosw pr_ctlinput function to include the rdomain. This is
needed so that the route and inp lookups done in TCP and UDP know where
to look. Additionally in_pcbnotifyall() and tcp_respond() got a rdomain
argument as well for similar reasons. With this tcp seems to be now
fully rdomain save and no longer leaks single packets into the main domain.
Looks good markus@@, henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.43 2009/06/05 00:05:22 claudio Exp $	*/
d216 1
a216 1
		icmp_mtudisc(&icmp, tp->t_inpcb->inp_rdomain);
d223 1
a223 1
		    tp->t_inpcb->inp_rdomain, EMSGSIZE, tcp_mtudisc);
d289 1
a289 1
			    inp->inp_rdomain);
@


1.43
log
@Initial support for routing domains. This allows to bind interfaces to
alternate routing table and separate them from other interfaces in distinct
routing tables. The same network can now be used in any doamin at the same
time without causing conflicts.
This diff is mostly mechanical and adds the necessary rdomain checks accross
net and netinet. L2 and IPv4 are mostly covered still missing pf and IPv6.
input and tested by jsg@@, phessler@@ and reyk@@. "put it in" deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.42 2008/02/20 11:24:03 markus Exp $	*/
d222 2
a223 2
		in_pcbnotifyall(&tcbtable, sintosa(&icmpsrc), EMSGSIZE,
		    tcp_mtudisc);
d457 1
a457 1
		    NULL, tp->rcv_nxt, tp->snd_una - 1, 0);
@


1.42
log
@when creating a response, use the correct TCP header instead of
relying on the mbuf chain layout; with claudio@@ and krw@@; ok henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.41 2007/11/27 17:23:23 deraadt Exp $	*/
d216 1
a216 1
		icmp_mtudisc(&icmp);
d288 2
a289 1
			rt = icmp_mtudisc_clone(sintosa(&sin));
@


1.41
log
@TCP_COMPAT_42 was last used in 1997.  Kill it.
ok millert
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.40 2007/09/01 18:49:28 henning Exp $	*/
d456 1
a456 1
		    (struct mbuf *)NULL, tp->rcv_nxt, tp->snd_una - 1, 0);
@


1.40
log
@since the
MGET* macros were changed to function calls, there wasn't any
need for the pool declarations and the inclusion of pool.h
From: tbert <bret.lambert@@gmail.com>
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.39 2007/06/15 18:23:07 markus Exp $	*/
a137 5
#ifdef TCP_COMPAT_42
	tcp_iss += TCP_ISSINCR/PR_SLOWHZ;		/* increment iss */
	if ((int)tcp_iss < 0)
		tcp_iss = 0;				/* XXX */
#else
a138 1
#endif /* TCP_COMPAT_42 */
a454 8
#ifdef TCP_COMPAT_42
		/*
		 * The keepalive packet must have nonzero length
		 * to get a 4.2 host to respond.
		 */
		tcp_respond(tp, mtod(tp->t_template, caddr_t),
		    (struct mbuf *)NULL, tp->rcv_nxt - 1, tp->snd_una - 1, 0);
#else
a456 1
#endif
@


1.39
log
@Drop the current random timestamps and the current ISN generation
code and replace both with a RFC1948 based method, so TCP clients
now have monotonic ISN/timestamps.  The server side uses completely
random ISN/timestamps and does time-wait recycling (on port reuse).
ok djm@@, mcbride@@; thanks to lots of testers
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.38 2005/11/15 21:09:46 miod Exp $	*/
d42 1
@


1.39.2.1
log
@MFC (markus)
when creating a response, use the correct TCP header instead of
relying on the mbuf chain layout; with claudio@@ and krw@@; ok henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.39 2007/06/15 18:23:07 markus Exp $	*/
d466 1
a466 1
		    NULL, tp->rcv_nxt - 1, tp->snd_una - 1, 0);
d469 1
a469 1
		    NULL, tp->rcv_nxt, tp->snd_una - 1, 0);
@


1.38
log
@Only two `h' in threshold.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.37 2005/06/30 08:51:31 markus Exp $	*/
d141 2
@


1.38.6.1
log
@MFC (markus)
when creating a response, use the correct TCP header instead of
relying on the mbuf chain layout; with claudio@@ and krw@@; ok henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.38 2005/11/15 21:09:46 miod Exp $	*/
d464 1
a464 1
		    NULL, tp->rcv_nxt - 1, tp->snd_una - 1, 0);
d467 1
a467 1
		    NULL, tp->rcv_nxt, tp->snd_una - 1, 0);
@


1.37
log
@implement PMTU checks from
        http://www.gont.com.ar/drafts/icmp-attacks-against-tcp.html
i.e. don't act on ICMP-need-frag immediately if adhoc checks on the
advertised mtu fail.  the mtu update is delayed until a tcp retransmit
happens.  initial patch by Fernando Gont, tested by many.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.36 2004/12/13 12:01:49 espie Exp $	*/
d357 2
a358 2
	 * to linear window opening at some threshhold size.
	 * For a threshhold, we use half the current window
d362 1
a362 1
	 * growth is 2 mss.  We don't allow the threshhold
@


1.36
log
@zap lvalue assignment, okay markus@@. approved miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.35 2004/11/25 15:32:08 markus Exp $	*/
d55 1
d202 25
@


1.35
log
@fix for race between invocation for timer and network input
1) add a reaper for TCP and SYN cache states (cf. netbsd pr 20390)
2) additional check for TCP_TIMER_ISARMED(TCPT_REXMT) in tcp_timer_persist()
with mickey@@; ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.34 2003/12/10 07:22:43 itojun Exp $	*/
d219 1
a219 1
	TCPT_RANGESET((long) tp->t_rxtcur,
@


1.34
log
@de-register.  deraadt ok
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.33 2003/06/02 23:28:14 millert Exp $	*/
d115 4
d200 4
d368 5
d406 4
d464 4
@


1.33
log
@Remove the advertising clause in the UCB license which Berkeley
rescinded 22 July 1999.  Proofed by myself and Theo.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.32 2003/02/21 20:52:06 tedu Exp $	*/
d148 1
a148 1
	register int i;
@


1.32
log
@remove useless assignment

ok jason@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.31 2002/11/06 01:52:08 kjc Exp $	*/
d16 1
a16 5
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *	This product includes software developed by the University of
 *	California, Berkeley and its contributors.
 * 4. Neither the name of the University nor the names of its contributors
@


1.31
log
@fix ecn breakage.
this part of falling back to non-ecn on timeout slipped during
merge from KAME.

ok @@art
report to bugs@@ by Han Boetes and Otto Moerbeek
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.30 2002/06/09 16:26:11 itojun Exp $	*/
d207 1
a207 1
		tp = tcp_drop(tp, tp->t_softerror ?
@


1.30
log
@whitespace
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.29 2002/05/16 14:10:51 kjc Exp $	*/
d302 9
@


1.30.2.1
log
@Pull patch from current:
Fix by kjc@@
Fix ecn breakage. This part of falling back to non-ecn on
timeout slipped during merge from KAME.
Reported to bugs@@ by Han Boetes and Otto Moerbeek.

deraadt@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.30 2002/06/09 16:26:11 itojun Exp $	*/
a301 9
#ifdef TCP_ECN
	/*
	 * if ECN is enabled, there might be a broken firewall which
	 * blocks ecn packets.  fall back to non-ecn.
	 */
	if ((tp->t_state == TCPS_SYN_SENT || tp->t_state == TCPS_SYN_RECEIVED)
	    && tcp_do_ecn && !(tp->t_flags & TF_DISABLE_ECN))
		tp->t_flags |= TF_DISABLE_ECN;
#endif
@


1.29
log
@bring in ECN support from KAME.
it consists of
 - ECN support in TCP
 - tunnel-egress and fragment reassembly rules in layer-3 not to lose
   congestion info at tunnel-egress and fragment reassembly

to enable ECN in TCP, build a kernel with TCP_ECN, and then,
turn it on by "sysctl -w net.inet.tcp.ecn=1".

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.28 2002/03/08 03:49:58 provos Exp $	*/
d220 1
a220 1
	/* 
d315 1
a315 1
	 * almost immediately.  To get more time between 
@


1.28
log
@use timeout(9) to schedule TCP timers.  this avoid traversing all
tcp connections during tcp_slowtimo.  apdapted from thorpej@@netbsd.org
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.27 2002/03/01 22:29:29 provos Exp $	*/
d333 7
@


1.27
log
@remove tcp_fasttimo and convert delayed acks to the timeout(9) API instead.
adapated from netbsd.  okay angelos@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.26 2002/01/15 19:18:01 provos Exp $	*/
d71 12
a131 2
	register struct inpcb *ip, *ipnxt;
	register struct tcpcb *tp;
a132 1
	register long i;
a135 31
	/*
	 * Search through tcb's and update active timers.
	 */
	ip = tcbtable.inpt_queue.cqh_first;
	if (ip == (struct inpcb *)0) {				/* XXX */
		splx(s);
		return;
	}
	for (; ip != (struct inpcb *)&tcbtable.inpt_queue; ip = ipnxt) {
		ipnxt = ip->inp_queue.cqe_next;
		tp = intotcpcb(ip);
		if (tp == 0 || tp->t_state == TCPS_LISTEN)
			continue;
		for (i = 0; i < TCPT_NTIMERS; i++) {
			if (tp->t_timer[i] && --tp->t_timer[i] == 0) {
				(void) tcp_usrreq(tp->t_inpcb->inp_socket,
				    PRU_SLOWTIMO, (struct mbuf *)0,
				    (struct mbuf *)i, (struct mbuf *)0);
				/* XXX NOT MP SAFE */
				if ((ipnxt == (void *)&tcbtable.inpt_queue &&
				    tcbtable.inpt_queue.cqh_last != ip) ||
				    ipnxt->inp_queue.cqe_prev != ip)
					goto tpgone;
			}
		}
		tp->t_idle++;
		if (tp->t_rtt)
			tp->t_rtt++;
tpgone:
		;
	}
a143 1
#ifndef TUBA_INCLUDE
d166 6
a171 4
struct tcpcb *
tcp_timers(tp, timer)
	register struct tcpcb *tp;
	int timer;
a172 2
	short rto;
#ifdef TCP_SACK
d177 11
a187 12
	if (timer == TCPT_2MSL || timer == TCPT_REXMT) {
		q = tp->snd_holes;
		while (q != NULL) {
			p = q;
			q = q->next;
			pool_put(&sackhl_pool, p);
		}
		tp->snd_holes = 0;
#if defined(TCP_SACK) && defined(TCP_FACK)
		tp->snd_fack = tp->snd_una;
		tp->retran_data = 0;
		tp->snd_awnd = 0;
d189 1
a189 1
	}
d192 6
a197 1
	switch (timer) {
d199 1
a199 13
	/*
	 * 2 MSL timeout in shutdown went off.  If we're closed but
	 * still waiting for peer to close and connection has been idle
	 * too long, or if 2MSL time is up from TIME_WAIT, delete connection
	 * control block.  Otherwise, check again in a bit.
	 */
	case TCPT_2MSL:
		if (tp->t_state != TCPS_TIME_WAIT &&
		    tp->t_idle <= tcp_maxidle)
			TCP_TIMER_ARM(tp, TCPT_2MSL, tcp_keepintvl);
		else
			tp = tcp_close(tp);
		break;
d201 26
a226 4
	/*
	 * Retransmission timer went off.  Message has not
	 * been acked within retransmit interval.  Back off
	 * to a longer retransmit interval and retransmit one segment.
d228 16
a243 41
	case TCPT_REXMT:
		if (++tp->t_rxtshift > TCP_MAXRXTSHIFT) {
			tp->t_rxtshift = TCP_MAXRXTSHIFT;
			tcpstat.tcps_timeoutdrop++;
			tp = tcp_drop(tp, tp->t_softerror ?
			    tp->t_softerror : ETIMEDOUT);
			break;
		}
		tcpstat.tcps_rexmttimeo++;
		rto = TCP_REXMTVAL(tp);
		if (rto < tp->t_rttmin)
			rto = tp->t_rttmin;
		TCPT_RANGESET((long) tp->t_rxtcur,
		    rto * tcp_backoff[tp->t_rxtshift],
		    tp->t_rttmin, TCPTV_REXMTMAX);
		TCP_TIMER_ARM(tp, TCPT_REXMT, tp->t_rxtcur);

		/* 
		 * If we are losing and we are trying path MTU discovery,
		 * try turning it off.  This will avoid black holes in
		 * the network which suppress or fail to send "packet
		 * too big" ICMP messages.  We should ideally do
		 * lots more sophisticated searching to find the right
		 * value here...
		 */
		if (ip_mtudisc && tp->t_inpcb &&
		    TCPS_HAVEESTABLISHED(tp->t_state) &&
		    tp->t_rxtshift > TCP_MAXRXTSHIFT / 6) {
			struct inpcb *inp = tp->t_inpcb;
			struct rtentry *rt = NULL;
			struct sockaddr_in sin;

			/* No data to send means path mtu is not a problem */
			if (!inp->inp_socket->so_snd.sb_cc)
				goto out;

			rt = in_pcbrtentry(inp);
			/* Check if path MTU discovery is disabled already */
			if (rt && (rt->rt_flags & RTF_HOST) &&
			    (rt->rt_rmx.rmx_locks & RTV_MTU))
				goto out;
d245 2
a246 2
			rt = NULL;
			switch(tp->pf) {
d248 7
a254 7
			case PF_INET6:
				/*
				 * We can not turn off path MTU for IPv6.
				 * Do nothing for now, maybe lower to
				 * minimum MTU.
				 */
				break;
d256 13
a268 7
			case PF_INET:
				bzero(&sin, sizeof(struct sockaddr_in));
				sin.sin_family = AF_INET;
				sin.sin_len = sizeof(struct sockaddr_in);
				sin.sin_addr = inp->inp_faddr;
				rt = icmp_mtudisc_clone(sintosa(&sin));
				break;
a269 6
			if (rt != NULL) {
				/* Disable path MTU discovery */
				if ((rt->rt_rmx.rmx_locks & RTV_MTU) == 0) {
					rt->rt_rmx.rmx_locks |= RTV_MTU;
					in_rtchange(inp, 0);
				}
d271 1
a271 4
				rtfree(rt);
			}
			out:
				;
d273 3
d277 14
a290 14
		/*
		 * If losing, let the lower level know and try for
		 * a better route.  Also, if we backed off this far,
		 * our srtt estimate is probably bogus.  Clobber it
		 * so we'll take the next rtt measurement as our srtt;
		 * move the current srtt into rttvar to keep the current
		 * retransmit times until then.
		 */
		if (tp->t_rxtshift > TCP_MAXRXTSHIFT / 4) {
			in_losing(tp->t_inpcb);
			tp->t_rttvar += (tp->t_srtt >> TCP_RTT_SHIFT);
			tp->t_srtt = 0;
		}
		tp->snd_nxt = tp->snd_una;
d292 5
a296 5
		/*
		 * Note:  We overload snd_last to function also as the
		 * snd_last variable described in RFC 2582
		 */
		tp->snd_last = tp->snd_max;
d298 29
a326 29
		/*
		 * If timing a segment in this window, stop the timer.
		 */
		tp->t_rtt = 0;
		/*
		 * Close the congestion window down to one segment
		 * (we'll open it by one segment for each ack we get).
		 * Since we probably have a window's worth of unacked
		 * data accumulated, this "slow start" keeps us from
		 * dumping all that data as back-to-back packets (which
		 * might overwhelm an intermediate gateway).
		 *
		 * There are two phases to the opening: Initially we
		 * open by one mss on each ack.  This makes the window
		 * size increase exponentially with time.  If the
		 * window is larger than the path can handle, this
		 * exponential growth results in dropped packet(s)
		 * almost immediately.  To get more time between 
		 * drops but still "push" the network to take advantage
		 * of improving conditions, we switch from exponential
		 * to linear window opening at some threshhold size.
		 * For a threshhold, we use half the current window
		 * size, truncated to a multiple of the mss.
		 *
		 * (the minimum cwnd that will give us exponential
		 * growth is 2 mss.  We don't allow the threshhold
		 * to go below this.)
		 */
		{
d333 13
a345 3
		}
		(void) tcp_output(tp);
		break;
d347 2
d350 5
a354 2
	 * Persistance timer into zero window.
	 * Force a byte to be output, if possible.
d356 34
a389 2
	case TCPT_PERSIST:
		tcpstat.tcps_persisttimeo++;
d391 10
a400 5
		 * Hack: if the peer is dead/unreachable, we do not
		 * time out if the window is closed.  After a full
		 * backoff, drop the connection if the idle time
		 * (no responses to probes) reaches the maximum
		 * backoff that we would use if retransmitting.
d402 1
a402 41
		rto = TCP_REXMTVAL(tp);
		if (rto < tp->t_rttmin)
			rto = tp->t_rttmin;
		if (tp->t_rxtshift == TCP_MAXRXTSHIFT &&
		    (tp->t_idle >= tcp_maxpersistidle ||
		     tp->t_idle >= rto * tcp_totbackoff)) {
			tcpstat.tcps_persistdrop++;
			tp = tcp_drop(tp, ETIMEDOUT);
			break;
		}
		tcp_setpersist(tp);
		tp->t_force = 1;
		(void) tcp_output(tp);
		tp->t_force = 0;
		break;

	/*
	 * Keep-alive timer went off; send something
	 * or drop connection if idle for too long.
	 */
	case TCPT_KEEP:
		tcpstat.tcps_keeptimeo++;
		if (TCPS_HAVEESTABLISHED(tp->t_state) == 0)
			goto dropit;
		if (tp->t_inpcb->inp_socket->so_options & SO_KEEPALIVE &&
		    tp->t_state <= TCPS_CLOSING) {
			if (tp->t_idle >= tcp_keepidle + tcp_maxidle)
				goto dropit;
			/*
			 * Send a packet designed to force a response
			 * if the peer is up and reachable:
			 * either an ACK if the connection is still alive,
			 * or an RST if the peer has closed the connection
			 * due to timeout or reboot.
			 * Using sequence number tp->snd_una-1
			 * causes the transmitted zero-length segment
			 * to lie outside the receive window;
			 * by the protocol spec, this requires the
			 * correspondent TCP to respond.
			 */
			tcpstat.tcps_keepprobe++;
d404 6
a409 8
			/*
			 * The keepalive packet must have nonzero length
			 * to get a 4.2 host to respond.
			 */
			tcp_respond(tp,
				mtod(tp->t_template, caddr_t),
				(struct mbuf *)NULL,
				tp->rcv_nxt - 1, tp->snd_una - 1, 0);
d411 2
a412 4
			tcp_respond(tp,
				mtod(tp->t_template, caddr_t),
				(struct mbuf *)NULL,
				tp->rcv_nxt, tp->snd_una - 1, 0);
d414 33
a446 10
			TCP_TIMER_ARM(tp, TCPT_KEEP, tcp_keepintvl);
		} else
			TCP_TIMER_ARM(tp, TCPT_KEEP, tcp_keepidle);
		break;
	dropit:
		tcpstat.tcps_keepdrops++;
		tp = tcp_drop(tp, ETIMEDOUT);
		break;
	}
	return (tp);
a447 1
#endif /* TUBA_INCLUDE */
@


1.26
log
@allocate sackholes with pool
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.25 2002/01/14 20:13:45 provos Exp $	*/
a38 1
#ifndef TUBA_INCLUDE
d45 1
d60 3
a62 3
int	tcp_keepidle = TCPTV_KEEP_IDLE;
int	tcp_keepintvl = TCPTV_KEEPINTVL;
int	tcp_maxpersistidle = TCPTV_KEEP_IDLE;	/* max idle time in persist */
d64 27
a90 1
#endif /* TUBA_INCLUDE */
d92 1
a92 1
 * Fast timeout routine for processing delayed acks
d95 1
a95 1
tcp_fasttimo()
d97 1
a97 2
	register struct inpcb *inp;
	register struct tcpcb *tp;
d100 6
d107 2
a108 12
	inp = tcbtable.inpt_queue.cqh_first;
	if (inp)						/* XXX */
	for (; inp != (struct inpcb *)&tcbtable.inpt_queue;
	    inp = inp->inp_queue.cqe_next) {
		if ((tp = (struct tcpcb *)inp->inp_ppcb) &&
		    (tp->t_flags & TF_DELACK)) {
			tp->t_flags &= ~TF_DELACK;
			tp->t_flags |= TF_ACKNOW;
			tcpstat.tcps_delack++;
			(void) tcp_output(tp);
		}
	}
@


1.25
log
@knf
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.24 2002/01/14 03:11:55 provos Exp $	*/
d184 1
a184 1
			free(p, M_PCB);
@


1.24
log
@use macros to manage tcp timers; based on netbsd
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.23 2002/01/02 20:35:40 deraadt Exp $	*/
d180 4
a183 3
		q = p = tp->snd_holes;
		while (p != 0) {
			q = p->next;
a184 1
			p = q;
d206 1
a206 1
			TCP_TIMER_ARM(tp,TCPT_2MSL, tcp_keepintvl);
@


1.23
log
@at least ; required after label or case; openbsd@@davidkrause.com
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.22 2001/06/08 03:53:47 angelos Exp $	*/
d157 1
a157 1
		tp->t_timer[i] = 0;
d206 1
a206 1
			tp->t_timer[TCPT_2MSL] = tcp_keepintvl;
d231 1
a231 1
		tp->t_timer[TCPT_REXMT] = tp->t_rxtcur;
d419 1
a419 1
			tp->t_timer[TCPT_KEEP] = tcp_keepintvl;
d421 1
a421 1
			tp->t_timer[TCPT_KEEP] = tcp_keepidle;
@


1.22
log
@Cut down on include files.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.21 2001/05/31 16:27:08 provos Exp $	*/
d287 1
@


1.22.4.1
log
@Merge in -current, builds on i386, otherwise untested
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.26 2002/01/15 19:18:01 provos Exp $	*/
d157 1
a157 1
		TCP_TIMER_DISARM(tp, i);
d180 4
a183 2
		q = tp->snd_holes;
		while (q != NULL) {
a184 2
			q = q->next;
			pool_put(&sackhl_pool, p);
d206 1
a206 1
			TCP_TIMER_ARM(tp, TCPT_2MSL, tcp_keepintvl);
d231 1
a231 1
		TCP_TIMER_ARM(tp, TCPT_REXMT, tp->t_rxtcur);
a286 1
				;
d418 1
a418 1
			TCP_TIMER_ARM(tp, TCPT_KEEP, tcp_keepintvl);
d420 1
a420 1
			TCP_TIMER_ARM(tp, TCPT_KEEP, tcp_keepidle);
@


1.22.4.2
log
@Sync UBC branch to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.22.4.1 2002/01/31 22:55:45 niklas Exp $	*/
d39 1
a45 1
#include <sys/kernel.h>
d60 3
a62 3
int	tcp_keepidle;
int	tcp_keepintvl;
int	tcp_maxpersistidle;	/* max idle time in persist */
d64 1
a64 19

/*
 * Time to delay the ACK.  This is initialized in tcp_init(), unless
 * its patched.
 */
int	tcp_delack_ticks;

void	tcp_timer_rexmt(void *);
void	tcp_timer_persist(void *);
void	tcp_timer_keep(void *);
void	tcp_timer_2msl(void *);

const tcp_timer_func_t tcp_timer_funcs[TCPT_NTIMERS] = {
	tcp_timer_rexmt,
	tcp_timer_persist,
	tcp_timer_keep,
	tcp_timer_2msl,
};

d66 1
a66 1
 * Timer state initialization, called from tcp_init().
d69 1
a69 1
tcp_timer_init(void)
d71 2
a72 21

	if (tcp_keepidle == 0)
		tcp_keepidle = TCPTV_KEEP_IDLE;

	if (tcp_keepintvl == 0)
		tcp_keepintvl = TCPTV_KEEPINTVL;

	if (tcp_maxpersistidle == 0)
		tcp_maxpersistidle = TCPTV_KEEP_IDLE;

	if (tcp_delack_ticks == 0)
		tcp_delack_ticks = TCP_DELACK_TICKS;
}

/*
 * Callout to process delayed ACKs for a TCPCB.
 */
void
tcp_delack(void *arg)
{
	struct tcpcb *tp = arg;
a74 6
	/*
	 * If tcp_output() wasn't able to transmit the ACK
	 * for whatever reason, it will restart the delayed
	 * ACK callout.
	 */

d76 12
a87 2
	tp->t_flags |= TF_ACKNOW;
	(void) tcp_output(tp);
d99 2
d102 1
d106 31
d145 1
d168 6
a173 1

a174 5
void	tcp_timer_freesack(struct tcpcb *);

void
tcp_timer_freesack(struct tcpcb *tp)
{
d179 13
a191 5
	q = tp->snd_holes;
	while (q != NULL) {
		p = q;
		q = q->next;
		pool_put(&sackhl_pool, p);
a192 7
	tp->snd_holes = 0;
#ifdef TCP_FACK
	tp->snd_fack = tp->snd_una;
	tp->retran_data = 0;
	tp->snd_awnd = 0;
#endif /* TCP_FACK */
}
d195 1
a195 6
void
tcp_timer_rexmt(void *arg)
{
	struct tcpcb *tp = arg;
	uint32_t rto;
	int s;
d197 13
a209 1
	s = splsoftnet();
d211 4
a214 26
#ifdef TCP_SACK
	tcp_timer_freesack(tp);
#endif
	if (++tp->t_rxtshift > TCP_MAXRXTSHIFT) {
		tp->t_rxtshift = TCP_MAXRXTSHIFT;
		tcpstat.tcps_timeoutdrop++;
		tp = tcp_drop(tp, tp->t_softerror ?
		    tp->t_softerror : ETIMEDOUT);
		goto out;
	}
	tcpstat.tcps_rexmttimeo++;
	rto = TCP_REXMTVAL(tp);
	if (rto < tp->t_rttmin)
		rto = tp->t_rttmin;
	TCPT_RANGESET((long) tp->t_rxtcur,
	    rto * tcp_backoff[tp->t_rxtshift],
	    tp->t_rttmin, TCPTV_REXMTMAX);
	TCP_TIMER_ARM(tp, TCPT_REXMT, tp->t_rxtcur);

	/* 
	 * If we are losing and we are trying path MTU discovery,
	 * try turning it off.  This will avoid black holes in
	 * the network which suppress or fail to send "packet
	 * too big" ICMP messages.  We should ideally do
	 * lots more sophisticated searching to find the right
	 * value here...
d216 41
a256 16
	if (ip_mtudisc && tp->t_inpcb &&
	    TCPS_HAVEESTABLISHED(tp->t_state) &&
	    tp->t_rxtshift > TCP_MAXRXTSHIFT / 6) {
		struct inpcb *inp = tp->t_inpcb;
		struct rtentry *rt = NULL;
		struct sockaddr_in sin;

		/* No data to send means path mtu is not a problem */
		if (!inp->inp_socket->so_snd.sb_cc)
			goto leave;

		rt = in_pcbrtentry(inp);
		/* Check if path MTU discovery is disabled already */
		if (rt && (rt->rt_flags & RTF_HOST) &&
		    (rt->rt_rmx.rmx_locks & RTV_MTU))
			goto leave;
d258 2
a259 2
		rt = NULL;
		switch(tp->pf) {
d261 7
a267 7
		case PF_INET6:
			/*
			 * We can not turn off path MTU for IPv6.
			 * Do nothing for now, maybe lower to
			 * minimum MTU.
			 */
			break;
d269 7
a275 13
		case PF_INET:
			bzero(&sin, sizeof(struct sockaddr_in));
			sin.sin_family = AF_INET;
			sin.sin_len = sizeof(struct sockaddr_in);
			sin.sin_addr = inp->inp_faddr;
			rt = icmp_mtudisc_clone(sintosa(&sin));
			break;
		}
		if (rt != NULL) {
			/* Disable path MTU discovery */
			if ((rt->rt_rmx.rmx_locks & RTV_MTU) == 0) {
				rt->rt_rmx.rmx_locks |= RTV_MTU;
				in_rtchange(inp, 0);
d277 6
d284 4
a287 1
			rtfree(rt);
a288 3
	leave:
		;
	}
d290 14
a303 14
	/*
	 * If losing, let the lower level know and try for
	 * a better route.  Also, if we backed off this far,
	 * our srtt estimate is probably bogus.  Clobber it
	 * so we'll take the next rtt measurement as our srtt;
	 * move the current srtt into rttvar to keep the current
	 * retransmit times until then.
	 */
	if (tp->t_rxtshift > TCP_MAXRXTSHIFT / 4) {
		in_losing(tp->t_inpcb);
		tp->t_rttvar += (tp->t_srtt >> TCP_RTT_SHIFT);
		tp->t_srtt = 0;
	}
	tp->snd_nxt = tp->snd_una;
d305 5
a309 5
	/*
	 * Note:  We overload snd_last to function also as the
	 * snd_last variable described in RFC 2582
	 */
	tp->snd_last = tp->snd_max;
d311 29
a339 29
	/*
	 * If timing a segment in this window, stop the timer.
	 */
	tp->t_rtttime = 0;
	/*
	 * Close the congestion window down to one segment
	 * (we'll open it by one segment for each ack we get).
	 * Since we probably have a window's worth of unacked
	 * data accumulated, this "slow start" keeps us from
	 * dumping all that data as back-to-back packets (which
	 * might overwhelm an intermediate gateway).
	 *
	 * There are two phases to the opening: Initially we
	 * open by one mss on each ack.  This makes the window
	 * size increase exponentially with time.  If the
	 * window is larger than the path can handle, this
	 * exponential growth results in dropped packet(s)
	 * almost immediately.  To get more time between 
	 * drops but still "push" the network to take advantage
	 * of improving conditions, we switch from exponential
	 * to linear window opening at some threshhold size.
	 * For a threshhold, we use half the current window
	 * size, truncated to a multiple of the mss.
	 *
	 * (the minimum cwnd that will give us exponential
	 * growth is 2 mss.  We don't allow the threshhold
	 * to go below this.)
	 */
	{
d346 3
a348 9
#ifdef TCP_ECN
		tp->snd_last = tp->snd_max;
		tp->t_flags |= TF_SEND_CWR;
#endif
#if 1 /* TCP_ECN */
		tcpstat.tcps_cwr_timeout++;
#endif
	}
	(void) tcp_output(tp);
d350 28
a377 10
 out:
	splx(s);
}

void
tcp_timer_persist(void *arg)
{
	struct tcpcb *tp = arg;
	uint32_t rto;
	int s;
a378 2
	s = splsoftnet();
	tcpstat.tcps_persisttimeo++;
d380 2
a381 5
	 * Hack: if the peer is dead/unreachable, we do not
	 * time out if the window is closed.  After a full
	 * backoff, drop the connection if the idle time
	 * (no responses to probes) reaches the maximum
	 * backoff that we would use if retransmitting.
d383 3
a385 33
	rto = TCP_REXMTVAL(tp);
	if (rto < tp->t_rttmin)
		rto = tp->t_rttmin;
	if (tp->t_rxtshift == TCP_MAXRXTSHIFT &&
	    ((tcp_now - tp->t_rcvtime) >= tcp_maxpersistidle ||
	    (tcp_now - tp->t_rcvtime) >= rto * tcp_totbackoff)) {
		tcpstat.tcps_persistdrop++;
		tp = tcp_drop(tp, ETIMEDOUT);
		goto out;
	}
	tcp_setpersist(tp);
	tp->t_force = 1;
	(void) tcp_output(tp);
	tp->t_force = 0;
 out:
	splx(s);
}

void
tcp_timer_keep(void *arg)
{
	struct tcpcb *tp = arg;
	int s;

	s = splsoftnet();

	tcpstat.tcps_keeptimeo++;
	if (TCPS_HAVEESTABLISHED(tp->t_state) == 0)
		goto dropit;
	if (tp->t_inpcb->inp_socket->so_options & SO_KEEPALIVE &&
	    tp->t_state <= TCPS_CLOSING) {
		if ((tcp_maxidle > 0) &&
		    ((tcp_now - tp->t_rcvtime) >= tcp_keepidle + tcp_maxidle))
d387 17
a403 13
		/*
		 * Send a packet designed to force a response
		 * if the peer is up and reachable:
		 * either an ACK if the connection is still alive,
		 * or an RST if the peer has closed the connection
		 * due to timeout or reboot.
		 * Using sequence number tp->snd_una-1
		 * causes the transmitted zero-length segment
		 * to lie outside the receive window;
		 * by the protocol spec, this requires the
		 * correspondent TCP to respond.
		 */
		tcpstat.tcps_keepprobe++;
d405 8
a412 6
		/*
		 * The keepalive packet must have nonzero length
		 * to get a 4.2 host to respond.
		 */
		tcp_respond(tp, mtod(tp->t_template, caddr_t),
		    (struct mbuf *)NULL, tp->rcv_nxt - 1, tp->snd_una - 1, 0);
d414 4
a417 2
		tcp_respond(tp, mtod(tp->t_template, caddr_t),
		    (struct mbuf *)NULL, tp->rcv_nxt, tp->snd_una - 1, 0);
d419 10
a428 33
		TCP_TIMER_ARM(tp, TCPT_KEEP, tcp_keepintvl);
	} else
		TCP_TIMER_ARM(tp, TCPT_KEEP, tcp_keepidle);

	splx(s);
	return;

 dropit:
	tcpstat.tcps_keepdrops++;
	tp = tcp_drop(tp, ETIMEDOUT);

	splx(s);
}

void
tcp_timer_2msl(void *arg)
{
	struct tcpcb *tp = arg;
	int s;

	s = splsoftnet();

#ifdef TCP_SACK
	tcp_timer_freesack(tp);
#endif

	if (tp->t_state != TCPS_TIME_WAIT &&
	    ((tcp_maxidle == 0) || ((tcp_now - tp->t_rcvtime) <= tcp_maxidle)))
		TCP_TIMER_ARM(tp, TCPT_2MSL, tcp_keepintvl);
	else
		tp = tcp_close(tp);

	splx(s);
d430 1
@


1.22.4.3
log
@sync to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.22.4.2 2002/06/11 03:31:37 art Exp $	*/
d220 1
a220 1
	/*
d315 1
a315 1
	 * almost immediately.  To get more time between
@


1.22.4.4
log
@sync
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d207 1
a207 1
		(void)tcp_drop(tp, tp->t_softerror ?
a301 9
#ifdef TCP_ECN
	/*
	 * if ECN is enabled, there might be a broken firewall which
	 * blocks ecn packets.  fall back to non-ecn.
	 */
	if ((tp->t_state == TCPS_SYN_SENT || tp->t_state == TCPS_SYN_RECEIVED)
	    && tcp_do_ecn && !(tp->t_flags & TF_DISABLE_ECN))
		tp->t_flags |= TF_DISABLE_ECN;
#endif
@


1.21
log
@Two fixes from Stevens via davidg@@freebsd, bug report by
armin@@wolfermann.org

- set the persist timer so that connections in CLOSING state timeout
- honor keep-alive timer in CLOSING state.

Fixes the problem in simulaneous close situation where connections
would never leave the CLOSING state and stay arround indefinitly.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.20 2000/12/13 09:47:08 provos Exp $	*/
a41 1
#include <sys/malloc.h>
a45 1
#include <sys/errno.h>
a46 1
#include <net/if.h>
a55 1
#include <netinet/tcp_seq.h>
a57 1
#include <netinet/tcpip.h>
a58 1
#include <dev/rndvar.h>
@


1.20
log
@more random tcp sequence numbers. okay deraadt@@, angelos@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.19 2000/12/12 08:12:04 provos Exp $	*/
d393 1
a393 1
		    tp->t_state <= TCPS_CLOSE_WAIT) {
@


1.20.2.1
log
@Pull in patch from current:
Fix (provos):
Two fixes from Stevens via davidg@@freebsd, bug report by
armin@@wolfermann.org

- set the persist timer so that connections in CLOSING state timeout
- honor keep-alive timer in CLOSING state.

Fixes the problem in simulaneous close situation where connections
would never leave the CLOSING state and stay arround indefinitly.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.21 2001/05/31 16:27:08 provos Exp $	*/
d393 1
a393 1
		    tp->t_state <= TCPS_CLOSING) {
@


1.19
log
@only disable path mtu for established connections that have data to send.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.18 2000/12/11 19:12:22 provos Exp $	*/
d147 1
a147 3
#else /* TCP_COMPAT_42 */
	tcp_iss += arc4random() % (2 * TCP_ISSINCR / PR_SLOWHZ) + 1; /* increment iss */
#endif /* !TCP_COMPAT_42 */
@


1.18
log
@turn off path mtu when icmp needfrag messages get blocked, okay itojun@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.17 2000/09/18 22:06:38 provos Exp $	*/
d250 1
d256 3
@


1.17
log
@Path MTU discovery based on NetBSD but with the decision to use the DF
flag delayed to ip_output().  That halves the code and reduces most of
the route lookups. okay deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.16 1999/12/21 17:49:28 provos Exp $	*/
d63 1
d240 1
a240 1
#if 0
d249 3
a251 1
		if (ip_mtudisc && tp->t_rxtshift > TCP_MAXRXTSHIFT / 6) {
d253 2
d256 31
a286 2
			if (tp->t_inpcb)
				rt = in_pcbrtentry(tp->t_inpcb);
d288 3
a290 1
			/* XXX:  Black hole recovery code goes here */
d292 1
a292 1
#endif
@


1.16
log
@option TCP_NEWRENO goes away, its the default case for TCP_SACK if
SACK is disabled for the connection or via sysctl
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.15 1999/11/15 05:50:59 hugh Exp $	*/
d239 18
@


1.16.2.1
log
@merge in approximately 2.9 into SMP branch
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.20 2000/12/13 09:47:08 provos Exp $	*/
a62 1
#include <netinet/ip_icmp.h>
d146 3
a148 1
#endif /* TCP_COMPAT_42 */
a238 57

		/* 
		 * If we are losing and we are trying path MTU discovery,
		 * try turning it off.  This will avoid black holes in
		 * the network which suppress or fail to send "packet
		 * too big" ICMP messages.  We should ideally do
		 * lots more sophisticated searching to find the right
		 * value here...
		 */
		if (ip_mtudisc && tp->t_inpcb &&
		    TCPS_HAVEESTABLISHED(tp->t_state) &&
		    tp->t_rxtshift > TCP_MAXRXTSHIFT / 6) {
			struct inpcb *inp = tp->t_inpcb;
			struct rtentry *rt = NULL;
			struct sockaddr_in sin;

			/* No data to send means path mtu is not a problem */
			if (!inp->inp_socket->so_snd.sb_cc)
				goto out;

			rt = in_pcbrtentry(inp);
			/* Check if path MTU discovery is disabled already */
			if (rt && (rt->rt_flags & RTF_HOST) &&
			    (rt->rt_rmx.rmx_locks & RTV_MTU))
				goto out;

			rt = NULL;
			switch(tp->pf) {
#ifdef INET6
			case PF_INET6:
				/*
				 * We can not turn off path MTU for IPv6.
				 * Do nothing for now, maybe lower to
				 * minimum MTU.
				 */
				break;
#endif
			case PF_INET:
				bzero(&sin, sizeof(struct sockaddr_in));
				sin.sin_family = AF_INET;
				sin.sin_len = sizeof(struct sockaddr_in);
				sin.sin_addr = inp->inp_faddr;
				rt = icmp_mtudisc_clone(sintosa(&sin));
				break;
			}
			if (rt != NULL) {
				/* Disable path MTU discovery */
				if ((rt->rt_rmx.rmx_locks & RTV_MTU) == 0) {
					rt->rt_rmx.rmx_locks |= RTV_MTU;
					in_rtchange(inp, 0);
				}

				rtfree(rt);
			}
			out:
		}

@


1.16.2.2
log
@Merge in -current from two days ago in the SMP branch.
As usual with merges, they do not indicate progress, so do not hold
your breath for working SMP, and do not mail me and ask about the
state of it.  It has not changed.  There is work ongoing, but very, very
slowly.  The commit is done in parts as to not lock up the tree in too
big chunks at a time.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.16.2.1 2001/05/14 22:40:15 niklas Exp $	*/
d42 1
d47 1
d49 1
d59 1
d62 1
d64 1
d393 1
a393 1
		    tp->t_state <= TCPS_CLOSING) {
@


1.16.2.3
log
@Merge in trunk
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d39 1
a45 1
#include <sys/kernel.h>
d60 3
a62 3
int	tcp_keepidle;
int	tcp_keepintvl;
int	tcp_maxpersistidle;	/* max idle time in persist */
d64 1
a64 7

/*
 * Time to delay the ACK.  This is initialized in tcp_init(), unless
 * its patched.
 */
int	tcp_delack_ticks;

d66 1
a66 1
 * Timer state initialization, called from tcp_init().
d69 1
a69 1
tcp_timer_init(void)
d71 2
a72 21

	if (tcp_keepidle == 0)
		tcp_keepidle = TCPTV_KEEP_IDLE;

	if (tcp_keepintvl == 0)
		tcp_keepintvl = TCPTV_KEEPINTVL;

	if (tcp_maxpersistidle == 0)
		tcp_maxpersistidle = TCPTV_KEEP_IDLE;

	if (tcp_delack_ticks == 0)
		tcp_delack_ticks = TCP_DELACK_TICKS;
}

/*
 * Callout to process delayed ACKs for a TCPCB.
 */
void
tcp_delack(void *arg)
{
	struct tcpcb *tp = arg;
a74 6
	/*
	 * If tcp_output() wasn't able to transmit the ACK
	 * for whatever reason, it will restart the delayed
	 * ACK callout.
	 */

d76 12
a87 2
	tp->t_flags |= TF_ACKNOW;
	(void) tcp_output(tp);
d157 1
a157 1
		TCP_TIMER_DISARM(tp, i);
d180 4
a183 2
		q = tp->snd_holes;
		while (q != NULL) {
a184 2
			q = q->next;
			pool_put(&sackhl_pool, p);
d206 1
a206 1
			TCP_TIMER_ARM(tp, TCPT_2MSL, tcp_keepintvl);
d231 1
a231 1
		TCP_TIMER_ARM(tp, TCPT_REXMT, tp->t_rxtcur);
a286 1
				;
d418 1
a418 1
			TCP_TIMER_ARM(tp, TCPT_KEEP, tcp_keepintvl);
d420 1
a420 1
			TCP_TIMER_ARM(tp, TCPT_KEEP, tcp_keepidle);
@


1.16.2.4
log
@Merge in -current from roughly a week ago
@
text
@a70 12
void	tcp_timer_rexmt(void *);
void	tcp_timer_persist(void *);
void	tcp_timer_keep(void *);
void	tcp_timer_2msl(void *);

const tcp_timer_func_t tcp_timer_funcs[TCPT_NTIMERS] = {
	tcp_timer_rexmt,
	tcp_timer_persist,
	tcp_timer_keep,
	tcp_timer_2msl,
};

d120 2
d123 1
d127 31
d166 1
d189 6
a194 1

a195 5
void	tcp_timer_freesack(struct tcpcb *);

void
tcp_timer_freesack(struct tcpcb *tp)
{
d200 13
a212 5
	q = tp->snd_holes;
	while (q != NULL) {
		p = q;
		q = q->next;
		pool_put(&sackhl_pool, p);
a213 7
	tp->snd_holes = 0;
#ifdef TCP_FACK
	tp->snd_fack = tp->snd_una;
	tp->retran_data = 0;
	tp->snd_awnd = 0;
#endif /* TCP_FACK */
}
d216 1
a216 6
void
tcp_timer_rexmt(void *arg)
{
	struct tcpcb *tp = arg;
	uint32_t rto;
	int s;
d218 13
a230 1
	s = splsoftnet();
d232 4
a235 26
#ifdef TCP_SACK
	tcp_timer_freesack(tp);
#endif
	if (++tp->t_rxtshift > TCP_MAXRXTSHIFT) {
		tp->t_rxtshift = TCP_MAXRXTSHIFT;
		tcpstat.tcps_timeoutdrop++;
		tp = tcp_drop(tp, tp->t_softerror ?
		    tp->t_softerror : ETIMEDOUT);
		goto out;
	}
	tcpstat.tcps_rexmttimeo++;
	rto = TCP_REXMTVAL(tp);
	if (rto < tp->t_rttmin)
		rto = tp->t_rttmin;
	TCPT_RANGESET((long) tp->t_rxtcur,
	    rto * tcp_backoff[tp->t_rxtshift],
	    tp->t_rttmin, TCPTV_REXMTMAX);
	TCP_TIMER_ARM(tp, TCPT_REXMT, tp->t_rxtcur);

	/* 
	 * If we are losing and we are trying path MTU discovery,
	 * try turning it off.  This will avoid black holes in
	 * the network which suppress or fail to send "packet
	 * too big" ICMP messages.  We should ideally do
	 * lots more sophisticated searching to find the right
	 * value here...
d237 41
a277 16
	if (ip_mtudisc && tp->t_inpcb &&
	    TCPS_HAVEESTABLISHED(tp->t_state) &&
	    tp->t_rxtshift > TCP_MAXRXTSHIFT / 6) {
		struct inpcb *inp = tp->t_inpcb;
		struct rtentry *rt = NULL;
		struct sockaddr_in sin;

		/* No data to send means path mtu is not a problem */
		if (!inp->inp_socket->so_snd.sb_cc)
			goto leave;

		rt = in_pcbrtentry(inp);
		/* Check if path MTU discovery is disabled already */
		if (rt && (rt->rt_flags & RTF_HOST) &&
		    (rt->rt_rmx.rmx_locks & RTV_MTU))
			goto leave;
d279 2
a280 2
		rt = NULL;
		switch(tp->pf) {
d282 7
a288 7
		case PF_INET6:
			/*
			 * We can not turn off path MTU for IPv6.
			 * Do nothing for now, maybe lower to
			 * minimum MTU.
			 */
			break;
d290 7
a296 13
		case PF_INET:
			bzero(&sin, sizeof(struct sockaddr_in));
			sin.sin_family = AF_INET;
			sin.sin_len = sizeof(struct sockaddr_in);
			sin.sin_addr = inp->inp_faddr;
			rt = icmp_mtudisc_clone(sintosa(&sin));
			break;
		}
		if (rt != NULL) {
			/* Disable path MTU discovery */
			if ((rt->rt_rmx.rmx_locks & RTV_MTU) == 0) {
				rt->rt_rmx.rmx_locks |= RTV_MTU;
				in_rtchange(inp, 0);
d298 6
d305 4
a308 1
			rtfree(rt);
a309 3
	leave:
		;
	}
d311 14
a324 14
	/*
	 * If losing, let the lower level know and try for
	 * a better route.  Also, if we backed off this far,
	 * our srtt estimate is probably bogus.  Clobber it
	 * so we'll take the next rtt measurement as our srtt;
	 * move the current srtt into rttvar to keep the current
	 * retransmit times until then.
	 */
	if (tp->t_rxtshift > TCP_MAXRXTSHIFT / 4) {
		in_losing(tp->t_inpcb);
		tp->t_rttvar += (tp->t_srtt >> TCP_RTT_SHIFT);
		tp->t_srtt = 0;
	}
	tp->snd_nxt = tp->snd_una;
d326 5
a330 5
	/*
	 * Note:  We overload snd_last to function also as the
	 * snd_last variable described in RFC 2582
	 */
	tp->snd_last = tp->snd_max;
d332 29
a360 29
	/*
	 * If timing a segment in this window, stop the timer.
	 */
	tp->t_rtttime = 0;
	/*
	 * Close the congestion window down to one segment
	 * (we'll open it by one segment for each ack we get).
	 * Since we probably have a window's worth of unacked
	 * data accumulated, this "slow start" keeps us from
	 * dumping all that data as back-to-back packets (which
	 * might overwhelm an intermediate gateway).
	 *
	 * There are two phases to the opening: Initially we
	 * open by one mss on each ack.  This makes the window
	 * size increase exponentially with time.  If the
	 * window is larger than the path can handle, this
	 * exponential growth results in dropped packet(s)
	 * almost immediately.  To get more time between 
	 * drops but still "push" the network to take advantage
	 * of improving conditions, we switch from exponential
	 * to linear window opening at some threshhold size.
	 * For a threshhold, we use half the current window
	 * size, truncated to a multiple of the mss.
	 *
	 * (the minimum cwnd that will give us exponential
	 * growth is 2 mss.  We don't allow the threshhold
	 * to go below this.)
	 */
	{
d367 3
a369 2
	}
	(void) tcp_output(tp);
d371 28
a398 10
 out:
	splx(s);
}

void
tcp_timer_persist(void *arg)
{
	struct tcpcb *tp = arg;
	uint32_t rto;
	int s;
a399 2
	s = splsoftnet();
	tcpstat.tcps_persisttimeo++;
d401 2
a402 5
	 * Hack: if the peer is dead/unreachable, we do not
	 * time out if the window is closed.  After a full
	 * backoff, drop the connection if the idle time
	 * (no responses to probes) reaches the maximum
	 * backoff that we would use if retransmitting.
d404 3
a406 33
	rto = TCP_REXMTVAL(tp);
	if (rto < tp->t_rttmin)
		rto = tp->t_rttmin;
	if (tp->t_rxtshift == TCP_MAXRXTSHIFT &&
	    ((tcp_now - tp->t_rcvtime) >= tcp_maxpersistidle ||
	    (tcp_now - tp->t_rcvtime) >= rto * tcp_totbackoff)) {
		tcpstat.tcps_persistdrop++;
		tp = tcp_drop(tp, ETIMEDOUT);
		goto out;
	}
	tcp_setpersist(tp);
	tp->t_force = 1;
	(void) tcp_output(tp);
	tp->t_force = 0;
 out:
	splx(s);
}

void
tcp_timer_keep(void *arg)
{
	struct tcpcb *tp = arg;
	int s;

	s = splsoftnet();

	tcpstat.tcps_keeptimeo++;
	if (TCPS_HAVEESTABLISHED(tp->t_state) == 0)
		goto dropit;
	if (tp->t_inpcb->inp_socket->so_options & SO_KEEPALIVE &&
	    tp->t_state <= TCPS_CLOSING) {
		if ((tcp_maxidle > 0) &&
		    ((tcp_now - tp->t_rcvtime) >= tcp_keepidle + tcp_maxidle))
d408 17
a424 13
		/*
		 * Send a packet designed to force a response
		 * if the peer is up and reachable:
		 * either an ACK if the connection is still alive,
		 * or an RST if the peer has closed the connection
		 * due to timeout or reboot.
		 * Using sequence number tp->snd_una-1
		 * causes the transmitted zero-length segment
		 * to lie outside the receive window;
		 * by the protocol spec, this requires the
		 * correspondent TCP to respond.
		 */
		tcpstat.tcps_keepprobe++;
d426 8
a433 6
		/*
		 * The keepalive packet must have nonzero length
		 * to get a 4.2 host to respond.
		 */
		tcp_respond(tp, mtod(tp->t_template, caddr_t),
		    (struct mbuf *)NULL, tp->rcv_nxt - 1, tp->snd_una - 1, 0);
d435 4
a438 2
		tcp_respond(tp, mtod(tp->t_template, caddr_t),
		    (struct mbuf *)NULL, tp->rcv_nxt, tp->snd_una - 1, 0);
d440 10
a449 33
		TCP_TIMER_ARM(tp, TCPT_KEEP, tcp_keepintvl);
	} else
		TCP_TIMER_ARM(tp, TCPT_KEEP, tcp_keepidle);

	splx(s);
	return;

 dropit:
	tcpstat.tcps_keepdrops++;
	tp = tcp_drop(tp, ETIMEDOUT);

	splx(s);
}

void
tcp_timer_2msl(void *arg)
{
	struct tcpcb *tp = arg;
	int s;

	s = splsoftnet();

#ifdef TCP_SACK
	tcp_timer_freesack(tp);
#endif

	if (tp->t_state != TCPS_TIME_WAIT &&
	    ((tcp_maxidle == 0) || ((tcp_now - tp->t_rcvtime) <= tcp_maxidle)))
		TCP_TIMER_ARM(tp, TCPT_2MSL, tcp_keepintvl);
	else
		tp = tcp_close(tp);

	splx(s);
d451 1
@


1.16.2.5
log
@Sync the SMP branch with 3.3
@
text
@d207 1
a207 1
		(void)tcp_drop(tp, tp->t_softerror ?
d220 1
a220 1
	/*
a301 9
#ifdef TCP_ECN
	/*
	 * if ECN is enabled, there might be a broken firewall which
	 * blocks ecn packets.  fall back to non-ecn.
	 */
	if ((tp->t_state == TCPS_SYN_SENT || tp->t_state == TCPS_SYN_RECEIVED)
	    && tcp_do_ecn && !(tp->t_flags & TF_DISABLE_ECN))
		tp->t_flags |= TF_DISABLE_ECN;
#endif
d315 1
a315 1
	 * almost immediately.  To get more time between
a332 7
#ifdef TCP_ECN
		tp->snd_last = tp->snd_max;
		tp->t_flags |= TF_SEND_CWR;
#endif
#if 1 /* TCP_ECN */
		tcpstat.tcps_cwr_timeout++;
#endif
@


1.16.2.6
log
@Sync SMP branch to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.16.2.5 2003/03/28 00:06:55 niklas Exp $	*/
d16 5
a20 1
 * 3. Neither the name of the University nor the names of its contributors
@


1.16.2.7
log
@Merge of current from two weeks agointo the SMP branch
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d148 1
a148 1
	int i;
@


1.15
log
@Fix tcp retransmit/persist timers, provos@@ OK.

Adapted from NetBSD:
    Fix a retransmission bug introduced by the Brakmo and Peterson
    RTO estimation changes.  Under some circumstances it would
    return a value of 0, while the old Van Jacobson RTO code would
    return a minimum of 3.  This would result in 12 retransmissions,
    each 1 second apart.  This takes care of those instances, and
    ensures that t_rttmin is used everywhere as a lower bound.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.14 1999/09/01 21:38:21 provos Exp $	*/
d253 1
a253 1
#if defined(TCP_SACK) || defined(TCP_NEWRENO)
d259 1
a259 1
#endif /* TCP_SACK or TCP_NEWRENO */
@


1.14
log
@increase tcp_iss increment
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.13 1999/07/02 20:39:08 cmetz Exp $	*/
d180 1
a180 1
	register int rexmt;
d232 5
a236 2
		rexmt = TCP_REXMTVAL(tp) * tcp_backoff[tp->t_rxtshift];
		TCPT_RANGESET((long) tp->t_rxtcur, rexmt,
d312 3
d317 1
a317 1
		     tp->t_idle >= TCP_REXMTVAL(tp) * tcp_totbackoff)) {
@


1.13
log
@Significant cleanups in the way TCP is made to handle multiple network
protocols.

"struct tcpiphdr" is now gone from much of the code, as are separate pointers
for ti and ti6. The result is fewer variables, which is generally a good thing.

Simple if(is_ipv6) ... else ... tests are gone in favor of a
switch(protocol family), which allows future new protocols to be added easily.
This also makes it possible for someone so inclined to re-implement TUBA (TCP
over CLNP?) and do it right instead of the kluged way it was done in 4.4.

The TCP header template is now referenced through a mbuf rather than done
through a data pointer and dtom()ed as needed. This is partly because dtom() is
evil and partly because max_linkhdr + IPv6 + TCP + MSS/TS/SACK opts won't fit
inside a packet header mbuf, so we need to grab a cluster for that (which the
code now does, if needed).
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.12 1999/04/21 21:38:58 provos Exp $	*/
d147 1
a147 1
	tcp_iss += arc4random() % (TCP_ISSINCR / PR_SLOWHZ) + 1; /* increment iss */
@


1.12
log
@From Tom Henderson <tomh@@cs.berkeley.edu>:

Fixed a sequence wraparound bug in the snd_recover variable discovered in
very large (multiple GByte) transfers (in loss free conditions, snd_recover
was not sufficiently tracking snd_una).  Thanks to Mark Smith for finding
this.

Fixed a bug in tcp_newreno that was preventing retransmission of data due
to partial acks. (Discovered by Jayanth Vijayaraghavan)
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.11 1999/01/27 16:47:29 provos Exp $	*/
d352 4
a355 2
			tcp_respond(tp, tp->t_template, (struct mbuf *)NULL,
			    tp->rcv_nxt - 1, tp->snd_una - 1, 0);
d357 4
a360 2
			tcp_respond(tp, tp->t_template, (struct mbuf *)NULL,
			    tp->rcv_nxt, tp->snd_una - 1, 0);
@


1.11
log
@fix NEWRENO behaviour, the newreo code assumed that the send socket buffer has
already been cleared of the acked data, though it was called before any
sbdrop() call and always called tcp_output() with 0 index in the send
socket buffer and thus causing data corruption. so do not set snd_una to
th_ack.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.10 1998/11/25 05:44:37 millert Exp $	*/
d250 7
@


1.10
log
@more min vs. ulmin/lmin fixes
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.9 1998/11/17 19:23:02 provos Exp $	*/
a249 3
#if defined (TCP_NEWRENO) || defined (TCP_SACK)
		tp->snd_last = tp->snd_una;
#endif
@


1.9
log
@NewReno, SACK and FACK support for TCP, adapted from code for BSDI
by Hari Balakrishnan (hari@@lcs.mit.edu), Tom Henderson (tomh@@cs.berkeley.edu)
and Venkat Padmanabhan (padmanab@@cs.berkeley.edu) as part of the
Daedalus research group at the University of California,
(http://daedalus.cs.berkeley.edu). [I was able to do this on time spent
at the Center for Information Technology Integration (citi.umich.edu)]
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.8 1997/08/26 20:02:34 deraadt Exp $	*/
d282 1
a282 1
		u_int win = min(tp->snd_wnd, tp->snd_cwnd) / 2 / tp->t_maxseg;
@


1.8
log
@indent
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.7 1997/02/05 15:48:26 deraadt Exp $	*/
d181 20
d250 3
@


1.7
log
@use arc4random()
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.6 1996/09/12 06:19:57 tholo Exp $	*/
d305 1
a305 1
		    	if (tp->t_idle >= tcp_keepidle + tcp_maxidle)
@


1.6
log
@TCP Persist handling; from 4.4BSD Lite2 (via NetBSD PR 2335)
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.5 1996/07/29 22:01:51 niklas Exp $	*/
d63 1
d147 1
a147 1
	tcp_iss += random() % (TCP_ISSINCR / PR_SLOWHZ) + 1; /* increment iss */
@


1.5
log
@Remove random() prototype, as it's not needed.  Besides it was wrong for the alpha :-)
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.4 1996/07/29 06:22:14 tholo Exp $	*/
d66 1
d169 2
d274 14
@


1.4
log
@Make TCP ISS increment by random amounts
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.3 1996/03/14 08:09:49 tholo Exp $	*/
a101 3
#ifndef TCP_COMPAT_42
	u_int random __P((void));
#endif /* !TCP_COMPAT_42 */
@


1.3
log
@From Lite2; skip slow start calculation if socket state is listen
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_timer.c,v 1.2 1996/03/03 22:30:48 niklas Exp $	*/
d102 3
d143 1
a144 1
#ifdef TCP_COMPAT_42
d147 3
a149 1
#endif
@


1.2
log
@From NetBSD: 960217 merge
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d120 1
a120 1
		if (tp == 0)
@


1.1
log
@Initial revision
@
text
@d1 2
a2 1
/*	$NetBSD: tcp_timer.c,v 1.13 1995/08/12 23:59:39 mycroft Exp $	*/
d207 1
a207 1
		TCPT_RANGESET(tp->t_rxtcur, rexmt,
@


1.1.1.1
log
@initial import of NetBSD tree
@
text
@@
