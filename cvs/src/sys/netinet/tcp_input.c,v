head	1.341;
access;
symbols
	OPENBSD_6_1:1.338.0.4
	OPENBSD_6_1_BASE:1.338
	OPENBSD_6_0:1.325.0.4
	OPENBSD_6_0_BASE:1.325
	OPENBSD_5_9:1.313.0.2
	OPENBSD_5_9_BASE:1.313
	OPENBSD_5_8:1.297.0.4
	OPENBSD_5_8_BASE:1.297
	OPENBSD_5_7:1.287.0.2
	OPENBSD_5_7_BASE:1.287
	OPENBSD_5_6:1.278.0.4
	OPENBSD_5_6_BASE:1.278
	OPENBSD_5_5:1.272.0.4
	OPENBSD_5_5_BASE:1.272
	OPENBSD_5_4:1.265.0.2
	OPENBSD_5_4_BASE:1.265
	OPENBSD_5_3:1.255.0.2
	OPENBSD_5_3_BASE:1.255
	OPENBSD_5_2:1.253.0.2
	OPENBSD_5_2_BASE:1.253
	OPENBSD_5_1_BASE:1.251
	OPENBSD_5_1:1.251.0.2
	OPENBSD_5_0:1.250.0.2
	OPENBSD_5_0_BASE:1.250
	OPENBSD_4_9:1.240.0.2
	OPENBSD_4_9_BASE:1.240
	OPENBSD_4_8:1.235.0.2
	OPENBSD_4_8_BASE:1.235
	OPENBSD_4_7:1.232.0.2
	OPENBSD_4_7_BASE:1.232
	OPENBSD_4_6:1.226.0.4
	OPENBSD_4_6_BASE:1.226
	OPENBSD_4_5:1.224.0.2
	OPENBSD_4_5_BASE:1.224
	OPENBSD_4_4:1.220.0.2
	OPENBSD_4_4_BASE:1.220
	OPENBSD_4_3:1.212.0.2
	OPENBSD_4_3_BASE:1.212
	OPENBSD_4_2:1.207.0.2
	OPENBSD_4_2_BASE:1.207
	OPENBSD_4_1:1.201.0.2
	OPENBSD_4_1_BASE:1.201
	OPENBSD_4_0:1.196.0.2
	OPENBSD_4_0_BASE:1.196
	OPENBSD_3_9:1.195.0.2
	OPENBSD_3_9_BASE:1.195
	OPENBSD_3_8:1.190.0.2
	OPENBSD_3_8_BASE:1.190
	OPENBSD_3_7:1.185.0.2
	OPENBSD_3_7_BASE:1.185
	OPENBSD_3_6:1.175.0.2
	OPENBSD_3_6_BASE:1.175
	SMP_SYNC_A:1.172
	SMP_SYNC_B:1.172
	OPENBSD_3_5:1.158.0.2
	OPENBSD_3_5_BASE:1.158
	OPENBSD_3_4:1.132.0.2
	OPENBSD_3_4_BASE:1.132
	UBC_SYNC_A:1.126
	OPENBSD_3_3:1.125.0.2
	OPENBSD_3_3_BASE:1.125
	OPENBSD_3_2:1.124.0.2
	OPENBSD_3_2_BASE:1.124
	OPENBSD_3_1:1.110.0.2
	OPENBSD_3_1_BASE:1.110
	UBC_SYNC_B:1.124
	UBC:1.100.0.4
	UBC_BASE:1.100
	OPENBSD_3_0:1.100.0.2
	OPENBSD_3_0_BASE:1.100
	OPENBSD_2_9_BASE:1.84
	OPENBSD_2_9:1.84.0.2
	OPENBSD_2_8:1.79.0.2
	OPENBSD_2_8_BASE:1.79
	OPENBSD_2_7:1.60.0.2
	OPENBSD_2_7_BASE:1.60
	SMP:1.56.0.2
	SMP_BASE:1.56
	kame_19991208:1.52
	OPENBSD_2_6:1.49.0.2
	OPENBSD_2_6_BASE:1.49
	OPENBSD_2_5:1.33.0.2
	OPENBSD_2_5_BASE:1.33
	OPENBSD_2_4:1.19.0.2
	OPENBSD_2_4_BASE:1.19
	OPENBSD_2_3:1.18.0.2
	OPENBSD_2_3_BASE:1.18
	OPENBSD_2_2:1.15.0.2
	OPENBSD_2_2_BASE:1.15
	OPENBSD_2_1:1.10.0.2
	OPENBSD_2_1_BASE:1.10
	OPENBSD_2_0:1.8.0.2
	OPENBSD_2_0_BASE:1.8
	netbsd_1_1:1.1.1.1;
locks; strict;
comment	@ * @;


1.341
date	2017.04.19.15.21.54;	author bluhm;	state Exp;
branches;
next	1.340;
commitid	86fZyVCZMRPZ29Fb;

1.340
date	2017.04.17.20.59.35;	author bluhm;	state Exp;
branches;
next	1.339;
commitid	6BVvUvIoqvGuYI1O;

1.339
date	2017.04.14.20.46.31;	author bluhm;	state Exp;
branches;
next	1.338;
commitid	00hB28wQPwG5Ysk0;

1.338
date	2017.02.09.15.19.32;	author jca;	state Exp;
branches;
next	1.337;
commitid	Hew5AYIxyEp5lNbI;

1.337
date	2017.01.29.19.58.47;	author bluhm;	state Exp;
branches;
next	1.336;
commitid	3e3CkrbYekyVOcxy;

1.336
date	2017.01.25.17.34.31;	author bluhm;	state Exp;
branches;
next	1.335;
commitid	pVtptbHA3yk4jSpN;

1.335
date	2017.01.10.09.01.18;	author mpi;	state Exp;
branches;
next	1.334;
commitid	xP9gcRskiS0BKnO6;

1.334
date	2016.12.19.08.36.49;	author mpi;	state Exp;
branches;
next	1.333;
commitid	QqHqT2WhCBWqYgGJ;

1.333
date	2016.11.16.14.11.26;	author mpi;	state Exp;
branches;
next	1.332;
commitid	BWcsCkPTStI42BHZ;

1.332
date	2016.11.16.08.50.32;	author mpi;	state Exp;
branches;
next	1.331;
commitid	1FZaHsMsvSO8gmsb;

1.331
date	2016.11.15.14.30.59;	author mpi;	state Exp;
branches;
next	1.330;
commitid	wxBQoju8vnbGAXQA;

1.330
date	2016.11.07.09.08.05;	author mpi;	state Exp;
branches;
next	1.329;
commitid	A6se4kFGvoRfJVfQ;

1.329
date	2016.10.04.13.56.50;	author mpi;	state Exp;
branches;
next	1.328;
commitid	saVELWRdlFByKEpt;

1.328
date	2016.09.19.16.06.25;	author bluhm;	state Exp;
branches;
next	1.327;
commitid	GyfKDWEpuTbsKJ59;

1.327
date	2016.09.15.02.00.18;	author dlg;	state Exp;
branches;
next	1.326;
commitid	RlO92XR575sygHqm;

1.326
date	2016.08.31.11.05.05;	author mpi;	state Exp;
branches;
next	1.325;
commitid	QNqLEcGCOZiHMKm4;

1.325
date	2016.07.20.09.15.28;	author bluhm;	state Exp;
branches;
next	1.324;
commitid	Qwlx91wnD3EO5HU6;

1.324
date	2016.07.01.18.37.15;	author jca;	state Exp;
branches;
next	1.323;
commitid	hgakYExJTBQa1YMy;

1.323
date	2016.06.27.20.57.41;	author jca;	state Exp;
branches;
next	1.322;
commitid	COKcOW0DSkzcKmDk;

1.322
date	2016.06.27.16.33.48;	author jca;	state Exp;
branches;
next	1.321;
commitid	s8BpQvqrMutiVjd6;

1.321
date	2016.06.27.15.59.51;	author bluhm;	state Exp;
branches;
next	1.320;
commitid	7m92ozFuOTF4OCaY;

1.320
date	2016.06.27.12.25.27;	author bluhm;	state Exp;
branches;
next	1.319;
commitid	5PT2ZUcqPK0OiFyW;

1.319
date	2016.06.09.23.09.51;	author bluhm;	state Exp;
branches;
next	1.318;
commitid	YdXCSgtyexyGdHnC;

1.318
date	2016.03.31.13.11.14;	author bluhm;	state Exp;
branches;
next	1.317;
commitid	tJ301TPcLUrpqvGu;

1.317
date	2016.03.29.18.13.20;	author bluhm;	state Exp;
branches;
next	1.316;
commitid	m1S5Qx2z8077Jh3c;

1.316
date	2016.03.27.19.19.01;	author bluhm;	state Exp;
branches;
next	1.315;
commitid	b8ii6TWWipjoxZhr;

1.315
date	2016.03.21.15.52.27;	author bluhm;	state Exp;
branches;
next	1.314;
commitid	7wNIPXOo0aTQzUHP;

1.314
date	2016.03.07.18.44.00;	author naddy;	state Exp;
branches;
next	1.313;
commitid	Z6e4eqr6FuYFPnlL;

1.313
date	2016.01.22.11.10.17;	author jsg;	state Exp;
branches;
next	1.312;
commitid	ff8KduQI7uZAaZXD;

1.312
date	2015.12.05.10.52.26;	author tedu;	state Exp;
branches;
next	1.311;
commitid	e5lGxAXE14M3fHuG;

1.311
date	2015.12.03.14.05.28;	author bluhm;	state Exp;
branches;
next	1.310;
commitid	Qo1JIwCdJHaA2LFI;

1.310
date	2015.11.29.15.09.32;	author mpi;	state Exp;
branches;
next	1.309;
commitid	9QYkqF8iLehm1Jfc;

1.309
date	2015.11.20.10.45.29;	author mpi;	state Exp;
branches;
next	1.308;
commitid	w6KS0uSMQTOlxUSs;

1.308
date	2015.11.06.11.20.56;	author mpi;	state Exp;
branches;
next	1.307;
commitid	oU39GoDixhmOhYXK;

1.307
date	2015.10.28.12.14.25;	author florian;	state Exp;
branches;
next	1.306;
commitid	Ajb0hNGeCqGFHjjg;

1.306
date	2015.10.24.16.08.48;	author mpi;	state Exp;
branches;
next	1.305;
commitid	xFxvBxiFybIsZNMc;

1.305
date	2015.09.11.08.17.06;	author claudio;	state Exp;
branches;
next	1.304;
commitid	Cr0DVA7exR1t2zXg;

1.304
date	2015.09.10.13.36.44;	author bluhm;	state Exp;
branches;
next	1.303;
commitid	bocjY5lXYJWyweqe;

1.303
date	2015.09.10.08.40.23;	author claudio;	state Exp;
branches;
next	1.302;
commitid	pJLw2zyoYX7OIUrV;

1.302
date	2015.08.27.20.56.16;	author bluhm;	state Exp;
branches;
next	1.301;
commitid	Dj0fqkE649GFzkeR;

1.301
date	2015.08.24.23.31.35;	author bluhm;	state Exp;
branches;
next	1.300;
commitid	tV1xrGxPupq6bXiA;

1.300
date	2015.08.24.15.37.03;	author bluhm;	state Exp;
branches;
next	1.299;
commitid	iKqcQwl3eIXo4smF;

1.299
date	2015.08.13.23.42.16;	author bluhm;	state Exp;
branches;
next	1.298;
commitid	2VGUl14uIMGVwSfv;

1.298
date	2015.08.13.14.59.13;	author bluhm;	state Exp;
branches;
next	1.297;
commitid	bUlcXgVREdJExlCy;

1.297
date	2015.07.16.16.12.15;	author mpi;	state Exp;
branches;
next	1.296;
commitid	STtcOm1B3VSMXz2h;

1.296
date	2015.07.15.22.16.42;	author deraadt;	state Exp;
branches;
next	1.295;
commitid	ncpqEGjDtSFuLAgn;

1.295
date	2015.07.10.22.07.48;	author bluhm;	state Exp;
branches;
next	1.294;
commitid	TVPS8V0JkTJbY68I;

1.294
date	2015.07.09.05.45.25;	author mpi;	state Exp;
branches;
next	1.293;
commitid	3lzuz5T7djZWDJfj;

1.293
date	2015.06.16.11.09.40;	author mpi;	state Exp;
branches;
next	1.292;
commitid	h7z8lokZ0dFyuWpg;

1.292
date	2015.06.07.12.02.28;	author jsg;	state Exp;
branches;
next	1.291;
commitid	st7eUqjf7vKTD48M;

1.291
date	2015.06.07.01.25.27;	author krw;	state Exp;
branches;
next	1.290;
commitid	7yzARhkDkBsYwsVv;

1.290
date	2015.05.13.10.42.46;	author jsg;	state Exp;
branches;
next	1.289;
commitid	hN5bFCE56DrAjl99;

1.289
date	2015.04.16.19.24.13;	author markus;	state Exp;
branches;
next	1.288;
commitid	2c41FFL8044mZVko;

1.288
date	2015.04.14.12.22.15;	author mikeb;	state Exp;
branches;
next	1.287;
commitid	bQi1IVHgugweH5gs;

1.287
date	2015.02.08.04.40.50;	author yasuoka;	state Exp;
branches;
next	1.286;
commitid	v0TRBcxZUQjo1nf8;

1.286
date	2014.12.19.17.14.40;	author tedu;	state Exp;
branches;
next	1.285;
commitid	zhW8jJrfVCoAthrR;

1.285
date	2014.12.05.15.50.04;	author mpi;	state Exp;
branches;
next	1.284;
commitid	t9FBKDfc4VDxpEy2;

1.284
date	2014.11.20.11.05.19;	author mpi;	state Exp;
branches;
next	1.283;
commitid	uo0PiO5ELdW7V3PO;

1.283
date	2014.11.18.02.37.31;	author tedu;	state Exp;
branches;
next	1.282;
commitid	Z1vcFtHO8wRH0yRt;

1.282
date	2014.11.04.15.24.40;	author mpi;	state Exp;
branches;
next	1.281;
commitid	7WMzGcppcCD2uLp0;

1.281
date	2014.10.24.17.58.47;	author bluhm;	state Exp;
branches;
next	1.280;
commitid	rw0LFInBtsgc28MT;

1.280
date	2014.10.14.09.52.26;	author mpi;	state Exp;
branches;
next	1.279;
commitid	6AYfDT0Lpez1LFQp;

1.279
date	2014.10.08.20.19.58;	author bluhm;	state Exp;
branches;
next	1.278;
commitid	UNVF0RF6IIJluFMm;

1.278
date	2014.07.22.11.06.10;	author mpi;	state Exp;
branches;
next	1.277;
commitid	DQakU8LLWV6Iwx84;

1.277
date	2014.07.11.13.15.34;	author bluhm;	state Exp;
branches;
next	1.276;
commitid	ViJ6P85Sj939uDH4;

1.276
date	2014.04.25.09.44.38;	author mpi;	state Exp;
branches;
next	1.275;

1.275
date	2014.04.21.12.22.26;	author henning;	state Exp;
branches;
next	1.274;

1.274
date	2014.04.21.11.10.54;	author henning;	state Exp;
branches;
next	1.273;

1.273
date	2014.04.14.09.06.42;	author mpi;	state Exp;
branches;
next	1.272;

1.272
date	2014.01.24.18.54.58;	author henning;	state Exp;
branches;
next	1.271;

1.271
date	2014.01.23.23.51.29;	author henning;	state Exp;
branches;
next	1.270;

1.270
date	2014.01.07.17.07.45;	author mikeb;	state Exp;
branches;
next	1.269;

1.269
date	2013.10.20.11.03.01;	author phessler;	state Exp;
branches;
next	1.268;

1.268
date	2013.09.06.18.35.16;	author bluhm;	state Exp;
branches;
next	1.267;

1.267
date	2013.08.13.09.52.53;	author mpi;	state Exp;
branches;
next	1.266;

1.266
date	2013.07.31.15.41.52;	author mikeb;	state Exp;
branches;
next	1.265;

1.265
date	2013.07.01.10.53.52;	author bluhm;	state Exp;
branches;
next	1.264;

1.264
date	2013.06.20.20.21.20;	author mikeb;	state Exp;
branches;
next	1.263;

1.263
date	2013.06.09.22.03.06;	author yasuoka;	state Exp;
branches;
next	1.262;

1.262
date	2013.06.03.16.57.05;	author bluhm;	state Exp;
branches;
next	1.261;

1.261
date	2013.06.03.13.19.08;	author bluhm;	state Exp;
branches;
next	1.260;

1.260
date	2013.04.10.08.50.59;	author mpi;	state Exp;
branches;
next	1.259;

1.259
date	2013.04.02.18.27.47;	author bluhm;	state Exp;
branches;
next	1.258;

1.258
date	2013.03.29.13.16.14;	author bluhm;	state Exp;
branches;
next	1.257;

1.257
date	2013.03.28.23.10.06;	author tedu;	state Exp;
branches;
next	1.256;

1.256
date	2013.03.14.11.18.37;	author mpi;	state Exp;
branches;
next	1.255;

1.255
date	2013.01.17.11.43.06;	author bluhm;	state Exp;
branches;
next	1.254;

1.254
date	2013.01.17.00.48.04;	author henning;	state Exp;
branches;
next	1.253;

1.253
date	2012.07.16.18.05.36;	author markus;	state Exp;
branches;
next	1.252;

1.252
date	2012.03.10.12.03.29;	author claudio;	state Exp;
branches;
next	1.251;

1.251
date	2011.10.15.18.56.52;	author haesbaert;	state Exp;
branches;
next	1.250;

1.250
date	2011.05.13.14.31.16;	author oga;	state Exp;
branches;
next	1.249;

1.249
date	2011.05.04.08.20.05;	author blambert;	state Exp;
branches;
next	1.248;

1.248
date	2011.04.29.06.28.21;	author blambert;	state Exp;
branches;
next	1.247;

1.247
date	2011.04.28.09.56.27;	author claudio;	state Exp;
branches;
next	1.246;

1.246
date	2011.04.24.19.36.54;	author bluhm;	state Exp;
branches;
next	1.245;

1.245
date	2011.04.12.10.47.29;	author mikeb;	state Exp;
branches;
next	1.244;

1.244
date	2011.04.05.18.16.07;	author blambert;	state Exp;
branches;
next	1.243;

1.243
date	2011.04.04.23.04.18;	author blambert;	state Exp;
branches;
next	1.242;

1.242
date	2011.04.04.22.25.24;	author blambert;	state Exp;
branches;
next	1.241;

1.241
date	2011.04.04.13.56.11;	author blambert;	state Exp;
branches;
next	1.240;

1.240
date	2011.01.07.17.50.42;	author bluhm;	state Exp;
branches;
next	1.239;

1.239
date	2010.09.29.19.42.11;	author claudio;	state Exp;
branches;
next	1.238;

1.238
date	2010.09.29.18.00.19;	author claudio;	state Exp;
branches;
next	1.237;

1.237
date	2010.09.29.08.18.23;	author claudio;	state Exp;
branches;
next	1.236;

1.236
date	2010.09.24.02.59.45;	author claudio;	state Exp;
branches;
next	1.235;

1.235
date	2010.07.20.15.36.03;	author matthew;	state Exp;
branches;
next	1.234;

1.234
date	2010.07.09.16.58.06;	author reyk;	state Exp;
branches;
next	1.233;

1.233
date	2010.07.03.04.44.51;	author guenther;	state Exp;
branches;
next	1.232;

1.232
date	2010.03.11.00.24.58;	author sthen;	state Exp;
branches;
next	1.231;

1.231
date	2010.01.15.18.20.23;	author chl;	state Exp;
branches;
next	1.230;

1.230
date	2009.11.13.20.54.05;	author claudio;	state Exp;
branches;
next	1.229;

1.229
date	2009.11.03.10.59.04;	author claudio;	state Exp;
branches;
next	1.228;

1.228
date	2009.08.20.13.25.42;	author bluhm;	state Exp;
branches;
next	1.227;

1.227
date	2009.08.10.10.13.43;	author claudio;	state Exp;
branches;
next	1.226;

1.226
date	2009.06.05.00.05.22;	author claudio;	state Exp;
branches;
next	1.225;

1.225
date	2009.06.03.18.22.44;	author naddy;	state Exp;
branches;
next	1.224;

1.224
date	2008.11.02.10.37.29;	author claudio;	state Exp;
branches;
next	1.223;

1.223
date	2008.10.10.20.03.42;	author dhill;	state Exp;
branches;
next	1.222;

1.222
date	2008.10.10.15.35.59;	author dhill;	state Exp;
branches;
next	1.221;

1.221
date	2008.09.09.15.26.12;	author mpf;	state Exp;
branches;
next	1.220;

1.220
date	2008.07.03.15.46.24;	author henning;	state Exp;
branches
	1.220.2.1;
next	1.219;

1.219
date	2008.06.14.22.15.30;	author jsing;	state Exp;
branches;
next	1.218;

1.218
date	2008.06.12.15.13.47;	author jsing;	state Exp;
branches;
next	1.217;

1.217
date	2008.06.12.15.08.47;	author jsing;	state Exp;
branches;
next	1.216;

1.216
date	2008.06.12.14.50.20;	author jsing;	state Exp;
branches;
next	1.215;

1.215
date	2008.05.15.19.40.38;	author markus;	state Exp;
branches;
next	1.214;

1.214
date	2008.05.09.02.44.54;	author markus;	state Exp;
branches;
next	1.213;

1.213
date	2008.05.06.08.47.35;	author markus;	state Exp;
branches;
next	1.212;

1.212
date	2008.02.20.11.24.02;	author markus;	state Exp;
branches;
next	1.211;

1.211
date	2008.02.11.18.03.16;	author bluhm;	state Exp;
branches;
next	1.210;

1.210
date	2007.11.27.17.23.23;	author deraadt;	state Exp;
branches;
next	1.209;

1.209
date	2007.11.27.16.22.13;	author martynas;	state Exp;
branches;
next	1.208;

1.208
date	2007.09.01.18.49.28;	author henning;	state Exp;
branches;
next	1.207;

1.207
date	2007.06.15.18.23.06;	author markus;	state Exp;
branches
	1.207.2.1;
next	1.206;

1.206
date	2007.06.11.11.29.35;	author henning;	state Exp;
branches;
next	1.205;

1.205
date	2007.06.01.00.52.38;	author henning;	state Exp;
branches;
next	1.204;

1.204
date	2007.05.27.21.37.53;	author deraadt;	state Exp;
branches;
next	1.203;

1.203
date	2007.05.27.20.20.54;	author dlg;	state Exp;
branches;
next	1.202;

1.202
date	2007.05.22.10.20.55;	author michele;	state Exp;
branches;
next	1.201;

1.201
date	2007.02.13.06.39.50;	author itojun;	state Exp;
branches
	1.201.2.1;
next	1.200;

1.200
date	2006.12.11.21.31.58;	author markus;	state Exp;
branches;
next	1.199;

1.199
date	2006.12.05.12.04.36;	author henning;	state Exp;
branches;
next	1.198;

1.198
date	2006.10.31.16.22.25;	author markus;	state Exp;
branches;
next	1.197;

1.197
date	2006.10.11.09.34.51;	author henning;	state Exp;
branches;
next	1.196;

1.196
date	2006.03.12.18.42.40;	author markus;	state Exp;
branches
	1.196.2.1;
next	1.195;

1.195
date	2006.02.26.17.50.45;	author markus;	state Exp;
branches
	1.195.2.1;
next	1.194;

1.194
date	2005.12.01.22.31.50;	author markus;	state Exp;
branches;
next	1.193;

1.193
date	2005.11.15.21.09.45;	author miod;	state Exp;
branches;
next	1.192;

1.192
date	2005.11.02.22.17.20;	author markus;	state Exp;
branches;
next	1.191;

1.191
date	2005.10.17.08.43.34;	author henning;	state Exp;
branches;
next	1.190;

1.190
date	2005.08.11.11.39.36;	author markus;	state Exp;
branches;
next	1.189;

1.189
date	2005.08.02.11.05.44;	author markus;	state Exp;
branches;
next	1.188;

1.188
date	2005.06.30.08.51.31;	author markus;	state Exp;
branches;
next	1.187;

1.187
date	2005.04.25.17.55.52;	author brad;	state Exp;
branches;
next	1.186;

1.186
date	2005.04.05.20.27.35;	author markus;	state Exp;
branches;
next	1.185;

1.185
date	2005.03.12.08.07.09;	author markus;	state Exp;
branches;
next	1.184;

1.184
date	2005.03.09.11.14.37;	author markus;	state Exp;
branches;
next	1.183;

1.183
date	2005.03.04.13.21.42;	author markus;	state Exp;
branches;
next	1.182;

1.182
date	2005.02.27.13.22.56;	author markus;	state Exp;
branches;
next	1.181;

1.181
date	2005.01.10.23.53.49;	author mcbride;	state Exp;
branches;
next	1.180;

1.180
date	2004.12.30.01.30.30;	author deraadt;	state Exp;
branches;
next	1.179;

1.179
date	2004.12.29.17.17.28;	author markus;	state Exp;
branches;
next	1.178;

1.178
date	2004.11.25.15.32.08;	author markus;	state Exp;
branches;
next	1.177;

1.177
date	2004.10.28.19.22.52;	author mcbride;	state Exp;
branches;
next	1.176;

1.176
date	2004.09.22.21.33.53;	author deraadt;	state Exp;
branches;
next	1.175;

1.175
date	2004.07.16.09.26.07;	author markus;	state Exp;
branches
	1.175.2.1;
next	1.174;

1.174
date	2004.06.20.18.16.50;	author itojun;	state Exp;
branches;
next	1.173;

1.173
date	2004.06.14.08.26.49;	author dhartmei;	state Exp;
branches;
next	1.172;

1.172
date	2004.06.08.19.47.24;	author markus;	state Exp;
branches;
next	1.171;

1.171
date	2004.05.31.11.02.11;	author markus;	state Exp;
branches;
next	1.170;

1.170
date	2004.05.27.08.17.31;	author markus;	state Exp;
branches;
next	1.169;

1.169
date	2004.05.26.22.47.40;	author markus;	state Exp;
branches;
next	1.168;

1.168
date	2004.05.21.11.36.23;	author markus;	state Exp;
branches;
next	1.167;

1.167
date	2004.05.07.14.42.27;	author millert;	state Exp;
branches;
next	1.166;

1.166
date	2004.05.04.22.50.18;	author claudio;	state Exp;
branches;
next	1.165;

1.165
date	2004.04.26.18.12.25;	author frantzen;	state Exp;
branches;
next	1.164;

1.164
date	2004.04.20.20.05.29;	author markus;	state Exp;
branches;
next	1.163;

1.163
date	2004.04.15.12.05.34;	author grange;	state Exp;
branches;
next	1.162;

1.162
date	2004.04.15.02.59.22;	author itojun;	state Exp;
branches;
next	1.161;

1.161
date	2004.04.14.20.46.50;	author markus;	state Exp;
branches;
next	1.160;

1.160
date	2004.04.12.14.17.55;	author markus;	state Exp;
branches;
next	1.159;

1.159
date	2004.04.04.17.39.07;	author deraadt;	state Exp;
branches;
next	1.158;

1.158
date	2004.03.17.11.42.29;	author markus;	state Exp;
branches
	1.158.2.1;
next	1.157;

1.157
date	2004.03.02.12.51.12;	author markus;	state Exp;
branches;
next	1.156;

1.156
date	2004.02.27.16.44.44;	author markus;	state Exp;
branches;
next	1.155;

1.155
date	2004.02.11.20.12.33;	author markus;	state Exp;
branches;
next	1.154;

1.154
date	2004.02.10.10.30.24;	author markus;	state Exp;
branches;
next	1.153;

1.153
date	2004.02.05.04.23.13;	author itojun;	state Exp;
branches;
next	1.152;

1.152
date	2004.01.31.19.40.09;	author markus;	state Exp;
branches;
next	1.151;

1.151
date	2004.01.29.17.02.56;	author markus;	state Exp;
branches;
next	1.150;

1.150
date	2004.01.29.13.30.18;	author markus;	state Exp;
branches;
next	1.149;

1.149
date	2004.01.29.11.55.28;	author markus;	state Exp;
branches;
next	1.148;

1.148
date	2004.01.29.10.06.21;	author markus;	state Exp;
branches;
next	1.147;

1.147
date	2004.01.22.14.38.28;	author markus;	state Exp;
branches;
next	1.146;

1.146
date	2004.01.15.17.04.59;	author markus;	state Exp;
branches;
next	1.145;

1.145
date	2004.01.15.09.46.21;	author markus;	state Exp;
branches;
next	1.144;

1.144
date	2004.01.14.13.38.21;	author markus;	state Exp;
branches;
next	1.143;

1.143
date	2004.01.13.13.26.14;	author markus;	state Exp;
branches;
next	1.142;

1.142
date	2004.01.13.09.22.52;	author markus;	state Exp;
branches;
next	1.141;

1.141
date	2004.01.09.12.31.44;	author markus;	state Exp;
branches;
next	1.140;

1.140
date	2004.01.07.20.48.10;	author markus;	state Exp;
branches;
next	1.139;

1.139
date	2004.01.07.09.08.54;	author itojun;	state Exp;
branches;
next	1.138;

1.138
date	2004.01.06.17.38.12;	author markus;	state Exp;
branches;
next	1.137;

1.137
date	2003.12.21.14.50.04;	author markus;	state Exp;
branches;
next	1.136;

1.136
date	2003.12.08.10.48.57;	author markus;	state Exp;
branches;
next	1.135;

1.135
date	2003.12.08.07.07.36;	author mcbride;	state Exp;
branches;
next	1.134;

1.134
date	2003.11.04.21.43.16;	author markus;	state Exp;
branches;
next	1.133;

1.133
date	2003.10.01.21.41.05;	author itojun;	state Exp;
branches;
next	1.132;

1.132
date	2003.07.09.22.03.16;	author itojun;	state Exp;
branches
	1.132.2.1;
next	1.131;

1.131
date	2003.06.09.07.40.25;	author itojun;	state Exp;
branches;
next	1.130;

1.130
date	2003.06.02.23.28.14;	author millert;	state Exp;
branches;
next	1.129;

1.129
date	2003.05.29.04.55.55;	author itojun;	state Exp;
branches;
next	1.128;

1.128
date	2003.05.29.00.35.18;	author itojun;	state Exp;
branches;
next	1.127;

1.127
date	2003.05.19.02.03.28;	author dhartmei;	state Exp;
branches;
next	1.126;

1.126
date	2003.04.29.10.25.41;	author miod;	state Exp;
branches;
next	1.125;

1.125
date	2003.02.14.17.54.46;	author dhartmei;	state Exp;
branches
	1.125.2.1;
next	1.124;

1.124
date	2002.09.11.03.27.03;	author itojun;	state Exp;
branches
	1.124.2.1;
next	1.123;

1.123
date	2002.09.05.23.37.35;	author itojun;	state Exp;
branches;
next	1.122;

1.122
date	2002.08.19.02.31.02;	author itojun;	state Exp;
branches;
next	1.121;

1.121
date	2002.08.19.02.28.23;	author itojun;	state Exp;
branches;
next	1.120;

1.120
date	2002.08.08.19.18.12;	author provos;	state Exp;
branches;
next	1.119;

1.119
date	2002.08.08.18.26.37;	author todd;	state Exp;
branches;
next	1.118;

1.118
date	2002.08.08.17.07.32;	author provos;	state Exp;
branches;
next	1.117;

1.117
date	2002.06.09.16.26.11;	author itojun;	state Exp;
branches;
next	1.116;

1.116
date	2002.06.07.16.18.02;	author itojun;	state Exp;
branches;
next	1.115;

1.115
date	2002.06.07.15.51.54;	author itojun;	state Exp;
branches;
next	1.114;

1.114
date	2002.06.07.06.42.00;	author itojun;	state Exp;
branches;
next	1.113;

1.113
date	2002.05.31.04.43.25;	author angelos;	state Exp;
branches;
next	1.112;

1.112
date	2002.05.29.07.54.59;	author itojun;	state Exp;
branches;
next	1.111;

1.111
date	2002.05.16.14.10.51;	author kjc;	state Exp;
branches;
next	1.110;

1.110
date	2002.03.19.14.58.54;	author itojun;	state Exp;
branches;
next	1.109;

1.109
date	2002.03.15.18.19.52;	author millert;	state Exp;
branches;
next	1.108;

1.108
date	2002.03.09.05.13.04;	author provos;	state Exp;
branches;
next	1.107;

1.107
date	2002.03.08.03.49.58;	author provos;	state Exp;
branches;
next	1.106;

1.106
date	2002.03.02.00.44.52;	author provos;	state Exp;
branches;
next	1.105;

1.105
date	2002.03.01.22.29.29;	author provos;	state Exp;
branches;
next	1.104;

1.104
date	2002.01.24.22.42.48;	author provos;	state Exp;
branches;
next	1.103;

1.103
date	2002.01.15.19.18.01;	author provos;	state Exp;
branches;
next	1.102;

1.102
date	2002.01.14.20.09.42;	author provos;	state Exp;
branches;
next	1.101;

1.101
date	2002.01.14.03.11.55;	author provos;	state Exp;
branches;
next	1.100;

1.100
date	2001.07.07.22.22.04;	author provos;	state Exp;
branches
	1.100.2.1
	1.100.4.1;
next	1.99;

1.99
date	2001.07.04.23.14.56;	author espie;	state Exp;
branches;
next	1.98;

1.98
date	2001.06.24.22.50.58;	author angelos;	state Exp;
branches;
next	1.97;

1.97
date	2001.06.23.18.54.44;	author angelos;	state Exp;
branches;
next	1.96;

1.96
date	2001.06.23.06.03.11;	author angelos;	state Exp;
branches;
next	1.95;

1.95
date	2001.06.23.02.27.10;	author angelos;	state Exp;
branches;
next	1.94;

1.94
date	2001.06.12.10.59.53;	author angelos;	state Exp;
branches;
next	1.93;

1.93
date	2001.06.08.03.53.46;	author angelos;	state Exp;
branches;
next	1.92;

1.92
date	2001.06.05.02.31.36;	author deraadt;	state Exp;
branches;
next	1.91;

1.91
date	2001.05.27.03.55.59;	author angelos;	state Exp;
branches;
next	1.90;

1.90
date	2001.05.27.03.16.10;	author angelos;	state Exp;
branches;
next	1.89;

1.89
date	2001.05.27.00.39.27;	author angelos;	state Exp;
branches;
next	1.88;

1.88
date	2001.05.20.08.35.11;	author angelos;	state Exp;
branches;
next	1.87;

1.87
date	2001.05.12.18.35.17;	author aaron;	state Exp;
branches;
next	1.86;

1.86
date	2001.05.11.17.20.11;	author aaron;	state Exp;
branches;
next	1.85;

1.85
date	2001.05.01.01.13.05;	author aaron;	state Exp;
branches;
next	1.84;

1.84
date	2001.04.04.05.42.57;	author itojun;	state Exp;
branches;
next	1.83;

1.83
date	2001.03.28.20.03.07;	author angelos;	state Exp;
branches;
next	1.82;

1.82
date	2001.02.08.18.46.22;	author itojun;	state Exp;
branches;
next	1.81;

1.81
date	2000.12.13.09.47.08;	author provos;	state Exp;
branches;
next	1.80;

1.80
date	2000.12.11.08.04.55;	author itojun;	state Exp;
branches;
next	1.79;

1.79
date	2000.10.14.01.04.10;	author itojun;	state Exp;
branches;
next	1.78;

1.78
date	2000.10.11.09.14.11;	author itojun;	state Exp;
branches;
next	1.77;

1.77
date	2000.09.25.09.41.02;	author provos;	state Exp;
branches;
next	1.76;

1.76
date	2000.09.23.01.07.38;	author chris;	state Exp;
branches;
next	1.75;

1.75
date	2000.09.21.17.30.48;	author provos;	state Exp;
branches;
next	1.74;

1.74
date	2000.09.20.17.00.22;	author provos;	state Exp;
branches;
next	1.73;

1.73
date	2000.09.19.18.10.59;	author deraadt;	state Exp;
branches;
next	1.72;

1.72
date	2000.09.19.03.20.59;	author angelos;	state Exp;
branches;
next	1.71;

1.71
date	2000.09.18.23.59.39;	author fgsch;	state Exp;
branches;
next	1.70;

1.70
date	2000.09.18.22.06.38;	author provos;	state Exp;
branches;
next	1.69;

1.69
date	2000.09.05.21.57.41;	author provos;	state Exp;
branches;
next	1.68;

1.68
date	2000.07.27.04.05.26;	author itojun;	state Exp;
branches;
next	1.67;

1.67
date	2000.07.11.16.53.22;	author provos;	state Exp;
branches;
next	1.66;

1.66
date	2000.07.09.12.53.55;	author itojun;	state Exp;
branches;
next	1.65;

1.65
date	2000.07.06.10.31.10;	author fgsch;	state Exp;
branches;
next	1.64;

1.64
date	2000.07.06.10.11.22;	author itojun;	state Exp;
branches;
next	1.63;

1.63
date	2000.07.06.05.24.45;	author itojun;	state Exp;
branches;
next	1.62;

1.62
date	2000.07.05.22.51.09;	author itojun;	state Exp;
branches;
next	1.61;

1.61
date	2000.05.15.03.38.40;	author angelos;	state Exp;
branches;
next	1.60;

1.60
date	2000.04.28.00.31.48;	author itojun;	state Exp;
branches;
next	1.59;

1.59
date	2000.04.27.20.53.08;	author provos;	state Exp;
branches;
next	1.58;

1.58
date	2000.04.14.04.20.57;	author itojun;	state Exp;
branches;
next	1.57;

1.57
date	2000.02.21.21.42.13;	author provos;	state Exp;
branches;
next	1.56;

1.56
date	99.12.21.17.49.28;	author provos;	state Exp;
branches
	1.56.2.1;
next	1.55;

1.55
date	99.12.21.15.41.07;	author itojun;	state Exp;
branches;
next	1.54;

1.54
date	99.12.15.16.37.20;	author provos;	state Exp;
branches;
next	1.53;

1.53
date	99.12.14.22.20.28;	author provos;	state Exp;
branches;
next	1.52;

1.52
date	99.12.08.06.50.20;	author itojun;	state Exp;
branches;
next	1.51;

1.51
date	99.11.15.05.50.59;	author hugh;	state Exp;
branches;
next	1.50;

1.50
date	99.11.04.11.24.23;	author ho;	state Exp;
branches;
next	1.49;

1.49
date	99.09.01.21.38.21;	author provos;	state Exp;
branches;
next	1.48;

1.48
date	99.08.31.21.41.05;	author provos;	state Exp;
branches;
next	1.47;

1.47
date	99.08.27.15.35.56;	author provos;	state Exp;
branches;
next	1.46;

1.46
date	99.08.06.18.17.37;	author deraadt;	state Exp;
branches;
next	1.45;

1.45
date	99.07.28.05.37.18;	author cmetz;	state Exp;
branches;
next	1.44;

1.44
date	99.07.22.17.14.18;	author niklas;	state Exp;
branches;
next	1.43;

1.43
date	99.07.18.16.33.08;	author deraadt;	state Exp;
branches;
next	1.42;

1.42
date	99.07.17.23.41.46;	author provos;	state Exp;
branches;
next	1.41;

1.41
date	99.07.13.21.57.42;	author deraadt;	state Exp;
branches;
next	1.40;

1.40
date	99.07.06.20.17.52;	author cmetz;	state Exp;
branches;
next	1.39;

1.39
date	99.07.06.20.14.06;	author cmetz;	state Exp;
branches;
next	1.38;

1.38
date	99.07.03.02.16.51;	author deraadt;	state Exp;
branches;
next	1.37;

1.37
date	99.07.02.20.39.07;	author cmetz;	state Exp;
branches;
next	1.36;

1.36
date	99.06.11.19.46.39;	author pattonme;	state Exp;
branches;
next	1.35;

1.35
date	99.05.24.17.46.40;	author provos;	state Exp;
branches;
next	1.34;

1.34
date	99.04.21.21.38.58;	author provos;	state Exp;
branches;
next	1.33;

1.33
date	99.03.27.21.04.20;	author provos;	state Exp;
branches;
next	1.32;

1.32
date	99.02.15.02.39.02;	author provos;	state Exp;
branches;
next	1.31;

1.31
date	99.02.09.22.58.24;	author hugh;	state Exp;
branches;
next	1.30;

1.30
date	99.02.08.17.36.28;	author deraadt;	state Exp;
branches;
next	1.29;

1.29
date	99.02.05.05.42.36;	author deraadt;	state Exp;
branches;
next	1.28;

1.28
date	99.01.27.16.47.29;	author provos;	state Exp;
branches;
next	1.27;

1.27
date	99.01.27.10.04.57;	author niklas;	state Exp;
branches;
next	1.26;

1.26
date	99.01.15.12.01.06;	author niklas;	state Exp;
branches;
next	1.25;

1.25
date	99.01.11.15.05.32;	author niklas;	state Exp;
branches;
next	1.24;

1.24
date	99.01.11.02.01.35;	author deraadt;	state Exp;
branches;
next	1.23;

1.23
date	99.01.07.06.05.04;	author deraadt;	state Exp;
branches;
next	1.22;

1.22
date	98.11.25.05.44.36;	author millert;	state Exp;
branches;
next	1.21;

1.21
date	98.11.17.19.23.01;	author provos;	state Exp;
branches;
next	1.20;

1.20
date	98.10.28.21.34.32;	author provos;	state Exp;
branches;
next	1.19;

1.19
date	98.06.27.02.42.40;	author deraadt;	state Exp;
branches;
next	1.18;

1.18
date	98.03.18.02.37.47;	author angelos;	state Exp;
branches;
next	1.17;

1.17
date	97.11.12.20.59.44;	author deraadt;	state Exp;
branches;
next	1.16;

1.16
date	97.11.12.20.57.43;	author deraadt;	state Exp;
branches;
next	1.15;

1.15
date	97.08.26.20.02.32;	author deraadt;	state Exp;
branches;
next	1.14;

1.14
date	97.08.16.01.34.41;	author angelos;	state Exp;
branches;
next	1.13;

1.13
date	97.08.09.01.26.00;	author angelos;	state Exp;
branches;
next	1.12;

1.12
date	97.07.06.08.04.10;	author deraadt;	state Exp;
branches;
next	1.11;

1.11
date	97.06.10.19.46.41;	author deraadt;	state Exp;
branches;
next	1.10;

1.10
date	97.05.12.18.00.29;	author deraadt;	state Exp;
branches;
next	1.9;

1.9
date	97.02.05.15.48.24;	author deraadt;	state Exp;
branches;
next	1.8;

1.8
date	96.09.25.11.39.56;	author niklas;	state Exp;
branches;
next	1.7;

1.7
date	96.09.20.22.53.11;	author deraadt;	state Exp;
branches;
next	1.6;

1.6
date	96.08.07.06.36.26;	author tholo;	state Exp;
branches;
next	1.5;

1.5
date	96.07.29.22.01.50;	author niklas;	state Exp;
branches;
next	1.4;

1.4
date	96.07.29.06.22.12;	author tholo;	state Exp;
branches;
next	1.3;

1.3
date	96.03.03.22.30.45;	author niklas;	state Exp;
branches;
next	1.2;

1.2
date	95.12.14.06.50.47;	author deraadt;	state Exp;
branches;
next	1.1;

1.1
date	95.10.18.08.53.12;	author deraadt;	state Exp;
branches
	1.1.1.1;
next	;

1.1.1.1
date	95.10.18.08.53.12;	author deraadt;	state Exp;
branches;
next	;

1.56.2.1
date	2000.03.02.07.04.42;	author niklas;	state Exp;
branches;
next	1.56.2.2;

1.56.2.2
date	2001.05.14.22.40.14;	author niklas;	state Exp;
branches;
next	1.56.2.3;

1.56.2.3
date	2001.07.04.10.55.06;	author niklas;	state Exp;
branches;
next	1.56.2.4;

1.56.2.4
date	2001.10.31.03.29.03;	author nate;	state Exp;
branches;
next	1.56.2.5;

1.56.2.5
date	2002.03.06.02.15.08;	author niklas;	state Exp;
branches;
next	1.56.2.6;

1.56.2.6
date	2002.03.28.14.56.45;	author niklas;	state Exp;
branches;
next	1.56.2.7;

1.56.2.7
date	2003.03.28.00.06.54;	author niklas;	state Exp;
branches;
next	1.56.2.8;

1.56.2.8
date	2003.05.13.19.36.17;	author ho;	state Exp;
branches;
next	1.56.2.9;

1.56.2.9
date	2003.06.07.11.06.08;	author ho;	state Exp;
branches;
next	1.56.2.10;

1.56.2.10
date	2004.02.19.10.57.24;	author niklas;	state Exp;
branches;
next	1.56.2.11;

1.56.2.11
date	2004.06.05.23.11.25;	author niklas;	state Exp;
branches;
next	1.56.2.12;

1.56.2.12
date	2004.06.08.21.07.29;	author niklas;	state Exp;
branches;
next	;

1.100.2.1
date	2002.06.24.18.19.05;	author miod;	state Exp;
branches;
next	;

1.100.4.1
date	2002.01.31.22.55.45;	author niklas;	state Exp;
branches;
next	1.100.4.2;

1.100.4.2
date	2002.06.11.03.31.37;	author art;	state Exp;
branches;
next	1.100.4.3;

1.100.4.3
date	2002.10.29.00.36.47;	author art;	state Exp;
branches;
next	1.100.4.4;

1.100.4.4
date	2003.05.19.22.40.41;	author tedu;	state Exp;
branches;
next	;

1.124.2.1
date	2003.02.22.05.18.55;	author margarida;	state Exp;
branches;
next	;

1.125.2.1
date	2004.03.03.02.35.59;	author brad;	state Exp;
branches;
next	1.125.2.2;

1.125.2.2
date	2004.03.03.08.40.07;	author brad;	state Exp;
branches;
next	;

1.132.2.1
date	2004.03.03.02.35.26;	author brad;	state Exp;
branches;
next	1.132.2.2;

1.132.2.2
date	2004.03.03.08.37.05;	author brad;	state Exp;
branches;
next	1.132.2.3;

1.132.2.3
date	2004.05.06.00.39.39;	author brad;	state Exp;
branches;
next	1.132.2.4;

1.132.2.4
date	2004.05.26.20.00.38;	author brad;	state Exp;
branches;
next	;

1.158.2.1
date	2004.05.06.00.45.37;	author brad;	state Exp;
branches;
next	1.158.2.2;

1.158.2.2
date	2004.05.26.20.02.06;	author brad;	state Exp;
branches;
next	1.158.2.3;

1.158.2.3
date	2005.01.11.04.40.29;	author brad;	state Exp;
branches;
next	1.158.2.4;

1.158.2.4
date	2005.03.20.23.44.05;	author brad;	state Exp;
branches;
next	1.158.2.5;

1.158.2.5
date	2005.04.01.15.32.53;	author brad;	state Exp;
branches;
next	;

1.175.2.1
date	2005.01.11.04.36.23;	author brad;	state Exp;
branches;
next	1.175.2.2;

1.175.2.2
date	2005.03.20.23.36.10;	author brad;	state Exp;
branches;
next	1.175.2.3;

1.175.2.3
date	2005.04.01.15.31.06;	author brad;	state Exp;
branches;
next	;

1.195.2.1
date	2006.11.13.23.12.19;	author brad;	state Exp;
branches;
next	1.195.2.2;

1.195.2.2
date	2006.11.17.04.03.35;	author brad;	state Exp;
branches;
next	;

1.196.2.1
date	2006.11.17.04.14.38;	author brad;	state Exp;
branches;
next	;

1.201.2.1
date	2008.02.21.17.34.26;	author henning;	state Exp;
branches;
next	;

1.207.2.1
date	2008.02.21.15.53.16;	author henning;	state Exp;
branches;
next	;

1.220.2.1
date	2008.11.05.23.18.14;	author brad;	state Exp;
branches;
next	;


desc
@@


1.341
log
@Use the rt_rmx defines that hide the struct rt_kmetrics indirection.
No binary change.
OK mpi@@
@
text
@/*	$OpenBSD: tcp_input.c,v 1.340 2017/04/17 20:59:35 bluhm Exp $	*/
/*	$NetBSD: tcp_input.c,v 1.23 1996/02/13 23:43:44 christos Exp $	*/

/*
 * Copyright (c) 1982, 1986, 1988, 1990, 1993, 1994
 *	The Regents of the University of California.  All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. Neither the name of the University nor the names of its contributors
 *    may be used to endorse or promote products derived from this software
 *    without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE
 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
 *
 *	@@(#)COPYRIGHT	1.1 (NRL) 17 January 1995
 *
 * NRL grants permission for redistribution and use in source and binary
 * forms, with or without modification, of the software and documentation
 * created at NRL provided that the following conditions are met:
 *
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgements:
 *	This product includes software developed by the University of
 *	California, Berkeley and its contributors.
 *	This product includes software developed at the Information
 *	Technology Division, US Naval Research Laboratory.
 * 4. Neither the name of the NRL nor the names of its contributors
 *    may be used to endorse or promote products derived from this software
 *    without specific prior written permission.
 *
 * THE SOFTWARE PROVIDED BY NRL IS PROVIDED BY NRL AND CONTRIBUTORS ``AS
 * IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED
 * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A
 * PARTICULAR PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL NRL OR
 * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
 * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
 * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
 * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
 * LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
 * NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
 * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 *
 * The views and conclusions contained in the software and documentation
 * are those of the authors and should not be interpreted as representing
 * official policies, either expressed or implied, of the US Naval
 * Research Laboratory (NRL).
 */

#include "pf.h"

#include <sys/param.h>
#include <sys/systm.h>
#include <sys/mbuf.h>
#include <sys/protosw.h>
#include <sys/socket.h>
#include <sys/socketvar.h>
#include <sys/timeout.h>
#include <sys/kernel.h>
#include <sys/pool.h>

#include <net/if.h>
#include <net/if_var.h>
#include <net/route.h>

#include <netinet/in.h>
#include <netinet/ip.h>
#include <netinet/in_pcb.h>
#include <netinet/ip_var.h>
#include <netinet/tcp.h>
#include <netinet/tcp_fsm.h>
#include <netinet/tcp_seq.h>
#include <netinet/tcp_timer.h>
#include <netinet/tcp_var.h>
#include <netinet/tcpip.h>
#include <netinet/tcp_debug.h>

#if NPF > 0
#include <net/pfvar.h>
#endif

struct	tcpiphdr tcp_saveti;

int tcp_mss_adv(struct mbuf *, int);
int tcp_flush_queue(struct tcpcb *);

#ifdef INET6
#include <netinet6/in6_var.h>
#include <netinet6/nd6.h>

struct  tcpipv6hdr tcp_saveti6;

/* for the packet header length in the mbuf */
#define M_PH_LEN(m)      (((struct mbuf *)(m))->m_pkthdr.len)
#define M_V6_LEN(m)      (M_PH_LEN(m) - sizeof(struct ip6_hdr))
#define M_V4_LEN(m)      (M_PH_LEN(m) - sizeof(struct ip))
#endif /* INET6 */

int	tcprexmtthresh = 3;
int	tcptv_keep_init = TCPTV_KEEP_INIT;

int tcp_rst_ppslim = 100;		/* 100pps */
int tcp_rst_ppslim_count = 0;
struct timeval tcp_rst_ppslim_last;

int tcp_ackdrop_ppslim = 100;		/* 100pps */
int tcp_ackdrop_ppslim_count = 0;
struct timeval tcp_ackdrop_ppslim_last;

#define TCP_PAWS_IDLE	(24 * 24 * 60 * 60 * PR_SLOWHZ)

/* for modulo comparisons of timestamps */
#define TSTMP_LT(a,b)	((int)((a)-(b)) < 0)
#define TSTMP_GEQ(a,b)	((int)((a)-(b)) >= 0)

/* for TCP SACK comparisons */
#define	SEQ_MIN(a,b)	(SEQ_LT(a,b) ? (a) : (b))
#define	SEQ_MAX(a,b)	(SEQ_GT(a,b) ? (a) : (b))

/*
 * Neighbor Discovery, Neighbor Unreachability Detection Upper layer hint.
 */
#ifdef INET6
#define ND6_HINT(tp) \
do { \
	if (tp && tp->t_inpcb && (tp->t_inpcb->inp_flags & INP_IPV6) &&	\
	    rtisvalid(tp->t_inpcb->inp_route6.ro_rt)) {			\
		nd6_nud_hint(tp->t_inpcb->inp_route6.ro_rt);		\
	} \
} while (0)
#else
#define ND6_HINT(tp)
#endif

#ifdef TCP_ECN
/*
 * ECN (Explicit Congestion Notification) support based on RFC3168
 * implementation note:
 *   snd_last is used to track a recovery phase.
 *   when cwnd is reduced, snd_last is set to snd_max.
 *   while snd_last > snd_una, the sender is in a recovery phase and
 *   its cwnd should not be reduced again.
 *   snd_last follows snd_una when not in a recovery phase.
 */
#endif

/*
 * Macro to compute ACK transmission behavior.  Delay the ACK unless
 * we have already delayed an ACK (must send an ACK every two segments).
 * We also ACK immediately if we received a PUSH and the ACK-on-PUSH
 * option is enabled or when the packet is coming from a loopback
 * interface.
 */
#define	TCP_SETUP_ACK(tp, tiflags, m) \
do { \
	struct ifnet *ifp = NULL; \
	if (m && (m->m_flags & M_PKTHDR)) \
		ifp = if_get(m->m_pkthdr.ph_ifidx); \
	if ((tp)->t_flags & TF_DELACK || \
	    (tcp_ack_on_push && (tiflags) & TH_PUSH) || \
	    (ifp && (ifp->if_flags & IFF_LOOPBACK))) \
		tp->t_flags |= TF_ACKNOW; \
	else \
		TCP_SET_DELACK(tp); \
	if_put(ifp); \
} while (0)

void	 syn_cache_put(struct syn_cache *);
void	 syn_cache_rm(struct syn_cache *);
int	 syn_cache_respond(struct syn_cache *, struct mbuf *);
void	 syn_cache_timer(void *);
void	 syn_cache_reaper(void *);
void	 syn_cache_insert(struct syn_cache *, struct tcpcb *);
void	 syn_cache_reset(struct sockaddr *, struct sockaddr *,
		struct tcphdr *, u_int);
int	 syn_cache_add(struct sockaddr *, struct sockaddr *, struct tcphdr *,
		unsigned int, struct socket *, struct mbuf *, u_char *, int,
		struct tcp_opt_info *, tcp_seq *);
struct socket *syn_cache_get(struct sockaddr *, struct sockaddr *,
		struct tcphdr *, unsigned int, unsigned int, struct socket *,
		struct mbuf *);
struct syn_cache *syn_cache_lookup(struct sockaddr *, struct sockaddr *,
		struct syn_cache_head **, u_int);

/*
 * Insert segment ti into reassembly queue of tcp with
 * control block tp.  Return TH_FIN if reassembly now includes
 * a segment with FIN.  The macro form does the common case inline
 * (segment is the next to be received on an established connection,
 * and the queue is empty), avoiding linkage into and removal
 * from the queue and repetition of various conversions.
 * Set DELACK for segments received in order, but ack immediately
 * when segments are out of order (so fast retransmit can work).
 */

int
tcp_reass(struct tcpcb *tp, struct tcphdr *th, struct mbuf *m, int *tlen)
{
	struct tcpqent *p, *q, *nq, *tiqe;

	/*
	 * Allocate a new queue entry, before we throw away any data.
	 * If we can't, just drop the packet.  XXX
	 */
	tiqe = pool_get(&tcpqe_pool, PR_NOWAIT);
	if (tiqe == NULL) {
		tiqe = TAILQ_LAST(&tp->t_segq, tcpqehead);
		if (tiqe != NULL && th->th_seq == tp->rcv_nxt) {
			/* Reuse last entry since new segment fills a hole */
			m_freem(tiqe->tcpqe_m);
			TAILQ_REMOVE(&tp->t_segq, tiqe, tcpqe_q);
		}
		if (tiqe == NULL || th->th_seq != tp->rcv_nxt) {
			/* Flush segment queue for this connection */
			tcp_freeq(tp);
			tcpstat_inc(tcps_rcvmemdrop);
			m_freem(m);
			return (0);
		}
	}

	/*
	 * Find a segment which begins after this one does.
	 */
	for (p = NULL, q = TAILQ_FIRST(&tp->t_segq); q != NULL;
	    p = q, q = TAILQ_NEXT(q, tcpqe_q))
		if (SEQ_GT(q->tcpqe_tcp->th_seq, th->th_seq))
			break;

	/*
	 * If there is a preceding segment, it may provide some of
	 * our data already.  If so, drop the data from the incoming
	 * segment.  If it provides all of our data, drop us.
	 */
	if (p != NULL) {
		struct tcphdr *phdr = p->tcpqe_tcp;
		int i;

		/* conversion to int (in i) handles seq wraparound */
		i = phdr->th_seq + phdr->th_reseqlen - th->th_seq;
		if (i > 0) {
		        if (i >= *tlen) {
				tcpstat_pkt(tcps_rcvduppack, tcps_rcvdupbyte,
				    *tlen);
				m_freem(m);
				pool_put(&tcpqe_pool, tiqe);
				return (0);
			}
			m_adj(m, i);
			*tlen -= i;
			th->th_seq += i;
		}
	}
	tcpstat_pkt(tcps_rcvoopack, tcps_rcvoobyte, *tlen);

	/*
	 * While we overlap succeeding segments trim them or,
	 * if they are completely covered, dequeue them.
	 */
	for (; q != NULL; q = nq) {
		struct tcphdr *qhdr = q->tcpqe_tcp;
		int i = (th->th_seq + *tlen) - qhdr->th_seq;

		if (i <= 0)
			break;
		if (i < qhdr->th_reseqlen) {
			qhdr->th_seq += i;
			qhdr->th_reseqlen -= i;
			m_adj(q->tcpqe_m, i);
			break;
		}
		nq = TAILQ_NEXT(q, tcpqe_q);
		m_freem(q->tcpqe_m);
		TAILQ_REMOVE(&tp->t_segq, q, tcpqe_q);
		pool_put(&tcpqe_pool, q);
	}

	/* Insert the new segment queue entry into place. */
	tiqe->tcpqe_m = m;
	th->th_reseqlen = *tlen;
	tiqe->tcpqe_tcp = th;
	if (p == NULL) {
		TAILQ_INSERT_HEAD(&tp->t_segq, tiqe, tcpqe_q);
	} else {
		TAILQ_INSERT_AFTER(&tp->t_segq, p, tiqe, tcpqe_q);
	}

	if (th->th_seq != tp->rcv_nxt)
		return (0);

	return (tcp_flush_queue(tp));
}

int
tcp_flush_queue(struct tcpcb *tp)
{
	struct socket *so = tp->t_inpcb->inp_socket;
	struct tcpqent *q, *nq;
	int flags;

	/*
	 * Present data to user, advancing rcv_nxt through
	 * completed sequence space.
	 */
	if (TCPS_HAVEESTABLISHED(tp->t_state) == 0)
		return (0);
	q = TAILQ_FIRST(&tp->t_segq);
	if (q == NULL || q->tcpqe_tcp->th_seq != tp->rcv_nxt)
		return (0);
	if (tp->t_state == TCPS_SYN_RECEIVED && q->tcpqe_tcp->th_reseqlen)
		return (0);
	do {
		tp->rcv_nxt += q->tcpqe_tcp->th_reseqlen;
		flags = q->tcpqe_tcp->th_flags & TH_FIN;

		nq = TAILQ_NEXT(q, tcpqe_q);
		TAILQ_REMOVE(&tp->t_segq, q, tcpqe_q);
		ND6_HINT(tp);
		if (so->so_state & SS_CANTRCVMORE)
			m_freem(q->tcpqe_m);
		else
			sbappendstream(&so->so_rcv, q->tcpqe_m);
		pool_put(&tcpqe_pool, q);
		q = nq;
	} while (q != NULL && q->tcpqe_tcp->th_seq == tp->rcv_nxt);
	tp->t_flags |= TF_BLOCKOUTPUT;
	sorwakeup(so);
	tp->t_flags &= ~TF_BLOCKOUTPUT;
	return (flags);
}

/*
 * TCP input routine, follows pages 65-76 of the
 * protocol specification dated September, 1981 very closely.
 */
int
tcp_input(struct mbuf **mp, int *offp, int proto, int af)
{
	struct mbuf *m = *mp;
	int iphlen = *offp;
	struct ip *ip = NULL;
	struct inpcb *inp = NULL;
	u_int8_t *optp = NULL;
	int optlen = 0;
	int tlen, off;
	struct tcpcb *tp = NULL;
	int tiflags;
	struct socket *so = NULL;
	int todrop, acked, ourfinisacked;
	int hdroptlen = 0;
	short ostate = 0;
	tcp_seq iss, *reuse = NULL;
	u_long tiwin;
	struct tcp_opt_info opti;
	struct tcphdr *th;
#ifdef INET6
	struct ip6_hdr *ip6 = NULL;
#endif /* INET6 */
#ifdef IPSEC
	struct m_tag *mtag;
	struct tdb_ident *tdbi;
	struct tdb *tdb;
	int error;
#endif /* IPSEC */
#ifdef TCP_ECN
	u_char iptos;
#endif

	tcpstat_inc(tcps_rcvtotal);

	opti.ts_present = 0;
	opti.maxseg = 0;

	/*
	 * RFC1122 4.2.3.10, p. 104: discard bcast/mcast SYN
	 */
	if (m->m_flags & (M_BCAST|M_MCAST))
		goto drop;

	/*
	 * Get IP and TCP header together in first mbuf.
	 * Note: IP leaves IP header in first mbuf.
	 */
	IP6_EXTHDR_GET(th, struct tcphdr *, m, iphlen, sizeof(*th));
	if (!th) {
		tcpstat_inc(tcps_rcvshort);
		return IPPROTO_DONE;
	}

	tlen = m->m_pkthdr.len - iphlen;
	switch (af) {
	case AF_INET:
		ip = mtod(m, struct ip *);
#ifdef TCP_ECN
		/* save ip_tos before clearing it for checksum */
		iptos = ip->ip_tos;
#endif
		break;
#ifdef INET6
	case AF_INET6:
		ip6 = mtod(m, struct ip6_hdr *);
#ifdef TCP_ECN
		iptos = (ntohl(ip6->ip6_flow) >> 20) & 0xff;
#endif

		/* Be proactive about malicious use of IPv4 mapped address */
		if (IN6_IS_ADDR_V4MAPPED(&ip6->ip6_src) ||
		    IN6_IS_ADDR_V4MAPPED(&ip6->ip6_dst)) {
			/* XXX stat */
			goto drop;
		}

		/*
		 * Be proactive about unspecified IPv6 address in source.
		 * As we use all-zero to indicate unbounded/unconnected pcb,
		 * unspecified IPv6 address can be used to confuse us.
		 *
		 * Note that packets with unspecified IPv6 destination is
		 * already dropped in ip6_input.
		 */
		if (IN6_IS_ADDR_UNSPECIFIED(&ip6->ip6_src)) {
			/* XXX stat */
			goto drop;
		}

		/* Discard packets to multicast */
		if (IN6_IS_ADDR_MULTICAST(&ip6->ip6_dst)) {
			/* XXX stat */
			goto drop;
		}
		break;
#endif
	default:
		unhandled_af(af);
	}

	/*
	 * Checksum extended TCP header and data.
	 */
	if ((m->m_pkthdr.csum_flags & M_TCP_CSUM_IN_OK) == 0) {
		int sum;

		if (m->m_pkthdr.csum_flags & M_TCP_CSUM_IN_BAD) {
			tcpstat_inc(tcps_rcvbadsum);
			goto drop;
		}
		tcpstat_inc(tcps_inswcsum);
		switch (af) {
		case AF_INET:
			sum = in4_cksum(m, IPPROTO_TCP, iphlen, tlen);
			break;
#ifdef INET6
		case AF_INET6:
			sum = in6_cksum(m, IPPROTO_TCP, sizeof(struct ip6_hdr),
			    tlen);
			break;
#endif
		}
		if (sum != 0) {
			tcpstat_inc(tcps_rcvbadsum);
			goto drop;
		}
	}

	/*
	 * Check that TCP offset makes sense,
	 * pull out TCP options and adjust length.		XXX
	 */
	off = th->th_off << 2;
	if (off < sizeof(struct tcphdr) || off > tlen) {
		tcpstat_inc(tcps_rcvbadoff);
		goto drop;
	}
	tlen -= off;
	if (off > sizeof(struct tcphdr)) {
		IP6_EXTHDR_GET(th, struct tcphdr *, m, iphlen, off);
		if (!th) {
			tcpstat_inc(tcps_rcvshort);
			return IPPROTO_DONE;
		}
		optlen = off - sizeof(struct tcphdr);
		optp = (u_int8_t *)(th + 1);
		/*
		 * Do quick retrieval of timestamp options ("options
		 * prediction?").  If timestamp is the only option and it's
		 * formatted as recommended in RFC 1323 appendix A, we
		 * quickly get the values now and not bother calling
		 * tcp_dooptions(), etc.
		 */
		if ((optlen == TCPOLEN_TSTAMP_APPA ||
		     (optlen > TCPOLEN_TSTAMP_APPA &&
			optp[TCPOLEN_TSTAMP_APPA] == TCPOPT_EOL)) &&
		     *(u_int32_t *)optp == htonl(TCPOPT_TSTAMP_HDR) &&
		     (th->th_flags & TH_SYN) == 0) {
			opti.ts_present = 1;
			opti.ts_val = ntohl(*(u_int32_t *)(optp + 4));
			opti.ts_ecr = ntohl(*(u_int32_t *)(optp + 8));
			optp = NULL;	/* we've parsed the options */
		}
	}
	tiflags = th->th_flags;

	/*
	 * Convert TCP protocol specific fields to host format.
	 */
	th->th_seq = ntohl(th->th_seq);
	th->th_ack = ntohl(th->th_ack);
	th->th_win = ntohs(th->th_win);
	th->th_urp = ntohs(th->th_urp);

	/*
	 * Locate pcb for segment.
	 */
#if NPF > 0
	inp = pf_inp_lookup(m);
#endif
findpcb:
	if (inp == NULL) {
		switch (af) {
#ifdef INET6
		case AF_INET6:
			inp = in6_pcbhashlookup(&tcbtable, &ip6->ip6_src,
			    th->th_sport, &ip6->ip6_dst, th->th_dport,
			    m->m_pkthdr.ph_rtableid);
			break;
#endif
		case AF_INET:
			inp = in_pcbhashlookup(&tcbtable, ip->ip_src,
			    th->th_sport, ip->ip_dst, th->th_dport,
			    m->m_pkthdr.ph_rtableid);
			break;
		}
	}
	if (inp == NULL) {
		int	inpl_reverse = 0;
		if (m->m_pkthdr.pf.flags & PF_TAG_TRANSLATE_LOCALHOST)
			inpl_reverse = 1;
		tcpstat_inc(tcps_pcbhashmiss);
		switch (af) {
#ifdef INET6
		case AF_INET6:
			inp = in6_pcblookup_listen(&tcbtable,
			    &ip6->ip6_dst, th->th_dport, inpl_reverse, m,
			    m->m_pkthdr.ph_rtableid);
			break;
#endif /* INET6 */
		case AF_INET:
			inp = in_pcblookup_listen(&tcbtable,
			    ip->ip_dst, th->th_dport, inpl_reverse, m,
			    m->m_pkthdr.ph_rtableid);
			break;
		}
		/*
		 * If the state is CLOSED (i.e., TCB does not exist) then
		 * all data in the incoming segment is discarded.
		 * If the TCB exists but is in CLOSED state, it is embryonic,
		 * but should either do a listen or a connect soon.
		 */
		if (inp == NULL) {
			tcpstat_inc(tcps_noport);
			goto dropwithreset_ratelim;
		}
	}
	KASSERT(sotoinpcb(inp->inp_socket) == inp);
	KASSERT(intotcpcb(inp) == NULL || intotcpcb(inp)->t_inpcb == inp);

	/* Check the minimum TTL for socket. */
	switch (af) {
	case AF_INET:
		if (inp->inp_ip_minttl && inp->inp_ip_minttl > ip->ip_ttl)
			goto drop;
		break;
#ifdef INET6
	case AF_INET6:
		if (inp->inp_ip6_minhlim &&
		    inp->inp_ip6_minhlim > ip6->ip6_hlim)
			goto drop;
		break;
#endif
	}

	tp = intotcpcb(inp);
	if (tp == NULL)
		goto dropwithreset_ratelim;
	if (tp->t_state == TCPS_CLOSED)
		goto drop;

	/* Unscale the window into a 32-bit value. */
	if ((tiflags & TH_SYN) == 0)
		tiwin = th->th_win << tp->snd_scale;
	else
		tiwin = th->th_win;

	so = inp->inp_socket;
	if (so->so_options & (SO_DEBUG|SO_ACCEPTCONN)) {
		union syn_cache_sa src;
		union syn_cache_sa dst;

		bzero(&src, sizeof(src));
		bzero(&dst, sizeof(dst));
		switch (af) {
		case AF_INET:
			src.sin.sin_len = sizeof(struct sockaddr_in);
			src.sin.sin_family = AF_INET;
			src.sin.sin_addr = ip->ip_src;
			src.sin.sin_port = th->th_sport;

			dst.sin.sin_len = sizeof(struct sockaddr_in);
			dst.sin.sin_family = AF_INET;
			dst.sin.sin_addr = ip->ip_dst;
			dst.sin.sin_port = th->th_dport;
			break;
#ifdef INET6
		case AF_INET6:
			src.sin6.sin6_len = sizeof(struct sockaddr_in6);
			src.sin6.sin6_family = AF_INET6;
			src.sin6.sin6_addr = ip6->ip6_src;
			src.sin6.sin6_port = th->th_sport;

			dst.sin6.sin6_len = sizeof(struct sockaddr_in6);
			dst.sin6.sin6_family = AF_INET6;
			dst.sin6.sin6_addr = ip6->ip6_dst;
			dst.sin6.sin6_port = th->th_dport;
			break;
#endif /* INET6 */
		default:
			goto badsyn;	/*sanity*/
		}

		if (so->so_options & SO_DEBUG) {
			ostate = tp->t_state;
			switch (af) {
#ifdef INET6
			case AF_INET6:
				memcpy(&tcp_saveti6.ti6_i, ip6, sizeof(*ip6));
				memcpy(&tcp_saveti6.ti6_t, th, sizeof(*th));
				break;
#endif
			case AF_INET:
				memcpy(&tcp_saveti.ti_i, ip, sizeof(*ip));
				memcpy(&tcp_saveti.ti_t, th, sizeof(*th));
				break;
			}
		}
		if (so->so_options & SO_ACCEPTCONN) {
			switch (tiflags & (TH_RST|TH_SYN|TH_ACK)) {

			case TH_SYN|TH_ACK|TH_RST:
			case TH_SYN|TH_RST:
			case TH_ACK|TH_RST:
			case TH_RST:
				syn_cache_reset(&src.sa, &dst.sa, th,
				    inp->inp_rtableid);
				goto drop;

			case TH_SYN|TH_ACK:
				/*
				 * Received a SYN,ACK.  This should
				 * never happen while we are in
				 * LISTEN.  Send an RST.
				 */
				goto badsyn;

			case TH_ACK:
				so = syn_cache_get(&src.sa, &dst.sa,
					th, iphlen, tlen, so, m);
				if (so == NULL) {
					/*
					 * We don't have a SYN for
					 * this ACK; send an RST.
					 */
					goto badsyn;
				} else if (so == (struct socket *)(-1)) {
					/*
					 * We were unable to create
					 * the connection.  If the
					 * 3-way handshake was
					 * completed, and RST has
					 * been sent to the peer.
					 * Since the mbuf might be
					 * in use for the reply,
					 * do not free it.
					 */
					m = NULL;
					goto drop;
				} else {
					/*
					 * We have created a
					 * full-blown connection.
					 */
					tp = NULL;
					inp = sotoinpcb(so);
					tp = intotcpcb(inp);
					if (tp == NULL)
						goto badsyn;	/*XXX*/

				}
				break;

			default:
				/*
				 * None of RST, SYN or ACK was set.
				 * This is an invalid packet for a
				 * TCB in LISTEN state.  Send a RST.
				 */
				goto badsyn;

			case TH_SYN:
				/*
				 * Received a SYN.
				 */
#ifdef INET6
				/*
				 * If deprecated address is forbidden, we do
				 * not accept SYN to deprecated interface
				 * address to prevent any new inbound
				 * connection from getting established.
				 * When we do not accept SYN, we send a TCP
				 * RST, with deprecated source address (instead
				 * of dropping it).  We compromise it as it is
				 * much better for peer to send a RST, and
				 * RST will be the final packet for the
				 * exchange.
				 *
				 * If we do not forbid deprecated addresses, we
				 * accept the SYN packet.  RFC2462 does not
				 * suggest dropping SYN in this case.
				 * If we decipher RFC2462 5.5.4, it says like
				 * this:
				 * 1. use of deprecated addr with existing
				 *    communication is okay - "SHOULD continue
				 *    to be used"
				 * 2. use of it with new communication:
				 *   (2a) "SHOULD NOT be used if alternate
				 *        address with sufficient scope is
				 *        available"
				 *   (2b) nothing mentioned otherwise.
				 * Here we fall into (2b) case as we have no
				 * choice in our source address selection - we
				 * must obey the peer.
				 *
				 * The wording in RFC2462 is confusing, and
				 * there are multiple description text for
				 * deprecated address handling - worse, they
				 * are not exactly the same.  I believe 5.5.4
				 * is the best one, so we follow 5.5.4.
				 */
				if (ip6 && !ip6_use_deprecated) {
					struct in6_ifaddr *ia6;
					struct ifnet *ifp =
					    if_get(m->m_pkthdr.ph_ifidx);

					if (ifp &&
					    (ia6 = in6ifa_ifpwithaddr(ifp,
					    &ip6->ip6_dst)) &&
					    (ia6->ia6_flags &
					    IN6_IFF_DEPRECATED)) {
						tp = NULL;
						if_put(ifp);
						goto dropwithreset;
					}
					if_put(ifp);
				}
#endif

				/*
				 * LISTEN socket received a SYN
				 * from itself?  This can't possibly
				 * be valid; drop the packet.
				 */
				if (th->th_dport == th->th_sport) {
					switch (af) {
#ifdef INET6
					case AF_INET6:
						if (IN6_ARE_ADDR_EQUAL(&ip6->ip6_src,
						    &ip6->ip6_dst)) {
							tcpstat_inc(tcps_badsyn);
							goto drop;
						}
						break;
#endif /* INET6 */
					case AF_INET:
						if (ip->ip_dst.s_addr == ip->ip_src.s_addr) {
							tcpstat_inc(tcps_badsyn);
							goto drop;
						}
						break;
					}
				}

				/*
				 * SYN looks ok; create compressed TCP
				 * state for it.
				 */
				if (so->so_qlen > so->so_qlimit ||
				    syn_cache_add(&src.sa, &dst.sa, th, iphlen,
				    so, m, optp, optlen, &opti, reuse) == -1) {
					tcpstat_inc(tcps_dropsyn);
					goto drop;
				}
				return IPPROTO_DONE;
			}
		}
	}

#ifdef DIAGNOSTIC
	/*
	 * Should not happen now that all embryonic connections
	 * are handled with compressed state.
	 */
	if (tp->t_state == TCPS_LISTEN)
		panic("tcp_input: TCPS_LISTEN");
#endif

#if NPF > 0
	pf_inp_link(m, inp);
#endif

#ifdef IPSEC
	/* Find most recent IPsec tag */
	mtag = m_tag_find(m, PACKET_TAG_IPSEC_IN_DONE, NULL);
	if (mtag != NULL) {
		tdbi = (struct tdb_ident *)(mtag + 1);
	        tdb = gettdb(tdbi->rdomain, tdbi->spi,
		    &tdbi->dst, tdbi->proto);
	} else
		tdb = NULL;
	ipsp_spd_lookup(m, af, iphlen, &error, IPSP_DIRECTION_IN,
	    tdb, inp, 0);
	if (error) {
		tcpstat_inc(tcps_rcvnosec);
		goto drop;
	}
#endif /* IPSEC */

	/*
	 * Segment received on connection.
	 * Reset idle time and keep-alive timer.
	 */
	tp->t_rcvtime = tcp_now;
	if (TCPS_HAVEESTABLISHED(tp->t_state))
		TCP_TIMER_ARM(tp, TCPT_KEEP, tcp_keepidle);

#ifdef TCP_SACK
	if (tp->sack_enable)
		tcp_del_sackholes(tp, th); /* Delete stale SACK holes */
#endif /* TCP_SACK */

	/*
	 * Process options.
	 */
#ifdef TCP_SIGNATURE
	if (optp || (tp->t_flags & TF_SIGNATURE))
#else
	if (optp)
#endif
		if (tcp_dooptions(tp, optp, optlen, th, m, iphlen, &opti,
		    m->m_pkthdr.ph_rtableid))
			goto drop;

	if (opti.ts_present && opti.ts_ecr) {
		int rtt_test;

		/* subtract out the tcp timestamp modulator */
		opti.ts_ecr -= tp->ts_modulate;

		/* make sure ts_ecr is sensible */
		rtt_test = tcp_now - opti.ts_ecr;
		if (rtt_test < 0 || rtt_test > TCP_RTT_MAX)
			opti.ts_ecr = 0;
	}

#ifdef TCP_ECN
	/* if congestion experienced, set ECE bit in subsequent packets. */
	if ((iptos & IPTOS_ECN_MASK) == IPTOS_ECN_CE) {
		tp->t_flags |= TF_RCVD_CE;
		tcpstat_inc(tcps_ecn_rcvce);
	}
#endif
	/*
	 * Header prediction: check for the two common cases
	 * of a uni-directional data xfer.  If the packet has
	 * no control flags, is in-sequence, the window didn't
	 * change and we're not retransmitting, it's a
	 * candidate.  If the length is zero and the ack moved
	 * forward, we're the sender side of the xfer.  Just
	 * free the data acked & wake any higher level process
	 * that was blocked waiting for space.  If the length
	 * is non-zero and the ack didn't move, we're the
	 * receiver side.  If we're getting packets in-order
	 * (the reassembly queue is empty), add the data to
	 * the socket buffer and note that we need a delayed ack.
	 */
	if (tp->t_state == TCPS_ESTABLISHED &&
#ifdef TCP_ECN
	    (tiflags & (TH_SYN|TH_FIN|TH_RST|TH_URG|TH_ECE|TH_CWR|TH_ACK)) == TH_ACK &&
#else
	    (tiflags & (TH_SYN|TH_FIN|TH_RST|TH_URG|TH_ACK)) == TH_ACK &&
#endif
	    (!opti.ts_present || TSTMP_GEQ(opti.ts_val, tp->ts_recent)) &&
	    th->th_seq == tp->rcv_nxt &&
	    tiwin && tiwin == tp->snd_wnd &&
	    tp->snd_nxt == tp->snd_max) {

		/*
		 * If last ACK falls within this segment's sequence numbers,
		 *  record the timestamp.
		 * Fix from Braden, see Stevens p. 870
		 */
		if (opti.ts_present && SEQ_LEQ(th->th_seq, tp->last_ack_sent)) {
			tp->ts_recent_age = tcp_now;
			tp->ts_recent = opti.ts_val;
		}

		if (tlen == 0) {
			if (SEQ_GT(th->th_ack, tp->snd_una) &&
			    SEQ_LEQ(th->th_ack, tp->snd_max) &&
			    tp->snd_cwnd >= tp->snd_wnd &&
			    tp->t_dupacks == 0) {
				/*
				 * this is a pure ack for outstanding data.
				 */
				tcpstat_inc(tcps_predack);
				if (opti.ts_present && opti.ts_ecr)
					tcp_xmit_timer(tp, tcp_now - opti.ts_ecr);
				else if (tp->t_rtttime &&
				    SEQ_GT(th->th_ack, tp->t_rtseq))
					tcp_xmit_timer(tp,
					    tcp_now - tp->t_rtttime);
				acked = th->th_ack - tp->snd_una;
				tcpstat_pkt(tcps_rcvackpack, tcps_rcvackbyte,
				    acked);
				ND6_HINT(tp);
				sbdrop(&so->so_snd, acked);

				/*
				 * If we had a pending ICMP message that
				 * refers to data that have just been
				 * acknowledged, disregard the recorded ICMP
				 * message.
				 */
				if ((tp->t_flags & TF_PMTUD_PEND) &&
				    SEQ_GT(th->th_ack, tp->t_pmtud_th_seq))
					tp->t_flags &= ~TF_PMTUD_PEND;

				/*
				 * Keep track of the largest chunk of data
				 * acknowledged since last PMTU update
				 */
				if (tp->t_pmtud_mss_acked < acked)
					tp->t_pmtud_mss_acked = acked;

				tp->snd_una = th->th_ack;
#if defined(TCP_SACK) || defined(TCP_ECN)
				/*
				 * We want snd_last to track snd_una so
				 * as to avoid sequence wraparound problems
				 * for very large transfers.
				 */
#ifdef TCP_ECN
				if (SEQ_GT(tp->snd_una, tp->snd_last))
#endif
				tp->snd_last = tp->snd_una;
#endif /* TCP_SACK */
#if defined(TCP_SACK) && defined(TCP_FACK)
				tp->snd_fack = tp->snd_una;
				tp->retran_data = 0;
#endif /* TCP_FACK */
				m_freem(m);

				/*
				 * If all outstanding data are acked, stop
				 * retransmit timer, otherwise restart timer
				 * using current (possibly backed-off) value.
				 * If process is waiting for space,
				 * wakeup/selwakeup/signal.  If data
				 * are ready to send, let tcp_output
				 * decide between more output or persist.
				 */
				if (tp->snd_una == tp->snd_max)
					TCP_TIMER_DISARM(tp, TCPT_REXMT);
				else if (TCP_TIMER_ISARMED(tp, TCPT_PERSIST) == 0)
					TCP_TIMER_ARM(tp, TCPT_REXMT, tp->t_rxtcur);

				tcp_update_sndspace(tp);
				if (sb_notify(&so->so_snd)) {
					tp->t_flags |= TF_BLOCKOUTPUT;
					sowwakeup(so);
					tp->t_flags &= ~TF_BLOCKOUTPUT;
				}
				if (so->so_snd.sb_cc ||
				    tp->t_flags & TF_NEEDOUTPUT)
					(void) tcp_output(tp);
				return IPPROTO_DONE;
			}
		} else if (th->th_ack == tp->snd_una &&
		    TAILQ_EMPTY(&tp->t_segq) &&
		    tlen <= sbspace(&so->so_rcv)) {
			/*
			 * This is a pure, in-sequence data packet
			 * with nothing on the reassembly queue and
			 * we have enough buffer space to take it.
			 */
#ifdef TCP_SACK
			/* Clean receiver SACK report if present */
			if (tp->sack_enable && tp->rcv_numsacks)
				tcp_clean_sackreport(tp);
#endif /* TCP_SACK */
			tcpstat_inc(tcps_preddat);
			tp->rcv_nxt += tlen;
			tcpstat_pkt(tcps_rcvpack, tcps_rcvbyte, tlen);
			ND6_HINT(tp);

			TCP_SETUP_ACK(tp, tiflags, m);
			/*
			 * Drop TCP, IP headers and TCP options then add data
			 * to socket buffer.
			 */
			if (so->so_state & SS_CANTRCVMORE)
				m_freem(m);
			else {
				if (opti.ts_present && opti.ts_ecr) {
					if (tp->rfbuf_ts < opti.ts_ecr &&
					    opti.ts_ecr - tp->rfbuf_ts < hz) {
						tcp_update_rcvspace(tp);
						/* Start over with next RTT. */
						tp->rfbuf_cnt = 0;
						tp->rfbuf_ts = 0;
					} else
						tp->rfbuf_cnt += tlen;
				}
				m_adj(m, iphlen + off);
				sbappendstream(&so->so_rcv, m);
			}
			tp->t_flags |= TF_BLOCKOUTPUT;
			sorwakeup(so);
			tp->t_flags &= ~TF_BLOCKOUTPUT;
			if (tp->t_flags & (TF_ACKNOW|TF_NEEDOUTPUT))
				(void) tcp_output(tp);
			return IPPROTO_DONE;
		}
	}

	/*
	 * Compute mbuf offset to TCP data segment.
	 */
	hdroptlen = iphlen + off;

	/*
	 * Calculate amount of space in receive window,
	 * and then do TCP input processing.
	 * Receive window is amount of space in rcv queue,
	 * but not less than advertised window.
	 */
	{ int win;

	win = sbspace(&so->so_rcv);
	if (win < 0)
		win = 0;
	tp->rcv_wnd = imax(win, (int)(tp->rcv_adv - tp->rcv_nxt));
	}

	/* Reset receive buffer auto scaling when not in bulk receive mode. */
	tp->rfbuf_cnt = 0;
	tp->rfbuf_ts = 0;

	switch (tp->t_state) {

	/*
	 * If the state is SYN_RECEIVED:
	 * 	if seg contains SYN/ACK, send an RST.
	 *	if seg contains an ACK, but not for our SYN/ACK, send an RST
	 */

	case TCPS_SYN_RECEIVED:
		if (tiflags & TH_ACK) {
			if (tiflags & TH_SYN) {
				tcpstat_inc(tcps_badsyn);
				goto dropwithreset;
			}
			if (SEQ_LEQ(th->th_ack, tp->snd_una) ||
			    SEQ_GT(th->th_ack, tp->snd_max))
				goto dropwithreset;
		}
		break;

	/*
	 * If the state is SYN_SENT:
	 *	if seg contains an ACK, but not for our SYN, drop the input.
	 *	if seg contains a RST, then drop the connection.
	 *	if seg does not contain SYN, then drop it.
	 * Otherwise this is an acceptable SYN segment
	 *	initialize tp->rcv_nxt and tp->irs
	 *	if seg contains ack then advance tp->snd_una
	 *	if SYN has been acked change to ESTABLISHED else SYN_RCVD state
	 *	arrange for segment to be acked (eventually)
	 *	continue processing rest of data/controls, beginning with URG
	 */
	case TCPS_SYN_SENT:
		if ((tiflags & TH_ACK) &&
		    (SEQ_LEQ(th->th_ack, tp->iss) ||
		     SEQ_GT(th->th_ack, tp->snd_max)))
			goto dropwithreset;
		if (tiflags & TH_RST) {
#ifdef TCP_ECN
			/* if ECN is enabled, fall back to non-ecn at rexmit */
			if (tcp_do_ecn && !(tp->t_flags & TF_DISABLE_ECN))
				goto drop;
#endif
			if (tiflags & TH_ACK)
				tp = tcp_drop(tp, ECONNREFUSED);
			goto drop;
		}
		if ((tiflags & TH_SYN) == 0)
			goto drop;
		if (tiflags & TH_ACK) {
			tp->snd_una = th->th_ack;
			if (SEQ_LT(tp->snd_nxt, tp->snd_una))
				tp->snd_nxt = tp->snd_una;
		}
		TCP_TIMER_DISARM(tp, TCPT_REXMT);
		tp->irs = th->th_seq;
		tcp_mss(tp, opti.maxseg);
		/* Reset initial window to 1 segment for retransmit */
		if (tp->t_rxtshift > 0)
			tp->snd_cwnd = tp->t_maxseg;
		tcp_rcvseqinit(tp);
		tp->t_flags |= TF_ACKNOW;
#ifdef TCP_SACK
                /*
                 * If we've sent a SACK_PERMITTED option, and the peer
                 * also replied with one, then TF_SACK_PERMIT should have
                 * been set in tcp_dooptions().  If it was not, disable SACKs.
                 */
		if (tp->sack_enable)
			tp->sack_enable = tp->t_flags & TF_SACK_PERMIT;
#endif
#ifdef TCP_ECN
		/*
		 * if ECE is set but CWR is not set for SYN-ACK, or
		 * both ECE and CWR are set for simultaneous open,
		 * peer is ECN capable.
		 */
		if (tcp_do_ecn) {
			switch (tiflags & (TH_ACK|TH_ECE|TH_CWR)) {
			case TH_ACK|TH_ECE:
			case TH_ECE|TH_CWR:
				tp->t_flags |= TF_ECN_PERMIT;
				tiflags &= ~(TH_ECE|TH_CWR);
				tcpstat_inc(tcps_ecn_accepts);
			}
		}
#endif

		if (tiflags & TH_ACK && SEQ_GT(tp->snd_una, tp->iss)) {
			tcpstat_inc(tcps_connects);
			soisconnected(so);
			tp->t_state = TCPS_ESTABLISHED;
			TCP_TIMER_ARM(tp, TCPT_KEEP, tcp_keepidle);
			/* Do window scaling on this connection? */
			if ((tp->t_flags & (TF_RCVD_SCALE|TF_REQ_SCALE)) ==
				(TF_RCVD_SCALE|TF_REQ_SCALE)) {
				tp->snd_scale = tp->requested_s_scale;
				tp->rcv_scale = tp->request_r_scale;
			}
			tcp_flush_queue(tp);

			/*
			 * if we didn't have to retransmit the SYN,
			 * use its rtt as our initial srtt & rtt var.
			 */
			if (tp->t_rtttime)
				tcp_xmit_timer(tp, tcp_now - tp->t_rtttime);
			/*
			 * Since new data was acked (the SYN), open the
			 * congestion window by one MSS.  We do this
			 * here, because we won't go through the normal
			 * ACK processing below.  And since this is the
			 * start of the connection, we know we are in
			 * the exponential phase of slow-start.
			 */
			tp->snd_cwnd += tp->t_maxseg;
		} else
			tp->t_state = TCPS_SYN_RECEIVED;

#if 0
trimthenstep6:
#endif
		/*
		 * Advance th->th_seq to correspond to first data byte.
		 * If data, trim to stay within window,
		 * dropping FIN if necessary.
		 */
		th->th_seq++;
		if (tlen > tp->rcv_wnd) {
			todrop = tlen - tp->rcv_wnd;
			m_adj(m, -todrop);
			tlen = tp->rcv_wnd;
			tiflags &= ~TH_FIN;
			tcpstat_pkt(tcps_rcvpackafterwin, tcps_rcvbyteafterwin,
			    todrop);
		}
		tp->snd_wl1 = th->th_seq - 1;
		tp->rcv_up = th->th_seq;
		goto step6;
	/*
	 * If a new connection request is received while in TIME_WAIT,
	 * drop the old connection and start over if the if the
	 * timestamp or the sequence numbers are above the previous
	 * ones.
	 */
	case TCPS_TIME_WAIT:
		if (((tiflags & (TH_SYN|TH_ACK)) == TH_SYN) &&
		    ((opti.ts_present &&
		    TSTMP_LT(tp->ts_recent, opti.ts_val)) ||
		    SEQ_GT(th->th_seq, tp->rcv_nxt))) {
#if NPF > 0
			/*
			 * The socket will be recreated but the new state
			 * has already been linked to the socket.  Remove the
			 * link between old socket and new state.
			 */
			pf_inp_unlink(inp);
#endif
			/*
			* Advance the iss by at least 32768, but
			* clear the msb in order to make sure
			* that SEG_LT(snd_nxt, iss).
			*/
			iss = tp->snd_nxt +
			    ((arc4random() & 0x7fffffff) | 0x8000);
			reuse = &iss;
			tp = tcp_close(tp);
			inp = NULL;
			goto findpcb;
		}
	}

	/*
	 * States other than LISTEN or SYN_SENT.
	 * First check timestamp, if present.
	 * Then check that at least some bytes of segment are within
	 * receive window.  If segment begins before rcv_nxt,
	 * drop leading data (and SYN); if nothing left, just ack.
	 *
	 * RFC 1323 PAWS: If we have a timestamp reply on this segment
	 * and it's less than opti.ts_recent, drop it.
	 */
	if (opti.ts_present && (tiflags & TH_RST) == 0 && tp->ts_recent &&
	    TSTMP_LT(opti.ts_val, tp->ts_recent)) {

		/* Check to see if ts_recent is over 24 days old.  */
		if ((int)(tcp_now - tp->ts_recent_age) > TCP_PAWS_IDLE) {
			/*
			 * Invalidate ts_recent.  If this segment updates
			 * ts_recent, the age will be reset later and ts_recent
			 * will get a valid value.  If it does not, setting
			 * ts_recent to zero will at least satisfy the
			 * requirement that zero be placed in the timestamp
			 * echo reply when ts_recent isn't valid.  The
			 * age isn't reset until we get a valid ts_recent
			 * because we don't want out-of-order segments to be
			 * dropped when ts_recent is old.
			 */
			tp->ts_recent = 0;
		} else {
			tcpstat_pkt(tcps_rcvduppack, tcps_rcvdupbyte, tlen);
			tcpstat_inc(tcps_pawsdrop);
			goto dropafterack;
		}
	}

	todrop = tp->rcv_nxt - th->th_seq;
	if (todrop > 0) {
		if (tiflags & TH_SYN) {
			tiflags &= ~TH_SYN;
			th->th_seq++;
			if (th->th_urp > 1)
				th->th_urp--;
			else
				tiflags &= ~TH_URG;
			todrop--;
		}
		if (todrop > tlen ||
		    (todrop == tlen && (tiflags & TH_FIN) == 0)) {
			/*
			 * Any valid FIN must be to the left of the
			 * window.  At this point, FIN must be a
			 * duplicate or out-of-sequence, so drop it.
			 */
			tiflags &= ~TH_FIN;
			/*
			 * Send ACK to resynchronize, and drop any data,
			 * but keep on processing for RST or ACK.
			 */
			tp->t_flags |= TF_ACKNOW;
			todrop = tlen;
			tcpstat_pkt(tcps_rcvduppack, tcps_rcvdupbyte, todrop);
		} else {
			tcpstat_pkt(tcps_rcvpartduppack, tcps_rcvpartdupbyte,
			    todrop);
		}
		hdroptlen += todrop;	/* drop from head afterwards */
		th->th_seq += todrop;
		tlen -= todrop;
		if (th->th_urp > todrop)
			th->th_urp -= todrop;
		else {
			tiflags &= ~TH_URG;
			th->th_urp = 0;
		}
	}

	/*
	 * If new data are received on a connection after the
	 * user processes are gone, then RST the other end.
	 */
	if ((so->so_state & SS_NOFDREF) &&
	    tp->t_state > TCPS_CLOSE_WAIT && tlen) {
		tp = tcp_close(tp);
		tcpstat_inc(tcps_rcvafterclose);
		goto dropwithreset;
	}

	/*
	 * If segment ends after window, drop trailing data
	 * (and PUSH and FIN); if nothing left, just ACK.
	 */
	todrop = (th->th_seq + tlen) - (tp->rcv_nxt+tp->rcv_wnd);
	if (todrop > 0) {
		tcpstat_inc(tcps_rcvpackafterwin);
		if (todrop >= tlen) {
			tcpstat_add(tcps_rcvbyteafterwin, tlen);
			/*
			 * If window is closed can only take segments at
			 * window edge, and have to drop data and PUSH from
			 * incoming segments.  Continue processing, but
			 * remember to ack.  Otherwise, drop segment
			 * and ack.
			 */
			if (tp->rcv_wnd == 0 && th->th_seq == tp->rcv_nxt) {
				tp->t_flags |= TF_ACKNOW;
				tcpstat_inc(tcps_rcvwinprobe);
			} else
				goto dropafterack;
		} else
			tcpstat_add(tcps_rcvbyteafterwin, todrop);
		m_adj(m, -todrop);
		tlen -= todrop;
		tiflags &= ~(TH_PUSH|TH_FIN);
	}

	/*
	 * If last ACK falls within this segment's sequence numbers,
	 * record its timestamp if it's more recent.
	 * Cf fix from Braden, see Stevens p. 870
	 */
	if (opti.ts_present && TSTMP_GEQ(opti.ts_val, tp->ts_recent) &&
	    SEQ_LEQ(th->th_seq, tp->last_ack_sent)) {
		if (SEQ_LEQ(tp->last_ack_sent, th->th_seq + tlen +
		    ((tiflags & (TH_SYN|TH_FIN)) != 0)))
			tp->ts_recent = opti.ts_val;
		else
			tp->ts_recent = 0;
		tp->ts_recent_age = tcp_now;
	}

	/*
	 * If the RST bit is set examine the state:
	 *    SYN_RECEIVED STATE:
	 *	If passive open, return to LISTEN state.
	 *	If active open, inform user that connection was refused.
	 *    ESTABLISHED, FIN_WAIT_1, FIN_WAIT2, CLOSE_WAIT STATES:
	 *	Inform user that connection was reset, and close tcb.
	 *    CLOSING, LAST_ACK, TIME_WAIT STATES
	 *	Close the tcb.
	 */
	if (tiflags & TH_RST) {
		if (th->th_seq != tp->last_ack_sent &&
		    th->th_seq != tp->rcv_nxt &&
		    th->th_seq != (tp->rcv_nxt + 1))
			goto drop;

		switch (tp->t_state) {
		case TCPS_SYN_RECEIVED:
#ifdef TCP_ECN
			/* if ECN is enabled, fall back to non-ecn at rexmit */
			if (tcp_do_ecn && !(tp->t_flags & TF_DISABLE_ECN))
				goto drop;
#endif
			so->so_error = ECONNREFUSED;
			goto close;

		case TCPS_ESTABLISHED:
		case TCPS_FIN_WAIT_1:
		case TCPS_FIN_WAIT_2:
		case TCPS_CLOSE_WAIT:
			so->so_error = ECONNRESET;
		close:
			tp->t_state = TCPS_CLOSED;
			tcpstat_inc(tcps_drops);
			tp = tcp_close(tp);
			goto drop;
		case TCPS_CLOSING:
		case TCPS_LAST_ACK:
		case TCPS_TIME_WAIT:
			tp = tcp_close(tp);
			goto drop;
		}
	}

	/*
	 * If a SYN is in the window, then this is an
	 * error and we ACK and drop the packet.
	 */
	if (tiflags & TH_SYN)
		goto dropafterack_ratelim;

	/*
	 * If the ACK bit is off we drop the segment and return.
	 */
	if ((tiflags & TH_ACK) == 0) {
		if (tp->t_flags & TF_ACKNOW)
			goto dropafterack;
		else
			goto drop;
	}

	/*
	 * Ack processing.
	 */
	switch (tp->t_state) {

	/*
	 * In SYN_RECEIVED state, the ack ACKs our SYN, so enter
	 * ESTABLISHED state and continue processing.
	 * The ACK was checked above.
	 */
	case TCPS_SYN_RECEIVED:
		tcpstat_inc(tcps_connects);
		soisconnected(so);
		tp->t_state = TCPS_ESTABLISHED;
		TCP_TIMER_ARM(tp, TCPT_KEEP, tcp_keepidle);
		/* Do window scaling? */
		if ((tp->t_flags & (TF_RCVD_SCALE|TF_REQ_SCALE)) ==
			(TF_RCVD_SCALE|TF_REQ_SCALE)) {
			tp->snd_scale = tp->requested_s_scale;
			tp->rcv_scale = tp->request_r_scale;
			tiwin = th->th_win << tp->snd_scale;
		}
		tcp_flush_queue(tp);
		tp->snd_wl1 = th->th_seq - 1;
		/* fall into ... */

	/*
	 * In ESTABLISHED state: drop duplicate ACKs; ACK out of range
	 * ACKs.  If the ack is in the range
	 *	tp->snd_una < th->th_ack <= tp->snd_max
	 * then advance tp->snd_una to th->th_ack and drop
	 * data from the retransmission queue.  If this ACK reflects
	 * more up to date window information we update our window information.
	 */
	case TCPS_ESTABLISHED:
	case TCPS_FIN_WAIT_1:
	case TCPS_FIN_WAIT_2:
	case TCPS_CLOSE_WAIT:
	case TCPS_CLOSING:
	case TCPS_LAST_ACK:
	case TCPS_TIME_WAIT:
#ifdef TCP_ECN
		/*
		 * if we receive ECE and are not already in recovery phase,
		 * reduce cwnd by half but don't slow-start.
		 * advance snd_last to snd_max not to reduce cwnd again
		 * until all outstanding packets are acked.
		 */
		if (tcp_do_ecn && (tiflags & TH_ECE)) {
			if ((tp->t_flags & TF_ECN_PERMIT) &&
			    SEQ_GEQ(tp->snd_una, tp->snd_last)) {
				u_int win;

				win = min(tp->snd_wnd, tp->snd_cwnd) / tp->t_maxseg;
				if (win > 1) {
					tp->snd_ssthresh = win / 2 * tp->t_maxseg;
					tp->snd_cwnd = tp->snd_ssthresh;
					tp->snd_last = tp->snd_max;
					tp->t_flags |= TF_SEND_CWR;
					tcpstat_inc(tcps_cwr_ecn);
				}
			}
			tcpstat_inc(tcps_ecn_rcvece);
		}
		/*
		 * if we receive CWR, we know that the peer has reduced
		 * its congestion window.  stop sending ecn-echo.
		 */
		if ((tiflags & TH_CWR)) {
			tp->t_flags &= ~TF_RCVD_CE;
			tcpstat_inc(tcps_ecn_rcvcwr);
		}
#endif /* TCP_ECN */

		if (SEQ_LEQ(th->th_ack, tp->snd_una)) {
			/*
			 * Duplicate/old ACK processing.
			 * Increments t_dupacks:
			 *	Pure duplicate (same seq/ack/window, no data)
			 * Doesn't affect t_dupacks:
			 *	Data packets.
			 *	Normal window updates (window opens)
			 * Resets t_dupacks:
			 *	New data ACKed.
			 *	Window shrinks
			 *	Old ACK
			 */
			if (tlen) {
				/* Drop very old ACKs unless th_seq matches */
				if (th->th_seq != tp->rcv_nxt &&
				   SEQ_LT(th->th_ack,
				   tp->snd_una - tp->max_sndwnd)) {
					tcpstat_inc(tcps_rcvacktooold);
					goto drop;
				}
				break;
			}
			/*
			 * If we get an old ACK, there is probably packet
			 * reordering going on.  Be conservative and reset
			 * t_dupacks so that we are less aggressive in
			 * doing a fast retransmit.
			 */
			if (th->th_ack != tp->snd_una) {
				tp->t_dupacks = 0;
				break;
			}
			if (tiwin == tp->snd_wnd) {
				tcpstat_inc(tcps_rcvdupack);
				/*
				 * If we have outstanding data (other than
				 * a window probe), this is a completely
				 * duplicate ack (ie, window info didn't
				 * change), the ack is the biggest we've
				 * seen and we've seen exactly our rexmt
				 * threshold of them, assume a packet
				 * has been dropped and retransmit it.
				 * Kludge snd_nxt & the congestion
				 * window so we send only this one
				 * packet.
				 *
				 * We know we're losing at the current
				 * window size so do congestion avoidance
				 * (set ssthresh to half the current window
				 * and pull our congestion window back to
				 * the new ssthresh).
				 *
				 * Dup acks mean that packets have left the
				 * network (they're now cached at the receiver)
				 * so bump cwnd by the amount in the receiver
				 * to keep a constant cwnd packets in the
				 * network.
				 */
				if (TCP_TIMER_ISARMED(tp, TCPT_REXMT) == 0)
					tp->t_dupacks = 0;
#if defined(TCP_SACK) && defined(TCP_FACK)
				/*
				 * In FACK, can enter fast rec. if the receiver
				 * reports a reass. queue longer than 3 segs.
				 */
				else if (++tp->t_dupacks == tcprexmtthresh ||
				    ((SEQ_GT(tp->snd_fack, tcprexmtthresh *
				    tp->t_maxseg + tp->snd_una)) &&
				    SEQ_GT(tp->snd_una, tp->snd_last))) {
#else
				else if (++tp->t_dupacks == tcprexmtthresh) {
#endif /* TCP_FACK */
					tcp_seq onxt = tp->snd_nxt;
					u_long win =
					    ulmin(tp->snd_wnd, tp->snd_cwnd) /
						2 / tp->t_maxseg;

#if defined(TCP_SACK) || defined(TCP_ECN)
					if (SEQ_LT(th->th_ack, tp->snd_last)){
						/*
						 * False fast retx after
						 * timeout.  Do not cut window.
						 */
						tp->t_dupacks = 0;
						goto drop;
					}
#endif
					if (win < 2)
						win = 2;
					tp->snd_ssthresh = win * tp->t_maxseg;
#ifdef TCP_SACK
					tp->snd_last = tp->snd_max;
					if (tp->sack_enable) {
						TCP_TIMER_DISARM(tp, TCPT_REXMT);
						tp->t_rtttime = 0;
#ifdef TCP_ECN
						tp->t_flags |= TF_SEND_CWR;
#endif
						tcpstat_inc(tcps_cwr_frecovery);
						tcpstat_inc(tcps_sack_recovery_episode);
#if defined(TCP_SACK) && defined(TCP_FACK)
						tp->t_dupacks = tcprexmtthresh;
						(void) tcp_output(tp);
						/*
						 * During FR, snd_cwnd is held
						 * constant for FACK.
						 */
						tp->snd_cwnd = tp->snd_ssthresh;
#else
						/*
						 * tcp_output() will send
						 * oldest SACK-eligible rtx.
						 */
						(void) tcp_output(tp);
						tp->snd_cwnd = tp->snd_ssthresh+
					           tp->t_maxseg * tp->t_dupacks;
#endif /* TCP_FACK */
						goto drop;
					}
#endif /* TCP_SACK */
					TCP_TIMER_DISARM(tp, TCPT_REXMT);
					tp->t_rtttime = 0;
					tp->snd_nxt = th->th_ack;
					tp->snd_cwnd = tp->t_maxseg;
#ifdef TCP_ECN
					tp->t_flags |= TF_SEND_CWR;
#endif
					tcpstat_inc(tcps_cwr_frecovery);
					tcpstat_inc(tcps_sndrexmitfast);
					(void) tcp_output(tp);

					tp->snd_cwnd = tp->snd_ssthresh +
					    tp->t_maxseg * tp->t_dupacks;
					if (SEQ_GT(onxt, tp->snd_nxt))
						tp->snd_nxt = onxt;
					goto drop;
				} else if (tp->t_dupacks > tcprexmtthresh) {
#if defined(TCP_SACK) && defined(TCP_FACK)
					/*
					 * while (awnd < cwnd)
					 *         sendsomething();
					 */
					if (tp->sack_enable) {
						if (tp->snd_awnd < tp->snd_cwnd)
							tcp_output(tp);
						goto drop;
					}
#endif /* TCP_FACK */
					tp->snd_cwnd += tp->t_maxseg;
					(void) tcp_output(tp);
					goto drop;
				}
			} else if (tiwin < tp->snd_wnd) {
				/*
				 * The window was retracted!  Previous dup
				 * ACKs may have been due to packets arriving
				 * after the shrunken window, not a missing
				 * packet, so play it safe and reset t_dupacks
				 */
				tp->t_dupacks = 0;
			}
			break;
		}
		/*
		 * If the congestion window was inflated to account
		 * for the other side's cached packets, retract it.
		 */
#if defined(TCP_SACK)
		if (tp->sack_enable) {
			if (tp->t_dupacks >= tcprexmtthresh) {
				/* Check for a partial ACK */
				if (tcp_sack_partialack(tp, th)) {
#if defined(TCP_SACK) && defined(TCP_FACK)
					/* Force call to tcp_output */
					if (tp->snd_awnd < tp->snd_cwnd)
						tp->t_flags |= TF_NEEDOUTPUT;
#else
					tp->snd_cwnd += tp->t_maxseg;
					tp->t_flags |= TF_NEEDOUTPUT;
#endif /* TCP_FACK */
				} else {
					/* Out of fast recovery */
					tp->snd_cwnd = tp->snd_ssthresh;
					if (tcp_seq_subtract(tp->snd_max,
					    th->th_ack) < tp->snd_ssthresh)
						tp->snd_cwnd =
						   tcp_seq_subtract(tp->snd_max,
					           th->th_ack);
					tp->t_dupacks = 0;
#if defined(TCP_SACK) && defined(TCP_FACK)
					if (SEQ_GT(th->th_ack, tp->snd_fack))
						tp->snd_fack = th->th_ack;
#endif /* TCP_FACK */
				}
			}
		} else {
			if (tp->t_dupacks >= tcprexmtthresh &&
			    !tcp_newreno(tp, th)) {
				/* Out of fast recovery */
				tp->snd_cwnd = tp->snd_ssthresh;
				if (tcp_seq_subtract(tp->snd_max, th->th_ack) <
				    tp->snd_ssthresh)
					tp->snd_cwnd =
					    tcp_seq_subtract(tp->snd_max,
					    th->th_ack);
				tp->t_dupacks = 0;
			}
		}
		if (tp->t_dupacks < tcprexmtthresh)
			tp->t_dupacks = 0;
#else /* else no TCP_SACK */
		if (tp->t_dupacks >= tcprexmtthresh &&
		    tp->snd_cwnd > tp->snd_ssthresh)
			tp->snd_cwnd = tp->snd_ssthresh;
		tp->t_dupacks = 0;
#endif
		if (SEQ_GT(th->th_ack, tp->snd_max)) {
			tcpstat_inc(tcps_rcvacktoomuch);
			goto dropafterack_ratelim;
		}
		acked = th->th_ack - tp->snd_una;
		tcpstat_pkt(tcps_rcvackpack, tcps_rcvackbyte, acked);

		/*
		 * If we have a timestamp reply, update smoothed
		 * round trip time.  If no timestamp is present but
		 * transmit timer is running and timed sequence
		 * number was acked, update smoothed round trip time.
		 * Since we now have an rtt measurement, cancel the
		 * timer backoff (cf., Phil Karn's retransmit alg.).
		 * Recompute the initial retransmit timer.
		 */
		if (opti.ts_present && opti.ts_ecr)
			tcp_xmit_timer(tp, tcp_now - opti.ts_ecr);
		else if (tp->t_rtttime && SEQ_GT(th->th_ack, tp->t_rtseq))
			tcp_xmit_timer(tp, tcp_now - tp->t_rtttime);

		/*
		 * If all outstanding data is acked, stop retransmit
		 * timer and remember to restart (more output or persist).
		 * If there is more data to be acked, restart retransmit
		 * timer, using current (possibly backed-off) value.
		 */
		if (th->th_ack == tp->snd_max) {
			TCP_TIMER_DISARM(tp, TCPT_REXMT);
			tp->t_flags |= TF_NEEDOUTPUT;
		} else if (TCP_TIMER_ISARMED(tp, TCPT_PERSIST) == 0)
			TCP_TIMER_ARM(tp, TCPT_REXMT, tp->t_rxtcur);
		/*
		 * When new data is acked, open the congestion window.
		 * If the window gives us less than ssthresh packets
		 * in flight, open exponentially (maxseg per packet).
		 * Otherwise open linearly: maxseg per window
		 * (maxseg^2 / cwnd per packet).
		 */
		{
		u_int cw = tp->snd_cwnd;
		u_int incr = tp->t_maxseg;

		if (cw > tp->snd_ssthresh)
			incr = incr * incr / cw;
#if defined (TCP_SACK)
		if (tp->t_dupacks < tcprexmtthresh)
#endif
		tp->snd_cwnd = ulmin(cw + incr, TCP_MAXWIN<<tp->snd_scale);
		}
		ND6_HINT(tp);
		if (acked > so->so_snd.sb_cc) {
			tp->snd_wnd -= so->so_snd.sb_cc;
			sbdrop(&so->so_snd, (int)so->so_snd.sb_cc);
			ourfinisacked = 1;
		} else {
			sbdrop(&so->so_snd, acked);
			tp->snd_wnd -= acked;
			ourfinisacked = 0;
		}

		tcp_update_sndspace(tp);
		if (sb_notify(&so->so_snd)) {
			tp->t_flags |= TF_BLOCKOUTPUT;
			sowwakeup(so);
			tp->t_flags &= ~TF_BLOCKOUTPUT;
		}

		/*
		 * If we had a pending ICMP message that referred to data
		 * that have just been acknowledged, disregard the recorded
		 * ICMP message.
		 */
		if ((tp->t_flags & TF_PMTUD_PEND) &&
		    SEQ_GT(th->th_ack, tp->t_pmtud_th_seq))
			tp->t_flags &= ~TF_PMTUD_PEND;

		/*
		 * Keep track of the largest chunk of data acknowledged
		 * since last PMTU update
		 */
		if (tp->t_pmtud_mss_acked < acked)
			tp->t_pmtud_mss_acked = acked;

		tp->snd_una = th->th_ack;
#ifdef TCP_ECN
		/* sync snd_last with snd_una */
		if (SEQ_GT(tp->snd_una, tp->snd_last))
			tp->snd_last = tp->snd_una;
#endif
		if (SEQ_LT(tp->snd_nxt, tp->snd_una))
			tp->snd_nxt = tp->snd_una;
#if defined (TCP_SACK) && defined (TCP_FACK)
		if (SEQ_GT(tp->snd_una, tp->snd_fack)) {
			tp->snd_fack = tp->snd_una;
			/* Update snd_awnd for partial ACK
			 * without any SACK blocks.
			 */
			tp->snd_awnd = tcp_seq_subtract(tp->snd_nxt,
				tp->snd_fack) + tp->retran_data;
		}
#endif

		switch (tp->t_state) {

		/*
		 * In FIN_WAIT_1 STATE in addition to the processing
		 * for the ESTABLISHED state if our FIN is now acknowledged
		 * then enter FIN_WAIT_2.
		 */
		case TCPS_FIN_WAIT_1:
			if (ourfinisacked) {
				/*
				 * If we can't receive any more
				 * data, then closing user can proceed.
				 * Starting the timer is contrary to the
				 * specification, but if we don't get a FIN
				 * we'll hang forever.
				 */
				if (so->so_state & SS_CANTRCVMORE) {
					soisdisconnected(so);
					TCP_TIMER_ARM(tp, TCPT_2MSL, tcp_maxidle);
				}
				tp->t_state = TCPS_FIN_WAIT_2;
			}
			break;

		/*
		 * In CLOSING STATE in addition to the processing for
		 * the ESTABLISHED state if the ACK acknowledges our FIN
		 * then enter the TIME-WAIT state, otherwise ignore
		 * the segment.
		 */
		case TCPS_CLOSING:
			if (ourfinisacked) {
				tp->t_state = TCPS_TIME_WAIT;
				tcp_canceltimers(tp);
				TCP_TIMER_ARM(tp, TCPT_2MSL, 2 * TCPTV_MSL);
				soisdisconnected(so);
			}
			break;

		/*
		 * In LAST_ACK, we may still be waiting for data to drain
		 * and/or to be acked, as well as for the ack of our FIN.
		 * If our FIN is now acknowledged, delete the TCB,
		 * enter the closed state and return.
		 */
		case TCPS_LAST_ACK:
			if (ourfinisacked) {
				tp = tcp_close(tp);
				goto drop;
			}
			break;

		/*
		 * In TIME_WAIT state the only thing that should arrive
		 * is a retransmission of the remote FIN.  Acknowledge
		 * it and restart the finack timer.
		 */
		case TCPS_TIME_WAIT:
			TCP_TIMER_ARM(tp, TCPT_2MSL, 2 * TCPTV_MSL);
			goto dropafterack;
		}
	}

step6:
	/*
	 * Update window information.
	 * Don't look at window if no ACK: TAC's send garbage on first SYN.
	 */
	if ((tiflags & TH_ACK) &&
	    (SEQ_LT(tp->snd_wl1, th->th_seq) || (tp->snd_wl1 == th->th_seq &&
	    (SEQ_LT(tp->snd_wl2, th->th_ack) ||
	    (tp->snd_wl2 == th->th_ack && tiwin > tp->snd_wnd))))) {
		/* keep track of pure window updates */
		if (tlen == 0 &&
		    tp->snd_wl2 == th->th_ack && tiwin > tp->snd_wnd)
			tcpstat_inc(tcps_rcvwinupd);
		tp->snd_wnd = tiwin;
		tp->snd_wl1 = th->th_seq;
		tp->snd_wl2 = th->th_ack;
		if (tp->snd_wnd > tp->max_sndwnd)
			tp->max_sndwnd = tp->snd_wnd;
		tp->t_flags |= TF_NEEDOUTPUT;
	}

	/*
	 * Process segments with URG.
	 */
	if ((tiflags & TH_URG) && th->th_urp &&
	    TCPS_HAVERCVDFIN(tp->t_state) == 0) {
		/*
		 * This is a kludge, but if we receive and accept
		 * random urgent pointers, we'll crash in
		 * soreceive.  It's hard to imagine someone
		 * actually wanting to send this much urgent data.
		 */
		if (th->th_urp + so->so_rcv.sb_cc > sb_max) {
			th->th_urp = 0;			/* XXX */
			tiflags &= ~TH_URG;		/* XXX */
			goto dodata;			/* XXX */
		}
		/*
		 * If this segment advances the known urgent pointer,
		 * then mark the data stream.  This should not happen
		 * in CLOSE_WAIT, CLOSING, LAST_ACK or TIME_WAIT STATES since
		 * a FIN has been received from the remote side.
		 * In these states we ignore the URG.
		 *
		 * According to RFC961 (Assigned Protocols),
		 * the urgent pointer points to the last octet
		 * of urgent data.  We continue, however,
		 * to consider it to indicate the first octet
		 * of data past the urgent section as the original
		 * spec states (in one of two places).
		 */
		if (SEQ_GT(th->th_seq+th->th_urp, tp->rcv_up)) {
			tp->rcv_up = th->th_seq + th->th_urp;
			so->so_oobmark = so->so_rcv.sb_cc +
			    (tp->rcv_up - tp->rcv_nxt) - 1;
			if (so->so_oobmark == 0)
				so->so_state |= SS_RCVATMARK;
			sohasoutofband(so);
			tp->t_oobflags &= ~(TCPOOB_HAVEDATA | TCPOOB_HADDATA);
		}
		/*
		 * Remove out of band data so doesn't get presented to user.
		 * This can happen independent of advancing the URG pointer,
		 * but if two URG's are pending at once, some out-of-band
		 * data may creep in... ick.
		 */
		if (th->th_urp <= (u_int16_t) tlen &&
		    (so->so_options & SO_OOBINLINE) == 0)
		        tcp_pulloutofband(so, th->th_urp, m, hdroptlen);
	} else
		/*
		 * If no out of band data is expected,
		 * pull receive urgent pointer along
		 * with the receive window.
		 */
		if (SEQ_GT(tp->rcv_nxt, tp->rcv_up))
			tp->rcv_up = tp->rcv_nxt;
dodata:							/* XXX */

	/*
	 * Process the segment text, merging it into the TCP sequencing queue,
	 * and arranging for acknowledgment of receipt if necessary.
	 * This process logically involves adjusting tp->rcv_wnd as data
	 * is presented to the user (this happens in tcp_usrreq.c,
	 * case PRU_RCVD).  If a FIN has already been received on this
	 * connection then we just ignore the text.
	 */
	if ((tlen || (tiflags & TH_FIN)) &&
	    TCPS_HAVERCVDFIN(tp->t_state) == 0) {
#ifdef TCP_SACK
		tcp_seq laststart = th->th_seq;
		tcp_seq lastend = th->th_seq + tlen;
#endif
		if (th->th_seq == tp->rcv_nxt && TAILQ_EMPTY(&tp->t_segq) &&
		    tp->t_state == TCPS_ESTABLISHED) {
			TCP_SETUP_ACK(tp, tiflags, m);
			tp->rcv_nxt += tlen;
			tiflags = th->th_flags & TH_FIN;
			tcpstat_pkt(tcps_rcvpack, tcps_rcvbyte, tlen);
			ND6_HINT(tp);
			if (so->so_state & SS_CANTRCVMORE)
				m_freem(m);
			else {
				m_adj(m, hdroptlen);
				sbappendstream(&so->so_rcv, m);
			}
			tp->t_flags |= TF_BLOCKOUTPUT;
			sorwakeup(so);
			tp->t_flags &= ~TF_BLOCKOUTPUT;
		} else {
			m_adj(m, hdroptlen);
			tiflags = tcp_reass(tp, th, m, &tlen);
			tp->t_flags |= TF_ACKNOW;
		}
#ifdef TCP_SACK
		if (tp->sack_enable)
			tcp_update_sack_list(tp, laststart, lastend);
#endif

		/*
		 * variable len never referenced again in modern BSD,
		 * so why bother computing it ??
		 */
#if 0
		/*
		 * Note the amount of data that peer has sent into
		 * our window, in order to estimate the sender's
		 * buffer size.
		 */
		len = so->so_rcv.sb_hiwat - (tp->rcv_adv - tp->rcv_nxt);
#endif /* 0 */
	} else {
		m_freem(m);
		tiflags &= ~TH_FIN;
	}

	/*
	 * If FIN is received ACK the FIN and let the user know
	 * that the connection is closing.  Ignore a FIN received before
	 * the connection is fully established.
	 */
	if ((tiflags & TH_FIN) && TCPS_HAVEESTABLISHED(tp->t_state)) {
		if (TCPS_HAVERCVDFIN(tp->t_state) == 0) {
			socantrcvmore(so);
			tp->t_flags |= TF_ACKNOW;
			tp->rcv_nxt++;
		}
		switch (tp->t_state) {

		/*
		 * In ESTABLISHED STATE enter the CLOSE_WAIT state.
		 */
		case TCPS_ESTABLISHED:
			tp->t_state = TCPS_CLOSE_WAIT;
			break;

		/*
		 * If still in FIN_WAIT_1 STATE FIN has not been acked so
		 * enter the CLOSING state.
		 */
		case TCPS_FIN_WAIT_1:
			tp->t_state = TCPS_CLOSING;
			break;

		/*
		 * In FIN_WAIT_2 state enter the TIME_WAIT state,
		 * starting the time-wait timer, turning off the other
		 * standard timers.
		 */
		case TCPS_FIN_WAIT_2:
			tp->t_state = TCPS_TIME_WAIT;
			tcp_canceltimers(tp);
			TCP_TIMER_ARM(tp, TCPT_2MSL, 2 * TCPTV_MSL);
			soisdisconnected(so);
			break;

		/*
		 * In TIME_WAIT state restart the 2 MSL time_wait timer.
		 */
		case TCPS_TIME_WAIT:
			TCP_TIMER_ARM(tp, TCPT_2MSL, 2 * TCPTV_MSL);
			break;
		}
	}
	if (so->so_options & SO_DEBUG) {
		switch (tp->pf) {
#ifdef INET6
		case PF_INET6:
			tcp_trace(TA_INPUT, ostate, tp, (caddr_t) &tcp_saveti6,
			    0, tlen);
			break;
#endif /* INET6 */
		case PF_INET:
			tcp_trace(TA_INPUT, ostate, tp, (caddr_t) &tcp_saveti,
			    0, tlen);
			break;
		}
	}

	/*
	 * Return any desired output.
	 */
	if (tp->t_flags & (TF_ACKNOW|TF_NEEDOUTPUT))
		(void) tcp_output(tp);
	return IPPROTO_DONE;

badsyn:
	/*
	 * Received a bad SYN.  Increment counters and dropwithreset.
	 */
	tcpstat_inc(tcps_badsyn);
	tp = NULL;
	goto dropwithreset;

dropafterack_ratelim:
	if (ppsratecheck(&tcp_ackdrop_ppslim_last, &tcp_ackdrop_ppslim_count,
	    tcp_ackdrop_ppslim) == 0) {
		/* XXX stat */
		goto drop;
	}
	/* ...fall into dropafterack... */

dropafterack:
	/*
	 * Generate an ACK dropping incoming segment if it occupies
	 * sequence space, where the ACK reflects our state.
	 */
	if (tiflags & TH_RST)
		goto drop;
	m_freem(m);
	tp->t_flags |= TF_ACKNOW;
	(void) tcp_output(tp);
	return IPPROTO_DONE;

dropwithreset_ratelim:
	/*
	 * We may want to rate-limit RSTs in certain situations,
	 * particularly if we are sending an RST in response to
	 * an attempt to connect to or otherwise communicate with
	 * a port for which we have no socket.
	 */
	if (ppsratecheck(&tcp_rst_ppslim_last, &tcp_rst_ppslim_count,
	    tcp_rst_ppslim) == 0) {
		/* XXX stat */
		goto drop;
	}
	/* ...fall into dropwithreset... */

dropwithreset:
	/*
	 * Generate a RST, dropping incoming segment.
	 * Make ACK acceptable to originator of segment.
	 * Don't bother to respond to RST.
	 */
	if (tiflags & TH_RST)
		goto drop;
	if (tiflags & TH_ACK) {
		tcp_respond(tp, mtod(m, caddr_t), th, (tcp_seq)0, th->th_ack,
		    TH_RST, m->m_pkthdr.ph_rtableid);
	} else {
		if (tiflags & TH_SYN)
			tlen++;
		tcp_respond(tp, mtod(m, caddr_t), th, th->th_seq + tlen,
		    (tcp_seq)0, TH_RST|TH_ACK, m->m_pkthdr.ph_rtableid);
	}
	m_freem(m);
	return IPPROTO_DONE;

drop:
	/*
	 * Drop space held by incoming segment and return.
	 */
	if (tp && (tp->t_inpcb->inp_socket->so_options & SO_DEBUG)) {
		switch (tp->pf) {
#ifdef INET6
		case PF_INET6:
			tcp_trace(TA_DROP, ostate, tp, (caddr_t) &tcp_saveti6,
			    0, tlen);
			break;
#endif /* INET6 */
		case PF_INET:
			tcp_trace(TA_DROP, ostate, tp, (caddr_t) &tcp_saveti,
			    0, tlen);
			break;
		}
	}

	m_freem(m);
	return IPPROTO_DONE;
}

int
tcp_dooptions(struct tcpcb *tp, u_char *cp, int cnt, struct tcphdr *th,
    struct mbuf *m, int iphlen, struct tcp_opt_info *oi,
    u_int rtableid)
{
	u_int16_t mss = 0;
	int opt, optlen;
#ifdef TCP_SIGNATURE
	caddr_t sigp = NULL;
	struct tdb *tdb = NULL;
#endif /* TCP_SIGNATURE */

	for (; cp && cnt > 0; cnt -= optlen, cp += optlen) {
		opt = cp[0];
		if (opt == TCPOPT_EOL)
			break;
		if (opt == TCPOPT_NOP)
			optlen = 1;
		else {
			if (cnt < 2)
				break;
			optlen = cp[1];
			if (optlen < 2 || optlen > cnt)
				break;
		}
		switch (opt) {

		default:
			continue;

		case TCPOPT_MAXSEG:
			if (optlen != TCPOLEN_MAXSEG)
				continue;
			if (!(th->th_flags & TH_SYN))
				continue;
			if (TCPS_HAVERCVDSYN(tp->t_state))
				continue;
			memcpy(&mss, cp + 2, sizeof(mss));
			mss = ntohs(mss);
			oi->maxseg = mss;
			break;

		case TCPOPT_WINDOW:
			if (optlen != TCPOLEN_WINDOW)
				continue;
			if (!(th->th_flags & TH_SYN))
				continue;
			if (TCPS_HAVERCVDSYN(tp->t_state))
				continue;
			tp->t_flags |= TF_RCVD_SCALE;
			tp->requested_s_scale = min(cp[2], TCP_MAX_WINSHIFT);
			break;

		case TCPOPT_TIMESTAMP:
			if (optlen != TCPOLEN_TIMESTAMP)
				continue;
			oi->ts_present = 1;
			memcpy(&oi->ts_val, cp + 2, sizeof(oi->ts_val));
			oi->ts_val = ntohl(oi->ts_val);
			memcpy(&oi->ts_ecr, cp + 6, sizeof(oi->ts_ecr));
			oi->ts_ecr = ntohl(oi->ts_ecr);

			if (!(th->th_flags & TH_SYN))
				continue;
			if (TCPS_HAVERCVDSYN(tp->t_state))
				continue;
			/*
			 * A timestamp received in a SYN makes
			 * it ok to send timestamp requests and replies.
			 */
			tp->t_flags |= TF_RCVD_TSTMP;
			tp->ts_recent = oi->ts_val;
			tp->ts_recent_age = tcp_now;
			break;

#ifdef TCP_SACK
		case TCPOPT_SACK_PERMITTED:
			if (!tp->sack_enable || optlen!=TCPOLEN_SACK_PERMITTED)
				continue;
			if (!(th->th_flags & TH_SYN))
				continue;
			if (TCPS_HAVERCVDSYN(tp->t_state))
				continue;
			/* MUST only be set on SYN */
			tp->t_flags |= TF_SACK_PERMIT;
			break;
		case TCPOPT_SACK:
			tcp_sack_option(tp, th, cp, optlen);
			break;
#endif
#ifdef TCP_SIGNATURE
		case TCPOPT_SIGNATURE:
			if (optlen != TCPOLEN_SIGNATURE)
				continue;

			if (sigp && timingsafe_bcmp(sigp, cp + 2, 16))
				return (-1);

			sigp = cp + 2;
			break;
#endif /* TCP_SIGNATURE */
		}
	}

#ifdef TCP_SIGNATURE
	if (tp->t_flags & TF_SIGNATURE) {
		union sockaddr_union src, dst;

		memset(&src, 0, sizeof(union sockaddr_union));
		memset(&dst, 0, sizeof(union sockaddr_union));

		switch (tp->pf) {
		case 0:
		case AF_INET:
			src.sa.sa_len = sizeof(struct sockaddr_in);
			src.sa.sa_family = AF_INET;
			src.sin.sin_addr = mtod(m, struct ip *)->ip_src;
			dst.sa.sa_len = sizeof(struct sockaddr_in);
			dst.sa.sa_family = AF_INET;
			dst.sin.sin_addr = mtod(m, struct ip *)->ip_dst;
			break;
#ifdef INET6
		case AF_INET6:
			src.sa.sa_len = sizeof(struct sockaddr_in6);
			src.sa.sa_family = AF_INET6;
			src.sin6.sin6_addr = mtod(m, struct ip6_hdr *)->ip6_src;
			dst.sa.sa_len = sizeof(struct sockaddr_in6);
			dst.sa.sa_family = AF_INET6;
			dst.sin6.sin6_addr = mtod(m, struct ip6_hdr *)->ip6_dst;
			break;
#endif /* INET6 */
		}

		tdb = gettdbbysrcdst(rtable_l2(rtableid),
		    0, &src, &dst, IPPROTO_TCP);

		/*
		 * We don't have an SA for this peer, so we turn off
		 * TF_SIGNATURE on the listen socket
		 */
		if (tdb == NULL && tp->t_state == TCPS_LISTEN)
			tp->t_flags &= ~TF_SIGNATURE;

	}

	if ((sigp ? TF_SIGNATURE : 0) ^ (tp->t_flags & TF_SIGNATURE)) {
		tcpstat_inc(tcps_rcvbadsig);
		return (-1);
	}

	if (sigp) {
		char sig[16];

		if (tdb == NULL) {
			tcpstat_inc(tcps_rcvbadsig);
			return (-1);
		}

		if (tcp_signature(tdb, tp->pf, m, th, iphlen, 1, sig) < 0)
			return (-1);

		if (timingsafe_bcmp(sig, sigp, 16)) {
			tcpstat_inc(tcps_rcvbadsig);
			return (-1);
		}

		tcpstat_inc(tcps_rcvgoodsig);
	}
#endif /* TCP_SIGNATURE */

	return (0);
}

#if defined(TCP_SACK)
u_long
tcp_seq_subtract(u_long a, u_long b)
{
	return ((long)(a - b));
}
#endif


#ifdef TCP_SACK
/*
 * This function is called upon receipt of new valid data (while not in header
 * prediction mode), and it updates the ordered list of sacks.
 */
void
tcp_update_sack_list(struct tcpcb *tp, tcp_seq rcv_laststart,
    tcp_seq rcv_lastend)
{
	/*
	 * First reported block MUST be the most recent one.  Subsequent
	 * blocks SHOULD be in the order in which they arrived at the
	 * receiver.  These two conditions make the implementation fully
	 * compliant with RFC 2018.
	 */
	int i, j = 0, count = 0, lastpos = -1;
	struct sackblk sack, firstsack, temp[MAX_SACK_BLKS];

	/* First clean up current list of sacks */
	for (i = 0; i < tp->rcv_numsacks; i++) {
		sack = tp->sackblks[i];
		if (sack.start == 0 && sack.end == 0) {
			count++; /* count = number of blocks to be discarded */
			continue;
		}
		if (SEQ_LEQ(sack.end, tp->rcv_nxt)) {
			tp->sackblks[i].start = tp->sackblks[i].end = 0;
			count++;
		} else {
			temp[j].start = tp->sackblks[i].start;
			temp[j++].end = tp->sackblks[i].end;
		}
	}
	tp->rcv_numsacks -= count;
	if (tp->rcv_numsacks == 0) { /* no sack blocks currently (fast path) */
		tcp_clean_sackreport(tp);
		if (SEQ_LT(tp->rcv_nxt, rcv_laststart)) {
			/* ==> need first sack block */
			tp->sackblks[0].start = rcv_laststart;
			tp->sackblks[0].end = rcv_lastend;
			tp->rcv_numsacks = 1;
		}
		return;
	}
	/* Otherwise, sack blocks are already present. */
	for (i = 0; i < tp->rcv_numsacks; i++)
		tp->sackblks[i] = temp[i]; /* first copy back sack list */
	if (SEQ_GEQ(tp->rcv_nxt, rcv_lastend))
		return;     /* sack list remains unchanged */
	/*
	 * From here, segment just received should be (part of) the 1st sack.
	 * Go through list, possibly coalescing sack block entries.
	 */
	firstsack.start = rcv_laststart;
	firstsack.end = rcv_lastend;
	for (i = 0; i < tp->rcv_numsacks; i++) {
		sack = tp->sackblks[i];
		if (SEQ_LT(sack.end, firstsack.start) ||
		    SEQ_GT(sack.start, firstsack.end))
			continue; /* no overlap */
		if (sack.start == firstsack.start && sack.end == firstsack.end){
			/*
			 * identical block; delete it here since we will
			 * move it to the front of the list.
			 */
			tp->sackblks[i].start = tp->sackblks[i].end = 0;
			lastpos = i;    /* last posn with a zero entry */
			continue;
		}
		if (SEQ_LEQ(sack.start, firstsack.start))
			firstsack.start = sack.start; /* merge blocks */
		if (SEQ_GEQ(sack.end, firstsack.end))
			firstsack.end = sack.end;     /* merge blocks */
		tp->sackblks[i].start = tp->sackblks[i].end = 0;
		lastpos = i;    /* last posn with a zero entry */
	}
	if (lastpos != -1) {    /* at least one merge */
		for (i = 0, j = 1; i < tp->rcv_numsacks; i++) {
			sack = tp->sackblks[i];
			if (sack.start == 0 && sack.end == 0)
				continue;
			temp[j++] = sack;
		}
		tp->rcv_numsacks = j; /* including first blk (added later) */
		for (i = 1; i < tp->rcv_numsacks; i++) /* now copy back */
			tp->sackblks[i] = temp[i];
	} else {        /* no merges -- shift sacks by 1 */
		if (tp->rcv_numsacks < MAX_SACK_BLKS)
			tp->rcv_numsacks++;
		for (i = tp->rcv_numsacks-1; i > 0; i--)
			tp->sackblks[i] = tp->sackblks[i-1];
	}
	tp->sackblks[0] = firstsack;
	return;
}

/*
 * Process the TCP SACK option.  tp->snd_holes is an ordered list
 * of holes (oldest to newest, in terms of the sequence space).
 */
void
tcp_sack_option(struct tcpcb *tp, struct tcphdr *th, u_char *cp, int optlen)
{
	int tmp_olen;
	u_char *tmp_cp;
	struct sackhole *cur, *p, *temp;

	if (!tp->sack_enable)
		return;
	/* SACK without ACK doesn't make sense. */
	if ((th->th_flags & TH_ACK) == 0)
	       return;
	/* Make sure the ACK on this segment is in [snd_una, snd_max]. */
	if (SEQ_LT(th->th_ack, tp->snd_una) ||
	    SEQ_GT(th->th_ack, tp->snd_max))
		return;
	/* Note: TCPOLEN_SACK must be 2*sizeof(tcp_seq) */
	if (optlen <= 2 || (optlen - 2) % TCPOLEN_SACK != 0)
		return;
	/* Note: TCPOLEN_SACK must be 2*sizeof(tcp_seq) */
	tmp_cp = cp + 2;
	tmp_olen = optlen - 2;
	tcpstat_inc(tcps_sack_rcv_opts);
	if (tp->snd_numholes < 0)
		tp->snd_numholes = 0;
	if (tp->t_maxseg == 0)
		panic("tcp_sack_option"); /* Should never happen */
	while (tmp_olen > 0) {
		struct sackblk sack;

		memcpy(&sack.start, tmp_cp, sizeof(tcp_seq));
		sack.start = ntohl(sack.start);
		memcpy(&sack.end, tmp_cp + sizeof(tcp_seq), sizeof(tcp_seq));
		sack.end = ntohl(sack.end);
		tmp_olen -= TCPOLEN_SACK;
		tmp_cp += TCPOLEN_SACK;
		if (SEQ_LEQ(sack.end, sack.start))
			continue; /* bad SACK fields */
		if (SEQ_LEQ(sack.end, tp->snd_una))
			continue; /* old block */
#if defined(TCP_SACK) && defined(TCP_FACK)
		/* Updates snd_fack.  */
		if (SEQ_GT(sack.end, tp->snd_fack))
			tp->snd_fack = sack.end;
#endif /* TCP_FACK */
		if (SEQ_GT(th->th_ack, tp->snd_una)) {
			if (SEQ_LT(sack.start, th->th_ack))
				continue;
		}
		if (SEQ_GT(sack.end, tp->snd_max))
			continue;
		if (tp->snd_holes == NULL) { /* first hole */
			tp->snd_holes = (struct sackhole *)
			    pool_get(&sackhl_pool, PR_NOWAIT);
			if (tp->snd_holes == NULL) {
				/* ENOBUFS, so ignore SACKed block for now*/
				goto done;
			}
			cur = tp->snd_holes;
			cur->start = th->th_ack;
			cur->end = sack.start;
			cur->rxmit = cur->start;
			cur->next = NULL;
			tp->snd_numholes = 1;
			tp->rcv_lastsack = sack.end;
			/*
			 * dups is at least one.  If more data has been
			 * SACKed, it can be greater than one.
			 */
			cur->dups = min(tcprexmtthresh,
			    ((sack.end - cur->end)/tp->t_maxseg));
			if (cur->dups < 1)
				cur->dups = 1;
			continue; /* with next sack block */
		}
		/* Go thru list of holes:  p = previous,  cur = current */
		p = cur = tp->snd_holes;
		while (cur) {
			if (SEQ_LEQ(sack.end, cur->start))
				/* SACKs data before the current hole */
				break; /* no use going through more holes */
			if (SEQ_GEQ(sack.start, cur->end)) {
				/* SACKs data beyond the current hole */
				cur->dups++;
				if (((sack.end - cur->end)/tp->t_maxseg) >=
				    tcprexmtthresh)
					cur->dups = tcprexmtthresh;
				p = cur;
				cur = cur->next;
				continue;
			}
			if (SEQ_LEQ(sack.start, cur->start)) {
				/* Data acks at least the beginning of hole */
#if defined(TCP_SACK) && defined(TCP_FACK)
				if (SEQ_GT(sack.end, cur->rxmit))
					tp->retran_data -=
					    tcp_seq_subtract(cur->rxmit,
					    cur->start);
				else
					tp->retran_data -=
					    tcp_seq_subtract(sack.end,
					    cur->start);
#endif /* TCP_FACK */
				if (SEQ_GEQ(sack.end, cur->end)) {
					/* Acks entire hole, so delete hole */
					if (p != cur) {
						p->next = cur->next;
						pool_put(&sackhl_pool, cur);
						cur = p->next;
					} else {
						cur = cur->next;
						pool_put(&sackhl_pool, p);
						p = cur;
						tp->snd_holes = p;
					}
					tp->snd_numholes--;
					continue;
				}
				/* otherwise, move start of hole forward */
				cur->start = sack.end;
				cur->rxmit = SEQ_MAX(cur->rxmit, cur->start);
				p = cur;
				cur = cur->next;
				continue;
			}
			/* move end of hole backward */
			if (SEQ_GEQ(sack.end, cur->end)) {
#if defined(TCP_SACK) && defined(TCP_FACK)
				if (SEQ_GT(cur->rxmit, sack.start))
					tp->retran_data -=
					    tcp_seq_subtract(cur->rxmit,
					    sack.start);
#endif /* TCP_FACK */
				cur->end = sack.start;
				cur->rxmit = SEQ_MIN(cur->rxmit, cur->end);
				cur->dups++;
				if (((sack.end - cur->end)/tp->t_maxseg) >=
				    tcprexmtthresh)
					cur->dups = tcprexmtthresh;
				p = cur;
				cur = cur->next;
				continue;
			}
			if (SEQ_LT(cur->start, sack.start) &&
			    SEQ_GT(cur->end, sack.end)) {
				/*
				 * ACKs some data in middle of a hole; need to
				 * split current hole
				 */
				temp = (struct sackhole *)
				    pool_get(&sackhl_pool, PR_NOWAIT);
				if (temp == NULL)
					goto done; /* ENOBUFS */
#if defined(TCP_SACK) && defined(TCP_FACK)
				if (SEQ_GT(cur->rxmit, sack.end))
					tp->retran_data -=
					    tcp_seq_subtract(sack.end,
					    sack.start);
				else if (SEQ_GT(cur->rxmit, sack.start))
					tp->retran_data -=
					    tcp_seq_subtract(cur->rxmit,
					    sack.start);
#endif /* TCP_FACK */
				temp->next = cur->next;
				temp->start = sack.end;
				temp->end = cur->end;
				temp->dups = cur->dups;
				temp->rxmit = SEQ_MAX(cur->rxmit, temp->start);
				cur->end = sack.start;
				cur->rxmit = SEQ_MIN(cur->rxmit, cur->end);
				cur->dups++;
				if (((sack.end - cur->end)/tp->t_maxseg) >=
					tcprexmtthresh)
					cur->dups = tcprexmtthresh;
				cur->next = temp;
				p = temp;
				cur = p->next;
				tp->snd_numholes++;
			}
		}
		/* At this point, p points to the last hole on the list */
		if (SEQ_LT(tp->rcv_lastsack, sack.start)) {
			/*
			 * Need to append new hole at end.
			 * Last hole is p (and it's not NULL).
			 */
			temp = (struct sackhole *)
			    pool_get(&sackhl_pool, PR_NOWAIT);
			if (temp == NULL)
				goto done; /* ENOBUFS */
			temp->start = tp->rcv_lastsack;
			temp->end = sack.start;
			temp->dups = min(tcprexmtthresh,
			    ((sack.end - sack.start)/tp->t_maxseg));
			if (temp->dups < 1)
				temp->dups = 1;
			temp->rxmit = temp->start;
			temp->next = 0;
			p->next = temp;
			tp->rcv_lastsack = sack.end;
			tp->snd_numholes++;
		}
	}
done:
#if defined(TCP_SACK) && defined(TCP_FACK)
	/*
	 * Update retran_data and snd_awnd.  Go through the list of
	 * holes.   Increment retran_data by (hole->rxmit - hole->start).
	 */
	tp->retran_data = 0;
	cur = tp->snd_holes;
	while (cur) {
		tp->retran_data += cur->rxmit - cur->start;
		cur = cur->next;
	}
	tp->snd_awnd = tcp_seq_subtract(tp->snd_nxt, tp->snd_fack) +
	    tp->retran_data;
#endif /* TCP_FACK */

	return;
}

/*
 * Delete stale (i.e, cumulatively ack'd) holes.  Hole is deleted only if
 * it is completely acked; otherwise, tcp_sack_option(), called from
 * tcp_dooptions(), will fix up the hole.
 */
void
tcp_del_sackholes(struct tcpcb *tp, struct tcphdr *th)
{
	if (tp->sack_enable && tp->t_state != TCPS_LISTEN) {
		/* max because this could be an older ack just arrived */
		tcp_seq lastack = SEQ_GT(th->th_ack, tp->snd_una) ?
			th->th_ack : tp->snd_una;
		struct sackhole *cur = tp->snd_holes;
		struct sackhole *prev;
		while (cur)
			if (SEQ_LEQ(cur->end, lastack)) {
				prev = cur;
				cur = cur->next;
				pool_put(&sackhl_pool, prev);
				tp->snd_numholes--;
			} else if (SEQ_LT(cur->start, lastack)) {
				cur->start = lastack;
				if (SEQ_LT(cur->rxmit, cur->start))
					cur->rxmit = cur->start;
				break;
			} else
				break;
		tp->snd_holes = cur;
	}
}

/*
 * Delete all receiver-side SACK information.
 */
void
tcp_clean_sackreport(struct tcpcb *tp)
{
	int i;

	tp->rcv_numsacks = 0;
	for (i = 0; i < MAX_SACK_BLKS; i++)
		tp->sackblks[i].start = tp->sackblks[i].end=0;

}

/*
 * Checks for partial ack.  If partial ack arrives, turn off retransmission
 * timer, deflate the window, do not clear tp->t_dupacks, and return 1.
 * If the ack advances at least to tp->snd_last, return 0.
 */
int
tcp_sack_partialack(struct tcpcb *tp, struct tcphdr *th)
{
	if (SEQ_LT(th->th_ack, tp->snd_last)) {
		/* Turn off retx. timer (will start again next segment) */
		TCP_TIMER_DISARM(tp, TCPT_REXMT);
		tp->t_rtttime = 0;
#ifndef TCP_FACK
		/*
		 * Partial window deflation.  This statement relies on the
		 * fact that tp->snd_una has not been updated yet.  In FACK
		 * hold snd_cwnd constant during fast recovery.
		 */
		if (tp->snd_cwnd > (th->th_ack - tp->snd_una)) {
			tp->snd_cwnd -= th->th_ack - tp->snd_una;
			tp->snd_cwnd += tp->t_maxseg;
		} else
			tp->snd_cwnd = tp->t_maxseg;
#endif
		return (1);
	}
	return (0);
}
#endif /* TCP_SACK */

/*
 * Pull out of band byte out of a segment so
 * it doesn't appear in the user's data queue.
 * It is still reflected in the segment length for
 * sequencing purposes.
 */
void
tcp_pulloutofband(struct socket *so, u_int urgent, struct mbuf *m, int off)
{
        int cnt = off + urgent - 1;

	while (cnt >= 0) {
		if (m->m_len > cnt) {
			char *cp = mtod(m, caddr_t) + cnt;
			struct tcpcb *tp = sototcpcb(so);

			tp->t_iobc = *cp;
			tp->t_oobflags |= TCPOOB_HAVEDATA;
			memmove(cp, cp + 1, m->m_len - cnt - 1);
			m->m_len--;
			return;
		}
		cnt -= m->m_len;
		m = m->m_next;
		if (m == NULL)
			break;
	}
	panic("tcp_pulloutofband");
}

/*
 * Collect new round-trip time estimate
 * and update averages and current timeout.
 */
void
tcp_xmit_timer(struct tcpcb *tp, int rtt)
{
	short delta;
	short rttmin;

	if (rtt < 0)
		rtt = 0;
	else if (rtt > TCP_RTT_MAX)
		rtt = TCP_RTT_MAX;

	tcpstat_inc(tcps_rttupdated);
	if (tp->t_srtt != 0) {
		/*
		 * delta is fixed point with 2 (TCP_RTT_BASE_SHIFT) bits
		 * after the binary point (scaled by 4), whereas
		 * srtt is stored as fixed point with 5 bits after the
		 * binary point (i.e., scaled by 32).  The following magic
		 * is equivalent to the smoothing algorithm in rfc793 with
		 * an alpha of .875 (srtt = rtt/8 + srtt*7/8 in fixed
		 * point).
		 */
		delta = (rtt << TCP_RTT_BASE_SHIFT) -
		    (tp->t_srtt >> TCP_RTT_SHIFT);
		if ((tp->t_srtt += delta) <= 0)
			tp->t_srtt = 1 << TCP_RTT_BASE_SHIFT;
		/*
		 * We accumulate a smoothed rtt variance (actually, a
		 * smoothed mean difference), then set the retransmit
		 * timer to smoothed rtt + 4 times the smoothed variance.
		 * rttvar is stored as fixed point with 4 bits after the
		 * binary point (scaled by 16).  The following is
		 * equivalent to rfc793 smoothing with an alpha of .75
		 * (rttvar = rttvar*3/4 + |delta| / 4).  This replaces
		 * rfc793's wired-in beta.
		 */
		if (delta < 0)
			delta = -delta;
		delta -= (tp->t_rttvar >> TCP_RTTVAR_SHIFT);
		if ((tp->t_rttvar += delta) <= 0)
			tp->t_rttvar = 1 << TCP_RTT_BASE_SHIFT;
	} else {
		/*
		 * No rtt measurement yet - use the unsmoothed rtt.
		 * Set the variance to half the rtt (so our first
		 * retransmit happens at 3*rtt).
		 */
		tp->t_srtt = (rtt + 1) << (TCP_RTT_SHIFT + TCP_RTT_BASE_SHIFT);
		tp->t_rttvar = (rtt + 1) <<
		    (TCP_RTTVAR_SHIFT + TCP_RTT_BASE_SHIFT - 1);
	}
	tp->t_rtttime = 0;
	tp->t_rxtshift = 0;

	/*
	 * the retransmit should happen at rtt + 4 * rttvar.
	 * Because of the way we do the smoothing, srtt and rttvar
	 * will each average +1/2 tick of bias.  When we compute
	 * the retransmit timer, we want 1/2 tick of rounding and
	 * 1 extra tick because of +-1/2 tick uncertainty in the
	 * firing of the timer.  The bias will give us exactly the
	 * 1.5 tick we need.  But, because the bias is
	 * statistical, we have to test that we don't drop below
	 * the minimum feasible timer (which is 2 ticks).
	 */
	rttmin = min(max(rtt + 2, tp->t_rttmin), TCPTV_REXMTMAX);
	TCPT_RANGESET(tp->t_rxtcur, TCP_REXMTVAL(tp), rttmin, TCPTV_REXMTMAX);

	/*
	 * We received an ack for a packet that wasn't retransmitted;
	 * it is probably safe to discard any error indications we've
	 * received recently.  This isn't quite right, but close enough
	 * for now (a route might have failed after we sent a segment,
	 * and the return path might not be symmetrical).
	 */
	tp->t_softerror = 0;
}

/*
 * Determine a reasonable value for maxseg size.
 * If the route is known, check route for mtu.
 * If none, use an mss that can be handled on the outgoing
 * interface without forcing IP to fragment; if bigger than
 * an mbuf cluster (MCLBYTES), round down to nearest multiple of MCLBYTES
 * to utilize large mbufs.  If no route is found, route has no mtu,
 * or the destination isn't local, use a default, hopefully conservative
 * size (usually 512 or the default IP max size, but no more than the mtu
 * of the interface), as we can't discover anything about intervening
 * gateways or networks.  We also initialize the congestion/slow start
 * window to be a single segment if the destination isn't local.
 * While looking at the routing entry, we also initialize other path-dependent
 * parameters from pre-set or cached values in the routing entry.
 *
 * Also take into account the space needed for options that we
 * send regularly.  Make maxseg shorter by that amount to assure
 * that we can send maxseg amount of data even when the options
 * are present.  Store the upper limit of the length of options plus
 * data in maxopd.
 *
 * NOTE: offer == -1 indicates that the maxseg size changed due to
 * Path MTU discovery.
 */
int
tcp_mss(struct tcpcb *tp, int offer)
{
	struct rtentry *rt;
	struct ifnet *ifp = NULL;
	int mss, mssopt;
	int iphlen;
	struct inpcb *inp;

	inp = tp->t_inpcb;

	mssopt = mss = tcp_mssdflt;

	rt = in_pcbrtentry(inp);

	if (rt == NULL)
		goto out;

	ifp = if_get(rt->rt_ifidx);
	if (ifp == NULL)
		goto out;

	switch (tp->pf) {
#ifdef INET6
	case AF_INET6:
		iphlen = sizeof(struct ip6_hdr);
		break;
#endif
	case AF_INET:
		iphlen = sizeof(struct ip);
		break;
	default:
		/* the family does not support path MTU discovery */
		goto out;
	}

	/*
	 * if there's an mtu associated with the route and we support
	 * path MTU discovery for the underlying protocol family, use it.
	 */
	if (rt->rt_mtu) {
		/*
		 * One may wish to lower MSS to take into account options,
		 * especially security-related options.
		 */
		if (tp->pf == AF_INET6 && rt->rt_mtu < IPV6_MMTU) {
			/*
			 * RFC2460 section 5, last paragraph: if path MTU is
			 * smaller than 1280, use 1280 as packet size and
			 * attach fragment header.
			 */
			mss = IPV6_MMTU - iphlen - sizeof(struct ip6_frag) -
			    sizeof(struct tcphdr);
		} else {
			mss = rt->rt_mtu - iphlen -
			    sizeof(struct tcphdr);
		}
	} else if (ifp->if_flags & IFF_LOOPBACK) {
		mss = ifp->if_mtu - iphlen - sizeof(struct tcphdr);
	} else if (tp->pf == AF_INET) {
		if (ip_mtudisc)
			mss = ifp->if_mtu - iphlen - sizeof(struct tcphdr);
	}
#ifdef INET6
	else if (tp->pf == AF_INET6) {
		/*
		 * for IPv6, path MTU discovery is always turned on,
		 * or the node must use packet size <= 1280.
		 */
		mss = ifp->if_mtu - iphlen - sizeof(struct tcphdr);
	}
#endif /* INET6 */

	/* Calculate the value that we offer in TCPOPT_MAXSEG */
	if (offer != -1) {
		mssopt = ifp->if_mtu - iphlen - sizeof(struct tcphdr);
		mssopt = max(tcp_mssdflt, mssopt);
	}
 out:
	if_put(ifp);
	/*
	 * The current mss, t_maxseg, is initialized to the default value.
	 * If we compute a smaller value, reduce the current mss.
	 * If we compute a larger value, return it for use in sending
	 * a max seg size option, but don't store it for use
	 * unless we received an offer at least that large from peer.
	 *
	 * However, do not accept offers lower than the minimum of
	 * the interface MTU and 216.
	 */
	if (offer > 0)
		tp->t_peermss = offer;
	if (tp->t_peermss)
		mss = min(mss, max(tp->t_peermss, 216));

	/* sanity - at least max opt. space */
	mss = max(mss, 64);

	/*
	 * maxopd stores the maximum length of data AND options
	 * in a segment; maxseg is the amount of data in a normal
	 * segment.  We need to store this value (maxopd) apart
	 * from maxseg, because now every segment carries options
	 * and thus we normally have somewhat less data in segments.
	 */
	tp->t_maxopd = mss;

	if ((tp->t_flags & (TF_REQ_TSTMP|TF_NOOPT)) == TF_REQ_TSTMP &&
	    (tp->t_flags & TF_RCVD_TSTMP) == TF_RCVD_TSTMP)
		mss -= TCPOLEN_TSTAMP_APPA;
#ifdef TCP_SIGNATURE
	if (tp->t_flags & TF_SIGNATURE)
		mss -= TCPOLEN_SIGLEN;
#endif

	if (offer == -1) {
		/* mss changed due to Path MTU discovery */
		tp->t_flags &= ~TF_PMTUD_PEND;
		tp->t_pmtud_mtu_sent = 0;
		tp->t_pmtud_mss_acked = 0;
		if (mss < tp->t_maxseg) {
			/*
			 * Follow suggestion in RFC 2414 to reduce the
			 * congestion window by the ratio of the old
			 * segment size to the new segment size.
			 */
			tp->snd_cwnd = ulmax((tp->snd_cwnd / tp->t_maxseg) *
					     mss, mss);
		}
	} else if (tcp_do_rfc3390 == 2) {
		/* increase initial window  */
		tp->snd_cwnd = ulmin(10 * mss, ulmax(2 * mss, 14600));
	} else if (tcp_do_rfc3390) {
		/* increase initial window  */
		tp->snd_cwnd = ulmin(4 * mss, ulmax(2 * mss, 4380));
	} else
		tp->snd_cwnd = mss;

	tp->t_maxseg = mss;

	return (offer != -1 ? mssopt : mss);
}

u_int
tcp_hdrsz(struct tcpcb *tp)
{
	u_int hlen;

	switch (tp->pf) {
#ifdef INET6
	case AF_INET6:
		hlen = sizeof(struct ip6_hdr);
		break;
#endif
	case AF_INET:
		hlen = sizeof(struct ip);
		break;
	default:
		hlen = 0;
		break;
	}
	hlen += sizeof(struct tcphdr);

	if ((tp->t_flags & (TF_REQ_TSTMP|TF_NOOPT)) == TF_REQ_TSTMP &&
	    (tp->t_flags & TF_RCVD_TSTMP) == TF_RCVD_TSTMP)
		hlen += TCPOLEN_TSTAMP_APPA;
#ifdef TCP_SIGNATURE
	if (tp->t_flags & TF_SIGNATURE)
		hlen += TCPOLEN_SIGLEN;
#endif
	return (hlen);
}

/*
 * Set connection variables based on the effective MSS.
 * We are passed the TCPCB for the actual connection.  If we
 * are the server, we are called by the compressed state engine
 * when the 3-way handshake is complete.  If we are the client,
 * we are called when we receive the SYN,ACK from the server.
 *
 * NOTE: The t_maxseg value must be initialized in the TCPCB
 * before this routine is called!
 */
void
tcp_mss_update(struct tcpcb *tp)
{
	int mss;
	u_long bufsize;
	struct rtentry *rt;
	struct socket *so;

	so = tp->t_inpcb->inp_socket;
	mss = tp->t_maxseg;

	rt = in_pcbrtentry(tp->t_inpcb);

	if (rt == NULL)
		return;

	bufsize = so->so_snd.sb_hiwat;
	if (bufsize < mss) {
		mss = bufsize;
		/* Update t_maxseg and t_maxopd */
		tcp_mss(tp, mss);
	} else {
		bufsize = roundup(bufsize, mss);
		if (bufsize > sb_max)
			bufsize = sb_max;
		(void)sbreserve(&so->so_snd, bufsize);
	}

	bufsize = so->so_rcv.sb_hiwat;
	if (bufsize > mss) {
		bufsize = roundup(bufsize, mss);
		if (bufsize > sb_max)
			bufsize = sb_max;
		(void)sbreserve(&so->so_rcv, bufsize);
	}

}

#if defined (TCP_SACK)
/*
 * Checks for partial ack.  If partial ack arrives, force the retransmission
 * of the next unacknowledged segment, do not clear tp->t_dupacks, and return
 * 1.  By setting snd_nxt to ti_ack, this forces retransmission timer to
 * be started again.  If the ack advances at least to tp->snd_last, return 0.
 */
int
tcp_newreno(struct tcpcb *tp, struct tcphdr *th)
{
	if (SEQ_LT(th->th_ack, tp->snd_last)) {
		/*
		 * snd_una has not been updated and the socket send buffer
		 * not yet drained of the acked data, so we have to leave
		 * snd_una as it was to get the correct data offset in
		 * tcp_output().
		 */
		tcp_seq onxt = tp->snd_nxt;
		u_long  ocwnd = tp->snd_cwnd;
		TCP_TIMER_DISARM(tp, TCPT_REXMT);
		tp->t_rtttime = 0;
		tp->snd_nxt = th->th_ack;
		/*
		 * Set snd_cwnd to one segment beyond acknowledged offset
		 * (tp->snd_una not yet updated when this function is called)
		 */
		tp->snd_cwnd = tp->t_maxseg + (th->th_ack - tp->snd_una);
		(void) tcp_output(tp);
		tp->snd_cwnd = ocwnd;
		if (SEQ_GT(onxt, tp->snd_nxt))
			tp->snd_nxt = onxt;
		/*
		 * Partial window deflation.  Relies on fact that tp->snd_una
		 * not updated yet.
		 */
		if (tp->snd_cwnd > th->th_ack - tp->snd_una)
			tp->snd_cwnd -= th->th_ack - tp->snd_una;
		else
			tp->snd_cwnd = 0;
		tp->snd_cwnd += tp->t_maxseg;

		return 1;
	}
	return 0;
}
#endif /* TCP_SACK */

int
tcp_mss_adv(struct mbuf *m, int af)
{
	int mss = 0;
	int iphlen;
	struct ifnet *ifp = NULL;

	if (m && (m->m_flags & M_PKTHDR))
		ifp = if_get(m->m_pkthdr.ph_ifidx);

	switch (af) {
	case AF_INET:
		if (ifp != NULL)
			mss = ifp->if_mtu;
		iphlen = sizeof(struct ip);
		break;
#ifdef INET6
	case AF_INET6:
		if (ifp != NULL)
			mss = ifp->if_mtu;
		iphlen = sizeof(struct ip6_hdr);
		break;
#endif  
	default:
		unhandled_af(af);
	}
	if_put(ifp);
	mss = mss - iphlen - sizeof(struct tcphdr);
	return (max(mss, tcp_mssdflt));
}

/*
 * TCP compressed state engine.  Currently used to hold compressed
 * state for SYN_RECEIVED.
 */

/* syn hash parameters */
int	tcp_syn_hash_size = TCP_SYN_HASH_SIZE;
int	tcp_syn_cache_limit = TCP_SYN_HASH_SIZE*TCP_SYN_BUCKET_SIZE;
int	tcp_syn_bucket_limit = 3*TCP_SYN_BUCKET_SIZE;
int	tcp_syn_use_limit = 100000;

struct syn_cache_set tcp_syn_cache[2];
int tcp_syn_cache_active;

#define SYN_HASH(sa, sp, dp, rand) \
	(((sa)->s_addr ^ (rand)[0]) *				\
	(((((u_int32_t)(dp))<<16) + ((u_int32_t)(sp))) ^ (rand)[4]))
#ifndef INET6
#define	SYN_HASHALL(hash, src, dst, rand) \
do {									\
	hash = SYN_HASH(&satosin(src)->sin_addr,			\
		satosin(src)->sin_port,					\
		satosin(dst)->sin_port, (rand));			\
} while (/*CONSTCOND*/ 0)
#else
#define SYN_HASH6(sa, sp, dp, rand) \
	(((sa)->s6_addr32[0] ^ (rand)[0]) *			\
	((sa)->s6_addr32[1] ^ (rand)[1]) *			\
	((sa)->s6_addr32[2] ^ (rand)[2]) *			\
	((sa)->s6_addr32[3] ^ (rand)[3]) *			\
	(((((u_int32_t)(dp))<<16) + ((u_int32_t)(sp))) ^ (rand)[4]))

#define SYN_HASHALL(hash, src, dst, rand) \
do {									\
	switch ((src)->sa_family) {					\
	case AF_INET:							\
		hash = SYN_HASH(&satosin(src)->sin_addr,		\
			satosin(src)->sin_port,				\
			satosin(dst)->sin_port, (rand));		\
		break;							\
	case AF_INET6:							\
		hash = SYN_HASH6(&satosin6(src)->sin6_addr,		\
			satosin6(src)->sin6_port,			\
			satosin6(dst)->sin6_port, (rand));		\
		break;							\
	default:							\
		hash = 0;						\
	}								\
} while (/*CONSTCOND*/0)
#endif /* INET6 */

void
syn_cache_rm(struct syn_cache *sc)
{
	sc->sc_flags |= SCF_DEAD;
	TAILQ_REMOVE(&sc->sc_buckethead->sch_bucket, sc, sc_bucketq);
	sc->sc_tp = NULL;
	LIST_REMOVE(sc, sc_tpq);
	sc->sc_buckethead->sch_length--;
	timeout_del(&sc->sc_timer);
	sc->sc_set->scs_count--;
}

void
syn_cache_put(struct syn_cache *sc)
{
	m_free(sc->sc_ipopts);
	if (sc->sc_route4.ro_rt != NULL) {
		rtfree(sc->sc_route4.ro_rt);
		sc->sc_route4.ro_rt = NULL;
	}
	timeout_set(&sc->sc_timer, syn_cache_reaper, sc);
	timeout_add(&sc->sc_timer, 0);
}

struct pool syn_cache_pool;

/*
 * We don't estimate RTT with SYNs, so each packet starts with the default
 * RTT and each timer step has a fixed timeout value.
 */
#define	SYN_CACHE_TIMER_ARM(sc)						\
do {									\
	TCPT_RANGESET((sc)->sc_rxtcur,					\
	    TCPTV_SRTTDFLT * tcp_backoff[(sc)->sc_rxtshift], TCPTV_MIN,	\
	    TCPTV_REXMTMAX);						\
	if (!timeout_initialized(&(sc)->sc_timer))			\
		timeout_set_proc(&(sc)->sc_timer, syn_cache_timer, (sc)); \
	timeout_add(&(sc)->sc_timer, (sc)->sc_rxtcur * (hz / PR_SLOWHZ)); \
} while (/*CONSTCOND*/0)

#define	SYN_CACHE_TIMESTAMP(sc)	tcp_now + (sc)->sc_modulate

void
syn_cache_init(void)
{
	int i;

	/* Initialize the hash buckets. */
	tcp_syn_cache[0].scs_buckethead = mallocarray(tcp_syn_hash_size,
	    sizeof(struct syn_cache_head), M_SYNCACHE, M_WAITOK|M_ZERO);
	tcp_syn_cache[1].scs_buckethead = mallocarray(tcp_syn_hash_size,
	    sizeof(struct syn_cache_head), M_SYNCACHE, M_WAITOK|M_ZERO);
	tcp_syn_cache[0].scs_size = tcp_syn_hash_size;
	tcp_syn_cache[1].scs_size = tcp_syn_hash_size;
	for (i = 0; i < tcp_syn_hash_size; i++) {
		TAILQ_INIT(&tcp_syn_cache[0].scs_buckethead[i].sch_bucket);
		TAILQ_INIT(&tcp_syn_cache[1].scs_buckethead[i].sch_bucket);
	}

	/* Initialize the syn cache pool. */
	pool_init(&syn_cache_pool, sizeof(struct syn_cache), 0, IPL_SOFTNET,
	    0, "syncache", NULL);
}

void
syn_cache_insert(struct syn_cache *sc, struct tcpcb *tp)
{
	struct syn_cache_set *set = &tcp_syn_cache[tcp_syn_cache_active];
	struct syn_cache_head *scp;
	struct syn_cache *sc2;
	int i;

	NET_ASSERT_LOCKED();

	/*
	 * If there are no entries in the hash table, reinitialize
	 * the hash secrets.  To avoid useless cache swaps and
	 * reinitialization, use it until the limit is reached.
	 * An emtpy cache is also the oportunity to resize the hash.
	 */
	if (set->scs_count == 0 && set->scs_use <= 0) {
		set->scs_use = tcp_syn_use_limit;
		if (set->scs_size != tcp_syn_hash_size) {
			scp = mallocarray(tcp_syn_hash_size, sizeof(struct
			    syn_cache_head), M_SYNCACHE, M_NOWAIT|M_ZERO);
			if (scp == NULL) {
				/* Try again next time. */
				set->scs_use = 0;
			} else {
				free(set->scs_buckethead, M_SYNCACHE,
				    set->scs_size *
				    sizeof(struct syn_cache_head));
				set->scs_buckethead = scp;
				set->scs_size = tcp_syn_hash_size;
				for (i = 0; i < tcp_syn_hash_size; i++)
					TAILQ_INIT(&scp[i].sch_bucket);
			}
		}
		arc4random_buf(set->scs_random, sizeof(set->scs_random));
		tcpstat_inc(tcps_sc_seedrandom);
	}

	SYN_HASHALL(sc->sc_hash, &sc->sc_src.sa, &sc->sc_dst.sa,
	    set->scs_random);
	scp = &set->scs_buckethead[sc->sc_hash % set->scs_size];
	sc->sc_buckethead = scp;

	/*
	 * Make sure that we don't overflow the per-bucket
	 * limit or the total cache size limit.
	 */
	if (scp->sch_length >= tcp_syn_bucket_limit) {
		tcpstat_inc(tcps_sc_bucketoverflow);
		/*
		 * Someone might attack our bucket hash function.  Reseed
		 * with random as soon as the passive syn cache gets empty.
		 */
		set->scs_use = 0;
		/*
		 * The bucket is full.  Toss the oldest element in the
		 * bucket.  This will be the first entry in the bucket.
		 */
		sc2 = TAILQ_FIRST(&scp->sch_bucket);
#ifdef DIAGNOSTIC
		/*
		 * This should never happen; we should always find an
		 * entry in our bucket.
		 */
		if (sc2 == NULL)
			panic("%s: bucketoverflow: impossible", __func__);
#endif
		syn_cache_rm(sc2);
		syn_cache_put(sc2);
	} else if (set->scs_count >= tcp_syn_cache_limit) {
		struct syn_cache_head *scp2, *sce;

		tcpstat_inc(tcps_sc_overflowed);
		/*
		 * The cache is full.  Toss the oldest entry in the
		 * first non-empty bucket we can find.
		 *
		 * XXX We would really like to toss the oldest
		 * entry in the cache, but we hope that this
		 * condition doesn't happen very often.
		 */
		scp2 = scp;
		if (TAILQ_EMPTY(&scp2->sch_bucket)) {
			sce = &set->scs_buckethead[set->scs_size];
			for (++scp2; scp2 != scp; scp2++) {
				if (scp2 >= sce)
					scp2 = &set->scs_buckethead[0];
				if (! TAILQ_EMPTY(&scp2->sch_bucket))
					break;
			}
#ifdef DIAGNOSTIC
			/*
			 * This should never happen; we should always find a
			 * non-empty bucket.
			 */
			if (scp2 == scp)
				panic("%s: cacheoverflow: impossible",
				    __func__);
#endif
		}
		sc2 = TAILQ_FIRST(&scp2->sch_bucket);
		syn_cache_rm(sc2);
		syn_cache_put(sc2);
	}

	/*
	 * Initialize the entry's timer.
	 */
	sc->sc_rxttot = 0;
	sc->sc_rxtshift = 0;
	SYN_CACHE_TIMER_ARM(sc);

	/* Link it from tcpcb entry */
	LIST_INSERT_HEAD(&tp->t_sc, sc, sc_tpq);

	/* Put it into the bucket. */
	TAILQ_INSERT_TAIL(&scp->sch_bucket, sc, sc_bucketq);
	scp->sch_length++;
	sc->sc_set = set;
	set->scs_count++;
	set->scs_use--;

	tcpstat_inc(tcps_sc_added);

	/*
	 * If the active cache has exceeded its use limit and
	 * the passive syn cache is empty, exchange their roles.
	 */
	if (set->scs_use <= 0 &&
	    tcp_syn_cache[!tcp_syn_cache_active].scs_count == 0)
		tcp_syn_cache_active = !tcp_syn_cache_active;
}

/*
 * Walk the timer queues, looking for SYN,ACKs that need to be retransmitted.
 * If we have retransmitted an entry the maximum number of times, expire
 * that entry.
 */
void
syn_cache_timer(void *arg)
{
	struct syn_cache *sc = arg;
	int s;

	NET_LOCK(s);
	if (sc->sc_flags & SCF_DEAD)
		goto out;

	if (__predict_false(sc->sc_rxtshift == TCP_MAXRXTSHIFT)) {
		/* Drop it -- too many retransmissions. */
		goto dropit;
	}

	/*
	 * Compute the total amount of time this entry has
	 * been on a queue.  If this entry has been on longer
	 * than the keep alive timer would allow, expire it.
	 */
	sc->sc_rxttot += sc->sc_rxtcur;
	if (sc->sc_rxttot >= tcptv_keep_init)
		goto dropit;

	tcpstat_inc(tcps_sc_retransmitted);
	(void) syn_cache_respond(sc, NULL);

	/* Advance the timer back-off. */
	sc->sc_rxtshift++;
	SYN_CACHE_TIMER_ARM(sc);

 out:
	NET_UNLOCK(s);
	return;

 dropit:
	tcpstat_inc(tcps_sc_timed_out);
	syn_cache_rm(sc);
	syn_cache_put(sc);
	NET_UNLOCK(s);
}

void
syn_cache_reaper(void *arg)
{
	struct syn_cache *sc = arg;

	pool_put(&syn_cache_pool, (sc));
	return;
}

/*
 * Remove syn cache created by the specified tcb entry,
 * because this does not make sense to keep them
 * (if there's no tcb entry, syn cache entry will never be used)
 */
void
syn_cache_cleanup(struct tcpcb *tp)
{
	struct syn_cache *sc, *nsc;

	NET_ASSERT_LOCKED();

	LIST_FOREACH_SAFE(sc, &tp->t_sc, sc_tpq, nsc) {
#ifdef DIAGNOSTIC
		if (sc->sc_tp != tp)
			panic("invalid sc_tp in syn_cache_cleanup");
#endif
		syn_cache_rm(sc);
		syn_cache_put(sc);
	}
	/* just for safety */
	LIST_INIT(&tp->t_sc);
}

/*
 * Find an entry in the syn cache.
 */
struct syn_cache *
syn_cache_lookup(struct sockaddr *src, struct sockaddr *dst,
    struct syn_cache_head **headp, u_int rtableid)
{
	struct syn_cache_set *sets[2];
	struct syn_cache *sc;
	struct syn_cache_head *scp;
	u_int32_t hash;
	int i;

	NET_ASSERT_LOCKED();

	/* Check the active cache first, the passive cache is likely emtpy. */
	sets[0] = &tcp_syn_cache[tcp_syn_cache_active];
	sets[1] = &tcp_syn_cache[!tcp_syn_cache_active];
	for (i = 0; i < 2; i++) {
		if (sets[i]->scs_count == 0)
			continue;
		SYN_HASHALL(hash, src, dst, sets[i]->scs_random);
		scp = &sets[i]->scs_buckethead[hash % sets[i]->scs_size];
		*headp = scp;
		TAILQ_FOREACH(sc, &scp->sch_bucket, sc_bucketq) {
			if (sc->sc_hash != hash)
				continue;
			if (!bcmp(&sc->sc_src, src, src->sa_len) &&
			    !bcmp(&sc->sc_dst, dst, dst->sa_len) &&
			    rtable_l2(rtableid) == rtable_l2(sc->sc_rtableid))
				return (sc);
		}
	}
	return (NULL);
}

/*
 * This function gets called when we receive an ACK for a
 * socket in the LISTEN state.  We look up the connection
 * in the syn cache, and if its there, we pull it out of
 * the cache and turn it into a full-blown connection in
 * the SYN-RECEIVED state.
 *
 * The return values may not be immediately obvious, and their effects
 * can be subtle, so here they are:
 *
 *	NULL	SYN was not found in cache; caller should drop the
 *		packet and send an RST.
 *
 *	-1	We were unable to create the new connection, and are
 *		aborting it.  An ACK,RST is being sent to the peer
 *		(unless we got screwey sequence numbners; see below),
 *		because the 3-way handshake has been completed.  Caller
 *		should not free the mbuf, since we may be using it.  If
 *		we are not, we will free it.
 *
 *	Otherwise, the return value is a pointer to the new socket
 *	associated with the connection.
 */
struct socket *
syn_cache_get(struct sockaddr *src, struct sockaddr *dst, struct tcphdr *th,
    u_int hlen, u_int tlen, struct socket *so, struct mbuf *m)
{
	struct syn_cache *sc;
	struct syn_cache_head *scp;
	struct inpcb *inp, *oldinp;
	struct tcpcb *tp = NULL;
	struct mbuf *am;
	struct socket *oso;
#if NPF > 0
	struct pf_divert *divert = NULL;
#endif

	NET_ASSERT_LOCKED();

	sc = syn_cache_lookup(src, dst, &scp, sotoinpcb(so)->inp_rtableid);
	if (sc == NULL)
		return (NULL);

	/*
	 * Verify the sequence and ack numbers.  Try getting the correct
	 * response again.
	 */
	if ((th->th_ack != sc->sc_iss + 1) ||
	    SEQ_LEQ(th->th_seq, sc->sc_irs) ||
	    SEQ_GT(th->th_seq, sc->sc_irs + 1 + sc->sc_win)) {
		(void) syn_cache_respond(sc, m);
		return ((struct socket *)(-1));
	}

	/* Remove this cache entry */
	syn_cache_rm(sc);

	/*
	 * Ok, create the full blown connection, and set things up
	 * as they would have been set up if we had created the
	 * connection when the SYN arrived.  If we can't create
	 * the connection, abort it.
	 */
	oso = so;
	so = sonewconn(so, SS_ISCONNECTED);
	if (so == NULL)
		goto resetandabort;

	oldinp = sotoinpcb(oso);
	inp = sotoinpcb(so);

#ifdef IPSEC
	/*
	 * We need to copy the required security levels
	 * from the old pcb. Ditto for any other
	 * IPsec-related information.
	 */
	memcpy(inp->inp_seclevel, oldinp->inp_seclevel,
	    sizeof(oldinp->inp_seclevel));
#endif /* IPSEC */
#ifdef INET6
	/*
	 * inp still has the OLD in_pcb stuff, set the
	 * v6-related flags on the new guy, too.
	 */
	inp->inp_flags |= (oldinp->inp_flags & INP_IPV6);
	if (inp->inp_flags & INP_IPV6) {
		inp->inp_ipv6.ip6_hlim = oldinp->inp_ipv6.ip6_hlim;
		inp->inp_hops = oldinp->inp_hops;
	} else
#endif /* INET6 */
	{
		inp->inp_ip.ip_ttl = oldinp->inp_ip.ip_ttl;
	}

#if NPF > 0
	if (m && m->m_pkthdr.pf.flags & PF_TAG_DIVERTED &&
	    (divert = pf_find_divert(m)) != NULL)
		inp->inp_rtableid = divert->rdomain;
	else
#endif
	/* inherit rtable from listening socket */
	inp->inp_rtableid = sc->sc_rtableid;

	inp->inp_lport = th->th_dport;
	switch (src->sa_family) {
#ifdef INET6
	case AF_INET6:
		inp->inp_laddr6 = satosin6(dst)->sin6_addr;
		break;
#endif /* INET6 */
	case AF_INET:
		inp->inp_laddr = satosin(dst)->sin_addr;
		inp->inp_options = ip_srcroute(m);
		if (inp->inp_options == NULL) {
			inp->inp_options = sc->sc_ipopts;
			sc->sc_ipopts = NULL;
		}
		break;
	}
	in_pcbrehash(inp);

	/*
	 * Give the new socket our cached route reference.
	 */
	if (src->sa_family == AF_INET)
		inp->inp_route = sc->sc_route4;         /* struct assignment */
#ifdef INET6
	else
		inp->inp_route6 = sc->sc_route6;
#endif
	sc->sc_route4.ro_rt = NULL;

	am = m_get(M_DONTWAIT, MT_SONAME);	/* XXX */
	if (am == NULL)
		goto resetandabort;
	am->m_len = src->sa_len;
	memcpy(mtod(am, caddr_t), src, src->sa_len);

	switch (src->sa_family) {
	case AF_INET:
		/* drop IPv4 packet to AF_INET6 socket */
		if (inp->inp_flags & INP_IPV6) {
			(void) m_free(am);
			goto resetandabort;
		}
		if (in_pcbconnect(inp, am)) {
			(void) m_free(am);
			goto resetandabort;
		}
		break;
#ifdef INET6
	case AF_INET6:
		if (in6_pcbconnect(inp, am)) {
			(void) m_free(am);
			goto resetandabort;
		}
		break;
#endif
	}
	(void) m_free(am);

	tp = intotcpcb(inp);
	tp->t_flags = sototcpcb(oso)->t_flags & (TF_NOPUSH|TF_NODELAY);
	if (sc->sc_request_r_scale != 15) {
		tp->requested_s_scale = sc->sc_requested_s_scale;
		tp->request_r_scale = sc->sc_request_r_scale;
		tp->t_flags |= TF_REQ_SCALE|TF_RCVD_SCALE;
	}
	if (sc->sc_flags & SCF_TIMESTAMP)
		tp->t_flags |= TF_REQ_TSTMP|TF_RCVD_TSTMP;

	tp->t_template = tcp_template(tp);
	if (tp->t_template == 0) {
		tp = tcp_drop(tp, ENOBUFS);	/* destroys socket */
		so = NULL;
		m_freem(m);
		goto abort;
	}
#ifdef TCP_SACK
	tp->sack_enable = sc->sc_flags & SCF_SACK_PERMIT;
#endif

	tp->ts_modulate = sc->sc_modulate;
	tp->ts_recent = sc->sc_timestamp;
	tp->iss = sc->sc_iss;
	tp->irs = sc->sc_irs;
	tcp_sendseqinit(tp);
#if defined (TCP_SACK) || defined(TCP_ECN)
	tp->snd_last = tp->snd_una;
#endif /* TCP_SACK */
#if defined(TCP_SACK) && defined(TCP_FACK)
	tp->snd_fack = tp->snd_una;
	tp->retran_data = 0;
	tp->snd_awnd = 0;
#endif /* TCP_FACK */
#ifdef TCP_ECN
	if (sc->sc_flags & SCF_ECN_PERMIT) {
		tp->t_flags |= TF_ECN_PERMIT;
		tcpstat_inc(tcps_ecn_accepts);
	}
#endif
#ifdef TCP_SACK
	if (sc->sc_flags & SCF_SACK_PERMIT)
		tp->t_flags |= TF_SACK_PERMIT;
#endif
#ifdef TCP_SIGNATURE
	if (sc->sc_flags & SCF_SIGNATURE)
		tp->t_flags |= TF_SIGNATURE;
#endif
	tcp_rcvseqinit(tp);
	tp->t_state = TCPS_SYN_RECEIVED;
	tp->t_rcvtime = tcp_now;
	TCP_TIMER_ARM(tp, TCPT_KEEP, tcptv_keep_init);
	tcpstat_inc(tcps_accepts);

	tcp_mss(tp, sc->sc_peermaxseg);	 /* sets t_maxseg */
	if (sc->sc_peermaxseg)
		tcp_mss_update(tp);
	/* Reset initial window to 1 segment for retransmit */
	if (sc->sc_rxtshift > 0)
		tp->snd_cwnd = tp->t_maxseg;
	tp->snd_wl1 = sc->sc_irs;
	tp->rcv_up = sc->sc_irs + 1;

	/*
	 * This is what whould have happened in tcp_output() when
	 * the SYN,ACK was sent.
	 */
	tp->snd_up = tp->snd_una;
	tp->snd_max = tp->snd_nxt = tp->iss+1;
	TCP_TIMER_ARM(tp, TCPT_REXMT, tp->t_rxtcur);
	if (sc->sc_win > 0 && SEQ_GT(tp->rcv_nxt + sc->sc_win, tp->rcv_adv))
		tp->rcv_adv = tp->rcv_nxt + sc->sc_win;
	tp->last_ack_sent = tp->rcv_nxt;

	tcpstat_inc(tcps_sc_completed);
	syn_cache_put(sc);
	return (so);

resetandabort:
	tcp_respond(NULL, mtod(m, caddr_t), th, (tcp_seq)0, th->th_ack, TH_RST,
	    m->m_pkthdr.ph_rtableid);
	m_freem(m);
abort:
	if (so != NULL)
		(void) soabort(so);
	syn_cache_put(sc);
	tcpstat_inc(tcps_sc_aborted);
	return ((struct socket *)(-1));
}

/*
 * This function is called when we get a RST for a
 * non-existent connection, so that we can see if the
 * connection is in the syn cache.  If it is, zap it.
 */

void
syn_cache_reset(struct sockaddr *src, struct sockaddr *dst, struct tcphdr *th,
    u_int rtableid)
{
	struct syn_cache *sc;
	struct syn_cache_head *scp;

	NET_ASSERT_LOCKED();

	if ((sc = syn_cache_lookup(src, dst, &scp, rtableid)) == NULL)
		return;
	if (SEQ_LT(th->th_seq, sc->sc_irs) ||
	    SEQ_GT(th->th_seq, sc->sc_irs + 1))
		return;
	syn_cache_rm(sc);
	tcpstat_inc(tcps_sc_reset);
	syn_cache_put(sc);
}

void
syn_cache_unreach(struct sockaddr *src, struct sockaddr *dst, struct tcphdr *th,
    u_int rtableid)
{
	struct syn_cache *sc;
	struct syn_cache_head *scp;

	NET_ASSERT_LOCKED();

	if ((sc = syn_cache_lookup(src, dst, &scp, rtableid)) == NULL)
		return;
	/* If the sequence number != sc_iss, then it's a bogus ICMP msg */
	if (ntohl (th->th_seq) != sc->sc_iss) {
		return;
	}

	/*
	 * If we've retransmitted 3 times and this is our second error,
	 * we remove the entry.  Otherwise, we allow it to continue on.
	 * This prevents us from incorrectly nuking an entry during a
	 * spurious network outage.
	 *
	 * See tcp_notify().
	 */
	if ((sc->sc_flags & SCF_UNREACH) == 0 || sc->sc_rxtshift < 3) {
		sc->sc_flags |= SCF_UNREACH;
		return;
	}

	syn_cache_rm(sc);
	tcpstat_inc(tcps_sc_unreach);
	syn_cache_put(sc);
}

/*
 * Given a LISTEN socket and an inbound SYN request, add
 * this to the syn cache, and send back a segment:
 *	<SEQ=ISS><ACK=RCV_NXT><CTL=SYN,ACK>
 * to the source.
 *
 * IMPORTANT NOTE: We do _NOT_ ACK data that might accompany the SYN.
 * Doing so would require that we hold onto the data and deliver it
 * to the application.  However, if we are the target of a SYN-flood
 * DoS attack, an attacker could send data which would eventually
 * consume all available buffer space if it were ACKed.  By not ACKing
 * the data, we avoid this DoS scenario.
 */

int
syn_cache_add(struct sockaddr *src, struct sockaddr *dst, struct tcphdr *th,
    u_int iphlen, struct socket *so, struct mbuf *m, u_char *optp, int optlen,
    struct tcp_opt_info *oi, tcp_seq *issp)
{
	struct tcpcb tb, *tp;
	long win;
	struct syn_cache *sc;
	struct syn_cache_head *scp;
	struct mbuf *ipopts;

	tp = sototcpcb(so);

	/*
	 * RFC1122 4.2.3.10, p. 104: discard bcast/mcast SYN
	 *
	 * Note this check is performed in tcp_input() very early on.
	 */

	/*
	 * Initialize some local state.
	 */
	win = sbspace(&so->so_rcv);
	if (win > TCP_MAXWIN)
		win = TCP_MAXWIN;

	bzero(&tb, sizeof(tb));
#ifdef TCP_SIGNATURE
	if (optp || (tp->t_flags & TF_SIGNATURE)) {
#else
	if (optp) {
#endif
		tb.pf = tp->pf;
#ifdef TCP_SACK
		tb.sack_enable = tp->sack_enable;
#endif
		tb.t_flags = tcp_do_rfc1323 ? (TF_REQ_SCALE|TF_REQ_TSTMP) : 0;
#ifdef TCP_SIGNATURE
		if (tp->t_flags & TF_SIGNATURE)
			tb.t_flags |= TF_SIGNATURE;
#endif
		tb.t_state = TCPS_LISTEN;
		if (tcp_dooptions(&tb, optp, optlen, th, m, iphlen, oi,
		    sotoinpcb(so)->inp_rtableid))
			return (-1);
	}

	switch (src->sa_family) {
	case AF_INET:
		/*
		 * Remember the IP options, if any.
		 */
		ipopts = ip_srcroute(m);
		break;
	default:
		ipopts = NULL;
	}

	/*
	 * See if we already have an entry for this connection.
	 * If we do, resend the SYN,ACK.  We do not count this
	 * as a retransmission (XXX though maybe we should).
	 */
	sc = syn_cache_lookup(src, dst, &scp, sotoinpcb(so)->inp_rtableid);
	if (sc != NULL) {
		tcpstat_inc(tcps_sc_dupesyn);
		if (ipopts) {
			/*
			 * If we were remembering a previous source route,
			 * forget it and use the new one we've been given.
			 */
			m_free(sc->sc_ipopts);
			sc->sc_ipopts = ipopts;
		}
		sc->sc_timestamp = tb.ts_recent;
		if (syn_cache_respond(sc, m) == 0) {
			tcpstat_inc(tcps_sndacks);
			tcpstat_inc(tcps_sndtotal);
		}
		return (0);
	}

	sc = pool_get(&syn_cache_pool, PR_NOWAIT|PR_ZERO);
	if (sc == NULL) {
		m_free(ipopts);
		return (-1);
	}

	/*
	 * Fill in the cache, and put the necessary IP and TCP
	 * options into the reply.
	 */
	memcpy(&sc->sc_src, src, src->sa_len);
	memcpy(&sc->sc_dst, dst, dst->sa_len);
	sc->sc_rtableid = sotoinpcb(so)->inp_rtableid;
	sc->sc_flags = 0;
	sc->sc_ipopts = ipopts;
	sc->sc_irs = th->th_seq;

	sc->sc_iss = issp ? *issp : arc4random();
	sc->sc_peermaxseg = oi->maxseg;
	sc->sc_ourmaxseg = tcp_mss_adv(m, sc->sc_src.sa.sa_family);
	sc->sc_win = win;
	sc->sc_timestamp = tb.ts_recent;
	if ((tb.t_flags & (TF_REQ_TSTMP|TF_RCVD_TSTMP)) ==
	    (TF_REQ_TSTMP|TF_RCVD_TSTMP)) {
		sc->sc_flags |= SCF_TIMESTAMP;
		sc->sc_modulate = arc4random();
	}
	if ((tb.t_flags & (TF_RCVD_SCALE|TF_REQ_SCALE)) ==
	    (TF_RCVD_SCALE|TF_REQ_SCALE)) {
		sc->sc_requested_s_scale = tb.requested_s_scale;
		sc->sc_request_r_scale = 0;
		/*
		 * Pick the smallest possible scaling factor that
		 * will still allow us to scale up to sb_max.
		 *
		 * We do this because there are broken firewalls that
		 * will corrupt the window scale option, leading to
		 * the other endpoint believing that our advertised
		 * window is unscaled.  At scale factors larger than
		 * 5 the unscaled window will drop below 1500 bytes,
		 * leading to serious problems when traversing these
		 * broken firewalls.
		 *
		 * With the default sbmax of 256K, a scale factor
		 * of 3 will be chosen by this algorithm.  Those who
		 * choose a larger sbmax should watch out
		 * for the compatiblity problems mentioned above.
		 *
		 * RFC1323: The Window field in a SYN (i.e., a <SYN>
		 * or <SYN,ACK>) segment itself is never scaled.
		 */
		while (sc->sc_request_r_scale < TCP_MAX_WINSHIFT &&
		    (TCP_MAXWIN << sc->sc_request_r_scale) < sb_max)
			sc->sc_request_r_scale++;
	} else {
		sc->sc_requested_s_scale = 15;
		sc->sc_request_r_scale = 15;
	}
#ifdef TCP_ECN
	/*
	 * if both ECE and CWR flag bits are set, peer is ECN capable.
	 */
	if (tcp_do_ecn &&
	    (th->th_flags & (TH_ECE|TH_CWR)) == (TH_ECE|TH_CWR))
		sc->sc_flags |= SCF_ECN_PERMIT;
#endif
#ifdef TCP_SACK
	/*
	 * Set SCF_SACK_PERMIT if peer did send a SACK_PERMITTED option
	 * (i.e., if tcp_dooptions() did set TF_SACK_PERMIT).
	 */
	if (tb.sack_enable && (tb.t_flags & TF_SACK_PERMIT))
		sc->sc_flags |= SCF_SACK_PERMIT;
#endif
#ifdef TCP_SIGNATURE
	if (tb.t_flags & TF_SIGNATURE)
		sc->sc_flags |= SCF_SIGNATURE;
#endif
	sc->sc_tp = tp;
	if (syn_cache_respond(sc, m) == 0) {
		syn_cache_insert(sc, tp);
		tcpstat_inc(tcps_sndacks);
		tcpstat_inc(tcps_sndtotal);
	} else {
		syn_cache_put(sc);
		tcpstat_inc(tcps_sc_dropped);
	}

	return (0);
}

int
syn_cache_respond(struct syn_cache *sc, struct mbuf *m)
{
	u_int8_t *optp;
	int optlen, error;
	u_int16_t tlen;
	struct ip *ip = NULL;
#ifdef INET6
	struct ip6_hdr *ip6 = NULL;
#endif
	struct tcphdr *th;
	u_int hlen;
	struct inpcb *inp;

	switch (sc->sc_src.sa.sa_family) {
	case AF_INET:
		hlen = sizeof(struct ip);
		break;
#ifdef INET6
	case AF_INET6:
		hlen = sizeof(struct ip6_hdr);
		break;
#endif
	default:
		m_freem(m);
		return (EAFNOSUPPORT);
	}

	/* Compute the size of the TCP options. */
	optlen = 4 + (sc->sc_request_r_scale != 15 ? 4 : 0) +
#ifdef TCP_SACK
	    ((sc->sc_flags & SCF_SACK_PERMIT) ? 4 : 0) +
#endif
#ifdef TCP_SIGNATURE
	    ((sc->sc_flags & SCF_SIGNATURE) ? TCPOLEN_SIGLEN : 0) +
#endif
	    ((sc->sc_flags & SCF_TIMESTAMP) ? TCPOLEN_TSTAMP_APPA : 0);

	tlen = hlen + sizeof(struct tcphdr) + optlen;

	/*
	 * Create the IP+TCP header from scratch.
	 */
	m_freem(m);
#ifdef DIAGNOSTIC
	if (max_linkhdr + tlen > MCLBYTES)
		return (ENOBUFS);
#endif
	MGETHDR(m, M_DONTWAIT, MT_DATA);
	if (m && max_linkhdr + tlen > MHLEN) {
		MCLGET(m, M_DONTWAIT);
		if ((m->m_flags & M_EXT) == 0) {
			m_freem(m);
			m = NULL;
		}
	}
	if (m == NULL)
		return (ENOBUFS);

	/* Fixup the mbuf. */
	m->m_data += max_linkhdr;
	m->m_len = m->m_pkthdr.len = tlen;
	m->m_pkthdr.ph_ifidx = 0;
	m->m_pkthdr.ph_rtableid = sc->sc_rtableid;
	memset(mtod(m, u_char *), 0, tlen);

	switch (sc->sc_src.sa.sa_family) {
	case AF_INET:
		ip = mtod(m, struct ip *);
		ip->ip_dst = sc->sc_src.sin.sin_addr;
		ip->ip_src = sc->sc_dst.sin.sin_addr;
		ip->ip_p = IPPROTO_TCP;
		th = (struct tcphdr *)(ip + 1);
		th->th_dport = sc->sc_src.sin.sin_port;
		th->th_sport = sc->sc_dst.sin.sin_port;
		break;
#ifdef INET6
	case AF_INET6:
		ip6 = mtod(m, struct ip6_hdr *);
		ip6->ip6_dst = sc->sc_src.sin6.sin6_addr;
		ip6->ip6_src = sc->sc_dst.sin6.sin6_addr;
		ip6->ip6_nxt = IPPROTO_TCP;
		/* ip6_plen will be updated in ip6_output() */
		th = (struct tcphdr *)(ip6 + 1);
		th->th_dport = sc->sc_src.sin6.sin6_port;
		th->th_sport = sc->sc_dst.sin6.sin6_port;
		break;
#endif
	default:
		unhandled_af(sc->sc_src.sa.sa_family);
	}

	th->th_seq = htonl(sc->sc_iss);
	th->th_ack = htonl(sc->sc_irs + 1);
	th->th_off = (sizeof(struct tcphdr) + optlen) >> 2;
	th->th_flags = TH_SYN|TH_ACK;
#ifdef TCP_ECN
	/* Set ECE for SYN-ACK if peer supports ECN. */
	if (tcp_do_ecn && (sc->sc_flags & SCF_ECN_PERMIT))
		th->th_flags |= TH_ECE;
#endif
	th->th_win = htons(sc->sc_win);
	/* th_sum already 0 */
	/* th_urp already 0 */

	/* Tack on the TCP options. */
	optp = (u_int8_t *)(th + 1);
	*optp++ = TCPOPT_MAXSEG;
	*optp++ = 4;
	*optp++ = (sc->sc_ourmaxseg >> 8) & 0xff;
	*optp++ = sc->sc_ourmaxseg & 0xff;

#ifdef TCP_SACK
	/* Include SACK_PERMIT_HDR option if peer has already done so. */
	if (sc->sc_flags & SCF_SACK_PERMIT) {
		*((u_int32_t *)optp) = htonl(TCPOPT_SACK_PERMIT_HDR);
		optp += 4;
	}
#endif

	if (sc->sc_request_r_scale != 15) {
		*((u_int32_t *)optp) = htonl(TCPOPT_NOP << 24 |
		    TCPOPT_WINDOW << 16 | TCPOLEN_WINDOW << 8 |
		    sc->sc_request_r_scale);
		optp += 4;
	}

	if (sc->sc_flags & SCF_TIMESTAMP) {
		u_int32_t *lp = (u_int32_t *)(optp);
		/* Form timestamp option as shown in appendix A of RFC 1323. */
		*lp++ = htonl(TCPOPT_TSTAMP_HDR);
		*lp++ = htonl(SYN_CACHE_TIMESTAMP(sc));
		*lp   = htonl(sc->sc_timestamp);
		optp += TCPOLEN_TSTAMP_APPA;
	}

#ifdef TCP_SIGNATURE
	if (sc->sc_flags & SCF_SIGNATURE) {
		union sockaddr_union src, dst;
		struct tdb *tdb;

		bzero(&src, sizeof(union sockaddr_union));
		bzero(&dst, sizeof(union sockaddr_union));
		src.sa.sa_len = sc->sc_src.sa.sa_len;
		src.sa.sa_family = sc->sc_src.sa.sa_family;
		dst.sa.sa_len = sc->sc_dst.sa.sa_len;
		dst.sa.sa_family = sc->sc_dst.sa.sa_family;

		switch (sc->sc_src.sa.sa_family) {
		case 0:	/*default to PF_INET*/
		case AF_INET:
			src.sin.sin_addr = mtod(m, struct ip *)->ip_src;
			dst.sin.sin_addr = mtod(m, struct ip *)->ip_dst;
			break;
#ifdef INET6
		case AF_INET6:
			src.sin6.sin6_addr = mtod(m, struct ip6_hdr *)->ip6_src;
			dst.sin6.sin6_addr = mtod(m, struct ip6_hdr *)->ip6_dst;
			break;
#endif /* INET6 */
		}

		tdb = gettdbbysrcdst(rtable_l2(sc->sc_rtableid),
		    0, &src, &dst, IPPROTO_TCP);
		if (tdb == NULL) {
			m_freem(m);
			return (EPERM);
		}

		/* Send signature option */
		*(optp++) = TCPOPT_SIGNATURE;
		*(optp++) = TCPOLEN_SIGNATURE;

		if (tcp_signature(tdb, sc->sc_src.sa.sa_family, m, th,
		    hlen, 0, optp) < 0) {
			m_freem(m);
			return (EINVAL);
		}
		optp += 16;

		/* Pad options list to the next 32 bit boundary and
		 * terminate it.
		 */
		*optp++ = TCPOPT_NOP;
		*optp++ = TCPOPT_EOL;
	}
#endif /* TCP_SIGNATURE */

	/* Compute the packet's checksum. */
	switch (sc->sc_src.sa.sa_family) {
	case AF_INET:
		ip->ip_len = htons(tlen - hlen);
		th->th_sum = 0;
		th->th_sum = in_cksum(m, tlen);
		break;
#ifdef INET6
	case AF_INET6:
		ip6->ip6_plen = htons(tlen - hlen);
		th->th_sum = 0;
		th->th_sum = in6_cksum(m, IPPROTO_TCP, hlen, tlen - hlen);
		break;
#endif
	}

	/* use IPsec policy and ttl from listening socket, on SYN ACK */
	inp = sc->sc_tp ? sc->sc_tp->t_inpcb : NULL;

	/*
	 * Fill in some straggling IP bits.  Note the stack expects
	 * ip_len to be in host order, for convenience.
	 */
	switch (sc->sc_src.sa.sa_family) {
	case AF_INET:
		ip->ip_len = htons(tlen);
		ip->ip_ttl = inp ? inp->inp_ip.ip_ttl : ip_defttl;
		if (inp != NULL)
			ip->ip_tos = inp->inp_ip.ip_tos;
		break;
#ifdef INET6
	case AF_INET6:
		ip6->ip6_vfc &= ~IPV6_VERSION_MASK;
		ip6->ip6_vfc |= IPV6_VERSION;
		ip6->ip6_plen = htons(tlen - hlen);
		/* ip6_hlim will be initialized afterwards */
		/* leave flowlabel = 0, it is legal and require no state mgmt */
		break;
#endif
	}

	switch (sc->sc_src.sa.sa_family) {
	case AF_INET:
		error = ip_output(m, sc->sc_ipopts, &sc->sc_route4,
		    (ip_mtudisc ? IP_MTUDISC : 0),  NULL, inp, 0);
		break;
#ifdef INET6
	case AF_INET6:
		ip6->ip6_hlim = in6_selecthlim(inp);

		error = ip6_output(m, NULL /*XXX*/, &sc->sc_route6, 0,
		    NULL, NULL);
		break;
#endif
	default:
		error = EAFNOSUPPORT;
		break;
	}
	return (error);
}
@


1.340
log
@Use the address family passed down with pr_input to simplify
tcp_input().
OK florian@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.339 2017/04/14 20:46:31 bluhm Exp $	*/
d2953 1
a2953 1
	if (rt->rt_rmx.rmx_mtu) {
d2958 1
a2958 1
		if (tp->pf == AF_INET6 && rt->rt_rmx.rmx_mtu < IPV6_MMTU) {
d2967 1
a2967 1
			mss = rt->rt_rmx.rmx_mtu - iphlen -
@


1.339
log
@Pass down the address family through the pr_input calls.  This
allows to simplify code used for both IPv4 and IPv6.
OK mikeb@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.338 2017/02/09 15:19:32 jca Exp $	*/
d362 1
a362 1
	struct ip *ip;
a401 18
	 * Before we do ANYTHING, we have to figure out if it's TCP/IPv6 or
	 * TCP/IPv4.
	 */
	switch (mtod(m, struct ip *)->ip_v) {
#ifdef INET6
	case 6:
		af = AF_INET6;
		break;
#endif
	case 4:
		af = AF_INET;
		break;
	default:
		m_freem(m);
		return IPPROTO_DONE;
	}

	/*
a404 24
	switch (af) {
	case AF_INET:
#ifdef DIAGNOSTIC
		if (iphlen < sizeof(struct ip)) {
			m_freem(m);
			return IPPROTO_DONE;
		}
#endif /* DIAGNOSTIC */
		break;
#ifdef INET6
	case AF_INET6:
#ifdef DIAGNOSTIC
		if (iphlen < sizeof(struct ip6_hdr)) {
			m_freem(m);
			return IPPROTO_DONE;
		}
#endif /* DIAGNOSTIC */
		break;
#endif
	default:
		m_freem(m);
		return IPPROTO_DONE;
	}

a411 4
	ip = NULL;
#ifdef INET6
	ip6 = NULL;
#endif
d454 2
@


1.338
log
@percpu counters for TCP stats

ok mpi@@ bluhm@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.337 2017/01/29 19:58:47 bluhm Exp $	*/
d358 1
a358 1
tcp_input(struct mbuf **mp, int *offp, int proto)
a385 1
	int af;
@


1.337
log
@Change the IPv4 pr_input function to the way IPv6 is implemented,
to get rid of struct ip6protosw and some wrapper functions.  It is
more consistent to have less different structures.  The divert_input
functions cannot be called anyway, so remove them.
OK visa@@ mpi@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.336 2017/01/25 17:34:31 bluhm Exp $	*/
d237 1
a237 1
			tcpstat.tcps_rcvmemdrop++;
d264 2
a265 2
				tcpstat.tcps_rcvduppack++;
				tcpstat.tcps_rcvdupbyte += *tlen;
d275 1
a275 2
	tcpstat.tcps_rcvoopack++;
	tcpstat.tcps_rcvoobyte += *tlen;
d391 1
a391 1
	tcpstat.tcps_rcvtotal++;
d450 1
a450 1
		tcpstat.tcps_rcvshort++;
d510 1
a510 1
			tcpstat.tcps_rcvbadsum++;
d513 1
a513 1
		tcpstat.tcps_inswcsum++;
d526 1
a526 1
			tcpstat.tcps_rcvbadsum++;
d537 1
a537 1
		tcpstat.tcps_rcvbadoff++;
d544 1
a544 1
			tcpstat.tcps_rcvshort++;
d604 1
a604 1
		++tcpstat.tcps_pcbhashmiss;
d626 1
a626 1
			++tcpstat.tcps_noport;
d843 1
a843 1
							tcpstat.tcps_badsyn++;
d850 1
a850 1
							tcpstat.tcps_badsyn++;
d864 1
a864 1
					tcpstat.tcps_dropsyn++;
d897 1
a897 1
		tcpstat.tcps_rcvnosec++;
d943 1
a943 1
		tcpstat.tcps_ecn_rcvce++;
d989 1
a989 1
				++tcpstat.tcps_predack;
d997 2
a998 2
				tcpstat.tcps_rcvackpack++;
				tcpstat.tcps_rcvackbyte += acked;
d1075 1
a1075 1
			++tcpstat.tcps_preddat;
d1077 1
a1077 2
			tcpstat.tcps_rcvpack++;
			tcpstat.tcps_rcvbyte += tlen;
d1144 1
a1144 1
				tcpstat.tcps_badsyn++;
d1216 1
a1216 1
				tcpstat.tcps_ecn_accepts++;
d1222 1
a1222 1
			tcpstat.tcps_connects++;
d1266 2
a1267 2
			tcpstat.tcps_rcvpackafterwin++;
			tcpstat.tcps_rcvbyteafterwin += todrop;
d1333 2
a1334 3
			tcpstat.tcps_rcvduppack++;
			tcpstat.tcps_rcvdupbyte += tlen;
			tcpstat.tcps_pawsdrop++;
d1363 2
a1364 2
			tcpstat.tcps_rcvdupbyte += todrop = tlen;
			tcpstat.tcps_rcvduppack++;
d1366 2
a1367 2
			tcpstat.tcps_rcvpartduppack++;
			tcpstat.tcps_rcvpartdupbyte += todrop;
d1387 1
a1387 1
		tcpstat.tcps_rcvafterclose++;
d1397 1
a1397 1
		tcpstat.tcps_rcvpackafterwin++;
d1399 1
a1399 1
			tcpstat.tcps_rcvbyteafterwin += tlen;
d1409 1
a1409 1
				tcpstat.tcps_rcvwinprobe++;
d1413 1
a1413 1
			tcpstat.tcps_rcvbyteafterwin += todrop;
d1467 1
a1467 1
			tcpstat.tcps_drops++;
d1506 1
a1506 1
		tcpstat.tcps_connects++;
d1554 1
a1554 1
					tcpstat.tcps_cwr_ecn++;
d1557 1
a1557 1
			tcpstat.tcps_ecn_rcvece++;
d1565 1
a1565 1
			tcpstat.tcps_ecn_rcvcwr++;
d1587 1
a1587 1
					tcpstat.tcps_rcvacktooold++;
d1603 1
a1603 1
				tcpstat.tcps_rcvdupack++;
d1668 2
a1669 2
						tcpstat.tcps_cwr_frecovery++;
						tcpstat.tcps_sack_recovery_episode++;
d1697 2
a1698 2
					tcpstat.tcps_cwr_frecovery++;
					tcpstat.tcps_sndrexmitfast++;
d1787 1
a1787 1
			tcpstat.tcps_rcvacktoomuch++;
d1791 1
a1791 2
		tcpstat.tcps_rcvackpack++;
		tcpstat.tcps_rcvackbyte += acked;
d1964 1
a1964 1
			tcpstat.tcps_rcvwinupd++;
d2050 1
a2050 2
			tcpstat.tcps_rcvpack++;
			tcpstat.tcps_rcvbyte += tlen;
d2162 1
a2162 1
	tcpstat.tcps_badsyn++;
d2389 1
a2389 1
		tcpstat.tcps_rcvbadsig++;
d2397 1
a2397 1
			tcpstat.tcps_rcvbadsig++;
d2405 1
a2405 1
			tcpstat.tcps_rcvbadsig++;
d2409 1
a2409 1
		tcpstat.tcps_rcvgoodsig++;
d2547 1
a2547 1
	tcpstat.tcps_sack_rcv_opts++;
d2867 1
a2867 1
	tcpstat.tcps_rttupdated++;
d3407 1
a3407 1
		tcpstat.tcps_sc_seedrandom++;
d3420 1
a3420 1
		tcpstat.tcps_sc_bucketoverflow++;
d3444 1
a3444 1
		tcpstat.tcps_sc_overflowed++;
d3494 1
a3494 1
	tcpstat.tcps_sc_added++;
d3534 1
a3534 1
	tcpstat.tcps_sc_retransmitted++;
d3546 1
a3546 1
	tcpstat.tcps_sc_timed_out++;
d3820 1
a3820 1
		tcpstat.tcps_ecn_accepts++;
d3835 1
a3835 1
	tcpstat.tcps_accepts++;
d3857 1
a3857 1
	tcpstat.tcps_sc_completed++;
d3869 1
a3869 1
	tcpstat.tcps_sc_aborted++;
d3894 1
a3894 1
	tcpstat.tcps_sc_reset++;
d3928 1
a3928 1
	tcpstat.tcps_sc_unreach++;
d4011 1
a4011 1
		tcpstat.tcps_sc_dupesyn++;
d4022 2
a4023 2
			tcpstat.tcps_sndacks++;
			tcpstat.tcps_sndtotal++;
d4109 2
a4110 2
		tcpstat.tcps_sndacks++;
		tcpstat.tcps_sndtotal++;
d4113 1
a4113 1
		tcpstat.tcps_sc_dropped++;
@


1.336
log
@Since raw_input() and route_input() are gone from pr_input, we can
make the variable parameters of the protocol input functions fixed.
Also add the proto to make it similar to IPv6.
OK mpi@@ guenther@@ millert@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.335 2017/01/10 09:01:18 mpi Exp $	*/
a353 11
#ifdef INET6
int
tcp6_input(struct mbuf **mp, int *offp, int proto)
{
	struct mbuf *m = *mp;

	tcp_input(m, *offp, proto);
	return IPPROTO_DONE;
}
#endif

d358 2
a359 2
void
tcp_input(struct mbuf *m, int iphlen, int proto)
d361 2
d418 1
a418 1
		return;	/*EAFNOSUPPORT*/
d430 1
a430 1
			return;
d439 1
a439 1
			return;
d446 1
a446 1
		return;
d452 1
a452 1
		return;
d546 1
a546 1
			return;
d868 1
a868 1
				return;
d1061 1
a1061 1
				return;
d1108 1
a1108 1
			return;
d2161 1
a2161 1
	return;
d2189 1
a2189 1
	return;
d2223 1
a2223 1
	return;
d2245 1
a2245 1
	return;
@


1.335
log
@Remove NULL checks before m_free(9), it deals with it.

ok bluhm@@, kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.334 2016/12/19 08:36:49 mpi Exp $	*/
d370 1
a370 1
tcp_input(struct mbuf *m, ...)
a385 2
	int iphlen;
	va_list ap;
a399 4

	va_start(ap, m);
	iphlen = va_arg(ap, int);
	va_end(ap);
@


1.334
log
@Introduce the NET_LOCK() a rwlock used to serialize accesses to the parts
of the network stack that are not yet ready to be executed in parallel or
where new sleeping points are not possible.

This first pass replace all the entry points leading to ip_output(). This
is done to not introduce new sleeping points when trying to acquire ART's
write lock, needed when a new L2 entry is created via the RT_RESOLVE.

Inputs from and ok bluhm@@, ok dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.333 2016/11/16 14:11:26 mpi Exp $	*/
d3343 1
a3343 2
	if (sc->sc_ipopts)
		(void) m_free(sc->sc_ipopts);
d4037 1
a4037 2
			if (sc->sc_ipopts)
				(void) m_free(sc->sc_ipopts);
d4050 1
a4050 2
		if (ipopts)
			(void) m_free(ipopts);
@


1.333
log
@Be consistent and do not use braces for single line statements.

Prodded by and ok bluhm@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.332 2016/11/16 08:50:32 mpi Exp $	*/
d3401 1
a3401 1
	splsoftassert(IPL_SOFTNET);
d3537 1
a3537 1
	s = splsoftnet();
d3563 1
a3563 1
	splx(s);
d3570 1
a3570 1
	splx(s);
d3592 1
a3592 1
	splsoftassert(IPL_SOFTNET);
d3619 1
a3619 1
	splsoftassert(IPL_SOFTNET);
d3679 1
a3679 1
	splsoftassert(IPL_SOFTNET);
d3907 1
a3907 1
	splsoftassert(IPL_SOFTNET);
d3926 1
a3926 1
	splsoftassert(IPL_SOFTNET);
@


1.332
log
@Kill recursive splsoftnet()s.

While here keep local definitions local.

ok bluhm@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.331 2016/11/15 14:30:59 mpi Exp $	*/
d3681 2
a3682 2
	if ((sc = syn_cache_lookup(src, dst, &scp,
	    sotoinpcb(so)->inp_rtableid)) == NULL) {
a3683 1
	}
d3912 1
a3912 1
	    SEQ_GT(th->th_seq, sc->sc_irs+1)) {
a3913 1
	}
d3928 1
a3928 1
	if ((sc = syn_cache_lookup(src, dst, &scp, rtableid)) == NULL) {
a3929 1
	}
d4030 2
a4031 2
	if ((sc = syn_cache_lookup(src, dst, &scp, sotoinpcb(so)->inp_rtableid))
	    != NULL) {
@


1.331
log
@Use __func__ in panic strings to reduce noise when grepping.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.330 2016/11/07 09:08:05 mpi Exp $	*/
d189 16
a204 2
void syn_cache_put(struct syn_cache *);
void syn_cache_rm(struct syn_cache *);
d3399 1
a3399 1
	int i, s;
d3401 1
a3401 1
	s = splsoftnet();
a3523 2

	splx(s);
a3590 1
	int s;
d3592 1
a3592 1
	s = splsoftnet();
a3603 2

	splx(s);
a3673 1
	int s;
d3679 2
a3680 1
	s = splsoftnet();
a3682 1
		splx(s);
a3693 1
		splx(s);
a3698 1
	splx(s);
a3906 1
	int s = splsoftnet();
d3908 3
a3910 2
	if ((sc = syn_cache_lookup(src, dst, &scp, rtableid)) == NULL) {
		splx(s);
a3911 1
	}
a3913 1
		splx(s);
a3916 1
	splx(s);
a3926 1
	int s;
d3928 2
a3929 1
	s = splsoftnet();
a3930 1
		splx(s);
a3934 1
		splx(s);
a3947 1
		splx(s);
a3951 1
	splx(s);
@


1.330
log
@Use goto for consistently instead of splx() and return.

This will allow to have a single lock/unlock dance per timer.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.329 2016/10/04 13:56:50 mpi Exp $	*/
d3444 1
a3444 1
			panic("syn_cache_insert: bucketoverflow: impossible");
d3475 2
a3476 2
				panic("syn_cache_insert: cacheoverflow: "
				    "impossible");
@


1.329
log
@One more timeout_set_proc(9) conversion.

Found by Chris Jackman, thanks!
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.328 2016/09/19 16:06:25 bluhm Exp $	*/
d3526 2
a3527 4
	if (sc->sc_flags & SCF_DEAD) {
		splx(s);
		return;
	}
d3550 1
@


1.328
log
@For incomming connections keep the TF_NOPUSH flag if TCP_NOPUSH was
set on the listen socket.
From David Hill; OK vgross@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.327 2016/09/15 02:00:18 dlg Exp $	*/
d3351 1
a3351 1
		timeout_set(&(sc)->sc_timer, syn_cache_timer, (sc));	\
@


1.327
log
@all pools have their ipl set via pool_setipl, so fold it into pool_init.

the ioff argument to pool_init() is unused and has been for many
years, so this replaces it with an ipl argument. because the ipl
will be set on init we no longer need pool_setipl.

most of these changes have been done with coccinelle using the spatch
below. cocci sucks at formatting code though, so i fixed that by hand.

the manpage and subr_pool.c bits i did myself.

ok tedu@@ jmatthew@@

@@ipl@@
expression pp;
expression ipl;
expression s, a, o, f, m, p;
@@@@
-pool_init(pp, s, a, o, f, m, p);
-pool_setipl(pp, ipl);
+pool_init(pp, s, a, ipl, f, m, p);
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.326 2016/08/31 11:05:05 mpi Exp $	*/
d3801 1
a3801 1
	tp->t_flags = sototcpcb(oso)->t_flags & TF_NODELAY;
@


1.326
log
@Use 'sc_route{4,6}' directly instead of casting them to 'struct route *'.

This is another little step towards deprecating 'struct route{,_in6}'.

ok florian@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.325 2016/07/20 09:15:28 bluhm Exp $	*/
d3375 2
a3376 3
	pool_init(&syn_cache_pool, sizeof(struct syn_cache), 0, 0, 0,
	    "syncache", NULL);
	pool_setipl(&syn_cache_pool, IPL_SOFTNET);
@


1.325
log
@Make the size for the syn cache hash array tunable.  As we are
swapping between two syn caches for random reseeding anyway, this
feature can be added easily.  When the cache is empty, there is an
opportunity to change the hash size.  This allows an admin under
SYN flood attack to defend his machine.
Suggested by claudio@@; OK jung@@ claudio@@ jmc@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.324 2016/07/01 18:37:15 jca Exp $	*/
a4150 1
	struct route *ro;
a4164 1
		ro = &sc->sc_route4;
a4168 1
		ro = (struct route *)&sc->sc_route6;
d4379 1
a4379 1
		error = ip_output(m, sc->sc_ipopts, ro,
d4386 1
a4386 1
		error = ip6_output(m, NULL /*XXX*/, (struct route_in6 *)ro, 0,
@


1.324
log
@Make accepted sockets inherit IP_TTL from the listening socket.

This is consistent with the IPV6_UNICAST_HOPS behavior, and is the only
way to allow applications to completely control the TTL of outgoing
packets (else an application could temporariy send packets with the
default TTL, until it sets again IP_TTL ; this is harmful eg for GTSM).

ok bluhm@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.323 2016/06/27 20:57:41 jca Exp $	*/
d3269 1
a3269 1
int	tcp_syn_cache_size = TCP_SYN_HASH_SIZE;
d3363 7
a3369 1
	for (i = 0; i < tcp_syn_cache_size; i++) {
d3386 1
a3386 1
	int s;
d3394 1
d3397 17
a3414 1
		set->scs_use = tcp_syn_use_limit;
d3420 1
a3420 1
	scp = &set->scs_buckethead[sc->sc_hash % tcp_syn_cache_size];
d3463 1
a3463 1
			sce = &set->scs_buckethead[tcp_syn_cache_size];
d3621 1
a3621 1
		scp = &sets[i]->scs_buckethead[hash % tcp_syn_cache_size];
@


1.323
log
@Missing "break;" in switch statement; repairs IP_MINTTL.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.322 2016/06/27 16:33:48 jca Exp $	*/
d3705 4
a3709 1
#endif /* INET6 */
@


1.322
log
@Implement IPV6_MINHOPCOUNT support.

Useful to implement GTSM support in daemons such as bgpd(8). Diff from
2013 revived by renato@@.  Input from bluhm@@, ok bluhm@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.321 2016/06/27 15:59:51 bluhm Exp $	*/
d640 1
@


1.321
log
@Copy inp_hops from the listening socket to the accepted one and use
its value for the SYN+ACK packet.  This makes the IPV6_UNICAST_HOPS
socket option usable for incoming TCP connections.
tested by renato@@;  OK jca@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.320 2016/06/27 12:25:27 bluhm Exp $	*/
d636 12
a647 2
	if (inp->inp_ip_minttl && inp->inp_ip_minttl > ip->ip_ttl)
		goto drop;
@


1.320
log
@The variable swapping between inp, newinp and oldinpcb in syn_cache_get()
was overly complicated.  Simplify the code without functional change.
OK jca@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.319 2016/06/09 23:09:51 bluhm Exp $	*/
d3693 1
d4350 1
a4350 1
		ip6->ip6_hlim = in6_selecthlim(NULL);
@


1.319
log
@Fix typo in comment.  From Kapetanakis Giannis
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.318 2016/03/31 13:11:14 bluhm Exp $	*/
d3630 1
a3630 1
	struct inpcb *inp = NULL;
d3673 2
a3674 1
	inp = sotoinpcb(oso);
d3682 2
a3683 5
	{
	  struct inpcb *newinp = sotoinpcb(so);
	  memcpy(newinp->inp_seclevel, inp->inp_seclevel,
	      sizeof(inp->inp_seclevel));
	}
d3690 3
a3692 10
	{
	  int flags = inp->inp_flags;
	  struct inpcb *oldinpcb = inp;

	  inp = sotoinpcb(so);
	  inp->inp_flags |= (flags & INP_IPV6);
	  if ((inp->inp_flags & INP_IPV6) != 0) {
	    inp->inp_ipv6.ip6_hlim =
	      oldinpcb->inp_ipv6.ip6_hlim;
	  }
a3693 2
#else /* INET6 */
	inp = sotoinpcb(so);
@


1.318
log
@If one of the TCP syn cache buckets overflow, it might be a collision
attack against our hash function.  In this case, switch to the
passive syn cache as soon as possible.  It will start with a new
random seed for the hash.
input and OK mpi@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.317 2016/03/29 18:13:20 bluhm Exp $	*/
d3376 1
a3376 1
	 * and reinitialization, use it until the limit is reached.
@


1.317
log
@Allow to adjust tcp_syn_use_limit with sysctl net.inet.tcp.synuselimit.
This is convenient to test the feature and may be useful to defend
against syn flooding in a denial of service condition.  It is
consistent to the existing syn cache sysctls.  Move some declarations
to tcp_var.h to access the syn cache sets from tcp_sysctl().
OK mpi@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.316 2016/03/27 19:19:01 bluhm Exp $	*/
d3395 5
@


1.316
log
@To prevent attacks on the hash buckets of the syn cache, our TCP
stack reseeds the hash function every time the cache is empty.
Unfortunatly the attacker can prevent the reseeding by sending
unanswered SYN packes periodically.
Fix this by having an active syn cache that gets new entries and a
passive one that is idling out.  When the passive one is empty and
the active one has been used 100000 times, they switch roles and
the hash function is reseeded with new random.
tedu@@ agrees; OK mpi@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.315 2016/03/21 15:52:27 bluhm Exp $	*/
a3257 2
#define	TCP_SYN_HASH_SIZE	293
#define	TCP_SYN_BUCKET_SIZE	35
d3263 1
a3263 6
struct syn_cache_set {
        struct		syn_cache_head scs_buckethead[TCP_SYN_HASH_SIZE];
        int		scs_count;
        int		scs_use;
        u_int32_t	scs_random[5];
} tcp_syn_cache[2];
@


1.315
log
@Add a tcps_sc_seedrandom counter in TCP SYN cache and netstat -s.
This shows how often the hash function is reseeded and the random
bucket distribution changes.
OK mpi@@ claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.314 2016/03/07 18:44:00 naddy Exp $	*/
d3263 13
a3275 7
int	tcp_syn_cache_count;
struct	syn_cache_head tcp_syn_cache[TCP_SYN_HASH_SIZE];
u_int32_t tcp_syn_hash[5];

#define SYN_HASH(sa, sp, dp) \
	(((sa)->s_addr ^ tcp_syn_hash[0]) *				\
	(((((u_int32_t)(dp))<<16) + ((u_int32_t)(sp))) ^ tcp_syn_hash[4]))
d3277 1
a3277 1
#define	SYN_HASHALL(hash, src, dst) \
d3281 1
a3281 1
		satosin(dst)->sin_port);				\
d3284 6
a3289 6
#define SYN_HASH6(sa, sp, dp) \
	(((sa)->s6_addr32[0] ^ tcp_syn_hash[0]) *			\
	((sa)->s6_addr32[1] ^ tcp_syn_hash[1]) *			\
	((sa)->s6_addr32[2] ^ tcp_syn_hash[2]) *			\
	((sa)->s6_addr32[3] ^ tcp_syn_hash[3]) *			\
	(((((u_int32_t)(dp))<<16) + ((u_int32_t)(sp))) ^ tcp_syn_hash[4]))
d3291 1
a3291 1
#define SYN_HASHALL(hash, src, dst) \
d3297 1
a3297 1
			satosin(dst)->sin_port);			\
d3302 1
a3302 1
			satosin6(dst)->sin6_port);			\
d3314 1
a3314 2
	TAILQ_REMOVE(&tcp_syn_cache[sc->sc_bucketidx].sch_bucket,
	    sc, sc_bucketq);
d3317 1
a3317 1
	tcp_syn_cache[sc->sc_bucketidx].sch_length--;
d3319 1
a3319 1
	tcp_syn_cache_count--;
d3359 4
a3362 2
	for (i = 0; i < tcp_syn_cache_size; i++)
		TAILQ_INIT(&tcp_syn_cache[i].sch_bucket);
d3373 1
d3378 2
d3382 2
a3383 1
	 * the hash secrets.
d3385 3
a3387 2
	if (tcp_syn_cache_count == 0) {
		arc4random_buf(tcp_syn_hash, sizeof(tcp_syn_hash));
d3391 4
a3394 3
	SYN_HASHALL(sc->sc_hash, &sc->sc_src.sa, &sc->sc_dst.sa);
	sc->sc_bucketidx = sc->sc_hash % tcp_syn_cache_size;
	scp = &tcp_syn_cache[sc->sc_bucketidx];
a3399 1
	s = splsoftnet();
d3417 1
a3417 1
	} else if (tcp_syn_cache_count >= tcp_syn_cache_limit) {
d3431 1
a3431 1
			sce = &tcp_syn_cache[tcp_syn_cache_size];
d3434 1
a3434 1
					scp2 = &tcp_syn_cache[0];
d3466 3
a3468 1
	tcp_syn_cache_count++;
d3471 9
d3574 1
d3578 1
d3582 5
a3586 8
	if (tcp_syn_cache_count == 0)
		return (NULL);

	SYN_HASHALL(hash, src, dst);
	scp = &tcp_syn_cache[hash % tcp_syn_cache_size];
	*headp = scp;
	TAILQ_FOREACH(sc, &scp->sch_bucket, sc_bucketq) {
		if (sc->sc_hash != hash)
d3588 11
a3598 4
		if (!bcmp(&sc->sc_src, src, src->sa_len) &&
		    !bcmp(&sc->sc_dst, dst, dst->sa_len) &&
		    rtable_l2(rtableid) == rtable_l2(sc->sc_rtableid))
			return (sc);
@


1.314
log
@Sync no-argument function declaration and definition by adding (void).
ok mpi@@ millert@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.313 2016/01/22 11:10:17 jsg Exp $	*/
d3374 1
a3374 1
	if (tcp_syn_cache_count == 0)
d3376 2
@


1.313
log
@fix a missing if_put() in the default af path of tcp_mss()
ok mpi@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.312 2015/12/05 10:52:26 tedu Exp $	*/
d3349 1
a3349 1
syn_cache_init()
@


1.312
log
@upgrade tcp/ip to use the latest in C89 technology: memcpy.
ok henning
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.311 2015/12/03 14:05:28 bluhm Exp $	*/
d2957 1
a2957 1
	struct ifnet *ifp;
d3031 1
a3032 1
 out:
@


1.311
log
@To avoid that the stack manipules the pf statekeys directly, introduce
pf_inp_...() lookup, link and unlink functions as an interface.
Locking can be added to them later.  Remove the first linking at
the beginning of tcp_input() and udp_input() as it is not necessary.
It will be done later anyway.  That code was a relict, from the
time before I had added the second linking.
Input from mikeb@@ and sashan@@;  OK sashan@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.310 2015/11/29 15:09:32 mpi Exp $	*/
d692 2
a693 2
				bcopy(ip6, &tcp_saveti6.ti6_i, sizeof(*ip6));
				bcopy(th, &tcp_saveti6.ti6_t, sizeof(*th));
d697 2
a698 2
				bcopy(ip, &tcp_saveti.ti_i, sizeof(*ip));
				bcopy(th, &tcp_saveti.ti_t, sizeof(*th));
d2275 1
a2275 1
			bcopy((char *) cp + 2, (char *) &mss, sizeof(mss));
d2295 1
a2295 1
			bcopy(cp + 2, &oi->ts_val, sizeof(oi->ts_val));
d2297 1
a2297 1
			bcopy(cp + 6, &oi->ts_ecr, sizeof(oi->ts_ecr));
d2550 1
a2550 1
		bcopy(tmp_cp, (char *) &(sack.start), sizeof(tcp_seq));
d2552 1
a2552 2
		bcopy(tmp_cp + sizeof(tcp_seq),
		    (char *) &(sack.end), sizeof(tcp_seq));
d2835 1
a2835 1
			bcopy(cp+1, cp, (unsigned)(m->m_len - cnt - 1));
d3654 2
a3655 2
	  bcopy(inp->inp_seclevel, newinp->inp_seclevel,
		sizeof(inp->inp_seclevel));
d3720 1
a3720 1
	bcopy(src, mtod(am, caddr_t), src->sa_len);
d4011 2
a4012 2
	bcopy(src, &sc->sc_src, src->sa_len);
	bcopy(dst, &sc->sc_dst, dst->sa_len);
@


1.310
log
@Fix an hypotetical NULL dereference which might become true once the TCP
layer will be turned mpsafe.  We're not there yet.

Reported by David Hill, ok florian@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.309 2015/11/20 10:45:29 mpi Exp $	*/
d583 1
a583 5
	if (m->m_pkthdr.pf.statekey) {
		inp = m->m_pkthdr.pf.statekey->inp;
		if (inp && inp->inp_pf_sk)
			KASSERT(m->m_pkthdr.pf.statekey == inp->inp_pf_sk);
	}
a600 6
#if NPF > 0
		if (m->m_pkthdr.pf.statekey && inp) {
			m->m_pkthdr.pf.statekey->inp = inp;
			inp->inp_pf_sk = m->m_pkthdr.pf.statekey;
		}
#endif
d873 1
a873 7
	if (m->m_pkthdr.pf.statekey && !m->m_pkthdr.pf.statekey->inp &&
	    !inp->inp_pf_sk) {
		m->m_pkthdr.pf.statekey->inp = inp;
		inp->inp_pf_sk = m->m_pkthdr.pf.statekey;
	}
	/* The statekey has finished finding the inp, it is no longer needed. */
	m->m_pkthdr.pf.statekey = NULL;
d1281 1
a1281 4
			if (inp->inp_pf_sk) {
				inp->inp_pf_sk->inp = NULL;
				inp->inp_pf_sk = NULL;
			}
@


1.309
log
@Make use if_get() and get rid of rt_ifp.

Tested by and ok sthen@@, ok visa@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.308 2015/11/06 11:20:56 mpi Exp $	*/
d2991 4
a3008 1
	ifp = if_get(rt->rt_ifidx);
a3029 7
	} else if (ifp == NULL) {
		/*
		 * ifp may be null and rmx_mtu may be zero in certain
		 * v6 cases (e.g., if ND wasn't able to resolve the
		 * destination host.
		 */
		goto out;
@


1.308
log
@Change nd6_nud_hint() to no longer manipulate rt_ifp directly.

While here remove unused argument and convert the route check to
rtisvalid(9).

ok bluhm@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.307 2015/10/28 12:14:25 florian Exp $	*/
a2990 2
	ifp = rt->rt_ifp;

d3005 1
d3027 1
a3027 1
	} else if (!ifp) {
d3055 1
a3055 1

@


1.307
log
@Remove linkmtu and maxmtu from struct nd_ifinfo. IN6_LINKMTU can now
die and ifp->if_mtu is the one true mtu.
Suggested by and OK mpi@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.306 2015/10/24 16:08:48 mpi Exp $	*/
d147 3
a149 4
	if (tp && tp->t_inpcb && (tp->t_inpcb->inp_flags & INP_IPV6) && \
	    tp->t_inpcb->inp_route6.ro_rt) { \
		nd6_nud_hint(tp->t_inpcb->inp_route6.ro_rt, \
		    tp->t_inpcb->inp_rtableid); \
@


1.306
log
@Ignore Router Advertisment's current hop limit.

Appart from the usual inet6 axe murdering exercise to keep you fit, this
allows us to get rid of a lot of layer violation due to the use of per-
ifp variables to store the current hop limit.

Imputs from bluhm@@, ok phessler@@, florian@@, bluhm@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.305 2015/09/11 08:17:06 claudio Exp $	*/
d3048 1
a3048 1
		mss = IN6_LINKMTU(ifp) - iphlen - sizeof(struct tcphdr);
a3053 1
#ifndef INET6
a3054 8
#else
		if (tp->pf == AF_INET6)
			mssopt = IN6_LINKMTU(ifp) - iphlen -
			    sizeof(struct tcphdr);
		else
			mssopt = ifp->if_mtu - iphlen - sizeof(struct tcphdr);
#endif

d3266 1
a3266 1
			mss = IN6_LINKMTU(ifp);
@


1.305
log
@Kill yet another argument to functions in IPv6. This time ip6_output's
ifpp - XXX: just for statistics
ifpp is always NULL in all callers so that statistic confirms ifpp is
dying
OK mpi@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.304 2015/09/10 13:36:44 bluhm Exp $	*/
d4366 1
a4366 2
		ip6->ip6_hlim = in6_selecthlim(NULL,
				ro->ro_rt ? ro->ro_rt->rt_ifp : NULL);
@


1.304
log
@Only half of the IPv6 source address was used as input for the syn
cache hash.  That makes it trivial to create syn cache collisions.
Take the full address, xor it with random data and put it into the
hash function.
OK markus@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.303 2015/09/10 08:40:23 claudio Exp $	*/
d4370 1
a4370 1
		    NULL, NULL, NULL);
@


1.303
log
@if_put added to the if_get calls. Reshuffle some code to make this easier.
OK dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.302 2015/08/27 20:56:16 bluhm Exp $	*/
d3300 1
a3300 1
u_int32_t syn_hash1, syn_hash2;
d3303 2
a3304 2
	((((sa)->s_addr^syn_hash1)*(((((u_int32_t)(dp))<<16) + \
				     ((u_int32_t)(sp)))^syn_hash2)))
d3314 5
a3318 3
	((((sa)->s6_addr32[0] ^ (sa)->s6_addr32[3] ^ syn_hash1) * \
	  (((((u_int32_t)(dp))<<16) + ((u_int32_t)(sp)))^syn_hash2)) \
	 & 0x7fffffff)
d3409 2
a3410 4
	if (tcp_syn_cache_count == 0) {
		syn_hash1 = arc4random();
		syn_hash2 = arc4random();
	}
@


1.302
log
@The syn cache is completely implemented in tcp_input.c.  So all its
global variables should also live there.
OK markus@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.301 2015/08/24 23:31:35 bluhm Exp $	*/
d105 1
a105 1
int tcp_mss_adv(struct ifnet *, int);
d178 3
d183 1
a183 2
	    (m && (m->m_flags & M_PKTHDR) && if_get(m->m_pkthdr.ph_ifidx) && \
	    (if_get(m->m_pkthdr.ph_ifidx)->if_flags & IFF_LOOPBACK))) \
d187 1
d818 2
d821 2
a822 2
					if ((ia6 = in6ifa_ifpwithaddr(
					    if_get(m->m_pkthdr.ph_ifidx),
d824 2
a825 1
					    (ia6->ia6_flags & IN6_IFF_DEPRECATED)) {
d827 1
d830 1
d3257 1
a3257 1
tcp_mss_adv(struct ifnet *ifp, int af)
d3261 4
d3282 1
d4055 1
a4055 2
	sc->sc_ourmaxseg = tcp_mss_adv(m->m_flags & M_PKTHDR ?
	    if_get(m->m_pkthdr.ph_ifidx) : NULL, sc->sc_src.sa.sa_family);
@


1.301
log
@Set the required IPL at the syn-cache pool instead of doing a
splsoftnet() explicitly.  The function syn_cache_lookup() is always
called at IPL_SOFTNET so a splsoftassert() is better than a needless
splsoftnet().
OK markus@@ dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.300 2015/08/24 15:37:03 bluhm Exp $	*/
d3279 6
d3286 1
@


1.300
log
@Rename the syn cache counter into tcp_syn_cache_count to have the
same prefix for all variables.  Convert the counter type to int,
the limit is also int.  Before searching the cache, check that it
is not empty.  Do not access the counter outside of the syn cache
from tcp_ctlinput(), let the syn_cache_lookup() function handle it.
OK dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.299 2015/08/13 23:42:16 bluhm Exp $	*/
d3373 1
a3524 1
	int s;
a3525 1
	s = splsoftnet();
a3526 1
	splx(s);
d3567 2
a3568 1
	int s;
a3575 1
	s = splsoftnet();
d3581 1
a3581 2
		    rtable_l2(rtableid) == rtable_l2(sc->sc_rtableid)) {
			splx(s);
a3582 1
		}
a3583 1
	splx(s);
@


1.299
log
@Use foreach queue macros in tcp syn cache.
OK markus@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.298 2015/08/13 14:59:13 bluhm Exp $	*/
d3279 1
a3279 1
u_long	syn_cache_count;
d3327 1
a3327 1
	syn_cache_count--;
d3386 1
a3386 1
	if (syn_cache_count == 0) {
d3417 1
a3417 1
	} else if (syn_cache_count >= tcp_syn_cache_limit) {
d3466 1
a3466 1
	syn_cache_count++;
d3571 3
a3574 1

@


1.298
log
@In tcp syn cache convert the struct sockaddr casts to satosin()
inline functions.  They have the advantage to check the old type
before casting.
OK dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.297 2015/07/16 16:12:15 mpi Exp $	*/
d3545 1
a3545 3
	for (sc = LIST_FIRST(&tp->t_sc); sc != NULL; sc = nsc) {
		nsc = LIST_NEXT(sc, sc_tpq);

d3576 1
a3576 2
	for (sc = TAILQ_FIRST(&scp->sch_bucket); sc != NULL;
	     sc = TAILQ_NEXT(sc, sc_bucketq)) {
@


1.297
log
@Expand ancient NTOHL/NTOHS/HTONS/HTONL macros.

ok guenther@@, henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.296 2015/07/15 22:16:42 deraadt Exp $	*/
d3288 3
a3290 3
	hash = SYN_HASH(&((struct sockaddr_in *)(src))->sin_addr,	\
		((struct sockaddr_in *)(src))->sin_port,		\
		((struct sockaddr_in *)(dst))->sin_port);		\
d3302 3
a3304 3
		hash = SYN_HASH(&((struct sockaddr_in *)(src))->sin_addr, \
			((struct sockaddr_in *)(src))->sin_port,	\
			((struct sockaddr_in *)(dst))->sin_port);	\
d3307 3
a3309 3
		hash = SYN_HASH6(&((struct sockaddr_in6 *)(src))->sin6_addr, \
			((struct sockaddr_in6 *)(src))->sin6_port,	\
			((struct sockaddr_in6 *)(dst))->sin6_port);	\
d3712 1
a3712 1
		inp->inp_laddr6 = ((struct sockaddr_in6 *)dst)->sin6_addr;
d3716 1
a3716 2

		inp->inp_laddr = ((struct sockaddr_in *)dst)->sin_addr;
@


1.296
log
@m_freem() can handle NULL, do not check for this condition beforehands.
ok stsp mpi
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.295 2015/07/10 22:07:48 bluhm Exp $	*/
d572 4
a575 4
	NTOHL(th->th_seq);
	NTOHL(th->th_ack);
	NTOHS(th->th_win);
	NTOHS(th->th_urp);
d2288 1
a2288 1
			NTOHS(mss);
d2308 1
a2308 1
			NTOHL(oi->ts_val);
d2310 1
a2310 1
			NTOHL(oi->ts_ecr);
d2563 1
a2563 1
		NTOHL(sack.start);
d2566 1
a2566 1
		NTOHL(sack.end);
@


1.295
log
@Make KASSERT in tcp_input() less strict, tcpcb may be NULL.
OK deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.294 2015/07/09 05:45:25 mpi Exp $	*/
d4142 1
a4142 2
		if (m)
			m_freem(m);
d4161 1
a4161 2
	if (m)
		m_freem(m);
d4283 1
a4283 2
			if (m)
				m_freem(m);
d4293 1
a4293 2
			if (m)
				m_freem(m);
@


1.294
log
@Remove unused arguments and the associated code from nd6_nud_hint().

ok claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.293 2015/06/16 11:09:40 mpi Exp $	*/
d641 1
a641 1
	KASSERT(intotcpcb(inp)->t_inpcb == inp);
@


1.293
log
@Store a unique ID, an interface index, rather than a pointer to the
receiving interface in the packet header of every mbuf.

The interface pointer should now be retrieved when necessary with
if_get().  If a NULL pointer is returned by if_get(), the interface
has probably been destroy/removed and the mbuf should be freed.

Such mechanism will simplify garbage collection of mbufs and limit
problems with dangling ifp pointers.

Tested by jmatthew@@ and krw@@, discussed with many.

ok mikeb@@, bluhm@@, dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.292 2015/06/07 12:02:28 jsg Exp $	*/
d149 1
a149 1
		nd6_nud_hint(tp->t_inpcb->inp_route6.ro_rt, NULL, 0, \
@


1.292
log
@Introduce unhandled_af() for cases where code conditionally does
something based on an address family and later assumes one of the paths
was taken.  This was initially just calls to panic until guenther
suggested a function to reduce the amount of strings needed.

This reduces the amount of noise with static analysers and acts
as a sanity check.

ok guenther@@ bluhm@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.291 2015/06/07 01:25:27 krw Exp $	*/
d180 2
a181 2
	    (m && (m->m_flags & M_PKTHDR) && m->m_pkthdr.rcvif && \
	    (m->m_pkthdr.rcvif->if_flags & IFF_LOOPBACK))) \
d816 2
a817 1
					if ((ia6 = in6ifa_ifpwithaddr(m->m_pkthdr.rcvif,
d4043 1
a4043 1
	    m->m_pkthdr.rcvif : NULL, sc->sc_src.sa.sa_family);
d4182 1
a4182 1
	m->m_pkthdr.rcvif = NULL;
@


1.291
log
@Replace a bunch of == 0 with == NULL in pointer tests. Nuke some
annoying trailing, leading and embedded whitespace. No change to
.o files.

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.290 2015/05/13 10:42:46 jsg Exp $	*/
d3265 3
a3267 1
#endif
d4208 1
a4208 1
		th = NULL;
@


1.290
log
@test mbuf pointers against NULL not 0
ok krw@@ miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.289 2015/04/16 19:24:13 markus Exp $	*/
d45 4
a48 4
 * 	This product includes software developed by the University of
 * 	California, Berkeley and its contributors.
 * 	This product includes software developed at the Information
 * 	Technology Division, US Naval Research Laboratory.
d635 1
a635 1
		if (inp == 0) {
d648 1
a648 1
	if (tp == 0)
d802 1
a802 1
				 *   (2b) nothing mentioned otherwise. 
d1003 2
a1004 2
				 * referres to data that have just been 
				 * acknowledged, disregard the recorded ICMP 
d1007 1
a1007 1
				if ((tp->t_flags & TF_PMTUD_PEND) && 
d1012 1
a1012 1
				 * Keep track of the largest chunk of data 
d1653 1
a1653 1
					    	/*
d1666 1
a1666 1
                    			if (tp->sack_enable) {
d1775 1
a1775 1
			  	    tp->snd_ssthresh)
d1864 1
a1864 1
		if ((tp->t_flags & TF_PMTUD_PEND) && 
d2628 1
a2628 1
				    	    tcp_seq_subtract(cur->rxmit,
d3065 1
a3065 1
	 * 
d3260 1
a3260 1
	case AF_INET6: 
d3265 1
a3265 1
#endif  
d3732 1
a3732 1
#endif  
@


1.289
log
@remove unfinished/unused support for socket-attached ipsec-policies
ok mikeb
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.288 2015/04/14 12:22:15 mikeb Exp $	*/
d2853 1
a2853 1
		if (m == 0)
@


1.288
log
@Remove support for storing credentials and auth information in the kernel.

This code is largely unfinished and is not used for anything.  The change
leaves identities as only objects referenced by ipsec_ref structure and
their handling requires some changes to support more advanced matching of
IPsec connections.

No objections from reyk and hshoexer, with and OK markus.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.287 2015/02/08 04:40:50 yasuoka Exp $	*/
a898 23

	/* Latch SA */
	if (inp->inp_tdb_in != tdb) {
		if (tdb) {
		        tdb_add_inp(tdb, inp, 1);
			if (inp->inp_ipo == NULL) {
				inp->inp_ipo = ipsec_add_policy(inp, af,
				    IPSP_DIRECTION_OUT);
				if (inp->inp_ipo == NULL) {
					goto drop;
				}
			}
			if (inp->inp_ipo->ipo_dstid == NULL &&
			    tdb->tdb_srcid != NULL) {
				inp->inp_ipo->ipo_dstid = tdb->tdb_srcid;
				tdb->tdb_srcid->ref_count++;
			}
		} else { /* Just reset */
		        TAILQ_REMOVE(&inp->inp_tdb_in->tdb_inp_in, inp,
				     inp_tdb_in_next);
			inp->inp_tdb_in = NULL;
		}
	}
a3673 5
	  newinp->inp_secrequire = inp->inp_secrequire;
	  if (inp->inp_ipo != NULL) {
		  newinp->inp_ipo = inp->inp_ipo;
		  inp->inp_ipo->ipo_ref_count++;
	  }
@


1.287
log
@Count dropped SYN packets on the tcpstat.  They are dropped due to the
listen queue (backlog) limit or the memory shortage in syn-cache.

ok henning reyk claudio
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.286 2014/12/19 17:14:40 tedu Exp $	*/
a915 12
			if (inp->inp_ipsec_remotecred == NULL &&
			    tdb->tdb_remote_cred != NULL) {
				inp->inp_ipsec_remotecred =
				    tdb->tdb_remote_cred;
				tdb->tdb_remote_cred->ref_count++;
			}
			if (inp->inp_ipsec_remoteauth == NULL &&
			    tdb->tdb_remote_auth != NULL) {
				inp->inp_ipsec_remoteauth =
				    tdb->tdb_remote_auth;
				tdb->tdb_remote_auth->ref_count++;
			}
a3700 9
	  }
	  if (inp->inp_ipsec_remotecred != NULL) {
		  newinp->inp_ipsec_remotecred = inp->inp_ipsec_remotecred;
		  inp->inp_ipsec_remotecred->ref_count++;
	  }
	  if (inp->inp_ipsec_remoteauth != NULL) {
		  newinp->inp_ipsec_remoteauth
		      = inp->inp_ipsec_remoteauth;
		  inp->inp_ipsec_remoteauth->ref_count++;
@


1.286
log
@unifdef INET in net code as a precursor to removing the pretend option.
long live the one true internet.
ok henning mikeb
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.285 2014/12/05 15:50:04 mpi Exp $	*/
d856 2
a857 1
				    so, m, optp, optlen, &opti, reuse) == -1)
d859 1
@


1.285
log
@Explicitly include <net/if_var.h> instead of pulling it in <net/if.h>.

ok mikeb@@, krw@@, bluhm@@, tedu@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.284 2014/11/20 11:05:19 mpi Exp $	*/
a666 1
#ifdef INET
a677 1
#endif
a2394 1
#ifdef INET
a2402 1
#endif
a4030 1
#ifdef INET
a4036 1
#endif
a4313 1
#ifdef INET
a4317 1
#endif /* INET */
a4377 1
#ifdef INET
a4383 1
#endif
a4395 1
#ifdef INET
a4399 1
#endif
@


1.284
log
@In TCP and UDP layers do not (ab)use the receiving interface to check
for a multicast/broadcast destination address.

These checks have already been done in the Ethernet and IP layers and
the mbuf(9) should contain all the required information at this point.
But since we cannot trust this spaghetti stack, be paranoid and make
sure to set the flags in the IP input routines.

Use explicit comments, requested by deraadt@@.  ok claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.283 2014/11/18 02:37:31 tedu Exp $	*/
d84 1
@


1.283
log
@move arc4random prototype to systm.h. more appropriate for most code
to include that than rdnvar.h. ok deraadt dlg
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.282 2014/11/04 15:24:40 mpi Exp $	*/
a396 1
	 * See below for AF specific multicast.
a460 4
		if (IN_MULTICAST(ip->ip_dst.s_addr) ||
		    in_broadcast(ip->ip_dst, m->m_pkthdr.rcvif,
		    m->m_pkthdr.ph_rtableid))
			goto drop;
@


1.282
log
@Remove "pl" suffix on pool names.

ok dlg@@, uebayasi@@, mikeb@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.281 2014/10/24 17:58:47 bluhm Exp $	*/
a81 2

#include <dev/rndvar.h>
@


1.281
log
@Fix indentation of closing brace.
From Florian Riehm
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.280 2014/10/14 09:52:26 mpi Exp $	*/
d3412 1
a3412 1
	    "synpl", NULL);
@


1.280
log
@Use rtfree() instead of RTFREE(), NULLify some free'd route pointers and
kill the macro.

ok mikeb@@, henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.279 2014/10/08 20:19:58 bluhm Exp $	*/
d591 1
a591 1
}
@


1.279
log
@Remove #ifdef SO_OOBINLINE, it is always defined.
OK henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.278 2014/07/22 11:06:10 mpi Exp $	*/
d3375 4
a3378 2
	if (sc->sc_route4.ro_rt != NULL)
		RTFREE(sc->sc_route4.ro_rt);
@


1.278
log
@Fewer <netinet/in_systm.h> !
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.277 2014/07/11 13:15:34 bluhm Exp $	*/
d2064 2
a2065 5
		if (th->th_urp <= (u_int16_t) tlen
#ifdef SO_OOBINLINE
		     && (so->so_options & SO_OOBINLINE) == 0
#endif
		     )
@


1.277
log
@There is a use-after-free somewhere in the code that links the pf
state to the socket pcb.  Add an additional assert to narrow down
the panics.
OK henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.276 2014/04/25 09:44:38 mpi Exp $	*/
a88 1
#include <netinet/in_systm.h>
@


1.276
log
@Kill in_localaddr(), one less usage of the global list of IPv4 addresses.

This function is used only once in our tree to optimize the size of the
MSS if the forward address correspond to a host on one of our subnets,
but only if ip.mutdisc is disable, which is not the default!

While here get rid of the "#ifdef RTV_MTU", it is here.

ok henning@@, mikeb@@, bluhm@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.275 2014/04/21 12:22:26 henning Exp $	*/
d588 1
a588 1
	if (m->m_pkthdr.pf.statekey)
d590 3
@


1.275
log
@ip_output() using varargs always struck me as bizarre, esp since it's only
ever used to pass on uint32 (for ipsec). stop that madness and just pass
the uint32, 0 in all cases but the two that pass the ipsec flowinfo.
ok deraadt reyk guenther
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.274 2014/04/21 11:10:54 henning Exp $	*/
a3042 1
#ifdef RTV_MTU
d3060 5
a3064 5
		} else
			mss = rt->rt_rmx.rmx_mtu - iphlen - sizeof(struct tcphdr);
	} else
#endif /* RTV_MTU */
	if (!ifp)
d3071 1
a3071 1
	else if (ifp->if_flags & IFF_LOOPBACK)
d3073 1
a3073 1
	else if (tp->pf == AF_INET) {
a3074 2
			mss = ifp->if_mtu - iphlen - sizeof(struct tcphdr);
		else if (inp && in_localaddr(inp->inp_faddr, inp->inp_rtableid))
@


1.274
log
@we'll do fine without casting NULL to struct foo * / void *
ok gcc & md5 (alas, no binary change)
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.272 2014/01/24 18:54:58 henning Exp $	*/
d4417 1
a4417 1
		    (ip_mtudisc ? IP_MTUDISC : 0),  NULL, inp);
@


1.273
log
@"struct pkthdr" holds a routing table ID, not a routing domain one.
Avoid the confusion by using an appropriate name for the variable.

Note that since routing domain IDs are a subset of the set of routing
table IDs, the following idiom is correct:

	rtableid = rdomain

But to get the routing domain ID corresponding to a given routing table
ID, you must call rtable_l2(9).

claudio@@ likes it, ok mikeb@@
@
text
@d4417 1
a4417 2
		    (ip_mtudisc ? IP_MTUDISC : 0), 
		    (struct ip_moptions *)NULL, inp);
d4426 1
a4426 1
			(struct ip6_moptions *)0, NULL, NULL);
@


1.272
log
@clearing the _CSUM_IN_OK flags is now utterly pointless, was only done for
statistics sideeffects before. ok lteo naddy
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.269 2013/10/20 11:03:01 phessler Exp $	*/
d467 1
a467 1
		    m->m_pkthdr.rdomain))
d598 1
a598 1
			    m->m_pkthdr.rdomain);
d604 1
a604 1
			    m->m_pkthdr.rdomain);
d624 1
a624 1
			    m->m_pkthdr.rdomain);
d630 1
a630 1
			    m->m_pkthdr.rdomain);
d962 1
a962 1
		    m->m_pkthdr.rdomain))
d2258 1
a2258 1
		    TH_RST, m->m_pkthdr.rdomain);
d2263 1
a2263 1
		    (tcp_seq)0, TH_RST|TH_ACK, m->m_pkthdr.rdomain);
d3903 1
a3903 1
	    m->m_pkthdr.rdomain);
d4241 1
a4241 1
	m->m_pkthdr.rdomain = sc->sc_rtableid;
@


1.271
log
@since the cksum rewrite the counters for hardware checksummed packets
are are lie, since the software engine emulates hardware offloading
and that is later indistinguishable. so kill the hw cksummed counters.
introduce software checksummed packet counters instead.
tcp/udp handles ip & ipvshit, ip cksum covered, 6 has no ip layer cksum.
as before we still have a miscounting bug for inbound with pf on, to be
fixed in the next step.
found by, prodding & ok naddy
@
text
@d536 1
a536 3
	} else
		/* XXXHB20140123 */
		m->m_pkthdr.csum_flags &= ~M_TCP_CSUM_IN_OK;
@


1.270
log
@Propagate an rdomain number to the nd6_lookup independently from
the ifp pointer which can be NULL.  This prevents a crash reported
by David Hill <dhill at mindcry ! org>.  OK bluhm
@
text
@a516 1
			tcpstat.tcps_inhwcsum++;
d520 1
d536 2
a537 1
	} else {
a538 2
		tcpstat.tcps_inhwcsum++;
	}
@


1.269
log
@Put a large chunk of the IPv6 rdomain support in-tree.

Still some important missing pieces, and this is not yet enabled.

OK bluhm@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.268 2013/09/06 18:35:16 bluhm Exp $	*/
d151 2
a152 1
		nd6_nud_hint(tp->t_inpcb->inp_route6.ro_rt, NULL, 0); \
@


1.268
log
@In one core dump the pointers to socket, inpcb, tcpcb on the stack
of tcp_input() and tcp_output() were very inconsistent.  Especially
the so->so_pcb is NULL which can only happen after the inp has been
detached.  The whole issue looks similar to the old panic:
pool_do_get(inpcbpl): free list modified.
http://marc.info/?l=openbsd-bugs&m=132630237316970&w=2

To get more information, add some asserts that guarantee the
consistency of the socket, inpcb, tcpcb linking.  They should trigger
when an inp is taken from the pcb hashes after it has been freed.
OK henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.267 2013/08/13 09:52:53 mpi Exp $	*/
d599 2
a600 1
			    th->th_sport, &ip6->ip6_dst, th->th_dport);
d625 2
a626 1
			    &ip6->ip6_dst, th->th_dport, inpl_reverse, m);
@


1.267
log
@When net.inet.ip.sourceroute is enable, store the source route
of incoming IPv4 packets with the SSRR or LSRR header option in
a m_tag rather than in a single static entry.

Use a new m_tag type, PACKET_TAG_SRCROUTE, for this and bump
PACKET_TAG_MAXSIZE accordingly.

Adapted from FreeBSD r135274 with inputs from bluhm@@.

ok bluhm@@, mikeb@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.266 2013/07/31 15:41:52 mikeb Exp $	*/
d644 2
@


1.266
log
@Move bridge_broadcast and subsequently all IPsec SPD lookup code out
of the IPL_NET.  pf_test should be no longer called under IPL_NET as
well.  The problem became evident after the related issue was brought
up by David Hill <dhill at mindcry ! org>.

With input from and OK mpi.  Tested by David and me.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.265 2013/07/01 10:53:52 bluhm Exp $	*/
d3772 1
a3772 1
		inp->inp_options = ip_srcroute();
d4046 1
a4046 1
		ipopts = ip_srcroute();
@


1.265
log
@The reverse parameter of in_pcblookup_listen() is a boolean and not
a flag.  Rename the variable inpl_flags in tcp_input() to inpl_reverse
like in udp_input().  No binary change.
OK mikeb@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.264 2013/06/20 20:21:20 mikeb Exp $	*/
d381 1
a381 1
	int error, s;
a888 1
        s = splnet();
a898 1
		splx(s);
a909 1
					splx(s);
a935 1
        splx(s);
d968 1
a968 1
                                                     
@


1.264
log
@Always make sure that the temporary TCP protocol control block
structure is zeroed out before use.  From David Hill <dhill at
mindcry ! org>;  ok blambert claudio henning
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.263 2013/06/09 22:03:06 yasuoka Exp $	*/
d616 1
a616 1
		int	inpl_flags = 0;
d618 1
a618 1
			inpl_flags = INPLOOKUP_WILDCARD;
d624 1
a624 1
			    &ip6->ip6_dst, th->th_dport, inpl_flags, m);
d629 1
a629 1
			    ip->ip_dst, th->th_dport, inpl_flags, m,
@


1.263
log
@Increment udpstat.udps_nosec and tcpstat.tcps_rcvnosec in case packet is
dropped by IPsec security policy.

input from and ok mikeb
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.262 2013/06/03 16:57:05 bluhm Exp $	*/
d4023 1
a4028 1
		bzero(&tb, sizeof(tb));
d4042 1
a4042 2
	} else
		tb.t_flags = 0;
@


1.262
log
@Link pf states and socket inpcbs together more tightly.  The linking
was only done when a packet traveled up the stack from pf to
tcp_input().  Now also link the state and inpcb when the packet is
going down from tcp_output() to pf.  As a consequence, divert-reply
states where the initial SYN does not get an answer, can be handled
more correctly.

This change is part of a larger diff that has been backed out in
2011.  Bring the feature back in small steps to see when bad things
start to happen.

OK henning deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.261 2013/06/03 13:19:08 bluhm Exp $	*/
d899 1
@


1.261
log
@Merge the duplicate IPv4 and IPv6 checksum checking code in tcp_input()
into one block.
OK mpi@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.260 2013/04/10 08:50:59 mpi Exp $	*/
d71 2
a100 1
#include "pf.h"
d877 2
a878 1
	if (m->m_pkthdr.pf.statekey) {
d1323 11
@


1.260
log
@Remove various external variable declaration from sources files and
move them to the corresponding header with an appropriate comment if
necessary.

ok guenther@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.259 2013/04/02 18:27:47 bluhm Exp $	*/
a470 17
		/*
		 * Checksum extended TCP header and data.
		 */
		if ((m->m_pkthdr.csum_flags & M_TCP_CSUM_IN_OK) == 0) {
			if (m->m_pkthdr.csum_flags & M_TCP_CSUM_IN_BAD) {
				tcpstat.tcps_inhwcsum++;
				tcpstat.tcps_rcvbadsum++;
				goto drop;
			}
			if (in4_cksum(m, IPPROTO_TCP, iphlen, tlen) != 0) {
				tcpstat.tcps_rcvbadsum++;
				goto drop;
			}
		} else {
			m->m_pkthdr.csum_flags &= ~M_TCP_CSUM_IN_OK;
			tcpstat.tcps_inhwcsum++;
		}
d504 9
d514 1
a514 16
		/*
		 * Checksum extended TCP header and data.
		 */
		if ((m->m_pkthdr.csum_flags & M_TCP_CSUM_IN_OK) == 0) {
			if (m->m_pkthdr.csum_flags & M_TCP_CSUM_IN_BAD) {
				tcpstat.tcps_inhwcsum++;
				tcpstat.tcps_rcvbadsum++;
				goto drop;
			}
			if (in6_cksum(m, IPPROTO_TCP, sizeof(struct ip6_hdr),
			    tlen)) {
				tcpstat.tcps_rcvbadsum++;
				goto drop;
			}
		} else {
			m->m_pkthdr.csum_flags &= ~M_TCP_CSUM_IN_OK;
d516 2
d519 9
a527 1
		break;
d529 8
@


1.259
log
@Use macros sotoinpcb() and intotcpcb() instead of casts.  Use NULL
instead of 0 for pointers.  No binary change.
OK mpi@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.258 2013/03/29 13:16:14 bluhm Exp $	*/
a122 2

extern u_long sb_max;
@


1.258
log
@Declare struct pf_state_key in the mbuf and in_pcb header files to
avoid ugly casts.
OK krw@@ tedu@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.257 2013/03/28 23:10:06 tedu Exp $	*/
d363 1
a363 1
	struct tcpcb *tp = 0;
d767 1
a767 1
					inp = (struct inpcb *)so->so_pcb;
d3660 1
a3660 1
	struct tcpcb *tp = 0;
d3711 1
a3711 1
	  struct inpcb *newinp = (struct inpcb *)so->so_pcb;
d3739 1
a3739 1
	  inp = (struct inpcb *)so->so_pcb;
d3747 1
a3747 1
	inp = (struct inpcb *)so->so_pcb;
@


1.257
log
@code that calls timeout functions should include timeout.h
slipped by on i386, but the zaurus doesn't automagically pick it up.
spotted by patrick
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.256 2013/03/14 11:18:37 mpi Exp $	*/
d597 1
a597 1
		inp = ((struct pf_state_key *)m->m_pkthdr.pf.statekey)->inp;
d616 1
a616 2
			((struct pf_state_key *)m->m_pkthdr.pf.statekey)->inp =
			    inp;
d884 1
a884 1
		((struct pf_state_key *)m->m_pkthdr.pf.statekey)->inp = inp;
@


1.256
log
@tedu faith(4), suggested by todd@@ some weeks ago after a submission by
dhill.

ok krw@@, mikeb@@, tedu@@ (implicit)
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.255 2013/01/17 11:43:06 bluhm Exp $	*/
d77 1
@


1.255
log
@After finding the socket's inp by using the pf's statekey, reset
the pointer to the statekey in the mbuf.
When an UDP socket is spliced, pf would use this key during ip_output()
although the packet went through two sockets in the meantime.  Reset
the mbuf's statekey in tcp_input() and udp_input() to eliminate the
pointer to pf lingering in the socket buffers.
OK claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.254 2013/01/17 00:48:04 henning Exp $	*/
a97 5
#include "faith.h"
#if NFAITH > 0
#include <net/if_types.h>
#endif

a343 10

#if NFAITH > 0
	if (m->m_pkthdr.rcvif) {
		if (m->m_pkthdr.rcvif->if_type == IFT_FAITH) {
			/* XXX send icmp6 host/port unreach? */
			m_freem(m);
			return IPPROTO_DONE;
		}
	}
#endif
@


1.254
log
@first or second coming, commie or not commie, one m in coming is sufficient
ok claudio
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.252 2012/03/10 12:03:29 claudio Exp $	*/
d902 2
@


1.253
log
@add IP_IPSECFLOWINFO option to sendmsg() and recvmsg(), so npppd(4)
can use this to select the IPsec tunnel for sending L2TP packets.
this fixes Windows (always binding to 1701) and Android clients
(negotiating wildcard flows); feedback mpf@@ and yasuoka@@;
ok henning@@ and yasuoka@@; ok jmc@@ for the manpage
@
text
@d179 1
a179 1
 * option is enabled or when the packet is comming from a loopback
@


1.252
log
@Increase TCP's initial window to 10 * MSS or 14600 bytes as proposed in
draft-ietf-tcpm-initcwnd. net.inet.tcp.rfc3390 defaults to 2 now which
uses the 10*MSS, setting it back to 1 brings back the old default of 4*MSS.
OK sperreault@@, henning@@, sthen@@, markus@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.251 2011/10/15 18:56:52 haesbaert Exp $	*/
d915 1
a915 1
	    tdb, inp);
@


1.251
log
@Respect the ToS setting in tcp syn+ack for IPv4, still need to fix for
IPv6.

ok claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.250 2011/05/13 14:31:16 oga Exp $	*/
d3163 3
@


1.250
log
@Revert the pf->socket linking diff.

at least krw@@, pirofti@@ and todd@@ have been seeing panics (todd and krw
with xxxterm not sure about pirofti) involving pool corruption while
using this commit.

krw and todd confirm that this backout fixes the problem.

ok blambert@@ krw@@, todd@@ henning@@ and kettenis@@

	    Double link between pf states and sockets.  Henning has
	    already implemented half of it.  The additional part is: -
	    The pf state lookup for outgoing packets is optimized by
	    using mbuf->inp->state.
	    - For incomming tcp, udp, raw, raw6 packets the socket
	    lookup always is optimized by using mbuf->state->inp.
	    - All protocols establish the link for incomming packets.
	    - All protocols set the inp in the mbuf for outgoing packets.
	      This allows the linkage beginning with the first packet
	      for outgoing connections.
	    - In case of divert states, delete the state when the socket
	      closes.  Otherwise new connections could match on old
	      states instead of being diverted to the listen socket.
	    ok henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.249 2011/05/04 08:20:05 blambert Exp $	*/
d4404 2
a4405 1
		/* XXX tos? */
@


1.249
log
@Clean up gotos for listening sockets to make it obvious when packets
are dropped and when normal program flow occurs.

Change error return value of syn_cache_add() from 0 to -1 in order
to clearly communicate intent.

ok claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.248 2011/04/29 06:28:21 blambert Exp $	*/
d898 1
a898 2
	if (m->m_pkthdr.pf.statekey && !inp->inp_pf_sk &&
	    !((struct pf_state_key *)m->m_pkthdr.pf.statekey)->inp) {
a1340 13
#if NPF > 0
			/*
			 * The socket will be recreated but the new state
			 * has already been linked to the socket.  Remove the
			 * link between old socket and new state.  Otherwise
			 * closing the socket would remove the state.
			 */
			if (inp->inp_pf_sk) {
				((struct pf_state_key *)inp->inp_pf_sk)->inp =
				    NULL;
				inp->inp_pf_sk = NULL;
			}
#endif
@


1.248
log
@In certain failure cases, a RST would be sent out on rdomain 0,
regardless of the rdomain the packet was received on. Explicitly
pass the rdomain to the tcp_respond() monstrosity to compensate
for said monstricism which led to this behavior.

ok claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.247 2011/04/28 09:56:27 claudio Exp $	*/
d744 1
a744 1
				break;
d775 1
a786 1
					goto after_listen;
d879 1
a879 1
				if (so->so_qlen <= so->so_qlimit &&
d881 3
a883 2
				    so, m, optp, optlen, &opti, reuse))
					m = NULL;
a884 1
			goto drop;
a887 1
after_listen:
d4058 1
a4058 1
			return (0);
d4097 1
a4097 1
		return (1);
d4104 1
a4104 1
		return (0);
d4189 2
a4190 1
	return (1);
@


1.247
log
@Make in_broadcast() rdomain aware. Mostly mechanical change.
This fixes the problem of binding sockets to broadcast IPs in other
rdomains.
OK henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.246 2011/04/24 19:36:54 bluhm Exp $	*/
d2281 1
a2281 1
		    TH_RST, 0);
d2286 1
a2286 1
		    (tcp_seq)0, TH_RST|TH_ACK, 0);
@


1.246
log
@Double link between pf states and sockets.  Henning has already
implemented half of it.  The additional part is:
- The pf state lookup for outgoing packets is optimized by using
  mbuf->inp->state.
- For incomming tcp, udp, raw, raw6 packets the socket lookup always
  is optimized by using mbuf->state->inp.
- All protocols establish the link for incomming packets.
- All protocols set the inp in the mbuf for outgoing packets.
  This allows the linkage beginning with the first packet for
  outgoing connections.
- In case of divert states, delete the state when the socket closes.
  Otherwise new connections could match on old states instead of
  being diverted to the listen socket.
ok henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.245 2011/04/12 10:47:29 mikeb Exp $	*/
d480 2
a481 1
		    in_broadcast(ip->ip_dst, m->m_pkthdr.rcvif))
@


1.245
log
@put the accepted socket of a diverted connection into the routing domain
of a connection originator.  this allows one to query the source rdomain
with a SO_RTABLE socket option.  figured out with reyk, ok claudio.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.244 2011/04/05 18:16:07 blambert Exp $	*/
d898 2
a899 1
	if (m->m_pkthdr.pf.statekey) {
d1342 13
@


1.244
log
@Replace if/else ladder with much more legible switch statement for
testing tcp flags.

ok henning@@ claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.243 2011/04/04 23:04:18 blambert Exp $	*/
d3674 3
d3760 6
@


1.243
log
@turn some macros into functions; saves 1400+ bytes from the kernel
on amd64

ok claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.242 2011/04/04 22:25:24 blambert Exp $	*/
d735 22
a756 6
			if ((tiflags & (TH_RST|TH_ACK|TH_SYN)) != TH_SYN) {
				if (tiflags & TH_RST) {
					syn_cache_reset(&src.sa, &dst.sa, th,
					    inp->inp_rtableid);
				} else if ((tiflags & (TH_ACK|TH_SYN)) ==
				    (TH_ACK|TH_SYN)) {
d758 2
a759 3
					 * Received a SYN,ACK.  This should
					 * never happen while we are in
					 * LISTEN.  Send an RST.
d762 12
a773 35
				} else if (tiflags & TH_ACK) {
					so = syn_cache_get(&src.sa, &dst.sa,
						th, iphlen, tlen, so, m);
					if (so == NULL) {
						/*
						 * We don't have a SYN for
						 * this ACK; send an RST.
						 */
						goto badsyn;
					} else if (so ==
					    (struct socket *)(-1)) {
						/*
						 * We were unable to create
						 * the connection.  If the
						 * 3-way handshake was
						 * completed, and RST has
						 * been sent to the peer.
						 * Since the mbuf might be
						 * in use for the reply,
						 * do not free it.
						 */
						m = NULL;
					} else {
						/*
						 * We have created a
						 * full-blown connection.
						 */
						tp = NULL;
						inp = (struct inpcb *)so->so_pcb;
						tp = intotcpcb(inp);
						if (tp == NULL)
							goto badsyn;	/*XXX*/

						goto after_listen;
					}
d776 2
a777 3
					 * None of RST, SYN or ACK was set.
					 * This is an invalid packet for a
					 * TCB in LISTEN state.  Send a RST.
d779 7
a785 1
					goto badsyn;
d787 11
a797 1
			} else {
@


1.242
log
@Instead of calling tcp_reass (tcp reassembly) with magic arguments
in order to skip most of the reassembly logic and try to flush
available tcp segments to the socket, just split it off into its
own function and use it where appropriate.

ok claudio@@ henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.241 2011/04/04 13:56:11 blambert Exp $	*/
d193 3
d3359 12
a3370 11
#define	SYN_CACHE_RM(sc)						\
do {									\
	(sc)->sc_flags |= SCF_DEAD;					\
	TAILQ_REMOVE(&tcp_syn_cache[(sc)->sc_bucketidx].sch_bucket,	\
	    (sc), sc_bucketq);						\
	(sc)->sc_tp = NULL;						\
	LIST_REMOVE((sc), sc_tpq);					\
	tcp_syn_cache[(sc)->sc_bucketidx].sch_length--;			\
	timeout_del(&(sc)->sc_timer);					\
	syn_cache_count--;						\
} while (/*CONSTCOND*/0)
d3372 10
a3381 9
#define	SYN_CACHE_PUT(sc)						\
do {									\
	if ((sc)->sc_ipopts)						\
		(void) m_free((sc)->sc_ipopts);				\
	if ((sc)->sc_route4.ro_rt != NULL)				\
		RTFREE((sc)->sc_route4.ro_rt);				\
	timeout_set(&(sc)->sc_timer, syn_cache_reaper, (sc));		\
	timeout_add(&(sc)->sc_timer, 0);				\
} while (/*CONSTCOND*/0)
d3455 2
a3456 2
		SYN_CACHE_RM(sc2);
		SYN_CACHE_PUT(sc2);
d3489 2
a3490 2
		SYN_CACHE_RM(sc2);
		SYN_CACHE_PUT(sc2);
d3555 2
a3556 2
	SYN_CACHE_RM(sc);
	SYN_CACHE_PUT(sc);
d3592 2
a3593 2
		SYN_CACHE_RM(sc);
		SYN_CACHE_PUT(sc);
d3688 1
a3688 1
	SYN_CACHE_RM(sc);
d3887 1
a3887 1
	SYN_CACHE_PUT(sc);
d3897 1
a3897 1
	SYN_CACHE_PUT(sc);
d3925 1
a3925 1
	SYN_CACHE_RM(sc);
d3928 1
a3928 1
	SYN_CACHE_PUT(sc);
d3964 1
a3964 1
	SYN_CACHE_RM(sc);
d3967 1
a3967 1
	SYN_CACHE_PUT(sc);
d4156 1
a4156 1
		SYN_CACHE_PUT(sc);
@


1.241
log
@change an if statement to a switch to reduce eye bleedage
no change in .o md5

"ok gcc" claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.240 2011/01/07 17:50:42 bluhm Exp $	*/
d111 1
a207 9
	struct socket *so = tp->t_inpcb->inp_socket;
	int flags;

	/*
	 * Call with th==0 after become established to
	 * force pre-ESTABLISHED data up to user socket.
	 */
	if (th == 0)
		goto present;
d297 13
a309 1
present:
d1280 2
a1281 2
			(void) tcp_reass(tp, (struct tcphdr *)0,
				(struct mbuf *)0, &tlen);
d1558 1
a1558 2
		(void) tcp_reass(tp, (struct tcphdr *)0, (struct mbuf *)0,
				 &tlen);
@


1.240
log
@Add socket option SO_SPLICE to splice together two TCP sockets.
The data received on the source socket will automatically be sent
on the drain socket.  This allows to write relay daemons with zero
data copy.
ok markus@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.239 2010/09/29 19:42:11 claudio Exp $	*/
d1255 3
a1257 4
			if ((tiflags & (TH_ACK|TH_ECE|TH_CWR))
			    == (TH_ACK|TH_ECE) ||
			    (tiflags & (TH_ACK|TH_ECE|TH_CWR))
			    == (TH_ECE|TH_CWR)) {
@


1.239
log
@Initialize the ts_recent (received timestamp) field in the newly created
socket from the information we have in the syncache. Also bzero() the
tcpcb that is passed to tcp_dooptions() just to be sure.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.238 2010/09/29 18:00:19 claudio Exp $	*/
d331 1
d333 1
d373 1
a373 1
	int todrop, acked, ourfinisacked, needoutput = 0;
d1095 2
a1096 1
				if (sb_notify(&so->so_snd))
d1098 4
a1101 1
				if (so->so_snd.sb_cc)
d1145 1
d1147 2
a1148 1
			if (tp->t_flags & TF_ACKNOW)
d1784 1
a1784 1
						needoutput = 1;
d1787 1
a1787 1
					needoutput = 1;
d1855 1
a1855 1
			needoutput = 1;
d1888 2
a1889 1
		if (sb_notify(&so->so_snd))
d1891 2
d2010 1
a2010 1
		needoutput = 1;
d2102 1
d2104 1
d2198 1
a2198 1
	if (needoutput || (tp->t_flags & TF_ACKNOW)) {
a2199 1
	}
@


1.238
log
@It is not allowed to recalculate the window scale after the initial SYN.
A session must stick to the rscale factor sent out in the SYN packet.
Remove the bogus tcp_rscale() call which is done after a full established
session is returned from the syncache.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.237 2010/09/29 08:18:23 claudio Exp $	*/
d3815 1
d3996 1
@


1.237
log
@Do not delay ACKs on connections using loopback interfaces. There is no
reason to reduce the amount of ACKs sent and delayed ACKs have a very bad
interaction with the large MTU of lo(4) and the fairly small socketbuffer
size. In collaboration with andre@@freebsd.
OK deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.236 2010/09/24 02:59:45 claudio Exp $	*/
a770 5
						/*
						 * Compute proper scaling
						 * value from buffer space
						 */
						tcp_rscale(tp, so->so_rcv.sb_hiwat);
@


1.236
log
@TCP send and recv buffer scaling.
Send buffer is scaled by not accounting unacknowledged on the wire
data against the buffer limit. Receive buffer scaling is done similar
to FreeBSD -- measure the delay * bandwith product and base the
buffer on that. The problem is that our RTT measurment is coarse
so it overshoots on low delay links. This does not matter that much
since the recvbuffer is almost always empty.
Add a back pressure mechanism to control the amount of memory
assigned to socketbuffers that kicks in when 80% of the cluster
pool is used.
Increases the download speed from 300kB/s to 4.4MB/s on ftp.eu.openbsd.org.

Based on work by markus@@ and djm@@.

OK dlg@@, henning@@, put it in deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.235 2010/07/20 15:36:03 matthew Exp $	*/
d178 2
a179 1
 * option is enabled.
d181 1
a181 1
#define	TCP_SETUP_ACK(tp, tiflags) \
d184 3
a186 1
	    (tcp_ack_on_push && (tiflags) & TH_PUSH)) \
d1122 2
a1144 1
			TCP_SETUP_ACK(tp, tiflags);
d2084 1
a2084 1
			TCP_SETUP_ACK(tp, tiflags);
@


1.235
log
@Switch some obvious network stack MAC comparisons from bcmp() to
timingsafe_bcmp().

ok deraadt@@; committed over WPA.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.234 2010/07/09 16:58:06 reyk Exp $	*/
d1094 1
d1126 10
d1166 4
d1879 2
d4083 20
d4104 1
a4104 2
		    TCP_MAXWIN << sc->sc_request_r_scale <
		    so->so_rcv.sb_hiwat)
@


1.234
log
@Add support for using IPsec in multiple rdomains.

This allows to run isakmpd/iked/ipsecctl in multiple rdomains
independently (with "route exec"); the kernel will pickup the rdomain
from the process context of the pfkey socket and load the flows and
SAs into the matching rdomain encap routing table.  The network stack
also needs to pass the rdomain to the ipsec stack to lookup the
correct rdomain that belongs to an interface/mbuf/... You can now run
individual IPsec configs per rdomain or create IPsec VPNs between
multiple rdomains on the same machine ;).  Note that a primary enc(4)
in addition to enc0 interface is required per rdomain, eg. enc1 rdomain 1.

Test by some people, mostly on existing "rdomain 0" setups.  Was in
snaps for some days and people didn't complain.

ok claudio@@ naddy@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.233 2010/07/03 04:44:51 guenther Exp $	*/
d2354 1
a2354 1
			if (sigp && bcmp(sigp, cp + 2, 16))
d2422 1
a2422 1
		if (bcmp(sig, sigp, 16)) {
@


1.233
log
@Fix the naming of interfaces and variables for rdomains and rtables
and make it possible to bind sockets (including listening sockets!)
to rtables and not just rdomains.  This changes the name of the
system calls, socket option, and ioctl.  After building with this
you should remove the files /usr/share/man/cat2/[gs]etrdomain.0.

Since this removes the existing [gs]etrdomain() system calls, the
libc major is bumped.

Written by claudio@@, criticized^Wcritiqued by me
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.232 2010/03/11 00:24:58 sthen Exp $	*/
d896 2
a897 1
	        tdb = gettdb(tdbi->spi, &tdbi->dst, tdbi->proto);
d966 2
a967 1
		if (tcp_dooptions(tp, optp, optlen, th, m, iphlen, &opti))
d2261 2
a2262 1
    struct mbuf *m, int iphlen, struct tcp_opt_info *oi)
d2394 2
a2395 1
		tdb = gettdbbysrcdst(0, &src, &dst, IPPROTO_TCP);
d3989 2
a3990 1
		if (tcp_dooptions(&tb, optp, optlen, th, m, iphlen, oi))
d4275 2
a4276 1
		tdb = gettdbbysrcdst(0, &src, &dst, IPPROTO_TCP);
@


1.232
log
@unbreak the build with a custom kernel config including "pseudo-device
faith 1", noticed by Andris Kadar.  ok kettenis@@ beck@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.231 2010/01/15 18:20:23 chl Exp $	*/
d726 1
a726 1
					    inp->inp_rdomain);
d3041 1
a3041 1
		else if (inp && in_localaddr(inp->inp_faddr, inp->inp_rdomain))
d3567 1
a3567 1
    struct syn_cache_head **headp, u_int rdomain)
d3585 1
a3585 1
		    rtable_l2(rdomain) == rtable_l2(sc->sc_rdomain)) {
d3631 1
a3631 1
	    sotoinpcb(so)->inp_rdomain)) == NULL) {
d3711 2
a3712 2
	/* inherit rdomain from listening socket */
	inp->inp_rdomain = sc->sc_rdomain;
d3870 1
a3870 1
    u_int rdomain)
d3876 1
a3876 1
	if ((sc = syn_cache_lookup(src, dst, &scp, rdomain)) == NULL) {
d3893 1
a3893 1
    u_int rdomain)
d3900 1
a3900 1
	if ((sc = syn_cache_lookup(src, dst, &scp, rdomain)) == NULL) {
d4008 1
a4008 1
	if ((sc = syn_cache_lookup(src, dst, &scp, sotoinpcb(so)->inp_rdomain))
d4041 1
a4041 1
	sc->sc_rdomain = sotoinpcb(so)->inp_rdomain;
d4169 1
a4169 1
	m->m_pkthdr.rdomain = sc->sc_rdomain;
@


1.231
log
@Replace pool_get() + bzero() with pool_get(..., PR_ZERO).

With input from oga@@ and krw@@

ok oga@@ krw@@ thib@@ markus@@ mk@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.230 2009/11/13 20:54:05 claudio Exp $	*/
d99 3
@


1.230
log
@Extend the protosw pr_ctlinput function to include the rdomain. This is
needed so that the route and inp lookups done in TCP and UDP know where
to look. Additionally in_pcbnotifyall() and tcp_respond() got a rdomain
argument as well for similar reasons. With this tcp seems to be now
fully rdomain save and no longer leaks single packets into the main domain.
Looks good markus@@, henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.229 2009/11/03 10:59:04 claudio Exp $	*/
d4025 1
a4025 1
	sc = pool_get(&syn_cache_pool, PR_NOWAIT);
a4035 2
	bzero(sc, sizeof(struct syn_cache));
	bzero(&sc->sc_timer, sizeof(sc->sc_timer));
@


1.229
log
@rtables are stacked on rdomains (it is possible to have multiple routing
tables on top of a rdomain) but until now our code was a crazy mix so that
it was impossible to correctly use rtables in that case. Additionally pf(4)
only knows about rtables and not about rdomains. This is especially bad when
tracking (possibly conflicting) states in various domains.
This diff fixes all or most of these issues. It adds a lookup function to
get the rdomain id based on a rtable id. Makes pf understand rdomains and
allows pf to move packets between rdomains (it is similar to NAT).
Because pf states now track the rdomain id as well it is necessary to modify
the pfsync wire format. So old and new systems will not sync up.
A lot of help by dlg@@, tested by sthen@@, jsg@@ and probably more
OK dlg@@, mpf@@, deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.228 2009/08/20 13:25:42 bluhm Exp $	*/
d2221 1
a2221 1
		    TH_RST);
d2226 1
a2226 1
		    (tcp_seq)0, TH_RST|TH_ACK);
d3848 2
a3849 1
	tcp_respond(NULL, mtod(m, caddr_t), th, (tcp_seq)0, th->th_ack, TH_RST);
@


1.228
log
@fix indentation
no binary change;  ok grunk@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.227 2009/08/10 10:13:43 claudio Exp $	*/
d3582 1
a3582 1
		    rdomain == sc->sc_rdomain) {
d3628 1
a3628 1
	    m->m_pkthdr.rdomain)) == NULL) {
d4004 2
a4005 2
	if ((sc = syn_cache_lookup(src, dst, &scp, m->m_pkthdr.rdomain)) !=
	    NULL) {
d4039 1
a4039 1
	sc->sc_rdomain = m->m_pkthdr.rdomain;
@


1.227
log
@sockets created via a listening socket lose the rdomain and fail to work
therefore. Inherit the rdomain through the syncache.
There are some interactions that need some more work (ctlinput) so this
can be improved but is good enough for now.
OK markus@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.226 2009/06/05 00:05:22 claudio Exp $	*/
d881 4
a884 5
		if (m->m_pkthdr.pf.statekey) {
			((struct pf_state_key *)m->m_pkthdr.pf.statekey)->inp =
			    inp;
			inp->inp_pf_sk = m->m_pkthdr.pf.statekey;
		}
@


1.226
log
@Initial support for routing domains. This allows to bind interfaces to
alternate routing table and separate them from other interfaces in distinct
routing tables. The same network can now be used in any doamin at the same
time without causing conflicts.
This diff is mostly mechanical and adds the necessary rdomain checks accross
net and netinet. L2 and IPv4 are mostly covered still missing pf and IPv6.
input and tested by jsg@@, phessler@@ and reyk@@. "put it in" deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.225 2009/06/03 18:22:44 naddy Exp $	*/
d722 2
a723 1
					syn_cache_reset(&src.sa, &dst.sa, th);
d3565 1
a3565 1
    struct syn_cache_head **headp)
d3582 2
a3583 1
		    !bcmp(&sc->sc_dst, dst, dst->sa_len)) {
d3628 2
a3629 1
	if ((sc = syn_cache_lookup(src, dst, &scp)) == NULL) {
d3662 1
d3709 3
d3866 2
a3867 1
syn_cache_reset(struct sockaddr *src, struct sockaddr *dst, struct tcphdr *th)
d3873 1
a3873 1
	if ((sc = syn_cache_lookup(src, dst, &scp)) == NULL) {
d3889 2
a3890 1
syn_cache_unreach(struct sockaddr *src, struct sockaddr *dst, struct tcphdr *th)
d3897 1
a3897 1
	if ((sc = syn_cache_lookup(src, dst, &scp)) == NULL) {
d4005 2
a4006 1
	if ((sc = syn_cache_lookup(src, dst, &scp)) != NULL) {
d4040 1
d4168 1
@


1.225
log
@add the basic infrastructure to take advantage of TCP and UDP receive
checksum offload over IPv6; ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.224 2008/11/02 10:37:29 claudio Exp $	*/
d608 2
a609 1
			    th->th_sport, ip->ip_dst, th->th_dport);
d634 2
a635 1
			    ip->ip_dst, th->th_dport, inpl_flags, m);
d3038 1
a3038 1
		else if (inp && in_localaddr(inp->inp_faddr))
@


1.224
log
@Remove the M_ANYCAST6 mbuf flag by doing the detection all in ip6_input().
M_ANYCAST6 was only used to signal tcp6_input() that it should drop the
packet and send back icmp error. This can be done in ip6_input() without
the need for a mbuf flag. Gives us back one slot in m_flags for possible
future need. Looked at and some input by naddy@@ and henning@@. OK dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.223 2008/10/10 20:03:42 dhill Exp $	*/
d525 14
a538 3
		if (in6_cksum(m, IPPROTO_TCP, sizeof(struct ip6_hdr), tlen)) {
			tcpstat.tcps_rcvbadsum++;
			goto drop;
@


1.223
log
@back out previous change.  Another panic, not as frequent, and
definitely not at will.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.222 2008/10/10 15:35:59 dhill Exp $	*/
a343 15

	/*
	 * draft-itojun-ipv6-tcp-to-anycast
	 * better place to put this in?
	 */
	if (m->m_flags & M_ANYCAST6) {
		if (m->m_len >= sizeof(struct ip6_hdr)) {
			struct ip6_hdr *ip6 = mtod(m, struct ip6_hdr *);
			icmp6_error(m, ICMP6_DST_UNREACH,
				ICMP6_DST_UNREACH_ADDR,
				(caddr_t)&ip6->ip6_dst - (caddr_t)ip6);
		} else
			m_freem(m);
		return IPPROTO_DONE;
	}
@


1.222
log
@Comment out statekey code to stop 'panic: soreceive 3', which
happens with IPv6 TCP traffic, until a better fix is found.

patch from henning@@
proded by deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.221 2008/09/09 15:26:12 mpf Exp $	*/
a596 1
/*
a600 1
*/
@


1.221
log
@The pf state to pcb linking code change didn't account for the
TIME_WAIT socket recycling code to redo the pcb lookup w/out
resetting the inp pointer. Therefore we used the stale pcb,
which leads us to reply with a RST to SYNs received on TIME_WAIT
sockets.  Also move the findpcb label below the pf pcb cache lookup,
to avoid using a stale pcb when the caching code gets activated.
OK markus@@, henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.220 2008/07/03 15:46:24 henning Exp $	*/
d597 1
d602 1
@


1.220
log
@link pf state keys to tcp pcbs and vice versa.
when we first do a pcb lookup and we have a pointer to a pf state key
in the mbuf header, store the state key pointer in the pcb and a pointer
to the pcb we just found in the state key. when either the state key
or the pcb is removed, clear the pointers.
on subsequent packets inbound we can skip the pcb lookup and just use the
pointer from the state key.
on subsequent packets outbound we can skip the state key lookup and use
the pointer from the pcb.
about 8% speedup with 100 concurrent tcp sessions, should help much more
with more tcp sessions.
ok markus ryan
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.219 2008/06/14 22:15:30 jsing Exp $	*/
a596 1
findpcb:
d601 1
d1312 1
@


1.220.2.1
log
@The pf state to pcb linking code change didn't account for the
TIME_WAIT socket recycling code to redo the pcb lookup w/out
resetting the inp pointer. Therefore we used the stale pcb,
which leads us to reply with a RST to SYNs received on TIME_WAIT
sockets.  Also move the findpcb label below the pf pcb cache lookup,
to avoid using a stale pcb when the caching code gets activated.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.220 2008/07/03 15:46:24 henning Exp $	*/
d597 1
a601 1
findpcb:
a1311 1
			inp = NULL;
@


1.219
log
@Include "faith.h" in order to get NFAITH. Also clean up NFAITH conditionals
whilst we're here.

ok henning@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.218 2008/06/12 15:13:47 jsing Exp $	*/
d100 5
d373 1
a373 1
	struct inpcb *inp;
d598 6
a603 1
	switch (af) {
d605 16
a620 4
	case AF_INET6:
		inp = in6_pcbhashlookup(&tcbtable, &ip6->ip6_src, th->th_sport,
		    &ip6->ip6_dst, th->th_dport);
		break;
a621 4
	case AF_INET:
		inp = in_pcbhashlookup(&tcbtable, ip->ip_src, th->th_sport,
		    ip->ip_dst, th->th_dport);
		break;
d623 1
a623 1
	if (inp == 0) {
d879 8
@


1.218
log
@Remove some crazy #if mess.

ok markus@@ henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.217 2008/06/12 15:08:47 jsing Exp $	*/
d98 2
d330 1
a330 1
#if defined(NFAITH) && 0 < NFAITH
@


1.217
log
@ANSIfy function definitions.

ok markus@@ mcbride@@ henning@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.216 2008/06/12 14:50:20 jsing Exp $	*/
d1645 1
a1645 1
#if defined(TCP_SACK)
a1646 2
#endif
#ifdef TCP_SACK
a1652 1
#if 1 /* TCP_ECN */
a1653 1
#endif
a1681 1
#if 1 /* TCP_ECN */
a1682 1
#endif
@


1.216
log
@Fix type difference between function prototype and implementation.

According to millert@@ this would have been promoted from a short to an int
anyway, since K&R C cannot pass variables that are smaller than an int.

ok deraadt@@ millert@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.215 2008/05/15 19:40:38 markus Exp $	*/
d191 1
a191 5
tcp_reass(tp, th, m, tlen)
	struct tcpcb *tp;
	struct tcphdr *th;
	struct mbuf *m;
	int *tlen;
d324 1
a324 3
tcp6_input(mp, offp, proto)
	struct mbuf **mp;
	int *offp, proto;
d2234 2
a2235 8
tcp_dooptions(tp, cp, cnt, th, m, iphlen, oi)
	struct tcpcb *tp;
	u_char *cp;
	int cnt;
	struct tcphdr *th;
	struct mbuf *m;
	int iphlen;
	struct tcp_opt_info *oi;
d2408 1
a2408 2
tcp_seq_subtract(a, b)
	u_long a, b;
d2744 1
a2744 3
tcp_del_sackholes(tp, th)
	struct tcpcb *tp;
	struct tcphdr *th;
d2773 1
a2773 2
tcp_clean_sackreport(tp)
	struct tcpcb *tp;
d2789 1
a2789 3
tcp_sack_partialack(tp, th)
	struct tcpcb *tp;
	struct tcphdr *th;
d2820 1
a2820 5
tcp_pulloutofband(so, urgent, m, off)
	struct socket *so;
	u_int urgent;
	struct mbuf *m;
	int off;
d2848 1
a2848 3
tcp_xmit_timer(tp, rtt)
	struct tcpcb *tp;
	int rtt;
d2950 1
a2950 3
tcp_mss(tp, offer)
	struct tcpcb *tp;
	int offer;
d3147 1
a3147 2
tcp_mss_update(tp)
	struct tcpcb *tp;
d3192 1
a3192 3
tcp_newreno(tp, th)
	struct tcpcb *tp;
	struct tcphdr *th;
d3353 1
a3353 3
syn_cache_insert(sc, tp)
	struct syn_cache *sc;
	struct tcpcb *tp;
d3515 1
a3515 2
syn_cache_cleanup(tp)
	struct tcpcb *tp;
d3542 2
a3543 4
syn_cache_lookup(src, dst, headp)
	struct sockaddr *src;
	struct sockaddr *dst;
	struct syn_cache_head **headp;
d3593 2
a3594 7
syn_cache_get(src, dst, th, hlen, tlen, so, m)
	struct sockaddr *src;
	struct sockaddr *dst;
	struct tcphdr *th;
	unsigned int hlen, tlen;
	struct socket *so;
	struct mbuf *m;
d3838 1
a3838 4
syn_cache_reset(src, dst, th)
	struct sockaddr *src;
	struct sockaddr *dst;
	struct tcphdr *th;
d3860 1
a3860 4
syn_cache_unreach(src, dst, th)
	struct sockaddr *src;
	struct sockaddr *dst;
	struct tcphdr *th;
d3912 3
a3914 11
syn_cache_add(src, dst, th, iphlen, so, m, optp, optlen, oi, issp)
	struct sockaddr *src;
	struct sockaddr *dst;
	struct tcphdr *th;
	unsigned int iphlen;
	struct socket *so;
	struct mbuf *m;
	u_char *optp;
	int optlen;
	struct tcp_opt_info *oi;
	tcp_seq *issp;
d4069 1
a4069 3
syn_cache_respond(sc, m)
	struct syn_cache *sc;
	struct mbuf *m;
@


1.215
log
@divert for ipv6; ok henning, pyr
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.214 2008/05/09 02:44:54 markus Exp $	*/
d2872 1
a2872 1
	short rtt;
@


1.214
log
@divert packets to local socket without modifying the ip header;
makes transparent proxies much easier; ok beck@@, feedback claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.213 2008/05/06 08:47:35 markus Exp $	*/
d618 1
a618 1
			    &ip6->ip6_dst, th->th_dport, inpl_flags);
@


1.213
log
@remove tcp_drain code since it's not longer used; ok henning, feedback thib
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.212 2008/02/20 11:24:02 markus Exp $	*/
d623 1
a623 1
			    ip->ip_dst, th->th_dport, inpl_flags);
@


1.212
log
@when creating a response, use the correct TCP header instead of
relying on the mbuf chain layout; with claudio@@ and krw@@; ok henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.211 2008/02/11 18:03:16 bluhm Exp $	*/
a1229 1
			tcp_reass_lock(tp);
a1231 1
			tcp_reass_unlock(tp);
a1506 1
		tcp_reass_lock(tp);
a1508 1
		tcp_reass_unlock(tp);
a2040 1
		tcp_reass_lock(tp);
a2042 1
			tcp_reass_unlock(tp);
a2058 1
			tcp_reass_unlock(tp);
@


1.211
log
@The TCP server has to recalculate the client's window size taken
from the first ACK packet.  Otherwise the server would use the
unscaled window size for the fist data it is sending.

ok markus@@ dhartmei@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.210 2007/11/27 17:23:23 deraadt Exp $	*/
d2212 1
a2212 1
		tcp_respond(tp, mtod(m, caddr_t), m, (tcp_seq)0, th->th_ack,
d2217 1
a2217 1
		tcp_respond(tp, mtod(m, caddr_t), m, th->th_seq + tlen,
d2220 1
d3867 2
a3868 1
	tcp_respond(NULL, mtod(m, caddr_t), m, (tcp_seq)0, th->th_ack, TH_RST);
@


1.210
log
@TCP_COMPAT_42 was last used in 1997.  Kill it.
ok millert
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.209 2007/11/27 16:22:13 martynas Exp $	*/
d1507 1
a3792 2
		tp->snd_scale = sc->sc_requested_s_scale;
		tp->rcv_scale = sc->sc_request_r_scale;
@


1.209
log
@typos;  ok jmc@@
sys/dev/pci/pciide.c from naddy@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.208 2007/09/01 18:49:28 henning Exp $	*/
a4071 4
#ifdef TCP_COMPAT_42
	tcp_iss += TCP_ISSINCR/2;
	sc->sc_iss = tcp_iss;
#else
a4072 1
#endif
@


1.208
log
@since the
MGET* macros were changed to function calls, there wasn't any
need for the pool declarations and the inclusion of pool.h
From: tbert <bret.lambert@@gmail.com>
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.207 2007/06/15 18:23:06 markus Exp $	*/
d1589 1
a1589 1
			 * t_dupacks so that we are less agressive in
@


1.207
log
@Drop the current random timestamps and the current ISN generation
code and replace both with a RFC1948 based method, so TCP clients
now have monotonic ISN/timestamps.  The server side uses completely
random ISN/timestamps and does time-wait recycling (on port reuse).
ok djm@@, mcbride@@; thanks to lots of testers
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.206 2007/06/11 11:29:35 henning Exp $	*/
d78 1
@


1.207.2.1
log
@MFC (markus)
when creating a response, use the correct TCP header instead of
relying on the mbuf chain layout; with claudio@@ and krw@@; ok henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.207 2007/06/15 18:23:06 markus Exp $	*/
d2210 1
a2210 1
		tcp_respond(tp, mtod(m, caddr_t), th, (tcp_seq)0, th->th_ack,
d2215 1
a2215 1
		tcp_respond(tp, mtod(m, caddr_t), th, th->th_seq + tlen,
a2217 1
	m_freem(m);
d3866 1
a3866 2
	tcp_respond(NULL, mtod(m, caddr_t), th, (tcp_seq)0, th->th_ack, TH_RST);
	m_freem(m);
@


1.206
log
@there was code inside #if NPF > 0, but pf.h was not included, so it did
not get build. the code looks at flags that used to be in mbuf tags, now
they are in the mbuf header, so we can check them unconditionally.
problem spotted by Daniel Roethlisberger <daniel@@roe.ch>, ok ryan markus
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.205 2007/06/01 00:52:38 henning Exp $	*/
d381 1
a381 1
	int iss = 0;
d849 1
a849 1
						so, m, optp, optlen, &opti))
d1271 22
a1391 13
			 * If a new connection request is received
			 * while in TIME_WAIT, drop the old connection
			 * and start over if the sequence numbers
			 * are above the previous ones.
			 */
			if (tiflags & TH_SYN &&
			    tp->t_state == TCPS_TIME_WAIT &&
			    SEQ_GT(th->th_seq, tp->rcv_nxt)) {
				iss = tp->snd_nxt + TCP_ISSINCR;
				tp = tcp_close(tp);
				goto findpcb;
			}
			/*
d3962 1
a3962 1
syn_cache_add(src, dst, th, iphlen, so, m, optp, optlen, oi)
d3972 1
d4075 1
a4075 1
	sc->sc_iss = tcp_rndiss_next();
@


1.205
log
@apply the "skip ipsec if there are no flows" speedup diff to IPv6 too.
we need a pointer to the inpcb to decide, which was not previously
passed to ip6_output, so this diff is a little bigger.
from itojun, ok ryan
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.204 2007/05/27 21:37:53 deraadt Exp $	*/
d610 1
a610 5
#if NPF > 0
		struct pf_mtag *t;

		if ((t = pf_find_mtag(m)) != NULL &&
		    t->flags & PF_TAG_TRANSLATE_LOCALHOST)
a611 1
#endif
@


1.204
log
@diffs are better if compilers see them first
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.203 2007/05/27 20:20:54 dlg Exp $	*/
d4379 1
a4379 1
			(struct ip6_moptions *)0, NULL);
@


1.203
log
@take static off tcp_mss_adv.

ok reyk@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.202 2007/05/22 10:20:55 michele Exp $	*/
d99 2
a103 2

int tcp_mss_adv(struct ifnet *, int);
@


1.202
log
@When a partial ack is received check if congestion window is larger than
acked bytes and update the window accordingly

fix PR4278

OK henning@@ markus@@ claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.201 2007/02/13 06:39:50 itojun Exp $	*/
d103 2
d3260 1
a3260 1
static int
@


1.201
log
@whitespace fix
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.200 2006/12/11 21:31:58 markus Exp $	*/
d3246 6
a3251 1
		tp->snd_cwnd -= (th->th_ack - tp->snd_una - tp->t_maxseg);
@


1.201.2.1
log
@MFC (markus)
when creating a response, use the correct TCP header instead of
relying on the mbuf chain layout; with claudio@@ and krw@@; ok henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.201 2007/02/13 06:39:50 itojun Exp $	*/
d2204 1
a2204 1
		tcp_respond(tp, mtod(m, caddr_t), th, (tcp_seq)0, th->th_ack,
d2209 1
a2209 1
		tcp_respond(tp, mtod(m, caddr_t), th, th->th_seq + tlen,
a2211 1
	m_freem(m);
d3855 1
a3855 2
	tcp_respond(NULL, mtod(m, caddr_t), th, (tcp_seq)0, th->th_ack, TH_RST);
	m_freem(m);
@


1.200
log
@allow RST with th_seq incremented (seen from windows tcp clients); ok dhartmei
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.199 2006/12/05 12:04:36 henning Exp $	*/
d1857 1
a1857 1
		    tp->t_pmtud_mss_acked = acked;
@


1.199
log
@make the syncache code respect (inherit) the ttl from the listening socket
when sending the synack response. ok markus
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.198 2006/10/31 16:22:25 markus Exp $	*/
d1431 2
a1432 1
		    th->th_seq != tp->rcv_nxt)
@


1.198
log
@do not re-generate the timestamp modulation offset for SYN-ACK retransmits;
this unbreaks TCP for high RTT (~3s); ok mcbride@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.197 2006/10/11 09:34:51 henning Exp $	*/
d4331 3
d4342 1
a4342 1
		ip->ip_ttl = ip_defttl;
a4355 3

	/* use IPsec policy from listening socket, on SYN ACK */
	inp = sc->sc_tp ? sc->sc_tp->t_inpcb : NULL;
@


1.197
log
@implement IP_MINTTL socket option fo tcp sockets
This is for RFC3682 aka the TTL security hack - sender sets TTL to 255,
receiver checks no router on the way (or, no more than expected) reduced
the TTL. carp uses that technique already.
modeled after FreeBSD implementation.
ok claudio djm deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.196 2006/03/12 18:42:40 markus Exp $	*/
d4070 1
a4070 1
	    (TF_REQ_TSTMP|TF_RCVD_TSTMP))
d4072 2
a4254 1
		sc->sc_modulate = arc4random();
@


1.196
log
@mbuf use-after-free; ok henning, djm, brad
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.195 2006/02/26 17:50:45 markus Exp $	*/
d639 4
@


1.196.2.1
log
@MFC:
Fix by markus@@

do not re-generate the timestamp modulation offset for SYN-ACK retransmits;
this unbreaks TCP for high RTT (~3s);

ok markus@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.196 2006/03/12 18:42:40 markus Exp $	*/
d4066 1
a4066 1
	    (TF_REQ_TSTMP|TF_RCVD_TSTMP)) {
a4067 2
		sc->sc_modulate = arc4random();
	}
d4249 1
@


1.195
log
@unbreak tcp window update (restore 4.4lite code); netbsd pr 13952;
ok claudio, henning, brad, djm, tedu
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.194 2005/12/01 22:31:50 markus Exp $	*/
d2028 4
d2057 1
a2057 1
			tcp_update_sack_list(tp, th->th_seq, th->th_seq + tlen);
@


1.195.2.1
log
@MFC:
Fix by markus@@

mbuf use-after-free

ok markus@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.195 2006/02/26 17:50:45 markus Exp $	*/
a2027 4
#ifdef TCP_SACK
		tcp_seq laststart = th->th_seq;
		tcp_seq lastend = th->th_seq + tlen;
#endif
d2053 1
a2053 1
			tcp_update_sack_list(tp, laststart, lastend);
@


1.195.2.2
log
@MFC:
Fix by markus@@

do not re-generate the timestamp modulation offset for SYN-ACK retransmits;
this unbreaks TCP for high RTT (~3s);

ok markus@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.195.2.1 2006/11/13 23:12:19 brad Exp $	*/
d4066 1
a4066 1
	    (TF_REQ_TSTMP|TF_RCVD_TSTMP)) {
a4067 2
		sc->sc_modulate = arc4random();
	}
d4249 1
@


1.194
log
@allow RST if the th_seq matches rcv_nxt in case the RST follows the
data immediately.  otherwise we would ignore RST for delayed acks;
ok deraadt, dhartmei
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.193 2005/11/15 21:09:45 miod Exp $	*/
d1941 4
a1944 3
	if ((tiflags & TH_ACK) && (SEQ_LT(tp->snd_wl1, th->th_seq) ||
	    (tp->snd_wl1 == th->th_seq && SEQ_LT(tp->snd_wl2, th->th_ack)) ||
	    (tp->snd_wl2 == th->th_ack && tiwin > tp->snd_wnd))) {
@


1.193
log
@Only two `h' in threshold.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.192 2005/11/02 22:17:20 markus Exp $	*/
d1426 2
a1427 1
		if (th->th_seq != tp->last_ack_sent)
@


1.192
log
@inherit sack_enable from the listen socket, this should allow connections
with both sack and md5 options in SYN.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.191 2005/10/17 08:43:34 henning Exp $	*/
d1591 1
a1591 1
				 * threshhold of them, assume a packet
@


1.191
log
@make pf use one mbuf tag instead of 6 distinct ones. use a little struct
in the data part for the data from the previously distinct tags.
look up the tag early and carry a pointer to it around.
makes the code easier and saves some tag lookups and thus helps performance,
as proven by tests run by Schberle Dniel <Schoeberle.Daniel@@aamtech.hu>
Initially hacked up somewhere over the atlantic ocean in an A330
early testing reyk and moritz, "put it in" theo
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.190 2005/08/11 11:39:36 markus Exp $	*/
d3979 1
a3979 1
		tb.sack_enable = tcp_do_sack;
@


1.190
log
@don't accept SYN-only TCP options for established connections;
cf FreeBSD-SA-05:15.tcp; ok claudio, mcbride
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.189 2005/08/02 11:05:44 markus Exp $	*/
d607 8
d620 1
a620 2
			    &ip6->ip6_dst, th->th_dport, m_tag_find(m,
			    PACKET_TAG_PF_TRANSLATE_LOCALHOST, NULL) != NULL);
d625 1
a625 2
			    ip->ip_dst, th->th_dport, m_tag_find(m,
			    PACKET_TAG_PF_TRANSLATE_LOCALHOST, NULL) != NULL);
@


1.189
log
@change the TCP reass queue from LIST to TAILQ;
ok henning claudio fgsch krw
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.188 2005/06/30 08:51:31 markus Exp $	*/
d2260 2
d2272 2
d2287 4
d2295 3
a2297 5
			if (th->th_flags & TH_SYN) {
				tp->t_flags |= TF_RCVD_TSTMP;
				tp->ts_recent = oi->ts_val;
				tp->ts_recent_age = tcp_now;
			}
d2304 6
a2309 3
			if (th->th_flags & TH_SYN)
				/* MUST only be set on SYN */
				tp->t_flags |= TF_SACK_PERMIT;
a3976 1
		tb.t_state = TCPS_LISTEN;
d3980 1
@


1.188
log
@implement PMTU checks from
        http://www.gont.com.ar/drafts/icmp-attacks-against-tcp.html
i.e. don't act on ICMP-need-frag immediately if adhoc checks on the
advertised mtu fail.  the mtu update is delayed until a tcp retransmit
happens.  initial patch by Fernando Gont, tested by many.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.187 2005/04/25 17:55:52 brad Exp $	*/
d194 1
a194 1
	struct ipqent *p, *q, *nq, *tiqe;
d211 1
a211 1
		tiqe = LIST_FIRST(&tp->segq);
d214 2
a215 4
			while ((p = LIST_NEXT(tiqe, ipqe_q)) != NULL)
				tiqe = p;
			m_freem(tiqe->ipqe_m);
			LIST_REMOVE(tiqe, ipqe_q);
d229 3
a231 3
	for (p = NULL, q = tp->segq.lh_first; q != NULL;
	    p = q, q = q->ipqe_q.le_next)
		if (SEQ_GT(q->ipqe_tcp->th_seq, th->th_seq))
d240 1
a240 1
		struct tcphdr *phdr = p->ipqe_tcp;
d266 1
a266 1
		struct tcphdr *qhdr = q->ipqe_tcp;
d274 1
a274 1
			m_adj(q->ipqe_m, i);
d277 3
a279 3
		nq = q->ipqe_q.le_next;
		m_freem(q->ipqe_m);
		LIST_REMOVE(q, ipqe_q);
d284 1
a284 1
	tiqe->ipqe_m = m;
d286 1
a286 1
	tiqe->ipqe_tcp = th;
d288 1
a288 1
		LIST_INSERT_HEAD(&tp->segq, tiqe, ipqe_q);
d290 1
a290 1
		LIST_INSERT_AFTER(p, tiqe, ipqe_q);
d300 2
a301 2
	q = tp->segq.lh_first;
	if (q == NULL || q->ipqe_tcp->th_seq != tp->rcv_nxt)
d303 1
a303 1
	if (tp->t_state == TCPS_SYN_RECEIVED && q->ipqe_tcp->th_reseqlen)
d306 2
a307 2
		tp->rcv_nxt += q->ipqe_tcp->th_reseqlen;
		flags = q->ipqe_tcp->th_flags & TH_FIN;
d309 2
a310 2
		nq = q->ipqe_q.le_next;
		LIST_REMOVE(q, ipqe_q);
d313 1
a313 1
			m_freem(q->ipqe_m);
d315 1
a315 1
			sbappendstream(&so->so_rcv, q->ipqe_m);
d318 1
a318 1
	} while (q != NULL && q->ipqe_tcp->th_seq == tp->rcv_nxt);
d1068 1
a1068 1
		    tp->segq.lh_first == NULL &&
d2021 1
a2021 1
		if (th->th_seq == tp->rcv_nxt && tp->segq.lh_first == NULL &&
@


1.187
log
@csum -> csum_flags

ok krw@@ canacar@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.186 2005/04/05 20:27:35 markus Exp $	*/
d1013 18
d1832 17
d3083 3
d3104 30
@


1.186
log
@add tcp sack stats, similar to freebsd; ok deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.185 2005/03/12 08:07:09 markus Exp $	*/
d487 2
a488 2
		if ((m->m_pkthdr.csum & M_TCP_CSUM_IN_OK) == 0) {
			if (m->m_pkthdr.csum & M_TCP_CSUM_IN_BAD) {
d498 1
a498 1
			m->m_pkthdr.csum &= ~M_TCP_CSUM_IN_OK;
@


1.185
log
@make sure code and comment match
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.184 2005/03/09 11:14:37 markus Exp $	*/
d1632 1
a1632 1
						tcpstat.tcps_sndrexmitfast++;
d2489 1
@


1.184
log
@from freebsd:
1. set rcv_laststart/rcv_lastend after checking the tcp window
2. pass rcv_laststart and rcv_lastend on the stack (shrink tcp state)
ok henning, djm
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.183 2005/03/04 13:21:42 markus Exp $	*/
d1380 2
a1381 2
	 * record its timestamp.
	 * Fix from Braden, see Stevens p. 870
d1385 5
a1390 1
		tp->ts_recent = opti.ts_val;
@


1.183
log
@- check th_ack against snd_una/max; from Raja Mukerji via hugh@@
- limit pool to tcp_sackhole_limit entries (sysctl-able)
- stop sack option processing on pool_get errors
- use SEQ_MIN/SEQ_MAX
ok henning, hshoexer, deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.182 2005/02/27 13:22:56 markus Exp $	*/
a950 6
#ifdef TCP_SACK
	if (tp->sack_enable) {
		tp->rcv_laststart = th->th_seq; /* last rec'vd segment*/
		tp->rcv_lastend = th->th_seq + tlen;
	}
#endif /* TCP_SACK */
d2008 1
a2008 1
			tcp_update_sack_list(tp);
d2369 2
a2370 2
tcp_update_sack_list(tp)
	struct tcpcb *tp;
d2399 1
a2399 1
		if (SEQ_LT(tp->rcv_nxt, tp->rcv_laststart)) {
d2401 2
a2402 2
			tp->sackblks[0].start = tp->rcv_laststart;
			tp->sackblks[0].end = tp->rcv_lastend;
d2410 1
a2410 1
	if (SEQ_GEQ(tp->rcv_nxt, tp->rcv_lastend))
d2416 2
a2417 2
	firstsack.start = tp->rcv_laststart;
	firstsack.end = tp->rcv_lastend;
@


1.182
log
@1. tcp_xmit_timer(): remove extra rtt decrement (t_rtttime is 0-based
   while t_rtt was 1-based), update callers
2. define and use TCP_RTT_BASE_SHIFT instead of the hardcoded 2.
3. add missing shifts when t_srtt/t_rttvar are used.
4. update the comments: t_srtt uses 5 bits of fraction (not 3)
   and t_rttvar uses 4 bits
5. remove obsolete/unused macros TCP_RTT_SCALE and TCP_RTTVAR_SCALE
6. make sure rttmin is not > TCPTV_REXMTMAX
parts from netbsd, ok mcbride, henning
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.181 2005/01/10 23:53:49 mcbride Exp $	*/
d130 4
d2272 1
a2272 2
			if (tcp_sack_option(tp, th, cp, optlen))
				continue;
d2466 1
a2466 2
 * Process the TCP SACK option.  Returns 1 if tcp_dooptions() should continue,
 * and 0 otherwise, if the option was fine.  tp->snd_holes is an ordered list
d2469 1
a2469 1
int
d2477 8
a2484 2
		return (1);

d2487 2
a2488 1
		return (1);
d2525 1
a2525 1
				continue;
d2589 1
a2589 1
				cur->rxmit = max (cur->rxmit, cur->start);
d2603 1
a2603 1
				cur->rxmit = min(cur->rxmit, cur->end);
d2621 1
a2621 1
					continue; /* ENOBUFS */
d2636 1
a2636 1
				temp->rxmit = max(cur->rxmit, temp->start);
d2638 1
a2638 1
				cur->rxmit = min(cur->rxmit, cur->end);
d2658 1
a2658 1
				continue; /* ENOBUFS */
d2672 1
d2688 1
a2688 1
	return (0);
@


1.181
log
@Make sure bogus values don't make their way into tcp_xmit_timer() calculations.
- Ignore ts_ecr if it is 0, or the resulting rtt is out of range.
  (use tp->t_rtttime instead)
- Initialise tcp_now to 1, to avoid the 500ms window where a valid ts_ecr
  of 0 could be ignored.
- Convert out-of-range rtt values to valid ones in tcp_xmit_timer().

ok frantzen@@ markus@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.180 2004/12/30 01:30:30 deraadt Exp $	*/
d943 1
a943 1
		if (rtt_test < 0 || rtt_test > (TCP_RTT_MAX - 1))
d1005 1
a1005 1
					tcp_xmit_timer(tp, tcp_now-opti.ts_ecr+1);
d1767 1
a1767 1
			tcp_xmit_timer(tp, tcp_now-opti.ts_ecr+1);
a2806 1
	--rtt;
d2809 1
a2809 1
	if (rtt > TCP_RTT_MAX)
d2815 4
a2818 2
		 * srtt is stored as fixed point with 3 bits after the
		 * binary point (i.e., scaled by 8).  The following magic
d2821 1
a2821 1
		 * point).  Adjust rtt to origin 0.
d2823 2
a2824 1
		delta = (rtt << 2) - (tp->t_srtt >> TCP_RTT_SHIFT);
d2826 1
a2826 1
			tp->t_srtt = 1;
d2831 2
a2832 2
		 * rttvar is stored as fixed point with 2 bits after the
		 * binary point (scaled by 4).  The following is
d2841 1
a2841 1
			tp->t_rttvar = 1;
d2848 3
a2850 2
		tp->t_srtt = rtt << (TCP_RTT_SHIFT + 2);
		tp->t_rttvar = rtt << (TCP_RTTVAR_SHIFT + 2 - 1);
d2866 1
a2866 4
	if (tp->t_rttmin > rtt + 2)
		rttmin = tp->t_rttmin;
	else
		rttmin = rtt + 2;
@


1.180
log
@handle rtt < 0; markus ok
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.179 2004/12/29 17:17:28 markus Exp $	*/
d935 4
a938 2
	/* subtract out the tcp timestamp modulator */
	if (opti.ts_present)
d940 6
d1004 1
a1004 1
				if (opti.ts_present)
d1766 1
a1766 1
		if (opti.ts_present)
d2807 1
d2809 3
a2811 1
		return;
a2813 1
	--rtt;
@


1.179
log
@fix indent
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.178 2004/11/25 15:32:08 markus Exp $	*/
d2798 3
@


1.178
log
@fix for race between invocation for timer and network input
1) add a reaper for TCP and SYN cache states (cf. netbsd pr 20390)
2) additional check for TCP_TIMER_ISARMED(TCPT_REXMT) in tcp_timer_persist()
with mickey@@; ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.177 2004/10/28 19:22:52 mcbride Exp $	*/
d999 1
a999 1
					    SEQ_GT(th->th_ack, tp->t_rtseq))
@


1.177
log
@Modulate tcp_now by a random amount on a per-connection basis.

ok markus@@ frantzen@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.176 2004/09/22 21:33:53 deraadt Exp $	*/
d3208 1
d3224 2
a3225 1
	pool_put(&syn_cache_pool, (sc));				\
d3371 4
d3405 12
@


1.176
log
@account for linkhdr size when choosing mbufs vs mbuf clusters
ok dhartmei markus claudio henning mcbride ...
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.175 2004/07/16 09:26:07 markus Exp $	*/
d935 4
d3242 1
a3242 1
#define	SYN_CACHE_TIMESTAMP(sc)	tcp_now
d3666 1
d4122 1
@


1.175
log
@undo 1.148, otherwise we have assymmetric cwnd when entering ESTABLISHED:
2mss on the server side, and 1mss on the client.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.174 2004/06/20 18:16:50 itojun Exp $	*/
d4036 1
a4036 1
	if (m && tlen > MHLEN) {
@


1.175.2.1
log
@MFC:
Fix by mcbride@@

Make sure bogus values don't make their way into tcp_xmit_timer() calculations.
- Convert out-of-range rtt values to valid ones in tcp_xmit_timer().

ok frantzen@@ markus@@ deraadt@@ mcbride@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.175 2004/07/16 09:26:07 markus Exp $	*/
d2795 1
a2796 6
	if (rtt < 0)
		rtt = 0;
	if (rtt > TCP_RTT_MAX)
		rtt = TCP_RTT_MAX;

	tcpstat.tcps_rttupdated++;
@


1.175.2.2
log
@MFC:
Fix by markus@@

- check th_ack against snd_una/max; from Raja Mukerji via hugh@@
- limit pool to tcp_sackhole_limit entries (sysctl-able)
- stop sack option processing on pool_get errors
- use SEQ_MIN/SEQ_MAX

ok deraadt@@ markus@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.175.2.1 2005/01/11 04:36:23 brad Exp $	*/
a129 4
/* for TCP SACK comparisons */
#define	SEQ_MIN(a,b)	(SEQ_LT(a,b) ? (a) : (b))
#define	SEQ_MAX(a,b)	(SEQ_GT(a,b) ? (a) : (b))

d2256 2
a2257 1
			tcp_sack_option(tp, th, cp, optlen);
d2451 2
a2452 1
 * Process the TCP SACK option.  tp->snd_holes is an ordered list
d2455 1
a2455 1
void
d2463 2
a2464 8
		return;
	/* SACK without ACK doesn't make sense. */
	if ((th->th_flags & TH_ACK) == 0)
	       return;
	/* Make sure the ACK on this segment is in [snd_una, snd_max]. */
	if (SEQ_LT(th->th_ack, tp->snd_una) ||
	    SEQ_GT(th->th_ack, tp->snd_max))
		return;
d2467 1
a2467 2
		return;
	/* Note: TCPOLEN_SACK must be 2*sizeof(tcp_seq) */
d2504 1
a2504 1
				goto done;
d2568 1
a2568 1
				cur->rxmit = SEQ_MAX(cur->rxmit, cur->start);
d2582 1
a2582 1
				cur->rxmit = SEQ_MIN(cur->rxmit, cur->end);
d2600 1
a2600 1
					goto done; /* ENOBUFS */
d2615 1
a2615 1
				temp->rxmit = SEQ_MAX(cur->rxmit, temp->start);
d2617 1
a2617 1
				cur->rxmit = SEQ_MIN(cur->rxmit, cur->end);
d2637 1
a2637 1
				goto done; /* ENOBUFS */
a2650 1
done:
d2666 1
a2666 1
	return;
@


1.175.2.3
log
@MFC:
Fix by markus@@

make sure code and comment match

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.175.2.2 2005/03/20 23:36:10 brad Exp $	*/
d1374 2
a1375 2
	 * record its timestamp if it's more recent.
	 * Cf fix from Braden, see Stevens p. 870
a1378 5
		if (SEQ_LEQ(tp->last_ack_sent, th->th_seq + tlen +
		    ((tiflags & (TH_SYN|TH_FIN)) != 0)))
			tp->ts_recent = opti.ts_val;
		else
			tp->ts_recent = 0;
d1380 1
@


1.174
log
@remove #ifdef TUBA
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.173 2004/06/14 08:26:49 dhartmei Exp $	*/
d1206 9
@


1.173
log
@Calculate optp (pointer to beginning of TCP options) based on th, not
mtod(m), since the previous IP6_EXTHDR_GET() only guarantees this part
to be continuous. Report from Andreas Bartelt. ok markus@@, itojun@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.172 2004/06/08 19:47:24 markus Exp $	*/
a70 1
#ifndef TUBA_INCLUDE
a123 1
#endif /* TUBA_INCLUDE */
a182 2
#ifndef TUBA_INCLUDE

a540 1
#endif /* TUBA_INCLUDE */
a2161 1
#ifndef TUBA_INCLUDE
a3080 1
#endif /* TUBA_INCLUDE */
@


1.172
log
@factor out md5 code; ok+tests henning@@, djm@@, hshoexer@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.171 2004/05/31 11:02:11 markus Exp $	*/
d564 1
a564 1
		optp = mtod(m, u_int8_t *) + iphlen + sizeof(struct tcphdr);
@


1.171
log
@simplify; ok henning, itojun
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.170 2004/05/27 08:17:31 markus Exp $	*/
a111 4
#ifdef TCP_SIGNATURE
#include <crypto/md5.h>
#endif

d2187 1
a2187 4
#ifdef TCP_SIGNATURE
	if (cp)
#endif /* TCP_SIGNATURE */
	for (; cnt > 0; cnt -= optlen, cp += optlen) {
a2318 1
		MD5_CTX ctx;
d2326 2
a2327 71
		MD5Init(&ctx);

		switch(tp->pf) {
		case 0:
#ifdef INET
		case AF_INET:
			{
				struct ippseudo ippseudo;

				ippseudo.ippseudo_src =
				    mtod(m, struct ip *)->ip_src;
				ippseudo.ippseudo_dst =
				    mtod(m, struct ip *)->ip_dst;
				ippseudo.ippseudo_pad = 0;
				ippseudo.ippseudo_p = IPPROTO_TCP;
				ippseudo.ippseudo_len = htons(
				    m->m_pkthdr.len - iphlen);

				MD5Update(&ctx, (char *)&ippseudo,
				    sizeof(struct ippseudo));
			}
			break;
#endif /* INET */
#ifdef INET6
		case AF_INET6:
			{
				struct ip6_hdr_pseudo ip6pseudo;
 
				bzero(&ip6pseudo, sizeof(ip6pseudo));
				ip6pseudo.ip6ph_src =
				    mtod(m, struct ip6_hdr *)->ip6_src;
				ip6pseudo.ip6ph_dst =
				    mtod(m, struct ip6_hdr *)->ip6_dst;
				in6_clearscope(&ip6pseudo.ip6ph_src);
				in6_clearscope(&ip6pseudo.ip6ph_dst);
				ip6pseudo.ip6ph_nxt = IPPROTO_TCP;
				ip6pseudo.ip6ph_len = htonl(m->m_pkthdr.len -
				    iphlen);
    
				MD5Update(&ctx, (char *)&ip6pseudo,
				    sizeof(ip6pseudo));
			}
			break;
#endif /* INET6 */
		}

		{
			struct tcphdr tcphdr;

			tcphdr.th_sport = th->th_sport;
			tcphdr.th_dport = th->th_dport;
			tcphdr.th_seq = htonl(th->th_seq);
			tcphdr.th_ack = htonl(th->th_ack);
			tcphdr.th_off = th->th_off;
			tcphdr.th_x2 = th->th_x2;
			tcphdr.th_flags = th->th_flags;
			tcphdr.th_win = htons(th->th_win);
			tcphdr.th_sum = 0;
			tcphdr.th_urp = htons(th->th_urp);

			MD5Update(&ctx, (char *)&tcphdr,
			    sizeof(struct tcphdr));
		}

		if (m_apply(m, iphlen + th->th_off * sizeof(uint32_t),
		    m->m_pkthdr.len - (iphlen + th->th_off * sizeof(uint32_t)),
		    tcp_signature_apply, (caddr_t)&ctx))
			return (-1); 

		MD5Update(&ctx, tdb->tdb_amxkey, tdb->tdb_amxkeylen);
		MD5Final(sig, &ctx);
a4121 1
		MD5_CTX ctx;
a4154 45
		MD5Init(&ctx);

		switch (sc->sc_src.sa.sa_family) {
		case 0:	/*default to PF_INET*/
#ifdef INET
		case AF_INET:
			{
				struct ippseudo ippseudo;

				ippseudo.ippseudo_src = ip->ip_src;
				ippseudo.ippseudo_dst = ip->ip_dst;
				ippseudo.ippseudo_pad = 0;
				ippseudo.ippseudo_p   = IPPROTO_TCP;
				ippseudo.ippseudo_len = htons(tlen - hlen);

				MD5Update(&ctx, (char *)&ippseudo,
				    sizeof(struct ippseudo));

			}
			break;
#endif /* INET */
#ifdef INET6
		case AF_INET6:
			{
				struct ip6_hdr_pseudo ip6pseudo;

				bzero(&ip6pseudo, sizeof(ip6pseudo));
				ip6pseudo.ip6ph_src = ip6->ip6_src;
				ip6pseudo.ip6ph_dst = ip6->ip6_dst;
				in6_clearscope(&ip6pseudo.ip6ph_src);
				in6_clearscope(&ip6pseudo.ip6ph_dst);
				ip6pseudo.ip6ph_nxt = IPPROTO_TCP;
				ip6pseudo.ip6ph_len = htonl(tlen - hlen);

				MD5Update(&ctx, (char *)&ip6pseudo,
				    sizeof(ip6pseudo));
			}
			break;
#endif /* INET6 */
		}

		th->th_sum = 0;
		MD5Update(&ctx, (char *)th, sizeof(struct tcphdr));
		MD5Update(&ctx, tdb->tdb_amxkey, tdb->tdb_amxkeylen);

d4159 6
a4164 1
		MD5Final(optp, &ctx);
@


1.170
log
@the tcp header might be in a different mbuf after pulldown();
fixes tcp corruption on rl(4); ok itojun, cedric
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.169 2004/05/26 22:47:40 markus Exp $	*/
d378 1
a378 1
	int len, tlen, off;
d473 1
a483 3

		tlen = m->m_pkthdr.len - iphlen;

d497 1
a497 2
			len = m->m_pkthdr.len - iphlen;
			if (in4_cksum(m, IPPROTO_TCP, iphlen, len) != 0) {
a508 1
		tlen = m->m_pkthdr.len - iphlen;
@


1.169
log
@use sa_family not inp; netbsd merge error; ok dhartmei
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.168 2004/05/21 11:36:23 markus Exp $	*/
a553 2

	th = (struct tcphdr *)(mtod(m, caddr_t) + iphlen);
@


1.168
log
@use 'mss' as lower limit, since 'ifp' might not be set; ok dhartmei@@, henning@@
report and test by mpf@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.167 2004/05/07 14:42:27 millert Exp $	*/
d3683 1
a3683 1
	if (inp)
@


1.167
log
@Replace RSA-derived md5 code with code derived from Colin Plumb's PD version.
This moves md5.c out of libkern and into sys/crypto where it belongs (as
requested by markus@@).  Note that md5.c is still mandatory (dev/rnd.c uses it).
Verified with IPsec + hmac-md5 and tcp md5sig. OK henning@@ and hshoexer@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.166 2004/05/04 22:50:18 claudio Exp $	*/
d3071 3
a3073 2
	 * However, do not accept offers under 216 bytes unless the
	 * interface MTU is actually that low.
d3078 2
a3079 1
		mss = min(mss, tp->t_peermss);
d3081 1
a3081 1
	mss = max(mss, min(216, ifp->if_mtu - iphlen - sizeof(struct tcphdr)));
@


1.166
log
@The tcp specific routing metrics are almost never used so reduce the routing
table from these metrics. struct rt_msghdr used by the routing socket is not
affected and so most userland apps don't need to be changed.
some man page polishing by jmc@@
OK henning@@ markus@@ theo@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.165 2004/04/26 18:12:25 frantzen Exp $	*/
d113 1
a113 1
#include <sys/md5k.h>
@


1.165
log
@- allow the user to force the TCP mss below the fail-safe 216 with a low
interface MTU.
- break a tcp_output() -> tcp_mtudisc() -> tcp_output() infinite recursion
when the TCP mss ends up larger than the interface MTU (when the if_mtu is
smaller than the tcp header).  connections will still stall
feedback from itojun@@, claudio@@ and provos and testing from beck@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.164 2004/04/20 20:05:29 markus Exp $	*/
d3134 1
a3134 1
	int mss, rtt;
d3147 1
a3147 39
#ifdef RTV_MTU	/* if route characteristics exist ... */
	/*
	 * While we're here, check if there's an initial rtt
	 * or rttvar.  Convert from the route-table units
	 * to scaled multiples of the slow timeout timer.
	 */
	if (tp->t_srtt == 0 && (rtt = rt->rt_rmx.rmx_rtt)) {
		/*
		 * XXX the lock bit for MTU indicates that the value
		 * is also a minimum value; this is subject to time.
		 */
		if (rt->rt_rmx.rmx_locks & RTV_RTT)
			TCPT_RANGESET(tp->t_rttmin,
			    rtt / (RTM_RTTUNIT / PR_SLOWHZ),
			    TCPTV_MIN, TCPTV_REXMTMAX);
		tp->t_srtt = rtt / (RTM_RTTUNIT / (PR_SLOWHZ * TCP_RTT_SCALE));
		if (rt->rt_rmx.rmx_rttvar)
			tp->t_rttvar = rt->rt_rmx.rmx_rttvar /
			    (RTM_RTTUNIT / (PR_SLOWHZ * TCP_RTTVAR_SCALE));
		else
			/* default variation is +- 1 rtt */
			tp->t_rttvar =
			    tp->t_srtt * TCP_RTTVAR_SCALE / TCP_RTT_SCALE;
		TCPT_RANGESET((long) tp->t_rxtcur,
		    ((tp->t_srtt >> 2) + tp->t_rttvar) >> 1,
		    tp->t_rttmin, TCPTV_REXMTMAX);
	}
#endif

	/*
	 * If there's a pipesize, change the socket buffer
	 * to that size.  Make the socket buffers an integral
	 * number of mss units; if the mss is larger than
	 * the socket buffer, decrease the mss.
	 */
#ifdef RTV_SPIPE
	if ((bufsize = rt->rt_rmx.rmx_sendpipe) == 0)
#endif
		bufsize = so->so_snd.sb_hiwat;
d3159 1
a3159 4
#ifdef RTV_RPIPE
	if ((bufsize = rt->rt_rmx.rmx_recvpipe) == 0)
#endif
		bufsize = so->so_rcv.sb_hiwat;
a3164 4
#ifdef RTV_RPIPE
		if (rt->rt_rmx.rmx_recvpipe > 0)
			tcp_rscale(tp, so->so_rcv.sb_hiwat);
#endif
a3166 11
#ifdef RTV_SSTHRESH
	if (rt->rt_rmx.rmx_ssthresh) {
		/*
		 * There's some sort of gateway or interface
		 * buffer limit on the path.  Use this to set
		 * the slow start threshhold, but set the
		 * threshold to no less than 2*mss.
		 */
		tp->snd_ssthresh = max(2 * mss, rt->rt_rmx.rmx_ssthresh);
	}
#endif /* RTV_MTU */
@


1.164
log
@add tcps_rcvacktooold; ok deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.163 2004/04/15 12:05:34 grange Exp $	*/
d3071 2
a3072 1
	 * However, do not accept offers under 216 bytes.
d3078 2
a3079 1
	mss = max(mss, 216);		/* sanity - at least max opt. space */
@


1.163
log
@Unbreak INET6less kernels.
ok markus
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.162 2004/04/15 02:59:22 itojun Exp $	*/
d1538 1
a1538 1
					/* XXX stat */
@


1.162
log
@allow TCP packet with IPv4 option (we have been dropping these).
simplify some of the codepath by using IP6_EXTHDR_GET.  markus ok
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.161 2004/04/14 20:46:50 markus Exp $	*/
d98 2
a103 1
struct	tcpiphdr tcp_saveti;
@


1.161
log
@syn_cache_get: send RST instead of RST+ACK in response to ACK; ok deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.160 2004/04/12 14:17:55 markus Exp $	*/
a115 1
struct	tcpiphdr tcp_saveti;
a449 9
		if (iphlen > sizeof(struct ip)) {
#if 0	/*XXX*/
			ip_stripoptions(m, (struct mbuf *)0);
			iphlen = sizeof(struct ip);
#else
			m_freem(m);
			return;
#endif
		}
d466 4
a469 6
	if (m->m_len < iphlen + sizeof(struct tcphdr)) {
		m = m_pullup2(m, iphlen + sizeof(struct tcphdr));
		if (m == NULL) {
			tcpstat.tcps_rcvshort++;
			return;
		}
a477 3
	    {
		struct tcpiphdr *ti;

a483 1
		ti = mtod(m, struct tcpiphdr *);
a491 4
		len = sizeof(struct ip) + tlen;
		bzero(ti->ti_x1, sizeof ti->ti_x1);
		ti->ti_len = (u_int16_t)tlen;
		HTONS(ti->ti_len);
d498 2
a499 1
			if ((ti->ti_sum = in_cksum(m, len)) != 0) {
a507 1
	    }
d567 4
a570 16
		if (m->m_len < iphlen + off) {
			if ((m = m_pullup2(m, iphlen + off)) == NULL) {
				tcpstat.tcps_rcvshort++;
				return;
			}
			switch (af) {
			case AF_INET:
				ip = mtod(m, struct ip *);
				break;
#ifdef INET6
			case AF_INET6:
				ip6 = mtod(m, struct ip6_hdr *);
				break;
#endif
			}
			th = (struct tcphdr *)(mtod(m, caddr_t) + iphlen);
d701 2
a702 1
				tcp_saveti6 = *(mtod(m, struct tcpipv6hdr *));
d706 2
a707 1
				tcp_saveti = *(mtod(m, struct tcpiphdr *));
@


1.160
log
@factor out dropafterack_ratelim code, use ratelimit
for tcps_rcvacktoomuch, too; drop very old ACKs; ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.159 2004/04/04 17:39:07 deraadt Exp $	*/
d3880 1
a3880 2
	(void) tcp_respond(NULL, mtod(m, caddr_t), m,
			   th->th_seq + tlen, (tcp_seq)0, TH_RST|TH_ACK);
@


1.159
log
@on in-window SYN, send back rate-limited ACK; ok dhartmei frantzen markus
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.158 2004/03/17 11:42:29 markus Exp $	*/
d125 3
a127 3
int tcp_synack_ppslim = 100;		/* 100pps */
int tcp_synack_ppslim_count = 0;
struct timeval tcp_synack_ppslim_last;
d1458 1
a1458 1
	 * error and we send an RST and drop the connection.
d1460 2
a1461 8
	if (tiflags & TH_SYN) {
		if (ppsratecheck(&tcp_synack_ppslim_last, &tcp_synack_ppslim_count,
		    tcp_synack_ppslim) == 0) {
			/* XXX stat */
			goto drop;
		}
		goto dropafterack;
	}
d1562 8
a1569 1
			if (tlen)
d1571 1
d1774 1
a1774 1
			goto dropafterack;
d2131 8
@


1.158
log
@typo in comment (fragment->segment); ok itojun@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.157 2004/03/02 12:51:12 markus Exp $	*/
d125 4
d1461 6
a1466 2
		tp = tcp_drop(tp, ECONNRESET);
		goto dropwithreset;
@


1.158.2.1
log
@MFC:
Fix by deraadt@@

on in-window SYN, send back rate-limited ACK

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.158 2004/03/17 11:42:29 markus Exp $	*/
a124 4
int tcp_synack_ppslim = 100;		/* 100pps */
int tcp_synack_ppslim_count = 0;
struct timeval tcp_synack_ppslim_last;

d1457 2
a1458 6
		if (ppsratecheck(&tcp_synack_ppslim_last, &tcp_synack_ppslim_count,
		    tcp_synack_ppslim) == 0) {
			/* XXX stat */
			goto drop;
		}
		goto dropafterack;
@


1.158.2.2
log
@MFC:
Fix by markus@@

factor out dropafterack_ratelim code, use ratelimit
for tcps_rcvacktoomuch, too; drop very old ACKs

ok deraadt@@ markus@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.158.2.1 2004/05/06 00:45:37 brad Exp $	*/
d125 3
a127 3
int tcp_ackdrop_ppslim = 100;		/* 100pps */
int tcp_ackdrop_ppslim_count = 0;
struct timeval tcp_ackdrop_ppslim_last;
d1458 1
a1458 1
	 * error and we ACK and drop the packet.
d1460 8
a1467 2
	if (tiflags & TH_SYN)
		goto dropafterack_ratelim;
d1568 1
a1568 8
			if (tlen) {
				/* Drop very old ACKs unless th_seq matches */
				if (th->th_seq != tp->rcv_nxt &&
				   SEQ_LT(th->th_ack,
				   tp->snd_una - tp->max_sndwnd)) {
					/* XXX stat */
					goto drop;
				}
a1569 1
			}
d1772 1
a1772 1
			goto dropafterack_ratelim;
a2128 8

dropafterack_ratelim:
	if (ppsratecheck(&tcp_ackdrop_ppslim_last, &tcp_ackdrop_ppslim_count,
	    tcp_ackdrop_ppslim) == 0) {
		/* XXX stat */
		goto drop;
	}
	/* ...fall into dropafterack... */
@


1.158.2.3
log
@MFC:
Fix by mcbride@@

Make sure bogus values don't make their way into tcp_xmit_timer() calculations.
- Convert out-of-range rtt values to valid ones in tcp_xmit_timer().

ok frantzen@@ markus@@ deraadt@@ mcbride@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.158.2.2 2004/05/26 20:02:06 brad Exp $	*/
d2904 1
a2905 6
	if (rtt < 0)
		rtt = 0;
	if (rtt > TCP_RTT_MAX)
		rtt = TCP_RTT_MAX;

	tcpstat.tcps_rttupdated++;
@


1.158.2.4
log
@MFC:
Fix by markus@@

- check th_ack against snd_una/max; from Raja Mukerji via hugh@@
- limit pool to tcp_sackhole_limit entries (sysctl-able)
- stop sack option processing on pool_get errors
- use SEQ_MIN/SEQ_MAX

ok deraadt@@ markus@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.158.2.3 2005/01/11 04:40:29 brad Exp $	*/
a135 4
/* for TCP SACK comparisons */
#define	SEQ_MIN(a,b)	(SEQ_LT(a,b) ? (a) : (b))
#define	SEQ_MAX(a,b)	(SEQ_GT(a,b) ? (a) : (b))

d2295 2
a2296 1
			tcp_sack_option(tp, th, cp, optlen);
d2560 2
a2561 1
 * Process the TCP SACK option.  tp->snd_holes is an ordered list
d2564 1
a2564 1
void
d2572 2
a2573 8
		return;
	/* SACK without ACK doesn't make sense. */
	if ((th->th_flags & TH_ACK) == 0)
	       return;
	/* Make sure the ACK on this segment is in [snd_una, snd_max]. */
	if (SEQ_LT(th->th_ack, tp->snd_una) ||
	    SEQ_GT(th->th_ack, tp->snd_max))
		return;
d2576 1
a2576 2
		return;
	/* Note: TCPOLEN_SACK must be 2*sizeof(tcp_seq) */
d2613 1
a2613 1
				goto done;
d2677 1
a2677 1
				cur->rxmit = SEQ_MAX(cur->rxmit, cur->start);
d2691 1
a2691 1
				cur->rxmit = SEQ_MIN(cur->rxmit, cur->end);
d2709 1
a2709 1
					goto done; /* ENOBUFS */
d2724 1
a2724 1
				temp->rxmit = SEQ_MAX(cur->rxmit, temp->start);
d2726 1
a2726 1
				cur->rxmit = SEQ_MIN(cur->rxmit, cur->end);
d2746 1
a2746 1
				goto done; /* ENOBUFS */
a2759 1
done:
d2775 1
a2775 1
	return;
@


1.158.2.5
log
@MFC:
Fix by markus@@

make sure code and comment match

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.158.2.4 2005/03/20 23:44:05 brad Exp $	*/
d1409 2
a1410 2
	 * record its timestamp if it's more recent.
	 * Cf fix from Braden, see Stevens p. 870
a1413 5
		if (SEQ_LEQ(tp->last_ack_sent, th->th_seq + tlen +
		    ((tiflags & (TH_SYN|TH_FIN)) != 0)))
			tp->ts_recent = opti.ts_val;
		else
			tp->ts_recent = 0;
d1415 1
@


1.157
log
@limit total number of queued out-of-order packets to NMBCLUSTERS/2; ok mcbride
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.156 2004/02/27 16:44:44 markus Exp $	*/
d220 1
a220 1
			/* Flush fragments for this connection */
d285 1
a285 1
	/* Insert the new fragment queue entry into place. */
@


1.156
log
@implement tcp_drain() similar to ip_drain(); ok mcbride@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.155 2004/02/11 20:12:33 markus Exp $	*/
d209 1
a209 1
	tiqe =  pool_get(&ipqent_pool, PR_NOWAIT);
d211 15
a225 3
		tcpstat.tcps_rcvmemdrop++;
		m_freem(m);
		return (0);
d252 1
a252 1
				pool_put(&ipqent_pool, tiqe);
d282 1
a282 1
		pool_put(&ipqent_pool, q);
d318 1
a318 1
		pool_put(&ipqent_pool, q);
@


1.155
log
@make mss signed; avoids large mss if ifp==NULL; ok itojun@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.154 2004/02/10 10:30:24 markus Exp $	*/
d1224 1
d1227 1
d1480 1
d1483 1
d1986 1
d1989 1
d2006 1
@


1.154
log
@check TF_SIGNATURE when calculating the mss; add TCPOLEN_SIGLEN and
avoid magic constants; ok henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.153 2004/02/05 04:23:13 itojun Exp $	*/
d3263 1
a3263 1
	u_int16_t mss = 0;
@


1.153
log
@take RFC2460 section 5 last paragraph into consideration when we compute MSS
(if path MTU < 1280, use 1280 as packet size and attach fragment header).
markus ok
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.152 2004/01/31 19:40:09 markus Exp $	*/
d3083 4
d4146 1
a4146 1
	    ((sc->sc_flags & SCF_SIGNATURE) ? TCPOLEN_SIGNATURE + 2 : 0) +
@


1.152
log
@!sack_disable -> sack_enable; ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.151 2004/01/29 17:02:56 markus Exp $	*/
d3004 10
a3013 1
		mss = rt->rt_rmx.rmx_mtu - iphlen - sizeof(struct tcphdr);
d3046 1
a3046 3
		if (tp->pf == AF_INET)
			mssopt = ifp->if_mtu - iphlen - sizeof(struct tcphdr);
		else
d3049 2
@


1.151
log
@reset TCPT_KEEP to tcp_keepidle when switching to ESTABLISHED;
ok henning, deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.150 2004/01/29 13:30:18 markus Exp $	*/
d948 1
a948 1
	if (!tp->sack_disable)
d964 1
a964 1
	if (!tp->sack_disable) {
d1079 1
a1079 1
			if (!tp->sack_disable && tp->rcv_numsacks)
d1192 2
a1193 3
                if (!tp->sack_disable)
                        if ((tp->t_flags & TF_SACK_PERMIT) == 0)
                                tp->sack_disable = 1;
d1618 1
a1618 1
                    			if (!tp->sack_disable) {
d1672 1
a1672 1
					if (!tp->sack_disable) {
d1698 1
a1698 1
		if (!tp->sack_disable) {
d2003 1
a2003 1
		if (!tp->sack_disable)
d2251 1
a2251 1
			if (tp->sack_disable || optlen!=TCPOLEN_SACK_PERMITTED)
d2534 1
a2534 1
	if (tp->sack_disable)
d2751 1
a2751 1
	if (!tp->sack_disable && tp->t_state != TCPS_LISTEN) {
d3771 1
a3771 1
	tp->sack_disable = (sc->sc_flags & SCF_SACK_PERMIT) ? 0 : 1;
d3966 1
a3966 1
		tb.sack_disable = tcp_do_sack ? 0 : 1;
d4074 1
a4074 1
	if (!tb.sack_disable && (tb.t_flags & TF_SACK_PERMIT))
@


1.150
log
@turn off TF_SIGNATURE on the listen socket if there is no matching SA.
allows using a single listen socket for both tcpmd5 and plain tcp.
ok aaron, henning.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.149 2004/01/29 11:55:28 markus Exp $	*/
d944 1
a944 1
	if (tp->t_state != TCPS_SYN_RECEIVED)
d1218 1
d1472 1
@


1.149
log
@support for RFC3390 (Increasing TCP's Initial Window); ok deraadt, itojun
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.148 2004/01/29 10:06:21 markus Exp $	*/
d2185 1
d2276 1
a2276 7
	if ((sigp ? TF_SIGNATURE : 0) ^ (tp->t_flags & TF_SIGNATURE)) {
		tcpstat.tcps_rcvbadsig++;
		return (-1);
	}

	if (sigp) {
		MD5_CTX ctx;
a2277 2
		struct tdb *tdb;
		char sig[16];
d2307 19
d3969 1
@


1.148
log
@don't increase the cwnd on syn-ack; ok itojun@@, deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.147 2004/01/22 14:38:28 markus Exp $	*/
d1181 3
d3073 3
d3795 3
a3797 8
#if 0
	/*
	 * XXX
	 * Initialize the initial congestion window.  If we
	 * had to retransmit the SYN,ACK, we must initialize cwnd
	 * to 1 segment (i.e. the Loss Window).
	 */
#endif
@


1.147
log
@add gettdbbysrcdst(), just like gettdb(), but compares tdb_src as well; ok mcbride@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.146 2004/01/15 17:04:59 markus Exp $	*/
a1228 9
			/*
			 * Since new data was acked (the SYN), open the
			 * congestion window by one MSS.  We do this
			 * here, because we won't go through the normal
			 * ACK processing below.  And since this is the
			 * start of the connection, we know we are in
			 * the exponential phase of slow-start.
			 */
			tp->snd_cwnd += tp->t_maxseg;
@


1.146
log
@es tanzt das KNF
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.145 2004/01/15 09:46:21 markus Exp $	*/
d2288 1
a2288 1
		union sockaddr_union sa;
d2292 2
a2293 1
		memset(&sa, 0, sizeof(union sockaddr_union));
d2299 6
a2304 3
			sa.sa.sa_len = sizeof(struct sockaddr_in);
			sa.sa.sa_family = AF_INET;
			sa.sin.sin_addr = mtod(m, struct ip *)->ip_dst;
d2309 6
a2314 3
			sa.sa.sa_len = sizeof(struct sockaddr_in6);
			sa.sa.sa_family = AF_INET6;
			sa.sin6.sin6_addr = mtod(m, struct ip6_hdr *)->ip6_dst;
d2319 1
a2319 1
		tdb = gettdb(0, &sa, IPPROTO_TCP);
a2320 1
			printf("tdb miss\n");
d2322 1
a2322 1
			return -1;
d4232 1
a4232 1
		union sockaddr_union sa;
d4235 6
a4240 3
		bzero(&sa, sizeof(union sockaddr_union));
		sa.sa.sa_len = sc->sc_dst.sa.sa_len;
		sa.sa.sa_family = sc->sc_dst.sa.sa_family;
d4246 2
a4247 1
			sa.sin.sin_addr = mtod(m, struct ip *)->ip_dst;
d4252 2
a4253 1
			sa.sin6.sin6_addr = mtod(m, struct ip6_hdr *)->ip6_dst;
d4258 1
a4258 1
		tdb = gettdb(0, &sa, IPPROTO_TCP);
@


1.145
log
@move call to tcp_mss_update() from syn_cache_add() to syn_cache_get(),
when the 3-way handshake completes (and not on the listen pcb).
ok itojun, dhartmei
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.144 2004/01/14 13:38:21 markus Exp $	*/
d2272 1
a2272 1
				return -1;
d2283 1
a2283 1
		return -1;
d2295 1
a2295 1
			case 0:
d2297 5
a2301 5
			case AF_INET:
				sa.sa.sa_len = sizeof(struct sockaddr_in);
				sa.sa.sa_family = AF_INET;
				sa.sin.sin_addr = mtod(m, struct ip *)->ip_dst;
				break;
d2304 5
a2308 5
			case AF_INET6:
				sa.sa.sa_len = sizeof(struct sockaddr_in6);
				sa.sa.sa_family = AF_INET6;
				sa.sin6.sin6_addr = mtod(m, struct ip6_hdr *)->ip6_dst;
				break;
d2322 1
a2322 1
			case 0:
d2324 3
a2326 3
			case AF_INET:
				{
					struct ippseudo ippseudo;
d2328 8
a2335 8
					ippseudo.ippseudo_src =
					    mtod(m, struct ip *)->ip_src;
					ippseudo.ippseudo_dst =
					    mtod(m, struct ip *)->ip_dst;
					ippseudo.ippseudo_pad = 0;
					ippseudo.ippseudo_p = IPPROTO_TCP;
					ippseudo.ippseudo_len = htons(
						m->m_pkthdr.len - iphlen);
d2337 4
a2340 4
					MD5Update(&ctx, (char *)&ippseudo,
						sizeof(struct ippseudo));
				}
				break;
d2343 19
a2361 19
			case AF_INET6:
				{
					struct ip6_hdr_pseudo ip6pseudo;
	 
					bzero(&ip6pseudo, sizeof(ip6pseudo));
					ip6pseudo.ip6ph_src =
					    mtod(m, struct ip6_hdr *)->ip6_src;
					ip6pseudo.ip6ph_dst =
					    mtod(m, struct ip6_hdr *)->ip6_dst;
					in6_clearscope(&ip6pseudo.ip6ph_src);
					in6_clearscope(&ip6pseudo.ip6ph_dst);
					ip6pseudo.ip6ph_nxt = IPPROTO_TCP;
					ip6pseudo.ip6ph_len = htonl(m->m_pkthdr.len -
					    iphlen);
	    
					MD5Update(&ctx, (char *)&ip6pseudo,
					    sizeof(ip6pseudo));
				}
				break;
d2380 1
a2380 1
				sizeof(struct tcphdr));
d2384 2
a2385 3
				m->m_pkthdr.len - (iphlen + th->th_off *
				sizeof(uint32_t)), tcp_signature_apply,
				(caddr_t)&ctx))
@


1.144
log
@syncache+ipv6 support for TCP_SIGNATURE; with itojun; ok deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.143 2004/01/13 13:26:14 markus Exp $	*/
d3790 3
a3792 2
	tcp_mss(tp, sc->sc_peermaxseg);

a3953 1
		tb.t_inpcb = tp->t_inpcb; /* XXX */
a3962 1

a3964 7

		if (optp) {
			/* Update t_maxopd and t_maxseg after all options are processed */
			(void) tcp_mss(tp, oi->maxseg);	/* sets t_maxseg */
			if (oi->maxseg)
				tcp_mss_update(tp);
		}
@


1.143
log
@bring back the old TCP_SIGNATURE code from tcp_input.c rev 1.45
and make it compile (does not work yet); ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.142 2004/01/13 09:22:52 markus Exp $	*/
d2193 3
d2296 1
d2300 1
a2300 1
				sa.sin.sin_addr = tp->t_inpcb->inp_laddr;
d2302 1
d2307 1
a2307 1
				sa.sin6.sin6_addr = tp->t_inpcb->inp_laddr6;
d2329 1
a2329 1
						tp->t_inpcb->inp_faddr;
d2331 1
a2331 1
						tp->t_inpcb->inp_laddr;
d2345 15
a2359 8
					static int printed = 0;

					if (!printed) {
						printf("error: TCP MD5 support"
							" for IPv6 not yet"
							" implemented.\n");
						printed = 1;
					}
d3780 4
d3948 28
a3988 18
	if (optp) {
		tb.t_inpcb = tp->t_inpcb; /* XXX */
		tb.pf = tp->pf;
#ifdef TCP_SACK
		tb.sack_disable = tcp_do_sack ? 0 : 1;
#endif
		tb.t_flags = tcp_do_rfc1323 ? (TF_REQ_SCALE|TF_REQ_TSTMP) : 0;
		if (tcp_dooptions(&tb, optp, optlen, th, m, iphlen, oi))
			return (0);

		/* Update t_maxopd and t_maxseg after all options are processed */
		(void) tcp_mss(tp, oi->maxseg);	/* sets t_maxseg */
		if (oi->maxseg)
			tcp_mss_update(tp);

	} else
		tb.t_flags = 0;

d4074 4
d4129 3
d4233 89
a4321 2
	/* XXX */
#endif
@


1.142
log
@pass pcb and not socket to ip_output; #ifdef SACK; ok itojun@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.141 2004/01/09 12:31:44 markus Exp $	*/
d111 4
d867 1
a867 1
				    syn_cache_add(&src.sa, &dst.sa, th, tlen,
d955 3
d959 3
a961 1
		tcp_dooptions(tp, optp, optlen, th, &opti);
d2177 2
a2178 2
void
tcp_dooptions(tp, cp, cnt, th, oi)
d2183 2
d2189 3
d2263 11
d2276 114
d3900 1
a3900 1
syn_cache_add(src, dst, th, hlen, so, m, optp, optlen, oi)
d3904 1
a3904 1
	unsigned int hlen;
d3952 2
a3953 1
		tcp_dooptions(&tb, optp, optlen, th, oi);
@


1.141
log
@decrease min mss to (256 - 40); ok deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.140 2004/01/07 20:48:10 markus Exp $	*/
a3932 1
	struct tcpcb *tp;
d3935 1
a3935 1
	struct socket *so;
d3956 1
d3958 1
a3985 5
	if (sc->sc_tp) {
		tp = sc->sc_tp;
		so = tp->t_inpcb->inp_socket;
	} else
		so = NULL;
d4102 2
a4103 4
#if 0
	/* XXX use IPsec policy on listening socket, on SYN ACK */
	tp = sc->sc_tp;
#endif
d4110 1
a4110 1
		    (struct ip_moptions *)NULL, so);
@


1.140
log
@crank mss limit from 64 to 256; ok itojun@@, dhartmei@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.139 2004/01/07 09:08:54 itojun Exp $	*/
d2891 1
a2891 1
	 * However, do not accept offers under 256 bytes.
d2897 1
a2897 1
	mss = max(mss, 256);		/* sanity - at least max opt. space */
@


1.139
log
@cleanup obsolete comment from NRL code.  markus ok
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.138 2004/01/06 17:38:12 markus Exp $	*/
d2891 1
a2891 1
	 * However, do not accept offers under 64 bytes.
d2897 1
a2897 1
	mss = max(mss, 64);		/* sanity - at least max opt. space */
@


1.138
log
@import netbsd's version of David Borman's syncache code
http://www.kohala.com/start/borman.97jun06.txt; ok deraadt@@, henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.137 2003/12/21 14:50:04 markus Exp $	*/
a448 9
		if (iphlen > sizeof(struct ip6_hdr)) {
#if 0 /*XXX*/
			ipv6_stripoptions(m, iphlen);
			iphlen = sizeof(struct ip6_hdr);
#else
			m_freem(m);
			return;
#endif
		}
d787 10
a796 9
				 * If deprecated address is forbidden,
				 * we do not accept SYN to deprecated interface
				 * address to prevent any new inbound connection from
				 * getting established.  So drop the SYN packet.
				 * When we do not accept SYN, we send a TCP RST,
				 * with deprecated source address (instead of dropping
				 * it).  We compromise it as it is much better for peer
				 * to send a RST, and RST will be the final packet
				 * for the exchange.
d798 5
a802 4
				 * If we do not forbid deprecated addresses, we accept
				 * the SYN packet.  RFC2462 does not suggest dropping
				 * SYN in this case.
				 * If we decipher RFC2462 5.5.4, it says like this:
d804 2
a805 2
				 *    communication is okay - "SHOULD continue to be
				 *    used"
d807 7
a813 5
				 *   (2a) "SHOULD NOT be used if alternate address
				 *        with sufficient scope is available"
				 *   (2b) nothing mentioned otherwise.
				 * Here we fall into (2b) case as we have no choice in
				 * our source address selection - we must obey the peer.
d815 5
a819 4
				 * The wording in RFC2462 is confusing, and there are
				 * multiple description text for deprecated address
				 * handling - worse, they are not exactly the same.
				 * I believe 5.5.4 is the best one, so we follow 5.5.4.
d3509 1
a3509 6
	 * v6-related flags on the new guy, too.   This is
	 * done particularly for the case where an AF_INET6
	 * socket is bound only to a port, and a v4 connection
	 * comes in on that port.
	 * we also copy the flowinfo from the original pcb
	 * to the new one.
a3530 9

		/*inp->inp_options = ip6_srcroute();*/ /* soon. */
		/*
		 * still need to tweak outbound options
		 * processing to include this mbuf in
		 * the right place and put the correct
		 * NextHdr values in the right places.
		 * XXX  rja
		 */
d4101 1
a4101 1
		/* XXX flowlabel? */
@


1.137
log
@check for multicast early, remove redundant checks; ok itojun, mcbride
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.136 2003/12/08 10:48:57 markus Exp $	*/
d80 2
a308 43
/*
 * First check for a port-specific bomb. We do not want to drop half-opens
 * for other ports if this is the only port being bombed.  We only check
 * the bottom 40 half open connections, to avoid wasting too much time.
 *
 * Or, otherwise it is more likely a generic syn bomb, so delete the oldest
 * half-open connection.
 */
void
tcpdropoldhalfopen(avoidtp, port)
	struct tcpcb *avoidtp;
	u_int16_t port;
{
	struct inpcb *inp;
	struct tcpcb *tp;
	int ncheck = 40;
	int s;

	s = splnet();
	CIRCLEQ_FOREACH_REVERSE(inp, &tcbtable.inpt_queue, inp_queue) {
		if ((tp = (struct tcpcb *)inp->inp_ppcb) &&
		    tp != avoidtp &&
		    tp->t_state == TCPS_SYN_RECEIVED &&
		    port == inp->inp_lport) {
			tcp_close(tp);
			goto done;
		}
		if (--ncheck)
			break;
	}

	CIRCLEQ_FOREACH_REVERSE(inp, &tcbtable.inpt_queue, inp_queue) {
		if ((tp = (struct tcpcb *)inp->inp_ppcb) &&
		    tp != avoidtp &&
		    tp->t_state == TCPS_SYN_RECEIVED) {
			tcp_close(tp);
			goto done;
		}
	}
done:
	splx(s);
}

a364 2
	struct in_addr laddr;
	int dropsocket = 0;
d367 1
a367 2
	u_int32_t ts_val, ts_ecr;
	int ts_present = 0;
a371 1
	struct in6_addr laddr6;
d391 3
d607 3
a609 3
			ts_present = 1;
			ts_val = ntohl(*(u_int32_t *)(optp + 4));
			ts_ecr = ntohl(*(u_int32_t *)(optp + 8));
d681 36
d731 43
a773 1
			struct socket *so1;
d775 19
d795 32
a826 32
			/*
			 * If deprecated address is forbidden,
			 * we do not accept SYN to deprecated interface
			 * address to prevent any new inbound connection from
			 * getting established.  So drop the SYN packet.
			 * When we do not accept SYN, we send a TCP RST,
			 * with deprecated source address (instead of dropping
			 * it).  We compromise it as it is much better for peer
			 * to send a RST, and RST will be the final packet
			 * for the exchange.
			 *
			 * If we do not forbid deprecated addresses, we accept
			 * the SYN packet.  RFC2462 does not suggest dropping
			 * SYN in this case.
			 * If we decipher RFC2462 5.5.4, it says like this:
			 * 1. use of deprecated addr with existing
			 *    communication is okay - "SHOULD continue to be
			 *    used"
			 * 2. use of it with new communication:
			 *   (2a) "SHOULD NOT be used if alternate address
			 *        with sufficient scope is available"
			 *   (2b) nothing mentioned otherwise.
			 * Here we fall into (2b) case as we have no choice in
			 * our source address selection - we must obey the peer.
			 *
			 * The wording in RFC2462 is confusing, and there are
			 * multiple description text for deprecated address
			 * handling - worse, they are not exactly the same.
			 * I believe 5.5.4 is the best one, so we follow 5.5.4.
			 */
			if (ip6 && !ip6_use_deprecated) {
				struct in6_ifaddr *ia6;
d828 6
a833 4
				if ((ia6 = in6ifa_ifpwithaddr(m->m_pkthdr.rcvif, &ip6->ip6_dst)) &&
				    (ia6->ia6_flags & IN6_IFF_DEPRECATED)) {
					tp = NULL;
					goto dropwithreset;
a834 1
			}
d837 7
a843 46
			so1 = sonewconn(so, 0);
			if (so1 == NULL) {
				tcpdropoldhalfopen(tp, th->th_dport);
				so1 = sonewconn(so, 0);
				if (so1 == NULL)
					goto drop;
			}
			so = so1;
			/*
			 * This is ugly, but ....
			 *
			 * Mark socket as temporary until we're
			 * committed to keeping it.  The code at
			 * ``drop'' and ``dropwithreset'' check the
			 * flag dropsocket to see if the temporary
			 * socket created here should be discarded.
			 * We mark the socket as discardable until
			 * we're committed to it below in TCPS_LISTEN.
			 */
			dropsocket++;
#ifdef IPSEC
			/*
			 * We need to copy the required security levels
			 * from the old pcb. Ditto for any other
			 * IPsec-related information.
			 */
			{
			  struct inpcb *newinp = (struct inpcb *)so->so_pcb;
			  bcopy(inp->inp_seclevel, newinp->inp_seclevel,
				sizeof(inp->inp_seclevel));
			  newinp->inp_secrequire = inp->inp_secrequire;
			  if (inp->inp_ipo != NULL) {
				  newinp->inp_ipo = inp->inp_ipo;
				  inp->inp_ipo->ipo_ref_count++;
			  }
			  if (inp->inp_ipsec_remotecred != NULL) {
				  newinp->inp_ipsec_remotecred = inp->inp_ipsec_remotecred;
				  inp->inp_ipsec_remotecred->ref_count++;
			  }
			  if (inp->inp_ipsec_remoteauth != NULL) {
				  newinp->inp_ipsec_remoteauth
				      = inp->inp_ipsec_remoteauth;
				  inp->inp_ipsec_remoteauth->ref_count++;
			  }
			}
#endif /* IPSEC */
d845 7
a851 22
			/*
			 * inp still has the OLD in_pcb stuff, set the
			 * v6-related flags on the new guy, too.   This is
			 * done particularly for the case where an AF_INET6
			 * socket is bound only to a port, and a v4 connection
			 * comes in on that port.
			 * we also copy the flowinfo from the original pcb
			 * to the new one.
			 */
			{
			  int flags = inp->inp_flags;
			  struct inpcb *oldinpcb = inp;

			  inp = (struct inpcb *)so->so_pcb;
			  inp->inp_flags |= (flags & INP_IPV6);
			  if ((inp->inp_flags & INP_IPV6) != 0) {
			    inp->inp_ipv6.ip6_hlim =
			      oldinpcb->inp_ipv6.ip6_hlim;
			  }
			}
#else /* INET6 */
			inp = (struct inpcb *)so->so_pcb;
d853 8
a860 5
			inp->inp_lport = th->th_dport;
			switch (af) {
#ifdef INET6
			case AF_INET6:
				inp->inp_laddr6 = ip6->ip6_dst;
a861 1
				/*inp->inp_options = ip6_srcroute();*/ /* soon. */
d863 2
a864 5
				 * still need to tweak outbound options
				 * processing to include this mbuf in
				 * the right place and put the correct
				 * NextHdr values in the right places.
				 * XXX  rja
d866 4
a869 6
				break;
#endif /* INET6 */
			case AF_INET:
				inp->inp_laddr = ip->ip_dst;
				inp->inp_options = ip_srcroute();
				break;
d871 1
a871 6
			in_pcbrehash(inp);
			tp = intotcpcb(inp);
			tp->t_state = TCPS_LISTEN;

			/* Compute proper scaling value from buffer space */
			tcp_rscale(tp, so->so_rcv.sb_hiwat);
d875 10
d953 1
a953 2
	 * Process options if not in LISTEN state,
	 * else do it below (after getting remote address).
d955 2
a956 3
	if (optp && tp->t_state != TCPS_LISTEN)
		tcp_dooptions(tp, optp, optlen, th,
			&ts_present, &ts_val, &ts_ecr);
d991 1
a991 1
	    (!ts_present || TSTMP_GEQ(ts_val, tp->ts_recent)) &&
d1001 1
a1001 1
		if (ts_present && SEQ_LEQ(th->th_seq, tp->last_ack_sent)) {
d1003 1
a1003 1
			tp->ts_recent = ts_val;
d1015 2
a1016 2
				if (ts_present)
					tcp_xmit_timer(tp, tcp_now-ts_ecr+1);
a1121 164
	 * If the state is LISTEN then ignore segment if it contains an RST.
	 * If the segment contains an ACK then it is bad and send a RST.
	 * If it does not contain a SYN then it is not interesting; drop it.
	 * If it is from this socket, drop it, it must be forged.
	 * Don't bother responding if the destination was a broadcast.
	 * Otherwise initialize tp->rcv_nxt, and tp->irs, select an initial
	 * tp->iss, and send a segment:
	 *     <SEQ=ISS><ACK=RCV_NXT><CTL=SYN,ACK>
	 * Also initialize tp->snd_nxt to tp->iss+1 and tp->snd_una to tp->iss.
	 * Fill in remote peer address fields if not previously specified.
	 * Enter SYN_RECEIVED state, and process any other fields of this
	 * segment in this state.
	 */
	case TCPS_LISTEN: {
		struct mbuf *am;
		struct sockaddr_in *sin;
#ifdef INET6
		struct sockaddr_in6 *sin6;
#endif /* INET6 */

		if (tiflags & TH_RST)
			goto drop;
		if (tiflags & TH_ACK)
			goto dropwithreset;
		if ((tiflags & TH_SYN) == 0)
			goto drop;
		if (th->th_dport == th->th_sport) {
			switch (af) {
#ifdef INET6
			case AF_INET6:
				if (IN6_ARE_ADDR_EQUAL(&ip6->ip6_src,
				    &ip6->ip6_dst))
					goto drop;
				break;
#endif /* INET6 */
			case AF_INET:
				if (ip->ip_dst.s_addr == ip->ip_src.s_addr)
					goto drop;
				break;
			}
		}

		am = m_get(M_DONTWAIT, MT_SONAME);	/* XXX */
		if (am == NULL)
			goto drop;
		switch (af) {
#ifdef INET6
		case AF_INET6:
			/*
			 * This is probably the place to set the tp->pf value.
			 * (Don't forget to do it in the v4 code as well!)
			 *
			 * Also, remember to blank out things like flowlabel, or
			 * set flowlabel for accepted sockets in v6.
			 *
			 * FURTHERMORE, this is PROBABLY the place where the
			 * whole business of key munging is set up for passive
			 * connections.
			 */
			am->m_len = sizeof(struct sockaddr_in6);
			sin6 = mtod(am, struct sockaddr_in6 *);
			bzero(sin6, sizeof(*sin6));
			sin6->sin6_family = AF_INET6;
			sin6->sin6_len = sizeof(struct sockaddr_in6);
			sin6->sin6_addr = ip6->ip6_src;
			sin6->sin6_port = th->th_sport;
			sin6->sin6_flowinfo =
			    ip6->ip6_flow & IPV6_FLOWINFO_MASK;
			laddr6 = inp->inp_laddr6;
			if (IN6_IS_ADDR_UNSPECIFIED(&inp->inp_laddr6))
				inp->inp_laddr6 = ip6->ip6_dst;
			/* This is a good optimization. */
			if (in6_pcbconnect(inp, am)) {
				inp->inp_laddr6 = laddr6;
				(void) m_free(am);
				goto drop;
			}
			break;
#endif
		case AF_INET:
			/* drop IPv4 packet to AF_INET6 socket */
			if (inp->inp_flags & INP_IPV6) {
				(void) m_free(am);
				goto drop;
			}
			am->m_len = sizeof(struct sockaddr_in);
			sin = mtod(am, struct sockaddr_in *);
			bzero(sin, sizeof(*sin));
			sin->sin_family = AF_INET;
			sin->sin_len = sizeof(*sin);
			sin->sin_addr = ip->ip_src;
			sin->sin_port = th->th_sport;
			bzero((caddr_t)sin->sin_zero, sizeof(sin->sin_zero));
			laddr = inp->inp_laddr;
			if (inp->inp_laddr.s_addr == INADDR_ANY)
				inp->inp_laddr = ip->ip_dst;
			if (in_pcbconnect(inp, am)) {
				inp->inp_laddr = laddr;
				(void) m_free(am);
				goto drop;
			}
			break;
		}
		(void) m_free(am);
		tp->t_template = tcp_template(tp);
		if (tp->t_template == 0) {
			tp = tcp_drop(tp, ENOBUFS);
			dropsocket = 0;		/* socket is already gone */
			goto drop;
		}
		if (optp)
			tcp_dooptions(tp, optp, optlen, th,
				&ts_present, &ts_val, &ts_ecr);
#ifdef TCP_SACK
		/*
		 * If peer did not send a SACK_PERMITTED option (i.e., if
		 * tcp_dooptions() did not set TF_SACK_PERMIT), set
                 * sack_disable to 1 if it is currently 0.
                 */
                if (!tp->sack_disable)
                        if ((tp->t_flags & TF_SACK_PERMIT) == 0)
                                tp->sack_disable = 1;
#endif

		if (iss)
			tp->iss = iss;
		else {
#ifdef TCP_COMPAT_42
			tcp_iss += TCP_ISSINCR/2;
			tp->iss = tcp_iss;
#else /* TCP_COMPAT_42 */
			tp->iss = tcp_rndiss_next();
#endif /* !TCP_COMPAT_42 */
		}
		tp->irs = th->th_seq;
		tcp_sendseqinit(tp);
#if defined (TCP_SACK) || defined(TCP_ECN)
		tp->snd_last = tp->snd_una;
#endif /* TCP_SACK */
#if defined(TCP_SACK) && defined(TCP_FACK)
		tp->snd_fack = tp->snd_una;
		tp->retran_data = 0;
		tp->snd_awnd = 0;
#endif /* TCP_FACK */
#ifdef TCP_ECN
		/*
		 * if both ECE and CWR flag bits are set, peer is ECN capable.
		 */
		if (tcp_do_ecn &&
		    (tiflags & (TH_ECE|TH_CWR)) == (TH_ECE|TH_CWR)) {
			tp->t_flags |= TF_ECN_PERMIT;
			tcpstat.tcps_ecn_accepts++;
		}
#endif
		tcp_rcvseqinit(tp);
		tp->t_flags |= TF_ACKNOW;
		tp->t_state = TCPS_SYN_RECEIVED;
		TCP_TIMER_ARM(tp, TCPT_KEEP, tcptv_keep_init);
		dropsocket = 0;		/* committed to socket */
		tcpstat.tcps_accepts++;
		goto trimthenstep6;
		}

	/*
d1175 1
d1236 1
d1238 1
d1266 1
a1266 1
	 * and it's less than ts_recent, drop it.
d1268 2
a1269 2
	if (ts_present && (tiflags & TH_RST) == 0 && tp->ts_recent &&
	    TSTMP_LT(ts_val, tp->ts_recent)) {
d1391 1
a1391 1
	if (ts_present && TSTMP_GEQ(ts_val, tp->ts_recent) &&
d1394 1
a1394 1
		tp->ts_recent = ts_val;
d1763 2
a1764 2
		if (ts_present)
			tcp_xmit_timer(tp, tcp_now-ts_ecr+1);
d2095 8
a2145 3
	/* destroy temporarily created socket */
	if (dropsocket)
		(void) soabort(so);
a2167 3
	/* destroy temporarily created socket */
	if (dropsocket)
		(void) soabort(so);
d2173 1
a2173 1
tcp_dooptions(tp, cp, cnt, th, ts_present, ts_val, ts_ecr)
d2178 1
a2178 2
	int *ts_present;
	u_int32_t *ts_val, *ts_ecr;
d2208 1
d2223 5
a2227 5
			*ts_present = 1;
			bcopy((char *)cp + 2, (char *) ts_val, sizeof(*ts_val));
			NTOHL(*ts_val);
			bcopy((char *)cp + 6, (char *) ts_ecr, sizeof(*ts_ecr));
			NTOHL(*ts_ecr);
d2235 1
a2235 1
				tp->ts_recent = *ts_val;
a2254 7
	/* Update t_maxopd and t_maxseg after all options are processed */
	if (th->th_flags & TH_SYN) {
		(void) tcp_mss(tp, mss);	/* sets t_maxseg */

		if (mss)
			tcp_mss_update(tp);
	}
d3084 1068
@


1.136
log
@switch to CIRCLEQ_FOREACH_REVERSE in tcpdropoldhalfopen() and
avoid dropping youngest TCB; ok henning deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.135 2003/12/08 07:07:36 mcbride Exp $	*/
d437 7
d525 4
d587 6
a1161 18
		/*
		 * RFC1122 4.2.3.10, p. 104: discard bcast/mcast SYN
		 */
		if (m->m_flags & (M_BCAST|M_MCAST))
			goto drop;
		switch (af) {
#ifdef INET6
		case AF_INET6:
			if (IN6_IS_ADDR_MULTICAST(&ip6->ip6_dst))
				goto drop;
			break;
#endif /* INET6 */
		case AF_INET:
			if (IN_MULTICAST(ip->ip_dst.s_addr) ||
			    in_broadcast(ip->ip_dst, m->m_pkthdr.rcvif))
				goto drop;
			break;
		}
d2284 1
a2284 1
	 * Don't bother to respond if destination was broadcast/multicast.
d2286 1
a2286 1
	if ((tiflags & TH_RST) || m->m_flags & (M_BCAST|M_MCAST))
a2287 13
	switch (af) {
#ifdef INET6
	case AF_INET6:
		/* For following calls to tcp_respond */
		if (IN6_IS_ADDR_MULTICAST(&ip6->ip6_dst))
			goto drop;
		break;
#endif /* INET6 */
	case AF_INET:
		if (IN_MULTICAST(ip->ip_dst.s_addr) ||
		    in_broadcast(ip->ip_dst, m->m_pkthdr.rcvif))
			goto drop;
	}
@


1.135
log
@Mbuf tag tcp and udp packets which are translated to localhost, and
use the the presence of this tag to reverse the match order in
in{6}_pcblookup_listen(). Some daemons (such as portmap) do a double
bind, binding to both * and localhost in order to differentiate local
from non-local connections, and potentially granting more privilege to
local ones. This change ensures that redirected connections to localhost
do not appear local to such a daemon.

Bulk of changes from dhartmei@@, some changes markus@@

ok dhartmei@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.134 2003/11/04 21:43:16 markus Exp $	*/
d326 1
a326 4
	inp = tcbtable.inpt_queue.cqh_first;
	if (inp)						/* XXX */
	for (; inp != (struct inpcb *)&tcbtable.inpt_queue && --ncheck;
	    inp = inp->inp_queue.cqe_prev) {
d334 2
d338 1
a338 4
	inp = tcbtable.inpt_queue.cqh_first;
	if (inp)						/* XXX */
	for (; inp != (struct inpcb *)&tcbtable.inpt_queue;
	    inp = inp->inp_queue.cqe_prev) {
@


1.134
log
@add in(6)_pcblookup_listen() and replace all calls to in_pcblookup()
with either in(6)_pcbhashlookup() or in(6)_pcblookup_listen();
in_pcblookup is now only used by bind(2); speeds up pcb lookup for
listening sockets; from Claudio Jeker
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.133 2003/10/01 21:41:05 itojun Exp $	*/
d674 2
a675 1
			    &ip6->ip6_dst, th->th_dport);
d680 2
a681 1
			    ip->ip_dst, th->th_dport);
@


1.133
log
@use random number generator to generate IPv6 fragment ID/flowlabel.
cleanup IPv6 flowlabel handling.  deraadt ok
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.132 2003/07/09 22:03:16 itojun Exp $	*/
d673 2
a674 3
			inp = in_pcblookup(&tcbtable, &ip6->ip6_src,
			    th->th_sport, &ip6->ip6_dst, th->th_dport,
			    INPLOOKUP_WILDCARD | INPLOOKUP_IPV6);
d678 2
a679 2
			inp = in_pcblookup(&tcbtable, &ip->ip_src, th->th_sport,
			    &ip->ip_dst, th->th_dport, INPLOOKUP_WILDCARD);
@


1.132
log
@do not flip ip_len/ip_off in netinet stack.  deraadt ok.
(please test, especially PF portion)
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.131 2003/06/09 07:40:25 itojun Exp $	*/
a831 2
			    inp->inp_ipv6.ip6_flow =
			      oldinpcb->inp_ipv6.ip6_flow;
d1190 2
a1191 2
			sin6->sin6_flowinfo = htonl(0x0fffffff) &
				inp->inp_ipv6.ip6_flow;
@


1.132.2.1
log
@MFC:
Fix by markus@@

implement tcp_drain() similar to ip_drain();

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.132 2003/07/09 22:03:16 itojun Exp $	*/
a1382 1
			tcp_reass_lock(tp);
a1384 1
			tcp_reass_unlock(tp);
a1642 1
		tcp_reass_lock(tp);
a1644 1
		tcp_reass_unlock(tp);
a2146 1
		tcp_reass_lock(tp);
a2148 1
			tcp_reass_unlock(tp);
a2164 1
			tcp_reass_unlock(tp);
@


1.132.2.2
log
@MFC:
Fix by markus@@

limit total number of queued out-of-order packets to NMBCLUSTERS/2;

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.132.2.1 2004/03/03 02:35:26 brad Exp $	*/
d203 1
a203 1
	tiqe = pool_get(&tcpqe_pool, PR_NOWAIT);
d205 3
a207 15
		tiqe = LIST_FIRST(&tp->segq);
		if (tiqe != NULL && th->th_seq == tp->rcv_nxt) {
			/* Reuse last entry since new segment fills a hole */
			while ((p = LIST_NEXT(tiqe, ipqe_q)) != NULL)
				tiqe = p;
			m_freem(tiqe->ipqe_m);
			LIST_REMOVE(tiqe, ipqe_q);
		}
		if (tiqe == NULL || th->th_seq != tp->rcv_nxt) {
			/* Flush fragments for this connection */
			tcp_freeq(tp);
			tcpstat.tcps_rcvmemdrop++;
			m_freem(m);
			return (0);
		}
d234 1
a234 1
				pool_put(&tcpqe_pool, tiqe);
d264 1
a264 1
		pool_put(&tcpqe_pool, q);
d300 1
a300 1
		pool_put(&tcpqe_pool, q);
@


1.132.2.3
log
@MFC:
Fix by deraadt@@

on in-window SYN, send back rate-limited ACK

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.132.2.2 2004/03/03 08:37:05 brad Exp $	*/
a118 4
int tcp_synack_ppslim = 100;		/* 100pps */
int tcp_synack_ppslim_count = 0;
struct timeval tcp_synack_ppslim_last;

d1623 2
a1624 6
		if (ppsratecheck(&tcp_synack_ppslim_last, &tcp_synack_ppslim_count,
		    tcp_synack_ppslim) == 0) {
			/* XXX stat */
			goto drop;
		}
		goto dropafterack;
@


1.132.2.4
log
@MFC:
Fix by markus@@

factor out dropafterack_ratelim code, use ratelimit
for tcps_rcvacktoomuch, too; drop very old ACKs

ok deraadt@@ markus@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.132.2.3 2004/05/06 00:39:39 brad Exp $	*/
d119 3
a121 3
int tcp_ackdrop_ppslim = 100;		/* 100pps */
int tcp_ackdrop_ppslim_count = 0;
struct timeval tcp_ackdrop_ppslim_last;
d1624 1
a1624 1
	 * error and we ACK and drop the packet.
d1626 8
a1633 2
	if (tiflags & TH_SYN)
		goto dropafterack_ratelim;
d1733 1
a1733 8
			if (tlen) {
				/* Drop very old ACKs unless th_seq matches */
				if (th->th_seq != tp->rcv_nxt &&
				   SEQ_LT(th->th_ack,
				   tp->snd_una - tp->max_sndwnd)) {
					/* XXX stat */
					goto drop;
				}
a1734 1
			}
d1937 1
a1937 1
			goto dropafterack_ratelim;
a2285 8

dropafterack_ratelim:
	if (ppsratecheck(&tcp_ackdrop_ppslim_last, &tcp_ackdrop_ppslim_count,
	    tcp_ackdrop_ppslim) == 0) {
		/* XXX stat */
		goto drop;
	}
	/* ...fall into dropafterack... */
@


1.131
log
@backout following:
>use m_pulldown not m_pullup2.  fix some bugs in IPv6 tcp_trace().

PR 3283 fixed (confirmed)
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.130 2003/06/02 23:28:14 millert Exp $	*/
a521 1
#if 1
a522 3
#else
		tlen = ((struct ip *)ti)->ip_len;
#endif
@


1.130
log
@Remove the advertising clause in the UCB license which Berkeley
rescinded 22 July 1999.  Proofed by myself and Theo.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.129 2003/05/29 04:55:55 itojun Exp $	*/
d100 3
d110 1
d416 1
a416 1
	int iphlen, toff;
a429 1
	struct mbuf *tcp_saveti = NULL;
d435 1
a435 1
	toff = va_arg(ap, int);
d465 1
a465 1
		if (toff < sizeof(struct ip)) {
d470 6
a475 6
		ip = mtod(m, struct ip *);
		iphlen = sizeof(*ip);
		IP6_EXTHDR_GET(th, struct tcphdr *, m, toff,
		    sizeof(struct tcphdr));
		if (th == NULL) {
			tcpstat.tcps_rcvshort++;
d477 1
a478 6
		len = m->m_pkthdr.len;
		tlen = len - toff;
#ifdef TCP_ECN
		/* save ip_tos before clearing it for checksum */
		iptos = ip->ip_tos;
#endif
d483 1
a483 1
		if (toff < sizeof(struct ip6_hdr)) {
d488 6
a493 6
		ip6 = mtod(m, struct ip6_hdr *);
		iphlen = sizeof(*ip6);
		IP6_EXTHDR_GET(th, struct tcphdr *, m, toff,
		    sizeof(struct tcphdr));
		if (th == NULL) {
			tcpstat.tcps_rcvshort++;
a494 5
		}
		len = m->m_pkthdr.len;
		tlen = len - toff;
#ifdef TCP_ECN
		iptos = (ntohl(ip6->ip6_flow) >> 20) & 0xff;
a495 19

		/* Be proactive about malicious use of IPv4 mapped address */
		if (IN6_IS_ADDR_V4MAPPED(&ip6->ip6_src) ||
		    IN6_IS_ADDR_V4MAPPED(&ip6->ip6_dst)) {
			/* XXX stat */
			goto drop;
		}

		/*
		 * Be proactive about unspecified IPv6 address in source.
		 * As we use all-zero to indicate unbounded/unconnected pcb,
		 * unspecified IPv6 address can be used to confuse us.
		 *
		 * Note that packets with unspecified IPv6 destination is
		 * already dropped in ip6_input.
		 */
		if (IN6_IS_ADDR_UNSPECIFIED(&ip6->ip6_src)) {
			/* XXX stat */
			goto drop;
a496 1

d504 12
d518 15
d536 4
a539 1
		HTONS(ip->ip_len);
d546 1
a546 1
			if (in4_cksum(m, IPPROTO_TCP, toff, tlen) != 0) {
d555 1
d558 26
d596 2
d609 16
a624 4
		IP6_EXTHDR_GET(th, struct tcphdr *, m, toff, off);
		if (th == NULL) {
			tcpstat.tcps_rcvshort++;
			return;
d627 1
a627 1
		optp = mtod(m, u_int8_t *) + toff + sizeof(struct tcphdr);
d715 5
a719 9
			tcp_saveti = NULL;
			MGETHDR(tcp_saveti, M_DONTWAIT, MT_HEADER);
			if (!tcp_saveti)
				goto nosave;
#ifdef DIAGNOSTIC
			if (iphlen + sizeof(struct tcphdr) > MCLBYTES) {
				printf("cannot save to tcp_saveti\n");
				goto nosave;
			}
d721 3
a723 7
			if (iphlen + sizeof(struct tcphdr) > MHLEN) {
				MCLGET(tcp_saveti, M_DONTWAIT);
				if ((tcp_saveti->m_flags & M_EXT) == 0) {
					m_freem(tcp_saveti);
					tcp_saveti = NULL;
					goto nosave;
				}
a724 4
			m_copydata(m, 0, iphlen, mtod(tcp_saveti, caddr_t));
			m_copydata(m, toff, sizeof(struct tcphdr),
			    mtod(tcp_saveti, caddr_t) + iphlen);
	nosave:;
d882 1
a882 1
	ipsp_spd_lookup(m, af, toff, &error, IPSP_DIRECTION_IN,
d1079 1
a1079 1
				m_adj(m, toff + off);
d1093 1
a1093 1
	hdroptlen = toff + off;
d2241 14
a2254 2
	if (so->so_options & SO_DEBUG)
		tcp_trace(TA_INPUT, ostate, tp, tcp_saveti, 0, tlen);
a2261 1
	m_freem(tcp_saveti);
a2273 1
	m_freem(tcp_saveti);
a2322 1
	m_freem(tcp_saveti);
d2329 14
a2342 2
	if (tp && (tp->t_inpcb->inp_socket->so_options & SO_DEBUG))
		tcp_trace(TA_DROP, ostate, tp, tcp_saveti, 0, tlen);
a2343 1
	m_freem(tcp_saveti);
@


1.129
log
@use IN6_LINKMTU for IPv6 link MTU.  sync w/kame
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.128 2003/05/29 00:35:18 itojun Exp $	*/
d16 1
a16 5
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *	This product includes software developed by the University of
 *	California, Berkeley and its contributors.
 * 4. Neither the name of the University nor the names of its contributors
@


1.128
log
@use m_pulldown not m_pullup2.  fix some bugs in IPv6 tcp_trace().
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.127 2003/05/19 02:03:28 dhartmei Exp $	*/
d3014 1
d3016 8
@


1.127
log
@Bad switch condition used for SO_DEBUG, ok itojun@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.126 2003/04/29 10:25:41 miod Exp $	*/
a103 3
struct	tcpiphdr tcp_saveti;
struct  tcpipv6hdr tcp_saveti6;

a110 1
struct	tcpiphdr tcp_saveti;
d416 1
a416 1
	int iphlen;
d430 1
d436 1
a436 1
	iphlen = va_arg(ap, int);
d466 1
a466 1
		if (iphlen < sizeof(struct ip)) {
d471 6
a476 6
		if (iphlen > sizeof(struct ip)) {
#if 0	/*XXX*/
			ip_stripoptions(m, (struct mbuf *)0);
			iphlen = sizeof(struct ip);
#else
			m_freem(m);
d478 6
a484 1
		}
d489 1
a489 1
		if (iphlen < sizeof(struct ip6_hdr)) {
d494 6
a499 6
		if (iphlen > sizeof(struct ip6_hdr)) {
#if 0 /*XXX*/
			ipv6_stripoptions(m, iphlen);
			iphlen = sizeof(struct ip6_hdr);
#else
			m_freem(m);
d501 5
d507 19
d527 1
a534 12
	if (m->m_len < iphlen + sizeof(struct tcphdr)) {
		m = m_pullup2(m, iphlen + sizeof(struct tcphdr));
		if (m == NULL) {
			tcpstat.tcps_rcvshort++;
			return;
		}
	}

	ip = NULL;
#ifdef INET6
	ip6 = NULL;
#endif
a536 15
	    {
		struct tcpiphdr *ti;

		ip = mtod(m, struct ip *);
#if 1
		tlen = m->m_pkthdr.len - iphlen;
#else
		tlen = ((struct ip *)ti)->ip_len;
#endif
		ti = mtod(m, struct tcpiphdr *);

#ifdef TCP_ECN
		/* save ip_tos before clearing it for checksum */
		iptos = ip->ip_tos;
#endif
d540 1
a540 4
		len = sizeof(struct ip) + tlen;
		bzero(ti->ti_x1, sizeof ti->ti_x1);
		ti->ti_len = (u_int16_t)tlen;
		HTONS(ti->ti_len);
d547 1
a547 1
			if ((ti->ti_sum = in_cksum(m, len)) != 0) {
a555 1
	    }
a557 26
		ip6 = mtod(m, struct ip6_hdr *);
		tlen = m->m_pkthdr.len - iphlen;
#ifdef TCP_ECN
		iptos = (ntohl(ip6->ip6_flow) >> 20) & 0xff;
#endif

		/* Be proactive about malicious use of IPv4 mapped address */
		if (IN6_IS_ADDR_V4MAPPED(&ip6->ip6_src) ||
		    IN6_IS_ADDR_V4MAPPED(&ip6->ip6_dst)) {
			/* XXX stat */
			goto drop;
		}

		/*
		 * Be proactive about unspecified IPv6 address in source.
		 * As we use all-zero to indicate unbounded/unconnected pcb,
		 * unspecified IPv6 address can be used to confuse us.
		 *
		 * Note that packets with unspecified IPv6 destination is
		 * already dropped in ip6_input.
		 */
		if (IN6_IS_ADDR_UNSPECIFIED(&ip6->ip6_src)) {
			/* XXX stat */
			goto drop;
		}

a569 2
	th = (struct tcphdr *)(mtod(m, caddr_t) + iphlen);

d581 4
a584 16
		if (m->m_len < iphlen + off) {
			if ((m = m_pullup2(m, iphlen + off)) == NULL) {
				tcpstat.tcps_rcvshort++;
				return;
			}
			switch (af) {
			case AF_INET:
				ip = mtod(m, struct ip *);
				break;
#ifdef INET6
			case AF_INET6:
				ip6 = mtod(m, struct ip6_hdr *);
				break;
#endif
			}
			th = (struct tcphdr *)(mtod(m, caddr_t) + iphlen);
d587 1
a587 1
		optp = mtod(m, u_int8_t *) + iphlen + sizeof(struct tcphdr);
d675 9
a683 5
			switch (af) {
#ifdef INET6
			case AF_INET6:
				tcp_saveti6 = *(mtod(m, struct tcpipv6hdr *));
				break;
d685 7
a691 3
			case AF_INET:
				tcp_saveti = *(mtod(m, struct tcpiphdr *));
				break;
d693 4
d854 1
a854 1
	ipsp_spd_lookup(m, af, iphlen, &error, IPSP_DIRECTION_IN,
d1051 1
a1051 1
				m_adj(m, iphlen + off);
d1065 1
a1065 1
	hdroptlen = iphlen + off;
d2213 2
a2214 14
	if (so->so_options & SO_DEBUG) {
		switch (tp->pf) {
#ifdef INET6
		case PF_INET6:
			tcp_trace(TA_INPUT, ostate, tp, (caddr_t) &tcp_saveti6,
			    0, tlen);
			break;
#endif /* INET6 */
		case PF_INET:
			tcp_trace(TA_INPUT, ostate, tp, (caddr_t) &tcp_saveti,
			    0, tlen);
			break;
		}
	}
d2222 1
d2235 1
d2285 1
d2292 2
a2293 14
	if (tp && (tp->t_inpcb->inp_socket->so_options & SO_DEBUG)) {
		switch (tp->pf) {
#ifdef INET6
		case PF_INET6:
			tcp_trace(TA_DROP, ostate, tp, (caddr_t) &tcp_saveti6,
			    0, tlen);
			break;
#endif /* INET6 */
		case PF_INET:
			tcp_trace(TA_DROP, ostate, tp, (caddr_t) &tcp_saveti,
			    0, tlen);
			break;
		}
	}
d2295 1
@


1.126
log
@Fix logic error introduced when importing a Stevens' bug fix in r1.20;
from provos@@, ok dhartmei@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.125 2003/02/14 17:54:46 dhartmei Exp $	*/
d2246 1
a2246 1
		switch (tp->pf == PF_INET6) {
@


1.125
log
@Fix an mbuf leak, where each incoming IPv6 TCP connection (to a listening
socket) would leak one MT_SONAME mbuf. ok deraadt@@, henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.124 2002/09/11 03:27:03 itojun Exp $	*/
d1477 1
a1477 1
		if (todrop >= tlen ||
@


1.125.2.1
log
@MFC:
Fix by markus@@

implement tcp_drain() similar to ip_drain();

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.125 2003/02/14 17:54:46 dhartmei Exp $	*/
a1390 1
			tcp_reass_lock(tp);
a1392 1
			tcp_reass_unlock(tp);
a1650 1
		tcp_reass_lock(tp);
a1652 1
		tcp_reass_unlock(tp);
a2154 1
		tcp_reass_lock(tp);
a2156 1
			tcp_reass_unlock(tp);
a2172 1
			tcp_reass_unlock(tp);
@


1.125.2.2
log
@MFC:
Fix by markus@@

limit total number of queued out-of-order packets to NMBCLUSTERS/2;

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.125.2.1 2004/03/03 02:35:59 brad Exp $	*/
d207 1
a207 1
	tiqe = pool_get(&tcpqe_pool, PR_NOWAIT);
d209 3
a211 15
		tiqe = LIST_FIRST(&tp->segq);
		if (tiqe != NULL && th->th_seq == tp->rcv_nxt) {
			/* Reuse last entry since new segment fills a hole */
			while ((p = LIST_NEXT(tiqe, ipqe_q)) != NULL)
				tiqe = p;
			m_freem(tiqe->ipqe_m);
			LIST_REMOVE(tiqe, ipqe_q);
		}
		if (tiqe == NULL || th->th_seq != tp->rcv_nxt) {
			/* Flush fragments for this connection */
			tcp_freeq(tp);
			tcpstat.tcps_rcvmemdrop++;
			m_freem(m);
			return (0);
		}
d238 1
a238 1
				pool_put(&tcpqe_pool, tiqe);
d268 1
a268 1
		pool_put(&tcpqe_pool, q);
d304 1
a304 1
		pool_put(&tcpqe_pool, q);
@


1.124
log
@fix pointer signedness mixup.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.123 2002/09/05 23:37:35 itojun Exp $	*/
a1234 1
			(void) m_free(am);
d1237 1
@


1.124.2.1
log
@Pull patch from current:
Fix by dhartmei@@
Fix an mbuf leak, where each incoming IPv6 TCP connection (to a listening
socket) would leak one MT_SONAME mbuf.

deraadt@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.124 2002/09/11 03:27:03 itojun Exp $	*/
d1235 1
a1237 1
		(void) m_free(am);
@


1.123
log
@never append data to shutdown(s, SHUT_RD) socket.  can lead to unexpected
kernel resource consumption.  NetBSD PR 18185
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.122 2002/08/19 02:31:02 itojun Exp $	*/
d405 1
a405 1
	caddr_t optp = NULL;
d631 1
a631 1
		optp = mtod(m, caddr_t) + iphlen + sizeof(struct tcphdr);
@


1.122
log
@be consistent with other KAME source, use "ip6" for ip6_hdr, not "ipv6".
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.121 2002/08/19 02:28:23 itojun Exp $	*/
d1080 6
a1085 2
			m_adj(m, iphlen + off);
			sbappendstream(&so->so_rcv, m);
d2163 6
a2168 2
			m_adj(m, hdroptlen);
			sbappendstream(&so->so_rcv, m);
@


1.121
log
@merge in IPv6 deprecated address handling from KAME.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.120 2002/08/08 19:18:12 provos Exp $	*/
d425 1
a425 1
	struct ip6_hdr *ipv6 = NULL;
d518 1
a518 1
	ipv6 = NULL;
d562 1
a562 1
		ipv6 = mtod(m, struct ip6_hdr *);
d565 1
a565 1
		iptos = (ntohl(ipv6->ip6_flow) >> 20) & 0xff;
d569 2
a570 2
		if (IN6_IS_ADDR_V4MAPPED(&ipv6->ip6_src) ||
		    IN6_IS_ADDR_V4MAPPED(&ipv6->ip6_dst)) {
d583 1
a583 1
		if (IN6_IS_ADDR_UNSPECIFIED(&ipv6->ip6_src)) {
d624 1
a624 1
				ipv6 = mtod(m, struct ip6_hdr *);
d667 2
a668 2
		inp = in6_pcbhashlookup(&tcbtable, &ipv6->ip6_src, th->th_sport,
		    &ipv6->ip6_dst, th->th_dport);
d681 2
a682 2
			inp = in_pcblookup(&tcbtable, &ipv6->ip6_src,
			    th->th_sport, &ipv6->ip6_dst, th->th_dport,
d764 1
a764 1
			if (ipv6 && !ip6_use_deprecated) {
d767 1
a767 1
				if ((ia6 = in6ifa_ifpwithaddr(m->m_pkthdr.rcvif, &ipv6->ip6_dst)) &&
d851 1
a851 1
				inp->inp_laddr6 = ipv6->ip6_dst;
d1142 2
a1143 2
				if (IN6_ARE_ADDR_EQUAL(&ipv6->ip6_src,
				    &ipv6->ip6_dst))
d1162 1
a1162 1
			if (IN6_IS_ADDR_MULTICAST(&ipv6->ip6_dst))
d1194 1
a1194 1
			sin6->sin6_addr = ipv6->ip6_src;
d1200 1
a1200 1
				inp->inp_laddr6 = ipv6->ip6_dst;
d2298 1
a2298 1
		if (IN6_IS_ADDR_MULTICAST(&ipv6->ip6_dst))
@


1.120
log
@redo socketbuf speedup.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.118 2002/08/08 17:07:32 provos Exp $	*/
d732 42
@


1.119
log
@backout the tree break. ok pb@@, art@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.117 2002/06/09 16:26:11 itojun Exp $	*/
d303 1
a303 1
			sbappend(&so->so_rcv, q->ipqe_m);
d1039 1
a1039 1
			sbappend(&so->so_rcv, m);
d2118 1
a2118 1
			sbappend(&so->so_rcv, m);
@


1.118
log
@socket buf speedup from thorpej@@netbsd, okay art@@ ericj@@:

Make insertion of data into socket buffers O(C):
* Keep pointers to the first and last mbufs of the last record in the
  socket buffer.
* Use the sb_lastrecord pointer in the sbappend*() family of functions
  to avoid traversing the packet chain to find the last record.
* Add a new sbappend_stream() function for stream protocols which
  guarantee that there will never be more than one record in the
  socket buffer.  This function uses the sb_mbtail pointer to perform
  the data insertion.  Make TCP use sbappend_stream(). On a profiling
run, this makes sbappend of a TCP transmission using
a 1M socket buffer go from 50% of the time to .02% of the time. Thanks
to Bill Sommerfeld and YAMAMOTO Takashi for their debugging
assistance!
@
text
@d303 1
a303 1
			sbappendstream(&so->so_rcv, q->ipqe_m);
d1039 1
a1039 1
			sbappendstream(&so->so_rcv, m);
d2118 1
a2118 1
			sbappendstream(&so->so_rcv, m);
@


1.117
log
@whitespace
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.116 2002/06/07 16:18:02 itojun Exp $	*/
d303 1
a303 1
			sbappend(&so->so_rcv, q->ipqe_m);
d1039 1
a1039 1
			sbappend(&so->so_rcv, m);
d2118 1
a2118 1
			sbappend(&so->so_rcv, m);
@


1.116
log
@avoid is_ipv6 construct.  a step towards IPv4-less kernel
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.115 2002/06/07 15:51:54 itojun Exp $	*/
d37 1
a37 1
 * 
d41 1
a41 1
 * 
d56 1
a56 1
 * 
d68 1
a68 1
 * 
d447 1
a447 1
 	 */
d632 1
a632 1
		/* 
d708 1
a708 1
	
d754 1
a754 1
			/* 
d786 1
a786 1
			 * we also copy the flowinfo from the original pcb 
d792 1
a792 1
			  
d796 1
a796 1
			    inp->inp_ipv6.ip6_hlim = 
d798 1
a798 1
			    inp->inp_ipv6.ip6_flow = 
d810 1
a810 1
				
d923 1
a923 1
	/* 
d948 1
a948 1
		/* 
d980 1
a980 1
				/* 
d1204 1
a1204 1
		 * tcp_dooptions() did not set TF_SACK_PERMIT), set 
d1208 1
a1208 1
                        if ((tp->t_flags & TF_SACK_PERMIT) == 0) 
d1255 1
a1255 1
  	 */
d1314 1
a1314 1
                        if ((tp->t_flags & TF_SACK_PERMIT) == 0) 
d1388 1
a1388 1
	 * Then check that at least some bytes of segment are within 
d1391 1
a1391 1
	 * 
d1425 1
a1425 1
			if (th->th_urp > 1) 
d1584 1
a1584 1
	
d1704 1
a1704 1
				 * network (they're now cached at the receiver) 
d1712 1
a1712 1
				/* 
d1717 1
a1717 1
				    ((SEQ_GT(tp->snd_fack, tcprexmtthresh * 
d1730 2
a1731 2
					    	/* 
						 * False fast retx after 
d1755 1
a1755 1
#if defined(TCP_SACK) && defined(TCP_FACK) 
d1764 1
a1764 1
						/* 
d1795 3
a1797 3
					/* 
					 * while (awnd < cwnd) 
					 *         sendsomething(); 
d1831 1
a1831 1
					if (tp->snd_awnd < tp->snd_cwnd) 
d1840 1
a1840 1
					if (tcp_seq_subtract(tp->snd_max, 
d1842 1
a1842 1
						tp->snd_cwnd = 
d1851 1
a1851 1
			} 
d1853 1
a1853 1
			if (tp->t_dupacks >= tcprexmtthresh && 
d1859 1
a1859 1
					tp->snd_cwnd = 
d2058 1
a2058 1
		 * a FIN has been received from the remote side. 
d2065 1
a2065 1
		 * of data past the urgent section as the original 
d2127 2
a2128 2
			tcp_update_sack_list(tp); 
#endif 
d2130 1
a2130 1
		/* 
d2177 1
a2177 1
		 * starting the time-wait timer, turning off the other 
d2363 1
a2363 1
			/* 
d2373 2
a2374 2
		
#ifdef TCP_SACK 
d2386 1
a2386 1
#endif          
d2399 1
a2399 1
u_long 
d2402 2
a2403 2
{ 
	return ((long)(a - b)); 
d2408 1
a2408 1
#ifdef TCP_SACK 
d2411 1
a2411 1
 * prediction mode), and it updates the ordered list of sacks. 
d2413 1
a2413 1
void 
d2415 3
a2417 3
	struct tcpcb *tp; 
{    
	/* 
d2422 1
a2422 1
	 */     
d2425 1
a2425 1
    
d2436 1
a2436 1
		} else { 
d2440 1
a2440 1
	}   
d2455 1
a2455 1
	if (SEQ_GEQ(tp->rcv_nxt, tp->rcv_lastend)) 
d2457 1
a2457 1
	/* 
d2469 1
a2469 1
			/* 
d2502 1
a2502 1
}  
d2507 2
a2508 2
 * of holes (oldest to newest, in terms of the sequence space).  
 */             
d2511 1
a2511 1
{       
d2515 1
a2515 1
   
d2518 1
a2518 1
           
d2530 1
a2530 1
            
d2532 1
a2532 1
		NTOHL(sack.start); 
d2540 1
a2540 1
		if (SEQ_LEQ(sack.end, tp->snd_una)) 
d2558 1
a2558 1
				continue;  
d2567 2
a2568 2
			/* 
			 * dups is at least one.  If more data has been 
d2571 1
a2571 1
			cur->dups = min(tcprexmtthresh, 
d2580 2
a2581 2
			if (SEQ_LEQ(sack.end, cur->start)) 
				/* SACKs data before the current hole */ 
d2597 2
a2598 2
					tp->retran_data -= 
				    	    tcp_seq_subtract(cur->rxmit, 
d2602 1
a2602 1
					    tcp_seq_subtract(sack.end, 
d2630 3
a2632 3
				if (SEQ_GT(cur->rxmit, sack.start)) 
					tp->retran_data -= 
					    tcp_seq_subtract(cur->rxmit, 
d2647 2
a2648 2
				/* 
				 * ACKs some data in middle of a hole; need to 
d2653 1
a2653 1
				if (temp == NULL) 
d2656 3
a2658 3
				if (SEQ_GT(cur->rxmit, sack.end)) 
					tp->retran_data -= 
					    tcp_seq_subtract(sack.end, 
d2661 2
a2662 2
					tp->retran_data -= 
					    tcp_seq_subtract(cur->rxmit, 
d2690 1
a2690 1
			if (temp == NULL) 
d2694 1
a2694 1
			temp->dups = min(tcprexmtthresh, 
d2706 2
a2707 2
	/* 
	 * Update retran_data and snd_awnd.  Go through the list of 
d2716 1
a2716 1
	tp->snd_awnd = tcp_seq_subtract(tp->snd_nxt, tp->snd_fack) + 
d2721 1
a2721 1
}   
d2725 1
a2725 1
 * it is completely acked; otherwise, tcp_sack_option(), called from 
d2756 1
a2756 1
/* 
d2771 1
a2771 1
/* 
d2786 2
a2787 2
		/* 
		 * Partial window deflation.  This statement relies on the 
d2817 1
a2817 1
	
d2878 1
a2878 1
		/* 
d2905 1
a2905 1
	
d2992 1
a2992 1
		 * v6 cases (e.g., if ND wasn't able to resolve the 
d3044 1
a3044 1
 	if ((tp->t_flags & (TF_REQ_TSTMP|TF_NOOPT)) == TF_REQ_TSTMP &&
d3058 1
a3058 1
		} 
d3174 1
a3174 1
/* 
d3197 1
a3197 1
		/* 
d3200 1
a3200 1
		 */ 
d3206 3
a3208 3
		/* 
		 * Partial window deflation.  Relies on fact that tp->snd_una 
		 * not updated yet.  
@


1.115
log
@no need for IPv4 mapped addr support
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.114 2002/06/07 06:42:00 itojun Exp $	*/
a2948 1
	int is_ipv6 = 0;
a2965 1
		is_ipv6 = 1;
d2998 1
a2998 1
	else if (!is_ipv6) {
d3005 1
a3005 1
	else if (is_ipv6) {
@


1.114
log
@missing bzero! - now linklocal tcp works correctly
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.113 2002/05/31 04:43:25 angelos Exp $	*/
d3008 5
a3012 13
		if (inp && IN6_IS_ADDR_V4MAPPED(&inp->inp_faddr6)) {
			/* mapped addr case */
			struct in_addr d;
			bcopy(&inp->inp_faddr6.s6_addr32[3], &d, sizeof(d));
			if (ip_mtudisc || in_localaddr(d))
				mss = ifp->if_mtu - iphlen - sizeof(struct tcphdr);
		} else {
			/*
			 * for IPv6, path MTU discovery is always turned on,
			 * or the node must use packet size <= 1280.
			 */
			mss = IN6_LINKMTU(ifp) - iphlen - sizeof(struct tcphdr);
		}
@


1.113
log
@Socket-specific IPsec policy.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.112 2002/05/29 07:54:59 itojun Exp $	*/
d1149 1
d1175 1
@


1.112
log
@attach nd_ifinfo structure to if_afdata.
split IPv6 MTU (advertised by RA) from real link MTU.
sync with kame
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.111 2002/05/16 14:10:51 kjc Exp $	*/
d764 3
a766 11
			  if (inp->inp_ipsec_localid != NULL) {
			  	newinp->inp_ipsec_localid = inp->inp_ipsec_localid;
				inp->inp_ipsec_localid->ref_count++;
			  }
			  if (inp->inp_ipsec_remoteid != NULL) {
			  	newinp->inp_ipsec_remoteid = inp->inp_ipsec_remoteid;
				inp->inp_ipsec_remoteid->ref_count++;
			  }
			  if (inp->inp_ipsec_localcred != NULL) {
			  	newinp->inp_ipsec_localcred = inp->inp_ipsec_localcred;
				inp->inp_ipsec_localcred->ref_count++;
d769 2
a770 7
			  	newinp->inp_ipsec_remotecred = inp->inp_ipsec_remotecred;
				inp->inp_ipsec_remotecred->ref_count++;
			  }
			  if (inp->inp_ipsec_localauth != NULL) {
			  	newinp->inp_ipsec_localauth
				  = inp->inp_ipsec_localauth;
				inp->inp_ipsec_localauth->ref_count++;
d773 3
a775 3
			  	newinp->inp_ipsec_remoteauth
				  = inp->inp_ipsec_remoteauth;
				inp->inp_ipsec_remoteauth->ref_count++;
d846 4
d855 9
a863 1
			if (inp->inp_ipsec_remoteid == NULL &&
d865 1
a865 1
				inp->inp_ipsec_remoteid = tdb->tdb_srcid;
a886 4

	/* Error or otherwise drop-packet indication */
	if (error)
		goto drop;
@


1.111
log
@bring in ECN support from KAME.
it consists of
 - ECN support in TCP
 - tunnel-egress and fragment reassembly rules in layer-3 not to lose
   congestion info at tunnel-egress and fragment reassembly

to enable ECN in TCP, build a kernel with TCP_ECN, and then,
turn it on by "sysctl -w net.inet.tcp.ecn=1".

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.110 2002/03/19 14:58:54 itojun Exp $	*/
d3022 1
a3022 1
			mss = ifp->if_mtu - iphlen - sizeof(struct tcphdr);
@


1.110
log
@drop TCP connections to broadcast address.
From: "Crist J. Clark" <cjclark@@alum.mit.edu>
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.109 2002/03/15 18:19:52 millert Exp $	*/
d145 12
d434 3
d533 4
d564 3
d921 7
d943 3
d947 1
d984 1
a984 1
#if defined(TCP_SACK)
d990 3
d1227 1
a1227 1
#if defined (TCP_SACK)
d1235 10
d1290 5
d1320 18
d1543 5
d1628 33
d1731 1
a1731 1
#if defined(TCP_SACK) 
d1751 6
d1782 6
d1940 5
@


1.109
log
@Kill #if __STDC__ used to do K&R vs. ANSI varargs/stdarg; just do things
the ANSI way.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.108 2002/03/09 05:13:04 provos Exp $	*/
a1082 2
		 * in_broadcast() should never return true on a received
		 * packet with M_BCAST not set.
a1088 1
			/* XXX What about IPv6 Anycasting ?? :-(  rja */
d1094 2
a1095 1
			if (IN_MULTICAST(ip->ip_dst.s_addr))
d2140 2
a2141 1
		if (IN_MULTICAST(ip->ip_dst.s_addr))
@


1.108
log
@check tiflags instead of th as th might point to freed memory; pointed out
by wayne@@stallion.oz.au; also whack register.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.107 2002/03/08 03:49:58 provos Exp $	*/
a388 1
#if __STDC__
a389 4
#else
tcp_input(m, va_alist)
	struct mbuf *m;
#endif
@


1.107
log
@use timeout(9) to schedule TCP timers.  this avoid traversing all
tcp connections during tcp_slowtimo.  apdapted from thorpej@@netbsd.org
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.106 2002/03/02 00:44:52 provos Exp $	*/
d151 1
a151 1
#define	TCP_SETUP_ACK(tp, th) \
d154 1
a154 1
	    (tcp_ack_on_push && (th)->th_flags & TH_PUSH)) \
d175 2
a176 2
	register struct tcpcb *tp;
	register struct tcphdr *th;
d180 1
a180 1
	register struct ipqent *p, *q, *nq, *tiqe;
d216 2
a217 2
		register struct tcphdr *phdr = p->ipqe_tcp;
		register int i;
d242 2
a243 2
		register struct tcphdr *qhdr = q->ipqe_tcp;
		register int i = (th->th_seq + *tlen) - qhdr->th_seq;
d312 2
a313 2
	register struct inpcb *inp;
	register struct tcpcb *tp;
d393 1
a393 1
	register struct mbuf *m;
d397 1
a397 1
	register struct inpcb *inp;
d401 2
a402 2
	register struct tcpcb *tp = 0;
	register int tiflags;
d415 1
a415 1
	register struct tcphdr *th;
d1015 1
a1015 1
			TCP_SETUP_ACK(tp, th);
d1059 1
a1059 1
		register struct sockaddr_in *sin;
d1061 1
a1061 1
		register struct sockaddr_in6 *sin6;
d1997 1
a1997 1
			TCP_SETUP_ACK(tp, th);
d2698 1
a2698 1
	register struct mbuf *m;
d2728 1
a2728 1
	register struct tcpcb *tp;
d2731 1
a2731 1
	register short delta;
d2827 1
a2827 1
	register struct tcpcb *tp;
@


1.106
log
@disable immediate ack on TH_PUSH.  make behaviour sysctl tuneable.
from netbsd; also fix a bug where setting TF_ACKNOW didn't actually
result in an ack.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.105 2002/03/01 22:29:29 provos Exp $	*/
d82 1
d881 1
a881 1
	tp->t_idle = 0;
d946 1
a946 1
				else if (tp->t_rtt &&
d948 2
a949 1
					tcp_xmit_timer(tp, tp->t_rtt);
d1292 2
a1293 2
			if (tp->t_rtt)
				tcp_xmit_timer(tp, tp->t_rtt);
d1650 1
a1650 1
						tp->t_rtt = 0;
d1673 1
a1673 1
					tp->t_rtt = 0;
d1783 2
a1784 2
		else if (tp->t_rtt && SEQ_GT(th->th_ack, tp->t_rtseq))
			tcp_xmit_timer(tp,tp->t_rtt);
d2669 1
a2669 1
		tp->t_rtt = 0;
d2771 1
a2771 1
	tp->t_rtt = 0;
d3090 1
a3090 1
		tp->t_rtt = 0;
@


1.105
log
@remove tcp_fasttimo and convert delayed acks to the timeout(9) API instead.
adapated from netbsd.  okay angelos@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.104 2002/01/24 22:42:48 provos Exp $	*/
d145 15
a1009 4
			if (th->th_flags & TH_PUSH)
				tp->t_flags |= TF_ACKNOW;
			else
				TCP_SET_DELACK(tp);
d1013 3
d1995 1
a1995 4
			if (th->th_flags & TH_PUSH)
				tp->t_flags |= TF_ACKNOW;
			else
				TCP_SET_DELACK(tp);
@


1.104
log
@allocate tcp reassembly queue via pool; based on netbsd; okay art@@ angelos@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.103 2002/01/15 19:18:01 provos Exp $	*/
d998 1
a998 1
				tp->t_flags |= TF_DELACK;
d1984 1
a1984 1
				tp->t_flags |= TF_DELACK;
@


1.103
log
@allocate sackholes with pool
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.102 2002/01/14 20:09:42 provos Exp $	*/
d179 1
a179 1
	MALLOC(tiqe, struct ipqent *, sizeof(struct ipqent), M_IPQ, M_NOWAIT);
d210 1
a210 1
				FREE(tiqe, M_IPQ);
d240 1
a240 1
		FREE(q, M_IPQ);
d276 1
a276 1
		FREE(q, M_IPQ);
@


1.102
log
@knf
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.101 2002/01/14 03:11:55 provos Exp $	*/
d2427 1
a2427 1
			    malloc(sizeof(struct sackhole), M_PCB, M_NOWAIT);
d2481 1
a2481 1
						free(cur, M_PCB);
d2485 1
a2485 1
						free(p, M_PCB);
d2523 2
a2524 2
				temp = (struct sackhole *)malloc(sizeof(*temp),
				    M_PCB,M_NOWAIT);
d2560 2
a2561 2
			temp = (struct sackhole *) malloc(sizeof(*temp),
			    M_PCB, M_NOWAIT);
d2615 1
a2615 1
				free(prev, M_PCB);
@


1.101
log
@use macros to manage tcp timers; based on netbsd
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.98 2001/06/24 22:50:58 angelos Exp $	*/
d1789 2
a1790 2
		register u_int cw = tp->snd_cwnd;
		register u_int incr = tp->t_maxseg;
d2382 1
a2382 5
tcp_sack_option(tp, th, cp, optlen)
	struct tcpcb *tp;
	struct tcphdr *th;
	u_char *cp;
	int    optlen;
d2389 1
a2389 1
		return 1;
d2393 1
a2393 1
		return 1;
d2403 1
a2403 1
		bcopy((char *) tmp_cp, (char *) &(sack.start), sizeof(tcp_seq));
d2405 1
a2405 1
		bcopy((char *) tmp_cp + sizeof(tcp_seq),
d2416 1
a2416 1
		if (SEQ_GEQ(sack.end, tp->snd_fack))
a2421 3
		} else {
			if (SEQ_LT(sack.start, tp->snd_una))
				continue;
d2425 1
a2425 1
		if (tp->snd_holes == 0) { /* first hole */
d2436 1
a2436 1
			cur->next = 0;
d2458 2
a2459 2
				if ( ((sack.end - cur->end)/tp->t_maxseg) >=
					tcprexmtthresh)
d2477 1
a2477 1
				if (SEQ_GEQ(sack.end,cur->end)){
d2484 1
a2484 1
						cur=cur->next;
d2508 1
a2508 1
				cur->rxmit = min (cur->rxmit, cur->end);
d2510 2
a2511 2
				if ( ((sack.end - cur->end)/tp->t_maxseg) >=
					tcprexmtthresh)
d2541 1
a2541 1
				temp->rxmit = max (cur->rxmit, temp->start);
d2543 1
a2543 1
				cur->rxmit = min (cur->rxmit, cur->end);
d2545 1
a2545 1
				if ( ((sack.end - cur->end)/tp->t_maxseg) >=
d2592 1
a2592 1
	return 0;
d2610 1
a2610 1
		struct sackhole *prev = cur;
d2613 1
a2615 1
				prev = cur;
d2669 1
a2669 1
		return 1;
d2671 1
a2671 1
	return 0;
@


1.100
log
@fix comment to make life easier for my special friend darren.
@
text
@d867 1
a867 1
		tp->t_timer[TCPT_KEEP] = tcp_keepidle;
d963 3
a965 3
					tp->t_timer[TCPT_REXMT] = 0;
				else if (tp->t_timer[TCPT_PERSIST] == 0)
					tp->t_timer[TCPT_REXMT] = tp->t_rxtcur;
d1193 1
a1193 1
		tp->t_timer[TCPT_KEEP] = tcptv_keep_init;
d1246 1
a1246 1
		tp->t_timer[TCPT_REXMT] = 0;
d1596 1
a1596 1
				if (tp->t_timer[TCPT_REXMT] == 0)
d1633 1
a1633 1
						tp->t_timer[TCPT_REXMT] = 0;
d1656 1
a1656 1
					tp->t_timer[TCPT_REXMT] = 0;
d1777 1
a1777 1
			tp->t_timer[TCPT_REXMT] = 0;
d1779 2
a1780 2
		} else if (tp->t_timer[TCPT_PERSIST] == 0)
			tp->t_timer[TCPT_REXMT] = tp->t_rxtcur;
d1843 1
a1843 1
					tp->t_timer[TCPT_2MSL] = tcp_maxidle;
d1859 1
a1859 1
				tp->t_timer[TCPT_2MSL] = 2 * TCPTV_MSL;
d1883 1
a1883 1
			tp->t_timer[TCPT_2MSL] = 2 * TCPTV_MSL;
d2056 1
a2056 1
			tp->t_timer[TCPT_2MSL] = 2 * TCPTV_MSL;
d2064 1
a2064 1
			tp->t_timer[TCPT_2MSL] = 2 * TCPTV_MSL;
d2662 1
a2662 1
		tp->t_timer[TCPT_REXMT] = 0;
d3083 1
a3083 1
		tp->t_timer[TCPT_REXMT] = 0;
@


1.100.2.1
log
@MFC of rev 1.114, requested by itojun:
missing bzero! - now linklocal tcp works correctly
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.114 2002/06/07 06:42:00 itojun Exp $	*/
a1108 1
			bzero(sin6, sizeof(*sin6));
a1133 1
			bzero(sin, sizeof(*sin));
@


1.100.4.1
log
@Merge in -current, builds on i386, otherwise untested
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.104 2002/01/24 22:42:48 provos Exp $	*/
d179 1
a179 1
	tiqe =  pool_get(&ipqent_pool, PR_NOWAIT);
d210 1
a210 1
				pool_put(&ipqent_pool, tiqe);
d240 1
a240 1
		pool_put(&ipqent_pool, q);
d276 1
a276 1
		pool_put(&ipqent_pool, q);
d867 1
a867 1
		TCP_TIMER_ARM(tp, TCPT_KEEP, tcp_keepidle);
d963 3
a965 3
					TCP_TIMER_DISARM(tp, TCPT_REXMT);
				else if (TCP_TIMER_ISARMED(tp, TCPT_PERSIST) == 0)
					TCP_TIMER_ARM(tp, TCPT_REXMT, tp->t_rxtcur);
d1193 1
a1193 1
		TCP_TIMER_ARM(tp, TCPT_KEEP, tcptv_keep_init);
d1246 1
a1246 1
		TCP_TIMER_DISARM(tp, TCPT_REXMT);
d1596 1
a1596 1
				if (TCP_TIMER_ISARMED(tp, TCPT_REXMT) == 0)
d1633 1
a1633 1
						TCP_TIMER_DISARM(tp, TCPT_REXMT);
d1656 1
a1656 1
					TCP_TIMER_DISARM(tp, TCPT_REXMT);
d1777 1
a1777 1
			TCP_TIMER_DISARM(tp, TCPT_REXMT);
d1779 2
a1780 2
		} else if (TCP_TIMER_ISARMED(tp, TCPT_PERSIST) == 0)
			TCP_TIMER_ARM(tp, TCPT_REXMT, tp->t_rxtcur);
d1789 2
a1790 2
		u_int cw = tp->snd_cwnd;
		u_int incr = tp->t_maxseg;
d1843 1
a1843 1
					TCP_TIMER_ARM(tp, TCPT_2MSL, tcp_maxidle);
d1859 1
a1859 1
				TCP_TIMER_ARM(tp, TCPT_2MSL, 2 * TCPTV_MSL);
d1883 1
a1883 1
			TCP_TIMER_ARM(tp, TCPT_2MSL, 2 * TCPTV_MSL);
d2056 1
a2056 1
			TCP_TIMER_ARM(tp, TCPT_2MSL, 2 * TCPTV_MSL);
d2064 1
a2064 1
			TCP_TIMER_ARM(tp, TCPT_2MSL, 2 * TCPTV_MSL);
d2382 5
a2386 1
tcp_sack_option(struct tcpcb *tp, struct tcphdr *th, u_char *cp, int optlen)
d2393 1
a2393 1
		return (1);
d2397 1
a2397 1
		return (1);
d2407 1
a2407 1
		bcopy(tmp_cp, (char *) &(sack.start), sizeof(tcp_seq));
d2409 1
a2409 1
		bcopy(tmp_cp + sizeof(tcp_seq),
d2420 1
a2420 1
		if (SEQ_GT(sack.end, tp->snd_fack))
d2426 3
d2432 1
a2432 1
		if (tp->snd_holes == NULL) { /* first hole */
d2434 1
a2434 1
			    pool_get(&sackhl_pool, PR_NOWAIT);
d2443 1
a2443 1
			cur->next = NULL;
d2465 2
a2466 2
				if (((sack.end - cur->end)/tp->t_maxseg) >=
				    tcprexmtthresh)
d2484 1
a2484 1
				if (SEQ_GEQ(sack.end, cur->end)) {
d2488 1
a2488 1
						pool_put(&sackhl_pool, cur);
d2491 2
a2492 2
						cur = cur->next;
						pool_put(&sackhl_pool, p);
d2515 1
a2515 1
				cur->rxmit = min(cur->rxmit, cur->end);
d2517 2
a2518 2
				if (((sack.end - cur->end)/tp->t_maxseg) >=
				    tcprexmtthresh)
d2530 2
a2531 2
				temp = (struct sackhole *)
				    pool_get(&sackhl_pool, PR_NOWAIT);
d2548 1
a2548 1
				temp->rxmit = max(cur->rxmit, temp->start);
d2550 1
a2550 1
				cur->rxmit = min(cur->rxmit, cur->end);
d2552 1
a2552 1
				if (((sack.end - cur->end)/tp->t_maxseg) >=
d2567 2
a2568 2
			temp = (struct sackhole *)
			    pool_get(&sackhl_pool, PR_NOWAIT);
d2599 1
a2599 1
	return (0);
d2617 1
a2617 1
		struct sackhole *prev;
d2620 2
a2622 2
				cur = cur->next;
				pool_put(&sackhl_pool, prev);
d2662 1
a2662 1
		TCP_TIMER_DISARM(tp, TCPT_REXMT);
d2676 1
a2676 1
		return (1);
d2678 1
a2678 1
	return (0);
d3083 1
a3083 1
		TCP_TIMER_DISARM(tp, TCPT_REXMT);
@


1.100.4.2
log
@Sync UBC branch to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.100.4.1 2002/01/31 22:55:45 niklas Exp $	*/
a81 1
#include <sys/kernel.h>
a143 27
#ifdef TCP_ECN
/*
 * ECN (Explicit Congestion Notification) support based on RFC3168
 * implementation note:
 *   snd_last is used to track a recovery phase.
 *   when cwnd is reduced, snd_last is set to snd_max.
 *   while snd_last > snd_una, the sender is in a recovery phase and
 *   its cwnd should not be reduced again.
 *   snd_last follows snd_una when not in a recovery phase.
 */
#endif

/*
 * Macro to compute ACK transmission behavior.  Delay the ACK unless
 * we have already delayed an ACK (must send an ACK every two segments).
 * We also ACK immediately if we received a PUSH and the ACK-on-PUSH
 * option is enabled.
 */
#define	TCP_SETUP_ACK(tp, tiflags) \
do { \
	if ((tp)->t_flags & TF_DELACK || \
	    (tcp_ack_on_push && (tiflags) & TH_PUSH)) \
		tp->t_flags |= TF_ACKNOW; \
	else \
		TCP_SET_DELACK(tp); \
} while (0)

d159 2
a160 2
	struct tcpcb *tp;
	struct tcphdr *th;
d164 1
a164 1
	struct ipqent *p, *q, *nq, *tiqe;
d200 2
a201 2
		struct tcphdr *phdr = p->ipqe_tcp;
		int i;
d226 2
a227 2
		struct tcphdr *qhdr = q->ipqe_tcp;
		int i = (th->th_seq + *tlen) - qhdr->th_seq;
d296 2
a297 2
	struct inpcb *inp;
	struct tcpcb *tp;
d373 1
d375 4
d381 1
a381 1
	struct inpcb *inp;
d385 2
a386 2
	struct tcpcb *tp = 0;
	int tiflags;
d399 1
a399 1
	struct tcphdr *th;
a410 3
#ifdef TCP_ECN
	u_char iptos;
#endif
a506 4
#ifdef TCP_ECN
		/* save ip_tos before clearing it for checksum */
		iptos = ip->ip_tos;
#endif
a533 3
#ifdef TCP_ECN
		iptos = (ntohl(ipv6->ip6_flow) >> 20) & 0xff;
#endif
d731 11
a741 3
			  if (inp->inp_ipo != NULL) {
				  newinp->inp_ipo = inp->inp_ipo;
				  inp->inp_ipo->ipo_ref_count++;
d744 7
a750 2
				  newinp->inp_ipsec_remotecred = inp->inp_ipsec_remotecred;
				  inp->inp_ipsec_remotecred->ref_count++;
d753 3
a755 3
				  newinp->inp_ipsec_remoteauth
				      = inp->inp_ipsec_remoteauth;
				  inp->inp_ipsec_remoteauth->ref_count++;
a825 4
	if (error) {
		splx(s);
		goto drop;
	}
d831 1
a831 9
			if (inp->inp_ipo == NULL) {
				inp->inp_ipo = ipsec_add_policy(inp, af,
				    IPSP_DIRECTION_OUT);
				if (inp->inp_ipo == NULL) {
					splx(s);
					goto drop;
				}
			}
			if (inp->inp_ipo->ipo_dstid == NULL &&
d833 1
a833 1
				inp->inp_ipo->ipo_dstid = tdb->tdb_srcid;
d855 4
d865 1
a865 1
	tp->t_rcvtime = tcp_now;
a887 7
#ifdef TCP_ECN
	/* if congestion experienced, set ECE bit in subsequent packets. */
	if ((iptos & IPTOS_ECN_MASK) == IPTOS_ECN_CE) {
		tp->t_flags |= TF_RCVD_CE;
		tcpstat.tcps_ecn_rcvce++;
	}
#endif
a902 3
#ifdef TCP_ECN
	    (tiflags & (TH_SYN|TH_FIN|TH_RST|TH_URG|TH_ECE|TH_CWR|TH_ACK)) == TH_ACK &&
#else
a903 1
#endif
d930 1
a930 1
				else if (tp->t_rtttime &&
d932 1
a932 2
					tcp_xmit_timer(tp,
					    tcp_now - tp->t_rtttime);
d939 1
a939 1
#if defined(TCP_SACK) || defined(TCP_ECN)
a944 3
#ifdef TCP_ECN
				if (SEQ_GT(tp->snd_una, tp->snd_last))
#endif
d995 4
a1001 3
			TCP_SETUP_ACK(tp, tiflags);
			if (tp->t_flags & TF_ACKNOW)
				(void) tcp_output(tp);
d1043 1
a1043 1
		struct sockaddr_in *sin;
d1045 1
a1045 1
		struct sockaddr_in6 *sin6;
d1072 2
d1080 1
d1086 1
a1086 2
			if (IN_MULTICAST(ip->ip_dst.s_addr) ||
			    in_broadcast(ip->ip_dst, m->m_pkthdr.rcvif))
a1108 1
			bzero(sin6, sizeof(*sin6));
a1133 1
			bzero(sin, sizeof(*sin));
d1182 1
a1182 1
#if defined (TCP_SACK) || defined(TCP_ECN)
a1189 10
#ifdef TCP_ECN
		/*
		 * if both ECE and CWR flag bits are set, peer is ECN capable.
		 */
		if (tcp_do_ecn &&
		    (tiflags & (TH_ECE|TH_CWR)) == (TH_ECE|TH_CWR)) {
			tp->t_flags |= TF_ECN_PERMIT;
			tcpstat.tcps_ecn_accepts++;
		}
#endif
a1234 5
#ifdef TCP_ECN
			/* if ECN is enabled, fall back to non-ecn at rexmit */
			if (tcp_do_ecn && !(tp->t_flags & TF_DISABLE_ECN))
				goto drop;
#endif
a1259 18
#ifdef TCP_ECN
		/*
		 * if ECE is set but CWR is not set for SYN-ACK, or
		 * both ECE and CWR are set for simultaneous open,
		 * peer is ECN capable.
		 */
		if (tcp_do_ecn) {
			if ((tiflags & (TH_ACK|TH_ECE|TH_CWR))
			    == (TH_ACK|TH_ECE) ||
			    (tiflags & (TH_ACK|TH_ECE|TH_CWR))
			    == (TH_ECE|TH_CWR)) {
				tp->t_flags |= TF_ECN_PERMIT;
				tiflags &= ~(TH_ECE|TH_CWR);
				tcpstat.tcps_ecn_accepts++;
			}
		}
#endif

d1276 2
a1277 2
			if (tp->t_rtttime)
				tcp_xmit_timer(tp, tcp_now - tp->t_rtttime);
a1464 5
#ifdef TCP_ECN
			/* if ECN is enabled, fall back to non-ecn at rexmit */
			if (tcp_do_ecn && !(tp->t_flags & TF_DISABLE_ECN))
				goto drop;
#endif
a1544 33
#ifdef TCP_ECN
		/*
		 * if we receive ECE and are not already in recovery phase,
		 * reduce cwnd by half but don't slow-start.
		 * advance snd_last to snd_max not to reduce cwnd again
		 * until all outstanding packets are acked.
		 */
		if (tcp_do_ecn && (tiflags & TH_ECE)) {
			if ((tp->t_flags & TF_ECN_PERMIT) &&
			    SEQ_GEQ(tp->snd_una, tp->snd_last)) {
				u_int win;

				win = min(tp->snd_wnd, tp->snd_cwnd) / tp->t_maxseg;
				if (win > 1) {
					tp->snd_ssthresh = win / 2 * tp->t_maxseg;
					tp->snd_cwnd = tp->snd_ssthresh;
					tp->snd_last = tp->snd_max;
					tp->t_flags |= TF_SEND_CWR;
					tcpstat.tcps_cwr_ecn++;
				}
			}
			tcpstat.tcps_ecn_rcvece++;
		}
		/*
		 * if we receive CWR, we know that the peer has reduced
		 * its congestion window.  stop sending ecn-echo.
		 */
		if ((tiflags & TH_CWR)) {
			tp->t_flags &= ~TF_RCVD_CE;
			tcpstat.tcps_ecn_rcvcwr++;
		}
#endif /* TCP_ECN */

d1615 1
a1615 1
#if defined(TCP_SACK) || defined(TCP_ECN)
d1634 1
a1634 7
						tp->t_rtttime = 0;
#ifdef TCP_ECN
						tp->t_flags |= TF_SEND_CWR;
#endif
#if 1 /* TCP_ECN */
						tcpstat.tcps_cwr_frecovery++;
#endif
d1657 1
a1657 1
					tp->t_rtttime = 0;
a1659 6
#ifdef TCP_ECN
					tp->t_flags |= TF_SEND_CWR;
#endif
#if 1 /* TCP_ECN */
					tcpstat.tcps_cwr_frecovery++;
#endif
d1767 2
a1768 2
		else if (tp->t_rtttime && SEQ_GT(th->th_ack, tp->t_rtseq))
			tcp_xmit_timer(tp, tcp_now - tp->t_rtttime);
a1811 5
#ifdef TCP_ECN
		/* sync snd_last with snd_una */
		if (SEQ_GT(tp->snd_una, tp->snd_last))
			tp->snd_last = tp->snd_una;
#endif
d1981 4
a1984 1
			TCP_SETUP_ACK(tp, tiflags);
d2134 1
a2134 2
		if (IN_MULTICAST(ip->ip_dst.s_addr) ||
		    in_broadcast(ip->ip_dst, m->m_pkthdr.rcvif))
d2656 1
a2656 1
		tp->t_rtttime = 0;
d2685 1
a2685 1
	struct mbuf *m;
d2715 1
a2715 1
	struct tcpcb *tp;
d2718 1
a2718 1
	short delta;
d2758 1
a2758 1
	tp->t_rtttime = 0;
d2814 1
a2814 1
	struct tcpcb *tp;
d2821 1
d2839 1
d2872 1
a2872 1
	else if (tp->pf == AF_INET) {
d2879 14
a2892 6
	else if (tp->pf == AF_INET6) {
		/*
		 * for IPv6, path MTU discovery is always turned on,
		 * or the node must use packet size <= 1280.
		 */
		mss = IN6_LINKMTU(ifp) - iphlen - sizeof(struct tcphdr);
d3077 1
a3077 1
		tp->t_rtttime = 0;
@


1.100.4.3
log
@sync to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.100.4.2 2002/06/11 03:31:37 art Exp $	*/
d37 1
a37 1
 *
d41 1
a41 1
 *
d56 1
a56 1
 *
d68 1
a68 1
 *
d303 1
a303 1
			sbappendstream(&so->so_rcv, q->ipqe_m);
d405 1
a405 1
	u_int8_t *optp = NULL;
d425 1
a425 1
	struct ip6_hdr *ip6 = NULL;
d447 1
a447 1
	 */
d518 1
a518 1
	ip6 = NULL;
d562 1
a562 1
		ip6 = mtod(m, struct ip6_hdr *);
d565 1
a565 1
		iptos = (ntohl(ip6->ip6_flow) >> 20) & 0xff;
d569 2
a570 2
		if (IN6_IS_ADDR_V4MAPPED(&ip6->ip6_src) ||
		    IN6_IS_ADDR_V4MAPPED(&ip6->ip6_dst)) {
d583 1
a583 1
		if (IN6_IS_ADDR_UNSPECIFIED(&ip6->ip6_src)) {
d624 1
a624 1
				ip6 = mtod(m, struct ip6_hdr *);
d631 2
a632 2
		optp = mtod(m, u_int8_t *) + iphlen + sizeof(struct tcphdr);
		/*
d667 2
a668 2
		inp = in6_pcbhashlookup(&tcbtable, &ip6->ip6_src, th->th_sport,
		    &ip6->ip6_dst, th->th_dport);
d681 2
a682 2
			inp = in_pcblookup(&tcbtable, &ip6->ip6_src,
			    th->th_sport, &ip6->ip6_dst, th->th_dport,
d708 1
a708 1

a732 42
#ifdef INET6
			/*
			 * If deprecated address is forbidden,
			 * we do not accept SYN to deprecated interface
			 * address to prevent any new inbound connection from
			 * getting established.  So drop the SYN packet.
			 * When we do not accept SYN, we send a TCP RST,
			 * with deprecated source address (instead of dropping
			 * it).  We compromise it as it is much better for peer
			 * to send a RST, and RST will be the final packet
			 * for the exchange.
			 *
			 * If we do not forbid deprecated addresses, we accept
			 * the SYN packet.  RFC2462 does not suggest dropping
			 * SYN in this case.
			 * If we decipher RFC2462 5.5.4, it says like this:
			 * 1. use of deprecated addr with existing
			 *    communication is okay - "SHOULD continue to be
			 *    used"
			 * 2. use of it with new communication:
			 *   (2a) "SHOULD NOT be used if alternate address
			 *        with sufficient scope is available"
			 *   (2b) nothing mentioned otherwise.
			 * Here we fall into (2b) case as we have no choice in
			 * our source address selection - we must obey the peer.
			 *
			 * The wording in RFC2462 is confusing, and there are
			 * multiple description text for deprecated address
			 * handling - worse, they are not exactly the same.
			 * I believe 5.5.4 is the best one, so we follow 5.5.4.
			 */
			if (ip6 && !ip6_use_deprecated) {
				struct in6_ifaddr *ia6;

				if ((ia6 = in6ifa_ifpwithaddr(m->m_pkthdr.rcvif, &ip6->ip6_dst)) &&
				    (ia6->ia6_flags & IN6_IFF_DEPRECATED)) {
					tp = NULL;
					goto dropwithreset;
				}
			}
#endif

d754 1
a754 1
			/*
d786 1
a786 1
			 * we also copy the flowinfo from the original pcb
d792 1
a792 1

d796 1
a796 1
			    inp->inp_ipv6.ip6_hlim =
d798 1
a798 1
			    inp->inp_ipv6.ip6_flow =
d809 2
a810 2
				inp->inp_laddr6 = ip6->ip6_dst;

d923 1
a923 1
	/*
d948 1
a948 1
		/*
d980 1
a980 1
				/*
d1038 2
a1039 6
			if (so->so_state & SS_CANTRCVMORE)
				m_freem(m);
			else {
				m_adj(m, iphlen + off);
				sbappendstream(&so->so_rcv, m);
			}
d1100 2
a1101 2
				if (IN6_ARE_ADDR_EQUAL(&ip6->ip6_src,
				    &ip6->ip6_dst))
d1120 1
a1120 1
			if (IN6_IS_ADDR_MULTICAST(&ip6->ip6_dst))
d1152 1
a1152 1
			sin6->sin6_addr = ip6->ip6_src;
d1158 1
a1158 1
				inp->inp_laddr6 = ip6->ip6_dst;
d1204 1
a1204 1
		 * tcp_dooptions() did not set TF_SACK_PERMIT), set
d1208 1
a1208 1
                        if ((tp->t_flags & TF_SACK_PERMIT) == 0)
d1255 1
a1255 1
	 */
d1314 1
a1314 1
                        if ((tp->t_flags & TF_SACK_PERMIT) == 0)
d1388 1
a1388 1
	 * Then check that at least some bytes of segment are within
d1391 1
a1391 1
	 *
d1425 1
a1425 1
			if (th->th_urp > 1)
d1584 1
a1584 1

d1704 1
a1704 1
				 * network (they're now cached at the receiver)
d1712 1
a1712 1
				/*
d1717 1
a1717 1
				    ((SEQ_GT(tp->snd_fack, tcprexmtthresh *
d1730 2
a1731 2
					    	/*
						 * False fast retx after
d1755 1
a1755 1
#if defined(TCP_SACK) && defined(TCP_FACK)
d1764 1
a1764 1
						/*
d1795 3
a1797 3
					/*
					 * while (awnd < cwnd)
					 *         sendsomething();
d1831 1
a1831 1
					if (tp->snd_awnd < tp->snd_cwnd)
d1840 1
a1840 1
					if (tcp_seq_subtract(tp->snd_max,
d1842 1
a1842 1
						tp->snd_cwnd =
d1851 1
a1851 1
			}
d1853 1
a1853 1
			if (tp->t_dupacks >= tcprexmtthresh &&
d1859 1
a1859 1
					tp->snd_cwnd =
d2058 1
a2058 1
		 * a FIN has been received from the remote side.
d2065 1
a2065 1
		 * of data past the urgent section as the original
d2117 2
a2118 6
			if (so->so_state & SS_CANTRCVMORE)
				m_freem(m);
			else {
				m_adj(m, hdroptlen);
				sbappendstream(&so->so_rcv, m);
			}
d2127 2
a2128 2
			tcp_update_sack_list(tp);
#endif
d2130 1
a2130 1
		/*
d2177 1
a2177 1
		 * starting the time-wait timer, turning off the other
d2256 1
a2256 1
		if (IN6_IS_ADDR_MULTICAST(&ip6->ip6_dst))
d2363 1
a2363 1
			/*
d2373 2
a2374 2

#ifdef TCP_SACK
d2386 1
a2386 1
#endif
d2399 1
a2399 1
u_long
d2402 2
a2403 2
{
	return ((long)(a - b));
d2408 1
a2408 1
#ifdef TCP_SACK
d2411 1
a2411 1
 * prediction mode), and it updates the ordered list of sacks.
d2413 1
a2413 1
void
d2415 3
a2417 3
	struct tcpcb *tp;
{
	/*
d2422 1
a2422 1
	 */
d2425 1
a2425 1

d2436 1
a2436 1
		} else {
d2440 1
a2440 1
	}
d2455 1
a2455 1
	if (SEQ_GEQ(tp->rcv_nxt, tp->rcv_lastend))
d2457 1
a2457 1
	/*
d2469 1
a2469 1
			/*
d2502 1
a2502 1
}
d2507 2
a2508 2
 * of holes (oldest to newest, in terms of the sequence space).
 */
d2511 1
a2511 1
{
d2515 1
a2515 1

d2518 1
a2518 1

d2530 1
a2530 1

d2532 1
a2532 1
		NTOHL(sack.start);
d2540 1
a2540 1
		if (SEQ_LEQ(sack.end, tp->snd_una))
d2558 1
a2558 1
				continue;
d2567 2
a2568 2
			/*
			 * dups is at least one.  If more data has been
d2571 1
a2571 1
			cur->dups = min(tcprexmtthresh,
d2580 2
a2581 2
			if (SEQ_LEQ(sack.end, cur->start))
				/* SACKs data before the current hole */
d2597 2
a2598 2
					tp->retran_data -=
				    	    tcp_seq_subtract(cur->rxmit,
d2602 1
a2602 1
					    tcp_seq_subtract(sack.end,
d2630 3
a2632 3
				if (SEQ_GT(cur->rxmit, sack.start))
					tp->retran_data -=
					    tcp_seq_subtract(cur->rxmit,
d2647 2
a2648 2
				/*
				 * ACKs some data in middle of a hole; need to
d2653 1
a2653 1
				if (temp == NULL)
d2656 3
a2658 3
				if (SEQ_GT(cur->rxmit, sack.end))
					tp->retran_data -=
					    tcp_seq_subtract(sack.end,
d2661 2
a2662 2
					tp->retran_data -=
					    tcp_seq_subtract(cur->rxmit,
d2690 1
a2690 1
			if (temp == NULL)
d2694 1
a2694 1
			temp->dups = min(tcprexmtthresh,
d2706 2
a2707 2
	/*
	 * Update retran_data and snd_awnd.  Go through the list of
d2716 1
a2716 1
	tp->snd_awnd = tcp_seq_subtract(tp->snd_nxt, tp->snd_fack) +
d2721 1
a2721 1
}
d2725 1
a2725 1
 * it is completely acked; otherwise, tcp_sack_option(), called from
d2756 1
a2756 1
/*
d2771 1
a2771 1
/*
d2786 2
a2787 2
		/*
		 * Partial window deflation.  This statement relies on the
d2817 1
a2817 1

d2878 1
a2878 1
		/*
d2905 1
a2905 1

d2992 1
a2992 1
		 * v6 cases (e.g., if ND wasn't able to resolve the
d3044 1
a3044 1
	if ((tp->t_flags & (TF_REQ_TSTMP|TF_NOOPT)) == TF_REQ_TSTMP &&
d3058 1
a3058 1
		}
d3174 1
a3174 1
/*
d3197 1
a3197 1
		/*
d3200 1
a3200 1
		 */
d3206 3
a3208 3
		/*
		 * Partial window deflation.  Relies on fact that tp->snd_una
		 * not updated yet.
@


1.100.4.4
log
@sync
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d1235 1
a1237 1
		(void) m_free(am);
d1477 1
a1477 1
		if (todrop > tlen ||
@


1.99
log
@Make preprocessor happier, don't give it untasty tokens at end of input.
Ok millert@@
@
text
@d2916 1
a2916 1
	 * However, do not accept offers under 32 bytes.
@


1.98
log
@Save tdb_remote_auth on the PCB on latching; also save information on
UDP PCB's if the socket is connected.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.97 2001/06/23 18:54:44 angelos Exp $	*/
d2680 1
a2680 1
#endif TCP_SACK
@


1.97
log
@Clear the checksum flags after verification. Also, don't count
checksum errors as hardware checksum packets as well.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.96 2001/06/23 06:03:11 angelos Exp $	*/
d841 6
@


1.96
log
@Keep stats on TCP/UDP hardware checksumming.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.95 2001/06/23 02:27:10 angelos Exp $	*/
d524 2
a525 1
		} else
d527 1
@


1.95
log
@TCP, UDP, IPv4 input hardware checksumming processing; also IPv4
output hardware checksumming. Not tested yet, but should be done
tonight.

Remain to be solved: interactions with bridge, TCP/UDP output
checksumming, interactions of TCP/UDP checksumming with routing
changes.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.94 2001/06/12 10:59:53 angelos Exp $	*/
d515 2
a516 2
			if (m->m_pkthdr.csum & M_TCP_CSUM_IN_BAD ||
			    (ti->ti_sum = in_cksum(m, len)) != 0) {
d520 6
a525 1
		}
@


1.94
log
@IPsec-related socket options; these can be set/removed/retrieved, but
are not taken into consideration in anything just yet.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.93 2001/06/08 03:53:46 angelos Exp $	*/
d514 6
a519 3
		if ((ti->ti_sum = in_cksum(m, len)) != 0) {
			tcpstat.tcps_rcvbadsum++;
			goto drop;
@


1.93
log
@Cut down on include files.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.92 2001/06/05 02:31:36 deraadt Exp $	*/
d737 9
a745 3
			  if (inp->inp_ipsec_auth != NULL) {
			  	newinp->inp_ipsec_auth = inp->inp_ipsec_auth;
				inp->inp_ipsec_auth->ref_count++;
@


1.92
log
@repair copyright notices for NRL & cmetz; cmetz
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.91 2001/05/27 03:55:59 angelos Exp $	*/
a77 1
#include <sys/malloc.h>
a81 2
#include <sys/errno.h>
#include <sys/domain.h>
a97 7
#include <dev/rndvar.h>
#include <machine/stdarg.h>
#include <sys/md5k.h>

#ifdef IPSEC
#include <netinet/ip_ipsp.h>
#endif /* IPSEC */
a100 4
#include <netinet/ip6.h>
#include <netinet6/ip6_var.h>
#include <netinet6/tcpipv6.h>
#include <netinet/icmp6.h>
@


1.91
log
@Also copy the authentication material to the new socket.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.90 2001/05/27 03:16:10 angelos Exp $	*/
d36 37
a72 1
 *	@@(#)tcp_input.c	8.5 (Berkeley) 4/10/94
a73 12

/*
%%% portions-copyright-nrl-95
Portions of this software are Copyright 1995-1998 by Randall Atkinson,
Ronald Lee, Daniel McDonald, Bao Phan, and Chris Winters. All Rights
Reserved. All rights under this copyright have been assigned to the US
Naval Research Laboratory (NRL). The NRL Copyright Notice and License
Agreement Version 1.1 (January 17, 1995) applies to these portions of the
software.
You should have received a copy of the license with this software. If you
didn't get a copy, you may request one from <license@@ipv6.nrl.navy.mil>.
*/
@


1.90
log
@Update pointers to IPsec-related PCB information when allocating new
PCB; store information from the TDB to the PCB, if it's not
initialized, so processed can eventually retrieve it.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.89 2001/05/27 00:39:27 angelos Exp $	*/
d713 1
a713 1
				newinp->inp_ipsec_localid->ref_count++;
d717 1
a717 1
				newinp->inp_ipsec_remoteid->ref_count++;
d721 1
a721 1
				newinp->inp_ipsec_localcred->ref_count++;
d725 5
a729 1
				newinp->inp_ipsec_remotecred->ref_count++;
@


1.89
log
@Use the new IPsec tags.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.88 2001/05/20 08:35:11 angelos Exp $	*/
d703 2
a704 1
			 * from the old pcb.
d711 16
d786 1
d799 1
a799 1
		if (tdb)
d801 12
a812 1
		else { /* Just reset */
@


1.88
log
@Use packet tags instead of tdbi.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.87 2001/05/12 18:35:17 aaron Exp $	*/
d769 1
a769 1
	mtag = m_tag_find(m, PACKET_TAG_IPSEC_DONE, NULL);
@


1.87
log
@Less verbose; angelos@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.86 2001/05/11 17:20:11 aaron Exp $	*/
d395 1
d769 1
d771 2
a772 4
	tdbi = (struct tdb_ident *) m->m_pkthdr.tdbi;
        if (tdbi == NULL)
                tdb = NULL;
        else
d774 2
a775 1

d777 1
a777 1
			tdb, inp);
@


1.86
log
@Check m_pullup() and m_pullup2() return for NULL, not 0; itojun@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.85 2001/05/01 01:13:05 aaron Exp $	*/
a441 1
			printf("extension headers are not allowed\n");
a459 1
			printf("extension headers are not allowed\n");
@


1.85
log
@Typo in comment.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.84 2001/04/04 05:42:57 itojun Exp $	*/
d475 1
a475 1
		if (m == 0) {
d562 1
a562 1
			if ((m = m_pullup2(m, iphlen + off)) == 0) {
@


1.84
log
@do not check ip_mtudisc on IPv6 TCP.
with IPv6 TCP PMTUD is mandatory, compute mss size accordingly.
sync with kame
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.83 2001/03/28 20:03:07 angelos Exp $	*/
d2897 1
a2897 1
 * we are called when we recieve the SYN,ACK from the server.
@


1.83
log
@Allow tdbi's to appear in mbufs throughout the stack; this allows
security properties of the packets to be pushed up to the application
(not done yet). Eventually, this will be turned into a packet
attributes framework.

Make sure tdbi's are free'd/cleared properly whenever drivers (or NFS)
does weird things with mbufs.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.82 2001/02/08 18:46:22 itojun Exp $	*/
a2763 1
#ifdef INET6
a2764 1
#endif
d2813 1
a2813 1
	else if (ip_mtudisc || ifp->if_flags & IFF_LOOPBACK)
d2815 6
d2823 1
a2823 1
		if (IN6_IS_ADDR_V4MAPPED(&inp->inp_faddr6)) {
d2827 1
a2827 1
			if (in_localaddr(d))
d2830 5
a2834 2
			if (in6_localaddr(&inp->inp_faddr6))
				mss = ifp->if_mtu - iphlen - sizeof(struct tcphdr);
a2837 2
	else if (inp && in_localaddr(inp->inp_faddr))
		mss = ifp->if_mtu - iphlen - sizeof(struct tcphdr);
@


1.82
log
@witch raw ip6 socket code from NRL to kame.
makes upgrades/code sharing much easier.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.81 2000/12/13 09:47:08 provos Exp $	*/
a84 2
#define PI_MAGIC 0xdeadbeef  /* XXX the horror! */

a400 6
#ifdef IPSEC
	tdbi = (struct tdb_ident *) m->m_pkthdr.tdbi;
	if (tdbi == (void *) PI_MAGIC)
	        tdbi = NULL;
#endif /* IPSEC */

a420 4
#ifdef IPSEC
	        if (tdbi)
		        free(tdbi, M_TEMP);
#endif /* IPSEC */
a432 4
#ifdef IPSEC
		        if (tdbi)
			        free(tdbi, M_TEMP);
#endif /* IPSEC */
a442 4
#ifdef IPSEC
		        if (tdbi)
			        free(tdbi, M_TEMP);
#endif /* IPSEC */
a452 4
#ifdef IPSEC
			if (tdbi)
			        free(tdbi, M_TEMP);
#endif /* IPSEC */
a461 4
#ifdef IPSEC
		        if (tdbi)
			        free(tdbi, M_TEMP);
#endif /* IPSEC */
a468 4
#ifdef IPSEC
	        if (tdbi)
		        free(tdbi, M_TEMP);
#endif /* IPSEC */
a476 4
#ifdef IPSEC
		        if (tdbi)
			        free(tdbi, M_TEMP);
#endif /* IPSEC */
a563 4
#ifdef IPSEC
				if (tdbi)
			                free(tdbi, M_TEMP);
#endif /* IPSEC */
d764 1
a764 2
			/* Compute proper scaling value from buffer space
			 */
d771 1
d779 11
a791 4
	if (tdbi)
	        free(tdbi, M_TEMP);
	tdbi = NULL;

a2087 5
#ifdef IPSEC
	if (tdbi)
	        free(tdbi, M_TEMP);
#endif

@


1.81
log
@more random tcp sequence numbers. okay deraadt@@, angelos@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.80 2000/12/11 08:04:55 itojun Exp $	*/
a783 2
				inp->inp_fflowinfo =
				    htonl(0x0fffffff) & ipv6->ip6_flow;
@


1.80
log
@nuke #ifdef TCP6 (no longer supported).
validate ICMPv6 too big messages (pmtud) based on pcb.  we accept
certain amount of non-validated ones, as IPv6 mandates ICMPv6 (so even for
traffic from unconnected pcb, we need pmtud).
sync with kame
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.79 2000/10/14 01:04:10 itojun Exp $	*/
d1143 3
a1145 1
		else
a1146 2
#ifdef TCP_COMPAT_42
		tcp_iss += TCP_ISSINCR/2;
d1148 1
a1148 1
		tcp_iss += arc4random() % TCP_ISSINCR + 1;
d1150 1
@


1.79
log
@implement net.inet.tcp.rstppslimit.  rate-limits outbound TCP RST traffic
to less than N per 1 second.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.78 2000/10/11 09:14:11 itojun Exp $	*/
d322 1
a322 1
#if defined(INET6) && !defined(TCP6)
@


1.78
log
@nuke inp_flags bits for controlling IPv4 mapped address.
we don't support IPv4 mapped address,
and there are inconsistent bit manipulation code so it's safer to nuke them.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.77 2000/09/25 09:41:02 provos Exp $	*/
d110 4
d687 1
a687 1
			goto dropwithreset;
d693 1
a693 1
		goto dropwithreset;
d2072 14
@


1.77
log
@on expiry of pmtu route, retry higher mtu. okay angelos@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.76 2000/09/23 01:07:38 chris Exp $	*/
d123 2
a124 3
	if (tp && tp->t_inpcb && (tp->t_inpcb->inp_flags & INP_IPV6) \
	 && !(tp->t_inpcb->inp_flags & INP_IPV6_MAPPED) \
	 && tp->t_inpcb->inp_route6.ro_rt) { \
d764 1
a764 4
			  inp->inp_flags |= (flags & (INP_IPV6 | INP_IPV6_UNDEC
						      | INP_IPV6_MAPPED));
			  if (flags & INP_IPV6_MAPPED)
				panic("unexpected v4 mapped inpcb");
@


1.76
log
@Angelos you forgot this one !!
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.75 2000/09/21 17:30:48 provos Exp $	*/
d2874 4
a2877 2
	if (offer && offer != -1)
		mss = min(mss, offer);
@


1.75
log
@calculate maxopd at the right place
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.74 2000/09/20 17:00:22 provos Exp $	*/
d85 2
a93 2

#define PI_MAGIC 0xdeadbeef  /* XXX the horror! */
@


1.74
log
@correctly calculate mss
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.73 2000/09/19 18:10:59 deraadt Exp $	*/
d2867 12
a2889 12

	/*
	 * The current mss, t_maxseg, is initialized to the default value.
	 * If we compute a smaller value, reduce the current mss.
	 * If we compute a larger value, return it for use in sending
	 * a max seg size option, but don't store it for use
	 * unless we received an offer at least that large from peer.
	 * However, do not accept offers under 32 bytes.
	 */
	if (offer && offer != -1)
		mss = min(mss, offer);
	mss = max(mss, 64);		/* sanity - at least max opt. space */
@


1.73
log
@only free tdbi if IPSEC
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.72 2000/09/19 03:20:59 angelos Exp $	*/
d1767 1
a1767 1
		tp->snd_cwnd = min(cw + incr, TCP_MAXWIN<<tp->snd_scale);
d2223 1
a2223 1
	if (th->th_flags & TH_SYN)
d2225 4
d2776 3
d2785 1
a2785 2
	struct route *ro;
	register struct rtentry *rt;
d2787 1
a2787 2
	register int rtt, mss, mssopt;
	u_long bufsize;
a2792 1
	struct socket *so;
a2794 2
	ro = &inp->inp_route;
	so = inp->inp_socket;
d2796 7
a2802 37
	if ((rt = ro->ro_rt) == (struct rtentry *)0) {
		/* No route yet, so try to acquire one */
#ifdef INET6
		bzero(ro, sizeof(struct route_in6));
#else
		bzero(ro, sizeof(struct route));
#endif
		/*
		 * Get a new IPv6 route if an IPv6 destination, otherwise, get
		 * and IPv4 route (including those pesky IPv4-mapped addresses).
		 */
		switch (sotopf(so)) {
#ifdef INET6
		case AF_INET6:
			if (IN6_IS_ADDR_UNSPECIFIED(&inp->inp_faddr6))
				break;
			ro->ro_dst.sa_family = AF_INET6;
			ro->ro_dst.sa_len = sizeof(struct sockaddr_in6);
			((struct sockaddr_in6 *) &ro->ro_dst)->sin6_addr =
			    inp->inp_faddr6;
			rtalloc(ro);
			break;
#endif /* INET6 */
		case AF_INET:
			if (inp->inp_faddr.s_addr == INADDR_ANY)
				break;
			ro->ro_dst.sa_family = AF_INET;
			ro->ro_dst.sa_len = sizeof(ro->ro_dst);
			satosin(&ro->ro_dst)->sin_addr = inp->inp_faddr;
			rtalloc(ro);
			break;
		}
		if ((rt = ro->ro_rt) == (struct rtentry *)0) {
			tp->t_maxopd = tp->t_maxseg = tcp_mssdflt;
			return (tcp_mssdflt);
		}
	}
a2804 2
	mssopt = mss = tcp_mssdflt;

d2820 1
a2820 28
#ifdef RTV_MTU	/* if route characteristics exist ... */
	/*
	 * While we're here, check if there's an initial rtt
	 * or rttvar.  Convert from the route-table units
	 * to scaled multiples of the slow timeout timer.
	 */
	if (tp->t_srtt == 0 && (rtt = rt->rt_rmx.rmx_rtt)) {
		/*
		 * XXX the lock bit for MTU indicates that the value
		 * is also a minimum value; this is subject to time.
		 */
		if (rt->rt_rmx.rmx_locks & RTV_RTT)
			TCPT_RANGESET(tp->t_rttmin,
			    rtt / (RTM_RTTUNIT / PR_SLOWHZ),
			    TCPTV_MIN, TCPTV_REXMTMAX);
		tp->t_srtt = rtt / (RTM_RTTUNIT / (PR_SLOWHZ * TCP_RTT_SCALE));
		if (rt->rt_rmx.rmx_rttvar)
			tp->t_rttvar = rt->rt_rmx.rmx_rttvar /
			    (RTM_RTTUNIT / (PR_SLOWHZ * TCP_RTTVAR_SCALE));
		else
			/* default variation is +- 1 rtt */
			tp->t_rttvar =
			    tp->t_srtt * TCP_RTTVAR_SCALE / TCP_RTT_SCALE;
		TCPT_RANGESET((long) tp->t_rxtcur,
		    ((tp->t_srtt >> 2) + tp->t_rttvar) >> 1,
		    tp->t_rttmin, TCPTV_REXMTMAX);
	}

d2867 13
d2890 48
d2939 3
a2941 5
	 * maxopd stores the maximum length of data AND options
	 * in a segment; maxseg is the amount of data in a normal
	 * segment.  We need to store this value (maxopd) apart
	 * from maxseg, because now every segment carries options
	 * and thus we normally have somewhat less data in segments.
d2943 22
a2964 5
	tp->t_maxopd = mss;

 	if ((tp->t_flags & (TF_REQ_TSTMP|TF_NOOPT)) == TF_REQ_TSTMP &&
	    (tp->t_flags & TF_RCVD_TSTMP) == TF_RCVD_TSTMP)
		mss -= TCPOLEN_TSTAMP_APPA;
a2965 7
#if	(MCLBYTES & (MCLBYTES - 1)) == 0
		if (mss > MCLBYTES)
			mss &= ~(MCLBYTES-1);
#else
		if (mss > MCLBYTES)
			mss = mss / MCLBYTES * MCLBYTES;
#endif
d2976 1
a2976 1
	if (bufsize < mss)
d2978 3
a2980 1
	else {
a2985 1
	tp->t_maxseg = mss;
a3000 1
	tp->snd_cwnd = mss;
a3012 2

	return (offer != -1 ? mssopt : mss);
@


1.72
log
@Lots and lots of changes.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.71 2000/09/18 23:59:39 fgsch Exp $	*/
d2108 1
d2111 1
@


1.71
log
@fix compilation problem on systems w/o inet6.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.70 2000/09/18 22:06:38 provos Exp $	*/
d93 2
a388 3
#ifdef IPSEC
	struct tdb *tdb = NULL;
#endif /* IPSEC */
d393 5
d400 6
a411 11
#ifdef IPSEC
	/* Save the last SA which was used to process the mbuf */
	if ((m->m_flags & (M_CONF|M_AUTH)) && m->m_pkthdr.tdbi) {
		struct tdb_ident *tdbi = m->m_pkthdr.tdbi;
		/* XXX gettdb() should really be called at spltdb().      */
		/* XXX this is splsoftnet(), currently they are the same. */
		tdb = gettdb(tdbi->spi, &tdbi->dst, tdbi->proto);
		free(m->m_pkthdr.tdbi, M_TEMP);
		m->m_pkthdr.tdbi = NULL;
	}
#endif /* IPSEC */
d426 4
d442 4
d456 4
d470 4
d483 4
d494 4
d506 4
d597 4
d813 16
a828 18
	/* Check if this socket requires security for incoming packets */
	if ((inp->inp_seclevel[SL_AUTH] >= IPSEC_LEVEL_REQUIRE &&
	     !(m->m_flags & M_AUTH)) ||
	    (inp->inp_seclevel[SL_ESP_TRANS] >= IPSEC_LEVEL_REQUIRE &&
	     !(m->m_flags & M_CONF))) {
#ifdef notyet
		switch (af) {
#ifdef INET6
		case AF_INET6:
			icmp6_error(m, ICMPV6_BLAH, ICMPV6_BLAH, 0);
			break;
#endif /* INET6 */
		case AF_INET:
			icmp_error(m, ICMP_BLAH, ICMP_BLAH, 0, 0);
			break;
		}
#endif /* notyet */
		tcpstat.tcps_rcvnosec++;
d830 1
a830 5
	}
	/* Use tdb_bind_out for this inp's outbound communication */
	if (tdb)
		tdb_add_inp(tdb, inp);
#endif /*IPSEC */
d2108 3
@


1.70
log
@Path MTU discovery based on NetBSD but with the decision to use the DF
flag delayed to ip_output().  That halves the code and reduces most of
the route lookups. okay deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.69 2000/09/05 21:57:41 provos Exp $	*/
d2753 4
a2756 1
	int iphlen, is_ipv6 = 0;
@


1.69
log
@various fixes to SACK and FACK from adesai@@cisco.com, tomh@@tomh.org and
osuga@@mml.yrp.nttdocomo.co.jp
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.68 2000/07/27 04:05:26 itojun Exp $	*/
d2746 1
a2746 1
	u_int offer;
d2751 1
a2751 1
	register int rtt, mss;
d2753 1
d2800 17
d2844 1
a2848 7
	/*
	 * XXX It's wrong to use PMTU values to determine the MSS we
	 * are going to advertise; we should only use the input interface's
	 * MTU instead (see draft-ietf-tcpimpl-pmtud-03.txt). tcp_mss()
	 * should be changed to be aware whether it's called for input or
	 * output MSS calculation, and act accordingly.
	 */
d2854 1
a2854 17
		mss = rt->rt_rmx.rmx_mtu - sizeof(struct tcphdr);
		switch (tp->pf) {
#ifdef INET6
		case AF_INET6:
			mss -= sizeof(struct ip6_hdr);
			break;
#endif
#ifdef notdef	/* no IPv4 path MTU discovery yet */
		case AF_INET:
			mss -= sizeof(struct ip);
			break;
#endif
		default:
			/* the family does not support path MTU discovery */
			mss = 0;
			break;
		}
a2855 3
		mss = 0;
#else
	mss = 0;
d2857 1
a2857 1
	if (mss == 0) {
d2863 14
a2876 6
		mss = ifp ? ifp->if_mtu - sizeof(struct tcpiphdr) : 0;
		switch (tp->pf) {
		case AF_INET:
			if (!in_localaddr(inp->inp_faddr))
				mss = min(mss, tcp_mssdflt);
			break;
d2879 11
d2898 1
a2898 1
	if (offer)
d2968 2
a2969 1
	return (mss);
@


1.68
log
@be proactive about unspecified IPv6 source address.  pcb layer uses
unspecified address (::) to mean "unbounded" or "unconnected",
and can be confused by packets from outside.

use of :: as source is not documented well in IPv6 specification.

not sure if it presents a real threat.  the worst case scenario is a DoS
against TCP listening socket:
- outsider transmit TCP SYN with :: as IPv6 source
- receiving side creates TCP control block with:
	local address = my addres
	remote address = ::	(meaning "unconnected")
	state = SYN_RCVD
  note that SYN ACK will not be sent due to ip6_output() filter.
  this stays until it timeouts.
- the TCP control block prevents listening TCP control block from
  being contacted (DoS).
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.67 2000/07/11 16:53:22 provos Exp $	*/
a1565 1
						tp->snd_cwnd += tp->t_maxseg;
a1566 1
						(void) tcp_output(tp); 
d1582 1
a1588 1
						tp->t_dupacks = tcprexmtthresh;
d1664 1
a1664 1
					           th->th_ack) + tp->t_maxseg;
d1681 1
a1681 1
					    th->th_ack) + tp->t_maxseg;
d1740 1
a1740 1
		if (SEQ_GEQ(th->th_ack, tp->snd_last)) 
d1760 1
a1760 1
		if (SEQ_GT(tp->snd_una, tp->snd_fack))
d1762 6
d2553 2
d2597 5
a2601 1
		tp->snd_cwnd -= (th->th_ack - tp->snd_una - tp->t_maxseg);
@


1.67
log
@compute correct window scale when recvpipe option is set in route; based
on diff from "Pete Kazmier" <pete@@kazmier.com>
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.66 2000/07/09 12:53:55 itojun Exp $	*/
d525 13
@


1.66
log
@be more cautious about tcp option length field.  drop bogus ones earlier.
not sure if there is a real threat or not, but it seems that there's
possibility for overrun/underrun (like non-NOP option with optlen > cnt).
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.65 2000/07/06 10:31:10 fgsch Exp $	*/
d764 1
a764 3
			while (tp->request_r_scale < TCP_MAX_WINSHIFT &&
			   TCP_MAXWIN << tp->request_r_scale < so->so_rcv.sb_hiwat)
				tp->request_r_scale++;
d2915 4
@


1.65
log
@Move domain.h above so this compiles again.
Remove netinet.h within ifdef INET6; this is already included.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.64 2000/07/06 10:11:22 itojun Exp $	*/
d2113 2
d2116 1
a2116 1
			if (optlen <= 0)
@


1.64
log
@- more icmp6/ip6 stats.
- protect IPv6 ND from being hosed (due to neighbor unreachability detection
  hint) by wrong tcp traffic.  still not sure if there's real attack, but
  it is good to be cautious.
- avoid bitfield for router renumbering header decl.
- implement packet-per-sec limitation for icmp6 errors, turn interval
  limit off (it is not very useful due to unix timer resolution).
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.63 2000/07/06 05:24:45 itojun Exp $	*/
d60 1
a85 4
#ifndef INET
#include <netinet/in.h>
#endif
#include <sys/domain.h>
@


1.63
log
@completely remove ipv4 mapped cases from tcp_input().
cleanup (indentation, v4-or-v6 conditions)
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.62 2000/07/05 22:51:09 itojun Exp $	*/
d127 1
a127 1
		nd6_nud_hint(tp->t_inpcb->inp_route6.ro_rt, NULL); \
@


1.62
log
@more cleanup for IPv4 mapped address support.  there seem to be some
inconsistency in corner cases (from NRL I believe).
todd (fries) and I have seen panic, with the following call chain:
ip6_input -> tcp_input -> tcp_respond -> ip_input -> bang!

more cleanups should be done, to decrease complexity.
for example, INP_IPV6_MAPPED should be nuked.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.61 2000/05/15 03:38:40 angelos Exp $	*/
a95 9
#ifndef CREATE_IPV6_MAPPED
#define CREATE_IPV6_MAPPED(a6, a4) \
do { \
	bzero(&(a6), sizeof(a6));			\
	(a6).s6_addr[10] = (a6).s6_addr[11] = 0xff;	\
	*(u_int32_t *)&(a6).s6_addr[12] = (a4);		\
} while (0)
#endif

d169 1
a169 1
	MALLOC(tiqe, struct ipqent *, sizeof (struct ipqent), M_IPQ, M_NOWAIT);
d370 1
a370 1
	register struct tcpiphdr *ti;
a394 1
	unsigned short is_ipv6;     /* Type of incoming datagram. */
d397 1
a415 1
#ifdef INET6
d420 13
a432 2
	is_ipv6 = mtod(m, struct ip *)->ip_v == 6;
#endif /* INET6 */
d438 9
a446 6
#ifndef INET6
	ti = mtod(m, struct tcpiphdr *);
#else /* INET6 */
	if (!is_ipv6)
#endif /* INET6 */
	if (iphlen > sizeof (struct ip)) {
d448 2
a449 1
		ip_stripoptions(m, (struct mbuf *)0);
d451 27
a477 1
		printf("extension headers are not allowed\n");
a479 1
#endif
d481 1
d483 2
a484 1
		if ((m = m_pullup2(m, iphlen + sizeof(struct tcphdr))) == 0) {
a487 3
#ifndef INET6
		ti = mtod(m, struct tcpiphdr *);
#endif /* INET6 */
d490 1
a490 2
	tlen = m->m_pkthdr.len - iphlen;

d492 10
a501 17
	/*
	 * After that, do initial segment processing which is still very
	 * dependent on what IP version you're using.
	 */

	if (is_ipv6) {
#ifdef DIAGNOSTIC
	  if (iphlen < sizeof(struct ip6_hdr)) {
	    m_freem(m);
	    return;
	  }
#endif /* DIAGNOSTIC */

	  /* strip off any options */
	  if (iphlen > sizeof(struct ip6_hdr)) {
#if 0 /*XXX*/
	    ipv6_stripoptions(m, iphlen);
d503 1
a503 3
		printf("extension headers are not allowed\n");
		m_freem(m);
		return;
d505 1
a505 2
	    iphlen = sizeof(struct ip6_hdr);
	  }
d507 17
a523 2
	  ti = NULL;
	  ipv6 = mtod(m, struct ip6_hdr *);
d532 9
a540 21
	  if (in6_cksum(m, IPPROTO_TCP, sizeof(struct ip6_hdr), tlen)) {
	    tcpstat.tcps_rcvbadsum++;
	    goto drop;
	  } /* endif in6_cksum */
	} else {
	  ti = mtod(m, struct tcpiphdr *);
#endif /* INET6 */

	/*
	 * Checksum extended TCP header and data.
	 */
#ifndef INET6
	tlen = ((struct ip *)ti)->ip_len;
#endif /* INET6 */
	len = sizeof (struct ip) + tlen;
	bzero(ti->ti_x1, sizeof ti->ti_x1);
	ti->ti_len = (u_int16_t)tlen;
	HTONS(ti->ti_len);
	if ((ti->ti_sum = in_cksum(m, len)) != 0) {
		tcpstat.tcps_rcvbadsum++;
		goto drop;
a541 3
#ifdef INET6
	}
#endif /* INET6 */
d551 1
a551 1
	if (off < sizeof (struct tcphdr) || off > tlen) {
d556 1
a556 1
	if (off > sizeof (struct tcphdr)) {
d562 4
d567 5
a571 5
			if (is_ipv6)
			  ipv6 = mtod(m, struct ip6_hdr *);
			else
#endif /* INET6 */
			ti = mtod(m, struct tcpiphdr *);
d574 1
a574 1
		optlen = off - sizeof (struct tcphdr);
d608 1
d610 10
a619 7
	if (is_ipv6) {
	  inp = in6_pcbhashlookup(&tcbtable, &ipv6->ip6_src, th->th_sport,
				 &ipv6->ip6_dst, th->th_dport);
	} else
#endif /* INET6 */
	inp = in_pcbhashlookup(&tcbtable, ti->ti_src, ti->ti_sport,
	    ti->ti_dst, ti->ti_dport);
d622 1
d624 1
a624 1
		if (is_ipv6)
d628 1
a628 1
		else
d630 5
a634 2
		inp = in_pcblookup(&tcbtable, &ti->ti_src, ti->ti_sport,
		    &ti->ti_dst, ti->ti_dport, INPLOOKUP_WILDCARD);
d663 1
d665 8
a672 5
			if (is_ipv6)
			  tcp_saveti6 = *(mtod(m, struct tcpipv6hdr *));
			else
#endif /* INET6 */
			tcp_saveti = *ti;
d726 3
a728 2
			  if ((inp->inp_flags & INP_IPV6) &&
			      !(inp->inp_flags & INP_IPV6_MAPPED)) {
d739 1
d741 14
a754 16
			if (is_ipv6) {
			  inp->inp_laddr6 = ipv6->ip6_dst;
			  inp->inp_fflowinfo = htonl(0x0fffffff) & 
			    ipv6->ip6_flow;
			  
			  /*inp->inp_options = ip6_srcroute();*/ /* soon. */
			  /* still need to tweak outbound options
			     processing to include this mbuf in
			     the right place and put the correct
			     NextHdr values in the right places.
			     XXX  rja */
			} else {
			  if (inp->inp_flags & INP_IPV6) {/* v4 to v6 socket */
			    CREATE_IPV6_MAPPED(inp->inp_laddr6,
			      ti->ti_dst.s_addr);
			  } else {
d756 4
a759 4
			    inp->inp_laddr = ti->ti_dst;
			    inp->inp_options = ip_srcroute();
#if INET6
			  }
a760 1
#endif /* INET6 */
d780 1
d782 1
a782 1
		if (is_ipv6)
d784 1
a784 1
		else
d786 4
a789 1
		icmp_error(m, ICMP_BLAH, ICMP_BLAH, 0, 0);
d993 1
d995 5
a999 9
		  if (is_ipv6) {
		    if (IN6_ARE_ADDR_EQUAL(&ipv6->ip6_src, &ipv6->ip6_dst))
		      goto drop;
		  } else {
#endif /* INET6 */
		    if (ti->ti_dst.s_addr == ti->ti_src.s_addr)
		      goto drop;
#ifdef INET6
		  }
d1001 5
d1014 2
a1015 1
		  goto drop;
d1017 1
a1017 1
		if (is_ipv6) {
d1021 1
a1021 1
		} else
d1023 5
a1027 2
		if (IN_MULTICAST(ti->ti_dst.s_addr))
			goto drop;
d1031 1
d1033 1
a1033 1
		if (is_ipv6) {
d1062 1
a1062 1
		} else
d1064 1
a1064 1
		{
d1070 1
a1070 1
			am->m_len = sizeof (struct sockaddr_in);
d1074 2
a1075 2
			sin->sin_addr = ti->ti_src;
			sin->sin_port = ti->ti_sport;
d1079 1
a1079 1
				inp->inp_laddr = ti->ti_dst;
d1086 1
d1229 1
a1229 1
		 * Advance ti->ti_seq to correspond to first data byte.
a1396 3
#ifndef INET6
		if (ti->ti_seq != tp->last_ack_sent)
#else
a1397 1
#endif
d1470 2
a1471 2
	 *	tp->snd_una < ti->ti_ack <= tp->snd_max
	 * then advance tp->snd_una to ti->ti_ack and drop
d2043 2
a2044 1
	  goto drop;
d2046 5
a2050 6
	if (is_ipv6) {
	  /* For following calls to tcp_respond */
	  ti = mtod(m, struct tcpiphdr *);
	  if (IN6_IS_ADDR_MULTICAST(&ipv6->ip6_dst))
	    goto drop;
	} else {
d2052 3
a2054 3
	    if (IN_MULTICAST(ti->ti_dst.s_addr))
	      goto drop;
#ifdef INET6
d2056 4
a2059 4
#endif /* INET6 */
	if (tiflags & TH_ACK)
		tcp_respond(tp, (caddr_t) ti, m, (tcp_seq)0, th->th_ack, TH_RST);
	else {
d2062 2
a2063 2
		tcp_respond(tp, (caddr_t) ti, m, th->th_seq+tlen, (tcp_seq)0,
		    TH_RST|TH_ACK);
d2743 19
a2761 21
	  /*
	   * Get a new IPv6 route if an IPv6 destination, otherwise, get
	   * and IPv4 route (including those pesky IPv4-mapped addresses).
	   */
	  bzero(ro,sizeof(struct route_in6));
	  if (sotopf(so) == AF_INET6) {
	    if (IN6_IS_ADDR_V4MAPPED(&inp->inp_faddr6)) {
	      /* Get an IPv4 route. */
	      ro->ro_dst.sa_family = AF_INET;
	      ro->ro_dst.sa_len = sizeof(ro->ro_dst);
	      ((struct sockaddr_in *) &ro->ro_dst)->sin_addr =
		inp->inp_faddr;
	      rtalloc(ro);
	    } else {
	      ro->ro_dst.sa_family = AF_INET6;
	      ro->ro_dst.sa_len = sizeof(struct sockaddr_in6);
	      ((struct sockaddr_in6 *) &ro->ro_dst)->sin6_addr =
		inp->inp_faddr6;
	      rtalloc(ro);
	    }
	  } else
d2763 3
a2765 1
		if (inp->inp_faddr.s_addr != INADDR_ANY) {
d2770 1
d2975 2
a2976 2
    }
    return 0;
@


1.61
log
@Add comment on input MSS calculation based on previous PMTUD results,
as per TCP-imply IETF WG draft(s). The correct approach is to just use
the relevant interface's MTU.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.60 2000/04/28 00:31:48 itojun Exp $	*/
d990 51
a1040 81
		  /*
		   * This is probably the place to set the tp->pf value.
		   * (Don't forget to do it in the v4 code as well!)
		   *
		   * Also, remember to blank out things like flowlabel, or
		   * set flowlabel for accepted sockets in v6.
		   *
		   * FURTHERMORE, this is PROBABLY the place where the whole
		   * business of key munging is set up for passive
		   * connections.
		   */
		  am->m_len = sizeof(struct sockaddr_in6);
		  sin6 = mtod(am, struct sockaddr_in6 *);
		  sin6->sin6_family = AF_INET6;
		  sin6->sin6_len = sizeof(struct sockaddr_in6);
		  sin6->sin6_addr = ipv6->ip6_src;
		  sin6->sin6_port = th->th_sport;
		  sin6->sin6_flowinfo = htonl(0x0fffffff) &
		    inp->inp_ipv6.ip6_flow;
		  laddr6 = inp->inp_laddr6;
		  if (IN6_IS_ADDR_UNSPECIFIED(&inp->inp_laddr6))
		    inp->inp_laddr6 = ipv6->ip6_dst;
		  /* This is a good optimization. */
		  if (in6_pcbconnect(inp, am)) {
		    inp->inp_laddr6 = laddr6;
		    (void) m_free(am);
		    goto drop;
		  } /* endif in6_pcbconnect() */
		  tp->pf = PF_INET6;
		} else {
		  /*
		   * Letting v4 incoming datagrams to reach valid 
		   * PF_INET6 sockets causes some overhead here.
		   */
		  if (inp->inp_flags & INP_IPV6) {
		    if (!(inp->inp_flags & (INP_IPV6_UNDEC|INP_IPV6_MAPPED))) {
		      (void) m_free(am);
		      goto drop;
		    }

		    am->m_len = sizeof(struct sockaddr_in6);
		    
		    sin6 = mtod(am, struct sockaddr_in6 *);
		    sin6->sin6_family = AF_INET6;
		    sin6->sin6_len = sizeof(*sin6);
		    CREATE_IPV6_MAPPED(sin6->sin6_addr, ti->ti_src.s_addr);
		    sin6->sin6_port = th->th_sport;
		    sin6->sin6_flowinfo = 0;

		    laddr6 = inp->inp_laddr6;
		    if (inp->inp_laddr.s_addr == INADDR_ANY)
		      CREATE_IPV6_MAPPED(inp->inp_laddr6, ti->ti_dst.s_addr);
		    
		    /*
		     * The pcb initially has the v6 default hoplimit
		     * set. We're sending v4 packets so we need to set
		     * the v4 ttl and tos.
		     */
		    inp->inp_ip.ip_ttl = ip_defttl;
		    inp->inp_ip.ip_tos = 0;
		    
		    if (in6_pcbconnect(inp, am)) {
		      inp->inp_laddr6 = laddr6;
		      (void) m_freem(am);
		      goto drop;
		    }
		    tp->pf = PF_INET;
		  } else { 
#endif /* INET6 */
		am->m_len = sizeof (struct sockaddr_in);
		sin = mtod(am, struct sockaddr_in *);
		sin->sin_family = AF_INET;
		sin->sin_len = sizeof(*sin);
		sin->sin_addr = ti->ti_src;
		sin->sin_port = ti->ti_sport;
		bzero((caddr_t)sin->sin_zero, sizeof(sin->sin_zero));
		laddr = inp->inp_laddr;
		if (inp->inp_laddr.s_addr == INADDR_ANY)
			inp->inp_laddr = ti->ti_dst;
		if (in_pcbconnect(inp, am)) {
			inp->inp_laddr = laddr;
a1041 1
			goto drop;
a1042 6
		(void) m_free(am);
		tp->pf = PF_INET;
#ifdef INET6
		  }  /* if (inp->inp_flags & INP_IPV6) */
		} /* if (is_ipv6) */
#endif /* INET6 */
d1961 1
d1963 4
a1966 3
		if (tp->pf == PF_INET6)
			tcp_trace(TA_INPUT, ostate, tp, (caddr_t) &tcp_saveti6, 0, tlen);
		else
d1968 5
a1972 1
			tcp_trace(TA_INPUT, ostate, tp, (caddr_t) &tcp_saveti, 0, tlen);
d2034 1
d2036 4
a2039 3
	  if (tp->pf == PF_INET6)
	    tcp_trace(TA_DROP, ostate, tp, (caddr_t) &tcp_saveti6, 0, tlen);
	  else
d2041 5
a2045 1
	    tcp_trace(TA_DROP, ostate, tp, (caddr_t) &tcp_saveti, 0, tlen);
@


1.60
log
@actually m_adj tries to drop tcp header part.  it is better to
touch tcp header before m_adj, than the other way around.
(no behavior change with the current m_adj code, new code is safer against
any future m_adj changes)
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.59 2000/04/27 20:53:08 provos Exp $	*/
d2792 7
@


1.59
log
@mbuf is freed by sbappend(), move the references to th up. found by art@@
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.58 2000/04/14 04:20:57 itojun Exp $	*/
a895 1
			m_adj(m, iphlen + off);
d900 1
@


1.58
log
@for layer 3 protocols that does not support path MTU discovery
(I mean, IPv4) do not try to use rmx_mtu on routing table.
this symptom was introduced by rmx_mtu initialization (necessary for IPv6
path MTU discovery) in net/route.c.  now prior behavior is recovered.
From: Hugh Graham <hugh@@openbsd.org>

there are several question about mssdflt semantics, though:

Question 1: with the current code, mssdflt does not override rmx_mtu value
(mssdflt overrides interface mtu only).  should we override rmx_mtu by
mssdflt as well?

Question 2: with the current code, mssdflt overrides mss computed from
if mtu, only when the destination is IPv4 non-local.  is it safe enough?
we may want to use mssdflt, whenever we are uncertain.
mss = if mtu - hdrsiz;
if (IPv4 non-local destination)
	mss = min(mss, mssdflt);
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.57 2000/02/21 21:42:13 provos Exp $	*/
a896 2
			sbappend(&so->so_rcv, m);
			sorwakeup(so);
d901 2
@


1.57
log
@TCP SACK fixes via Tom Henderson (tomh@@cs.berkeley.edu):
- tcp_sack_adjust() was completely rewritten, since it was erroneously
referencing receiver side sequence numbers and comparing with sender
side sequence numbers (thanks to Arun Desai (adesai@@cisco.com) who
discovered the problem)
- in tcp_output(), moved assignment of sendalot=0 to the piece of code
immediately following the search for sack-eligible retransmissions
(bug identified by Arun Desai).
- tcp_input() was not clearing t_dupacks if fewer than three dupacks arrived
between acks of new data. (bug identified by Gaurav Banga (gaurav@@netapp.com))
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.56 1999/12/21 17:49:28 provos Exp $	*/
d2790 2
a2791 1
	 * if there's an mtu associated with the route, use it
d2793 7
a2799 1
	if (rt->rt_rmx.rmx_mtu)
d2801 18
a2818 14
	{
	  /*
	   * One may wish to lower MSS to take into account options,
	   * especially security-related options.
	   */
	  if (tp->pf == AF_INET6) 
	    mss = rt->rt_rmx.rmx_mtu - sizeof(struct tcpipv6hdr);
	  else
#endif /* INET6 */
		mss = rt->rt_rmx.rmx_mtu - sizeof(struct tcpiphdr);
#ifdef INET6
	}
#endif /* INET6 */
	else
d2820 6
a2825 6
	{
	  /*
	   *  ifp may be null and rmx_mtu may be zero in certain
	   *  v6 cases (e.g., if ND wasn't able to resolve the 
	   *  destination host.
	   */
d2827 6
a2832 5
#ifdef INET6
		if (tp->pf == AF_INET)
#endif /* INET6 */
		if (!in_localaddr(inp->inp_faddr))
			mss = min(mss, tcp_mssdflt);
@


1.56
log
@option TCP_NEWRENO goes away, its the default case for TCP_SACK if
SACK is disabled for the connection or via sysctl
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.55 1999/12/21 15:41:07 itojun Exp $	*/
d1675 2
@


1.56.2.1
log
@Sync with -current
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
a1674 2
		if (tp->t_dupacks < tcprexmtthresh)
			tp->t_dupacks = 0;
@


1.56.2.2
log
@merge in approximately 2.9 into SMP branch
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.84 2001/04/04 05:42:57 itojun Exp $	*/
a59 1
#include <sys/domain.h>
d85 4
d96 9
a119 4
int tcp_rst_ppslim = 100;		/* 100pps */
int tcp_rst_ppslim_count = 0;
struct timeval tcp_rst_ppslim_last;

d133 4
a136 3
	if (tp && tp->t_inpcb && (tp->t_inpcb->inp_flags & INP_IPV6) && \
	    tp->t_inpcb->inp_route6.ro_rt) { \
		nd6_nud_hint(tp->t_inpcb->inp_route6.ro_rt, NULL, 0); \
d178 1
a178 1
	MALLOC(tiqe, struct ipqent *, sizeof(struct ipqent), M_IPQ, M_NOWAIT);
d329 1
a329 1
#ifdef INET6
d379 1
a379 1
	struct ip *ip;
d399 3
d404 1
a406 6
#ifdef IPSEC
	struct tdb_ident *tdbi;
	struct tdb *tdb;
	int error, s;
#endif /* IPSEC */
	int af;
d414 12
d430 2
a431 13
	switch (mtod(m, struct ip *)->ip_v) {
#ifdef INET6
	case 6:
		af = AF_INET6;
		break;
#endif
	case 4:
		af = AF_INET;
		break;
	default:
		m_freem(m);
		return;	/*EAFNOSUPPORT*/
	}
d437 6
a442 9
	switch (af) {
	case AF_INET:
#ifdef DIAGNOSTIC
		if (iphlen < sizeof(struct ip)) {
			m_freem(m);
			return;
		}
#endif /* DIAGNOSTIC */
		if (iphlen > sizeof(struct ip)) {
d444 1
a444 21
			ip_stripoptions(m, (struct mbuf *)0);
			iphlen = sizeof(struct ip);
#else
			printf("extension headers are not allowed\n");
			m_freem(m);
			return;
#endif
		}
		break;
#ifdef INET6
	case AF_INET6:
#ifdef DIAGNOSTIC
		if (iphlen < sizeof(struct ip6_hdr)) {
			m_freem(m);
			return;
		}
#endif /* DIAGNOSTIC */
		if (iphlen > sizeof(struct ip6_hdr)) {
#if 0 /*XXX*/
			ipv6_stripoptions(m, iphlen);
			iphlen = sizeof(struct ip6_hdr);
d446 1
a446 8
			printf("extension headers are not allowed\n");
			m_freem(m);
			return;
#endif
		}
		break;
#endif
	default:
d449 1
a450 1

d452 1
a452 2
		m = m_pullup2(m, iphlen + sizeof(struct tcphdr));
		if (m == 0) {
d456 3
d461 2
a462 1
	ip = NULL;
d464 17
a480 10
	ipv6 = NULL;
#endif
	switch (af) {
	case AF_INET:
	    {
		struct tcpiphdr *ti;

		ip = mtod(m, struct ip *);
#if 1
		tlen = m->m_pkthdr.len - iphlen;
d482 3
a484 1
		tlen = ((struct ip *)ti)->ip_len;
d486 2
a487 1
		ti = mtod(m, struct tcpiphdr *);
d489 2
a490 17
		/*
		 * Checksum extended TCP header and data.
		 */
		len = sizeof(struct ip) + tlen;
		bzero(ti->ti_x1, sizeof ti->ti_x1);
		ti->ti_len = (u_int16_t)tlen;
		HTONS(ti->ti_len);
		if ((ti->ti_sum = in_cksum(m, len)) != 0) {
			tcpstat.tcps_rcvbadsum++;
			goto drop;
		}
		break;
	    }
#ifdef INET6
	case AF_INET6:
		ipv6 = mtod(m, struct ip6_hdr *);
		tlen = m->m_pkthdr.len - iphlen;
d499 7
a505 12
		/*
		 * Be proactive about unspecified IPv6 address in source.
		 * As we use all-zero to indicate unbounded/unconnected pcb,
		 * unspecified IPv6 address can be used to confuse us.
		 *
		 * Note that packets with unspecified IPv6 destination is
		 * already dropped in ip6_input.
		 */
		if (IN6_IS_ADDR_UNSPECIFIED(&ipv6->ip6_src)) {
			/* XXX stat */
			goto drop;
		}
d507 15
a521 9
		/*
		 * Checksum extended TCP header and data.
		 */
		if (in6_cksum(m, IPPROTO_TCP, sizeof(struct ip6_hdr), tlen)) {
			tcpstat.tcps_rcvbadsum++;
			goto drop;
		}
		break;
#endif
d523 1
d533 1
a533 1
	if (off < sizeof(struct tcphdr) || off > tlen) {
d538 1
a538 1
	if (off > sizeof(struct tcphdr)) {
a543 4
			switch (af) {
			case AF_INET:
				ip = mtod(m, struct ip *);
				break;
d545 5
a549 5
			case AF_INET6:
				ipv6 = mtod(m, struct ip6_hdr *);
				break;
#endif
			}
d552 1
a552 1
		optlen = off - sizeof(struct tcphdr);
a585 1
	switch (af) {
d587 7
a593 10
	case AF_INET6:
		inp = in6_pcbhashlookup(&tcbtable, &ipv6->ip6_src, th->th_sport,
		    &ipv6->ip6_dst, th->th_dport);
		break;
#endif
	case AF_INET:
		inp = in_pcbhashlookup(&tcbtable, ip->ip_src, th->th_sport,
		    ip->ip_dst, th->th_dport);
		break;
	}
a595 1
		switch (af) {
d597 1
a597 1
		case AF_INET6:
d601 1
a601 1
			break;
d603 2
a604 5
		case AF_INET:
			inp = in_pcblookup(&tcbtable, &ip->ip_src, th->th_sport,
			    &ip->ip_dst, th->th_dport, INPLOOKUP_WILDCARD);
			break;
		}
d613 1
a613 1
			goto dropwithreset_ratelim;
d619 1
a619 1
		goto dropwithreset_ratelim;
a632 1
			switch (af) {
d634 5
a638 8
			case AF_INET6:
				tcp_saveti6 = *(mtod(m, struct tcpipv6hdr *));
				break;
#endif
			case AF_INET:
				tcp_saveti = *(mtod(m, struct tcpiphdr *));
				break;
			}
d690 4
a693 2
			  inp->inp_flags |= (flags & INP_IPV6);
			  if ((inp->inp_flags & INP_IPV6) != 0) {
a703 1
			switch (af) {
d705 16
a720 12
			case AF_INET6:
				inp->inp_laddr6 = ipv6->ip6_dst;
				
				/*inp->inp_options = ip6_srcroute();*/ /* soon. */
				/*
				 * still need to tweak outbound options
				 * processing to include this mbuf in
				 * the right place and put the correct
				 * NextHdr values in the right places.
				 * XXX  rja
				 */
				break;
d722 4
a725 4
			case AF_INET:
				inp->inp_laddr = ip->ip_dst;
				inp->inp_options = ip_srcroute();
				break;
d727 1
d732 5
a736 2
			/* Compute proper scaling value from buffer space */
			tcp_rscale(tp, so->so_rcv.sb_hiwat);
d741 15
a755 19
        s = splnet();
	tdbi = (struct tdb_ident *) m->m_pkthdr.tdbi;
        if (tdbi == NULL)
                tdb = NULL;
        else
	        tdb = gettdb(tdbi->spi, &tdbi->dst, tdbi->proto);

	ipsp_spd_lookup(m, af, iphlen, &error, IPSP_DIRECTION_IN,
			tdb, inp);

	/* Latch SA */
	if (inp->inp_tdb_in != tdb) {
		if (tdb)
		        tdb_add_inp(tdb, inp, 1);
		else { /* Just reset */
		        TAILQ_REMOVE(&inp->inp_tdb_in->tdb_inp_in, inp,
				     inp_tdb_in_next);
			inp->inp_tdb_in = NULL;
		}
d757 4
a760 6
        splx(s);

	/* Error or otherwise drop-packet indication */
	if (error)
		goto drop;
#endif /* IPSEC */
d896 3
a902 3
			m_adj(m, iphlen + off);
			sbappend(&so->so_rcv, m);
			sorwakeup(so);
a955 1
			switch (af) {
d957 9
a965 5
			case AF_INET6:
				if (IN6_ARE_ADDR_EQUAL(&ipv6->ip6_src,
				    &ipv6->ip6_dst))
					goto drop;
				break;
a966 5
			case AF_INET:
				if (ip->ip_dst.s_addr == ip->ip_src.s_addr)
					goto drop;
				break;
			}
d975 1
a975 2
			goto drop;
		switch (af) {
d977 1
a977 1
		case AF_INET6:
d981 1
a981 1
			break;
d983 2
a984 5
		case AF_INET:
			if (IN_MULTICAST(ip->ip_dst.s_addr))
				goto drop;
			break;
		}
a987 1
		switch (af) {
d989 82
a1070 52
		case AF_INET6:
			/*
			 * This is probably the place to set the tp->pf value.
			 * (Don't forget to do it in the v4 code as well!)
			 *
			 * Also, remember to blank out things like flowlabel, or
			 * set flowlabel for accepted sockets in v6.
			 *
			 * FURTHERMORE, this is PROBABLY the place where the
			 * whole business of key munging is set up for passive
			 * connections.
			 */
			am->m_len = sizeof(struct sockaddr_in6);
			sin6 = mtod(am, struct sockaddr_in6 *);
			sin6->sin6_family = AF_INET6;
			sin6->sin6_len = sizeof(struct sockaddr_in6);
			sin6->sin6_addr = ipv6->ip6_src;
			sin6->sin6_port = th->th_sport;
			sin6->sin6_flowinfo = htonl(0x0fffffff) &
				inp->inp_ipv6.ip6_flow;
			laddr6 = inp->inp_laddr6;
			if (IN6_IS_ADDR_UNSPECIFIED(&inp->inp_laddr6))
				inp->inp_laddr6 = ipv6->ip6_dst;
			/* This is a good optimization. */
			if (in6_pcbconnect(inp, am)) {
				inp->inp_laddr6 = laddr6;
				(void) m_free(am);
				goto drop;
			}
			break;
#endif
		case AF_INET:
			/* drop IPv4 packet to AF_INET6 socket */
			if (inp->inp_flags & INP_IPV6) {
				(void) m_free(am);
				goto drop;
			}
			am->m_len = sizeof(struct sockaddr_in);
			sin = mtod(am, struct sockaddr_in *);
			sin->sin_family = AF_INET;
			sin->sin_len = sizeof(*sin);
			sin->sin_addr = ip->ip_src;
			sin->sin_port = th->th_sport;
			bzero((caddr_t)sin->sin_zero, sizeof(sin->sin_zero));
			laddr = inp->inp_laddr;
			if (inp->inp_laddr.s_addr == INADDR_ANY)
				inp->inp_laddr = ip->ip_dst;
			if (in_pcbconnect(inp, am)) {
				inp->inp_laddr = laddr;
				(void) m_free(am);
				goto drop;
			}
d1072 1
a1072 1
			break;
d1074 6
d1102 2
a1103 1
		else {
d1105 1
a1105 2
			tcp_iss += TCP_ISSINCR/2;
			tp->iss = tcp_iss;
d1107 1
a1107 1
			tp->iss = tcp_rndiss_next();
a1108 1
		}
d1221 1
a1221 1
		 * Advance th->th_seq to correspond to first data byte.
d1389 3
d1393 1
d1466 2
a1467 2
	 *	tp->snd_una < th->th_ack <= tp->snd_max
	 * then advance tp->snd_una to th->th_ack and drop
d1554 1
d1556 1
a1571 1
						tp->t_dupacks = tcprexmtthresh;
d1578 1
d1654 1
a1654 1
					           th->th_ack);
d1671 1
a1671 1
					    th->th_ack);
d1730 1
a1730 1
		if (tp->t_dupacks < tcprexmtthresh)
d1732 1
a1732 1
		tp->snd_cwnd = ulmin(cw + incr, TCP_MAXWIN<<tp->snd_scale);
d1750 1
a1750 1
		if (SEQ_GT(tp->snd_una, tp->snd_fack)) {
a1751 6
			/* Update snd_awnd for partial ACK
			 * without any SACK blocks.
			 */
			tp->snd_awnd = tcp_seq_subtract(tp->snd_nxt,
				tp->snd_fack) + tp->retran_data;
		}
a1997 1
		switch (tp->pf == PF_INET6) {
d1999 3
a2001 4
		case PF_INET6:
			tcp_trace(TA_INPUT, ostate, tp, (caddr_t) &tcp_saveti6,
			    0, tlen);
			break;
d2003 1
a2003 5
		case PF_INET:
			tcp_trace(TA_INPUT, ostate, tp, (caddr_t) &tcp_saveti,
			    0, tlen);
			break;
		}
a2025 14
dropwithreset_ratelim:
	/*
	 * We may want to rate-limit RSTs in certain situations,
	 * particularly if we are sending an RST in response to
	 * an attempt to connect to or otherwise communicate with
	 * a port for which we have no socket.
	 */
	if (ppsratecheck(&tcp_rst_ppslim_last, &tcp_rst_ppslim_count,
	    tcp_rst_ppslim) == 0) {
		/* XXX stat */
		goto drop;
	}
	/* ...fall into dropwithreset... */

d2033 1
a2033 2
		goto drop;
	switch (af) {
d2035 6
a2040 5
	case AF_INET6:
		/* For following calls to tcp_respond */
		if (IN6_IS_ADDR_MULTICAST(&ipv6->ip6_dst))
			goto drop;
		break;
d2042 3
a2044 3
	case AF_INET:
		if (IN_MULTICAST(ip->ip_dst.s_addr))
			goto drop;
d2046 4
a2049 4
	if (tiflags & TH_ACK) {
		tcp_respond(tp, mtod(m, caddr_t), m, (tcp_seq)0, th->th_ack,
		    TH_RST);
	} else {
d2052 2
a2053 2
		tcp_respond(tp, mtod(m, caddr_t), m, th->th_seq + tlen,
		    (tcp_seq)0, TH_RST|TH_ACK);
a2064 1
		switch (tp->pf) {
d2066 3
a2068 4
		case PF_INET6:
			tcp_trace(TA_DROP, ostate, tp, (caddr_t) &tcp_saveti6,
			    0, tlen);
			break;
d2070 1
a2070 5
		case PF_INET:
			tcp_trace(TA_DROP, ostate, tp, (caddr_t) &tcp_saveti,
			    0, tlen);
			break;
		}
a2099 2
			if (cnt < 2)
				break;
d2101 1
a2101 1
			if (optlen < 2 || optlen > cnt)
d2163 1
a2163 1
	if (th->th_flags & TH_SYN) {
a2164 4

		if (mss)
			tcp_mss_update(tp);
	}
a2522 2
				if (SEQ_LT(cur->rxmit, cur->start))
					cur->rxmit = cur->start;
d2565 1
a2565 5
		if (tp->snd_cwnd > (th->th_ack - tp->snd_una)) {
			tp->snd_cwnd -= th->th_ack - tp->snd_una;
			tp->snd_cwnd += tp->t_maxseg;
		} else
			tp->snd_cwnd = tp->t_maxseg;
a2705 3
 *
 * NOTE: offer == -1 indicates that the maxseg size changed due to
 * Path MTU discovery.
d2710 1
a2710 1
	int offer;
d2712 2
a2713 1
	struct rtentry *rt;
d2715 2
a2716 3
	int mss, mssopt;
	int iphlen;
	int is_ipv6 = 0;
d2718 1
d2721 2
d2724 2
a2725 10
	mssopt = mss = tcp_mssdflt;

	rt = in_pcbrtentry(inp);

	if (rt == NULL)
		goto out;

	ifp = rt->rt_ifp;

	switch (tp->pf) {
d2727 32
a2758 11
	case AF_INET6:
		iphlen = sizeof(struct ip6_hdr);
		is_ipv6 = 1;
		break;
#endif
	case AF_INET:
		iphlen = sizeof(struct ip);
		break;
	default:
		/* the family does not support path MTU discovery */
		goto out;
d2760 1
d2762 1
a2762 1
#ifdef RTV_MTU
d2764 3
a2766 2
	 * if there's an mtu associated with the route and we support
	 * path MTU discovery for the underlying protocol family, use it.
d2768 1
a2768 1
	if (rt->rt_rmx.rmx_mtu) {
d2770 2
a2771 2
		 * One may wish to lower MSS to take into account options,
		 * especially security-related options.
d2773 35
a2807 2
		mss = rt->rt_rmx.rmx_mtu - iphlen - sizeof(struct tcphdr);
	} else
d2809 9
a2817 31
	if (!ifp)
		/*
		 * ifp may be null and rmx_mtu may be zero in certain
		 * v6 cases (e.g., if ND wasn't able to resolve the 
		 * destination host.
		 */
		goto out;
	else if (ifp->if_flags & IFF_LOOPBACK)
		mss = ifp->if_mtu - iphlen - sizeof(struct tcphdr);
	else if (!is_ipv6) {
		if (ip_mtudisc)
			mss = ifp->if_mtu - iphlen - sizeof(struct tcphdr);
		else if (inp && in_localaddr(inp->inp_faddr))
			mss = ifp->if_mtu - iphlen - sizeof(struct tcphdr);
	}
#ifdef INET6
	else if (is_ipv6) {
		if (inp && IN6_IS_ADDR_V4MAPPED(&inp->inp_faddr6)) {
			/* mapped addr case */
			struct in_addr d;
			bcopy(&inp->inp_faddr6.s6_addr32[3], &d, sizeof(d));
			if (ip_mtudisc || in_localaddr(d))
				mss = ifp->if_mtu - iphlen - sizeof(struct tcphdr);
		} else {
			/*
			 * for IPv6, path MTU discovery is always turned on,
			 * or the node must use packet size <= 1280.
			 */
			mss = ifp->if_mtu - iphlen - sizeof(struct tcphdr);
		}
	}
d2819 2
a2820 5

	/* Calculate the value that we offer in TCPOPT_MAXSEG */
	if (offer != -1) {
		mssopt = ifp->if_mtu - iphlen - sizeof(struct tcphdr);
		mssopt = max(tcp_mssdflt, mssopt);
a2821 2

 out:
d2830 2
a2831 4
	if (offer > 0)
		tp->t_peermss = offer;
	if (tp->t_peermss)
		mss = min(mss, tp->t_peermss);
a2832 1

d2846 6
a2851 73
	if (offer == -1) {
		/* mss changed due to Path MTU discovery */
		if (mss < tp->t_maxseg) {
			/*
			 * Follow suggestion in RFC 2414 to reduce the
			 * congestion window by the ratio of the old
			 * segment size to the new segment size.
			 */
			tp->snd_cwnd = ulmax((tp->snd_cwnd / tp->t_maxseg) *
					     mss, mss);
		} 
	} else
		tp->snd_cwnd = mss;

	tp->t_maxseg = mss;

	return (offer != -1 ? mssopt : mss);
}

/*
 * Set connection variables based on the effective MSS.
 * We are passed the TCPCB for the actual connection.  If we
 * are the server, we are called by the compressed state engine
 * when the 3-way handshake is complete.  If we are the client,
 * we are called when we recieve the SYN,ACK from the server.
 *
 * NOTE: The t_maxseg value must be initialized in the TCPCB
 * before this routine is called!
 */
void
tcp_mss_update(tp)
	struct tcpcb *tp;
{
	int mss, rtt;
	u_long bufsize;
	struct rtentry *rt;
	struct socket *so;

	so = tp->t_inpcb->inp_socket;
	mss = tp->t_maxseg;

	rt = in_pcbrtentry(tp->t_inpcb);

	if (rt == NULL)
		return;

#ifdef RTV_MTU	/* if route characteristics exist ... */
	/*
	 * While we're here, check if there's an initial rtt
	 * or rttvar.  Convert from the route-table units
	 * to scaled multiples of the slow timeout timer.
	 */
	if (tp->t_srtt == 0 && (rtt = rt->rt_rmx.rmx_rtt)) {
		/*
		 * XXX the lock bit for MTU indicates that the value
		 * is also a minimum value; this is subject to time.
		 */
		if (rt->rt_rmx.rmx_locks & RTV_RTT)
			TCPT_RANGESET(tp->t_rttmin,
			    rtt / (RTM_RTTUNIT / PR_SLOWHZ),
			    TCPTV_MIN, TCPTV_REXMTMAX);
		tp->t_srtt = rtt / (RTM_RTTUNIT / (PR_SLOWHZ * TCP_RTT_SCALE));
		if (rt->rt_rmx.rmx_rttvar)
			tp->t_rttvar = rt->rt_rmx.rmx_rttvar /
			    (RTM_RTTUNIT / (PR_SLOWHZ * TCP_RTTVAR_SCALE));
		else
			/* default variation is +- 1 rtt */
			tp->t_rttvar =
			    tp->t_srtt * TCP_RTTVAR_SCALE / TCP_RTT_SCALE;
		TCPT_RANGESET((long) tp->t_rxtcur,
		    ((tp->t_srtt >> 2) + tp->t_rttvar) >> 1,
		    tp->t_rttmin, TCPTV_REXMTMAX);
	}
a2852 1

d2863 1
a2863 1
	if (bufsize < mss) {
d2865 1
a2865 3
		/* Update t_maxseg and t_maxopd */
		tcp_mss(tp, mss);
	} else {
d2871 1
a2881 4
#ifdef RTV_RPIPE
		if (rt->rt_rmx.rmx_recvpipe > 0)
			tcp_rscale(tp, so->so_rcv.sb_hiwat);
#endif
d2883 1
d2896 1
d2939 2
a2940 2
	}
	return 0;
@


1.56.2.3
log
@Merge in -current from two days ago in the SMP branch.
As usual with merges, they do not indicate progress, so do not hold
your breath for working SMP, and do not mail me and ask about the
state of it.  It has not changed.  There is work ongoing, but very, very
slowly.  The commit is done in parts as to not lock up the tree in too
big chunks at a time.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.56.2.2 2001/05/14 22:40:14 niklas Exp $	*/
d36 1
a36 37
 *	@@(#)COPYRIGHT	1.1 (NRL) 17 January 1995
 * 
 * NRL grants permission for redistribution and use in source and binary
 * forms, with or without modification, of the software and documentation
 * created at NRL provided that the following conditions are met:
 * 
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgements:
 * 	This product includes software developed by the University of
 * 	California, Berkeley and its contributors.
 * 	This product includes software developed at the Information
 * 	Technology Division, US Naval Research Laboratory.
 * 4. Neither the name of the NRL nor the names of its contributors
 *    may be used to endorse or promote products derived from this software
 *    without specific prior written permission.
 * 
 * THE SOFTWARE PROVIDED BY NRL IS PROVIDED BY NRL AND CONTRIBUTORS ``AS
 * IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED
 * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A
 * PARTICULAR PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL NRL OR
 * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
 * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
 * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
 * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
 * LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
 * NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
 * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 * 
 * The views and conclusions contained in the software and documentation
 * are those of the authors and should not be interpreted as representing
 * official policies, either expressed or implied, of the US Naval
 * Research Laboratory (NRL).
d39 12
d54 1
d59 2
d77 7
d87 4
a394 1
	struct m_tag *mtag;
d442 1
d461 1
d475 1
a475 1
		if (m == NULL) {
d505 3
a507 13
		if ((m->m_pkthdr.csum & M_TCP_CSUM_IN_OK) == 0) {
			if (m->m_pkthdr.csum & M_TCP_CSUM_IN_BAD) {
				tcpstat.tcps_inhwcsum++;
				tcpstat.tcps_rcvbadsum++;
				goto drop;
			}
			if ((ti->ti_sum = in_cksum(m, len)) != 0) {
				tcpstat.tcps_rcvbadsum++;
				goto drop;
			}
		} else {
			m->m_pkthdr.csum &= ~M_TCP_CSUM_IN_OK;
			tcpstat.tcps_inhwcsum++;
d562 1
a562 1
			if ((m = m_pullup2(m, iphlen + off)) == NULL) {
d704 1
a704 2
			 * from the old pcb. Ditto for any other
			 * IPsec-related information.
a710 26
			  if (inp->inp_ipsec_localid != NULL) {
			  	newinp->inp_ipsec_localid = inp->inp_ipsec_localid;
				inp->inp_ipsec_localid->ref_count++;
			  }
			  if (inp->inp_ipsec_remoteid != NULL) {
			  	newinp->inp_ipsec_remoteid = inp->inp_ipsec_remoteid;
				inp->inp_ipsec_remoteid->ref_count++;
			  }
			  if (inp->inp_ipsec_localcred != NULL) {
			  	newinp->inp_ipsec_localcred = inp->inp_ipsec_localcred;
				inp->inp_ipsec_localcred->ref_count++;
			  }
			  if (inp->inp_ipsec_remotecred != NULL) {
			  	newinp->inp_ipsec_remotecred = inp->inp_ipsec_remotecred;
				inp->inp_ipsec_remotecred->ref_count++;
			  }
			  if (inp->inp_ipsec_localauth != NULL) {
			  	newinp->inp_ipsec_localauth
				  = inp->inp_ipsec_localauth;
				inp->inp_ipsec_localauth->ref_count++;
			  }
			  if (inp->inp_ipsec_remoteauth != NULL) {
			  	newinp->inp_ipsec_remoteauth
				  = inp->inp_ipsec_remoteauth;
				inp->inp_ipsec_remoteauth->ref_count++;
			  }
a769 2
	/* Find most recent IPsec tag */
	mtag = m_tag_find(m, PACKET_TAG_IPSEC_IN_DONE, NULL);
d771 4
a774 2
	if (mtag != NULL) {
		tdbi = (struct tdb_ident *)(mtag + 1);
d776 1
a776 2
	} else
		tdb = NULL;
d778 1
a778 1
	    tdb, inp);
d782 1
a782 1
		if (tdb) {
d784 1
a784 18
			if (inp->inp_ipsec_remoteid == NULL &&
			    tdb->tdb_srcid != NULL) {
				inp->inp_ipsec_remoteid = tdb->tdb_srcid;
				tdb->tdb_srcid->ref_count++;
			}
			if (inp->inp_ipsec_remotecred == NULL &&
			    tdb->tdb_remote_cred != NULL) {
				inp->inp_ipsec_remotecred =
				    tdb->tdb_remote_cred;
				tdb->tdb_remote_cred->ref_count++;
			}
			if (inp->inp_ipsec_remoteauth == NULL &&
			    tdb->tdb_remote_auth != NULL) {
				inp->inp_ipsec_remoteauth =
				    tdb->tdb_remote_auth;
				tdb->tdb_remote_auth->ref_count++;
			}
		} else { /* Just reset */
d2897 1
a2897 1
 * we are called when we receive the SYN,ACK from the server.
@


1.56.2.4
log
@Sync the SMP branch to something just after 3.0
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.56.2.3 2001/07/04 10:55:06 niklas Exp $	*/
d2680 1
a2680 1
#endif /* TCP_SACK */
d2916 1
a2916 1
	 * However, do not accept offers under 64 bytes.
@


1.56.2.5
log
@Merge in trunk
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
a144 15
 * Macro to compute ACK transmission behavior.  Delay the ACK unless
 * we have already delayed an ACK (must send an ACK every two segments).
 * We also ACK immediately if we received a PUSH and the ACK-on-PUSH
 * option is enabled.
 */
#define	TCP_SETUP_ACK(tp, th) \
do { \
	if ((tp)->t_flags & TF_DELACK || \
	    (tcp_ack_on_push && (th)->th_flags & TH_PUSH)) \
		tp->t_flags |= TF_ACKNOW; \
	else \
		TCP_SET_DELACK(tp); \
} while (0)

/*
d179 1
a179 1
	tiqe =  pool_get(&ipqent_pool, PR_NOWAIT);
d210 1
a210 1
				pool_put(&ipqent_pool, tiqe);
d240 1
a240 1
		pool_put(&ipqent_pool, q);
d276 1
a276 1
		pool_put(&ipqent_pool, q);
d867 1
a867 1
		TCP_TIMER_ARM(tp, TCPT_KEEP, tcp_keepidle);
d963 3
a965 3
					TCP_TIMER_DISARM(tp, TCPT_REXMT);
				else if (TCP_TIMER_ISARMED(tp, TCPT_PERSIST) == 0)
					TCP_TIMER_ARM(tp, TCPT_REXMT, tp->t_rxtcur);
d995 4
a1001 3
			TCP_SETUP_ACK(tp, th);
			if (tp->t_flags & TF_ACKNOW)
				(void) tcp_output(tp);
d1193 1
a1193 1
		TCP_TIMER_ARM(tp, TCPT_KEEP, tcptv_keep_init);
d1246 1
a1246 1
		TCP_TIMER_DISARM(tp, TCPT_REXMT);
d1596 1
a1596 1
				if (TCP_TIMER_ISARMED(tp, TCPT_REXMT) == 0)
d1633 1
a1633 1
						TCP_TIMER_DISARM(tp, TCPT_REXMT);
d1656 1
a1656 1
					TCP_TIMER_DISARM(tp, TCPT_REXMT);
d1777 1
a1777 1
			TCP_TIMER_DISARM(tp, TCPT_REXMT);
d1779 2
a1780 2
		} else if (TCP_TIMER_ISARMED(tp, TCPT_PERSIST) == 0)
			TCP_TIMER_ARM(tp, TCPT_REXMT, tp->t_rxtcur);
d1789 2
a1790 2
		u_int cw = tp->snd_cwnd;
		u_int incr = tp->t_maxseg;
d1843 1
a1843 1
					TCP_TIMER_ARM(tp, TCPT_2MSL, tcp_maxidle);
d1859 1
a1859 1
				TCP_TIMER_ARM(tp, TCPT_2MSL, 2 * TCPTV_MSL);
d1883 1
a1883 1
			TCP_TIMER_ARM(tp, TCPT_2MSL, 2 * TCPTV_MSL);
d1981 4
a1984 1
			TCP_SETUP_ACK(tp, th);
d2056 1
a2056 1
			TCP_TIMER_ARM(tp, TCPT_2MSL, 2 * TCPTV_MSL);
d2064 1
a2064 1
			TCP_TIMER_ARM(tp, TCPT_2MSL, 2 * TCPTV_MSL);
d2382 5
a2386 1
tcp_sack_option(struct tcpcb *tp, struct tcphdr *th, u_char *cp, int optlen)
d2393 1
a2393 1
		return (1);
d2397 1
a2397 1
		return (1);
d2407 1
a2407 1
		bcopy(tmp_cp, (char *) &(sack.start), sizeof(tcp_seq));
d2409 1
a2409 1
		bcopy(tmp_cp + sizeof(tcp_seq),
d2420 1
a2420 1
		if (SEQ_GT(sack.end, tp->snd_fack))
d2426 3
d2432 1
a2432 1
		if (tp->snd_holes == NULL) { /* first hole */
d2434 1
a2434 1
			    pool_get(&sackhl_pool, PR_NOWAIT);
d2443 1
a2443 1
			cur->next = NULL;
d2465 2
a2466 2
				if (((sack.end - cur->end)/tp->t_maxseg) >=
				    tcprexmtthresh)
d2484 1
a2484 1
				if (SEQ_GEQ(sack.end, cur->end)) {
d2488 1
a2488 1
						pool_put(&sackhl_pool, cur);
d2491 2
a2492 2
						cur = cur->next;
						pool_put(&sackhl_pool, p);
d2515 1
a2515 1
				cur->rxmit = min(cur->rxmit, cur->end);
d2517 2
a2518 2
				if (((sack.end - cur->end)/tp->t_maxseg) >=
				    tcprexmtthresh)
d2530 2
a2531 2
				temp = (struct sackhole *)
				    pool_get(&sackhl_pool, PR_NOWAIT);
d2548 1
a2548 1
				temp->rxmit = max(cur->rxmit, temp->start);
d2550 1
a2550 1
				cur->rxmit = min(cur->rxmit, cur->end);
d2552 1
a2552 1
				if (((sack.end - cur->end)/tp->t_maxseg) >=
d2567 2
a2568 2
			temp = (struct sackhole *)
			    pool_get(&sackhl_pool, PR_NOWAIT);
d2599 1
a2599 1
	return (0);
d2617 1
a2617 1
		struct sackhole *prev;
d2620 2
a2622 2
				cur = cur->next;
				pool_put(&sackhl_pool, prev);
d2662 1
a2662 1
		TCP_TIMER_DISARM(tp, TCPT_REXMT);
d2676 1
a2676 1
		return (1);
d2678 1
a2678 1
	return (0);
d3083 1
a3083 1
		TCP_TIMER_DISARM(tp, TCPT_REXMT);
@


1.56.2.6
log
@Merge in -current from roughly a week ago
@
text
@a81 1
#include <sys/kernel.h>
d150 1
a150 1
#define	TCP_SETUP_ACK(tp, tiflags) \
d153 1
a153 1
	    (tcp_ack_on_push && (tiflags) & TH_PUSH)) \
d174 2
a175 2
	struct tcpcb *tp;
	struct tcphdr *th;
d179 1
a179 1
	struct ipqent *p, *q, *nq, *tiqe;
d215 2
a216 2
		struct tcphdr *phdr = p->ipqe_tcp;
		int i;
d241 2
a242 2
		struct tcphdr *qhdr = q->ipqe_tcp;
		int i = (th->th_seq + *tlen) - qhdr->th_seq;
d311 2
a312 2
	struct inpcb *inp;
	struct tcpcb *tp;
d388 1
d390 4
d396 1
a396 1
	struct inpcb *inp;
d400 2
a401 2
	struct tcpcb *tp = 0;
	int tiflags;
d414 1
a414 1
	struct tcphdr *th;
d880 1
a880 1
	tp->t_rcvtime = tcp_now;
d945 1
a945 1
				else if (tp->t_rtttime &&
d947 1
a947 2
					tcp_xmit_timer(tp,
					    tcp_now - tp->t_rtttime);
d1013 1
a1013 1
			TCP_SETUP_ACK(tp, tiflags);
d1057 1
a1057 1
		struct sockaddr_in *sin;
d1059 1
a1059 1
		struct sockaddr_in6 *sin6;
d1086 2
d1094 1
d1100 1
a1100 2
			if (IN_MULTICAST(ip->ip_dst.s_addr) ||
			    in_broadcast(ip->ip_dst, m->m_pkthdr.rcvif))
d1290 2
a1291 2
			if (tp->t_rtttime)
				tcp_xmit_timer(tp, tcp_now - tp->t_rtttime);
d1648 1
a1648 1
						tp->t_rtttime = 0;
d1671 1
a1671 1
					tp->t_rtttime = 0;
d1781 2
a1782 2
		else if (tp->t_rtttime && SEQ_GT(th->th_ack, tp->t_rtseq))
			tcp_xmit_timer(tp, tcp_now - tp->t_rtttime);
d1995 1
a1995 1
			TCP_SETUP_ACK(tp, tiflags);
d2145 1
a2145 2
		if (IN_MULTICAST(ip->ip_dst.s_addr) ||
		    in_broadcast(ip->ip_dst, m->m_pkthdr.rcvif))
d2667 1
a2667 1
		tp->t_rtttime = 0;
d2696 1
a2696 1
	struct mbuf *m;
d2726 1
a2726 1
	struct tcpcb *tp;
d2729 1
a2729 1
	short delta;
d2769 1
a2769 1
	tp->t_rtttime = 0;
d2825 1
a2825 1
	struct tcpcb *tp;
d3088 1
a3088 1
		tp->t_rtttime = 0;
@


1.56.2.7
log
@Sync the SMP branch with 3.3
@
text
@d37 1
a37 1
 *
d41 1
a41 1
 *
d56 1
a56 1
 *
d68 1
a68 1
 *
a144 12
#ifdef TCP_ECN
/*
 * ECN (Explicit Congestion Notification) support based on RFC3168
 * implementation note:
 *   snd_last is used to track a recovery phase.
 *   when cwnd is reduced, snd_last is set to snd_max.
 *   while snd_last > snd_una, the sender is in a recovery phase and
 *   its cwnd should not be reduced again.
 *   snd_last follows snd_una when not in a recovery phase.
 */
#endif

d291 1
a291 1
			sbappendstream(&so->so_rcv, q->ipqe_m);
d393 1
a393 1
	u_int8_t *optp = NULL;
d413 1
a413 1
	struct ip6_hdr *ip6 = NULL;
a421 3
#ifdef TCP_ECN
	u_char iptos;
#endif
d432 1
a432 1
	 */
d503 1
a503 1
	ip6 = NULL;
a517 4
#ifdef TCP_ECN
		/* save ip_tos before clearing it for checksum */
		iptos = ip->ip_tos;
#endif
d543 1
a543 1
		ip6 = mtod(m, struct ip6_hdr *);
a544 3
#ifdef TCP_ECN
		iptos = (ntohl(ip6->ip6_flow) >> 20) & 0xff;
#endif
d547 2
a548 2
		if (IN6_IS_ADDR_V4MAPPED(&ip6->ip6_src) ||
		    IN6_IS_ADDR_V4MAPPED(&ip6->ip6_dst)) {
d561 1
a561 1
		if (IN6_IS_ADDR_UNSPECIFIED(&ip6->ip6_src)) {
d602 1
a602 1
				ip6 = mtod(m, struct ip6_hdr *);
d609 2
a610 2
		optp = mtod(m, u_int8_t *) + iphlen + sizeof(struct tcphdr);
		/*
d645 2
a646 2
		inp = in6_pcbhashlookup(&tcbtable, &ip6->ip6_src, th->th_sport,
		    &ip6->ip6_dst, th->th_dport);
d659 2
a660 2
			inp = in_pcblookup(&tcbtable, &ip6->ip6_src,
			    th->th_sport, &ip6->ip6_dst, th->th_dport,
d686 1
a686 1

a710 42
#ifdef INET6
			/*
			 * If deprecated address is forbidden,
			 * we do not accept SYN to deprecated interface
			 * address to prevent any new inbound connection from
			 * getting established.  So drop the SYN packet.
			 * When we do not accept SYN, we send a TCP RST,
			 * with deprecated source address (instead of dropping
			 * it).  We compromise it as it is much better for peer
			 * to send a RST, and RST will be the final packet
			 * for the exchange.
			 *
			 * If we do not forbid deprecated addresses, we accept
			 * the SYN packet.  RFC2462 does not suggest dropping
			 * SYN in this case.
			 * If we decipher RFC2462 5.5.4, it says like this:
			 * 1. use of deprecated addr with existing
			 *    communication is okay - "SHOULD continue to be
			 *    used"
			 * 2. use of it with new communication:
			 *   (2a) "SHOULD NOT be used if alternate address
			 *        with sufficient scope is available"
			 *   (2b) nothing mentioned otherwise.
			 * Here we fall into (2b) case as we have no choice in
			 * our source address selection - we must obey the peer.
			 *
			 * The wording in RFC2462 is confusing, and there are
			 * multiple description text for deprecated address
			 * handling - worse, they are not exactly the same.
			 * I believe 5.5.4 is the best one, so we follow 5.5.4.
			 */
			if (ip6 && !ip6_use_deprecated) {
				struct in6_ifaddr *ia6;

				if ((ia6 = in6ifa_ifpwithaddr(m->m_pkthdr.rcvif, &ip6->ip6_dst)) &&
				    (ia6->ia6_flags & IN6_IFF_DEPRECATED)) {
					tp = NULL;
					goto dropwithreset;
				}
			}
#endif

d732 1
a732 1
			/*
d742 11
a752 3
			  if (inp->inp_ipo != NULL) {
				  newinp->inp_ipo = inp->inp_ipo;
				  inp->inp_ipo->ipo_ref_count++;
d755 7
a761 2
				  newinp->inp_ipsec_remotecred = inp->inp_ipsec_remotecred;
				  inp->inp_ipsec_remotecred->ref_count++;
d764 3
a766 3
				  newinp->inp_ipsec_remoteauth
				      = inp->inp_ipsec_remoteauth;
				  inp->inp_ipsec_remoteauth->ref_count++;
d777 1
a777 1
			 * we also copy the flowinfo from the original pcb
d783 1
a783 1

d787 1
a787 1
			    inp->inp_ipv6.ip6_hlim =
d789 1
a789 1
			    inp->inp_ipv6.ip6_flow =
d800 2
a801 2
				inp->inp_laddr6 = ip6->ip6_dst;

a836 4
	if (error) {
		splx(s);
		goto drop;
	}
d842 1
a842 9
			if (inp->inp_ipo == NULL) {
				inp->inp_ipo = ipsec_add_policy(inp, af,
				    IPSP_DIRECTION_OUT);
				if (inp->inp_ipo == NULL) {
					splx(s);
					goto drop;
				}
			}
			if (inp->inp_ipo->ipo_dstid == NULL &&
d844 1
a844 1
				inp->inp_ipo->ipo_dstid = tdb->tdb_srcid;
d866 4
d899 1
a899 8
#ifdef TCP_ECN
	/* if congestion experienced, set ECE bit in subsequent packets. */
	if ((iptos & IPTOS_ECN_MASK) == IPTOS_ECN_CE) {
		tp->t_flags |= TF_RCVD_CE;
		tcpstat.tcps_ecn_rcvce++;
	}
#endif
	/*
a913 3
#ifdef TCP_ECN
	    (tiflags & (TH_SYN|TH_FIN|TH_RST|TH_URG|TH_ECE|TH_CWR|TH_ACK)) == TH_ACK &&
#else
a914 1
#endif
d920 1
a920 1
		/*
d951 2
a952 2
#if defined(TCP_SACK) || defined(TCP_ECN)
				/*
a956 3
#ifdef TCP_ECN
				if (SEQ_GT(tp->snd_una, tp->snd_last))
#endif
d1007 2
a1008 6
			if (so->so_state & SS_CANTRCVMORE)
				m_freem(m);
			else {
				m_adj(m, iphlen + off);
				sbappendstream(&so->so_rcv, m);
			}
d1069 2
a1070 2
				if (IN6_ARE_ADDR_EQUAL(&ip6->ip6_src,
				    &ip6->ip6_dst))
d1089 1
a1089 1
			if (IN6_IS_ADDR_MULTICAST(&ip6->ip6_dst))
a1117 1
			bzero(sin6, sizeof(*sin6));
d1120 1
a1120 1
			sin6->sin6_addr = ip6->ip6_src;
d1126 1
a1126 1
				inp->inp_laddr6 = ip6->ip6_dst;
a1142 1
			bzero(sin, sizeof(*sin));
d1156 1
a1158 1
		(void) m_free(am);
d1171 1
a1171 1
		 * tcp_dooptions() did not set TF_SACK_PERMIT), set
d1175 1
a1175 1
                        if ((tp->t_flags & TF_SACK_PERMIT) == 0)
d1191 1
a1191 1
#if defined (TCP_SACK) || defined(TCP_ECN)
a1198 10
#ifdef TCP_ECN
		/*
		 * if both ECE and CWR flag bits are set, peer is ECN capable.
		 */
		if (tcp_do_ecn &&
		    (tiflags & (TH_ECE|TH_CWR)) == (TH_ECE|TH_CWR)) {
			tp->t_flags |= TF_ECN_PERMIT;
			tcpstat.tcps_ecn_accepts++;
		}
#endif
d1212 1
a1212 1
	 */
a1243 5
#ifdef TCP_ECN
			/* if ECN is enabled, fall back to non-ecn at rexmit */
			if (tcp_do_ecn && !(tp->t_flags & TF_DISABLE_ECN))
				goto drop;
#endif
d1266 1
a1266 1
                        if ((tp->t_flags & TF_SACK_PERMIT) == 0)
a1268 18
#ifdef TCP_ECN
		/*
		 * if ECE is set but CWR is not set for SYN-ACK, or
		 * both ECE and CWR are set for simultaneous open,
		 * peer is ECN capable.
		 */
		if (tcp_do_ecn) {
			if ((tiflags & (TH_ACK|TH_ECE|TH_CWR))
			    == (TH_ACK|TH_ECE) ||
			    (tiflags & (TH_ACK|TH_ECE|TH_CWR))
			    == (TH_ECE|TH_CWR)) {
				tp->t_flags |= TF_ECN_PERMIT;
				tiflags &= ~(TH_ECE|TH_CWR);
				tcpstat.tcps_ecn_accepts++;
			}
		}
#endif

d1322 1
a1322 1
	 * Then check that at least some bytes of segment are within
d1325 1
a1325 1
	 *
d1359 1
a1359 1
			if (th->th_urp > 1)
a1473 5
#ifdef TCP_ECN
			/* if ECN is enabled, fall back to non-ecn at rexmit */
			if (tcp_do_ecn && !(tp->t_flags & TF_DISABLE_ECN))
				goto drop;
#endif
d1513 1
a1513 1

a1553 33
#ifdef TCP_ECN
		/*
		 * if we receive ECE and are not already in recovery phase,
		 * reduce cwnd by half but don't slow-start.
		 * advance snd_last to snd_max not to reduce cwnd again
		 * until all outstanding packets are acked.
		 */
		if (tcp_do_ecn && (tiflags & TH_ECE)) {
			if ((tp->t_flags & TF_ECN_PERMIT) &&
			    SEQ_GEQ(tp->snd_una, tp->snd_last)) {
				u_int win;

				win = min(tp->snd_wnd, tp->snd_cwnd) / tp->t_maxseg;
				if (win > 1) {
					tp->snd_ssthresh = win / 2 * tp->t_maxseg;
					tp->snd_cwnd = tp->snd_ssthresh;
					tp->snd_last = tp->snd_max;
					tp->t_flags |= TF_SEND_CWR;
					tcpstat.tcps_cwr_ecn++;
				}
			}
			tcpstat.tcps_ecn_rcvece++;
		}
		/*
		 * if we receive CWR, we know that the peer has reduced
		 * its congestion window.  stop sending ecn-echo.
		 */
		if ((tiflags & TH_CWR)) {
			tp->t_flags &= ~TF_RCVD_CE;
			tcpstat.tcps_ecn_rcvcwr++;
		}
#endif /* TCP_ECN */

d1600 1
a1600 1
				 * network (they're now cached at the receiver)
d1608 1
a1608 1
				/*
d1613 1
a1613 1
				    ((SEQ_GT(tp->snd_fack, tcprexmtthresh *
d1624 1
a1624 1
#if defined(TCP_SACK) || defined(TCP_ECN)
d1626 2
a1627 2
					    	/*
						 * False fast retx after
a1643 6
#ifdef TCP_ECN
						tp->t_flags |= TF_SEND_CWR;
#endif
#if 1 /* TCP_ECN */
						tcpstat.tcps_cwr_frecovery++;
#endif
d1645 1
a1645 1
#if defined(TCP_SACK) && defined(TCP_FACK)
d1654 1
a1654 1
						/*
a1668 6
#ifdef TCP_ECN
					tp->t_flags |= TF_SEND_CWR;
#endif
#if 1 /* TCP_ECN */
					tcpstat.tcps_cwr_frecovery++;
#endif
d1679 3
a1681 3
					/*
					 * while (awnd < cwnd)
					 *         sendsomething();
d1715 1
a1715 1
					if (tp->snd_awnd < tp->snd_cwnd)
d1724 1
a1724 1
					if (tcp_seq_subtract(tp->snd_max,
d1726 1
a1726 1
						tp->snd_cwnd =
d1735 1
a1735 1
			}
d1737 1
a1737 1
			if (tp->t_dupacks >= tcprexmtthresh &&
d1743 1
a1743 1
					tp->snd_cwnd =
a1820 5
#ifdef TCP_ECN
		/* sync snd_last with snd_una */
		if (SEQ_GT(tp->snd_una, tp->snd_last))
			tp->snd_last = tp->snd_una;
#endif
d1937 1
a1937 1
		 * a FIN has been received from the remote side.
d1944 1
a1944 1
		 * of data past the urgent section as the original
d1996 2
a1997 6
			if (so->so_state & SS_CANTRCVMORE)
				m_freem(m);
			else {
				m_adj(m, hdroptlen);
				sbappendstream(&so->so_rcv, m);
			}
d2006 2
a2007 2
			tcp_update_sack_list(tp);
#endif
d2009 1
a2009 1
		/*
d2056 1
a2056 1
		 * starting the time-wait timer, turning off the other
d2135 1
a2135 1
		if (IN6_IS_ADDR_MULTICAST(&ip6->ip6_dst))
d2242 1
a2242 1
			/*
d2252 2
a2253 2

#ifdef TCP_SACK
d2265 1
a2265 1
#endif
d2278 1
a2278 1
u_long
d2281 2
a2282 2
{
	return ((long)(a - b));
d2287 1
a2287 1
#ifdef TCP_SACK
d2290 1
a2290 1
 * prediction mode), and it updates the ordered list of sacks.
d2292 1
a2292 1
void
d2294 3
a2296 3
	struct tcpcb *tp;
{
	/*
d2301 1
a2301 1
	 */
d2304 1
a2304 1

d2315 1
a2315 1
		} else {
d2319 1
a2319 1
	}
d2334 1
a2334 1
	if (SEQ_GEQ(tp->rcv_nxt, tp->rcv_lastend))
d2336 1
a2336 1
	/*
d2348 1
a2348 1
			/*
d2381 1
a2381 1
}
d2386 2
a2387 2
 * of holes (oldest to newest, in terms of the sequence space).
 */
d2390 1
a2390 1
{
d2394 1
a2394 1

d2397 1
a2397 1

d2409 1
a2409 1

d2411 1
a2411 1
		NTOHL(sack.start);
d2419 1
a2419 1
		if (SEQ_LEQ(sack.end, tp->snd_una))
d2437 1
a2437 1
				continue;
d2446 2
a2447 2
			/*
			 * dups is at least one.  If more data has been
d2450 1
a2450 1
			cur->dups = min(tcprexmtthresh,
d2459 2
a2460 2
			if (SEQ_LEQ(sack.end, cur->start))
				/* SACKs data before the current hole */
d2476 2
a2477 2
					tp->retran_data -=
				    	    tcp_seq_subtract(cur->rxmit,
d2481 1
a2481 1
					    tcp_seq_subtract(sack.end,
d2509 3
a2511 3
				if (SEQ_GT(cur->rxmit, sack.start))
					tp->retran_data -=
					    tcp_seq_subtract(cur->rxmit,
d2526 2
a2527 2
				/*
				 * ACKs some data in middle of a hole; need to
d2532 1
a2532 1
				if (temp == NULL)
d2535 3
a2537 3
				if (SEQ_GT(cur->rxmit, sack.end))
					tp->retran_data -=
					    tcp_seq_subtract(sack.end,
d2540 2
a2541 2
					tp->retran_data -=
					    tcp_seq_subtract(cur->rxmit,
d2569 1
a2569 1
			if (temp == NULL)
d2573 1
a2573 1
			temp->dups = min(tcprexmtthresh,
d2585 2
a2586 2
	/*
	 * Update retran_data and snd_awnd.  Go through the list of
d2595 1
a2595 1
	tp->snd_awnd = tcp_seq_subtract(tp->snd_nxt, tp->snd_fack) +
d2600 1
a2600 1
}
d2604 1
a2604 1
 * it is completely acked; otherwise, tcp_sack_option(), called from
d2635 1
a2635 1
/*
d2650 1
a2650 1
/*
d2665 2
a2666 2
		/*
		 * Partial window deflation.  This statement relies on the
d2696 1
a2696 1

d2757 1
a2757 1
		/*
d2784 1
a2784 1

d2828 1
d2846 1
d2873 1
a2873 1
		 * v6 cases (e.g., if ND wasn't able to resolve the
d2879 1
a2879 1
	else if (tp->pf == AF_INET) {
d2886 14
a2899 6
	else if (tp->pf == AF_INET6) {
		/*
		 * for IPv6, path MTU discovery is always turned on,
		 * or the node must use packet size <= 1280.
		 */
		mss = IN6_LINKMTU(ifp) - iphlen - sizeof(struct tcphdr);
d2933 1
a2933 1
	if ((tp->t_flags & (TF_REQ_TSTMP|TF_NOOPT)) == TF_REQ_TSTMP &&
d2947 1
a2947 1
		}
d3063 1
a3063 1
/*
d3086 1
a3086 1
		/*
d3089 1
a3089 1
		 */
d3095 3
a3097 3
		/*
		 * Partial window deflation.  Relies on fact that tp->snd_una
		 * not updated yet.
@


1.56.2.8
log
@Sync the SMP branch to -current. This includes moving to ELF.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.56.2.7 2003/03/28 00:06:54 niklas Exp $	*/
d1477 1
a1477 1
		if (todrop > tlen ||
@


1.56.2.9
log
@Sync SMP branch to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.56.2.8 2003/05/13 19:36:17 ho Exp $	*/
d16 5
a20 1
 * 3. Neither the name of the University nor the names of its contributors
d104 3
d114 1
d420 1
a420 1
	int iphlen, toff;
a433 1
	struct mbuf *tcp_saveti = NULL;
d439 1
a439 1
	toff = va_arg(ap, int);
d469 1
a469 1
		if (toff < sizeof(struct ip)) {
d474 6
a479 6
		ip = mtod(m, struct ip *);
		iphlen = sizeof(*ip);
		IP6_EXTHDR_GET(th, struct tcphdr *, m, toff,
		    sizeof(struct tcphdr));
		if (th == NULL) {
			tcpstat.tcps_rcvshort++;
d481 1
a482 6
		len = m->m_pkthdr.len;
		tlen = len - toff;
#ifdef TCP_ECN
		/* save ip_tos before clearing it for checksum */
		iptos = ip->ip_tos;
#endif
d487 1
a487 1
		if (toff < sizeof(struct ip6_hdr)) {
d492 6
a497 6
		ip6 = mtod(m, struct ip6_hdr *);
		iphlen = sizeof(*ip6);
		IP6_EXTHDR_GET(th, struct tcphdr *, m, toff,
		    sizeof(struct tcphdr));
		if (th == NULL) {
			tcpstat.tcps_rcvshort++;
a498 5
		}
		len = m->m_pkthdr.len;
		tlen = len - toff;
#ifdef TCP_ECN
		iptos = (ntohl(ip6->ip6_flow) >> 20) & 0xff;
a499 6

		/* Be proactive about malicious use of IPv4 mapped address */
		if (IN6_IS_ADDR_V4MAPPED(&ip6->ip6_src) ||
		    IN6_IS_ADDR_V4MAPPED(&ip6->ip6_dst)) {
			/* XXX stat */
			goto drop;
a500 14

		/*
		 * Be proactive about unspecified IPv6 address in source.
		 * As we use all-zero to indicate unbounded/unconnected pcb,
		 * unspecified IPv6 address can be used to confuse us.
		 *
		 * Note that packets with unspecified IPv6 destination is
		 * already dropped in ip6_input.
		 */
		if (IN6_IS_ADDR_UNSPECIFIED(&ip6->ip6_src)) {
			/* XXX stat */
			goto drop;
		}

d508 12
d522 15
d540 4
a543 1
		HTONS(ip->ip_len);
d550 1
a550 1
			if (in4_cksum(m, IPPROTO_TCP, toff, tlen) != 0) {
d559 1
d562 26
d600 2
d613 16
a628 4
		IP6_EXTHDR_GET(th, struct tcphdr *, m, toff, off);
		if (th == NULL) {
			tcpstat.tcps_rcvshort++;
			return;
d631 1
a631 1
		optp = mtod(m, u_int8_t *) + toff + sizeof(struct tcphdr);
d719 5
a723 9
			tcp_saveti = NULL;
			MGETHDR(tcp_saveti, M_DONTWAIT, MT_HEADER);
			if (!tcp_saveti)
				goto nosave;
#ifdef DIAGNOSTIC
			if (iphlen + sizeof(struct tcphdr) > MCLBYTES) {
				printf("cannot save to tcp_saveti\n");
				goto nosave;
			}
d725 3
a727 7
			if (iphlen + sizeof(struct tcphdr) > MHLEN) {
				MCLGET(tcp_saveti, M_DONTWAIT);
				if ((tcp_saveti->m_flags & M_EXT) == 0) {
					m_freem(tcp_saveti);
					tcp_saveti = NULL;
					goto nosave;
				}
a728 4
			m_copydata(m, 0, iphlen, mtod(tcp_saveti, caddr_t));
			m_copydata(m, toff, sizeof(struct tcphdr),
			    mtod(tcp_saveti, caddr_t) + iphlen);
	nosave:;
d886 1
a886 1
	ipsp_spd_lookup(m, af, toff, &error, IPSP_DIRECTION_IN,
d1083 1
a1083 1
				m_adj(m, toff + off);
d1097 1
a1097 1
	hdroptlen = toff + off;
d2245 14
a2258 2
	if (so->so_options & SO_DEBUG)
		tcp_trace(TA_INPUT, ostate, tp, tcp_saveti, 0, tlen);
a2265 1
	m_freem(tcp_saveti);
a2277 1
	m_freem(tcp_saveti);
a2326 1
	m_freem(tcp_saveti);
d2333 14
a2346 2
	if (tp && (tp->t_inpcb->inp_socket->so_options & SO_DEBUG))
		tcp_trace(TA_DROP, ostate, tp, tcp_saveti, 0, tlen);
a2347 1
	m_freem(tcp_saveti);
a3065 1
#ifndef INET6
a3066 8
#else
		if (tp->pf == AF_INET)
			mssopt = ifp->if_mtu - iphlen - sizeof(struct tcphdr);
		else
			mssopt = IN6_LINKMTU(ifp) - iphlen -
			    sizeof(struct tcphdr);
#endif

@


1.56.2.10
log
@Merge of current from two weeks agointo the SMP branch
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
a79 2
#include <dev/rndvar.h>

a99 3
struct	tcpiphdr tcp_saveti;
struct  tcpipv6hdr tcp_saveti6;

a105 4
#ifdef TCP_SIGNATURE
#include <sys/md5k.h>
#endif

a106 1
struct	tcpiphdr tcp_saveti;
d303 47
d406 2
d410 3
a412 2
	struct tcp_opt_info opti;
	int iphlen;
d416 1
d426 1
d432 1
a432 1
	iphlen = va_arg(ap, int);
a436 10
	opti.ts_present = 0;
	opti.maxseg = 0;

	/*
	 * RFC1122 4.2.3.10, p. 104: discard bcast/mcast SYN
	 * See below for AF specific multicast.
	 */
	if (m->m_flags & (M_BCAST|M_MCAST))
		goto drop;

d462 1
a462 1
		if (iphlen < sizeof(struct ip)) {
d467 6
a472 6
		if (iphlen > sizeof(struct ip)) {
#if 0	/*XXX*/
			ip_stripoptions(m, (struct mbuf *)0);
			iphlen = sizeof(struct ip);
#else
			m_freem(m);
d474 6
a480 1
		}
d485 1
a485 1
		if (iphlen < sizeof(struct ip6_hdr)) {
d490 34
a530 12
	if (m->m_len < iphlen + sizeof(struct tcphdr)) {
		m = m_pullup2(m, iphlen + sizeof(struct tcphdr));
		if (m == NULL) {
			tcpstat.tcps_rcvshort++;
			return;
		}
	}

	ip = NULL;
#ifdef INET6
	ip6 = NULL;
#endif
a532 15
	    {
		struct tcpiphdr *ti;

		ip = mtod(m, struct ip *);
		if (IN_MULTICAST(ip->ip_dst.s_addr) ||
		    in_broadcast(ip->ip_dst, m->m_pkthdr.rcvif))
			goto drop;

		tlen = m->m_pkthdr.len - iphlen;
		ti = mtod(m, struct tcpiphdr *);

#ifdef TCP_ECN
		/* save ip_tos before clearing it for checksum */
		iptos = ip->ip_tos;
#endif
d536 1
a536 4
		len = sizeof(struct ip) + tlen;
		bzero(ti->ti_x1, sizeof ti->ti_x1);
		ti->ti_len = (u_int16_t)tlen;
		HTONS(ti->ti_len);
d543 1
a543 1
			if ((ti->ti_sum = in_cksum(m, len)) != 0) {
a551 1
	    }
a553 32
		ip6 = mtod(m, struct ip6_hdr *);
		tlen = m->m_pkthdr.len - iphlen;
#ifdef TCP_ECN
		iptos = (ntohl(ip6->ip6_flow) >> 20) & 0xff;
#endif

		/* Be proactive about malicious use of IPv4 mapped address */
		if (IN6_IS_ADDR_V4MAPPED(&ip6->ip6_src) ||
		    IN6_IS_ADDR_V4MAPPED(&ip6->ip6_dst)) {
			/* XXX stat */
			goto drop;
		}

		/*
		 * Be proactive about unspecified IPv6 address in source.
		 * As we use all-zero to indicate unbounded/unconnected pcb,
		 * unspecified IPv6 address can be used to confuse us.
		 *
		 * Note that packets with unspecified IPv6 destination is
		 * already dropped in ip6_input.
		 */
		if (IN6_IS_ADDR_UNSPECIFIED(&ip6->ip6_src)) {
			/* XXX stat */
			goto drop;
		}

		/* Discard packets to multicast */
		if (IN6_IS_ADDR_MULTICAST(&ip6->ip6_dst)) {
			/* XXX stat */
			goto drop;
		}

a565 2
	th = (struct tcphdr *)(mtod(m, caddr_t) + iphlen);

d577 4
a580 16
		if (m->m_len < iphlen + off) {
			if ((m = m_pullup2(m, iphlen + off)) == NULL) {
				tcpstat.tcps_rcvshort++;
				return;
			}
			switch (af) {
			case AF_INET:
				ip = mtod(m, struct ip *);
				break;
#ifdef INET6
			case AF_INET6:
				ip6 = mtod(m, struct ip6_hdr *);
				break;
#endif
			}
			th = (struct tcphdr *)(mtod(m, caddr_t) + iphlen);
d583 1
a583 1
		optp = mtod(m, u_int8_t *) + iphlen + sizeof(struct tcphdr);
d596 3
a598 3
			opti.ts_present = 1;
			opti.ts_val = ntohl(*(u_int32_t *)(optp + 4));
			opti.ts_ecr = ntohl(*(u_int32_t *)(optp + 8));
d633 3
a635 3
			inp = in6_pcblookup_listen(&tcbtable,
			    &ip6->ip6_dst, th->th_dport, m_tag_find(m,
			    PACKET_TAG_PF_TRANSLATE_LOCALHOST, NULL) != NULL);
d639 2
a640 3
			inp = in_pcblookup_listen(&tcbtable,
			    ip->ip_dst, th->th_dport, m_tag_find(m,
			    PACKET_TAG_PF_TRANSLATE_LOCALHOST, NULL) != NULL);
a668 36
		union syn_cache_sa src;
		union syn_cache_sa dst;

		bzero(&src, sizeof(src));
		bzero(&dst, sizeof(dst));
		switch (af) {
#ifdef INET
		case AF_INET:
			src.sin.sin_len = sizeof(struct sockaddr_in);
			src.sin.sin_family = AF_INET;
			src.sin.sin_addr = ip->ip_src;
			src.sin.sin_port = th->th_sport;

			dst.sin.sin_len = sizeof(struct sockaddr_in);
			dst.sin.sin_family = AF_INET;
			dst.sin.sin_addr = ip->ip_dst;
			dst.sin.sin_port = th->th_dport;
			break;
#endif
#ifdef INET6
		case AF_INET6:
			src.sin6.sin6_len = sizeof(struct sockaddr_in6);
			src.sin6.sin6_family = AF_INET6;
			src.sin6.sin6_addr = ip6->ip6_src;
			src.sin6.sin6_port = th->th_sport;

			dst.sin6.sin6_len = sizeof(struct sockaddr_in6);
			dst.sin6.sin6_family = AF_INET6;
			dst.sin6.sin6_addr = ip6->ip6_dst;
			dst.sin6.sin6_port = th->th_dport;
			break;
#endif /* INET6 */
		default:
			goto badsyn;	/*sanity*/
		}

d671 9
a679 5
			switch (af) {
#ifdef INET6
			case AF_INET6:
				tcp_saveti6 = *(mtod(m, struct tcpipv6hdr *));
				break;
d681 7
a687 3
			case AF_INET:
				tcp_saveti = *(mtod(m, struct tcpiphdr *));
				break;
d689 4
d695 1
a695 43
			if ((tiflags & (TH_RST|TH_ACK|TH_SYN)) != TH_SYN) {
				if (tiflags & TH_RST) {
					syn_cache_reset(&src.sa, &dst.sa, th);
				} else if ((tiflags & (TH_ACK|TH_SYN)) ==
				    (TH_ACK|TH_SYN)) {
					/*
					 * Received a SYN,ACK.  This should
					 * never happen while we are in
					 * LISTEN.  Send an RST.
					 */
					goto badsyn;
				} else if (tiflags & TH_ACK) {
					so = syn_cache_get(&src.sa, &dst.sa,
						th, iphlen, tlen, so, m);
					if (so == NULL) {
						/*
						 * We don't have a SYN for
						 * this ACK; send an RST.
						 */
						goto badsyn;
					} else if (so ==
					    (struct socket *)(-1)) {
						/*
						 * We were unable to create
						 * the connection.  If the
						 * 3-way handshake was
						 * completed, and RST has
						 * been sent to the peer.
						 * Since the mbuf might be
						 * in use for the reply,
						 * do not free it.
						 */
						m = NULL;
					} else {
						/*
						 * We have created a
						 * full-blown connection.
						 */
						tp = NULL;
						inp = (struct inpcb *)so->so_pcb;
						tp = intotcpcb(inp);
						if (tp == NULL)
							goto badsyn;	/*XXX*/
a696 19
						/*
						 * Compute proper scaling
						 * value from buffer space
						 */
						tcp_rscale(tp, so->so_rcv.sb_hiwat);
						goto after_listen;
					}
				} else {
					/*
					 * None of RST, SYN or ACK was set.
					 * This is an invalid packet for a
					 * TCB in LISTEN state.  Send a RST.
					 */
					goto badsyn;
				}
			} else {
				/*
				 * Received a SYN.
				 */
d698 32
a729 37
				/*
				 * If deprecated address is forbidden, we do
				 * not accept SYN to deprecated interface
				 * address to prevent any new inbound
				 * connection from getting established.
				 * When we do not accept SYN, we send a TCP
				 * RST, with deprecated source address (instead
				 * of dropping it).  We compromise it as it is
				 * much better for peer to send a RST, and
				 * RST will be the final packet for the
				 * exchange.
				 *
				 * If we do not forbid deprecated addresses, we
				 * accept the SYN packet.  RFC2462 does not
				 * suggest dropping SYN in this case.
				 * If we decipher RFC2462 5.5.4, it says like
				 * this:
				 * 1. use of deprecated addr with existing
				 *    communication is okay - "SHOULD continue
				 *    to be used"
				 * 2. use of it with new communication:
				 *   (2a) "SHOULD NOT be used if alternate
				 *        address with sufficient scope is
				 *        available"
				 *   (2b) nothing mentioned otherwise. 
				 * Here we fall into (2b) case as we have no
				 * choice in our source address selection - we
				 * must obey the peer.
				 *
				 * The wording in RFC2462 is confusing, and
				 * there are multiple description text for
				 * deprecated address handling - worse, they
				 * are not exactly the same.  I believe 5.5.4
				 * is the best one, so we follow 5.5.4.
				 */
				if (ip6 && !ip6_use_deprecated) {
					struct in6_ifaddr *ia6;
d731 4
a734 6
					if ((ia6 = in6ifa_ifpwithaddr(m->m_pkthdr.rcvif,
					    &ip6->ip6_dst)) &&
					    (ia6->ia6_flags & IN6_IFF_DEPRECATED)) {
						tp = NULL;
						goto dropwithreset;
					}
d736 1
d739 46
a784 7
				/*
				 * LISTEN socket received a SYN
				 * from itself?  This can't possibly
				 * be valid; drop the packet.
				 */
				if (th->th_dport == th->th_sport) {
					switch (af) {
d786 24
a809 7
					case AF_INET6:
						if (IN6_ARE_ADDR_EQUAL(&ip6->ip6_src,
						    &ip6->ip6_dst)) {
							tcpstat.tcps_badsyn++;
							goto drop;
						}
						break;
d811 5
a815 8
					case AF_INET:
						if (ip->ip_dst.s_addr == ip->ip_src.s_addr) {
							tcpstat.tcps_badsyn++;
							goto drop;
						}
						break;
					}
				}
d817 1
d819 5
a823 2
				 * SYN looks ok; create compressed TCP
				 * state for it.
d825 6
a830 4
				if (so->so_qlen <= so->so_qlimit &&
				    syn_cache_add(&src.sa, &dst.sa, th, iphlen,
						so, m, optp, optlen, &opti))
					m = NULL;
d832 6
a837 1
			goto drop;
a840 10
after_listen:
#ifdef DIAGNOSTIC
	/*
	 * Should not happen now that all embryonic connections
	 * are handled with compressed state.
	 */
	if (tp->t_state == TCPS_LISTEN)
		panic("tcp_input: TCPS_LISTEN");
#endif

d850 1
a850 1
	ipsp_spd_lookup(m, af, iphlen, &error, IPSP_DIRECTION_IN,
d900 1
a900 1
	if (TCPS_HAVEESTABLISHED(tp->t_state))
d904 1
a904 1
	if (tp->sack_enable)
d909 2
a910 1
	 * Process options.
d912 3
a914 7
#ifdef TCP_SIGNATURE
	if (optp || (tp->t_flags & TF_SIGNATURE))
#else
	if (optp)
#endif
		if (tcp_dooptions(tp, optp, optlen, th, m, iphlen, &opti))
			goto drop;
d917 1
a917 1
	if (tp->sack_enable) {
d949 1
a949 1
	    (!opti.ts_present || TSTMP_GEQ(opti.ts_val, tp->ts_recent)) &&
d959 1
a959 1
		if (opti.ts_present && SEQ_LEQ(th->th_seq, tp->last_ack_sent)) {
d961 1
a961 1
			tp->ts_recent = opti.ts_val;
d973 2
a974 2
				if (opti.ts_present)
					tcp_xmit_timer(tp, tcp_now-opti.ts_ecr+1);
d1032 1
a1032 1
			if (tp->sack_enable && tp->rcv_numsacks)
d1047 1
a1047 1
				m_adj(m, iphlen + off);
d1061 1
a1061 1
	hdroptlen = iphlen + off;
d1080 19
a1098 4
	 * If the state is SYN_RECEIVED:
	 * 	if seg contains SYN/ACK, send an RST.
	 *	if seg contains an ACK, but not for our SYN/ACK, send an RST
	 */
d1100 19
a1118 5
	case TCPS_SYN_RECEIVED:
		if (tiflags & TH_ACK) {
			if (tiflags & TH_SYN) {
				tcpstat.tcps_badsyn++;
				goto dropwithreset;
a1119 3
			if (SEQ_LEQ(th->th_ack, tp->snd_una) ||
			    SEQ_GT(th->th_ack, tp->snd_max))
				goto dropwithreset;
d1121 157
a1277 1
		break;
a1314 4
		tcp_mss(tp, opti.maxseg);
		/* Reset initial window to 1 segment for retransmit */
		if (tp->t_rxtshift > 0)
			tp->snd_cwnd = tp->t_maxseg;
d1323 3
a1325 2
		if (tp->sack_enable)
			tp->sack_enable = tp->t_flags & TF_SACK_PERMIT;
a1348 1
			TCP_TIMER_ARM(tp, TCPT_KEEP, tcp_keepidle);
d1363 9
a1374 1
#if 0
a1375 1
#endif
d1403 1
a1403 1
	 * and it's less than opti.ts_recent, drop it.
d1405 2
a1406 2
	if (opti.ts_present && (tiflags & TH_RST) == 0 && tp->ts_recent &&
	    TSTMP_LT(opti.ts_val, tp->ts_recent)) {
d1528 1
a1528 1
	if (opti.ts_present && TSTMP_GEQ(opti.ts_val, tp->ts_recent) &&
d1531 1
a1531 1
		tp->ts_recent = opti.ts_val;
a1608 1
		TCP_TIMER_ARM(tp, TCPT_KEEP, tcp_keepidle);
d1755 1
a1755 1
                    			if (tp->sack_enable) {
d1809 1
a1809 1
					if (tp->sack_enable) {
d1835 1
a1835 1
		if (tp->sack_enable) {
d1900 2
a1901 2
		if (opti.ts_present)
			tcp_xmit_timer(tp, tcp_now-opti.ts_ecr+1);
d2140 1
a2140 1
		if (tp->sack_enable)
d2209 2
a2210 14
	if (so->so_options & SO_DEBUG) {
		switch (tp->pf) {
#ifdef INET6
		case PF_INET6:
			tcp_trace(TA_INPUT, ostate, tp, (caddr_t) &tcp_saveti6,
			    0, tlen);
			break;
#endif /* INET6 */
		case PF_INET:
			tcp_trace(TA_INPUT, ostate, tp, (caddr_t) &tcp_saveti,
			    0, tlen);
			break;
		}
	}
d2218 1
a2220 8
badsyn:
	/*
	 * Received a bad SYN.  Increment counters and dropwithreset.
	 */
	tcpstat.tcps_badsyn++;
	tp = NULL;
	goto dropwithreset;

d2231 1
d2252 1
a2252 1
	 * Don't bother to respond to RST.
d2254 1
a2254 1
	if (tiflags & TH_RST)
d2256 13
d2278 4
d2288 2
a2289 14
	if (tp && (tp->t_inpcb->inp_socket->so_options & SO_DEBUG)) {
		switch (tp->pf) {
#ifdef INET6
		case PF_INET6:
			tcp_trace(TA_DROP, ostate, tp, (caddr_t) &tcp_saveti6,
			    0, tlen);
			break;
#endif /* INET6 */
		case PF_INET:
			tcp_trace(TA_DROP, ostate, tp, (caddr_t) &tcp_saveti,
			    0, tlen);
			break;
		}
	}
d2291 1
d2293 3
d2300 2
a2301 2
int
tcp_dooptions(tp, cp, cnt, th, m, iphlen, oi)
d2306 2
a2307 3
	struct mbuf *m;
	int iphlen;
	struct tcp_opt_info *oi;
d2311 1
a2311 8
#ifdef TCP_SIGNATURE
	caddr_t sigp = NULL;
	struct tdb *tdb = NULL;
#endif /* TCP_SIGNATURE */

#ifdef TCP_SIGNATURE
	if (cp)
#endif /* TCP_SIGNATURE */
a2336 1
			oi->maxseg = mss;
d2351 5
a2355 5
			oi->ts_present = 1;
			bcopy(cp + 2, &oi->ts_val, sizeof(oi->ts_val));
			NTOHL(oi->ts_val);
			bcopy(cp + 6, &oi->ts_ecr, sizeof(oi->ts_ecr));
			NTOHL(oi->ts_ecr);
d2363 1
a2363 1
				tp->ts_recent = oi->ts_val;
d2370 1
a2370 1
			if (!tp->sack_enable || optlen!=TCPOLEN_SACK_PERMITTED)
a2380 43
#ifdef TCP_SIGNATURE
		case TCPOPT_SIGNATURE:
			if (optlen != TCPOLEN_SIGNATURE)
				continue;

			if (sigp && bcmp(sigp, cp + 2, 16))
				return (-1);

			sigp = cp + 2;
			break;
#endif /* TCP_SIGNATURE */
		}
	}

#ifdef TCP_SIGNATURE
	if (tp->t_flags & TF_SIGNATURE) {
		union sockaddr_union src, dst;

		memset(&src, 0, sizeof(union sockaddr_union));
		memset(&dst, 0, sizeof(union sockaddr_union));

		switch (tp->pf) {
		case 0:
#ifdef INET
		case AF_INET:
			src.sa.sa_len = sizeof(struct sockaddr_in);
			src.sa.sa_family = AF_INET;
			src.sin.sin_addr = mtod(m, struct ip *)->ip_src;
			dst.sa.sa_len = sizeof(struct sockaddr_in);
			dst.sa.sa_family = AF_INET;
			dst.sin.sin_addr = mtod(m, struct ip *)->ip_dst;
			break;
#endif
#ifdef INET6
		case AF_INET6:
			src.sa.sa_len = sizeof(struct sockaddr_in6);
			src.sa.sa_family = AF_INET6;
			src.sin6.sin6_addr = mtod(m, struct ip6_hdr *)->ip6_src;
			dst.sa.sa_len = sizeof(struct sockaddr_in6);
			dst.sa.sa_family = AF_INET6;
			dst.sin6.sin6_addr = mtod(m, struct ip6_hdr *)->ip6_dst;
			break;
#endif /* INET6 */
a2381 15

		tdb = gettdbbysrcdst(0, &src, &dst, IPPROTO_TCP);

		/*
		 * We don't have an SA for this peer, so we turn off
		 * TF_SIGNATURE on the listen socket
		 */
		if (tdb == NULL && tp->t_state == TCPS_LISTEN)
			tp->t_flags &= ~TF_SIGNATURE;

	}

	if ((sigp ? TF_SIGNATURE : 0) ^ (tp->t_flags & TF_SIGNATURE)) {
		tcpstat.tcps_rcvbadsig++;
		return (-1);
d2383 3
d2387 2
a2388 87
	if (sigp) {
		MD5_CTX ctx;
		char sig[16];

		if (tdb == NULL) {
			tcpstat.tcps_rcvbadsig++;
			return (-1);
		}

		MD5Init(&ctx);

		switch(tp->pf) {
		case 0:
#ifdef INET
		case AF_INET:
			{
				struct ippseudo ippseudo;

				ippseudo.ippseudo_src =
				    mtod(m, struct ip *)->ip_src;
				ippseudo.ippseudo_dst =
				    mtod(m, struct ip *)->ip_dst;
				ippseudo.ippseudo_pad = 0;
				ippseudo.ippseudo_p = IPPROTO_TCP;
				ippseudo.ippseudo_len = htons(
				    m->m_pkthdr.len - iphlen);

				MD5Update(&ctx, (char *)&ippseudo,
				    sizeof(struct ippseudo));
			}
			break;
#endif /* INET */
#ifdef INET6
		case AF_INET6:
			{
				struct ip6_hdr_pseudo ip6pseudo;
 
				bzero(&ip6pseudo, sizeof(ip6pseudo));
				ip6pseudo.ip6ph_src =
				    mtod(m, struct ip6_hdr *)->ip6_src;
				ip6pseudo.ip6ph_dst =
				    mtod(m, struct ip6_hdr *)->ip6_dst;
				in6_clearscope(&ip6pseudo.ip6ph_src);
				in6_clearscope(&ip6pseudo.ip6ph_dst);
				ip6pseudo.ip6ph_nxt = IPPROTO_TCP;
				ip6pseudo.ip6ph_len = htonl(m->m_pkthdr.len -
				    iphlen);
    
				MD5Update(&ctx, (char *)&ip6pseudo,
				    sizeof(ip6pseudo));
			}
			break;
#endif /* INET6 */
		}

		{
			struct tcphdr tcphdr;

			tcphdr.th_sport = th->th_sport;
			tcphdr.th_dport = th->th_dport;
			tcphdr.th_seq = htonl(th->th_seq);
			tcphdr.th_ack = htonl(th->th_ack);
			tcphdr.th_off = th->th_off;
			tcphdr.th_x2 = th->th_x2;
			tcphdr.th_flags = th->th_flags;
			tcphdr.th_win = htons(th->th_win);
			tcphdr.th_sum = 0;
			tcphdr.th_urp = htons(th->th_urp);

			MD5Update(&ctx, (char *)&tcphdr,
			    sizeof(struct tcphdr));
		}

		if (m_apply(m, iphlen + th->th_off * sizeof(uint32_t),
		    m->m_pkthdr.len - (iphlen + th->th_off * sizeof(uint32_t)),
		    tcp_signature_apply, (caddr_t)&ctx))
			return (-1); 

		MD5Update(&ctx, tdb->tdb_amxkey, tdb->tdb_amxkeylen);
		MD5Final(sig, &ctx);

		if (bcmp(sig, sigp, 16)) {
			tcpstat.tcps_rcvbadsig++;
			return (-1);
		}

		tcpstat.tcps_rcvgoodsig++;
a2389 3
#endif /* TCP_SIGNATURE */

	return (0);
d2510 1
a2510 1
	if (!tp->sack_enable)
d2727 1
a2727 1
	if (tp->sack_enable && tp->t_state != TCPS_LISTEN) {
d3030 1
a3030 1
	 * However, do not accept offers under 216 bytes.
d3036 1
a3036 1
	mss = max(mss, 216);		/* sanity - at least max opt. space */
a3061 3
	} else if (tcp_do_rfc3390) {
		/* increase initial window  */
		tp->snd_cwnd = ulmin(4 * mss, ulmax(2 * mss, 4380));
a3218 1150

static int
tcp_mss_adv(struct ifnet *ifp, int af)
{
	u_int16_t mss = 0;
	int iphlen;

	switch (af) {
	case AF_INET:
		if (ifp != NULL)
			mss = ifp->if_mtu;
		iphlen = sizeof(struct ip);
		break;
#ifdef INET6
	case AF_INET6: 
		if (ifp != NULL)
			mss = IN6_LINKMTU(ifp);
		iphlen = sizeof(struct ip6_hdr);
		break;
#endif  
	}
	mss = mss - iphlen - sizeof(struct tcphdr);
	return (max(mss, tcp_mssdflt));
}

/*
 * TCP compressed state engine.  Currently used to hold compressed
 * state for SYN_RECEIVED.
 */

u_long	syn_cache_count;
u_int32_t syn_hash1, syn_hash2;

#define SYN_HASH(sa, sp, dp) \
	((((sa)->s_addr^syn_hash1)*(((((u_int32_t)(dp))<<16) + \
				     ((u_int32_t)(sp)))^syn_hash2)))
#ifndef INET6
#define	SYN_HASHALL(hash, src, dst) \
do {									\
	hash = SYN_HASH(&((struct sockaddr_in *)(src))->sin_addr,	\
		((struct sockaddr_in *)(src))->sin_port,		\
		((struct sockaddr_in *)(dst))->sin_port);		\
} while (/*CONSTCOND*/ 0)
#else
#define SYN_HASH6(sa, sp, dp) \
	((((sa)->s6_addr32[0] ^ (sa)->s6_addr32[3] ^ syn_hash1) * \
	  (((((u_int32_t)(dp))<<16) + ((u_int32_t)(sp)))^syn_hash2)) \
	 & 0x7fffffff)

#define SYN_HASHALL(hash, src, dst) \
do {									\
	switch ((src)->sa_family) {					\
	case AF_INET:							\
		hash = SYN_HASH(&((struct sockaddr_in *)(src))->sin_addr, \
			((struct sockaddr_in *)(src))->sin_port,	\
			((struct sockaddr_in *)(dst))->sin_port);	\
		break;							\
	case AF_INET6:							\
		hash = SYN_HASH6(&((struct sockaddr_in6 *)(src))->sin6_addr, \
			((struct sockaddr_in6 *)(src))->sin6_port,	\
			((struct sockaddr_in6 *)(dst))->sin6_port);	\
		break;							\
	default:							\
		hash = 0;						\
	}								\
} while (/*CONSTCOND*/0)
#endif /* INET6 */

#define	SYN_CACHE_RM(sc)						\
do {									\
	TAILQ_REMOVE(&tcp_syn_cache[(sc)->sc_bucketidx].sch_bucket,	\
	    (sc), sc_bucketq);						\
	(sc)->sc_tp = NULL;						\
	LIST_REMOVE((sc), sc_tpq);					\
	tcp_syn_cache[(sc)->sc_bucketidx].sch_length--;			\
	timeout_del(&(sc)->sc_timer);					\
	syn_cache_count--;						\
} while (/*CONSTCOND*/0)

#define	SYN_CACHE_PUT(sc)						\
do {									\
	if ((sc)->sc_ipopts)						\
		(void) m_free((sc)->sc_ipopts);				\
	if ((sc)->sc_route4.ro_rt != NULL)				\
		RTFREE((sc)->sc_route4.ro_rt);				\
	pool_put(&syn_cache_pool, (sc));				\
} while (/*CONSTCOND*/0)

struct pool syn_cache_pool;

/*
 * We don't estimate RTT with SYNs, so each packet starts with the default
 * RTT and each timer step has a fixed timeout value.
 */
#define	SYN_CACHE_TIMER_ARM(sc)						\
do {									\
	TCPT_RANGESET((sc)->sc_rxtcur,					\
	    TCPTV_SRTTDFLT * tcp_backoff[(sc)->sc_rxtshift], TCPTV_MIN,	\
	    TCPTV_REXMTMAX);						\
	if (!timeout_initialized(&(sc)->sc_timer))			\
		timeout_set(&(sc)->sc_timer, syn_cache_timer, (sc));	\
	timeout_add(&(sc)->sc_timer, (sc)->sc_rxtcur * (hz / PR_SLOWHZ)); \
} while (/*CONSTCOND*/0)

#define	SYN_CACHE_TIMESTAMP(sc)	tcp_now

void
syn_cache_init()
{
	int i;

	/* Initialize the hash buckets. */
	for (i = 0; i < tcp_syn_cache_size; i++)
		TAILQ_INIT(&tcp_syn_cache[i].sch_bucket);

	/* Initialize the syn cache pool. */
	pool_init(&syn_cache_pool, sizeof(struct syn_cache), 0, 0, 0,
	    "synpl", NULL);
}

void
syn_cache_insert(sc, tp)
	struct syn_cache *sc;
	struct tcpcb *tp;
{
	struct syn_cache_head *scp;
	struct syn_cache *sc2;
	int s;

	/*
	 * If there are no entries in the hash table, reinitialize
	 * the hash secrets.
	 */
	if (syn_cache_count == 0) {
		syn_hash1 = arc4random();
		syn_hash2 = arc4random();
	}

	SYN_HASHALL(sc->sc_hash, &sc->sc_src.sa, &sc->sc_dst.sa);
	sc->sc_bucketidx = sc->sc_hash % tcp_syn_cache_size;
	scp = &tcp_syn_cache[sc->sc_bucketidx];

	/*
	 * Make sure that we don't overflow the per-bucket
	 * limit or the total cache size limit.
	 */
	s = splsoftnet();
	if (scp->sch_length >= tcp_syn_bucket_limit) {
		tcpstat.tcps_sc_bucketoverflow++;
		/*
		 * The bucket is full.  Toss the oldest element in the
		 * bucket.  This will be the first entry in the bucket.
		 */
		sc2 = TAILQ_FIRST(&scp->sch_bucket);
#ifdef DIAGNOSTIC
		/*
		 * This should never happen; we should always find an
		 * entry in our bucket.
		 */
		if (sc2 == NULL)
			panic("syn_cache_insert: bucketoverflow: impossible");
#endif
		SYN_CACHE_RM(sc2);
		SYN_CACHE_PUT(sc2);
	} else if (syn_cache_count >= tcp_syn_cache_limit) {
		struct syn_cache_head *scp2, *sce;

		tcpstat.tcps_sc_overflowed++;
		/*
		 * The cache is full.  Toss the oldest entry in the
		 * first non-empty bucket we can find.
		 *
		 * XXX We would really like to toss the oldest
		 * entry in the cache, but we hope that this
		 * condition doesn't happen very often.
		 */
		scp2 = scp;
		if (TAILQ_EMPTY(&scp2->sch_bucket)) {
			sce = &tcp_syn_cache[tcp_syn_cache_size];
			for (++scp2; scp2 != scp; scp2++) {
				if (scp2 >= sce)
					scp2 = &tcp_syn_cache[0];
				if (! TAILQ_EMPTY(&scp2->sch_bucket))
					break;
			}
#ifdef DIAGNOSTIC
			/*
			 * This should never happen; we should always find a
			 * non-empty bucket.
			 */
			if (scp2 == scp)
				panic("syn_cache_insert: cacheoverflow: "
				    "impossible");
#endif
		}
		sc2 = TAILQ_FIRST(&scp2->sch_bucket);
		SYN_CACHE_RM(sc2);
		SYN_CACHE_PUT(sc2);
	}

	/*
	 * Initialize the entry's timer.
	 */
	sc->sc_rxttot = 0;
	sc->sc_rxtshift = 0;
	SYN_CACHE_TIMER_ARM(sc);

	/* Link it from tcpcb entry */
	LIST_INSERT_HEAD(&tp->t_sc, sc, sc_tpq);

	/* Put it into the bucket. */
	TAILQ_INSERT_TAIL(&scp->sch_bucket, sc, sc_bucketq);
	scp->sch_length++;
	syn_cache_count++;

	tcpstat.tcps_sc_added++;
	splx(s);
}

/*
 * Walk the timer queues, looking for SYN,ACKs that need to be retransmitted.
 * If we have retransmitted an entry the maximum number of times, expire
 * that entry.
 */
void
syn_cache_timer(void *arg)
{
	struct syn_cache *sc = arg;
	int s;

	s = splsoftnet();

	if (__predict_false(sc->sc_rxtshift == TCP_MAXRXTSHIFT)) {
		/* Drop it -- too many retransmissions. */
		goto dropit;
	}

	/*
	 * Compute the total amount of time this entry has
	 * been on a queue.  If this entry has been on longer
	 * than the keep alive timer would allow, expire it.
	 */
	sc->sc_rxttot += sc->sc_rxtcur;
	if (sc->sc_rxttot >= tcptv_keep_init)
		goto dropit;

	tcpstat.tcps_sc_retransmitted++;
	(void) syn_cache_respond(sc, NULL);

	/* Advance the timer back-off. */
	sc->sc_rxtshift++;
	SYN_CACHE_TIMER_ARM(sc);

	splx(s);
	return;

 dropit:
	tcpstat.tcps_sc_timed_out++;
	SYN_CACHE_RM(sc);
	SYN_CACHE_PUT(sc);
	splx(s);
}

/*
 * Remove syn cache created by the specified tcb entry,
 * because this does not make sense to keep them
 * (if there's no tcb entry, syn cache entry will never be used)
 */
void
syn_cache_cleanup(tp)
	struct tcpcb *tp;
{
	struct syn_cache *sc, *nsc;
	int s;

	s = splsoftnet();

	for (sc = LIST_FIRST(&tp->t_sc); sc != NULL; sc = nsc) {
		nsc = LIST_NEXT(sc, sc_tpq);

#ifdef DIAGNOSTIC
		if (sc->sc_tp != tp)
			panic("invalid sc_tp in syn_cache_cleanup");
#endif
		SYN_CACHE_RM(sc);
		SYN_CACHE_PUT(sc);
	}
	/* just for safety */
	LIST_INIT(&tp->t_sc);

	splx(s);
}

/*
 * Find an entry in the syn cache.
 */
struct syn_cache *
syn_cache_lookup(src, dst, headp)
	struct sockaddr *src;
	struct sockaddr *dst;
	struct syn_cache_head **headp;
{
	struct syn_cache *sc;
	struct syn_cache_head *scp;
	u_int32_t hash;
	int s;

	SYN_HASHALL(hash, src, dst);

	scp = &tcp_syn_cache[hash % tcp_syn_cache_size];
	*headp = scp;
	s = splsoftnet();
	for (sc = TAILQ_FIRST(&scp->sch_bucket); sc != NULL;
	     sc = TAILQ_NEXT(sc, sc_bucketq)) {
		if (sc->sc_hash != hash)
			continue;
		if (!bcmp(&sc->sc_src, src, src->sa_len) &&
		    !bcmp(&sc->sc_dst, dst, dst->sa_len)) {
			splx(s);
			return (sc);
		}
	}
	splx(s);
	return (NULL);
}

/*
 * This function gets called when we receive an ACK for a
 * socket in the LISTEN state.  We look up the connection
 * in the syn cache, and if its there, we pull it out of
 * the cache and turn it into a full-blown connection in
 * the SYN-RECEIVED state.
 *
 * The return values may not be immediately obvious, and their effects
 * can be subtle, so here they are:
 *
 *	NULL	SYN was not found in cache; caller should drop the
 *		packet and send an RST.
 *
 *	-1	We were unable to create the new connection, and are
 *		aborting it.  An ACK,RST is being sent to the peer
 *		(unless we got screwey sequence numbners; see below),
 *		because the 3-way handshake has been completed.  Caller
 *		should not free the mbuf, since we may be using it.  If
 *		we are not, we will free it.
 *
 *	Otherwise, the return value is a pointer to the new socket
 *	associated with the connection.
 */
struct socket *
syn_cache_get(src, dst, th, hlen, tlen, so, m)
	struct sockaddr *src;
	struct sockaddr *dst;
	struct tcphdr *th;
	unsigned int hlen, tlen;
	struct socket *so;
	struct mbuf *m;
{
	struct syn_cache *sc;
	struct syn_cache_head *scp;
	struct inpcb *inp = NULL;
	struct tcpcb *tp = 0;
	struct mbuf *am;
	int s;
	struct socket *oso;

	s = splsoftnet();
	if ((sc = syn_cache_lookup(src, dst, &scp)) == NULL) {
		splx(s);
		return (NULL);
	}

	/*
	 * Verify the sequence and ack numbers.  Try getting the correct
	 * response again.
	 */
	if ((th->th_ack != sc->sc_iss + 1) ||
	    SEQ_LEQ(th->th_seq, sc->sc_irs) ||
	    SEQ_GT(th->th_seq, sc->sc_irs + 1 + sc->sc_win)) {
		(void) syn_cache_respond(sc, m);
		splx(s);
		return ((struct socket *)(-1));
	}

	/* Remove this cache entry */
	SYN_CACHE_RM(sc);
	splx(s);

	/*
	 * Ok, create the full blown connection, and set things up
	 * as they would have been set up if we had created the
	 * connection when the SYN arrived.  If we can't create
	 * the connection, abort it.
	 */
	oso = so;
	so = sonewconn(so, SS_ISCONNECTED);
	if (so == NULL)
		goto resetandabort;

	inp = sotoinpcb(oso);
#ifdef IPSEC
	/*
	 * We need to copy the required security levels
	 * from the old pcb. Ditto for any other
	 * IPsec-related information.
	 */
	{
	  struct inpcb *newinp = (struct inpcb *)so->so_pcb;
	  bcopy(inp->inp_seclevel, newinp->inp_seclevel,
		sizeof(inp->inp_seclevel));
	  newinp->inp_secrequire = inp->inp_secrequire;
	  if (inp->inp_ipo != NULL) {
		  newinp->inp_ipo = inp->inp_ipo;
		  inp->inp_ipo->ipo_ref_count++;
	  }
	  if (inp->inp_ipsec_remotecred != NULL) {
		  newinp->inp_ipsec_remotecred = inp->inp_ipsec_remotecred;
		  inp->inp_ipsec_remotecred->ref_count++;
	  }
	  if (inp->inp_ipsec_remoteauth != NULL) {
		  newinp->inp_ipsec_remoteauth
		      = inp->inp_ipsec_remoteauth;
		  inp->inp_ipsec_remoteauth->ref_count++;
	  }
	}
#endif /* IPSEC */
#ifdef INET6
	/*
	 * inp still has the OLD in_pcb stuff, set the
	 * v6-related flags on the new guy, too.
	 */
	{
	  int flags = inp->inp_flags;
	  struct inpcb *oldinpcb = inp;

	  inp = (struct inpcb *)so->so_pcb;
	  inp->inp_flags |= (flags & INP_IPV6);
	  if ((inp->inp_flags & INP_IPV6) != 0) {
	    inp->inp_ipv6.ip6_hlim =
	      oldinpcb->inp_ipv6.ip6_hlim;
	  }
	}
#else /* INET6 */
	inp = (struct inpcb *)so->so_pcb;
#endif /* INET6 */

	inp->inp_lport = th->th_dport;
	switch (src->sa_family) {
#ifdef INET6
	case AF_INET6:
		inp->inp_laddr6 = ((struct sockaddr_in6 *)dst)->sin6_addr;
		break;
#endif /* INET6 */
	case AF_INET:

		inp->inp_laddr = ((struct sockaddr_in *)dst)->sin_addr;
		inp->inp_options = ip_srcroute();
		if (inp->inp_options == NULL) {
			inp->inp_options = sc->sc_ipopts;
			sc->sc_ipopts = NULL;
		}
		break;
	}
	in_pcbrehash(inp);

	/*
	 * Give the new socket our cached route reference.
	 */
	if (inp)
		inp->inp_route = sc->sc_route4;         /* struct assignment */
#ifdef INET6
	else
		inp->inp_route6 = sc->sc_route6;
#endif  
	sc->sc_route4.ro_rt = NULL;

	am = m_get(M_DONTWAIT, MT_SONAME);	/* XXX */
	if (am == NULL)
		goto resetandabort;
	am->m_len = src->sa_len;
	bcopy(src, mtod(am, caddr_t), src->sa_len);

	switch (src->sa_family) {
	case AF_INET:
		/* drop IPv4 packet to AF_INET6 socket */
		if (inp->inp_flags & INP_IPV6) {
			(void) m_free(am);
			goto resetandabort;
		}
		if (in_pcbconnect(inp, am)) {
			(void) m_free(am);
			goto resetandabort;
		}
		break;
#ifdef INET6
	case AF_INET6:
		if (in6_pcbconnect(inp, am)) {
			(void) m_free(am);
			goto resetandabort;
		}
		break;
#endif
	}
	(void) m_free(am);

	tp = intotcpcb(inp);
	tp->t_flags = sototcpcb(oso)->t_flags & TF_NODELAY;
	if (sc->sc_request_r_scale != 15) {
		tp->requested_s_scale = sc->sc_requested_s_scale;
		tp->request_r_scale = sc->sc_request_r_scale;
		tp->snd_scale = sc->sc_requested_s_scale;
		tp->rcv_scale = sc->sc_request_r_scale;
		tp->t_flags |= TF_REQ_SCALE|TF_RCVD_SCALE;
	}
	if (sc->sc_flags & SCF_TIMESTAMP)
		tp->t_flags |= TF_REQ_TSTMP|TF_RCVD_TSTMP;

	tp->t_template = tcp_template(tp);
	if (tp->t_template == 0) {
		tp = tcp_drop(tp, ENOBUFS);	/* destroys socket */
		so = NULL;
		m_freem(m);
		goto abort;
	}
#ifdef TCP_SACK
	tp->sack_enable = sc->sc_flags & SCF_SACK_PERMIT;
#endif

	tp->iss = sc->sc_iss;
	tp->irs = sc->sc_irs;
	tcp_sendseqinit(tp);
#if defined (TCP_SACK) || defined(TCP_ECN)
	tp->snd_last = tp->snd_una;
#endif /* TCP_SACK */
#if defined(TCP_SACK) && defined(TCP_FACK)
	tp->snd_fack = tp->snd_una;
	tp->retran_data = 0;
	tp->snd_awnd = 0;
#endif /* TCP_FACK */
#ifdef TCP_ECN
	if (sc->sc_flags & SCF_ECN_PERMIT) {
		tp->t_flags |= TF_ECN_PERMIT;
		tcpstat.tcps_ecn_accepts++;
	}
#endif
#ifdef TCP_SACK
	if (sc->sc_flags & SCF_SACK_PERMIT)
		tp->t_flags |= TF_SACK_PERMIT;
#endif
#ifdef TCP_SIGNATURE
	if (sc->sc_flags & SCF_SIGNATURE)
		tp->t_flags |= TF_SIGNATURE;
#endif
	tcp_rcvseqinit(tp);
	tp->t_state = TCPS_SYN_RECEIVED;
	tp->t_rcvtime = tcp_now;
	TCP_TIMER_ARM(tp, TCPT_KEEP, tcptv_keep_init);
	tcpstat.tcps_accepts++;

	tcp_mss(tp, sc->sc_peermaxseg);	 /* sets t_maxseg */
	if (sc->sc_peermaxseg)
		tcp_mss_update(tp);
	/* Reset initial window to 1 segment for retransmit */
	if (sc->sc_rxtshift > 0)
		tp->snd_cwnd = tp->t_maxseg;
	tp->snd_wl1 = sc->sc_irs;
	tp->rcv_up = sc->sc_irs + 1;

	/*
	 * This is what whould have happened in tcp_output() when
	 * the SYN,ACK was sent.
	 */
	tp->snd_up = tp->snd_una;
	tp->snd_max = tp->snd_nxt = tp->iss+1;
	TCP_TIMER_ARM(tp, TCPT_REXMT, tp->t_rxtcur);
	if (sc->sc_win > 0 && SEQ_GT(tp->rcv_nxt + sc->sc_win, tp->rcv_adv))
		tp->rcv_adv = tp->rcv_nxt + sc->sc_win;
	tp->last_ack_sent = tp->rcv_nxt;

	tcpstat.tcps_sc_completed++;
	SYN_CACHE_PUT(sc);
	return (so);

resetandabort:
	(void) tcp_respond(NULL, mtod(m, caddr_t), m,
			   th->th_seq + tlen, (tcp_seq)0, TH_RST|TH_ACK);
abort:
	if (so != NULL)
		(void) soabort(so);
	SYN_CACHE_PUT(sc);
	tcpstat.tcps_sc_aborted++;
	return ((struct socket *)(-1));
}

/*
 * This function is called when we get a RST for a
 * non-existent connection, so that we can see if the
 * connection is in the syn cache.  If it is, zap it.
 */

void
syn_cache_reset(src, dst, th)
	struct sockaddr *src;
	struct sockaddr *dst;
	struct tcphdr *th;
{
	struct syn_cache *sc;
	struct syn_cache_head *scp;
	int s = splsoftnet();

	if ((sc = syn_cache_lookup(src, dst, &scp)) == NULL) {
		splx(s);
		return;
	}
	if (SEQ_LT(th->th_seq, sc->sc_irs) ||
	    SEQ_GT(th->th_seq, sc->sc_irs+1)) {
		splx(s);
		return;
	}
	SYN_CACHE_RM(sc);
	splx(s);
	tcpstat.tcps_sc_reset++;
	SYN_CACHE_PUT(sc);
}

void
syn_cache_unreach(src, dst, th)
	struct sockaddr *src;
	struct sockaddr *dst;
	struct tcphdr *th;
{
	struct syn_cache *sc;
	struct syn_cache_head *scp;
	int s;

	s = splsoftnet();
	if ((sc = syn_cache_lookup(src, dst, &scp)) == NULL) {
		splx(s);
		return;
	}
	/* If the sequence number != sc_iss, then it's a bogus ICMP msg */
	if (ntohl (th->th_seq) != sc->sc_iss) {
		splx(s);
		return;
	}

	/*
	 * If we've retransmitted 3 times and this is our second error,
	 * we remove the entry.  Otherwise, we allow it to continue on.
	 * This prevents us from incorrectly nuking an entry during a
	 * spurious network outage.
	 *
	 * See tcp_notify().
	 */
	if ((sc->sc_flags & SCF_UNREACH) == 0 || sc->sc_rxtshift < 3) {
		sc->sc_flags |= SCF_UNREACH;
		splx(s);
		return;
	}

	SYN_CACHE_RM(sc);
	splx(s);
	tcpstat.tcps_sc_unreach++;
	SYN_CACHE_PUT(sc);
}

/*
 * Given a LISTEN socket and an inbound SYN request, add
 * this to the syn cache, and send back a segment:
 *	<SEQ=ISS><ACK=RCV_NXT><CTL=SYN,ACK>
 * to the source.
 *
 * IMPORTANT NOTE: We do _NOT_ ACK data that might accompany the SYN.
 * Doing so would require that we hold onto the data and deliver it
 * to the application.  However, if we are the target of a SYN-flood
 * DoS attack, an attacker could send data which would eventually
 * consume all available buffer space if it were ACKed.  By not ACKing
 * the data, we avoid this DoS scenario.
 */

int
syn_cache_add(src, dst, th, iphlen, so, m, optp, optlen, oi)
	struct sockaddr *src;
	struct sockaddr *dst;
	struct tcphdr *th;
	unsigned int iphlen;
	struct socket *so;
	struct mbuf *m;
	u_char *optp;
	int optlen;
	struct tcp_opt_info *oi;
{
	struct tcpcb tb, *tp;
	long win;
	struct syn_cache *sc;
	struct syn_cache_head *scp;
	struct mbuf *ipopts;

	tp = sototcpcb(so);

	/*
	 * RFC1122 4.2.3.10, p. 104: discard bcast/mcast SYN
	 *
	 * Note this check is performed in tcp_input() very early on.
	 */

	/*
	 * Initialize some local state.
	 */
	win = sbspace(&so->so_rcv);
	if (win > TCP_MAXWIN)
		win = TCP_MAXWIN;

#ifdef TCP_SIGNATURE
	if (optp || (tp->t_flags & TF_SIGNATURE)) {
#else
	if (optp) {
#endif
		tb.pf = tp->pf;
#ifdef TCP_SACK
		tb.sack_enable = tcp_do_sack;
#endif
		tb.t_flags = tcp_do_rfc1323 ? (TF_REQ_SCALE|TF_REQ_TSTMP) : 0;
#ifdef TCP_SIGNATURE
		tb.t_state = TCPS_LISTEN;
		if (tp->t_flags & TF_SIGNATURE)
			tb.t_flags |= TF_SIGNATURE;
#endif
		if (tcp_dooptions(&tb, optp, optlen, th, m, iphlen, oi))
			return (0);
	} else
		tb.t_flags = 0;

	switch (src->sa_family) {
#ifdef INET
	case AF_INET:
		/*
		 * Remember the IP options, if any.
		 */
		ipopts = ip_srcroute();
		break;
#endif
	default:
		ipopts = NULL;
	}

	/*
	 * See if we already have an entry for this connection.
	 * If we do, resend the SYN,ACK.  We do not count this
	 * as a retransmission (XXX though maybe we should).
	 */
	if ((sc = syn_cache_lookup(src, dst, &scp)) != NULL) {
		tcpstat.tcps_sc_dupesyn++;
		if (ipopts) {
			/*
			 * If we were remembering a previous source route,
			 * forget it and use the new one we've been given.
			 */
			if (sc->sc_ipopts)
				(void) m_free(sc->sc_ipopts);
			sc->sc_ipopts = ipopts;
		}
		sc->sc_timestamp = tb.ts_recent;
		if (syn_cache_respond(sc, m) == 0) {
			tcpstat.tcps_sndacks++;
			tcpstat.tcps_sndtotal++;
		}
		return (1);
	}

	sc = pool_get(&syn_cache_pool, PR_NOWAIT);
	if (sc == NULL) {
		if (ipopts)
			(void) m_free(ipopts);
		return (0);
	}

	/*
	 * Fill in the cache, and put the necessary IP and TCP
	 * options into the reply.
	 */
	bzero(sc, sizeof(struct syn_cache));
	bzero(&sc->sc_timer, sizeof(sc->sc_timer));
	bcopy(src, &sc->sc_src, src->sa_len);
	bcopy(dst, &sc->sc_dst, dst->sa_len);
	sc->sc_flags = 0;
	sc->sc_ipopts = ipopts;
	sc->sc_irs = th->th_seq;

#ifdef TCP_COMPAT_42
	tcp_iss += TCP_ISSINCR/2;
	sc->sc_iss = tcp_iss;
#else
	sc->sc_iss = tcp_rndiss_next();
#endif
	sc->sc_peermaxseg = oi->maxseg;
	sc->sc_ourmaxseg = tcp_mss_adv(m->m_flags & M_PKTHDR ?
	    m->m_pkthdr.rcvif : NULL, sc->sc_src.sa.sa_family);
	sc->sc_win = win;
	sc->sc_timestamp = tb.ts_recent;
	if ((tb.t_flags & (TF_REQ_TSTMP|TF_RCVD_TSTMP)) ==
	    (TF_REQ_TSTMP|TF_RCVD_TSTMP))
		sc->sc_flags |= SCF_TIMESTAMP;
	if ((tb.t_flags & (TF_RCVD_SCALE|TF_REQ_SCALE)) ==
	    (TF_RCVD_SCALE|TF_REQ_SCALE)) {
		sc->sc_requested_s_scale = tb.requested_s_scale;
		sc->sc_request_r_scale = 0;
		while (sc->sc_request_r_scale < TCP_MAX_WINSHIFT &&
		    TCP_MAXWIN << sc->sc_request_r_scale <
		    so->so_rcv.sb_hiwat)
			sc->sc_request_r_scale++;
	} else {
		sc->sc_requested_s_scale = 15;
		sc->sc_request_r_scale = 15;
	}
#ifdef TCP_ECN
	/*
	 * if both ECE and CWR flag bits are set, peer is ECN capable.
	 */
	if (tcp_do_ecn &&
	    (th->th_flags & (TH_ECE|TH_CWR)) == (TH_ECE|TH_CWR))
		sc->sc_flags |= SCF_ECN_PERMIT;
#endif
#ifdef TCP_SACK
	/*
	 * Set SCF_SACK_PERMIT if peer did send a SACK_PERMITTED option
	 * (i.e., if tcp_dooptions() did set TF_SACK_PERMIT).
	 */
	if (tb.sack_enable && (tb.t_flags & TF_SACK_PERMIT))
		sc->sc_flags |= SCF_SACK_PERMIT;
#endif
#ifdef TCP_SIGNATURE
	if (tb.t_flags & TF_SIGNATURE)
		sc->sc_flags |= SCF_SIGNATURE;
#endif
	sc->sc_tp = tp;
	if (syn_cache_respond(sc, m) == 0) {
		syn_cache_insert(sc, tp);
		tcpstat.tcps_sndacks++;
		tcpstat.tcps_sndtotal++;
	} else {
		SYN_CACHE_PUT(sc);
		tcpstat.tcps_sc_dropped++;
	}
	return (1);
}

int
syn_cache_respond(sc, m)
	struct syn_cache *sc;
	struct mbuf *m;
{
	struct route *ro;
	u_int8_t *optp;
	int optlen, error;
	u_int16_t tlen;
	struct ip *ip = NULL;
#ifdef INET6
	struct ip6_hdr *ip6 = NULL;
#endif
	struct tcphdr *th;
	u_int hlen;
	struct inpcb *inp;

	switch (sc->sc_src.sa.sa_family) {
	case AF_INET:
		hlen = sizeof(struct ip);
		ro = &sc->sc_route4;
		break;
#ifdef INET6
	case AF_INET6:
		hlen = sizeof(struct ip6_hdr);
		ro = (struct route *)&sc->sc_route6;
		break;
#endif
	default:
		if (m)
			m_freem(m);
		return (EAFNOSUPPORT);
	}

	/* Compute the size of the TCP options. */
	optlen = 4 + (sc->sc_request_r_scale != 15 ? 4 : 0) +
#ifdef TCP_SACK
	    ((sc->sc_flags & SCF_SACK_PERMIT) ? 4 : 0) +
#endif
#ifdef TCP_SIGNATURE
	    ((sc->sc_flags & SCF_SIGNATURE) ? TCPOLEN_SIGNATURE + 2 : 0) +
#endif
	    ((sc->sc_flags & SCF_TIMESTAMP) ? TCPOLEN_TSTAMP_APPA : 0);

	tlen = hlen + sizeof(struct tcphdr) + optlen;

	/*
	 * Create the IP+TCP header from scratch.
	 */
	if (m)
		m_freem(m);
#ifdef DIAGNOSTIC
	if (max_linkhdr + tlen > MCLBYTES)
		return (ENOBUFS);
#endif
	MGETHDR(m, M_DONTWAIT, MT_DATA);
	if (m && tlen > MHLEN) {
		MCLGET(m, M_DONTWAIT);
		if ((m->m_flags & M_EXT) == 0) {
			m_freem(m);
			m = NULL;
		}
	}
	if (m == NULL)
		return (ENOBUFS);

	/* Fixup the mbuf. */
	m->m_data += max_linkhdr;
	m->m_len = m->m_pkthdr.len = tlen;
	m->m_pkthdr.rcvif = NULL;
	memset(mtod(m, u_char *), 0, tlen);

	switch (sc->sc_src.sa.sa_family) {
	case AF_INET:
		ip = mtod(m, struct ip *);
		ip->ip_dst = sc->sc_src.sin.sin_addr;
		ip->ip_src = sc->sc_dst.sin.sin_addr;
		ip->ip_p = IPPROTO_TCP;
		th = (struct tcphdr *)(ip + 1);
		th->th_dport = sc->sc_src.sin.sin_port;
		th->th_sport = sc->sc_dst.sin.sin_port;
		break;
#ifdef INET6
	case AF_INET6:
		ip6 = mtod(m, struct ip6_hdr *);
		ip6->ip6_dst = sc->sc_src.sin6.sin6_addr;
		ip6->ip6_src = sc->sc_dst.sin6.sin6_addr;
		ip6->ip6_nxt = IPPROTO_TCP;
		/* ip6_plen will be updated in ip6_output() */
		th = (struct tcphdr *)(ip6 + 1);
		th->th_dport = sc->sc_src.sin6.sin6_port;
		th->th_sport = sc->sc_dst.sin6.sin6_port;
		break;
#endif
	default:
		th = NULL;
	}

	th->th_seq = htonl(sc->sc_iss);
	th->th_ack = htonl(sc->sc_irs + 1);
	th->th_off = (sizeof(struct tcphdr) + optlen) >> 2;
	th->th_flags = TH_SYN|TH_ACK;
#ifdef TCP_ECN
	/* Set ECE for SYN-ACK if peer supports ECN. */
	if (tcp_do_ecn && (sc->sc_flags & SCF_ECN_PERMIT))
		th->th_flags |= TH_ECE;
#endif
	th->th_win = htons(sc->sc_win);
	/* th_sum already 0 */
	/* th_urp already 0 */

	/* Tack on the TCP options. */
	optp = (u_int8_t *)(th + 1);
	*optp++ = TCPOPT_MAXSEG;
	*optp++ = 4;
	*optp++ = (sc->sc_ourmaxseg >> 8) & 0xff;
	*optp++ = sc->sc_ourmaxseg & 0xff;

#ifdef TCP_SACK
	/* Include SACK_PERMIT_HDR option if peer has already done so. */
	if (sc->sc_flags & SCF_SACK_PERMIT) {
		*((u_int32_t *)optp) = htonl(TCPOPT_SACK_PERMIT_HDR);
		optp += 4;
	}
#endif

	if (sc->sc_request_r_scale != 15) {
		*((u_int32_t *)optp) = htonl(TCPOPT_NOP << 24 |
		    TCPOPT_WINDOW << 16 | TCPOLEN_WINDOW << 8 |
		    sc->sc_request_r_scale);
		optp += 4;
	}

	if (sc->sc_flags & SCF_TIMESTAMP) {
		u_int32_t *lp = (u_int32_t *)(optp);
		/* Form timestamp option as shown in appendix A of RFC 1323. */
		*lp++ = htonl(TCPOPT_TSTAMP_HDR);
		*lp++ = htonl(SYN_CACHE_TIMESTAMP(sc));
		*lp   = htonl(sc->sc_timestamp);
		optp += TCPOLEN_TSTAMP_APPA;
	}

#ifdef TCP_SIGNATURE
	if (sc->sc_flags & SCF_SIGNATURE) {
		MD5_CTX ctx;
		union sockaddr_union src, dst;
		struct tdb *tdb;

		bzero(&src, sizeof(union sockaddr_union));
		bzero(&dst, sizeof(union sockaddr_union));
		src.sa.sa_len = sc->sc_src.sa.sa_len;
		src.sa.sa_family = sc->sc_src.sa.sa_family;
		dst.sa.sa_len = sc->sc_dst.sa.sa_len;
		dst.sa.sa_family = sc->sc_dst.sa.sa_family;

		switch (sc->sc_src.sa.sa_family) {
		case 0:	/*default to PF_INET*/
#ifdef INET
		case AF_INET:
			src.sin.sin_addr = mtod(m, struct ip *)->ip_src;
			dst.sin.sin_addr = mtod(m, struct ip *)->ip_dst;
			break;
#endif /* INET */
#ifdef INET6
		case AF_INET6:
			src.sin6.sin6_addr = mtod(m, struct ip6_hdr *)->ip6_src;
			dst.sin6.sin6_addr = mtod(m, struct ip6_hdr *)->ip6_dst;
			break;
#endif /* INET6 */
		}

		tdb = gettdbbysrcdst(0, &src, &dst, IPPROTO_TCP);
		if (tdb == NULL) {
			if (m)
				m_freem(m);
			return (EPERM);
		}

		MD5Init(&ctx);

		switch (sc->sc_src.sa.sa_family) {
		case 0:	/*default to PF_INET*/
#ifdef INET
		case AF_INET:
			{
				struct ippseudo ippseudo;

				ippseudo.ippseudo_src = ip->ip_src;
				ippseudo.ippseudo_dst = ip->ip_dst;
				ippseudo.ippseudo_pad = 0;
				ippseudo.ippseudo_p   = IPPROTO_TCP;
				ippseudo.ippseudo_len = htons(tlen - hlen);

				MD5Update(&ctx, (char *)&ippseudo,
				    sizeof(struct ippseudo));

			}
			break;
#endif /* INET */
#ifdef INET6
		case AF_INET6:
			{
				struct ip6_hdr_pseudo ip6pseudo;

				bzero(&ip6pseudo, sizeof(ip6pseudo));
				ip6pseudo.ip6ph_src = ip6->ip6_src;
				ip6pseudo.ip6ph_dst = ip6->ip6_dst;
				in6_clearscope(&ip6pseudo.ip6ph_src);
				in6_clearscope(&ip6pseudo.ip6ph_dst);
				ip6pseudo.ip6ph_nxt = IPPROTO_TCP;
				ip6pseudo.ip6ph_len = htonl(tlen - hlen);

				MD5Update(&ctx, (char *)&ip6pseudo,
				    sizeof(ip6pseudo));
			}
			break;
#endif /* INET6 */
		}

		th->th_sum = 0;
		MD5Update(&ctx, (char *)th, sizeof(struct tcphdr));
		MD5Update(&ctx, tdb->tdb_amxkey, tdb->tdb_amxkeylen);

		/* Send signature option */
		*(optp++) = TCPOPT_SIGNATURE;
		*(optp++) = TCPOLEN_SIGNATURE;

		MD5Final(optp, &ctx);
		optp += 16;

		/* Pad options list to the next 32 bit boundary and
		 * terminate it.
		 */
		*optp++ = TCPOPT_NOP;
		*optp++ = TCPOPT_EOL;
	}
#endif /* TCP_SIGNATURE */

	/* Compute the packet's checksum. */
	switch (sc->sc_src.sa.sa_family) {
	case AF_INET:
		ip->ip_len = htons(tlen - hlen);
		th->th_sum = 0;
		th->th_sum = in_cksum(m, tlen);
		break;
#ifdef INET6
	case AF_INET6:
		ip6->ip6_plen = htons(tlen - hlen);
		th->th_sum = 0;
		th->th_sum = in6_cksum(m, IPPROTO_TCP, hlen, tlen - hlen);
		break;
#endif
	}

	/*
	 * Fill in some straggling IP bits.  Note the stack expects
	 * ip_len to be in host order, for convenience.
	 */
	switch (sc->sc_src.sa.sa_family) {
#ifdef INET
	case AF_INET:
		ip->ip_len = htons(tlen);
		ip->ip_ttl = ip_defttl;
		/* XXX tos? */
		break;
#endif
#ifdef INET6
	case AF_INET6:
		ip6->ip6_vfc &= ~IPV6_VERSION_MASK;
		ip6->ip6_vfc |= IPV6_VERSION;
		ip6->ip6_plen = htons(tlen - hlen);
		/* ip6_hlim will be initialized afterwards */
		/* leave flowlabel = 0, it is legal and require no state mgmt */
		break;
#endif
	}

	/* use IPsec policy from listening socket, on SYN ACK */
	inp = sc->sc_tp ? sc->sc_tp->t_inpcb : NULL;

	switch (sc->sc_src.sa.sa_family) {
#ifdef INET
	case AF_INET:
		error = ip_output(m, sc->sc_ipopts, ro,
		    (ip_mtudisc ? IP_MTUDISC : 0), 
		    (struct ip_moptions *)NULL, inp);
		break;
#endif
#ifdef INET6
	case AF_INET6:
		ip6->ip6_hlim = in6_selecthlim(NULL,
				ro->ro_rt ? ro->ro_rt->rt_ifp : NULL);

		error = ip6_output(m, NULL /*XXX*/, (struct route_in6 *)ro, 0,
			(struct ip6_moptions *)0, NULL);
		break;
#endif
	default:
		error = EAFNOSUPPORT;
		break;
	}
	return (error);
}
@


1.56.2.11
log
@Merge with the trunk
@
text
@a97 2
struct	tcpiphdr tcp_saveti;

d102 1
d112 1
a112 1
#include <crypto/md5.h>
d116 1
a124 4
int tcp_ackdrop_ppslim = 100;		/* 100pps */
int tcp_ackdrop_ppslim_count = 0;
struct timeval tcp_ackdrop_ppslim_last;

d209 1
a209 1
	tiqe = pool_get(&tcpqe_pool, PR_NOWAIT);
d211 3
a213 15
		tiqe = LIST_FIRST(&tp->segq);
		if (tiqe != NULL && th->th_seq == tp->rcv_nxt) {
			/* Reuse last entry since new segment fills a hole */
			while ((p = LIST_NEXT(tiqe, ipqe_q)) != NULL)
				tiqe = p;
			m_freem(tiqe->ipqe_m);
			LIST_REMOVE(tiqe, ipqe_q);
		}
		if (tiqe == NULL || th->th_seq != tp->rcv_nxt) {
			/* Flush segment queue for this connection */
			tcp_freeq(tp);
			tcpstat.tcps_rcvmemdrop++;
			m_freem(m);
			return (0);
		}
d240 1
a240 1
				pool_put(&tcpqe_pool, tiqe);
d270 1
a270 1
		pool_put(&tcpqe_pool, q);
d273 1
a273 1
	/* Insert the new segment queue entry into place. */
d306 1
a306 1
		pool_put(&tcpqe_pool, q);
d362 1
a362 1
	int tlen, off;
d435 9
d460 6
a465 4
	IP6_EXTHDR_GET(th, struct tcphdr *, m, iphlen, sizeof(*th));
	if (!th) {
		tcpstat.tcps_rcvshort++;
		return;
a467 1
	tlen = m->m_pkthdr.len - iphlen;
d474 3
d481 4
d492 4
d502 1
a502 1
			if (in4_cksum(m, IPPROTO_TCP, iphlen, tlen) != 0) {
d511 1
d515 1
d558 2
d571 16
a586 4
		IP6_EXTHDR_GET(th, struct tcphdr *, m, iphlen, off);
		if (!th) {
			tcpstat.tcps_rcvshort++;
			return;
d717 1
a717 2
				bcopy(ip6, &tcp_saveti6.ti6_i, sizeof(*ip6));
				bcopy(th, &tcp_saveti6.ti6_t, sizeof(*th));
d721 1
a721 2
				bcopy(ip, &tcp_saveti.ti_i, sizeof(*ip));
				bcopy(th, &tcp_saveti.ti_t, sizeof(*th));
a1223 1
			tcp_reass_lock(tp);
a1225 1
			tcp_reass_unlock(tp);
d1440 1
a1440 1
	 * error and we ACK and drop the packet.
d1442 4
a1445 2
	if (tiflags & TH_SYN)
		goto dropafterack_ratelim;
a1477 1
		tcp_reass_lock(tp);
a1479 1
		tcp_reass_unlock(tp);
d1544 1
a1544 8
			if (tlen) {
				/* Drop very old ACKs unless th_seq matches */
				if (th->th_seq != tp->rcv_nxt &&
				   SEQ_LT(th->th_ack,
				   tp->snd_una - tp->max_sndwnd)) {
					tcpstat.tcps_rcvacktooold++;
					goto drop;
				}
a1545 1
			}
d1748 1
a1748 1
			goto dropafterack_ratelim;
a1981 1
		tcp_reass_lock(tp);
a1983 1
			tcp_reass_unlock(tp);
a1999 1
			tcp_reass_unlock(tp);
a2102 8
dropafterack_ratelim:
	if (ppsratecheck(&tcp_ackdrop_ppslim_last, &tcp_ackdrop_ppslim_count,
	    tcp_ackdrop_ppslim) == 0) {
		/* XXX stat */
		goto drop;
	}
	/* ...fall into dropafterack... */

d3004 1
a3004 10
		if (tp->pf == AF_INET6 && rt->rt_rmx.rmx_mtu < IPV6_MMTU) {
			/*
			 * RFC2460 section 5, last paragraph: if path MTU is
			 * smaller than 1280, use 1280 as packet size and
			 * attach fragment header.
			 */
			mss = IPV6_MMTU - iphlen - sizeof(struct ip6_frag) -
			    sizeof(struct tcphdr);
		} else
			mss = rt->rt_rmx.rmx_mtu - iphlen - sizeof(struct tcphdr);
d3037 3
a3039 1
		if (tp->pf == AF_INET6)
a3041 2
		else
			mssopt = ifp->if_mtu - iphlen - sizeof(struct tcphdr);
d3054 1
a3054 3
	 * 
	 * However, do not accept offers lower than the minimum of
	 * the interface MTU and 216.
d3059 2
a3060 4
		mss = min(mss, max(tp->t_peermss, 216));

	/* sanity - at least max opt. space */
	mss = max(mss, 64);
a3073 4
#ifdef TCP_SIGNATURE
	if (tp->t_flags & TF_SIGNATURE)
		mss -= TCPOLEN_SIGLEN;
#endif
d3111 1
a3111 1
	int mss;
d3124 39
a3162 1
	bufsize = so->so_snd.sb_hiwat;
d3174 4
a3177 1
	bufsize = so->so_rcv.sb_hiwat;
d3183 4
d3189 11
d3250 1
a3250 1
	int mss = 0;
d3714 1
a3714 1
	if (src->sa_family == AF_INET)
d3830 2
a3831 1
	tcp_respond(NULL, mtod(m, caddr_t), m, (tcp_seq)0, th->th_ack, TH_RST);
d4133 1
a4133 1
	    ((sc->sc_flags & SCF_SIGNATURE) ? TCPOLEN_SIGLEN : 0) +
@


1.56.2.12
log
@sync to head
@
text
@d112 4
d2191 4
a2194 1
	for (; cp && cnt > 0; cnt -= optlen, cp += optlen) {
d2326 1
d2334 71
a2404 2
		if (tcp_signature(tdb, tp->pf, m, th, iphlen, 1, sig) < 0)
			return (-1);
d4199 1
d4233 45
d4282 1
a4282 6
		if (tcp_signature(tdb, sc->sc_src.sa.sa_family, m, th,
		    hlen, 0, optp) < 0) {
			if (m)
				m_freem(m);
			return (EINVAL);
		}
@


1.55
log
@be paranoid about malicious use of v4 mapped addr on v6 packet.
malicious party may try to use v4 mapped addr as source/dest to
confuse tcp/udp layer, or to bypass security checks,
for example, naive stack can mistakingly think a packet with
src = ::ffff:127.0.0.1 is from local node.

(sync with kame)
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.54 1999/12/15 16:37:20 provos Exp $	*/
d840 1
a840 1
#if defined(TCP_SACK) || defined(TCP_NEWRENO)
d847 1
a847 1
#endif /* TCP_SACK or TCP_NEWRENO */
d1111 1
a1111 1
#if defined (TCP_SACK) || defined (TCP_NEWRENO)
d1113 1
a1113 1
#endif /* TCP_SACK || TCP_NEWRENO */
d1548 1
a1548 1
#if defined(TCP_SACK) || defined(TCP_NEWRENO) 
d1563 1
a1563 1
#if defined(TCP_SACK) || defined(TCP_NEWRENO)
d1634 1
a1634 17
#ifdef TCP_NEWRENO
		if (tp->t_dupacks >= tcprexmtthresh && !tcp_newreno(tp, th)) {
			/* Out of fast recovery */
			tp->snd_cwnd = tp->snd_ssthresh;
			/* 
			 * Window inflation should have left us with approx.
			 * snd_ssthresh outstanding data.  But in case we
			 * would be inclined to send a burst, better to do
			 * it via the slow start mechanism.
			 */
			if (tcp_seq_subtract(tp->snd_max, th->th_ack) <
			    tp->snd_ssthresh)
				tp->snd_cwnd = tcp_seq_subtract(tp->snd_max,
				    th->th_ack) + tp->t_maxseg;	
			tp->t_dupacks = 0;
		}
#elif defined(TCP_SACK)
d1675 1
a1675 1
#else /* else neither TCP_NEWRENO nor TCP_SACK */
d1727 1
a1727 1
#if defined (TCP_NEWRENO) || defined (TCP_SACK)
d2165 1
a2165 1
#if defined(TCP_SACK) || defined(TCP_NEWRENO)
d2898 1
a2898 1
#if defined(TCP_NEWRENO) || defined (TCP_SACK)
d2940 1
a2940 1
#endif /* TCP_NEWRENO || TCP_SACK */
@


1.54
log
@never go into persist mode if there are still segments to be retransmitted.
set retransmit timer again if it was cleared, that can happen in SACK when
there are no elligble SACK holes to be retransmitted and the receiver window
is full.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.53 1999/12/14 22:20:28 provos Exp $	*/
d491 7
@


1.53
log
@sack.end may not be > tp->snd_max but can be equal.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.52 1999/12/08 06:50:20 itojun Exp $	*/
a1580 12
						/* 
						 * It is possible for 
						 * tcp_output to fail to send
						 * a segment.  If so, make 
						 * sure that REMXT timer is set.
						 */ 
						if (SEQ_GT(tp->snd_max, 
						    tp->snd_una) &&
                        			tp->t_timer[TCPT_REXMT] == 0 &&
                        			tp->t_timer[TCPT_PERSIST] == 0)
                        			tp->t_timer[TCPT_REXMT] = 
						    tp->t_rxtcur;
a2017 11
#ifdef TCP_SACK
	/* 
	 * In SACK, it is possible for tcp_output() to fail to send a segment 
	 * after the retransmission timer has been turned off.  Make sure that
	 * the retransmission timer is set if we are in fast recovery. 
	 */
		if (needoutput && SEQ_GT(tp->snd_max, tp->snd_una) && 
		    tp->t_timer[TCPT_REXMT] == 0 && 
		    tp->t_timer[TCPT_PERSIST] == 0)
			tp->t_timer[TCPT_REXMT] = tp->t_rxtcur;
#endif
@


1.52
log
@bring in KAME IPv6 code, dated 19991208.
replaces NRL IPv6 layer.  reuses NRL pcb layer.  no IPsec-on-v6 support.
see sys/netinet6/{TODO,IMPLEMENTATION} for more details.

GENERIC configuration should work fine as before.  GENERIC.v6 works fine
as well, but you'll need KAME userland tools to play with IPv6 (will be
bringed into soon).
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.51 1999/11/15 05:50:59 hugh Exp $	*/
d2357 1
a2357 1
		if (SEQ_GEQ(sack.end, tp->snd_max))
@


1.51
log
@Fix tcp retransmit/persist timers, provos@@ OK.

Adapted from NetBSD:
    Fix a retransmission bug introduced by the Brakmo and Peterson
    RTO estimation changes.  Under some circumstances it would
    return a value of 0, while the old Van Jacobson RTO code would
    return a minimum of 3.  This would result in 12 retransmissions,
    each 1 second apart.  This takes care of those instances, and
    ensures that t_rttmin is used everywhere as a lower bound.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.50 1999/11/04 11:24:23 ho Exp $	*/
d85 3
d90 2
a91 2
#include <netinet6/ipv6.h>
#include <netinet6/ipv6_var.h>
d93 11
d110 1
a110 1
#define M_V6_LEN(m)      (M_PH_LEN(m) - sizeof(struct ipv6))
d128 16
d270 1
d329 38
d388 1
d405 1
a405 1
	struct ipv6 *ipv6 = NULL;
d442 2
a443 1
	if (iphlen > sizeof (struct ip))
d445 6
d471 1
a471 1
	  if (iphlen < sizeof(struct ipv6)) {
d478 2
a479 1
	  if (iphlen > sizeof(struct ipv6)) {
d481 6
a486 1
	    iphlen = sizeof(struct ipv6);
d490 1
a490 1
	  ipv6 = mtod(m, struct ipv6 *);
d492 1
a492 1
	  if (in6_cksum(m, IPPROTO_TCP, tlen, sizeof(struct ipv6))) {
d539 1
a539 1
			  ipv6 = mtod(m, struct ipv6 *);
d581 2
a582 2
	  inp = in6_pcbhashlookup(&tcbtable, &ipv6->ipv6_src, th->th_sport,
				 &ipv6->ipv6_dst, th->th_dport);
d591 2
a592 2
			inp = in_pcblookup(&tcbtable, &ipv6->ipv6_src,
			    th->th_sport, &ipv6->ipv6_dst, th->th_dport,
d687 4
a690 4
			    inp->inp_ipv6.ipv6_hoplimit = 
			      oldinpcb->inp_ipv6.ipv6_hoplimit;
			    inp->inp_ipv6.ipv6_versfl = 
			      oldinpcb->inp_ipv6.ipv6_versfl;
d699 1
a699 1
			  inp->inp_laddr6 = ipv6->ipv6_dst;
d701 1
a701 1
			    ipv6->ipv6_versfl;
d703 1
a703 1
			  /*inp->inp_options = ipv6_srcroute();*/ /* soon. */
d742 1
a742 1
			ipv6_icmp_error(m, ICMPV6_BLAH, ICMPV6_BLAH, 0);
d830 1
d884 1
d889 1
a889 2
			m->m_data += iphlen + off;
			m->m_len -= iphlen + off;
d901 1
a901 1
	 * Drop TCP, IP headers and TCP options.
d903 1
a903 2
	m->m_data += iphlen + off;
	m->m_len  -= iphlen + off;
d951 1
a951 1
		    if (IN6_ARE_ADDR_EQUAL(&ipv6->ipv6_src, &ipv6->ipv6_dst))
d972 1
a972 1
			if (IN6_IS_ADDR_MULTICAST(&ipv6->ipv6_dst))
d998 1
a998 1
		  sin6->sin6_addr = ipv6->ipv6_src;
d1001 1
a1001 1
		    inp->inp_ipv6.ipv6_versfl;
d1004 1
a1004 1
		    inp->inp_laddr6 = ipv6->ipv6_dst;
d1068 1
d1297 1
a1297 1
		m_adj(m, todrop);
d1382 1
d1384 3
d1753 1
d1906 1
a1906 1
		        tcp_pulloutofband(so, th->th_urp, m); /* XXX? */
d1937 2
d1942 1
d2068 1
a2068 1
	  if (IN6_IS_ADDR_MULTICAST(&ipv6->ipv6_dst))
d2610 1
a2610 1
tcp_pulloutofband(so, urgent, m)
d2614 1
d2616 1
a2616 1
        int cnt = urgent - 1;
d2761 1
a2761 1
	  bzero(ro,sizeof(struct route6));
@


1.50
log
@Add comment about gettdb() and spl level.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.49 1999/09/01 21:38:21 provos Exp $	*/
d2554 1
d2607 5
a2611 2
	TCPT_RANGESET(tp->t_rxtcur, TCP_REXMTVAL(tp),
	    rtt + 2, TCPTV_REXMTMAX);
d2711 3
a2713 1
			tp->t_rttmin = rtt / (RTM_RTTUNIT / PR_SLOWHZ);
@


1.49
log
@increase tcp_iss increment
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.48 1999/08/31 21:41:05 provos Exp $	*/
d348 2
@


1.48
log
@correctly update window information
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.47 1999/08/27 15:35:56 provos Exp $	*/
d1014 1
a1014 1
		tcp_iss += arc4random() % (TCP_ISSINCR / 2) + 1;
@


1.47
log
@more SACK hole validity testing; fix a tcp seq arithmetic bug. cmetz and me.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.46 1999/08/06 18:17:37 deraadt Exp $	*/
d1750 1
a1750 1
	if (((tiflags & TH_ACK) && SEQ_LT(tp->snd_wl1, th->th_seq)) ||
d1752 1
a1752 1
	    (tp->snd_wl2 == th->th_ack && tiwin > tp->snd_wnd)) {
@


1.46
log
@back out all recent changes, which continue to be a source for nasty bugs
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.43 1999/07/18 16:33:08 deraadt Exp $	*/
d2256 9
d2447 2
a2448 1
		tcp_seq lastack = max(th->th_ack, tp->snd_una);
@


1.45
log
@Moved the m_data/m_len shave of IP and TCP headers back to its original
location, as attempts to do it differently have caused too many problems.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.44 1999/07/22 17:14:18 niklas Exp $	*/
a50 6
/*
 * XXX - At this point, the TUBA support is likely to be hopelessly broken.
 * That's the bad news. The good news is that doing it again and doing it
 * right shouldn't be hard now that the IPv4 dependencies are isolated.
 */

d91 3
a99 6
#ifdef INET6
char tcp_savebuf[sizeof(struct ipv6) + sizeof(struct tcphdr)];
#else /* INET6 */
char tcp_savebuf[sizeof(struct ip) + sizeof(struct tcphdr)];
#endif /* INET6 */

d101 1
a307 1
	va_dcl
d310 1
d320 1
a328 1
	unsigned int pf;
d332 5
a336 9
	union {
		caddr_t p;
#ifdef INET
		struct ip *ip;
#endif /* INET */
#ifdef INET6
		struct ipv6 *ipv6;
#endif /* INET */
	} nhu;
d353 1
a353 1

d355 2
a356 5
	 * Before we do ANYTHING, we have to figure out what network protocol
	 * is underneath the TCP header in this packet.
	 *
	 * For IPv4 and IPv6, options don't really do anything at this layer
	 * and therefore are stripped off.
d358 1
a358 39
#if defined(INET) && defined(INET6)
	switch (mtod(m, struct ip *)->ip_v) {
#else /* defined(INET) && defined(INET6) */
	switch (-1) {
	case -1:
#endif /* defined(INET) && defined(INET6) */
#ifdef INET
	case 4:
		pf = PF_INET;

#ifdef DIAGNOSTIC
		if (iphlen < sizeof(struct ip)) {
			m_freem(m);
			return;
		}
#endif /* DIAGNOSTIC */

		if (iphlen > sizeof(struct ip)) {
			ip_stripoptions(m, (struct mbuf *)0);
			iphlen = sizeof(struct ip);
		}
		break;
#endif /* INET */
#ifdef INET6
	case 6:
		pf = PF_INET6;

#ifdef DIAGNOSTIC
		if (iphlen < sizeof(struct ipv6)) {
			m_freem(m);
			return;
		}
#endif /* DIAGNOSTIC */

		if (iphlen > sizeof(struct ipv6)) {
			ipv6_stripoptions(m, iphlen);
			iphlen = sizeof(struct ipv6);
		}
		break;
a359 4
	default:
		m_freem(m);
		return;
	}
d365 7
d377 3
d384 1
d386 2
a387 1
	 * Checksum extended TCP header and data.
a388 10
#if defined(INET) && defined(INET6)
	switch (pf) {
#else /* defined(INET) && defined(INET6) */
	switch (-1) {
	case -1:
#endif /* defined(INET) && defined(INET6) */
#ifdef INET
	case PF_INET:
		{
			struct ipovly *ipovly;
d390 7
a396 1
			ipovly = mtod(m, struct ipovly *);
d398 16
a413 4
			len = sizeof (struct ip) + tlen;
			bzero(ipovly->ih_x1, sizeof ipovly->ih_x1);
			ipovly->ih_len = (u_int16_t)tlen;
			HTONS(ipovly->ih_len);
d415 14
a428 7
			if (in_cksum(m, len)) {
				tcpstat.tcps_rcvbadsum++;
				goto drop;
			}
		}
		break;
#endif /* INET */
d430 1
a430 6
	case PF_INET6:
		if (in6_cksum(m, IPPROTO_TCP, tlen, sizeof(struct ipv6))) {
			tcpstat.tcps_rcvbadsum++;
			goto drop;
		} /* endif in6_cksum */
		break;
a431 2
	}

a433 1
	nhu.p = mtod(m, caddr_t);
d452 6
a493 12
#if defined(INET) && defined(INET6)
	switch (pf) {
#else /* defined(INET) && defined(INET6) */
	switch (-1) {
	case -1:
#endif /* defined(INET) && defined(INET6) */
#ifdef INET
	case PF_INET:
		inp = in_pcbhashlookup(&tcbtable, nhu.ip->ip_src,
			th->th_sport, nhu.ip->ip_dst, th->th_dport);
		break;
#endif /* INET */
d495 4
a498 4
	case PF_INET6:
		inp = in6_pcbhashlookup(&tcbtable, &nhu.ipv6->ipv6_src,
			th->th_sport, &nhu.ipv6->ipv6_dst, th->th_dport);
		break;
d500 2
a501 2
	}

a503 13
#if defined(INET) && defined(INET6)
		switch (pf) {
#else /* defined(INET) && defined(INET6) */
		switch (-1) {
		case -1:
#endif /* defined(INET) && defined(INET6) */
#ifdef INET
		case PF_INET:
			inp = in_pcblookup(&tcbtable, &nhu.ip->ip_src,
				th->th_sport, &nhu.ip->ip_dst, th->th_dport,
				INPLOOKUP_WILDCARD);
			break;
#endif /* INET */
d505 5
a509 6
		case PF_INET6:
			inp = in_pcblookup(&tcbtable, &nhu.ipv6->ipv6_src,
				th->th_sport, &nhu.ipv6->ipv6_dst,
				th->th_dport,
				INPLOOKUP_WILDCARD | INPLOOKUP_IPV6);
			break;
d511 2
a512 2
		}

d541 6
a546 2
			bcopy(mtod(m, caddr_t), tcp_savebuf,
				iphlen + sizeof(struct tcphdr));
d594 2
a595 2
				int flags = inp->inp_flags;
				struct inpcb *oldinpcb = inp;
d597 10
a606 13
				inp = (struct inpcb *)so->so_pcb;
				inp->inp_flags |=
					(flags & (INP_IPV6 | INP_IPV6_UNDEC
					| INP_IPV6_MAPPED));
				if ((inp->inp_flags & INP_IPV6) &&
						!(inp->inp_flags &
						INP_IPV6_MAPPED)) {
					inp->inp_ipv6.ipv6_hoplimit = 
						oldinpcb->inp_ipv6.
						ipv6_hoplimit;
					inp->inp_ipv6.ipv6_versfl = 
						oldinpcb->inp_ipv6.ipv6_versfl;
				}
a611 21
#if defined(INET) && defined(INET6)
			switch (pf) {
#else /* defined(INET) && defined(INET6) */
			switch (-1) {
			case -1:
#endif /* defined(INET) && defined(INET6) */
#ifdef INET
			case PF_INET:
#ifdef INET6
				if (inp->inp_flags & INP_IPV6) {
					/* v4 to v6 socket */
					CREATE_IPV6_MAPPED(inp->inp_laddr6,
						nhu.ip->ip_dst.s_addr);
				} else
#endif /* INET6 */
				{
					inp->inp_laddr = nhu.ip->ip_dst;
					inp->inp_options = ip_srcroute();
				}
				break;
#endif /* INET */
d613 16
a628 5
			case PF_INET6:
				inp->inp_laddr6 = nhu.ipv6->ipv6_dst;
				inp->inp_fflowinfo = htonl(0x0fffffff) & 
					nhu.ipv6->ipv6_versfl;
				break;
d630 4
d635 1
a635 1

d643 1
a643 2
			   TCP_MAXWIN << tp->request_r_scale <
			   so->so_rcv.sb_hiwat)
a654 11
#if defined(INET) && defined(INET6)
		switch (pf) {
#else /* defined(INET) && defined(INET6) */
		switch (-1) {
		case -1:
#endif /* defined(INET) && defined(INET6) */
#ifdef INET
		case PF_INET:
			icmp_error(m, ICMP_BLAH, ICMP_BLAH, 0, 0);
			break;
#endif /* INET */
d656 1
a656 1
		case PF_INET6:
d658 1
a658 1
			break;
d660 1
a660 1
		}
d687 3
a689 9
	if (tp->t_state != TCPS_LISTEN)
#ifdef TCP_SIGNATURE
		if (optp || (tp->t_flags & TF_SIGNATURE))
#else /* TCP_SIGNATURE */
		if (optp)
#endif /* TCP_SIGNATURE */
			if (tcp_dooptions(tp, optp, optlen, th, m, iphlen,
					&ts_present, &ts_val, &ts_ecr))
				goto drop;
d852 4
a863 13
#if defined(INET) && defined(INET6)
			switch (pf) {
#else /* defined(INET) && defined(INET6) */
			switch (-1) {
			case -1:
#endif /* defined(INET) && defined(INET6) */
#ifdef INET
			case PF_INET:
				if (nhu.ip->ip_src.s_addr ==
						nhu.ip->ip_dst.s_addr)
					goto drop;
				break;
#endif /* INET */
d865 9
a873 5
			case PF_INET6:
				if (IN6_ARE_ADDR_EQUAL(&nhu.ipv6->ipv6_src,
						&nhu.ipv6->ipv6_dst))
					goto drop;
				break;
a874 1
			}
a883 14
#if defined(INET) && defined(INET6)
		switch (pf) {
#else /* defined(INET) && defined(INET6) */
		switch (-1) {
		case -1:
#endif /* defined(INET) && defined(INET6) */
#ifdef INET
		case PF_INET:
			if (nhu.ip->ip_dst.s_addr == INADDR_BROADCAST)
				goto drop;
			if (IN_MULTICAST(nhu.ip->ip_dst.s_addr))
				goto drop;
			break;
#endif /* INET */
d885 3
a887 2
		case PF_INET6:
			if (IN6_IS_ADDR_MULTICAST(&nhu.ipv6->ipv6_dst))
d889 1
a889 1
			break;
d891 2
a892 2
		}

a895 9

#if defined(INET) && defined(INET6)
		switch (pf) {
#else /* defined(INET) && defined(INET6) */
		switch (-1) {
		case -1:
#endif /* defined(INET) && defined(INET6) */
#ifdef INET
		case PF_INET:
d897 69
a965 43
			/*
			 * Letting v4 incoming datagrams to reach valid 
			 * PF_INET6 sockets causes some overhead here.
			 */
			if (inp->inp_flags & INP_IPV6) {
				struct sockaddr_in6 *sin6;
				struct in6_addr laddr6;

				if (!(inp->inp_flags & (INP_IPV6_UNDEC |
						INP_IPV6_MAPPED))) {
					m_freem(am);
					goto drop;
				}

				am->m_len = sizeof(struct sockaddr_in6);
				sin6 = mtod(am, struct sockaddr_in6 *);
				sin6->sin6_family = AF_INET6;
				sin6->sin6_len = sizeof(struct sockaddr_in6);
				CREATE_IPV6_MAPPED(sin6->sin6_addr,
					nhu.ip->ip_src.s_addr);
				sin6->sin6_port = th->th_sport;
				sin6->sin6_flowinfo = 0;

				laddr6 = inp->inp_laddr6;
				if (inp->inp_laddr.s_addr == INADDR_ANY)
					break;
				CREATE_IPV6_MAPPED(inp->inp_laddr6,
					nhu.ip->ip_dst.s_addr);

				/*
				 * The pcb initially has the v6 default hop
				 * limit set. We're sending v4 packets, so we
				 * need to set the v4 ttl and tos.
				 */
				inp->inp_ip.ip_ttl = ip_defttl;
				inp->inp_ip.ip_tos = 0;

				if (in6_pcbconnect(inp, am)) {
					inp->inp_laddr6 = laddr6;
					m_freem(am);
					goto drop;
				}
			} else /* (inp->inp_flags & INP_IPV6) */
d967 16
a982 24
			{
				struct sockaddr_in *sin;
				struct in_addr laddr;

				am->m_len = sizeof(struct sockaddr_in);
				sin = mtod(am, struct sockaddr_in *);
				sin->sin_family = AF_INET;
				sin->sin_len = sizeof(struct sockaddr_in);
				sin->sin_addr = nhu.ip->ip_src;
				sin->sin_port = th->th_sport;
				bzero((caddr_t)sin->sin_zero,
					sizeof(sin->sin_zero));
				laddr = inp->inp_laddr;
				if (inp->inp_laddr.s_addr == INADDR_ANY)
					inp->inp_laddr = nhu.ip->ip_dst;
				if (in_pcbconnect(inp, am)) {
					inp->inp_laddr = laddr;
					m_free(am);
					goto drop;
				}
			} /* (inp->inp_flags & INP_IPV6) */
			tp->pf = PF_INET;
			break;
#endif /* INET */
d984 2
a985 37
		case PF_INET6:
			{
				struct sockaddr_in6 *sin6;
				struct in6_addr laddr6;

				/*
			 	 * This is probably the place to set the tp->pf
				 * value. (Don't forget to do it in the v4 code
				 * as well!)
				 *
				 * Also, remember to blank out things like
				 * flowlabel, or set flowlabel for accepted
				 * sockets in v6.
				 */

				am->m_len = sizeof(struct sockaddr_in6);
				sin6 = mtod(am, struct sockaddr_in6 *);
				sin6->sin6_family = AF_INET6;
				sin6->sin6_len = sizeof(struct sockaddr_in6);
				sin6->sin6_addr = nhu.ipv6->ipv6_src;
				sin6->sin6_port = th->th_sport;
				sin6->sin6_flowinfo = htonl(0x0fffffff) &
					inp->inp_ipv6.ipv6_versfl;
				laddr6 = inp->inp_laddr6;

				if (IN6_IS_ADDR_UNSPECIFIED(&inp->inp_laddr6))
					inp->inp_laddr6 = nhu.ipv6->ipv6_dst;
				/* This is a good optimization. */
				if (in6_pcbconnect(inp, am)) {
					inp->inp_laddr6 = laddr6;
					m_free(am);
					goto drop;
				}
			}

			tp->pf = PF_INET6;
			break;
a986 3
		}

		m_free(am);
d993 3
a995 11

#ifdef TCP_SIGNATURE
		if (optp || (tp->t_flags & TF_SIGNATURE)) {
#else /* TCP_SIGNATURE */
		if (optp) {
#endif /* TCP_SIGNATURE */
			if (tcp_dooptions(tp, optp, optlen, th, m, iphlen,
					&ts_present, &ts_val, &ts_ecr))
				goto drop;
		}

d1296 1
a1296 1
		if (th->th_seq != tp->last_ack_sent)
d1825 1
d1922 8
a1929 3

	if (so->so_options & SO_DEBUG)
		tcp_trace(TA_INPUT, ostate, tp, tcp_savebuf, 0, tlen);
a1969 14
#if defined(INET) && defined(INET6)
	switch (pf) {
#else /* defined(INET) && defined(INET6) */
	switch (-1) {
	case -1:
#endif /* defined(INET) && defined(INET6) */
#ifdef INET
	case PF_INET:
		if (mtod(m, struct ip *)->ip_dst.s_addr == INADDR_BROADCAST)
			goto drop;
		if (IN_MULTICAST(mtod(m, struct ip *)->ip_dst.s_addr))
			goto drop;
		break;
#endif /* INET */
d1971 6
a1976 4
	case PF_INET6:
		if (IN6_IS_ADDR_MULTICAST(&mtod(m, struct ipv6 *)->ipv6_dst))
			goto drop;
		break;
d1978 3
d1982 1
a1982 1

d1984 1
a1984 2
		tcp_respond(tp, mtod(m, caddr_t), m, (tcp_seq)0, th->th_ack,
			TH_RST);
d1988 2
a1989 2
		tcp_respond(tp, mtod(m, caddr_t), m, th->th_seq+tlen,
			(tcp_seq)0, TH_RST|TH_ACK);
d2000 8
a2007 2
	if (tp && (tp->t_inpcb->inp_socket->so_options & SO_DEBUG))
		tcp_trace(TA_DROP, ostate, tp, tcp_savebuf, 0, tlen);
d2017 2
a2018 2
int
tcp_dooptions(tp, cp, cnt, th, m, iphlen, ts_present, ts_val, ts_ecr)
a2022 2
	struct mbuf *m;
	int iphlen;
a2027 3
#ifdef TCP_SIGNATURE
	caddr_t sigp = NULL;
#endif /* TCP_SIGNATURE */
a2095 11
#ifdef TCP_SIGNATURE
		case TCPOPT_SIGNATURE:
			if (optlen != TCPOLEN_SIGNATURE)
				continue;

			if (sigp && bcmp(sigp, cp + 2, 16))
				return -1;

			sigp = cp + 2;
			break;
#endif /* TCP_SIGNATURE */
a2097 113

#ifdef TCP_SIGNATURE
	if ((sigp ? TF_SIGNATURE : 0) ^ (tp->t_flags & TF_SIGNATURE)) {
		tcpstat.tcps_rcvbadsig++;
		return -1;
	}

	if (sigp) {
		MD5_CTX ctx;
		union sockaddr_union sa;
		struct tdb *tdb;
		char sig[16];

		memset(&sa, 0, sizeof(union sockaddr_union));

		switch (tp->pf) {
			case 0:
			case AF_INET:
				sa.sa.sa_len = sizeof(struct sockaddr_in);
				sa.sa.sa_family = AF_INET;
				sa.sin.sin_addr = tp->t_inpcb->inp_laddr;
				break;
#ifdef INET6
			case AF_INET6:
				sa.sa.sa_len = sizeof(struct sockaddr_in6);
				sa.sa.sa_family = AF_INET6;
				sa.sin6.sin6_addr = tp->t_inpcb->inp_laddr6;
				break;
#endif /* INET6 */
		}

		tdb = gettdb(0, &sa, IPPROTO_TCP);
		if (tdb == NULL) {
			printf("tdb miss\n");
			tcpstat.tcps_rcvbadsig++;
			return -1;
		}

		MD5Init(&ctx);

		switch(tp->pf) {
			case 0:
#ifdef INET
			case AF_INET:
				{
					struct ippseudo ippseudo;

					ippseudo.ippseudo_src =
						tp->t_inpcb->inp_faddr;
					ippseudo.ippseudo_dst =
						tp->t_inpcb->inp_laddr;
					ippseudo.ippseudo_pad = 0;
					ippseudo.ippseudo_p = IPPROTO_TCP;
					ippseudo.ippseudo_len = htons(
						m->m_pkthdr.len - iphlen);

					MD5Update(&ctx, (char *)&ippseudo,
						sizeof(struct ippseudo));
				}
				break;
#endif /* INET */
#ifdef INET6
			case AF_INET6:
				{
					static int printed = 0;

					if (!printed) {
						printf("error: TCP MD5 support"
							" for IPv6 not yet"
							" implemented.\n");
						printed = 1;
					}
				}
				break
#endif /* INET6 */
		}

		{
			struct tcphdr tcphdr;

			tcphdr.th_sport = th->th_sport;
			tcphdr.th_dport = th->th_dport;
			tcphdr.th_seq = htonl(th->th_seq);
			tcphdr.th_ack = htonl(th->th_ack);
			tcphdr.th_off = th->th_off;
			tcphdr.th_x2 = th->th_x2;
			tcphdr.th_flags = th->th_flags;
			tcphdr.th_win = htons(th->th_win);
			tcphdr.th_sum = 0;
			tcphdr.th_urp = htons(th->th_urp);

			MD5Update(&ctx, (char *)&tcphdr,
				sizeof(struct tcphdr));
		}

		if (m_apply(m, iphlen + th->th_off * sizeof(uint32_t),
				m->m_pkthdr.len - (iphlen + th->th_off *
				sizeof(uint32_t)), tcp_signature_apply,
				(caddr_t)&ctx))
			return (-1); 

		MD5Update(&ctx, tdb->tdb_amxkey, tdb->tdb_amxkeylen);
		MD5Final(sig, &ctx);

		if (bcmp(sig, sigp, 16)) {
			tcpstat.tcps_rcvbadsig++;
			return (-1);
		}

		tcpstat.tcps_rcvgoodsig++;
	}
#endif /* TCP_SIGNATURE */

a2100 2

	return (0);
@


1.44
log
@Reintroduce rev 1.41 which brings us TCP signatures again, but this time
hopefully without random kernel data corruption.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.43 1999/07/18 16:33:08 deraadt Exp $	*/
d896 6
a1961 7

	/*
	 * Drop TCP, IP headers and TCP options.
	 */
	m->m_data += iphlen + off;
	m->m_len  -= iphlen + off;

@


1.43
log
@use proper C
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.42 1999/07/17 23:41:46 provos Exp $	*/
d51 6
a96 3
struct	tcpiphdr tcp_saveti;
struct  tcpipv6hdr tcp_saveti6;

d103 6
a109 1
struct	tcpiphdr tcp_saveti;
d316 1
a318 1
	register struct tcpiphdr *ti;
a327 1
	struct in_addr laddr;
d336 1
d340 9
a348 5
#ifdef INET6
	struct in6_addr laddr6;
	unsigned short is_ipv6;     /* Type of incoming datagram. */
	struct ipv6 *ipv6 = NULL;
#endif /* INET6 */
d365 1
a365 1
#ifdef INET6
d367 5
a371 2
	 * Before we do ANYTHING, we have to figure out if it's TCP/IPv6 or
	 * TCP/IPv4.
d373 39
a411 1
	is_ipv6 = mtod(m, struct ip *)->ip_v == 6;
d413 4
a421 7
#ifndef INET6
	ti = mtod(m, struct tcpiphdr *);
#else /* INET6 */
	if (!is_ipv6)
#endif /* INET6 */
	if (iphlen > sizeof (struct ip))
		ip_stripoptions(m, (struct mbuf *)0);
a426 3
#ifndef INET6
		ti = mtod(m, struct tcpiphdr *);
#endif /* INET6 */
a430 1
#ifdef INET6
d432 1
a432 2
	 * After that, do initial segment processing which is still very
	 * dependent on what IP version you're using.
d434 10
d445 1
a445 7
	if (is_ipv6) {
#ifdef DIAGNOSTIC
	  if (iphlen < sizeof(struct ipv6)) {
	    m_freem(m);
	    return;
	  }
#endif /* DIAGNOSTIC */
d447 4
a450 16
	  /* strip off any options */
	  if (iphlen > sizeof(struct ipv6)) {
	    ipv6_stripoptions(m, iphlen);
	    iphlen = sizeof(struct ipv6);
	  }

	  ti = NULL;
	  ipv6 = mtod(m, struct ipv6 *);

	  if (in6_cksum(m, IPPROTO_TCP, tlen, sizeof(struct ipv6))) {
	    tcpstat.tcps_rcvbadsum++;
	    goto drop;
	  } /* endif in6_cksum */
	} else {
	  ti = mtod(m, struct tcpiphdr *);
#endif /* INET6 */
d452 14
a465 5
	/*
	 * Checksum extended TCP header and data.
	 */
#ifndef INET6
	tlen = ((struct ip *)ti)->ip_len;
a466 7
	len = sizeof (struct ip) + tlen;
	bzero(ti->ti_x1, sizeof ti->ti_x1);
	ti->ti_len = (u_int16_t)tlen;
	HTONS(ti->ti_len);
	if ((ti->ti_sum = in_cksum(m, len)) != 0) {
		tcpstat.tcps_rcvbadsum++;
		goto drop;
d468 1
a468 3
#ifdef INET6
	}
#endif /* INET6 */
d471 1
a489 6
#ifdef INET6
			if (is_ipv6)
			  ipv6 = mtod(m, struct ipv6 *);
			else
#endif /* INET6 */
			ti = mtod(m, struct tcpiphdr *);
d526 12
d539 4
a542 4
	if (is_ipv6) {
	  inp = in6_pcbhashlookup(&tcbtable, &ipv6->ipv6_src, th->th_sport,
				 &ipv6->ipv6_dst, th->th_dport);
	} else
d544 2
a545 2
	inp = in_pcbhashlookup(&tcbtable, ti->ti_src, ti->ti_sport,
	    ti->ti_dst, ti->ti_dport);
d548 13
d562 6
a567 5
		if (is_ipv6)
			inp = in_pcblookup(&tcbtable, &ipv6->ipv6_src,
			    th->th_sport, &ipv6->ipv6_dst, th->th_dport,
			    INPLOOKUP_WILDCARD | INPLOOKUP_IPV6);
		else
d569 2
a570 2
		inp = in_pcblookup(&tcbtable, &ti->ti_src, ti->ti_sport,
		    &ti->ti_dst, ti->ti_dport, INPLOOKUP_WILDCARD);
d599 2
a600 6
#ifdef INET6
			if (is_ipv6)
			  tcp_saveti6 = *(mtod(m, struct tcpipv6hdr *));
			else
#endif /* INET6 */
			tcp_saveti = *ti;
d648 2
a649 2
			  int flags = inp->inp_flags;
			  struct inpcb *oldinpcb = inp;
d651 13
a663 10
			  inp = (struct inpcb *)so->so_pcb;
			  inp->inp_flags |= (flags & (INP_IPV6 | INP_IPV6_UNDEC
						      | INP_IPV6_MAPPED));
			  if ((inp->inp_flags & INP_IPV6) &&
			      !(inp->inp_flags & INP_IPV6_MAPPED)) {
			    inp->inp_ipv6.ipv6_hoplimit = 
			      oldinpcb->inp_ipv6.ipv6_hoplimit;
			    inp->inp_ipv6.ipv6_versfl = 
			      oldinpcb->inp_ipv6.ipv6_versfl;
			  }
d669 21
d691 5
a695 16
			if (is_ipv6) {
			  inp->inp_laddr6 = ipv6->ipv6_dst;
			  inp->inp_fflowinfo = htonl(0x0fffffff) & 
			    ipv6->ipv6_versfl;
			  
			  /*inp->inp_options = ipv6_srcroute();*/ /* soon. */
			  /* still need to tweak outbound options
			     processing to include this mbuf in
			     the right place and put the correct
			     NextHdr values in the right places.
			     XXX  rja */
			} else {
			  if (inp->inp_flags & INP_IPV6) {/* v4 to v6 socket */
			    CREATE_IPV6_MAPPED(inp->inp_laddr6,
			      ti->ti_dst.s_addr);
			  } else {
a696 4
			    inp->inp_laddr = ti->ti_dst;
			    inp->inp_options = ip_srcroute();
#if INET6
			  }
d698 1
a698 1
#endif /* INET6 */
d706 2
a707 1
			   TCP_MAXWIN << tp->request_r_scale < so->so_rcv.sb_hiwat)
d719 11
d731 1
a731 1
		if (is_ipv6)
d733 1
a733 1
		else
d735 1
a735 1
		icmp_error(m, ICMP_BLAH, ICMP_BLAH, 0, 0);
d762 9
a770 3
	if (optp && tp->t_state != TCPS_LISTEN)
		tcp_dooptions(tp, optp, optlen, th,
			&ts_present, &ts_val, &ts_ecr);
a895 6
	 * Drop TCP, IP headers and TCP options.
	 */
	m->m_data += iphlen + off;
	m->m_len  -= iphlen + off;

	/*
a926 4
		register struct sockaddr_in *sin;
#ifdef INET6
		register struct sockaddr_in6 *sin6;
#endif /* INET6 */
d935 13
d949 5
a953 9
		  if (is_ipv6) {
		    if (IN6_ARE_ADDR_EQUAL(&ipv6->ipv6_src, &ipv6->ipv6_dst))
		      goto drop;
		  } else {
#endif /* INET6 */
		    if (ti->ti_dst.s_addr == ti->ti_src.s_addr)
		      goto drop;
#ifdef INET6
		  }
d955 1
d965 14
d980 2
a981 3
		if (is_ipv6) {
			/* XXX What about IPv6 Anycasting ?? :-(  rja */
			if (IN6_IS_ADDR_MULTICAST(&ipv6->ipv6_dst))
d983 1
a983 1
		} else
d985 2
a986 2
		if (IN_MULTICAST(ti->ti_dst.s_addr))
			goto drop;
d990 9
d1000 43
a1042 69
		if (is_ipv6) {
		  /*
		   * This is probably the place to set the tp->pf value.
		   * (Don't forget to do it in the v4 code as well!)
		   *
		   * Also, remember to blank out things like flowlabel, or
		   * set flowlabel for accepted sockets in v6.
		   *
		   * FURTHERMORE, this is PROBABLY the place where the whole
		   * business of key munging is set up for passive
		   * connections.
		   */
		  am->m_len = sizeof(struct sockaddr_in6);
		  sin6 = mtod(am, struct sockaddr_in6 *);
		  sin6->sin6_family = AF_INET6;
		  sin6->sin6_len = sizeof(struct sockaddr_in6);
		  sin6->sin6_addr = ipv6->ipv6_src;
		  sin6->sin6_port = th->th_sport;
		  sin6->sin6_flowinfo = htonl(0x0fffffff) &
		    inp->inp_ipv6.ipv6_versfl;
		  laddr6 = inp->inp_laddr6;
		  if (IN6_IS_ADDR_UNSPECIFIED(&inp->inp_laddr6))
		    inp->inp_laddr6 = ipv6->ipv6_dst;
		  /* This is a good optimization. */
		  if (in6_pcbconnect(inp, am)) {
		    inp->inp_laddr6 = laddr6;
		    (void) m_free(am);
		    goto drop;
		  } /* endif in6_pcbconnect() */
		  tp->pf = PF_INET6;
		} else {
		  /*
		   * Letting v4 incoming datagrams to reach valid 
		   * PF_INET6 sockets causes some overhead here.
		   */
		  if (inp->inp_flags & INP_IPV6) {
		    if (!(inp->inp_flags & (INP_IPV6_UNDEC|INP_IPV6_MAPPED))) {
		      (void) m_free(am);
		      goto drop;
		    }

		    am->m_len = sizeof(struct sockaddr_in6);
		    
		    sin6 = mtod(am, struct sockaddr_in6 *);
		    sin6->sin6_family = AF_INET6;
		    sin6->sin6_len = sizeof(*sin6);
		    CREATE_IPV6_MAPPED(sin6->sin6_addr, ti->ti_src.s_addr);
		    sin6->sin6_port = th->th_sport;
		    sin6->sin6_flowinfo = 0;

		    laddr6 = inp->inp_laddr6;
		    if (inp->inp_laddr.s_addr == INADDR_ANY)
		      CREATE_IPV6_MAPPED(inp->inp_laddr6, ti->ti_dst.s_addr);
		    
		    /*
		     * The pcb initially has the v6 default hoplimit
		     * set. We're sending v4 packets so we need to set
		     * the v4 ttl and tos.
		     */
		    inp->inp_ip.ip_ttl = ip_defttl;
		    inp->inp_ip.ip_tos = 0;
		    
		    if (in6_pcbconnect(inp, am)) {
		      inp->inp_laddr6 = laddr6;
		      (void) m_freem(am);
		      goto drop;
		    }
		    tp->pf = PF_INET;
		  } else { 
d1044 24
a1067 16
		am->m_len = sizeof (struct sockaddr_in);
		sin = mtod(am, struct sockaddr_in *);
		sin->sin_family = AF_INET;
		sin->sin_len = sizeof(*sin);
		sin->sin_addr = ti->ti_src;
		sin->sin_port = ti->ti_sport;
		bzero((caddr_t)sin->sin_zero, sizeof(sin->sin_zero));
		laddr = inp->inp_laddr;
		if (inp->inp_laddr.s_addr == INADDR_ANY)
			inp->inp_laddr = ti->ti_dst;
		if (in_pcbconnect(inp, am)) {
			inp->inp_laddr = laddr;
			(void) m_free(am);
			goto drop;
		}
		(void) m_free(am);
d1069 37
a1105 2
		  }  /* if (inp->inp_flags & INP_IPV6) */
		} /* if (is_ipv6) */
d1107 3
d1116 11
a1126 3
		if (optp)
			tcp_dooptions(tp, optp, optlen, th,
				&ts_present, &ts_val, &ts_ecr);
d1427 1
a1427 1
		if (ti->ti_seq != tp->last_ack_sent)
d1958 6
d2059 3
a2061 8
	if (so->so_options & SO_DEBUG) {
#ifdef INET6
		if (tp->pf == PF_INET6)
			tcp_trace(TA_INPUT, ostate, tp, (caddr_t) &tcp_saveti6, 0, tlen);
		else
#endif /* INET6 */
			tcp_trace(TA_INPUT, ostate, tp, (caddr_t) &tcp_saveti, 0, tlen);
	}
d2102 14
d2117 4
a2120 6
	if (is_ipv6) {
	  /* For following calls to tcp_respond */
	  ti = mtod(m, struct tcpiphdr *);
	  if (IN6_IS_ADDR_MULTICAST(&ipv6->ipv6_dst))
	    goto drop;
	} else {
a2121 3
	    if (IN_MULTICAST(ti->ti_dst.s_addr))
	      goto drop;
#ifdef INET6
d2123 1
a2123 1
#endif /* INET6 */
d2125 2
a2126 1
		tcp_respond(tp, (caddr_t) ti, m, (tcp_seq)0, th->th_ack, TH_RST);
d2130 2
a2131 2
		tcp_respond(tp, (caddr_t) ti, m, th->th_seq+tlen, (tcp_seq)0,
		    TH_RST|TH_ACK);
d2142 2
a2143 8
	if (tp && (tp->t_inpcb->inp_socket->so_options & SO_DEBUG)) {
#ifdef INET6
	  if (tp->pf == PF_INET6)
	    tcp_trace(TA_DROP, ostate, tp, (caddr_t) &tcp_saveti6, 0, tlen);
	  else
#endif /* INET6 */
	    tcp_trace(TA_DROP, ostate, tp, (caddr_t) &tcp_saveti, 0, tlen);
	}
d2153 2
a2154 2
void
tcp_dooptions(tp, cp, cnt, th, ts_present, ts_val, ts_ecr)
d2159 2
d2166 3
d2237 88
d2326 34
d2361 2
d2366 2
@


1.42
log
@revert tcp_input.c to before 07/01/1999 - this seems to solve the mysterious
data corruptions and panics that people have experienced.  by reverting
we loose tcp signatures and ipv6 cleanups, the code looked correct to me.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.36 1999/06/11 19:46:39 pattonme Exp $	*/
d634 1
a634 1
			};
@


1.41
log
@correct non-STDC case
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.40 1999/07/06 20:17:52 cmetz Exp $	*/
a50 6
/*
 * XXX - At this point, the TUBA support is likely to be hopelessly broken.
 * That's the bad news. The good news is that doing it again and doing it
 * right shouldn't be hard now that the IPv4 dependencies are isolated.
 */

d91 3
a99 6
#ifdef INET6
char tcp_savebuf[sizeof(struct ipv6) + sizeof(struct tcphdr)];
#else /* INET6 */
char tcp_savebuf[sizeof(struct ip) + sizeof(struct tcphdr)];
#endif /* INET6 */

d101 1
a307 1
	va_dcl
d310 1
d320 1
a328 1
	unsigned int pf;
d332 5
a336 9
	union {
		caddr_t p;
#ifdef INET
		struct ip *ip;
#endif /* INET */
#ifdef INET6
		struct ipv6 *ipv6;
#endif /* INET */
	} nhu;
d353 1
a353 1

d355 2
a356 5
	 * Before we do ANYTHING, we have to figure out what network protocol
	 * is underneath the TCP header in this packet.
	 *
	 * For IPv4 and IPv6, options don't really do anything at this layer
	 * and therefore are stripped off.
d358 1
a358 39
#if defined(INET) && defined(INET6)
	switch (mtod(m, struct ip *)->ip_v) {
#else /* defined(INET) && defined(INET6) */
	switch (-1) {
	case -1:
#endif /* defined(INET) && defined(INET6) */
#ifdef INET
	case 4:
		pf = PF_INET;

#ifdef DIAGNOSTIC
		if (iphlen < sizeof(struct ip)) {
			m_freem(m);
			return;
		}
#endif /* DIAGNOSTIC */

		if (iphlen > sizeof(struct ip)) {
			ip_stripoptions(m, (struct mbuf *)0);
			iphlen = sizeof(struct ip);
		}
		break;
#endif /* INET */
#ifdef INET6
	case 6:
		pf = PF_INET6;

#ifdef DIAGNOSTIC
		if (iphlen < sizeof(struct ipv6)) {
			m_freem(m);
			return;
		}
#endif /* DIAGNOSTIC */

		if (iphlen > sizeof(struct ipv6)) {
			ipv6_stripoptions(m, iphlen);
			iphlen = sizeof(struct ipv6);
		}
		break;
a359 4
	default:
		m_freem(m);
		return;
	}
d365 7
d377 3
d384 1
d386 2
a387 1
	 * Checksum extended TCP header and data.
a388 10
#if defined(INET) && defined(INET6)
	switch (pf) {
#else /* defined(INET) && defined(INET6) */
	switch (-1) {
	case -1:
#endif /* defined(INET) && defined(INET6) */
#ifdef INET
	case PF_INET:
		{
			struct ipovly *ipovly;
d390 7
a396 1
			ipovly = mtod(m, struct ipovly *);
d398 16
a413 4
			len = sizeof (struct ip) + tlen;
			bzero(ipovly->ih_x1, sizeof ipovly->ih_x1);
			ipovly->ih_len = (u_int16_t)tlen;
			HTONS(ipovly->ih_len);
d415 14
a428 7
			if (in_cksum(m, len)) {
				tcpstat.tcps_rcvbadsum++;
				goto drop;
			}
		}
		break;
#endif /* INET */
d430 1
a430 6
	case PF_INET6:
		if (in6_cksum(m, IPPROTO_TCP, tlen, sizeof(struct ipv6))) {
			tcpstat.tcps_rcvbadsum++;
			goto drop;
		} /* endif in6_cksum */
		break;
a431 2
	}

a433 1
	nhu.p = mtod(m, caddr_t);
d452 6
a493 12
#if defined(INET) && defined(INET6)
	switch (pf) {
#else /* defined(INET) && defined(INET6) */
	switch (-1) {
	case -1:
#endif /* defined(INET) && defined(INET6) */
#ifdef INET
	case PF_INET:
		inp = in_pcbhashlookup(&tcbtable, nhu.ip->ip_src,
			th->th_sport, nhu.ip->ip_dst, th->th_dport);
		break;
#endif /* INET */
d495 4
a498 4
	case PF_INET6:
		inp = in6_pcbhashlookup(&tcbtable, &nhu.ipv6->ipv6_src,
			th->th_sport, &nhu.ipv6->ipv6_dst, th->th_dport);
		break;
d500 2
a501 2
	}

a503 13
#if defined(INET) && defined(INET6)
		switch (pf) {
#else /* defined(INET) && defined(INET6) */
		switch (-1) {
		case -1:
#endif /* defined(INET) && defined(INET6) */
#ifdef INET
		case PF_INET:
			inp = in_pcblookup(&tcbtable, &nhu.ip->ip_src,
				th->th_sport, &nhu.ip->ip_dst, th->th_dport,
				INPLOOKUP_WILDCARD);
			break;
#endif /* INET */
d505 5
a509 6
		case PF_INET6:
			inp = in_pcblookup(&tcbtable, &nhu.ipv6->ipv6_src,
				th->th_sport, &nhu.ipv6->ipv6_dst,
				th->th_dport,
				INPLOOKUP_WILDCARD | INPLOOKUP_IPV6);
			break;
d511 2
a512 2
		}

d541 6
a546 2
			bcopy(mtod(m, caddr_t), tcp_savebuf,
				iphlen + sizeof(struct tcphdr));
d594 2
a595 2
				int flags = inp->inp_flags;
				struct inpcb *oldinpcb = inp;
d597 10
a606 13
				inp = (struct inpcb *)so->so_pcb;
				inp->inp_flags |=
					(flags & (INP_IPV6 | INP_IPV6_UNDEC
					| INP_IPV6_MAPPED));
				if ((inp->inp_flags & INP_IPV6) &&
						!(inp->inp_flags &
						INP_IPV6_MAPPED)) {
					inp->inp_ipv6.ipv6_hoplimit = 
						oldinpcb->inp_ipv6.
						ipv6_hoplimit;
					inp->inp_ipv6.ipv6_versfl = 
						oldinpcb->inp_ipv6.ipv6_versfl;
				}
a611 21
#if defined(INET) && defined(INET6)
			switch (pf) {
#else /* defined(INET) && defined(INET6) */
			switch (-1) {
			case -1:
#endif /* defined(INET) && defined(INET6) */
#ifdef INET
			case PF_INET:
#ifdef INET6
				if (inp->inp_flags & INP_IPV6) {
					/* v4 to v6 socket */
					CREATE_IPV6_MAPPED(inp->inp_laddr6,
						nhu.ip->ip_dst.s_addr);
				} else
#endif /* INET6 */
				{
					inp->inp_laddr = nhu.ip->ip_dst;
					inp->inp_options = ip_srcroute();
				}
				break;
#endif /* INET */
d613 22
a634 5
			case PF_INET6:
				inp->inp_laddr6 = nhu.ipv6->ipv6_dst;
				inp->inp_fflowinfo = htonl(0x0fffffff) & 
					nhu.ipv6->ipv6_versfl;
				break;
a635 2
			}

d643 1
a643 2
			   TCP_MAXWIN << tp->request_r_scale <
			   so->so_rcv.sb_hiwat)
a654 11
#if defined(INET) && defined(INET6)
		switch (pf) {
#else /* defined(INET) && defined(INET6) */
		switch (-1) {
		case -1:
#endif /* defined(INET) && defined(INET6) */
#ifdef INET
		case PF_INET:
			icmp_error(m, ICMP_BLAH, ICMP_BLAH, 0, 0);
			break;
#endif /* INET */
d656 1
a656 1
		case PF_INET6:
d658 1
a658 1
			break;
d660 1
a660 1
		}
d687 3
a689 9
	if (tp->t_state != TCPS_LISTEN)
#ifdef TCP_SIGNATURE
		if (optp || (tp->t_flags & TF_SIGNATURE))
#else /* TCP_SIGNATURE */
		if (optp)
#endif /* TCP_SIGNATURE */
			if (tcp_dooptions(tp, optp, optlen, th, m, iphlen,
					&ts_present, &ts_val, &ts_ecr))
				goto drop;
d852 4
a863 13
#if defined(INET) && defined(INET6)
			switch (pf) {
#else /* defined(INET) && defined(INET6) */
			switch (-1) {
			case -1:
#endif /* defined(INET) && defined(INET6) */
#ifdef INET
			case PF_INET:
				if (nhu.ip->ip_src.s_addr ==
						nhu.ip->ip_dst.s_addr)
					goto drop;
				break;
#endif /* INET */
d865 9
a873 5
			case PF_INET6:
				if (IN6_ARE_ADDR_EQUAL(&nhu.ipv6->ipv6_src,
						&nhu.ipv6->ipv6_dst))
					goto drop;
				break;
a874 1
			}
a883 14
#if defined(INET) && defined(INET6)
		switch (pf) {
#else /* defined(INET) && defined(INET6) */
		switch (-1) {
		case -1:
#endif /* defined(INET) && defined(INET6) */
#ifdef INET
		case PF_INET:
			if (nhu.ip->ip_dst.s_addr == INADDR_BROADCAST)
				goto drop;
			if (IN_MULTICAST(nhu.ip->ip_dst.s_addr))
				goto drop;
			break;
#endif /* INET */
d885 3
a887 2
		case PF_INET6:
			if (IN6_IS_ADDR_MULTICAST(&nhu.ipv6->ipv6_dst))
d889 1
a889 1
			break;
d891 2
a892 2
		}

a895 9

#if defined(INET) && defined(INET6)
		switch (pf) {
#else /* defined(INET) && defined(INET6) */
		switch (-1) {
		case -1:
#endif /* defined(INET) && defined(INET6) */
#ifdef INET
		case PF_INET:
d897 69
a965 43
			/*
			 * Letting v4 incoming datagrams to reach valid 
			 * PF_INET6 sockets causes some overhead here.
			 */
			if (inp->inp_flags & INP_IPV6) {
				struct sockaddr_in6 *sin6;
				struct in6_addr laddr6;

				if (!(inp->inp_flags & (INP_IPV6_UNDEC |
						INP_IPV6_MAPPED))) {
					m_freem(am);
					goto drop;
				}

				am->m_len = sizeof(struct sockaddr_in6);
				sin6 = mtod(am, struct sockaddr_in6 *);
				sin6->sin6_family = AF_INET6;
				sin6->sin6_len = sizeof(struct sockaddr_in6);
				CREATE_IPV6_MAPPED(sin6->sin6_addr,
					nhu.ip->ip_src.s_addr);
				sin6->sin6_port = th->th_sport;
				sin6->sin6_flowinfo = 0;

				laddr6 = inp->inp_laddr6;
				if (inp->inp_laddr.s_addr == INADDR_ANY)
					break;
				CREATE_IPV6_MAPPED(inp->inp_laddr6,
					nhu.ip->ip_dst.s_addr);

				/*
				 * The pcb initially has the v6 default hop
				 * limit set. We're sending v4 packets, so we
				 * need to set the v4 ttl and tos.
				 */
				inp->inp_ip.ip_ttl = ip_defttl;
				inp->inp_ip.ip_tos = 0;

				if (in6_pcbconnect(inp, am)) {
					inp->inp_laddr6 = laddr6;
					m_freem(am);
					goto drop;
				}
			} else /* (inp->inp_flags & INP_IPV6) */
d967 16
a982 24
			{
				struct sockaddr_in *sin;
				struct in_addr laddr;

				am->m_len = sizeof(struct sockaddr_in);
				sin = mtod(am, struct sockaddr_in *);
				sin->sin_family = AF_INET;
				sin->sin_len = sizeof(struct sockaddr_in);
				sin->sin_addr = nhu.ip->ip_src;
				sin->sin_port = th->th_sport;
				bzero((caddr_t)sin->sin_zero,
					sizeof(sin->sin_zero));
				laddr = inp->inp_laddr;
				if (inp->inp_laddr.s_addr == INADDR_ANY)
					inp->inp_laddr = nhu.ip->ip_dst;
				if (in_pcbconnect(inp, am)) {
					inp->inp_laddr = laddr;
					m_free(am);
					goto drop;
				}
			} /* (inp->inp_flags & INP_IPV6) */
			tp->pf = PF_INET;
			break;
#endif /* INET */
d984 2
a985 37
		case PF_INET6:
			{
				struct sockaddr_in6 *sin6;
				struct in6_addr laddr6;

				/*
			 	 * This is probably the place to set the tp->pf
				 * value. (Don't forget to do it in the v4 code
				 * as well!)
				 *
				 * Also, remember to blank out things like
				 * flowlabel, or set flowlabel for accepted
				 * sockets in v6.
				 */

				am->m_len = sizeof(struct sockaddr_in6);
				sin6 = mtod(am, struct sockaddr_in6 *);
				sin6->sin6_family = AF_INET6;
				sin6->sin6_len = sizeof(struct sockaddr_in6);
				sin6->sin6_addr = nhu.ipv6->ipv6_src;
				sin6->sin6_port = th->th_sport;
				sin6->sin6_flowinfo = htonl(0x0fffffff) &
					inp->inp_ipv6.ipv6_versfl;
				laddr6 = inp->inp_laddr6;

				if (IN6_IS_ADDR_UNSPECIFIED(&inp->inp_laddr6))
					inp->inp_laddr6 = nhu.ipv6->ipv6_dst;
				/* This is a good optimization. */
				if (in6_pcbconnect(inp, am)) {
					inp->inp_laddr6 = laddr6;
					m_free(am);
					goto drop;
				}
			}

			tp->pf = PF_INET6;
			break;
a986 3
		}

		m_free(am);
d993 3
a995 15

#ifdef TCP_SIGNATURE
		if (optp || (tp->t_flags & TF_SIGNATURE)) {
#else /* TCP_SIGNATURE */
		if (optp) {
#endif /* TCP_SIGNATURE */
			m->m_data -= iphlen + off;
			m->m_len  += iphlen + off;
			if (tcp_dooptions(tp, optp, optlen, th, m, iphlen,
					&ts_present, &ts_val, &ts_ecr))
				goto drop;
			m->m_data += iphlen + off;
			m->m_len  -= iphlen + off;
		}

d1296 1
a1296 1
		if (th->th_seq != tp->last_ack_sent)
d1922 8
a1929 3

	if (so->so_options & SO_DEBUG)
		tcp_trace(TA_INPUT, ostate, tp, tcp_savebuf, 0, tlen);
a1969 14
#if defined(INET) && defined(INET6)
	switch (pf) {
#else /* defined(INET) && defined(INET6) */
	switch (-1) {
	case -1:
#endif /* defined(INET) && defined(INET6) */
#ifdef INET
	case PF_INET:
		if (mtod(m, struct ip *)->ip_dst.s_addr == INADDR_BROADCAST)
			goto drop;
		if (IN_MULTICAST(mtod(m, struct ip *)->ip_dst.s_addr))
			goto drop;
		break;
#endif /* INET */
d1971 6
a1976 4
	case PF_INET6:
		if (IN6_IS_ADDR_MULTICAST(&mtod(m, struct ipv6 *)->ipv6_dst))
			goto drop;
		break;
d1978 3
d1982 1
a1982 1

d1984 1
a1984 2
		tcp_respond(tp, mtod(m, caddr_t), m, (tcp_seq)0, th->th_ack,
			TH_RST);
d1988 2
a1989 2
		tcp_respond(tp, mtod(m, caddr_t), m, th->th_seq+tlen,
			(tcp_seq)0, TH_RST|TH_ACK);
d2000 8
a2007 2
	if (tp && (tp->t_inpcb->inp_socket->so_options & SO_DEBUG))
		tcp_trace(TA_DROP, ostate, tp, tcp_savebuf, 0, tlen);
d2017 2
a2018 2
int
tcp_dooptions(tp, cp, cnt, th, m, iphlen, ts_present, ts_val, ts_ecr)
a2022 2
	struct mbuf *m;
	int iphlen;
a2027 3
#ifdef TCP_SIGNATURE
	caddr_t sigp = NULL;
#endif /* TCP_SIGNATURE */
a2095 11
#ifdef TCP_SIGNATURE
		case TCPOPT_SIGNATURE:
			if (optlen != TCPOLEN_SIGNATURE)
				continue;

			if (sigp && bcmp(sigp, cp + 2, 16))
				return -1;

			sigp = cp + 2;
			break;
#endif /* TCP_SIGNATURE */
a2097 113

#ifdef TCP_SIGNATURE
	if ((sigp ? TF_SIGNATURE : 0) ^ (tp->t_flags & TF_SIGNATURE)) {
		tcpstat.tcps_rcvbadsig++;
		return -1;
	}

	if (sigp) {
		MD5_CTX ctx;
		union sockaddr_union sa;
		struct tdb *tdb;
		char sig[16];

		memset(&sa, 0, sizeof(union sockaddr_union));

		switch (tp->pf) {
			case 0:
			case AF_INET:
				sa.sa.sa_len = sizeof(struct sockaddr_in);
				sa.sa.sa_family = AF_INET;
				sa.sin.sin_addr = tp->t_inpcb->inp_laddr;
				break;
#ifdef INET6
			case AF_INET6:
				sa.sa.sa_len = sizeof(struct sockaddr_in6);
				sa.sa.sa_family = AF_INET6;
				sa.sin6.sin6_addr = tp->t_inpcb->inp_laddr6;
				break;
#endif /* INET6 */
		}

		tdb = gettdb(0, &sa, IPPROTO_TCP);
		if (tdb == NULL) {
			printf("tdb miss\n");
			tcpstat.tcps_rcvbadsig++;
			return -1;
		}

		MD5Init(&ctx);

		switch(tp->pf) {
			case 0:
#ifdef INET
			case AF_INET:
				{
					struct ippseudo ippseudo;

					ippseudo.ippseudo_src =
						tp->t_inpcb->inp_faddr;
					ippseudo.ippseudo_dst =
						tp->t_inpcb->inp_laddr;
					ippseudo.ippseudo_pad = 0;
					ippseudo.ippseudo_p = IPPROTO_TCP;
					ippseudo.ippseudo_len = htons(
						m->m_pkthdr.len - iphlen);

					MD5Update(&ctx, (char *)&ippseudo,
						sizeof(struct ippseudo));
				}
				break;
#endif /* INET */
#ifdef INET6
			case AF_INET6:
				{
					static int printed = 0;

					if (!printed) {
						printf("error: TCP MD5 support"
							" for IPv6 not yet"
							" implemented.\n");
						printed = 1;
					}
				}
				break
#endif /* INET6 */
		}

		{
			struct tcphdr tcphdr;

			tcphdr.th_sport = th->th_sport;
			tcphdr.th_dport = th->th_dport;
			tcphdr.th_seq = htonl(th->th_seq);
			tcphdr.th_ack = htonl(th->th_ack);
			tcphdr.th_off = th->th_off;
			tcphdr.th_x2 = th->th_x2;
			tcphdr.th_flags = th->th_flags;
			tcphdr.th_win = htons(th->th_win);
			tcphdr.th_sum = 0;
			tcphdr.th_urp = htons(th->th_urp);

			MD5Update(&ctx, (char *)&tcphdr,
				sizeof(struct tcphdr));
		}

		if (m_apply(m, iphlen + th->th_off * sizeof(uint32_t),
				m->m_pkthdr.len - (iphlen + th->th_off *
				sizeof(uint32_t)), tcp_signature_apply,
				(caddr_t)&ctx))
			return (-1); 

		MD5Update(&ctx, tdb->tdb_amxkey, tdb->tdb_amxkeylen);
		MD5Final(sig, &ctx);

		if (bcmp(sig, sigp, 16)) {
			tcpstat.tcps_rcvbadsig++;
			return (-1);
		}

		tcpstat.tcps_rcvgoodsig++;
	};
#endif /* TCP_SIGNATURE */

a2100 2

	return (0);
@


1.40
log
@Added support for TCP MD5 option (RFC 2385).
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.38 1999/07/03 02:16:51 deraadt Exp $	*/
d316 1
@


1.39
log
@Fixed compilation problems when INET6 is enabled.
@
text
@d761 9
a769 3
	if (optp && tp->t_state != TCPS_LISTEN)
		tcp_dooptions(tp, optp, optlen, th,
			&ts_present, &ts_val, &ts_ecr);
d1077 1
a1077 1
				struct laddr6;
d1122 13
a1134 3
		if (optp)
			tcp_dooptions(tp, optp, optlen, th,
				&ts_present, &ts_val, &ts_ecr);
d2156 2
a2157 2
void
tcp_dooptions(tp, cp, cnt, th, ts_present, ts_val, ts_ecr)
d2162 2
d2169 3
d2240 11
d2254 112
d2369 2
@


1.38
log
@indent
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.37 1999/07/02 20:39:07 cmetz Exp $	*/
a326 1
	struct in_addr laddr;
d533 2
a534 2
		inp = in_pcbhashlookup(&tcbtable, nhu.ip->ip_src, th->th_sport,
			nhu.ip->ip_dst, th->th_dport);
d539 2
a540 2
		inp = in6_pcbhashlookup(&tcbtable, nhu.ipv6->ipv6_src,
			th->th_sport, nhu.ipv6->ipv6_dst, th->th_dport);
d980 1
a980 1
			if (IN6_IS_ADDR_MULTICAST(nhu.ipv6->ipv6_dst))
d1004 2
a1005 1
				struct sockaddr_in6 sin6;
d1045 1
d1070 2
a1071 1
				struct sockaddr_in6 sin6;
@


1.37
log
@Significant cleanups in the way TCP is made to handle multiple network
protocols.

"struct tcpiphdr" is now gone from much of the code, as are separate pointers
for ti and ti6. The result is fewer variables, which is generally a good thing.

Simple if(is_ipv6) ... else ... tests are gone in favor of a
switch(protocol family), which allows future new protocols to be added easily.
This also makes it possible for someone so inclined to re-implement TUBA (TCP
over CLNP?) and do it right instead of the kluged way it was done in 4.4.

The TCP header template is now referenced through a mbuf rather than done
through a data pointer and dtom()ed as needed. This is partly because dtom() is
evil and partly because max_linkhdr + IPv6 + TCP + MSS/TS/SACK opts won't fit
inside a packet header mbuf, so we need to grab a cluster for that (which the
code now does, if needed).
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.36 1999/06/11 19:46:39 pattonme Exp $	*/
d374 1
a374 1
	switch(mtod(m, struct ip *)->ip_v) {
d376 1
a376 1
	switch(-1) {
d435 1
a435 1
	switch(pf) {
d437 1
a437 1
	switch(-1) {
d527 1
a527 1
	switch(pf) {
d529 1
a529 1
	switch(-1) {
d549 1
a549 1
		switch(pf) {
d551 1
a551 1
		switch(-1) {
d670 1
a670 1
			switch(pf) {
d672 1
a672 1
			switch(-1) {
d720 1
a720 1
		switch(pf) {
d722 1
a722 1
		switch(-1) {
d936 1
a936 1
			switch(pf) {
d938 1
a938 1
			switch(-1) {
d966 1
a966 1
		switch(pf) {
d968 1
a968 1
		switch(-1) {
d992 1
a992 1
		switch(pf) {
d994 1
a994 1
		switch(-1) {
d2088 1
a2088 1
	switch(pf) {
d2090 1
a2090 1
	switch(-1) {
@


1.36
log
@removed TCPCOOKIE support.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.35 1999/05/24 17:46:40 provos Exp $	*/
d51 6
a96 3
struct	tcpiphdr tcp_saveti;
struct  tcpipv6hdr tcp_saveti6;

d103 6
a109 1
struct	tcpiphdr tcp_saveti;
a317 1
	register struct tcpiphdr *ti;
d336 1
d340 9
a348 5
#ifdef INET6
	struct in6_addr laddr6;
	unsigned short is_ipv6;     /* Type of incoming datagram. */
	struct ipv6 *ipv6 = NULL;
#endif /* INET6 */
d365 1
a365 1
#ifdef INET6
d367 5
a371 2
	 * Before we do ANYTHING, we have to figure out if it's TCP/IPv6 or
	 * TCP/IPv4.
d373 39
a411 1
	is_ipv6 = mtod(m, struct ip *)->ip_v == 6;
d413 4
a421 7
#ifndef INET6
	ti = mtod(m, struct tcpiphdr *);
#else /* INET6 */
	if (!is_ipv6)
#endif /* INET6 */
	if (iphlen > sizeof (struct ip))
		ip_stripoptions(m, (struct mbuf *)0);
a426 3
#ifndef INET6
		ti = mtod(m, struct tcpiphdr *);
#endif /* INET6 */
a430 1
#ifdef INET6
d432 1
a432 2
	 * After that, do initial segment processing which is still very
	 * dependent on what IP version you're using.
d434 10
d445 1
a445 7
	if (is_ipv6) {
#ifdef DIAGNOSTIC
	  if (iphlen < sizeof(struct ipv6)) {
	    m_freem(m);
	    return;
	  }
#endif /* DIAGNOSTIC */
d447 4
a450 16
	  /* strip off any options */
	  if (iphlen > sizeof(struct ipv6)) {
	    ipv6_stripoptions(m, iphlen);
	    iphlen = sizeof(struct ipv6);
	  }

	  ti = NULL;
	  ipv6 = mtod(m, struct ipv6 *);

	  if (in6_cksum(m, IPPROTO_TCP, tlen, sizeof(struct ipv6))) {
	    tcpstat.tcps_rcvbadsum++;
	    goto drop;
	  } /* endif in6_cksum */
	} else {
	  ti = mtod(m, struct tcpiphdr *);
#endif /* INET6 */
d452 14
a465 5
	/*
	 * Checksum extended TCP header and data.
	 */
#ifndef INET6
	tlen = ((struct ip *)ti)->ip_len;
a466 7
	len = sizeof (struct ip) + tlen;
	bzero(ti->ti_x1, sizeof ti->ti_x1);
	ti->ti_len = (u_int16_t)tlen;
	HTONS(ti->ti_len);
	if ((ti->ti_sum = in_cksum(m, len)) != 0) {
		tcpstat.tcps_rcvbadsum++;
		goto drop;
d468 1
a468 3
#ifdef INET6
	}
#endif /* INET6 */
d471 1
a489 6
#ifdef INET6
			if (is_ipv6)
			  ipv6 = mtod(m, struct ipv6 *);
			else
#endif /* INET6 */
			ti = mtod(m, struct tcpiphdr *);
d526 12
d539 4
a542 4
	if (is_ipv6) {
	  inp = in6_pcbhashlookup(&tcbtable, &ipv6->ipv6_src, th->th_sport,
				 &ipv6->ipv6_dst, th->th_dport);
	} else
d544 2
a545 2
	inp = in_pcbhashlookup(&tcbtable, ti->ti_src, ti->ti_sport,
	    ti->ti_dst, ti->ti_dport);
d548 13
d562 6
a567 5
		if (is_ipv6)
			inp = in_pcblookup(&tcbtable, &ipv6->ipv6_src,
			    th->th_sport, &ipv6->ipv6_dst, th->th_dport,
			    INPLOOKUP_WILDCARD | INPLOOKUP_IPV6);
		else
d569 2
a570 2
		inp = in_pcblookup(&tcbtable, &ti->ti_src, ti->ti_sport,
		    &ti->ti_dst, ti->ti_dport, INPLOOKUP_WILDCARD);
d599 2
a600 6
#ifdef INET6
			if (is_ipv6)
			  tcp_saveti6 = *(mtod(m, struct tcpipv6hdr *));
			else
#endif /* INET6 */
			tcp_saveti = *ti;
d648 2
a649 2
			  int flags = inp->inp_flags;
			  struct inpcb *oldinpcb = inp;
d651 13
a663 10
			  inp = (struct inpcb *)so->so_pcb;
			  inp->inp_flags |= (flags & (INP_IPV6 | INP_IPV6_UNDEC
						      | INP_IPV6_MAPPED));
			  if ((inp->inp_flags & INP_IPV6) &&
			      !(inp->inp_flags & INP_IPV6_MAPPED)) {
			    inp->inp_ipv6.ipv6_hoplimit = 
			      oldinpcb->inp_ipv6.ipv6_hoplimit;
			    inp->inp_ipv6.ipv6_versfl = 
			      oldinpcb->inp_ipv6.ipv6_versfl;
			  }
d669 21
d691 5
a695 22
			if (is_ipv6) {
			  inp->inp_laddr6 = ipv6->ipv6_dst;
			  inp->inp_fflowinfo = htonl(0x0fffffff) & 
			    ipv6->ipv6_versfl;
			  
			  /*inp->inp_options = ipv6_srcroute();*/ /* soon. */
			  /* still need to tweak outbound options
			     processing to include this mbuf in
			     the right place and put the correct
			     NextHdr values in the right places.
			     XXX  rja */
			} else {
			  if (inp->inp_flags & INP_IPV6) {/* v4 to v6 socket */
			    CREATE_IPV6_MAPPED(inp->inp_laddr6,
			      ti->ti_dst.s_addr);
			  } else {
#endif /* INET6 */
			    inp->inp_laddr = ti->ti_dst;
			    inp->inp_options = ip_srcroute();
#if INET6
			  }
			};
d697 2
d706 2
a707 1
			   TCP_MAXWIN << tp->request_r_scale < so->so_rcv.sb_hiwat)
d719 11
d731 1
a731 1
		if (is_ipv6)
d733 1
a733 1
		else
d735 1
a735 1
		icmp_error(m, ICMP_BLAH, ICMP_BLAH, 0, 0);
a926 4
		register struct sockaddr_in *sin;
#ifdef INET6
		register struct sockaddr_in6 *sin6;
#endif /* INET6 */
d935 13
d949 5
a953 9
		  if (is_ipv6) {
		    if (IN6_ARE_ADDR_EQUAL(&ipv6->ipv6_src, &ipv6->ipv6_dst))
		      goto drop;
		  } else {
#endif /* INET6 */
		    if (ti->ti_dst.s_addr == ti->ti_src.s_addr)
		      goto drop;
#ifdef INET6
		  }
d955 1
d965 14
d980 2
a981 3
		if (is_ipv6) {
			/* XXX What about IPv6 Anycasting ?? :-(  rja */
			if (IN6_IS_ADDR_MULTICAST(&ipv6->ipv6_dst))
d983 1
a983 1
		} else
d985 2
a986 2
		if (IN_MULTICAST(ti->ti_dst.s_addr))
			goto drop;
d990 9
d1000 42
a1041 69
		if (is_ipv6) {
		  /*
		   * This is probably the place to set the tp->pf value.
		   * (Don't forget to do it in the v4 code as well!)
		   *
		   * Also, remember to blank out things like flowlabel, or
		   * set flowlabel for accepted sockets in v6.
		   *
		   * FURTHERMORE, this is PROBABLY the place where the whole
		   * business of key munging is set up for passive
		   * connections.
		   */
		  am->m_len = sizeof(struct sockaddr_in6);
		  sin6 = mtod(am, struct sockaddr_in6 *);
		  sin6->sin6_family = AF_INET6;
		  sin6->sin6_len = sizeof(struct sockaddr_in6);
		  sin6->sin6_addr = ipv6->ipv6_src;
		  sin6->sin6_port = th->th_sport;
		  sin6->sin6_flowinfo = htonl(0x0fffffff) &
		    inp->inp_ipv6.ipv6_versfl;
		  laddr6 = inp->inp_laddr6;
		  if (IN6_IS_ADDR_UNSPECIFIED(&inp->inp_laddr6))
		    inp->inp_laddr6 = ipv6->ipv6_dst;
		  /* This is a good optimization. */
		  if (in6_pcbconnect(inp, am)) {
		    inp->inp_laddr6 = laddr6;
		    (void) m_free(am);
		    goto drop;
		  } /* endif in6_pcbconnect() */
		  tp->pf = PF_INET6;
		} else {
		  /*
		   * Letting v4 incoming datagrams to reach valid 
		   * PF_INET6 sockets causes some overhead here.
		   */
		  if (inp->inp_flags & INP_IPV6) {
		    if (!(inp->inp_flags & (INP_IPV6_UNDEC|INP_IPV6_MAPPED))) {
		      (void) m_free(am);
		      goto drop;
		    }

		    am->m_len = sizeof(struct sockaddr_in6);
		    
		    sin6 = mtod(am, struct sockaddr_in6 *);
		    sin6->sin6_family = AF_INET6;
		    sin6->sin6_len = sizeof(*sin6);
		    CREATE_IPV6_MAPPED(sin6->sin6_addr, ti->ti_src.s_addr);
		    sin6->sin6_port = th->th_sport;
		    sin6->sin6_flowinfo = 0;

		    laddr6 = inp->inp_laddr6;
		    if (inp->inp_laddr.s_addr == INADDR_ANY)
		      CREATE_IPV6_MAPPED(inp->inp_laddr6, ti->ti_dst.s_addr);
		    
		    /*
		     * The pcb initially has the v6 default hoplimit
		     * set. We're sending v4 packets so we need to set
		     * the v4 ttl and tos.
		     */
		    inp->inp_ip.ip_ttl = ip_defttl;
		    inp->inp_ip.ip_tos = 0;
		    
		    if (in6_pcbconnect(inp, am)) {
		      inp->inp_laddr6 = laddr6;
		      (void) m_freem(am);
		      goto drop;
		    }
		    tp->pf = PF_INET;
		  } else { 
d1043 23
a1065 16
		am->m_len = sizeof (struct sockaddr_in);
		sin = mtod(am, struct sockaddr_in *);
		sin->sin_family = AF_INET;
		sin->sin_len = sizeof(*sin);
		sin->sin_addr = ti->ti_src;
		sin->sin_port = ti->ti_sport;
		bzero((caddr_t)sin->sin_zero, sizeof(sin->sin_zero));
		laddr = inp->inp_laddr;
		if (inp->inp_laddr.s_addr == INADDR_ANY)
			inp->inp_laddr = ti->ti_dst;
		if (in_pcbconnect(inp, am)) {
			inp->inp_laddr = laddr;
			(void) m_free(am);
			goto drop;
		}
		(void) m_free(am);
d1067 36
a1102 2
		  }  /* if (inp->inp_flags & INP_IPV6) */
		} /* if (is_ipv6) */
d1104 3
d1113 1
d1117 1
d1418 1
a1418 1
		if (ti->ti_seq != tp->last_ack_sent)
d2044 3
a2046 8
	if (so->so_options & SO_DEBUG) {
#ifdef INET6
		if (tp->pf == PF_INET6)
			tcp_trace(TA_INPUT, ostate, tp, (struct tcpiphdr *) &tcp_saveti6, 0, tlen);
		else
#endif /* INET6 */
			tcp_trace(TA_INPUT, ostate, tp, &tcp_saveti, 0, tlen);
	}
d2087 14
d2102 4
a2105 6
	if (is_ipv6) {
	  /* For following calls to tcp_respond */
	  ti = mtod(m, struct tcpiphdr *);
	  if (IN6_IS_ADDR_MULTICAST(&ipv6->ipv6_dst))
	    goto drop;
	} else {
a2106 3
	    if (IN_MULTICAST(ti->ti_dst.s_addr))
	      goto drop;
#ifdef INET6
d2108 1
a2108 1
#endif /* INET6 */
d2110 2
a2111 1
		tcp_respond(tp, ti, m, (tcp_seq)0, th->th_ack, TH_RST);
d2115 2
a2116 2
		tcp_respond(tp, ti, m, th->th_seq+tlen, (tcp_seq)0,
		    TH_RST|TH_ACK);
d2127 2
a2128 8
	if (tp && (tp->t_inpcb->inp_socket->so_options & SO_DEBUG)) {
#ifdef INET6
	  if (tp->pf == PF_INET6)
	    tcp_trace(TA_DROP, ostate, tp, (struct tcpiphdr *)&tcp_saveti6, 0, tlen);
	  else
#endif /* INET6 */
	    tcp_trace(TA_DROP, ostate, tp, &tcp_saveti, 0, tlen);
	}
d2219 1
@


1.35
log
@instead of dropping out of window SYNs, send an ACK and drop afterwards.
fixes a problem with NFS over TCP reported by Jason Thorpe, fix from
klm@@netbsd.org
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.34 1999/04/21 21:38:58 provos Exp $	*/
a112 115
#ifdef TCPCOOKIE
/*
 * Code originally by Matt Blaze and John Ioannidis. This code implements
 * a cookie-like extension for TCP. Adapted to OpenBSD by Angelos D.
 * Keromytis.
 */

#ifndef TCK_NFRIENDS
#define TCK_NFRIENDS 16
#endif /* TCK_NFRIENDS */

static struct in_addr tck_friends[TCK_NFRIENDS];
static int tck_nfriends = 0;
static int tck_initialized = 0;

#define TCK_PORT  333			/* Unused port! */

static int
tck_isafriend(struct in_addr f)
{
	register int i;
	
	for (i = tck_nfriends - 1; i >= 0; i--)
	  if (tck_friends[i].s_addr == f.s_addr)
	    return 1;

	return 0;
}

static void
tck_delat(int n)
{
	int i;
	
	if ((n >= tck_nfriends) || (tck_nfriends == 0))
	  return;

	for (i = n + 1; i < tck_nfriends ; i++)
	  tck_friends[i - 1] = tck_friends[i];

	tck_nfriends--;
}

static void
tck_addfriend(struct in_addr f)
{
#ifdef DEBUG_TCPCOOKIE
	printf("tck_addfriend: 0x%08x\n", ntohl(f.s_addr));
#endif /* DEBUG_TCPCOOKIE */

	if (tck_isafriend(f))
	  return;

	if (tck_nfriends == TCK_NFRIENDS)
	  tck_delat(0);

	tck_friends[tck_nfriends++] = f;
}

/*
 * static void
 * tck_delfriend(struct in_addr f)
 * {
 *	int i;
 *
 *      for (i = tck_nfriends - 1; i >= 0; i--)
 *        if (tck_friends[i].s_addr == f.s_addr)
 *	    goto found1;
 *	
 *	return;
 *
 * found1:
 *	tck_delat(i);
 * }
*/

static u_int32_t
tck_makecookie(f)
	struct in_addr f;
{
	static MD5_CTX ctx;
	u_int8_t buf[16];
	MD5_CTX ctx2;

	if (tck_initialized == 0) {	/* This only happens once per reboot */
		tck_initialized = 1;

		get_random_bytes((void *) buf, 16);
		MD5Init(&ctx);
		MD5Update(&ctx, buf, 16);
	}
	ctx2 = ctx;
	MD5Update(&ctx2, (void *) &f, sizeof(f));
	MD5Final(buf, &ctx2);		/* This may not be necessary */
	return ((buf[0] << 24) | (buf[1] << 16) | (buf[2] << 8) | buf[3]);
}	

static int
tck_chkcookie(ti)
	struct tcpiphdr *ti;
{
#ifdef DEBUG_TCPCOOKIE
	printf("tck_chkcookie: src = 0x%08x, cookie = 0x%08x, seq = 0x%08x, ack = 0x%08x\n", ntohl(ti->ti_src.s_addr), tck_makecookie(ti->ti_src), ti->ti_seq, ti->ti_ack);
#endif /* DEBUG_TCPCOOKIE */

	if (tck_makecookie(ti->ti_src) == ti->ti_seq) {
		/* seq in host order */
		tck_addfriend(ti->ti_src);
		return 1;
	}
	return 0;
}

#endif /* TCPCOOKIE */

a489 16
#ifdef TCPCOOKIE
	/* 
	 * If this looks like a cookie response, check it.
	 * If it is, the check routine also adds the source
	 * of the packet to the friends list.
	 */

#ifdef INET6
	if (!is_ipv6 && (tiflags & TH_RST) && (ntohs(th->th_dport) == TCK_PORT))
#else /* INET6 */
	if ((tiflags & TH_RST) && (ntohs(ti->ti_dport) == TCK_PORT))
#endif /* INET6 */
	  if (tck_chkcookie(ti))
	    goto drop;			/* RST is no longer needed */
#endif /* TCPCOOKIE */

a875 19

#ifdef TCPCOOKIE
		/*
		 * If source address is on friends list, proceed, otherwise
		 * try to obtain a cookie and drop the frame.
		 */
		
		if (!tck_isafriend(ti->ti_src)) {
			u_int32_t acookie;

			acookie = tck_makecookie(ti->ti_src);
			ti->ti_dport = htons(TCK_PORT);
			tcp_respond(tp, ti, m, acookie, acookie, TH_ACK);
			/* destroy temporarily created socket */
			if (dropsocket)
				(void) soabort(so);
			return;
		}
#endif /* TCPCOOKIE */
@


1.34
log
@From Tom Henderson <tomh@@cs.berkeley.edu>:

Fixed a sequence wraparound bug in the snd_recover variable discovered in
very large (multiple GByte) transfers (in loss free conditions, snd_recover
was not sufficiently tracking snd_una).  Thanks to Mark Smith for finding
this.

Fixed a bug in tcp_newreno that was preventing retransmission of data due
to partial acks. (Discovered by Jayanth Vijayaraghavan)
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.33 1999/03/27 21:04:20 provos Exp $	*/
d1484 6
a1489 2
	if ((tiflags & TH_ACK) == 0)
		goto drop;
@


1.33
log
@add SADB_X_BINDSA to pfkey allowing incoming SAs to refer to an outgoing
SA to be used, use this SA in ip_output if available. allow mobile road
warriors for bind SAs with wildcard dst and src addresses. check IPSEC
AUTH and ESP level when receiving packets, drop them if protection is
insufficient. add stats to show dropped packets because of insufficient
IPSEC protection. -- phew.  this was all done in canada. dugsong and linh
provided the ride and company.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.32 1999/02/15 02:39:02 provos Exp $	*/
d878 8
d2989 5
a2993 1
		tp->snd_cwnd = tp->t_maxseg;
@


1.32
log
@when allocating sack blocks check for failing malloc(), if it fails
just ignore the sack block + fix misleading comment. tomh@@CS.Berkeley.EDU
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.31 1999/02/09 22:58:24 hugh Exp $	*/
d80 4
d444 3
d459 9
d702 12
d778 22
@


1.31
log
@correct rst handling should not consult ack field here
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.29 1999/02/05 05:42:36 deraadt Exp $	*/
d2347 4
d2442 4
a2455 2
				temp = (struct sackhole *)malloc(sizeof(*temp),
				    M_PCB,M_NOWAIT);
d2481 2
d2498 1
a2498 1
	 * Update retran_data, snd_fack, and snd_awnd.  Go through the list of 
a2499 1
	 * snd_fack gets the highest value of hole->end. 
@


1.30
log
@init incr tcp iss from snd_nxt, not rcv_nxt; 4.4
@
text
@d1388 1
a1388 3
		if ((th->th_seq != tp->rcv_nxt) &&
		    (th->th_ack && ((SEQ_GT(th->th_ack, tp->snd_nxt) ||
		      SEQ_LT(th->th_ack, (tp->snd_nxt - tp->snd_wnd))))))
@


1.29
log
@indent
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.28 1999/01/27 16:47:29 provos Exp $	*/
d1343 1
a1343 1
				iss = tp->rcv_nxt + TCP_ISSINCR;
@


1.28
log
@fix NEWRENO behaviour, the newreo code assumed that the send socket buffer has
already been cleared of the acked data, though it was called before any
sbdrop() call and always called tcp_output() with 0 index in the send
socket buffer and thus causing data corruption. so do not set snd_una to
th_ack.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.27 1999/01/27 10:04:57 niklas Exp $	*/
d1926 16
a1941 16
	  if (th->th_seq == tp->rcv_nxt && tp->segq.lh_first == NULL &&
	      tp->t_state == TCPS_ESTABLISHED) {
	    if (th->th_flags & TH_PUSH)
	      tp->t_flags |= TF_ACKNOW;
	    else
	      tp->t_flags |= TF_DELACK;
	    (tp)->rcv_nxt += tlen;
	    tiflags = th->th_flags & TH_FIN;
	    tcpstat.tcps_rcvpack++;
	    tcpstat.tcps_rcvbyte += tlen;
	    sbappend(&so->so_rcv, m);
	    sorwakeup(so);
	  } else {
	    tiflags = tcp_reass(tp, th, m, &tlen);
	    tp->t_flags |= TF_ACKNOW;
	  }
d1947 4
a1950 4
	  /* 
	   * variable len never referenced again in modern BSD,
	   * so why bother computing it ??
	   */
@


1.27
log
@reordered FIN segments caused early termination, bug introduced by ipv6 integration
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.26 1999/01/15 12:01:06 niklas Exp $	*/
d2915 6
a2921 1
		tcp_seq ouna = tp->snd_una;	/* snd_una not yet updated */
a2926 1
		tp->snd_una = th->th_ack;
a2928 1
		tp->snd_una = ouna;
@


1.26
log
@IN_MULTICAST takes network order addresses
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.25 1999/01/11 15:05:32 niklas Exp $	*/
d1939 1
a1939 1
	    tcp_reass(tp, th, m, &tlen);
@


1.25
log
@Make TCP_SACK compile with new netinet
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.24 1999/01/11 02:01:35 deraadt Exp $	*/
d983 1
a983 1
		if (IN_MULTICAST(ntohl(ti->ti_dst.s_addr)))
d2068 1
a2068 1
	    if (IN_MULTICAST(ntohl(ti->ti_dst.s_addr)))
@


1.24
log
@netinet merge of NRL stuff. some indent and shrinkage needed; NRL/cmetz
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.23 1999/01/07 06:05:04 deraadt Exp $	*/
d2517 1
a2517 1
	struct tcpiphdr *th;
d2562 1
a2562 1
	struct tcpiphdr *th;
d2564 1
a2564 1
	if (SEQ_LT(th->ti_ack, tp->snd_last)) {
d2911 2
a2912 2
struct tcpcb *tp;
struct tcphdr *th;
@


1.23
log
@in_pcblookup() now takes ptr to both ip address arguments
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.22 1998/11/25 05:44:36 millert Exp $	*/
d39 12
d80 16
d234 1
a234 19
#define	TCP_REASS(tp, ti, m, so, flags) { \
	if ((ti)->ti_seq == (tp)->rcv_nxt && \
	    (tp)->segq.lh_first == NULL && \
	    (tp)->t_state == TCPS_ESTABLISHED) { \
		if ((ti)->ti_flags & TH_PUSH) \
			tp->t_flags |= TF_ACKNOW; \
		else \
			tp->t_flags |= TF_DELACK; \
		(tp)->rcv_nxt += (ti)->ti_len; \
		flags = (ti)->ti_flags & TH_FIN; \
		tcpstat.tcps_rcvpack++;\
		tcpstat.tcps_rcvbyte += (ti)->ti_len;\
		sbappend(&(so)->so_rcv, (m)); \
		sorwakeup(so); \
	} else { \
		(flags) = tcp_reass((tp), (ti), (m)); \
		tp->t_flags |= TF_ACKNOW; \
	} \
}
d238 1
a238 1
tcp_reass(tp, ti, m)
d240 1
a240 1
	register struct tcpiphdr *ti;
d242 1
d249 1
a249 1
	 * Call with ti==0 after become established to
d252 1
a252 1
	if (ti == 0)
d271 1
a271 1
		if (SEQ_GT(q->ipqe_tcp->ti_seq, ti->ti_seq))
d280 1
a280 1
		register struct tcpiphdr *phdr = p->ipqe_tcp;
d284 1
a284 1
		i = phdr->ti_seq + phdr->ti_len - ti->ti_seq;
d286 1
a286 1
			if (i >= ti->ti_len) {
d288 1
a288 1
				tcpstat.tcps_rcvdupbyte += ti->ti_len;
d294 2
a295 2
			ti->ti_len -= i;
			ti->ti_seq += i;
d299 1
a299 1
	tcpstat.tcps_rcvoobyte += ti->ti_len;
d306 2
a307 2
		register struct tcpiphdr *qhdr = q->ipqe_tcp;
		register int i = (ti->ti_seq + ti->ti_len) - qhdr->ti_seq;
d311 3
a313 3
		if (i < qhdr->ti_len) {
			qhdr->ti_seq += i;
			qhdr->ti_len -= i;
d325 2
a326 1
	tiqe->ipqe_tcp = ti;
d341 1
a341 1
	if (q == NULL || q->ipqe_tcp->ti_seq != tp->rcv_nxt)
d343 1
a343 1
	if (tp->t_state == TCPS_SYN_RECEIVED && q->ipqe_tcp->ti_len)
d346 2
a347 2
		tp->rcv_nxt += q->ipqe_tcp->ti_len;
		flags = q->ipqe_tcp->ti_flags & TH_FIN;
d357 1
a357 1
	} while (q != NULL && q->ipqe_tcp->ti_seq == tp->rcv_nxt);
d439 6
d451 9
d464 1
d466 3
d471 2
a472 2
	if (m->m_len < sizeof (struct tcpiphdr)) {
		if ((m = m_pullup(m, sizeof (struct tcpiphdr))) == 0) {
d476 1
d478 1
d481 33
d517 1
d519 1
d528 3
d533 2
d539 1
a539 1
	off = ti->ti_off << 2;
a544 1
	ti->ti_len = tlen;
d546 2
a547 2
		if (m->m_len < sizeof(struct ip) + off) {
			if ((m = m_pullup(m, sizeof (struct ip) + off)) == 0) {
d551 5
d557 1
d560 1
a560 1
		optp = mtod(m, caddr_t) + sizeof (struct tcpiphdr);
d572 1
a572 1
		     (ti->ti_flags & TH_SYN) == 0) {
d579 1
a579 1
	tiflags = ti->ti_flags;
d584 4
a587 4
	NTOHL(ti->ti_seq);
	NTOHL(ti->ti_ack);
	NTOHS(ti->ti_win);
	NTOHS(ti->ti_urp);
d596 3
d600 1
d609 6
d619 7
d648 1
a648 1
		tiwin = ti->ti_win << tp->snd_scale;
d650 1
a650 1
		tiwin = ti->ti_win;
d656 5
d668 1
a668 1
				tcpdropoldhalfopen(tp, ti->ti_dport);
d686 26
d713 26
a738 2
			inp->inp_laddr = ti->ti_dst;
			inp->inp_lport = ti->ti_dport;
a739 3
#if BSD>=43
			inp->inp_options = ip_srcroute();
#endif
d761 1
a761 1
		tcp_del_sackholes(tp, ti); /* Delete stale SACK holes */
d769 1
a769 1
		tcp_dooptions(tp, optp, optlen, ti,
d774 2
a775 2
		tp->rcv_laststart = ti->ti_seq; /* last rec'vd segment*/
		tp->rcv_lastend = ti->ti_seq + ti->ti_len;
d795 1
a795 1
	    ti->ti_seq == tp->rcv_nxt &&
d804 1
a804 1
		if (ts_present && SEQ_LEQ(ti->ti_seq, tp->last_ack_sent)) {
d809 3
a811 3
		if (ti->ti_len == 0) {
			if (SEQ_GT(ti->ti_ack, tp->snd_una) &&
			    SEQ_LEQ(ti->ti_ack, tp->snd_max) &&
d821 1
a821 1
					    SEQ_GT(ti->ti_ack, tp->t_rtseq))
d823 1
a823 1
				acked = ti->ti_ack - tp->snd_una;
d827 1
a827 1
				tp->snd_una = ti->ti_ack;
d854 1
a854 1
		} else if (ti->ti_ack == tp->snd_una &&
d856 1
a856 1
		    ti->ti_len <= sbspace(&so->so_rcv)) {
d858 1
a858 1
			 * this is a pure, in-sequence data packet
d868 1
a868 1
			tp->rcv_nxt += ti->ti_len;
d870 1
a870 1
			tcpstat.tcps_rcvbyte += ti->ti_len;
d875 2
a876 2
			m->m_data += sizeof(struct tcpiphdr)+off-sizeof(struct tcphdr);
			m->m_len -= sizeof(struct tcpiphdr)+off-sizeof(struct tcphdr);
d879 1
a879 1
			if (ti->ti_flags & TH_PUSH)
d890 2
a891 2
	m->m_data += sizeof(struct tcpiphdr)+off-sizeof(struct tcphdr);
	m->m_len  -= sizeof(struct tcpiphdr)+off-sizeof(struct tcphdr);
d926 3
d936 13
a948 3
		if ((ti->ti_dport == ti->ti_sport) &&
		    (ti->ti_dst.s_addr == ti->ti_src.s_addr))
		 	goto drop;
d974 10
a983 2
		if (m->m_flags & (M_BCAST|M_MCAST) ||
		    IN_MULTICAST(ti->ti_dst.s_addr))
d988 71
d1075 4
d1086 1
a1086 1
			tcp_dooptions(tp, optp, optlen, ti,
d1108 1
a1108 1
		tp->irs = ti->ti_seq;
d1139 2
a1140 2
			if (SEQ_LEQ(ti->ti_ack, tp->snd_una) ||
			    SEQ_GT(ti->ti_ack, tp->snd_max))
d1159 2
a1160 2
		    (SEQ_LEQ(ti->ti_ack, tp->iss) ||
		     SEQ_GT(ti->ti_ack, tp->snd_max)))
d1170 1
a1170 1
			tp->snd_una = ti->ti_ack;
d1175 1
a1175 1
		tp->irs = ti->ti_seq;
d1198 2
a1199 2
			(void) tcp_reass(tp, (struct tcpiphdr *)0,
				(struct mbuf *)0);
d1224 3
a1226 3
		ti->ti_seq++;
		if (ti->ti_len > tp->rcv_wnd) {
			todrop = ti->ti_len - tp->rcv_wnd;
d1228 1
a1228 1
			ti->ti_len = tp->rcv_wnd;
d1233 2
a1234 2
		tp->snd_wl1 = ti->ti_seq - 1;
		tp->rcv_up = ti->ti_seq;
d1267 1
a1267 1
			tcpstat.tcps_rcvdupbyte += ti->ti_len;
d1273 1
a1273 1
	todrop = tp->rcv_nxt - ti->ti_seq;
d1277 3
a1279 3
			ti->ti_seq++;
			if (ti->ti_urp > 1) 
				ti->ti_urp--;
d1284 2
a1285 2
		if (todrop >= ti->ti_len ||
		    (todrop == ti->ti_len && (tiflags & TH_FIN) == 0)) {
d1297 1
a1297 1
			tcpstat.tcps_rcvdupbyte += todrop = ti->ti_len;
d1304 4
a1307 4
		ti->ti_seq += todrop;
		ti->ti_len -= todrop;
		if (ti->ti_urp > todrop)
			ti->ti_urp -= todrop;
d1310 1
a1310 1
			ti->ti_urp = 0;
d1319 1
a1319 1
	    tp->t_state > TCPS_CLOSE_WAIT && ti->ti_len) {
d1329 1
a1329 1
	todrop = (ti->ti_seq+ti->ti_len) - (tp->rcv_nxt+tp->rcv_wnd);
d1332 2
a1333 2
		if (todrop >= ti->ti_len) {
			tcpstat.tcps_rcvbyteafterwin += ti->ti_len;
d1342 1
a1342 1
			    SEQ_GT(ti->ti_seq, tp->rcv_nxt)) {
d1354 1
a1354 1
			if (tp->rcv_wnd == 0 && ti->ti_seq == tp->rcv_nxt) {
d1362 1
a1362 1
		ti->ti_len -= todrop;
d1372 1
a1372 1
	    SEQ_LEQ(ti->ti_seq, tp->last_ack_sent)) {
d1388 3
a1390 4

		if ((ti->ti_seq != tp->rcv_nxt) &&
		    (ti->ti_ack && ((SEQ_GT(ti->ti_ack, tp->snd_nxt) ||
		      SEQ_LT(ti->ti_ack, (tp->snd_nxt - tp->snd_wnd))))))
d1451 3
a1453 2
		(void) tcp_reass(tp, (struct tcpiphdr *)0, (struct mbuf *)0);
		tp->snd_wl1 = ti->ti_seq - 1;
d1471 1
a1471 2

		if (SEQ_LEQ(ti->ti_ack, tp->snd_una)) {
d1484 1
a1484 1
			if (ti->ti_len)
d1492 1
a1492 1
			if (ti->ti_ack != tp->snd_una) {
d1542 1
a1542 1
					if (SEQ_LT(ti->ti_ack, tp->snd_last)){
d1598 1
a1598 1
					tp->snd_nxt = ti->ti_ack;
d1640 1
a1640 1
		if (tp->t_dupacks >= tcprexmtthresh && !tcp_newreno(tp, ti)) {
d1649 1
a1649 1
			if (tcp_seq_subtract(tp->snd_max, ti->ti_ack) <
d1652 1
a1652 1
				    ti->ti_ack) + tp->t_maxseg;	
d1659 1
a1659 1
				if (tcp_sack_partialack(tp, ti)) {
d1672 1
a1672 1
					    ti->ti_ack) < tp->snd_ssthresh)
d1675 1
a1675 1
					           ti->ti_ack) + tp->t_maxseg;	
d1678 2
a1679 2
					if (SEQ_GT(ti->ti_ack, tp->snd_fack))
						tp->snd_fack = ti->ti_ack;
d1685 1
a1685 1
			    !tcp_newreno(tp, ti)) {
d1688 1
a1688 1
				if (tcp_seq_subtract(tp->snd_max, ti->ti_ack) <
d1692 1
a1692 1
					    ti->ti_ack) + tp->t_maxseg;	
d1702 1
a1702 1
		if (SEQ_GT(ti->ti_ack, tp->snd_max)) {
d1706 1
a1706 1
		acked = ti->ti_ack - tp->snd_una;
d1721 1
a1721 1
		else if (tp->t_rtt && SEQ_GT(ti->ti_ack, tp->t_rtseq))
d1730 1
a1730 1
		if (ti->ti_ack == tp->snd_max) {
d1749 1
a1749 1
		if (SEQ_GEQ(ti->ti_ack, tp->snd_last)) 
d1764 1
a1764 1
		tp->snd_una = ti->ti_ack;
d1840 3
a1842 3
	if (((tiflags & TH_ACK) && SEQ_LT(tp->snd_wl1, ti->ti_seq)) ||
	    (tp->snd_wl1 == ti->ti_seq && SEQ_LT(tp->snd_wl2, ti->ti_ack)) ||
	    (tp->snd_wl2 == ti->ti_ack && tiwin > tp->snd_wnd)) {
d1844 2
a1845 2
		if (ti->ti_len == 0 &&
		    tp->snd_wl2 == ti->ti_ack && tiwin > tp->snd_wnd)
d1848 2
a1849 2
		tp->snd_wl1 = ti->ti_seq;
		tp->snd_wl2 = ti->ti_ack;
d1858 1
a1858 1
	if ((tiflags & TH_URG) && ti->ti_urp &&
d1866 2
a1867 2
		if (ti->ti_urp + so->so_rcv.sb_cc > sb_max) {
			ti->ti_urp = 0;			/* XXX */
d1885 2
a1886 2
		if (SEQ_GT(ti->ti_seq+ti->ti_urp, tp->rcv_up)) {
			tp->rcv_up = ti->ti_seq + ti->ti_urp;
d1900 1
a1900 1
		if (ti->ti_urp <= (u_int16_t) ti->ti_len
d1905 1
a1905 1
			tcp_pulloutofband(so, ti, m);
d1924 1
a1924 1
	if ((ti->ti_len || (tiflags & TH_FIN)) &&
d1926 16
a1941 1
		TCP_REASS(tp, ti, m, so, tiflags);
d1946 6
d1958 1
d2012 8
a2019 2
	if (so->so_options & SO_DEBUG)
		tcp_trace(TA_INPUT, ostate, tp, &tcp_saveti, 0);
d2058 15
a2072 3
	if ((tiflags & TH_RST) || m->m_flags & (M_BCAST|M_MCAST) ||
	    IN_MULTICAST(ti->ti_dst.s_addr))
		goto drop;
d2074 1
a2074 1
		tcp_respond(tp, ti, m, (tcp_seq)0, ti->ti_ack, TH_RST);
d2077 2
a2078 2
			ti->ti_len++;
		tcp_respond(tp, ti, m, ti->ti_seq+ti->ti_len, (tcp_seq)0,
d2090 9
a2098 2
	if (tp && (tp->t_inpcb->inp_socket->so_options & SO_DEBUG))
		tcp_trace(TA_DROP, ostate, tp, &tcp_saveti, 0);
d2108 1
a2108 1
tcp_dooptions(tp, cp, cnt, ti, ts_present, ts_val, ts_ecr)
d2112 1
a2112 1
	struct tcpiphdr *ti;
d2138 1
a2138 1
			if (!(ti->ti_flags & TH_SYN))
d2147 1
a2147 1
			if (!(ti->ti_flags & TH_SYN))
d2166 1
a2166 1
			if (ti->ti_flags & TH_SYN) {
d2176 2
a2177 2
				continue;  
			if (ti->ti_flags & TH_SYN)  
d2182 1
a2182 1
			if (tcp_sack_option(tp, ti, cp, optlen))
d2189 1
a2189 1
	if (ti->ti_flags & TH_SYN)
d2304 2
a2305 2
int         
tcp_sack_option(tp, ti, cp, optlen) 
d2307 1
a2307 1
	struct tcpiphdr *ti;
d2350 1
a2350 1
			cur->start = ti->ti_ack;
d2515 1
a2515 1
tcp_del_sackholes(tp, ti)
d2517 1
a2517 1
	struct tcpiphdr *ti;
d2521 1
a2521 1
		tcp_seq lastack = max(ti->ti_ack, tp->snd_una);
d2560 1
a2560 1
tcp_sack_partialack(tp, ti)
d2562 1
a2562 1
	struct tcpiphdr *ti;
d2564 1
a2564 1
	if (SEQ_LT(ti->ti_ack, tp->snd_last)) {
d2574 1
a2574 1
		tp->snd_cwnd -= (ti->ti_ack - tp->snd_una - tp->t_maxseg);
d2589 1
a2589 1
tcp_pulloutofband(so, ti, m)
d2591 1
a2591 1
	struct tcpiphdr *ti;
d2594 1
a2594 1
	int cnt = ti->ti_urp - 1;
d2726 1
d2730 23
a2764 1
	so = inp->inp_socket;
d2795 10
d2806 3
d2812 9
a2820 1
		mss = ifp->if_mtu - sizeof(struct tcpiphdr);
d2910 1
a2910 1
tcp_newreno(tp, ti)
d2912 1
a2912 1
struct tcpiphdr *ti;
d2914 1
a2914 1
	if (SEQ_LT(ti->ti_ack, tp->snd_last)) {
d2920 1
a2920 1
		tp->snd_nxt = ti->ti_ack;
d2922 1
a2922 1
		tp->snd_una = ti->ti_ack;
d2932 1
a2932 1
		tp->snd_cwnd -= (ti->ti_ack - tp->snd_una - tp->t_maxseg);
@


1.22
log
@more min vs. ulmin/lmin fixes
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.21 1998/11/17 19:23:01 provos Exp $	*/
d531 2
a532 2
		inp = in_pcblookup(&tcbtable, ti->ti_src, ti->ti_sport,
		    ti->ti_dst, ti->ti_dport, INPLOOKUP_WILDCARD);
@


1.21
log
@NewReno, SACK and FACK support for TCP, adapted from code for BSDI
by Hari Balakrishnan (hari@@lcs.mit.edu), Tom Henderson (tomh@@cs.berkeley.edu)
and Venkat Padmanabhan (padmanab@@cs.berkeley.edu) as part of the
Daedalus research group at the University of California,
(http://daedalus.cs.berkeley.edu). [I was able to do this on time spent
at the Center for Information Technology Integration (citi.umich.edu)]
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.20 1998/10/28 21:34:32 provos Exp $	*/
d1295 3
a1297 3
					u_int win =
					    min(tp->snd_wnd, tp->snd_cwnd) / 2 /
						tp->t_maxseg;
@


1.20
log
@- fix three bugs pointed out in Stevens, i.a. updating timestamps correctly
- fix a 4.4bsd-lite2 bug, when tcp options are present the maximum segment
size is not updated correctly, so that fast recovery forces out a segment
which is split in two segments by tcp_output(), the fix is adpated from
FreeBSD, the effective mss is recorded after option negotiation in 3way
handshake.
[I was able to fix this on time spent at Center for Information Technology
Integration (citi.umich.edu)]
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.19 1998/06/27 02:42:40 deraadt Exp $	*/
d612 5
d625 6
d666 1
a666 1
			    tp->t_dupacks < tcprexmtthresh) {
d681 4
d715 5
d845 11
d867 8
d935 10
d963 9
d1230 25
a1254 1
			if (ti->ti_len == 0 && tiwin == tp->snd_wnd) {
d1280 1
a1280 2
				if (tp->t_timer[TCPT_REXMT] == 0 ||
				    ti->ti_ack != tp->snd_una)
d1282 10
d1293 1
d1299 12
d1314 40
d1358 1
d1360 1
d1367 11
d1382 7
a1388 1
			} else
d1390 1
d1397 58
d1459 1
d1498 1
a1498 3
		 * (maxseg^2 / cwnd per packet), plus a constant
		 * fraction of a packet (maxseg/8) to help larger windows
		 * open quickly enough.
d1506 3
d1525 4
d1685 4
d1754 1
a1754 1
	if (needoutput || (tp->t_flags & TF_ACKNOW))
d1756 12
d1883 14
d1904 389
a2433 1
	extern int tcp_mssdflt;
d2568 37
@


1.19
log
@indent
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.18 1998/03/18 02:37:47 angelos Exp $	*/
d644 1
d646 1
a646 2
		if (ts_present && SEQ_LEQ(ti->ti_seq, tp->last_ack_sent) &&
		   SEQ_LT(tp->last_ack_sent, ti->ti_seq + ti->ti_len)) {
d983 2
a984 1
		if (todrop >= ti->ti_len) {
d1068 1
d1070 2
a1071 3
	if (ts_present && SEQ_LEQ(ti->ti_seq, tp->last_ack_sent) &&
	    SEQ_LT(tp->last_ack_sent, ti->ti_seq + ti->ti_len +
		   ((tiflags & (TH_SYN|TH_FIN)) != 0))) {
d1583 1
a1583 1
	u_int16_t mss;
a1608 1
			(void) tcp_mss(tp, mss);	/* sets t_maxseg */
d1641 3
d1768 6
d1800 2
a1801 1
		if ((rt = ro->ro_rt) == (struct rtentry *)0)
d1803 1
a1841 7
#if	(MCLBYTES & (MCLBYTES - 1)) == 0
		if (mss > MCLBYTES)
			mss &= ~(MCLBYTES-1);
#else
		if (mss > MCLBYTES)
			mss = mss / MCLBYTES * MCLBYTES;
#endif
d1855 27
a1881 8
	mss = max(mss, 32);		/* sanity */
	if (mss < tp->t_maxseg || offer != 0) {
		/*
		 * If there's a pipesize, change the socket buffer
		 * to that size.  Make the socket buffers an integral
		 * number of mss units; if the mss is larger than
		 * the socket buffer, decrease the mss.
		 */
d1883 1
a1883 1
		if ((bufsize = rt->rt_rmx.rmx_sendpipe) == 0)
d1885 10
a1894 10
			bufsize = so->so_snd.sb_hiwat;
		if (bufsize < mss)
			mss = bufsize;
		else {
			bufsize = roundup(bufsize, mss);
			if (bufsize > sb_max)
				bufsize = sb_max;
			(void)sbreserve(&so->so_snd, bufsize);
		}
		tp->t_maxseg = mss;
d1897 1
a1897 1
		if ((bufsize = rt->rt_rmx.rmx_recvpipe) == 0)
d1899 6
a1904 7
			bufsize = so->so_rcv.sb_hiwat;
		if (bufsize > mss) {
			bufsize = roundup(bufsize, mss);
			if (bufsize > sb_max)
				bufsize = sb_max;
			(void)sbreserve(&so->so_rcv, bufsize);
		}
@


1.18
log
@Add FreeBSD patch (check for SYN packets arriving at a socket in
LISTEN state with source address/port == destination address/port).
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.17 1997/11/12 20:59:44 deraadt Exp $	*/
d158 2
a159 1
tck_makecookie(struct in_addr f)
d179 2
a180 1
tck_chkcookie(struct tcpiphdr *ti)
d186 2
a187 1
	if (tck_makecookie(ti->ti_src) == ti->ti_seq) { /* seq in host order */
d776 3
a778 3
		if (!tck_isafriend(ti->ti_src))
		{
			u_long acookie;
d784 1
a784 1
			  (void) soabort(so);
@


1.17
log
@correct RST validity checking; fc@@parkone.ci.oakland.ca.us
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.15 1997/08/26 20:02:32 deraadt Exp $	*/
d743 1
d763 3
d843 18
d1133 3
a1135 3
	 * In SYN_RECEIVED state if the ack ACKs our SYN then enter
	 * ESTABLISHED state and continue processing, otherwise
	 * send an RST.
a1137 3
		if (SEQ_GT(tp->snd_una, ti->ti_ack) ||
		    SEQ_GT(ti->ti_ack, tp->snd_max))
			goto dropwithreset;
@


1.16
log
@indent
@
text
@d1062 3
a1064 3
		if ((ti->ti_seq != tp->rcv_nxt) ||
		    (ti->ti_ack && ((SEQ_LEQ(ti->ti_ack, tp->iss) ||
		    SEQ_GT(ti->ti_ack, tp->snd_max)))))
@


1.15
log
@indent
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.14 1997/08/16 01:34:41 angelos Exp $	*/
d160 1
a160 1
        static MD5_CTX ctx;
d163 7
a169 9
	
	if (tck_initialized == 0)	/* This only happens once per reboot */
	{
	    tck_initialized = 1;
	    
	    get_random_bytes((void *) buf, 16);
	    
	    MD5Init(&ctx);
	    MD5Update(&ctx, buf, 16);
a170 1

a173 1
	
d184 1
a184 2
	if (tck_makecookie(ti->ti_src) == ti->ti_seq) /* seq in host order */
	{
d188 1
a188 2
	else
	  return 0;
d367 1
a367 1
	if (inp)                                                /* XXX */
d380 1
a380 1
	if (inp)                                                /* XXX */
d1060 1
a1060 1
	if (tiflags&TH_RST) {
d1064 1
a1064 1
		      SEQ_GT(ti->ti_ack, tp->snd_max)))))
d1193 1
a1193 1
					       tp->t_maxseg * tp->t_dupacks;
@


1.14
log
@Just some more debugging info.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.13 1997/08/09 01:26:00 angelos Exp $	*/
d1309 1
a1309 1
	 	/*
d1464 1
a1464 1
	 	/*
d1471 1
a1471 1
	 	/*
d1479 1
a1479 1
	 	/*
@


1.13
log
@SYN flood protection, by specifying
option TCPCOOKIE
in the kernel config file. For very busy servers, consider raising
the TCK_NFRIENDS value (it's currenly set to 16).

Code originally from Matt Blaze and John Ioannidis.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.12 1997/07/06 08:04:10 deraadt Exp $	*/
d118 1
a118 1
	for (i = n+1; i < tck_nfriends ; i++)
d185 1
a185 1
	printf("tck_chkcookie: src = 0x%08x, cookie = 0x%08x, ack = 0x%08x\n", ntohl(ti->ti_src.s_addr), tck_makecookie(ti->ti_src), ti->ti_ack);
@


1.12
log
@unsigned calc should be signed; jdp@@polstra.com; freebsd pr#3998
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.11 1997/06/10 19:46:41 deraadt Exp $	*/
a64 1

d66 1
d81 117
d514 12
d768 20
@


1.11
log
@ensure RST is within window; avalon@@coombs.anu.edu.au
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.10 1997/05/12 18:00:29 deraadt Exp $	*/
d611 1
a611 1
	tp->rcv_wnd = max(win, (int)(tp->rcv_adv - tp->rcv_nxt));
@


1.10
log
@argh
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.9 1997/02/05 15:48:24 deraadt Exp $	*/
d917 1
a917 1
	if (tiflags&TH_RST) switch (tp->t_state) {
d919 4
a922 14
	case TCPS_SYN_RECEIVED:
		so->so_error = ECONNREFUSED;
		goto close;

	case TCPS_ESTABLISHED:
	case TCPS_FIN_WAIT_1:
	case TCPS_FIN_WAIT_2:
	case TCPS_CLOSE_WAIT:
		so->so_error = ECONNRESET;
	close:
		tp->t_state = TCPS_CLOSED;
		tcpstat.tcps_drops++;
		tp = tcp_close(tp);
		goto drop;
d924 21
a944 5
	case TCPS_CLOSING:
	case TCPS_LAST_ACK:
	case TCPS_TIME_WAIT:
		tp = tcp_close(tp);
		goto drop;
@


1.9
log
@use arc4random()
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.8 1996/09/25 11:39:56 niklas Exp $	*/
d274 4
a277 2
		    tp->t_state == TCPS_SYN_RECEIVED)
			break;
@


1.8
log
@Drop unused variable
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.7 1996/09/20 22:53:11 deraadt Exp $	*/
d64 1
d680 1
a680 1
		tcp_iss += random() % (TCP_ISSINCR / 2) + 1;
@


1.7
log
@`solve' the syn bomb problem as well as currently known; add sysctl's for
SOMAXCONN (kern.somaxconn), SOMINCONN (kern.sominconn), and TCPTV_KEEP_INIT
(net.inet.tcp.keepinittime). when this is not enough (ie. overfull), start
doing tail drop, but slightly prefer the same port.
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.6 1996/08/07 06:36:26 tholo Exp $	*/
d249 1
a249 1
	register struct tcpcb *tp, *droptp = NULL;
@


1.6
log
@Partial protection from TCP SYN attacks
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.5 1996/07/29 22:01:50 niklas Exp $	*/
d69 1
d236 45
d435 10
a444 3
			so = sonewconn(so, 0);
			if (so == 0)
				goto drop;
d686 1
a686 1
		tp->t_timer[TCPT_KEEP] = TCPTV_KEEP_INIT;
@


1.5
log
@Remove random() prototype, as it's not needed.  Besides it was wrong for the alpha :-)
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.4 1996/07/29 06:22:12 tholo Exp $	*/
d427 2
a428 1
	tp->t_timer[TCPT_KEEP] = tcp_keepidle;
@


1.4
log
@Make TCP ISS increment by random amounts
@
text
@d1 1
a1 1
/*	$OpenBSD: tcp_input.c,v 1.3 1996/03/03 22:30:45 niklas Exp $	*/
a245 3
#ifndef TCP_COMPAT_42
	u_int random __P((void));
#endif /* !TCP_COMPAT_42 */
@


1.3
log
@From NetBSD: 960217 merge
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d246 3
d625 1
d627 3
@


1.2
log
@from netbsd:
make netinet work on systems where pointers and longs are 64 bits
(like the alpha).  Biggest problem: IP headers were overlayed with
structure which included pointers, and which therefore didn't overlay
properly on 64-bit machines.  Solution: instead of threading pointers
through IP header overlays, add a "queue element" structure to do
the threading, and point it at the ip headers.
@
text
@d1 2
a2 1
/*	$NetBSD: tcp_input.c,v 1.20 1995/11/21 01:07:39 cgd Exp $	*/
d65 2
a68 1
struct	inpcb *tcp_last_inpcb = 0;
d239 4
a242 1
tcp_input(m, iphlen)
d244 1
a244 1
	int iphlen;
d249 1
a249 1
	int optlen;
d253 1
a253 1
	struct socket *so;
d255 1
a255 1
	short ostate;
d262 6
d293 1
a293 1
	if (ti->ti_sum = in_cksum(m, len)) {
d352 4
a355 7
	inp = tcp_last_inpcb;
	if (inp == 0 ||
	    inp->inp_lport != ti->ti_dport ||
	    inp->inp_fport != ti->ti_sport ||
	    inp->inp_faddr.s_addr != ti->ti_src.s_addr ||
	    inp->inp_laddr.s_addr != ti->ti_dst.s_addr) {
		++tcpstat.tcps_pcbcachemiss;
d364 2
a365 1
		if (inp == 0)
d367 1
a367 1
		tcp_last_inpcb = inp;
d407 1
d1137 3
a1139 4
	if ((tiflags & TH_ACK) &&
	    (SEQ_LT(tp->snd_wl1, ti->ti_seq) || tp->snd_wl1 == ti->ti_seq &&
	    (SEQ_LT(tp->snd_wl2, ti->ti_ack) ||
	     tp->snd_wl2 == ti->ti_ack && tiwin > tp->snd_wnd))) {
d1197 1
a1197 1
		if (ti->ti_urp <= ti->ti_len
d1221 1
a1221 1
	if ((ti->ti_len || (tiflags&TH_FIN)) &&
d1237 2
a1238 1
	 * that the connection is closing.
d1240 1
a1240 1
	if (tiflags & TH_FIN) {
d1249 1
a1249 2
		 * In SYN_RECEIVED and ESTABLISHED STATES
		 * enter the CLOSE_WAIT state.
a1250 1
		case TCPS_SYN_RECEIVED:
d1586 1
a1586 1
		TCPT_RANGESET(tp->t_rxtcur,
@


1.1
log
@Initial revision
@
text
@d1 1
a1 1
/*	$NetBSD: tcp_input.c,v 1.19 1995/08/04 01:12:23 mycroft Exp $	*/
d90 1
a90 1
	    (tp)->seg_next == (struct tcpiphdr *)(tp) && \
d115 1
a115 1
	register struct tcpiphdr *q;
d127 11
d140 3
a142 3
	for (q = tp->seg_next; q != (struct tcpiphdr *)tp;
	    q = (struct tcpiphdr *)q->ti_next)
		if (SEQ_GT(q->ti_seq, ti->ti_seq))
d150 2
a151 1
	if ((struct tcpiphdr *)q->ti_prev != (struct tcpiphdr *)tp) {
d153 1
a153 1
		q = (struct tcpiphdr *)q->ti_prev;
d155 1
a155 1
		i = q->ti_seq + q->ti_len - ti->ti_seq;
d161 1
a167 1
		q = (struct tcpiphdr *)(q->ti_next);
a170 1
	REASS_MBUF(ti) = m;		/* XXX */
d176 4
a179 2
	while (q != (struct tcpiphdr *)tp) {
		register int i = (ti->ti_seq + ti->ti_len) - q->ti_seq;
d182 4
a185 4
		if (i < q->ti_len) {
			q->ti_seq += i;
			q->ti_len -= i;
			m_adj(REASS_MBUF(q), i);
d188 4
a191 4
		q = (struct tcpiphdr *)q->ti_next;
		m = REASS_MBUF((struct tcpiphdr *)q->ti_prev);
		remque(q->ti_prev);
		m_freem(m);
d194 8
a201 4
	/*
	 * Stick new segment in its place.
	 */
	insque(ti, q->ti_prev);
d210 2
a211 2
	ti = tp->seg_next;
	if (ti == (struct tcpiphdr *)tp || ti->ti_seq != tp->rcv_nxt)
d213 1
a213 1
	if (tp->t_state == TCPS_SYN_RECEIVED && ti->ti_len)
d216 5
a220 5
		tp->rcv_nxt += ti->ti_len;
		flags = ti->ti_flags & TH_FIN;
		remque(ti);
		m = REASS_MBUF(ti);
		ti = (struct tcpiphdr *)ti->ti_next;
d222 1
a222 1
			m_freem(m);
d224 4
a227 2
			sbappend(&so->so_rcv, m);
	} while (ti != (struct tcpiphdr *)tp && ti->ti_seq == tp->rcv_nxt);
d279 1
a279 2
	ti->ti_next = ti->ti_prev = 0;
	ti->ti_x1 = 0;
d500 1
a500 1
		    tp->seg_next == (struct tcpiphdr *)tp &&
@


1.1.1.1
log
@initial import of NetBSD tree
@
text
@@

