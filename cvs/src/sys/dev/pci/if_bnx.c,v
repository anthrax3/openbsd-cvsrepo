head	1.124;
access;
symbols
	OPENBSD_6_1:1.124.0.2
	OPENBSD_6_1_BASE:1.124
	OPENBSD_6_0:1.122.0.4
	OPENBSD_6_0_BASE:1.122
	OPENBSD_5_9:1.120.0.2
	OPENBSD_5_9_BASE:1.120
	OPENBSD_5_8:1.112.0.4
	OPENBSD_5_8_BASE:1.112
	OPENBSD_5_7:1.109.0.4
	OPENBSD_5_7_BASE:1.109
	OPENBSD_5_6:1.107.0.4
	OPENBSD_5_6_BASE:1.107
	OPENBSD_5_5:1.103.0.4
	OPENBSD_5_5_BASE:1.103
	OPENBSD_5_4:1.101.0.2
	OPENBSD_5_4_BASE:1.101
	OPENBSD_5_3:1.100.0.2
	OPENBSD_5_3_BASE:1.100
	OPENBSD_5_2:1.97.0.2
	OPENBSD_5_2_BASE:1.97
	OPENBSD_5_1_BASE:1.95
	OPENBSD_5_1:1.95.0.4
	OPENBSD_5_0:1.95.0.2
	OPENBSD_5_0_BASE:1.95
	OPENBSD_4_9:1.90.0.2
	OPENBSD_4_9_BASE:1.90
	OPENBSD_4_8:1.89.0.2
	OPENBSD_4_8_BASE:1.89
	OPENBSD_4_7:1.86.0.2
	OPENBSD_4_7_BASE:1.86
	OPENBSD_4_6:1.81.0.4
	OPENBSD_4_6_BASE:1.81
	OPENBSD_4_5:1.71.0.2
	OPENBSD_4_5_BASE:1.71
	OPENBSD_4_4:1.64.0.2
	OPENBSD_4_4_BASE:1.64
	OPENBSD_4_3:1.58.0.2
	OPENBSD_4_3_BASE:1.58
	OPENBSD_4_2:1.53.0.2
	OPENBSD_4_2_BASE:1.53
	OPENBSD_4_1:1.48.0.2
	OPENBSD_4_1_BASE:1.48
	OPENBSD_4_0:1.23.0.2
	OPENBSD_4_0_BASE:1.23;
locks; strict;
comment	@ * @;


1.124
date	2017.01.24.03.57.35;	author dlg;	state Exp;
branches;
next	1.123;
commitid	PERtGPXCvlLRRBr8;

1.123
date	2017.01.22.10.17.38;	author dlg;	state Exp;
branches;
next	1.122;
commitid	VyLWTsbepAOk7VQM;

1.122
date	2016.05.05.23.01.28;	author jmatthew;	state Exp;
branches;
next	1.121;
commitid	PR1HuEwGAcQSKywi;

1.121
date	2016.04.13.10.34.32;	author mpi;	state Exp;
branches;
next	1.120;
commitid	8YSL8ByWzGeIGBiJ;

1.120
date	2015.12.11.16.07.01;	author mpi;	state Exp;
branches
	1.120.2.1;
next	1.119;
commitid	fbhqfhfdKxBcsetK;

1.119
date	2015.12.10.12.24.27;	author dlg;	state Exp;
branches;
next	1.118;
commitid	7qe8kq5mOqtUe5tZ;

1.118
date	2015.12.05.16.23.37;	author jmatthew;	state Exp;
branches;
next	1.117;
commitid	mcoyezmlcJRZ8L4g;

1.117
date	2015.11.25.03.09.59;	author dlg;	state Exp;
branches;
next	1.116;
commitid	B0kwmVGiD5DVx4kv;

1.116
date	2015.11.20.03.35.23;	author dlg;	state Exp;
branches;
next	1.115;
commitid	eYnPulzvLjDImPCa;

1.115
date	2015.10.25.13.04.28;	author mpi;	state Exp;
branches;
next	1.114;
commitid	hPF95ClMUQfeqQDX;

1.114
date	2015.09.10.18.10.34;	author deraadt;	state Exp;
branches;
next	1.113;
commitid	pbNNrPaFfPV40pxN;

1.113
date	2015.09.04.21.43.10;	author kettenis;	state Exp;
branches;
next	1.112;
commitid	m6XE8Rr3MaMUBwnM;

1.112
date	2015.07.24.01.19.18;	author dlg;	state Exp;
branches;
next	1.111;
commitid	cjAWF3nxEg0ja6xV;

1.111
date	2015.06.24.09.40.54;	author mpi;	state Exp;
branches;
next	1.110;
commitid	MVWrtktB46JRxFWT;

1.110
date	2015.03.10.15.28.48;	author mpi;	state Exp;
branches;
next	1.109;
commitid	jCNgp5RmnPnv64qi;

1.109
date	2015.01.27.03.17.36;	author dlg;	state Exp;
branches;
next	1.108;
commitid	MyKPm9Q3dQu92BiX;

1.108
date	2014.12.22.02.28.51;	author tedu;	state Exp;
branches;
next	1.107;
commitid	yM2VFFhpDTeFQlve;

1.107
date	2014.07.18.07.11.04;	author dlg;	state Exp;
branches;
next	1.106;
commitid	7glHgy6gM5e0eKrK;

1.106
date	2014.07.12.18.48.51;	author tedu;	state Exp;
branches;
next	1.105;
commitid	OBNa5kfxQ2UXoiIw;

1.105
date	2014.07.09.00.13.05;	author dlg;	state Exp;
branches;
next	1.104;
commitid	rtjRvgSEAsY5cyVb;

1.104
date	2014.07.08.05.35.18;	author dlg;	state Exp;
branches;
next	1.103;
commitid	0QJleeeWqZmC5anF;

1.103
date	2013.10.30.04.08.07;	author dlg;	state Exp;
branches;
next	1.102;

1.102
date	2013.10.23.20.22.12;	author brad;	state Exp;
branches;
next	1.101;

1.101
date	2013.03.28.17.21.44;	author brad;	state Exp;
branches;
next	1.100;

1.100
date	2013.01.13.05.45.10;	author brad;	state Exp;
branches;
next	1.99;

1.99
date	2012.12.10.10.38.56;	author mikeb;	state Exp;
branches;
next	1.98;

1.98
date	2012.12.05.23.20.20;	author deraadt;	state Exp;
branches;
next	1.97;

1.97
date	2012.07.05.13.50.15;	author phessler;	state Exp;
branches;
next	1.96;

1.96
date	2012.05.14.14.17.30;	author mikeb;	state Exp;
branches;
next	1.95;

1.95
date	2011.06.22.16.44.27;	author tedu;	state Exp;
branches;
next	1.94;

1.94
date	2011.04.18.04.27.31;	author dlg;	state Exp;
branches;
next	1.93;

1.93
date	2011.04.13.07.28.35;	author dlg;	state Exp;
branches;
next	1.92;

1.92
date	2011.04.05.18.01.21;	author henning;	state Exp;
branches;
next	1.91;

1.91
date	2011.04.03.15.36.02;	author jasper;	state Exp;
branches;
next	1.90;

1.90
date	2010.09.20.07.40.38;	author deraadt;	state Exp;
branches;
next	1.89;

1.89
date	2010.08.03.16.11.57;	author jsg;	state Exp;
branches;
next	1.88;

1.88
date	2010.05.24.21.23.23;	author sthen;	state Exp;
branches;
next	1.87;

1.87
date	2010.05.19.15.27.35;	author oga;	state Exp;
branches;
next	1.86;

1.86
date	2009.11.23.10.54.43;	author claudio;	state Exp;
branches;
next	1.85;

1.85
date	2009.11.09.14.32.41;	author dlg;	state Exp;
branches;
next	1.84;

1.84
date	2009.08.13.14.24.47;	author jasper;	state Exp;
branches;
next	1.83;

1.83
date	2009.08.09.11.40.56;	author deraadt;	state Exp;
branches;
next	1.82;

1.82
date	2009.08.06.19.53.13;	author sthen;	state Exp;
branches;
next	1.81;

1.81
date	2009.07.03.04.54.05;	author dlg;	state Exp;
branches;
next	1.80;

1.80
date	2009.07.03.04.34.51;	author dlg;	state Exp;
branches;
next	1.79;

1.79
date	2009.06.20.15.42.28;	author naddy;	state Exp;
branches;
next	1.78;

1.78
date	2009.04.22.01.17.26;	author dlg;	state Exp;
branches;
next	1.77;

1.77
date	2009.04.22.00.38.04;	author dlg;	state Exp;
branches;
next	1.76;

1.76
date	2009.04.20.12.24.52;	author dlg;	state Exp;
branches;
next	1.75;

1.75
date	2009.04.20.11.39.02;	author reyk;	state Exp;
branches;
next	1.74;

1.74
date	2009.04.14.07.41.24;	author kettenis;	state Exp;
branches;
next	1.73;

1.73
date	2009.04.09.11.36.05;	author dlg;	state Exp;
branches;
next	1.72;

1.72
date	2009.03.30.02.38.53;	author dlg;	state Exp;
branches;
next	1.71;

1.71
date	2008.11.28.02.44.17;	author brad;	state Exp;
branches;
next	1.70;

1.70
date	2008.11.09.15.08.26;	author naddy;	state Exp;
branches;
next	1.69;

1.69
date	2008.10.19.23.16.38;	author brad;	state Exp;
branches;
next	1.68;

1.68
date	2008.10.16.19.18.03;	author naddy;	state Exp;
branches;
next	1.67;

1.67
date	2008.10.16.19.16.21;	author naddy;	state Exp;
branches;
next	1.66;

1.66
date	2008.10.02.20.21.14;	author brad;	state Exp;
branches;
next	1.65;

1.65
date	2008.09.10.14.01.22;	author blambert;	state Exp;
branches;
next	1.64;

1.64
date	2008.06.24.23.02.42;	author brad;	state Exp;
branches;
next	1.63;

1.63
date	2008.06.13.21.40.21;	author brad;	state Exp;
branches;
next	1.62;

1.62
date	2008.06.13.07.40.30;	author brad;	state Exp;
branches;
next	1.61;

1.61
date	2008.06.08.16.20.27;	author reyk;	state Exp;
branches;
next	1.60;

1.60
date	2008.05.29.05.36.48;	author brad;	state Exp;
branches;
next	1.59;

1.59
date	2008.05.23.08.49.27;	author brad;	state Exp;
branches;
next	1.58;

1.58
date	2008.02.28.02.02.43;	author brad;	state Exp;
branches;
next	1.57;

1.57
date	2008.02.22.22.25.27;	author kettenis;	state Exp;
branches;
next	1.56;

1.56
date	2008.02.17.19.34.40;	author brad;	state Exp;
branches;
next	1.55;

1.55
date	2007.11.25.19.16.00;	author dlg;	state Exp;
branches;
next	1.54;

1.54
date	2007.08.28.18.34.38;	author deraadt;	state Exp;
branches;
next	1.53;

1.53
date	2007.07.04.00.20.22;	author krw;	state Exp;
branches;
next	1.52;

1.52
date	2007.05.22.22.08.57;	author reyk;	state Exp;
branches;
next	1.51;

1.51
date	2007.05.22.16.51.34;	author jasper;	state Exp;
branches;
next	1.50;

1.50
date	2007.05.22.04.22.57;	author ray;	state Exp;
branches;
next	1.49;

1.49
date	2007.05.21.10.05.03;	author reyk;	state Exp;
branches;
next	1.48;

1.48
date	2007.03.05.11.13.09;	author reyk;	state Exp;
branches;
next	1.47;

1.47
date	2007.03.03.11.17.48;	author reyk;	state Exp;
branches;
next	1.46;

1.46
date	2007.03.03.03.46.12;	author todd;	state Exp;
branches;
next	1.45;

1.45
date	2007.03.02.14.08.48;	author reyk;	state Exp;
branches;
next	1.44;

1.44
date	2007.03.02.13.49.50;	author reyk;	state Exp;
branches;
next	1.43;

1.43
date	2007.01.30.03.21.10;	author krw;	state Exp;
branches;
next	1.42;

1.42
date	2007.01.27.12.38.59;	author krw;	state Exp;
branches;
next	1.41;

1.41
date	2007.01.21.01.08.03;	author mcbride;	state Exp;
branches;
next	1.40;

1.40
date	2007.01.20.00.36.07;	author dlg;	state Exp;
branches;
next	1.39;

1.39
date	2007.01.19.18.35.50;	author mcbride;	state Exp;
branches;
next	1.38;

1.38
date	2007.01.10.18.09.26;	author deraadt;	state Exp;
branches;
next	1.37;

1.37
date	2006.12.24.12.54.13;	author reyk;	state Exp;
branches;
next	1.36;

1.36
date	2006.11.26.15.12.24;	author brad;	state Exp;
branches;
next	1.35;

1.35
date	2006.11.20.21.52.15;	author brad;	state Exp;
branches;
next	1.34;

1.34
date	2006.11.20.21.26.27;	author brad;	state Exp;
branches;
next	1.33;

1.33
date	2006.11.19.17.35.46;	author brad;	state Exp;
branches;
next	1.32;

1.32
date	2006.10.26.00.05.07;	author brad;	state Exp;
branches;
next	1.31;

1.31
date	2006.10.25.02.37.50;	author brad;	state Exp;
branches;
next	1.30;

1.30
date	2006.10.22.20.27.41;	author brad;	state Exp;
branches;
next	1.29;

1.29
date	2006.10.21.23.45.51;	author deraadt;	state Exp;
branches;
next	1.28;

1.28
date	2006.10.21.22.18.39;	author brad;	state Exp;
branches;
next	1.27;

1.27
date	2006.10.19.20.52.29;	author brad;	state Exp;
branches;
next	1.26;

1.26
date	2006.10.19.20.36.20;	author brad;	state Exp;
branches;
next	1.25;

1.25
date	2006.10.14.21.19.09;	author brad;	state Exp;
branches;
next	1.24;

1.24
date	2006.10.04.00.23.04;	author deraadt;	state Exp;
branches;
next	1.23;

1.23
date	2006.08.25.02.13.51;	author brad;	state Exp;
branches;
next	1.22;

1.22
date	2006.08.21.17.02.03;	author deraadt;	state Exp;
branches;
next	1.21;

1.21
date	2006.08.21.03.32.11;	author brad;	state Exp;
branches;
next	1.20;

1.20
date	2006.08.21.03.22.09;	author brad;	state Exp;
branches;
next	1.19;

1.19
date	2006.08.20.21.47.19;	author brad;	state Exp;
branches;
next	1.18;

1.18
date	2006.08.20.08.36.33;	author brad;	state Exp;
branches;
next	1.17;

1.17
date	2006.08.20.06.22.25;	author brad;	state Exp;
branches;
next	1.16;

1.16
date	2006.08.19.04.01.02;	author brad;	state Exp;
branches;
next	1.15;

1.15
date	2006.08.14.20.45.00;	author marco;	state Exp;
branches;
next	1.14;

1.14
date	2006.08.14.19.10.23;	author marco;	state Exp;
branches;
next	1.13;

1.13
date	2006.08.14.18.07.46;	author marco;	state Exp;
branches;
next	1.12;

1.12
date	2006.08.14.17.26.35;	author marco;	state Exp;
branches;
next	1.11;

1.11
date	2006.08.14.16.58.56;	author brad;	state Exp;
branches;
next	1.10;

1.10
date	2006.08.14.16.07.39;	author marco;	state Exp;
branches;
next	1.9;

1.9
date	2006.08.13.19.29.46;	author marco;	state Exp;
branches;
next	1.8;

1.8
date	2006.08.13.06.39.58;	author brad;	state Exp;
branches;
next	1.7;

1.7
date	2006.08.10.04.25.15;	author brad;	state Exp;
branches;
next	1.6;

1.6
date	2006.08.10.04.13.09;	author brad;	state Exp;
branches;
next	1.5;

1.5
date	2006.08.10.04.01.52;	author brad;	state Exp;
branches;
next	1.4;

1.4
date	2006.08.09.15.49.49;	author marco;	state Exp;
branches;
next	1.3;

1.3
date	2006.06.26.05.52.04;	author brad;	state Exp;
branches;
next	1.2;

1.2
date	2006.06.26.05.37.05;	author brad;	state Exp;
branches;
next	1.1;

1.1
date	2006.06.26.04.57.54;	author brad;	state Exp;
branches;
next	;

1.120.2.1
date	2016.05.06.03.26.38;	author jmatthew;	state Exp;
branches;
next	;
commitid	1wIQ2VPv3upowRuW;


desc
@@


1.124
log
@add support for multiple transmit ifqueues per network interface.

an ifq to transmit a packet is picked by the current traffic
conditioner (ie, priq or hfsc) by providing an index into an array
of ifqs. by default interfaces get a single ifq but can ask for
more using if_attach_queues().

the vast majority of our drivers still think there's a 1:1 mapping
between interfaces and transmit queues, so their if_start routines
take an ifnet pointer instead of a pointer to the ifqueue struct.
instead of changing all the drivers in the tree, drivers can opt
into using an if_qstart routine and setting the IFXF_MPSAFE flag.
the stack provides a compatability wrapper from the new if_qstart
handler to the previous if_start handlers if IFXF_MPSAFE isnt set.

enabling hfsc on an interface configures it to transmit everything
through the first ifq. any other ifqs are left configured as priq,
but unused, when hfsc is enabled.

getting this in now so everyone can kick the tyres.

ok mpi@@ visa@@ (who provided some tweaks for cnmac).
@
text
@/*	$OpenBSD: if_bnx.c,v 1.123 2017/01/22 10:17:38 dlg Exp $	*/

/*-
 * Copyright (c) 2006 Broadcom Corporation
 *	David Christensen <davidch@@broadcom.com>.  All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 *
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. Neither the name of Broadcom Corporation nor the name of its contributors
 *    may be used to endorse or promote products derived from this software
 *    without specific prior written consent.
 *
 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS'
 * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS
 * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
 * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
 * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
 * THE POSSIBILITY OF SUCH DAMAGE.
 */

/*
 * The following controllers are supported by this driver:
 *   BCM5706C A2, A3
 *   BCM5706S A2, A3
 *   BCM5708C B1, B2
 *   BCM5708S B1, B2
 *   BCM5709C A1, C0
 *   BCM5709S A1, C0
 *   BCM5716  C0
 *
 * The following controllers are not supported by this driver:
 *   BCM5706C A0, A1
 *   BCM5706S A0, A1
 *   BCM5708C A0, B0
 *   BCM5708S A0, B0
 *   BCM5709C A0  B0, B1, B2 (pre-production)
 *   BCM5709S A0, B0, B1, B2 (pre-production)
 */

#include <dev/pci/if_bnxreg.h>

struct bnx_firmware {
	char *filename;
	struct bnx_firmware_header *fw;

	u_int32_t *bnx_COM_FwText;
	u_int32_t *bnx_COM_FwData;
	u_int32_t *bnx_COM_FwRodata;
	u_int32_t *bnx_COM_FwBss;
	u_int32_t *bnx_COM_FwSbss;

	u_int32_t *bnx_RXP_FwText;
	u_int32_t *bnx_RXP_FwData;
	u_int32_t *bnx_RXP_FwRodata;
	u_int32_t *bnx_RXP_FwBss;
	u_int32_t *bnx_RXP_FwSbss;

	u_int32_t *bnx_TPAT_FwText;
	u_int32_t *bnx_TPAT_FwData;
	u_int32_t *bnx_TPAT_FwRodata;
	u_int32_t *bnx_TPAT_FwBss;
	u_int32_t *bnx_TPAT_FwSbss;

	u_int32_t *bnx_TXP_FwText;
	u_int32_t *bnx_TXP_FwData;
	u_int32_t *bnx_TXP_FwRodata;
	u_int32_t *bnx_TXP_FwBss;
	u_int32_t *bnx_TXP_FwSbss;
};

struct bnx_firmware bnx_firmwares[] = {
	{ "bnx-b06",		NULL },
	{ "bnx-b09",		NULL }
};
#define	BNX_FW_B06	0
#define	BNX_FW_B09	1

struct bnx_rv2p {
	char *filename;
	struct bnx_rv2p_header *fw;

	u_int32_t *bnx_rv2p_proc1;
	u_int32_t *bnx_rv2p_proc2;
};

struct bnx_rv2p bnx_rv2ps[] = {
	{ "bnx-rv2p",		NULL },
	{ "bnx-xi-rv2p",	NULL },
	{ "bnx-xi90-rv2p",	NULL }
};
#define BNX_RV2P	0
#define BNX_XI_RV2P	1
#define BNX_XI90_RV2P	2

void	nswaph(u_int32_t *p, int wcount);

/****************************************************************************/
/* BNX Driver Version                                                       */
/****************************************************************************/

#define BNX_DRIVER_VERSION	"v0.9.6"

/****************************************************************************/
/* BNX Debug Options                                                        */
/****************************************************************************/
#ifdef BNX_DEBUG
	u_int32_t bnx_debug = BNX_WARN;

	/*          0 = Never              */
	/*          1 = 1 in 2,147,483,648 */
	/*        256 = 1 in     8,388,608 */
	/*       2048 = 1 in     1,048,576 */
	/*      65536 = 1 in        32,768 */
	/*    1048576 = 1 in         2,048 */
	/*  268435456 =	1 in             8 */
	/*  536870912 = 1 in             4 */
	/* 1073741824 = 1 in             2 */

	/* Controls how often the l2_fhdr frame error check will fail. */
	int bnx_debug_l2fhdr_status_check = 0;

	/* Controls how often the unexpected attention check will fail. */
	int bnx_debug_unexpected_attention = 0;

	/* Controls how often to simulate an mbuf allocation failure. */
	int bnx_debug_mbuf_allocation_failure = 0;

	/* Controls how often to simulate a DMA mapping failure. */
	int bnx_debug_dma_map_addr_failure = 0;

	/* Controls how often to simulate a bootcode failure. */
	int bnx_debug_bootcode_running_failure = 0;
#endif

/****************************************************************************/
/* PCI Device ID Table                                                      */
/*                                                                          */
/* Used by bnx_probe() to identify the devices supported by this driver.    */
/****************************************************************************/
const struct pci_matchid bnx_devices[] = {
	{ PCI_VENDOR_BROADCOM, PCI_PRODUCT_BROADCOM_BCM5706 },
	{ PCI_VENDOR_BROADCOM, PCI_PRODUCT_BROADCOM_BCM5706S },
	{ PCI_VENDOR_BROADCOM, PCI_PRODUCT_BROADCOM_BCM5708 },
	{ PCI_VENDOR_BROADCOM, PCI_PRODUCT_BROADCOM_BCM5708S },
	{ PCI_VENDOR_BROADCOM, PCI_PRODUCT_BROADCOM_BCM5709 },
	{ PCI_VENDOR_BROADCOM, PCI_PRODUCT_BROADCOM_BCM5709S },
	{ PCI_VENDOR_BROADCOM, PCI_PRODUCT_BROADCOM_BCM5716 },
	{ PCI_VENDOR_BROADCOM, PCI_PRODUCT_BROADCOM_BCM5716S }
};

/****************************************************************************/
/* Supported Flash NVRAM device data.                                       */
/****************************************************************************/
static struct flash_spec flash_table[] =
{
#define BUFFERED_FLAGS		(BNX_NV_BUFFERED | BNX_NV_TRANSLATE)
#define NONBUFFERED_FLAGS	(BNX_NV_WREN)

	/* Slow EEPROM */
	{0x00000000, 0x40830380, 0x009f0081, 0xa184a053, 0xaf000400,
	 BUFFERED_FLAGS, SEEPROM_PAGE_BITS, SEEPROM_PAGE_SIZE,
	 SEEPROM_BYTE_ADDR_MASK, SEEPROM_TOTAL_SIZE,
	 "EEPROM - slow"},
	/* Expansion entry 0001 */
	{0x08000002, 0x4b808201, 0x00050081, 0x03840253, 0xaf020406,
	 NONBUFFERED_FLAGS, SAIFUN_FLASH_PAGE_BITS, SAIFUN_FLASH_PAGE_SIZE,
	 SAIFUN_FLASH_BYTE_ADDR_MASK, 0,
	 "Entry 0001"},
	/* Saifun SA25F010 (non-buffered flash) */
	/* strap, cfg1, & write1 need updates */
	{0x04000001, 0x47808201, 0x00050081, 0x03840253, 0xaf020406,
	 0, SAIFUN_FLASH_PAGE_BITS, SAIFUN_FLASH_PAGE_SIZE,
	 SAIFUN_FLASH_BYTE_ADDR_MASK, SAIFUN_FLASH_BASE_TOTAL_SIZE*2,
	 "Non-buffered flash (128kB)"},
	/* Saifun SA25F020 (non-buffered flash) */
	/* strap, cfg1, & write1 need updates */
	{0x0c000003, 0x4f808201, 0x00050081, 0x03840253, 0xaf020406,
	 NONBUFFERED_FLAGS, SAIFUN_FLASH_PAGE_BITS, SAIFUN_FLASH_PAGE_SIZE,
	 SAIFUN_FLASH_BYTE_ADDR_MASK, SAIFUN_FLASH_BASE_TOTAL_SIZE*4,
	 "Non-buffered flash (256kB)"},
	/* Expansion entry 0100 */
	{0x11000000, 0x53808201, 0x00050081, 0x03840253, 0xaf020406,
	 NONBUFFERED_FLAGS, SAIFUN_FLASH_PAGE_BITS, SAIFUN_FLASH_PAGE_SIZE,
	 SAIFUN_FLASH_BYTE_ADDR_MASK, 0,
	 "Entry 0100"},
	/* Entry 0101: ST M45PE10 (non-buffered flash, TetonII B0) */
	{0x19000002, 0x5b808201, 0x000500db, 0x03840253, 0xaf020406,
	 NONBUFFERED_FLAGS, ST_MICRO_FLASH_PAGE_BITS, ST_MICRO_FLASH_PAGE_SIZE,
	 ST_MICRO_FLASH_BYTE_ADDR_MASK, ST_MICRO_FLASH_BASE_TOTAL_SIZE*2,
	 "Entry 0101: ST M45PE10 (128kB non-bufferred)"},
	/* Entry 0110: ST M45PE20 (non-buffered flash)*/
	{0x15000001, 0x57808201, 0x000500db, 0x03840253, 0xaf020406,
	 NONBUFFERED_FLAGS, ST_MICRO_FLASH_PAGE_BITS, ST_MICRO_FLASH_PAGE_SIZE,
	 ST_MICRO_FLASH_BYTE_ADDR_MASK, ST_MICRO_FLASH_BASE_TOTAL_SIZE*4,
	 "Entry 0110: ST M45PE20 (256kB non-bufferred)"},
	/* Saifun SA25F005 (non-buffered flash) */
	/* strap, cfg1, & write1 need updates */
	{0x1d000003, 0x5f808201, 0x00050081, 0x03840253, 0xaf020406,
	 NONBUFFERED_FLAGS, SAIFUN_FLASH_PAGE_BITS, SAIFUN_FLASH_PAGE_SIZE,
	 SAIFUN_FLASH_BYTE_ADDR_MASK, SAIFUN_FLASH_BASE_TOTAL_SIZE,
	 "Non-buffered flash (64kB)"},
	/* Fast EEPROM */
	{0x22000000, 0x62808380, 0x009f0081, 0xa184a053, 0xaf000400,
	 BUFFERED_FLAGS, SEEPROM_PAGE_BITS, SEEPROM_PAGE_SIZE,
	 SEEPROM_BYTE_ADDR_MASK, SEEPROM_TOTAL_SIZE,
	 "EEPROM - fast"},
	/* Expansion entry 1001 */
	{0x2a000002, 0x6b808201, 0x00050081, 0x03840253, 0xaf020406,
	 NONBUFFERED_FLAGS, SAIFUN_FLASH_PAGE_BITS, SAIFUN_FLASH_PAGE_SIZE,
	 SAIFUN_FLASH_BYTE_ADDR_MASK, 0,
	 "Entry 1001"},
	/* Expansion entry 1010 */
	{0x26000001, 0x67808201, 0x00050081, 0x03840253, 0xaf020406,
	 NONBUFFERED_FLAGS, SAIFUN_FLASH_PAGE_BITS, SAIFUN_FLASH_PAGE_SIZE,
	 SAIFUN_FLASH_BYTE_ADDR_MASK, 0,
	 "Entry 1010"},
	/* ATMEL AT45DB011B (buffered flash) */
	{0x2e000003, 0x6e808273, 0x00570081, 0x68848353, 0xaf000400,
	 BUFFERED_FLAGS, BUFFERED_FLASH_PAGE_BITS, BUFFERED_FLASH_PAGE_SIZE,
	 BUFFERED_FLASH_BYTE_ADDR_MASK, BUFFERED_FLASH_TOTAL_SIZE,
	 "Buffered flash (128kB)"},
	/* Expansion entry 1100 */
	{0x33000000, 0x73808201, 0x00050081, 0x03840253, 0xaf020406,
	 NONBUFFERED_FLAGS, SAIFUN_FLASH_PAGE_BITS, SAIFUN_FLASH_PAGE_SIZE,
	 SAIFUN_FLASH_BYTE_ADDR_MASK, 0,
	 "Entry 1100"},
	/* Expansion entry 1101 */
	{0x3b000002, 0x7b808201, 0x00050081, 0x03840253, 0xaf020406,
	 NONBUFFERED_FLAGS, SAIFUN_FLASH_PAGE_BITS, SAIFUN_FLASH_PAGE_SIZE,
	 SAIFUN_FLASH_BYTE_ADDR_MASK, 0,
	 "Entry 1101"},
	/* Ateml Expansion entry 1110 */
	{0x37000001, 0x76808273, 0x00570081, 0x68848353, 0xaf000400,
	 BUFFERED_FLAGS, BUFFERED_FLASH_PAGE_BITS, BUFFERED_FLASH_PAGE_SIZE,
	 BUFFERED_FLASH_BYTE_ADDR_MASK, 0,
	 "Entry 1110 (Atmel)"},
	/* ATMEL AT45DB021B (buffered flash) */
	{0x3f000003, 0x7e808273, 0x00570081, 0x68848353, 0xaf000400,
	 BUFFERED_FLAGS, BUFFERED_FLASH_PAGE_BITS, BUFFERED_FLASH_PAGE_SIZE,
	 BUFFERED_FLASH_BYTE_ADDR_MASK, BUFFERED_FLASH_TOTAL_SIZE*2,
	 "Buffered flash (256kB)"},
};

/*
 * The BCM5709 controllers transparently handle the
 * differences between Atmel 264 byte pages and all
 * flash devices which use 256 byte pages, so no
 * logical-to-physical mapping is required in the
 * driver.
 */
static struct flash_spec flash_5709 = {
	.flags		= BNX_NV_BUFFERED,
	.page_bits	= BCM5709_FLASH_PAGE_BITS,
	.page_size	= BCM5709_FLASH_PAGE_SIZE,
	.addr_mask	= BCM5709_FLASH_BYTE_ADDR_MASK,
	.total_size	= BUFFERED_FLASH_TOTAL_SIZE * 2,
	.name		= "5709 buffered flash (256kB)",
};

/****************************************************************************/
/* OpenBSD device entry points.                                             */
/****************************************************************************/
int	bnx_probe(struct device *, void *, void *);
void	bnx_attach(struct device *, struct device *, void *);
void	bnx_attachhook(struct device *);
int	bnx_read_firmware(struct bnx_softc *sc, int);
int	bnx_read_rv2p(struct bnx_softc *sc, int);
#if 0
void	bnx_detach(void *);
#endif

/****************************************************************************/
/* BNX Debug Data Structure Dump Routines                                   */
/****************************************************************************/
#ifdef BNX_DEBUG
void	bnx_dump_mbuf(struct bnx_softc *, struct mbuf *);
void	bnx_dump_tx_mbuf_chain(struct bnx_softc *, int, int);
void	bnx_dump_rx_mbuf_chain(struct bnx_softc *, int, int);
void	bnx_dump_txbd(struct bnx_softc *, int, struct tx_bd *);
void	bnx_dump_rxbd(struct bnx_softc *, int, struct rx_bd *);
void	bnx_dump_l2fhdr(struct bnx_softc *, int, struct l2_fhdr *);
void	bnx_dump_tx_chain(struct bnx_softc *, int, int);
void	bnx_dump_rx_chain(struct bnx_softc *, int, int);
void	bnx_dump_status_block(struct bnx_softc *);
void	bnx_dump_stats_block(struct bnx_softc *);
void	bnx_dump_driver_state(struct bnx_softc *);
void	bnx_dump_hw_state(struct bnx_softc *);
void	bnx_breakpoint(struct bnx_softc *);
#endif

/****************************************************************************/
/* BNX Register/Memory Access Routines                                      */
/****************************************************************************/
u_int32_t	bnx_reg_rd_ind(struct bnx_softc *, u_int32_t);
void	bnx_reg_wr_ind(struct bnx_softc *, u_int32_t, u_int32_t);
void	bnx_ctx_wr(struct bnx_softc *, u_int32_t, u_int32_t, u_int32_t);
int	bnx_miibus_read_reg(struct device *, int, int);
void	bnx_miibus_write_reg(struct device *, int, int, int);
void	bnx_miibus_statchg(struct device *);

/****************************************************************************/
/* BNX NVRAM Access Routines                                                */
/****************************************************************************/
int	bnx_acquire_nvram_lock(struct bnx_softc *);
int	bnx_release_nvram_lock(struct bnx_softc *);
void	bnx_enable_nvram_access(struct bnx_softc *);
void	bnx_disable_nvram_access(struct bnx_softc *);
int	bnx_nvram_read_dword(struct bnx_softc *, u_int32_t, u_int8_t *,
	    u_int32_t);
int	bnx_init_nvram(struct bnx_softc *);
int	bnx_nvram_read(struct bnx_softc *, u_int32_t, u_int8_t *, int);
int	bnx_nvram_test(struct bnx_softc *);
#ifdef BNX_NVRAM_WRITE_SUPPORT
int	bnx_enable_nvram_write(struct bnx_softc *);
void	bnx_disable_nvram_write(struct bnx_softc *);
int	bnx_nvram_erase_page(struct bnx_softc *, u_int32_t);
int	bnx_nvram_write_dword(struct bnx_softc *, u_int32_t, u_int8_t *,
	    u_int32_t);
int	bnx_nvram_write(struct bnx_softc *, u_int32_t, u_int8_t *, int);
#endif

/****************************************************************************/
/*                                                                          */
/****************************************************************************/
void	bnx_get_media(struct bnx_softc *);
void	bnx_init_media(struct bnx_softc *);
int	bnx_dma_alloc(struct bnx_softc *);
void	bnx_dma_free(struct bnx_softc *);
void	bnx_release_resources(struct bnx_softc *);

/****************************************************************************/
/* BNX Firmware Synchronization and Load                                    */
/****************************************************************************/
int	bnx_fw_sync(struct bnx_softc *, u_int32_t);
void	bnx_load_rv2p_fw(struct bnx_softc *, u_int32_t *, u_int32_t,
	    u_int32_t);
void	bnx_load_cpu_fw(struct bnx_softc *, struct cpu_reg *,
	    struct fw_info *);
void	bnx_init_cpus(struct bnx_softc *);

void	bnx_stop(struct bnx_softc *);
int	bnx_reset(struct bnx_softc *, u_int32_t);
int	bnx_chipinit(struct bnx_softc *);
int	bnx_blockinit(struct bnx_softc *);
int	bnx_get_buf(struct bnx_softc *, u_int16_t *, u_int16_t *, u_int32_t *);

int	bnx_init_tx_chain(struct bnx_softc *);
void	bnx_init_tx_context(struct bnx_softc *);
int	bnx_fill_rx_chain(struct bnx_softc *);
void	bnx_init_rx_context(struct bnx_softc *);
int	bnx_init_rx_chain(struct bnx_softc *);
void	bnx_free_rx_chain(struct bnx_softc *);
void	bnx_free_tx_chain(struct bnx_softc *);
void	bnx_rxrefill(void *);

int	bnx_tx_encap(struct bnx_softc *, struct mbuf *, int *);
void	bnx_start(struct ifqueue *);
int	bnx_ioctl(struct ifnet *, u_long, caddr_t);
void	bnx_watchdog(struct ifnet *);
int	bnx_ifmedia_upd(struct ifnet *);
void	bnx_ifmedia_sts(struct ifnet *, struct ifmediareq *);
void	bnx_init(void *);
void	bnx_mgmt_init(struct bnx_softc *sc);

void	bnx_init_context(struct bnx_softc *);
void	bnx_get_mac_addr(struct bnx_softc *);
void	bnx_set_mac_addr(struct bnx_softc *);
void	bnx_phy_intr(struct bnx_softc *);
void	bnx_rx_intr(struct bnx_softc *);
void	bnx_tx_intr(struct bnx_softc *);
void	bnx_disable_intr(struct bnx_softc *);
void	bnx_enable_intr(struct bnx_softc *);

int	bnx_intr(void *);
void	bnx_iff(struct bnx_softc *);
void	bnx_stats_update(struct bnx_softc *);
void	bnx_tick(void *);

/****************************************************************************/
/* OpenBSD device dispatch table.                                           */
/****************************************************************************/
struct cfattach bnx_ca = {
	sizeof(struct bnx_softc), bnx_probe, bnx_attach
};

struct cfdriver bnx_cd = {
	NULL, "bnx", DV_IFNET
};

/****************************************************************************/
/* Device probe function.                                                   */
/*                                                                          */
/* Compares the device to the driver's list of supported devices and        */
/* reports back to the OS whether this is the right driver for the device.  */
/*                                                                          */
/* Returns:                                                                 */
/*   BUS_PROBE_DEFAULT on success, positive value on failure.               */
/****************************************************************************/
int
bnx_probe(struct device *parent, void *match, void *aux)
{
	return (pci_matchbyid((struct pci_attach_args *)aux, bnx_devices,
	    nitems(bnx_devices)));
}

void
nswaph(u_int32_t *p, int wcount)
{
	for (; wcount; wcount -=4) {
		*p = ntohl(*p);
		p++;
	}
}

int
bnx_read_firmware(struct bnx_softc *sc, int idx)
{
	struct bnx_firmware *bfw = &bnx_firmwares[idx];
	struct bnx_firmware_header *hdr = bfw->fw;
	u_char *p, *q;
	size_t size;
	int error;

	if (hdr != NULL)
		return (0);

	if ((error = loadfirmware(bfw->filename, &p, &size)) != 0)
		return (error);

	if (size < sizeof(struct bnx_firmware_header)) {
		free(p, M_DEVBUF, size);
		return (EINVAL);
	}

	hdr = (struct bnx_firmware_header *)p;

	hdr->bnx_COM_FwReleaseMajor = ntohl(hdr->bnx_COM_FwReleaseMajor);
	hdr->bnx_COM_FwReleaseMinor = ntohl(hdr->bnx_COM_FwReleaseMinor);
	hdr->bnx_COM_FwReleaseFix = ntohl(hdr->bnx_COM_FwReleaseFix);
	hdr->bnx_COM_FwStartAddr = ntohl(hdr->bnx_COM_FwStartAddr);
	hdr->bnx_COM_FwTextAddr = ntohl(hdr->bnx_COM_FwTextAddr);
	hdr->bnx_COM_FwTextLen = ntohl(hdr->bnx_COM_FwTextLen);
	hdr->bnx_COM_FwDataAddr = ntohl(hdr->bnx_COM_FwDataAddr);
	hdr->bnx_COM_FwDataLen = ntohl(hdr->bnx_COM_FwDataLen);
	hdr->bnx_COM_FwRodataAddr = ntohl(hdr->bnx_COM_FwRodataAddr);
	hdr->bnx_COM_FwRodataLen = ntohl(hdr->bnx_COM_FwRodataLen);
	hdr->bnx_COM_FwBssAddr = ntohl(hdr->bnx_COM_FwBssAddr);
	hdr->bnx_COM_FwBssLen = ntohl(hdr->bnx_COM_FwBssLen);
	hdr->bnx_COM_FwSbssAddr = ntohl(hdr->bnx_COM_FwSbssAddr);
	hdr->bnx_COM_FwSbssLen = ntohl(hdr->bnx_COM_FwSbssLen);

	hdr->bnx_RXP_FwReleaseMajor = ntohl(hdr->bnx_RXP_FwReleaseMajor);
	hdr->bnx_RXP_FwReleaseMinor = ntohl(hdr->bnx_RXP_FwReleaseMinor);
	hdr->bnx_RXP_FwReleaseFix = ntohl(hdr->bnx_RXP_FwReleaseFix);
	hdr->bnx_RXP_FwStartAddr = ntohl(hdr->bnx_RXP_FwStartAddr);
	hdr->bnx_RXP_FwTextAddr = ntohl(hdr->bnx_RXP_FwTextAddr);
	hdr->bnx_RXP_FwTextLen = ntohl(hdr->bnx_RXP_FwTextLen);
	hdr->bnx_RXP_FwDataAddr = ntohl(hdr->bnx_RXP_FwDataAddr);
	hdr->bnx_RXP_FwDataLen = ntohl(hdr->bnx_RXP_FwDataLen);
	hdr->bnx_RXP_FwRodataAddr = ntohl(hdr->bnx_RXP_FwRodataAddr);
	hdr->bnx_RXP_FwRodataLen = ntohl(hdr->bnx_RXP_FwRodataLen);
	hdr->bnx_RXP_FwBssAddr = ntohl(hdr->bnx_RXP_FwBssAddr);
	hdr->bnx_RXP_FwBssLen = ntohl(hdr->bnx_RXP_FwBssLen);
	hdr->bnx_RXP_FwSbssAddr = ntohl(hdr->bnx_RXP_FwSbssAddr);
	hdr->bnx_RXP_FwSbssLen = ntohl(hdr->bnx_RXP_FwSbssLen);

	hdr->bnx_TPAT_FwReleaseMajor = ntohl(hdr->bnx_TPAT_FwReleaseMajor);
	hdr->bnx_TPAT_FwReleaseMinor = ntohl(hdr->bnx_TPAT_FwReleaseMinor);
	hdr->bnx_TPAT_FwReleaseFix = ntohl(hdr->bnx_TPAT_FwReleaseFix);
	hdr->bnx_TPAT_FwStartAddr = ntohl(hdr->bnx_TPAT_FwStartAddr);
	hdr->bnx_TPAT_FwTextAddr = ntohl(hdr->bnx_TPAT_FwTextAddr);
	hdr->bnx_TPAT_FwTextLen = ntohl(hdr->bnx_TPAT_FwTextLen);
	hdr->bnx_TPAT_FwDataAddr = ntohl(hdr->bnx_TPAT_FwDataAddr);
	hdr->bnx_TPAT_FwDataLen = ntohl(hdr->bnx_TPAT_FwDataLen);
	hdr->bnx_TPAT_FwRodataAddr = ntohl(hdr->bnx_TPAT_FwRodataAddr);
	hdr->bnx_TPAT_FwRodataLen = ntohl(hdr->bnx_TPAT_FwRodataLen);
	hdr->bnx_TPAT_FwBssAddr = ntohl(hdr->bnx_TPAT_FwBssAddr);
	hdr->bnx_TPAT_FwBssLen = ntohl(hdr->bnx_TPAT_FwBssLen);
	hdr->bnx_TPAT_FwSbssAddr = ntohl(hdr->bnx_TPAT_FwSbssAddr);
	hdr->bnx_TPAT_FwSbssLen = ntohl(hdr->bnx_TPAT_FwSbssLen);

	hdr->bnx_TXP_FwReleaseMajor = ntohl(hdr->bnx_TXP_FwReleaseMajor);
	hdr->bnx_TXP_FwReleaseMinor = ntohl(hdr->bnx_TXP_FwReleaseMinor);
	hdr->bnx_TXP_FwReleaseFix = ntohl(hdr->bnx_TXP_FwReleaseFix);
	hdr->bnx_TXP_FwStartAddr = ntohl(hdr->bnx_TXP_FwStartAddr);
	hdr->bnx_TXP_FwTextAddr = ntohl(hdr->bnx_TXP_FwTextAddr);
	hdr->bnx_TXP_FwTextLen = ntohl(hdr->bnx_TXP_FwTextLen);
	hdr->bnx_TXP_FwDataAddr = ntohl(hdr->bnx_TXP_FwDataAddr);
	hdr->bnx_TXP_FwDataLen = ntohl(hdr->bnx_TXP_FwDataLen);
	hdr->bnx_TXP_FwRodataAddr = ntohl(hdr->bnx_TXP_FwRodataAddr);
	hdr->bnx_TXP_FwRodataLen = ntohl(hdr->bnx_TXP_FwRodataLen);
	hdr->bnx_TXP_FwBssAddr = ntohl(hdr->bnx_TXP_FwBssAddr);
	hdr->bnx_TXP_FwBssLen = ntohl(hdr->bnx_TXP_FwBssLen);
	hdr->bnx_TXP_FwSbssAddr = ntohl(hdr->bnx_TXP_FwSbssAddr);
	hdr->bnx_TXP_FwSbssLen = ntohl(hdr->bnx_TXP_FwSbssLen);

	q = p + sizeof(*hdr);

	bfw->bnx_COM_FwText = (u_int32_t *)q;
	q += hdr->bnx_COM_FwTextLen;
	nswaph(bfw->bnx_COM_FwText, hdr->bnx_COM_FwTextLen);
	bfw->bnx_COM_FwData = (u_int32_t *)q;
	q += hdr->bnx_COM_FwDataLen;
	nswaph(bfw->bnx_COM_FwData, hdr->bnx_COM_FwDataLen);
	bfw->bnx_COM_FwRodata = (u_int32_t *)q;
	q += hdr->bnx_COM_FwRodataLen;
	nswaph(bfw->bnx_COM_FwRodata, hdr->bnx_COM_FwRodataLen);
	bfw->bnx_COM_FwBss = (u_int32_t *)q;
	q += hdr->bnx_COM_FwBssLen;
	nswaph(bfw->bnx_COM_FwBss, hdr->bnx_COM_FwBssLen);
	bfw->bnx_COM_FwSbss = (u_int32_t *)q;
	q += hdr->bnx_COM_FwSbssLen;
	nswaph(bfw->bnx_COM_FwSbss, hdr->bnx_COM_FwSbssLen);

	bfw->bnx_RXP_FwText = (u_int32_t *)q;
	q += hdr->bnx_RXP_FwTextLen;
	nswaph(bfw->bnx_RXP_FwText, hdr->bnx_RXP_FwTextLen);
	bfw->bnx_RXP_FwData = (u_int32_t *)q;
	q += hdr->bnx_RXP_FwDataLen;
	nswaph(bfw->bnx_RXP_FwData, hdr->bnx_RXP_FwDataLen);
	bfw->bnx_RXP_FwRodata = (u_int32_t *)q;
	q += hdr->bnx_RXP_FwRodataLen;
	nswaph(bfw->bnx_RXP_FwRodata, hdr->bnx_RXP_FwRodataLen);
	bfw->bnx_RXP_FwBss = (u_int32_t *)q;
	q += hdr->bnx_RXP_FwBssLen;
	nswaph(bfw->bnx_RXP_FwBss, hdr->bnx_RXP_FwBssLen);
	bfw->bnx_RXP_FwSbss = (u_int32_t *)q;
	q += hdr->bnx_RXP_FwSbssLen;
	nswaph(bfw->bnx_RXP_FwSbss, hdr->bnx_RXP_FwSbssLen);

	bfw->bnx_TPAT_FwText = (u_int32_t *)q;
	q += hdr->bnx_TPAT_FwTextLen;
	nswaph(bfw->bnx_TPAT_FwText, hdr->bnx_TPAT_FwTextLen);
	bfw->bnx_TPAT_FwData = (u_int32_t *)q;
	q += hdr->bnx_TPAT_FwDataLen;
	nswaph(bfw->bnx_TPAT_FwData, hdr->bnx_TPAT_FwDataLen);
	bfw->bnx_TPAT_FwRodata = (u_int32_t *)q;
	q += hdr->bnx_TPAT_FwRodataLen;
	nswaph(bfw->bnx_TPAT_FwRodata, hdr->bnx_TPAT_FwRodataLen);
	bfw->bnx_TPAT_FwBss = (u_int32_t *)q;
	q += hdr->bnx_TPAT_FwBssLen;
	nswaph(bfw->bnx_TPAT_FwBss, hdr->bnx_TPAT_FwBssLen);
	bfw->bnx_TPAT_FwSbss = (u_int32_t *)q;
	q += hdr->bnx_TPAT_FwSbssLen;
	nswaph(bfw->bnx_TPAT_FwSbss, hdr->bnx_TPAT_FwSbssLen);

	bfw->bnx_TXP_FwText = (u_int32_t *)q;
	q += hdr->bnx_TXP_FwTextLen;
	nswaph(bfw->bnx_TXP_FwText, hdr->bnx_TXP_FwTextLen);
	bfw->bnx_TXP_FwData = (u_int32_t *)q;
	q += hdr->bnx_TXP_FwDataLen;
	nswaph(bfw->bnx_TXP_FwData, hdr->bnx_TXP_FwDataLen);
	bfw->bnx_TXP_FwRodata = (u_int32_t *)q;
	q += hdr->bnx_TXP_FwRodataLen;
	nswaph(bfw->bnx_TXP_FwRodata, hdr->bnx_TXP_FwRodataLen);
	bfw->bnx_TXP_FwBss = (u_int32_t *)q;
	q += hdr->bnx_TXP_FwBssLen;
	nswaph(bfw->bnx_TXP_FwBss, hdr->bnx_TXP_FwBssLen);
	bfw->bnx_TXP_FwSbss = (u_int32_t *)q;
	q += hdr->bnx_TXP_FwSbssLen;
	nswaph(bfw->bnx_TXP_FwSbss, hdr->bnx_TXP_FwSbssLen);

	if (q - p != size) {
		free(p, M_DEVBUF, size);
		hdr = NULL;
		return EINVAL;
	}

	bfw->fw = hdr;

	return (0);
}

int
bnx_read_rv2p(struct bnx_softc *sc, int idx)
{
	struct bnx_rv2p *rv2p = &bnx_rv2ps[idx];
	struct bnx_rv2p_header *hdr = rv2p->fw;
	u_char *p, *q;
	size_t size;
	int error;

	if (hdr != NULL)
		return (0);

	if ((error = loadfirmware(rv2p->filename, &p, &size)) != 0)
		return (error);

	if (size < sizeof(struct bnx_rv2p_header)) {
		free(p, M_DEVBUF, size);
		return (EINVAL);
	}

	hdr = (struct bnx_rv2p_header *)p;

	hdr->bnx_rv2p_proc1len = ntohl(hdr->bnx_rv2p_proc1len);
	hdr->bnx_rv2p_proc2len = ntohl(hdr->bnx_rv2p_proc2len);

	q = p + sizeof(*hdr);

	rv2p->bnx_rv2p_proc1 = (u_int32_t *)q;
	q += hdr->bnx_rv2p_proc1len;
	nswaph(rv2p->bnx_rv2p_proc1, hdr->bnx_rv2p_proc1len);
	rv2p->bnx_rv2p_proc2 = (u_int32_t *)q;
	q += hdr->bnx_rv2p_proc2len;
	nswaph(rv2p->bnx_rv2p_proc2, hdr->bnx_rv2p_proc2len);
	
	if (q - p != size) {
		free(p, M_DEVBUF, size);
		return EINVAL;
	}

	rv2p->fw = hdr;

	return (0);
}


/****************************************************************************/
/* Device attach function.                                                  */
/*                                                                          */
/* Allocates device resources, performs secondary chip identification,      */
/* resets and initializes the hardware, and initializes driver instance     */
/* variables.                                                               */
/*                                                                          */
/* Returns:                                                                 */
/*   0 on success, positive value on failure.                               */
/****************************************************************************/
void
bnx_attach(struct device *parent, struct device *self, void *aux)
{
	struct bnx_softc	*sc = (struct bnx_softc *)self;
	struct pci_attach_args	*pa = aux;
	pci_chipset_tag_t	pc = pa->pa_pc;
	u_int32_t		val;
	pcireg_t		memtype;
	const char 		*intrstr = NULL;

	sc->bnx_pa = *pa;

	/*
	 * Map control/status registers.
	*/
	memtype = pci_mapreg_type(pa->pa_pc, pa->pa_tag, BNX_PCI_BAR0);  
	if (pci_mapreg_map(pa, BNX_PCI_BAR0, memtype, 0, &sc->bnx_btag,
	    &sc->bnx_bhandle, NULL, &sc->bnx_size, 0)) {
		printf(": can't find mem space\n");
		return;
	}

	if (pci_intr_map(pa, &sc->bnx_ih)) {
		printf(": couldn't map interrupt\n");
		goto bnx_attach_fail;
	}
	intrstr = pci_intr_string(pc, sc->bnx_ih);

	/*
	 * Configure byte swap and enable indirect register access.
	 * Rely on CPU to do target byte swapping on big endian systems.
	 * Access to registers outside of PCI configurtion space are not
	 * valid until this is done.
	 */
	pci_conf_write(pa->pa_pc, pa->pa_tag, BNX_PCICFG_MISC_CONFIG,
	    BNX_PCICFG_MISC_CONFIG_REG_WINDOW_ENA |
	    BNX_PCICFG_MISC_CONFIG_TARGET_MB_WORD_SWAP);

	/* Save ASIC revsion info. */
	sc->bnx_chipid =  REG_RD(sc, BNX_MISC_ID);

	/*
	 * Find the base address for shared memory access.
	 * Newer versions of bootcode use a signature and offset
	 * while older versions use a fixed address.
	 */
	val = REG_RD_IND(sc, BNX_SHM_HDR_SIGNATURE);
	if ((val & BNX_SHM_HDR_SIGNATURE_SIG_MASK) == BNX_SHM_HDR_SIGNATURE_SIG)
		sc->bnx_shmem_base = REG_RD_IND(sc, BNX_SHM_HDR_ADDR_0 +
		    (sc->bnx_pa.pa_function << 2));
	else
		sc->bnx_shmem_base = HOST_VIEW_SHMEM_BASE;

	DBPRINT(sc, BNX_INFO, "bnx_shmem_base = 0x%08X\n", sc->bnx_shmem_base);

	/* Set initial device and PHY flags */
	sc->bnx_flags = 0;
	sc->bnx_phy_flags = 0;

	/* Get PCI bus information (speed and type). */
	val = REG_RD(sc, BNX_PCICFG_MISC_STATUS);
	if (val & BNX_PCICFG_MISC_STATUS_PCIX_DET) {
		u_int32_t clkreg;

		sc->bnx_flags |= BNX_PCIX_FLAG;

		clkreg = REG_RD(sc, BNX_PCICFG_PCI_CLOCK_CONTROL_BITS);

		clkreg &= BNX_PCICFG_PCI_CLOCK_CONTROL_BITS_PCI_CLK_SPD_DET;
		switch (clkreg) {
		case BNX_PCICFG_PCI_CLOCK_CONTROL_BITS_PCI_CLK_SPD_DET_133MHZ:
			sc->bus_speed_mhz = 133;
			break;

		case BNX_PCICFG_PCI_CLOCK_CONTROL_BITS_PCI_CLK_SPD_DET_95MHZ:
			sc->bus_speed_mhz = 100;
			break;

		case BNX_PCICFG_PCI_CLOCK_CONTROL_BITS_PCI_CLK_SPD_DET_66MHZ:
		case BNX_PCICFG_PCI_CLOCK_CONTROL_BITS_PCI_CLK_SPD_DET_80MHZ:
			sc->bus_speed_mhz = 66;
			break;

		case BNX_PCICFG_PCI_CLOCK_CONTROL_BITS_PCI_CLK_SPD_DET_48MHZ:
		case BNX_PCICFG_PCI_CLOCK_CONTROL_BITS_PCI_CLK_SPD_DET_55MHZ:
			sc->bus_speed_mhz = 50;
			break;

		case BNX_PCICFG_PCI_CLOCK_CONTROL_BITS_PCI_CLK_SPD_DET_LOW:
		case BNX_PCICFG_PCI_CLOCK_CONTROL_BITS_PCI_CLK_SPD_DET_32MHZ:
		case BNX_PCICFG_PCI_CLOCK_CONTROL_BITS_PCI_CLK_SPD_DET_38MHZ:
			sc->bus_speed_mhz = 33;
			break;
		}
	} else if (val & BNX_PCICFG_MISC_STATUS_M66EN)
			sc->bus_speed_mhz = 66;
		else
			sc->bus_speed_mhz = 33;

	if (val & BNX_PCICFG_MISC_STATUS_32BIT_DET)
		sc->bnx_flags |= BNX_PCI_32BIT_FLAG;

	/* Hookup IRQ last. */
	sc->bnx_intrhand = pci_intr_establish(pc, sc->bnx_ih,
	    IPL_NET | IPL_MPSAFE, bnx_intr, sc, sc->bnx_dev.dv_xname);
	if (sc->bnx_intrhand == NULL) {
		printf(": couldn't establish interrupt");
		if (intrstr != NULL)
			printf(" at %s", intrstr);
		printf("\n");
		goto bnx_attach_fail;
	}

	printf(": %s\n", intrstr);

	config_mountroot(self, bnx_attachhook);
	return;

bnx_attach_fail:
	bnx_release_resources(sc);
	DBPRINT(sc, BNX_VERBOSE_RESET, "Exiting %s()\n", __FUNCTION__);
}

void
bnx_attachhook(struct device *self)
{
	struct bnx_softc *sc = (struct bnx_softc *)self;
	struct pci_attach_args *pa = &sc->bnx_pa;
	struct ifnet		*ifp;
	int			error, mii_flags = 0;
	int			fw = BNX_FW_B06;
	int			rv2p = BNX_RV2P;

	if (BNX_CHIP_NUM(sc) == BNX_CHIP_NUM_5709) {
		fw = BNX_FW_B09;
		if ((BNX_CHIP_REV(sc) == BNX_CHIP_REV_Ax))
			rv2p = BNX_XI90_RV2P;
		else
			rv2p = BNX_XI_RV2P;
	}

	if ((error = bnx_read_firmware(sc, fw)) != 0) {
		printf("%s: error %d, could not read firmware\n",
		    sc->bnx_dev.dv_xname, error);
		return;
	}

	if ((error = bnx_read_rv2p(sc, rv2p)) != 0) {
		printf("%s: error %d, could not read rv2p\n",
		    sc->bnx_dev.dv_xname, error);
		return;
	}

	/* Reset the controller. */
	if (bnx_reset(sc, BNX_DRV_MSG_CODE_RESET))
		goto bnx_attach_fail;

	/* Initialize the controller. */
	if (bnx_chipinit(sc)) {
		printf("%s: Controller initialization failed!\n",
		    sc->bnx_dev.dv_xname);
		goto bnx_attach_fail;
	}

	/* Perform NVRAM test. */
	if (bnx_nvram_test(sc)) {
		printf("%s: NVRAM test failed!\n",
		    sc->bnx_dev.dv_xname);
		goto bnx_attach_fail;
	}

	/* Fetch the permanent Ethernet MAC address. */
	bnx_get_mac_addr(sc);

	/*
	 * Trip points control how many BDs
	 * should be ready before generating an
	 * interrupt while ticks control how long
	 * a BD can sit in the chain before
	 * generating an interrupt.  Set the default 
	 * values for the RX and TX rings.
	 */

#ifdef BNX_DEBUG
	/* Force more frequent interrupts. */
	sc->bnx_tx_quick_cons_trip_int = 1;
	sc->bnx_tx_quick_cons_trip     = 1;
	sc->bnx_tx_ticks_int           = 0;
	sc->bnx_tx_ticks               = 0;

	sc->bnx_rx_quick_cons_trip_int = 1;
	sc->bnx_rx_quick_cons_trip     = 1;
	sc->bnx_rx_ticks_int           = 0;
	sc->bnx_rx_ticks               = 0;
#else
	sc->bnx_tx_quick_cons_trip_int = 20;
	sc->bnx_tx_quick_cons_trip     = 20;
	sc->bnx_tx_ticks_int           = 80;
	sc->bnx_tx_ticks               = 80;

	sc->bnx_rx_quick_cons_trip_int = 6;
	sc->bnx_rx_quick_cons_trip     = 6;
	sc->bnx_rx_ticks_int           = 18;
	sc->bnx_rx_ticks               = 18;
#endif

	/* Update statistics once every second. */
	sc->bnx_stats_ticks = 1000000 & 0xffff00;

	/* Find the media type for the adapter. */
	bnx_get_media(sc);

	/*
	 * Store config data needed by the PHY driver for
	 * backplane applications
	 */
	sc->bnx_shared_hw_cfg = REG_RD_IND(sc, sc->bnx_shmem_base +
		BNX_SHARED_HW_CFG_CONFIG);
	sc->bnx_port_hw_cfg = REG_RD_IND(sc, sc->bnx_shmem_base +
		BNX_PORT_HW_CFG_CONFIG);

	/* Allocate DMA memory resources. */
	sc->bnx_dmatag = pa->pa_dmat;
	if (bnx_dma_alloc(sc)) {
		printf("%s: DMA resource allocation failed!\n",
		    sc->bnx_dev.dv_xname);
		goto bnx_attach_fail;
	}

	/* Initialize the ifnet interface. */
	ifp = &sc->arpcom.ac_if;
	ifp->if_softc = sc;
	ifp->if_flags = IFF_BROADCAST | IFF_SIMPLEX | IFF_MULTICAST;
	ifp->if_xflags = IFXF_MPSAFE;
	ifp->if_ioctl = bnx_ioctl;
	ifp->if_qstart = bnx_start;
	ifp->if_watchdog = bnx_watchdog;
	IFQ_SET_MAXLEN(&ifp->if_snd, USABLE_TX_BD - 1);
	bcopy(sc->eaddr, sc->arpcom.ac_enaddr, ETHER_ADDR_LEN);
	bcopy(sc->bnx_dev.dv_xname, ifp->if_xname, IFNAMSIZ);

	ifp->if_capabilities = IFCAP_VLAN_MTU | IFCAP_CSUM_TCPv4 |
	    IFCAP_CSUM_UDPv4;

#if NVLAN > 0
	ifp->if_capabilities |= IFCAP_VLAN_HWTAGGING;
#endif

	sc->mbuf_alloc_size = BNX_MAX_MRU;

	printf("%s: address %s\n", sc->bnx_dev.dv_xname,
	    ether_sprintf(sc->arpcom.ac_enaddr));

	sc->bnx_mii.mii_ifp = ifp;
	sc->bnx_mii.mii_readreg = bnx_miibus_read_reg;
	sc->bnx_mii.mii_writereg = bnx_miibus_write_reg;
	sc->bnx_mii.mii_statchg = bnx_miibus_statchg;

	/* Handle any special PHY initialization for SerDes PHYs. */
	bnx_init_media(sc);

	/* Look for our PHY. */
	ifmedia_init(&sc->bnx_mii.mii_media, 0, bnx_ifmedia_upd,
	    bnx_ifmedia_sts);
	mii_flags |= MIIF_DOPAUSE;
	if (sc->bnx_phy_flags & BNX_PHY_SERDES_FLAG)
		mii_flags |= MIIF_HAVEFIBER;
	mii_attach(&sc->bnx_dev, &sc->bnx_mii, 0xffffffff,
	    sc->bnx_phy_addr, MII_OFFSET_ANY, mii_flags);

	if (LIST_FIRST(&sc->bnx_mii.mii_phys) == NULL) {
		printf("%s: no PHY found!\n", sc->bnx_dev.dv_xname);
		ifmedia_add(&sc->bnx_mii.mii_media,
		    IFM_ETHER|IFM_MANUAL, 0, NULL);
		ifmedia_set(&sc->bnx_mii.mii_media,
		    IFM_ETHER|IFM_MANUAL);
	} else {
		ifmedia_set(&sc->bnx_mii.mii_media,
		    IFM_ETHER|IFM_AUTO);
	}

	/* Attach to the Ethernet interface list. */
	if_attach(ifp);
	ether_ifattach(ifp);

	timeout_set(&sc->bnx_timeout, bnx_tick, sc);
	timeout_set(&sc->bnx_rxrefill, bnx_rxrefill, sc);

	/* Print some important debugging info. */
	DBRUN(BNX_INFO, bnx_dump_driver_state(sc));

	/* Get the firmware running so ASF still works. */
	bnx_mgmt_init(sc);

	/* Handle interrupts */
	sc->bnx_flags |= BNX_ACTIVE_FLAG;

	goto bnx_attach_exit;

bnx_attach_fail:
	bnx_release_resources(sc);

bnx_attach_exit:
	DBPRINT(sc, BNX_VERBOSE_RESET, "Exiting %s()\n", __FUNCTION__);
}

/****************************************************************************/
/* Device detach function.                                                  */
/*                                                                          */
/* Stops the controller, resets the controller, and releases resources.     */
/*                                                                          */
/* Returns:                                                                 */
/*   0 on success, positive value on failure.                               */
/****************************************************************************/
#if 0
void
bnx_detach(void *xsc)
{
	struct bnx_softc *sc;
	struct ifnet *ifp = &sc->arpcom.ac_if;

	sc = device_get_softc(dev);

	DBPRINT(sc, BNX_VERBOSE_RESET, "Entering %s()\n", __FUNCTION__);

	/* Stop and reset the controller. */
	bnx_stop(sc);
	bnx_reset(sc, BNX_DRV_MSG_CODE_RESET);

	ether_ifdetach(ifp);

	/* If we have a child device on the MII bus remove it too. */
	bus_generic_detach(dev);
	device_delete_child(dev, sc->bnx_mii);

	/* Release all remaining resources. */
	bnx_release_resources(sc);

	DBPRINT(sc, BNX_VERBOSE_RESET, "Exiting %s()\n", __FUNCTION__);

	return(0);
}
#endif

/****************************************************************************/
/* Indirect register read.                                                  */
/*                                                                          */
/* Reads NetXtreme II registers using an index/data register pair in PCI    */
/* configuration space.  Using this mechanism avoids issues with posted     */
/* reads but is much slower than memory-mapped I/O.                         */
/*                                                                          */
/* Returns:                                                                 */
/*   The value of the register.                                             */
/****************************************************************************/
u_int32_t
bnx_reg_rd_ind(struct bnx_softc *sc, u_int32_t offset)
{
	struct pci_attach_args	*pa = &(sc->bnx_pa);

	pci_conf_write(pa->pa_pc, pa->pa_tag, BNX_PCICFG_REG_WINDOW_ADDRESS,
	    offset);
#ifdef BNX_DEBUG
	{
		u_int32_t val;
		val = pci_conf_read(pa->pa_pc, pa->pa_tag,
		    BNX_PCICFG_REG_WINDOW);
		DBPRINT(sc, BNX_EXCESSIVE, "%s(); offset = 0x%08X, "
		    "val = 0x%08X\n", __FUNCTION__, offset, val);
		return (val);
	}
#else
	return pci_conf_read(pa->pa_pc, pa->pa_tag, BNX_PCICFG_REG_WINDOW);
#endif
}

/****************************************************************************/
/* Indirect register write.                                                 */
/*                                                                          */
/* Writes NetXtreme II registers using an index/data register pair in PCI   */
/* configuration space.  Using this mechanism avoids issues with posted     */
/* writes but is muchh slower than memory-mapped I/O.                       */
/*                                                                          */
/* Returns:                                                                 */
/*   Nothing.                                                               */
/****************************************************************************/
void
bnx_reg_wr_ind(struct bnx_softc *sc, u_int32_t offset, u_int32_t val)
{
	struct pci_attach_args  *pa = &(sc->bnx_pa);

	DBPRINT(sc, BNX_EXCESSIVE, "%s(); offset = 0x%08X, val = 0x%08X\n",
		__FUNCTION__, offset, val);

	pci_conf_write(pa->pa_pc, pa->pa_tag, BNX_PCICFG_REG_WINDOW_ADDRESS,
	    offset);
	pci_conf_write(pa->pa_pc, pa->pa_tag, BNX_PCICFG_REG_WINDOW, val);
}

/****************************************************************************/
/* Context memory write.                                                    */
/*                                                                          */
/* The NetXtreme II controller uses context memory to track connection      */
/* information for L2 and higher network protocols.                         */
/*                                                                          */
/* Returns:                                                                 */
/*   Nothing.                                                               */
/****************************************************************************/
void
bnx_ctx_wr(struct bnx_softc *sc, u_int32_t cid_addr, u_int32_t ctx_offset,
    u_int32_t ctx_val)
{
	u_int32_t idx, offset = ctx_offset + cid_addr;
	u_int32_t val, retry_cnt = 5;

	if (BNX_CHIP_NUM(sc) == BNX_CHIP_NUM_5709) {
		REG_WR(sc, BNX_CTX_CTX_DATA, ctx_val);
		REG_WR(sc, BNX_CTX_CTX_CTRL,
		    (offset | BNX_CTX_CTX_CTRL_WRITE_REQ));

		for (idx = 0; idx < retry_cnt; idx++) {
			val = REG_RD(sc, BNX_CTX_CTX_CTRL);
			if ((val & BNX_CTX_CTX_CTRL_WRITE_REQ) == 0)
				break;
			DELAY(5);
		}

#if 0
		if (val & BNX_CTX_CTX_CTRL_WRITE_REQ)
			BNX_PRINTF("%s(%d); Unable to write CTX memory: "
				"cid_addr = 0x%08X, offset = 0x%08X!\n",
				__FILE__, __LINE__, cid_addr, ctx_offset);
#endif

	} else {
		REG_WR(sc, BNX_CTX_DATA_ADR, offset);
		REG_WR(sc, BNX_CTX_DATA, ctx_val);
	}
}

/****************************************************************************/
/* PHY register read.                                                       */
/*                                                                          */
/* Implements register reads on the MII bus.                                */
/*                                                                          */
/* Returns:                                                                 */
/*   The value of the register.                                             */
/****************************************************************************/
int
bnx_miibus_read_reg(struct device *dev, int phy, int reg)
{
	struct bnx_softc	*sc = (struct bnx_softc *)dev;
	u_int32_t		val;
	int			i;

	/*
	 * The BCM5709S PHY is an IEEE Clause 45 PHY
	 * with special mappings to work with IEEE
	 * Clause 22 register accesses.
	 */
	if ((sc->bnx_phy_flags & BNX_PHY_IEEE_CLAUSE_45_FLAG) != 0) {
		if (reg >= MII_BMCR && reg <= MII_ANLPRNP)
			reg += 0x10;
	}

	if (sc->bnx_phy_flags & BNX_PHY_INT_MODE_AUTO_POLLING_FLAG) {
		val = REG_RD(sc, BNX_EMAC_MDIO_MODE);
		val &= ~BNX_EMAC_MDIO_MODE_AUTO_POLL;

		REG_WR(sc, BNX_EMAC_MDIO_MODE, val);
		REG_RD(sc, BNX_EMAC_MDIO_MODE);

		DELAY(40);
	}

	val = BNX_MIPHY(phy) | BNX_MIREG(reg) |
	    BNX_EMAC_MDIO_COMM_COMMAND_READ | BNX_EMAC_MDIO_COMM_DISEXT |
	    BNX_EMAC_MDIO_COMM_START_BUSY;
	REG_WR(sc, BNX_EMAC_MDIO_COMM, val);

	for (i = 0; i < BNX_PHY_TIMEOUT; i++) {
		DELAY(10);

		val = REG_RD(sc, BNX_EMAC_MDIO_COMM);
		if (!(val & BNX_EMAC_MDIO_COMM_START_BUSY)) {
			DELAY(5);

			val = REG_RD(sc, BNX_EMAC_MDIO_COMM);
			val &= BNX_EMAC_MDIO_COMM_DATA;

			break;
		}
	}

	if (val & BNX_EMAC_MDIO_COMM_START_BUSY) {
		BNX_PRINTF(sc, "%s(%d): Error: PHY read timeout! phy = %d, "
		    "reg = 0x%04X\n", __FILE__, __LINE__, phy, reg);
		val = 0x0;
	} else
		val = REG_RD(sc, BNX_EMAC_MDIO_COMM);

	DBPRINT(sc, BNX_EXCESSIVE,
	    "%s(): phy = %d, reg = 0x%04X, val = 0x%04X\n", __FUNCTION__, phy,
	    (u_int16_t) reg & 0xffff, (u_int16_t) val & 0xffff);

	if (sc->bnx_phy_flags & BNX_PHY_INT_MODE_AUTO_POLLING_FLAG) {
		val = REG_RD(sc, BNX_EMAC_MDIO_MODE);
		val |= BNX_EMAC_MDIO_MODE_AUTO_POLL;

		REG_WR(sc, BNX_EMAC_MDIO_MODE, val);
		REG_RD(sc, BNX_EMAC_MDIO_MODE);

		DELAY(40);
	}

	return (val & 0xffff);
}

/****************************************************************************/
/* PHY register write.                                                      */
/*                                                                          */
/* Implements register writes on the MII bus.                               */
/*                                                                          */
/* Returns:                                                                 */
/*   The value of the register.                                             */
/****************************************************************************/
void
bnx_miibus_write_reg(struct device *dev, int phy, int reg, int val)
{
	struct bnx_softc	*sc = (struct bnx_softc *)dev;
	u_int32_t		val1;
	int			i;

	DBPRINT(sc, BNX_EXCESSIVE, "%s(): phy = %d, reg = 0x%04X, "
	    "val = 0x%04X\n", __FUNCTION__,
	    phy, (u_int16_t) reg & 0xffff, (u_int16_t) val & 0xffff);

	/*
	 * The BCM5709S PHY is an IEEE Clause 45 PHY
	 * with special mappings to work with IEEE
	 * Clause 22 register accesses.
	 */
	if ((sc->bnx_phy_flags & BNX_PHY_IEEE_CLAUSE_45_FLAG) != 0) {
		if (reg >= MII_BMCR && reg <= MII_ANLPRNP)
			reg += 0x10;
	}

	if (sc->bnx_phy_flags & BNX_PHY_INT_MODE_AUTO_POLLING_FLAG) {
		val1 = REG_RD(sc, BNX_EMAC_MDIO_MODE);
		val1 &= ~BNX_EMAC_MDIO_MODE_AUTO_POLL;

		REG_WR(sc, BNX_EMAC_MDIO_MODE, val1);
		REG_RD(sc, BNX_EMAC_MDIO_MODE);

		DELAY(40);
	}

	val1 = BNX_MIPHY(phy) | BNX_MIREG(reg) | val |
	    BNX_EMAC_MDIO_COMM_COMMAND_WRITE |
	    BNX_EMAC_MDIO_COMM_START_BUSY | BNX_EMAC_MDIO_COMM_DISEXT;
	REG_WR(sc, BNX_EMAC_MDIO_COMM, val1);

	for (i = 0; i < BNX_PHY_TIMEOUT; i++) {
		DELAY(10);

		val1 = REG_RD(sc, BNX_EMAC_MDIO_COMM);
		if (!(val1 & BNX_EMAC_MDIO_COMM_START_BUSY)) {
			DELAY(5);
			break;
		}
	}

	if (val1 & BNX_EMAC_MDIO_COMM_START_BUSY) {
		BNX_PRINTF(sc, "%s(%d): PHY write timeout!\n", __FILE__,
		    __LINE__);
	}

	if (sc->bnx_phy_flags & BNX_PHY_INT_MODE_AUTO_POLLING_FLAG) {
		val1 = REG_RD(sc, BNX_EMAC_MDIO_MODE);
		val1 |= BNX_EMAC_MDIO_MODE_AUTO_POLL;

		REG_WR(sc, BNX_EMAC_MDIO_MODE, val1);
		REG_RD(sc, BNX_EMAC_MDIO_MODE);

		DELAY(40);
	}
}

/****************************************************************************/
/* MII bus status change.                                                   */
/*                                                                          */
/* Called by the MII bus driver when the PHY establishes link to set the    */
/* MAC interface registers.                                                 */
/*                                                                          */
/* Returns:                                                                 */
/*   Nothing.                                                               */
/****************************************************************************/
void
bnx_miibus_statchg(struct device *dev)
{
	struct bnx_softc	*sc = (struct bnx_softc *)dev;
	struct mii_data		*mii = &sc->bnx_mii;
	u_int32_t		rx_mode = sc->rx_mode;
	int			val;

	val = REG_RD(sc, BNX_EMAC_MODE);
	val &= ~(BNX_EMAC_MODE_PORT | BNX_EMAC_MODE_HALF_DUPLEX | 
		BNX_EMAC_MODE_MAC_LOOP | BNX_EMAC_MODE_FORCE_LINK | 
		BNX_EMAC_MODE_25G);

	/*
	 * Get flow control negotiation result.
	 */
	if (IFM_SUBTYPE(mii->mii_media.ifm_cur->ifm_media) == IFM_AUTO &&
	    (mii->mii_media_active & IFM_ETH_FMASK) != sc->bnx_flowflags) {
		sc->bnx_flowflags = mii->mii_media_active & IFM_ETH_FMASK;
		mii->mii_media_active &= ~IFM_ETH_FMASK;
	}

	/* Set MII or GMII interface based on the speed
	 * negotiated by the PHY.
	 */
	switch (IFM_SUBTYPE(mii->mii_media_active)) {
	case IFM_10_T:
		if (BNX_CHIP_NUM(sc) != BNX_CHIP_NUM_5706) {
			DBPRINT(sc, BNX_INFO, "Enabling 10Mb interface.\n");
			val |= BNX_EMAC_MODE_PORT_MII_10;
			break;
		}
		/* FALLTHROUGH */
	case IFM_100_TX:
		DBPRINT(sc, BNX_INFO, "Enabling MII interface.\n");
		val |= BNX_EMAC_MODE_PORT_MII;
		break;
	case IFM_2500_SX:
		DBPRINT(sc, BNX_INFO, "Enabling 2.5G MAC mode.\n");
		val |= BNX_EMAC_MODE_25G;
		/* FALLTHROUGH */
	case IFM_1000_T:
	case IFM_1000_SX:
		DBPRINT(sc, BNX_INFO, "Enablinb GMII interface.\n");
		val |= BNX_EMAC_MODE_PORT_GMII;
		break;
	default:
		val |= BNX_EMAC_MODE_PORT_GMII;
		break;
	}

	/* Set half or full duplex based on the duplicity
	 * negotiated by the PHY.
	 */
	if ((mii->mii_media_active & IFM_GMASK) == IFM_HDX) {
		DBPRINT(sc, BNX_INFO, "Setting Half-Duplex interface.\n");
		val |= BNX_EMAC_MODE_HALF_DUPLEX;
	} else
		DBPRINT(sc, BNX_INFO, "Setting Full-Duplex interface.\n");

	REG_WR(sc, BNX_EMAC_MODE, val);

	/*
	 * 802.3x flow control
	 */
	if (sc->bnx_flowflags & IFM_ETH_RXPAUSE) {
		DBPRINT(sc, BNX_INFO, "Enabling RX mode flow control.\n");
		rx_mode |= BNX_EMAC_RX_MODE_FLOW_EN;
	} else {
		DBPRINT(sc, BNX_INFO, "Disabling RX mode flow control.\n");
		rx_mode &= ~BNX_EMAC_RX_MODE_FLOW_EN;
	}

	if (sc->bnx_flowflags & IFM_ETH_TXPAUSE) {
		DBPRINT(sc, BNX_INFO, "Enabling TX mode flow control.\n");
		BNX_SETBIT(sc, BNX_EMAC_TX_MODE, BNX_EMAC_TX_MODE_FLOW_EN);
	} else {
		DBPRINT(sc, BNX_INFO, "Disabling TX mode flow control.\n");
		BNX_CLRBIT(sc, BNX_EMAC_TX_MODE, BNX_EMAC_TX_MODE_FLOW_EN);
	}

	/* Only make changes if the recive mode has actually changed. */
	if (rx_mode != sc->rx_mode) {
		DBPRINT(sc, BNX_VERBOSE, "Enabling new receive mode: 0x%08X\n",
		    rx_mode);

		sc->rx_mode = rx_mode;
		REG_WR(sc, BNX_EMAC_RX_MODE, rx_mode);
	}
}

/****************************************************************************/
/* Acquire NVRAM lock.                                                      */
/*                                                                          */
/* Before the NVRAM can be accessed the caller must acquire an NVRAM lock.  */
/* Locks 0 and 2 are reserved, lock 1 is used by firmware and lock 2 is     */
/* for use by the driver.                                                   */
/*                                                                          */
/* Returns:                                                                 */
/*   0 on success, positive value on failure.                               */
/****************************************************************************/
int
bnx_acquire_nvram_lock(struct bnx_softc *sc)
{
	u_int32_t		val;
	int			j;

	DBPRINT(sc, BNX_VERBOSE, "Acquiring NVRAM lock.\n");

	/* Request access to the flash interface. */
	REG_WR(sc, BNX_NVM_SW_ARB, BNX_NVM_SW_ARB_ARB_REQ_SET2);
	for (j = 0; j < NVRAM_TIMEOUT_COUNT; j++) {
		val = REG_RD(sc, BNX_NVM_SW_ARB);
		if (val & BNX_NVM_SW_ARB_ARB_ARB2)
			break;

		DELAY(5);
	}

	if (j >= NVRAM_TIMEOUT_COUNT) {
		DBPRINT(sc, BNX_WARN, "Timeout acquiring NVRAM lock!\n");
		return (EBUSY);
	}

	return (0);
}

/****************************************************************************/
/* Release NVRAM lock.                                                      */
/*                                                                          */
/* When the caller is finished accessing NVRAM the lock must be released.   */
/* Locks 0 and 2 are reserved, lock 1 is used by firmware and lock 2 is     */
/* for use by the driver.                                                   */
/*                                                                          */
/* Returns:                                                                 */
/*   0 on success, positive value on failure.                               */
/****************************************************************************/
int
bnx_release_nvram_lock(struct bnx_softc *sc)
{
	int			j;
	u_int32_t		val;

	DBPRINT(sc, BNX_VERBOSE, "Releasing NVRAM lock.\n");

	/* Relinquish nvram interface. */
	REG_WR(sc, BNX_NVM_SW_ARB, BNX_NVM_SW_ARB_ARB_REQ_CLR2);

	for (j = 0; j < NVRAM_TIMEOUT_COUNT; j++) {
		val = REG_RD(sc, BNX_NVM_SW_ARB);
		if (!(val & BNX_NVM_SW_ARB_ARB_ARB2))
			break;

		DELAY(5);
	}

	if (j >= NVRAM_TIMEOUT_COUNT) {
		DBPRINT(sc, BNX_WARN, "Timeout reeasing NVRAM lock!\n");
		return (EBUSY);
	}

	return (0);
}

#ifdef BNX_NVRAM_WRITE_SUPPORT
/****************************************************************************/
/* Enable NVRAM write access.                                               */
/*                                                                          */
/* Before writing to NVRAM the caller must enable NVRAM writes.             */
/*                                                                          */
/* Returns:                                                                 */
/*   0 on success, positive value on failure.                               */
/****************************************************************************/
int
bnx_enable_nvram_write(struct bnx_softc *sc)
{
	u_int32_t		val;

	DBPRINT(sc, BNX_VERBOSE, "Enabling NVRAM write.\n");

	val = REG_RD(sc, BNX_MISC_CFG);
	REG_WR(sc, BNX_MISC_CFG, val | BNX_MISC_CFG_NVM_WR_EN_PCI);

	if (!ISSET(sc->bnx_flash_info->flags, BNX_NV_BUFFERED)) {
		int j;

		REG_WR(sc, BNX_NVM_COMMAND, BNX_NVM_COMMAND_DONE);
		REG_WR(sc, BNX_NVM_COMMAND,
		    BNX_NVM_COMMAND_WREN | BNX_NVM_COMMAND_DOIT);

		for (j = 0; j < NVRAM_TIMEOUT_COUNT; j++) {
			DELAY(5);

			val = REG_RD(sc, BNX_NVM_COMMAND);
			if (val & BNX_NVM_COMMAND_DONE)
				break;
		}

		if (j >= NVRAM_TIMEOUT_COUNT) {
			DBPRINT(sc, BNX_WARN, "Timeout writing NVRAM!\n");
			return (EBUSY);
		}
	}

	return (0);
}

/****************************************************************************/
/* Disable NVRAM write access.                                              */
/*                                                                          */
/* When the caller is finished writing to NVRAM write access must be        */
/* disabled.                                                                */
/*                                                                          */
/* Returns:                                                                 */
/*   Nothing.                                                               */
/****************************************************************************/
void
bnx_disable_nvram_write(struct bnx_softc *sc)
{
	u_int32_t		val;

	DBPRINT(sc, BNX_VERBOSE,  "Disabling NVRAM write.\n");

	val = REG_RD(sc, BNX_MISC_CFG);
	REG_WR(sc, BNX_MISC_CFG, val & ~BNX_MISC_CFG_NVM_WR_EN);
}
#endif

/****************************************************************************/
/* Enable NVRAM access.                                                     */
/*                                                                          */
/* Before accessing NVRAM for read or write operations the caller must      */
/* enabled NVRAM access.                                                    */
/*                                                                          */
/* Returns:                                                                 */
/*   Nothing.                                                               */
/****************************************************************************/
void
bnx_enable_nvram_access(struct bnx_softc *sc)
{
	u_int32_t		val;

	DBPRINT(sc, BNX_VERBOSE, "Enabling NVRAM access.\n");

	val = REG_RD(sc, BNX_NVM_ACCESS_ENABLE);
	/* Enable both bits, even on read. */
	REG_WR(sc, BNX_NVM_ACCESS_ENABLE,
	    val | BNX_NVM_ACCESS_ENABLE_EN | BNX_NVM_ACCESS_ENABLE_WR_EN);
}

/****************************************************************************/
/* Disable NVRAM access.                                                    */
/*                                                                          */
/* When the caller is finished accessing NVRAM access must be disabled.     */
/*                                                                          */
/* Returns:                                                                 */
/*   Nothing.                                                               */
/****************************************************************************/
void
bnx_disable_nvram_access(struct bnx_softc *sc)
{
	u_int32_t		val;

	DBPRINT(sc, BNX_VERBOSE, "Disabling NVRAM access.\n");

	val = REG_RD(sc, BNX_NVM_ACCESS_ENABLE);

	/* Disable both bits, even after read. */
	REG_WR(sc, BNX_NVM_ACCESS_ENABLE,
	    val & ~(BNX_NVM_ACCESS_ENABLE_EN | BNX_NVM_ACCESS_ENABLE_WR_EN));
}

#ifdef BNX_NVRAM_WRITE_SUPPORT
/****************************************************************************/
/* Erase NVRAM page before writing.                                         */
/*                                                                          */
/* Non-buffered flash parts require that a page be erased before it is      */
/* written.                                                                 */
/*                                                                          */
/* Returns:                                                                 */
/*   0 on success, positive value on failure.                               */
/****************************************************************************/
int
bnx_nvram_erase_page(struct bnx_softc *sc, u_int32_t offset)
{
	u_int32_t		cmd;
	int			j;

	/* Buffered flash doesn't require an erase. */
	if (ISSET(sc->bnx_flash_info->flags, BNX_NV_BUFFERED))
		return (0);

	DBPRINT(sc, BNX_VERBOSE, "Erasing NVRAM page.\n");

	/* Build an erase command. */
	cmd = BNX_NVM_COMMAND_ERASE | BNX_NVM_COMMAND_WR |
	    BNX_NVM_COMMAND_DOIT;

	/*
	 * Clear the DONE bit separately, set the NVRAM address to erase,
	 * and issue the erase command.
	 */
	REG_WR(sc, BNX_NVM_COMMAND, BNX_NVM_COMMAND_DONE);
	REG_WR(sc, BNX_NVM_ADDR, offset & BNX_NVM_ADDR_NVM_ADDR_VALUE);
	REG_WR(sc, BNX_NVM_COMMAND, cmd);

	/* Wait for completion. */
	for (j = 0; j < NVRAM_TIMEOUT_COUNT; j++) {
		u_int32_t val;

		DELAY(5);

		val = REG_RD(sc, BNX_NVM_COMMAND);
		if (val & BNX_NVM_COMMAND_DONE)
			break;
	}

	if (j >= NVRAM_TIMEOUT_COUNT) {
		DBPRINT(sc, BNX_WARN, "Timeout erasing NVRAM.\n");
		return (EBUSY);
	}

	return (0);
}
#endif /* BNX_NVRAM_WRITE_SUPPORT */

/****************************************************************************/
/* Read a dword (32 bits) from NVRAM.                                       */
/*                                                                          */
/* Read a 32 bit word from NVRAM.  The caller is assumed to have already    */
/* obtained the NVRAM lock and enabled the controller for NVRAM access.     */
/*                                                                          */
/* Returns:                                                                 */
/*   0 on success and the 32 bit value read, positive value on failure.     */
/****************************************************************************/
int
bnx_nvram_read_dword(struct bnx_softc *sc, u_int32_t offset,
    u_int8_t *ret_val, u_int32_t cmd_flags)
{
	u_int32_t		cmd;
	int			i, rc = 0;

	/* Build the command word. */
	cmd = BNX_NVM_COMMAND_DOIT | cmd_flags;

	/* Calculate the offset for buffered flash if translation is used. */
	if (ISSET(sc->bnx_flash_info->flags, BNX_NV_TRANSLATE)) {
		offset = ((offset / sc->bnx_flash_info->page_size) <<
		    sc->bnx_flash_info->page_bits) +
		    (offset % sc->bnx_flash_info->page_size);
	}

	/*
	 * Clear the DONE bit separately, set the address to read,
	 * and issue the read.
	 */
	REG_WR(sc, BNX_NVM_COMMAND, BNX_NVM_COMMAND_DONE);
	REG_WR(sc, BNX_NVM_ADDR, offset & BNX_NVM_ADDR_NVM_ADDR_VALUE);
	REG_WR(sc, BNX_NVM_COMMAND, cmd);

	/* Wait for completion. */
	for (i = 0; i < NVRAM_TIMEOUT_COUNT; i++) {
		u_int32_t val;

		DELAY(5);

		val = REG_RD(sc, BNX_NVM_COMMAND);
		if (val & BNX_NVM_COMMAND_DONE) {
			val = REG_RD(sc, BNX_NVM_READ);

			val = bnx_be32toh(val);
			memcpy(ret_val, &val, 4);
			break;
		}
	}

	/* Check for errors. */
	if (i >= NVRAM_TIMEOUT_COUNT) {
		BNX_PRINTF(sc, "%s(%d): Timeout error reading NVRAM at "
		    "offset 0x%08X!\n", __FILE__, __LINE__, offset);
		rc = EBUSY;
	}

	return(rc);
}

#ifdef BNX_NVRAM_WRITE_SUPPORT
/****************************************************************************/
/* Write a dword (32 bits) to NVRAM.                                        */
/*                                                                          */
/* Write a 32 bit word to NVRAM.  The caller is assumed to have already     */
/* obtained the NVRAM lock, enabled the controller for NVRAM access, and    */
/* enabled NVRAM write access.                                              */
/*                                                                          */
/* Returns:                                                                 */
/*   0 on success, positive value on failure.                               */
/****************************************************************************/
int
bnx_nvram_write_dword(struct bnx_softc *sc, u_int32_t offset, u_int8_t *val,
    u_int32_t cmd_flags)
{
	u_int32_t		cmd, val32;
	int			j;

	/* Build the command word. */
	cmd = BNX_NVM_COMMAND_DOIT | BNX_NVM_COMMAND_WR | cmd_flags;

	/* Calculate the offset for buffered flash if translation is used. */
	if (ISSET(sc->bnx_flash_info->flags, BNX_NV_TRANSLATE)) {
		offset = ((offset / sc->bnx_flash_info->page_size) <<
		    sc->bnx_flash_info->page_bits) +
		    (offset % sc->bnx_flash_info->page_size);
	}

	/*
	 * Clear the DONE bit separately, convert NVRAM data to big-endian,
	 * set the NVRAM address to write, and issue the write command
	 */
	REG_WR(sc, BNX_NVM_COMMAND, BNX_NVM_COMMAND_DONE);
	memcpy(&val32, val, 4);
	val32 = htobe32(val32);
	REG_WR(sc, BNX_NVM_WRITE, val32);
	REG_WR(sc, BNX_NVM_ADDR, offset & BNX_NVM_ADDR_NVM_ADDR_VALUE);
	REG_WR(sc, BNX_NVM_COMMAND, cmd);

	/* Wait for completion. */
	for (j = 0; j < NVRAM_TIMEOUT_COUNT; j++) {
		DELAY(5);

		if (REG_RD(sc, BNX_NVM_COMMAND) & BNX_NVM_COMMAND_DONE)
			break;
	}
	if (j >= NVRAM_TIMEOUT_COUNT) {
		BNX_PRINTF(sc, "%s(%d): Timeout error writing NVRAM at "
		    "offset 0x%08X\n", __FILE__, __LINE__, offset);
		return (EBUSY);
	}

	return (0);
}
#endif /* BNX_NVRAM_WRITE_SUPPORT */

/****************************************************************************/
/* Initialize NVRAM access.                                                 */
/*                                                                          */
/* Identify the NVRAM device in use and prepare the NVRAM interface to      */
/* access that device.                                                      */
/*                                                                          */
/* Returns:                                                                 */
/*   0 on success, positive value on failure.                               */
/****************************************************************************/
int
bnx_init_nvram(struct bnx_softc *sc)
{
	u_int32_t		val;
	int			j, entry_count, rc = 0;
	struct flash_spec	*flash;

	DBPRINT(sc,BNX_VERBOSE_RESET, "Entering %s()\n", __FUNCTION__);

	if (BNX_CHIP_NUM(sc) == BNX_CHIP_NUM_5709) {
		sc->bnx_flash_info = &flash_5709;
		goto bnx_init_nvram_get_flash_size;
	}

	/* Determine the selected interface. */
	val = REG_RD(sc, BNX_NVM_CFG1);

	entry_count = sizeof(flash_table) / sizeof(struct flash_spec);

	/*
	 * Flash reconfiguration is required to support additional
	 * NVRAM devices not directly supported in hardware.
	 * Check if the flash interface was reconfigured
	 * by the bootcode.
	 */

	if (val & 0x40000000) {
		/* Flash interface reconfigured by bootcode. */

		DBPRINT(sc,BNX_INFO_LOAD, 
			"bnx_init_nvram(): Flash WAS reconfigured.\n");

		for (j = 0, flash = &flash_table[0]; j < entry_count;
		     j++, flash++) {
			if ((val & FLASH_BACKUP_STRAP_MASK) ==
			    (flash->config1 & FLASH_BACKUP_STRAP_MASK)) {
				sc->bnx_flash_info = flash;
				break;
			}
		}
	} else {
		/* Flash interface not yet reconfigured. */
		u_int32_t mask;

		DBPRINT(sc,BNX_INFO_LOAD, 
			"bnx_init_nvram(): Flash was NOT reconfigured.\n");

		if (val & (1 << 23))
			mask = FLASH_BACKUP_STRAP_MASK;
		else
			mask = FLASH_STRAP_MASK;

		/* Look for the matching NVRAM device configuration data. */
		for (j = 0, flash = &flash_table[0]; j < entry_count;
		    j++, flash++) {
			/* Check if the dev matches any of the known devices. */
			if ((val & mask) == (flash->strapping & mask)) {
				/* Found a device match. */
				sc->bnx_flash_info = flash;

				/* Request access to the flash interface. */
				if ((rc = bnx_acquire_nvram_lock(sc)) != 0)
					return (rc);

				/* Reconfigure the flash interface. */
				bnx_enable_nvram_access(sc);
				REG_WR(sc, BNX_NVM_CFG1, flash->config1);
				REG_WR(sc, BNX_NVM_CFG2, flash->config2);
				REG_WR(sc, BNX_NVM_CFG3, flash->config3);
				REG_WR(sc, BNX_NVM_WRITE1, flash->write1);
				bnx_disable_nvram_access(sc);
				bnx_release_nvram_lock(sc);

				break;
			}
		}
	}

	/* Check if a matching device was found. */
	if (j == entry_count) {
		sc->bnx_flash_info = NULL;
		BNX_PRINTF(sc, "%s(%d): Unknown Flash NVRAM found!\n",
			__FILE__, __LINE__);
		rc = ENODEV;
	}

bnx_init_nvram_get_flash_size:
	/* Write the flash config data to the shared memory interface. */
	val = REG_RD_IND(sc, sc->bnx_shmem_base + BNX_SHARED_HW_CFG_CONFIG2);
	val &= BNX_SHARED_HW_CFG2_NVM_SIZE_MASK;
	if (val)
		sc->bnx_flash_size = val;
	else
		sc->bnx_flash_size = sc->bnx_flash_info->total_size;

	DBPRINT(sc, BNX_INFO_LOAD, "bnx_init_nvram() flash->total_size = "
	    "0x%08X\n", sc->bnx_flash_info->total_size);

	DBPRINT(sc, BNX_VERBOSE_RESET, "Exiting %s()\n", __FUNCTION__);

	return (rc);
}

/****************************************************************************/
/* Read an arbitrary range of data from NVRAM.                              */
/*                                                                          */
/* Prepares the NVRAM interface for access and reads the requested data     */
/* into the supplied buffer.                                                */
/*                                                                          */
/* Returns:                                                                 */
/*   0 on success and the data read, positive value on failure.             */
/****************************************************************************/
int
bnx_nvram_read(struct bnx_softc *sc, u_int32_t offset, u_int8_t *ret_buf,
    int buf_size)
{
	int			rc = 0;
	u_int32_t		cmd_flags, offset32, len32, extra;

	if (buf_size == 0)
		return (0);

	/* Request access to the flash interface. */
	if ((rc = bnx_acquire_nvram_lock(sc)) != 0)
		return (rc);

	/* Enable access to flash interface */
	bnx_enable_nvram_access(sc);

	len32 = buf_size;
	offset32 = offset;
	extra = 0;

	cmd_flags = 0;

	if (offset32 & 3) {
		u_int8_t buf[4];
		u_int32_t pre_len;

		offset32 &= ~3;
		pre_len = 4 - (offset & 3);

		if (pre_len >= len32) {
			pre_len = len32;
			cmd_flags =
			    BNX_NVM_COMMAND_FIRST | BNX_NVM_COMMAND_LAST;
		} else
			cmd_flags = BNX_NVM_COMMAND_FIRST;

		rc = bnx_nvram_read_dword(sc, offset32, buf, cmd_flags);

		if (rc)
			return (rc);

		memcpy(ret_buf, buf + (offset & 3), pre_len);

		offset32 += 4;
		ret_buf += pre_len;
		len32 -= pre_len;
	}

	if (len32 & 3) {
		extra = 4 - (len32 & 3);
		len32 = (len32 + 4) & ~3;
	}

	if (len32 == 4) {
		u_int8_t buf[4];

		if (cmd_flags)
			cmd_flags = BNX_NVM_COMMAND_LAST;
		else
			cmd_flags =
			    BNX_NVM_COMMAND_FIRST | BNX_NVM_COMMAND_LAST;

		rc = bnx_nvram_read_dword(sc, offset32, buf, cmd_flags);

		memcpy(ret_buf, buf, 4 - extra);
	} else if (len32 > 0) {
		u_int8_t buf[4];

		/* Read the first word. */
		if (cmd_flags)
			cmd_flags = 0;
		else
			cmd_flags = BNX_NVM_COMMAND_FIRST;

		rc = bnx_nvram_read_dword(sc, offset32, ret_buf, cmd_flags);

		/* Advance to the next dword. */
		offset32 += 4;
		ret_buf += 4;
		len32 -= 4;

		while (len32 > 4 && rc == 0) {
			rc = bnx_nvram_read_dword(sc, offset32, ret_buf, 0);

			/* Advance to the next dword. */
			offset32 += 4;
			ret_buf += 4;
			len32 -= 4;
		}

		if (rc)
			return (rc);

		cmd_flags = BNX_NVM_COMMAND_LAST;
		rc = bnx_nvram_read_dword(sc, offset32, buf, cmd_flags);

		memcpy(ret_buf, buf, 4 - extra);
	}

	/* Disable access to flash interface and release the lock. */
	bnx_disable_nvram_access(sc);
	bnx_release_nvram_lock(sc);

	return (rc);
}

#ifdef BNX_NVRAM_WRITE_SUPPORT
/****************************************************************************/
/* Write an arbitrary range of data from NVRAM.                             */
/*                                                                          */
/* Prepares the NVRAM interface for write access and writes the requested   */
/* data from the supplied buffer.  The caller is responsible for            */
/* calculating any appropriate CRCs.                                        */
/*                                                                          */
/* Returns:                                                                 */
/*   0 on success, positive value on failure.                               */
/****************************************************************************/
int
bnx_nvram_write(struct bnx_softc *sc, u_int32_t offset, u_int8_t *data_buf,
    int buf_size)
{
	u_int32_t		written, offset32, len32;
	u_int8_t		*buf, start[4], end[4];
	int			rc = 0;
	int			align_start, align_end;

	buf = data_buf;
	offset32 = offset;
	len32 = buf_size;
	align_start = align_end = 0;

	if ((align_start = (offset32 & 3))) {
		offset32 &= ~3;
		len32 += align_start;
		if ((rc = bnx_nvram_read(sc, offset32, start, 4)))
			return (rc);
	}

	if (len32 & 3) {
		if ((len32 > 4) || !align_start) {
			align_end = 4 - (len32 & 3);
			len32 += align_end;
			if ((rc = bnx_nvram_read(sc, offset32 + len32 - 4,
			    end, 4))) {
				return (rc);
			}
		}
	}

	if (align_start || align_end) {
		buf = malloc(len32, M_DEVBUF, M_NOWAIT);
		if (buf == 0)
			return (ENOMEM);

		if (align_start)
			memcpy(buf, start, 4);

		if (align_end)
			memcpy(buf + len32 - 4, end, 4);

		memcpy(buf + align_start, data_buf, buf_size);
	}

	written = 0;
	while ((written < len32) && (rc == 0)) {
		u_int32_t page_start, page_end, data_start, data_end;
		u_int32_t addr, cmd_flags;
		int i;
		u_int8_t flash_buffer[264];

	    /* Find the page_start addr */
		page_start = offset32 + written;
		page_start -= (page_start % sc->bnx_flash_info->page_size);
		/* Find the page_end addr */
		page_end = page_start + sc->bnx_flash_info->page_size;
		/* Find the data_start addr */
		data_start = (written == 0) ? offset32 : page_start;
		/* Find the data_end addr */
		data_end = (page_end > offset32 + len32) ?
		    (offset32 + len32) : page_end;

		/* Request access to the flash interface. */
		if ((rc = bnx_acquire_nvram_lock(sc)) != 0)
			goto nvram_write_end;

		/* Enable access to flash interface */
		bnx_enable_nvram_access(sc);

		cmd_flags = BNX_NVM_COMMAND_FIRST;
		if (!ISSET(sc->bnx_flash_info->flags, BNX_NV_BUFFERED)) {
			int j;

			/* Read the whole page into the buffer
			 * (non-buffer flash only) */
			for (j = 0; j < sc->bnx_flash_info->page_size; j += 4) {
				if (j == (sc->bnx_flash_info->page_size - 4))
					cmd_flags |= BNX_NVM_COMMAND_LAST;

				rc = bnx_nvram_read_dword(sc,
					page_start + j,
					&flash_buffer[j],
					cmd_flags);

				if (rc)
					goto nvram_write_end;

				cmd_flags = 0;
			}
		}

		/* Enable writes to flash interface (unlock write-protect) */
		if ((rc = bnx_enable_nvram_write(sc)) != 0)
			goto nvram_write_end;

		/* Erase the page */
		if ((rc = bnx_nvram_erase_page(sc, page_start)) != 0)
			goto nvram_write_end;

		/* Re-enable the write again for the actual write */
		bnx_enable_nvram_write(sc);

		/* Loop to write back the buffer data from page_start to
		 * data_start */
		i = 0;
		if (!ISSET(sc->bnx_flash_info->flags, BNX_NV_BUFFERED)) {
			for (addr = page_start; addr < data_start;
				addr += 4, i += 4) {

				rc = bnx_nvram_write_dword(sc, addr,
				    &flash_buffer[i], cmd_flags);

				if (rc != 0)
					goto nvram_write_end;

				cmd_flags = 0;
			}
		}

		/* Loop to write the new data from data_start to data_end */
		for (addr = data_start; addr < data_end; addr += 4, i++) {
			if ((addr == page_end - 4) ||
			    (ISSET(sc->bnx_flash_info->flags, BNX_NV_BUFFERED)
			    && (addr == data_end - 4))) {

				cmd_flags |= BNX_NVM_COMMAND_LAST;
			}

			rc = bnx_nvram_write_dword(sc, addr, buf, cmd_flags);

			if (rc != 0)
				goto nvram_write_end;

			cmd_flags = 0;
			buf += 4;
		}

		/* Loop to write back the buffer data from data_end
		 * to page_end */
		if (!ISSET(sc->bnx_flash_info->flags, BNX_NV_BUFFERED)) {
			for (addr = data_end; addr < page_end;
			    addr += 4, i += 4) {

				if (addr == page_end-4)
					cmd_flags = BNX_NVM_COMMAND_LAST;

				rc = bnx_nvram_write_dword(sc, addr,
				    &flash_buffer[i], cmd_flags);

				if (rc != 0)
					goto nvram_write_end;

				cmd_flags = 0;
			}
		}

		/* Disable writes to flash interface (lock write-protect) */
		bnx_disable_nvram_write(sc);

		/* Disable access to flash interface */
		bnx_disable_nvram_access(sc);
		bnx_release_nvram_lock(sc);

		/* Increment written */
		written += data_end - data_start;
	}

nvram_write_end:
	if (align_start || align_end)
		free(buf, M_DEVBUF, len32);

	return (rc);
}
#endif /* BNX_NVRAM_WRITE_SUPPORT */

/****************************************************************************/
/* Verifies that NVRAM is accessible and contains valid data.               */
/*                                                                          */
/* Reads the configuration data from NVRAM and verifies that the CRC is     */
/* correct.                                                                 */
/*                                                                          */
/* Returns:                                                                 */
/*   0 on success, positive value on failure.                               */
/****************************************************************************/
int
bnx_nvram_test(struct bnx_softc *sc)
{
	u_int32_t		buf[BNX_NVRAM_SIZE / 4];
	u_int8_t		*data = (u_int8_t *) buf;
	int			rc = 0;
	u_int32_t		magic, csum;

	/*
	 * Check that the device NVRAM is valid by reading
	 * the magic value at offset 0.
	 */
	if ((rc = bnx_nvram_read(sc, 0, data, 4)) != 0)
		goto bnx_nvram_test_done;

	magic = bnx_be32toh(buf[0]);
	if (magic != BNX_NVRAM_MAGIC) {
		rc = ENODEV;
		BNX_PRINTF(sc, "%s(%d): Invalid NVRAM magic value! "
		    "Expected: 0x%08X, Found: 0x%08X\n",
		    __FILE__, __LINE__, BNX_NVRAM_MAGIC, magic);
		goto bnx_nvram_test_done;
	}

	/*
	 * Verify that the device NVRAM includes valid
	 * configuration data.
	 */
	if ((rc = bnx_nvram_read(sc, 0x100, data, BNX_NVRAM_SIZE)) != 0)
		goto bnx_nvram_test_done;

	csum = ether_crc32_le(data, 0x100);
	if (csum != BNX_CRC32_RESIDUAL) {
		rc = ENODEV;
		BNX_PRINTF(sc, "%s(%d): Invalid Manufacturing Information "
		    "NVRAM CRC! Expected: 0x%08X, Found: 0x%08X\n",
		    __FILE__, __LINE__, BNX_CRC32_RESIDUAL, csum);
		goto bnx_nvram_test_done;
	}

	csum = ether_crc32_le(data + 0x100, 0x100);
	if (csum != BNX_CRC32_RESIDUAL) {
		BNX_PRINTF(sc, "%s(%d): Invalid Feature Configuration "
		    "Information NVRAM CRC! Expected: 0x%08X, Found: 08%08X\n",
		    __FILE__, __LINE__, BNX_CRC32_RESIDUAL, csum);
		rc = ENODEV;
	}

bnx_nvram_test_done:
	return (rc);
}

/****************************************************************************/
/* Identifies the current media type of the controller and sets the PHY     */
/* address.                                                                 */
/*                                                                          */
/* Returns:                                                                 */
/*   Nothing.                                                               */
/****************************************************************************/
void
bnx_get_media(struct bnx_softc *sc)
{
	u_int32_t val;
 
	sc->bnx_phy_addr = 1;
 
	if (BNX_CHIP_NUM(sc) == BNX_CHIP_NUM_5709) {
		u_int32_t val = REG_RD(sc, BNX_MISC_DUAL_MEDIA_CTRL);
		u_int32_t bond_id = val & BNX_MISC_DUAL_MEDIA_CTRL_BOND_ID;
		u_int32_t strap;

		/*
		 * The BCM5709S is software configurable
		 * for Copper or SerDes operation.
		 */
		if (bond_id == BNX_MISC_DUAL_MEDIA_CTRL_BOND_ID_C) {
			DBPRINT(sc, BNX_INFO_LOAD,
			    "5709 bonded for copper.\n");
			goto bnx_get_media_exit;
		} else if (bond_id == BNX_MISC_DUAL_MEDIA_CTRL_BOND_ID_S) {
			DBPRINT(sc, BNX_INFO_LOAD,
			    "5709 bonded for dual media.\n");
			sc->bnx_phy_flags |= BNX_PHY_SERDES_FLAG;
			goto bnx_get_media_exit;
		}

		if (val & BNX_MISC_DUAL_MEDIA_CTRL_STRAP_OVERRIDE)
			strap = (val & BNX_MISC_DUAL_MEDIA_CTRL_PHY_CTRL) >> 21;
		else {
			strap = (val & BNX_MISC_DUAL_MEDIA_CTRL_PHY_CTRL_STRAP)
			    >> 8;
		}

		if (sc->bnx_pa.pa_function == 0) {
			switch (strap) {
			case 0x4:
			case 0x5:
			case 0x6:
				DBPRINT(sc, BNX_INFO_LOAD, 
					"BCM5709 s/w configured for SerDes.\n");
				sc->bnx_phy_flags |= BNX_PHY_SERDES_FLAG;
				break;
			default:
				DBPRINT(sc, BNX_INFO_LOAD, 
					"BCM5709 s/w configured for Copper.\n");
			}
		} else {
			switch (strap) {
			case 0x1:
			case 0x2:
			case 0x4:
				DBPRINT(sc, BNX_INFO_LOAD, 
					"BCM5709 s/w configured for SerDes.\n");
				sc->bnx_phy_flags |= BNX_PHY_SERDES_FLAG;
				break;
			default:
				DBPRINT(sc, BNX_INFO_LOAD, 
					"BCM5709 s/w configured for Copper.\n");
			}
		}

	} else if (BNX_CHIP_BOND_ID(sc) & BNX_CHIP_BOND_ID_SERDES_BIT)
		sc->bnx_phy_flags |= BNX_PHY_SERDES_FLAG;

	if (sc->bnx_phy_flags & BNX_PHY_SERDES_FLAG) {
		sc->bnx_flags |= BNX_NO_WOL_FLAG;

		if (BNX_CHIP_NUM(sc) == BNX_CHIP_NUM_5709)
			sc->bnx_phy_flags |= BNX_PHY_IEEE_CLAUSE_45_FLAG;

		/*
		 * The BCM5708S, BCM5709S, and BCM5716S controllers use a
		 * separate PHY for SerDes.
		 */
		if (BNX_CHIP_NUM(sc) != BNX_CHIP_NUM_5706) {
			sc->bnx_phy_addr = 2;
			val = REG_RD_IND(sc, sc->bnx_shmem_base +
				 BNX_SHARED_HW_CFG_CONFIG);
			if (val & BNX_SHARED_HW_CFG_PHY_2_5G) {
				sc->bnx_phy_flags |= BNX_PHY_2_5G_CAPABLE_FLAG;
				DBPRINT(sc, BNX_INFO_LOAD,
				    "Found 2.5Gb capable adapter\n");
			}
		}
	} else if ((BNX_CHIP_NUM(sc) == BNX_CHIP_NUM_5706) ||
		   (BNX_CHIP_NUM(sc) == BNX_CHIP_NUM_5708))
		sc->bnx_phy_flags |= BNX_PHY_CRC_FIX_FLAG;

bnx_get_media_exit:
	DBPRINT(sc, (BNX_INFO_LOAD | BNX_INFO_PHY), 
		"Using PHY address %d.\n", sc->bnx_phy_addr);
}

/****************************************************************************/
/* Performs PHY initialization required before MII drivers access the       */
/* device.                                                                  */
/*                                                                          */
/* Returns:                                                                 */
/*   Nothing.                                                               */
/****************************************************************************/
void
bnx_init_media(struct bnx_softc *sc)
{
	if (sc->bnx_phy_flags & BNX_PHY_IEEE_CLAUSE_45_FLAG) {
		/*
		 * Configure the BCM5709S / BCM5716S PHYs to use traditional
		 * IEEE Clause 22 method. Otherwise we have no way to attach
		 * the PHY to the mii(4) layer. PHY specific configuration
		 * is done by the mii(4) layer.
		 */

		/* Select auto-negotiation MMD of the PHY. */
		bnx_miibus_write_reg(&sc->bnx_dev, sc->bnx_phy_addr,
		    BRGPHY_BLOCK_ADDR, BRGPHY_BLOCK_ADDR_ADDR_EXT);

		bnx_miibus_write_reg(&sc->bnx_dev, sc->bnx_phy_addr,
		    BRGPHY_ADDR_EXT, BRGPHY_ADDR_EXT_AN_MMD);

		bnx_miibus_write_reg(&sc->bnx_dev, sc->bnx_phy_addr,
		    BRGPHY_BLOCK_ADDR, BRGPHY_BLOCK_ADDR_COMBO_IEEE0);
	}
}

/****************************************************************************/
/* Free any DMA memory owned by the driver.                                 */
/*                                                                          */
/* Scans through each data structre that requires DMA memory and frees      */
/* the memory if allocated.                                                 */
/*                                                                          */
/* Returns:                                                                 */
/*   Nothing.                                                               */
/****************************************************************************/
void
bnx_dma_free(struct bnx_softc *sc)
{
	int			i;

	DBPRINT(sc,BNX_VERBOSE_RESET, "Entering %s()\n", __FUNCTION__);

	/* Destroy the status block. */
	if (sc->status_block != NULL && sc->status_map != NULL) {
		bus_dmamap_sync(sc->bnx_dmatag, sc->status_map, 0,
		    sc->status_map->dm_mapsize, BUS_DMASYNC_POSTREAD);
		bus_dmamap_unload(sc->bnx_dmatag, sc->status_map);
		bus_dmamem_unmap(sc->bnx_dmatag, (caddr_t)sc->status_block,
		    BNX_STATUS_BLK_SZ);		
		bus_dmamem_free(sc->bnx_dmatag, &sc->status_seg,
		    sc->status_rseg);
		bus_dmamap_destroy(sc->bnx_dmatag, sc->status_map);
		sc->status_block = NULL;
		sc->status_map = NULL;
	}

	/* Destroy the statistics block. */
	if (sc->stats_block != NULL && sc->stats_map != NULL) {
		bus_dmamap_unload(sc->bnx_dmatag, sc->stats_map);
		bus_dmamem_unmap(sc->bnx_dmatag, (caddr_t)sc->stats_block,
		    BNX_STATS_BLK_SZ);		
		bus_dmamem_free(sc->bnx_dmatag, &sc->stats_seg,
		    sc->stats_rseg);
		bus_dmamap_destroy(sc->bnx_dmatag, sc->stats_map);
		sc->stats_block = NULL;
		sc->stats_map = NULL;
	}

	/* Free, unmap and destroy all context memory pages. */
	if (BNX_CHIP_NUM(sc) == BNX_CHIP_NUM_5709) {
		for (i = 0; i < sc->ctx_pages; i++) {
			if (sc->ctx_block[i] != NULL) {
				bus_dmamap_unload(sc->bnx_dmatag,
				    sc->ctx_map[i]);
				bus_dmamem_unmap(sc->bnx_dmatag,
				    (caddr_t)sc->ctx_block[i],
				    BCM_PAGE_SIZE);
				bus_dmamem_free(sc->bnx_dmatag,
				    &sc->ctx_segs[i], sc->ctx_rsegs[i]);
				bus_dmamap_destroy(sc->bnx_dmatag,
				    sc->ctx_map[i]);
				sc->ctx_block[i] = NULL;
			}
		}
	}

	/* Free, unmap and destroy all TX buffer descriptor chain pages. */
	for (i = 0; i < TX_PAGES; i++ ) {
		if (sc->tx_bd_chain[i] != NULL &&
		    sc->tx_bd_chain_map[i] != NULL) {
			bus_dmamap_unload(sc->bnx_dmatag,
			    sc->tx_bd_chain_map[i]);
			bus_dmamem_unmap(sc->bnx_dmatag,
			    (caddr_t)sc->tx_bd_chain[i], BNX_TX_CHAIN_PAGE_SZ);
			bus_dmamem_free(sc->bnx_dmatag, &sc->tx_bd_chain_seg[i],
			    sc->tx_bd_chain_rseg[i]);
			bus_dmamap_destroy(sc->bnx_dmatag,
			    sc->tx_bd_chain_map[i]);
			sc->tx_bd_chain[i] = NULL;
			sc->tx_bd_chain_map[i] = NULL;
		}
	}

	/* Unload and destroy the TX mbuf maps. */
	for (i = 0; i < TOTAL_TX_BD; i++) {
		bus_dmamap_unload(sc->bnx_dmatag, sc->tx_mbuf_map[i]);
		bus_dmamap_destroy(sc->bnx_dmatag, sc->tx_mbuf_map[i]);
	}

	/* Free, unmap and destroy all RX buffer descriptor chain pages. */
	for (i = 0; i < RX_PAGES; i++ ) {
		if (sc->rx_bd_chain[i] != NULL &&
		    sc->rx_bd_chain_map[i] != NULL) {
			bus_dmamap_unload(sc->bnx_dmatag,
			    sc->rx_bd_chain_map[i]);
			bus_dmamem_unmap(sc->bnx_dmatag,
			    (caddr_t)sc->rx_bd_chain[i], BNX_RX_CHAIN_PAGE_SZ);
			bus_dmamem_free(sc->bnx_dmatag, &sc->rx_bd_chain_seg[i],
			    sc->rx_bd_chain_rseg[i]);

			bus_dmamap_destroy(sc->bnx_dmatag,
			    sc->rx_bd_chain_map[i]);
			sc->rx_bd_chain[i] = NULL;
			sc->rx_bd_chain_map[i] = NULL;
		}
	}

	/* Unload and destroy the RX mbuf maps. */
	for (i = 0; i < TOTAL_RX_BD; i++) {
		if (sc->rx_mbuf_map[i] != NULL) {
			bus_dmamap_unload(sc->bnx_dmatag, sc->rx_mbuf_map[i]);
			bus_dmamap_destroy(sc->bnx_dmatag, sc->rx_mbuf_map[i]);
		}
	}

	DBPRINT(sc, BNX_VERBOSE_RESET, "Exiting %s()\n", __FUNCTION__);
}

/****************************************************************************/
/* Allocate any DMA memory needed by the driver.                            */
/*                                                                          */
/* Allocates DMA memory needed for the various global structures needed by  */
/* hardware.                                                                */
/*                                                                          */
/* Returns:                                                                 */
/*   0 for success, positive value for failure.                             */
/****************************************************************************/
int
bnx_dma_alloc(struct bnx_softc *sc)
{
	int			i, rc = 0;

	DBPRINT(sc, BNX_VERBOSE_RESET, "Entering %s()\n", __FUNCTION__);

	/*
	 * Create DMA maps for the TX buffer mbufs.
	 */
	for (i = 0; i < TOTAL_TX_BD; i++) {
		if (bus_dmamap_create(sc->bnx_dmatag,
		    MCLBYTES * BNX_MAX_SEGMENTS, BNX_MAX_SEGMENTS,
		    MCLBYTES, 0, BUS_DMA_NOWAIT, &sc->tx_mbuf_map[i])) {
			printf(": Could not create Tx mbuf %d DMA map!\n", 1);
			rc = ENOMEM;
			goto bnx_dma_alloc_exit;
		}
	}

	/*
	 * Allocate DMA memory for the status block, map the memory into DMA
	 * space, and fetch the physical address of the block.
	 */
	if (bus_dmamap_create(sc->bnx_dmatag, BNX_STATUS_BLK_SZ, 1,
	    BNX_STATUS_BLK_SZ, 0, BUS_DMA_NOWAIT, &sc->status_map)) {
		printf(": Could not create status block DMA map!\n");
		rc = ENOMEM;
		goto bnx_dma_alloc_exit;
	}

	if (bus_dmamem_alloc(sc->bnx_dmatag, BNX_STATUS_BLK_SZ,
	    BNX_DMA_ALIGN, BNX_DMA_BOUNDARY, &sc->status_seg, 1,
	    &sc->status_rseg, BUS_DMA_NOWAIT | BUS_DMA_ZERO)) {
		printf(": Could not allocate status block DMA memory!\n");
		rc = ENOMEM;
		goto bnx_dma_alloc_exit;
	}

	if (bus_dmamem_map(sc->bnx_dmatag, &sc->status_seg, sc->status_rseg,
	    BNX_STATUS_BLK_SZ, (caddr_t *)&sc->status_block, BUS_DMA_NOWAIT)) {
		printf(": Could not map status block DMA memory!\n");
		rc = ENOMEM;
		goto bnx_dma_alloc_exit;
	}

	if (bus_dmamap_load(sc->bnx_dmatag, sc->status_map,
	    sc->status_block, BNX_STATUS_BLK_SZ, NULL, BUS_DMA_NOWAIT)) {
		printf(": Could not load status block DMA memory!\n");
		rc = ENOMEM;
		goto bnx_dma_alloc_exit;
	}

	bus_dmamap_sync(sc->bnx_dmatag, sc->status_map, 0,
	    sc->status_map->dm_mapsize, BUS_DMASYNC_PREREAD);

	sc->status_block_paddr = sc->status_map->dm_segs[0].ds_addr;

	/* DRC - Fix for 64 bit addresses. */
	DBPRINT(sc, BNX_INFO, "status_block_paddr = 0x%08X\n",
		(u_int32_t) sc->status_block_paddr);

	/* BCM5709 uses host memory as cache for context memory. */
	if (BNX_CHIP_NUM(sc) == BNX_CHIP_NUM_5709) {
		sc->ctx_pages = 0x2000 / BCM_PAGE_SIZE;
		if (sc->ctx_pages == 0)
			sc->ctx_pages = 1;
		if (sc->ctx_pages > 4) /* XXX */
			sc->ctx_pages = 4;

		DBRUNIF((sc->ctx_pages > 512),
			BCE_PRINTF("%s(%d): Too many CTX pages! %d > 512\n",
				__FILE__, __LINE__, sc->ctx_pages));


		for (i = 0; i < sc->ctx_pages; i++) {
			if (bus_dmamap_create(sc->bnx_dmatag, BCM_PAGE_SIZE,
			    1, BCM_PAGE_SIZE, BNX_DMA_BOUNDARY,
			    BUS_DMA_NOWAIT | BUS_DMA_ALLOCNOW,
			    &sc->ctx_map[i]) != 0) {
				rc = ENOMEM;
				goto bnx_dma_alloc_exit;
			}

			if (bus_dmamem_alloc(sc->bnx_dmatag, BCM_PAGE_SIZE,
			    BCM_PAGE_SIZE, BNX_DMA_BOUNDARY, &sc->ctx_segs[i],
			    1, &sc->ctx_rsegs[i], BUS_DMA_NOWAIT) != 0) {
				rc = ENOMEM;
				goto bnx_dma_alloc_exit;
			}

			if (bus_dmamem_map(sc->bnx_dmatag, &sc->ctx_segs[i],
			    sc->ctx_rsegs[i], BCM_PAGE_SIZE,
			    (caddr_t *)&sc->ctx_block[i],
			    BUS_DMA_NOWAIT) != 0) {
				rc = ENOMEM;
				goto bnx_dma_alloc_exit;
			}

			if (bus_dmamap_load(sc->bnx_dmatag, sc->ctx_map[i],
			    sc->ctx_block[i], BCM_PAGE_SIZE, NULL,
			    BUS_DMA_NOWAIT) != 0) {
				rc = ENOMEM;
				goto bnx_dma_alloc_exit;
			}

			bzero(sc->ctx_block[i], BCM_PAGE_SIZE);
		}
	}

	/*
	 * Allocate DMA memory for the statistics block, map the memory into
	 * DMA space, and fetch the physical address of the block.
	 */
	if (bus_dmamap_create(sc->bnx_dmatag, BNX_STATS_BLK_SZ, 1,
	    BNX_STATS_BLK_SZ, 0, BUS_DMA_NOWAIT, &sc->stats_map)) {
		printf(": Could not create stats block DMA map!\n");
		rc = ENOMEM;
		goto bnx_dma_alloc_exit;
	}

	if (bus_dmamem_alloc(sc->bnx_dmatag, BNX_STATS_BLK_SZ,
	    BNX_DMA_ALIGN, BNX_DMA_BOUNDARY, &sc->stats_seg, 1,
	    &sc->stats_rseg, BUS_DMA_NOWAIT | BUS_DMA_ZERO)) {
		printf(": Could not allocate stats block DMA memory!\n");
		rc = ENOMEM;
		goto bnx_dma_alloc_exit;
	}

	if (bus_dmamem_map(sc->bnx_dmatag, &sc->stats_seg, sc->stats_rseg,
	    BNX_STATS_BLK_SZ, (caddr_t *)&sc->stats_block, BUS_DMA_NOWAIT)) {
		printf(": Could not map stats block DMA memory!\n");
		rc = ENOMEM;
		goto bnx_dma_alloc_exit;
	}

	if (bus_dmamap_load(sc->bnx_dmatag, sc->stats_map,
	    sc->stats_block, BNX_STATS_BLK_SZ, NULL, BUS_DMA_NOWAIT)) {
		printf(": Could not load status block DMA memory!\n");
		rc = ENOMEM;
		goto bnx_dma_alloc_exit;
	}

	sc->stats_block_paddr = sc->stats_map->dm_segs[0].ds_addr;

	/* DRC - Fix for 64 bit address. */
	DBPRINT(sc,BNX_INFO, "stats_block_paddr = 0x%08X\n", 
	    (u_int32_t) sc->stats_block_paddr);

	/*
	 * Allocate DMA memory for the TX buffer descriptor chain,
	 * and fetch the physical address of the block.
	 */
	for (i = 0; i < TX_PAGES; i++) {
		if (bus_dmamap_create(sc->bnx_dmatag, BNX_TX_CHAIN_PAGE_SZ, 1,
		    BNX_TX_CHAIN_PAGE_SZ, 0, BUS_DMA_NOWAIT,
		    &sc->tx_bd_chain_map[i])) {
			printf(": Could not create Tx desc %d DMA map!\n", i);
			rc = ENOMEM;
			goto bnx_dma_alloc_exit;
		}

		if (bus_dmamem_alloc(sc->bnx_dmatag, BNX_TX_CHAIN_PAGE_SZ,
		    BCM_PAGE_SIZE, BNX_DMA_BOUNDARY, &sc->tx_bd_chain_seg[i], 1,
		    &sc->tx_bd_chain_rseg[i], BUS_DMA_NOWAIT)) {
			printf(": Could not allocate TX desc %d DMA memory!\n",
			    i);
			rc = ENOMEM;
			goto bnx_dma_alloc_exit;
		}

		if (bus_dmamem_map(sc->bnx_dmatag, &sc->tx_bd_chain_seg[i],
		    sc->tx_bd_chain_rseg[i], BNX_TX_CHAIN_PAGE_SZ,
		    (caddr_t *)&sc->tx_bd_chain[i], BUS_DMA_NOWAIT)) {
			printf(": Could not map TX desc %d DMA memory!\n", i);
			rc = ENOMEM;
			goto bnx_dma_alloc_exit;
		}

		if (bus_dmamap_load(sc->bnx_dmatag, sc->tx_bd_chain_map[i],
		    (caddr_t)sc->tx_bd_chain[i], BNX_TX_CHAIN_PAGE_SZ, NULL,
		    BUS_DMA_NOWAIT)) {
			printf(": Could not load TX desc %d DMA memory!\n", i);
			rc = ENOMEM;
			goto bnx_dma_alloc_exit;
		}

		sc->tx_bd_chain_paddr[i] =
		    sc->tx_bd_chain_map[i]->dm_segs[0].ds_addr;

		/* DRC - Fix for 64 bit systems. */
		DBPRINT(sc, BNX_INFO, "tx_bd_chain_paddr[%d] = 0x%08X\n", 
		    i, (u_int32_t) sc->tx_bd_chain_paddr[i]);
	}

	/*
	 * Allocate DMA memory for the Rx buffer descriptor chain,
	 * and fetch the physical address of the block.
	 */
	for (i = 0; i < RX_PAGES; i++) {
		if (bus_dmamap_create(sc->bnx_dmatag, BNX_RX_CHAIN_PAGE_SZ, 1,
		    BNX_RX_CHAIN_PAGE_SZ, 0, BUS_DMA_NOWAIT,
		    &sc->rx_bd_chain_map[i])) {
			printf(": Could not create Rx desc %d DMA map!\n", i);
			rc = ENOMEM;
			goto bnx_dma_alloc_exit;
		}

		if (bus_dmamem_alloc(sc->bnx_dmatag, BNX_RX_CHAIN_PAGE_SZ,
		    BCM_PAGE_SIZE, BNX_DMA_BOUNDARY, &sc->rx_bd_chain_seg[i], 1,
		    &sc->rx_bd_chain_rseg[i], BUS_DMA_NOWAIT | BUS_DMA_ZERO)) {
			printf(": Could not allocate Rx desc %d DMA memory!\n", 
			    i);
			rc = ENOMEM;
			goto bnx_dma_alloc_exit;
		}

		if (bus_dmamem_map(sc->bnx_dmatag, &sc->rx_bd_chain_seg[i],
		    sc->rx_bd_chain_rseg[i], BNX_RX_CHAIN_PAGE_SZ,
		    (caddr_t *)&sc->rx_bd_chain[i], BUS_DMA_NOWAIT)) {
			printf(": Could not map Rx desc %d DMA memory!\n", i);
			rc = ENOMEM;
			goto bnx_dma_alloc_exit;
		}

		if (bus_dmamap_load(sc->bnx_dmatag, sc->rx_bd_chain_map[i],
		    (caddr_t)sc->rx_bd_chain[i], BNX_RX_CHAIN_PAGE_SZ, NULL,
		    BUS_DMA_NOWAIT)) {
			printf(": Could not load Rx desc %d DMA memory!\n", i);
			rc = ENOMEM;
			goto bnx_dma_alloc_exit;
		}

		sc->rx_bd_chain_paddr[i] =
		    sc->rx_bd_chain_map[i]->dm_segs[0].ds_addr;

		/* DRC - Fix for 64 bit systems. */
		DBPRINT(sc, BNX_INFO, "rx_bd_chain_paddr[%d] = 0x%08X\n", 
		    i, (u_int32_t) sc->rx_bd_chain_paddr[i]);
	}

	/*
	 * Create DMA maps for the Rx buffer mbufs.
	 */
	for (i = 0; i < TOTAL_RX_BD; i++) {
		if (bus_dmamap_create(sc->bnx_dmatag, BNX_MAX_MRU,
		    BNX_MAX_SEGMENTS, BNX_MAX_MRU, 0, BUS_DMA_NOWAIT,
		    &sc->rx_mbuf_map[i])) {
			printf(": Could not create Rx mbuf %d DMA map!\n", i);
			rc = ENOMEM;
			goto bnx_dma_alloc_exit;
		}
	}

 bnx_dma_alloc_exit:
	DBPRINT(sc, BNX_VERBOSE_RESET, "Exiting %s()\n", __FUNCTION__);

	return(rc);
}

/****************************************************************************/
/* Release all resources used by the driver.                                */
/*                                                                          */
/* Releases all resources acquired by the driver including interrupts,      */
/* interrupt handler, interfaces, mutexes, and DMA memory.                  */
/*                                                                          */
/* Returns:                                                                 */
/*   Nothing.                                                               */
/****************************************************************************/
void
bnx_release_resources(struct bnx_softc *sc)
{
	struct pci_attach_args	*pa = &(sc->bnx_pa);

	DBPRINT(sc, BNX_VERBOSE_RESET, "Entering %s()\n", __FUNCTION__);

	bnx_dma_free(sc);

	if (sc->bnx_intrhand != NULL)
		pci_intr_disestablish(pa->pa_pc, sc->bnx_intrhand);

	if (sc->bnx_size)
		bus_space_unmap(sc->bnx_btag, sc->bnx_bhandle, sc->bnx_size);

	DBPRINT(sc, BNX_VERBOSE_RESET, "Exiting %s()\n", __FUNCTION__);
}

/****************************************************************************/
/* Firmware synchronization.                                                */
/*                                                                          */
/* Before performing certain events such as a chip reset, synchronize with  */
/* the firmware first.                                                      */
/*                                                                          */
/* Returns:                                                                 */
/*   0 for success, positive value for failure.                             */
/****************************************************************************/
int
bnx_fw_sync(struct bnx_softc *sc, u_int32_t msg_data)
{
	int			i, rc = 0;
	u_int32_t		val;

	/* Don't waste any time if we've timed out before. */
	if (sc->bnx_fw_timed_out) {
		rc = EBUSY;
		goto bnx_fw_sync_exit;
	}

	/* Increment the message sequence number. */
	sc->bnx_fw_wr_seq++;
	msg_data |= sc->bnx_fw_wr_seq;

 	DBPRINT(sc, BNX_VERBOSE, "bnx_fw_sync(): msg_data = 0x%08X\n",
	    msg_data);

	/* Send the message to the bootcode driver mailbox. */
	REG_WR_IND(sc, sc->bnx_shmem_base + BNX_DRV_MB, msg_data);

	/* Wait for the bootcode to acknowledge the message. */
	for (i = 0; i < FW_ACK_TIME_OUT_MS; i++) {
		/* Check for a response in the bootcode firmware mailbox. */
		val = REG_RD_IND(sc, sc->bnx_shmem_base + BNX_FW_MB);
		if ((val & BNX_FW_MSG_ACK) == (msg_data & BNX_DRV_MSG_SEQ))
			break;
		DELAY(1000);
	}

	/* If we've timed out, tell the bootcode that we've stopped waiting. */
	if (((val & BNX_FW_MSG_ACK) != (msg_data & BNX_DRV_MSG_SEQ)) &&
		((msg_data & BNX_DRV_MSG_DATA) != BNX_DRV_MSG_DATA_WAIT0)) {
		BNX_PRINTF(sc, "%s(%d): Firmware synchronization timeout! "
		    "msg_data = 0x%08X\n", __FILE__, __LINE__, msg_data);

		msg_data &= ~BNX_DRV_MSG_CODE;
		msg_data |= BNX_DRV_MSG_CODE_FW_TIMEOUT;

		REG_WR_IND(sc, sc->bnx_shmem_base + BNX_DRV_MB, msg_data);

		sc->bnx_fw_timed_out = 1;
		rc = EBUSY;
	}

bnx_fw_sync_exit:
	return (rc);
}

/****************************************************************************/
/* Load Receive Virtual 2 Physical (RV2P) processor firmware.               */
/*                                                                          */
/* Returns:                                                                 */
/*   Nothing.                                                               */
/****************************************************************************/
void
bnx_load_rv2p_fw(struct bnx_softc *sc, u_int32_t *rv2p_code, 
    u_int32_t rv2p_code_len, u_int32_t rv2p_proc)
{
	int			i;
	u_int32_t		val;

	/* Set the page size used by RV2P. */
	if (rv2p_proc == RV2P_PROC2) {
		BNX_RV2P_PROC2_CHG_MAX_BD_PAGE(rv2p_code,
		    USABLE_RX_BD_PER_PAGE);
	}

	for (i = 0; i < rv2p_code_len; i += 8) {
		REG_WR(sc, BNX_RV2P_INSTR_HIGH, *rv2p_code);
		rv2p_code++;
		REG_WR(sc, BNX_RV2P_INSTR_LOW, *rv2p_code);
		rv2p_code++;

		if (rv2p_proc == RV2P_PROC1) {
			val = (i / 8) | BNX_RV2P_PROC1_ADDR_CMD_RDWR;
			REG_WR(sc, BNX_RV2P_PROC1_ADDR_CMD, val);
		} else {
			val = (i / 8) | BNX_RV2P_PROC2_ADDR_CMD_RDWR;
			REG_WR(sc, BNX_RV2P_PROC2_ADDR_CMD, val);
		}
	}

	/* Reset the processor, un-stall is done later. */
	if (rv2p_proc == RV2P_PROC1)
		REG_WR(sc, BNX_RV2P_COMMAND, BNX_RV2P_COMMAND_PROC1_RESET);
	else
		REG_WR(sc, BNX_RV2P_COMMAND, BNX_RV2P_COMMAND_PROC2_RESET);
}

/****************************************************************************/
/* Load RISC processor firmware.                                            */
/*                                                                          */
/* Loads firmware from the file if_bnxfw.h into the scratchpad memory       */
/* associated with a particular processor.                                  */
/*                                                                          */
/* Returns:                                                                 */
/*   Nothing.                                                               */
/****************************************************************************/
void
bnx_load_cpu_fw(struct bnx_softc *sc, struct cpu_reg *cpu_reg,
    struct fw_info *fw)
{
	u_int32_t		offset;
	u_int32_t		val;

	/* Halt the CPU. */
	val = REG_RD_IND(sc, cpu_reg->mode);
	val |= cpu_reg->mode_value_halt;
	REG_WR_IND(sc, cpu_reg->mode, val);
	REG_WR_IND(sc, cpu_reg->state, cpu_reg->state_value_clear);

	/* Load the Text area. */
	offset = cpu_reg->spad_base + (fw->text_addr - cpu_reg->mips_view_base);
	if (fw->text) {
		int j;

		for (j = 0; j < (fw->text_len / 4); j++, offset += 4)
			REG_WR_IND(sc, offset, fw->text[j]);
	}

	/* Load the Data area. */
	offset = cpu_reg->spad_base + (fw->data_addr - cpu_reg->mips_view_base);
	if (fw->data) {
		int j;

		for (j = 0; j < (fw->data_len / 4); j++, offset += 4)
			REG_WR_IND(sc, offset, fw->data[j]);
	}

	/* Load the SBSS area. */
	offset = cpu_reg->spad_base + (fw->sbss_addr - cpu_reg->mips_view_base);
	if (fw->sbss) {
		int j;

		for (j = 0; j < (fw->sbss_len / 4); j++, offset += 4)
			REG_WR_IND(sc, offset, fw->sbss[j]);
	}

	/* Load the BSS area. */
	offset = cpu_reg->spad_base + (fw->bss_addr - cpu_reg->mips_view_base);
	if (fw->bss) {
		int j;

		for (j = 0; j < (fw->bss_len/4); j++, offset += 4)
			REG_WR_IND(sc, offset, fw->bss[j]);
	}

	/* Load the Read-Only area. */
	offset = cpu_reg->spad_base +
	    (fw->rodata_addr - cpu_reg->mips_view_base);
	if (fw->rodata) {
		int j;

		for (j = 0; j < (fw->rodata_len / 4); j++, offset += 4)
			REG_WR_IND(sc, offset, fw->rodata[j]);
	}

	/* Clear the pre-fetch instruction. */
	REG_WR_IND(sc, cpu_reg->inst, 0);
	REG_WR_IND(sc, cpu_reg->pc, fw->start_addr);

	/* Start the CPU. */
	val = REG_RD_IND(sc, cpu_reg->mode);
	val &= ~cpu_reg->mode_value_halt;
	REG_WR_IND(sc, cpu_reg->state, cpu_reg->state_value_clear);
	REG_WR_IND(sc, cpu_reg->mode, val);
}

/****************************************************************************/
/* Initialize the RV2P, RX, TX, TPAT, and COM CPUs.                         */
/*                                                                          */
/* Loads the firmware for each CPU and starts the CPU.                      */
/*                                                                          */
/* Returns:                                                                 */
/*   Nothing.                                                               */
/****************************************************************************/
void
bnx_init_cpus(struct bnx_softc *sc)
{
	struct bnx_firmware *bfw = &bnx_firmwares[BNX_FW_B06];
	struct bnx_rv2p *rv2p = &bnx_rv2ps[BNX_RV2P];
	struct cpu_reg cpu_reg;
	struct fw_info fw;

	if (BNX_CHIP_NUM(sc) == BNX_CHIP_NUM_5709) {
		bfw = &bnx_firmwares[BNX_FW_B09];
		if ((BNX_CHIP_REV(sc) == BNX_CHIP_REV_Ax))
			rv2p = &bnx_rv2ps[BNX_XI90_RV2P];
		else
			rv2p = &bnx_rv2ps[BNX_XI_RV2P];
	}

	/* Initialize the RV2P processor. */
	bnx_load_rv2p_fw(sc, rv2p->bnx_rv2p_proc1,
	    rv2p->fw->bnx_rv2p_proc1len, RV2P_PROC1);
	bnx_load_rv2p_fw(sc, rv2p->bnx_rv2p_proc2,
	    rv2p->fw->bnx_rv2p_proc2len, RV2P_PROC2);

	/* Initialize the RX Processor. */
	cpu_reg.mode = BNX_RXP_CPU_MODE;
	cpu_reg.mode_value_halt = BNX_RXP_CPU_MODE_SOFT_HALT;
	cpu_reg.mode_value_sstep = BNX_RXP_CPU_MODE_STEP_ENA;
	cpu_reg.state = BNX_RXP_CPU_STATE;
	cpu_reg.state_value_clear = 0xffffff;
	cpu_reg.gpr0 = BNX_RXP_CPU_REG_FILE;
	cpu_reg.evmask = BNX_RXP_CPU_EVENT_MASK;
	cpu_reg.pc = BNX_RXP_CPU_PROGRAM_COUNTER;
	cpu_reg.inst = BNX_RXP_CPU_INSTRUCTION;
	cpu_reg.bp = BNX_RXP_CPU_HW_BREAKPOINT;
	cpu_reg.spad_base = BNX_RXP_SCRATCH;
	cpu_reg.mips_view_base = 0x8000000;

	fw.ver_major = bfw->fw->bnx_RXP_FwReleaseMajor;
	fw.ver_minor = bfw->fw->bnx_RXP_FwReleaseMinor;
	fw.ver_fix = bfw->fw->bnx_RXP_FwReleaseFix;
	fw.start_addr = bfw->fw->bnx_RXP_FwStartAddr;

	fw.text_addr = bfw->fw->bnx_RXP_FwTextAddr;
	fw.text_len = bfw->fw->bnx_RXP_FwTextLen;
	fw.text_index = 0;
	fw.text = bfw->bnx_RXP_FwText;

	fw.data_addr = bfw->fw->bnx_RXP_FwDataAddr;
	fw.data_len = bfw->fw->bnx_RXP_FwDataLen;
	fw.data_index = 0;
	fw.data = bfw->bnx_RXP_FwData;

	fw.sbss_addr = bfw->fw->bnx_RXP_FwSbssAddr;
	fw.sbss_len = bfw->fw->bnx_RXP_FwSbssLen;
	fw.sbss_index = 0;
	fw.sbss = bfw->bnx_RXP_FwSbss;

	fw.bss_addr = bfw->fw->bnx_RXP_FwBssAddr;
	fw.bss_len = bfw->fw->bnx_RXP_FwBssLen;
	fw.bss_index = 0;
	fw.bss = bfw->bnx_RXP_FwBss;

	fw.rodata_addr = bfw->fw->bnx_RXP_FwRodataAddr;
	fw.rodata_len = bfw->fw->bnx_RXP_FwRodataLen;
	fw.rodata_index = 0;
	fw.rodata = bfw->bnx_RXP_FwRodata;

	DBPRINT(sc, BNX_INFO_RESET, "Loading RX firmware.\n");
	bnx_load_cpu_fw(sc, &cpu_reg, &fw);

	/* Initialize the TX Processor. */
	cpu_reg.mode = BNX_TXP_CPU_MODE;
	cpu_reg.mode_value_halt = BNX_TXP_CPU_MODE_SOFT_HALT;
	cpu_reg.mode_value_sstep = BNX_TXP_CPU_MODE_STEP_ENA;
	cpu_reg.state = BNX_TXP_CPU_STATE;
	cpu_reg.state_value_clear = 0xffffff;
	cpu_reg.gpr0 = BNX_TXP_CPU_REG_FILE;
	cpu_reg.evmask = BNX_TXP_CPU_EVENT_MASK;
	cpu_reg.pc = BNX_TXP_CPU_PROGRAM_COUNTER;
	cpu_reg.inst = BNX_TXP_CPU_INSTRUCTION;
	cpu_reg.bp = BNX_TXP_CPU_HW_BREAKPOINT;
	cpu_reg.spad_base = BNX_TXP_SCRATCH;
	cpu_reg.mips_view_base = 0x8000000;

	fw.ver_major = bfw->fw->bnx_TXP_FwReleaseMajor;
	fw.ver_minor = bfw->fw->bnx_TXP_FwReleaseMinor;
	fw.ver_fix = bfw->fw->bnx_TXP_FwReleaseFix;
	fw.start_addr = bfw->fw->bnx_TXP_FwStartAddr;

	fw.text_addr = bfw->fw->bnx_TXP_FwTextAddr;
	fw.text_len = bfw->fw->bnx_TXP_FwTextLen;
	fw.text_index = 0;
	fw.text = bfw->bnx_TXP_FwText;

	fw.data_addr = bfw->fw->bnx_TXP_FwDataAddr;
	fw.data_len = bfw->fw->bnx_TXP_FwDataLen;
	fw.data_index = 0;
	fw.data = bfw->bnx_TXP_FwData;

	fw.sbss_addr = bfw->fw->bnx_TXP_FwSbssAddr;
	fw.sbss_len = bfw->fw->bnx_TXP_FwSbssLen;
	fw.sbss_index = 0;
	fw.sbss = bfw->bnx_TXP_FwSbss;

	fw.bss_addr = bfw->fw->bnx_TXP_FwBssAddr;
	fw.bss_len = bfw->fw->bnx_TXP_FwBssLen;
	fw.bss_index = 0;
	fw.bss = bfw->bnx_TXP_FwBss;

	fw.rodata_addr = bfw->fw->bnx_TXP_FwRodataAddr;
	fw.rodata_len = bfw->fw->bnx_TXP_FwRodataLen;
	fw.rodata_index = 0;
	fw.rodata = bfw->bnx_TXP_FwRodata;

	DBPRINT(sc, BNX_INFO_RESET, "Loading TX firmware.\n");
	bnx_load_cpu_fw(sc, &cpu_reg, &fw);

	/* Initialize the TX Patch-up Processor. */
	cpu_reg.mode = BNX_TPAT_CPU_MODE;
	cpu_reg.mode_value_halt = BNX_TPAT_CPU_MODE_SOFT_HALT;
	cpu_reg.mode_value_sstep = BNX_TPAT_CPU_MODE_STEP_ENA;
	cpu_reg.state = BNX_TPAT_CPU_STATE;
	cpu_reg.state_value_clear = 0xffffff;
	cpu_reg.gpr0 = BNX_TPAT_CPU_REG_FILE;
	cpu_reg.evmask = BNX_TPAT_CPU_EVENT_MASK;
	cpu_reg.pc = BNX_TPAT_CPU_PROGRAM_COUNTER;
	cpu_reg.inst = BNX_TPAT_CPU_INSTRUCTION;
	cpu_reg.bp = BNX_TPAT_CPU_HW_BREAKPOINT;
	cpu_reg.spad_base = BNX_TPAT_SCRATCH;
	cpu_reg.mips_view_base = 0x8000000;

	fw.ver_major = bfw->fw->bnx_TPAT_FwReleaseMajor;
	fw.ver_minor = bfw->fw->bnx_TPAT_FwReleaseMinor;
	fw.ver_fix = bfw->fw->bnx_TPAT_FwReleaseFix;
	fw.start_addr = bfw->fw->bnx_TPAT_FwStartAddr;

	fw.text_addr = bfw->fw->bnx_TPAT_FwTextAddr;
	fw.text_len = bfw->fw->bnx_TPAT_FwTextLen;
	fw.text_index = 0;
	fw.text = bfw->bnx_TPAT_FwText;

	fw.data_addr = bfw->fw->bnx_TPAT_FwDataAddr;
	fw.data_len = bfw->fw->bnx_TPAT_FwDataLen;
	fw.data_index = 0;
	fw.data = bfw->bnx_TPAT_FwData;

	fw.sbss_addr = bfw->fw->bnx_TPAT_FwSbssAddr;
	fw.sbss_len = bfw->fw->bnx_TPAT_FwSbssLen;
	fw.sbss_index = 0;
	fw.sbss = bfw->bnx_TPAT_FwSbss;

	fw.bss_addr = bfw->fw->bnx_TPAT_FwBssAddr;
	fw.bss_len = bfw->fw->bnx_TPAT_FwBssLen;
	fw.bss_index = 0;
	fw.bss = bfw->bnx_TPAT_FwBss;

	fw.rodata_addr = bfw->fw->bnx_TPAT_FwRodataAddr;
	fw.rodata_len = bfw->fw->bnx_TPAT_FwRodataLen;
	fw.rodata_index = 0;
	fw.rodata = bfw->bnx_TPAT_FwRodata;

	DBPRINT(sc, BNX_INFO_RESET, "Loading TPAT firmware.\n");
	bnx_load_cpu_fw(sc, &cpu_reg, &fw);

	/* Initialize the Completion Processor. */
	cpu_reg.mode = BNX_COM_CPU_MODE;
	cpu_reg.mode_value_halt = BNX_COM_CPU_MODE_SOFT_HALT;
	cpu_reg.mode_value_sstep = BNX_COM_CPU_MODE_STEP_ENA;
	cpu_reg.state = BNX_COM_CPU_STATE;
	cpu_reg.state_value_clear = 0xffffff;
	cpu_reg.gpr0 = BNX_COM_CPU_REG_FILE;
	cpu_reg.evmask = BNX_COM_CPU_EVENT_MASK;
	cpu_reg.pc = BNX_COM_CPU_PROGRAM_COUNTER;
	cpu_reg.inst = BNX_COM_CPU_INSTRUCTION;
	cpu_reg.bp = BNX_COM_CPU_HW_BREAKPOINT;
	cpu_reg.spad_base = BNX_COM_SCRATCH;
	cpu_reg.mips_view_base = 0x8000000;

	fw.ver_major = bfw->fw->bnx_COM_FwReleaseMajor;
	fw.ver_minor = bfw->fw->bnx_COM_FwReleaseMinor;
	fw.ver_fix = bfw->fw->bnx_COM_FwReleaseFix;
	fw.start_addr = bfw->fw->bnx_COM_FwStartAddr;

	fw.text_addr = bfw->fw->bnx_COM_FwTextAddr;
	fw.text_len = bfw->fw->bnx_COM_FwTextLen;
	fw.text_index = 0;
	fw.text = bfw->bnx_COM_FwText;

	fw.data_addr = bfw->fw->bnx_COM_FwDataAddr;
	fw.data_len = bfw->fw->bnx_COM_FwDataLen;
	fw.data_index = 0;
	fw.data = bfw->bnx_COM_FwData;

	fw.sbss_addr = bfw->fw->bnx_COM_FwSbssAddr;
	fw.sbss_len = bfw->fw->bnx_COM_FwSbssLen;
	fw.sbss_index = 0;
	fw.sbss = bfw->bnx_COM_FwSbss;

	fw.bss_addr = bfw->fw->bnx_COM_FwBssAddr;
	fw.bss_len = bfw->fw->bnx_COM_FwBssLen;
	fw.bss_index = 0;
	fw.bss = bfw->bnx_COM_FwBss;

	fw.rodata_addr = bfw->fw->bnx_COM_FwRodataAddr;
	fw.rodata_len = bfw->fw->bnx_COM_FwRodataLen;
	fw.rodata_index = 0;
	fw.rodata = bfw->bnx_COM_FwRodata;

	DBPRINT(sc, BNX_INFO_RESET, "Loading COM firmware.\n");
	bnx_load_cpu_fw(sc, &cpu_reg, &fw);
}

/****************************************************************************/
/* Initialize context memory.                                               */
/*                                                                          */
/* Clears the memory associated with each Context ID (CID).                 */
/*                                                                          */
/* Returns:                                                                 */
/*   Nothing.                                                               */
/****************************************************************************/
void
bnx_init_context(struct bnx_softc *sc)
{
	if (BNX_CHIP_NUM(sc) == BNX_CHIP_NUM_5709) {
		/* DRC: Replace this constant value with a #define. */
		int i, retry_cnt = 10;
		u_int32_t val;
 
		/*
		 * BCM5709 context memory may be cached
		 * in host memory so prepare the host memory
		 * for access.
		 */
		val = BNX_CTX_COMMAND_ENABLED | BNX_CTX_COMMAND_MEM_INIT
		    | (1 << 12);
		val |= (BCM_PAGE_BITS - 8) << 16;
		REG_WR(sc, BNX_CTX_COMMAND, val);

		/* Wait for mem init command to complete. */
		for (i = 0; i < retry_cnt; i++) {
			val = REG_RD(sc, BNX_CTX_COMMAND);
			if (!(val & BNX_CTX_COMMAND_MEM_INIT))
				break;
			DELAY(2);
		}

		/* ToDo: Consider returning an error here. */
 
		for (i = 0; i < sc->ctx_pages; i++) {
			int j;

			/* Set the physaddr of the context memory cache. */
			val = (u_int32_t)(sc->ctx_segs[i].ds_addr);
			REG_WR(sc, BNX_CTX_HOST_PAGE_TBL_DATA0, val |
				BNX_CTX_HOST_PAGE_TBL_DATA0_VALID);
			val = (u_int32_t)
			    ((u_int64_t)sc->ctx_segs[i].ds_addr >> 32);
			REG_WR(sc, BNX_CTX_HOST_PAGE_TBL_DATA1, val);
			REG_WR(sc, BNX_CTX_HOST_PAGE_TBL_CTRL, i |
				BNX_CTX_HOST_PAGE_TBL_CTRL_WRITE_REQ);

			/* Verify that the context memory write was successful. */
			for (j = 0; j < retry_cnt; j++) {
				val = REG_RD(sc, BNX_CTX_HOST_PAGE_TBL_CTRL);
				if ((val & BNX_CTX_HOST_PAGE_TBL_CTRL_WRITE_REQ) == 0)
					break;
				DELAY(5);
			}

			/* ToDo: Consider returning an error here. */
		}
	} else {
		u_int32_t vcid_addr, offset;

		/*
		 * For the 5706/5708, context memory is local to
		 * the controller, so initialize the controller
		 * context memory.
		 */

		vcid_addr = GET_CID_ADDR(96);
		while (vcid_addr) {

			vcid_addr -= PHY_CTX_SIZE;

			REG_WR(sc, BNX_CTX_VIRT_ADDR, 0);
			REG_WR(sc, BNX_CTX_PAGE_TBL, vcid_addr);
 
			for(offset = 0; offset < PHY_CTX_SIZE; offset += 4) {
				CTX_WR(sc, 0x00, offset, 0);
			}

			REG_WR(sc, BNX_CTX_VIRT_ADDR, vcid_addr);
			REG_WR(sc, BNX_CTX_PAGE_TBL, vcid_addr);
		}
 	}
}

/****************************************************************************/
/* Fetch the permanent MAC address of the controller.                       */
/*                                                                          */
/* Returns:                                                                 */
/*   Nothing.                                                               */
/****************************************************************************/
void
bnx_get_mac_addr(struct bnx_softc *sc)
{
	u_int32_t		mac_lo = 0, mac_hi = 0;

	/*
	 * The NetXtreme II bootcode populates various NIC
	 * power-on and runtime configuration items in a
	 * shared memory area.  The factory configured MAC
	 * address is available from both NVRAM and the
	 * shared memory area so we'll read the value from
	 * shared memory for speed.
	 */

	mac_hi = REG_RD_IND(sc, sc->bnx_shmem_base + BNX_PORT_HW_CFG_MAC_UPPER);
	mac_lo = REG_RD_IND(sc, sc->bnx_shmem_base + BNX_PORT_HW_CFG_MAC_LOWER);

	if ((mac_lo == 0) && (mac_hi == 0)) {
		BNX_PRINTF(sc, "%s(%d): Invalid Ethernet address!\n",
		    __FILE__, __LINE__);
	} else {
		sc->eaddr[0] = (u_char)(mac_hi >> 8);
		sc->eaddr[1] = (u_char)(mac_hi >> 0);
		sc->eaddr[2] = (u_char)(mac_lo >> 24);
		sc->eaddr[3] = (u_char)(mac_lo >> 16);
		sc->eaddr[4] = (u_char)(mac_lo >> 8);
		sc->eaddr[5] = (u_char)(mac_lo >> 0);
	}

	DBPRINT(sc, BNX_INFO, "Permanent Ethernet address = "
	    "%6D\n", sc->eaddr, ":");
}

/****************************************************************************/
/* Program the MAC address.                                                 */
/*                                                                          */
/* Returns:                                                                 */
/*   Nothing.                                                               */
/****************************************************************************/
void
bnx_set_mac_addr(struct bnx_softc *sc)
{
	u_int32_t		val;
	u_int8_t		*mac_addr = sc->eaddr;

	DBPRINT(sc, BNX_INFO, "Setting Ethernet address = "
	    "%6D\n", sc->eaddr, ":");

	val = (mac_addr[0] << 8) | mac_addr[1];

	REG_WR(sc, BNX_EMAC_MAC_MATCH0, val);

	val = (mac_addr[2] << 24) | (mac_addr[3] << 16) |
		(mac_addr[4] << 8) | mac_addr[5];

	REG_WR(sc, BNX_EMAC_MAC_MATCH1, val);
}

/****************************************************************************/
/* Stop the controller.                                                     */
/*                                                                          */
/* Returns:                                                                 */
/*   Nothing.                                                               */
/****************************************************************************/
void
bnx_stop(struct bnx_softc *sc)
{
	struct ifnet		*ifp = &sc->arpcom.ac_if;
	struct ifmedia_entry	*ifm;
	struct mii_data		*mii;
	int			mtmp, itmp;

	DBPRINT(sc, BNX_VERBOSE_RESET, "Entering %s()\n", __FUNCTION__);

	timeout_del(&sc->bnx_timeout);
	timeout_del(&sc->bnx_rxrefill);

	ifp->if_flags &= ~IFF_RUNNING;
	ifq_clr_oactive(&ifp->if_snd);

	/* Disable the transmit/receive blocks. */
	REG_WR(sc, BNX_MISC_ENABLE_CLR_BITS, 0x5ffffff);
	REG_RD(sc, BNX_MISC_ENABLE_CLR_BITS);
	DELAY(20);

	bnx_disable_intr(sc);

	intr_barrier(sc->bnx_intrhand);
	KASSERT((ifp->if_flags & IFF_RUNNING) == 0);

	/* Tell firmware that the driver is going away. */
	bnx_reset(sc, BNX_DRV_MSG_CODE_SUSPEND_NO_WOL);

	/* Free RX buffers. */
	bnx_free_rx_chain(sc);

	/* Free TX buffers. */
	bnx_free_tx_chain(sc);

	/*
	 * Isolate/power down the PHY, but leave the media selection
	 * unchanged so that things will be put back to normal when
	 * we bring the interface back up.
	 */
	mii = &sc->bnx_mii;
	itmp = ifp->if_flags;
	ifp->if_flags |= IFF_UP;
	ifm = mii->mii_media.ifm_cur;
	mtmp = ifm->ifm_media;
	ifm->ifm_media = IFM_ETHER|IFM_NONE;
	mii_mediachg(mii);
	ifm->ifm_media = mtmp;
	ifp->if_flags = itmp;

	ifp->if_timer = 0;

	sc->bnx_link = 0;

	DBPRINT(sc, BNX_VERBOSE_RESET, "Exiting %s()\n", __FUNCTION__);

	bnx_mgmt_init(sc);
}

int
bnx_reset(struct bnx_softc *sc, u_int32_t reset_code)
{
	struct pci_attach_args	*pa = &(sc->bnx_pa);
	u_int32_t		val;
	int			i, rc = 0;

	DBPRINT(sc, BNX_VERBOSE_RESET, "Entering %s()\n", __FUNCTION__);

	/* Wait for pending PCI transactions to complete. */
	REG_WR(sc, BNX_MISC_ENABLE_CLR_BITS,
	    BNX_MISC_ENABLE_CLR_BITS_TX_DMA_ENABLE |
	    BNX_MISC_ENABLE_CLR_BITS_DMA_ENGINE_ENABLE |
	    BNX_MISC_ENABLE_CLR_BITS_RX_DMA_ENABLE |
	    BNX_MISC_ENABLE_CLR_BITS_HOST_COALESCE_ENABLE);
	val = REG_RD(sc, BNX_MISC_ENABLE_CLR_BITS);
	DELAY(5);

	/* Disable DMA */
	if (BNX_CHIP_NUM(sc) == BNX_CHIP_NUM_5709) {
		val = REG_RD(sc, BNX_MISC_NEW_CORE_CTL);
		val &= ~BNX_MISC_NEW_CORE_CTL_DMA_ENABLE;
		REG_WR(sc, BNX_MISC_NEW_CORE_CTL, val);
	}

	/* Assume bootcode is running. */
	sc->bnx_fw_timed_out = 0;

	/* Give the firmware a chance to prepare for the reset. */
	rc = bnx_fw_sync(sc, BNX_DRV_MSG_DATA_WAIT0 | reset_code);
	if (rc)
		goto bnx_reset_exit;

	/* Set a firmware reminder that this is a soft reset. */
	REG_WR_IND(sc, sc->bnx_shmem_base + BNX_DRV_RESET_SIGNATURE,
	    BNX_DRV_RESET_SIGNATURE_MAGIC);

	/* Dummy read to force the chip to complete all current transactions. */
	val = REG_RD(sc, BNX_MISC_ID);

	/* Chip reset. */
	if (BNX_CHIP_NUM(sc) == BNX_CHIP_NUM_5709) {
		REG_WR(sc, BNX_MISC_COMMAND, BNX_MISC_COMMAND_SW_RESET);
		REG_RD(sc, BNX_MISC_COMMAND);
		DELAY(5);

		val = BNX_PCICFG_MISC_CONFIG_REG_WINDOW_ENA |
		      BNX_PCICFG_MISC_CONFIG_TARGET_MB_WORD_SWAP;

		pci_conf_write(pa->pa_pc, pa->pa_tag, BNX_PCICFG_MISC_CONFIG,
		    val);
	} else {
		val = BNX_PCICFG_MISC_CONFIG_CORE_RST_REQ |
			BNX_PCICFG_MISC_CONFIG_REG_WINDOW_ENA |
			BNX_PCICFG_MISC_CONFIG_TARGET_MB_WORD_SWAP;
		REG_WR(sc, BNX_PCICFG_MISC_CONFIG, val);

		/* Allow up to 30us for reset to complete. */
		for (i = 0; i < 10; i++) {
			val = REG_RD(sc, BNX_PCICFG_MISC_CONFIG);
			if ((val & (BNX_PCICFG_MISC_CONFIG_CORE_RST_REQ |
				BNX_PCICFG_MISC_CONFIG_CORE_RST_BSY)) == 0) {
				break;
			}
			DELAY(10);
		}

		/* Check that reset completed successfully. */
		if (val & (BNX_PCICFG_MISC_CONFIG_CORE_RST_REQ |
		    BNX_PCICFG_MISC_CONFIG_CORE_RST_BSY)) {
			BNX_PRINTF(sc, "%s(%d): Reset failed!\n",
			    __FILE__, __LINE__);
			rc = EBUSY;
			goto bnx_reset_exit;
		}
	}

	/* Make sure byte swapping is properly configured. */
	val = REG_RD(sc, BNX_PCI_SWAP_DIAG0);
	if (val != 0x01020304) {
		BNX_PRINTF(sc, "%s(%d): Byte swap is incorrect!\n",
		    __FILE__, __LINE__);
		rc = ENODEV;
		goto bnx_reset_exit;
	}

	/* Just completed a reset, assume that firmware is running again. */
	sc->bnx_fw_timed_out = 0;

	/* Wait for the firmware to finish its initialization. */
	rc = bnx_fw_sync(sc, BNX_DRV_MSG_DATA_WAIT1 | reset_code);
	if (rc)
		BNX_PRINTF(sc, "%s(%d): Firmware did not complete "
		    "initialization!\n", __FILE__, __LINE__);

bnx_reset_exit:
	DBPRINT(sc, BNX_VERBOSE_RESET, "Exiting %s()\n", __FUNCTION__);

	return (rc);
}

int
bnx_chipinit(struct bnx_softc *sc)
{
	struct pci_attach_args	*pa = &(sc->bnx_pa);
	u_int32_t		val;
	int			rc = 0;

	DBPRINT(sc, BNX_VERBOSE_RESET, "Entering %s()\n", __FUNCTION__);

	/* Make sure the interrupt is not active. */
	REG_WR(sc, BNX_PCICFG_INT_ACK_CMD, BNX_PCICFG_INT_ACK_CMD_MASK_INT);

	/* Initialize DMA byte/word swapping, configure the number of DMA  */
	/* channels and PCI clock compensation delay.                      */
	val = BNX_DMA_CONFIG_DATA_BYTE_SWAP |
	    BNX_DMA_CONFIG_DATA_WORD_SWAP |
#if BYTE_ORDER == BIG_ENDIAN
	    BNX_DMA_CONFIG_CNTL_BYTE_SWAP |
#endif
	    BNX_DMA_CONFIG_CNTL_WORD_SWAP |
	    DMA_READ_CHANS << 12 |
	    DMA_WRITE_CHANS << 16;

	val |= (0x2 << 20) | BNX_DMA_CONFIG_CNTL_PCI_COMP_DLY;

	if ((sc->bnx_flags & BNX_PCIX_FLAG) && (sc->bus_speed_mhz == 133))
		val |= BNX_DMA_CONFIG_PCI_FAST_CLK_CMP;

	/*
	 * This setting resolves a problem observed on certain Intel PCI
	 * chipsets that cannot handle multiple outstanding DMA operations.
	 * See errata E9_5706A1_65.
	 */
	if ((BNX_CHIP_NUM(sc) == BNX_CHIP_NUM_5706) &&
	    (BNX_CHIP_ID(sc) != BNX_CHIP_ID_5706_A0) &&
	    !(sc->bnx_flags & BNX_PCIX_FLAG))
		val |= BNX_DMA_CONFIG_CNTL_PING_PONG_DMA;

	REG_WR(sc, BNX_DMA_CONFIG, val);

#if 1
	/* Clear the PCI-X relaxed ordering bit. See errata E3_5708CA0_570. */
	if (sc->bnx_flags & BNX_PCIX_FLAG) {
		val = pci_conf_read(pa->pa_pc, pa->pa_tag, BNX_PCI_PCIX_CMD);
		pci_conf_write(pa->pa_pc, pa->pa_tag, BNX_PCI_PCIX_CMD,
		    val & ~0x20000);
	}
#endif

	/* Enable the RX_V2P and Context state machines before access. */
	REG_WR(sc, BNX_MISC_ENABLE_SET_BITS,
	    BNX_MISC_ENABLE_SET_BITS_HOST_COALESCE_ENABLE |
	    BNX_MISC_ENABLE_STATUS_BITS_RX_V2P_ENABLE |
	    BNX_MISC_ENABLE_STATUS_BITS_CONTEXT_ENABLE);

	/* Initialize context mapping and zero out the quick contexts. */
	bnx_init_context(sc);

	/* Initialize the on-boards CPUs */
	bnx_init_cpus(sc);

	/* Prepare NVRAM for access. */
	if (bnx_init_nvram(sc)) {
		rc = ENODEV;
		goto bnx_chipinit_exit;
	}

	/* Set the kernel bypass block size */
	val = REG_RD(sc, BNX_MQ_CONFIG);
	val &= ~BNX_MQ_CONFIG_KNL_BYP_BLK_SIZE;
	val |= BNX_MQ_CONFIG_KNL_BYP_BLK_SIZE_256;

	/* Enable bins used on the 5709. */
	if (BNX_CHIP_NUM(sc) == BNX_CHIP_NUM_5709) {
		val |= BNX_MQ_CONFIG_BIN_MQ_MODE;
		if (BNX_CHIP_ID(sc) == BNX_CHIP_ID_5709_A1)
			val |= BNX_MQ_CONFIG_HALT_DIS;
	}

	REG_WR(sc, BNX_MQ_CONFIG, val);

	val = 0x10000 + (MAX_CID_CNT * MB_KERNEL_CTX_SIZE);
	REG_WR(sc, BNX_MQ_KNL_BYP_WIND_START, val);
	REG_WR(sc, BNX_MQ_KNL_WIND_END, val);

	val = (BCM_PAGE_BITS - 8) << 24;
	REG_WR(sc, BNX_RV2P_CONFIG, val);

	/* Configure page size. */
	val = REG_RD(sc, BNX_TBDR_CONFIG);
	val &= ~BNX_TBDR_CONFIG_PAGE_SIZE;
	val |= (BCM_PAGE_BITS - 8) << 24 | 0x40;
	REG_WR(sc, BNX_TBDR_CONFIG, val);

#if 0
	/* Set the perfect match control register to default. */
	REG_WR_IND(sc, BNX_RXP_PM_CTRL, 0);
#endif

bnx_chipinit_exit:
	DBPRINT(sc, BNX_VERBOSE_RESET, "Exiting %s()\n", __FUNCTION__);

	return(rc);
}

/****************************************************************************/
/* Initialize the controller in preparation to send/receive traffic.        */
/*                                                                          */
/* Returns:                                                                 */
/*   0 for success, positive value for failure.                             */
/****************************************************************************/
int
bnx_blockinit(struct bnx_softc *sc)
{
	u_int32_t		reg, val;
	int 			rc = 0;

	DBPRINT(sc, BNX_VERBOSE_RESET, "Entering %s()\n", __FUNCTION__);

	/* Load the hardware default MAC address. */
	bnx_set_mac_addr(sc);

	/* Set the Ethernet backoff seed value */
	val = sc->eaddr[0] + (sc->eaddr[1] << 8) + (sc->eaddr[2] << 16) +
	    (sc->eaddr[3]) + (sc->eaddr[4] << 8) + (sc->eaddr[5] << 16);
	REG_WR(sc, BNX_EMAC_BACKOFF_SEED, val);

	sc->last_status_idx = 0;
	sc->rx_mode = BNX_EMAC_RX_MODE_SORT_MODE;

	/* Set up link change interrupt generation. */
	REG_WR(sc, BNX_EMAC_ATTENTION_ENA, BNX_EMAC_ATTENTION_ENA_LINK);
	REG_WR(sc, BNX_HC_ATTN_BITS_ENABLE, STATUS_ATTN_BITS_LINK_STATE);

	/* Program the physical address of the status block. */
	REG_WR(sc, BNX_HC_STATUS_ADDR_L, (u_int32_t)(sc->status_block_paddr));
	REG_WR(sc, BNX_HC_STATUS_ADDR_H,
	    (u_int32_t)((u_int64_t)sc->status_block_paddr >> 32));

	/* Program the physical address of the statistics block. */
	REG_WR(sc, BNX_HC_STATISTICS_ADDR_L,
	    (u_int32_t)(sc->stats_block_paddr));
	REG_WR(sc, BNX_HC_STATISTICS_ADDR_H,
	    (u_int32_t)((u_int64_t)sc->stats_block_paddr >> 32));

	/* Program various host coalescing parameters. */
	REG_WR(sc, BNX_HC_TX_QUICK_CONS_TRIP, (sc->bnx_tx_quick_cons_trip_int
	    << 16) | sc->bnx_tx_quick_cons_trip);
	REG_WR(sc, BNX_HC_RX_QUICK_CONS_TRIP, (sc->bnx_rx_quick_cons_trip_int
	    << 16) | sc->bnx_rx_quick_cons_trip);
	REG_WR(sc, BNX_HC_COMP_PROD_TRIP, (sc->bnx_comp_prod_trip_int << 16) |
	    sc->bnx_comp_prod_trip);
	REG_WR(sc, BNX_HC_TX_TICKS, (sc->bnx_tx_ticks_int << 16) |
	    sc->bnx_tx_ticks);
	REG_WR(sc, BNX_HC_RX_TICKS, (sc->bnx_rx_ticks_int << 16) |
	    sc->bnx_rx_ticks);
	REG_WR(sc, BNX_HC_COM_TICKS, (sc->bnx_com_ticks_int << 16) |
	    sc->bnx_com_ticks);
	REG_WR(sc, BNX_HC_CMD_TICKS, (sc->bnx_cmd_ticks_int << 16) |
	    sc->bnx_cmd_ticks);
	REG_WR(sc, BNX_HC_STATS_TICKS, (sc->bnx_stats_ticks & 0xffff00));
	REG_WR(sc, BNX_HC_STAT_COLLECT_TICKS, 0xbb8);  /* 3ms */
	REG_WR(sc, BNX_HC_CONFIG,
	    (BNX_HC_CONFIG_RX_TMR_MODE | BNX_HC_CONFIG_TX_TMR_MODE |
	    BNX_HC_CONFIG_COLLECT_STATS));

	/* Clear the internal statistics counters. */
	REG_WR(sc, BNX_HC_COMMAND, BNX_HC_COMMAND_CLR_STAT_NOW);

	/* Verify that bootcode is running. */
	reg = REG_RD_IND(sc, sc->bnx_shmem_base + BNX_DEV_INFO_SIGNATURE);

	DBRUNIF(DB_RANDOMTRUE(bnx_debug_bootcode_running_failure),
	    BNX_PRINTF(sc, "%s(%d): Simulating bootcode failure.\n",
	    __FILE__, __LINE__); reg = 0);

	if ((reg & BNX_DEV_INFO_SIGNATURE_MAGIC_MASK) !=
	    BNX_DEV_INFO_SIGNATURE_MAGIC) {
		BNX_PRINTF(sc, "%s(%d): Bootcode not running! Found: 0x%08X, "
		    "Expected: 08%08X\n", __FILE__, __LINE__,
		    (reg & BNX_DEV_INFO_SIGNATURE_MAGIC_MASK),
		    BNX_DEV_INFO_SIGNATURE_MAGIC);
		rc = ENODEV;
		goto bnx_blockinit_exit;
	}

	/* Check if any management firmware is running. */
	reg = REG_RD_IND(sc, sc->bnx_shmem_base + BNX_PORT_FEATURE);
	if (reg & (BNX_PORT_FEATURE_ASF_ENABLED |
	    BNX_PORT_FEATURE_IMD_ENABLED)) {
		DBPRINT(sc, BNX_INFO, "Management F/W Enabled.\n");
		sc->bnx_flags |= BNX_MFW_ENABLE_FLAG;
	}

	sc->bnx_fw_ver = REG_RD_IND(sc, sc->bnx_shmem_base +
	    BNX_DEV_INFO_BC_REV);

	DBPRINT(sc, BNX_INFO, "bootcode rev = 0x%08X\n", sc->bnx_fw_ver);

	/* Enable DMA */
	if (BNX_CHIP_NUM(sc) == BNX_CHIP_NUM_5709) {
		val = REG_RD(sc, BNX_MISC_NEW_CORE_CTL);
		val |= BNX_MISC_NEW_CORE_CTL_DMA_ENABLE;
		REG_WR(sc, BNX_MISC_NEW_CORE_CTL, val);
	}

	/* Allow bootcode to apply any additional fixes before enabling MAC. */
	rc = bnx_fw_sync(sc, BNX_DRV_MSG_DATA_WAIT2 | BNX_DRV_MSG_CODE_RESET);

	/* Enable link state change interrupt generation. */
	if (BNX_CHIP_NUM(sc) == BNX_CHIP_NUM_5709) {
		REG_WR(sc, BNX_MISC_ENABLE_SET_BITS,
		    BNX_MISC_ENABLE_DEFAULT_XI);
	} else 
		REG_WR(sc, BNX_MISC_ENABLE_SET_BITS, BNX_MISC_ENABLE_DEFAULT);

	/* Enable all remaining blocks in the MAC. */
	REG_WR(sc, BNX_MISC_ENABLE_SET_BITS, 0x5ffffff);
	REG_RD(sc, BNX_MISC_ENABLE_SET_BITS);
	DELAY(20);

bnx_blockinit_exit:
	DBPRINT(sc, BNX_VERBOSE_RESET, "Exiting %s()\n", __FUNCTION__);

	return (rc);
}

/****************************************************************************/
/* Encapsulate an mbuf cluster into the rx_bd chain.                        */
/*                                                                          */
/* The NetXtreme II can support Jumbo frames by using multiple rx_bd's.     */
/* This routine will map an mbuf cluster into 1 or more rx_bd's as          */
/* necessary.                                                               */
/*                                                                          */
/* Returns:                                                                 */
/*   0 for success, positive value for failure.                             */
/****************************************************************************/
int
bnx_get_buf(struct bnx_softc *sc, u_int16_t *prod,
    u_int16_t *chain_prod, u_int32_t *prod_bseq)
{
	bus_dmamap_t		map;
	struct mbuf 		*m;
	struct rx_bd		*rxbd;
	int			i;
	u_int32_t		addr;
#ifdef BNX_DEBUG
	u_int16_t		debug_chain_prod = *chain_prod;
#endif
	u_int16_t		first_chain_prod;

	DBPRINT(sc, (BNX_VERBOSE_RESET | BNX_VERBOSE_RECV), "Entering %s()\n", 
	    __FUNCTION__);

	/* Make sure the inputs are valid. */
	DBRUNIF((*chain_prod > MAX_RX_BD),
	    printf("%s: RX producer out of range: 0x%04X > 0x%04X\n",
	    *chain_prod, (u_int16_t) MAX_RX_BD));

	DBPRINT(sc, BNX_VERBOSE_RECV, "%s(enter): prod = 0x%04X, chain_prod = "
	    "0x%04X, prod_bseq = 0x%08X\n", __FUNCTION__, *prod, *chain_prod,
	    *prod_bseq);

	/* This is a new mbuf allocation. */
	m = MCLGETI(NULL, M_DONTWAIT, NULL, MCLBYTES);
	if (!m)
		return (0);
	m->m_len = m->m_pkthdr.len = MCLBYTES;
	/* the chip aligns the ip header for us, no need to m_adj */

	/* Map the mbuf cluster into device memory. */
	map = sc->rx_mbuf_map[*chain_prod];
	if (bus_dmamap_load_mbuf(sc->bnx_dmatag, map, m, BUS_DMA_NOWAIT)) {
		m_freem(m);
		return (0);
	}
	first_chain_prod = *chain_prod;

#ifdef BNX_DEBUG
	/* Track the distribution of buffer segments. */
	sc->rx_mbuf_segs[map->dm_nsegs]++;
#endif

	/* Setup the rx_bd for the first segment. */
	rxbd = &sc->rx_bd_chain[RX_PAGE(*chain_prod)][RX_IDX(*chain_prod)];

	addr = (u_int32_t)map->dm_segs[0].ds_addr;
	rxbd->rx_bd_haddr_lo = addr;
	addr = (u_int32_t)((u_int64_t)map->dm_segs[0].ds_addr >> 32);
	rxbd->rx_bd_haddr_hi = addr;
	rxbd->rx_bd_len = map->dm_segs[0].ds_len;
	rxbd->rx_bd_flags = RX_BD_FLAGS_START;
	*prod_bseq += map->dm_segs[0].ds_len;

	for (i = 1; i < map->dm_nsegs; i++) {
		*prod = NEXT_RX_BD(*prod);
		*chain_prod = RX_CHAIN_IDX(*prod); 

		rxbd =
		    &sc->rx_bd_chain[RX_PAGE(*chain_prod)][RX_IDX(*chain_prod)];

		addr = (u_int32_t)map->dm_segs[i].ds_addr;
		rxbd->rx_bd_haddr_lo = addr;
		addr = (u_int32_t)((u_int64_t)map->dm_segs[i].ds_addr >> 32);
		rxbd->rx_bd_haddr_hi = addr;
		rxbd->rx_bd_len = map->dm_segs[i].ds_len;
		rxbd->rx_bd_flags = 0;
		*prod_bseq += map->dm_segs[i].ds_len;
	}

	rxbd->rx_bd_flags |= RX_BD_FLAGS_END;

	/*
	 * Save the mbuf, adjust the map pointer (swap map for first and
	 * last rx_bd entry so that rx_mbuf_ptr and rx_mbuf_map matches)
	 * and update our counter.
	 */
	sc->rx_mbuf_ptr[*chain_prod] = m;
	sc->rx_mbuf_map[first_chain_prod] = sc->rx_mbuf_map[*chain_prod];
	sc->rx_mbuf_map[*chain_prod] = map;

	DBRUN(BNX_VERBOSE_RECV, bnx_dump_rx_mbuf_chain(sc, debug_chain_prod, 
	    map->dm_nsegs));

	return (map->dm_nsegs);
}


/****************************************************************************/
/* Initialize the TX context memory.                                        */
/*                                                                          */
/* Returns:                                                                 */
/*   Nothing                                                                */
/****************************************************************************/
void
bnx_init_tx_context(struct bnx_softc *sc)
{
	u_int32_t val;

	/* Initialize the context ID for an L2 TX chain. */
	if (BNX_CHIP_NUM(sc) == BNX_CHIP_NUM_5709) {
		/* Set the CID type to support an L2 connection. */
		val = BNX_L2CTX_TYPE_TYPE_L2 | BNX_L2CTX_TYPE_SIZE_L2;
		CTX_WR(sc, GET_CID_ADDR(TX_CID), BNX_L2CTX_TYPE_XI, val);
		val = BNX_L2CTX_CMD_TYPE_TYPE_L2 | (8 << 16);
		CTX_WR(sc, GET_CID_ADDR(TX_CID), BNX_L2CTX_CMD_TYPE_XI, val);

		/* Point the hardware to the first page in the chain. */
		val = (u_int32_t)((u_int64_t)sc->tx_bd_chain_paddr[0] >> 32);
		CTX_WR(sc, GET_CID_ADDR(TX_CID),
		    BNX_L2CTX_TBDR_BHADDR_HI_XI, val);
		val = (u_int32_t)(sc->tx_bd_chain_paddr[0]);
		CTX_WR(sc, GET_CID_ADDR(TX_CID),
		    BNX_L2CTX_TBDR_BHADDR_LO_XI, val);
	} else {
		/* Set the CID type to support an L2 connection. */
		val = BNX_L2CTX_TYPE_TYPE_L2 | BNX_L2CTX_TYPE_SIZE_L2;
		CTX_WR(sc, GET_CID_ADDR(TX_CID), BNX_L2CTX_TYPE, val);
		val = BNX_L2CTX_CMD_TYPE_TYPE_L2 | (8 << 16);
		CTX_WR(sc, GET_CID_ADDR(TX_CID), BNX_L2CTX_CMD_TYPE, val);

		/* Point the hardware to the first page in the chain. */
		val = (u_int32_t)((u_int64_t)sc->tx_bd_chain_paddr[0] >> 32);
		CTX_WR(sc, GET_CID_ADDR(TX_CID), BNX_L2CTX_TBDR_BHADDR_HI, val);
		val = (u_int32_t)(sc->tx_bd_chain_paddr[0]);
		CTX_WR(sc, GET_CID_ADDR(TX_CID), BNX_L2CTX_TBDR_BHADDR_LO, val);
	}
}

/****************************************************************************/
/* Allocate memory and initialize the TX data structures.                   */
/*                                                                          */
/* Returns:                                                                 */
/*   0 for success, positive value for failure.                             */
/****************************************************************************/
int
bnx_init_tx_chain(struct bnx_softc *sc)
{
	struct tx_bd		*txbd;
	u_int32_t		addr;
	int			i, rc = 0;

	DBPRINT(sc, BNX_VERBOSE_RESET, "Entering %s()\n", __FUNCTION__);

	/* Set the initial TX producer/consumer indices. */
	sc->tx_prod = 0;
	sc->tx_cons = 0;
	sc->tx_prod_bseq = 0;
	sc->used_tx_bd = 0;
	sc->max_tx_bd =	USABLE_TX_BD;
	DBRUNIF(1, sc->tx_hi_watermark = USABLE_TX_BD);
	DBRUNIF(1, sc->tx_full_count = 0);

	/*
	 * The NetXtreme II supports a linked-list structure called
	 * a Buffer Descriptor Chain (or BD chain).  A BD chain
	 * consists of a series of 1 or more chain pages, each of which
	 * consists of a fixed number of BD entries.
	 * The last BD entry on each page is a pointer to the next page
	 * in the chain, and the last pointer in the BD chain
	 * points back to the beginning of the chain.
	 */

	/* Set the TX next pointer chain entries. */
	for (i = 0; i < TX_PAGES; i++) {
		int j;

		txbd = &sc->tx_bd_chain[i][USABLE_TX_BD_PER_PAGE];

		/* Check if we've reached the last page. */
		if (i == (TX_PAGES - 1))
			j = 0;
		else
			j = i + 1;

		addr = (u_int32_t)sc->tx_bd_chain_paddr[j];
		txbd->tx_bd_haddr_lo = addr;
		addr = (u_int32_t)((u_int64_t)sc->tx_bd_chain_paddr[j] >> 32);
		txbd->tx_bd_haddr_hi = addr;
	}

	/*
	 * Initialize the context ID for an L2 TX chain.
	 */
	bnx_init_tx_context(sc);

	DBPRINT(sc, BNX_VERBOSE_RESET, "Exiting %s()\n", __FUNCTION__);

	return(rc);
}

/****************************************************************************/
/* Free memory and clear the TX data structures.                            */
/*                                                                          */
/* Returns:                                                                 */
/*   Nothing.                                                               */
/****************************************************************************/
void
bnx_free_tx_chain(struct bnx_softc *sc)
{
	int			i;

	DBPRINT(sc, BNX_VERBOSE_RESET, "Entering %s()\n", __FUNCTION__);

	/* Unmap, unload, and free any mbufs still in the TX mbuf chain. */
	for (i = 0; i < TOTAL_TX_BD; i++) {
		if (sc->tx_mbuf_ptr[i] != NULL) {
			if (sc->tx_mbuf_map[i] != NULL) {
				bus_dmamap_sync(sc->bnx_dmatag,
				    sc->tx_mbuf_map[i],	0,
				    sc->tx_mbuf_map[i]->dm_mapsize,
				    BUS_DMASYNC_POSTWRITE);
				bus_dmamap_unload(sc->bnx_dmatag,
				    sc->tx_mbuf_map[i]);
			}
			m_freem(sc->tx_mbuf_ptr[i]);
			sc->tx_mbuf_ptr[i] = NULL;
			DBRUNIF(1, sc->tx_mbuf_alloc--);
		}
	}

	/* Clear each TX chain page. */
	for (i = 0; i < TX_PAGES; i++)
		bzero(sc->tx_bd_chain[i], BNX_TX_CHAIN_PAGE_SZ);

	sc->used_tx_bd = 0;

	/* Check if we lost any mbufs in the process. */
	DBRUNIF((sc->tx_mbuf_alloc),
	    printf("%s: Memory leak! Lost %d mbufs from tx chain!\n",
	    sc->tx_mbuf_alloc));

	DBPRINT(sc, BNX_VERBOSE_RESET, "Exiting %s()\n", __FUNCTION__);
}

/****************************************************************************/
/* Initialize the RX context memory.                                        */
/*                                                                          */
/* Returns:                                                                 */
/*   Nothing                                                                */
/****************************************************************************/
void
bnx_init_rx_context(struct bnx_softc *sc)
{
	u_int32_t val;

	/* Initialize the context ID for an L2 RX chain. */
	val = BNX_L2CTX_CTX_TYPE_CTX_BD_CHN_TYPE_VALUE |
		BNX_L2CTX_CTX_TYPE_SIZE_L2 | (0x02 << 8);

	/*
	 * Set the level for generating pause frames
	 * when the number of available rx_bd's gets
	 * too low (the low watermark) and the level
	 * when pause frames can be stopped (the high
	 * watermark).
	 */
	if (BNX_CHIP_NUM(sc) == BNX_CHIP_NUM_5709) {
		u_int32_t lo_water, hi_water;

		lo_water = BNX_L2CTX_RX_LO_WATER_MARK_DEFAULT;
		hi_water = USABLE_RX_BD / 4;

		lo_water /= BNX_L2CTX_RX_LO_WATER_MARK_SCALE;
		hi_water /= BNX_L2CTX_RX_HI_WATER_MARK_SCALE;

		if (hi_water > 0xf)
			hi_water = 0xf;
		else if (hi_water == 0)
			lo_water = 0;

		val |= (lo_water << BNX_L2CTX_RX_LO_WATER_MARK_SHIFT) |
		    (hi_water << BNX_L2CTX_RX_HI_WATER_MARK_SHIFT);
	}

 	CTX_WR(sc, GET_CID_ADDR(RX_CID), BNX_L2CTX_CTX_TYPE, val);

	/* Setup the MQ BIN mapping for l2_ctx_host_bseq. */
	if (BNX_CHIP_NUM(sc) == BNX_CHIP_NUM_5709) {
		val = REG_RD(sc, BNX_MQ_MAP_L2_5);
		REG_WR(sc, BNX_MQ_MAP_L2_5, val | BNX_MQ_MAP_L2_5_ARM);
	}

	/* Point the hardware to the first page in the chain. */
	val = (u_int32_t)((u_int64_t)sc->rx_bd_chain_paddr[0] >> 32);
	CTX_WR(sc, GET_CID_ADDR(RX_CID), BNX_L2CTX_NX_BDHADDR_HI, val);
	val = (u_int32_t)(sc->rx_bd_chain_paddr[0]);
	CTX_WR(sc, GET_CID_ADDR(RX_CID), BNX_L2CTX_NX_BDHADDR_LO, val);
}

/****************************************************************************/
/* Add mbufs to the RX chain until its full or an mbuf allocation error     */
/* occurs.                                                                  */
/*                                                                          */
/* Returns:                                                                 */
/*   Nothing                                                                */
/****************************************************************************/
int
bnx_fill_rx_chain(struct bnx_softc *sc)
{
	u_int16_t		prod, chain_prod;
	u_int32_t		prod_bseq;
	u_int			slots, used;
	int			ndesc = 0;
#ifdef BNX_DEBUG
	int rx_mbuf_alloc_before;
#endif

	DBPRINT(sc, BNX_EXCESSIVE_RECV, "Entering %s()\n", __FUNCTION__);

	prod = sc->rx_prod;
	prod_bseq = sc->rx_prod_bseq;

#ifdef BNX_DEBUG
	rx_mbuf_alloc_before = sc->rx_mbuf_alloc;
#endif

	/* Keep filling the RX chain until it's full. */
	slots = if_rxr_get(&sc->rx_ring, sc->max_rx_bd);
	while (slots > 0) {
		chain_prod = RX_CHAIN_IDX(prod);
		
		used = bnx_get_buf(sc, &prod, &chain_prod, &prod_bseq);
		if (used == 0) {
			/* Bail out if we can't add an mbuf to the chain. */
			break;
		}
		slots -= used;

		prod = NEXT_RX_BD(prod);
		ndesc++;
	}
	if_rxr_put(&sc->rx_ring, slots);

	/* Save the RX chain producer index. */
	sc->rx_prod = prod;
	sc->rx_prod_bseq = prod_bseq;

	/* Tell the chip about the waiting rx_bd's. */
	REG_WR16(sc, MB_RX_CID_ADDR + BNX_L2CTX_HOST_BDIDX, sc->rx_prod);
	REG_WR(sc, MB_RX_CID_ADDR + BNX_L2CTX_HOST_BSEQ, sc->rx_prod_bseq);

	DBPRINT(sc, BNX_EXCESSIVE_RECV, "Exiting %s()\n", __FUNCTION__);

	return (ndesc);
}

/****************************************************************************/
/* Allocate memory and initialize the RX data structures.                   */
/*                                                                          */
/* Returns:                                                                 */
/*   0 for success, positive value for failure.                             */
/****************************************************************************/
int
bnx_init_rx_chain(struct bnx_softc *sc)
{
	struct rx_bd		*rxbd;
	int			i, rc = 0;
	u_int32_t		addr;

	DBPRINT(sc, BNX_VERBOSE_RESET, "Entering %s()\n", __FUNCTION__);

	/* Initialize the RX producer and consumer indices. */
	sc->rx_prod = 0;
	sc->rx_cons = 0;
	sc->rx_prod_bseq = 0;
	sc->max_rx_bd = USABLE_RX_BD;
	DBRUNIF(1, sc->rx_low_watermark = USABLE_RX_BD);
	DBRUNIF(1, sc->rx_empty_count = 0);

	/* Initialize the RX next pointer chain entries. */
	for (i = 0; i < RX_PAGES; i++) {
		int j;

		rxbd = &sc->rx_bd_chain[i][USABLE_RX_BD_PER_PAGE];

		/* Check if we've reached the last page. */
		if (i == (RX_PAGES - 1))
			j = 0;
		else
			j = i + 1;

		/* Setup the chain page pointers. */
		addr = (u_int32_t)((u_int64_t)sc->rx_bd_chain_paddr[j] >> 32);
		rxbd->rx_bd_haddr_hi = addr;
		addr = (u_int32_t)sc->rx_bd_chain_paddr[j];
		rxbd->rx_bd_haddr_lo = addr;
	}

	if_rxr_init(&sc->rx_ring, 2, sc->max_rx_bd);

	/* Fill up the RX chain. */
	bnx_fill_rx_chain(sc);

	for (i = 0; i < RX_PAGES; i++)
		bus_dmamap_sync(sc->bnx_dmatag, sc->rx_bd_chain_map[i], 0,
		    sc->rx_bd_chain_map[i]->dm_mapsize,
		    BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);

	bnx_init_rx_context(sc);

	DBRUN(BNX_VERBOSE_RECV, bnx_dump_rx_chain(sc, 0, TOTAL_RX_BD));

	DBPRINT(sc, BNX_VERBOSE_RESET, "Exiting %s()\n", __FUNCTION__);

	return(rc);
}

/****************************************************************************/
/* Free memory and clear the RX data structures.                            */
/*                                                                          */
/* Returns:                                                                 */
/*   Nothing.                                                               */
/****************************************************************************/
void
bnx_free_rx_chain(struct bnx_softc *sc)
{
	int			i;
#ifdef BNX_DEBUG
	int			rx_mbuf_alloc_before;
#endif

	DBPRINT(sc, BNX_VERBOSE_RESET, "Entering %s()\n", __FUNCTION__);

#ifdef BNX_DEBUG
	rx_mbuf_alloc_before = sc->rx_mbuf_alloc;
#endif

	/* Free any mbufs still in the RX mbuf chain. */
	for (i = 0; i < TOTAL_RX_BD; i++) {
		if (sc->rx_mbuf_ptr[i] != NULL) {
			if (sc->rx_mbuf_map[i] != NULL) {
				bus_dmamap_sync(sc->bnx_dmatag,
				    sc->rx_mbuf_map[i],	0,
				    sc->rx_mbuf_map[i]->dm_mapsize,
				    BUS_DMASYNC_POSTREAD);
				bus_dmamap_unload(sc->bnx_dmatag,
				    sc->rx_mbuf_map[i]);
			}
			m_freem(sc->rx_mbuf_ptr[i]);
			sc->rx_mbuf_ptr[i] = NULL;
			DBRUNIF(1, sc->rx_mbuf_alloc--);
		}
	}

	DBRUNIF((rx_mbuf_alloc_before - sc->rx_mbuf_alloc),
		BNX_PRINTF(sc, "%s(): Released %d mbufs.\n",
		__FUNCTION__, (rx_mbuf_alloc_before - sc->rx_mbuf_alloc)));

	/* Clear each RX chain page. */
	for (i = 0; i < RX_PAGES; i++)
		bzero(sc->rx_bd_chain[i], BNX_RX_CHAIN_PAGE_SZ);

	/* Check if we lost any mbufs in the process. */
	DBRUNIF((sc->rx_mbuf_alloc),
	    printf("%s: Memory leak! Lost %d mbufs from rx chain!\n",
	    sc->rx_mbuf_alloc));

	DBPRINT(sc, BNX_VERBOSE_RESET, "Exiting %s()\n", __FUNCTION__);
}

void
bnx_rxrefill(void *xsc)
{
	struct bnx_softc	*sc = xsc;
	int			s;

	s = splnet();
	if (!bnx_fill_rx_chain(sc))
		timeout_add(&sc->bnx_rxrefill, 1);
	splx(s);
}

/****************************************************************************/
/* Set media options.                                                       */
/*                                                                          */
/* Returns:                                                                 */
/*   0 for success, positive value for failure.                             */
/****************************************************************************/
int
bnx_ifmedia_upd(struct ifnet *ifp)
{
	struct bnx_softc	*sc;
	struct mii_data		*mii;
	int			rc = 0;

	sc = ifp->if_softc;

	mii = &sc->bnx_mii;
	sc->bnx_link = 0;
	if (mii->mii_instance) {
		struct mii_softc *miisc;
		LIST_FOREACH(miisc, &mii->mii_phys, mii_list)
			mii_phy_reset(miisc);
	}
	mii_mediachg(mii);

	return(rc);
}

/****************************************************************************/
/* Reports current media status.                                            */
/*                                                                          */
/* Returns:                                                                 */
/*   Nothing.                                                               */
/****************************************************************************/
void
bnx_ifmedia_sts(struct ifnet *ifp, struct ifmediareq *ifmr)
{
	struct bnx_softc	*sc;
	struct mii_data		*mii;
	int			s;

	sc = ifp->if_softc;

	s = splnet();

	mii = &sc->bnx_mii;

	mii_pollstat(mii);
	ifmr->ifm_status = mii->mii_media_status;
	ifmr->ifm_active = (mii->mii_media_active & ~IFM_ETH_FMASK) |
	    sc->bnx_flowflags;

	splx(s);
}

/****************************************************************************/
/* Handles PHY generated interrupt events.                                  */
/*                                                                          */
/* Returns:                                                                 */
/*   Nothing.                                                               */
/****************************************************************************/
void
bnx_phy_intr(struct bnx_softc *sc)
{
	u_int32_t		new_link_state, old_link_state;

	new_link_state = sc->status_block->status_attn_bits &
	    STATUS_ATTN_BITS_LINK_STATE;
	old_link_state = sc->status_block->status_attn_bits_ack &
	    STATUS_ATTN_BITS_LINK_STATE;

	/* Handle any changes if the link state has changed. */
	if (new_link_state != old_link_state) {
		DBRUN(BNX_VERBOSE_INTR, bnx_dump_status_block(sc));

		sc->bnx_link = 0;
		timeout_del(&sc->bnx_timeout);
		bnx_tick(sc);

		/* Update the status_attn_bits_ack field in the status block. */
		if (new_link_state) {
			REG_WR(sc, BNX_PCICFG_STATUS_BIT_SET_CMD,
			    STATUS_ATTN_BITS_LINK_STATE);
			DBPRINT(sc, BNX_INFO, "Link is now UP.\n");
		} else {
			REG_WR(sc, BNX_PCICFG_STATUS_BIT_CLEAR_CMD,
			    STATUS_ATTN_BITS_LINK_STATE);
			DBPRINT(sc, BNX_INFO, "Link is now DOWN.\n");
		}
	}

	/* Acknowledge the link change interrupt. */
	REG_WR(sc, BNX_EMAC_STATUS, BNX_EMAC_STATUS_LINK_CHANGE);
}

/****************************************************************************/
/* Handles received frame interrupt events.                                 */
/*                                                                          */
/* Returns:                                                                 */
/*   Nothing.                                                               */
/****************************************************************************/
void
bnx_rx_intr(struct bnx_softc *sc)
{
	struct status_block	*sblk = sc->status_block;
	struct ifnet		*ifp = &sc->arpcom.ac_if;
	struct mbuf_list	ml = MBUF_LIST_INITIALIZER();
	u_int16_t		hw_cons, sw_cons, sw_chain_cons;
	u_int16_t		sw_prod, sw_chain_prod;
	u_int32_t		sw_prod_bseq;
	struct l2_fhdr		*l2fhdr;
	int			i;

	DBRUNIF(1, sc->rx_interrupts++);

	if (if_rxr_inuse(&sc->rx_ring) == 0)
		return;

	/* Prepare the RX chain pages to be accessed by the host CPU. */
	for (i = 0; i < RX_PAGES; i++)
		bus_dmamap_sync(sc->bnx_dmatag,
		    sc->rx_bd_chain_map[i], 0,
		    sc->rx_bd_chain_map[i]->dm_mapsize,
		    BUS_DMASYNC_POSTWRITE);

	/* Get the hardware's view of the RX consumer index. */
	hw_cons = sc->hw_rx_cons = sblk->status_rx_quick_consumer_index0;
	if ((hw_cons & USABLE_RX_BD_PER_PAGE) == USABLE_RX_BD_PER_PAGE)
		hw_cons++;

	/* Get working copies of the driver's view of the RX indices. */
	sw_cons = sc->rx_cons;
	sw_prod = sc->rx_prod;
	sw_prod_bseq = sc->rx_prod_bseq;

	DBPRINT(sc, BNX_INFO_RECV, "%s(enter): sw_prod = 0x%04X, "
	    "sw_cons = 0x%04X, sw_prod_bseq = 0x%08X\n",
	    __FUNCTION__, sw_prod, sw_cons, sw_prod_bseq);

	/* Prevent speculative reads from getting ahead of the status block. */
	bus_space_barrier(sc->bnx_btag, sc->bnx_bhandle, 0, 0,
	    BUS_SPACE_BARRIER_READ);

	/* 
	 * Scan through the receive chain as long 
	 * as there is work to do.
	 */
	while (sw_cons != hw_cons) {
		struct mbuf *m;
		struct rx_bd *rxbd;
		unsigned int len;
		u_int32_t status;

		/* Clear the mbuf pointer. */
		m = NULL;

		/* Convert the producer/consumer indices to an actual
		 * rx_bd index.
		 */
		sw_chain_cons = RX_CHAIN_IDX(sw_cons);
		sw_chain_prod = RX_CHAIN_IDX(sw_prod);

		/* Get the used rx_bd. */
		rxbd = &sc->rx_bd_chain[RX_PAGE(sw_chain_cons)][RX_IDX(sw_chain_cons)];
		if_rxr_put(&sc->rx_ring, 1);
	
		DBRUN(BNX_VERBOSE_RECV, printf("%s(): ", __FUNCTION__); 
		bnx_dump_rxbd(sc, sw_chain_cons, rxbd));

		/* The mbuf is stored with the last rx_bd entry of a packet. */
		if (sc->rx_mbuf_ptr[sw_chain_cons] != NULL) {
			/* Validate that this is the last rx_bd. */
			DBRUNIF((!(rxbd->rx_bd_flags & RX_BD_FLAGS_END)),
			    printf("%s: Unexpected mbuf found in "
			        "rx_bd[0x%04X]!\n", sw_chain_cons);
				bnx_breakpoint(sc));

			/* DRC - ToDo: If the received packet is small, say less
			 *             than 128 bytes, allocate a new mbuf here,
			 *             copy the data to that mbuf, and recycle
			 *             the mapped jumbo frame.
			 */

			/* Unmap the mbuf from DMA space. */
			bus_dmamap_sync(sc->bnx_dmatag,
			    sc->rx_mbuf_map[sw_chain_cons], 0,
			    sc->rx_mbuf_map[sw_chain_cons]->dm_mapsize,
			    BUS_DMASYNC_POSTREAD);
			bus_dmamap_unload(sc->bnx_dmatag,
			    sc->rx_mbuf_map[sw_chain_cons]);

			/* Remove the mbuf from RX chain. */
			m = sc->rx_mbuf_ptr[sw_chain_cons];
			sc->rx_mbuf_ptr[sw_chain_cons] = NULL;

			/*
			 * Frames received on the NetXteme II are prepended 
			 * with the l2_fhdr structure which provides status
			 * information about the received frame (including
			 * VLAN tags and checksum info) and are also
			 * automatically adjusted to align the IP header
			 * (i.e. two null bytes are inserted before the 
			 * Ethernet header).
			 */
			l2fhdr = mtod(m, struct l2_fhdr *);

			len    = l2fhdr->l2_fhdr_pkt_len;
			status = l2fhdr->l2_fhdr_status;

			DBRUNIF(DB_RANDOMTRUE(bnx_debug_l2fhdr_status_check),
			    printf("Simulating l2_fhdr status error.\n");
			    status = status | L2_FHDR_ERRORS_PHY_DECODE);

			/* Watch for unusual sized frames. */
			DBRUNIF(((len < BNX_MIN_MTU) ||
			    (len > BNX_MAX_JUMBO_ETHER_MTU_VLAN)),
			    printf("%s: Unusual frame size found. "
			    "Min(%d), Actual(%d), Max(%d)\n", (int)BNX_MIN_MTU,
			    len, (int) BNX_MAX_JUMBO_ETHER_MTU_VLAN);

			bnx_dump_mbuf(sc, m);
			bnx_breakpoint(sc));

			len -= ETHER_CRC_LEN;

			/* Check the received frame for errors. */
			if (status &  (L2_FHDR_ERRORS_BAD_CRC | 
			    L2_FHDR_ERRORS_PHY_DECODE |
			    L2_FHDR_ERRORS_ALIGNMENT | 
			    L2_FHDR_ERRORS_TOO_SHORT |
			    L2_FHDR_ERRORS_GIANT_FRAME)) {
				/* Log the error and release the mbuf. */
				ifp->if_ierrors++;
				DBRUNIF(1, sc->l2fhdr_status_errors++);

				m_freem(m);
				m = NULL;
				goto bnx_rx_int_next_rx;
			}

			/* Skip over the l2_fhdr when passing the data up
			 * the stack.
			 */
			m_adj(m, sizeof(struct l2_fhdr) + ETHER_ALIGN);

			/* Adjust the pckt length to match the received data. */
			m->m_pkthdr.len = m->m_len = len;

			DBRUN(BNX_VERBOSE_RECV,
			    struct ether_header *eh;
			    eh = mtod(m, struct ether_header *);
			    printf("%s: to: %6D, from: %6D, type: 0x%04X\n",
			    __FUNCTION__, eh->ether_dhost, ":", 
			    eh->ether_shost, ":", htons(eh->ether_type)));

			/* Validate the checksum. */

			/* Check for an IP datagram. */
			if (status & L2_FHDR_STATUS_IP_DATAGRAM) {
				/* Check if the IP checksum is valid. */
				if ((l2fhdr->l2_fhdr_ip_xsum ^ 0xffff)
				    == 0)
					m->m_pkthdr.csum_flags |=
					    M_IPV4_CSUM_IN_OK;
				else
					DBPRINT(sc, BNX_WARN_SEND, 
					    "%s(): Invalid IP checksum "
					        "= 0x%04X!\n",
						__FUNCTION__,
						l2fhdr->l2_fhdr_ip_xsum
						);
			}

			/* Check for a valid TCP/UDP frame. */
			if (status & (L2_FHDR_STATUS_TCP_SEGMENT |
			    L2_FHDR_STATUS_UDP_DATAGRAM)) {
				/* Check for a good TCP/UDP checksum. */
				if ((status &
				    (L2_FHDR_ERRORS_TCP_XSUM |
				    L2_FHDR_ERRORS_UDP_XSUM)) == 0) {
					m->m_pkthdr.csum_flags |=
					    M_TCP_CSUM_IN_OK |
					    M_UDP_CSUM_IN_OK;
				} else {
					DBPRINT(sc, BNX_WARN_SEND, 
					    "%s(): Invalid TCP/UDP "
					    "checksum = 0x%04X!\n",
					    __FUNCTION__,
					    l2fhdr->l2_fhdr_tcp_udp_xsum);
				}
			}

			/*
			 * If we received a packet with a vlan tag,
			 * attach that information to the packet.
			 */
			if ((status & L2_FHDR_STATUS_L2_VLAN_TAG) &&
			    !(sc->rx_mode & BNX_EMAC_RX_MODE_KEEP_VLAN_TAG)) {
#if NVLAN > 0
				DBPRINT(sc, BNX_VERBOSE_SEND,
				    "%s(): VLAN tag = 0x%04X\n",
				    __FUNCTION__,
				    l2fhdr->l2_fhdr_vlan_tag);

				m->m_pkthdr.ether_vtag =
				    l2fhdr->l2_fhdr_vlan_tag;
				m->m_flags |= M_VLANTAG;
#else
				m_freem(m);
				m = NULL;
				goto bnx_rx_int_next_rx;
#endif			
			}

bnx_rx_int_next_rx:
			sw_prod = NEXT_RX_BD(sw_prod);
		}

		sw_cons = NEXT_RX_BD(sw_cons);

		/* If we have a packet, pass it up the stack */
		if (m) {
			sc->rx_cons = sw_cons;

			DBPRINT(sc, BNX_VERBOSE_RECV,
			    "%s(): Passing received frame up.\n", __FUNCTION__);
			ml_enqueue(&ml, m);
			DBRUNIF(1, sc->rx_mbuf_alloc--);

			sw_cons = sc->rx_cons;
		}

		/* Refresh hw_cons to see if there's new work */
		if (sw_cons == hw_cons) {
			hw_cons = sc->hw_rx_cons =
			    sblk->status_rx_quick_consumer_index0;
			if ((hw_cons & USABLE_RX_BD_PER_PAGE) ==
			    USABLE_RX_BD_PER_PAGE)
				hw_cons++;
		}

		/* Prevent speculative reads from getting ahead of
		 * the status block.
		 */
		bus_space_barrier(sc->bnx_btag, sc->bnx_bhandle, 0, 0, 
		    BUS_SPACE_BARRIER_READ);
	}

	/* No new packets to process.  Refill the RX chain and exit. */
	sc->rx_cons = sw_cons;
	if (!bnx_fill_rx_chain(sc))
		timeout_add(&sc->bnx_rxrefill, 1);

	for (i = 0; i < RX_PAGES; i++)
		bus_dmamap_sync(sc->bnx_dmatag,
		    sc->rx_bd_chain_map[i], 0,
		    sc->rx_bd_chain_map[i]->dm_mapsize,
		    BUS_DMASYNC_PREWRITE);

	if_input(ifp, &ml);

	DBPRINT(sc, BNX_INFO_RECV, "%s(exit): rx_prod = 0x%04X, "
	    "rx_cons = 0x%04X, rx_prod_bseq = 0x%08X\n",
	    __FUNCTION__, sc->rx_prod, sc->rx_cons, sc->rx_prod_bseq);
}

/****************************************************************************/
/* Handles transmit completion interrupt events.                            */
/*                                                                          */
/* Returns:                                                                 */
/*   Nothing.                                                               */
/****************************************************************************/
void
bnx_tx_intr(struct bnx_softc *sc)
{
	struct status_block	*sblk = sc->status_block;
	struct ifnet		*ifp = &sc->arpcom.ac_if;
	bus_dmamap_t		map;
	u_int16_t		hw_tx_cons, sw_tx_cons, sw_tx_chain_cons;
	int			freed, used;

	DBRUNIF(1, sc->tx_interrupts++);

	/* Get the hardware's view of the TX consumer index. */
	hw_tx_cons = sc->hw_tx_cons = sblk->status_tx_quick_consumer_index0;

	/* Skip to the next entry if this is a chain page pointer. */
	if ((hw_tx_cons & USABLE_TX_BD_PER_PAGE) == USABLE_TX_BD_PER_PAGE)
		hw_tx_cons++;

	sw_tx_cons = sc->tx_cons;

	/* Prevent speculative reads from getting ahead of the status block. */
	bus_space_barrier(sc->bnx_btag, sc->bnx_bhandle, 0, 0, 
	    BUS_SPACE_BARRIER_READ);

	/* Cycle through any completed TX chain page entries. */
	freed = 0;
	while (sw_tx_cons != hw_tx_cons) {
#ifdef BNX_DEBUG
		struct tx_bd *txbd = NULL;
#endif
		sw_tx_chain_cons = TX_CHAIN_IDX(sw_tx_cons);

		DBPRINT(sc, BNX_INFO_SEND, "%s(): hw_tx_cons = 0x%04X, "
		    "sw_tx_cons = 0x%04X, sw_tx_chain_cons = 0x%04X\n",
		    __FUNCTION__, hw_tx_cons, sw_tx_cons, sw_tx_chain_cons);

		DBRUNIF((sw_tx_chain_cons > MAX_TX_BD),
		    printf("%s: TX chain consumer out of range! "
		    " 0x%04X > 0x%04X\n", sw_tx_chain_cons, (int)MAX_TX_BD);
		    bnx_breakpoint(sc));

		DBRUNIF(1, txbd = &sc->tx_bd_chain
		    [TX_PAGE(sw_tx_chain_cons)][TX_IDX(sw_tx_chain_cons)]);
		
		DBRUNIF((txbd == NULL),
		    printf("%s: Unexpected NULL tx_bd[0x%04X]!\n", 
		    sw_tx_chain_cons);
		    bnx_breakpoint(sc));

		DBRUN(BNX_INFO_SEND, printf("%s: ", __FUNCTION__);
		    bnx_dump_txbd(sc, sw_tx_chain_cons, txbd));

		map = sc->tx_mbuf_map[sw_tx_chain_cons];
		if (sc->tx_mbuf_ptr[sw_tx_chain_cons] != NULL) {
			/* Validate that this is the last tx_bd. */
			DBRUNIF((!(txbd->tx_bd_flags & TX_BD_FLAGS_END)),
			    printf("%s: tx_bd END flag not set but "
			    "txmbuf == NULL!\n");
			    bnx_breakpoint(sc));

			DBRUN(BNX_INFO_SEND,
			    printf("%s: Unloading map/freeing mbuf "
			    "from tx_bd[0x%04X]\n",
			    __FUNCTION__, sw_tx_chain_cons));

			/* Unmap the mbuf. */
			bus_dmamap_sync(sc->bnx_dmatag, map, 0,
			    map->dm_mapsize, BUS_DMASYNC_POSTWRITE);
			bus_dmamap_unload(sc->bnx_dmatag, map);

			/* Free the mbuf. */
			m_freem(sc->tx_mbuf_ptr[sw_tx_chain_cons]);
			sc->tx_mbuf_ptr[sw_tx_chain_cons] = NULL;
		}
		
		freed++;
		sw_tx_cons = NEXT_TX_BD(sw_tx_cons);
	}

	used = atomic_sub_int_nv(&sc->used_tx_bd, freed);

	sc->tx_cons = sw_tx_cons;

	/* Clear the TX timeout timer. */
	if (used == 0)
		ifp->if_timer = 0;

	if (ifq_is_oactive(&ifp->if_snd))
		ifq_restart(&ifp->if_snd);
}

/****************************************************************************/
/* Disables interrupt generation.                                           */
/*                                                                          */
/* Returns:                                                                 */
/*   Nothing.                                                               */
/****************************************************************************/
void
bnx_disable_intr(struct bnx_softc *sc)
{
	REG_WR(sc, BNX_PCICFG_INT_ACK_CMD, BNX_PCICFG_INT_ACK_CMD_MASK_INT);
	REG_RD(sc, BNX_PCICFG_INT_ACK_CMD);
}

/****************************************************************************/
/* Enables interrupt generation.                                            */
/*                                                                          */
/* Returns:                                                                 */
/*   Nothing.                                                               */
/****************************************************************************/
void
bnx_enable_intr(struct bnx_softc *sc)
{
	u_int32_t		val;

	REG_WR(sc, BNX_PCICFG_INT_ACK_CMD, BNX_PCICFG_INT_ACK_CMD_INDEX_VALID |
	    BNX_PCICFG_INT_ACK_CMD_MASK_INT | sc->last_status_idx);

	REG_WR(sc, BNX_PCICFG_INT_ACK_CMD, BNX_PCICFG_INT_ACK_CMD_INDEX_VALID | 
	    sc->last_status_idx);

	val = REG_RD(sc, BNX_HC_COMMAND);
	REG_WR(sc, BNX_HC_COMMAND, val | BNX_HC_COMMAND_COAL_NOW);
}

/****************************************************************************/
/* Handles controller initialization.                                       */
/*                                                                          */
/* Returns:                                                                 */
/*   Nothing.                                                               */
/****************************************************************************/
void
bnx_init(void *xsc)
{
	struct bnx_softc	*sc = (struct bnx_softc *)xsc;
	struct ifnet		*ifp = &sc->arpcom.ac_if;
	u_int32_t		ether_mtu;
	int			s;

	DBPRINT(sc, BNX_VERBOSE_RESET, "Entering %s()\n", __FUNCTION__);

	s = splnet();

	bnx_stop(sc);

	if (bnx_reset(sc, BNX_DRV_MSG_CODE_RESET)) {
		BNX_PRINTF(sc, "Controller reset failed!\n");
		goto bnx_init_exit;
	}

	if (bnx_chipinit(sc)) {
		BNX_PRINTF(sc, "Controller initialization failed!\n");
		goto bnx_init_exit;
	}

	if (bnx_blockinit(sc)) {
		BNX_PRINTF(sc, "Block initialization failed!\n");
		goto bnx_init_exit;
	}

	/* Load our MAC address. */
	bcopy(sc->arpcom.ac_enaddr, sc->eaddr, ETHER_ADDR_LEN);
	bnx_set_mac_addr(sc);

	/* Calculate and program the Ethernet MRU size. */
	ether_mtu = BNX_MAX_STD_ETHER_MTU_VLAN;

	DBPRINT(sc, BNX_INFO, "%s(): setting MRU = %d\n",
	    __FUNCTION__, ether_mtu);

	/*
	 * Program the MRU and enable Jumbo frame
	 * support.
	 */
	REG_WR(sc, BNX_EMAC_RX_MTU_SIZE, ether_mtu |
		BNX_EMAC_RX_MTU_SIZE_JUMBO_ENA);

	/* Calculate the RX Ethernet frame size for rx_bd's. */
	sc->max_frame_size = sizeof(struct l2_fhdr) + 2 + ether_mtu + 8;

	DBPRINT(sc, BNX_INFO, "%s(): mclbytes = %d, mbuf_alloc_size = %d, "
	    "max_frame_size = %d\n", __FUNCTION__, (int)MCLBYTES,
	    sc->mbuf_alloc_size, sc->max_frame_size);

	/* Program appropriate promiscuous/multicast filtering. */
	bnx_iff(sc);

	/* Init RX buffer descriptor chain. */
	bnx_init_rx_chain(sc);

	/* Init TX buffer descriptor chain. */
	bnx_init_tx_chain(sc);

	/* Enable host interrupts. */
	bnx_enable_intr(sc);

	bnx_ifmedia_upd(ifp);

	ifp->if_flags |= IFF_RUNNING;
	ifq_clr_oactive(&ifp->if_snd);

	timeout_add_sec(&sc->bnx_timeout, 1);

bnx_init_exit:
	DBPRINT(sc, BNX_VERBOSE_RESET, "Exiting %s()\n", __FUNCTION__);

	splx(s);

	return;
}

void
bnx_mgmt_init(struct bnx_softc *sc)
{
	struct ifnet	*ifp = &sc->arpcom.ac_if;
	u_int32_t	val;

	/* Check if the driver is still running and bail out if it is. */
	if (ifp->if_flags & IFF_RUNNING)
		goto bnx_mgmt_init_exit;

	/* Initialize the on-boards CPUs */
	bnx_init_cpus(sc);

	val = (BCM_PAGE_BITS - 8) << 24;
	REG_WR(sc, BNX_RV2P_CONFIG, val);

	/* Enable all critical blocks in the MAC. */
	REG_WR(sc, BNX_MISC_ENABLE_SET_BITS,
	    BNX_MISC_ENABLE_SET_BITS_RX_V2P_ENABLE |
	    BNX_MISC_ENABLE_SET_BITS_RX_DMA_ENABLE |
	    BNX_MISC_ENABLE_SET_BITS_COMPLETION_ENABLE);
	REG_RD(sc, BNX_MISC_ENABLE_SET_BITS);
	DELAY(20);

	bnx_ifmedia_upd(ifp);

bnx_mgmt_init_exit:
 	DBPRINT(sc, BNX_VERBOSE_RESET, "Exiting %s()\n", __FUNCTION__);
}

/****************************************************************************/
/* Encapsultes an mbuf cluster into the tx_bd chain structure and makes the */
/* memory visible to the controller.                                        */
/*                                                                          */
/* Returns:                                                                 */
/*   0 for success, positive value for failure.                             */
/****************************************************************************/
int
bnx_tx_encap(struct bnx_softc *sc, struct mbuf *m, int *used)
{
	bus_dmamap_t		map;
	struct tx_bd 		*txbd = NULL;
	u_int16_t		vlan_tag = 0, flags = 0;
	u_int16_t		chain_prod, chain_head, prod;
#ifdef BNX_DEBUG
	u_int16_t		debug_prod;
#endif
	u_int32_t		addr, prod_bseq;
	int			i, error;

	/* Transfer any checksum offload flags to the bd. */
	if (m->m_pkthdr.csum_flags) {
		if (m->m_pkthdr.csum_flags & M_IPV4_CSUM_OUT)
			flags |= TX_BD_FLAGS_IP_CKSUM;
		if (m->m_pkthdr.csum_flags &
		    (M_TCP_CSUM_OUT | M_UDP_CSUM_OUT))
			flags |= TX_BD_FLAGS_TCP_UDP_CKSUM;
	}

#if NVLAN > 0
	/* Transfer any VLAN tags to the bd. */
	if (m->m_flags & M_VLANTAG) {
		flags |= TX_BD_FLAGS_VLAN_TAG;
		vlan_tag = m->m_pkthdr.ether_vtag;
	}
#endif

	/* Map the mbuf into DMAable memory. */
	prod = sc->tx_prod;
	chain_head = chain_prod = TX_CHAIN_IDX(prod);
	map = sc->tx_mbuf_map[chain_head];

	/* Map the mbuf into our DMA address space. */
	error = bus_dmamap_load_mbuf(sc->bnx_dmatag, map, m,
	    BUS_DMA_NOWAIT);
	switch (error) {
	case 0:
		break;

	case EFBIG:
		if ((error = m_defrag(m, M_DONTWAIT)) == 0 &&
		    (error = bus_dmamap_load_mbuf(sc->bnx_dmatag, map, m,
		     BUS_DMA_NOWAIT)) == 0)
			break;

		/* FALLTHROUGH */
	default:
		sc->tx_dma_map_failures++;
		return (ENOBUFS);
	}

	/* prod points to an empty tx_bd at this point. */
	prod_bseq = sc->tx_prod_bseq;
#ifdef BNX_DEBUG
	debug_prod = chain_prod;
#endif

	DBPRINT(sc, BNX_INFO_SEND,
		"%s(): Start: prod = 0x%04X, chain_prod = %04X, "
		"prod_bseq = 0x%08X\n",
		__FUNCTION__, prod, chain_prod, prod_bseq);

	/*
	 * Cycle through each mbuf segment that makes up
	 * the outgoing frame, gathering the mapping info
	 * for that segment and creating a tx_bd for the
	 * mbuf.
	 */
	for (i = 0; i < map->dm_nsegs ; i++) {
		chain_prod = TX_CHAIN_IDX(prod);
		txbd = &sc->tx_bd_chain[TX_PAGE(chain_prod)][TX_IDX(chain_prod)];

		addr = (u_int32_t)map->dm_segs[i].ds_addr;
		txbd->tx_bd_haddr_lo = addr;
		addr = (u_int32_t)((u_int64_t)map->dm_segs[i].ds_addr >> 32);
		txbd->tx_bd_haddr_hi = addr;
		txbd->tx_bd_mss_nbytes = map->dm_segs[i].ds_len;
		txbd->tx_bd_vlan_tag = vlan_tag;
		txbd->tx_bd_flags = flags;
		prod_bseq += map->dm_segs[i].ds_len;
		if (i == 0)
			txbd->tx_bd_flags |= TX_BD_FLAGS_START;
		prod = NEXT_TX_BD(prod);
 	}

	/* Set the END flag on the last TX buffer descriptor. */
	txbd->tx_bd_flags |= TX_BD_FLAGS_END;

	DBRUN(BNX_INFO_SEND, bnx_dump_tx_chain(sc, debug_prod,
	    map->dm_nsegs));

	DBPRINT(sc, BNX_INFO_SEND,
		"%s(): End: prod = 0x%04X, chain_prod = %04X, "
		"prod_bseq = 0x%08X\n",
		__FUNCTION__, prod, chain_prod, prod_bseq);

	sc->tx_mbuf_ptr[chain_prod] = m;
	sc->tx_mbuf_map[chain_head] = sc->tx_mbuf_map[chain_prod];
	sc->tx_mbuf_map[chain_prod] = map;

	*used += map->dm_nsegs;

	DBRUNIF(1, sc->tx_mbuf_alloc++);

	DBRUN(BNX_VERBOSE_SEND, bnx_dump_tx_mbuf_chain(sc, chain_prod, 
	    map->dm_nsegs));

	bus_dmamap_sync(sc->bnx_dmatag, map, 0, map->dm_mapsize,
	    BUS_DMASYNC_PREWRITE);

	/* prod points to the next free tx_bd at this point. */
	sc->tx_prod = prod;
	sc->tx_prod_bseq = prod_bseq;

	return (0);
}

/****************************************************************************/
/* Main transmit routine.                                                   */
/*                                                                          */
/* Returns:                                                                 */
/*   Nothing.                                                               */
/****************************************************************************/
void
bnx_start(struct ifqueue *ifq)
{
	struct ifnet		*ifp = ifq->ifq_if;
	struct bnx_softc	*sc = ifp->if_softc;
	struct mbuf		*m_head = NULL;
	int			used;
	u_int16_t		tx_prod, tx_chain_prod;

	if (!sc->bnx_link) {
		ifq_purge(ifq);
		goto bnx_start_exit;
	}

	/* prod points to the next free tx_bd. */
	tx_prod = sc->tx_prod;
	tx_chain_prod = TX_CHAIN_IDX(tx_prod);

	DBPRINT(sc, BNX_INFO_SEND, "%s(): Start: tx_prod = 0x%04X, "
	    "tx_chain_prod = %04X, tx_prod_bseq = 0x%08X\n",
	    __FUNCTION__, tx_prod, tx_chain_prod, sc->tx_prod_bseq);

	/*
	 * Keep adding entries while there is space in the ring.
	 */
	used = 0;
	while (1) {
		if (sc->used_tx_bd + used + BNX_MAX_SEGMENTS + 1 >=
		    sc->max_tx_bd) {
			DBPRINT(sc, BNX_INFO_SEND, "TX chain is closed for "
			    "business! Total tx_bd used = %d\n",
			    sc->used_tx_bd + used);
			ifq_set_oactive(ifq);
			break;
		}

		m_head = ifq_dequeue(ifq);
		if (m_head == NULL)
			break;

		if (bnx_tx_encap(sc, m_head, &used)) {
			m_freem(m_head);
			continue;
		}

#if NBPFILTER > 0
		if (ifp->if_bpf)
			bpf_mtap_ether(ifp->if_bpf, m_head, BPF_DIRECTION_OUT);
#endif
	}

	if (used == 0) {
		/* no packets were dequeued */
		DBPRINT(sc, BNX_VERBOSE_SEND,
		    "%s(): No packets were dequeued\n", __FUNCTION__);
		goto bnx_start_exit;
	}

	/* Update the driver's counters. */
	used = atomic_add_int_nv(&sc->used_tx_bd, used);

	/* Update some debug statistics counters */
	DBRUNIF((used > sc->tx_hi_watermark),
	    sc->tx_hi_watermark = used);
	DBRUNIF(used == sc->max_tx_bd, sc->tx_full_count++);

	tx_chain_prod = TX_CHAIN_IDX(sc->tx_prod);
	DBPRINT(sc, BNX_INFO_SEND, "%s(): End: tx_prod = 0x%04X, tx_chain_prod "
	    "= 0x%04X, tx_prod_bseq = 0x%08X\n", __FUNCTION__, tx_prod,
	    tx_chain_prod, sc->tx_prod_bseq);

	/* Start the transmit. */
	REG_WR16(sc, MB_TX_CID_ADDR + BNX_L2CTX_TX_HOST_BIDX, sc->tx_prod);
	REG_WR(sc, MB_TX_CID_ADDR + BNX_L2CTX_TX_HOST_BSEQ, sc->tx_prod_bseq);

	/* Set the tx timeout. */
	ifp->if_timer = BNX_TX_TIMEOUT;

bnx_start_exit:
	return;
}

/****************************************************************************/
/* Handles any IOCTL calls from the operating system.                       */
/*                                                                          */
/* Returns:                                                                 */
/*   0 for success, positive value for failure.                             */
/****************************************************************************/
int
bnx_ioctl(struct ifnet *ifp, u_long command, caddr_t data)
{
	struct bnx_softc	*sc = ifp->if_softc;
	struct ifreq		*ifr = (struct ifreq *) data;
	struct mii_data		*mii = &sc->bnx_mii;
	int			s, error = 0;

	s = splnet();

	switch (command) {
	case SIOCSIFADDR:
		ifp->if_flags |= IFF_UP;
		if (!(ifp->if_flags & IFF_RUNNING))
			bnx_init(sc);
		break;

	case SIOCSIFFLAGS:
		if (ifp->if_flags & IFF_UP) {
			if (ifp->if_flags & IFF_RUNNING)
				error = ENETRESET;
			else
				bnx_init(sc);
		} else {
			if (ifp->if_flags & IFF_RUNNING)
				bnx_stop(sc);
		}
		break;

	case SIOCSIFMEDIA:
		/* Flow control requires full-duplex mode. */
		if (IFM_SUBTYPE(ifr->ifr_media) == IFM_AUTO ||
		    (ifr->ifr_media & IFM_FDX) == 0)
			ifr->ifr_media &= ~IFM_ETH_FMASK;

		if (IFM_SUBTYPE(ifr->ifr_media) != IFM_AUTO) {
			if ((ifr->ifr_media & IFM_ETH_FMASK) == IFM_FLOW) {
				/* We can do both TXPAUSE and RXPAUSE. */
				ifr->ifr_media |=
				    IFM_ETH_TXPAUSE | IFM_ETH_RXPAUSE;
			}
			sc->bnx_flowflags = ifr->ifr_media & IFM_ETH_FMASK;
		}
		/* FALLTHROUGH */
	case SIOCGIFMEDIA:
		DBPRINT(sc, BNX_VERBOSE, "bnx_phy_flags = 0x%08X\n",
		    sc->bnx_phy_flags);

		error = ifmedia_ioctl(ifp, ifr, &mii->mii_media, command);
		break;

	case SIOCGIFRXR:
		error = if_rxr_ioctl((struct if_rxrinfo *)ifr->ifr_data,
		    NULL, MCLBYTES, &sc->rx_ring);
		break;

	default:
		error = ether_ioctl(ifp, &sc->arpcom, command, data);
	}

	if (error == ENETRESET) {
		if (ifp->if_flags & IFF_RUNNING)
			bnx_iff(sc);
		error = 0;
	}

	splx(s);
	return (error);
}

/****************************************************************************/
/* Transmit timeout handler.                                                */
/*                                                                          */
/* Returns:                                                                 */
/*   Nothing.                                                               */
/****************************************************************************/
void
bnx_watchdog(struct ifnet *ifp)
{
	struct bnx_softc	*sc = ifp->if_softc;

	DBRUN(BNX_WARN_SEND, bnx_dump_driver_state(sc);
	    bnx_dump_status_block(sc));

	/*
	 * If we are in this routine because of pause frames, then
	 * don't reset the hardware.
	 */
	if (REG_RD(sc, BNX_EMAC_TX_STATUS) & BNX_EMAC_TX_STATUS_XOFFED)	
		return;

	printf("%s: Watchdog timeout occurred, resetting!\n",
	    ifp->if_xname);

	/* DBRUN(BNX_FATAL, bnx_breakpoint(sc)); */

	bnx_init(sc);

	ifp->if_oerrors++;
}

/*
 * Interrupt handler.
 */
/****************************************************************************/
/* Main interrupt entry point.  Verifies that the controller generated the  */
/* interrupt and then calls a separate routine for handle the various       */
/* interrupt causes (PHY, TX, RX).                                          */
/*                                                                          */
/* Returns:                                                                 */
/*   0 for success, positive value for failure.                             */
/****************************************************************************/
int
bnx_intr(void *xsc)
{
	struct bnx_softc	*sc = xsc;
	struct ifnet		*ifp = &sc->arpcom.ac_if;
	u_int32_t		status_attn_bits;
	u_int16_t		status_idx;
	int			rv = 0;

	if ((sc->bnx_flags & BNX_ACTIVE_FLAG) == 0)
		return (0);

	DBRUNIF(1, sc->interrupts_generated++);

	bus_dmamap_sync(sc->bnx_dmatag, sc->status_map, 0,
	    sc->status_map->dm_mapsize, BUS_DMASYNC_POSTREAD);

	/*
	 * If the hardware status block index
	 * matches the last value read by the
	 * driver and we haven't asserted our
	 * interrupt then there's nothing to do.
	 */
	status_idx = sc->status_block->status_idx;
	if (status_idx != sc->last_status_idx || 
	    !ISSET(REG_RD(sc, BNX_PCICFG_MISC_STATUS),
	    BNX_PCICFG_MISC_STATUS_INTA_VALUE)) {
		rv = 1;

		/* Ack the interrupt */
		REG_WR(sc, BNX_PCICFG_INT_ACK_CMD,
		    BNX_PCICFG_INT_ACK_CMD_INDEX_VALID | status_idx);

		status_attn_bits = sc->status_block->status_attn_bits;

		DBRUNIF(DB_RANDOMTRUE(bnx_debug_unexpected_attention),
		    printf("Simulating unexpected status attention bit set.");
		    status_attn_bits = status_attn_bits |
		    STATUS_ATTN_BITS_PARITY_ERROR);

		/* Was it a link change interrupt? */
		if ((status_attn_bits & STATUS_ATTN_BITS_LINK_STATE) !=
		    (sc->status_block->status_attn_bits_ack &
		    STATUS_ATTN_BITS_LINK_STATE)) {
			KERNEL_LOCK();
			bnx_phy_intr(sc);
			KERNEL_UNLOCK();
		}

		/* If any other attention is asserted then the chip is toast. */
		if (((status_attn_bits & ~STATUS_ATTN_BITS_LINK_STATE) !=
		    (sc->status_block->status_attn_bits_ack & 
		    ~STATUS_ATTN_BITS_LINK_STATE))) {
			KERNEL_LOCK();
			DBRUN(1, sc->unexpected_attentions++);

			BNX_PRINTF(sc, "Fatal attention detected: 0x%08X\n",
			    sc->status_block->status_attn_bits);

			DBRUN(BNX_FATAL,
			    if (bnx_debug_unexpected_attention == 0)
				bnx_breakpoint(sc));

			bnx_init(sc);
			KERNEL_UNLOCK();
			goto out;
		}

		/* Check for any completed RX frames. */
		if (sc->status_block->status_rx_quick_consumer_index0 !=
		    sc->hw_rx_cons)
			bnx_rx_intr(sc);

		/* Check for any completed TX frames. */
		if (sc->status_block->status_tx_quick_consumer_index0 !=
		    sc->hw_tx_cons)
			bnx_tx_intr(sc);

		/*
		 * Save the status block index value for use during the
		 * next interrupt.
		 */
		sc->last_status_idx = status_idx;

		/* Start moving packets again */
		if (ifp->if_flags & IFF_RUNNING &&
		    !IFQ_IS_EMPTY(&ifp->if_snd))
			ifq_start(&ifp->if_snd);
	}

out:
	bus_dmamap_sync(sc->bnx_dmatag, sc->status_map, 0,
	    sc->status_map->dm_mapsize, BUS_DMASYNC_PREREAD);

	return (rv);
}

/****************************************************************************/
/* Programs the various packet receive modes (broadcast and multicast).     */
/*                                                                          */
/* Returns:                                                                 */
/*   Nothing.                                                               */
/****************************************************************************/
void
bnx_iff(struct bnx_softc *sc)
{
	struct arpcom		*ac = &sc->arpcom;
	struct ifnet		*ifp = &ac->ac_if;
	struct ether_multi	*enm;
	struct ether_multistep	step;
	u_int32_t		hashes[NUM_MC_HASH_REGISTERS] = { 0, 0, 0, 0, 0, 0, 0, 0 };
	u_int32_t		rx_mode, sort_mode;
	int			h, i;

	/* Initialize receive mode default settings. */
	rx_mode = sc->rx_mode & ~(BNX_EMAC_RX_MODE_PROMISCUOUS |
	    BNX_EMAC_RX_MODE_KEEP_VLAN_TAG);
	sort_mode = 1 | BNX_RPM_SORT_USER0_BC_EN;
	ifp->if_flags &= ~IFF_ALLMULTI;

	/*
	 * ASF/IPMI/UMP firmware requires that VLAN tag stripping
	 * be enbled.
	 */
	if (!(ifp->if_capabilities & IFCAP_VLAN_HWTAGGING) &&
	    (!(sc->bnx_flags & BNX_MFW_ENABLE_FLAG)))
		rx_mode |= BNX_EMAC_RX_MODE_KEEP_VLAN_TAG;

	/*
	 * Check for promiscuous, all multicast, or selected
	 * multicast address filtering.
	 */
	if (ifp->if_flags & IFF_PROMISC) {
		DBPRINT(sc, BNX_INFO, "Enabling promiscuous mode.\n");

		ifp->if_flags |= IFF_ALLMULTI;
		/* Enable promiscuous mode. */
		rx_mode |= BNX_EMAC_RX_MODE_PROMISCUOUS;
		sort_mode |= BNX_RPM_SORT_USER0_PROM_EN;
	} else if (ac->ac_multirangecnt > 0) {
		DBPRINT(sc, BNX_INFO, "Enabling all multicast mode.\n");

		ifp->if_flags |= IFF_ALLMULTI;
		/* Enable all multicast addresses. */
		for (i = 0; i < NUM_MC_HASH_REGISTERS; i++)
			REG_WR(sc, BNX_EMAC_MULTICAST_HASH0 + (i * 4),
			    0xffffffff);
		sort_mode |= BNX_RPM_SORT_USER0_MC_EN;
	} else {
		/* Accept one or more multicast(s). */
		DBPRINT(sc, BNX_INFO, "Enabling selective multicast mode.\n");

		ETHER_FIRST_MULTI(step, ac, enm);
		while (enm != NULL) {
			h = ether_crc32_le(enm->enm_addrlo, ETHER_ADDR_LEN) &
			    0xFF;

			hashes[(h & 0xE0) >> 5] |= 1 << (h & 0x1F);

			ETHER_NEXT_MULTI(step, enm);
		}

		for (i = 0; i < NUM_MC_HASH_REGISTERS; i++)
			REG_WR(sc, BNX_EMAC_MULTICAST_HASH0 + (i * 4),
			    hashes[i]);

		sort_mode |= BNX_RPM_SORT_USER0_MC_HSH_EN;
	}

	/* Only make changes if the recive mode has actually changed. */
	if (rx_mode != sc->rx_mode) {
		DBPRINT(sc, BNX_VERBOSE, "Enabling new receive mode: 0x%08X\n", 
		    rx_mode);

		sc->rx_mode = rx_mode;
		REG_WR(sc, BNX_EMAC_RX_MODE, rx_mode);
	}

	/* Disable and clear the exisitng sort before enabling a new sort. */
	REG_WR(sc, BNX_RPM_SORT_USER0, 0x0);
	REG_WR(sc, BNX_RPM_SORT_USER0, sort_mode);
	REG_WR(sc, BNX_RPM_SORT_USER0, sort_mode | BNX_RPM_SORT_USER0_ENA);
}

/****************************************************************************/
/* Called periodically to updates statistics from the controllers           */
/* statistics block.                                                        */
/*                                                                          */
/* Returns:                                                                 */
/*   Nothing.                                                               */
/****************************************************************************/
void
bnx_stats_update(struct bnx_softc *sc)
{
	struct ifnet		*ifp = &sc->arpcom.ac_if;
	struct statistics_block	*stats;

	DBPRINT(sc, BNX_EXCESSIVE, "Entering %s()\n", __FUNCTION__);

	stats = (struct statistics_block *)sc->stats_block;

	/* 
	 * Update the interface statistics from the
	 * hardware statistics.
	 */
	ifp->if_collisions = (u_long)stats->stat_EtherStatsCollisions;

	ifp->if_ierrors = (u_long)stats->stat_EtherStatsUndersizePkts +
	    (u_long)stats->stat_EtherStatsOverrsizePkts +
	    (u_long)stats->stat_IfInMBUFDiscards +
	    (u_long)stats->stat_Dot3StatsAlignmentErrors +
	    (u_long)stats->stat_Dot3StatsFCSErrors;

	ifp->if_oerrors = (u_long)
	    stats->stat_emac_tx_stat_dot3statsinternalmactransmiterrors +
	    (u_long)stats->stat_Dot3StatsExcessiveCollisions +
	    (u_long)stats->stat_Dot3StatsLateCollisions;

	/* 
	 * Certain controllers don't report 
	 * carrier sense errors correctly.
	 * See errata E11_5708CA0_1165. 
	 */
	if (!(BNX_CHIP_NUM(sc) == BNX_CHIP_NUM_5706) &&
	    !(BNX_CHIP_ID(sc) == BNX_CHIP_ID_5708_A0))
		ifp->if_oerrors += (u_long) stats->stat_Dot3StatsCarrierSenseErrors;

	/*
	 * Update the sysctl statistics from the
	 * hardware statistics.
	 */
	sc->stat_IfHCInOctets = ((u_int64_t)stats->stat_IfHCInOctets_hi << 32) +
	    (u_int64_t) stats->stat_IfHCInOctets_lo;

	sc->stat_IfHCInBadOctets =
	    ((u_int64_t) stats->stat_IfHCInBadOctets_hi << 32) + 
	    (u_int64_t) stats->stat_IfHCInBadOctets_lo;

	sc->stat_IfHCOutOctets =
	    ((u_int64_t) stats->stat_IfHCOutOctets_hi << 32) +
	    (u_int64_t) stats->stat_IfHCOutOctets_lo;

	sc->stat_IfHCOutBadOctets =
	    ((u_int64_t) stats->stat_IfHCOutBadOctets_hi << 32) +
	    (u_int64_t) stats->stat_IfHCOutBadOctets_lo;

	sc->stat_IfHCInUcastPkts =
	    ((u_int64_t) stats->stat_IfHCInUcastPkts_hi << 32) +
	    (u_int64_t) stats->stat_IfHCInUcastPkts_lo;

	sc->stat_IfHCInMulticastPkts =
	    ((u_int64_t) stats->stat_IfHCInMulticastPkts_hi << 32) +
	    (u_int64_t) stats->stat_IfHCInMulticastPkts_lo;

	sc->stat_IfHCInBroadcastPkts =
	    ((u_int64_t) stats->stat_IfHCInBroadcastPkts_hi << 32) +
	    (u_int64_t) stats->stat_IfHCInBroadcastPkts_lo;

	sc->stat_IfHCOutUcastPkts =
	   ((u_int64_t) stats->stat_IfHCOutUcastPkts_hi << 32) +
	    (u_int64_t) stats->stat_IfHCOutUcastPkts_lo;

	sc->stat_IfHCOutMulticastPkts =
	    ((u_int64_t) stats->stat_IfHCOutMulticastPkts_hi << 32) +
	    (u_int64_t) stats->stat_IfHCOutMulticastPkts_lo;

	sc->stat_IfHCOutBroadcastPkts =
	    ((u_int64_t) stats->stat_IfHCOutBroadcastPkts_hi << 32) +
	    (u_int64_t) stats->stat_IfHCOutBroadcastPkts_lo;

	sc->stat_emac_tx_stat_dot3statsinternalmactransmiterrors =
	    stats->stat_emac_tx_stat_dot3statsinternalmactransmiterrors;

	sc->stat_Dot3StatsCarrierSenseErrors =
	    stats->stat_Dot3StatsCarrierSenseErrors;

	sc->stat_Dot3StatsFCSErrors = stats->stat_Dot3StatsFCSErrors;

	sc->stat_Dot3StatsAlignmentErrors =
	    stats->stat_Dot3StatsAlignmentErrors;

	sc->stat_Dot3StatsSingleCollisionFrames =
	    stats->stat_Dot3StatsSingleCollisionFrames;

	sc->stat_Dot3StatsMultipleCollisionFrames =
	    stats->stat_Dot3StatsMultipleCollisionFrames;

	sc->stat_Dot3StatsDeferredTransmissions =
	    stats->stat_Dot3StatsDeferredTransmissions;

	sc->stat_Dot3StatsExcessiveCollisions =
	    stats->stat_Dot3StatsExcessiveCollisions;

	sc->stat_Dot3StatsLateCollisions = stats->stat_Dot3StatsLateCollisions;

	sc->stat_EtherStatsCollisions = stats->stat_EtherStatsCollisions;

	sc->stat_EtherStatsFragments = stats->stat_EtherStatsFragments;

	sc->stat_EtherStatsJabbers = stats->stat_EtherStatsJabbers;

	sc->stat_EtherStatsUndersizePkts = stats->stat_EtherStatsUndersizePkts;

	sc->stat_EtherStatsOverrsizePkts = stats->stat_EtherStatsOverrsizePkts;

	sc->stat_EtherStatsPktsRx64Octets =
	    stats->stat_EtherStatsPktsRx64Octets;

	sc->stat_EtherStatsPktsRx65Octetsto127Octets =
	    stats->stat_EtherStatsPktsRx65Octetsto127Octets;

	sc->stat_EtherStatsPktsRx128Octetsto255Octets =
	    stats->stat_EtherStatsPktsRx128Octetsto255Octets;

	sc->stat_EtherStatsPktsRx256Octetsto511Octets =
	    stats->stat_EtherStatsPktsRx256Octetsto511Octets;

	sc->stat_EtherStatsPktsRx512Octetsto1023Octets =
	    stats->stat_EtherStatsPktsRx512Octetsto1023Octets;

	sc->stat_EtherStatsPktsRx1024Octetsto1522Octets =
	    stats->stat_EtherStatsPktsRx1024Octetsto1522Octets;

	sc->stat_EtherStatsPktsRx1523Octetsto9022Octets =
	    stats->stat_EtherStatsPktsRx1523Octetsto9022Octets;

	sc->stat_EtherStatsPktsTx64Octets =
	    stats->stat_EtherStatsPktsTx64Octets;

	sc->stat_EtherStatsPktsTx65Octetsto127Octets =
	    stats->stat_EtherStatsPktsTx65Octetsto127Octets;

	sc->stat_EtherStatsPktsTx128Octetsto255Octets =
	    stats->stat_EtherStatsPktsTx128Octetsto255Octets;

	sc->stat_EtherStatsPktsTx256Octetsto511Octets =
	    stats->stat_EtherStatsPktsTx256Octetsto511Octets;

	sc->stat_EtherStatsPktsTx512Octetsto1023Octets =
	    stats->stat_EtherStatsPktsTx512Octetsto1023Octets;

	sc->stat_EtherStatsPktsTx1024Octetsto1522Octets =
	    stats->stat_EtherStatsPktsTx1024Octetsto1522Octets;

	sc->stat_EtherStatsPktsTx1523Octetsto9022Octets =
	    stats->stat_EtherStatsPktsTx1523Octetsto9022Octets;

	sc->stat_XonPauseFramesReceived = stats->stat_XonPauseFramesReceived;

	sc->stat_XoffPauseFramesReceived = stats->stat_XoffPauseFramesReceived;

	sc->stat_OutXonSent = stats->stat_OutXonSent;

	sc->stat_OutXoffSent = stats->stat_OutXoffSent;

	sc->stat_FlowControlDone = stats->stat_FlowControlDone;

	sc->stat_MacControlFramesReceived =
	    stats->stat_MacControlFramesReceived;

	sc->stat_XoffStateEntered = stats->stat_XoffStateEntered;

	sc->stat_IfInFramesL2FilterDiscards =
	    stats->stat_IfInFramesL2FilterDiscards;

	sc->stat_IfInRuleCheckerDiscards = stats->stat_IfInRuleCheckerDiscards;

	sc->stat_IfInFTQDiscards = stats->stat_IfInFTQDiscards;

	sc->stat_IfInMBUFDiscards = stats->stat_IfInMBUFDiscards;

	sc->stat_IfInRuleCheckerP4Hit = stats->stat_IfInRuleCheckerP4Hit;

	sc->stat_CatchupInRuleCheckerDiscards =
	    stats->stat_CatchupInRuleCheckerDiscards;

	sc->stat_CatchupInFTQDiscards = stats->stat_CatchupInFTQDiscards;

	sc->stat_CatchupInMBUFDiscards = stats->stat_CatchupInMBUFDiscards;

	sc->stat_CatchupInRuleCheckerP4Hit =
	    stats->stat_CatchupInRuleCheckerP4Hit;

	DBPRINT(sc, BNX_EXCESSIVE, "Exiting %s()\n", __FUNCTION__);
}

void
bnx_tick(void *xsc)
{
	struct bnx_softc	*sc = xsc;
	struct ifnet		*ifp = &sc->arpcom.ac_if;
	struct mii_data		*mii = NULL;
	u_int32_t		msg;

	/* Tell the firmware that the driver is still running. */
#ifdef BNX_DEBUG
	msg = (u_int32_t)BNX_DRV_MSG_DATA_PULSE_CODE_ALWAYS_ALIVE;
#else
	msg = (u_int32_t)++sc->bnx_fw_drv_pulse_wr_seq;
#endif
	REG_WR_IND(sc, sc->bnx_shmem_base + BNX_DRV_PULSE_MB, msg);

	/* Update the statistics from the hardware statistics block. */
	bnx_stats_update(sc);

	/* Schedule the next tick. */
	timeout_add_sec(&sc->bnx_timeout, 1);

	/* If link is up already up then we're done. */
	if (sc->bnx_link)
		goto bnx_tick_exit;

	mii = &sc->bnx_mii;
	mii_tick(mii);

	/* Check if the link has come up. */
	if (!sc->bnx_link && mii->mii_media_status & IFM_ACTIVE &&
	    IFM_SUBTYPE(mii->mii_media_active) != IFM_NONE) {
		sc->bnx_link++;
		/* Now that link is up, handle any outstanding TX traffic. */
		if (!ifq_empty(&ifp->if_snd))
			ifq_start(&ifp->if_snd);
	}

bnx_tick_exit:
	return;
}

/****************************************************************************/
/* BNX Debug Routines                                                       */
/****************************************************************************/
#ifdef BNX_DEBUG

/****************************************************************************/
/* Prints out information about an mbuf.                                    */
/*                                                                          */
/* Returns:                                                                 */
/*   Nothing.                                                               */
/****************************************************************************/
void
bnx_dump_mbuf(struct bnx_softc *sc, struct mbuf *m)
{
	struct mbuf		*mp = m;

	if (m == NULL) {
		/* Index out of range. */
		printf("mbuf ptr is null!\n");
		return;
	}

	while (mp) {
		printf("mbuf: vaddr = %p, m_len = %d, m_flags = ", 
		    mp, mp->m_len);

		if (mp->m_flags & M_EXT)
			printf("M_EXT ");
		if (mp->m_flags & M_PKTHDR)
			printf("M_PKTHDR ");
		printf("\n");

		if (mp->m_flags & M_EXT)
			printf("- m_ext: vaddr = %p, ext_size = 0x%04X\n", 
			    mp, mp->m_ext.ext_size);

		mp = mp->m_next;
	}
}

/****************************************************************************/
/* Prints out the mbufs in the TX mbuf chain.                               */
/*                                                                          */
/* Returns:                                                                 */
/*   Nothing.                                                               */
/****************************************************************************/
void
bnx_dump_tx_mbuf_chain(struct bnx_softc *sc, int chain_prod, int count)
{
	struct mbuf		*m;
	int			i;

	BNX_PRINTF(sc,
	    "----------------------------"
	    "  tx mbuf data  "
	    "----------------------------\n");

	for (i = 0; i < count; i++) {
	 	m = sc->tx_mbuf_ptr[chain_prod];
		BNX_PRINTF(sc, "txmbuf[%d]\n", chain_prod);
		bnx_dump_mbuf(sc, m);
		chain_prod = TX_CHAIN_IDX(NEXT_TX_BD(chain_prod));
	}

	BNX_PRINTF(sc,
	    "--------------------------------------------"
	    "----------------------------\n");
}

/*
 * This routine prints the RX mbuf chain.
 */
void
bnx_dump_rx_mbuf_chain(struct bnx_softc *sc, int chain_prod, int count)
{
	struct mbuf		*m;
	int			i;

	BNX_PRINTF(sc,
	    "----------------------------"
	    "  rx mbuf data  "
	    "----------------------------\n");

	for (i = 0; i < count; i++) {
	 	m = sc->rx_mbuf_ptr[chain_prod];
		BNX_PRINTF(sc, "rxmbuf[0x%04X]\n", chain_prod);
		bnx_dump_mbuf(sc, m);
		chain_prod = RX_CHAIN_IDX(NEXT_RX_BD(chain_prod));
	}


	BNX_PRINTF(sc,
	    "--------------------------------------------"
	    "----------------------------\n");
}

void
bnx_dump_txbd(struct bnx_softc *sc, int idx, struct tx_bd *txbd)
{
	if (idx > MAX_TX_BD)
		/* Index out of range. */
		BNX_PRINTF(sc, "tx_bd[0x%04X]: Invalid tx_bd index!\n", idx);
	else if ((idx & USABLE_TX_BD_PER_PAGE) == USABLE_TX_BD_PER_PAGE)
		/* TX Chain page pointer. */
		BNX_PRINTF(sc, "tx_bd[0x%04X]: haddr = 0x%08X:%08X, chain "
		    "page pointer\n", idx, txbd->tx_bd_haddr_hi,
		    txbd->tx_bd_haddr_lo);
	else
		/* Normal tx_bd entry. */
		BNX_PRINTF(sc, "tx_bd[0x%04X]: haddr = 0x%08X:%08X, nbytes = "
		    "0x%08X, vlan tag = 0x%4X, flags = 0x%08X\n", idx, 
		    txbd->tx_bd_haddr_hi, txbd->tx_bd_haddr_lo,
		    txbd->tx_bd_mss_nbytes, txbd->tx_bd_vlan_tag,
		    txbd->tx_bd_flags);
}

void
bnx_dump_rxbd(struct bnx_softc *sc, int idx, struct rx_bd *rxbd)
{
	if (idx > MAX_RX_BD)
		/* Index out of range. */
		BNX_PRINTF(sc, "rx_bd[0x%04X]: Invalid rx_bd index!\n", idx);
	else if ((idx & USABLE_RX_BD_PER_PAGE) == USABLE_RX_BD_PER_PAGE)
		/* TX Chain page pointer. */
		BNX_PRINTF(sc, "rx_bd[0x%04X]: haddr = 0x%08X:%08X, chain page "
		    "pointer\n", idx, rxbd->rx_bd_haddr_hi,
		    rxbd->rx_bd_haddr_lo);
	else
		/* Normal tx_bd entry. */
		BNX_PRINTF(sc, "rx_bd[0x%04X]: haddr = 0x%08X:%08X, nbytes = "
		    "0x%08X, flags = 0x%08X\n", idx, 
			rxbd->rx_bd_haddr_hi, rxbd->rx_bd_haddr_lo,
			rxbd->rx_bd_len, rxbd->rx_bd_flags);
}

void
bnx_dump_l2fhdr(struct bnx_softc *sc, int idx, struct l2_fhdr *l2fhdr)
{
	BNX_PRINTF(sc, "l2_fhdr[0x%04X]: status = 0x%08X, "
	    "pkt_len = 0x%04X, vlan = 0x%04x, ip_xsum = 0x%04X, "
	    "tcp_udp_xsum = 0x%04X\n", idx,
	    l2fhdr->l2_fhdr_status, l2fhdr->l2_fhdr_pkt_len,
	    l2fhdr->l2_fhdr_vlan_tag, l2fhdr->l2_fhdr_ip_xsum,
	    l2fhdr->l2_fhdr_tcp_udp_xsum);
}

/*
 * This routine prints the TX chain.
 */
void
bnx_dump_tx_chain(struct bnx_softc *sc, int tx_prod, int count)
{
	struct tx_bd		*txbd;
	int			i;

	/* First some info about the tx_bd chain structure. */
	BNX_PRINTF(sc,
	    "----------------------------"
	    "  tx_bd  chain  "
	    "----------------------------\n");

	BNX_PRINTF(sc,
	    "page size      = 0x%08X, tx chain pages        = 0x%08X\n",
	    (u_int32_t)BCM_PAGE_SIZE, (u_int32_t) TX_PAGES);

	BNX_PRINTF(sc,
	    "tx_bd per page = 0x%08X, usable tx_bd per page = 0x%08X\n",
	    (u_int32_t)TOTAL_TX_BD_PER_PAGE, (u_int32_t)USABLE_TX_BD_PER_PAGE);

	BNX_PRINTF(sc, "total tx_bd    = 0x%08X\n", (u_int32_t)TOTAL_TX_BD);

	BNX_PRINTF(sc, ""
	    "-----------------------------"
	    "   tx_bd data   "
	    "-----------------------------\n");

	/* Now print out the tx_bd's themselves. */
	for (i = 0; i < count; i++) {
	 	txbd = &sc->tx_bd_chain[TX_PAGE(tx_prod)][TX_IDX(tx_prod)];
		bnx_dump_txbd(sc, tx_prod, txbd);
		tx_prod = TX_CHAIN_IDX(NEXT_TX_BD(tx_prod));
	}

	BNX_PRINTF(sc,
	    "-----------------------------"
	    "--------------"
	    "-----------------------------\n");
}

/*
 * This routine prints the RX chain.
 */
void
bnx_dump_rx_chain(struct bnx_softc *sc, int rx_prod, int count)
{
	struct rx_bd		*rxbd;
	int			i;

	/* First some info about the tx_bd chain structure. */
	BNX_PRINTF(sc,
	    "----------------------------"
	    "  rx_bd  chain  "
	    "----------------------------\n");

	BNX_PRINTF(sc, "----- RX_BD Chain -----\n");

	BNX_PRINTF(sc,
	    "page size      = 0x%08X, rx chain pages        = 0x%08X\n",
	    (u_int32_t)BCM_PAGE_SIZE, (u_int32_t)RX_PAGES);

	BNX_PRINTF(sc,
	    "rx_bd per page = 0x%08X, usable rx_bd per page = 0x%08X\n",
	    (u_int32_t)TOTAL_RX_BD_PER_PAGE, (u_int32_t)USABLE_RX_BD_PER_PAGE);

	BNX_PRINTF(sc, "total rx_bd    = 0x%08X\n", (u_int32_t)TOTAL_RX_BD);

	BNX_PRINTF(sc,
	    "----------------------------"
	    "   rx_bd data   "
	    "----------------------------\n");

	/* Now print out the rx_bd's themselves. */
	for (i = 0; i < count; i++) {
		rxbd = &sc->rx_bd_chain[RX_PAGE(rx_prod)][RX_IDX(rx_prod)];
		bnx_dump_rxbd(sc, rx_prod, rxbd);
		rx_prod = RX_CHAIN_IDX(NEXT_RX_BD(rx_prod));
	}

	BNX_PRINTF(sc,
	    "----------------------------"
	    "--------------"
	    "----------------------------\n");
}

/*
 * This routine prints the status block.
 */
void
bnx_dump_status_block(struct bnx_softc *sc)
{
	struct status_block	*sblk;

	sblk = sc->status_block;

   	BNX_PRINTF(sc, "----------------------------- Status Block "
	    "-----------------------------\n");

	BNX_PRINTF(sc,
	    "attn_bits  = 0x%08X, attn_bits_ack = 0x%08X, index = 0x%04X\n",
	    sblk->status_attn_bits, sblk->status_attn_bits_ack,
	    sblk->status_idx);

	BNX_PRINTF(sc, "rx_cons0   = 0x%08X, tx_cons0      = 0x%08X\n",
	    sblk->status_rx_quick_consumer_index0,
	    sblk->status_tx_quick_consumer_index0);

	BNX_PRINTF(sc, "status_idx = 0x%04X\n", sblk->status_idx);

	/* Theses indices are not used for normal L2 drivers. */
	if (sblk->status_rx_quick_consumer_index1 || 
		sblk->status_tx_quick_consumer_index1)
		BNX_PRINTF(sc, "rx_cons1  = 0x%08X, tx_cons1      = 0x%08X\n",
		    sblk->status_rx_quick_consumer_index1,
		    sblk->status_tx_quick_consumer_index1);

	if (sblk->status_rx_quick_consumer_index2 || 
		sblk->status_tx_quick_consumer_index2)
		BNX_PRINTF(sc, "rx_cons2  = 0x%08X, tx_cons2      = 0x%08X\n",
		    sblk->status_rx_quick_consumer_index2,
		    sblk->status_tx_quick_consumer_index2);

	if (sblk->status_rx_quick_consumer_index3 || 
		sblk->status_tx_quick_consumer_index3)
		BNX_PRINTF(sc, "rx_cons3  = 0x%08X, tx_cons3      = 0x%08X\n",
		    sblk->status_rx_quick_consumer_index3,
		    sblk->status_tx_quick_consumer_index3);

	if (sblk->status_rx_quick_consumer_index4 || 
		sblk->status_rx_quick_consumer_index5)
		BNX_PRINTF(sc, "rx_cons4  = 0x%08X, rx_cons5      = 0x%08X\n",
		    sblk->status_rx_quick_consumer_index4,
		    sblk->status_rx_quick_consumer_index5);

	if (sblk->status_rx_quick_consumer_index6 || 
		sblk->status_rx_quick_consumer_index7)
		BNX_PRINTF(sc, "rx_cons6  = 0x%08X, rx_cons7      = 0x%08X\n",
		    sblk->status_rx_quick_consumer_index6,
		    sblk->status_rx_quick_consumer_index7);

	if (sblk->status_rx_quick_consumer_index8 || 
		sblk->status_rx_quick_consumer_index9)
		BNX_PRINTF(sc, "rx_cons8  = 0x%08X, rx_cons9      = 0x%08X\n",
		    sblk->status_rx_quick_consumer_index8,
		    sblk->status_rx_quick_consumer_index9);

	if (sblk->status_rx_quick_consumer_index10 || 
		sblk->status_rx_quick_consumer_index11)
		BNX_PRINTF(sc, "rx_cons10 = 0x%08X, rx_cons11     = 0x%08X\n",
		    sblk->status_rx_quick_consumer_index10,
		    sblk->status_rx_quick_consumer_index11);

	if (sblk->status_rx_quick_consumer_index12 || 
		sblk->status_rx_quick_consumer_index13)
		BNX_PRINTF(sc, "rx_cons12 = 0x%08X, rx_cons13     = 0x%08X\n",
		    sblk->status_rx_quick_consumer_index12,
		    sblk->status_rx_quick_consumer_index13);

	if (sblk->status_rx_quick_consumer_index14 || 
		sblk->status_rx_quick_consumer_index15)
		BNX_PRINTF(sc, "rx_cons14 = 0x%08X, rx_cons15     = 0x%08X\n",
		    sblk->status_rx_quick_consumer_index14,
		    sblk->status_rx_quick_consumer_index15);

	if (sblk->status_completion_producer_index || 
		sblk->status_cmd_consumer_index)
		BNX_PRINTF(sc, "com_prod  = 0x%08X, cmd_cons      = 0x%08X\n",
		    sblk->status_completion_producer_index,
		    sblk->status_cmd_consumer_index);

	BNX_PRINTF(sc, "-------------------------------------------"
	    "-----------------------------\n");
}

/*
 * This routine prints the statistics block.
 */
void
bnx_dump_stats_block(struct bnx_softc *sc)
{
	struct statistics_block	*sblk;

	sblk = sc->stats_block;

	BNX_PRINTF(sc, ""
	    "-----------------------------"
	    " Stats  Block "
	    "-----------------------------\n");

	BNX_PRINTF(sc, "IfHcInOctets         = 0x%08X:%08X, "
	    "IfHcInBadOctets      = 0x%08X:%08X\n",
	    sblk->stat_IfHCInOctets_hi, sblk->stat_IfHCInOctets_lo,
	    sblk->stat_IfHCInBadOctets_hi, sblk->stat_IfHCInBadOctets_lo);

	BNX_PRINTF(sc, "IfHcOutOctets        = 0x%08X:%08X, "
	    "IfHcOutBadOctets     = 0x%08X:%08X\n",
	    sblk->stat_IfHCOutOctets_hi, sblk->stat_IfHCOutOctets_lo,
	    sblk->stat_IfHCOutBadOctets_hi, sblk->stat_IfHCOutBadOctets_lo);

	BNX_PRINTF(sc, "IfHcInUcastPkts      = 0x%08X:%08X, "
	    "IfHcInMulticastPkts  = 0x%08X:%08X\n",
	    sblk->stat_IfHCInUcastPkts_hi, sblk->stat_IfHCInUcastPkts_lo,
	    sblk->stat_IfHCInMulticastPkts_hi,
	    sblk->stat_IfHCInMulticastPkts_lo);

	BNX_PRINTF(sc, "IfHcInBroadcastPkts  = 0x%08X:%08X, "
	    "IfHcOutUcastPkts     = 0x%08X:%08X\n",
	    sblk->stat_IfHCInBroadcastPkts_hi,
	    sblk->stat_IfHCInBroadcastPkts_lo,
	    sblk->stat_IfHCOutUcastPkts_hi,
	    sblk->stat_IfHCOutUcastPkts_lo);

	BNX_PRINTF(sc, "IfHcOutMulticastPkts = 0x%08X:%08X, "
	    "IfHcOutBroadcastPkts = 0x%08X:%08X\n",
	    sblk->stat_IfHCOutMulticastPkts_hi,
	    sblk->stat_IfHCOutMulticastPkts_lo,
	    sblk->stat_IfHCOutBroadcastPkts_hi,
	    sblk->stat_IfHCOutBroadcastPkts_lo);

	if (sblk->stat_emac_tx_stat_dot3statsinternalmactransmiterrors)
		BNX_PRINTF(sc, "0x%08X : "
		    "emac_tx_stat_dot3statsinternalmactransmiterrors\n", 
		    sblk->stat_emac_tx_stat_dot3statsinternalmactransmiterrors);

	if (sblk->stat_Dot3StatsCarrierSenseErrors)
		BNX_PRINTF(sc, "0x%08X : Dot3StatsCarrierSenseErrors\n",
		    sblk->stat_Dot3StatsCarrierSenseErrors);

	if (sblk->stat_Dot3StatsFCSErrors)
		BNX_PRINTF(sc, "0x%08X : Dot3StatsFCSErrors\n",
		    sblk->stat_Dot3StatsFCSErrors);

	if (sblk->stat_Dot3StatsAlignmentErrors)
		BNX_PRINTF(sc, "0x%08X : Dot3StatsAlignmentErrors\n",
		    sblk->stat_Dot3StatsAlignmentErrors);

	if (sblk->stat_Dot3StatsSingleCollisionFrames)
		BNX_PRINTF(sc, "0x%08X : Dot3StatsSingleCollisionFrames\n",
		    sblk->stat_Dot3StatsSingleCollisionFrames);

	if (sblk->stat_Dot3StatsMultipleCollisionFrames)
		BNX_PRINTF(sc, "0x%08X : Dot3StatsMultipleCollisionFrames\n",
		    sblk->stat_Dot3StatsMultipleCollisionFrames);
	
	if (sblk->stat_Dot3StatsDeferredTransmissions)
		BNX_PRINTF(sc, "0x%08X : Dot3StatsDeferredTransmissions\n",
		    sblk->stat_Dot3StatsDeferredTransmissions);

	if (sblk->stat_Dot3StatsExcessiveCollisions)
		BNX_PRINTF(sc, "0x%08X : Dot3StatsExcessiveCollisions\n",
		    sblk->stat_Dot3StatsExcessiveCollisions);

	if (sblk->stat_Dot3StatsLateCollisions)
		BNX_PRINTF(sc, "0x%08X : Dot3StatsLateCollisions\n",
		    sblk->stat_Dot3StatsLateCollisions);

	if (sblk->stat_EtherStatsCollisions)
		BNX_PRINTF(sc, "0x%08X : EtherStatsCollisions\n",
		    sblk->stat_EtherStatsCollisions);

	if (sblk->stat_EtherStatsFragments) 
		BNX_PRINTF(sc, "0x%08X : EtherStatsFragments\n",
		    sblk->stat_EtherStatsFragments);

	if (sblk->stat_EtherStatsJabbers)
		BNX_PRINTF(sc, "0x%08X : EtherStatsJabbers\n",
		    sblk->stat_EtherStatsJabbers);

	if (sblk->stat_EtherStatsUndersizePkts)
		BNX_PRINTF(sc, "0x%08X : EtherStatsUndersizePkts\n",
		    sblk->stat_EtherStatsUndersizePkts);

	if (sblk->stat_EtherStatsOverrsizePkts)
		BNX_PRINTF(sc, "0x%08X : EtherStatsOverrsizePkts\n",
		    sblk->stat_EtherStatsOverrsizePkts);

	if (sblk->stat_EtherStatsPktsRx64Octets)
		BNX_PRINTF(sc, "0x%08X : EtherStatsPktsRx64Octets\n",
		    sblk->stat_EtherStatsPktsRx64Octets);

	if (sblk->stat_EtherStatsPktsRx65Octetsto127Octets)
		BNX_PRINTF(sc, "0x%08X : EtherStatsPktsRx65Octetsto127Octets\n",
		    sblk->stat_EtherStatsPktsRx65Octetsto127Octets);

	if (sblk->stat_EtherStatsPktsRx128Octetsto255Octets)
		BNX_PRINTF(sc, "0x%08X : "
		    "EtherStatsPktsRx128Octetsto255Octets\n",
		    sblk->stat_EtherStatsPktsRx128Octetsto255Octets);

	if (sblk->stat_EtherStatsPktsRx256Octetsto511Octets)
		BNX_PRINTF(sc, "0x%08X : "
		    "EtherStatsPktsRx256Octetsto511Octets\n",
		    sblk->stat_EtherStatsPktsRx256Octetsto511Octets);

	if (sblk->stat_EtherStatsPktsRx512Octetsto1023Octets)
		BNX_PRINTF(sc, "0x%08X : "
		    "EtherStatsPktsRx512Octetsto1023Octets\n",
		    sblk->stat_EtherStatsPktsRx512Octetsto1023Octets);

	if (sblk->stat_EtherStatsPktsRx1024Octetsto1522Octets)
		BNX_PRINTF(sc, "0x%08X : "
		    "EtherStatsPktsRx1024Octetsto1522Octets\n",
		sblk->stat_EtherStatsPktsRx1024Octetsto1522Octets);

	if (sblk->stat_EtherStatsPktsRx1523Octetsto9022Octets)
		BNX_PRINTF(sc, "0x%08X : "
		    "EtherStatsPktsRx1523Octetsto9022Octets\n",
		    sblk->stat_EtherStatsPktsRx1523Octetsto9022Octets);

	if (sblk->stat_EtherStatsPktsTx64Octets)
		BNX_PRINTF(sc, "0x%08X : EtherStatsPktsTx64Octets\n",
		    sblk->stat_EtherStatsPktsTx64Octets);

	if (sblk->stat_EtherStatsPktsTx65Octetsto127Octets)
		BNX_PRINTF(sc, "0x%08X : EtherStatsPktsTx65Octetsto127Octets\n",
		    sblk->stat_EtherStatsPktsTx65Octetsto127Octets);

	if (sblk->stat_EtherStatsPktsTx128Octetsto255Octets)
		BNX_PRINTF(sc, "0x%08X : "
		    "EtherStatsPktsTx128Octetsto255Octets\n",
		    sblk->stat_EtherStatsPktsTx128Octetsto255Octets);

	if (sblk->stat_EtherStatsPktsTx256Octetsto511Octets)
		BNX_PRINTF(sc, "0x%08X : "
		    "EtherStatsPktsTx256Octetsto511Octets\n",
		    sblk->stat_EtherStatsPktsTx256Octetsto511Octets);

	if (sblk->stat_EtherStatsPktsTx512Octetsto1023Octets)
		BNX_PRINTF(sc, "0x%08X : "
		    "EtherStatsPktsTx512Octetsto1023Octets\n",
		    sblk->stat_EtherStatsPktsTx512Octetsto1023Octets);

	if (sblk->stat_EtherStatsPktsTx1024Octetsto1522Octets)
		BNX_PRINTF(sc, "0x%08X : "
		    "EtherStatsPktsTx1024Octetsto1522Octets\n",
		    sblk->stat_EtherStatsPktsTx1024Octetsto1522Octets);

	if (sblk->stat_EtherStatsPktsTx1523Octetsto9022Octets)
		BNX_PRINTF(sc, "0x%08X : "
		    "EtherStatsPktsTx1523Octetsto9022Octets\n",
		    sblk->stat_EtherStatsPktsTx1523Octetsto9022Octets);

	if (sblk->stat_XonPauseFramesReceived)
		BNX_PRINTF(sc, "0x%08X : XonPauseFramesReceived\n",
		    sblk->stat_XonPauseFramesReceived);

	if (sblk->stat_XoffPauseFramesReceived)
		BNX_PRINTF(sc, "0x%08X : XoffPauseFramesReceived\n",
		    sblk->stat_XoffPauseFramesReceived);

	if (sblk->stat_OutXonSent)
		BNX_PRINTF(sc, "0x%08X : OutXonSent\n",
		    sblk->stat_OutXonSent);

	if (sblk->stat_OutXoffSent)
		BNX_PRINTF(sc, "0x%08X : OutXoffSent\n",
		    sblk->stat_OutXoffSent);

	if (sblk->stat_FlowControlDone)
		BNX_PRINTF(sc, "0x%08X : FlowControlDone\n",
		    sblk->stat_FlowControlDone);

	if (sblk->stat_MacControlFramesReceived)
		BNX_PRINTF(sc, "0x%08X : MacControlFramesReceived\n",
		    sblk->stat_MacControlFramesReceived);

	if (sblk->stat_XoffStateEntered)
		BNX_PRINTF(sc, "0x%08X : XoffStateEntered\n",
		    sblk->stat_XoffStateEntered);

	if (sblk->stat_IfInFramesL2FilterDiscards)
		BNX_PRINTF(sc, "0x%08X : IfInFramesL2FilterDiscards\n",
		    sblk->stat_IfInFramesL2FilterDiscards);

	if (sblk->stat_IfInRuleCheckerDiscards)
		BNX_PRINTF(sc, "0x%08X : IfInRuleCheckerDiscards\n",
		    sblk->stat_IfInRuleCheckerDiscards);

	if (sblk->stat_IfInFTQDiscards)
		BNX_PRINTF(sc, "0x%08X : IfInFTQDiscards\n",
		    sblk->stat_IfInFTQDiscards);

	if (sblk->stat_IfInMBUFDiscards)
		BNX_PRINTF(sc, "0x%08X : IfInMBUFDiscards\n",
		    sblk->stat_IfInMBUFDiscards);

	if (sblk->stat_IfInRuleCheckerP4Hit)
		BNX_PRINTF(sc, "0x%08X : IfInRuleCheckerP4Hit\n",
		    sblk->stat_IfInRuleCheckerP4Hit);

	if (sblk->stat_CatchupInRuleCheckerDiscards)
		BNX_PRINTF(sc, "0x%08X : CatchupInRuleCheckerDiscards\n",
		    sblk->stat_CatchupInRuleCheckerDiscards);

	if (sblk->stat_CatchupInFTQDiscards)
		BNX_PRINTF(sc, "0x%08X : CatchupInFTQDiscards\n",
		    sblk->stat_CatchupInFTQDiscards);

	if (sblk->stat_CatchupInMBUFDiscards)
		BNX_PRINTF(sc, "0x%08X : CatchupInMBUFDiscards\n",
		    sblk->stat_CatchupInMBUFDiscards);

	if (sblk->stat_CatchupInRuleCheckerP4Hit)
		BNX_PRINTF(sc, "0x%08X : CatchupInRuleCheckerP4Hit\n",
		    sblk->stat_CatchupInRuleCheckerP4Hit);

	BNX_PRINTF(sc,
	    "-----------------------------"
	    "--------------"
	    "-----------------------------\n");
}

void
bnx_dump_driver_state(struct bnx_softc *sc)
{
	BNX_PRINTF(sc,
	    "-----------------------------"
	    " Driver State "
	    "-----------------------------\n");

	BNX_PRINTF(sc, "%p - (sc) driver softc structure virtual "
	    "address\n", sc);

	BNX_PRINTF(sc, "%p - (sc->status_block) status block virtual address\n",
	    sc->status_block);

	BNX_PRINTF(sc, "%p - (sc->stats_block) statistics block virtual "
	    "address\n", sc->stats_block);

	BNX_PRINTF(sc, "%p - (sc->tx_bd_chain) tx_bd chain virtual "
	    "adddress\n", sc->tx_bd_chain);

	BNX_PRINTF(sc, "%p - (sc->rx_bd_chain) rx_bd chain virtual address\n",
	    sc->rx_bd_chain);

	BNX_PRINTF(sc, "%p - (sc->tx_mbuf_ptr) tx mbuf chain virtual address\n",
	    sc->tx_mbuf_ptr);

	BNX_PRINTF(sc, "%p - (sc->rx_mbuf_ptr) rx mbuf chain virtual address\n",
	    sc->rx_mbuf_ptr);

	BNX_PRINTF(sc,
	    "         0x%08X - (sc->interrupts_generated) h/w intrs\n",
	    sc->interrupts_generated);
	
	BNX_PRINTF(sc,
	    "         0x%08X - (sc->rx_interrupts) rx interrupts handled\n",
	    sc->rx_interrupts);

	BNX_PRINTF(sc,
	    "         0x%08X - (sc->tx_interrupts) tx interrupts handled\n",
	    sc->tx_interrupts);

	BNX_PRINTF(sc,
	    "         0x%08X - (sc->last_status_idx) status block index\n",
	    sc->last_status_idx);

	BNX_PRINTF(sc, "         0x%08X - (sc->tx_prod) tx producer index\n",
	    sc->tx_prod);

	BNX_PRINTF(sc, "         0x%08X - (sc->tx_cons) tx consumer index\n",
	    sc->tx_cons);

	BNX_PRINTF(sc,
	    "         0x%08X - (sc->tx_prod_bseq) tx producer bseq index\n",
	    sc->tx_prod_bseq);

	BNX_PRINTF(sc,
	    "         0x%08X - (sc->tx_mbuf_alloc) tx mbufs allocated\n",
	    sc->tx_mbuf_alloc);

	BNX_PRINTF(sc,
	    "         0x%08X - (sc->used_tx_bd) used tx_bd's\n",
	    sc->used_tx_bd);

	BNX_PRINTF(sc,
	    "         0x%08X/%08X - (sc->tx_hi_watermark) tx hi watermark\n",
	    sc->tx_hi_watermark, sc->max_tx_bd);

	BNX_PRINTF(sc, "         0x%08X - (sc->rx_prod) rx producer index\n",
	    sc->rx_prod);

	BNX_PRINTF(sc, "         0x%08X - (sc->rx_cons) rx consumer index\n",
	    sc->rx_cons);

	BNX_PRINTF(sc,
	    "         0x%08X - (sc->rx_prod_bseq) rx producer bseq index\n",
	    sc->rx_prod_bseq);

	BNX_PRINTF(sc,
	    "         0x%08X - (sc->rx_mbuf_alloc) rx mbufs allocated\n",
	    sc->rx_mbuf_alloc);

	BNX_PRINTF(sc,
	    "0x%08X/%08X - (sc->rx_low_watermark) rx low watermark\n",
	    sc->rx_low_watermark, sc->max_rx_bd);

	BNX_PRINTF(sc,
	    "         0x%08X - (sc->mbuf_alloc_failed) "
	    "mbuf alloc failures\n",
	    sc->mbuf_alloc_failed);

	BNX_PRINTF(sc,
	    "         0x%0X - (sc->mbuf_sim_allocated_failed) "
	    "simulated mbuf alloc failures\n",
	    sc->mbuf_sim_alloc_failed);

	BNX_PRINTF(sc, "-------------------------------------------"
	    "-----------------------------\n");
}

void
bnx_dump_hw_state(struct bnx_softc *sc)
{
	u_int32_t		val1;
	int			i;

	BNX_PRINTF(sc,
	    "----------------------------"
	    " Hardware State "
	    "----------------------------\n");

	BNX_PRINTF(sc, "0x%08X : bootcode version\n", sc->bnx_fw_ver);

	val1 = REG_RD(sc, BNX_MISC_ENABLE_STATUS_BITS);
	BNX_PRINTF(sc, "0x%08X : (0x%04X) misc_enable_status_bits\n",
	    val1, BNX_MISC_ENABLE_STATUS_BITS);

	val1 = REG_RD(sc, BNX_DMA_STATUS);
	BNX_PRINTF(sc, "0x%08X : (0x%04X) dma_status\n", val1, BNX_DMA_STATUS);

	val1 = REG_RD(sc, BNX_CTX_STATUS);
	BNX_PRINTF(sc, "0x%08X : (0x%04X) ctx_status\n", val1, BNX_CTX_STATUS);

	val1 = REG_RD(sc, BNX_EMAC_STATUS);
	BNX_PRINTF(sc, "0x%08X : (0x%04X) emac_status\n", val1,
	    BNX_EMAC_STATUS);

	val1 = REG_RD(sc, BNX_RPM_STATUS);
	BNX_PRINTF(sc, "0x%08X : (0x%04X) rpm_status\n", val1, BNX_RPM_STATUS);

	val1 = REG_RD(sc, BNX_TBDR_STATUS);
	BNX_PRINTF(sc, "0x%08X : (0x%04X) tbdr_status\n", val1,
	    BNX_TBDR_STATUS);

	val1 = REG_RD(sc, BNX_TDMA_STATUS);
	BNX_PRINTF(sc, "0x%08X : (0x%04X) tdma_status\n", val1,
	    BNX_TDMA_STATUS);

	val1 = REG_RD(sc, BNX_HC_STATUS);
	BNX_PRINTF(sc, "0x%08X : (0x%04X) hc_status\n", val1, BNX_HC_STATUS);

	BNX_PRINTF(sc, 
	    "----------------------------"
	    "----------------"
	    "----------------------------\n");

	BNX_PRINTF(sc, 
	    "----------------------------"
	    " Register  Dump "
	    "----------------------------\n");

	for (i = 0x400; i < 0x8000; i += 0x10)
		BNX_PRINTF(sc, "0x%04X: 0x%08X 0x%08X 0x%08X 0x%08X\n",
		    i, REG_RD(sc, i), REG_RD(sc, i + 0x4),
		    REG_RD(sc, i + 0x8), REG_RD(sc, i + 0xC));

	BNX_PRINTF(sc, 
	    "----------------------------"
	    "----------------"
	    "----------------------------\n");
}

void
bnx_breakpoint(struct bnx_softc *sc)
{
	/* Unreachable code to shut the compiler up about unused functions. */
	if (0) {
   		bnx_dump_txbd(sc, 0, NULL);
		bnx_dump_rxbd(sc, 0, NULL);
		bnx_dump_tx_mbuf_chain(sc, 0, USABLE_TX_BD);
		bnx_dump_rx_mbuf_chain(sc, 0, sc->max_rx_bd);
		bnx_dump_l2fhdr(sc, 0, NULL);
		bnx_dump_tx_chain(sc, 0, USABLE_TX_BD);
		bnx_dump_rx_chain(sc, 0, sc->max_rx_bd);
		bnx_dump_status_block(sc);
		bnx_dump_stats_block(sc);
		bnx_dump_driver_state(sc);
		bnx_dump_hw_state(sc);
	}

	bnx_dump_driver_state(sc);
	/* Print the important status block fields. */
	bnx_dump_status_block(sc);

#if 0
	/* Call the debugger. */
	breakpoint();
#endif

	return;
}
#endif
@


1.123
log
@move counting if_opackets next to counting if_obytes in if_enqueue.

this means packets are consistently counted in one place, unlike the
many and various ways that drivers thought they should do it.

ok mpi@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.122 2016/05/05 23:01:28 jmatthew Exp $	*/
d369 1
a369 1
void	bnx_start(struct ifnet *);
d876 1
a876 1
	ifp->if_start = bnx_start;
d4868 1
a4868 1
bnx_start(struct ifnet *ifp)
d4870 1
d4877 1
a4877 1
		ifq_purge(&ifp->if_snd);
d4899 1
a4899 1
			ifq_set_oactive(&ifp->if_snd);
d4903 1
a4903 1
		IFQ_DEQUEUE(&ifp->if_snd, m_head);
d5153 2
a5154 5
		    !IFQ_IS_EMPTY(&ifp->if_snd)) {
			KERNEL_LOCK();
			bnx_start(ifp);
			KERNEL_UNLOCK();
		}
d5487 2
a5488 2
		if (!IFQ_IS_EMPTY(&ifp->if_snd))
			bnx_start(ifp);
@


1.122
log
@r1.10 of if_bnx.c effectively removed the limit on the number of segments in
the tx dma maps, apparently to allow heavily fragmented packets to be sent.

The tx ring accounting in bnx_start assumed that the longest fragment chain
we'd see was BNX_MAX_SEGMENTS, so sending a heavily fragmented packet when the
ring was already full could cause it to overflow.

In the 10 years since r1.10, we've started defragmenting packets if they
won't fit in the dma map, so we can limit the maps to BNX_MAX_SEGMENTS again.
While we're here, ensure there's always at least one slot on the tx ring free,
for consistency between drivers.

Fixes packet corruption seen by otto@@
ok mpi@@ dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.121 2016/04/13 10:34:32 mpi Exp $	*/
a4565 2

			ifp->if_opackets++;
@


1.121
log
@G/C IFQ_SET_READY().
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.120 2015/12/11 16:07:01 mpi Exp $	*/
d2420 1
a2420 1
		    MCLBYTES * BNX_MAX_SEGMENTS, USABLE_TX_BD,
d4895 2
a4896 1
		if (sc->used_tx_bd + used + BNX_MAX_SEGMENTS >= sc->max_tx_bd) {
@


1.120
log
@Replace mountroothook_establish(9) by config_mountroot(9) a narrower API
similar to config_defer(9).

ok mikeb@@, deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.119 2015/12/10 12:24:27 dlg Exp $	*/
a878 1
	IFQ_SET_READY(&ifp->if_snd);
@


1.120.2.1
log
@r1.10 of if_bnx.c effectively removed the limit on the number of segments in
the tx dma maps, apparently to allow heavily fragmented packets to be sent.

The tx ring accounting in bnx_start assumed that the longest fragment chain
we'd see was BNX_MAX_SEGMENTS, so sending a heavily fragmented packet when the
ring was already full could cause it to overflow.

In the 10 years since r1.10, we've started defragmenting packets if they
won't fit in the dma map, so we can limit the maps to BNX_MAX_SEGMENTS again.
While we're here, ensure there's always at least one slot on the tx ring free,
for consistency between drivers.

Fixes packet corruption seen by otto@@
ok mpi@@ dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.120 2015/12/11 16:07:01 mpi Exp $	*/
d2421 1
a2421 1
		    MCLBYTES * BNX_MAX_SEGMENTS, BNX_MAX_SEGMENTS,
d4896 1
a4896 2
		if (sc->used_tx_bd + used + BNX_MAX_SEGMENTS + 1 >=
		    sc->max_tx_bd) {
@


1.119
log
@mark bnx_start as mpsafe.

tweak it to use ifq_restart so ifq_clr_oactive is serialised with start.

ok jmatthew@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.118 2015/12/05 16:23:37 jmatthew Exp $	*/
d277 1
a277 1
void	bnx_attachhook(void *);
d756 1
a756 1
	mountroothook_establish(bnx_attachhook, sc);
d765 1
a765 1
bnx_attachhook(void *xsc)
d767 1
a767 1
	struct bnx_softc *sc = xsc;
@


1.118
log
@Make the bnx interrupt handler mpsafe, and perform rx and tx completion
outside the kernel lock.

Remove tx descriptor lists (essentially backing out if_bnx.c r1.77),
add an interrupt barrier in bnx_stop, check the rx ring state before receiving
packets, adjust the tx counter with atomic operations, and rework bnx_start
to check for ring space before dequeueing and drop the packet if bnx_encap
fails.

tested on BCM5708 by me and on BCM5709 by Hrvoje Popovski
ok dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.117 2015/11/25 03:09:59 dlg Exp $	*/
d874 1
d4577 2
d4583 2
a4584 10
	/* Clear the tx hardware queue full flag. */
	if (used < sc->max_tx_bd) {
		DBRUNIF(ifq_is_oactive(&ifp->if_snd),
		    printf("%s: Open TX chain! %d/%d (used/total)\n",
			sc->bnx_dev.dv_xname, used,
			sc->max_tx_bd));
		ifq_clr_oactive(&ifp->if_snd);
	}

	sc->tx_cons = sw_tx_cons;
d4878 2
a4879 4
	/* If there's no link or the transmit queue is empty then just exit. */
	if (!sc->bnx_link || IFQ_IS_EMPTY(&ifp->if_snd)) {
		DBPRINT(sc, BNX_INFO_SEND,
		    "%s(): No link or transmit queue empty.\n", __FUNCTION__);
@


1.117
log
@replace IFF_OACTIVE manipulation with mpsafe operations.

there are two things shared between the network stack and drivers
in the send path: the send queue and the IFF_OACTIVE flag. the send
queue is now protected by a mutex. this diff makes the oactive
functionality mpsafe too.

IFF_OACTIVE is part of if_flags. there are two problems with that.
firstly, if_flags is a short and we dont have any MI atomic operations
to manipulate a short. secondly, while we could make the IFF_OACTIVE
operates mpsafe, all changes to other flags would have to be made
safe at the same time, otherwise a read-modify-write cycle on their
updates could clobber the oactive change.

instead, this moves the oactive mark into struct ifqueue and provides
an API for changing it. there's ifq_set_oactive, ifq_clr_oactive,
and ifq_is_oactive. these are modelled on ifsq_set_oactive,
ifsq_clr_oactive, and ifsq_is_oactive in dragonflybsd.

this diff includes changes to all the drivers manipulating IFF_OACTIVE
to now use the ifsq_{set,clr_is}_oactive API too.

ok kettenis@@ mpi@@ jmatthew@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.116 2015/11/20 03:35:23 dlg Exp $	*/
d368 1
a368 1
int	bnx_tx_encap(struct bnx_softc *, struct mbuf *);
a390 4
struct rwlock bnx_tx_pool_lk = RWLOCK_INITIALIZER("bnxplinit");
struct pool *bnx_tx_pool = NULL;
void	bnx_alloc_pkts(void *);

d744 2
a745 2
	sc->bnx_intrhand = pci_intr_establish(pc, sc->bnx_ih, IPL_NET,
	    bnx_intr, sc, sc->bnx_dev.dv_xname);
d2364 5
a2368 2
	/* Destroy the TX dmamaps. */
	/* This isn't necessary since we dont allocate them up front */
d2416 13
a2603 9
	 * Create lists to hold TX mbufs.
	 */
	TAILQ_INIT(&sc->tx_free_pkts);
	TAILQ_INIT(&sc->tx_used_pkts);
	sc->tx_pkt_count = 0;
	mtx_init(&sc->tx_pkt_mtx, IPL_NET);
	task_set(&sc->tx_alloc_task, bnx_alloc_pkts, sc);

	/*
d3272 3
a3735 41
void
bnx_alloc_pkts(void *xsc)
{
	struct bnx_softc *sc = xsc;
	struct ifnet *ifp = &sc->arpcom.ac_if;
	struct bnx_pkt *pkt;
	int i;
	int s;

	for (i = 0; i < 4; i++) { /* magic! */
		pkt = pool_get(bnx_tx_pool, PR_WAITOK);
		if (pkt == NULL)
			break;

		if (bus_dmamap_create(sc->bnx_dmatag,
		    MCLBYTES * BNX_MAX_SEGMENTS, USABLE_TX_BD,
		    MCLBYTES, 0, BUS_DMA_WAITOK | BUS_DMA_ALLOCNOW,
		    &pkt->pkt_dmamap) != 0)
			goto put;

		if (!ISSET(ifp->if_flags, IFF_UP))
			goto stopping;

		mtx_enter(&sc->tx_pkt_mtx);
		TAILQ_INSERT_TAIL(&sc->tx_free_pkts, pkt, pkt_entry);
		sc->tx_pkt_count++;
		mtx_leave(&sc->tx_pkt_mtx);
	}

	s = splnet();
	if (!IFQ_IS_EMPTY(&ifp->if_snd))
		bnx_start(ifp);
	splx(s);

	return;

stopping:
	bus_dmamap_destroy(sc->bnx_dmatag, pkt->pkt_dmamap);
put:
	pool_put(bnx_tx_pool, pkt);
}
a3792 3
	/* Force an allocation of some dmamaps for tx up front */
	bnx_alloc_pkts(sc);

a3848 1
	struct bnx_pkt		*pkt;
d3854 14
a3867 13
	mtx_enter(&sc->tx_pkt_mtx);
	while ((pkt = TAILQ_FIRST(&sc->tx_used_pkts)) != NULL) {
		TAILQ_REMOVE(&sc->tx_used_pkts, pkt, pkt_entry);
		mtx_leave(&sc->tx_pkt_mtx);

		bus_dmamap_sync(sc->bnx_dmatag, pkt->pkt_dmamap, 0,
		    pkt->pkt_dmamap->dm_mapsize, BUS_DMASYNC_POSTWRITE);
		bus_dmamap_unload(sc->bnx_dmatag, pkt->pkt_dmamap);

		m_freem(pkt->pkt_mbuf);

		mtx_enter(&sc->tx_pkt_mtx);
		TAILQ_INSERT_TAIL(&sc->tx_free_pkts, pkt, pkt_entry);
a3869 13
	/* Destroy all the dmamaps we allocated for TX */
	while ((pkt = TAILQ_FIRST(&sc->tx_free_pkts)) != NULL) {
		TAILQ_REMOVE(&sc->tx_free_pkts, pkt, pkt_entry);
		sc->tx_pkt_count--;
		mtx_leave(&sc->tx_pkt_mtx);

		bus_dmamap_destroy(sc->bnx_dmatag, pkt->pkt_dmamap);
		pool_put(bnx_tx_pool, pkt);

		mtx_enter(&sc->tx_pkt_mtx);
	}
	mtx_leave(&sc->tx_pkt_mtx);

d4236 3
a4497 1
	struct bnx_pkt		*pkt;
d4500 1
d4518 1
d4545 14
a4558 11
		mtx_enter(&sc->tx_pkt_mtx);
		pkt = TAILQ_FIRST(&sc->tx_used_pkts);
		if (pkt != NULL && pkt->pkt_end_desc == sw_tx_chain_cons) {
			TAILQ_REMOVE(&sc->tx_used_pkts, pkt, pkt_entry);
			mtx_leave(&sc->tx_pkt_mtx);
			/*
			 * Free the associated mbuf. Remember
			 * that only the last tx_bd of a packet
			 * has an mbuf pointer and DMA map.
			 */
			map = pkt->pkt_dmamap;
d4563 3
a4565 1
			m_freem(pkt->pkt_mbuf);
a4567 3

			mtx_enter(&sc->tx_pkt_mtx);
			TAILQ_INSERT_TAIL(&sc->tx_free_pkts, pkt, pkt_entry);
d4569 2
a4570 3
		mtx_leave(&sc->tx_pkt_mtx);

		sc->used_tx_bd--;
d4572 1
d4574 1
a4574 13
		/* Refresh hw_cons to see if there's new work. */
		hw_tx_cons = sc->hw_tx_cons =
		    sblk->status_tx_quick_consumer_index0;
		if ((hw_tx_cons & USABLE_TX_BD_PER_PAGE) ==
		    USABLE_TX_BD_PER_PAGE)
			hw_tx_cons++;

		/* Prevent speculative reads from getting ahead of
		 * the status block.
		 */
		bus_space_barrier(sc->bnx_btag, sc->bnx_bhandle, 0, 0, 
		    BUS_SPACE_BARRIER_READ);
	}
d4577 2
a4578 1
	ifp->if_timer = 0;
d4581 1
a4581 1
	if (sc->used_tx_bd < sc->max_tx_bd) {
d4583 3
a4585 3
			printf("%s: Open TX chain! %d/%d (used/total)\n",
			       sc->bnx_dev.dv_xname, sc->used_tx_bd,
			       sc->max_tx_bd));
a4637 1
	int			txpl = 1;
a4641 15
	if (rw_enter(&bnx_tx_pool_lk, RW_WRITE | RW_INTR) != 0)
		return;
	if (bnx_tx_pool == NULL) {
		bnx_tx_pool = malloc(sizeof(*bnx_tx_pool), M_DEVBUF, M_WAITOK);
		if (bnx_tx_pool != NULL) {
			pool_init(bnx_tx_pool, sizeof(struct bnx_pkt),
			    0, 0, 0, "bnxpkts", NULL);
		} else
			txpl = 0;
	}
	rw_exit(&bnx_tx_pool_lk);

	if (!txpl)
		return;

d4750 1
a4750 1
bnx_tx_encap(struct bnx_softc *sc, struct mbuf *m)
a4751 1
	struct bnx_pkt		*pkt;
d4755 1
a4755 1
	u_int16_t		chain_prod, prod;
d4760 1
a4760 15
	int			i, error, add;

	mtx_enter(&sc->tx_pkt_mtx);
	pkt = TAILQ_FIRST(&sc->tx_free_pkts);
	if (pkt == NULL) {
		add = (sc->tx_pkt_count <= TOTAL_TX_BD);
		mtx_leave(&sc->tx_pkt_mtx);

		if (add)
			task_add(systq, &sc->tx_alloc_task);

		return (ENOMEM);
	}
	TAILQ_REMOVE(&sc->tx_free_pkts, pkt, pkt_entry);
	mtx_leave(&sc->tx_pkt_mtx);
d4781 2
a4782 2
	chain_prod = TX_CHAIN_IDX(prod);
	map = pkt->pkt_dmamap;
d4800 1
a4800 1
		goto maperr;
a4802 4
	/* Make sure there's room in the chain */
	if (map->dm_nsegs > (sc->max_tx_bd - sc->used_tx_bd))
		goto nospace;

d4848 3
a4850 6
	pkt->pkt_mbuf = m;
	pkt->pkt_end_desc = chain_prod;
	
	mtx_enter(&sc->tx_pkt_mtx);
	TAILQ_INSERT_TAIL(&sc->tx_used_pkts, pkt, pkt_entry);
	mtx_leave(&sc->tx_pkt_mtx);
d4852 1
a4852 1
	sc->used_tx_bd += map->dm_nsegs;
a4853 4
	/* Update some debug statistics counters */
	DBRUNIF((sc->used_tx_bd > sc->tx_hi_watermark),
	    sc->tx_hi_watermark = sc->used_tx_bd);
	DBRUNIF(sc->used_tx_bd == sc->max_tx_bd, sc->tx_full_count++);
a4866 9

nospace:
	bus_dmamap_unload(sc->bnx_dmatag, map);
maperr:
	mtx_enter(&sc->tx_pkt_mtx);
	TAILQ_INSERT_TAIL(&sc->tx_free_pkts, pkt, pkt_entry);
	mtx_leave(&sc->tx_pkt_mtx);

	return (ENOMEM);
d4880 1
a4880 1
	int			count = 0;
d4901 3
a4903 14
	while (sc->used_tx_bd < sc->max_tx_bd) {
		/* Check for any frames to send. */
		m_head = ifq_deq_begin(&ifp->if_snd);
		if (m_head == NULL)
			break;

		/*
		 * Pack the data into the transmit ring. If we
		 * don't have room, set the OACTIVE flag to wait
		 * for the NIC to drain the chain.
		 */
		if (bnx_tx_encap(sc, m_head)) {
			ifq_deq_rollback(&ifp->if_snd, m_head);
			ifq_set_oactive(&ifp->if_snd);
d4906 2
a4907 1
			    sc->used_tx_bd);
d4911 8
a4918 2
		ifq_deq_commit(&ifp->if_snd, m_head);
		count++;
a4920 1
		/* Send a copy of the frame to any BPF listeners. */
d4926 1
a4926 1
	if (count == 0) {
d4934 7
a4941 1

d5118 2
a5119 1
		    STATUS_ATTN_BITS_LINK_STATE))
d5121 2
d5128 1
d5139 1
d5160 3
a5162 1
		if (ifp->if_flags & IFF_RUNNING && !IFQ_IS_EMPTY(&ifp->if_snd))
d5164 2
@


1.116
log
@shuffle struct ifqueue so in flight mbufs are protected by a mutex.

the code is refactored so the IFQ macros call newly implemented ifq
functions. the ifq code is split so each discipline (priq and hfsc
in our case) is an opaque set of operations that the common ifq
code can call. the common code does the locking, accounting (ifq_len
manipulation), and freeing of the mbuf if the disciplines enqueue
function rejects it. theyre kind of like bufqs in the block layer
with their fifo and nscan disciplines.

the new api also supports atomic switching of disciplines at runtime.
the hfsc setup in pf_ioctl.c has been tweaked to build a complete
hfsc_if structure which it attaches to the send queue in a single
operation, rather than attaching to the interface up front and
building up a list of queues.

the send queue is now mutexed, which raises the expectation that
packets can be enqueued or purged on one cpu while another cpu is
dequeueing them in a driver for transmission. a lot of drivers use
IFQ_POLL to peek at an mbuf and attempt to fit it on the ring before
committing to it with a later IFQ_DEQUEUE operation. if the mbuf
gets freed in between the POLL and DEQUEUE operations, fireworks
will ensue.

to avoid this, the ifq api introduces ifq_deq_begin, ifq_deq_rollback,
and ifq_deq_commit. ifq_deq_begin allows a driver to take the ifq
mutex and get a reference to the mbuf they wish to try and tx. if
there's space, they can ifq_deq_commit it to remove the mbuf and
release the mutex. if there's no space, ifq_deq_rollback simply
releases the mutex. this api was developed to make updating the
drivers using IFQ_POLL easy, instead of having to do significant
semantic changes to avoid POLL that we cannot test on all the
hardware.

the common code has been tested pretty hard, and all the driver
modifications are straightforward except for de(4). if that breaks
it can be dealt with later.

ok mpi@@ jmatthew@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.115 2015/10/25 13:04:28 mpi Exp $	*/
d3259 2
a3260 1
	ifp->if_flags &= ~(IFF_RUNNING | IFF_OACTIVE);
d4638 5
a4642 5
		DBRUNIF((ifp->if_flags & IFF_OACTIVE),
		    printf("%s: Open TX chain! %d/%d (used/total)\n",
			sc->bnx_dev.dv_xname, sc->used_tx_bd,
			sc->max_tx_bd));
		ifp->if_flags &= ~IFF_OACTIVE;
d4772 1
a4772 1
	ifp->if_flags &= ~IFF_OACTIVE;
d5021 1
a5021 1
			ifp->if_flags |= IFF_OACTIVE;
@


1.115
log
@arp_ifinit() is no longer needed.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.114 2015/09/10 18:10:34 deraadt Exp $	*/
d5009 1
a5009 1
		IFQ_POLL(&ifp->if_snd, m_head);
d5019 1
d5027 1
a5027 1
		IFQ_DEQUEUE(&ifp->if_snd, m_head);
@


1.114
log
@sizes for free(); ok sthen
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.113 2015/09/04 21:43:10 kettenis Exp $	*/
a5070 1
	struct ifaddr		*ifa = (struct ifaddr *) data;
a5081 2
		if (ifa->ifa_addr->sa_family == AF_INET)
			arp_ifinit(&sc->arpcom, ifa);
@


1.113
log
@The bnx_tx_pool gets used from interrupt context, so drop the explicit
backend allocoter here without passing PR_WAITOK to pool_init(9).

ok mikeb@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.112 2015/07/24 01:19:18 dlg Exp $	*/
d447 1
a447 1
		free(p, M_DEVBUF, 0);
d580 1
a580 1
		free(p, M_DEVBUF, 0);
d606 1
a606 1
		free(p, M_DEVBUF, 0);
d625 1
a625 1
		free(p, M_DEVBUF, 0);
d2093 1
a2093 1
		free(buf, M_DEVBUF, 0);
@


1.112
log
@if we free the mbuf in the rx path, clear the pointer to it so we dont
try and queue it for the stack and cause a use after free.

found by maxime villard and brainy
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.111 2015/06/24 09:40:54 mpi Exp $	*/
d4704 1
a4704 1
			    0, 0, 0, "bnxpkts", &pool_allocator_nointr);
@


1.111
log
@Increment if_ipackets in if_input().

Note that pseudo-drivers not using if_input() are not affected by this
conversion.

ok mikeb@@, kettenis@@, claudio@@, dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.110 2015/03/10 15:28:48 mpi Exp $	*/
d4477 1
@


1.110
log
@Convert to if_input().

Tested and ok sthen@@, ok dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.109 2015/01/27 03:17:36 dlg Exp $	*/
a4479 3

			/* Pass the mbuf off to the upper layers. */
			ifp->if_ipackets++;
@


1.109
log
@remove the second void * argument on tasks.

when workqs were introduced, we provided a second argument so you
could pass a thing and some context to work on it in. there were
very few things that took advantage of the second argument, so when
i introduced pools i suggested removing it. since tasks were meant
to replace workqs, it was requested that we keep the second argument
to make porting from workqs to tasks easier.

now that workqs are gone, i had a look at the use of the second
argument again and found only one good use of it (vdsp(4) on sparc64
if you're interested) and a tiny handful of questionable uses. the
vast majority of tasks only used a single argument. i have since
modified all tasks that used two args to only use one, so now we
can remove the second argument.

so this is a mechanical change. all tasks only passed NULL as their
second argument, so we can just remove it.

ok krw@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.108 2014/12/22 02:28:51 tedu Exp $	*/
d4277 1
a4415 3
			/* Send the packet to the appropriate interface. */
			m->m_pkthdr.rcvif = ifp;

a4493 10
#if NBPFILTER > 0
			/*
			 * Handle BPF listeners. Let the BPF
			 * user see the packet.
			 */
			if (ifp->if_bpf)
				bpf_mtap_ether(ifp->if_bpf, m,
				    BPF_DIRECTION_IN);
#endif

d4496 1
a4496 1
			ether_input_mbuf(ifp, m);
d4528 2
@


1.108
log
@unifdef INET
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.107 2014/07/18 07:11:04 dlg Exp $	*/
d393 1
a393 1
void	bnx_alloc_pkts(void *, void *);
d2598 1
a2598 1
	task_set(&sc->tx_alloc_task, bnx_alloc_pkts, sc, NULL);
d3730 1
a3730 1
bnx_alloc_pkts(void *xsc, void *arg)
d3828 1
a3828 1
	bnx_alloc_pkts(sc, NULL);
@


1.107
log
@implement EFBIG handling for heavily fragmented packets on the tx path.

ok claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.106 2014/07/12 18:48:51 tedu Exp $	*/
a5094 1
#ifdef INET
a5096 1
#endif /* INET */
@


1.106
log
@add a size argument to free. will be used soon, but for now default to 0.
after discussions with beck deraadt kettenis.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.105 2014/07/09 00:13:05 dlg Exp $	*/
d4885 12
a4896 3
	if (error != 0) {
		printf("%s: Error mapping mbuf into TX chain!\n",
		    sc->bnx_dev.dv_xname);
@


1.105
log
@dont try to be smart about avoiding the use of too many descriptors
when filling the rx ring. trust the hwm.

problem found by sthen@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.104 2014/07/08 05:35:18 dlg Exp $	*/
d447 1
a447 1
		free(p, M_DEVBUF);
d580 1
a580 1
		free(p, M_DEVBUF);
d606 1
a606 1
		free(p, M_DEVBUF);
d625 1
a625 1
		free(p, M_DEVBUF);
d2093 1
a2093 1
		free(buf, M_DEVBUF);
@


1.104
log
@cut things that relied on mclgeti for rx ring accounting/restriction over
to using if_rxr.

cut the reporting systat did over to the rxr ioctl.

tested as much as i can on alpha, amd64, and sparc64.
mpi@@ has run it on macppc.
ok mpi@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.103 2013/10/30 04:08:07 dlg Exp $	*/
d4018 1
a4018 1
	while (slots > BNX_MAX_SEGMENTS) {
d5124 5
@


1.103
log
@replace the workq bits to supply new tx pkt descriptors with a task.

tested locally on a dell poweredge 2950
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.102 2013/10/23 20:22:12 brad Exp $	*/
a882 1
	m_clsetwms(ifp, MCLBYTES, 2, USABLE_RX_BD);
d3666 1
a3666 1
	m = MCLGETI(NULL, M_DONTWAIT, &sc->arpcom.ac_if, MCLBYTES);
d3668 1
a3668 1
		return (ENOBUFS);
d3676 1
a3676 1
		return (ENOBUFS);
a3679 7
	/* Make sure there is room in the receive chain. */
	if (map->dm_nsegs > sc->free_rx_bd) {
		bus_dmamap_unload(sc->bnx_dmatag, map);
		m_freem(m);
		return (EFBIG);
	}

a3684 5
	/* Update some debug statistics counters */
	DBRUNIF((sc->free_rx_bd < sc->rx_low_watermark), 
	    sc->rx_low_watermark = sc->free_rx_bd);
	DBRUNIF((sc->free_rx_bd == sc->max_rx_bd), sc->rx_empty_count++);

a3721 1
	sc->free_rx_bd -= map->dm_nsegs;
d3726 1
a3726 1
	return (0);
d4001 1
d4004 1
a4004 1
	int rx_mbuf_alloc_before, free_rx_bd_before;
a4013 1
	free_rx_bd_before = sc->free_rx_bd;
d4017 2
a4018 1
	while (sc->free_rx_bd > 0) {
d4020 3
a4022 1
		if (bnx_get_buf(sc, &prod, &chain_prod, &prod_bseq)) {
d4026 2
d4031 1
a4031 7

#if 0
	DBRUNIF((sc->rx_mbuf_alloc - rx_mbuf_alloc_before),
		BNX_PRINTF(sc, "%s(): Installed %d mbufs in %d rx_bd entries.\n",
		__FUNCTION__, (sc->rx_mbuf_alloc - rx_mbuf_alloc_before), 
		(free_rx_bd_before - sc->free_rx_bd)));
#endif
a4064 1
	sc->free_rx_bd = USABLE_RX_BD;
d4088 2
a4151 2
	sc->free_rx_bd = sc->max_rx_bd;

a4309 5
	/* Update some debug statistics counters */
	DBRUNIF((sc->free_rx_bd < sc->rx_low_watermark),
	    sc->rx_low_watermark = sc->free_rx_bd);
	DBRUNIF((sc->free_rx_bd == USABLE_RX_BD), sc->rx_empty_count++);

d4331 1
a4331 1
		sc->free_rx_bd++;
a6244 3

	BNX_PRINTF(sc, "         0x%08X - (sc->free_rx_bd) free rx_bd's\n",
	    sc->free_rx_bd);
@


1.102
log
@Enable TX checksum offload.

ok naddy@@ sthen@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.101 2013/03/28 17:21:44 brad Exp $	*/
d2599 1
a3771 4
	mtx_enter(&sc->tx_pkt_mtx);
	CLR(sc->bnx_flags, BNX_ALLOC_PKTS_FLAG);
	mtx_leave(&sc->tx_pkt_mtx);

d4865 1
a4865 1
	int			i, error;
d4870 5
a4874 4
		if (sc->tx_pkt_count <= TOTAL_TX_BD &&
		    !ISSET(sc->bnx_flags, BNX_ALLOC_PKTS_FLAG) &&
		    workq_add_task(NULL, 0, bnx_alloc_pkts, sc, NULL) == 0)
			SET(sc->bnx_flags, BNX_ALLOC_PKTS_FLAG);
a4875 1
		mtx_leave(&sc->tx_pkt_mtx);
@


1.101
log
@Let mii_attach() know where the PHY is located instead of scanning
for it since we know where it will be anyway and remove the code
from the MII bus read/write functions to force reading/writing
from the predetermined location. Copied from bge(4) and this is
what the upstream FreeBSD bce(4) driver has done once FreBSD
gained a mii_attach().

ok dlg@@ sthen@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.100 2013/01/13 05:45:10 brad Exp $	*/
d887 2
a888 5
	ifp->if_capabilities = IFCAP_VLAN_MTU;

#ifdef BNX_CSUM
	ifp->if_capabilities |= IFCAP_CSUM_TCPv4 | IFCAP_CSUM_UDPv4;
#endif	
@


1.100
log
@Enable flow control support with 5708S/5709S adapters.

ok dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.99 2012/12/10 10:38:56 mikeb Exp $	*/
d917 1
a917 1
	    MII_PHY_ANY, MII_OFFSET_ANY, mii_flags);
a1102 7
	/* Make sure we are accessing the correct PHY address. */
	if (phy != sc->bnx_phy_addr) {
		DBPRINT(sc, BNX_VERBOSE,
		    "Invalid PHY address %d for PHY read!\n", phy);
		return(0);
	}

a1179 7

	/* Make sure we are accessing the correct PHY address. */
	if (phy != sc->bnx_phy_addr) {
		DBPRINT(sc, BNX_VERBOSE, "Invalid PHY address %d for PHY write!\n",
		    phy);
		return;
	}
@


1.99
log
@Under some circumstances (currently only reproducible with IPsec)
bnx can be left w/o clusters on the receive ring and will stall.
To prevent that schedule a timeout if refill fails.  Bug was
reported by jj@@, fix tested by me, ok dlg
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.98 2012/12/05 23:20:20 deraadt Exp $	*/
d913 1
a913 3
	if (BNX_CHIP_NUM(sc) == BNX_CHIP_NUM_5706 ||
	    (!(sc->bnx_phy_flags & BNX_PHY_SERDES_FLAG)))
		mii_flags |= MIIF_DOPAUSE;
@


1.98
log
@Remove excessive sys/cdefs.h inclusion
ok guenther millert kettenis
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.97 2012/07/05 13:50:15 phessler Exp $	*/
d361 1
a361 1
void	bnx_fill_rx_chain(struct bnx_softc *);
d366 1
d937 1
d3276 1
d4032 1
a4032 1
void
d4037 1
d4060 1
d4079 2
d4198 12
d4575 2
a4576 1
	bnx_fill_rx_chain(sc);
@


1.97
log
@Add flow control to bnx(4)

Tested on 5706, 5708, 5709, 5716 chipsets.

From Brad

OK phessler@@, sthen@@, mikeb@@,
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.96 2012/05/14 14:17:30 mikeb Exp $	*/
a31 5

#if 0
#include <sys/cdefs.h>
__FBSDID("$FreeBSD: src/sys/dev/bce/if_bce.c,v 1.3 2006/04/13 14:12:26 ru Exp $");
#endif
@


1.96
log
@fixup "couldn't establish interrupt" error printf;  from brad, ok phessler
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.95 2011/06/22 16:44:27 tedu Exp $	*/
d917 3
d1269 1
d1277 9
d1325 28
d3987 7
d4007 2
a4008 1
		val |= lo_water |
a4242 1
	ifmr->ifm_active = mii->mii_media_active;
d4244 2
d5133 14
@


1.95
log
@kill a few more casts that aren't helpful.  ok krw miod
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.94 2011/04/18 04:27:31 dlg Exp $	*/
a750 2
	printf(": %s\n", intrstr);

d755 4
a758 2
		printf("%s: couldn't establish interrupt\n",
		    sc->bnx_dev.dv_xname);
d761 2
@


1.94
log
@ido not disable interrupts in the isr and then enable them again
when leaving. when you're handling an interrupt it is masked.
whacking the chip is work for no gain.

modify the interrupt handler so it only processes the rings once
rather than looping over them until it runs out of work to do

looping in the isr is bad for several reasons:

firstly, the chip does interrupt mitigation so you have a
decent/predictable amount of work to do in the isr. your first loop
will do that chunk of work (ie, it pulls off 50ish packets), and
then the successive looping aggressively pull one or two packets
off the rx ring. these extra loops work against the benefit that
interrupt mitigation provides.

bus space reads are slow. we should avoid doing them where possible
(but we should always do them when necessary).

doing the loop 5 times per isr works against the mclgeti semantics.
it knows a nic is busy and therefore needs more rx descriptors by
watching to see when the nic uses all of its descriptors between
interrupts. if we're aggressively pulling packets off by looping
in the isr then we're skewing this check.

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.93 2011/04/13 07:28:35 dlg Exp $	*/
d3917 1
a3917 1
		bzero((char *)sc->tx_bd_chain[i], BNX_TX_CHAIN_PAGE_SZ);
d4133 1
a4133 1
		bzero((char *)sc->rx_bd_chain[i], BNX_RX_CHAIN_PAGE_SZ);
@


1.93
log
@to quote from the gospel of bus_dma.9:

   Synchronization operations are expressed from the perspective of the host
   RAM, e.g., a device -> memory operation is a READ and a memory -> device
   operation is a WRITE.

the status block that the isr reads is written to by the device.
the chip writes to memory, it is therefore a READ.

this also adds the preread sync when the map is set up and the postread
sync when the map is torn down for better symmetry. there are probably
more issues like this in the code, but this is a start.

discovered while discussing another diff with claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.92 2011/04/05 18:01:21 henning Exp $	*/
d5147 2
a5148 2
	struct bnx_softc	*sc;
	struct ifnet		*ifp;
d5150 2
a5152 1
	sc = xsc;
a5155 2
	ifp = &sc->arpcom.ac_if;

d5167 9
a5175 9
	if ((sc->status_block->status_idx == sc->last_status_idx) && 
	    (REG_RD(sc, BNX_PCICFG_MISC_STATUS) &
	    BNX_PCICFG_MISC_STATUS_INTA_VALUE))
		return (0);

	/* Ack the interrupt and stop others from occuring. */
	REG_WR(sc, BNX_PCICFG_INT_ACK_CMD,
	    BNX_PCICFG_INT_ACK_CMD_USE_INT_HC_PARAM |
	    BNX_PCICFG_INT_ACK_CMD_MASK_INT);
a5176 2
	/* Keep processing data as long as there is work to do. */
	for (;;) {
d5201 1
a5201 1
			    bnx_breakpoint(sc));
d5204 1
a5204 1
			return (1);
d5217 2
a5218 1
		/* Save the status block index value for use during the
d5221 1
a5221 1
		sc->last_status_idx = sc->status_block->status_idx;
d5223 3
a5225 12
		/* Prevent speculative reads from getting ahead of the
		 * status block.
		 */
		bus_space_barrier(sc->bnx_btag, sc->bnx_bhandle, 0, 0, 
		    BUS_SPACE_BARRIER_READ);

		/* If there's no work left then exit the isr. */
		if ((sc->status_block->status_rx_quick_consumer_index0 ==
		    sc->hw_rx_cons) &&
		    (sc->status_block->status_tx_quick_consumer_index0 ==
		    sc->hw_tx_cons))
			break;
d5228 1
d5232 1
a5232 12
	/* Re-enable interrupts. */
	REG_WR(sc, BNX_PCICFG_INT_ACK_CMD,
	    BNX_PCICFG_INT_ACK_CMD_INDEX_VALID | sc->last_status_idx |
	    BNX_PCICFG_INT_ACK_CMD_MASK_INT);
	REG_WR(sc, BNX_PCICFG_INT_ACK_CMD,
	    BNX_PCICFG_INT_ACK_CMD_INDEX_VALID | sc->last_status_idx);

	/* Handle any frames that arrived while handling the interrupt. */
	if (ifp->if_flags & IFF_RUNNING && !IFQ_IS_EMPTY(&ifp->if_snd))
		bnx_start(ifp);

	return (1);
@


1.92
log
@mechanic rename M_{TCP|UDP}V4_CSUM_OUT -> M_{TCP|UDP}_CSUM_OUT
ok claudio krw
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.91 2011/04/03 15:36:02 jasper Exp $	*/
d2289 2
d2429 3
d5160 1
a5160 1
	    sc->status_map->dm_mapsize, BUS_DMASYNC_POSTWRITE);
d5240 1
a5240 1
	    sc->status_map->dm_mapsize, BUS_DMASYNC_PREWRITE);
@


1.91
log
@use nitems(); no binary change for drivers that are compiled on amd64.

ok claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.90 2010/09/20 07:40:38 deraadt Exp $	*/
d4836 1
a4836 1
		    (M_TCPV4_CSUM_OUT | M_UDPV4_CSUM_OUT))
@


1.90
log
@Stop doing shutdown hooks in network drivers where possible.  We already
take all interfaces down, via their xxstop routines.  Claudio and I have
verified that none of the shutdown hooks do much extra beyond what xxstop
was already doing; it is largely a pile of junk.
ok claudio, some early comments by sthen; also read by matthew, jsg
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.89 2010/08/03 16:11:57 jsg Exp $	*/
d423 1
a423 1
	    sizeof(bnx_devices)/sizeof(bnx_devices[0])));
@


1.89
log
@Correct use of logical and where binary and was intended.
Spotted by lint, but mirrors a similiar change in the
original FreeBSD code from over a year ago.

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.88 2010/05/24 21:23:23 sthen Exp $	*/
a287 1
void	bnx_shutdown(void *);
a991 17

/****************************************************************************/
/* Device shutdown function.                                                */
/*                                                                          */
/* Stops and resets the controller.                                         */
/*                                                                          */
/* Returns:                                                                 */
/*   Nothing                                                                */
/****************************************************************************/
void
bnx_shutdown(void *xsc)
{
	struct bnx_softc	*sc = (struct bnx_softc *)xsc;

	bnx_stop(sc);
	bnx_reset(sc, BNX_DRV_MSG_CODE_RESET);
}
@


1.88
log
@Support fibre PHY on BCM5709S. From FreeBSD via Brad.
Tested by Brad on: BCM5706, BCM5708C
Tested by me on: BCM5716 (BCM5709 PHY)
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.87 2010/05/19 15:27:35 oga Exp $	*/
d2230 1
a2230 1
	if (sc->bnx_phy_flags && BNX_PHY_SERDES_FLAG) {
@


1.87
log
@BUS_DMA_ZERO instead of alloc, map, bzero.

ok krw@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.86 2009/11/23 10:54:43 claudio Exp $	*/
d45 1
d54 1
a54 1
 *   BCM5709S A0, A1, B0, B1, B2, C0 (pre-production)
d344 1
d910 3
d1128 10
d1217 10
d2207 1
d2220 1
d2232 8
d2257 30
@


1.86
log
@bnx(4) is a bit special. The chip itself is capable of swapping endianess
so there is no need for htoleXX calls. The only thing needed is the correct
layout of the DMA-ed structures. Additionally it uses PAGE_SIZE but assumed
that it is always 4k. Fix the macros that failed to respect that so that it
works on 8k PAGE_SIZE systems. This makes bnx(4) work on sparc64.
Tested on amd64 by dlg@@. OK dlg@@, deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.85 2009/11/09 14:32:41 dlg Exp $	*/
d2360 1
a2360 1
	    &sc->status_rseg, BUS_DMA_NOWAIT)) {
a2380 1
	bzero(sc->status_block, BNX_STATUS_BLK_SZ);
d2447 1
a2447 1
	    &sc->stats_rseg, BUS_DMA_NOWAIT)) {
a2467 1
	bzero(sc->stats_block, BNX_STATS_BLK_SZ);
d2542 1
a2542 1
		    &sc->rx_bd_chain_rseg[i], BUS_DMA_NOWAIT)) {
a2564 1
		bzero(sc->rx_bd_chain[i], BNX_RX_CHAIN_PAGE_SZ);
@


1.85
log
@Link state change interrupt was not generated due to a missing bit in
the MAC event register.

fix from atte dot peltomaki at iki dot fi
tested by me on 5708 and 5709
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.83 2009/08/09 11:40:56 deraadt Exp $	*/
d3629 2
a3630 2
	addr = (u_int32_t)(map->dm_segs[0].ds_addr);
	rxbd->rx_bd_haddr_lo = htole32(addr);
d3632 3
a3634 3
	rxbd->rx_bd_haddr_hi = htole32(addr);
	rxbd->rx_bd_len = htole32(map->dm_segs[0].ds_len);
	rxbd->rx_bd_flags = htole32(RX_BD_FLAGS_START);
d3644 2
a3645 2
		addr = (u_int32_t)(map->dm_segs[i].ds_addr);
		rxbd->rx_bd_haddr_lo = htole32(addr);
d3647 2
a3648 2
		rxbd->rx_bd_haddr_hi = htole32(addr);
		rxbd->rx_bd_len = htole32(map->dm_segs[i].ds_len);
d3653 1
a3653 1
	rxbd->rx_bd_flags |= htole32(RX_BD_FLAGS_END);
d3807 2
a3808 2
		addr = (u_int32_t)(sc->tx_bd_chain_paddr[j]);
		txbd->tx_bd_haddr_lo = htole32(addr);
d3810 1
a3810 1
		txbd->tx_bd_haddr_hi = htole32(addr);
d4019 3
a4021 3
		rxbd->rx_bd_haddr_hi = htole32(addr);
		addr = (u_int32_t)(sc->rx_bd_chain_paddr[j]);
		rxbd->rx_bd_haddr_lo = htole32(addr);
d4844 2
a4845 2
		addr = (u_int32_t)(map->dm_segs[i].ds_addr);
		txbd->tx_bd_haddr_lo = htole32(addr);
d4847 4
a4850 4
		txbd->tx_bd_haddr_hi = htole32(addr);
		txbd->tx_bd_mss_nbytes = htole16(map->dm_segs[i].ds_len);
		txbd->tx_bd_vlan_tag = htole16(vlan_tag);
		txbd->tx_bd_flags = htole16(flags);
d4853 1
a4853 1
			txbd->tx_bd_flags |= htole16(TX_BD_FLAGS_START);
d4858 1
a4858 1
	txbd->tx_bd_flags |= htole16(TX_BD_FLAGS_END);
@


1.84
log
@- consistify cfdriver for the ethernet drivers (0 -> NULL)

ok dlg@@
@
text
@d3463 1
@


1.83
log
@MCLGETI() will now allocate a mbuf header if it is not provided, thus
reducing the amount of splnet/splx dancing required.. especially in the
worst case (of m_cldrop)
ok dlg kettenis damien
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.82 2009/08/06 19:53:13 sthen Exp $	*/
d406 1
a406 1
	0, "bnx", DV_IFNET
@


1.82
log
@Add device id for BCM5716S, tidy whitespace. From Brad.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.81 2009/07/03 04:54:05 dlg Exp $	*/
d3594 2
a3595 2
	MGETHDR(m, M_DONTWAIT, MT_DATA);
	if (m == NULL)
a3596 7

	/* Attach a cluster to the mbuf. */
	MCLGETI(m, M_DONTWAIT, &sc->arpcom.ac_if, MCLBYTES);
	if (!(m->m_flags & M_EXT)) {
		m_freem(m);
		return (ENOBUFS);
	}
@


1.81
log
@this is a rather large change to add support for the BCM5709.

the 5709s use a the b09 firmwares, which is different to the b06 used by
all the other chips supported by bnx. the majority of the diff comes from
special handling for some indirect reads and writes, and because it needs
more host memory to operate with.

ive tried to keep the cosmetic changes to a minimum.

"go for it" deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.78 2009/04/22 01:17:26 dlg Exp $	*/
a160 1

d163 2
a164 2
	{ PCI_VENDOR_BROADCOM, PCI_PRODUCT_BROADCOM_BCM5716 }

@


1.80
log
@newer bnx chips use a separate firmware to the "old" ones. this updates
the b06 firmware for the older chips, and adds the b09 firmware. there are
three variants of the rv2p code thats loaded onto the chips, so this has
been split out into separate firmware files as well.

the driver has been updated to handle the split firmwares, and to easily
allow loading of the different versions. this change only supports the
loading of the firmwares for the currently supported chips.

after this change you must build the new firmwares and install them as well
as your new kernel.

"go to it" deraadt@@
@
text
@d44 2
d52 2
d160 2
a161 2
	{ PCI_VENDOR_BROADCOM, PCI_PRODUCT_BROADCOM_BCM5708S }
#if 0
d163 3
a165 2
	{ PCI_VENDOR_BROADCOM, PCI_PRODUCT_BROADCOM_BCM5709S }
#endif
d173 3
d178 1
a178 1
	 1, SEEPROM_PAGE_BITS, SEEPROM_PAGE_SIZE,
d183 1
a183 1
	 0, SAIFUN_FLASH_PAGE_BITS, SAIFUN_FLASH_PAGE_SIZE,
d195 1
a195 1
	 0, SAIFUN_FLASH_PAGE_BITS, SAIFUN_FLASH_PAGE_SIZE,
d200 1
a200 1
	 0, SAIFUN_FLASH_PAGE_BITS, SAIFUN_FLASH_PAGE_SIZE,
d205 1
a205 1
	 0, ST_MICRO_FLASH_PAGE_BITS, ST_MICRO_FLASH_PAGE_SIZE,
d210 1
a210 1
	 0, ST_MICRO_FLASH_PAGE_BITS, ST_MICRO_FLASH_PAGE_SIZE,
d216 1
a216 1
	 0, SAIFUN_FLASH_PAGE_BITS, SAIFUN_FLASH_PAGE_SIZE,
d221 1
a221 1
	 1, SEEPROM_PAGE_BITS, SEEPROM_PAGE_SIZE,
d226 1
a226 1
	 0, SAIFUN_FLASH_PAGE_BITS, SAIFUN_FLASH_PAGE_SIZE,
d231 1
a231 1
	 0, SAIFUN_FLASH_PAGE_BITS, SAIFUN_FLASH_PAGE_SIZE,
d236 1
a236 1
	 1, BUFFERED_FLASH_PAGE_BITS, BUFFERED_FLASH_PAGE_SIZE,
d241 1
a241 1
	 0, SAIFUN_FLASH_PAGE_BITS, SAIFUN_FLASH_PAGE_SIZE,
d246 1
a246 1
	 0, SAIFUN_FLASH_PAGE_BITS, SAIFUN_FLASH_PAGE_SIZE,
d251 1
a251 1
	 1, BUFFERED_FLASH_PAGE_BITS, BUFFERED_FLASH_PAGE_SIZE,
d256 1
a256 1
	 1, BUFFERED_FLASH_PAGE_BITS, BUFFERED_FLASH_PAGE_SIZE,
d261 16
d343 1
d365 1
d367 1
d697 2
a698 1
		sc->bnx_shmem_base = REG_RD_IND(sc, BNX_SHM_HDR_ADDR_0);
a775 1
	u_int32_t		val;
d777 10
d788 1
a788 1
	if ((error = bnx_read_firmware(sc, BNX_FW_B06)) != 0) {
d794 1
a794 1
	if ((error = bnx_read_rv2p(sc, BNX_RV2P)) != 0) {
d856 2
a857 21
	/*
	 * The SerDes based NetXtreme II controllers
	 * that support 2.5Gb operation (currently 
	 * 5708S) use a PHY at address 2, otherwise 
	 * the PHY is present at address 1.
	 */
	sc->bnx_phy_addr = 1;

	if (BNX_CHIP_BOND_ID(sc) & BNX_CHIP_BOND_ID_SERDES_BIT) {
		sc->bnx_phy_flags |= BNX_PHY_SERDES_FLAG;
		sc->bnx_flags |= BNX_NO_WOL_FLAG;
		if (BNX_CHIP_NUM(sc) != BNX_CHIP_NUM_5706) {
			sc->bnx_phy_addr = 2;
			val = REG_RD_IND(sc, sc->bnx_shmem_base +
					 BNX_SHARED_HW_CFG_CONFIG);
			if (val & BNX_SHARED_HW_CFG_PHY_2_5G) {
				sc->bnx_phy_flags |= BNX_PHY_2_5G_CAPABLE_FLAG;
				DBPRINT(sc, BNX_WARN, "Found 2.5Gb capable adapter\n");
			}
		}
	}
d1071 2
a1072 2
bnx_ctx_wr(struct bnx_softc *sc, u_int32_t cid_addr, u_int32_t offset,
    u_int32_t val)
d1074 2
d1077 18
a1094 2
	DBPRINT(sc, BNX_EXCESSIVE, "%s(); cid_addr = 0x%08X, offset = 0x%08X, "
		"val = 0x%08X\n", __FUNCTION__, cid_addr, offset, val);
d1096 4
a1099 3
	offset += cid_addr;
	REG_WR(sc, BNX_CTX_DATA_ADR, offset);
	REG_WR(sc, BNX_CTX_DATA, val);
d1398 1
a1398 1
	if (!sc->bnx_flash_info->buffered) {
d1504 1
a1504 1
	if (sc->bnx_flash_info->buffered)
d1560 2
a1561 2
	/* Calculate the offset for buffered flash. */
	if (sc->bnx_flash_info->buffered)
d1565 1
d1622 2
a1623 2
	/* Calculate the offset for buffered flash. */
	if (sc->bnx_flash_info->buffered)
d1627 1
d1670 1
a1670 1
	int			j, entry_count, rc;
d1675 5
a1684 2
	rc = 0;

d1752 1
d1968 1
a1968 1
		if (sc->bnx_flash_info->buffered == 0) {
d2003 1
a2003 1
		if (sc->bnx_flash_info->buffered == 0) {
d2020 2
a2021 2
			    ((sc->bnx_flash_info->buffered) &&
			    (addr == data_end - 4))) {
d2037 1
a2037 1
		if (sc->bnx_flash_info->buffered == 0) {
d2135 91
d2265 18
d2388 48
d2695 6
d2710 1
a2710 2
		}
		else {
d2818 8
d3032 22
a3053 1
	u_int32_t		vcid;
d3055 4
a3058 3
	vcid = 96;
	while (vcid) {
		u_int32_t vcid_addr, pcid_addr, offset;
d3060 17
a3076 1
		vcid--;
d3078 4
a3081 2
   		vcid_addr = GET_CID_ADDR(vcid);
		pcid_addr = vcid_addr;
d3083 17
a3099 2
		REG_WR(sc, BNX_CTX_VIRT_ADDR, 0x00);
		REG_WR(sc, BNX_CTX_PAGE_TBL, pcid_addr);
d3101 4
a3104 7
		/* Zero out the context. */
		for (offset = 0; offset < PHY_CTX_SIZE; offset += 4)
			CTX_WR(sc, 0x00, offset, 0);

		REG_WR(sc, BNX_CTX_VIRT_ADDR, vcid_addr);
		REG_WR(sc, BNX_CTX_PAGE_TBL, pcid_addr);
	}
d3234 1
d3249 7
d3272 4
a3275 4
	val = BNX_PCICFG_MISC_CONFIG_CORE_RST_REQ |
	    BNX_PCICFG_MISC_CONFIG_REG_WINDOW_ENA |
	    BNX_PCICFG_MISC_CONFIG_TARGET_MB_WORD_SWAP;
	REG_WR(sc, BNX_PCICFG_MISC_CONFIG, val);
d3277 2
a3278 6
	/* Allow up to 30us for reset to complete. */
	for (i = 0; i < 10; i++) {
		val = REG_RD(sc, BNX_PCICFG_MISC_CONFIG);
		if ((val & (BNX_PCICFG_MISC_CONFIG_CORE_RST_REQ |
		    BNX_PCICFG_MISC_CONFIG_CORE_RST_BSY)) == 0)
			break;
d3280 17
a3296 2
		DELAY(10);
	}
d3298 8
a3305 6
	/* Check that reset completed successfully. */
	if (val & (BNX_PCICFG_MISC_CONFIG_CORE_RST_REQ |
	    BNX_PCICFG_MISC_CONFIG_CORE_RST_BSY)) {
		BNX_PRINTF(sc, "%s(%d): Reset failed!\n", __FILE__, __LINE__);
		rc = EBUSY;
		goto bnx_reset_exit;
d3372 1
d3379 1
d3403 8
d3426 5
d3530 7
d3541 5
a3545 1
	REG_WR(sc, BNX_HC_ATTN_BITS_ENABLE, STATUS_ATTN_BITS_LINK_STATE);
d3725 41
d3775 1
a3775 1
	u_int32_t		val, addr;
d3823 1
a3823 14
	val = BNX_L2CTX_TYPE_TYPE_L2;
	val |= BNX_L2CTX_TYPE_SIZE_L2;
	CTX_WR(sc, GET_CID_ADDR(TX_CID), BNX_L2CTX_TYPE, val);

	val = BNX_L2CTX_CMD_TYPE_TYPE_L2 | (8 << 16);
	CTX_WR(sc, GET_CID_ADDR(TX_CID), BNX_L2CTX_CMD_TYPE, val);

	/* Point the hardware to the first page in the chain. */
	val = (u_int32_t)((u_int64_t)sc->tx_bd_chain_paddr[0] >> 32);
	CTX_WR(sc, GET_CID_ADDR(TX_CID), BNX_L2CTX_TBDR_BHADDR_HI, val);
	val = (u_int32_t)(sc->tx_bd_chain_paddr[0]);
	CTX_WR(sc, GET_CID_ADDR(TX_CID), BNX_L2CTX_TBDR_BHADDR_LO, val);

	DBRUN(BNX_VERBOSE_SEND, bnx_dump_tx_chain(sc, 0, TOTAL_TX_BD));
d3888 47
d3999 1
a3999 1
	u_int32_t		val, addr;
a4030 12
	/* Initialize the context ID for an L2 RX chain. */
	val = BNX_L2CTX_CTX_TYPE_CTX_BD_CHN_TYPE_VALUE;
	val |= BNX_L2CTX_CTX_TYPE_SIZE_L2;
	val |= 0x02 << 8;
	CTX_WR(sc, GET_CID_ADDR(RX_CID), BNX_L2CTX_CTX_TYPE, val);

	/* Point the hardware to the first page in the chain. */
	val = (u_int32_t)((u_int64_t)sc->rx_bd_chain_paddr[0] >> 32);
	CTX_WR(sc, GET_CID_ADDR(RX_CID), BNX_L2CTX_NX_BDHADDR_HI, val);
	val = (u_int32_t)(sc->rx_bd_chain_paddr[0]);
	CTX_WR(sc, GET_CID_ADDR(RX_CID), BNX_L2CTX_NX_BDHADDR_LO, val);

d4038 2
@


1.79
log
@Rewrite the interface flag handling case code and update the receive
filter handling to take advantage of ac_multirangecnt and have correct
IFF_ALLMULTI handling.  From Brad.
@
text
@d54 43
a96 86
int bnx_COM_b06FwReleaseMajor;
int bnx_COM_b06FwReleaseMinor;
int bnx_COM_b06FwReleaseFix;
u_int32_t bnx_COM_b06FwStartAddr;
u_int32_t bnx_COM_b06FwTextAddr;
int bnx_COM_b06FwTextLen;
u_int32_t bnx_COM_b06FwDataAddr;
int bnx_COM_b06FwDataLen;
u_int32_t bnx_COM_b06FwRodataAddr;
int bnx_COM_b06FwRodataLen;
u_int32_t bnx_COM_b06FwBssAddr;
int bnx_COM_b06FwBssLen;
u_int32_t bnx_COM_b06FwSbssAddr;
int bnx_COM_b06FwSbssLen;

int bnx_RXP_b06FwReleaseMajor;
int bnx_RXP_b06FwReleaseMinor;
int bnx_RXP_b06FwReleaseFix;
u_int32_t bnx_RXP_b06FwStartAddr;
u_int32_t bnx_RXP_b06FwTextAddr;
int bnx_RXP_b06FwTextLen;
u_int32_t bnx_RXP_b06FwDataAddr;
int bnx_RXP_b06FwDataLen;
u_int32_t bnx_RXP_b06FwRodataAddr;
int bnx_RXP_b06FwRodataLen;
u_int32_t bnx_RXP_b06FwBssAddr;
int bnx_RXP_b06FwBssLen;
u_int32_t bnx_RXP_b06FwSbssAddr;
int bnx_RXP_b06FwSbssLen;

int bnx_TPAT_b06FwReleaseMajor;
int bnx_TPAT_b06FwReleaseMinor;
int bnx_TPAT_b06FwReleaseFix;
u_int32_t bnx_TPAT_b06FwStartAddr;
u_int32_t bnx_TPAT_b06FwTextAddr;
int bnx_TPAT_b06FwTextLen;
u_int32_t bnx_TPAT_b06FwDataAddr;
int bnx_TPAT_b06FwDataLen;
u_int32_t bnx_TPAT_b06FwRodataAddr;
int bnx_TPAT_b06FwRodataLen;
u_int32_t bnx_TPAT_b06FwBssAddr;
int bnx_TPAT_b06FwBssLen;
u_int32_t bnx_TPAT_b06FwSbssAddr;
int bnx_TPAT_b06FwSbssLen;

int bnx_TXP_b06FwReleaseMajor;
int bnx_TXP_b06FwReleaseMinor;
int bnx_TXP_b06FwReleaseFix;
u_int32_t bnx_TXP_b06FwStartAddr;
u_int32_t bnx_TXP_b06FwTextAddr;
int bnx_TXP_b06FwTextLen;
u_int32_t bnx_TXP_b06FwDataAddr;
int bnx_TXP_b06FwDataLen;
u_int32_t bnx_TXP_b06FwRodataAddr;
int bnx_TXP_b06FwRodataLen;
u_int32_t bnx_TXP_b06FwBssAddr;
int bnx_TXP_b06FwBssLen;
u_int32_t bnx_TXP_b06FwSbssAddr;
int bnx_TXP_b06FwSbssLen;

int bnx_rv2p_proc1len;
int bnx_rv2p_proc2len;

u_int32_t *bnx_COM_b06FwText;
u_int32_t *bnx_COM_b06FwData;
u_int32_t *bnx_COM_b06FwRodata;
u_int32_t *bnx_COM_b06FwBss;
u_int32_t *bnx_COM_b06FwSbss;

u_int32_t *bnx_RXP_b06FwText;
u_int32_t *bnx_RXP_b06FwData;
u_int32_t *bnx_RXP_b06FwRodata;
u_int32_t *bnx_RXP_b06FwBss;
u_int32_t *bnx_RXP_b06FwSbss;

u_int32_t *bnx_TPAT_b06FwText;
u_int32_t *bnx_TPAT_b06FwData;
u_int32_t *bnx_TPAT_b06FwRodata;
u_int32_t *bnx_TPAT_b06FwBss;
u_int32_t *bnx_TPAT_b06FwSbss;

u_int32_t *bnx_TXP_b06FwText;
u_int32_t *bnx_TXP_b06FwData;
u_int32_t *bnx_TXP_b06FwRodata;
u_int32_t *bnx_TXP_b06FwBss;
u_int32_t *bnx_TXP_b06FwSbss;
d98 8
a105 2
u_int32_t *bnx_rv2p_proc1;
u_int32_t *bnx_rv2p_proc2;
d259 2
a260 1
int	bnx_read_firmware(struct bnx_softc *sc);
d409 1
a409 1
bnx_read_firmware(struct bnx_softc *sc)
d411 2
a412 1
	static struct bnx_firmware_header *hdr;
d417 1
a417 1
	if (hdr)
d420 135
a554 2
	if ((error = loadfirmware("bnx", &p, &size)) != 0)
		return error;
d556 1
a556 1
	if (size < sizeof (struct bnx_firmware_header)) {
d558 1
d562 24
a585 1
	hdr = (struct bnx_firmware_header *)p;
d587 1
a587 59
	bnx_COM_b06FwReleaseMajor = ntohl(hdr->bnx_COM_b06FwReleaseMajor);
	bnx_COM_b06FwReleaseMinor = ntohl(hdr->bnx_COM_b06FwReleaseMinor);
	bnx_COM_b06FwReleaseFix = ntohl(hdr->bnx_COM_b06FwReleaseFix);
	bnx_COM_b06FwStartAddr = ntohl(hdr->bnx_COM_b06FwStartAddr);
	bnx_COM_b06FwTextAddr = ntohl(hdr->bnx_COM_b06FwTextAddr);
	bnx_COM_b06FwTextLen = ntohl(hdr->bnx_COM_b06FwTextLen);
	bnx_COM_b06FwDataAddr = ntohl(hdr->bnx_COM_b06FwDataAddr);
	bnx_COM_b06FwDataLen = ntohl(hdr->bnx_COM_b06FwDataLen);
	bnx_COM_b06FwRodataAddr = ntohl(hdr->bnx_COM_b06FwRodataAddr);
	bnx_COM_b06FwRodataLen = ntohl(hdr->bnx_COM_b06FwRodataLen);
	bnx_COM_b06FwBssAddr = ntohl(hdr->bnx_COM_b06FwBssAddr);
	bnx_COM_b06FwBssLen = ntohl(hdr->bnx_COM_b06FwBssLen);
	bnx_COM_b06FwSbssAddr = ntohl(hdr->bnx_COM_b06FwSbssAddr);
	bnx_COM_b06FwSbssLen = ntohl(hdr->bnx_COM_b06FwSbssLen);

	bnx_RXP_b06FwReleaseMajor = ntohl(hdr->bnx_RXP_b06FwReleaseMajor);
	bnx_RXP_b06FwReleaseMinor = ntohl(hdr->bnx_RXP_b06FwReleaseMinor);
	bnx_RXP_b06FwReleaseFix = ntohl(hdr->bnx_RXP_b06FwReleaseFix);
	bnx_RXP_b06FwStartAddr = ntohl(hdr->bnx_RXP_b06FwStartAddr);
	bnx_RXP_b06FwTextAddr = ntohl(hdr->bnx_RXP_b06FwTextAddr);
	bnx_RXP_b06FwTextLen = ntohl(hdr->bnx_RXP_b06FwTextLen);
	bnx_RXP_b06FwDataAddr = ntohl(hdr->bnx_RXP_b06FwDataAddr);
	bnx_RXP_b06FwDataLen = ntohl(hdr->bnx_RXP_b06FwDataLen);
	bnx_RXP_b06FwRodataAddr = ntohl(hdr->bnx_RXP_b06FwRodataAddr);
	bnx_RXP_b06FwRodataLen = ntohl(hdr->bnx_RXP_b06FwRodataLen);
	bnx_RXP_b06FwBssAddr = ntohl(hdr->bnx_RXP_b06FwBssAddr);
	bnx_RXP_b06FwBssLen = ntohl(hdr->bnx_RXP_b06FwBssLen);
	bnx_RXP_b06FwSbssAddr = ntohl(hdr->bnx_RXP_b06FwSbssAddr);
	bnx_RXP_b06FwSbssLen = ntohl(hdr->bnx_RXP_b06FwSbssLen);

	bnx_TPAT_b06FwReleaseMajor = ntohl(hdr->bnx_TPAT_b06FwReleaseMajor);
	bnx_TPAT_b06FwReleaseMinor = ntohl(hdr->bnx_TPAT_b06FwReleaseMinor);
	bnx_TPAT_b06FwReleaseFix = ntohl(hdr->bnx_TPAT_b06FwReleaseFix);
	bnx_TPAT_b06FwStartAddr = ntohl(hdr->bnx_TPAT_b06FwStartAddr);
	bnx_TPAT_b06FwTextAddr = ntohl(hdr->bnx_TPAT_b06FwTextAddr);
	bnx_TPAT_b06FwTextLen = ntohl(hdr->bnx_TPAT_b06FwTextLen);
	bnx_TPAT_b06FwDataAddr = ntohl(hdr->bnx_TPAT_b06FwDataAddr);
	bnx_TPAT_b06FwDataLen = ntohl(hdr->bnx_TPAT_b06FwDataLen);
	bnx_TPAT_b06FwRodataAddr = ntohl(hdr->bnx_TPAT_b06FwRodataAddr);
	bnx_TPAT_b06FwRodataLen = ntohl(hdr->bnx_TPAT_b06FwRodataLen);
	bnx_TPAT_b06FwBssAddr = ntohl(hdr->bnx_TPAT_b06FwBssAddr);
	bnx_TPAT_b06FwBssLen = ntohl(hdr->bnx_TPAT_b06FwBssLen);
	bnx_TPAT_b06FwSbssAddr = ntohl(hdr->bnx_TPAT_b06FwSbssAddr);
	bnx_TPAT_b06FwSbssLen = ntohl(hdr->bnx_TPAT_b06FwSbssLen);

	bnx_TXP_b06FwReleaseMajor = ntohl(hdr->bnx_TXP_b06FwReleaseMajor);
	bnx_TXP_b06FwReleaseMinor = ntohl(hdr->bnx_TXP_b06FwReleaseMinor);
	bnx_TXP_b06FwReleaseFix = ntohl(hdr->bnx_TXP_b06FwReleaseFix);
	bnx_TXP_b06FwStartAddr = ntohl(hdr->bnx_TXP_b06FwStartAddr);
	bnx_TXP_b06FwTextAddr = ntohl(hdr->bnx_TXP_b06FwTextAddr);
	bnx_TXP_b06FwTextLen = ntohl(hdr->bnx_TXP_b06FwTextLen);
	bnx_TXP_b06FwDataAddr = ntohl(hdr->bnx_TXP_b06FwDataAddr);
	bnx_TXP_b06FwDataLen = ntohl(hdr->bnx_TXP_b06FwDataLen);
	bnx_TXP_b06FwRodataAddr = ntohl(hdr->bnx_TXP_b06FwRodataAddr);
	bnx_TXP_b06FwRodataLen = ntohl(hdr->bnx_TXP_b06FwRodataLen);
	bnx_TXP_b06FwBssAddr = ntohl(hdr->bnx_TXP_b06FwBssAddr);
	bnx_TXP_b06FwBssLen = ntohl(hdr->bnx_TXP_b06FwBssLen);
	bnx_TXP_b06FwSbssAddr = ntohl(hdr->bnx_TXP_b06FwSbssAddr);
	bnx_TXP_b06FwSbssLen = ntohl(hdr->bnx_TXP_b06FwSbssLen);
d589 2
a590 2
	bnx_rv2p_proc1len = ntohl(hdr->bnx_rv2p_proc1len);
	bnx_rv2p_proc2len = ntohl(hdr->bnx_rv2p_proc2len);
d594 6
a599 70
	bnx_COM_b06FwText = (u_int32_t *)q;
	q += bnx_COM_b06FwTextLen;
	nswaph(bnx_COM_b06FwText, bnx_COM_b06FwTextLen);
	bnx_COM_b06FwData = (u_int32_t *)q;
	q += bnx_COM_b06FwDataLen;
	nswaph(bnx_COM_b06FwData, bnx_COM_b06FwDataLen);
	bnx_COM_b06FwRodata = (u_int32_t *)q;
	q += bnx_COM_b06FwRodataLen;
	nswaph(bnx_COM_b06FwRodata, bnx_COM_b06FwRodataLen);
	bnx_COM_b06FwBss = (u_int32_t *)q;
	q += bnx_COM_b06FwBssLen;
	nswaph(bnx_COM_b06FwBss, bnx_COM_b06FwBssLen);
	bnx_COM_b06FwSbss = (u_int32_t *)q;
	q += bnx_COM_b06FwSbssLen;
	nswaph(bnx_COM_b06FwSbss, bnx_COM_b06FwSbssLen);

	bnx_RXP_b06FwText = (u_int32_t *)q;
	q += bnx_RXP_b06FwTextLen;
	nswaph(bnx_RXP_b06FwText, bnx_RXP_b06FwTextLen);
	bnx_RXP_b06FwData = (u_int32_t *)q;
	q += bnx_RXP_b06FwDataLen;
	nswaph(bnx_RXP_b06FwData, bnx_RXP_b06FwDataLen);
	bnx_RXP_b06FwRodata = (u_int32_t *)q;
	q += bnx_RXP_b06FwRodataLen;
	nswaph(bnx_RXP_b06FwRodata, bnx_RXP_b06FwRodataLen);
	bnx_RXP_b06FwBss = (u_int32_t *)q;
	q += bnx_RXP_b06FwBssLen;
	nswaph(bnx_RXP_b06FwBss, bnx_RXP_b06FwBssLen);
	bnx_RXP_b06FwSbss = (u_int32_t *)q;
	q += bnx_RXP_b06FwSbssLen;
	nswaph(bnx_RXP_b06FwSbss, bnx_RXP_b06FwSbssLen);

	bnx_TPAT_b06FwText = (u_int32_t *)q;
	q += bnx_TPAT_b06FwTextLen;
	nswaph(bnx_TPAT_b06FwText, bnx_TPAT_b06FwTextLen);
	bnx_TPAT_b06FwData = (u_int32_t *)q;
	q += bnx_TPAT_b06FwDataLen;
	nswaph(bnx_TPAT_b06FwData, bnx_TPAT_b06FwDataLen);
	bnx_TPAT_b06FwRodata = (u_int32_t *)q;
	q += bnx_TPAT_b06FwRodataLen;
	nswaph(bnx_TPAT_b06FwRodata, bnx_TPAT_b06FwRodataLen);
	bnx_TPAT_b06FwBss = (u_int32_t *)q;
	q += bnx_TPAT_b06FwBssLen;
	nswaph(bnx_TPAT_b06FwBss, bnx_TPAT_b06FwBssLen);
	bnx_TPAT_b06FwSbss = (u_int32_t *)q;
	q += bnx_TPAT_b06FwSbssLen;
	nswaph(bnx_TPAT_b06FwSbss, bnx_TPAT_b06FwSbssLen);

	bnx_TXP_b06FwText = (u_int32_t *)q;
	q += bnx_TXP_b06FwTextLen;
	nswaph(bnx_TXP_b06FwText, bnx_TXP_b06FwTextLen);
	bnx_TXP_b06FwData = (u_int32_t *)q;
	q += bnx_TXP_b06FwDataLen;
	nswaph(bnx_TXP_b06FwData, bnx_TXP_b06FwDataLen);
	bnx_TXP_b06FwRodata = (u_int32_t *)q;
	q += bnx_TXP_b06FwRodataLen;
	nswaph(bnx_TXP_b06FwRodata, bnx_TXP_b06FwRodataLen);
	bnx_TXP_b06FwBss = (u_int32_t *)q;
	q += bnx_TXP_b06FwBssLen;
	nswaph(bnx_TXP_b06FwBss, bnx_TXP_b06FwBssLen);
	bnx_TXP_b06FwSbss = (u_int32_t *)q;
	q += bnx_TXP_b06FwSbssLen;
	nswaph(bnx_TXP_b06FwSbss, bnx_TXP_b06FwSbssLen);

	bnx_rv2p_proc1 = (u_int32_t *)q;
	q += bnx_rv2p_proc1len;
	nswaph(bnx_rv2p_proc1, bnx_rv2p_proc1len);
	bnx_rv2p_proc2 = (u_int32_t *)q;
	q += bnx_rv2p_proc2len;
	nswaph(bnx_rv2p_proc2, bnx_rv2p_proc2len);
a602 1
		hdr = NULL;
d606 2
d751 1
a751 1
	if ((error = bnx_read_firmware(sc)) != 0) {
d757 6
d2608 2
d2614 4
a2617 4
	bnx_load_rv2p_fw(sc, bnx_rv2p_proc1, bnx_rv2p_proc1len,
	    RV2P_PROC1);
	bnx_load_rv2p_fw(sc, bnx_rv2p_proc2, bnx_rv2p_proc2len,
	    RV2P_PROC2);
d2633 4
a2636 4
	fw.ver_major = bnx_RXP_b06FwReleaseMajor;
	fw.ver_minor = bnx_RXP_b06FwReleaseMinor;
	fw.ver_fix = bnx_RXP_b06FwReleaseFix;
	fw.start_addr = bnx_RXP_b06FwStartAddr;
d2638 2
a2639 2
	fw.text_addr = bnx_RXP_b06FwTextAddr;
	fw.text_len = bnx_RXP_b06FwTextLen;
d2641 1
a2641 1
	fw.text = bnx_RXP_b06FwText;
d2643 2
a2644 2
	fw.data_addr = bnx_RXP_b06FwDataAddr;
	fw.data_len = bnx_RXP_b06FwDataLen;
d2646 1
a2646 1
	fw.data = bnx_RXP_b06FwData;
d2648 2
a2649 2
	fw.sbss_addr = bnx_RXP_b06FwSbssAddr;
	fw.sbss_len = bnx_RXP_b06FwSbssLen;
d2651 1
a2651 1
	fw.sbss = bnx_RXP_b06FwSbss;
d2653 2
a2654 2
	fw.bss_addr = bnx_RXP_b06FwBssAddr;
	fw.bss_len = bnx_RXP_b06FwBssLen;
d2656 1
a2656 1
	fw.bss = bnx_RXP_b06FwBss;
d2658 2
a2659 2
	fw.rodata_addr = bnx_RXP_b06FwRodataAddr;
	fw.rodata_len = bnx_RXP_b06FwRodataLen;
d2661 1
a2661 1
	fw.rodata = bnx_RXP_b06FwRodata;
d2680 4
a2683 4
	fw.ver_major = bnx_TXP_b06FwReleaseMajor;
	fw.ver_minor = bnx_TXP_b06FwReleaseMinor;
	fw.ver_fix = bnx_TXP_b06FwReleaseFix;
	fw.start_addr = bnx_TXP_b06FwStartAddr;
d2685 2
a2686 2
	fw.text_addr = bnx_TXP_b06FwTextAddr;
	fw.text_len = bnx_TXP_b06FwTextLen;
d2688 1
a2688 1
	fw.text = bnx_TXP_b06FwText;
d2690 2
a2691 2
	fw.data_addr = bnx_TXP_b06FwDataAddr;
	fw.data_len = bnx_TXP_b06FwDataLen;
d2693 1
a2693 1
	fw.data = bnx_TXP_b06FwData;
d2695 2
a2696 2
	fw.sbss_addr = bnx_TXP_b06FwSbssAddr;
	fw.sbss_len = bnx_TXP_b06FwSbssLen;
d2698 1
a2698 1
	fw.sbss = bnx_TXP_b06FwSbss;
d2700 2
a2701 2
	fw.bss_addr = bnx_TXP_b06FwBssAddr;
	fw.bss_len = bnx_TXP_b06FwBssLen;
d2703 1
a2703 1
	fw.bss = bnx_TXP_b06FwBss;
d2705 2
a2706 2
	fw.rodata_addr = bnx_TXP_b06FwRodataAddr;
	fw.rodata_len = bnx_TXP_b06FwRodataLen;
d2708 1
a2708 1
	fw.rodata = bnx_TXP_b06FwRodata;
d2727 4
a2730 4
	fw.ver_major = bnx_TPAT_b06FwReleaseMajor;
	fw.ver_minor = bnx_TPAT_b06FwReleaseMinor;
	fw.ver_fix = bnx_TPAT_b06FwReleaseFix;
	fw.start_addr = bnx_TPAT_b06FwStartAddr;
d2732 2
a2733 2
	fw.text_addr = bnx_TPAT_b06FwTextAddr;
	fw.text_len = bnx_TPAT_b06FwTextLen;
d2735 1
a2735 1
	fw.text = bnx_TPAT_b06FwText;
d2737 2
a2738 2
	fw.data_addr = bnx_TPAT_b06FwDataAddr;
	fw.data_len = bnx_TPAT_b06FwDataLen;
d2740 1
a2740 1
	fw.data = bnx_TPAT_b06FwData;
d2742 2
a2743 2
	fw.sbss_addr = bnx_TPAT_b06FwSbssAddr;
	fw.sbss_len = bnx_TPAT_b06FwSbssLen;
d2745 1
a2745 1
	fw.sbss = bnx_TPAT_b06FwSbss;
d2747 2
a2748 2
	fw.bss_addr = bnx_TPAT_b06FwBssAddr;
	fw.bss_len = bnx_TPAT_b06FwBssLen;
d2750 1
a2750 1
	fw.bss = bnx_TPAT_b06FwBss;
d2752 2
a2753 2
	fw.rodata_addr = bnx_TPAT_b06FwRodataAddr;
	fw.rodata_len = bnx_TPAT_b06FwRodataLen;
d2755 1
a2755 1
	fw.rodata = bnx_TPAT_b06FwRodata;
d2774 4
a2777 4
	fw.ver_major = bnx_COM_b06FwReleaseMajor;
	fw.ver_minor = bnx_COM_b06FwReleaseMinor;
	fw.ver_fix = bnx_COM_b06FwReleaseFix;
	fw.start_addr = bnx_COM_b06FwStartAddr;
d2779 2
a2780 2
	fw.text_addr = bnx_COM_b06FwTextAddr;
	fw.text_len = bnx_COM_b06FwTextLen;
d2782 1
a2782 1
	fw.text = bnx_COM_b06FwText;
d2784 2
a2785 2
	fw.data_addr = bnx_COM_b06FwDataAddr;
	fw.data_len = bnx_COM_b06FwDataLen;
d2787 1
a2787 1
	fw.data = bnx_COM_b06FwData;
d2789 2
a2790 2
	fw.sbss_addr = bnx_COM_b06FwSbssAddr;
	fw.sbss_len = bnx_COM_b06FwSbssLen;
d2792 1
a2792 1
	fw.sbss = bnx_COM_b06FwSbss;
d2794 2
a2795 2
	fw.bss_addr = bnx_COM_b06FwBssAddr;
	fw.bss_len = bnx_COM_b06FwBssLen;
d2797 1
a2797 1
	fw.bss = bnx_COM_b06FwBss;
d2799 2
a2800 2
	fw.rodata_addr = bnx_COM_b06FwRodataAddr;
	fw.rodata_len = bnx_COM_b06FwRodataLen;
d2802 1
a2802 1
	fw.rodata = bnx_COM_b06FwRodata;
@


1.78
log
@dont need to zero the tx pkt pool structure before initting it now that
pool_init does its job properly.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.77 2009/04/22 00:38:04 dlg Exp $	*/
d400 1
a400 1
void	bnx_set_rx_mode(struct bnx_softc *);
d4317 1
a4317 1
	bnx_set_rx_mode(sc);
d4642 4
a4645 8
			if ((ifp->if_flags & IFF_RUNNING) &&
			    ((ifp->if_flags ^ sc->bnx_if_flags) &
			    (IFF_ALLMULTI | IFF_PROMISC)) != 0) {
				bnx_set_rx_mode(sc);
			} else {
				if (!(ifp->if_flags & IFF_RUNNING))
					bnx_init(sc);
			}
a4649 1
		sc->bnx_if_flags = ifp->if_flags;
d4666 1
a4666 1
			bnx_set_rx_mode(sc);
d4835 1
a4835 1
bnx_set_rx_mode(struct bnx_softc *sc)
d4849 1
d4866 1
d4870 1
a4870 2
	} else if (ifp->if_flags & IFF_ALLMULTI) {
allmulti:
d4873 1
a4884 5
			if (bcmp(enm->enm_addrlo, enm->enm_addrhi,
			    ETHER_ADDR_LEN)) {
				ifp->if_flags |= IFF_ALLMULTI;
				goto allmulti;
			}
d4887 1
d4889 1
@


1.77
log
@replace arrays of dmamaps and mbuf pointers used to manage packets
on the tx rings (one mbuf ptr/dmamap array entry was created for
every tx descriptor slot at attach time) with a dynamically grown
list of mbuf pointers and dmamaps.

bnx used to have 512 dmamaps/mbuf pointers for the tx ring, now my
system is running with 8 under moderate load.

the big bonus from this is that the dmamap handling is greatly
simplified.

reyk@@ likes this a lot
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.76 2009/04/20 12:24:52 dlg Exp $	*/
d4261 1
a4261 2
		bnx_tx_pool = malloc(sizeof(*bnx_tx_pool), M_DEVBUF,
		    M_WAITOK | M_ZERO);
@


1.76
log
@when transmitting packets, put the dmamap we used for the packet into the
last descriptor slot in the ring. the tx completion code expects the dmamap
to be there so it can unload it.

ok reyk@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.75 2009/04/20 11:39:02 reyk Exp $	*/
d404 4
d2141 2
a2142 7
	/* Unload and destroy the TX mbuf maps. */
	for (i = 0; i < TOTAL_TX_BD; i++) {
		if (sc->tx_mbuf_map[i] != NULL) {
			bus_dmamap_unload(sc->bnx_dmatag, sc->tx_mbuf_map[i]);
			bus_dmamap_destroy(sc->bnx_dmatag, sc->tx_mbuf_map[i]);
		}
	}
d2316 1
a2316 1
	 * Create DMA maps for the TX buffer mbufs.
d2318 4
a2321 9
	for (i = 0; i < TOTAL_TX_BD; i++) {
		if (bus_dmamap_create(sc->bnx_dmatag,
		    MCLBYTES * BNX_MAX_SEGMENTS, USABLE_TX_BD,
		    MCLBYTES, 0, BUS_DMA_NOWAIT, &sc->tx_mbuf_map[i])) {
			printf(": Could not create Tx mbuf %d DMA map!\n", i);
			rc = ENOMEM;
			goto bnx_dma_alloc_exit;
		}
	}
d3357 46
d3418 3
d3490 1
d3496 25
a3520 14
	for (i = 0; i < TOTAL_TX_BD; i++) {
		if (sc->tx_mbuf_ptr[i] != NULL) {
			if (sc->tx_mbuf_map[i] != NULL) {
				bus_dmamap_sync(sc->bnx_dmatag,
				    sc->tx_mbuf_map[i], 0,
				    sc->tx_mbuf_map[i]->dm_mapsize,
				    BUS_DMASYNC_POSTWRITE);
				bus_dmamap_unload(sc->bnx_dmatag,
				    sc->tx_mbuf_map[i]);
			}
			m_freem(sc->tx_mbuf_ptr[i]);
			sc->tx_mbuf_ptr[i] = NULL;
			DBRUNIF(1, sc->tx_mbuf_alloc--);
		}			
d3522 1
d4105 2
d4151 14
a4164 16
		/*
		 * Free the associated mbuf. Remember
		 * that only the last tx_bd of a packet
		 * has an mbuf pointer and DMA map.
		 */
		if (sc->tx_mbuf_ptr[sw_tx_chain_cons] != NULL) {
			/* Validate that this is the last tx_bd. */
			DBRUNIF((!(txbd->tx_bd_flags & TX_BD_FLAGS_END)),
			    printf("%s: tx_bd END flag not set but "
			    "txmbuf == NULL!\n");
			    bnx_breakpoint(sc));

			DBRUN(BNX_INFO_SEND,
			    printf("%s: Unloading map/freeing mbuf "
			    "from tx_bd[0x%04X]\n",
			    __FUNCTION__, sw_tx_chain_cons));
d4166 1
a4166 8
			/* Unmap the mbuf. */
			bus_dmamap_unload(sc->bnx_dmatag,
			    sc->tx_mbuf_map[sw_tx_chain_cons]);
	
			/* Free the mbuf. */
			m_freem(sc->tx_mbuf_ptr[sw_tx_chain_cons]);
			sc->tx_mbuf_ptr[sw_tx_chain_cons] = NULL;
			DBRUNIF(1, sc->tx_mbuf_alloc--);
d4169 3
d4173 1
d4253 1
d4258 16
d4384 1
d4388 1
a4388 1
	u_int16_t		chain_prod, chain_head, prod;
d4395 14
d4428 2
a4429 2
	chain_head = chain_prod = TX_CHAIN_IDX(prod);
	map = sc->tx_mbuf_map[chain_head];
d4432 2
a4433 1
	error = bus_dmamap_load_mbuf(sc->bnx_dmatag, map, m, BUS_DMA_NOWAIT);
d4438 1
a4438 1
		return (error);
d4442 2
a4443 4
	if (map->dm_nsegs > (sc->max_tx_bd - sc->used_tx_bd)) {
		bus_dmamap_unload(sc->bnx_dmatag, map);
		return (ENOBUFS);
	}
d4478 1
a4478 1
 
d4490 7
a4496 12
	/*
	 * Ensure that the mbuf pointer for this
	 * transmission is placed at the array
	 * index of the last descriptor in this
	 * chain.  This is done because a single
	 * map is used for all segments of the mbuf
	 * and we don't want to unload the map before
	 * all of the segments have been freed.
	 */
	sc->tx_mbuf_map[chain_head] = sc->tx_mbuf_map[chain_prod];
	sc->tx_mbuf_map[chain_prod] = map;
	sc->tx_mbuf_ptr[chain_prod] = m;
d4516 9
@


1.75
log
@fix dma map unmapping and unloading in the tx cleanup path.

ok dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.74 2009/04/14 07:41:24 kettenis Exp $	*/
d4317 1
a4317 1
	u_int16_t		chain_prod, prod;
d4343 2
a4344 2
	chain_prod = TX_CHAIN_IDX(prod);
	map = sc->tx_mbuf_map[chain_prod];
d4415 2
d4428 3
@


1.74
log
@Don't free an mbuf that's still on the TX queue.  While there sanitize the
function signature of bnx_tx_encap() such that people don't get weird ideas
like this again.

ok dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.73 2009/04/09 11:36:05 dlg Exp $	*/
d3454 1
a3454 1
			if (sc->tx_mbuf_map != NULL)
d3459 3
d3629 1
a3629 1
			if (sc->rx_mbuf_map[i] != NULL)
d3634 3
@


1.73
log
@white space fixes
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.72 2009/03/30 02:38:53 dlg Exp $	*/
d381 1
a381 1
int	bnx_tx_encap(struct bnx_softc *, struct mbuf **);
d4306 1
a4306 1
bnx_tx_encap(struct bnx_softc *sc, struct mbuf **m_head)
a4309 1
	struct mbuf		*m0;
d4316 1
a4316 1
	int			i, error, rc = 0;
a4317 1
	m0 = *m_head;
d4319 2
a4320 2
	if (m0->m_pkthdr.csum_flags) {
		if (m0->m_pkthdr.csum_flags & M_IPV4_CSUM_OUT)
d4322 1
a4322 1
		if (m0->m_pkthdr.csum_flags &
d4329 1
a4329 1
	if (m0->m_flags & M_VLANTAG) {
d4331 1
a4331 1
		vlan_tag = m0->m_pkthdr.ether_vtag;
d4341 1
a4341 1
	error = bus_dmamap_load_mbuf(sc->bnx_dmatag, map, m0, BUS_DMA_NOWAIT);
a4344 2
		m_freem(m0);
		*m_head = NULL;
d4409 1
a4409 1
	sc->tx_mbuf_ptr[chain_prod] = m0;
d4425 1
a4425 1
	return (rc);
d4471 1
a4471 1
		if (bnx_tx_encap(sc, &m_head)) {
@


1.72
log
@switch to MCLGETI.

this conversion is the easiest ive done so far. the mbuf allocation wrapper
in the driver already had code to handle a failing cluster allocator as
part of a test harness, now we test that code all the time with MCLGETI.

ok kettenis@@
tested by phessler@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.70 2008/11/09 15:08:26 naddy Exp $	*/
d856 1
a856 1
        m_clsetwms(ifp, MCLBYTES, 2, USABLE_RX_BD);
d1864 1
a1864 1
	       	if ((len32 > 4) || !align_start) {
d4286 3
a4288 3
	       BNX_MISC_ENABLE_SET_BITS_RX_V2P_ENABLE |
	       BNX_MISC_ENABLE_SET_BITS_RX_DMA_ENABLE |
	       BNX_MISC_ENABLE_SET_BITS_COMPLETION_ENABLE);
d4728 1
a4728 1
            BNX_PCICFG_INT_ACK_CMD_MASK_INT);
@


1.71
log
@Eliminate the redundant bits of code for MTU and multicast handling
from the individual drivers now that ether_ioctl() handles this.

Shrinks the i386 kernels by..
RAMDISK - 2176 bytes
RAMDISKB - 1504 bytes
RAMDISKC - 736 bytes

Tested by naddy@@/okan@@/sthen@@/brad@@/todd@@/jmc@@ and lots of users.
Build tested on almost all archs by todd@@/brad@@

ok naddy@@
@
text
@d373 1
a373 2
int	bnx_get_buf(struct bnx_softc *, struct mbuf *, u_int16_t *,
	    u_int16_t *, u_int32_t *);
d856 1
d3254 1
a3254 1
bnx_get_buf(struct bnx_softc *sc, struct mbuf *m, u_int16_t *prod,
d3258 1
a3258 1
	struct mbuf 		*m_new = NULL;
d3260 1
a3260 1
	int			i, rc = 0;
d3279 10
a3288 55
	/* Check whether this is a new mbuf allocation. */
	if (m == NULL) {
		/* Simulate an mbuf allocation failure. */
		DBRUNIF(DB_RANDOMTRUE(bnx_debug_mbuf_allocation_failure),
			sc->mbuf_alloc_failed++;
			sc->mbuf_sim_alloc_failed++;
			rc = ENOBUFS;
			goto bnx_get_buf_exit);

		/* This is a new mbuf allocation. */
		MGETHDR(m_new, M_DONTWAIT, MT_DATA);
		if (m_new == NULL) {
			DBPRINT(sc, BNX_WARN,
			    "%s(%d): RX mbuf header allocation failed!\n", 
			    __FILE__, __LINE__);

			sc->mbuf_alloc_failed++;

			rc = ENOBUFS;
			goto bnx_get_buf_exit;
		}

		DBRUNIF(1, sc->rx_mbuf_alloc++);

		/* Simulate an mbuf cluster allocation failure. */
		DBRUNIF(DB_RANDOMTRUE(bnx_debug_mbuf_allocation_failure),
			m_freem(m_new);
			sc->rx_mbuf_alloc--;
			sc->mbuf_alloc_failed++; 
			sc->mbuf_sim_alloc_failed++;
			rc = ENOBUFS;
			goto bnx_get_buf_exit);

		/* Attach a cluster to the mbuf. */
		MCLGET(m_new, M_DONTWAIT);
		if (!(m_new->m_flags & M_EXT)) {
			DBPRINT(sc, BNX_WARN,
			    "%s(%d): RX mbuf chain allocation failed!\n", 
			    __FILE__, __LINE__);
			
			m_freem(m_new);
			DBRUNIF(1, sc->rx_mbuf_alloc--);

			sc->mbuf_alloc_failed++;
			rc = ENOBUFS;
			goto bnx_get_buf_exit;
		}
			
		/* Initialize the mbuf cluster. */
		m_new->m_len = m_new->m_pkthdr.len = sc->mbuf_alloc_size;
	} else {
		/* Reuse an existing mbuf. */
		m_new = m;
		m_new->m_len = m_new->m_pkthdr.len = sc->mbuf_alloc_size;
		m_new->m_data = m_new->m_ext.ext_buf;
d3290 2
d3295 4
a3299 10
	if (bus_dmamap_load_mbuf(sc->bnx_dmatag, map, m_new, BUS_DMA_NOWAIT)) {
		BNX_PRINTF(sc, "%s(%d): Error mapping mbuf into RX chain!\n",
		    __FILE__, __LINE__);

		m_freem(m_new);
		DBRUNIF(1, sc->rx_mbuf_alloc--);

		rc = ENOBUFS;
		goto bnx_get_buf_exit;
	}
d3304 2
a3305 6

		m_freem(m_new);
		DBRUNIF(1, sc->rx_mbuf_alloc--);

		rc = EFBIG;
		goto bnx_get_buf_exit;
d3352 1
a3352 1
	sc->rx_mbuf_ptr[*chain_prod] = m_new;
d3360 1
a3360 9
	DBPRINT(sc, BNX_VERBOSE_RECV, "%s(exit): prod = 0x%04X, chain_prod "
	    "= 0x%04X, prod_bseq = 0x%08X\n", __FUNCTION__, *prod,
	    *chain_prod, *prod_bseq);

bnx_get_buf_exit:
	DBPRINT(sc, (BNX_VERBOSE_RESET | BNX_VERBOSE_RECV), "Exiting %s()\n", 
	    __FUNCTION__);

	return(rc);
d3508 1
a3508 1
		if (bnx_get_buf(sc, NULL, &prod, &chain_prod, &prod_bseq)) {
@


1.70
log
@Introduce bpf_mtap_ether(), which for the benefit of bpf listeners
creates the VLAN encapsulation from the tag stored in the mbuf
header.  Idea from FreeBSD, input from claudio@@ and canacar@@.

Switch all hardware VLAN enabled drivers to the new function.

ok claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.69 2008/10/19 23:16:38 brad Exp $	*/
d4589 1
a4590 1
	struct ifaddr		*ifa = (struct ifaddr *)data;
a4606 7
	case SIOCSIFMTU:
		if (ifr->ifr_mtu < ETHERMIN || ifr->ifr_mtu > ifp->if_hardmtu)
			error = EINVAL;
		else if (ifp->if_mtu != ifr->ifr_mtu)
			ifp->if_mtu = ifr->ifr_mtu;
		break;

a4623 13
	case SIOCADDMULTI:
	case SIOCDELMULTI:
		error = (command == SIOCADDMULTI)
			? ether_addmulti(ifr, &sc->arpcom)
			: ether_delmulti(ifr, &sc->arpcom);

		if (error == ENETRESET) {
			if (ifp->if_flags & IFF_RUNNING)
				bnx_set_rx_mode(sc);
			error = 0;
		}
		break;

d4634 6
@


1.69
log
@Re-add support for RX VLAN tag stripping.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.68 2008/10/16 19:18:03 naddy Exp $	*/
d4050 2
a4051 1
				bpf_mtap(ifp->if_bpf, m, BPF_DIRECTION_IN);
d4550 1
a4550 1
			bpf_mtap(ifp->if_bpf, m_head, BPF_DIRECTION_OUT);
@


1.68
log
@Switch the existing TX VLAN hardware support over to having the
tag in the header.  Convert TX tagging in the drivers.

Help and ok brad@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.67 2008/10/16 19:16:21 naddy Exp $	*/
d4839 2
a4840 1
	if (!(sc->bnx_flags & BNX_MFW_ENABLE_FLAG))
@


1.67
log
@Convert RX tag stripping to storing the tag in the mbuf header and
enable RX tag stripping for re(4).

ok brad@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.66 2008/10/02 20:21:14 brad Exp $	*/
d4391 1
a4391 3
	if ((m0->m_flags & (M_PROTO1|M_PKTHDR)) == (M_PROTO1|M_PKTHDR) &&
	    m0->m_pkthdr.rcvif != NULL) {
		struct ifvlan *ifv = m0->m_pkthdr.rcvif->if_softc;
d4393 1
a4393 1
		vlan_tag = ifv->ifv_tag;
@


1.66
log
@First step towards cleaning up the Ethernet driver ioctl handling.
Move calling ether_ioctl() from the top of the ioctl function, which
at the moment does absolutely nothing, to the default switch case.
Thus allowing drivers to define their own ioctl handlers and then
falling back on ether_ioctl(). The only functional change this results
in at the moment is having all Ethernet drivers returning the proper
errno of ENOTTY instead of EINVAL/ENXIO when encountering unknown
ioctl's.

Shrinks the i386 kernels by..
RAMDISK - 1024 bytes
RAMDISKB -  1120 bytes
RAMDISKC - 832 bytes

Tested by martin@@/jsing@@/todd@@/brad@@
Build tested on almost all archs by todd@@/brad@@

ok jsing@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.65 2008/09/10 14:01:22 blambert Exp $	*/
a4016 2
				struct ether_vlan_header vh;

d4022 3
a4024 13
				if (m->m_pkthdr.len < ETHER_HDR_LEN) {
					m_freem(m);
					goto bnx_rx_int_next_rx;
				}
				m_copydata(m, 0, ETHER_HDR_LEN, (caddr_t)&vh);
				vh.evl_proto = vh.evl_encap_proto;
				vh.evl_tag = htons(l2fhdr->l2_fhdr_vlan_tag);
				vh.evl_encap_proto = htons(ETHERTYPE_VLAN);
				m_adj(m, ETHER_HDR_LEN);
				M_PREPEND(m, sizeof(vh), M_DONTWAIT);
				if (m == NULL)
					goto bnx_rx_int_next_rx;
				m_copyback(m, 0, sizeof(vh), &vh);
@


1.65
log
@Convert timeout_add() calls using multiples of hz to timeout_add_sec()

Really just the low-hanging fruit of (hopefully) forthcoming timeout
conversions.

ok art@@, krw@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.64 2008/06/24 23:02:42 brad Exp $	*/
a4608 5
	if ((error = ether_ioctl(ifp, &sc->arpcom, command, data)) > 0) {
		splx(s);
		return (error);
	}

d4666 1
a4666 2
		error = ENOTTY;
		break;
a4669 1

@


1.64
log
@Fixed a problem that would cause errors (especially when in low memory
systems) because the RX chain was corrupted when an mbuf was mapped to
an unexpected number of buffers.

From davidch@@FreeBSD
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.63 2008/06/13 21:40:21 brad Exp $	*/
d4330 1
a4330 1
	timeout_add(&sc->bnx_timeout, hz);
d5143 1
a5143 1
	timeout_add(&sc->bnx_timeout, hz);
@


1.63
log
@fix compilation with BNX_DEBUG.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.62 2008/06/13 07:40:30 brad Exp $	*/
d377 1
d2933 1
a2933 1
	/* Free the RX lists. */
d3279 1
d3281 1
a3282 2
		    BNX_PRINTF(sc, "Simulating mbuf allocation failure.\n");

d3284 1
d3295 1
a3295 1
			DBRUNIF(1, sc->mbuf_alloc_failed++);
d3302 11
a3319 1

a3320 1
			DBRUNIF(1, sc->mbuf_alloc_failed++);
d3322 1
d3327 1
d3330 1
d3344 1
d3346 9
d3357 1
a3357 1
		rc = ENOBUFS;
d3361 4
a3364 4
	/* Watch for overflow. */
	DBRUNIF((sc->free_rx_bd > USABLE_RX_BD),
	    printf("%s: Too many free rx_bd (0x%04X > 0x%04X)!\n", 
	    sc->free_rx_bd, (u_int16_t) USABLE_RX_BD));
d3369 1
a3369 1
	DBRUNIF((sc->free_rx_bd == 0), sc->rx_empty_count++);
d3530 2
d3541 54
d3605 1
a3605 2
	u_int16_t		prod, chain_prod;
	u_int32_t		prod_bseq, val, addr;
d3649 2
a3650 16
	/* Allocate mbuf clusters for the rx_bd chain. */
	prod = prod_bseq = 0;
	while (prod < TOTAL_RX_BD) {
		chain_prod = RX_CHAIN_IDX(prod);
		if (bnx_get_buf(sc, NULL, &prod, &chain_prod, &prod_bseq)) {
			BNX_PRINTF(sc, "Error filling RX chain: rx_bd[0x%04X]!\n",
				chain_prod);
			rc = ENOBUFS;
			break;
		}
		prod = NEXT_RX_BD(prod);
	}

	/* Save the RX chain producer index. */
	sc->rx_prod = prod;
	sc->rx_prod_bseq = prod_bseq;
a3656 4
	/* Tell the chip about the waiting rx_bd's. */
	REG_WR16(sc, MB_RX_CID_ADDR + BNX_L2CTX_HOST_BDIDX, sc->rx_prod);
	REG_WR(sc, MB_RX_CID_ADDR + BNX_L2CTX_HOST_BSEQ, sc->rx_prod_bseq);

d3674 3
d3680 4
d3698 4
d3706 2
d3856 1
a3856 1
	DBRUNIF((sc->free_rx_bd == 0), sc->rx_empty_count++);
d3868 3
d3906 1
a3906 1
			/* Remove the mbuf from the driver's chain. */
d3946 1
d3950 2
a3951 30
				/* Reuse the mbuf for a new frame. */
				if (bnx_get_buf(sc, m, &sw_prod,
				    &sw_chain_prod, &sw_prod_bseq)) {
					DBRUNIF(1, bnx_breakpoint(sc));
					panic("%s: Can't reuse RX mbuf!\n",
					    sc->bnx_dev.dv_xname);
				}
				goto bnx_rx_int_next_rx;
			}

			/* 
			 * Get a new mbuf for the rx_bd.   If no new
			 * mbufs are available then reuse the current mbuf,
			 * log an ierror on the interface, and generate
			 * an error in the system log.
			 */
			if (bnx_get_buf(sc, NULL, &sw_prod, &sw_chain_prod,
			    &sw_prod_bseq)) {
				DBRUN(BNX_WARN, BNX_PRINTF(sc, "Failed to allocate "
					"new mbuf, incoming frame dropped!\n"));

				ifp->if_ierrors++;

				/* Try and reuse the exisitng mbuf. */
				if (bnx_get_buf(sc, m, &sw_prod,
				    &sw_chain_prod, &sw_prod_bseq)) {
					DBRUNIF(1, bnx_breakpoint(sc));
					panic("%s: Double mbuf allocation "
					    "failure!", sc->bnx_dev.dv_xname);
				}
d4043 13
a4064 2
			/* Pass the mbuf off to the upper layers. */
			ifp->if_ipackets++;
d4070 1
a4070 2
bnx_rx_int_next_rx:
			sw_prod = NEXT_RX_BD(sw_prod);
a4072 2
		sw_cons = NEXT_RX_BD(sw_cons);

d4089 4
a4098 7
	sc->rx_cons = sw_cons;
	sc->rx_prod = sw_prod;
	sc->rx_prod_bseq = sw_prod_bseq;

	REG_WR16(sc, MB_RX_CID_ADDR + BNX_L2CTX_HOST_BDIDX, sc->rx_prod);
	REG_WR(sc, MB_RX_CID_ADDR + BNX_L2CTX_HOST_BSEQ, sc->rx_prod_bseq);

d4423 1
d4694 7
d5781 12
d5815 3
a5817 2
	    "         0x%08X - (sc->txmbuf_alloc) tx mbufs allocated\n",
	    sc->tx_mbuf_alloc);
d5820 3
a5822 12
	    "         0x%08X - (sc->rx_mbuf_alloc) rx mbufs allocated\n",
	    sc->rx_mbuf_alloc);

	BNX_PRINTF(sc, "         0x%08X - (sc->used_tx_bd) used tx_bd's\n",
	    sc->used_tx_bd);

	BNX_PRINTF(sc, "0x%08X/%08X - (sc->tx_hi_watermark) tx hi watermark\n",
	    sc->tx_hi_watermark, sc->max_tx_bd);

	BNX_PRINTF(sc,
	    "         0x%08X - (sc->mbuf_alloc_failed) failed mbuf alloc\n",
	    sc->mbuf_alloc_failed);
d5898 1
a5898 1
		bnx_dump_rx_mbuf_chain(sc, 0, USABLE_RX_BD);
d5901 1
a5901 1
		bnx_dump_rx_chain(sc, 0, USABLE_RX_BD);
@


1.62
log
@Remove slack space for RX/TX chains since it only covers sloppy coding.

From davidch @@ FreeBSD
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.61 2008/06/08 16:20:27 reyk Exp $	*/
d4386 1
a4386 1
		__FUNCTION__, *prod, chain_prod, prod_bseq);
d4414 2
a4415 1
	DBRUN(BNX_INFO_SEND, bnx_dump_tx_chain(sc, debug_prod, nseg));
d4441 1
a4441 1
	    map_arg.maxsegs));
@


1.61
log
@don't declare foo_driver_version[] strings and turn them into defines,
nothing uses them and it saves a few bytes in the kernel.

ok claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.60 2008/05/29 05:36:48 brad Exp $	*/
d2320 2
a2321 4
		    MCLBYTES * BNX_MAX_SEGMENTS,
		    USABLE_TX_BD - BNX_TX_SLACK_SPACE,
		    MCLBYTES, 0, BUS_DMA_NOWAIT,
		    &sc->tx_mbuf_map[i])) {
d3342 1
d3345 1
d3420 1
d3422 1
d3534 2
a3535 1
	sc->free_rx_bd = BNX_RX_SLACK_SPACE;
d3537 1
d3572 1
a3572 1
	while (prod < BNX_RX_SLACK_SPACE) {
d3779 1
d3782 1
d4154 1
a4154 1
	if ((sc->used_tx_bd + BNX_TX_SLACK_SPACE) < USABLE_TX_BD) {
d4156 3
a4158 2
		    printf("%s: TX chain is open for business! Used "
		    "tx_bd = %d\n", sc->used_tx_bd));
d4371 2
a4372 7
	/*
	 * The chip seems to require that at least 16 descriptors be kept
	 * empty at all times.  Make sure we honor that.
	 * XXX Would it be faster to assume worst case scenario for
	 * map->dm_nsegs and do this calculation higher up?
	 */
	if (map->dm_nsegs > (USABLE_TX_BD - sc->used_tx_bd - BNX_TX_SLACK_SPACE)) {
d4433 1
d4436 1
a4436 1

d4479 1
a4479 2
	 * Keep adding entries while there is space in the ring.  We keep
	 * BNX_TX_SLACK_SPACE entries unused at all times.
d4481 1
a4481 1
	while (sc->used_tx_bd < USABLE_TX_BD - BNX_TX_SLACK_SPACE) {
d5736 1
a5736 1
	    sc->rx_low_watermark, (u_int32_t) USABLE_RX_BD);
d5750 1
a5750 1
	    sc->tx_hi_watermark, (u_int32_t) USABLE_TX_BD);
@


1.60
log
@- Add a debug message to mention when a 2.5Gb adapter is found.
- Change invalid PHY address debug message in bnx_miibus_write_reg()
from warn level to verbose.
- Add two new softc fields and store the shared and port hw config
data.

From FreeBSD

ok dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.59 2008/05/23 08:49:27 brad Exp $	*/
d149 2
a150 1
char bnx_driver_version[] = "v0.9.6";
@


1.59
log
@Simplify the combination use of pci_mapreg_type()/pci_mapreg_map() as
suggested by dlg@@ awhile ago.

ok dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.58 2008/02/28 02:02:43 brad Exp $	*/
d41 1
d43 1
d47 1
a47 1
 *   BCM5706S A0, A1, A2, A3
d49 1
a49 1
 *   BCM5708S A0, B0, B1, B2
d822 1
a822 1
			if (val & BNX_SHARED_HW_CFG_PHY_2_5G)
d824 2
d829 9
d1144 1
a1144 1
		DBPRINT(sc, BNX_WARN, "Invalid PHY address %d for PHY write!\n",
@


1.58
log
@Add initial bits for fiber support with the BCM5706/BCM5708 chipsets.

Tested with copper adapters by brad@@, johan@@ and Jung <moorang at gmail dot com>

ok dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.57 2008/02/22 22:25:27 kettenis Exp $	*/
d630 2
a631 8
	switch (memtype) {
	case PCI_MAPREG_TYPE_MEM | PCI_MAPREG_MEM_TYPE_32BIT:
	case PCI_MAPREG_TYPE_MEM | PCI_MAPREG_MEM_TYPE_64BIT:
		if (pci_mapreg_map(pa, BNX_PCI_BAR0,
		    memtype, 0, &sc->bnx_btag, &sc->bnx_bhandle,
		    NULL, &sc->bnx_size, 0) == 0)
			break;
	default:
@


1.57
log
@Avoid unaligned PCI config space access.

ok brad@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.56 2008/02/17 19:34:40 brad Exp $	*/
d41 1
a41 1
 *   BCM5708C B1
a660 5
	if (BNX_CHIP_BOND_ID(sc) & BNX_CHIP_BOND_ID_SERDES_BIT) {
		printf(": SerDes controllers are not supported!\n");
		goto bnx_attach_fail;
	}

d747 1
a747 1
	int error;
d812 4
a815 4
	 * The copper based NetXtreme II controllers
	 * use an integrated PHY at address 1 while
	 * the SerDes controllers use a PHY at
	 * address 2.
d822 1
a822 1
		if (BNX_CHIP_NUM(sc) == BNX_CHIP_NUM_5708) {
a830 5
	if (sc->bnx_phy_flags & BNX_PHY_SERDES_FLAG) {
		printf(": SerDes is not supported by this driver!\n");
		goto bnx_attach_fail;
	}

a845 4
        if (sc->bnx_phy_flags & BNX_PHY_2_5G_CAPABLE_FLAG)
                ifp->if_baudrate = IF_Mbps(2500);
        else
                ifp->if_baudrate = IF_Gbps(1);
d874 2
d877 1
a877 1
	    MII_PHY_ANY, MII_OFFSET_ANY, 0);
d940 2
a941 6
	if (sc->bnx_phy_flags & BNX_PHY_SERDES_FLAG) {
		ifmedia_removeall(&sc->bnx_ifmedia);
	} else {
		bus_generic_detach(dev);
		device_delete_child(dev, sc->bnx_mii);
	}
d1201 1
d1203 4
a1206 1
	BNX_CLRBIT(sc, BNX_EMAC_MODE, BNX_EMAC_MODE_PORT);
d1208 27
a1234 7
	/* Set MII or GMII inerface based on the speed negotiated by the PHY. */
	if (IFM_SUBTYPE(mii->mii_media_active) == IFM_1000_T) {
		DBPRINT(sc, BNX_INFO, "Setting GMII interface.\n");
		BNX_SETBIT(sc, BNX_EMAC_MODE, BNX_EMAC_MODE_PORT_GMII);
	} else {
		DBPRINT(sc, BNX_INFO, "Setting MII interface.\n");
		BNX_SETBIT(sc, BNX_EMAC_MODE, BNX_EMAC_MODE_PORT_MII);
d1240 4
a1243 1
	if ((mii->mii_media_active & IFM_GMASK) == IFM_FDX) {
d1245 2
a1246 5
		BNX_CLRBIT(sc, BNX_EMAC_MODE, BNX_EMAC_MODE_HALF_DUPLEX);
	} else {
		DBPRINT(sc, BNX_INFO, "Setting Half-Duplex interface.\n");
		BNX_SETBIT(sc, BNX_EMAC_MODE, BNX_EMAC_MODE_HALF_DUPLEX);
	}
d2906 3
a2908 1
	struct mii_data		*mii = NULL;
a2911 2
	mii = &sc->bnx_mii;

d2932 15
a3640 1
	struct ifmedia		*ifm;
a3643 3
	ifm = &sc->bnx_ifmedia;

	/* DRC - ToDo: Add SerDes support. */
a3675 2
	/* DRC - ToDo: Add SerDes support. */

d4537 1
a4537 1
	struct mii_data		*mii;
d4600 1
a4600 8
		if (sc->bnx_phy_flags & BNX_PHY_SERDES_FLAG)
			error = ifmedia_ioctl(ifp, ifr,
			    &sc->bnx_ifmedia, command);
		else {
			mii = &sc->bnx_mii;
			error = ifmedia_ioctl(ifp, ifr,
			    &mii->mii_media, command);
		}
a5073 2

	/* DRC - ToDo: Add SerDes support and check SerDes link here. */
@


1.56
log
@Remove the check for non-production bnx(4) chipsets. These chipsets are
not officially "supported" and could have errata which the driver does
not workaround but they should more or less work.

Tested by marco@@ with a BCM5708 B0 chipset.

ok marco@@ dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.55 2007/11/25 19:16:00 dlg Exp $	*/
a3054 2
		u_int16_t val;

d3057 1
a3057 1
		    val & ~0x2);
@


1.55
log
@IF_Gbps(2.5) is wrong.

ok claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.54 2007/08/28 18:34:38 deraadt Exp $	*/
a43 2
 * (These are not "Production" versions of the controller.)
 * 
d47 1
a47 1
 *   BCM5708S A0, B0, B1
a659 12

	/* Weed out any non-production controller revisions. */
	switch(BNX_CHIP_ID(sc)) {
	case BNX_CHIP_ID_5706_A0:
	case BNX_CHIP_ID_5706_A1:
	case BNX_CHIP_ID_5708_A0:
	case BNX_CHIP_ID_5708_B0:
		printf(": unsupported controller revision (%c%d)!\n",
		    (((pci_conf_read(pa->pa_pc, pa->pa_tag, 0x08) & 0xf0) >> 4)
		    + 'A'), (pci_conf_read(pa->pa_pc, pa->pa_tag, 0x08) & 0xf));
		goto bnx_attach_fail;
	}
@


1.54
log
@unify firmware load failure messages; ok mglocker
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.53 2007/07/04 00:20:22 krw Exp $	*/
d871 1
a871 1
                ifp->if_baudrate = IF_Gbps(2.5);
@


1.53
log
@Revert r1.42 of if_bnx.c, "Enable IPv4 transmit TCP/UDP checksum
offload", and associated man page change. To use IPv4 transmit TCP/UDP
checksum offloading you must again define BNX_CSUM.

As requested by mbalmer@@ via deraadt@@ on suggestion of reyk@@ in
response to PR #5437.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.52 2007/05/22 22:08:57 reyk Exp $	*/
d769 1
a769 1
		printf("%s: could not read firmware (error=%d)\n",
@


1.52
log
@Add the BCM5709 PCI device Id. It is disabled for now since we do not
support SerDes-based (1000base-SX fibre) bnx(4) devices yet. The
reason is simple - we do not have any fibre bnx(4) to test and port
the SerDes changes from the other bnx drivers.

From brad found in the Linux driver
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.51 2007/05/22 16:51:34 jasper Exp $	*/
d879 5
a883 2
	ifp->if_capabilities = IFCAP_VLAN_MTU | IFCAP_CSUM_TCPv4 |
			       IFCAP_CSUM_UDPv4;
@


1.51
log
@adress -> address

from brad
ok claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.50 2007/05/22 04:22:57 ray Exp $	*/
d194 2
a195 1
	{ PCI_VENDOR_BROADCOM, PCI_PRODUCT_BROADCOM_BCM5709 }
@


1.50
log
@Use BNX_PRINTF instead of printf with missing argument.

OK reyk@@, earlier version OK tedu@@, dlg@@, and miod@@.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.49 2007/05/21 10:05:03 reyk Exp $	*/
d1459 1
a1459 1
	 * Clear the DONE bit separately, set the NVRAM adress to erase,
@


1.49
log
@fix bnx vlan tagging in the rx path; do not attach the vlan tag twice
if the firmware has been told to keep it and copy the tag in network
byte order in the other case.

ok mcbride@@ dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.48 2007/03/05 11:13:09 reyk Exp $	*/
d4200 1
a4200 1
		printf("%s: Controller reset failed!\n");
d4205 1
a4205 1
		printf("%s: Controller initialization failed!\n");
d4210 1
a4210 1
		printf("%s: Block initialization failed!\n");
d4705 1
a4705 1
			printf("%s: Fatal attention detected: 0x%08X\n", 
@


1.48
log
@remove jumbo frame support by replacing MEXTALLOC with MCLGET, and
simplify the VLAN code.

this will close PR 5356 (system panics under high load).

From claudio@@ who is currently not around to commit this fix

tested and ok by mcbride@@, reyk@@, todd@@, Paul Hirsch, and brad
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.47 2007/03/03 11:17:48 reyk Exp $	*/
d3945 2
a3946 1
			if (status & L2_FHDR_STATUS_L2_VLAN_TAG) {
d3961 1
a3961 1
				vh.evl_tag = l2fhdr->l2_fhdr_vlan_tag;
@


1.47
log
@instead of establishing the interrupt in the mounthook, move it back
to the attach function and set a flag in the mounthook to start
accepting interrupts (there are possible problems with establishing
interrupts after the ioapics are enabled in i386 GENERIC.MP).

also suggested by kettenis
tested by mcbride, me, and some others
ok dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.46 2007/03/03 03:46:12 todd Exp $	*/
a872 1
	ifp->if_hardmtu = BNX_MAX_JUMBO_MTU;
d3283 1
a3283 1
		MEXTMALLOC(m_new, sc->mbuf_alloc_size, M_DONTWAIT);
d3963 2
a3964 5
				if ((m = m_prepend(m, sizeof(vh), M_DONTWAIT)) == NULL)
					goto bnx_rx_int_next_rx;
				m->m_pkthdr.len += sizeof(vh);
				if (m->m_len < sizeof(vh) &&
				    (m = m_pullup(m, sizeof(vh))) == NULL)
d4218 1
a4218 1
	ether_mtu = BNX_MAX_JUMBO_ETHER_MTU_VLAN;
@


1.46
log
@Replacing some spaces with tabs and some typo fixes
from brad@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.45 2007/03/02 14:08:48 reyk Exp $	*/
d741 9
a762 1
	pci_chipset_tag_t	pc = pa->pa_pc;
d925 2
a926 8
	/* Hookup IRQ last. */
	sc->bnx_intrhand = pci_intr_establish(pc, sc->bnx_ih, IPL_NET,
	    bnx_intr, sc, sc->bnx_dev.dv_xname);
	if (sc->bnx_intrhand == NULL) {
		printf("%s: couldn't establish interrupt\n",
		    sc->bnx_dev.dv_xname);
		goto bnx_attach_fail;
	}
d4661 3
@


1.45
log
@oops, this is $OpenBSD$
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d3244 1
a3244 1
	u_int16_t debug_chain_prod =	*chain_prod;
d3246 1
a3246 1
	u_int16_t first_chain_prod;
d3357 3
a3359 3
	 * Save the mbuf, ajust the map pointer (swap map for first and
	 * last rx_bd entry to that rx_mbuf_ptr and rx_mbuf_map matches)
	 * and update counter.
@


1.44
log
@- remove the code to bring down the PHY in bnx_stop(), it's wrong
  (ifm_data isn't updated) and lead to a panic in mii_phy_setmedia(),
  or reading past the end mii_media_table[].
- make sure the dma_map matches the mbuf in the rx structures. We would
  sync/unload the wrong map, leading to a DIAGNOSTIC panic, or eventually
  leaking memory when bounce buffers are needed.

From NetBSD

ok marco@@, brad@@
@
text
@d1 1
a1 1
/*	$NetBSD: if_bnx.c,v 1.2 2007/02/15 19:24:47 bouyer Exp $	*/
@


1.43
log
@Allow the bnx(4) driver to make use of all of the available hardware
multicast hash slots. The bnx(4) hardware supports 8 slots instead of
4 like the bge(4) hardware.

From Mike Karels via FreeBSD

Tested by Brad, biorn@@ and Johan M:son Lindman
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.42 2007/01/27 12:38:59 krw Exp $	*/
a2906 1
	struct ifmedia_entry	*ifm;
a2907 1
	int			mtmp, itmp;
a2932 20
	/*
	 * Isolate/power down the PHY, but leave the media selection
	 * unchanged so that things will be put back to normal when
	 * we bring the interface back up.
	 */

	itmp = ifp->if_flags;
	ifp->if_flags |= IFF_UP;
	/*
	 * If we are called from bnx_detach(), mii is already NULL.
	 */
	if (mii != NULL) {
		ifm = mii->mii_media.ifm_cur;
		mtmp = ifm->ifm_media;
		ifm->ifm_media = IFM_ETHER|IFM_NONE;
		mii_mediachg(mii);
		ifm->ifm_media = mtmp;
	}

	ifp->if_flags = itmp;
d3246 1
d3306 1
d3356 5
a3360 1
	/* Save the mbuf and update our counter. */
d3362 2
@


1.42
log
@Enable transmit TCP/UDP checksum offload.

From Brad, tested by Brad, biorn@@ and Johan M:son Lindman.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.41 2007/01/21 01:08:03 mcbride Exp $	*/
d4787 1
a4787 1
	u_int32_t		hashes[4] = { 0, 0, 0, 0 };
d4834 2
a4835 2
			    0x7F;
			hashes[(h & 0x60) >> 5] |= 1 << (h & 0x1F);
d4839 1
a4839 1
		for (i = 0; i < 4; i++)
@


1.41
log
@Remove bogus check for old firmware.

Identical fixes from myself and brad@@, also reported by chefren@@pi.net.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.40 2007/01/20 00:36:07 dlg Exp $	*/
d871 2
a872 5
	ifp->if_capabilities = IFCAP_VLAN_MTU;

#ifdef BNX_CSUM
	ifp->if_capabilities |= IFCAP_CSUM_TCPv4 | IFCAP_CSUM_UDPv4;
#endif
@


1.40
log
@move the interrupt establishment till after everything in the softc is
set up and allocated (which happens in a mountroothook). this prevents an
early call to the interrupt handler from causing a null deref when trying
to look into the unallocated regions.

found by mcbride when ciss and bnx were sharing an interrupt. mounting
root caused interrupts before the bnx was properly set up.

"commit your fix" mcbride@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.39 2007/01/19 18:35:50 mcbride Exp $	*/
a452 1
fail:
a463 5
	if (bnx_COM_b06FwTextAddr > size) {
		printf("%s: probably trying to use old firmware\n",
		    sc->bnx_dev.dv_xname);
		goto fail;
	}
@


1.39
log
@bnx_init() takes a pointer to sc, not ifp.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.38 2007/01/10 18:09:26 deraadt Exp $	*/
a629 1
	pci_intr_handle_t	ih;
d649 1
a649 1
	if (pci_intr_map(pa, &ih)) {
d653 1
a653 2

	intrstr = pci_intr_string(pc, ih);
a744 10
	/* Hookup IRQ last. */
	sc->bnx_intrhand = pci_intr_establish(pc, ih, IPL_NET, bnx_intr, sc,
	    sc->bnx_dev.dv_xname);
	if (sc->bnx_intrhand == NULL) {
		printf("%s: couldn't establish interrupt", sc->bnx_dev.dv_xname);
		if (intrstr != NULL)
			printf(" at %s", intrstr);
		printf("\n");
		goto bnx_attach_fail;
	}
d760 1
d925 9
@


1.38
log
@change firmware byte order to be same on all architectures
THIS MEANS YOU NEED TO UPDATE YOUR FIRMWARE FILE BEFORE BOOTING WITH
A NEW KERNEL
tested by marco, biorn
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.37 2006/12/24 12:54:13 reyk Exp $	*/
d4594 1
a4594 1
					bnx_init(ifp);
@


1.37
log
@use the right size when loading the rx/tx descriptor bus dma maps.

from the NetBSD port

tested by bion@@ and others from tech@@
ok marco@@ brad@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.36 2006/11/26 15:12:24 brad Exp $	*/
d144 2
d429 9
d453 1
d460 64
a523 59
	bnx_COM_b06FwReleaseMajor = hdr->bnx_COM_b06FwReleaseMajor;
	bnx_COM_b06FwReleaseMinor = hdr->bnx_COM_b06FwReleaseMinor;
	bnx_COM_b06FwReleaseFix = hdr->bnx_COM_b06FwReleaseFix;
	bnx_COM_b06FwStartAddr = hdr->bnx_COM_b06FwStartAddr;
	bnx_COM_b06FwTextAddr = hdr->bnx_COM_b06FwTextAddr;
	bnx_COM_b06FwTextLen = hdr->bnx_COM_b06FwTextLen;
	bnx_COM_b06FwDataAddr = hdr->bnx_COM_b06FwDataAddr;
	bnx_COM_b06FwDataLen = hdr->bnx_COM_b06FwDataLen;
	bnx_COM_b06FwRodataAddr = hdr->bnx_COM_b06FwRodataAddr;
	bnx_COM_b06FwRodataLen = hdr->bnx_COM_b06FwRodataLen;
	bnx_COM_b06FwBssAddr = hdr->bnx_COM_b06FwBssAddr;
	bnx_COM_b06FwBssLen = hdr->bnx_COM_b06FwBssLen;
	bnx_COM_b06FwSbssAddr = hdr->bnx_COM_b06FwSbssAddr;
	bnx_COM_b06FwSbssLen = hdr->bnx_COM_b06FwSbssLen;

	bnx_RXP_b06FwReleaseMajor = hdr->bnx_RXP_b06FwReleaseMajor;
	bnx_RXP_b06FwReleaseMinor = hdr->bnx_RXP_b06FwReleaseMinor;
	bnx_RXP_b06FwReleaseFix = hdr->bnx_RXP_b06FwReleaseFix;
	bnx_RXP_b06FwStartAddr = hdr->bnx_RXP_b06FwStartAddr;
	bnx_RXP_b06FwTextAddr = hdr->bnx_RXP_b06FwTextAddr;
	bnx_RXP_b06FwTextLen = hdr->bnx_RXP_b06FwTextLen;
	bnx_RXP_b06FwDataAddr = hdr->bnx_RXP_b06FwDataAddr;
	bnx_RXP_b06FwDataLen = hdr->bnx_RXP_b06FwDataLen;
	bnx_RXP_b06FwRodataAddr = hdr->bnx_RXP_b06FwRodataAddr;
	bnx_RXP_b06FwRodataLen = hdr->bnx_RXP_b06FwRodataLen;
	bnx_RXP_b06FwBssAddr = hdr->bnx_RXP_b06FwBssAddr;
	bnx_RXP_b06FwBssLen = hdr->bnx_RXP_b06FwBssLen;
	bnx_RXP_b06FwSbssAddr = hdr->bnx_RXP_b06FwSbssAddr;
	bnx_RXP_b06FwSbssLen = hdr->bnx_RXP_b06FwSbssLen;

	bnx_TPAT_b06FwReleaseMajor = hdr->bnx_TPAT_b06FwReleaseMajor;
	bnx_TPAT_b06FwReleaseMinor = hdr->bnx_TPAT_b06FwReleaseMinor;
	bnx_TPAT_b06FwReleaseFix = hdr->bnx_TPAT_b06FwReleaseFix;
	bnx_TPAT_b06FwStartAddr = hdr->bnx_TPAT_b06FwStartAddr;
	bnx_TPAT_b06FwTextAddr = hdr->bnx_TPAT_b06FwTextAddr;
	bnx_TPAT_b06FwTextLen = hdr->bnx_TPAT_b06FwTextLen;
	bnx_TPAT_b06FwDataAddr = hdr->bnx_TPAT_b06FwDataAddr;
	bnx_TPAT_b06FwDataLen = hdr->bnx_TPAT_b06FwDataLen;
	bnx_TPAT_b06FwRodataAddr = hdr->bnx_TPAT_b06FwRodataAddr;
	bnx_TPAT_b06FwRodataLen = hdr->bnx_TPAT_b06FwRodataLen;
	bnx_TPAT_b06FwBssAddr = hdr->bnx_TPAT_b06FwBssAddr;
	bnx_TPAT_b06FwBssLen = hdr->bnx_TPAT_b06FwBssLen;
	bnx_TPAT_b06FwSbssAddr = hdr->bnx_TPAT_b06FwSbssAddr;
	bnx_TPAT_b06FwSbssLen = hdr->bnx_TPAT_b06FwSbssLen;

	bnx_TXP_b06FwReleaseMajor = hdr->bnx_TXP_b06FwReleaseMajor;
	bnx_TXP_b06FwReleaseMinor = hdr->bnx_TXP_b06FwReleaseMinor;
	bnx_TXP_b06FwReleaseFix = hdr->bnx_TXP_b06FwReleaseFix;
	bnx_TXP_b06FwStartAddr = hdr->bnx_TXP_b06FwStartAddr;
	bnx_TXP_b06FwTextAddr = hdr->bnx_TXP_b06FwTextAddr;
	bnx_TXP_b06FwTextLen = hdr->bnx_TXP_b06FwTextLen;
	bnx_TXP_b06FwDataAddr = hdr->bnx_TXP_b06FwDataAddr;
	bnx_TXP_b06FwDataLen = hdr->bnx_TXP_b06FwDataLen;
	bnx_TXP_b06FwRodataAddr = hdr->bnx_TXP_b06FwRodataAddr;
	bnx_TXP_b06FwRodataLen = hdr->bnx_TXP_b06FwRodataLen;
	bnx_TXP_b06FwBssAddr = hdr->bnx_TXP_b06FwBssAddr;
	bnx_TXP_b06FwBssLen = hdr->bnx_TXP_b06FwBssLen;
	bnx_TXP_b06FwSbssAddr = hdr->bnx_TXP_b06FwSbssAddr;
	bnx_TXP_b06FwSbssLen = hdr->bnx_TXP_b06FwSbssLen;
d525 2
a526 2
	bnx_rv2p_proc1len = hdr->bnx_rv2p_proc1len;
	bnx_rv2p_proc2len = hdr->bnx_rv2p_proc2len;
d532 1
d535 1
d538 1
d541 1
d544 1
d548 1
d551 1
d554 1
d557 1
d560 1
d564 1
d567 1
d570 1
d573 1
d576 1
d580 1
d583 1
d586 1
d589 1
d592 1
d596 1
d599 1
@


1.36
log
@commented out entry for the BCM5709.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.35 2006/11/20 21:52:15 brad Exp $	*/
d2265 1
a2265 1
		    (caddr_t)sc->tx_bd_chain[i], BNX_STATS_BLK_SZ, NULL,
d2326 1
a2326 1
		    (caddr_t)sc->rx_bd_chain[i], BNX_STATS_BLK_SZ, NULL,
@


1.35
log
@only try to do HW checksum offload for TCP and UDP.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.34 2006/11/20 21:26:27 brad Exp $	*/
d191 3
@


1.34
log
@Due to an incorrect macro, it appears that the driver has always been
accidentally truncating off the VLAN tag field in the TX descriptor.  Fix
this by splitting up the vlan_tag and flags fields into separate fields,
and handling them appropriately.

From scottl@@FreeBSD
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.33 2006/11/19 17:35:46 brad Exp $	*/
d841 1
a841 1
	IFQ_SET_MAXLEN(&ifp->if_snd, USABLE_TX_BD);
d849 1
a849 2
	ifp->if_capabilities |= IFCAP_CSUM_IPv4|IFCAP_CSUM_TCPv4|
				IFCAP_CSUM_UDPv4;
a4300 1
#ifdef BNX_CSUM
a4308 1
#endif
@


1.33
log
@In bnx_start, check the used_tx_bd count rather than the descriptors
mbuf pointer to see if the transmit ring is full.  The mbuf pointer
is set only in the last descriptor of a multi-descriptor packet.
By relying on the mbuf pointers of the earlier descriptors, the
driver would sometimes overwrite a descriptor belonging to a
packet that wasn't completed yet.  Also, tx_chain_prod wasn't
updated inside the loop, causing the wrong descriptor to be checked
after the first iteration.  The upshot of all this was the loss of
some transmitted packets at medium to high packet rates.

In bnx_tx_encap, remove a couple of old statements that shuffled
around the tx_mbuf_map pointers.  These now correspond 1-to-1 with
the transmit descriptors, and they are not supposed to be changed.

Correct a couple of inaccurate comments.

From jdp@@FreeBSD
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.32 2006/10/26 00:05:07 brad Exp $	*/
a852 1
#ifdef BNX_VLAN
a855 1
#endif
d3943 1
a3943 1
				vh.evl_tag = l2fhdr->l2_fhdr_vlan_tag >> 16;
d4077 1
a4077 2
			DBRUNIF((!(txbd->tx_bd_vlan_tag_flags &
			    TX_BD_FLAGS_END)),
d4293 1
a4293 2
	u_int32_t		vlan_tag_flags = 0;
	u_int32_t		addr, prod_bseq;
d4298 1
d4306 1
a4306 1
			vlan_tag_flags |= TX_BD_FLAGS_IP_CKSUM;
d4309 1
a4309 1
			vlan_tag_flags |= TX_BD_FLAGS_TCP_UDP_CKSUM;
a4312 1
#ifdef BNX_VLAN
d4318 2
a4319 2
		vlan_tag_flags |= (TX_BD_FLAGS_VLAN_TAG |
		    (htons(ifv->ifv_tag) << 16));
a4321 1
#endif
d4375 2
a4376 1
		txbd->tx_bd_vlan_tag_flags = htole16(vlan_tag_flags);
d4379 1
a4379 1
			txbd->tx_bd_vlan_tag_flags |=htole16(TX_BD_FLAGS_START);
d4384 1
a4384 1
	txbd->tx_bd_vlan_tag_flags |= htole16(TX_BD_FLAGS_END);
d5189 1
a5189 1
		    "0x%08X, flags = 0x%08X\n", idx, 
d5191 2
a5192 1
		    txbd->tx_bd_mss_nbytes, txbd->tx_bd_vlan_tag_flags);
@


1.32
log
@do the minimal initialization of the firmware so that ASF always
works.

From ambrisko@@FreeBSD
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.31 2006/10/25 02:37:50 brad Exp $	*/
d4398 7
a4404 7
	 * Ensure that the map for this transmission
	 * is placed at the array index of the last
	 * descriptor in this chain.  This is done
	 * because a single map is used for all 
	 * segments of the mbuf and we don't want to
	 * delete the map before all of the segments
	 * have been freed.
a4405 3
	sc->tx_mbuf_map[TX_CHAIN_IDX(sc->tx_prod)] =
		sc->tx_mbuf_map[chain_prod];
	sc->tx_mbuf_map[chain_prod] = map;
d4417 1
a4417 1
	/* prod still points the last used tx_bd at this point. */
d4453 5
a4457 2
	/* Keep adding entries while there is space in the ring. */
	while (sc->tx_mbuf_ptr[tx_chain_prod] == NULL) {
@


1.31
log
@replace a few more instances of hand rolled code with the
LIST_FOREACH macro.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.30 2006/10/22 20:27:41 brad Exp $	*/
d381 1
d895 3
d2933 1
d4251 30
@


1.30
log
@now with the right revision of this diff which compiles. ok pedro, mglocker.

- Ensure that at least 16 TX descriptors are kept unused in the ring.
- Use more complete error handling for TX load problems.

From scottl@@FreeBSD
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.28 2006/10/21 22:18:39 brad Exp $	*/
d3622 1
a3622 2
		for (miisc = LIST_FIRST(&mii->mii_phys); miisc != NULL;
		    miisc = LIST_NEXT(miisc, mii_list))
@


1.29
log
@does not compile
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.27 2006/10/19 20:52:29 brad Exp $	*/
a4298 6
	/*
	 * XXX This should be handled higher up.
	 */
	if ((USABLE_TX_BD - sc->used_tx_bd - BNX_TX_SLACK_SPACE) <= 0)
		return (ENOBUFS);

d4304 2
d4309 11
d4423 1
a4423 1
	while (!IFQ_IS_EMPTY(&ifp->if_snd)) {
d4431 2
a4432 3
		 * don't have room, place the mbuf back at the
		 * head of the queue and set the OACTIVE flag
		 * to wait for the NIC to drain the chain.
@


1.28
log
@- Ensure that at least 16 TX descriptors are kept unused in the ring.
- Use more complete error handling for TX load problems.

From scottl@@FreeBSD
@
text
@d4299 6
a4309 2
		m_freem(m0);
		*m_head = NULL;
a4312 11
	/*
	 * The chip seems to require that at least 16 descriptors be kept
	 * empty at all times.  Make sure we honor that.
	 * XXX Would it be faster to assume worst case scenario for
	 * map->dm_nsegs and do this calculation higher up?
	 */
	if (map->dm_nsegs > (USABLE_TX_BD - sc->used_tx_bd - BNX_TX_SLACK_SPACE)) {
		bus_dmamap_unload(sc->tx_mbuf_tag, map);
		return (ENOBUFS);
	}

d4416 1
a4416 1
	while (sc->tx_mbuf_ptr[tx_chain_prod] == NULL) {
d4424 3
a4426 2
		 * don't have room, set the OACTIVE flag to wait
		 * for the NIC to drain the chain.
@


1.27
log
@make the exit label naming scheme match the current function names, removes
a FreeBSD-ism from the original driver.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.26 2006/10/19 20:36:20 brad Exp $	*/
a4298 6
	/*
	 * XXX This should be handled higher up.
	 */
	if ((USABLE_TX_BD - sc->used_tx_bd - BNX_TX_SLACK_SPACE) <= 0)
		return (ENOBUFS);

d4304 2
d4309 11
d4423 1
a4423 1
	while (!IFQ_IS_EMPTY(&ifp->if_snd)) {
d4431 2
a4432 3
		 * don't have room, place the mbuf back at the
		 * head of the queue and set the OACTIVE flag
		 * to wait for the NIC to drain the chain.
@


1.26
log
@Overhaul the transmit path:
- Eliminate the bnx_dmamap_arg structure.
- Refactor the loop that fills the buffer descriptor so that it can be done
with a single set of logic in a single loop instead of two sets of logic.
- Eliminate the need to cache and pass descriptor indexes between the start
loop and the encap function.
- Change the start loop to always check the ifnet sendq for more work.

From scottl@@FreeBSD
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.25 2006/10/14 21:19:09 brad Exp $	*/
d4185 1
a4185 1
		goto bnx_init_locked_exit;
d4190 1
a4190 1
		goto bnx_init_locked_exit;
d4195 1
a4195 1
		goto bnx_init_locked_exit;
d4241 1
a4241 1
bnx_init_locked_exit:
d4404 1
a4404 1
		goto bnx_start_locked_exit;
d4450 1
a4450 1
		goto bnx_start_locked_exit;
d4467 1
a4467 1
bnx_start_locked_exit:
d5023 1
a5023 1
		goto bnx_tick_locked_exit;
d5039 1
a5039 1
bnx_tick_locked_exit:
@


1.25
log
@- Simplify the arguments to bnx_tx_encap.
- Don't copy the bd_chain head pointers into temporary objects, they are
available globally.

From scottl@@FreeBSD
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.24 2006/10/04 00:23:04 deraadt Exp $	*/
a350 1
void	bnx_dma_map_tx_desc(void *, bus_dmamap_t);
d374 1
a374 1
int	bnx_tx_encap(struct bnx_softc *, struct mbuf *, u_int16_t *);
a2134 102
/* Map TX buffers into TX buffer descriptors.                               */
/*                                                                          */
/* Given a series of DMA memory containting an outgoing frame, map the      */
/* segments into the tx_bd structure used by the hardware.                  */
/*                                                                          */
/* Returns:                                                                 */
/*   Nothing.                                                               */
/****************************************************************************/
void
bnx_dma_map_tx_desc(void *arg, bus_dmamap_t map)
{
	struct bnx_dmamap_arg	*map_arg;
	struct bnx_softc	*sc;
	struct tx_bd		*txbd = NULL;
	int			i = 0, nseg;
	u_int16_t		prod, chain_prod;
	u_int32_t		prod_bseq, addr;
#ifdef BNX_DEBUG
	u_int16_t		debug_prod;
#endif

	map_arg = arg;
	sc = map_arg->sc;
	nseg = map->dm_nsegs;

	/* Signal error to caller if there's too many segments */
	if (nseg > map_arg->maxsegs) {
		DBPRINT(sc, BNX_WARN, "%s(): Mapped TX descriptors: max segs "
		    "= %d, " "actual segs = %d\n",
		    __FUNCTION__, map_arg->maxsegs, nseg);

		map_arg->maxsegs = 0;
		return;
	}

	/* prod points to an empty tx_bd at this point. */
	prod = map_arg->prod;
	chain_prod = map_arg->chain_prod;
	prod_bseq = map_arg->prod_bseq;

#ifdef BNX_DEBUG
	debug_prod = chain_prod;
#endif

	DBPRINT(sc, BNX_INFO_SEND, "%s(): Start: prod = 0x%04X, chain_prod "
	    "= %04X, " "prod_bseq = 0x%08X\n",
	    __FUNCTION__, prod, chain_prod, prod_bseq);

	/*
	 * Cycle through each mbuf segment that makes up
	 * the outgoing frame, gathering the mapping info
	 * for that segment and creating a tx_bd for the
	 * mbuf.
	 */

	txbd = &sc->tx_bd_chain[TX_PAGE(chain_prod)][TX_IDX(chain_prod)];

	/* Setup the first tx_bd for the first segment. */
	addr = (u_int32_t)(map->dm_segs[i].ds_addr);
	txbd->tx_bd_haddr_lo = htole32(addr);
	addr = (u_int32_t)((u_int64_t)map->dm_segs[i].ds_addr >> 32);
	txbd->tx_bd_haddr_hi = htole32(addr);
	txbd->tx_bd_mss_nbytes = htole16(map->dm_segs[i].ds_len);
	txbd->tx_bd_vlan_tag_flags = htole16(map_arg->tx_flags |
	    TX_BD_FLAGS_START);
	prod_bseq += map->dm_segs[i].ds_len;

	/* Setup any remaing segments. */
	for (i = 1; i < nseg; i++) {
		prod = NEXT_TX_BD(prod);
		chain_prod = TX_CHAIN_IDX(prod);

		txbd = 
		    &sc->tx_bd_chain[TX_PAGE(chain_prod)][TX_IDX(chain_prod)];

		addr = (u_int32_t)(map->dm_segs[i].ds_addr);
		txbd->tx_bd_haddr_lo = htole32(addr);
		addr = (u_int32_t)((u_int64_t)map->dm_segs[i].ds_addr >> 32);
		txbd->tx_bd_haddr_hi = htole32(addr);
		txbd->tx_bd_mss_nbytes = htole16(map->dm_segs[i].ds_len);
		txbd->tx_bd_vlan_tag_flags = htole16(map_arg->tx_flags);

		prod_bseq += map->dm_segs[i].ds_len;
	}

	/* Set the END flag on the last TX buffer descriptor. */
	txbd->tx_bd_vlan_tag_flags |= htole16(TX_BD_FLAGS_END);

	DBRUN(BNX_INFO_SEND, bnx_dump_tx_chain(sc, debug_prod, nseg));

	DBPRINT(sc, BNX_INFO_SEND, "%s(): End: prod = 0x%04X, chain_prod "
	    "= %04X, " "prod_bseq = 0x%08X\n",
	    __FUNCTION__, prod, chain_prod, prod_bseq);

	/* prod points to the last tx_bd at this point. */
	map_arg->maxsegs = nseg;
	map_arg->prod = prod;
	map_arg->chain_prod = chain_prod;
	map_arg->prod_bseq = prod_bseq;
}

/****************************************************************************/
d4257 1
a4257 1
bnx_tx_encap(struct bnx_softc *sc, struct mbuf *m_head, u_int16_t *prod)
d4259 3
d4263 6
a4268 4
	u_int16_t		chain_prod;
	struct bnx_dmamap_arg	map_arg;
	bus_dmamap_t		map;
	int			rc = 0;
d4270 1
d4273 2
a4274 2
	if (m_head->m_pkthdr.csum_flags) {
		if (m_head->m_pkthdr.csum_flags & M_IPV4_CSUM_OUT)
d4276 1
a4276 1
		if (m_head->m_pkthdr.csum_flags &
d4285 3
a4287 3
	if ((m_head->m_flags & (M_PROTO1|M_PKTHDR)) == (M_PROTO1|M_PKTHDR) &&
	    m_head->m_pkthdr.rcvif != NULL) {
		struct ifvlan *ifv = m_head->m_pkthdr.rcvif->if_softc;
d4295 2
a4296 1
	chain_prod = TX_CHAIN_IDX(*prod);
a4297 6
	map_arg.sc = sc;
	map_arg.prod = *prod;
	map_arg.chain_prod = chain_prod;
	map_arg.prod_bseq = sc->tx_prod_bseq;
	map_arg.tx_flags = vlan_tag_flags;
	map_arg.maxsegs = USABLE_TX_BD - sc->used_tx_bd - BNX_TX_SLACK_SPACE;
d4299 5
a4303 3
#if 0
	KASSERT(map_arg.maxsegs > 0, ("Invalid TX maxsegs value!"));
#endif
d4306 2
a4307 2
	if (bus_dmamap_load_mbuf(sc->bnx_dmatag, map, m_head,
	    BUS_DMA_NOWAIT)) {
d4310 1
a4310 2
		rc = ENOBUFS;
		goto bnx_tx_encap_exit;
d4312 43
a4354 1
	bnx_dma_map_tx_desc(&map_arg, map);
d4365 5
a4369 4
	sc->tx_mbuf_map[chain_prod] = sc->tx_mbuf_map[map_arg.chain_prod];
	sc->tx_mbuf_map[map_arg.chain_prod] = map;
	sc->tx_mbuf_ptr[map_arg.chain_prod] = m_head;
	sc->used_tx_bd += map_arg.maxsegs;
d4380 2
a4381 2
	*prod = map_arg.prod;
	sc->tx_prod_bseq = map_arg.prod_bseq;
d4383 1
a4383 3
bnx_tx_encap_exit:

	return(rc);
d4416 1
a4416 1
	while (sc->tx_mbuf_ptr[tx_chain_prod] == NULL) {
d4428 1
a4428 1
		if (bnx_tx_encap(sc, m_head, &tx_prod)) {
a4443 1
		tx_prod = NEXT_TX_BD(tx_prod);
d4454 1
a4454 2
	sc->tx_prod = tx_prod;
	tx_chain_prod = TX_CHAIN_IDX(tx_prod);
@


1.24
log
@Use loadfirmware(9) to get /etc/firmware/bnx instead of hard-coding a
gigantic firmware into the kernel; checked by brad
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.23 2006/08/25 02:13:51 brad Exp $	*/
d375 1
a375 2
int	bnx_tx_encap(struct bnx_softc *, struct mbuf *, u_int16_t *,
	    u_int16_t *, u_int32_t *);
d2191 1
a2191 1
	txbd = &map_arg->tx_chain[TX_PAGE(chain_prod)][TX_IDX(chain_prod)];
d2209 1
a2209 1
		    &map_arg->tx_chain[TX_PAGE(chain_prod)][TX_IDX(chain_prod)];
d4360 1
a4360 2
bnx_tx_encap(struct bnx_softc *sc, struct mbuf *m_head, u_int16_t *prod,
    u_int16_t *chain_prod, u_int32_t *prod_bseq)
d4363 1
d4366 1
a4366 1
	int			i, rc = 0;
d4392 2
a4393 1
	map = sc->tx_mbuf_map[*chain_prod];
d4396 2
a4397 2
	map_arg.chain_prod = *chain_prod;
	map_arg.prod_bseq = *prod_bseq;
a4404 3
	for (i = 0; i < TX_PAGES; i++)
		map_arg.tx_chain[i] = sc->tx_bd_chain[i];

d4424 1
a4424 1
	sc->tx_mbuf_map[*chain_prod] = sc->tx_mbuf_map[map_arg.chain_prod];
d4434 1
a4434 1
	DBRUN(BNX_VERBOSE_SEND, bnx_dump_tx_mbuf_chain(sc, *chain_prod, 
d4439 1
a4439 2
	*chain_prod = map_arg.chain_prod;
	*prod_bseq = map_arg.prod_bseq;
a4458 1
	u_int32_t		tx_prod_bseq;
a4469 1
	tx_prod_bseq = sc->tx_prod_bseq;
d4473 1
a4473 1
	    __FUNCTION__, tx_prod, tx_chain_prod, tx_prod_bseq);
d4488 1
a4488 2
		if (bnx_tx_encap(sc, m_head, &tx_prod, &tx_chain_prod,
		    &tx_prod_bseq)) {
a4504 1
		tx_chain_prod = TX_CHAIN_IDX(tx_prod);
d4516 1
a4516 1
	sc->tx_prod_bseq = tx_prod_bseq;
d4520 1
a4520 1
	    tx_chain_prod, tx_prod_bseq);
@


1.23
log
@don't need to clear if_timer during attach.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.22 2006/08/21 17:02:03 deraadt Exp $	*/
d53 90
a142 1
#include <dev/microcode/bnx/bnxfw.h>
d288 2
d425 145
a585 3
	pci_intr_handle_t	ih;
	const char 		*intrstr = NULL;
	struct ifnet		*ifp;
d588 2
d706 35
d747 2
a748 1
		printf(": Controller initialization failed!\n");
d754 2
a755 1
		printf(": NVRAM test failed!\n");
d862 1
a862 12
	/* Hookup IRQ last. */
	sc->bnx_intrhand = pci_intr_establish(pc, ih, IPL_NET, bnx_intr, sc,
	    sc->bnx_dev.dv_xname);
	if (sc->bnx_intrhand == NULL) {
		printf(": couldn't establish interrupt");
		if (intrstr != NULL)
			printf(" at %s", intrstr);
		printf("\n");
		goto bnx_attach_fail;
	}

	printf(": %s, address %s\n", intrstr,
d2677 1
a2677 1
	bnx_load_rv2p_fw(sc, bnx_rv2p_proc1, sizeof(bnx_rv2p_proc1),
d2679 1
a2679 1
	bnx_load_rv2p_fw(sc, bnx_rv2p_proc2, sizeof(bnx_rv2p_proc2),
d4650 2
a4651 1
	printf("%s: Watchdog timeout occurred, resetting!\n");
@


1.22
log
@ramdisks do not have vlan, drop mbuf; ok brad
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.21 2006/08/21 03:32:11 brad Exp $	*/
a563 1
	ifp->if_timer = 0;
@


1.21
log
@simplfy code a bit and fix comments, this is the MRU being set not the
MTU.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.20 2006/08/21 03:22:09 brad Exp $	*/
d3771 1
d3795 4
@


1.20
log
@enable Jumbo support.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.19 2006/08/20 21:47:19 brad Exp $	*/
d589 1
a589 2
	/* Assume a standard 1500 byte MTU size for mbuf allocations. */
	sc->mbuf_alloc_size = MCLBYTES;
d4041 1
a4041 1
	/* Calculate and program the Ethernet MTU size. */
d4044 1
a4044 1
	DBPRINT(sc, BNX_INFO, "%s(): setting mtu = %d\n",
d4047 3
a4049 4
	/* 
	 * Program the MTU and enable Jumbo frame 
	 * support.  Also set the mbuf
	 * allocation count for RX frames.
a4052 1
	sc->mbuf_alloc_size = BNX_MAX_MRU;
@


1.19
log
@remove a comment.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.18 2006/08/20 08:36:33 brad Exp $	*/
a569 1
#ifdef BNX_JUMBO
a570 1
#endif
d3115 1
a3115 4
		if (sc->mbuf_alloc_size <= MCLBYTES)
			MCLGET(m_new, M_DONTWAIT);
		else
			MEXTMALLOC(m_new, sc->mbuf_alloc_size, M_DONTWAIT);
a4042 1
#ifdef BNX_JUMBO
a4043 3
#else
	ether_mtu = BNX_MAX_STD_ETHER_MTU_VLAN;
#endif
d4049 1
a4049 1
	 * Program the mtu and enable jumbo frame 
a4052 1
#ifdef BNX_JUMBO
a4055 4
#else
	REG_WR(sc, BNX_EMAC_RX_MTU_SIZE, ether_mtu);
	sc->mbuf_alloc_size = MCLBYTES;
#endif
@


1.18
log
@cosmetic tweaks.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.17 2006/08/20 06:22:25 brad Exp $	*/
d4065 1
a4065 1
	sc->mbuf_alloc_size = BNX_MAX_MRU; /* MJUM9BYTES */
@


1.17
log
@- replace IF_DEQUEUE/IF_PREPEND with IFQ_POLL/IFQ_DEQUEUE.
- enable RX checksum offload.
- remove some unused code.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.16 2006/08/19 04:01:02 brad Exp $	*/
d3097 1
a3097 3
		    BNX_PRINTF(sc,
		        "%s(%d): Simulating mbuf allocation failure.\n",
			__FILE__, __LINE__);
d3382 2
a3383 2
			printf("%s: Error filling RX chain: rx_bd[0x%04X]!\n",
			    chain_prod);
d3702 2
a3703 2
				DBRUN(BNX_WARN, printf("%s: Failed to allocate "
				    "new mbuf, incoming frame dropped!\n"));
d4313 1
a4313 1
        }
d4339 8
a4346 6
			} else if (!(ifp->if_flags & IFF_RUNNING))
				bnx_init(ifp);

                } else if (ifp->if_flags & IFF_RUNNING)
			bnx_stop(sc);

d4353 2
a4354 2
                        ? ether_addmulti(ifr, &sc->arpcom)
                        : ether_delmulti(ifr, &sc->arpcom);
@


1.16
log
@set the capabilities VLAN MTU flag.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.15 2006/08/14 20:45:00 marco Exp $	*/
a410 12
#if 0
	/* 
	 * The embedded PCIe to PCI-X bridge (EPB) 
	 * in the 5708 cannot address memory above 
	 * 40 bits (E7_5708CB1_23043 & E6_5708SB1_23043). 
	 */
	if (BNX_CHIP_NUM(sc) == BNX_CHIP_NUM_5708)
		sc->max_bus_addr = BNX_BUS_SPACE_MAXADDR;
	else
		sc->max_bus_addr = BUS_SPACE_MAXADDR;
#endif

d570 1
a570 1
#if 0
d580 11
d1931 2
a1932 2
	 * for that segment and creating a tx_bd to for
	 * the mbuf.
d3737 7
a3743 5
#ifdef BNX_CKSUM
			/* Validate the checksum if offload enabled. */
			if (ifp->if_capenable & IFCAP_RXCSUM) {
				/* Check for an IP datagram. */
				if (status & L2_FHDR_STATUS_IP_DATAGRAM) {
d3745 9
a3753 1
					    CSUM_IP_CHECKED;
d3755 16
a3770 12
					/* Check if the IP checksum is valid. */
					if ((l2fhdr->l2_fhdr_ip_xsum ^ 0xffff)
					    == 0)
						m->m_pkthdr.csum_flags |=
						    CSUM_IP_VALID;
					else
						DBPRINT(sc, BNX_WARN_SEND, 
						    "%s(): Invalid IP checksum "
						        "= 0x%04X!\n",
							__FUNCTION__,
							l2fhdr->l2_fhdr_ip_xsum
							);
d3772 1
d3774 15
a3788 18
				/* Check for a valid TCP/UDP frame. */
				if (status & (L2_FHDR_STATUS_TCP_SEGMENT |
				    L2_FHDR_STATUS_UDP_DATAGRAM)) {
					/* Check for a good TCP/UDP checksum. */
					if ((status &
					    (L2_FHDR_ERRORS_TCP_XSUM |
					    L2_FHDR_ERRORS_UDP_XSUM)) == 0) {
						m->m_pkthdr.csum_data = l2fhdr->l2_fhdr_tcp_udp_xsum;
						m->m_pkthdr.csum_flags |=
						    (CSUM_DATA_VALID |
						    CSUM_PSEUDO_HDR);
					} else {
						DBPRINT(sc, BNX_WARN_SEND, 
						    "%s(): Invalid TCP/UDP "
						    "checksum = 0x%04X!\n",
						    __FUNCTION__,
						    l2fhdr->l2_fhdr_tcp_udp_xsum);
					}
d3790 13
a3802 2
			}		
#endif
d4050 1
a4050 1
#if 0
d4064 1
a4064 1
#if 0
a4121 3
#ifdef BNX_VLAN
	struct m_tag		*mtag;
#endif
d4123 1
a4123 1
#ifdef BNX_CKSUM
d4126 1
a4126 1
		if (m_head->m_pkthdr.csum_flags & CSUM_IP)
d4128 2
a4129 1
		if (m_head->m_pkthdr.csum_flags & (CSUM_TCP | CSUM_UDP))
d4135 1
d4137 3
a4139 2
	mtag = VLAN_OUTPUT_TAG(&sc->arpcom.ac_if, m_head);
	if (mtag != NULL)
d4141 3
a4143 1
		    (VLAN_TAG_VALUE(mtag) << 16));
d4238 1
a4238 1
		IF_DEQUEUE(&ifp->if_snd, m_head);
a4249 1
			IF_PREPEND(&ifp->if_snd, m_head);
d4257 1
@


1.15
log
@And some more KNF.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.14 2006/08/14 19:10:23 marco Exp $	*/
d589 2
@


1.14
log
@KNF
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.13 2006/08/14 18:07:46 marco Exp $	*/
d4187 5
a4191 5
	struct bnx_softc *sc = ifp->if_softc;
	struct mbuf *m_head = NULL;
	int count = 0;
	u_int16_t tx_prod, tx_chain_prod;
	u_int32_t	tx_prod_bseq;
d4195 2
a4196 2
		DBPRINT(sc, BNX_INFO_SEND, "%s(): No link or transmit queue empty.\n", 
			__FUNCTION__);
d4205 3
a4207 4
	DBPRINT(sc, BNX_INFO_SEND,
		"%s(): Start: tx_prod = 0x%04X, tx_chain_prod = %04X, "
		"tx_prod_bseq = 0x%08X\n",
		__FUNCTION__, tx_prod, tx_chain_prod, tx_prod_bseq);
a4210 1

d4222 2
a4223 1
		if (bnx_tx_encap(sc, m_head, &tx_prod, &tx_chain_prod, &tx_prod_bseq)) {
d4226 3
a4228 3
			DBPRINT(sc, BNX_INFO_SEND,
				"TX chain is closed for business! Total tx_bd used = %d\n", 
				sc->used_tx_bd);
a4238 1

d4245 2
a4246 2
		DBPRINT(sc, BNX_VERBOSE_SEND, "%s(): No packets were dequeued\n", 
			__FUNCTION__);
d4251 1
a4251 1
	sc->tx_prod      = tx_prod;
d4254 3
a4256 4
	DBPRINT(sc, BNX_INFO_SEND,
		"%s(): End: tx_prod = 0x%04X, tx_chain_prod = 0x%04X, "
		"tx_prod_bseq = 0x%08X\n",
		__FUNCTION__, tx_prod, tx_chain_prod, tx_prod_bseq);
d4278 5
a4282 5
	struct bnx_softc *sc = ifp->if_softc;
	struct ifreq *ifr = (struct ifreq *) data;
	struct ifaddr *ifa = (struct ifaddr *)data;
	struct mii_data *mii;
	int s, error = 0;
d4301 1
d4308 1
d4313 1
a4313 1
			     (IFF_ALLMULTI | IFF_PROMISC)) != 0) {
d4315 6
a4320 8
			} else {
				if (!(ifp->if_flags & IFF_RUNNING))
					bnx_init(ifp);
                        }
                } else {
			if (ifp->if_flags & IFF_RUNNING)
				bnx_stop(sc);
		}
d4323 1
d4336 1
d4340 1
a4340 1
			sc->bnx_phy_flags);
d4342 1
a4342 1
		if (sc->bnx_phy_flags & BNX_PHY_SERDES_FLAG) {
d4345 1
a4345 1
		} else {
d4351 1
d4371 1
a4371 1
	struct bnx_softc *sc = ifp->if_softc;
d4373 2
a4374 3
	DBRUN(BNX_WARN_SEND, 
		bnx_dump_driver_state(sc);
		bnx_dump_status_block(sc));
d4399 3
a4401 3
	struct bnx_softc *sc;
	struct ifnet *ifp;
	u_int32_t status_attn_bits;
d4418 2
a4419 1
		(REG_RD(sc, BNX_PCICFG_MISC_STATUS) & BNX_PCICFG_MISC_STATUS_INTA_VALUE))
d4424 2
a4425 2
		BNX_PCICFG_INT_ACK_CMD_USE_INT_HC_PARAM |
		BNX_PCICFG_INT_ACK_CMD_MASK_INT);
a4428 1

d4432 3
a4434 2
			printf("Simulating unexpected status attention bit set.");
			status_attn_bits = status_attn_bits | STATUS_ATTN_BITS_PARITY_ERROR);
d4438 2
a4439 1
			(sc->status_block->status_attn_bits_ack & STATUS_ATTN_BITS_LINK_STATE))
d4444 2
a4445 3
			(sc->status_block->status_attn_bits_ack & 
			~STATUS_ATTN_BITS_LINK_STATE))) {

d4449 1
a4449 1
				sc->status_block->status_attn_bits);
d4451 3
a4453 3
			DBRUN(BNX_FATAL, 
				if (bnx_debug_unexpected_attention == 0)
					bnx_breakpoint(sc));
d4460 2
a4461 1
		if (sc->status_block->status_rx_quick_consumer_index0 != sc->hw_rx_cons)
d4465 2
a4466 1
		if (sc->status_block->status_tx_quick_consumer_index0 != sc->hw_tx_cons)
d4469 3
a4471 1
		/* Save the status block index value for use during the next interrupt. */
d4474 3
a4476 1
		/* Prevent speculative reads from getting ahead of the status block. */
d4478 1
a4478 1
			BUS_SPACE_BARRIER_READ);
d4480 5
a4484 3
		/* If there's no work left then exit the interrupt service routine. */
		if ((sc->status_block->status_rx_quick_consumer_index0 == sc->hw_rx_cons) &&
	    	(sc->status_block->status_tx_quick_consumer_index0 == sc->hw_tx_cons))
a4485 1
	
d4493 2
a4494 2
	       BNX_PCICFG_INT_ACK_CMD_INDEX_VALID | sc->last_status_idx |
	       BNX_PCICFG_INT_ACK_CMD_MASK_INT);
d4496 1
a4496 1
	       BNX_PCICFG_INT_ACK_CMD_INDEX_VALID | sc->last_status_idx);
d4514 7
a4520 7
	struct arpcom *ac = &sc->arpcom;
	struct ifnet *ifp = &ac->ac_if;
	struct ether_multi *enm;
	struct ether_multistep step;
	u_int32_t hashes[4] = { 0, 0, 0, 0 };
	u_int32_t rx_mode, sort_mode;
	int h, i;
d4523 2
a4524 2
	rx_mode   = sc->rx_mode & ~(BNX_EMAC_RX_MODE_PROMISCUOUS |
			    BNX_EMAC_RX_MODE_KEEP_VLAN_TAG);
d4550 2
a4551 1
			REG_WR(sc, BNX_EMAC_MULTICAST_HASH0 + (i * 4), 0xffffffff);
d4559 2
a4560 1
			if (bcmp(enm->enm_addrlo, enm->enm_addrhi, ETHER_ADDR_LEN)) {
d4564 2
a4565 1
			h = ether_crc32_le(enm->enm_addrlo, ETHER_ADDR_LEN) & 0x7F;
d4571 2
a4572 1
			REG_WR(sc, BNX_EMAC_MULTICAST_HASH0 + (i * 4), hashes[i]);
d4580 1
a4580 1
			rx_mode);
d4602 2
a4603 2
	struct ifnet *ifp = &sc->arpcom.ac_if;
	struct statistics_block *stats;
d4607 1
a4607 1
	stats = (struct statistics_block *) sc->stats_block;
d4613 1
a4613 1
	ifp->if_collisions = (u_long) stats->stat_EtherStatsCollisions;
d4615 10
a4624 9
	ifp->if_ierrors = (u_long) stats->stat_EtherStatsUndersizePkts +
				      (u_long) stats->stat_EtherStatsOverrsizePkts +
					  (u_long) stats->stat_IfInMBUFDiscards +
					  (u_long) stats->stat_Dot3StatsAlignmentErrors +
					  (u_long) stats->stat_Dot3StatsFCSErrors;

	ifp->if_oerrors = (u_long) stats->stat_emac_tx_stat_dot3statsinternalmactransmiterrors +
					  (u_long) stats->stat_Dot3StatsExcessiveCollisions +
					  (u_long) stats->stat_Dot3StatsLateCollisions;
d4639 2
a4640 3
	sc->stat_IfHCInOctets = 
		((u_int64_t) stats->stat_IfHCInOctets_hi << 32) + 
		 (u_int64_t) stats->stat_IfHCInOctets_lo;
d4643 2
a4644 2
		((u_int64_t) stats->stat_IfHCInBadOctets_hi << 32) + 
		 (u_int64_t) stats->stat_IfHCInBadOctets_lo;
d4647 2
a4648 2
		((u_int64_t) stats->stat_IfHCOutOctets_hi << 32) +
		 (u_int64_t) stats->stat_IfHCOutOctets_lo;
d4651 2
a4652 2
		((u_int64_t) stats->stat_IfHCOutBadOctets_hi << 32) +
		 (u_int64_t) stats->stat_IfHCOutBadOctets_lo;
d4655 2
a4656 2
		((u_int64_t) stats->stat_IfHCInUcastPkts_hi << 32) +
		 (u_int64_t) stats->stat_IfHCInUcastPkts_lo;
d4659 2
a4660 2
		((u_int64_t) stats->stat_IfHCInMulticastPkts_hi << 32) +
		 (u_int64_t) stats->stat_IfHCInMulticastPkts_lo;
d4663 2
a4664 2
		((u_int64_t) stats->stat_IfHCInBroadcastPkts_hi << 32) +
		 (u_int64_t) stats->stat_IfHCInBroadcastPkts_lo;
d4667 2
a4668 2
		((u_int64_t) stats->stat_IfHCOutUcastPkts_hi << 32) +
		 (u_int64_t) stats->stat_IfHCOutUcastPkts_lo;
d4671 2
a4672 2
		((u_int64_t) stats->stat_IfHCOutMulticastPkts_hi << 32) +
		 (u_int64_t) stats->stat_IfHCOutMulticastPkts_lo;
d4675 2
a4676 2
		((u_int64_t) stats->stat_IfHCOutBroadcastPkts_hi << 32) +
		 (u_int64_t) stats->stat_IfHCOutBroadcastPkts_lo;
d4679 1
a4679 1
		stats->stat_emac_tx_stat_dot3statsinternalmactransmiterrors;
d4682 1
a4682 1
		stats->stat_Dot3StatsCarrierSenseErrors;
d4684 1
a4684 2
	sc->stat_Dot3StatsFCSErrors = 
		stats->stat_Dot3StatsFCSErrors;
d4687 1
a4687 1
		stats->stat_Dot3StatsAlignmentErrors;
d4690 1
a4690 1
		stats->stat_Dot3StatsSingleCollisionFrames;
d4693 1
a4693 1
		stats->stat_Dot3StatsMultipleCollisionFrames;
d4696 1
a4696 1
		stats->stat_Dot3StatsDeferredTransmissions;
d4699 1
a4699 1
		stats->stat_Dot3StatsExcessiveCollisions;
d4701 1
a4701 2
	sc->stat_Dot3StatsLateCollisions =
		stats->stat_Dot3StatsLateCollisions;
d4703 1
a4703 2
	sc->stat_EtherStatsCollisions =
		stats->stat_EtherStatsCollisions;
d4705 1
a4705 2
	sc->stat_EtherStatsFragments =
		stats->stat_EtherStatsFragments;
d4707 1
a4707 2
	sc->stat_EtherStatsJabbers =
		stats->stat_EtherStatsJabbers;
d4709 1
a4709 2
	sc->stat_EtherStatsUndersizePkts =
		stats->stat_EtherStatsUndersizePkts;
d4711 1
a4711 2
	sc->stat_EtherStatsOverrsizePkts =
		stats->stat_EtherStatsOverrsizePkts;
d4714 1
a4714 1
		stats->stat_EtherStatsPktsRx64Octets;
d4717 1
a4717 1
		stats->stat_EtherStatsPktsRx65Octetsto127Octets;
d4720 1
a4720 1
		stats->stat_EtherStatsPktsRx128Octetsto255Octets;
d4723 1
a4723 1
		stats->stat_EtherStatsPktsRx256Octetsto511Octets;
d4726 1
a4726 1
		stats->stat_EtherStatsPktsRx512Octetsto1023Octets;
d4729 1
a4729 1
		stats->stat_EtherStatsPktsRx1024Octetsto1522Octets;
d4732 1
a4732 1
		stats->stat_EtherStatsPktsRx1523Octetsto9022Octets;
d4735 1
a4735 1
		stats->stat_EtherStatsPktsTx64Octets;
d4738 1
a4738 1
		stats->stat_EtherStatsPktsTx65Octetsto127Octets;
d4741 1
a4741 1
		stats->stat_EtherStatsPktsTx128Octetsto255Octets;
d4744 1
a4744 1
		stats->stat_EtherStatsPktsTx256Octetsto511Octets;
d4747 1
a4747 1
		stats->stat_EtherStatsPktsTx512Octetsto1023Octets;
d4750 1
a4750 1
		stats->stat_EtherStatsPktsTx1024Octetsto1522Octets;
d4753 1
a4753 1
		stats->stat_EtherStatsPktsTx1523Octetsto9022Octets;
d4755 1
a4755 2
	sc->stat_XonPauseFramesReceived =
		stats->stat_XonPauseFramesReceived;
d4757 1
a4757 2
	sc->stat_XoffPauseFramesReceived =
		stats->stat_XoffPauseFramesReceived;
d4759 1
a4759 2
	sc->stat_OutXonSent =
		stats->stat_OutXonSent;
d4761 1
a4761 2
	sc->stat_OutXoffSent =
		stats->stat_OutXoffSent;
d4763 1
a4763 2
	sc->stat_FlowControlDone =
		stats->stat_FlowControlDone;
d4766 1
a4766 1
		stats->stat_MacControlFramesReceived;
d4768 1
a4768 2
	sc->stat_XoffStateEntered =
		stats->stat_XoffStateEntered;
d4771 1
a4771 1
		stats->stat_IfInFramesL2FilterDiscards;
d4773 1
a4773 2
	sc->stat_IfInRuleCheckerDiscards =
		stats->stat_IfInRuleCheckerDiscards;
d4775 1
a4775 2
	sc->stat_IfInFTQDiscards =
		stats->stat_IfInFTQDiscards;
d4777 1
a4777 2
	sc->stat_IfInMBUFDiscards =
		stats->stat_IfInMBUFDiscards;
d4779 1
a4779 2
	sc->stat_IfInRuleCheckerP4Hit =
		stats->stat_IfInRuleCheckerP4Hit;
d4782 1
a4782 1
		stats->stat_CatchupInRuleCheckerDiscards;
d4784 1
a4784 2
	sc->stat_CatchupInFTQDiscards =
		stats->stat_CatchupInFTQDiscards;
d4786 1
a4786 2
	sc->stat_CatchupInMBUFDiscards =
		stats->stat_CatchupInMBUFDiscards;
d4789 1
a4789 1
		stats->stat_CatchupInRuleCheckerP4Hit;
d4797 4
a4800 4
	struct bnx_softc *sc = xsc;
	struct ifnet *ifp = &sc->arpcom.ac_if;
	struct mii_data *mii = NULL;
	u_int32_t msg;
d4804 1
a4804 1
	msg = (u_int32_t) BNX_DRV_MSG_DATA_PULSE_CODE_ALWAYS_ALIVE;
d4806 1
a4806 1
	msg = (u_int32_t) ++sc->bnx_fw_drv_pulse_wr_seq;
d4852 1
a4852 1
	struct mbuf *mp = m;
a4875 2


d4887 2
a4888 2
	struct mbuf *m;
	int i;
d4891 3
a4893 3
		"----------------------------"
		"  tx mbuf data  "
		"----------------------------\n");
d4903 2
a4904 3
		"----------------------------"
		"----------------"
		"----------------------------\n");
d4913 2
a4914 2
	struct mbuf *m;
	int i;
d4917 3
a4919 3
		"----------------------------"
		"  rx mbuf data  "
		"----------------------------\n");
d4930 2
a4931 3
		"----------------------------"
		"----------------"
		"----------------------------\n");
d4942 3
a4944 2
		BNX_PRINTF(sc, "tx_bd[0x%04X]: haddr = 0x%08X:%08X, chain page pointer\n", 
			idx, txbd->tx_bd_haddr_hi, txbd->tx_bd_haddr_lo);
d4947 4
a4950 4
		BNX_PRINTF(sc, "tx_bd[0x%04X]: haddr = 0x%08X:%08X, nbytes = 0x%08X, "
			"flags = 0x%08X\n", idx, 
			txbd->tx_bd_haddr_hi, txbd->tx_bd_haddr_lo,
			txbd->tx_bd_mss_nbytes, txbd->tx_bd_vlan_tag_flags);
d4961 3
a4963 2
		BNX_PRINTF(sc, "rx_bd[0x%04X]: haddr = 0x%08X:%08X, chain page pointer\n", 
			idx, rxbd->rx_bd_haddr_hi, rxbd->rx_bd_haddr_lo);
d4966 2
a4967 2
		BNX_PRINTF(sc, "rx_bd[0x%04X]: haddr = 0x%08X:%08X, nbytes = 0x%08X, "
			"flags = 0x%08X\n", idx, 
d4976 5
a4980 5
		"pkt_len = 0x%04X, vlan = 0x%04x, ip_xsum = 0x%04X, "
		"tcp_udp_xsum = 0x%04X\n", idx,
		l2fhdr->l2_fhdr_status, l2fhdr->l2_fhdr_pkt_len,
		l2fhdr->l2_fhdr_vlan_tag, l2fhdr->l2_fhdr_ip_xsum,
		l2fhdr->l2_fhdr_tcp_udp_xsum);
d4989 2
a4990 2
	struct tx_bd *txbd;
	int i;
d4994 3
a4996 3
		"----------------------------"
		"  tx_bd  chain  "
		"----------------------------\n");
d4998 3
a5000 2
	BNX_PRINTF(sc, "page size      = 0x%08X, tx chain pages        = 0x%08X\n",
		(u_int32_t) BCM_PAGE_SIZE, (u_int32_t) TX_PAGES);
d5002 3
a5004 2
	BNX_PRINTF(sc, "tx_bd per page = 0x%08X, usable tx_bd per page = 0x%08X\n",
		(u_int32_t) TOTAL_TX_BD_PER_PAGE, (u_int32_t) USABLE_TX_BD_PER_PAGE);
d5006 1
a5006 1
	BNX_PRINTF(sc, "total tx_bd    = 0x%08X\n", (u_int32_t) TOTAL_TX_BD);
d5009 3
a5011 3
		"-----------------------------"
		"   tx_bd data   "
		"-----------------------------\n");
d5021 3
a5023 3
		"-----------------------------"
		"--------------"
		"-----------------------------\n");
d5032 2
a5033 2
	struct rx_bd *rxbd;
	int i;
d5037 3
a5039 3
		"----------------------------"
		"  rx_bd  chain  "
		"----------------------------\n");
d5043 3
a5045 2
	BNX_PRINTF(sc, "page size      = 0x%08X, rx chain pages        = 0x%08X\n",
		(u_int32_t) BCM_PAGE_SIZE, (u_int32_t) RX_PAGES);
d5047 3
a5049 2
	BNX_PRINTF(sc, "rx_bd per page = 0x%08X, usable rx_bd per page = 0x%08X\n",
		(u_int32_t) TOTAL_RX_BD_PER_PAGE, (u_int32_t) USABLE_RX_BD_PER_PAGE);
d5051 1
a5051 1
	BNX_PRINTF(sc, "total rx_bd    = 0x%08X\n", (u_int32_t) TOTAL_RX_BD);
d5054 3
a5056 3
		"----------------------------"
		"   rx_bd data   "
		"----------------------------\n");
d5066 3
a5068 3
		"----------------------------"
		"--------------"
		"----------------------------\n");
d5077 1
a5077 1
	struct status_block *sblk;
d5082 1
a5082 1
		"-----------------------------\n");
d5084 4
a5087 3
	BNX_PRINTF(sc, "attn_bits  = 0x%08X, attn_bits_ack = 0x%08X, index = 0x%04X\n",
		sblk->status_attn_bits, sblk->status_attn_bits_ack,
		sblk->status_idx);
d5090 2
a5091 2
		sblk->status_rx_quick_consumer_index0,
		sblk->status_tx_quick_consumer_index0);
d5099 2
a5100 2
			sblk->status_rx_quick_consumer_index1,
			sblk->status_tx_quick_consumer_index1);
d5105 2
a5106 2
			sblk->status_rx_quick_consumer_index2,
			sblk->status_tx_quick_consumer_index2);
d5111 2
a5112 2
			sblk->status_rx_quick_consumer_index3,
			sblk->status_tx_quick_consumer_index3);
d5117 2
a5118 2
			sblk->status_rx_quick_consumer_index4,
			sblk->status_rx_quick_consumer_index5);
d5123 2
a5124 2
			sblk->status_rx_quick_consumer_index6,
			sblk->status_rx_quick_consumer_index7);
d5129 2
a5130 2
			sblk->status_rx_quick_consumer_index8,
			sblk->status_rx_quick_consumer_index9);
d5135 2
a5136 2
			sblk->status_rx_quick_consumer_index10,
			sblk->status_rx_quick_consumer_index11);
d5141 2
a5142 2
			sblk->status_rx_quick_consumer_index12,
			sblk->status_rx_quick_consumer_index13);
d5147 2
a5148 2
			sblk->status_rx_quick_consumer_index14,
			sblk->status_rx_quick_consumer_index15);
d5153 2
a5154 2
			sblk->status_completion_producer_index,
			sblk->status_cmd_consumer_index);
d5157 1
a5157 1
		"-----------------------------\n");
d5166 1
a5166 1
	struct statistics_block *sblk;
d5171 3
a5173 3
		"-----------------------------"
		" Stats  Block "
		"-----------------------------\n");
d5176 3
a5178 3
		"IfHcInBadOctets      = 0x%08X:%08X\n",
		sblk->stat_IfHCInOctets_hi, sblk->stat_IfHCInOctets_lo,
		sblk->stat_IfHCInBadOctets_hi, sblk->stat_IfHCInBadOctets_lo);
d5181 3
a5183 3
		"IfHcOutBadOctets     = 0x%08X:%08X\n",
		sblk->stat_IfHCOutOctets_hi, sblk->stat_IfHCOutOctets_lo,
		sblk->stat_IfHCOutBadOctets_hi, sblk->stat_IfHCOutBadOctets_lo);
d5186 4
a5189 3
		"IfHcInMulticastPkts  = 0x%08X:%08X\n",
		sblk->stat_IfHCInUcastPkts_hi, sblk->stat_IfHCInUcastPkts_lo,
		sblk->stat_IfHCInMulticastPkts_hi, sblk->stat_IfHCInMulticastPkts_lo);
d5192 12
a5203 7
		"IfHcOutUcastPkts     = 0x%08X:%08X\n",
		sblk->stat_IfHCInBroadcastPkts_hi, sblk->stat_IfHCInBroadcastPkts_lo,
		sblk->stat_IfHCOutUcastPkts_hi, sblk->stat_IfHCOutUcastPkts_lo);

	BNX_PRINTF(sc, "IfHcOutMulticastPkts = 0x%08X:%08X, IfHcOutBroadcastPkts = 0x%08X:%08X\n",
		sblk->stat_IfHCOutMulticastPkts_hi, sblk->stat_IfHCOutMulticastPkts_lo,
		sblk->stat_IfHCOutBroadcastPkts_hi, sblk->stat_IfHCOutBroadcastPkts_lo);
d5207 2
a5208 2
		"emac_tx_stat_dot3statsinternalmactransmiterrors\n", 
		sblk->stat_emac_tx_stat_dot3statsinternalmactransmiterrors);
d5212 1
a5212 1
			sblk->stat_Dot3StatsCarrierSenseErrors);
d5216 1
a5216 1
			sblk->stat_Dot3StatsFCSErrors);
d5220 1
a5220 1
			sblk->stat_Dot3StatsAlignmentErrors);
d5224 1
a5224 1
			sblk->stat_Dot3StatsSingleCollisionFrames);
d5228 1
a5228 1
			sblk->stat_Dot3StatsMultipleCollisionFrames);
d5232 1
a5232 1
			sblk->stat_Dot3StatsDeferredTransmissions);
d5236 1
a5236 1
			sblk->stat_Dot3StatsExcessiveCollisions);
d5240 1
a5240 1
			sblk->stat_Dot3StatsLateCollisions);
d5244 1
a5244 1
			sblk->stat_EtherStatsCollisions);
d5248 1
a5248 1
			sblk->stat_EtherStatsFragments);
d5252 1
a5252 1
			sblk->stat_EtherStatsJabbers);
d5256 1
a5256 1
			sblk->stat_EtherStatsUndersizePkts);
d5260 1
a5260 1
			sblk->stat_EtherStatsOverrsizePkts);
d5264 1
a5264 1
			sblk->stat_EtherStatsPktsRx64Octets);
d5268 1
a5268 1
			sblk->stat_EtherStatsPktsRx65Octetsto127Octets);
d5271 3
a5273 2
		BNX_PRINTF(sc, "0x%08X : EtherStatsPktsRx128Octetsto255Octets\n",
			sblk->stat_EtherStatsPktsRx128Octetsto255Octets);
d5276 3
a5278 2
		BNX_PRINTF(sc, "0x%08X : EtherStatsPktsRx256Octetsto511Octets\n",
			sblk->stat_EtherStatsPktsRx256Octetsto511Octets);
d5281 3
a5283 2
		BNX_PRINTF(sc, "0x%08X : EtherStatsPktsRx512Octetsto1023Octets\n",
			sblk->stat_EtherStatsPktsRx512Octetsto1023Octets);
d5286 3
a5288 2
		BNX_PRINTF(sc, "0x%08X : EtherStatsPktsRx1024Octetsto1522Octets\n",
			sblk->stat_EtherStatsPktsRx1024Octetsto1522Octets);
d5291 3
a5293 2
		BNX_PRINTF(sc, "0x%08X : EtherStatsPktsRx1523Octetsto9022Octets\n",
			sblk->stat_EtherStatsPktsRx1523Octetsto9022Octets);
d5297 1
a5297 1
			sblk->stat_EtherStatsPktsTx64Octets);
d5301 1
a5301 1
			sblk->stat_EtherStatsPktsTx65Octetsto127Octets);
d5304 3
a5306 2
		BNX_PRINTF(sc, "0x%08X : EtherStatsPktsTx128Octetsto255Octets\n",
			sblk->stat_EtherStatsPktsTx128Octetsto255Octets);
d5309 3
a5311 2
		BNX_PRINTF(sc, "0x%08X : EtherStatsPktsTx256Octetsto511Octets\n",
			sblk->stat_EtherStatsPktsTx256Octetsto511Octets);
d5314 3
a5316 2
		BNX_PRINTF(sc, "0x%08X : EtherStatsPktsTx512Octetsto1023Octets\n",
			sblk->stat_EtherStatsPktsTx512Octetsto1023Octets);
d5319 3
a5321 2
		BNX_PRINTF(sc, "0x%08X : EtherStatsPktsTx1024Octetsto1522Octets\n",
			sblk->stat_EtherStatsPktsTx1024Octetsto1522Octets);
d5324 3
a5326 2
		BNX_PRINTF(sc, "0x%08X : EtherStatsPktsTx1523Octetsto9022Octets\n",
			sblk->stat_EtherStatsPktsTx1523Octetsto9022Octets);
d5330 1
a5330 1
			sblk->stat_XonPauseFramesReceived);
d5333 2
a5334 2
	   BNX_PRINTF(sc, "0x%08X : XoffPauseFramesReceived\n",
			sblk->stat_XoffPauseFramesReceived);
d5338 1
a5338 1
			sblk->stat_OutXonSent);
d5342 1
a5342 1
			sblk->stat_OutXoffSent);
d5346 1
a5346 1
			sblk->stat_FlowControlDone);
d5350 1
a5350 1
			sblk->stat_MacControlFramesReceived);
d5354 1
a5354 1
			sblk->stat_XoffStateEntered);
d5358 1
a5358 1
			sblk->stat_IfInFramesL2FilterDiscards);
d5362 1
a5362 1
			sblk->stat_IfInRuleCheckerDiscards);
d5366 1
a5366 1
			sblk->stat_IfInFTQDiscards);
d5370 1
a5370 1
			sblk->stat_IfInMBUFDiscards);
d5374 1
a5374 1
			sblk->stat_IfInRuleCheckerP4Hit);
d5378 1
a5378 1
			sblk->stat_CatchupInRuleCheckerDiscards);
d5382 1
a5382 1
			sblk->stat_CatchupInFTQDiscards);
d5386 1
a5386 1
			sblk->stat_CatchupInMBUFDiscards);
d5390 1
a5390 1
			sblk->stat_CatchupInRuleCheckerP4Hit);
d5393 3
a5395 3
		"-----------------------------"
		"--------------"
		"-----------------------------\n");
d5427 2
a5428 1
	BNX_PRINTF(sc, "         0x%08X - (sc->interrupts_generated) h/w intrs\n",
d5431 2
a5432 1
	BNX_PRINTF(sc, "         0x%08X - (sc->rx_interrupts) rx interrupts handled\n",
d5435 3
a5437 2
	BNX_PRINTF(sc, "         0x%08X - (sc->tx_interrupts) tx interrupts handled\n",
	   sc->tx_interrupts);
d5439 2
a5440 1
	BNX_PRINTF(sc, "         0x%08X - (sc->last_status_idx) status block index\n",
d5449 2
a5450 1
	BNX_PRINTF(sc, "         0x%08X - (sc->tx_prod_bseq) tx producer bseq index\n",
d5459 2
a5460 1
	BNX_PRINTF(sc, "         0x%08X - (sc->rx_prod_bseq) rx producer bseq index\n",
d5463 2
a5464 1
	BNX_PRINTF(sc, "         0x%08X - (sc->rx_mbuf_alloc) rx mbufs allocated\n",
d5470 2
a5471 1
	BNX_PRINTF(sc, "0x%08X/%08X - (sc->rx_low_watermark) rx low watermark\n",
d5474 2
a5475 1
	BNX_PRINTF(sc, "         0x%08X - (sc->txmbuf_alloc) tx mbufs allocated\n",
d5478 2
a5479 1
	BNX_PRINTF(sc, "         0x%08X - (sc->rx_mbuf_alloc) rx mbufs allocated\n",
d5488 2
a5489 1
	BNX_PRINTF(sc, "         0x%08X - (sc->mbuf_alloc_failed) failed mbuf alloc\n",
d5499 2
a5500 2
	u_int32_t val1;
	int i;
d5503 3
a5505 3
		"----------------------------"
		" Hardware State "
		"----------------------------\n");
d5511 1
a5511 1
		val1, BNX_MISC_ENABLE_STATUS_BITS);
d5520 2
a5521 1
	BNX_PRINTF(sc, "0x%08X : (0x%04X) emac_status\n", val1, BNX_EMAC_STATUS);
d5527 2
a5528 1
	BNX_PRINTF(sc, "0x%08X : (0x%04X) tbdr_status\n", val1, BNX_TBDR_STATUS);
d5531 2
a5532 1
	BNX_PRINTF(sc, "0x%08X : (0x%04X) tdma_status\n", val1, BNX_TDMA_STATUS);
d5538 3
a5540 3
		"----------------------------"
		"----------------"
		"----------------------------\n");
d5543 3
a5545 3
		"----------------------------"
		" Register  Dump "
		"----------------------------\n");
d5549 2
a5550 2
			i, REG_RD(sc, i), REG_RD(sc, i + 0x4),
			REG_RD(sc, i + 0x8), REG_RD(sc, i + 0xC));
d5553 3
a5555 3
		"----------------------------"
		"----------------"
		"----------------------------\n");
a5560 1

@


1.13
log
@More KNF; no functional change.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.12 2006/08/14 17:26:35 marco Exp $	*/
d2958 2
a2959 2
	u_int32_t reg, val;
	int rc = 0;
d2967 2
a2968 3
	val = sc->eaddr[0]         + (sc->eaddr[1] << 8) +
	      (sc->eaddr[2] << 16) + (sc->eaddr[3]     ) +
	      (sc->eaddr[4] << 8)  + (sc->eaddr[5] << 16);
d2978 1
a2978 2
	REG_WR(sc, BNX_HC_STATUS_ADDR_L,
		(u_int32_t)(sc->status_block_paddr));
d2980 1
a2980 1
		(u_int32_t)((u_int64_t)sc->status_block_paddr >> 32));
d2984 1
a2984 1
		(u_int32_t)(sc->stats_block_paddr));
d2986 1
a2986 1
		(u_int32_t)((u_int64_t)sc->stats_block_paddr >> 32));
d2989 16
a3004 18
	REG_WR(sc, BNX_HC_TX_QUICK_CONS_TRIP,
		(sc->bnx_tx_quick_cons_trip_int << 16) | sc->bnx_tx_quick_cons_trip);
	REG_WR(sc, BNX_HC_RX_QUICK_CONS_TRIP,
		(sc->bnx_rx_quick_cons_trip_int << 16) | sc->bnx_rx_quick_cons_trip);
	REG_WR(sc, BNX_HC_COMP_PROD_TRIP,
		(sc->bnx_comp_prod_trip_int << 16) | sc->bnx_comp_prod_trip);
	REG_WR(sc, BNX_HC_TX_TICKS,
		(sc->bnx_tx_ticks_int << 16) | sc->bnx_tx_ticks);
	REG_WR(sc, BNX_HC_RX_TICKS,
		(sc->bnx_rx_ticks_int << 16) | sc->bnx_rx_ticks);
	REG_WR(sc, BNX_HC_COM_TICKS,
		(sc->bnx_com_ticks_int << 16) | sc->bnx_com_ticks);
	REG_WR(sc, BNX_HC_CMD_TICKS,
		(sc->bnx_cmd_ticks_int << 16) | sc->bnx_cmd_ticks);
	REG_WR(sc, BNX_HC_STATS_TICKS,
		(sc->bnx_stats_ticks & 0xffff00));
	REG_WR(sc, BNX_HC_STAT_COLLECT_TICKS,
		0xbb8);  /* 3ms */
d3006 2
a3007 2
		(BNX_HC_CONFIG_RX_TMR_MODE | BNX_HC_CONFIG_TX_TMR_MODE |
		BNX_HC_CONFIG_COLLECT_STATS));
d3016 2
a3017 3
		BNX_PRINTF(sc, "%s(%d): Simulating bootcode failure.\n",
			__FILE__, __LINE__);
		reg = 0);
d3022 3
a3024 3
			"Expected: 08%08X\n", __FILE__, __LINE__,
			(reg & BNX_DEV_INFO_SIGNATURE_MAGIC_MASK),
			BNX_DEV_INFO_SIGNATURE_MAGIC);
d3031 2
a3032 1
	if (reg & (BNX_PORT_FEATURE_ASF_ENABLED | BNX_PORT_FEATURE_IMD_ENABLED)) {
d3037 3
a3039 1
	sc->bnx_fw_ver = REG_RD_IND(sc, sc->bnx_shmem_base + BNX_DEV_INFO_BC_REV);
d3070 2
a3071 2
bnx_get_buf(struct bnx_softc *sc, struct mbuf *m, u_int16_t *prod, u_int16_t *chain_prod, 
	u_int32_t *prod_bseq)
d3073 5
a3077 5
	bus_dmamap_t			map;
	struct mbuf 			*m_new = NULL;
	struct rx_bd			*rxbd;
	int				i, rc = 0;
	u_int32_t			addr;
d3083 1
a3083 1
		__FUNCTION__);
d3087 2
a3088 2
		printf("%s: RX producer out of range: 0x%04X > 0x%04X\n",
		*chain_prod, (u_int16_t) MAX_RX_BD));
d3090 3
a3092 2
	DBPRINT(sc, BNX_VERBOSE_RECV, "%s(enter): prod = 0x%04X, chain_prod = 0x%04X, "
		"prod_bseq = 0x%08X\n", __FUNCTION__, *prod, *chain_prod, *prod_bseq);
d3095 4
a3099 3
		DBRUNIF(DB_RANDOMTRUE(bnx_debug_mbuf_allocation_failure),
			BNX_PRINTF(sc, "%s(%d): Simulating mbuf allocation failure.\n",
				__FILE__, __LINE__);
d3107 3
a3109 3

			DBPRINT(sc, BNX_WARN, "%s(%d): RX mbuf header allocation failed!\n", 
				__FILE__, __LINE__);
d3123 3
a3125 3

			DBPRINT(sc, BNX_WARN, "%s(%d): RX mbuf chain allocation failed!\n", 
				__FILE__, __LINE__);
d3147 1
a3147 1
			__FILE__, __LINE__);
d3159 2
a3160 2
		printf("%s: Too many free rx_bd (0x%04X > 0x%04X)!\n", 
			sc->free_rx_bd, (u_int16_t) USABLE_RX_BD));
d3163 1
a3163 1
		sc->rx_low_watermark = sc->free_rx_bd);
d3169 1
a3169 1
	rxbd->rx_bd_haddr_lo  = htole32(addr);
d3171 3
a3173 3
	rxbd->rx_bd_haddr_hi  = htole32(addr);
	rxbd->rx_bd_len       = htole32(map->dm_segs[0].ds_len);
	rxbd->rx_bd_flags     = htole32(RX_BD_FLAGS_START);
a3176 1

d3180 2
a3181 1
		rxbd = &sc->rx_bd_chain[RX_PAGE(*chain_prod)][RX_IDX(*chain_prod)];
d3184 1
a3184 1
		rxbd->rx_bd_haddr_lo  = htole32(addr);
d3186 3
a3188 3
		rxbd->rx_bd_haddr_hi  = htole32(addr);
		rxbd->rx_bd_len       = htole32(map->dm_segs[i].ds_len);
		rxbd->rx_bd_flags     = 0;
d3199 1
a3199 1
		map->dm_nsegs));
d3201 3
a3203 2
	DBPRINT(sc, BNX_VERBOSE_RECV, "%s(exit): prod = 0x%04X, chain_prod = 0x%04X, "
		"prod_bseq = 0x%08X\n", __FUNCTION__, *prod, *chain_prod, *prod_bseq);
d3207 1
a3207 1
		__FUNCTION__);
d3221 3
a3223 3
	struct tx_bd *txbd;
	u_int32_t val, addr;
	int i, rc = 0;
d3228 3
a3230 3
	sc->tx_prod        = 0;
	sc->tx_cons        = 0;
	sc->tx_prod_bseq   = 0;
d3294 1
a3294 1
	int i;
d3318 2
a3319 3
		printf("%s: Memory leak! Lost %d mbufs "
			"from tx chain!\n",
			sc->tx_mbuf_alloc));
d3333 4
a3336 4
	struct rx_bd *rxbd;
	int i, rc = 0;
	u_int16_t prod, chain_prod;
	u_int32_t prod_bseq, val, addr;
d3341 4
a3344 4
	sc->rx_prod        = 0;
	sc->rx_cons        = 0;
	sc->rx_prod_bseq   = 0;
	sc->free_rx_bd     = BNX_RX_SLACK_SPACE;
d3384 1
a3384 1
				chain_prod);
d3392 1
a3392 1
	sc->rx_prod      = prod;
d3395 1
a3395 1
	for (i = 0; i < RX_PAGES; i++) {
a3398 1
	}
d3420 1
a3420 1
	int i;
d3444 2
a3445 2
		printf("%s: Memory leak! Lost %d mbufs from rx chain!\n",
			sc->rx_mbuf_alloc));
d3459 4
a3462 4
	struct bnx_softc *sc;
	struct mii_data *mii;
	struct ifmedia *ifm;
	int rc = 0;
d3491 3
a3493 3
	struct bnx_softc *sc;
	struct mii_data *mii;
	int s;
d3519 1
a3519 1
	u_int32_t new_link_state, old_link_state;
d3522 1
a3522 1
		STATUS_ATTN_BITS_LINK_STATE;
d3524 1
a3524 1
		STATUS_ATTN_BITS_LINK_STATE;
a3527 1

d3537 1
a3537 1
				STATUS_ATTN_BITS_LINK_STATE);
d3541 1
a3541 1
				STATUS_ATTN_BITS_LINK_STATE);
a3543 1

d3559 7
a3565 6
	struct status_block *sblk = sc->status_block;
	struct ifnet *ifp = &sc->arpcom.ac_if;
	u_int16_t hw_cons, sw_cons, sw_chain_cons, sw_prod, sw_chain_prod;
	u_int32_t sw_prod_bseq;
	struct l2_fhdr *l2fhdr;
	int i;
d3587 2
a3588 3
		"sw_cons = 0x%04X, sw_prod_bseq = 0x%08X\n",
		__FUNCTION__, sw_prod, sw_cons, 
		sw_prod_bseq);
d3591 2
a3592 2
	bus_space_barrier(sc->bnx_btag, sc->bnx_bhandle, 0, 0, 
		BUS_SPACE_BARRIER_READ);
d3595 1
a3595 1
		sc->rx_low_watermark = sc->free_rx_bd);
d3607 3
a3609 1
		/* Convert the producer/consumer indices to an actual rx_bd index. */
d3617 2
a3618 3
		DBRUN(BNX_VERBOSE_RECV, 
			printf("%s(): ", __FUNCTION__); 
			bnx_dump_rxbd(sc, sw_chain_cons, rxbd));
a3621 1

d3624 2
a3625 2
				printf("%s: Unexpected mbuf found in rx_bd[0x%04X]!\n",
				sw_chain_cons);
d3628 5
a3632 4
			/* DRC - ToDo: If the received packet is small, say less */
			/*             than 128 bytes, allocate a new mbuf here, */
			/*             copy the data to that mbuf, and recycle   */
			/*             the mapped jumbo frame.                   */
d3661 2
a3662 2
				printf("Simulating l2_fhdr status error.\n");
				status = status | L2_FHDR_ERRORS_PHY_DECODE);
d3665 8
a3672 7
			DBRUNIF(((len < BNX_MIN_MTU) || (len > BNX_MAX_JUMBO_ETHER_MTU_VLAN)),
				printf("%s: Unusual frame size found. "
					"Min(%d), Actual(%d), Max(%d)\n", 
					(int) BNX_MIN_MTU, 
					len, (int) BNX_MAX_JUMBO_ETHER_MTU_VLAN);
				bnx_dump_mbuf(sc, m);
		 		bnx_breakpoint(sc));
d3678 4
a3681 3
				L2_FHDR_ERRORS_PHY_DECODE | L2_FHDR_ERRORS_ALIGNMENT | 
				L2_FHDR_ERRORS_TOO_SHORT  | L2_FHDR_ERRORS_GIANT_FRAME)) {

d3686 2
a3687 2
				if (bnx_get_buf(sc, m, &sw_prod, &sw_chain_prod, &sw_prod_bseq)) {

d3689 2
a3690 2
					panic("%s: Can't reuse RX mbuf!\n", sc->bnx_dev.dv_xname);

d3701 4
a3704 5
			if (bnx_get_buf(sc, NULL, &sw_prod, &sw_chain_prod, &sw_prod_bseq)) {

				DBRUN(BNX_WARN, 
					printf("%s: Failed to allocate "
					"new mbuf, incoming frame dropped!\n"));
d3709 2
a3710 2
				if (bnx_get_buf(sc, m, &sw_prod, &sw_chain_prod, &sw_prod_bseq)) {

d3712 2
a3713 2
					panic("%s: Double mbuf allocation failure!", sc->bnx_dev.dv_xname);

d3718 3
a3720 1
			/* Skip over the l2_fhdr when passing the data up the stack. */
d3723 1
a3723 1
			/* Adjust the packet length to match the received data. */
d3730 5
a3734 5
				struct ether_header *eh;
				eh = mtod(m, struct ether_header *);
				printf("%s: to: %6D, from: %6D, type: 0x%04X\n",
					__FUNCTION__, eh->ether_dhost, ":", 
					eh->ether_shost, ":", htons(eh->ether_type)));
a3738 1

d3741 2
a3742 1
					m->m_pkthdr.csum_flags |= CSUM_IP_CHECKED;
d3745 4
a3748 2
					if ((l2fhdr->l2_fhdr_ip_xsum ^ 0xffff) == 0)
						m->m_pkthdr.csum_flags |= CSUM_IP_VALID;
d3751 5
a3755 2
							"%s(): Invalid IP checksum = 0x%04X!\n",
							__FUNCTION__, l2fhdr->l2_fhdr_ip_xsum);
d3760 1
a3760 2
					L2_FHDR_STATUS_UDP_DATAGRAM)) {

d3762 8
a3769 7
					if ((status & (L2_FHDR_ERRORS_TCP_XSUM |
						      L2_FHDR_ERRORS_UDP_XSUM)) == 0) {
						m->m_pkthdr.csum_data =
						    l2fhdr->l2_fhdr_tcp_udp_xsum;
						m->m_pkthdr.csum_flags |= (CSUM_DATA_VALID 
							| CSUM_PSEUDO_HDR);
					} else
d3771 5
a3775 2
							"%s(): Invalid TCP/UDP checksum = 0x%04X!\n",
							__FUNCTION__, l2fhdr->l2_fhdr_tcp_udp_xsum);
d3791 2
a3792 2
			DBPRINT(sc, BNX_VERBOSE_RECV, "%s(): Passing received frame up.\n",
				__FUNCTION__);
d3804 4
a3807 2
			hw_cons = sc->hw_rx_cons = sblk->status_rx_quick_consumer_index0;
			if ((hw_cons & USABLE_RX_BD_PER_PAGE) == USABLE_RX_BD_PER_PAGE)
d3811 3
a3813 1
		/* Prevent speculative reads from getting ahead of the status block. */
d3815 1
a3815 1
			BUS_SPACE_BARRIER_READ);
d3832 2
a3833 2
		"rx_cons = 0x%04X, rx_prod_bseq = 0x%08X\n",
		__FUNCTION__, sc->rx_prod, sc->rx_cons, sc->rx_prod_bseq);
d3845 3
a3847 3
	struct status_block *sblk = sc->status_block;
	struct ifnet *ifp = &sc->arpcom.ac_if;
	u_int16_t hw_tx_cons, sw_tx_cons, sw_tx_chain_cons;
d3862 1
a3862 1
		BUS_SPACE_BARRIER_READ);
d3871 3
a3873 4
		DBPRINT(sc, BNX_INFO_SEND,
			"%s(): hw_tx_cons = 0x%04X, sw_tx_cons = 0x%04X, "
			"sw_tx_chain_cons = 0x%04X\n",
			__FUNCTION__, hw_tx_cons, sw_tx_cons, sw_tx_chain_cons);
d3876 3
a3878 5
			printf("%s: TX chain consumer out of range! "
				" 0x%04X > 0x%04X\n",
				sw_tx_chain_cons, 
				(int) MAX_TX_BD);
			bnx_breakpoint(sc));
d3880 2
a3881 3
		DBRUNIF(1,
			txbd = &sc->tx_bd_chain[TX_PAGE(sw_tx_chain_cons)]
				[TX_IDX(sw_tx_chain_cons)]);
d3884 3
a3886 3
			printf("%s: Unexpected NULL tx_bd[0x%04X]!\n", 
				sw_tx_chain_cons);
			bnx_breakpoint(sc));
d3888 2
a3889 3
		DBRUN(BNX_INFO_SEND, 
			printf("%s: ", __FUNCTION__);
			bnx_dump_txbd(sc, sw_tx_chain_cons, txbd));
a3896 1

d3898 10
a3907 8
			DBRUNIF((!(txbd->tx_bd_vlan_tag_flags & TX_BD_FLAGS_END)),
				printf("%s: tx_bd END flag not set but "
				"txmbuf == NULL!\n");
				bnx_breakpoint(sc));

			DBRUN(BNX_INFO_SEND, 
				printf("%s: Unloading map/freeing mbuf "
					"from tx_bd[0x%04X]\n", __FUNCTION__, sw_tx_chain_cons));
d3925 4
a3928 2
		hw_tx_cons = sc->hw_tx_cons = sblk->status_tx_quick_consumer_index0;
		if ((hw_tx_cons & USABLE_TX_BD_PER_PAGE) == USABLE_TX_BD_PER_PAGE)
d3931 3
a3933 1
		/* Prevent speculative reads from getting ahead of the status block. */
d3935 1
a3935 1
			BUS_SPACE_BARRIER_READ);
d3944 2
a3945 2
			printf("%s: TX chain is open for business! Used tx_bd = %d\n", 
				sc->used_tx_bd));
d3961 1
a3961 2
	REG_WR(sc, BNX_PCICFG_INT_ACK_CMD,
	       BNX_PCICFG_INT_ACK_CMD_MASK_INT);
d3974 1
a3974 1
	u_int32_t val;
d3976 2
a3977 3
	REG_WR(sc, BNX_PCICFG_INT_ACK_CMD,
	       BNX_PCICFG_INT_ACK_CMD_INDEX_VALID |
	       BNX_PCICFG_INT_ACK_CMD_MASK_INT | sc->last_status_idx);
d3979 2
a3980 2
	REG_WR(sc, BNX_PCICFG_INT_ACK_CMD,
	       BNX_PCICFG_INT_ACK_CMD_INDEX_VALID | sc->last_status_idx);
d3995 4
a3998 4
	struct bnx_softc *sc = (struct bnx_softc *)xsc;
	struct ifnet *ifp = &sc->arpcom.ac_if;
	u_int32_t ether_mtu;
	int s;
d4032 2
a4033 1
	DBPRINT(sc, BNX_INFO, "%s(): setting mtu = %d\n",__FUNCTION__, ether_mtu);
d4052 3
a4054 4
	DBPRINT(sc, BNX_INFO, 
		"%s(): mclbytes = %d, mbuf_alloc_size = %d, "
		"max_frame_size = %d\n",
		__FUNCTION__, (int) MCLBYTES, sc->mbuf_alloc_size, sc->max_frame_size);
d4092 1
a4092 1
	u_int16_t *chain_prod, u_int32_t *prod_bseq)
d4094 4
a4097 1
	u_int32_t vlan_tag_flags = 0;
d4099 1
a4099 1
	struct m_tag *mtag;
a4100 3
	struct bnx_dmamap_arg map_arg;
	bus_dmamap_t map;
	int i, rc = 0;
d4117 1
a4117 1
			(VLAN_TAG_VALUE(mtag) << 16));
d4122 2
a4123 2
	map_arg.sc         = sc;
	map_arg.prod       = *prod;
d4125 3
a4127 4
	map_arg.prod_bseq  = *prod_bseq;
	map_arg.tx_flags   = vlan_tag_flags;
	map_arg.maxsegs    = USABLE_TX_BD - sc->used_tx_bd - 
		BNX_TX_SLACK_SPACE;
d4155 1
a4155 2
	sc->tx_mbuf_map[*chain_prod] = 
		sc->tx_mbuf_map[map_arg.chain_prod];
d4160 2
a4161 2
	DBRUNIF((sc->used_tx_bd > sc->tx_hi_watermark), 
		sc->tx_hi_watermark = sc->used_tx_bd);
d4166 1
a4166 1
		map_arg.maxsegs));
d4169 1
a4169 1
	*prod       = map_arg.prod;
d4171 1
a4171 1
	*prod_bseq  = map_arg.prod_bseq;
@


1.12
log
@First in a series of KNF.  No functional change.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.11 2006/08/14 16:58:56 brad Exp $	*/
d1430 1
a1430 1
	int buf_size)
d1432 2
a1433 2
	int rc = 0;
	u_int32_t cmd_flags, offset32, len32, extra;
d1436 1
a1436 1
		return 0;
d1440 1
a1440 1
		return rc;
d1460 3
a1462 3
			cmd_flags = BNX_NVM_COMMAND_FIRST | BNX_NVM_COMMAND_LAST;
		}
		else {
a1463 1
		}
d1468 1
a1468 1
			return rc;
d1488 2
a1489 2
			cmd_flags = BNX_NVM_COMMAND_FIRST |
				    BNX_NVM_COMMAND_LAST;
d1494 1
a1494 2
	}
	else if (len32 > 0) {
d1520 1
a1520 1
			return rc;
d1532 1
a1532 1
	return rc;
d1548 1
a1548 1
	int buf_size)
d1550 4
a1553 4
	u_int32_t written, offset32, len32;
	u_int8_t *buf, start[4], end[4];
	int rc = 0;
	int align_start, align_end;
d1564 1
a1564 1
			return rc;
d1572 2
a1573 2
				end, 4))) {
				return rc;
d1581 3
a1583 2
			return ENOMEM;
		if (align_start) {
d1585 2
a1586 2
		}
		if (align_end) {
d1588 1
a1588 1
		}
d1608 1
a1608 1
			(offset32 + len32) : page_end;
d1624 1
a1624 1
				if (j == (sc->bnx_flash_info->page_size - 4)) {
d1626 1
a1626 1
				}
d1658 1
a1658 1
					&flash_buffer[i], cmd_flags);
d1670 2
a1671 2
				((sc->bnx_flash_info->buffered) &&
				 (addr == data_end - 4))) {
d1675 2
a1676 2
			rc = bnx_nvram_write_dword(sc, addr, buf,
				cmd_flags);
d1689 1
a1689 1
				addr += 4, i += 4) {
d1691 1
a1691 1
				if (addr == page_end-4) {
d1693 1
a1693 1
                		}
d1695 1
a1695 1
					&flash_buffer[i], cmd_flags);
d1719 1
a1719 1
	return rc;
d1735 4
a1738 4
	u_int32_t buf[BNX_NVRAM_SIZE / 4];
	u_int8_t *data = (u_int8_t *) buf;
	int rc = 0;
	u_int32_t magic, csum;
d1750 3
a1752 3
		BNX_PRINTF(sc, "%s(%d): Invalid NVRAM magic value! Expected: 0x%08X, "
			"Found: 0x%08X\n",
			__FILE__, __LINE__, BNX_NVRAM_MAGIC, magic);
d1766 3
a1768 3
		BNX_PRINTF(sc, "%s(%d): Invalid Manufacturing Information NVRAM CRC! "
			"Expected: 0x%08X, Found: 0x%08X\n",
			__FILE__, __LINE__, BNX_CRC32_RESIDUAL, csum);
d1774 3
a1776 3
		BNX_PRINTF(sc, "%s(%d): Invalid Feature Configuration Information "
			"NVRAM CRC! Expected: 0x%08X, Found: 08%08X\n",
			__FILE__, __LINE__, BNX_CRC32_RESIDUAL, csum);
d1781 1
a1781 1
	return rc;
d1796 1
a1796 1
	int i;
d1828 2
a1829 1
			bus_dmamap_unload(sc->bnx_dmatag, sc->tx_bd_chain_map[i]);
d1834 2
a1835 1
			bus_dmamap_destroy(sc->bnx_dmatag, sc->tx_bd_chain_map[i]);
d1853 2
a1854 1
			bus_dmamap_unload(sc->bnx_dmatag, sc->rx_bd_chain_map[i]);
d1860 2
a1861 1
			bus_dmamap_destroy(sc->bnx_dmatag, sc->rx_bd_chain_map[i]);
d1890 6
a1895 6
	struct bnx_dmamap_arg *map_arg;
	struct bnx_softc *sc;
	struct tx_bd *txbd = NULL;
	int i = 0, nseg;
	u_int16_t prod, chain_prod;
	u_int32_t	prod_bseq, addr;
d1897 1
a1897 1
	u_int16_t debug_prod;
d1906 3
a1908 4
		DBPRINT(sc, BNX_WARN,
			"%s(): Mapped TX descriptors: max segs = %d, "
			"actual segs = %d\n",
			__FUNCTION__, map_arg->maxsegs, nseg);
d1915 1
a1915 1
	prod       = map_arg->prod;
d1917 1
a1917 1
	prod_bseq  = map_arg->prod_bseq;
d1923 3
a1925 4
	DBPRINT(sc, BNX_INFO_SEND,
		"%s(): Start: prod = 0x%04X, chain_prod = %04X, "
		"prod_bseq = 0x%08X\n",
		__FUNCTION__, prod, chain_prod, prod_bseq);
d1938 1
a1938 1
	txbd->tx_bd_haddr_lo       = htole32(addr);
d1940 2
a1941 2
	txbd->tx_bd_haddr_hi       = htole32(addr);
	txbd->tx_bd_mss_nbytes     = htole16(map->dm_segs[i].ds_len);
d1943 1
a1943 1
			TX_BD_FLAGS_START);
d1948 1
a1948 1
		prod       = NEXT_TX_BD(prod);
d1951 2
a1952 1
		txbd = &map_arg->tx_chain[TX_PAGE(chain_prod)][TX_IDX(chain_prod)];
d1955 1
a1955 1
		txbd->tx_bd_haddr_lo       = htole32(addr);
d1957 2
a1958 2
		txbd->tx_bd_haddr_hi       = htole32(addr);
		txbd->tx_bd_mss_nbytes     = htole16(map->dm_segs[i].ds_len);
d1969 3
a1971 4
	DBPRINT(sc, BNX_INFO_SEND,
		"%s(): End: prod = 0x%04X, chain_prod = %04X, "
		"prod_bseq = 0x%08X\n",
		__FUNCTION__, prod, chain_prod, prod_bseq);
d1974 2
a1975 2
	map_arg->maxsegs    = nseg;
	map_arg->prod       = prod;
d1977 1
a1977 1
	map_arg->prod_bseq  = prod_bseq;
d1992 1
a1992 1
	int i, rc = 0;
d2074 1
a2074 1
		(u_int32_t) sc->stats_block_paddr);
d2092 2
a2093 1
			printf(": Could not allocate TX desc %d DMA memory!\n", i);
d2114 2
a2115 1
		sc->tx_bd_chain_paddr[i] = sc->tx_bd_chain_map[i]->dm_segs[0].ds_addr;
d2119 1
a2119 1
			i, (u_int32_t) sc->tx_bd_chain_paddr[i]);
d2153 2
a2154 1
			printf(": Could not allocate Rx desc %d DMA memory!\n", i);
d2176 2
a2177 1
		sc->rx_bd_chain_paddr[i] = sc->rx_bd_chain_map[i]->dm_segs[0].ds_addr;
d2181 1
a2181 1
			i, (u_int32_t) sc->rx_bd_chain_paddr[i]);
d2215 1
a2215 1
	struct pci_attach_args *pa = &(sc->bnx_pa);
d2242 2
a2243 2
	int i, rc = 0;
	u_int32_t val;
d2255 2
a2256 1
 	DBPRINT(sc, BNX_VERBOSE, "bnx_fw_sync(): msg_data = 0x%08X\n", msg_data);
a2272 1

d2274 1
a2274 2
			"msg_data = 0x%08X\n",
			__FILE__, __LINE__, msg_data);
d2297 1
a2297 1
	u_int32_t rv2p_code_len, u_int32_t rv2p_proc)
d2299 2
a2300 2
	int i;
	u_int32_t val;
d2319 1
a2319 1
	if (rv2p_proc == RV2P_PROC1) {
d2321 1
a2321 2
	}
	else {
a2322 1
	}
d2336 1
a2336 1
	struct fw_info *fw)
d2338 2
a2339 2
	u_int32_t offset;
	u_int32_t val;
d2352 1
a2352 1
		for (j = 0; j < (fw->text_len / 4); j++, offset += 4) {
a2353 1
	        }
d2361 1
a2361 1
		for (j = 0; j < (fw->data_len / 4); j++, offset += 4) {
a2362 1
		}
d2370 1
a2370 1
		for (j = 0; j < (fw->sbss_len / 4); j++, offset += 4) {
a2371 1
		}
d2379 1
a2379 1
		for (j = 0; j < (fw->bss_len/4); j++, offset += 4) {
a2380 1
		}
d2385 1
a2385 1
		(fw->rodata_addr - cpu_reg->mips_view_base);
d2389 1
a2389 1
		for (j = 0; j < (fw->rodata_len / 4); j++, offset += 4) {
a2390 1
		}
d2419 4
a2422 2
	bnx_load_rv2p_fw(sc, bnx_rv2p_proc1, sizeof(bnx_rv2p_proc1), RV2P_PROC1);
	bnx_load_rv2p_fw(sc, bnx_rv2p_proc2, sizeof(bnx_rv2p_proc2), RV2P_PROC2);
d2624 1
a2624 1
	u_int32_t vcid;
d2639 1
a2639 1
		for (offset = 0; offset < PHY_CTX_SIZE; offset += 4) {
a2640 1
		}
d2656 1
a2656 1
	u_int32_t mac_lo = 0, mac_hi = 0;
d2667 2
a2668 4
	mac_hi = REG_RD_IND(sc, sc->bnx_shmem_base +
		BNX_PORT_HW_CFG_MAC_UPPER);
	mac_lo = REG_RD_IND(sc, sc->bnx_shmem_base +
		BNX_PORT_HW_CFG_MAC_LOWER);
d2672 1
a2672 1
			__FILE__, __LINE__);
d2682 2
a2683 1
	DBPRINT(sc, BNX_INFO, "Permanent Ethernet address = %6D\n", sc->eaddr, ":");
d2695 2
a2696 2
	u_int32_t val;
	u_int8_t *mac_addr = sc->eaddr;
d2698 2
a2699 1
	DBPRINT(sc, BNX_INFO, "Setting Ethernet address = %6D\n", sc->eaddr, ":");
d2720 4
a2723 4
	struct ifnet *ifp = &sc->arpcom.ac_if;
	struct ifmedia_entry *ifm;
	struct mii_data *mii = NULL;
	int mtmp, itmp;
d2780 2
a2781 2
	u_int32_t val;
	int i, rc = 0;
d2787 4
a2790 4
	       BNX_MISC_ENABLE_CLR_BITS_TX_DMA_ENABLE |
	       BNX_MISC_ENABLE_CLR_BITS_DMA_ENGINE_ENABLE |
	       BNX_MISC_ENABLE_CLR_BITS_RX_DMA_ENABLE |
	       BNX_MISC_ENABLE_CLR_BITS_HOST_COALESCE_ENABLE);
d2804 1
a2804 1
		   BNX_DRV_RESET_SIGNATURE_MAGIC);
d2811 2
a2812 2
	      BNX_PCICFG_MISC_CONFIG_REG_WINDOW_ENA |
	      BNX_PCICFG_MISC_CONFIG_TARGET_MB_WORD_SWAP;
d2819 1
a2819 1
			    BNX_PCICFG_MISC_CONFIG_CORE_RST_BSY)) == 0) {
d2821 1
a2821 1
		}
d2827 2
a2828 3
		   BNX_PCICFG_MISC_CONFIG_CORE_RST_BSY)) {
		BNX_PRINTF(sc, "%s(%d): Reset failed!\n",
			__FILE__, __LINE__);
d2837 1
a2837 1
			__FILE__, __LINE__);
d2848 2
a2849 2
		BNX_PRINTF(sc, "%s(%d): Firmware did not complete initialization!\n",
			__FILE__, __LINE__);
d2860 3
a2862 3
	struct pci_attach_args *pa = &(sc->bnx_pa);
	u_int32_t val;
	int rc = 0;
d2872 1
a2872 1
	      BNX_DMA_CONFIG_DATA_WORD_SWAP |
d2874 1
a2874 1
	      BNX_DMA_CONFIG_CNTL_BYTE_SWAP |
d2876 3
a2878 3
	      BNX_DMA_CONFIG_CNTL_WORD_SWAP |
	      DMA_READ_CHANS << 12 |
	      DMA_WRITE_CHANS << 16;
d2902 2
a2903 1
		pci_conf_write(pa->pa_pc, pa->pa_tag, BNX_PCI_PCIX_CMD, val & ~0x2);
d2908 3
a2910 3
	       BNX_MISC_ENABLE_SET_BITS_HOST_COALESCE_ENABLE |
	       BNX_MISC_ENABLE_STATUS_BITS_RX_V2P_ENABLE |
	       BNX_MISC_ENABLE_STATUS_BITS_CONTEXT_ENABLE);
@


1.11
log
@disable debugging.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.10 2006/08/14 16:07:39 marco Exp $	*/
d347 8
a354 8
	struct bnx_softc *sc = (struct bnx_softc *)self;
	struct pci_attach_args *pa = aux;
	pci_chipset_tag_t pc = pa->pa_pc;
	pci_intr_handle_t ih;
	const char *intrstr = NULL;
	struct ifnet *ifp;
	u_int32_t val;
	pcireg_t memtype;
d388 2
a389 2
			       BNX_PCICFG_MISC_CONFIG_REG_WINDOW_ENA |
			       BNX_PCICFG_MISC_CONFIG_TARGET_MB_WORD_SWAP);
d396 8
a403 8
		case BNX_CHIP_ID_5706_A0:
		case BNX_CHIP_ID_5706_A1:
		case BNX_CHIP_ID_5708_A0:
		case BNX_CHIP_ID_5708_B0:
			printf(": unsupported controller revision (%c%d)!\n",
				(((pci_conf_read(pa->pa_pc, pa->pa_tag, 0x08) & 0xf0) >> 4) + 'A'),
			    (pci_conf_read(pa->pa_pc, pa->pa_tag, 0x08) & 0xf));
			goto bnx_attach_fail;
d475 1
a475 2
	} else {
		if (val & BNX_PCICFG_MISC_STATUS_M66EN)
a478 1
	}
a643 1

d700 1
a700 1
	struct bnx_softc *sc = (struct bnx_softc *)xsc;
d719 1
a719 1
	struct pci_attach_args *pa = &(sc->bnx_pa);
d721 2
a722 1
	pci_conf_write(pa->pa_pc, pa->pa_tag, BNX_PCICFG_REG_WINDOW_ADDRESS, offset);
d726 5
a730 4
		val = pci_conf_read(pa->pa_pc, pa->pa_tag, BNX_PCICFG_REG_WINDOW);
		DBPRINT(sc, BNX_EXCESSIVE, "%s(); offset = 0x%08X, val = 0x%08X\n",
			__FUNCTION__, offset, val);
		return val;
d755 2
a756 1
	pci_conf_write(pa->pa_pc, pa->pa_tag, BNX_PCICFG_REG_WINDOW_ADDRESS, offset);
d770 2
a771 1
bnx_ctx_wr(struct bnx_softc *sc, u_int32_t cid_addr, u_int32_t offset, u_int32_t val)
d793 3
a795 3
	struct bnx_softc *sc = (struct bnx_softc *)dev;
	u_int32_t val;
	int i;
d799 2
a800 1
		DBPRINT(sc, BNX_VERBOSE, "Invalid PHY address %d for PHY read!\n", phy);
d815 2
a816 2
		BNX_EMAC_MDIO_COMM_COMMAND_READ | BNX_EMAC_MDIO_COMM_DISEXT |
		BNX_EMAC_MDIO_COMM_START_BUSY;
d834 2
a835 2
		BNX_PRINTF(sc, "%s(%d): Error: PHY read timeout! phy = %d, reg = 0x%04X\n",
			__FILE__, __LINE__, phy, reg);
d837 1
a837 1
	} else {
a838 1
	}
d840 3
a842 2
	DBPRINT(sc, BNX_EXCESSIVE, "%s(): phy = %d, reg = 0x%04X, val = 0x%04X\n",
		__FUNCTION__, phy, (u_int16_t) reg & 0xffff, (u_int16_t) val & 0xffff);
a854 1

d868 3
a870 3
	struct bnx_softc *sc = (struct bnx_softc *)dev;
	u_int32_t val1;
	int i;
d874 2
a875 1
		DBPRINT(sc, BNX_WARN, "Invalid PHY address %d for PHY write!\n", phy);
d879 3
a881 2
	DBPRINT(sc, BNX_EXCESSIVE, "%s(): phy = %d, reg = 0x%04X, val = 0x%04X\n",
		__FUNCTION__, phy, (u_int16_t) reg & 0xffff, (u_int16_t) val & 0xffff);
d894 2
a895 2
		BNX_EMAC_MDIO_COMM_COMMAND_WRITE |
		BNX_EMAC_MDIO_COMM_START_BUSY | BNX_EMAC_MDIO_COMM_DISEXT;
d908 4
a911 3
	if (val1 & BNX_EMAC_MDIO_COMM_START_BUSY)
		BNX_PRINTF(sc, "%s(%d): PHY write timeout!\n",
			__FILE__, __LINE__);
d936 2
a937 2
	struct bnx_softc *sc = (struct bnx_softc *)dev;
	struct mii_data *mii = &sc->bnx_mii;
d950 3
a952 1
	/* Set half or full duplex based on the duplicity negotiated by the PHY. */
a961 1

d975 2
a976 2
	u_int32_t val;
	int j;
d992 1
a992 1
		return EBUSY;
d995 1
a995 1
	return 0;
d1011 2
a1012 2
	int j;
	u_int32_t val;
d1016 1
a1016 3
	/*
	 * Relinquish nvram interface.
	 */
d1029 1
a1029 1
		return EBUSY;
d1032 1
a1032 1
	return 0;
d1047 1
a1047 1
	u_int32_t val;
d1058 2
a1059 1
		REG_WR(sc, BNX_NVM_COMMAND,	BNX_NVM_COMMAND_WREN | BNX_NVM_COMMAND_DOIT);
d1071 1
a1071 1
			return EBUSY;
d1074 2
a1075 1
	return 0;
d1090 1
a1090 1
	u_int32_t val;
d1111 1
a1111 1
	u_int32_t val;
d1118 1
a1118 1
	       val | BNX_NVM_ACCESS_ENABLE_EN | BNX_NVM_ACCESS_ENABLE_WR_EN);
d1132 1
a1132 1
	u_int32_t val;
d1140 1
a1140 2
		val & ~(BNX_NVM_ACCESS_ENABLE_EN |
			BNX_NVM_ACCESS_ENABLE_WR_EN));
d1156 2
a1157 2
	u_int32_t cmd;
	int j;
d1161 1
a1161 1
		return 0;
d1167 1
a1167 1
	      BNX_NVM_COMMAND_DOIT;
d1190 1
a1190 1
		return EBUSY;
d1193 1
a1193 1
	return 0;
d1207 2
a1208 2
bnx_nvram_read_dword(struct bnx_softc *sc, u_int32_t offset, u_int8_t *ret_val,
							u_int32_t cmd_flags)
d1210 2
a1211 2
	u_int32_t cmd;
	int i, rc = 0;
d1217 1
a1217 1
	if (sc->bnx_flash_info->buffered) {
d1219 2
a1220 3
			   sc->bnx_flash_info->page_bits) +
			  (offset % sc->bnx_flash_info->page_size);
	}
d1248 2
a1249 2
		BNX_PRINTF(sc, "%s(%d): Timeout error reading NVRAM at offset 0x%08X!\n",
			__FILE__, __LINE__, offset);
d1269 1
a1269 1
	u_int32_t cmd_flags)
d1271 2
a1272 2
	u_int32_t cmd, val32;
	int j;
d1278 1
a1278 1
	if (sc->bnx_flash_info->buffered) {
d1280 2
a1281 3
			  sc->bnx_flash_info->page_bits) +
			 (offset % sc->bnx_flash_info->page_size);
	}
d1302 3
a1304 3
		BNX_PRINTF(sc, "%s(%d): Timeout error writing NVRAM at offset 0x%08X\n",
			__FILE__, __LINE__, offset);
		return EBUSY;
d1307 1
a1307 1
	return 0;
d1323 3
a1325 3
	u_int32_t val;
	int j, entry_count, rc;
	struct flash_spec *flash;
d1370 3
a1372 3
		for (j = 0, flash = &flash_table[0]; j < entry_count; j++, flash++) {

			/* Check if the device matches any of the known devices. */
d1379 1
a1379 1
					return rc;
d1411 2
a1412 2
	DBPRINT(sc, BNX_INFO_LOAD, "bnx_init_nvram() flash->total_size = 0x%08X\n",
		sc->bnx_flash_info->total_size);
d1414 1
a1414 1
	DBPRINT(sc,BNX_VERBOSE_RESET, "Exiting %s()\n", __FUNCTION__);
d1416 1
a1416 1
	return rc;
@


1.10
log
@Change bus_dmamap_create to use the appropriate values.  This fixes the
issues brad was seeing.  Help from jason.

ok brad.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.9 2006/08/13 19:29:46 marco Exp $	*/
a50 2

#define BNX_DEBUG
@


1.9
log
@Get rid of _HI & _LO macros altogether since they used a wrong idiom.
This was pointed out by mickey The driver now uses the same idiom as mpi.

help from miod, mickey and kettenis

ok brad
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.8 2006/08/13 06:39:58 brad Exp $	*/
d2123 4
a2126 2
		if (bus_dmamap_create(sc->bnx_dmatag, MCLBYTES * BNX_MAX_SEGMENTS,
		    BNX_MAX_SEGMENTS, MCLBYTES, 0, BUS_DMA_NOWAIT,
@


1.8
log
@fix a typo, BNX_DRBUG -> BNX_DEBUG
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.7 2006/08/10 04:25:15 brad Exp $	*/
d1892 1
a1892 1
	u_int32_t	prod_bseq;
d1936 4
a1939 2
	txbd->tx_bd_haddr_lo       = htole32(BNX_ADDR_LO(map->dm_segs[i].ds_addr));
	txbd->tx_bd_haddr_hi       = htole32(BNX_ADDR_HI(map->dm_segs[i].ds_addr));
d1952 4
a1955 2
		txbd->tx_bd_haddr_lo       = htole32(BNX_ADDR_LO(map->dm_segs[i].ds_addr));
		txbd->tx_bd_haddr_hi       = htole32(BNX_ADDR_HI(map->dm_segs[i].ds_addr));
d2980 1
a2980 1
		BNX_ADDR_LO(sc->status_block_paddr));
d2982 1
a2982 1
		BNX_ADDR_HI(sc->status_block_paddr));
d2986 1
a2986 1
		BNX_ADDR_LO(sc->stats_block_paddr));
d2988 1
a2988 1
		BNX_ADDR_HI(sc->stats_block_paddr));
d3075 5
a3079 4
	bus_dmamap_t		map;
	struct mbuf *m_new = NULL;
	struct rx_bd		*rxbd;
	int i, rc = 0;
d3081 1
a3081 1
	u_int16_t debug_chain_prod = *chain_prod;
d3168 4
a3171 2
	rxbd->rx_bd_haddr_lo  = htole32(BNX_ADDR_LO(map->dm_segs[0].ds_addr));
	rxbd->rx_bd_haddr_hi  = htole32(BNX_ADDR_HI(map->dm_segs[0].ds_addr));
d3183 4
a3186 2
		rxbd->rx_bd_haddr_lo  = htole32(BNX_ADDR_LO(map->dm_segs[i].ds_addr));
		rxbd->rx_bd_haddr_hi  = htole32(BNX_ADDR_HI(map->dm_segs[i].ds_addr));
d3221 1
a3221 1
	u_int32_t val;
d3255 4
a3258 2
		txbd->tx_bd_haddr_hi = htole32(BNX_ADDR_HI(sc->tx_bd_chain_paddr[j]));
		txbd->tx_bd_haddr_lo = htole32(BNX_ADDR_LO(sc->tx_bd_chain_paddr[j]));
d3272 1
a3272 1
	val = BNX_ADDR_HI(sc->tx_bd_chain_paddr[0]);
d3274 1
a3274 1
	val = BNX_ADDR_LO(sc->tx_bd_chain_paddr[0]);
d3336 1
a3336 1
	u_int32_t prod_bseq, val;
d3360 4
a3363 2
		rxbd->rx_bd_haddr_hi = htole32(BNX_ADDR_HI(sc->rx_bd_chain_paddr[j]));
		rxbd->rx_bd_haddr_lo = htole32(BNX_ADDR_LO(sc->rx_bd_chain_paddr[j]));
d3373 1
a3373 1
	val = BNX_ADDR_HI(sc->rx_bd_chain_paddr[0]);
d3375 1
a3375 1
	val = BNX_ADDR_LO(sc->rx_bd_chain_paddr[0]);
a4850 1
	u_int32_t val_hi, val_lo;
d4860 2
a4861 4
		val_hi = BNX_ADDR_HI(mp);
		val_lo = BNX_ADDR_LO(mp);
		printf("mbuf: vaddr = 0x%08X:%08X, m_len = %d, m_flags = ", 
			   val_hi, val_lo, mp->m_len);
d4869 3
a4871 6
		if (mp->m_flags & M_EXT) {
			val_hi = BNX_ADDR_HI(mp->m_ext.ext_buf);
			val_lo = BNX_ADDR_LO(mp->m_ext.ext_buf);
			printf("- m_ext: vaddr = 0x%08X:%08X, ext_size = 0x%04X\n", 
				val_hi, val_lo, mp->m_ext.ext_size);
		}
d5381 4
a5384 1
	u_int32_t val_hi, val_lo;
d5386 5
a5390 4
	BNX_PRINTF(sc,
		"-----------------------------"
		" Driver State "
		"-----------------------------\n");
d5392 2
a5393 14
	val_hi = BNX_ADDR_HI(sc);
	val_lo = BNX_ADDR_LO(sc);
	BNX_PRINTF(sc, "0x%08X:%08X - (sc) driver softc structure virtual address\n",
		val_hi, val_lo);

	val_hi = BNX_ADDR_HI(sc->status_block);
	val_lo = BNX_ADDR_LO(sc->status_block);
	BNX_PRINTF(sc, "0x%08X:%08X - (sc->status_block) status block virtual address\n",
		val_hi, val_lo);

	val_hi = BNX_ADDR_HI(sc->stats_block);
	val_lo = BNX_ADDR_LO(sc->stats_block);
	BNX_PRINTF(sc, "0x%08X:%08X - (sc->stats_block) statistics block virtual address\n",
		val_hi, val_lo);
d5395 2
a5396 5
	val_hi = BNX_ADDR_HI(sc->tx_bd_chain);
	val_lo = BNX_ADDR_LO(sc->tx_bd_chain);
	BNX_PRINTF(sc,
		"0x%08X:%08X - (sc->tx_bd_chain) tx_bd chain virtual adddress\n",
		val_hi, val_lo);
d5398 2
a5399 5
	val_hi = BNX_ADDR_HI(sc->rx_bd_chain);
	val_lo = BNX_ADDR_LO(sc->rx_bd_chain);
	BNX_PRINTF(sc,
		"0x%08X:%08X - (sc->rx_bd_chain) rx_bd chain virtual address\n",
		val_hi, val_lo);
d5401 2
a5402 5
	val_hi = BNX_ADDR_HI(sc->tx_mbuf_ptr);
	val_lo = BNX_ADDR_LO(sc->tx_mbuf_ptr);
	BNX_PRINTF(sc,
		"0x%08X:%08X - (sc->tx_mbuf_ptr) tx mbuf chain virtual address\n",
		val_hi, val_lo);
d5404 2
a5405 5
	val_hi = BNX_ADDR_HI(sc->rx_mbuf_ptr);
	val_lo = BNX_ADDR_LO(sc->rx_mbuf_ptr);
	BNX_PRINTF(sc, 
		"0x%08X:%08X - (sc->rx_mbuf_ptr) rx mbuf chain virtual address\n",
		val_hi, val_lo);
d5408 1
a5408 1
		sc->interrupts_generated);
d5411 1
a5411 1
		sc->rx_interrupts);
d5414 1
a5414 1
		sc->tx_interrupts);
d5417 1
a5417 1
		sc->last_status_idx);
d5420 1
a5420 1
		sc->tx_prod);
d5423 1
a5423 1
		sc->tx_cons);
d5426 1
a5426 1
		sc->tx_prod_bseq);
d5429 1
a5429 1
		sc->rx_prod);
d5432 1
a5432 1
		sc->rx_cons);
d5435 1
a5435 1
		sc->rx_prod_bseq);
d5438 1
a5438 1
		sc->rx_mbuf_alloc);
d5441 1
a5441 1
		sc->free_rx_bd);
d5444 1
a5444 1
		sc->rx_low_watermark, (u_int32_t) USABLE_RX_BD);
d5447 1
a5447 1
		sc->tx_mbuf_alloc);
d5450 1
a5450 1
		sc->rx_mbuf_alloc);
d5453 1
a5453 1
		sc->used_tx_bd);
d5456 1
a5456 1
		sc->tx_hi_watermark, (u_int32_t) USABLE_TX_BD);
d5459 1
a5459 1
		sc->mbuf_alloc_failed);
d5461 2
a5462 4
	BNX_PRINTF(sc,
		"-----------------------------"
		"--------------"
		"-----------------------------\n");
@


1.7
log
@unmap memory address space in bnx_release_resources().
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.6 2006/08/10 04:13:09 brad Exp $	*/
d515 1
a515 1
#ifdef BNX_DRBUG
@


1.6
log
@cosmetic tweaking.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.5 2006/08/10 04:01:52 brad Exp $	*/
a356 1
	bus_size_t size;
d369 1
a369 1
		    NULL, &size, 0) == 0)
d2212 3
@


1.5
log
@remove typedef's.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.4 2006/08/09 15:49:49 marco Exp $	*/
d199 2
a200 2
int bnx_probe			(struct device *, void *, void *);
void bnx_attach			(struct device *, struct device *, void *);
d202 1
a202 1
void  bnx_detach		(void *);
d204 1
a204 1
void bnx_shutdown		(void *);
d210 13
a222 13
void bnx_dump_mbuf 		(struct bnx_softc *, struct mbuf *);
void bnx_dump_tx_mbuf_chain	(struct bnx_softc *, int, int);
void bnx_dump_rx_mbuf_chain	(struct bnx_softc *, int, int);
void bnx_dump_txbd		(struct bnx_softc *, int, struct tx_bd *);
void bnx_dump_rxbd		(struct bnx_softc *, int, struct rx_bd *);
void bnx_dump_l2fhdr		(struct bnx_softc *, int, struct l2_fhdr *);
void bnx_dump_tx_chain		(struct bnx_softc *, int, int);
void bnx_dump_rx_chain		(struct bnx_softc *, int, int);
void bnx_dump_status_block	(struct bnx_softc *);
void bnx_dump_stats_block	(struct bnx_softc *);
void bnx_dump_driver_state	(struct bnx_softc *);
void bnx_dump_hw_state		(struct bnx_softc *);
void bnx_breakpoint		(struct bnx_softc *);
d228 6
a233 6
u_int32_t bnx_reg_rd_ind		(struct bnx_softc *, u_int32_t);
void bnx_reg_wr_ind		(struct bnx_softc *, u_int32_t, u_int32_t);
void bnx_ctx_wr			(struct bnx_softc *, u_int32_t, u_int32_t, u_int32_t);
int bnx_miibus_read_reg		(struct device *, int, int);
void bnx_miibus_write_reg	(struct device *, int, int, int);
void bnx_miibus_statchg		(struct device *);
d238 9
a246 8
int bnx_acquire_nvram_lock	(struct bnx_softc *);
int bnx_release_nvram_lock	(struct bnx_softc *);
void bnx_enable_nvram_access	(struct bnx_softc *);
void bnx_disable_nvram_access	(struct bnx_softc *);
int bnx_nvram_read_dword	(struct bnx_softc *, u_int32_t, u_int8_t *, u_int32_t);
int bnx_init_nvram		(struct bnx_softc *);
int bnx_nvram_read		(struct bnx_softc *, u_int32_t, u_int8_t *, int);
int bnx_nvram_test		(struct bnx_softc *);
d248 6
a253 5
int bnx_enable_nvram_write	(struct bnx_softc *);
void bnx_disable_nvram_write	(struct bnx_softc *);
int bnx_nvram_erase_page	(struct bnx_softc *, u_int32_t);
int bnx_nvram_write_dword	(struct bnx_softc *, u_int32_t, u_int8_t *, u_int32_t);
int bnx_nvram_write		(struct bnx_softc *, u_int32_t, u_int8_t *, int);
d259 4
a262 4
int bnx_dma_alloc		(struct bnx_softc *);
void bnx_dma_free		(struct bnx_softc *);
void bnx_release_resources	(struct bnx_softc *);
void bnx_dma_map_tx_desc	(void *, bus_dmamap_t);
d267 41
a307 37
int bnx_fw_sync			(struct bnx_softc *, u_int32_t);
void bnx_load_rv2p_fw		(struct bnx_softc *, u_int32_t *, u_int32_t, u_int32_t);
void bnx_load_cpu_fw		(struct bnx_softc *, struct cpu_reg *, struct fw_info *);
void bnx_init_cpus		(struct bnx_softc *);

void bnx_stop			(struct bnx_softc *);
int bnx_reset			(struct bnx_softc *, u_int32_t);
int bnx_chipinit 		(struct bnx_softc *);
int bnx_blockinit 		(struct bnx_softc *);
int bnx_get_buf			(struct bnx_softc *, struct mbuf *, u_int16_t *, u_int16_t *, u_int32_t *);

int bnx_init_tx_chain		(struct bnx_softc *);
int bnx_init_rx_chain		(struct bnx_softc *);
void bnx_free_rx_chain		(struct bnx_softc *);
void bnx_free_tx_chain		(struct bnx_softc *);

int bnx_tx_encap		(struct bnx_softc *, struct mbuf *, u_int16_t *, u_int16_t *, u_int32_t *);
void bnx_start			(struct ifnet *);
int bnx_ioctl			(struct ifnet *, u_long, caddr_t);
void bnx_watchdog		(struct ifnet *);
int bnx_ifmedia_upd		(struct ifnet *);
void bnx_ifmedia_sts		(struct ifnet *, struct ifmediareq *);
void bnx_init			(void *);

void bnx_init_context		(struct bnx_softc *);
void bnx_get_mac_addr		(struct bnx_softc *);
void bnx_set_mac_addr		(struct bnx_softc *);
void bnx_phy_intr		(struct bnx_softc *);
void bnx_rx_intr		(struct bnx_softc *);
void bnx_tx_intr		(struct bnx_softc *);
void bnx_disable_intr		(struct bnx_softc *);
void bnx_enable_intr		(struct bnx_softc *);

int bnx_intr			(void *);
void bnx_set_rx_mode		(struct bnx_softc *);
void bnx_stats_update		(struct bnx_softc *);
void bnx_tick			(void *);
@


1.4
log
@Reorder dmamap & dmamem to match man page.
Redo detection of _LO & _HI macro; help from miod and jordan.
ok beck brad
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.3 2006/06/26 05:52:04 brad Exp $	*/
d66 1
a66 1
	u32 bnx_debug = BNX_WARN;
d228 3
a230 3
u32 bnx_reg_rd_ind		(struct bnx_softc *, u32);
void bnx_reg_wr_ind		(struct bnx_softc *, u32, u32);
void bnx_ctx_wr			(struct bnx_softc *, u32, u32, u32);
d242 1
a242 1
int bnx_nvram_read_dword	(struct bnx_softc *, u32, u8 *, u32);
d244 1
a244 1
int bnx_nvram_read		(struct bnx_softc *, u32, u8 *, int);
d249 3
a251 3
int bnx_nvram_erase_page	(struct bnx_softc *, u32);
int bnx_nvram_write_dword	(struct bnx_softc *, u32, u8 *, u32);
int bnx_nvram_write		(struct bnx_softc *, u32, u8 *, int);
d265 2
a266 2
int bnx_fw_sync			(struct bnx_softc *, u32);
void bnx_load_rv2p_fw		(struct bnx_softc *, u32 *, u32, u32);
d271 1
a271 1
int bnx_reset			(struct bnx_softc *, u32);
d274 1
a274 1
int bnx_get_buf			(struct bnx_softc *, struct mbuf *, u16 *, u16 *, u32 *);
d281 1
a281 1
int bnx_tx_encap		(struct bnx_softc *, struct mbuf *, u16 *, u16 *, u32 *);
d349 1
a349 1
	u32 val;
d440 1
a440 1
		u32 clkreg;
d716 2
a717 2
u32
bnx_reg_rd_ind(struct bnx_softc *sc, u32 offset)
d724 1
a724 1
		u32 val;
d746 1
a746 1
bnx_reg_wr_ind(struct bnx_softc *sc, u32 offset, u32 val)
d767 1
a767 1
bnx_ctx_wr(struct bnx_softc *sc, u32 cid_addr, u32 offset, u32 val)
d790 1
a790 1
	u32 val;
d837 1
a837 1
		__FUNCTION__, phy, (u16) reg & 0xffff, (u16) val & 0xffff);
d865 1
a865 1
	u32 val1;
d875 1
a875 1
		__FUNCTION__, phy, (u16) reg & 0xffff, (u16) val & 0xffff);
d967 1
a967 1
	u32 val;
d1004 1
a1004 1
	u32 val;
d1041 1
a1041 1
	u32 val;
d1082 1
a1082 1
	u32 val;
d1103 1
a1103 1
	u32 val;
d1124 1
a1124 1
	u32 val;
d1147 1
a1147 1
bnx_nvram_erase_page(struct bnx_softc *sc, u32 offset)
d1149 1
a1149 1
	u32 cmd;
d1172 1
a1172 1
		u32 val;
d1200 2
a1201 2
bnx_nvram_read_dword(struct bnx_softc *sc, u32 offset, u8 *ret_val,
							u32 cmd_flags)
d1203 1
a1203 1
	u32 cmd;
d1226 1
a1226 1
		u32 val;
d1262 2
a1263 2
bnx_nvram_write_dword(struct bnx_softc *sc, u32 offset, u8 *val,
	u32 cmd_flags)
d1265 1
a1265 1
	u32 cmd, val32;
d1318 1
a1318 1
	u32 val;
d1354 1
a1354 1
		u32 mask;
d1424 1
a1424 1
bnx_nvram_read(struct bnx_softc *sc, u32 offset, u8 *ret_buf,
d1428 1
a1428 1
	u32 cmd_flags, offset32, len32, extra;
d1447 2
a1448 2
		u8 buf[4];
		u32 pre_len;
d1479 1
a1479 1
		u8 buf[4];
d1492 1
a1492 1
		u8 buf[4];
d1544 1
a1544 1
bnx_nvram_write(struct bnx_softc *sc, u32 offset, u8 *data_buf,
d1547 2
a1548 2
	u32 written, offset32, len32;
	u8 *buf, start[4], end[4];
d1590 2
a1591 2
		u32 page_start, page_end, data_start, data_end;
		u32 addr, cmd_flags;
d1593 1
a1593 1
		u8 flash_buffer[264];
d1731 2
a1732 2
	u32 buf[BNX_NVRAM_SIZE / 4];
	u8 *data = (u8 *) buf;
d1734 1
a1734 1
	u32 magic, csum;
d1886 2
a1887 2
	u16 prod, chain_prod;
	u32	prod_bseq;
d1889 1
a1889 1
	u16 debug_prod;
d2024 1
a2024 1
		(u32) sc->status_block_paddr);
d2064 1
a2064 1
		(u32) sc->stats_block_paddr);
d2107 1
a2107 1
			i, (u32) sc->tx_bd_chain_paddr[i]);
d2165 1
a2165 1
			i, (u32) sc->rx_bd_chain_paddr[i]);
d2221 1
a2221 1
bnx_fw_sync(struct bnx_softc *sc, u32 msg_data)
d2224 1
a2224 1
	u32 val;
d2278 2
a2279 2
bnx_load_rv2p_fw(struct bnx_softc *sc, u32 *rv2p_code, 
	u32 rv2p_code_len, u32 rv2p_proc)
d2282 1
a2282 1
	u32 val;
d2322 2
a2323 2
	u32 offset;
	u32 val;
d2611 1
a2611 1
	u32 vcid;
d2615 1
a2615 1
		u32 vcid_addr, pcid_addr, offset;
d2644 1
a2644 1
	u32 mac_lo = 0, mac_hi = 0;
d2684 2
a2685 2
	u32 val;
	u8 *mac_addr = sc->eaddr;
d2766 1
a2766 1
bnx_reset(struct bnx_softc *sc, u32 reset_code)
d2768 1
a2768 1
	u32 val;
d2850 1
a2850 1
	u32 val;
d2888 1
a2888 1
		u16 val;
d2946 1
a2946 1
	u32 reg, val;
d3060 2
a3061 2
bnx_get_buf(struct bnx_softc *sc, struct mbuf *m, u16 *prod, u16 *chain_prod, 
	u32 *prod_bseq)
d3068 1
a3068 1
	u16 debug_chain_prod = *chain_prod;
d3077 1
a3077 1
		*chain_prod, (u16) MAX_RX_BD));
d3147 1
a3147 1
			sc->free_rx_bd, (u16) USABLE_RX_BD));
d3204 1
a3204 1
	u32 val;
d3316 2
a3317 2
	u16 prod, chain_prod;
	u32 prod_bseq, val;
d3499 1
a3499 1
	u32 new_link_state, old_link_state;
d3543 2
a3544 2
	u16 hw_cons, sw_cons, sw_chain_cons, sw_prod, sw_chain_prod;
	u32 sw_prod_bseq;
d3587 1
a3587 1
		u32 status;
d3813 1
a3813 1
	u16 hw_tx_cons, sw_tx_cons, sw_tx_chain_cons;
d3941 1
a3941 1
	u32 val;
d3965 1
a3965 1
	u32 ether_mtu;
d4059 2
a4060 2
bnx_tx_encap(struct bnx_softc *sc, struct mbuf *m_head, u16 *prod,
	u16 *chain_prod, u32 *prod_bseq)
d4062 1
a4062 1
	u32 vlan_tag_flags = 0;
d4160 2
a4161 2
	u16 tx_prod, tx_chain_prod;
	u32	tx_prod_bseq;
d4372 1
a4372 1
	u32 status_attn_bits;
d4481 2
a4482 2
	u32 hashes[4] = { 0, 0, 0, 0 };
	u32 rx_mode, sort_mode;
d4598 2
a4599 2
		((u64) stats->stat_IfHCInOctets_hi << 32) + 
		 (u64) stats->stat_IfHCInOctets_lo;
d4602 2
a4603 2
		((u64) stats->stat_IfHCInBadOctets_hi << 32) + 
		 (u64) stats->stat_IfHCInBadOctets_lo;
d4606 2
a4607 2
		((u64) stats->stat_IfHCOutOctets_hi << 32) +
		 (u64) stats->stat_IfHCOutOctets_lo;
d4610 2
a4611 2
		((u64) stats->stat_IfHCOutBadOctets_hi << 32) +
		 (u64) stats->stat_IfHCOutBadOctets_lo;
d4614 2
a4615 2
		((u64) stats->stat_IfHCInUcastPkts_hi << 32) +
		 (u64) stats->stat_IfHCInUcastPkts_lo;
d4618 2
a4619 2
		((u64) stats->stat_IfHCInMulticastPkts_hi << 32) +
		 (u64) stats->stat_IfHCInMulticastPkts_lo;
d4622 2
a4623 2
		((u64) stats->stat_IfHCInBroadcastPkts_hi << 32) +
		 (u64) stats->stat_IfHCInBroadcastPkts_lo;
d4626 2
a4627 2
		((u64) stats->stat_IfHCOutUcastPkts_hi << 32) +
		 (u64) stats->stat_IfHCOutUcastPkts_lo;
d4630 2
a4631 2
		((u64) stats->stat_IfHCOutMulticastPkts_hi << 32) +
		 (u64) stats->stat_IfHCOutMulticastPkts_lo;
d4634 2
a4635 2
		((u64) stats->stat_IfHCOutBroadcastPkts_hi << 32) +
		 (u64) stats->stat_IfHCOutBroadcastPkts_lo;
d4778 1
a4778 1
	u32 msg;
d4782 1
a4782 1
	msg = (u32) BNX_DRV_MSG_DATA_PULSE_CODE_ALWAYS_ALIVE;
d4784 1
a4784 1
	msg = (u32) ++sc->bnx_fw_drv_pulse_wr_seq;
d4830 1
a4830 1
	u32 val_hi, val_lo;
d4985 1
a4985 1
		(u32) BCM_PAGE_SIZE, (u32) TX_PAGES);
d4988 1
a4988 1
		(u32) TOTAL_TX_BD_PER_PAGE, (u32) USABLE_TX_BD_PER_PAGE);
d4990 1
a4990 1
	BNX_PRINTF(sc, "total tx_bd    = 0x%08X\n", (u32) TOTAL_TX_BD);
d5028 1
a5028 1
		(u32) BCM_PAGE_SIZE, (u32) RX_PAGES);
d5031 1
a5031 1
		(u32) TOTAL_RX_BD_PER_PAGE, (u32) USABLE_RX_BD_PER_PAGE);
d5033 1
a5033 1
	BNX_PRINTF(sc, "total rx_bd    = 0x%08X\n", (u32) TOTAL_RX_BD);
d5366 1
a5366 1
	u32 val_hi, val_lo;
d5449 1
a5449 1
		sc->rx_low_watermark, (u32) USABLE_RX_BD);
d5461 1
a5461 1
		sc->tx_hi_watermark, (u32) USABLE_TX_BD);
d5475 1
a5475 1
	u32 val1;
@


1.3
log
@do not allow a Jumbo size MTU yet.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.2 2006/06/26 05:37:05 brad Exp $	*/
d1797 2
a1798 1
	if (sc->status_block != NULL) {
d1803 1
d1805 1
a1805 4
	}
	if (sc->status_map != NULL) {
		bus_dmamap_unload(sc->bnx_dmatag, sc->status_map);
		bus_dmamap_destroy(sc->bnx_dmatag, sc->status_map);
d1809 2
a1810 1
	if (sc->stats_block != NULL) {
d1815 1
d1817 1
a1817 4
	}
	if (sc->stats_map != NULL) {
		bus_dmamap_unload(sc->bnx_dmatag, sc->stats_map);
		bus_dmamap_destroy(sc->bnx_dmatag, sc->stats_map);
d1822 3
a1824 1
		if (sc->tx_bd_chain[i] != NULL) {
d1829 1
d1831 1
a1832 6

		if (sc->tx_bd_chain_map[i] != NULL) {
			bus_dmamap_unload(sc->bnx_dmatag, sc->tx_bd_chain_map[i]);
			bus_dmamap_destroy(sc->bnx_dmatag, sc->tx_bd_chain_map[i]);
		}

d1845 3
a1847 1
		if (sc->rx_bd_chain[i] != NULL) {
a1851 2
			sc->rx_bd_chain[i] = NULL;
		}
a1852 2
		if (sc->rx_bd_chain_map[i] != NULL) {
			bus_dmamap_unload(sc->bnx_dmatag, sc->rx_bd_chain_map[i]);
d1854 2
a1856 1

d1990 7
a2011 7
	if (bus_dmamap_create(sc->bnx_dmatag, BNX_STATUS_BLK_SZ, 1,
	    BNX_STATUS_BLK_SZ, 0, BUS_DMA_NOWAIT, &sc->status_map)) {
		printf(": Could not create status block DMA map!\n");
		rc = ENOMEM;
		goto bnx_dma_alloc_exit;
	}

d2030 7
a2051 7
	if (bus_dmamap_create(sc->bnx_dmatag, BNX_STATS_BLK_SZ, 1,
	    BNX_STATS_BLK_SZ, 0, BUS_DMA_NOWAIT, &sc->stats_map)) {
		printf(": Could not create stats block DMA map!\n");
		rc = ENOMEM;
		goto bnx_dma_alloc_exit;
	}

d2071 8
a2094 8
		if (bus_dmamap_create(sc->bnx_dmatag, BNX_TX_CHAIN_PAGE_SZ, 1,
		    BNX_TX_CHAIN_PAGE_SZ, 0, BUS_DMA_NOWAIT,
		    &sc->tx_bd_chain_map[i])) {
			printf(": Could not create Tx desc %d DMA map!\n", i);
			rc = ENOMEM;
			goto bnx_dma_alloc_exit;
		}

d2128 8
a2147 8
			rc = ENOMEM;
			goto bnx_dma_alloc_exit;
		}

		if (bus_dmamap_create(sc->bnx_dmatag, BNX_RX_CHAIN_PAGE_SZ, 1,
		    BNX_RX_CHAIN_PAGE_SZ, 0, BUS_DMA_NOWAIT,
		    &sc->rx_bd_chain_map[i])) {
			printf(": Could not create Rx desc %d DMA map!\n", i);
@


1.2
log
@relocate the firmware per Theo's request.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_bnx.c,v 1.1 2006/06/26 04:57:54 brad Exp $	*/
d581 1
d583 1
@


1.1
log
@Add a rough initial port of the bce driver from FreeBSD, which provides
support for the new line of Broadcom NetXtreme II Gigabit PCI-X and PCIe
controllers, though renamed to bnx. This is work in progress, there
are some known issues. With help from Reyk with the bus_dma code.

Thanks to David Christensen at Broadcom for the driver and for providing
some PCI-X and PCIe adapters.

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d55 1
a55 1
#include <dev/pci/if_bnxfw.h>
@

