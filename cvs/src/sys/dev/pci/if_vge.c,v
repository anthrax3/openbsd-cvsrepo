head	1.71;
access;
symbols
	OPENBSD_6_2_BASE:1.71
	OPENBSD_6_1:1.71.0.4
	OPENBSD_6_1_BASE:1.71
	OPENBSD_6_0:1.70.0.4
	OPENBSD_6_0_BASE:1.70
	OPENBSD_5_9:1.69.0.2
	OPENBSD_5_9_BASE:1.69
	OPENBSD_5_8:1.63.0.4
	OPENBSD_5_8_BASE:1.63
	OPENBSD_5_7:1.59.0.4
	OPENBSD_5_7_BASE:1.59
	OPENBSD_5_6:1.58.0.4
	OPENBSD_5_6_BASE:1.58
	OPENBSD_5_5:1.57.0.4
	OPENBSD_5_5_BASE:1.57
	OPENBSD_5_4:1.55.0.2
	OPENBSD_5_4_BASE:1.55
	OPENBSD_5_3:1.53.0.2
	OPENBSD_5_3_BASE:1.53
	OPENBSD_5_2:1.51.0.6
	OPENBSD_5_2_BASE:1.51
	OPENBSD_5_1_BASE:1.51
	OPENBSD_5_1:1.51.0.4
	OPENBSD_5_0:1.51.0.2
	OPENBSD_5_0_BASE:1.51
	OPENBSD_4_9:1.48.0.2
	OPENBSD_4_9_BASE:1.48
	OPENBSD_4_8:1.47.0.4
	OPENBSD_4_8_BASE:1.47
	OPENBSD_4_7:1.47.0.2
	OPENBSD_4_7_BASE:1.47
	OPENBSD_4_6:1.43.0.6
	OPENBSD_4_6_BASE:1.43
	OPENBSD_4_5:1.43.0.2
	OPENBSD_4_5_BASE:1.43
	OPENBSD_4_4:1.37.0.2
	OPENBSD_4_4_BASE:1.37
	OPENBSD_4_3:1.35.0.2
	OPENBSD_4_3_BASE:1.35
	OPENBSD_4_2:1.33.0.2
	OPENBSD_4_2_BASE:1.33
	OPENBSD_4_1:1.32.0.2
	OPENBSD_4_1_BASE:1.32
	OPENBSD_4_0:1.27.0.2
	OPENBSD_4_0_BASE:1.27
	OPENBSD_3_9:1.18.0.2
	OPENBSD_3_9_BASE:1.18
	OPENBSD_3_8:1.16.0.2
	OPENBSD_3_8_BASE:1.16
	OPENBSD_3_7:1.7.0.2
	OPENBSD_3_7_BASE:1.7;
locks; strict;
comment	@ * @;


1.71
date	2017.01.22.10.17.38;	author dlg;	state Exp;
branches;
next	1.70;
commitid	VyLWTsbepAOk7VQM;

1.70
date	2016.04.13.10.34.32;	author mpi;	state Exp;
branches;
next	1.69;
commitid	8YSL8ByWzGeIGBiJ;

1.69
date	2015.11.25.03.09.59;	author dlg;	state Exp;
branches;
next	1.68;
commitid	B0kwmVGiD5DVx4kv;

1.68
date	2015.11.24.17.11.39;	author mpi;	state Exp;
branches;
next	1.67;
commitid	5gdEnqVoJuTuwdTu;

1.67
date	2015.11.16.04.02.34;	author dlg;	state Exp;
branches;
next	1.66;
commitid	t1bcoM5NEVzG1K5n;

1.66
date	2015.11.14.17.54.57;	author mpi;	state Exp;
branches;
next	1.65;
commitid	Waft2RDjXAxr4qZ9;

1.65
date	2015.10.25.13.04.28;	author mpi;	state Exp;
branches;
next	1.64;
commitid	hPF95ClMUQfeqQDX;

1.64
date	2015.09.11.13.02.28;	author stsp;	state Exp;
branches;
next	1.63;
commitid	6vhYvh5CxZAHMnsN;

1.63
date	2015.06.24.09.40.54;	author mpi;	state Exp;
branches;
next	1.62;
commitid	MVWrtktB46JRxFWT;

1.62
date	2015.04.13.08.45.48;	author mpi;	state Exp;
branches;
next	1.61;
commitid	aiRvgNOa4qke9vft;

1.61
date	2015.04.08.10.07.47;	author mpi;	state Exp;
branches;
next	1.60;
commitid	hnmA6leYzflFI0c3;

1.60
date	2015.03.14.03.38.48;	author jsg;	state Exp;
branches;
next	1.59;
commitid	p4LJxGKbi0BU2cG6;

1.59
date	2014.12.22.02.28.52;	author tedu;	state Exp;
branches;
next	1.58;
commitid	yM2VFFhpDTeFQlve;

1.58
date	2014.07.22.13.12.11;	author mpi;	state Exp;
branches;
next	1.57;
commitid	TGHgrLxu6sxZoiFt;

1.57
date	2013.08.21.05.21.44;	author dlg;	state Exp;
branches;
next	1.56;

1.56
date	2013.08.07.01.06.38;	author bluhm;	state Exp;
branches;
next	1.55;

1.55
date	2013.03.15.01.33.23;	author brad;	state Exp;
branches;
next	1.54;

1.54
date	2013.03.14.17.04.50;	author brad;	state Exp;
branches;
next	1.53;

1.53
date	2012.11.29.21.10.32;	author brad;	state Exp;
branches;
next	1.52;

1.52
date	2012.11.23.18.40.30;	author gsoares;	state Exp;
branches;
next	1.51;

1.51
date	2011.06.22.16.44.27;	author tedu;	state Exp;
branches;
next	1.50;

1.50
date	2011.04.05.18.01.21;	author henning;	state Exp;
branches;
next	1.49;

1.49
date	2011.04.03.15.36.03;	author jasper;	state Exp;
branches;
next	1.48;

1.48
date	2010.08.27.17.08.00;	author jsg;	state Exp;
branches;
next	1.47;

1.47
date	2010.02.24.21.44.12;	author kettenis;	state Exp;
branches;
next	1.46;

1.46
date	2009.11.23.23.18.16;	author kettenis;	state Exp;
branches;
next	1.45;

1.45
date	2009.09.04.21.43.00;	author kettenis;	state Exp;
branches;
next	1.44;

1.44
date	2009.08.13.14.24.47;	author jasper;	state Exp;
branches;
next	1.43;

1.43
date	2008.11.28.02.44.18;	author brad;	state Exp;
branches;
next	1.42;

1.42
date	2008.11.09.15.08.26;	author naddy;	state Exp;
branches;
next	1.41;

1.41
date	2008.10.22.05.31.29;	author brad;	state Exp;
branches;
next	1.40;

1.40
date	2008.10.14.18.01.53;	author naddy;	state Exp;
branches;
next	1.39;

1.39
date	2008.10.02.20.21.14;	author brad;	state Exp;
branches;
next	1.38;

1.38
date	2008.09.10.14.01.23;	author blambert;	state Exp;
branches;
next	1.37;

1.37
date	2008.05.22.19.23.04;	author mk;	state Exp;
branches;
next	1.36;

1.36
date	2008.05.13.01.40.39;	author brad;	state Exp;
branches;
next	1.35;

1.35
date	2007.12.11.02.36.02;	author brad;	state Exp;
branches;
next	1.34;

1.34
date	2007.10.10.12.46.44;	author kettenis;	state Exp;
branches;
next	1.33;

1.33
date	2007.05.01.11.28.06;	author canacar;	state Exp;
branches;
next	1.32;

1.32
date	2006.12.04.14.35.20;	author reyk;	state Exp;
branches;
next	1.31;

1.31
date	2006.11.23.02.00.54;	author brad;	state Exp;
branches;
next	1.30;

1.30
date	2006.11.14.17.08.24;	author damien;	state Exp;
branches;
next	1.29;

1.29
date	2006.10.19.10.55.56;	author tom;	state Exp;
branches;
next	1.28;

1.28
date	2006.10.03.19.46.08;	author damien;	state Exp;
branches;
next	1.27;

1.27
date	2006.07.28.15.58.38;	author kettenis;	state Exp;
branches;
next	1.26;

1.26
date	2006.06.17.18.00.43;	author brad;	state Exp;
branches;
next	1.25;

1.25
date	2006.06.13.01.33.45;	author brad;	state Exp;
branches;
next	1.24;

1.24
date	2006.05.28.00.20.21;	author brad;	state Exp;
branches;
next	1.23;

1.23
date	2006.05.28.00.04.24;	author jason;	state Exp;
branches;
next	1.22;

1.22
date	2006.05.27.10.03.15;	author brad;	state Exp;
branches;
next	1.21;

1.21
date	2006.05.20.03.47.56;	author brad;	state Exp;
branches;
next	1.20;

1.20
date	2006.03.25.22.41.46;	author djm;	state Exp;
branches;
next	1.19;

1.19
date	2006.03.20.16.15.03;	author brad;	state Exp;
branches;
next	1.18;

1.18
date	2005.11.07.02.57.45;	author brad;	state Exp;
branches;
next	1.17;

1.17
date	2005.10.08.01.58.17;	author brad;	state Exp;
branches;
next	1.16;

1.16
date	2005.08.09.04.10.12;	author mickey;	state Exp;
branches;
next	1.15;

1.15
date	2005.07.03.02.38.23;	author brad;	state Exp;
branches;
next	1.14;

1.14
date	2005.05.03.03.13.05;	author brad;	state Exp;
branches;
next	1.13;

1.13
date	2005.04.30.19.41.24;	author brad;	state Exp;
branches;
next	1.12;

1.12
date	2005.04.30.19.24.00;	author brad;	state Exp;
branches;
next	1.11;

1.11
date	2005.04.25.17.55.51;	author brad;	state Exp;
branches;
next	1.10;

1.10
date	2005.04.08.15.15.52;	author brad;	state Exp;
branches;
next	1.9;

1.9
date	2005.04.08.13.36.48;	author brad;	state Exp;
branches;
next	1.8;

1.8
date	2005.04.02.01.25.48;	author brad;	state Exp;
branches;
next	1.7;

1.7
date	2005.03.15.17.06.10;	author pvalchev;	state Exp;
branches;
next	1.6;

1.6
date	2005.01.15.05.24.11;	author brad;	state Exp;
branches;
next	1.5;

1.5
date	2004.12.27.00.46.40;	author pvalchev;	state Exp;
branches;
next	1.4;

1.4
date	2004.12.26.05.58.25;	author pvalchev;	state Exp;
branches;
next	1.3;

1.3
date	2004.12.26.05.54.30;	author pvalchev;	state Exp;
branches;
next	1.2;

1.2
date	2004.12.12.06.13.32;	author pvalchev;	state Exp;
branches;
next	1.1;

1.1
date	2004.12.01.01.29.00;	author pvalchev;	state Exp;
branches;
next	;


desc
@@


1.71
log
@move counting if_opackets next to counting if_obytes in if_enqueue.

this means packets are consistently counted in one place, unlike the
many and various ways that drivers thought they should do it.

ok mpi@@ deraadt@@
@
text
@/*	$OpenBSD: if_vge.c,v 1.70 2016/04/13 10:34:32 mpi Exp $	*/
/*	$FreeBSD: if_vge.c,v 1.3 2004/09/11 22:13:25 wpaul Exp $	*/
/*
 * Copyright (c) 2004
 *	Bill Paul <wpaul@@windriver.com>.  All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *	This product includes software developed by Bill Paul.
 * 4. Neither the name of the author nor the names of any co-contributors
 *    may be used to endorse or promote products derived from this software
 *    without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY Bill Paul AND CONTRIBUTORS ``AS IS'' AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED.  IN NO EVENT SHALL Bill Paul OR THE VOICES IN HIS HEAD
 * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
 * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
 * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
 * THE POSSIBILITY OF SUCH DAMAGE.
 */

/*
 * VIA Networking Technologies VT612x PCI gigabit ethernet NIC driver.
 *
 * Written by Bill Paul <wpaul@@windriver.com>
 * Senior Networking Software Engineer
 * Wind River Systems
 *
 * Ported to OpenBSD by Peter Valchev <pvalchev@@openbsd.org>
 */

/*
 * The VIA Networking VT6122 is a 32bit, 33/66MHz PCI device that
 * combines a tri-speed ethernet MAC and PHY, with the following
 * features:
 *
 *	o Jumbo frame support up to 16K
 *	o Transmit and receive flow control
 *	o IPv4 checksum offload
 *	o VLAN tag insertion and stripping
 *	o TCP large send
 *	o 64-bit multicast hash table filter
 *	o 64 entry CAM filter
 *	o 16K RX FIFO and 48K TX FIFO memory
 *	o Interrupt moderation
 *
 * The VT6122 supports up to four transmit DMA queues. The descriptors
 * in the transmit ring can address up to 7 data fragments; frames which
 * span more than 7 data buffers must be coalesced, but in general the
 * BSD TCP/IP stack rarely generates frames more than 2 or 3 fragments
 * long. The receive descriptors address only a single buffer.
 *
 * There are two peculiar design issues with the VT6122. One is that
 * receive data buffers must be aligned on a 32-bit boundary. This is
 * not a problem where the VT6122 is used as a LOM device in x86-based
 * systems, but on architectures that generate unaligned access traps, we
 * have to do some copying.
 *
 * The other issue has to do with the way 64-bit addresses are handled.
 * The DMA descriptors only allow you to specify 48 bits of addressing
 * information. The remaining 16 bits are specified using one of the
 * I/O registers. If you only have a 32-bit system, then this isn't
 * an issue, but if you have a 64-bit system and more than 4GB of
 * memory, you must have to make sure your network data buffers reside
 * in the same 48-bit 'segment.'
 *
 * Special thanks to Ryan Fu at VIA Networking for providing documentation
 * and sample NICs for testing.
 */

#include "bpfilter.h"
#include "vlan.h"

#include <sys/param.h>
#include <sys/endian.h>
#include <sys/systm.h>
#include <sys/sockio.h>
#include <sys/mbuf.h>
#include <sys/malloc.h>
#include <sys/kernel.h>
#include <sys/device.h>
#include <sys/timeout.h>
#include <sys/socket.h>

#include <net/if.h>
#include <net/if_media.h>

#include <netinet/in.h>
#include <netinet/if_ether.h>

#if NBPFILTER > 0
#include <net/bpf.h>
#endif

#include <dev/mii/miivar.h>

#include <dev/pci/pcireg.h>
#include <dev/pci/pcivar.h>
#include <dev/pci/pcidevs.h>

#include <dev/pci/if_vgereg.h>
#include <dev/pci/if_vgevar.h>

int vge_probe		(struct device *, void *, void *);
void vge_attach		(struct device *, struct device *, void *);
int vge_detach		(struct device *, int);

int vge_encap		(struct vge_softc *, struct mbuf *, int);

int vge_allocmem		(struct vge_softc *);
void vge_freemem	(struct vge_softc *);
int vge_newbuf		(struct vge_softc *, int, struct mbuf *);
int vge_rx_list_init	(struct vge_softc *);
int vge_tx_list_init	(struct vge_softc *);
void vge_rxeof		(struct vge_softc *);
void vge_txeof		(struct vge_softc *);
int vge_intr		(void *);
void vge_tick		(void *);
void vge_start		(struct ifnet *);
int vge_ioctl		(struct ifnet *, u_long, caddr_t);
int vge_init		(struct ifnet *);
void vge_stop		(struct vge_softc *);
void vge_watchdog	(struct ifnet *);
int vge_ifmedia_upd	(struct ifnet *);
void vge_ifmedia_sts	(struct ifnet *, struct ifmediareq *);

#ifdef VGE_EEPROM
void vge_eeprom_getword	(struct vge_softc *, int, u_int16_t *);
#endif
void vge_read_eeprom	(struct vge_softc *, caddr_t, int, int, int);

void vge_miipoll_start	(struct vge_softc *);
void vge_miipoll_stop	(struct vge_softc *);
int vge_miibus_readreg	(struct device *, int, int);
void vge_miibus_writereg (struct device *, int, int, int);
void vge_miibus_statchg	(struct device *);

void vge_cam_clear	(struct vge_softc *);
int vge_cam_set		(struct vge_softc *, uint8_t *);
void vge_iff		(struct vge_softc *);
void vge_reset		(struct vge_softc *);

struct cfattach vge_ca = {
	sizeof(struct vge_softc), vge_probe, vge_attach, vge_detach
};

struct cfdriver vge_cd = {
	NULL, "vge", DV_IFNET
};

#define VGE_PCI_LOIO             0x10
#define VGE_PCI_LOMEM            0x14

int vge_debug = 0;
#define DPRINTF(x)	if (vge_debug) printf x
#define DPRINTFN(n, x)	if (vge_debug >= (n)) printf x

const struct pci_matchid vge_devices[] = {
	{ PCI_VENDOR_VIATECH, PCI_PRODUCT_VIATECH_VT612x },
};

#ifdef VGE_EEPROM
/*
 * Read a word of data stored in the EEPROM at address 'addr.'
 */
void
vge_eeprom_getword(struct vge_softc *sc, int addr, u_int16_t *dest)
{
	int			i;
	u_int16_t		word = 0;

	/*
	 * Enter EEPROM embedded programming mode. In order to
	 * access the EEPROM at all, we first have to set the
	 * EELOAD bit in the CHIPCFG2 register.
	 */
	CSR_SETBIT_1(sc, VGE_CHIPCFG2, VGE_CHIPCFG2_EELOAD);
	CSR_SETBIT_1(sc, VGE_EECSR, VGE_EECSR_EMBP/*|VGE_EECSR_ECS*/);

	/* Select the address of the word we want to read */
	CSR_WRITE_1(sc, VGE_EEADDR, addr);

	/* Issue read command */
	CSR_SETBIT_1(sc, VGE_EECMD, VGE_EECMD_ERD);

	/* Wait for the done bit to be set. */
	for (i = 0; i < VGE_TIMEOUT; i++) {
		if (CSR_READ_1(sc, VGE_EECMD) & VGE_EECMD_EDONE)
			break;
	}

	if (i == VGE_TIMEOUT) {
		printf("%s: EEPROM read timed out\n", sc->vge_dev.dv_xname);
		*dest = 0;
		return;
	}

	/* Read the result */
	word = CSR_READ_2(sc, VGE_EERDDAT);

	/* Turn off EEPROM access mode. */
	CSR_CLRBIT_1(sc, VGE_EECSR, VGE_EECSR_EMBP/*|VGE_EECSR_ECS*/);
	CSR_CLRBIT_1(sc, VGE_CHIPCFG2, VGE_CHIPCFG2_EELOAD);

	*dest = word;
}
#endif

/*
 * Read a sequence of words from the EEPROM.
 */
void
vge_read_eeprom(struct vge_softc *sc, caddr_t dest, int off, int cnt,
    int swap)
{
	int			i;
#ifdef VGE_EEPROM
	u_int16_t		word = 0, *ptr;

	for (i = 0; i < cnt; i++) {
		vge_eeprom_getword(sc, off + i, &word);
		ptr = (u_int16_t *)(dest + (i * 2));
		if (swap)
			*ptr = ntohs(word);
		else
			*ptr = word;
	}
#else
	for (i = 0; i < ETHER_ADDR_LEN; i++)
		dest[i] = CSR_READ_1(sc, VGE_PAR0 + i);
#endif
}

void
vge_miipoll_stop(struct vge_softc *sc)
{
	int			i;

	CSR_WRITE_1(sc, VGE_MIICMD, 0);

	for (i = 0; i < VGE_TIMEOUT; i++) {
		DELAY(1);
		if (CSR_READ_1(sc, VGE_MIISTS) & VGE_MIISTS_IIDL)
			break;
	}

	if (i == VGE_TIMEOUT)
		printf("%s: failed to idle MII autopoll\n", sc->vge_dev.dv_xname);
}

void
vge_miipoll_start(struct vge_softc *sc)
{
	int			i;

	/* First, make sure we're idle. */

	CSR_WRITE_1(sc, VGE_MIICMD, 0);
	CSR_WRITE_1(sc, VGE_MIIADDR, VGE_MIIADDR_SWMPL);

	for (i = 0; i < VGE_TIMEOUT; i++) {
		DELAY(1);
		if (CSR_READ_1(sc, VGE_MIISTS) & VGE_MIISTS_IIDL)
			break;
	}

	if (i == VGE_TIMEOUT) {
		printf("%s: failed to idle MII autopoll\n", sc->vge_dev.dv_xname);
		return;
	}

	/* Now enable auto poll mode. */

	CSR_WRITE_1(sc, VGE_MIICMD, VGE_MIICMD_MAUTO);

	/* And make sure it started. */

	for (i = 0; i < VGE_TIMEOUT; i++) {
		DELAY(1);
		if ((CSR_READ_1(sc, VGE_MIISTS) & VGE_MIISTS_IIDL) == 0)
			break;
	}

	if (i == VGE_TIMEOUT)
		printf("%s: failed to start MII autopoll\n", sc->vge_dev.dv_xname);
}

int
vge_miibus_readreg(struct device *dev, int phy, int reg)
{
	struct vge_softc	*sc = (struct vge_softc *)dev;
	int			i, s;
	u_int16_t		rval = 0;

	if (phy != (CSR_READ_1(sc, VGE_MIICFG) & 0x1F))
		return(0);

	s = splnet();

	vge_miipoll_stop(sc);

	/* Specify the register we want to read. */
	CSR_WRITE_1(sc, VGE_MIIADDR, reg);

	/* Issue read command. */
	CSR_SETBIT_1(sc, VGE_MIICMD, VGE_MIICMD_RCMD);

	/* Wait for the read command bit to self-clear. */
	for (i = 0; i < VGE_TIMEOUT; i++) {
		DELAY(1);
		if ((CSR_READ_1(sc, VGE_MIICMD) & VGE_MIICMD_RCMD) == 0)
			break;
	}

	if (i == VGE_TIMEOUT)
		printf("%s: MII read timed out\n", sc->vge_dev.dv_xname);
	else
		rval = CSR_READ_2(sc, VGE_MIIDATA);

	vge_miipoll_start(sc);
	splx(s);

	return (rval);
}

void
vge_miibus_writereg(struct device *dev, int phy, int reg, int data)
{
	struct vge_softc	*sc = (struct vge_softc *)dev;
	int			i, s;

	if (phy != (CSR_READ_1(sc, VGE_MIICFG) & 0x1F))
		return;

	s = splnet();
	vge_miipoll_stop(sc);

	/* Specify the register we want to write. */
	CSR_WRITE_1(sc, VGE_MIIADDR, reg);

	/* Specify the data we want to write. */
	CSR_WRITE_2(sc, VGE_MIIDATA, data);

	/* Issue write command. */
	CSR_SETBIT_1(sc, VGE_MIICMD, VGE_MIICMD_WCMD);

	/* Wait for the write command bit to self-clear. */
	for (i = 0; i < VGE_TIMEOUT; i++) {
		DELAY(1);
		if ((CSR_READ_1(sc, VGE_MIICMD) & VGE_MIICMD_WCMD) == 0)
			break;
	}

	if (i == VGE_TIMEOUT) {
		printf("%s: MII write timed out\n", sc->vge_dev.dv_xname);
	}

	vge_miipoll_start(sc);
	splx(s);
}

void
vge_cam_clear(struct vge_softc *sc)
{
	int			i;

	/*
	 * Turn off all the mask bits. This tells the chip
	 * that none of the entries in the CAM filter are valid.
	 * desired entries will be enabled as we fill the filter in.
	 */

	CSR_CLRBIT_1(sc, VGE_CAMCTL, VGE_CAMCTL_PAGESEL);
	CSR_SETBIT_1(sc, VGE_CAMCTL, VGE_PAGESEL_CAMMASK);
	CSR_WRITE_1(sc, VGE_CAMADDR, VGE_CAMADDR_ENABLE);
	for (i = 0; i < 8; i++)
		CSR_WRITE_1(sc, VGE_CAM0 + i, 0);

	/* Clear the VLAN filter too. */

	CSR_WRITE_1(sc, VGE_CAMADDR, VGE_CAMADDR_ENABLE|VGE_CAMADDR_AVSEL|0);
	for (i = 0; i < 8; i++)
		CSR_WRITE_1(sc, VGE_CAM0 + i, 0);

	CSR_WRITE_1(sc, VGE_CAMADDR, 0);
	CSR_CLRBIT_1(sc, VGE_CAMCTL, VGE_CAMCTL_PAGESEL);
	CSR_SETBIT_1(sc, VGE_CAMCTL, VGE_PAGESEL_MAR);

	sc->vge_camidx = 0;
}

int
vge_cam_set(struct vge_softc *sc, uint8_t *addr)
{
	int			i, error = 0;

	if (sc->vge_camidx == VGE_CAM_MAXADDRS)
		return(ENOSPC);

	/* Select the CAM data page. */
	CSR_CLRBIT_1(sc, VGE_CAMCTL, VGE_CAMCTL_PAGESEL);
	CSR_SETBIT_1(sc, VGE_CAMCTL, VGE_PAGESEL_CAMDATA);

	/* Set the filter entry we want to update and enable writing. */
	CSR_WRITE_1(sc, VGE_CAMADDR, VGE_CAMADDR_ENABLE|sc->vge_camidx);

	/* Write the address to the CAM registers */
	for (i = 0; i < ETHER_ADDR_LEN; i++)
		CSR_WRITE_1(sc, VGE_CAM0 + i, addr[i]);

	/* Issue a write command. */
	CSR_SETBIT_1(sc, VGE_CAMCTL, VGE_CAMCTL_WRITE);

	/* Wake for it to clear. */
	for (i = 0; i < VGE_TIMEOUT; i++) {
		DELAY(1);
		if ((CSR_READ_1(sc, VGE_CAMCTL) & VGE_CAMCTL_WRITE) == 0)
			break;
	}

	if (i == VGE_TIMEOUT) {
		printf("%s: setting CAM filter failed\n", sc->vge_dev.dv_xname);
		error = EIO;
		goto fail;
	}

	/* Select the CAM mask page. */
	CSR_CLRBIT_1(sc, VGE_CAMCTL, VGE_CAMCTL_PAGESEL);
	CSR_SETBIT_1(sc, VGE_CAMCTL, VGE_PAGESEL_CAMMASK);

	/* Set the mask bit that enables this filter. */
	CSR_SETBIT_1(sc, VGE_CAM0 + (sc->vge_camidx/8),
	    1<<(sc->vge_camidx & 7));

	sc->vge_camidx++;

fail:
	/* Turn off access to CAM. */
	CSR_WRITE_1(sc, VGE_CAMADDR, 0);
	CSR_CLRBIT_1(sc, VGE_CAMCTL, VGE_CAMCTL_PAGESEL);
	CSR_SETBIT_1(sc, VGE_CAMCTL, VGE_PAGESEL_MAR);

	return (error);
}

/*
 * We use the 64-entry CAM filter for perfect filtering.
 * If there's more than 64 multicast addresses, we use the
 * hash filter instead.
 */
void
vge_iff(struct vge_softc *sc)
{
	struct arpcom		*ac = &sc->arpcom;
	struct ifnet		*ifp = &ac->ac_if;
	struct ether_multi	*enm;
	struct ether_multistep	step;
	u_int32_t		h = 0, hashes[2];
	u_int8_t		rxctl;
	int			error;

	vge_cam_clear(sc);
	rxctl = CSR_READ_1(sc, VGE_RXCTL);
	rxctl &= ~(VGE_RXCTL_RX_BCAST | VGE_RXCTL_RX_MCAST |
	    VGE_RXCTL_RX_PROMISC | VGE_RXCTL_RX_UCAST);
	bzero(hashes, sizeof(hashes));
	ifp->if_flags &= ~IFF_ALLMULTI;

	/*
	 * Always accept broadcast frames.
	 * Always accept frames destined to our station address.
	 */
	rxctl |= VGE_RXCTL_RX_BCAST | VGE_RXCTL_RX_UCAST;

	if ((ifp->if_flags & IFF_PROMISC) == 0)
		rxctl |= VGE_RXCTL_RX_MCAST;

	if (ifp->if_flags & IFF_PROMISC || ac->ac_multirangecnt > 0) {
		ifp->if_flags |= IFF_ALLMULTI;
		if (ifp->if_flags & IFF_PROMISC)
			rxctl |= VGE_RXCTL_RX_PROMISC;
		hashes[0] = hashes[1] = 0xFFFFFFFF;
	} else if (ac->ac_multicnt > VGE_CAM_MAXADDRS) {
		ETHER_FIRST_MULTI(step, ac, enm);
		while (enm != NULL) {
			h = ether_crc32_be(enm->enm_addrlo,
			    ETHER_ADDR_LEN) >> 26;

			hashes[h >> 5] |= 1 << (h & 0x1f);

			ETHER_NEXT_MULTI(step, enm);
		}
	} else {
		ETHER_FIRST_MULTI(step, ac, enm);
		while (enm != NULL) {
			error = vge_cam_set(sc, enm->enm_addrlo);
			if (error)
				break;

			ETHER_NEXT_MULTI(step, enm);
		}
	}

	CSR_WRITE_4(sc, VGE_MAR0, hashes[0]);
	CSR_WRITE_4(sc, VGE_MAR1, hashes[1]);
	CSR_WRITE_1(sc, VGE_RXCTL, rxctl);
}

void
vge_reset(struct vge_softc *sc)
{
	int			i;

	CSR_WRITE_1(sc, VGE_CRS1, VGE_CR1_SOFTRESET);

	for (i = 0; i < VGE_TIMEOUT; i++) {
		DELAY(5);
		if ((CSR_READ_1(sc, VGE_CRS1) & VGE_CR1_SOFTRESET) == 0)
			break;
	}

	if (i == VGE_TIMEOUT) {
		printf("%s: soft reset timed out", sc->vge_dev.dv_xname);
		CSR_WRITE_1(sc, VGE_CRS3, VGE_CR3_STOP_FORCE);
		DELAY(2000);
	}

	DELAY(5000);

	CSR_SETBIT_1(sc, VGE_EECSR, VGE_EECSR_RELOAD);

	for (i = 0; i < VGE_TIMEOUT; i++) {
		DELAY(5);
		if ((CSR_READ_1(sc, VGE_EECSR) & VGE_EECSR_RELOAD) == 0)
			break;
	}

	CSR_CLRBIT_1(sc, VGE_CHIPCFG0, VGE_CHIPCFG0_PACPI);
}

/*
 * Probe for a VIA gigabit chip. Check the PCI vendor and device
 * IDs against our list and return a device name if we find a match.
 */
int
vge_probe(struct device *dev, void *match, void *aux)
{
	return (pci_matchbyid((struct pci_attach_args *)aux, vge_devices,
	    nitems(vge_devices)));
}

/*
 * Allocate memory for RX/TX rings
 */
int
vge_allocmem(struct vge_softc *sc)
{
	int			nseg, rseg;
	int			i, error;

	nseg = 32;

	/* Allocate DMA'able memory for the TX ring */

	error = bus_dmamap_create(sc->sc_dmat, VGE_TX_LIST_SZ, 1,
	    VGE_TX_LIST_SZ, 0, BUS_DMA_ALLOCNOW,
	    &sc->vge_ldata.vge_tx_list_map);
	if (error)
		return (ENOMEM);
	error = bus_dmamem_alloc(sc->sc_dmat, VGE_TX_LIST_SZ,
	    ETHER_ALIGN, 0,
	    &sc->vge_ldata.vge_tx_listseg, 1, &rseg, BUS_DMA_NOWAIT);
	if (error) {
		printf("%s: can't alloc TX list\n", sc->vge_dev.dv_xname);
		return (ENOMEM);
	}

	/* Load the map for the TX ring. */
	error = bus_dmamem_map(sc->sc_dmat, &sc->vge_ldata.vge_tx_listseg,
	     1, VGE_TX_LIST_SZ,
	     (caddr_t *)&sc->vge_ldata.vge_tx_list, BUS_DMA_NOWAIT);
	memset(sc->vge_ldata.vge_tx_list, 0, VGE_TX_LIST_SZ);
	if (error) {
		printf("%s: can't map TX dma buffers\n",
		    sc->vge_dev.dv_xname);
		bus_dmamem_free(sc->sc_dmat, &sc->vge_ldata.vge_tx_listseg, rseg);
		return (ENOMEM);
	}

	error = bus_dmamap_load(sc->sc_dmat, sc->vge_ldata.vge_tx_list_map,
	    sc->vge_ldata.vge_tx_list, VGE_TX_LIST_SZ, NULL, BUS_DMA_NOWAIT);
	if (error) {
		printf("%s: can't load TX dma map\n", sc->vge_dev.dv_xname);
		bus_dmamap_destroy(sc->sc_dmat, sc->vge_ldata.vge_tx_list_map);
		bus_dmamem_unmap(sc->sc_dmat, (caddr_t)sc->vge_ldata.vge_tx_list,
		    VGE_TX_LIST_SZ);
		bus_dmamem_free(sc->sc_dmat, &sc->vge_ldata.vge_tx_listseg, rseg);
		return (ENOMEM);
	}

	/* Create DMA maps for TX buffers */

	for (i = 0; i < VGE_TX_DESC_CNT; i++) {
		error = bus_dmamap_create(sc->sc_dmat, MCLBYTES * nseg,
		    VGE_TX_FRAGS, MCLBYTES, 0, BUS_DMA_ALLOCNOW,
		    &sc->vge_ldata.vge_tx_dmamap[i]);
		if (error) {
			printf("%s: can't create DMA map for TX\n",
			    sc->vge_dev.dv_xname);
			return (ENOMEM);
		}
	}

	/* Allocate DMA'able memory for the RX ring */

	error = bus_dmamap_create(sc->sc_dmat, VGE_RX_LIST_SZ, 1,
	    VGE_RX_LIST_SZ, 0, BUS_DMA_ALLOCNOW,
	    &sc->vge_ldata.vge_rx_list_map);
	if (error)
		return (ENOMEM);
	error = bus_dmamem_alloc(sc->sc_dmat, VGE_RX_LIST_SZ, VGE_RING_ALIGN,
	    0, &sc->vge_ldata.vge_rx_listseg, 1, &rseg, BUS_DMA_NOWAIT);
	if (error) {
		printf("%s: can't alloc RX list\n", sc->vge_dev.dv_xname);
		return (ENOMEM);
	}

	/* Load the map for the RX ring. */

	error = bus_dmamem_map(sc->sc_dmat, &sc->vge_ldata.vge_rx_listseg,
	     1, VGE_RX_LIST_SZ,
	     (caddr_t *)&sc->vge_ldata.vge_rx_list, BUS_DMA_NOWAIT);
	memset(sc->vge_ldata.vge_rx_list, 0, VGE_RX_LIST_SZ);
	if (error) {
		printf("%s: can't map RX dma buffers\n",
		    sc->vge_dev.dv_xname);
		bus_dmamem_free(sc->sc_dmat, &sc->vge_ldata.vge_rx_listseg, rseg);
		return (ENOMEM);
	}
	error = bus_dmamap_load(sc->sc_dmat, sc->vge_ldata.vge_rx_list_map,
	    sc->vge_ldata.vge_rx_list, VGE_RX_LIST_SZ, NULL, BUS_DMA_NOWAIT);
	if (error) {
		printf("%s: can't load RX dma map\n", sc->vge_dev.dv_xname);
		bus_dmamap_destroy(sc->sc_dmat, sc->vge_ldata.vge_rx_list_map);
		bus_dmamem_unmap(sc->sc_dmat, (caddr_t)sc->vge_ldata.vge_rx_list,
		    VGE_RX_LIST_SZ);
		bus_dmamem_free(sc->sc_dmat, &sc->vge_ldata.vge_rx_listseg, rseg);
		return (ENOMEM);
	}

	/* Create DMA maps for RX buffers */

	for (i = 0; i < VGE_RX_DESC_CNT; i++) {
		error = bus_dmamap_create(sc->sc_dmat, MCLBYTES * nseg, nseg,
		    MCLBYTES, 0, BUS_DMA_ALLOCNOW,
		    &sc->vge_ldata.vge_rx_dmamap[i]);
		if (error) {
			printf("%s: can't create DMA map for RX\n",
			    sc->vge_dev.dv_xname);
			return (ENOMEM);
		}
	}

	return (0);
}

void
vge_freemem(struct vge_softc *sc)
{
	int i;

	for (i = 0; i < VGE_RX_DESC_CNT; i++)
		bus_dmamap_destroy(sc->sc_dmat,
		    sc->vge_ldata.vge_rx_dmamap[i]);

	bus_dmamap_unload(sc->sc_dmat, sc->vge_ldata.vge_rx_list_map);
	bus_dmamap_destroy(sc->sc_dmat, sc->vge_ldata.vge_rx_list_map);
	bus_dmamem_unmap(sc->sc_dmat, (caddr_t)sc->vge_ldata.vge_rx_list,
	    VGE_RX_LIST_SZ);
	bus_dmamem_free(sc->sc_dmat, &sc->vge_ldata.vge_rx_listseg, 1);

	for (i = 0; i < VGE_TX_DESC_CNT; i++)
		bus_dmamap_destroy(sc->sc_dmat,
		    sc->vge_ldata.vge_tx_dmamap[i]);

	bus_dmamap_unload(sc->sc_dmat, sc->vge_ldata.vge_tx_list_map);
	bus_dmamap_destroy(sc->sc_dmat, sc->vge_ldata.vge_tx_list_map);
	bus_dmamem_unmap(sc->sc_dmat, (caddr_t)sc->vge_ldata.vge_tx_list,
	    VGE_TX_LIST_SZ);
	bus_dmamem_free(sc->sc_dmat, &sc->vge_ldata.vge_tx_listseg, 1);
}

/*
 * Attach the interface. Allocate softc structures, do ifmedia
 * setup and ethernet/BPF attach.
 */
void
vge_attach(struct device *parent, struct device *self, void *aux)
{
	u_char			eaddr[ETHER_ADDR_LEN];
	struct vge_softc	*sc = (struct vge_softc *)self;
	struct pci_attach_args	*pa = aux;
	pci_chipset_tag_t	pc = pa->pa_pc;
	pci_intr_handle_t	ih;
	const char		*intrstr = NULL;
	struct ifnet		*ifp;
	int			error = 0;

	/*
	 * Map control/status registers.
	 */
	if (pci_mapreg_map(pa, VGE_PCI_LOMEM, PCI_MAPREG_TYPE_MEM, 0,
	    &sc->vge_btag, &sc->vge_bhandle, NULL, &sc->vge_bsize, 0)) {
		if (pci_mapreg_map(pa, VGE_PCI_LOIO, PCI_MAPREG_TYPE_IO, 0,
		    &sc->vge_btag, &sc->vge_bhandle, NULL, &sc->vge_bsize, 0)) {
			printf(": can't map mem or i/o space\n");
			return;
		}
	}

	/* Allocate interrupt */
	if (pci_intr_map(pa, &ih)) {
		printf(": couldn't map interrupt\n");
		return;
	}
	intrstr = pci_intr_string(pc, ih);
	sc->vge_intrhand = pci_intr_establish(pc, ih, IPL_NET, vge_intr, sc,
	    sc->vge_dev.dv_xname);
	if (sc->vge_intrhand == NULL) {
		printf(": couldn't establish interrupt");
		if (intrstr != NULL)
			printf(" at %s", intrstr);
		return;
	}
	printf(": %s", intrstr);

	sc->sc_dmat = pa->pa_dmat;
	sc->sc_pc = pa->pa_pc;

	/* Reset the adapter. */
	vge_reset(sc);

	/*
	 * Get station address from the EEPROM.
	 */
	vge_read_eeprom(sc, eaddr, VGE_EE_EADDR, 3, 1);

	bcopy(eaddr, &sc->arpcom.ac_enaddr, ETHER_ADDR_LEN);

	printf(", address %s\n",
	    ether_sprintf(sc->arpcom.ac_enaddr));

	error = vge_allocmem(sc);

	if (error)
		return;

	ifp = &sc->arpcom.ac_if;
	ifp->if_softc = sc;
	ifp->if_flags = IFF_BROADCAST | IFF_SIMPLEX | IFF_MULTICAST;
	ifp->if_ioctl = vge_ioctl;
	ifp->if_start = vge_start;
	ifp->if_watchdog = vge_watchdog;
#ifdef VGE_JUMBO
	ifp->if_hardmtu = VGE_JUMBO_MTU;
#endif
	IFQ_SET_MAXLEN(&ifp->if_snd, VGE_IFQ_MAXLEN);

	ifp->if_capabilities = IFCAP_VLAN_MTU | IFCAP_CSUM_IPv4 |
				IFCAP_CSUM_TCPv4 | IFCAP_CSUM_UDPv4;

#if NVLAN > 0
	ifp->if_capabilities |= IFCAP_VLAN_HWTAGGING;
#endif

	/* Set interface name */
	strlcpy(ifp->if_xname, sc->vge_dev.dv_xname, IFNAMSIZ);

	/* Do MII setup */
	sc->sc_mii.mii_ifp = ifp;
	sc->sc_mii.mii_readreg = vge_miibus_readreg;
	sc->sc_mii.mii_writereg = vge_miibus_writereg;
	sc->sc_mii.mii_statchg = vge_miibus_statchg;
	ifmedia_init(&sc->sc_mii.mii_media, 0,
	    vge_ifmedia_upd, vge_ifmedia_sts);
	mii_attach(self, &sc->sc_mii, 0xffffffff, MII_PHY_ANY,
	    MII_OFFSET_ANY, MIIF_DOPAUSE);
	if (LIST_FIRST(&sc->sc_mii.mii_phys) == NULL) {
		printf("%s: no PHY found!\n", sc->vge_dev.dv_xname);
		ifmedia_add(&sc->sc_mii.mii_media, IFM_ETHER|IFM_MANUAL,
		    0, NULL);
		ifmedia_set(&sc->sc_mii.mii_media, IFM_ETHER|IFM_MANUAL);
	} else
		ifmedia_set(&sc->sc_mii.mii_media, IFM_ETHER|IFM_AUTO);

	timeout_set(&sc->timer_handle, vge_tick, sc);

	/*
	 * Call MI attach routine.
	 */
	if_attach(ifp);
	ether_ifattach(ifp);
}

int
vge_detach(struct device *self, int flags)
{
	struct vge_softc *sc = (void *)self;
	struct ifnet *ifp = &sc->arpcom.ac_if;

	pci_intr_disestablish(sc->sc_pc, sc->vge_intrhand);

	vge_stop(sc);

	/* Detach all PHYs */
	mii_detach(&sc->sc_mii, MII_PHY_ANY, MII_OFFSET_ANY);

	/* Delete any remaining media. */
	ifmedia_delete_instance(&sc->sc_mii.mii_media, IFM_INST_ANY);

	ether_ifdetach(ifp);
	if_detach(ifp);

	vge_freemem(sc);

	bus_space_unmap(sc->vge_btag, sc->vge_bhandle, sc->vge_bsize);
	return (0);
}

int
vge_newbuf(struct vge_softc *sc, int idx, struct mbuf *m)
{
	struct mbuf		*m_new = NULL;
	struct vge_rx_desc	*r;
	bus_dmamap_t		rxmap = sc->vge_ldata.vge_rx_dmamap[idx];
	int			i;

	if (m == NULL) {
		/* Allocate a new mbuf */
		MGETHDR(m_new, M_DONTWAIT, MT_DATA);
		if (m_new == NULL)
			return (ENOBUFS);

		/* Allocate a cluster */
		MCLGET(m_new, M_DONTWAIT);
		if (!(m_new->m_flags & M_EXT)) {
			m_freem(m_new);
			return (ENOBUFS);
		}

		m = m_new;
	} else
		m->m_data = m->m_ext.ext_buf;

	m->m_len = m->m_pkthdr.len = MCLBYTES;
	/* Fix-up alignment so payload is doubleword-aligned */
	/* XXX m_adj(m, ETHER_ALIGN); */

	if (bus_dmamap_load_mbuf(sc->sc_dmat, rxmap, m, BUS_DMA_NOWAIT))
		return (ENOBUFS);

	if (rxmap->dm_nsegs > 1)
		goto out;

	/* Map the segments into RX descriptors */
	r = &sc->vge_ldata.vge_rx_list[idx];

	if (letoh32(r->vge_sts) & VGE_RDSTS_OWN) {
		printf("%s: tried to map a busy RX descriptor\n",
		    sc->vge_dev.dv_xname);
		goto out;
	}
	r->vge_buflen = htole16(VGE_BUFLEN(rxmap->dm_segs[0].ds_len) | VGE_RXDESC_I);
	r->vge_addrlo = htole32(VGE_ADDR_LO(rxmap->dm_segs[0].ds_addr));
	r->vge_addrhi = htole16(VGE_ADDR_HI(rxmap->dm_segs[0].ds_addr) & 0xFFFF);
	r->vge_sts = htole32(0);
	r->vge_ctl = htole32(0);

	/*
	 * Note: the manual fails to document the fact that for
	 * proper operation, the driver needs to replenish the RX
	 * DMA ring 4 descriptors at a time (rather than one at a
	 * time, like most chips). We can allocate the new buffers
	 * but we should not set the OWN bits until we're ready
	 * to hand back 4 of them in one shot.
	 */
#define VGE_RXCHUNK 4
	sc->vge_rx_consumed++;
	if (sc->vge_rx_consumed == VGE_RXCHUNK) {
		for (i = idx; i != idx - sc->vge_rx_consumed; i--)
			sc->vge_ldata.vge_rx_list[i].vge_sts |=
			    htole32(VGE_RDSTS_OWN);
		sc->vge_rx_consumed = 0;
	}

	sc->vge_ldata.vge_rx_mbuf[idx] = m;

	bus_dmamap_sync(sc->sc_dmat, rxmap, 0,
	    rxmap->dm_mapsize, BUS_DMASYNC_PREREAD);

	return (0);
out:
	DPRINTF(("vge_newbuf: out of memory\n"));
	if (m_new != NULL)
		m_freem(m_new);
	return (ENOMEM);
}

int
vge_tx_list_init(struct vge_softc *sc)
{
	bzero(sc->vge_ldata.vge_tx_list, VGE_TX_LIST_SZ);
	bzero(&sc->vge_ldata.vge_tx_mbuf,
	    (VGE_TX_DESC_CNT * sizeof(struct mbuf *)));

	bus_dmamap_sync(sc->sc_dmat,
	    sc->vge_ldata.vge_tx_list_map, 0,
	    sc->vge_ldata.vge_tx_list_map->dm_mapsize,
	    BUS_DMASYNC_PREWRITE);
	sc->vge_ldata.vge_tx_prodidx = 0;
	sc->vge_ldata.vge_tx_considx = 0;
	sc->vge_ldata.vge_tx_free = VGE_TX_DESC_CNT;

	return (0);
}

/* Init RX descriptors and allocate mbufs with vge_newbuf()
 * A ring is used, and last descriptor points to first. */
int
vge_rx_list_init(struct vge_softc *sc)
{
	int			i;

	bzero(sc->vge_ldata.vge_rx_list, VGE_RX_LIST_SZ);
	bzero(&sc->vge_ldata.vge_rx_mbuf,
	    (VGE_RX_DESC_CNT * sizeof(struct mbuf *)));

	sc->vge_rx_consumed = 0;

	for (i = 0; i < VGE_RX_DESC_CNT; i++) {
		if (vge_newbuf(sc, i, NULL) == ENOBUFS)
			return (ENOBUFS);
	}

	/* Flush the RX descriptors */

	bus_dmamap_sync(sc->sc_dmat,
	    sc->vge_ldata.vge_rx_list_map,
	    0, sc->vge_ldata.vge_rx_list_map->dm_mapsize,
	    BUS_DMASYNC_PREWRITE|BUS_DMASYNC_PREREAD);

	sc->vge_ldata.vge_rx_prodidx = 0;
	sc->vge_rx_consumed = 0;
	sc->vge_head = sc->vge_tail = NULL;

	return (0);
}

/*
 * RX handler. We support the reception of jumbo frames that have
 * been fragmented across multiple 2K mbuf cluster buffers.
 */
void
vge_rxeof(struct vge_softc *sc)
{
	struct mbuf_list	ml = MBUF_LIST_INITIALIZER();
	struct mbuf		*m;
	struct ifnet		*ifp;
	int			i, total_len;
	int			lim = 0;
	struct vge_rx_desc	*cur_rx;
	u_int32_t		rxstat, rxctl;

	ifp = &sc->arpcom.ac_if;
	i = sc->vge_ldata.vge_rx_prodidx;

	/* Invalidate the descriptor memory */

	bus_dmamap_sync(sc->sc_dmat,
	    sc->vge_ldata.vge_rx_list_map,
	    0, sc->vge_ldata.vge_rx_list_map->dm_mapsize,
	    BUS_DMASYNC_POSTREAD);

	while (!VGE_OWN(&sc->vge_ldata.vge_rx_list[i])) {
		struct mbuf *m0 = NULL;

		cur_rx = &sc->vge_ldata.vge_rx_list[i];
		m = sc->vge_ldata.vge_rx_mbuf[i];
		total_len = VGE_RXBYTES(cur_rx);
		rxstat = letoh32(cur_rx->vge_sts);
		rxctl = letoh32(cur_rx->vge_ctl);

		/* Invalidate the RX mbuf and unload its map */

		bus_dmamap_sync(sc->sc_dmat,
		    sc->vge_ldata.vge_rx_dmamap[i],
		    0, sc->vge_ldata.vge_rx_dmamap[i]->dm_mapsize,
		    BUS_DMASYNC_POSTWRITE);
		bus_dmamap_unload(sc->sc_dmat,
		    sc->vge_ldata.vge_rx_dmamap[i]);

		/*
		 * If the 'start of frame' bit is set, this indicates
		 * either the first fragment in a multi-fragment receive,
		 * or an intermediate fragment. Either way, we want to
		 * accumulate the buffers.
		 */
		if (rxstat & VGE_RXPKT_SOF) {
			DPRINTF(("vge_rxeof: SOF\n"));
			m->m_len = MCLBYTES;
			if (sc->vge_head == NULL)
				sc->vge_head = sc->vge_tail = m;
			else {
				m->m_flags &= ~M_PKTHDR;
				sc->vge_tail->m_next = m;
				sc->vge_tail = m;
			}
			vge_newbuf(sc, i, NULL);
			VGE_RX_DESC_INC(i);
			continue;
		}

		/*
		 * Bad/error frames will have the RXOK bit cleared.
		 * However, there's one error case we want to allow:
		 * if a VLAN tagged frame arrives and the chip can't
		 * match it against the CAM filter, it considers this
		 * a 'VLAN CAM filter miss' and clears the 'RXOK' bit.
		 * We don't want to drop the frame though: our VLAN
		 * filtering is done in software.
		 */
		if (!(rxstat & VGE_RDSTS_RXOK) && !(rxstat & VGE_RDSTS_VIDM)
		    && !(rxstat & VGE_RDSTS_CSUMERR)) {
			ifp->if_ierrors++;
			/*
			 * If this is part of a multi-fragment packet,
			 * discard all the pieces.
			 */
			if (sc->vge_head != NULL) {
				m_freem(sc->vge_head);
				sc->vge_head = sc->vge_tail = NULL;
			}
			vge_newbuf(sc, i, m);
			VGE_RX_DESC_INC(i);
			continue;
		}

		/*
		 * If allocating a replacement mbuf fails,
		 * reload the current one.
		 */

		if (vge_newbuf(sc, i, NULL) == ENOBUFS) {
			if (sc->vge_head != NULL) {
				m_freem(sc->vge_head);
				sc->vge_head = sc->vge_tail = NULL;
			}

			m0 = m_devget(mtod(m, char *),
			    total_len - ETHER_CRC_LEN, ETHER_ALIGN);
			vge_newbuf(sc, i, m);
			if (m0 == NULL) {
				ifp->if_ierrors++;
				continue;
			}
			m = m0;

			VGE_RX_DESC_INC(i);
			continue;
		}

		VGE_RX_DESC_INC(i);

		if (sc->vge_head != NULL) {
			m->m_len = total_len % MCLBYTES;
			/*
			 * Special case: if there's 4 bytes or less
			 * in this buffer, the mbuf can be discarded:
			 * the last 4 bytes is the CRC, which we don't
			 * care about anyway.
			 */
			if (m->m_len <= ETHER_CRC_LEN) {
				sc->vge_tail->m_len -=
				    (ETHER_CRC_LEN - m->m_len);
				m_freem(m);
			} else {
				m->m_len -= ETHER_CRC_LEN;
				m->m_flags &= ~M_PKTHDR;
				sc->vge_tail->m_next = m;
			}
			m = sc->vge_head;
			sc->vge_head = sc->vge_tail = NULL;
			m->m_pkthdr.len = total_len - ETHER_CRC_LEN;
		} else
			m->m_pkthdr.len = m->m_len =
			    (total_len - ETHER_CRC_LEN);

#ifdef __STRICT_ALIGNMENT
		bcopy(m->m_data, m->m_data + ETHER_ALIGN, total_len);
		m->m_data += ETHER_ALIGN;
#endif
		/* Do RX checksumming */

		/* Check IP header checksum */
		if ((rxctl & VGE_RDCTL_IPPKT) &&
		    (rxctl & VGE_RDCTL_IPCSUMOK))
			m->m_pkthdr.csum_flags |= M_IPV4_CSUM_IN_OK;

		/* Check TCP/UDP checksum */
		if ((rxctl & (VGE_RDCTL_TCPPKT|VGE_RDCTL_UDPPKT)) &&
		    (rxctl & VGE_RDCTL_PROTOCSUMOK))
			m->m_pkthdr.csum_flags |= M_TCP_CSUM_IN_OK | M_UDP_CSUM_IN_OK;

#if NVLAN > 0
		if (rxstat & VGE_RDSTS_VTAG) {
			m->m_pkthdr.ether_vtag = swap16(rxctl & VGE_RDCTL_VLANID);
			m->m_flags |= M_VLANTAG;
		}
#endif

		ml_enqueue(&ml, m);

		lim++;
		if (lim == VGE_RX_DESC_CNT)
			break;
	}

	if_input(ifp, &ml);

	/* Flush the RX DMA ring */
	bus_dmamap_sync(sc->sc_dmat,
	    sc->vge_ldata.vge_rx_list_map,
	    0, sc->vge_ldata.vge_rx_list_map->dm_mapsize,
	    BUS_DMASYNC_PREWRITE|BUS_DMASYNC_PREREAD);

	sc->vge_ldata.vge_rx_prodidx = i;
	CSR_WRITE_2(sc, VGE_RXDESC_RESIDUECNT, lim);
}

void
vge_txeof(struct vge_softc *sc)
{
	struct ifnet		*ifp;
	u_int32_t		txstat;
	int			idx;

	ifp = &sc->arpcom.ac_if;
	idx = sc->vge_ldata.vge_tx_considx;

	/* Invalidate the TX descriptor list */

	bus_dmamap_sync(sc->sc_dmat,
	    sc->vge_ldata.vge_tx_list_map,
	    0, sc->vge_ldata.vge_tx_list_map->dm_mapsize,
	    BUS_DMASYNC_POSTREAD);

	/* Transmitted frames can be now free'd from the TX list */
	while (idx != sc->vge_ldata.vge_tx_prodidx) {
		txstat = letoh32(sc->vge_ldata.vge_tx_list[idx].vge_sts);
		if (txstat & VGE_TDSTS_OWN)
			break;

		m_freem(sc->vge_ldata.vge_tx_mbuf[idx]);
		sc->vge_ldata.vge_tx_mbuf[idx] = NULL;
		bus_dmamap_unload(sc->sc_dmat,
		    sc->vge_ldata.vge_tx_dmamap[idx]);
		if (txstat & (VGE_TDSTS_EXCESSCOLL|VGE_TDSTS_COLL))
			ifp->if_collisions++;
		if (txstat & VGE_TDSTS_TXERR)
			ifp->if_oerrors++;

		sc->vge_ldata.vge_tx_free++;
		VGE_TX_DESC_INC(idx);
	}

	/* No changes made to the TX ring, so no flush needed */

	if (idx != sc->vge_ldata.vge_tx_considx) {
		sc->vge_ldata.vge_tx_considx = idx;
		ifq_clr_oactive(&ifp->if_snd);
		ifp->if_timer = 0;
	}

	/*
	 * If not all descriptors have been released reaped yet,
	 * reload the timer so that we will eventually get another
	 * interrupt that will cause us to re-enter this routine.
	 * This is done in case the transmitter has gone idle.
	 */
	if (sc->vge_ldata.vge_tx_free != VGE_TX_DESC_CNT)
		CSR_WRITE_1(sc, VGE_CRS1, VGE_CR1_TIMER0_ENABLE);
}

void
vge_tick(void *xsc)
{
	struct vge_softc	*sc = xsc;
	struct ifnet		*ifp = &sc->arpcom.ac_if;
	struct mii_data		*mii = &sc->sc_mii;
	int s;

	s = splnet();

	mii_tick(mii);

	if (sc->vge_link) {
		if (!(mii->mii_media_status & IFM_ACTIVE)) {
			sc->vge_link = 0;
			ifp->if_link_state = LINK_STATE_DOWN;
			if_link_state_change(ifp);
		}
	} else {
		if (mii->mii_media_status & IFM_ACTIVE &&
		    IFM_SUBTYPE(mii->mii_media_active) != IFM_NONE) {
			sc->vge_link = 1;
			if (mii->mii_media_status & IFM_FDX)
				ifp->if_link_state = LINK_STATE_FULL_DUPLEX;
			else
				ifp->if_link_state = LINK_STATE_HALF_DUPLEX;
			if_link_state_change(ifp);
			if (!IFQ_IS_EMPTY(&ifp->if_snd))
				vge_start(ifp);
		}
	}
	timeout_add_sec(&sc->timer_handle, 1);
	splx(s);
}

int
vge_intr(void *arg)
{
	struct vge_softc	*sc = arg;
	struct ifnet		*ifp;
	u_int32_t		status;
	int			claimed = 0;

	ifp = &sc->arpcom.ac_if;

	if (!(ifp->if_flags & IFF_UP))
		return 0;

	/* Disable interrupts */
	CSR_WRITE_1(sc, VGE_CRC3, VGE_CR3_INT_GMSK);

	for (;;) {
		status = CSR_READ_4(sc, VGE_ISR);
		DPRINTFN(3, ("vge_intr: status=%#x\n", status));

		/* If the card has gone away the read returns 0xffffffff. */
		if (status == 0xFFFFFFFF)
			break;

		if (status) {
			CSR_WRITE_4(sc, VGE_ISR, status);
		}

		if ((status & VGE_INTRS) == 0)
			break;

		claimed = 1;

		if (status & (VGE_ISR_RXOK|VGE_ISR_RXOK_HIPRIO))
			vge_rxeof(sc);

		if (status & (VGE_ISR_RXOFLOW|VGE_ISR_RXNODESC)) {
			DPRINTFN(2, ("vge_intr: RX error, recovering\n"));
			vge_rxeof(sc);
			CSR_WRITE_1(sc, VGE_RXQCSRS, VGE_RXQCSR_RUN);
			CSR_WRITE_1(sc, VGE_RXQCSRS, VGE_RXQCSR_WAK);
		}

		if (status & (VGE_ISR_TXOK0|VGE_ISR_TIMER0))
			vge_txeof(sc);

		if (status & (VGE_ISR_TXDMA_STALL|VGE_ISR_RXDMA_STALL)) {
			DPRINTFN(2, ("DMA_STALL\n"));
			vge_init(ifp);
		}

		if (status & VGE_ISR_LINKSTS) {
			timeout_del(&sc->timer_handle);
			vge_tick(sc);
		}
	}

	/* Re-enable interrupts */
	CSR_WRITE_1(sc, VGE_CRS3, VGE_CR3_INT_GMSK);

	if (!IFQ_IS_EMPTY(&ifp->if_snd))
		vge_start(ifp);

	return (claimed);
}

/*
 * Encapsulate an mbuf chain into the TX ring by combining it w/
 * the descriptors.
 */
int
vge_encap(struct vge_softc *sc, struct mbuf *m_head, int idx)
{
	bus_dmamap_t		txmap;
	struct vge_tx_desc	*d = NULL;
	struct vge_tx_frag	*f;
	int			error, frag;
	u_int32_t		vge_flags;
	unsigned int		len;

	vge_flags = 0;

	if (m_head->m_pkthdr.csum_flags & M_IPV4_CSUM_OUT)
		vge_flags |= VGE_TDCTL_IPCSUM;
	if (m_head->m_pkthdr.csum_flags & M_TCP_CSUM_OUT)
		vge_flags |= VGE_TDCTL_TCPCSUM;
	if (m_head->m_pkthdr.csum_flags & M_UDP_CSUM_OUT)
		vge_flags |= VGE_TDCTL_UDPCSUM;

	txmap = sc->vge_ldata.vge_tx_dmamap[idx];
	error = bus_dmamap_load_mbuf(sc->sc_dmat, txmap,
	    m_head, BUS_DMA_NOWAIT);
	switch (error) {
	case 0:
		break;
	case EFBIG: /* mbuf chain is too fragmented */
		if ((error = m_defrag(m_head, M_DONTWAIT)) == 0 &&
		    (error = bus_dmamap_load_mbuf(sc->sc_dmat, txmap, m_head,
		    BUS_DMA_NOWAIT)) == 0)
			break;
	default:
		return (error);
        }

	d = &sc->vge_ldata.vge_tx_list[idx];
	/* If owned by chip, fail */
	if (letoh32(d->vge_sts) & VGE_TDSTS_OWN)
		return (ENOBUFS);

	for (frag = 0; frag < txmap->dm_nsegs; frag++) {
		f = &d->vge_frag[frag];
		f->vge_buflen = htole16(VGE_BUFLEN(txmap->dm_segs[frag].ds_len));
		f->vge_addrlo = htole32(VGE_ADDR_LO(txmap->dm_segs[frag].ds_addr));
		f->vge_addrhi = htole16(VGE_ADDR_HI(txmap->dm_segs[frag].ds_addr) & 0xFFFF);
	}

	/* This chip does not do auto-padding */
	if (m_head->m_pkthdr.len < VGE_MIN_FRAMELEN) {
		f = &d->vge_frag[frag];

		f->vge_buflen = htole16(VGE_BUFLEN(VGE_MIN_FRAMELEN -
		    m_head->m_pkthdr.len));
		f->vge_addrlo = htole32(VGE_ADDR_LO(txmap->dm_segs[0].ds_addr));
		f->vge_addrhi = htole16(VGE_ADDR_HI(txmap->dm_segs[0].ds_addr) & 0xFFFF);
		len = VGE_MIN_FRAMELEN;
		frag++;
	} else
		len = m_head->m_pkthdr.len;

	/* For some reason, we need to tell the card fragment + 1 */
	frag++;

	bus_dmamap_sync(sc->sc_dmat, txmap, 0, txmap->dm_mapsize,
	    BUS_DMASYNC_PREWRITE);

	d->vge_sts = htole32(len << 16);
	d->vge_ctl = htole32(vge_flags|(frag << 28) | VGE_TD_LS_NORM);

	if (len > ETHERMTU + ETHER_HDR_LEN)
		d->vge_ctl |= htole32(VGE_TDCTL_JUMBO);

#if NVLAN > 0
	/* Set up hardware VLAN tagging. */
	if (m_head->m_flags & M_VLANTAG) {
		d->vge_ctl |= htole32(m_head->m_pkthdr.ether_vtag |
		    VGE_TDCTL_VTAG);
	}
#endif

	sc->vge_ldata.vge_tx_dmamap[idx] = txmap;
	sc->vge_ldata.vge_tx_mbuf[idx] = m_head;
	sc->vge_ldata.vge_tx_free--;
	sc->vge_ldata.vge_tx_list[idx].vge_sts |= htole32(VGE_TDSTS_OWN);

	idx++;
	return (0);
}

/*
 * Main transmit routine.
 */
void
vge_start(struct ifnet *ifp)
{
	struct vge_softc	*sc;
	struct mbuf		*m_head = NULL;
	int			idx, pidx = 0;

	sc = ifp->if_softc;

	if (!sc->vge_link || ifq_is_oactive(&ifp->if_snd))
		return;

	if (IFQ_IS_EMPTY(&ifp->if_snd))
		return;

	idx = sc->vge_ldata.vge_tx_prodidx;

	pidx = idx - 1;
	if (pidx < 0)
		pidx = VGE_TX_DESC_CNT - 1;

	for (;;) {
		if (sc->vge_ldata.vge_tx_mbuf[idx] != NULL) {
			ifq_set_oactive(&ifp->if_snd);
			break;
		}

		IFQ_DEQUEUE(&ifp->if_snd, m_head);
		if (m_head == NULL)
			break;

		if (vge_encap(sc, m_head, idx)) {
			m_freem(m_head);
			ifp->if_oerrors++;
			continue;
		}

		/*
		 * If there's a BPF listener, bounce a copy of this frame
		 * to him.
		 */
#if NBPFILTER > 0
		if (ifp->if_bpf)
			bpf_mtap_ether(ifp->if_bpf, m_head, BPF_DIRECTION_OUT);
#endif

		sc->vge_ldata.vge_tx_list[pidx].vge_frag[0].vge_buflen |=
		    htole16(VGE_TXDESC_Q);

		pidx = idx;
		VGE_TX_DESC_INC(idx);
	}

	if (idx == sc->vge_ldata.vge_tx_prodidx) {
		return;
	}

	/* Flush the TX descriptors */

	bus_dmamap_sync(sc->sc_dmat,
	    sc->vge_ldata.vge_tx_list_map,
	    0, sc->vge_ldata.vge_tx_list_map->dm_mapsize,
	    BUS_DMASYNC_PREWRITE|BUS_DMASYNC_PREREAD);

	/* Issue a transmit command. */
	CSR_WRITE_2(sc, VGE_TXQCSRS, VGE_TXQCSR_WAK0);

	sc->vge_ldata.vge_tx_prodidx = idx;

	/*
	 * Use the countdown timer for interrupt moderation.
	 * 'TX done' interrupts are disabled. Instead, we reset the
	 * countdown timer, which will begin counting until it hits
	 * the value in the SSTIMER register, and then trigger an
	 * interrupt. Each time we set the TIMER0_ENABLE bit, the
	 * the timer count is reloaded. Only when the transmitter
	 * is idle will the timer hit 0 and an interrupt fire.
	 */
	CSR_WRITE_1(sc, VGE_CRS1, VGE_CR1_TIMER0_ENABLE);

	/*
	 * Set a timeout in case the chip goes out to lunch.
	 */
	ifp->if_timer = 5;
}

int
vge_init(struct ifnet *ifp)
{
	struct vge_softc	*sc = ifp->if_softc;
	int			i;

	/*
	 * Cancel pending I/O and free all RX/TX buffers.
	 */
	vge_stop(sc);
	vge_reset(sc);

	/* Initialize RX descriptors list */
	if (vge_rx_list_init(sc) == ENOBUFS) {
		printf("%s: init failed: no memory for RX buffers\n",
		    sc->vge_dev.dv_xname);
		vge_stop(sc);
		return (ENOBUFS);
	}
	/* Initialize TX descriptors */
	if (vge_tx_list_init(sc) == ENOBUFS) {
		printf("%s: init failed: no memory for TX buffers\n",
		    sc->vge_dev.dv_xname);
		vge_stop(sc);
		return (ENOBUFS);
	}

	/* Set our station address */
	for (i = 0; i < ETHER_ADDR_LEN; i++)
		CSR_WRITE_1(sc, VGE_PAR0 + i, sc->arpcom.ac_enaddr[i]);

	/* Set receive FIFO threshold */
	CSR_CLRBIT_1(sc, VGE_RXCFG, VGE_RXCFG_FIFO_THR);
	CSR_SETBIT_1(sc, VGE_RXCFG, VGE_RXFIFOTHR_128BYTES);

	if (ifp->if_capabilities & IFCAP_VLAN_HWTAGGING) {
		/*
		 * Allow transmission and reception of VLAN tagged
		 * frames.
		 */
		CSR_CLRBIT_1(sc, VGE_RXCFG, VGE_RXCFG_VTAGOPT);
		CSR_SETBIT_1(sc, VGE_RXCFG, VGE_VTAG_OPT2);
	}

	/* Set DMA burst length */
	CSR_CLRBIT_1(sc, VGE_DMACFG0, VGE_DMACFG0_BURSTLEN);
	CSR_SETBIT_1(sc, VGE_DMACFG0, VGE_DMABURST_128);

	CSR_SETBIT_1(sc, VGE_TXCFG, VGE_TXCFG_ARB_PRIO|VGE_TXCFG_NONBLK);

	/* Set collision backoff algorithm */
	CSR_CLRBIT_1(sc, VGE_CHIPCFG1, VGE_CHIPCFG1_CRANDOM|
	    VGE_CHIPCFG1_CAP|VGE_CHIPCFG1_MBA|VGE_CHIPCFG1_BAKOPT);
	CSR_SETBIT_1(sc, VGE_CHIPCFG1, VGE_CHIPCFG1_OFSET);

	/* Disable LPSEL field in priority resolution */
	CSR_SETBIT_1(sc, VGE_DIAGCTL, VGE_DIAGCTL_LPSEL_DIS);

	/*
	 * Load the addresses of the DMA queues into the chip.
	 * Note that we only use one transmit queue.
	 */
	CSR_WRITE_4(sc, VGE_TXDESC_ADDR_LO0,
	    VGE_ADDR_LO(sc->vge_ldata.vge_tx_listseg.ds_addr));
	CSR_WRITE_2(sc, VGE_TXDESCNUM, VGE_TX_DESC_CNT - 1);

	CSR_WRITE_4(sc, VGE_RXDESC_ADDR_LO,
	    VGE_ADDR_LO(sc->vge_ldata.vge_rx_listseg.ds_addr));
	CSR_WRITE_2(sc, VGE_RXDESCNUM, VGE_RX_DESC_CNT - 1);
	CSR_WRITE_2(sc, VGE_RXDESC_RESIDUECNT, VGE_RX_DESC_CNT);

	/* Enable and wake up the RX descriptor queue */
	CSR_WRITE_1(sc, VGE_RXQCSRS, VGE_RXQCSR_RUN);
	CSR_WRITE_1(sc, VGE_RXQCSRS, VGE_RXQCSR_WAK);

	/* Enable the TX descriptor queue */
	CSR_WRITE_2(sc, VGE_TXQCSRS, VGE_TXQCSR_RUN0);

	/* Set up the receive filter -- allow large frames for VLANs. */
	CSR_WRITE_1(sc, VGE_RXCTL, VGE_RXCTL_RX_GIANT);

	/* Program promiscuous mode and multicast filters. */
	vge_iff(sc);

	/* Initialize pause timer. */
	CSR_WRITE_2(sc, VGE_TX_PAUSE_TIMER, 0xFFFF);
	/*
	 * Initialize flow control parameters.
	 *  TX XON high threshold : 48
	 *  TX pause low threshold : 24
	 *  Disable half-duplex flow control
	 */
	CSR_WRITE_1(sc, VGE_CRC2, 0xFF);
	CSR_WRITE_1(sc, VGE_CRS2, VGE_CR2_XON_ENABLE | 0x0B);

	/* Enable jumbo frame reception (if desired) */

	/* Start the MAC. */
	CSR_WRITE_1(sc, VGE_CRC0, VGE_CR0_STOP);
	CSR_WRITE_1(sc, VGE_CRS1, VGE_CR1_NOPOLL);
	CSR_WRITE_1(sc, VGE_CRS0,
	    VGE_CR0_TX_ENABLE|VGE_CR0_RX_ENABLE|VGE_CR0_START);

	/*
	 * Configure one-shot timer for microsecond
	 * resulution and load it for 500 usecs.
	 */
	CSR_SETBIT_1(sc, VGE_DIAGCTL, VGE_DIAGCTL_TIMER0_RES);
	CSR_WRITE_2(sc, VGE_SSTIMER, 400);

	/*
	 * Configure interrupt moderation for receive. Enable
	 * the holdoff counter and load it, and set the RX
	 * suppression count to the number of descriptors we
	 * want to allow before triggering an interrupt.
	 * The holdoff timer is in units of 20 usecs.
	 */

#ifdef notyet
	CSR_WRITE_1(sc, VGE_INTCTL1, VGE_INTCTL_TXINTSUP_DISABLE);
	/* Select the interrupt holdoff timer page. */
	CSR_CLRBIT_1(sc, VGE_CAMCTL, VGE_CAMCTL_PAGESEL);
	CSR_SETBIT_1(sc, VGE_CAMCTL, VGE_PAGESEL_INTHLDOFF);
	CSR_WRITE_1(sc, VGE_INTHOLDOFF, 10); /* ~200 usecs */

	/* Enable use of the holdoff timer. */
	CSR_WRITE_1(sc, VGE_CRS3, VGE_CR3_INT_HOLDOFF);
	CSR_WRITE_1(sc, VGE_INTCTL1, VGE_INTCTL_SC_RELOAD);

	/* Select the RX suppression threshold page. */
	CSR_CLRBIT_1(sc, VGE_CAMCTL, VGE_CAMCTL_PAGESEL);
	CSR_SETBIT_1(sc, VGE_CAMCTL, VGE_PAGESEL_RXSUPPTHR);
	CSR_WRITE_1(sc, VGE_RXSUPPTHR, 64); /* interrupt after 64 packets */

	/* Restore the page select bits. */
	CSR_CLRBIT_1(sc, VGE_CAMCTL, VGE_CAMCTL_PAGESEL);
	CSR_SETBIT_1(sc, VGE_CAMCTL, VGE_PAGESEL_MAR);
#endif

	/*
	 * Enable interrupts.
	 */
	CSR_WRITE_4(sc, VGE_IMR, VGE_INTRS);
	CSR_WRITE_4(sc, VGE_ISR, 0);
	CSR_WRITE_1(sc, VGE_CRS3, VGE_CR3_INT_GMSK);

	/* Restore BMCR state */
	mii_mediachg(&sc->sc_mii);

	ifp->if_flags |= IFF_RUNNING;
	ifq_clr_oactive(&ifp->if_snd);

	sc->vge_link = 0;

	if (!timeout_pending(&sc->timer_handle))
		timeout_add_sec(&sc->timer_handle, 1);

	return (0);
}

/*
 * Set media options.
 */
int
vge_ifmedia_upd(struct ifnet *ifp)
{
	struct vge_softc *sc = ifp->if_softc;

	return (mii_mediachg(&sc->sc_mii));
}

/*
 * Report current media status.
 */
void
vge_ifmedia_sts(struct ifnet *ifp, struct ifmediareq *ifmr)
{
	struct vge_softc *sc = ifp->if_softc;

	mii_pollstat(&sc->sc_mii);
	ifmr->ifm_active = sc->sc_mii.mii_media_active;
	ifmr->ifm_status = sc->sc_mii.mii_media_status;
}

void
vge_miibus_statchg(struct device *dev)
{
	struct vge_softc	*sc = (struct vge_softc *)dev;
	struct mii_data		*mii;
	struct ifmedia_entry	*ife;

	mii = &sc->sc_mii;
	ife = mii->mii_media.ifm_cur;

	/*
	 * If the user manually selects a media mode, we need to turn
	 * on the forced MAC mode bit in the DIAGCTL register. If the
	 * user happens to choose a full duplex mode, we also need to
	 * set the 'force full duplex' bit. This applies only to
	 * 10Mbps and 100Mbps speeds. In autoselect mode, forced MAC
	 * mode is disabled, and in 1000baseT mode, full duplex is
	 * always implied, so we turn on the forced mode bit but leave
	 * the FDX bit cleared.
	 */

	switch (IFM_SUBTYPE(ife->ifm_media)) {
	case IFM_AUTO:
		CSR_CLRBIT_1(sc, VGE_DIAGCTL, VGE_DIAGCTL_MACFORCE);
		CSR_CLRBIT_1(sc, VGE_DIAGCTL, VGE_DIAGCTL_FDXFORCE);
		break;
	case IFM_1000_T:
		CSR_SETBIT_1(sc, VGE_DIAGCTL, VGE_DIAGCTL_MACFORCE);
		CSR_CLRBIT_1(sc, VGE_DIAGCTL, VGE_DIAGCTL_FDXFORCE);
		break;
	case IFM_100_TX:
	case IFM_10_T:
		CSR_SETBIT_1(sc, VGE_DIAGCTL, VGE_DIAGCTL_MACFORCE);
		if ((ife->ifm_media & IFM_GMASK) == IFM_FDX) {
			CSR_SETBIT_1(sc, VGE_DIAGCTL, VGE_DIAGCTL_FDXFORCE);
		} else {
			CSR_CLRBIT_1(sc, VGE_DIAGCTL, VGE_DIAGCTL_FDXFORCE);
		}
		break;
	default:
		printf("%s: unknown media type: %llx\n",
		    sc->vge_dev.dv_xname, IFM_SUBTYPE(ife->ifm_media));
		break;
	}

	/*
	 * 802.3x flow control
	*/
	CSR_WRITE_1(sc, VGE_CRC2, VGE_CR2_FDX_TXFLOWCTL_ENABLE |
	    VGE_CR2_FDX_RXFLOWCTL_ENABLE);
	if ((IFM_OPTIONS(mii->mii_media_active) & IFM_ETH_TXPAUSE) != 0)
		CSR_WRITE_1(sc, VGE_CRS2, VGE_CR2_FDX_TXFLOWCTL_ENABLE);
	if ((IFM_OPTIONS(mii->mii_media_active) & IFM_ETH_RXPAUSE) != 0)
		CSR_WRITE_1(sc, VGE_CRS2, VGE_CR2_FDX_RXFLOWCTL_ENABLE);
}

int
vge_ioctl(struct ifnet *ifp, u_long command, caddr_t data)
{
	struct vge_softc	*sc = ifp->if_softc;
	struct ifreq		*ifr = (struct ifreq *) data;
	int			s, error = 0;

	s = splnet();

	switch (command) {
	case SIOCSIFADDR:
		ifp->if_flags |= IFF_UP;
		if (!(ifp->if_flags & IFF_RUNNING))
			vge_init(ifp);
		break;

	case SIOCSIFFLAGS:
		if (ifp->if_flags & IFF_UP) {
			if (ifp->if_flags & IFF_RUNNING)
				error = ENETRESET;
			else
				vge_init(ifp);
		} else {
			if (ifp->if_flags & IFF_RUNNING)
				vge_stop(sc);
		}
		break;

	case SIOCGIFMEDIA:
	case SIOCSIFMEDIA:
		error = ifmedia_ioctl(ifp, ifr, &sc->sc_mii.mii_media, command);
		break;

	default:
		error = ether_ioctl(ifp, &sc->arpcom, command, data);
	}

	if (error == ENETRESET) {
		if (ifp->if_flags & IFF_RUNNING)
			vge_iff(sc);
		error = 0;
	}

	splx(s);
	return (error);
}

void
vge_watchdog(struct ifnet *ifp)
{
	struct vge_softc *sc = ifp->if_softc;
	int s;

	s = splnet();
	printf("%s: watchdog timeout\n", sc->vge_dev.dv_xname);
	ifp->if_oerrors++;

	vge_txeof(sc);
	vge_rxeof(sc);

	vge_init(ifp);

	splx(s);
}

/*
 * Stop the adapter and free any mbufs allocated to the
 * RX and TX lists.
 */
void
vge_stop(struct vge_softc *sc)
{
	int			i;
	struct ifnet		*ifp;

	ifp = &sc->arpcom.ac_if;
	ifp->if_timer = 0;

	timeout_del(&sc->timer_handle);

	ifp->if_flags &= ~IFF_RUNNING;
	ifq_clr_oactive(&ifp->if_snd);

	CSR_WRITE_1(sc, VGE_CRC3, VGE_CR3_INT_GMSK);
	CSR_WRITE_1(sc, VGE_CRS0, VGE_CR0_STOP);
	CSR_WRITE_4(sc, VGE_ISR, 0xFFFFFFFF);
	CSR_WRITE_2(sc, VGE_TXQCSRC, 0xFFFF);
	CSR_WRITE_1(sc, VGE_RXQCSRC, 0xFF);
	CSR_WRITE_4(sc, VGE_RXDESC_ADDR_LO, 0);

	if (sc->vge_head != NULL) {
		m_freem(sc->vge_head);
		sc->vge_head = sc->vge_tail = NULL;
	}

	/* Free the TX list buffers. */
	for (i = 0; i < VGE_TX_DESC_CNT; i++) {
		if (sc->vge_ldata.vge_tx_mbuf[i] != NULL) {
			bus_dmamap_unload(sc->sc_dmat,
			    sc->vge_ldata.vge_tx_dmamap[i]);
			m_freem(sc->vge_ldata.vge_tx_mbuf[i]);
			sc->vge_ldata.vge_tx_mbuf[i] = NULL;
		}
	}

	/* Free the RX list buffers. */
	for (i = 0; i < VGE_RX_DESC_CNT; i++) {
		if (sc->vge_ldata.vge_rx_mbuf[i] != NULL) {
			bus_dmamap_unload(sc->sc_dmat,
			    sc->vge_ldata.vge_rx_dmamap[i]);
			m_freem(sc->vge_ldata.vge_rx_mbuf[i]);
			sc->vge_ldata.vge_rx_mbuf[i] = NULL;
		}
	}
}
@


1.70
log
@G/C IFQ_SET_READY().
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.69 2015/11/25 03:09:59 dlg Exp $	*/
a1183 2
		else
			ifp->if_opackets++;
@


1.69
log
@replace IFF_OACTIVE manipulation with mpsafe operations.

there are two things shared between the network stack and drivers
in the send path: the send queue and the IFF_OACTIVE flag. the send
queue is now protected by a mutex. this diff makes the oactive
functionality mpsafe too.

IFF_OACTIVE is part of if_flags. there are two problems with that.
firstly, if_flags is a short and we dont have any MI atomic operations
to manipulate a short. secondly, while we could make the IFF_OACTIVE
operates mpsafe, all changes to other flags would have to be made
safe at the same time, otherwise a read-modify-write cycle on their
updates could clobber the oactive change.

instead, this moves the oactive mark into struct ifqueue and provides
an API for changing it. there's ifq_set_oactive, ifq_clr_oactive,
and ifq_is_oactive. these are modelled on ifsq_set_oactive,
ifsq_clr_oactive, and ifsq_is_oactive in dragonflybsd.

this diff includes changes to all the drivers manipulating IFF_OACTIVE
to now use the ifsq_{set,clr_is}_oactive API too.

ok kettenis@@ mpi@@ jmatthew@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.68 2015/11/24 17:11:39 mpi Exp $	*/
a780 1
	IFQ_SET_READY(&ifp->if_snd);
@


1.68
log
@You only need <net/if_dl.h> if you're using LLADDR() or a sockaddr_dl.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.67 2015/11/16 04:02:34 dlg Exp $	*/
d1196 1
a1196 1
		ifp->if_flags &= ~IFF_OACTIVE;
d1415 1
a1415 1
	if (!sc->vge_link || ifp->if_flags & IFF_OACTIVE)
d1429 1
a1429 1
			ifp->if_flags |= IFF_OACTIVE;
d1642 1
a1642 1
	ifp->if_flags &= ~IFF_OACTIVE;
d1812 2
a1813 1
	ifp->if_flags &= ~(IFF_RUNNING | IFF_OACTIVE);
@


1.67
log
@rework vge_start to avoid IFQ_POLL

firstly, this checks for space in the tx ring before looking at the
send queue. if there's no space, then IFF_OACTIVE is set and break.

if there's space use IFQ_DEQUEUE to pull a packet off. if we fail
to encapsulate it, it gets dropped.

encap has been changed so the dmamaps the mbufs are loaded into are
created with 7 segments instead of 32. this means we detect when
the packet would overflow the tx descriptor at dmamap load time,
rather than after we've looped over the segments writing them into
the descriptor. we now use m_defrag to defrag the mbuf instead of
allocating a new one and using m_copydata.

now if we have any encap error on the first mbuf, we no longer set
IFF_OACTIVE and wait for an interrupt that never comes to clear it.

testing and (excellent) code review by richard proctor
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.66 2015/11/14 17:54:57 mpi Exp $	*/
a98 1
#include <net/if_dl.h>
@


1.66
log
@Do not include <net/if_vlan_var.h> when it's not necessary.

Because of the VLAN hacks in mpw(4) this file still contains the definition
of "struct ifvlan" which depends on <sys/refcnt.h> which in turns pull
<sys/atomic.h>...
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.65 2015/10/25 13:04:28 mpi Exp $	*/
d618 2
a619 2
		error = bus_dmamap_create(sc->sc_dmat, MCLBYTES * nseg, nseg,
		    MCLBYTES, 0, BUS_DMA_ALLOCNOW,
a1318 1
	struct ifnet		*ifp = &sc->arpcom.ac_if;
a1321 1
	struct mbuf		*mnew = NULL;
d1324 1
a1335 1
repack:
d1338 11
a1348 5
	if (error) {
		printf("%s: can't map mbuf (error %d)\n",
		    sc->vge_dev.dv_xname, error);
		return (ENOBUFS);
	}
a1355 3
		/* Check if we have used all 7 fragments. */
		if (frag == VGE_TX_FRAGS)
			break;
a1361 25
	/*
	 * We used up all 7 fragments!  Now what we have to do is
	 * copy the data into a mbuf cluster and map that.
	 */
	if (frag == VGE_TX_FRAGS) {
		MGETHDR(mnew, M_DONTWAIT, MT_DATA);
		if (mnew == NULL)
			return (ENOBUFS);

		if (m_head->m_pkthdr.len > MHLEN) {
			MCLGET(mnew, M_DONTWAIT);
			if (!(mnew->m_flags & M_EXT)) {
				m_freem(mnew);
				return (ENOBUFS);
			}
		}
		m_copydata(m_head, 0, m_head->m_pkthdr.len,
		    mtod(mnew, caddr_t));
		mnew->m_pkthdr.len = mnew->m_len = m_head->m_pkthdr.len;
		IFQ_DEQUEUE(&ifp->if_snd, m_head);
		m_freem(m_head);
		m_head = mnew;
		goto repack;
	}

d1370 1
a1370 1
		m_head->m_pkthdr.len = VGE_MIN_FRAMELEN;
d1372 3
a1374 1
	}
d1381 1
a1381 1
	d->vge_sts = htole32(m_head->m_pkthdr.len << 16);
d1384 1
a1384 1
	if (m_head->m_pkthdr.len > ETHERMTU + ETHER_HDR_LEN)
a1400 4
	if (mnew == NULL) {
		/* if mbuf is coalesced, it is already dequeued */
		IFQ_DEQUEUE(&ifp->if_snd, m_head);
	}
d1428 7
a1434 2
	while (sc->vge_ldata.vge_tx_mbuf[idx] == NULL) {
		IFQ_POLL(&ifp->if_snd, m_head);
d1438 6
a1451 5

		if (vge_encap(sc, m_head, idx)) {
			ifp->if_flags |= IFF_OACTIVE;
			break;
		}
@


1.65
log
@arp_ifinit() is no longer needed.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.64 2015/09/11 13:02:28 stsp Exp $	*/
a103 5

#if NVLAN > 0
#include <net/if_types.h>
#include <net/if_vlan_var.h>
#endif
@


1.64
log
@Make room for media types of the future. Extend the ifmedia word to 64 bits.
This changes numbers of the SIOCSIFMEDIA and SIOCGIFMEDIA ioctls and
grows struct ifmediareq.

Old ifconfig and dhclient binaries can still assign addresses, however
the 'media' subcommand stops working. Recompiling ifconfig and dhclient
with new headers before a reboot should not be necessary unless in very
special circumstances where non-default media settings must be used to
get link and console access is not available.

There may be some MD fallout but that will be cleared up later.

ok deraadt miod
with help and suggestions from several sharks attending l2k15
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.63 2015/06/24 09:40:54 mpi Exp $	*/
a1761 1
	struct ifaddr		*ifa = (struct ifaddr *) data;
a1771 2
		if (ifa->ifa_addr->sa_family == AF_INET)
			arp_ifinit(&sc->arpcom, ifa);
@


1.63
log
@Increment if_ipackets in if_input().

Note that pseudo-drivers not using if_input() are not affected by this
conversion.

ok mikeb@@, kettenis@@, claudio@@, dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.62 2015/04/13 08:45:48 mpi Exp $	*/
d1742 1
a1742 1
		printf("%s: unknown media type: %x\n",
@


1.62
log
@Now that if_input() set the receiving interface pointer on mbufs for us
there's no need to do it in m_devget(9).

Stop passing an ``ifp'' will help for upcoming interface pointer -> index
conversion.

While here remove unused ``ifp'' argument from m_clget(9) and kill two
birds^W layer violations in one commit.

ok henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.61 2015/04/08 10:07:47 mpi Exp $	*/
a1121 2
		ifp->if_ipackets++;

@


1.61
log
@Convert to if_input().

ok dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.60 2015/03/14 03:38:48 jsg Exp $	*/
d1080 1
a1080 1
			    total_len - ETHER_CRC_LEN, ETHER_ALIGN, ifp);
@


1.60
log
@Remove some includes include-what-you-use claims don't
have any direct symbols used.  Tested for indirect use by compiling
amd64/i386/sparc64 kernels.

ok tedu@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.59 2014/12/22 02:28:52 tedu Exp $	*/
d986 1
a1122 1
		m->m_pkthdr.rcvif = ifp;
d1143 1
a1143 5
#if NBPFILTER > 0
		if (ifp->if_bpf)
			bpf_mtap_ether(ifp->if_bpf, m, BPF_DIRECTION_IN);
#endif
		ether_input_mbuf(ifp, m);
d1149 2
@


1.59
log
@unifdef INET
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.58 2014/07/22 13:12:11 mpi Exp $	*/
a113 1
#include <dev/mii/mii.h>
@


1.58
log
@Fewer <netinet/in_systm.h>
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.57 2013/08/21 05:21:44 dlg Exp $	*/
a101 1
#ifdef INET
a103 1
#endif
a1777 1
#ifdef INET
a1779 1
#endif
@


1.57
log
@get rid of the copy argument in m_devget that let you provide an
alternative to bcopy since noone uses it.

while there use memcpy instead of bcopy because we know the memory cannot
overlap.

ok henning@@ matthew@@ mikeb@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.56 2013/08/07 01:06:38 bluhm Exp $	*/
a103 2
#include <netinet/in_systm.h>
#include <netinet/ip.h>
@


1.56
log
@Most network drivers include netinet/in_var.h, but apparently they
don't have to.  Just remove these include lines.
Compiled on amd64 i386 sparc64; OK henning@@ mikeb@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.55 2013/03/15 01:33:23 brad Exp $	*/
d1084 1
a1084 1
			    total_len - ETHER_CRC_LEN, ETHER_ALIGN, ifp, NULL);
@


1.55
log
@Rewrite receive filter handling and ioctl bits.

ok sthen@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.54 2013/03/14 17:04:50 brad Exp $	*/
a104 1
#include <netinet/in_var.h>
@


1.54
log
@Add some missing bits for flow control support and enable it.

Tested with PCI and PCIe vge(4).

ok sthen@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.53 2012/11/29 21:10:32 brad Exp $	*/
d165 1
a165 1
void vge_setmulti	(struct vge_softc *);
d472 3
a474 3
 * Program the multicast filter. We use the 64-entry CAM filter
 * for perfect filtering. If there's more than 64 multicast addresses,
 * we use the hash filter instead.
d477 1
a477 1
vge_setmulti(struct vge_softc *sc)
d483 2
a485 1
	u_int32_t		h = 0, hashes[2] = { 0, 0 };
a486 1
	/* First, zot all the multicast entries. */
d488 4
a491 2
	CSR_WRITE_4(sc, VGE_MAR0, 0);
	CSR_WRITE_4(sc, VGE_MAR1, 0);
d495 2
a496 2
	 * If the user wants allmulti or promisc mode, enable reception
	 * of all multicast frames.
d498 1
a498 7
	if (ifp->if_flags & IFF_PROMISC) {
allmulti:
		CSR_WRITE_4(sc, VGE_MAR0, 0xFFFFFFFF);
		CSR_WRITE_4(sc, VGE_MAR1, 0xFFFFFFFF);
		ifp->if_flags |= IFF_ALLMULTI;
		return;
	}
d500 2
a501 16
	/* Now program new ones */
	ETHER_FIRST_MULTI(step, ac, enm);
	while (enm != NULL) {
		if (bcmp(enm->enm_addrlo, enm->enm_addrhi, ETHER_ADDR_LEN))
			goto allmulti;

		error = vge_cam_set(sc, enm->enm_addrlo);
		if (error)
			break;

		ETHER_NEXT_MULTI(step, enm);
	}

	/* If there were too many addresses, use the hash filter. */
	if (error) {
		vge_cam_clear(sc);
d503 6
d513 1
d518 6
d525 2
a526 2
		CSR_WRITE_4(sc, VGE_MAR0, hashes[0]);
		CSR_WRITE_4(sc, VGE_MAR1, hashes[1]);
d528 4
a1589 1

d1607 1
a1607 19
	CSR_WRITE_1(sc, VGE_RXCTL, VGE_RXCTL_RX_UCAST|VGE_RXCTL_RX_GIANT);

	/* If we want promiscuous mode, set the allframes bit. */
	if (ifp->if_flags & IFF_PROMISC) {
		CSR_SETBIT_1(sc, VGE_RXCTL, VGE_RXCTL_RX_PROMISC);
	}

	/* Set capture broadcast bit to capture broadcast frames. */
	if (ifp->if_flags & IFF_BROADCAST) {
		CSR_SETBIT_1(sc, VGE_RXCTL, VGE_RXCTL_RX_BCAST);
	}

	/* Set multicast bit to capture multicast frames. */
	if (ifp->if_flags & IFF_MULTICAST) {
		CSR_SETBIT_1(sc, VGE_RXCTL, VGE_RXCTL_RX_MCAST);
	}

	/* Init the cam filter. */
	vge_cam_clear(sc);
d1609 2
a1610 2
	/* Init the multicast filter. */
	vge_setmulti(sc);
a1679 1
	sc->vge_if_flags = 0;
d1781 2
a1782 1
		switch (ifa->ifa_addr->sa_family) {
d1784 1
a1784 2
		case AF_INET:
			vge_init(ifp);
a1785 1
			break;
a1786 4
		default:
			vge_init(ifp);
			break;
		}
d1791 3
a1793 13
			if (ifp->if_flags & IFF_RUNNING &&
			    ifp->if_flags & IFF_PROMISC &&
			    !(sc->vge_if_flags & IFF_PROMISC)) {
				CSR_SETBIT_1(sc, VGE_RXCTL,
				    VGE_RXCTL_RX_PROMISC);
				vge_setmulti(sc);
			} else if (ifp->if_flags & IFF_RUNNING &&
			    !(ifp->if_flags & IFF_PROMISC) &&
			    sc->vge_if_flags & IFF_PROMISC) {
				CSR_CLRBIT_1(sc, VGE_RXCTL,
				    VGE_RXCTL_RX_PROMISC);
				vge_setmulti(sc);
                        } else
a1798 1
		sc->vge_if_flags = ifp->if_flags;
d1812 1
a1812 1
			vge_setmulti(sc);
@


1.53
log
@Remove setting an initial assumed baudrate upon driver attach which is not
necessarily correct, there might not even be a link when attaching.

ok mikeb@@ reyk@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.52 2012/11/23 18:40:30 gsoares Exp $	*/
d814 1
a814 1
	    MII_OFFSET_ANY, 0);
d1632 10
a1641 3
	/* Enable flow control */

	CSR_WRITE_1(sc, VGE_CRS2, 0x8B);
d1777 10
@


1.52
log
@set ifp->if_baudrate with IF_Gbps() / IF_Mbps().

OK reyk@@ sthen@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.51 2011/06/22 16:44:27 tedu Exp $	*/
a789 1
	ifp->if_baudrate = IF_Gbps(1);
@


1.51
log
@kill a few more casts that aren't helpful.  ok krw miod
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.50 2011/04/05 18:01:21 henning Exp $	*/
d790 1
a790 1
	ifp->if_baudrate = 1000000000;
@


1.50
log
@mechanic rename M_{TCP|UDP}V4_CSUM_OUT -> M_{TCP|UDP}_CSUM_OUT
ok claudio krw
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.49 2011/04/03 15:36:03 jasper Exp $	*/
d774 1
a774 1
	bcopy(eaddr, (char *)&sc->arpcom.ac_enaddr, ETHER_ADDR_LEN);
d940 2
a941 2
	bzero ((char *)sc->vge_ldata.vge_tx_list, VGE_TX_LIST_SZ);
	bzero ((char *)&sc->vge_ldata.vge_tx_mbuf,
d962 2
a963 2
	bzero ((char *)sc->vge_ldata.vge_rx_list, VGE_RX_LIST_SZ);
	bzero ((char *)&sc->vge_ldata.vge_rx_mbuf,
d1126 1
a1126 2
		bcopy(m->m_data, m->m_data + ETHER_ALIGN,
		    total_len);
@


1.49
log
@use nitems(); no binary change for drivers that are compiled on amd64.

ok claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.48 2010/08/27 17:08:00 jsg Exp $	*/
d1349 1
a1349 1
	if (m_head->m_pkthdr.csum_flags & M_TCPV4_CSUM_OUT)
d1351 1
a1351 1
	if (m_head->m_pkthdr.csum_flags & M_UDPV4_CSUM_OUT)
@


1.48
log
@remove the unused if_init callback in struct ifnet
ok deraadt@@ henning@@ claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.47 2010/02/24 21:44:12 kettenis Exp $	*/
d575 1
a575 1
	    sizeof(vge_devices)/sizeof(vge_devices[0])));
@


1.47
log
@Don't print "EEPROM reload timed out" message.  Devices that don't have an
EEPROM exist (RouterBOARD RB600A) and reloading default values from the
EEPROM will fail on those decives.

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.46 2009/11/23 23:18:16 kettenis Exp $	*/
a789 1
	ifp->if_init = vge_init;
@


1.46
log
@Make vge(4) detachable.

ok jsg@@, deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.45 2009/09/04 21:43:00 kettenis Exp $	*/
a561 5
	}

	if (i == VGE_TIMEOUT) {
		printf("%s: EEPROM reload timed out\n", sc->vge_dev.dv_xname);
		return;
@


1.45
log
@Make sure the MAC address is correct on big-endian platforms if it isn't read
from the EEPROM.

ok miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.44 2009/08/13 14:24:47 jasper Exp $	*/
d131 1
d136 1
d169 1
a169 1
	sizeof(struct vge_softc), vge_probe, vge_attach
d698 26
a738 1
	bus_size_t		iosize;
d744 1
a744 1
	    &sc->vge_btag, &sc->vge_bhandle, NULL, &iosize, 0)) {
d746 1
a746 1
		    &sc->vge_btag, &sc->vge_bhandle, NULL, &iosize, 0)) {
d769 1
d837 25
@


1.44
log
@- consistify cfdriver for the ethernet drivers (0 -> NULL)

ok dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.43 2008/11/28 02:44:18 brad Exp $	*/
a703 1
	u_int16_t		as[3];
d710 1
a710 1
	int			error = 0, i;
d749 1
a749 5
	vge_read_eeprom(sc, (caddr_t)as, VGE_EE_EADDR, 3, 0);
	for (i = 0; i < 3; i++) {
		eaddr[(i * 2) + 0] = as[i] & 0xff;
		eaddr[(i * 2) + 1] = as[i] >> 8;
	}
@


1.43
log
@Eliminate the redundant bits of code for MTU and multicast handling
from the individual drivers now that ether_ioctl() handles this.

Shrinks the i386 kernels by..
RAMDISK - 2176 bytes
RAMDISKB - 1504 bytes
RAMDISKC - 736 bytes

Tested by naddy@@/okan@@/sthen@@/brad@@/todd@@/jmc@@ and lots of users.
Build tested on almost all archs by todd@@/brad@@

ok naddy@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.42 2008/11/09 15:08:26 naddy Exp $	*/
d171 1
a171 1
	0, "vge", DV_IFNET
@


1.42
log
@Introduce bpf_mtap_ether(), which for the benefit of bpf listeners
creates the VLAN encapsulation from the tag stored in the mbuf
header.  Idea from FreeBSD, input from claudio@@ and canacar@@.

Switch all hardware VLAN enabled drivers to the new function.

ok claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.41 2008/10/22 05:31:29 brad Exp $	*/
d1736 1
a1737 1
	struct ifaddr		*ifa = (struct ifaddr *) data;
d1757 1
a1757 6
	case SIOCSIFMTU:
		if (ifr->ifr_mtu < ETHERMIN || ifr->ifr_mtu > ifp->if_hardmtu)
			error = EINVAL;
		else if (ifp->if_mtu != ifr->ifr_mtu)
			ifp->if_mtu = ifr->ifr_mtu;
		break;
a1779 5
	case SIOCADDMULTI:
	case SIOCDELMULTI:
		error = (command == SIOCADDMULTI) ?
		    ether_addmulti(ifr, &sc->arpcom) :
		    ether_delmulti(ifr, &sc->arpcom);
a1780 6
		if (error == ENETRESET) {
			if (ifp->if_flags & IFF_RUNNING)
				vge_setmulti(sc);
			error = 0;
		}
		break;
d1785 1
d1788 6
@


1.41
log
@Re-add support TX VLAN tag insertion and RX VLAN tag stripping.

Tested by Dawe <dawedawe at gmx dot de>
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.40 2008/10/14 18:01:53 naddy Exp $	*/
d1112 1
a1112 1
			bpf_mtap(ifp->if_bpf, m, BPF_DIRECTION_IN);
d1441 1
a1441 1
			bpf_mtap(ifp->if_bpf, m_head, BPF_DIRECTION_OUT);
@


1.40
log
@Change m_devget()'s outdated and unused "offset" argument:  It is
now the offset into the first mbuf of the target chain before copying
the source data over.  From FreeBSD.

Convert drivers' use of m_devget().  Mostly from thib@@.

Update mbuf(9) man page.

ok claudio@@, thib@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.39 2008/10/02 20:21:14 brad Exp $	*/
d85 1
d110 5
d783 4
d1103 7
d1385 8
d1523 9
@


1.39
log
@First step towards cleaning up the Ethernet driver ioctl handling.
Move calling ether_ioctl() from the top of the ioctl function, which
at the moment does absolutely nothing, to the default switch case.
Thus allowing drivers to define their own ioctl handlers and then
falling back on ether_ioctl(). The only functional change this results
in at the moment is having all Ethernet drivers returning the proper
errno of ENOTTY instead of EINVAL/ENXIO when encountering unknown
ioctl's.

Shrinks the i386 kernels by..
RAMDISK - 1024 bytes
RAMDISKB -  1120 bytes
RAMDISKC - 832 bytes

Tested by martin@@/jsing@@/todd@@/brad@@
Build tested on almost all archs by todd@@/brad@@

ok jsing@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.38 2008/09/10 14:01:23 blambert Exp $	*/
d1034 2
a1035 3
			m0 = m_devget(mtod(m, char *) - ETHER_ALIGN,
			    total_len - ETHER_CRC_LEN + ETHER_ALIGN,
			    0, ifp, NULL);
a1040 1
			m_adj(m0, ETHER_ALIGN);
@


1.38
log
@Convert timeout_add() calls using multiples of hz to timeout_add_sec()

Really just the low-hanging fruit of (hopefully) forthcoming timeout
conversions.

ok art@@, krw@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.37 2008/05/22 19:23:04 mk Exp $	*/
a1709 5
	if ((error = ether_ioctl(ifp, &sc->arpcom, command, data)) > 0) {
		splx(s);
		return (error);
	}

d1770 1
a1770 2
		error = ENOTTY;
		break;
@


1.37
log
@More timeout(9) usage cleaned up.

ok claudio
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.36 2008/05/13 01:40:39 brad Exp $	*/
d1203 1
a1203 1
	timeout_add(&sc->timer_handle, hz);
d1625 1
a1625 1
		timeout_add(&sc->timer_handle, hz);
@


1.36
log
@Since Ethernet links can only be full duplex or half duplex the link
state reporting code in the MII layer / em(4) and vge(4) will never
fall back to the point of only reporting the link as being UP without
the duplex setting being reported, so simplify the code a bit here.

ok dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.35 2007/12/11 02:36:02 brad Exp $	*/
d1813 2
a1814 2
	if (timeout_pending(&sc->timer_handle))
		timeout_del(&sc->timer_handle);
@


1.35
log
@- Remove disabled and unusable HW VLAN tagging code.
- Remove setup of the HW VLAN stripping.

Issue reported by and fix tested by henric@@

ok dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.34 2007/10/10 12:46:44 kettenis Exp $	*/
d1196 1
a1196 1
			else if (mii->mii_media_status & IFM_HDX)
a1197 2
			else
				ifp->if_link_state = LINK_STATE_UP;
@


1.34
log
@Fix some obviously bogus code in vge_newbuf().  Should fix PR 5582.

ok claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.33 2007/05/01 11:28:06 canacar Exp $	*/
a84 1
#include "vlan.h"
a108 5
#if NVLAN > 0
#include <net/if_types.h>
#include <net/if_vlan_var.h>
#endif

a776 4
#ifdef VGE_VLAN
	ifp->if_capabilities |= IFCAP_VLAN_HWTAGGING;
#endif

a1288 7
#if NVLAN > 0
	struct ifvlan		*ifv = NULL;

	if ((m_head->m_flags & (M_PROTO1|M_PKTHDR)) == (M_PROTO1|M_PKTHDR) &&
	    m_head->m_pkthdr.rcvif != NULL)
		ifv = m_head->m_pkthdr.rcvif->if_softc;
#endif
a1376 10
	/*
	 * Set up hardware VLAN tagging.
	 */
#if NVLAN > 0
	if (ifv != NULL) {
		sc->vge_ldata.vge_tx_list[idx].vge_ctl |=
		    htole32(htons(ifv->ifv_tag) | VGE_TDCTL_VTAG);
	}
#endif

d1499 3
a1501 6
	/*
	 * Set receive FIFO threshold. Also allow transmission and
	 * reception of VLAN tagged frames.
	 */
	CSR_CLRBIT_1(sc, VGE_RXCFG, VGE_RXCFG_FIFO_THR|VGE_RXCFG_VTAGOPT);
	CSR_SETBIT_1(sc, VGE_RXCFG, VGE_RXFIFOTHR_128BYTES|VGE_VTAG_OPT2);
@


1.33
log
@Missing braces in vge_tick(). Fixes link state announcements.
ok reyk@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.32 2006/12/04 14:35:20 reyk Exp $	*/
d836 2
d839 1
a839 1
		m_new->m_data = m_new->m_ext.ext_buf;
d841 1
a841 1
	m_new->m_len = m_new->m_pkthdr.len = MCLBYTES;
d843 1
a843 1
	/* XXX m_adj(m_new, ETHER_ALIGN); */
d845 1
a845 1
	if (bus_dmamap_load_mbuf(sc->sc_dmat, rxmap, m_new, BUS_DMA_NOWAIT))
d882 1
a882 1
	sc->vge_ldata.vge_rx_mbuf[idx] = m_new;
@


1.32
log
@report full/half duplex state for non-MII interfaces

ok brad@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.31 2006/11/23 02:00:54 brad Exp $	*/
d1193 1
a1193 1
		if (!(mii->mii_media_status & IFM_ACTIVE))
d1197 1
@


1.31
log
@OpenBSD-ify the HW VLAN tag insertion code.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.30 2006/11/14 17:08:24 damien Exp $	*/
d1201 6
a1206 1
			ifp->if_link_state = LINK_STATE_UP;
@


1.30
log
@don't always leave the mbuf on the if_snd queue if vge_encap() fails.
if the mbuf is coalesced in vge_encap(), the mbuf reference is no
longer valid.  drop the mbuf in this case.

bug introduced in r1.28
tested by Frank Denis
fixes kernel/5291

"go for it" deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.29 2006/10/19 10:55:56 tom Exp $	*/
d1291 7
d1389 2
a1390 3
#ifdef VGE_VLAN
	mtag = VLAN_OUTPUT_TAG(&sc->arpcom.ac_if, m_head);
	if (mtag != NULL)
d1392 2
a1393 1
		    htole32(htons(VLAN_TAG_VALUE(mtag)) | VGE_TDCTL_VTAG);
@


1.29
log
@s/Mhz/MHz/ in comments and printf() strings

ok jsg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.28 2006/10/03 19:46:08 damien Exp $	*/
d1284 1
d1288 1
d1331 3
a1333 1
		struct mbuf *m = NULL;
a1334 5
		MGETHDR(m, M_DONTWAIT, MT_DATA);
		if (m == NULL) {
			m_freem(m_head);
			return (ENOBUFS);
		}
d1336 3
a1338 4
			MCLGET(m, M_DONTWAIT);
			if (!(m->m_flags & M_EXT)) {
				m_freem(m);
				m_freem(m_head);
d1343 3
a1345 2
		    mtod(m, caddr_t));
		m->m_pkthdr.len = m->m_len = m_head->m_pkthdr.len;
d1347 1
a1347 1
		m_head = m;
d1390 4
a1393 1

a1438 1
		IFQ_DEQUEUE(&ifp->if_snd, m_head);
@


1.28
log
@don't use IF_PREPEND() on altq's.
use IFQ_POLL()/IFQ_DEQUEUE() logic instead as described in altq(4).

tested by jolan@@ on macppc
"diffs look ok" brad@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.27 2006/07/28 15:58:38 kettenis Exp $	*/
d46 1
a46 1
 * The VIA Networking VT6122 is a 32bit, 33/66Mhz PCI device that
@


1.27
log
@do not bother playing tag with the PCI_COMMAND_STATUS_REG

tested by jolan@@, ok brad@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.26 2006/06/17 18:00:43 brad Exp $	*/
d1420 1
a1420 1
		IFQ_DEQUEUE(&ifp->if_snd, m_head);
a1433 1
			IF_PREPEND(&ifp->if_snd, m_head);
d1437 1
@


1.26
log
@add sys/timeout.h
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.25 2006/06/13 01:33:45 brad Exp $	*/
a712 1
	pcireg_t		command;
d717 2
a718 13
	command = pci_conf_read(pc, pa->pa_tag, PCI_COMMAND_STATUS_REG);
	if ((command & (PCI_COMMAND_IO_ENABLE | PCI_COMMAND_MEM_ENABLE)) == 0) {
		printf(": neither i/o nor mem enabled\n");
		return;
	}

	if (command & PCI_COMMAND_MEM_ENABLE) {
		if (pci_mapreg_map(pa, VGE_PCI_LOMEM, PCI_MAPREG_TYPE_MEM, 0,
		    &sc->vge_btag, &sc->vge_bhandle, NULL, &iosize, 0)) {
			printf(": can't map mem space\n");
			return;
		}
	} else {
d721 1
a721 1
			printf(": can't map i/o space\n");
@


1.25
log
@rev 1.13 fixed the MTU ioctl handler to allow adjusting the MTU
but it seems Jumbo support is broken, so disable Jumbos for now.

issue reported by jolan@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.24 2006/05/28 00:20:21 brad Exp $	*/
d95 1
@


1.24
log
@- remove ETHER_MAX_LEN_JUMBO and ETHERMTU_JUMBO.
- use if_hardmtu for MTU ioctl handlers.

ok reyk@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.23 2006/05/28 00:04:24 jason Exp $	*/
d785 1
d787 1
@


1.23
log
@unknown ioctl is ENOTTY not EINVAL
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.22 2006/05/27 10:03:15 brad Exp $	*/
d785 1
a785 1
	ifp->if_hardmtu = ETHERMTU_JUMBO;
d1756 1
a1756 1
		if (ifr->ifr_mtu < ETHERMIN || ifr->ifr_mtu > ETHERMTU_JUMBO)
@


1.22
log
@remove IFCAP_JUMBO_MTU interface capabilities flag and set if_hardmtu in a few
more drivers.

ok reyk@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.21 2006/05/20 03:47:56 brad Exp $	*/
d1800 1
a1800 1
		error = EINVAL;
@


1.21
log
@set if_jumbo_mtu and the IFCAP_JUMBO_MTU capabilities flag where
appropriate.

ok reyk@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.20 2006/03/25 22:41:46 djm Exp $	*/
d785 1
d789 2
a790 3
	ifp->if_capabilities = IFCAP_VLAN_MTU | IFCAP_JUMBO_MTU |
				IFCAP_CSUM_IPv4 | IFCAP_CSUM_TCPv4 |
				IFCAP_CSUM_UDPv4;
@


1.20
log
@allow bpf(4) to ignore packets based on their direction (inbound or
outbound), using a new BIOCSDIRFILT ioctl;
guidance, feedback and ok canacar@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.19 2006/03/20 16:15:03 brad Exp $	*/
d788 3
a790 2
	ifp->if_capabilities = IFCAP_VLAN_MTU|IFCAP_CSUM_IPv4|
				IFCAP_CSUM_TCPv4|IFCAP_CSUM_UDPv4;
@


1.19
log
@de-register.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.18 2005/11/07 02:57:45 brad Exp $	*/
d1113 1
a1113 1
			bpf_mtap(ifp->if_bpf, m);
d1438 1
a1438 1
			bpf_mtap(ifp->if_bpf, m_head);
@


1.18
log
@- splimp -> splnet
- remove spl's from attach
- removing redundant checks before pci_mapreg_map()
- fix dmesg printing
- de-allocate resources on failure to attach
- remove unused VLAN input code from vge(4)
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.17 2005/10/08 01:58:17 brad Exp $	*/
d191 1
a191 1
	register int		i;
d535 1
a535 1
	register int		i;
d1832 1
a1832 1
	register int		i;
@


1.17
log
@Some fixes for vge(4)'s multicast handling, including..

- Fix IFF_ALLMULTI handling
- Stop endless loop in multicast hash table filter mode

From christos NetBSD

ok pvalchev@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.16 2005/08/09 04:10:12 mickey Exp $	*/
d320 1
a320 1
	s = splimp();
d357 1
a357 1
	s = splimp();
a1110 6
#ifdef VGE_VLAN
		if (rxstat & VGE_RDSTS_VTAG)
			VLAN_INPUT_TAG(ifp, m,
			    ntohs((rxctl & VGE_RDCTL_VLANID)), continue);
#endif

d1196 1
a1196 1
	s = splimp();
d1732 1
a1732 1
	s = splimp();
@


1.16
log
@do not set PCI_COMMAND_MASTER_ENABLE explicitly as it's already set in pcisubmatch(); kettenis@@ testing; brad@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.15 2005/07/03 02:38:23 brad Exp $	*/
d487 1
d493 1
a494 1
	if (ifp->if_flags & IFF_ALLMULTI || ifp->if_flags & IFF_PROMISC) {
d497 1
d504 1
a504 2
		if (bcmp(enm->enm_addrlo, enm->enm_addrhi, ETHER_ADDR_LEN)) {
			ifp->if_flags |= IFF_ALLMULTI;
d506 1
a506 1
		}
d510 1
d520 4
a523 6
			h = (ether_crc32_be(enm->enm_addrlo,
			    ETHER_ADDR_LEN) >> 26) & 0x0000003F;
			if (h < 32)
				hashes[0] |= (1 << h);
			else
				hashes[1] |= (1 << (h - 32));
@


1.15
log
@enable use of the hardware 64 entry CAM table for perfect multicast
filtering otherwise fallback on the multicast hash table if trying to
filter on more than 64 addresses or if we're trying to flip on ALLMULTI.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.14 2005/05/03 03:13:05 brad Exp $	*/
a717 5
	command |= PCI_COMMAND_IO_ENABLE | PCI_COMMAND_MEM_ENABLE |
	    PCI_COMMAND_MASTER_ENABLE;
	pci_conf_write(pc, pa->pa_tag, PCI_COMMAND_STATUS_REG, command);
	command = pci_conf_read(pc, pa->pa_tag, PCI_COMMAND_STATUS_REG);

@


1.14
log
@enable HW transmit checksum offload

ok pvalchev@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.13 2005/04/30 19:41:24 brad Exp $	*/
d480 1
a482 35
	if (ifp->if_flags & IFF_ALLMULTI || ifp->if_flags & IFF_PROMISC) {
		CSR_WRITE_4(sc, VGE_MAR0, 0xFFFFFFFF);
		CSR_WRITE_4(sc, VGE_MAR1, 0xFFFFFFFF);
		return;
	}
	/* reset existing hash bits */
	CSR_WRITE_4(sc, VGE_MAR0, 0);
	CSR_WRITE_4(sc, VGE_MAR1, 0);

	/* program new ones */
	ETHER_FIRST_MULTI(step, ac, enm);
	while (enm != NULL) {
		if (bcmp(enm->enm_addrlo, enm->enm_addrhi, ETHER_ADDR_LEN))
			ifp->if_flags |= IFF_ALLMULTI;
		h = (ether_crc32_be(enm->enm_addrlo,
		    ETHER_ADDR_LEN) >> 26) & 0x0000003F;
		if (h < 32)
			hashes[0] |= (1 << h);
		else
			hashes[1] |= (1 << (h - 32));
		ETHER_NEXT_MULTI(step, enm);
	}
	CSR_WRITE_4(sc, VGE_MAR0, hashes[0]);
	CSR_WRITE_4(sc, VGE_MAR1, hashes[1]);

#ifdef CAM_FILTERING
	struct ifnet		*ifp;
	u_int32_t		h, hashes[2] = { 0, 0 };
	int			mcnt = 0;
	struct arpcom		*ac = &sc->arpcom;
	struct ether_multi	*enm;
	struct ether_multistep	step;

	ifp = &sc->arpcom.ac_if;

d492 1
d499 1
d504 1
a504 1
			mcnt = MAX_NUM_MULTICAST_ADDRESSES;
d506 2
a507 1
		if (mcnt == MAX_NUM_MULTICAST_ADDRESSES)
d509 2
d512 17
a528 8
		h = (ether_crc32_be(enm->enm_addrlo,
		    ETHER_ADDR_LEN) >> 26) & 0x0000003F;
		if (h < 32)
			hashes[0] |= (1 << h);
		else
			hashes[1] |= (1 << (h - 32));
		mcnt++;
		ETHER_NEXT_MULTI(step, enm);
a529 4
	
	CSR_WRITE_4(sc, VGE_MAR0, hashes[0]);
	CSR_WRITE_4(sc, VGE_MAR1, hashes[1]);
#endif
a1589 1
#ifdef CAM_FILTERING
a1590 1
#endif
@


1.13
log
@- Add missing break for SIOCSIFADDR
- Allow setting the MTU

ok pvalchev@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.12 2005/04/30 19:24:00 brad Exp $	*/
d817 2
a818 1
	ifp->if_capabilities = IFCAP_VLAN_MTU;
a822 4
#ifdef VGE_CSUM_OFFLOAD
	ifp->if_capabilities |= IFCAP_CSUM_IPv4|IFCAP_CSUM_TCPv4|
				IFCAP_CSUM_UDPv4;
#endif
d1331 10
d1413 1
a1413 1
	d->vge_ctl = htole32((frag << 28) | VGE_TD_LS_NORM);
@


1.12
log
@- Correct the if_link_state_change() logic.
- Reading the EEPROM to learn the station address doesn't seem to work
  on boards with VIA gigE controllers that are embedded in VIA chipsets.
  Presumably, they don't have an external EEPROM and store the MAC
  address somewhere else. To get around this, read the station
  address from the RX filter registers instead.  This has been tested
  to work on both embedded and standalone controllers.

From FreeBSD

ok pvalchev@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.11 2005/04/25 17:55:51 brad Exp $	*/
d1783 1
a1783 1
#if 0 /* XXX mtu gets reset to 0 at ifconfig up for some reason with this */
d1785 1
a1785 1
		if (ifr->ifr_mtu > ETHERMTU_JUMBO)
d1787 1
a1787 1
		else
a1789 1
#endif
@


1.11
log
@csum -> csum_flags

ok krw@@ canacar@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.10 2005/04/08 15:15:52 brad Exp $	*/
d149 1
d151 1
d184 1
d229 1
d239 1
d250 4
d1241 1
a1241 1
			ifp->if_link_state = LINK_STATE_UP;
d1247 1
a1247 1
			ifp->if_link_state = LINK_STATE_DOWN;
@


1.10
log
@fix parenthesis
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.9 2005/04/08 13:36:48 brad Exp $	*/
d1127 1
a1127 1
			m->m_pkthdr.csum |= M_IPV4_CSUM_IN_OK;
d1130 1
a1130 1
		if (rxctl & (VGE_RDCTL_TCPPKT|VGE_RDCTL_UDPPKT) &&
d1132 1
a1132 1
			m->m_pkthdr.csum |= M_TCP_CSUM_IN_OK | M_UDP_CSUM_IN_OK;
@


1.9
log
@- enable reception of VLAN sized frames
- enable HW receive checksum offload

ok pvlachev@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.8 2005/04/02 01:25:48 brad Exp $	*/
d1125 1
a1125 1
		if (rxctl & VGE_RDCTL_IPPKT) &&
d1131 1
a1131 1
		    rxctl & VGE_RDCTL_PROTOCSUMOK) {
@


1.8
log
@make use of if_link_state_change().

From FreeBSD

ok pvalchev@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.7 2005/03/15 17:06:10 pvalchev Exp $	*/
a801 5
#ifdef VGE_CSUM_OFFLOAD
	ifp->if_capabilities = IFCAP_VLAN_MTU;
	ifp->if_hwassist = VGE_CSUM_FEATURES;
	ifp->if_capabilities |= IFCAP_HWCSUM|IFCAP_VLAN_HWTAGGING;
#endif
d808 10
d1122 1
a1122 3
		/* Do RX checksumming if enabled */
#ifdef VGE_CSUM_OFFLOAD
		if (ifp->if_capenable & IFCAP_RXCSUM) {
d1124 9
a1132 14
			/* Check IP header checksum */
			if (rxctl & VGE_RDCTL_IPPKT)
				m->m_pkthdr.csum_flags |= CSUM_IP_CHECKED;
			if (rxctl & VGE_RDCTL_IPCSUMOK)
				m->m_pkthdr.csum_flags |= CSUM_IP_VALID;

			/* Check TCP/UDP checksum */
			if (rxctl & (VGE_RDCTL_TCPPKT|VGE_RDCTL_UDPPKT) &&
			    rxctl & VGE_RDCTL_PROTOCSUMOK) {
				m->m_pkthdr.csum_flags |=
				    CSUM_DATA_VALID|CSUM_PSEUDO_HDR;
				m->m_pkthdr.csum_data = 0xffff;
			}
		}
d1134 1
@


1.7
log
@use IFQ_ rather than IF_ macro here too, maybe helps altq; ok henning
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.6 2005/01/15 05:24:11 brad Exp $	*/
d1233 2
d1239 2
@


1.6
log
@make sure interface is in RUNNING state before touching the multicast filters

From NetBSD

NetBSD PR 27678 for details

ok mcbride@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.5 2004/12/27 00:46:40 pvalchev Exp $	*/
d1444 1
a1444 1
		IF_DEQUEUE(&ifp->if_snd, m_head);
@


1.5
log
@remove useless debugging leftover
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.4 2004/12/26 05:58:25 pvalchev Exp $	*/
d1806 1
d1808 2
a1809 1
			vge_setmulti(sc);
@


1.4
log
@Bounce the mbuf to the BPF listener before committing it to the wire
in the TX case, fixes rare problems associated with accessing already
free'd memory if the encap routine bails out (panic in PROMISC mode).
ok deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.3 2004/12/26 05:54:30 pvalchev Exp $	*/
a1016 3
		if (rxstat & VGE_RXPKT_MOF || rxstat & VGE_RXPKT_EOF ||
		    rxstat & VGE_RXPKT_ONEFRAG)
			printf("vge_rxeof: bizzarre!\n");
@


1.3
log
@htole32 and friends to get this working on big endian (macppc)
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.2 2004/12/12 06:13:32 pvalchev Exp $	*/
a1447 1

d1451 9
a1470 9

		/*
		 * If there's a BPF listener, bounce a copy of this frame
		 * to him.
		 */
#if NBPFILTER > 0
		if (ifp->if_bpf)
			bpf_mtap(ifp->if_bpf, m_head);
#endif
@


1.2
log
@a hack to read MAC address correctly on big endian; ok drahn
however a correct clean way to do this should be found
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vge.c,v 1.1 2004/12/01 01:29:00 pvalchev Exp $	*/
a140 1
void vge_tx_task		(void *, int);
d886 2
a887 2
	r->vge_sts = 0;
	r->vge_ctl = 0;
a1152 1

d1396 2
a1397 2
	d->vge_sts = m_head->m_pkthdr.len << 16;
	d->vge_ctl = (frag << 28) | VGE_TD_LS_NORM;
d1400 1
a1400 1
		d->vge_ctl |= VGE_TDCTL_JUMBO;
@


1.1
log
@VIA VT612x PCI Gigabit Ethernet adapter support, ok deraadt
from FreeBSD
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d719 1
d726 1
a726 1
	int			error = 0;
d782 5
a786 1
	vge_read_eeprom(sc, (caddr_t)eaddr, VGE_EE_EADDR, 3, 0);
@

