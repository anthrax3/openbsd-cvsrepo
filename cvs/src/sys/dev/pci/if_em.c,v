head	1.336;
access;
symbols
	OPENBSD_6_1:1.335.0.4
	OPENBSD_6_1_BASE:1.335
	OPENBSD_6_0:1.331.0.4
	OPENBSD_6_0_BASE:1.331
	OPENBSD_5_9:1.330.0.2
	OPENBSD_5_9_BASE:1.330
	OPENBSD_5_8:1.299.0.4
	OPENBSD_5_8_BASE:1.299
	OPENBSD_5_7:1.295.0.4
	OPENBSD_5_7_BASE:1.295
	OPENBSD_5_6:1.287.0.4
	OPENBSD_5_6_BASE:1.287
	OPENBSD_5_5:1.277.0.4
	OPENBSD_5_5_BASE:1.277
	OPENBSD_5_4:1.269.0.4
	OPENBSD_5_4_BASE:1.269
	OPENBSD_5_3:1.269.0.2
	OPENBSD_5_3_BASE:1.269
	OPENBSD_5_2:1.264.0.2
	OPENBSD_5_2_BASE:1.264
	OPENBSD_5_1_BASE:1.261
	OPENBSD_5_1:1.261.0.2
	OPENBSD_5_0:1.259.0.2
	OPENBSD_5_0_BASE:1.259
	OPENBSD_4_9:1.249.0.2
	OPENBSD_4_9_BASE:1.249
	OPENBSD_4_8:1.244.0.2
	OPENBSD_4_8_BASE:1.244
	OPENBSD_4_7:1.235.0.2
	OPENBSD_4_7_BASE:1.235
	OPENBSD_4_6:1.214.0.4
	OPENBSD_4_6_BASE:1.214
	OPENBSD_4_5:1.207.0.2
	OPENBSD_4_5_BASE:1.207
	OPENBSD_4_4:1.186.0.2
	OPENBSD_4_4_BASE:1.186
	OPENBSD_4_3:1.180.0.2
	OPENBSD_4_3_BASE:1.180
	OPENBSD_4_2:1.172.0.2
	OPENBSD_4_2_BASE:1.172
	OPENBSD_4_1:1.166.0.2
	OPENBSD_4_1_BASE:1.166
	OPENBSD_4_0:1.146.0.2
	OPENBSD_4_0_BASE:1.146
	OPENBSD_3_9:1.109.0.2
	OPENBSD_3_9_BASE:1.109
	OPENBSD_3_8:1.67.0.2
	OPENBSD_3_8_BASE:1.67
	OPENBSD_3_7:1.39.0.2
	OPENBSD_3_7_BASE:1.39
	OPENBSD_3_6:1.27.0.2
	OPENBSD_3_6_BASE:1.27
	SMP_SYNC_A:1.21
	SMP_SYNC_B:1.21
	OPENBSD_3_5:1.17.0.2
	OPENBSD_3_5_BASE:1.17
	OPENBSD_3_4:1.11.0.2
	OPENBSD_3_4_BASE:1.11
	UBC_SYNC_A:1.7
	SMP:1.7.0.4
	OPENBSD_3_3:1.7.0.2
	OPENBSD_3_3_BASE:1.7
	UBC:1.2.0.4
	UBC_SYNC_B:1.2
	OPENBSD_3_2:1.2.0.2
	OPENBSD_3_2_BASE:1.2;
locks; strict;
comment	@ * @;


1.336
date	2017.07.25.20.45.18;	author bluhm;	state Exp;
branches;
next	1.335;
commitid	MSlxCZcrnRGxPu5Z;

1.335
date	2017.03.19.11.09.26;	author jsg;	state Exp;
branches;
next	1.334;
commitid	C8KxFzCXnnd7g2hA;

1.334
date	2017.01.24.03.57.35;	author dlg;	state Exp;
branches;
next	1.333;
commitid	PERtGPXCvlLRRBr8;

1.333
date	2017.01.22.10.17.38;	author dlg;	state Exp;
branches;
next	1.332;
commitid	VyLWTsbepAOk7VQM;

1.332
date	2016.10.27.03.06.53;	author dlg;	state Exp;
branches;
next	1.331;
commitid	tMxqIWVTjiRzeFoN;

1.331
date	2016.04.13.10.34.32;	author mpi;	state Exp;
branches;
next	1.330;
commitid	8YSL8ByWzGeIGBiJ;

1.330
date	2016.02.18.14.24.39;	author bluhm;	state Exp;
branches;
next	1.329;
commitid	byf6gliq76JeDmXn;

1.329
date	2016.01.12.00.05.21;	author dlg;	state Exp;
branches;
next	1.328;
commitid	9fyc2c6bK53rQNBQ;

1.328
date	2016.01.11.01.31.53;	author dlg;	state Exp;
branches;
next	1.327;
commitid	thOCri5A37wAVmo3;

1.327
date	2016.01.09.11.54.19;	author dlg;	state Exp;
branches;
next	1.326;
commitid	TY4nWKzq1KnFVQtl;

1.326
date	2016.01.07.12.18.38;	author dlg;	state Exp;
branches;
next	1.325;
commitid	nPm75R4Cc8xv8Z6x;

1.325
date	2016.01.07.11.19.54;	author dlg;	state Exp;
branches;
next	1.324;
commitid	wWgJmkazk961VJfi;

1.324
date	2016.01.07.07.18.07;	author dlg;	state Exp;
branches;
next	1.323;
commitid	ihMyfWHDTPiEzfbD;

1.323
date	2016.01.07.07.03.55;	author dlg;	state Exp;
branches;
next	1.322;
commitid	l4hf68jdiFFUPlBg;

1.322
date	2016.01.07.06.49.04;	author dlg;	state Exp;
branches;
next	1.321;
commitid	b48zEso4qXvpUnZm;

1.321
date	2016.01.07.06.37.45;	author dlg;	state Exp;
branches;
next	1.320;
commitid	h0QKEHNi2uSw3Yfo;

1.320
date	2016.01.07.06.20.38;	author dlg;	state Exp;
branches;
next	1.319;
commitid	fH1dhpSM7aD5LAbp;

1.319
date	2016.01.07.05.34.11;	author dlg;	state Exp;
branches;
next	1.318;
commitid	lQMzNuMfiPEoy70A;

1.318
date	2016.01.07.04.37.53;	author dlg;	state Exp;
branches;
next	1.317;
commitid	tzVWqIOXQjQlBfSc;

1.317
date	2016.01.07.04.30.45;	author dlg;	state Exp;
branches;
next	1.316;
commitid	OXnjNH3hhKuBOevC;

1.316
date	2016.01.07.04.21.36;	author dlg;	state Exp;
branches;
next	1.315;
commitid	37DaaqmjJ4UFqRg1;

1.315
date	2016.01.07.03.56.03;	author dlg;	state Exp;
branches;
next	1.314;
commitid	ioMNsUl2QDhTGC3w;

1.314
date	2015.12.31.14.20.25;	author dlg;	state Exp;
branches;
next	1.313;
commitid	Tss0nyG8F6aPbGfA;

1.313
date	2015.11.25.03.09.59;	author dlg;	state Exp;
branches;
next	1.312;
commitid	B0kwmVGiD5DVx4kv;

1.312
date	2015.11.20.13.11.16;	author mpi;	state Exp;
branches;
next	1.311;
commitid	yh7en7VrwgRcVL7Y;

1.311
date	2015.11.20.03.35.23;	author dlg;	state Exp;
branches;
next	1.310;
commitid	eYnPulzvLjDImPCa;

1.310
date	2015.10.29.03.19.42;	author jsg;	state Exp;
branches;
next	1.309;
commitid	lqC79Zf3FGub1Dql;

1.309
date	2015.10.25.13.04.28;	author mpi;	state Exp;
branches;
next	1.308;
commitid	hPF95ClMUQfeqQDX;

1.308
date	2015.10.08.09.21.26;	author kettenis;	state Exp;
branches;
next	1.307;
commitid	g67gW0iMKfhISvm3;

1.307
date	2015.10.06.15.21.16;	author kettenis;	state Exp;
branches;
next	1.306;
commitid	73D5xGBG5qIQxdyt;

1.306
date	2015.09.30.11.25.08;	author kettenis;	state Exp;
branches;
next	1.305;
commitid	bsKIVU2MHH8EeBw9;

1.305
date	2015.09.19.12.48.26;	author kettenis;	state Exp;
branches;
next	1.304;
commitid	xW9tscJ44ApnBTFq;

1.304
date	2015.09.11.13.02.28;	author stsp;	state Exp;
branches;
next	1.303;
commitid	6vhYvh5CxZAHMnsN;

1.303
date	2015.09.01.09.48.50;	author mpi;	state Exp;
branches;
next	1.302;
commitid	tscPKvhc2r0ktZqa;

1.302
date	2015.09.01.07.09.55;	author deraadt;	state Exp;
branches;
next	1.301;
commitid	VvLv8PeakqoJLqr3;

1.301
date	2015.08.26.09.17.20;	author kettenis;	state Exp;
branches;
next	1.300;
commitid	ze8pXARkfnKEgh8n;

1.300
date	2015.08.21.09.16.06;	author kettenis;	state Exp;
branches;
next	1.299;
commitid	MPNQ3ZVIFZ5E3Uat;

1.299
date	2015.06.24.09.40.54;	author mpi;	state Exp;
branches;
next	1.298;
commitid	MVWrtktB46JRxFWT;

1.298
date	2015.06.04.18.33.41;	author dms;	state Exp;
branches;
next	1.297;
commitid	KGqt9GuXdcKKj76A;

1.297
date	2015.05.12.20.20.18;	author kettenis;	state Exp;
branches;
next	1.296;
commitid	4ry9A2pLmm5paImX;

1.296
date	2015.05.12.02.33.39;	author jsg;	state Exp;
branches;
next	1.295;
commitid	tSo3dk97sZVrtqBm;

1.295
date	2015.02.11.23.21.47;	author brad;	state Exp;
branches;
next	1.294;
commitid	cgBeGMCX8oqslYjJ;

1.294
date	2015.02.11.21.27.08;	author brad;	state Exp;
branches;
next	1.293;
commitid	8OG3wlG6Krr2eL2X;

1.293
date	2015.02.09.03.09.57;	author dlg;	state Exp;
branches;
next	1.292;
commitid	fE9MPAUoNdw8sZYO;

1.292
date	2015.02.08.06.02.24;	author mpi;	state Exp;
branches;
next	1.291;
commitid	0JvlQ1Upf6mzhLzw;

1.291
date	2015.01.28.22.33.02;	author brad;	state Exp;
branches;
next	1.290;
commitid	l8MpG4B8r5OyDqro;

1.290
date	2014.12.22.02.28.52;	author tedu;	state Exp;
branches;
next	1.289;
commitid	yM2VFFhpDTeFQlve;

1.289
date	2014.11.19.23.47.22;	author brad;	state Exp;
branches;
next	1.288;
commitid	FBN1fmnpIc8fn6ZD;

1.288
date	2014.08.26.11.01.21;	author mikeb;	state Exp;
branches;
next	1.287;
commitid	NTysWaOWh0v3MRJC;

1.287
date	2014.07.13.23.10.23;	author deraadt;	state Exp;
branches
	1.287.4.1;
next	1.286;
commitid	JtO5uXxVcnZfhUkR;

1.286
date	2014.07.12.18.48.51;	author tedu;	state Exp;
branches;
next	1.285;
commitid	OBNa5kfxQ2UXoiIw;

1.285
date	2014.07.08.05.35.18;	author dlg;	state Exp;
branches;
next	1.284;
commitid	0QJleeeWqZmC5anF;

1.284
date	2014.07.08.02.57.27;	author dlg;	state Exp;
branches;
next	1.283;
commitid	9BDMJN0oe19z7syB;

1.283
date	2014.07.08.00.17.44;	author dlg;	state Exp;
branches;
next	1.282;
commitid	ok9Nfo7JreI2KvKg;

1.282
date	2014.07.08.00.11.50;	author dlg;	state Exp;
branches;
next	1.281;
commitid	ttsefQpVHAkgQR25;

1.281
date	2014.07.07.23.12.00;	author dlg;	state Exp;
branches;
next	1.280;
commitid	931CFJkwr1eUZQ6l;

1.280
date	2014.06.11.04.28.43;	author dlg;	state Exp;
branches;
next	1.279;
commitid	x3DdXl9hyYhpEKA4;

1.279
date	2014.03.10.04.09.53;	author jsg;	state Exp;
branches;
next	1.278;

1.278
date	2014.03.10.03.08.34;	author jsg;	state Exp;
branches;
next	1.277;

1.277
date	2014.02.22.04.41.31;	author chris;	state Exp;
branches;
next	1.276;

1.276
date	2014.02.17.07.02.45;	author jsg;	state Exp;
branches;
next	1.275;

1.275
date	2013.12.28.03.34.54;	author deraadt;	state Exp;
branches;
next	1.274;

1.274
date	2013.12.06.21.03.04;	author deraadt;	state Exp;
branches;
next	1.273;

1.273
date	2013.11.27.01.13.10;	author jsg;	state Exp;
branches;
next	1.272;

1.272
date	2013.11.21.14.44.37;	author jsg;	state Exp;
branches;
next	1.271;

1.271
date	2013.11.15.14.53.03;	author deraadt;	state Exp;
branches;
next	1.270;

1.270
date	2013.10.19.15.45.33;	author naddy;	state Exp;
branches;
next	1.269;

1.269
date	2013.01.27.04.18.02;	author brad;	state Exp;
branches;
next	1.268;

1.268
date	2012.11.28.01.15.33;	author brad;	state Exp;
branches;
next	1.267;

1.267
date	2012.08.16.09.31.53;	author mikeb;	state Exp;
branches;
next	1.266;

1.266
date	2012.08.16.09.30.55;	author mikeb;	state Exp;
branches;
next	1.265;

1.265
date	2012.08.15.16.30.25;	author mikeb;	state Exp;
branches;
next	1.264;

1.264
date	2012.05.17.10.45.17;	author jsg;	state Exp;
branches;
next	1.263;

1.263
date	2012.05.14.10.14.44;	author mikeb;	state Exp;
branches;
next	1.262;

1.262
date	2012.02.15.04.06.27;	author jsg;	state Exp;
branches;
next	1.261;

1.261
date	2011.10.05.02.52.09;	author jsg;	state Exp;
branches;
next	1.260;

1.260
date	2011.08.30.02.51.19;	author haesbaert;	state Exp;
branches;
next	1.259;

1.259
date	2011.07.05.16.51.34;	author kettenis;	state Exp;
branches;
next	1.258;

1.258
date	2011.06.16.13.21.00;	author kettenis;	state Exp;
branches;
next	1.257;

1.257
date	2011.06.03.13.06.06;	author kettenis;	state Exp;
branches;
next	1.256;

1.256
date	2011.04.22.10.09.57;	author jsg;	state Exp;
branches;
next	1.255;

1.255
date	2011.04.14.21.14.28;	author jsg;	state Exp;
branches;
next	1.254;

1.254
date	2011.04.13.00.19.00;	author dlg;	state Exp;
branches;
next	1.253;

1.253
date	2011.04.05.20.24.32;	author jsg;	state Exp;
branches;
next	1.252;

1.252
date	2011.04.05.18.01.21;	author henning;	state Exp;
branches;
next	1.251;

1.251
date	2011.04.03.15.36.02;	author jasper;	state Exp;
branches;
next	1.250;

1.250
date	2011.03.09.12.24.15;	author mpf;	state Exp;
branches;
next	1.249;

1.249
date	2011.02.13.19.45.54;	author miod;	state Exp;
branches;
next	1.248;

1.248
date	2010.09.19.13.10.21;	author yasuoka;	state Exp;
branches;
next	1.247;

1.247
date	2010.09.07.16.21.44;	author deraadt;	state Exp;
branches;
next	1.246;

1.246
date	2010.08.31.17.13.44;	author deraadt;	state Exp;
branches;
next	1.245;

1.245
date	2010.08.27.15.56.09;	author deraadt;	state Exp;
branches;
next	1.244;

1.244
date	2010.08.08.12.53.16;	author kettenis;	state Exp;
branches;
next	1.243;

1.243
date	2010.08.04.17.10.34;	author jsg;	state Exp;
branches;
next	1.242;

1.242
date	2010.08.03.16.21.52;	author jsg;	state Exp;
branches;
next	1.241;

1.241
date	2010.07.26.19.21.24;	author kettenis;	state Exp;
branches;
next	1.240;

1.240
date	2010.06.28.20.24.39;	author jsg;	state Exp;
branches;
next	1.239;

1.239
date	2010.06.27.20.13.04;	author jsg;	state Exp;
branches;
next	1.238;

1.238
date	2010.06.21.21.11.52;	author jsg;	state Exp;
branches;
next	1.237;

1.237
date	2010.06.21.20.43.44;	author jsg;	state Exp;
branches;
next	1.236;

1.236
date	2010.05.18.21.51.10;	author jsg;	state Exp;
branches;
next	1.235;

1.235
date	2010.03.16.22.48.43;	author kettenis;	state Exp;
branches;
next	1.234;

1.234
date	2009.12.02.23.30.00;	author sthen;	state Exp;
branches;
next	1.233;

1.233
date	2009.11.26.16.01.00;	author dms;	state Exp;
branches;
next	1.232;

1.232
date	2009.11.26.15.53.15;	author dms;	state Exp;
branches;
next	1.231;

1.231
date	2009.11.26.13.47.02;	author dms;	state Exp;
branches;
next	1.230;

1.230
date	2009.11.26.13.42.33;	author dms;	state Exp;
branches;
next	1.229;

1.229
date	2009.11.25.13.28.13;	author dms;	state Exp;
branches;
next	1.228;

1.228
date	2009.10.13.23.55.20;	author deraadt;	state Exp;
branches;
next	1.227;

1.227
date	2009.10.11.19.24.48;	author dms;	state Exp;
branches;
next	1.226;

1.226
date	2009.10.11.00.18.37;	author dms;	state Exp;
branches;
next	1.225;

1.225
date	2009.10.10.04.49.26;	author deraadt;	state Exp;
branches;
next	1.224;

1.224
date	2009.10.09.21.04.03;	author deraadt;	state Exp;
branches;
next	1.223;

1.223
date	2009.10.09.20.50.32;	author deraadt;	state Exp;
branches;
next	1.222;

1.222
date	2009.09.04.22.13.51;	author dms;	state Exp;
branches;
next	1.221;

1.221
date	2009.08.21.22.54.10;	author dms;	state Exp;
branches;
next	1.220;

1.220
date	2009.08.13.14.24.47;	author jasper;	state Exp;
branches;
next	1.219;

1.219
date	2009.08.12.20.02.42;	author dlg;	state Exp;
branches;
next	1.218;

1.218
date	2009.08.12.14.39.05;	author dlg;	state Exp;
branches;
next	1.217;

1.217
date	2009.08.10.19.41.05;	author deraadt;	state Exp;
branches;
next	1.216;

1.216
date	2009.08.09.11.40.56;	author deraadt;	state Exp;
branches;
next	1.215;

1.215
date	2009.07.27.16.37.52;	author claudio;	state Exp;
branches;
next	1.214;

1.214
date	2009.06.26.14.30.35;	author claudio;	state Exp;
branches;
next	1.213;

1.213
date	2009.06.23.14.09.51;	author claudio;	state Exp;
branches;
next	1.212;

1.212
date	2009.06.05.16.27.40;	author naddy;	state Exp;
branches;
next	1.211;

1.211
date	2009.06.04.05.08.43;	author claudio;	state Exp;
branches;
next	1.210;

1.210
date	2009.06.03.17.39.44;	author claudio;	state Exp;
branches;
next	1.209;

1.209
date	2009.05.31.04.47.50;	author deraadt;	state Exp;
branches;
next	1.208;

1.208
date	2009.05.25.10.17.55;	author sthen;	state Exp;
branches;
next	1.207;

1.207
date	2009.01.27.09.17.51;	author dlg;	state Exp;
branches
	1.207.2.1;
next	1.206;

1.206
date	2008.12.23.07.40.31;	author dlg;	state Exp;
branches;
next	1.205;

1.205
date	2008.12.21.23.32.51;	author dlg;	state Exp;
branches;
next	1.204;

1.204
date	2008.12.21.23.30.26;	author dlg;	state Exp;
branches;
next	1.203;

1.203
date	2008.12.15.02.33.04;	author brad;	state Exp;
branches;
next	1.202;

1.202
date	2008.12.06.11.39.38;	author dlg;	state Exp;
branches;
next	1.201;

1.201
date	2008.12.04.02.36.51;	author brad;	state Exp;
branches;
next	1.200;

1.200
date	2008.12.03.00.59.48;	author dlg;	state Exp;
branches;
next	1.199;

1.199
date	2008.11.29.10.23.29;	author sthen;	state Exp;
branches;
next	1.198;

1.198
date	2008.11.28.02.44.17;	author brad;	state Exp;
branches;
next	1.197;

1.197
date	2008.11.26.00.14.48;	author dlg;	state Exp;
branches;
next	1.196;

1.196
date	2008.11.24.17.08.36;	author dlg;	state Exp;
branches;
next	1.195;

1.195
date	2008.11.09.15.08.26;	author naddy;	state Exp;
branches;
next	1.194;

1.194
date	2008.10.28.05.43.11;	author brad;	state Exp;
branches;
next	1.193;

1.193
date	2008.10.19.19.53.09;	author brad;	state Exp;
branches;
next	1.192;

1.192
date	2008.10.15.19.12.18;	author blambert;	state Exp;
branches;
next	1.191;

1.191
date	2008.10.05.11.57.48;	author kettenis;	state Exp;
branches;
next	1.190;

1.190
date	2008.10.02.20.21.14;	author brad;	state Exp;
branches;
next	1.189;

1.189
date	2008.09.30.17.59.22;	author brad;	state Exp;
branches;
next	1.188;

1.188
date	2008.09.24.19.12.59;	author chl;	state Exp;
branches;
next	1.187;

1.187
date	2008.08.29.23.28.34;	author brad;	state Exp;
branches;
next	1.186;

1.186
date	2008.07.15.17.50.20;	author kettenis;	state Exp;
branches;
next	1.185;

1.185
date	2008.06.15.16.37.00;	author millert;	state Exp;
branches;
next	1.184;

1.184
date	2008.06.08.16.20.27;	author reyk;	state Exp;
branches;
next	1.183;

1.183
date	2008.06.03.12.45.27;	author brad;	state Exp;
branches;
next	1.182;

1.182
date	2008.05.13.01.40.39;	author brad;	state Exp;
branches;
next	1.181;

1.181
date	2008.04.09.12.50.11;	author dlg;	state Exp;
branches;
next	1.180;

1.180
date	2008.03.02.01.28.16;	author brad;	state Exp;
branches;
next	1.179;

1.179
date	2008.03.02.00.02.11;	author brad;	state Exp;
branches;
next	1.178;

1.178
date	2008.02.27.20.05.51;	author brad;	state Exp;
branches;
next	1.177;

1.177
date	2008.02.20.00.00.06;	author brad;	state Exp;
branches;
next	1.176;

1.176
date	2008.02.04.00.30.01;	author brad;	state Exp;
branches;
next	1.175;

1.175
date	2008.02.02.05.11.51;	author brad;	state Exp;
branches;
next	1.174;

1.174
date	2007.10.21.03.49.54;	author brad;	state Exp;
branches;
next	1.173;

1.173
date	2007.10.01.15.34.48;	author krw;	state Exp;
branches;
next	1.172;

1.172
date	2007.05.31.01.04.57;	author henning;	state Exp;
branches;
next	1.171;

1.171
date	2007.05.31.00.47.53;	author ckuethe;	state Exp;
branches;
next	1.170;

1.170
date	2007.05.30.06.29.17;	author ckuethe;	state Exp;
branches;
next	1.169;

1.169
date	2007.05.09.18.02.46;	author deraadt;	state Exp;
branches;
next	1.168;

1.168
date	2007.05.09.17.32.59;	author kettenis;	state Exp;
branches;
next	1.167;

1.167
date	2007.03.16.00.07.36;	author reyk;	state Exp;
branches;
next	1.166;

1.166
date	2007.01.26.15.55.30;	author weingart;	state Exp;
branches;
next	1.165;

1.165
date	2007.01.21.18.38.02;	author kettenis;	state Exp;
branches;
next	1.164;

1.164
date	2007.01.15.22.51.05;	author kettenis;	state Exp;
branches;
next	1.163;

1.163
date	2006.12.27.14.33.04;	author kettenis;	state Exp;
branches;
next	1.162;

1.162
date	2006.12.06.23.25.58;	author reyk;	state Exp;
branches;
next	1.161;

1.161
date	2006.12.04.14.35.20;	author reyk;	state Exp;
branches;
next	1.160;

1.160
date	2006.11.21.02.42.27;	author brad;	state Exp;
branches;
next	1.159;

1.159
date	2006.11.21.02.30.37;	author brad;	state Exp;
branches;
next	1.158;

1.158
date	2006.11.18.18.39.14;	author brad;	state Exp;
branches;
next	1.157;

1.157
date	2006.11.17.02.03.32;	author brad;	state Exp;
branches;
next	1.156;

1.156
date	2006.11.14.03.59.00;	author brad;	state Exp;
branches;
next	1.155;

1.155
date	2006.11.10.21.15.56;	author brad;	state Exp;
branches;
next	1.154;

1.154
date	2006.11.07.21.05.56;	author brad;	state Exp;
branches;
next	1.153;

1.153
date	2006.11.06.03.52.37;	author brad;	state Exp;
branches;
next	1.152;

1.152
date	2006.11.03.06.39.10;	author brad;	state Exp;
branches;
next	1.151;

1.151
date	2006.10.30.08.34.14;	author dlg;	state Exp;
branches;
next	1.150;

1.150
date	2006.09.29.16.59.59;	author brad;	state Exp;
branches;
next	1.149;

1.149
date	2006.09.17.21.35.58;	author brad;	state Exp;
branches;
next	1.148;

1.148
date	2006.09.17.20.26.14;	author brad;	state Exp;
branches;
next	1.147;

1.147
date	2006.09.17.17.51.01;	author brad;	state Exp;
branches;
next	1.146;

1.146
date	2006.08.22.15.51.18;	author brad;	state Exp;
branches
	1.146.2.1;
next	1.145;

1.145
date	2006.08.14.17.23.32;	author brad;	state Exp;
branches;
next	1.144;

1.144
date	2006.08.09.17.12.58;	author brad;	state Exp;
branches;
next	1.143;

1.143
date	2006.08.09.04.44.06;	author brad;	state Exp;
branches;
next	1.142;

1.142
date	2006.08.09.03.48.25;	author brad;	state Exp;
branches;
next	1.141;

1.141
date	2006.08.04.14.25.24;	author brad;	state Exp;
branches;
next	1.140;

1.140
date	2006.08.04.02.44.50;	author brad;	state Exp;
branches;
next	1.139;

1.139
date	2006.08.01.23.50.14;	author brad;	state Exp;
branches;
next	1.138;

1.138
date	2006.07.10.00.16.18;	author drahn;	state Exp;
branches;
next	1.137;

1.137
date	2006.07.08.04.34.34;	author brad;	state Exp;
branches;
next	1.136;

1.136
date	2006.07.07.02.56.18;	author brad;	state Exp;
branches;
next	1.135;

1.135
date	2006.07.05.01.15.30;	author brad;	state Exp;
branches;
next	1.134;

1.134
date	2006.07.03.20.55.55;	author brad;	state Exp;
branches;
next	1.133;

1.133
date	2006.06.28.02.46.54;	author brad;	state Exp;
branches;
next	1.132;

1.132
date	2006.06.24.00.49.36;	author brad;	state Exp;
branches;
next	1.131;

1.131
date	2006.05.31.02.09.18;	author brad;	state Exp;
branches;
next	1.130;

1.130
date	2006.05.28.23.38.49;	author brad;	state Exp;
branches;
next	1.129;

1.129
date	2006.05.28.10.40.27;	author brad;	state Exp;
branches;
next	1.128;

1.128
date	2006.05.28.00.38.44;	author brad;	state Exp;
branches;
next	1.127;

1.127
date	2006.05.28.00.04.24;	author jason;	state Exp;
branches;
next	1.126;

1.126
date	2006.05.27.10.03.15;	author brad;	state Exp;
branches;
next	1.125;

1.125
date	2006.05.26.20.50.41;	author deraadt;	state Exp;
branches;
next	1.124;

1.124
date	2006.05.25.18.27.34;	author brad;	state Exp;
branches;
next	1.123;

1.123
date	2006.05.25.14.31.37;	author jason;	state Exp;
branches;
next	1.122;

1.122
date	2006.05.20.05.12.23;	author reyk;	state Exp;
branches;
next	1.121;

1.121
date	2006.05.20.03.47.56;	author brad;	state Exp;
branches;
next	1.120;

1.120
date	2006.05.20.02.58.00;	author brad;	state Exp;
branches;
next	1.119;

1.119
date	2006.05.07.07.06.23;	author brad;	state Exp;
branches;
next	1.118;

1.118
date	2006.05.07.06.42.43;	author brad;	state Exp;
branches;
next	1.117;

1.117
date	2006.05.01.16.38.19;	author brad;	state Exp;
branches;
next	1.116;

1.116
date	2006.04.28.18.22.29;	author brad;	state Exp;
branches;
next	1.115;

1.115
date	2006.04.18.19.06.02;	author brad;	state Exp;
branches;
next	1.114;

1.114
date	2006.04.16.03.54.30;	author brad;	state Exp;
branches;
next	1.113;

1.113
date	2006.04.12.07.11.28;	author dlg;	state Exp;
branches;
next	1.112;

1.112
date	2006.03.28.05.33.03;	author brad;	state Exp;
branches;
next	1.111;

1.111
date	2006.03.27.18.01.53;	author brad;	state Exp;
branches;
next	1.110;

1.110
date	2006.03.25.22.41.44;	author djm;	state Exp;
branches;
next	1.109;

1.109
date	2006.02.24.06.09.44;	author brad;	state Exp;
branches
	1.109.2.1;
next	1.108;

1.108
date	2006.02.22.06.02.09;	author brad;	state Exp;
branches;
next	1.107;

1.107
date	2006.02.17.04.01.05;	author brad;	state Exp;
branches;
next	1.106;

1.106
date	2006.02.17.03.57.29;	author brad;	state Exp;
branches;
next	1.105;

1.105
date	2006.02.15.14.53.56;	author brad;	state Exp;
branches;
next	1.104;

1.104
date	2006.02.10.09.12.25;	author brad;	state Exp;
branches;
next	1.103;

1.103
date	2006.02.10.08.58.06;	author brad;	state Exp;
branches;
next	1.102;

1.102
date	2006.01.28.20.56.15;	author brad;	state Exp;
branches;
next	1.101;

1.101
date	2006.01.14.00.37.11;	author brad;	state Exp;
branches;
next	1.100;

1.100
date	2005.12.10.18.41.50;	author brad;	state Exp;
branches;
next	1.99;

1.99
date	2005.12.10.04.01.36;	author brad;	state Exp;
branches;
next	1.98;

1.98
date	2005.12.04.01.11.57;	author brad;	state Exp;
branches;
next	1.97;

1.97
date	2005.11.28.17.53.14;	author wilfried;	state Exp;
branches;
next	1.96;

1.96
date	2005.11.27.06.37.13;	author brad;	state Exp;
branches;
next	1.95;

1.95
date	2005.11.26.19.05.24;	author brad;	state Exp;
branches;
next	1.94;

1.94
date	2005.11.19.22.17.15;	author brad;	state Exp;
branches;
next	1.93;

1.93
date	2005.11.18.18.13.29;	author brad;	state Exp;
branches;
next	1.92;

1.92
date	2005.11.18.05.32.06;	author brad;	state Exp;
branches;
next	1.91;

1.91
date	2005.11.18.05.22.06;	author brad;	state Exp;
branches;
next	1.90;

1.90
date	2005.11.18.03.58.14;	author brad;	state Exp;
branches;
next	1.89;

1.89
date	2005.11.15.01.40.43;	author brad;	state Exp;
branches;
next	1.88;

1.88
date	2005.11.14.16.04.15;	author brad;	state Exp;
branches;
next	1.87;

1.87
date	2005.11.14.16.00.08;	author brad;	state Exp;
branches;
next	1.86;

1.86
date	2005.11.14.14.07.32;	author brad;	state Exp;
branches;
next	1.85;

1.85
date	2005.11.13.03.48.07;	author brad;	state Exp;
branches;
next	1.84;

1.84
date	2005.11.08.01.33.19;	author brad;	state Exp;
branches;
next	1.83;

1.83
date	2005.11.04.17.45.03;	author brad;	state Exp;
branches;
next	1.82;

1.82
date	2005.10.26.21.58.19;	author brad;	state Exp;
branches;
next	1.81;

1.81
date	2005.10.24.21.42.34;	author brad;	state Exp;
branches;
next	1.80;

1.80
date	2005.10.21.02.10.34;	author brad;	state Exp;
branches;
next	1.79;

1.79
date	2005.10.21.02.03.16;	author brad;	state Exp;
branches;
next	1.78;

1.78
date	2005.10.16.17.32.37;	author brad;	state Exp;
branches;
next	1.77;

1.77
date	2005.10.15.14.43.36;	author brad;	state Exp;
branches;
next	1.76;

1.76
date	2005.10.15.07.33.25;	author brad;	state Exp;
branches;
next	1.75;

1.75
date	2005.10.10.18.27.21;	author brad;	state Exp;
branches;
next	1.74;

1.74
date	2005.10.09.19.36.35;	author brad;	state Exp;
branches;
next	1.73;

1.73
date	2005.10.08.01.49.20;	author brad;	state Exp;
branches;
next	1.72;

1.72
date	2005.10.08.00.59.13;	author brad;	state Exp;
branches;
next	1.71;

1.71
date	2005.10.07.23.24.42;	author brad;	state Exp;
branches;
next	1.70;

1.70
date	2005.10.02.16.44.32;	author brad;	state Exp;
branches;
next	1.69;

1.69
date	2005.10.01.21.26.06;	author brad;	state Exp;
branches;
next	1.68;

1.68
date	2005.09.10.23.25.41;	author brad;	state Exp;
branches;
next	1.67;

1.67
date	2005.08.09.04.10.12;	author mickey;	state Exp;
branches
	1.67.2.1;
next	1.66;

1.66
date	2005.07.16.19.05.36;	author brad;	state Exp;
branches;
next	1.65;

1.65
date	2005.07.16.17.08.02;	author brad;	state Exp;
branches;
next	1.64;

1.64
date	2005.07.13.20.25.46;	author brad;	state Exp;
branches;
next	1.63;

1.63
date	2005.07.07.21.28.10;	author brad;	state Exp;
branches;
next	1.62;

1.62
date	2005.07.03.16.58.16;	author brad;	state Exp;
branches;
next	1.61;

1.61
date	2005.07.03.07.31.43;	author brad;	state Exp;
branches;
next	1.60;

1.60
date	2005.07.02.23.10.11;	author brad;	state Exp;
branches;
next	1.59;

1.59
date	2005.07.02.06.15.44;	author deraadt;	state Exp;
branches;
next	1.58;

1.58
date	2005.06.14.03.27.58;	author brad;	state Exp;
branches;
next	1.57;

1.57
date	2005.06.14.03.24.32;	author brad;	state Exp;
branches;
next	1.56;

1.56
date	2005.06.14.03.18.10;	author brad;	state Exp;
branches;
next	1.55;

1.55
date	2005.06.12.23.43.29;	author millert;	state Exp;
branches;
next	1.54;

1.54
date	2005.06.01.02.07.12;	author brad;	state Exp;
branches;
next	1.53;

1.53
date	2005.05.29.07.54.26;	author brad;	state Exp;
branches;
next	1.52;

1.52
date	2005.05.27.20.36.35;	author brad;	state Exp;
branches;
next	1.51;

1.51
date	2005.05.23.23.26.56;	author tedu;	state Exp;
branches;
next	1.50;

1.50
date	2005.05.07.22.16.36;	author brad;	state Exp;
branches;
next	1.49;

1.49
date	2005.05.07.15.48.34;	author brad;	state Exp;
branches;
next	1.48;

1.48
date	2005.05.01.12.19.48;	author markus;	state Exp;
branches;
next	1.47;

1.47
date	2005.04.25.17.55.51;	author brad;	state Exp;
branches;
next	1.46;

1.46
date	2005.04.25.02.08.08;	author brad;	state Exp;
branches;
next	1.45;

1.45
date	2005.04.10.04.08.40;	author brad;	state Exp;
branches;
next	1.44;

1.44
date	2005.04.01.06.44.14;	author brad;	state Exp;
branches;
next	1.43;

1.43
date	2005.03.31.15.31.22;	author brad;	state Exp;
branches;
next	1.42;

1.42
date	2005.03.27.17.11.13;	author brad;	state Exp;
branches;
next	1.41;

1.41
date	2005.03.27.16.38.13;	author brad;	state Exp;
branches;
next	1.40;

1.40
date	2005.03.26.23.04.58;	author brad;	state Exp;
branches;
next	1.39;

1.39
date	2005.03.16.11.59.09;	author markus;	state Exp;
branches
	1.39.2.1;
next	1.38;

1.38
date	2005.02.07.15.03.50;	author mcbride;	state Exp;
branches;
next	1.37;

1.37
date	2005.01.17.03.19.29;	author brad;	state Exp;
branches;
next	1.36;

1.36
date	2005.01.15.18.44.28;	author brad;	state Exp;
branches;
next	1.35;

1.35
date	2005.01.01.05.17.32;	author brad;	state Exp;
branches;
next	1.34;

1.34
date	2004.12.08.15.41.46;	author markus;	state Exp;
branches;
next	1.33;

1.33
date	2004.12.08.04.28.40;	author brad;	state Exp;
branches;
next	1.32;

1.32
date	2004.11.16.14.39.14;	author brad;	state Exp;
branches;
next	1.31;

1.31
date	2004.10.01.19.08.04;	author grange;	state Exp;
branches;
next	1.30;

1.30
date	2004.09.30.21.53.15;	author jason;	state Exp;
branches;
next	1.29;

1.29
date	2004.09.30.21.19.31;	author jason;	state Exp;
branches;
next	1.28;

1.28
date	2004.09.23.17.45.16;	author brad;	state Exp;
branches;
next	1.27;

1.27
date	2004.09.16.09.37.14;	author mcbride;	state Exp;
branches
	1.27.2.1;
next	1.26;

1.26
date	2004.09.08.23.01.55;	author deraadt;	state Exp;
branches;
next	1.25;

1.25
date	2004.09.06.08.49.19;	author markus;	state Exp;
branches;
next	1.24;

1.24
date	2004.07.14.01.25.31;	author deraadt;	state Exp;
branches;
next	1.23;

1.23
date	2004.06.18.20.42.34;	author mcbride;	state Exp;
branches;
next	1.22;

1.22
date	2004.06.18.20.31.31;	author mcbride;	state Exp;
branches;
next	1.21;

1.21
date	2004.05.04.06.00.51;	author henric;	state Exp;
branches;
next	1.20;

1.20
date	2004.04.26.07.27.52;	author deraadt;	state Exp;
branches;
next	1.19;

1.19
date	2004.04.18.04.15.00;	author henric;	state Exp;
branches;
next	1.18;

1.18
date	2004.04.03.18.51.01;	author grange;	state Exp;
branches;
next	1.17;

1.17
date	2004.02.12.21.21.06;	author markus;	state Exp;
branches;
next	1.16;

1.16
date	2003.12.09.23.41.35;	author henning;	state Exp;
branches;
next	1.15;

1.15
date	2003.12.04.23.30.15;	author henning;	state Exp;
branches;
next	1.14;

1.14
date	2003.12.04.02.50.27;	author naddy;	state Exp;
branches;
next	1.13;

1.13
date	2003.10.13.21.19.29;	author jason;	state Exp;
branches;
next	1.12;

1.12
date	2003.10.05.21.58.42;	author henric;	state Exp;
branches;
next	1.11;

1.11
date	2003.08.23.18.52.18;	author fgsch;	state Exp;
branches;
next	1.10;

1.10
date	2003.06.29.21.42.53;	author avsm;	state Exp;
branches;
next	1.9;

1.9
date	2003.06.13.19.21.21;	author henric;	state Exp;
branches;
next	1.8;

1.8
date	2003.06.13.02.23.16;	author brad;	state Exp;
branches;
next	1.7;

1.7
date	2003.02.27.16.31.09;	author nate;	state Exp;
branches
	1.7.4.1;
next	1.6;

1.6
date	2002.12.18.15.21.15;	author nate;	state Exp;
branches;
next	1.5;

1.5
date	2002.11.26.06.01.28;	author nate;	state Exp;
branches;
next	1.4;

1.4
date	2002.11.26.05.09.36;	author nate;	state Exp;
branches;
next	1.3;

1.3
date	2002.11.22.02.12.01;	author deraadt;	state Exp;
branches;
next	1.2;

1.2
date	2002.09.25.00.28.10;	author nate;	state Exp;
branches
	1.2.4.1;
next	1.1;

1.1
date	2002.09.24.18.56.02;	author nate;	state Exp;
branches;
next	;

1.2.4.1
date	2002.10.29.00.33.28;	author art;	state Exp;
branches;
next	1.2.4.2;

1.2.4.2
date	2003.05.19.22.18.00;	author tedu;	state Exp;
branches;
next	;

1.7.4.1
date	2004.02.19.10.56.26;	author niklas;	state Exp;
branches;
next	1.7.4.2;

1.7.4.2
date	2004.06.05.23.12.49;	author niklas;	state Exp;
branches;
next	;

1.27.2.1
date	2005.06.17.00.37.14;	author brad;	state Exp;
branches;
next	;

1.39.2.1
date	2005.06.17.00.44.10;	author brad;	state Exp;
branches;
next	;

1.67.2.1
date	2006.06.30.08.52.37;	author brad;	state Exp;
branches;
next	1.67.2.2;

1.67.2.2
date	2006.09.22.19.25.42;	author brad;	state Exp;
branches;
next	;

1.109.2.1
date	2006.06.30.08.37.16;	author brad;	state Exp;
branches;
next	1.109.2.2;

1.109.2.2
date	2006.09.17.19.50.00;	author brad;	state Exp;
branches;
next	;

1.146.2.1
date	2006.11.02.01.56.59;	author brad;	state Exp;
branches;
next	;

1.207.2.1
date	2009.05.25.21.44.20;	author sthen;	state Exp;
branches;
next	;

1.287.4.1
date	2014.09.07.03.15.42;	author jsg;	state Exp;
branches;
next	;
commitid	WD5M7v5ollO6mSXH;


desc
@@


1.336
log
@The LINK_STATE_IS_UP() macro considers LINK_STATE_UNKNOWN as up.
So the em(4) driver never got out of that state.  Better compare
the new link state value with the old one, like other drivers do.
bug report Matthias Pitzl; OK deraadt@@
@
text
@/**************************************************************************

Copyright (c) 2001-2003, Intel Corporation
All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are met:

 1. Redistributions of source code must retain the above copyright notice,
    this list of conditions and the following disclaimer.

 2. Redistributions in binary form must reproduce the above copyright
    notice, this list of conditions and the following disclaimer in the
    documentation and/or other materials provided with the distribution.

 3. Neither the name of the Intel Corporation nor the names of its
    contributors may be used to endorse or promote products derived from
    this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE
LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
POSSIBILITY OF SUCH DAMAGE.

***************************************************************************/

/* $OpenBSD: if_em.c,v 1.335 2017/03/19 11:09:26 jsg Exp $ */
/* $FreeBSD: if_em.c,v 1.46 2004/09/29 18:28:28 mlaier Exp $ */

#include <dev/pci/if_em.h>
#include <dev/pci/if_em_soc.h>

/*********************************************************************
 *  Driver version
 *********************************************************************/

#define EM_DRIVER_VERSION	"6.2.9"

/*********************************************************************
 *  PCI Device ID Table
 *********************************************************************/
const struct pci_matchid em_devices[] = {
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_80003ES2LAN_CPR_DPT },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_80003ES2LAN_SDS_DPT },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_80003ES2LAN_CPR_SPT },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_80003ES2LAN_SDS_SPT },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82540EM },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82540EM_LOM },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82540EP },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82540EP_LOM },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82540EP_LP },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82541EI },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82541EI_MOBILE },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82541ER },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82541ER_LOM },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82541GI },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82541GI_LF },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82541GI_MOBILE },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82542 },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82543GC_COPPER },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82543GC_FIBER },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82544EI_COPPER },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82544EI_FIBER },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82544GC_COPPER },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82544GC_LOM },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82545EM_COPPER },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82545EM_FIBER },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82545GM_COPPER },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82545GM_FIBER },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82545GM_SERDES },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82546EB_COPPER },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82546EB_FIBER },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82546EB_QUAD_CPR },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82546GB_COPPER },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82546GB_FIBER },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82546GB_PCIE },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82546GB_QUAD_CPR },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82546GB_QUAD_CPR_K },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82546GB_SERDES },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82546GB_2 },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82547EI },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82547EI_MOBILE },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82547GI },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82571EB_AF },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82571EB_AT },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82571EB_COPPER },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82571EB_FIBER },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82571EB_QUAD_CPR },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82571EB_QUAD_CPR_LP },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82571EB_QUAD_FBR },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82571EB_SERDES },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82571EB_SDS_DUAL },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82571EB_SDS_QUAD },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82571PT_QUAD_CPR },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82572EI_COPPER },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82572EI_FIBER },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82572EI_SERDES },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82572EI },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82573E },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82573E_IAMT },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82573E_PM },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82573L },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82573L_PL_1 },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82573L_PL_2 },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82573V_PM },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82574L },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82574LA },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82575EB_COPPER },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82575EB_SERDES },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82575GB_QUAD_CPR },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82575GB_QP_PM },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82576 },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82576_FIBER },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82576_SERDES },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82576_QUAD_COPPER },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82576_QUAD_CU_ET2 },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82576_NS },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82576_NS_SERDES },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82576_SERDES_QUAD },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82577LC },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82577LM },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82578DC },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82578DM },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82579LM },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82579V },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_I210_COPPER },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_I210_FIBER },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_I210_SERDES },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_I210_SGMII },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_I210_COPPER_NF },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_I210_SERDES_NF },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_I211_COPPER },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_I217_LM },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_I217_V },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_I218_LM },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_I218_LM_2 },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_I218_LM_3 },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_I218_V },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_I218_V_2 },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_I218_V_3 },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_I219_LM },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_I219_LM2 },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_I219_LM3 },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_I219_LM4 },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_I219_LM5 },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_I219_V },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_I219_V2 },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_I219_V4 },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_I219_V5 },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82580_COPPER },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82580_FIBER },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82580_SERDES },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82580_SGMII },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82580_COPPER_DUAL },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82580_QUAD_FIBER },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_DH89XXCC_SGMII },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_DH89XXCC_SERDES },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_DH89XXCC_BPLANE },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_DH89XXCC_SFP },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82583V },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_I350_COPPER },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_I350_FIBER },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_I350_SERDES },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_I350_SGMII },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_I354_BP_1GBPS },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_I354_BP_2_5GBPS },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_I354_SGMII },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_ICH8_82567V_3 },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_ICH8_IFE },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_ICH8_IFE_G },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_ICH8_IFE_GT },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_ICH8_IGP_AMT },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_ICH8_IGP_C },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_ICH8_IGP_M },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_ICH8_IGP_M_AMT },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_ICH9_BM },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_ICH9_IFE },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_ICH9_IFE_G },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_ICH9_IFE_GT },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_ICH9_IGP_AMT },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_ICH9_IGP_C },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_ICH9_IGP_M },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_ICH9_IGP_M_AMT },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_ICH9_IGP_M_V },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_ICH10_D_BM_LF },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_ICH10_D_BM_LM },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_ICH10_R_BM_LF },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_ICH10_R_BM_LM },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_ICH10_R_BM_V },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_EP80579_LAN_1 },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_EP80579_LAN_2 },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_EP80579_LAN_3 },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_EP80579_LAN_4 },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_EP80579_LAN_5 },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_EP80579_LAN_6 }
};

/*********************************************************************
 *  Function prototypes
 *********************************************************************/
int  em_probe(struct device *, void *, void *);
void em_attach(struct device *, struct device *, void *);
void em_defer_attach(struct device*);
int  em_detach(struct device *, int);
int  em_activate(struct device *, int);
int  em_intr(void *);
void em_start(struct ifqueue *);
int  em_ioctl(struct ifnet *, u_long, caddr_t);
void em_watchdog(struct ifnet *);
void em_init(void *);
void em_stop(void *, int);
void em_media_status(struct ifnet *, struct ifmediareq *);
int  em_media_change(struct ifnet *);
uint64_t  em_flowstatus(struct em_softc *);
void em_identify_hardware(struct em_softc *);
int  em_allocate_pci_resources(struct em_softc *);
void em_free_pci_resources(struct em_softc *);
void em_local_timer(void *);
int  em_hardware_init(struct em_softc *);
void em_setup_interface(struct em_softc *);
int  em_setup_transmit_structures(struct em_softc *);
void em_initialize_transmit_unit(struct em_softc *);
int  em_setup_receive_structures(struct em_softc *);
void em_initialize_receive_unit(struct em_softc *);
void em_enable_intr(struct em_softc *);
void em_disable_intr(struct em_softc *);
void em_free_transmit_structures(struct em_softc *);
void em_free_receive_structures(struct em_softc *);
void em_update_stats_counters(struct em_softc *);
void em_disable_aspm(struct em_softc *);
void em_txeof(struct em_softc *);
int  em_allocate_receive_structures(struct em_softc *);
int  em_allocate_transmit_structures(struct em_softc *);
int  em_rxfill(struct em_softc *);
int  em_rxeof(struct em_softc *);
void em_receive_checksum(struct em_softc *, struct em_rx_desc *,
			 struct mbuf *);
u_int	em_transmit_checksum_setup(struct em_softc *, struct mbuf *, u_int,
	    u_int32_t *, u_int32_t *);
void em_iff(struct em_softc *);
#ifdef EM_DEBUG
void em_print_hw_stats(struct em_softc *);
#endif
void em_update_link_status(struct em_softc *);
int  em_get_buf(struct em_softc *, int);
void em_enable_hw_vlans(struct em_softc *);
u_int em_encap(struct em_softc *, struct mbuf *);
void em_smartspeed(struct em_softc *);
int  em_82547_fifo_workaround(struct em_softc *, int);
void em_82547_update_fifo_head(struct em_softc *, int);
int  em_82547_tx_fifo_reset(struct em_softc *);
void em_82547_move_tail(void *arg);
void em_82547_move_tail_locked(struct em_softc *);
int  em_dma_malloc(struct em_softc *, bus_size_t, struct em_dma_alloc *);
void em_dma_free(struct em_softc *, struct em_dma_alloc *);
u_int32_t em_fill_descriptors(u_int64_t address, u_int32_t length,
			      PDESC_ARRAY desc_array);
void em_flush_tx_ring(struct em_softc *);
void em_flush_rx_ring(struct em_softc *);
void em_flush_desc_rings(struct em_softc *);

/*********************************************************************
 *  OpenBSD Device Interface Entry Points
 *********************************************************************/

struct cfattach em_ca = {
	sizeof(struct em_softc), em_probe, em_attach, em_detach,
	em_activate
};

struct cfdriver em_cd = {
	NULL, "em", DV_IFNET
};

static int em_smart_pwr_down = FALSE;

/*********************************************************************
 *  Device identification routine
 *
 *  em_probe determines if the driver should be loaded on
 *  adapter based on PCI vendor/device id of the adapter.
 *
 *  return 0 on no match, positive on match
 *********************************************************************/

int
em_probe(struct device *parent, void *match, void *aux)
{
	INIT_DEBUGOUT("em_probe: begin");

	return (pci_matchbyid((struct pci_attach_args *)aux, em_devices,
	    nitems(em_devices)));
}

void
em_defer_attach(struct device *self)
{
	struct em_softc *sc = (struct em_softc *)self;
	struct pci_attach_args *pa = &sc->osdep.em_pa;
	pci_chipset_tag_t	pc = pa->pa_pc;
	void *gcu;

	INIT_DEBUGOUT("em_defer_attach: begin");

	if ((gcu = em_lookup_gcu(self)) == 0) {
		printf("%s: No GCU found, defered attachment failed\n",
		    DEVNAME(sc));

		if (sc->sc_intrhand)
			pci_intr_disestablish(pc, sc->sc_intrhand);
		sc->sc_intrhand = 0;

		em_stop(sc, 1);

		em_free_pci_resources(sc);

		sc->sc_rx_desc_ring = NULL;
		em_dma_free(sc, &sc->sc_rx_dma);
		sc->sc_tx_desc_ring = NULL;
		em_dma_free(sc, &sc->sc_tx_dma);

		return;
	}
	
	sc->hw.gcu = gcu;
	
	em_attach_miibus(self);			

	em_setup_interface(sc);			

	em_setup_link(&sc->hw);			

	em_update_link_status(sc);
}

/*********************************************************************
 *  Device initialization routine
 *
 *  The attach entry point is called when the driver is being loaded.
 *  This routine identifies the type of hardware, allocates all resources
 *  and initializes the hardware.
 *
 *********************************************************************/

void 
em_attach(struct device *parent, struct device *self, void *aux)
{
	struct pci_attach_args *pa = aux;
	struct em_softc *sc;
	int defer = 0;
    
	INIT_DEBUGOUT("em_attach: begin");

	sc = (struct em_softc *)self;
	sc->sc_dmat = pa->pa_dmat;
	sc->osdep.em_pa = *pa;

	timeout_set(&sc->timer_handle, em_local_timer, sc);
	timeout_set(&sc->tx_fifo_timer_handle, em_82547_move_tail, sc);

	/* Determine hardware revision */
	em_identify_hardware(sc);

	/*
	 * Only use MSI on the newer PCIe parts, with the exception
	 * of 82571/82572 due to "Byte Enables 2 and 3 Are Not Set" errata
	 */
	if (sc->hw.mac_type <= em_82572)
		sc->osdep.em_pa.pa_flags &= ~PCI_FLAGS_MSI_ENABLED;

	/* Parameters (to be read from user) */
	if (sc->hw.mac_type >= em_82544) {
		sc->sc_tx_slots = EM_MAX_TXD;
		sc->sc_rx_slots = EM_MAX_RXD;
	} else {
		sc->sc_tx_slots = EM_MAX_TXD_82543;
		sc->sc_rx_slots = EM_MAX_RXD_82543;
	}
	sc->tx_int_delay = EM_TIDV;
	sc->tx_abs_int_delay = EM_TADV;
	sc->rx_int_delay = EM_RDTR;
	sc->rx_abs_int_delay = EM_RADV;
	sc->hw.autoneg = DO_AUTO_NEG;
	sc->hw.wait_autoneg_complete = WAIT_FOR_AUTO_NEG_DEFAULT;
	sc->hw.autoneg_advertised = AUTONEG_ADV_DEFAULT;
	sc->hw.tbi_compatibility_en = TRUE;
	sc->sc_rx_buffer_len = EM_RXBUFFER_2048;

	sc->hw.phy_init_script = 1;
	sc->hw.phy_reset_disable = FALSE;

#ifndef EM_MASTER_SLAVE
	sc->hw.master_slave = em_ms_hw_default;
#else
	sc->hw.master_slave = EM_MASTER_SLAVE;
#endif

	/*
	 * This controls when hardware reports transmit completion
	 * status.   
	 */
	sc->hw.report_tx_early = 1;

	if (em_allocate_pci_resources(sc))
		goto err_pci;

	/* Initialize eeprom parameters */
	em_init_eeprom_params(&sc->hw);

	/*
	 * Set the max frame size assuming standard Ethernet
	 * sized frames.
	 */
	switch (sc->hw.mac_type) {
		case em_82573:
		{
			uint16_t	eeprom_data = 0;

			/*
			 * 82573 only supports Jumbo frames
			 * if ASPM is disabled.
			 */
			em_read_eeprom(&sc->hw, EEPROM_INIT_3GIO_3,
			    1, &eeprom_data);
			if (eeprom_data & EEPROM_WORD1A_ASPM_MASK) {
				sc->hw.max_frame_size = ETHER_MAX_LEN;
				break;
			}
			/* Allow Jumbo frames */
			/* FALLTHROUGH */
		}
		case em_82571:
		case em_82572:
		case em_82574:
		case em_82575:
		case em_82580:
		case em_i210:
		case em_i350:
		case em_ich9lan:
		case em_ich10lan:
		case em_pch2lan:
		case em_pch_lpt:
		case em_pch_spt:
		case em_80003es2lan:
			/* 9K Jumbo Frame size */
			sc->hw.max_frame_size = 9234;
			break;
		case em_pchlan:
			sc->hw.max_frame_size = 4096;
			break;
		case em_82542_rev2_0:
		case em_82542_rev2_1:
		case em_ich8lan:
			/* Adapters that do not support Jumbo frames */
			sc->hw.max_frame_size = ETHER_MAX_LEN;
			break;
		default:
			sc->hw.max_frame_size =
			    MAX_JUMBO_FRAME_SIZE;
	}

	sc->hw.min_frame_size = 
	    ETHER_MIN_LEN + ETHER_CRC_LEN;

	/* Allocate Transmit Descriptor ring */
	if (em_dma_malloc(sc, sc->sc_tx_slots * sizeof(struct em_tx_desc),
	    &sc->sc_tx_dma) != 0) {
		printf("%s: Unable to allocate tx_desc memory\n", 
		       DEVNAME(sc));
		goto err_tx_desc;
	}
	sc->sc_tx_desc_ring = (struct em_tx_desc *)sc->sc_tx_dma.dma_vaddr;

	/* Allocate Receive Descriptor ring */
	if (em_dma_malloc(sc, sc->sc_rx_slots * sizeof(struct em_rx_desc),
	    &sc->sc_rx_dma) != 0) {
		printf("%s: Unable to allocate rx_desc memory\n",
		       DEVNAME(sc));
		goto err_rx_desc;
	}
	sc->sc_rx_desc_ring = (struct em_rx_desc *)sc->sc_rx_dma.dma_vaddr;

	/* Initialize the hardware */
	if ((defer = em_hardware_init(sc))) {
		if (defer == EAGAIN)
			config_defer(self, em_defer_attach);
		else {
			printf("%s: Unable to initialize the hardware\n",
			    DEVNAME(sc));
			goto err_hw_init;
		}
	}

	if (sc->hw.mac_type == em_80003es2lan || sc->hw.mac_type == em_82575 ||
	    sc->hw.mac_type == em_82580 || sc->hw.mac_type == em_i210 ||
	    sc->hw.mac_type == em_i350) {
		uint32_t reg = EM_READ_REG(&sc->hw, E1000_STATUS);
		sc->hw.bus_func = (reg & E1000_STATUS_FUNC_MASK) >>
		    E1000_STATUS_FUNC_SHIFT;

		switch (sc->hw.bus_func) {
		case 0:
			sc->hw.swfw = E1000_SWFW_PHY0_SM;
			break;
		case 1:
			sc->hw.swfw = E1000_SWFW_PHY1_SM;
			break;
		case 2:
			sc->hw.swfw = E1000_SWFW_PHY2_SM;
			break;
		case 3:
			sc->hw.swfw = E1000_SWFW_PHY3_SM;
			break;
		}
	} else {
		sc->hw.bus_func = 0;
	}

	/* Copy the permanent MAC address out of the EEPROM */
	if (em_read_mac_addr(&sc->hw) < 0) {
		printf("%s: EEPROM read error while reading mac address\n",
		       DEVNAME(sc));
		goto err_mac_addr;
	}

	bcopy(sc->hw.mac_addr, sc->sc_ac.ac_enaddr, ETHER_ADDR_LEN);

	/* Setup OS specific network interface */
	if (!defer)
		em_setup_interface(sc);

	/* Initialize statistics */
	em_clear_hw_cntrs(&sc->hw);
#ifndef SMALL_KERNEL
	em_update_stats_counters(sc);
#endif
	sc->hw.get_link_status = 1;
	if (!defer)
		em_update_link_status(sc);

	printf(", address %s\n", ether_sprintf(sc->sc_ac.ac_enaddr));

	/* Indicate SOL/IDER usage */
	if (em_check_phy_reset_block(&sc->hw))
		printf("%s: PHY reset is blocked due to SOL/IDER session.\n",
		    DEVNAME(sc));

	/* Identify 82544 on PCI-X */
	em_get_bus_info(&sc->hw);
	if (sc->hw.bus_type == em_bus_type_pcix &&
	    sc->hw.mac_type == em_82544)
		sc->pcix_82544 = TRUE;
        else
		sc->pcix_82544 = FALSE;

	sc->hw.icp_xxxx_is_link_up = FALSE;

	INIT_DEBUGOUT("em_attach: end");
	return;

err_mac_addr:
err_hw_init:
	sc->sc_rx_desc_ring = NULL;
	em_dma_free(sc, &sc->sc_rx_dma);
err_rx_desc:
	sc->sc_tx_desc_ring = NULL;
	em_dma_free(sc, &sc->sc_tx_dma);
err_tx_desc:
err_pci:
	em_free_pci_resources(sc);
}

/*********************************************************************
 *  Transmit entry point
 *
 *  em_start is called by the stack to initiate a transmit.
 *  The driver will remain in this routine as long as there are
 *  packets to transmit and transmit resources are available.
 *  In case resources are not available stack is notified and
 *  the packet is requeued.
 **********************************************************************/

void
em_start(struct ifqueue *ifq)
{
	struct ifnet *ifp = ifq->ifq_if;
	struct em_softc *sc = ifp->if_softc;
	u_int head, free, used;
	struct mbuf *m;
	int post = 0;

	if (!sc->link_active) {
		ifq_purge(ifq);
		return;
	}

	/* calculate free space */
	head = sc->sc_tx_desc_head;
	free = sc->sc_tx_desc_tail;
	if (free <= head)
		free += sc->sc_tx_slots;
	free -= head;

	if (sc->hw.mac_type != em_82547) {
		bus_dmamap_sync(sc->sc_dmat, sc->sc_tx_dma.dma_map,
		    0, sc->sc_tx_dma.dma_map->dm_mapsize,
		    BUS_DMASYNC_POSTREAD | BUS_DMASYNC_POSTWRITE);
	}

	for (;;) {
		/* use 2 because cksum setup can use an extra slot */
		if (EM_MAX_SCATTER + 2 > free) {
			ifq_set_oactive(ifq);
			break;
		}

		m = ifq_dequeue(ifq);
		if (m == NULL)
			break;

		used = em_encap(sc, m);
		if (used == 0) {
			m_freem(m);
			continue;
		}

		KASSERT(used <= free);

		free -= used;

#if NBPFILTER > 0
		/* Send a copy of the frame to the BPF listener */
		if (ifp->if_bpf)
			bpf_mtap_ether(ifp->if_bpf, m, BPF_DIRECTION_OUT);
#endif

		/* Set timeout in case hardware has problems transmitting */
		ifp->if_timer = EM_TX_TIMEOUT;

		if (sc->hw.mac_type == em_82547) {
			int len = m->m_pkthdr.len;

			if (sc->link_duplex == HALF_DUPLEX)
				em_82547_move_tail_locked(sc);
			else {
				E1000_WRITE_REG(&sc->hw, TDT,
				    sc->sc_tx_desc_head);
				em_82547_update_fifo_head(sc, len);
			}
		}

		post = 1;
	}

	if (sc->hw.mac_type != em_82547) {
		bus_dmamap_sync(sc->sc_dmat, sc->sc_tx_dma.dma_map,
		    0, sc->sc_tx_dma.dma_map->dm_mapsize,
		    BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);
		/* 
		 * Advance the Transmit Descriptor Tail (Tdt),
		 * this tells the E1000 that this frame is
		 * available to transmit.
		 */
		if (post)
			E1000_WRITE_REG(&sc->hw, TDT, sc->sc_tx_desc_head);
	}
}

/*********************************************************************
 *  Ioctl entry point
 *
 *  em_ioctl is called when the user wants to configure the
 *  interface.
 *
 *  return 0 on success, positive on failure
 **********************************************************************/

int
em_ioctl(struct ifnet *ifp, u_long command, caddr_t data)
{
	int		error = 0;
	struct ifreq   *ifr = (struct ifreq *) data;
	struct em_softc *sc = ifp->if_softc;
	int s;

	s = splnet();

	switch (command) {
	case SIOCSIFADDR:
		IOCTL_DEBUGOUT("ioctl rcv'd: SIOCSIFADDR (Set Interface "
			       "Addr)");
		if (!(ifp->if_flags & IFF_UP)) {
			ifp->if_flags |= IFF_UP;
			em_init(sc);
		}
		break;

	case SIOCSIFFLAGS:
		IOCTL_DEBUGOUT("ioctl rcv'd: SIOCSIFFLAGS (Set Interface Flags)");
		if (ifp->if_flags & IFF_UP) {
			if (ifp->if_flags & IFF_RUNNING)
				error = ENETRESET;
			else
				em_init(sc);
		} else {
			if (ifp->if_flags & IFF_RUNNING)
				em_stop(sc, 0);
		}
		break;

	case SIOCSIFMEDIA:
		/* Check SOL/IDER usage */
		if (em_check_phy_reset_block(&sc->hw)) {
			printf("%s: Media change is blocked due to SOL/IDER session.\n",
			    DEVNAME(sc));
			break;
		}
	case SIOCGIFMEDIA:
		IOCTL_DEBUGOUT("ioctl rcv'd: SIOCxIFMEDIA (Get/Set Interface Media)");
		error = ifmedia_ioctl(ifp, ifr, &sc->media, command);
		break;

	case SIOCGIFRXR:
		error = if_rxr_ioctl((struct if_rxrinfo *)ifr->ifr_data,
		    NULL, EM_MCLBYTES, &sc->sc_rx_ring);
		break;

	default:
		error = ether_ioctl(ifp, &sc->sc_ac, command, data);
	}

	if (error == ENETRESET) {
		if (ifp->if_flags & IFF_RUNNING) {
			em_disable_intr(sc);
			em_iff(sc);
			if (sc->hw.mac_type == em_82542_rev2_0)
				em_initialize_receive_unit(sc);
			em_enable_intr(sc);
		}
		error = 0;
	}

	splx(s);
	return (error);
}

/*********************************************************************
 *  Watchdog entry point
 *
 *  This routine is called whenever hardware quits transmitting.
 *
 **********************************************************************/

void
em_watchdog(struct ifnet *ifp)
{
	struct em_softc *sc = ifp->if_softc;

	/* If we are in this routine because of pause frames, then
	 * don't reset the hardware.
	 */
	if (E1000_READ_REG(&sc->hw, STATUS) & E1000_STATUS_TXOFF) {
		ifp->if_timer = EM_TX_TIMEOUT;
		return;
	}
	printf("%s: watchdog: head %u tail %u TDH %u TDT %u\n",
	    DEVNAME(sc),
	    sc->sc_tx_desc_head, sc->sc_tx_desc_tail,
	    E1000_READ_REG(&sc->hw, TDH), E1000_READ_REG(&sc->hw, TDT));

	em_init(sc);

	sc->watchdog_events++;
}

/*********************************************************************
 *  Init entry point
 *
 *  This routine is used in two ways. It is used by the stack as
 *  init entry point in network interface structure. It is also used
 *  by the driver as a hw/sw initialization routine to get to a
 *  consistent state.
 *
 **********************************************************************/

void
em_init(void *arg)
{
	struct em_softc *sc = arg;
	struct ifnet   *ifp = &sc->sc_ac.ac_if;
	uint32_t	pba;
	int s;

	s = splnet();

	INIT_DEBUGOUT("em_init: begin");

	em_stop(sc, 0);

	/*
	 * Packet Buffer Allocation (PBA)
	 * Writing PBA sets the receive portion of the buffer
	 * the remainder is used for the transmit buffer.
	 *
	 * Devices before the 82547 had a Packet Buffer of 64K.
	 *   Default allocation: PBA=48K for Rx, leaving 16K for Tx.
	 * After the 82547 the buffer was reduced to 40K.
	 *   Default allocation: PBA=30K for Rx, leaving 10K for Tx.
	 *   Note: default does not leave enough room for Jumbo Frame >10k.
	 */
	switch (sc->hw.mac_type) {
	case em_82547:
	case em_82547_rev_2: /* 82547: Total Packet Buffer is 40K */
		if (sc->hw.max_frame_size > EM_RXBUFFER_8192)
			pba = E1000_PBA_22K; /* 22K for Rx, 18K for Tx */
		else
			pba = E1000_PBA_30K; /* 30K for Rx, 10K for Tx */
		sc->tx_fifo_head = 0;
		sc->tx_head_addr = pba << EM_TX_HEAD_ADDR_SHIFT;
		sc->tx_fifo_size = (E1000_PBA_40K - pba) << EM_PBA_BYTES_SHIFT;
		break;
	case em_82571:
	case em_82572: /* Total Packet Buffer on these is 48k */
	case em_82575:
	case em_82580:
	case em_80003es2lan:
	case em_i350:
		pba = E1000_PBA_32K; /* 32K for Rx, 16K for Tx */
		break;
	case em_i210:
		pba = E1000_PBA_34K;
		break;
	case em_82573: /* 82573: Total Packet Buffer is 32K */
		/* Jumbo frames not supported */
		pba = E1000_PBA_12K; /* 12K for Rx, 20K for Tx */
		break;
	case em_82574: /* Total Packet Buffer is 40k */
		pba = E1000_PBA_20K; /* 20K for Rx, 20K for Tx */
		break;
	case em_ich8lan:
		pba = E1000_PBA_8K;
		break;
	case em_ich9lan:
	case em_ich10lan:
		/* Boost Receive side for jumbo frames */
		if (sc->hw.max_frame_size > EM_RXBUFFER_4096)
			pba = E1000_PBA_14K;
		else
			pba = E1000_PBA_10K;
		break;
	case em_pchlan:
	case em_pch2lan:
	case em_pch_lpt:
	case em_pch_spt:
		pba = E1000_PBA_26K;
		break;
	default:
		/* Devices before 82547 had a Packet Buffer of 64K.   */
		if (sc->hw.max_frame_size > EM_RXBUFFER_8192)
			pba = E1000_PBA_40K; /* 40K for Rx, 24K for Tx */
		else
			pba = E1000_PBA_48K; /* 48K for Rx, 16K for Tx */
	}
	INIT_DEBUGOUT1("em_init: pba=%dK",pba);
	E1000_WRITE_REG(&sc->hw, PBA, pba);

	/* Get the latest mac address, User can use a LAA */
	bcopy(sc->sc_ac.ac_enaddr, sc->hw.mac_addr, ETHER_ADDR_LEN);

	/* Initialize the hardware */
	if (em_hardware_init(sc)) {
		printf("%s: Unable to initialize the hardware\n", 
		       DEVNAME(sc));
		splx(s);
		return;
	}
	em_update_link_status(sc);

	E1000_WRITE_REG(&sc->hw, VET, ETHERTYPE_VLAN);
	if (ifp->if_capabilities & IFCAP_VLAN_HWTAGGING)
		em_enable_hw_vlans(sc);

	/* Prepare transmit descriptors and buffers */
	if (em_setup_transmit_structures(sc)) {
		printf("%s: Could not setup transmit structures\n", 
		       DEVNAME(sc));
		em_stop(sc, 0);
		splx(s);
		return;
	}
	em_initialize_transmit_unit(sc);

	/* Prepare receive descriptors and buffers */
	if (em_setup_receive_structures(sc)) {
		printf("%s: Could not setup receive structures\n", 
		       DEVNAME(sc));
		em_stop(sc, 0);
		splx(s);
		return;
	}
	em_initialize_receive_unit(sc);

	/* Program promiscuous mode and multicast filters. */
	em_iff(sc);

	ifp->if_flags |= IFF_RUNNING;
	ifq_clr_oactive(&ifp->if_snd);

	timeout_add_sec(&sc->timer_handle, 1);
	em_clear_hw_cntrs(&sc->hw);
	em_enable_intr(sc);

	/* Don't reset the phy next time init gets called */
	sc->hw.phy_reset_disable = TRUE;

	splx(s);
}

/*********************************************************************
 *
 *  Interrupt Service routine
 *
 **********************************************************************/
int 
em_intr(void *arg)
{
	struct em_softc	*sc = arg;
	struct ifnet	*ifp = &sc->sc_ac.ac_if;
	u_int32_t	reg_icr, test_icr;

	test_icr = reg_icr = E1000_READ_REG(&sc->hw, ICR);
	if (sc->hw.mac_type >= em_82571)
		test_icr = (reg_icr & E1000_ICR_INT_ASSERTED);
	if (!test_icr)
		return (0);

	if (ifp->if_flags & IFF_RUNNING) {
		em_txeof(sc);

		if (em_rxeof(sc) || ISSET(reg_icr, E1000_ICR_RXO)) {
			if (em_rxfill(sc)) {
				E1000_WRITE_REG(&sc->hw, RDT,
				    sc->sc_rx_desc_head);
			}
		}
	}

	/* Link status change */
	if (reg_icr & (E1000_ICR_RXSEQ | E1000_ICR_LSC)) {
		KERNEL_LOCK();
		sc->hw.get_link_status = 1;
		em_check_for_link(&sc->hw);
		em_update_link_status(sc);
		KERNEL_UNLOCK();
	}

	return (1);
}

/*********************************************************************
 *
 *  Media Ioctl callback
 *
 *  This routine is called whenever the user queries the status of
 *  the interface using ifconfig.
 *
 **********************************************************************/
void
em_media_status(struct ifnet *ifp, struct ifmediareq *ifmr)
{
	struct em_softc *sc = ifp->if_softc;
	uint64_t fiber_type = IFM_1000_SX;
	u_int16_t gsr;

	INIT_DEBUGOUT("em_media_status: begin");

	em_check_for_link(&sc->hw);
	em_update_link_status(sc);

	ifmr->ifm_status = IFM_AVALID;
	ifmr->ifm_active = IFM_ETHER;

	if (!sc->link_active) {
		ifmr->ifm_active |= IFM_NONE;
		return;
	}

	ifmr->ifm_status |= IFM_ACTIVE;

	if (sc->hw.media_type == em_media_type_fiber ||
	    sc->hw.media_type == em_media_type_internal_serdes) {
		if (sc->hw.mac_type == em_82545)
			fiber_type = IFM_1000_LX;
		ifmr->ifm_active |= fiber_type | IFM_FDX;
	} else {
		switch (sc->link_speed) {
		case 10:
			ifmr->ifm_active |= IFM_10_T;
			break;
		case 100:
			ifmr->ifm_active |= IFM_100_TX;
			break;
		case 1000:
			ifmr->ifm_active |= IFM_1000_T;
			break;
		}

		if (sc->link_duplex == FULL_DUPLEX)
			ifmr->ifm_active |= em_flowstatus(sc) | IFM_FDX;
		else
			ifmr->ifm_active |= IFM_HDX;

		if (IFM_SUBTYPE(ifmr->ifm_active) == IFM_1000_T) {
			em_read_phy_reg(&sc->hw, PHY_1000T_STATUS, &gsr);
			if (gsr & SR_1000T_MS_CONFIG_RES)
				ifmr->ifm_active |= IFM_ETH_MASTER;
		}
	}
}

/*********************************************************************
 *
 *  Media Ioctl callback
 *
 *  This routine is called when the user changes speed/duplex using
 *  media/mediopt option with ifconfig.
 *
 **********************************************************************/
int
em_media_change(struct ifnet *ifp)
{
	struct em_softc *sc = ifp->if_softc;
	struct ifmedia	*ifm = &sc->media;

	INIT_DEBUGOUT("em_media_change: begin");

	if (IFM_TYPE(ifm->ifm_media) != IFM_ETHER)
		return (EINVAL);

	switch (IFM_SUBTYPE(ifm->ifm_media)) {
	case IFM_AUTO:
		sc->hw.autoneg = DO_AUTO_NEG;
		sc->hw.autoneg_advertised = AUTONEG_ADV_DEFAULT;
		break;
	case IFM_1000_LX:
	case IFM_1000_SX:
	case IFM_1000_T:
		sc->hw.autoneg = DO_AUTO_NEG;
		sc->hw.autoneg_advertised = ADVERTISE_1000_FULL;
		break;
	case IFM_100_TX:
		sc->hw.autoneg = FALSE;
		sc->hw.autoneg_advertised = 0;
		if ((ifm->ifm_media & IFM_GMASK) == IFM_FDX)
			sc->hw.forced_speed_duplex = em_100_full;
		else
			sc->hw.forced_speed_duplex = em_100_half;
		break;
	case IFM_10_T:
		sc->hw.autoneg = FALSE;
		sc->hw.autoneg_advertised = 0;
		if ((ifm->ifm_media & IFM_GMASK) == IFM_FDX)
			sc->hw.forced_speed_duplex = em_10_full;
		else
			sc->hw.forced_speed_duplex = em_10_half;
		break;
	default:
		printf("%s: Unsupported media type\n", DEVNAME(sc));
	}

	/*
	 * As the speed/duplex settings may have changed we need to
	 * reset the PHY.
	 */
	sc->hw.phy_reset_disable = FALSE;

	em_init(sc);

	return (0);
}

uint64_t
em_flowstatus(struct em_softc *sc)
{
	u_int16_t ar, lpar;

	if (sc->hw.media_type == em_media_type_fiber ||
	    sc->hw.media_type == em_media_type_internal_serdes)
		return (0);

	em_read_phy_reg(&sc->hw, PHY_AUTONEG_ADV, &ar);
	em_read_phy_reg(&sc->hw, PHY_LP_ABILITY, &lpar);

	if ((ar & NWAY_AR_PAUSE) && (lpar & NWAY_LPAR_PAUSE))
		return (IFM_FLOW|IFM_ETH_TXPAUSE|IFM_ETH_RXPAUSE);
	else if (!(ar & NWAY_AR_PAUSE) && (ar & NWAY_AR_ASM_DIR) &&
		(lpar & NWAY_LPAR_PAUSE) && (lpar & NWAY_LPAR_ASM_DIR))
		return (IFM_FLOW|IFM_ETH_TXPAUSE);
	else if ((ar & NWAY_AR_PAUSE) && (ar & NWAY_AR_ASM_DIR) &&
		!(lpar & NWAY_LPAR_PAUSE) && (lpar & NWAY_LPAR_ASM_DIR))
		return (IFM_FLOW|IFM_ETH_RXPAUSE);

	return (0);
}

/*********************************************************************
 *
 *  This routine maps the mbufs to tx descriptors.
 *
 *  return 0 on success, positive on failure
 **********************************************************************/
u_int
em_encap(struct em_softc *sc, struct mbuf *m)
{
	struct em_packet *pkt;
	struct em_tx_desc *desc;
	bus_dmamap_t map;
	u_int32_t txd_upper, txd_lower;
	u_int head, last, used = 0;
	int i, j;

	/* For 82544 Workaround */
	DESC_ARRAY		desc_array;
	u_int32_t		array_elements;

	/* get a dmamap for this packet from the next free slot */
	head = sc->sc_tx_desc_head;
	pkt = &sc->sc_tx_pkts_ring[head];
	map = pkt->pkt_map;

	switch (bus_dmamap_load_mbuf(sc->sc_dmat, map, m, BUS_DMA_NOWAIT)) {
	case 0:
		break;
	case EFBIG:
		if (m_defrag(m, M_DONTWAIT) == 0 &&
		    bus_dmamap_load_mbuf(sc->sc_dmat, map, m,
		     BUS_DMA_NOWAIT) == 0)
			break;

		/* FALLTHROUGH */
	default:
		sc->no_tx_dma_setup++;
		return (0);
	}

	bus_dmamap_sync(sc->sc_dmat, map,
	    0, map->dm_mapsize,
	    BUS_DMASYNC_PREWRITE);

	if (sc->hw.mac_type == em_82547) {
		bus_dmamap_sync(sc->sc_dmat, sc->sc_tx_dma.dma_map,
		    0, sc->sc_tx_dma.dma_map->dm_mapsize,
		    BUS_DMASYNC_POSTREAD | BUS_DMASYNC_POSTWRITE);
	}

	if (sc->hw.mac_type >= em_82543 && sc->hw.mac_type != em_82575 &&
	    sc->hw.mac_type != em_82580 && sc->hw.mac_type != em_i210 &&
	    sc->hw.mac_type != em_i350) {
		used += em_transmit_checksum_setup(sc, m, head,
		    &txd_upper, &txd_lower);
	} else {
		txd_upper = txd_lower = 0;
	}

	head += used;
	if (head >= sc->sc_tx_slots)
		head -= sc->sc_tx_slots;

	for (i = 0; i < map->dm_nsegs; i++) {
		/* If sc is 82544 and on PCI-X bus */
		if (sc->pcix_82544) {
			/*
			 * Check the Address and Length combination and
			 * split the data accordingly
			 */
			array_elements = em_fill_descriptors(
			    map->dm_segs[i].ds_addr, map->dm_segs[i].ds_len,
			    &desc_array);
			for (j = 0; j < array_elements; j++) {
				desc = &sc->sc_tx_desc_ring[head];

				desc->buffer_addr = htole64(
					desc_array.descriptor[j].address);
				desc->lower.data = htole32(
					(sc->sc_txd_cmd | txd_lower |
					 (u_int16_t)desc_array.descriptor[j].length));
				desc->upper.data = htole32(txd_upper);

				last = head;
				if (++head == sc->sc_tx_slots)
					head = 0;

				used++;
			}
		} else {
			desc = &sc->sc_tx_desc_ring[head];

			desc->buffer_addr = htole64(map->dm_segs[i].ds_addr);
			desc->lower.data = htole32(sc->sc_txd_cmd |
			    txd_lower | map->dm_segs[i].ds_len);
			desc->upper.data = htole32(txd_upper);

			last = head;
			if (++head == sc->sc_tx_slots)
	        		head = 0;

			used++;
		}
	}

#if NVLAN > 0
	/* Find out if we are in VLAN mode */
	if (m->m_flags & M_VLANTAG) {
		/* Set the VLAN id */
		desc->upper.fields.special = htole16(m->m_pkthdr.ether_vtag);

		/* Tell hardware to add tag */
		desc->lower.data |= htole32(E1000_TXD_CMD_VLE);
	}
#endif

	/* mark the packet with the mbuf and last desc slot */
	pkt->pkt_m = m;
	pkt->pkt_eop = last;

	sc->sc_tx_desc_head = head;

	/* 
	 * Last Descriptor of Packet
	 * needs End Of Packet (EOP)
	 * and Report Status (RS)
	 */
	desc->lower.data |= htole32(E1000_TXD_CMD_EOP | E1000_TXD_CMD_RS);

	if (sc->hw.mac_type == em_82547) {
		bus_dmamap_sync(sc->sc_dmat, sc->sc_tx_dma.dma_map,
		    0, sc->sc_tx_dma.dma_map->dm_mapsize,
		    BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);
	}

	return (used);
}

/*********************************************************************
 *
 * 82547 workaround to avoid controller hang in half-duplex environment.
 * The workaround is to avoid queuing a large packet that would span
 * the internal Tx FIFO ring boundary. We need to reset the FIFO pointers
 * in this case. We do that only when FIFO is quiescent.
 *
 **********************************************************************/
void
em_82547_move_tail_locked(struct em_softc *sc)
{
	uint16_t hw_tdt;
	uint16_t sw_tdt;
	struct em_tx_desc *tx_desc;
	uint16_t length = 0;
	boolean_t eop = 0;

	hw_tdt = E1000_READ_REG(&sc->hw, TDT);
	sw_tdt = sc->sc_tx_desc_head;

	while (hw_tdt != sw_tdt) {
		tx_desc = &sc->sc_tx_desc_ring[hw_tdt];
		length += tx_desc->lower.flags.length;
		eop = tx_desc->lower.data & E1000_TXD_CMD_EOP;
		if (++hw_tdt == sc->sc_tx_slots)
			hw_tdt = 0;

		if (eop) {
			if (em_82547_fifo_workaround(sc, length)) {
				sc->tx_fifo_wrk_cnt++;
				timeout_add(&sc->tx_fifo_timer_handle, 1);
				break;
			}
			E1000_WRITE_REG(&sc->hw, TDT, hw_tdt);
			em_82547_update_fifo_head(sc, length);
			length = 0;
		}
	}
}

void
em_82547_move_tail(void *arg)
{
	struct em_softc *sc = arg;
	int s;

	s = splnet();
	em_82547_move_tail_locked(sc);
	splx(s);
}

int
em_82547_fifo_workaround(struct em_softc *sc, int len)
{
	int fifo_space, fifo_pkt_len;

	fifo_pkt_len = EM_ROUNDUP(len + EM_FIFO_HDR, EM_FIFO_HDR);

	if (sc->link_duplex == HALF_DUPLEX) {
		fifo_space = sc->tx_fifo_size - sc->tx_fifo_head;

		if (fifo_pkt_len >= (EM_82547_PKT_THRESH + fifo_space)) {
			if (em_82547_tx_fifo_reset(sc))
				return (0);
			else
				return (1);
		}
	}

	return (0);
}

void
em_82547_update_fifo_head(struct em_softc *sc, int len)
{
	int fifo_pkt_len = EM_ROUNDUP(len + EM_FIFO_HDR, EM_FIFO_HDR);

	/* tx_fifo_head is always 16 byte aligned */
	sc->tx_fifo_head += fifo_pkt_len;
	if (sc->tx_fifo_head >= sc->tx_fifo_size)
		sc->tx_fifo_head -= sc->tx_fifo_size;
}

int
em_82547_tx_fifo_reset(struct em_softc *sc)
{
	uint32_t tctl;

	if ((E1000_READ_REG(&sc->hw, TDT) ==
	     E1000_READ_REG(&sc->hw, TDH)) &&
	    (E1000_READ_REG(&sc->hw, TDFT) ==
	     E1000_READ_REG(&sc->hw, TDFH)) &&
	    (E1000_READ_REG(&sc->hw, TDFTS) ==
	     E1000_READ_REG(&sc->hw, TDFHS)) &&
	    (E1000_READ_REG(&sc->hw, TDFPC) == 0)) {

		/* Disable TX unit */
		tctl = E1000_READ_REG(&sc->hw, TCTL);
		E1000_WRITE_REG(&sc->hw, TCTL, tctl & ~E1000_TCTL_EN);

		/* Reset FIFO pointers */
		E1000_WRITE_REG(&sc->hw, TDFT, sc->tx_head_addr);
		E1000_WRITE_REG(&sc->hw, TDFH, sc->tx_head_addr);
		E1000_WRITE_REG(&sc->hw, TDFTS, sc->tx_head_addr);
		E1000_WRITE_REG(&sc->hw, TDFHS, sc->tx_head_addr);

		/* Re-enable TX unit */
		E1000_WRITE_REG(&sc->hw, TCTL, tctl);
		E1000_WRITE_FLUSH(&sc->hw);

		sc->tx_fifo_head = 0;
		sc->tx_fifo_reset_cnt++;

		return (TRUE);
	} else
		return (FALSE);
}

void
em_iff(struct em_softc *sc)
{
	struct ifnet *ifp = &sc->sc_ac.ac_if;
	struct arpcom *ac = &sc->sc_ac;
	u_int32_t reg_rctl = 0;
	u_int8_t  mta[MAX_NUM_MULTICAST_ADDRESSES * ETH_LENGTH_OF_ADDRESS];
	struct ether_multi *enm;
	struct ether_multistep step;
	int i = 0;

	IOCTL_DEBUGOUT("em_iff: begin");

	if (sc->hw.mac_type == em_82542_rev2_0) {
		reg_rctl = E1000_READ_REG(&sc->hw, RCTL);
		if (sc->hw.pci_cmd_word & CMD_MEM_WRT_INVALIDATE)
			em_pci_clear_mwi(&sc->hw);
		reg_rctl |= E1000_RCTL_RST;
		E1000_WRITE_REG(&sc->hw, RCTL, reg_rctl);
		msec_delay(5);
	}

	reg_rctl = E1000_READ_REG(&sc->hw, RCTL);
	reg_rctl &= ~(E1000_RCTL_MPE | E1000_RCTL_UPE);
	ifp->if_flags &= ~IFF_ALLMULTI;

	if (ifp->if_flags & IFF_PROMISC || ac->ac_multirangecnt > 0 ||
	    ac->ac_multicnt > MAX_NUM_MULTICAST_ADDRESSES) {
		ifp->if_flags |= IFF_ALLMULTI;
		reg_rctl |= E1000_RCTL_MPE;
		if (ifp->if_flags & IFF_PROMISC)
			reg_rctl |= E1000_RCTL_UPE;
	} else {
		ETHER_FIRST_MULTI(step, ac, enm);
		while (enm != NULL) {
			bcopy(enm->enm_addrlo, mta + i, ETH_LENGTH_OF_ADDRESS);
			i += ETH_LENGTH_OF_ADDRESS;

			ETHER_NEXT_MULTI(step, enm);
		}

		em_mc_addr_list_update(&sc->hw, mta, ac->ac_multicnt, 0, 1);
	}

	E1000_WRITE_REG(&sc->hw, RCTL, reg_rctl);

	if (sc->hw.mac_type == em_82542_rev2_0) {
		reg_rctl = E1000_READ_REG(&sc->hw, RCTL);
		reg_rctl &= ~E1000_RCTL_RST;
		E1000_WRITE_REG(&sc->hw, RCTL, reg_rctl);
		msec_delay(5);
		if (sc->hw.pci_cmd_word & CMD_MEM_WRT_INVALIDATE)
			em_pci_set_mwi(&sc->hw);
	}
}

/*********************************************************************
 *  Timer routine
 *
 *  This routine checks for link status and updates statistics.
 *
 **********************************************************************/

void
em_local_timer(void *arg)
{
	struct ifnet   *ifp;
	struct em_softc *sc = arg;
	int s;

	ifp = &sc->sc_ac.ac_if;

	s = splnet();

#ifndef SMALL_KERNEL
	em_update_stats_counters(sc);
#ifdef EM_DEBUG
	if (ifp->if_flags & IFF_DEBUG && ifp->if_flags & IFF_RUNNING)
		em_print_hw_stats(sc);
#endif
#endif
	em_smartspeed(sc);

	timeout_add_sec(&sc->timer_handle, 1);

	splx(s);
}

void
em_update_link_status(struct em_softc *sc)
{
	struct ifnet *ifp = &sc->sc_ac.ac_if;
	u_char link_state;

	if (E1000_READ_REG(&sc->hw, STATUS) & E1000_STATUS_LU) {
		if (sc->link_active == 0) {
			em_get_speed_and_duplex(&sc->hw,
						&sc->link_speed,
						&sc->link_duplex);
			/* Check if we may set SPEED_MODE bit on PCI-E */
			if ((sc->link_speed == SPEED_1000) &&
			    ((sc->hw.mac_type == em_82571) ||
			    (sc->hw.mac_type == em_82572) ||
			    (sc->hw.mac_type == em_82575) ||
			    (sc->hw.mac_type == em_82580))) {
				int tarc0;

				tarc0 = E1000_READ_REG(&sc->hw, TARC0);
				tarc0 |= SPEED_MODE_BIT;
				E1000_WRITE_REG(&sc->hw, TARC0, tarc0);
			}
			sc->link_active = 1;
			sc->smartspeed = 0;
			ifp->if_baudrate = IF_Mbps(sc->link_speed);
		}
		link_state = (sc->link_duplex == FULL_DUPLEX) ?
		    LINK_STATE_FULL_DUPLEX : LINK_STATE_HALF_DUPLEX;
		if (ifp->if_link_state != link_state) {
			ifp->if_link_state = link_state;
			if_link_state_change(ifp);
		}
	} else {
		if (sc->link_active == 1) {
			ifp->if_baudrate = sc->link_speed = 0;
			sc->link_duplex = 0;
			sc->link_active = 0;
		}
		if (ifp->if_link_state != LINK_STATE_DOWN) {
			ifp->if_link_state = LINK_STATE_DOWN;
			if_link_state_change(ifp);
		}
	}
}

/*********************************************************************
 *
 *  This routine disables all traffic on the adapter by issuing a
 *  global reset on the MAC and deallocates TX/RX buffers. 
 *
 **********************************************************************/

void
em_stop(void *arg, int softonly)
{
	struct em_softc *sc = arg;
	struct ifnet   *ifp = &sc->sc_ac.ac_if;

	/* Tell the stack that the interface is no longer active */
	ifp->if_flags &= ~IFF_RUNNING;

	INIT_DEBUGOUT("em_stop: begin");

	timeout_del(&sc->timer_handle);
	timeout_del(&sc->tx_fifo_timer_handle);

	if (!softonly)
		em_disable_intr(sc);
	if (sc->hw.mac_type == em_pch_spt)
		em_flush_desc_rings(sc);
	if (!softonly)
		em_reset_hw(&sc->hw);

	intr_barrier(sc->sc_intrhand);
	ifq_barrier(&ifp->if_snd);

	KASSERT((ifp->if_flags & IFF_RUNNING) == 0);

	ifq_clr_oactive(&ifp->if_snd);
	ifp->if_timer = 0;

	em_free_transmit_structures(sc);
	em_free_receive_structures(sc);
}

/*********************************************************************
 *
 *  Determine hardware revision.
 *
 **********************************************************************/
void
em_identify_hardware(struct em_softc *sc)
{
	u_int32_t reg;
	struct pci_attach_args *pa = &sc->osdep.em_pa;

	/* Make sure our PCI config space has the necessary stuff set */
	sc->hw.pci_cmd_word = pci_conf_read(pa->pa_pc, pa->pa_tag,
					    PCI_COMMAND_STATUS_REG);

	/* Save off the information about this board */
	sc->hw.vendor_id = PCI_VENDOR(pa->pa_id);
	sc->hw.device_id = PCI_PRODUCT(pa->pa_id);

	reg = pci_conf_read(pa->pa_pc, pa->pa_tag, PCI_CLASS_REG);
	sc->hw.revision_id = PCI_REVISION(reg);

	reg = pci_conf_read(pa->pa_pc, pa->pa_tag, PCI_SUBSYS_ID_REG);
	sc->hw.subsystem_vendor_id = PCI_VENDOR(reg);
	sc->hw.subsystem_id = PCI_PRODUCT(reg);

	/* Identify the MAC */
	if (em_set_mac_type(&sc->hw))
		printf("%s: Unknown MAC Type\n", DEVNAME(sc));

	if (sc->hw.mac_type == em_pchlan)
		sc->hw.revision_id = PCI_PRODUCT(pa->pa_id) & 0x0f;

	if (sc->hw.mac_type == em_82541 ||
	    sc->hw.mac_type == em_82541_rev_2 ||
	    sc->hw.mac_type == em_82547 ||
	    sc->hw.mac_type == em_82547_rev_2)
		sc->hw.phy_init_script = TRUE;
}

void
em_legacy_irq_quirk_spt(struct em_softc *sc)
{
	uint32_t	reg;

	/* Legacy interrupt: SPT needs a quirk. */
	if (sc->hw.mac_type != em_pch_spt)
		return;
	if (sc->legacy_irq == 0)
		return;

	reg = EM_READ_REG(&sc->hw, E1000_FEXTNVM7);
	reg |= E1000_FEXTNVM7_SIDE_CLK_UNGATE;
	EM_WRITE_REG(&sc->hw, E1000_FEXTNVM7, reg);

	reg = EM_READ_REG(&sc->hw, E1000_FEXTNVM9);
	reg |= E1000_FEXTNVM9_IOSFSB_CLKGATE_DIS |
	    E1000_FEXTNVM9_IOSFSB_CLKREQ_DIS;
	EM_WRITE_REG(&sc->hw, E1000_FEXTNVM9, reg);
}

int
em_allocate_pci_resources(struct em_softc *sc)
{
	int		val, rid;
	pci_intr_handle_t	ih;
	const char		*intrstr = NULL;
	struct pci_attach_args *pa = &sc->osdep.em_pa;
	pci_chipset_tag_t	pc = pa->pa_pc;

	val = pci_conf_read(pa->pa_pc, pa->pa_tag, EM_MMBA);
	if (PCI_MAPREG_TYPE(val) != PCI_MAPREG_TYPE_MEM) {
		printf(": mmba is not mem space\n");
		return (ENXIO);
	}
	if (pci_mapreg_map(pa, EM_MMBA, PCI_MAPREG_MEM_TYPE(val), 0,
	    &sc->osdep.mem_bus_space_tag, &sc->osdep.mem_bus_space_handle,
	    &sc->osdep.em_membase, &sc->osdep.em_memsize, 0)) {
		printf(": cannot find mem space\n");
		return (ENXIO);
	}

	switch (sc->hw.mac_type) {
	case em_82544:
	case em_82540:
	case em_82545:
	case em_82546:
	case em_82541:
	case em_82541_rev_2:
		/* Figure out where our I/O BAR is ? */
		for (rid = PCI_MAPREG_START; rid < PCI_MAPREG_END;) {
			val = pci_conf_read(pa->pa_pc, pa->pa_tag, rid);
			if (PCI_MAPREG_TYPE(val) == PCI_MAPREG_TYPE_IO) {
				sc->io_rid = rid;
				break;
			}
			rid += 4;
			if (PCI_MAPREG_MEM_TYPE(val) ==
			    PCI_MAPREG_MEM_TYPE_64BIT)
				rid += 4;	/* skip high bits, too */
		}

		if (pci_mapreg_map(pa, rid, PCI_MAPREG_TYPE_IO, 0,
		    &sc->osdep.io_bus_space_tag, &sc->osdep.io_bus_space_handle,
		    &sc->osdep.em_iobase, &sc->osdep.em_iosize, 0)) {
			printf(": cannot find i/o space\n");
			return (ENXIO);
		}

		sc->hw.io_base = 0;
		break;
	default:
		break;
	}

	sc->osdep.em_flashoffset = 0;
	/* for ICH8 and family we need to find the flash memory */
	if (sc->hw.mac_type == em_pch_spt) {
		sc->osdep.flash_bus_space_tag = sc->osdep.mem_bus_space_tag;
		sc->osdep.flash_bus_space_handle = sc->osdep.mem_bus_space_handle;
		sc->osdep.em_flashbase = 0;
		sc->osdep.em_flashsize = 0;
		sc->osdep.em_flashoffset = 0xe000;
	} else if (IS_ICH8(sc->hw.mac_type)) {
		val = pci_conf_read(pa->pa_pc, pa->pa_tag, EM_FLASH);
		if (PCI_MAPREG_TYPE(val) != PCI_MAPREG_TYPE_MEM) {
			printf(": flash is not mem space\n");
			return (ENXIO);
		}

		if (pci_mapreg_map(pa, EM_FLASH, PCI_MAPREG_MEM_TYPE(val), 0,
		    &sc->osdep.flash_bus_space_tag, &sc->osdep.flash_bus_space_handle,
		    &sc->osdep.em_flashbase, &sc->osdep.em_flashsize, 0)) {
			printf(": cannot find mem space\n");
			return (ENXIO);
		}
        }

	sc->legacy_irq = 0;
	if (pci_intr_map_msi(pa, &ih)) {
		if (pci_intr_map(pa, &ih)) {
			printf(": couldn't map interrupt\n");
			return (ENXIO);
		}
		sc->legacy_irq = 1;
	}

	sc->osdep.dev = (struct device *)sc;
	sc->hw.back = &sc->osdep;

	intrstr = pci_intr_string(pc, ih);
	sc->sc_intrhand = pci_intr_establish(pc, ih, IPL_NET | IPL_MPSAFE,
	    em_intr, sc, DEVNAME(sc));
	if (sc->sc_intrhand == NULL) {
		printf(": couldn't establish interrupt");
		if (intrstr != NULL)
			printf(" at %s", intrstr);
		printf("\n");
		return (ENXIO);
	}
	printf(": %s", intrstr);

	/*
	 * the ICP_xxxx device has multiple, duplicate register sets for
	 * use when it is being used as a network processor. Disable those
	 * registers here, as they are not necessary in this context and
	 * can confuse the system
	 */
	if(sc->hw.mac_type == em_icp_xxxx) {
		int offset;
		pcireg_t val;
		
		if (!pci_get_capability(sc->osdep.em_pa.pa_pc, 
		    sc->osdep.em_pa.pa_tag, PCI_CAP_ID_ST, &offset, &val)) {
			return (0);
		}
		offset += PCI_ST_SMIA_OFFSET;
		pci_conf_write(sc->osdep.em_pa.pa_pc, sc->osdep.em_pa.pa_tag,
		    offset, 0x06);
		E1000_WRITE_REG(&sc->hw, IMC1, ~0x0);
		E1000_WRITE_REG(&sc->hw, IMC2, ~0x0);
	}
	return (0);
}

void
em_free_pci_resources(struct em_softc *sc)
{
	struct pci_attach_args *pa = &sc->osdep.em_pa;
	pci_chipset_tag_t	pc = pa->pa_pc;

	if (sc->sc_intrhand)
		pci_intr_disestablish(pc, sc->sc_intrhand);
	sc->sc_intrhand = 0;

	if (sc->osdep.em_flashbase)
		bus_space_unmap(sc->osdep.flash_bus_space_tag, sc->osdep.flash_bus_space_handle,
				sc->osdep.em_flashsize);
	sc->osdep.em_flashbase = 0;

	if (sc->osdep.em_iobase)
		bus_space_unmap(sc->osdep.io_bus_space_tag, sc->osdep.io_bus_space_handle,
				sc->osdep.em_iosize);
	sc->osdep.em_iobase = 0;

	if (sc->osdep.em_membase)
		bus_space_unmap(sc->osdep.mem_bus_space_tag, sc->osdep.mem_bus_space_handle,
				sc->osdep.em_memsize);
	sc->osdep.em_membase = 0;
}

/*********************************************************************
 *
 *  Initialize the hardware to a configuration as specified by the
 *  em_softc structure. The controller is reset, the EEPROM is
 *  verified, the MAC address is set, then the shared initialization
 *  routines are called.
 *
 **********************************************************************/
int
em_hardware_init(struct em_softc *sc)
{
	uint32_t ret_val;
	u_int16_t rx_buffer_size;

	INIT_DEBUGOUT("em_hardware_init: begin");
	if (sc->hw.mac_type == em_pch_spt)
		em_flush_desc_rings(sc);
	/* Issue a global reset */
	em_reset_hw(&sc->hw);

	/* When hardware is reset, fifo_head is also reset */
	sc->tx_fifo_head = 0;

	/* Make sure we have a good EEPROM before we read from it */
	if (em_get_flash_presence_i210(&sc->hw) &&
	    em_validate_eeprom_checksum(&sc->hw) < 0) {
		/*
		 * Some PCIe parts fail the first check due to
		 * the link being in sleep state, call it again,
		 * if it fails a second time its a real issue.
		 */
		if (em_validate_eeprom_checksum(&sc->hw) < 0) {
			printf("%s: The EEPROM Checksum Is Not Valid\n",
			       DEVNAME(sc));
			return (EIO);
		}
	}

	if (em_get_flash_presence_i210(&sc->hw) &&
	    em_read_part_num(&sc->hw, &(sc->part_num)) < 0) {
		printf("%s: EEPROM read error while reading part number\n",
		       DEVNAME(sc));
		return (EIO);
	}

	/* Set up smart power down as default off on newer adapters */
	if (!em_smart_pwr_down &&
	     (sc->hw.mac_type == em_82571 ||
	      sc->hw.mac_type == em_82572 ||
	      sc->hw.mac_type == em_82575 ||
	      sc->hw.mac_type == em_82580 ||
	      sc->hw.mac_type == em_i210 ||
	      sc->hw.mac_type == em_i350 )) {
		uint16_t phy_tmp = 0;

		/* Speed up time to link by disabling smart power down */
		em_read_phy_reg(&sc->hw, IGP02E1000_PHY_POWER_MGMT, &phy_tmp);
		phy_tmp &= ~IGP02E1000_PM_SPD;
		em_write_phy_reg(&sc->hw, IGP02E1000_PHY_POWER_MGMT, phy_tmp);
	}

	em_legacy_irq_quirk_spt(sc);

	/*
	 * These parameters control the automatic generation (Tx) and 
	 * response (Rx) to Ethernet PAUSE frames.
	 * - High water mark should allow for at least two frames to be
	 *   received after sending an XOFF.
	 * - Low water mark works best when it is very near the high water mark.
	 *   This allows the receiver to restart by sending XON when it has
	 *   drained a bit.  Here we use an arbitary value of 1500 which will
	 *   restart after one full frame is pulled from the buffer.  There
	 *   could be several smaller frames in the buffer and if so they will
	 *   not trigger the XON until their total number reduces the buffer
	 *   by 1500.
	 * - The pause time is fairly large at 1000 x 512ns = 512 usec.
	 */
	rx_buffer_size = ((E1000_READ_REG(&sc->hw, PBA) & 0xffff) << 10 );

	sc->hw.fc_high_water = rx_buffer_size -
	    EM_ROUNDUP(sc->hw.max_frame_size, 1024);
	sc->hw.fc_low_water = sc->hw.fc_high_water - 1500;
	if (sc->hw.mac_type == em_80003es2lan)
		sc->hw.fc_pause_time = 0xFFFF;
	else
		sc->hw.fc_pause_time = 1000;
	sc->hw.fc_send_xon = TRUE;
	sc->hw.fc = E1000_FC_FULL;

	em_disable_aspm(sc);

	if ((ret_val = em_init_hw(&sc->hw)) != 0) {
		if (ret_val == E1000_DEFER_INIT) {
			INIT_DEBUGOUT("\nHardware Initialization Deferred ");
			return (EAGAIN);
		}
		printf("\n%s: Hardware Initialization Failed\n",
		       DEVNAME(sc));
		return (EIO);
	}

	em_check_for_link(&sc->hw);

	return (0);
}

/*********************************************************************
 *
 *  Setup networking device structure and register an interface.
 *
 **********************************************************************/
void
em_setup_interface(struct em_softc *sc)
{
	struct ifnet   *ifp;
	uint64_t fiber_type = IFM_1000_SX;

	INIT_DEBUGOUT("em_setup_interface: begin");

	ifp = &sc->sc_ac.ac_if;
	strlcpy(ifp->if_xname, DEVNAME(sc), IFNAMSIZ);
	ifp->if_softc = sc;
	ifp->if_flags = IFF_BROADCAST | IFF_SIMPLEX | IFF_MULTICAST;
	ifp->if_xflags = IFXF_MPSAFE;
	ifp->if_ioctl = em_ioctl;
	ifp->if_qstart = em_start;
	ifp->if_watchdog = em_watchdog;
	ifp->if_hardmtu =
		sc->hw.max_frame_size - ETHER_HDR_LEN - ETHER_CRC_LEN;
	IFQ_SET_MAXLEN(&ifp->if_snd, sc->sc_tx_slots - 1);

	ifp->if_capabilities = IFCAP_VLAN_MTU;

#if NVLAN > 0
	if (sc->hw.mac_type != em_82575 && sc->hw.mac_type != em_82580 &&
	    sc->hw.mac_type != em_i210 && sc->hw.mac_type != em_i350)
		ifp->if_capabilities |= IFCAP_VLAN_HWTAGGING;
#endif

	if (sc->hw.mac_type >= em_82543 && sc->hw.mac_type != em_82575 &&
	    sc->hw.mac_type != em_82580 && sc->hw.mac_type != em_i210 &&
	    sc->hw.mac_type != em_i350)
		ifp->if_capabilities |= IFCAP_CSUM_TCPv4 | IFCAP_CSUM_UDPv4;

	/* 
	 * Specify the media types supported by this adapter and register
	 * callbacks to update media and link information
	 */
	ifmedia_init(&sc->media, IFM_IMASK, em_media_change,
		     em_media_status);
	if (sc->hw.media_type == em_media_type_fiber ||
	    sc->hw.media_type == em_media_type_internal_serdes) {
		if (sc->hw.mac_type == em_82545)
			fiber_type = IFM_1000_LX;
		ifmedia_add(&sc->media, IFM_ETHER | fiber_type | IFM_FDX, 
			    0, NULL);
		ifmedia_add(&sc->media, IFM_ETHER | fiber_type, 
			    0, NULL);
	} else {
		ifmedia_add(&sc->media, IFM_ETHER | IFM_10_T, 0, NULL);
		ifmedia_add(&sc->media, IFM_ETHER | IFM_10_T | IFM_FDX, 
			    0, NULL);
		ifmedia_add(&sc->media, IFM_ETHER | IFM_100_TX, 
			    0, NULL);
		ifmedia_add(&sc->media, IFM_ETHER | IFM_100_TX | IFM_FDX, 
			    0, NULL);
		if (sc->hw.phy_type != em_phy_ife) {
			ifmedia_add(&sc->media, IFM_ETHER | IFM_1000_T | IFM_FDX, 
				    0, NULL);
			ifmedia_add(&sc->media, IFM_ETHER | IFM_1000_T, 0, NULL);
		}
	}
	ifmedia_add(&sc->media, IFM_ETHER | IFM_AUTO, 0, NULL);
	ifmedia_set(&sc->media, IFM_ETHER | IFM_AUTO);

	if_attach(ifp);
	ether_ifattach(ifp);
}

int
em_detach(struct device *self, int flags)
{
	struct em_softc *sc = (struct em_softc *)self;
	struct ifnet *ifp = &sc->sc_ac.ac_if;
	struct pci_attach_args *pa = &sc->osdep.em_pa;
	pci_chipset_tag_t	pc = pa->pa_pc;

	if (sc->sc_intrhand)
		pci_intr_disestablish(pc, sc->sc_intrhand);
	sc->sc_intrhand = 0;

	em_stop(sc, 1);

	em_free_pci_resources(sc);

	if (sc->sc_rx_desc_ring != NULL) {
		sc->sc_rx_desc_ring = NULL;
		em_dma_free(sc, &sc->sc_rx_dma);
	}
	if (sc->sc_tx_desc_ring != NULL) {
		sc->sc_tx_desc_ring = NULL;
		em_dma_free(sc, &sc->sc_tx_dma);
	}

	ether_ifdetach(ifp);
	if_detach(ifp);

	return (0);
}

int
em_activate(struct device *self, int act)
{
	struct em_softc *sc = (struct em_softc *)self;
	struct ifnet *ifp = &sc->sc_ac.ac_if;
	int rv = 0;

	switch (act) {
	case DVACT_SUSPEND:
		if (ifp->if_flags & IFF_RUNNING)
			em_stop(sc, 0);
		/* We have no children atm, but we will soon */
		rv = config_activate_children(self, act);
		break;
	case DVACT_RESUME:
		if (ifp->if_flags & IFF_UP)
			em_init(sc);
		break;
	default:
		rv = config_activate_children(self, act);
		break;
	}
	return (rv);
}

/*********************************************************************
 *
 *  Workaround for SmartSpeed on 82541 and 82547 controllers
 *
 **********************************************************************/	
void
em_smartspeed(struct em_softc *sc)
{
	uint16_t phy_tmp;
 
	if (sc->link_active || (sc->hw.phy_type != em_phy_igp) || 
	    !sc->hw.autoneg || !(sc->hw.autoneg_advertised & ADVERTISE_1000_FULL))
		return;

	if (sc->smartspeed == 0) {
		/* If Master/Slave config fault is asserted twice,
		 * we assume back-to-back */
		em_read_phy_reg(&sc->hw, PHY_1000T_STATUS, &phy_tmp);
		if (!(phy_tmp & SR_1000T_MS_CONFIG_FAULT))
			return;
		em_read_phy_reg(&sc->hw, PHY_1000T_STATUS, &phy_tmp);
		if (phy_tmp & SR_1000T_MS_CONFIG_FAULT) {
			em_read_phy_reg(&sc->hw, PHY_1000T_CTRL,
					&phy_tmp);
			if (phy_tmp & CR_1000T_MS_ENABLE) {
				phy_tmp &= ~CR_1000T_MS_ENABLE;
				em_write_phy_reg(&sc->hw,
						    PHY_1000T_CTRL, phy_tmp);
				sc->smartspeed++;
				if (sc->hw.autoneg &&
				    !em_phy_setup_autoneg(&sc->hw) &&
				    !em_read_phy_reg(&sc->hw, PHY_CTRL,
						       &phy_tmp)) {
					phy_tmp |= (MII_CR_AUTO_NEG_EN |  
						    MII_CR_RESTART_AUTO_NEG);
					em_write_phy_reg(&sc->hw,
							 PHY_CTRL, phy_tmp);
				}
			}
		}
		return;
	} else if (sc->smartspeed == EM_SMARTSPEED_DOWNSHIFT) {
		/* If still no link, perhaps using 2/3 pair cable */
		em_read_phy_reg(&sc->hw, PHY_1000T_CTRL, &phy_tmp);
		phy_tmp |= CR_1000T_MS_ENABLE;
		em_write_phy_reg(&sc->hw, PHY_1000T_CTRL, phy_tmp);
		if (sc->hw.autoneg &&
		    !em_phy_setup_autoneg(&sc->hw) &&
		    !em_read_phy_reg(&sc->hw, PHY_CTRL, &phy_tmp)) {
			phy_tmp |= (MII_CR_AUTO_NEG_EN |
				    MII_CR_RESTART_AUTO_NEG);
			em_write_phy_reg(&sc->hw, PHY_CTRL, phy_tmp);
		}
	}
	/* Restart process after EM_SMARTSPEED_MAX iterations */
	if (sc->smartspeed++ == EM_SMARTSPEED_MAX)
		sc->smartspeed = 0;
}

/*
 * Manage DMA'able memory.
 */
int
em_dma_malloc(struct em_softc *sc, bus_size_t size, struct em_dma_alloc *dma)
{
	int r;

	r = bus_dmamap_create(sc->sc_dmat, size, 1,
	    size, 0, BUS_DMA_WAITOK | BUS_DMA_ALLOCNOW, &dma->dma_map);
	if (r != 0)
		return (r);

	r = bus_dmamem_alloc(sc->sc_dmat, size, PAGE_SIZE, 0, &dma->dma_seg,
	    1, &dma->dma_nseg, BUS_DMA_WAITOK | BUS_DMA_ZERO);
	if (r != 0)
		goto destroy;

	r = bus_dmamem_map(sc->sc_dmat, &dma->dma_seg, dma->dma_nseg, size,
	    &dma->dma_vaddr, BUS_DMA_WAITOK);
	if (r != 0)
		goto free;

	r = bus_dmamap_load(sc->sc_dmat, dma->dma_map, dma->dma_vaddr, size,
	    NULL, BUS_DMA_WAITOK);
	if (r != 0)
		goto unmap;

	dma->dma_size = size;
	return (0);

unmap:
	bus_dmamem_unmap(sc->sc_dmat, dma->dma_vaddr, size);
free:
	bus_dmamem_free(sc->sc_dmat, &dma->dma_seg, dma->dma_nseg);
destroy:
	bus_dmamap_destroy(sc->sc_dmat, dma->dma_map);

	return (r);
}

void
em_dma_free(struct em_softc *sc, struct em_dma_alloc *dma)
{
	bus_dmamap_unload(sc->sc_dmat, dma->dma_map);
	bus_dmamem_unmap(sc->sc_dmat, dma->dma_vaddr, dma->dma_size);
	bus_dmamem_free(sc->sc_dmat, &dma->dma_seg, dma->dma_nseg);
	bus_dmamap_destroy(sc->sc_dmat, dma->dma_map);
}

/*********************************************************************
 *
 *  Allocate memory for tx_buffer structures. The tx_buffer stores all
 *  the information needed to transmit a packet on the wire.
 *
 **********************************************************************/
int
em_allocate_transmit_structures(struct em_softc *sc)
{
	bus_dmamap_sync(sc->sc_dmat, sc->sc_tx_dma.dma_map,
	    0, sc->sc_tx_dma.dma_map->dm_mapsize,
	    BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);

	sc->sc_tx_pkts_ring = mallocarray(sc->sc_tx_slots,
	    sizeof(*sc->sc_tx_pkts_ring), M_DEVBUF, M_NOWAIT | M_ZERO);
	if (sc->sc_tx_pkts_ring == NULL) {
		printf("%s: Unable to allocate tx_buffer memory\n", 
		       DEVNAME(sc));
		return (ENOMEM);
	}

	return (0);
}

/*********************************************************************
 *
 *  Allocate and initialize transmit structures. 
 *
 **********************************************************************/
int
em_setup_transmit_structures(struct em_softc *sc)
{
	struct em_packet *pkt;
	int error, i;

	if ((error = em_allocate_transmit_structures(sc)) != 0)
		goto fail;

	bzero((void *) sc->sc_tx_desc_ring,
	      (sizeof(struct em_tx_desc)) * sc->sc_tx_slots);

	for (i = 0; i < sc->sc_tx_slots; i++) {
		pkt = &sc->sc_tx_pkts_ring[i];
		error = bus_dmamap_create(sc->sc_dmat, MAX_JUMBO_FRAME_SIZE,
		    EM_MAX_SCATTER / (sc->pcix_82544 ? 2 : 1),
		    MAX_JUMBO_FRAME_SIZE, 0, BUS_DMA_NOWAIT, &pkt->pkt_map);
		if (error != 0) {
			printf("%s: Unable to create TX DMA map\n",
			    DEVNAME(sc));
			goto fail;
		}
	}

	sc->sc_tx_desc_head = 0;
	sc->sc_tx_desc_tail = 0;

	/* Set checksum context */
	sc->active_checksum_context = OFFLOAD_NONE;

	return (0);

fail:
	em_free_transmit_structures(sc);
	return (error);
}

/*********************************************************************
 *
 *  Enable transmit unit.
 *
 **********************************************************************/
void
em_initialize_transmit_unit(struct em_softc *sc)
{
	u_int32_t	reg_tctl, reg_tipg = 0;
	u_int64_t	bus_addr;

	INIT_DEBUGOUT("em_initialize_transmit_unit: begin");

	/* Setup the Base and Length of the Tx Descriptor Ring */
	bus_addr = sc->sc_tx_dma.dma_map->dm_segs[0].ds_addr;
	E1000_WRITE_REG(&sc->hw, TDLEN, 
			sc->sc_tx_slots *
			sizeof(struct em_tx_desc));
	E1000_WRITE_REG(&sc->hw, TDBAH, (u_int32_t)(bus_addr >> 32));
	E1000_WRITE_REG(&sc->hw, TDBAL, (u_int32_t)bus_addr);

	/* Setup the HW Tx Head and Tail descriptor pointers */
	E1000_WRITE_REG(&sc->hw, TDT, 0);
	E1000_WRITE_REG(&sc->hw, TDH, 0);

	HW_DEBUGOUT2("Base = %x, Length = %x\n", 
		     E1000_READ_REG(&sc->hw, TDBAL),
		     E1000_READ_REG(&sc->hw, TDLEN));

	/* Set the default values for the Tx Inter Packet Gap timer */
	switch (sc->hw.mac_type) {
	case em_82542_rev2_0:
	case em_82542_rev2_1:
		reg_tipg = DEFAULT_82542_TIPG_IPGT;
		reg_tipg |= DEFAULT_82542_TIPG_IPGR1 << E1000_TIPG_IPGR1_SHIFT;
		reg_tipg |= DEFAULT_82542_TIPG_IPGR2 << E1000_TIPG_IPGR2_SHIFT;
		break;
	case em_80003es2lan:
		reg_tipg = DEFAULT_82543_TIPG_IPGR1;
		reg_tipg |= DEFAULT_80003ES2LAN_TIPG_IPGR2 << E1000_TIPG_IPGR2_SHIFT;
		break;
	default:
		if (sc->hw.media_type == em_media_type_fiber ||
		    sc->hw.media_type == em_media_type_internal_serdes)
			reg_tipg = DEFAULT_82543_TIPG_IPGT_FIBER;
		else
			reg_tipg = DEFAULT_82543_TIPG_IPGT_COPPER;
		reg_tipg |= DEFAULT_82543_TIPG_IPGR1 << E1000_TIPG_IPGR1_SHIFT;
		reg_tipg |= DEFAULT_82543_TIPG_IPGR2 << E1000_TIPG_IPGR2_SHIFT;
	}


	E1000_WRITE_REG(&sc->hw, TIPG, reg_tipg);
	E1000_WRITE_REG(&sc->hw, TIDV, sc->tx_int_delay);
	if (sc->hw.mac_type >= em_82540)
		E1000_WRITE_REG(&sc->hw, TADV, sc->tx_abs_int_delay);

	/* Setup Transmit Descriptor Base Settings */   
	sc->sc_txd_cmd = E1000_TXD_CMD_IFCS;

	if (sc->hw.mac_type == em_82575 || sc->hw.mac_type == em_82580 ||
	    sc->hw.mac_type == em_i210 || sc->hw.mac_type == em_i350) {
		/* 82575/6 need to enable the TX queue and lack the IDE bit */
		reg_tctl = E1000_READ_REG(&sc->hw, TXDCTL);
		reg_tctl |= E1000_TXDCTL_QUEUE_ENABLE;
		E1000_WRITE_REG(&sc->hw, TXDCTL, reg_tctl);
	} else if (sc->tx_int_delay > 0)
		sc->sc_txd_cmd |= E1000_TXD_CMD_IDE;

	/* Program the Transmit Control Register */
	reg_tctl = E1000_TCTL_PSP | E1000_TCTL_EN |
		   (E1000_COLLISION_THRESHOLD << E1000_CT_SHIFT);
	if (sc->hw.mac_type >= em_82571)
		reg_tctl |= E1000_TCTL_MULR;
	if (sc->link_duplex == FULL_DUPLEX)
		reg_tctl |= E1000_FDX_COLLISION_DISTANCE << E1000_COLD_SHIFT;
	else
		reg_tctl |= E1000_HDX_COLLISION_DISTANCE << E1000_COLD_SHIFT;
	/* This write will effectively turn on the transmit unit */
	E1000_WRITE_REG(&sc->hw, TCTL, reg_tctl);

	/* SPT Si errata workaround to avoid data corruption */

	if (sc->hw.mac_type == em_pch_spt) {
		uint32_t	reg_val;

		reg_val = EM_READ_REG(&sc->hw, E1000_IOSFPC);
		reg_val |= E1000_RCTL_RDMTS_HEX;
		EM_WRITE_REG(&sc->hw, E1000_IOSFPC, reg_val);

		reg_val = E1000_READ_REG(&sc->hw, TARC0);
		reg_val |= E1000_TARC0_CB_MULTIQ_3_REQ;
		E1000_WRITE_REG(&sc->hw, TARC0, reg_val);
	}
}

/*********************************************************************
 *
 *  Free all transmit related data structures.
 *
 **********************************************************************/
void
em_free_transmit_structures(struct em_softc *sc)
{
	struct em_packet *pkt;
	int i;

	INIT_DEBUGOUT("free_transmit_structures: begin");

	if (sc->sc_tx_pkts_ring != NULL) {
		for (i = 0; i < sc->sc_tx_slots; i++) {
			pkt = &sc->sc_tx_pkts_ring[i];

			if (pkt->pkt_m != NULL) {
				bus_dmamap_sync(sc->sc_dmat, pkt->pkt_map,
				    0, pkt->pkt_map->dm_mapsize,
				    BUS_DMASYNC_POSTWRITE);
				bus_dmamap_unload(sc->sc_dmat, pkt->pkt_map);

				m_freem(pkt->pkt_m);
				pkt->pkt_m = NULL;
			}

			if (pkt->pkt_map != NULL) {
				bus_dmamap_destroy(sc->sc_dmat, pkt->pkt_map);
				pkt->pkt_map = NULL;
			}
		}

		free(sc->sc_tx_pkts_ring, M_DEVBUF,
		    sc->sc_tx_slots * sizeof(*sc->sc_tx_pkts_ring));
		sc->sc_tx_pkts_ring = NULL;
	}

	bus_dmamap_sync(sc->sc_dmat, sc->sc_tx_dma.dma_map,
	    0, sc->sc_tx_dma.dma_map->dm_mapsize,
	    BUS_DMASYNC_POSTREAD | BUS_DMASYNC_POSTWRITE);
}

/*********************************************************************
 *
 *  The offload context needs to be set when we transfer the first
 *  packet of a particular protocol (TCP/UDP). We change the
 *  context only if the protocol type changes.
 *
 **********************************************************************/
u_int
em_transmit_checksum_setup(struct em_softc *sc, struct mbuf *mp, u_int head,
    u_int32_t *txd_upper, u_int32_t *txd_lower)
{
	struct em_context_desc *TXD;

	if (mp->m_pkthdr.csum_flags & M_TCP_CSUM_OUT) {
		*txd_upper = E1000_TXD_POPTS_TXSM << 8;
		*txd_lower = E1000_TXD_CMD_DEXT | E1000_TXD_DTYP_D;
		if (sc->active_checksum_context == OFFLOAD_TCP_IP)
			return (0);
		else
			sc->active_checksum_context = OFFLOAD_TCP_IP;
	} else if (mp->m_pkthdr.csum_flags & M_UDP_CSUM_OUT) {
		*txd_upper = E1000_TXD_POPTS_TXSM << 8;
		*txd_lower = E1000_TXD_CMD_DEXT | E1000_TXD_DTYP_D;
		if (sc->active_checksum_context == OFFLOAD_UDP_IP)
			return (0);
		else
			sc->active_checksum_context = OFFLOAD_UDP_IP;
	} else {
		*txd_upper = 0;
		*txd_lower = 0;
		return (0);
	}

	/* If we reach this point, the checksum offload context
	 * needs to be reset.
	 */
	TXD = (struct em_context_desc *)&sc->sc_tx_desc_ring[head];

	TXD->lower_setup.ip_fields.ipcss = ETHER_HDR_LEN;
	TXD->lower_setup.ip_fields.ipcso = 
	    ETHER_HDR_LEN + offsetof(struct ip, ip_sum);
	TXD->lower_setup.ip_fields.ipcse = 
	    htole16(ETHER_HDR_LEN + sizeof(struct ip) - 1);

	TXD->upper_setup.tcp_fields.tucss = 
	    ETHER_HDR_LEN + sizeof(struct ip);
	TXD->upper_setup.tcp_fields.tucse = htole16(0);

	if (sc->active_checksum_context == OFFLOAD_TCP_IP) {
		TXD->upper_setup.tcp_fields.tucso = 
		    ETHER_HDR_LEN + sizeof(struct ip) + 
		    offsetof(struct tcphdr, th_sum);
	} else if (sc->active_checksum_context == OFFLOAD_UDP_IP) {
		TXD->upper_setup.tcp_fields.tucso = 
		    ETHER_HDR_LEN + sizeof(struct ip) + 
		    offsetof(struct udphdr, uh_sum);
	}

	TXD->tcp_seg_setup.data = htole32(0);
	TXD->cmd_and_length = htole32(sc->sc_txd_cmd | E1000_TXD_CMD_DEXT);

	return (1);
}

/**********************************************************************
 *
 *  Examine each tx_buffer in the used queue. If the hardware is done
 *  processing the packet then free associated resources. The
 *  tx_buffer is put back on the free queue. 
 *
 **********************************************************************/
void
em_txeof(struct em_softc *sc)
{
	struct ifnet *ifp = &sc->sc_ac.ac_if;
	struct em_packet *pkt;
	struct em_tx_desc *desc;
	u_int head, tail;
	u_int free = 0;

	head = sc->sc_tx_desc_head;
	tail = sc->sc_tx_desc_tail;

	if (head == tail)
		return;

	bus_dmamap_sync(sc->sc_dmat, sc->sc_tx_dma.dma_map,
	    0, sc->sc_tx_dma.dma_map->dm_mapsize,
	    BUS_DMASYNC_POSTREAD);

	do {
		pkt = &sc->sc_tx_pkts_ring[tail];
		desc = &sc->sc_tx_desc_ring[pkt->pkt_eop];

		if (!ISSET(desc->upper.fields.status, E1000_TXD_STAT_DD))
			break;

		bus_dmamap_sync(sc->sc_dmat, pkt->pkt_map,
		    0, pkt->pkt_map->dm_mapsize,
		    BUS_DMASYNC_POSTWRITE);
		bus_dmamap_unload(sc->sc_dmat, pkt->pkt_map);

		KASSERT(pkt->pkt_m != NULL);

		m_freem(pkt->pkt_m);
		pkt->pkt_m = NULL;

		tail = pkt->pkt_eop;

		if (++tail == sc->sc_tx_slots)
			tail = 0;

		free++;
	} while (tail != head);

	bus_dmamap_sync(sc->sc_dmat, sc->sc_tx_dma.dma_map,
	    0, sc->sc_tx_dma.dma_map->dm_mapsize,
	    BUS_DMASYNC_PREREAD);

	if (free == 0)
		return;

	sc->sc_tx_desc_tail = tail;

	if (ifq_is_oactive(&ifp->if_snd))
		ifq_restart(&ifp->if_snd);
	else if (tail == head)
		ifp->if_timer = 0;
}

/*********************************************************************
 *
 *  Get a buffer from system mbuf buffer pool.
 *
 **********************************************************************/
int
em_get_buf(struct em_softc *sc, int i)
{
	struct mbuf    *m;
	struct em_packet *pkt;
	struct em_rx_desc *desc;
	int error;

	pkt = &sc->sc_rx_pkts_ring[i];
	desc = &sc->sc_rx_desc_ring[i];

	KASSERT(pkt->pkt_m == NULL);

	m = MCLGETI(NULL, M_DONTWAIT, NULL, EM_MCLBYTES);
	if (m == NULL) {
		sc->mbuf_cluster_failed++;
		return (ENOBUFS);
	}
	m->m_len = m->m_pkthdr.len = EM_MCLBYTES;
	m_adj(m, ETHER_ALIGN);

	error = bus_dmamap_load_mbuf(sc->sc_dmat, pkt->pkt_map,
	    m, BUS_DMA_NOWAIT);
	if (error) {
		m_freem(m);
		return (error);
	}

	bus_dmamap_sync(sc->sc_dmat, pkt->pkt_map,
	    0, pkt->pkt_map->dm_mapsize,
	    BUS_DMASYNC_PREREAD);
	pkt->pkt_m = m;

	memset(desc, 0, sizeof(*desc));
	htolem64(&desc->buffer_addr, pkt->pkt_map->dm_segs[0].ds_addr);

	return (0);
}

/*********************************************************************
 *
 *  Allocate memory for rx_buffer structures. Since we use one 
 *  rx_buffer per received packet, the maximum number of rx_buffer's 
 *  that we'll need is equal to the number of receive descriptors 
 *  that we've allocated.
 *
 **********************************************************************/
int
em_allocate_receive_structures(struct em_softc *sc)
{
	struct em_packet *pkt;
	int i;
	int error;

	sc->sc_rx_pkts_ring = mallocarray(sc->sc_rx_slots,
	    sizeof(*sc->sc_rx_pkts_ring), M_DEVBUF, M_NOWAIT | M_ZERO);
	if (sc->sc_rx_pkts_ring == NULL) {
		printf("%s: Unable to allocate rx_buffer memory\n", 
		    DEVNAME(sc));
		return (ENOMEM);
	}

	bus_dmamap_sync(sc->sc_dmat, sc->sc_rx_dma.dma_map,
	    0, sc->sc_rx_dma.dma_map->dm_mapsize,
	    BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);

	for (i = 0; i < sc->sc_rx_slots; i++) {
		pkt = &sc->sc_rx_pkts_ring[i];

		error = bus_dmamap_create(sc->sc_dmat, EM_MCLBYTES, 1,
		    EM_MCLBYTES, 0, BUS_DMA_NOWAIT, &pkt->pkt_map);
		if (error != 0) {
			printf("%s: em_allocate_receive_structures: "
			    "bus_dmamap_create failed; error %u\n",
			    DEVNAME(sc), error);
			goto fail;
		}

		pkt->pkt_m = NULL;
	}

        return (0);

fail:
	em_free_receive_structures(sc);
	return (error);
}

/*********************************************************************
 *
 *  Allocate and initialize receive structures.
 *  
 **********************************************************************/
int
em_setup_receive_structures(struct em_softc *sc)
{
	struct ifnet *ifp = &sc->sc_ac.ac_if;
	u_int lwm;

	memset(sc->sc_rx_desc_ring, 0,
	    sc->sc_rx_slots * sizeof(*sc->sc_rx_desc_ring));

	if (em_allocate_receive_structures(sc))
		return (ENOMEM);

	/* Setup our descriptor pointers */
	sc->sc_rx_desc_tail = 0;
	sc->sc_rx_desc_head = sc->sc_rx_slots - 1;

	lwm = max(4, 2 * ((ifp->if_hardmtu / MCLBYTES) + 1));
	if_rxr_init(&sc->sc_rx_ring, lwm, sc->sc_rx_slots);

	if (em_rxfill(sc) == 0) {
		printf("%s: unable to fill any rx descriptors\n",
		    DEVNAME(sc));
	}

	return (0);
}

/*********************************************************************
 *
 *  Enable receive unit.
 *  
 **********************************************************************/
void
em_initialize_receive_unit(struct em_softc *sc)
{
	u_int32_t	reg_rctl;
	u_int32_t	reg_rxcsum;
	u_int64_t	bus_addr;

	INIT_DEBUGOUT("em_initialize_receive_unit: begin");

	/* Make sure receives are disabled while setting up the descriptor ring */
	E1000_WRITE_REG(&sc->hw, RCTL, 0);

	/* Set the Receive Delay Timer Register */
	E1000_WRITE_REG(&sc->hw, RDTR, 
			sc->rx_int_delay | E1000_RDT_FPDB);

	if (sc->hw.mac_type >= em_82540) {
		if (sc->rx_int_delay)
			E1000_WRITE_REG(&sc->hw, RADV, sc->rx_abs_int_delay);

		/* Set the interrupt throttling rate.  Value is calculated
		 * as DEFAULT_ITR = 1/(MAX_INTS_PER_SEC * 256ns) */
		E1000_WRITE_REG(&sc->hw, ITR, DEFAULT_ITR);
	}

	/* Setup the Base and Length of the Rx Descriptor Ring */
	bus_addr = sc->sc_rx_dma.dma_map->dm_segs[0].ds_addr;
	E1000_WRITE_REG(&sc->hw, RDLEN,
	    sc->sc_rx_slots * sizeof(*sc->sc_rx_desc_ring));
	E1000_WRITE_REG(&sc->hw, RDBAH, (u_int32_t)(bus_addr >> 32));
	E1000_WRITE_REG(&sc->hw, RDBAL, (u_int32_t)bus_addr);

	/* Setup the Receive Control Register */
	reg_rctl = E1000_RCTL_EN | E1000_RCTL_BAM | E1000_RCTL_LBM_NO |
	    E1000_RCTL_RDMTS_HALF |
	    (sc->hw.mc_filter_type << E1000_RCTL_MO_SHIFT);

	if (sc->hw.tbi_compatibility_on == TRUE)
		reg_rctl |= E1000_RCTL_SBP;

	/*
	 * The i350 has a bug where it always strips the CRC whether
	 * asked to or not.  So ask for stripped CRC here and
	 * cope in rxeof
	 */
	if (sc->hw.mac_type == em_i210 || sc->hw.mac_type == em_i350)
		reg_rctl |= E1000_RCTL_SECRC;

	switch (sc->sc_rx_buffer_len) {
	default:
	case EM_RXBUFFER_2048:
		reg_rctl |= E1000_RCTL_SZ_2048;
		break;
	case EM_RXBUFFER_4096:
		reg_rctl |= E1000_RCTL_SZ_4096|E1000_RCTL_BSEX|E1000_RCTL_LPE;
		break;		  
	case EM_RXBUFFER_8192:
		reg_rctl |= E1000_RCTL_SZ_8192|E1000_RCTL_BSEX|E1000_RCTL_LPE;
		break;
	case EM_RXBUFFER_16384:
		reg_rctl |= E1000_RCTL_SZ_16384|E1000_RCTL_BSEX|E1000_RCTL_LPE;
		break;
	}

	if (sc->hw.max_frame_size != ETHER_MAX_LEN)
		reg_rctl |= E1000_RCTL_LPE;

	/* Enable 82543 Receive Checksum Offload for TCP and UDP */
	if (sc->hw.mac_type >= em_82543) {
		reg_rxcsum = E1000_READ_REG(&sc->hw, RXCSUM);
		reg_rxcsum |= (E1000_RXCSUM_IPOFL | E1000_RXCSUM_TUOFL);
		E1000_WRITE_REG(&sc->hw, RXCSUM, reg_rxcsum);
	}

	/*
	 * XXX TEMPORARY WORKAROUND: on some systems with 82573
	 * long latencies are observed, like Lenovo X60.
	 */
	if (sc->hw.mac_type == em_82573)
		E1000_WRITE_REG(&sc->hw, RDTR, 0x20);

	if (sc->hw.mac_type == em_82575 || sc->hw.mac_type == em_82580 ||
	    sc->hw.mac_type == em_i210 || sc->hw.mac_type == em_i350) {
		/* 82575/6 need to enable the RX queue */
		uint32_t reg;
		reg = E1000_READ_REG(&sc->hw, RXDCTL);
		reg |= E1000_RXDCTL_QUEUE_ENABLE;
		E1000_WRITE_REG(&sc->hw, RXDCTL, reg);
	}

	/* Enable Receives */
	E1000_WRITE_REG(&sc->hw, RCTL, reg_rctl);

	/* Setup the HW Rx Head and Tail Descriptor Pointers */
	E1000_WRITE_REG(&sc->hw, RDH, 0);
	E1000_WRITE_REG(&sc->hw, RDT, sc->sc_rx_desc_head);
}

/*********************************************************************
 *
 *  Free receive related data structures.
 *
 **********************************************************************/
void
em_free_receive_structures(struct em_softc *sc)
{
	struct em_packet *pkt;
	int i;

	INIT_DEBUGOUT("free_receive_structures: begin");

	if_rxr_init(&sc->sc_rx_ring, 0, 0);

	bus_dmamap_sync(sc->sc_dmat, sc->sc_rx_dma.dma_map,
	    0, sc->sc_rx_dma.dma_map->dm_mapsize,
	    BUS_DMASYNC_POSTREAD | BUS_DMASYNC_POSTWRITE);

	if (sc->sc_rx_pkts_ring != NULL) {
		for (i = 0; i < sc->sc_rx_slots; i++) {
			pkt = &sc->sc_rx_pkts_ring[i];
			if (pkt->pkt_m != NULL) {
				bus_dmamap_sync(sc->sc_dmat, pkt->pkt_map,
				    0, pkt->pkt_map->dm_mapsize,
				    BUS_DMASYNC_POSTREAD);
				bus_dmamap_unload(sc->sc_dmat, pkt->pkt_map);
				m_freem(pkt->pkt_m);
				pkt->pkt_m = NULL;
			}
			bus_dmamap_destroy(sc->sc_dmat, pkt->pkt_map);
		}

		free(sc->sc_rx_pkts_ring, M_DEVBUF,
		    sc->sc_rx_slots * sizeof(*sc->sc_rx_pkts_ring));
		sc->sc_rx_pkts_ring = NULL;
	}

	if (sc->fmp != NULL) {
		m_freem(sc->fmp);
		sc->fmp = NULL;
		sc->lmp = NULL;
	}
}

int
em_rxfill(struct em_softc *sc)
{
	u_int slots;
	int post = 0;
	int i;

	i = sc->sc_rx_desc_head;

	bus_dmamap_sync(sc->sc_dmat, sc->sc_rx_dma.dma_map,
	    0, sc->sc_rx_dma.dma_map->dm_mapsize,
	    BUS_DMASYNC_POSTWRITE);

	for (slots = if_rxr_get(&sc->sc_rx_ring, sc->sc_rx_slots);
	    slots > 0; slots--) {
		if (++i == sc->sc_rx_slots)
			i = 0;

		if (em_get_buf(sc, i) != 0)
			break;

		sc->sc_rx_desc_head = i;
		post = 1;
	}

	if_rxr_put(&sc->sc_rx_ring, slots);

	bus_dmamap_sync(sc->sc_dmat, sc->sc_rx_dma.dma_map,
	    0, sc->sc_rx_dma.dma_map->dm_mapsize,
	    BUS_DMASYNC_PREWRITE);

	return (post);
}

/*********************************************************************
 *
 *  This routine executes in interrupt context. It replenishes
 *  the mbufs in the descriptor and sends data which has been
 *  dma'ed into host memory to upper layer.
 *
 *********************************************************************/
int
em_rxeof(struct em_softc *sc)
{
	struct ifnet	    *ifp = &sc->sc_ac.ac_if;
	struct mbuf_list    ml = MBUF_LIST_INITIALIZER();
	struct mbuf	    *m;
	u_int8_t	    accept_frame = 0;
	u_int8_t	    eop = 0;
	u_int16_t	    len, desc_len, prev_len_adj;
	int		    i, rv = 0;

	/* Pointer to the receive descriptor being examined. */
	struct em_rx_desc   *desc;
	struct em_packet    *pkt;
	u_int8_t	    status;

	if (if_rxr_inuse(&sc->sc_rx_ring) == 0)
		return (0);

	i = sc->sc_rx_desc_tail;

	bus_dmamap_sync(sc->sc_dmat, sc->sc_rx_dma.dma_map,
	    0, sc->sc_rx_dma.dma_map->dm_mapsize,
	    BUS_DMASYNC_POSTREAD);

	do {
		m = NULL;

		pkt = &sc->sc_rx_pkts_ring[i];
		desc = &sc->sc_rx_desc_ring[i];

		status = desc->status;
		if (!ISSET(status, E1000_RXD_STAT_DD))
			break;

		/* pull the mbuf off the ring */
		bus_dmamap_sync(sc->sc_dmat, pkt->pkt_map,
		    0, pkt->pkt_map->dm_mapsize,
		    BUS_DMASYNC_POSTREAD);
		bus_dmamap_unload(sc->sc_dmat, pkt->pkt_map);
		m = pkt->pkt_m;
		pkt->pkt_m = NULL;

		KASSERT(m != NULL);

		if_rxr_put(&sc->sc_rx_ring, 1);
		rv = 1;

		accept_frame = 1;
		prev_len_adj = 0;
		desc_len = letoh16(desc->length);

		if (status & E1000_RXD_STAT_EOP) {
			eop = 1;
			if (desc_len < ETHER_CRC_LEN) {
				len = 0;
				prev_len_adj = ETHER_CRC_LEN - desc_len;
			} else if (sc->hw.mac_type == em_i210 ||
			    sc->hw.mac_type == em_i350)
				len = desc_len;
			else
				len = desc_len - ETHER_CRC_LEN;
		} else {
			eop = 0;
			len = desc_len;
		}

		if (desc->errors & E1000_RXD_ERR_FRAME_ERR_MASK) {
			u_int8_t last_byte;
			u_int32_t pkt_len = desc_len;

			if (sc->fmp != NULL)
				pkt_len += sc->fmp->m_pkthdr.len; 

			last_byte = *(mtod(m, caddr_t) + desc_len - 1);
			if (TBI_ACCEPT(&sc->hw, status, desc->errors,
			    pkt_len, last_byte)) {
#ifndef SMALL_KERNEL
				em_tbi_adjust_stats(&sc->hw, &sc->stats, 
				    pkt_len, sc->hw.mac_addr);
#endif
				if (len > 0)
					len--;
			} else
				accept_frame = 0;
		}

		if (accept_frame) {
			/* Assign correct length to the current fragment */
			m->m_len = len;

			if (sc->fmp == NULL) {
				m->m_pkthdr.len = m->m_len;
				sc->fmp = m;	 /* Store the first mbuf */
				sc->lmp = m;
			} else {
				/* Chain mbuf's together */
				m->m_flags &= ~M_PKTHDR;
				/*
				 * Adjust length of previous mbuf in chain if
				 * we received less than 4 bytes in the last
				 * descriptor.
				 */
				if (prev_len_adj > 0) {
					sc->lmp->m_len -= prev_len_adj;
					sc->fmp->m_pkthdr.len -= prev_len_adj;
				}
				sc->lmp->m_next = m;
				sc->lmp = m;
				sc->fmp->m_pkthdr.len += m->m_len;
			}

			if (eop) {
				m = sc->fmp;

				em_receive_checksum(sc, desc, m);
#if NVLAN > 0
				if (desc->status & E1000_RXD_STAT_VP) {
					m->m_pkthdr.ether_vtag =
					    letoh16(desc->special);
					m->m_flags |= M_VLANTAG;
				}
#endif
				ml_enqueue(&ml, m);

				sc->fmp = NULL;
				sc->lmp = NULL;
			}
		} else {
			sc->dropped_pkts++;

			if (sc->fmp != NULL) {
				m_freem(sc->fmp);
				sc->fmp = NULL;
				sc->lmp = NULL;
			}

			m_freem(m);
		}

		/* Advance our pointers to the next descriptor. */
		if (++i == sc->sc_rx_slots)
			i = 0;
	} while (if_rxr_inuse(&sc->sc_rx_ring) > 0);

	bus_dmamap_sync(sc->sc_dmat, sc->sc_rx_dma.dma_map,
	    0, sc->sc_rx_dma.dma_map->dm_mapsize,
	    BUS_DMASYNC_PREREAD);

	sc->sc_rx_desc_tail = i;

	if_input(ifp, &ml);

	return (rv);
}

/*********************************************************************
 *
 *  Verify that the hardware indicated that the checksum is valid. 
 *  Inform the stack about the status of checksum so that stack
 *  doesn't spend time verifying the checksum.
 *
 *********************************************************************/
void
em_receive_checksum(struct em_softc *sc, struct em_rx_desc *rx_desc,
    struct mbuf *mp)
{
	/* 82543 or newer only */
	if ((sc->hw.mac_type < em_82543) ||
	    /* Ignore Checksum bit is set */
	    (rx_desc->status & E1000_RXD_STAT_IXSM)) {
		mp->m_pkthdr.csum_flags = 0;
		return;
	}

	if (rx_desc->status & E1000_RXD_STAT_IPCS) {
		/* Did it pass? */
		if (!(rx_desc->errors & E1000_RXD_ERR_IPE)) {
			/* IP Checksum Good */
			mp->m_pkthdr.csum_flags = M_IPV4_CSUM_IN_OK;

		} else
			mp->m_pkthdr.csum_flags = 0;
	}

	if (rx_desc->status & E1000_RXD_STAT_TCPCS) {
		/* Did it pass? */        
		if (!(rx_desc->errors & E1000_RXD_ERR_TCPE))
			mp->m_pkthdr.csum_flags |=
				M_TCP_CSUM_IN_OK | M_UDP_CSUM_IN_OK;
	}
}

/*
 * This turns on the hardware offload of the VLAN
 * tag insertion and strip
 */
void 
em_enable_hw_vlans(struct em_softc *sc)
{
	uint32_t ctrl;

	ctrl = E1000_READ_REG(&sc->hw, CTRL);
	ctrl |= E1000_CTRL_VME;
	E1000_WRITE_REG(&sc->hw, CTRL, ctrl);
}

void
em_enable_intr(struct em_softc *sc)
{
	E1000_WRITE_REG(&sc->hw, IMS, (IMS_ENABLE_MASK));
}

void
em_disable_intr(struct em_softc *sc)
{
	/*
	 * The first version of 82542 had an errata where when link
	 * was forced it would stay up even if the cable was disconnected
	 * Sequence errors were used to detect the disconnect and then
	 * the driver would unforce the link.  This code is in the ISR.
	 * For this to work correctly the Sequence error interrupt had
	 * to be enabled all the time.
	 */

	if (sc->hw.mac_type == em_82542_rev2_0)
		E1000_WRITE_REG(&sc->hw, IMC, (0xffffffff & ~E1000_IMC_RXSEQ));
	else
		E1000_WRITE_REG(&sc->hw, IMC, 0xffffffff);
}

void
em_write_pci_cfg(struct em_hw *hw, uint32_t reg, uint16_t *value)
{
	struct pci_attach_args *pa = &((struct em_osdep *)hw->back)->em_pa;
	pcireg_t val;

	val = pci_conf_read(pa->pa_pc, pa->pa_tag, reg & ~0x3);
	if (reg & 0x2) {
		val &= 0x0000ffff;
		val |= (*value << 16);
	} else {
		val &= 0xffff0000;
		val |= *value;
	}
	pci_conf_write(pa->pa_pc, pa->pa_tag, reg & ~0x3, val);
}

void
em_read_pci_cfg(struct em_hw *hw, uint32_t reg, uint16_t *value)
{
	struct pci_attach_args *pa = &((struct em_osdep *)hw->back)->em_pa;
	pcireg_t val;

	val = pci_conf_read(pa->pa_pc, pa->pa_tag, reg & ~0x3);
	if (reg & 0x2)
		*value = (val >> 16) & 0xffff;
	else
		*value = val & 0xffff;
}

void
em_pci_set_mwi(struct em_hw *hw)
{
	struct pci_attach_args *pa = &((struct em_osdep *)hw->back)->em_pa;

	pci_conf_write(pa->pa_pc, pa->pa_tag, PCI_COMMAND_STATUS_REG,
		(hw->pci_cmd_word | CMD_MEM_WRT_INVALIDATE));
}

void
em_pci_clear_mwi(struct em_hw *hw)
{
	struct pci_attach_args *pa = &((struct em_osdep *)hw->back)->em_pa;

	pci_conf_write(pa->pa_pc, pa->pa_tag, PCI_COMMAND_STATUS_REG,
		(hw->pci_cmd_word & ~CMD_MEM_WRT_INVALIDATE));
}

/*
 * We may eventually really do this, but its unnecessary
 * for now so we just return unsupported.
 */
int32_t
em_read_pcie_cap_reg(struct em_hw *hw, uint32_t reg, uint16_t *value)
{
	return -E1000_NOT_IMPLEMENTED;
}

/*********************************************************************
* 82544 Coexistence issue workaround.
*    There are 2 issues.
*       1. Transmit Hang issue.
*    To detect this issue, following equation can be used...
*          SIZE[3:0] + ADDR[2:0] = SUM[3:0].
*          If SUM[3:0] is in between 1 to 4, we will have this issue.
*
*       2. DAC issue.
*    To detect this issue, following equation can be used...
*          SIZE[3:0] + ADDR[2:0] = SUM[3:0].
*          If SUM[3:0] is in between 9 to c, we will have this issue.
*
*
*    WORKAROUND:
*          Make sure we do not have ending address as 1,2,3,4(Hang) or 9,a,b,c (DAC)
*
*** *********************************************************************/
u_int32_t
em_fill_descriptors(u_int64_t address, u_int32_t length,
    PDESC_ARRAY desc_array)
{
        /* Since issue is sensitive to length and address.*/
        /* Let us first check the address...*/
        u_int32_t safe_terminator;
        if (length <= 4) {
                desc_array->descriptor[0].address = address;
                desc_array->descriptor[0].length = length;
                desc_array->elements = 1;
                return desc_array->elements;
        }
        safe_terminator = (u_int32_t)((((u_int32_t)address & 0x7) + (length & 0xF)) & 0xF);
        /* if it does not fall between 0x1 to 0x4 and 0x9 to 0xC then return */
        if (safe_terminator == 0   ||
        (safe_terminator > 4   &&
        safe_terminator < 9)   ||
        (safe_terminator > 0xC &&
        safe_terminator <= 0xF)) {
                desc_array->descriptor[0].address = address;
                desc_array->descriptor[0].length = length;
                desc_array->elements = 1;
                return desc_array->elements;
        }

        desc_array->descriptor[0].address = address;
        desc_array->descriptor[0].length = length - 4;
        desc_array->descriptor[1].address = address + (length - 4);
        desc_array->descriptor[1].length = 4;
        desc_array->elements = 2;
        return desc_array->elements;
}

/*
 * Disable the L0S and L1 LINK states.
 */
void
em_disable_aspm(struct em_softc *sc)
{
	int offset;
	pcireg_t val;

	switch (sc->hw.mac_type) {
		case em_82571:
		case em_82572:
		case em_82573:
		case em_82574:
			break;
		default:
			return;
	}

	if (!pci_get_capability(sc->osdep.em_pa.pa_pc, sc->osdep.em_pa.pa_tag,
	    PCI_CAP_PCIEXPRESS, &offset, NULL))
		return;

	/* Disable PCIe Active State Power Management (ASPM). */
	val = pci_conf_read(sc->osdep.em_pa.pa_pc, sc->osdep.em_pa.pa_tag,
	    offset + PCI_PCIE_LCSR);

	switch (sc->hw.mac_type) {
		case em_82571:
		case em_82572:
			val &= ~PCI_PCIE_LCSR_ASPM_L1;
			break;
		case em_82573:
		case em_82574:
			val &= ~(PCI_PCIE_LCSR_ASPM_L0S |
			    PCI_PCIE_LCSR_ASPM_L1);
			break;
		default:
			break;
	}

	pci_conf_write(sc->osdep.em_pa.pa_pc, sc->osdep.em_pa.pa_tag,
	    offset + PCI_PCIE_LCSR, val);
}

/*
 * em_flush_tx_ring - remove all descriptors from the tx_ring
 *
 * We want to clear all pending descriptors from the TX ring.
 * zeroing happens when the HW reads the regs. We assign the ring itself as
 * the data of the next descriptor. We don't care about the data we are about
 * to reset the HW.
 */
void
em_flush_tx_ring(struct em_softc *sc)
{
	uint32_t		 tctl, txd_lower = E1000_TXD_CMD_IFCS;
	uint16_t		 size = 512;
	struct em_tx_desc	*txd;

	KASSERT(sc->sc_tx_desc_ring != NULL);

	tctl = EM_READ_REG(&sc->hw, E1000_TCTL);
	EM_WRITE_REG(&sc->hw, E1000_TCTL, tctl | E1000_TCTL_EN);

	KASSERT(EM_READ_REG(&sc->hw, E1000_TDT) == sc->sc_tx_desc_head);

	txd = &sc->sc_tx_desc_ring[sc->sc_tx_desc_head];
	txd->buffer_addr = sc->sc_tx_dma.dma_map->dm_segs[0].ds_addr;
	txd->lower.data = htole32(txd_lower | size);
	txd->upper.data = 0;

	/* flush descriptors to memory before notifying the HW */
	bus_space_barrier(sc->osdep.mem_bus_space_tag,
	    sc->osdep.mem_bus_space_handle, 0, 0, BUS_SPACE_BARRIER_WRITE);

	if (++sc->sc_tx_desc_head == sc->sc_tx_slots)
		sc->sc_tx_desc_head = 0;

	EM_WRITE_REG(&sc->hw, E1000_TDT, sc->sc_tx_desc_head);
	bus_space_barrier(sc->osdep.mem_bus_space_tag, sc->osdep.mem_bus_space_handle,
	    0, 0, BUS_SPACE_BARRIER_READ|BUS_SPACE_BARRIER_WRITE);
	usec_delay(250);
}

/*
 * em_flush_rx_ring - remove all descriptors from the rx_ring
 *
 * Mark all descriptors in the RX ring as consumed and disable the rx ring
 */
void
em_flush_rx_ring(struct em_softc *sc)
{
	uint32_t	rctl, rxdctl;

	rctl = EM_READ_REG(&sc->hw, E1000_RCTL);
	EM_WRITE_REG(&sc->hw, E1000_RCTL, rctl & ~E1000_RCTL_EN);
	E1000_WRITE_FLUSH(&sc->hw);
	usec_delay(150);

	rxdctl = EM_READ_REG(&sc->hw, E1000_RXDCTL);
	/* zero the lower 14 bits (prefetch and host thresholds) */
	rxdctl &= 0xffffc000;
	/*
	 * update thresholds: prefetch threshold to 31, host threshold to 1
	 * and make sure the granularity is "descriptors" and not "cache lines"
	 */
	rxdctl |= (0x1F | (1 << 8) | E1000_RXDCTL_THRESH_UNIT_DESC);
	EM_WRITE_REG(&sc->hw, E1000_RXDCTL, rxdctl);

	/* momentarily enable the RX ring for the changes to take effect */
	EM_WRITE_REG(&sc->hw, E1000_RCTL, rctl | E1000_RCTL_EN);
	E1000_WRITE_FLUSH(&sc->hw);
	usec_delay(150);
	EM_WRITE_REG(&sc->hw, E1000_RCTL, rctl & ~E1000_RCTL_EN);
}

/*
 * em_flush_desc_rings - remove all descriptors from the descriptor rings
 *
 * In i219, the descriptor rings must be emptied before resetting the HW
 * or before changing the device state to D3 during runtime (runtime PM).
 *
 * Failure to do this will cause the HW to enter a unit hang state which can
 * only be released by PCI reset on the device
 *
 */
void
em_flush_desc_rings(struct em_softc *sc)
{
	struct pci_attach_args	*pa = &sc->osdep.em_pa;
	uint32_t		 fextnvm11, tdlen;
	uint16_t		 hang_state;

	/* First, disable MULR fix in FEXTNVM11 */
	fextnvm11 = EM_READ_REG(&sc->hw, E1000_FEXTNVM11);
	fextnvm11 |= E1000_FEXTNVM11_DISABLE_MULR_FIX;
	EM_WRITE_REG(&sc->hw, E1000_FEXTNVM11, fextnvm11);

	/* do nothing if we're not in faulty state, or if the queue is empty */
	tdlen = EM_READ_REG(&sc->hw, E1000_TDLEN);
	hang_state = pci_conf_read(pa->pa_pc, pa->pa_tag, PCICFG_DESC_RING_STATUS);
	if (!(hang_state & FLUSH_DESC_REQUIRED) || !tdlen)
		return;
	em_flush_tx_ring(sc);

	/* recheck, maybe the fault is caused by the rx ring */
	hang_state = pci_conf_read(pa->pa_pc, pa->pa_tag, PCICFG_DESC_RING_STATUS);
	if (hang_state & FLUSH_DESC_REQUIRED)
		em_flush_rx_ring(sc);
}

#ifndef SMALL_KERNEL
/**********************************************************************
 *
 *  Update the board statistics counters. 
 *
 **********************************************************************/
void
em_update_stats_counters(struct em_softc *sc)
{
	struct ifnet   *ifp = &sc->sc_ac.ac_if;

	sc->stats.crcerrs += E1000_READ_REG(&sc->hw, CRCERRS);
	sc->stats.mpc += E1000_READ_REG(&sc->hw, MPC);
	sc->stats.ecol += E1000_READ_REG(&sc->hw, ECOL);

	sc->stats.latecol += E1000_READ_REG(&sc->hw, LATECOL);
	sc->stats.colc += E1000_READ_REG(&sc->hw, COLC);

	sc->stats.ruc += E1000_READ_REG(&sc->hw, RUC);
	sc->stats.roc += E1000_READ_REG(&sc->hw, ROC);

	if (sc->hw.mac_type >= em_82543) {
		sc->stats.algnerrc += 
		E1000_READ_REG(&sc->hw, ALGNERRC);
		sc->stats.rxerrc += 
		E1000_READ_REG(&sc->hw, RXERRC);
		sc->stats.cexterr += 
		E1000_READ_REG(&sc->hw, CEXTERR);
	}

#ifdef EM_DEBUG
	if (sc->hw.media_type == em_media_type_copper ||
	    (E1000_READ_REG(&sc->hw, STATUS) & E1000_STATUS_LU)) {
		sc->stats.symerrs += E1000_READ_REG(&sc->hw, SYMERRS);
		sc->stats.sec += E1000_READ_REG(&sc->hw, SEC);
	}
	sc->stats.scc += E1000_READ_REG(&sc->hw, SCC);

	sc->stats.mcc += E1000_READ_REG(&sc->hw, MCC);
	sc->stats.dc += E1000_READ_REG(&sc->hw, DC);
	sc->stats.rlec += E1000_READ_REG(&sc->hw, RLEC);
	sc->stats.xonrxc += E1000_READ_REG(&sc->hw, XONRXC);
	sc->stats.xontxc += E1000_READ_REG(&sc->hw, XONTXC);
	sc->stats.xoffrxc += E1000_READ_REG(&sc->hw, XOFFRXC);
	sc->stats.xofftxc += E1000_READ_REG(&sc->hw, XOFFTXC);
	sc->stats.fcruc += E1000_READ_REG(&sc->hw, FCRUC);
	sc->stats.prc64 += E1000_READ_REG(&sc->hw, PRC64);
	sc->stats.prc127 += E1000_READ_REG(&sc->hw, PRC127);
	sc->stats.prc255 += E1000_READ_REG(&sc->hw, PRC255);
	sc->stats.prc511 += E1000_READ_REG(&sc->hw, PRC511);
	sc->stats.prc1023 += E1000_READ_REG(&sc->hw, PRC1023);
	sc->stats.prc1522 += E1000_READ_REG(&sc->hw, PRC1522);
	sc->stats.gprc += E1000_READ_REG(&sc->hw, GPRC);
	sc->stats.bprc += E1000_READ_REG(&sc->hw, BPRC);
	sc->stats.mprc += E1000_READ_REG(&sc->hw, MPRC);
	sc->stats.gptc += E1000_READ_REG(&sc->hw, GPTC);

	/* For the 64-bit byte counters the low dword must be read first. */
	/* Both registers clear on the read of the high dword */

	sc->stats.gorcl += E1000_READ_REG(&sc->hw, GORCL); 
	sc->stats.gorch += E1000_READ_REG(&sc->hw, GORCH);
	sc->stats.gotcl += E1000_READ_REG(&sc->hw, GOTCL);
	sc->stats.gotch += E1000_READ_REG(&sc->hw, GOTCH);

	sc->stats.rnbc += E1000_READ_REG(&sc->hw, RNBC);
	sc->stats.rfc += E1000_READ_REG(&sc->hw, RFC);
	sc->stats.rjc += E1000_READ_REG(&sc->hw, RJC);

	sc->stats.torl += E1000_READ_REG(&sc->hw, TORL);
	sc->stats.torh += E1000_READ_REG(&sc->hw, TORH);
	sc->stats.totl += E1000_READ_REG(&sc->hw, TOTL);
	sc->stats.toth += E1000_READ_REG(&sc->hw, TOTH);

	sc->stats.tpr += E1000_READ_REG(&sc->hw, TPR);
	sc->stats.tpt += E1000_READ_REG(&sc->hw, TPT);
	sc->stats.ptc64 += E1000_READ_REG(&sc->hw, PTC64);
	sc->stats.ptc127 += E1000_READ_REG(&sc->hw, PTC127);
	sc->stats.ptc255 += E1000_READ_REG(&sc->hw, PTC255);
	sc->stats.ptc511 += E1000_READ_REG(&sc->hw, PTC511);
	sc->stats.ptc1023 += E1000_READ_REG(&sc->hw, PTC1023);
	sc->stats.ptc1522 += E1000_READ_REG(&sc->hw, PTC1522);
	sc->stats.mptc += E1000_READ_REG(&sc->hw, MPTC);
	sc->stats.bptc += E1000_READ_REG(&sc->hw, BPTC);

	if (sc->hw.mac_type >= em_82543) {
		sc->stats.tncrs += 
		E1000_READ_REG(&sc->hw, TNCRS);
		sc->stats.tsctc += 
		E1000_READ_REG(&sc->hw, TSCTC);
		sc->stats.tsctfc += 
		E1000_READ_REG(&sc->hw, TSCTFC);
	}
#endif

	/* Fill out the OS statistics structure */
	ifp->if_collisions = sc->stats.colc;

	/* Rx Errors */
	ifp->if_ierrors =
	    sc->dropped_pkts +
	    sc->stats.rxerrc +
	    sc->stats.crcerrs +
	    sc->stats.algnerrc +
	    sc->stats.ruc + sc->stats.roc +
	    sc->stats.mpc + sc->stats.cexterr +
	    sc->rx_overruns;

	/* Tx Errors */
	ifp->if_oerrors = sc->stats.ecol + sc->stats.latecol +
	    sc->watchdog_events;
}

#ifdef EM_DEBUG
/**********************************************************************
 *
 *  This routine is called only when IFF_DEBUG is enabled.
 *  This routine provides a way to take a look at important statistics
 *  maintained by the driver and hardware.
 *
 **********************************************************************/
void
em_print_hw_stats(struct em_softc *sc)
{
	const char * const unit = DEVNAME(sc);

	printf("%s: Excessive collisions = %lld\n", unit,
		(long long)sc->stats.ecol);
	printf("%s: Symbol errors = %lld\n", unit,
		(long long)sc->stats.symerrs);
	printf("%s: Sequence errors = %lld\n", unit,
		(long long)sc->stats.sec);
	printf("%s: Defer count = %lld\n", unit,
		(long long)sc->stats.dc);

	printf("%s: Missed Packets = %lld\n", unit,
		(long long)sc->stats.mpc);
	printf("%s: Receive No Buffers = %lld\n", unit,
		(long long)sc->stats.rnbc);
	/* RLEC is inaccurate on some hardware, calculate our own */
	printf("%s: Receive Length Errors = %lld\n", unit,
		((long long)sc->stats.roc +
		(long long)sc->stats.ruc));
	printf("%s: Receive errors = %lld\n", unit,
		(long long)sc->stats.rxerrc);
	printf("%s: Crc errors = %lld\n", unit,
		(long long)sc->stats.crcerrs);
	printf("%s: Alignment errors = %lld\n", unit,
		(long long)sc->stats.algnerrc);
	printf("%s: Carrier extension errors = %lld\n", unit,
		(long long)sc->stats.cexterr);

	printf("%s: RX overruns = %ld\n", unit,
		sc->rx_overruns);
	printf("%s: watchdog timeouts = %ld\n", unit,
		sc->watchdog_events);

	printf("%s: XON Rcvd = %lld\n", unit,
		(long long)sc->stats.xonrxc);
	printf("%s: XON Xmtd = %lld\n", unit,
		(long long)sc->stats.xontxc);
	printf("%s: XOFF Rcvd = %lld\n", unit,
		(long long)sc->stats.xoffrxc);
	printf("%s: XOFF Xmtd = %lld\n", unit,
		(long long)sc->stats.xofftxc);

	printf("%s: Good Packets Rcvd = %lld\n", unit,
		(long long)sc->stats.gprc);
	printf("%s: Good Packets Xmtd = %lld\n", unit,
		(long long)sc->stats.gptc);
}
#endif
#endif /* !SMALL_KERNEL */
@


1.335
log
@Match the Kaby Lake and Lewisburg (Skylake-EP PCH) MACs with I219 PHYs.
Expanded version of a diff from claudio@@ who tested on x270 ok kettenis@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.334 2017/01/24 03:57:35 dlg Exp $ */
d1461 1
d1484 4
a1487 5
		if (!LINK_STATE_IS_UP(ifp->if_link_state)) {
			if (sc->link_duplex == FULL_DUPLEX)
				ifp->if_link_state = LINK_STATE_FULL_DUPLEX;
			else
				ifp->if_link_state = LINK_STATE_HALF_DUPLEX;
@


1.334
log
@add support for multiple transmit ifqueues per network interface.

an ifq to transmit a packet is picked by the current traffic
conditioner (ie, priq or hfsc) by providing an index into an array
of ifqs. by default interfaces get a single ifq but can ask for
more using if_attach_queues().

the vast majority of our drivers still think there's a 1:1 mapping
between interfaces and transmit queues, so their if_start routines
take an ifnet pointer instead of a pointer to the ifqueue struct.
instead of changing all the drivers in the tree, drivers can opt
into using an if_qstart routine and setting the IFXF_MPSAFE flag.
the stack provides a compatability wrapper from the new if_qstart
handler to the previous if_start handlers if IFXF_MPSAFE isnt set.

enabling hfsc on an interface configures it to transmit everything
through the first ifq. any other ifqs are left configured as priq,
but unused, when hfsc is enabled.

getting this in now so everyone can kick the tyres.

ok mpi@@ visa@@ (who provided some tweaks for cnmac).
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.333 2017/01/22 10:17:38 dlg Exp $ */
d149 4
a153 1
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_I219_LM2 },
d155 2
@


1.333
log
@move counting if_opackets next to counting if_obytes in if_enqueue.

this means packets are consistently counted in one place, unlike the
many and various ways that drivers thought they should do it.

ok mpi@@ deraadt@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.332 2016/10/27 03:06:53 dlg Exp $ */
d209 1
a209 1
void em_start(struct ifnet *);
d586 1
a586 1
em_start(struct ifnet *ifp)
d588 1
d595 1
a595 1
		IFQ_PURGE(&ifp->if_snd);
d615 1
a615 1
			ifq_set_oactive(&ifp->if_snd);
d619 1
a619 1
		m = ifq_dequeue(&ifp->if_snd);
d1874 1
a1874 1
	ifp->if_start = em_start;
@


1.332
log
@tell ix and em to use 2k+ETHER_ALIGN clusters for rx on all archs.

this means that the ethernet header and therefore its payload will
be aligned correctly for the stack. without this em and ix are
sufferring a 30 to 40 percent hit in forwarding performance because
the ethernet stack expects to be able to prepend 8 bytes for an
ethernet header so it can gaurantee its alignment. because em and
ix only had 6 bytes where the ethernet header was, it always prepends
an mbuf which turns out to be expensive. this way the prepend will
be cheap because the 8 byte space will exist.

2k+ETHER_ALIGN clusters will end up using the newly created mcl2k2
pool.

the regression was isolated and the fix tested by hrvoje popovski.
ok mikeb@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.331 2016/04/13 10:34:32 mpi Exp $ */
a2417 2

	ifp->if_opackets += free;
@


1.331
log
@G/C IFQ_SET_READY().
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.330 2016/02/18 14:24:39 bluhm Exp $ */
a2452 1
#ifdef __STRICT_ALIGNMENT
a2453 1
#endif
@


1.330
log
@Add support for the Intel i219 network chip to the em(4) driver.
from Christian Ehrhardt; input jsg@@; OK deraadt@@ sthen@@ mpi@@ jsg@@
tested by sthen@@ jca@@ benno@@ bluhm@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.329 2016/01/12 00:05:21 dlg Exp $ */
a1877 1
	IFQ_SET_READY(&ifp->if_snd);
@


1.329
log
@post the packet on em_82547 chips after bpf

now that start and txeof can run on different cpus, txeof could
have freed the mbuf before bpf got to it.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.328 2016/01/11 01:31:53 dlg Exp $ */
d148 4
d260 3
d445 1
d855 1
d1518 1
a1518 1
	if (!softonly) {
d1520 3
a1523 1
	}
d1577 21
d1652 1
d1654 7
a1660 1
	if (IS_ICH8(sc->hw.mac_type)) {
d1675 7
a1681 3
	if (pci_intr_map_msi(pa, &ih) && pci_intr_map(pa, &ih)) {
		printf(": couldn't map interrupt\n");
		return (ENXIO);
d1763 2
d1809 2
d2239 14
d3130 107
@


1.328
log
@do further work on the em transmit path to simplify the code.

noone could understand how em_txeof worked, so i rewrote it.

this also gets rid of the sc_tx_desc_free var that needed atomic
ops. space to use in em_start and space to free in em_txeof is now
calculated from the producer and consumer.

testers have reported better responsiveness with this. somehow.
if em issues persist after this, im rolling back to pre-mpsafe changes.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.327 2016/01/09 11:54:19 dlg Exp $ */
d633 12
a1230 6
		if (sc->link_duplex == HALF_DUPLEX)
			em_82547_move_tail_locked(sc);
		else {
			E1000_WRITE_REG(&sc->hw, TDT, head);
			em_82547_update_fifo_head(sc, m->m_pkthdr.len);
		}
@


1.327
log
@consistently use the desc ring pointers as guards for their dmamem.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.326 2016/01/07 12:18:38 dlg Exp $ */
d236 2
a237 2
void em_transmit_checksum_setup(struct em_softc *, struct mbuf *,
				u_int32_t *, u_int32_t *);
d245 1
a245 1
int  em_encap(struct em_softc *, struct mbuf *);
d581 1
d590 7
d604 2
a605 1
		if (EM_MAX_SCATTER + 1 > sc->sc_tx_desc_free) {
d614 2
a615 2
		if (em_encap(sc, m) != 0) {
			/* ifp->if_oerrors++; */
d620 4
d645 2
a646 4
		if (post) {
			E1000_WRITE_REG(&sc->hw, TDT,
			    sc->sc_tx_desc_head);
		}
d747 3
a749 3
	printf("%s: watchdog: cons %u prod %u free %u TDH %u TDT %u\n",
	    DEVNAME(sc), sc->sc_tx_desc_tail,
	    sc->sc_tx_desc_head, sc->sc_tx_desc_free,
d1092 1
a1092 1
int
d1095 6
a1100 4
	u_int32_t	txd_upper;
	u_int32_t	txd_lower, txd_used = 0;
	int		i, j, first, error = 0, last = 0;
	bus_dmamap_t	map;
a1104 1
	u_int32_t		counter;
d1106 3
a1108 14
	struct em_packet *pkt, *pkt_mapped;
	struct em_tx_desc *desc;

	/*
	 * Map the packet for DMA.
	 *
	 * Capture the first descriptor index,
	 * this descriptor will have the index
	 * of the EOP which is the only one that
	 * no gets a DONE bit writeback.
	 */
	first = sc->sc_tx_desc_head;
	pkt = &sc->sc_tx_pkts_ring[first];
	pkt_mapped = pkt;
d1111 1
a1111 2
	error = bus_dmamap_load_mbuf(sc->sc_dmat, map, m, BUS_DMA_NOWAIT);
	switch (error) {
d1115 3
a1117 3
		if ((error = m_defrag(m, M_DONTWAIT)) == 0 &&
		    (error = bus_dmamap_load_mbuf(sc->sc_dmat, map, m,
		     BUS_DMA_NOWAIT)) == 0)
d1123 1
a1123 1
		return (error);
d1126 4
d1138 4
a1141 3
	    sc->hw.mac_type != em_i350)
		em_transmit_checksum_setup(sc, m, &txd_upper, &txd_lower);
	else
d1143 1
d1145 3
a1147 1
	i = sc->sc_tx_desc_head;
d1149 1
a1149 1
	for (j = 0; j < map->dm_nsegs; j++) {
d1157 1
a1157 1
			    map->dm_segs[j].ds_addr, map->dm_segs[j].ds_len,
d1159 2
a1160 3
			for (counter = 0; counter < array_elements; counter++) {
				pkt = &sc->sc_tx_pkts_ring[i];
				desc = &sc->sc_tx_desc_ring[i];
d1163 1
a1163 1
					desc_array.descriptor[counter].address);
d1166 6
a1171 5
					 (u_int16_t)desc_array.descriptor[counter].length));
				desc->upper.data = htole32((txd_upper));
				last = i;
				if (++i == sc->sc_tx_slots)
					i = 0;
d1173 1
a1173 3
				pkt->pkt_m = NULL;
				pkt->pkt_eop = -1;
				txd_used++;
d1176 1
a1176 2
			pkt = &sc->sc_tx_pkts_ring[i];
			desc = &sc->sc_tx_desc_ring[i];
d1178 3
a1180 3
			desc->buffer_addr = htole64(map->dm_segs[j].ds_addr);
			desc->lower.data = htole32(
				sc->sc_txd_cmd | txd_lower | map->dm_segs[j].ds_len);
d1183 3
a1185 3
			last = i;
			if (++i == sc->sc_tx_slots)
	        		i = 0;
d1187 1
a1187 2
			pkt->pkt_m = NULL;
			pkt->pkt_eop = -1;
a1190 6
	sc->sc_tx_desc_head = i;
	if (sc->pcix_82544)
		atomic_sub_int(&sc->sc_tx_desc_free, txd_used);
	else
		atomic_sub_int(&sc->sc_tx_desc_free, map->dm_nsegs);

d1195 1
a1195 2
		desc->upper.fields.special =
		    htole16(m->m_pkthdr.ether_vtag);
d1202 1
d1204 1
a1204 2
	pkt_mapped->pkt_map = pkt->pkt_map;
	pkt->pkt_map = map;
d1206 1
a1206 2
	bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
	    BUS_DMASYNC_PREWRITE);
d1213 1
a1213 8
	desc->lower.data |=
	    htole32(E1000_TXD_CMD_EOP | E1000_TXD_CMD_RS);

	/*
	 * Keep track in the first buffer which
	 * descriptor will be written back
	 */
	pkt_mapped->pkt_eop = last;
a1214 5
	/* 
	 * Advance the Transmit Descriptor Tail (Tdt),
	 * this tells the E1000 that this frame is
	 * available to transmit.
	 */
d1222 1
a1222 1
			E1000_WRITE_REG(&sc->hw, TDT, i);
d1227 1
a1227 1
	return (0);
a2095 3
	/* Set number of descriptors available */
	sc->sc_tx_desc_free = sc->sc_tx_slots;

d2210 1
d2238 2
a2239 2
void
em_transmit_checksum_setup(struct em_softc *sc, struct mbuf *mp,
a2242 2
	struct em_packet *pkt;
	int curr_txd;
d2244 14
a2257 20
	if (mp->m_pkthdr.csum_flags) {
		if (mp->m_pkthdr.csum_flags & M_TCP_CSUM_OUT) {
			*txd_upper = E1000_TXD_POPTS_TXSM << 8;
			*txd_lower = E1000_TXD_CMD_DEXT | E1000_TXD_DTYP_D;
			if (sc->active_checksum_context == OFFLOAD_TCP_IP)
				return;
			else
				sc->active_checksum_context = OFFLOAD_TCP_IP;
		} else if (mp->m_pkthdr.csum_flags & M_UDP_CSUM_OUT) {
			*txd_upper = E1000_TXD_POPTS_TXSM << 8;
			*txd_lower = E1000_TXD_CMD_DEXT | E1000_TXD_DTYP_D;
			if (sc->active_checksum_context == OFFLOAD_UDP_IP)
				return;
			else
				sc->active_checksum_context = OFFLOAD_UDP_IP;
		} else {
			*txd_upper = 0;
			*txd_lower = 0;
			return;
		}
d2261 1
a2261 1
		return;
d2267 1
a2267 3
	curr_txd = sc->sc_tx_desc_head;
	pkt = &sc->sc_tx_pkts_ring[curr_txd];
	TXD = (struct em_context_desc *) &sc->sc_tx_desc_ring[curr_txd];
d2292 1
a2292 8
	pkt->pkt_m = NULL;
	pkt->pkt_eop = -1;

	if (++curr_txd == sc->sc_tx_slots)
		curr_txd = 0;

	atomic_dec_int(&sc->sc_tx_desc_free);
	sc->sc_tx_desc_head = curr_txd;
d2305 1
a2305 1
	int first, last, done, num_avail, free = 0;
d2307 6
a2312 2
	struct em_tx_desc   *tx_desc, *eop_desc;
	struct ifnet   *ifp = &sc->sc_ac.ac_if;
d2314 1
a2314 1
	if (sc->sc_tx_desc_free == sc->sc_tx_slots)
a2316 16
	first = sc->sc_tx_desc_tail;
	tx_desc = &sc->sc_tx_desc_ring[first];
	pkt = &sc->sc_tx_pkts_ring[first];
	last = pkt->pkt_eop;
	eop_desc = &sc->sc_tx_desc_ring[last];

	/*
	 * What this does is get the index of the
	 * first descriptor AFTER the EOP of the 
	 * first packet, that way we can do the
	 * simple comparison on the inner while loop.
	 */
	if (++last == sc->sc_tx_slots)
		last = 0;
	done = last;

a2319 6
	while (eop_desc->upper.fields.status & E1000_TXD_STAT_DD) {
		/* We clean the range of the packet */
		while (first != done) {
			tx_desc->upper.data = 0;
			tx_desc->lower.data = 0;
			free++;
d2321 21
a2341 14
			if (pkt->pkt_m != NULL) {
				ifp->if_opackets++;
				if (pkt->pkt_map->dm_nsegs > 0) {
					bus_dmamap_sync(sc->sc_dmat,
					    pkt->pkt_map, 0,
					    pkt->pkt_map->dm_mapsize,
					    BUS_DMASYNC_POSTWRITE);
					bus_dmamap_unload(sc->sc_dmat,
					    pkt->pkt_map);
				}
				m_freem(pkt->pkt_m);
				pkt->pkt_m = NULL;
			}
			pkt->pkt_eop = -1;
d2343 2
a2344 2
			if (++first == sc->sc_tx_slots)
				first = 0;
a2345 14
			pkt = &sc->sc_tx_pkts_ring[first];
			tx_desc = &sc->sc_tx_desc_ring[first];
		}
		/* See if we can continue to the next packet */
		last = pkt->pkt_eop;
		if (last != -1) {
			eop_desc = &sc->sc_tx_desc_ring[last];
			/* Get new done point */
			if (++last == sc->sc_tx_slots)
				last = 0;
			done = last;
		} else
			break;
	}
d2350 4
a2353 1
	sc->sc_tx_desc_tail = first;
d2355 1
a2355 1
	num_avail = atomic_add_int_nv(&sc->sc_tx_desc_free, free);
d2359 1
a2359 1
	else if (num_avail == sc->sc_tx_slots)
d2470 1
a2470 1
	    sizeof(struct em_rx_desc) * sc->sc_rx_slots);
d2522 2
a2523 2
	E1000_WRITE_REG(&sc->hw, RDLEN, sc->sc_rx_slots *
			sizeof(struct em_rx_desc));
@


1.326
log
@look at pkts inside the loop over the pkts in em_free_receive_structures.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.325 2016/01/07 11:19:54 dlg Exp $ */
d311 2
d314 1
d557 1
d560 1
d1908 1
a1909 1
		sc->sc_rx_desc_ring = NULL;
d1912 1
a1913 1
		sc->sc_tx_desc_ring = NULL;
@


1.325
log
@rename em_buffers to em_packets.

shorten a bunch of variable names while here.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.324 2016/01/07 07:18:07 dlg Exp $ */
a2664 1
		pkt = &sc->sc_rx_pkts_ring[i];
d2666 1
@


1.324
log
@rename the rx and tx ring softc vars.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.323 2016/01/07 07:03:55 dlg Exp $ */
d1077 1
a1077 1
em_encap(struct em_softc *sc, struct mbuf *m_head)
d1089 2
a1090 2
	struct em_buffer   *tx_buffer, *tx_buffer_mapped;
	struct em_tx_desc *current_tx_desc = NULL;
d1101 3
a1103 3
	tx_buffer = &sc->sc_tx_buffers[first];
	tx_buffer_mapped = tx_buffer;
	map = tx_buffer->map;
d1105 1
a1105 1
	error = bus_dmamap_load_mbuf(sc->sc_dmat, map, m_head, BUS_DMA_NOWAIT);
d1110 2
a1111 2
		if ((error = m_defrag(m_head, M_DONTWAIT)) == 0 &&
		    (error = bus_dmamap_load_mbuf(sc->sc_dmat, map, m_head,
d1130 1
a1130 1
		em_transmit_checksum_setup(sc, m_head, &txd_upper, &txd_lower);
d1147 4
a1150 3
				tx_buffer = &sc->sc_tx_buffers[i];
				current_tx_desc = &sc->sc_tx_desc_ring[i];
				current_tx_desc->buffer_addr = htole64(
d1152 1
a1152 1
				current_tx_desc->lower.data = htole32(
d1155 1
a1155 1
				current_tx_desc->upper.data = htole32((txd_upper));
d1160 2
a1161 2
				tx_buffer->m_head = NULL;
				tx_buffer->next_eop = -1;
d1165 2
a1166 2
			tx_buffer = &sc->sc_tx_buffers[i];
			current_tx_desc = &sc->sc_tx_desc_ring[i];
d1168 2
a1169 2
			current_tx_desc->buffer_addr = htole64(map->dm_segs[j].ds_addr);
			current_tx_desc->lower.data = htole32(
d1171 2
a1172 1
			current_tx_desc->upper.data = htole32(txd_upper);
d1177 2
a1178 2
			tx_buffer->m_head = NULL;
			tx_buffer->next_eop = -1;
d1190 1
a1190 1
	if (m_head->m_flags & M_VLANTAG) {
d1192 2
a1193 2
		current_tx_desc->upper.fields.special =
			htole16(m_head->m_pkthdr.ether_vtag);
d1196 1
a1196 1
		current_tx_desc->lower.data |= htole32(E1000_TXD_CMD_VLE);
d1200 4
a1203 3
	tx_buffer->m_head = m_head;
	tx_buffer_mapped->map = tx_buffer->map;
	tx_buffer->map = map;
d1212 1
a1212 1
	current_tx_desc->lower.data |=
d1219 1
a1219 2
	tx_buffer = &sc->sc_tx_buffers[first];
	tx_buffer->next_eop = last;
d1234 1
a1234 1
			em_82547_update_fifo_head(sc, m_head->m_pkthdr.len);
d2064 3
a2066 2
	if (!(sc->sc_tx_buffers = mallocarray(sc->sc_tx_slots,
	    sizeof(struct em_buffer), M_DEVBUF, M_NOWAIT | M_ZERO))) {
d2083 1
a2083 1
	struct  em_buffer *tx_buffer;
a2091 1
	tx_buffer = sc->sc_tx_buffers;
d2093 1
d2096 1
a2096 1
		    MAX_JUMBO_FRAME_SIZE, 0, BUS_DMA_NOWAIT, &tx_buffer->map);
a2101 1
		tx_buffer++;
d2210 2
a2211 2
	struct em_buffer   *tx_buffer;
	int		i;
d2215 7
a2221 7
	if (sc->sc_tx_buffers != NULL) {
		tx_buffer = sc->sc_tx_buffers;
		for (i = 0; i < sc->sc_tx_slots; i++, tx_buffer++) {
			if (tx_buffer->map != NULL &&
			    tx_buffer->map->dm_nsegs > 0) {
				bus_dmamap_sync(sc->sc_dmat, tx_buffer->map,
				    0, tx_buffer->map->dm_mapsize,
d2223 3
a2225 2
				bus_dmamap_unload(sc->sc_dmat,
				    tx_buffer->map);
d2227 4
a2230 8
			if (tx_buffer->m_head != NULL) {
				m_freem(tx_buffer->m_head);
				tx_buffer->m_head = NULL;
			}
			if (tx_buffer->map != NULL) {
				bus_dmamap_destroy(sc->sc_dmat,
				    tx_buffer->map);
				tx_buffer->map = NULL;
d2233 4
a2236 5
	}
	if (sc->sc_tx_buffers != NULL) {
		free(sc->sc_tx_buffers, M_DEVBUF,
		    sc->sc_tx_slots * sizeof(struct em_buffer));
		sc->sc_tx_buffers = NULL;
d2256 1
a2256 1
	struct em_buffer *tx_buffer;
d2289 1
a2289 1
	tx_buffer = &sc->sc_tx_buffers[curr_txd];
d2315 2
a2316 2
	tx_buffer->m_head = NULL;
	tx_buffer->next_eop = -1;
d2336 1
a2336 1
	struct em_buffer *tx_buffer;
d2345 2
a2346 2
	tx_buffer = &sc->sc_tx_buffers[first];
	last = tx_buffer->next_eop;
d2369 1
a2369 1
			if (tx_buffer->m_head != NULL) {
d2371 1
a2371 1
				if (tx_buffer->map->dm_nsegs > 0) {
d2373 2
a2374 2
					    tx_buffer->map, 0,
					    tx_buffer->map->dm_mapsize,
d2377 1
a2377 1
					    tx_buffer->map);
d2379 2
a2380 2
				m_freem(tx_buffer->m_head);
				tx_buffer->m_head = NULL;
d2382 1
a2382 1
			tx_buffer->next_eop = -1;
d2387 1
a2387 1
			tx_buffer = &sc->sc_tx_buffers[first];
d2391 1
a2391 1
		last = tx_buffer->next_eop;
d2424 1
a2424 1
	struct em_buffer *pkt;
d2428 1
a2428 1
	pkt = &sc->sc_rx_buffers[i];
d2431 1
a2431 5
	if (pkt->m_head != NULL) {
		printf("%s: em_get_buf: slot %d already has an mbuf\n",
		    DEVNAME(sc), i);
		return (ENOBUFS);
	}
d2434 1
a2434 1
	if (!m) {
d2443 2
a2444 1
	error = bus_dmamap_load_mbuf(sc->sc_dmat, pkt->map, m, BUS_DMA_NOWAIT);
d2450 2
a2451 1
	bus_dmamap_sync(sc->sc_dmat, pkt->map, 0, pkt->map->dm_mapsize,
d2453 1
a2453 1
	pkt->m_head = m;
d2455 2
a2456 2
	bzero(desc, sizeof(*desc));
	desc->buffer_addr = htole64(pkt->map->dm_segs[0].ds_addr);
d2472 11
a2482 2
	int		i, error;
	struct em_buffer *rx_buffer;
d2488 2
a2489 6
	if (!(sc->sc_rx_buffers = mallocarray(sc->sc_rx_slots,
	    sizeof(struct em_buffer), M_DEVBUF, M_NOWAIT | M_ZERO))) {
		printf("%s: Unable to allocate rx_buffer memory\n", 
		       DEVNAME(sc));
		return (ENOMEM);
	}
a2490 2
	rx_buffer = sc->sc_rx_buffers;
	for (i = 0; i < sc->sc_rx_slots; i++, rx_buffer++) {
d2492 1
a2492 1
		    EM_MCLBYTES, 0, BUS_DMA_NOWAIT, &rx_buffer->map);
d2499 2
a2500 1
		rx_buffer->m_head = NULL;
d2653 2
a2654 2
	struct em_buffer   *rx_buffer;
	int		i;
d2664 6
a2669 6
	if (sc->sc_rx_buffers != NULL) {
		rx_buffer = sc->sc_rx_buffers;
		for (i = 0; i < sc->sc_rx_slots; i++, rx_buffer++) {
			if (rx_buffer->m_head != NULL) {
				bus_dmamap_sync(sc->sc_dmat, rx_buffer->map,
				    0, rx_buffer->map->dm_mapsize,
d2671 3
a2673 3
				bus_dmamap_unload(sc->sc_dmat, rx_buffer->map);
				m_freem(rx_buffer->m_head);
				rx_buffer->m_head = NULL;
d2675 1
a2675 1
			bus_dmamap_destroy(sc->sc_dmat, rx_buffer->map);
d2677 4
a2680 5
	}
	if (sc->sc_rx_buffers != NULL) {
		free(sc->sc_rx_buffers, M_DEVBUF,
		    sc->sc_rx_slots * sizeof(struct em_buffer));
		sc->sc_rx_buffers = NULL;
d2744 1
a2744 1
	struct em_buffer    *pkt;
d2759 1
a2760 1
		pkt = &sc->sc_rx_buffers[i];
d2767 2
a2768 1
		bus_dmamap_sync(sc->sc_dmat, pkt->map, 0, pkt->map->dm_mapsize,
d2770 5
a2774 10
		bus_dmamap_unload(sc->sc_dmat, pkt->map);
		m = pkt->m_head;
		pkt->m_head = NULL;

		if (m == NULL) {
			panic("em_rxeof: NULL mbuf in slot %d "
			    "(nrx %d, filled %d)", i,
			    if_rxr_inuse(&sc->sc_rx_ring),
			    sc->sc_rx_desc_head);
		}
@


1.323
log
@prefix the rx and tx ring softc members with sc_
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.322 2016/01/07 06:49:04 dlg Exp $ */
d311 2
a312 2
		em_dma_free(sc, &sc->sc_rxdma);
		em_dma_free(sc, &sc->sc_txdma);
d365 2
a366 2
		sc->sc_num_tx_desc = EM_MAX_TXD;
		sc->sc_num_rx_desc = EM_MAX_RXD;
d368 2
a369 2
		sc->sc_num_tx_desc = EM_MAX_TXD_82543;
		sc->sc_num_rx_desc = EM_MAX_RXD_82543;
d457 2
a458 2
	if (em_dma_malloc(sc, sc->sc_num_tx_desc * sizeof(struct em_tx_desc),
	    &sc->sc_txdma) != 0) {
d463 1
a463 1
	sc->sc_tx_desc_base = (struct em_tx_desc *)sc->sc_txdma.dma_vaddr;
d466 2
a467 2
	if (em_dma_malloc(sc, sc->sc_num_rx_desc * sizeof(struct em_rx_desc),
	    &sc->sc_rxdma) != 0) {
d472 1
a472 1
	sc->sc_rx_desc_base = (struct em_rx_desc *)sc->sc_rxdma.dma_vaddr;
d554 1
a554 1
	em_dma_free(sc, &sc->sc_rxdma);
d556 1
a556 1
	em_dma_free(sc, &sc->sc_txdma);
d585 2
a586 2
		bus_dmamap_sync(sc->sc_dmat, sc->sc_txdma.dma_map,
		    0, sc->sc_txdma.dma_map->dm_mapsize,
d591 1
a591 1
		if (EM_MAX_SCATTER + 1 > sc->sc_num_tx_desc_avail) {
d619 2
a620 2
		bus_dmamap_sync(sc->sc_dmat, sc->sc_txdma.dma_map,
		    0, sc->sc_txdma.dma_map->dm_mapsize,
d629 1
a629 1
			    sc->sc_next_avail_tx_desc);
d732 2
a733 2
	    DEVNAME(sc), sc->sc_next_tx_to_clean,
	    sc->sc_next_avail_tx_desc, sc->sc_num_tx_desc_avail,
d907 1
a907 1
				    sc->sc_last_rx_desc_filled);
d1100 2
a1101 2
	first = sc->sc_next_avail_tx_desc;
	tx_buffer = &sc->sc_tx_buffer_area[first];
d1122 2
a1123 2
		bus_dmamap_sync(sc->sc_dmat, sc->sc_txdma.dma_map,
		    0, sc->sc_txdma.dma_map->dm_mapsize,
d1134 1
a1134 1
	i = sc->sc_next_avail_tx_desc;
d1147 2
a1148 2
				tx_buffer = &sc->sc_tx_buffer_area[i];
				current_tx_desc = &sc->sc_tx_desc_base[i];
d1156 1
a1156 1
				if (++i == sc->sc_num_tx_desc)
d1164 2
a1165 2
			tx_buffer = &sc->sc_tx_buffer_area[i];
			current_tx_desc = &sc->sc_tx_desc_base[i];
d1172 1
a1172 1
			if (++i == sc->sc_num_tx_desc)
d1180 1
a1180 1
	sc->sc_next_avail_tx_desc = i;
d1182 1
a1182 1
		atomic_sub_int(&sc->sc_num_tx_desc_avail, txd_used);
d1184 1
a1184 1
		atomic_sub_int(&sc->sc_num_tx_desc_avail, map->dm_nsegs);
d1216 1
a1216 1
	tx_buffer = &sc->sc_tx_buffer_area[first];
d1225 2
a1226 2
		bus_dmamap_sync(sc->sc_dmat, sc->sc_txdma.dma_map,
		    0, sc->sc_txdma.dma_map->dm_mapsize,
d1257 1
a1257 1
	sw_tdt = sc->sc_next_avail_tx_desc;
d1260 1
a1260 1
		tx_desc = &sc->sc_tx_desc_base[hw_tdt];
d1263 1
a1263 1
		if (++hw_tdt == sc->sc_num_tx_desc)
d1833 1
a1833 1
	IFQ_SET_MAXLEN(&ifp->if_snd, sc->sc_num_tx_desc - 1);
d1900 7
a1906 7
	if (sc->sc_rx_desc_base != NULL) {
		em_dma_free(sc, &sc->sc_rxdma);
		sc->sc_rx_desc_base = NULL;
	}
	if (sc->sc_tx_desc_base != NULL) {
		em_dma_free(sc, &sc->sc_txdma);
		sc->sc_tx_desc_base = NULL;
d2058 2
a2059 2
	bus_dmamap_sync(sc->sc_dmat, sc->sc_txdma.dma_map,
	    0, sc->sc_txdma.dma_map->dm_mapsize,
d2062 1
a2062 1
	if (!(sc->sc_tx_buffer_area = mallocarray(sc->sc_num_tx_desc,
d2086 2
a2087 2
	bzero((void *) sc->sc_tx_desc_base,
	      (sizeof(struct em_tx_desc)) * sc->sc_num_tx_desc);
d2089 2
a2090 2
	tx_buffer = sc->sc_tx_buffer_area;
	for (i = 0; i < sc->sc_num_tx_desc; i++) {
d2102 2
a2103 2
	sc->sc_next_avail_tx_desc = 0;
	sc->sc_next_tx_to_clean = 0;
d2106 1
a2106 1
	sc->sc_num_tx_desc_avail = sc->sc_num_tx_desc;
d2132 1
a2132 1
	bus_addr = sc->sc_txdma.dma_map->dm_segs[0].ds_addr;
d2134 1
a2134 1
			sc->sc_num_tx_desc *
d2213 3
a2215 3
	if (sc->sc_tx_buffer_area != NULL) {
		tx_buffer = sc->sc_tx_buffer_area;
		for (i = 0; i < sc->sc_num_tx_desc; i++, tx_buffer++) {
d2235 4
a2238 4
	if (sc->sc_tx_buffer_area != NULL) {
		free(sc->sc_tx_buffer_area, M_DEVBUF,
		    sc->sc_num_tx_desc * sizeof(struct em_buffer));
		sc->sc_tx_buffer_area = NULL;
d2241 2
a2242 2
	bus_dmamap_sync(sc->sc_dmat, sc->sc_txdma.dma_map,
	    0, sc->sc_txdma.dma_map->dm_mapsize,
d2290 3
a2292 3
	curr_txd = sc->sc_next_avail_tx_desc;
	tx_buffer = &sc->sc_tx_buffer_area[curr_txd];
	TXD = (struct em_context_desc *) &sc->sc_tx_desc_base[curr_txd];
d2320 1
a2320 1
	if (++curr_txd == sc->sc_num_tx_desc)
d2323 2
a2324 2
	atomic_dec_int(&sc->sc_num_tx_desc_avail);
	sc->sc_next_avail_tx_desc = curr_txd;
d2342 1
a2342 1
	if (sc->sc_num_tx_desc_avail == sc->sc_num_tx_desc)
d2345 3
a2347 3
	first = sc->sc_next_tx_to_clean;
	tx_desc = &sc->sc_tx_desc_base[first];
	tx_buffer = &sc->sc_tx_buffer_area[first];
d2349 1
a2349 1
	eop_desc = &sc->sc_tx_desc_base[last];
d2357 1
a2357 1
	if (++last == sc->sc_num_tx_desc)
d2361 2
a2362 2
	bus_dmamap_sync(sc->sc_dmat, sc->sc_txdma.dma_map,
	    0, sc->sc_txdma.dma_map->dm_mapsize,
d2386 1
a2386 1
			if (++first == sc->sc_num_tx_desc)
d2389 2
a2390 2
			tx_buffer = &sc->sc_tx_buffer_area[first];
			tx_desc = &sc->sc_tx_desc_base[first];
d2395 1
a2395 1
			eop_desc = &sc->sc_tx_desc_base[last];
d2397 1
a2397 1
			if (++last == sc->sc_num_tx_desc)
d2403 2
a2404 2
	bus_dmamap_sync(sc->sc_dmat, sc->sc_txdma.dma_map,
	    0, sc->sc_txdma.dma_map->dm_mapsize,
d2407 1
a2407 1
	sc->sc_next_tx_to_clean = first;
d2409 1
a2409 1
	num_avail = atomic_add_int_nv(&sc->sc_num_tx_desc_avail, free);
d2413 1
a2413 1
	else if (num_avail == sc->sc_num_tx_desc)
d2430 2
a2431 2
	pkt = &sc->sc_rx_buffer_area[i];
	desc = &sc->sc_rx_desc_base[i];
d2479 2
a2480 2
	bus_dmamap_sync(sc->sc_dmat, sc->sc_rxdma.dma_map,
	    0, sc->sc_rxdma.dma_map->dm_mapsize,
d2483 1
a2483 1
	if (!(sc->sc_rx_buffer_area = mallocarray(sc->sc_num_rx_desc,
d2490 2
a2491 2
	rx_buffer = sc->sc_rx_buffer_area;
	for (i = 0; i < sc->sc_num_rx_desc; i++, rx_buffer++) {
d2521 2
a2522 2
	memset(sc->sc_rx_desc_base, 0,
	    sizeof(struct em_rx_desc) * sc->sc_num_rx_desc);
d2528 2
a2529 2
	sc->sc_next_rx_desc_to_check = 0;
	sc->sc_last_rx_desc_filled = sc->sc_num_rx_desc - 1;
d2532 1
a2532 1
	if_rxr_init(&sc->sc_rx_ring, lwm, sc->sc_num_rx_desc);
d2573 2
a2574 2
	bus_addr = sc->sc_rxdma.dma_map->dm_segs[0].ds_addr;
	E1000_WRITE_REG(&sc->hw, RDLEN, sc->sc_num_rx_desc *
d2642 1
a2642 1
	E1000_WRITE_REG(&sc->hw, RDT, sc->sc_last_rx_desc_filled);
d2660 2
a2661 2
	bus_dmamap_sync(sc->sc_dmat, sc->sc_rxdma.dma_map,
	    0, sc->sc_rxdma.dma_map->dm_mapsize,
d2664 3
a2666 3
	if (sc->sc_rx_buffer_area != NULL) {
		rx_buffer = sc->sc_rx_buffer_area;
		for (i = 0; i < sc->sc_num_rx_desc; i++, rx_buffer++) {
d2678 4
a2681 4
	if (sc->sc_rx_buffer_area != NULL) {
		free(sc->sc_rx_buffer_area, M_DEVBUF,
		    sc->sc_num_rx_desc * sizeof(struct em_buffer));
		sc->sc_rx_buffer_area = NULL;
d2698 1
a2698 1
	i = sc->sc_last_rx_desc_filled;
d2700 2
a2701 2
	bus_dmamap_sync(sc->sc_dmat, sc->sc_rxdma.dma_map,
	    0, sc->sc_rxdma.dma_map->dm_mapsize,
d2704 1
a2704 1
	for (slots = if_rxr_get(&sc->sc_rx_ring, sc->sc_num_rx_desc);
d2706 1
a2706 1
		if (++i == sc->sc_num_rx_desc)
d2712 1
a2712 1
		sc->sc_last_rx_desc_filled = i;
d2718 2
a2719 2
	bus_dmamap_sync(sc->sc_dmat, sc->sc_rxdma.dma_map,
	    0, sc->sc_rxdma.dma_map->dm_mapsize,
d2751 1
a2751 1
	i = sc->sc_next_rx_desc_to_check;
d2753 2
a2754 2
	bus_dmamap_sync(sc->sc_dmat, sc->sc_rxdma.dma_map,
	    0, sc->sc_rxdma.dma_map->dm_mapsize,
d2760 2
a2761 2
		desc = &sc->sc_rx_desc_base[i];
		pkt = &sc->sc_rx_buffer_area[i];
d2778 1
a2778 1
			    sc->sc_last_rx_desc_filled);
d2877 1
a2877 1
		if (++i == sc->sc_num_rx_desc)
d2881 2
a2882 2
	bus_dmamap_sync(sc->sc_dmat, sc->sc_rxdma.dma_map,
	    0, sc->sc_rxdma.dma_map->dm_mapsize,
d2885 1
a2885 1
	sc->sc_next_rx_desc_to_check = i;
@


1.322
log
@host the rx ring dmamap syncs out of em_get_buf into em_rxfill.

this lets us do the syncs once for a fill of the ring instead of
once for every packet put onto the ring. it mirrors how we try to
do things for tx.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.321 2016/01/07 06:37:45 dlg Exp $ */
d311 2
a312 2
		em_dma_free(sc, &sc->rxdma);
		em_dma_free(sc, &sc->txdma);
d365 2
a366 2
		sc->num_tx_desc = EM_MAX_TXD;
		sc->num_rx_desc = EM_MAX_RXD;
d368 2
a369 2
		sc->num_tx_desc = EM_MAX_TXD_82543;
		sc->num_rx_desc = EM_MAX_RXD_82543;
d379 1
a379 1
	sc->rx_buffer_len = EM_RXBUFFER_2048;
d457 2
a458 2
	if (em_dma_malloc(sc, sc->num_tx_desc * sizeof(struct em_tx_desc),
	    &sc->txdma) != 0) {
d463 1
a463 1
	sc->tx_desc_base = (struct em_tx_desc *)sc->txdma.dma_vaddr;
d466 2
a467 2
	if (em_dma_malloc(sc, sc->num_rx_desc * sizeof(struct em_rx_desc),
	    &sc->rxdma) != 0) {
d472 1
a472 1
	sc->rx_desc_base = (struct em_rx_desc *)sc->rxdma.dma_vaddr;
d554 1
a554 1
	em_dma_free(sc, &sc->rxdma);
d556 1
a556 1
	em_dma_free(sc, &sc->txdma);
d585 2
a586 2
		bus_dmamap_sync(sc->sc_dmat, sc->txdma.dma_map,
		    0, sc->txdma.dma_map->dm_mapsize,
d591 1
a591 1
		if (EM_MAX_SCATTER + 1 > sc->num_tx_desc_avail) {
d619 2
a620 2
		bus_dmamap_sync(sc->sc_dmat, sc->txdma.dma_map,
		    0, sc->txdma.dma_map->dm_mapsize,
d627 4
a630 2
		if (post)
			E1000_WRITE_REG(&sc->hw, TDT, sc->next_avail_tx_desc);
d690 1
a690 1
		    NULL, EM_MCLBYTES, &sc->rx_ring);
d732 2
a733 2
	    DEVNAME(sc), sc->next_tx_to_clean,
	    sc->next_avail_tx_desc, sc->num_tx_desc_avail,
d907 1
a907 1
				    sc->last_rx_desc_filled);
d1100 2
a1101 2
	first = sc->next_avail_tx_desc;
	tx_buffer = &sc->tx_buffer_area[first];
d1122 2
a1123 2
		bus_dmamap_sync(sc->sc_dmat, sc->txdma.dma_map,
		    0, sc->txdma.dma_map->dm_mapsize,
d1134 1
a1134 1
	i = sc->next_avail_tx_desc;
d1147 2
a1148 2
				tx_buffer = &sc->tx_buffer_area[i];
				current_tx_desc = &sc->tx_desc_base[i];
d1152 1
a1152 1
					(sc->txd_cmd | txd_lower |
d1156 1
a1156 1
				if (++i == sc->num_tx_desc)
d1164 2
a1165 2
			tx_buffer = &sc->tx_buffer_area[i];
			current_tx_desc = &sc->tx_desc_base[i];
d1169 1
a1169 1
				sc->txd_cmd | txd_lower | map->dm_segs[j].ds_len);
d1172 1
a1172 1
			if (++i == sc->num_tx_desc)
d1180 1
a1180 1
	sc->next_avail_tx_desc = i;
d1182 1
a1182 1
		atomic_sub_int(&sc->num_tx_desc_avail, txd_used);
d1184 1
a1184 1
		atomic_sub_int(&sc->num_tx_desc_avail, map->dm_nsegs);
d1216 1
a1216 1
	tx_buffer = &sc->tx_buffer_area[first];
d1225 2
a1226 2
		bus_dmamap_sync(sc->sc_dmat, sc->txdma.dma_map,
		    0, sc->txdma.dma_map->dm_mapsize,
d1257 1
a1257 1
	sw_tdt = sc->next_avail_tx_desc;
d1260 1
a1260 1
		tx_desc = &sc->tx_desc_base[hw_tdt];
d1263 1
a1263 1
		if (++hw_tdt == sc->num_tx_desc)
d1833 1
a1833 1
	IFQ_SET_MAXLEN(&ifp->if_snd, sc->num_tx_desc - 1);
d1900 7
a1906 7
	if (sc->rx_desc_base != NULL) {
		em_dma_free(sc, &sc->rxdma);
		sc->rx_desc_base = NULL;
	}
	if (sc->tx_desc_base != NULL) {
		em_dma_free(sc, &sc->txdma);
		sc->tx_desc_base = NULL;
d2058 2
a2059 2
	bus_dmamap_sync(sc->sc_dmat, sc->txdma.dma_map,
	    0, sc->txdma.dma_map->dm_mapsize,
d2062 1
a2062 1
	if (!(sc->tx_buffer_area = mallocarray(sc->num_tx_desc,
d2086 2
a2087 2
	bzero((void *) sc->tx_desc_base,
	      (sizeof(struct em_tx_desc)) * sc->num_tx_desc);
d2089 2
a2090 2
	tx_buffer = sc->tx_buffer_area;
	for (i = 0; i < sc->num_tx_desc; i++) {
d2102 2
a2103 2
	sc->next_avail_tx_desc = 0;
	sc->next_tx_to_clean = 0;
d2106 1
a2106 1
	sc->num_tx_desc_avail = sc->num_tx_desc;
d2132 1
a2132 1
	bus_addr = sc->txdma.dma_map->dm_segs[0].ds_addr;
d2134 1
a2134 1
			sc->num_tx_desc *
d2176 1
a2176 1
	sc->txd_cmd = E1000_TXD_CMD_IFCS;
d2185 1
a2185 1
		sc->txd_cmd |= E1000_TXD_CMD_IDE;
d2213 3
a2215 3
	if (sc->tx_buffer_area != NULL) {
		tx_buffer = sc->tx_buffer_area;
		for (i = 0; i < sc->num_tx_desc; i++, tx_buffer++) {
d2235 4
a2238 4
	if (sc->tx_buffer_area != NULL) {
		free(sc->tx_buffer_area, M_DEVBUF,
		    sc->num_tx_desc * sizeof(struct em_buffer));
		sc->tx_buffer_area = NULL;
d2241 2
a2242 2
	bus_dmamap_sync(sc->sc_dmat, sc->txdma.dma_map,
	    0, sc->txdma.dma_map->dm_mapsize,
d2290 3
a2292 3
	curr_txd = sc->next_avail_tx_desc;
	tx_buffer = &sc->tx_buffer_area[curr_txd];
	TXD = (struct em_context_desc *) &sc->tx_desc_base[curr_txd];
d2315 1
a2315 1
	TXD->cmd_and_length = htole32(sc->txd_cmd | E1000_TXD_CMD_DEXT);
d2320 1
a2320 1
	if (++curr_txd == sc->num_tx_desc)
d2323 2
a2324 2
	atomic_dec_int(&sc->num_tx_desc_avail);
	sc->next_avail_tx_desc = curr_txd;
d2342 1
a2342 1
	if (sc->num_tx_desc_avail == sc->num_tx_desc)
d2345 3
a2347 3
	first = sc->next_tx_to_clean;
	tx_desc = &sc->tx_desc_base[first];
	tx_buffer = &sc->tx_buffer_area[first];
d2349 1
a2349 1
	eop_desc = &sc->tx_desc_base[last];
d2357 1
a2357 1
	if (++last == sc->num_tx_desc)
d2361 2
a2362 2
	bus_dmamap_sync(sc->sc_dmat, sc->txdma.dma_map,
	    0, sc->txdma.dma_map->dm_mapsize,
d2386 1
a2386 1
			if (++first == sc->num_tx_desc)
d2389 2
a2390 2
			tx_buffer = &sc->tx_buffer_area[first];
			tx_desc = &sc->tx_desc_base[first];
d2395 1
a2395 1
			eop_desc = &sc->tx_desc_base[last];
d2397 1
a2397 1
			if (++last == sc->num_tx_desc)
d2403 2
a2404 2
	bus_dmamap_sync(sc->sc_dmat, sc->txdma.dma_map,
	    0, sc->txdma.dma_map->dm_mapsize,
d2407 1
a2407 1
	sc->next_tx_to_clean = first;
d2409 1
a2409 1
	num_avail = atomic_add_int_nv(&sc->num_tx_desc_avail, free);
d2413 1
a2413 1
	else if (num_avail == sc->num_tx_desc)
d2430 2
a2431 2
	pkt = &sc->rx_buffer_area[i];
	desc = &sc->rx_desc_base[i];
d2479 2
a2480 2
	bus_dmamap_sync(sc->sc_dmat, sc->rxdma.dma_map,
	    0, sc->rxdma.dma_map->dm_mapsize,
d2483 1
a2483 1
	if (!(sc->rx_buffer_area = mallocarray(sc->num_rx_desc,
d2490 2
a2491 2
	rx_buffer = sc->rx_buffer_area;
	for (i = 0; i < sc->num_rx_desc; i++, rx_buffer++) {
d2521 2
a2522 2
	memset(sc->rx_desc_base, 0,
	    sizeof(struct em_rx_desc) * sc->num_rx_desc);
d2528 2
a2529 2
	sc->next_rx_desc_to_check = 0;
	sc->last_rx_desc_filled = sc->num_rx_desc - 1;
d2532 1
a2532 1
	if_rxr_init(&sc->rx_ring, lwm, sc->num_rx_desc);
d2573 2
a2574 2
	bus_addr = sc->rxdma.dma_map->dm_segs[0].ds_addr;
	E1000_WRITE_REG(&sc->hw, RDLEN, sc->num_rx_desc *
d2595 1
a2595 1
	switch (sc->rx_buffer_len) {
d2642 1
a2642 1
	E1000_WRITE_REG(&sc->hw, RDT, sc->last_rx_desc_filled);
d2658 1
a2658 1
	if_rxr_init(&sc->rx_ring, 0, 0);
d2660 2
a2661 2
	bus_dmamap_sync(sc->sc_dmat, sc->rxdma.dma_map,
	    0, sc->rxdma.dma_map->dm_mapsize,
d2664 3
a2666 3
	if (sc->rx_buffer_area != NULL) {
		rx_buffer = sc->rx_buffer_area;
		for (i = 0; i < sc->num_rx_desc; i++, rx_buffer++) {
d2678 4
a2681 4
	if (sc->rx_buffer_area != NULL) {
		free(sc->rx_buffer_area, M_DEVBUF,
		    sc->num_rx_desc * sizeof(struct em_buffer));
		sc->rx_buffer_area = NULL;
d2698 1
a2698 1
	i = sc->last_rx_desc_filled;
d2700 2
a2701 2
	bus_dmamap_sync(sc->sc_dmat, sc->rxdma.dma_map,
	    0, sc->rxdma.dma_map->dm_mapsize,
d2704 1
a2704 1
	for (slots = if_rxr_get(&sc->rx_ring, sc->num_rx_desc);
d2706 1
a2706 1
		if (++i == sc->num_rx_desc)
d2712 1
a2712 1
		sc->last_rx_desc_filled = i;
d2716 1
a2716 1
	if_rxr_put(&sc->rx_ring, slots);
d2718 2
a2719 2
	bus_dmamap_sync(sc->sc_dmat, sc->rxdma.dma_map,
	    0, sc->rxdma.dma_map->dm_mapsize,
d2748 1
a2748 1
	if (if_rxr_inuse(&sc->rx_ring) == 0)
d2751 1
a2751 1
	i = sc->next_rx_desc_to_check;
d2753 2
a2754 2
	bus_dmamap_sync(sc->sc_dmat, sc->rxdma.dma_map,
	    0, sc->rxdma.dma_map->dm_mapsize,
d2760 2
a2761 2
		desc = &sc->rx_desc_base[i];
		pkt = &sc->rx_buffer_area[i];
d2777 2
a2778 2
			    if_rxr_inuse(&sc->rx_ring),
			    sc->last_rx_desc_filled);
d2781 1
a2781 1
		if_rxr_put(&sc->rx_ring, 1);
d2877 1
a2877 1
		if (++i == sc->num_rx_desc)
d2879 1
a2879 1
	} while (if_rxr_inuse(&sc->rx_ring) > 0);
d2881 2
a2882 2
	bus_dmamap_sync(sc->sc_dmat, sc->rxdma.dma_map,
	    0, sc->rxdma.dma_map->dm_mapsize,
d2885 1
a2885 1
	sc->next_rx_desc_to_check = i;
@


1.321
log
@unify the bus_dmamap_sync calls around the tx and rx rings.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.320 2016/01/07 06:20:38 dlg Exp $ */
a2456 4
	bus_dmamap_sync(sc->sc_dmat, sc->rxdma.dma_map,
	    sizeof(*desc) * i, sizeof(*desc),
	    BUS_DMASYNC_POSTWRITE);

a2459 4
	bus_dmamap_sync(sc->sc_dmat, sc->rxdma.dma_map,
	    sizeof(*desc) * i, sizeof(*desc),
	    BUS_DMASYNC_PREWRITE);

d2698 4
d2715 4
@


1.320
log
@simplify the calculation of the dmamem size for the tx and rx rings.

we dont user config of the ring size, especially before attach time,
and the dmamem api takes care of rounding up to PAGE_SIZE if it needs
to.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.319 2016/01/07 05:34:11 dlg Exp $ */
d585 2
a586 2
		bus_dmamap_sync(sc->sc_dmat, sc->txdma.dma_map, 0,
		    sc->txdma.dma_map->dm_mapsize,
d619 2
a620 2
		bus_dmamap_sync(sc->sc_dmat, sc->txdma.dma_map, 0,
		    sc->txdma.dma_map->dm_mapsize,
d1120 2
a1121 2
		bus_dmamap_sync(sc->sc_dmat, sc->txdma.dma_map, 0,
		    sc->txdma.dma_map->dm_mapsize,
d1223 2
a1224 2
		bus_dmamap_sync(sc->sc_dmat, sc->txdma.dma_map, 0,
		    sc->txdma.dma_map->dm_mapsize,
d2056 3
a2058 2
	bus_dmamap_sync(sc->sc_dmat, sc->txdma.dma_map, 0,
	    sc->txdma.dma_size, BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);
d2239 3
a2241 2
	bus_dmamap_sync(sc->sc_dmat, sc->txdma.dma_map, 0,
	    sc->txdma.dma_size, BUS_DMASYNC_POSTREAD | BUS_DMASYNC_POSTWRITE);
d2359 3
a2361 2
	bus_dmamap_sync(sc->sc_dmat, sc->txdma.dma_map, 0,
	    sc->txdma.dma_map->dm_mapsize, BUS_DMASYNC_POSTREAD);
d2401 3
a2403 3
	bus_dmamap_sync(sc->sc_dmat, sc->txdma.dma_map, 0,
	    sc->txdma.dma_map->dm_mapsize,
	    BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);
d2458 2
a2459 1
	    sizeof(*desc) * i, sizeof(*desc), BUS_DMASYNC_POSTWRITE);
d2465 2
a2466 1
	    sizeof(*desc) * i, sizeof(*desc), BUS_DMASYNC_PREWRITE);
d2485 2
a2486 2
	bus_dmamap_sync(sc->sc_dmat, sc->rxdma.dma_map, 0,
	    sc->rxdma.dma_map->dm_mapsize,
d2666 2
a2667 2
	bus_dmamap_sync(sc->sc_dmat, sc->rxdma.dma_map, 0,
	    sc->rxdma.dma_map->dm_mapsize,
d2752 1
a2752 1
	    0, sizeof(*desc) * sc->num_rx_desc,
d2880 1
a2880 1
	    0, sizeof(*desc) * sc->num_rx_desc,
@


1.319
log
@unify the dma tag into sc_dmat in em_softc.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.318 2016/01/07 04:37:53 dlg Exp $ */
a341 1
	int tsize, rsize;
a455 8
	if (sc->hw.mac_type >= em_82544)
	    tsize = EM_ROUNDUP(sc->num_tx_desc * sizeof(struct em_tx_desc),
		EM_MAX_TXD * sizeof(struct em_tx_desc));
	else
	    tsize = EM_ROUNDUP(sc->num_tx_desc * sizeof(struct em_tx_desc),
		EM_MAX_TXD_82543 * sizeof(struct em_tx_desc));
	tsize = EM_ROUNDUP(tsize, PAGE_SIZE);

d457 2
a458 1
	if (em_dma_malloc(sc, tsize, &sc->txdma)) {
a464 8
	if (sc->hw.mac_type >= em_82544)
	    rsize = EM_ROUNDUP(sc->num_rx_desc * sizeof(struct em_rx_desc),
		EM_MAX_RXD * sizeof(struct em_rx_desc));
	else
	    rsize = EM_ROUNDUP(sc->num_rx_desc * sizeof(struct em_rx_desc),
		EM_MAX_RXD_82543 * sizeof(struct em_rx_desc));
	rsize = EM_ROUNDUP(rsize, PAGE_SIZE);

d466 2
a467 1
	if (em_dma_malloc(sc, rsize, &sc->rxdma)) {
d472 1
a472 1
	sc->rx_desc_base = (struct em_rx_desc *) sc->rxdma.dma_vaddr;
@


1.318
log
@sprinkle DEVNAME
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.317 2016/01/07 04:30:45 dlg Exp $ */
d252 1
a252 2
int  em_dma_malloc(struct em_softc *, bus_size_t, struct em_dma_alloc *,
		   int);
d348 1
d466 1
a466 1
	if (em_dma_malloc(sc, tsize, &sc->txdma, BUS_DMA_NOWAIT)) {
d482 1
a482 1
	if (em_dma_malloc(sc, rsize, &sc->rxdma, BUS_DMA_NOWAIT)) {
d600 1
a600 1
		bus_dmamap_sync(sc->txdma.dma_tag, sc->txdma.dma_map, 0,
d634 1
a634 1
		bus_dmamap_sync(sc->txdma.dma_tag, sc->txdma.dma_map, 0,
d1118 1
a1118 1
	error = bus_dmamap_load_mbuf(sc->txtag, map, m_head, BUS_DMA_NOWAIT);
d1124 1
a1124 1
		    (error = bus_dmamap_load_mbuf(sc->txtag, map, m_head,
d1135 1
a1135 1
		bus_dmamap_sync(sc->txdma.dma_tag, sc->txdma.dma_map, 0,
d1214 1
a1214 1
	bus_dmamap_sync(sc->txtag, map, 0, map->dm_mapsize,
d1238 1
a1238 1
		bus_dmamap_sync(sc->txdma.dma_tag, sc->txdma.dma_map, 0,
d1912 9
a1920 2
	em_dma_free(sc, &sc->rxdma);
	em_dma_free(sc, &sc->txdma);
d2016 1
a2016 2
em_dma_malloc(struct em_softc *sc, bus_size_t size,
    struct em_dma_alloc *dma, int mapflags)
d2020 19
a2038 35
	dma->dma_tag = sc->osdep.em_pa.pa_dmat;
	r = bus_dmamap_create(dma->dma_tag, size, 1,
	    size, 0, BUS_DMA_NOWAIT, &dma->dma_map);
	if (r != 0) {
		printf("%s: em_dma_malloc: bus_dmamap_create failed; "
			"error %u\n", DEVNAME(sc), r);
		goto fail_0;
	}

	r = bus_dmamem_alloc(dma->dma_tag, size, PAGE_SIZE, 0, &dma->dma_seg,
	    1, &dma->dma_nseg, BUS_DMA_NOWAIT);
	if (r != 0) {
		printf("%s: em_dma_malloc: bus_dmammem_alloc failed; "
			"size %lu, error %d\n", DEVNAME(sc),
			(unsigned long)size, r);
		goto fail_1;
	}

	r = bus_dmamem_map(dma->dma_tag, &dma->dma_seg, dma->dma_nseg, size,
	    &dma->dma_vaddr, BUS_DMA_NOWAIT);
	if (r != 0) {
		printf("%s: em_dma_malloc: bus_dmammem_map failed; "
			"size %lu, error %d\n", DEVNAME(sc),
			(unsigned long)size, r);
		goto fail_2;
	}

	r = bus_dmamap_load(sc->osdep.em_pa.pa_dmat, dma->dma_map,
			    dma->dma_vaddr, size, NULL,
			    mapflags | BUS_DMA_NOWAIT);
	if (r != 0) {
		printf("%s: em_dma_malloc: bus_dmamap_load failed; "
			"error %u\n", DEVNAME(sc), r);
		goto fail_3;
	}
d2043 6
a2048 9
fail_3:
	bus_dmamem_unmap(dma->dma_tag, dma->dma_vaddr, size);
fail_2:
	bus_dmamem_free(dma->dma_tag, &dma->dma_seg, dma->dma_nseg);
fail_1:
	bus_dmamap_destroy(dma->dma_tag, dma->dma_map);
fail_0:
	dma->dma_map = NULL;
	dma->dma_tag = NULL;
d2056 4
a2059 13
	if (dma->dma_tag == NULL)
		return;

	if (dma->dma_map != NULL) {
		bus_dmamap_sync(dma->dma_tag, dma->dma_map, 0,
		    dma->dma_map->dm_mapsize,
		    BUS_DMASYNC_POSTREAD | BUS_DMASYNC_POSTWRITE);
		bus_dmamap_unload(dma->dma_tag, dma->dma_map);
		bus_dmamem_unmap(dma->dma_tag, dma->dma_vaddr, dma->dma_size);
		bus_dmamem_free(dma->dma_tag, &dma->dma_seg, dma->dma_nseg);
		bus_dmamap_destroy(dma->dma_tag, dma->dma_map);
	}
	dma->dma_tag = NULL;
d2071 3
a2100 2
	sc->txtag = sc->osdep.em_pa.pa_dmat;

d2103 1
a2103 1
		error = bus_dmamap_create(sc->txtag, MAX_JUMBO_FRAME_SIZE,
a2121 2
	bus_dmamap_sync(sc->txdma.dma_tag, sc->txdma.dma_map, 0,
	    sc->txdma.dma_size, BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);
d2230 1
a2230 1
				bus_dmamap_sync(sc->txtag, tx_buffer->map,
d2233 1
a2233 1
				bus_dmamap_unload(sc->txtag,
d2241 1
a2241 1
				bus_dmamap_destroy(sc->txtag,
d2252 3
a2254 2
	if (sc->txtag != NULL)
		sc->txtag = NULL;
d2372 1
a2372 1
	bus_dmamap_sync(sc->txdma.dma_tag, sc->txdma.dma_map, 0,
d2384 1
a2384 1
					bus_dmamap_sync(sc->txtag,
d2388 1
a2388 1
					bus_dmamap_unload(sc->txtag,
d2413 1
a2413 1
	bus_dmamap_sync(sc->txdma.dma_tag, sc->txdma.dma_map, 0,
d2459 1
a2459 1
	error = bus_dmamap_load_mbuf(sc->rxtag, pkt->map, m, BUS_DMA_NOWAIT);
d2465 1
a2465 1
	bus_dmamap_sync(sc->rxtag, pkt->map, 0, pkt->map->dm_mapsize,
d2469 1
a2469 1
	bus_dmamap_sync(sc->rxdma.dma_tag, sc->rxdma.dma_map,
d2475 1
a2475 1
	bus_dmamap_sync(sc->rxdma.dma_tag, sc->rxdma.dma_map,
d2495 4
a2505 2
	sc->rxtag = sc->osdep.em_pa.pa_dmat;

d2508 1
a2508 1
		error = bus_dmamap_create(sc->rxtag, EM_MCLBYTES, 1,
a2517 3
	bus_dmamap_sync(sc->rxdma.dma_tag, sc->rxdma.dma_map, 0,
	    sc->rxdma.dma_map->dm_mapsize,
	    BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);
d2676 4
d2684 1
a2684 1
				bus_dmamap_sync(sc->rxtag, rx_buffer->map,
d2687 1
a2687 1
				bus_dmamap_unload(sc->rxtag, rx_buffer->map);
d2691 1
a2691 1
			bus_dmamap_destroy(sc->rxtag, rx_buffer->map);
a2698 2
	if (sc->rxtag != NULL)
		sc->rxtag = NULL;
d2761 1
a2761 1
	bus_dmamap_sync(sc->rxdma.dma_tag, sc->rxdma.dma_map,
d2776 1
a2776 1
		bus_dmamap_sync(sc->rxtag, pkt->map, 0, pkt->map->dm_mapsize,
d2778 1
a2778 1
		bus_dmamap_unload(sc->rxtag, pkt->map);
d2889 1
a2889 1
	bus_dmamap_sync(sc->rxdma.dma_tag, sc->rxdma.dma_map,
@


1.317
log
@rename the struct arpcom interface_data in em_softc to sc_ac.

makes it more consistent with the rest of the tree.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.316 2016/01/07 04:21:36 dlg Exp $ */
d303 1
a303 1
		    sc->sc_dev.dv_xname);
d468 1
a468 1
		       sc->sc_dev.dv_xname);
d484 1
a484 1
		       sc->sc_dev.dv_xname);
d495 1
a495 1
			    sc->sc_dev.dv_xname);
d528 1
a528 1
		       sc->sc_dev.dv_xname);
d552 1
a552 1
		    sc->sc_dev.dv_xname);
d693 1
a693 1
			    sc->sc_dev.dv_xname);
d745 1
a745 1
	    sc->sc_dev.dv_xname, sc->next_tx_to_clean,
d850 1
a850 1
		       sc->sc_dev.dv_xname);
d863 1
a863 1
		       sc->sc_dev.dv_xname);
d873 1
a873 1
		       sc->sc_dev.dv_xname);
d1045 1
a1045 1
		printf("%s: Unsupported media type\n", sc->sc_dev.dv_xname);
d1570 1
a1570 1
		printf("%s: Unknown MAC Type\n", sc->sc_dev.dv_xname);
d1662 1
a1662 1
	    em_intr, sc, sc->sc_dev.dv_xname);
d1752 1
a1752 1
			       sc->sc_dev.dv_xname);
d1760 1
a1760 1
		       sc->sc_dev.dv_xname);
d1814 1
a1814 1
		       sc->sc_dev.dv_xname);
d1837 1
a1837 1
	strlcpy(ifp->if_xname, sc->sc_dev.dv_xname, IFNAMSIZ);
d2019 1
a2019 1
			"error %u\n", sc->sc_dev.dv_xname, r);
d2027 1
a2027 1
			"size %lu, error %d\n", sc->sc_dev.dv_xname,
d2036 1
a2036 1
			"size %lu, error %d\n", sc->sc_dev.dv_xname,
d2046 1
a2046 1
			"error %u\n", sc->sc_dev.dv_xname, r);
d2096 1
a2096 1
		       sc->sc_dev.dv_xname);
d2129 1
a2129 1
			    sc->sc_dev.dv_xname);
d2467 1
a2467 1
		    sc->sc_dev.dv_xname, i);
d2520 1
a2520 1
		       sc->sc_dev.dv_xname);
d2533 1
a2533 1
			    sc->sc_dev.dv_xname, error);
d2575 1
a2575 1
		    sc->sc_dev.dv_xname);
d3275 1
a3275 1
	const char * const unit = sc->sc_dev.dv_xname;
@


1.316
log
@rename em_softc sc_dv to sc_dev. like ALL OUR OTHER DRIVERS.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.315 2016/01/07 03:56:03 dlg Exp $ */
d532 1
a532 2
	bcopy(sc->hw.mac_addr, sc->interface_data.ac_enaddr,
	    ETHER_ADDR_LEN);
d547 1
a547 1
	printf(", address %s\n", ether_sprintf(sc->interface_data.ac_enaddr));
d707 1
a707 1
		error = ether_ioctl(ifp, &sc->interface_data, command, data);
d768 1
a768 1
	struct ifnet   *ifp = &sc->interface_data.ac_if;
d845 1
a845 2
	bcopy(sc->interface_data.ac_enaddr, sc->hw.mac_addr,
	      ETHER_ADDR_LEN);
d905 1
a905 1
	struct ifnet	*ifp = &sc->interface_data.ac_if;
d1373 2
a1374 2
	struct ifnet *ifp = &sc->interface_data.ac_if;
	struct arpcom *ac = &sc->interface_data;
d1440 1
a1440 1
	ifp = &sc->interface_data.ac_if;
d1461 1
a1461 1
	struct ifnet *ifp = &sc->interface_data.ac_if;
d1515 1
a1515 1
	struct ifnet   *ifp = &sc->interface_data.ac_if;
d1836 1
a1836 1
	ifp = &sc->interface_data.ac_if;
d1901 1
a1901 1
	struct ifnet *ifp = &sc->interface_data.ac_if;
d1925 1
a1925 1
	struct ifnet *ifp = &sc->interface_data.ac_if;
d2373 1
a2373 1
	struct ifnet   *ifp = &sc->interface_data.ac_if;
d2557 1
a2557 1
	struct ifnet *ifp = &sc->interface_data.ac_if;
d2764 1
a2764 1
	struct ifnet	    *ifp = &sc->interface_data.ac_if;
d3160 1
a3160 1
	struct ifnet   *ifp = &sc->interface_data.ac_if;
@


1.315
log
@tweak em to make it mpsafe, both for interrupts and if_start.

this is mostly work by kettenis and claudio, with further work from
me to make the transmit side from the stack mpsafe.

there's a watchdog issue that will be worked on in tree after this
change.

tested by hrvoje popovski and gregor best
ok mpi@@ claudio@@ deraadt@@ jmatthew@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.314 2015/12/31 14:20:25 dlg Exp $ */
d303 1
a303 1
		    sc->sc_dv.dv_xname);
d468 1
a468 1
		       sc->sc_dv.dv_xname);
d484 1
a484 1
		       sc->sc_dv.dv_xname);
d495 1
a495 1
			    sc->sc_dv.dv_xname);
d528 1
a528 1
		       sc->sc_dv.dv_xname);
d553 1
a553 1
		    sc->sc_dv.dv_xname);
d694 1
a694 1
			    sc->sc_dv.dv_xname);
d746 1
a746 1
	    sc->sc_dv.dv_xname, sc->next_tx_to_clean,
d852 1
a852 1
		       sc->sc_dv.dv_xname);
d865 1
a865 1
		       sc->sc_dv.dv_xname);
d875 1
a875 1
		       sc->sc_dv.dv_xname);
d1047 1
a1047 1
		printf("%s: Unsupported media type\n", sc->sc_dv.dv_xname);
d1572 1
a1572 1
		printf("%s: Unknown MAC Type\n", sc->sc_dv.dv_xname);
d1664 1
a1664 1
	    em_intr, sc, sc->sc_dv.dv_xname);
d1754 1
a1754 1
			       sc->sc_dv.dv_xname);
d1762 1
a1762 1
		       sc->sc_dv.dv_xname);
d1816 1
a1816 1
		       sc->sc_dv.dv_xname);
d1839 1
a1839 1
	strlcpy(ifp->if_xname, sc->sc_dv.dv_xname, IFNAMSIZ);
d2021 1
a2021 1
			"error %u\n", sc->sc_dv.dv_xname, r);
d2029 1
a2029 1
			"size %lu, error %d\n", sc->sc_dv.dv_xname,
d2038 1
a2038 1
			"size %lu, error %d\n", sc->sc_dv.dv_xname,
d2048 1
a2048 1
			"error %u\n", sc->sc_dv.dv_xname, r);
d2098 1
a2098 1
		       sc->sc_dv.dv_xname);
d2131 1
a2131 1
			    sc->sc_dv.dv_xname);
d2469 1
a2469 1
		    sc->sc_dv.dv_xname, i);
d2522 1
a2522 1
		       sc->sc_dv.dv_xname);
d2535 1
a2535 1
			    sc->sc_dv.dv_xname, error);
d2577 1
a2577 1
		    sc->sc_dv.dv_xname);
d3277 1
a3277 1
	const char * const unit = sc->sc_dv.dv_xname;
@


1.314
log
@82544 on pcix busses needs a workaround that effectively doubles
the possible number of slots a packet can use on the tx ring.

to make it easier to reserve and account for space on the ring,
half the number of dma descriptors on those chips so the number of
slots can stay the same.

ok claudio@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.313 2015/11/25 03:09:59 dlg Exp $ */
d233 1
a233 1
void em_rxeof(struct em_softc *);
a590 1
	struct mbuf    *m_head;
d592 2
a593 1
	int		post = 0;
d595 2
a596 4
	if (!(ifp->if_flags & IFF_RUNNING) || ifq_is_oactive(&ifp->if_snd))
		return;

	if (!sc->link_active)
d598 1
d607 2
a608 2
		m_head = ifq_deq_begin(&ifp->if_snd);
		if (m_head == NULL)
d610 1
d612 2
a613 3
		if (em_encap(sc, m_head)) {
			ifq_deq_rollback(&ifp->if_snd, m_head);
			ifq_set_oactive(&ifp->if_snd);
d615 5
a621 2
		ifq_deq_commit(&ifp->if_snd, m_head);

d625 1
a625 1
			bpf_mtap_ether(ifp->if_bpf, m_head, BPF_DIRECTION_OUT);
d745 4
a748 1
	printf("%s: watchdog timeout -- resetting\n", sc->sc_dv.dv_xname);
a908 1
	int		refill = 0;
a916 1
		em_rxeof(sc);
d918 7
a924 1
		refill = 1;
a926 5
	if (reg_icr & E1000_ICR_RXO)
		sc->rx_overruns++;

	KERNEL_LOCK();

d929 1
d933 1
a933 10
	}

	if (ifp->if_flags & IFF_RUNNING && !IFQ_IS_EMPTY(&ifp->if_snd))
		em_start(ifp);

	KERNEL_UNLOCK();

	if (refill && em_rxfill(sc)) {
		/* Advance the Rx Queue #0 "Tail Pointer". */
		E1000_WRITE_REG(&sc->hw, RDT, sc->last_rx_desc_filled);
d1095 1
a1095 1
	u_int32_t	txd_lower, txd_used = 0, txd_saved = 0;
a1107 19
	 * Force a cleanup if number of TX descriptors
	 * available hits the threshold
	 */
	if (sc->num_tx_desc_avail <= EM_TX_CLEANUP_THRESHOLD) {
		em_txeof(sc);
		/* Now do we at least have a minimal? */
		if (sc->num_tx_desc_avail <= EM_TX_OP_THRESHOLD) {
			sc->no_tx_desc_avail1++;
			return (ENOBUFS);
		}
	}

	if (sc->hw.mac_type == em_82547) {
		bus_dmamap_sync(sc->txdma.dma_tag, sc->txdma.dma_map, 0,
		    sc->txdma.dma_map->dm_mapsize,
		    BUS_DMASYNC_POSTREAD | BUS_DMASYNC_POSTWRITE);
	}

	/*
d1133 1
a1133 1
		goto loaderr;
d1136 5
a1140 4
	EM_KASSERT(map->dm_nsegs!= 0, ("em_encap: empty packet"));

	if (map->dm_nsegs > sc->num_tx_desc_avail - 2)
		goto fail;
a1149 2
	if (sc->pcix_82544)
		txd_saved = i;
d1158 3
a1160 3
			array_elements = em_fill_descriptors(map->dm_segs[j].ds_addr,
							     map->dm_segs[j].ds_len,
							     &desc_array);
a1161 4
				if (txd_used == sc->num_tx_desc_avail) {
					sc->next_avail_tx_desc = txd_saved;
					goto fail;
				}
d1197 1
a1197 1
		sc->num_tx_desc_avail -= txd_used;
d1199 1
a1199 1
		sc->num_tx_desc_avail -= map->dm_nsegs;
a1251 12

fail:
	sc->no_tx_desc_avail2++;
	bus_dmamap_unload(sc->txtag, map);
	error = ENOBUFS;
loaderr:
	if (sc->hw.mac_type == em_82547) {
		bus_dmamap_sync(sc->txdma.dma_tag, sc->txdma.dma_map, 0,
		    sc->txdma.dma_map->dm_mapsize,
		    BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);
	}
	return (error);
a1520 2
	ifq_clr_oactive(&ifp->if_snd);
	ifp->if_timer = 0;
d1533 1
d1537 3
d1842 1
d2358 1
a2358 1
	sc->num_tx_desc_avail--;
d2372 1
a2372 1
	int first, last, done, num_avail;
a2379 3
	KERNEL_LOCK();

	num_avail = sc->num_tx_desc_avail;
d2403 1
a2403 1
			num_avail++;
d2443 1
a2443 8
	/*
	 * If we have enough room, clear IFF_OACTIVE to tell the stack
	 * that it is OK to send packets.
	 * If there are no pending descriptors, clear the timeout. Otherwise,
	 * if some descriptors have been freed, restart the timeout.
	 */
	if (num_avail > EM_TX_CLEANUP_THRESHOLD)
		ifq_clr_oactive(&ifp->if_snd);
d2445 3
a2447 2
	/* All clean, turn off the timer */
	if (num_avail == sc->num_tx_desc)
a2448 7
	/* Some cleaned, reset the timer */
	else if (num_avail != sc->num_tx_desc_avail)
		ifp->if_timer = EM_TX_TIMEOUT;

	sc->num_tx_desc_avail = num_avail;

	KERNEL_UNLOCK();
d2763 1
a2763 1
void
d2772 1
a2772 1
	int		    i;
d2780 1
a2780 1
		return;
d2813 1
d2919 2
@


1.313
log
@replace IFF_OACTIVE manipulation with mpsafe operations.

there are two things shared between the network stack and drivers
in the send path: the send queue and the IFF_OACTIVE flag. the send
queue is now protected by a mutex. this diff makes the oactive
functionality mpsafe too.

IFF_OACTIVE is part of if_flags. there are two problems with that.
firstly, if_flags is a short and we dont have any MI atomic operations
to manipulate a short. secondly, while we could make the IFF_OACTIVE
operates mpsafe, all changes to other flags would have to be made
safe at the same time, otherwise a read-modify-write cycle on their
updates could clobber the oactive change.

instead, this moves the oactive mark into struct ifqueue and provides
an API for changing it. there's ifq_set_oactive, ifq_clr_oactive,
and ifq_is_oactive. these are modelled on ifsq_set_oactive,
ifsq_clr_oactive, and ifsq_is_oactive in dragonflybsd.

this diff includes changes to all the drivers manipulating IFF_OACTIVE
to now use the ifsq_{set,clr_is}_oactive API too.

ok kettenis@@ mpi@@ jmatthew@@ deraadt@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.312 2015/11/20 13:11:16 mpi Exp $ */
d2164 2
a2165 2
			    EM_MAX_SCATTER, MAX_JUMBO_FRAME_SIZE, 0,
			    BUS_DMA_NOWAIT, &tx_buffer->map);
@


1.312
log
@Revert all the changes to run the tx completion path wihtout holding the
KERNE_LOCK.

A piece is still not right as many peole reported a "watchdog timeout"
problem.

This basically brings us back to r1.305.

ok dlg@@, jmatthew@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.311 2015/11/20 03:35:23 dlg Exp $ */
d595 1
a595 1
	if ((ifp->if_flags & (IFF_OACTIVE | IFF_RUNNING)) != IFF_RUNNING)
d614 1
a614 1
			ifp->if_flags |= IFF_OACTIVE;
d881 1
a881 1
	ifp->if_flags &= ~IFF_OACTIVE;
d1560 2
a1561 1
	ifp->if_flags &= ~(IFF_RUNNING | IFF_OACTIVE);
d2490 1
a2490 1
		ifp->if_flags &= ~IFF_OACTIVE;
@


1.311
log
@shuffle struct ifqueue so in flight mbufs are protected by a mutex.

the code is refactored so the IFQ macros call newly implemented ifq
functions. the ifq code is split so each discipline (priq and hfsc
in our case) is an opaque set of operations that the common ifq
code can call. the common code does the locking, accounting (ifq_len
manipulation), and freeing of the mbuf if the disciplines enqueue
function rejects it. theyre kind of like bufqs in the block layer
with their fifo and nscan disciplines.

the new api also supports atomic switching of disciplines at runtime.
the hfsc setup in pf_ioctl.c has been tweaked to build a complete
hfsc_if structure which it attaches to the send queue in a single
operation, rather than attaching to the interface up front and
building up a list of queues.

the send queue is now mutexed, which raises the expectation that
packets can be enqueued or purged on one cpu while another cpu is
dequeueing them in a driver for transmission. a lot of drivers use
IFQ_POLL to peek at an mbuf and attempt to fit it on the ring before
committing to it with a later IFQ_DEQUEUE operation. if the mbuf
gets freed in between the POLL and DEQUEUE operations, fireworks
will ensue.

to avoid this, the ifq api introduces ifq_deq_begin, ifq_deq_rollback,
and ifq_deq_commit. ifq_deq_begin allows a driver to take the ifq
mutex and get a reference to the mbuf they wish to try and tx. if
there's space, they can ifq_deq_commit it to remove the mbuf and
release the mutex. if there's no space, ifq_deq_rollback simply
releases the mutex. this api was developed to make updating the
drivers using IFQ_POLL easy, instead of having to do significant
semantic changes to avoid POLL that we cannot test on all the
hardware.

the common code has been tested pretty hard, and all the driver
modifications are straightforward except for de(4). if that breaks
it can be dealt with later.

ok mpi@@ jmatthew@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.310 2015/10/29 03:19:42 jsg Exp $ */
d921 2
a924 1
		KERNEL_LOCK();
a927 3
		if (!IFQ_IS_EMPTY(&ifp->if_snd))
			em_start(ifp);
		KERNEL_UNLOCK();
d930 5
d1111 11
a1121 4
	/* Check that we have least the minimal number of TX descriptors. */
	if (sc->num_tx_desc_avail <= EM_TX_OP_THRESHOLD) {
		sc->no_tx_desc_avail1++;
		return (ENOBUFS);
d1223 6
a1261 8
	membar_producer();

	sc->next_avail_tx_desc = i;
	if (sc->pcix_82544)
		atomic_sub_int(&sc->num_tx_desc_avail, txd_used);
	else
		atomic_sub_int(&sc->num_tx_desc_avail, map->dm_nsegs);

a2390 2
	membar_producer();

d2394 1
a2394 1
	atomic_dec_int(&sc->num_tx_desc_avail);
d2408 1
a2408 1
	int first, last, done, num_avail, free = 0;
d2416 1
a2416 1
	membar_consumer();
d2418 1
d2442 1
a2442 1
			free++;
d2482 8
a2489 1
	num_avail = atomic_add_int_nv(&sc->num_tx_desc_avail, free);
d2494 3
d2498 3
a2500 11
	/*
	 * If we have enough room, clear IFF_OACTIVE to tell the stack
	 * that it is OK to send packets.
	 */
	if (ISSET(ifp->if_flags, IFF_OACTIVE) &&
	    num_avail > EM_TX_OP_THRESHOLD) {
		KERNEL_LOCK();
		CLR(ifp->if_flags, IFF_OACTIVE);
		em_start(ifp);
		KERNEL_UNLOCK();
	}
@


1.310
log
@fix newlines on an error message
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.309 2015/10/25 13:04:28 mpi Exp $ */
d608 1
a608 1
		IFQ_POLL(&ifp->if_snd, m_head);
d613 1
d618 1
a618 1
		IFQ_DEQUEUE(&ifp->if_snd, m_head);
@


1.309
log
@arp_ifinit() is no longer needed.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.308 2015/10/08 09:21:26 kettenis Exp $ */
d1843 1
a1843 1
		printf("%s: Hardware Initialization Failed",
@


1.308
log
@Call em_start() when we detect a link state change such that packets start
flowing again even if the send queue is currently full.  Restores the fix
made by makeb@@ in rev 1.263 which was lost in making the tx completion path
mpsafe.

ok mikeb@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.307 2015/10/06 15:21:16 kettenis Exp $ */
a658 1
	struct ifaddr  *ifa = (struct ifaddr *)data;
a671 2
		if (ifa->ifa_addr->sa_family == AF_INET)
			arp_ifinit(&sc->interface_data, ifa);
@


1.307
log
@Make sure that tx_buffer->next_eop is properly set before we bump the number
of available descriptors, such that the interrupt handler doesn't attempt
to complete partially initialized descriptors.  Seems to fix the watchdog
timeouts reported by various people.

Tested by Mattieu Baptiste and Gregor Best.
ok mikeb@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.306 2015/09/30 11:25:08 kettenis Exp $ */
d929 2
@


1.306
log
@Run the tx completion path without the kernel held.  This makes the
"fast path" through the interrupt handler not grab the kernel lock anymore.
This removes the code that attempts to reclaim tx descriptors from em_start().
Keeping that code would have complicated the locking.  The need to reclaim
tx descriptors that way should have largely disappeared now that the interrupt
handler doesn't have to wait on the kernel lock.

ok mpi@@
tested by many
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.305 2015/09/19 12:48:26 kettenis Exp $ */
a1212 6
	sc->next_avail_tx_desc = i;
	if (sc->pcix_82544)
		atomic_sub_int(&sc->num_tx_desc_avail, txd_used);
	else
		atomic_sub_int(&sc->num_tx_desc_avail, map->dm_nsegs);

d1246 8
d2383 2
d2409 2
@


1.305
log
@Avoid using a mutex in the rx completion path.  Instead rely on
intr_barrier(9) to avoid having the interrupt handler touch the rx data
structures while we're brining down the interface.  This actually reverts
many of the changes in rev. 1.300.

ok mikeb@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.304 2015/09/11 13:02:28 stsp Exp $ */
a922 2
	KERNEL_LOCK();

d925 1
d929 1
a931 5
	if (ifp->if_flags & IFF_RUNNING && !IFQ_IS_EMPTY(&ifp->if_snd))
		em_start(ifp);

	KERNEL_UNLOCK();

d1108 4
a1111 11
	/*
	 * Force a cleanup if number of TX descriptors
	 * available hits the threshold
	 */
	if (sc->num_tx_desc_avail <= EM_TX_CLEANUP_THRESHOLD) {
		em_txeof(sc);
		/* Now do we at least have a minimal? */
		if (sc->num_tx_desc_avail <= EM_TX_OP_THRESHOLD) {
			sc->no_tx_desc_avail1++;
			return (ENOBUFS);
		}
d1215 1
a1215 1
		sc->num_tx_desc_avail -= txd_used;
d1217 1
a1217 1
		sc->num_tx_desc_avail -= map->dm_nsegs;
d2384 1
a2384 1
	sc->num_tx_desc_avail--;
d2398 1
a2398 1
	int first, last, done, num_avail;
a2405 3
	KERNEL_LOCK();

	num_avail = sc->num_tx_desc_avail;
d2429 1
a2429 1
			num_avail++;
d2469 1
a2469 8
	/*
	 * If we have enough room, clear IFF_OACTIVE to tell the stack
	 * that it is OK to send packets.
	 * If there are no pending descriptors, clear the timeout. Otherwise,
	 * if some descriptors have been freed, restart the timeout.
	 */
	if (num_avail > EM_TX_CLEANUP_THRESHOLD)
		ifp->if_flags &= ~IFF_OACTIVE;
a2473 3
	/* Some cleaned, reset the timer */
	else if (num_avail != sc->num_tx_desc_avail)
		ifp->if_timer = EM_TX_TIMEOUT;
d2475 11
a2485 3
	sc->num_tx_desc_avail = num_avail;

	KERNEL_UNLOCK();
@


1.304
log
@Make room for media types of the future. Extend the ifmedia word to 64 bits.
This changes numbers of the SIOCSIFMEDIA and SIOCGIFMEDIA ioctls and
grows struct ifmediareq.

Old ifconfig and dhclient binaries can still assign addresses, however
the 'media' subcommand stops working. Recompiling ifconfig and dhclient
with new headers before a reboot should not be necessary unless in very
special circumstances where non-default media settings must be used to
get link and console access is not available.

There may be some MD fallout but that will be cleared up later.

ok deraadt miod
with help and suggestions from several sharks attending l2k15
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.303 2015/09/01 09:48:50 mpi Exp $ */
a350 2
	mtx_init(&sc->rx_mtx, IPL_NET);

d920 3
a931 5
	if (reg_icr & E1000_ICR_RXO) {
		sc->rx_overruns++;
		refill = 1;
	}

d935 2
a941 2
	KERNEL_UNLOCK();

d1575 4
a2752 1
	mtx_enter(&sc->rx_mtx);
a2753 1
	mtx_leave(&sc->rx_mtx);
a2790 2
	mtx_enter(&sc->rx_mtx);

a2806 2
	mtx_leave(&sc->rx_mtx);

a2821 1
	struct mbuf_list    free_ml = MBUF_LIST_INITIALIZER();
d2833 1
a2833 3
	mtx_enter(&sc->rx_mtx);
	if (if_rxr_inuse(&sc->rx_ring) == 0) {
		mtx_leave(&sc->rx_mtx);
a2834 1
	}
d2952 1
a2952 1
				ml_enqueue(&free_ml, sc->fmp);
d2957 1
a2957 1
			ml_enqueue(&free_ml, m);
a2969 5

	mtx_leave(&sc->rx_mtx);

	while ((m = ml_dequeue(&free_ml)))
		m_freem(m);
@


1.303
log
@Use the correct free(9) size for the RX ring.

ok dlg@@, phessler@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.302 2015/09/01 07:09:55 deraadt Exp $ */
d212 1
a212 1
int  em_flowstatus(struct em_softc *);
d961 1
a961 1
	u_char fiber_type = IFM_1000_SX;
d1071 1
a1071 1
int
d1873 1
a1873 1
	u_char fiber_type = IFM_1000_SX;
@


1.302
log
@sizes for free(), mostly related to firmwares.
ok dlg
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.301 2015/08/26 09:17:20 kettenis Exp $ */
d2773 1
a2773 1
		    sc->num_tx_desc * sizeof(struct em_buffer));
@


1.301
log
@Get rid if em_align.  This approach used to make sense, but now that the
hardware rx mtu always gets set to the maximum supported value we will hit
it for every received packet.  Instead, use a larger mbuf cluster size on
strict alignment architectures such that we can always m_adj to make sure the
packets are properly aligned.  This wastes some memory but simplifies things
considerably.  Hopefully we can reduce the spillage in the near future by
taking advantage of recent improvements in the pool code.

ok mpi@@, mikeb@@, dlg@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.300 2015/08/21 09:16:06 kettenis Exp $ */
d2311 2
a2312 1
		free(sc->tx_buffer_area, M_DEVBUF, 0);
d2772 2
a2773 1
		free(sc->rx_buffer_area, M_DEVBUF, 0);
@


1.300
log
@Run the part of the interrupt handler that does rx completion without holding
the kernel lock.

ok mpi@@, dlg@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.299 2015/06/24 09:40:54 mpi Exp $ */
a231 5
#ifdef __STRICT_ALIGNMENT
void em_realign(struct em_softc *, struct mbuf *, u_int16_t *);
#else
#define em_realign(a, b, c) /* a, b, c */
#endif
d706 1
a706 1
		    NULL, MCLBYTES, &sc->rx_ring);
d2526 1
a2526 1
	m = MCLGETI(NULL, M_DONTWAIT, NULL, MCLBYTES);
d2531 4
a2534 3
	m->m_len = m->m_pkthdr.len = MCLBYTES;
	if (sc->hw.max_frame_size <= (MCLBYTES - ETHER_ALIGN))
		m_adj(m, ETHER_ALIGN);
d2583 2
a2584 2
		error = bus_dmamap_create(sc->rxtag, MCLBYTES, 1,
		    MCLBYTES, 0, BUS_DMA_NOWAIT, &rx_buffer->map);
a2783 47
#ifdef __STRICT_ALIGNMENT
void
em_realign(struct em_softc *sc, struct mbuf *m, u_int16_t *prev_len_adj)
{
	unsigned char tmp_align_buf[ETHER_ALIGN];
	int tmp_align_buf_len = 0;

	/*
	 * The Ethernet payload is not 32-bit aligned when
	 * Jumbo packets are enabled, so on architectures with
	 * strict alignment we need to shift the entire packet
	 * ETHER_ALIGN bytes. Ugh.
	 */
	if (sc->hw.max_frame_size <= (MCLBYTES - ETHER_ALIGN))
		return;

	if (*prev_len_adj > sc->align_buf_len)
		*prev_len_adj -= sc->align_buf_len;
	else
		*prev_len_adj = 0;

	if (m->m_len > (MCLBYTES - ETHER_ALIGN)) {
		bcopy(m->m_data + (MCLBYTES - ETHER_ALIGN),
		    &tmp_align_buf, ETHER_ALIGN);
		tmp_align_buf_len = m->m_len -
		    (MCLBYTES - ETHER_ALIGN);
		m->m_len -= ETHER_ALIGN;
	} 

	if (m->m_len) {
		bcopy(m->m_data, m->m_data + ETHER_ALIGN, m->m_len);
		if (!sc->align_buf_len)
			m->m_data += ETHER_ALIGN;
	}

	if (sc->align_buf_len) {
		m->m_len += sc->align_buf_len;
		bcopy(&sc->align_buf, m->m_data, sc->align_buf_len);
	}

	if (tmp_align_buf_len) 
		bcopy(&tmp_align_buf, &sc->align_buf, tmp_align_buf_len);

	sc->align_buf_len = tmp_align_buf_len;
}
#endif /* __STRICT_ALIGNMENT */

a2917 2

			em_realign(sc, m, &prev_len_adj); /* STRICT_ALIGN */
@


1.299
log
@Increment if_ipackets in if_input().

Note that pseudo-drivers not using if_input() are not affected by this
conversion.

ok mikeb@@, kettenis@@, claudio@@, dlg@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.298 2015/06/04 18:33:41 dms Exp $ */
d356 2
d927 2
d949 2
d1707 2
a1708 2
	sc->sc_intrhand = pci_intr_establish(pc, ih, IPL_NET, em_intr, sc,
					      sc->sc_dv.dv_xname);
d2422 2
d2505 2
d2756 4
d2842 2
d2860 2
d2877 1
d2889 3
a2891 1
	if (if_rxr_inuse(&sc->rx_ring) == 0)
d2893 1
d3013 1
a3013 1
 				m_freem(sc->fmp);
d3018 1
a3018 1
			m_freem(m);
d3030 7
a3037 2

	sc->next_rx_desc_to_check = i;
@


1.298
log
@Add support for em(4) on Teak 3020, a Tolopai (EP80579)
based devices. This introduces Realtek PHY into em driver
code and is only a temporary solution to the problem.

OK deraadt@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.297 2015/05/12 20:20:18 kettenis Exp $ */
a2971 2
				ifp->if_ipackets++;

@


1.297
log
@Make sure the rx ring lwm is set to at least 4.  As far as we know, all
hardware variants need at least 4 descriptors on the rx ring to be able to
receive packets.  Should fix the issue reported by Christian Schulte on
bugs@@.

ok mikeb@@, sthen@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.296 2015/05/12 02:33:39 jsg Exp $ */
d190 4
a193 1
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_EP80579_LAN_3 }
d304 2
d329 1
a329 1
	em_update_link_status(sc);		
d331 1
a331 1
	em_setup_link(&sc->hw);			
@


1.296
log
@The i211 does not support an external EEPROM only a OTP
Internal Non-Volatile Memory (iNVM).  Add support for reading
words out of it instead of an EEPROM.

From Patrick Wildt with some more offsets added.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.295 2015/02/11 23:21:47 brad Exp $ */
d2602 1
d2614 2
a2615 2
	if_rxr_init(&sc->rx_ring, 2 * ((ifp->if_hardmtu / MCLBYTES) + 1),
	    sc->num_rx_desc);
@


1.295
log
@Disable the L1 ASPM link state to workaround errata with the
82571 / 82572 controllers.

As noticed in the Linux driver and there is related errata for that too.

ok jsg@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.294 2015/02/11 21:27:08 brad Exp $ */
d1778 2
a1779 1
	if (em_validate_eeprom_checksum(&sc->hw) < 0) {
d1792 2
a1793 1
	if (em_read_part_num(&sc->hw, &(sc->part_num)) < 0) {
@


1.294
log
@Disable the L0S and L1 ASPM link states to workaround errata with the
82573 / 82574 controllers.

82573..
8 82573 Disappears in PCI Configuration Space When L0s and L1 PCIe Link
States Are Enabled
41 Delay of Received Ethernet Packet During ASPM L1

82574..
24. PCIe: Common Mode Voltage Shift During L1 Exit
25. Dropped Rx Packets

From FreeBSD

ok jsg@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.293 2015/02/09 03:09:57 dlg Exp $ */
d3202 2
d3218 15
a3232 1
	val &= ~(PCI_PCIE_LCSR_ASPM_L0S | PCI_PCIE_LCSR_ASPM_L1);
@


1.293
log
@tweak the new if_input function so it takes an mbuf_list instead
of a single mbuf. this forces us to batch work between the hardware
rx handlers and the stack.

this includes a converstion of bge from ether_input to if_input.

ok claudio@@ pelikan@@ mpi@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.292 2015/02/08 06:02:24 mpi Exp $ */
d225 1
d1839 2
d3190 29
@


1.292
log
@Convert to if_input().

ok pelikan@@, reyk@@, blambert@@, henning@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.291 2015/01/28 22:33:02 brad Exp $ */
d2847 1
d2973 1
a2973 2

				if_input(ifp, m);
d2998 2
@


1.291
log
@- Add PCH2 and PCH LPT to the list of chips capable of only 9K jumbos.
- Updated PBA values for the 82574 controller (20KB) and ICH9/10 with
  jumbos (14KB).

Tested by a few on 82574, ICH9 and PCH LPT

From FreeBSD
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.290 2014/12/22 02:28:52 tedu Exp $ */
a2962 1
				m->m_pkthdr.rcvif = ifp;
a2971 6
#if NBPFILTER > 0
				if (ifp->if_bpf) {
					bpf_mtap_ether(ifp->if_bpf, m,
					    BPF_DIRECTION_IN);
				}
#endif
d2973 1
a2973 1
				ether_input_mbuf(ifp, m);
@


1.290
log
@unifdef INET
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.289 2014/11/19 23:47:22 brad Exp $ */
d433 2
d436 1
a436 1
			/* Limit Jumbo Frame size */
d813 1
a813 1
		pba = E1000_PBA_30K; /* 30K for Rx, 10K for Tx */
d820 5
a824 1
		pba = E1000_PBA_10K;
@


1.289
log
@Copy over some recent commits from ix(4)..

- remove pointless timeout_del/add dance in the interrupt handler
- don't try to update the link status every second
- Gather full statistics only when EM_DEBUG is defined

ok mikeb@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.288 2014/08/26 11:01:21 mikeb Exp $ */
a669 1
#ifdef INET
a671 1
#endif /* INET */
@


1.288
log
@Revert part of the if_rxr diff that incorrectly moves RX ring tail
index update code from the buf_get success path to the do it all
the time code path.  Tested by millert;  ok dlg, deraadt
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.287 2014/07/13 23:10:23 deraadt Exp $ */
a916 1
		timeout_del(&sc->timer_handle);
a919 1
		timeout_add_sec(&sc->timer_handle, 1); 
a1480 2
	em_check_for_link(&sc->hw);
	em_update_link_status(sc);
d3199 20
a3218 1
	struct ifnet   *ifp;
d3220 1
a3225 2
	sc->stats.crcerrs += E1000_READ_REG(&sc->hw, CRCERRS);
	sc->stats.mpc += E1000_READ_REG(&sc->hw, MPC);
a3226 1
	sc->stats.ecol += E1000_READ_REG(&sc->hw, ECOL);
a3228 2
	sc->stats.latecol += E1000_READ_REG(&sc->hw, LATECOL);
	sc->stats.colc += E1000_READ_REG(&sc->hw, COLC);
a3255 1
	sc->stats.ruc += E1000_READ_REG(&sc->hw, RUC);
a3256 1
	sc->stats.roc += E1000_READ_REG(&sc->hw, ROC);
a3275 4
		sc->stats.algnerrc += 
		E1000_READ_REG(&sc->hw, ALGNERRC);
		sc->stats.rxerrc += 
		E1000_READ_REG(&sc->hw, RXERRC);
a3277 2
		sc->stats.cexterr += 
		E1000_READ_REG(&sc->hw, CEXTERR);
d3283 1
a3283 1
	ifp = &sc->interface_data.ac_if;
@


1.287
log
@Some reallocarray() use; review Jean-Philippe Ouellet, patrick keshishian
ok tedu
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.286 2014/07/12 18:48:51 tedu Exp $ */
d2820 1
a2820 1
	    slots > 0; slots--) { 
d2827 1
a2830 1
	sc->last_rx_desc_filled = i;
@


1.287.4.1
log
@OpenBSD 5.6 errata 1: Incorrect RX ring computation leads to panics
under load with bge(4), em(4) and ix(4).
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.287 2014/07/13 23:10:23 deraadt Exp $ */
d2820 1
a2820 1
	    slots > 0; slots--) {
a2826 1
		sc->last_rx_desc_filled = i;
d2830 1
@


1.286
log
@add a size argument to free. will be used soon, but for now default to 0.
after discussions with beck deraadt kettenis.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.285 2014/07/08 05:35:18 dlg Exp $ */
d2122 2
a2123 2
	if (!(sc->tx_buffer_area = malloc(sizeof(struct em_buffer) *
	    sc->num_tx_desc, M_DEVBUF, M_NOWAIT | M_ZERO))) {
d2556 2
a2557 2
	if (!(sc->rx_buffer_area = malloc(sizeof(struct em_buffer) *
	    sc->num_rx_desc, M_DEVBUF, M_NOWAIT | M_ZERO))) {
@


1.285
log
@cut things that relied on mclgeti for rx ring accounting/restriction over
to using if_rxr.

cut the reporting systat did over to the rxr ioctl.

tested as much as i can on alpha, amd64, and sparc64.
mpi@@ has run it on macppc.
ok mpi@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.284 2014/07/08 02:57:27 dlg Exp $ */
d2300 1
a2300 1
		free(sc->tx_buffer_area, M_DEVBUF);
d2750 1
a2750 1
		free(sc->rx_buffer_area, M_DEVBUF);
@


1.284
log
@bus_dmamap_sync the rx ring once per em_rxeof call, rather than for every
rx descriptor.

slightly tweak by matthew
tested on alpha and amd64
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.283 2014/07/08 00:17:44 dlg Exp $ */
d701 5
a1877 3
	m_clsetwms(ifp, MCLBYTES, 2 * ((ifp->if_hardmtu / MCLBYTES) + 1),
	    sc->num_rx_desc);

d2511 1
a2511 1
	m = MCLGETI(NULL, M_DONTWAIT, &sc->interface_data.ac_if, MCLBYTES);
a2538 2
	sc->rx_ndescs++;

d2596 4
a2599 2
	bzero((void *) sc->rx_desc_base,
	    (sizeof(struct em_rx_desc)) * sc->num_rx_desc);
a2606 1
	sc->rx_ndescs = 0;
d2608 4
a2611 2
	em_rxfill(sc);
	if (sc->rx_ndescs < 1) {
d2813 1
d2819 2
a2820 1
	while (sc->rx_ndescs < sc->num_rx_desc) {
a2826 1
		sc->last_rx_desc_filled = i;
d2830 3
d2858 1
a2858 1
	if (sc->rx_ndescs == 0)
d2886 2
a2887 1
			    "(nrx %d, filled %d)", i, sc->rx_ndescs,
d2891 1
a2891 2
		m_cluncount(m, 1);
		sc->rx_ndescs--;
d3000 1
a3000 1
	} while (sc->rx_ndescs > 0);
@


1.283
log
@in em_rxeof, when the ifp stack var is declared its initted to the
right value out of the softc. then its assigned the same value again
after the rest of the var decls.

well, it used to be. not after this commit.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.282 2014/07/08 00:11:50 dlg Exp $ */
d2851 3
d2856 5
a2860 1
	while (sc->rx_ndescs > 0) {
a2865 4
		bus_dmamap_sync(sc->rxdma.dma_tag, sc->rxdma.dma_map,
		    sizeof(*desc) * i, sizeof(*desc),
		    BUS_DMASYNC_POSTREAD);

d2867 1
a2867 4
		if (!ISSET(status, E1000_RXD_STAT_DD)) {
			bus_dmamap_sync(sc->rxdma.dma_tag, sc->rxdma.dma_map,
			    sizeof(*desc) * i, sizeof(*desc),
			    BUS_DMASYNC_PREREAD);
a2868 1
		}
a2989 4
		bus_dmamap_sync(sc->rxdma.dma_tag, sc->rxdma.dma_map,
		    sizeof(*desc) * i, sizeof(*desc),
		    BUS_DMASYNC_PREREAD);

d2993 6
a2998 1
	}
@


1.282
log
@em_rxeof is only called from em_intr, and only if IFF_RUNNING is
set. em_rxeof doesnt have to check that flag again.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.281 2014/07/07 23:12:00 dlg Exp $ */
a2849 2

	ifp = &sc->interface_data.ac_if;
@


1.281
log
@if em encounters a heavilty fragmented packet, it can (will) stall the
entire tx path. if we try to bus_dmamap_load a very fragmented packet
m_defrag it and try again.

this is just like if_bge.c r1.355.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.280 2014/06/11 04:28:43 dlg Exp $ */
a2851 3

	if (!ISSET(ifp->if_flags, IFF_RUNNING))
		return;
@


1.280
log
@em(4) receives jumbos by chaining its MCLBYTES sized descriptors
together, so to receive a full 9000 byte frame, it needs 5 descriptors.
its current mclgeti low watermark is 4.

it appears that the chip will block if it has rxed a packet into
its internal buffers waiting for descriptors. if you're at the lwm,
that means you're DoSed.

this raises the lwm so we can get at least two jumbos, ie, 10
descriptors.

ok deraadt@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.279 2014/03/10 04:09:53 jsg Exp $ */
d1136 11
a1146 1
	if (error != 0) {
d1150 1
@


1.279
log
@match on 82580 quad fiber and add untested support for
DH89XX/Cave Creek PCH which seem to function like a 82580 with some
external Marvell PHYs.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.278 2014/03/10 03:08:34 jsg Exp $ */
d1862 2
a1863 1
	m_clsetwms(ifp, MCLBYTES, 4, sc->num_rx_desc);
@


1.278
log
@match on more i217/i218 variants
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.277 2014/02/22 04:41:31 chris Exp $ */
d153 5
@


1.277
log
@basic i210/i211 support (improved after looking at gollo@@ i210 diff on misc)

tested on Supermicro X10SLL

ok jsg@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.276 2014/02/17 07:02:45 jsg Exp $ */
d143 2
d146 2
@


1.276
log
@Add initial support for i354 MAC and M88E1543 PHY.
Currently treated the same as i350, i354 specific EEE settings
and 2.5Gb backplane connections not properly handled yet.

Tested by Andrew Lester on a Supermicro A1SRi-2758F.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.275 2013/12/28 03:34:54 deraadt Exp $ */
d133 7
d420 1
d489 2
a490 1
	    sc->hw.mac_type == em_82580 || sc->hw.mac_type == em_i350) {
d791 3
d1137 2
a1138 1
	    sc->hw.mac_type != em_82580 && sc->hw.mac_type != em_i350)
d1777 2
a1778 1
	      sc->hw.mac_type == em_i350)) {
d1859 1
a1859 1
	    sc->hw.mac_type != em_i350)
d1864 2
a1865 1
	    sc->hw.mac_type != em_82580 && sc->hw.mac_type != em_i350)
d2220 1
a2220 1
	    sc->hw.mac_type == em_i350) {
d2645 1
a2645 1
	if (sc->hw.mac_type == em_i350)
d2682 1
a2682 1
	    sc->hw.mac_type == em_i350) {
d2880 2
a2881 1
			} else if (sc->hw.mac_type == em_i350)
@


1.275
log
@The few network drivers that called their children's (ie. mii PHY
drivers) activate functions at DVACT_RESUME time do not need to do
so, since their PHYs are repaired by IFF_UP.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.274 2013/12/06 21:03:04 deraadt Exp $ */
d147 3
@


1.274
log
@Add a DVACT_WAKEUP op to the *_activate() API.  This is called after the
kernel resumes normal (non-cold, able to run processes, etc) operation.
Previously we were relying on specific DVACT_RESUME op's in drivers
creating callback/threads themselves, but that has become too common,
indicating the need for a built-in mechanism.
ok dlg kettenis, tested by a sufficient amount of people
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.273 2013/11/27 01:13:10 jsg Exp $ */
a1923 1
		rv = config_activate_children(self, act);
@


1.273
log
@use a macro when testing for an ich8 family mac type
no binary change
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.272 2013/11/21 14:44:37 jsg Exp $ */
a1916 3
	case DVACT_QUIESCE:
		rv = config_activate_children(self, act);
		break;
d1927 3
@


1.272
log
@Initial support for the integrated Lynx Point and Lynx Point LP Ethernet
with external i217 and i218 PHYs.
Requires a changed way of detecting the eeprom flash bank from FreeBSD
as suggested by Masanobu SAITOH.  Thanks to everyone who tested.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.271 2013/11/15 14:53:03 deraadt Exp $ */
d1630 1
a1630 6
	if (sc->hw.mac_type == em_ich8lan ||
	    sc->hw.mac_type == em_ich9lan ||
	    sc->hw.mac_type == em_ich10lan ||
	    sc->hw.mac_type == em_pchlan ||
	    sc->hw.mac_type == em_pch2lan ||
	    sc->hw.mac_type == em_pch_lpt) {
@


1.271
log
@Nathan Wheeler has an em which lacks a prom.  Rather than fail when no
MAC address, continue on, because if_etherattach contains logic for this.
ok mikeb
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.270 2013/10/19 15:45:33 naddy Exp $ */
d133 4
d795 1
d1634 2
a1635 1
	    sc->hw.mac_type == em_pch2lan) {
@


1.270
log
@Enable TX checksum offload; from brad@@ with input from mikeb@@.
Tested extensively by henning@@ and myself.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.269 2013/01/27 04:18:02 brad Exp $ */
a232 1
int  em_is_valid_ether_addr(u_int8_t *);
a503 5
	if (!em_is_valid_ether_addr(sc->hw.mac_addr)) {
		printf("%s: Invalid mac address\n", sc->sc_dv.dv_xname);
		goto err_mac_addr;
	}

a3039 11
}

int
em_is_valid_ether_addr(u_int8_t *addr)
{
	const char zero_addr[6] = { 0, 0, 0, 0, 0, 0 };

	if ((addr[0] & 1) || (!bcmp(addr, zero_addr, ETHER_ADDR_LEN)))
		return (FALSE);

	return (TRUE);
@


1.269
log
@Correct the PBA size used for PCH adapters (26KB).

From FreeBSD

ok jsg@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.268 2012/11/28 01:15:33 brad Exp $ */
a213 1
#ifdef EM_CSUM_OFFLOAD
a215 1
#endif
d1122 2
a1123 2
#ifdef EM_CSUM_OFFLOAD
	if (sc->hw.mac_type >= em_82543)
a1126 3
#else
	txd_upper = txd_lower = 0;
#endif
d1851 3
a1853 4
#ifdef EM_CSUM_OFFLOAD
	if (sc->hw.mac_type >= em_82543)
		ifp->if_capabilities |= IFCAP_CSUM_TCPv4|IFCAP_CSUM_UDPv4;
#endif
a2271 1
#ifdef EM_CSUM_OFFLOAD
a2351 1
#endif /* EM_CSUM_OFFLOAD */
@


1.268
log
@- Use IF_Gbps(1) instead of IF_Mbps(1000)
- Use IF_Mbps() instead of multiplying the link speed by a bare value
- Remove a useless comment as baudrate is already handled properly
- Remove some commented out bits of code
- Use IF_Mbps() instead of the bare value

ok sthen@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.267 2012/08/16 09:31:53 mikeb Exp $ */
a794 1
	case em_pchlan:
d797 1
@


1.267
log
@we're not going to loop in rxeof here as well so remove the leftovers
from brad, ok jsg
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.266 2012/08/16 09:30:55 mikeb Exp $ */
d1488 1
a1488 1
			ifp->if_baudrate = sc->link_speed * 1000000;
@


1.266
log
@revert previous; wrong diff
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.264 2012/05/17 10:45:17 jsg Exp $ */
d211 1
a211 1
void em_rxeof(struct em_softc *, int);
d884 1
a884 1
		em_rxeof(sc, -1);
a2809 3
 *  We loop at most count times if count is > 0, or until done if
 *  count < 0.
 *
d2812 1
a2812 1
em_rxeof(struct em_softc *sc, int count)
d2833 1
a2833 1
	while (count != 0 && sc->rx_ndescs > 0) {
a2871 1
			count--;
@


1.265
log
@we're not going to loop in rxeof here as well so remove the leftovers
from brad, ok jsg
@
text
@a2536 2
	printf("%s: allocated rx_buffer_area at %p (for %d)\n",
	    sc->sc_dv.dv_xname, sc->rx_buffer_area, sc->num_rx_desc);
a2721 2
		printf("%s: deallocated rx_buffer_area at %p\n",
		    sc->sc_dv.dv_xname, sc->rx_buffer_area);
d2786 1
a2786 1
	int i, iter = 0;
a2792 8

		if (&sc->rx_buffer_area[i] == NULL)
			panic("%s: rxfill(%d): null pkt at %p[%d], "
			    "last %d ndescs %d/%d\n", sc->sc_dv.dv_xname,
			    iter, sc->rx_buffer_area, i,
			    sc->last_rx_desc_filled, sc->rx_ndescs,
			    sc->num_rx_desc);
		iter++;
@


1.264
log
@Add support for i350 based devices, based in part on Intel code
in FreeBSD.  Workaround the apparently undocumented errata where the
CRC is always stripped whether asked to or not, and take the FreeBSD
workaround for a known errata when clearing the vlan filter.

Thanks to Jens A. Griepentrog for donating a card.

ok dlg@@ mikeb@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.263 2012/05/14 10:14:44 mikeb Exp $ */
d2537 2
d2724 2
d2790 1
a2790 1
	int i;
d2797 8
@


1.263
log
@trigger tx start routine when link goes up to prevent a lockup
situation when send queue is full and no rx interrupt happen.
initial diff and tests by erik lax, <erik at halon.se>, ok jsg
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.262 2012/02/15 04:06:27 jsg Exp $ */
d139 4
d409 1
d477 1
a477 1
	    sc->hw.mac_type == em_82580) {
d780 1
d1770 2
a1771 1
	      sc->hw.mac_type == em_82580)) {
d1851 2
a1852 1
	if (sc->hw.mac_type != em_82575 && sc->hw.mac_type != em_82580)
d2213 2
a2214 1
	if (sc->hw.mac_type == em_82575 || sc->hw.mac_type == em_82580) {
d2636 8
d2677 2
a2678 1
	if (sc->hw.mac_type == em_82575 || sc->hw.mac_type == em_82580) {
d2880 3
a2882 1
			} else
@


1.262
log
@82571/82572 do not properly set byte enables 2 and 3 on MSI
writes.  Some (but not all) chipsets will fail to generate
interrupts in this case, so do not attempt to enable MSI
on 82571/82572.

Problem reported by David Imhoff with interrupts working on PE1950
but not working on a R610.

ok kettenis@@ claudio@@ deraadt@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.261 2011/10/05 02:52:09 jsg Exp $ */
a879 3
		if (!IFQ_IS_EMPTY(&ifp->if_snd))
			em_start(ifp);

d896 3
@


1.261
log
@Add the remaining parts of support for 82580 based devices such as
the Intel I340-T4 and HP NC365T and simplify some of the multi port
handling while here.

Thanks to fredrik danerklint for donating a card, Linden Varley
for setting up a test system and everyone who made sure this
didn't break their existing em setups.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.260 2011/08/30 02:51:19 haesbaert Exp $ */
d332 5
a336 2
	/* Only use MSI on the newer PCIe parts */
	if (sc->hw.mac_type < em_82571)
@


1.260
log
@Don't OR the VID, we want the whole TCI, this makes vlanprio (PCP/CF)
available to our network stack.
ok mcbride naddy henning
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.259 2011/07/05 16:51:34 kettenis Exp $ */
d468 24
d1841 1
a1841 1
	if (sc->hw.mac_type != em_82575)
d2202 1
a2202 1
	if (sc->hw.mac_type == em_82575) {
d2656 8
@


1.259
log
@Stupid driver makes a copy of struct pci_attach_args.  Make sure we clear
the MSI enabled flag there such that the driver actually pays attention to it.
Found out the hard way by Chris Smith on an 82540EM, which defenitely does
not like MSI.

ok deraadt@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.258 2011/06/16 13:21:00 kettenis Exp $ */
d2891 1
a2891 2
					    (letoh16(desc->special) &
					     E1000_RXD_SPC_VLAN_MASK);
@


1.258
log
@Enable MSI on newish PCIe hardware, essentially everything handled by the Linux
e1000e driver (which enables MSI as well), leaving everything handled by the
old Linux e1000 driver (which doesn't enable MSI) use legacy interrupts.

tested by many; ok jsg@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.257 2011/06/03 13:06:06 kettenis Exp $ */
d332 1
a332 1
	/* Only use MSIe on the newer PCIe parts */
d334 1
a334 1
		pa->pa_flags &= ~PCI_FLAGS_MSI_ENABLED;
@


1.257
log
@Fix em_write_pci_cfg() and em_read_pci_cfg() to avoid unaligned access, and
make em_write_pci_cfg() do a proper read/modify/write cycle, to avoid changing
the neighbouring 16 bits.  Also remove the comment in em_pci_set_mwi() and
em_pci_clear_mwi(); writting 0 to the status bits in the command/status word
is the right thing to do.  Fixes a panic on sparc64 and other strict alignment
architectures.

ok deraadt@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.256 2011/04/22 10:09:57 jsg Exp $ */
d332 4
d1622 1
a1622 1
	if (pci_intr_map(pa, &ih)) {
@


1.256
log
@Add support for PCH2 (Sandy Bridge) MAC with 82579 PHY.
From Laurence Tratt.

ok claudio@@ deraadt@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.255 2011/04/14 21:14:28 jsg Exp $ */
d3017 11
a3027 3
	pci_chipset_tag_t pc = pa->pa_pc;
	/* Should we do read/mask/write...?  16 vs 32 bit!!! */
	pci_conf_write(pc, pa->pa_tag, reg, *value);
d3034 7
a3040 2
	pci_chipset_tag_t pc = pa->pa_pc;
	*value = pci_conf_read(pc, pa->pa_tag, reg);
d3047 2
a3048 3
	pci_chipset_tag_t pc = pa->pa_pc;
	/* Should we do read/mask/write...?  16 vs 32 bit!!! */
	pci_conf_write(pc, pa->pa_tag, PCI_COMMAND_STATUS_REG,
d3056 2
a3057 3
	pci_chipset_tag_t pc = pa->pa_pc;
	/* Should we do read/mask/write...?  16 vs 32 bit!!! */
	pci_conf_write(pc, pa->pa_tag, PCI_COMMAND_STATUS_REG,
@


1.255
log
@the mechanical part of 82580 support, more to come
ok claudio@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.254 2011/04/13 00:19:00 dlg Exp $ */
d131 2
d761 3
d1602 2
a1603 1
	    sc->hw.mac_type == em_pchlan) {
@


1.254
log
@modify the interrupt handler so it only processes the rings once,
rather than looping over them until it runs out of work to do.

looping in the isr is bad for several reasons:

firstly, the chip does interrupt mitigation so you have a
decent/predictable amount of work to do in the isr. your first loop
will do that chunk of work (ie, it pulls off 50ish packets), and
then the successive looping aggressively pull one or two packets
off the rx ring. these extra loops work against the benefit that
interrupt mitigation provides.

bus space reads are slow. we should avoid doing them where possible
(but we should always do them when necessary).

doing the loop 5 times per isr works against the mclgeti semantics.
it knows a nic is busy and therefore needs more rx descriptors by
watching to see when the nic uses all of its descriptors between
interrupts. if we're aggressively pulling packets off by looping
in the isr then we're skewing this check.

ok deraadt@@ claudio@@
this is like src/sys/dev/pci/if_ix.c r1.50.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.253 2011/04/05 20:24:32 jsg Exp $ */
d131 5
d395 1
d740 1
d1436 2
a1437 1
			    (sc->hw.mac_type == em_82575))) {
d1726 2
a1727 1
	      sc->hw.mac_type == em_82575)) {
@


1.253
log
@We only use the io space in em_reset_hw() on a few MAC types
and it does not exist at all on newer hardware so only map
it on those types we are interested in.

Fixes "PRO/1000 PT (82575EB)" for Sylvain Desveaux and will
also be required for at least 82580.

ok claudio@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.252 2011/04/05 18:01:21 henning Exp $ */
d823 2
a824 2
	struct em_softc  *sc = arg;
	struct ifnet	*ifp;
d826 1
a826 2
	int claimed = 0;
	int refill;
d828 23
a850 1
	ifp = &sc->interface_data.ac_if;
d852 4
a855 9
	for (;;) {
		test_icr = reg_icr = E1000_READ_REG(&sc->hw, ICR);
		if (sc->hw.mac_type >= em_82571)
			test_icr = (reg_icr & E1000_ICR_INT_ASSERTED);
		if (!test_icr)
			break;

		claimed = 1;
		refill = 0;
d857 3
a859 24
		if (ifp->if_flags & IFF_RUNNING) {
			em_rxeof(sc, -1);
			em_txeof(sc);
			refill = 1;
		}

		/* Link status change */
		if (reg_icr & (E1000_ICR_RXSEQ | E1000_ICR_LSC)) {
			timeout_del(&sc->timer_handle);
			sc->hw.get_link_status = 1;
			em_check_for_link(&sc->hw);
			em_update_link_status(sc);
			timeout_add_sec(&sc->timer_handle, 1); 
		}

		if (reg_icr & E1000_ICR_RXO) {
			sc->rx_overruns++;
			refill = 1;
		}

		if (refill && em_rxfill(sc)) {
			/* Advance the Rx Queue #0 "Tail Pointer". */
			E1000_WRITE_REG(&sc->hw, RDT, sc->last_rx_desc_filled);
		}
d862 1
a862 4
	if (ifp->if_flags & IFF_RUNNING && !IFQ_IS_EMPTY(&ifp->if_snd))
		em_start(ifp);

	return (claimed);
@


1.252
log
@mechanic rename M_{TCP|UDP}V4_CSUM_OUT -> M_{TCP|UDP}_CSUM_OUT
ok claudio krw
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.251 2011/04/03 15:36:02 jasper Exp $ */
d1560 7
a1566 1
	if (sc->hw.mac_type > em_82543) {
d1588 3
@


1.251
log
@use nitems(); no binary change for drivers that are compiled on amd64.

ok claudio@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.250 2011/03/09 12:24:15 mpf Exp $ */
d2239 1
a2239 1
		if (mp->m_pkthdr.csum_flags & M_TCPV4_CSUM_OUT) {
d2246 1
a2246 1
		} else if (mp->m_pkthdr.csum_flags & M_UDPV4_CSUM_OUT) {
@


1.250
log
@HW stats debugging via ifconfig emX debug instead of
a global em_display_debug_stats variable.
OK mcbride, matthew, deraadt, henning.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.249 2011/02/13 19:45:54 miod Exp $ */
d258 1
a258 1
	    sizeof(em_devices)/sizeof(em_devices[0])));
@


1.249
log
@Do not compile statistics counters code if defined(SMALL_KERNEL). Makes i386
RAMDISKA breathe a bit better.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.248 2010/09/19 13:10:21 yasuoka Exp $ */
a39 9
#ifndef SMALL_KERNEL
#ifdef EM_DEBUG
/*********************************************************************
 *  Set this to one to display debug statistics
 *********************************************************************/
int             em_display_debug_stats = 0;
#endif
#endif

d1412 1
a1412 1
	if (em_display_debug_stats && ifp->if_flags & IFF_RUNNING)
d3205 1
a3205 1
 *  This routine is called only when em_display_debug_stats is enabled.
@


1.248
log
@add support for 82583V.  Confirmed to work on Portwell CAD-0205.

ok jsg@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.247 2010/09/07 16:21:44 deraadt Exp $ */
d40 1
d47 1
d486 1
d488 1
d1418 1
d1424 1
d2833 1
d2836 1
d3105 1
d3270 1
@


1.247
log
@remove the powerhook code.  All architectures now use the ca_activate tree
traversal code to suspend/resume
ok oga kettenis blambert
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.246 2010/08/31 17:13:44 deraadt Exp $ */
d138 1
@


1.246
log
@Add DVACT_QUIECE support.  This is called before splhigh() and before
DVACT_SUSPEND, therefore DVACT_QUIECE can do standard sleeping operations
to get ready.
Discussed quite a while back with kettenis and jakemsr, oga suddenly needed
it as well and wrote half of it, so it was time to finish it.
proofread by miod.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.245 2010/08/27 15:56:09 deraadt Exp $ */
a172 1
void em_powerhook(int, void *);
a282 3
		if (sc->sc_powerhook != NULL)
			powerhook_disestablish(sc->sc_powerhook);

a505 1
	sc->sc_powerhook = powerhook_establish(em_powerhook, sc);
a1854 3
	if (sc->sc_powerhook != NULL)
		powerhook_disestablish(sc->sc_powerhook);

a1890 6
}

void
em_powerhook(int why, void *arg)
{
	em_activate(arg, why);
@


1.245
log
@Have the em powerhook call the activate function, which does a way better
job of taking the chip up and down.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.244 2010/08/08 12:53:16 kettenis Exp $ */
d1883 3
d1898 1
a1898 1
	return rv;
@


1.244
log
@Make sure hw.revision_id gets initialized before it's used by em_set_mac_type()
and move it back to the location where it was before rev. 1.239, while
keeping the horrible override for em_pchlan.  From Holger Mikolon.

ok jsg@@, deraadt@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.243 2010/08/04 17:10:34 jsg Exp $ */
d173 1
a174 1
void em_power(int, void *);
d510 1
a510 1
	sc->sc_powerhook = powerhook_establish(em_power, sc);
a522 13
void
em_power(int why, void *arg)
{
	struct em_softc *sc = (struct em_softc *)arg;
	struct ifnet *ifp;

	if (why == PWR_RESUME) {
		ifp = &sc->interface_data.ac_if;
		if (ifp->if_flags & IFF_UP)
			em_init(sc);
	}
}

d1896 6
@


1.243
log
@Correct a problem reported by Holger Mikolon that turns out to be
a bug in the initial EP80579 commit from dms that was exposed by gcc4.

Lots of help tracking down the block of code at fault from
Mike Belopuhov, but I spotted the problem in the end :)

ok kettenis@@ deraadt@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.242 2010/08/03 16:21:52 jsg Exp $ */
d1538 3
a1550 4
	else {
		reg = pci_conf_read(pa->pa_pc, pa->pa_tag, PCI_CLASS_REG);
		sc->hw.revision_id = PCI_REVISION(reg);
	}
@


1.242
log
@Disable hardware VLAN stripping/insertion on 8257[56] for now.  While
stripping works insertion seems to have trouble in certain conditions,
which needs to be fixed before we want to enable hardware support for this.

ok deraadt@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.241 2010/07/26 19:21:24 kettenis Exp $ */
d1651 1
a1651 1
		uint8_t offset;
d1655 1
a1655 2
		    sc->osdep.em_pa.pa_tag, PCI_CAP_ID_ST, (int*) &offset, 
		    &val)) {
@


1.241
log
@Make sure we stop DMA before suspend instead of doing it as the first thing
we do upon resume and failing to cope with the fact that the state has changed
under our feet.  Fixes watchdog timeout issues in at least one case.

ok deraadt@@, tested by thib@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.240 2010/06/28 20:24:39 jsg Exp $ */
d1819 2
a1820 1
	ifp->if_capabilities |= IFCAP_VLAN_HWTAGGING;
@


1.240
log
@Initial 82578 support from Mike Belopuhov.

ok claudio@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.239 2010/06/27 20:13:04 jsg Exp $ */
d1898 2
a1903 1
		em_stop(sc, 0);
@


1.239
log
@More PCH/82577 bits from FreeBSD, this does not include
all the workarounds but is enough to make things run at
faster than 10 Mbit speeds, though these aren't always
reflecting in ifmedia properly just yet.

ok claudio@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.238 2010/06/21 21:11:52 jsg Exp $ */
d136 2
@


1.238
log
@Initial support for PCH based em adapters with 82577 PHY,
from Laurence Tratt based on FreeBSD code.  Confirmed to
work on lenovo t410i/t410s/x201.

Desktop machines with PCH tend to be paired with a 82578 PHY,
these will at some point be supported but not yet.

ok claudio@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.237 2010/06/21 20:43:44 jsg Exp $ */
a1535 3
	reg = pci_conf_read(pa->pa_pc, pa->pa_tag, PCI_CLASS_REG);
	sc->hw.revision_id = PCI_REVISION(reg);

d1543 7
@


1.237
log
@Add some more ids for existing mac and phy types found
in the FreeBSD driver.

ok claudio@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.236 2010/05/18 21:51:10 jsg Exp $ */
d134 2
d404 3
d769 1
d1602 2
a1603 1
	    sc->hw.mac_type == em_ich10lan) {
@


1.236
log
@Add as yet untested support for the 82576 quad copper ET2
based on information in the linux driver.

ok claudio@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.235 2010/03/16 22:48:43 kettenis Exp $ */
d121 1
d125 1
d132 3
@


1.235
log
@Set rx_ndescs to zero when initializing the rx ring.  Otherwise we'll
effectively lose receive descriptors each time we reset the interface, until
we run out of descriptors and panic.  Should fix the "em_rxeof: NULL mbuf in
slot 0 (nrx 256, filled 255)" panic on em(4).

ok jsing@@ (for the em(4) bits), jsg@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.234 2009/12/02 23:30:00 sthen Exp $ */
d128 1
@


1.234
log
@Zap trailing whitespace. From Brad.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.233 2009/11/26 16:01:00 dms Exp $ */
d2525 1
@


1.233
log
@Fix an issue where 82573L based em(4) devices had long latencies on the
recieved packets.

fix from intel drivers, via Brad

ok claudio@@, deraadt@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.232 2009/11/26 15:53:15 dms Exp $ */
d2606 6
a2611 6
	/*                                                                                                                                                                           
	 * XXX TEMPORARY WORKAROUND: on some systems with 82573                                                                                                                      
	 * long latencies are observed, like Lenovo X60.                                                                                                                             
	 */                                                                                                                                                                          
	if (sc->hw.mac_type == em_82573)                                                                                                                                             
		E1000_WRITE_REG(&sc->hw, RDTR, 0x20);                                                                                                                                
@


1.232
log
@em_stop() removes IFF_RUNNING flag, so we should rely on the IFF_UP being set

ok deraadt@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.231 2009/11/26 13:47:02 dms Exp $ */
d2605 7
@


1.231
log
@unbrak previous

ok deraadt@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.230 2009/11/26 13:42:33 dms Exp $ */
d1885 1
a1885 1
		if (ifp->if_flags & IFF_RUNNING)
@


1.230
log
@handle DV_SUSPEND and DV_RESUME

tested by deraadt@@ and me
ok deraadt@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.229 2009/11/25 13:28:13 dms Exp $ */
d1874 1
@


1.229
log
@Add support for em(4) interfaces found on intel EP80579 SoC. The MAC part is
basicly 82545, but the PHY's are separated form the chip and they are accessed
through a special PCI device called GCU which has the MDIO interface. Since
there is no direct relationship between MAC and PHY, so for the moment they
are assigned to each other the way its done on Axiomtek NA-200, that was
danted to us by them.

This also adds a device driver for the GCU.

tested by me on Axiomtek board
reviewed by claudio@@, kettenis@@, deraadt@@
'commit that as is' deraadt@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.228 2009/10/13 23:55:20 deraadt Exp $ */
d162 1
d230 2
a231 1
	sizeof(struct em_softc), em_probe, em_attach, em_detach
d1870 20
@


1.228
log
@Start doing the neccessary operations in the detach function in the right order.
No other functional change expected.  ok dms
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.227 2009/10/11 19:24:48 dms Exp $ */
d38 1
d149 4
a152 1
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_ICH10_R_BM_V }
d160 1
d256 39
d309 3
a311 2
	int		tsize, rsize;

d441 8
a448 4
	if (em_hardware_init(sc)) {
		printf("%s: Unable to initialize the hardware\n",
		       sc->sc_dv.dv_xname);
		goto err_hw_init;
d464 1
a464 1
	      ETHER_ADDR_LEN);
d467 2
a468 1
	em_setup_interface(sc);
d474 2
a475 1
	em_update_link_status(sc);
d491 3
a684 1

d1608 1
d1623 21
d1684 1
d1753 5
a1757 1
	if (em_init_hw(&sc->hw) < 0) {
@


1.227
log
@remove duplicate ierrors increment (rx_overruns gets incremented) which was
introduced in rev. 1.204. from brad

ok by claudio@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.226 2009/10/11 00:18:37 dms Exp $ */
d163 1
a163 1
void em_stop(void *);
d577 1
a577 1
				em_stop(sc);
d661 1
a661 1
	em_stop(sc);
d736 1
a736 1
		em_stop(sc);
d746 1
a746 1
		em_stop(sc);
d1427 1
a1427 1
em_stop(void *arg)
a1428 1
	struct ifnet   *ifp;
d1430 1
a1430 1
	ifp = &sc->interface_data.ac_if;
d1434 1
d1437 1
a1437 2
	em_disable_intr(sc);
	em_reset_hw(&sc->hw);
d1441 5
d1766 2
d1769 8
a1776 2
	timeout_del(&sc->timer_handle);
	timeout_del(&sc->tx_fifo_timer_handle);
a1783 3

	if (sc->sc_powerhook != NULL)
		powerhook_disestablish(sc->sc_powerhook);
@


1.226
log
@add support for ICH9 M V chipset, from brad.

ok by claudio@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.225 2009/10/10 04:49:26 deraadt Exp $ */
a810 1
			ifp->if_ierrors++;
@


1.225
log
@Again, in detatch... call whatever disconnects our interrupt, before we
go messing with the maps.  Only affects my disconnectable em(4).
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.224 2009/10/09 21:04:03 deraadt Exp $ */
d143 1
@


1.224
log
@Must also timeout_del twice in detach()...
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.223 2009/10/09 20:50:32 deraadt Exp $ */
d1766 1
a1768 1
	em_free_pci_resources(sc);
@


1.223
log
@A working detach function.  Has no impact on anything else in the driver.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.222 2009/09/04 22:13:51 dms Exp $ */
d1762 3
@


1.222
log
@Bring back support for iCH10 based chips. This time support for fiber cards
seems to be fixed, thanks to tests done by mpf at mailq dot de.
Also support for older fiber cards that have no PHY seems to be working,
thanks to claudio@@
The code includes all the changes that i backed out, plus two tweaks:
1. em_detect_gig_phy() gets called in em_setup_link() instead of
em_copper_link_preconfig(), this enables phy detection on fiber cards.
2. em_detect_gig_phy() gets a condition to look for old fiber cards, that
have no PHY.

ok by claudio@@, prodded by deraadt@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.221 2009/08/21 22:54:10 dms Exp $ */
d155 1
d223 1
a223 1
	sizeof(struct em_softc), em_probe, em_attach
d1755 19
@


1.221
log
@Back-out support for iCH10 chips from em(4).
It seems that new phy detection code breaks
some of the newer fiber cards.

found by Brad, ok by claudio@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.220 2009/08/13 14:24:47 jasper Exp $ */
d135 1
d142 6
a147 1
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_ICH9_IGP_M_AMT }
d342 3
a344 1
		case em_80003es2lan:	/* Limit Jumbo Frame size */
a346 1
			/* Adapters that do not support Jumbo frames */
d350 1
d700 1
d1529 2
a1530 1
	    sc->hw.mac_type == em_ich9lan) {
@


1.220
log
@- consistify cfdriver for the ethernet drivers (0 -> NULL)

ok dlg@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.219 2009/08/12 20:02:42 dlg Exp $ */
a134 1
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_ICH9_BM },
d141 1
a141 6
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_ICH9_IGP_M_AMT },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_ICH10_D_BM_LF },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_ICH10_D_BM_LM },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_ICH10_R_BM_LF },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_ICH10_R_BM_LM },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_ICH10_R_BM_V }
d336 1
a336 3
		case em_ich10lan:
		case em_80003es2lan:
			/* Limit Jumbo Frame size */
d339 1
a342 1
			/* Adapters that do not support Jumbo frames */
a691 1
	case em_ich10lan:
d1520 1
a1520 2
	    sc->hw.mac_type == em_ich9lan ||
	    sc->hw.mac_type == em_ich10lan) {
@


1.219
log
@revert my change to m_cluncount which tries to prevent the system
running out of mbufs for rx rings.

if the system low watermark is lower than a rx rings low watermark,
we'll never send a packet up the stack, we'll always recycle it.

found by thib@@ on a bge
sadface
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.218 2009/08/12 14:39:05 dlg Exp $ */
d226 1
a226 1
	0, "em", DV_IFNET
@


1.218
log
@if we get dangerously low on clusters during interrupts, we need
to free some for use on the rx rings on network cards.

this modifies m_cluncount to advise callers when we're in such a
situation, and makes them responsible for freeing up the cluster
for allocation by MCLGETI later.

fixes an awesome lockup with sis(4) henning has been experiencing.
this is not the best fix, but it is better than the current situation.

yep deraadt@@ tested by henning@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.217 2009/08/10 19:41:05 deraadt Exp $ */
d2652 1
a2653 4
		if (m_cluncount(m) == 0)
			accept_frame = 1;
		else
			accept_frame = 0;
d2655 1
@


1.217
log
@A few more simple cases of shutdown hooks which only call xxstop, when
we now know the interface has already been stopped
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.216 2009/08/09 11:40:56 deraadt Exp $ */
a2651 1
		m_cluncount(m, 1);
d2653 4
a2657 1
		accept_frame = 1;
@


1.216
log
@MCLGETI() will now allocate a mbuf header if it is not provided, thus
reducing the amount of splnet/splx dancing required.. especially in the
worst case (of m_cldrop)
ok dlg kettenis damien
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.215 2009/07/27 16:37:52 claudio Exp $ */
a154 1
void em_shutdown(void *);
a439 1
	sc->sc_shutdownhook = shutdownhook_establish(em_shutdown, sc);
a462 14
}

/*********************************************************************
 *
 *  Shutdown entry point
 *
 **********************************************************************/ 

void
em_shutdown(void *arg)
{
	struct em_softc *sc = arg;

	em_stop(sc);
@


1.215
log
@Split comment from lint keyword. OK dms@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.214 2009/06/26 14:30:35 claudio Exp $ */
d2310 2
a2311 8
	MGETHDR(m, M_DONTWAIT, MT_DATA);
	if (m == NULL) {
		sc->mbuf_alloc_failed++;
		return (ENOBUFS);
	}
	MCLGETI(m, M_DONTWAIT, &sc->interface_data.ac_if, MCLBYTES);
	if ((m->m_flags & M_EXT) == 0) {
		m_freem(m);
@


1.214
log
@Support the ICH10 variants of em(4). All the work done by Dariusz Swiderski
with help from Brad. OK deraadt@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.213 2009/06/23 14:09:51 claudio Exp $ */
d335 2
a336 1
			/* Allow Jumbo frames - FALLTHROUGH */
@


1.213
log
@Add support for the 82574L chips and the bme1000 phy which is also used on
some newer ICH* chips. All the hard work done by Dariusz Swiderski
sfires (at) sfires.net, tested by myself, sthen@@ and many more.
Eyeballed and OK dlg@@ kettenis@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.212 2009/06/05 16:27:40 naddy Exp $ */
d135 1
d142 6
a147 1
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_ICH9_IGP_M_AMT }
d342 3
a344 1
		case em_80003es2lan:	/* Limit Jumbo Frame size */
a346 1
			/* Adapters that do not support Jumbo frames */
d350 1
d715 1
d1544 2
a1545 1
	    sc->hw.mac_type == em_ich9lan) {
@


1.212
log
@tidy up promiscuous mode and multicast handling; from Brad; ok sthen@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.211 2009/06/04 05:08:43 claudio Exp $ */
d119 1
d333 1
d699 3
@


1.211
log
@Match em(4) against all the newer chips (82575/6) and treat them all the
same. Not sure if the 82576 is 100% compatible to the 82575 but only when
enabled it will be possible to test them. OK jsg@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.210 2009/06/03 17:39:44 claudio Exp $ */
d190 1
a190 2
void em_set_promisc(struct em_softc *);
void em_set_multi(struct em_softc *);
d574 4
a577 13
			/*
			 * If only the PROMISC or ALLMULTI flag changes, then
			 * don't do a full re-init of the chip, just update
			 * the Rx filter.
			 */
			if ((ifp->if_flags & IFF_RUNNING) &&
			    ((ifp->if_flags ^ sc->if_flags) &
			     (IFF_ALLMULTI | IFF_PROMISC)) != 0) {
				em_set_promisc(sc);
			} else {
				if (!(ifp->if_flags & IFF_RUNNING))
					em_init(sc);
			}
a581 1
		sc->if_flags = ifp->if_flags;
d603 1
a603 1
			em_set_multi(sc);
a740 3
	/* Setup Multicast table */
	em_set_multi(sc);

d751 2
a752 2
	/* Don't lose promiscuous settings */
	em_set_promisc(sc);
d1287 1
a1287 27
em_set_promisc(struct em_softc *sc)
{
	u_int32_t	reg_rctl;
	struct ifnet   *ifp = &sc->interface_data.ac_if;

	reg_rctl = E1000_READ_REG(&sc->hw, RCTL);

	if (ifp->if_flags & IFF_PROMISC) {
		reg_rctl |= (E1000_RCTL_UPE | E1000_RCTL_MPE);
	} else if (ifp->if_flags & IFF_ALLMULTI) {
		reg_rctl |= E1000_RCTL_MPE;
		reg_rctl &= ~E1000_RCTL_UPE;
	} else {
		reg_rctl &= ~(E1000_RCTL_UPE | E1000_RCTL_MPE);
	}
	E1000_WRITE_REG(&sc->hw, RCTL, reg_rctl);
}

/*********************************************************************
 *  Multicast Update
 *
 *  This routine is called whenever multicast address list is updated.
 *
 **********************************************************************/

void
em_set_multi(struct em_softc *sc)
d1289 2
a1292 2
	struct ifnet *ifp = &sc->interface_data.ac_if;
	struct arpcom *ac = &sc->interface_data;
d1297 1
a1297 2
	IOCTL_DEBUGOUT("em_set_multi: begin");
	ifp->if_flags &= ~IFF_ALLMULTI;
d1309 4
a1312 1
	if (ac->ac_multirangecnt > 0 ||
d1316 2
a1319 1

a1327 1
		reg_rctl &= ~E1000_RCTL_MPE;
d1329 1
@


1.210
log
@Add support for the newer 82575 and maybe 82576 chips. The cards work more
or less out of the box if one explicitly enables the TX DMA engine.
Only tested with 82575, people with 82576 cards may contact me for a diff.
OK kettenis@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.209 2009/05/31 04:47:50 deraadt Exp $ */
d120 2
a121 1
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82575EB_COPPER },
d126 1
@


1.209
log
@doubled error messages are silly
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.208 2009/05/25 10:17:55 sthen Exp $ */
d119 6
d331 1
d699 1
d1422 2
a1423 1
			    (sc->hw.mac_type == em_82572))) {
d1671 2
a1672 1
	      sc->hw.mac_type == em_82572)) {
d2050 1
d2056 11
a2077 6

	/* Setup Transmit Descriptor Base Settings */   
	sc->txd_cmd = E1000_TXD_CMD_IFCS;

	if (sc->tx_int_delay > 0)
		sc->txd_cmd |= E1000_TXD_CMD_IDE;
@


1.208
log
@Add missing letoh in em(4) vlan handling, resulting in a problem on
big-endian arch where vlans were in use. Fix from Brad. Problem reported
and fix tested by Axton Grams, also tested by me. ok dlg@@.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.207 2009/01/27 09:17:51 dlg Exp $ */
d296 1
a296 3
	if (em_allocate_pci_resources(sc)) {
		printf("%s: Allocation of PCI resources failed\n",
		    sc->sc_dv.dv_xname);
a297 1
	}
@


1.207
log
@make drivers tell the mclgeti allocator what their maximum ring size is
to prevent the hwm growing beyond that. this allows the livelock mitigation
to do something where the hwm used to grow beyond twice the rx rings size.

ok kettenis@@ claudio@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.206 2008/12/23 07:40:31 dlg Exp $ */
d2755 1
a2755 1
					    (desc->special &
@


1.207.2.1
log
@From -current, ok dlg@@: Add missing letoh in em(4) vlan handling,
resulting in a problem on big-endian arch where vlans were in use.
Fix from Brad.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.207 2009/01/27 09:17:51 dlg Exp $ */
d2755 1
a2755 1
					    (letoh16(desc->special) &
@


1.206
log
@allow us to completely exhaust the rx ring now that we handle the RXO (rx
overflow) interrupt.

Yes deraadt@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.204 2008/12/21 23:30:26 dlg Exp $ */
d1735 2
@


1.205
log
@rework the programming of the multicast addresses onto the chip to use the
"new" multicast address and address range counters in the ifp. shrinks
and simplifies that code a lot.

ive had this diff since may 2007.
@
text
@d2647 1
a2647 1
	while (count != 0 && sc->rx_ndescs > 1) {
@


1.204
log
@use the RXO (rx overflow) interrupt to try to refill the rx ring. this lets
us cope if the rx ring empties completely and the hardware tells us we're
still getting packets.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.202 2008/12/06 11:39:38 dlg Exp $ */
a1323 1
	int mcnt = 0;
d1328 1
d1331 1
d1341 14
a1354 5
	ETHER_FIRST_MULTI(step, ac, enm);
	while (enm != NULL) {
		if (bcmp(enm->enm_addrlo, enm->enm_addrhi, ETHER_ADDR_LEN)) {
			ifp->if_flags |= IFF_ALLMULTI;
			mcnt = MAX_NUM_MULTICAST_ADDRESSES;
d1356 3
a1358 6
		if (mcnt == MAX_NUM_MULTICAST_ADDRESSES)
			break;
		bcopy(enm->enm_addrlo, &mta[mcnt*ETH_LENGTH_OF_ADDRESS],
		      ETH_LENGTH_OF_ADDRESS);
		mcnt++;
		ETHER_NEXT_MULTI(step, enm);
d1360 1
a1360 7

	if (mcnt >= MAX_NUM_MULTICAST_ADDRESSES) {
		reg_rctl = E1000_READ_REG(&sc->hw, RCTL);
		reg_rctl |= E1000_RCTL_MPE;
		E1000_WRITE_REG(&sc->hw, RCTL, reg_rctl);
	} else
		em_mc_addr_list_update(&sc->hw, mta, mcnt, 0, 1);
@


1.203
log
@revert 1.20 now that the new allocator is used to control the number of
RX buffers allocated.

ok dlg@@
@
text
@d786 1
d798 1
a801 5
			if (em_rxfill(sc)) {
				/* Advance the Rx Queue #0 "Tail Pointer". */
				E1000_WRITE_REG(&sc->hw, RDT,
				    sc->last_rx_desc_filled);
			}
d803 1
d815 1
a815 1
		if (reg_icr & E1000_ICR_RXO)
d817 8
@


1.202
log
@uncount clusters taken off the rx ring immediately. if those clusters were
being chained into a jumbo we would not replace them when filling the rx
ring again until they were passed up the stack.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.201 2008/12/04 02:36:51 brad Exp $ */
d264 7
a270 2
	sc->num_tx_desc = EM_MIN_TXD;
	sc->num_rx_desc = EM_MIN_RXD;
a669 14

	if (ifp->if_flags & IFF_UP) {
		if (sc->hw.mac_type >= em_82544) {
		    sc->num_tx_desc = EM_MAX_TXD;
		    sc->num_rx_desc = EM_MAX_RXD;
		} else {
		    sc->num_tx_desc = EM_MAX_TXD_82543;
		    sc->num_rx_desc = EM_MAX_RXD_82543;
		}
	} else {
		sc->num_tx_desc = EM_MIN_TXD;
		sc->num_rx_desc = EM_MIN_RXD;
	}
	IFQ_SET_MAXLEN(&ifp->if_snd, sc->num_tx_desc - 1);
@


1.201
log
@Add initial support for the ICH9 IGP M and ICH9 IGP M AMT chipsets.

For now the chunk in em_detect_gig_phy() is a hack to get things going
until it can be figured out why exactly the PHY id is not probed
properly.

Based on a diff from jcs@@ via ckuethe@@
ok kettenis@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.200 2008/12/03 00:59:48 dlg Exp $ */
d2680 1
@


1.200
log
@recommit the use of the new mbuf cluster allocator.

this starts em up with 4 mbufs on the rx ring, which will then grow as
usage demands. this also allows em to take advantage of the new livelock
mitigation code as well as freeing up a boatload of kernel memory.

this version of the diff makes sure we only ever post the last descriptor
we filled to the hardware, rather than the whole ring when bringing the
interface up. it has been tested by users who got panics with the previous
diff without trouble.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.197 2008/11/26 00:14:48 dlg Exp $ */
d130 3
a132 1
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_ICH9_IGP_C }
@


1.199
log
@revert 1.197 if_em.c, 1.38/1.39 if_em.h, requested by dlg, until a bug
reported on misc@@ can be tracked down.

identical diff from jsing.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.198 2008/11/28 02:44:17 brad Exp $ */
d167 6
d807 5
d1462 3
a1470 3
	/* Tell the stack that the interface is no longer active */
	ifp->if_flags &= ~(IFF_RUNNING | IFF_OACTIVE);

d2301 2
a2302 2
	bus_dmamap_t	map;
	struct em_buffer *rx_buffer;
d2305 9
d2319 1
a2319 1
	MCLGET(m, M_DONTWAIT);
a2325 1

d2329 1
a2329 6
	/*
	 * Using memory from the mbuf cluster pool, invoke the
	 * bus_dma machinery to arrange the memory mapping.
	 */
	error = bus_dmamap_load_mbuf(sc->rxtag, sc->rx_sparemap,
	    m, BUS_DMA_NOWAIT);
d2335 3
a2337 3
	rx_buffer = &sc->rx_buffer_area[i];
	if (rx_buffer->m_head != NULL)
		bus_dmamap_unload(sc->rxtag, rx_buffer->map);
d2339 2
a2340 3
	map = rx_buffer->map;
	rx_buffer->map = sc->rx_sparemap;
	sc->rx_sparemap = map;
d2342 2
a2343 2
	bus_dmamap_sync(sc->rxtag, rx_buffer->map, 0,
	    rx_buffer->map->dm_mapsize, BUS_DMASYNC_PREREAD);
d2345 2
a2346 1
	rx_buffer->m_head = m;
d2348 1
a2348 1
	sc->rx_desc_base[i].buffer_addr = htole64(rx_buffer->map->dm_segs[0].ds_addr);
a2375 9
	error = bus_dmamap_create(sc->rxtag, MCLBYTES, 1, MCLBYTES,
		    0, BUS_DMA_NOWAIT, &sc->rx_sparemap);
	if (error != 0) {
		printf("%s: em_allocate_receive_structures: "
		    "bus_dmamap_create failed; error %u\n",
		    sc->sc_dv.dv_xname, error);
		goto fail;
	}

d2379 1
a2379 2
					MCLBYTES, 0, BUS_DMA_NOWAIT,
					&rx_buffer->map);
d2386 1
a2387 6

	for (i = 0; i < sc->num_rx_desc; i++) {
		error = em_get_buf(sc, i);
		if (error != 0)
			goto fail;
        }
d2415 8
d2502 1
a2502 1
	E1000_WRITE_REG(&sc->hw, RDT, sc->num_rx_desc - 1);
a2517 4
	if (sc->rx_sparemap) {
		bus_dmamap_destroy(sc->rxtag, sc->rx_sparemap);
		sc->rx_sparemap = NULL;
	}
d2521 1
a2521 2
			if (rx_buffer->map != NULL &&
			    rx_buffer->map->dm_nsegs > 0) {
d2525 1
a2525 4
				bus_dmamap_unload(sc->rxtag,
				    rx_buffer->map);
			}
			if (rx_buffer->m_head != NULL) {
d2529 1
a2529 5
			if (rx_buffer->map != NULL) {
				bus_dmamap_destroy(sc->rxtag,
				    rx_buffer->map);
				rx_buffer->map = NULL;
			}
d2538 75
d2628 2
a2629 2
	struct ifnet	    *ifp;
	struct mbuf	    *mp;
d2636 2
a2637 1
	struct em_rx_desc   *current_desc;
d2641 4
a2645 3
	current_desc = &sc->rx_desc_base[i];
	bus_dmamap_sync(sc->rxdma.dma_tag, sc->rxdma.dma_map, 0,
	    sc->rxdma.dma_map->dm_mapsize, BUS_DMASYNC_POSTREAD);
d2647 9
a2655 2
	if (!((current_desc->status) & E1000_RXD_STAT_DD))
		return;
d2657 7
a2663 4
	while ((current_desc->status & E1000_RXD_STAT_DD) &&
	    (count != 0) &&
	    (ifp->if_flags & IFF_RUNNING)) {
		struct mbuf *m = NULL;
d2665 2
a2666 7
		mp = sc->rx_buffer_area[i].m_head;
		/*
		 * Can't defer bus_dmamap_sync(9) because TBI_ACCEPT
		 * needs to access the last received byte in the mbuf.
		 */
		bus_dmamap_sync(sc->rxtag, sc->rx_buffer_area[i].map,
		    0, sc->rx_buffer_area[i].map->dm_mapsize,
d2668 11
d2682 2
a2683 2
		desc_len = letoh16(current_desc->length);
		status = current_desc->status;
d2697 1
a2697 1
		if (current_desc->errors & E1000_RXD_ERR_FRAME_ERR_MASK) {
d2704 2
a2705 2
			last_byte = *(mtod(mp, caddr_t) + desc_len - 1);
			if (TBI_ACCEPT(&sc->hw, status, current_desc->errors,
d2707 2
a2708 4
				em_tbi_adjust_stats(&sc->hw, 
						    &sc->stats, 
						    pkt_len, 
						    sc->hw.mac_addr);
a2715 5
			if (em_get_buf(sc, i) != 0) {
				sc->dropped_pkts++;
				goto discard;
			}

d2717 1
a2717 35
			mp->m_len = len;

#ifdef __STRICT_ALIGNMENT
			/*
			 * The Ethernet payload is not 32-bit aligned when
			 * Jumbo packets are enabled, so on architectures with
			 * strict alignment we need to shift the entire packet
			 * ETHER_ALIGN bytes. Ugh.
			 */
			if (sc->hw.max_frame_size > (MCLBYTES - ETHER_ALIGN)) {
				unsigned char tmp_align_buf[ETHER_ALIGN];
				int tmp_align_buf_len = 0;

				if (prev_len_adj > sc->align_buf_len)
					prev_len_adj -= sc->align_buf_len;
				else
					prev_len_adj = 0;

				if (mp->m_len > (MCLBYTES - ETHER_ALIGN)) {
					bcopy(mp->m_data +
					    (MCLBYTES - ETHER_ALIGN),
					    &tmp_align_buf,
					    ETHER_ALIGN);
					tmp_align_buf_len = mp->m_len -
					    (MCLBYTES - ETHER_ALIGN);
					mp->m_len -= ETHER_ALIGN;
				} 

				if (mp->m_len) {
					bcopy(mp->m_data,
					    mp->m_data + ETHER_ALIGN,
					    mp->m_len);
					if (!sc->align_buf_len)
						mp->m_data += ETHER_ALIGN;
				}
d2719 1
a2719 14
				if (sc->align_buf_len) {
					mp->m_len += sc->align_buf_len;
					bcopy(&sc->align_buf,
					    mp->m_data,
					    sc->align_buf_len);
				}

				if (tmp_align_buf_len) 
					bcopy(&tmp_align_buf,
					    &sc->align_buf,
					    tmp_align_buf_len);
				sc->align_buf_len = tmp_align_buf_len;
			}
#endif /* __STRICT_ALIGNMENT */
d2722 3
a2724 3
				mp->m_pkthdr.len = mp->m_len;
				sc->fmp = mp;	 /* Store the first mbuf */
				sc->lmp = mp;
d2727 1
a2727 1
				mp->m_flags &= ~M_PKTHDR;
d2737 3
a2739 3
				sc->lmp->m_next = mp;
				sc->lmp = sc->lmp->m_next;
				sc->fmp->m_pkthdr.len += mp->m_len;
a2742 1
				sc->fmp->m_pkthdr.rcvif = ifp;
a2743 1
				em_receive_checksum(sc, current_desc, sc->fmp);
d2745 4
d2750 3
a2752 3
				if (current_desc->status & E1000_RXD_STAT_VP) {
					sc->fmp->m_pkthdr.ether_vtag =
					    (current_desc->special &
d2754 7
a2760 1
					sc->fmp->m_flags |= M_VLANTAG;
d2764 2
a2765 1
				m = sc->fmp;
d2771 1
a2771 8
discard:
			/* Reuse loaded DMA map and just update mbuf chain */
			mp = sc->rx_buffer_area[i].m_head;
			mp->m_len = mp->m_pkthdr.len = MCLBYTES;
			mp->m_data = mp->m_ext.ext_buf;
			mp->m_next = NULL;
			if (sc->hw.max_frame_size <= (MCLBYTES - ETHER_ALIGN))
				m_adj(mp, ETHER_ALIGN);
d2777 2
a2778 1
			m = NULL;
d2781 3
a2783 5
		/* Zero out the receive descriptors status. */
		current_desc->status = 0;
		bus_dmamap_sync(sc->rxdma.dma_tag, sc->rxdma.dma_map, 0,
		    sc->rxdma.dma_map->dm_mapsize,
		    BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);
a2787 18
		if (m != NULL) {
			sc->next_rx_desc_to_check = i;

#if NBPFILTER > 0
			/*
			 * Handle BPF listeners. Let the BPF
			 * user see the packet.
			 */
			if (ifp->if_bpf)
				bpf_mtap_ether(ifp->if_bpf, m,
				    BPF_DIRECTION_IN);
#endif

			ether_input_mbuf(ifp, m);

			i = sc->next_rx_desc_to_check;
		}
		current_desc = &sc->rx_desc_base[i];
a2789 5

	/* Advance the E1000's Receive Queue #0  "Tail Pointer". */
	if (--i < 0)
		i = sc->num_rx_desc - 1;
	E1000_WRITE_REG(&sc->hw, RDT, i);
@


1.198
log
@Eliminate the redundant bits of code for MTU and multicast handling
from the individual drivers now that ether_ioctl() handles this.

Shrinks the i386 kernels by..
RAMDISK - 2176 bytes
RAMDISKB - 1504 bytes
RAMDISKC - 736 bytes

Tested by naddy@@/okan@@/sthen@@/brad@@/todd@@/jmc@@ and lots of users.
Build tested on almost all archs by todd@@/brad@@

ok naddy@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.197 2008/11/26 00:14:48 dlg Exp $ */
a166 6
#ifdef __STRICT_ALIGNMENT
void em_realign(struct em_softc *, struct mbuf *, u_int16_t *);
#else
#define em_realign(a, b, c) /* a, b, c */
#endif
void em_rxfill(struct em_softc *);
a800 1
			em_rxfill(sc);
a1450 3
	/* Tell the stack that the interface is no longer active */
	ifp->if_flags &= ~(IFF_RUNNING | IFF_OACTIVE);

d1457 3
d2290 2
a2291 2
	struct em_buffer *pkt;
	struct em_rx_desc *desc;
a2293 9
	pkt = &sc->rx_buffer_area[i];
	desc = &sc->rx_desc_base[i];

	if (pkt->m_head != NULL) {
		printf("%s: em_get_buf: slot %d already has an mbuf\n",
		    sc->sc_dv.dv_xname, i);
		return (ENOBUFS);
	}

d2299 1
a2299 1
	MCLGETI(m, M_DONTWAIT, &sc->interface_data.ac_if, MCLBYTES);
d2306 1
d2310 6
a2315 1
	error = bus_dmamap_load_mbuf(sc->rxtag, pkt->map, m, BUS_DMA_NOWAIT);
d2321 3
a2323 3
	bus_dmamap_sync(sc->rxtag, pkt->map, 0, pkt->map->dm_mapsize,
	    BUS_DMASYNC_PREREAD);
	pkt->m_head = m;
d2325 3
a2327 2
	bus_dmamap_sync(sc->rxdma.dma_tag, sc->rxdma.dma_map,
	    sizeof(*desc) * i, sizeof(*desc), BUS_DMASYNC_POSTWRITE);
d2329 2
a2330 2
	bzero(desc, sizeof(*desc));
	desc->buffer_addr = htole64(pkt->map->dm_segs[0].ds_addr);
d2332 1
a2332 2
	bus_dmamap_sync(sc->rxdma.dma_tag, sc->rxdma.dma_map,
	    sizeof(*desc) * i, sizeof(*desc), BUS_DMASYNC_PREWRITE);
d2334 1
a2334 1
	sc->rx_ndescs++;
d2362 9
d2374 2
a2375 1
		    MCLBYTES, 0, BUS_DMA_NOWAIT, &rx_buffer->map);
a2381 1
		rx_buffer->m_head = NULL;
d2383 6
a2415 8
	sc->last_rx_desc_filled = sc->num_rx_desc - 1;

	em_rxfill(sc);
	if (sc->num_rx_desc < 1) {
		printf("%s: unable to fill and rx descriptors\n",
		    sc->sc_dv.dv_xname);
	}

d2511 4
d2518 2
a2519 1
			if (rx_buffer->m_head != NULL) {
d2523 4
a2526 1
				bus_dmamap_unload(sc->rxtag, rx_buffer->map);
d2530 5
a2534 1
			bus_dmamap_destroy(sc->rxtag, rx_buffer->map);
a2542 74

	if (sc->fmp != NULL) {
		m_freem(sc->fmp);
		sc->fmp = NULL;
		sc->lmp = NULL;
	}
}

#ifdef __STRICT_ALIGNMENT
void
em_realign(struct em_softc *sc, struct mbuf *m, u_int16_t *prev_len_adj)
{
	unsigned char tmp_align_buf[ETHER_ALIGN];
	int tmp_align_buf_len = 0;

	/*
	 * The Ethernet payload is not 32-bit aligned when
	 * Jumbo packets are enabled, so on architectures with
	 * strict alignment we need to shift the entire packet
	 * ETHER_ALIGN bytes. Ugh.
	 */
	if (sc->hw.max_frame_size <= (MCLBYTES - ETHER_ALIGN))
		return;

	if (*prev_len_adj > sc->align_buf_len)
		*prev_len_adj -= sc->align_buf_len;
	else
		*prev_len_adj = 0;

	if (m->m_len > (MCLBYTES - ETHER_ALIGN)) {
		bcopy(m->m_data + (MCLBYTES - ETHER_ALIGN),
		    &tmp_align_buf, ETHER_ALIGN);
		tmp_align_buf_len = m->m_len -
		    (MCLBYTES - ETHER_ALIGN);
		m->m_len -= ETHER_ALIGN;
	} 

	if (m->m_len) {
		bcopy(m->m_data, m->m_data + ETHER_ALIGN, m->m_len);
		if (!sc->align_buf_len)
			m->m_data += ETHER_ALIGN;
	}

	if (sc->align_buf_len) {
		m->m_len += sc->align_buf_len;
		bcopy(&sc->align_buf, m->m_data, sc->align_buf_len);
	}

	if (tmp_align_buf_len) 
		bcopy(&tmp_align_buf, &sc->align_buf, tmp_align_buf_len);

	sc->align_buf_len = tmp_align_buf_len;
}
#endif /* __STRICT_ALIGNMENT */

void
em_rxfill(struct em_softc *sc)
{
	int i;

	i = sc->last_rx_desc_filled;

	while (sc->rx_ndescs < sc->num_rx_desc) {
		if (++i == sc->num_rx_desc)
			i = 0;

		if (em_get_buf(sc, i) != 0)
			break;

		sc->last_rx_desc_filled = i;
	}

	/* Advance the E1000's Receive Queue #0  "Tail Pointer". */
	E1000_WRITE_REG(&sc->hw, RDT, sc->last_rx_desc_filled);
d2558 2
a2559 2
	struct ifnet	    *ifp = &sc->interface_data.ac_if;
	struct mbuf	    *m;
d2566 1
a2566 2
	struct em_rx_desc   *desc;
	struct em_buffer    *pkt;
d2570 4
d2575 1
a2575 1
	if (!ISSET(ifp->if_flags, IFF_RUNNING))
d2578 4
a2581 1
	i = sc->next_rx_desc_to_check;
d2583 7
a2589 20
	while (count != 0 && sc->rx_ndescs > 1) {
		m = NULL;

		desc = &sc->rx_desc_base[i];
		pkt = &sc->rx_buffer_area[i];

		bus_dmamap_sync(sc->rxdma.dma_tag, sc->rxdma.dma_map,
		    sizeof(*desc) * i, sizeof(*desc),
		    BUS_DMASYNC_POSTREAD);

		status = desc->status;
		if (!ISSET(status, E1000_RXD_STAT_DD)) {
			bus_dmamap_sync(sc->rxdma.dma_tag, sc->rxdma.dma_map,
			    sizeof(*desc) * i, sizeof(*desc),
			    BUS_DMASYNC_PREREAD);
			break;
		}

		/* pull the mbuf off the ring */
		bus_dmamap_sync(sc->rxtag, pkt->map, 0, pkt->map->dm_mapsize,
a2590 8
		bus_dmamap_unload(sc->rxtag, pkt->map);
		m = pkt->m_head;
		pkt->m_head = NULL;

		if (m == NULL)
			printf("omg teh nulls\n");

		sc->rx_ndescs--;
d2594 2
a2595 2
		desc_len = letoh16(desc->length);

d2609 1
a2609 1
		if (desc->errors & E1000_RXD_ERR_FRAME_ERR_MASK) {
d2616 2
a2617 2
			last_byte = *(mtod(m, caddr_t) + desc_len - 1);
			if (TBI_ACCEPT(&sc->hw, status, desc->errors,
d2619 4
a2622 2
				em_tbi_adjust_stats(&sc->hw, &sc->stats, 
				    pkt_len, sc->hw.mac_addr);
d2630 5
d2636 1
a2636 1
			m->m_len = len;
d2638 48
a2685 1
			em_realign(sc, m, &prev_len_adj); /* STRICT_ALIGN */
d2688 3
a2690 3
				m->m_pkthdr.len = m->m_len;
				sc->fmp = m;	 /* Store the first mbuf */
				sc->lmp = m;
d2693 1
a2693 1
				m->m_flags &= ~M_PKTHDR;
d2703 3
a2705 3
				sc->lmp->m_next = m;
				sc->lmp = m;
				sc->fmp->m_pkthdr.len += m->m_len;
d2709 1
d2711 1
a2712 4
				m = sc->fmp;
				m->m_pkthdr.rcvif = ifp;

				em_receive_checksum(sc, desc, m);
d2714 3
a2716 3
				if (desc->status & E1000_RXD_STAT_VP) {
					m->m_pkthdr.ether_vtag =
					    (desc->special &
d2718 1
a2718 7
					m->m_flags |= M_VLANTAG;
				}
#endif
#if NBPFILTER > 0
				if (ifp->if_bpf) {
					bpf_mtap_ether(ifp->if_bpf, m,
					    BPF_DIRECTION_IN);
d2722 1
a2722 2
				ether_input_mbuf(ifp, m);

d2728 8
a2735 1

d2741 1
a2741 2

			m_freem(m);
d2744 5
a2748 3
		bus_dmamap_sync(sc->rxdma.dma_tag, sc->rxdma.dma_map,
		    sizeof(*desc) * i, sizeof(*desc),
		    BUS_DMASYNC_PREREAD);
d2753 18
d2773 5
@


1.197
log
@rework the filling of the rx ring. this switches us to having the cluster
allocation limited by per ifp statistics, ie, we're not guaranteed to have
mbufs in every slot on the rx ring.

instead of filling the ring with 256 mbufs all the time (about 512KB of
kva) when em is brought up, we give it 4. as demand grows we increase the
number of mbufs allowed on the ring. i will bet most users wont go above
50ish mbufs, so we're saving them 400KB of kva.

tested by many, including one on sparc64
ok claudio@@ deraadt@@ henning@@ krw@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.196 2008/11/24 17:08:36 dlg Exp $ */
d558 1
a558 7
	case SIOCSIFMTU:
		IOCTL_DEBUGOUT("ioctl rcv'd: SIOCSIFMTU (Set Interface MTU)");
		if (ifr->ifr_mtu < ETHERMIN || ifr->ifr_mtu > ifp->if_hardmtu)
			error = EINVAL;
		else if (ifp->if_mtu != ifr->ifr_mtu)
			ifp->if_mtu = ifr->ifr_mtu;
		break;
d581 1
a581 18
	case SIOCADDMULTI:
	case SIOCDELMULTI:
		IOCTL_DEBUGOUT("ioctl rcv'd: SIOC(ADD|DEL)MULTI");
		error = (command == SIOCADDMULTI)
			? ether_addmulti(ifr, &sc->interface_data)
			: ether_delmulti(ifr, &sc->interface_data);

		if (error == ENETRESET) {
			if (ifp->if_flags & IFF_RUNNING) {
				em_disable_intr(sc);
				em_set_multi(sc);
				if (sc->hw.mac_type == em_82542_rev2_0)
					em_initialize_receive_unit(sc);
				em_enable_intr(sc);
			}
			error = 0;
		}
		break;
d593 1
d596 11
@


1.196
log
@some whitespace fixes in em_rxeof
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.195 2008/11/09 15:08:26 naddy Exp $ */
d167 6
d818 1
d1469 3
a1477 3
	/* Tell the stack that the interface is no longer active */
	ifp->if_flags &= ~(IFF_RUNNING | IFF_OACTIVE);

d2308 2
a2309 2
	bus_dmamap_t	map;
	struct em_buffer *rx_buffer;
d2312 9
d2326 1
a2326 1
	MCLGET(m, M_DONTWAIT);
a2332 1

d2336 1
a2336 6
	/*
	 * Using memory from the mbuf cluster pool, invoke the
	 * bus_dma machinery to arrange the memory mapping.
	 */
	error = bus_dmamap_load_mbuf(sc->rxtag, sc->rx_sparemap,
	    m, BUS_DMA_NOWAIT);
d2342 3
a2344 3
	rx_buffer = &sc->rx_buffer_area[i];
	if (rx_buffer->m_head != NULL)
		bus_dmamap_unload(sc->rxtag, rx_buffer->map);
d2346 2
a2347 3
	map = rx_buffer->map;
	rx_buffer->map = sc->rx_sparemap;
	sc->rx_sparemap = map;
d2349 2
a2350 2
	bus_dmamap_sync(sc->rxtag, rx_buffer->map, 0,
	    rx_buffer->map->dm_mapsize, BUS_DMASYNC_PREREAD);
d2352 2
a2353 1
	rx_buffer->m_head = m;
d2355 1
a2355 1
	sc->rx_desc_base[i].buffer_addr = htole64(rx_buffer->map->dm_segs[0].ds_addr);
a2382 9
	error = bus_dmamap_create(sc->rxtag, MCLBYTES, 1, MCLBYTES,
		    0, BUS_DMA_NOWAIT, &sc->rx_sparemap);
	if (error != 0) {
		printf("%s: em_allocate_receive_structures: "
		    "bus_dmamap_create failed; error %u\n",
		    sc->sc_dv.dv_xname, error);
		goto fail;
	}

d2386 1
a2386 2
					MCLBYTES, 0, BUS_DMA_NOWAIT,
					&rx_buffer->map);
d2393 1
a2394 6

	for (i = 0; i < sc->num_rx_desc; i++) {
		error = em_get_buf(sc, i);
		if (error != 0)
			goto fail;
        }
d2422 8
a2524 4
	if (sc->rx_sparemap) {
		bus_dmamap_destroy(sc->rxtag, sc->rx_sparemap);
		sc->rx_sparemap = NULL;
	}
d2528 1
a2528 2
			if (rx_buffer->map != NULL &&
			    rx_buffer->map->dm_nsegs > 0) {
d2532 1
a2532 4
				bus_dmamap_unload(sc->rxtag,
				    rx_buffer->map);
			}
			if (rx_buffer->m_head != NULL) {
d2536 1
a2536 5
			if (rx_buffer->map != NULL) {
				bus_dmamap_destroy(sc->rxtag,
				    rx_buffer->map);
				rx_buffer->map = NULL;
			}
d2545 74
d2634 2
a2635 2
	struct ifnet	    *ifp;
	struct mbuf	    *mp;
d2642 2
a2643 1
	struct em_rx_desc   *current_desc;
d2647 4
a2651 3
	current_desc = &sc->rx_desc_base[i];
	bus_dmamap_sync(sc->rxdma.dma_tag, sc->rxdma.dma_map, 0,
	    sc->rxdma.dma_map->dm_mapsize, BUS_DMASYNC_POSTREAD);
d2653 9
a2661 2
	if (!((current_desc->status) & E1000_RXD_STAT_DD))
		return;
d2663 7
a2669 4
	while ((current_desc->status & E1000_RXD_STAT_DD) &&
	    (count != 0) &&
	    (ifp->if_flags & IFF_RUNNING)) {
		struct mbuf *m = NULL;
d2671 2
a2672 7
		mp = sc->rx_buffer_area[i].m_head;
		/*
		 * Can't defer bus_dmamap_sync(9) because TBI_ACCEPT
		 * needs to access the last received byte in the mbuf.
		 */
		bus_dmamap_sync(sc->rxtag, sc->rx_buffer_area[i].map,
		    0, sc->rx_buffer_area[i].map->dm_mapsize,
d2674 8
d2685 2
a2686 2
		desc_len = letoh16(current_desc->length);
		status = current_desc->status;
d2700 1
a2700 1
		if (current_desc->errors & E1000_RXD_ERR_FRAME_ERR_MASK) {
d2707 2
a2708 2
			last_byte = *(mtod(mp, caddr_t) + desc_len - 1);
			if (TBI_ACCEPT(&sc->hw, status, current_desc->errors,
d2710 2
a2711 4
				em_tbi_adjust_stats(&sc->hw, 
						    &sc->stats, 
						    pkt_len, 
						    sc->hw.mac_addr);
a2718 5
			if (em_get_buf(sc, i) != 0) {
				sc->dropped_pkts++;
				goto discard;
			}

d2720 1
a2720 1
			mp->m_len = len;
d2722 1
a2722 48
#ifdef __STRICT_ALIGNMENT
			/*
			 * The Ethernet payload is not 32-bit aligned when
			 * Jumbo packets are enabled, so on architectures with
			 * strict alignment we need to shift the entire packet
			 * ETHER_ALIGN bytes. Ugh.
			 */
			if (sc->hw.max_frame_size > (MCLBYTES - ETHER_ALIGN)) {
				unsigned char tmp_align_buf[ETHER_ALIGN];
				int tmp_align_buf_len = 0;

				if (prev_len_adj > sc->align_buf_len)
					prev_len_adj -= sc->align_buf_len;
				else
					prev_len_adj = 0;

				if (mp->m_len > (MCLBYTES - ETHER_ALIGN)) {
					bcopy(mp->m_data +
					    (MCLBYTES - ETHER_ALIGN),
					    &tmp_align_buf,
					    ETHER_ALIGN);
					tmp_align_buf_len = mp->m_len -
					    (MCLBYTES - ETHER_ALIGN);
					mp->m_len -= ETHER_ALIGN;
				} 

				if (mp->m_len) {
					bcopy(mp->m_data,
					    mp->m_data + ETHER_ALIGN,
					    mp->m_len);
					if (!sc->align_buf_len)
						mp->m_data += ETHER_ALIGN;
				}

				if (sc->align_buf_len) {
					mp->m_len += sc->align_buf_len;
					bcopy(&sc->align_buf,
					    mp->m_data,
					    sc->align_buf_len);
				}

				if (tmp_align_buf_len) 
					bcopy(&tmp_align_buf,
					    &sc->align_buf,
					    tmp_align_buf_len);
				sc->align_buf_len = tmp_align_buf_len;
			}
#endif /* __STRICT_ALIGNMENT */
d2725 3
a2727 3
				mp->m_pkthdr.len = mp->m_len;
				sc->fmp = mp;	 /* Store the first mbuf */
				sc->lmp = mp;
d2730 1
a2730 1
				mp->m_flags &= ~M_PKTHDR;
d2740 3
a2742 3
				sc->lmp->m_next = mp;
				sc->lmp = sc->lmp->m_next;
				sc->fmp->m_pkthdr.len += mp->m_len;
a2745 1
				sc->fmp->m_pkthdr.rcvif = ifp;
a2746 1
				em_receive_checksum(sc, current_desc, sc->fmp);
d2748 4
d2753 3
a2755 3
				if (current_desc->status & E1000_RXD_STAT_VP) {
					sc->fmp->m_pkthdr.ether_vtag =
					    (current_desc->special &
d2757 1
a2757 1
					sc->fmp->m_flags |= M_VLANTAG;
d2760 8
a2768 1
				m = sc->fmp;
d2774 1
a2774 8
discard:
			/* Reuse loaded DMA map and just update mbuf chain */
			mp = sc->rx_buffer_area[i].m_head;
			mp->m_len = mp->m_pkthdr.len = MCLBYTES;
			mp->m_data = mp->m_ext.ext_buf;
			mp->m_next = NULL;
			if (sc->hw.max_frame_size <= (MCLBYTES - ETHER_ALIGN))
				m_adj(mp, ETHER_ALIGN);
d2780 2
a2781 1
			m = NULL;
d2784 3
a2786 5
		/* Zero out the receive descriptors status. */
		current_desc->status = 0;
		bus_dmamap_sync(sc->rxdma.dma_tag, sc->rxdma.dma_map, 0,
		    sc->rxdma.dma_map->dm_mapsize,
		    BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);
a2790 18
		if (m != NULL) {
			sc->next_rx_desc_to_check = i;

#if NBPFILTER > 0
			/*
			 * Handle BPF listeners. Let the BPF
			 * user see the packet.
			 */
			if (ifp->if_bpf)
				bpf_mtap_ether(ifp->if_bpf, m,
				    BPF_DIRECTION_IN);
#endif

			ether_input_mbuf(ifp, m);

			i = sc->next_rx_desc_to_check;
		}
		current_desc = &sc->rx_desc_base[i];
a2792 5

	/* Advance the E1000's Receive Queue #0  "Tail Pointer". */
	if (--i < 0)
		i = sc->num_rx_desc - 1;
	E1000_WRITE_REG(&sc->hw, RDT, i);
@


1.195
log
@Introduce bpf_mtap_ether(), which for the benefit of bpf listeners
creates the VLAN encapsulation from the tag stored in the mbuf
header.  Idea from FreeBSD, input from claudio@@ and canacar@@.

Switch all hardware VLAN enabled drivers to the new function.

ok claudio@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.194 2008/10/28 05:43:11 brad Exp $ */
d2578 1
a2578 1
	u_int8_t            status;
d2629 1
a2629 1
				       pkt_len, last_byte)) {
d2705 12
a2716 11
                                /*
                                 * Adjust length of previous mbuf in chain if we
                                 * received less than 4 bytes in the last descriptor.
                                 */
                                if (prev_len_adj > 0) {
                                        sc->lmp->m_len -= prev_len_adj;
                                        sc->fmp->m_pkthdr.len -= prev_len_adj;
                                }
                                sc->lmp->m_next = mp;
                                sc->lmp = sc->lmp->m_next;
                                sc->fmp->m_pkthdr.len += mp->m_len;
@


1.194
log
@Some tweaks for the usage of NVLAN > 0 checks in the code.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.193 2008/10/19 19:53:09 brad Exp $ */
d496 1
a496 1
			bpf_mtap(ifp->if_bpf, m_head, BPF_DIRECTION_OUT);
d2772 2
a2773 1
				bpf_mtap(ifp->if_bpf, m, BPF_DIRECTION_IN);
@


1.193
log
@Re-add support TX VLAN tag insertion and RX VLAN tag stripping.

Tested by naddy@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.192 2008/10/15 19:12:18 blambert Exp $ */
d1111 1
d1121 1
d2721 3
a2723 2
				em_receive_checksum(sc, current_desc,
					    sc->fmp);
d2730 2
@


1.192
log
@Second pass of simple timeout_add -> timeout_add_sec conversions
This should take care of the simpler ones (i.e., timeout values of
integer multiples of hz).

ok krw@@, art@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.191 2008/10/05 11:57:48 kettenis Exp $ */
d181 1
d743 4
d1111 10
d1736 4
d2721 6
d2819 14
@


1.191
log
@Always update published link state even if the internal link state doesn't
change.  Prevents us from getting stuck in LINK_STATE_UNKNOWN.  Fixes PR 5914.

tested by deraadt@@, sthen@@
ok deraadt@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.190 2008/10/02 20:21:14 brad Exp $ */
d771 1
a771 1
	timeout_add(&sc->timer_handle, hz);
d816 1
a816 1
			timeout_add(&sc->timer_handle, hz); 
d1382 1
a1382 1
	timeout_add(&sc->timer_handle, hz);
@


1.190
log
@First step towards cleaning up the Ethernet driver ioctl handling.
Move calling ether_ioctl() from the top of the ioctl function, which
at the moment does absolutely nothing, to the default switch case.
Thus allowing drivers to define their own ioctl handlers and then
falling back on ether_ioctl(). The only functional change this results
in at the moment is having all Ethernet drivers returning the proper
errno of ENOTTY instead of EINVAL/ENXIO when encountering unknown
ioctl's.

Shrinks the i386 kernels by..
RAMDISK - 1024 bytes
RAMDISKB -  1120 bytes
RAMDISKC - 832 bytes

Tested by martin@@/jsing@@/todd@@/brad@@
Build tested on almost all archs by todd@@/brad@@

ok jsing@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.189 2008/09/30 17:59:22 brad Exp $ */
d1410 2
d1423 2
@


1.189
log
@style nits.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.188 2008/09/24 19:12:59 chl Exp $ */
a537 5
	if ((error = ether_ioctl(ifp, &sc->interface_data, command, data)) > 0) {
		splx(s);
		return (error);
	}

d610 1
a610 2
		IOCTL_DEBUGOUT1("ioctl received: UNKNOWN (0x%x)", (int)command);
		error = ENOTTY;
@


1.188
log
@remove dead stores and newly created unused variables.

Found by LLVM/Clang Static Analyzer.

ok henning@@ brad@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.187 2008/08/29 23:28:34 brad Exp $ */
d1860 1
a1860 3
			    dma->dma_vaddr,
			    size,
			    NULL,
@


1.187
log
@Disable the use of Jumbo frames on the first generation chips (82542).
The exact details are unknown (possibly hw errata?) but the Windows
and Linux drivers have never supported Jumbos on this chipset and since
it is so old and rare it is not that big of a deal.

From FreeBSD

ok dlg@@ awhile ago.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.186 2008/07/15 17:50:20 kettenis Exp $ */
a2422 1
	struct ifnet	*ifp;
a2425 1
	ifp = &sc->interface_data.ac_if;
@


1.186
log
@Backout rev 1.162.  This change made us muck with with pci config space at
address 0x1a and 0x1e, and that's not where the PCIe capability stuff
lives.  Potentially it was mucking with an IO BAR (super dangerous).
But probably it was achieving nothing at all.

ok dlg@@, marco@@, brad@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.185 2008/06/15 16:37:00 millert Exp $ */
d318 3
a321 1
			/* ICH8 does not support jumbo frames */
@


1.185
log
@Don't see rx_abs_int_delay if rx_int_delay is not set.  Setting
rx_abs_int_delay to be non-zero when rx_int_delay is zero appears
to trigger a bug elsewhere in the kernel for certain em revisions.
Based on a diff from beck@@.  OK beck@@ marco@@ henning@@ brad@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.184 2008/06/08 16:20:27 reyk Exp $ */
d2872 4
d2879 1
a2879 17
	struct pci_attach_args *pa = &((struct em_osdep *)hw->back)->em_pa;
	int32_t	rc;
	u_int16_t pectl;

	/* find the PCIe link width and set max read request to 4KB */
	if (pci_get_capability(pa->pa_pc, pa->pa_tag, PCI_CAP_PCIEXPRESS,
	    NULL, NULL) != 0) {
		em_read_pci_cfg(hw, reg + 0x12, value);

		em_read_pci_cfg(hw, reg + 0x8, &pectl);
		pectl = (pectl & ~0x7000) | (5 << 12);
		em_write_pci_cfg(hw, reg + 0x8, &pectl);
		rc = 0;
	} else
		rc = -1;

	return (rc);
@


1.184
log
@don't declare foo_driver_version[] strings and turn them into defines,
nothing uses them and it saves a few bytes in the kernel.

ok claudio@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.183 2008/06/03 12:45:27 brad Exp $ */
d2435 2
a2436 1
		E1000_WRITE_REG(&sc->hw, RADV, sc->rx_abs_int_delay);
@


1.183
log
@put code to print periodic debug statistics in #ifdef EM_DEBUG, shrinks
the driver for about 292 bytes on i386.

ok reyk@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.182 2008/05/13 01:40:39 brad Exp $ */
d50 1
a50 1
char em_driver_version[] = "6.2.9";
@


1.182
log
@Since Ethernet links can only be full duplex or half duplex the link
state reporting code in the MII layer / em(4) and vge(4) will never
fall back to the point of only reporting the link as being UP without
the duplex setting being reported, so simplify the code a bit here.

ok dlg@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.181 2008/04/09 12:50:11 dlg Exp $ */
d39 1
d44 1
d176 1
d178 1
d1379 2
a1380 1
	em_update_stats_counters(sc);	
d1383 1
d3050 1
d3108 1
@


1.181
log
@dma sync the tx ring and post new packets to the chip once per call to
the start routine instead of once per packet.

tested on various archs including amd64, i386, and sparc64.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.179 2008/03/02 00:02:11 brad Exp $ */
d1410 1
a1410 1
			else if (sc->link_duplex == HALF_DUPLEX)
a1411 2
			else
				ifp->if_link_state = LINK_STATE_UP;
@


1.180
log
@At the moment em_flowstatus() does not deal with fiber interfaces and
will not return any flow control status so just return no status (0)
instead of reading copper PHY registers and not returning anything
anyway.

ok kettenis@@
@
text
@d460 1
d468 6
a475 1

d494 16
a509 1
	}	
d1010 6
d1032 1
a1032 1
		return (error);
d1132 8
a1139 9
	bus_dmamap_sync(sc->txdma.dma_tag, sc->txdma.dma_map, 0,
	    sc->txdma.dma_map->dm_mapsize,
	    BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);
	if (sc->hw.mac_type == em_82547 &&
	    sc->link_duplex == HALF_DUPLEX) {
		em_82547_move_tail_locked(sc);
	} else {
		E1000_WRITE_REG(&sc->hw, TDT, i);
		if (sc->hw.mac_type == em_82547)
d1141 1
d1149 8
a1156 1
	return (ENOBUFS);
@


1.179
log
@If bus_dmamap_load_mbuf() fails in em_get_buf() use m_freem() intead of
m_free() to free the mbuf cluster.

ok krw@@ mglocker@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.178 2008/02/27 20:05:51 brad Exp $ */
d934 4
@


1.178
log
@Correct the watchdog timer by moving it out from under the condition check
for the IFF_OACTIVE flag.

Tested by brad@@, johan@@, krw@@, wilfried@@

From mickey
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.177 2008/02/20 00:00:06 brad Exp $ */
d2267 1
a2267 1
		m_free(m);
@


1.177
log
@Add support for the Intel ICH9 chipsets.

Initial diff from Henry Precheur based on a commit from matthias@@dragonflybsd
which was derived from the FreeBSD driver. Additional Flash changes from
sephe@@dragonflybsd which was derived from the FreeBSD driver. Typo fixes
in Henry's diff and a few other improvements from the FreeBSD driver from
brad@@.

Tested on a variety of different em(4) adapters in addition to ICH8/9.

ok dlg@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.176 2008/02/04 00:30:01 brad Exp $ */
d2218 1
a2218 1
	if (num_avail > EM_TX_CLEANUP_THRESHOLD) {
d2220 8
a2227 7
		/* All clean, turn off the timer */
		if (num_avail == sc->num_tx_desc)
			ifp->if_timer = 0;
		/* Some cleaned, reset the timer */
		else if (num_avail != sc->num_tx_desc_avail)
			ifp->if_timer = EM_TX_TIMEOUT;
	}
@


1.176
log
@Add PCI ids for some 82571 based multi port adapters.

From FreeBSD

ok dlg@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.175 2008/02/02 05:11:51 brad Exp $ */
a116 3
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_ICH8_IGP_M_AMT },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_ICH8_IGP_AMT },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_ICH8_IGP_C },
d120 9
a128 1
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_ICH8_IGP_M }
d310 1
d695 3
d1498 3
a1500 2
	/* for ICH8 we need to find the flash memory */
	if (sc->hw.mac_type == em_ich8lan) {
@


1.175
log
@Move the current flow control status code out of em_media_status()
and into a separate function which was modeled after the MII
frameworks mii_phy_flowstatus() function. This was done so as to
make em_media_status() a little nicer looking and so that when flow
control status is added for fiber adapters that em_media_status()
won't look so ugly. No functional change.

Tested by wilfried@@ and brad@@

ok dlg@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.174 2007/10/21 03:49:54 brad Exp $ */
d103 3
@


1.174
log
@Allow for the adjustment of the number of RX descriptors
for the newer generations of em(4) chipsets independently
from the first two generations (82542/82543). The first
two generations have hardware errata limiting the upper
maximum to 256 descriptors. The number of RX descriptors
has not been adjusted yet.

ok beck@@ henning@@ dlg@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.173 2007/10/01 15:34:48 krw Exp $ */
d138 1
d809 1
a809 1
	u_int16_t ar, lpar, gsr;
d845 1
a845 1
			ifmr->ifm_active |= IFM_FDX;
a848 15
		if (ifmr->ifm_active & IFM_FDX) {
			em_read_phy_reg(&sc->hw, PHY_AUTONEG_ADV, &ar);
			em_read_phy_reg(&sc->hw, PHY_LP_ABILITY, &lpar);

			if ((ar & NWAY_AR_PAUSE) && (lpar & NWAY_LPAR_PAUSE))
				ifmr->ifm_active |= IFM_FLOW | IFM_ETH_TXPAUSE |
						    IFM_ETH_RXPAUSE;
			else if (!(ar & NWAY_AR_PAUSE) && (ar & NWAY_AR_ASM_DIR) &&
			    (lpar & NWAY_LPAR_PAUSE) && (lpar & NWAY_LPAR_ASM_DIR))
				ifmr->ifm_active |= IFM_FLOW | IFM_ETH_TXPAUSE;
			else if ((ar & NWAY_AR_PAUSE) && (ar & NWAY_AR_ASM_DIR) &&
			    !(lpar & NWAY_LPAR_PAUSE) && (lpar & NWAY_LPAR_ASM_DIR))
				ifmr->ifm_active |= IFM_FLOW | IFM_ETH_RXPAUSE;
		}

d914 20
@


1.173
log
@More easy bzero() -> M_ZERO. Use 'p = malloc(sizeof(*p) ...' where
obvious.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.172 2007/05/31 01:04:57 henning Exp $ */
d332 6
a337 2
	rsize = EM_ROUNDUP(sc->num_rx_desc * sizeof(struct em_rx_desc),
	    EM_MAX_RXD * sizeof(struct em_rx_desc));
d638 1
a638 1
		if (sc->hw.mac_type >= em_82544)
d640 2
a641 1
		else
d643 2
a644 1
		sc->num_rx_desc = EM_MAX_RXD;
@


1.172
log
@only call em_init() when IFF_UP is set, not unconditional.
prevents another round of autonegotiation (and thus, few seconds outage)
with every address change that had to be reintroduced a few revs ago
because of the watchdog timeout problems people were seeing.
this gives the benifit from both with the problems of neither ;)
tested by daniel polak on a system that saw the watchdog timeouts before
ok theo
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.171 2007/05/31 00:47:53 ckuethe Exp $ */
d1844 2
a1845 4
	if (!(sc->tx_buffer_area =
	      (struct em_buffer *) malloc(sizeof(struct em_buffer) *
					     sc->num_tx_desc, M_DEVBUF,
					     M_NOWAIT))) {
a1850 3
	bzero(sc->tx_buffer_area,
	      sizeof(struct em_buffer) * sc->num_tx_desc);

d2277 2
a2278 4
	if (!(sc->rx_buffer_area =
	      (struct em_buffer *) malloc(sizeof(struct em_buffer) *
					     sc->num_rx_desc, M_DEVBUF,
					     M_NOWAIT))) {
a2282 3

	bzero(sc->rx_buffer_area,
	      sizeof(struct em_buffer) * sc->num_rx_desc);
@


1.171
log
@1000 != 0x1000 (4096)

Bring the flow control delay time down to what the comment says it should
be. By using a smaller flow control pause time when the buffer isn't full,
my em(4) goes about 20Mbps faster.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.170 2007/05/30 06:29:17 ckuethe Exp $ */
d506 4
a509 2
		ifp->if_flags |= IFF_UP;
		em_init(sc);
@


1.170
log
@Move the knob for the interrupt throttling register next to the knobs for
the other interrupt moderation schemes.
ok beck drahn
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.169 2007/05/09 18:02:46 deraadt Exp $ */
d1610 1
a1610 1
		sc->hw.fc_pause_time = 0x1000;
@


1.169
log
@delete unused functions.  typical vendor garbage driver..; ok kettenis
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.168 2007/05/09 17:32:59 kettenis Exp $ */
a2378 2
#define MAX_INTS_PER_SEC	8000
#define DEFAULT_ITR		1000000000/(MAX_INTS_PER_SEC * 256)
@


1.168
log
@Revert rev 1.116.  For some reason this caused the device to do DMA from/to
random addresses in some cases, causing watchdog timeouts.

tested by many; ok deraadt@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.167 2007/03/16 00:07:36 reyk Exp $ */
d159 1
d162 1
d2025 1
d2106 1
@


1.167
log
@A new PCI id for Intel's PCIe quad port fiber adapter.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.166 2007/01/26 15:55:30 weingart Exp $ */
d505 1
a505 2
		if (!(ifp->if_flags & IFF_RUNNING))
			em_init(sc);
@


1.166
log
@
Workaround for an issue with em(4) interfaces on Lenovo X60/T60 laptops where
the interface will fail to initialize with an EEPROM error if the interface
does not have a link upon boot.

Tested by mk@@ and janek@@

From Jack Vogel@@Intel via brad
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.165 2007/01/21 18:38:02 kettenis Exp $ */
d101 1
@


1.165
log
@Fix typo.  From brad@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.164 2007/01/15 22:51:05 kettenis Exp $ */
d1556 10
a1565 3
		printf("%s: The EEPROM Checksum Is Not Valid\n",
		       sc->sc_dv.dv_xname);
		return (EIO);
@


1.164
log
@Report flow control status.

From brad@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.163 2006/12/27 14:33:04 kettenis Exp $ */
d844 1
a844 1
						    IFM_ETH_TXPAUSE;
@


1.163
log
@Set IFM_ETH_MASTER if local PHY configuration resolved to MASTER.

From brad@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.162 2006/12/06 23:25:58 reyk Exp $ */
d798 1
a798 1
	u_int16_t gsr;
d837 15
@


1.162
log
@Implement em_read_pcie_cap_reg(), where we set the max read size on
PCIe to 4k.

>From kmacy@@FreeBSD
Tested by mk@@ and Johan Mson Lindman <tybollt at solace dot mh dot se>
with the 82573 chipset.

ok brad@@ mglocker@@ mk@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.161 2006/12/04 14:35:20 reyk Exp $ */
d798 1
d832 1
d837 6
@


1.161
log
@report full/half duplex state for non-MII interfaces

ok brad@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.160 2006/11/21 02:42:27 brad Exp $ */
a2778 4
/*
 * We may eventually really do this, but its unnecessary
 * for now so we just return unsupported.
 */
d2782 17
a2798 1
	return (0);
@


1.160
log
@Remove watchdog handler workaround introduced in rev 1.149 which is no
longer necessary.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.159 2006/11/21 02:30:37 brad Exp $ */
d1319 6
a1324 1
			ifp->if_link_state = LINK_STATE_UP;
@


1.159
log
@style changes. no op.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.158 2006/11/18 18:39:14 brad Exp $ */
a596 8

	/*
	 * Reclaim first as there is a possibility of losing Tx completion
	 * interrupts.
	 */
	em_txeof(sc);
	if (sc->num_tx_desc_avail == sc->num_tx_desc)
 		return;
@


1.158
log
@fix comments
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.157 2006/11/17 02:03:32 brad Exp $ */
d588 1
a588 2
	struct em_softc *sc;
	sc = ifp->if_softc;
d787 1
a787 2
	if (ifp->if_flags & IFF_RUNNING &&
	    IFQ_IS_EMPTY(&ifp->if_snd) == 0)
d804 1
a804 1
	struct em_softc *sc= ifp->if_softc;
@


1.157
log
@Add a lower TX threshold value and use this when checking the number of
available TX descriptors in the case that em_encap() has tried to reclaim
descriptors.

From Jack Vogel@@Intel

Tested by brad@@, mk@@, Gabriel Kihlman <gk at stacken dot kth dot se>,
Johan Mson Lindman <tybollt at solace dot mh dot se>
Tested on amd64/i386/sparc64
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.156 2006/11/14 03:59:00 brad Exp $ */
a671 1
	/* Total Packet Buffer on these is 48k */
d673 1
a673 1
	case em_82572:
@


1.156
log
@Rework the transmit register handling. In em_encap() store the index of
the EOP descriptor in the first descriptor of the packet. In em_txeof()
search for the DD bit set only in the EOP descriptors, embedding the
cleanup of all packet's descriptors into the inner loop.

This change is important for future chips, where the DD bit is going
to be set only in the EOP descriptors.

From Jack Vogel@@Intel

Tested by brad@@, mk@@, reyk@@, Gabriel Kihlman <gk at stacken dot kth dot se>,
Johan Mson Lindman <tybollt at solace dot mh dot se>, Jason Dixon and a few
others.
Tested on i386/amd64/sparc64.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.155 2006/11/10 21:15:56 brad Exp $ */
d938 2
a939 1
		if (sc->num_tx_desc_avail <= EM_TX_CLEANUP_THRESHOLD) {
d2106 4
a2109 2
	 * Now calculate the terminating index
	 * for the cleanup loop below.
d2170 1
d2173 1
@


1.155
log
@Pre-allocate the TX DMA maps intead of creating and destroying a DMA map
per packet sent.

Tested by brad@@, ckuethe@@, Gabriel Kihlman <gk at stacken dot kth dot se>
and Tim Wiess <tim at nop dot cx>.
Tested with amd64/i386/sparc64.

ok damien@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.154 2006/11/07 21:05:56 brad Exp $ */
d921 1
a921 1
	int		i, j, error = 0;
d929 1
a929 1
	struct em_buffer   *tx_buffer;
d946 5
d952 3
a954 3
	tx_buffer = &sc->tx_buffer_area[sc->next_avail_tx_desc];
	error = bus_dmamap_load_mbuf(sc->txtag, tx_buffer->map,
				     m_head, BUS_DMA_NOWAIT);
d956 2
d964 1
a964 2
	if (map->dm_nsegs > sc->num_tx_desc_avail) {
		sc->no_tx_desc_avail2++;
a965 1
	}
d977 1
a977 1
	if (sc->pcix_82544) {
d979 1
a979 2
		txd_used = 0;
	}
a992 1
					sc->no_tx_desc_avail2++;
d1003 1
d1008 1
d1019 1
a1019 1

d1024 1
d1035 2
d1041 10
a1050 1
	 * Last Descriptor of Packet needs End Of Packet (EOP) 
d1052 2
a1053 1
	current_tx_desc->lower.data |= htole32(E1000_TXD_CMD_EOP);
d1056 3
a1058 2
	 * Advance the Transmit Descriptor Tail (Tdt), this tells the E1000
	 * that this frame is available to transmit.
d1075 1
d1863 1
a1863 1
	sc->oldest_used_tx_desc = 0;
d1892 1
d1948 2
a1949 2
	/* Setup Transmit Descriptor Settings for this adapter */   
	sc->txd_cmd = E1000_TXD_CMD_IFCS | E1000_TXD_CMD_RS;
d2070 1
d2089 1
a2089 1
	int i, num_avail;
d2091 1
a2091 1
	struct em_tx_desc   *tx_desc;
d2098 5
a2102 1
	i = sc->oldest_used_tx_desc;
d2104 7
a2110 2
	tx_buffer = &sc->tx_buffer_area[i];
	tx_desc = &sc->tx_desc_base[i];
d2114 6
a2119 1
	while (tx_desc->upper.fields.status & E1000_TXD_STAT_DD) {
d2121 12
a2132 10
		tx_desc->upper.data = 0;
		num_avail++;

		if (tx_buffer->m_head != NULL) {
			ifp->if_opackets++;
			if (tx_buffer->map->dm_nsegs > 0) {
				bus_dmamap_sync(sc->txtag, tx_buffer->map,
				    0, tx_buffer->map->dm_mapsize,
				    BUS_DMASYNC_POSTWRITE);
				bus_dmamap_unload(sc->txtag, tx_buffer->map);
d2134 1
a2134 3
			m_freem(tx_buffer->m_head);
			tx_buffer->m_head = NULL;
		}
d2136 2
a2137 2
		if (++i == sc->num_tx_desc)
			i = 0;
d2139 13
a2151 2
		tx_buffer = &sc->tx_buffer_area[i];
		tx_desc = &sc->tx_desc_base[i];
d2157 1
a2157 1
	sc->oldest_used_tx_desc = i;
@


1.154
log
@em_get_buf():
- Use bus_dmamap_load_mbuf() instead of bus_dmamap_load() + mtod().
- Only BUS_DMASYNC_PREREAD is necessary for the bus_dmamap_sync().
em_allocate_receive_structures():
- Clean up error handling for receive buffer allocation and just
have everything done by em_free_receive_structures() now.
em_free_receive_structures():
- A few changes here to allow this function to be called from
em_stop() as well as em_allocate_receive_structures().

Tested on i386/amd64/sparc64.

ok reyk@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.153 2006/11/06 03:52:37 brad Exp $ */
d921 2
a922 1
	int		i, j, error;
d929 1
a929 3
	struct em_q	q;

	struct em_buffer   *tx_buffer = NULL;
d947 2
a948 7
	if (bus_dmamap_create(sc->txtag, MAX_JUMBO_FRAME_SIZE,
	    EM_MAX_SCATTER, MAX_JUMBO_FRAME_SIZE, 0,
	    BUS_DMA_NOWAIT, &q.map)) {
		sc->no_tx_map_avail++;
		return (ENOMEM);
	}
	error = bus_dmamap_load_mbuf(sc->txtag, q.map,
d950 1
a952 1
		bus_dmamap_destroy(sc->txtag, q.map);
d955 1
a955 1
	EM_KASSERT(q.map->dm_nsegs!= 0, ("em_encap: empty packet"));
d957 1
a957 1
	if (q.map->dm_nsegs > sc->num_tx_desc_avail) {
d959 1
a959 2
		bus_dmamap_destroy(sc->txtag, q.map);
		return (ENOBUFS);
d976 1
a976 1
	for (j = 0; j < q.map->dm_nsegs; j++) {
d983 2
a984 2
			array_elements = em_fill_descriptors(q.map->dm_segs[j].ds_addr,
							     q.map->dm_segs[j].ds_len,
d990 1
a990 2
					bus_dmamap_destroy(sc->txtag, q.map);
					return (ENOBUFS);
d1010 1
a1010 1
			current_tx_desc->buffer_addr = htole64(q.map->dm_segs[j].ds_addr);
d1012 1
a1012 1
				sc->txd_cmd | txd_lower | q.map->dm_segs[j].ds_len);
d1026 1
a1026 1
		sc->num_tx_desc_avail -= q.map->dm_nsegs;
d1029 1
a1029 2
	tx_buffer->map = q.map;
	bus_dmamap_sync(sc->txtag, q.map, 0, q.map->dm_mapsize,
d1054 4
d1818 2
a1819 1
	sc->txtag = sc->osdep.em_pa.pa_dmat;
d1821 2
a1822 2
	if (em_allocate_transmit_structures(sc))
		return (ENOMEM);
d1827 15
d1850 2
d1854 4
d1950 8
a1958 2
				bus_dmamap_unload(sc->txtag, tx_buffer->map);
				bus_dmamap_destroy(sc->txtag, tx_buffer->map);
d1960 6
a1966 1
			tx_buffer->m_head = NULL;
d2088 1
a2088 1
		if (tx_buffer->m_head) {
d2090 6
a2095 3
			bus_dmamap_unload(sc->txtag, tx_buffer->map);
			bus_dmamap_destroy(sc->txtag, tx_buffer->map);

@


1.153
log
@Sync up to Intel's latest FreeBSD em driver (6.2.9). Adds support
for a few newer Intel PCIe boards, some code removal and cleaning
and a few bug fixes.

From: Jack Vogel@@Intel

Tested by mk@@ wilfried@@ brad@@ dlg@@, Marc Winiger, Gabriel Kihlman,
Jason Dixon, Johan Mson Lindman, and a few other end users.

Tested with 82543, 82544, 82540, 82545, 82541, 82547, 82546 and 82573.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.152 2006/11/03 06:39:10 brad Exp $ */
d2130 2
a2131 2
	error = bus_dmamap_load(sc->rxtag, sc->rx_sparemap,
	    mtod(m, void *), m->m_len, NULL, BUS_DMA_NOWAIT);
d2146 1
a2146 2
	    rx_buffer->map->dm_mapsize,
	    BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);
d2207 2
a2208 5
		if (error != 0) {
			sc->rx_buffer_area[i].m_head = NULL;
			sc->rx_desc_base[i].buffer_addr = 0;
			return (error);
                }
d2217 1
a2217 3
	sc->rxtag = NULL;
	free(sc->rx_buffer_area, M_DEVBUF);
	sc->rx_buffer_area = NULL;
d2342 12
d2355 3
a2357 2
				bus_dmamap_unload(sc->rxtag, rx_buffer->map);
				bus_dmamap_destroy(sc->rxtag, rx_buffer->map);
a2358 3
			if (rx_buffer->m_head != NULL)
				m_freem(rx_buffer->m_head);
			rx_buffer->m_head = NULL;
@


1.152
log
@the 8257E KCS PCI id is not the MAC but an IPMI interface being provided
from the chipset, so remove it.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.151 2006/10/30 08:34:14 dlg Exp $ */
d48 1
a48 1
char em_driver_version[] = "6.1.4";
d100 1
d117 2
d559 6
d650 2
a651 1
	/* Packet Buffer Allocation (PBA)
d672 4
a675 3
	case em_80003es2lan: /* 80003es2lan: Total Packet Buffer is 48K */
	case em_82571: /* 82571: Total Packet Buffer is 48K */
	case em_82572: /* 82572: Total Packet Buffer is 48K */
a1290 2
#define SPEED_MODE_BIT	(1<<21)		/* On PCI-E MACs only */

d1306 1
d1539 2
a1540 1
		/* speed up time to link by disabling smart power down */
d1552 6
a1557 5
	 *   This allows the receiver to restart by sending XON when it has drained
	 *   a bit.  Here we use an arbitary value of 1500 which will restart after
	 *   one full frame is pulled from the buffer.  There could be several smaller
	 *   frames in the buffer and if so they will not trigger the XON until their
	 *   total number reduces the buffer by 1500.
d1570 1
a1570 1
	sc->hw.fc = em_fc_full;
d1593 1
d1851 1
a1851 2
	u_int32_t	reg_tctl, reg_tarc;
	u_int32_t	reg_tipg = 0;
a1897 18
	/* Do adapter specific tweaks before we enable the transmitter */
	if (sc->hw.mac_type == em_82571 || sc->hw.mac_type == em_82572) {
		reg_tarc = E1000_READ_REG(&sc->hw, TARC0);
		reg_tarc |= (1 << 25);
		E1000_WRITE_REG(&sc->hw, TARC0, reg_tarc);
		reg_tarc = E1000_READ_REG(&sc->hw, TARC1);
		reg_tarc |= (1 << 25);
		reg_tarc &= ~(1 << 28);
		E1000_WRITE_REG(&sc->hw, TARC1, reg_tarc);
	} else if (sc->hw.mac_type == em_80003es2lan) {
		reg_tarc = E1000_READ_REG(&sc->hw, TARC0);
		reg_tarc |= 1;
		E1000_WRITE_REG(&sc->hw, TARC0, reg_tarc);
		reg_tarc = E1000_READ_REG(&sc->hw, TARC1);
		reg_tarc |= 1;
		E1000_WRITE_REG(&sc->hw, TARC1, reg_tarc);
	}

a2285 4
	/* Setup the HW Rx Head and Tail Descriptor Pointers */
	E1000_WRITE_REG(&sc->hw, RDT, sc->num_rx_desc - 1);
	E1000_WRITE_REG(&sc->hw, RDH, 0);

d2322 4
d2698 10
d2902 1
@


1.151
log
@removed unused variable.

ok brad@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.149 2006/09/17 21:35:58 brad Exp $ */
a106 1
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82573E_KCS },
@


1.150
log
@move the checksum stuff under EM_CSUM_OFFLOAD.
@
text
@a2114 1
	struct ifnet   *ifp;
a2115 2

	ifp = &sc->interface_data.ac_if;
@


1.149
log
@Try to reclaim the TX descriptors in the watchdog handler before actually
issuing a watchdog reset of the interface.

From yongari@@FreeBSD
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.148 2006/09/17 20:26:14 brad Exp $ */
d959 7
a965 2
#if 0
	em_transmit_checksum_setup(sc, m_head, &txd_upper, &txd_lower);
a966 1
	txd_upper = txd_lower = 0;
d1597 5
@


1.148
log
@Overhaul RX path to recover from mbuf cluster allocation failure.
- Create a spare DMA map for RX handler to recover from
  bus_dmamap_load() failure.
- Make sure to update status bit in RX descriptors even if we failed
  to allocate a new buffer.
- Don't blindly unload DMA map. Reuse loaded DMA map if received
  packet has errors.

From yongari@@FreeBSD
Tested by myself and a number of end-users on i386/amd64/sparc64
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.147 2006/09/17 17:51:01 brad Exp $ */
d590 8
@


1.147
log
@revert revision 1.131, the code in question was later found to not ensure
the proper alignment requirement for the VLAN layer on strict alignment
architectures. This would result in Jumbo's working fine as long as VLANs
were not in use. If VLANs were in use and a packet comes in with a size
of 2046 bytes or larger, it would be corrupted as it came up through the
VLAN layer. Also check the hw max frame size, instead of the MTU, so the
alignment fixup is done as appropriate.

Fixes PR 5185.
Tested by Rui DeSousa with macppc and myself with alpha/sparc64.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.146 2006/08/22 15:51:18 brad Exp $ */
d162 1
a162 1
int  em_get_buf(int, struct em_softc *, struct mbuf *);
d2093 1
a2093 1
em_get_buf(int i, struct em_softc *sc, struct mbuf *nmp)
d2095 2
a2096 1
	struct mbuf    *mp = nmp;
d2103 10
a2112 17
	if (mp == NULL) {
		MGETHDR(mp, M_DONTWAIT, MT_DATA);
		if (mp == NULL) {
			sc->mbuf_alloc_failed++;
			return (ENOBUFS);
		}
		MCLGET(mp, M_DONTWAIT);
		if ((mp->m_flags & M_EXT) == 0) {
			m_freem(mp);
			sc->mbuf_cluster_failed++;
			return (ENOBUFS);
		}
		mp->m_len = mp->m_pkthdr.len = MCLBYTES;
	} else {
		mp->m_len = mp->m_pkthdr.len = MCLBYTES;
		mp->m_data = mp->m_ext.ext_buf;
		mp->m_next = NULL;
d2114 1
d2117 1
a2117 3
		m_adj(mp, ETHER_ALIGN);

	rx_buffer = &sc->rx_buffer_area[i];
d2123 2
a2124 2
	error = bus_dmamap_load(sc->rxtag, rx_buffer->map,
	    mtod(mp, void *), mp->m_len, NULL, 0);
d2126 1
a2126 1
		m_free(mp);
d2129 9
a2137 2
	rx_buffer->m_head = mp;
	sc->rx_desc_base[i].buffer_addr = htole64(rx_buffer->map->dm_segs[0].ds_addr);
d2142 4
d2177 9
d2200 1
a2200 1
		error = em_get_buf(i, sc, NULL);
d2334 4
d2380 1
d2397 4
a2403 1
		bus_dmamap_unload(sc->rxtag, sc->rx_buffer_area[i].map);
d2408 2
a2409 1
		if (current_desc->status & E1000_RXD_STAT_EOP) {
d2430 1
a2430 2
			if (TBI_ACCEPT(&sc->hw, current_desc->status,
				       current_desc->errors,
d2443 1
a2443 1
			if (em_get_buf(i, sc, NULL) == ENOBUFS) {
d2445 1
a2445 6
				em_get_buf(i, sc, mp);
				if (sc->fmp != NULL)
					m_freem(sc->fmp);
				sc->fmp = NULL;
				sc->lmp = NULL;
				break;
d2531 14
a2544 5
			em_get_buf(i, sc, mp);
			if (sc->fmp != NULL)
				m_freem(sc->fmp);
			sc->fmp = NULL;
			sc->lmp = NULL;
@


1.146
log
@- Re-add the m_adj() back into em_get_buf(), but this time check
the HW max frame size and only call m_adj() if the size is less
than or equal to MCLBYTES - ETHER_ALIGN (2046).
- Set the HW long packet enable bit on all adapters, even 82573
based adapters which are capable of Jumbo's.
- Only do RX alignment fixup on adapters capable of Jumbo frames.

ok jason@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.145 2006/08/14 17:23:32 brad Exp $ */
a153 3
#ifdef __STRICT_ALIGNMENT
void em_fixup_rx(struct em_softc *);
#endif
d2435 49
a2508 4
#ifdef __STRICT_ALIGNMENT
				if (sc->hw.max_frame_size > (MCLBYTES - ETHER_ALIGN))
					em_fixup_rx(sc);
#endif
a2555 43

#ifdef __STRICT_ALIGNMENT
/*
 * When Jumbo frames are enabled we should realign the entire payload on
 * strict alignment architecures. This is a serious design mistake of the
 * 8254x chipset as it nullifies DMA operations. 8254x allows the RX buffer
 * size to be 2048/4096/8192/16384. What we really want is 2048 - ETHER_ALIGN
 * to align its payload. On non strict alignment architectures 8254x still
 * performs unaligned memory access which will reduce the performance too. To
 * avoid copying over an entire frame to align, we allocate a new mbuf and
 * copy the Ethernet header to the new mbuf. The new mbuf is then prepended
 * into the existing mbuf chain.
 *
 * Be aware, best performance of the 8254x chipset is achived only when Jumbo
 * frames are not used at all on strict alignment architectures.
 */
void
em_fixup_rx(struct em_softc *sc)
{
	struct mbuf *m, *n;

	m = sc->fmp;
	if (m->m_len <= (MCLBYTES - ETHER_HDR_LEN)) {
		bcopy(m->m_data, m->m_data + ETHER_HDR_LEN, m->m_len);
		m->m_data += ETHER_HDR_LEN;
	} else {
		MGETHDR(n, M_DONTWAIT, MT_DATA);
		if (n != NULL) {
			bcopy(m->m_data, n->m_data, ETHER_HDR_LEN);
			m->m_data += ETHER_HDR_LEN;
			m->m_len -= ETHER_HDR_LEN;
			n->m_len = ETHER_HDR_LEN;
			M_MOVE_PKTHDR(n, m);
			n->m_next = m;
			sc->fmp = n;
		} else {
			sc->dropped_pkts++;
			m_freem(sc->fmp);
			sc->fmp = NULL;
		}
	}
}
#endif
@


1.146.2.1
log
@MFC:
Fix by brad@@

revert revision 1.131, the code in question was later found to not ensure
the proper alignment requirement for the VLAN layer on strict alignment
architectures. This would result in Jumbo's working fine as long as VLANs
were not in use. If VLANs were in use and a packet comes in with a size
of 2046 bytes or larger, it would be corrupted as it came up through the
VLAN layer. Also check the hw max frame size, instead of the MTU, so the
alignment fixup is done as appropriate.

Fixes PR 5185.
Tested by Rui DeSousa with macppc and myself with alpha/sparc64
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.146 2006/08/22 15:51:18 brad Exp $ */
d154 3
a2437 49
#ifdef __STRICT_ALIGNMENT
			/*
			 * The Ethernet payload is not 32-bit aligned when
			 * Jumbo packets are enabled, so on architectures with
			 * strict alignment we need to shift the entire packet
			 * ETHER_ALIGN bytes. Ugh.
			 */
			if (sc->hw.max_frame_size > (MCLBYTES - ETHER_ALIGN)) {
				unsigned char tmp_align_buf[ETHER_ALIGN];
				int tmp_align_buf_len = 0;

				if (prev_len_adj > sc->align_buf_len)
					prev_len_adj -= sc->align_buf_len;
				else
					prev_len_adj = 0;

				if (mp->m_len > (MCLBYTES - ETHER_ALIGN)) {
					bcopy(mp->m_data +
					    (MCLBYTES - ETHER_ALIGN),
					    &tmp_align_buf,
					    ETHER_ALIGN);
					tmp_align_buf_len = mp->m_len -
					    (MCLBYTES - ETHER_ALIGN);
					mp->m_len -= ETHER_ALIGN;
				} 

				if (mp->m_len) {
					bcopy(mp->m_data,
					    mp->m_data + ETHER_ALIGN,
					    mp->m_len);
					if (!sc->align_buf_len)
						mp->m_data += ETHER_ALIGN;
				}

				if (sc->align_buf_len) {
					mp->m_len += sc->align_buf_len;
					bcopy(&sc->align_buf,
					    mp->m_data,
					    sc->align_buf_len);
				}

				if (tmp_align_buf_len) 
					bcopy(&tmp_align_buf,
					    &sc->align_buf,
					    tmp_align_buf_len);
				sc->align_buf_len = tmp_align_buf_len;
			}
#endif /* __STRICT_ALIGNMENT */

d2463 4
d2514 43
@


1.145
log
@replace a incorrect number with a proper define. this is a no-op change
since E1000_FDX_COLLISION_DISTANCE and E1000_HDX_COLLISION_DISTANCE
use the same values.

From glebius@@FreeBSD
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.144 2006/08/09 17:12:58 brad Exp $ */
d2124 3
d2297 1
a2297 1
	if (sc->hw.mac_type != em_82573)
d2464 2
a2465 1
				em_fixup_rx(sc);
@


1.144
log
@cosmetic tweaks.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.143 2006/08/09 04:44:06 brad Exp $ */
d1896 1
a1896 1
	if (sc->link_duplex == 1)
@


1.143
log
@Sync up to Intel's latest FreeBSD em driver (6.1.4). Adds PCI id for the PCIe
quad port copper adapter, improvements for media support with fiber adapters,
and some fixes for the ICH8 support.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.142 2006/08/09 03:48:25 brad Exp $ */
d1070 1
a1070 1
		if(++hw_tdt == sc->num_tx_desc)
d1635 2
a1636 2
	if(sc->link_active || (sc->hw.phy_type != em_phy_igp) || 
	   !sc->hw.autoneg || !(sc->hw.autoneg_advertised & ADVERTISE_1000_FULL))
d1639 1
a1639 1
	if(sc->smartspeed == 0) {
d1643 2
a1644 1
		if(!(phy_tmp & SR_1000T_MS_CONFIG_FAULT)) return;
d1646 1
a1646 1
		if(phy_tmp & SR_1000T_MS_CONFIG_FAULT) {
d1649 1
a1649 1
			if(phy_tmp & CR_1000T_MS_ENABLE) {
d1654 3
a1656 3
				if(sc->hw.autoneg &&
				   !em_phy_setup_autoneg(&sc->hw) &&
				   !em_read_phy_reg(&sc->hw, PHY_CTRL,
d1666 1
a1666 1
	} else if(sc->smartspeed == EM_SMARTSPEED_DOWNSHIFT) {
d1671 3
a1673 3
		if(sc->hw.autoneg &&
		   !em_phy_setup_autoneg(&sc->hw) &&
		   !em_read_phy_reg(&sc->hw, PHY_CTRL, &phy_tmp)) {
d1680 1
a1680 1
	if(sc->smartspeed++ == EM_SMARTSPEED_MAX)
d1870 1
a1870 1
	if(sc->hw.mac_type >= em_82540)
d2048 1
a2048 1
	while(tx_desc->upper.fields.status & E1000_TXD_STAT_DD) {
d2249 1
a2249 1
	if(sc->hw.mac_type >= em_82540) {
d2725 1
a2725 1
	if(sc->hw.media_type == em_media_type_copper ||
@


1.142
log
@Use the DMA map size from the DMA map instead of the dma_size field with
bus_dma sync's.

ok dlg@@ marco@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.141 2006/08/04 14:25:24 brad Exp $ */
d48 1
a48 1
char em_driver_version[] = "6.0.5";
d99 1
d793 1
d810 5
a814 2
	if (sc->hw.media_type == em_media_type_fiber) {
		ifmr->ifm_active |= IFM_1000_SX | IFM_FDX;
d858 1
d860 1
a860 1
        case IFM_1000_T:
d1572 1
d1595 5
a1599 2
	if (sc->hw.media_type == em_media_type_fiber) {
		ifmedia_add(&sc->media, IFM_ETHER | IFM_1000_SX | IFM_FDX, 
d1601 1
a1601 1
		ifmedia_add(&sc->media, IFM_ETHER | IFM_1000_SX, 
d1858 2
a1859 1
		if (sc->hw.media_type == em_media_type_fiber)
a1883 2
		if (sc->hw.media_type == em_media_type_internal_serdes)
			reg_tarc |= (1 << 20);
@


1.141
log
@- merge em/ixgb_disable_promisc() into em/ixgb_set_promisc().
- rearrange interface flags ioctl handler.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.140 2006/08/04 02:44:50 brad Exp $ */
d1026 2
a1027 1
	    sc->txdma.dma_size, BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);
d2037 1
a2037 1
	    sc->txdma.dma_size, BUS_DMASYNC_POSTREAD);
d2059 2
a2060 1
	    sc->txdma.dma_size, BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);
d2185 2
a2186 1
	    sc->rxdma.dma_size, BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);
d2358 1
a2358 1
	    sc->rxdma.dma_size, BUS_DMASYNC_POSTREAD);
d2469 2
a2470 1
		    sc->rxdma.dma_size, BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);
@


1.140
log
@fix up error messages in em/ixgb_allocate_pci_resources().
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.139 2006/08/01 23:50:14 brad Exp $ */
a160 1
void em_disable_promisc(struct em_softc *);
d521 13
a533 5
			if (!(ifp->if_flags & IFF_RUNNING))
				em_init(sc);

			em_disable_promisc(sc);
			em_set_promisc(sc);
d538 1
a1160 1
	u_int32_t	ctrl;
a1163 1
	ctrl = E1000_READ_REG(&sc->hw, CTRL);
a1166 1
		E1000_WRITE_REG(&sc->hw, RCTL, reg_rctl);
d1170 2
a1171 1
		E1000_WRITE_REG(&sc->hw, RCTL, reg_rctl);
a1172 11
}

void
em_disable_promisc(struct em_softc *sc)
{
	u_int32_t	reg_rctl;

	reg_rctl = E1000_READ_REG(&sc->hw, RCTL);

	reg_rctl &=  (~E1000_RCTL_UPE);
	reg_rctl &=  (~E1000_RCTL_MPE);
a1174 1

@


1.139
log
@(em/ixgb)_(clean_transmit_interrupts/process_receive_interrupts) ->
(em/ixgb)_(txeof/rxeof)
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.138 2006/07/10 00:16:18 drahn Exp $ */
d1384 1
a1384 1
		printf(": mmba isn't memory");
d1390 1
a1390 1
		printf(": can't find mem space\n");
d1411 1
a1411 1
			printf(": can't find io space\n");
d1422 1
a1422 1
			printf(": flash isn't memory");
d1429 1
a1429 1
			printf(": can't find mem space\n");
@


1.138
log
@Fully initialize the softc structure before enabling interrupt. ok brad@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.137 2006/07/08 04:34:34 brad Exp $ */
d149 1
a149 1
void em_clean_transmit_interrupts(struct em_softc *);
d152 1
a152 1
void em_process_receive_interrupts(struct em_softc *, int);
d748 2
a749 2
			em_process_receive_interrupts(sc, -1);
			em_clean_transmit_interrupts(sc);
d909 1
a909 1
		em_clean_transmit_interrupts(sc);
d2025 1
a2025 1
em_clean_transmit_interrupts(struct em_softc *sc)
d2345 1
a2345 1
em_process_receive_interrupts(struct em_softc *sc, int count)
@


1.137
log
@don't add 1000Mbps media types for a 10/100 only PHY.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.136 2006/07/07 02:56:18 brad Exp $ */
d1439 2
a1451 2
		
	sc->hw.back = &sc->osdep;
@


1.136
log
@Sync up to Intel's latest FreeBSD em driver (6.0.5). Adds support
for new chipset revisions embedded in the ESB2 and ICH8 core logic
chipsets.

The previous attempt at commiting this included an unrelated change
to how the I/O base address was being set and this was the cause of
the breakage.

From: Intel's web-site
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.135 2006/07/05 01:15:30 brad Exp $ */
d1606 5
a1610 3
		ifmedia_add(&sc->media, IFM_ETHER | IFM_1000_T | IFM_FDX, 
			    0, NULL);
		ifmedia_add(&sc->media, IFM_ETHER | IFM_1000_T, 0, NULL);
@


1.135
log
@revert back to the older driver as this causes some breakage.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.133 2006/06/28 02:46:54 brad Exp $ */
d48 1
a48 1
char em_driver_version[] = "5.1.5";
d56 2
d111 6
a116 1
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82573V_PM }
d192 2
d302 4
d316 1
a316 1
		EM_MAX_TXD_82544 * sizeof(struct em_tx_desc));
d319 1
a319 1
		EM_MAX_TXD * sizeof(struct em_tx_desc));
d618 1
a618 1
		    sc->num_tx_desc = EM_MAX_TXD_82544;
d620 1
a620 1
		    sc->num_tx_desc = EM_MAX_TXD;
d631 6
d658 3
d1271 2
d1283 9
d1407 1
d1409 2
a1410 4
				   &sc->osdep.em_iobtag,
				   &sc->osdep.em_iobhandle,
				   &sc->osdep.em_iobase,
				   &sc->osdep.em_iosize, 0)) {
d1418 16
d1462 1
a1462 1
	if(sc->sc_intrhand)
d1466 7
a1472 2
	if(sc->osdep.em_iobase)
		bus_space_unmap(sc->osdep.em_iobtag, sc->osdep.em_iobhandle,
d1476 1
a1476 1
	if(sc->osdep.em_membase)
d1515 11
d1817 1
a1817 1
	u_int32_t	reg_tctl, tarc;
a1823 2
	E1000_WRITE_REG(&sc->hw, TDBAL, (u_int32_t)bus_addr);
	E1000_WRITE_REG(&sc->hw, TDBAH, (u_int32_t)(bus_addr >> 32));
d1827 2
d1831 1
a1832 1
	E1000_WRITE_REG(&sc->hw, TDT, 0);
d1864 20
d1893 1
a1895 22
	if (sc->hw.mac_type == em_82571 || sc->hw.mac_type == em_82572) {
		tarc = E1000_READ_REG(&sc->hw, TARC0);
		tarc |= ((1 << 25) | (1 << 21));
		E1000_WRITE_REG(&sc->hw, TARC0, tarc);
		tarc = E1000_READ_REG(&sc->hw, TARC1);
		tarc |= (1 << 25);
		if (reg_tctl & E1000_TCTL_MULR)
			tarc &= ~(1 << 28);
		else
			tarc |= (1 << 28);
		E1000_WRITE_REG(&sc->hw, TARC1, tarc);
	} else if (sc->hw.mac_type == em_80003es2lan) {
		tarc = E1000_READ_REG(&sc->hw, TARC0);
		tarc |= 1;
		if (sc->hw.media_type == em_media_type_internal_serdes)
			tarc |= (1 << 20);
		E1000_WRITE_REG(&sc->hw, TARC0, tarc);
		tarc = E1000_READ_REG(&sc->hw, TARC1);
		tarc |= 1;
		E1000_WRITE_REG(&sc->hw, TARC1, tarc);
	}

a2251 2
	E1000_WRITE_REG(&sc->hw, RDBAL, (u_int32_t)bus_addr);
	E1000_WRITE_REG(&sc->hw, RDBAH, (u_int32_t)(bus_addr >> 32));
d2254 2
d2258 1
a2259 1
	E1000_WRITE_REG(&sc->hw, RDT, sc->num_rx_desc - 1);
d2801 1
a2801 1
	    sc->stats.rlec + sc->stats.rnbc +
d2835 4
a2838 2
	printf("%s: Receive length errors = %lld\n", unit,
		(long long)sc->stats.rlec);
@


1.134
log
@Sync up to Intel's latest FreeBSD em driver (6.0.5). Adds support
for new chipset revisions embedded in the ESB2 and ICH8 core logic
chipsets.

From: Intel's web-site
@
text
@d48 1
a48 1
char em_driver_version[] = "6.0.5";
a55 2
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_80003ES2LAN_CPR_SPT },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_80003ES2LAN_SDS_SPT },
d109 1
a109 6
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82573V_PM },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_ICH8_IGP_M_AMT },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_ICH8_IGP_AMT },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_ICH8_IGP_C },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_ICH8_IFE },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_ICH8_IGP_M }
a184 2
static int em_smart_pwr_down = FALSE;

a292 4
		case em_ich8lan:
			/* ICH8 does not support jumbo frames */
			sc->hw.max_frame_size = ETHER_MAX_LEN;
			break;
d303 1
a303 1
		EM_MAX_TXD * sizeof(struct em_tx_desc));
d306 1
a306 1
		EM_MAX_TXD_82543 * sizeof(struct em_tx_desc));
d605 2
a607 2
		else
		    sc->num_tx_desc = EM_MAX_TXD_82543;
a617 6
	 *
	 * Devices before the 82547 had a Packet Buffer of 64K.
	 *   Default allocation: PBA=48K for Rx, leaving 16K for Tx.
	 * After the 82547 the buffer was reduced to 40K.
	 *   Default allocation: PBA=30K for Rx, leaving 10K for Tx.
	 *   Note: default does not leave enough room for Jumbo Frame >10k.
a638 3
	case em_ich8lan:
		pba = E1000_PBA_8K;
		break;
a1248 2
#define SPEED_MODE_BIT	(1<<21)		/* On PCI-E MACs only */

a1258 9
			/* Check if we may set SPEED_MODE bit on PCI-E */
			if ((sc->link_speed == SPEED_1000) &&
			    ((sc->hw.mac_type == em_82571) ||
			    (sc->hw.mac_type == em_82572))) {
				int tarc0;
				tarc0 = E1000_READ_REG(&sc->hw, TARC0);
				tarc0 |= SPEED_MODE_BIT;
				E1000_WRITE_REG(&sc->hw, TARC0, tarc0);
			}
a1373 1

d1375 4
a1378 2
		    &sc->osdep.io_bus_space_tag, &sc->osdep.io_bus_space_handle,
		    &sc->osdep.em_iobase, &sc->osdep.em_iosize, 0)) {
d1383 1
a1383 1
		sc->hw.io_base = sc->osdep.em_iobase;
a1385 16
	/* for ICH8 we need to find the flash memory */
	if (sc->hw.mac_type == em_ich8lan) {
		val = pci_conf_read(pa->pa_pc, pa->pa_tag, EM_FLASH);
		if (PCI_MAPREG_TYPE(val) != PCI_MAPREG_TYPE_MEM) {
			printf(": flash isn't memory");
			return (ENXIO);
		}

		if (pci_mapreg_map(pa, EM_FLASH, PCI_MAPREG_MEM_TYPE(val), 0,
		    &sc->osdep.flash_bus_space_tag, &sc->osdep.flash_bus_space_handle,
		    &sc->osdep.em_flashbase, &sc->osdep.em_flashsize, 0)) {
			printf(": can't find mem space\n");
			return (ENXIO);
		}
        }

d1414 1
a1414 1
	if (sc->sc_intrhand)
d1418 2
a1419 7
	if (sc->osdep.em_flashbase)
		bus_space_unmap(sc->osdep.flash_bus_space_tag, sc->osdep.flash_bus_space_handle,
				sc->osdep.em_flashsize);
	sc->osdep.em_flashbase = 0;

	if (sc->osdep.em_iobase)
		bus_space_unmap(sc->osdep.io_bus_space_tag, sc->osdep.io_bus_space_handle,
d1423 1
a1423 1
	if (sc->osdep.em_membase)
a1461 11
	/* Set up smart power down as default off on newer adapters */
	if (!em_smart_pwr_down &&
	     (sc->hw.mac_type == em_82571 ||
	      sc->hw.mac_type == em_82572)) {
		uint16_t phy_tmp = 0;
		/* speed up time to link by disabling smart power down */
		em_read_phy_reg(&sc->hw, IGP02E1000_PHY_POWER_MGMT, &phy_tmp);
		phy_tmp &= ~IGP02E1000_PM_SPD;
		em_write_phy_reg(&sc->hw, IGP02E1000_PHY_POWER_MGMT, phy_tmp);
	}

d1753 1
a1753 1
	u_int32_t	reg_tctl, reg_tarc;
d1760 2
a1764 2
	E1000_WRITE_REG(&sc->hw, TDBAH, (u_int32_t)(bus_addr >> 32));
	E1000_WRITE_REG(&sc->hw, TDBAL, (u_int32_t)bus_addr);
d1767 1
a1768 1
	E1000_WRITE_REG(&sc->hw, TDH, 0);
a1799 20
	/* Do adapter specific tweaks before we enable the transmitter */
	if (sc->hw.mac_type == em_82571 || sc->hw.mac_type == em_82572) {
		reg_tarc = E1000_READ_REG(&sc->hw, TARC0);
		reg_tarc |= (1 << 25);
		E1000_WRITE_REG(&sc->hw, TARC0, reg_tarc);
		reg_tarc = E1000_READ_REG(&sc->hw, TARC1);
		reg_tarc |= (1 << 25);
		reg_tarc &= ~(1 << 28);
		E1000_WRITE_REG(&sc->hw, TARC1, reg_tarc);
	} else if (sc->hw.mac_type == em_80003es2lan) {
		reg_tarc = E1000_READ_REG(&sc->hw, TARC0);
		reg_tarc |= 1;
		if (sc->hw.media_type == em_media_type_internal_serdes)
			reg_tarc |= (1 << 20);
		E1000_WRITE_REG(&sc->hw, TARC0, reg_tarc);
		reg_tarc = E1000_READ_REG(&sc->hw, TARC1);
		reg_tarc |= 1;
		E1000_WRITE_REG(&sc->hw, TARC1, reg_tarc);
	}

a1808 1
	/* This write will effectively turn on the transmit unit */
d1811 22
d2189 2
a2192 2
	E1000_WRITE_REG(&sc->hw, RDBAH, (u_int32_t)(bus_addr >> 32));
	E1000_WRITE_REG(&sc->hw, RDBAL, (u_int32_t)bus_addr);
d2195 1
a2196 1
	E1000_WRITE_REG(&sc->hw, RDH, 0);
d2738 1
a2738 1
	    sc->stats.ruc + sc->stats.roc +
d2772 2
a2773 4
	/* RLEC is inaccurate on some hardware, calculate our own */
	printf("%s: Receive Length Errors = %lld\n", unit,
		((long long)sc->stats.roc +
		(long long)sc->stats.ruc));
@


1.133
log
@remove some whitespace.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.132 2006/06/24 00:49:36 brad Exp $ */
d48 1
a48 1
char em_driver_version[] = "5.1.5";
d56 2
d111 6
a116 1
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82573V_PM }
d192 2
d302 4
d316 1
a316 1
		EM_MAX_TXD_82544 * sizeof(struct em_tx_desc));
d319 1
a319 1
		EM_MAX_TXD * sizeof(struct em_tx_desc));
d618 1
a618 1
		    sc->num_tx_desc = EM_MAX_TXD_82544;
d620 1
a620 1
		    sc->num_tx_desc = EM_MAX_TXD;
d631 6
d658 3
d1271 2
d1283 9
d1407 1
d1409 2
a1410 4
				   &sc->osdep.em_iobtag,
				   &sc->osdep.em_iobhandle,
				   &sc->osdep.em_iobase,
				   &sc->osdep.em_iosize, 0)) {
d1415 1
a1415 1
		sc->hw.io_base = 0;
d1418 16
d1462 1
a1462 1
	if(sc->sc_intrhand)
d1466 7
a1472 2
	if(sc->osdep.em_iobase)
		bus_space_unmap(sc->osdep.em_iobtag, sc->osdep.em_iobhandle,
d1476 1
a1476 1
	if(sc->osdep.em_membase)
d1515 11
d1817 1
a1817 1
	u_int32_t	reg_tctl, tarc;
a1823 2
	E1000_WRITE_REG(&sc->hw, TDBAL, (u_int32_t)bus_addr);
	E1000_WRITE_REG(&sc->hw, TDBAH, (u_int32_t)(bus_addr >> 32));
d1827 2
d1831 1
a1832 1
	E1000_WRITE_REG(&sc->hw, TDT, 0);
d1864 20
d1893 1
a1895 22
	if (sc->hw.mac_type == em_82571 || sc->hw.mac_type == em_82572) {
		tarc = E1000_READ_REG(&sc->hw, TARC0);
		tarc |= ((1 << 25) | (1 << 21));
		E1000_WRITE_REG(&sc->hw, TARC0, tarc);
		tarc = E1000_READ_REG(&sc->hw, TARC1);
		tarc |= (1 << 25);
		if (reg_tctl & E1000_TCTL_MULR)
			tarc &= ~(1 << 28);
		else
			tarc |= (1 << 28);
		E1000_WRITE_REG(&sc->hw, TARC1, tarc);
	} else if (sc->hw.mac_type == em_80003es2lan) {
		tarc = E1000_READ_REG(&sc->hw, TARC0);
		tarc |= 1;
		if (sc->hw.media_type == em_media_type_internal_serdes)
			tarc |= (1 << 20);
		E1000_WRITE_REG(&sc->hw, TARC0, tarc);
		tarc = E1000_READ_REG(&sc->hw, TARC1);
		tarc |= 1;
		E1000_WRITE_REG(&sc->hw, TARC1, tarc);
	}

a2251 2
	E1000_WRITE_REG(&sc->hw, RDBAL, (u_int32_t)bus_addr);
	E1000_WRITE_REG(&sc->hw, RDBAH, (u_int32_t)(bus_addr >> 32));
d2254 2
d2258 1
a2259 1
	E1000_WRITE_REG(&sc->hw, RDT, sc->num_rx_desc - 1);
d2801 1
a2801 1
	    sc->stats.rlec + sc->stats.rnbc +
d2835 4
a2838 2
	printf("%s: Receive length errors = %lld\n", unit,
		(long long)sc->stats.rlec);
@


1.132
log
@make em_fixup_rx() a void function.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.131 2006/05/31 02:09:18 brad Exp $ */
a2436 2


@


1.131
log
@fix Jumbo frames on strict alignment architectures by allocating a new mbuf and
copying the Ethernet header to the new mbuf. The new mbuf is then prepended
into the existing mbuf chain.

From FreeBSD

ok reyk@@ pascoe@@ jason@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.130 2006/05/28 23:38:49 brad Exp $ */
d147 1
a147 1
int  em_fixup_rx(struct em_softc *);
d2455 1
a2455 1
int
a2458 1
	int error = 0;
a2477 1
			error = ENOMEM;
a2479 2

	return (error);
@


1.130
log
@- force the maximum receivable frame size down to 1518 bytes for
strict alignment architectures for the time being.
- remove the m_adj() on non-strict alignment architectures as this
seems to resolve the Jumbo crashing issue.

tested by a few developers. ok reyk@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.129 2006/05/28 10:40:27 brad Exp $ */
d146 3
a270 3
#ifdef __STRICT_ALIGNMENT
	sc->hw.max_frame_size = ETHER_MAX_LEN;
#else
a296 1
#endif
a2052 5
#ifdef __STRICT_ALIGNMENT
	if (ifp->if_mtu <= ETHERMTU)
		m_adj(mp, ETHER_ALIGN);
#endif

a2221 1
#ifndef __STRICT_ALIGNMENT
a2223 1
#endif
a2362 49
#ifdef __STRICT_ALIGNMENT
			/*
			 * The Ethernet payload is not 32-bit aligned when
			 * Jumbo packets are enabled, so on architectures with
			 * strict alignment we need to shift the entire packet
			 * ETHER_ALIGN bytes. Ugh.
			 */
			if (ifp->if_mtu > ETHERMTU) {
				unsigned char tmp_align_buf[ETHER_ALIGN];
				int tmp_align_buf_len = 0;

				if (prev_len_adj > sc->align_buf_len)
					prev_len_adj -= sc->align_buf_len;
				else
					prev_len_adj = 0;

				if (mp->m_len > MCLBYTES - ETHER_ALIGN) {
					bcopy(mp->m_data +
					    (MCLBYTES - ETHER_ALIGN),
					    &tmp_align_buf,
					    ETHER_ALIGN);
					tmp_align_buf_len = mp->m_len -
					    (MCLBYTES - ETHER_ALIGN);
					mp->m_len -= ETHER_ALIGN;
				} 

				if (mp->m_len) {
					bcopy(mp->m_data,
					    mp->m_data + ETHER_ALIGN,
					    mp->m_len);
					if (!sc->align_buf_len)
						mp->m_data += ETHER_ALIGN;
				}

				if (sc->align_buf_len) {
					mp->m_len += sc->align_buf_len;
					bcopy(&sc->align_buf,
					    mp->m_data,
					    sc->align_buf_len);
				}

				if (tmp_align_buf_len) 
					bcopy(&tmp_align_buf,
					    &sc->align_buf,
					    tmp_align_buf_len);
				sc->align_buf_len = tmp_align_buf_len;
			}
#endif /* __STRICT_ALIGNMENT */

d2388 3
d2437 49
@


1.129
log
@always set if_hardmtu.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.128 2006/05/28 00:38:44 brad Exp $ */
d268 3
d297 1
d2054 1
d2057 1
d2228 1
d2231 1
@


1.128
log
@use if_hardmtu for MTU ioctl handler.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.127 2006/05/28 00:04:24 jason Exp $ */
d1513 2
a1514 4
	if (sc->hw.mac_type != em_82573) {
		ifp->if_hardmtu =
			sc->hw.max_frame_size - ETHER_HDR_LEN - ETHER_CRC_LEN;
	}
@


1.127
log
@unknown ioctl is ENOTTY not EINVAL
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.126 2006/05/27 10:03:15 brad Exp $ */
d498 1
a498 2
		if (ifr->ifr_mtu < ETHERMIN || ifr->ifr_mtu >
		    sc->hw.max_frame_size - ETHER_HDR_LEN - ETHER_CRC_LEN)
@


1.126
log
@remove IFCAP_JUMBO_MTU interface capabilities flag and set if_hardmtu in a few
more drivers.

ok reyk@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.125 2006/05/26 20:50:41 deraadt Exp $ */
d542 1
a542 1
		error = EINVAL;
@


1.125
log
@rename jumbo mtu to if_hardmtu; ok brad reyk
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.124 2006/05/25 18:27:34 brad Exp $ */
a1516 1
		ifp->if_capabilities |= IFCAP_JUMBO_MTU;
d1521 1
a1521 1
	ifp->if_capabilities |= IFCAP_VLAN_MTU;
@


1.124
log
@formatting
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.123 2006/05/25 14:31:37 jason Exp $ */
d1515 1
a1515 1
		ifp->if_jumbo_mtu =
@


1.123
log
@formatting; ok brad
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.122 2006/05/20 05:12:23 reyk Exp $ */
d249 11
a259 11
        /*
         * This controls when hardware reports transmit completion
         * status.   
         */
        sc->hw.report_tx_early = 1;

        if (em_allocate_pci_resources(sc)) {
                printf("%s: Allocation of PCI resources failed\n",
                       sc->sc_dv.dv_xname);
                goto err_pci;
        }
@


1.122
log
@fix pci resource allocation in em, don't crash!

fix by brad@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.121 2006/05/20 03:47:56 brad Exp $ */
d620 8
a627 8
	    if (sc->hw.max_frame_size > EM_RXBUFFER_8192)
		    pba = E1000_PBA_22K; /* 22K for Rx, 18K for Tx */
	    else
		    pba = E1000_PBA_30K; /* 30K for Rx, 10K for Tx */
	    sc->tx_fifo_head = 0;
	    sc->tx_head_addr = pba << EM_TX_HEAD_ADDR_SHIFT;
	    sc->tx_fifo_size = (E1000_PBA_40K - pba) << EM_PBA_BYTES_SHIFT;
	    break;
d631 2
a632 2
	    pba = E1000_PBA_32K; /* 32K for Rx, 16K for Tx */
	    break;
d634 3
a636 3
	    /* Jumbo frames not supported */
	    pba = E1000_PBA_12K; /* 12K for Rx, 20K for Tx */
	    break;
d638 5
a642 5
	    /* Devices before 82547 had a Packet Buffer of 64K.   */
	    if (sc->hw.max_frame_size > EM_RXBUFFER_8192)
		pba = E1000_PBA_40K; /* 40K for Rx, 24K for Tx */
	    else
		pba = E1000_PBA_48K; /* 48K for Rx, 16K for Tx */
d1276 1
a1276 1
 *  This routine disables all traffic on the sc by issuing a
d1923 1
a1923 1
	ETHER_HDR_LEN + offsetof(struct ip, ip_sum);
d1928 1
a1928 1
	ETHER_HDR_LEN + sizeof(struct ip);
d1933 2
a1934 2
		ETHER_HDR_LEN + sizeof(struct ip) + 
		offsetof(struct tcphdr, th_sum);
d1937 2
a1938 2
		ETHER_HDR_LEN + sizeof(struct ip) + 
		offsetof(struct udphdr, uh_sum);
d2204 2
a2205 2
		   E1000_RCTL_RDMTS_HALF |
		   (sc->hw.mc_filter_type << E1000_RCTL_MO_SHIFT);
d2544 1
a2544 2
	    E1000_WRITE_REG(&sc->hw, IMC,
	        (0xffffffff & ~E1000_IMC_RXSEQ));
d2546 1
a2546 2
	    E1000_WRITE_REG(&sc->hw, IMC,
	        0xffffffff);
d2662 1
a2662 1
 		sc->stats.sec += E1000_READ_REG(&sc->hw, SEC);
d2741 7
a2747 7
	sc->dropped_pkts +
	sc->stats.rxerrc +
	sc->stats.crcerrs +
	sc->stats.algnerrc +
	sc->stats.rlec + sc->stats.rnbc +
	sc->stats.mpc + sc->stats.cexterr +
	sc->rx_overruns;
@


1.121
log
@set if_jumbo_mtu and the IFCAP_JUMBO_MTU capabilities flag where
appropriate.

ok reyk@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.120 2006/05/20 02:58:00 brad Exp $ */
d249 12
a296 12

	/*
	 * This controls when hardware reports transmit completion
	 * status.
	 */
	sc->hw.report_tx_early = 1;

	if (em_allocate_pci_resources(sc)) {
		printf("%s: Allocation of PCI resources failed\n",
		       sc->sc_dv.dv_xname);
		goto err_pci;
	}
@


1.120
log
@simplify MTU ioctl switch case.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.119 2006/05/07 07:06:23 brad Exp $ */
d1514 5
d1522 1
a1522 1
	ifp->if_capabilities = IFCAP_VLAN_MTU;
@


1.119
log
@fix a typo and some KNF.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.118 2006/05/07 06:42:43 brad Exp $ */
d248 4
d257 16
a277 4
		case em_82573:
			/* 82573 does not support Jumbo frames */
			sc->hw.max_frame_size = ETHER_MAX_LEN;
			break;
a297 3
	/* Initialize eeprom parameters */
	em_init_eeprom_params(&sc->hw);

d471 1
a471 2
	int		max_frame_size, error = 0;
	uint16_t	eeprom_data = 0;
a497 21
		switch (sc->hw.mac_type) {
			case em_82573:
				/*
				 * 82573 only supports Jumbo frames
				 * if ASPM is disabled.
				 */
				em_read_eeprom(&sc->hw, EEPROM_INIT_3GIO_3,
				    1, &eeprom_data);
				if (eeprom_data & EEPROM_WORD1A_ASPM_MASK) {
					max_frame_size = ETHER_MAX_LEN;
					break;
				}
				/* Allow Jumbo frames - FALLTHROUGH */
			case em_82571:
			case em_82572:
			case em_80003es2lan:	/* Limit Jumbo Frame size */
				max_frame_size = 9234;
				break;
			default:
				max_frame_size = MAX_JUMBO_FRAME_SIZE;
		}
d499 1
a499 1
		    max_frame_size - ETHER_HDR_LEN - ETHER_CRC_LEN)
a1508 1

@


1.118
log
@- Remove unreachable bus_dmamap_unload() in em_dma_malloc().
- Set the dma_tag to NULL upon failure in em_dma_malloc().
- In em_dma_free(), return if dma_tag is NULL.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.117 2006/05/01 16:38:19 brad Exp $ */
a580 1
	ifp->if_flags &= ~IFF_RUNNING;
d1009 1
a1009 1
		if (sc->hw.mac_type == em_82547) {
a1010 1
		}
d1130 1
a1130 1
	} else {
a1131 1
	}
d1247 1
a1247 1
	if (em_display_debug_stats && ifp->if_flags & IFF_RUNNING) {
a1248 1
	}
d1369 1
a1369 1
		/* Figure our where our IO BAR is ? */
a1893 1

a1900 1

d2059 1
a2059 1
	if (ifp->if_mtu <= ETHERMTU) {
a2060 1
	}
a2214 1

d2330 1
a2330 2
			}
			else {
a2331 1
			}
d2518 1
a2518 1
		} else {
a2519 1
		}
d2524 1
a2524 1
		if (!(rx_desc->errors & E1000_RXD_ERR_TCPE)) {
a2526 1
		}
@


1.117
log
@replace magic value of 32 with EM_MAX_SCATTER.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.116 2006/04/28 18:22:29 brad Exp $ */
a1671 2
/* fail_4: */
	bus_dmamap_unload(dma->dma_tag, dma->dma_map);
d1680 2
a1681 1
	/* dma->dma_tag = NULL; */
d1688 13
a1700 4
	bus_dmamap_unload(dma->dma_tag, dma->dma_map);
	bus_dmamem_unmap(dma->dma_tag, dma->dma_vaddr, dma->dma_size);
	bus_dmamem_free(dma->dma_tag, &dma->dma_seg, dma->dma_nseg);
	bus_dmamap_destroy(dma->dma_tag, dma->dma_map);
@


1.116
log
@when setting the interface address, only call em_init() if the interface
is not already running.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.115 2006/04/18 19:06:02 brad Exp $ */
d905 3
a907 2
	if (bus_dmamap_create(sc->txtag, MAX_JUMBO_FRAME_SIZE, 32,
	    MAX_JUMBO_FRAME_SIZE, 0, BUS_DMA_NOWAIT, &q.map)) {
@


1.115
log
@add a few more Intel Gig PCI ids.

Some of these are from jason@@ and the rest are from the Linux PCI ids page.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.114 2006/04/16 03:54:30 brad Exp $ */
d477 2
a478 2
		em_init(sc);
		switch (ifa->ifa_addr->sa_family) {
d480 1
a480 1
		case AF_INET:
a481 1
			break;
a482 3
		default:
			break;
		}
@


1.114
log
@remove splnet usage from em_intr().
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.113 2006/04/12 07:11:28 dlg Exp $ */
d89 1
d93 2
d104 6
a109 1
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82573L }
@


1.113
log
@when the interrupt handler has run out of work to do it shouldnt return 0
from the work loop. instead it should break from it so the spl can be
lowered and any work that has been done can be counted. this fixes
interrupt counting at least, and possibly issues related to leaving splnet
raised..

ok deraadt@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.112 2006/03/28 05:33:03 brad Exp $ */
d716 1
a716 3
	int s, claimed = 0;

	s = splnet();
a750 1
	splx(s);
@


1.112
log
@Sync up to Intel's latest FreeBSD em driver (5.1.5). Adds support
for the 82563 PCI Express chipset and a few fixes.

From: Intel's web-site
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.111 2006/03/27 18:01:53 brad Exp $ */
d727 1
a727 1
			return (0);
@


1.111
log
@sync in some of the new PCI ids.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.110 2006/03/25 22:41:44 djm Exp $ */
d48 1
a48 1
char em_driver_version[] = "3.2.18";
d54 2
d247 2
a248 1
			sc->hw.max_frame_size = 10500;
d338 5
d451 1
d483 12
d497 2
a498 5
				max_frame_size = 10500;
				break;
			case em_82573:
				/* 82573 does not support Jumbo frames */
				max_frame_size = ETHER_MAX_LEN;
d634 1
d715 1
a715 1
	u_int32_t	reg_icr;
d723 5
a727 6
		reg_icr = E1000_READ_REG(&sc->hw, ICR);
		if (sc->hw.mac_type >= em_82571 &&
		    (reg_icr & E1000_ICR_INT_ASSERTED) == 0)
			break;
		else if (reg_icr == 0)
			break;
d1489 4
a1492 1
	sc->hw.fc_pause_time = 0x1000;
d1753 1
a1753 1
	u_int32_t	reg_tctl;
d1782 4
d1805 1
a1805 1
	if (sc->link_duplex == 1) {
d1807 1
a1807 1
	} else {
d1809 22
a1831 1
	E1000_WRITE_REG(&sc->hw, TCTL, reg_tctl);
@


1.110
log
@allow bpf(4) to ignore packets based on their direction (inbound or
outbound), using a new BIOCSDIRFILT ioctl;
guidance, feedback and ok canacar@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.109 2006/02/24 06:09:44 brad Exp $ */
d80 1
a80 1
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82546EB_QUAD_COPPER },
d84 2
a85 1
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82546GB_QUAD_COPPER },
d96 1
d99 1
a99 1
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82573L },
@


1.109
log
@update link status here.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.108 2006/02/22 06:02:09 brad Exp $ */
d420 1
a420 1
			bpf_mtap(ifp->if_bpf, m_head);
d2428 1
a2428 1
				bpf_mtap(ifp->if_bpf, m);
@


1.109.2.1
log
@MFC:
Fix by brad@@

rev 1.131
fix Jumbo frames on strict alignment architectures by allocating a new mbuf and
copying the Ethernet header to the new mbuf. The new mbuf is then prepended
into the existing mbuf chain.

rev 1.130
remove the m_adj().

ok reyk@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.109 2006/02/24 06:09:44 brad Exp $ */
a133 3
#ifdef __STRICT_ALIGNMENT
void em_fixup_rx(struct em_softc *);
#endif
d2007 4
d2324 49
a2397 3
#ifdef __STRICT_ALIGNMENT
				em_fixup_rx(sc);
#endif
a2443 43

#ifdef __STRICT_ALIGNMENT
/*
 * When Jumbo frames are enabled we should realign the entire payload on
 * strict alignment architecures. This is a serious design mistake of the
 * 8254x chipset as it nullifies DMA operations. 8254x allows the RX buffer
 * size to be 2048/4096/8192/16384. What we really want is 2048 - ETHER_ALIGN
 * to align its payload. On non strict alignment architectures 8254x still
 * performs unaligned memory access which will reduce the performance too. To
 * avoid copying over an entire frame to align, we allocate a new mbuf and
 * copy the Ethernet header to the new mbuf. The new mbuf is then prepended
 * into the existing mbuf chain.
 *
 * Be aware, best performance of the 8254x chipset is achived only when Jumbo
 * frames are not used at all on strict alignment architectures.
 */
void
em_fixup_rx(struct em_softc *sc)
{
	struct mbuf *m, *n;

	m = sc->fmp;
	if (m->m_len <= (MCLBYTES - ETHER_HDR_LEN)) {
		bcopy(m->m_data, m->m_data + ETHER_HDR_LEN, m->m_len);
		m->m_data += ETHER_HDR_LEN;
	} else {
		MGETHDR(n, M_DONTWAIT, MT_DATA);
		if (n != NULL) {
			bcopy(m->m_data, n->m_data, ETHER_HDR_LEN);
			m->m_data += ETHER_HDR_LEN;
			m->m_len -= ETHER_HDR_LEN;
			n->m_len = ETHER_HDR_LEN;
			M_MOVE_PKTHDR(n, m);
			n->m_next = m;
			sc->fmp = n;
		} else {
			sc->dropped_pkts++;
			m_freem(sc->fmp);
			sc->fmp = NULL;
		}
	}
}
#endif
@


1.109.2.2
log
@MFC:
Fix by brad@@

revert revision 1.131, the code in question was later found to not ensure
the proper alignment requirement for the VLAN layer on strict alignment
architectures. This would result in Jumbo's working fine as long as VLANs
were not in use. If VLANs were in use and a packet comes in with a size
of 2046 bytes or larger, it would be corrupted as it came up through the
VLAN layer. Also check the hw max frame size, instead of the MTU, so the
alignment fixup is done as appropriate.

Fixes PR 5185.
Tested by Rui DeSousa with macppc and myself with alpha/sparc64.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.109.2.1 2006/06/30 08:37:16 brad Exp $ */
d134 3
a2009 3
	if (sc->hw.max_frame_size <= (MCLBYTES - ETHER_ALIGN))
		m_adj(mp, ETHER_ALIGN);

a2322 49
#ifdef __STRICT_ALIGNMENT
			/*
			 * The Ethernet payload is not 32-bit aligned when
			 * Jumbo packets are enabled, so on architectures with
			 * strict alignment we need to shift the entire packet
			 * ETHER_ALIGN bytes. Ugh.
			 */
			if (sc->hw.max_frame_size > (MCLBYTES - ETHER_ALIGN)) {
				unsigned char tmp_align_buf[ETHER_ALIGN];
				int tmp_align_buf_len = 0;

				if (prev_len_adj > sc->align_buf_len)
					prev_len_adj -= sc->align_buf_len;
				else
					prev_len_adj = 0;

				if (mp->m_len > (MCLBYTES - ETHER_ALIGN)) {
					bcopy(mp->m_data +
					    (MCLBYTES - ETHER_ALIGN),
					    &tmp_align_buf,
					    ETHER_ALIGN);
					tmp_align_buf_len = mp->m_len -
					    (MCLBYTES - ETHER_ALIGN);
					mp->m_len -= ETHER_ALIGN;
				} 

				if (mp->m_len) {
					bcopy(mp->m_data,
					    mp->m_data + ETHER_ALIGN,
					    mp->m_len);
					if (!sc->align_buf_len)
						mp->m_data += ETHER_ALIGN;
				}

				if (sc->align_buf_len) {
					mp->m_len += sc->align_buf_len;
					bcopy(&sc->align_buf,
					    mp->m_data,
					    sc->align_buf_len);
				}

				if (tmp_align_buf_len) 
					bcopy(&tmp_align_buf,
					    &sc->align_buf,
					    tmp_align_buf_len);
				sc->align_buf_len = tmp_align_buf_len;
			}
#endif /* __STRICT_ALIGNMENT */

d2348 3
d2397 43
@


1.108
log
@For 82544 and newer chips increase the number of TX descriptors to 512.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.107 2006/02/17 04:01:05 brad Exp $ */
d643 1
@


1.107
log
@If there is no link then set IFM_NONE so ifconfig will show a media
status of (none) whether in auto or forced speed/duplex mode.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.106 2006/02/17 03:57:29 brad Exp $ */
d272 6
a277 2
	tsize = EM_ROUNDUP(sc->num_tx_desc * sizeof(struct em_tx_desc),
	    EM_MAX_TXD * sizeof(struct em_tx_desc));
d588 4
a591 1
		sc->num_tx_desc = EM_MAX_TXD;
@


1.106
log
@- simplify link state handling code.
- update interface baud rate properly so userland programs such as a
SNMP daemon or bgpctl/ospfctl for example will display the correct
interface speed instead of always saying 1 Gbps.

From FreeBSD
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.105 2006/02/15 14:53:56 brad Exp $ */
d750 2
a751 1
	if (!sc->link_active)
d753 1
@


1.105
log
@be gone whitespace.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.104 2006/02/10 09:12:25 brad Exp $ */
d325 1
a325 1
	em_check_for_link(&sc->hw);
d745 1
a745 14
	if (E1000_READ_REG(&sc->hw, STATUS) & E1000_STATUS_LU) {
		if (sc->link_active == 0) {
			em_get_speed_and_duplex(&sc->hw, 
						&sc->link_speed, 
						&sc->link_duplex);
			sc->link_active = 1;
		}
	} else {
		if (sc->link_active == 1) {
			sc->link_speed = 0;
			sc->link_duplex = 0;
			sc->link_active = 0;
		}
	}
d1232 1
d1240 1
d1246 1
a1246 1
			sc->link_speed = 0;
a1469 13
	if (E1000_READ_REG(&sc->hw, STATUS) & E1000_STATUS_LU)
		sc->link_active = 1;
	else
		sc->link_active = 0;

	if (sc->link_active) {
		em_get_speed_and_duplex(&sc->hw, 
					&sc->link_speed, 
					&sc->link_duplex);
	} else {
		sc->link_speed = 0;
		sc->link_duplex = 0;
	}
a1487 1
	ifp->if_baudrate = 1000000000;
@


1.104
log
@fix a typo in em_clean_transmit_interrupts() that will cause the
watchdog timer to fire if the TX descriptor ring is emptied for
EM_TX_TIMEOUT seconds.

The same bug exists in ixgb(4) too.

From FreeSBD
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.103 2006/02/10 08:58:06 brad Exp $ */
d1245 7
a1251 7
        if (E1000_READ_REG(&sc->hw, STATUS) & E1000_STATUS_LU) {
                if (sc->link_active == 0) {
                        em_get_speed_and_duplex(&sc->hw,
                                                &sc->link_speed,
                                                &sc->link_duplex);
                        sc->link_active = 1;
                        sc->smartspeed = 0;
d1254 6
a1259 6
                }
        } else {
                if (sc->link_active == 1) {
                        sc->link_speed = 0;
                        sc->link_duplex = 0;
                        sc->link_active = 0;
d1262 2
a1263 2
                }
        }
@


1.103
log
@remove unnecessary link state check in the watchdog handler.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.102 2006/01/28 20:56:15 brad Exp $ */
d1982 1
a1982 1
		else if (num_avail == sc->num_tx_desc_avail)
@


1.102
log
@a little cleaning.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.101 2006/01/14 00:37:11 brad Exp $ */
a549 2

	em_check_for_link(&sc->hw);
@


1.101
log
@Only update the RX ring consumer pointer after running through the RX loop,
not with each iteration through the loop.

From FreeBSD
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.100 2005/12/10 18:41:50 brad Exp $ */
d159 1
a159 1
 *  OpenBSD Device Interface Entry Points		     
d176 1
a176 1
 *  return 0 on success, positive on failure
d192 3
a194 4
 *  This routine identifies the type of hardware, allocates all resources 
 *  and initializes the hardware.     
 *  
 *  return 0 on success, positive on failure
d238 1
a238 1
	 * sized frames
d264 1
a264 1
		printf("%s: Allocation of PCI resources failed\n", 
d290 1
a290 1
		printf("%s: Unable to allocate rx_desc memory\n", 
d566 1
a566 1
 *  by the driver as a hw/sw initialization routine to get to a 
d1689 2
a1690 2
 *  Allocate memory for tx_buffer structures. The tx_buffer stores all 
 *  the information needed to transmit a packet on the wire. 
d2274 1
a2274 1
	if (!((current_desc->status) & E1000_RXD_STAT_DD)) {
a2275 1
	}
d2278 2
a2279 2
		    (count != 0) &&
		    (ifp->if_flags & IFF_RUNNING)) {
a2313 1

d2321 3
a2323 3
				if (len > 0) len--;
			}
			else {
a2324 1
			}
a2327 1

d2428 1
a2428 1
		/* Zero out the receive descriptors status  */
d2433 1
a2433 1
		/* Advance our pointers to the next descriptor */
d2457 2
a2458 1
	if (--i < 0) i = sc->num_rx_desc - 1;
@


1.100
log
@add a shutdown function and register it with shutdownhook_establish().
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.99 2005/12/10 04:01:36 brad Exp $ */
a2437 3
		/* Advance the E1000's Receive Queue #0	 "Tail Pointer". */
		E1000_WRITE_REG(&sc->hw, RDT, i);

d2460 4
@


1.99
log
@remove a bit of unused code.

Pointed out by Andrey Matveev <evol at online dot ptt dot ru> through noticing
a missing splx which pointed out the fact that code is unused to me.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.98 2005/12/04 01:11:57 brad Exp $ */
d105 1
d339 1
d363 14
@


1.98
log
@On the 82571 and newer chipset the ICR register is meaningful only
if the E1000_ICR_INT_ASSERTED bit is set.

From FreeBSD
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.97 2005/11/28 17:53:14 wilfried Exp $ */
a427 3

	if (sc->in_detach)
		return (error);
@


1.97
log
@back out last change, caused me panics on jumbo packets, ok deraadt@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.96 2005/11/27 06:37:13 brad Exp $ */
d685 4
a688 1
		if (reg_icr == 0)
@


1.96
log
@Since reception of Jumbo frames is enabled by default; ensure proper
alignment with m_adj() in em_get_buf() whether the MTU is bumped higher
or not.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.95 2005/11/26 19:05:24 brad Exp $ */
d2009 3
a2011 1
	m_adj(mp, ETHER_ALIGN);
@


1.95
log
@set Ethernet flow control parameters in em_hardware_init()
after the PBA size has been set.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.94 2005/11/19 22:17:15 brad Exp $ */
d2009 1
a2009 3
	if (ifp->if_mtu <= ETHERMTU) {
		m_adj(mp, ETHER_ALIGN);
	}
@


1.94
log
@a whole lot of spaces to tabs, KNF and some other cleaning.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.93 2005/11/18 18:13:29 brad Exp $ */
a227 10
	/*
	 * These parameters control the automatic generation(Tx) and
	 * response(Rx) to Ethernet PAUSE frames.
	 */
	sc->hw.fc_high_water = FC_DEFAULT_HI_THRESH;
	sc->hw.fc_low_water = FC_DEFAULT_LO_THRESH;
	sc->hw.fc_pause_time = FC_DEFAULT_TX_TIMER;
	sc->hw.fc_send_xon = TRUE;
	sc->hw.fc = em_fc_full;

d1417 2
d1438 22
@


1.93
log
@PCIX -> PCI-X in a few comments
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.92 2005/11/18 05:32:06 brad Exp $ */
d133 4
a136 7
void em_receive_checksum(struct em_softc *, 
				     struct em_rx_desc *,
				     struct mbuf *);
void em_transmit_checksum_setup(struct em_softc *,
					    struct mbuf *,
					    u_int32_t *,
					    u_int32_t *);
d142 1
a142 2
int  em_get_buf(int, struct em_softc *,
			    struct mbuf *);
d150 2
a151 2
int  em_dma_malloc(struct em_softc *, bus_size_t,
    struct em_dma_alloc *, int);
d154 2
a155 3
u_int32_t em_fill_descriptors (bus_addr_t address,
                                      u_int32_t length,
                                      PDESC_ARRAY desc_array);
d233 1
a233 1
	sc->hw.fc_low_water  = FC_DEFAULT_LO_THRESH;
d235 1
a235 1
	sc->hw.fc_send_xon   = TRUE;
d239 1
a239 1
        sc->hw.phy_reset_disable = FALSE;
d242 1
a242 1
        sc->hw.master_slave = em_ms_hw_default;
d244 1
a244 1
        sc->hw.master_slave = EM_MASTER_SLAVE;
a336 6
	/* Print the link status */
        if (sc->link_active == 1) {
                em_get_speed_and_duplex(&sc->hw, &sc->link_speed,
                                        &sc->link_duplex);
	}

d339 7
a345 9
        /* Identify 82544 on PCI-X */
        em_get_bus_info(&sc->hw);
        if(sc->hw.bus_type == em_bus_type_pcix &&
           sc->hw.mac_type == em_82544) {
                sc->pcix_82544 = TRUE;
        }
        else {
                sc->pcix_82544 = FALSE;
        }
a415 1

d478 1
a478 1
		    max_frame_size - ETHER_HDR_LEN - ETHER_CRC_LEN) {
d480 1
a480 1
		} else if (ifp->if_mtu != ifr->ifr_mtu) {
a481 1
		}
d486 1
a486 1
			if (!(ifp->if_flags & IFF_RUNNING)) {
a487 1
                        }
d492 1
a492 1
			if (ifp->if_flags & IFF_RUNNING) {
a493 1
			}
a553 1

d625 3
a627 3
        /* Get the latest mac address, User can use a LAA */
        bcopy(sc->interface_data.ac_enaddr, sc->hw.mac_addr,
              ETHER_ADDR_LEN);
d687 1
a687 1
	int s, claimed = 0, wantinit = 0;
d714 1
a714 1
		if (reg_icr & E1000_ICR_RXO) {
a715 2
			wantinit = 1;
		}
a716 4
#if 0
	if (wantinit)
		em_init(sc);
#endif
d803 1
a803 1
		return(EINVAL);
d821 1
a821 1
			sc->hw.forced_speed_duplex	= em_100_half;
d829 1
a829 1
			sc->hw.forced_speed_duplex	= em_10_half;
d835 5
a839 4
        /* As the speed/duplex settings may have changed we need to
         * reset the PHY.
         */
        sc->hw.phy_reset_disable = FALSE;
d843 1
a843 1
	return(0);
d859 4
a862 4
        /* For 82544 Workaround */
        DESC_ARRAY              desc_array;
        u_int32_t               array_elements;
        u_int32_t               counter;
d910 4
a913 4
        if (sc->pcix_82544) {
                txd_saved = i;
                txd_used = 0;
        }
d915 38
a952 38
                /* If sc is 82544 and on PCI-X bus */
                if (sc->pcix_82544) {
                        /*
                         * Check the Address and Length combination and
                         * split the data accordingly
                         */
                        array_elements = em_fill_descriptors(q.map->dm_segs[j].ds_addr,
                                                             q.map->dm_segs[j].ds_len,
                                                             &desc_array);
                        for (counter = 0; counter < array_elements; counter++) {
                                if (txd_used == sc->num_tx_desc_avail) {
                                          sc->next_avail_tx_desc = txd_saved;
                                          sc->no_tx_desc_avail2++;
                                          bus_dmamap_destroy(sc->txtag, q.map);
                                          return (ENOBUFS);
                                }
                                tx_buffer = &sc->tx_buffer_area[i];
                                current_tx_desc = &sc->tx_desc_base[i];
                                current_tx_desc->buffer_addr = htole64(
                                        desc_array.descriptor[counter].address);
                                current_tx_desc->lower.data = htole32(
                                        (sc->txd_cmd | txd_lower |
                                         (u_int16_t)desc_array.descriptor[counter].length));
                                current_tx_desc->upper.data = htole32((txd_upper));
                                if (++i == sc->num_tx_desc)
                                         i = 0;

                                tx_buffer->m_head = NULL;
                                txd_used++;
                        }
                } else {
		        tx_buffer = &sc->tx_buffer_area[i];
		        current_tx_desc = &sc->tx_desc_base[i];

		        current_tx_desc->buffer_addr = htole64(q.map->dm_segs[j].ds_addr);
		        current_tx_desc->lower.data = htole32(
		            sc->txd_cmd | txd_lower | q.map->dm_segs[j].ds_len);
		        current_tx_desc->upper.data = htole32(txd_upper);
d954 1
a954 1
		        if (++i == sc->num_tx_desc)
d956 3
a958 3
		
		        tx_buffer->m_head = NULL;
                }
d962 4
a965 6
        if (sc->pcix_82544) {
                sc->num_tx_desc_avail -= txd_used;
        }
        else {
                sc->num_tx_desc_avail -= q.map->dm_nsegs;
        }
d1023 1
a1023 1
		if(eop) {
d1039 1
a1039 1
        struct em_softc *sc = arg;
d1058 4
a1061 6
			if (em_82547_tx_fifo_reset(sc)) {
				return(0);
			}
			else {
				return(1);
			}
d1065 1
a1065 1
	return(0);
d1075 1
a1075 1
	if (sc->tx_fifo_head >= sc->tx_fifo_size) {
a1076 1
	}
d1084 7
a1090 7
	if ( (E1000_READ_REG(&sc->hw, TDT) ==
	      E1000_READ_REG(&sc->hw, TDH)) &&
	     (E1000_READ_REG(&sc->hw, TDFT) ==
	      E1000_READ_REG(&sc->hw, TDFH)) &&
	     (E1000_READ_REG(&sc->hw, TDFTS) ==
	      E1000_READ_REG(&sc->hw, TDFHS)) &&
	     (E1000_READ_REG(&sc->hw, TDFPC) == 0)) {
d1109 3
a1111 4
		return(TRUE);
	}
	else {
		return(FALSE);
a1117 1

d1170 1
a1170 1
		if (sc->hw.pci_cmd_word & CMD_MEM_WRT_INVALIDATE) {
a1171 1
		}
d1202 1
a1202 1
		if (sc->hw.pci_cmd_word & CMD_MEM_WRT_INVALIDATE) {
a1203 1
		}
a1312 1

d1392 1
a1392 1
	return(0);
d1438 1
a1438 1
		return(EIO);
d1444 1
a1444 1
		return(EIO);
d1450 1
a1450 1
		return(EIO);
d1468 1
a1468 1
	return(0);
d1590 1
a1590 1
	struct em_dma_alloc *dma, int mapflags)
d1820 2
a1821 4
em_transmit_checksum_setup(struct em_softc *sc,
			   struct mbuf *mp,
			   u_int32_t *txd_upper,
			   u_int32_t *txd_lower) 
d1967 1
a1967 2
em_get_buf(int i, struct em_softc *sc,
    struct mbuf *nmp)
d1980 1
a1980 1
			return(ENOBUFS);
d1986 1
a1986 1
			return(ENOBUFS);
d2009 1
a2009 1
		return(error);
d2017 1
a2017 1
	return(0);
d2443 2
a2444 3
em_receive_checksum(struct em_softc *sc,
		    struct em_rx_desc *rx_desc,
		    struct mbuf *mp)
d2505 1
a2505 1
	if ((addr[0] & 1) || (!bcmp(addr, zero_addr, ETHER_ADDR_LEN))) {
a2506 1
	}
d2508 1
a2508 1
	return(TRUE);
d2512 1
a2512 3
em_write_pci_cfg(struct em_hw *hw,
		      uint32_t reg,
		      uint16_t *value)
d2521 1
a2521 2
em_read_pci_cfg(struct em_hw *hw, uint32_t reg,
		     uint16_t *value)
d2567 2
a2568 3
em_fill_descriptors (bus_addr_t address,
                              u_int32_t length,
                              PDESC_ARRAY desc_array)
@


1.92
log
@Use bus_addr_t for address in em_fill_descriptors().
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.91 2005/11/18 05:22:06 brad Exp $ */
d350 1
a350 1
        /* Identify 82544 on PCIX */
d938 1
a938 1
                /* If sc is 82544 and on PCIX bus */
@


1.91
log
@fix wrong htole usage in the 82544 PCI-X workaround codepath in em_encap().

From FreeBSD
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.90 2005/11/18 03:58:14 brad Exp $ */
d158 1
a158 1
u_int32_t em_fill_descriptors (u_int64_t address,
d2608 1
a2608 1
em_fill_descriptors (u_int64_t address,
@


1.90
log
@revert part of rev 1.45 ..

- Modify the caller of em_encap() to detect a NULL m_head and not try
  to queue the mbuf if that happens.

which was in preparation for a software-based workaround for a HW VLAN
tagging issue, but due to a HW limitation with tagging, we cannot use
HW VLAN tagging at all.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.89 2005/11/15 01:40:43 brad Exp $ */
a880 1
	u_int64_t       address;
d939 1
a939 3
                if(sc->pcix_82544) {
                        array_elements = 0;
                        address = htole64(q.map->dm_segs[j].ds_addr);
d944 2
a945 2
                        array_elements = em_fill_descriptors(address,
                                                             htole32(q.map->dm_segs[j].ds_len),
@


1.89
log
@remove braces and fix indenting here so its easier to read.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.88 2005/11/14 16:04:15 brad Exp $ */
d147 1
a147 1
int  em_encap(struct em_softc *, struct mbuf **);
d414 1
a414 7
		/*
		 * em_encap() can modify our pointer, and or make it NULL on
		 * failure.  In that event, we can't requeue.
		 */
		if (em_encap(sc, &m_head)) {
			if (m_head == NULL)
				break;
d876 1
a876 1
em_encap(struct em_softc *sc, struct mbuf **m_headp)
a882 2
	struct mbuf	*m_head;

a891 2

	m_head = *m_headp;
@


1.88
log
@re-add comment which is still valid for em_print_hw_stats().
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.87 2005/11/14 16:00:08 brad Exp $ */
d530 1
a530 1
				if (sc->hw.mac_type == em_82542_rev2_0) {
d532 1
a532 2
				}
					em_enable_intr(sc);
@


1.87
log
@remove unused em_print_debug_info() function.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.86 2005/11/14 14:07:32 brad Exp $ */
d2761 7
@


1.86
log
@remove unused HW VLAN tagging support which cannot be used due to HW limitations.

ok dlg@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.85 2005/11/13 03:48:07 brad Exp $ */
a156 1
void em_print_debug_info(struct em_softc *);
a2758 47
}

/**********************************************************************
 *
 *  This routine is called only when em_display_debug_stats is enabled.
 *  This routine provides a way to take a look at important statistics
 *  maintained by the driver and hardware.
 *
 **********************************************************************/
void
em_print_debug_info(struct em_softc *sc)
{
	const char * const unit = sc->sc_dv.dv_xname;
	uint8_t *hw_addr = sc->hw.hw_addr;

	printf("%s: Adapter hardware address = %p \n", unit, hw_addr);
	printf("%s: CTRL = 0x%x RCTL = 0x%x \n", unit,
		E1000_READ_REG(&sc->hw, CTRL),
		E1000_READ_REG(&sc->hw, CTRL));
	printf("%s: Packet buffer = Tx=%dk Rx=%dk \n", unit,
		((E1000_READ_REG(&sc->hw, PBA) & 0xffff0000) >> 16),\
		(E1000_READ_REG(&sc->hw, PBA) & 0xffff) );
	printf("%s: tx_int_delay = %d, tx_abs_int_delay = %d\n", unit,
		E1000_READ_REG(&sc->hw, TIDV),
		E1000_READ_REG(&sc->hw, TADV));
	printf("%s: rx_int_delay = %d, rx_abs_int_delay = %d\n", unit,
		E1000_READ_REG(&sc->hw, RDTR),
		E1000_READ_REG(&sc->hw, RADV));

	printf("%s: fifo workaround = %lld, fifo_reset_count = %lld\n", unit,
		(long long)sc->tx_fifo_wrk_cnt,
		(long long)sc->tx_fifo_reset_cnt);
	printf("%s: hw tdh = %d, hw tdt = %d\n", unit,
		E1000_READ_REG(&sc->hw, TDH),
		E1000_READ_REG(&sc->hw, TDT));
	printf("%s: Num Tx descriptors avail = %d\n", unit,
	       sc->num_tx_desc_avail);
	printf("%s: Tx Descriptors not avail1 = %ld\n", unit,
	       sc->no_tx_desc_avail1);
	printf("%s: Tx Descriptors not avail2 = %ld\n", unit,
	       sc->no_tx_desc_avail2);
	printf("%s: Std mbuf failed = %ld\n", unit,
		sc->mbuf_alloc_failed);
	printf("%s: Std mbuf cluster failed = %ld\n", unit,
		sc->mbuf_cluster_failed);
	printf("%s: Driver dropped packets = %ld\n", unit,
	       sc->dropped_pkts);
@


1.85
log
@- Introduce two more stat counters, counting number of RX
  overruns and number of watchdog timeouts.
- Do not increase if->if_oerrors in em_watchdog(), since
  this leads to counter slipping back, when if->if_oerrors
  is recalculated in em_update_stats_counters(). Instead
  increase watchdog counter in em_watchdog() and take it
  into account in em_update_stats_counters().

From glebius FreeBSD

ok dlg@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.84 2005/11/08 01:33:19 brad Exp $ */
d897 1
a897 3
#if NVLAN > 0
	struct ifvlan *ifv = NULL;
#endif
a944 7
#if NVLAN > 0
	/* Find out if we are in vlan mode */
	if ((m_head->m_flags & (M_PROTO1|M_PKTHDR)) == (M_PROTO1|M_PKTHDR) &&
	    m_head->m_pkthdr.rcvif != NULL)
		ifv = m_head->m_pkthdr.rcvif->if_softc;
#endif

a1005 10

#if NVLAN > 0
	if (ifv != NULL) {
		/* Set the vlan id */
		current_tx_desc->upper.fields.special = htole16(ifv->ifv_tag);

		/* Tell hardware to add tag */
		current_tx_desc->lower.data |= htole32(E1000_TXD_CMD_VLE);
	}
#endif
@


1.84
log
@Sync up to Intel's latest FreeBSD em driver (3.2.18). A few fixes
for the new PCI Express chips.

From: Intel's web-site
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.83 2005/11/04 17:45:03 brad Exp $ */
d582 1
a582 1
	ifp->if_oerrors++;
d741 1
a741 1
			ifp->if_ierrors++;
d2773 2
a2774 1
	sc->stats.mpc + sc->stats.cexterr;
d2777 2
a2778 1
	ifp->if_oerrors = sc->stats.ecol + sc->stats.latecol;
d2836 1
a2836 1
	       (long long)sc->stats.symerrs);
d2838 1
a2838 1
	       (long long)sc->stats.sec);
d2840 1
a2840 1
	       (long long)sc->stats.dc);
d2843 1
a2843 1
	       (long long)sc->stats.mpc);
d2845 1
a2845 1
	       (long long)sc->stats.rnbc);
d2847 1
a2847 1
	       (long long)sc->stats.rlec);
d2849 1
a2849 1
	       (long long)sc->stats.rxerrc);
d2851 1
a2851 1
	       (long long)sc->stats.crcerrs);
d2853 1
a2853 1
	       (long long)sc->stats.algnerrc);
d2855 5
a2859 1
	       (long long)sc->stats.cexterr);
d2862 1
a2862 1
	       (long long)sc->stats.xonrxc);
d2864 1
a2864 1
	       (long long)sc->stats.xontxc);
d2866 1
a2866 1
	       (long long)sc->stats.xoffrxc);
d2868 1
a2868 1
	       (long long)sc->stats.xofftxc);
d2871 1
a2871 1
	       (long long)sc->stats.gprc);
d2873 1
a2873 1
	       (long long)sc->stats.gptc);
@


1.83
log
@don't bother setting error in em_attach() since it's
not being used anyway.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.82 2005/10/26 21:58:19 brad Exp $ */
d48 1
a48 1
char em_driver_version[] = "3.2.15";
@


1.82
log
@add missing bus_dmamap_sync()'s, much closer to working on hppa
though it still falls over with NFS builds.

From: FreeBSD

ok deraadt@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.81 2005/10/24 21:42:34 brad Exp $ */
a208 1
	int		error = 0;
a281 1
		error = ENXIO;
a295 1
		error = ENOMEM;
a307 1
		error = ENOMEM;
a315 1
		error = EIO;
a322 1
		error = EIO;
a327 1
		error = EIO;
@


1.81
log
@Revamp interrupt handling in em(4) driver:

o Do not mask the RX overrun interrupt.

o Rewrite em_intr():
  - Axe EM_MAX_INTR.
  - Cycle acknowledging interrupts and processing
    packets until zero interrupt cause register is
    read.
  - If RX overrun comes in log this fact.

From glebius FreeBSD

ok krw@@ beck@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.80 2005/10/21 02:10:34 brad Exp $ */
d1047 2
d1994 2
a2002 3
			bus_dmamap_sync(sc->txtag, tx_buffer->map,
			    0, tx_buffer->map->dm_mapsize,
			    BUS_DMASYNC_POSTWRITE);
d2016 2
d2083 1
a2083 2
	    mtod(mp, void *), mp->m_len, NULL,
	    0);
d2091 2
a2092 1
	    rx_buffer->map->dm_mapsize, BUS_DMASYNC_PREREAD);
d2146 2
d2319 2
d2482 2
@


1.80
log
@Remove unused global adapter linked list.

From FreeBSD
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.79 2005/10/21 02:03:16 brad Exp $ */
d717 2
a718 1
	u_int32_t	loop_cnt = EM_MAX_INTR;
d720 1
a720 3
	struct ifnet	*ifp;
	struct em_softc  *sc = arg;
	int s;
d726 4
a729 5
	reg_icr = E1000_READ_REG(&sc->hw, ICR);
	if (!reg_icr) {
		splx(s);
		return (0);
	}
d731 1
a731 8
	/* Link status change */
	if (reg_icr & (E1000_ICR_RXSEQ | E1000_ICR_LSC)) {
		timeout_del(&sc->timer_handle);
		sc->hw.get_link_status = 1;
		em_check_for_link(&sc->hw);
		em_update_link_status(sc);
		timeout_add(&sc->timer_handle, hz); 
	}
a732 1
	while (loop_cnt > 0) {
d737 14
a750 1
		loop_cnt--;
d752 4
d757 2
a758 1
	if (ifp->if_flags & IFF_RUNNING && IFQ_IS_EMPTY(&ifp->if_snd) == 0)
d762 1
a762 1
	return (1);
@


1.79
log
@In em_process_receive_interrupts() cycle check IFF_RUNNING flag.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.78 2005/10/16 17:32:37 brad Exp $ */
a44 6
 *  Linked list of board private structures for all NICs found
 *********************************************************************/

struct em_softc *em_adapter_list = NULL;

/*********************************************************************
a214 5

	if (em_adapter_list != NULL)
		em_adapter_list->prev = sc;
	sc->next = em_adapter_list;
	em_adapter_list = sc;
@


1.78
log
@While in em_process_receive_interrupts() processing the packet em_init()
may be called (either from em_watchdog() from softclock interrupt or
from ifconfig). em_init() resets the card, in particular it sets
sc->next_rx_desc_to_check to 0 and resets hardware RX Head and Tail
descriptor pointers. The loop in em_process_receive_interrupts()
does not expect these things to change, and a mess may result.

>From glebius FreeBSD

ok krw@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.77 2005/10/15 14:43:36 brad Exp $ */
d2322 3
a2324 1
	while ((current_desc->status & E1000_RXD_STAT_DD) && (count != 0)) {
@


1.77
log
@- put spl's right in the code and remove the macros
- remove splassert()'s
- remove empty bus_dma_tag_destroy macro from code and header
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.76 2005/10/15 07:33:25 brad Exp $ */
d2323 1
a2458 9

#if NBPFILTER > 0
				/*
				 * Handle BPF listeners. Let the BPF
				 * user see the packet.
				 */
				if (ifp->if_bpf)
					bpf_mtap(ifp->if_bpf, sc->fmp);
#endif
d2461 1
a2461 1
				ether_input_mbuf(ifp, sc->fmp);
d2481 1
a2481 1
		if (++i == sc->num_rx_desc) {
d2483 17
a2499 3
			current_desc = sc->rx_desc_base;
		} else
			current_desc++;
@


1.76
log
@sort PCI ids
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.75 2005/10/10 18:27:21 brad Exp $ */
a420 2
	mtx_assert(&sc->mtx, MA_OWNED);

d474 1
a474 1
	EM_LOCK_STATE();
d476 1
a476 1
	EM_LOCK(sc);
d482 1
a482 1
		EM_UNLOCK(sc);
d567 1
a567 1
	EM_UNLOCK(sc);
d619 1
a619 1
	EM_LOCK_STATE();
d621 1
a621 1
	EM_LOCK(sc);
a624 2
        mtx_assert(&sc->mtx, MA_OWNED);

d677 1
a677 1
		EM_UNLOCK(sc);
d686 1
a686 1
		EM_UNLOCK(sc);
d699 1
a699 1
		EM_UNLOCK(sc);
d717 1
a717 1
	EM_UNLOCK(sc);
d732 1
a732 1
	EM_LOCK_STATE();
d734 1
a734 1
	EM_LOCK(sc);
d740 1
a740 1
		EM_UNLOCK(sc);
d764 1
a764 1
	EM_UNLOCK(sc);
a1079 2
	EM_LOCK_ASSERT(sc);

d1107 1
a1107 1
	EM_LOCK_STATE();
d1109 1
a1109 1
	EM_LOCK(sc);
d1111 1
a1111 1
	EM_UNLOCK(sc);
d1293 1
a1293 1
	EM_LOCK_STATE();
d1297 1
a1297 1
	EM_LOCK(sc);
d1309 1
a1309 1
	EM_UNLOCK(sc);
a1350 2
	mtx_assert(&sc->mtx, MA_OWNED);

a1717 1
	bus_dma_tag_destroy(dma->dma_tag);
a1730 1
	bus_dma_tag_destroy(dma->dma_tag);
d1883 1
a1883 2
	if (sc->txtag != NULL) {
		bus_dma_tag_destroy(sc->txtag);
a1884 1
	}
a1985 2
	mtx_assert(&sc->mtx, MA_OWNED);

d2117 1
a2117 1
		return(ENOMEM);
d2134 1
a2134 1
			goto fail_1;
d2143 1
a2143 1
			return(error);
d2147 1
a2147 1
        return(0);
d2149 1
a2149 3
fail_1:
	bus_dma_tag_destroy(sc->rxtag);
/* fail_0: */
d2287 1
a2287 2
	if (sc->rxtag != NULL) {
		bus_dma_tag_destroy(sc->rxtag);
a2288 1
	}
a2312 2

	mtx_assert(&sc->mtx, MA_OWNED);
@


1.75
log
@- use correct size when setting hw.max_frame_size for non PCI-E cards
- ethernet -> Ethernet
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.74 2005/10/09 19:36:35 brad Exp $ */
a94 3
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82573E },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82573E_IAMT },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82573L },
d101 3
@


1.74
log
@remove colon after "address" when printing the MAC address.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.73 2005/10/08 01:49:20 brad Exp $ */
d265 1
a265 1
	 * Set the max frame size assuming standard ethernet
d279 1
a279 1
			    MAX_JUMBO_FRAME_SIZE + ETHER_CRC_LEN;
d2408 1
a2408 1
			 * The ethernet payload is not 32-bit aligned when
@


1.73
log
@fix spl usage in em_init().
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.72 2005/10/08 00:59:13 brad Exp $ */
d367 1
a367 1
	printf(", address: %s\n", ether_sprintf(sc->interface_data.ac_enaddr));
@


1.72
log
@- return from em_start() if not IFF_RUNNING.
- remove unnecessary em_start_locked()/em_init_locked().
- remove unnecessary spl usage in em_start().
- fix spl usage in em_ioctl().

ok krw@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.71 2005/10/07 23:24:42 brad Exp $ */
d681 2
a682 1
		goto fail;
d689 3
a691 2
		em_stop(sc); 
		goto fail;
d703 2
a704 1
		goto fail;
d708 2
a709 2
        /* Don't lose promiscuous settings */
        em_set_promisc(sc);
d718 2
a719 3
        /* Don't reset the phy next time init gets called */
        sc->hw.phy_reset_disable = TRUE;
	return;
a720 1
fail:
@


1.71
log
@Sync up to Intel's latest FreeBSD em driver which adds
support for the 82571 and 82572 PCI Express chips.

From: Intel's web-site

ok krw@@ pedro@@ deraadt@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.70 2005/10/02 16:44:32 brad Exp $ */
a113 1
void em_start_locked(struct ifnet *);
a116 1
void em_init_locked(struct em_softc *);
d416 1
a416 1
em_start_locked(struct ifnet *ifp)
d423 3
a459 11
void
em_start(struct ifnet *ifp)
{
	struct em_softc *sc = ifp->if_softc;
	EM_LOCK_STATE();

	EM_LOCK(sc);
	em_start_locked(ifp);
	EM_UNLOCK(sc);
}

d474 1
a477 1
	struct ifaddr  *ifa = (struct ifaddr *)data;
a478 2
	error = ether_ioctl(ifp, &sc->interface_data, command, data);
	EM_UNLOCK(sc);
d480 5
a484 1
	if (error > 0)
d486 1
a486 1
        if (sc->in_detach) return(error);
a526 1
		EM_LOCK(sc);
d529 1
a529 1
				em_init_locked(sc);
a538 1
		EM_UNLOCK(sc);
a548 1
                                EM_LOCK(sc);
a554 1
                                EM_UNLOCK(sc);
d569 2
a570 1
	return(error);
a612 1
 *  return 0 on success, positive on failure
d616 1
a616 1
em_init_locked(struct em_softc *sc)
d618 1
d620 2
d623 1
a623 1
	uint32_t	pba;
d681 1
a681 1
		return;
d689 1
a689 1
		return;
d701 1
a701 1
		return;
d717 1
a717 7
}

void
em_init(void *arg)
{
	struct em_softc *sc = arg;
	EM_LOCK_STATE();
d719 1
a719 2
	EM_LOCK(sc);
	em_init_locked(sc);
d765 1
a765 1
		em_start_locked(ifp);
@


1.70
log
@spaces vs tab
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.69 2005/10/01 21:26:06 brad Exp $ */
d54 1
a54 1
char em_driver_version[] = "2.1.7";
d97 7
d270 12
a281 6
	if (sc->hw.mac_type == em_82573) {
		sc->hw.max_frame_size = 
		    ETHER_MAX_LEN;
	} else {
		sc->hw.max_frame_size = 
		    MAX_JUMBO_FRAME_SIZE + ETHER_CRC_LEN;
d482 1
a482 1
	int		error = 0;
d514 14
a527 4
		if (ifr->ifr_mtu < ETHERMIN ||
		    ifr->ifr_mtu > MAX_JUMBO_FRAME_SIZE - ETHER_HDR_LEN || \
			/* 82573 does not support Jumbo frames */
			(sc->hw.mac_type == em_82573 && ifr->ifr_mtu > ETHERMTU)) {
a651 6
	 *
	 * Devices before the 82547 had a Packet Buffer of 64K.
	 *   Default allocation: PBA=48K for Rx, leaving 16K for Tx.
	 * After the 82547 the buffer was reduced to 40K.
	 *   Default allocation: PBA=30K for Rx, leaving 10K for Tx.
	 *   Note: default does not leave enough room for Jumbo Frame >10k.
d653 25
a677 16
	if(sc->hw.mac_type < em_82547) {
		/* Total FIFO is 64K */
		if(sc->rx_buffer_len > EM_RXBUFFER_8192)
			pba = E1000_PBA_40K; /* 40K for Rx, 24K for Tx */
		else
			pba = E1000_PBA_48K; /* 48K for Rx, 16K for Tx */
	} else {
		/* Total FIFO is 40K */
		if(sc->hw.max_frame_size > EM_RXBUFFER_8192) {
			pba = E1000_PBA_22K; /* 22K for Rx, 18K for Tx */
		} else {
		        pba = E1000_PBA_30K; /* 30K for Rx, 10K for Tx */
		}
		sc->tx_fifo_head = 0;
		sc->tx_head_addr = pba << EM_TX_HEAD_ADDR_SHIFT;
		sc->tx_fifo_size = (E1000_PBA_40K - pba) << EM_PBA_BYTES_SHIFT;
d1418 4
a1421 4
	if(sc->hw.mac_type == em_82541 ||
	   sc->hw.mac_type == em_82541_rev_2 ||
	   sc->hw.mac_type == em_82547 ||
	   sc->hw.mac_type == em_82547_rev_2)
d1773 1
a1773 1
		return ENOMEM;
d1779 1
a1779 1
	return 0;
d1864 1
a1864 1
	if (sc->hw.mac_type >= em_82573)
d2199 1
a2199 1
		return ENOMEM;
d2203 1
a2203 1
	return(0);
d2800 1
a2800 1
	sc->stats.rlec +
d2820 13
a2832 11
        printf("%s: Adapter hardware address = %p \n", unit, hw_addr);
	printf("%s:CTRL  = 0x%x\n", unit, 
		E1000_READ_REG(&sc->hw, CTRL)); 
	printf("%s:RCTL  = 0x%x PS=(0x8402)\n", unit, 
		E1000_READ_REG(&sc->hw, RCTL));
        printf("%s:tx_int_delay = %d, tx_abs_int_delay = %d\n", unit,
              E1000_READ_REG(&sc->hw, TIDV),
              E1000_READ_REG(&sc->hw, TADV));
        printf("%s:rx_int_delay = %d, rx_abs_int_delay = %d\n", unit,
              E1000_READ_REG(&sc->hw, RDTR),
              E1000_READ_REG(&sc->hw, RADV));
d2834 1
a2834 1
	printf("%s: fifo workaround = %lld, fifo_reset = %lld\n", unit,
@


1.69
log
@remove return at the end of void function.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.68 2005/09/10 23:25:41 brad Exp $ */
d452 3
a454 3
        EM_LOCK(sc);
        em_start_locked(ifp);
        EM_UNLOCK(sc);
d512 1
a512 1
                EM_LOCK(sc);
d525 1
a525 1
                EM_UNLOCK(sc);
d705 1
a705 1
        struct em_softc *sc = arg;
d708 3
a710 3
        EM_LOCK(sc);
        em_init_locked(sc);
        EM_UNLOCK(sc);
d727 1
a727 1
        EM_LOCK(sc);
d733 1
a733 1
                EM_UNLOCK(sc);
d755 1
a755 1
                em_start_locked(ifp);
d757 1
a757 1
        EM_UNLOCK(sc);
d1073 1
a1073 1
        EM_LOCK_ASSERT(sc);
d1104 3
a1106 3
        EM_LOCK(sc);
        em_82547_move_tail_locked(sc);
        EM_UNLOCK(sc);
d1304 1
a1304 1
        EM_UNLOCK(sc);
@


1.68
log
@whitespace removal and KNF
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.67 2005/08/09 04:10:12 mickey Exp $ */
a443 1
	return;
a454 1
	return;
a590 1
	return;
a699 2

	return;
a710 1
        return;
a818 1
	return;
a1095 1
	return;
a1141 2

	return;
a1199 2

	return;
a1211 2

	return;
a1273 2

	return;
a1304 1
	return;
a1329 3

        return;

a1358 2

	return;
a1396 2

	return;
a1485 1

a1595 2

	return;
a1654 2

	return;
a1851 2

	return;
a1885 1
	return;
a1969 2

	return;
a2037 1
	return;
a2260 2

	return;
a2295 1
	return;
a2504 1
	return;
a2550 1
	return;
a2570 1
	return;
a2602 1
	return;
a2612 1

a2622 1

a2778 1

a2823 2

	return;
a2867 2

	return;
@


1.67
log
@do not set PCI_COMMAND_MASTER_ENABLE explicitly as it's already set in pcisubmatch(); kettenis@@ testing; brad@@ ok
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.66 2005/07/16 19:05:36 brad Exp $ */
a49 1

d411 1
a411 1
	
d418 2
a419 1
		if (m_head == NULL) break;
d953 1
a953 1
	em_transmit_checksum_setup(sc,	m_head, &txd_upper, &txd_lower);
@


1.67.2.1
log
@MFC:
Fix by brad@@

rev 1.131
fix Jumbo frames on strict alignment architectures by allocating a new mbuf and
copying the Ethernet header to the new mbuf. The new mbuf is then prepended
into the existing mbuf chain.

rev 1.130
remove the m_adj().

ok reyk@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.67 2005/08/09 04:10:12 mickey Exp $ */
a134 3
#ifdef __STRICT_ALIGNMENT
void em_fixup_rx(struct em_softc *);
#endif
d2110 4
d2433 49
a2515 3
#ifdef __STRICT_ALIGNMENT
				em_fixup_rx(sc);
#endif
a2544 43

#ifdef __STRICT_ALIGNMENT
/*
 * When Jumbo frames are enabled we should realign the entire payload on
 * strict alignment architecures. This is a serious design mistake of the
 * 8254x chipset as it nullifies DMA operations. 8254x allows the RX buffer
 * size to be 2048/4096/8192/16384. What we really want is 2048 - ETHER_ALIGN
 * to align its payload. On non strict alignment architectures 8254x still
 * performs unaligned memory access which will reduce the performance too. To
 * avoid copying over an entire frame to align, we allocate a new mbuf and
 * copy the Ethernet header to the new mbuf. The new mbuf is then prepended
 * into the existing mbuf chain.
 *
 * Be aware, best performance of the 8254x chipset is achived only when Jumbo
 * frames are not used at all on strict alignment architectures.
 */
void
em_fixup_rx(struct em_softc *sc)
{
	struct mbuf *m, *n;

	m = sc->fmp;
	if (m->m_len <= (MCLBYTES - ETHER_HDR_LEN)) {
		bcopy(m->m_data, m->m_data + ETHER_HDR_LEN, m->m_len);
		m->m_data += ETHER_HDR_LEN;
	} else {
		MGETHDR(n, M_DONTWAIT, MT_DATA);
		if (n != NULL) {
			bcopy(m->m_data, n->m_data, ETHER_HDR_LEN);
			m->m_data += ETHER_HDR_LEN;
			m->m_len -= ETHER_HDR_LEN;
			n->m_len = ETHER_HDR_LEN;
			M_MOVE_PKTHDR(n, m);
			n->m_next = m;
			sc->fmp = n;
		} else {
			sc->dropped_pkts++;
			m_freem(sc->fmp);
			sc->fmp = NULL;
		}
	}
}
#endif
@


1.67.2.2
log
@MFC:
Fix by brad@@

revert revision 1.131, the code in question was later found to not ensure
the proper alignment requirement for the VLAN layer on strict alignment
architectures. This would result in Jumbo's working fine as long as VLANs
were not in use. If VLANs were in use and a packet comes in with a size
of 2046 bytes or larger, it would be corrupted as it came up through the
VLAN layer. Also check the hw max frame size, instead of the MTU, so the
alignment fixup is done as appropriate.

Fixes PR 5185.
Tested by Rui DeSousa with macppc and myself with alpha/sparc64.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.67.2.1 2006/06/30 08:52:37 brad Exp $ */
d135 3
a2112 3
	if (sc->hw.max_frame_size <= (MCLBYTES - ETHER_ALIGN))
		m_adj(mp, ETHER_ALIGN);

a2431 49
#ifdef __STRICT_ALIGNMENT
			/*
			 * The Ethernet payload is not 32-bit aligned when
			 * Jumbo packets are enabled, so on architectures with
			 * strict alignment we need to shift the entire packet
			 * ETHER_ALIGN bytes. Ugh.
			 */
			if (sc->hw.max_frame_size > (MCLBYTES - ETHER_ALIGN)) {
				unsigned char tmp_align_buf[ETHER_ALIGN];
				int tmp_align_buf_len = 0;

				if (prev_len_adj > sc->align_buf_len)
					prev_len_adj -= sc->align_buf_len;
				else
					prev_len_adj = 0;

				if (mp->m_len > (MCLBYTES - ETHER_ALIGN)) {
					bcopy(mp->m_data +
					    (MCLBYTES - ETHER_ALIGN),
					    &tmp_align_buf,
					    ETHER_ALIGN);
					tmp_align_buf_len = mp->m_len -
					    (MCLBYTES - ETHER_ALIGN);
					mp->m_len -= ETHER_ALIGN;
				} 

				if (mp->m_len) {
					bcopy(mp->m_data,
					    mp->m_data + ETHER_ALIGN,
					    mp->m_len);
					if (!sc->align_buf_len)
						mp->m_data += ETHER_ALIGN;
				}

				if (sc->align_buf_len) {
					mp->m_len += sc->align_buf_len;
					bcopy(&sc->align_buf,
					    mp->m_data,
					    sc->align_buf_len);
				}

				if (tmp_align_buf_len) 
					bcopy(&tmp_align_buf,
					    &sc->align_buf,
					    tmp_align_buf_len);
				sc->align_buf_len = tmp_align_buf_len;
			}
#endif /* __STRICT_ALIGNMENT */

d2466 3
d2498 43
@


1.66
log
@move headers and remove some FreeBSD specific stuff.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.65 2005/07/16 17:08:02 brad Exp $ */
a1396 9
	if (!((sc->hw.pci_cmd_word & PCI_COMMAND_MASTER_ENABLE) &&
	      (sc->hw.pci_cmd_word & PCI_COMMAND_MEM_ENABLE))) {
		printf("%s: Memory Access and/or Bus Master bits were not set!\n", 
		       sc->sc_dv.dv_xname);
		sc->hw.pci_cmd_word |= 
		(PCI_COMMAND_MASTER_ENABLE | PCI_COMMAND_MEM_ENABLE);
		pci_conf_write(pa->pa_pc, pa->pa_tag, PCI_COMMAND_STATUS_REG,
			       sc->hw.pci_cmd_word);
	}
@


1.65
log
@fix support for interrupt mitigation.

ok nate@@
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.64 2005/07/13 20:25:46 brad Exp $ */
a35 41

#include "bpfilter.h"
#include "vlan.h"

#include <sys/param.h>
#include <sys/systm.h>
#include <sys/sockio.h>
#include <sys/mbuf.h>
#include <sys/malloc.h>
#include <sys/kernel.h>
#include <sys/device.h>
#include <sys/socket.h>

#include <net/if.h>
#include <net/if_dl.h>
#include <net/if_media.h>

#ifdef INET
#include <netinet/in.h>
#include <netinet/in_systm.h>
#include <netinet/in_var.h>
#include <netinet/ip.h>
#include <netinet/if_ether.h>
#include <netinet/tcp.h>
#include <netinet/udp.h>
#endif

#if NVLAN > 0
#include <net/if_types.h>
#include <net/if_vlan_var.h>
#endif

#if NBPFILTER > 0
#include <net/bpf.h>
#endif

#include <uvm/uvm_extern.h>

#include <dev/pci/pcireg.h>
#include <dev/pci/pcivar.h>
#include <dev/pci/pcidevs.h>
@


1.64
log
@remove white space and fix formatting for readability.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.63 2005/07/07 21:28:10 brad Exp $ */
a218 12
 *  Tunable default values.
 *********************************************************************/

#define E1000_TICKS_TO_USECS(ticks)     ((1024 * (ticks) + 500) / 1000)
#define E1000_USECS_TO_TICKS(usecs)     ((1000 * (usecs) + 512) / 1024)

int em_tx_int_delay_dflt = E1000_TICKS_TO_USECS(EM_TIDV);
int em_rx_int_delay_dflt = E1000_TICKS_TO_USECS(EM_RDTR);
int em_tx_abs_int_delay_dflt = E1000_TICKS_TO_USECS(EM_TADV);
int em_rx_abs_int_delay_dflt = E1000_TICKS_TO_USECS(EM_RADV);

/*********************************************************************
d273 4
a321 1

d1910 1
a1910 1
	E1000_WRITE_REG(&sc->hw, TIDV, sc->tx_int_delay.value);
d1912 1
a1912 2
		E1000_WRITE_REG(&sc->hw, TADV,
		    sc->tx_abs_int_delay.value);
d1929 1
a1929 1
	if (sc->tx_int_delay.value > 0)
d2286 1
a2286 1
			sc->rx_int_delay.value | E1000_RDT_FPDB);
d2289 1
a2289 2
		E1000_WRITE_REG(&sc->hw, RADV,
		    sc->rx_abs_int_delay.value);
@


1.63
log
@check ETHERMIN and stop calling em_init_locked() from SIOCSIFMTU ioctl.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.62 2005/07/03 16:58:16 brad Exp $ */
a1896 1

d1914 2
a1915 2
			reg_tipg |= DEFAULT_82543_TIPG_IPGR1 << E1000_TIPG_IPGR1_SHIFT;
			reg_tipg |= DEFAULT_82543_TIPG_IPGR2 << E1000_TIPG_IPGR2_SHIFT;
@


1.62
log
@include CRC
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.61 2005/07/03 07:31:43 brad Exp $ */
d553 2
a554 1
		if (ifr->ifr_mtu > MAX_JUMBO_FRAME_SIZE - ETHER_HDR_LEN || \
d558 1
a558 2
		} else {
                        EM_LOCK(sc);
a559 2
			em_init_locked(sc);
                        EM_UNLOCK(sc);
@


1.61
log
@no need for HW VLAN tag removal so clean up some code.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.60 2005/07/02 23:10:11 brad Exp $ */
d318 1
a318 1
		    MAX_JUMBO_FRAME_SIZE;
@


1.60
log
@clear IFF_RUNNING & IFF_OACTIVE in foo_stop() before de-allocating resources.
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.59 2005/07/02 06:15:44 deraadt Exp $ */
a189 2
void em_enable_vlans(struct em_softc *);
void em_disable_vlans(struct em_softc *);
a721 2
	/* em_enable_vlans(sc); */

a1003 1

d1009 1
a1010 1
#if NVLAN > 0
d1012 1
a1012 2
	    m_head->m_pkthdr.rcvif != NULL &&
	    m_head->m_pkthdr.rcvif->if_type == IFT_L2VLAN)
a1205 1

a1256 9

#if 0
		/* Disable VLAN stripping in promiscous mode 
		 * This enables bridging of vlan tagged frames to occur 
		 * and also allows vlan tags to be seen in tcpdump
		 */
		ctrl &= ~E1000_CTRL_VME; 
		E1000_WRITE_REG(&sc->hw, CTRL, ctrl);
#endif
a1276 1
	/* em_enable_vlans(sc); */
a2647 26
}

void
em_enable_vlans(struct em_softc *sc)
{
	uint32_t ctrl;

	E1000_WRITE_REG(&sc->hw, VET, ETHERTYPE_VLAN);

	ctrl = E1000_READ_REG(&sc->hw, CTRL);
	ctrl |= E1000_CTRL_VME; 
	E1000_WRITE_REG(&sc->hw, CTRL, ctrl);

	return;
}

void
em_disable_vlans(struct em_softc *sc)
{
	uint32_t ctrl;

	ctrl = E1000_READ_REG(&sc->hw, CTRL);
	ctrl &= ~E1000_CTRL_VME;
	E1000_WRITE_REG(&sc->hw, CTRL, ctrl);

	return;
@


1.59
log
@sync
@
text
@d34 1
a34 1
/* $OpenBSD: if_em.c,v 1.58 2005/06/14 03:27:58 brad Exp $ */
a1441 2
	em_free_transmit_structures(sc);
	em_free_receive_structures(sc);
d1445 3
@


1.58
log
@at least allow the transmit checksum code to compile
though this hasn't been re-enabled yet.
@
text
@d34 1
a35 1
/* $OpenBSD: if_em.c,v 1.57 2005/06/14 03:24:32 brad Exp $ */
d96 1
a96 1
char em_driver_version[] = "1.7.35";
d137 2
d315 7
a321 2
	sc->hw.max_frame_size = 
	    ETHER_MAX_LEN_JUMBO;
d555 3
a557 1
		if (ifr->ifr_mtu > MAX_JUMBO_FRAME_SIZE - ETHER_HDR_LEN) {
d1946 2
a2104 3
#ifdef DBG_STATS
	sc->clean_tx_interrupts++;
#endif
d2364 2
a2365 1
	reg_rctl |= E1000_RCTL_LPE;
a2445 3
#ifdef DBG_STATS
		sc->no_pkts_avail++;
#endif
a2956 6
#ifdef DBG_STATS
	printf("%s: Packets not Avail = %ld\n", unit, 
	       sc->no_pkts_avail);
	printf("%s: CleanTxInterrupts = %ld\n", unit,
	       sc->clean_tx_interrupts);
#endif
@


1.57
log
@fix prototype
@
text
@d35 1
a35 1
/* $OpenBSD: if_em.c,v 1.56 2005/06/14 03:18:10 brad Exp $ */
d59 2
a1994 1
#if 0
d2007 1
a2007 1
		if (mp->m_pkthdr.csum_flags & CSUM_TCP) {
d2015 1
a2015 1
		} else if (mp->m_pkthdr.csum_flags & CSUM_UDP) {
a2072 1
#endif
@


1.56
log
@re-add part of rev 1.49...

sync em_receive_checksum() closer to the FreeBSD driver

ok millert@@ msf@@
@
text
@d35 1
a35 1
/* $OpenBSD: if_em.c,v 1.55 2005/06/12 23:43:29 millert Exp $ */
d184 1
a184 1
int  em_get_buf(int i, struct em_softc *,
@


1.55
log
@Back out revs 1.48 and 1.49.  Checksum offloading caused problems on
an 82547EI and may affects others.  Ok henning@@
@
text
@d35 1
a35 1
/* $OpenBSD: if_em.c,v 1.54 2005/06/01 02:07:12 brad Exp $ */
d2635 2
a2636 1
	    (rx_desc->status & E1000_RXD_STAT_IXSM))
d2638 12
d2651 7
a2657 8
	if ((rx_desc->status & (E1000_RXD_STAT_IPCS|E1000_RXD_ERR_IPE)) ==
	    E1000_RXD_STAT_IPCS)
		mp->m_pkthdr.csum_flags |= M_IPV4_CSUM_IN_OK;

	if ((rx_desc->status & (E1000_RXD_STAT_IPCS|E1000_RXD_ERR_IPE|
	    E1000_RXD_STAT_TCPCS|E1000_RXD_ERR_TCPE)) ==
	    (E1000_RXD_STAT_TCPCS | E1000_RXD_STAT_IPCS))
		mp->m_pkthdr.csum_flags |= M_TCP_CSUM_IN_OK | M_UDP_CSUM_IN_OK;
@


1.54
log
@fix ordering of PCI devs
@
text
@d35 1
a35 1
/* $OpenBSD: if_em.c,v 1.53 2005/05/29 07:54:26 brad Exp $ */
a58 2
#include <netinet/tcp.h>
#include <netinet/udp.h>
d184 1
a184 1
int  em_get_buf(int, struct em_softc *,
d997 5
a1001 4
	if (sc->hw.mac_type >= em_82543)
		em_transmit_checksum_setup(sc, m_head, &txd_upper, &txd_lower);
	else
		txd_upper = txd_lower = 0;
a1658 3
	if (sc->hw.mac_type >= em_82543)
		ifp->if_capabilities |= IFCAP_CSUM_TCPv4|IFCAP_CSUM_UDPv4;

d1993 1
d2005 2
a2006 1
		if (mp->m_pkthdr.csum_flags & M_TCPV4_CSUM_OUT) {
d2013 2
a2014 1
		} else if (mp->m_pkthdr.csum_flags & M_UDPV4_CSUM_OUT) {
d2072 1
d2638 8
a2645 18
	if (rx_desc->status & E1000_RXD_STAT_IPCS) {
		/* Did it pass? */
		if (!(rx_desc->errors & E1000_RXD_ERR_IPE)) {
			/* IP Checksum Good */
			mp->m_pkthdr.csum_flags = M_IPV4_CSUM_IN_OK;

		} else {
			mp->m_pkthdr.csum_flags = 0;
		}
	}

	if (rx_desc->status & E1000_RXD_STAT_TCPCS) {
		/* Did it pass? */        
		if (!(rx_desc->errors & E1000_RXD_ERR_TCPE)) {
			mp->m_pkthdr.csum_flags |=
				M_TCP_CSUM_IN_OK | M_UDP_CSUM_IN_OK;
		}
	}
@


1.53
log
@- better pcidevs entries for Intel Gig and add 82573 ids
- add/fix up Abocom enries
@
text
@d35 1
a35 1
/* $OpenBSD: if_em.c,v 1.52 2005/05/27 20:36:35 brad Exp $ */
d108 1
a110 1
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82541EI_MOBILE },
d115 1
a116 1
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82543GC_COPPER },
a130 1
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82546GB_SERDES },
d133 1
@


1.52
log
@allow reception of Jumbo frames by default without having to bump
the MTU up.

tested by marious@@, ok mcbride@@
@
text
@d35 1
a35 1
/* $OpenBSD: if_em.c,v 1.51 2005/05/23 23:26:56 tedu Exp $ */
a101 7
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82542 },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82543GC_SC },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82543GC },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82544EI },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82544EI_SC },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82544GC },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82544GC_LOM },
a102 6
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82545EM },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82546EB },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82545EM_SC },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82546EB_SC },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82541EI },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82541EI_NC },
d104 1
a105 5
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82540EP },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82541EP },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82547EI },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82547EI_MOB },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82546GB_QUAD },
d107 16
a125 4
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82547EI_CT },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82541EI_MT },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82541EI_MOB },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82541EI_MT2 },
d128 9
a136 3
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82546EB_SERDES },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82546GB },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_PRO_1000_GT }
@


1.51
log
@loose is not lose. ok deraadt tdeval and a few more typos from jfb
@
text
@d35 1
a35 1
/* $OpenBSD: if_em.c,v 1.50 2005/05/07 22:16:36 brad Exp $ */
d313 1
a313 1
	    ETHER_MAX_LEN;
a551 2
			sc->hw.max_frame_size = 
			ifp->if_mtu + ETHER_HDR_LEN + ETHER_CRC_LEN;
d2355 1
a2355 2
	if (ifp->if_mtu > ETHERMTU)
		reg_rctl |= E1000_RCTL_LPE;
@


1.50
log
@enable transmit checksum offload on all chips except 82542.
@
text
@d35 1
a35 1
/* $OpenBSD: if_em.c,v 1.49 2005/05/07 15:48:34 brad Exp $ */
d739 1
a739 1
        /* Don't loose promiscuous settings */
@


1.49
log
@- enable transmit checksum offload
- sync em_receive_checksum() closer to the FreeBSD driver

tested on 540, 541PI, 543, 544 and 546EB by djm@@, marco@@, brad@@
and a few others.
@
text
@d35 1
a35 1
/* $OpenBSD: if_em.c,v 1.48 2005/05/01 12:19:48 markus Exp $ */
d1000 4
a1003 1
	em_transmit_checksum_setup(sc, m_head, &txd_upper, &txd_lower);
d1659 4
a1662 1
	ifp->if_capabilities = IFCAP_VLAN_MTU|IFCAP_CSUM_TCPv4|IFCAP_CSUM_UDPv4;
@


1.48
log
@update the maxium sendqueue size on ifconfig up; this should fix problems
where IP cannot send packets larger then 11*mtu (e.g for large UDP/NFS
packets); pascoe@@ brad@@
@
text
@d35 1
a35 1
/* $OpenBSD: if_em.c,v 1.47 2005/04/25 17:55:51 brad Exp $ */
d59 2
d185 1
a185 1
int  em_get_buf(int i, struct em_softc *,
d1000 1
a1000 5

#if 0
	em_transmit_checksum_setup(sc,	m_head, &txd_upper, &txd_lower);
#endif
	txd_upper = txd_lower = 0;
d1656 1
a1656 1
	ifp->if_capabilities = IFCAP_VLAN_MTU;
a1991 1
#if 0
d2003 1
a2003 2

		if (mp->m_pkthdr.csum_flags & CSUM_TCP) {
d2010 1
a2010 2

		} else if (mp->m_pkthdr.csum_flags & CSUM_UDP) {
a2067 1
#endif
d2634 18
a2651 8
	if ((rx_desc->status & (E1000_RXD_STAT_IPCS|E1000_RXD_ERR_IPE)) ==
	    E1000_RXD_STAT_IPCS)
		mp->m_pkthdr.csum_flags |= M_IPV4_CSUM_IN_OK;

	if ((rx_desc->status & (E1000_RXD_STAT_IPCS|E1000_RXD_ERR_IPE|
	    E1000_RXD_STAT_TCPCS|E1000_RXD_ERR_TCPE)) ==
	    (E1000_RXD_STAT_TCPCS | E1000_RXD_STAT_IPCS))
		mp->m_pkthdr.csum_flags |= M_TCP_CSUM_IN_OK | M_UDP_CSUM_IN_OK;
@


1.47
log
@csum -> csum_flags

ok krw@@ canacar@@
@
text
@d35 1
a35 1
/* $OpenBSD: if_em.c,v 1.46 2005/04/25 02:08:08 brad Exp $ */
d671 1
@


1.46
log
@Use ETHERTYPE_VLAN.
@
text
@d35 1
a35 1
/* $OpenBSD: if_em.c,v 1.45 2005/04/10 04:08:40 brad Exp $ */
d2641 1
a2641 1
		mp->m_pkthdr.csum |= M_IPV4_CSUM_IN_OK;
d2646 1
a2646 1
		mp->m_pkthdr.csum |= M_TCP_CSUM_IN_OK | M_UDP_CSUM_IN_OK;
@


1.45
log
@- Run em_local_timer() once per second instead of running it once per 2 seconds.
  This makes gathering of error stats more precise, and netstat(1) output look
  right.
- Modify the caller of em_encap() to detect a NULL m_head and not try
  to queue the mbuf if that happens.

From FreeBSD

ok krw@@ beck@@
@
text
@d35 1
a35 1
/* $OpenBSD: if_em.c,v 1.44 2005/04/01 06:44:14 brad Exp $ */
d2654 1
a2654 1
	E1000_WRITE_REG(&sc->hw, VET, ETHERTYPE_8021Q);
@


1.44
log
@- remove unused function em_print_link_status() used by FreeBSD
- add em_disable_vlans() which disables HW VLAN support; From FreeBSD
@
text
@d35 1
a35 1
/* $OpenBSD: if_em.c,v 1.43 2005/03/31 15:31:22 brad Exp $ */
d187 1
a187 1
int  em_encap(struct em_softc *, struct mbuf *);
d463 7
a469 1
		if (em_encap(sc, m_head)) {
d742 1
a742 1
	timeout_add(&sc->timer_handle, 2*hz);
d794 1
a794 1
		timeout_add(&sc->timer_handle, 2*hz); 
d939 1
a939 1
em_encap(struct em_softc *sc, struct mbuf *m_head)
d946 2
d959 2
a960 1
	/*struct ifnet	 *ifp = &sc->interface_data.ac_if;*/
d1376 1
a1376 1
	timeout_add(&sc->timer_handle, 2*hz);
@


1.43
log
@enable receive checksum offload
@
text
@d35 1
a35 1
/* $OpenBSD: if_em.c,v 1.42 2005/03/27 17:11:13 brad Exp $ */
a181 1
void em_print_link_status(struct em_softc *);
d186 1
a1373 28
em_print_link_status(struct em_softc *sc)
{
        if (E1000_READ_REG(&sc->hw, STATUS) & E1000_STATUS_LU) {
                if (sc->link_active == 0) {
                        em_get_speed_and_duplex(&sc->hw,
                                                &sc->link_speed,
                                                &sc->link_duplex);
                        printf("%s: Link is up %d Mbps %s\n",
                               sc->sc_dv.dv_xname,
                               sc->link_speed,
                               ((sc->link_duplex == FULL_DUPLEX) ?
                                "Full Duplex" : "Half Duplex"));
                        sc->link_active = 1;
                        sc->smartspeed = 0;
                }
        } else {
                if (sc->link_active == 1) {
                        sc->link_speed = 0;
                        sc->link_duplex = 0;
                        printf("%s: Link is Down\n", sc->sc_dv.dv_xname);
                        sc->link_active = 0;
                }
        }

        return;
}

void
a2639 1

d2649 12
@


1.42
log
@EB -> GB
@
text
@d35 1
a35 1
/* $OpenBSD: if_em.c,v 1.41 2005/03/27 16:38:13 brad Exp $ */
a2313 1
#if 0
a2314 1
#endif
a2378 1
#if 0
a2383 1
#endif
@


1.41
log
@remove FreeBSD ifdef bloat.

ok krw@@
@
text
@d35 1
a35 1
/* $OpenBSD: if_em.c,v 1.40 2005/03/26 23:04:58 brad Exp $ */
d120 1
a120 1
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82546EB_QUAD },
@


1.40
log
@Use "struct em_softc *sc" consistently all over and uncover the
watchdog reset message.

ok krw@@
@
text
@d35 1
a35 1
/* $OpenBSD: if_em.c,v 1.39 2005/03/16 11:59:09 markus Exp $ */
a95 62
#ifdef __FreeBSD__
/*********************************************************************
 *  PCI Device ID Table
 *
 *  Used by probe to select devices to load on
 *  Last field stores an index into em_strings
 *  Last entry must be all 0s
 *
 *  { Vendor ID, Device ID, SubVendor ID, SubDevice ID, String Index }
 *********************************************************************/

em_vendor_info_t em_vendor_info_array[] =
{
        /* Intel(R) PRO/1000 Network Connection */
        { 0x8086, 0x1000, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1001, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1004, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1008, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1009, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x100C, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x100D, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x100E, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x100F, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1010, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1011, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1012, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1013, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1014, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1015, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1016, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1017, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1018, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1019, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x101A, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x101D, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x101E, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1026, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1027, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1028, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1075, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1076, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1077, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1078, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1079, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x107A, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x107B, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x107C, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x108A, PCI_ANY_ID, PCI_ANY_ID, 0},
        /* required last entry */
        { 0, 0, 0, 0, 0}
};

/*********************************************************************
 *  Table of branding strings for all supported NICs.
 *********************************************************************/

char *em_strings[] = {
        "Intel(R) PRO/1000 Network Connection"
};
#endif /* __FreeBSD__ */

#ifdef __OpenBSD__
a134 1
#endif /* __OpenBSD__ */
a138 8
#ifdef __FreeBSD__
int  em_probe(device_t);
int  em_attach(device_t);
int  em_detach(device_t);
int  em_shutdown(device_t);
void em_intr(void *);
#endif /* __FreeBSD__ */
#ifdef __OpenBSD__
a142 1
#endif /* __OpenBSD__ */
a156 4
#ifdef __FreeBSD__
void em_setup_interface(device_t, struct em_softc *);
#endif
#ifdef __OpenBSD__
a157 1
#endif
a198 4
#ifdef __FreeBSD__
int  em_sysctl_stats(SYSCTL_HANDLER_ARGS);
int  em_sysctl_debug_info(SYSCTL_HANDLER_ARGS);
#endif /* __FreeBSD__ */
a201 6
#ifdef __FreeBSD__
int  em_sysctl_int_delay(SYSCTL_HANDLER_ARGS);
void em_add_int_delay_sysctl(struct em_softc *, const char *,
                                    const char *, struct em_int_delay_info *,
                                    int, int);
#endif /* __FreeBSD__ */
d204 1
a204 1
 *  FreeBSD Device Interface Entry Points		     
a206 21
#ifdef __FreeBSD__
device_method_t em_methods[] = {
        /* Device interface */
        DEVMETHOD(device_probe, em_probe),
        DEVMETHOD(device_attach, em_attach),
        DEVMETHOD(device_detach, em_detach),
        DEVMETHOD(device_shutdown, em_shutdown),
        {0, 0}
};

driver_t em_driver = {
        "em", em_methods, sizeof(struct em_softc),
};

devclass_t em_devclass;
DRIVER_MODULE(em, pci, em_driver, em_devclass, 0, 0);
MODULE_DEPEND(em, pci, 1, 1, 1);
MODULE_DEPEND(em, ether, 1, 1, 1);
#endif /* __FreeBSD__ */

#ifdef __OpenBSD__
a213 1
#endif /* __OpenBSD__ */
a226 7
#ifdef __FreeBSD__
TUNABLE_INT("hw.em.tx_int_delay", &em_tx_int_delay_dflt);
TUNABLE_INT("hw.em.rx_int_delay", &em_rx_int_delay_dflt);
TUNABLE_INT("hw.em.tx_abs_int_delay", &em_tx_abs_int_delay_dflt);
TUNABLE_INT("hw.em.rx_abs_int_delay", &em_rx_abs_int_delay_dflt);
#endif /* __FreeBSD__ */

a235 46
#ifdef __FreeBSD__
int
em_probe(device_t dev)
{
        em_vendor_info_t *ent;

        u_int16_t       pci_vendor_id = 0;
        u_int16_t       pci_device_id = 0;
        u_int16_t       pci_subvendor_id = 0;
        u_int16_t       pci_subdevice_id = 0;
        char            adapter_name[60];

        INIT_DEBUGOUT("em_probe: begin");

        pci_vendor_id = pci_get_vendor(dev);
        if (pci_vendor_id != EM_VENDOR_ID)
                return(ENXIO);

        pci_device_id = pci_get_device(dev);
        pci_subvendor_id = pci_get_subvendor(dev);
        pci_subdevice_id = pci_get_subdevice(dev);

        ent = em_vendor_info_array;
        while (ent->vendor_id != 0) {
                if ((pci_vendor_id == ent->vendor_id) &&
                    (pci_device_id == ent->device_id) &&

                    ((pci_subvendor_id == ent->subvendor_id) ||
                     (ent->subvendor_id == PCI_ANY_ID)) &&

                    ((pci_subdevice_id == ent->subdevice_id) ||
                     (ent->subdevice_id == PCI_ANY_ID))) {
                        sprintf(adapter_name, "%s, Version - %s",
                                em_strings[ent->index],
                                em_driver_version);
                        device_set_desc_copy(dev, adapter_name);
                        return(0);
                }
                ent++;
        }

        return(ENXIO);
}
#endif /* __FreeBSD__ */

#ifdef __OpenBSD__
a243 1
#endif /* __OpenBSD__ */
a254 7
#ifdef __FreeBSD__
int
em_attach(device_t dev)
{
	pci_chipset_tag_t pc = pa->pa_pc;
#endif /* __FreeBSD__ */
#ifdef __OpenBSD__
a258 1
#endif /* __OpenBSD__ */
a264 15
#ifdef __FreeBSD__
	/* Allocate, clear, and link in our sc structure */
	if (!(sc = device_get_softc(dev))) {
		printf("em: sc structure allocation failed\n");
		return(ENOMEM);
	}
	bzero(sc, sizeof(struct em_softc));
	sc->dev = dev;
	sc->osdep.dev = dev;
	sc->sc_dv.dv_xname = device_get_unit(dev);
	EM_LOCK_INIT(sc, device_get_nameunit(dev));
#endif /* __FreeBSD__ */


#ifdef __OpenBSD__
a266 1
#endif
a272 31
#ifdef __FreeBSD__
	/* SYSCTL stuff */
	sysctl_ctx_init(&sc->sysctl_ctx);
	sc->sysctl_tree = SYSCTL_ADD_NODE(&sc->sysctl_ctx,
					       SYSCTL_STATIC_CHILDREN(_hw),
					       OID_AUTO,
					       device_get_nameunit(dev),
					       CTLFLAG_RD,
					       0, "");
	if (sc->sysctl_tree == NULL) {
		error = EIO;
		goto err_sysctl;
	}

	SYSCTL_ADD_PROC(&sc->sysctl_ctx,
			SYSCTL_CHILDREN(sc->sysctl_tree),
			OID_AUTO, "debug_info", CTLTYPE_INT|CTLFLAG_RW,
			(void *)sc, 0,
			em_sysctl_debug_info, "I", "Debug Information");

	SYSCTL_ADD_PROC(&sc->sysctl_ctx,
			SYSCTL_CHILDREN(sc->sysctl_tree),
			OID_AUTO, "stats", CTLTYPE_INT|CTLFLAG_RW,
			(void *)sc, 0,
			em_sysctl_stats, "I", "Statistics");

	callout_init(&sc->timer, CALLOUT_MPSAFE);
	callout_init(&sc->tx_fifo_timer, CALLOUT_MPSAFE);
#endif /* __FreeBSD__ */

#ifdef __OpenBSD__
a274 1
#endif /* __OpenBSD__ */
a278 22
#ifdef __FreeBSD__
        /* Set up some sysctls for the tunable interrupt delays */
        em_add_int_delay_sysctl(sc, "rx_int_delay",
            "receive interrupt delay in usecs", &sc->rx_int_delay,
            E1000_REG_OFFSET(&sc->hw, RDTR), em_rx_int_delay_dflt);
        em_add_int_delay_sysctl(sc, "tx_int_delay",
            "transmit interrupt delay in usecs", &sc->tx_int_delay,
            E1000_REG_OFFSET(&sc->hw, TIDV), em_tx_int_delay_dflt);
        if (sc->hw.mac_type >= em_82540) {
                em_add_int_delay_sysctl(sc, "rx_abs_int_delay",
                    "receive interrupt delay limit in usecs",
                    &sc->rx_abs_int_delay,
                    E1000_REG_OFFSET(&sc->hw, RADV),
                    em_rx_abs_int_delay_dflt);
                em_add_int_delay_sysctl(sc, "tx_abs_int_delay",
                    "transmit interrupt delay limit in usecs",
                    &sc->tx_abs_int_delay,
                    E1000_REG_OFFSET(&sc->hw, TADV),
                    em_tx_abs_int_delay_dflt);
        }
#endif /* __FreeBSD__ */

d314 1
a314 1
	    MINIMUM_ETHERNET_PACKET_SIZE + ETHER_CRC_LEN;
a329 1

a396 9
#ifdef __FreeBSD__
                printf("%s:  Speed:%d Mbps  Duplex:%s\n",
                       sc->sc_dv.dv_xname,
                       sc->link_speed,
                       sc->link_duplex == FULL_DUPLEX ? "Full" : "Half");
        } else
                printf("%s:  Speed:N/A  Duplex:N/A\n", sc->sc_dv.dv_xname);
#endif /* __FreeBSD__ */
#ifdef __OpenBSD__
a399 1
#endif /* __OpenBSD__ */
a410 4
#ifdef __FreeBSD__
	return(0);
#endif
#ifdef __OpenBSD__
a412 1
#endif
a421 6
#ifdef __FreeBSD__
	sysctl_ctx_free(&sc->sysctl_ctx);
err_sysctl:
	return(error);
#endif /* __FreeBSD__ */

a423 1
#ifdef __OpenBSD__
a435 87
#endif

/*********************************************************************
 *  Device removal routine
 *
 *  The detach entry point is called when the driver is being removed.
 *  This routine stops the adapter and deallocates all the resources
 *  that were allocated for driver operation.
 *  
 *  return 0 on success, positive on failure
 *********************************************************************/

#ifdef __FreeBSD__
int
em_detach(device_t dev)
{
        struct em_softc *sc = device_get_softc(dev);
        struct ifnet   *ifp = &sc->interface_data.ac_if;
	EM_LOCK_STATE();

        INIT_DEBUGOUT("em_detach: begin");

        EM_LOCK(sc);
        sc->in_detach = 1;
        em_stop(sc);
        em_phy_hw_reset(&sc->hw);
        EM_UNLOCK(sc);
#if  __FreeBSD_version < 500000
        ether_ifdetach(&sc->interface_data.ac_if, ETHER_BPF_SUPPORTED);
#else
        ether_ifdetach(&sc->interface_data.ac_if);
#endif
        em_free_pci_resources(sc);
        bus_generic_detach(dev);

        /* Free Transmit Descriptor ring */
        if (sc->tx_desc_base) {
                em_dma_free(sc, &sc->txdma);
                sc->tx_desc_base = NULL;
        }

        /* Free Receive Descriptor ring */
        if (sc->rx_desc_base) {
                em_dma_free(sc, &sc->rxdma);
                sc->rx_desc_base = NULL;
        }

        /* Free the sysctl tree */
        sysctl_ctx_free(&sc->sysctl_ctx);

        /* Remove from the sc list */
        if (em_adapter_list == sc)
                em_adapter_list = sc->next;
        if (sc->next != NULL)
                sc->next->prev = sc->prev;
        if (sc->prev != NULL)
                sc->prev->next = sc->next;

        EM_LOCK_DESTROY(sc);

        ifp->if_flags &= ~(IFF_RUNNING | IFF_OACTIVE);
        ifp->if_timer = 0;

        return(0);
}
#endif /* __FreeBSD__ */

/*********************************************************************
 *
 *  Shutdown entry point
 *
 **********************************************************************/

#ifdef __FreeBSD__
int
em_shutdown(device_t dev)
{
        struct em_softc *sc = device_get_softc(dev);
	EM_LOCK_STATE();

        EM_LOCK(sc);
        em_stop(sc);
        EM_UNLOCK(sc);
        return(0);
}
#endif /* __FreeBSD__ */

a511 1
#ifdef __OpenBSD__
a518 1
#endif /* __OpenBSD__ */
a522 7
#ifdef __FreeBSD__
	case SIOCGIFADDR:
		IOCTL_DEBUGOUT("ioctl rcv'd: SIOCxIFADDR (Get/Set Interface Addr)");
		ether_ioctl(ifp, command, data);
		break;
#endif /* __FreeBSD__ */
#ifdef __OpenBSD__
a536 1
#endif /* __OpenBSD__ */
a569 1
#ifdef __OpenBSD__
a574 1
#endif /* __OpenBSD__ */
a581 3
#ifdef DEVICE_POLLING
				if (!(ifp->if_flags & IFF_POLLING))
#endif
a584 1
#ifdef __OpenBSD__
a586 1
#endif /* __OpenBSD__ */
a592 14
#ifdef __FreeBSD__
	case SIOCSIFCAP:
		IOCTL_DEBUGOUT("ioctl rcv'd: SIOCSIFCAP (Set Capabilities)");
		mask = ifr->ifr_reqcap ^ ifp->if_capenable;
		if (mask & IFCAP_HWCSUM) {
			if (IFCAP_HWCSUM & ifp->if_capenable)
				ifp->if_capenable &= ~IFCAP_HWCSUM;
			else
				ifp->if_capenable |= IFCAP_HWCSUM;
			if (ifp->if_flags & IFF_RUNNING)
				em_init(sc);
		}
		break;
#endif /* __FreeBSD__ */
a695 1
#ifdef __FreeBSD__
a698 1
#endif /* __FreeBSD__ */
a735 11
#ifdef __FreeBSD__
	if (sc->hw.mac_type >= em_82543) {
		if (ifp->if_capenable & IFCAP_TXCSUM)
			ifp->if_hwassist = EM_CHECKSUM_FEATURES;
		else
			ifp->if_hwassist = 0;
	}

	callout_reset(&sc->timer, 2*hz, em_local_timer, sc);
#endif /* __FreeBSD__ */
#ifdef __OpenBSD__
a736 1
#endif
d738 1
a738 10
#ifdef DEVICE_POLLING
        /*
         * Only enable interrupts if we are not polling, make sure
         * they are off otherwise.
         */
        if (ifp->if_flags & IFF_POLLING)
                em_disable_intr(sc);
        else
#endif /* DEVICE_POLLING */
		em_enable_intr(sc);
a757 47

#ifdef DEVICE_POLLING
poll_handler_t em_poll;

void
em_poll_locked(struct ifnet *ifp, enum poll_cmd cmd, int count)
{
        struct em_softc *sc = ifp->if_softc;
        u_int32_t reg_icr;

        mtx_assert(&sc->mtx, MA_OWNED);

        if (cmd == POLL_DEREGISTER) {       /* final call, enable interrupts */
                em_enable_intr(sc);
                return;
        }
        if (cmd == POLL_AND_CHECK_STATUS) {
                reg_icr = E1000_READ_REG(&sc->hw, ICR);
                if (reg_icr & (E1000_ICR_RXSEQ | E1000_ICR_LSC)) {
                        callout_stop(&sc->timer);
                        sc->hw.get_link_status = 1;
                        em_check_for_link(&sc->hw);
                        em_update_link_status(sc);
                        callout_reset(&sc->timer, 2*hz, em_local_timer, sc);
                }
        }
        if (ifp->if_flags & IFF_RUNNING) {
                em_process_receive_interrupts(sc, count);
                em_clean_transmit_interrupts(sc);
        }

        if (ifp->if_flags & IFF_RUNNING && ifp->if_snd.ifq_head != NULL)
                em_start_locked(ifp);
}

void
em_poll(struct ifnet *ifp, enum poll_cmd cmd, int count)
{
        struct em_softc *sc = ifp->if_softc;
	EM_LOCK_STATE();

        EM_LOCK(sc);
        em_poll_locked(ifp, cmd, count);
        EM_UNLOCK(sc);
}
#endif /* DEVICE_POLLING */

a762 4
#ifdef __FreeBSD__
void
#endif
#ifdef __OpenBSD__
a763 1
#endif
a775 14
#ifdef DEVICE_POLLING
        if (ifp->if_flags & IFF_POLLING) {
                EM_UNLOCK(sc);
                return;
        }

        if (ether_poll_register(em_poll, ifp)) {
                em_disable_intr(sc);
                em_poll_locked(ifp, 0, 1);
                EM_UNLOCK(sc);
                return;
        }
#endif /* DEVICE_POLLING */

a778 4
#ifdef __FreeBSD__
		return;
#endif
#ifdef __OpenBSD__
a779 1
#endif
a783 4
#ifdef __FreeBSD__
                callout_stop(&sc->timer);
#endif
#ifdef __OpenBSD__
a784 1
#endif
a787 4
#ifdef __FreeBSD__
                callout_reset(&sc->timer, 2*hz, em_local_timer, sc);
#endif
#ifdef __OpenBSD__
a788 1
#endif
a798 4
#ifdef __FreeBSD__
        if (ifp->if_flags & IFF_RUNNING && ifp->if_snd.ifq_head != NULL)
#endif
#ifdef __OpenBSD__
a799 1
#endif
a802 4
#ifdef __FreeBSD__
	return;
#endif
#ifdef __OpenBSD__
a803 1
#endif
a805 2


a855 3
#if defined(__FreeBSD__) && __FreeBSD_version < 500000
			ifmr->ifm_active |= IFM_1000_TX;
#else
a856 1
#endif
a891 3
#if defined(__FreeBSD__) && __FreeBSD_version < 500000
        case IFM_1000_TX:
#else
a892 1
#endif
a925 15
#ifdef __FreeBSD__
void
em_tx_cb(void *arg, bus_dma_segment_t *seg, int nsegs, bus_size_t mapsize, int error)
{
	struct em_q *q = arg;

	if (error)
		return;
	KASSERT(nsegs <= EM_MAX_SCATTER,
		("Too many DMA segments returned when mapping tx packet"));
	q->nsegs = nsegs;
	bcopy(seg, q->segs, nsegs * sizeof(seg[0]));
}
#endif /* __FreeBSD__ */

d989 4
a992 8
#ifdef __FreeBSD__
	if (ifp->if_hwassist > 0) {
		em_transmit_checksum_setup(sc,	m_head,
					   &txd_upper, &txd_lower);
	} else
#endif /* __FreeBSD__ */
		txd_upper = txd_lower = 0;

a1132 5
#ifdef __FreeBSD__
                                callout_reset(&sc->tx_fifo_timer, 1,
                                        em_82547_move_tail, sc);
#endif
#ifdef __OpenBSD__
a1133 1
#endif
a1289 3
#ifdef __FreeBSD__
	struct ifmultiaddr  *ifma;
#endif
a1291 1
#ifdef __OpenBSD__
a1294 1
#endif /* __OpenBSD__ */
a1306 18

#ifdef __FreeBSD__
#if __FreeBSD_version < 500000
        LIST_FOREACH(ifma, &ifp->if_multiaddrs, ifma_link) {
#else
        TAILQ_FOREACH(ifma, &ifp->if_multiaddrs, ifma_link) {
#endif
                if (ifma->ifma_addr->sa_family != AF_LINK)
                        continue;

                if (mcnt == MAX_NUM_MULTICAST_ADDRESSES) break;

                bcopy(LLADDR((struct sockaddr_dl *)ifma->ifma_addr),
                      &mta[mcnt*ETH_LENGTH_OF_ADDRESS], ETH_LENGTH_OF_ADDRESS);
                mcnt++;
        }
#endif /* __FreeBSD__ */
#ifdef __OpenBSD__
a1319 1
#endif /* __OpenBSD__ */
a1340 1

a1366 4
#ifdef __FreeBSD__
        callout_reset(&sc->timer, 2*hz, em_local_timer, sc);
#endif /* __FreeBSD__ */
#ifdef __OpenBSD__
a1367 1
#endif /* __OpenBSD__ */
a1447 5
#ifdef __FreeBSD__
        callout_stop(&sc->timer);
        callout_stop(&sc->tx_fifo_timer);
#endif /* __FreeBSD__ */
#ifdef __OpenBSD__
a1449 1
#endif /* __OpenBSD__ */
a1452 1

a1458 1

a1550 5
#ifdef __FreeBSD__
                sc->hw.io_base =
                rman_get_start(sc->res_ioport);
#endif
#ifdef __OpenBSD__
a1551 1
#endif
a1658 4
#ifdef __FreeBSD__
em_setup_interface(device_t dev, struct em_softc *sc)
#endif
#ifdef __OpenBSD__
a1659 1
#endif
a1664 4
#ifdef __FreeBSD__
        if_initname(ifp, device_get_name(dev), device_get_unit(dev));
#endif
#ifdef __OpenBSD__
a1665 1
#endif
a1667 3
#ifdef __FreeBSD__
	ifp->if_init =	em_init;
#endif
a1672 4
#ifdef __FreeBSD__
	ifp->if_snd.ifq_maxlen = sc->num_tx_desc - 1;
#endif
#ifdef __OpenBSD__
a1674 1
#endif
d1676 1
a1676 18
#ifdef __FreeBSD__
	if (sc->hw.mac_type >= em_82543) {
		ifp->if_capabilities = IFCAP_HWCSUM;
		ifp->if_capenable = ifp->if_capabilities;
	}

	/*
	 * Tell the upper layer(s) we support long frames.
	 */
	ifp->if_data.ifi_hdrlen = sizeof(struct ether_vlan_header);
#if __FreeBSD_version >= 500000
	ifp->if_capabilities |= IFCAP_VLAN_HWTAGGING | IFCAP_VLAN_MTU;
#endif
#endif /* __FreeBSD__ */

#ifdef __OpenBSD__
	ifp->if_capabilities |= IFCAP_VLAN_MTU;
#endif
a1703 1
#ifdef __OpenBSD__
d1706 1
a1706 1
#endif
a1770 1

a1773 11
#ifdef __FreeBSD__
void
em_dmamap_cb(void *arg, bus_dma_segment_t *segs, int nseg, int error)
{ 
	if (error)
		return;
	*(bus_addr_t*) arg = segs->ds_addr;
	return;
}
#endif /* __FreeBSD__ */

a1779 22
#ifdef __FreeBSD__
	r = bus_dma_tag_create(NULL,			/* parent */
			       PAGE_SIZE, 0,		/* alignment, bounds */
			       BUS_SPACE_MAXADDR,	/* lowaddr */
			       BUS_SPACE_MAXADDR,	/* highaddr */
			       NULL, NULL,		/* filter, filterarg */
			       size,			/* maxsize */
			       1,			/* nsegments */
			       size,			/* maxsegsize */
			       BUS_DMA_ALLOCNOW,	/* flags */
			       NULL,			/* lockfunc */
			       NULL,			/* lockarg */
			       &dma->dma_tag);
	if (r != 0) {
		printf("%s: em_dma_malloc: bus_dma_tag_create failed; "
			"error %u\n", sc->sc_dv.dv_xname, r);
		goto fail_0;
	}

	r = bus_dmamap_create(dma->dma_tag, BUS_DMA_NOWAIT, &dma->dma_map);
#endif /* __FreeBSD__ */
#ifdef __OpenBSD__
a1782 1
#endif /* __OpenBSD__ */
a1845 1

a1877 22
#ifdef __FreeBSD__
	/*
	 * Setup DMA descriptor areas.
	 */
	if (bus_dma_tag_create(NULL,	/* parent */
		    PAGE_SIZE, 0,	/* alignment, bounds */
		    BUS_SPACE_MAXADDR,       /* lowaddr */
		    BUS_SPACE_MAXADDR,       /* highaddr */
		    NULL, NULL,              /* filter, filterarg */
		    MCLBYTES * 8,            /* maxsize */
		    EM_MAX_SCATTER,          /* nsegments */
		    MCLBYTES * 8,            /* maxsegsize */
		    BUS_DMA_ALLOCNOW,        /* flags */
		    NULL,                    /* lockfunc */
		    NULL,                    /* lockarg */
		    &sc->txtag)) {
		printf("%s: Unable to allocate TX DMA tag\n", sc->sc_dv.dv_xname);
		return (ENOMEM);
	}

#endif /* __FreeBSD__ */
#ifdef __OpenBSD__
a1878 1
#endif
d2012 1
a2012 1
#ifdef __FreeBSD__
d2091 1
a2091 1
#endif /* __FreeBSD__ */
a2250 19
#ifdef __FreeBSD__
	error = bus_dma_tag_create(NULL,                /* parent */
				PAGE_SIZE, 0,            /* alignment, bounds */
				BUS_SPACE_MAXADDR,       /* lowaddr */
				BUS_SPACE_MAXADDR,       /* highaddr */
				NULL, NULL,              /* filter, filterarg */
				MCLBYTES,                /* maxsize */
				1,                       /* nsegments */
				MCLBYTES,                /* maxsegsize */
				BUS_DMA_ALLOCNOW,        /* flags */
				&sc->rxtag);
	if (error != 0) {
		printf("%s: em_allocate_receive_structures: "
			"bus_dma_tag_create failed; error %u\n",
			sc->sc_dv.dv_xname, error);
		goto fail_0;
	}
#endif /* __FreeBSD__ */
#ifdef __OpenBSD__
a2251 1
#endif
d2314 1
a2314 1
#ifdef __FreeBSD__
a2341 4
#ifdef __FreeBSD__
	bus_addr = sc->rxdma.dma_paddr;
#endif
#ifdef __OpenBSD__
a2342 1
#endif
a2379 1
#ifdef __FreeBSD__
d2381 2
a2382 2
	if ((sc->hw.mac_type >= em_82543) && 
	    (ifp->if_capenable & IFCAP_RXCSUM)) {
d2387 1
a2387 1
#endif /* __FreeBSD__ */
a2445 5
#ifdef __FreeBSD__
#if __FreeBSD_version < 500000
	struct ether_header *eh;
#endif
#endif /* __FreeBSD__ */
a2603 1
#ifdef __OpenBSD__
a2614 31
#endif /* __OpenBSD__ */
#ifdef __FreeBSD__
#if __FreeBSD_version < 500000
				eh = mtod(sc->fmp, struct ether_header *);
				/* Remove ethernet header from mbuf */
				m_adj(sc->fmp, sizeof(struct ether_header));
                                em_receive_checksum(sc, current_desc,
                                                    sc->fmp);
                                if (current_desc->status & E1000_RXD_STAT_VP)
                                        VLAN_INPUT_TAG(eh, sc->fmp,
                                                       (current_desc->special &
                                                        E1000_RXD_SPC_VLAN_MASK));
                                else
                                        ether_input(ifp, eh, sc->fmp);
#else

                                em_receive_checksum(sc, current_desc,
                                                    sc->fmp);
                                if (current_desc->status & E1000_RXD_STAT_VP)
                                        VLAN_INPUT_TAG(ifp, sc->fmp,
                                                       (current_desc->special &
                                                        E1000_RXD_SPC_VLAN_MASK),
                                                       sc->fmp = NULL);

                                if (sc->fmp != NULL) {
                                        EM_UNLOCK(sc);
                                        (*ifp->if_input)(ifp, sc->fmp);
                                        EM_LOCK(sc);
                                }
#endif
#endif /* __FreeBSD__ */
a2655 33
#ifdef __FreeBSD__
	/* 82543 or newer only */
	if ((sc->hw.mac_type < em_82543) ||
	    /* Ignore Checksum bit is set */
	    (rx_desc->status & E1000_RXD_STAT_IXSM)) {
		mp->m_pkthdr.csum_flags = 0;
		return;
	}

	if (rx_desc->status & E1000_RXD_STAT_IPCS) {
		/* Did it pass? */
		if (!(rx_desc->errors & E1000_RXD_ERR_IPE)) {
			/* IP Checksum Good */
			mp->m_pkthdr.csum_flags = CSUM_IP_CHECKED;
			mp->m_pkthdr.csum_flags |= CSUM_IP_VALID;

		} else {
			mp->m_pkthdr.csum_flags = 0;
		}
	}

	if (rx_desc->status & E1000_RXD_STAT_TCPCS) {
		/* Did it pass? */	  
		if (!(rx_desc->errors & E1000_RXD_ERR_TCPE)) {
			mp->m_pkthdr.csum_flags |= 
			(CSUM_DATA_VALID | CSUM_PSEUDO_HDR);
			mp->m_pkthdr.csum_data = htons(0xffff);
		}
	}

	return;
#endif /* __FreeBSD__ */
#ifdef __OpenBSD__
a2669 1
#endif /* __OpenBSD__ */
a2769 15
#ifdef __FreeBSD__
int32_t
em_io_read(struct em_hw *hw, unsigned long port)
{
        return(inl(port));
}

void
em_io_write(struct em_hw *hw, unsigned long port, uint32_t value)
{
        outl(port, value);
        return;
}
#endif /* __FreeBSD__ */

a2910 5
#ifndef __OpenBSD__
	ifp->if_ibytes = sc->stats.gorcl;
	ifp->if_obytes = sc->stats.gotcl;
	ifp->if_imcasts = sc->stats.mprc;
#endif
a2926 1

a3024 106

#ifdef __FreeBSD__
int
em_sysctl_debug_info(SYSCTL_HANDLER_ARGS)
{
	int error;
	int result;
	struct em_softc *sc;

	result = -1;
	error = sysctl_handle_int(oidp, &result, 0, req);

	if (error || !req->newptr)
		return (error);

	if (result == 1) {
		sc = (struct em_softc *)arg1;
		em_print_debug_info(sc);
	}

	return error;
}


int
em_sysctl_stats(SYSCTL_HANDLER_ARGS)
{
	int error;
	int result;
	struct em_softc *sc;

	result = -1;
	error = sysctl_handle_int(oidp, &result, 0, req);

	if (error || !req->newptr)
		return (error);

	if (result == 1) {
		sc = (struct em_softc *)arg1;
		em_print_hw_stats(sc);
	}

	return error;
}

int
em_sysctl_int_delay(SYSCTL_HANDLER_ARGS)
{
	struct em_int_delay_info *info;
	struct em_softc *sc;
	u_int32_t regval;
	int error;
	int usecs;
	int ticks;
	int s;

	info = (struct em_int_delay_info *)arg1;
	sc = info->sc;
	usecs = info->value;
	error = sysctl_handle_int(oidp, &usecs, 0, req);
	if (error != 0 || req->newptr == NULL)
		return error;
	if (usecs < 0 || usecs > E1000_TICKS_TO_USECS(65535))
		return EINVAL;
	info->value = usecs;
	ticks = E1000_USECS_TO_TICKS(usecs);

	s = splimp();
	regval = E1000_READ_OFFSET(&sc->hw, info->offset);
	regval = (regval & ~0xffff) | (ticks & 0xffff);
	/* Handle a few special cases. */
	switch (info->offset) {
	case E1000_RDTR:
	case E1000_82542_RDTR:
		regval |= E1000_RDT_FPDB;
		break;
	case E1000_TIDV:
	case E1000_82542_TIDV:
		if (ticks == 0) {
			sc->txd_cmd &= ~E1000_TXD_CMD_IDE;
			/* Don't write 0 into the TIDV register. */
			regval++;
		} else
			sc->txd_cmd |= E1000_TXD_CMD_IDE;
		break;
	}
	E1000_WRITE_OFFSET(&sc->hw, info->offset, regval);
	splx(s);
	return 0;
}

void
em_add_int_delay_sysctl(struct em_softc *sc, const char *name,
    const char *description, struct em_int_delay_info *info,
    int offset, int value)
{
	info->sc = sc;
	info->offset = offset;
	info->value = value;
	SYSCTL_ADD_PROC(&sc->sysctl_ctx,
	    SYSCTL_CHILDREN(sc->sysctl_tree),
	    OID_AUTO, name, CTLTYPE_INT|CTLFLAG_RW,
	    info, 0, em_sysctl_int_delay, "I", description);
}
#endif /* __FreeBSD__ */

@


1.39
log
@don't account packet's twice; from joel@@; ok deraadt@@, henning@@
@
text
@d35 1
a35 1
/* $OpenBSD: if_em.c,v 1.38 2005/02/07 15:03:50 mcbride Exp $ */
d305 1
a305 1
        "em", em_methods, sizeof(struct em_softc ),
d442 1
a442 1
	bzero(sc, sizeof(struct em_softc ));
d716 1
a716 1
        struct em_softc * sc = device_get_softc(dev);
d860 1
a860 1
	struct em_softc * sc = ifp->if_softc;
d993 1
a993 1
	struct em_softc * sc;
d1004 3
a1006 2
	if (em_check_for_link(&sc->hw))
	        printf("%s: watchdog timeout -- resetting\n", sc->sc_dv.dv_xname);
d1154 1
a1154 1
        struct em_softc * sc = arg;
d1315 1
a1315 1
	struct em_softc * sc= ifp->if_softc;
d1380 1
a1380 1
	struct em_softc * sc = ifp->if_softc;
d1762 1
a1762 1
em_set_promisc(struct em_softc * sc)
d1794 1
a1794 1
em_disable_promisc(struct em_softc * sc)
d1817 1
a1817 1
em_set_multi(struct em_softc * sc)
d1908 1
a1908 1
	struct em_softc * sc = arg;
d1935 1
a1935 1
em_print_link_status(struct em_softc * sc)
d1963 1
a1963 1
em_update_link_status(struct em_softc * sc)
d2001 1
a2001 1
	struct em_softc * sc = arg;
d2034 1
a2034 1
em_identify_hardware(struct em_softc * sc)
d2078 1
a2078 1
em_allocate_pci_resources(struct em_softc * sc)
d2152 1
a2152 1
em_free_pci_resources(struct em_softc* sc)
d2182 1
a2182 1
em_hardware_init(struct em_softc * sc)
d2235 1
a2235 1
em_setup_interface(device_t dev, struct em_softc * sc)
d2238 1
a2238 1
em_setup_interface(struct em_softc * sc)
d2500 1
a2500 1
em_allocate_transmit_structures(struct em_softc * sc)
d2523 1
a2523 1
em_setup_transmit_structures(struct em_softc* sc)
d2574 1
a2574 1
em_initialize_transmit_unit(struct em_softc * sc)
d2646 1
a2646 1
em_free_transmit_structures(struct em_softc* sc)
d2684 1
a2684 1
em_transmit_checksum_setup(struct em_softc * sc,
d2771 1
a2771 1
em_clean_transmit_interrupts(struct em_softc* sc)
d2904 1
a2904 1
em_allocate_receive_structures(struct em_softc* sc)
d2982 1
a2982 1
em_setup_receive_structures(struct em_softc * sc)
d3001 1
a3001 1
em_initialize_receive_unit(struct em_softc * sc)
d3097 1
a3097 1
em_free_receive_structures(struct em_softc * sc)
d3138 1
a3138 1
em_process_receive_interrupts(struct em_softc* sc, int count)
d3441 1
a3441 1
em_enable_vlans(struct em_softc * sc)
d3455 1
a3455 1
em_enable_intr(struct em_softc* sc)
@


1.39.2.1
log
@MFC:
Fix by markus@@

update the maxium sendqueue size on ifconfig up; this should fix problems
where IP cannot send packets larger then 11*mtu (e.g for large UDP/NFS
packets)

ok deraadt@@ markus@@
@
text
@d35 1
a35 1
/* $OpenBSD: if_em.c,v 1.39 2005/03/16 11:59:09 markus Exp $ */
a1045 1
	IFQ_SET_MAXLEN(&ifp->if_snd, sc->num_tx_desc - 1);
@


1.38
log
@em(4) doesn't use the mii layer, call if_link_state_change() directly.
- link state changes for em now show up on the routing socket
- carp failover now occurs right away when the link goes down, rather
  than waiting for several ip_output() errors to occur.

ok brad@@ mpf@@
@
text
@d35 1
a35 1
/* $OpenBSD: if_em.c,v 1.37 2005/01/17 03:19:29 brad Exp $ */
d3692 1
d3696 1
@


1.37
log
@add id for Intel 82546GB dual port PCI-E adapter.

From FreeBSD
@
text
@d35 1
a35 1
/* $OpenBSD: if_em.c,v 1.36 2005/01/15 18:44:28 brad Exp $ */
d1964 1
d1972 2
d1980 2
@


1.36
log
@rev 1.56

Corrected a workaround that should only be applied to one adapter.
Workaround was causing device hangs when incorrectly applied to
other adapters.

From FreeBSD
@
text
@d35 1
a35 1
/* $OpenBSD: if_em.c,v 1.35 2005/01/01 05:17:32 brad Exp $ */
d143 1
d194 1
@


1.35
log
@my -> may
@
text
@d35 1
a35 1
/* $OpenBSD: if_em.c,v 1.34 2004/12/08 15:41:46 markus Exp $ */
d3456 15
a3470 2
	E1000_WRITE_REG(&sc->hw, IMC, 
			(0xffffffff & ~E1000_IMC_RXSEQ));
@


1.34
log
@powerhook: em_init on resume
@
text
@d35 1
a35 1
/* $OpenBSD: if_em.c,v 1.33 2004/12/08 04:28:40 brad Exp $ */
d1419 1
a1419 1
        /* As the speed/duplex settings my have changed we need to
@


1.33
log
@use ETHER_MAX_LEN
@
text
@d35 1
a35 1
/* $OpenBSD: if_em.c,v 1.32 2004/11/16 14:39:14 brad Exp $ */
d211 1
d665 1
d684 15
@


1.32
log
@- Added fix for 82547 which corrects an issue with Jumbo frames larger than 10k.
- Corrected TBI workaround.
- Corrected incorrect LED operation issues.

From FreeBSD

ok deraadt@@
@
text
@d35 1
a35 1
/* $OpenBSD: if_em.c,v 1.31 2004/10/01 19:08:04 grange Exp $ */
d549 1
a549 1
	    ETHERMTU + ETHER_HDR_LEN + ETHER_CRC_LEN;
@


1.31
log
@Fix off-by-BAR in IO space finding.

ok jason@@
@
text
@d34 2
a35 2
/*$FreeBSD: if_em.c,v 1.38 2004/03/17 17:50:31 njl Exp $*/
/* $OpenBSD: if_em.c,v 1.30 2004/09/30 21:53:15 jason Exp $ */
d94 1
a94 1
char em_driver_version[] = "1.7.25";
d957 1
a957 1
		IOCTL_DEBUGOUT1("ioctl received: UNKNOWN (0x%x)\n", (int)command);
d1012 2
d1028 29
a1426 4
#define EM_FIFO_HDR		 0x10
#define EM_82547_PKT_THRESH	 0x3e0
#define EM_82547_TX_FIFO_SIZE	 0x2800
#define EM_82547_TX_FIFO_BEGIN	 0xf00
d1637 1
a1637 1
				sc->tx_fifo_wrk++;
d1674 1
a1674 1
		fifo_space = EM_82547_TX_FIFO_SIZE - sc->tx_fifo_head;
d1696 2
a1697 2
	if (sc->tx_fifo_head >= EM_82547_TX_FIFO_SIZE) {
		sc->tx_fifo_head -= EM_82547_TX_FIFO_SIZE;
d1722 4
a1725 4
		E1000_WRITE_REG(&sc->hw, TDFT, EM_82547_TX_FIFO_BEGIN);
		E1000_WRITE_REG(&sc->hw, TDFH, EM_82547_TX_FIFO_BEGIN);
		E1000_WRITE_REG(&sc->hw, TDFTS, EM_82547_TX_FIFO_BEGIN);
		E1000_WRITE_REG(&sc->hw, TDFHS, EM_82547_TX_FIFO_BEGIN);
d1732 1
a1732 1
		sc->tx_fifo_reset++;
d1746 1
d1750 1
d1755 9
d1784 1
d3666 1
a3666 1
	sc->stats.rlec + sc->stats.rnbc + 
d3689 4
d3707 2
a3708 2
		(long long)sc->tx_fifo_wrk,
		(long long)sc->tx_fifo_reset);
@


1.30
log
@when trying to locate the io register we must jump over memory BARs, which
are variable size.  Do it correctly: jump by 8 for 64 bit BARs.
@
text
@d35 1
a35 1
/* $OpenBSD: if_em.c,v 1.29 2004/09/30 21:19:31 jason Exp $ */
d2036 1
a2036 1
		for (rid = PCI_MAPREG_START; rid <= PCI_MAPREG_END;) {
@


1.29
log
@magic constants... bad... this isn't linux.
@
text
@d35 1
a35 1
/* $OpenBSD: if_em.c,v 1.28 2004/09/23 17:45:16 brad Exp $ */
d2016 1
a2016 1
	int		i, val, rid;
d2036 1
a2036 2
		rid = EM_MMBA;
		for (i = 0; i < 5; i++) {
d2043 3
@


1.28
log
@don't need to set ifp->if_mtu or ifp->if_output in each driver,
{ether,atm,fddi}_ifattach already does this.

ok mcbride@@ markus@@ henning@@
@
text
@d35 1
a35 1
/* $OpenBSD: if_em.c,v 1.27 2004/09/16 09:37:14 mcbride Exp $ */
d2039 1
a2039 1
			if (val & 0x00000001) {
@


1.27
log
@Use a sane value for maxsegsz, fixes this card for alpha (PR 3920).

ok miod@@
@
text
@d35 1
a35 1
/* $OpenBSD: if_em.c,v 1.26 2004/09/08 23:01:55 deraadt Exp $ */
a2185 2
	ifp->if_mtu = ETHERMTU;
	ifp->if_output = ether_output;
@


1.27.2.1
log
@MFC:
Fix by markus@@

update the maxium sendqueue size on ifconfig up; this should fix problems
where IP cannot send packets larger then 11*mtu (e.g for large UDP/NFS
packets)

ok deraadt@@ markus@@
@
text
@d35 1
a35 1
/* $OpenBSD: if_em.c,v 1.27 2004/09/16 09:37:14 mcbride Exp $ */
d1025 1
a1025 1
	IFQ_SET_MAXLEN(&ifp->if_snd, sc->num_tx_desc - 1);
@


1.26
log
@typo, wrong type; cd@@sentia.nl
@
text
@d35 1
a35 1
/* $OpenBSD: if_em.c,v 1.25 2004/09/06 08:49:19 markus Exp $ */
d1443 1
a1443 1
	    0, 0, BUS_DMA_NOWAIT, &q.map)) {
@


1.25
log
@add INTEL PRO_1000_GT; ok deraadt
@
text
@d35 1
a35 1
/* $OpenBSD: if_em.c,v 1.24 2004/07/14 01:25:31 deraadt Exp $ */
d586 1
a586 1
	    EM_MAX_RXD * sizeof(struct em_tx_desc));
@


1.24
log
@allocate the full ring set, even if we are currently running with a reduced set
@
text
@d35 1
a35 1
/* $OpenBSD: if_em.c,v 1.23 2004/06/18 20:42:34 mcbride Exp $ */
d142 1
d192 2
a193 1
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82546EB_SERDES }
@


1.23
log
@On architectures which have strict alignment, shift the entire mbuf chain by
ETHER_ALIGN bytes when jumbo packets are enabled (mtu > ETHERMTU).

ok henric@@ (slightly different diff)
@
text
@d35 1
a35 1
/* $OpenBSD: if_em.c,v 1.22 2004/06/18 20:31:31 mcbride Exp $ */
d570 3
a572 2
	tsize = EM_ROUNDUP(sc->num_tx_desc *
			   sizeof(struct em_tx_desc), 4096);
d583 3
a585 2
	rsize = EM_ROUNDUP(sc->num_rx_desc *
			   sizeof(struct em_rx_desc), 4096);
@


1.22
log
@Pass MAX_JUMBO_FRAME_SIZE as the size argument of bus_dmamap_create(),
fixes sending of jumbo frames.

ok henric@@ drahn@@
@
text
@d35 1
a35 1
/* $OpenBSD: if_em.c,v 1.21 2004/05/04 06:00:51 henric Exp $ */
d3164 49
d3214 1
a3214 1
				mp->m_pkthdr.len = len;
d3230 1
a3230 1
                                sc->fmp->m_pkthdr.len += len;
@


1.21
log
@Sort out the various Intel Pro/1000 IDs.
From Marco Peereboom.
@
text
@d35 1
a35 1
/* $OpenBSD: if_em.c,v 1.20 2004/04/26 07:27:52 deraadt Exp $ */
d1438 2
a1439 2
	if (bus_dmamap_create(sc->txtag, MCLBYTES, 32, 0, 0, BUS_DMA_NOWAIT,
            &q.map)) {
@


1.20
log
@this driver had 256 clusters for receive buffers.  move to 512, to increase
performance, if the interface is up.  at boot time, allocate only 12 though
... though we note that em_stop() frees them all.  perhaps some are used to
talk to other parts of the engine though at runtime... tested by mcbride and
beck
@
text
@d35 1
a35 1
/* $OpenBSD: if_em.c,v 1.19 2004/04/18 04:15:00 henric Exp $ */
d173 1
a173 1
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82541ER2 },
d179 1
a179 1
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82547EI_LOM },
d185 7
a191 7
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82547GI },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82541GI },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82541GI_MOBILE },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82541ER },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82546GB_COPPER },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82546GB_FIBER },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82546GB_SERDES }
@


1.19
log
@Sync with FreeBSD's "em".
@
text
@d35 1
a35 1
/* $OpenBSD: if_em.c,v 1.16 2003/12/09 23:41:35 henning Exp $ */
d516 2
a517 2
	sc->num_tx_desc = EM_MAX_TXD;
	sc->num_rx_desc = EM_MAX_RXD;
d1006 1
a1006 1
	struct ifnet   *ifp;
d1014 9
a1061 1
	ifp = &sc->interface_data.ac_if;
@


1.18
log
@Add \n to some error messages to make dmesg looks better; ok deraadt@@
@
text
@d34 2
a35 2
/*$FreeBSD: if_em.c,v 1.26 2003/06/05 17:51:37 pdeuskar Exp $*/
/* $OpenBSD: if_em.c,v 1.17 2004/02/12 21:21:06 markus Exp $ */
a77 6
#ifdef DEBUG
#define EM_KASSERT(exp,msg)        do { if (!(exp)) panic msg; } while (0)
#else
#define EM_KASSERT(exp,msg)
#endif

d94 55
a148 1
char em_driver_version[] = "1.6.6";
d150 4
d155 1
d173 1
d179 1
a181 3
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82546GB_COPPER },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82546GB_FIBER },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82546GB_SERDES },
d188 4
a191 1
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82541ER }
d193 1
d198 8
a207 5

#if 0
int  em_detach(void *);
int  em_shutdown(void *);
#endif
d209 1
d211 1
d215 1
d224 4
d229 1
d255 1
d264 2
a265 1
void em_82547_move_tail(void *);
d271 13
d289 21
d317 20
d347 46
d401 1
d413 7
d424 2
a425 5
#if 0
	pci_chipset_tag_t pc = pa->pa_pc;
#endif
	struct em_softc *sc = (struct em_softc *)self;
	int		s;
a429 1
	s = splimp();
a434 1
		splx(s);
d441 1
d444 3
d448 1
d481 2
a482 2
	callout_handle_init(&sc->timer_handle);
	callout_handle_init(&sc->tx_fifo_timer_handle);
d485 1
d488 1
d493 22
a517 4
	sc->tx_int_delay = EM_TIDV;
	sc->tx_abs_int_delay = EM_TADV;
	sc->rx_int_delay = EM_RDTR;
	sc->rx_abs_int_delay = EM_RADV;
d535 1
d537 5
a618 2
	printf(", address: %s\n", ether_sprintf(sc->interface_data.ac_enaddr));

d629 12
a640 3
	if (sc->link_active == 1) {
		em_get_speed_and_duplex(&sc->hw, &sc->link_speed, 
					&sc->link_duplex);
d643 12
d656 4
a659 1
	splx(s);
d661 1
d673 2
a675 3
/*err_sysctl:*/
	splx(s);
	return;
d688 1
d691 1
a691 1
em_detach(void* arg)
d693 30
a722 3
	struct em_softc *sc = arg;
	struct ifnet   *ifp = &sc->interface_data.ac_if;
	int		s;
d724 2
a725 2
	INIT_DEBUGOUT("em_detach: begin");
	s = splimp();
d727 7
a733 8
	em_stop(sc);
	em_phy_hw_reset(&sc->hw);
#if __FreeBSD_version < 500000
	ether_ifdetach(&sc->interface_data.ac_if, ETHER_BPF_SUPPORTED);
#else
	ether_ifdetach(&sc->interface_data.ac_if);
#endif
	em_free_pci_resources(sc);
d735 1
a735 19
	/* Free Transmit Descriptor ring */
	if (sc->tx_desc_base) {
		em_dma_free(sc, &sc->txdma);
		sc->tx_desc_base = NULL;
	}

	/* Free Receive Descriptor ring */
	if (sc->rx_desc_base) {
		em_dma_free(sc, &sc->rxdma);
		sc->rx_desc_base = NULL;
	}

	/* Remove from the adapter list */
	if (em_adapter_list == sc)
		em_adapter_list = sc->next;
	if (sc->next != NULL)
		sc->next->prev = sc->prev;
	if (sc->prev != NULL)
		sc->prev->next = sc->next;
d737 2
a738 2
	ifp->if_flags &= ~(IFF_RUNNING | IFF_OACTIVE);
	ifp->if_timer = 0;
d740 1
a740 2
	splx(s);
	return(0);
d742 1
d750 1
d752 1
a752 1
em_shutdown(void* arg)
d754 7
a760 3
	struct em_softc *sc = arg;
	em_stop(sc);
	return(0);
d762 1
a763 1
#endif /* __FreeBSD__ */
d776 1
a776 1
em_start(struct ifnet *ifp)
a777 1
	int		s;
d781 2
a785 2
	s = splimp();	   

d808 12
a819 1
	splx(s);
d835 1
a835 1
	int		s, error = 0;
a836 1
	struct ifaddr  *ifa = (struct ifaddr *)data;
d838 1
d840 5
a844 1
	s = splimp();
d846 1
a846 2
	if ((error = ether_ioctl(ifp, &sc->interface_data, command, data)) > 0) {
		splx(s);
d848 2
a849 1
	}
d859 1
d874 1
d880 1
d884 2
a885 1
			em_init(sc);
d890 1
d892 3
a894 2
			if (!(ifp->if_flags & IFF_RUNNING))
				em_init(sc);
d903 1
d908 1
d914 1
d916 1
d923 1
a923 1
				if (!(ifp->if_ipending & IFF_POLLING))
d926 1
d928 1
d931 1
d953 1
a953 1
		IOCTL_DEBUGOUT1("ioctl received: UNKNOWN (0x%d)\n", (int)command);
a956 1
	splx(s);
d981 2
a982 1
	printf("%s: watchdog timeout -- resetting\n", sc->sc_dv.dv_xname);
a985 1
	em_stop(sc);
d1004 1
a1004 1
em_init(void *arg)
a1005 1
	int		s;
a1006 1
	struct em_softc * sc = arg;
d1010 1
a1010 1
	s = splimp();
d1014 6
a1023 1
		splx(s);
a1033 1
		splx(s);
a1045 1
		splx(s);
d1050 3
d1064 2
d1067 1
a1067 1

d1069 1
d1076 1
a1076 1
        if (ifp->if_ipending & IFF_POLLING)
d1082 2
a1083 2
	/* Don't reset the phy next time init gets called */
	sc->hw.phy_reset_disable = TRUE;
a1084 1
	splx(s);
d1088 12
d1102 32
a1133 1
static poll_handler_t em_poll;
d1135 1
a1135 1
static void
d1138 2
a1139 2
	struct em_softc *sc = ifp->if_softc;
	u_int32_t reg_icr;
d1141 3
a1143 21
	if (cmd == POLL_DEREGISTER) {	    /* final call, enable interrupts */
		em_enable_intr(sc);
		return;
	}
	if (cmd == POLL_AND_CHECK_STATUS) {
		reg_icr = E1000_READ_REG(&sc->hw, ICR);
		if (reg_icr & (E1000_ICR_RXSEQ | E1000_ICR_LSC)) {
			untimeout(em_local_timer, sc, sc->timer_handle);
			sc->hw.get_link_status = 1;
			em_check_for_link(&sc->hw);
			em_print_link_status(sc);
			sc->timer_handle = timeout(em_local_timer, sc, 2*hz);
		}
	}
	if (ifp->if_flags & IFF_RUNNING) {
		em_process_receive_interrupts(sc, count);
		em_clean_transmit_interrupts(sc);
	}

	if (ifp->if_flags & IFF_RUNNING && ifp->if_snd.ifq_head != NULL)
		em_start(ifp);
d1152 4
d1157 1
d1163 4
a1166 1
	struct em_softc *sc = arg;
d1171 4
a1174 2
	if (ifp->if_ipending & IFF_POLLING)
		return;
d1176 6
a1181 5
	if (ether_poll_register(em_poll, ifp)) {
		em_disable_intr(sc);
		em_poll(ifp, 0, 1);
		return;
	}
d1183 1
d1186 5
d1192 1
d1197 4
d1202 1
d1205 5
a1209 1
		em_print_link_status(sc);
d1211 1
d1222 4
d1227 2
a1228 1
		em_start(ifp);
d1230 5
d1236 1
d1291 3
d1295 1
d1331 5
a1335 1
	case IFM_1000_T:
d1359 4
a1362 4
	/* As the speed/duplex settings my have changed we need to
	 * reset the PHY.
	 */
	sc->hw.phy_reset_disable = FALSE;
d1377 1
a1377 1
	EM_KASSERT(nsegs <= EM_MAX_SCATTER,
d1398 1
a1398 1
	u_int32_t	txd_lower;
d1400 6
d1431 1
a1431 1
	    &q.map)) {
d1469 4
d1474 40
a1513 7
		tx_buffer = &sc->tx_buffer_area[i];
		current_tx_desc = &sc->tx_desc_base[i];

		current_tx_desc->buffer_addr = htole64(q.map->dm_segs[j].ds_addr);
		current_tx_desc->lower.data = htole32(
		    sc->txd_cmd | txd_lower | q.map->dm_segs[j].ds_len);
		current_tx_desc->upper.data = htole32(txd_upper);
d1515 2
a1516 2
		if (++i == sc->num_tx_desc)
			i = 0;
d1518 2
a1519 1
		tx_buffer->m_head = NULL;
a1521 1
	sc->num_tx_desc_avail -= q.map->dm_nsegs;
d1523 6
d1556 1
a1556 1
		em_82547_move_tail(sc);
d1572 1
a1572 1
 * in this case. We do that only when FIFO is queiced.
d1576 1
a1576 1
em_82547_move_tail(void *arg)
a1577 2
	int s;
	struct em_softc *sc = arg;
d1584 2
a1585 1
	s = splimp();
d1599 5
d1605 2
a1606 7
				splx(s);
				return;
			}
			else {
				E1000_WRITE_REG(&sc->hw, TDT, hw_tdt);
				em_82547_update_fifo_head(sc, length);
				length = 0;
d1608 3
a1612 1
	splx(s);
d1616 11
d1750 6
d1759 1
a1759 2
	int mcnt = 0;
	struct ifnet *ifp = &sc->interface_data.ac_if;
d1773 17
d1803 1
d1810 1
a1810 1
		em_mc_addr_list_update(&sc->hw, mta, mcnt, 0);
a1835 1
	int s;
d1838 2
d1842 1
a1842 1
	s = splimp();
d1845 1
a1845 1
	em_print_link_status(sc);
d1852 4
d1857 1
d1859 1
a1859 1
	splx(s);
d1866 45
a1910 15
	if (E1000_READ_REG(&sc->hw, STATUS) & E1000_STATUS_LU) {
		if (sc->link_active == 0) {
			em_get_speed_and_duplex(&sc->hw, 
						&sc->link_speed, 
						&sc->link_duplex);
			sc->link_active = 1;
			sc->smartspeed = 0;
		}
	} else {
		if (sc->link_active == 1) {
			sc->link_speed = 0;
			sc->link_duplex = 0;
			sc->link_active = 0;
		}
	}
a1911 1
	return;
d1928 3
a1930 1
	INIT_DEBUGOUT("em_stop: begin\n");
d1933 5
d1940 1
d1992 6
d2012 1
a2012 1
		printf(": mmba isn't memory\n");
d2041 8
d2106 1
d2156 4
d2161 1
d2167 7
d2185 4
d2191 1
a2192 2
	strlcpy(ifp->if_xname, sc->sc_dv.dv_xname, IFNAMSIZ);
	
d2202 1
a2202 1
	ifp->if_data.ifi_hdrlen = sizeof(struct ehter_vlan_header);
d2238 1
d2241 1
a2241 1

a2309 1

d2337 2
d2348 1
d2352 1
a2352 1

d2399 1
a2399 1
	/* bus_dma_tag_destroy(dma->dma_tag); */
d2413 1
a2413 1
	/* bus_dma_tag_destroy(dma->dma_tag); */
d2462 2
d2470 1
d2472 1
d2504 1
d2540 1
a2540 1
	E1000_WRITE_REG(&sc->hw, TIDV, sc->tx_int_delay);
d2542 2
a2543 1
		E1000_WRITE_REG(&sc->hw, TADV, sc->tx_abs_int_delay);
d2558 1
a2558 1
	if (sc->tx_int_delay > 0)
a2592 1
#ifdef __FreeBSD__
a2593 1
#endif
a2696 1
	int s;
d2702 2
a2706 1
	s = splimp();
a2755 1
	splx(s);
d2863 1
d2865 1
d2892 1
a2892 1
	/* bus_dma_tag_destroy(sc->rxtag); */
d2934 1
d2942 1
a2942 1
			sc->rx_int_delay | E1000_RDT_FPDB);
d2945 2
a2946 1
		E1000_WRITE_REG(&sc->hw, RADV, sc->rx_abs_int_delay);
d2956 4
d2961 1
d3045 1
a3045 1
		/* bus_dma_tag_destroy(sc->rxtag); */
d3067 1
d3070 1
d3073 1
a3073 1
	u_int16_t	    len, desc_len;
d3079 2
d3101 1
d3106 7
a3112 1
			len = desc_len - ETHER_CRC_LEN;
d3134 1
a3134 1
				len--;
d3163 11
a3173 3
				sc->lmp->m_next = mp;
				sc->lmp = sc->lmp->m_next;
				sc->fmp->m_pkthdr.len += len;
d3180 1
d3189 4
a3192 1

d3194 1
d3198 23
d3222 1
a3222 14
				em_receive_checksum(sc, current_desc,
						sc->fmp);

#ifdef __FreeBSD__
				if (current_desc->status & E1000_RXD_STAT_VP)
					VLAN_INPUT_TAG(eh, sc->fmp, 
					    (letoh16(current_desc->special) &
					    E1000_RXD_SPC_VLAN_MASK));
				else
					ether_input(ifp, eh, sc->fmp);
#else /* __FreeBSD__ */
				ether_input_mbuf(ifp, sc->fmp);
#endif /* !__FreeBSD__ */

d3295 2
a3296 1
#else /* __FreeBSD__ */
d3311 1
a3311 1
#endif /* __FreeBSD__ */
d3315 2
a3316 1
void em_enable_vlans(struct em_softc * sc)
d3399 3
a3401 2
uint32_t
em_io_read(struct em_hw *hw, uint32_t port)
d3403 1
a3403 2
	return bus_space_read_4(((struct em_osdep *)(hw)->back)->em_iobtag,
		((struct em_osdep *)(hw)->back)->em_iobhandle, port);
d3407 1
a3407 1
em_io_write(struct em_hw *hw, uint32_t port, uint32_t value)
d3409 56
a3464 4
	bus_space_write_4(((struct em_osdep *)(hw)->back)->em_iobtag,
			((struct em_osdep *)(hw)->back)->em_iobhandle, port,
			value);
	return;
d3477 5
a3482 1
	sc->stats.symerrs += E1000_READ_REG(&sc->hw, SYMERRS);
a3490 1
	sc->stats.sec += E1000_READ_REG(&sc->hw, SEC);
d3586 9
d3608 1
a3608 1
	printf("%s: Num Tx Descriptors avail = %ld\n", unit,
d3712 60
@


1.17
log
@don't reset the PHY when IPs are configured; from freebsd revision 1.16
avoids hang when using gigabit copper; ok henric@@, beck@@
@
text
@d35 1
a35 1
/* $OpenBSD: if_em.c,v 1.16 2003/12/09 23:41:35 henning Exp $ */
d1536 1
a1536 1
		printf(": mmba isn't memory");
d1542 1
a1542 1
		printf(": can't find mem space");
d1562 1
a1562 1
			printf(": can't find io space");
@


1.16
log
@match a couple more models
ok deraadt@@
@
text
@d35 1
a35 1
/* $OpenBSD: if_em.c,v 1.15 2003/12/04 23:30:15 henning Exp $ */
d810 3
d1015 5
@


1.15
log
@match new ones, ok theo
@
text
@d35 1
a35 1
/* $OpenBSD: if_em.c,v 1.14 2003/12/04 02:50:27 naddy Exp $ */
d129 8
a136 1
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82546GB_SERDES }
@


1.14
log
@add code to actually enable multicast reception; go-ahead from deraadt@@
@
text
@d35 1
a35 1
/* $OpenBSD: if_em.c,v 1.13 2003/10/13 21:19:29 jason Exp $ */
d126 4
a129 1
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82540EP_LP }
@


1.13
log
@rx checksum offload support (based on the freebsd implementation)
@
text
@d35 1
a35 1
/* $OpenBSD: if_em.c,v 1.12 2003/10/05 21:58:42 henric Exp $ */
d1328 3
a1330 3
#ifdef __FreeBSD__
	struct ifmultiaddr  *ifma;
#endif
d1332 1
a1332 3
#ifdef __FreeBSD__
	struct ifnet   *ifp = &sc->interface_data.ac_if;
#endif
d1346 10
a1355 13
#ifdef __FreeBSD__
#if __FreeBSD_version < 500000 
	LIST_FOREACH(ifma, &ifp->if_multiaddrs, ifma_link) {
#else
	TAILQ_FOREACH(ifma, &ifp->if_multiaddrs, ifma_link) {
#endif
		if (ifma->ifma_addr->sa_family != AF_LINK)
			continue;

		if (mcnt == MAX_NUM_MULTICAST_ADDRESSES) break;

		bcopy(LLADDR((struct sockaddr_dl *)ifma->ifma_addr),
		      &mta[mcnt*ETH_LENGTH_OF_ADDRESS], ETH_LENGTH_OF_ADDRESS);
d1357 1
a1358 1
#endif /* __FreeBSD__ */
@


1.12
log
@Stop the chip from stripping VLAN headers (the driver
ignores them) and tell the rest of the stack that "em"
support VLAN frames.  The "em" driver should now work with
VLAN(4) pseudo-devs (and it should no longer be silently
stripping VLAN headers when bridging).

prodding by Attila Nagy
ok jason@@
@
text
@d35 1
a35 1
/* $OpenBSD: if_em.c,v 1.11 2003/08/23 18:52:18 fgsch Exp $ */
d2733 15
@


1.11
log
@switch to ether_input_mbuf; krw@@ testing and ok.
@
text
@d35 1
a35 1
/* $OpenBSD: if_em.c,v 1.9 2003/06/13 19:21:21 henric Exp $ */
d749 1
a749 1
	em_enable_vlans(sc);
d1695 3
@


1.10
log
@change a %ju (which we dont have yet) to a %lu with an argument cast
discussed with henric@@, nate@@
@
text
@d2535 1
d2537 1
d2639 1
d2643 1
a2652 1
#endif /* __FreeBSD__ */
d2654 3
@


1.9
log
@Sync with FreeBSD's "em".

ok deraadt@@
@
text
@d35 1
a35 1
/* $OpenBSD: $ */
d1844 2
a1845 2
			"size %ju, error %d\n", sc->sc_dv.dv_xname,
			size, r);
d1853 2
a1854 2
			"size %ju, error %d\n", sc->sc_dv.dv_xname,
			size, r);
@


1.8
log
@Add/fix some PCI ids for Intel gig hardware. pcidevs diff from henric@@.

deraadt@@ ok
@
text
@d3 1
a3 1
Copyright (c) 2001-2002 Intel Corporation
d6 9
a14 11
Redistribution and use in source and binary forms of the Software, with or
without modification, are permitted provided that the following conditions
are met:

 1. Redistributions of source code of the Software may retain the above
    copyright notice, this list of conditions and the following disclaimer.

 2. Redistributions in binary form of the Software may reproduce the above
    copyright notice, this list of conditions and the following disclaimer
    in the documentation and/or other materials provided with the
    distribution.
d17 2
a18 2
    contributors shall be used to endorse or promote products derived from
    this Software without specific prior written permission.
d23 8
a30 8
ARE DISCLAIMED. IN NO EVENT SHALL THE INTEL OR ITS CONTRIBUTORS BE LIABLE
FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
SUCH DAMAGE.
d34 2
a35 1
/*$FreeBSD$*/
d78 6
d85 1
a85 1
 *  Set this to one to display debug statistics                                                   
d92 3
a94 3
#if 0
struct em_softc *em_em_softc_list = NULL;
#endif
d100 1
a100 1
char em_driver_version[] = "1.3.14";
d119 1
d121 6
d130 1
a130 1
 *  Function prototypes            
d141 1
a141 1
int  em_ioctl(struct ifnet *, IOCTL_CMD_TYPE, caddr_t);
d165 1
a165 1
void em_process_receive_interrupts(struct em_softc *);
d167 1
a167 1
				     struct em_rx_desc * rx_desc,
a168 1
#if 0
a170 1
					    struct em_tx_buffer *,
a172 1
#endif /* 0 */
d178 1
a178 1
int  em_get_buf(struct em_rx_buffer *, struct em_softc *,
d180 12
a191 6
void em_enable_vlans(struct em_softc *em_softc);


int em_malloc_dma(struct em_softc *sc, struct em_dmamap *emm,
			 bus_size_t size);
void em_free_dma(struct em_softc *sc, struct em_dmamap *emm);
d194 1
a194 1
 *  FreeBSD Device Interface Entry Points                    
d230 1
d236 1
a236 1
        struct pci_attach_args *pa = aux;
d241 3
a243 2
	int             s;
	int             tsize, rsize;
d248 13
d263 37
a299 1
	timeout_set(&sc->em_timeout, em_local_timer, sc);
d305 6
a310 4
	sc->num_tx_desc = MAX_TXD;
	sc->num_rx_desc = MAX_RXD;
	sc->tx_int_delay = TIDV;
	sc->rx_int_delay = RIDV;
d317 4
d327 6
a332 1
	/* Set the max frame size assuming standard ethernet sized frames */   
d334 1
a334 1
	ETHERMTU + ETHER_HDR_LEN + ETHER_CRC_LEN;
d337 7
a343 1
	MINIMUM_ETHERNET_PACKET_SIZE + ETHER_CRC_LEN;
a344 10
	/* This controls when hardware reports transmit completion status. */
	if ((EM_REPORT_TX_EARLY == 0) || (EM_REPORT_TX_EARLY == 1)) {
		sc->hw.report_tx_early = EM_REPORT_TX_EARLY;
	} else {
		if (sc->hw.mac_type < em_82543) {
			sc->hw.report_tx_early = 0;
		} else {
			sc->hw.report_tx_early = 1;
		}
	}
d349 2
a350 3
		em_free_pci_resources(sc);
		splx(s);
		return;
d353 4
d361 2
a362 2
	if(em_malloc_dma(sc, &sc->osdep.em_tx, tsize)) {
		printf("%s: Unable to allocate TxDescriptor memory\n", 
d364 2
a365 3
		em_free_pci_resources(sc);
		splx(s);
		return;
d367 1
a367 2

	sc->tx_desc_base = (struct em_tx_desc *)sc->osdep.em_tx.emm_kva;
d373 1
a373 1
	if(em_malloc_dma(sc, &sc->osdep.em_rx, rsize)) {
d376 2
a377 4
		em_free_pci_resources(sc);
		em_free_dma(sc, &sc->osdep.em_tx);
		splx(s);
		return;
d379 1
a379 2

	sc->rx_desc_base = (struct em_rx_desc *)sc->osdep.em_rx.emm_kva;
d385 2
a386 5
		em_free_pci_resources(sc);
		em_free_dma(sc, &sc->osdep.em_tx);
		em_free_dma(sc, &sc->osdep.em_rx);
		splx(s);
		return;
d393 8
a400 1
		return;
d403 2
a404 2
	memcpy((char *)&sc->arpcom.ac_enaddr, sc->hw.mac_addr,
	       ETH_LENGTH_OF_ADDRESS);
d406 1
a406 1
	printf(", address: %s\n", ether_sprintf(sc->arpcom.ac_enaddr));
d425 17
d448 1
a448 1
 *  This routine stops the em_softc and deallocates all the resources
d453 1
a453 1
#if 0
d458 2
a459 2
	struct ifnet   *ifp = &sc->arpcom.ac_if;
	int             s;
d466 5
a470 2
	if_detach(ifp);
	ether_ifdetach(ifp);
d475 1
a475 1
		em_free_dma(sc, &sc->osdep.em_tx);
d481 1
a481 1
		em_free_dma(sc, &sc->osdep.em_rx);
d485 3
a487 4
#if 0
	/* Remove from the em_softc list */
	if (em_em_softc_list == sc)
		em_em_softc_list = sc->next;
a491 1
#endif /* 0 */
d500 6
d514 1
a514 1
#endif /* 0 */
d529 1
a529 1
	int             i, s;
d531 1
a531 5
	u_int32_t       txd_upper; 
	u_int32_t       txd_lower;
	struct em_tx_buffer   *tx_buffer;
	struct em_tx_desc *current_tx_desc = NULL;
	struct em_softc * sc = ifp->if_softc;
d536 1
a536 6
	s = splimp();      

	for(;;) {
#if NVLAN > 0
		struct ifvlan *ifv = NULL;
#endif
d538 1
d543 1
a543 4
		if (sc->num_tx_desc_avail <= TX_CLEANUP_THRESHOLD)
			em_clean_transmit_interrupts(sc);

		if (sc->num_tx_desc_avail <= TX_CLEANUP_THRESHOLD) {
a544 1
			sc->no_tx_desc_avail++;
a547 18
		tx_buffer =  SIMPLEQ_FIRST(&sc->free_tx_buffer_list);
		if (!tx_buffer) {
			sc->no_tx_buffer_avail1++;
			/* 
			 * OK so we should not get here but I've seen
			 * it so let us try to clean up and then try
			 * to get a tx_buffer again and only break if
			 * we still don't get one.
			 */
			em_clean_transmit_interrupts(sc);
			tx_buffer = SIMPLEQ_FIRST(&sc->free_tx_buffer_list);
			if (!tx_buffer) {
				ifp->if_flags |= IFF_OACTIVE;
				sc->no_tx_buffer_avail2++;
				break;
			}
		}

a549 75
		SIMPLEQ_REMOVE_HEAD(&sc->free_tx_buffer_list, tx_buffer,
				    em_tx_entry);

		tx_buffer->num_tx_desc_used = 0;
		tx_buffer->m_head = m_head;
#if 0
		if (ifp->if_hwassist > 0) {
			em_transmit_checksum_setup(sc,  m_head, tx_buffer, 
						   &txd_upper, &txd_lower);
		} else {
#endif
			txd_upper = 0;
			txd_lower = 0;
#if 0
		}
#endif

#if NVLAN > 0
		/* Find out if we are in vlan mode */
		if ((m_head->m_flags & (M_PROTO1|M_PKTHDR)) == 
		    (M_PROTO1|M_PKTHDR) &&
		    m_head->m_pkthdr.rcvif != NULL &&
		    m_head->m_pkthdr.rcvif->if_type == IFT_L2VLAN)
			ifv = m_head->m_pkthdr.rcvif->if_softc;
#endif

		if (bus_dmamap_load_mbuf(sc->osdep.em_pa.pa_dmat,
					 tx_buffer->dmamap,
					 m_head, BUS_DMA_NOWAIT))
			return;

		for (i = 0; i < tx_buffer->dmamap->dm_nsegs; i++) {
			bus_addr_t addr= tx_buffer->dmamap->dm_segs[i].ds_addr;
			bus_size_t len = tx_buffer->dmamap->dm_segs[i].ds_len;

			current_tx_desc = sc->next_avail_tx_desc;
			current_tx_desc->buffer_addr = htole64(addr);

			current_tx_desc->lower.data = htole32(txd_lower | len);
			current_tx_desc->upper.data = htole32(txd_upper);

			if (current_tx_desc == sc->last_tx_desc)
				sc->next_avail_tx_desc =
				sc->first_tx_desc;
			else
				sc->next_avail_tx_desc++;

			sc->num_tx_desc_avail--;
			tx_buffer->num_tx_desc_used++;
		}

		/* Put this tx_buffer at the end in the "in use" list */
		SIMPLEQ_INSERT_TAIL(&sc->used_tx_buffer_list, tx_buffer, 
				   em_tx_entry);

#if NVLAN > 0
		if (ifv != NULL) {
			/* Tell hardware to add tag */
			current_tx_desc->lower.data |=
				htole32(E1000_TXD_CMD_VLE);

			/* Set the vlan id */
			current_tx_desc->upper.fields.special =
				htole16(ifv->ifv_tag);
		}
#endif

		/* 
		 * Last Descriptor of Packet needs End Of Packet
		 * (EOP), Report Status (RS) and append Ethernet CRC
		 * (IFCS) bits set.
		 */
		current_tx_desc->lower.data |=
			htole32(sc->txd_cmd|E1000_TXD_CMD_EOP);

d551 1
a551 4
		/*
		 * If there's a BPF listener, bounce a copy of this frame
		 * to him.
		 */
d556 2
a557 9
		/* 
		 * Advance the Transmit Descriptor Tail (Tdt), this
		 * tells the E1000 that this frame is available to
		 * transmit.
		 */
		E1000_WRITE_REG(&sc->hw, TDT, 
				(((_BSD_PTRDIFF_T_) sc->next_avail_tx_desc -
				  (_BSD_PTRDIFF_T_) sc->first_tx_desc) >> 4));
	} /* end of while loop */
d559 1
a560 4

	/* Set timeout in case chip has problems transmitting */
	ifp->if_timer = EM_TX_TIMEOUT;

d574 1
a574 1
em_ioctl(struct ifnet *ifp, IOCTL_CMD_TYPE command, caddr_t data)
d576 1
a576 1
	int             s, error = 0;
d583 4
a586 4
        if ((error = ether_ioctl(ifp, &sc->arpcom, command, data)) > 0) {
                splx(s);
                return (error);
        }
d590 6
d599 2
a600 1
                switch (ifa->ifa_addr->sa_family) {
d602 3
a604 4
                case AF_INET:
                        em_init(sc);
                        arp_ifinit(&sc->arpcom, ifa);
                        break;
d606 3
a608 4
                default:
                        em_init(sc);
                        break;
                }
d622 1
a622 2
		IOCTL_DEBUGOUT("ioctl rcv'd: SIOCSIFFLAGS (Set Interface "
			       "Flags)");
d624 1
a624 7
			if (ifp->if_flags & IFF_RUNNING &&
			    ifp->if_flags & IFF_PROMISC) {
				em_set_promisc(sc);
			} else if (ifp->if_flags & IFF_RUNNING &&
				   !(ifp->if_flags & IFF_PROMISC)) {
				em_disable_promisc(sc);
			} else
d626 3
d638 3
a640 13
#if 0
		if (ifp->if_flags & IFF_RUNNING) {
			em_disable_intr(sc);
			em_set_multi(sc);
			if (sc->hw.mac_type == em_82542_rev2_0)
				em_initialize_receive_unit(sc);
			em_enable_intr(sc);
		}
		break;
#endif /* 0 */
                error = (command == SIOCADDMULTI)
                        ? ether_addmulti(ifr, &sc->arpcom)
                        : ether_delmulti(ifr, &sc->arpcom);
d642 2
a643 2
                if (error == ENETRESET) {
                        if (ifp->if_flags & IFF_RUNNING) {
d646 1
a646 1
				if (sc->hw.mac_type == em_82542_rev2_0)
d648 5
a652 1
				em_enable_intr(sc);
d654 2
a655 2
                        error = 0;
                }
d659 1
a659 2
		IOCTL_DEBUGOUT("ioctl rcv'd: SIOCxIFMEDIA (Get/Set Interface "
			       "Media)");
d662 1
a662 1
#if 0
d675 1
a675 1
#endif /* 0 */
d677 1
a677 2
		IOCTL_DEBUGOUT1("ioctl received: UNKNOWN (0x%d)\n",
				(int)command);
a684 110
void
em_set_promisc(struct em_softc * sc)
{

	u_int32_t       reg_rctl;
	struct ifnet   *ifp = &sc->arpcom.ac_if;

	reg_rctl = E1000_READ_REG(&sc->hw, RCTL);

	if (ifp->if_flags & IFF_PROMISC) {
		reg_rctl |= (E1000_RCTL_UPE | E1000_RCTL_MPE);
		E1000_WRITE_REG(&sc->hw, RCTL, reg_rctl);
	} else if (ifp->if_flags & IFF_ALLMULTI) {
		reg_rctl |= E1000_RCTL_MPE;
		reg_rctl &= ~E1000_RCTL_UPE;
		E1000_WRITE_REG(&sc->hw, RCTL, reg_rctl);
	}

	return;
}

void
em_disable_promisc(struct em_softc * sc)
{
	u_int32_t       reg_rctl;

	reg_rctl = E1000_READ_REG(&sc->hw, RCTL);

	reg_rctl &=  (~E1000_RCTL_UPE);
	reg_rctl &=  (~E1000_RCTL_MPE);
	E1000_WRITE_REG(&sc->hw, RCTL, reg_rctl);

	return;
}


/*********************************************************************
 *  Multicast Update
 *
 *  This routine is called whenever multicast address list is updated.
 *
 **********************************************************************/

void
em_set_multi(struct em_softc * sc)
{
	u_int32_t reg_rctl = 0;
	u_int8_t  mta[MAX_NUM_MULTICAST_ADDRESSES * ETH_LENGTH_OF_ADDRESS];
	u_int16_t pci_cmd_word;
#if 0
	struct ifmultiaddr  *ifma;
#endif
	int mcnt = 0;
        struct pci_attach_args *pa = &sc->osdep.em_pa;
#if 0
	struct ifnet   *ifp = &sc->arpcom.ac_if;
#endif

	IOCTL_DEBUGOUT("em_set_multi: begin");

	if (sc->hw.mac_type == em_82542_rev2_0) {
		reg_rctl = E1000_READ_REG(&sc->hw, RCTL);
		if (sc->hw.pci_cmd_word & CMD_MEM_WRT_INVALIDATE) {
			pci_cmd_word = sc->hw.pci_cmd_word & 
				       ~CMD_MEM_WRT_INVALIDATE;
			pci_conf_write(pa->pa_pc, pa->pa_tag,
				       PCI_COMMAND_STATUS_REG, pci_cmd_word);
		}
		reg_rctl |= E1000_RCTL_RST;
		E1000_WRITE_REG(&sc->hw, RCTL, reg_rctl);
		msec_delay(5);
	}

#if 0
#if __FreeBSD_version < 500000 
	LIST_FOREACH(ifma, &ifp->if_multiaddrs, ifma_link) {
#else
	TAILQ_FOREACH(ifma, &ifp->if_multiaddrs, ifma_link) {
#endif
		if (ifma->ifma_addr->sa_family != AF_LINK)
			continue;

		bcopy(LLADDR((struct sockaddr_dl *)ifma->ifma_addr),
		      &mta[mcnt*ETH_LENGTH_OF_ADDRESS], ETH_LENGTH_OF_ADDRESS);
		mcnt++;
	}
#endif /* 0 */

	if (mcnt > MAX_NUM_MULTICAST_ADDRESSES) {
		reg_rctl = E1000_READ_REG(&sc->hw, RCTL);
		reg_rctl |= E1000_RCTL_MPE;
		E1000_WRITE_REG(&sc->hw, RCTL, reg_rctl);
	} else
		em_mc_addr_list_update(&sc->hw, mta, mcnt, 0);

	if (sc->hw.mac_type == em_82542_rev2_0) {
		reg_rctl = E1000_READ_REG(&sc->hw, RCTL);
		reg_rctl &= ~E1000_RCTL_RST;
		E1000_WRITE_REG(&sc->hw, RCTL, reg_rctl);
		msec_delay(5);
		if (sc->hw.pci_cmd_word & CMD_MEM_WRT_INVALIDATE) {
			pci_conf_write(pa->pa_pc, pa->pa_tag,
				       PCI_COMMAND_STATUS_REG, 
				       sc->hw.pci_cmd_word);
		}
	}

	return;
}

d718 1
a718 1
 *  Timer routine
d720 4
a723 1
 *  This routine checks for link status and updates statistics.
d725 1
d729 1
a729 1
em_local_timer(void *arg)
d731 1
a731 1
	int s;
d734 2
a735 1
	ifp = &sc->arpcom.ac_if;
d739 19
a757 5
	em_check_for_link(&sc->hw);
	em_print_link_status(sc);
	em_update_stats_counters(sc);   
	if (em_display_debug_stats && ifp->if_flags & IFF_RUNNING) {
		em_print_hw_stats(sc);
d759 1
a759 1
	timeout_add(&sc->em_timeout, 2*hz);
d761 2
a762 3
	splx(s);
	return;
}
d764 3
a766 71
void
em_print_link_status(struct em_softc * sc)
{
	if (E1000_READ_REG(&sc->hw, STATUS) & E1000_STATUS_LU) {
		if (sc->link_active == 0) {
			em_get_speed_and_duplex(&sc->hw, 
						&sc->link_speed, 
						&sc->link_duplex);
			sc->link_active = 1;
		}
	} else {
		if (sc->link_active == 1) {
			sc->link_speed = 0;
			sc->link_duplex = 0;
			sc->link_active = 0;
		}
	}

	return;
}

/*********************************************************************
 *  Init entry point
 *
 *  This routine is used in two ways. It is used by the stack as
 *  init entry point in network interface structure. It is also used
 *  by the driver as a hw/sw initialization routine to get to a 
 *  consistent state.
 *
 *  return 0 on success, positive on failure
 **********************************************************************/

void
em_init(void *arg)
{
	int             s;
	struct ifnet   *ifp;
	struct em_softc * sc= arg;

	INIT_DEBUGOUT("em_init: begin");

	s = splimp();

	em_stop(sc);

	/* Initialize the hardware */
	if (em_hardware_init(sc)) {
		printf("%s: Unable to initialize the hardware\n", 
		       sc->sc_dv.dv_xname);
		splx(s);
		return;
	}

	em_enable_vlans(sc);

	/* Prepare transmit descriptors and buffers */
	if (em_setup_transmit_structures(sc)) {
		printf("%s: Could not setup transmit structures\n", 
		       sc->sc_dv.dv_xname);
		em_stop(sc); 
		splx(s);
		return;
	}
	em_initialize_transmit_unit(sc);

	/* Setup Multicast table */
	em_set_multi(sc);

	/* Prepare receive descriptors and buffers */
	if (em_setup_receive_structures(sc)) {
		printf("%s: Could not setup receive structures\n", 
d774 1
a774 1
	ifp = &sc->arpcom.ac_if;
d778 1
a778 1
#if 0
d785 1
a785 1
#endif /* 0 */
d787 1
a787 1
	timeout_add(&sc->em_timeout, 2*hz);
d789 10
a798 1
	em_enable_intr(sc);
d805 2
a806 6
/*********************************************************************
 *
 *  This routine disables all traffic on the em_softc by issuing a
 *  global reset on the MAC and deallocates TX/RX buffers. 
 *
 **********************************************************************/
d808 2
a809 2
void
em_stop(void *arg)
d811 2
a812 3
	struct ifnet   *ifp;
	struct em_softc * sc = arg;
	ifp = &sc->arpcom.ac_if;
d814 18
a831 6
	INIT_DEBUGOUT("em_stop: begin\n");
	em_disable_intr(sc);
	em_reset_hw(&sc->hw);
	timeout_del(&sc->em_timeout);
	em_free_transmit_structures(sc);
	em_free_receive_structures(sc);
d833 2
a834 5

	/* Tell the stack that the interface is no longer active */
	ifp->if_flags &= ~(IFF_RUNNING | IFF_OACTIVE);

	return;
d836 1
a842 1

d846 4
a849 4
	u_int32_t       loop_cnt = EM_MAX_INTR;
	u_int32_t       reg_icr;
	struct ifnet    *ifp;
	struct em_softc *sc= arg;
d851 1
a851 1
	ifp = &sc->arpcom.ac_if;
d853 3
a855 3
	em_disable_intr(sc);
	while (loop_cnt > 0 && 
	       (reg_icr = E1000_READ_REG(&sc->hw, ICR)) != 0) {
d857 19
a875 8
		/* Link status change */
		if (reg_icr & (E1000_ICR_RXSEQ | E1000_ICR_LSC)) {
			timeout_del(&sc->em_timeout);
			sc->hw.get_link_status = 1;
			em_check_for_link(&sc->hw);
			em_print_link_status(sc);
			timeout_add(&sc->em_timeout, 2*hz); 
		}
d877 1
d879 1
a879 1
			em_process_receive_interrupts(sc);
a884 2
	em_enable_intr(sc);

d888 1
a888 1
	return (EM_MAX_INTR != loop_cnt);
d892 1
d966 1
a966 1
	struct ifmedia  *ifm = &sc->media;
d1007 460
a1466 1
/* Section end: Other registered entry points */
d1485 1
a1485 1
		printf("%s: Memory Access and/or Bus Master bits not set!\n", 
d1505 4
a1508 30
	/* Set MacType, etc. based on this PCI info */
	switch (sc->hw.device_id) {
	case E1000_DEV_ID_82542:
		sc->hw.mac_type = (sc->hw.revision_id == 3) ?
				       em_82542_rev2_1 : em_82542_rev2_0;
		break;
	case E1000_DEV_ID_82543GC_FIBER:
	case E1000_DEV_ID_82543GC_COPPER:
		sc->hw.mac_type = em_82543;
		break;
	case E1000_DEV_ID_82544EI_FIBER:
	case E1000_DEV_ID_82544EI_COPPER:
	case E1000_DEV_ID_82544GC_COPPER:
	case E1000_DEV_ID_82544GC_LOM:
		sc->hw.mac_type = em_82544;
		break;
	case E1000_DEV_ID_82540EM:
		sc->hw.mac_type = em_82540;
		break;
	case E1000_DEV_ID_82545EM_FIBER:
	case E1000_DEV_ID_82545EM_COPPER:
		sc->hw.mac_type = em_82545;
		break;
	case E1000_DEV_ID_82546EB_FIBER:
	case E1000_DEV_ID_82546EB_COPPER:
		sc->hw.mac_type = em_82546;
		break;
	default:
		INIT_DEBUGOUT1("Unknown device id 0x%x", sc->hw.device_id);
	}
d1515 3
a1517 3
	int             i, val, rid;
	pci_intr_handle_t       ih;
	const char              *intrstr = NULL;
d1519 1
a1519 1
	pci_chipset_tag_t       pc = pa->pa_pc;
d1525 3
a1527 3
        }
        if (pci_mapreg_map(pa, EM_MMBA, PCI_MAPREG_MEM_TYPE(val), 0,
	    &sc->osdep.em_btag, &sc->osdep.em_bhandle,
a1532 12
#if 0
        if (pci_mapreg_map(pa, EM_MMBA, PCI_MAPREG_MEM_TYPE_32BIT, 0,
	    &sc->osdep.em_btag, &sc->osdep.em_bhandle, &sc->osdep.em_membase,
	    &sc->osdep.em_memsize, 0) &&
       	    pci_mapreg_map(pa, EM_MMBA, PCI_MAPREG_MEM_TYPE_64BIT, 0,
    	    &sc->osdep.em_btag, &sc->osdep.em_bhandle, &sc->osdep.em_membase,
	    	&sc->osdep.em_memsize, 0)) {
                printf(": can't find mem space");
                return (ENXIO);
        }
#endif /* 0 */

d1544 1
a1544 1
        	if (pci_mapreg_map(pa, rid, PCI_MAPREG_TYPE_IO, 0,
d1549 3
a1551 3
                	printf(": can't find io space");
                	return (ENXIO);
        	}
d1554 4
a1557 4
        if (pci_intr_map(pa, &ih)) {
                printf(": couldn't map interrupt\n");
                return (ENXIO);
        }
d1559 8
a1566 8
        intrstr = pci_intr_string(pc, ih);
        sc->sc_intrhand = pci_intr_establish(pc, ih, IPL_NET, em_intr, sc,
                                              sc->sc_dv.dv_xname);
        if (sc->sc_intrhand == NULL) {
                printf(": couldn't establish interrupt");
                if (intrstr != NULL)
                        printf(" at %s", intrstr);
                printf("\n");
d1568 2
a1569 2
        }
        printf(": %s", intrstr);
d1580 1
a1580 1
	pci_chipset_tag_t       pc = pa->pa_pc;
d1592 1
a1592 1
		bus_space_unmap(sc->osdep.em_btag, sc->osdep.em_bhandle,
d1612 3
d1663 1
a1663 1
	ifp = &sc->arpcom.ac_if;
d1667 2
a1668 2
#if 0
	ifp->if_init =  em_init;
d1678 1
a1678 1
	bcopy(sc->sc_dv.dv_xname, ifp->if_xname, IFNAMSIZ);
d1680 1
a1680 2

#if 0
d1685 10
a1694 1
#endif /* 0 */
d1697 1
a1697 1
	 * Specify the media types supported by this em_softc and register
d1731 169
d1908 1
a1908 1
	      (struct em_tx_buffer *) malloc(sizeof(struct em_tx_buffer) *
d1917 1
a1917 1
	      sizeof(struct em_tx_buffer) * sc->num_tx_desc);
d1930 20
a1949 2
	struct em_tx_buffer   *tx_buffer;
	int             i;
d1952 1
a1952 9
		return ENOMEM;

	sc->first_tx_desc = sc->tx_desc_base;
	sc->last_tx_desc =
	sc->first_tx_desc + (sc->num_tx_desc - 1);


	SIMPLEQ_INIT(&sc->free_tx_buffer_list);
	SIMPLEQ_INIT(&sc->used_tx_buffer_list);
d1954 1
a1954 14
	tx_buffer = sc->tx_buffer_area;

	/* Setup the linked list of the tx_buffer's */
	for (i = 0; i < sc->num_tx_desc; i++, tx_buffer++) {
		bzero((void *) tx_buffer, sizeof(struct em_tx_buffer));
		if (bus_dmamap_create(sc->osdep.em_pa.pa_dmat, MCLBYTES, 32,
				      MCLBYTES, 0, BUS_DMA_NOWAIT,
				      &tx_buffer->dmamap))
			return ENOBUFS;
		SIMPLEQ_INSERT_TAIL(&sc->free_tx_buffer_list, 
				   tx_buffer, em_tx_entry);
	}

	bzero((void *) sc->first_tx_desc,
d1957 2
a1958 3
	/* Setup TX descriptor pointers */
	sc->next_avail_tx_desc = sc->first_tx_desc;
	sc->oldest_used_tx_desc = sc->first_tx_desc;
d1966 1
a1966 1
	return 0;
d1977 3
a1979 2
	u_int32_t       reg_tctl;
	u_int32_t       reg_tipg = 0;
d1982 3
a1984 3
	E1000_WRITE_REG(&sc->hw, TDBAL,
			sc->osdep.em_tx.emm_dmamap->dm_segs[0].ds_addr);
	E1000_WRITE_REG(&sc->hw, TDBAH, 0);
a1997 1

a1999 12
	case em_82543:
	case em_82544:
	case em_82540:
	case em_82545:
	case em_82546:
		if (sc->hw.media_type == em_media_type_fiber)
			reg_tipg = DEFAULT_82543_TIPG_IPGT_FIBER;
		else
			reg_tipg = DEFAULT_82543_TIPG_IPGT_COPPER;
		reg_tipg |= DEFAULT_82543_TIPG_IPGR1 << E1000_TIPG_IPGR1_SHIFT;
		reg_tipg |= DEFAULT_82543_TIPG_IPGR2 << E1000_TIPG_IPGR2_SHIFT;
		break;
d2007 6
a2012 1
		printf("%s: Invalid mac type detected\n", sc->sc_dv.dv_xname);
d2014 1
d2017 2
d2031 1
a2031 1
	sc->txd_cmd = E1000_TXD_CMD_IFCS;
a2035 5
	if (sc->hw.report_tx_early == 1)
		sc->txd_cmd |= E1000_TXD_CMD_RS;
	else
		sc->txd_cmd |= E1000_TXD_CMD_RPS;

d2047 2
a2048 2
	struct em_tx_buffer   *tx_buffer;
	int             i;
d2055 3
a2057 1
			if (tx_buffer->m_head != NULL)
d2059 1
a2060 5

			bus_dmamap_unload(sc->osdep.em_pa.pa_dmat,
			    tx_buffer->dmamap);
			bus_dmamap_destroy(sc->osdep.em_pa.pa_dmat,
			    tx_buffer->dmamap);
d2067 6
d2083 1
a2083 1
#if 0
a2086 1
			   struct em_tx_buffer *tx_buffer,
d2091 3
a2093 1
	struct em_tx_desc * current_tx_desc;
d2125 3
a2127 2
	current_tx_desc = sc->next_avail_tx_desc;
	TXD = (struct em_context_desc *)current_tx_desc;
d2133 1
a2133 1
	ETHER_HDR_LEN + sizeof(struct ip) - 1;
d2137 1
a2137 1
	TXD->upper_setup.tcp_fields.tucse = 0;
d2149 4
a2152 2
	TXD->tcp_seg_setup.data = 0;
	TXD->cmd_and_length = E1000_TXD_CMD_DEXT;
d2154 2
a2155 4
	if (current_tx_desc == sc->last_tx_desc)
		sc->next_avail_tx_desc = sc->first_tx_desc;
	else
		sc->next_avail_tx_desc++;
d2158 1
a2159 1
	tx_buffer->num_tx_desc_used++;
d2162 43
a2204 1
#endif /* 0 */
d2206 30
d2243 2
a2244 2
em_get_buf(struct em_rx_buffer *rx_buffer, struct em_softc *sc,
	   struct mbuf *mp)
d2246 2
a2247 1
	struct mbuf    *nmp;
d2249 1
d2251 1
a2251 1
	ifp = &sc->arpcom.ac_if;
d2254 2
a2255 2
		MGETHDR(nmp, M_DONTWAIT, MT_DATA);
		if (nmp == NULL) {
d2259 3
a2261 3
		MCLGET(nmp, M_DONTWAIT);
		if ((nmp->m_flags & M_EXT) == 0) {
			m_freem(nmp);
d2265 1
a2265 1
		nmp->m_len = nmp->m_pkthdr.len = MCLBYTES;
d2267 26
a2292 17
		nmp = mp;
		nmp->m_len = nmp->m_pkthdr.len = MCLBYTES;
		nmp->m_data = nmp->m_ext.ext_buf;
		nmp->m_next = NULL;
	}

	if (bus_dmamap_load_mbuf(sc->osdep.em_pa.pa_dmat,
				 rx_buffer->dmamap,
				 nmp, BUS_DMA_NOWAIT))
		return(ENOBUFS);

	if (ifp->if_mtu <= ETHERMTU)
		m_adj(nmp, ETHER_ALIGN);

	rx_buffer->m_head = nmp;
	rx_buffer->buffer_addr = 
		rx_buffer->dmamap->dm_segs[0].ds_addr + ETHER_ALIGN;
d2308 2
a2309 2
	int             i;
	struct em_rx_buffer   *rx_buffer;
d2312 1
a2312 1
	      (struct em_rx_buffer *) malloc(sizeof(struct em_rx_buffer) *
d2321 1
a2321 1
	      sizeof(struct em_rx_buffer) * sc->num_rx_desc);
d2323 32
a2354 2
	for (i = 0, rx_buffer = sc->rx_buffer_area;
	    i < sc->num_rx_desc; i++, rx_buffer++) {
d2356 8
a2363 5
		if (bus_dmamap_create(sc->osdep.em_pa.pa_dmat,
				      MCLBYTES, 1, MCLBYTES, 0,
				      BUS_DMA_NOWAIT,
				      &rx_buffer->dmamap))
			return ENOBUFS;
d2365 1
a2365 5
		if (em_get_buf(rx_buffer, sc, NULL) == ENOBUFS) {
			rx_buffer->m_head = NULL;
			return(ENOBUFS);
		}
	}
d2367 7
a2373 1
	return(0);
d2384 2
a2385 3
	struct em_rx_buffer   *rx_buffer;
	struct em_rx_desc     *rx_desc;
	int             i;
a2389 26
	SIMPLEQ_INIT(&sc->rx_buffer_list);

	sc->first_rx_desc =
	(struct em_rx_desc *) sc->rx_desc_base;
	sc->last_rx_desc =
	sc->first_rx_desc + (sc->num_rx_desc - 1);

	rx_buffer = (struct em_rx_buffer *) sc->rx_buffer_area;

	bzero((void *) sc->first_rx_desc,
	      (sizeof(struct em_rx_desc)) * sc->num_rx_desc);

	/* Build a linked list of rx_buffer's */
	for (i = 0, rx_desc = sc->first_rx_desc;
	    i < sc->num_rx_desc;
	    i++, rx_buffer++, rx_desc++) {
		if (rx_buffer->m_head == NULL)
			printf("%s: Receive buffer memory not allocated", 
			       sc->sc_dv.dv_xname);
		else {
			rx_desc->buffer_addr = htole64(rx_buffer->buffer_addr);
			SIMPLEQ_INSERT_TAIL(&sc->rx_buffer_list, 
					   rx_buffer, em_rx_entry);
		}
	}

d2391 1
a2391 2
	sc->next_rx_desc_to_check = sc->first_rx_desc;

d2403 3
a2405 3
	u_int32_t       reg_rctl;
#if 0
	u_int32_t       reg_rxcsum;
d2407 2
a2408 1
	struct ifnet    *ifp;
d2410 1
a2410 1
	ifp = &sc->arpcom.ac_if;
d2412 1
a2412 4
	/*
	 * Make sure receives are disabled while setting up the
	 * descriptor ring
	 */
d2419 10
d2430 3
a2432 3
	E1000_WRITE_REG(&sc->hw, RDBAL, 
			sc->osdep.em_rx.emm_dmamap->dm_segs[0].ds_addr);
	E1000_WRITE_REG(&sc->hw, RDBAH, 0);
d2438 1
a2438 3
	E1000_WRITE_REG(&sc->hw, RDT,
			(((_BSD_PTRDIFF_T_) sc->last_rx_desc -
			  (_BSD_PTRDIFF_T_) sc->first_rx_desc) >> 4));
d2456 1
a2456 1
		break;            
d2468 1
a2468 1
#if 0
d2476 1
a2476 1
#endif /* 0 */
d2492 2
a2493 2
	struct em_rx_buffer   *rx_buffer;
	int             i;
d2500 4
a2506 5

			bus_dmamap_unload(sc->osdep.em_pa.pa_dmat,
			    rx_buffer->dmamap);
			bus_dmamap_destroy(sc->osdep.em_pa.pa_dmat,
			    rx_buffer->dmamap);
d2513 4
d2526 3
d2531 1
a2531 1
em_process_receive_interrupts(struct em_softc* sc)
d2533 2
a2534 2
	struct mbuf         *mp;
	struct ifnet        *ifp;
d2536 4
a2539 5
	u_int16_t           len;
	u_int8_t            last_byte;
	u_int8_t            accept_frame = 0;
	u_int8_t            eop = 0;
	u_int32_t           pkt_len = 0;
a2542 2
	struct em_rx_desc   *last_desc_processed;
	struct em_rx_buffer *rx_buffer;
d2544 3
a2546 2
	ifp = &sc->arpcom.ac_if;
	current_desc = sc->next_rx_desc_to_check;
d2555 1
a2555 1
	while (current_desc->status & E1000_RXD_STAT_DD) {
d2557 5
a2561 8
		/* Get a pointer to the actual receive buffer */
		rx_buffer = SIMPLEQ_FIRST(&sc->rx_buffer_list);

		if (rx_buffer == NULL) {
			printf("%s: Found null rx_buffer\n",
			       sc->sc_dv.dv_xname);
			return;
		}
a2562 1
		mp = rx_buffer->m_head;      
d2564 1
a2564 1

d2566 1
d2568 1
a2568 1
			len = letoh16(current_desc->length) - ETHER_CRC_LEN;
d2571 1
a2571 1
			len = letoh16(current_desc->length);
d2575 2
d2578 1
a2578 3
			/* Compute packet length for tbi_accept macro */
			pkt_len = letoh16(current_desc->length);
			if (sc->fmp != NULL) {
a2579 1
			}
d2581 1
a2581 2
			last_byte = *(mtod(rx_buffer->m_head,caddr_t) + 
				      letoh16(current_desc->length) - 1);
d2583 2
a2584 2
			if (TBI_ACCEPT(&sc->hw, current_desc->status, 
				       current_desc->errors, 
d2591 2
a2592 1
			} else {
d2599 1
a2599 1
			if (em_get_buf(rx_buffer, sc, NULL) == ENOBUFS) {
d2601 3
a2603 2
				em_get_buf(rx_buffer, sc, mp);
				if (sc->fmp != NULL) m_freem(sc->fmp);
d2626 2
a2636 1

a2637 1

d2640 4
a2643 3
				em_receive_checksum(sc, current_desc, 
						    sc->fmp);
#if 0
d2646 2
a2647 1
					     letoh16(current_desc->special));
d2649 1
a2649 1
#endif /* 0 */
d2657 3
a2659 2
			em_get_buf(rx_buffer, sc, mp);
			if (sc->fmp != NULL) m_freem(sc->fmp);
d2667 2
a2668 11
		if (rx_buffer->m_head != NULL) {
			current_desc->buffer_addr =
				htole64(rx_buffer->buffer_addr);
		}

		/* Advance our pointers to the next descriptor
		 * (checking for wrap). */
		if (current_desc == sc->last_rx_desc)
			sc->next_rx_desc_to_check = sc->first_rx_desc;
		else
			((sc)->next_rx_desc_to_check)++;
d2670 6
a2675 15
		last_desc_processed = current_desc;
		current_desc = sc->next_rx_desc_to_check;
		/* 
		 * Put the buffer that we just indicated back at the
		 * end of our list
		 */
		SIMPLEQ_REMOVE_HEAD(&sc->rx_buffer_list, rx_buffer,
				    em_rx_entry);
		SIMPLEQ_INSERT_TAIL(&sc->rx_buffer_list, 
				   rx_buffer, em_rx_entry);

		/* Advance the E1000's Receive Queue #0  "Tail Pointer". */
		E1000_WRITE_REG(&sc->hw, RDT, 
				(((u_long) last_desc_processed -
				  (u_long) sc->first_rx_desc) >> 4));
d2677 1
d2693 1
a2693 1
#if 0
d2715 1
a2715 1
		/* Did it pass? */        
d2724 1
a2724 1
#endif /* 0 */
d2732 1
a2732 1
	E1000_WRITE_REG(&sc->hw, VET, QTAG_TYPE);
d2756 14
a2769 1
void em_write_pci_cfg(struct em_hw *hw,
d2773 1
a2773 1
        struct pci_attach_args *pa = &((struct em_osdep *)hw->back)->em_pa;
d2775 1
d2779 2
a2780 1
void em_read_pci_cfg(struct em_hw *hw, uint32_t reg,
d2783 1
a2783 1
        struct pci_attach_args *pa = &((struct em_osdep *)hw->back)->em_pa;
d2789 24
a2812 1
uint32_t em_io_read(struct em_hw *hw, uint32_t port)
d2814 2
a2815 7
#if 0
	return(inl(port));
#endif
	return bus_space_read_4(
                ((struct em_osdep *)(hw)->back)->em_iobtag,
		((struct em_osdep *)(hw)->back)->em_iobhandle,
		port);
d2818 2
a2819 1
void em_io_write(struct em_hw *hw, uint32_t port, uint32_t value)
d2821 2
a2822 7
#if 0
	outl(port, value);
#endif
	bus_space_write_4(
			((struct em_osdep *)(hw)->back)->em_iobtag,
			((struct em_osdep *)(hw)->back)->em_iobhandle,
			port,
d2825 1
a2825 1
} 
d2842 1
d2909 1
a2909 1
	ifp = &sc->arpcom.ac_if;
a2911 2
	ifp->if_ipackets = sc->stats.gprc;
	ifp->if_opackets = sc->stats.gptc;
d2940 1
a2940 1
em_print_hw_stats(struct em_softc *sc)
d2942 2
d2945 1
a2945 1
	printf("%s: Packets not Avail = %ld\n", sc->sc_dv.dv_xname, 
d2947 1
a2947 1
	printf("%s: CleanTxInterrupts = %ld\n", sc->sc_dv.dv_xname, 
d2950 21
d2972 4
a2975 10
	printf("%s: Tx Descriptors not Avail = %ld\n", sc->sc_dv.dv_xname, 
	       sc->no_tx_desc_avail);
	printf("%s: Tx Buffer not avail1 = %ld\n", sc->sc_dv.dv_xname, 
	       sc->no_tx_buffer_avail1);
	printf("%s: Tx Buffer not avail2 = %ld\n", sc->sc_dv.dv_xname, 
	       sc->no_tx_buffer_avail2);
	printf("%s: Std Mbuf Failed = %ld\n",sc->sc_dv.dv_xname, 
	       sc->mbuf_alloc_failed);
	printf("%s: Std Cluster Failed = %ld\n",sc->sc_dv.dv_xname, 
	       sc->mbuf_cluster_failed);
d2977 3
a2979 1
	printf("%s: Symbol errors = %lld\n", sc->sc_dv.dv_xname, 
d2981 1
a2981 1
	printf("%s: Sequence errors = %lld\n", sc->sc_dv.dv_xname, 
d2983 1
a2983 1
	printf("%s: Defer count = %lld\n", sc->sc_dv.dv_xname, 
d2986 1
a2986 1
	printf("%s: Missed Packets = %lld\n", sc->sc_dv.dv_xname, 
d2988 1
a2988 1
	printf("%s: Receive No Buffers = %lld\n", sc->sc_dv.dv_xname, 
d2990 1
a2990 1
	printf("%s: Receive length errors = %lld\n", sc->sc_dv.dv_xname, 
d2992 1
a2992 1
	printf("%s: Receive errors = %lld\n", sc->sc_dv.dv_xname, 
d2994 1
a2994 1
	printf("%s: Crc errors = %lld\n", sc->sc_dv.dv_xname, 
d2996 1
a2996 1
	printf("%s: Alignment errors = %lld\n", sc->sc_dv.dv_xname, 
d2998 1
a2998 1
	printf("%s: Carrier extension errors = %lld\n", sc->sc_dv.dv_xname,
a2999 2
	printf("%s: Driver dropped packets = %ld\n", sc->sc_dv.dv_xname, 
	       sc->dropped_pkts);
d3001 1
a3001 1
	printf("%s: XON Rcvd = %lld\n", sc->sc_dv.dv_xname, 
d3003 1
a3003 1
	printf("%s: XON Xmtd = %lld\n", sc->sc_dv.dv_xname, 
d3005 1
a3005 1
	printf("%s: XOFF Rcvd = %lld\n", sc->sc_dv.dv_xname, 
d3007 1
a3007 1
	printf("%s: XOFF Xmtd = %lld\n", sc->sc_dv.dv_xname, 
d3010 1
a3010 1
	printf("%s: Good Packets Rcvd = %lld\n", sc->sc_dv.dv_xname,
d3012 1
a3012 1
	printf("%s: Good Packets Xmtd = %lld\n", sc->sc_dv.dv_xname,
d3014 2
d3018 3
a3020 10

/**********************************************************************
 *
 *  Examine each tx_buffer in the used queue. If the hardware is done
 *  processing the packet then free associated resources. The
 *  tx_buffer is put back on the free queue. 
 *
 **********************************************************************/
void
em_clean_transmit_interrupts(struct em_softc* sc)
d3022 3
a3024 4
	struct em_tx_buffer *tx_buffer;
	struct em_tx_desc   *tx_desc;
	int             s;
	struct ifnet   *ifp;
d3026 2
a3027 4
	s = splimp();
#ifdef DBG_STATS
	sc->clean_tx_interrupts++;
#endif
d3029 2
a3030 37
	for (tx_buffer = SIMPLEQ_FIRST(&sc->used_tx_buffer_list);
	    tx_buffer; 
	    tx_buffer = SIMPLEQ_FIRST(&sc->used_tx_buffer_list)) {

		/* 
		 * Get hold of the next descriptor that the em will
		 * report status back to (this will be the last
		 * descriptor of a given tx_buffer). We only want to
		 * free the tx_buffer (and it resources) if the driver
		 * is done with ALL of the descriptors.  If the driver
		 * is done with the last one then it is done with all
		 * of them.
		 */

		tx_desc = sc->oldest_used_tx_desc +
			  (tx_buffer->num_tx_desc_used - 1);

		/* Check for wrap case */
		if (tx_desc > sc->last_tx_desc)
			tx_desc -= sc->num_tx_desc;


		/* 
		 * If the descriptor done bit is set free tx_buffer
		 * and associated resources
		 */
		if (tx_desc->upper.fields.status & E1000_TXD_STAT_DD) {

			SIMPLEQ_REMOVE_HEAD(&sc->used_tx_buffer_list, 
					   tx_buffer,
					   em_tx_entry);

			if ((tx_desc == sc->last_tx_desc))
				sc->oldest_used_tx_desc =
				sc->first_tx_desc;
			else
				sc->oldest_used_tx_desc = (tx_desc + 1);
d3032 4
a3035 4
			/* Make available the descriptors that were
			 * previously used */
			sc->num_tx_desc_avail +=
			tx_buffer->num_tx_desc_used;
d3037 2
a3038 1
			tx_buffer->num_tx_desc_used = 0;
a3039 17
			if (tx_buffer->m_head) {
				m_freem(tx_buffer->m_head);
				tx_buffer->m_head = NULL;
			}
			/* Return this "Software packet" back to the
			 * "free" list */
			SIMPLEQ_INSERT_TAIL(&sc->free_tx_buffer_list, 
					   tx_buffer, em_tx_entry);
		} else {
			/* 
			 * Found a tx_buffer that the em is not done
			 * with then there is no reason to check the
			 * rest of the queue.
			 */
			break;
		}
	}		      /* end for each tx_buffer */
d3041 6
a3046 1
	ifp = &sc->arpcom.ac_if;
d3048 2
a3049 8
	/* Tell the stack that it is OK to send packets */
	if (sc->num_tx_desc_avail > TX_CLEANUP_THRESHOLD) {
		ifp->if_timer = 0;
		ifp->if_flags &= ~IFF_OACTIVE;
	}
	splx(s);
	return;
}
d3051 2
a3052 4
int em_malloc_dma(struct em_softc *sc, struct em_dmamap *emm,
			 bus_size_t size)
{
	bus_dma_tag_t	dma_tag = sc->osdep.em_pa.pa_dmat;
d3054 4
a3057 1
	emm->emm_size = size;
d3059 3
a3061 18
        if (bus_dmamem_alloc(dma_tag, size, PAGE_SIZE, 0, &emm->emm_seg, 1,
			     &emm->emm_rseg, BUS_DMA_NOWAIT)) {
		goto fail0;
        }
        if (bus_dmamem_map(dma_tag, &emm->emm_seg, emm->emm_rseg, size,
			   &emm->emm_kva, BUS_DMA_NOWAIT)) {
		goto fail1;
        }
        if (bus_dmamap_create(dma_tag, size, 1, size, 0, BUS_DMA_NOWAIT,
			      &emm->emm_dmamap)) {
		goto fail2;
        }
        if (bus_dmamap_load(dma_tag, emm->emm_dmamap, emm->emm_kva, size,
			    NULL, BUS_DMA_NOWAIT)) {
		goto fail3;
        }
       	 
	return 0;
a3062 17
 fail3:
	bus_dmamap_destroy(dma_tag, emm->emm_dmamap);
 fail2:
	bus_dmamem_unmap(dma_tag, emm->emm_kva, size);
 fail1:
	bus_dmamem_free(dma_tag, &emm->emm_seg, emm->emm_rseg);
 fail0:
	return (ENOBUFS);
}

void em_free_dma(struct em_softc *sc, struct em_dmamap *emm)
{
	bus_dmamap_unload(sc->osdep.em_pa.pa_dmat, emm->emm_dmamap);
	bus_dmamap_destroy(sc->osdep.em_pa.pa_dmat, emm->emm_dmamap);
	bus_dmamem_unmap(sc->osdep.em_pa.pa_dmat, emm->emm_kva, emm->emm_size);
	bus_dmamem_free(sc->osdep.em_pa.pa_dmat, &emm->emm_seg, emm->emm_rseg);
}
@


1.7
log
@print out the ethernet address in the dmesg.
from David Krause <openbsd@@davidkrause.com>
@
text
@d108 1
a108 1
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82544GC_LX },
d114 1
a114 1
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82545EM_LX },
@


1.7.4.1
log
@Merge of current from two weeks agointo the SMP branch
@
text
@d3 1
a3 1
Copyright (c) 2001-2003, Intel Corporation
d6 11
a16 9
Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are met:

 1. Redistributions of source code must retain the above copyright notice,
    this list of conditions and the following disclaimer.

 2. Redistributions in binary form must reproduce the above copyright
    notice, this list of conditions and the following disclaimer in the
    documentation and/or other materials provided with the distribution.
d19 2
a20 2
    contributors may be used to endorse or promote products derived from
    this software without specific prior written permission.
d25 8
a32 8
ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE
LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
POSSIBILITY OF SUCH DAMAGE.
d36 1
a36 2
/*$FreeBSD: if_em.c,v 1.26 2003/06/05 17:51:37 pdeuskar Exp $*/
/* $OpenBSD$ */
a78 6
#ifdef DEBUG
#define EM_KASSERT(exp,msg)        do { if (!(exp)) panic msg; } while (0)
#else
#define EM_KASSERT(exp,msg)
#endif

d80 1
a80 1
 *  Set this to one to display debug statistics
d87 3
a89 3

struct em_softc *em_adapter_list = NULL;

d95 1
a95 1
char em_driver_version[] = "1.6.6";
d108 1
a108 1
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82544GC_LOM },
d114 1
a114 18
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82541EI },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82540EM_LOM },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82540EP_LOM },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82540EP },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82541EP },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82547EI },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82546EB_QUAD },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82540EP_LP },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82546GB_COPPER },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82546GB_FIBER },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82546GB_SERDES },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82545GM_COPPER },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82545GM_FIBER },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82545GM_SERDES },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82547GI },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82541GI },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82541GI_MOBILE },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82541ER }
d118 1
a118 1
 *  Function prototypes
d129 1
a129 1
int  em_ioctl(struct ifnet *, u_long, caddr_t);
d153 1
a153 1
void em_process_receive_interrupts(struct em_softc *, int);
d155 1
a155 1
				     struct em_rx_desc *,
d157 1
d160 1
d163 1
d169 1
a169 1
int  em_get_buf(int i, struct em_softc *,
d171 6
a176 12
void em_enable_vlans(struct em_softc *);
int  em_encap(struct em_softc *, struct mbuf *);
void em_smartspeed(struct em_softc *);
int  em_82547_fifo_workaround(struct em_softc *, int);
void em_82547_update_fifo_head(struct em_softc *, int);
int  em_82547_tx_fifo_reset(struct em_softc *);
void em_82547_move_tail(void *);
int  em_dma_malloc(struct em_softc *, bus_size_t,
    struct em_dma_alloc *, int);
void em_dma_free(struct em_softc *, struct em_dma_alloc *);
void em_print_debug_info(struct em_softc *);
int  em_is_valid_ether_addr(u_int8_t *);
d179 1
a179 1
 *  FreeBSD Device Interface Entry Points		     
a214 1
 *  return 0 on success, positive on failure
d220 1
a220 1
	struct pci_attach_args *pa = aux;
d225 2
a226 3
	int		s;
	int		tsize, rsize;
	int		error = 0;
a230 13
#ifdef __FreeBSD__
	/* Allocate, clear, and link in our sc structure */
	if (!(sc = device_get_softc(dev))) {
		printf("em: sc structure allocation failed\n");
		splx(s);
		return(ENOMEM);
	}
	bzero(sc, sizeof(struct em_softc ));
	sc->dev = dev;
	sc->osdep.dev = dev;
	sc->sc_dv.dv_xname = device_get_unit(dev);
#endif /* __FreeBSD__ */

d233 1
a233 37
	if (em_adapter_list != NULL)
		em_adapter_list->prev = sc;
	sc->next = em_adapter_list;
	em_adapter_list = sc;

#ifdef __FreeBSD__
	/* SYSCTL stuff */
	sysctl_ctx_init(&sc->sysctl_ctx);
	sc->sysctl_tree = SYSCTL_ADD_NODE(&sc->sysctl_ctx,
					       SYSCTL_STATIC_CHILDREN(_hw),
					       OID_AUTO,
					       device_get_nameunit(dev),
					       CTLFLAG_RD,
					       0, "");
	if (sc->sysctl_tree == NULL) {
		error = EIO;
		goto err_sysctl;
	}

	SYSCTL_ADD_PROC(&sc->sysctl_ctx,
			SYSCTL_CHILDREN(sc->sysctl_tree),
			OID_AUTO, "debug_info", CTLTYPE_INT|CTLFLAG_RW,
			(void *)sc, 0,
			em_sysctl_debug_info, "I", "Debug Information");

	SYSCTL_ADD_PROC(&sc->sysctl_ctx,
			SYSCTL_CHILDREN(sc->sysctl_tree),
			OID_AUTO, "stats", CTLTYPE_INT|CTLFLAG_RW,
			(void *)sc, 0,
			em_sysctl_stats, "I", "Statistics");

	callout_handle_init(&sc->timer_handle);
	callout_handle_init(&sc->tx_fifo_timer_handle);
#endif /* __FreeBSD__ */

	timeout_set(&sc->timer_handle, em_local_timer, sc);
	timeout_set(&sc->tx_fifo_timer_handle, em_82547_move_tail, sc);
d239 4
a242 6
	sc->num_tx_desc = EM_MAX_TXD;
	sc->num_rx_desc = EM_MAX_RXD;
	sc->tx_int_delay = EM_TIDV;
	sc->tx_abs_int_delay = EM_TADV;
	sc->rx_int_delay = EM_RDTR;
	sc->rx_abs_int_delay = EM_RADV;
a248 4
	/*
	 * These parameters control the automatic generation(Tx) and
	 * response(Rx) to Ethernet PAUSE frames.
	 */
d255 1
a255 6
	sc->hw.phy_init_script = 1;

	/*
	 * Set the max frame size assuming standard ethernet
	 * sized frames
	 */
d257 1
a257 1
	    ETHERMTU + ETHER_HDR_LEN + ETHER_CRC_LEN;
d260 1
a260 7
	    MINIMUM_ETHERNET_PACKET_SIZE + ETHER_CRC_LEN;

	/*
	 * This controls when hardware reports transmit completion
	 * status.
	 */
	sc->hw.report_tx_early = 1;
d262 10
d276 3
a278 2
		error = ENXIO;
		goto err_pci;
a280 4

	/* Initialize eeprom parameters */
	em_init_eeprom_params(&sc->hw);

d285 2
a286 2
	if (em_dma_malloc(sc, tsize, &sc->txdma, BUS_DMA_NOWAIT)) {
		printf("%s: Unable to allocate tx_desc memory\n", 
d288 3
a290 2
		error = ENOMEM;
		goto err_tx_desc;
d292 2
a293 1
	sc->tx_desc_base = (struct em_tx_desc *)sc->txdma.dma_vaddr;
d299 1
a299 1
	if (em_dma_malloc(sc, rsize, &sc->rxdma, BUS_DMA_NOWAIT)) {
d302 4
a305 2
		error = ENOMEM;
		goto err_rx_desc;
d307 2
a308 1
	sc->rx_desc_base = (struct em_rx_desc *) sc->rxdma.dma_vaddr;
d314 5
a318 2
		error = EIO;
		goto err_hw_init;
d325 1
a325 8
		error = EIO;
		goto err_mac_addr;
	}

	if (!em_is_valid_ether_addr(sc->hw.mac_addr)) {
		printf("%s: Invalid mac address\n", sc->sc_dv.dv_xname);
		error = EIO;
		goto err_mac_addr;
d328 2
a329 2
	bcopy(sc->hw.mac_addr, sc->interface_data.ac_enaddr,
	      ETHER_ADDR_LEN);
d331 1
a331 1
	printf(", address: %s\n", ether_sprintf(sc->interface_data.ac_enaddr));
a349 17
	return;

err_mac_addr:
err_hw_init:
	em_dma_free(sc, &sc->rxdma);
err_rx_desc:
	em_dma_free(sc, &sc->txdma);
err_tx_desc:
err_pci:
	em_free_pci_resources(sc);
#ifdef __FreeBSD__
	sysctl_ctx_free(&sc->sysctl_ctx);
#endif /* __FreeBSD__ */
/*err_sysctl:*/
	splx(s);
	return;

d356 1
a356 1
 *  This routine stops the adapter and deallocates all the resources
d361 1
a361 1
#ifdef __FreeBSD__
d366 2
a367 2
	struct ifnet   *ifp = &sc->interface_data.ac_if;
	int		s;
d374 2
a375 5
#if __FreeBSD_version < 500000
	ether_ifdetach(&sc->interface_data.ac_if, ETHER_BPF_SUPPORTED);
#else
	ether_ifdetach(&sc->interface_data.ac_if);
#endif
d380 1
a380 1
		em_dma_free(sc, &sc->txdma);
d386 1
a386 1
		em_dma_free(sc, &sc->rxdma);
d390 4
a393 3
	/* Remove from the adapter list */
	if (em_adapter_list == sc)
		em_adapter_list = sc->next;
d398 1
a406 6
/*********************************************************************
 *
 *  Shutdown entry point
 *
 **********************************************************************/

d415 1
a415 1
#endif /* __FreeBSD__ */
d430 1
a430 1
	int		s;
d432 5
a436 1
	struct em_softc *sc = ifp->if_softc;
d441 6
a446 1
	s = splimp();	   
a447 1
	for (;;) {
d452 4
a455 1
		if (em_encap(sc, m_head)) {
d457 1
d461 18
d481 75
d557 4
a560 1
		/* Send a copy of the frame to the BPF listener */
d565 9
a573 2
		/* Set timeout in case hardware has problems transmitting */
		ifp->if_timer = EM_TX_TIMEOUT;
a574 1
	}	
d576 4
d593 1
a593 1
em_ioctl(struct ifnet *ifp, u_long command, caddr_t data)
d595 1
a595 1
	int		s, error = 0;
d602 4
a605 4
	if ((error = ether_ioctl(ifp, &sc->interface_data, command, data)) > 0) {
		splx(s);
		return (error);
	}
a608 6
#ifdef __FreeBSD__
	case SIOCGIFADDR:
		IOCTL_DEBUGOUT("ioctl rcv'd: SIOCxIFADDR (Get/Set Interface Addr)");
		ether_ioctl(ifp, command, data);
		break;
#endif /* __FreeBSD__ */
d612 1
a612 2
		em_init(sc);
		switch (ifa->ifa_addr->sa_family) {
d614 4
a617 3
		case AF_INET:
			arp_ifinit(&sc->interface_data, ifa);
			break;
d619 4
a622 3
		default:
			break;
		}
d636 2
a637 1
		IOCTL_DEBUGOUT("ioctl rcv'd: SIOCSIFFLAGS (Set Interface Flags)");
d639 7
a645 1
			if (!(ifp->if_flags & IFF_RUNNING))
a646 3

			em_disable_promisc(sc);
			em_set_promisc(sc);
d656 13
a668 3
		error = (command == SIOCADDMULTI)
			? ether_addmulti(ifr, &sc->interface_data)
			: ether_delmulti(ifr, &sc->interface_data);
d670 2
a671 2
		if (error == ENETRESET) {
			if (ifp->if_flags & IFF_RUNNING) {
d674 1
a674 1
				if (sc->hw.mac_type == em_82542_rev2_0) {
d676 1
a676 5
				}
#ifdef DEVICE_POLLING
				if (!(ifp->if_ipending & IFF_POLLING))
#endif
					em_enable_intr(sc);
d678 2
a679 2
			error = 0;
		}
d683 2
a684 1
		IOCTL_DEBUGOUT("ioctl rcv'd: SIOCxIFMEDIA (Get/Set Interface Media)");
d687 1
a687 1
#ifdef __FreeBSD__
d700 1
a700 1
#endif /* __FreeBSD__ */
d702 2
a703 1
		IOCTL_DEBUGOUT1("ioctl received: UNKNOWN (0x%d)\n", (int)command);
d711 110
d854 50
d917 1
a917 1
	int		s;
d919 1
a919 1
	struct em_softc * sc = arg;
d935 1
a935 1
	/* em_enable_vlans(sc); */
d960 1
a960 1
	ifp = &sc->interface_data.ac_if;
d964 1
a964 1
#ifdef __FreeBSD__
d971 1
a971 1
#endif /* __FreeBSD__ */
d973 1
a973 1
	timeout_add(&sc->timer_handle, 2*hz);
d975 1
a975 10
#ifdef DEVICE_POLLING
        /*
         * Only enable interrupts if we are not polling, make sure
         * they are off otherwise.
         */
        if (ifp->if_ipending & IFF_POLLING)
                em_disable_intr(sc);
        else
#endif /* DEVICE_POLLING */
		em_enable_intr(sc);
d982 6
a987 2
#ifdef DEVICE_POLLING
static poll_handler_t em_poll;
d989 2
a990 2
static void
em_poll(struct ifnet *ifp, enum poll_cmd cmd, int count)
d992 11
a1002 2
	struct em_softc *sc = ifp->if_softc;
	u_int32_t reg_icr;
d1004 2
a1005 18
	if (cmd == POLL_DEREGISTER) {	    /* final call, enable interrupts */
		em_enable_intr(sc);
		return;
	}
	if (cmd == POLL_AND_CHECK_STATUS) {
		reg_icr = E1000_READ_REG(&sc->hw, ICR);
		if (reg_icr & (E1000_ICR_RXSEQ | E1000_ICR_LSC)) {
			untimeout(em_local_timer, sc, sc->timer_handle);
			sc->hw.get_link_status = 1;
			em_check_for_link(&sc->hw);
			em_print_link_status(sc);
			sc->timer_handle = timeout(em_local_timer, sc, 2*hz);
		}
	}
	if (ifp->if_flags & IFF_RUNNING) {
		em_process_receive_interrupts(sc, count);
		em_clean_transmit_interrupts(sc);
	}
d1007 1
a1007 2
	if (ifp->if_flags & IFF_RUNNING && ifp->if_snd.ifq_head != NULL)
		em_start(ifp);
a1008 1
#endif /* DEVICE_POLLING */
d1015 1
d1019 4
a1022 4
	u_int32_t	loop_cnt = EM_MAX_INTR;
	u_int32_t	reg_icr;
	struct ifnet	*ifp;
	struct em_softc *sc = arg;
d1024 1
a1024 1
	ifp = &sc->interface_data.ac_if;
d1026 3
a1028 3
#ifdef DEVICE_POLLING
	if (ifp->if_ipending & IFF_POLLING)
		return;
d1030 8
a1037 19
	if (ether_poll_register(em_poll, ifp)) {
		em_disable_intr(sc);
		em_poll(ifp, 0, 1);
		return;
	}
#endif /* DEVICE_POLLING */
	reg_icr = E1000_READ_REG(&sc->hw, ICR);
	if (!reg_icr) {
		return (0);
	}

	/* Link status change */
	if (reg_icr & (E1000_ICR_RXSEQ | E1000_ICR_LSC)) {
		timeout_del(&sc->timer_handle);
		sc->hw.get_link_status = 1;
		em_check_for_link(&sc->hw);
		em_print_link_status(sc);
		timeout_add(&sc->timer_handle, 2*hz); 
	}
a1038 1
	while (loop_cnt > 0) {
d1040 1
a1040 1
			em_process_receive_interrupts(sc, -1);
d1046 2
d1051 1
a1051 1
	return (1);
a1054 1

d1128 1
a1128 1
	struct ifmedia	*ifm = &sc->media;
d1169 1
a1169 455

#ifdef __FreeBSD__
void
em_tx_cb(void *arg, bus_dma_segment_t *seg, int nsegs, bus_size_t mapsize, int error)
{
	struct em_q *q = arg;

	if (error)
		return;
	EM_KASSERT(nsegs <= EM_MAX_SCATTER,
		("Too many DMA segments returned when mapping tx packet"));
	q->nsegs = nsegs;
	bcopy(seg, q->segs, nsegs * sizeof(seg[0]));
}
#endif /* __FreeBSD__ */

#define EM_FIFO_HDR		 0x10
#define EM_82547_PKT_THRESH	 0x3e0
#define EM_82547_TX_FIFO_SIZE	 0x2800
#define EM_82547_TX_FIFO_BEGIN	 0xf00
/*********************************************************************
 *
 *  This routine maps the mbufs to tx descriptors.
 *
 *  return 0 on success, positive on failure
 **********************************************************************/
int
em_encap(struct em_softc *sc, struct mbuf *m_head)
{
	u_int32_t	txd_upper;
	u_int32_t	txd_lower;
	int		i, j, error;
#if NVLAN > 0
	struct ifvlan *ifv = NULL;
#endif
	struct em_q	q;

	struct em_buffer   *tx_buffer = NULL;
	struct em_tx_desc *current_tx_desc = NULL;
	/*struct ifnet	 *ifp = &sc->interface_data.ac_if;*/

	/*
	 * Force a cleanup if number of TX descriptors
	 * available hits the threshold
	 */
	if (sc->num_tx_desc_avail <= EM_TX_CLEANUP_THRESHOLD) {
		em_clean_transmit_interrupts(sc);
		if (sc->num_tx_desc_avail <= EM_TX_CLEANUP_THRESHOLD) {
			sc->no_tx_desc_avail1++;
			return (ENOBUFS);
		}
	}

	/*
	 * Map the packet for DMA.
	 */
	if (bus_dmamap_create(sc->txtag, MCLBYTES, 32, 0, 0, BUS_DMA_NOWAIT,
	    &q.map)) {
		sc->no_tx_map_avail++;
		return (ENOMEM);
	}
	error = bus_dmamap_load_mbuf(sc->txtag, q.map,
				     m_head, BUS_DMA_NOWAIT);
	if (error != 0) {
		sc->no_tx_dma_setup++;
		bus_dmamap_destroy(sc->txtag, q.map);
		return (error);
	}
	EM_KASSERT(q.map->dm_nsegs!= 0, ("em_encap: empty packet"));

	if (q.map->dm_nsegs > sc->num_tx_desc_avail) {
		sc->no_tx_desc_avail2++;
		bus_dmamap_destroy(sc->txtag, q.map);
		return (ENOBUFS);
	}


#ifdef __FreeBSD__
	if (ifp->if_hwassist > 0) {
		em_transmit_checksum_setup(sc,	m_head,
					   &txd_upper, &txd_lower);
	} else
#endif /* __FreeBSD__ */
		txd_upper = txd_lower = 0;


	/* Find out if we are in vlan mode */
#if NVLAN > 0
	if ((m_head->m_flags & (M_PROTO1|M_PKTHDR)) == (M_PROTO1|M_PKTHDR) &&
	    m_head->m_pkthdr.rcvif != NULL &&
	    m_head->m_pkthdr.rcvif->if_type == IFT_L2VLAN)
		ifv = m_head->m_pkthdr.rcvif->if_softc;
#endif

	i = sc->next_avail_tx_desc;
	for (j = 0; j < q.map->dm_nsegs; j++) {
		tx_buffer = &sc->tx_buffer_area[i];
		current_tx_desc = &sc->tx_desc_base[i];

		current_tx_desc->buffer_addr = htole64(q.map->dm_segs[j].ds_addr);
		current_tx_desc->lower.data = htole32(
		    sc->txd_cmd | txd_lower | q.map->dm_segs[j].ds_len);
		current_tx_desc->upper.data = htole32(txd_upper);

		if (++i == sc->num_tx_desc)
			i = 0;
		
		tx_buffer->m_head = NULL;
	}

	sc->num_tx_desc_avail -= q.map->dm_nsegs;
	sc->next_avail_tx_desc = i;

#if NVLAN > 0
	if (ifv != NULL) {
		/* Set the vlan id */
		current_tx_desc->upper.fields.special = htole16(ifv->ifv_tag);

		/* Tell hardware to add tag */
		current_tx_desc->lower.data |= htole32(E1000_TXD_CMD_VLE);
	}
#endif

	tx_buffer->m_head = m_head;
	tx_buffer->map = q.map;
	bus_dmamap_sync(sc->txtag, q.map, 0, q.map->dm_mapsize,
	    BUS_DMASYNC_PREWRITE);

	/* 
	 * Last Descriptor of Packet needs End Of Packet (EOP) 
	 */
	current_tx_desc->lower.data |= htole32(E1000_TXD_CMD_EOP);

	/* 
	 * Advance the Transmit Descriptor Tail (Tdt), this tells the E1000
	 * that this frame is available to transmit.
	 */
	if (sc->hw.mac_type == em_82547 &&
	    sc->link_duplex == HALF_DUPLEX) {
		em_82547_move_tail(sc);
	} else {
		E1000_WRITE_REG(&sc->hw, TDT, i);
		if (sc->hw.mac_type == em_82547) {
			em_82547_update_fifo_head(sc, m_head->m_pkthdr.len);
		}
	}

	return (0);
}

/*********************************************************************
 *
 * 82547 workaround to avoid controller hang in half-duplex environment.
 * The workaround is to avoid queuing a large packet that would span
 * the internal Tx FIFO ring boundary. We need to reset the FIFO pointers
 * in this case. We do that only when FIFO is queiced.
 *
 **********************************************************************/
void
em_82547_move_tail(void *arg)
{
	int s;
	struct em_softc *sc = arg;
	uint16_t hw_tdt;
	uint16_t sw_tdt;
	struct em_tx_desc *tx_desc;
	uint16_t length = 0;
	boolean_t eop = 0;

	s = splimp();
	hw_tdt = E1000_READ_REG(&sc->hw, TDT);
	sw_tdt = sc->next_avail_tx_desc;

	while (hw_tdt != sw_tdt) {
		tx_desc = &sc->tx_desc_base[hw_tdt];
		length += tx_desc->lower.flags.length;
		eop = tx_desc->lower.data & E1000_TXD_CMD_EOP;
		if(++hw_tdt == sc->num_tx_desc)
			hw_tdt = 0;

		if(eop) {
			if (em_82547_fifo_workaround(sc, length)) {
				sc->tx_fifo_wrk++;
				timeout_add(&sc->tx_fifo_timer_handle, 1);
				splx(s);
				return;
			}
			else {
				E1000_WRITE_REG(&sc->hw, TDT, hw_tdt);
				em_82547_update_fifo_head(sc, length);
				length = 0;
			}
		}
	}
	splx(s);
	return;
}

int
em_82547_fifo_workaround(struct em_softc *sc, int len)
{
	int fifo_space, fifo_pkt_len;

	fifo_pkt_len = EM_ROUNDUP(len + EM_FIFO_HDR, EM_FIFO_HDR);

	if (sc->link_duplex == HALF_DUPLEX) {
		fifo_space = EM_82547_TX_FIFO_SIZE - sc->tx_fifo_head;

		if (fifo_pkt_len >= (EM_82547_PKT_THRESH + fifo_space)) {
			if (em_82547_tx_fifo_reset(sc)) {
				return(0);
			}
			else {
				return(1);
			}
		}
	}

	return(0);
}

void
em_82547_update_fifo_head(struct em_softc *sc, int len)
{
	int fifo_pkt_len = EM_ROUNDUP(len + EM_FIFO_HDR, EM_FIFO_HDR);

	/* tx_fifo_head is always 16 byte aligned */
	sc->tx_fifo_head += fifo_pkt_len;
	if (sc->tx_fifo_head >= EM_82547_TX_FIFO_SIZE) {
		sc->tx_fifo_head -= EM_82547_TX_FIFO_SIZE;
	}

	return;
}


int
em_82547_tx_fifo_reset(struct em_softc *sc)
{
	uint32_t tctl;

	if ( (E1000_READ_REG(&sc->hw, TDT) ==
	      E1000_READ_REG(&sc->hw, TDH)) &&
	     (E1000_READ_REG(&sc->hw, TDFT) ==
	      E1000_READ_REG(&sc->hw, TDFH)) &&
	     (E1000_READ_REG(&sc->hw, TDFTS) ==
	      E1000_READ_REG(&sc->hw, TDFHS)) &&
	     (E1000_READ_REG(&sc->hw, TDFPC) == 0)) {

		/* Disable TX unit */
		tctl = E1000_READ_REG(&sc->hw, TCTL);
		E1000_WRITE_REG(&sc->hw, TCTL, tctl & ~E1000_TCTL_EN);

		/* Reset FIFO pointers */
		E1000_WRITE_REG(&sc->hw, TDFT, EM_82547_TX_FIFO_BEGIN);
		E1000_WRITE_REG(&sc->hw, TDFH, EM_82547_TX_FIFO_BEGIN);
		E1000_WRITE_REG(&sc->hw, TDFTS, EM_82547_TX_FIFO_BEGIN);
		E1000_WRITE_REG(&sc->hw, TDFHS, EM_82547_TX_FIFO_BEGIN);

		/* Re-enable TX unit */
		E1000_WRITE_REG(&sc->hw, TCTL, tctl);
		E1000_WRITE_FLUSH(&sc->hw);

		sc->tx_fifo_head = 0;
		sc->tx_fifo_reset++;

		return(TRUE);
	}
	else {
		return(FALSE);
	}
}

void
em_set_promisc(struct em_softc * sc)
{

	u_int32_t	reg_rctl;
	struct ifnet   *ifp = &sc->interface_data.ac_if;

	reg_rctl = E1000_READ_REG(&sc->hw, RCTL);

	if (ifp->if_flags & IFF_PROMISC) {
		reg_rctl |= (E1000_RCTL_UPE | E1000_RCTL_MPE);
		E1000_WRITE_REG(&sc->hw, RCTL, reg_rctl);
	} else if (ifp->if_flags & IFF_ALLMULTI) {
		reg_rctl |= E1000_RCTL_MPE;
		reg_rctl &= ~E1000_RCTL_UPE;
		E1000_WRITE_REG(&sc->hw, RCTL, reg_rctl);
	}

	return;
}

void
em_disable_promisc(struct em_softc * sc)
{
	u_int32_t	reg_rctl;

	reg_rctl = E1000_READ_REG(&sc->hw, RCTL);

	reg_rctl &=  (~E1000_RCTL_UPE);
	reg_rctl &=  (~E1000_RCTL_MPE);
	E1000_WRITE_REG(&sc->hw, RCTL, reg_rctl);

	return;
}


/*********************************************************************
 *  Multicast Update
 *
 *  This routine is called whenever multicast address list is updated.
 *
 **********************************************************************/

void
em_set_multi(struct em_softc * sc)
{
	u_int32_t reg_rctl = 0;
	u_int8_t  mta[MAX_NUM_MULTICAST_ADDRESSES * ETH_LENGTH_OF_ADDRESS];
	struct arpcom *ac = &sc->interface_data;
	struct ether_multi *enm;
	struct ether_multistep step;
	int mcnt = 0;
	struct ifnet *ifp = &sc->interface_data.ac_if;

	IOCTL_DEBUGOUT("em_set_multi: begin");

	if (sc->hw.mac_type == em_82542_rev2_0) {
		reg_rctl = E1000_READ_REG(&sc->hw, RCTL);
		if (sc->hw.pci_cmd_word & CMD_MEM_WRT_INVALIDATE) {
			em_pci_clear_mwi(&sc->hw);
		}
		reg_rctl |= E1000_RCTL_RST;
		E1000_WRITE_REG(&sc->hw, RCTL, reg_rctl);
		msec_delay(5);
	}

	ETHER_FIRST_MULTI(step, ac, enm);
	while (enm != NULL) {
		if (bcmp(enm->enm_addrlo, enm->enm_addrhi, ETHER_ADDR_LEN)) {
			ifp->if_flags |= IFF_ALLMULTI;
			mcnt = MAX_NUM_MULTICAST_ADDRESSES;
		}
		if (mcnt == MAX_NUM_MULTICAST_ADDRESSES)
			break;
		bcopy(enm->enm_addrlo, &mta[mcnt*ETH_LENGTH_OF_ADDRESS],
		      ETH_LENGTH_OF_ADDRESS);
		mcnt++;
		ETHER_NEXT_MULTI(step, enm);
	}

	if (mcnt >= MAX_NUM_MULTICAST_ADDRESSES) {
		reg_rctl = E1000_READ_REG(&sc->hw, RCTL);
		reg_rctl |= E1000_RCTL_MPE;
		E1000_WRITE_REG(&sc->hw, RCTL, reg_rctl);
	} else
		em_mc_addr_list_update(&sc->hw, mta, mcnt, 0);

	if (sc->hw.mac_type == em_82542_rev2_0) {
		reg_rctl = E1000_READ_REG(&sc->hw, RCTL);
		reg_rctl &= ~E1000_RCTL_RST;
		E1000_WRITE_REG(&sc->hw, RCTL, reg_rctl);
		msec_delay(5);
		if (sc->hw.pci_cmd_word & CMD_MEM_WRT_INVALIDATE) {
			em_pci_set_mwi(&sc->hw);
		}
	}

	return;
}


/*********************************************************************
 *  Timer routine
 *
 *  This routine checks for link status and updates statistics.
 *
 **********************************************************************/

void
em_local_timer(void *arg)
{
	int s;
	struct ifnet   *ifp;
	struct em_softc * sc = arg;
	ifp = &sc->interface_data.ac_if;

	s = splimp();

	em_check_for_link(&sc->hw);
	em_print_link_status(sc);
	em_update_stats_counters(sc);	
	if (em_display_debug_stats && ifp->if_flags & IFF_RUNNING) {
		em_print_hw_stats(sc);
	}
	em_smartspeed(sc);

	timeout_add(&sc->timer_handle, 2*hz);

	splx(s);
	return;
}

void
em_print_link_status(struct em_softc * sc)
{
	if (E1000_READ_REG(&sc->hw, STATUS) & E1000_STATUS_LU) {
		if (sc->link_active == 0) {
			em_get_speed_and_duplex(&sc->hw, 
						&sc->link_speed, 
						&sc->link_duplex);
			sc->link_active = 1;
			sc->smartspeed = 0;
		}
	} else {
		if (sc->link_active == 1) {
			sc->link_speed = 0;
			sc->link_duplex = 0;
			sc->link_active = 0;
		}
	}

	return;
}

/*********************************************************************
 *
 *  This routine disables all traffic on the sc by issuing a
 *  global reset on the MAC and deallocates TX/RX buffers. 
 *
 **********************************************************************/

void
em_stop(void *arg)
{
	struct ifnet   *ifp;
	struct em_softc * sc = arg;
	ifp = &sc->interface_data.ac_if;

	INIT_DEBUGOUT("em_stop: begin\n");
	em_disable_intr(sc);
	em_reset_hw(&sc->hw);
	timeout_del(&sc->timer_handle);
	timeout_del(&sc->tx_fifo_timer_handle);
	em_free_transmit_structures(sc);
	em_free_receive_structures(sc);


	/* Tell the stack that the interface is no longer active */
	ifp->if_flags &= ~(IFF_RUNNING | IFF_OACTIVE);

	return;
}
d1188 1
a1188 1
		printf("%s: Memory Access and/or Bus Master bits were not set!\n", 
d1208 30
a1237 4
	/* Identify the MAC */
	if (em_set_mac_type(&sc->hw))
		printf("%s: Unknown MAC Type\n", sc->sc_dv.dv_xname);

d1244 3
a1246 3
	int		i, val, rid;
	pci_intr_handle_t	ih;
	const char		*intrstr = NULL;
d1248 1
a1248 1
	pci_chipset_tag_t	pc = pa->pa_pc;
d1254 3
a1256 3
	}
	if (pci_mapreg_map(pa, EM_MMBA, PCI_MAPREG_MEM_TYPE(val), 0,
	    &sc->osdep.mem_bus_space_tag, &sc->osdep.mem_bus_space_handle,
d1262 12
d1285 1
a1285 1
		if (pci_mapreg_map(pa, rid, PCI_MAPREG_TYPE_IO, 0,
d1290 3
a1292 3
			printf(": can't find io space");
			return (ENXIO);
		}
d1295 4
a1298 4
	if (pci_intr_map(pa, &ih)) {
		printf(": couldn't map interrupt\n");
		return (ENXIO);
	}
d1300 8
a1307 8
	intrstr = pci_intr_string(pc, ih);
	sc->sc_intrhand = pci_intr_establish(pc, ih, IPL_NET, em_intr, sc,
					      sc->sc_dv.dv_xname);
	if (sc->sc_intrhand == NULL) {
		printf(": couldn't establish interrupt");
		if (intrstr != NULL)
			printf(" at %s", intrstr);
		printf("\n");
d1309 2
a1310 2
	}
	printf(": %s", intrstr);
d1321 1
a1321 1
	pci_chipset_tag_t	pc = pa->pa_pc;
d1333 1
a1333 1
		bus_space_unmap(sc->osdep.mem_bus_space_tag, sc->osdep.mem_bus_space_handle,
a1352 3
	/* When hardware is reset, fifo_head is also reset */
	sc->tx_fifo_head = 0;

d1401 1
a1401 1
	ifp = &sc->interface_data.ac_if;
d1405 2
a1406 2
#ifdef __FreeBSD__
	ifp->if_init =	em_init;
d1416 1
a1416 1
	strlcpy(ifp->if_xname, sc->sc_dv.dv_xname, IFNAMSIZ);
d1418 2
a1419 1
#ifdef __FreeBSD__
d1424 1
a1424 13

	/*
	 * Tell the upper layer(s) we support long frames.
	 */
	ifp->if_data.ifi_hdrlen = sizeof(struct ehter_vlan_header);
#if __FreeBSD_version >= 500000
	ifp->if_capabilities |= IFCAP_VLAN_HWTAGGING | IFCAP_VLAN_MTU;
#endif
#endif /* __FreeBSD__ */

#ifdef __OpenBSD__
	ifp->if_capabilities |= IFCAP_VLAN_MTU;
#endif
d1427 1
a1427 1
	 * Specify the media types supported by this adapter and register
a1460 169
 *  Workaround for SmartSpeed on 82541 and 82547 controllers
 *
 **********************************************************************/	
void
em_smartspeed(struct em_softc *sc)
{
	uint16_t phy_tmp;
 
	if(sc->link_active || (sc->hw.phy_type != em_phy_igp) || 
	   !sc->hw.autoneg || !(sc->hw.autoneg_advertised & ADVERTISE_1000_FULL))
		return;

	if(sc->smartspeed == 0) {
		/* If Master/Slave config fault is asserted twice,
		 * we assume back-to-back */
		em_read_phy_reg(&sc->hw, PHY_1000T_STATUS, &phy_tmp);
		if(!(phy_tmp & SR_1000T_MS_CONFIG_FAULT)) return;
		em_read_phy_reg(&sc->hw, PHY_1000T_STATUS, &phy_tmp);
		if(phy_tmp & SR_1000T_MS_CONFIG_FAULT) {
			em_read_phy_reg(&sc->hw, PHY_1000T_CTRL,
					&phy_tmp);
			if(phy_tmp & CR_1000T_MS_ENABLE) {
				phy_tmp &= ~CR_1000T_MS_ENABLE;
				em_write_phy_reg(&sc->hw,
						    PHY_1000T_CTRL, phy_tmp);
				sc->smartspeed++;
				if(sc->hw.autoneg &&
				   !em_phy_setup_autoneg(&sc->hw) &&
				   !em_read_phy_reg(&sc->hw, PHY_CTRL,
						       &phy_tmp)) {
					phy_tmp |= (MII_CR_AUTO_NEG_EN |  
						    MII_CR_RESTART_AUTO_NEG);
					em_write_phy_reg(&sc->hw,
							 PHY_CTRL, phy_tmp);
				}
			}
		}
		return;
	} else if(sc->smartspeed == EM_SMARTSPEED_DOWNSHIFT) {
		/* If still no link, perhaps using 2/3 pair cable */
		em_read_phy_reg(&sc->hw, PHY_1000T_CTRL, &phy_tmp);
		phy_tmp |= CR_1000T_MS_ENABLE;
		em_write_phy_reg(&sc->hw, PHY_1000T_CTRL, phy_tmp);
		if(sc->hw.autoneg &&
		   !em_phy_setup_autoneg(&sc->hw) &&
		   !em_read_phy_reg(&sc->hw, PHY_CTRL, &phy_tmp)) {
			phy_tmp |= (MII_CR_AUTO_NEG_EN |
				    MII_CR_RESTART_AUTO_NEG);
			em_write_phy_reg(&sc->hw, PHY_CTRL, phy_tmp);
		}
	}
	/* Restart process after EM_SMARTSPEED_MAX iterations */
	if(sc->smartspeed++ == EM_SMARTSPEED_MAX)
		sc->smartspeed = 0;

	return;
}


/*
 * Manage DMA'able memory.
 */

#ifdef __FreeBSD__
void
em_dmamap_cb(void *arg, bus_dma_segment_t *segs, int nseg, int error)
{ 
	if (error)
		return;
	*(bus_addr_t*) arg = segs->ds_addr;
	return;
}
#endif /* __FreeBSD__ */

int
em_dma_malloc(struct em_softc *sc, bus_size_t size,
	struct em_dma_alloc *dma, int mapflags)
{
	int r;

#ifdef __FreeBSD__
	r = bus_dma_tag_create(NULL,			/* parent */
			       PAGE_SIZE, 0,		/* alignment, bounds */
			       BUS_SPACE_MAXADDR,	/* lowaddr */
			       BUS_SPACE_MAXADDR,	/* highaddr */
			       NULL, NULL,		/* filter, filterarg */
			       size,			/* maxsize */
			       1,			/* nsegments */
			       size,			/* maxsegsize */
			       BUS_DMA_ALLOCNOW,	/* flags */
			       &dma->dma_tag);
	if (r != 0) {
		printf("%s: em_dma_malloc: bus_dma_tag_create failed; "
			"error %u\n", sc->sc_dv.dv_xname, r);
		goto fail_0;
	}

	r = bus_dmamap_create(dma->dma_tag, BUS_DMA_NOWAIT, &dma->dma_map);
#endif /* __FreeBSD__ */
	dma->dma_tag = sc->osdep.em_pa.pa_dmat;
	r = bus_dmamap_create(dma->dma_tag, size, 1,
	    size, 0, BUS_DMA_NOWAIT, &dma->dma_map);

	if (r != 0) {
		printf("%s: em_dma_malloc: bus_dmamap_create failed; "
			"error %u\n", sc->sc_dv.dv_xname, r);
		goto fail_0;
	}

	r = bus_dmamem_alloc(dma->dma_tag, size, PAGE_SIZE, 0, &dma->dma_seg,
	    1, &dma->dma_nseg, BUS_DMA_NOWAIT);
	if (r != 0) {
		printf("%s: em_dma_malloc: bus_dmammem_alloc failed; "
			"size %lu, error %d\n", sc->sc_dv.dv_xname,
			(unsigned long)size, r);
		goto fail_1;
	}

	r = bus_dmamem_map(dma->dma_tag, &dma->dma_seg, dma->dma_nseg, size,
	    &dma->dma_vaddr, BUS_DMA_NOWAIT);
	if (r != 0) {
		printf("%s: em_dma_malloc: bus_dmammem_map failed; "
			"size %lu, error %d\n", sc->sc_dv.dv_xname,
			(unsigned long)size, r);
		goto fail_2;
	}

	r = bus_dmamap_load(sc->osdep.em_pa.pa_dmat, dma->dma_map,
			    dma->dma_vaddr,
			    size,
			    NULL,
			    mapflags | BUS_DMA_NOWAIT);
	if (r != 0) {
		printf("%s: em_dma_malloc: bus_dmamap_load failed; "
			"error %u\n", sc->sc_dv.dv_xname, r);
		goto fail_3;
	}

	dma->dma_size = size;
	return (0);

/* fail_4: */
	bus_dmamap_unload(dma->dma_tag, dma->dma_map);
fail_3:
	bus_dmamem_unmap(dma->dma_tag, dma->dma_vaddr, size);
fail_2:
	bus_dmamem_free(dma->dma_tag, &dma->dma_seg, dma->dma_nseg);
fail_1:
	bus_dmamap_destroy(dma->dma_tag, dma->dma_map);
	/* bus_dma_tag_destroy(dma->dma_tag); */
fail_0:
	dma->dma_map = NULL;
	/* dma->dma_tag = NULL; */
	return (r);
}

void
em_dma_free(struct em_softc *sc, struct em_dma_alloc *dma)
{
	bus_dmamap_unload(dma->dma_tag, dma->dma_map);
	bus_dmamem_unmap(dma->dma_tag, dma->dma_vaddr, dma->dma_size);
	bus_dmamem_free(dma->dma_tag, &dma->dma_seg, dma->dma_nseg);
	bus_dmamap_destroy(dma->dma_tag, dma->dma_map);
	/* bus_dma_tag_destroy(dma->dma_tag); */
}


/*********************************************************************
 *
d1469 1
a1469 1
	      (struct em_buffer *) malloc(sizeof(struct em_buffer) *
d1478 1
a1478 1
	      sizeof(struct em_buffer) * sc->num_tx_desc);
d1491 13
a1503 17
#ifdef __FreeBSD__
	/*
	 * Setup DMA descriptor areas.
	 */
	if (bus_dma_tag_create(NULL,	/* parent */
		    PAGE_SIZE, 0,	/* alignment, bounds */
		    BUS_SPACE_MAXADDR,       /* lowaddr */
		    BUS_SPACE_MAXADDR,       /* highaddr */
		    NULL, NULL,              /* filter, filterarg */
		    MCLBYTES * 8,            /* maxsize */
		    EM_MAX_SCATTER,          /* nsegments */
		    MCLBYTES * 8,            /* maxsegsize */
		    BUS_DMA_ALLOCNOW,        /* flags */
		    &sc->txtag)) {
		printf("%s: Unable to allocate TX DMA tag\n", sc->sc_dv.dv_xname);
		return (ENOMEM);
	}
d1505 1
a1505 2
#endif /* __FreeBSD__ */
	sc->txtag = sc->osdep.em_pa.pa_dmat;
d1507 10
a1516 2
	if (em_allocate_transmit_structures(sc))
		return (ENOMEM);
d1518 1
a1518 1
	bzero((void *) sc->tx_desc_base,
d1521 3
a1523 2
	sc->next_avail_tx_desc = 0;
	sc->oldest_used_tx_desc = 0;
d1531 1
a1531 1
	return (0);
d1542 2
a1543 3
	u_int32_t	reg_tctl;
	u_int32_t	reg_tipg = 0;
	u_int64_t	bus_addr;
d1546 3
a1548 3
	bus_addr = sc->txdma.dma_map->dm_segs[0].ds_addr;
	E1000_WRITE_REG(&sc->hw, TDBAL, (u_int32_t)bus_addr);
	E1000_WRITE_REG(&sc->hw, TDBAH, (u_int32_t)(bus_addr >> 32));
d1562 1
d1565 12
d1584 1
a1584 6
		if (sc->hw.media_type == em_media_type_fiber)
			reg_tipg = DEFAULT_82543_TIPG_IPGT_FIBER;
		else
			reg_tipg = DEFAULT_82543_TIPG_IPGT_COPPER;
			reg_tipg |= DEFAULT_82543_TIPG_IPGR1 << E1000_TIPG_IPGR1_SHIFT;
			reg_tipg |= DEFAULT_82543_TIPG_IPGR2 << E1000_TIPG_IPGR2_SHIFT;
a1585 1

a1587 2
	if(sc->hw.mac_type >= em_82540)
		E1000_WRITE_REG(&sc->hw, TADV, sc->tx_abs_int_delay);
d1600 1
a1600 1
	sc->txd_cmd = E1000_TXD_CMD_IFCS | E1000_TXD_CMD_RS;
d1605 5
d1621 2
a1622 2
	struct em_buffer   *tx_buffer;
	int		i;
d1629 1
a1629 3
			if (tx_buffer->m_head != NULL) {
				bus_dmamap_unload(sc->txtag, tx_buffer->map);
				bus_dmamap_destroy(sc->txtag, tx_buffer->map);
a1630 1
			}
d1632 5
a1642 6
	if (sc->txtag != NULL) {
#ifdef __FreeBSD__
		bus_dma_tag_destroy(sc->txtag);
#endif
		sc->txtag = NULL;
	}
d1653 1
a1653 1
#ifdef __FreeBSD__
d1657 1
d1662 1
a1662 3
	struct em_buffer *tx_buffer;
	int curr_txd;

d1694 2
a1695 3
	curr_txd = sc->next_avail_tx_desc;
	tx_buffer = &sc->tx_buffer_area[curr_txd];
	TXD = (struct em_context_desc *) &sc->tx_desc_base[curr_txd];
d1701 1
a1701 1
	    htole16(ETHER_HDR_LEN + sizeof(struct ip) - 1);
d1705 1
a1705 1
	TXD->upper_setup.tcp_fields.tucse = htole16(0);
d1717 2
a1718 2
	TXD->tcp_seg_setup.data = htole32(0);
	TXD->cmd_and_length = htole32(sc->txd_cmd | E1000_TXD_CMD_DEXT);
d1720 4
a1723 4
	tx_buffer->m_head = NULL;

	if (++curr_txd == sc->num_tx_desc)
		curr_txd = 0;
a1725 1
	sc->next_avail_tx_desc = curr_txd;
d1727 1
d1730 1
a1730 56
#endif /* __FreeBSD__ */

/**********************************************************************
 *
 *  Examine each tx_buffer in the used queue. If the hardware is done
 *  processing the packet then free associated resources. The
 *  tx_buffer is put back on the free queue. 
 *
 **********************************************************************/
void
em_clean_transmit_interrupts(struct em_softc* sc)
{
	int s;
	int i, num_avail;
	struct em_buffer *tx_buffer;
	struct em_tx_desc   *tx_desc;
	struct ifnet   *ifp = &sc->interface_data.ac_if;

	if (sc->num_tx_desc_avail == sc->num_tx_desc)
		return;

	s = splimp();
#ifdef DBG_STATS
	sc->clean_tx_interrupts++;
#endif
	num_avail = sc->num_tx_desc_avail;
	i = sc->oldest_used_tx_desc;

	tx_buffer = &sc->tx_buffer_area[i];
	tx_desc = &sc->tx_desc_base[i];

	while(tx_desc->upper.fields.status & E1000_TXD_STAT_DD) {

		tx_desc->upper.data = 0;
		num_avail++;

		if (tx_buffer->m_head) {
			ifp->if_opackets++;
			bus_dmamap_sync(sc->txtag, tx_buffer->map,
			    0, tx_buffer->map->dm_mapsize,
			    BUS_DMASYNC_POSTWRITE);
			bus_dmamap_unload(sc->txtag, tx_buffer->map);
			bus_dmamap_destroy(sc->txtag, tx_buffer->map);

			m_freem(tx_buffer->m_head);
			tx_buffer->m_head = NULL;
		}

		if (++i == sc->num_tx_desc)
			i = 0;

		tx_buffer = &sc->tx_buffer_area[i];
		tx_desc = &sc->tx_desc_base[i];
	}

	sc->oldest_used_tx_desc = i;
a1731 17
	/*
	 * If we have enough room, clear IFF_OACTIVE to tell the stack
	 * that it is OK to send packets.
	 * If there are no pending descriptors, clear the timeout. Otherwise,
	 * if some descriptors have been freed, restart the timeout.
	 */
	if (num_avail > EM_TX_CLEANUP_THRESHOLD) {
		ifp->if_flags &= ~IFF_OACTIVE;
		if (num_avail == sc->num_tx_desc)
			ifp->if_timer = 0;
		else if (num_avail == sc->num_tx_desc_avail)
			ifp->if_timer = EM_TX_TIMEOUT;
	}
	sc->num_tx_desc_avail = num_avail;
	splx(s);
	return;
}
d1739 2
a1740 2
em_get_buf(int i, struct em_softc *sc,
    struct mbuf *nmp)
d1742 1
a1742 2
	struct mbuf    *mp = nmp;
	struct em_buffer *rx_buffer;
a1743 1
	int error;
d1745 1
a1745 1
	ifp = &sc->interface_data.ac_if;
d1748 2
a1749 2
		MGETHDR(mp, M_DONTWAIT, MT_DATA);
		if (mp == NULL) {
d1753 3
a1755 3
		MCLGET(mp, M_DONTWAIT);
		if ((mp->m_flags & M_EXT) == 0) {
			m_freem(mp);
d1759 1
a1759 1
		mp->m_len = mp->m_pkthdr.len = MCLBYTES;
d1761 17
a1777 26
		mp->m_len = mp->m_pkthdr.len = MCLBYTES;
		mp->m_data = mp->m_ext.ext_buf;
		mp->m_next = NULL;
	}

	if (ifp->if_mtu <= ETHERMTU) {
		m_adj(mp, ETHER_ALIGN);
	}

	rx_buffer = &sc->rx_buffer_area[i];

	/*
	 * Using memory from the mbuf cluster pool, invoke the
	 * bus_dma machinery to arrange the memory mapping.
	 */
	error = bus_dmamap_load(sc->rxtag, rx_buffer->map,
	    mtod(mp, void *), mp->m_len, NULL,
	    0);
	if (error) {
		m_free(mp);
		return(error);
	}
	rx_buffer->m_head = mp;
	sc->rx_desc_base[i].buffer_addr = htole64(rx_buffer->map->dm_segs[0].ds_addr);
	bus_dmamap_sync(sc->rxtag, rx_buffer->map, 0,
	    rx_buffer->map->dm_mapsize, BUS_DMASYNC_PREREAD);
d1793 2
a1794 2
	int		i, error;
	struct em_buffer *rx_buffer;
d1797 1
a1797 1
	      (struct em_buffer *) malloc(sizeof(struct em_buffer) *
d1806 10
a1815 1
	      sizeof(struct em_buffer) * sc->num_rx_desc);
d1817 3
a1819 30
#ifdef __FreeBSD__
	error = bus_dma_tag_create(NULL,                /* parent */
				PAGE_SIZE, 0,            /* alignment, bounds */
				BUS_SPACE_MAXADDR,       /* lowaddr */
				BUS_SPACE_MAXADDR,       /* highaddr */
				NULL, NULL,              /* filter, filterarg */
				MCLBYTES,                /* maxsize */
				1,                       /* nsegments */
				MCLBYTES,                /* maxsegsize */
				BUS_DMA_ALLOCNOW,        /* flags */
				&sc->rxtag);
	if (error != 0) {
		printf("%s: em_allocate_receive_structures: "
			"bus_dma_tag_create failed; error %u\n",
			sc->sc_dv.dv_xname, error);
		goto fail_0;
	}
#endif /* __FreeBSD__ */
	sc->rxtag = sc->osdep.em_pa.pa_dmat;

	rx_buffer = sc->rx_buffer_area;
	for (i = 0; i < sc->num_rx_desc; i++, rx_buffer++) {
		error = bus_dmamap_create(sc->rxtag, MCLBYTES, 1,
					MCLBYTES, 0, BUS_DMA_NOWAIT,
					&rx_buffer->map);
		if (error != 0) {
			printf("%s: em_allocate_receive_structures: "
			    "bus_dmamap_create failed; error %u\n",
			    sc->sc_dv.dv_xname, error);
			goto fail_1;
d1823 1
a1823 18
	for (i = 0; i < sc->num_rx_desc; i++) {
		error = em_get_buf(i, sc, NULL);
		if (error != 0) {
			sc->rx_buffer_area[i].m_head = NULL;
			sc->rx_desc_base[i].buffer_addr = 0;
			return(error);
                }
        }

        return(0);

fail_1:
	/* bus_dma_tag_destroy(sc->rxtag); */
/* fail_0: */
	sc->rxtag = NULL;
	free(sc->rx_buffer_area, M_DEVBUF);
	sc->rx_buffer_area = NULL;
	return (error);
d1834 3
a1836 2
	bzero((void *) sc->rx_desc_base,
	    (sizeof(struct em_rx_desc)) * sc->num_rx_desc);
d1841 26
d1868 2
a1869 1
	sc->next_rx_desc_to_check = 0;
d1881 3
a1883 3
	u_int32_t	reg_rctl;
#ifdef __FreeBSD__
	u_int32_t	reg_rxcsum;
d1885 1
a1885 2
	struct ifnet	*ifp;
	u_int64_t	bus_addr;
d1887 1
a1887 1
	ifp = &sc->interface_data.ac_if;
d1889 4
a1892 1
	/* Make sure receives are disabled while setting up the descriptor ring */
a1898 10
	if(sc->hw.mac_type >= em_82540) {
		E1000_WRITE_REG(&sc->hw, RADV, sc->rx_abs_int_delay);

		/* Set the interrupt throttling rate.  Value is calculated
		 * as DEFAULT_ITR = 1/(MAX_INTS_PER_SEC * 256ns) */
#define MAX_INTS_PER_SEC	8000
#define DEFAULT_ITR		1000000000/(MAX_INTS_PER_SEC * 256)
		E1000_WRITE_REG(&sc->hw, ITR, DEFAULT_ITR);
	}

d1900 3
a1902 3
	bus_addr = sc->rxdma.dma_map->dm_segs[0].ds_addr;
	E1000_WRITE_REG(&sc->hw, RDBAL, (u_int32_t)bus_addr);
	E1000_WRITE_REG(&sc->hw, RDBAH, (u_int32_t)(bus_addr >> 32));
d1908 3
a1910 1
	E1000_WRITE_REG(&sc->hw, RDT, sc->num_rx_desc - 1);
d1928 1
a1928 1
		break;		  
d1940 1
a1940 1
#ifdef __FreeBSD__
d1948 1
a1948 1
#endif /* __FreeBSD__ */
d1964 2
a1965 2
	struct em_buffer   *rx_buffer;
	int		i;
a1971 4
			if (rx_buffer->map != NULL) {
				bus_dmamap_unload(sc->rxtag, rx_buffer->map);
				bus_dmamap_destroy(sc->rxtag, rx_buffer->map);
			}
d1975 5
a1985 4
	if (sc->rxtag != NULL) {
		/* bus_dma_tag_destroy(sc->rxtag); */
		sc->rxtag = NULL;
	}
a1994 3
 *  We loop at most count times if count is > 0, or until done if
 *  count < 0.
 *
d1997 1
a1997 1
em_process_receive_interrupts(struct em_softc* sc, int count)
d1999 2
a2000 3
	struct ifnet	    *ifp;
	struct mbuf	    *mp;
#ifdef __FreeBSD__
d2002 5
a2006 5
#endif
	u_int8_t	    accept_frame = 0;
	u_int8_t	    eop = 0;
	u_int16_t	    len, desc_len;
	int		    i;
d2010 2
d2013 2
a2014 3
	ifp = &sc->interface_data.ac_if;
	i = sc->next_rx_desc_to_check;
	current_desc = &sc->rx_desc_base[i];
d2023 1
a2023 1
	while ((current_desc->status & E1000_RXD_STAT_DD) && (count != 0)) {
d2025 2
a2026 5
		mp = sc->rx_buffer_area[i].m_head;
		bus_dmamap_sync(sc->rxtag, sc->rx_buffer_area[i].map,
		    0, sc->rx_buffer_area[i].map->dm_mapsize,
		    BUS_DMASYNC_POSTREAD);
		bus_dmamap_unload(sc->rxtag, sc->rx_buffer_area[i].map);
d2028 7
d2036 1
a2036 1
		desc_len = letoh16(current_desc->length);
a2037 1
			count--;
d2039 1
a2039 1
			len = desc_len - ETHER_CRC_LEN;
d2042 1
a2042 1
			len = desc_len;
a2045 2
			u_int8_t last_byte;
			u_int32_t pkt_len = desc_len;
d2047 3
a2049 1
			if (sc->fmp != NULL)
d2051 1
d2053 2
a2054 1
			last_byte = *(mtod(mp, caddr_t) + desc_len - 1);
d2056 2
a2057 2
			if (TBI_ACCEPT(&sc->hw, current_desc->status,
				       current_desc->errors,
d2064 1
a2064 2
			}
			else {
d2071 1
a2071 1
			if (em_get_buf(i, sc, NULL) == ENOBUFS) {
d2073 2
a2074 3
				em_get_buf(i, sc, mp);
				if (sc->fmp != NULL)
					m_freem(sc->fmp);
a2096 2
				ifp->if_ipackets++;

d2106 1
a2106 1
#ifdef __FreeBSD__
d2108 1
d2111 3
a2113 5
#endif
				em_receive_checksum(sc, current_desc,
						sc->fmp);

#ifdef __FreeBSD__
d2116 1
a2116 2
					    (letoh16(current_desc->special) &
					    E1000_RXD_SPC_VLAN_MASK));
d2118 1
a2119 3
#else /* __FreeBSD__ */
				ether_input_mbuf(ifp, sc->fmp);
#endif /* !__FreeBSD__ */
d2126 2
a2127 3
			em_get_buf(i, sc, mp);
			if (sc->fmp != NULL)
				m_freem(sc->fmp);
d2135 11
a2145 2
		/* Advance the E1000's Receive Queue #0	 "Tail Pointer". */
		E1000_WRITE_REG(&sc->hw, RDT, i);
d2147 15
a2161 6
		/* Advance our pointers to the next descriptor */
		if (++i == sc->num_rx_desc) {
			i = 0;
			current_desc = sc->rx_desc_base;
		} else
			current_desc++;
a2162 1
	sc->next_rx_desc_to_check = i;
d2178 1
a2178 1
#ifdef __FreeBSD__
d2200 1
a2200 1
		/* Did it pass? */	  
d2209 1
a2209 16
#else /* __FreeBSD__ */
	/* 82543 or newer only */
	if ((sc->hw.mac_type < em_82543) ||
	    /* Ignore Checksum bit is set */
	    (rx_desc->status & E1000_RXD_STAT_IXSM))
		return;

	if ((rx_desc->status & (E1000_RXD_STAT_IPCS|E1000_RXD_ERR_IPE)) ==
	    E1000_RXD_STAT_IPCS)
		mp->m_pkthdr.csum |= M_IPV4_CSUM_IN_OK;

	if ((rx_desc->status & (E1000_RXD_STAT_IPCS|E1000_RXD_ERR_IPE|
	    E1000_RXD_STAT_TCPCS|E1000_RXD_ERR_TCPE)) ==
	    (E1000_RXD_STAT_TCPCS | E1000_RXD_STAT_IPCS))
		mp->m_pkthdr.csum |= M_TCP_CSUM_IN_OK | M_UDP_CSUM_IN_OK;
#endif /* __FreeBSD__ */
d2217 1
a2217 1
	E1000_WRITE_REG(&sc->hw, VET, ETHERTYPE_8021Q);
d2241 1
a2241 14
int
em_is_valid_ether_addr(u_int8_t *addr)
{
	const char zero_addr[6] = { 0, 0, 0, 0, 0, 0 };

	if ((addr[0] & 1) || (!bcmp(addr, zero_addr, ETHER_ADDR_LEN))) {
		return (FALSE);
	}

	return(TRUE);
}

void
em_write_pci_cfg(struct em_hw *hw,
d2245 1
a2245 1
	struct pci_attach_args *pa = &((struct em_osdep *)hw->back)->em_pa;
a2246 1
	/* Should we do read/mask/write...?  16 vs 32 bit!!! */
d2250 1
a2250 2
void
em_read_pci_cfg(struct em_hw *hw, uint32_t reg,
d2253 1
a2253 1
	struct pci_attach_args *pa = &((struct em_osdep *)hw->back)->em_pa;
d2259 1
a2259 2
void
em_pci_set_mwi(struct em_hw *hw)
d2261 7
a2267 6
	struct pci_attach_args *pa = &((struct em_osdep *)hw->back)->em_pa;
	pci_chipset_tag_t pc = pa->pa_pc;
	/* Should we do read/mask/write...?  16 vs 32 bit!!! */
	pci_conf_write(pc, pa->pa_tag, PCI_COMMAND_STATUS_REG,
		(hw->pci_cmd_word | CMD_MEM_WRT_INVALIDATE));

d2270 1
a2270 2
void
em_pci_clear_mwi(struct em_hw *hw)
d2272 7
a2278 20
	struct pci_attach_args *pa = &((struct em_osdep *)hw->back)->em_pa;
	pci_chipset_tag_t pc = pa->pa_pc;
	/* Should we do read/mask/write...?  16 vs 32 bit!!! */
	pci_conf_write(pc, pa->pa_tag, PCI_COMMAND_STATUS_REG,
		(hw->pci_cmd_word & ~CMD_MEM_WRT_INVALIDATE));

}

uint32_t
em_io_read(struct em_hw *hw, uint32_t port)
{
	return bus_space_read_4(((struct em_osdep *)(hw)->back)->em_iobtag,
		((struct em_osdep *)(hw)->back)->em_iobhandle, port);
}

void
em_io_write(struct em_hw *hw, uint32_t port, uint32_t value)
{
	bus_space_write_4(((struct em_osdep *)(hw)->back)->em_iobtag,
			((struct em_osdep *)(hw)->back)->em_iobhandle, port,
d2281 1
a2281 1
}
a2297 1

d2364 1
a2364 1
	ifp = &sc->interface_data.ac_if;
d2367 2
d2397 1
a2397 1
em_print_debug_info(struct em_softc *sc)
a2398 2
	const char * const unit = sc->sc_dv.dv_xname;

d2400 1
a2400 1
	printf("%s: Packets not Avail = %ld\n", unit, 
d2402 1
a2402 1
	printf("%s: CleanTxInterrupts = %ld\n", unit,
a2404 21
	printf("%s: fifo workaround = %lld, fifo_reset = %lld\n", unit,
		(long long)sc->tx_fifo_wrk,
		(long long)sc->tx_fifo_reset);
	printf("%s: hw tdh = %d, hw tdt = %d\n", unit,
		E1000_READ_REG(&sc->hw, TDH),
		E1000_READ_REG(&sc->hw, TDT));
	printf("%s: Num Tx Descriptors avail = %ld\n", unit,
	       sc->num_tx_desc_avail);
	printf("%s: Tx Descriptors not avail1 = %ld\n", unit,
	       sc->no_tx_desc_avail1);
	printf("%s: Tx Descriptors not avail2 = %ld\n", unit,
	       sc->no_tx_desc_avail2);
	printf("%s: Std mbuf failed = %ld\n", unit,
		sc->mbuf_alloc_failed);
	printf("%s: Std mbuf cluster failed = %ld\n", unit,
		sc->mbuf_cluster_failed);
	printf("%s: Driver dropped packets = %ld\n", unit,
	       sc->dropped_pkts);

	return;
}
d2406 10
a2415 4
void
em_print_hw_stats(struct em_softc *sc)
{
	const char * const unit = sc->sc_dv.dv_xname;
d2417 1
a2417 3
	printf("%s: Excessive collisions = %lld\n", unit,
		(long long)sc->stats.ecol);
	printf("%s: Symbol errors = %lld\n", unit,
d2419 1
a2419 1
	printf("%s: Sequence errors = %lld\n", unit,
d2421 1
a2421 1
	printf("%s: Defer count = %lld\n", unit,
d2424 1
a2424 1
	printf("%s: Missed Packets = %lld\n", unit,
d2426 1
a2426 1
	printf("%s: Receive No Buffers = %lld\n", unit,
d2428 1
a2428 1
	printf("%s: Receive length errors = %lld\n", unit,
d2430 1
a2430 1
	printf("%s: Receive errors = %lld\n", unit,
d2432 1
a2432 1
	printf("%s: Crc errors = %lld\n", unit,
d2434 1
a2434 1
	printf("%s: Alignment errors = %lld\n", unit,
d2436 1
a2436 1
	printf("%s: Carrier extension errors = %lld\n", unit,
d2438 2
d2441 1
a2441 1
	printf("%s: XON Rcvd = %lld\n", unit,
d2443 1
a2443 1
	printf("%s: XON Xmtd = %lld\n", unit,
d2445 1
a2445 1
	printf("%s: XOFF Rcvd = %lld\n", unit,
d2447 1
a2447 1
	printf("%s: XOFF Xmtd = %lld\n", unit,
d2450 1
a2450 1
	printf("%s: Good Packets Rcvd = %lld\n", unit,
d2452 1
a2452 1
	printf("%s: Good Packets Xmtd = %lld\n", unit,
d2454 1
a2455 2
	return;
}
d2457 9
a2465 3
#ifdef __FreeBSD__
int
em_sysctl_debug_info(SYSCTL_HANDLER_ARGS)
d2467 9
a2475 3
	int error;
	int result;
	struct em_softc *sc;
d2477 62
a2538 2
	result = -1;
	error = sysctl_handle_int(oidp, &result, 0, req);
d2540 1
a2540 2
	if (error || !req->newptr)
		return (error);
d2542 4
a2545 3
	if (result == 1) {
		sc = (struct em_softc *)arg1;
		em_print_debug_info(sc);
d2547 2
a2548 2

	return error;
d2551 2
a2552 3

int
em_sysctl_stats(SYSCTL_HANDLER_ARGS)
d2554 1
a2554 3
	int error;
	int result;
	struct em_softc *sc;
d2556 1
a2556 2
	result = -1;
	error = sysctl_handle_int(oidp, &result, 0, req);
d2558 18
a2575 2
	if (error || !req->newptr)
		return (error);
d2577 16
a2592 6
	if (result == 1) {
		sc = (struct em_softc *)arg1;
		em_print_hw_stats(sc);
	}

	return error;
a2593 2
#endif /* __FreeBSD__ */

@


1.7.4.2
log
@Merge with the trunk
@
text
@d34 1
a34 1
/*$FreeBSD: if_em.c,v 1.38 2004/03/17 17:50:31 njl Exp $*/
d78 6
d100 1
a100 55
char em_driver_version[] = "1.7.25";

#ifdef __FreeBSD__
/*********************************************************************
 *  PCI Device ID Table
 *
 *  Used by probe to select devices to load on
 *  Last field stores an index into em_strings
 *  Last entry must be all 0s
 *
 *  { Vendor ID, Device ID, SubVendor ID, SubDevice ID, String Index }
 *********************************************************************/

em_vendor_info_t em_vendor_info_array[] =
{
        /* Intel(R) PRO/1000 Network Connection */
        { 0x8086, 0x1000, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1001, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1004, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1008, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1009, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x100C, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x100D, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x100E, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x100F, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1010, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1011, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1012, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1013, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1014, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1015, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1016, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1017, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1018, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1019, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x101A, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x101D, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x101E, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1026, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1027, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1028, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1075, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1076, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1077, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1078, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1079, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x107A, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x107B, PCI_ANY_ID, PCI_ANY_ID, 0},
        /* required last entry */
        { 0, 0, 0, 0, 0}
};

/*********************************************************************
 *  Table of branding strings for all supported NICs.
 *********************************************************************/
a101 4
char *em_strings[] = {
        "Intel(R) PRO/1000 Network Connection"
};
#endif /* __FreeBSD__ */
a102 1
#ifdef __OpenBSD__
a119 1
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82541EI_NC },
a124 1
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82547EI_MOB },
d127 3
d133 4
a136 7
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82547EI_CT },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82541EI_MT },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82541EI_MOB },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82541EI_MT2 },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82546EB_COPPER },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82546EB_FIBER },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82546EB_SERDES }
a137 1
#endif /* __OpenBSD__ */
a141 8
#ifdef __FreeBSD__
int  em_probe(device_t);
int  em_attach(device_t);
int  em_detach(device_t);
int  em_shutdown(device_t);
void em_intr(void *);
#endif /* __FreeBSD__ */
#ifdef __OpenBSD__
d144 5
a149 1
#endif /* __OpenBSD__ */
a150 1
void em_start_locked(struct ifnet *);
a153 1
void em_init_locked(struct em_softc *);
a161 4
#ifdef __FreeBSD__
void em_setup_interface(device_t, struct em_softc *);
#endif
#ifdef __OpenBSD__
a162 1
#endif
a187 1
void em_update_link_status(struct em_softc *);
d196 1
a196 2
void em_82547_move_tail(void *arg);
void em_82547_move_tail_locked(struct em_softc *);
a201 13
#ifdef __FreeBSD__
int  em_sysctl_stats(SYSCTL_HANDLER_ARGS);
int  em_sysctl_debug_info(SYSCTL_HANDLER_ARGS);
#endif /* __FreeBSD__ */
u_int32_t em_fill_descriptors (u_int64_t address,
                                      u_int32_t length,
                                      PDESC_ARRAY desc_array);
#ifdef __FreeBSD__
int  em_sysctl_int_delay(SYSCTL_HANDLER_ARGS);
void em_add_int_delay_sysctl(struct em_softc *, const char *,
                                    const char *, struct em_int_delay_info *,
                                    int, int);
#endif /* __FreeBSD__ */
a206 21
#ifdef __FreeBSD__
device_method_t em_methods[] = {
        /* Device interface */
        DEVMETHOD(device_probe, em_probe),
        DEVMETHOD(device_attach, em_attach),
        DEVMETHOD(device_detach, em_detach),
        DEVMETHOD(device_shutdown, em_shutdown),
        {0, 0}
};

driver_t em_driver = {
        "em", em_methods, sizeof(struct em_softc ),
};

devclass_t em_devclass;
DRIVER_MODULE(em, pci, em_driver, em_devclass, 0, 0);
MODULE_DEPEND(em, pci, 1, 1, 1);
MODULE_DEPEND(em, ether, 1, 1, 1);
#endif /* __FreeBSD__ */

#ifdef __OpenBSD__
a213 20
#endif /* __OpenBSD__ */

/*********************************************************************
 *  Tunable default values.
 *********************************************************************/

#define E1000_TICKS_TO_USECS(ticks)     ((1024 * (ticks) + 500) / 1000)
#define E1000_USECS_TO_TICKS(usecs)     ((1000 * (usecs) + 512) / 1024)

int em_tx_int_delay_dflt = E1000_TICKS_TO_USECS(EM_TIDV);
int em_rx_int_delay_dflt = E1000_TICKS_TO_USECS(EM_RDTR);
int em_tx_abs_int_delay_dflt = E1000_TICKS_TO_USECS(EM_TADV);
int em_rx_abs_int_delay_dflt = E1000_TICKS_TO_USECS(EM_RADV);

#ifdef __FreeBSD__
TUNABLE_INT("hw.em.tx_int_delay", &em_tx_int_delay_dflt);
TUNABLE_INT("hw.em.rx_int_delay", &em_rx_int_delay_dflt);
TUNABLE_INT("hw.em.tx_abs_int_delay", &em_tx_abs_int_delay_dflt);
TUNABLE_INT("hw.em.rx_abs_int_delay", &em_rx_abs_int_delay_dflt);
#endif /* __FreeBSD__ */
a223 46
#ifdef __FreeBSD__
int
em_probe(device_t dev)
{
        em_vendor_info_t *ent;

        u_int16_t       pci_vendor_id = 0;
        u_int16_t       pci_device_id = 0;
        u_int16_t       pci_subvendor_id = 0;
        u_int16_t       pci_subdevice_id = 0;
        char            adapter_name[60];

        INIT_DEBUGOUT("em_probe: begin");

        pci_vendor_id = pci_get_vendor(dev);
        if (pci_vendor_id != EM_VENDOR_ID)
                return(ENXIO);

        pci_device_id = pci_get_device(dev);
        pci_subvendor_id = pci_get_subvendor(dev);
        pci_subdevice_id = pci_get_subdevice(dev);

        ent = em_vendor_info_array;
        while (ent->vendor_id != 0) {
                if ((pci_vendor_id == ent->vendor_id) &&
                    (pci_device_id == ent->device_id) &&

                    ((pci_subvendor_id == ent->subvendor_id) ||
                     (ent->subvendor_id == PCI_ANY_ID)) &&

                    ((pci_subdevice_id == ent->subdevice_id) ||
                     (ent->subdevice_id == PCI_ANY_ID))) {
                        sprintf(adapter_name, "%s, Version - %s",
                                em_strings[ent->index],
                                em_driver_version);
                        device_set_desc_copy(dev, adapter_name);
                        return(0);
                }
                ent++;
        }

        return(ENXIO);
}
#endif /* __FreeBSD__ */

#ifdef __OpenBSD__
a231 1
#endif /* __OpenBSD__ */
a242 7
#ifdef __FreeBSD__
int
em_attach(device_t dev)
{
	pci_chipset_tag_t pc = pa->pa_pc;
#endif /* __FreeBSD__ */
#ifdef __OpenBSD__
d247 5
a251 2
#endif /* __OpenBSD__ */
	struct em_softc *sc;
d256 1
d262 1
a268 1
	EM_LOCK_INIT(sc, device_get_nameunit(dev));
a270 3

#ifdef __OpenBSD__
	sc = (struct em_softc *)self;
a271 1
#endif
d304 2
a305 2
	callout_init(&sc->timer, CALLOUT_MPSAFE);
	callout_init(&sc->tx_fifo_timer, CALLOUT_MPSAFE);
a307 1
#ifdef __OpenBSD__
a309 1
#endif /* __OpenBSD__ */
a313 22
#ifdef __FreeBSD__
        /* Set up some sysctls for the tunable interrupt delays */
        em_add_int_delay_sysctl(sc, "rx_int_delay",
            "receive interrupt delay in usecs", &sc->rx_int_delay,
            E1000_REG_OFFSET(&sc->hw, RDTR), em_rx_int_delay_dflt);
        em_add_int_delay_sysctl(sc, "tx_int_delay",
            "transmit interrupt delay in usecs", &sc->tx_int_delay,
            E1000_REG_OFFSET(&sc->hw, TIDV), em_tx_int_delay_dflt);
        if (sc->hw.mac_type >= em_82540) {
                em_add_int_delay_sysctl(sc, "rx_abs_int_delay",
                    "receive interrupt delay limit in usecs",
                    &sc->rx_abs_int_delay,
                    E1000_REG_OFFSET(&sc->hw, RADV),
                    em_rx_abs_int_delay_dflt);
                em_add_int_delay_sysctl(sc, "tx_abs_int_delay",
                    "transmit interrupt delay limit in usecs",
                    &sc->tx_abs_int_delay,
                    E1000_REG_OFFSET(&sc->hw, TADV),
                    em_tx_abs_int_delay_dflt);
        }
#endif /* __FreeBSD__ */

d315 6
a320 2
	sc->num_tx_desc = EM_MIN_TXD;
	sc->num_rx_desc = EM_MIN_RXD;
a337 1
        sc->hw.phy_reset_disable = FALSE;
a338 5
#ifndef EM_MASTER_SLAVE
        sc->hw.master_slave = em_ms_hw_default;
#else
        sc->hw.master_slave = EM_MASTER_SLAVE;
#endif
d416 2
d428 3
a430 12
        if (sc->link_active == 1) {
                em_get_speed_and_duplex(&sc->hw, &sc->link_speed,
                                        &sc->link_duplex);
#ifdef __FreeBSD__
                printf("%s:  Speed:%d Mbps  Duplex:%s\n",
                       sc->sc_dv.dv_xname,
                       sc->link_speed,
                       sc->link_duplex == FULL_DUPLEX ? "Full" : "Half");
        } else
                printf("%s:  Speed:N/A  Duplex:N/A\n", sc->sc_dv.dv_xname);
#endif /* __FreeBSD__ */
#ifdef __OpenBSD__
a432 12
	printf(", address: %s\n", ether_sprintf(sc->interface_data.ac_enaddr));
#endif /* __OpenBSD__ */

        /* Identify 82544 on PCIX */
        em_get_bus_info(&sc->hw);
        if(sc->hw.bus_type == em_bus_type_pcix &&
           sc->hw.mac_type == em_82544) {
                sc->pcix_82544 = TRUE;
        }
        else {
                sc->pcix_82544 = FALSE;
        }
d434 1
a434 4
#ifdef __FreeBSD__
	return(0);
#endif
#ifdef __OpenBSD__
a435 1
#endif
a446 2
err_sysctl:
	return(error);
d448 3
a462 1

d465 1
a465 1
em_detach(device_t dev)
d467 11
a477 13
        struct em_softc * sc = device_get_softc(dev);
        struct ifnet   *ifp = &sc->interface_data.ac_if;
	EM_LOCK_STATE();

        INIT_DEBUGOUT("em_detach: begin");

        EM_LOCK(sc);
        sc->in_detach = 1;
        em_stop(sc);
        em_phy_hw_reset(&sc->hw);
        EM_UNLOCK(sc);
#if  __FreeBSD_version < 500000
        ether_ifdetach(&sc->interface_data.ac_if, ETHER_BPF_SUPPORTED);
d479 1
a479 1
        ether_ifdetach(&sc->interface_data.ac_if);
d481 1
a481 2
        em_free_pci_resources(sc);
        bus_generic_detach(dev);
d483 19
a501 5
        /* Free Transmit Descriptor ring */
        if (sc->tx_desc_base) {
                em_dma_free(sc, &sc->txdma);
                sc->tx_desc_base = NULL;
        }
d503 2
a504 5
        /* Free Receive Descriptor ring */
        if (sc->rx_desc_base) {
                em_dma_free(sc, &sc->rxdma);
                sc->rx_desc_base = NULL;
        }
d506 2
a507 17
        /* Free the sysctl tree */
        sysctl_ctx_free(&sc->sysctl_ctx);

        /* Remove from the sc list */
        if (em_adapter_list == sc)
                em_adapter_list = sc->next;
        if (sc->next != NULL)
                sc->next->prev = sc->prev;
        if (sc->prev != NULL)
                sc->prev->next = sc->next;

        EM_LOCK_DESTROY(sc);

        ifp->if_flags &= ~(IFF_RUNNING | IFF_OACTIVE);
        ifp->if_timer = 0;

        return(0);
a508 1
#endif /* __FreeBSD__ */
a515 1
#ifdef __FreeBSD__
d517 1
a517 1
em_shutdown(device_t dev)
d519 4
a522 2
        struct em_softc *sc = device_get_softc(dev);
	EM_LOCK_STATE();
a523 5
        EM_LOCK(sc);
        em_stop(sc);
        EM_UNLOCK(sc);
        return(0);
}
a525 1

d537 1
a537 1
em_start_locked(struct ifnet *ifp)
d539 1
a542 2
	mtx_assert(&sc->mtx, MA_OWNED);
	
d546 2
d570 1
a570 12
	return;
}

void
em_start(struct ifnet *ifp)
{
	struct em_softc *sc = ifp->if_softc;
	EM_LOCK_STATE();

        EM_LOCK(sc);
        em_start_locked(ifp);
        EM_UNLOCK(sc);
d586 1
a586 1
	int		error = 0;
d588 1
a589 1
	EM_LOCK_STATE();
d591 1
a591 5
#ifdef __OpenBSD__
	struct ifaddr  *ifa = (struct ifaddr *)data;
	EM_LOCK(sc);
	error = ether_ioctl(ifp, &sc->interface_data, command, data);
	EM_UNLOCK(sc);
d593 2
a594 1
	if (error > 0)
d596 1
a596 2
#endif /* __OpenBSD__ */
        if (sc->in_detach) return(error);
a605 1
#ifdef __OpenBSD__
a619 1
#endif /* __OpenBSD__ */
a624 1
                        EM_LOCK(sc);
d628 1
a628 2
			em_init_locked(sc);
                        EM_UNLOCK(sc);
a632 1
                EM_LOCK(sc);
d634 2
a635 3
			if (!(ifp->if_flags & IFF_RUNNING)) {
				em_init_locked(sc);
                        }
a643 1
                EM_UNLOCK(sc);
a647 1
#ifdef __OpenBSD__
a652 1
#endif /* __OpenBSD__ */
a653 1
                                EM_LOCK(sc);
d660 1
a660 1
				if (!(ifp->if_flags & IFF_POLLING))
a662 1
                                EM_UNLOCK(sc);
a663 1
#ifdef __OpenBSD__
a665 1
#endif /* __OpenBSD__ */
d687 1
a687 1
		IOCTL_DEBUGOUT1("ioctl received: UNKNOWN (0x%x)\n", (int)command);
d691 1
d716 1
a716 2
	if (em_check_for_link(&sc->hw))
	        printf("%s: watchdog timeout -- resetting\n", sc->sc_dv.dv_xname);
d720 1
d739 1
a739 1
em_init_locked(struct em_softc *sc)
d741 3
a743 1
	struct ifnet   *ifp = &sc->interface_data.ac_if;
d747 1
a747 1
        mtx_assert(&sc->mtx, MA_OWNED);
a750 15
	if (ifp->if_flags & IFF_UP) {
		sc->num_tx_desc = EM_MAX_TXD;
		sc->num_rx_desc = EM_MAX_RXD;
	} else {
		sc->num_tx_desc = EM_MIN_TXD;
		sc->num_rx_desc = EM_MIN_RXD;
	}


#ifdef __FreeBSD__
        /* Get the latest mac address, User can use a LAA */
        bcopy(sc->interface_data.ac_enaddr, sc->hw.mac_addr,
              ETHER_ADDR_LEN);
#endif /* __FreeBSD__ */

d755 1
d766 1
d779 1
d784 1
a784 3
        /* Don't loose promiscuous settings */
        em_set_promisc(sc);

d795 1
a796 3
	callout_reset(&sc->timer, 2*hz, em_local_timer, sc);
#endif /* __FreeBSD__ */
#ifdef __OpenBSD__
a797 1
#endif
d804 1
a804 1
        if (ifp->if_flags & IFF_POLLING)
d810 1
a810 3
        /* Don't reset the phy next time init gets called */
        sc->hw.phy_reset_disable = TRUE;

a813 12
void
em_init(void *arg)
{
        struct em_softc * sc = arg;
	EM_LOCK_STATE();

        EM_LOCK(sc);
        em_init_locked(sc);
        EM_UNLOCK(sc);
        return;
}

d816 1
a816 1
poll_handler_t em_poll;
d818 2
a819 2
void
em_poll_locked(struct ifnet *ifp, enum poll_cmd cmd, int count)
d821 2
a822 2
        struct em_softc *sc = ifp->if_softc;
        u_int32_t reg_icr;
d824 18
a841 1
        mtx_assert(&sc->mtx, MA_OWNED);
d843 2
a844 32
        if (cmd == POLL_DEREGISTER) {       /* final call, enable interrupts */
                em_enable_intr(sc);
                return;
        }
        if (cmd == POLL_AND_CHECK_STATUS) {
                reg_icr = E1000_READ_REG(&sc->hw, ICR);
                if (reg_icr & (E1000_ICR_RXSEQ | E1000_ICR_LSC)) {
                        callout_stop(&sc->timer);
                        sc->hw.get_link_status = 1;
                        em_check_for_link(&sc->hw);
                        em_update_link_status(sc);
                        callout_reset(&sc->timer, 2*hz, em_local_timer, sc);
                }
        }
        if (ifp->if_flags & IFF_RUNNING) {
                em_process_receive_interrupts(sc, count);
                em_clean_transmit_interrupts(sc);
        }

        if (ifp->if_flags & IFF_RUNNING && ifp->if_snd.ifq_head != NULL)
                em_start_locked(ifp);
}

void
em_poll(struct ifnet *ifp, enum poll_cmd cmd, int count)
{
        struct em_softc *sc = ifp->if_softc;
	EM_LOCK_STATE();

        EM_LOCK(sc);
        em_poll_locked(ifp, cmd, count);
        EM_UNLOCK(sc);
a852 4
#ifdef __FreeBSD__
void
#endif
#ifdef __OpenBSD__
a853 1
#endif
d859 1
a859 4
	struct em_softc  *sc = arg;
	EM_LOCK_STATE();

        EM_LOCK(sc);
d864 2
a865 4
        if (ifp->if_flags & IFF_POLLING) {
                EM_UNLOCK(sc);
                return;
        }
d867 5
a871 6
        if (ether_poll_register(em_poll, ifp)) {
                em_disable_intr(sc);
                em_poll_locked(ifp, 0, 1);
                EM_UNLOCK(sc);
                return;
        }
a872 1

a874 5
                EM_UNLOCK(sc);
#ifdef __FreeBSD__
		return;
#endif
#ifdef __OpenBSD__
a875 1
#endif
a879 4
#ifdef __FreeBSD__
                callout_stop(&sc->timer);
#endif
#ifdef __OpenBSD__
a880 1
#endif
d883 1
a883 5
		em_update_link_status(sc);
#ifdef __FreeBSD__
                callout_reset(&sc->timer, 2*hz, em_local_timer, sc);
#endif
#ifdef __OpenBSD__
a884 1
#endif
a894 4
#ifdef __FreeBSD__
        if (ifp->if_flags & IFF_RUNNING && ifp->if_snd.ifq_head != NULL)
#endif
#ifdef __OpenBSD__
d896 1
a896 2
#endif
                em_start_locked(ifp);
a897 5
        EM_UNLOCK(sc);
#ifdef __FreeBSD__
	return;
#endif
#ifdef __OpenBSD__
a898 1
#endif
a952 3
#if defined(__FreeBSD__) && __FreeBSD_version < 500000
			ifmr->ifm_active |= IFM_1000_TX;
#else
a953 1
#endif
d989 1
a989 5
#if defined(__FreeBSD__) && __FreeBSD_version < 500000
        case IFM_1000_TX:
#else
        case IFM_1000_T:
#endif
a1012 5
        /* As the speed/duplex settings my have changed we need to
         * reset the PHY.
         */
        sc->hw.phy_reset_disable = FALSE;

d1026 1
a1026 1
	KASSERT(nsegs <= EM_MAX_SCATTER,
d1047 1
a1047 1
	u_int32_t	txd_lower, txd_used = 0, txd_saved = 0;
a1048 6
	u_int64_t       address;

        /* For 82544 Workaround */
        DESC_ARRAY              desc_array;
        u_int32_t               array_elements;
        u_int32_t               counter;
d1074 1
a1074 1
            &q.map)) {
a1111 4
        if (sc->pcix_82544) {
                txd_saved = i;
                txd_used = 0;
        }
d1113 7
a1119 40
                /* If sc is 82544 and on PCIX bus */
                if(sc->pcix_82544) {
                        array_elements = 0;
                        address = htole64(q.map->dm_segs[j].ds_addr);
                        /*
                         * Check the Address and Length combination and
                         * split the data accordingly
                         */
                        array_elements = em_fill_descriptors(address,
                                                             htole32(q.map->dm_segs[j].ds_len),
                                                             &desc_array);
                        for (counter = 0; counter < array_elements; counter++) {
                                if (txd_used == sc->num_tx_desc_avail) {
                                          sc->next_avail_tx_desc = txd_saved;
                                          sc->no_tx_desc_avail2++;
                                          bus_dmamap_destroy(sc->txtag, q.map);
                                          return (ENOBUFS);
                                }
                                tx_buffer = &sc->tx_buffer_area[i];
                                current_tx_desc = &sc->tx_desc_base[i];
                                current_tx_desc->buffer_addr = htole64(
                                        desc_array.descriptor[counter].address);
                                current_tx_desc->lower.data = htole32(
                                        (sc->txd_cmd | txd_lower |
                                         (u_int16_t)desc_array.descriptor[counter].length));
                                current_tx_desc->upper.data = htole32((txd_upper));
                                if (++i == sc->num_tx_desc)
                                         i = 0;

                                tx_buffer->m_head = NULL;
                                txd_used++;
                        }
                } else {
		        tx_buffer = &sc->tx_buffer_area[i];
		        current_tx_desc = &sc->tx_desc_base[i];

		        current_tx_desc->buffer_addr = htole64(q.map->dm_segs[j].ds_addr);
		        current_tx_desc->lower.data = htole32(
		            sc->txd_cmd | txd_lower | q.map->dm_segs[j].ds_len);
		        current_tx_desc->upper.data = htole32(txd_upper);
d1121 2
a1122 2
		        if (++i == sc->num_tx_desc)
	        		i = 0;
d1124 1
a1124 2
		        tx_buffer->m_head = NULL;
                }
d1127 1
a1128 6
        if (sc->pcix_82544) {
                sc->num_tx_desc_avail -= txd_used;
        }
        else {
                sc->num_tx_desc_avail -= q.map->dm_nsegs;
        }
d1156 1
a1156 1
		em_82547_move_tail_locked(sc);
d1172 1
a1172 1
 * in this case. We do that only when FIFO is quiescent.
d1176 1
a1176 1
em_82547_move_tail_locked(struct em_softc *sc)
d1178 2
d1186 1
a1186 2
        EM_LOCK_ASSERT(sc);

a1199 5
#ifdef __FreeBSD__
                                callout_reset(&sc->tx_fifo_timer, 1,
                                        em_82547_move_tail, sc);
#endif
#ifdef __OpenBSD__
d1201 7
a1207 2
#endif
				break;
a1208 3
			E1000_WRITE_REG(&sc->hw, TDT, hw_tdt);
			em_82547_update_fifo_head(sc, length);
			length = 0;
d1211 1
a1214 11
void
em_82547_move_tail(void *arg)
{
        struct em_softc *sc = arg;
	EM_LOCK_STATE();

        EM_LOCK(sc);
        em_82547_move_tail_locked(sc);
        EM_UNLOCK(sc);
}

a1337 6
#ifdef __FreeBSD__
	struct ifmultiaddr  *ifma;
#endif
	int mcnt = 0;
	struct ifnet *ifp = &sc->interface_data.ac_if;
#ifdef __OpenBSD__
d1341 2
a1342 1
#endif /* __OpenBSD__ */
a1355 17
#ifdef __FreeBSD__
#if __FreeBSD_version < 500000
        LIST_FOREACH(ifma, &ifp->if_multiaddrs, ifma_link) {
#else
        TAILQ_FOREACH(ifma, &ifp->if_multiaddrs, ifma_link) {
#endif
                if (ifma->ifma_addr->sa_family != AF_LINK)
                        continue;

                if (mcnt == MAX_NUM_MULTICAST_ADDRESSES) break;

                bcopy(LLADDR((struct sockaddr_dl *)ifma->ifma_addr),
                      &mta[mcnt*ETH_LENGTH_OF_ADDRESS], ETH_LENGTH_OF_ADDRESS);
                mcnt++;
        }
#endif /* __FreeBSD__ */
#ifdef __OpenBSD__
a1368 1
#endif /* __OpenBSD__ */
d1375 1
a1375 1
		em_mc_addr_list_update(&sc->hw, mta, mcnt, 0, 1);
d1401 1
a1403 2
	EM_LOCK_STATE();

d1406 1
a1406 1
	EM_LOCK(sc);
d1409 1
a1409 1
	em_update_link_status(sc);
a1415 4
#ifdef __FreeBSD__
        callout_reset(&sc->timer, 2*hz, em_local_timer, sc);
#endif /* __FreeBSD__ */
#ifdef __OpenBSD__
a1416 1
#endif /* __OpenBSD__ */
d1418 1
a1418 1
        EM_UNLOCK(sc);
d1425 15
a1439 45
        if (E1000_READ_REG(&sc->hw, STATUS) & E1000_STATUS_LU) {
                if (sc->link_active == 0) {
                        em_get_speed_and_duplex(&sc->hw,
                                                &sc->link_speed,
                                                &sc->link_duplex);
                        printf("%s: Link is up %d Mbps %s\n",
                               sc->sc_dv.dv_xname,
                               sc->link_speed,
                               ((sc->link_duplex == FULL_DUPLEX) ?
                                "Full Duplex" : "Half Duplex"));
                        sc->link_active = 1;
                        sc->smartspeed = 0;
                }
        } else {
                if (sc->link_active == 1) {
                        sc->link_speed = 0;
                        sc->link_duplex = 0;
                        printf("%s: Link is Down\n", sc->sc_dv.dv_xname);
                        sc->link_active = 0;
                }
        }

        return;
}

void
em_update_link_status(struct em_softc * sc)
{
        if (E1000_READ_REG(&sc->hw, STATUS) & E1000_STATUS_LU) {
                if (sc->link_active == 0) {
                        em_get_speed_and_duplex(&sc->hw,
                                                &sc->link_speed,
                                                &sc->link_duplex);
                        sc->link_active = 1;
                        sc->smartspeed = 0;
                }
        } else {
                if (sc->link_active == 1) {
                        sc->link_speed = 0;
                        sc->link_duplex = 0;
                        sc->link_active = 0;
                }
        }

        return;
d1441 1
d1458 1
a1458 3
	mtx_assert(&sc->mtx, MA_OWNED);

	INIT_DEBUGOUT("em_stop: begin");
a1460 5
#ifdef __FreeBSD__
        callout_stop(&sc->timer);
        callout_stop(&sc->tx_fifo_timer);
#endif /* __FreeBSD__ */
#ifdef __OpenBSD__
a1462 1
#endif /* __OpenBSD__ */
a1513 6
	if(sc->hw.mac_type == em_82541 ||
	   sc->hw.mac_type == em_82541_rev_2 ||
	   sc->hw.mac_type == em_82547 ||
	   sc->hw.mac_type == em_82547_rev_2)
		sc->hw.phy_init_script = TRUE;

d1534 1
a1534 1
		printf(": can't find mem space\n");
d1554 1
a1554 1
			printf(": can't find io space\n");
a1556 8

#ifdef __FreeBSD__
                sc->hw.io_base =
                rman_get_start(sc->res_ioport);
#endif
#ifdef __OpenBSD__
		sc->hw.io_base = 0;
#endif
a1613 1
	INIT_DEBUGOUT("em_hardware_init: begin");
a1662 4
#ifdef __FreeBSD__
em_setup_interface(device_t dev, struct em_softc * sc)
#endif
#ifdef __OpenBSD__
a1663 1
#endif
a1668 7
#ifdef __FreeBSD__
        if_initname(ifp, device_get_name(dev), device_get_unit(dev));
#endif
#ifdef __OpenBSD__
	strlcpy(ifp->if_xname, sc->sc_dv.dv_xname, IFNAMSIZ);
#endif

a1679 4
#ifdef __FreeBSD__
	ifp->if_snd.ifq_maxlen = sc->num_tx_desc - 1;
#endif
#ifdef __OpenBSD__
a1681 1
#endif
d1683 2
d1694 1
a1694 1
	ifp->if_data.ifi_hdrlen = sizeof(struct ether_vlan_header);
a1729 1
#ifdef __OpenBSD__
d1732 1
a1732 1
#endif
d1801 1
a1828 2
			       NULL,			/* lockfunc */
			       NULL,			/* lockarg */
a1837 1
#ifdef __OpenBSD__
d1841 1
a1841 1
#endif /* __OpenBSD__ */
d1888 1
a1888 1
	bus_dma_tag_destroy(dma->dma_tag);
d1902 1
a1902 1
	bus_dma_tag_destroy(dma->dma_tag);
a1950 2
		    NULL,                    /* lockfunc */
		    NULL,                    /* lockarg */
a1956 1
#ifdef __OpenBSD__
a1957 1
#endif
a1988 1
	INIT_DEBUGOUT("em_initialize_transmit_unit: begin");
d2024 1
a2024 1
	E1000_WRITE_REG(&sc->hw, TIDV, sc->tx_int_delay.value);
d2026 1
a2026 2
		E1000_WRITE_REG(&sc->hw, TADV,
		    sc->tx_abs_int_delay.value);
d2041 1
a2041 1
	if (sc->tx_int_delay.value > 0)
d2076 1
d2078 1
d2182 1
a2187 2
	mtx_assert(&sc->mtx, MA_OWNED);

d2191 1
d2241 1
a2348 1
#ifdef __OpenBSD__
a2349 1
#endif
d2376 1
a2376 1
	bus_dma_tag_destroy(sc->rxtag);
a2417 1
	INIT_DEBUGOUT("em_initialize_receive_unit: begin");
d2425 1
a2425 1
			sc->rx_int_delay.value | E1000_RDT_FPDB);
d2428 1
a2428 2
		E1000_WRITE_REG(&sc->hw, RADV,
		    sc->rx_abs_int_delay.value);
a2437 4
#ifdef __FreeBSD__
	bus_addr = sc->rxdma.dma_paddr;
#endif
#ifdef __OpenBSD__
a2438 1
#endif
d2522 1
a2522 1
		bus_dma_tag_destroy(sc->rxtag);
a2543 1
#if __FreeBSD_version < 500000
a2545 1
#endif /* __FreeBSD__ */
d2548 1
a2548 1
	u_int16_t	    len, desc_len, prev_len_adj;
a2553 2
	mtx_assert(&sc->mtx, MA_OWNED);

a2573 1
		prev_len_adj = 0;
d2578 1
a2578 7
			if (desc_len < ETHER_CRC_LEN) {
				len = 0;
				prev_len_adj = ETHER_CRC_LEN - desc_len;
			}
			else {
				len = desc_len - ETHER_CRC_LEN;
			}
d2600 1
a2600 1
				if (len > 0) len--;
d2629 3
a2631 11
                                /*
                                 * Adjust length of previous mbuf in chain if we
                                 * received less than 4 bytes in the last descriptor.
                                 */
                                if (prev_len_adj > 0) {
                                        sc->lmp->m_len -= prev_len_adj;
                                        sc->fmp->m_pkthdr.len -= prev_len_adj;
                                }
                                sc->lmp->m_next = mp;
                                sc->lmp = sc->lmp->m_next;
                                sc->fmp->m_pkthdr.len += len;
a2637 1
#ifdef __OpenBSD__
d2646 1
a2646 4
				em_receive_checksum(sc, current_desc,
					    sc->fmp);
				ether_input_mbuf(ifp, sc->fmp);
#endif /* __OpenBSD__ */
a2647 1
#if __FreeBSD_version < 500000
d2651 14
a2664 9
                                em_receive_checksum(sc, current_desc,
                                                    sc->fmp);
                                if (current_desc->status & E1000_RXD_STAT_VP)
                                        VLAN_INPUT_TAG(eh, sc->fmp,
                                                       (current_desc->special &
                                                        E1000_RXD_SPC_VLAN_MASK));
                                else
                                        ether_input(ifp, eh, sc->fmp);
#else
a2665 15
                                em_receive_checksum(sc, current_desc,
                                                    sc->fmp);
                                if (current_desc->status & E1000_RXD_STAT_VP)
                                        VLAN_INPUT_TAG(ifp, sc->fmp,
                                                       (current_desc->special &
                                                        E1000_RXD_SPC_VLAN_MASK),
                                                       sc->fmp = NULL);

                                if (sc->fmp != NULL) {
                                        EM_UNLOCK(sc);
                                        (*ifp->if_input)(ifp, sc->fmp);
                                        EM_LOCK(sc);
                                }
#endif
#endif /* __FreeBSD__ */
d2738 1
a2738 2
#endif /* __FreeBSD__ */
#ifdef __OpenBSD__
d2753 1
a2753 1
#endif /* __OpenBSD__ */
d2757 1
a2757 2
void
em_enable_vlans(struct em_softc * sc)
d2840 2
a2841 3
#ifdef __FreeBSD__
int32_t
em_io_read(struct em_hw *hw, unsigned long port)
d2843 2
a2844 1
        return(inl(port));
d2848 1
a2848 1
em_io_write(struct em_hw *hw, unsigned long port, uint32_t value)
d2850 4
a2853 56
        outl(port, value);
        return;
}
#endif /* __FreeBSD__ */

/*********************************************************************
* 82544 Coexistence issue workaround.
*    There are 2 issues.
*       1. Transmit Hang issue.
*    To detect this issue, following equation can be used...
*          SIZE[3:0] + ADDR[2:0] = SUM[3:0].
*          If SUM[3:0] is in between 1 to 4, we will have this issue.
*
*       2. DAC issue.
*    To detect this issue, following equation can be used...
*          SIZE[3:0] + ADDR[2:0] = SUM[3:0].
*          If SUM[3:0] is in between 9 to c, we will have this issue.
*
*
*    WORKAROUND:
*          Make sure we do not have ending address as 1,2,3,4(Hang) or 9,a,b,c (DAC)
*
*** *********************************************************************/
u_int32_t
em_fill_descriptors (u_int64_t address,
                              u_int32_t length,
                              PDESC_ARRAY desc_array)
{
        /* Since issue is sensitive to length and address.*/
        /* Let us first check the address...*/
        u_int32_t safe_terminator;
        if (length <= 4) {
                desc_array->descriptor[0].address = address;
                desc_array->descriptor[0].length = length;
                desc_array->elements = 1;
                return desc_array->elements;
        }
        safe_terminator = (u_int32_t)((((u_int32_t)address & 0x7) + (length & 0xF)) & 0xF);
        /* if it does not fall between 0x1 to 0x4 and 0x9 to 0xC then return */
        if (safe_terminator == 0   ||
        (safe_terminator > 4   &&
        safe_terminator < 9)   ||
        (safe_terminator > 0xC &&
        safe_terminator <= 0xF)) {
                desc_array->descriptor[0].address = address;
                desc_array->descriptor[0].length = length;
                desc_array->elements = 1;
                return desc_array->elements;
        }

        desc_array->descriptor[0].address = address;
        desc_array->descriptor[0].length = length - 4;
        desc_array->descriptor[1].address = address + (length - 4);
        desc_array->descriptor[1].length = 4;
        desc_array->elements = 2;
        return desc_array->elements;
a2865 5
	if(sc->hw.media_type == em_media_type_copper ||
	    (E1000_READ_REG(&sc->hw, STATUS) & E1000_STATUS_LU)) {
		sc->stats.symerrs += E1000_READ_REG(&sc->hw, SYMERRS);
 		sc->stats.sec += E1000_READ_REG(&sc->hw, SEC);
	}
d2867 1
d2876 1
a2971 9
	uint8_t *hw_addr = sc->hw.hw_addr;

        printf("%s: Adapter hardware address = %p \n", unit, hw_addr);
        printf("%s:tx_int_delay = %d, tx_abs_int_delay = %d\n", unit,
              E1000_READ_REG(&sc->hw, TIDV),
              E1000_READ_REG(&sc->hw, TADV));
        printf("%s:rx_int_delay = %d, rx_abs_int_delay = %d\n", unit,
              E1000_READ_REG(&sc->hw, RDTR),
              E1000_READ_REG(&sc->hw, RADV));
d2985 1
a2985 1
	printf("%s: Num Tx descriptors avail = %d\n", unit,
a3088 60
}

int
em_sysctl_int_delay(SYSCTL_HANDLER_ARGS)
{
	struct em_int_delay_info *info;
	struct em_softc *sc;
	u_int32_t regval;
	int error;
	int usecs;
	int ticks;
	int s;

	info = (struct em_int_delay_info *)arg1;
	sc = info->sc;
	usecs = info->value;
	error = sysctl_handle_int(oidp, &usecs, 0, req);
	if (error != 0 || req->newptr == NULL)
		return error;
	if (usecs < 0 || usecs > E1000_TICKS_TO_USECS(65535))
		return EINVAL;
	info->value = usecs;
	ticks = E1000_USECS_TO_TICKS(usecs);

	s = splimp();
	regval = E1000_READ_OFFSET(&sc->hw, info->offset);
	regval = (regval & ~0xffff) | (ticks & 0xffff);
	/* Handle a few special cases. */
	switch (info->offset) {
	case E1000_RDTR:
	case E1000_82542_RDTR:
		regval |= E1000_RDT_FPDB;
		break;
	case E1000_TIDV:
	case E1000_82542_TIDV:
		if (ticks == 0) {
			sc->txd_cmd &= ~E1000_TXD_CMD_IDE;
			/* Don't write 0 into the TIDV register. */
			regval++;
		} else
			sc->txd_cmd |= E1000_TXD_CMD_IDE;
		break;
	}
	E1000_WRITE_OFFSET(&sc->hw, info->offset, regval);
	splx(s);
	return 0;
}

void
em_add_int_delay_sysctl(struct em_softc *sc, const char *name,
    const char *description, struct em_int_delay_info *info,
    int offset, int value)
{
	info->sc = sc;
	info->offset = offset;
	info->value = value;
	SYSCTL_ADD_PROC(&sc->sysctl_ctx,
	    SYSCTL_CHILDREN(sc->sysctl_tree),
	    OID_AUTO, name, CTLTYPE_INT|CTLFLAG_RW,
	    info, 0, em_sysctl_int_delay, "I", description);
@


1.6
log
@fix memory leak when downing an interface.
from Patrik Lindergren <patrik@@lindergren.com>
@
text
@d331 2
d1310 1
a1310 1
        printf(": %s\n", intrstr);
@


1.5
log
@1000baseTX -> 1000baseT
- More technically correct
- Matches FreeBSD and NetBSD
- Preserved #define for 1000baseTX for backwards compatibility
ok jason@@
@
text
@d1630 5
d1973 5
@


1.4
log
@use pci_matchbyid
@
text
@a1102 3
#if __FreeBSD_version < 500000 
			ifmr->ifm_active |= IFM_1000_TX;
#else
a1103 1
#endif
a1138 3
#if __FreeBSD_version < 500000 
	case IFM_1000_TX:
#else
a1139 1
#endif
a1442 5
#if __FreeBSD_version < 500000 
		ifmedia_add(&sc->media, IFM_ETHER | IFM_1000_TX | IFM_FDX, 
			    0, NULL);
		ifmedia_add(&sc->media, IFM_ETHER | IFM_1000_TX, 0, NULL);
#else
a1445 1
#endif
@


1.3
log
@nate, why is it that for every single ethernet driver you merge into the
tree, you forget to delete the printf's that fire EVERY SINGLE TIME it
changes media?!?!
@
text
@d101 14
a114 23
struct em_device
{
	u_int16_t	vendor_id;
	u_int16_t	device_id;
	int		match;
};

struct em_device em_devs[] =
{
	/* Intel(R) PRO/1000 Network Connection */
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82542,		2},
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82543GC_SC,	2},
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82543GC,		2},
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82544EI,		2},
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82544EI_SC,	2},
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82544GC,		2},
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82544GC_LX,	2},
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82540EM,		2},
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82545EM,		2},
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82546EB,		2},
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82545EM_SC,	2},
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82546EB_SC,	2},
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82545EM_LX,	2},
a201 3
	struct pci_attach_args *pa = (struct pci_attach_args *)aux;
	int i;

d204 2
a205 7
	for (i = 0; i < sizeof(em_devs) / sizeof(em_devs[0]); i++) {
		if (PCI_VENDOR(pa->pa_id) == em_devs[i].vendor_id &&
		    PCI_PRODUCT(pa->pa_id) == em_devs[i].device_id)
			return (em_devs[i].match);
	}

	return (0);
@


1.2
log
@#if NVLAN > 0 around vlan portions of code
@
text
@a904 5
			printf("%s: Link is up %d Mbps %s\n",
			       sc->sc_dv.dv_xname,
			       sc->link_speed,
			       ((sc->link_duplex == FULL_DUPLEX) ?
				"Full Duplex" : "Half Duplex"));
a910 1
			printf("%s: Link is Down\n", sc->sc_dv.dv_xname);
@


1.2.4.1
log
@sync to -current
@
text
@@


1.2.4.2
log
@sync
@
text
@d101 23
a123 14
const struct pci_matchid em_devices[] = {
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82542 },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82543GC_SC },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82543GC },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82544EI },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82544EI_SC },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82544GC },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82544GC_LX },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82540EM },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82545EM },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82546EB },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82545EM_SC },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82546EB_SC },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82545EM_LX },
d211 3
d216 7
a222 2
	return (pci_matchbyid((struct pci_attach_args *)aux, em_devices,
	    sizeof(em_devices)/sizeof(em_devices[0])));
a347 2
	printf(", address: %s\n", ether_sprintf(sc->arpcom.ac_enaddr));

d905 5
d916 1
d1126 3
d1130 1
d1166 3
d1170 1
d1339 1
a1339 1
        printf(": %s", intrstr);
d1474 5
d1482 1
a1666 5

			bus_dmamap_unload(sc->osdep.em_pa.pa_dmat,
			    tx_buffer->dmamap);
			bus_dmamap_destroy(sc->osdep.em_pa.pa_dmat,
			    tx_buffer->dmamap);
a2004 5

			bus_dmamap_unload(sc->osdep.em_pa.pa_dmat,
			    rx_buffer->dmamap);
			bus_dmamap_destroy(sc->osdep.em_pa.pa_dmat,
			    rx_buffer->dmamap);
@


1.1
log
@Driver for Intel PRO/1000 gigabit ethernet adapters.
This driver should work with all current models of gigabit ethernet adapters.

Driver written by Intel
Ported from FreeBSD by Henric Jungheim <henric@@attbi.com>
bus_dma and endian support by me.
@
text
@d459 1
d461 1
d513 1
d520 1
d551 1
d561 1
@

