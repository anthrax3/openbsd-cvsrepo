head	1.14;
access;
symbols
	OPENBSD_6_2:1.14.0.2
	OPENBSD_6_2_BASE:1.14
	OPENBSD_6_1:1.13.0.8
	OPENBSD_6_1_BASE:1.13
	OPENBSD_6_0:1.13.0.6
	OPENBSD_6_0_BASE:1.13
	OPENBSD_5_9:1.13.0.2
	OPENBSD_5_9_BASE:1.13
	OPENBSD_5_8:1.12.0.4
	OPENBSD_5_8_BASE:1.12
	OPENBSD_5_7:1.10.0.8
	OPENBSD_5_7_BASE:1.10
	OPENBSD_5_6:1.10.0.6
	OPENBSD_5_6_BASE:1.10
	OPENBSD_5_5:1.10.0.4
	OPENBSD_5_5_BASE:1.10;
locks; strict;
comment	@ * @;


1.14
date	2017.07.01.16.14.10;	author kettenis;	state Exp;
branches;
next	1.13;
commitid	KnwRPOZok9A30HI4;

1.13
date	2015.09.23.23.12.12;	author kettenis;	state Exp;
branches;
next	1.12;
commitid	lQlppvmETCN49oZe;

1.12
date	2015.04.18.11.41.28;	author jsg;	state Exp;
branches;
next	1.11;
commitid	c3CbYQJYD10xhd6O;

1.11
date	2015.04.12.17.10.07;	author kettenis;	state Exp;
branches;
next	1.10;
commitid	7RIU3AxWXbuzxDet;

1.10
date	2013.12.15.11.42.10;	author kettenis;	state Exp;
branches;
next	1.9;

1.9
date	2013.12.01.11.47.13;	author kettenis;	state Exp;
branches;
next	1.8;

1.8
date	2013.11.30.20.13.36;	author kettenis;	state Exp;
branches;
next	1.7;

1.7
date	2013.11.30.20.03.32;	author kettenis;	state Exp;
branches;
next	1.6;

1.6
date	2013.11.20.02.03.52;	author jsg;	state Exp;
branches;
next	1.5;

1.5
date	2013.11.19.15.08.04;	author jsg;	state Exp;
branches;
next	1.4;

1.4
date	2013.11.17.18.47.13;	author kettenis;	state Exp;
branches;
next	1.3;

1.3
date	2013.11.02.22.58.10;	author kettenis;	state Exp;
branches;
next	1.2;

1.2
date	2013.09.30.06.47.48;	author jsg;	state Exp;
branches;
next	1.1;

1.1
date	2013.08.07.19.49.07;	author kettenis;	state Exp;
branches;
next	;


desc
@@


1.14
log
@Update inteldrm(4) to code based on Linux 4.4.70.  This brings us support for
Skylake and Cherryview and better support for Broadwell and Valleyview.  Also
adds MST support.  Some tweaks to the TTM code and radeondrm(4) to keep it
working with the updated generic DRM code needed for inteldrm(4).

Tested by many.
@
text
@#if !defined(_I915_TRACE_H_) || defined(TRACE_HEADER_MULTI_READ)
#define _I915_TRACE_H_

#ifdef __linux__
#include <linux/stringify.h>
#include <linux/types.h>
#include <linux/tracepoint.h>
#endif

#include <dev/pci/drm/drmP.h>
#include "i915_drv.h"
#include "intel_drv.h"
#include "intel_ringbuffer.h"

#undef TRACE_SYSTEM
#define TRACE_SYSTEM i915
#define TRACE_INCLUDE_FILE i915_trace

/* pipe updates */

TRACE_EVENT(i915_pipe_update_start,
	    TP_PROTO(struct intel_crtc *crtc),
	    TP_ARGS(crtc),

	    TP_STRUCT__entry(
			     __field(enum pipe, pipe)
			     __field(u32, frame)
			     __field(u32, scanline)
			     __field(u32, min)
			     __field(u32, max)
			     ),

	    TP_fast_assign(
			   __entry->pipe = crtc->pipe;
			   __entry->frame = crtc->base.dev->driver->get_vblank_counter(crtc->base.dev,
										       crtc->pipe);
			   __entry->scanline = intel_get_crtc_scanline(crtc);
			   __entry->min = crtc->debug.min_vbl;
			   __entry->max = crtc->debug.max_vbl;
			   ),

	    TP_printk("pipe %c, frame=%u, scanline=%u, min=%u, max=%u",
		      pipe_name(__entry->pipe), __entry->frame,
		       __entry->scanline, __entry->min, __entry->max)
);

TRACE_EVENT(i915_pipe_update_vblank_evaded,
	    TP_PROTO(struct intel_crtc *crtc),
	    TP_ARGS(crtc),

	    TP_STRUCT__entry(
			     __field(enum pipe, pipe)
			     __field(u32, frame)
			     __field(u32, scanline)
			     __field(u32, min)
			     __field(u32, max)
			     ),

	    TP_fast_assign(
			   __entry->pipe = crtc->pipe;
			   __entry->frame = crtc->debug.start_vbl_count;
			   __entry->scanline = crtc->debug.scanline_start;
			   __entry->min = crtc->debug.min_vbl;
			   __entry->max = crtc->debug.max_vbl;
			   ),

	    TP_printk("pipe %c, frame=%u, scanline=%u, min=%u, max=%u",
		      pipe_name(__entry->pipe), __entry->frame,
		       __entry->scanline, __entry->min, __entry->max)
);

TRACE_EVENT(i915_pipe_update_end,
	    TP_PROTO(struct intel_crtc *crtc, u32 frame, int scanline_end),
	    TP_ARGS(crtc, frame, scanline_end),

	    TP_STRUCT__entry(
			     __field(enum pipe, pipe)
			     __field(u32, frame)
			     __field(u32, scanline)
			     ),

	    TP_fast_assign(
			   __entry->pipe = crtc->pipe;
			   __entry->frame = frame;
			   __entry->scanline = scanline_end;
			   ),

	    TP_printk("pipe %c, frame=%u, scanline=%u",
		      pipe_name(__entry->pipe), __entry->frame,
		      __entry->scanline)
);

/* object tracking */

TRACE_EVENT(i915_gem_object_create,
	    TP_PROTO(struct drm_i915_gem_object *obj),
	    TP_ARGS(obj),

	    TP_STRUCT__entry(
			     __field(struct drm_i915_gem_object *, obj)
			     __field(u32, size)
			     ),

	    TP_fast_assign(
			   __entry->obj = obj;
			   __entry->size = obj->base.size;
			   ),

	    TP_printk("obj=%p, size=%u", __entry->obj, __entry->size)
);

TRACE_EVENT(i915_gem_shrink,
	    TP_PROTO(struct drm_i915_private *i915, unsigned long target, unsigned flags),
	    TP_ARGS(i915, target, flags),

	    TP_STRUCT__entry(
			     __field(int, dev)
			     __field(unsigned long, target)
			     __field(unsigned, flags)
			     ),

	    TP_fast_assign(
			   __entry->dev = i915->dev->primary->index;
			   __entry->target = target;
			   __entry->flags = flags;
			   ),

	    TP_printk("dev=%d, target=%lu, flags=%x",
		      __entry->dev, __entry->target, __entry->flags)
);

TRACE_EVENT(i915_vma_bind,
	    TP_PROTO(struct i915_vma *vma, unsigned flags),
	    TP_ARGS(vma, flags),

	    TP_STRUCT__entry(
			     __field(struct drm_i915_gem_object *, obj)
			     __field(struct i915_address_space *, vm)
			     __field(u64, offset)
			     __field(u32, size)
			     __field(unsigned, flags)
			     ),

	    TP_fast_assign(
			   __entry->obj = vma->obj;
			   __entry->vm = vma->vm;
			   __entry->offset = vma->node.start;
			   __entry->size = vma->node.size;
			   __entry->flags = flags;
			   ),

	    TP_printk("obj=%p, offset=%016llx size=%x%s vm=%p",
		      __entry->obj, __entry->offset, __entry->size,
		      __entry->flags & PIN_MAPPABLE ? ", mappable" : "",
		      __entry->vm)
);

TRACE_EVENT(i915_vma_unbind,
	    TP_PROTO(struct i915_vma *vma),
	    TP_ARGS(vma),

	    TP_STRUCT__entry(
			     __field(struct drm_i915_gem_object *, obj)
			     __field(struct i915_address_space *, vm)
			     __field(u64, offset)
			     __field(u32, size)
			     ),

	    TP_fast_assign(
			   __entry->obj = vma->obj;
			   __entry->vm = vma->vm;
			   __entry->offset = vma->node.start;
			   __entry->size = vma->node.size;
			   ),

	    TP_printk("obj=%p, offset=%016llx size=%x vm=%p",
		      __entry->obj, __entry->offset, __entry->size, __entry->vm)
);

#define VM_TO_TRACE_NAME(vm) \
	(i915_is_ggtt(vm) ? "G" : \
		      "P")

DECLARE_EVENT_CLASS(i915_va,
	TP_PROTO(struct i915_address_space *vm, u64 start, u64 length, const char *name),
	TP_ARGS(vm, start, length, name),

	TP_STRUCT__entry(
		__field(struct i915_address_space *, vm)
		__field(u64, start)
		__field(u64, end)
		__string(name, name)
	),

	TP_fast_assign(
		__entry->vm = vm;
		__entry->start = start;
		__entry->end = start + length - 1;
		__assign_str(name, name);
	),

	TP_printk("vm=%p (%s), 0x%llx-0x%llx",
		  __entry->vm, __get_str(name),  __entry->start, __entry->end)
);

DEFINE_EVENT(i915_va, i915_va_alloc,
	     TP_PROTO(struct i915_address_space *vm, u64 start, u64 length, const char *name),
	     TP_ARGS(vm, start, length, name)
);

DECLARE_EVENT_CLASS(i915_px_entry,
	TP_PROTO(struct i915_address_space *vm, u32 px, u64 start, u64 px_shift),
	TP_ARGS(vm, px, start, px_shift),

	TP_STRUCT__entry(
		__field(struct i915_address_space *, vm)
		__field(u32, px)
		__field(u64, start)
		__field(u64, end)
	),

	TP_fast_assign(
		__entry->vm = vm;
		__entry->px = px;
		__entry->start = start;
		__entry->end = ((start + (1ULL << px_shift)) & ~((1ULL << px_shift)-1)) - 1;
	),

	TP_printk("vm=%p, pde=%d (0x%llx-0x%llx)",
		  __entry->vm, __entry->px, __entry->start, __entry->end)
);

DEFINE_EVENT(i915_px_entry, i915_page_table_entry_alloc,
	     TP_PROTO(struct i915_address_space *vm, u32 pde, u64 start, u64 pde_shift),
	     TP_ARGS(vm, pde, start, pde_shift)
);

DEFINE_EVENT_PRINT(i915_px_entry, i915_page_directory_entry_alloc,
		   TP_PROTO(struct i915_address_space *vm, u32 pdpe, u64 start, u64 pdpe_shift),
		   TP_ARGS(vm, pdpe, start, pdpe_shift),

		   TP_printk("vm=%p, pdpe=%d (0x%llx-0x%llx)",
			     __entry->vm, __entry->px, __entry->start, __entry->end)
);

DEFINE_EVENT_PRINT(i915_px_entry, i915_page_directory_pointer_entry_alloc,
		   TP_PROTO(struct i915_address_space *vm, u32 pml4e, u64 start, u64 pml4e_shift),
		   TP_ARGS(vm, pml4e, start, pml4e_shift),

		   TP_printk("vm=%p, pml4e=%d (0x%llx-0x%llx)",
			     __entry->vm, __entry->px, __entry->start, __entry->end)
);

/* Avoid extra math because we only support two sizes. The format is defined by
 * bitmap_scnprintf. Each 32 bits is 8 HEX digits followed by comma */
#define TRACE_PT_SIZE(bits) \
	((((bits) == 1024) ? 288 : 144) + 1)

DECLARE_EVENT_CLASS(i915_page_table_entry_update,
	TP_PROTO(struct i915_address_space *vm, u32 pde,
		 struct i915_page_table *pt, u32 first, u32 count, u32 bits),
	TP_ARGS(vm, pde, pt, first, count, bits),

	TP_STRUCT__entry(
		__field(struct i915_address_space *, vm)
		__field(u32, pde)
		__field(u32, first)
		__field(u32, last)
		__dynamic_array(char, cur_ptes, TRACE_PT_SIZE(bits))
	),

	TP_fast_assign(
		__entry->vm = vm;
		__entry->pde = pde;
		__entry->first = first;
		__entry->last = first + count - 1;
		scnprintf(__get_str(cur_ptes),
			  TRACE_PT_SIZE(bits),
			  "%*pb",
			  bits,
			  pt->used_ptes);
	),

	TP_printk("vm=%p, pde=%d, updating %u:%u\t%s",
		  __entry->vm, __entry->pde, __entry->last, __entry->first,
		  __get_str(cur_ptes))
);

DEFINE_EVENT(i915_page_table_entry_update, i915_page_table_entry_map,
	TP_PROTO(struct i915_address_space *vm, u32 pde,
		 struct i915_page_table *pt, u32 first, u32 count, u32 bits),
	TP_ARGS(vm, pde, pt, first, count, bits)
);

TRACE_EVENT(i915_gem_object_change_domain,
	    TP_PROTO(struct drm_i915_gem_object *obj, u32 old_read, u32 old_write),
	    TP_ARGS(obj, old_read, old_write),

	    TP_STRUCT__entry(
			     __field(struct drm_i915_gem_object *, obj)
			     __field(u32, read_domains)
			     __field(u32, write_domain)
			     ),

	    TP_fast_assign(
			   __entry->obj = obj;
			   __entry->read_domains = obj->base.read_domains | (old_read << 16);
			   __entry->write_domain = obj->base.write_domain | (old_write << 16);
			   ),

	    TP_printk("obj=%p, read=%02x=>%02x, write=%02x=>%02x",
		      __entry->obj,
		      __entry->read_domains >> 16,
		      __entry->read_domains & 0xffff,
		      __entry->write_domain >> 16,
		      __entry->write_domain & 0xffff)
);

TRACE_EVENT(i915_gem_object_pwrite,
	    TP_PROTO(struct drm_i915_gem_object *obj, u32 offset, u32 len),
	    TP_ARGS(obj, offset, len),

	    TP_STRUCT__entry(
			     __field(struct drm_i915_gem_object *, obj)
			     __field(u32, offset)
			     __field(u32, len)
			     ),

	    TP_fast_assign(
			   __entry->obj = obj;
			   __entry->offset = offset;
			   __entry->len = len;
			   ),

	    TP_printk("obj=%p, offset=%u, len=%u",
		      __entry->obj, __entry->offset, __entry->len)
);

TRACE_EVENT(i915_gem_object_pread,
	    TP_PROTO(struct drm_i915_gem_object *obj, u32 offset, u32 len),
	    TP_ARGS(obj, offset, len),

	    TP_STRUCT__entry(
			     __field(struct drm_i915_gem_object *, obj)
			     __field(u32, offset)
			     __field(u32, len)
			     ),

	    TP_fast_assign(
			   __entry->obj = obj;
			   __entry->offset = offset;
			   __entry->len = len;
			   ),

	    TP_printk("obj=%p, offset=%u, len=%u",
		      __entry->obj, __entry->offset, __entry->len)
);

TRACE_EVENT(i915_gem_object_fault,
	    TP_PROTO(struct drm_i915_gem_object *obj, u32 index, bool gtt, bool write),
	    TP_ARGS(obj, index, gtt, write),

	    TP_STRUCT__entry(
			     __field(struct drm_i915_gem_object *, obj)
			     __field(u32, index)
			     __field(bool, gtt)
			     __field(bool, write)
			     ),

	    TP_fast_assign(
			   __entry->obj = obj;
			   __entry->index = index;
			   __entry->gtt = gtt;
			   __entry->write = write;
			   ),

	    TP_printk("obj=%p, %s index=%u %s",
		      __entry->obj,
		      __entry->gtt ? "GTT" : "CPU",
		      __entry->index,
		      __entry->write ? ", writable" : "")
);

DECLARE_EVENT_CLASS(i915_gem_object,
	    TP_PROTO(struct drm_i915_gem_object *obj),
	    TP_ARGS(obj),

	    TP_STRUCT__entry(
			     __field(struct drm_i915_gem_object *, obj)
			     ),

	    TP_fast_assign(
			   __entry->obj = obj;
			   ),

	    TP_printk("obj=%p", __entry->obj)
);

DEFINE_EVENT(i915_gem_object, i915_gem_object_clflush,
	     TP_PROTO(struct drm_i915_gem_object *obj),
	     TP_ARGS(obj)
);

DEFINE_EVENT(i915_gem_object, i915_gem_object_destroy,
	    TP_PROTO(struct drm_i915_gem_object *obj),
	    TP_ARGS(obj)
);

TRACE_EVENT(i915_gem_evict,
	    TP_PROTO(struct drm_device *dev, u32 size, u32 align, unsigned flags),
	    TP_ARGS(dev, size, align, flags),

	    TP_STRUCT__entry(
			     __field(u32, dev)
			     __field(u32, size)
			     __field(u32, align)
			     __field(unsigned, flags)
			    ),

	    TP_fast_assign(
			   __entry->dev = dev->primary->index;
			   __entry->size = size;
			   __entry->align = align;
			   __entry->flags = flags;
			  ),

	    TP_printk("dev=%d, size=%d, align=%d %s",
		      __entry->dev, __entry->size, __entry->align,
		      __entry->flags & PIN_MAPPABLE ? ", mappable" : "")
);

TRACE_EVENT(i915_gem_evict_everything,
	    TP_PROTO(struct drm_device *dev),
	    TP_ARGS(dev),

	    TP_STRUCT__entry(
			     __field(u32, dev)
			    ),

	    TP_fast_assign(
			   __entry->dev = dev->primary->index;
			  ),

	    TP_printk("dev=%d", __entry->dev)
);

TRACE_EVENT(i915_gem_evict_vm,
	    TP_PROTO(struct i915_address_space *vm),
	    TP_ARGS(vm),

	    TP_STRUCT__entry(
			     __field(u32, dev)
			     __field(struct i915_address_space *, vm)
			    ),

	    TP_fast_assign(
			   __entry->dev = vm->dev->primary->index;
			   __entry->vm = vm;
			  ),

	    TP_printk("dev=%d, vm=%p", __entry->dev, __entry->vm)
);

TRACE_EVENT(i915_gem_ring_sync_to,
	    TP_PROTO(struct drm_i915_gem_request *to_req,
		     struct intel_engine_cs *from,
		     struct drm_i915_gem_request *req),
	    TP_ARGS(to_req, from, req),

	    TP_STRUCT__entry(
			     __field(u32, dev)
			     __field(u32, sync_from)
			     __field(u32, sync_to)
			     __field(u32, seqno)
			     ),

	    TP_fast_assign(
			   __entry->dev = from->dev->primary->index;
			   __entry->sync_from = from->id;
			   __entry->sync_to = to_req->ring->id;
			   __entry->seqno = i915_gem_request_get_seqno(req);
			   ),

	    TP_printk("dev=%u, sync-from=%u, sync-to=%u, seqno=%u",
		      __entry->dev,
		      __entry->sync_from, __entry->sync_to,
		      __entry->seqno)
);

TRACE_EVENT(i915_gem_ring_dispatch,
	    TP_PROTO(struct drm_i915_gem_request *req, u32 flags),
	    TP_ARGS(req, flags),

	    TP_STRUCT__entry(
			     __field(u32, dev)
			     __field(u32, ring)
			     __field(u32, seqno)
			     __field(u32, flags)
			     ),

	    TP_fast_assign(
			   struct intel_engine_cs *ring =
						i915_gem_request_get_ring(req);
			   __entry->dev = ring->dev->primary->index;
			   __entry->ring = ring->id;
			   __entry->seqno = i915_gem_request_get_seqno(req);
			   __entry->flags = flags;
			   i915_trace_irq_get(ring, req);
			   ),

	    TP_printk("dev=%u, ring=%u, seqno=%u, flags=%x",
		      __entry->dev, __entry->ring, __entry->seqno, __entry->flags)
);

TRACE_EVENT(i915_gem_ring_flush,
	    TP_PROTO(struct drm_i915_gem_request *req, u32 invalidate, u32 flush),
	    TP_ARGS(req, invalidate, flush),

	    TP_STRUCT__entry(
			     __field(u32, dev)
			     __field(u32, ring)
			     __field(u32, invalidate)
			     __field(u32, flush)
			     ),

	    TP_fast_assign(
			   __entry->dev = req->ring->dev->primary->index;
			   __entry->ring = req->ring->id;
			   __entry->invalidate = invalidate;
			   __entry->flush = flush;
			   ),

	    TP_printk("dev=%u, ring=%x, invalidate=%04x, flush=%04x",
		      __entry->dev, __entry->ring,
		      __entry->invalidate, __entry->flush)
);

DECLARE_EVENT_CLASS(i915_gem_request,
	    TP_PROTO(struct drm_i915_gem_request *req),
	    TP_ARGS(req),

	    TP_STRUCT__entry(
			     __field(u32, dev)
			     __field(u32, ring)
			     __field(u32, seqno)
			     ),

	    TP_fast_assign(
			   struct intel_engine_cs *ring =
						i915_gem_request_get_ring(req);
			   __entry->dev = ring->dev->primary->index;
			   __entry->ring = ring->id;
			   __entry->seqno = i915_gem_request_get_seqno(req);
			   ),

	    TP_printk("dev=%u, ring=%u, seqno=%u",
		      __entry->dev, __entry->ring, __entry->seqno)
);

DEFINE_EVENT(i915_gem_request, i915_gem_request_add,
	    TP_PROTO(struct drm_i915_gem_request *req),
	    TP_ARGS(req)
);

TRACE_EVENT(i915_gem_request_notify,
	    TP_PROTO(struct intel_engine_cs *ring),
	    TP_ARGS(ring),

	    TP_STRUCT__entry(
			     __field(u32, dev)
			     __field(u32, ring)
			     __field(u32, seqno)
			     ),

	    TP_fast_assign(
			   __entry->dev = ring->dev->primary->index;
			   __entry->ring = ring->id;
			   __entry->seqno = ring->get_seqno(ring, false);
			   ),

	    TP_printk("dev=%u, ring=%u, seqno=%u",
		      __entry->dev, __entry->ring, __entry->seqno)
);

DEFINE_EVENT(i915_gem_request, i915_gem_request_retire,
	    TP_PROTO(struct drm_i915_gem_request *req),
	    TP_ARGS(req)
);

DEFINE_EVENT(i915_gem_request, i915_gem_request_complete,
	    TP_PROTO(struct drm_i915_gem_request *req),
	    TP_ARGS(req)
);

TRACE_EVENT(i915_gem_request_wait_begin,
	    TP_PROTO(struct drm_i915_gem_request *req),
	    TP_ARGS(req),

	    TP_STRUCT__entry(
			     __field(u32, dev)
			     __field(u32, ring)
			     __field(u32, seqno)
			     __field(bool, blocking)
			     ),

	    /* NB: the blocking information is racy since mutex_is_locked
	     * doesn't check that the current thread holds the lock. The only
	     * other option would be to pass the boolean information of whether
	     * or not the class was blocking down through the stack which is
	     * less desirable.
	     */
	    TP_fast_assign(
			   struct intel_engine_cs *ring =
						i915_gem_request_get_ring(req);
			   __entry->dev = ring->dev->primary->index;
			   __entry->ring = ring->id;
			   __entry->seqno = i915_gem_request_get_seqno(req);
			   __entry->blocking =
				     mutex_is_locked(&ring->dev->struct_mutex);
			   ),

	    TP_printk("dev=%u, ring=%u, seqno=%u, blocking=%s",
		      __entry->dev, __entry->ring,
		      __entry->seqno, __entry->blocking ?  "yes (NB)" : "no")
);

DEFINE_EVENT(i915_gem_request, i915_gem_request_wait_end,
	    TP_PROTO(struct drm_i915_gem_request *req),
	    TP_ARGS(req)
);

TRACE_EVENT(i915_flip_request,
	    TP_PROTO(int plane, struct drm_i915_gem_object *obj),

	    TP_ARGS(plane, obj),

	    TP_STRUCT__entry(
		    __field(int, plane)
		    __field(struct drm_i915_gem_object *, obj)
		    ),

	    TP_fast_assign(
		    __entry->plane = plane;
		    __entry->obj = obj;
		    ),

	    TP_printk("plane=%d, obj=%p", __entry->plane, __entry->obj)
);

TRACE_EVENT(i915_flip_complete,
	    TP_PROTO(int plane, struct drm_i915_gem_object *obj),

	    TP_ARGS(plane, obj),

	    TP_STRUCT__entry(
		    __field(int, plane)
		    __field(struct drm_i915_gem_object *, obj)
		    ),

	    TP_fast_assign(
		    __entry->plane = plane;
		    __entry->obj = obj;
		    ),

	    TP_printk("plane=%d, obj=%p", __entry->plane, __entry->obj)
);

TRACE_EVENT_CONDITION(i915_reg_rw,
	TP_PROTO(bool write, u32 reg, u64 val, int len, bool trace),

	TP_ARGS(write, reg, val, len, trace),

	TP_CONDITION(trace),

	TP_STRUCT__entry(
		__field(u64, val)
		__field(u32, reg)
		__field(u16, write)
		__field(u16, len)
		),

	TP_fast_assign(
		__entry->val = (u64)val;
		__entry->reg = reg;
		__entry->write = write;
		__entry->len = len;
		),

	TP_printk("%s reg=0x%x, len=%d, val=(0x%x, 0x%x)",
		__entry->write ? "write" : "read",
		__entry->reg, __entry->len,
		(u32)(__entry->val & 0xffffffff),
		(u32)(__entry->val >> 32))
);

TRACE_EVENT(intel_gpu_freq_change,
	    TP_PROTO(u32 freq),
	    TP_ARGS(freq),

	    TP_STRUCT__entry(
			     __field(u32, freq)
			     ),

	    TP_fast_assign(
			   __entry->freq = freq;
			   ),

	    TP_printk("new_freq=%u", __entry->freq)
);

/**
 * DOC: i915_ppgtt_create and i915_ppgtt_release tracepoints
 *
 * With full ppgtt enabled each process using drm will allocate at least one
 * translation table. With these traces it is possible to keep track of the
 * allocation and of the lifetime of the tables; this can be used during
 * testing/debug to verify that we are not leaking ppgtts.
 * These traces identify the ppgtt through the vm pointer, which is also printed
 * by the i915_vma_bind and i915_vma_unbind tracepoints.
 */
DECLARE_EVENT_CLASS(i915_ppgtt,
	TP_PROTO(struct i915_address_space *vm),
	TP_ARGS(vm),

	TP_STRUCT__entry(
			__field(struct i915_address_space *, vm)
			__field(u32, dev)
	),

	TP_fast_assign(
			__entry->vm = vm;
			__entry->dev = vm->dev->primary->index;
	),

	TP_printk("dev=%u, vm=%p", __entry->dev, __entry->vm)
)

DEFINE_EVENT(i915_ppgtt, i915_ppgtt_create,
	TP_PROTO(struct i915_address_space *vm),
	TP_ARGS(vm)
);

DEFINE_EVENT(i915_ppgtt, i915_ppgtt_release,
	TP_PROTO(struct i915_address_space *vm),
	TP_ARGS(vm)
);

/**
 * DOC: i915_context_create and i915_context_free tracepoints
 *
 * These tracepoints are used to track creation and deletion of contexts.
 * If full ppgtt is enabled, they also print the address of the vm assigned to
 * the context.
 */
DECLARE_EVENT_CLASS(i915_context,
	TP_PROTO(struct intel_context *ctx),
	TP_ARGS(ctx),

	TP_STRUCT__entry(
			__field(u32, dev)
			__field(struct intel_context *, ctx)
			__field(struct i915_address_space *, vm)
	),

	TP_fast_assign(
			__entry->ctx = ctx;
			__entry->vm = ctx->ppgtt ? &ctx->ppgtt->base : NULL;
			__entry->dev = ctx->i915->dev->primary->index;
	),

	TP_printk("dev=%u, ctx=%p, ctx_vm=%p",
		  __entry->dev, __entry->ctx, __entry->vm)
)

DEFINE_EVENT(i915_context, i915_context_create,
	TP_PROTO(struct intel_context *ctx),
	TP_ARGS(ctx)
);

DEFINE_EVENT(i915_context, i915_context_free,
	TP_PROTO(struct intel_context *ctx),
	TP_ARGS(ctx)
);

/**
 * DOC: switch_mm tracepoint
 *
 * This tracepoint allows tracking of the mm switch, which is an important point
 * in the lifetime of the vm in the legacy submission path. This tracepoint is
 * called only if full ppgtt is enabled.
 */
TRACE_EVENT(switch_mm,
	TP_PROTO(struct intel_engine_cs *ring, struct intel_context *to),

	TP_ARGS(ring, to),

	TP_STRUCT__entry(
			__field(u32, ring)
			__field(struct intel_context *, to)
			__field(struct i915_address_space *, vm)
			__field(u32, dev)
	),

	TP_fast_assign(
			__entry->ring = ring->id;
			__entry->to = to;
			__entry->vm = to->ppgtt? &to->ppgtt->base : NULL;
			__entry->dev = ring->dev->primary->index;
	),

	TP_printk("dev=%u, ring=%u, ctx=%p, ctx_vm=%p",
		  __entry->dev, __entry->ring, __entry->to, __entry->vm)
);

#endif /* _I915_TRACE_H_ */

/* This part must be outside protection */
#undef TRACE_INCLUDE_PATH
#define TRACE_INCLUDE_PATH .
#ifdef __linux__
#include <trace/define_trace.h>
#endif
@


1.13
log
@Update inteldrm to the code from Linux 3.14.52 (which corresponds to
commit 48f8f36a6c8018c2b36ea207aaf68ef5326c5075 on the linux-3.14.y
branch of the linux-stable tree).  This brings preliminary support for
the GPU on Intel's Broadwell CPUs.  Don't expect these to work
perfectly yet.  There are some remaining issues with older hardware as
well, but no significant regressions have been uncovered.

This also updates some of drm core code.  The radeondrm code remains
based on Linux 3.8 with some minimal canges to adjust to changes in
the core drm APIs.

Joint effort with jsg@@, who did the initial update of the relevant drm
core bits.  Committing this early to make sure it gets more testing
and make it possible for others to help getting the remaining wrinkles
straightened out.
@
text
@a0 1
/*	$OpenBSD: i915_trace.h,v 1.12 2015/04/18 11:41:28 jsg Exp $	*/
d4 6
d12 1
a16 1
#define TRACE_SYSTEM_STRING __stringify(TRACE_SYSTEM)
d19 74
d112 20
d133 2
a134 2
	    TP_PROTO(struct i915_vma *vma, bool mappable),
	    TP_ARGS(vma, mappable),
d139 1
a139 1
			     __field(u32, offset)
d141 1
a141 1
			     __field(bool, mappable)
d149 1
a149 1
			   __entry->mappable = mappable;
d152 1
a152 1
	    TP_printk("obj=%p, offset=%08x size=%x%s vm=%p",
d154 1
a154 1
		      __entry->mappable ? ", mappable" : "",
d165 1
a165 1
			     __field(u32, offset)
d176 1
a176 1
	    TP_printk("obj=%p, offset=%08x size=%x vm=%p",
d180 115
d410 2
a411 2
	    TP_PROTO(struct drm_device *dev, u32 size, u32 align, bool mappable),
	    TP_ARGS(dev, size, align, mappable),
d417 1
a417 1
			     __field(bool, mappable)
d424 1
a424 1
			   __entry->mappable = mappable;
d429 1
a429 1
		      __entry->mappable ? ", mappable" : "")
d465 4
a468 4
	    TP_PROTO(struct intel_ring_buffer *from,
		     struct intel_ring_buffer *to,
		     u32 seqno),
	    TP_ARGS(from, to, seqno),
d480 2
a481 2
			   __entry->sync_to = to->id;
			   __entry->seqno = seqno;
d491 2
a492 2
	    TP_PROTO(struct intel_ring_buffer *ring, u32 seqno, u32 flags),
	    TP_ARGS(ring, seqno, flags),
d502 2
d506 1
a506 1
			   __entry->seqno = seqno;
d508 1
a508 1
			   i915_trace_irq_get(ring, seqno);
d516 2
a517 2
	    TP_PROTO(struct intel_ring_buffer *ring, u32 invalidate, u32 flush),
	    TP_ARGS(ring, invalidate, flush),
d527 2
a528 2
			   __entry->dev = ring->dev->primary->index;
			   __entry->ring = ring->id;
d539 2
a540 2
	    TP_PROTO(struct intel_ring_buffer *ring, u32 seqno),
	    TP_ARGS(ring, seqno),
d549 2
d553 1
a553 1
			   __entry->seqno = seqno;
d561 2
a562 2
	    TP_PROTO(struct intel_ring_buffer *ring, u32 seqno),
	    TP_ARGS(ring, seqno)
d565 2
a566 2
TRACE_EVENT(i915_gem_request_complete,
	    TP_PROTO(struct intel_ring_buffer *ring),
d586 7
a592 2
	    TP_PROTO(struct intel_ring_buffer *ring, u32 seqno),
	    TP_ARGS(ring, seqno)
d596 2
a597 2
	    TP_PROTO(struct intel_ring_buffer *ring, u32 seqno),
	    TP_ARGS(ring, seqno),
d613 2
d617 3
a619 2
			   __entry->seqno = seqno;
			   __entry->blocking = mutex_is_locked(&ring->dev->struct_mutex);
d623 2
a624 2
		      __entry->dev, __entry->ring, __entry->seqno,
		      __entry->blocking ?  "yes (NB)" : "no")
d628 2
a629 29
	    TP_PROTO(struct intel_ring_buffer *ring, u32 seqno),
	    TP_ARGS(ring, seqno)
);

DECLARE_EVENT_CLASS(i915_ring,
	    TP_PROTO(struct intel_ring_buffer *ring),
	    TP_ARGS(ring),

	    TP_STRUCT__entry(
			     __field(u32, dev)
			     __field(u32, ring)
			     ),

	    TP_fast_assign(
			   __entry->dev = ring->dev->primary->index;
			   __entry->ring = ring->id;
			   ),

	    TP_printk("dev=%u, ring=%u", __entry->dev, __entry->ring)
);

DEFINE_EVENT(i915_ring, i915_ring_wait_begin,
	    TP_PROTO(struct intel_ring_buffer *ring),
	    TP_ARGS(ring)
);

DEFINE_EVENT(i915_ring, i915_ring_wait_end,
	    TP_PROTO(struct intel_ring_buffer *ring),
	    TP_ARGS(ring)
d711 104
d820 3
@


1.12
log
@define and use trace macros
discussed with kettenis
@
text
@d1 1
a1 1
/*	$OpenBSD: i915_trace.h,v 1.11 2015/04/12 17:10:07 kettenis Exp $	*/
d33 3
a35 3
TRACE_EVENT(i915_gem_object_bind,
	    TP_PROTO(struct drm_i915_gem_object *obj, bool mappable),
	    TP_ARGS(obj, mappable),
d39 1
d46 4
a49 3
			   __entry->obj = obj;
			   __entry->offset = obj->gtt_space->start;
			   __entry->size = obj->gtt_space->size;
d53 1
a53 1
	    TP_printk("obj=%p, offset=%08x size=%x%s",
d55 2
a56 1
		      __entry->mappable ? ", mappable" : "")
d59 3
a61 3
TRACE_EVENT(i915_gem_object_unbind,
	    TP_PROTO(struct drm_i915_gem_object *obj),
	    TP_ARGS(obj),
d65 1
d71 4
a74 3
			   __entry->obj = obj;
			   __entry->offset = obj->gtt_space->start;
			   __entry->size = obj->gtt_space->size;
d77 2
a78 2
	    TP_printk("obj=%p, offset=%08x size=%x",
		      __entry->obj, __entry->offset, __entry->size)
d233 43
d347 18
a364 3
DEFINE_EVENT(i915_gem_request, i915_gem_request_complete,
	    TP_PROTO(struct intel_ring_buffer *ring, u32 seqno),
	    TP_ARGS(ring, seqno)
d469 4
a472 2
TRACE_EVENT(i915_reg_rw,
	TP_PROTO(bool write, u32 reg, u64 val, int len),
d474 1
a474 1
	TP_ARGS(write, reg, val, len),
@


1.11
log
@Add a few missing trace functions, and "use" them.  Add back the WATCH_GTT
code (that isn't actually compiled in).  Use dev_priv->dev in one more place
now that we have it, and add set_normalized_timespec() and use it.
@
text
@d1 451
a451 126
/*	$OpenBSD: i915_trace.h,v 1.10 2013/12/15 11:42:10 kettenis Exp $	*/
/*
 * Copyright (c) 2013 Mark Kettenis <kettenis@@openbsd.org>
 *
 * Permission to use, copy, modify, and distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 */

static inline void
trace_i915_gem_object_create(struct drm_i915_gem_object *obj)
{
}

static inline void
trace_i915_gem_object_destroy(struct drm_i915_gem_object *obj)
{
}

static inline void
trace_i915_gem_request_add(struct intel_ring_buffer *ring, u32 seqno)
{
}

static inline void
trace_i915_gem_request_complete(struct intel_ring_buffer *ring, u32 seqno)
{
}

static inline void
trace_i915_gem_request_retire(struct intel_ring_buffer *ring, u32 seqno)
{
}

static inline void
trace_i915_gem_request_wait_begin(struct intel_ring_buffer *ring, u32 seqno)
{
}

static inline void
trace_i915_gem_request_wait_end(struct intel_ring_buffer *ring, u32 seqno)
{
}

static inline void
trace_i915_ring_wait_begin(struct intel_ring_buffer *ring)
{
}

static inline void
trace_i915_ring_wait_end(struct intel_ring_buffer *ring)
{
}

static inline void
trace_i915_flip_request(int plane, struct drm_i915_gem_object *obj)
{
}

static inline void
trace_i915_flip_complete(int plane, struct drm_i915_gem_object *obj)
{
}

static inline void
trace_i915_gem_object_change_domain(struct drm_i915_gem_object *obj,
				    u32 old_read, u32 old_write)
{
}

static inline void
trace_i915_gem_object_pwrite(struct drm_i915_gem_object *obj,
			     u32 offset, u32 len)
{
}

static inline void
trace_i915_gem_object_pread(struct drm_i915_gem_object *obj,
			    u32 offset, u32 len)
{
}

static inline void
trace_i915_gem_object_bind(struct drm_i915_gem_object *obj, bool mappable)
{
}

static inline void
trace_i915_gem_object_unbind(struct drm_i915_gem_object *obj)
{
}

static inline void
trace_i915_reg_rw(bool write, u32 reg, u64 val, int len)
{
}

static inline void
trace_i915_gem_evict(struct drm_device *dev, u32 size, u32 align, bool mappable)
{
}

static inline void
trace_i915_gem_evict_everything(struct drm_device *dev)
{
}

static inline void
trace_i915_gem_ring_dispatch(struct intel_ring_buffer *ring, u32 seqno,
			     u32 flags)
{
}

static inline void
trace_i915_gem_ring_flush(struct intel_ring_buffer *ring, u32 invalidate,
			     u32 flush)
{
}
@


1.10
log
@Overhaul the pread and pwrite code to match what Linux does.  Should fix a few
more cache coherency issues, hopefully reducing the number of artifacts
showing up the screen.
@
text
@d1 1
a1 1
/*	$OpenBSD: i915_trace.h,v 1.9 2013/12/01 11:47:13 kettenis Exp $	*/
d24 5
d34 5
d54 20
d113 12
@


1.9
log
@Bring back the DRM_IOCTL_I915_GEM_WAIT diff now that I've figured out what
made it fail (WARN_ON() was evaluating its argument multiple times).
This time, also advertise support through I915_PARAM_HAS_WAIT_TIMEOUT.
@
text
@d1 1
a1 1
/*	$OpenBSD: i915_trace.h,v 1.8 2013/11/30 20:13:36 kettenis Exp $	*/
d46 12
@


1.8
log
@Oops!  Only intended to commit the i915_dma.c changes in the previous commit.
@
text
@d1 1
a1 1
/*	$OpenBSD: i915_trace.h,v 1.6 2013/11/20 02:03:52 jsg Exp $	*/
d30 10
@


1.7
log
@Reorder some case statements to reduce the diffs with Linux.
@
text
@a33 10
trace_i915_gem_request_wait_begin(struct intel_ring_buffer *ring, u32 seqno)
{
}

static inline void
trace_i915_gem_request_wait_end(struct intel_ring_buffer *ring, u32 seqno)
{
}

static inline void
@


1.6
log
@switch to the drm_mm based gtt eviction code from linux 3.8.13
ok kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: i915_trace.h,v 1.5 2013/11/19 15:08:04 jsg Exp $	*/
d30 10
@


1.5
log
@backout the DRM_IOCTL_I915_GEM_WAIT commit
it seems to leave X unuseable on resume on at least snb/ivb
ok kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: i915_trace.h,v 1.4 2013/11/17 18:47:13 kettenis Exp $	*/
d51 10
@


1.4
log
@Implement DRM_IOCTL_I915_GEM_WAIT.  Based on an earlier diff from jsg@@

ok jsg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: i915_trace.h,v 1.3 2013/11/02 22:58:10 kettenis Exp $	*/
a29 10
{
}

static inline void
trace_i915_gem_request_wait_begin(struct intel_ring_buffer *ring, u32 seqno)
{
}

static inline void
trace_i915_gem_request_wait_end(struct intel_ring_buffer *ring, u32 seqno)
@


1.3
log
@Replace drm_handle_create/delete with drm_gem_handle_create/delete and make
the necessary adjustments to reference counting of GEM objects.  Matches what
Linux does these days.
@
text
@d1 1
a1 1
/*	$OpenBSD: i915_trace.h,v 1.2 2013/09/30 06:47:48 jsg Exp $	*/
d30 10
@


1.2
log
@move the read/write functions and macros closer to linux
noteably this uses the gt lock and force wake in some cases
and includes a gen5/ironlake errata.
ok kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: i915_trace.h,v 1.1 2013/08/07 19:49:07 kettenis Exp $	*/
d17 5
@


1.1
log
@Another major overhaul of the inteldrm(4) GEM code, bringing us considerably
closer to the Linux 3.8.13 codebase.  Almost certainly squashes a few more
bugs.

ok jsg@@
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d41 5
@

