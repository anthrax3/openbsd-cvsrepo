head	1.13;
access;
symbols
	OPENBSD_6_1:1.13.0.8
	OPENBSD_6_1_BASE:1.13
	OPENBSD_6_0:1.13.0.6
	OPENBSD_6_0_BASE:1.13
	OPENBSD_5_9:1.13.0.2
	OPENBSD_5_9_BASE:1.13
	OPENBSD_5_8:1.12.0.4
	OPENBSD_5_8_BASE:1.12
	OPENBSD_5_7:1.10.0.8
	OPENBSD_5_7_BASE:1.10
	OPENBSD_5_6:1.10.0.6
	OPENBSD_5_6_BASE:1.10
	OPENBSD_5_5:1.10.0.4
	OPENBSD_5_5_BASE:1.10;
locks; strict;
comment	@ * @;


1.13
date	2015.09.23.23.12.12;	author kettenis;	state Exp;
branches;
next	1.12;
commitid	lQlppvmETCN49oZe;

1.12
date	2015.04.18.11.41.28;	author jsg;	state Exp;
branches;
next	1.11;
commitid	c3CbYQJYD10xhd6O;

1.11
date	2015.04.12.17.10.07;	author kettenis;	state Exp;
branches;
next	1.10;
commitid	7RIU3AxWXbuzxDet;

1.10
date	2013.12.15.11.42.10;	author kettenis;	state Exp;
branches;
next	1.9;

1.9
date	2013.12.01.11.47.13;	author kettenis;	state Exp;
branches;
next	1.8;

1.8
date	2013.11.30.20.13.36;	author kettenis;	state Exp;
branches;
next	1.7;

1.7
date	2013.11.30.20.03.32;	author kettenis;	state Exp;
branches;
next	1.6;

1.6
date	2013.11.20.02.03.52;	author jsg;	state Exp;
branches;
next	1.5;

1.5
date	2013.11.19.15.08.04;	author jsg;	state Exp;
branches;
next	1.4;

1.4
date	2013.11.17.18.47.13;	author kettenis;	state Exp;
branches;
next	1.3;

1.3
date	2013.11.02.22.58.10;	author kettenis;	state Exp;
branches;
next	1.2;

1.2
date	2013.09.30.06.47.48;	author jsg;	state Exp;
branches;
next	1.1;

1.1
date	2013.08.07.19.49.07;	author kettenis;	state Exp;
branches;
next	;


desc
@@


1.13
log
@Update inteldrm to the code from Linux 3.14.52 (which corresponds to
commit 48f8f36a6c8018c2b36ea207aaf68ef5326c5075 on the linux-3.14.y
branch of the linux-stable tree).  This brings preliminary support for
the GPU on Intel's Broadwell CPUs.  Don't expect these to work
perfectly yet.  There are some remaining issues with older hardware as
well, but no significant regressions have been uncovered.

This also updates some of drm core code.  The radeondrm code remains
based on Linux 3.8 with some minimal canges to adjust to changes in
the core drm APIs.

Joint effort with jsg@@, who did the initial update of the relevant drm
core bits.  Committing this early to make sure it gets more testing
and make it possible for others to help getting the remaining wrinkles
straightened out.
@
text
@/*	$OpenBSD: i915_trace.h,v 1.12 2015/04/18 11:41:28 jsg Exp $	*/
#if !defined(_I915_TRACE_H_) || defined(TRACE_HEADER_MULTI_READ)
#define _I915_TRACE_H_

#include <dev/pci/drm/drmP.h>
#include "i915_drv.h"
#include "intel_ringbuffer.h"

#undef TRACE_SYSTEM
#define TRACE_SYSTEM i915
#define TRACE_SYSTEM_STRING __stringify(TRACE_SYSTEM)
#define TRACE_INCLUDE_FILE i915_trace

/* object tracking */

TRACE_EVENT(i915_gem_object_create,
	    TP_PROTO(struct drm_i915_gem_object *obj),
	    TP_ARGS(obj),

	    TP_STRUCT__entry(
			     __field(struct drm_i915_gem_object *, obj)
			     __field(u32, size)
			     ),

	    TP_fast_assign(
			   __entry->obj = obj;
			   __entry->size = obj->base.size;
			   ),

	    TP_printk("obj=%p, size=%u", __entry->obj, __entry->size)
);

TRACE_EVENT(i915_vma_bind,
	    TP_PROTO(struct i915_vma *vma, bool mappable),
	    TP_ARGS(vma, mappable),

	    TP_STRUCT__entry(
			     __field(struct drm_i915_gem_object *, obj)
			     __field(struct i915_address_space *, vm)
			     __field(u32, offset)
			     __field(u32, size)
			     __field(bool, mappable)
			     ),

	    TP_fast_assign(
			   __entry->obj = vma->obj;
			   __entry->vm = vma->vm;
			   __entry->offset = vma->node.start;
			   __entry->size = vma->node.size;
			   __entry->mappable = mappable;
			   ),

	    TP_printk("obj=%p, offset=%08x size=%x%s vm=%p",
		      __entry->obj, __entry->offset, __entry->size,
		      __entry->mappable ? ", mappable" : "",
		      __entry->vm)
);

TRACE_EVENT(i915_vma_unbind,
	    TP_PROTO(struct i915_vma *vma),
	    TP_ARGS(vma),

	    TP_STRUCT__entry(
			     __field(struct drm_i915_gem_object *, obj)
			     __field(struct i915_address_space *, vm)
			     __field(u32, offset)
			     __field(u32, size)
			     ),

	    TP_fast_assign(
			   __entry->obj = vma->obj;
			   __entry->vm = vma->vm;
			   __entry->offset = vma->node.start;
			   __entry->size = vma->node.size;
			   ),

	    TP_printk("obj=%p, offset=%08x size=%x vm=%p",
		      __entry->obj, __entry->offset, __entry->size, __entry->vm)
);

TRACE_EVENT(i915_gem_object_change_domain,
	    TP_PROTO(struct drm_i915_gem_object *obj, u32 old_read, u32 old_write),
	    TP_ARGS(obj, old_read, old_write),

	    TP_STRUCT__entry(
			     __field(struct drm_i915_gem_object *, obj)
			     __field(u32, read_domains)
			     __field(u32, write_domain)
			     ),

	    TP_fast_assign(
			   __entry->obj = obj;
			   __entry->read_domains = obj->base.read_domains | (old_read << 16);
			   __entry->write_domain = obj->base.write_domain | (old_write << 16);
			   ),

	    TP_printk("obj=%p, read=%02x=>%02x, write=%02x=>%02x",
		      __entry->obj,
		      __entry->read_domains >> 16,
		      __entry->read_domains & 0xffff,
		      __entry->write_domain >> 16,
		      __entry->write_domain & 0xffff)
);

TRACE_EVENT(i915_gem_object_pwrite,
	    TP_PROTO(struct drm_i915_gem_object *obj, u32 offset, u32 len),
	    TP_ARGS(obj, offset, len),

	    TP_STRUCT__entry(
			     __field(struct drm_i915_gem_object *, obj)
			     __field(u32, offset)
			     __field(u32, len)
			     ),

	    TP_fast_assign(
			   __entry->obj = obj;
			   __entry->offset = offset;
			   __entry->len = len;
			   ),

	    TP_printk("obj=%p, offset=%u, len=%u",
		      __entry->obj, __entry->offset, __entry->len)
);

TRACE_EVENT(i915_gem_object_pread,
	    TP_PROTO(struct drm_i915_gem_object *obj, u32 offset, u32 len),
	    TP_ARGS(obj, offset, len),

	    TP_STRUCT__entry(
			     __field(struct drm_i915_gem_object *, obj)
			     __field(u32, offset)
			     __field(u32, len)
			     ),

	    TP_fast_assign(
			   __entry->obj = obj;
			   __entry->offset = offset;
			   __entry->len = len;
			   ),

	    TP_printk("obj=%p, offset=%u, len=%u",
		      __entry->obj, __entry->offset, __entry->len)
);

TRACE_EVENT(i915_gem_object_fault,
	    TP_PROTO(struct drm_i915_gem_object *obj, u32 index, bool gtt, bool write),
	    TP_ARGS(obj, index, gtt, write),

	    TP_STRUCT__entry(
			     __field(struct drm_i915_gem_object *, obj)
			     __field(u32, index)
			     __field(bool, gtt)
			     __field(bool, write)
			     ),

	    TP_fast_assign(
			   __entry->obj = obj;
			   __entry->index = index;
			   __entry->gtt = gtt;
			   __entry->write = write;
			   ),

	    TP_printk("obj=%p, %s index=%u %s",
		      __entry->obj,
		      __entry->gtt ? "GTT" : "CPU",
		      __entry->index,
		      __entry->write ? ", writable" : "")
);

DECLARE_EVENT_CLASS(i915_gem_object,
	    TP_PROTO(struct drm_i915_gem_object *obj),
	    TP_ARGS(obj),

	    TP_STRUCT__entry(
			     __field(struct drm_i915_gem_object *, obj)
			     ),

	    TP_fast_assign(
			   __entry->obj = obj;
			   ),

	    TP_printk("obj=%p", __entry->obj)
);

DEFINE_EVENT(i915_gem_object, i915_gem_object_clflush,
	     TP_PROTO(struct drm_i915_gem_object *obj),
	     TP_ARGS(obj)
);

DEFINE_EVENT(i915_gem_object, i915_gem_object_destroy,
	    TP_PROTO(struct drm_i915_gem_object *obj),
	    TP_ARGS(obj)
);

TRACE_EVENT(i915_gem_evict,
	    TP_PROTO(struct drm_device *dev, u32 size, u32 align, bool mappable),
	    TP_ARGS(dev, size, align, mappable),

	    TP_STRUCT__entry(
			     __field(u32, dev)
			     __field(u32, size)
			     __field(u32, align)
			     __field(bool, mappable)
			    ),

	    TP_fast_assign(
			   __entry->dev = dev->primary->index;
			   __entry->size = size;
			   __entry->align = align;
			   __entry->mappable = mappable;
			  ),

	    TP_printk("dev=%d, size=%d, align=%d %s",
		      __entry->dev, __entry->size, __entry->align,
		      __entry->mappable ? ", mappable" : "")
);

TRACE_EVENT(i915_gem_evict_everything,
	    TP_PROTO(struct drm_device *dev),
	    TP_ARGS(dev),

	    TP_STRUCT__entry(
			     __field(u32, dev)
			    ),

	    TP_fast_assign(
			   __entry->dev = dev->primary->index;
			  ),

	    TP_printk("dev=%d", __entry->dev)
);

TRACE_EVENT(i915_gem_evict_vm,
	    TP_PROTO(struct i915_address_space *vm),
	    TP_ARGS(vm),

	    TP_STRUCT__entry(
			     __field(u32, dev)
			     __field(struct i915_address_space *, vm)
			    ),

	    TP_fast_assign(
			   __entry->dev = vm->dev->primary->index;
			   __entry->vm = vm;
			  ),

	    TP_printk("dev=%d, vm=%p", __entry->dev, __entry->vm)
);

TRACE_EVENT(i915_gem_ring_sync_to,
	    TP_PROTO(struct intel_ring_buffer *from,
		     struct intel_ring_buffer *to,
		     u32 seqno),
	    TP_ARGS(from, to, seqno),

	    TP_STRUCT__entry(
			     __field(u32, dev)
			     __field(u32, sync_from)
			     __field(u32, sync_to)
			     __field(u32, seqno)
			     ),

	    TP_fast_assign(
			   __entry->dev = from->dev->primary->index;
			   __entry->sync_from = from->id;
			   __entry->sync_to = to->id;
			   __entry->seqno = seqno;
			   ),

	    TP_printk("dev=%u, sync-from=%u, sync-to=%u, seqno=%u",
		      __entry->dev,
		      __entry->sync_from, __entry->sync_to,
		      __entry->seqno)
);

TRACE_EVENT(i915_gem_ring_dispatch,
	    TP_PROTO(struct intel_ring_buffer *ring, u32 seqno, u32 flags),
	    TP_ARGS(ring, seqno, flags),

	    TP_STRUCT__entry(
			     __field(u32, dev)
			     __field(u32, ring)
			     __field(u32, seqno)
			     __field(u32, flags)
			     ),

	    TP_fast_assign(
			   __entry->dev = ring->dev->primary->index;
			   __entry->ring = ring->id;
			   __entry->seqno = seqno;
			   __entry->flags = flags;
			   i915_trace_irq_get(ring, seqno);
			   ),

	    TP_printk("dev=%u, ring=%u, seqno=%u, flags=%x",
		      __entry->dev, __entry->ring, __entry->seqno, __entry->flags)
);

TRACE_EVENT(i915_gem_ring_flush,
	    TP_PROTO(struct intel_ring_buffer *ring, u32 invalidate, u32 flush),
	    TP_ARGS(ring, invalidate, flush),

	    TP_STRUCT__entry(
			     __field(u32, dev)
			     __field(u32, ring)
			     __field(u32, invalidate)
			     __field(u32, flush)
			     ),

	    TP_fast_assign(
			   __entry->dev = ring->dev->primary->index;
			   __entry->ring = ring->id;
			   __entry->invalidate = invalidate;
			   __entry->flush = flush;
			   ),

	    TP_printk("dev=%u, ring=%x, invalidate=%04x, flush=%04x",
		      __entry->dev, __entry->ring,
		      __entry->invalidate, __entry->flush)
);

DECLARE_EVENT_CLASS(i915_gem_request,
	    TP_PROTO(struct intel_ring_buffer *ring, u32 seqno),
	    TP_ARGS(ring, seqno),

	    TP_STRUCT__entry(
			     __field(u32, dev)
			     __field(u32, ring)
			     __field(u32, seqno)
			     ),

	    TP_fast_assign(
			   __entry->dev = ring->dev->primary->index;
			   __entry->ring = ring->id;
			   __entry->seqno = seqno;
			   ),

	    TP_printk("dev=%u, ring=%u, seqno=%u",
		      __entry->dev, __entry->ring, __entry->seqno)
);

DEFINE_EVENT(i915_gem_request, i915_gem_request_add,
	    TP_PROTO(struct intel_ring_buffer *ring, u32 seqno),
	    TP_ARGS(ring, seqno)
);

TRACE_EVENT(i915_gem_request_complete,
	    TP_PROTO(struct intel_ring_buffer *ring),
	    TP_ARGS(ring),

	    TP_STRUCT__entry(
			     __field(u32, dev)
			     __field(u32, ring)
			     __field(u32, seqno)
			     ),

	    TP_fast_assign(
			   __entry->dev = ring->dev->primary->index;
			   __entry->ring = ring->id;
			   __entry->seqno = ring->get_seqno(ring, false);
			   ),

	    TP_printk("dev=%u, ring=%u, seqno=%u",
		      __entry->dev, __entry->ring, __entry->seqno)
);

DEFINE_EVENT(i915_gem_request, i915_gem_request_retire,
	    TP_PROTO(struct intel_ring_buffer *ring, u32 seqno),
	    TP_ARGS(ring, seqno)
);

TRACE_EVENT(i915_gem_request_wait_begin,
	    TP_PROTO(struct intel_ring_buffer *ring, u32 seqno),
	    TP_ARGS(ring, seqno),

	    TP_STRUCT__entry(
			     __field(u32, dev)
			     __field(u32, ring)
			     __field(u32, seqno)
			     __field(bool, blocking)
			     ),

	    /* NB: the blocking information is racy since mutex_is_locked
	     * doesn't check that the current thread holds the lock. The only
	     * other option would be to pass the boolean information of whether
	     * or not the class was blocking down through the stack which is
	     * less desirable.
	     */
	    TP_fast_assign(
			   __entry->dev = ring->dev->primary->index;
			   __entry->ring = ring->id;
			   __entry->seqno = seqno;
			   __entry->blocking = mutex_is_locked(&ring->dev->struct_mutex);
			   ),

	    TP_printk("dev=%u, ring=%u, seqno=%u, blocking=%s",
		      __entry->dev, __entry->ring, __entry->seqno,
		      __entry->blocking ?  "yes (NB)" : "no")
);

DEFINE_EVENT(i915_gem_request, i915_gem_request_wait_end,
	    TP_PROTO(struct intel_ring_buffer *ring, u32 seqno),
	    TP_ARGS(ring, seqno)
);

DECLARE_EVENT_CLASS(i915_ring,
	    TP_PROTO(struct intel_ring_buffer *ring),
	    TP_ARGS(ring),

	    TP_STRUCT__entry(
			     __field(u32, dev)
			     __field(u32, ring)
			     ),

	    TP_fast_assign(
			   __entry->dev = ring->dev->primary->index;
			   __entry->ring = ring->id;
			   ),

	    TP_printk("dev=%u, ring=%u", __entry->dev, __entry->ring)
);

DEFINE_EVENT(i915_ring, i915_ring_wait_begin,
	    TP_PROTO(struct intel_ring_buffer *ring),
	    TP_ARGS(ring)
);

DEFINE_EVENT(i915_ring, i915_ring_wait_end,
	    TP_PROTO(struct intel_ring_buffer *ring),
	    TP_ARGS(ring)
);

TRACE_EVENT(i915_flip_request,
	    TP_PROTO(int plane, struct drm_i915_gem_object *obj),

	    TP_ARGS(plane, obj),

	    TP_STRUCT__entry(
		    __field(int, plane)
		    __field(struct drm_i915_gem_object *, obj)
		    ),

	    TP_fast_assign(
		    __entry->plane = plane;
		    __entry->obj = obj;
		    ),

	    TP_printk("plane=%d, obj=%p", __entry->plane, __entry->obj)
);

TRACE_EVENT(i915_flip_complete,
	    TP_PROTO(int plane, struct drm_i915_gem_object *obj),

	    TP_ARGS(plane, obj),

	    TP_STRUCT__entry(
		    __field(int, plane)
		    __field(struct drm_i915_gem_object *, obj)
		    ),

	    TP_fast_assign(
		    __entry->plane = plane;
		    __entry->obj = obj;
		    ),

	    TP_printk("plane=%d, obj=%p", __entry->plane, __entry->obj)
);

TRACE_EVENT_CONDITION(i915_reg_rw,
	TP_PROTO(bool write, u32 reg, u64 val, int len, bool trace),

	TP_ARGS(write, reg, val, len, trace),

	TP_CONDITION(trace),

	TP_STRUCT__entry(
		__field(u64, val)
		__field(u32, reg)
		__field(u16, write)
		__field(u16, len)
		),

	TP_fast_assign(
		__entry->val = (u64)val;
		__entry->reg = reg;
		__entry->write = write;
		__entry->len = len;
		),

	TP_printk("%s reg=0x%x, len=%d, val=(0x%x, 0x%x)",
		__entry->write ? "write" : "read",
		__entry->reg, __entry->len,
		(u32)(__entry->val & 0xffffffff),
		(u32)(__entry->val >> 32))
);

TRACE_EVENT(intel_gpu_freq_change,
	    TP_PROTO(u32 freq),
	    TP_ARGS(freq),

	    TP_STRUCT__entry(
			     __field(u32, freq)
			     ),

	    TP_fast_assign(
			   __entry->freq = freq;
			   ),

	    TP_printk("new_freq=%u", __entry->freq)
);

#endif /* _I915_TRACE_H_ */

/* This part must be outside protection */
#undef TRACE_INCLUDE_PATH
#define TRACE_INCLUDE_PATH .
@


1.12
log
@define and use trace macros
discussed with kettenis
@
text
@d1 1
a1 1
/*	$OpenBSD: i915_trace.h,v 1.11 2015/04/12 17:10:07 kettenis Exp $	*/
d33 3
a35 3
TRACE_EVENT(i915_gem_object_bind,
	    TP_PROTO(struct drm_i915_gem_object *obj, bool mappable),
	    TP_ARGS(obj, mappable),
d39 1
d46 4
a49 3
			   __entry->obj = obj;
			   __entry->offset = obj->gtt_space->start;
			   __entry->size = obj->gtt_space->size;
d53 1
a53 1
	    TP_printk("obj=%p, offset=%08x size=%x%s",
d55 2
a56 1
		      __entry->mappable ? ", mappable" : "")
d59 3
a61 3
TRACE_EVENT(i915_gem_object_unbind,
	    TP_PROTO(struct drm_i915_gem_object *obj),
	    TP_ARGS(obj),
d65 1
d71 4
a74 3
			   __entry->obj = obj;
			   __entry->offset = obj->gtt_space->start;
			   __entry->size = obj->gtt_space->size;
d77 2
a78 2
	    TP_printk("obj=%p, offset=%08x size=%x",
		      __entry->obj, __entry->offset, __entry->size)
d233 43
d347 18
a364 3
DEFINE_EVENT(i915_gem_request, i915_gem_request_complete,
	    TP_PROTO(struct intel_ring_buffer *ring, u32 seqno),
	    TP_ARGS(ring, seqno)
d469 4
a472 2
TRACE_EVENT(i915_reg_rw,
	TP_PROTO(bool write, u32 reg, u64 val, int len),
d474 1
a474 1
	TP_ARGS(write, reg, val, len),
@


1.11
log
@Add a few missing trace functions, and "use" them.  Add back the WATCH_GTT
code (that isn't actually compiled in).  Use dev_priv->dev in one more place
now that we have it, and add set_normalized_timespec() and use it.
@
text
@d1 451
a451 126
/*	$OpenBSD: i915_trace.h,v 1.10 2013/12/15 11:42:10 kettenis Exp $	*/
/*
 * Copyright (c) 2013 Mark Kettenis <kettenis@@openbsd.org>
 *
 * Permission to use, copy, modify, and distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 */

static inline void
trace_i915_gem_object_create(struct drm_i915_gem_object *obj)
{
}

static inline void
trace_i915_gem_object_destroy(struct drm_i915_gem_object *obj)
{
}

static inline void
trace_i915_gem_request_add(struct intel_ring_buffer *ring, u32 seqno)
{
}

static inline void
trace_i915_gem_request_complete(struct intel_ring_buffer *ring, u32 seqno)
{
}

static inline void
trace_i915_gem_request_retire(struct intel_ring_buffer *ring, u32 seqno)
{
}

static inline void
trace_i915_gem_request_wait_begin(struct intel_ring_buffer *ring, u32 seqno)
{
}

static inline void
trace_i915_gem_request_wait_end(struct intel_ring_buffer *ring, u32 seqno)
{
}

static inline void
trace_i915_ring_wait_begin(struct intel_ring_buffer *ring)
{
}

static inline void
trace_i915_ring_wait_end(struct intel_ring_buffer *ring)
{
}

static inline void
trace_i915_flip_request(int plane, struct drm_i915_gem_object *obj)
{
}

static inline void
trace_i915_flip_complete(int plane, struct drm_i915_gem_object *obj)
{
}

static inline void
trace_i915_gem_object_change_domain(struct drm_i915_gem_object *obj,
				    u32 old_read, u32 old_write)
{
}

static inline void
trace_i915_gem_object_pwrite(struct drm_i915_gem_object *obj,
			     u32 offset, u32 len)
{
}

static inline void
trace_i915_gem_object_pread(struct drm_i915_gem_object *obj,
			    u32 offset, u32 len)
{
}

static inline void
trace_i915_gem_object_bind(struct drm_i915_gem_object *obj, bool mappable)
{
}

static inline void
trace_i915_gem_object_unbind(struct drm_i915_gem_object *obj)
{
}

static inline void
trace_i915_reg_rw(bool write, u32 reg, u64 val, int len)
{
}

static inline void
trace_i915_gem_evict(struct drm_device *dev, u32 size, u32 align, bool mappable)
{
}

static inline void
trace_i915_gem_evict_everything(struct drm_device *dev)
{
}

static inline void
trace_i915_gem_ring_dispatch(struct intel_ring_buffer *ring, u32 seqno,
			     u32 flags)
{
}

static inline void
trace_i915_gem_ring_flush(struct intel_ring_buffer *ring, u32 invalidate,
			     u32 flush)
{
}
@


1.10
log
@Overhaul the pread and pwrite code to match what Linux does.  Should fix a few
more cache coherency issues, hopefully reducing the number of artifacts
showing up the screen.
@
text
@d1 1
a1 1
/*	$OpenBSD: i915_trace.h,v 1.9 2013/12/01 11:47:13 kettenis Exp $	*/
d24 5
d34 5
d54 20
d113 12
@


1.9
log
@Bring back the DRM_IOCTL_I915_GEM_WAIT diff now that I've figured out what
made it fail (WARN_ON() was evaluating its argument multiple times).
This time, also advertise support through I915_PARAM_HAS_WAIT_TIMEOUT.
@
text
@d1 1
a1 1
/*	$OpenBSD: i915_trace.h,v 1.8 2013/11/30 20:13:36 kettenis Exp $	*/
d46 12
@


1.8
log
@Oops!  Only intended to commit the i915_dma.c changes in the previous commit.
@
text
@d1 1
a1 1
/*	$OpenBSD: i915_trace.h,v 1.6 2013/11/20 02:03:52 jsg Exp $	*/
d30 10
@


1.7
log
@Reorder some case statements to reduce the diffs with Linux.
@
text
@a33 10
trace_i915_gem_request_wait_begin(struct intel_ring_buffer *ring, u32 seqno)
{
}

static inline void
trace_i915_gem_request_wait_end(struct intel_ring_buffer *ring, u32 seqno)
{
}

static inline void
@


1.6
log
@switch to the drm_mm based gtt eviction code from linux 3.8.13
ok kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: i915_trace.h,v 1.5 2013/11/19 15:08:04 jsg Exp $	*/
d30 10
@


1.5
log
@backout the DRM_IOCTL_I915_GEM_WAIT commit
it seems to leave X unuseable on resume on at least snb/ivb
ok kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: i915_trace.h,v 1.4 2013/11/17 18:47:13 kettenis Exp $	*/
d51 10
@


1.4
log
@Implement DRM_IOCTL_I915_GEM_WAIT.  Based on an earlier diff from jsg@@

ok jsg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: i915_trace.h,v 1.3 2013/11/02 22:58:10 kettenis Exp $	*/
a29 10
{
}

static inline void
trace_i915_gem_request_wait_begin(struct intel_ring_buffer *ring, u32 seqno)
{
}

static inline void
trace_i915_gem_request_wait_end(struct intel_ring_buffer *ring, u32 seqno)
@


1.3
log
@Replace drm_handle_create/delete with drm_gem_handle_create/delete and make
the necessary adjustments to reference counting of GEM objects.  Matches what
Linux does these days.
@
text
@d1 1
a1 1
/*	$OpenBSD: i915_trace.h,v 1.2 2013/09/30 06:47:48 jsg Exp $	*/
d30 10
@


1.2
log
@move the read/write functions and macros closer to linux
noteably this uses the gt lock and force wake in some cases
and includes a gen5/ironlake errata.
ok kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: i915_trace.h,v 1.1 2013/08/07 19:49:07 kettenis Exp $	*/
d17 5
@


1.1
log
@Another major overhaul of the inteldrm(4) GEM code, bringing us considerably
closer to the Linux 3.8.13 codebase.  Almost certainly squashes a few more
bugs.

ok jsg@@
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d41 5
@

