head	1.15;
access;
symbols
	OPENBSD_6_2:1.15.0.2
	OPENBSD_6_2_BASE:1.15
	OPENBSD_6_1:1.12.0.4
	OPENBSD_6_1_BASE:1.12
	OPENBSD_6_0:1.11.0.4
	OPENBSD_6_0_BASE:1.11
	OPENBSD_5_9:1.8.0.2
	OPENBSD_5_9_BASE:1.8
	OPENBSD_5_8:1.4.0.4
	OPENBSD_5_8_BASE:1.4;
locks; strict;
comment	@ * @;


1.15
date	2017.07.12.20.12.19;	author kettenis;	state Exp;
branches;
next	1.14;
commitid	63xYTpLuz3Z38Pwu;

1.14
date	2017.07.05.20.30.13;	author kettenis;	state Exp;
branches;
next	1.13;
commitid	wA527vsQhGJhZItC;

1.13
date	2017.07.01.16.14.10;	author kettenis;	state Exp;
branches;
next	1.12;
commitid	KnwRPOZok9A30HI4;

1.12
date	2016.09.15.02.00.17;	author dlg;	state Exp;
branches;
next	1.11;
commitid	RlO92XR575sygHqm;

1.11
date	2016.04.07.20.30.59;	author kettenis;	state Exp;
branches;
next	1.10;
commitid	egheFuJ0GTdFttws;

1.10
date	2016.04.05.20.44.03;	author kettenis;	state Exp;
branches;
next	1.9;
commitid	NmhNQ0K4GRfCKIMY;

1.9
date	2016.04.05.08.22.50;	author kettenis;	state Exp;
branches;
next	1.8;
commitid	4zEfxNVjitzOF81p;

1.8
date	2016.02.05.15.51.10;	author kettenis;	state Exp;
branches;
next	1.7;
commitid	4O5RxyA1IYOPmGvL;

1.7
date	2016.01.01.15.28.26;	author kettenis;	state Exp;
branches;
next	1.6;
commitid	RyWMZBqIRjF37V3c;

1.6
date	2015.12.31.13.01.00;	author kettenis;	state Exp;
branches;
next	1.5;
commitid	PRTGqV1xSkCKPIeR;

1.5
date	2015.09.26.11.17.15;	author kettenis;	state Exp;
branches;
next	1.4;
commitid	DUG1LQonw3dWeI9h;

1.4
date	2015.04.08.15.01.33;	author jsg;	state Exp;
branches;
next	1.3;
commitid	B0L5WM1pXCWbQ7Or;

1.3
date	2015.04.08.02.28.13;	author jsg;	state Exp;
branches;
next	1.2;
commitid	pBZw25gbMMahiUV2;

1.2
date	2015.04.06.12.25.10;	author jsg;	state Exp;
branches;
next	1.1;
commitid	CN1fAwudhSb2ckyl;

1.1
date	2015.04.05.11.53.53;	author kettenis;	state Exp;
branches;
next	;
commitid	3YXcRggXXMDC9Cpg;


desc
@@


1.15
log
@Add a "Backlight" property to connectors with an associated backlight
controller for the inteldrm(4) driver.  If wscons(4) provides backlight
control, prefer ir over raw hardware control and attach it to LVDS, eDP
and DSI connectors which are the connector types typically connected to
laptop screens.
@
text
@/*	$OpenBSD: drm_linux.c,v 1.14 2017/07/05 20:30:13 kettenis Exp $	*/
/*
 * Copyright (c) 2013 Jonathan Gray <jsg@@openbsd.org>
 * Copyright (c) 2015, 2016 Mark Kettenis <kettenis@@openbsd.org>
 *
 * Permission to use, copy, modify, and distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 */

#include <dev/pci/drm/drmP.h>
#include <dev/pci/ppbreg.h>

void
flush_barrier(void *arg)
{
	int *barrier = arg;

	*barrier = 1;
	wakeup(barrier);
}

void
flush_workqueue(struct workqueue_struct *wq)
{
	struct sleep_state sls;
	struct task task;
	int barrier = 0;

	if (cold)
		return;

	task_set(&task, flush_barrier, &barrier);
	task_add((struct taskq *)wq, &task);
	while (!barrier) {
		sleep_setup(&sls, &barrier, PWAIT, "flwqbar");
		sleep_finish(&sls, !barrier);
	}
}

void
flush_work(struct work_struct *work)
{
	struct sleep_state sls;
	struct task task;
	int barrier = 0;

	if (cold)
		return;

	task_set(&task, flush_barrier, &barrier);
	task_add(work->tq, &task);
	while (!barrier) {
		sleep_setup(&sls, &barrier, PWAIT, "flwkbar");
		sleep_finish(&sls, !barrier);
	}
}

void
flush_delayed_work(struct delayed_work *dwork)
{
	struct sleep_state sls;
	struct task task;
	int barrier = 0;

	if (cold)
		return;

	while (timeout_pending(&dwork->to))
		tsleep(&barrier, PWAIT, "fldwto", 1);

	task_set(&task, flush_barrier, &barrier);
	task_add(dwork->tq, &task);
	while (!barrier) {
		sleep_setup(&sls, &barrier, PWAIT, "fldwbar");
		sleep_finish(&sls, !barrier);
	}
}

struct timespec
ns_to_timespec(const int64_t nsec)
{
	struct timespec ts;
	int32_t rem;

	if (nsec == 0) {
		ts.tv_sec = 0;
		ts.tv_nsec = 0;
		return (ts);
	}

	ts.tv_sec = nsec / NSEC_PER_SEC;
	rem = nsec % NSEC_PER_SEC;
	if (rem < 0) {
		ts.tv_sec--;
		rem += NSEC_PER_SEC;
	}
	ts.tv_nsec = rem;
	return (ts);
}

int64_t
timeval_to_ns(const struct timeval *tv)
{
	return ((int64_t)tv->tv_sec * NSEC_PER_SEC) +
		tv->tv_usec * NSEC_PER_USEC;
}

struct timeval
ns_to_timeval(const int64_t nsec)
{
	struct timeval tv;
	int32_t rem;

	if (nsec == 0) {
		tv.tv_sec = 0;
		tv.tv_usec = 0;
		return (tv);
	}

	tv.tv_sec = nsec / NSEC_PER_SEC;
	rem = nsec % NSEC_PER_SEC;
	if (rem < 0) {
		tv.tv_sec--;
		rem += NSEC_PER_SEC;
	}
	tv.tv_usec = rem / 1000;
	return (tv);
}

int64_t
timeval_to_us(const struct timeval *tv)
{
	return ((int64_t)tv->tv_sec * 1000000) + tv->tv_usec;
}

extern char *hw_vendor, *hw_prod;

static bool
dmi_found(const struct dmi_system_id *dsi)
{
	int i, slot;

	for (i = 0; i < nitems(dsi->matches); i++) {
		slot = dsi->matches[i].slot;
		switch (slot) {
		case DMI_NONE:
			break;
		case DMI_SYS_VENDOR:
		case DMI_BOARD_VENDOR:
			if (hw_vendor != NULL &&
			    !strcmp(hw_vendor, dsi->matches[i].substr))
				break;
			else
				return false;
		case DMI_PRODUCT_NAME:
		case DMI_BOARD_NAME:
			if (hw_prod != NULL &&
			    !strcmp(hw_prod, dsi->matches[i].substr))
				break;
			else
				return false;
		default:
			return false;
		}
	}

	return true;
}

int
dmi_check_system(const struct dmi_system_id *sysid)
{
	const struct dmi_system_id *dsi;
	int num = 0;

	for (dsi = sysid; dsi->matches[0].slot != 0 ; dsi++) {
		if (dmi_found(dsi)) {
			num++;
			if (dsi->callback && dsi->callback(dsi))
				break;
		}
	}
	return (num);
}

struct vm_page *
alloc_pages(unsigned int gfp_mask, unsigned int order)
{
	int flags = (gfp_mask & M_NOWAIT) ? UVM_PLA_NOWAIT : UVM_PLA_WAITOK;
	struct pglist mlist;

	if (gfp_mask & M_CANFAIL)
		flags |= UVM_PLA_FAILOK;
	if (gfp_mask & M_ZERO)
		flags |= UVM_PLA_ZERO;

	TAILQ_INIT(&mlist);
	if (uvm_pglistalloc(PAGE_SIZE << order, 0, -1, PAGE_SIZE, 0,
	    &mlist, 1, flags))
		return NULL;
	return TAILQ_FIRST(&mlist);
}

void
__free_pages(struct vm_page *page, unsigned int order)
{
	struct pglist mlist;
	int i;
	
	TAILQ_INIT(&mlist);
	for (i = 0; i < (1 << order); i++)
		TAILQ_INSERT_TAIL(&mlist, &page[i], pageq);
	uvm_pglistfree(&mlist);
}

void *
kmap(struct vm_page *pg)
{
	vaddr_t va;

#if defined (__HAVE_PMAP_DIRECT)
	va = pmap_map_direct(pg);
#else
	va = uvm_km_valloc_wait(phys_map, PAGE_SIZE);
	pmap_kenter_pa(va, VM_PAGE_TO_PHYS(pg), PROT_READ | PROT_WRITE);
	pmap_update(pmap_kernel());
#endif
	return (void *)va;
}

void
kunmap(void *addr)
{
	vaddr_t va = (vaddr_t)addr;

#if defined (__HAVE_PMAP_DIRECT)
	pmap_unmap_direct(va);
#else
	pmap_kremove(va, PAGE_SIZE);
	pmap_update(pmap_kernel());
	uvm_km_free_wakeup(phys_map, va, PAGE_SIZE);
#endif
}

void *
vmap(struct vm_page **pages, unsigned int npages, unsigned long flags,
     pgprot_t prot)
{
	vaddr_t va;
	paddr_t pa;
	int i;

	va = uvm_km_valloc(kernel_map, PAGE_SIZE * npages);
	if (va == 0)
		return NULL;
	for (i = 0; i < npages; i++) {
		pa = VM_PAGE_TO_PHYS(pages[i]) | prot;
		pmap_enter(pmap_kernel(), va + (i * PAGE_SIZE), pa,
		    PROT_READ | PROT_WRITE,
		    PROT_READ | PROT_WRITE | PMAP_WIRED);
		pmap_update(pmap_kernel());
	}

	return (void *)va;
}

void
vunmap(void *addr, size_t size)
{
	vaddr_t va = (vaddr_t)addr;

	pmap_remove(pmap_kernel(), va, va + size);
	pmap_update(pmap_kernel());
	uvm_km_free(kernel_map, va, size);
}

void
print_hex_dump(const char *level, const char *prefix_str, int prefix_type,
    int rowsize, int groupsize, const void *buf, size_t len, bool ascii)
{
	const uint8_t *cbuf = buf;
	int i;

	for (i = 0; i < len; i++) {
		if ((i % rowsize) == 0)
			printf("%s", prefix_str);
		printf("%02x", cbuf[i]);
		if ((i % rowsize) == (rowsize - 1))
			printf("\n");
		else
			printf(" ");
	}
}

void *
memchr_inv(const void *s, int c, size_t n)
{
	if (n != 0) {
		const unsigned char *p = s;

		do {
			if (*p++ != (unsigned char)c)
				return ((void *)(p - 1));
		}while (--n != 0);
	}
	return (NULL);
}

int
panic_cmp(struct rb_node *a, struct rb_node *b)
{
	panic(__func__);
}

#undef RB_ROOT
#define RB_ROOT(head)	(head)->rbh_root

RB_GENERATE(linux_root, rb_node, __entry, panic_cmp);

/*
 * This is a fairly minimal implementation of the Linux "idr" API.  It
 * probably isn't very efficient, and defenitely isn't RCU safe.  The
 * pre-load buffer is global instead of per-cpu; we rely on the kernel
 * lock to make this work.  We do randomize our IDs in order to make
 * them harder to guess.
 */

int idr_cmp(struct idr_entry *, struct idr_entry *);
SPLAY_PROTOTYPE(idr_tree, idr_entry, entry, idr_cmp);

struct pool idr_pool;
struct idr_entry *idr_entry_cache;

void
idr_init(struct idr *idr)
{
	static int initialized;

	if (!initialized) {
		pool_init(&idr_pool, sizeof(struct idr_entry), 0, IPL_TTY, 0,
		    "idrpl", NULL);
		initialized = 1;
	}
	SPLAY_INIT(&idr->tree);
}

void
idr_destroy(struct idr *idr)
{
	struct idr_entry *id;

	while ((id = SPLAY_MIN(idr_tree, &idr->tree))) {
		SPLAY_REMOVE(idr_tree, &idr->tree, id);
		pool_put(&idr_pool, id);
	}
}

void
idr_preload(unsigned int gfp_mask)
{
	int flags = (gfp_mask & GFP_NOWAIT) ? PR_NOWAIT : PR_WAITOK;

	KERNEL_ASSERT_LOCKED();

	if (idr_entry_cache == NULL)
		idr_entry_cache = pool_get(&idr_pool, flags);
}

int
idr_alloc(struct idr *idr, void *ptr, int start, int end,
    unsigned int gfp_mask)
{
	int flags = (gfp_mask & GFP_NOWAIT) ? PR_NOWAIT : PR_WAITOK;
	struct idr_entry *id;
	int begin;

	KERNEL_ASSERT_LOCKED();

	if (idr_entry_cache) {
		id = idr_entry_cache;
		idr_entry_cache = NULL;
	} else {
		id = pool_get(&idr_pool, flags);
		if (id == NULL)
			return -ENOMEM;
	}

	if (end <= 0)
		end = INT_MAX;

#ifdef notyet
	id->id = begin = start + arc4random_uniform(end - start);
#else
	id->id = begin = start;
#endif
	while (SPLAY_INSERT(idr_tree, &idr->tree, id)) {
		if (++id->id == end)
			id->id = start;
		if (id->id == begin) {
			pool_put(&idr_pool, id);
			return -ENOSPC;
		}
	}
	id->ptr = ptr;
	return id->id;
}

void *
idr_replace(struct idr *idr, void *ptr, int id)
{
	struct idr_entry find, *res;
	void *old;

	find.id = id;
	res = SPLAY_FIND(idr_tree, &idr->tree, &find);
	if (res == NULL)
		return ERR_PTR(-ENOENT);
	old = res->ptr;
	res->ptr = ptr;
	return old;
}

void
idr_remove(struct idr *idr, int id)
{
	struct idr_entry find, *res;

	find.id = id;
	res = SPLAY_FIND(idr_tree, &idr->tree, &find);
	if (res) {
		SPLAY_REMOVE(idr_tree, &idr->tree, res);
		pool_put(&idr_pool, res);
	}
}

void *
idr_find(struct idr *idr, int id)
{
	struct idr_entry find, *res;

	find.id = id;
	res = SPLAY_FIND(idr_tree, &idr->tree, &find);
	if (res == NULL)
		return NULL;
	return res->ptr;
}

void *
idr_get_next(struct idr *idr, int *id)
{
	struct idr_entry *res;

	res = idr_find(idr, *id);
	if (res == NULL)
		res = SPLAY_MIN(idr_tree, &idr->tree);
	else
		res = SPLAY_NEXT(idr_tree, &idr->tree, res);
	if (res == NULL)
		return NULL;
	*id = res->id;
	return res->ptr;
}

int
idr_for_each(struct idr *idr, int (*func)(int, void *, void *), void *data)
{
	struct idr_entry *id;
	int ret;

	SPLAY_FOREACH(id, idr_tree, &idr->tree) {
		ret = func(id->id, id->ptr, data);
		if (ret)
			return ret;
	}

	return 0;
}

int
idr_cmp(struct idr_entry *a, struct idr_entry *b)
{
	return (a->id < b->id ? -1 : a->id > b->id);
}

SPLAY_GENERATE(idr_tree, idr_entry, entry, idr_cmp);

void
ida_init(struct ida *ida)
{
	ida->counter = 0;
}

void
ida_destroy(struct ida *ida)
{
}

void
ida_remove(struct ida *ida, int id)
{
}

int
ida_simple_get(struct ida *ida, unsigned int start, unsigned int end,
    int flags)
{
	if (end <= 0)
		end = INT_MAX;

	if (start > ida->counter)
		ida->counter = start;

	if (ida->counter >= end)
		return -ENOSPC;

	return ida->counter++;
}

int
sg_alloc_table(struct sg_table *table, unsigned int nents, gfp_t gfp_mask)
{
	table->sgl = mallocarray(nents, sizeof(struct scatterlist),
	    M_DRM, gfp_mask);
	if (table->sgl == NULL)
		return -ENOMEM;
	table->nents = table->orig_nents = nents;
	return 0;
}

void
sg_free_table(struct sg_table *table)
{
	free(table->sgl, M_DRM,
	    table->orig_nents * sizeof(struct scatterlist));
}

size_t
sg_copy_from_buffer(struct scatterlist *sgl, unsigned int nents,
    const void *buf, size_t buflen)
{
	panic("%s", __func__);
}

int
i2c_transfer(struct i2c_adapter *adap, struct i2c_msg *msgs, int num)
{
	void *cmd = NULL;
	int cmdlen = 0;
	int err, ret = 0;
	int op;

	if (adap->algo)
		return adap->algo->master_xfer(adap, msgs, num);

	iic_acquire_bus(&adap->ic, 0);

	while (num > 2) {
		op = (msgs->flags & I2C_M_RD) ? I2C_OP_READ : I2C_OP_WRITE;
		err = iic_exec(&adap->ic, op, msgs->addr, NULL, 0,
		    msgs->buf, msgs->len, 0);
		if (err) {
			ret = -err;
			goto fail;
		}
		msgs++;
		num--;
		ret++;
	}

	if (num > 1) {
		cmd = msgs->buf;
		cmdlen = msgs->len;
		msgs++;
		num--;
		ret++;
	}

	op = (msgs->flags & I2C_M_RD) ? I2C_OP_READ_WITH_STOP : I2C_OP_WRITE_WITH_STOP;
	err = iic_exec(&adap->ic, op, msgs->addr, cmd, cmdlen, msgs->buf, msgs->len, 0);
	if (err) {
		ret = -err;
		goto fail;
	}
	msgs++;
	ret++;

fail:
	iic_release_bus(&adap->ic, 0);

	return ret;
}

#if defined(__amd64__) || defined(__i386__)

/*
 * This is a minimal implementation of the Linux vga_get/vga_put
 * interface.  In all likelyhood, it will only work for inteldrm(4) as
 * it assumes that if there is another active VGA device in the
 * system, it is sitting behind a PCI bridge.
 */

extern int pci_enumerate_bus(struct pci_softc *,
    int (*)(struct pci_attach_args *), struct pci_attach_args *);

pcitag_t vga_bridge_tag;
int vga_bridge_disabled;

int
vga_disable_bridge(struct pci_attach_args *pa)
{
	pcireg_t bhlc, bc;

	if (pa->pa_domain != 0)
		return 0;

	bhlc = pci_conf_read(pa->pa_pc, pa->pa_tag, PCI_BHLC_REG);
	if (PCI_HDRTYPE_TYPE(bhlc) != 1)
		return 0;

	bc = pci_conf_read(pa->pa_pc, pa->pa_tag, PPB_REG_BRIDGECONTROL);
	if ((bc & PPB_BC_VGA_ENABLE) == 0)
		return 0;
	bc &= ~PPB_BC_VGA_ENABLE;
	pci_conf_write(pa->pa_pc, pa->pa_tag, PPB_REG_BRIDGECONTROL, bc);

	vga_bridge_tag = pa->pa_tag;
	vga_bridge_disabled = 1;

	return 1;
}

void
vga_get_uninterruptible(struct pci_dev *pdev, int rsrc)
{
	KASSERT(pdev->pci->sc_bridgetag == NULL);
	pci_enumerate_bus(pdev->pci, vga_disable_bridge, NULL);
}

void
vga_put(struct pci_dev *pdev, int rsrc)
{
	pcireg_t bc;

	if (!vga_bridge_disabled)
		return;

	bc = pci_conf_read(pdev->pc, vga_bridge_tag, PPB_REG_BRIDGECONTROL);
	bc |= PPB_BC_VGA_ENABLE;
	pci_conf_write(pdev->pc, vga_bridge_tag, PPB_REG_BRIDGECONTROL, bc);

	vga_bridge_disabled = 0;
}

#endif

/*
 * ACPI types and interfaces.
 */

#if defined(__amd64__) || defined(__i386__)
#include "acpi.h"
#endif

#if NACPI > 0

#include <dev/acpi/acpireg.h>
#include <dev/acpi/acpivar.h>

acpi_status
acpi_get_table_with_size(const char *sig, int instance,
    struct acpi_table_header **hdr, acpi_size *size)
{
	struct acpi_softc *sc = acpi_softc;
	struct acpi_q *entry;

	KASSERT(instance == 1);

	SIMPLEQ_FOREACH(entry, &sc->sc_tables, q_next) {
		if (memcmp(entry->q_table, sig, strlen(sig)) == 0) {
			*hdr = entry->q_table;
			*size = (*hdr)->length;
			return 0;
		}
	}

	return AE_NOT_FOUND;
}

#endif

void
backlight_do_update_status(void *arg)
{
	backlight_update_status(arg);
}

struct backlight_device *
backlight_device_register(const char *name, void *kdev, void *data,
    const struct backlight_ops *ops, struct backlight_properties *props)
{
	struct backlight_device *bd;

	bd = malloc(sizeof(*bd), M_DRM, M_WAITOK);
	bd->ops = ops;
	bd->props = *props;
	bd->data = data;

	task_set(&bd->task, backlight_do_update_status, bd);
	
	return bd;
}

void
backlight_device_unregister(struct backlight_device *bd)
{
	free(bd, M_DRM, sizeof(*bd));
}

void
backlight_schedule_update_status(struct backlight_device *bd)
{
	task_add(systq, &bd->task);
}
@


1.14
log
@Fix native/raw backlight support in inteldrm(4).
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.c,v 1.13 2017/07/01 16:14:10 kettenis Exp $	*/
d700 6
d716 2
d726 6
@


1.13
log
@Update inteldrm(4) to code based on Linux 4.4.70.  This brings us support for
Skylake and Cherryview and better support for Broadwell and Valleyview.  Also
adds MST support.  Some tweaks to the TTM code and radeondrm(4) to keep it
working with the updated generic DRM code needed for inteldrm(4).

Tested by many.
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.c,v 1.12 2016/09/15 02:00:17 dlg Exp $	*/
d699 20
@


1.12
log
@all pools have their ipl set via pool_setipl, so fold it into pool_init.

the ioff argument to pool_init() is unused and has been for many
years, so this replaces it with an ipl argument. because the ipl
will be set on init we no longer need pool_setipl.

most of these changes have been done with coccinelle using the spatch
below. cocci sucks at formatting code though, so i fixed that by hand.

the manpage and subr_pool.c bits i did myself.

ok tedu@@ jmatthew@@

@@ipl@@
expression pp;
expression ipl;
expression s, a, o, f, m, p;
@@@@
-pool_init(pp, s, a, o, f, m, p);
-pool_setipl(pp, ipl);
+pool_init(pp, s, a, ipl, f, m, p);
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.c,v 1.11 2016/04/07 20:30:59 kettenis Exp $	*/
d22 66
d139 6
d203 2
d286 32
d400 1
d402 3
d417 15
d457 16
d495 106
@


1.11
log
@Return -ENOSPC if idr_alloc() fails to allocate an unused id instead of
spinning forever.
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.c,v 1.10 2016/04/05 20:44:03 kettenis Exp $	*/
d243 1
a243 1
		pool_init(&idr_pool, sizeof(struct idr_entry), 0, 0, 0,
a244 1
		pool_setipl(&idr_pool, IPL_TTY);
@


1.10
log
@Add an implementation of the Linux "idr" API.
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.c,v 1.9 2016/04/05 08:22:50 kettenis Exp $	*/
d279 1
d295 1
a295 1
	id->id = start + arc4random_uniform(end - start);
d299 4
@


1.9
log
@Split out the generic GEM code (like Linux did) and switch it over to
the vma offset manager.  This brings us a little bit more isolation between
applications as GEM buffers are now tied to a specific /dev/drmX clone.

ok jsg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.c,v 1.8 2016/02/05 15:51:10 kettenis Exp $	*/
d4 1
d222 128
@


1.8
log
@Implement acpi_get_table_with_size().  Will soon be used to read VFCT
tables in radeondrm(4).
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.c,v 1.7 2016/01/01 15:28:26 kettenis Exp $	*/
d210 11
@


1.7
log
@Reimplement vga_put() such that it compiles on i386 as well.
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.c,v 1.6 2015/12/31 13:01:00 kettenis Exp $	*/
d270 35
@


1.6
log
@Provide a minimal implementation of the Linux vga_get/vga_put API and use it
in inteldrm(4).

The Intel integrated graphics device has a major design flaw where it needs
legacy VGA io access to disable VGA mode completely.  This only works if
legacy VGA io routing is setup such that it actually reaches the IGD.  This
typically isn't the case if the primary VGA device is a discrete graphics
device.  To make sure we don't whack that device we have to temporarily
route legacy VGA io access to the IGD.

Fixes the "black screen" issue reported by Timo Myrra and others.
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.c,v 1.5 2015/09/26 11:17:15 kettenis Exp $	*/
a249 18
int
vga_enable_bridge(struct pci_attach_args *pa)
{
	pcireg_t bc;

	if (!vga_bridge_disabled)
		return 0;

	if (pa->pa_tag != vga_bridge_tag)
		return 0;

	bc = pci_conf_read(pa->pa_pc, pa->pa_tag, PPB_REG_BRIDGECONTROL);
	bc |= PPB_BC_VGA_ENABLE;
	pci_conf_write(pa->pa_pc, pa->pa_tag, PPB_REG_BRIDGECONTROL, bc);

	return 1;
}

d260 10
a269 2
	KASSERT(pdev->pci->sc_bridgetag == NULL);
	pci_enumerate_bus(pdev->pci, vga_enable_bridge, NULL);
@


1.5
log
@Make the PPGTT code work.  Seems to fix the caching issues on Broadwell.
Comments on some of the later Broadwell-related commits in the Linux tree
seem to say that the PPAT flags in for the (global) GTT are simply broken in
the hardware.
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.c,v 1.4 2015/04/08 15:01:33 jsg Exp $	*/
d19 1
d211 72
@


1.4
log
@Move vmap back to kernel_map/uvm_km_valloc as it's allowed to fail.
This should help dlg's dell 2950 that gets stuck during boot with vmap
in the trace.

ok kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.c,v 1.3 2015/04/08 02:28:13 jsg Exp $	*/
d119 28
@


1.3
log
@ttm has it's own version of kmap/kunmap that uses
kernel_map/uvm_km_valloc and i915 has a version that uses
phys_map/uvm_km_valloc_wait as calling code assumes kmap would
sleep if no memory is available.

Move these and ttm's vmap/vunmap into the linux compat files
and make them all use phys_map/uvm_km_valloc_wait.

looks good kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.c,v 1.2 2015/04/06 12:25:10 jsg Exp $	*/
d158 1
a158 1
	va = uvm_km_valloc_wait(phys_map, PAGE_SIZE * npages);
d179 1
a179 1
	uvm_km_free(phys_map, va, size);
@


1.2
log
@move some inline linux compat into the dedicated files
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.c,v 1.1 2015/04/05 11:53:53 kettenis Exp $	*/
d120 62
@


1.1
log
@Another round of reducing diffs with Linux.  This one moves the various
copy_to_user and copy_from_user functions into drm_linux.h and uses them
instead of copyin/copyout and DRM_COPY_*.  Also move the timespec functions,
and put i915_gem_object_is_purgable() where it belongs.

Uncovered a bug where the arguments to copyout() were in the wrong order.

ok jsg@@
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d40 79
@

