head	1.48;
access;
symbols
	OPENBSD_6_1:1.48.0.2
	OPENBSD_6_1_BASE:1.48
	OPENBSD_6_0:1.47.0.4
	OPENBSD_6_0_BASE:1.47
	OPENBSD_5_9:1.45.0.2
	OPENBSD_5_9_BASE:1.45
	OPENBSD_5_8:1.33.0.4
	OPENBSD_5_8_BASE:1.33
	OPENBSD_5_7:1.7.0.4
	OPENBSD_5_7_BASE:1.7
	OPENBSD_5_6:1.1.0.4
	OPENBSD_5_6_BASE:1.1;
locks; strict;
comment	@ * @;


1.48
date	2016.10.08.05.52.06;	author guenther;	state Exp;
branches;
next	1.47;
commitid	gFhAhnnQ2SlMacGa;

1.47
date	2016.04.05.20.44.03;	author kettenis;	state Exp;
branches;
next	1.46;
commitid	NmhNQ0K4GRfCKIMY;

1.46
date	2016.04.05.08.19.00;	author kettenis;	state Exp;
branches;
next	1.45;
commitid	BaK28M7uSySRlqZl;

1.45
date	2016.02.05.15.51.10;	author kettenis;	state Exp;
branches;
next	1.44;
commitid	4O5RxyA1IYOPmGvL;

1.44
date	2016.02.05.10.05.12;	author kettenis;	state Exp;
branches;
next	1.43;
commitid	gX0sRFu8RGimO2hC;

1.43
date	2015.12.31.13.01.00;	author kettenis;	state Exp;
branches;
next	1.42;
commitid	PRTGqV1xSkCKPIeR;

1.42
date	2015.10.17.21.41.12;	author kettenis;	state Exp;
branches;
next	1.41;
commitid	bHt1y1EnMlJS0gRQ;

1.41
date	2015.09.27.21.28.14;	author kettenis;	state Exp;
branches;
next	1.40;
commitid	Np8P85ZmWpjis6qB;

1.40
date	2015.09.27.11.09.26;	author jsg;	state Exp;
branches;
next	1.39;
commitid	OkoKp05dU7tP7DK3;

1.39
date	2015.09.26.22.00.00;	author kettenis;	state Exp;
branches;
next	1.38;
commitid	Mvg1eWGKMP5bOyT1;

1.38
date	2015.09.26.19.52.16;	author kettenis;	state Exp;
branches;
next	1.37;
commitid	PpEJMvqmELqAFnQv;

1.37
date	2015.09.26.11.17.15;	author kettenis;	state Exp;
branches;
next	1.36;
commitid	DUG1LQonw3dWeI9h;

1.36
date	2015.09.25.20.27.52;	author kettenis;	state Exp;
branches;
next	1.35;
commitid	jaD3JYENYge6B4QV;

1.35
date	2015.09.24.20.52.28;	author kettenis;	state Exp;
branches;
next	1.34;
commitid	7aH5GgFn0EMAmSm3;

1.34
date	2015.09.23.23.12.11;	author kettenis;	state Exp;
branches;
next	1.33;
commitid	lQlppvmETCN49oZe;

1.33
date	2015.07.16.18.48.51;	author kettenis;	state Exp;
branches;
next	1.32;
commitid	L0a8i9q8D7R6QA4N;

1.32
date	2015.07.11.04.00.46;	author jsg;	state Exp;
branches;
next	1.31;
commitid	eVKv6xUxvZe6BPUh;

1.31
date	2015.06.26.15.22.23;	author kettenis;	state Exp;
branches;
next	1.30;
commitid	zE715ZsjyYsYQNQ0;

1.30
date	2015.06.24.19.01.51;	author kettenis;	state Exp;
branches;
next	1.29;
commitid	gUkVFrZSFfq0QPRv;

1.29
date	2015.06.24.17.59.42;	author kettenis;	state Exp;
branches;
next	1.28;
commitid	3wz7SV1D1yJbfWE9;

1.28
date	2015.06.24.08.32.39;	author kettenis;	state Exp;
branches;
next	1.27;
commitid	hfEqCdm8ecmxIgUE;

1.27
date	2015.04.18.14.47.34;	author jsg;	state Exp;
branches;
next	1.26;
commitid	c1fUeeFWMNg4COgR;

1.26
date	2015.04.18.11.41.28;	author jsg;	state Exp;
branches;
next	1.25;
commitid	c3CbYQJYD10xhd6O;

1.25
date	2015.04.18.11.05.32;	author jsg;	state Exp;
branches;
next	1.24;
commitid	N5rmYm7ybHimJmMa;

1.24
date	2015.04.12.17.10.07;	author kettenis;	state Exp;
branches;
next	1.23;
commitid	7RIU3AxWXbuzxDet;

1.23
date	2015.04.12.12.14.30;	author jsg;	state Exp;
branches;
next	1.22;
commitid	os4Nms6pAXvmynAf;

1.22
date	2015.04.12.05.31.23;	author jsg;	state Exp;
branches;
next	1.21;
commitid	09jvnnyFAQrVbK5f;

1.21
date	2015.04.12.03.54.10;	author jsg;	state Exp;
branches;
next	1.20;
commitid	uVTyY1h8Sggc8pFj;

1.20
date	2015.04.11.14.39.37;	author jsg;	state Exp;
branches;
next	1.19;
commitid	MAOlCKi3JlwvLeJa;

1.19
date	2015.04.11.05.10.13;	author jsg;	state Exp;
branches;
next	1.18;
commitid	pjaRMzmEKTQk8EZt;

1.18
date	2015.04.11.02.59.05;	author jsg;	state Exp;
branches;
next	1.17;
commitid	NptfR81VAOcNKwQU;

1.17
date	2015.04.10.12.06.52;	author jsg;	state Exp;
branches;
next	1.16;
commitid	5bVyebI6DOf5FKY3;

1.16
date	2015.04.10.05.31.25;	author jsg;	state Exp;
branches;
next	1.15;
commitid	BNr9TiYARwtS3iCu;

1.15
date	2015.04.08.04.03.06;	author jsg;	state Exp;
branches;
next	1.14;
commitid	yFnN7rFafIBD7cOc;

1.14
date	2015.04.08.02.28.13;	author jsg;	state Exp;
branches;
next	1.13;
commitid	pBZw25gbMMahiUV2;

1.13
date	2015.04.06.15.43.15;	author jsg;	state Exp;
branches;
next	1.12;
commitid	DCPoYnokQzAg9pjM;

1.12
date	2015.04.06.12.25.10;	author jsg;	state Exp;
branches;
next	1.11;
commitid	CN1fAwudhSb2ckyl;

1.11
date	2015.04.06.08.14.00;	author kettenis;	state Exp;
branches;
next	1.10;
commitid	3FenpHSGCnS2uSz0;

1.10
date	2015.04.06.05.35.29;	author jsg;	state Exp;
branches;
next	1.9;
commitid	oeVBooRupIYToF2n;

1.9
date	2015.04.05.11.53.53;	author kettenis;	state Exp;
branches;
next	1.8;
commitid	3YXcRggXXMDC9Cpg;

1.8
date	2015.04.03.13.10.59;	author jsg;	state Exp;
branches;
next	1.7;
commitid	PZIJ62HYZVx8fbpI;

1.7
date	2015.02.12.11.11.45;	author jsg;	state Exp;
branches;
next	1.6;
commitid	SzbWuibzaFWN7p7E;

1.6
date	2015.02.12.06.30.56;	author jsg;	state Exp;
branches;
next	1.5;
commitid	pZ1bJqLc6BdU0mTp;

1.5
date	2015.02.12.02.12.02;	author kettenis;	state Exp;
branches;
next	1.4;
commitid	cYXtgYH6nnLqDRGU;

1.4
date	2015.02.11.07.01.36;	author jsg;	state Exp;
branches;
next	1.3;
commitid	dLgISW35NAmGN8Xl;

1.3
date	2015.02.10.00.23.53;	author jsg;	state Exp;
branches;
next	1.2;
commitid	G1YbxwpP7YxexmMy;

1.2
date	2014.09.20.21.17.43;	author kettenis;	state Exp;
branches;
next	1.1;
commitid	EVxnMw291QGly5Fu;

1.1
date	2014.04.01.20.16.50;	author kettenis;	state Exp;
branches;
next	;


desc
@@


1.48
log
@Various printf claim to report the PID, so actually report that and not the TID

ok kettenis@@ tedu@@
@
text
@/*	$OpenBSD: drm_linux.h,v 1.47 2016/04/05 20:44:03 kettenis Exp $	*/
/*
 * Copyright (c) 2013, 2014, 2015 Mark Kettenis
 *
 * Permission to use, copy, modify, and distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 */

#include <sys/atomic.h>
#include <sys/task.h>

typedef int irqreturn_t;
#define IRQ_NONE	0
#define IRQ_HANDLED	1

typedef u_int64_t u64;
typedef u_int32_t u32;
typedef u_int16_t u16;
typedef u_int8_t u8;

typedef int32_t s32;
typedef int64_t s64;

typedef uint64_t __u64;

typedef uint16_t __le16;
typedef uint16_t __be16;
typedef uint32_t __le32;
typedef uint32_t __be32;

typedef bus_addr_t dma_addr_t;
typedef bus_addr_t phys_addr_t;

typedef off_t loff_t;

#define __force
#define __always_unused	__unused
#define __read_mostly
#define __iomem
#define __must_check
#define __init

#define barrier()		__asm __volatile("" : : : "memory");

#define uninitialized_var(x) x

#if BYTE_ORDER == BIG_ENDIAN
#define __BIG_ENDIAN
#else
#define __LITTLE_ENDIAN
#endif

#define le16_to_cpu(x) letoh16(x)
#define le32_to_cpu(x) letoh32(x)
#define cpu_to_le16(x) htole16(x)
#define cpu_to_le32(x) htole32(x)

#define be32_to_cpup(x) betoh32(*x)

#define lower_32_bits(n)	((u32)(n))
#define upper_32_bits(_val)	((u32)(((_val) >> 16) >> 16))
#define DMA_BIT_MASK(n) (((n) == 64) ? ~0ULL : (1ULL<<(n)) -1)
#define BIT(x)			(1 << x)
#define BITS_TO_LONGS(x)	howmany((x), 8 * sizeof(long))

#define ACCESS_ONCE(x)		(x)

#define EXPORT_SYMBOL(x)

#define IS_ENABLED(x) x - 0

#define MODULE_FIRMWARE(x)
#define MODULE_PARM_DESC(parm, desc)
#define module_param_named(name, value, type, perm)

#define ARRAY_SIZE nitems

#define ERESTARTSYS	EINTR
#define ETIME		ETIMEDOUT
#define EREMOTEIO	EIO
#define EPROTO		EIO
#define ENOTSUPP	ENOTSUP

#define KERN_INFO
#define KERN_WARNING
#define KERN_NOTICE
#define KERN_DEBUG
#define KERN_CRIT
#define KERN_ERR

#define KBUILD_MODNAME "drm"

#ifndef pr_fmt
#define pr_fmt(fmt) fmt
#endif

#define printk_once(fmt, arg...) ({		\
	static int __warned;			\
	if (!__warned) {			\
		printf(fmt, ## arg);		\
		__warned = 1;			\
	}					\
})

#define printk(fmt, arg...)	printf(fmt, ## arg)
#define pr_warn(fmt, arg...)	printf(pr_fmt(fmt), ## arg)
#define pr_warn_once(fmt, arg...)	printk_once(pr_fmt(fmt), ## arg)
#define pr_notice(fmt, arg...)	printf(pr_fmt(fmt), ## arg)
#define pr_crit(fmt, arg...)	printf(pr_fmt(fmt), ## arg)
#define pr_err(fmt, arg...)	printf(pr_fmt(fmt), ## arg)

#ifdef DRMDEBUG
#define pr_info(fmt, arg...)	printf(pr_fmt(fmt), ## arg)
#define pr_info_once(fmt, arg...)	printk_once(pr_fmt(fmt), ## arg)
#define pr_debug(fmt, arg...)	printf(pr_fmt(fmt), ## arg)
#else
#define pr_info(fmt, arg...)	do { } while(0)
#define pr_info_once(fmt, arg...)	do { } while(0)
#define pr_debug(fmt, arg...)	do { } while(0)
#endif

#define dev_warn(dev, fmt, arg...)				\
	printf("drm:pid%d:%s *WARNING* " fmt, curproc->p_p->ps_pid,	\
	    __func__ , ## arg)
#define dev_notice(dev, fmt, arg...)				\
	printf("drm:pid%d:%s *NOTICE* " fmt, curproc->p_p->ps_pid,	\
	    __func__ , ## arg)
#define dev_crit(dev, fmt, arg...)				\
	printf("drm:pid%d:%s *ERROR* " fmt, curproc->p_p->ps_pid,	\
	    __func__ , ## arg)
#define dev_err(dev, fmt, arg...)				\
	printf("drm:pid%d:%s *ERROR* " fmt, curproc->p_p->ps_pid,	\
	    __func__ , ## arg)

#ifdef DRMDEBUG
#define dev_info(dev, fmt, arg...)				\
	printf("drm: " fmt, ## arg)
#define dev_debug(dev, fmt, arg...)				\
	printf("drm:pid%d:%s *DEBUG* " fmt, curproc->p_p->ps_pid,	\
	    __func__ , ## arg)
#else
#define dev_info(dev, fmt, arg...) 				\
	    do { } while(0)
#define dev_debug(dev, fmt, arg...) 				\
	    do { } while(0)
#endif

#define unlikely(x)	__builtin_expect(!!(x), 0)
#define likely(x)	__builtin_expect(!!(x), 1)

#define BUG()								\
do {									\
	panic("BUG at %s:%d", __FILE__, __LINE__);			\
} while (0)

#define BUG_ON(x) KASSERT(!(x))

#define BUILD_BUG_ON(x) CTASSERT(!(x))
#define BUILD_BUG_ON_NOT_POWER_OF_2(x)

#define WARN(condition, fmt...) ({ 					\
	int __ret = !!(condition);					\
	if (__ret)							\
		printf(fmt);						\
	unlikely(__ret);						\
})

#define WARN_ONCE(condition, fmt...) ({					\
	static int __warned;						\
	int __ret = !!(condition);					\
	if (__ret && !__warned) {					\
		printf(fmt);						\
		__warned = 1;						\
	}								\
	unlikely(__ret);						\
})

#define _WARN_STR(x) #x

#define WARN_ON(condition) ({						\
	int __ret = !!(condition);					\
	if (__ret)							\
		printf("WARNING %s failed at %s:%d\n",			\
		    _WARN_STR(condition), __FILE__, __LINE__);		\
	unlikely(__ret);						\
})

#define WARN_ON_ONCE(condition) ({					\
	static int __warned;						\
	int __ret = !!(condition);					\
	if (__ret && !__warned) {					\
		printf("WARNING %s failed at %s:%d\n",			\
		    _WARN_STR(condition), __FILE__, __LINE__);		\
		__warned = 1;						\
	}								\
	unlikely(__ret);						\
})

#define TP_PROTO(x...) x

#define DEFINE_EVENT(template, name, proto, args) \
static inline void trace_##name(proto) {}

#define TRACE_EVENT(name, proto, args, tstruct, assign, print) \
static inline void trace_##name(proto) {}

#define TRACE_EVENT_CONDITION(name, proto, args, cond, tstruct, assign, print) \
static inline void trace_##name(proto) {}

#define DECLARE_EVENT_CLASS(name, proto, args, tstruct, assign, print) \
static inline void trace_##name(proto) {}

#define IS_ERR_VALUE(x) unlikely((x) >= (unsigned long)-ELAST)

static inline void *
ERR_PTR(long error)
{
	return (void *) error;
}

static inline long
PTR_ERR(const void *ptr)
{
	return (long) ptr;
}

static inline long
IS_ERR(const void *ptr)
{
        return IS_ERR_VALUE((unsigned long)ptr);
}

static inline long
IS_ERR_OR_NULL(const void *ptr)
{
        return !ptr || IS_ERR_VALUE((unsigned long)ptr);
}

#define container_of(ptr, type, member) ({                      \
	__typeof( ((type *)0)->member ) *__mptr = (ptr);        \
	(type *)( (char *)__mptr - offsetof(type,member) );})

#ifndef __DECONST
#define __DECONST(type, var)    ((type)(__uintptr_t)(const void *)(var))
#endif

typedef struct rwlock rwlock_t;
typedef struct mutex spinlock_t;
#define DEFINE_SPINLOCK(x)	struct mutex x

static inline void
spin_lock_irqsave(struct mutex *mtxp, __unused unsigned long flags)
{
	mtx_enter(mtxp);
}
static inline void
spin_unlock_irqrestore(struct mutex *mtxp, __unused unsigned long flags)
{
	mtx_leave(mtxp);
}
#define spin_lock(mtxp)			mtx_enter(mtxp)
#define spin_unlock(mtxp)		mtx_leave(mtxp)
#define spin_lock_irq(mtxp)		mtx_enter(mtxp)
#define spin_unlock_irq(mtxp)		mtx_leave(mtxp)
#define assert_spin_locked(mtxp)	MUTEX_ASSERT_LOCKED(mtxp)
#define mutex_lock_interruptible(rwl)	-rw_enter(rwl, RW_WRITE | RW_INTR)
#define mutex_lock(rwl)			rw_enter_write(rwl)
#define mutex_lock_nest_lock(rwl, sub)	rw_enter_write(rwl)
#define mutex_trylock(rwl)		(rw_enter(rwl, RW_WRITE | RW_NOSLEEP) == 0)
#define mutex_unlock(rwl)		rw_exit_write(rwl)
#define mutex_is_locked(rwl)		(rw_status(rwl) == RW_WRITE)
#define down_read(rwl)			rw_enter_read(rwl)
#define up_read(rwl)			rw_exit_read(rwl)
#define down_write(rwl)			rw_enter_write(rwl)
#define up_write(rwl)			rw_exit_write(rwl)
#define read_lock(rwl)			rw_enter_read(rwl)
#define read_unlock(rwl)		rw_exit_read(rwl)
#define write_lock(rwl)			rw_enter_write(rwl)
#define write_unlock(rwl)		rw_exit_write(rwl)

#define local_irq_save(x)		(x) = splhigh()
#define local_irq_restore(x)		splx((x))

struct wait_queue_head {
	struct mutex lock;
	unsigned int count;
};
typedef struct wait_queue_head wait_queue_head_t;

static inline void
init_waitqueue_head(wait_queue_head_t *wq)
{
	mtx_init(&wq->lock, IPL_NONE);
	wq->count = 0;
}

#define wait_event(wq, condition) \
do {						\
	struct sleep_state sls;			\
						\
	if (condition)				\
		break;				\
	atomic_inc_int(&(wq).count);		\
	sleep_setup(&sls, &wq, 0, "drmwe");	\
	sleep_finish(&sls, !(condition));	\
	atomic_dec_int(&(wq).count);		\
} while (!(condition))

#define __wait_event_timeout(wq, condition, ret) \
do {						\
	struct sleep_state sls;			\
	int deadline, __error;			\
						\
	atomic_inc_int(&(wq).count);		\
	sleep_setup(&sls, &wq, 0, "drmwet");	\
	sleep_setup_timeout(&sls, ret);		\
	deadline = ticks + ret;			\
	sleep_finish(&sls, !(condition));	\
	ret = deadline - ticks;			\
	__error = sleep_finish_timeout(&sls);	\
	atomic_dec_int(&(wq).count);		\
	if (ret < 0 || __error == EWOULDBLOCK)	\
		ret = 0;			\
	if (ret == 0 && (condition)) {		\
		ret = 1;			\
		break;				\
	}					\
} while (ret > 0 && !(condition))

#define wait_event_timeout(wq, condition, timo)	\
({						\
	long __ret = timo;			\
	if (!(condition))			\
		__wait_event_timeout(wq, condition, __ret); \
	__ret;					\
})

#define __wait_event_interruptible_timeout(wq, condition, ret) \
do {						\
	struct sleep_state sls;			\
	int deadline, __error, __error1;		\
						\
	atomic_inc_int(&(wq).count);		\
	sleep_setup(&sls, &wq, PCATCH, "drmweti"); \
	sleep_setup_timeout(&sls, ret);		\
	sleep_setup_signal(&sls, PCATCH);	\
	deadline = ticks + ret;			\
	sleep_finish(&sls, !(condition));	\
	ret = deadline - ticks;			\
	__error1 = sleep_finish_timeout(&sls);	\
	__error = sleep_finish_signal(&sls);	\
	atomic_dec_int(&(wq).count);		\
	if (ret < 0 || __error1 == EWOULDBLOCK)	\
		ret = 0;			\
	if (__error == ERESTART)			\
		ret = -ERESTARTSYS;		\
	else if (__error)				\
		ret = -__error;			\
	if (ret == 0 && (condition)) {		\
		ret = 1;			\
		break;				\
	}					\
} while (ret > 0 && !(condition))

#define wait_event_interruptible_timeout(wq, condition, timo) \
({						\
	long __ret = timo;			\
	if (!(condition))			\
		__wait_event_interruptible_timeout(wq, condition, __ret); \
	__ret;					\
})

#define wake_up(x)			wakeup(x)
#define wake_up_all(x)			wakeup(x)
#define wake_up_all_locked(x)		wakeup(x)
#define wake_up_interruptible(x)	wakeup(x)

#define waitqueue_active(wq)		((wq)->count > 0)

struct completion {
	u_int done;
	wait_queue_head_t wait;
};

#define INIT_COMPLETION(x) ((x).done = 0)

static inline void
init_completion(struct completion *x)
{
	x->done = 0;
	mtx_init(&x->wait.lock, IPL_NONE);
}

static inline u_long
wait_for_completion_interruptible_timeout(struct completion *x, u_long timo)
{
	int ret;

	mtx_enter(&x->wait.lock);
	while (x->done == 0) {
		ret = msleep(x, &x->wait.lock, PCATCH, "wfcit", timo);
		if (ret) {
			mtx_leave(&x->wait.lock);
			return (ret == EWOULDBLOCK) ? 0 : -ret;
		}
	}

	return 1;
}

static inline void
complete_all(struct completion *x)
{
	mtx_enter(&x->wait.lock);
	x->done = 1;
	mtx_leave(&x->wait.lock);
	wakeup(x);
}

struct workqueue_struct;

static inline struct workqueue_struct *
alloc_ordered_workqueue(const char *name, int flags)
{
	struct taskq *tq = taskq_create(name, 1, IPL_TTY, 0);
	return (struct workqueue_struct *)tq;
}

static inline void
destroy_workqueue(struct workqueue_struct *wq)
{
	taskq_destroy((struct taskq *)wq);
}

struct work_struct {
	struct task task;
	struct taskq *tq;
};

typedef void (*work_func_t)(struct work_struct *);

static inline void
INIT_WORK(struct work_struct *work, work_func_t func)
{
	work->tq = systq;
	task_set(&work->task, (void (*)(void *))func, work);
}

static inline bool
queue_work(struct workqueue_struct *wq, struct work_struct *work)
{
	work->tq = (struct taskq *)wq;
	return task_add(work->tq, &work->task);
}

static inline void
cancel_work_sync(struct work_struct *work)
{
	task_del(work->tq, &work->task);
}

struct delayed_work {
	struct work_struct work;
	struct timeout to;
	struct taskq *tq;
};

static inline struct delayed_work *
to_delayed_work(struct work_struct *work)
{
	return container_of(work, struct delayed_work, work);
}

static void
__delayed_work_tick(void *arg)
{
	struct delayed_work *dwork = arg;

	task_add(dwork->tq, &dwork->work.task);
}

static inline void
INIT_DELAYED_WORK(struct delayed_work *dwork, work_func_t func)
{
	INIT_WORK(&dwork->work, func);
	timeout_set(&dwork->to, __delayed_work_tick, &dwork->work);
}

static inline bool
schedule_work(struct work_struct *work)
{
	return task_add(work->tq, &work->task);
}

static inline bool
schedule_delayed_work(struct delayed_work *dwork, int jiffies)
{
	dwork->tq = systq;
	return timeout_add(&dwork->to, jiffies);
}

static inline bool
queue_delayed_work(struct workqueue_struct *wq,
    struct delayed_work *dwork, int jiffies)
{
	dwork->tq = (struct taskq *)wq;
	return timeout_add(&dwork->to, jiffies);
}

static inline bool
mod_delayed_work(struct workqueue_struct *wq,
    struct delayed_work *dwork, int jiffies)
{
	dwork->tq = (struct taskq *)wq;
	return (timeout_add(&dwork->to, jiffies) == 0);
}

static inline bool
cancel_delayed_work(struct delayed_work *dwork)
{
	if (timeout_del(&dwork->to))
		return true;
	return task_del(dwork->tq, &dwork->work.task);
}

static inline bool
cancel_delayed_work_sync(struct delayed_work *dwork)
{
	if (timeout_del(&dwork->to))
		return true;
	return task_del(dwork->tq, &dwork->work.task);
}

#define flush_workqueue(x)
#define flush_scheduled_work(x)
#define flush_delayed_work(x) (void)(x)

#define setup_timer(x, y, z)	timeout_set((x), (void (*)(void *))(y), (void *)(z))
#define mod_timer(x, y)		timeout_add((x), (y - jiffies))
#define del_timer_sync(x)	timeout_del((x))

#define NSEC_PER_USEC	1000L
#define NSEC_PER_SEC	1000000000L
#define KHZ2PICOS(a)	(1000000000UL/(a))

extern struct timespec ns_to_timespec(const int64_t);
extern int64_t timeval_to_ns(const struct timeval *);
extern struct timeval ns_to_timeval(const int64_t);

static inline struct timespec
timespec_sub(struct timespec t1, struct timespec t2)
{
	struct timespec diff;

	timespecsub(&t1, &t2, &diff);
	return diff;
}

#define time_in_range(x, min, max) ((x) >= (min) && (x) <= (max))

extern int ticks;
#define jiffies ticks
#undef HZ
#define HZ	hz

#define MAX_JIFFY_OFFSET	((INT_MAX >> 1) - 1)

static inline unsigned long
round_jiffies_up(unsigned long j)
{
	return roundup(j, hz);
}

static inline unsigned long
round_jiffies_up_relative(unsigned long j)
{
	return roundup(j, hz);
}

#define jiffies_to_msecs(x)	(((int64_t)(x)) * 1000 / hz)
#define msecs_to_jiffies(x)	(((int64_t)(x)) * hz / 1000)
#define time_after(a,b)		((long)(b) - (long)(a) < 0)
#define time_after_eq(a,b)	((long)(b) - (long)(a) <= 0)
#define get_seconds()		time_second
#define getrawmonotonic(x)	nanouptime(x)

static inline void
set_normalized_timespec(struct timespec *ts, time_t sec, int64_t nsec)
{
	while (nsec > NSEC_PER_SEC) {
		nsec -= NSEC_PER_SEC;
		sec++;
	}

	ts->tv_sec = sec;
	ts->tv_nsec = nsec;
}

static inline int64_t
timespec_to_ns(const struct timespec *ts)
{
	return ((ts->tv_sec * NSEC_PER_SEC) + ts->tv_nsec);
}

static inline int
timespec_to_jiffies(const struct timespec *ts)
{
	long long to_ticks;

	to_ticks = (long long)hz * ts->tv_sec + ts->tv_nsec / (tick * 1000);
	if (to_ticks > INT_MAX)
		to_ticks = INT_MAX;

	return ((int)to_ticks);
}

static inline int
timespec_valid(const struct timespec *ts)
{
	if (ts->tv_sec < 0 || ts->tv_sec > 100000000 ||
	    ts->tv_nsec < 0 || ts->tv_nsec >= 1000000000)
		return (0);
	return (1);
}

typedef struct timeval ktime_t;

static inline struct timeval
ktime_get(void)
{
	struct timeval tv;
	
	getmicrouptime(&tv);
	return tv;
}

static inline struct timeval
ktime_get_monotonic_offset(void)
{
	struct timeval tv = {0, 0};
	return tv;
}

static inline int64_t
ktime_to_ns(struct timeval tv)
{
	return timeval_to_ns(&tv);
}

#define ktime_to_timeval(tv) (tv)

static inline struct timeval
ktime_sub(struct timeval a, struct timeval b)
{
	struct timeval res;
	timersub(&a, &b, &res);
	return res;
}

static inline struct timeval
ktime_add_ns(struct timeval tv, int64_t ns)
{
	return ns_to_timeval(timeval_to_ns(&tv) + ns);
}

static inline struct timeval
ktime_sub_ns(struct timeval tv, int64_t ns)
{
	return ns_to_timeval(timeval_to_ns(&tv) - ns);
}

#define GFP_ATOMIC	M_NOWAIT
#define GFP_NOWAIT	M_NOWAIT
#define GFP_KERNEL	(M_WAITOK | M_CANFAIL)
#define GFP_TEMPORARY	(M_WAITOK | M_CANFAIL)
#define __GFP_NOWARN	0
#define __GFP_NORETRY	0

static inline void *
kmalloc(size_t size, int flags)
{
	return malloc(size, M_DRM, flags);
}

static inline void *
kmalloc_array(size_t n, size_t size, int flags)
{
	if (n == 0 || SIZE_MAX / n < size)
		return NULL;
	return malloc(n * size, M_DRM, flags);
}

static inline void *
kcalloc(size_t n, size_t size, int flags)
{
	if (n == 0 || SIZE_MAX / n < size)
		return NULL;
	return malloc(n * size, M_DRM, flags | M_ZERO);
}

static inline void *
kzalloc(size_t size, int flags)
{
	return malloc(size, M_DRM, flags | M_ZERO);
}

static inline void
kfree(void *objp)
{
	free(objp, M_DRM, 0);
}

static inline void *
kmemdup(const void *src, size_t len, int flags)
{
	void *p = malloc(len, M_DRM, flags);
	if (p)
		memcpy(p, src, len);
	return (p);
}

static inline void *
vzalloc(unsigned long size)
{
	return malloc(size, M_DRM, M_WAITOK | M_CANFAIL | M_ZERO);
}

static inline void
vfree(void *objp)
{
	free(objp, M_DRM, 0);
}

struct kref {
	uint32_t refcount;
};

static inline void
kref_init(struct kref *ref)
{
	ref->refcount = 1;
}

static inline void
kref_get(struct kref *ref)
{
	atomic_inc_int(&ref->refcount);
}

static inline int
kref_get_unless_zero(struct kref *ref)
{
	if (ref->refcount != 0) {
		atomic_inc_int(&ref->refcount);
		return (1);
	} else {
		return (0);
	}
}

static inline void
kref_put(struct kref *ref, void (*release)(struct kref *ref))
{
	if (atomic_dec_int_nv(&ref->refcount) == 0)
		release(ref);
}

static inline void
kref_sub(struct kref *ref, unsigned int v, void (*release)(struct kref *ref))
{
	if (atomic_sub_int_nv(&ref->refcount, v) == 0)
		release(ref);
}

struct kobject {
	struct kref kref;
	struct kobj_type *type;
};

struct kobj_type {
	void (*release)(struct kobject *);
};

static inline void
kobject_init(struct kobject *obj, struct kobj_type *type)
{
	kref_init(&obj->kref);
	obj->type = type;
}

static inline int
kobject_init_and_add(struct kobject *obj, struct kobj_type *type,
    struct kobject *parent, const char *fmt, ...)
{
	kobject_init(obj, type);
	return (0);
}

static inline struct kobject *
kobject_get(struct kobject *obj)
{
	if (obj != NULL)
		kref_get(&obj->kref);
	return (obj);
}

static inline void
kobject_release(struct kref *ref)
{
	struct kobject *obj = container_of(ref, struct kobject, kref);
	if (obj->type && obj->type->release)
		obj->type->release(obj);
}

static inline void
kobject_put(struct kobject *obj)
{
	if (obj != NULL)
		kref_put(&obj->kref, kobject_release);
}

static inline void
kobject_del(struct kobject *obj)
{
}

struct idr_entry {
	SPLAY_ENTRY(idr_entry) entry;
	int id;
	void *ptr;
};

struct idr {
	SPLAY_HEAD(idr_tree, idr_entry) tree;
};

void idr_init(struct idr *);
void idr_preload(unsigned int);
int idr_alloc(struct idr *, void *, int, int, unsigned int);
#define idr_preload_end()
void *idr_find(struct idr *, int);
void idr_remove(struct idr *, int);
void idr_destroy(struct idr *);
int idr_for_each(struct idr *, int (*)(int, void *, void *), void *);

#define min_t(t, a, b) ({ \
	t __min_a = (a); \
	t __min_b = (b); \
	__min_a < __min_b ? __min_a : __min_b; })

#define max_t(t, a, b) ({ \
	t __max_a = (a); \
	t __max_b = (b); \
	__max_a > __max_b ? __max_a : __max_b; })

#define clamp_t(t, x, a, b) min_t(t, max_t(t, x, a), b)

#define do_div(n, base) \
	n = n / base

static inline uint64_t
div_u64(uint64_t x, uint32_t y)
{
	return (x / y);
}

static inline uint64_t
div64_u64(uint64_t x, uint64_t y)
{
	return (x / y);
}

static inline int64_t
div64_s64(int64_t x, int64_t y)
{
	return (x / y);
}

#define mult_frac(x, n, d) (((x) * (n)) / (d))

static inline int64_t
abs64(int64_t x)
{
	return (x < 0 ? -x : x);
}

static inline unsigned long
__copy_to_user(void *to, const void *from, unsigned len)
{
	if (copyout(from, to, len))
		return len;
	return 0;
}

static inline unsigned long
copy_to_user(void *to, const void *from, unsigned len)
{
	return __copy_to_user(to, from, len);
}

static inline unsigned long
__copy_from_user(void *to, const void *from, unsigned len)
{
	if (copyin(from, to, len))
		return len;
	return 0;
}

static inline unsigned long
copy_from_user(void *to, const void *from, unsigned len)
{
	return __copy_from_user(to, from, len);
}

#define get_user(x, ptr)	-copyin(ptr, &(x), sizeof(x))
#define put_user(x, ptr)	-copyout(&(x), ptr, sizeof(x))

static __inline uint16_t
hweight16(uint32_t x)
{
	x = (x & 0x5555) + ((x & 0xaaaa) >> 1);
	x = (x & 0x3333) + ((x & 0xcccc) >> 2);
	x = (x + (x >> 4)) & 0x0f0f;
	x = (x + (x >> 8)) & 0x00ff;
	return (x);
}

static inline uint32_t
hweight32(uint32_t x)
{
	x = (x & 0x55555555) + ((x & 0xaaaaaaaa) >> 1);
	x = (x & 0x33333333) + ((x & 0xcccccccc) >> 2);
	x = (x + (x >> 4)) & 0x0f0f0f0f;
	x = (x + (x >> 8));
	x = (x + (x >> 16)) & 0x000000ff;
	return x;
}

#define console_lock()
#define console_unlock()

#ifndef PCI_MEM_START
#define PCI_MEM_START	0
#endif

#ifndef PCI_MEM_END
#define PCI_MEM_END	0xffffffff
#endif

enum dmi_field {
        DMI_NONE,
        DMI_BIOS_VENDOR,
        DMI_BIOS_VERSION,
        DMI_BIOS_DATE,
        DMI_SYS_VENDOR,
        DMI_PRODUCT_NAME,
        DMI_PRODUCT_VERSION,
        DMI_PRODUCT_SERIAL,
        DMI_PRODUCT_UUID,
        DMI_BOARD_VENDOR,
        DMI_BOARD_NAME,
        DMI_BOARD_VERSION,
        DMI_BOARD_SERIAL,
        DMI_BOARD_ASSET_TAG,
        DMI_CHASSIS_VENDOR,
        DMI_CHASSIS_TYPE,
        DMI_CHASSIS_VERSION,
        DMI_CHASSIS_SERIAL,
        DMI_CHASSIS_ASSET_TAG,
        DMI_STRING_MAX,
};

struct dmi_strmatch {
	unsigned char slot;
	char substr[79];
};

struct dmi_system_id {
        int (*callback)(const struct dmi_system_id *);
        const char *ident;
        struct dmi_strmatch matches[4];
};
#define	DMI_MATCH(a, b) {(a), (b)}
#define	DMI_EXACT_MATCH(a, b) {(a), (b)}
int dmi_check_system(const struct dmi_system_id *);

struct resource {
	u_long	start;
};

struct pci_bus {
	unsigned char	number;
};

struct pci_dev {
	struct pci_bus	_bus;
	struct pci_bus	*bus;

	unsigned int	devfn;
	uint16_t	vendor;
	uint16_t	device;
	uint16_t	subsystem_vendor;
	uint16_t	subsystem_device;

	pci_chipset_tag_t pc;
	pcitag_t	tag;
	struct pci_softc *pci;
};
#define PCI_ANY_ID (uint16_t) (~0U)

#define PCI_VENDOR_ID_ASUSTEK	PCI_VENDOR_ASUSTEK
#define PCI_VENDOR_ID_ATI	PCI_VENDOR_ATI
#define PCI_VENDOR_ID_DELL	PCI_VENDOR_DELL
#define PCI_VENDOR_ID_HP	PCI_VENDOR_HP
#define PCI_VENDOR_ID_IBM	PCI_VENDOR_IBM
#define PCI_VENDOR_ID_INTEL	PCI_VENDOR_INTEL
#define PCI_VENDOR_ID_SONY	PCI_VENDOR_SONY
#define PCI_VENDOR_ID_VIA	PCI_VENDOR_VIATECH

#define PCI_DEVICE_ID_ATI_RADEON_QY	PCI_PRODUCT_ATI_RADEON_QY

#define PCI_DEVFN(slot, func)	((slot) << 3 | (func))
#define PCI_SLOT(devfn)		((devfn) >> 3)
#define PCI_FUNC(devfn)		((devfn) & 0x7)

static inline void
pci_read_config_dword(struct pci_dev *pdev, int reg, u32 *val)
{
	*val = pci_conf_read(pdev->pc, pdev->tag, reg);
} 

static inline void
pci_read_config_word(struct pci_dev *pdev, int reg, u16 *val)
{
	uint32_t v;

	v = pci_conf_read(pdev->pc, pdev->tag, (reg & ~0x2));
	*val = (v >> ((reg & 0x2) * 8));
} 

static inline void
pci_read_config_byte(struct pci_dev *pdev, int reg, u8 *val)
{
	uint32_t v;

	v = pci_conf_read(pdev->pc, pdev->tag, (reg & ~0x3));
	*val = (v >> ((reg & 0x3) * 8));
} 

static inline void
pci_write_config_dword(struct pci_dev *pdev, int reg, u32 val)
{
	pci_conf_write(pdev->pc, pdev->tag, reg, val);
} 

static inline void
pci_write_config_word(struct pci_dev *pdev, int reg, u16 val)
{
	uint32_t v;

	v = pci_conf_read(pdev->pc, pdev->tag, (reg & ~0x2));
	v &= ~(0xffff << ((reg & 0x2) * 8));
	v |= (val << ((reg & 0x2) * 8));
	pci_conf_write(pdev->pc, pdev->tag, (reg & ~0x2), v);
} 

static inline void
pci_write_config_byte(struct pci_dev *pdev, int reg, u8 val)
{
	uint32_t v;

	v = pci_conf_read(pdev->pc, pdev->tag, (reg & ~0x3));
	v &= ~(0xff << ((reg & 0x3) * 8));
	v |= (val << ((reg & 0x3) * 8));
	pci_conf_write(pdev->pc, pdev->tag, (reg & ~0x3), v);
}

typedef enum {
	PCI_D0,
	PCI_D1,
	PCI_D2,
	PCI_D3hot,
	PCI_D3cold
} pci_power_t;

#if defined(__amd64__) || defined(__i386__)

#define PCI_DMA_BIDIRECTIONAL	0

static inline dma_addr_t
pci_map_page(struct pci_dev *pdev, struct vm_page *page, unsigned long offset, size_t size, int direction)
{
	return VM_PAGE_TO_PHYS(page);
}

static inline void
pci_unmap_page(struct pci_dev *pdev, dma_addr_t dma_address, size_t size, int direction)
{
}

static inline int
pci_dma_mapping_error(struct pci_dev *pdev, dma_addr_t dma_addr)
{
	return 0;
}

#define VGA_RSRC_LEGACY_IO	0x01

void vga_get_uninterruptible(struct pci_dev *, int);
void vga_put(struct pci_dev *, int);

#endif

#define memcpy_toio(d, s, n)	memcpy(d, s, n)
#define memcpy_fromio(d, s, n)	memcpy(d, s, n)
#define memset_io(d, b, n)	memset(d, b, n)

static inline u32
ioread32(const volatile void __iomem *addr)
{
	return (*(volatile uint32_t *)addr);
}

static inline u64
ioread64(const volatile void __iomem *addr)
{
	return (*(volatile uint64_t *)addr);
}

static inline void
iowrite32(u32 val, volatile void __iomem *addr)
{
	*(volatile uint32_t *)addr = val;
}

#define readl(p) ioread32(p)
#define writel(v, p) iowrite32(v, p)
#define readq(p) ioread64(p)

#define page_to_phys(page)	(VM_PAGE_TO_PHYS(page))
#define page_to_pfn(pp)		(VM_PAGE_TO_PHYS(pp) / PAGE_SIZE)
#define offset_in_page(off)	((off) & PAGE_MASK)
#define set_page_dirty(page)	atomic_clearbits_int(&page->pg_flags, PG_CLEAN)

#define VERIFY_READ	0x1
#define VERIFY_WRITE	0x2
static inline int
access_ok(int type, const void *addr, unsigned long size)
{
	return true;
}

#define CAP_SYS_ADMIN	0x1
static inline int
capable(int cap)
{
	KASSERT(cap == CAP_SYS_ADMIN);
	return suser(curproc, 0);
}

typedef int pgprot_t;
#define pgprot_val(v)	(v)
#define PAGE_KERNEL	0

void	*kmap(struct vm_page *);
void	 kunmap(void *addr);
void	*vmap(struct vm_page **, unsigned int, unsigned long, pgprot_t);
void	 vunmap(void *, size_t);

#define round_up(x, y) ((((x) + ((y) - 1)) / (y)) * (y))
#define round_down(x, y) (((x) / (y)) * (y))
#define roundup2(x, y) (((x)+((y)-1))&(~((y)-1))) /* if y is powers of two */
#define DIV_ROUND_UP(x, y)	(((x) + ((y) - 1)) / (y))
#define DIV_ROUND_UP_ULL(x, y)	DIV_ROUND_UP(x, y)
#define DIV_ROUND_CLOSEST(x, y)	(((x) + ((y) / 2)) / (y))

static inline unsigned long
roundup_pow_of_two(unsigned long x)
{
	return (1UL << flsl(x - 1));
}

#define is_power_of_2(x)	(x != 0 && (((x) - 1) & (x)) == 0)

#define PAGE_ALIGN(addr)	(((addr) + PAGE_MASK) & ~PAGE_MASK)
#define IS_ALIGNED(x, y)	(((x) & ((y) - 1)) == 0)

static __inline void
udelay(unsigned long usecs)
{
	DELAY(usecs);
}

static __inline void
ndelay(unsigned long nsecs)
{
	DELAY(max(nsecs / 1000, 1));
}

static __inline void
usleep_range(unsigned long min, unsigned long max)
{
	DELAY(min);
}

static __inline void
mdelay(unsigned long msecs)
{
	int loops = msecs;
	while (loops--)
		DELAY(1000);
}

static inline uint32_t ror32(uint32_t word, unsigned int shift)
{
	return (word >> shift) | (word << (32 - shift));
}

static inline int
irqs_disabled(void)
{
	return (cold);
}

static inline int
in_dbg_master(void)
{
#ifdef DDB
	return (db_is_active);
#endif
	return (0);
}

#define oops_in_progress in_dbg_master()

static inline int
power_supply_is_system_supplied(void)
{
	/* XXX return 0 if on battery */
	return (1);
}

#define _U      0x01
#define _L      0x02
#define _N      0x04
#define _S      0x08
#define _P      0x10
#define _C      0x20
#define _X      0x40
#define _B      0x80

static inline int
isascii(int c)
{
	return ((unsigned int)c <= 0177);
}

static inline int
isprint(int c)
{
	if (c == -1)
		return (0);
	if ((unsigned char)c >= 040 && (unsigned char)c <= 0176)
		return (1);
	return (0);
}

#ifdef __macppc__
static __inline int
of_machine_is_compatible(const char *model)
{
	extern char *hw_prod;
	return (strcmp(model, hw_prod) == 0);
}
#endif

struct vm_page *alloc_pages(unsigned int, unsigned int);
void	__free_pages(struct vm_page *, unsigned int);

static inline struct vm_page *
alloc_page(unsigned int gfp_mask)
{
	return alloc_pages(gfp_mask, 0);
}

static inline void
__free_page(struct vm_page *page)
{
	return __free_pages(page, 0);
}

static inline unsigned int
get_order(size_t size)
{
	return flsl((size - 1) >> PAGE_SHIFT);
}

#if defined(__i386__) || defined(__amd64__)

static inline void
pagefault_disable(void)
{
	KASSERT(curcpu()->ci_inatomic == 0);
	curcpu()->ci_inatomic = 1;
}

static inline void
pagefault_enable(void)
{
	KASSERT(curcpu()->ci_inatomic == 1);
	curcpu()->ci_inatomic = 0;
}

static inline int
in_atomic(void)
{
	return curcpu()->ci_inatomic;
}

static inline void *
kmap_atomic(struct vm_page *pg)
{
	vaddr_t va;

#if defined (__HAVE_PMAP_DIRECT)
	va = pmap_map_direct(pg);
#else
	extern vaddr_t pmap_tmpmap_pa(paddr_t);
	va = pmap_tmpmap_pa(VM_PAGE_TO_PHYS(pg));
#endif
	return (void *)va;
}

static inline void
kunmap_atomic(void *addr)
{
#if defined (__HAVE_PMAP_DIRECT)
	pmap_unmap_direct((vaddr_t)addr);
#else
	extern void pmap_tmpunmap_pa(void);
	pmap_tmpunmap_pa();
#endif
}

static inline unsigned long
__copy_to_user_inatomic(void *to, const void *from, unsigned len)
{
	struct cpu_info *ci = curcpu();
	int inatomic = ci->ci_inatomic;
	int error;

	ci->ci_inatomic = 1;
	error = copyout(from, to, len);
	ci->ci_inatomic = inatomic;

	return (error ? len : 0);
}

static inline unsigned long
__copy_from_user_inatomic(void *to, const void *from, unsigned len)
{
	struct cpu_info *ci = curcpu();
	int inatomic = ci->ci_inatomic;
	int error;

	ci->ci_inatomic = 1;
	error = copyin(from, to, len);
	ci->ci_inatomic = inatomic;

	return (error ? len : 0);
}

static inline unsigned long
__copy_from_user_inatomic_nocache(void *to, const void *from, unsigned len)
{
	return __copy_from_user_inatomic(to, from, len);
}

#endif

struct fb_var_screeninfo {
	int pixclock;
};

struct fb_info {
	struct fb_var_screeninfo var;
	void *par;
};

#define framebuffer_alloc(flags, device) \
	kzalloc(sizeof(struct fb_info), GFP_KERNEL)

struct address_space;
#define unmap_mapping_range(mapping, holebegin, holeend, even_cows)

/*
 * ACPI types and interfaces.
 */

typedef size_t acpi_size;
typedef int acpi_status;

struct acpi_table_header;

#define ACPI_SUCCESS(x) ((x) == 0)

#define AE_NOT_FOUND	0x0005

acpi_status acpi_get_table_with_size(const char *, int, struct acpi_table_header **, acpi_size *);
@


1.47
log
@Add an implementation of the Linux "idr" API.
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.h,v 1.46 2016/04/05 08:19:00 kettenis Exp $	*/
d132 1
a132 1
	printf("drm:pid%d:%s *WARNING* " fmt, curproc->p_pid,	\
d135 1
a135 1
	printf("drm:pid%d:%s *NOTICE* " fmt, curproc->p_pid,	\
d138 1
a138 1
	printf("drm:pid%d:%s *ERROR* " fmt, curproc->p_pid,	\
d141 1
a141 1
	printf("drm:pid%d:%s *ERROR* " fmt, curproc->p_pid,	\
d148 1
a148 1
	printf("drm:pid%d:%s *DEBUG* " fmt, curproc->p_pid,	\
@


1.46
log
@Add vma offset manager code.

ok jsg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.h,v 1.45 2016/02/05 15:51:10 kettenis Exp $	*/
d682 1
d835 19
@


1.45
log
@Implement acpi_get_table_with_size().  Will soon be used to read VFCT
tables in radeondrm(4).
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.h,v 1.44 2016/02/05 10:05:12 kettenis Exp $	*/
d33 2
d1381 3
@


1.44
log
@Improve Linux PCI compatibility code.
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.h,v 1.43 2015/12/31 13:01:00 kettenis Exp $	*/
d1379 15
@


1.43
log
@Provide a minimal implementation of the Linux vga_get/vga_put API and use it
in inteldrm(4).

The Intel integrated graphics device has a major design flaw where it needs
legacy VGA io access to disable VGA mode completely.  This only works if
legacy VGA io routing is setup such that it actually reaches the IGD.  This
typically isn't the case if the primary VGA device is a discrete graphics
device.  To make sure we don't whack that device we have to temporarily
route legacy VGA io access to the IGD.

Fixes the "black screen" issue reported by Timo Myrra and others.
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.h,v 1.42 2015/10/17 21:41:12 kettenis Exp $	*/
d978 4
d983 4
d991 1
d1010 2
@


1.42
log
@Fix the code that sets up the MCH BAR on systems where the (buggy) BIOS
doesn't do this for us.  The code was poking registers on the wrong PCI
device.  We were just lucky that it worked on most systems.

This should fix machines such as the Asus EeePC 701 and get rid of the

error: [drm:pid0:i915_gem_detect_bit_6_swizzle] *ERROR* Couldn't read from
MC HBAR.  Disabling tiling.

messages on that machine.
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.h,v 1.41 2015/09/27 21:28:14 kettenis Exp $	*/
d985 1
d1082 5
@


1.41
log
@Enable monitor hot plugging for the framebuffer console.

Tested on the VGA port of a Radeon 7500 and Radeon 9250 (aka 9200 PRO).
Hopefully this works on Intel Graphics as well.
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.h,v 1.40 2015/09/27 11:09:26 jsg Exp $	*/
d973 4
@


1.40
log
@Switch remaining users of the FreeBSD refcount apis back to the original
linux kref/kobject use.

ok kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.h,v 1.39 2015/09/26 22:00:00 kettenis Exp $	*/
d1346 12
@


1.39
log
@Try a little bit harder to clean up if attaching inteldrm(4) fails.
The crucial bit is that we now clear dev->dev_priv, which prevents the X
server from opening /dev/drmN and crashing the kernel because the driver
isn't fully initialized.

While there, try a little bit harder to print error messages the proper way.
Things will still look ugly though if the failure is somewhere in the Linux
code.
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.h,v 1.38 2015/09/26 19:52:16 kettenis Exp $	*/
d741 1
a741 1
	uint32_t count;
d747 1
a747 1
	ref->count = 1;
d753 12
a764 1
	atomic_inc_int(&ref->count);
d770 1
a770 1
	if (atomic_dec_int_nv(&ref->count) == 0)
d772 59
@


1.38
log
@Update drm_irq.c to the version from Linux 3.14.52.
Disable the DRM_IOCTL_IRQ_BUSID and DRM_IOCTL_CONTROL ioctls.
These are legacy ioctls for DRI1 support, which we no longer support on
OpenBSD.
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.h,v 1.37 2015/09/26 11:17:15 kettenis Exp $	*/
d428 13
@


1.37
log
@Make the PPGTT code work.  Seems to fix the caching issues on Broadwell.
Comments on some of the later Broadwell-related commits in the Linux tree
seem to say that the PPAT flags in for the (global) GTT are simply broken in
the hardware.
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.h,v 1.36 2015/09/25 20:27:52 kettenis Exp $	*/
d383 1
d621 1
d629 35
@


1.36
log
@Apparently 0 is not a power of 2 (despite <sys/param.h> claiming that it is).
Fixes inteldrm(4) on the GM45 chipset.
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.h,v 1.35 2015/09/24 20:52:28 kettenis Exp $	*/
d937 23
d983 1
d1122 21
@


1.35
log
@Properly implement waitqueue_active().  Gets rid of spurious

  *ERROR* Hangcheck timer elapsed... xxx ring idle

messages.
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.h,v 1.34 2015/09/23 23:12:11 kettenis Exp $	*/
d1005 1
a1005 1
#define is_power_of_2(x)	((((x)-1)&(x))==0)
@


1.34
log
@Update inteldrm to the code from Linux 3.14.52 (which corresponds to
commit 48f8f36a6c8018c2b36ea207aaf68ef5326c5075 on the linux-3.14.y
branch of the linux-stable tree).  This brings preliminary support for
the GPU on Intel's Broadwell CPUs.  Don't expect these to work
perfectly yet.  There are some remaining issues with older hardware as
well, but no significant regressions have been uncovered.

This also updates some of drm core code.  The radeondrm code remains
based on Linux 3.8 with some minimal canges to adjust to changes in
the core drm APIs.

Joint effort with jsg@@, who did the initial update of the relevant drm
core bits.  Committing this early to make sure it gets more testing
and make it possible for others to help getting the remaining wrinkles
straightened out.
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.h,v 1.33 2015/07/16 18:48:51 kettenis Exp $	*/
d3 1
a3 1
 * Copyright (c) 2013, 2014 Mark Kettenis
d293 1
d301 1
d310 1
d313 1
d321 1
d328 1
d350 1
d359 1
d384 1
a384 1
#define waitqueue_active(x)		true
@


1.33
log
@Introduce a Linux compatible wait_event API and use it in the inteldrm code.

ok jsg@@, guenther@@
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.h,v 1.32 2015/07/11 04:00:46 jsg Exp $	*/
d18 1
d41 2
d44 1
a44 1
#define __always_unused
d50 2
d70 4
d77 2
d121 1
d125 1
d166 1
d211 4
a214 1
#define TRACE_EVENT(name, proto, args, struct, assign, print) \
d275 2
d288 3
d315 1
a315 1
	int deadline, error;			\
d322 2
a323 2
	error = sleep_finish_timeout(&sls);	\
	if (ret < 0 || error == EWOULDBLOCK)	\
d342 1
a342 1
	int deadline, error, error1;		\
d350 3
a352 3
	error1 = sleep_finish_timeout(&sls);	\
	error = sleep_finish_signal(&sls);	\
	if (ret < 0 || error1 == EWOULDBLOCK)	\
d354 1
a354 1
	if (error == ERESTART)			\
d356 2
a357 2
	else if (error)				\
		ret = -error;			\
d376 2
d430 1
d475 6
d496 8
d519 8
d535 11
d551 8
d611 10
d623 1
d662 9
d682 23
d715 5
d733 8
d851 2
d867 62
d936 7
a942 3
	u32 r;
	memcpy(&r, (void *)addr, 4);
	return (r);
d948 1
a948 1
	memcpy((void *)addr, &val, 4);
d951 3
d959 16
d988 1
d997 2
d1009 6
d1048 2
d1055 25
@


1.32
log
@Make use of recent drm_linux.h additions to further reduce the
diff to linux.

ok kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.h,v 1.31 2015/06/26 15:22:23 kettenis Exp $	*/
d279 70
@


1.31
log
@Add Linux completion API and use it.

ok jsg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.h,v 1.30 2015/06/24 19:01:51 kettenis Exp $	*/
d402 1
a402 1
static inline void
d405 3
a407 2
	timeout_del(&dwork->to);
	task_del(dwork->tq, &dwork->work.task);
@


1.30
log
@#undef HZ before defining it such that compiling a kernel with -DHZ=xxx works.
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.h,v 1.29 2015/06/24 17:59:42 kettenis Exp $	*/
d283 40
@


1.29
log
@Linux jiffies and OpenBSD ticks are the same thing.

ok jsg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.h,v 1.28 2015/06/24 08:32:39 kettenis Exp $	*/
d379 1
@


1.28
log
@Introduce Linux work queue APIs and use them.  As a side-effect, this will
move some of the work from the system task queue to the driver-specific
task queue.

ok jsg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.h,v 1.27 2015/04/18 14:47:34 jsg Exp $	*/
d377 2
@


1.27
log
@another round of reducing the diff to linux
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.h,v 1.26 2015/04/18 11:41:28 jsg Exp $	*/
d18 2
d284 85
d376 8
@


1.26
log
@define and use trace macros
discussed with kettenis
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.h,v 1.25 2015/04/18 11:05:32 jsg Exp $	*/
d45 2
d91 8
d101 1
d235 1
d294 2
d403 6
d555 1
d619 7
@


1.25
log
@add and use module param macros
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.h,v 1.24 2015/04/12 17:10:07 kettenis Exp $	*/
d178 11
@


1.24
log
@Add a few missing trace functions, and "use" them.  Add back the WATCH_GTT
code (that isn't actually compiled in).  Use dev_priv->dev in one more place
now that we have it, and add set_normalized_timespec() and use it.
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.h,v 1.23 2015/04/12 12:14:30 jsg Exp $	*/
d63 1
d65 3
@


1.23
log
@change back to linux style pci vendor/device defines
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.h,v 1.22 2015/04/12 05:31:23 jsg Exp $	*/
d267 12
@


1.22
log
@Switch back to ioread32 and iowrite32 for cases where bus_space_vaddr is
used instead of bus_space_read/bus_space_write.
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.h,v 1.21 2015/04/12 03:54:10 jsg Exp $	*/
d475 11
@


1.21
log
@make wait_queue_head a struct with a mutex
better matches linux behaviour
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.h,v 1.20 2015/04/11 14:39:37 jsg Exp $	*/
d479 14
@


1.20
log
@rename i915 interrupt handlers from *_intr back to *_irq_handler
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.h,v 1.19 2015/04/11 05:10:13 jsg Exp $	*/
a36 1
typedef int wait_queue_head_t;
d239 11
@


1.19
log
@change back to spinlock_t/DEFINE_SPINLOCK
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.h,v 1.18 2015/04/11 02:59:05 jsg Exp $	*/
d18 1
@


1.18
log
@add/use max_t()
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.h,v 1.17 2015/04/10 12:06:52 jsg Exp $	*/
d210 1
@


1.17
log
@Move irqs_disabled() and in_dbg_master() out of the i386/amd64 ifdef block
and change drm_can_sleep() to only use in_atomic() on i386/amd64 as
it isn't defined for other archs currently.  Unbreaks the sparc64 build.
Found the hard way by benoit@@
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.h,v 1.16 2015/04/10 05:31:25 jsg Exp $	*/
d338 5
@


1.16
log
@add irqs_disabled() and in_dbg_master() using cold and db_is_active
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.h,v 1.15 2015/04/08 04:03:06 jsg Exp $	*/
d516 15
a559 15
}

static inline int
irqs_disabled(void)
{
	return (cold);
}

static inline int
in_dbg_master(void)
{
#ifdef DDB
	return (db_is_active);
#endif
	return (0);
@


1.15
log
@change back to memcpy_toio/memcpy_fromio/memset_io
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.h,v 1.14 2015/04/08 02:28:13 jsg Exp $	*/
d545 15
@


1.14
log
@ttm has it's own version of kmap/kunmap that uses
kernel_map/uvm_km_valloc and i915 has a version that uses
phys_map/uvm_km_valloc_wait as calling code assumes kmap would
sleep if no memory is available.

Move these and ttm's vmap/vunmap into the linux compat files
and make them all use phys_map/uvm_km_valloc_wait.

looks good kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.h,v 1.13 2015/04/06 15:43:15 jsg Exp $	*/
d459 3
a461 1
#define memcpy_toio(d, s, n) memcpy(d, s, n)
@


1.13
log
@Move almost all of the linux compat from drmP.h to drm_linux.h.
The exception being the barrier defines that are implemented in terms of
DRM_* defines.

ok kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.h,v 1.12 2015/04/06 12:25:10 jsg Exp $	*/
d464 9
@


1.12
log
@move some inline linux compat into the dedicated files
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.h,v 1.11 2015/04/06 08:14:00 kettenis Exp $	*/
d21 13
d41 30
d125 84
d251 5
d283 62
d451 8
d461 1
a461 1
#define page_to_phys(page)	(VM_PAGE_TO_PHYS(page)
d467 46
@


1.11
log
@Add get_user() and put_user() compatibility interfaces and use them.

ok jsg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.h,v 1.10 2015/04/06 05:35:29 jsg Exp $	*/
d116 1
d118 1
d121 2
d151 6
d187 78
@


1.10
log
@add and use macros for wake_up/wake_up_all/wake_up_all_locked
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.h,v 1.9 2015/04/05 11:53:53 kettenis Exp $	*/
d174 3
@


1.9
log
@Another round of reducing diffs with Linux.  This one moves the various
copy_to_user and copy_from_user functions into drm_linux.h and uses them
instead of copyin/copyout and DRM_COPY_*.  Also move the timespec functions,
and put i915_gem_object_is_purgable() where it belongs.

Uncovered a bug where the arguments to copyout() were in the wrong order.

ok jsg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.h,v 1.8 2015/04/03 13:10:59 jsg Exp $	*/
d112 3
@


1.8
log
@resync i915_drv.h to make it diffable to linux
ok kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.h,v 1.7 2015/02/12 11:11:45 jsg Exp $	*/
d112 60
d217 34
@


1.7
log
@switch back to IRQ_NONE/IRQ_HANDLED
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.h,v 1.6 2015/02/12 06:30:56 jsg Exp $	*/
d21 4
d26 3
d81 2
@


1.6
log
@switch MUTEX_ASSERT_LOCKED calls back to assert_spin_locked
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.h,v 1.5 2015/02/12 02:12:02 kettenis Exp $	*/
d17 3
@


1.5
log
@Add mutex_is_locked and use it wherever linux uses it.
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.h,v 1.4 2015/02/11 07:01:36 jsg Exp $	*/
d86 1
@


1.4
log
@Switch most printf style functions calls back to linux function names
and move DRM_INFO/pr_info/dev_info messages under DRMDEBUG.
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.h,v 1.3 2015/02/10 00:23:53 jsg Exp $	*/
d89 1
@


1.3
log
@add definitions for linux style locks
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.h,v 1.2 2014/09/20 21:17:43 kettenis Exp $	*/
d19 52
@


1.2
log
@Make another fast path properly atomic.
@
text
@d1 1
a1 1
/*	$OpenBSD: drm_linux.h,v 1.1 2014/04/01 20:16:50 kettenis Exp $	*/
d19 26
@


1.1
log
@Move some duplicated code implementing Linux compatibility APIs and stick it
in a seperate header file.  This will become a dumping ground for similar code.

ok jsg@@
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d17 2
@

