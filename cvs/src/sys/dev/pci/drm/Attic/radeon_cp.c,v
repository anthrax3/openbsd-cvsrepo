head	1.50;
access;
symbols
	OPENBSD_5_4:1.49.0.4
	OPENBSD_5_4_BASE:1.49
	OPENBSD_5_3:1.49.0.2
	OPENBSD_5_3_BASE:1.49
	OPENBSD_5_2:1.48.0.6
	OPENBSD_5_2_BASE:1.48
	OPENBSD_5_1_BASE:1.48
	OPENBSD_5_1:1.48.0.4
	OPENBSD_5_0:1.48.0.2
	OPENBSD_5_0_BASE:1.48
	OPENBSD_4_9:1.46.0.4
	OPENBSD_4_9_BASE:1.46
	OPENBSD_4_8:1.46.0.2
	OPENBSD_4_8_BASE:1.46
	OPENBSD_4_7:1.43.0.2
	OPENBSD_4_7_BASE:1.43
	OPENBSD_4_6:1.43.0.4
	OPENBSD_4_6_BASE:1.43
	OPENBSD_4_5:1.30.0.2
	OPENBSD_4_5_BASE:1.30
	OPENBSD_4_4:1.6.0.2
	OPENBSD_4_4_BASE:1.6
	OPENBSD_4_3:1.1.0.2
	OPENBSD_4_3_BASE:1.1;
locks; strict;
comment	@ * @;


1.50
date	2013.08.12.04.11.52;	author jsg;	state dead;
branches;
next	1.49;

1.49
date	2012.12.06.15.05.21;	author mpi;	state Exp;
branches;
next	1.48;

1.48
date	2011.06.02.18.22.00;	author weerd;	state Exp;
branches;
next	1.47;

1.47
date	2011.05.30.21.50.46;	author oga;	state Exp;
branches;
next	1.46;

1.46
date	2010.03.29.00.56.00;	author oga;	state Exp;
branches;
next	1.45;

1.45
date	2010.03.28.13.23.13;	author oga;	state Exp;
branches;
next	1.44;

1.44
date	2010.03.27.00.09.50;	author oga;	state Exp;
branches;
next	1.43;

1.43
date	2009.06.07.02.04.34;	author chl;	state Exp;
branches;
next	1.42;

1.42
date	2009.05.11.00.06.39;	author oga;	state Exp;
branches;
next	1.41;

1.41
date	2009.04.06.04.21.59;	author oga;	state Exp;
branches;
next	1.40;

1.40
date	2009.04.03.15.22.31;	author oga;	state Exp;
branches;
next	1.39;

1.39
date	2009.04.03.14.41.23;	author oga;	state Exp;
branches;
next	1.38;

1.38
date	2009.04.02.20.32.34;	author oga;	state Exp;
branches;
next	1.37;

1.37
date	2009.03.31.20.05.06;	author oga;	state Exp;
branches;
next	1.36;

1.36
date	2009.03.27.19.36.55;	author oga;	state Exp;
branches;
next	1.35;

1.35
date	2009.03.05.23.08.23;	author oga;	state Exp;
branches;
next	1.34;

1.34
date	2009.03.05.23.00.46;	author oga;	state Exp;
branches;
next	1.33;

1.33
date	2009.03.05.22.57.19;	author oga;	state Exp;
branches;
next	1.32;

1.32
date	2009.03.05.22.51.32;	author oga;	state Exp;
branches;
next	1.31;

1.31
date	2009.03.01.23.54.17;	author oga;	state Exp;
branches;
next	1.30;

1.30
date	2009.02.16.00.01.25;	author oga;	state Exp;
branches;
next	1.29;

1.29
date	2009.02.15.23.10.48;	author oga;	state Exp;
branches;
next	1.28;

1.28
date	2009.02.15.22.53.45;	author oga;	state Exp;
branches;
next	1.27;

1.27
date	2009.02.15.22.42.20;	author oga;	state Exp;
branches;
next	1.26;

1.26
date	2009.02.15.20.18.59;	author oga;	state Exp;
branches;
next	1.25;

1.25
date	2009.02.15.20.03.19;	author oga;	state Exp;
branches;
next	1.24;

1.24
date	2009.02.12.23.07.23;	author jsg;	state Exp;
branches;
next	1.23;

1.23
date	2009.02.09.10.52.44;	author oga;	state Exp;
branches;
next	1.22;

1.22
date	2008.12.11.17.20.19;	author oga;	state Exp;
branches;
next	1.21;

1.21
date	2008.11.26.00.11.39;	author oga;	state Exp;
branches;
next	1.20;

1.20
date	2008.11.24.23.00.33;	author oga;	state Exp;
branches;
next	1.19;

1.19
date	2008.11.24.17.48.22;	author oga;	state Exp;
branches;
next	1.18;

1.18
date	2008.11.24.16.56.25;	author oga;	state Exp;
branches;
next	1.17;

1.17
date	2008.11.24.05.51.23;	author oga;	state Exp;
branches;
next	1.16;

1.16
date	2008.11.24.03.37.56;	author oga;	state Exp;
branches;
next	1.15;

1.15
date	2008.11.22.22.43.53;	author oga;	state Exp;
branches;
next	1.14;

1.14
date	2008.11.22.20.49.36;	author oga;	state Exp;
branches;
next	1.13;

1.13
date	2008.11.22.14.42.36;	author oga;	state Exp;
branches;
next	1.12;

1.12
date	2008.11.18.15.58.01;	author oga;	state Exp;
branches;
next	1.11;

1.11
date	2008.11.10.17.35.05;	author oga;	state Exp;
branches;
next	1.10;

1.10
date	2008.11.10.16.55.47;	author oga;	state Exp;
branches;
next	1.9;

1.9
date	2008.10.07.22.25.12;	author oga;	state Exp;
branches;
next	1.8;

1.8
date	2008.09.18.15.10.57;	author oga;	state Exp;
branches;
next	1.7;

1.7
date	2008.09.01.17.40.26;	author oga;	state Exp;
branches;
next	1.6;

1.6
date	2008.07.29.22.23.51;	author oga;	state Exp;
branches;
next	1.5;

1.5
date	2008.07.29.19.44.13;	author oga;	state Exp;
branches;
next	1.4;

1.4
date	2008.07.15.16.57.48;	author oga;	state Exp;
branches;
next	1.3;

1.3
date	2008.07.03.18.25.14;	author oga;	state Exp;
branches;
next	1.2;

1.2
date	2008.06.11.09.33.01;	author oga;	state Exp;
branches;
next	1.1;

1.1
date	2007.11.28.23.37.34;	author oga;	state Exp;
branches;
next	;


desc
@@


1.50
log
@Add a port of the TTM and Radeon DRM code from Linux 3.8.13.
Includes kernel modesetting, framebuffer console and support
for newer hardware.

Firmware needs to be present for acceleration and in some cases
modesetting to work.  It can be installed via fw_update
or manually via pkg_add.

With lots of help from kettenis@@ some macppc bits from mpi@@
and some ttm refcount/queue bits from FreeBSD.

Thanks to M:Tier and the OpenBSD Foundation for sponsoring this work.
@
text
@/* $OpenBSD: radeon_cp.c,v 1.49 2012/12/06 15:05:21 mpi Exp $ */
/* radeon_cp.c -- CP support for Radeon -*- linux-c -*- */
/*
 * Copyright 2000 Precision Insight, Inc., Cedar Park, Texas.
 * Copyright 2000 VA Linux Systems, Inc., Fremont, California.
 * Copyright 2007-2009 Advanced Micro Devices, Inc.
 * Copyright 2008 Red Hat Inc.
 * All Rights Reserved.
 *
 * Permission is hereby granted, free of charge, to any person obtaining a
 * copy of this software and associated documentation files (the "Software"),
 * to deal in the Software without restriction, including without limitation
 * the rights to use, copy, modify, merge, publish, distribute, sublicense,
 * and/or sell copies of the Software, and to permit persons to whom the
 * Software is furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice (including the next
 * paragraph) shall be included in all copies or substantial portions of the
 * Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
 * PRECISION INSIGHT AND/OR ITS SUPPLIERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
 * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
 * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
 * DEALINGS IN THE SOFTWARE.
 *
 * Authors:
 *    Kevin E. Martin <martin@@valinux.com>
 *    Gareth Hughes <gareth@@valinux.com>
 *    Dave Airlie <airlied@@redhat.com>
 *    Alex Deucher <alexander.deucher@@amd.com>
 */

#include "drmP.h"
#include "drm.h"
#include "radeon_drm.h"
#include "radeon_drv.h"
#include "r300_reg.h"

#include "radeon_microcode.h"
#include "r600_microcode.h"
#define RADEON_FIFO_DEBUG	0

int	radeon_do_cleanup_cp(struct drm_device *);
void	radeon_do_cp_start(drm_radeon_private_t *);
void	radeon_do_cp_reset(drm_radeon_private_t *);
void	radeon_do_cp_stop(drm_radeon_private_t *);
int	radeon_do_engine_reset(struct drm_device *);
void	radeon_cp_init_ring_buffer(struct drm_device *, drm_radeon_private_t *);
int	radeon_do_init_cp(struct drm_device *, drm_radeon_init_t *);
void	radeon_cp_load_microcode(drm_radeon_private_t *);
int	radeon_cp_get_buffers(struct drm_device *dev, struct drm_file *,
	    struct drm_dma *);

void	r600gart_add_entry(struct drm_ati_pcigart_info *, bus_size_t,
	    bus_addr_t);

u32	R500_READ_MCIND(drm_radeon_private_t *, int );
u32	RS480_READ_MCIND(drm_radeon_private_t *, int);
u32	RS690_READ_MCIND(drm_radeon_private_t *, int);
u32	RS600_READ_MCIND(drm_radeon_private_t *, int);
u32	IGP_READ_MCIND(drm_radeon_private_t *, int);
int	RADEON_READ_PLL(struct drm_device * , int);
u32	RADEON_READ_PCIE(drm_radeon_private_t *, int);

int	radeon_do_pixcache_flush(drm_radeon_private_t *);
int	radeon_do_wait_for_fifo(drm_radeon_private_t *, int);
int	radeon_do_wait_for_idle(drm_radeon_private_t *);
int	r600_do_wait_for_fifo(drm_radeon_private_t *, int);
int	r600_do_wait_for_idle(drm_radeon_private_t *);
void	radeon_init_pipes(drm_radeon_private_t *);
void	radeon_test_writeback(drm_radeon_private_t *);
void	radeon_set_igpgart(drm_radeon_private_t *, int);
void	rs600_set_igpgart(drm_radeon_private_t *, int);
void	radeon_set_pciegart(drm_radeon_private_t *, int);
void	radeon_set_pcigart(drm_radeon_private_t *, int);
int	radeondrm_setup_pcigart(struct drm_radeon_private *);
int	radeon_setup_pcigart_surface(drm_radeon_private_t *dev_priv);

# define ATI_PCIGART_PAGE_SIZE		4096	/**< PCI GART page size */
# define ATI_PCIGART_PAGE_MASK		(~(ATI_PCIGART_PAGE_SIZE-1))

#define R600_PTE_VALID     (1 << 0)
#define R600_PTE_SYSTEM    (1 << 1)
#define R600_PTE_SNOOPED   (1 << 2)
#define R600_PTE_READABLE  (1 << 5)
#define R600_PTE_WRITEABLE (1 << 6)

/* MAX values used for gfx init */
#define R6XX_MAX_SH_GPRS           256
#define R6XX_MAX_TEMP_GPRS         16
#define R6XX_MAX_SH_THREADS        256
#define R6XX_MAX_SH_STACK_ENTRIES  4096
#define R6XX_MAX_BACKENDS          8
#define R6XX_MAX_BACKENDS_MASK     0xff
#define R6XX_MAX_SIMDS             8
#define R6XX_MAX_SIMDS_MASK        0xff
#define R6XX_MAX_PIPES             8
#define R6XX_MAX_PIPES_MASK        0xff

#define R7XX_MAX_SH_GPRS           256
#define R7XX_MAX_TEMP_GPRS         16
#define R7XX_MAX_SH_THREADS        256
#define R7XX_MAX_SH_STACK_ENTRIES  4096
#define R7XX_MAX_BACKENDS          8
#define R7XX_MAX_BACKENDS_MASK     0xff
#define R7XX_MAX_SIMDS             16
#define R7XX_MAX_SIMDS_MASK        0xffff
#define R7XX_MAX_PIPES             8
#define R7XX_MAX_PIPES_MASK        0xff


u32
RADEON_READ_MM(drm_radeon_private_t *dev_priv, int addr)
{
	u32 ret;

	if (addr < 0x10000)
		ret = bus_space_read_4(dev_priv->regs->bst,
		    dev_priv->regs->bsh, addr);
	else {
		bus_space_write_4(dev_priv->regs->bst, dev_priv->regs->bsh,
		    RADEON_MM_INDEX, addr);
		ret = bus_space_read_4(dev_priv->regs->bst,
		    dev_priv->regs->bsh, RADEON_MM_DATA);
	}

	return ret;
}

u32
R500_READ_MCIND(drm_radeon_private_t *dev_priv, int addr)
{
	u32 ret;
	RADEON_WRITE(R520_MC_IND_INDEX, 0x7f0000 | (addr & 0xff));
	ret = RADEON_READ(R520_MC_IND_DATA);
	RADEON_WRITE(R520_MC_IND_INDEX, 0);
	return ret;
}

u32
RS480_READ_MCIND(drm_radeon_private_t *dev_priv, int addr)
{
	u32 ret;
	RADEON_WRITE(RS480_NB_MC_INDEX, addr & 0xff);
	ret = RADEON_READ(RS480_NB_MC_DATA);
	RADEON_WRITE(RS480_NB_MC_INDEX, 0xff);
	return ret;
}

u32
RS690_READ_MCIND(drm_radeon_private_t *dev_priv, int addr)
{
	u32 ret;
	RADEON_WRITE(RS690_MC_INDEX, (addr & RS690_MC_INDEX_MASK));
	ret = RADEON_READ(RS690_MC_DATA);
	RADEON_WRITE(RS690_MC_INDEX, RS690_MC_INDEX_MASK);
	return ret;
}

u32
RS600_READ_MCIND(drm_radeon_private_t *dev_priv, int addr)
{
	u32 ret;
	RADEON_WRITE(RS600_MC_INDEX, ((addr & RS600_MC_ADDR_MASK) |
				      RS600_MC_IND_CITF_ARB0));
	ret = RADEON_READ(RS600_MC_DATA);
	return ret;
}
u32
IGP_READ_MCIND(drm_radeon_private_t *dev_priv, int addr)
{
	if (((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RS690) ||
	    ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RS740))
		return RS690_READ_MCIND(dev_priv, addr);
	else if ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RS600)
		return RS600_READ_MCIND(dev_priv, addr);
	else
		return RS480_READ_MCIND(dev_priv, addr);
}

u32
radeon_read_fb_location(drm_radeon_private_t *dev_priv)
{

	if ((dev_priv->flags & RADEON_FAMILY_MASK) >= CHIP_RV770)
		return RADEON_READ(R700_MC_VM_FB_LOCATION);
	else if ((dev_priv->flags & RADEON_FAMILY_MASK) >= CHIP_R600)
		return RADEON_READ(R600_MC_VM_FB_LOCATION);
	else if ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RV515)
		return R500_READ_MCIND(dev_priv, RV515_MC_FB_LOCATION);
	else if (((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RS690) ||
		((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RS740))
		return RS690_READ_MCIND(dev_priv, RS690_MC_FB_LOCATION);
	else if ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RS600)
		return RS600_READ_MCIND(dev_priv, RS600_MC_FB_LOCATION);
	else if ((dev_priv->flags & RADEON_FAMILY_MASK) > CHIP_RV515)
		return R500_READ_MCIND(dev_priv, R520_MC_FB_LOCATION);
	else
		return RADEON_READ(RADEON_MC_FB_LOCATION);
}

void
radeon_write_fb_location(drm_radeon_private_t *dev_priv, u32 fb_loc)
{
	if ((dev_priv->flags & RADEON_FAMILY_MASK) >= CHIP_RV770)
		RADEON_WRITE(R700_MC_VM_FB_LOCATION, fb_loc);
	else if ((dev_priv->flags & RADEON_FAMILY_MASK) >= CHIP_R600)
		RADEON_WRITE(R600_MC_VM_FB_LOCATION, fb_loc);
	else if ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RV515)
		R500_WRITE_MCIND(RV515_MC_FB_LOCATION, fb_loc);
	else if (((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RS690) ||
		 ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RS740))
		RS690_WRITE_MCIND(RS690_MC_FB_LOCATION, fb_loc);
	else if ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RS600)
		RS600_WRITE_MCIND(RS600_MC_FB_LOCATION, fb_loc);
	else if ((dev_priv->flags & RADEON_FAMILY_MASK) > CHIP_RV515)
		R500_WRITE_MCIND(R520_MC_FB_LOCATION, fb_loc);
	else
		RADEON_WRITE(RADEON_MC_FB_LOCATION, fb_loc);
}

void
radeon_write_agp_location(drm_radeon_private_t *dev_priv, u32 agp_loc)
{
	/*R6xx/R7xx: AGP_TOP and BOT are actually 18 bits each */
	if ((dev_priv->flags & RADEON_FAMILY_MASK) >= CHIP_RV770) {
		RADEON_WRITE(R700_MC_VM_AGP_BOT, agp_loc & 0xffff); /* FIX ME */
		RADEON_WRITE(R700_MC_VM_AGP_TOP, (agp_loc >> 16) & 0xffff);
	} else if ((dev_priv->flags & RADEON_FAMILY_MASK) >= CHIP_R600) {
		RADEON_WRITE(R600_MC_VM_AGP_BOT, agp_loc & 0xffff); /* FIX ME */
		RADEON_WRITE(R600_MC_VM_AGP_TOP, (agp_loc >> 16) & 0xffff);
	} else if ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RV515)
		R500_WRITE_MCIND(RV515_MC_AGP_LOCATION, agp_loc);
	else if (((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RS690) ||
		 ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RS740))
		RS690_WRITE_MCIND(RS690_MC_AGP_LOCATION, agp_loc);
	else if ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RS600)
		RS600_WRITE_MCIND(RS600_MC_AGP_LOCATION, agp_loc);
	else if ((dev_priv->flags & RADEON_FAMILY_MASK) > CHIP_RV515)
		R500_WRITE_MCIND(R520_MC_AGP_LOCATION, agp_loc);
	else
		RADEON_WRITE(RADEON_MC_AGP_LOCATION, agp_loc);
}

void
radeon_write_agp_base(drm_radeon_private_t *dev_priv, u64 agp_base)
{
	u32 agp_base_hi = upper_32_bits(agp_base);
	u32 agp_base_lo = agp_base & 0xffffffff;
	u32 r6xx_agp_base = (agp_base >> 22) & 0x3ffff;

	/* R6xx/R7xx must be aligned to a 4MB boundry */
	if ((dev_priv->flags & RADEON_FAMILY_MASK) >= CHIP_RV770)
		RADEON_WRITE(R700_MC_VM_AGP_BASE, r6xx_agp_base);
	else if ((dev_priv->flags & RADEON_FAMILY_MASK) >= CHIP_R600)
		RADEON_WRITE(R600_MC_VM_AGP_BASE, r6xx_agp_base);
	else if ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RV515) {
		R500_WRITE_MCIND(RV515_MC_AGP_BASE, agp_base_lo);
		R500_WRITE_MCIND(RV515_MC_AGP_BASE_2, agp_base_hi);
	} else if (((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RS690) ||
		 ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RS740)) {
		RS690_WRITE_MCIND(RS690_MC_AGP_BASE, agp_base_lo);
		RS690_WRITE_MCIND(RS690_MC_AGP_BASE_2, agp_base_hi);
	} else if ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RS600) {
		RS600_WRITE_MCIND(RS600_AGP_BASE, agp_base_lo);
		RS600_WRITE_MCIND(RS600_AGP_BASE_2, agp_base_hi);
	} else if ((dev_priv->flags & RADEON_FAMILY_MASK) > CHIP_RV515) {
		R500_WRITE_MCIND(R520_MC_AGP_BASE, agp_base_lo);
		R500_WRITE_MCIND(R520_MC_AGP_BASE_2, agp_base_hi);
	} else if (((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RS400) ||
		   ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RS480)) {
		RADEON_WRITE(RADEON_AGP_BASE, agp_base_lo);
		RADEON_WRITE(RS480_AGP_BASE_2, agp_base_hi);
	} else {
		RADEON_WRITE(RADEON_AGP_BASE, agp_base_lo);
		if ((dev_priv->flags & RADEON_FAMILY_MASK) >= CHIP_R200)
			RADEON_WRITE(RADEON_AGP_BASE_2, agp_base_hi);
	}
}

void
radeon_enable_bm(struct drm_radeon_private *dev_priv)
{
	u32 tmp;
	/* Turn on bus mastering */
	if (((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RS690) ||
	    ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RS740)) {
		/* rs600/rs690/rs740 */
		tmp = RADEON_READ(RADEON_BUS_CNTL) & ~RS600_BUS_MASTER_DIS;
		RADEON_WRITE(RADEON_BUS_CNTL, tmp);
	} else if (((dev_priv->flags & RADEON_FAMILY_MASK) <= CHIP_RV350) ||
		   ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_R420) ||
		   ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RS400) ||
		   ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RS480)) {
		/* r1xx, r2xx, r300, r(v)350, r420/r481, rs400/rs480 */
		tmp = RADEON_READ(RADEON_BUS_CNTL) & ~RADEON_BUS_MASTER_DIS;
		RADEON_WRITE(RADEON_BUS_CNTL, tmp);
	} /* PCIE cards appears to not need this */
}

int
RADEON_READ_PLL(struct drm_device *dev, int addr)
{
	drm_radeon_private_t *dev_priv = dev->dev_private;

	RADEON_WRITE8(RADEON_CLOCK_CNTL_INDEX, addr & 0x1f);
	return RADEON_READ(RADEON_CLOCK_CNTL_DATA);
}

u32
RADEON_READ_PCIE(drm_radeon_private_t *dev_priv, int addr)
{
	RADEON_WRITE8(RADEON_PCIE_INDEX, addr & 0xff);
	return RADEON_READ(RADEON_PCIE_DATA);
}

/*
 * Some R600/R700 setup functions.
 */
static u32 r600_get_tile_pipe_to_backend_map(u32 num_tile_pipes,
					     u32 num_backends,
					     u32 backend_disable_mask)
{
	u32 backend_map = 0;
	u32 enabled_backends_mask;
	u32 enabled_backends_count;
	u32 cur_pipe;
	u32 swizzle_pipe[R6XX_MAX_PIPES];
	u32 cur_backend;
	u32 i;

	if (num_tile_pipes > R6XX_MAX_PIPES)
		num_tile_pipes = R6XX_MAX_PIPES;
	if (num_tile_pipes < 1)
		num_tile_pipes = 1;
	if (num_backends > R6XX_MAX_BACKENDS)
		num_backends = R6XX_MAX_BACKENDS;
	if (num_backends < 1)
		num_backends = 1;

	enabled_backends_mask = 0;
	enabled_backends_count = 0;
	for (i = 0; i < R6XX_MAX_BACKENDS; ++i) {
		if (((backend_disable_mask >> i) & 1) == 0) {
			enabled_backends_mask |= (1 << i);
			++enabled_backends_count;
		}
		if (enabled_backends_count == num_backends)
			break;
	}

	if (enabled_backends_count == 0) {
		enabled_backends_mask = 1;
		enabled_backends_count = 1;
	}

	if (enabled_backends_count != num_backends)
		num_backends = enabled_backends_count;

	memset((uint8_t *)&swizzle_pipe[0], 0, sizeof(u32) * R6XX_MAX_PIPES);
	switch (num_tile_pipes) {
	case 1:
		swizzle_pipe[0] = 0;
		break;
	case 2:
		swizzle_pipe[0] = 0;
		swizzle_pipe[1] = 1;
		break;
	case 3:
		swizzle_pipe[0] = 0;
		swizzle_pipe[1] = 1;
		swizzle_pipe[2] = 2;
		break;
	case 4:
		swizzle_pipe[0] = 0;
		swizzle_pipe[1] = 1;
		swizzle_pipe[2] = 2;
		swizzle_pipe[3] = 3;
		break;
	case 5:
		swizzle_pipe[0] = 0;
		swizzle_pipe[1] = 1;
		swizzle_pipe[2] = 2;
		swizzle_pipe[3] = 3;
		swizzle_pipe[4] = 4;
		break;
	case 6:
		swizzle_pipe[0] = 0;
		swizzle_pipe[1] = 2;
		swizzle_pipe[2] = 4;
		swizzle_pipe[3] = 5;
		swizzle_pipe[4] = 1;
		swizzle_pipe[5] = 3;
		break;
	case 7:
		swizzle_pipe[0] = 0;
		swizzle_pipe[1] = 2;
		swizzle_pipe[2] = 4;
		swizzle_pipe[3] = 6;
		swizzle_pipe[4] = 1;
		swizzle_pipe[5] = 3;
		swizzle_pipe[6] = 5;
		break;
	case 8:
		swizzle_pipe[0] = 0;
		swizzle_pipe[1] = 2;
		swizzle_pipe[2] = 4;
		swizzle_pipe[3] = 6;
		swizzle_pipe[4] = 1;
		swizzle_pipe[5] = 3;
		swizzle_pipe[6] = 5;
		swizzle_pipe[7] = 7;
		break;
	}

	cur_backend = 0;
	for (cur_pipe = 0; cur_pipe < num_tile_pipes; ++cur_pipe) {
		while (((1 << cur_backend) & enabled_backends_mask) == 0)
			cur_backend = (cur_backend + 1) % R6XX_MAX_BACKENDS;

		backend_map |= (u32)(((cur_backend & 3) << (swizzle_pipe[cur_pipe] * 2)));

		cur_backend = (cur_backend + 1) % R6XX_MAX_BACKENDS;
	}

	return backend_map;
}

static int r600_count_pipe_bits(uint32_t val)
{
	int i, ret = 0;
	for (i = 0; i < 32; i++) {
		ret += val & 1;
		val >>= 1;
	}
	return ret;
}

static void r600_gfx_init(struct drm_device *dev,
			  drm_radeon_private_t *dev_priv)
{
	int i, j, num_qd_pipes;
	u32 sx_debug_1;
	u32 tc_cntl;
	u32 arb_pop;
	u32 num_gs_verts_per_thread;
	u32 vgt_gs_per_es;
	u32 gs_prim_buffer_depth = 0;
	u32 sq_ms_fifo_sizes;
	u32 sq_config;
	u32 sq_gpr_resource_mgmt_1 = 0;
	u32 sq_gpr_resource_mgmt_2 = 0;
	u32 sq_thread_resource_mgmt = 0;
	u32 sq_stack_resource_mgmt_1 = 0;
	u32 sq_stack_resource_mgmt_2 = 0;
	u32 hdp_host_path_cntl;
	u32 backend_map;
	u32 gb_tiling_config = 0;
	u32 cc_rb_backend_disable = 0;
	u32 cc_gc_shader_pipe_config = 0;
	u32 ramcfg;

	/* setup chip specs */
	switch (dev_priv->flags & RADEON_FAMILY_MASK) {
	case CHIP_R600:
		dev_priv->r600_max_pipes = 4;
		dev_priv->r600_max_tile_pipes = 8;
		dev_priv->r600_max_simds = 4;
		dev_priv->r600_max_backends = 4;
		dev_priv->r600_max_gprs = 256;
		dev_priv->r600_max_threads = 192;
		dev_priv->r600_max_stack_entries = 256;
		dev_priv->r600_max_hw_contexts = 8;
		dev_priv->r600_max_gs_threads = 16;
		dev_priv->r600_sx_max_export_size = 128;
		dev_priv->r600_sx_max_export_pos_size = 16;
		dev_priv->r600_sx_max_export_smx_size = 128;
		dev_priv->r600_sq_num_cf_insts = 2;
		break;
	case CHIP_RV630:
	case CHIP_RV635:
		dev_priv->r600_max_pipes = 2;
		dev_priv->r600_max_tile_pipes = 2;
		dev_priv->r600_max_simds = 3;
		dev_priv->r600_max_backends = 1;
		dev_priv->r600_max_gprs = 128;
		dev_priv->r600_max_threads = 192;
		dev_priv->r600_max_stack_entries = 128;
		dev_priv->r600_max_hw_contexts = 8;
		dev_priv->r600_max_gs_threads = 4;
		dev_priv->r600_sx_max_export_size = 128;
		dev_priv->r600_sx_max_export_pos_size = 16;
		dev_priv->r600_sx_max_export_smx_size = 128;
		dev_priv->r600_sq_num_cf_insts = 2;
		break;
	case CHIP_RV610:
	case CHIP_RS780:
	case CHIP_RS880:
	case CHIP_RV620:
		dev_priv->r600_max_pipes = 1;
		dev_priv->r600_max_tile_pipes = 1;
		dev_priv->r600_max_simds = 2;
		dev_priv->r600_max_backends = 1;
		dev_priv->r600_max_gprs = 128;
		dev_priv->r600_max_threads = 192;
		dev_priv->r600_max_stack_entries = 128;
		dev_priv->r600_max_hw_contexts = 4;
		dev_priv->r600_max_gs_threads = 4;
		dev_priv->r600_sx_max_export_size = 128;
		dev_priv->r600_sx_max_export_pos_size = 16;
		dev_priv->r600_sx_max_export_smx_size = 128;
		dev_priv->r600_sq_num_cf_insts = 1;
		break;
	case CHIP_RV670:
		dev_priv->r600_max_pipes = 4;
		dev_priv->r600_max_tile_pipes = 4;
		dev_priv->r600_max_simds = 4;
		dev_priv->r600_max_backends = 4;
		dev_priv->r600_max_gprs = 192;
		dev_priv->r600_max_threads = 192;
		dev_priv->r600_max_stack_entries = 256;
		dev_priv->r600_max_hw_contexts = 8;
		dev_priv->r600_max_gs_threads = 16;
		dev_priv->r600_sx_max_export_size = 128;
		dev_priv->r600_sx_max_export_pos_size = 16;
		dev_priv->r600_sx_max_export_smx_size = 128;
		dev_priv->r600_sq_num_cf_insts = 2;
		break;
	default:
		break;
	}

	/* Initialize HDP */
	j = 0;
	for (i = 0; i < 32; i++) {
		RADEON_WRITE((0x2c14 + j), 0x00000000);
		RADEON_WRITE((0x2c18 + j), 0x00000000);
		RADEON_WRITE((0x2c1c + j), 0x00000000);
		RADEON_WRITE((0x2c20 + j), 0x00000000);
		RADEON_WRITE((0x2c24 + j), 0x00000000);
		j += 0x18;
	}

	RADEON_WRITE(R600_GRBM_CNTL, R600_GRBM_READ_TIMEOUT(0xff));

	/* setup tiling, simd, pipe config */
	ramcfg = RADEON_READ(R600_RAMCFG);

	switch (dev_priv->r600_max_tile_pipes) {
	case 1:
		gb_tiling_config |= R600_PIPE_TILING(0);
		break;
	case 2:
		gb_tiling_config |= R600_PIPE_TILING(1);
		break;
	case 4:
		gb_tiling_config |= R600_PIPE_TILING(2);
		break;
	case 8:
		gb_tiling_config |= R600_PIPE_TILING(3);
		break;
	default:
		break;
	}

	gb_tiling_config |= R600_BANK_TILING((ramcfg >> R600_NOOFBANK_SHIFT) & R600_NOOFBANK_MASK);

	gb_tiling_config |= R600_GROUP_SIZE(0);

	if (((ramcfg >> R600_NOOFROWS_SHIFT) & R600_NOOFROWS_MASK) > 3) {
		gb_tiling_config |= R600_ROW_TILING(3);
		gb_tiling_config |= R600_SAMPLE_SPLIT(3);
	} else {
		gb_tiling_config |=
			R600_ROW_TILING(((ramcfg >> R600_NOOFROWS_SHIFT) & R600_NOOFROWS_MASK));
		gb_tiling_config |=
			R600_SAMPLE_SPLIT(((ramcfg >> R600_NOOFROWS_SHIFT) & R600_NOOFROWS_MASK));
	}

	gb_tiling_config |= R600_BANK_SWAPS(1);

	backend_map = r600_get_tile_pipe_to_backend_map(dev_priv->r600_max_tile_pipes,
							dev_priv->r600_max_backends,
							(0xff << dev_priv->r600_max_backends) & 0xff);
	gb_tiling_config |= R600_BACKEND_MAP(backend_map);

	cc_gc_shader_pipe_config =
		R600_INACTIVE_QD_PIPES((R6XX_MAX_PIPES_MASK << dev_priv->r600_max_pipes) & R6XX_MAX_PIPES_MASK);
	cc_gc_shader_pipe_config |=
		R600_INACTIVE_SIMDS((R6XX_MAX_SIMDS_MASK << dev_priv->r600_max_simds) & R6XX_MAX_SIMDS_MASK);

	cc_rb_backend_disable =
		R600_BACKEND_DISABLE((R6XX_MAX_BACKENDS_MASK << dev_priv->r600_max_backends) & R6XX_MAX_BACKENDS_MASK);

	RADEON_WRITE(R600_GB_TILING_CONFIG,      gb_tiling_config);
	RADEON_WRITE(R600_DCP_TILING_CONFIG,    (gb_tiling_config & 0xffff));
	RADEON_WRITE(R600_HDP_TILING_CONFIG,    (gb_tiling_config & 0xffff));

	RADEON_WRITE(R600_CC_RB_BACKEND_DISABLE,      cc_rb_backend_disable);
	RADEON_WRITE(R600_CC_GC_SHADER_PIPE_CONFIG,   cc_gc_shader_pipe_config);
	RADEON_WRITE(R600_GC_USER_SHADER_PIPE_CONFIG, cc_gc_shader_pipe_config);

	num_qd_pipes =
		R6XX_MAX_BACKENDS - r600_count_pipe_bits(cc_gc_shader_pipe_config & R600_INACTIVE_QD_PIPES_MASK);
	RADEON_WRITE(R600_VGT_OUT_DEALLOC_CNTL, (num_qd_pipes * 4) & R600_DEALLOC_DIST_MASK);
	RADEON_WRITE(R600_VGT_VERTEX_REUSE_BLOCK_CNTL, ((num_qd_pipes * 4) - 2) & R600_VTX_REUSE_DEPTH_MASK);

	/* set HW defaults for 3D engine */
	RADEON_WRITE(R600_CP_QUEUE_THRESHOLDS, (R600_ROQ_IB1_START(0x16) |
						R600_ROQ_IB2_START(0x2b)));

	RADEON_WRITE(R600_CP_MEQ_THRESHOLDS, (R600_MEQ_END(0x40) |
					      R600_ROQ_END(0x40)));

	RADEON_WRITE(R600_TA_CNTL_AUX, (R600_DISABLE_CUBE_ANISO |
					R600_SYNC_GRADIENT |
					R600_SYNC_WALKER |
					R600_SYNC_ALIGNER));

	if ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RV670)
		RADEON_WRITE(R600_ARB_GDEC_RD_CNTL, 0x00000021);

	sx_debug_1 = RADEON_READ(R600_SX_DEBUG_1);
	sx_debug_1 |= R600_SMX_EVENT_RELEASE;
	if (((dev_priv->flags & RADEON_FAMILY_MASK) > CHIP_R600))
		sx_debug_1 |= R600_ENABLE_NEW_SMX_ADDRESS;
	RADEON_WRITE(R600_SX_DEBUG_1, sx_debug_1);

	if (((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_R600) ||
	    ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RV630) ||
	    ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RV610) ||
	    ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RV620) ||
	    ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RS780) ||
	    ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RS880))
		RADEON_WRITE(R600_DB_DEBUG, R600_PREZ_MUST_WAIT_FOR_POSTZ_DONE);
	else
		RADEON_WRITE(R600_DB_DEBUG, 0);

	RADEON_WRITE(R600_DB_WATERMARKS, (R600_DEPTH_FREE(4) |
					  R600_DEPTH_FLUSH(16) |
					  R600_DEPTH_PENDING_FREE(4) |
					  R600_DEPTH_CACHELINE_FREE(16)));
	RADEON_WRITE(R600_PA_SC_MULTI_CHIP_CNTL, 0);
	RADEON_WRITE(R600_VGT_NUM_INSTANCES, 0);

	RADEON_WRITE(R600_SPI_CONFIG_CNTL, R600_GPR_WRITE_PRIORITY(0));
	RADEON_WRITE(R600_SPI_CONFIG_CNTL_1, R600_VTX_DONE_DELAY(0));

	sq_ms_fifo_sizes = RADEON_READ(R600_SQ_MS_FIFO_SIZES);
	if (((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RV610) ||
	    ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RV620) ||
	    ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RS780) ||
	    ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RS880)) {
		sq_ms_fifo_sizes = (R600_CACHE_FIFO_SIZE(0xa) |
				    R600_FETCH_FIFO_HIWATER(0xa) |
				    R600_DONE_FIFO_HIWATER(0xe0) |
				    R600_ALU_UPDATE_FIFO_HIWATER(0x8));
	} else if (((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_R600) ||
		   ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RV630)) {
		sq_ms_fifo_sizes &= ~R600_DONE_FIFO_HIWATER(0xff);
		sq_ms_fifo_sizes |= R600_DONE_FIFO_HIWATER(0x4);
	}
	RADEON_WRITE(R600_SQ_MS_FIFO_SIZES, sq_ms_fifo_sizes);

	/* SQ_CONFIG, SQ_GPR_RESOURCE_MGMT, SQ_THREAD_RESOURCE_MGMT, SQ_STACK_RESOURCE_MGMT
	 * should be adjusted as needed by the 2D/3D drivers.  This just sets default values
	 */
	sq_config = RADEON_READ(R600_SQ_CONFIG);
	sq_config &= ~(R600_PS_PRIO(3) |
		       R600_VS_PRIO(3) |
		       R600_GS_PRIO(3) |
		       R600_ES_PRIO(3));
	sq_config |= (R600_DX9_CONSTS |
		      R600_VC_ENABLE |
		      R600_PS_PRIO(0) |
		      R600_VS_PRIO(1) |
		      R600_GS_PRIO(2) |
		      R600_ES_PRIO(3));

	if ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_R600) {
		sq_gpr_resource_mgmt_1 = (R600_NUM_PS_GPRS(124) |
					  R600_NUM_VS_GPRS(124) |
					  R600_NUM_CLAUSE_TEMP_GPRS(4));
		sq_gpr_resource_mgmt_2 = (R600_NUM_GS_GPRS(0) |
					  R600_NUM_ES_GPRS(0));
		sq_thread_resource_mgmt = (R600_NUM_PS_THREADS(136) |
					   R600_NUM_VS_THREADS(48) |
					   R600_NUM_GS_THREADS(4) |
					   R600_NUM_ES_THREADS(4));
		sq_stack_resource_mgmt_1 = (R600_NUM_PS_STACK_ENTRIES(128) |
					    R600_NUM_VS_STACK_ENTRIES(128));
		sq_stack_resource_mgmt_2 = (R600_NUM_GS_STACK_ENTRIES(0) |
					    R600_NUM_ES_STACK_ENTRIES(0));
	} else if (((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RV610) ||
		   ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RV620) ||
		   ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RS780) ||
		   ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RS880)) {
		/* no vertex cache */
		sq_config &= ~R600_VC_ENABLE;

		sq_gpr_resource_mgmt_1 = (R600_NUM_PS_GPRS(44) |
					  R600_NUM_VS_GPRS(44) |
					  R600_NUM_CLAUSE_TEMP_GPRS(2));
		sq_gpr_resource_mgmt_2 = (R600_NUM_GS_GPRS(17) |
					  R600_NUM_ES_GPRS(17));
		sq_thread_resource_mgmt = (R600_NUM_PS_THREADS(79) |
					   R600_NUM_VS_THREADS(78) |
					   R600_NUM_GS_THREADS(4) |
					   R600_NUM_ES_THREADS(31));
		sq_stack_resource_mgmt_1 = (R600_NUM_PS_STACK_ENTRIES(40) |
					    R600_NUM_VS_STACK_ENTRIES(40));
		sq_stack_resource_mgmt_2 = (R600_NUM_GS_STACK_ENTRIES(32) |
					    R600_NUM_ES_STACK_ENTRIES(16));
	} else if (((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RV630) ||
		   ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RV635)) {
		sq_gpr_resource_mgmt_1 = (R600_NUM_PS_GPRS(44) |
					  R600_NUM_VS_GPRS(44) |
					  R600_NUM_CLAUSE_TEMP_GPRS(2));
		sq_gpr_resource_mgmt_2 = (R600_NUM_GS_GPRS(18) |
					  R600_NUM_ES_GPRS(18));
		sq_thread_resource_mgmt = (R600_NUM_PS_THREADS(79) |
					   R600_NUM_VS_THREADS(78) |
					   R600_NUM_GS_THREADS(4) |
					   R600_NUM_ES_THREADS(31));
		sq_stack_resource_mgmt_1 = (R600_NUM_PS_STACK_ENTRIES(40) |
					    R600_NUM_VS_STACK_ENTRIES(40));
		sq_stack_resource_mgmt_2 = (R600_NUM_GS_STACK_ENTRIES(32) |
					    R600_NUM_ES_STACK_ENTRIES(16));
	} else if ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RV670) {
		sq_gpr_resource_mgmt_1 = (R600_NUM_PS_GPRS(44) |
					  R600_NUM_VS_GPRS(44) |
					  R600_NUM_CLAUSE_TEMP_GPRS(2));
		sq_gpr_resource_mgmt_2 = (R600_NUM_GS_GPRS(17) |
					  R600_NUM_ES_GPRS(17));
		sq_thread_resource_mgmt = (R600_NUM_PS_THREADS(79) |
					   R600_NUM_VS_THREADS(78) |
					   R600_NUM_GS_THREADS(4) |
					   R600_NUM_ES_THREADS(31));
		sq_stack_resource_mgmt_1 = (R600_NUM_PS_STACK_ENTRIES(64) |
					    R600_NUM_VS_STACK_ENTRIES(64));
		sq_stack_resource_mgmt_2 = (R600_NUM_GS_STACK_ENTRIES(64) |
					    R600_NUM_ES_STACK_ENTRIES(64));
	}

	RADEON_WRITE(R600_SQ_CONFIG, sq_config);
	RADEON_WRITE(R600_SQ_GPR_RESOURCE_MGMT_1,  sq_gpr_resource_mgmt_1);
	RADEON_WRITE(R600_SQ_GPR_RESOURCE_MGMT_2,  sq_gpr_resource_mgmt_2);
	RADEON_WRITE(R600_SQ_THREAD_RESOURCE_MGMT, sq_thread_resource_mgmt);
	RADEON_WRITE(R600_SQ_STACK_RESOURCE_MGMT_1, sq_stack_resource_mgmt_1);
	RADEON_WRITE(R600_SQ_STACK_RESOURCE_MGMT_2, sq_stack_resource_mgmt_2);

	if (((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RV610) ||
	    ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RV620) ||
	    ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RS780) ||
	    ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RS880))
		RADEON_WRITE(R600_VGT_CACHE_INVALIDATION, R600_CACHE_INVALIDATION(R600_TC_ONLY));
	else
		RADEON_WRITE(R600_VGT_CACHE_INVALIDATION, R600_CACHE_INVALIDATION(R600_VC_AND_TC));

	RADEON_WRITE(R600_PA_SC_AA_SAMPLE_LOCS_2S, (R600_S0_X(0xc) |
						    R600_S0_Y(0x4) |
						    R600_S1_X(0x4) |
						    R600_S1_Y(0xc)));
	RADEON_WRITE(R600_PA_SC_AA_SAMPLE_LOCS_4S, (R600_S0_X(0xe) |
						    R600_S0_Y(0xe) |
						    R600_S1_X(0x2) |
						    R600_S1_Y(0x2) |
						    R600_S2_X(0xa) |
						    R600_S2_Y(0x6) |
						    R600_S3_X(0x6) |
						    R600_S3_Y(0xa)));
	RADEON_WRITE(R600_PA_SC_AA_SAMPLE_LOCS_8S_WD0, (R600_S0_X(0xe) |
							R600_S0_Y(0xb) |
							R600_S1_X(0x4) |
							R600_S1_Y(0xc) |
							R600_S2_X(0x1) |
							R600_S2_Y(0x6) |
							R600_S3_X(0xa) |
							R600_S3_Y(0xe)));
	RADEON_WRITE(R600_PA_SC_AA_SAMPLE_LOCS_8S_WD1, (R600_S4_X(0x6) |
							R600_S4_Y(0x1) |
							R600_S5_X(0x0) |
							R600_S5_Y(0x0) |
							R600_S6_X(0xb) |
							R600_S6_Y(0x4) |
							R600_S7_X(0x7) |
							R600_S7_Y(0x8)));


	switch (dev_priv->flags & RADEON_FAMILY_MASK) {
	case CHIP_R600:
	case CHIP_RV630:
	case CHIP_RV635:
		gs_prim_buffer_depth = 0;
		break;
	case CHIP_RV610:
	case CHIP_RS780:
	case CHIP_RS880:
	case CHIP_RV620:
		gs_prim_buffer_depth = 32;
		break;
	case CHIP_RV670:
		gs_prim_buffer_depth = 128;
		break;
	default:
		break;
	}

	num_gs_verts_per_thread = dev_priv->r600_max_pipes * 16;
	vgt_gs_per_es = gs_prim_buffer_depth + num_gs_verts_per_thread;
	/* Max value for this is 256 */
	if (vgt_gs_per_es > 256)
		vgt_gs_per_es = 256;

	RADEON_WRITE(R600_VGT_ES_PER_GS, 128);
	RADEON_WRITE(R600_VGT_GS_PER_ES, vgt_gs_per_es);
	RADEON_WRITE(R600_VGT_GS_PER_VS, 2);
	RADEON_WRITE(R600_VGT_GS_VERTEX_REUSE, 16);

	/* more default values. 2D/3D driver should adjust as needed */
	RADEON_WRITE(R600_PA_SC_LINE_STIPPLE_STATE, 0);
	RADEON_WRITE(R600_VGT_STRMOUT_EN, 0);
	RADEON_WRITE(R600_SX_MISC, 0);
	RADEON_WRITE(R600_PA_SC_MODE_CNTL, 0);
	RADEON_WRITE(R600_PA_SC_AA_CONFIG, 0);
	RADEON_WRITE(R600_PA_SC_LINE_STIPPLE, 0);
	RADEON_WRITE(R600_SPI_INPUT_Z, 0);
	RADEON_WRITE(R600_SPI_PS_IN_CONTROL_0, R600_NUM_INTERP(2));
	RADEON_WRITE(R600_CB_COLOR7_FRAG, 0);

	/* clear render buffer base addresses */
	RADEON_WRITE(R600_CB_COLOR0_BASE, 0);
	RADEON_WRITE(R600_CB_COLOR1_BASE, 0);
	RADEON_WRITE(R600_CB_COLOR2_BASE, 0);
	RADEON_WRITE(R600_CB_COLOR3_BASE, 0);
	RADEON_WRITE(R600_CB_COLOR4_BASE, 0);
	RADEON_WRITE(R600_CB_COLOR5_BASE, 0);
	RADEON_WRITE(R600_CB_COLOR6_BASE, 0);
	RADEON_WRITE(R600_CB_COLOR7_BASE, 0);

	switch (dev_priv->flags & RADEON_FAMILY_MASK) {
	case CHIP_RV610:
	case CHIP_RS780:
	case CHIP_RS880:
	case CHIP_RV620:
		tc_cntl = R600_TC_L2_SIZE(8);
		break;
	case CHIP_RV630:
	case CHIP_RV635:
		tc_cntl = R600_TC_L2_SIZE(4);
		break;
	case CHIP_R600:
		tc_cntl = R600_TC_L2_SIZE(0) | R600_L2_DISABLE_LATE_HIT;
		break;
	default:
		tc_cntl = R600_TC_L2_SIZE(0);
		break;
	}

	RADEON_WRITE(R600_TC_CNTL, tc_cntl);

	hdp_host_path_cntl = RADEON_READ(R600_HDP_HOST_PATH_CNTL);
	RADEON_WRITE(R600_HDP_HOST_PATH_CNTL, hdp_host_path_cntl);

	arb_pop = RADEON_READ(R600_ARB_POP);
	arb_pop |= R600_ENABLE_TC128;
	RADEON_WRITE(R600_ARB_POP, arb_pop);

	RADEON_WRITE(R600_PA_SC_MULTI_CHIP_CNTL, 0);
	RADEON_WRITE(R600_PA_CL_ENHANCE, (R600_CLIP_VTX_REORDER_ENA |
					  R600_NUM_CLIP_SEQ(3)));
	RADEON_WRITE(R600_PA_SC_ENHANCE, R600_FORCE_EOV_MAX_CLK_CNT(4095));

}

static u32
r700_get_tile_pipe_to_backend_map(u32 num_tile_pipes, u32 num_backends,
    u32 backend_disable_mask)
{
	u32 backend_map = 0;
	u32 enabled_backends_mask;
	u32 enabled_backends_count;
	u32 cur_pipe;
	u32 swizzle_pipe[R7XX_MAX_PIPES];
	u32 cur_backend;
	u32 i;

	if (num_tile_pipes > R7XX_MAX_PIPES)
		num_tile_pipes = R7XX_MAX_PIPES;
	if (num_tile_pipes < 1)
		num_tile_pipes = 1;
	if (num_backends > R7XX_MAX_BACKENDS)
		num_backends = R7XX_MAX_BACKENDS;
	if (num_backends < 1)
		num_backends = 1;

	enabled_backends_mask = 0;
	enabled_backends_count = 0;
	for (i = 0; i < R7XX_MAX_BACKENDS; ++i) {
		if (((backend_disable_mask >> i) & 1) == 0) {
			enabled_backends_mask |= (1 << i);
			++enabled_backends_count;
		}
		if (enabled_backends_count == num_backends)
			break;
	}

	if (enabled_backends_count == 0) {
		enabled_backends_mask = 1;
		enabled_backends_count = 1;
	}

	if (enabled_backends_count != num_backends)
		num_backends = enabled_backends_count;

	memset((uint8_t *)&swizzle_pipe[0], 0, sizeof(u32) * R7XX_MAX_PIPES);
	switch (num_tile_pipes) {
	case 1:
		swizzle_pipe[0] = 0;
		break;
	case 2:
		swizzle_pipe[0] = 0;
		swizzle_pipe[1] = 1;
		break;
	case 3:
		swizzle_pipe[0] = 0;
		swizzle_pipe[1] = 2;
		swizzle_pipe[2] = 1;
		break;
	case 4:
		swizzle_pipe[0] = 0;
		swizzle_pipe[1] = 2;
		swizzle_pipe[2] = 3;
		swizzle_pipe[3] = 1;
		break;
	case 5:
		swizzle_pipe[0] = 0;
		swizzle_pipe[1] = 2;
		swizzle_pipe[2] = 4;
		swizzle_pipe[3] = 1;
		swizzle_pipe[4] = 3;
		break;
	case 6:
		swizzle_pipe[0] = 0;
		swizzle_pipe[1] = 2;
		swizzle_pipe[2] = 4;
		swizzle_pipe[3] = 5;
		swizzle_pipe[4] = 3;
		swizzle_pipe[5] = 1;
		break;
	case 7:
		swizzle_pipe[0] = 0;
		swizzle_pipe[1] = 2;
		swizzle_pipe[2] = 4;
		swizzle_pipe[3] = 6;
		swizzle_pipe[4] = 3;
		swizzle_pipe[5] = 1;
		swizzle_pipe[6] = 5;
		break;
	case 8:
		swizzle_pipe[0] = 0;
		swizzle_pipe[1] = 2;
		swizzle_pipe[2] = 4;
		swizzle_pipe[3] = 6;
		swizzle_pipe[4] = 3;
		swizzle_pipe[5] = 1;
		swizzle_pipe[6] = 7;
		swizzle_pipe[7] = 5;
		break;
	}

	cur_backend = 0;
	for (cur_pipe = 0; cur_pipe < num_tile_pipes; ++cur_pipe) {
		while (((1 << cur_backend) & enabled_backends_mask) == 0)
			cur_backend = (cur_backend + 1) % R7XX_MAX_BACKENDS;

		backend_map |= (u32)(((cur_backend & 3) << (swizzle_pipe[cur_pipe] * 2)));

		cur_backend = (cur_backend + 1) % R7XX_MAX_BACKENDS;
	}

	return backend_map;
}

static void r700_gfx_init(struct drm_device *dev,
			  drm_radeon_private_t *dev_priv)
{
	int i, j, num_qd_pipes;
	u32 sx_debug_1;
	u32 smx_dc_ctl0;
	u32 num_gs_verts_per_thread;
	u32 vgt_gs_per_es;
	u32 gs_prim_buffer_depth = 0;
	u32 sq_ms_fifo_sizes;
	u32 sq_config;
	u32 sq_thread_resource_mgmt;
	u32 hdp_host_path_cntl;
	u32 sq_dyn_gpr_size_simd_ab_0;
	u32 backend_map;
	u32 gb_tiling_config = 0;
	u32 cc_rb_backend_disable = 0;
	u32 cc_gc_shader_pipe_config = 0;
	u32 mc_arb_ramcfg;
	u32 db_debug4;

	/* setup chip specs */
	switch (dev_priv->flags & RADEON_FAMILY_MASK) {
	case CHIP_RV770:
		dev_priv->r600_max_pipes = 4;
		dev_priv->r600_max_tile_pipes = 8;
		dev_priv->r600_max_simds = 10;
		dev_priv->r600_max_backends = 4;
		dev_priv->r600_max_gprs = 256;
		dev_priv->r600_max_threads = 248;
		dev_priv->r600_max_stack_entries = 512;
		dev_priv->r600_max_hw_contexts = 8;
		dev_priv->r600_max_gs_threads = 16 * 2;
		dev_priv->r600_sx_max_export_size = 128;
		dev_priv->r600_sx_max_export_pos_size = 16;
		dev_priv->r600_sx_max_export_smx_size = 112;
		dev_priv->r600_sq_num_cf_insts = 2;

		dev_priv->r700_sx_num_of_sets = 7;
		dev_priv->r700_sc_prim_fifo_size = 0xF9;
		dev_priv->r700_sc_hiz_tile_fifo_size = 0x30;
		dev_priv->r700_sc_earlyz_tile_fifo_fize = 0x130;
		break;
	case CHIP_RV730:
		dev_priv->r600_max_pipes = 2;
		dev_priv->r600_max_tile_pipes = 4;
		dev_priv->r600_max_simds = 8;
		dev_priv->r600_max_backends = 2;
		dev_priv->r600_max_gprs = 128;
		dev_priv->r600_max_threads = 248;
		dev_priv->r600_max_stack_entries = 256;
		dev_priv->r600_max_hw_contexts = 8;
		dev_priv->r600_max_gs_threads = 16 * 2;
		dev_priv->r600_sx_max_export_size = 256;
		dev_priv->r600_sx_max_export_pos_size = 32;
		dev_priv->r600_sx_max_export_smx_size = 224;
		dev_priv->r600_sq_num_cf_insts = 2;

		dev_priv->r700_sx_num_of_sets = 7;
		dev_priv->r700_sc_prim_fifo_size = 0xf9;
		dev_priv->r700_sc_hiz_tile_fifo_size = 0x30;
		dev_priv->r700_sc_earlyz_tile_fifo_fize = 0x130;
		if (dev_priv->r600_sx_max_export_pos_size > 16) {
			dev_priv->r600_sx_max_export_pos_size -= 16;
			dev_priv->r600_sx_max_export_smx_size += 16;
		}
		break;
	case CHIP_RV710:
		dev_priv->r600_max_pipes = 2;
		dev_priv->r600_max_tile_pipes = 2;
		dev_priv->r600_max_simds = 2;
		dev_priv->r600_max_backends = 1;
		dev_priv->r600_max_gprs = 256;
		dev_priv->r600_max_threads = 192;
		dev_priv->r600_max_stack_entries = 256;
		dev_priv->r600_max_hw_contexts = 4;
		dev_priv->r600_max_gs_threads = 8 * 2;
		dev_priv->r600_sx_max_export_size = 128;
		dev_priv->r600_sx_max_export_pos_size = 16;
		dev_priv->r600_sx_max_export_smx_size = 112;
		dev_priv->r600_sq_num_cf_insts = 1;

		dev_priv->r700_sx_num_of_sets = 7;
		dev_priv->r700_sc_prim_fifo_size = 0x40;
		dev_priv->r700_sc_hiz_tile_fifo_size = 0x30;
		dev_priv->r700_sc_earlyz_tile_fifo_fize = 0x130;
		break;
	case CHIP_RV740:
		dev_priv->r600_max_pipes = 4;
		dev_priv->r600_max_tile_pipes = 4;
		dev_priv->r600_max_simds = 8;
		dev_priv->r600_max_backends = 4;
		dev_priv->r600_max_gprs = 256;
		dev_priv->r600_max_threads = 248;
		dev_priv->r600_max_stack_entries = 512;
		dev_priv->r600_max_hw_contexts = 8;
		dev_priv->r600_max_gs_threads = 16 * 2;
		dev_priv->r600_sx_max_export_size = 256;
		dev_priv->r600_sx_max_export_pos_size = 32;
		dev_priv->r600_sx_max_export_smx_size = 224;
		dev_priv->r600_sq_num_cf_insts = 2;

		dev_priv->r700_sx_num_of_sets = 7;
		dev_priv->r700_sc_prim_fifo_size = 0x100;
		dev_priv->r700_sc_hiz_tile_fifo_size = 0x30;
		dev_priv->r700_sc_earlyz_tile_fifo_fize = 0x130;

		if (dev_priv->r600_sx_max_export_pos_size > 16) {
			dev_priv->r600_sx_max_export_pos_size -= 16;
			dev_priv->r600_sx_max_export_smx_size += 16;
		}
		break;
	default:
		break;
	}

	/* Initialize HDP */
	j = 0;
	for (i = 0; i < 32; i++) {
		RADEON_WRITE((0x2c14 + j), 0x00000000);
		RADEON_WRITE((0x2c18 + j), 0x00000000);
		RADEON_WRITE((0x2c1c + j), 0x00000000);
		RADEON_WRITE((0x2c20 + j), 0x00000000);
		RADEON_WRITE((0x2c24 + j), 0x00000000);
		j += 0x18;
	}

	RADEON_WRITE(R600_GRBM_CNTL, R600_GRBM_READ_TIMEOUT(0xff));

	/* setup tiling, simd, pipe config */
	mc_arb_ramcfg = RADEON_READ(R700_MC_ARB_RAMCFG);

	switch (dev_priv->r600_max_tile_pipes) {
	case 1:
		gb_tiling_config |= R600_PIPE_TILING(0);
		break;
	case 2:
		gb_tiling_config |= R600_PIPE_TILING(1);
		break;
	case 4:
		gb_tiling_config |= R600_PIPE_TILING(2);
		break;
	case 8:
		gb_tiling_config |= R600_PIPE_TILING(3);
		break;
	default:
		break;
	}

	if ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RV770)
		gb_tiling_config |= R600_BANK_TILING(1);
	else
		gb_tiling_config |= R600_BANK_TILING((mc_arb_ramcfg >> R700_NOOFBANK_SHIFT) & R700_NOOFBANK_MASK);

	gb_tiling_config |= R600_GROUP_SIZE(0);

	if (((mc_arb_ramcfg >> R700_NOOFROWS_SHIFT) & R700_NOOFROWS_MASK) > 3) {
		gb_tiling_config |= R600_ROW_TILING(3);
		gb_tiling_config |= R600_SAMPLE_SPLIT(3);
	} else {
		gb_tiling_config |=
			R600_ROW_TILING(((mc_arb_ramcfg >> R700_NOOFROWS_SHIFT) & R700_NOOFROWS_MASK));
		gb_tiling_config |=
			R600_SAMPLE_SPLIT(((mc_arb_ramcfg >> R700_NOOFROWS_SHIFT) & R700_NOOFROWS_MASK));
	}

	gb_tiling_config |= R600_BANK_SWAPS(1);

	backend_map = r700_get_tile_pipe_to_backend_map(dev_priv->r600_max_tile_pipes,
							dev_priv->r600_max_backends,
							(0xff << dev_priv->r600_max_backends) & 0xff);
	gb_tiling_config |= R600_BACKEND_MAP(backend_map);

	cc_gc_shader_pipe_config =
		R600_INACTIVE_QD_PIPES((R7XX_MAX_PIPES_MASK << dev_priv->r600_max_pipes) & R7XX_MAX_PIPES_MASK);
	cc_gc_shader_pipe_config |=
		R600_INACTIVE_SIMDS((R7XX_MAX_SIMDS_MASK << dev_priv->r600_max_simds) & R7XX_MAX_SIMDS_MASK);

	cc_rb_backend_disable =
		R600_BACKEND_DISABLE((R7XX_MAX_BACKENDS_MASK << dev_priv->r600_max_backends) & R7XX_MAX_BACKENDS_MASK);

	RADEON_WRITE(R600_GB_TILING_CONFIG,      gb_tiling_config);
	RADEON_WRITE(R600_DCP_TILING_CONFIG,    (gb_tiling_config & 0xffff));
	RADEON_WRITE(R600_HDP_TILING_CONFIG,    (gb_tiling_config & 0xffff));

	RADEON_WRITE(R600_CC_RB_BACKEND_DISABLE,      cc_rb_backend_disable);
	RADEON_WRITE(R600_CC_GC_SHADER_PIPE_CONFIG,   cc_gc_shader_pipe_config);
	RADEON_WRITE(R600_GC_USER_SHADER_PIPE_CONFIG, cc_gc_shader_pipe_config);

	RADEON_WRITE(R700_CC_SYS_RB_BACKEND_DISABLE, cc_rb_backend_disable);
	RADEON_WRITE(R700_CGTS_SYS_TCC_DISABLE, 0);
	RADEON_WRITE(R700_CGTS_TCC_DISABLE, 0);
	RADEON_WRITE(R700_CGTS_USER_SYS_TCC_DISABLE, 0);
	RADEON_WRITE(R700_CGTS_USER_TCC_DISABLE, 0);

	num_qd_pipes =
		R7XX_MAX_BACKENDS - r600_count_pipe_bits(cc_gc_shader_pipe_config & R600_INACTIVE_QD_PIPES_MASK);
	RADEON_WRITE(R600_VGT_OUT_DEALLOC_CNTL, (num_qd_pipes * 4) & R600_DEALLOC_DIST_MASK);
	RADEON_WRITE(R600_VGT_VERTEX_REUSE_BLOCK_CNTL, ((num_qd_pipes * 4) - 2) & R600_VTX_REUSE_DEPTH_MASK);

	/* set HW defaults for 3D engine */
	RADEON_WRITE(R600_CP_QUEUE_THRESHOLDS, (R600_ROQ_IB1_START(0x16) |
						R600_ROQ_IB2_START(0x2b)));

	RADEON_WRITE(R600_CP_MEQ_THRESHOLDS, R700_STQ_SPLIT(0x30));

	RADEON_WRITE(R600_TA_CNTL_AUX, (R600_DISABLE_CUBE_ANISO |
					R600_SYNC_GRADIENT |
					R600_SYNC_WALKER |
					R600_SYNC_ALIGNER));

	sx_debug_1 = RADEON_READ(R700_SX_DEBUG_1);
	sx_debug_1 |= R700_ENABLE_NEW_SMX_ADDRESS;
	RADEON_WRITE(R700_SX_DEBUG_1, sx_debug_1);

	smx_dc_ctl0 = RADEON_READ(R600_SMX_DC_CTL0);
	smx_dc_ctl0 &= ~R700_CACHE_DEPTH(0x1ff);
	smx_dc_ctl0 |= R700_CACHE_DEPTH((dev_priv->r700_sx_num_of_sets * 64) - 1);
	RADEON_WRITE(R600_SMX_DC_CTL0, smx_dc_ctl0);

	RADEON_WRITE(R700_SMX_EVENT_CTL, (R700_ES_FLUSH_CTL(4) |
					  R700_GS_FLUSH_CTL(4) |
					  R700_ACK_FLUSH_CTL(3) |
					  R700_SYNC_FLUSH_CTL));

	if ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RV770)
		RADEON_WRITE(R700_DB_DEBUG3, R700_DB_CLK_OFF_DELAY(0x1f));
	else {
		db_debug4 = RADEON_READ(RV700_DB_DEBUG4);
		db_debug4 |= RV700_DISABLE_TILE_COVERED_FOR_PS_ITER;
		RADEON_WRITE(RV700_DB_DEBUG4, db_debug4);
	}

	RADEON_WRITE(R600_SX_EXPORT_BUFFER_SIZES, (R600_COLOR_BUFFER_SIZE((dev_priv->r600_sx_max_export_size / 4) - 1) |
						   R600_POSITION_BUFFER_SIZE((dev_priv->r600_sx_max_export_pos_size / 4) - 1) |
						   R600_SMX_BUFFER_SIZE((dev_priv->r600_sx_max_export_smx_size / 4) - 1)));

	RADEON_WRITE(R700_PA_SC_FIFO_SIZE_R7XX, (R700_SC_PRIM_FIFO_SIZE(dev_priv->r700_sc_prim_fifo_size) |
						 R700_SC_HIZ_TILE_FIFO_SIZE(dev_priv->r700_sc_hiz_tile_fifo_size) |
						 R700_SC_EARLYZ_TILE_FIFO_SIZE(dev_priv->r700_sc_earlyz_tile_fifo_fize)));

	RADEON_WRITE(R600_PA_SC_MULTI_CHIP_CNTL, 0);

	RADEON_WRITE(R600_VGT_NUM_INSTANCES, 1);

	RADEON_WRITE(R600_SPI_CONFIG_CNTL, R600_GPR_WRITE_PRIORITY(0));

	RADEON_WRITE(R600_SPI_CONFIG_CNTL_1, R600_VTX_DONE_DELAY(4));

	RADEON_WRITE(R600_CP_PERFMON_CNTL, 0);

	sq_ms_fifo_sizes = (R600_CACHE_FIFO_SIZE(16 * dev_priv->r600_sq_num_cf_insts) |
			    R600_DONE_FIFO_HIWATER(0xe0) |
			    R600_ALU_UPDATE_FIFO_HIWATER(0x8));
	switch (dev_priv->flags & RADEON_FAMILY_MASK) {
	case CHIP_RV770:
		sq_ms_fifo_sizes |= R600_FETCH_FIFO_HIWATER(0x1);
		break;
	case CHIP_RV730:
	case CHIP_RV710:
	case CHIP_RV740:
	default:
		sq_ms_fifo_sizes |= R600_FETCH_FIFO_HIWATER(0x4);
		break;
	}
	RADEON_WRITE(R600_SQ_MS_FIFO_SIZES, sq_ms_fifo_sizes);

	/* SQ_CONFIG, SQ_GPR_RESOURCE_MGMT, SQ_THREAD_RESOURCE_MGMT, SQ_STACK_RESOURCE_MGMT
	 * should be adjusted as needed by the 2D/3D drivers.  This just sets default values
	 */
	sq_config = RADEON_READ(R600_SQ_CONFIG);
	sq_config &= ~(R600_PS_PRIO(3) |
		       R600_VS_PRIO(3) |
		       R600_GS_PRIO(3) |
		       R600_ES_PRIO(3));
	sq_config |= (R600_DX9_CONSTS |
		      R600_VC_ENABLE |
		      R600_EXPORT_SRC_C |
		      R600_PS_PRIO(0) |
		      R600_VS_PRIO(1) |
		      R600_GS_PRIO(2) |
		      R600_ES_PRIO(3));
	if ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RV710)
		/* no vertex cache */
		sq_config &= ~R600_VC_ENABLE;

	RADEON_WRITE(R600_SQ_CONFIG, sq_config);

	RADEON_WRITE(R600_SQ_GPR_RESOURCE_MGMT_1,  (R600_NUM_PS_GPRS((dev_priv->r600_max_gprs * 24)/64) |
						    R600_NUM_VS_GPRS((dev_priv->r600_max_gprs * 24)/64) |
						    R600_NUM_CLAUSE_TEMP_GPRS(((dev_priv->r600_max_gprs * 24)/64)/2)));

	RADEON_WRITE(R600_SQ_GPR_RESOURCE_MGMT_2,  (R600_NUM_GS_GPRS((dev_priv->r600_max_gprs * 7)/64) |
						    R600_NUM_ES_GPRS((dev_priv->r600_max_gprs * 7)/64)));

	sq_thread_resource_mgmt = (R600_NUM_PS_THREADS((dev_priv->r600_max_threads * 4)/8) |
				   R600_NUM_VS_THREADS((dev_priv->r600_max_threads * 2)/8) |
				   R600_NUM_ES_THREADS((dev_priv->r600_max_threads * 1)/8));
	if (((dev_priv->r600_max_threads * 1) / 8) > dev_priv->r600_max_gs_threads)
		sq_thread_resource_mgmt |= R600_NUM_GS_THREADS(dev_priv->r600_max_gs_threads);
	else
		sq_thread_resource_mgmt |= R600_NUM_GS_THREADS((dev_priv->r600_max_gs_threads * 1)/8);
	RADEON_WRITE(R600_SQ_THREAD_RESOURCE_MGMT, sq_thread_resource_mgmt);

	RADEON_WRITE(R600_SQ_STACK_RESOURCE_MGMT_1, (R600_NUM_PS_STACK_ENTRIES((dev_priv->r600_max_stack_entries * 1)/4) |
						     R600_NUM_VS_STACK_ENTRIES((dev_priv->r600_max_stack_entries * 1)/4)));

	RADEON_WRITE(R600_SQ_STACK_RESOURCE_MGMT_2, (R600_NUM_GS_STACK_ENTRIES((dev_priv->r600_max_stack_entries * 1)/4) |
						     R600_NUM_ES_STACK_ENTRIES((dev_priv->r600_max_stack_entries * 1)/4)));

	sq_dyn_gpr_size_simd_ab_0 = (R700_SIMDA_RING0((dev_priv->r600_max_gprs * 38)/64) |
				     R700_SIMDA_RING1((dev_priv->r600_max_gprs * 38)/64) |
				     R700_SIMDB_RING0((dev_priv->r600_max_gprs * 38)/64) |
				     R700_SIMDB_RING1((dev_priv->r600_max_gprs * 38)/64));

	RADEON_WRITE(R700_SQ_DYN_GPR_SIZE_SIMD_AB_0, sq_dyn_gpr_size_simd_ab_0);
	RADEON_WRITE(R700_SQ_DYN_GPR_SIZE_SIMD_AB_1, sq_dyn_gpr_size_simd_ab_0);
	RADEON_WRITE(R700_SQ_DYN_GPR_SIZE_SIMD_AB_2, sq_dyn_gpr_size_simd_ab_0);
	RADEON_WRITE(R700_SQ_DYN_GPR_SIZE_SIMD_AB_3, sq_dyn_gpr_size_simd_ab_0);
	RADEON_WRITE(R700_SQ_DYN_GPR_SIZE_SIMD_AB_4, sq_dyn_gpr_size_simd_ab_0);
	RADEON_WRITE(R700_SQ_DYN_GPR_SIZE_SIMD_AB_5, sq_dyn_gpr_size_simd_ab_0);
	RADEON_WRITE(R700_SQ_DYN_GPR_SIZE_SIMD_AB_6, sq_dyn_gpr_size_simd_ab_0);
	RADEON_WRITE(R700_SQ_DYN_GPR_SIZE_SIMD_AB_7, sq_dyn_gpr_size_simd_ab_0);

	RADEON_WRITE(R700_PA_SC_FORCE_EOV_MAX_CNTS, (R700_FORCE_EOV_MAX_CLK_CNT(4095) |
						     R700_FORCE_EOV_MAX_REZ_CNT(255)));

	if ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RV710)
		RADEON_WRITE(R600_VGT_CACHE_INVALIDATION, (R600_CACHE_INVALIDATION(R600_TC_ONLY) |
							   R700_AUTO_INVLD_EN(R700_ES_AND_GS_AUTO)));
	else
		RADEON_WRITE(R600_VGT_CACHE_INVALIDATION, (R600_CACHE_INVALIDATION(R600_VC_AND_TC) |
							   R700_AUTO_INVLD_EN(R700_ES_AND_GS_AUTO)));

	switch (dev_priv->flags & RADEON_FAMILY_MASK) {
	case CHIP_RV770:
	case CHIP_RV730:
	case CHIP_RV740:
		gs_prim_buffer_depth = 384;
		break;
	case CHIP_RV710:
		gs_prim_buffer_depth = 128;
		break;
	default:
		break;
	}

	num_gs_verts_per_thread = dev_priv->r600_max_pipes * 16;
	vgt_gs_per_es = gs_prim_buffer_depth + num_gs_verts_per_thread;
	/* Max value for this is 256 */
	if (vgt_gs_per_es > 256)
		vgt_gs_per_es = 256;

	RADEON_WRITE(R600_VGT_ES_PER_GS, 128);
	RADEON_WRITE(R600_VGT_GS_PER_ES, vgt_gs_per_es);
	RADEON_WRITE(R600_VGT_GS_PER_VS, 2);

	/* more default values. 2D/3D driver should adjust as needed */
	RADEON_WRITE(R600_VGT_GS_VERTEX_REUSE, 16);
	RADEON_WRITE(R600_PA_SC_LINE_STIPPLE_STATE, 0);
	RADEON_WRITE(R600_VGT_STRMOUT_EN, 0);
	RADEON_WRITE(R600_SX_MISC, 0);
	RADEON_WRITE(R600_PA_SC_MODE_CNTL, 0);
	RADEON_WRITE(R700_PA_SC_EDGERULE, 0xaaaaaaaa);
	RADEON_WRITE(R600_PA_SC_AA_CONFIG, 0);
	RADEON_WRITE(R600_PA_SC_CLIPRECT_RULE, 0xffff);
	RADEON_WRITE(R600_PA_SC_LINE_STIPPLE, 0);
	RADEON_WRITE(R600_SPI_INPUT_Z, 0);
	RADEON_WRITE(R600_SPI_PS_IN_CONTROL_0, R600_NUM_INTERP(2));
	RADEON_WRITE(R600_CB_COLOR7_FRAG, 0);

	/* clear render buffer base addresses */
	RADEON_WRITE(R600_CB_COLOR0_BASE, 0);
	RADEON_WRITE(R600_CB_COLOR1_BASE, 0);
	RADEON_WRITE(R600_CB_COLOR2_BASE, 0);
	RADEON_WRITE(R600_CB_COLOR3_BASE, 0);
	RADEON_WRITE(R600_CB_COLOR4_BASE, 0);
	RADEON_WRITE(R600_CB_COLOR5_BASE, 0);
	RADEON_WRITE(R600_CB_COLOR6_BASE, 0);
	RADEON_WRITE(R600_CB_COLOR7_BASE, 0);

	RADEON_WRITE(R700_TCP_CNTL, 0);

	hdp_host_path_cntl = RADEON_READ(R600_HDP_HOST_PATH_CNTL);
	RADEON_WRITE(R600_HDP_HOST_PATH_CNTL, hdp_host_path_cntl);

	RADEON_WRITE(R600_PA_SC_MULTI_CHIP_CNTL, 0);

	RADEON_WRITE(R600_PA_CL_ENHANCE, (R600_CLIP_VTX_REORDER_ENA |
					  R600_NUM_CLIP_SEQ(3)));

}

#if RADEON_FIFO_DEBUG
static void
radeon_status(drm_radeon_private_t *dev_priv)
{
	printf("%s:\n", __FUNCTION__);
	printf("RBBM_STATUS = 0x%08x\n",
	       (unsigned int)RADEON_READ(RADEON_RBBM_STATUS));
	printf("CP_RB_RTPR = 0x%08x\n",
	       (unsigned int)RADEON_READ(RADEON_CP_RB_RPTR));
	printf("CP_RB_WTPR = 0x%08x\n",
	       (unsigned int)RADEON_READ(RADEON_CP_RB_WPTR));
	printf("AIC_CNTL = 0x%08x\n",
	       (unsigned int)RADEON_READ(RADEON_AIC_CNTL));
	printf("AIC_STAT = 0x%08x\n",
	       (unsigned int)RADEON_READ(RADEON_AIC_STAT));
	printf("AIC_PT_BASE = 0x%08x\n",
	       (unsigned int)RADEON_READ(RADEON_AIC_PT_BASE));
	printf("TLB_ADDR = 0x%08x\n",
	       (unsigned int)RADEON_READ(RADEON_AIC_TLB_ADDR));
	printf("TLB_DATA = 0x%08x\n",
	       (unsigned int)RADEON_READ(RADEON_AIC_TLB_DATA));
}
#endif

/* ================================================================
 * Engine, FIFO control
 */

int
radeon_do_pixcache_flush(drm_radeon_private_t *dev_priv)
{
	u32 tmp;
	int i;

	if ((dev_priv->flags & RADEON_FAMILY_MASK) <= CHIP_RV280) {
		tmp = RADEON_READ(RADEON_RB3D_DSTCACHE_CTLSTAT);
		tmp |= RADEON_RB3D_DC_FLUSH_ALL;
		RADEON_WRITE(RADEON_RB3D_DSTCACHE_CTLSTAT, tmp);

		for (i = 0; i < dev_priv->usec_timeout; i++) {
			if (!(RADEON_READ(RADEON_RB3D_DSTCACHE_CTLSTAT)
			      & RADEON_RB3D_DC_BUSY)) {
				return 0;
			}
			DRM_UDELAY(1);
		}
	} else {
		/* don't flush or purge cache here or lockup */
		return 0;
	}

#if RADEON_FIFO_DEBUG
	DRM_ERROR("failed!\n");
	radeon_status(dev_priv);
#endif
	return EBUSY;
}

int
radeon_do_wait_for_fifo(drm_radeon_private_t *dev_priv, int entries)
{
	int i;

	for (i = 0; i < dev_priv->usec_timeout; i++) {
		int slots = (RADEON_READ(RADEON_RBBM_STATUS)
			     & RADEON_RBBM_FIFOCNT_MASK);
		if (slots >= entries)
			return 0;
		DRM_UDELAY(1);
	}
	DRM_INFO("wait for fifo failed status : 0x%08X 0x%08X\n",
		 RADEON_READ(RADEON_RBBM_STATUS),
		 RADEON_READ(R300_VAP_CNTL_STATUS));

#if RADEON_FIFO_DEBUG
	DRM_ERROR("failed!\n");
	radeon_status(dev_priv);
#endif
	return EBUSY;
}

int
radeon_do_wait_for_idle(drm_radeon_private_t *dev_priv)
{
	int i, ret;

	if ((dev_priv->flags & RADEON_FAMILY_MASK) >= CHIP_R600)
		return (r600_do_wait_for_idle(dev_priv));

	ret = radeon_do_wait_for_fifo(dev_priv, 64);
	if (ret)
		return ret;

	for (i = 0; i < dev_priv->usec_timeout; i++) {
		if (!(RADEON_READ(RADEON_RBBM_STATUS)
		      & RADEON_RBBM_ACTIVE)) {
			radeon_do_pixcache_flush(dev_priv);
			return 0;
		}
		DRM_UDELAY(1);
	}
	DRM_INFO("wait idle failed status : 0x%08X 0x%08X\n",
		 RADEON_READ(RADEON_RBBM_STATUS),
		 RADEON_READ(R300_VAP_CNTL_STATUS));

#if RADEON_FIFO_DEBUG
	DRM_ERROR("failed!\n");
	radeon_status(dev_priv);
#endif
	return EBUSY;
}

int
r600_do_wait_for_fifo(drm_radeon_private_t *dev_priv, int entries)
{
	int i;

	for (i = 0; i < dev_priv->usec_timeout; i++) {
		int slots;
		if ((dev_priv->flags & RADEON_FAMILY_MASK) >= CHIP_RV770)
			slots = (RADEON_READ(R600_GRBM_STATUS)
				 & R700_CMDFIFO_AVAIL_MASK);
		else
			slots = (RADEON_READ(R600_GRBM_STATUS)
				 & R600_CMDFIFO_AVAIL_MASK);
		if (slots >= entries)
			return 0;
		DRM_UDELAY(1);
	}
	DRM_INFO("wait for fifo failed status : 0x%08X 0x%08X\n",
		 RADEON_READ(R600_GRBM_STATUS),
		 RADEON_READ(R600_GRBM_STATUS2));

	return -EBUSY;
}

int
r600_do_wait_for_idle(drm_radeon_private_t *dev_priv)
{
	int i, ret;

	if ((dev_priv->flags & RADEON_FAMILY_MASK) >= CHIP_RV770)
		ret = r600_do_wait_for_fifo(dev_priv, 8);
	else
		ret = r600_do_wait_for_fifo(dev_priv, 16);
	if (ret)
		return ret;
	for (i = 0; i < dev_priv->usec_timeout; i++) {
		if (!(RADEON_READ(R600_GRBM_STATUS) & R600_GUI_ACTIVE))
			return 0;
		DRM_UDELAY(1);
	}
	DRM_INFO("wait idle failed status : 0x%08X 0x%08X\n",
		 RADEON_READ(R600_GRBM_STATUS),
		 RADEON_READ(R600_GRBM_STATUS2));

	return -EBUSY;
}

void
radeon_init_pipes(drm_radeon_private_t *dev_priv)
{
	uint32_t gb_tile_config, gb_pipe_sel = 0;

	if ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RV530) {
		uint32_t z_pipe_sel = RADEON_READ(RV530_GB_PIPE_SELECT2);
		if ((z_pipe_sel & 3) == 3)
			dev_priv->num_z_pipes = 2;
		else
			dev_priv->num_z_pipes = 1;
	} else
		dev_priv->num_z_pipes = 1;

	/* RS4xx/RS6xx/R4xx/R5xx */
	if ((dev_priv->flags & RADEON_FAMILY_MASK) >= CHIP_R420) {
		gb_pipe_sel = RADEON_READ(R400_GB_PIPE_SELECT);
		dev_priv->num_gb_pipes = ((gb_pipe_sel >> 12) & 0x3) + 1;
	} else {
		/* R3xx */
		if (((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_R300) ||
		    ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_R350)) {
			dev_priv->num_gb_pipes = 2;
		} else {
			/* R3Vxx */
			dev_priv->num_gb_pipes = 1;
		}
	}
	DRM_DEBUG("Num pipes: %d\n", dev_priv->num_gb_pipes);

	gb_tile_config = (R300_ENABLE_TILING | R300_TILE_SIZE_16 /*| R300_SUBPIXEL_1_16*/);

	switch (dev_priv->num_gb_pipes) {
	case 2: gb_tile_config |= R300_PIPE_COUNT_R300; break;
	case 3: gb_tile_config |= R300_PIPE_COUNT_R420_3P; break;
	case 4: gb_tile_config |= R300_PIPE_COUNT_R420; break;
	default:
	case 1: gb_tile_config |= R300_PIPE_COUNT_RV350; break;
	}

	if ((dev_priv->flags & RADEON_FAMILY_MASK) >= CHIP_RV515) {
		RADEON_WRITE_PLL(R500_DYN_SCLK_PWMEM_PIPE, (1 | ((gb_pipe_sel >> 8) & 0xf) << 4));
		RADEON_WRITE(R300_SU_REG_DEST, ((1 << dev_priv->num_gb_pipes) - 1));
	}
	RADEON_WRITE(R300_GB_TILE_CONFIG, gb_tile_config);
	radeon_do_wait_for_idle(dev_priv);
	RADEON_WRITE(R300_DST_PIPE_CONFIG, RADEON_READ(R300_DST_PIPE_CONFIG) | R300_PIPE_AUTO_CONFIG);
	RADEON_WRITE(R300_RB2D_DSTCACHE_MODE, (RADEON_READ(R300_RB2D_DSTCACHE_MODE) |
					       R300_DC_AUTOFLUSH_ENABLE |
					       R300_DC_DC_DISABLE_IGNORE_PE));


}

/* ================================================================
 * CP control, initialization
 */
static void r600_vm_flush_gart_range(struct drm_radeon_private *dev_priv)
{
	u_int32_t	resp, countdown = 1000;

	RADEON_WRITE(R600_VM_CONTEXT0_INVALIDATION_LOW_ADDR, dev_priv->gart_vm_start >> 12);
	RADEON_WRITE(R600_VM_CONTEXT0_INVALIDATION_HIGH_ADDR, (dev_priv->gart_vm_start + dev_priv->gart_size - 1) >> 12);
	RADEON_WRITE(R600_VM_CONTEXT0_REQUEST_RESPONSE, 2);

	do {
		resp = RADEON_READ(R600_VM_CONTEXT0_REQUEST_RESPONSE);
		countdown--;
		DRM_UDELAY(1);
	} while (((resp & 0xf0) == 0) && countdown);
}

static void r600_vm_init(struct drm_radeon_private *dev_priv)
{
	/* initialise the VM to use the page table we constructed up there */
	u32 vm_c0, i;
	u32 mc_rd_a;
	u32 vm_l2_cntl, vm_l2_cntl3;
	/* okay set up the PCIE aperture type thingo */
	RADEON_WRITE(R600_MC_VM_SYSTEM_APERTURE_LOW_ADDR, dev_priv->gart_vm_start >> 12);
	RADEON_WRITE(R600_MC_VM_SYSTEM_APERTURE_HIGH_ADDR, (dev_priv->gart_vm_start + dev_priv->gart_size - 1) >> 12);
	RADEON_WRITE(R600_MC_VM_SYSTEM_APERTURE_DEFAULT_ADDR, 0);

	/* setup MC RD a */
	mc_rd_a = R600_MCD_L1_TLB | R600_MCD_L1_FRAG_PROC | R600_MCD_SYSTEM_ACCESS_MODE_IN_SYS |
		R600_MCD_SYSTEM_APERTURE_UNMAPPED_ACCESS_PASS_THRU | R600_MCD_EFFECTIVE_L1_TLB_SIZE(5) |
		R600_MCD_EFFECTIVE_L1_QUEUE_SIZE(5) | R600_MCD_WAIT_L2_QUERY;

	RADEON_WRITE(R600_MCD_RD_A_CNTL, mc_rd_a);
	RADEON_WRITE(R600_MCD_RD_B_CNTL, mc_rd_a);

	RADEON_WRITE(R600_MCD_WR_A_CNTL, mc_rd_a);
	RADEON_WRITE(R600_MCD_WR_B_CNTL, mc_rd_a);

	RADEON_WRITE(R600_MCD_RD_GFX_CNTL, mc_rd_a);
	RADEON_WRITE(R600_MCD_WR_GFX_CNTL, mc_rd_a);

	RADEON_WRITE(R600_MCD_RD_SYS_CNTL, mc_rd_a);
	RADEON_WRITE(R600_MCD_WR_SYS_CNTL, mc_rd_a);

	RADEON_WRITE(R600_MCD_RD_HDP_CNTL, mc_rd_a | R600_MCD_L1_STRICT_ORDERING);
	RADEON_WRITE(R600_MCD_WR_HDP_CNTL, mc_rd_a /*| R600_MCD_L1_STRICT_ORDERING*/);

	RADEON_WRITE(R600_MCD_RD_PDMA_CNTL, mc_rd_a);
	RADEON_WRITE(R600_MCD_WR_PDMA_CNTL, mc_rd_a);

	RADEON_WRITE(R600_MCD_RD_SEM_CNTL, mc_rd_a | R600_MCD_SEMAPHORE_MODE);
	RADEON_WRITE(R600_MCD_WR_SEM_CNTL, mc_rd_a);

	vm_l2_cntl = R600_VM_L2_CACHE_EN | R600_VM_L2_FRAG_PROC | R600_VM_ENABLE_PTE_CACHE_LRU_W;
	vm_l2_cntl |= R600_VM_L2_CNTL_QUEUE_SIZE(7);
	RADEON_WRITE(R600_VM_L2_CNTL, vm_l2_cntl);

	RADEON_WRITE(R600_VM_L2_CNTL2, 0);
	vm_l2_cntl3 = (R600_VM_L2_CNTL3_BANK_SELECT_0(0) |
		       R600_VM_L2_CNTL3_BANK_SELECT_1(1) |
		       R600_VM_L2_CNTL3_CACHE_UPDATE_MODE(2));
	RADEON_WRITE(R600_VM_L2_CNTL3, vm_l2_cntl3);

	vm_c0 = R600_VM_ENABLE_CONTEXT | R600_VM_PAGE_TABLE_DEPTH_FLAT;

	RADEON_WRITE(R600_VM_CONTEXT0_CNTL, vm_c0);

	vm_c0 &= ~R600_VM_ENABLE_CONTEXT;

	/* disable all other contexts */
	for (i = 1; i < 8; i++)
		RADEON_WRITE(R600_VM_CONTEXT0_CNTL + (i * 4), vm_c0);

	RADEON_WRITE(R600_VM_CONTEXT0_PAGE_TABLE_BASE_ADDR, dev_priv->gart_info.bus_addr >> 12);
	RADEON_WRITE(R600_VM_CONTEXT0_PAGE_TABLE_START_ADDR, dev_priv->gart_vm_start >> 12);
	RADEON_WRITE(R600_VM_CONTEXT0_PAGE_TABLE_END_ADDR, (dev_priv->gart_vm_start + dev_priv->gart_size - 1) >> 12);

	r600_vm_flush_gart_range(dev_priv);
}

/* load r600 microcode */
static void r600_cp_load_microcode(drm_radeon_private_t *dev_priv)
{
	const u32 (*cp)[3];
	const u32 *pfp;
	int i;

	switch (dev_priv->flags & RADEON_FAMILY_MASK) {
	case CHIP_R600:
		DRM_DEBUG("Loading R600 Microcode\n");
		cp  = R600_cp_microcode;
		pfp = R600_pfp_microcode;
		break;
	case CHIP_RV610:
		DRM_DEBUG("Loading RV610 Microcode\n");
		cp  = RV610_cp_microcode;
		pfp = RV610_pfp_microcode;
		break;
	case CHIP_RV630:
		DRM_DEBUG("Loading RV630 Microcode\n");
		cp  = RV630_cp_microcode;
		pfp = RV630_pfp_microcode;
		break;
	case CHIP_RV620:
		DRM_DEBUG("Loading RV620 Microcode\n");
		cp  = RV620_cp_microcode;
		pfp = RV620_pfp_microcode;
		break;
	case CHIP_RV635:
		DRM_DEBUG("Loading RV635 Microcode\n");
		cp  = RV635_cp_microcode;
		pfp = RV635_pfp_microcode;
		break;
	case CHIP_RV670:
		DRM_DEBUG("Loading RV670 Microcode\n");
		cp  = RV670_cp_microcode;
		pfp = RV670_pfp_microcode;
		break;
	case CHIP_RS780:
	case CHIP_RS880:
		DRM_DEBUG("Loading RS780/RS880 Microcode\n");
		cp  = RS780_cp_microcode;
		pfp = RS780_pfp_microcode;
		break;
	default:
		return;
	}

	radeon_do_cp_stop(dev_priv);

	RADEON_WRITE(R600_CP_RB_CNTL,
		     R600_RB_NO_UPDATE |
		     R600_RB_BLKSZ(15) |
		     R600_RB_BUFSZ(3));

	RADEON_WRITE(R600_GRBM_SOFT_RESET, R600_SOFT_RESET_CP);
	RADEON_READ(R600_GRBM_SOFT_RESET);
	DRM_UDELAY(15000);
	RADEON_WRITE(R600_GRBM_SOFT_RESET, 0);

	RADEON_WRITE(R600_CP_ME_RAM_WADDR, 0);

	for (i = 0; i < PM4_UCODE_SIZE; i++) {
		RADEON_WRITE(R600_CP_ME_RAM_DATA, cp[i][0]);
		RADEON_WRITE(R600_CP_ME_RAM_DATA, cp[i][1]);
		RADEON_WRITE(R600_CP_ME_RAM_DATA, cp[i][2]);
	}

	RADEON_WRITE(R600_CP_PFP_UCODE_ADDR, 0);
	for (i = 0; i < PFP_UCODE_SIZE; i++)
		RADEON_WRITE(R600_CP_PFP_UCODE_DATA, pfp[i]);

	RADEON_WRITE(R600_CP_PFP_UCODE_ADDR, 0);
	RADEON_WRITE(R600_CP_ME_RAM_WADDR, 0);
	RADEON_WRITE(R600_CP_ME_RAM_RADDR, 0);
}

static void r700_vm_init(struct drm_radeon_private  *dev_priv)
{
	/* initialise the VM to use the page table we constructed up there */
	u32 vm_c0, i;
	u32 mc_vm_md_l1;
	u32 vm_l2_cntl, vm_l2_cntl3;
	/* okay set up the PCIE aperture type thingo */
	RADEON_WRITE(R700_MC_VM_SYSTEM_APERTURE_LOW_ADDR, dev_priv->gart_vm_start >> 12);
	RADEON_WRITE(R700_MC_VM_SYSTEM_APERTURE_HIGH_ADDR, (dev_priv->gart_vm_start + dev_priv->gart_size - 1) >> 12);
	RADEON_WRITE(R700_MC_VM_SYSTEM_APERTURE_DEFAULT_ADDR, 0);

	mc_vm_md_l1 = R700_ENABLE_L1_TLB |
	    R700_ENABLE_L1_FRAGMENT_PROCESSING |
	    R700_SYSTEM_ACCESS_MODE_IN_SYS |
	    R700_SYSTEM_APERTURE_UNMAPPED_ACCESS_PASS_THRU |
	    R700_EFFECTIVE_L1_TLB_SIZE(5) |
	    R700_EFFECTIVE_L1_QUEUE_SIZE(5);

	RADEON_WRITE(R700_MC_VM_MD_L1_TLB0_CNTL, mc_vm_md_l1);
	RADEON_WRITE(R700_MC_VM_MD_L1_TLB1_CNTL, mc_vm_md_l1);
	RADEON_WRITE(R700_MC_VM_MD_L1_TLB2_CNTL, mc_vm_md_l1);
	RADEON_WRITE(R700_MC_VM_MB_L1_TLB0_CNTL, mc_vm_md_l1);
	RADEON_WRITE(R700_MC_VM_MB_L1_TLB1_CNTL, mc_vm_md_l1);
	RADEON_WRITE(R700_MC_VM_MB_L1_TLB2_CNTL, mc_vm_md_l1);
	RADEON_WRITE(R700_MC_VM_MB_L1_TLB3_CNTL, mc_vm_md_l1);

	vm_l2_cntl = R600_VM_L2_CACHE_EN | R600_VM_L2_FRAG_PROC | R600_VM_ENABLE_PTE_CACHE_LRU_W;
	vm_l2_cntl |= R700_VM_L2_CNTL_QUEUE_SIZE(7);
	RADEON_WRITE(R600_VM_L2_CNTL, vm_l2_cntl);

	RADEON_WRITE(R600_VM_L2_CNTL2, 0);
	vm_l2_cntl3 = R700_VM_L2_CNTL3_BANK_SELECT(0) | R700_VM_L2_CNTL3_CACHE_UPDATE_MODE(2);
	RADEON_WRITE(R600_VM_L2_CNTL3, vm_l2_cntl3);

	vm_c0 = R600_VM_ENABLE_CONTEXT | R600_VM_PAGE_TABLE_DEPTH_FLAT;

	RADEON_WRITE(R600_VM_CONTEXT0_CNTL, vm_c0);

	vm_c0 &= ~R600_VM_ENABLE_CONTEXT;

	/* disable all other contexts */
	for (i = 1; i < 8; i++)
		RADEON_WRITE(R600_VM_CONTEXT0_CNTL + (i * 4), vm_c0);

	RADEON_WRITE(R700_VM_CONTEXT0_PAGE_TABLE_BASE_ADDR, dev_priv->gart_info.bus_addr >> 12);
	RADEON_WRITE(R700_VM_CONTEXT0_PAGE_TABLE_START_ADDR, dev_priv->gart_vm_start >> 12);
	RADEON_WRITE(R700_VM_CONTEXT0_PAGE_TABLE_END_ADDR, (dev_priv->gart_vm_start + dev_priv->gart_size - 1) >> 12);

	r600_vm_flush_gart_range(dev_priv);
}

/* load r600 microcode */
static void r700_cp_load_microcode(drm_radeon_private_t *dev_priv)
{
	const u32 *pfp;
	const u32 *cp;
	int i;

	switch (dev_priv->flags & RADEON_FAMILY_MASK) {
	case CHIP_RV770:
		DRM_DEBUG("Loading RV770/RV790 Microcode\n");
		pfp = RV770_pfp_microcode;
		cp  = RV770_cp_microcode;
		break;
	case CHIP_RV730:
	case CHIP_RV740:
		DRM_DEBUG("Loading RV730/RV740 Microcode\n");
		pfp = RV730_pfp_microcode;
		cp  = RV730_cp_microcode;
		break;
	case CHIP_RV710:
		DRM_DEBUG("Loading RV710 Microcode\n");
		pfp = RV710_pfp_microcode;
		cp  = RV710_cp_microcode;
		break;
	default:
		return;
	}

	radeon_do_cp_stop(dev_priv);

	RADEON_WRITE(R600_CP_RB_CNTL,
		     R600_RB_NO_UPDATE |
		     (15 << 8) |
		     (3 << 0));

	RADEON_WRITE(R600_GRBM_SOFT_RESET, R600_SOFT_RESET_CP);
	RADEON_READ(R600_GRBM_SOFT_RESET);
	DRM_UDELAY(15000);
	RADEON_WRITE(R600_GRBM_SOFT_RESET, 0);

	RADEON_WRITE(R600_CP_PFP_UCODE_ADDR, 0);
	for (i = 0; i < R700_PFP_UCODE_SIZE; i++)
		RADEON_WRITE(R600_CP_PFP_UCODE_DATA, pfp[i]);
	RADEON_WRITE(R600_CP_PFP_UCODE_ADDR, 0);

	RADEON_WRITE(R600_CP_ME_RAM_WADDR, 0);
	for (i = 0; i < R700_PM4_UCODE_SIZE; i++)
		RADEON_WRITE(R600_CP_ME_RAM_DATA, cp[i]);
	RADEON_WRITE(R600_CP_ME_RAM_WADDR, 0);

	RADEON_WRITE(R600_CP_PFP_UCODE_ADDR, 0);
	RADEON_WRITE(R600_CP_ME_RAM_WADDR, 0);
	RADEON_WRITE(R600_CP_ME_RAM_RADDR, 0);
}

/* Load the microcode for the CP */
void
radeon_cp_load_microcode(drm_radeon_private_t *dev_priv)
{
	const u32	(*cp)[2];
	int		 i;

	DRM_DEBUG("\n");

	if (((dev_priv->flags & RADEON_FAMILY_MASK) >= CHIP_RV770)) {
		r700_cp_load_microcode(dev_priv);
		return;
	} else if ((dev_priv->flags & RADEON_FAMILY_MASK) >= CHIP_R600) {
		r600_cp_load_microcode(dev_priv);
		return;
	}

	switch (dev_priv->flags & RADEON_FAMILY_MASK) {
	case CHIP_R100:
	case CHIP_RV100:
	case CHIP_RV200:
	case CHIP_RS100:
	case CHIP_RS200:
		DRM_DEBUG("Loading R100 Microcode\n");
		cp = R100_cp_microcode;
		break;
	case CHIP_R200:
	case CHIP_RV250:
	case CHIP_RV280:
	case CHIP_RS300:
		DRM_DEBUG("Loading R200 Microcode\n");
		cp = R200_cp_microcode;
		break;
	case CHIP_R300:
	case CHIP_R350:
	case CHIP_RV350:
	case CHIP_RV380:
	case CHIP_RS400:
	case CHIP_RS480:
		DRM_DEBUG("Loading R300 Microcode\n");
		cp = R300_cp_microcode;
		break;
	case CHIP_R420:
	case CHIP_R423:
	case CHIP_RV410:
		DRM_DEBUG("Loading R400 Microcode\n");
		cp = R420_cp_microcode;
		break;
	case CHIP_RS690:
	case CHIP_RS740:
		DRM_DEBUG("Loading RS690/RS740 Microcode\n");
		cp = RS690_cp_microcode;
		break;
	case CHIP_RS600:
		DRM_DEBUG("Loading RS600 Microcode\n");
		cp = RS600_cp_microcode;
		break;
	case CHIP_RV515:
	case CHIP_R520:
	case CHIP_RV530:
	case CHIP_R580:
	case CHIP_RV560:
	case CHIP_RV570:
		DRM_DEBUG("Loading R500 Microcode\n");
		cp = R520_cp_microcode;
		break;
	default:
		return;
	}

	radeon_do_wait_for_idle(dev_priv);

	RADEON_WRITE(RADEON_CP_ME_RAM_ADDR, 0);

	for (i = 0; i != 256; i++) {
		RADEON_WRITE(RADEON_CP_ME_RAM_DATAH, cp[i][1]);
		RADEON_WRITE(RADEON_CP_ME_RAM_DATAL, cp[i][0]);
	}
}

/* Wait for the CP to go idle.
 */
int
radeon_do_cp_idle(drm_radeon_private_t *dev_priv)
{
	DRM_DEBUG("\n");

	if (dev_priv->cp_running == 0)
		return (0);

	if ((dev_priv->flags & RADEON_FAMILY_MASK) >= CHIP_R600) {
		BEGIN_RING(5);
		OUT_RING(CP_PACKET3(R600_IT_EVENT_WRITE, 0));
		OUT_RING(R600_CACHE_FLUSH_AND_INV_EVENT);
		/* wait for 3D idle clean */
		OUT_RING(CP_PACKET3(R600_IT_SET_CONFIG_REG, 1));
		OUT_RING((R600_WAIT_UNTIL - R600_SET_CONFIG_REG_OFFSET) >> 2);
		OUT_RING(RADEON_WAIT_3D_IDLE | RADEON_WAIT_3D_IDLECLEAN);

		ADVANCE_RING();
		COMMIT_RING();

		return (r600_do_wait_for_idle(dev_priv));
	}

	BEGIN_RING(6);

	RADEON_PURGE_CACHE();
	RADEON_PURGE_ZCACHE();
	RADEON_WAIT_UNTIL_IDLE();

	ADVANCE_RING();
	COMMIT_RING();

	return (radeon_do_wait_for_idle(dev_priv));
}

/* Start the Command Processor.
 */
void
radeon_do_cp_start(drm_radeon_private_t *dev_priv)
{
	DRM_DEBUG("\n");

	if ((dev_priv->flags & RADEON_FAMILY_MASK) >= CHIP_R600) {
		BEGIN_RING(7);
		OUT_RING(CP_PACKET3(R600_IT_ME_INITIALIZE, 5));
		OUT_RING(0x00000001);
		if (((dev_priv->flags & RADEON_FAMILY_MASK) < CHIP_RV770))
			OUT_RING(0x00000003);
		else
			OUT_RING(0x00000000);
		OUT_RING((dev_priv->r600_max_hw_contexts - 1));
		OUT_RING(R600_ME_INITIALIZE_DEVICE_ID(1));
		OUT_RING(0x00000000);
		OUT_RING(0x00000000);
		ADVANCE_RING();
		COMMIT_RING();

		/* set the mux and reset the halt bit */
		RADEON_WRITE(R600_CP_ME_CNTL, 0xff);
	} else {
		radeon_do_wait_for_idle(dev_priv);

		RADEON_WRITE(RADEON_CP_CSQ_CNTL, dev_priv->cp_mode);

		/* on r420, any DMA from CP to system memory while 2D is active
		 * can cause a hang.  workaround is to queue a CP RESYNC token
		 */
		if ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_R420) {
			BEGIN_RING(3);
			OUT_RING(CP_PACKET0(R300_CP_RESYNC_ADDR, 1));
			OUT_RING(5); /* scratch reg 5 */
			OUT_RING(0xdeadbeef);
			ADVANCE_RING();
			COMMIT_RING();
		}

		BEGIN_RING(8);
		/* isync can only be written through cp on r5xx write it here */
		OUT_RING(CP_PACKET0(RADEON_ISYNC_CNTL, 0));
		OUT_RING(RADEON_ISYNC_ANY2D_IDLE3D |
			 RADEON_ISYNC_ANY3D_IDLE2D |
			 RADEON_ISYNC_WAIT_IDLEGUI |
			 RADEON_ISYNC_CPSCRATCH_IDLEGUI);
		RADEON_PURGE_CACHE();
		RADEON_PURGE_ZCACHE();
		RADEON_WAIT_UNTIL_IDLE();
		ADVANCE_RING();
		COMMIT_RING();

		dev_priv->track_flush |= RADEON_FLUSH_EMITED | RADEON_PURGE_EMITED;
	}

	dev_priv->cp_running = 1;
}

/* Reset the Command Processor.  This will not flush any pending
 * commands, so you must wait for the CP command stream to complete
 * before calling this routine.
 */
void
radeon_do_cp_reset(drm_radeon_private_t *dev_priv)
{
	u32 cur_read_ptr;
	DRM_DEBUG("\n");

	
	if ((dev_priv->flags & RADEON_FAMILY_MASK) >= CHIP_R600) {
		cur_read_ptr = RADEON_READ(R600_CP_RB_RPTR);
		RADEON_WRITE(R600_CP_RB_WPTR, cur_read_ptr);
	} else {
		cur_read_ptr = RADEON_READ(RADEON_CP_RB_RPTR);
		RADEON_WRITE(RADEON_CP_RB_WPTR, cur_read_ptr);
	}
	radeondrm_set_ring_head(dev_priv, cur_read_ptr);
	dev_priv->ring.tail = cur_read_ptr;
}

/* Stop the Command Processor.  This will not flush any pending
 * commands, so you must flush the command stream and wait for the CP
 * to go idle before calling this routine.
 */
void
radeon_do_cp_stop(drm_radeon_private_t *dev_priv)
{
	DRM_DEBUG("\n");

	/* finish the pending CP_RESYNC token */
	if ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_R420) {
		BEGIN_RING(2);
		OUT_RING(CP_PACKET0(R300_RB3D_DSTCACHE_CTLSTAT, 0));
		OUT_RING(R300_RB3D_DC_FINISH);
		ADVANCE_RING();
		COMMIT_RING();
		radeon_do_wait_for_idle(dev_priv);
	}

	if ((dev_priv->flags & RADEON_FAMILY_MASK) >= CHIP_R600)
		RADEON_WRITE(R600_CP_ME_CNTL, 0xff | R600_CP_ME_HALT);
	else 
		RADEON_WRITE(RADEON_CP_CSQ_CNTL, RADEON_CSQ_PRIDIS_INDDIS);

	dev_priv->cp_running = 0;
}

int r600_do_engine_reset(struct drm_device *dev)
{
	drm_radeon_private_t *dev_priv = dev->dev_private;
	u32 cp_ptr, cp_me_cntl, cp_rb_cntl;

	DRM_DEBUG("Resetting GPU\n");

	cp_ptr = RADEON_READ(R600_CP_RB_WPTR);
	cp_me_cntl = RADEON_READ(R600_CP_ME_CNTL);
	RADEON_WRITE(R600_CP_ME_CNTL, R600_CP_ME_HALT);

	RADEON_WRITE(R600_GRBM_SOFT_RESET, 0x7fff);
	RADEON_READ(R600_GRBM_SOFT_RESET);
	DRM_UDELAY(50);
	RADEON_WRITE(R600_GRBM_SOFT_RESET, 0);
	RADEON_READ(R600_GRBM_SOFT_RESET);

	RADEON_WRITE(R600_CP_RB_WPTR_DELAY, 0);
	cp_rb_cntl = RADEON_READ(R600_CP_RB_CNTL);
	RADEON_WRITE(R600_CP_RB_CNTL, R600_RB_RPTR_WR_ENA);

	RADEON_WRITE(R600_CP_RB_RPTR_WR, cp_ptr);
	RADEON_WRITE(R600_CP_RB_WPTR, cp_ptr);
	RADEON_WRITE(R600_CP_RB_CNTL, cp_rb_cntl);
	RADEON_WRITE(R600_CP_ME_CNTL, cp_me_cntl);

	/* Reset the CP ring */
	radeon_do_cp_reset(dev_priv);

	/* The CP is no longer running after an engine reset */
	dev_priv->cp_running = 0;

	/* Reset any pending vertex, indirect buffers */
	radeon_freelist_reset(dev);

	return 0;

}

/* Reset the engine.  This will stop the CP if it is running.
 */
int
radeon_do_engine_reset(struct drm_device *dev)
{
	drm_radeon_private_t *dev_priv = dev->dev_private;
	u32 clock_cntl_index = 0, mclk_cntl = 0, rbbm_soft_reset;
	DRM_DEBUG("\n");

	if ((dev_priv->flags & RADEON_FAMILY_MASK) >= CHIP_R600)
		return (r600_do_engine_reset(dev));

	radeon_do_pixcache_flush(dev_priv);

	if ((dev_priv->flags & RADEON_FAMILY_MASK) <= CHIP_RV410) {
	        /* may need something similar for newer chips */
		clock_cntl_index = RADEON_READ(RADEON_CLOCK_CNTL_INDEX);
		mclk_cntl = RADEON_READ_PLL(dev, RADEON_MCLK_CNTL);

		RADEON_WRITE_PLL(RADEON_MCLK_CNTL, (mclk_cntl |
						    RADEON_FORCEON_MCLKA |
						    RADEON_FORCEON_MCLKB |
						    RADEON_FORCEON_YCLKA |
						    RADEON_FORCEON_YCLKB |
						    RADEON_FORCEON_MC |
						    RADEON_FORCEON_AIC));
	}

	rbbm_soft_reset = RADEON_READ(RADEON_RBBM_SOFT_RESET);

	RADEON_WRITE(RADEON_RBBM_SOFT_RESET, (rbbm_soft_reset |
					      RADEON_SOFT_RESET_CP |
					      RADEON_SOFT_RESET_HI |
					      RADEON_SOFT_RESET_SE |
					      RADEON_SOFT_RESET_RE |
					      RADEON_SOFT_RESET_PP |
					      RADEON_SOFT_RESET_E2 |
					      RADEON_SOFT_RESET_RB));
	RADEON_READ(RADEON_RBBM_SOFT_RESET);
	RADEON_WRITE(RADEON_RBBM_SOFT_RESET, (rbbm_soft_reset &
					      ~(RADEON_SOFT_RESET_CP |
						RADEON_SOFT_RESET_HI |
						RADEON_SOFT_RESET_SE |
						RADEON_SOFT_RESET_RE |
						RADEON_SOFT_RESET_PP |
						RADEON_SOFT_RESET_E2 |
						RADEON_SOFT_RESET_RB)));
	RADEON_READ(RADEON_RBBM_SOFT_RESET);

	if ((dev_priv->flags & RADEON_FAMILY_MASK) <= CHIP_RV410) {
		RADEON_WRITE_PLL(RADEON_MCLK_CNTL, mclk_cntl);
		RADEON_WRITE(RADEON_CLOCK_CNTL_INDEX, clock_cntl_index);
		RADEON_WRITE(RADEON_RBBM_SOFT_RESET, rbbm_soft_reset);
	}

	/* setup the raster pipes */
	if ((dev_priv->flags & RADEON_FAMILY_MASK) >= CHIP_R300)
	    radeon_init_pipes(dev_priv);

	/* Reset the CP ring */
	radeon_do_cp_reset(dev_priv);

	/* The CP is no longer running after an engine reset */
	dev_priv->cp_running = 0;

	/* Reset any pending vertex, indirect buffers */
	radeon_freelist_reset(dev);

	return 0;
}

static void r600_cp_init_ring_buffer(struct drm_device *dev,
    drm_radeon_private_t *dev_priv)
{
	u32 ring_start;
	u64 rptr_addr;

	if (((dev_priv->flags & RADEON_FAMILY_MASK) >= CHIP_RV770))
		r700_gfx_init(dev, dev_priv);
	else
		r600_gfx_init(dev, dev_priv);

	RADEON_WRITE(R600_GRBM_SOFT_RESET, R600_SOFT_RESET_CP);
	RADEON_READ(R600_GRBM_SOFT_RESET);
	DRM_UDELAY(15000);
	RADEON_WRITE(R600_GRBM_SOFT_RESET, 0);


	/* Set ring buffer size */
#ifdef __BIG_ENDIAN
	RADEON_WRITE(R600_CP_RB_CNTL,
		     RADEON_BUF_SWAP_32BIT |
		     RADEON_RB_NO_UPDATE |
		     (dev_priv->ring.rptr_update_l2qw << 8) |
		     dev_priv->ring.size_l2qw);
#else
	RADEON_WRITE(R600_CP_RB_CNTL,
		     RADEON_RB_NO_UPDATE |
		     (dev_priv->ring.rptr_update_l2qw << 8) |
		     dev_priv->ring.size_l2qw);
#endif

	RADEON_WRITE(R600_CP_SEM_WAIT_TIMER, 0x4);

	/* Set the write pointer delay */
	RADEON_WRITE(R600_CP_RB_WPTR_DELAY, 0);

#ifdef __BIG_ENDIAN
	RADEON_WRITE(R600_CP_RB_CNTL,
		     RADEON_BUF_SWAP_32BIT |
		     RADEON_RB_NO_UPDATE |
		     RADEON_RB_RPTR_WR_ENA |
		     (dev_priv->ring.rptr_update_l2qw << 8) |
		     dev_priv->ring.size_l2qw);
#else
	RADEON_WRITE(R600_CP_RB_CNTL,
		     RADEON_RB_NO_UPDATE |
		     RADEON_RB_RPTR_WR_ENA |
		     (dev_priv->ring.rptr_update_l2qw << 8) |
		     dev_priv->ring.size_l2qw);
#endif

	/* Initialize the ring buffer's read and write pointers */
	RADEON_WRITE(R600_CP_RB_RPTR_WR, 0);
	RADEON_WRITE(R600_CP_RB_WPTR, 0);
	radeondrm_set_ring_head(dev_priv, 0);
	dev_priv->ring.tail = 0;

#if __OS_HAS_AGP
	if (dev_priv->flags & RADEON_IS_AGP) {
		rptr_addr = dev_priv->ring_rptr->offset - dev->agp->base +
		    dev_priv->gart_vm_start;
	} else
#endif
	{
		rptr_addr = dev_priv->ring_rptr->offset - dev->sg->handle +
		    dev_priv->gart_vm_start;
	}
	RADEON_WRITE(R600_CP_RB_RPTR_ADDR,
		     rptr_addr & 0xffffffff);
	RADEON_WRITE(R600_CP_RB_RPTR_ADDR_HI,
		     upper_32_bits(rptr_addr));

#ifdef __BIG_ENDIAN
	RADEON_WRITE(R600_CP_RB_CNTL,
		     RADEON_BUF_SWAP_32BIT |
		     (dev_priv->ring.rptr_update_l2qw << 8) |
		     dev_priv->ring.size_l2qw);
#else
	RADEON_WRITE(R600_CP_RB_CNTL,
		     (dev_priv->ring.rptr_update_l2qw << 8) |
		     dev_priv->ring.size_l2qw);
#endif

#if __OS_HAS_AGP
	if (dev_priv->flags & RADEON_IS_AGP) {
		/* XXX */
		radeon_write_agp_base(dev_priv, dev->agp->base);

		/* XXX */
		radeon_write_agp_location(dev_priv,
			     (((dev_priv->gart_vm_start - 1 +
				dev_priv->gart_size) & 0xffff0000) |
			      (dev_priv->gart_vm_start >> 16)));

		ring_start = (dev_priv->cp_ring->offset
			      - dev->agp->base
			      + dev_priv->gart_vm_start);
	} else
#endif
		ring_start = (dev_priv->cp_ring->offset - dev->sg->handle +
		    dev_priv->gart_vm_start);

	RADEON_WRITE(R600_CP_RB_BASE, ring_start >> 8);

	RADEON_WRITE(R600_CP_ME_CNTL, 0xff);

	RADEON_WRITE(R600_CP_DEBUG, (1 << 27) | (1 << 28));

	/* Initialize the scratch register pointer.  This will cause
	 * the scratch register values to be written out to memory
	 * whenever they are updated.
	 *
	 * We simply put this behind the ring read pointer, this works
	 * with PCI GART as well as (whatever kind of) AGP GART
	 */
	{
		u64 scratch_addr;

		scratch_addr = RADEON_READ(R600_CP_RB_RPTR_ADDR);
		scratch_addr |= ((u64)RADEON_READ(R600_CP_RB_RPTR_ADDR_HI)) << 32;
		scratch_addr += R600_SCRATCH_REG_OFFSET;
		scratch_addr >>= 8;
		scratch_addr &= 0xffffffff;

		RADEON_WRITE(R600_SCRATCH_ADDR, (uint32_t)scratch_addr);
	}

	RADEON_WRITE(R600_SCRATCH_UMSK, 0x7);

	/* Turn on bus mastering */
	radeon_enable_bm(dev_priv);

	radeondrm_write_rptr(dev_priv, R600_SCRATCHOFF(0), 0);
	RADEON_WRITE(R600_LAST_FRAME_REG, 0);

	radeondrm_write_rptr(dev_priv, R600_SCRATCHOFF(1), 0);
	RADEON_WRITE(R600_LAST_DISPATCH_REG, 0);

	radeondrm_write_rptr(dev_priv, R600_SCRATCHOFF(2), 0);
	RADEON_WRITE(R600_LAST_CLEAR_REG, 0);

	/* reset sarea copies of these */
	if (dev_priv->sarea_priv) {
		dev_priv->sarea_priv->last_frame = 0;
		dev_priv->sarea_priv->last_dispatch = 0;
		dev_priv->sarea_priv->last_clear = 0;
	}

	r600_do_wait_for_idle(dev_priv);
}

void
radeon_cp_init_ring_buffer(struct drm_device *dev,
    drm_radeon_private_t *dev_priv)
{
	u32 ring_start, cur_read_ptr;

	if ((dev_priv->flags & RADEON_FAMILY_MASK) >= CHIP_R600) {
		r600_cp_init_ring_buffer(dev, dev_priv);
		return;
	}
	/* Initialize the memory controller. With new memory map, the fb location
	 * is not changed, it should have been properly initialized already. Part
	 * of the problem is that the code below is bogus, assuming the GART is
	 * always appended to the fb which is not necessarily the case
	 */
	if (!dev_priv->new_memmap)
		radeon_write_fb_location(dev_priv,
			     ((dev_priv->gart_vm_start - 1) & 0xffff0000)
			     | (dev_priv->fb_location >> 16));

#if __OS_HAS_AGP
	if (dev_priv->flags & RADEON_IS_AGP) {
		radeon_write_agp_base(dev_priv, dev->agp->base);

		radeon_write_agp_location(dev_priv,
			     (((dev_priv->gart_vm_start - 1 +
				dev_priv->gart_size) & 0xffff0000) |
			      (dev_priv->gart_vm_start >> 16)));

		ring_start = (dev_priv->cp_ring->offset
			      - dev->agp->base
			      + dev_priv->gart_vm_start);
	} else
#endif
		ring_start = (dev_priv->cp_ring->offset - dev->sg->handle +
		    dev_priv->gart_vm_start);

	RADEON_WRITE(RADEON_CP_RB_BASE, ring_start);

	/* Set the write pointer delay */
	RADEON_WRITE(RADEON_CP_RB_WPTR_DELAY, 0);

	/* Initialize the ring buffer's read and write pointers */
	cur_read_ptr = RADEON_READ(RADEON_CP_RB_RPTR);
	RADEON_WRITE(RADEON_CP_RB_WPTR, cur_read_ptr);
	radeondrm_set_ring_head(dev_priv, cur_read_ptr);
	dev_priv->ring.tail = cur_read_ptr;

#if __OS_HAS_AGP
	if (dev_priv->flags & RADEON_IS_AGP) {
		RADEON_WRITE(RADEON_CP_RB_RPTR_ADDR,
		    dev_priv->ring_rptr->offset - dev->agp->base +
		    dev_priv->gart_vm_start);
	} else
#endif
	{
		RADEON_WRITE(RADEON_CP_RB_RPTR_ADDR,
		    dev_priv->ring_rptr->offset - dev->sg->handle +
		    dev_priv->gart_vm_start);
	}

	/* Set ring buffer size */
#ifdef __BIG_ENDIAN
	RADEON_WRITE(RADEON_CP_RB_CNTL,
		     RADEON_BUF_SWAP_32BIT |
		     (dev_priv->ring.fetch_size_l2ow << 18) |
		     (dev_priv->ring.rptr_update_l2qw << 8) |
		     dev_priv->ring.size_l2qw);
#else
	RADEON_WRITE(RADEON_CP_RB_CNTL,
		     (dev_priv->ring.fetch_size_l2ow << 18) |
		     (dev_priv->ring.rptr_update_l2qw << 8) |
		     dev_priv->ring.size_l2qw);
#endif

	/* Initialize the scratch register pointer.  This will cause
	 * the scratch register values to be written out to memory
	 * whenever they are updated.
	 *
	 * We simply put this behind the ring read pointer, this works
	 * with PCI GART as well as (whatever kind of) AGP GART
	 */
	RADEON_WRITE(RADEON_SCRATCH_ADDR, RADEON_READ(RADEON_CP_RB_RPTR_ADDR)
		     + RADEON_SCRATCH_REG_OFFSET);

	RADEON_WRITE(RADEON_SCRATCH_UMSK, 0x7);

	radeon_enable_bm(dev_priv);

	radeondrm_write_rptr(dev_priv, RADEON_SCRATCHOFF(0), 0);
	dev_priv->sarea_priv->last_frame = 0;
	RADEON_WRITE(RADEON_LAST_FRAME_REG, dev_priv->sarea_priv->last_frame);

	radeondrm_write_rptr(dev_priv, RADEON_SCRATCHOFF(1), 0);
	dev_priv->sarea_priv->last_dispatch = 0;
	RADEON_WRITE(RADEON_LAST_DISPATCH_REG,
	    dev_priv->sarea_priv->last_dispatch);

	radeondrm_write_rptr(dev_priv, RADEON_SCRATCHOFF(2), 0);
	dev_priv->sarea_priv->last_clear = 0;
	RADEON_WRITE(RADEON_LAST_CLEAR_REG, dev_priv->sarea_priv->last_clear);

	radeon_do_wait_for_idle(dev_priv);

	/* Sync everything up */
	RADEON_WRITE(RADEON_ISYNC_CNTL,
		     (RADEON_ISYNC_ANY2D_IDLE3D |
		      RADEON_ISYNC_ANY3D_IDLE2D |
		      RADEON_ISYNC_WAIT_IDLEGUI |
		      RADEON_ISYNC_CPSCRATCH_IDLEGUI));

}

void
radeon_test_writeback(drm_radeon_private_t *dev_priv)
{
	u32 tmp;

	/* Start with assuming that writeback doesn't work */
	dev_priv->writeback_works = 0;

	/* Writeback doesn't seem to work everywhere, test it here and possibly
	 * enable it if it appears to work
	 */

	if ((dev_priv->flags & RADEON_FAMILY_MASK) >= CHIP_R600) {
		radeondrm_write_rptr(dev_priv, R600_SCRATCHOFF(1), 0);
		RADEON_WRITE(R600_SCRATCH_REG1, 0xdeadbeef);

		for (tmp = 0; tmp < dev_priv->usec_timeout; tmp++) {
			u32 val;

			val = radeondrm_read_rptr(dev_priv, R600_SCRATCHOFF(1));
			if (val == 0xdeadbeef)
				break;
			DRM_UDELAY(1);
		}
	} else {
		radeondrm_write_rptr(dev_priv, RADEON_SCRATCHOFF(1), 0);
		RADEON_WRITE(RADEON_SCRATCH_REG1, 0xdeadbeef);

		for (tmp = 0; tmp < dev_priv->usec_timeout; tmp++) {
			if (radeondrm_read_rptr(dev_priv,
			    RADEON_SCRATCHOFF(1)) == 0xdeadbeef)
			break;
			DRM_UDELAY(1);
		}
	}

	if (tmp < dev_priv->usec_timeout) {
		dev_priv->writeback_works = 1;
		DRM_DEBUG("writeback test succeeded in %d usecs\n", tmp);
	} else {
		dev_priv->writeback_works = 0;
		DRM_INFO("writeback test failed\n");
	}
	if (radeon_no_wb == 1) {
		dev_priv->writeback_works = 0;
		DRM_INFO("writeback forced off\n");
	}

	if (!dev_priv->writeback_works) {
		/* Disable writeback to avoid unnecessary bus master transfers */
		if ((dev_priv->flags & RADEON_FAMILY_MASK) >= CHIP_R600) {
			RADEON_WRITE(R600_CP_RB_CNTL,
			    RADEON_READ(R600_CP_RB_CNTL) | RADEON_RB_NO_UPDATE);
			RADEON_WRITE(R600_SCRATCH_UMSK, 0);
		} else {
			RADEON_WRITE(RADEON_CP_RB_CNTL,
			    RADEON_READ(RADEON_CP_RB_CNTL) |
			    RADEON_RB_NO_UPDATE);
			RADEON_WRITE(RADEON_SCRATCH_UMSK, 0);
		}
	}
}

void
r600_page_table_cleanup(struct drm_device *dev,
    struct drm_ati_pcigart_info *gart_info)
{
	if (gart_info->bus_addr) {
		gart_info->bus_addr = 0;
		if (gart_info->gart_table_location == DRM_ATI_GART_MAIN &&
		    gart_info->tbl.dma.mem != NULL) {
			drm_dmamem_free(dev->dmat, gart_info->tbl.dma.mem);
			gart_info->tbl.dma.mem = NULL;
		}
	}
}

void
r600gart_add_entry(struct drm_ati_pcigart_info *gart_info, bus_size_t offset,
    bus_addr_t entry_addr)
{
	u_int64_t	page_base = (u_int64_t)entry_addr &
	    		    ATI_PCIGART_PAGE_MASK;
	page_base |= R600_PTE_VALID | R600_PTE_SYSTEM | R600_PTE_SNOOPED;
	page_base |= R600_PTE_READABLE | R600_PTE_WRITEABLE;
	bus_space_write_4(gart_info->tbl.fb.bst, gart_info->tbl.fb.bsh,
	    offset * sizeof(u_int64_t), (u_int32_t)page_base);
	bus_space_write_4(gart_info->tbl.fb.bst, gart_info->tbl.fb.bsh,
	    offset * sizeof(u_int64_t) + 4, upper_32_bits(page_base));
}

/* R600 has page table setup */
int r600_page_table_init(struct drm_device *dev)
{
	drm_radeon_private_t		*dev_priv = dev->dev_private;
	struct drm_ati_pcigart_info	*gart_info = &dev_priv->gart_info;
	struct drm_sg_mem		*entry = dev->sg;
	int				 i, j, max_pages, pages, gart_idx;
	bus_addr_t			 entry_addr;

	/* okay page table is available - lets rock */

	max_pages = (gart_info->table_size / sizeof(u_int64_t));
	/* convert from ati pages */
	max_pages /= (PAGE_SIZE / ATI_PCIGART_PAGE_SIZE);
	pages = (entry->mem->map->dm_nsegs <= max_pages) ?
	    entry->mem->map->dm_nsegs : max_pages;

	bus_space_set_region_1(gart_info->tbl.fb.bst, gart_info->tbl.fb.bsh,
	    0, 0, gart_info->table_size);

	KASSERT(PAGE_SIZE >= ATI_PCIGART_PAGE_SIZE);

	for (gart_idx = 0, i = 0; i < pages; i++) {
		entry_addr = dev->sg->mem->map->dm_segs[i].ds_addr;
		for (j = 0; j < (PAGE_SIZE / ATI_PCIGART_PAGE_SIZE);
		    j++, entry_addr += ATI_PCIGART_PAGE_SIZE)
			r600gart_add_entry(gart_info, gart_idx++, entry_addr);
	}
	return 0;
}

/*
 * Set up the addresses for a pcigart table, then fill it.
 */
int
radeondrm_setup_pcigart(struct drm_radeon_private *dev_priv)
{
	struct drm_ati_pcigart_info	*agi = &dev_priv->gart_info;
	struct drm_device		*dev;
	bus_addr_t			 gartaddr;
	u_int32_t			 sctrl;
	int				 ret;

	dev = (struct drm_device *)dev_priv->drmdev;

	agi->table_mask = DMA_BIT_MASK(32);

	/* if we have an offset set from userspace */
	if (dev_priv->pcigart_offset_set) {
		gartaddr = dev_priv->fb_aper_offset + dev_priv->pcigart_offset;

		agi->tbl.fb.bst = dev_priv->bst;
		/* XXX write combining */
		if ((ret = bus_space_map(agi->tbl.fb.bst, gartaddr,
		    agi->table_size, 0, &agi->tbl.fb.bsh)) != 0)
			return (ret);

		/* this is a radeon virtual address */
		agi->bus_addr = dev_priv->fb_location +
		    dev_priv->pcigart_offset;
		if ((dev_priv->flags & RADEON_FAMILY_MASK) >= CHIP_R600) {
			agi->gart_reg_if = DRM_ATI_GART_R600;
		} else if (dev_priv->flags & RADEON_IS_PCIE) {
			agi->gart_reg_if = DRM_ATI_GART_PCIE;
		} else {
			agi->gart_reg_if = DRM_ATI_GART_PCI;
		}
		agi->gart_table_location = DRM_ATI_GART_FB;
	} else {
		if (dev_priv->flags & RADEON_IS_PCIE ||
		    ((dev_priv->flags & RADEON_FAMILY_MASK) >= CHIP_R600)) {
			DRM_ERROR("Cannot use PCI Express without GART "
			    "in FB memory\n");
			return (EINVAL);
		}
		if (dev_priv->flags & RADEON_IS_IGPGART)
			agi->gart_reg_if = DRM_ATI_GART_IGP;
		else
			agi->gart_reg_if = DRM_ATI_GART_PCI;
			
		agi->gart_table_location = DRM_ATI_GART_MAIN;

		/* pcigart_init will allocate dma memory for us */
		agi->bus_addr = 0;
	}

	if ((dev_priv->flags & RADEON_FAMILY_MASK) < CHIP_R600) {
		/* clear surfaces while we write the gart */
		sctrl = RADEON_READ(RADEON_SURFACE_CNTL);
		RADEON_WRITE(RADEON_SURFACE_CNTL, 0);
	}
	if ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RS600 ||
	    ((dev_priv->flags & RADEON_FAMILY_MASK) >= CHIP_R600))
		ret = r600_page_table_init(dev);
	else
		ret = drm_ati_pcigart_init(dev, agi);
	if ((dev_priv->flags & RADEON_FAMILY_MASK) < CHIP_R600)
		RADEON_WRITE(RADEON_SURFACE_CNTL, sctrl);
	if (ret) {
		DRM_ERROR("failed to init PCI GART!\n");
		return (ENOMEM);
	}

	if ((dev_priv->flags & RADEON_FAMILY_MASK) < CHIP_R600 &&
	    (ret = radeon_setup_pcigart_surface(dev_priv)) != 0) {
		DRM_ERROR("failed to setup GART surface!\n");
		if ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RS600)
			r600_page_table_cleanup(dev, &dev_priv->gart_info);
		else
			drm_ati_pcigart_cleanup(dev, &dev_priv->gart_info);
		return (ret);
	}

	/* Turn on PCI GART */
	radeon_set_pcigart(dev_priv, 1);

	return (0);
}

/* Enable or disable IGP GART on the chip */
void
radeon_set_igpgart(drm_radeon_private_t *dev_priv, int on) {
	u32 temp;

	if (on) {
		DRM_DEBUG("programming igp gart %08X %08lX %08X\n",
			 dev_priv->gart_vm_start,
			 (long)dev_priv->gart_info.bus_addr,
			 dev_priv->gart_size);

		temp = IGP_READ_MCIND(dev_priv, RS480_MC_MISC_CNTL);
		if (((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RS690) ||
		    ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RS740))
			IGP_WRITE_MCIND(RS480_MC_MISC_CNTL, (RS480_GART_INDEX_REG_EN |
							     RS690_BLOCK_GFX_D3_EN));
		else
			IGP_WRITE_MCIND(RS480_MC_MISC_CNTL, RS480_GART_INDEX_REG_EN);

		IGP_WRITE_MCIND(RS480_AGP_ADDRESS_SPACE_SIZE, (RS480_GART_EN |
							       RS480_VA_SIZE_32MB));

		temp = IGP_READ_MCIND(dev_priv, RS480_GART_FEATURE_ID);
		IGP_WRITE_MCIND(RS480_GART_FEATURE_ID, (RS480_HANG_EN |
							RS480_TLB_ENABLE |
							RS480_GTW_LAC_EN |
							RS480_1LEVEL_GART));

		temp = dev_priv->gart_info.bus_addr & 0xfffff000;
		temp |= (upper_32_bits(dev_priv->gart_info.bus_addr) & 0xff) << 4;
		IGP_WRITE_MCIND(RS480_GART_BASE, temp);

		temp = IGP_READ_MCIND(dev_priv, RS480_AGP_MODE_CNTL);
		IGP_WRITE_MCIND(RS480_AGP_MODE_CNTL, ((1 << RS480_REQ_TYPE_SNOOP_SHIFT) |
						      RS480_REQ_TYPE_SNOOP_DIS));

		radeon_write_agp_base(dev_priv, dev_priv->gart_vm_start);

		dev_priv->gart_size = 32*1024*1024;
		temp = (((dev_priv->gart_vm_start - 1 + dev_priv->gart_size) &
		    0xffff0000) | (dev_priv->gart_vm_start >> 16));

		radeon_write_agp_location(dev_priv, temp);

		temp = IGP_READ_MCIND(dev_priv, RS480_AGP_ADDRESS_SPACE_SIZE);
		IGP_WRITE_MCIND(RS480_AGP_ADDRESS_SPACE_SIZE, (RS480_GART_EN |
							       RS480_VA_SIZE_32MB));

		do {
			temp = IGP_READ_MCIND(dev_priv, RS480_GART_CACHE_CNTRL);
			if ((temp & RS480_GART_CACHE_INVALIDATE) == 0)
				break;
			DRM_UDELAY(1);
		} while (1);

		IGP_WRITE_MCIND(RS480_GART_CACHE_CNTRL,
				RS480_GART_CACHE_INVALIDATE);

		do {
			temp = IGP_READ_MCIND(dev_priv, RS480_GART_CACHE_CNTRL);
			if ((temp & RS480_GART_CACHE_INVALIDATE) == 0)
				break;
			DRM_UDELAY(1);
		} while (1);

		IGP_WRITE_MCIND(RS480_GART_CACHE_CNTRL, 0);
	} else {
		IGP_WRITE_MCIND(RS480_AGP_ADDRESS_SPACE_SIZE, 0);
	}
}

/* Enable or disable IGP GART on the chip */
void
rs600_set_igpgart(drm_radeon_private_t *dev_priv, int on)
{
	u32 temp;
	int i;

	if (on) {
		DRM_DEBUG("programming igp gart %08X %08lX %08X\n",
			 dev_priv->gart_vm_start,
			 (long)dev_priv->gart_info.bus_addr,
			 dev_priv->gart_size);

		IGP_WRITE_MCIND(RS600_MC_PT0_CNTL, (RS600_EFFECTIVE_L2_CACHE_SIZE(6) |
						    RS600_EFFECTIVE_L2_QUEUE_SIZE(6)));

		for (i = 0; i < 19; i++)
			IGP_WRITE_MCIND(RS600_MC_PT0_CLIENT0_CNTL + i,
					(RS600_ENABLE_TRANSLATION_MODE_OVERRIDE |
					 RS600_SYSTEM_ACCESS_MODE_IN_SYS |
					 RS600_SYSTEM_APERTURE_UNMAPPED_ACCESS_PASSTHROUGH |
					 RS600_EFFECTIVE_L1_CACHE_SIZE(3) |
					 RS600_ENABLE_FRAGMENT_PROCESSING |
					 RS600_EFFECTIVE_L1_QUEUE_SIZE(3)));

		IGP_WRITE_MCIND(RS600_MC_PT0_CONTEXT0_CNTL, (RS600_ENABLE_PAGE_TABLE |
							     RS600_PAGE_TABLE_TYPE_FLAT));

		/* disable all other contexts */
		for (i = 1; i < 8; i++)
			IGP_WRITE_MCIND(RS600_MC_PT0_CONTEXT0_CNTL + i, 0);

		/* setup the page table aperture */
		IGP_WRITE_MCIND(RS600_MC_PT0_CONTEXT0_FLAT_BASE_ADDR,
				dev_priv->gart_info.bus_addr);
		IGP_WRITE_MCIND(RS600_MC_PT0_CONTEXT0_FLAT_START_ADDR,
				dev_priv->gart_vm_start);
		IGP_WRITE_MCIND(RS600_MC_PT0_CONTEXT0_FLAT_END_ADDR,
				(dev_priv->gart_vm_start + dev_priv->gart_size - 1));
		IGP_WRITE_MCIND(RS600_MC_PT0_CONTEXT0_DEFAULT_READ_ADDR, 0);

		/* setup the system aperture */
		IGP_WRITE_MCIND(RS600_MC_PT0_SYSTEM_APERTURE_LOW_ADDR,
				dev_priv->gart_vm_start);
		IGP_WRITE_MCIND(RS600_MC_PT0_SYSTEM_APERTURE_HIGH_ADDR,
				(dev_priv->gart_vm_start + dev_priv->gart_size - 1));

		/* enable page tables */
		temp = IGP_READ_MCIND(dev_priv, RS600_MC_PT0_CNTL);
		IGP_WRITE_MCIND(RS600_MC_PT0_CNTL, (temp | RS600_ENABLE_PT));

		temp = IGP_READ_MCIND(dev_priv, RS600_MC_CNTL1);
		IGP_WRITE_MCIND(RS600_MC_CNTL1, (temp | RS600_ENABLE_PAGE_TABLES));

		/* invalidate the cache */
		temp = IGP_READ_MCIND(dev_priv, RS600_MC_PT0_CNTL);

		temp &= ~(RS600_INVALIDATE_ALL_L1_TLBS | RS600_INVALIDATE_L2_CACHE);
		IGP_WRITE_MCIND(RS600_MC_PT0_CNTL, temp);
		temp = IGP_READ_MCIND(dev_priv, RS600_MC_PT0_CNTL);

		temp |= RS600_INVALIDATE_ALL_L1_TLBS | RS600_INVALIDATE_L2_CACHE;
		IGP_WRITE_MCIND(RS600_MC_PT0_CNTL, temp);
		temp = IGP_READ_MCIND(dev_priv, RS600_MC_PT0_CNTL);

		temp &= ~(RS600_INVALIDATE_ALL_L1_TLBS | RS600_INVALIDATE_L2_CACHE);
		IGP_WRITE_MCIND(RS600_MC_PT0_CNTL, temp);
		temp = IGP_READ_MCIND(dev_priv, RS600_MC_PT0_CNTL);

	} else {
		IGP_WRITE_MCIND(RS600_MC_PT0_CNTL, 0);
		temp = IGP_READ_MCIND(dev_priv, RS600_MC_CNTL1);
		temp &= ~RS600_ENABLE_PAGE_TABLES;
		IGP_WRITE_MCIND(RS600_MC_CNTL1, temp);
	}
}

void
radeon_set_pciegart(drm_radeon_private_t *dev_priv, int on)
{
	u32 tmp = RADEON_READ_PCIE(dev_priv, RADEON_PCIE_TX_GART_CNTL);
	if (on) {

		DRM_DEBUG("programming pcie %08X %08lX %08X\n",
			  dev_priv->gart_vm_start,
			  (long)dev_priv->gart_info.bus_addr,
			  dev_priv->gart_size);
		RADEON_WRITE_PCIE(RADEON_PCIE_TX_DISCARD_RD_ADDR_LO,
				  dev_priv->gart_vm_start);
		RADEON_WRITE_PCIE(RADEON_PCIE_TX_GART_BASE,
				  dev_priv->gart_info.bus_addr);
		RADEON_WRITE_PCIE(RADEON_PCIE_TX_GART_START_LO,
				  dev_priv->gart_vm_start);
		RADEON_WRITE_PCIE(RADEON_PCIE_TX_GART_END_LO,
				  dev_priv->gart_vm_start +
				  dev_priv->gart_size - 1);

		radeon_write_agp_location(dev_priv, 0xffffffc0); /* ?? */

		RADEON_WRITE_PCIE(RADEON_PCIE_TX_GART_CNTL,
				  RADEON_PCIE_TX_GART_EN);
	} else {
		RADEON_WRITE_PCIE(RADEON_PCIE_TX_GART_CNTL,
				  tmp & ~RADEON_PCIE_TX_GART_EN);
	}
}

/* Enable or disable PCI GART on the chip */
void
radeon_set_pcigart(drm_radeon_private_t *dev_priv, int on)
{
	u32 tmp;

	
	if (((dev_priv->flags & RADEON_FAMILY_MASK) >= CHIP_RV770)) {
		if (on)
			r700_vm_init(dev_priv);
		return;
	} else if ((dev_priv->flags & RADEON_FAMILY_MASK) >= CHIP_R600) {
		if (on)
			r600_vm_init(dev_priv);
		return;
	} else if (((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RS690) ||
	    ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RS740) ||
	    (dev_priv->flags & RADEON_IS_IGPGART)) {
		radeon_set_igpgart(dev_priv, on);
		return;
	} else

	if ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RS600) {
		rs600_set_igpgart(dev_priv, on);
		return;
	}

	if (dev_priv->flags & RADEON_IS_PCIE) {
		radeon_set_pciegart(dev_priv, on);
		return;
	}

	tmp = RADEON_READ(RADEON_AIC_CNTL);

	if (on) {
		RADEON_WRITE(RADEON_AIC_CNTL,
			     tmp | RADEON_PCIGART_TRANSLATE_EN);

		/* set PCI GART page-table base address
		 */
		RADEON_WRITE(RADEON_AIC_PT_BASE, dev_priv->gart_info.bus_addr);

		/* set address range for PCI address translate
		 */
		RADEON_WRITE(RADEON_AIC_LO_ADDR, dev_priv->gart_vm_start);
		RADEON_WRITE(RADEON_AIC_HI_ADDR, dev_priv->gart_vm_start
			     + dev_priv->gart_size - 1);

		/* Turn off AGP aperture -- is this required for PCI GART?
		 */
		radeon_write_agp_location(dev_priv, 0xffffffc0);
		RADEON_WRITE(RADEON_AGP_COMMAND, 0);	/* clear AGP_COMMAND */
	} else {
		RADEON_WRITE(RADEON_AIC_CNTL,
			     tmp & ~RADEON_PCIGART_TRANSLATE_EN);
	}
}

int
radeon_setup_pcigart_surface(drm_radeon_private_t *dev_priv)
{
	struct drm_ati_pcigart_info *gart_info = &dev_priv->gart_info;
	struct radeon_virt_surface *vp;
	int i;

	for (i = 0; i < RADEON_MAX_SURFACES * 2; i++) {
		if (!dev_priv->virt_surfaces[i].file_priv ||
		    dev_priv->virt_surfaces[i].file_priv == PCIGART_FILE_PRIV)
			break;
	}
	if (i >= 2 * RADEON_MAX_SURFACES)
		return ENOMEM;
	vp = &dev_priv->virt_surfaces[i];

	for (i = 0; i < RADEON_MAX_SURFACES; i++) {
		struct radeon_surface *sp = &dev_priv->surfaces[i];
		if (sp->refcount)
			continue;

		vp->surface_index = i;
		vp->lower = gart_info->bus_addr;
		vp->upper = vp->lower + gart_info->table_size;
		vp->flags = 0;
		vp->file_priv = PCIGART_FILE_PRIV;

		sp->refcount = 1;
		sp->lower = vp->lower;
		sp->upper = vp->upper;
		sp->flags = 0;

		RADEON_WRITE(RADEON_SURFACE0_INFO + 16 * i, sp->flags);
		RADEON_WRITE(RADEON_SURFACE0_LOWER_BOUND + 16 * i, sp->lower);
		RADEON_WRITE(RADEON_SURFACE0_UPPER_BOUND + 16 * i, sp->upper);
		return 0;
	}

	return ENOMEM;
}

int
radeon_do_init_cp(struct drm_device *dev, drm_radeon_init_t *init)
{
	drm_radeon_private_t	*dev_priv = dev->dev_private;
	u_int32_t		 ssz;
	int			 lshift, sshift;


	DRM_DEBUG("\n");

	/* if we require new memory map but we don't have it fail */
	if ((dev_priv->flags & RADEON_NEW_MEMMAP) && !dev_priv->new_memmap) {
		DRM_ERROR("Cannot initialise DRM on this card\nThis card requires a new X.org DDX for 3D\n");
		radeon_do_cleanup_cp(dev);
		return EINVAL;
	}

	if (init->is_pci && (dev_priv->flags & RADEON_IS_AGP)) {
		DRM_DEBUG("Forcing AGP card to PCI mode\n");
		dev_priv->flags &= ~RADEON_IS_AGP;
		if ((dev_priv->flags & RADEON_FAMILY_MASK) >= CHIP_R600) {
			/* The writeback test succeeds, but when writeback is
			 * enabled, the ring buffer read ptr update fails
			 * after first 128 bytes.
			 */
			radeon_no_wb = 1;
		}
	} else if (!(dev_priv->flags & (RADEON_IS_AGP | RADEON_IS_PCI | RADEON_IS_PCIE))
		 && !init->is_pci) {
		DRM_DEBUG("Restoring AGP flag\n");
		dev_priv->flags |= RADEON_IS_AGP;
	}

	if ((!(dev_priv->flags & RADEON_IS_AGP)) && !dev->sg) {
		DRM_ERROR("PCI GART memory not allocated!\n");
		radeon_do_cleanup_cp(dev);
		return EINVAL;
	}

	dev_priv->usec_timeout = init->usec_timeout;
	if (dev_priv->usec_timeout < 1 ||
	    dev_priv->usec_timeout > RADEON_MAX_USEC_TIMEOUT) {
		DRM_DEBUG("TIMEOUT problem!\n");
		radeon_do_cleanup_cp(dev);
		return EINVAL;
	}

	dev_priv->cp_mode = init->cp_mode;

	/* We don't support anything other than bus-mastering ring mode,
	 * but the ring can be in either AGP or PCI space for the ring
	 * read pointer.
	 */
	if ((init->cp_mode != RADEON_CSQ_PRIBM_INDDIS) &&
	    (init->cp_mode != RADEON_CSQ_PRIBM_INDBM)) {
		DRM_DEBUG("BAD cp_mode (%x)!\n", init->cp_mode);
		radeon_do_cleanup_cp(dev);
		return EINVAL;
	}

	switch (init->fb_bpp) {
	case 16:
		dev_priv->color_fmt = RADEON_COLOR_FORMAT_RGB565;
		break;
	case 32:
	default:
		dev_priv->color_fmt = RADEON_COLOR_FORMAT_ARGB8888;
		break;
	}
	dev_priv->front_offset = init->front_offset;
	dev_priv->front_pitch = init->front_pitch;
	dev_priv->back_offset = init->back_offset;
	dev_priv->back_pitch = init->back_pitch;

	if ((dev_priv->flags & RADEON_FAMILY_MASK) < CHIP_R600) {
		switch (init->depth_bpp) {
		case 16:
			dev_priv->depth_fmt = RADEON_DEPTH_FORMAT_16BIT_INT_Z;
			break;
		case 32:
		default:
			dev_priv->depth_fmt = RADEON_DEPTH_FORMAT_24BIT_INT_Z;
			break;
		}
		dev_priv->depth_offset = init->depth_offset;
		dev_priv->depth_pitch = init->depth_pitch;

			/* Hardware state for depth clears.  Remove this
			 * if/when we no longer clear the depth buffer with
			 * a 3D rectangle. Hard-code all values to prevent
			 * unwanted 3D state from slipping through and
			 * screwing with the clear operation.
			 */
			dev_priv->depth_clear.rb3d_cntl =
			    (RADEON_PLANE_MASK_ENABLE |
			    (dev_priv->color_fmt << 10) |
			    (dev_priv->chip_family < CHIP_R200 ?
			    RADEON_ZBLOCK16 : 0));

			dev_priv->depth_clear.rb3d_zstencilcntl =
			    (dev_priv->depth_fmt | RADEON_Z_TEST_ALWAYS |
			    RADEON_STENCIL_TEST_ALWAYS |
			    RADEON_STENCIL_S_FAIL_REPLACE |
			    RADEON_STENCIL_ZPASS_REPLACE |
			    RADEON_STENCIL_ZFAIL_REPLACE |
			    RADEON_Z_WRITE_ENABLE);

			dev_priv->depth_clear.se_cntl = (RADEON_FFACE_CULL_CW |
			    RADEON_BFACE_SOLID | RADEON_FFACE_SOLID |
			    RADEON_FLAT_SHADE_VTX_LAST |
			    RADEON_DIFFUSE_SHADE_FLAT |
			    RADEON_ALPHA_SHADE_FLAT |
			    RADEON_SPECULAR_SHADE_FLAT |
			    RADEON_FOG_SHADE_FLAT |
			    RADEON_VTX_PIX_CENTER_OGL |
			    RADEON_ROUND_MODE_TRUNC |
			    RADEON_ROUND_PREC_8TH_PIX);
	}

	dev_priv->ring_offset = init->ring_offset;
	dev_priv->ring_rptr_offset = init->ring_rptr_offset;
	dev_priv->buffers_offset = init->buffers_offset;
	dev_priv->gart_textures_offset = init->gart_textures_offset;

	dev_priv->sarea = drm_getsarea(dev);
	if (!dev_priv->sarea) {
		DRM_ERROR("could not find sarea!\n");
		radeon_do_cleanup_cp(dev);
		/* XXX */
		return EINVAL;
	}

	dev_priv->cp_ring = drm_core_findmap(dev, init->ring_offset);
	if (!dev_priv->cp_ring) {
		DRM_ERROR("could not find cp ring region!\n");
		radeon_do_cleanup_cp(dev);
		return EINVAL;
	}
	dev_priv->ring_rptr = drm_core_findmap(dev, init->ring_rptr_offset);
	if (!dev_priv->ring_rptr) {
		DRM_ERROR("could not find ring read pointer!\n");
		radeon_do_cleanup_cp(dev);
		return EINVAL;
	}
	dev->agp_buffer_map = drm_core_findmap(dev, init->buffers_offset);
	if (!dev->agp_buffer_map) {
		DRM_ERROR("could not find dma buffer region!\n");
		radeon_do_cleanup_cp(dev);
		return EINVAL;
	}

	if (init->gart_textures_offset) {
		dev_priv->gart_textures =
		    drm_core_findmap(dev, init->gart_textures_offset);
		if (!dev_priv->gart_textures) {
			DRM_ERROR("could not find GART texture region!\n");
			radeon_do_cleanup_cp(dev);
			return EINVAL;
		}
	}

	dev_priv->sarea_priv =
	    (drm_radeon_sarea_t *)((u8 *)dev_priv->sarea->handle +
	    init->sarea_priv_offset);

#if __OS_HAS_AGP
	if (dev_priv->flags & RADEON_IS_AGP) {
		/* XXX WC */
		drm_core_ioremap(dev_priv->cp_ring, dev);
		drm_core_ioremap(dev_priv->ring_rptr, dev);
		drm_core_ioremap(dev->agp_buffer_map, dev);
		if (!dev_priv->cp_ring->handle ||
		    !dev_priv->ring_rptr->handle ||
		    !dev->agp_buffer_map->handle) {
			DRM_ERROR("could not find ioremap agp regions!\n");
			radeon_do_cleanup_cp(dev);
			return EINVAL;
		}
	} else
#endif
	{
		dev_priv->cp_ring->handle = (void *)dev_priv->cp_ring->offset;
		dev_priv->ring_rptr->handle =
		    (void *)dev_priv->ring_rptr->offset;
		dev->agp_buffer_map->handle =
		    (void *)dev->agp_buffer_map->offset;

		DRM_DEBUG("dev_priv->cp_ring->handle %p\n",
			  dev_priv->cp_ring->handle);
		DRM_DEBUG("dev_priv->ring_rptr->handle %p\n",
			  dev_priv->ring_rptr->handle);
		DRM_DEBUG("dev->agp_buffer_map->handle %p\n",
			  dev->agp_buffer_map->handle);
	}

	if ((dev_priv->flags & RADEON_FAMILY_MASK) >= CHIP_R600) {
		lshift = 24;
		sshift = 8;
		ssz = 0x1000000;
	} else {
		lshift = 16;
		sshift = 0;
		ssz = 0x10000;
	}

	dev_priv->fb_location = (radeon_read_fb_location(dev_priv) & 0xffff) <<
	   lshift;
	dev_priv->fb_size =
	    (((radeon_read_fb_location(dev_priv) & 0xffff0000u) << sshift) +
	    ssz) - dev_priv->fb_location;

	dev_priv->front_pitch_offset = (((dev_priv->front_pitch / 64) << 22) |
					((dev_priv->front_offset
					  + dev_priv->fb_location) >> 10));

	dev_priv->back_pitch_offset = (((dev_priv->back_pitch / 64) << 22) |
				       ((dev_priv->back_offset
					 + dev_priv->fb_location) >> 10));

	dev_priv->depth_pitch_offset = (((dev_priv->depth_pitch / 64) << 22) |
					((dev_priv->depth_offset
					  + dev_priv->fb_location) >> 10));

	dev_priv->gart_size = init->gart_size;

	/* New let's set the memory map ... */
	if (dev_priv->new_memmap) {
		u32 base = 0;

		DRM_DEBUG("Setting GART location based on new memory map\n");

		/* If using AGP, try to locate the AGP aperture at the same
		 * location in the card and on the bus, though we have to
		 * align it down.
		 */
#if __OS_HAS_AGP
		if (dev_priv->flags & RADEON_IS_AGP) {
			base = dev->agp->base;
			/* Check if valid */
			if ((base + dev_priv->gart_size - 1) >= dev_priv->fb_location &&
			    base < (dev_priv->fb_location + dev_priv->fb_size - 1)) {
				DRM_INFO("Can't use AGP base @@0x%08lx, won't fit\n",
					 dev->agp->base);
				base = 0;
			}
		}
#endif
		/* If not or if AGP is at 0 (Macs), try to put it elsewhere */
		if (base == 0) {
			base = dev_priv->fb_location + dev_priv->fb_size;
			if (base < dev_priv->fb_location ||
			    ((base + dev_priv->gart_size) & 0xfffffffful) < base)
				base = dev_priv->fb_location
					- dev_priv->gart_size;
		}
		dev_priv->gart_vm_start = base & 0xffc00000u;
		if (dev_priv->gart_vm_start != base)
			DRM_INFO("GART aligned down from 0x%08x to 0x%08x\n",
				 base, dev_priv->gart_vm_start);
	} else {
		DRM_DEBUG("Setting GART location based on old memory map\n");
		dev_priv->gart_vm_start = dev_priv->fb_location +
			RADEON_READ(RADEON_CONFIG_APER_SIZE);
	}

#if __OS_HAS_AGP
	if (dev_priv->flags & RADEON_IS_AGP)
		dev_priv->gart_buffers_offset = (dev->agp_buffer_map->offset -
		    dev->agp->base + dev_priv->gart_vm_start);
	else
#endif
		dev_priv->gart_buffers_offset = (dev->agp_buffer_map->offset -
		    dev->sg->handle + dev_priv->gart_vm_start);

	DRM_DEBUG("fb 0x%08x size %d\n",
		  (unsigned int) dev_priv->fb_location,
		  (unsigned int) dev_priv->fb_size);
	DRM_DEBUG("dev_priv->gart_size %d\n", dev_priv->gart_size);
	DRM_DEBUG("dev_priv->gart_vm_start 0x%x\n", dev_priv->gart_vm_start);
	DRM_DEBUG("dev_priv->gart_buffers_offset 0x%lx\n",
		  dev_priv->gart_buffers_offset);

	dev_priv->ring.start = (u_int32_t *)dev_priv->cp_ring->handle;
	dev_priv->ring.size = init->ring_size / sizeof(u_int32_t);
	dev_priv->ring.end = ((u_int32_t *)dev_priv->cp_ring->handle +
	    dev_priv->ring.size);
	dev_priv->ring.tail_mask = dev_priv->ring.size - 1;

	/* Parameters for ringbuffer initialisation */
	dev_priv->ring.size_l2qw = drm_order(init->ring_size / 8);
	dev_priv->ring.rptr_update_l2qw = drm_order( /* init->rptr_update */
	    4096 / 8);
	dev_priv->ring.fetch_size_l2ow = drm_order( /* init->fetch_size */
	    32 / 16);

#if __OS_HAS_AGP
	if (dev_priv->flags & RADEON_IS_AGP) {
		/* Turn off PCI GART */
		radeon_set_pcigart(dev_priv, 0);
	} else
#endif
	{
		if (radeondrm_setup_pcigart(dev_priv) != 0) {
			radeon_do_cleanup_cp(dev);
			return EINVAL;
		}
	}

	radeon_cp_load_microcode(dev_priv);
	radeon_cp_init_ring_buffer(dev, dev_priv);

	dev_priv->last_buf = 0;

	radeon_do_engine_reset(dev);
	radeon_test_writeback(dev_priv);

	if ((dev_priv->flags & RADEON_FAMILY_MASK) >= CHIP_R600)
		r600_cs_init(dev);

	return 0;
}

int
radeon_do_cleanup_cp(struct drm_device *dev)
{
	drm_radeon_private_t *dev_priv = dev->dev_private;
	DRM_DEBUG("\n");

#if __OS_HAS_AGP
	if (dev_priv->flags & RADEON_IS_AGP) {
		if (dev_priv->cp_ring != NULL)
			drm_core_ioremapfree(dev_priv->cp_ring, dev);
		if (dev_priv->ring_rptr != NULL)
			drm_core_ioremapfree(dev_priv->ring_rptr, dev);
		if (dev->agp_buffer_map != NULL)
			drm_core_ioremapfree(dev->agp_buffer_map, dev);
	} else
#endif
	{

		if (dev_priv->gart_info.bus_addr) {
			/* Turn off PCI GART */
			radeon_set_pcigart(dev_priv, 0);
			if ((dev_priv->flags & RADEON_FAMILY_MASK) >= CHIP_R600
			    || (dev_priv->flags & RADEON_FAMILY_MASK) ==
			    CHIP_RS600) {
				r600_page_table_cleanup(dev,
				    &dev_priv->gart_info);
			} else if (drm_ati_pcigart_cleanup(dev,
			    &dev_priv->gart_info)) {
				DRM_ERROR("failed to cleanup PCI GART!\n");
			}
		}

		if (dev_priv->gart_info.gart_table_location ==
		    DRM_ATI_GART_FB && dev_priv->gart_info.tbl.fb.bst != 0)
			bus_space_unmap(dev_priv->gart_info.tbl.fb.bst,
			    dev_priv->gart_info.tbl.fb.bsh,
			    dev_priv->gart_info.table_size);
		memset(&dev_priv->gart_info.tbl, 0,
		    sizeof(dev_priv->gart_info.tbl));
	}
	dev->agp_buffer_map = dev_priv->ring_rptr = dev_priv->cp_ring = NULL;

	return 0;
}

int
radeon_cp_init(struct drm_device *dev, void *data, struct drm_file *file_priv)
{
	drm_radeon_init_t 		*init = data;

	LOCK_TEST_WITH_RETURN(dev, file_priv);

	if (init->func == RADEON_INIT_R300_CP)
		r300_init_reg_flags(dev);

	switch (init->func) {
	case RADEON_INIT_CP:
	case RADEON_INIT_R200_CP:
	case RADEON_INIT_R300_CP:
	case RADEON_INIT_R600_CP:
		return radeon_do_init_cp(dev, init);
	case RADEON_CLEANUP_CP:
		return radeon_do_cleanup_cp(dev);
	}

	return EINVAL;
}

int
radeon_cp_start(struct drm_device *dev, void *data, struct drm_file *file_priv)
{
	drm_radeon_private_t *dev_priv = dev->dev_private;
	DRM_DEBUG("\n");

	LOCK_TEST_WITH_RETURN(dev, file_priv);

	if (dev_priv->cp_running) {
		DRM_DEBUG("while CP running\n");
		return 0;
	}
	if (dev_priv->cp_mode == RADEON_CSQ_PRIDIS_INDDIS) {
		DRM_DEBUG("called with bogus CP mode (%d)\n",
			  dev_priv->cp_mode);
		return 0;
	}

	radeon_do_cp_start(dev_priv);

	return 0;
}

/* Stop the CP.  The engine must have been idled before calling this
 * routine.
 */
int
radeon_cp_stop(struct drm_device *dev, void *data, struct drm_file *file_priv)
{
	drm_radeon_private_t *dev_priv = dev->dev_private;
	drm_radeon_cp_stop_t *stop = data;
	int ret;
	DRM_DEBUG("\n");

	LOCK_TEST_WITH_RETURN(dev, file_priv);

	if (!dev_priv->cp_running)
		return 0;

	/* If we fail to make the engine go idle, we return an error
	 * code so that the DRM ioctl wrapper can try again.
	 */
	if (stop->idle) {
		ret = radeon_do_cp_idle(dev_priv);
		if (ret)
			return ret;
	}

	/* Finally, we can turn off the CP.  If the engine isn't idle,
	 * we will get some dropped triangles as they won't be fully
	 * rendered before the CP is shut down.
	 *
	 * After turning off we reset the engine.
	 */
	radeon_do_cp_stop(dev_priv);
	radeon_do_engine_reset(dev);

	return 0;
}

void
radeon_driver_lastclose(struct drm_device *dev)
{
	drm_radeon_private_t *dev_priv = dev->dev_private;
	int i, ret;

	radeon_surfaces_release(PCIGART_FILE_PRIV, dev->dev_private);

	if (dev_priv->cp_running) {
		/* Stop the cp */
		while ((ret = radeon_do_cp_idle(dev_priv)) != 0) {
			DRM_DEBUG("radeon_do_cp_idle %d\n", ret);
			tsleep(&ret, PZERO, "rdnrel", 1);
		}
		radeon_do_cp_stop(dev_priv);
		radeon_do_engine_reset(dev);
	}

	if ((dev_priv->flags & RADEON_FAMILY_MASK) < CHIP_R600) {
		/* Disable *all* interrupts */
		RADEON_WRITE(RADEON_GEN_INT_CNTL, 0);

		/* remove all surfaces */
		for (i = 0; i < RADEON_MAX_SURFACES; i++) {
			RADEON_WRITE(RADEON_SURFACE0_INFO + 16 * i, 0);
			RADEON_WRITE(RADEON_SURFACE0_LOWER_BOUND + 16 * i, 0);
			RADEON_WRITE(RADEON_SURFACE0_UPPER_BOUND + 16 * i, 0);
			bzero(&dev_priv->surfaces[i],
			    sizeof(struct radeon_surface));
		}
	}

	/* Free memory heap structures */
	drm_mem_takedown(&dev_priv->gart_heap);
	drm_mem_takedown(&dev_priv->fb_heap);

	radeon_do_cleanup_cp(dev);
}

/* Just reset the CP ring.  Called as part of an X Server engine reset.
 */
int
radeon_cp_reset(struct drm_device *dev, void *data, struct drm_file *file_priv)
{
	drm_radeon_private_t *dev_priv = dev->dev_private;
	DRM_DEBUG("\n");

	LOCK_TEST_WITH_RETURN(dev, file_priv);

	if (!dev_priv) {
		DRM_DEBUG("called before init done\n");
		return EINVAL;
	}

	radeon_do_cp_reset(dev_priv);

	/* The CP is no longer running after an engine reset */
	dev_priv->cp_running = 0;

	return 0;
}

int
radeon_cp_idle(struct drm_device *dev, void *data, struct drm_file *file_priv)
{
	drm_radeon_private_t *dev_priv = dev->dev_private;
	DRM_DEBUG("\n");

	LOCK_TEST_WITH_RETURN(dev, file_priv);

	return radeon_do_cp_idle(dev_priv);
}

/*
 * This code will reinit the Radeon CP hardware after a resume from disc.
 * AFAIK, it would be very difficult to pickle the state at suspend time, so
 * here we make sure that all Radeon hardware initialisation is re-done without
 * affecting running applications.
 *
 * Charl P. Botha <http://cpbotha.net>
 */
int
radeon_cp_resume(struct drm_device *dev)
{
	drm_radeon_private_t *dev_priv = dev->dev_private;

	if (!dev_priv) {
		DRM_ERROR("Called with no initialization\n");
		return EINVAL;
	}

	DRM_DEBUG("Starting radeon_cp_resume()\n");

#if __OS_HAS_AGP
	if (dev_priv->flags & RADEON_IS_AGP) {
		/* Turn off PCI GART */
		radeon_set_pcigart(dev_priv, 0);
	} else
#endif
	{
		/* Turn on PCI GART */
		radeon_set_pcigart(dev_priv, 1);
	}

	radeon_cp_load_microcode(dev_priv);
	radeon_cp_init_ring_buffer(dev, dev_priv);

	radeon_do_engine_reset(dev);
	if ((dev_priv->flags & RADEON_FAMILY_MASK) < CHIP_R600)
		radeon_irq_set_state(dev, RADEON_SW_INT_ENABLE, 1);

	DRM_DEBUG("radeon_cp_resume() complete\n");

	return 0;
}

/* ================================================================
 * Freelist management
 */

/* Original comment: FIXME: ROTATE_BUFS is a hack to cycle through
 *   bufs until freelist code is used.  Note this hides a problem with
 *   the scratch register * (used to keep track of last buffer
 *   completed) being written to before * the last buffer has actually
 *   completed rendering.
 *
 * KW:  It's also a good way to find free buffers quickly.
 *
 * KW: Ideally this loop wouldn't exist, and freelist_get wouldn't
 * sleep.  However, bugs in older versions of radeon_accel.c mean that
 * we essentially have to do this, else old clients will break.
 *
 * However, it does leave open a potential deadlock where all the
 * buffers are held by other clients, which can't release them because
 * they can't get the lock.
 */

struct drm_buf *
radeon_freelist_get(struct drm_device *dev)
{
	struct drm_device_dma *dma = dev->dma;
	drm_radeon_private_t *dev_priv = dev->dev_private;
	drm_radeon_buf_priv_t *buf_priv;
	struct drm_buf *buf;
	int i, t;
	int start;

	if (++dev_priv->last_buf >= dma->buf_count)
		dev_priv->last_buf = 0;

	start = dev_priv->last_buf;

	for (t = 0; t < dev_priv->usec_timeout; t++) {
		u_int32_t done_age = radeondrm_get_scratch(dev_priv, 1);

		DRM_DEBUG("done_age = %d\n", done_age);
		for (i = 0; i < dma->buf_count; i++) {
			buf = dma->buflist[start];
			buf_priv = buf->dev_private;
			if (buf->file_priv == NULL || (buf->pending &&
			    buf_priv->age <= done_age)) {
				buf->pending = 0;
				return buf;
			}
			if (++start >=dma->buf_count)
				start = 0;
		}

		if (t) {
			DRM_UDELAY(1);
		}
	}

	return NULL;
}

void
radeon_freelist_reset(struct drm_device *dev)
{
	struct drm_device_dma *dma = dev->dma;
	drm_radeon_private_t *dev_priv = dev->dev_private;
	int i;

	dev_priv->last_buf = 0;
	for (i = 0; i < dma->buf_count; i++) {
		struct drm_buf *buf = dma->buflist[i];
		drm_radeon_buf_priv_t *buf_priv = buf->dev_private;
		buf_priv->age = 0;
	}
}

/* ================================================================
 * CP command submission
 */

int
radeon_wait_ring(drm_radeon_private_t *dev_priv, int n)
{
	drm_radeon_ring_buffer_t	*ring = &dev_priv->ring;
	u_int32_t			 last_head;
	int				 i;

	last_head = radeondrm_get_ring_head(dev_priv);

	for (i = 0; i < dev_priv->usec_timeout; i++) {
		u_int32_t head = radeondrm_get_ring_head(dev_priv);

		ring->space = head - ring->tail;
		if (ring->space <= 0)
			ring->space += ring->size;
		if (ring->space > n)
			return 0;

		if (head != last_head)
			i = 0;
		last_head = head;

		DRM_UDELAY(1);
	}

	/* FIXME: This return value is ignored in the BEGIN_RING macro! */
#if RADEON_FIFO_DEBUG
	radeon_status(dev_priv);
	DRM_ERROR("failed!\n");
#endif
	return EBUSY;
}

int
radeon_cp_buffers(struct drm_device *dev, struct drm_dma * d,
    struct drm_file *file_priv)
{
	int i;
	struct drm_buf *buf;

	for (i = d->granted_count; i < d->request_count; i++) {
		buf = radeon_freelist_get(dev);
		if (!buf)
			return EBUSY;	/* NOTE: broken client */

		buf->file_priv = file_priv;

		if (DRM_COPY_TO_USER(&d->request_indices[i], &buf->idx,
				     sizeof(buf->idx)))
			return EFAULT;
		if (DRM_COPY_TO_USER(&d->request_sizes[i], &buf->total,
				     sizeof(buf->total)))
			return EFAULT;

		d->granted_count++;
	}
	return 0;
}

/* Create mappings for registers and framebuffer so userland doesn't necessarily
 * have to find them.
 */
int
radeon_driver_firstopen(struct drm_device *dev)
{
	drm_radeon_private_t	*dev_priv = dev->dev_private;
	struct drm_local_map	*map;
	int			 ret;

	dev_priv->gart_info.table_size = RADEON_PCIGART_TABLE_SIZE;

	ret = drm_addmap(dev, dev_priv->fb_aper_offset, dev_priv->fb_aper_size,
	    _DRM_FRAME_BUFFER, _DRM_WRITE_COMBINING, &map);
	if (ret != 0)
		return ret;

	return 0;
}
@


1.49
log
@Rework how AGP memory regions are mapped and add support for AGP bridges
that do not support remapping for processor accesses.

Add new functions to map/unmap/mmap agp memory and let the agp layer
decides how these memory regions should be accessed. It's assumed here
that the bridge does not support remapping if its aperture address is 0.

This is the last diff required for having drm(4) on macppc using agp(4).

Joint work with and ok kettenis@@
@
text
@d1 1
a1 1
/* $OpenBSD: radeon_cp.c,v 1.48 2011/06/02 18:22:00 weerd Exp $ */
@


1.48
log
@Add $OpenBSD$ after oga said 'go ahead and fix that'

'go for it' oga@@
@
text
@d1 1
a1 1
/* $OpenBSD$ */
d3277 1
a3277 1
			drm_core_ioremapfree(dev_priv->cp_ring);
d3279 1
a3279 1
			drm_core_ioremapfree(dev_priv->ring_rptr);
d3281 1
a3281 1
			drm_core_ioremapfree(dev->agp_buffer_map);
@


1.47
log
@Add RADEON_CS ioctl support for r600 and r700.

This is a faked up version of the gem command submission method for r600
required for OpenGL support on these chipsets.

Currently support is not perfect. since these chips have a rather funky
ringbuffer based interrupt method which this code does not yet support so
interrupt based polling methods must be turned off in mesa.

I've not found a good way which to do that per-driver, so until I work
that out I the following .drirc (or /etc/drirc) chunk (provided by
Brynet after I was too slack to provide it myself) will be needed:

<driconf>
        <device screen="0" driver="r600">
                <application name="all">
                        <option name="fthrottle_mode" value="0"/>
                        <option name="vblank_mode" value="0"/>
                </application>
        </device>
</driconf>


Tested by many on tech@@. While it provided more problems, this diff made
espie@@ stop nagging me when he finally found out it existed.
@
text
@d1 1
@


1.46
log
@Don't try and idle the engine via the ring if the cp is not running.

It means we've cleaned up the ring and bad things will happen (like
panics) on X closedown.

tested by (and ok) beck@@
@
text
@d115 18
d3260 3
@


1.45
log
@tweak spacing a bit. This has been annoying me.
@
text
@d1927 2
@


1.44
log
@DRM for R600 and R700 chipsets.

note, only the pcidevs for those chipsets that have been tested are
enabled for now. Please contact me if you have a r600 or r700 that does
not attach radeondrm. Only the 2D/Xv bits are here. I'm ambivalent about
the implementation of the RADEON_CS ioctl for OpenGL since that was
originally kernel-modesetting only. When we update mesa I shall think
about (and test) it.

Tested by quite a number. Zero bad reports. Nagged perpetually by
robert@@ (and probably others) for months now.
@
text
@d2376 2
a2377 2
			     dev_priv->ring_rptr->offset
			     - dev->agp->base + dev_priv->gart_vm_start);
@


1.43
log
@fix uninitialized or undefined value returned to caller

found by LLVM/Clang Static Analyzer.

with a remind from oga@@ about 80 cols wrap

ok oga@@
@
text
@d5 2
a6 1
 * Copyright 2007 Advanced Micro Devices, Inc.
d31 2
d42 1
d56 3
d62 1
a63 5
u32	radeon_read_fb_location(drm_radeon_private_t *);
void	radeon_write_fb_location(drm_radeon_private_t *, u32);
void	radeon_write_fb_location(drm_radeon_private_t *, u32);
void	radeon_write_agp_location(drm_radeon_private_t *, u32);
void	radeon_write_agp_base(drm_radeon_private_t *, u64);
d70 2
d75 1
d79 33
d145 9
d156 5
a160 2
        if ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RS690)
	    return RS690_READ_MCIND(dev_priv, addr);
d162 1
a162 1
	    return RS480_READ_MCIND(dev_priv, addr);
d169 5
a173 1
	if ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RV515)
d175 2
a176 1
	else if ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RS690)
d178 2
d189 5
a193 1
	if ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RV515)
d195 2
a196 1
	else if ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RS690)
d198 2
d209 8
a216 1
	if ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RV515)
d218 2
a219 1
	else if ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RS690)
d221 2
d234 1
d236 6
a241 1
	if ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RV515) {
d244 2
a245 1
	} else if ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RS690) {
d248 3
d265 20
d301 1061
d1448 3
d1474 47
d1526 9
d1553 1
a1553 1
	switch(dev_priv->num_gb_pipes) {
d1563 1
a1563 1
		RADEON_WRITE(R500_SU_REG_DEST, ((1 << dev_priv->num_gb_pipes) - 1));
d1578 261
d1844 3
a1846 1
	int i;
d1849 7
a1855 1
	radeon_do_wait_for_idle(dev_priv);
d1857 6
a1862 7
	RADEON_WRITE(RADEON_CP_ME_RAM_ADDR, 0);

	if (((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_R100) ||
	    ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RV100) ||
	    ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RV200) ||
	    ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RS100) ||
	    ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RS200)) {
d1864 6
a1869 10
		for (i = 0; i < 256; i++) {
			RADEON_WRITE(RADEON_CP_ME_RAM_DATAH,
				     R100_cp_microcode[i][1]);
			RADEON_WRITE(RADEON_CP_ME_RAM_DATAL,
				     R100_cp_microcode[i][0]);
		}
	} else if (((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_R200) ||
		   ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RV250) ||
		   ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RV280) ||
		   ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RS300)) {
d1871 8
a1878 12
		for (i = 0; i < 256; i++) {
			RADEON_WRITE(RADEON_CP_ME_RAM_DATAH,
				     R200_cp_microcode[i][1]);
			RADEON_WRITE(RADEON_CP_ME_RAM_DATAL,
				     R200_cp_microcode[i][0]);
		}
	} else if (((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_R300) ||
		   ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_R350) ||
		   ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RV350) ||
		   ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RV380) ||
		   ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RS400) ||
		   ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RS480)) {
d1880 5
a1884 9
		for (i = 0; i < 256; i++) {
			RADEON_WRITE(RADEON_CP_ME_RAM_DATAH,
				     R300_cp_microcode[i][1]);
			RADEON_WRITE(RADEON_CP_ME_RAM_DATAL,
				     R300_cp_microcode[i][0]);
		}
	} else if (((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_R420) ||
		   ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_R423) ||	
		   ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RV410)) {
d1886 17
a1902 20
		for (i = 0; i < 256; i++) {
			RADEON_WRITE(RADEON_CP_ME_RAM_DATAH,
				     R420_cp_microcode[i][1]);
			RADEON_WRITE(RADEON_CP_ME_RAM_DATAL,
				     R420_cp_microcode[i][0]);
		}
	} else if ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RS690) {
		DRM_DEBUG("Loading RS690 Microcode\n");
		for (i = 0; i < 256; i++) {
			RADEON_WRITE(RADEON_CP_ME_RAM_DATAH,
				     RS690_cp_microcode[i][1]);
			RADEON_WRITE(RADEON_CP_ME_RAM_DATAL,
				     RS690_cp_microcode[i][0]);
		}
	} else if (((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RV515) ||
		   ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_R520) ||
		   ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RV530) ||
		   ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_R580) ||
		   ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RV560) ||
		   ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RV570)) {
d1904 13
a1916 6
		for (i = 0; i < 256; i++) {
			RADEON_WRITE(RADEON_CP_ME_RAM_DATAH,
				     R520_cp_microcode[i][1]);
			RADEON_WRITE(RADEON_CP_ME_RAM_DATAL,
				     R520_cp_microcode[i][0]);
		}
d1927 16
d1952 1
a1952 1
	return radeon_do_wait_for_idle(dev_priv);
d1960 23
a1982 1
	radeon_do_wait_for_idle(dev_priv);
d1984 11
a1994 1
	RADEON_WRITE(RADEON_CP_CSQ_CNTL, dev_priv->cp_mode);
d1996 12
a2007 1
	dev_priv->cp_running = 1;
d2009 2
a2010 12
	BEGIN_RING(8);
	/* isync can only be written through cp on r5xx write it here */
	OUT_RING(CP_PACKET0(RADEON_ISYNC_CNTL, 0));
	OUT_RING(RADEON_ISYNC_ANY2D_IDLE3D |
		 RADEON_ISYNC_ANY3D_IDLE2D |
		 RADEON_ISYNC_WAIT_IDLEGUI |
		 RADEON_ISYNC_CPSCRATCH_IDLEGUI);
	RADEON_PURGE_CACHE();
	RADEON_PURGE_ZCACHE();
	RADEON_WAIT_UNTIL_IDLE();
	ADVANCE_RING();
	COMMIT_RING();
d2012 1
a2012 1
	dev_priv->track_flush |= RADEON_FLUSH_EMITED | RADEON_PURGE_EMITED;
d2025 8
a2032 2
	cur_read_ptr = RADEON_READ(RADEON_CP_RB_RPTR);
	RADEON_WRITE(RADEON_CP_RB_WPTR, cur_read_ptr);
d2044 54
a2097 1
	DRM_DEBUG("\n");
d2099 1
a2099 1
	RADEON_WRITE(RADEON_CP_CSQ_CNTL, RADEON_CSQ_PRIDIS_INDDIS);
a2100 1
	dev_priv->cp_running = 0;
d2112 3
d2174 151
a2329 1
	u32 tmp;
d2331 4
d2412 1
a2412 30
	/* Turn on bus mastering */
	switch (dev_priv->flags & RADEON_FAMILY_MASK) {
	case CHIP_RS690:
		/* rs600/rs690 */
		tmp = RADEON_READ(RADEON_BUS_CNTL) & ~RS600_BUS_MASTER_DIS;
		RADEON_WRITE(RADEON_BUS_CNTL, tmp);
		break;
	case CHIP_R100:
	case CHIP_RV100:
	case CHIP_RS100:
	case CHIP_RV200:
	case CHIP_RS200:
	case CHIP_R200:
	case CHIP_RV250:
	case CHIP_RS300:
	case CHIP_RV280:
	case CHIP_R300:
	case CHIP_R350:
	case CHIP_RV350:
	case CHIP_R420:
	case CHIP_RS400:
	case CHIP_RS480:
		/* r1xx, r2xx, r300, r(v)350, r420/r481, rs400/rs480 */
		tmp = RADEON_READ(RADEON_BUS_CNTL) & ~RADEON_BUS_MASTER_DIS;
		RADEON_WRITE(RADEON_BUS_CNTL, tmp);
		break;
	default:
		/* PCIE cards appear not to need this */
		break;
	}
d2421 1
a2421 1
		     dev_priv->sarea_priv->last_dispatch);
d2443 3
a2448 2
	radeondrm_write_rptr(dev_priv, RADEON_SCRATCHOFF(1), 0);
	RADEON_WRITE(RADEON_SCRATCH_REG1, 0xdeadbeef);
d2450 19
a2468 3
	for (tmp = 0; tmp < dev_priv->usec_timeout; tmp++) {
		if (radeondrm_read_rptr(dev_priv, RADEON_SCRATCHOFF(1)) ==
		    0xdeadbeef)
d2470 2
a2471 1
		DRM_UDELAY(1);
d2488 68
a2555 2
		RADEON_WRITE(RADEON_CP_RB_CNTL, RADEON_READ(RADEON_CP_RB_CNTL) | RADEON_RB_NO_UPDATE);
		RADEON_WRITE(RADEON_SCRATCH_UMSK, 0);
d2557 1
d2569 1
d2589 7
a2595 2
		agi->gart_reg_if = dev_priv->flags & RADEON_IS_PCIE ?
		    DRM_ATI_GART_PCIE : DRM_ATI_GART_PCI;
d2598 2
a2599 1
		if (dev_priv->flags & RADEON_IS_PCIE) {
d2604 5
a2608 2
		agi->gart_reg_if = dev_priv->flags & RADEON_IS_IGPGART ?
		    DRM_ATI_GART_IGP : DRM_ATI_GART_PCI;
d2615 13
a2627 1
	if (drm_ati_pcigart_init(dev, agi)) {
d2632 10
d2650 1
a2650 2
radeon_set_igpgart(drm_radeon_private_t *dev_priv, int on)
{
d2660 2
a2661 2

		if ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RS690)
d2687 2
a2688 2
		temp = (((dev_priv->gart_vm_start - 1 + dev_priv->gart_size) & 
			0xffff0000) | (dev_priv->gart_vm_start >> 16));
d2701 1
a2701 1
		} while(1);
d2711 1
a2711 1
		} while(1);
d2719 77
d2832 11
a2842 1
	if (((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RS690) ||
d2846 5
d2885 41
d2928 4
a2931 1
	drm_radeon_private_t *dev_priv = dev->dev_private;
d2942 1
a2942 2
	if (init->is_pci && (dev_priv->flags & RADEON_IS_AGP))
	{
d2945 9
a2953 4
	}
	else if (!(dev_priv->flags & (RADEON_IS_AGP | RADEON_IS_PCI | RADEON_IS_PCIE))
		 && !init->is_pci)
	{
d2999 43
a3041 8
	switch (init->depth_bpp) {
	case 16:
		dev_priv->depth_fmt = RADEON_DEPTH_FORMAT_16BIT_INT_Z;
		break;
	case 32:
	default:
		dev_priv->depth_fmt = RADEON_DEPTH_FORMAT_24BIT_INT_Z;
		break;
a3042 32
	dev_priv->depth_offset = init->depth_offset;
	dev_priv->depth_pitch = init->depth_pitch;

	/* Hardware state for depth clears.  Remove this if/when we no
	 * longer clear the depth buffer with a 3D rectangle.  Hard-code
	 * all values to prevent unwanted 3D state from slipping through
	 * and screwing with the clear operation.
	 */
	dev_priv->depth_clear.rb3d_cntl = (RADEON_PLANE_MASK_ENABLE |
					   (dev_priv->color_fmt << 10) |
					   (dev_priv->chip_family < CHIP_R200 ? RADEON_ZBLOCK16 : 0));

	dev_priv->depth_clear.rb3d_zstencilcntl =
	    (dev_priv->depth_fmt |
	     RADEON_Z_TEST_ALWAYS |
	     RADEON_STENCIL_TEST_ALWAYS |
	     RADEON_STENCIL_S_FAIL_REPLACE |
	     RADEON_STENCIL_ZPASS_REPLACE |
	     RADEON_STENCIL_ZFAIL_REPLACE | RADEON_Z_WRITE_ENABLE);

	dev_priv->depth_clear.se_cntl = (RADEON_FFACE_CULL_CW |
					 RADEON_BFACE_SOLID |
					 RADEON_FFACE_SOLID |
					 RADEON_FLAT_SHADE_VTX_LAST |
					 RADEON_DIFFUSE_SHADE_FLAT |
					 RADEON_ALPHA_SHADE_FLAT |
					 RADEON_SPECULAR_SHADE_FLAT |
					 RADEON_FOG_SHADE_FLAT |
					 RADEON_VTX_PIX_CENTER_OGL |
					 RADEON_ROUND_MODE_TRUNC |
					 RADEON_ROUND_PREC_8TH_PIX);

d3053 1
d3087 2
a3088 2
	    (drm_radeon_sarea_t *) ((u8 *) dev_priv->sarea->handle +
				    init->sarea_priv_offset);
d3092 1
d3120 12
a3131 1
	dev_priv->fb_location = (radeon_read_fb_location(dev_priv) & 0xffff) << 16;
d3133 2
a3134 2
		((radeon_read_fb_location(dev_priv) & 0xffff0000u) + 0x10000)
		- dev_priv->fb_location;
d3192 2
a3193 3
		dev_priv->gart_buffers_offset = (dev->agp_buffer_map->offset
						 - dev->agp->base
						 + dev_priv->gart_vm_start);
d3199 3
a3232 3
	/* Start with assuming that writeback doesn't work */
	dev_priv->writeback_works = 0;

d3265 7
a3271 1
			if (drm_ati_pcigart_cleanup(dev, &dev_priv->gart_info))
d3273 1
d3284 1
a3284 3
	dev_priv->cp_ring = NULL;
	dev_priv->ring_rptr = NULL;
	dev->agp_buffer_map = NULL;
d3292 1
a3292 1
	drm_radeon_init_t *init = data;
d3303 1
d3363 2
a3366 2

	/* Reset the engine */
d3378 2
d3384 1
a3384 1
				tsleep(&ret, PZERO, "rdnrel", 1);
d3390 12
a3401 9
	/* Disable *all* interrupts */
	RADEON_WRITE(RADEON_GEN_INT_CNTL, 0);

	/* remove all surfaces */
	for (i = 0; i < RADEON_MAX_SURFACES; i++) {
		RADEON_WRITE(RADEON_SURFACE0_INFO + 16 * i, 0);
		RADEON_WRITE(RADEON_SURFACE0_LOWER_BOUND + 16 * i, 0);
		RADEON_WRITE(RADEON_SURFACE0_UPPER_BOUND + 16 * i, 0);
		bzero(&dev_priv->surfaces[i], sizeof(struct radeon_surface));
a3407 1
	/* deallocate kernel resources */
d3480 2
a3481 1
	radeon_irq_set_state(dev, RADEON_SW_INT_ENABLE, 1);
d3528 2
a3529 2
		for (i = start; i < dma->buf_count; i++) {
			buf = dma->buflist[i];
d3536 2
a3537 1
			start = 0;
a3544 35
	DRM_DEBUG("returning NULL!\n");
	return NULL;
}

#if 0
struct drm_buf *radeon_freelist_get(struct drm_device * dev)
{
	struct drm_device_dma *dma = dev->dma;
	drm_radeon_private_t *dev_priv = dev->dev_private;
	drm_radeon_buf_priv_t *buf_priv;
	struct drm_buf *buf;
	int i, t;
	int start;
	u32 done_age;

	done_age = radeondrm_get_scratch(dev_priv, 1);

	if (++dev_priv->last_buf >= dma->buf_count)
		dev_priv->last_buf = 0;

	start = dev_priv->last_buf;

	for (t = 0; t < 2; t++) {
		for (i = start; i < dma->buf_count; i++) {
			buf = dma->buflist[i];
			buf_priv = buf->dev_private;
			if (buf->file_priv == 0 || (buf->pending &&
			    buf_priv->age <= done_age)) {
				buf->pending = 0;
				return buf;
			}
		}
		start = 0;
	}

a3546 1
#endif
@


1.42
log
@Rework the pcigart stuff somewhat.

firstly: move the pcigart initialisation in radeon_cp.c into its own
function to avoid the horrible nesting and make it more readable.

secondly: make the pcigart code more intelligent depending on whether
the gart table is in pci memory, or system memory. In the former case we
use the bus_space functions and thus don't need BUS_SPACE_LINEAR, while
i'm here, stop using the drm wrapper functions for mapping (which
require a drm_local_map structure, which will die eventually) and just
use bus_space_map itself.

tested on pcie (in framebuffer memory) here on my x800. tested on an
i386 agp card forced to pci mode by sthen.  Doesn't make IGP chips
worse, doesn't make them better either (tested on a rs690).

basic idea from a commit "upstream" a while ago. All the code from yours
truly.
@
text
@d776 2
a777 2
		if (bus_space_map(agi->tbl.fb.bst, gartaddr, agi->table_size,
		    0, &agi->tbl.fb.bsh) != 0)
@


1.41
log
@merge radeon_mem_release() and radeon_mem_takedown() into the drm_heap
interface as drm_mem_release() and drm_mem_takedown() respectively.

While this interface's days are numbered, I'm about to make another
driver use it to remove even worse code.

Roll on memory management...
@
text
@d72 1
d755 56
d1233 1
a1233 43
		dev_priv->gart_info.table_mask = DMA_BIT_MASK(32);
		/* if we have an offset set from userspace */
		if (dev_priv->pcigart_offset_set) {
			dev_priv->gart_info.bus_addr =
			    dev_priv->pcigart_offset + dev_priv->fb_location;
			dev_priv->gart_info.mapping.offset =
			    dev_priv->pcigart_offset + dev_priv->fb_aper_offset;
			dev_priv->gart_info.mapping.size =
			    dev_priv->gart_info.table_size;

			drm_core_ioremap_wc(&dev_priv->gart_info.mapping, dev);
			dev_priv->gart_info.addr =
			    dev_priv->gart_info.mapping.handle;

			if (dev_priv->flags & RADEON_IS_PCIE)
				dev_priv->gart_info.gart_reg_if = DRM_ATI_GART_PCIE;
			else
				dev_priv->gart_info.gart_reg_if = DRM_ATI_GART_PCI;
			dev_priv->gart_info.gart_table_location =
			    DRM_ATI_GART_FB;

			DRM_DEBUG("Setting phys_pci_gart to %p %08lX\n",
				  dev_priv->gart_info.addr,
				  dev_priv->pcigart_offset);
		} else {
			if (dev_priv->flags & RADEON_IS_IGPGART)
				dev_priv->gart_info.gart_reg_if = DRM_ATI_GART_IGP;
			else
				dev_priv->gart_info.gart_reg_if = DRM_ATI_GART_PCI;
			dev_priv->gart_info.gart_table_location =
			    DRM_ATI_GART_MAIN;
			dev_priv->gart_info.addr = NULL;
			dev_priv->gart_info.bus_addr = 0;
			if (dev_priv->flags & RADEON_IS_PCIE) {
				DRM_ERROR
				    ("Cannot use PCI Express without GART in FB memory\n");
				radeon_do_cleanup_cp(dev);
				return EINVAL;
			}
		}

		if (drm_ati_pcigart_init(dev, &dev_priv->gart_info)) {
			DRM_ERROR("failed to init PCI GART!\n");
d1235 1
a1235 1
			return ENOMEM;
a1236 3

		/* Turn on PCI GART */
		radeon_set_pcigart(dev_priv, 1);
d1278 7
a1284 6
		if (dev_priv->gart_info.gart_table_location == DRM_ATI_GART_FB)
		{
			drm_core_ioremapfree(&dev_priv->gart_info.mapping);
			dev_priv->gart_info.addr = 0;
			dev_priv->gart_info.gart_table_location = 0;
		}
@


1.40
log
@detypedef drm_local_map.
@
text
@d1390 2
a1391 2
	radeon_mem_takedown(&(dev_priv->gart_heap));
	radeon_mem_takedown(&(dev_priv->fb_heap));
@


1.39
log
@Change a bunch of "printk" in commented out debug code into "printf" and
kill the compat define. Should have done this ages ago.
@
text
@d1652 3
a1654 3
	int ret;
	drm_local_map_t *map;
	drm_radeon_private_t *dev_priv = dev->dev_private;
@


1.38
log
@Correct the writing to RING_RPTR_ADDR in the non agp case, should be a
hardware virtual address offset, not a physical one. From upstream.
@
text
@d199 2
a200 2
	printk("%s:\n", __FUNCTION__);
	printk("RBBM_STATUS = 0x%08x\n",
d202 1
a202 1
	printk("CP_RB_RTPR = 0x%08x\n",
d204 1
a204 1
	printk("CP_RB_WTPR = 0x%08x\n",
d206 1
a206 1
	printk("AIC_CNTL = 0x%08x\n",
d208 1
a208 1
	printk("AIC_STAT = 0x%08x\n",
d210 1
a210 1
	printk("AIC_PT_BASE = 0x%08x\n",
d212 1
a212 1
	printk("TLB_ADDR = 0x%08x\n",
d214 1
a214 1
	printk("TLB_DATA = 0x%08x\n",
@


1.37
log
@remove the drm_read and drm_write functions. instead just do the
conditional on whether we treat the data like memspace or system memory
into the one driver that needs this.

Something similar was done upstream a while back.
@
text
@a630 6
		struct drm_sg_mem *entry = dev->sg;
		unsigned long tmp_ofs, page_ofs;

		tmp_ofs = dev_priv->ring_rptr->offset - dev->sg->handle;
		page_ofs = tmp_ofs >> PAGE_SHIFT;

d632 2
a633 4
		    entry->mem->map->dm_segs[page_ofs].ds_addr);
		DRM_DEBUG("ring rptr: offset=0x%08lx handle=0x%08lx\n",
		    (unsigned long)entry->mem->map->dm_segs[page_ofs].ds_addr,
		    entry->handle + tmp_ofs);
@


1.36
log
@Push the per-driver dma hook a little further down.

All for all the drivers using the dma-bufs interface, their per-driver
ioctl hooks all started out the same way, followed by a call to another
function to actually select the buffer. Save some space by moving that
selection logic into the main dma_ioctl call, and make the second
function the hook.
@
text
@d492 1
a492 1
	SET_RING_HEAD(dev_priv, cur_read_ptr);
d620 1
a620 1
	SET_RING_HEAD(dev_priv, cur_read_ptr);
a667 4
	dev_priv->scratch = ((__volatile__ u32 *)
			     dev_priv->ring_rptr->handle +
			     (RADEON_SCRATCH_REG_OFFSET / sizeof(u32)));

d701 2
a702 1
	dev_priv->sarea_priv->last_frame = dev_priv->scratch[0] = 0;
d705 2
a706 1
	dev_priv->sarea_priv->last_dispatch = dev_priv->scratch[1] = 0;
d710 2
a711 1
	dev_priv->sarea_priv->last_clear = dev_priv->scratch[2] = 0;
d733 1
a733 1
	DRM_WRITE32(dev_priv->ring_rptr, RADEON_SCRATCHOFF(1), 0);
d737 1
a737 1
		if (DRM_READ32(dev_priv->ring_rptr, RADEON_SCRATCHOFF(1)) ==
d1518 2
a1519 1
		u32 done_age = GET_SCRATCH(1);
d1550 3
a1552 1
	u32 done_age = DRM_READ32(dev_priv->ring_rptr, RADEON_SCRATCHOFF(1));
d1598 5
a1602 3
	drm_radeon_ring_buffer_t *ring = &dev_priv->ring;
	int i;
	u32 last_head = GET_RING_HEAD(dev_priv);
d1605 1
a1605 1
		u_int32_t head = GET_RING_HEAD(dev_priv);
@


1.35
log
@De-macro the ring manipulation macros in favour of functions. Saves a
large pile of space.

Tested by several, thanks.
@
text
@d1625 2
a1626 2
radeon_cp_get_buffers(struct drm_device *dev, struct drm_file *file_priv,
    struct drm_dma * d)
a1647 35
}

int
radeon_cp_buffers(struct drm_device *dev, void *data,
    struct drm_file *file_priv)
{
	struct drm_device_dma *dma = dev->dma;
	int ret = 0;
	struct drm_dma *d = data;

	LOCK_TEST_WITH_RETURN(dev, file_priv);

	/* Please don't send us buffers.
	 */
	if (d->send_count != 0) {
		DRM_ERROR("Process %d trying to send %d buffers via drmDMA\n",
			  DRM_CURRENTPID, d->send_count);
		return EINVAL;
	}

	/* We'll send you buffers.
	 */
	if (d->request_count < 0 || d->request_count > dma->buf_count) {
		DRM_ERROR("Process %d trying to get %d buffers (of %d max)\n",
			  DRM_CURRENTPID, d->request_count, dma->buf_count);
		return EINVAL;
	}

	d->granted_count = 0;

	if (d->request_count) {
		ret = radeon_cp_get_buffers(dev, file_priv, d);
	}

	return ret;
@


1.34
log
@Do a similar thing to inteldrm re removing the old vblank crtc
inferfaces.  Shrinks the code.
@
text
@a438 1
	RING_LOCALS;
a457 3
	RING_LOCALS;
	DRM_DEBUG("\n");

d1165 7
a1171 4
	dev_priv->ring.start = (u32 *) dev_priv->cp_ring->handle;
	dev_priv->ring.end = ((u32 *) dev_priv->cp_ring->handle
			      + init->ring_size / sizeof(u32));
	dev_priv->ring.size = init->ring_size;
d1173 4
a1176 8

	dev_priv->ring.rptr_update = /* init->rptr_update */ 4096;
	dev_priv->ring.rptr_update_l2qw = drm_order( /* init->rptr_update */ 4096 / 8);

	dev_priv->ring.fetch_size = /* init->fetch_size */ 32;
	dev_priv->ring.fetch_size_l2ow = drm_order( /* init->fetch_size */ 32 / 16);

	dev_priv->ring.tail_mask = (dev_priv->ring.size / sizeof(u32)) - 1;
d1601 1
a1601 1
		u32 head = GET_RING_HEAD(dev_priv);
d1603 1
a1603 1
		ring->space = (head - ring->tail) * sizeof(u32);
@


1.33
log
@Kill a bunch of (long long long) dead ioctls.

Shaves some bytes.
@
text
@a951 4
	/* Enable vblank on CRTC1 for older X servers
	 */
	dev_priv->vblank_crtc = DRM_RADEON_VBLANK_CRTC1;

@


1.32
log
@Remove the stats_boxes counters and associated code from radeondrm.

They're really not all that useful.
@
text
@a1490 12
int
radeon_engine_reset(struct drm_device *dev, void *data,
    struct drm_file *file_priv)
{
	DRM_DEBUG("\n");

	LOCK_TEST_WITH_RETURN(dev, file_priv);

	return radeon_do_engine_reset(dev);
}


@


1.31
log
@Switch more info printfs to debug. The average user doesn't want to see
them.

Prompted by deraadt@@
@
text
@a228 2
	dev_priv->stats.boxes |= RADEON_BOX_WAIT_IDLE;

a257 2
	dev_priv->stats.boxes |= RADEON_BOX_WAIT_IDLE;

a280 2
	dev_priv->stats.boxes |= RADEON_BOX_WAIT_IDLE;

a955 1
	dev_priv->do_boxes = 0;
d1546 1
a1546 3
						       buf_priv->age <=
						       done_age)) {
				dev_priv->stats.requested_bufs++;
a1554 1
			dev_priv->stats.freelist_loops++;
a1576 1
	dev_priv->stats.freelist_loops++;
d1583 1
a1583 3
						    buf_priv->age <=
						    done_age)) {
				dev_priv->stats.requested_bufs++;
a1628 2

		dev_priv->stats.boxes |= RADEON_BOX_WAIT_IDLE;
@


1.30
log
@Kill ring.high_mark. it's unused.
@
text
@d1129 1
a1129 1
		DRM_INFO("Setting GART location based on new memory map\n");
d1160 1
a1160 1
		DRM_INFO("Setting GART location based on old memory map\n");
@


1.29
log
@The core drm code calls drm_irq_uninstall() when needed at lastclose.

Due to the fact that most of the drivers didn't keep their mmio regions
mapped from attach, all irq-using drm drivers have a hook in lastclose()
to remove the irq before it unmaps its registers. Since now they all
keep them mapped, this isn't an issue. Remove the redundant calls.
@
text
@a1193 2
	dev_priv->ring.high_mark = RADEON_RING_HIGH_MARK;

@


1.28
log
@radeon_do_cp_resume was only called in one place (and that function just
did that one function call), so instead inline it in place.
@
text
@a1273 7
	/* Make sure interrupts are disabled here because the uninstall ioctl
	 * may not have been called from userspace and after dev_private
	 * is freed, it's too late.
	 */
	if (dev->irq_enabled)
		drm_irq_uninstall(dev);

@


1.27
log
@the body of radeon_do_cp_flush() has been if 0ed out forever. so remove
it and just remove it from the only place it was called.
@
text
@a47 1
int	radeon_do_resume_cp(struct drm_device *);
a1313 41
/* This code will reinit the Radeon CP hardware after a resume from disc.
 * AFAIK, it would be very difficult to pickle the state at suspend time, so
 * here we make sure that all Radeon hardware initialisation is re-done without
 * affecting running applications.
 *
 * Charl P. Botha <http://cpbotha.net>
 */
int
radeon_do_resume_cp(struct drm_device *dev)
{
	drm_radeon_private_t *dev_priv = dev->dev_private;

	if (!dev_priv) {
		DRM_ERROR("Called with no initialization\n");
		return EINVAL;
	}

	DRM_DEBUG("Starting radeon_do_resume_cp()\n");

#if __OS_HAS_AGP
	if (dev_priv->flags & RADEON_IS_AGP) {
		/* Turn off PCI GART */
		radeon_set_pcigart(dev_priv, 0);
	} else
#endif
	{
		/* Turn on PCI GART */
		radeon_set_pcigart(dev_priv, 1);
	}

	radeon_cp_load_microcode(dev_priv);
	radeon_cp_init_ring_buffer(dev, dev_priv);

	radeon_do_engine_reset(dev);
	radeon_irq_set_state(dev, RADEON_SW_INT_ENABLE, 1);

	DRM_DEBUG("radeon_do_resume_cp() complete\n");

	return 0;
}

d1465 7
a1471 1
/* Added by Charl P. Botha to call radeon_do_resume_cp().
d1474 1
a1474 1
radeon_cp_resume(struct drm_device *dev, void *data, struct drm_file *file_priv)
d1476 19
d1496 9
a1504 1
	return radeon_do_resume_cp(dev);
@


1.26
log
@Make the pcigart functions return 0 on success and an errno on failure,
instead of 1 on success and zero on failure. I hated that twisty logic.
@
text
@a44 1
void	radeon_do_cp_flush(drm_radeon_private_t * dev_priv);
a440 16
/* Flush any pending commands to the CP.  This should only be used just
 * prior to a wait for idle, as it informs the engine that the command
 * stream is ending.
 */
void
radeon_do_cp_flush(drm_radeon_private_t *dev_priv)
{
	DRM_DEBUG("\n");
#if 0
	u32 tmp;

	tmp = RADEON_READ(RADEON_CP_RB_WPTR) | (1 << 31);
	RADEON_WRITE(RADEON_CP_RB_WPTR, tmp);
#endif
}

a1415 7

	/* Flush any pending CP commands.  This ensures any outstanding
	 * commands are exectuted by the engine before we turn it off.
	 */
	if (stop->flush) {
		radeon_do_cp_flush(dev_priv);
	}
@


1.25
log
@convert drm_scatter code over to using the new dmamem api.

removes the custom code in there, so shrinks the kernel by a few bytes.
Convert other code to deal with data structure changes.
@
text
@d1262 1
a1262 1
		if (!drm_ati_pcigart_init(dev, &dev_priv->gart_info)) {
d1314 1
a1314 1
			if (!drm_ati_pcigart_cleanup(dev, &dev_priv->gart_info))
@


1.24
log
@Change microcode loaded messages to debug, this was printed
after every suspend/resume cycle filling up the dmesg buffer
with the same message over and over again.
ok oga@@
@
text
@d637 2
a638 3
		ring_start = (dev_priv->cp_ring->offset
			      - (unsigned long)dev->sg->virtual
			      + dev_priv->gart_vm_start);
d662 1
a662 2
		tmp_ofs = dev_priv->ring_rptr->offset -
				(unsigned long)dev->sg->virtual;
d665 2
a666 1
		RADEON_WRITE(RADEON_CP_RB_RPTR_ADDR, entry->busaddr[page_ofs]);
d668 2
a669 2
			  (unsigned long)entry->busaddr[page_ofs],
			  entry->handle + tmp_ofs);
d1190 2
a1191 3
		dev_priv->gart_buffers_offset = (dev->agp_buffer_map->offset
					- (unsigned long)dev->sg->virtual
					+ dev_priv->gart_vm_start);
@


1.23
log
@Only print information on the writeback test if it fails. Otherwise only
print if we're debugging.

Nagged often enough my marco@@
@
text
@d377 1
a377 1
		DRM_INFO("Loading R100 Microcode\n");
d388 1
a388 1
		DRM_INFO("Loading R200 Microcode\n");
d401 1
a401 1
		DRM_INFO("Loading R300 Microcode\n");
d411 1
a411 1
		DRM_INFO("Loading R400 Microcode\n");
d419 1
a419 1
		DRM_INFO("Loading RS690 Microcode\n");
d432 1
a432 1
		DRM_INFO("Loading R500 Microcode\n");
@


1.22
log
@Don't do radeon_cp_dispatch flip on lastclose.

Sometimes the sarea isn't there and screws us. The intention of this
call was to set the scanout buffer back to being correct.

On the other hand: If we're in lastclose the xserver is shutting and
thus the scanout buffer is moot. Kernel modesetting will probably
revising pageflipping, but that'll be a different interface anyway.
Since all lastclose does not is call radeon_do_release() just rename
radeon_do_release to lastclose and nuke the old one.

Uwe@@ has some crashes in here occasionally, this diff fixed them for him.
@
text
@d775 1
a775 1
		DRM_INFO("writeback test succeeded in %d usecs\n", tmp);
@


1.21
log
@Zero the surface when we free them. stops some state problems which cause
corruption on second X start on some machines.

This driver is really quite dumb.
@
text
@d1465 1
a1465 1
radeon_do_release(struct drm_device *dev)
@


1.20
log
@Work around the stupidity of radeondrm by double checking that things are
running before we play with things.

Lots more cleanup needed, but now you can shut X without it crashing.
@
text
@d331 1
a331 1
	DRM_INFO("Num pipes: %d\n", dev_priv->num_gb_pipes);
d1488 1
@


1.19
log
@destatic radeondrm almost completely. I'm sick of ddb lying to me.
shaves a few bytes, but that's just gravy.
@
text
@d1303 1
a1303 1
		if (dev_priv->cp_ring != NULL) {
d1305 1
a1305 3
			dev_priv->cp_ring = NULL;
		}
		if (dev_priv->ring_rptr != NULL) {
d1307 1
a1307 3
			dev_priv->ring_rptr = NULL;
		}
		if (dev->agp_buffer_map != NULL) {
a1308 2
			dev->agp_buffer_map = NULL;
		}
d1324 1
d1327 3
d1470 4
a1473 12
	if (dev_priv) {
		if (dev_priv->cp_running) {
			/* Stop the cp */
			while ((ret = radeon_do_cp_idle(dev_priv)) != 0) {
				DRM_DEBUG("radeon_do_cp_idle %d\n", ret);
#ifdef __linux__
				schedule();
#else
#if defined(__FreeBSD__) && __FreeBSD_version > 500000
				mtx_sleep(&ret, &dev->dev_lock, PZERO, "rdnrel",
				       1);
#else
a1474 5
#endif
#endif
			}
			radeon_do_cp_stop(dev_priv);
			radeon_do_engine_reset(dev);
d1476 3
d1480 2
a1481 2
		/* Disable *all* interrupts */
		RADEON_WRITE(RADEON_GEN_INT_CNTL, 0);
d1483 6
a1488 8
		/* remove all surfaces */
		for (i = 0; i < RADEON_MAX_SURFACES; i++) {
			RADEON_WRITE(RADEON_SURFACE0_INFO + 16 * i, 0);
			RADEON_WRITE(RADEON_SURFACE0_LOWER_BOUND +
				     16 * i, 0);
			RADEON_WRITE(RADEON_SURFACE0_UPPER_BOUND +
				     16 * i, 0);
		}
d1490 3
a1492 3
		/* Free memory heap structures */
		radeon_mem_takedown(&(dev_priv->gart_heap));
		radeon_mem_takedown(&(dev_priv->fb_heap));
d1494 2
a1495 3
		/* deallocate kernel resources */
		radeon_do_cleanup_cp(dev);
	}
a1551 12
/* ================================================================
 * Fullscreen mode
 */

/* KW: Deprecated to say the least:
 */
int
radeon_fullscreen(struct drm_device *dev, void *data,
    struct drm_file *file_priv)
{
	return 0;
}
@


1.18
log
@back out the buf_priv change. it made some incorrect assumptions and
broke radeondrm. Fixing it is ugly, so another change will have to be made
later.


I /hate/ the drm_buf api, it will die as soon as it can.
@
text
@d41 33
a73 2
static int radeon_do_cleanup_cp(struct drm_device * dev);
static void radeon_do_cp_start(drm_radeon_private_t * dev_priv);
d75 3
a77 1
static u32 R500_READ_MCIND(drm_radeon_private_t *dev_priv, int addr)
d86 2
a87 1
static u32 RS480_READ_MCIND(drm_radeon_private_t *dev_priv, int addr)
d96 2
a97 1
static u32 RS690_READ_MCIND(drm_radeon_private_t *dev_priv, int addr)
d106 2
a107 1
static u32 IGP_READ_MCIND(drm_radeon_private_t *dev_priv, int addr)
d115 2
a116 1
u32 radeon_read_fb_location(drm_radeon_private_t *dev_priv)
d129 2
a130 1
static void radeon_write_fb_location(drm_radeon_private_t *dev_priv, u32 fb_loc)
d142 2
a143 1
static void radeon_write_agp_location(drm_radeon_private_t *dev_priv, u32 agp_loc)
d155 2
a156 1
static void radeon_write_agp_base(drm_radeon_private_t *dev_priv, u64 agp_base)
d181 2
a182 1
static int RADEON_READ_PLL(struct drm_device * dev, int addr)
d190 2
a191 1
static u32 RADEON_READ_PCIE(drm_radeon_private_t *dev_priv, int addr)
d198 2
a199 1
static void radeon_status(drm_radeon_private_t * dev_priv)
d225 2
a226 1
static int radeon_do_pixcache_flush(drm_radeon_private_t * dev_priv)
d257 2
a258 1
static int radeon_do_wait_for_fifo(drm_radeon_private_t * dev_priv, int entries)
d282 2
a283 1
static int radeon_do_wait_for_idle(drm_radeon_private_t * dev_priv)
d312 2
a313 1
static void radeon_init_pipes(drm_radeon_private_t * dev_priv)
d362 2
a363 1
static void radeon_cp_load_microcode(drm_radeon_private_t * dev_priv)
d446 2
a447 1
static void radeon_do_cp_flush(drm_radeon_private_t * dev_priv)
d460 2
a461 1
int radeon_do_cp_idle(drm_radeon_private_t * dev_priv)
d480 2
a481 1
static void radeon_do_cp_start(drm_radeon_private_t * dev_priv)
d512 2
a513 1
static void radeon_do_cp_reset(drm_radeon_private_t * dev_priv)
d528 2
a529 1
static void radeon_do_cp_stop(drm_radeon_private_t * dev_priv)
d540 2
a541 1
static int radeon_do_engine_reset(struct drm_device * dev)
d606 3
a608 2
static void radeon_cp_init_ring_buffer(struct drm_device * dev,
				       drm_radeon_private_t * dev_priv)
d755 2
a756 1
static void radeon_test_writeback(drm_radeon_private_t * dev_priv)
d793 2
a794 1
static void radeon_set_igpgart(drm_radeon_private_t * dev_priv, int on)
d864 2
a865 1
static void radeon_set_pciegart(drm_radeon_private_t * dev_priv, int on)
d895 2
a896 1
static void radeon_set_pcigart(drm_radeon_private_t * dev_priv, int on)
d937 2
a938 1
static int radeon_do_init_cp(struct drm_device * dev, drm_radeon_init_t * init)
d1288 2
a1289 1
static int radeon_do_cleanup_cp(struct drm_device * dev)
d1343 2
a1344 1
static int radeon_do_resume_cp(struct drm_device * dev)
d1377 2
a1378 1
int radeon_cp_init(struct drm_device *dev, void *data, struct drm_file *file_priv)
d1399 2
a1400 1
int radeon_cp_start(struct drm_device *dev, void *data, struct drm_file *file_priv)
d1425 2
a1426 1
int radeon_cp_stop(struct drm_device *dev, void *data, struct drm_file *file_priv)
d1466 2
a1467 1
void radeon_do_release(struct drm_device * dev)
d1515 2
a1516 1
int radeon_cp_reset(struct drm_device *dev, void *data, struct drm_file *file_priv)
d1536 2
a1537 1
int radeon_cp_idle(struct drm_device *dev, void *data, struct drm_file *file_priv)
d1549 2
a1550 1
int radeon_cp_resume(struct drm_device *dev, void *data, struct drm_file *file_priv)
d1556 3
a1558 1
int radeon_engine_reset(struct drm_device *dev, void *data, struct drm_file *file_priv)
d1573 3
a1575 1
int radeon_fullscreen(struct drm_device *dev, void *data, struct drm_file *file_priv)
d1601 2
a1602 1
struct drm_buf *radeon_freelist_get(struct drm_device * dev)
d1678 2
a1679 1
void radeon_freelist_reset(struct drm_device * dev)
d1697 2
a1698 1
int radeon_wait_ring(drm_radeon_private_t * dev_priv, int n)
d1730 3
a1732 3
static int radeon_cp_get_buffers(struct drm_device *dev,
				 struct drm_file *file_priv,
				 struct drm_dma * d)
d1756 3
a1758 1
int radeon_cp_buffers(struct drm_device *dev, void *data, struct drm_file *file_priv)
d1794 2
a1795 1
int radeon_driver_firstopen(struct drm_device *dev)
@


1.17
log
@Instead of having a ``private data'' pointer in the dma buffers, just
ask the driver how large they need the structure we allocate to be, and
use inheritance like we do for struct device. Simplifies things a little
bit and saves us a pointer.
@
text
@d1547 1
a1547 1
			buf_priv = (drm_radeon_buf_priv_t *)buf;
d1613 1
a1613 1
		drm_radeon_buf_priv_t *buf_priv = (drm_radeon_buf_priv_t *)buf;
@


1.16
log
@we're a real device now and we don't on-demand allocate our softc. Do
not zero it during the cleanup ioctl.
@
text
@d1547 1
a1547 1
			buf_priv = buf->dev_private;
d1613 1
a1613 1
		drm_radeon_buf_priv_t *buf_priv = buf->dev_private;
@


1.15
log
@Make all drm drivers map their mmio register space on attach instead of
using the drm_maps interface (this was done for inteldrm a few days
ago).  All drivers now ignore the mmio_offset argument that the init
ioctl takes.

This clears up the code and makes sure that drm_ioremap_core() doesn't
need the vga_pci_map inteface anymore, so we don't have to pass in the
vga softc anymore. We also get to kill the drm_resource_{start,length}
linux-alike functions since we just calculate all the requisite offsets
at startup and cache those we need. This now means that technically the
only driver that needs the vga_pci_map api is inteldrm (due to sharing
with intagp issues), though this diff doesn't convert them over.
@
text
@a1270 2
	/* only clear to the start of flags */
	memset(dev_priv, 0, offsetof(drm_radeon_private_t, flags));
@


1.14
log
@Remove the driver->load callback and just do all the initialization in
the attach function. First step towards splitting drm off as it's own
(bus independant) device, as it should be.
@
text
@d1429 1
a1429 2
		if (dev_priv->mmio)	/* remove this after permanent addmaps */
			RADEON_WRITE(RADEON_GEN_INT_CNTL, 0);
d1431 7
a1437 8
		if (dev_priv->mmio) {	/* remove all surfaces */
			for (i = 0; i < RADEON_MAX_SURFACES; i++) {
				RADEON_WRITE(RADEON_SURFACE0_INFO + 16 * i, 0);
				RADEON_WRITE(RADEON_SURFACE0_LOWER_BOUND +
					     16 * i, 0);
				RADEON_WRITE(RADEON_SURFACE0_UPPER_BOUND +
					     16 * i, 0);
			}
d1726 2
a1727 10
	ret = drm_addmap(dev, drm_get_resource_start(dev, 2),
			 drm_get_resource_len(dev, 2), _DRM_REGISTERS,
			 _DRM_READ_ONLY, &dev_priv->mmio);
	if (ret != 0)
		return ret;

	dev_priv->fb_aper_offset = drm_get_resource_start(dev, 0);
	ret = drm_addmap(dev, dev_priv->fb_aper_offset,
			 drm_get_resource_len(dev, 0), _DRM_FRAME_BUFFER,
			 _DRM_WRITE_COMBINING, &map);
@


1.13
log
@reduce the dependancy of drm_pci_alloc upon the drm device softc. Just
pass in the dma tag
@
text
@a1716 45
int radeon_driver_load(struct drm_device *dev, unsigned long flags)
{
	drm_radeon_private_t *dev_priv;
	int ret = 0;

	dev_priv = drm_calloc(1, sizeof(drm_radeon_private_t), DRM_MEM_DRIVER);
	if (dev_priv == NULL)
		return ENOMEM;

	dev->dev_private = (void *)dev_priv;
	dev_priv->flags = flags;

	switch (flags & RADEON_FAMILY_MASK) {
	case CHIP_R100:
	case CHIP_RV200:
	case CHIP_R200:
	case CHIP_R300:
	case CHIP_R350:
	case CHIP_R420:
	case CHIP_R423:
	case CHIP_RV410:
	case CHIP_RV515:
	case CHIP_R520:
	case CHIP_RV570:
	case CHIP_R580:
		dev_priv->flags |= RADEON_HAS_HIERZ;
		break;
	default:
		/* all other chips have no hierarchical z buffer */
		break;
	}

	dev_priv->chip_family = flags & RADEON_FAMILY_MASK;
	if (drm_device_is_agp(dev))
		dev_priv->flags |= RADEON_IS_AGP;
	else if (drm_device_is_pcie(dev))
		dev_priv->flags |= RADEON_IS_PCIE;
	else
		dev_priv->flags |= RADEON_IS_PCI;

	DRM_DEBUG("%s card detected\n",
		  ((dev_priv->flags & RADEON_IS_AGP) ? "AGP" : (((dev_priv->flags & RADEON_IS_PCIE) ? "PCIE" : "PCI"))));
	return ret;
}

a1740 11
	return 0;
}

int radeon_driver_unload(struct drm_device *dev)
{
	drm_radeon_private_t *dev_priv = dev->dev_private;

	DRM_DEBUG("\n");
	drm_free(dev_priv, sizeof(*dev_priv), DRM_MEM_DRIVER);

	dev->dev_private = NULL;
@


1.12
log
@Remove dev->agp_buffer_token, linux needs it, we do not.
@
text
@d1243 1
a1243 1
			drm_core_ioremapfree(dev_priv->cp_ring, dev);
d1247 1
a1247 1
			drm_core_ioremapfree(dev_priv->ring_rptr, dev);
d1251 1
a1251 1
			drm_core_ioremapfree(dev->agp_buffer_map, dev);
d1267 1
a1267 1
			drm_core_ioremapfree(&dev_priv->gart_info.mapping, dev);
@


1.11
log
@Fix the bits to enable bus mastering mode on some newer chips. From
Alex Deuchar via drm git.
@
text
@a1014 1
	dev->agp_buffer_token = init->buffers_offset;
@


1.10
log
@Make writeback work on after a suspend. From Dave Airlie via drm git.
@
text
@d361 1
d649 29
a677 2
	tmp = RADEON_READ(RADEON_BUS_CNTL) & ~RADEON_BUS_MASTER_DIS;
	RADEON_WRITE(RADEON_BUS_CNTL, tmp);
d1737 1
@


1.9
log
@Kill the linux-ready negative return codes in ``shared'' code. We handle
them wrong in several cases that i've noticed and Merging when needed is
still fairly simple, anyway. This shaves another 500 bytes from an amd64
kernel due to not having to flip the sign on some things. It also stops
my eyes bleeding.

Tested by a few along with the last diff that went in.
@
text
@a630 3
	/* Start with assuming that writeback doesn't work */
	dev_priv->writeback_works = 0;

d1186 3
@


1.8
log
@Rework the drm locking to be at least halfway sane. The freebsd code
held a lock over all driver ioctls in order to be ``mpsafe''. Stop lying
to ourselves for a start. This code is not fully mpsafe, and should not
pretend to be so.  Put the locking around where it should, and rely on
biglock for the rest. This will need to be fixed, but avoids some of the
horrible that we have right now.

Tested by many over a long time and several iterations.
@
text
@d210 1
a210 1
	return -EBUSY;
d234 1
a234 1
	return -EBUSY;
d263 1
a263 1
	return -EBUSY;
d863 1
a863 1
		return -EINVAL;
d881 1
a881 1
		return -EINVAL;
d889 1
a889 1
		return -EINVAL;
d907 1
a907 1
		return -EINVAL;
d975 1
a975 1
		return -EINVAL;
d982 1
a982 1
		return -EINVAL;
d988 1
a988 1
		return -EINVAL;
d995 1
a995 1
		return -EINVAL;
d1004 1
a1004 1
			return -EINVAL;
d1022 1
a1022 1
			return -EINVAL;
d1176 1
a1176 1
				return -EINVAL;
d1183 1
a1183 1
			return -ENOMEM;
d1263 1
a1263 1
		return -EINVAL;
d1308 1
a1308 1
	return -EINVAL;
d1435 1
a1435 1
		return -EINVAL;
d1628 1
a1628 1
	return -EBUSY;
d1641 1
a1641 1
			return -EBUSY;	/* NOTE: broken client */
d1647 1
a1647 1
			return -EFAULT;
d1650 1
a1650 1
			return -EFAULT;
d1670 1
a1670 1
		return -EINVAL;
d1678 1
a1678 1
		return -EINVAL;
d1697 1
a1697 1
		return -ENOMEM;
@


1.7
log
@convert a tsleep back to msleep that got lost in a previous upstream merge.
Won't sleep with a spinlock here anymore.
@
text
@d1393 1
a1393 2
				msleep(&ret, &dev->dev_lock, PZERO,
				    "rdnrel", 1);
@


1.6
log
@Update to DRM git.

Some stability fixes for radeon. The most part of this diff is related
to fixing up the VBLANK (vertical blank interrupt) handling. Now, if the
X driver supports the DRM_IOCTL_MODESET_CTL ioctl, (to be used when
changing the video modes), then allow the vblank to be disabled once
that ioctl has been called. Otherwise, keep the interrupt enabled at all
time, since disabling it otherwise will lead to problems.

Tested by a few. "no problem" on API/ABI deraadt@@.
@
text
@d1393 2
a1394 1
				tsleep(&ret, PZERO, "rdnrel", 1);
@


1.5
log
@Switch all instances of malloc/free in the DRM to drm_alloc, drm_free
and drm_calloc.

With the recent change to check overflow in drm_calloc, this means that
all allocations that require multiplication are now checked. Also use
drm_calloc() when zeroing is needed and drop the bzero/memset
afterwards.  Finally, make drm_free() check for NULL, so we don't need
to do so every time.

ok miod@@, deraadt@@
@
text
@d226 3
d255 3
a895 11
	switch(init->func) {
	case RADEON_INIT_R200_CP:
		dev_priv->microcode_version = UCODE_R200;
		break;
	case RADEON_INIT_R300_CP:
		dev_priv->microcode_version = UCODE_R300;
		break;
	default:
		dev_priv->microcode_version = UCODE_R100;
	}

d943 1
a943 2
					   (dev_priv->microcode_version ==
					    UCODE_R100 ? RADEON_ZBLOCK16 : 0));
d1149 1
a1149 1
			drm_core_ioremap(&dev_priv->gart_info.mapping, dev);
d1721 1
@


1.4
log
@Remove some debug code that i forgot to remove in a previous commit.

Pointed out by Chris Cappuccio, thanks!
@
text
@d1701 1
a1701 1
	dev_priv = drm_alloc(sizeof(drm_radeon_private_t), DRM_MEM_DRIVER);
a1704 1
	memset(dev_priv, 0, sizeof(drm_radeon_private_t));
@


1.3
log
@Update the radeondrm driver to be level with drm git.

adds:

- support for RS400 chips
- some cleanup of a few things
- fixes a hard lockup for r3-500 cards.

Tested by a few
@
text
@a225 3
	DRM_INFO("wait for fifo failed status : 0x%08X 0x%08X\n",
		 RADEON_READ(RADEON_RBBM_STATUS),
		 RADEON_READ(R300_VAP_CNTL_STATUS));
a251 3
	DRM_INFO("wait idle failed status : 0x%08X 0x%08X\n",
		 RADEON_READ(RADEON_RBBM_STATUS),
		 RADEON_READ(R300_VAP_CNTL_STATUS));
@


1.2
log
@Update to DRM git as of a few days ago. This mostly affects the
card-specific files with a few minor changes elsewhere.

The main change to the OpenBSD specific stuff is the change to the irq
api due to the vblank rework.

4 more large bugs known, I have a fix for one.

Tested by many.  prompted by deraadt@@.
@
text
@d42 1
d130 4
d202 2
a203 17
		/* 3D */
		tmp = RADEON_READ(R300_RB3D_DSTCACHE_CTLSTAT);
		tmp |= RADEON_RB3D_DC_FLUSH_ALL;
		RADEON_WRITE(R300_RB3D_DSTCACHE_CTLSTAT, tmp);

		/* 2D */
		tmp = RADEON_READ(RADEON_RB2D_DSTCACHE_CTLSTAT);
		tmp |= RADEON_RB3D_DC_FLUSH_ALL;
		RADEON_WRITE(RADEON_RB3D_DSTCACHE_CTLSTAT, tmp);

		for (i = 0; i < dev_priv->usec_timeout; i++) {
			if (!(RADEON_READ(RADEON_RB2D_DSTCACHE_CTLSTAT)
			  & RADEON_RB3D_DC_BUSY)) {
				return 0;
			}
			DRM_UDELAY(1);
		}
d226 3
d255 3
d351 1
d440 7
a446 2
	BEGIN_RING(6);

a449 1

d452 2
d747 1
a747 8
		if ((dev_priv->flags & RADEON_FAMILY_MASK) == CHIP_RS690) {
			IGP_WRITE_MCIND(RS690_MC_AGP_BASE,
					(unsigned int)dev_priv->gart_vm_start);
			IGP_WRITE_MCIND(RS690_MC_AGP_BASE_2, 0);
		} else {
			RADEON_WRITE(RADEON_AGP_BASE, (unsigned int)dev_priv->gart_vm_start);
			RADEON_WRITE(RS480_AGP_BASE_2, 0);
		}
d1295 1
@


1.1
log
@Initial import of the DRM (direct rendering manager).

This is the kernel part necessary for DRI support in X. Disabled for now
because it still has a few bugs, but now I can work on it in tree. Also
requires the requisite bits in X, which are currently under discussion
on how to deal with them with privsep. ported from a combination of the
free and netbsd implementations.

Known bugs:
1) only the first occurence of X in any session will have dri, after
that something prevents it working.
2) if the machine does not have a dri capable card, the kernel panics.
Something's up in one of the probe functions. I haven't been able to
find it though.
3) radeon cards need to be forced to use PCI mode otherwise they get
into an infinite loop.

This is known to at least kinda work with SiS, radeons in pci mode and
intel cards.

ok deraadt, kinda ok art, a few other people had a quick look.
@
text
@d5 1
d38 2
a39 1
#define RADEON_FIFO_DEBUG	1
d43 92
a134 777
/* CP microcode (from ATI) */
static const u32 R200_cp_microcode[][2] = {
	{0x21007000, 0000000000},
	{0x20007000, 0000000000},
	{0x000000ab, 0x00000004},
	{0x000000af, 0x00000004},
	{0x66544a49, 0000000000},
	{0x49494174, 0000000000},
	{0x54517d83, 0000000000},
	{0x498d8b64, 0000000000},
	{0x49494949, 0000000000},
	{0x49da493c, 0000000000},
	{0x49989898, 0000000000},
	{0xd34949d5, 0000000000},
	{0x9dc90e11, 0000000000},
	{0xce9b9b9b, 0000000000},
	{0x000f0000, 0x00000016},
	{0x352e232c, 0000000000},
	{0x00000013, 0x00000004},
	{0x000f0000, 0x00000016},
	{0x352e272c, 0000000000},
	{0x000f0001, 0x00000016},
	{0x3239362f, 0000000000},
	{0x000077ef, 0x00000002},
	{0x00061000, 0x00000002},
	{0x00000020, 0x0000001a},
	{0x00004000, 0x0000001e},
	{0x00061000, 0x00000002},
	{0x00000020, 0x0000001a},
	{0x00004000, 0x0000001e},
	{0x00061000, 0x00000002},
	{0x00000020, 0x0000001a},
	{0x00004000, 0x0000001e},
	{0x00000016, 0x00000004},
	{0x0003802a, 0x00000002},
	{0x040067e0, 0x00000002},
	{0x00000016, 0x00000004},
	{0x000077e0, 0x00000002},
	{0x00065000, 0x00000002},
	{0x000037e1, 0x00000002},
	{0x040067e1, 0x00000006},
	{0x000077e0, 0x00000002},
	{0x000077e1, 0x00000002},
	{0x000077e1, 0x00000006},
	{0xffffffff, 0000000000},
	{0x10000000, 0000000000},
	{0x0003802a, 0x00000002},
	{0x040067e0, 0x00000006},
	{0x00007675, 0x00000002},
	{0x00007676, 0x00000002},
	{0x00007677, 0x00000002},
	{0x00007678, 0x00000006},
	{0x0003802b, 0x00000002},
	{0x04002676, 0x00000002},
	{0x00007677, 0x00000002},
	{0x00007678, 0x00000006},
	{0x0000002e, 0x00000018},
	{0x0000002e, 0x00000018},
	{0000000000, 0x00000006},
	{0x0000002f, 0x00000018},
	{0x0000002f, 0x00000018},
	{0000000000, 0x00000006},
	{0x01605000, 0x00000002},
	{0x00065000, 0x00000002},
	{0x00098000, 0x00000002},
	{0x00061000, 0x00000002},
	{0x64c0603d, 0x00000004},
	{0x00080000, 0x00000016},
	{0000000000, 0000000000},
	{0x0400251d, 0x00000002},
	{0x00007580, 0x00000002},
	{0x00067581, 0x00000002},
	{0x04002580, 0x00000002},
	{0x00067581, 0x00000002},
	{0x00000046, 0x00000004},
	{0x00005000, 0000000000},
	{0x00061000, 0x00000002},
	{0x0000750e, 0x00000002},
	{0x00019000, 0x00000002},
	{0x00011055, 0x00000014},
	{0x00000055, 0x00000012},
	{0x0400250f, 0x00000002},
	{0x0000504a, 0x00000004},
	{0x00007565, 0x00000002},
	{0x00007566, 0x00000002},
	{0x00000051, 0x00000004},
	{0x01e655b4, 0x00000002},
	{0x4401b0dc, 0x00000002},
	{0x01c110dc, 0x00000002},
	{0x2666705d, 0x00000018},
	{0x040c2565, 0x00000002},
	{0x0000005d, 0x00000018},
	{0x04002564, 0x00000002},
	{0x00007566, 0x00000002},
	{0x00000054, 0x00000004},
	{0x00401060, 0x00000008},
	{0x00101000, 0x00000002},
	{0x000d80ff, 0x00000002},
	{0x00800063, 0x00000008},
	{0x000f9000, 0x00000002},
	{0x000e00ff, 0x00000002},
	{0000000000, 0x00000006},
	{0x00000080, 0x00000018},
	{0x00000054, 0x00000004},
	{0x00007576, 0x00000002},
	{0x00065000, 0x00000002},
	{0x00009000, 0x00000002},
	{0x00041000, 0x00000002},
	{0x0c00350e, 0x00000002},
	{0x00049000, 0x00000002},
	{0x00051000, 0x00000002},
	{0x01e785f8, 0x00000002},
	{0x00200000, 0x00000002},
	{0x00600073, 0x0000000c},
	{0x00007563, 0x00000002},
	{0x006075f0, 0x00000021},
	{0x20007068, 0x00000004},
	{0x00005068, 0x00000004},
	{0x00007576, 0x00000002},
	{0x00007577, 0x00000002},
	{0x0000750e, 0x00000002},
	{0x0000750f, 0x00000002},
	{0x00a05000, 0x00000002},
	{0x00600076, 0x0000000c},
	{0x006075f0, 0x00000021},
	{0x000075f8, 0x00000002},
	{0x00000076, 0x00000004},
	{0x000a750e, 0x00000002},
	{0x0020750f, 0x00000002},
	{0x00600079, 0x00000004},
	{0x00007570, 0x00000002},
	{0x00007571, 0x00000002},
	{0x00007572, 0x00000006},
	{0x00005000, 0x00000002},
	{0x00a05000, 0x00000002},
	{0x00007568, 0x00000002},
	{0x00061000, 0x00000002},
	{0x00000084, 0x0000000c},
	{0x00058000, 0x00000002},
	{0x0c607562, 0x00000002},
	{0x00000086, 0x00000004},
	{0x00600085, 0x00000004},
	{0x400070dd, 0000000000},
	{0x000380dd, 0x00000002},
	{0x00000093, 0x0000001c},
	{0x00065095, 0x00000018},
	{0x040025bb, 0x00000002},
	{0x00061096, 0x00000018},
	{0x040075bc, 0000000000},
	{0x000075bb, 0x00000002},
	{0x000075bc, 0000000000},
	{0x00090000, 0x00000006},
	{0x00090000, 0x00000002},
	{0x000d8002, 0x00000006},
	{0x00005000, 0x00000002},
	{0x00007821, 0x00000002},
	{0x00007800, 0000000000},
	{0x00007821, 0x00000002},
	{0x00007800, 0000000000},
	{0x01665000, 0x00000002},
	{0x000a0000, 0x00000002},
	{0x000671cc, 0x00000002},
	{0x0286f1cd, 0x00000002},
	{0x000000a3, 0x00000010},
	{0x21007000, 0000000000},
	{0x000000aa, 0x0000001c},
	{0x00065000, 0x00000002},
	{0x000a0000, 0x00000002},
	{0x00061000, 0x00000002},
	{0x000b0000, 0x00000002},
	{0x38067000, 0x00000002},
	{0x000a00a6, 0x00000004},
	{0x20007000, 0000000000},
	{0x01200000, 0x00000002},
	{0x20077000, 0x00000002},
	{0x01200000, 0x00000002},
	{0x20007000, 0000000000},
	{0x00061000, 0x00000002},
	{0x0120751b, 0x00000002},
	{0x8040750a, 0x00000002},
	{0x8040750b, 0x00000002},
	{0x00110000, 0x00000002},
	{0x000380dd, 0x00000002},
	{0x000000bd, 0x0000001c},
	{0x00061096, 0x00000018},
	{0x844075bd, 0x00000002},
	{0x00061095, 0x00000018},
	{0x840075bb, 0x00000002},
	{0x00061096, 0x00000018},
	{0x844075bc, 0x00000002},
	{0x000000c0, 0x00000004},
	{0x804075bd, 0x00000002},
	{0x800075bb, 0x00000002},
	{0x804075bc, 0x00000002},
	{0x00108000, 0x00000002},
	{0x01400000, 0x00000002},
	{0x006000c4, 0x0000000c},
	{0x20c07000, 0x00000020},
	{0x000000c6, 0x00000012},
	{0x00800000, 0x00000006},
	{0x0080751d, 0x00000006},
	{0x000025bb, 0x00000002},
	{0x000040c0, 0x00000004},
	{0x0000775c, 0x00000002},
	{0x00a05000, 0x00000002},
	{0x00661000, 0x00000002},
	{0x0460275d, 0x00000020},
	{0x00004000, 0000000000},
	{0x00007999, 0x00000002},
	{0x00a05000, 0x00000002},
	{0x00661000, 0x00000002},
	{0x0460299b, 0x00000020},
	{0x00004000, 0000000000},
	{0x01e00830, 0x00000002},
	{0x21007000, 0000000000},
	{0x00005000, 0x00000002},
	{0x00038042, 0x00000002},
	{0x040025e0, 0x00000002},
	{0x000075e1, 0000000000},
	{0x00000001, 0000000000},
	{0x000380d9, 0x00000002},
	{0x04007394, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
};

static const u32 radeon_cp_microcode[][2] = {
	{0x21007000, 0000000000},
	{0x20007000, 0000000000},
	{0x000000b4, 0x00000004},
	{0x000000b8, 0x00000004},
	{0x6f5b4d4c, 0000000000},
	{0x4c4c427f, 0000000000},
	{0x5b568a92, 0000000000},
	{0x4ca09c6d, 0000000000},
	{0xad4c4c4c, 0000000000},
	{0x4ce1af3d, 0000000000},
	{0xd8afafaf, 0000000000},
	{0xd64c4cdc, 0000000000},
	{0x4cd10d10, 0000000000},
	{0x000f0000, 0x00000016},
	{0x362f242d, 0000000000},
	{0x00000012, 0x00000004},
	{0x000f0000, 0x00000016},
	{0x362f282d, 0000000000},
	{0x000380e7, 0x00000002},
	{0x04002c97, 0x00000002},
	{0x000f0001, 0x00000016},
	{0x333a3730, 0000000000},
	{0x000077ef, 0x00000002},
	{0x00061000, 0x00000002},
	{0x00000021, 0x0000001a},
	{0x00004000, 0x0000001e},
	{0x00061000, 0x00000002},
	{0x00000021, 0x0000001a},
	{0x00004000, 0x0000001e},
	{0x00061000, 0x00000002},
	{0x00000021, 0x0000001a},
	{0x00004000, 0x0000001e},
	{0x00000017, 0x00000004},
	{0x0003802b, 0x00000002},
	{0x040067e0, 0x00000002},
	{0x00000017, 0x00000004},
	{0x000077e0, 0x00000002},
	{0x00065000, 0x00000002},
	{0x000037e1, 0x00000002},
	{0x040067e1, 0x00000006},
	{0x000077e0, 0x00000002},
	{0x000077e1, 0x00000002},
	{0x000077e1, 0x00000006},
	{0xffffffff, 0000000000},
	{0x10000000, 0000000000},
	{0x0003802b, 0x00000002},
	{0x040067e0, 0x00000006},
	{0x00007675, 0x00000002},
	{0x00007676, 0x00000002},
	{0x00007677, 0x00000002},
	{0x00007678, 0x00000006},
	{0x0003802c, 0x00000002},
	{0x04002676, 0x00000002},
	{0x00007677, 0x00000002},
	{0x00007678, 0x00000006},
	{0x0000002f, 0x00000018},
	{0x0000002f, 0x00000018},
	{0000000000, 0x00000006},
	{0x00000030, 0x00000018},
	{0x00000030, 0x00000018},
	{0000000000, 0x00000006},
	{0x01605000, 0x00000002},
	{0x00065000, 0x00000002},
	{0x00098000, 0x00000002},
	{0x00061000, 0x00000002},
	{0x64c0603e, 0x00000004},
	{0x000380e6, 0x00000002},
	{0x040025c5, 0x00000002},
	{0x00080000, 0x00000016},
	{0000000000, 0000000000},
	{0x0400251d, 0x00000002},
	{0x00007580, 0x00000002},
	{0x00067581, 0x00000002},
	{0x04002580, 0x00000002},
	{0x00067581, 0x00000002},
	{0x00000049, 0x00000004},
	{0x00005000, 0000000000},
	{0x000380e6, 0x00000002},
	{0x040025c5, 0x00000002},
	{0x00061000, 0x00000002},
	{0x0000750e, 0x00000002},
	{0x00019000, 0x00000002},
	{0x00011055, 0x00000014},
	{0x00000055, 0x00000012},
	{0x0400250f, 0x00000002},
	{0x0000504f, 0x00000004},
	{0x000380e6, 0x00000002},
	{0x040025c5, 0x00000002},
	{0x00007565, 0x00000002},
	{0x00007566, 0x00000002},
	{0x00000058, 0x00000004},
	{0x000380e6, 0x00000002},
	{0x040025c5, 0x00000002},
	{0x01e655b4, 0x00000002},
	{0x4401b0e4, 0x00000002},
	{0x01c110e4, 0x00000002},
	{0x26667066, 0x00000018},
	{0x040c2565, 0x00000002},
	{0x00000066, 0x00000018},
	{0x04002564, 0x00000002},
	{0x00007566, 0x00000002},
	{0x0000005d, 0x00000004},
	{0x00401069, 0x00000008},
	{0x00101000, 0x00000002},
	{0x000d80ff, 0x00000002},
	{0x0080006c, 0x00000008},
	{0x000f9000, 0x00000002},
	{0x000e00ff, 0x00000002},
	{0000000000, 0x00000006},
	{0x0000008f, 0x00000018},
	{0x0000005b, 0x00000004},
	{0x000380e6, 0x00000002},
	{0x040025c5, 0x00000002},
	{0x00007576, 0x00000002},
	{0x00065000, 0x00000002},
	{0x00009000, 0x00000002},
	{0x00041000, 0x00000002},
	{0x0c00350e, 0x00000002},
	{0x00049000, 0x00000002},
	{0x00051000, 0x00000002},
	{0x01e785f8, 0x00000002},
	{0x00200000, 0x00000002},
	{0x0060007e, 0x0000000c},
	{0x00007563, 0x00000002},
	{0x006075f0, 0x00000021},
	{0x20007073, 0x00000004},
	{0x00005073, 0x00000004},
	{0x000380e6, 0x00000002},
	{0x040025c5, 0x00000002},
	{0x00007576, 0x00000002},
	{0x00007577, 0x00000002},
	{0x0000750e, 0x00000002},
	{0x0000750f, 0x00000002},
	{0x00a05000, 0x00000002},
	{0x00600083, 0x0000000c},
	{0x006075f0, 0x00000021},
	{0x000075f8, 0x00000002},
	{0x00000083, 0x00000004},
	{0x000a750e, 0x00000002},
	{0x000380e6, 0x00000002},
	{0x040025c5, 0x00000002},
	{0x0020750f, 0x00000002},
	{0x00600086, 0x00000004},
	{0x00007570, 0x00000002},
	{0x00007571, 0x00000002},
	{0x00007572, 0x00000006},
	{0x000380e6, 0x00000002},
	{0x040025c5, 0x00000002},
	{0x00005000, 0x00000002},
	{0x00a05000, 0x00000002},
	{0x00007568, 0x00000002},
	{0x00061000, 0x00000002},
	{0x00000095, 0x0000000c},
	{0x00058000, 0x00000002},
	{0x0c607562, 0x00000002},
	{0x00000097, 0x00000004},
	{0x000380e6, 0x00000002},
	{0x040025c5, 0x00000002},
	{0x00600096, 0x00000004},
	{0x400070e5, 0000000000},
	{0x000380e6, 0x00000002},
	{0x040025c5, 0x00000002},
	{0x000380e5, 0x00000002},
	{0x000000a8, 0x0000001c},
	{0x000650aa, 0x00000018},
	{0x040025bb, 0x00000002},
	{0x000610ab, 0x00000018},
	{0x040075bc, 0000000000},
	{0x000075bb, 0x00000002},
	{0x000075bc, 0000000000},
	{0x00090000, 0x00000006},
	{0x00090000, 0x00000002},
	{0x000d8002, 0x00000006},
	{0x00007832, 0x00000002},
	{0x00005000, 0x00000002},
	{0x000380e7, 0x00000002},
	{0x04002c97, 0x00000002},
	{0x00007820, 0x00000002},
	{0x00007821, 0x00000002},
	{0x00007800, 0000000000},
	{0x01200000, 0x00000002},
	{0x20077000, 0x00000002},
	{0x01200000, 0x00000002},
	{0x20007000, 0x00000002},
	{0x00061000, 0x00000002},
	{0x0120751b, 0x00000002},
	{0x8040750a, 0x00000002},
	{0x8040750b, 0x00000002},
	{0x00110000, 0x00000002},
	{0x000380e5, 0x00000002},
	{0x000000c6, 0x0000001c},
	{0x000610ab, 0x00000018},
	{0x844075bd, 0x00000002},
	{0x000610aa, 0x00000018},
	{0x840075bb, 0x00000002},
	{0x000610ab, 0x00000018},
	{0x844075bc, 0x00000002},
	{0x000000c9, 0x00000004},
	{0x804075bd, 0x00000002},
	{0x800075bb, 0x00000002},
	{0x804075bc, 0x00000002},
	{0x00108000, 0x00000002},
	{0x01400000, 0x00000002},
	{0x006000cd, 0x0000000c},
	{0x20c07000, 0x00000020},
	{0x000000cf, 0x00000012},
	{0x00800000, 0x00000006},
	{0x0080751d, 0x00000006},
	{0000000000, 0000000000},
	{0x0000775c, 0x00000002},
	{0x00a05000, 0x00000002},
	{0x00661000, 0x00000002},
	{0x0460275d, 0x00000020},
	{0x00004000, 0000000000},
	{0x01e00830, 0x00000002},
	{0x21007000, 0000000000},
	{0x6464614d, 0000000000},
	{0x69687420, 0000000000},
	{0x00000073, 0000000000},
	{0000000000, 0000000000},
	{0x00005000, 0x00000002},
	{0x000380d0, 0x00000002},
	{0x040025e0, 0x00000002},
	{0x000075e1, 0000000000},
	{0x00000001, 0000000000},
	{0x000380e0, 0x00000002},
	{0x04002394, 0x00000002},
	{0x00005000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0x00000008, 0000000000},
	{0x00000004, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
	{0000000000, 0000000000},
};

static const u32 R300_cp_microcode[][2] = {
	{ 0x4200e000, 0000000000 },
	{ 0x4000e000, 0000000000 },
	{ 0x000000af, 0x00000008 },
	{ 0x000000b3, 0x00000008 },
	{ 0x6c5a504f, 0000000000 },
	{ 0x4f4f497a, 0000000000 },
	{ 0x5a578288, 0000000000 },
	{ 0x4f91906a, 0000000000 },
	{ 0x4f4f4f4f, 0000000000 },
	{ 0x4fe24f44, 0000000000 },
	{ 0x4f9c9c9c, 0000000000 },
	{ 0xdc4f4fde, 0000000000 },
	{ 0xa1cd4f4f, 0000000000 },
	{ 0xd29d9d9d, 0000000000 },
	{ 0x4f0f9fd7, 0000000000 },
	{ 0x000ca000, 0x00000004 },
	{ 0x000d0012, 0x00000038 },
	{ 0x0000e8b4, 0x00000004 },
	{ 0x000d0014, 0x00000038 },
	{ 0x0000e8b6, 0x00000004 },
	{ 0x000d0016, 0x00000038 },
	{ 0x0000e854, 0x00000004 },
	{ 0x000d0018, 0x00000038 },
	{ 0x0000e855, 0x00000004 },
	{ 0x000d001a, 0x00000038 },
	{ 0x0000e856, 0x00000004 },
	{ 0x000d001c, 0x00000038 },
	{ 0x0000e857, 0x00000004 },
	{ 0x000d001e, 0x00000038 },
	{ 0x0000e824, 0x00000004 },
	{ 0x000d0020, 0x00000038 },
	{ 0x0000e825, 0x00000004 },
	{ 0x000d0022, 0x00000038 },
	{ 0x0000e830, 0x00000004 },
	{ 0x000d0024, 0x00000038 },
	{ 0x0000f0c0, 0x00000004 },
	{ 0x000d0026, 0x00000038 },
	{ 0x0000f0c1, 0x00000004 },
	{ 0x000d0028, 0x00000038 },
	{ 0x0000f041, 0x00000004 },
	{ 0x000d002a, 0x00000038 },
	{ 0x0000f184, 0x00000004 },
	{ 0x000d002c, 0x00000038 },
	{ 0x0000f185, 0x00000004 },
	{ 0x000d002e, 0x00000038 },
	{ 0x0000f186, 0x00000004 },
	{ 0x000d0030, 0x00000038 },
	{ 0x0000f187, 0x00000004 },
	{ 0x000d0032, 0x00000038 },
	{ 0x0000f180, 0x00000004 },
	{ 0x000d0034, 0x00000038 },
	{ 0x0000f393, 0x00000004 },
	{ 0x000d0036, 0x00000038 },
	{ 0x0000f38a, 0x00000004 },
	{ 0x000d0038, 0x00000038 },
	{ 0x0000f38e, 0x00000004 },
	{ 0x0000e821, 0x00000004 },
	{ 0x0140a000, 0x00000004 },
	{ 0x00000043, 0x00000018 },
	{ 0x00cce800, 0x00000004 },
	{ 0x001b0001, 0x00000004 },
	{ 0x08004800, 0x00000004 },
	{ 0x001b0001, 0x00000004 },
	{ 0x08004800, 0x00000004 },
	{ 0x001b0001, 0x00000004 },
	{ 0x08004800, 0x00000004 },
	{ 0x0000003a, 0x00000008 },
	{ 0x0000a000, 0000000000 },
	{ 0x02c0a000, 0x00000004 },
	{ 0x000ca000, 0x00000004 },
	{ 0x00130000, 0x00000004 },
	{ 0x000c2000, 0x00000004 },
	{ 0xc980c045, 0x00000008 },
	{ 0x2000451d, 0x00000004 },
	{ 0x0000e580, 0x00000004 },
	{ 0x000ce581, 0x00000004 },
	{ 0x08004580, 0x00000004 },
	{ 0x000ce581, 0x00000004 },
	{ 0x0000004c, 0x00000008 },
	{ 0x0000a000, 0000000000 },
	{ 0x000c2000, 0x00000004 },
	{ 0x0000e50e, 0x00000004 },
	{ 0x00032000, 0x00000004 },
	{ 0x00022056, 0x00000028 },
	{ 0x00000056, 0x00000024 },
	{ 0x0800450f, 0x00000004 },
	{ 0x0000a050, 0x00000008 },
	{ 0x0000e565, 0x00000004 },
	{ 0x0000e566, 0x00000004 },
	{ 0x00000057, 0x00000008 },
	{ 0x03cca5b4, 0x00000004 },
	{ 0x05432000, 0x00000004 },
	{ 0x00022000, 0x00000004 },
	{ 0x4ccce063, 0x00000030 },
	{ 0x08274565, 0x00000004 },
	{ 0x00000063, 0x00000030 },
	{ 0x08004564, 0x00000004 },
	{ 0x0000e566, 0x00000004 },
	{ 0x0000005a, 0x00000008 },
	{ 0x00802066, 0x00000010 },
	{ 0x00202000, 0x00000004 },
	{ 0x001b00ff, 0x00000004 },
	{ 0x01000069, 0x00000010 },
	{ 0x001f2000, 0x00000004 },
	{ 0x001c00ff, 0x00000004 },
	{ 0000000000, 0x0000000c },
	{ 0x00000085, 0x00000030 },
	{ 0x0000005a, 0x00000008 },
	{ 0x0000e576, 0x00000004 },
	{ 0x000ca000, 0x00000004 },
	{ 0x00012000, 0x00000004 },
	{ 0x00082000, 0x00000004 },
	{ 0x1800650e, 0x00000004 },
	{ 0x00092000, 0x00000004 },
	{ 0x000a2000, 0x00000004 },
	{ 0x000f0000, 0x00000004 },
	{ 0x00400000, 0x00000004 },
	{ 0x00000079, 0x00000018 },
	{ 0x0000e563, 0x00000004 },
	{ 0x00c0e5f9, 0x000000c2 },
	{ 0x0000006e, 0x00000008 },
	{ 0x0000a06e, 0x00000008 },
	{ 0x0000e576, 0x00000004 },
	{ 0x0000e577, 0x00000004 },
	{ 0x0000e50e, 0x00000004 },
	{ 0x0000e50f, 0x00000004 },
	{ 0x0140a000, 0x00000004 },
	{ 0x0000007c, 0x00000018 },
	{ 0x00c0e5f9, 0x000000c2 },
	{ 0x0000007c, 0x00000008 },
	{ 0x0014e50e, 0x00000004 },
	{ 0x0040e50f, 0x00000004 },
	{ 0x00c0007f, 0x00000008 },
	{ 0x0000e570, 0x00000004 },
	{ 0x0000e571, 0x00000004 },
	{ 0x0000e572, 0x0000000c },
	{ 0x0000a000, 0x00000004 },
	{ 0x0140a000, 0x00000004 },
	{ 0x0000e568, 0x00000004 },
	{ 0x000c2000, 0x00000004 },
	{ 0x00000089, 0x00000018 },
	{ 0x000b0000, 0x00000004 },
	{ 0x18c0e562, 0x00000004 },
	{ 0x0000008b, 0x00000008 },
	{ 0x00c0008a, 0x00000008 },
	{ 0x000700e4, 0x00000004 },
	{ 0x00000097, 0x00000038 },
	{ 0x000ca099, 0x00000030 },
	{ 0x080045bb, 0x00000004 },
	{ 0x000c209a, 0x00000030 },
	{ 0x0800e5bc, 0000000000 },
	{ 0x0000e5bb, 0x00000004 },
	{ 0x0000e5bc, 0000000000 },
	{ 0x00120000, 0x0000000c },
	{ 0x00120000, 0x00000004 },
	{ 0x001b0002, 0x0000000c },
	{ 0x0000a000, 0x00000004 },
	{ 0x0000e821, 0x00000004 },
	{ 0x0000e800, 0000000000 },
	{ 0x0000e821, 0x00000004 },
	{ 0x0000e82e, 0000000000 },
	{ 0x02cca000, 0x00000004 },
	{ 0x00140000, 0x00000004 },
	{ 0x000ce1cc, 0x00000004 },
	{ 0x050de1cd, 0x00000004 },
	{ 0x000000a7, 0x00000020 },
	{ 0x4200e000, 0000000000 },
	{ 0x000000ae, 0x00000038 },
	{ 0x000ca000, 0x00000004 },
	{ 0x00140000, 0x00000004 },
	{ 0x000c2000, 0x00000004 },
	{ 0x00160000, 0x00000004 },
	{ 0x700ce000, 0x00000004 },
	{ 0x001400aa, 0x00000008 },
	{ 0x4000e000, 0000000000 },
	{ 0x02400000, 0x00000004 },
	{ 0x400ee000, 0x00000004 },
	{ 0x02400000, 0x00000004 },
	{ 0x4000e000, 0000000000 },
	{ 0x000c2000, 0x00000004 },
	{ 0x0240e51b, 0x00000004 },
	{ 0x0080e50a, 0x00000005 },
	{ 0x0080e50b, 0x00000005 },
	{ 0x00220000, 0x00000004 },
	{ 0x000700e4, 0x00000004 },
	{ 0x000000c1, 0x00000038 },
	{ 0x000c209a, 0x00000030 },
	{ 0x0880e5bd, 0x00000005 },
	{ 0x000c2099, 0x00000030 },
	{ 0x0800e5bb, 0x00000005 },
	{ 0x000c209a, 0x00000030 },
	{ 0x0880e5bc, 0x00000005 },
	{ 0x000000c4, 0x00000008 },
	{ 0x0080e5bd, 0x00000005 },
	{ 0x0000e5bb, 0x00000005 },
	{ 0x0080e5bc, 0x00000005 },
	{ 0x00210000, 0x00000004 },
	{ 0x02800000, 0x00000004 },
	{ 0x00c000c8, 0x00000018 },
	{ 0x4180e000, 0x00000040 },
	{ 0x000000ca, 0x00000024 },
	{ 0x01000000, 0x0000000c },
	{ 0x0100e51d, 0x0000000c },
	{ 0x000045bb, 0x00000004 },
	{ 0x000080c4, 0x00000008 },
	{ 0x0000f3ce, 0x00000004 },
	{ 0x0140a000, 0x00000004 },
	{ 0x00cc2000, 0x00000004 },
	{ 0x08c053cf, 0x00000040 },
	{ 0x00008000, 0000000000 },
	{ 0x0000f3d2, 0x00000004 },
	{ 0x0140a000, 0x00000004 },
	{ 0x00cc2000, 0x00000004 },
	{ 0x08c053d3, 0x00000040 },
	{ 0x00008000, 0000000000 },
	{ 0x0000f39d, 0x00000004 },
	{ 0x0140a000, 0x00000004 },
	{ 0x00cc2000, 0x00000004 },
	{ 0x08c0539e, 0x00000040 },
	{ 0x00008000, 0000000000 },
	{ 0x03c00830, 0x00000004 },
	{ 0x4200e000, 0000000000 },
	{ 0x0000a000, 0x00000004 },
	{ 0x200045e0, 0x00000004 },
	{ 0x0000e5e1, 0000000000 },
	{ 0x00000001, 0000000000 },
	{ 0x000700e1, 0x00000004 },
	{ 0x0800e394, 0000000000 },
	{ 0000000000, 0000000000 },
	{ 0000000000, 0000000000 },
	{ 0000000000, 0000000000 },
	{ 0000000000, 0000000000 },
	{ 0000000000, 0000000000 },
	{ 0000000000, 0000000000 },
	{ 0000000000, 0000000000 },
	{ 0000000000, 0000000000 },
	{ 0000000000, 0000000000 },
	{ 0000000000, 0000000000 },
	{ 0000000000, 0000000000 },
	{ 0000000000, 0000000000 },
	{ 0000000000, 0000000000 },
	{ 0000000000, 0000000000 },
	{ 0000000000, 0000000000 },
	{ 0000000000, 0000000000 },
	{ 0000000000, 0000000000 },
	{ 0000000000, 0000000000 },
	{ 0000000000, 0000000000 },
	{ 0000000000, 0000000000 },
	{ 0000000000, 0000000000 },
	{ 0000000000, 0000000000 },
	{ 0000000000, 0000000000 },
	{ 0000000000, 0000000000 },
	{ 0000000000, 0000000000 },
	{ 0000000000, 0000000000 },
	{ 0000000000, 0000000000 },
	{ 0000000000, 0000000000 },
};
a149 9
static u32 RADEON_READ_IGPGART(drm_radeon_private_t *dev_priv, int addr)
{
	u32 ret;
	RADEON_WRITE(RADEON_IGPGART_INDEX, addr & 0x7f);
	ret = RADEON_READ(RADEON_IGPGART_DATA);
	RADEON_WRITE(RADEON_IGPGART_INDEX, 0x7f);
	return ret;
}

d184 29
a212 8
	tmp = RADEON_READ(RADEON_RB3D_DSTCACHE_CTLSTAT);
	tmp |= RADEON_RB3D_DC_FLUSH_ALL;
	RADEON_WRITE(RADEON_RB3D_DSTCACHE_CTLSTAT, tmp);

	for (i = 0; i < dev_priv->usec_timeout; i++) {
		if (!(RADEON_READ(RADEON_RB3D_DSTCACHE_CTLSTAT)
		      & RADEON_RB3D_DC_BUSY)) {
			return 0;
a213 1
		DRM_UDELAY(1);
d270 44
d328 16
a343 1
	if (dev_priv->microcode_version == UCODE_R200) {
d351 5
a355 1
	} else if (dev_priv->microcode_version == UCODE_R300) {
d363 24
a386 1
	} else {
d389 1
a389 1
				     radeon_cp_microcode[i][1]);
d391 1
a391 1
				     radeon_cp_microcode[i][0]);
d486 1
a486 1
	u32 clock_cntl_index, mclk_cntl, rbbm_soft_reset;
d491 13
a503 10
	clock_cntl_index = RADEON_READ(RADEON_CLOCK_CNTL_INDEX);
	mclk_cntl = RADEON_READ_PLL(dev, RADEON_MCLK_CNTL);

	RADEON_WRITE_PLL(RADEON_MCLK_CNTL, (mclk_cntl |
					    RADEON_FORCEON_MCLKA |
					    RADEON_FORCEON_MCLKB |
					    RADEON_FORCEON_YCLKA |
					    RADEON_FORCEON_YCLKB |
					    RADEON_FORCEON_MC |
					    RADEON_FORCEON_AIC));
d526 9
a534 3
	RADEON_WRITE_PLL(RADEON_MCLK_CNTL, mclk_cntl);
	RADEON_WRITE(RADEON_CLOCK_CNTL_INDEX, clock_cntl_index);
	RADEON_WRITE(RADEON_RBBM_SOFT_RESET, rbbm_soft_reset);
d560 1
a560 1
		RADEON_WRITE(RADEON_MC_FB_LOCATION,
d566 3
a568 2
		RADEON_WRITE(RADEON_AGP_BASE, (unsigned int)dev->agp->base);
		RADEON_WRITE(RADEON_MC_AGP_LOCATION,
d711 1
a711 1
	u32 temp, tmp;
a712 2
	tmp = RADEON_READ(RADEON_AIC_CNTL);
	DRM_DEBUG("setting igpgart AIC CNTL is %08X\n", tmp);
d714 1
a714 1
		DRM_DEBUG("programming igpgart %08X %08lX %08X\n",
d719 1
a719 5
		RADEON_WRITE_IGPGART(RADEON_IGPGART_UNK_18, 0x1000);
		RADEON_WRITE_IGPGART(RADEON_IGPGART_ENABLE, 0x1);
		RADEON_WRITE_IGPGART(RADEON_IGPGART_CTRL, 0x42040800);
		RADEON_WRITE_IGPGART(RADEON_IGPGART_BASE_ADDR,
				     dev_priv->gart_info.bus_addr);
d721 31
a751 2
		temp = RADEON_READ_IGPGART(dev_priv, RADEON_IGPGART_UNK_39);
		RADEON_WRITE_IGPGART(RADEON_IGPGART_UNK_39, temp);
a752 1
		RADEON_WRITE(RADEON_AGP_BASE, (unsigned int)dev_priv->gart_vm_start);
d754 18
a771 4
		RADEON_WRITE(RADEON_MC_AGP_LOCATION,
			     (((dev_priv->gart_vm_start - 1 +
			       dev_priv->gart_size) & 0xffff0000) |
			     (dev_priv->gart_vm_start >> 16)));
d773 6
a778 2
		temp = RADEON_READ_IGPGART(dev_priv, RADEON_IGPGART_ENABLE);
		RADEON_WRITE_IGPGART(RADEON_IGPGART_ENABLE, temp);
d780 4
a783 5
		RADEON_READ_IGPGART(dev_priv, RADEON_IGPGART_FLUSH);
		RADEON_WRITE_IGPGART(RADEON_IGPGART_FLUSH, 0x1);
		RADEON_READ_IGPGART(dev_priv, RADEON_IGPGART_FLUSH);
		RADEON_WRITE_IGPGART(RADEON_IGPGART_FLUSH, 0x0);
       }
d805 1
a805 1
		RADEON_WRITE(RADEON_MC_AGP_LOCATION, 0xffffffc0);	/* ?? */
d820 2
a821 1
	if (dev_priv->flags & RADEON_IS_IGPGART) {
d849 1
a849 1
		RADEON_WRITE(RADEON_MC_AGP_LOCATION, 0xffffffc0);	/* ?? */
d1057 1
a1057 2
	dev_priv->fb_location = (RADEON_READ(RADEON_MC_FB_LOCATION)
				 & 0xffff) << 16;
d1059 1
a1059 1
		((RADEON_READ(RADEON_MC_FB_LOCATION) & 0xffff0000u) + 0x10000)
d1155 1
d1312 1
a1312 1
		r300_init_reg_flags();
d1334 1
a1334 1
		DRM_DEBUG("%s while CP running\n", __FUNCTION__);
d1338 2
a1339 2
		DRM_DEBUG("%s called with bogus CP mode (%d)\n",
			  __FUNCTION__, dev_priv->cp_mode);
d1404 2
a1405 1
				DRM_SLEEPLOCK(&ret, &dev->dev_lock, PZERO, "rdnrel",
d1407 3
d1449 1
a1449 1
		DRM_DEBUG("%s called before init done\n", __FUNCTION__);
d1726 4
@

