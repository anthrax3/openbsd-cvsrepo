head	1.43;
access;
symbols
	OPENBSD_6_1:1.42.0.4
	OPENBSD_6_1_BASE:1.42
	OPENBSD_6_0:1.25.0.8
	OPENBSD_6_0_BASE:1.25
	OPENBSD_5_9:1.25.0.2
	OPENBSD_5_9_BASE:1.25
	OPENBSD_5_8:1.25.0.4
	OPENBSD_5_8_BASE:1.25
	OPENBSD_5_7:1.24.0.4
	OPENBSD_5_7_BASE:1.24
	OPENBSD_5_6:1.17.0.4
	OPENBSD_5_6_BASE:1.17
	OPENBSD_5_5:1.13.0.4
	OPENBSD_5_5_BASE:1.13
	OPENBSD_5_4:1.12.0.4
	OPENBSD_5_4_BASE:1.12
	OPENBSD_5_3:1.12.0.2
	OPENBSD_5_3_BASE:1.12;
locks; strict;
comment	@ * @;


1.43
date	2017.04.08.02.57.25;	author deraadt;	state Exp;
branches;
next	1.42;
commitid	6s3MfY9d6ZKdL2Uz;

1.42
date	2017.02.11.04.12.28;	author dlg;	state Exp;
branches;
next	1.41;
commitid	6kesBBgzlCwI3ezn;

1.41
date	2017.02.08.07.06.43;	author dlg;	state Exp;
branches;
next	1.40;
commitid	3wTawdgRvbzDLKIt;

1.40
date	2017.02.07.05.08.53;	author dlg;	state Exp;
branches;
next	1.39;
commitid	GigTHPGnY7Xy3ty1;

1.39
date	2017.02.07.04.43.59;	author dlg;	state Exp;
branches;
next	1.38;
commitid	hBk66MYTgCzBlzYP;

1.38
date	2017.02.07.04.42.56;	author dlg;	state Exp;
branches;
next	1.37;
commitid	dsVa834bdEEFjCEp;

1.37
date	2017.02.07.03.14.53;	author dlg;	state Exp;
branches;
next	1.36;
commitid	Ak7U4winhygvbD2F;

1.36
date	2017.02.07.02.47.19;	author dlg;	state Exp;
branches;
next	1.35;
commitid	cH6LSugruPho9e3b;

1.35
date	2017.02.07.00.25.40;	author dlg;	state Exp;
branches;
next	1.34;
commitid	edUbWKpk0KKxT42l;

1.34
date	2017.02.06.07.04.31;	author dlg;	state Exp;
branches;
next	1.33;
commitid	cjHKAQ4RwpdSosJc;

1.33
date	2017.02.06.06.16.36;	author dlg;	state Exp;
branches;
next	1.32;
commitid	E2mpsCOmI3ei7chT;

1.32
date	2017.01.23.05.18.45;	author dlg;	state Exp;
branches;
next	1.31;
commitid	zOn8Oe0KDoNPoq3l;

1.31
date	2017.01.23.04.26.57;	author dlg;	state Exp;
branches;
next	1.30;
commitid	NY4GwH9K5t06AQNj;

1.30
date	2017.01.23.04.25.02;	author dlg;	state Exp;
branches;
next	1.29;
commitid	ld5CIyJoUifKhJx5;

1.29
date	2017.01.23.01.10.31;	author dlg;	state Exp;
branches;
next	1.28;
commitid	7pJZ4RqwhUBfuMRS;

1.28
date	2016.10.24.05.27.52;	author yasuoka;	state Exp;
branches;
next	1.27;
commitid	yJ7W3lppMOyZ9hui;

1.27
date	2016.10.24.03.45.48;	author yasuoka;	state Exp;
branches;
next	1.26;
commitid	9XBEYrlw7qFRmvYT;

1.26
date	2016.10.24.03.11.58;	author yasuoka;	state Exp;
branches;
next	1.25;
commitid	yokESni4FH9yeoF6;

1.25
date	2015.03.14.03.38.48;	author jsg;	state Exp;
branches;
next	1.24;
commitid	p4LJxGKbi0BU2cG6;

1.24
date	2015.01.09.03.34.40;	author dlg;	state Exp;
branches;
next	1.23;
commitid	b149VTnWJQOtRiYy;

1.23
date	2015.01.07.10.26.48;	author dlg;	state Exp;
branches;
next	1.22;
commitid	7uX1sGCc9834mOlA;

1.22
date	2015.01.07.04.56.56;	author dlg;	state Exp;
branches;
next	1.21;
commitid	WbG9SAIOPQlZzwPb;

1.21
date	2015.01.07.04.46.18;	author dlg;	state Exp;
branches;
next	1.20;
commitid	XqnsQdj75kfrrlkX;

1.20
date	2015.01.05.23.18.36;	author dlg;	state Exp;
branches;
next	1.19;
commitid	CEsVOUyXFQc0QRNf;

1.19
date	2014.10.08.14.44.39;	author dlg;	state Exp;
branches;
next	1.18;
commitid	texmUe0rD17BfpER;

1.18
date	2014.09.30.18.02.33;	author kettenis;	state Exp;
branches;
next	1.17;
commitid	CXrnjExFgakphr0u;

1.17
date	2014.07.13.23.10.23;	author deraadt;	state Exp;
branches;
next	1.16;
commitid	JtO5uXxVcnZfhUkR;

1.16
date	2014.07.12.18.48.52;	author tedu;	state Exp;
branches;
next	1.15;
commitid	OBNa5kfxQ2UXoiIw;

1.15
date	2014.03.28.22.25.49;	author dlg;	state Exp;
branches;
next	1.14;

1.14
date	2014.03.27.23.17.40;	author dlg;	state Exp;
branches;
next	1.13;

1.13
date	2013.08.30.08.51.56;	author haesbaert;	state Exp;
branches;
next	1.12;

1.12
date	2012.08.25.07.03.04;	author haesbaert;	state Exp;
branches;
next	1.11;

1.11
date	2012.08.25.07.01.35;	author haesbaert;	state Exp;
branches;
next	1.10;

1.10
date	2012.08.23.11.18.53;	author dlg;	state Exp;
branches;
next	1.9;

1.9
date	2012.08.23.07.21.06;	author dlg;	state Exp;
branches;
next	1.8;

1.8
date	2012.08.23.05.52.05;	author dlg;	state Exp;
branches;
next	1.7;

1.7
date	2012.08.20.07.38.43;	author dlg;	state Exp;
branches;
next	1.6;

1.6
date	2012.08.16.07.55.08;	author dlg;	state Exp;
branches;
next	1.5;

1.5
date	2012.08.16.04.41.49;	author dlg;	state Exp;
branches;
next	1.4;

1.4
date	2012.08.16.04.36.37;	author dlg;	state Exp;
branches;
next	1.3;

1.3
date	2012.08.16.04.28.36;	author dlg;	state Exp;
branches;
next	1.2;

1.2
date	2012.08.16.03.50.14;	author dlg;	state Exp;
branches;
next	1.1;

1.1
date	2012.08.14.00.27.51;	author dlg;	state Exp;
branches;
next	;


desc
@@


1.43
log
@A pile of sizes to free(9).  In test for a few days in snapshots.
Errors will result in nice clean panic messages so we know what's wrong.
Reviewed by dhill visa natano jsg.
@
text
@/* $OpenBSD: mfii.c,v 1.42 2017/02/11 04:12:28 dlg Exp $ */

/*
 * Copyright (c) 2012 David Gwynne <dlg@@openbsd.org>
 *
 * Permission to use, copy, modify, and distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 */

#include "bio.h"

#include <sys/param.h>
#include <sys/systm.h>
#include <sys/malloc.h>
#include <sys/device.h>
#include <sys/types.h>
#include <sys/pool.h>
#include <sys/task.h>
#include <sys/atomic.h>

#include <dev/pci/pcidevs.h>
#include <dev/pci/pcivar.h>

#include <machine/bus.h>

#include <scsi/scsi_all.h>
#include <scsi/scsi_disk.h>
#include <scsi/scsiconf.h>

#include <dev/ic/mfireg.h>
#include <dev/pci/mpiireg.h>

#define	MFII_BAR		0x14
#define	MFII_PCI_MEMSIZE	0x2000 /* 8k */

#define MFII_OSTS_INTR_VALID	0x00000009
#define MFII_RPI		0x6c /* reply post host index */

#define MFII_REQ_TYPE_SCSI	MPII_REQ_DESCR_SCSI_IO
#define MFII_REQ_TYPE_LDIO	(0x7 << 1)
#define MFII_REQ_TYPE_MFA	(0x1 << 1)
#define MFII_REQ_TYPE_NO_LOCK	(0x2 << 1)
#define MFII_REQ_TYPE_HI_PRI	(0x6 << 1)

#define MFII_REQ_MFA(_a)	htole64((_a) | MFII_REQ_TYPE_MFA)

#define MFII_FUNCTION_PASSTHRU_IO			(0xf0)
#define MFII_FUNCTION_LDIO_REQUEST			(0xf1)

struct mfii_request_descr {
	u_int8_t	flags;
	u_int8_t	msix_index;
	u_int16_t	smid;

	u_int16_t	lmid;
	u_int16_t	dev_handle;
} __packed;

#define MFII_RAID_CTX_IO_TYPE_SYSPD	(0x1 << 4)
#define MFII_RAID_CTX_TYPE_CUDA		(0x2 << 4)

struct mfii_raid_context {
	u_int8_t	type_nseg;
	u_int8_t	_reserved1;
	u_int16_t	timeout_value;

	u_int8_t	reg_lock_flags;
#define MFII_RAID_CTX_RL_FLAGS_SEQNO_EN	(0x08)
#define MFII_RAID_CTX_RL_FLAGS_CPU0	(0x00)
#define MFII_RAID_CTX_RL_FLAGS_CPU1	(0x10)
#define MFII_RAID_CTX_RL_FLAGS_CUDA	(0x80)
	u_int8_t	_reserved2;
	u_int16_t	virtual_disk_target_id;

	u_int64_t	reg_lock_row_lba;

	u_int32_t	reg_lock_length;

	u_int16_t	next_lm_id;
	u_int8_t	ex_status;
	u_int8_t	status;

	u_int8_t	raid_flags;
	u_int8_t	num_sge;
	u_int16_t	config_seq_num;

	u_int8_t	span_arm;
	u_int8_t	_reserved3[3];
} __packed;

struct mfii_sge {
	u_int64_t	sg_addr;
	u_int32_t	sg_len;
	u_int16_t	_reserved;
	u_int8_t	sg_next_chain_offset;
	u_int8_t	sg_flags;
} __packed;

#define MFII_SGE_ADDR_MASK		(0x03)
#define MFII_SGE_ADDR_SYSTEM		(0x00)
#define MFII_SGE_ADDR_IOCDDR		(0x01)
#define MFII_SGE_ADDR_IOCPLB		(0x02)
#define MFII_SGE_ADDR_IOCPLBNTA		(0x03)
#define MFII_SGE_END_OF_LIST		(0x40)
#define MFII_SGE_CHAIN_ELEMENT		(0x80)

#define MFII_REQUEST_SIZE	256

#define MR_DCMD_LD_MAP_GET_INFO			0x0300e101

#define MFII_MAX_ROW		32
#define MFII_MAX_ARRAY		128

struct mfii_array_map {
	uint16_t		mam_pd[MFII_MAX_ROW];
} __packed;

struct mfii_dev_handle {
	uint16_t		mdh_cur_handle;
	uint8_t			mdh_valid;
	uint8_t			mdh_reserved;
	uint16_t		mdh_handle[2];
} __packed;

struct mfii_ld_map {
	uint32_t		mlm_total_size;
	uint32_t		mlm_reserved1[5];
	uint32_t		mlm_num_lds;
	uint32_t		mlm_reserved2;
	uint8_t			mlm_tgtid_to_ld[2 * MFI_MAX_LD];
	uint8_t			mlm_pd_timeout;
	uint8_t			mlm_reserved3[7];
	struct mfii_array_map	mlm_am[MFII_MAX_ARRAY];
	struct mfii_dev_handle	mlm_dev_handle[MFI_MAX_PD];
} __packed;

struct mfii_task_mgmt {
	union {
		uint8_t			request[128];
		struct mpii_msg_scsi_task_request
					mpii_request;
	} __packed __aligned(8);

	union {
		uint8_t			reply[128];
		uint32_t		flags;
#define MFII_TASK_MGMT_FLAGS_LD				(1 << 0)
#define MFII_TASK_MGMT_FLAGS_PD				(1 << 1)
		struct mpii_msg_scsi_task_reply
					mpii_reply;
	} __packed __aligned(8);
} __packed __aligned(8);

struct mfii_dmamem {
	bus_dmamap_t		mdm_map;
	bus_dma_segment_t	mdm_seg;
	size_t			mdm_size;
	caddr_t			mdm_kva;
};
#define MFII_DMA_MAP(_mdm)	((_mdm)->mdm_map)
#define MFII_DMA_LEN(_mdm)	((_mdm)->mdm_size)
#define MFII_DMA_DVA(_mdm)	((u_int64_t)(_mdm)->mdm_map->dm_segs[0].ds_addr)
#define MFII_DMA_KVA(_mdm)	((void *)(_mdm)->mdm_kva)

struct mfii_softc;

struct mfii_ccb {
	void			*ccb_request;
	u_int64_t		ccb_request_dva;
	bus_addr_t		ccb_request_offset;

	struct mfi_sense	*ccb_sense;
	u_int64_t		ccb_sense_dva;
	bus_addr_t		ccb_sense_offset;

	struct mfii_sge		*ccb_sgl;
	u_int64_t		ccb_sgl_dva;
	bus_addr_t		ccb_sgl_offset;
	u_int			ccb_sgl_len;

	struct mfii_request_descr ccb_req;

	bus_dmamap_t		ccb_dmamap;

	/* data for sgl */
	void			*ccb_data;
	size_t			ccb_len;

	int			ccb_direction;
#define MFII_DATA_NONE			0
#define MFII_DATA_IN			1
#define MFII_DATA_OUT			2

	void			*ccb_cookie;
	void			(*ccb_done)(struct mfii_softc *,
				    struct mfii_ccb *);

	u_int32_t		ccb_flags;
#define MFI_CCB_F_ERR			(1<<0)
	u_int			ccb_smid;
	u_int			ccb_refcnt;
	SIMPLEQ_ENTRY(mfii_ccb)	ccb_link;
};
SIMPLEQ_HEAD(mfii_ccb_list, mfii_ccb);

struct mfii_pd_softc {
	struct scsi_link	pd_link;
	struct scsibus_softc	*pd_scsibus;
	struct srp		pd_dev_handles;
	uint8_t			pd_timeout;
};

struct mfii_iop {
	u_int8_t ldio_req_type;
	u_int8_t ldio_ctx_type_nseg;
	u_int8_t ldio_ctx_reg_lock_flags;
	u_int8_t sge_flag_chain;
	u_int8_t sge_flag_eol;
};

struct mfii_softc {
	struct device		sc_dev;
	const struct mfii_iop	*sc_iop;

	pci_chipset_tag_t	sc_pc;
	pcitag_t		sc_tag;

	bus_space_tag_t		sc_iot;
	bus_space_handle_t	sc_ioh;
	bus_size_t		sc_ios;
	bus_dma_tag_t		sc_dmat;

	void			*sc_ih;

	struct mutex		sc_ccb_mtx;
	struct mutex		sc_post_mtx;

	u_int			sc_max_cmds;
	u_int			sc_max_sgl;

	u_int			sc_reply_postq_depth;
	u_int			sc_reply_postq_index;
	struct mutex		sc_reply_postq_mtx;
	struct mfii_dmamem	*sc_reply_postq;

	struct mfii_dmamem	*sc_requests;
	struct mfii_dmamem	*sc_sense;
	struct mfii_dmamem	*sc_sgl;

	struct mfii_ccb		*sc_ccb;
	struct mfii_ccb_list	sc_ccb_freeq;

	struct mfii_ccb		*sc_aen_ccb;
	struct task		sc_aen_task;

	struct mutex		sc_abort_mtx;
	struct mfii_ccb_list	sc_abort_list;
	struct task		sc_abort_task;

	struct scsi_link	sc_link;
	struct scsibus_softc	*sc_scsibus;
	struct mfii_pd_softc	*sc_pd;
	struct scsi_iopool	sc_iopool;

	struct mfi_ctrl_info	sc_info;
};

int		mfii_match(struct device *, void *, void *);
void		mfii_attach(struct device *, struct device *, void *);
int		mfii_detach(struct device *, int);

struct cfattach mfii_ca = {
	sizeof(struct mfii_softc),
	mfii_match,
	mfii_attach,
	mfii_detach
};

struct cfdriver mfii_cd = {
	NULL,
	"mfii",
	DV_DULL
};

void		mfii_scsi_cmd(struct scsi_xfer *);
void		mfii_scsi_cmd_done(struct mfii_softc *, struct mfii_ccb *);

struct scsi_adapter mfii_switch = {
	mfii_scsi_cmd,
	scsi_minphys,
	NULL, /* probe */
	NULL, /* unprobe */
	NULL  /* ioctl */
};

void		mfii_pd_scsi_cmd(struct scsi_xfer *);
int		mfii_pd_scsi_probe(struct scsi_link *);

struct scsi_adapter mfii_pd_switch = {
	mfii_pd_scsi_cmd,
	scsi_minphys,
	mfii_pd_scsi_probe
};

#define DEVNAME(_sc)		((_sc)->sc_dev.dv_xname)

u_int32_t		mfii_read(struct mfii_softc *, bus_size_t);
void			mfii_write(struct mfii_softc *, bus_size_t, u_int32_t);

struct mfii_dmamem *	mfii_dmamem_alloc(struct mfii_softc *, size_t);
void			mfii_dmamem_free(struct mfii_softc *,
			    struct mfii_dmamem *);

void *			mfii_get_ccb(void *);
void			mfii_put_ccb(void *, void *);
int			mfii_init_ccb(struct mfii_softc *);
void			mfii_scrub_ccb(struct mfii_ccb *);

int			mfii_transition_firmware(struct mfii_softc *);
int			mfii_initialise_firmware(struct mfii_softc *);
int			mfii_get_info(struct mfii_softc *);
int			mfii_syspd(struct mfii_softc *);

void			mfii_start(struct mfii_softc *, struct mfii_ccb *);
void			mfii_done(struct mfii_softc *, struct mfii_ccb *);
int			mfii_poll(struct mfii_softc *, struct mfii_ccb *);
void			mfii_poll_done(struct mfii_softc *, struct mfii_ccb *);
int			mfii_exec(struct mfii_softc *, struct mfii_ccb *);
void			mfii_exec_done(struct mfii_softc *, struct mfii_ccb *);
int			mfii_my_intr(struct mfii_softc *);
int			mfii_intr(void *);
void			mfii_postq(struct mfii_softc *);

int			mfii_load_ccb(struct mfii_softc *, struct mfii_ccb *,
			    void *, int);
int			mfii_load_mfa(struct mfii_softc *, struct mfii_ccb *,
			    void *, int);

int			mfii_mfa_poll(struct mfii_softc *, struct mfii_ccb *);

int			mfii_mgmt(struct mfii_softc *, struct mfii_ccb *,
			    u_int32_t, const union mfi_mbox *,
			    void *, size_t, int);

int			mfii_scsi_cmd_io(struct mfii_softc *,
			    struct scsi_xfer *);
int			mfii_scsi_cmd_cdb(struct mfii_softc *,
			    struct scsi_xfer *);
int			mfii_pd_scsi_cmd_cdb(struct mfii_softc *,
			    struct scsi_xfer *);
void			mfii_scsi_cmd_tmo(void *);

int			mfii_dev_handles_update(struct mfii_softc *sc);
void			mfii_dev_handles_dtor(void *, void *);

void			mfii_abort_task(void *);
void			mfii_abort(struct mfii_softc *, struct mfii_ccb *,
			    uint16_t, uint16_t, uint8_t, uint32_t);
void			mfii_scsi_cmd_abort_done(struct mfii_softc *,
			    struct mfii_ccb *);

int			mfii_aen_register(struct mfii_softc *);
void			mfii_aen_start(struct mfii_softc *, struct mfii_ccb *,
			    struct mfii_dmamem *, uint32_t);
void			mfii_aen_done(struct mfii_softc *, struct mfii_ccb *);
void			mfii_aen(void *);
void			mfii_aen_unregister(struct mfii_softc *);

void			mfii_aen_pd_insert(struct mfii_softc *,
			    const struct mfi_evtarg_pd_address *);
void			mfii_aen_pd_remove(struct mfii_softc *,
			    const struct mfi_evtarg_pd_address *);
void			mfii_aen_pd_state_change(struct mfii_softc *,
			    const struct mfi_evtarg_pd_state *);

/*
 * mfii boards support asynchronous (and non-polled) completion of
 * dcmds by proxying them through a passthru mpii command that points
 * at a dcmd frame. since the passthru command is submitted like
 * the scsi commands using an SMID in the request descriptor,
 * ccb_request memory * must contain the passthru command because
 * that is what the SMID refers to. this means ccb_request cannot
 * contain the dcmd. rather than allocating separate dma memory to
 * hold the dcmd, we reuse the sense memory buffer for it.
 */

void			mfii_dcmd_start(struct mfii_softc *,
			    struct mfii_ccb *);

static inline void
mfii_dcmd_scrub(struct mfii_ccb *ccb)
{
	memset(ccb->ccb_sense, 0, sizeof(*ccb->ccb_sense));
}

static inline struct mfi_dcmd_frame *
mfii_dcmd_frame(struct mfii_ccb *ccb)
{
	CTASSERT(sizeof(struct mfi_dcmd_frame) <= sizeof(*ccb->ccb_sense));
	return ((struct mfi_dcmd_frame *)ccb->ccb_sense);
}

static inline void
mfii_dcmd_sync(struct mfii_softc *sc, struct mfii_ccb *ccb, int flags)
{
	bus_dmamap_sync(sc->sc_dmat, MFII_DMA_MAP(sc->sc_sense),
	    ccb->ccb_sense_offset, sizeof(*ccb->ccb_sense), flags);
}

#define mfii_fw_state(_sc) mfii_read((_sc), MFI_OSP)

const struct mfii_iop mfii_iop_thunderbolt = {
	MFII_REQ_TYPE_LDIO,
	0,
	0,
	MFII_SGE_CHAIN_ELEMENT | MFII_SGE_ADDR_IOCPLBNTA,
	0
};

/*
 * a lot of these values depend on us not implementing fastpath yet.
 */
const struct mfii_iop mfii_iop_25 = {
	MFII_REQ_TYPE_NO_LOCK,
	MFII_RAID_CTX_TYPE_CUDA | 0x1,
	MFII_RAID_CTX_RL_FLAGS_CPU0, /* | MFII_RAID_CTX_RL_FLAGS_SEQNO_EN */
	MFII_SGE_CHAIN_ELEMENT,
	MFII_SGE_END_OF_LIST
};

struct mfii_device {
	pcireg_t		mpd_vendor;
	pcireg_t		mpd_product;
	const struct mfii_iop	*mpd_iop;
};

const struct mfii_device mfii_devices[] = {
	{ PCI_VENDOR_SYMBIOS,	PCI_PRODUCT_SYMBIOS_MEGARAID_2208,
	    &mfii_iop_thunderbolt },
	{ PCI_VENDOR_SYMBIOS,	PCI_PRODUCT_SYMBIOS_MEGARAID_3008,
	    &mfii_iop_25 },
	{ PCI_VENDOR_SYMBIOS,	PCI_PRODUCT_SYMBIOS_MEGARAID_3108,
	    &mfii_iop_25 }
};

const struct mfii_iop *mfii_find_iop(struct pci_attach_args *);

const struct mfii_iop *
mfii_find_iop(struct pci_attach_args *pa)
{
	const struct mfii_device *mpd;
	int i;

	for (i = 0; i < nitems(mfii_devices); i++) {
		mpd = &mfii_devices[i];

		if (mpd->mpd_vendor == PCI_VENDOR(pa->pa_id) &&
		    mpd->mpd_product == PCI_PRODUCT(pa->pa_id))
			return (mpd->mpd_iop);
	}

	return (NULL);
}

int
mfii_match(struct device *parent, void *match, void *aux)
{
	return ((mfii_find_iop(aux) != NULL) ? 1 : 0);
}

void
mfii_attach(struct device *parent, struct device *self, void *aux)
{
	struct mfii_softc *sc = (struct mfii_softc *)self;
	struct pci_attach_args *pa = aux;
	pcireg_t memtype;
	pci_intr_handle_t ih;
	struct scsibus_attach_args saa;
	u_int32_t status;

	/* init sc */
	sc->sc_iop = mfii_find_iop(aux);
	sc->sc_dmat = pa->pa_dmat;
	SIMPLEQ_INIT(&sc->sc_ccb_freeq);
	mtx_init(&sc->sc_ccb_mtx, IPL_BIO);
	mtx_init(&sc->sc_post_mtx, IPL_BIO);
	mtx_init(&sc->sc_reply_postq_mtx, IPL_BIO);
	scsi_iopool_init(&sc->sc_iopool, sc, mfii_get_ccb, mfii_put_ccb);

	sc->sc_aen_ccb = NULL;
	task_set(&sc->sc_aen_task, mfii_aen, sc);

	mtx_init(&sc->sc_abort_mtx, IPL_BIO);
	SIMPLEQ_INIT(&sc->sc_abort_list);
	task_set(&sc->sc_abort_task, mfii_abort_task, sc);

	/* wire up the bus shizz */
	memtype = pci_mapreg_type(pa->pa_pc, pa->pa_tag, MFII_BAR);
	if (pci_mapreg_map(pa, MFII_BAR, memtype, 0,
	    &sc->sc_iot, &sc->sc_ioh, NULL, &sc->sc_ios, MFII_PCI_MEMSIZE)) {
		printf(": unable to map registers\n");
		return;
	}

	/* disable interrupts */
	mfii_write(sc, MFI_OMSK, 0xffffffff);

	if (pci_intr_map_msi(pa, &ih) != 0 && pci_intr_map(pa, &ih) != 0) {
		printf(": unable to map interrupt\n");
		goto pci_unmap;
	}
	printf(": %s\n", pci_intr_string(pa->pa_pc, ih));

	/* lets get started */
	if (mfii_transition_firmware(sc))
		goto pci_unmap;

	status = mfii_fw_state(sc);
	sc->sc_max_cmds = status & MFI_STATE_MAXCMD_MASK;
	sc->sc_max_sgl = (status & MFI_STATE_MAXSGL_MASK) >> 16;

	/* sense memory */
	CTASSERT(sizeof(struct mfi_sense) == MFI_SENSE_SIZE);
	sc->sc_sense = mfii_dmamem_alloc(sc, sc->sc_max_cmds * MFI_SENSE_SIZE);
	if (sc->sc_sense == NULL) {
		printf("%s: unable to allocate sense memory\n", DEVNAME(sc));
		goto pci_unmap;
	}

	sc->sc_reply_postq_depth = roundup(sc->sc_max_cmds, 16);

	sc->sc_reply_postq = mfii_dmamem_alloc(sc,
	    sc->sc_reply_postq_depth * sizeof(struct mpii_reply_descr));
	if (sc->sc_reply_postq == NULL)
		goto free_sense;

	memset(MFII_DMA_KVA(sc->sc_reply_postq), 0xff,
	    MFII_DMA_LEN(sc->sc_reply_postq));

	sc->sc_requests = mfii_dmamem_alloc(sc,
	    MFII_REQUEST_SIZE * (sc->sc_max_cmds + 1));
	if (sc->sc_requests == NULL)
		goto free_reply_postq;

	sc->sc_sgl = mfii_dmamem_alloc(sc, sc->sc_max_cmds *
	    sizeof(struct mfii_sge) * sc->sc_max_sgl);
	if (sc->sc_sgl == NULL)
		goto free_requests;

	if (mfii_init_ccb(sc) != 0) {
		printf("%s: could not init ccb list\n", DEVNAME(sc));
		goto free_sgl;
	}

	/* kickstart firmware with all addresses and pointers */
	if (mfii_initialise_firmware(sc) != 0) {
		printf("%s: could not initialize firmware\n", DEVNAME(sc));
		goto free_sgl;
	}

	if (mfii_get_info(sc) != 0) {
		printf("%s: could not retrieve controller information\n",
		    DEVNAME(sc));
		goto free_sgl;
	}

	printf("%s: \"%s\", firmware %s", DEVNAME(sc),
	    sc->sc_info.mci_product_name, sc->sc_info.mci_package_version);
	if (letoh16(sc->sc_info.mci_memory_size) > 0)
		printf(", %uMB cache", letoh16(sc->sc_info.mci_memory_size));
	printf("\n");

	sc->sc_ih = pci_intr_establish(sc->sc_pc, ih, IPL_BIO,
	    mfii_intr, sc, DEVNAME(sc));
	if (sc->sc_ih == NULL)
		goto free_sgl;

	sc->sc_link.openings = sc->sc_max_cmds;
	sc->sc_link.adapter_softc = sc;
	sc->sc_link.adapter = &mfii_switch;
	sc->sc_link.adapter_target = sc->sc_info.mci_max_lds;
	sc->sc_link.adapter_buswidth = sc->sc_info.mci_max_lds;
	sc->sc_link.pool = &sc->sc_iopool;

	memset(&saa, 0, sizeof(saa));
	saa.saa_sc_link = &sc->sc_link;

	config_found(&sc->sc_dev, &saa, scsiprint);

	mfii_syspd(sc);

#ifdef notyet
	if (mfii_aen_register(sc) != 0) {
		/* error printed by mfii_aen_register */
		goto intr_disestablish;
	}
#endif

	/* enable interrupts */
	mfii_write(sc, MFI_OSTS, 0xffffffff);
	mfii_write(sc, MFI_OMSK, ~MFII_OSTS_INTR_VALID);

	return;
#ifdef notyet
intr_disestablish:
	pci_intr_disestablish(sc->sc_pc, sc->sc_ih);
#endif
free_sgl:
	mfii_dmamem_free(sc, sc->sc_sgl);
free_requests:
	mfii_dmamem_free(sc, sc->sc_requests);
free_reply_postq:
	mfii_dmamem_free(sc, sc->sc_reply_postq);
free_sense:
	mfii_dmamem_free(sc, sc->sc_sense);
pci_unmap:
	bus_space_unmap(sc->sc_iot, sc->sc_ioh, sc->sc_ios);
}

struct srp_gc mfii_dev_handles_gc =
    SRP_GC_INITIALIZER(mfii_dev_handles_dtor, NULL);

static inline uint16_t
mfii_dev_handle(struct mfii_softc *sc, uint16_t target)
{
	struct srp_ref sr;
	uint16_t *map, handle;

	map = srp_enter(&sr, &sc->sc_pd->pd_dev_handles);
	handle = map[target];
	srp_leave(&sr);

	return (handle);
}

int
mfii_dev_handles_update(struct mfii_softc *sc)
{
	struct mfii_ld_map *lm;
	uint16_t *dev_handles = NULL;
	struct mfii_ccb *ccb;
	int i;
	int rv = 0;

	lm = malloc(sizeof(*lm), M_TEMP, M_WAITOK|M_ZERO);
	ccb = scsi_io_get(&sc->sc_iopool, 0);

	rv = mfii_mgmt(sc, ccb, MR_DCMD_LD_MAP_GET_INFO, NULL,
	    lm, sizeof(*lm), SCSI_DATA_IN|SCSI_NOSLEEP);

	scsi_io_put(&sc->sc_iopool, ccb);
	if (rv != 0) {
		rv = EIO;
		goto free_lm;
	}

	dev_handles = mallocarray(MFI_MAX_PD, sizeof(*dev_handles),
	    M_DEVBUF, M_WAITOK);

	for (i = 0; i < MFI_MAX_PD; i++)
		dev_handles[i] = lm->mlm_dev_handle[i].mdh_cur_handle;

	/* commit the updated info */
	sc->sc_pd->pd_timeout = lm->mlm_pd_timeout;
	srp_update_locked(&mfii_dev_handles_gc,
	    &sc->sc_pd->pd_dev_handles, dev_handles);

free_lm:
	free(lm, M_TEMP, sizeof(*lm));

	return (rv);
}

void
mfii_dev_handles_dtor(void *null, void *v)
{
	uint16_t *dev_handles = v;

	free(dev_handles, M_DEVBUF, sizeof(*dev_handles) * MFI_MAX_PD);
}

int
mfii_syspd(struct mfii_softc *sc)
{
	struct scsibus_attach_args saa;
	struct scsi_link *link;

	sc->sc_pd = malloc(sizeof(*sc->sc_pd), M_DEVBUF, M_WAITOK|M_ZERO);
	if (sc->sc_pd == NULL)
		return (1);

	srp_init(&sc->sc_pd->pd_dev_handles);
	if (mfii_dev_handles_update(sc) != 0)
		goto free_pdsc;

	link = &sc->sc_pd->pd_link;
	link->adapter = &mfii_pd_switch;
	link->adapter_softc = sc;
	link->adapter_buswidth = MFI_MAX_PD;
	link->adapter_target = -1;
	link->openings = sc->sc_max_cmds - 1;
	link->pool = &sc->sc_iopool;

	memset(&saa, 0, sizeof(saa));
	saa.saa_sc_link = link;

	sc->sc_pd->pd_scsibus = (struct scsibus_softc *)
	    config_found(&sc->sc_dev, &saa, scsiprint);

	return (0);

free_pdsc:
	free(sc->sc_pd, M_DEVBUF, sizeof(*sc->sc_pd));
	return (1);
}

int
mfii_detach(struct device *self, int flags)
{
	struct mfii_softc *sc = (struct mfii_softc *)self;

	if (sc->sc_ih == NULL)
		return (0);

	mfii_aen_unregister(sc);
	pci_intr_disestablish(sc->sc_pc, sc->sc_ih);
	mfii_dmamem_free(sc, sc->sc_sgl);
	mfii_dmamem_free(sc, sc->sc_requests);
	mfii_dmamem_free(sc, sc->sc_reply_postq);
	mfii_dmamem_free(sc, sc->sc_sense);
	bus_space_unmap(sc->sc_iot, sc->sc_ioh, sc->sc_ios);

	return (0);
}

u_int32_t
mfii_read(struct mfii_softc *sc, bus_size_t r)
{
	bus_space_barrier(sc->sc_iot, sc->sc_ioh, r, 4,
	    BUS_SPACE_BARRIER_READ);
	return (bus_space_read_4(sc->sc_iot, sc->sc_ioh, r));
}

void
mfii_write(struct mfii_softc *sc, bus_size_t r, u_int32_t v)
{
	bus_space_write_4(sc->sc_iot, sc->sc_ioh, r, v);
	bus_space_barrier(sc->sc_iot, sc->sc_ioh, r, 4,
	    BUS_SPACE_BARRIER_WRITE);
}

struct mfii_dmamem *
mfii_dmamem_alloc(struct mfii_softc *sc, size_t size)
{
	struct mfii_dmamem *m;
	int nsegs;

	m = malloc(sizeof(*m), M_DEVBUF, M_NOWAIT | M_ZERO);
	if (m == NULL)
		return (NULL);

	m->mdm_size = size;

	if (bus_dmamap_create(sc->sc_dmat, size, 1, size, 0,
	    BUS_DMA_NOWAIT | BUS_DMA_ALLOCNOW, &m->mdm_map) != 0)
		goto mdmfree;

	if (bus_dmamem_alloc(sc->sc_dmat, size, PAGE_SIZE, 0, &m->mdm_seg, 1,
	    &nsegs, BUS_DMA_NOWAIT | BUS_DMA_ZERO) != 0)
		goto destroy;

	if (bus_dmamem_map(sc->sc_dmat, &m->mdm_seg, nsegs, size, &m->mdm_kva,
	    BUS_DMA_NOWAIT) != 0)
		goto free;

	if (bus_dmamap_load(sc->sc_dmat, m->mdm_map, m->mdm_kva, size, NULL,
	    BUS_DMA_NOWAIT) != 0)
		goto unmap;

	return (m);

unmap:
	bus_dmamem_unmap(sc->sc_dmat, m->mdm_kva, m->mdm_size);
free:
	bus_dmamem_free(sc->sc_dmat, &m->mdm_seg, 1);
destroy:
	bus_dmamap_destroy(sc->sc_dmat, m->mdm_map);
mdmfree:
	free(m, M_DEVBUF, sizeof *m);

	return (NULL);
}

void
mfii_dmamem_free(struct mfii_softc *sc, struct mfii_dmamem *m)
{
	bus_dmamap_unload(sc->sc_dmat, m->mdm_map);
	bus_dmamem_unmap(sc->sc_dmat, m->mdm_kva, m->mdm_size);
	bus_dmamem_free(sc->sc_dmat, &m->mdm_seg, 1);
	bus_dmamap_destroy(sc->sc_dmat, m->mdm_map);
	free(m, M_DEVBUF, sizeof *m);
}

void
mfii_dcmd_start(struct mfii_softc *sc, struct mfii_ccb *ccb)
{
	struct mpii_msg_scsi_io *io = ccb->ccb_request;
	struct mfii_raid_context *ctx = (struct mfii_raid_context *)(io + 1);
	struct mfii_sge *sge = (struct mfii_sge *)(ctx + 1);

	io->function = MFII_FUNCTION_PASSTHRU_IO;
	io->sgl_offset0 = (uint32_t *)sge - (uint32_t *)io;

	htolem64(&sge->sg_addr, ccb->ccb_sense_dva);
	htolem32(&sge->sg_len, sizeof(*ccb->ccb_sense));
	sge->sg_flags = MFII_SGE_CHAIN_ELEMENT | MFII_SGE_ADDR_IOCPLBNTA;

	ccb->ccb_req.flags = MFII_REQ_TYPE_SCSI;
	ccb->ccb_req.smid = letoh16(ccb->ccb_smid);

	mfii_start(sc, ccb);
}

int
mfii_aen_register(struct mfii_softc *sc)
{
	struct mfi_evt_log_info mel;
	struct mfii_ccb *ccb;
	struct mfii_dmamem *mdm;
	int rv;

	ccb = scsi_io_get(&sc->sc_iopool, 0);
	if (ccb == NULL) {
		printf("%s: unable to allocate ccb for aen\n", DEVNAME(sc));
		return (ENOMEM);
	}

	memset(&mel, 0, sizeof(mel));

	rv = mfii_mgmt(sc, ccb, MR_DCMD_CTRL_EVENT_GET_INFO, NULL,
	    &mel, sizeof(mel), SCSI_DATA_IN|SCSI_NOSLEEP);
	if (rv != 0) {
		scsi_io_put(&sc->sc_iopool, ccb);
		printf("%s: unable to get event info\n", DEVNAME(sc));
		return (EIO);
	}

	mdm = mfii_dmamem_alloc(sc, sizeof(struct mfi_evt_detail));
	if (mdm == NULL) {
		scsi_io_put(&sc->sc_iopool, ccb);
		printf("%s: unable to allocate event data\n", DEVNAME(sc));
		return (ENOMEM);
	}

	/* replay all the events from boot */
	mfii_aen_start(sc, ccb, mdm, lemtoh32(&mel.mel_boot_seq_num));

	return (0);
}

void
mfii_aen_start(struct mfii_softc *sc, struct mfii_ccb *ccb,
    struct mfii_dmamem *mdm, uint32_t seq)
{
	struct mfi_dcmd_frame *dcmd = mfii_dcmd_frame(ccb);
	struct mfi_frame_header *hdr = &dcmd->mdf_header;
	union mfi_sgl *sgl = &dcmd->mdf_sgl;
	union mfi_evt_class_locale mec;

	mfii_scrub_ccb(ccb);
	mfii_dcmd_scrub(ccb);
	memset(MFII_DMA_KVA(mdm), 0, MFII_DMA_LEN(mdm));

	ccb->ccb_cookie = mdm;
	ccb->ccb_done = mfii_aen_done;
	sc->sc_aen_ccb = ccb;

	mec.mec_members.class = MFI_EVT_CLASS_DEBUG;
	mec.mec_members.reserved = 0;
	mec.mec_members.locale = htole16(MFI_EVT_LOCALE_ALL);

	hdr->mfh_cmd = MFI_CMD_DCMD;
	hdr->mfh_sg_count = 1;
	hdr->mfh_flags = htole16(MFI_FRAME_DIR_READ | MFI_FRAME_SGL64);
	htolem32(&hdr->mfh_data_len, MFII_DMA_LEN(mdm));
	dcmd->mdf_opcode = htole32(MR_DCMD_CTRL_EVENT_WAIT);
	htolem32(&dcmd->mdf_mbox.w[0], seq);
	htolem32(&dcmd->mdf_mbox.w[1], mec.mec_word);
	htolem64(&sgl->sg64[0].addr, MFII_DMA_DVA(mdm));
	htolem32(&sgl->sg64[0].len, MFII_DMA_LEN(mdm));

	bus_dmamap_sync(sc->sc_dmat, MFII_DMA_MAP(mdm),
	    0, MFII_DMA_LEN(mdm), BUS_DMASYNC_PREREAD);

	mfii_dcmd_sync(sc, ccb, BUS_DMASYNC_PREREAD|BUS_DMASYNC_PREWRITE);
	mfii_dcmd_start(sc, ccb);
}

void
mfii_aen_done(struct mfii_softc *sc, struct mfii_ccb *ccb)
{
	KASSERT(sc->sc_aen_ccb == ccb);

	/* defer to a thread with KERNEL_LOCK so we can run autoconf */
	task_add(systq, &sc->sc_aen_task);
}

void
mfii_aen(void *arg)
{
	struct mfii_softc *sc = arg;
	struct mfii_ccb *ccb = sc->sc_aen_ccb;
	struct mfii_dmamem *mdm = ccb->ccb_cookie;
	const struct mfi_evt_detail *med = MFII_DMA_KVA(mdm);

	mfii_dcmd_sync(sc, ccb,
	    BUS_DMASYNC_POSTREAD|BUS_DMASYNC_POSTWRITE);
	bus_dmamap_sync(sc->sc_dmat, MFII_DMA_MAP(mdm),
	    0, MFII_DMA_LEN(mdm), BUS_DMASYNC_POSTREAD);

#if 0
	printf("%s: %u %08x %02x %s\n", DEVNAME(sc),
	    lemtoh32(&med->med_seq_num), lemtoh32(&med->med_code),
	    med->med_arg_type, med->med_description);
#endif

	switch (lemtoh32(&med->med_code)) {
	case MFI_EVT_PD_INSERTED_EXT:
		if (med->med_arg_type != MFI_EVT_ARGS_PD_ADDRESS)
			break;
		
		mfii_aen_pd_insert(sc, &med->args.pd_address);
		break;
 	case MFI_EVT_PD_REMOVED_EXT:
		if (med->med_arg_type != MFI_EVT_ARGS_PD_ADDRESS)
			break;
		
		mfii_aen_pd_remove(sc, &med->args.pd_address);
		break;

	case MFI_EVT_PD_STATE_CHANGE:
		if (med->med_arg_type != MFI_EVT_ARGS_PD_STATE)
			break;

		mfii_aen_pd_state_change(sc, &med->args.pd_state);
		break;

	default:
		break;
	}

	mfii_aen_start(sc, ccb, mdm, lemtoh32(&med->med_seq_num) + 1);
}

void
mfii_aen_pd_insert(struct mfii_softc *sc,
    const struct mfi_evtarg_pd_address *pd)
{
#if 0
	printf("%s: pd inserted ext\n", DEVNAME(sc));
	printf("%s:  device_id %04x encl_id: %04x type %x\n", DEVNAME(sc),
	    lemtoh16(&pd->device_id), lemtoh16(&pd->encl_id),
	    pd->scsi_dev_type);
	printf("%s:  connected %02x addrs %016llx %016llx\n", DEVNAME(sc),
	    pd->connected.port_bitmap, lemtoh64(&pd->sas_addr[0]),
	    lemtoh64(&pd->sas_addr[1]));
#endif

	if (mfii_dev_handles_update(sc) != 0) /* refresh map */
		return;

	scsi_probe_target(sc->sc_pd->pd_scsibus, lemtoh16(&pd->device_id));
}

void
mfii_aen_pd_remove(struct mfii_softc *sc,
    const struct mfi_evtarg_pd_address *pd)
{
#if 0
	printf("%s: pd removed ext\n", DEVNAME(sc));
	printf("%s:  device_id %04x encl_id: %04x type %u\n", DEVNAME(sc),
	    lemtoh16(&pd->device_id), lemtoh16(&pd->encl_id),
	    pd->scsi_dev_type);
	printf("%s:  connected %02x addrs %016llx %016llx\n", DEVNAME(sc),
	    pd->connected.port_bitmap, lemtoh64(&pd->sas_addr[0]),
	    lemtoh64(&pd->sas_addr[1]));
#endif
	uint16_t target = lemtoh16(&pd->device_id);

	scsi_activate(sc->sc_pd->pd_scsibus, target, -1, DVACT_DEACTIVATE);

	/* the firmware will abort outstanding commands for us */

	scsi_detach_target(sc->sc_pd->pd_scsibus, target, DETACH_FORCE);
}

void
mfii_aen_pd_state_change(struct mfii_softc *sc,
    const struct mfi_evtarg_pd_state *state)
{
	uint16_t target = lemtoh16(&state->pd.mep_device_id);

	if (state->prev_state == htole32(MFI_PD_SYSTEM) &&
	    state->new_state != htole32(MFI_PD_SYSTEM)) {
		/* it's been pulled or configured for raid */

		scsi_activate(sc->sc_pd->pd_scsibus, target, -1,
		    DVACT_DEACTIVATE);
		/* outstanding commands will simply complete or get aborted */
		scsi_detach_target(sc->sc_pd->pd_scsibus, target,
		    DETACH_FORCE);

	} else if (state->prev_state == htole32(MFI_PD_UNCONFIG_GOOD) &&
	    state->new_state == htole32(MFI_PD_SYSTEM)) {
		/* the firmware is handing the disk over */

		scsi_probe_target(sc->sc_pd->pd_scsibus, target);
	}
}

void
mfii_aen_unregister(struct mfii_softc *sc)
{
	/* XXX */
}

int
mfii_transition_firmware(struct mfii_softc *sc)
{
	int32_t			fw_state, cur_state;
	int			max_wait, i;

	fw_state = mfii_fw_state(sc) & MFI_STATE_MASK;

	while (fw_state != MFI_STATE_READY) {
		cur_state = fw_state;
		switch (fw_state) {
		case MFI_STATE_FAULT:
			printf("%s: firmware fault\n", DEVNAME(sc));
			return (1);
		case MFI_STATE_WAIT_HANDSHAKE:
			mfii_write(sc, MFI_SKINNY_IDB,
			    MFI_INIT_CLEAR_HANDSHAKE);
			max_wait = 2;
			break;
		case MFI_STATE_OPERATIONAL:
			mfii_write(sc, MFI_SKINNY_IDB, MFI_INIT_READY);
			max_wait = 10;
			break;
		case MFI_STATE_UNDEFINED:
		case MFI_STATE_BB_INIT:
			max_wait = 2;
			break;
		case MFI_STATE_FW_INIT:
		case MFI_STATE_DEVICE_SCAN:
		case MFI_STATE_FLUSH_CACHE:
			max_wait = 20;
			break;
		default:
			printf("%s: unknown firmware state %d\n",
			    DEVNAME(sc), fw_state);
			return (1);
		}
		for (i = 0; i < (max_wait * 10); i++) {
			fw_state = mfii_fw_state(sc) & MFI_STATE_MASK;
			if (fw_state == cur_state)
				DELAY(100000);
			else
				break;
		}
		if (fw_state == cur_state) {
			printf("%s: firmware stuck in state %#x\n",
			    DEVNAME(sc), fw_state);
			return (1);
		}
	}

	return (0);
}

int
mfii_get_info(struct mfii_softc *sc)
{
	struct mfii_ccb *ccb;
	int rv;

	ccb = scsi_io_get(&sc->sc_iopool, 0);
	rv = mfii_mgmt(sc, ccb, MR_DCMD_CTRL_GET_INFO, NULL,
	    &sc->sc_info, sizeof(sc->sc_info), SCSI_DATA_IN|SCSI_NOSLEEP);
	scsi_io_put(&sc->sc_iopool, ccb);

	if (rv != 0)
		return (rv);

#ifdef MFI_DEBUG
	for (i = 0; i < sc->sc_info.mci_image_component_count; i++) {
		printf("%s: active FW %s Version %s date %s time %s\n",
		    DEVNAME(sc),
		    sc->sc_info.mci_image_component[i].mic_name,
		    sc->sc_info.mci_image_component[i].mic_version,
		    sc->sc_info.mci_image_component[i].mic_build_date,
		    sc->sc_info.mci_image_component[i].mic_build_time);
	}

	for (i = 0; i < sc->sc_info.mci_pending_image_component_count; i++) {
		printf("%s: pending FW %s Version %s date %s time %s\n",
		    DEVNAME(sc),
		    sc->sc_info.mci_pending_image_component[i].mic_name,
		    sc->sc_info.mci_pending_image_component[i].mic_version,
		    sc->sc_info.mci_pending_image_component[i].mic_build_date,
		    sc->sc_info.mci_pending_image_component[i].mic_build_time);
	}

	printf("%s: max_arms %d max_spans %d max_arrs %d max_lds %d name %s\n",
	    DEVNAME(sc),
	    sc->sc_info.mci_max_arms,
	    sc->sc_info.mci_max_spans,
	    sc->sc_info.mci_max_arrays,
	    sc->sc_info.mci_max_lds,
	    sc->sc_info.mci_product_name);

	printf("%s: serial %s present %#x fw time %d max_cmds %d max_sg %d\n",
	    DEVNAME(sc),
	    sc->sc_info.mci_serial_number,
	    sc->sc_info.mci_hw_present,
	    sc->sc_info.mci_current_fw_time,
	    sc->sc_info.mci_max_cmds,
	    sc->sc_info.mci_max_sg_elements);

	printf("%s: max_rq %d lds_pres %d lds_deg %d lds_off %d pd_pres %d\n",
	    DEVNAME(sc),
	    sc->sc_info.mci_max_request_size,
	    sc->sc_info.mci_lds_present,
	    sc->sc_info.mci_lds_degraded,
	    sc->sc_info.mci_lds_offline,
	    sc->sc_info.mci_pd_present);

	printf("%s: pd_dsk_prs %d pd_dsk_pred_fail %d pd_dsk_fail %d\n",
	    DEVNAME(sc),
	    sc->sc_info.mci_pd_disks_present,
	    sc->sc_info.mci_pd_disks_pred_failure,
	    sc->sc_info.mci_pd_disks_failed);

	printf("%s: nvram %d mem %d flash %d\n",
	    DEVNAME(sc),
	    sc->sc_info.mci_nvram_size,
	    sc->sc_info.mci_memory_size,
	    sc->sc_info.mci_flash_size);

	printf("%s: ram_cor %d ram_uncor %d clus_all %d clus_act %d\n",
	    DEVNAME(sc),
	    sc->sc_info.mci_ram_correctable_errors,
	    sc->sc_info.mci_ram_uncorrectable_errors,
	    sc->sc_info.mci_cluster_allowed,
	    sc->sc_info.mci_cluster_active);

	printf("%s: max_strps_io %d raid_lvl %#x adapt_ops %#x ld_ops %#x\n",
	    DEVNAME(sc),
	    sc->sc_info.mci_max_strips_per_io,
	    sc->sc_info.mci_raid_levels,
	    sc->sc_info.mci_adapter_ops,
	    sc->sc_info.mci_ld_ops);

	printf("%s: strp_sz_min %d strp_sz_max %d pd_ops %#x pd_mix %#x\n",
	    DEVNAME(sc),
	    sc->sc_info.mci_stripe_sz_ops.min,
	    sc->sc_info.mci_stripe_sz_ops.max,
	    sc->sc_info.mci_pd_ops,
	    sc->sc_info.mci_pd_mix_support);

	printf("%s: ecc_bucket %d pckg_prop %s\n",
	    DEVNAME(sc),
	    sc->sc_info.mci_ecc_bucket_count,
	    sc->sc_info.mci_package_version);

	printf("%s: sq_nm %d prd_fail_poll %d intr_thrtl %d intr_thrtl_to %d\n",
	    DEVNAME(sc),
	    sc->sc_info.mci_properties.mcp_seq_num,
	    sc->sc_info.mci_properties.mcp_pred_fail_poll_interval,
	    sc->sc_info.mci_properties.mcp_intr_throttle_cnt,
	    sc->sc_info.mci_properties.mcp_intr_throttle_timeout);

	printf("%s: rbld_rate %d patr_rd_rate %d bgi_rate %d cc_rate %d\n",
	    DEVNAME(sc),
	    sc->sc_info.mci_properties.mcp_rebuild_rate,
	    sc->sc_info.mci_properties.mcp_patrol_read_rate,
	    sc->sc_info.mci_properties.mcp_bgi_rate,
	    sc->sc_info.mci_properties.mcp_cc_rate);

	printf("%s: rc_rate %d ch_flsh %d spin_cnt %d spin_dly %d clus_en %d\n",
	    DEVNAME(sc),
	    sc->sc_info.mci_properties.mcp_recon_rate,
	    sc->sc_info.mci_properties.mcp_cache_flush_interval,
	    sc->sc_info.mci_properties.mcp_spinup_drv_cnt,
	    sc->sc_info.mci_properties.mcp_spinup_delay,
	    sc->sc_info.mci_properties.mcp_cluster_enable);

	printf("%s: coerc %d alarm %d dis_auto_rbld %d dis_bat_wrn %d ecc %d\n",
	    DEVNAME(sc),
	    sc->sc_info.mci_properties.mcp_coercion_mode,
	    sc->sc_info.mci_properties.mcp_alarm_enable,
	    sc->sc_info.mci_properties.mcp_disable_auto_rebuild,
	    sc->sc_info.mci_properties.mcp_disable_battery_warn,
	    sc->sc_info.mci_properties.mcp_ecc_bucket_size);

	printf("%s: ecc_leak %d rest_hs %d exp_encl_dev %d\n",
	    DEVNAME(sc),
	    sc->sc_info.mci_properties.mcp_ecc_bucket_leak_rate,
	    sc->sc_info.mci_properties.mcp_restore_hotspare_on_insertion,
	    sc->sc_info.mci_properties.mcp_expose_encl_devices);

	printf("%s: vendor %#x device %#x subvendor %#x subdevice %#x\n",
	    DEVNAME(sc),
	    sc->sc_info.mci_pci.mip_vendor,
	    sc->sc_info.mci_pci.mip_device,
	    sc->sc_info.mci_pci.mip_subvendor,
	    sc->sc_info.mci_pci.mip_subdevice);

	printf("%s: type %#x port_count %d port_addr ",
	    DEVNAME(sc),
	    sc->sc_info.mci_host.mih_type,
	    sc->sc_info.mci_host.mih_port_count);

	for (i = 0; i < 8; i++)
		printf("%.0llx ", sc->sc_info.mci_host.mih_port_addr[i]);
	printf("\n");

	printf("%s: type %.x port_count %d port_addr ",
	    DEVNAME(sc),
	    sc->sc_info.mci_device.mid_type,
	    sc->sc_info.mci_device.mid_port_count);

	for (i = 0; i < 8; i++)
		printf("%.0llx ", sc->sc_info.mci_device.mid_port_addr[i]);
	printf("\n");
#endif /* MFI_DEBUG */

	return (0);
}

int
mfii_mfa_poll(struct mfii_softc *sc, struct mfii_ccb *ccb)
{
	struct mfi_frame_header	*hdr = ccb->ccb_request;
	u_int64_t r;
	int to = 0, rv = 0;

#ifdef DIAGNOSTIC
	if (ccb->ccb_cookie != NULL || ccb->ccb_done != NULL)
		panic("mfii_mfa_poll called with cookie or done set");
#endif

	hdr->mfh_context = ccb->ccb_smid;
	hdr->mfh_cmd_status = 0xff;
	hdr->mfh_flags |= htole16(MFI_FRAME_DONT_POST_IN_REPLY_QUEUE);

	r = MFII_REQ_MFA(ccb->ccb_request_dva);
	memcpy(&ccb->ccb_req, &r, sizeof(ccb->ccb_req));

	mfii_start(sc, ccb);

	for (;;) {
		bus_dmamap_sync(sc->sc_dmat, MFII_DMA_MAP(sc->sc_requests),
		    ccb->ccb_request_offset, MFII_REQUEST_SIZE,
		    BUS_DMASYNC_POSTREAD | BUS_DMASYNC_POSTWRITE);

		if (hdr->mfh_cmd_status != 0xff)
			break;

		if (to++ > 5000) { /* XXX 5 seconds busywait sucks */
			printf("%s: timeout on ccb %d\n", DEVNAME(sc),
			    ccb->ccb_smid);
			ccb->ccb_flags |= MFI_CCB_F_ERR;
			rv = 1;
			break;
		}

		bus_dmamap_sync(sc->sc_dmat, MFII_DMA_MAP(sc->sc_requests),
		    ccb->ccb_request_offset, MFII_REQUEST_SIZE,
		    BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);

		delay(1000);
	}

	if (ccb->ccb_len > 0) {
		bus_dmamap_sync(sc->sc_dmat, ccb->ccb_dmamap,
		    0, ccb->ccb_dmamap->dm_mapsize,
		    (ccb->ccb_direction == MFII_DATA_IN) ?
		    BUS_DMASYNC_POSTREAD : BUS_DMASYNC_POSTWRITE);

		bus_dmamap_unload(sc->sc_dmat, ccb->ccb_dmamap);
	}

	return (rv);
}

int
mfii_poll(struct mfii_softc *sc, struct mfii_ccb *ccb)
{
	void (*done)(struct mfii_softc *, struct mfii_ccb *);
	void *cookie;
	int rv = 1;

	done = ccb->ccb_done;
	cookie = ccb->ccb_cookie;

	ccb->ccb_done = mfii_poll_done;
	ccb->ccb_cookie = &rv;

	mfii_start(sc, ccb);

	do {
		delay(10);
		mfii_postq(sc);
	} while (rv == 1);

	ccb->ccb_cookie = cookie;
	done(sc, ccb);

	return (0);
}

void
mfii_poll_done(struct mfii_softc *sc, struct mfii_ccb *ccb)
{
	int *rv = ccb->ccb_cookie;

	*rv = 0;
}

int
mfii_exec(struct mfii_softc *sc, struct mfii_ccb *ccb)
{
	struct mutex m = MUTEX_INITIALIZER(IPL_BIO);

#ifdef DIAGNOSTIC
	if (ccb->ccb_cookie != NULL || ccb->ccb_done != NULL)
		panic("mfii_exec called with cookie or done set");
#endif

	ccb->ccb_cookie = &m;
	ccb->ccb_done = mfii_exec_done;

	mtx_enter(&m);
	while (ccb->ccb_cookie != NULL)
		msleep(ccb, &m, PRIBIO, "mfiiexec", 0);
	mtx_leave(&m);

	return (0);
}

void
mfii_exec_done(struct mfii_softc *sc, struct mfii_ccb *ccb)
{
	struct mutex *m = ccb->ccb_cookie;

	mtx_enter(m);
	ccb->ccb_cookie = NULL;
	wakeup_one(ccb);
	mtx_leave(m);
}

int
mfii_mgmt(struct mfii_softc *sc, struct mfii_ccb *ccb,
    u_int32_t opc, const union mfi_mbox *mbox, void *buf, size_t len,
    int flags)
{
	struct mfi_dcmd_frame *dcmd = ccb->ccb_request;
	struct mfi_frame_header	*hdr = &dcmd->mdf_header;
	u_int64_t r;
	u_int8_t *dma_buf;
	int rv = EIO;

	dma_buf = dma_alloc(len, PR_WAITOK);
	if (dma_buf == NULL)
		return (ENOMEM);

	mfii_scrub_ccb(ccb);
	ccb->ccb_data = dma_buf;
	ccb->ccb_len = len;
	switch (flags & (SCSI_DATA_IN | SCSI_DATA_OUT)) {
	case SCSI_DATA_IN:
		ccb->ccb_direction = MFII_DATA_IN;
		hdr->mfh_flags = htole16(MFI_FRAME_DIR_READ);
		break;
	case SCSI_DATA_OUT:
		ccb->ccb_direction = MFII_DATA_OUT;
		hdr->mfh_flags = htole16(MFI_FRAME_DIR_WRITE);
		memcpy(dma_buf, buf, len);
		break;
	}

	if (mfii_load_mfa(sc, ccb, &dcmd->mdf_sgl,
	    ISSET(flags, SCSI_NOSLEEP)) != 0) {
		rv = ENOMEM;
		goto done;
	}

	hdr->mfh_cmd = MFI_CMD_DCMD;
	hdr->mfh_context = ccb->ccb_smid;
	hdr->mfh_data_len = htole32(len);
	hdr->mfh_sg_count = ccb->ccb_dmamap->dm_nsegs;

	dcmd->mdf_opcode = opc;
	/* handle special opcodes */
	if (mbox != NULL)
		memcpy(&dcmd->mdf_mbox, mbox, sizeof(dcmd->mdf_mbox));

	if (ISSET(flags, SCSI_NOSLEEP))
		mfii_mfa_poll(sc, ccb);
	else {
		r = MFII_REQ_MFA(ccb->ccb_request_dva);
		memcpy(&ccb->ccb_req, &r, sizeof(ccb->ccb_req));
		mfii_exec(sc, ccb);
	}

	if (hdr->mfh_cmd_status == MFI_STAT_OK) {
		rv = 0;

		if (ccb->ccb_direction == MFII_DATA_IN)
			memcpy(buf, dma_buf, len);
	}

done:
	dma_free(dma_buf, len);

	return (rv);
}

int
mfii_load_mfa(struct mfii_softc *sc, struct mfii_ccb *ccb,
    void *sglp, int nosleep)
{
	union mfi_sgl *sgl = sglp;
	bus_dmamap_t dmap = ccb->ccb_dmamap;
	int error;
	int i;

	if (ccb->ccb_len == 0)
		return (0);

	error = bus_dmamap_load(sc->sc_dmat, dmap,
	    ccb->ccb_data, ccb->ccb_len, NULL,
	    nosleep ? BUS_DMA_NOWAIT : BUS_DMA_WAITOK);
	if (error) {
		printf("%s: error %d loading dmamap\n", DEVNAME(sc), error);
		return (1);
	}

	for (i = 0; i < dmap->dm_nsegs; i++) {
		sgl->sg32[i].addr = htole32(dmap->dm_segs[i].ds_addr);
		sgl->sg32[i].len = htole32(dmap->dm_segs[i].ds_len);
	}

	bus_dmamap_sync(sc->sc_dmat, dmap, 0, dmap->dm_mapsize,
	    ccb->ccb_direction == MFII_DATA_OUT ?
	    BUS_DMASYNC_PREWRITE : BUS_DMASYNC_PREREAD);

	return (0);
}

void
mfii_start(struct mfii_softc *sc, struct mfii_ccb *ccb)
{
	u_long *r = (u_long *)&ccb->ccb_req;

	bus_dmamap_sync(sc->sc_dmat, MFII_DMA_MAP(sc->sc_requests),
	    ccb->ccb_request_offset, MFII_REQUEST_SIZE,
	    BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);

#if defined(__LP64__)
	bus_space_write_raw_8(sc->sc_iot, sc->sc_ioh, MFI_IQPL, *r);
#else
	mtx_enter(&sc->sc_post_mtx);
	bus_space_write_raw_4(sc->sc_iot, sc->sc_ioh, MFI_IQPL, r[0]);
	bus_space_barrier(sc->sc_iot, sc->sc_ioh,
	    MFI_IQPL, 8, BUS_SPACE_BARRIER_WRITE);

	bus_space_write_raw_4(sc->sc_iot, sc->sc_ioh, MFI_IQPH, r[1]);
	bus_space_barrier(sc->sc_iot, sc->sc_ioh,
	    MFI_IQPH, 8, BUS_SPACE_BARRIER_WRITE);
	mtx_leave(&sc->sc_post_mtx);
#endif
}

void
mfii_done(struct mfii_softc *sc, struct mfii_ccb *ccb)
{
	bus_dmamap_sync(sc->sc_dmat, MFII_DMA_MAP(sc->sc_requests),
	    ccb->ccb_request_offset, MFII_REQUEST_SIZE,
	    BUS_DMASYNC_POSTREAD | BUS_DMASYNC_POSTWRITE);

	if (ccb->ccb_sgl_len > 0) {
		bus_dmamap_sync(sc->sc_dmat, MFII_DMA_MAP(sc->sc_sgl),
		    ccb->ccb_sgl_offset, ccb->ccb_sgl_len,
		    BUS_DMASYNC_POSTWRITE);
	}

	if (ccb->ccb_len > 0) {
		bus_dmamap_sync(sc->sc_dmat, ccb->ccb_dmamap,
		    0, ccb->ccb_dmamap->dm_mapsize,
		    (ccb->ccb_direction == MFII_DATA_IN) ?
		    BUS_DMASYNC_POSTREAD : BUS_DMASYNC_POSTWRITE);

		bus_dmamap_unload(sc->sc_dmat, ccb->ccb_dmamap);
	}

	ccb->ccb_done(sc, ccb);
}

int
mfii_initialise_firmware(struct mfii_softc *sc)
{
	struct mpii_msg_iocinit_request *iiq;
	struct mfii_dmamem *m;
	struct mfii_ccb *ccb;
	struct mfi_init_frame *init;
	int rv;

	m = mfii_dmamem_alloc(sc, sizeof(*iiq));
	if (m == NULL)
		return (1);

	iiq = MFII_DMA_KVA(m);
	memset(iiq, 0, sizeof(*iiq));

	iiq->function = MPII_FUNCTION_IOC_INIT;
	iiq->whoinit = MPII_WHOINIT_HOST_DRIVER;

	iiq->msg_version_maj = 0x02;
	iiq->msg_version_min = 0x00;
	iiq->hdr_version_unit = 0x10;
	iiq->hdr_version_dev = 0x0;

	iiq->system_request_frame_size = htole16(MFII_REQUEST_SIZE / 4);

	iiq->reply_descriptor_post_queue_depth =
	    htole16(sc->sc_reply_postq_depth);
	iiq->reply_free_queue_depth = htole16(0);

	htolem32(&iiq->sense_buffer_address_high,
	    MFII_DMA_DVA(sc->sc_sense) >> 32);

	htolem32(&iiq->reply_descriptor_post_queue_address_lo,
	    MFII_DMA_DVA(sc->sc_reply_postq));
	htolem32(&iiq->reply_descriptor_post_queue_address_hi,
	    MFII_DMA_DVA(sc->sc_reply_postq) >> 32);

	htolem32(&iiq->system_request_frame_base_address_lo,
	    MFII_DMA_DVA(sc->sc_requests));
	htolem32(&iiq->system_request_frame_base_address_hi,
	    MFII_DMA_DVA(sc->sc_requests) >> 32);

	iiq->timestamp = htole64(time_uptime);

	ccb = scsi_io_get(&sc->sc_iopool, 0);
	mfii_scrub_ccb(ccb);
	init = ccb->ccb_request;

	init->mif_header.mfh_cmd = MFI_CMD_INIT;
	init->mif_header.mfh_data_len = htole32(sizeof(*iiq));
	init->mif_qinfo_new_addr = htole64(MFII_DMA_DVA(m));

	bus_dmamap_sync(sc->sc_dmat, MFII_DMA_MAP(sc->sc_reply_postq),
	    0, MFII_DMA_LEN(sc->sc_reply_postq),
	    BUS_DMASYNC_PREREAD);

	bus_dmamap_sync(sc->sc_dmat, MFII_DMA_MAP(m),
	    0, sizeof(*iiq), BUS_DMASYNC_PREREAD);

	rv = mfii_mfa_poll(sc, ccb);

	bus_dmamap_sync(sc->sc_dmat, MFII_DMA_MAP(m),
	    0, sizeof(*iiq), BUS_DMASYNC_POSTREAD);

	scsi_io_put(&sc->sc_iopool, ccb);
	mfii_dmamem_free(sc, m);

	return (rv);
}

int
mfii_my_intr(struct mfii_softc *sc)
{
	u_int32_t status;

	status = mfii_read(sc, MFI_OSTS);
	if (ISSET(status, 0x1)) {
		mfii_write(sc, MFI_OSTS, status);
		return (1);
	}

	return (ISSET(status, MFII_OSTS_INTR_VALID) ? 1 : 0);
}

int
mfii_intr(void *arg)
{
	struct mfii_softc *sc = arg;

	if (!mfii_my_intr(sc))
		return (0);

	mfii_postq(sc);

	return (1);
}

void
mfii_postq(struct mfii_softc *sc)
{
	struct mfii_ccb_list ccbs = SIMPLEQ_HEAD_INITIALIZER(ccbs);
	struct mpii_reply_descr *postq = MFII_DMA_KVA(sc->sc_reply_postq);
	struct mpii_reply_descr *rdp;
	struct mfii_ccb *ccb;
	int rpi = 0;

	mtx_enter(&sc->sc_reply_postq_mtx);

	bus_dmamap_sync(sc->sc_dmat, MFII_DMA_MAP(sc->sc_reply_postq),
	    0, MFII_DMA_LEN(sc->sc_reply_postq),
	    BUS_DMASYNC_POSTREAD);

	for (;;) {
		rdp = &postq[sc->sc_reply_postq_index];
		if ((rdp->reply_flags & MPII_REPLY_DESCR_TYPE_MASK) ==
		    MPII_REPLY_DESCR_UNUSED)
			break;
		if (rdp->data == 0xffffffff) {
			/*
			 * ioc is still writing to the reply post queue
			 * race condition - bail!
			 */
			break;
		}

		ccb = &sc->sc_ccb[letoh16(rdp->smid) - 1];
		SIMPLEQ_INSERT_TAIL(&ccbs, ccb, ccb_link);
		memset(rdp, 0xff, sizeof(*rdp));

		sc->sc_reply_postq_index++;
		sc->sc_reply_postq_index %= sc->sc_reply_postq_depth;
		rpi = 1;
	}

	bus_dmamap_sync(sc->sc_dmat, MFII_DMA_MAP(sc->sc_reply_postq),
	    0, MFII_DMA_LEN(sc->sc_reply_postq),
	    BUS_DMASYNC_PREREAD);

	if (rpi)
		mfii_write(sc, MFII_RPI, sc->sc_reply_postq_index);

	mtx_leave(&sc->sc_reply_postq_mtx);

	while ((ccb = SIMPLEQ_FIRST(&ccbs)) != NULL) {
		SIMPLEQ_REMOVE_HEAD(&ccbs, ccb_link);
		mfii_done(sc, ccb);
	}
}

void
mfii_scsi_cmd(struct scsi_xfer *xs)
{
	struct scsi_link *link = xs->sc_link;
	struct mfii_softc *sc = link->adapter_softc;
	struct mfii_ccb *ccb = xs->io;

	mfii_scrub_ccb(ccb);
	ccb->ccb_cookie = xs;
	ccb->ccb_done = mfii_scsi_cmd_done;
	ccb->ccb_data = xs->data;
	ccb->ccb_len = xs->datalen;

	timeout_set(&xs->stimeout, mfii_scsi_cmd_tmo, xs);

	switch (xs->cmd->opcode) {
	case READ_COMMAND:
	case READ_BIG:
	case READ_12:
	case READ_16:
	case WRITE_COMMAND:
	case WRITE_BIG:
	case WRITE_12:
	case WRITE_16:
		if (mfii_scsi_cmd_io(sc, xs) != 0)
			goto stuffup;

		break;

	default:
		if (mfii_scsi_cmd_cdb(sc, xs) != 0)
			goto stuffup;
		break;
	}

	xs->error = XS_NOERROR;
	xs->resid = 0;

	if (ISSET(xs->flags, SCSI_POLL)) {
		if (mfii_poll(sc, ccb) != 0)
			goto stuffup;
		return;
	}

	ccb->ccb_refcnt = 2; /* one for the chip, one for the timeout */
	timeout_add_msec(&xs->stimeout, xs->timeout);
	mfii_start(sc, ccb);

	return;

stuffup:
	xs->error = XS_DRIVER_STUFFUP;
	scsi_done(xs);
}

void
mfii_scsi_cmd_done(struct mfii_softc *sc, struct mfii_ccb *ccb)
{
	struct scsi_xfer *xs = ccb->ccb_cookie;
	struct mpii_msg_scsi_io *io = ccb->ccb_request;
	struct mfii_raid_context *ctx = (struct mfii_raid_context *)(io + 1);
	u_int refs = 1;

	if (timeout_del(&xs->stimeout))
		refs = 2;

	switch (ctx->status) {
	case MFI_STAT_OK:
		break;

	case MFI_STAT_SCSI_DONE_WITH_ERROR:
		xs->error = XS_SENSE;
		memset(&xs->sense, 0, sizeof(xs->sense));
		memcpy(&xs->sense, ccb->ccb_sense, sizeof(xs->sense));
		break;

	case MFI_STAT_LD_OFFLINE:
	case MFI_STAT_DEVICE_NOT_FOUND:
		xs->error = XS_SELTIMEOUT;
		break;

	default:
		xs->error = XS_DRIVER_STUFFUP;
		break;
	}

	if (atomic_sub_int_nv(&ccb->ccb_refcnt, refs) == 0)
		scsi_done(xs);
}

int
mfii_scsi_cmd_io(struct mfii_softc *sc, struct scsi_xfer *xs)
{
	struct scsi_link *link = xs->sc_link;
	struct mfii_ccb *ccb = xs->io;
	struct mpii_msg_scsi_io *io = ccb->ccb_request;
	struct mfii_raid_context *ctx = (struct mfii_raid_context *)(io + 1);

	io->dev_handle = htole16(link->target);
	io->function = MFII_FUNCTION_LDIO_REQUEST;
	io->sense_buffer_low_address = htole32(ccb->ccb_sense_dva);
	io->sgl_flags = htole16(0x02); /* XXX */
	io->sense_buffer_length = sizeof(xs->sense);
	io->sgl_offset0 = (sizeof(*io) + sizeof(*ctx)) / 4;
	io->data_length = htole32(xs->datalen);
	io->io_flags = htole16(xs->cmdlen);
	switch (xs->flags & (SCSI_DATA_IN | SCSI_DATA_OUT)) {
	case SCSI_DATA_IN:
		ccb->ccb_direction = MFII_DATA_IN;
		io->direction = MPII_SCSIIO_DIR_READ;
		break;
	case SCSI_DATA_OUT:
		ccb->ccb_direction = MFII_DATA_OUT;
		io->direction = MPII_SCSIIO_DIR_WRITE;
		break;
	default:
		ccb->ccb_direction = MFII_DATA_NONE;
		io->direction = MPII_SCSIIO_DIR_NONE;
		break;
	}
	memcpy(io->cdb, xs->cmd, xs->cmdlen);

	ctx->type_nseg = sc->sc_iop->ldio_ctx_type_nseg;
	ctx->timeout_value = htole16(0x14); /* XXX */
	ctx->reg_lock_flags = sc->sc_iop->ldio_ctx_reg_lock_flags;
	ctx->virtual_disk_target_id = htole16(link->target);

	if (mfii_load_ccb(sc, ccb, ctx + 1,
	    ISSET(xs->flags, SCSI_NOSLEEP)) != 0)
		return (1);

	ctx->num_sge = (ccb->ccb_len == 0) ? 0 : ccb->ccb_dmamap->dm_nsegs;

	ccb->ccb_req.flags = sc->sc_iop->ldio_req_type;
	ccb->ccb_req.smid = letoh16(ccb->ccb_smid);

	return (0);
}

int
mfii_scsi_cmd_cdb(struct mfii_softc *sc, struct scsi_xfer *xs)
{
	struct scsi_link *link = xs->sc_link;
	struct mfii_ccb *ccb = xs->io;
	struct mpii_msg_scsi_io *io = ccb->ccb_request;
	struct mfii_raid_context *ctx = (struct mfii_raid_context *)(io + 1);

	io->dev_handle = htole16(link->target);
	io->function = MFII_FUNCTION_LDIO_REQUEST;
	io->sense_buffer_low_address = htole32(ccb->ccb_sense_dva);
	io->sgl_flags = htole16(0x02); /* XXX */
	io->sense_buffer_length = sizeof(xs->sense);
	io->sgl_offset0 = (sizeof(*io) + sizeof(*ctx)) / 4;
	io->data_length = htole32(xs->datalen);
	io->io_flags = htole16(xs->cmdlen);
	io->lun[0] = htobe16(link->lun);
	switch (xs->flags & (SCSI_DATA_IN | SCSI_DATA_OUT)) {
	case SCSI_DATA_IN:
		ccb->ccb_direction = MFII_DATA_IN;
		io->direction = MPII_SCSIIO_DIR_READ;
		break;
	case SCSI_DATA_OUT:
		ccb->ccb_direction = MFII_DATA_OUT;
		io->direction = MPII_SCSIIO_DIR_WRITE;
		break;
	default:
		ccb->ccb_direction = MFII_DATA_NONE;
		io->direction = MPII_SCSIIO_DIR_NONE;
		break;
	}
	memcpy(io->cdb, xs->cmd, xs->cmdlen);

	ctx->virtual_disk_target_id = htole16(link->target);

	if (mfii_load_ccb(sc, ccb, ctx + 1,
	    ISSET(xs->flags, SCSI_NOSLEEP)) != 0)
		return (1);

	ctx->num_sge = (ccb->ccb_len == 0) ? 0 : ccb->ccb_dmamap->dm_nsegs;

	ccb->ccb_req.flags = MFII_REQ_TYPE_SCSI;
	ccb->ccb_req.smid = letoh16(ccb->ccb_smid);

	return (0);
}

void
mfii_pd_scsi_cmd(struct scsi_xfer *xs)
{
	struct scsi_link *link = xs->sc_link;
	struct mfii_softc *sc = link->adapter_softc;
	struct mfii_ccb *ccb = xs->io;

	mfii_scrub_ccb(ccb);
	ccb->ccb_cookie = xs;
	ccb->ccb_done = mfii_scsi_cmd_done;
	ccb->ccb_data = xs->data;
	ccb->ccb_len = xs->datalen;

	timeout_set(&xs->stimeout, mfii_scsi_cmd_tmo, xs);

	xs->error = mfii_pd_scsi_cmd_cdb(sc, xs);
	if (xs->error != XS_NOERROR)
		goto done;

	xs->resid = 0;

	if (ISSET(xs->flags, SCSI_POLL)) {
		if (mfii_poll(sc, ccb) != 0)
			goto stuffup;
		return;
	}

	ccb->ccb_refcnt = 2; /* one for the chip, one for the timeout */
	timeout_add_msec(&xs->stimeout, xs->timeout);
	mfii_start(sc, ccb);

	return;

stuffup:
	xs->error = XS_DRIVER_STUFFUP;
done:
	scsi_done(xs);
}

int
mfii_pd_scsi_probe(struct scsi_link *link)
{
	struct mfii_softc *sc = link->adapter_softc;
	struct mfii_ccb *ccb;
	struct mfi_pd_details mpd;
	union mfi_mbox mbox;
	int rv;

	if (link->lun > 0)
		return (0);

	memset(&mbox, 0, sizeof(mbox));
	mbox.s[0] = htole16(link->target);

	ccb = scsi_io_get(&sc->sc_iopool, 0);
	rv = mfii_mgmt(sc, ccb, MR_DCMD_PD_GET_INFO, &mbox, &mpd, sizeof(mpd),
	    SCSI_DATA_IN|SCSI_NOSLEEP);
	scsi_io_put(&sc->sc_iopool, ccb);
	if (rv != 0)
		return (EIO);

	if (mpd.mpd_fw_state != htole16(MFI_PD_SYSTEM))
		return (ENXIO);

	return (0);
}

int
mfii_pd_scsi_cmd_cdb(struct mfii_softc *sc, struct scsi_xfer *xs)
{
	struct scsi_link *link = xs->sc_link;
	struct mfii_ccb *ccb = xs->io;
	struct mpii_msg_scsi_io *io = ccb->ccb_request;
	struct mfii_raid_context *ctx = (struct mfii_raid_context *)(io + 1);
	uint16_t dev_handle;

	dev_handle = mfii_dev_handle(sc, link->target);
	if (dev_handle == htole16(0xffff))
		return (XS_SELTIMEOUT);

	io->dev_handle = dev_handle;
	io->function = 0;
	io->sense_buffer_low_address = htole32(ccb->ccb_sense_dva);
	io->sgl_flags = htole16(0x02); /* XXX */
	io->sense_buffer_length = sizeof(xs->sense);
	io->sgl_offset0 = (sizeof(*io) + sizeof(*ctx)) / 4;
	io->data_length = htole32(xs->datalen);
	io->io_flags = htole16(xs->cmdlen);
	io->lun[0] = htobe16(link->lun);
	switch (xs->flags & (SCSI_DATA_IN | SCSI_DATA_OUT)) {
	case SCSI_DATA_IN:
		ccb->ccb_direction = MFII_DATA_IN;
		io->direction = MPII_SCSIIO_DIR_READ;
		break;
	case SCSI_DATA_OUT:
		ccb->ccb_direction = MFII_DATA_OUT;
		io->direction = MPII_SCSIIO_DIR_WRITE;
		break;
	default:
		ccb->ccb_direction = MFII_DATA_NONE;
		io->direction = MPII_SCSIIO_DIR_NONE;
		break;
	}
	memcpy(io->cdb, xs->cmd, xs->cmdlen);

	ctx->virtual_disk_target_id = htole16(link->target);
	ctx->raid_flags = MFII_RAID_CTX_IO_TYPE_SYSPD;
	ctx->timeout_value = sc->sc_pd->pd_timeout;

	if (mfii_load_ccb(sc, ccb, ctx + 1,
	    ISSET(xs->flags, SCSI_NOSLEEP)) != 0)
		return (XS_DRIVER_STUFFUP);

	ctx->num_sge = (ccb->ccb_len == 0) ? 0 : ccb->ccb_dmamap->dm_nsegs;

	ccb->ccb_req.flags = MFII_REQ_TYPE_HI_PRI;
	ccb->ccb_req.smid = letoh16(ccb->ccb_smid);
	ccb->ccb_req.dev_handle = dev_handle;

	return (XS_NOERROR);
}

int
mfii_load_ccb(struct mfii_softc *sc, struct mfii_ccb *ccb, void *sglp,
    int nosleep)
{
	struct mpii_msg_request *req = ccb->ccb_request;
	struct mfii_sge *sge = NULL, *nsge = sglp;
	struct mfii_sge *ce = NULL;
	bus_dmamap_t dmap = ccb->ccb_dmamap;
	u_int space;
	int i;

	int error;

	if (ccb->ccb_len == 0)
		return (0);

	error = bus_dmamap_load(sc->sc_dmat, dmap,
	    ccb->ccb_data, ccb->ccb_len, NULL,
	    nosleep ? BUS_DMA_NOWAIT : BUS_DMA_WAITOK);
	if (error) {
		printf("%s: error %d loading dmamap\n", DEVNAME(sc), error);
		return (1);
	}

	space = (MFII_REQUEST_SIZE - ((u_int8_t *)nsge - (u_int8_t *)req)) /
	    sizeof(*nsge);
	if (dmap->dm_nsegs > space) {
		space--;

		ccb->ccb_sgl_len = (dmap->dm_nsegs - space) * sizeof(*nsge);
		memset(ccb->ccb_sgl, 0, ccb->ccb_sgl_len);

		ce = nsge + space;
		ce->sg_addr = htole64(ccb->ccb_sgl_dva);
		ce->sg_len = htole32(ccb->ccb_sgl_len);
		ce->sg_flags = sc->sc_iop->sge_flag_chain;

		req->chain_offset = ((u_int8_t *)ce - (u_int8_t *)req) / 16;
	}

	for (i = 0; i < dmap->dm_nsegs; i++) {
		if (nsge == ce)
			nsge = ccb->ccb_sgl;

		sge = nsge;

		sge->sg_addr = htole64(dmap->dm_segs[i].ds_addr);
		sge->sg_len = htole32(dmap->dm_segs[i].ds_len);
		sge->sg_flags = MFII_SGE_ADDR_SYSTEM;

		nsge = sge + 1;
	}
	sge->sg_flags |= sc->sc_iop->sge_flag_eol;

	bus_dmamap_sync(sc->sc_dmat, dmap, 0, dmap->dm_mapsize,
	    ccb->ccb_direction == MFII_DATA_OUT ?
	    BUS_DMASYNC_PREWRITE : BUS_DMASYNC_PREREAD);

	if (ccb->ccb_sgl_len > 0) {
		bus_dmamap_sync(sc->sc_dmat, MFII_DMA_MAP(sc->sc_sgl),
		    ccb->ccb_sgl_offset, ccb->ccb_sgl_len,
		    BUS_DMASYNC_PREWRITE);
	}

	return (0);
}

void
mfii_scsi_cmd_tmo(void *xsp)
{
	struct scsi_xfer *xs = xsp;
	struct scsi_link *link = xs->sc_link;
	struct mfii_softc *sc = link->adapter_softc;
	struct mfii_ccb *ccb = xs->io;

	mtx_enter(&sc->sc_abort_mtx);
	SIMPLEQ_INSERT_TAIL(&sc->sc_abort_list, ccb, ccb_link);
	mtx_leave(&sc->sc_abort_mtx);

	task_add(systqmp, &sc->sc_abort_task);
}

void
mfii_abort_task(void *scp)
{
	struct mfii_softc *sc = scp;
	struct mfii_ccb *list;

	mtx_enter(&sc->sc_abort_mtx);
	list = SIMPLEQ_FIRST(&sc->sc_abort_list);
	SIMPLEQ_INIT(&sc->sc_abort_list);
	mtx_leave(&sc->sc_abort_mtx);

	while (list != NULL) {
		struct mfii_ccb *ccb = list;
		struct scsi_xfer *xs = ccb->ccb_cookie;
		struct scsi_link *link = xs->sc_link;

		uint16_t dev_handle;
		struct mfii_ccb *accb;

		list = SIMPLEQ_NEXT(ccb, ccb_link);

		dev_handle = mfii_dev_handle(sc, link->target);
		if (dev_handle == htole16(0xffff)) {
			/* device is gone */
			if (atomic_dec_int_nv(&ccb->ccb_refcnt) == 0)
				scsi_done(xs);
			continue;
		}

		accb = scsi_io_get(&sc->sc_iopool, 0);
		mfii_scrub_ccb(accb);
		mfii_abort(sc, accb, dev_handle, ccb->ccb_smid,
		    MPII_SCSI_TASK_ABORT_TASK,
		    htole32(MFII_TASK_MGMT_FLAGS_PD));

		accb->ccb_cookie = ccb;
		accb->ccb_done = mfii_scsi_cmd_abort_done;

		mfii_start(sc, accb);
	}
}

void
mfii_abort(struct mfii_softc *sc, struct mfii_ccb *accb, uint16_t dev_handle,
    uint16_t smid, uint8_t type, uint32_t flags)
{
	struct mfii_task_mgmt *msg;
	struct mpii_msg_scsi_task_request *req;

	msg = accb->ccb_request;
	req = &msg->mpii_request;
	req->dev_handle = dev_handle;
	req->function = MPII_FUNCTION_SCSI_TASK_MGMT;
	req->task_type = type;
	htolem16(&req->task_mid, smid);
	msg->flags = flags;

	accb->ccb_req.flags = MFII_REQ_TYPE_HI_PRI;
	accb->ccb_req.smid = letoh16(accb->ccb_smid);
}

void
mfii_scsi_cmd_abort_done(struct mfii_softc *sc, struct mfii_ccb *accb)
{
	struct mfii_ccb *ccb = accb->ccb_cookie;
	struct scsi_xfer *xs = ccb->ccb_cookie;

	/* XXX check accb completion? */

	scsi_io_put(&sc->sc_iopool, accb);

	if (atomic_dec_int_nv(&ccb->ccb_refcnt) == 0)
		scsi_done(xs);
}

void *
mfii_get_ccb(void *cookie)
{
	struct mfii_softc *sc = cookie;
	struct mfii_ccb *ccb;

	mtx_enter(&sc->sc_ccb_mtx);
	ccb = SIMPLEQ_FIRST(&sc->sc_ccb_freeq);
	if (ccb != NULL)
		SIMPLEQ_REMOVE_HEAD(&sc->sc_ccb_freeq, ccb_link);
	mtx_leave(&sc->sc_ccb_mtx);

	return (ccb);
}

void
mfii_scrub_ccb(struct mfii_ccb *ccb)
{
	ccb->ccb_cookie = NULL;
	ccb->ccb_done = NULL;
	ccb->ccb_flags = 0;
	ccb->ccb_data = NULL;
	ccb->ccb_direction = 0;
	ccb->ccb_len = 0;
	ccb->ccb_sgl_len = 0;
	ccb->ccb_refcnt = 1;

	memset(&ccb->ccb_req, 0, sizeof(ccb->ccb_req));
	memset(ccb->ccb_request, 0, MFII_REQUEST_SIZE);
}

void
mfii_put_ccb(void *cookie, void *io)
{
	struct mfii_softc *sc = cookie;
	struct mfii_ccb *ccb = io;

	mtx_enter(&sc->sc_ccb_mtx);
	SIMPLEQ_INSERT_HEAD(&sc->sc_ccb_freeq, ccb, ccb_link);
	mtx_leave(&sc->sc_ccb_mtx);
}

int
mfii_init_ccb(struct mfii_softc *sc)
{
	struct mfii_ccb *ccb;
	u_int8_t *request = MFII_DMA_KVA(sc->sc_requests);
	u_int8_t *sense = MFII_DMA_KVA(sc->sc_sense);
	u_int8_t *sgl = MFII_DMA_KVA(sc->sc_sgl);
	u_int i;
	int error;

	sc->sc_ccb = mallocarray(sc->sc_max_cmds, sizeof(struct mfii_ccb),
	    M_DEVBUF, M_WAITOK|M_ZERO);

	for (i = 0; i < sc->sc_max_cmds; i++) {
		ccb = &sc->sc_ccb[i];

		/* create a dma map for transfer */
		error = bus_dmamap_create(sc->sc_dmat,
		    MAXPHYS, sc->sc_max_sgl, MAXPHYS, 0,
		    BUS_DMA_NOWAIT | BUS_DMA_ALLOCNOW, &ccb->ccb_dmamap);
		if (error) {
			printf("%s: cannot create ccb dmamap (%d)\n",
			    DEVNAME(sc), error);
			goto destroy;
		}

		/* select i + 1'th request. 0 is reserved for events */
		ccb->ccb_smid = i + 1;
		ccb->ccb_request_offset = MFII_REQUEST_SIZE * (i + 1);
		ccb->ccb_request = request + ccb->ccb_request_offset;
		ccb->ccb_request_dva = MFII_DMA_DVA(sc->sc_requests) +
		    ccb->ccb_request_offset;

		/* select i'th sense */
		ccb->ccb_sense_offset = MFI_SENSE_SIZE * i;
		ccb->ccb_sense = (struct mfi_sense *)(sense +
		    ccb->ccb_sense_offset);
		ccb->ccb_sense_dva = MFII_DMA_DVA(sc->sc_sense) +
		    ccb->ccb_sense_offset;

		/* select i'th sgl */
		ccb->ccb_sgl_offset = sizeof(struct mfii_sge) *
		    sc->sc_max_sgl * i;
		ccb->ccb_sgl = (struct mfii_sge *)(sgl + ccb->ccb_sgl_offset);
		ccb->ccb_sgl_dva = MFII_DMA_DVA(sc->sc_sgl) +
		    ccb->ccb_sgl_offset;

		/* add ccb to queue */
		mfii_put_ccb(sc, ccb);
	}

	return (0);

destroy:
	/* free dma maps and ccb memory */
	while ((ccb = mfii_get_ccb(sc)) != NULL)
		bus_dmamap_destroy(sc->sc_dmat, ccb->ccb_dmamap);

	free(sc->sc_ccb, M_DEVBUF, 0);

	return (1);
}

@


1.42
log
@disable aen handling.

on some or all original mfii boards (2208) the aen path fires repeatedly
without reporting anything, causes enough load to start actual io.

found by naddy@@
@
text
@d1 1
a1 1
/* $OpenBSD: mfii.c,v 1.41 2017/02/08 07:06:43 dlg Exp $ */
d722 1
a722 1
	free(sc->sc_pd, M_DEVBUF, 0);
d798 1
a798 1
	free(m, M_DEVBUF, 0);
d810 1
a810 1
	free(m, M_DEVBUF, 0);
@


1.41
log
@fix a mixup of lengths of addresses and lengths in the aen_start sgl

basically use htolem64 to set the address and htolem32 for the
length, not the other way round. lucky this is mostly run on x86.

found by Jon Kloske
@
text
@d1 1
a1 1
/* $OpenBSD: mfii.c,v 1.39 2017/02/07 04:43:59 dlg Exp $ */
d601 1
d606 1
d613 1
d616 1
@


1.40
log
@handle physical disk state changes.

more specificially we probe the disk if it goes from UNCONFIGURED_GOOD
to a SYSTEM disk, and detach it if goes from being a SYSTEM disk
to anything else.

this semantic comes from the lsi^Wavago code in the illumos mr_sas
driver. seems to work fine.

i think this covers all the ways a passthru disk can transition on
these boards.
@
text
@d894 2
a895 2
	htolem32(&sgl->sg64[0].addr, MFII_DMA_DVA(mdm));
	htolem64(&sgl->sg64[0].len, MFII_DMA_LEN(mdm));
@


1.39
log
@i got the MFII_TASK_MGMT flags round the wrong way.
@
text
@d1 1
a1 1
/* $OpenBSD: mfii.c,v 1.36 2017/02/07 02:47:19 dlg Exp $ */
d382 2
d945 8
d1000 24
@


1.38
log
@support hotplug of physical disks.

this only handles MFI_EVT_PD_INSERTED_EXT and MFI_EVT_PD_REMOVED_EXT so
far. if this code is to be reused in mfi, it should probably change to
use MFI_EVT_PD_INSERTED and MFI_EVT_PD_REMOVED instead.

unlike mpii and mpi, it looks like the firmware aborts outstanding
commands against a disk when it's physically removed, so we dont
have to explicitly abort them. this is probably a carry over from
mfi generation boards which dont have an explicit abort command
they can use.
@
text
@d156 2
a157 2
#define MFII_TASK_MGMT_FLAGS_PD				(1 << 0)
#define MFII_TASK_MGMT_FLAGS_LD				(1 << 1)
@


1.37
log
@add the framework around asynchronous event notifications.

this submits MR_DCMD_CTRL_EVENT_WAIT commands via the async dcmd
path to read all events from boot onward, and eventually ends up
waiting after the boot messages are consumed.

right now none of the events are handled, but this can be added now
this framework is in place.

the board does generate human readable log messages for every event.
we can send them somewhere (dmesg or syslog for example), but for
now theyre masked by #if 0.
@
text
@d378 5
d925 3
a927 2
	printf("%s: %u %08x %s\n", DEVNAME(sc), lemtoh32(&med->med_seq_num),
	    lemtoh32(&med->med_code), med->med_description);
d930 17
d948 42
@


1.36
log
@provide support for submitting async dcmd frames.

async dcmds are submitted via an mpii request (like the scsi commands
are) which uses the ccb_request buffer, meaning that the dcmd itself
has to go somewhere else. this reuses the sense buffer on the ccb
for the dcmd, and provides wrappers for accessing that space and
submitting a dcmd via the passthru command.
@
text
@d1 1
a1 1
/* $OpenBSD: mfii.c,v 1.35 2017/02/07 00:25:40 dlg Exp $ */
d262 3
d371 7
d492 3
d594 5
d604 2
d723 1
d820 111
@


1.35
log
@whitespace fixes. no functional change.
@
text
@d1 1
a1 1
/* $OpenBSD: mfii.c,v 1.34 2017/02/06 07:04:31 dlg Exp $ */
d368 34
d512 1
d781 9
d791 3
d795 5
@


1.34
log
@implement scsi command timeouts.

there's a struct timeout in scsi_xfer for this purpose, which is
used to schedule a timeout of the command in the future. the timeout
adds the xs to a list in mfii_softc of outstanding commands that
are to be aborted. this list is processed in a task so we can sleep
for an mfii_ccb. the new ccb is used to issue an abort against the
specific command that timed out.

to avoid having a timeout complete at the same time as a command
on the chip, a refcnt is added to ccbs. the chip and the timeout
get a ref each. the mfii completion path will attempt to timeout_del,
and if that's succesful it will subtract the timeouts ref as well
as its own. if it fails, the abort path owns the ccb and becomes
responsible for calling scsi_done on behalf of the mfii completion
path.
@
text
@d1 1
a1 1
/* $OpenBSD: mfii.c,v 1.33 2017/02/06 06:16:36 dlg Exp $ */
d194 1
a194 1
	/* data for sgl */  
d668 1
a668 1
	pci_intr_disestablish(sc->sc_pc, sc->sc_ih); 
d1194 1
a1194 1
        bus_space_write_raw_8(sc->sc_iot, sc->sc_ioh, MFI_IQPL, *r);
d1925 1
a1925 1
		ccb->ccb_sense = (struct mfi_sense *)(sense + 
@


1.33
log
@megaraid sas fusion chips have their own command for aborting tasks
@
text
@d1 1
a1 1
/* $OpenBSD: mfii.c,v 1.32 2017/01/23 05:18:45 dlg Exp $ */
d27 2
d210 1
d262 4
d357 1
d362 6
d448 4
d1396 2
d1427 2
d1430 1
d1444 4
d1469 2
a1470 1
	scsi_done(xs);
d1582 2
d1596 2
d1599 1
d1758 90
d1873 1
@


1.32
log
@rework how we address physical disks on the second scsibus.

to talk to a physical disk on mfii you need to know its physical
disk id and its current dev handle.

you can fetch a list of physical disks with a MR_DCMD_PD_GET_LIST
command, and you get the dev handle by fetching the associated info
from a MR_DCMD_LD_MAP_GET_INFO command.

i made a mistake and thought that the index into the PD_GET_LIST
info was the target id of a disk, and that should also be used as
the index into the LD_MAP_GET_INFO structures. it turns out that
the PD_GET_LIST is a dense array of info that points at the target
id, and the target id is used as the index into the LD_MAP_GET_INFO.

it also turns out that the dev handles from LD_MAP_GET_INFO can
change at runtime, so we should update them all when the bus topology
changes.

this change fetches a list of dev handles via LD_MAP_GET_INFO up
front, and makes them availble to the passthru bus scsi_cmd handler
via SRP. in the future hotplug events will update the map concurrently
with disk accesses.

also get rid of the probe for pd disks since the id from PD_GET_LIST
and what the scsibus automatically probes are the same. we just let
the midlayre blindly probe all possible targets on the passthru
bus. the pd scsibus probe handler still fetches specific disk info
to ensure we only provide access to disks marked as PASSTHRU in the
firmware.
@
text
@d1 1
a1 1
/* $OpenBSD: mfii.c,v 1.31 2017/01/23 04:26:57 dlg Exp $ */
d143 17
@


1.31
log
@store the full 64bits of the sense bufers dva.

this is in preparation of reusing the sense buffer for passthru dcmds
@
text
@d1 1
a1 1
/* $OpenBSD: mfii.c,v 1.30 2017/01/23 04:25:02 dlg Exp $ */
a194 6
struct mfii_pd_link {
	u_int16_t		pd_id;
	struct mfi_pd_details	pd_info;
	u_int16_t		pd_handle;
};

d198 1
a198 1
	struct mfii_pd_link	*pd_links[MFI_MAX_PD];
d334 2
d528 16
d545 1
a545 1
mfii_syspd(struct mfii_softc *sc)
a546 2
	struct scsibus_attach_args saa;
	struct scsi_link *link;
d548 1
a548 2
	struct mfii_pd_link *pl;
	struct mfi_pd_list *pd;
d550 2
a551 6
	u_int npds, i;
	int rv;

	sc->sc_pd = malloc(sizeof(*sc->sc_pd), M_DEVBUF, M_WAITOK|M_ZERO);
	if (sc->sc_pd == NULL)
		return (1);
d554 1
a554 2
	if (lm == NULL)
		goto free_pdsc;
a555 1
	ccb = scsi_io_get(&sc->sc_iopool, 0);
d558 1
d560 2
a561 1
	if (rv != 0)
d563 1
d565 7
d573 8
d582 4
a585 3
	pd = malloc(sizeof(*pd), M_TEMP, M_WAITOK|M_ZERO);
	if (pd == NULL)
		goto free_lm;
d587 2
a588 6
	ccb = scsi_io_get(&sc->sc_iopool, 0);
	rv = mfii_mgmt(sc, ccb, MR_DCMD_PD_GET_LIST, NULL,
	    pd, sizeof(*pd), SCSI_DATA_IN|SCSI_NOSLEEP);
	scsi_io_put(&sc->sc_iopool, ccb);
	if (rv != 0)
		goto free_pd;
d590 5
a594 5
	npds = letoh32(pd->mpl_no_pd);
	for (i = 0; i < npds; i++) {
		pl = malloc(sizeof(*pl), M_DEVBUF, M_WAITOK|M_ZERO);
		if (pl == NULL)
			goto free_pl;
d596 3
a598 4
		pl->pd_id = pd->mpl_address[i].mpa_pd_id;
		pl->pd_handle = lm->mlm_dev_handle[i].mdh_cur_handle;
		sc->sc_pd->pd_links[i] = pl;
	}
d600 3
a602 2
	free(pd, M_TEMP, 0);
	free(lm, M_TEMP, 0);
a618 5
free_pl:
	for (i = 0; i < npds; i++) {
		pl = sc->sc_pd->pd_links[i];
		if (pl == NULL)
			break;
a619 6
		free(pl, M_DEVBUF, 0);
	}
free_pd:
	free(pd, M_TEMP, 0);
free_lm:
	free(lm, M_TEMP, 0);
d1537 3
a1539 2
	if (mfii_pd_scsi_cmd_cdb(sc, xs) != 0)
		goto stuffup;
a1540 1
	xs->error = XS_NOERROR;
d1554 1
d1561 1
d1563 1
a1564 2
	struct mfii_softc *sc = link->adapter_softc;
	struct mfii_pd_link *pl = sc->sc_pd->pd_links[link->target];
a1569 3
	if (pl == NULL)
		return (ENXIO);

d1571 1
a1571 1
	mbox.s[0] = pl->pd_id;
d1574 2
a1575 2
	rv = mfii_mgmt(sc, ccb, MR_DCMD_PD_GET_INFO, &mbox, &pl->pd_info,
	    sizeof(pl->pd_info), SCSI_DATA_IN|SCSI_NOSLEEP);
d1580 1
a1580 1
	if (letoh16(pl->pd_info.mpd_fw_state) != MFI_PD_SYSTEM)
d1593 1
d1595 5
a1599 1
	io->dev_handle = sc->sc_pd->pd_links[link->target]->pd_handle;
d1630 1
a1630 1
		return (1);
d1636 1
a1636 1
	ccb->ccb_req.dev_handle = sc->sc_pd->pd_links[link->target]->pd_handle;
d1638 1
a1638 1
	return (0);
@


1.30
log
@add the mfii opcode for passthru commands
@
text
@d1 1
a1 1
/* $OpenBSD: mfii.c,v 1.29 2017/01/23 01:10:31 dlg Exp $ */
d163 1
a163 1
	u_int32_t		ccb_sense_dva;
d1776 2
a1777 2
		ccb->ccb_sense_dva = (u_int32_t)(MFII_DMA_DVA(sc->sc_sense) +
		    ccb->ccb_sense_offset);
@


1.29
log
@represent the mbox layout with union instead of an array of bytes.

memcpying uint16_ts into inconsistently addressed offsets is hard
to read, and this makes future work easier to implement.

tested on mfi(4) and mfii(4)
@
text
@d1 1
a1 1
/* $OpenBSD: mfii.c,v 1.28 2016/10/24 05:27:52 yasuoka Exp $ */
d54 1
@


1.28
log
@Backout last 2 revisions.  Requested by deraadt.
@
text
@d1 1
a1 1
/* $OpenBSD: mfii.c,v 1.25 2015/03/14 03:38:48 jsg Exp $ */
d329 2
a330 1
			    u_int32_t, u_int8_t *, void *, size_t, int);
d1044 2
a1045 1
    u_int32_t opc, u_int8_t *mbox, void *buf, size_t len, int flags)
d1086 1
a1086 1
		memcpy(dcmd->mdf_mbox, mbox, MFI_MBOX_SIZE);
d1553 1
a1553 1
	uint8_t mbox[MFI_MBOX_SIZE];
d1564 2
a1565 2
	memset(mbox, 0, sizeof(mbox));
	memcpy(&mbox[0], &pl->pd_id, sizeof(pl->pd_id));
d1568 1
a1568 1
	rv = mfii_mgmt(sc, ccb, MR_DCMD_PD_GET_INFO, mbox, &pl->pd_info,
@


1.27
log
@Make mfii(4) bio(4) capable.

ok dlg
@
text
@d1 1
a1 1
/* $OpenBSD: mfii.c,v 1.26 2016/10/24 03:11:58 yasuoka Exp $ */
a24 1
#include <sys/dkio.h>
a26 1
#include <sys/dkio.h>
a27 1
#include <dev/biovar.h>
a214 7
struct mfii_cfg {
	struct mfi_conf		*cfg;
	struct mfi_array	*cfg_array;
	struct mfi_ld_cfg	*cfg_ld;
	struct mfi_hotspare	*cfg_hs;
};

a252 3

	struct ksensor		*sc_sensors;
	struct ksensordev	sc_sensordev;
a257 1
int		mfii_scsi_ioctl(struct scsi_link *, u_long, caddr_t, int);
d280 1
a280 1
	mfii_scsi_ioctl
a336 20
int			mfii_scsi_ioctl_cache(struct scsi_link *, u_int,
			    struct dk_cache *);
#if NBIO > 0
int			mfii_ioctl(struct device *, u_long, caddr_t);
int			mfii_fill_cfg(struct mfii_softc *, struct mfii_cfg *);
int			mfii_ioctl_inq(struct mfii_softc *, struct bioc_inq *);
int			mfii_ioctl_vol(struct mfii_softc *, struct bioc_vol *);
int			mfii_ioctl_disk(struct mfii_softc *,
			    struct bioc_disk *);
int			mfii_ioctl_alarm(struct mfii_softc *,
			    struct bioc_alarm *);
int			mfii_ioctl_blink(struct mfii_softc *,
			    struct bioc_blink *);
int			mfii_ioctl_setstate(struct mfii_softc *,
			    struct bioc_setstate *);
int			mfii_ioctl_patrol(struct mfii_softc *,
			    struct bioc_patrol *);
int			mfii_create_sensors(struct mfii_softc *);
void			mfii_refresh_sensors(void *);
#endif
d509 1
a509 2
	sc->sc_scsibus = (struct scsibus_softc *)
	    config_found(&sc->sc_dev, &saa, scsiprint);
a516 10
#if NBIO > 0
	if (bio_register(&sc->sc_dev, mfii_ioctl) != 0)
		panic("%s: controller registration failed", DEVNAME(sc));

#ifndef SMALL_KERNEL
	if (mfii_create_sensors(sc) != 0)
		printf("%s: unable to create sensors\n", DEVNAME(sc));
#endif
#endif /* NBIO > 0 */

a623 4
	if (sc->sc_sensors) {
		sensordev_deinstall(&sc->sc_sensordev);
		free(sc->sc_sensors, M_DEVBUF, sc->sc_info.mci_lds_present);
	}
a1067 4
	default:
		ccb->ccb_direction = MFII_DATA_NONE;
		hdr->mfh_flags = htole16(MFI_FRAME_DIR_NONE);
		break;
a1798 789
int
mfii_scsi_ioctl(struct scsi_link *link, u_long cmd, caddr_t addr, int flag)
{
	switch (cmd) {
	case DIOCGCACHE:
	case DIOCSCACHE:
		return mfii_scsi_ioctl_cache(link, cmd,
		    (struct dk_cache *)addr);
	default:
#if NBIO > 0
		return mfii_ioctl(link->adapter_softc, cmd, addr);
#else
		break;
#endif
	}
	return (ENOTTY);
}

int
mfii_scsi_ioctl_cache(struct scsi_link *link, u_int cmd, struct dk_cache *dc)
{
	struct mfii_softc *sc = (struct mfii_softc *)link->adapter_softc;
	struct mfi_ld_prop ldp;
	uint8_t mbox[MFI_MBOX_SIZE];
	struct mfii_ccb *ccb;
	int rv, wrenable, rdenable;

	memset(mbox, 0, sizeof(mbox));
	*((uint16_t *)&mbox[0]) = htole16(link->target);
	ccb = scsi_io_get(&sc->sc_iopool, 0);
	rv = mfii_mgmt(sc, ccb, MR_DCMD_LD_GET_PROPERTIES, mbox,
	    &ldp, sizeof(ldp), SCSI_DATA_IN|SCSI_NOSLEEP);
	scsi_io_put(&sc->sc_iopool, ccb);
	if (rv != 0)
		return (rv);

	if (letoh16(sc->sc_info.mci_memory_size) > 0) {
		wrenable = ISSET(ldp.mlp_cur_cache_policy,
		    MR_LD_CACHE_ALLOW_WRITE_CACHE)? 1 : 0;
		rdenable = ISSET(ldp.mlp_cur_cache_policy,
		    MR_LD_CACHE_ALLOW_READ_CACHE)? 1 : 0;
	} else {
		wrenable = ISSET(ldp.mlp_diskcache_policy,
		    MR_LD_DISK_CACHE_ENABLE)? 1 : 0;
		rdenable = 0;
	}

	if (cmd == DIOCGCACHE) {
		dc->wrcache = wrenable;
		dc->rdcache = rdenable;
		return (0);
	}
	if (((dc->wrcache) ? 1 : 0) == wrenable &&
	    ((dc->rdcache) ? 1 : 0) == rdenable)
		return (0);

	mbox[0] = ldp.mlp_ld.mld_target;
	mbox[1] = ldp.mlp_ld.mld_res;
	*(uint16_t *)&mbox[2] = ldp.mlp_ld.mld_seq;
	if (letoh16(sc->sc_info.mci_memory_size) > 0) {
		if (dc->rdcache)
			SET(ldp.mlp_cur_cache_policy,
			    MR_LD_CACHE_ALLOW_READ_CACHE);
		else
			CLR(ldp.mlp_cur_cache_policy,
			    MR_LD_CACHE_ALLOW_READ_CACHE);
		if (dc->wrcache)
			SET(ldp.mlp_cur_cache_policy,
			    MR_LD_CACHE_ALLOW_WRITE_CACHE);
		else
			CLR(ldp.mlp_cur_cache_policy,
			    MR_LD_CACHE_ALLOW_WRITE_CACHE);
	} else {
		if (dc->rdcache)
			return (EOPNOTSUPP);
		if (dc->wrcache)
			ldp.mlp_diskcache_policy = MR_LD_DISK_CACHE_ENABLE;
		else
			ldp.mlp_diskcache_policy = MR_LD_DISK_CACHE_DISABLE;
	}

	ccb = scsi_io_get(&sc->sc_iopool, 0);
	rv = mfii_mgmt(sc, ccb, MR_DCMD_LD_SET_PROPERTIES, mbox,
	    &ldp, sizeof(ldp), SCSI_DATA_OUT|SCSI_NOSLEEP);
	scsi_io_put(&sc->sc_iopool, ccb);

	return (rv);
}

#if NBIO > 0
int
mfii_ioctl(struct device *dev, u_long cmd, caddr_t addr)
{
	struct mfii_softc *sc = (struct mfii_softc *)dev;
	int rv = ENOTTY;

	switch (cmd) {
	case BIOCINQ:
		rv = mfii_ioctl_inq(sc, (struct bioc_inq *)addr);
		break;
	case BIOCVOL:
		rv = mfii_ioctl_vol(sc, (struct bioc_vol *)addr);
		break;
	case BIOCDISK:
		rv = mfii_ioctl_disk(sc, (struct bioc_disk *)addr);
		break;
	case BIOCALARM:
		rv = mfii_ioctl_alarm(sc, (struct bioc_alarm *)addr);
		break;
	case BIOCBLINK:
		rv = mfii_ioctl_blink(sc, (struct bioc_blink *)addr);
		break;
	case BIOCSETSTATE:
		rv = mfii_ioctl_setstate(sc, (struct bioc_setstate *)addr);
		break;
	case BIOCPATROL:
		rv = mfii_ioctl_patrol(sc, (struct bioc_patrol *)addr);
		break;
	}

	return (rv);
}

int
mfii_fill_cfg(struct mfii_softc *sc, struct mfii_cfg *cfg)
{
	int rv, mfc_size;
	struct mfi_conf *mfc;
	struct mfii_ccb *ccb;

	mfc_size = sizeof(*mfc);
 again:
	mfc = malloc(mfc_size, M_TEMP, M_WAITOK | M_ZERO);
	ccb = scsi_io_get(&sc->sc_iopool, 0);
	rv = mfii_mgmt(sc, ccb, MR_DCMD_CONF_GET, NULL,
	    mfc, mfc_size, SCSI_DATA_IN|SCSI_NOSLEEP);
	scsi_io_put(&sc->sc_iopool, ccb);
	if (rv == 0) {
		mfc->mfc_size = letoh32(mfc->mfc_size);
		mfc->mfc_no_array = letoh16(mfc->mfc_no_array);
		mfc->mfc_array_size = letoh16(mfc->mfc_array_size);
		mfc->mfc_no_ld = letoh16(mfc->mfc_no_ld);
		mfc->mfc_ld_size = letoh16(mfc->mfc_ld_size);
		mfc->mfc_no_hs = letoh16(mfc->mfc_no_hs);
		mfc->mfc_hs_size = letoh16(mfc->mfc_hs_size);

		if (mfc_size < mfc->mfc_size) {
			mfc_size = mfc->mfc_size;
			free(mfc, M_TEMP, mfc_size);
			goto again;
		}
		/* remember allocated size for free() */
		mfc->mfc_size = mfc_size;

		cfg->cfg = mfc;
		cfg->cfg_array = (struct mfi_array *)((caddr_t)mfc +
		    offsetof(struct mfi_conf, mfc_array));
		cfg->cfg_ld = (struct mfi_ld_cfg *)((caddr_t)cfg->cfg_array +
		    mfc->mfc_array_size * mfc->mfc_no_array);
		cfg->cfg_hs = (struct mfi_hotspare *)((caddr_t)cfg->cfg_ld +
		    mfc->mfc_ld_size * mfc->mfc_no_ld);

		return (0);
	}

	free(mfc, M_TEMP, mfc_size);
	return (rv);
}

int
mfii_ioctl_inq(struct mfii_softc *sc, struct bioc_inq *bi)
{
	int rv;
	struct mfii_cfg cfg = { .cfg = NULL };

	rv = mfii_fill_cfg(sc, &cfg);
	if (rv != 0)
		return (rv);

	bi->bi_novol = cfg.cfg->mfc_no_ld + cfg.cfg->mfc_no_hs;
	bi->bi_nodisk = letoh16(sc->sc_info.mci_pd_disks_present);
	strlcpy(bi->bi_dev, DEVNAME(sc), sizeof(bi->bi_dev));

	if (cfg.cfg != NULL)
		free(cfg.cfg, M_TEMP, cfg.cfg->mfc_size);

	return (0);
}

int
mfii_ioctl_vol(struct mfii_softc *sc, struct bioc_vol *bv)
{
	int rv;
	struct mfii_cfg cfg = { .cfg = NULL };
	struct mfi_ld_cfg *ld;
	struct mfi_ld_list *list = NULL;
	struct scsi_link *link;
	struct mfii_ccb *ccb;
	uint8_t mbox[MFI_MBOX_SIZE];

	if ((link = scsi_get_link(sc->sc_scsibus, bv->bv_volid, 0)) != NULL &&
	    link->device_softc != NULL) {
		struct device *dev = link->device_softc;
		strlcpy(bv->bv_dev, dev->dv_xname, sizeof(bv->bv_dev));
	}
	rv = mfii_fill_cfg(sc, &cfg);
	if (rv != 0)
		goto done;

	if (bv->bv_volid >= cfg.cfg->mfc_no_ld) {
		int hsid;
		struct mfi_pd_details *pd;

		hsid = bv->bv_volid - cfg.cfg->mfc_no_ld;
		if (hsid >= cfg.cfg->mfc_no_hs)
			return (EINVAL);

		pd = malloc(sizeof(*pd), M_TEMP, M_WAITOK | M_ZERO);
		ccb = scsi_io_get(&sc->sc_iopool, 0);
		memset(mbox, 0, sizeof(mbox));
		*((uint16_t *)&mbox[0]) = cfg.cfg_hs[hsid].mhs_pd.mfp_id;
		rv = mfii_mgmt(sc, ccb, MR_DCMD_PD_GET_INFO, mbox,
		    pd, sizeof(*pd), SCSI_DATA_IN|SCSI_NOSLEEP);
		scsi_io_put(&sc->sc_iopool, ccb);
		if (rv == 0) {
			bv->bv_status = BIOC_SVONLINE;
			bv->bv_size = letoh64(pd->mpd_size) * 512;
			bv->bv_level = -1;
			bv->bv_nodisk = 1;
		}
		free(pd, M_TEMP, sizeof(*pd));

		goto done;
	}

	list = malloc(sizeof(*list), M_TEMP, M_WAITOK | M_ZERO);
	ccb = scsi_io_get(&sc->sc_iopool, 0);
	rv = mfii_mgmt(sc, ccb, MR_DCMD_LD_GET_LIST, NULL,
	    list, sizeof(*list), SCSI_DATA_IN|SCSI_NOSLEEP);
	scsi_io_put(&sc->sc_iopool, ccb);
	if (rv != 0)
		goto done;

	if (bv->bv_volid >= letoh32(list->mll_no_ld)) {
		rv = EINVAL;
		goto done;
	}

	switch (list->mll_list[bv->bv_volid].mll_state) {
	case MFI_LD_OFFLINE:
		bv->bv_status = BIOC_SVOFFLINE;
		break;
	case MFI_LD_PART_DEGRADED:
	case MFI_LD_DEGRADED:
		bv->bv_status = BIOC_SVDEGRADED;
		break;
	case MFI_LD_ONLINE:
		bv->bv_status = BIOC_SVONLINE;
		break;
	default:
		bv->bv_status = BIOC_SVINVALID;
		break;
	}
	bv->bv_size = letoh64(list->mll_list[bv->bv_volid].mll_size) * 512;

	ld = cfg.cfg->mfc_ld + bv->bv_volid;
	bv->bv_cache =
	    (ld->mlc_prop.mlp_cur_cache_policy & MR_LD_CACHE_WRITE_BACK)
	    ? BIOC_CVWRITEBACK : BIOC_CVWRITETHROUGH;

	switch (ld->mlc_parm.mpa_pri_raid) {
	case MFI_DDF_PRL_RAID0:
		bv->bv_level = 0;
		break;
	case MFI_DDF_PRL_RAID1:
	case MFI_DDF_PRL_RAID1E:
		bv->bv_level = 1;
		break;
	case MFI_DDF_PRL_RAID3:
		bv->bv_level = 3;
		break;
	case MFI_DDF_PRL_RAID4:
		bv->bv_level = 4;
		break;
	case MFI_DDF_PRL_RAID5:
	case MFI_DDF_PRL_RAID5E:
	case MFI_DDF_PRL_RAID5EE:
		bv->bv_level = 5;
		break;
	case MFI_DDF_PRL_RAID6:
		bv->bv_level = 6;
		break;
	case MFI_DDF_PRL_JBOD:
	case MFI_DDF_PRL_CONCAT:
	default:
		bv->bv_level = 0;
		break;
	}
	bv->bv_nodisk =
	    ld->mlc_parm.mpa_no_drv_per_span * ld->mlc_parm.mpa_span_depth;
 done:
	free(list, M_TEMP, sizeof(*list));
	if (cfg.cfg != NULL)
		free(cfg.cfg, M_TEMP, cfg.cfg->mfc_size);

	return (rv);
}

int
mfii_ioctl_disk(struct mfii_softc *sc, struct bioc_disk *bd)
{
	int rv, spanidx, diskidx, arrayidx, pdidx;
	struct mfii_cfg cfg = { .cfg = NULL };
	struct mfi_ld_cfg *ld;
	struct mfii_ccb *ccb;
	struct scsi_inquiry_data *inq;
	struct mfi_pd_details *pd_det = NULL;
	uint8_t mbox[MFI_MBOX_SIZE];

	rv = mfii_fill_cfg(sc, &cfg);
	if (rv != 0)
		goto done;

	if (bd->bd_volid >= cfg.cfg->mfc_no_ld) {
		int hsid = bd->bd_volid - cfg.cfg->mfc_no_ld;
		if (hsid >= cfg.cfg->mfc_no_hs) {
			rv = EINVAL;
			goto done;
		}
		pdidx = letoh16(cfg.cfg_hs[hsid].mhs_pd.mfp_id);
	} else {
		ld = cfg.cfg->mfc_ld + bd->bd_volid;
		spanidx = bd->bd_diskid / ld->mlc_parm.mpa_no_drv_per_span;
		diskidx = bd->bd_diskid % ld->mlc_parm.mpa_no_drv_per_span;
		if (spanidx < 0 || MFI_MAX_SPAN <= spanidx) {
			rv = EINVAL;
			goto done;
		}
		arrayidx =
		    letoh16(ld[bd->bd_volid].mlc_span[spanidx].mls_index);
		if (arrayidx < 0 || cfg.cfg->mfc_no_array <= arrayidx) {
			rv = EINVAL;
			goto done;
		}
		pdidx = letoh16(
		    cfg.cfg->mfc_array[arrayidx].pd[diskidx].mar_pd.mfp_id);
	}

	memset(mbox, 0, sizeof(mbox));
	*((uint16_t *)&mbox[0]) = htole16(pdidx);

	pd_det = malloc(sizeof(*pd_det), M_TEMP, M_WAITOK | M_ZERO);
	ccb = scsi_io_get(&sc->sc_iopool, 0);
	rv = mfii_mgmt(sc, ccb, MR_DCMD_PD_GET_INFO, mbox,
	    pd_det, sizeof(*pd_det), SCSI_DATA_IN|SCSI_NOSLEEP);
	scsi_io_put(&sc->sc_iopool, ccb);
	if (rv != 0)
		goto done;

	bd->bd_channel = pd_det->mpd_enc_idx;
	bd->bd_target = pd_det->mpd_enc_slot;

	switch (letoh16(pd_det->mpd_fw_state)) {
	case MFI_PD_UNCONFIG_GOOD:
		bd->bd_status = BIOC_SDUNUSED;
		break;
	case MFI_PD_UNCONFIG_BAD:
		bd->bd_status = BIOC_SDINVALID;
		break;
	case MFI_PD_HOTSPARE:
		bd->bd_status = BIOC_SDHOTSPARE;
		break;
	case MFI_PD_OFFLINE:
		bd->bd_status = BIOC_SDOFFLINE;
		break;
	case MFI_PD_FAILED:
		bd->bd_status = BIOC_SDFAILED;
		break;
	case MFI_PD_REBUILD:
		bd->bd_status = BIOC_SDREBUILD;
		break;
	case MFI_PD_ONLINE:
		bd->bd_status = BIOC_SDONLINE;
		break;
	case MFI_PD_COPYBACK:
	case MFI_PD_SYSTEM:
		bd->bd_status = BIOC_SDINVALID;
		break;
	}
	bd->bd_size = letoh64(pd_det->mpd_size) * 512;

	inq = (struct scsi_inquiry_data *)pd_det->mpd_inq_data;

	memset(bd->bd_vendor, 0, sizeof(bd->bd_vendor));
	memcpy(bd->bd_vendor, inq->vendor,
	    MIN(sizeof(bd->bd_vendor) - 1, sizeof(inq->vendor)));

	rv = 0;
 done:
	free(pd_det, M_TEMP, sizeof(*pd_det));
	if (cfg.cfg != NULL)
		free(cfg.cfg, M_TEMP, cfg.cfg->mfc_size);

	return (rv);
}

int
mfii_ioctl_setstate(struct mfii_softc *sc, struct bioc_setstate *bs)
{
	int rv, i;
	struct mfii_ccb *ccb;
	struct mfi_pd_list *list = NULL;
	struct mfi_pd_details *pd = NULL;
	uint8_t	mbox[MFI_MBOX_SIZE];

	list = malloc(sizeof(*list), M_TEMP, M_WAITOK | M_ZERO);
	pd = malloc(sizeof(*pd), M_TEMP, M_WAITOK | M_ZERO);

	ccb = scsi_io_get(&sc->sc_iopool, 0);
	rv = mfii_mgmt(sc, ccb, MR_DCMD_PD_GET_LIST, NULL,
	    list, sizeof(*list), SCSI_DATA_IN | SCSI_NOSLEEP);
	scsi_io_put(&sc->sc_iopool, ccb);
	if (rv != 0)
		goto done;

	for (i = 0; i < letoh16(list->mpl_no_pd); i++)
		if (list->mpl_address[i].mpa_enc_index == bs->bs_channel &&
		    list->mpl_address[i].mpa_enc_slot == bs->bs_target)
			break;
	if (i >= letoh16(list->mpl_no_pd)) {
		rv = EINVAL;
		goto done;
	}

	memset(mbox, 0, sizeof(mbox));
	*((uint16_t *)&mbox[0]) = list->mpl_address[i].mpa_pd_id;
	ccb = scsi_io_get(&sc->sc_iopool, 0);
	rv = mfii_mgmt(sc, ccb, MR_DCMD_PD_GET_INFO, mbox,
	    pd, sizeof(*pd), SCSI_DATA_IN | SCSI_NOSLEEP);
	scsi_io_put(&sc->sc_iopool, ccb);
	if (rv != 0)
		goto done;

	memset(mbox, 0, sizeof(mbox));
	*((uint16_t *)&mbox[0]) = pd->mpd_pd.mfp_id;
	*((uint16_t *)&mbox[2]) = pd->mpd_pd.mfp_seq;

	switch (bs->bs_status) {
	case BIOC_SSONLINE:
		*((uint16_t *)&mbox[4]) = htole16(MFI_PD_ONLINE);
		break;
	case BIOC_SSOFFLINE:
		*((uint16_t *)&mbox[4]) = htole16(MFI_PD_OFFLINE);
		break;
	case BIOC_SSHOTSPARE:
		*((uint16_t *)&mbox[4]) = htole16(MFI_PD_HOTSPARE);
		break;
	case BIOC_SSREBUILD:
		*((uint16_t *)&mbox[4]) = htole16(MFI_PD_REBUILD);
		break;
	default:
		rv = EINVAL;
		goto done;
	}

	ccb = scsi_io_get(&sc->sc_iopool, 0);
	rv = mfii_mgmt(sc, ccb, MR_DCMD_PD_SET_STATE, mbox,
	    NULL, 0, SCSI_NOSLEEP);
	scsi_io_put(&sc->sc_iopool, ccb);

 done:
	free(list, M_TEMP, sizeof(*list));
	free(pd, M_TEMP, sizeof(*pd));

	return (rv);
}

int
mfii_ioctl_alarm(struct mfii_softc *sc, struct bioc_alarm *ba)
{
	struct mfii_ccb *ccb;
	u_char spkr;
	int rv, cmd, flags = 0;

	if (!ISSET(letoh32(sc->sc_info.mci_hw_present), MFI_INFO_HW_ALARM))
		return (ENXIO);

	switch (ba->ba_status) {
	case BIOC_SADISABLE:
		cmd = MR_DCMD_SPEAKER_DISABLE;
		break;
	case BIOC_SAENABLE:
		cmd = MR_DCMD_SPEAKER_ENABLE;
		break;
	case BIOC_SASILENCE:
		cmd = MR_DCMD_SPEAKER_SILENCE;
		break;
	case BIOC_GASTATUS:
		cmd = MR_DCMD_SPEAKER_GET;
		flags = SCSI_DATA_IN;
		break;
	case BIOC_SATEST:
		cmd = MR_DCMD_SPEAKER_TEST;
		break;
	default:
		return (EINVAL);
	}

	ccb = scsi_io_get(&sc->sc_iopool, 0);
	rv = mfii_mgmt(sc, ccb, MR_DCMD_PD_SET_STATE, NULL,
	    &spkr, sizeof(spkr), flags | SCSI_NOSLEEP);
	scsi_io_put(&sc->sc_iopool, ccb);
	if (rv != 0)
		return (rv);

	ba->ba_status = (ba->ba_status == BIOC_GASTATUS)? spkr : 0;

	return (rv);
}

int
mfii_ioctl_blink(struct mfii_softc *sc, struct bioc_blink *bb)
{
	struct mfi_pd_list *list = NULL;
	struct mfii_ccb *ccb;
	uint8_t	mbox[MFI_MBOX_SIZE];
	int rv, i, cmd;

	list = malloc(sizeof(*list), M_TEMP, M_WAITOK | M_ZERO);

	ccb = scsi_io_get(&sc->sc_iopool, 0);
	rv = mfii_mgmt(sc, ccb, MR_DCMD_PD_GET_LIST, NULL,
	    list, sizeof(*list), SCSI_DATA_IN | SCSI_NOSLEEP);
	scsi_io_put(&sc->sc_iopool, ccb);
	if (rv != 0)
		goto done;

	for (i = 0; i < letoh16(list->mpl_no_pd); i++)
		if (list->mpl_address[i].mpa_enc_index == bb->bb_channel &&
		    list->mpl_address[i].mpa_enc_slot == bb->bb_target)
			break;
	if (i >= letoh16(list->mpl_no_pd)) {
		rv = EINVAL;
		goto done;
	}

	memset(mbox, 0, sizeof(mbox));
	*((uint16_t *)&mbox[0]) = list->mpl_address[i].mpa_pd_id;

	switch (bb->bb_status) {
	case BIOC_SBUNBLINK:
		cmd = MR_DCMD_PD_UNBLINK;
		break;
	case BIOC_SBBLINK:
	case BIOC_SBALARM:
		cmd = MR_DCMD_PD_BLINK;
		break;
	default:
		rv = EINVAL;
		goto done;
	}

	ccb = scsi_io_get(&sc->sc_iopool, 0);
	rv = mfii_mgmt(sc, ccb, cmd, NULL, NULL, 0, SCSI_NOSLEEP);
	scsi_io_put(&sc->sc_iopool, ccb);

 done:
	free(list, M_TEMP, sizeof(*list));

	return (ENOTTY);
}

int
mfii_ioctl_patrol(struct mfii_softc *sc, struct bioc_patrol *bp)
{
	int rv = EINVAL, cmd;
	struct mfii_ccb *ccb;
	struct mfi_pr_properties prop;
	struct mfi_pr_status status;
	uint32_t time;

	switch (bp->bp_opcode) {
	case BIOC_SPSTOP:
	case BIOC_SPSTART:
		cmd = (bp->bp_opcode == BIOC_SPSTART)
		    ? MR_DCMD_PR_START : MR_DCMD_PR_STOP;
		ccb = scsi_io_get(&sc->sc_iopool, 0);
		rv = mfii_mgmt(sc, ccb, cmd, NULL, NULL, 0, SCSI_NOSLEEP);
		scsi_io_put(&sc->sc_iopool, ccb);
		break;

	case BIOC_GPSTATUS:
		ccb = scsi_io_get(&sc->sc_iopool, 0);
		rv = mfii_mgmt(sc, ccb, MR_DCMD_PR_GET_PROPERTIES, NULL,
		    &prop, sizeof(prop), SCSI_DATA_IN | SCSI_NOSLEEP);
		scsi_io_put(&sc->sc_iopool, ccb);
		if (rv != 0)
			break;
		ccb = scsi_io_get(&sc->sc_iopool, 0);
		rv = mfii_mgmt(sc, ccb, MR_DCMD_PR_GET_STATUS, NULL,
		    &status, sizeof(status), SCSI_DATA_IN | SCSI_NOSLEEP);
		scsi_io_put(&sc->sc_iopool, ccb);
		if (rv != 0)
			break;
		ccb = scsi_io_get(&sc->sc_iopool, 0);
		rv = mfii_mgmt(sc, ccb, MR_DCMD_TIME_SECS_GET, NULL,
		    &time, sizeof(time), SCSI_DATA_IN | SCSI_NOSLEEP);
		scsi_io_put(&sc->sc_iopool, ccb);
		if (rv != 0)
			break;
		time = letoh32(time);

		switch (prop.op_mode) {
		case MFI_PR_OPMODE_AUTO:
			bp->bp_mode = BIOC_SPMAUTO;
			bp->bp_autoival = letoh32(prop.exec_freq);
			bp->bp_autonext = letoh32(prop.next_exec);
			bp->bp_autonow = time;
			break;
		case MFI_PR_OPMODE_MANUAL:
			bp->bp_mode = BIOC_SPMMANUAL;
			break;
		case MFI_PR_OPMODE_DISABLED:
			bp->bp_mode = BIOC_SPMDISABLED;
			break;
		}

		switch (status.state) {
		case MFI_PR_STATE_STOPPED:
			bp->bp_status = BIOC_SPSSTOPPED;
			break;
		case MFI_PR_STATE_READY:
			bp->bp_status = BIOC_SPSREADY;
			break;
		case MFI_PR_STATE_ACTIVE:
			bp->bp_status = BIOC_SPSACTIVE;
			break;
		case MFI_PR_STATE_ABORTED:
			bp->bp_status = BIOC_SPSABORTED;
			break;
		}
		break;

	case BIOC_SPDISABLE:
	case BIOC_SPMANUAL:
		ccb = scsi_io_get(&sc->sc_iopool, 0);
		rv = mfii_mgmt(sc, ccb, MR_DCMD_PR_GET_PROPERTIES, NULL,
		    &prop, sizeof(prop), SCSI_DATA_IN | SCSI_NOSLEEP);
		scsi_io_put(&sc->sc_iopool, ccb);
		if (rv != 0)
			break;
		prop.op_mode = (bp->bp_opcode == BIOC_SPDISABLE)
		    ? MFI_PR_OPMODE_DISABLED : MFI_PR_OPMODE_MANUAL;
		ccb = scsi_io_get(&sc->sc_iopool, 0);
		rv = mfii_mgmt(sc, ccb, MR_DCMD_PR_SET_PROPERTIES, NULL,
		    &prop, sizeof(prop), SCSI_DATA_OUT | SCSI_NOSLEEP);
		scsi_io_put(&sc->sc_iopool, ccb);
		break;

	case BIOC_SPAUTO:
		ccb = scsi_io_get(&sc->sc_iopool, 0);
		rv = mfii_mgmt(sc, ccb, MR_DCMD_PR_GET_PROPERTIES, NULL,
		    &prop, sizeof(prop), SCSI_DATA_IN | SCSI_NOSLEEP);
		scsi_io_put(&sc->sc_iopool, ccb);
		if (rv != 0)
			break;
		prop.op_mode = MFI_PR_OPMODE_AUTO;

		ccb = scsi_io_get(&sc->sc_iopool, 0);
		rv = mfii_mgmt(sc, ccb, MR_DCMD_TIME_SECS_GET, NULL,
		    &time, sizeof(time), SCSI_DATA_IN | SCSI_NOSLEEP);
		scsi_io_put(&sc->sc_iopool, ccb);
		if (rv != 0)
			break;
		time = letoh32(time);
		if (bp->bp_autoival != 0) {
			if (bp->bp_autoival == -1)
				prop.exec_freq = htole32(0xffffffffUL);
			else if (bp->bp_autoival > 0)
				prop.exec_freq = htole32(bp->bp_autoival);
			else {
				rv = EINVAL;
				break;
			}
		}
		if (bp->bp_autonext != 0) {
			if (bp->bp_autonext > 0)
				prop.next_exec =
				    htole32(time + bp->bp_autonext);
			else {
				rv = EINVAL;
				break;
			}
		}
		ccb = scsi_io_get(&sc->sc_iopool, 0);
		rv = mfii_mgmt(sc, ccb, MR_DCMD_PR_SET_PROPERTIES, NULL,
		    &prop, sizeof(prop), SCSI_DATA_OUT | SCSI_NOSLEEP);
		scsi_io_put(&sc->sc_iopool, ccb);
		break;
	}

	return (rv);
}

#ifndef SMALL_KERNEL
int
mfii_create_sensors(struct mfii_softc *sc)
{
	int i, no_ld;
	struct device *dev;
	struct scsi_link *link;

	no_ld = letoh16(sc->sc_info.mci_lds_present);

	strlcpy(sc->sc_sensordev.xname, DEVNAME(sc),
	    sizeof(sc->sc_sensordev.xname));

	sc->sc_sensors = mallocarray(no_ld, sizeof(struct ksensor),
	    M_DEVBUF, M_NOWAIT | M_ZERO);
	if (sc->sc_sensors == NULL)
		return (-1);

	for (i = 0; i < no_ld; i++) {
		if ((link = scsi_get_link(sc->sc_scsibus, i, 0)) == NULL ||
		    link->device_softc == NULL)
			goto err;

		dev = link->device_softc;
		sc->sc_sensors[i].type = SENSOR_DRIVE;
		sc->sc_sensors[i].status = SENSOR_S_UNKNOWN;
		strlcpy(sc->sc_sensors[i].desc, dev->dv_xname,
		    sizeof(sc->sc_sensors[i].desc));
		sensor_attach(&sc->sc_sensordev, &sc->sc_sensors[i]);
	}

	if (sensor_task_register(sc, mfii_refresh_sensors, 10) == NULL)
		goto err;

	sensordev_install(&sc->sc_sensordev);

	return (0);
 err:
	free(sc->sc_sensors, M_DEVBUF, no_ld);

	return (-1);
}

void
mfii_refresh_sensors(void *arg)
{
	int i, rv;
	struct mfi_ld_list *list = NULL;
	struct mfii_softc *sc = arg;
	struct mfii_ccb *ccb;

	list = malloc(sizeof(*list), M_TEMP, M_WAITOK | M_ZERO);
	ccb = scsi_io_get(&sc->sc_iopool, 0);
	rv = mfii_mgmt(sc, ccb, MR_DCMD_LD_GET_LIST, NULL,
	    list, sizeof(*list), SCSI_DATA_IN|SCSI_NOSLEEP);
	scsi_io_put(&sc->sc_iopool, ccb);

	if (rv == 0) {
		for (i = 0; i < letoh16(sc->sc_info.mci_lds_present); i++) {
			switch (list->mll_list[i].mll_state) {
			case MFI_LD_OFFLINE:
				sc->sc_sensors[i].value = SENSOR_DRIVE_FAIL;
				sc->sc_sensors[i].status = SENSOR_S_CRIT;
				break;
			case MFI_LD_PART_DEGRADED:
			case MFI_LD_DEGRADED:
				sc->sc_sensors[i].value = SENSOR_DRIVE_PFAIL;
				sc->sc_sensors[i].status = SENSOR_S_WARN;
				break;
			case MFI_LD_ONLINE:
				sc->sc_sensors[i].value = SENSOR_DRIVE_ONLINE;
				sc->sc_sensors[i].status = SENSOR_S_OK;
				break;
			default:
				sc->sc_sensors[i].value = 0; /* unknown */
				sc->sc_sensors[i].status = SENSOR_S_UNKNOWN;
				break;
			}
		}
	}

	free(list, M_TEMP, sizeof(*list));
}
#endif
#endif
@


1.26
log
@Add scsi ioctl hook to do a special treatment for DIOC{G,S}CACHE which
is already done in mfi(4).

ok dlg
@
text
@d1 1
a1 1
/* $OpenBSD: mfii.c,v 1.25 2015/03/14 03:38:48 jsg Exp $ */
d28 1
d30 1
d218 7
d263 3
d353 18
d543 2
a544 1
	config_found(&sc->sc_dev, &saa, scsiprint);
d552 10
d669 4
d1117 4
d1861 3
d1865 1
d1940 701
@


1.25
log
@Remove some includes include-what-you-use claims don't
have any direct symbols used.  Tested for indirect use by compiling
amd64/i386/sparc64 kernels.

ok tedu@@ deraadt@@
@
text
@d1 1
a1 1
/* $OpenBSD: mfii.c,v 1.24 2015/01/09 03:34:40 dlg Exp $ */
d25 1
d259 1
d282 1
a282 1
	NULL  /* ioctl */
d339 2
d1803 84
@


1.24
log
@implement mfii_scsi_cmd_io for handling actual io. previously i got
away with being lazy and just passing everything to the vanilla
scsi cdb path.

sending io via the cdb path with chained sgls seems to trigger a
firmware fault on the new invader boards. sending the same io via
the ldio path works fine though.

tested on invader and thunderbolt boards:

mfii0 at pci1 dev 0 function 0 "Symbios Logic MegaRAID SAS3108" rev 0x02: msi
mfii0: "PERC H730 Mini", firmware 25.2.1.0037, 1024MB cache

mfii0 at pci1 dev 0 function 0 "Symbios Logic MegaRAID SAS2208" rev 0x05: msi
mfii0: "PERC H710 Mini", firmware 21.3.0-0009, 512MB cache

ok jmatthew@@
@
text
@d1 1
a1 1
/* $OpenBSD: mfii.c,v 1.23 2015/01/07 10:26:48 dlg Exp $ */
a22 1
#include <sys/kernel.h>
@


1.23
log
@use the same trick as mpii for posting the request descriptor with
a single 64bit write on lp64 archs, instead of two sequenced 32bit
writes.  cos the 64bit store is atomic, we dont need the mutex
around it either.
@
text
@d1 1
a1 1
/* $OpenBSD: mfii.c,v 1.22 2015/01/07 04:56:56 dlg Exp $ */
d67 1
d75 4
d209 3
d343 3
d350 3
d354 3
a1351 1
#if 0
a1366 1
#endif
a1368 1
#if 0
a1370 1
#endif
d1422 1
d1424 31
a1454 2
	u_int64_t blkno;
	u_int32_t nblks;
d1456 7
a1462 1
	ccb->ccb_req.flags = MFII_REQ_TYPE_LDIO;
d1465 1
a1465 3
	scsi_cmd_rw_decode(xs->cmd, &blkno, &nblks);

	return (1);
@


1.22
log
@replace bcopy with memcpy. still cant see the bug im looking for.
@
text
@d1 1
a1 1
/* $OpenBSD: mfii.c,v 1.21 2015/01/07 04:46:18 dlg Exp $ */
d1126 1
a1126 1
	u_int32_t *r = (u_int32_t *)&ccb->ccb_req;
d1132 3
d1136 7
a1142 2
	mfii_write(sc, MFI_IQPL, r[0]);
	mfii_write(sc, MFI_IQPH, r[1]);
d1144 1
@


1.21
log
@i may as well turn bzero into memset while i am busy not having
luck finding my bug.
@
text
@d1 1
a1 1
/* $OpenBSD: mfii.c,v 1.20 2015/01/05 23:18:36 dlg Exp $ */
d1050 1
a1050 1
		bcopy(buf, dma_buf, len);
d1082 1
a1082 1
			bcopy(dma_buf, buf, len);
d1443 1
a1443 1
	bcopy(xs->cmd, io->cdb, xs->cmdlen);
d1554 1
a1554 1
	bcopy(xs->cmd, io->cdb, xs->cmdlen);
@


1.20
log
@there's already three different types of chips in this family of
controllers. the flags used in sgls on the first gen (thunderbolt)
are different to the ones used on the second and third gens (fury
and invader).

this creates an mfii_iop struct to store differences between these
chips, and uses them to set the flags on the sgls we generate for
the chip.

this solves lockups caused by stuck io on the following chips:

mfii0 at pci1 dev 0 function 0 "Symbios Logic MegaRAID SAS3108" rev 0x02: msi
mfii0: "PERC H730 Mini", firmware 25.2.1.0037, 1024MB cache

and

mfii0 at pci1 dev 0 function 0 "Symbios Logic MegaRAID SAS3008" rev 0x02: msi
mfii0: "PERC H330 Mini", firmware 25.2.1.0037

ive also tested this diff on:

mfii0 at pci10 dev 0 function 0 "Symbios Logic MegaRAID SAS2208" rev 0x05: msi
mfii0: "PERC H810 Adapter", firmware 21.2.0-0007, 1024MB cache

and

mfii0 at pci1 dev 0 function 0 "Symbios Logic MegaRAID SAS2208" rev 0x05: msi
mfii0: "PERC H710 Mini", firmware 21.3.0-0009, 512MB cache

Hrvoje Popovski reported the bug and verified the fix on his hardware.
@
text
@d1 1
a1 1
/* $OpenBSD: mfii.c,v 1.19 2014/10/08 14:44:39 dlg Exp $ */
d490 1
a490 1
	bzero(&saa, sizeof(saa));
d576 1
a576 1
	bzero(&saa, sizeof(saa));
d1177 1
a1177 1
	bzero(iiq, sizeof(*iiq));
d1603 1
a1603 1
		bzero(ccb->ccb_sgl, ccb->ccb_sgl_len);
d1666 2
a1667 2
	bzero(&ccb->ccb_req, sizeof(ccb->ccb_req));
	bzero(ccb->ccb_request, MFII_REQUEST_SIZE);
@


1.19
log
@add support for megaraid 3008 (fury) and 3108 (invader) cards. the
new dell h730 is a rebaged 3108.

adding the ids appears to be enough to support this chip. ill need
to check the sgl code to be sure though.
@
text
@d1 1
a1 1
/* $OpenBSD: mfii.c,v 1.18 2014/09/30 18:02:33 kettenis Exp $ */
d203 5
d210 1
d334 3
a336 4
static const struct pci_matchid mfii_devices[] = {
	{ PCI_VENDOR_SYMBIOS,	PCI_PRODUCT_SYMBIOS_MEGARAID_2208 },
	{ PCI_VENDOR_SYMBIOS,	PCI_PRODUCT_SYMBIOS_MEGARAID_3008 },
	{ PCI_VENDOR_SYMBIOS,	PCI_PRODUCT_SYMBIOS_MEGARAID_3108 }
d339 39
d381 1
a381 1
	return (pci_matchbyid(aux, mfii_devices, nitems(mfii_devices)));
d395 1
d1608 1
a1608 2
		ce->sg_flags = MFII_SGE_CHAIN_ELEMENT |
		    MFII_SGE_ADDR_IOCPLBNTA;
d1625 1
@


1.18
log
@Add support for "physical devices".  Tested on:

mfii0 at pci1 dev 0 function 0 "Symbios Logic MegaRAID SAS2208" rev 0x05: msi
mfii0: "LSI MegaRAID ROMB", firmware 23.22.0-0012, 1024MB cache

ok dlg@@
@
text
@d1 1
a1 1
/* $OpenBSD: mfii.c,v 1.17 2014/07/13 23:10:23 deraadt Exp $ */
d329 3
a331 1
	{ PCI_VENDOR_SYMBIOS,	PCI_PRODUCT_SYMBIOS_MEGARAID_2208 }
@


1.17
log
@Some reallocarray() use; review Jean-Philippe Ouellet, patrick keshishian
ok tedu
@
text
@d1 1
a1 1
/* $OpenBSD: mfii.c,v 1.16 2014/07/12 18:48:52 tedu Exp $ */
d51 1
d63 1
a63 1
	u_int16_t	field;
d66 2
d111 28
d190 13
d236 1
d270 9
d296 1
d322 2
d448 2
d468 86
d1408 114
@


1.16
log
@add a size argument to free. will be used soon, but for now default to 0.
after discussions with beck deraadt kettenis.
@
text
@d1 1
a1 1
/* $OpenBSD: mfii.c,v 1.15 2014/03/28 22:25:49 dlg Exp $ */
d1385 1
a1385 1
	sc->sc_ccb = malloc(sizeof(struct mfii_ccb) * sc->sc_max_cmds,
@


1.15
log
@if you split a 64bit thing into two 32bit halves, it helps to write
half of the source value to both the hi and lo parts. writing both
of the source halves to just lo isnt going to work good.

found by naddy@@. sorry guys.
@
text
@d1 1
a1 1
/* $OpenBSD: mfii.c,v 1.14 2014/03/27 23:17:40 dlg Exp $ */
d479 1
a479 1
	free(m, M_DEVBUF);
d491 1
a491 1
	free(m, M_DEVBUF);
d1433 1
a1433 1
	free(sc->sc_ccb, M_DEVBUF);
@


1.14
log
@unbreak mfii after i changed the layout of some structures it borrows
from mpii.

disappointment from deraadt@@
@
text
@d1 1
a1 1
/* $OpenBSD: mfii.c,v 1.13 2013/08/30 08:51:56 haesbaert Exp $ */
d1011 1
a1011 1
	htolem32(&iiq->system_request_frame_base_address_lo,
@


1.13
log
@Turn on msi for mfii(4).

There is a family of Supermicro boards where the apic pin is
incorrectly mapped on acpi, it tells us the pin for "Intel boot
interrupts". Since this is a fairly new chip, lets use MSI as no one
else is probably using it via apic, this fixes the routing issues.

Machines/Motherboards seen so far with incorrect routing:
Supermicro X9DR3-F
Supermicro X9DRH + Symbios Logic MegaRAID SAS2208
Fujitsu primergy RX300 S7 + Symbios Logic MegaRAID SAS2208

ok dlg@@
@
text
@d1 1
a1 1
/* $OpenBSD: mfii.c,v 1.12 2012/08/25 07:03:04 haesbaert Exp $ */
d1001 2
a1002 2
	iiq->sense_buffer_address_high =
	    htole32(MFII_DMA_DVA(sc->sc_sense) >> 32);
d1004 9
a1012 5
	iiq->reply_descriptor_post_queue_address =
	    htole64(MFII_DMA_DVA(sc->sc_reply_postq));

	iiq->system_request_frame_base_address =
	    htole64(MFII_DMA_DVA(sc->sc_requests));
@


1.12
log
@Make sure we disable interrupts on attachment before re-enabling.

ok dlg@@.
@
text
@d1 1
a1 1
/* $OpenBSD: mfii.c,v 1.11 2012/08/25 07:01:35 haesbaert Exp $ */
d310 1
a310 1
	if (pci_intr_map(pa, &ih) != 0) {
@


1.11
log
@Small cleanup.

ok dlg@@.
@
text
@d1 1
a1 1
/* $OpenBSD: mfii.c,v 1.10 2012/08/23 11:18:53 dlg Exp $ */
d306 3
@


1.10
log
@the chain_offset in mfii requests are in 16 byte units, not 4 like
mpii. this stops the chip from freaking out on me when doing chained
sgls.

found by alex wilson who wins prizes.
@
text
@d1 1
a1 1
/* $OpenBSD: mfii.c,v 1.9 2012/08/23 07:21:06 dlg Exp $ */
d1155 2
a1156 4
		if (mfii_poll(sc, ccb) != 0) {
			xs->error = XS_DRIVER_STUFFUP;
			scsi_done(xs);
		}
@


1.9
log
@turns out - is not commutative.

correctly determine the number of segments in the next chain, and also
figure out the correct offset for the chain element at the end of the
request frame.
@
text
@d1 1
a1 1
/* $OpenBSD: mfii.c,v 1.7 2012/08/20 07:38:43 dlg Exp $ */
d1290 3
a1292 1
		ccb->ccb_sgl_len = (dmap->dm_nsegs - space) * sizeof(*sge);
d1300 1
a1300 1
		req->chain_offset = ((u_int8_t *)ce - (u_int8_t *)req) / 4;
d1311 1
d1414 2
a1415 2
		ccb->ccb_sgl_dva = (MFII_DMA_DVA(sc->sc_sgl) +
		    ccb->ccb_sgl_offset);
@


1.8
log
@stupid code bug.

instead of initting the ccbs sgl dma virtual address, i was assigning it
to the sense memories dva. this means we wouldnt be getting sense data
where we thought it was, and passing NULL (does NULL mean anything over
a pci bus?) to the hardware when we have long sgl chains.

hopefully this fixes the NMIs ive been getting.
@
text
@d1289 2
a1290 1
		ccb->ccb_sgl_len = (space - dmap->dm_nsegs) * sizeof(*sge);
d1292 1
a1292 1
		ce = nsge + space - 1;
d1298 1
a1298 1
		req->chain_offset = ((u_int8_t *)req - (u_int8_t *)ce) / 4;
@


1.7
log
@add support for chaining a scatter gather list off a request frame if it
runs out of space for entries.
@
text
@d1 1
a1 1
/* $OpenBSD: mfii.c,v 1.6 2012/08/16 07:55:08 dlg Exp $ */
d1410 1
a1410 1
		ccb->ccb_sense_dva = (MFII_DMA_DVA(sc->sc_sgl) +
@


1.6
log
@mfii_exec_done clears ccb_cookie, so mfii_exec should test that, not
ccb_done.
@
text
@d1 1
a1 1
/* $OpenBSD: mfii.c,v 1.5 2012/08/16 04:41:49 dlg Exp $ */
d130 5
d185 1
d343 5
d350 1
a350 1
		goto free_requests;
d356 1
a356 1
		goto free_requests;
d362 1
a362 1
		goto free_requests;
d374 1
a374 1
		goto free_requests;
d393 2
a394 1

d414 1
d950 6
d1266 1
d1268 1
d1270 1
d1286 14
d1301 3
d1316 6
d1344 1
d1346 1
a1346 1
	ccb->ccb_done = NULL;
a1347 1
	ccb->ccb_data = NULL;
d1349 1
d1372 2
a1373 2
	u_int32_t i;
	int max_sgl;
a1375 3
	max_sgl = (MFII_REQUEST_SIZE - (sizeof(struct mpii_msg_scsi_io) +
	    sizeof(struct mfii_raid_context))) / sizeof(struct mpii_sge);

d1379 2
a1380 2
	for (i = 1; i <= sc->sc_max_cmds; i++) {
		ccb = &sc->sc_ccb[i - 1];
d1384 1
a1384 2
		    // MAXPHYS, sc->sc_max_sgl, MAXPHYS, 0,
		    MAXPHYS, max_sgl, MAXPHYS, 0,
d1392 3
a1394 3
		/* select i'th request */
		ccb->ccb_smid = i;
		ccb->ccb_request_offset = MFII_REQUEST_SIZE * i;
d1400 1
a1400 1
		ccb->ccb_sense_offset = MFI_SENSE_SIZE * (i - 1);
d1405 7
@


1.5
log
@white space, no real changes
@
text
@d1 1
a1 1
/* $OpenBSD: mfii.c,v 1.4 2012/08/16 04:36:37 dlg Exp $ */
d799 1
a799 1
	while (ccb->ccb_done != NULL)
@


1.4
log
@move completions of ccbs out of the postq mutex. avoids the unlikely but
still possible deadlock that can occur if a completion starts a polled
command.
@
text
@d1 1
a1 1
/* $OpenBSD: mfii.c,v 1.3 2012/08/16 04:28:36 dlg Exp $ */
d855 1
a855 1
        hdr->mfh_sg_count = ccb->ccb_dmamap->dm_nsegs;
d898 4
a901 4
        if (error) {
                printf("%s: error %d loading dmamap\n", DEVNAME(sc), error);
                return (1);
        }
d1159 2
a1160 2
        case MFI_STAT_OK:
                break;
d1162 5
a1166 5
        case MFI_STAT_SCSI_DONE_WITH_ERROR:
                xs->error = XS_SENSE;
                memset(&xs->sense, 0, sizeof(xs->sense));
                memcpy(&xs->sense, ccb->ccb_sense, sizeof(xs->sense));
                break;
d1170 1
a1170 1
                xs->error = XS_SELTIMEOUT;
d1173 4
a1176 4
        default:
                xs->error = XS_DRIVER_STUFFUP;
                break;
        }
d1259 4
a1262 4
        if (error) {
                printf("%s: error %d loading dmamap\n", DEVNAME(sc), error);
                return (1);
        }
@


1.3
log
@replace the SLIST for ccbs with a SIMPLEQ so i can add stuff to the end
of ccb lists.
@
text
@d1 1
a1 1
/* $OpenBSD: mfii.c,v 1.2 2012/08/16 03:50:14 dlg Exp $ */
d1046 1
d1072 1
a1072 1
		mfii_done(sc, ccb);
d1088 5
@


1.2
log
@rewrite the mfii_mgmt path to be a bit more... symmetrical.
@
text
@d1 1
a1 1
/* $OpenBSD: mfii.c,v 1.1 2012/08/14 00:27:51 dlg Exp $ */
d150 1
a150 1
	SLIST_ENTRY(mfii_ccb)	ccb_link;
d152 1
a152 1
SLIST_HEAD(mfii_ccb_list, mfii_ccb);
d287 1
a287 1
	SLIST_INIT(&sc->sc_ccb_freeq);
d1281 1
a1281 1
	ccb = SLIST_FIRST(&sc->sc_ccb_freeq);
d1283 1
a1283 1
		SLIST_REMOVE_HEAD(&sc->sc_ccb_freeq, ccb_link);
d1310 1
a1310 1
	SLIST_INSERT_HEAD(&sc->sc_ccb_freeq, ccb, ccb_link);
@


1.1
log
@introduce mfii(4), a driver for the generation of megaraid sas boards
after the ones currently supported by mfi(4).

mfii is to mfi what mpii is to mpi. it is also strange in that it reuses
bits of both mfi(4) and mpii(4) hardware structures. the register layout
is sort of like mfi, but the majority of the messaging (post and
completion paths) are like mpii. the new logical disk io message is
the same as the scsi io command in mpii with an extra raid context bit on
the end.

other operating systems have supported the new hardware in their existing
megaraid sas drivers by cutting them in half and using a metric buttload of
function pointers at pretty much every driver entry point to switch between
the non-fusion behaviour and the fusion behavior. the only really common
code seems to be the handling of the management commands before branching
off into the chip specific message handling to move it on and off the
hardware. i'll deal with abstracting the mgmt stuff out later.

this is working so im getting it in now to polish further in the tree.

ok by mikeb@@ haesbaert@@ deraadt@@ matthew@@
@
text
@d1 1
a1 1
/* $OpenBSD$ */
a133 2
	union mfi_sgl		*ccb_sgl;

d241 2
a245 2
void			mfii_empty_done(struct mfii_softc *,
			    struct mfii_ccb *);
d249 2
d254 2
a255 6
int			mfii_mgmt(struct mfii_softc *, u_int32_t, u_int32_t,
			    u_int32_t, void *, u_int8_t *);
int			mfii_do_mgmt(struct mfii_softc *, struct mfii_ccb *,
			    u_int32_t, u_int32_t, u_int32_t, void *,
			    u_int8_t *);
void			mfii_mgmt_done(struct mfii_softc *, struct mfii_ccb *);
a260 2
int			mfii_create_sgl(struct mfii_softc *, struct mfii_ccb *,
			    int);
d538 10
a547 3
	if (mfii_mgmt(sc, MR_DCMD_CTRL_GET_INFO, MFII_DATA_IN,
	    sizeof(sc->sc_info), &sc->sc_info, NULL))
		return (1);
d702 5
d709 1
a709 1
	hdr->mfh_flags |= MFI_FRAME_DONT_POST_IN_REPLY_QUEUE;
d739 8
a746 1
	ccb->ccb_done(sc, ccb);
d767 1
a767 1
		delay(1);
d786 1
a786 2
mfii_mgmt(struct mfii_softc *sc, u_int32_t opc, u_int32_t dir, u_int32_t len,
    void *buf, uint8_t *mbox)
d788 17
a804 2
	struct mfii_ccb *ccb;
	int rv;
d806 4
a809 4
	ccb = scsi_io_get(&sc->sc_iopool, 0);
	mfii_scrub_ccb(ccb);
	rv = mfii_do_mgmt(sc, ccb, opc, dir, len, buf, mbox);
	scsi_io_put(&sc->sc_iopool, ccb);
d811 4
a814 1
	return (rv);
d818 2
a819 2
mfii_do_mgmt(struct mfii_softc *sc, struct mfii_ccb *ccb, u_int32_t opc,
    u_int32_t dir, u_int32_t len, void *buf, uint8_t *mbox)
d821 5
a825 4
	struct mfi_dcmd_frame	*dcmd;
	int			rv = EINVAL;
	uint8_t			*dma_buf = NULL;
	//int			s;
d829 20
d850 1
d852 4
a855 4
	dcmd = ccb->ccb_request;
	memset(dcmd->mdf_mbox, 0, MFI_MBOX_SIZE);
	dcmd->mdf_header.mfh_cmd = MFI_CMD_DCMD;
	dcmd->mdf_header.mfh_timeout = 0;
a857 5
	dcmd->mdf_header.mfh_data_len = htole32(0);
	ccb->ccb_direction = dir;
	ccb->ccb_cookie = ccb;
	ccb->ccb_done = mfii_mgmt_done;

d859 1
a859 1
	if (mbox)
d862 6
a867 12
	if (dir != MFII_DATA_NONE) {
		if (dir == MFII_DATA_OUT)
			bcopy(buf, dma_buf, len);
		dcmd->mdf_header.mfh_data_len = htole32(len);
		ccb->ccb_data = dma_buf;
		ccb->ccb_len = len;
		ccb->ccb_sgl = &dcmd->mdf_sgl;

		if (mfii_create_sgl(sc, ccb, BUS_DMA_WAITOK)) {
			rv = EINVAL;
			goto done;
		}
d870 2
a871 10
	if (cold) {
		if (mfii_mfa_poll(sc, ccb)) {
			rv = EIO;
			goto done;
		}
	} else {
		panic("%s !cold", __func__);
#if 0
		s = splbio();
		mfii_start(sc, ccb);
d873 2
a874 9
		while (ccb->ccb_cookie != NULL)
			tsleep(ccb, PRIBIO, "mfimgmt", 0);
		splx(s);

		if (ccb->ccb_flags & MFI_CCB_F_ERR) {
			rv = EIO;
			goto done;
		}
#endif
a876 4
	if (dir == MFII_DATA_IN)
		bcopy(dma_buf, buf, len);

	rv = 0;
d878 1
a878 2
	if (dma_buf)
		dma_free(dma_buf, len);
d883 3
a885 2
void
mfii_mgmt_done(struct mfii_softc *sc, struct mfii_ccb *ccb)
d887 4
a890 1
	struct mfi_frame_header *hdr = ccb->ccb_request;
d892 2
a893 5
	if (ccb->ccb_data != NULL) {
		bus_dmamap_sync(sc->sc_dmat, ccb->ccb_dmamap, 0,
		    ccb->ccb_dmamap->dm_mapsize,
		    (ccb->ccb_direction & MFII_DATA_IN) ?
		    BUS_DMASYNC_POSTREAD : BUS_DMASYNC_POSTWRITE);
d895 7
a901 2
		bus_dmamap_unload(sc->sc_dmat, ccb->ccb_dmamap);
	}
d903 3
a905 27
	if (hdr->mfh_cmd_status != MFI_STAT_OK)
		ccb->ccb_flags |= MFI_CCB_F_ERR;

	ccb->ccb_cookie = NULL;

	wakeup(ccb);
}

int 
mfii_create_sgl(struct mfii_softc *sc, struct mfii_ccb *ccb, int flags)
{
	struct mfi_frame_header *hdr;
	bus_dma_segment_t *sgd;
	union mfi_sgl *sgl;
	int error, i;

	if (ccb->ccb_data == NULL)
		return (1);

	error = bus_dmamap_load(sc->sc_dmat, ccb->ccb_dmamap,
	    ccb->ccb_data, ccb->ccb_len, NULL, flags);
	if (error) {
		if (error == EFBIG)   
			printf("more than %d dma segs\n", sc->sc_max_sgl);
		else
			printf("error %d loading dma map\n", error);
		return (1);
d908 3
a910 19
	hdr = ccb->ccb_request;
	sgl = ccb->ccb_sgl;
	sgd = ccb->ccb_dmamap->dm_segs;
	for (i = 0; i < ccb->ccb_dmamap->dm_nsegs; i++) {
		sgl->sg32[i].addr = htole32(sgd[i].ds_addr);
		sgl->sg32[i].len = htole32(sgd[i].ds_len);
	}

	if (ccb->ccb_direction == MFII_DATA_IN) {
		hdr->mfh_flags |= MFI_FRAME_DIR_READ;
		bus_dmamap_sync(sc->sc_dmat, ccb->ccb_dmamap, 0,
		    ccb->ccb_dmamap->dm_mapsize, BUS_DMASYNC_PREREAD);
	} else {
		hdr->mfh_flags |= MFI_FRAME_DIR_WRITE;
		bus_dmamap_sync(sc->sc_dmat, ccb->ccb_dmamap, 0,
		    ccb->ccb_dmamap->dm_mapsize, BUS_DMASYNC_PREWRITE);
	}

	hdr->mfh_sg_count = ccb->ccb_dmamap->dm_nsegs;
d937 9
a948 6
void
mfii_empty_done(struct mfii_softc *sc, struct mfii_ccb *ccb)
{
	/* nop */
}

a1004 1
	ccb->ccb_done = mfii_empty_done;
a1148 1
	bus_dmamap_t dmap = ccb->ccb_dmamap;
a1151 7
	if (ccb->ccb_len != 0) {
		bus_dmamap_sync(sc->sc_dmat, dmap, 0, dmap->dm_mapsize,
		    ccb->ccb_direction == MFII_DATA_OUT ?
		    BUS_DMASYNC_PREWRITE : BUS_DMASYNC_PREREAD);
		bus_dmamap_unload(sc->sc_dmat, dmap);
	}

a1295 1
	ccb->ccb_sgl = NULL;
@

