head	1.102;
access;
symbols
	OPENBSD_6_1:1.102.0.2
	OPENBSD_6_1_BASE:1.102
	OPENBSD_6_0:1.95.0.4
	OPENBSD_6_0_BASE:1.95
	OPENBSD_5_9:1.92.0.2
	OPENBSD_5_9_BASE:1.92
	OPENBSD_5_8:1.78.0.4
	OPENBSD_5_8_BASE:1.78
	OPENBSD_5_7:1.75.0.4
	OPENBSD_5_7_BASE:1.75
	OPENBSD_5_6:1.61.0.4
	OPENBSD_5_6_BASE:1.61
	OPENBSD_5_5:1.56.0.4
	OPENBSD_5_5_BASE:1.56
	OPENBSD_5_4:1.42.0.4
	OPENBSD_5_4_BASE:1.42
	OPENBSD_5_3:1.42.0.2
	OPENBSD_5_3_BASE:1.42
	OPENBSD_5_2:1.30.0.4
	OPENBSD_5_2_BASE:1.30
	OPENBSD_5_1_BASE:1.30
	OPENBSD_5_1:1.30.0.2
	OPENBSD_5_0:1.29.0.2
	OPENBSD_5_0_BASE:1.29
	OPENBSD_4_9:1.12.0.4
	OPENBSD_4_9_BASE:1.12
	OPENBSD_4_8:1.12.0.2
	OPENBSD_4_8_BASE:1.12
	OPENBSD_4_7:1.11.0.2
	OPENBSD_4_7_BASE:1.11
	OPENBSD_4_6:1.10.0.6
	OPENBSD_4_6_BASE:1.10
	OPENBSD_4_5:1.10.0.2
	OPENBSD_4_5_BASE:1.10
	OPENBSD_4_4:1.7.0.2
	OPENBSD_4_4_BASE:1.7
	OPENBSD_4_3:1.6.0.2
	OPENBSD_4_3_BASE:1.6
	OPENBSD_4_2:1.5.0.2
	OPENBSD_4_2_BASE:1.5;
locks; strict;
comment	@ * @;


1.102
date	2017.02.07.06.51.58;	author dlg;	state Exp;
branches;
next	1.101;
commitid	WWdq3lXKnxKhvKAa;

1.101
date	2017.01.24.03.57.35;	author dlg;	state Exp;
branches;
next	1.100;
commitid	PERtGPXCvlLRRBr8;

1.100
date	2017.01.22.10.17.38;	author dlg;	state Exp;
branches;
next	1.99;
commitid	VyLWTsbepAOk7VQM;

1.99
date	2016.10.31.01.38.57;	author dlg;	state Exp;
branches;
next	1.98;
commitid	mBgvFlsJVH8d545O;

1.98
date	2016.10.31.01.23.46;	author dlg;	state Exp;
branches;
next	1.97;
commitid	pjavtorA4mAPvpIP;

1.97
date	2016.10.28.10.14.16;	author dlg;	state Exp;
branches;
next	1.96;
commitid	ca5q5RzsAXrwme3g;

1.96
date	2016.09.15.02.00.17;	author dlg;	state Exp;
branches;
next	1.95;
commitid	RlO92XR575sygHqm;

1.95
date	2016.05.23.15.22.44;	author tedu;	state Exp;
branches;
next	1.94;
commitid	Hsu9ZZbSw737UJHI;

1.94
date	2016.04.13.11.36.00;	author mpi;	state Exp;
branches;
next	1.93;
commitid	nHRUtEnkD6rbEjY0;

1.93
date	2016.04.13.10.34.32;	author mpi;	state Exp;
branches;
next	1.92;
commitid	8YSL8ByWzGeIGBiJ;

1.92
date	2015.12.11.16.07.02;	author mpi;	state Exp;
branches;
next	1.91;
commitid	fbhqfhfdKxBcsetK;

1.91
date	2015.12.09.03.22.39;	author dlg;	state Exp;
branches;
next	1.90;
commitid	ORE7f8VM8QK0ujAk;

1.90
date	2015.12.03.12.45.56;	author dlg;	state Exp;
branches;
next	1.89;
commitid	Be8SvhCNSjXXFAIz;

1.89
date	2015.12.01.12.37.12;	author dlg;	state Exp;
branches;
next	1.88;
commitid	rfKmBzOnfXPGOKgo;

1.88
date	2015.11.25.03.09.59;	author dlg;	state Exp;
branches;
next	1.87;
commitid	B0kwmVGiD5DVx4kv;

1.87
date	2015.11.24.10.04.34;	author dlg;	state Exp;
branches;
next	1.86;
commitid	btyTOkIsa9bm2wls;

1.86
date	2015.11.19.12.46.08;	author dlg;	state Exp;
branches;
next	1.85;
commitid	kRuXF7sFGTW8o13K;

1.85
date	2015.10.25.13.04.28;	author mpi;	state Exp;
branches;
next	1.84;
commitid	hPF95ClMUQfeqQDX;

1.84
date	2015.09.29.10.52.22;	author dlg;	state Exp;
branches;
next	1.83;
commitid	Y4Uu9MKAjlOkvEiX;

1.83
date	2015.09.01.06.08.57;	author deraadt;	state Exp;
branches;
next	1.82;
commitid	Ue14giaMVrzcXUsX;

1.82
date	2015.08.15.01.17.01;	author dlg;	state Exp;
branches;
next	1.81;
commitid	yvMJnDkpgNnsVn9s;

1.81
date	2015.08.15.00.49.15;	author dlg;	state Exp;
branches;
next	1.80;
commitid	Q1eHxg9yeRYgCTK9;

1.80
date	2015.08.14.10.42.25;	author dlg;	state Exp;
branches;
next	1.79;
commitid	QwV1sBl8OYbtEuJY;

1.79
date	2015.08.14.07.24.18;	author dlg;	state Exp;
branches;
next	1.78;
commitid	TQZqivbOrXc08N6z;

1.78
date	2015.06.24.09.40.54;	author mpi;	state Exp;
branches;
next	1.77;
commitid	MVWrtktB46JRxFWT;

1.77
date	2015.05.17.02.33.09;	author chris;	state Exp;
branches;
next	1.76;
commitid	tubX4eDNF3WxSfYW;

1.76
date	2015.03.14.03.38.48;	author jsg;	state Exp;
branches;
next	1.75;
commitid	p4LJxGKbi0BU2cG6;

1.75
date	2015.02.20.23.24.30;	author chris;	state Exp;
branches;
next	1.74;
commitid	81alK0kSbDwwwMfG;

1.74
date	2015.02.18.23.58.34;	author dlg;	state Exp;
branches;
next	1.73;
commitid	jIeDMQvlCKI0NUcK;

1.73
date	2015.02.18.09.57.33;	author dlg;	state Exp;
branches;
next	1.72;
commitid	cUfgp9NpGggzgDzl;

1.72
date	2014.12.22.02.28.52;	author tedu;	state Exp;
branches;
next	1.71;
commitid	yM2VFFhpDTeFQlve;

1.71
date	2014.10.28.00.36.06;	author dlg;	state Exp;
branches;
next	1.70;
commitid	xIhjs05XPmbKhEau;

1.70
date	2014.10.04.11.42.27;	author dlg;	state Exp;
branches;
next	1.69;
commitid	i4YNnQjJ0TBr15MY;

1.69
date	2014.10.03.13.41.55;	author dlg;	state Exp;
branches;
next	1.68;
commitid	R3Mnz2tMAoyzVJX4;

1.68
date	2014.10.03.13.10.15;	author dlg;	state Exp;
branches;
next	1.67;
commitid	PiiiX9Nd0UJkmOk4;

1.67
date	2014.10.03.09.52.01;	author dlg;	state Exp;
branches;
next	1.66;
commitid	DIKQ4ANKmKTjLJro;

1.66
date	2014.10.03.09.25.21;	author dlg;	state Exp;
branches;
next	1.65;
commitid	FeTZNGLL7OzVuYFI;

1.65
date	2014.10.03.06.36.10;	author dlg;	state Exp;
branches;
next	1.64;
commitid	aAeA9mSFnJ1l78G5;

1.64
date	2014.09.14.14.17.25;	author jsg;	state Exp;
branches;
next	1.63;
commitid	uzzBR7hz9ncd4O6G;

1.63
date	2014.08.19.11.13.16;	author dlg;	state Exp;
branches;
next	1.62;
commitid	R9tLXJLqpjh2HcEE;

1.62
date	2014.08.18.05.11.03;	author dlg;	state Exp;
branches;
next	1.61;
commitid	hjFdrSJM3VTXJUZV;

1.61
date	2014.07.12.18.48.51;	author tedu;	state Exp;
branches;
next	1.60;
commitid	OBNa5kfxQ2UXoiIw;

1.60
date	2014.07.10.07.02.50;	author dlg;	state Exp;
branches;
next	1.59;
commitid	PnEEAIgQEyIHziq7;

1.59
date	2014.07.08.05.35.18;	author dlg;	state Exp;
branches;
next	1.58;
commitid	0QJleeeWqZmC5anF;

1.58
date	2014.06.17.04.58.45;	author dlg;	state Exp;
branches;
next	1.57;
commitid	CBMr43PTER5xrnx3;

1.57
date	2014.03.24.01.00.58;	author dlg;	state Exp;
branches;
next	1.56;

1.56
date	2014.02.10.05.21.41;	author dlg;	state Exp;
branches;
next	1.55;

1.55
date	2014.02.05.08.17.30;	author dlg;	state Exp;
branches;
next	1.54;

1.54
date	2014.01.31.00.52.20;	author dlg;	state Exp;
branches;
next	1.53;

1.53
date	2014.01.31.00.50.45;	author dlg;	state Exp;
branches;
next	1.52;

1.52
date	2014.01.23.01.54.02;	author dlg;	state Exp;
branches;
next	1.51;

1.51
date	2014.01.23.01.51.53;	author dlg;	state Exp;
branches;
next	1.50;

1.50
date	2014.01.21.23.26.50;	author dlg;	state Exp;
branches;
next	1.49;

1.49
date	2014.01.19.21.43.36;	author dlg;	state Exp;
branches;
next	1.48;

1.48
date	2014.01.19.09.04.37;	author dlg;	state Exp;
branches;
next	1.47;

1.47
date	2014.01.19.03.53.46;	author dlg;	state Exp;
branches;
next	1.46;

1.46
date	2014.01.19.03.08.56;	author dlg;	state Exp;
branches;
next	1.45;

1.45
date	2014.01.19.03.05.46;	author dlg;	state Exp;
branches;
next	1.44;

1.44
date	2014.01.19.03.03.50;	author dlg;	state Exp;
branches;
next	1.43;

1.43
date	2014.01.19.02.55.43;	author dlg;	state Exp;
branches;
next	1.42;

1.42
date	2013.01.29.07.17.45;	author brad;	state Exp;
branches;
next	1.41;

1.41
date	2013.01.25.02.56.41;	author dlg;	state Exp;
branches;
next	1.40;

1.40
date	2013.01.25.02.13.01;	author dlg;	state Exp;
branches;
next	1.39;

1.39
date	2013.01.21.00.41.42;	author dlg;	state Exp;
branches;
next	1.38;

1.38
date	2013.01.15.03.48.20;	author dlg;	state Exp;
branches;
next	1.37;

1.37
date	2013.01.15.00.22.32;	author dlg;	state Exp;
branches;
next	1.36;

1.36
date	2013.01.14.23.58.34;	author dlg;	state Exp;
branches;
next	1.35;

1.35
date	2013.01.14.23.46.01;	author dlg;	state Exp;
branches;
next	1.34;

1.34
date	2013.01.14.06.00.48;	author dlg;	state Exp;
branches;
next	1.33;

1.33
date	2013.01.14.04.02.02;	author dlg;	state Exp;
branches;
next	1.32;

1.32
date	2013.01.14.00.47.53;	author dlg;	state Exp;
branches;
next	1.31;

1.31
date	2012.11.29.21.10.32;	author brad;	state Exp;
branches;
next	1.30;

1.30
date	2011.11.28.10.25.22;	author blambert;	state Exp;
branches;
next	1.29;

1.29
date	2011.08.08.01.30.25;	author dlg;	state Exp;
branches;
next	1.28;

1.28
date	2011.06.23.04.09.08;	author dlg;	state Exp;
branches;
next	1.27;

1.27
date	2011.06.23.03.36.06;	author dlg;	state Exp;
branches;
next	1.26;

1.26
date	2011.06.22.21.04.31;	author deraadt;	state Exp;
branches;
next	1.25;

1.25
date	2011.06.22.10.34.15;	author dlg;	state Exp;
branches;
next	1.24;

1.24
date	2011.06.22.08.38.45;	author jsg;	state Exp;
branches;
next	1.23;

1.23
date	2011.06.22.04.09.54;	author dlg;	state Exp;
branches;
next	1.22;

1.22
date	2011.06.22.04.03.01;	author deraadt;	state Exp;
branches;
next	1.21;

1.21
date	2011.06.22.03.54.31;	author dlg;	state Exp;
branches;
next	1.20;

1.20
date	2011.06.21.21.56.28;	author dlg;	state Exp;
branches;
next	1.19;

1.19
date	2011.06.21.11.57.20;	author dlg;	state Exp;
branches;
next	1.18;

1.18
date	2011.06.21.10.31.28;	author dlg;	state Exp;
branches;
next	1.17;

1.17
date	2011.06.21.06.55.44;	author deraadt;	state Exp;
branches;
next	1.16;

1.16
date	2011.06.20.13.02.49;	author dlg;	state Exp;
branches;
next	1.15;

1.15
date	2011.06.20.06.56.06;	author dlg;	state Exp;
branches;
next	1.14;

1.14
date	2011.06.20.05.19.20;	author dlg;	state Exp;
branches;
next	1.13;

1.13
date	2011.05.02.22.13.27;	author chl;	state Exp;
branches;
next	1.12;

1.12
date	2010.05.19.15.27.35;	author oga;	state Exp;
branches;
next	1.11;

1.11
date	2009.08.13.14.24.47;	author jasper;	state Exp;
branches;
next	1.10;

1.10
date	2008.11.28.02.44.18;	author brad;	state Exp;
branches;
next	1.9;

1.9
date	2008.10.02.20.21.14;	author brad;	state Exp;
branches;
next	1.8;

1.8
date	2008.09.10.14.01.22;	author blambert;	state Exp;
branches;
next	1.7;

1.7
date	2008.05.23.08.49.27;	author brad;	state Exp;
branches;
next	1.6;

1.6
date	2008.01.16.19.30.19;	author thib;	state Exp;
branches;
next	1.5;

1.5
date	2007.06.01.18.07.08;	author reyk;	state Exp;
branches;
next	1.4;

1.4
date	2007.05.31.22.09.09;	author reyk;	state Exp;
branches;
next	1.3;

1.3
date	2007.05.31.19.14.05;	author reyk;	state Exp;
branches;
next	1.2;

1.2
date	2007.05.31.19.12.56;	author reyk;	state Exp;
branches;
next	1.1;

1.1
date	2007.05.31.18.23.42;	author reyk;	state Exp;
branches;
next	;


desc
@@


1.102
log
@move the mbuf pools to m_pool_init and a single global memory limit

this replaces individual calls to pool_init, pool_set_constraints, and
pool_sethardlimit with calls to m_pool_init. m_pool_init inits the
mbuf pools with the mbuf pool allocator, and because of that doesnt
set per pool limits.

ok bluhm@@ as part of a larger diff
@
text
@/*	$OpenBSD: if_myx.c,v 1.101 2017/01/24 03:57:35 dlg Exp $	*/

/*
 * Copyright (c) 2007 Reyk Floeter <reyk@@openbsd.org>
 *
 * Permission to use, copy, modify, and distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 */

/*
 * Driver for the Myricom Myri-10G Lanai-Z8E Ethernet chipsets.
 */

#include "bpfilter.h"

#include <sys/param.h>
#include <sys/systm.h>
#include <sys/sockio.h>
#include <sys/mbuf.h>
#include <sys/kernel.h>
#include <sys/socket.h>
#include <sys/malloc.h>
#include <sys/pool.h>
#include <sys/timeout.h>
#include <sys/device.h>
#include <sys/proc.h>
#include <sys/queue.h>

#include <machine/bus.h>
#include <machine/intr.h>

#include <net/if.h>
#include <net/if_dl.h>
#include <net/if_media.h>

#if NBPFILTER > 0
#include <net/bpf.h>
#endif

#include <netinet/in.h>
#include <netinet/if_ether.h>

#include <dev/pci/pcireg.h>
#include <dev/pci/pcivar.h>
#include <dev/pci/pcidevs.h>

#include <dev/pci/if_myxreg.h>

#ifdef MYX_DEBUG
#define MYXDBG_INIT	(1<<0)	/* chipset initialization */
#define MYXDBG_CMD	(2<<0)	/* commands */
#define MYXDBG_INTR	(3<<0)	/* interrupts */
#define MYXDBG_ALL	0xffff	/* enable all debugging messages */
int myx_debug = MYXDBG_ALL;
#define DPRINTF(_lvl, _arg...)	do {					\
	if (myx_debug & (_lvl))						\
		printf(_arg);						\
} while (0)
#else
#define DPRINTF(_lvl, arg...)
#endif

#define DEVNAME(_s)	((_s)->sc_dev.dv_xname)

struct myx_dmamem {
	bus_dmamap_t		 mxm_map;
	bus_dma_segment_t	 mxm_seg;
	int			 mxm_nsegs;
	size_t			 mxm_size;
	caddr_t			 mxm_kva;
};

struct pool *myx_mcl_pool;

struct myx_slot {
	bus_dmamap_t		 ms_map;
	struct mbuf		*ms_m;
};

struct myx_rx_ring {
	struct myx_softc	*mrr_softc;
	struct timeout		 mrr_refill;
	struct if_rxring	 mrr_rxr;
	struct myx_slot		*mrr_slots;
	u_int32_t		 mrr_offset;
	u_int			 mrr_running;
	u_int			 mrr_prod;
	u_int			 mrr_cons;
	struct mbuf		*(*mrr_mclget)(void);
};

enum myx_state {
	MYX_S_OFF = 0,
	MYX_S_RUNNING,
	MYX_S_DOWN
};

struct myx_softc {
	struct device		 sc_dev;
	struct arpcom		 sc_ac;

	pci_chipset_tag_t	 sc_pc;
	pci_intr_handle_t	 sc_ih;
	pcitag_t		 sc_tag;

	bus_dma_tag_t		 sc_dmat;
	bus_space_tag_t		 sc_memt;
	bus_space_handle_t	 sc_memh;
	bus_size_t		 sc_mems;

	struct myx_dmamem	 sc_zerodma;
	struct myx_dmamem	 sc_cmddma;
	struct myx_dmamem	 sc_paddma;

	struct myx_dmamem	 sc_sts_dma;
	volatile struct myx_status	*sc_sts;

	int			 sc_intx;
	void			*sc_irqh;
	u_int32_t		 sc_irqcoaloff;
	u_int32_t		 sc_irqclaimoff;
	u_int32_t		 sc_irqdeassertoff;

	struct myx_dmamem	 sc_intrq_dma;
	struct myx_intrq_desc	*sc_intrq;
	u_int			 sc_intrq_count;
	u_int			 sc_intrq_idx;

	u_int			 sc_rx_ring_count;
#define  MYX_RXSMALL		 0
#define  MYX_RXBIG		 1
	struct myx_rx_ring	 sc_rx_ring[2];

	bus_size_t		 sc_tx_boundary;
	u_int			 sc_tx_ring_count;
	u_int32_t		 sc_tx_ring_offset;
	u_int			 sc_tx_nsegs;
	u_int32_t		 sc_tx_count; /* shadows ms_txdonecnt */
	u_int			 sc_tx_ring_prod;
	u_int			 sc_tx_ring_cons;

	u_int			 sc_tx_prod;
	u_int			 sc_tx_cons;
	struct myx_slot		*sc_tx_slots;

	struct ifmedia		 sc_media;

	volatile enum myx_state	 sc_state;
	volatile u_int8_t	 sc_linkdown;
};

#define MYX_RXSMALL_SIZE	MCLBYTES
#define MYX_RXBIG_SIZE		(MYX_MTU - \
    (ETHER_ALIGN + ETHER_HDR_LEN + ETHER_VLAN_ENCAP_LEN))

int	 myx_match(struct device *, void *, void *);
void	 myx_attach(struct device *, struct device *, void *);
int	 myx_pcie_dc(struct myx_softc *, struct pci_attach_args *);
int	 myx_query(struct myx_softc *sc, char *, size_t);
u_int	 myx_ether_aton(char *, u_int8_t *, u_int);
void	 myx_attachhook(struct device *);
int	 myx_loadfirmware(struct myx_softc *, const char *);
int	 myx_probe_firmware(struct myx_softc *);

void	 myx_read(struct myx_softc *, bus_size_t, void *, bus_size_t);
void	 myx_write(struct myx_softc *, bus_size_t, void *, bus_size_t);

#if defined(__LP64__)
#define _myx_bus_space_write bus_space_write_raw_region_8
typedef u_int64_t myx_bus_t;
#else
#define _myx_bus_space_write bus_space_write_raw_region_4
typedef u_int32_t myx_bus_t;
#endif
#define myx_bus_space_write(_sc, _o, _a, _l) \
    _myx_bus_space_write((_sc)->sc_memt, (_sc)->sc_memh, (_o), (_a), (_l))

int	 myx_cmd(struct myx_softc *, u_int32_t, struct myx_cmd *, u_int32_t *);
int	 myx_boot(struct myx_softc *, u_int32_t);

int	 myx_rdma(struct myx_softc *, u_int);
int	 myx_dmamem_alloc(struct myx_softc *, struct myx_dmamem *,
	    bus_size_t, u_int align);
void	 myx_dmamem_free(struct myx_softc *, struct myx_dmamem *);
int	 myx_media_change(struct ifnet *);
void	 myx_media_status(struct ifnet *, struct ifmediareq *);
void	 myx_link_state(struct myx_softc *, u_int32_t);
void	 myx_watchdog(struct ifnet *);
int	 myx_ioctl(struct ifnet *, u_long, caddr_t);
int	 myx_rxrinfo(struct myx_softc *, struct if_rxrinfo *);
void	 myx_up(struct myx_softc *);
void	 myx_iff(struct myx_softc *);
void	 myx_down(struct myx_softc *);

void	 myx_start(struct ifqueue *);
void	 myx_write_txd_tail(struct myx_softc *, struct myx_slot *, u_int8_t,
	    u_int32_t, u_int);
int	 myx_load_mbuf(struct myx_softc *, struct myx_slot *, struct mbuf *);
int	 myx_setlladdr(struct myx_softc *, u_int32_t, u_int8_t *);
int	 myx_intr(void *);
void	 myx_rxeof(struct myx_softc *);
void	 myx_txeof(struct myx_softc *, u_int32_t);

int			myx_buf_fill(struct myx_softc *, struct myx_slot *,
			    struct mbuf *(*)(void));
struct mbuf *		myx_mcl_small(void);
struct mbuf *		myx_mcl_big(void);

int			myx_rx_init(struct myx_softc *, int, bus_size_t);
int			myx_rx_fill(struct myx_softc *, struct myx_rx_ring *);
void			myx_rx_empty(struct myx_softc *, struct myx_rx_ring *);
void			myx_rx_free(struct myx_softc *, struct myx_rx_ring *);

int			myx_tx_init(struct myx_softc *, bus_size_t);
void			myx_tx_empty(struct myx_softc *);
void			myx_tx_free(struct myx_softc *);

void			myx_refill(void *);

struct cfdriver myx_cd = {
	NULL, "myx", DV_IFNET
};
struct cfattach myx_ca = {
	sizeof(struct myx_softc), myx_match, myx_attach
};

const struct pci_matchid myx_devices[] = {
	{ PCI_VENDOR_MYRICOM, PCI_PRODUCT_MYRICOM_Z8E },
	{ PCI_VENDOR_MYRICOM, PCI_PRODUCT_MYRICOM_Z8E_9 }
};

int
myx_match(struct device *parent, void *match, void *aux)
{
	return (pci_matchbyid(aux, myx_devices, nitems(myx_devices)));
}

void
myx_attach(struct device *parent, struct device *self, void *aux)
{
	struct myx_softc	*sc = (struct myx_softc *)self;
	struct pci_attach_args	*pa = aux;
	char			 part[32];
	pcireg_t		 memtype;

	sc->sc_pc = pa->pa_pc;
	sc->sc_tag = pa->pa_tag;
	sc->sc_dmat = pa->pa_dmat;

	sc->sc_rx_ring[MYX_RXSMALL].mrr_softc = sc;
	sc->sc_rx_ring[MYX_RXSMALL].mrr_mclget = myx_mcl_small;
	timeout_set(&sc->sc_rx_ring[MYX_RXSMALL].mrr_refill, myx_refill,
	    &sc->sc_rx_ring[MYX_RXSMALL]);
	sc->sc_rx_ring[MYX_RXBIG].mrr_softc = sc;
	sc->sc_rx_ring[MYX_RXBIG].mrr_mclget = myx_mcl_big;
	timeout_set(&sc->sc_rx_ring[MYX_RXBIG].mrr_refill, myx_refill,
	    &sc->sc_rx_ring[MYX_RXBIG]);

	/* Map the PCI memory space */
	memtype = pci_mapreg_type(sc->sc_pc, sc->sc_tag, MYXBAR0);
	if (pci_mapreg_map(pa, MYXBAR0, memtype, BUS_SPACE_MAP_PREFETCHABLE,
	    &sc->sc_memt, &sc->sc_memh, NULL, &sc->sc_mems, 0)) {
		printf(": unable to map register memory\n");
		return;
	}

	/* Get board details (mac/part) */
	memset(part, 0, sizeof(part));
	if (myx_query(sc, part, sizeof(part)) != 0)
		goto unmap;

	/* Map the interrupt */
	if (pci_intr_map_msi(pa, &sc->sc_ih) != 0) {
		if (pci_intr_map(pa, &sc->sc_ih) != 0) {
			printf(": unable to map interrupt\n");
			goto unmap;
		}
		sc->sc_intx = 1;
	}

	printf(": %s, model %s, address %s\n",
	    pci_intr_string(pa->pa_pc, sc->sc_ih),
	    part[0] == '\0' ? "(unknown)" : part,
	    ether_sprintf(sc->sc_ac.ac_enaddr));

	/* this is sort of racy */
	if (myx_mcl_pool == NULL) {
		myx_mcl_pool = malloc(sizeof(*myx_mcl_pool), M_DEVBUF,
		    M_WAITOK);
		if (myx_mcl_pool == NULL) {
			printf("%s: unable to allocate mcl pool\n",
			    DEVNAME(sc));
			goto unmap;
		}

		m_pool_init(myx_mcl_pool, MYX_RXBIG_SIZE, MYX_BOUNDARY,
		    "myxmcl");
	}

	if (myx_pcie_dc(sc, pa) != 0)
		printf("%s: unable to configure PCI Express\n", DEVNAME(sc));

	config_mountroot(self, myx_attachhook);

	return;

 unmap:
	bus_space_unmap(sc->sc_memt, sc->sc_memh, sc->sc_mems);
	sc->sc_mems = 0;
}

int
myx_pcie_dc(struct myx_softc *sc, struct pci_attach_args *pa)
{
	pcireg_t dcsr;
	pcireg_t mask = PCI_PCIE_DCSR_MPS | PCI_PCIE_DCSR_ERO;
	pcireg_t dc = ((fls(4096) - 8) << 12) | PCI_PCIE_DCSR_ERO;
	int reg;

	if (pci_get_capability(sc->sc_pc, pa->pa_tag, PCI_CAP_PCIEXPRESS,
	    &reg, NULL) == 0)
		return (-1);

	reg += PCI_PCIE_DCSR;
	dcsr = pci_conf_read(sc->sc_pc, pa->pa_tag, reg);
	if ((dcsr & mask) != dc) {
		CLR(dcsr, mask);
		SET(dcsr, dc);
		pci_conf_write(sc->sc_pc, pa->pa_tag, reg, dcsr);
	}

	return (0);
}

u_int
myx_ether_aton(char *mac, u_int8_t *lladdr, u_int maxlen)
{
	u_int		i, j;
	u_int8_t	digit;

	memset(lladdr, 0, ETHER_ADDR_LEN);
	for (i = j = 0; mac[i] != '\0' && i < maxlen; i++) {
		if (mac[i] >= '0' && mac[i] <= '9')
			digit = mac[i] - '0';
		else if (mac[i] >= 'A' && mac[i] <= 'F')
			digit = mac[i] - 'A' + 10;
		else if (mac[i] >= 'a' && mac[i] <= 'f')
			digit = mac[i] - 'a' + 10;
		else
			continue;
		if ((j & 1) == 0)
			digit <<= 4;
		lladdr[j++/2] |= digit;
	}

	return (i);
}

int
myx_query(struct myx_softc *sc, char *part, size_t partlen)
{
	struct myx_gen_hdr hdr;
	u_int32_t	offset;
	u_int8_t	strings[MYX_STRING_SPECS_SIZE];
	u_int		i, len, maxlen;

	myx_read(sc, MYX_HEADER_POS, &offset, sizeof(offset));
	offset = betoh32(offset);
	if (offset + sizeof(hdr) > sc->sc_mems) {
		printf(": header is outside register window\n");
		return (1);
	}

	myx_read(sc, offset, &hdr, sizeof(hdr));
	offset = betoh32(hdr.fw_specs);
	len = min(betoh32(hdr.fw_specs_len), sizeof(strings));

	bus_space_read_region_1(sc->sc_memt, sc->sc_memh, offset, strings, len);

	for (i = 0; i < len; i++) {
		maxlen = len - i;
		if (strings[i] == '\0')
			break;
		if (maxlen > 4 && memcmp("MAC=", &strings[i], 4) == 0) {
			i += 4;
			i += myx_ether_aton(&strings[i],
			    sc->sc_ac.ac_enaddr, maxlen);
		} else if (maxlen > 3 && memcmp("PC=", &strings[i], 3) == 0) {
			i += 3;
			i += strlcpy(part, &strings[i], min(maxlen, partlen));
		}
		for (; i < len; i++) {
			if (strings[i] == '\0')
				break;
		}
	}

	return (0);
}

int
myx_loadfirmware(struct myx_softc *sc, const char *filename)
{
	struct myx_gen_hdr	hdr;
	u_int8_t		*fw;
	size_t			fwlen;
	u_int32_t		offset;
	u_int			i, ret = 1;

	if (loadfirmware(filename, &fw, &fwlen) != 0) {
		printf("%s: could not load firmware %s\n", DEVNAME(sc),
		    filename);
		return (1);
	}
	if (fwlen > MYX_SRAM_SIZE || fwlen < MYXFW_MIN_LEN) {
		printf("%s: invalid firmware %s size\n", DEVNAME(sc), filename);
		goto err;
	}

	memcpy(&offset, fw + MYX_HEADER_POS, sizeof(offset));
	offset = betoh32(offset);
	if ((offset + sizeof(hdr)) > fwlen) {
		printf("%s: invalid firmware %s\n", DEVNAME(sc), filename);
		goto err;
	}

	memcpy(&hdr, fw + offset, sizeof(hdr));
	DPRINTF(MYXDBG_INIT, "%s: "
	    "fw hdr off %u, length %u, type 0x%x, version %s\n",
	    DEVNAME(sc), offset, betoh32(hdr.fw_hdrlength),
	    betoh32(hdr.fw_type), hdr.fw_version);

	if (betoh32(hdr.fw_type) != MYXFW_TYPE_ETH ||
	    memcmp(MYXFW_VER, hdr.fw_version, strlen(MYXFW_VER)) != 0) {
		printf("%s: invalid firmware type 0x%x version %s\n",
		    DEVNAME(sc), betoh32(hdr.fw_type), hdr.fw_version);
		goto err;
	}

	/* Write the firmware to the card's SRAM */
	for (i = 0; i < fwlen; i += 256)
		myx_write(sc, i + MYX_FW, fw + i, min(256, fwlen - i));

	if (myx_boot(sc, fwlen) != 0) {
		printf("%s: failed to boot %s\n", DEVNAME(sc), filename);
		goto err;
	}

	ret = 0;

err:
	free(fw, M_DEVBUF, fwlen);
	return (ret);
}

void
myx_attachhook(struct device *self)
{
	struct myx_softc	*sc = (struct myx_softc *)self;
	struct ifnet		*ifp = &sc->sc_ac.ac_if;
	struct myx_cmd		 mc;

	/* Allocate command DMA memory */
	if (myx_dmamem_alloc(sc, &sc->sc_cmddma, MYXALIGN_CMD,
	    MYXALIGN_CMD) != 0) {
		printf("%s: failed to allocate command DMA memory\n",
		    DEVNAME(sc));
		return;
	}

	/* Try the firmware stored on disk */
	if (myx_loadfirmware(sc, MYXFW_ALIGNED) != 0) {
		/* error printed by myx_loadfirmware */
		goto freecmd;
	}

	memset(&mc, 0, sizeof(mc));

	if (myx_cmd(sc, MYXCMD_RESET, &mc, NULL) != 0) {
		printf("%s: failed to reset the device\n", DEVNAME(sc));
		goto freecmd;
	}

	sc->sc_tx_boundary = 4096;

	if (myx_probe_firmware(sc) != 0) {
		printf("%s: error while selecting firmware\n", DEVNAME(sc));
		goto freecmd;
	}

	sc->sc_irqh = pci_intr_establish(sc->sc_pc, sc->sc_ih,
	    IPL_NET | IPL_MPSAFE, myx_intr, sc, DEVNAME(sc));
	if (sc->sc_irqh == NULL) {
		printf("%s: unable to establish interrupt\n", DEVNAME(sc));
		goto freecmd;
	}

	ifp->if_softc = sc;
	ifp->if_flags = IFF_BROADCAST | IFF_SIMPLEX | IFF_MULTICAST;
	ifp->if_xflags = IFXF_MPSAFE;
	ifp->if_ioctl = myx_ioctl;
	ifp->if_qstart = myx_start;
	ifp->if_watchdog = myx_watchdog;
	ifp->if_hardmtu = MYX_RXBIG_SIZE;
	strlcpy(ifp->if_xname, DEVNAME(sc), IFNAMSIZ);
	IFQ_SET_MAXLEN(&ifp->if_snd, 1);

	ifp->if_capabilities = IFCAP_VLAN_MTU;
#if 0
	ifp->if_capabilities |= IFCAP_VLAN_HWTAGGING;
	ifp->if_capabilities |= IFCAP_CSUM_IPv4 | IFCAP_CSUM_TCPv4 |
	    IFCAP_CSUM_UDPv4;
#endif

	ifmedia_init(&sc->sc_media, 0, myx_media_change, myx_media_status);
	ifmedia_add(&sc->sc_media, IFM_ETHER | IFM_AUTO, 0, NULL);
	ifmedia_set(&sc->sc_media, IFM_ETHER | IFM_AUTO);

	if_attach(ifp);
	ether_ifattach(ifp);

	return;

freecmd:
	myx_dmamem_free(sc, &sc->sc_cmddma);
}

int
myx_probe_firmware(struct myx_softc *sc)
{
	struct myx_dmamem test;
	bus_dmamap_t map;
	struct myx_cmd mc;
	pcireg_t csr;
	int offset;
	int width = 0;

	if (pci_get_capability(sc->sc_pc, sc->sc_tag, PCI_CAP_PCIEXPRESS,
	    &offset, NULL)) {
		csr = pci_conf_read(sc->sc_pc, sc->sc_tag,
		    offset + PCI_PCIE_LCSR);
		width = (csr >> 20) & 0x3f;

		if (width <= 4) {
			/*
			 * if the link width is 4 or less we can use the
			 * aligned firmware.
			 */
			return (0);
		}
	}

	if (myx_dmamem_alloc(sc, &test, 4096, 4096) != 0)
		return (1);
	map = test.mxm_map;

	bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
	    BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);

	memset(&mc, 0, sizeof(mc));
	mc.mc_data0 = htobe32(MYX_ADDRLOW(map->dm_segs[0].ds_addr));
	mc.mc_data1 = htobe32(MYX_ADDRHIGH(map->dm_segs[0].ds_addr));
	mc.mc_data2 = htobe32(4096 * 0x10000);
	if (myx_cmd(sc, MYXCMD_UNALIGNED_DMA_TEST, &mc, NULL) != 0) {
		printf("%s: DMA read test failed\n", DEVNAME(sc));
		goto fail;
	}

	memset(&mc, 0, sizeof(mc));
	mc.mc_data0 = htobe32(MYX_ADDRLOW(map->dm_segs[0].ds_addr));
	mc.mc_data1 = htobe32(MYX_ADDRHIGH(map->dm_segs[0].ds_addr));
	mc.mc_data2 = htobe32(4096 * 0x1);
	if (myx_cmd(sc, MYXCMD_UNALIGNED_DMA_TEST, &mc, NULL) != 0) {
		printf("%s: DMA write test failed\n", DEVNAME(sc));
		goto fail;
	}

	memset(&mc, 0, sizeof(mc));
	mc.mc_data0 = htobe32(MYX_ADDRLOW(map->dm_segs[0].ds_addr));
	mc.mc_data1 = htobe32(MYX_ADDRHIGH(map->dm_segs[0].ds_addr));
	mc.mc_data2 = htobe32(4096 * 0x10001);
	if (myx_cmd(sc, MYXCMD_UNALIGNED_DMA_TEST, &mc, NULL) != 0) {
		printf("%s: DMA read/write test failed\n", DEVNAME(sc));
		goto fail;
	}

	bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
	    BUS_DMASYNC_POSTREAD | BUS_DMASYNC_POSTWRITE);
	myx_dmamem_free(sc, &test);
	return (0);

fail:
	bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
	    BUS_DMASYNC_POSTREAD | BUS_DMASYNC_POSTWRITE);
	myx_dmamem_free(sc, &test);

	if (myx_loadfirmware(sc, MYXFW_UNALIGNED) != 0) {
		printf("%s: unable to load %s\n", DEVNAME(sc),
		    MYXFW_UNALIGNED);
		return (1);
	}

	sc->sc_tx_boundary = 2048;

	printf("%s: using unaligned firmware\n", DEVNAME(sc));
	return (0);
}

void
myx_read(struct myx_softc *sc, bus_size_t off, void *ptr, bus_size_t len)
{
	bus_space_barrier(sc->sc_memt, sc->sc_memh, off, len,
	    BUS_SPACE_BARRIER_READ);
	bus_space_read_raw_region_4(sc->sc_memt, sc->sc_memh, off, ptr, len);
}

void
myx_write(struct myx_softc *sc, bus_size_t off, void *ptr, bus_size_t len)
{
	bus_space_write_raw_region_4(sc->sc_memt, sc->sc_memh, off, ptr, len);
	bus_space_barrier(sc->sc_memt, sc->sc_memh, off, len,
	    BUS_SPACE_BARRIER_WRITE);
}

int
myx_dmamem_alloc(struct myx_softc *sc, struct myx_dmamem *mxm,
    bus_size_t size, u_int align)
{
	mxm->mxm_size = size;

	if (bus_dmamap_create(sc->sc_dmat, mxm->mxm_size, 1,
	    mxm->mxm_size, 0, BUS_DMA_WAITOK | BUS_DMA_ALLOCNOW,
	    &mxm->mxm_map) != 0)
		return (1);
	if (bus_dmamem_alloc(sc->sc_dmat, mxm->mxm_size,
	    align, 0, &mxm->mxm_seg, 1, &mxm->mxm_nsegs,
	    BUS_DMA_WAITOK | BUS_DMA_ZERO) != 0)
		goto destroy;
	if (bus_dmamem_map(sc->sc_dmat, &mxm->mxm_seg, mxm->mxm_nsegs,
	    mxm->mxm_size, &mxm->mxm_kva, BUS_DMA_WAITOK) != 0)
		goto free;
	if (bus_dmamap_load(sc->sc_dmat, mxm->mxm_map, mxm->mxm_kva,
	    mxm->mxm_size, NULL, BUS_DMA_WAITOK) != 0)
		goto unmap;

	return (0);
 unmap:
	bus_dmamem_unmap(sc->sc_dmat, mxm->mxm_kva, mxm->mxm_size);
 free:
	bus_dmamem_free(sc->sc_dmat, &mxm->mxm_seg, 1);
 destroy:
	bus_dmamap_destroy(sc->sc_dmat, mxm->mxm_map);
	return (1);
}

void
myx_dmamem_free(struct myx_softc *sc, struct myx_dmamem *mxm)
{
	bus_dmamap_unload(sc->sc_dmat, mxm->mxm_map);
	bus_dmamem_unmap(sc->sc_dmat, mxm->mxm_kva, mxm->mxm_size);
	bus_dmamem_free(sc->sc_dmat, &mxm->mxm_seg, 1);
	bus_dmamap_destroy(sc->sc_dmat, mxm->mxm_map);
}

int
myx_cmd(struct myx_softc *sc, u_int32_t cmd, struct myx_cmd *mc, u_int32_t *r)
{
	bus_dmamap_t		 map = sc->sc_cmddma.mxm_map;
	struct myx_response	*mr;
	u_int			 i;
	u_int32_t		 result, data;
#ifdef MYX_DEBUG
	static const char *cmds[MYXCMD_MAX] = {
		"CMD_NONE",
		"CMD_RESET",
		"CMD_GET_VERSION",
		"CMD_SET_INTRQDMA",
		"CMD_SET_BIGBUFSZ",
		"CMD_SET_SMALLBUFSZ",
		"CMD_GET_TXRINGOFF",
		"CMD_GET_RXSMALLRINGOFF",
		"CMD_GET_RXBIGRINGOFF",
		"CMD_GET_INTRACKOFF",
		"CMD_GET_INTRDEASSERTOFF",
		"CMD_GET_TXRINGSZ",
		"CMD_GET_RXRINGSZ",
		"CMD_SET_INTRQSZ",
		"CMD_SET_IFUP",
		"CMD_SET_IFDOWN",
		"CMD_SET_MTU",
		"CMD_GET_INTRCOALDELAYOFF",
		"CMD_SET_STATSINTVL",
		"CMD_SET_STATSDMA_OLD",
		"CMD_SET_PROMISC",
		"CMD_UNSET_PROMISC",
		"CMD_SET_LLADDR",
		"CMD_SET_FC",
		"CMD_UNSET_FC",
		"CMD_DMA_TEST",
		"CMD_SET_ALLMULTI",
		"CMD_UNSET_ALLMULTI",
		"CMD_SET_MCASTGROUP",
		"CMD_UNSET_MCASTGROUP",
		"CMD_UNSET_MCAST",
		"CMD_SET_STATSDMA",
		"CMD_UNALIGNED_DMA_TEST",
		"CMD_GET_UNALIGNED_STATUS"
	};
#endif

	mc->mc_cmd = htobe32(cmd);
	mc->mc_addr_high = htobe32(MYX_ADDRHIGH(map->dm_segs[0].ds_addr));
	mc->mc_addr_low = htobe32(MYX_ADDRLOW(map->dm_segs[0].ds_addr));

	mr = (struct myx_response *)sc->sc_cmddma.mxm_kva;
	mr->mr_result = 0xffffffff;

	/* Send command */
	myx_write(sc, MYX_CMD, (u_int8_t *)mc, sizeof(struct myx_cmd));
	bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
	    BUS_DMASYNC_PREREAD);

	for (i = 0; i < 20; i++) {
		bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
		    BUS_DMASYNC_POSTREAD);
		result = betoh32(mr->mr_result);
		data = betoh32(mr->mr_data);

		if (result != 0xffffffff)
			break;

		bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
		    BUS_DMASYNC_PREREAD);
		delay(1000);
	}

	DPRINTF(MYXDBG_CMD, "%s(%s): %s completed, i %d, "
	    "result 0x%x, data 0x%x (%u)\n", DEVNAME(sc), __func__,
	    cmds[cmd], i, result, data, data);

	if (result != 0)
		return (-1);

	if (r != NULL)
		*r = data;
	return (0);
}

int
myx_boot(struct myx_softc *sc, u_int32_t length)
{
	struct myx_bootcmd	 bc;
	bus_dmamap_t		 map = sc->sc_cmddma.mxm_map;
	u_int32_t		*status;
	u_int			 i, ret = 1;

	memset(&bc, 0, sizeof(bc));
	bc.bc_addr_high = htobe32(MYX_ADDRHIGH(map->dm_segs[0].ds_addr));
	bc.bc_addr_low = htobe32(MYX_ADDRLOW(map->dm_segs[0].ds_addr));
	bc.bc_result = 0xffffffff;
	bc.bc_offset = htobe32(MYX_FW_BOOT);
	bc.bc_length = htobe32(length - 8);
	bc.bc_copyto = htobe32(8);
	bc.bc_jumpto = htobe32(0);

	status = (u_int32_t *)sc->sc_cmddma.mxm_kva;
	*status = 0;

	/* Send command */
	myx_write(sc, MYX_BOOT, &bc, sizeof(bc));
	bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
	    BUS_DMASYNC_PREREAD);

	for (i = 0; i < 200; i++) {
		bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
		    BUS_DMASYNC_POSTREAD);
		if (*status == 0xffffffff) {
			ret = 0;
			break;
		}

		bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
		    BUS_DMASYNC_PREREAD);
		delay(1000);
	}

	DPRINTF(MYXDBG_CMD, "%s: boot completed, i %d, result %d\n",
	    DEVNAME(sc), i, ret);

	return (ret);
}

int
myx_rdma(struct myx_softc *sc, u_int do_enable)
{
	struct myx_rdmacmd	 rc;
	bus_dmamap_t		 map = sc->sc_cmddma.mxm_map;
	bus_dmamap_t		 pad = sc->sc_paddma.mxm_map;
	u_int32_t		*status;
	int			 ret = 1;
	u_int			 i;

	/*
	 * It is required to setup a _dummy_ RDMA address. It also makes
	 * some PCI-E chipsets resend dropped messages.
	 */
	rc.rc_addr_high = htobe32(MYX_ADDRHIGH(map->dm_segs[0].ds_addr));
	rc.rc_addr_low = htobe32(MYX_ADDRLOW(map->dm_segs[0].ds_addr));
	rc.rc_result = 0xffffffff;
	rc.rc_rdma_high = htobe32(MYX_ADDRHIGH(pad->dm_segs[0].ds_addr));
	rc.rc_rdma_low = htobe32(MYX_ADDRLOW(pad->dm_segs[0].ds_addr));
	rc.rc_enable = htobe32(do_enable);

	status = (u_int32_t *)sc->sc_cmddma.mxm_kva;
	*status = 0;

	bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
	    BUS_DMASYNC_PREREAD);

	/* Send command */
	myx_write(sc, MYX_RDMA, &rc, sizeof(rc));

	for (i = 0; i < 20; i++) {
		bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
		    BUS_DMASYNC_POSTREAD);

		if (*status == 0xffffffff) {
			ret = 0;
			break;
		}

		bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
		    BUS_DMASYNC_PREREAD);
		delay(1000);
	}

	DPRINTF(MYXDBG_CMD, "%s(%s): dummy RDMA %s, i %d, result 0x%x\n",
	    DEVNAME(sc), __func__,
	    do_enable ? "enabled" : "disabled", i, betoh32(*status));

	return (ret);
}

int
myx_media_change(struct ifnet *ifp)
{
	/* ignore */
	return (0);
}

void
myx_media_status(struct ifnet *ifp, struct ifmediareq *imr)
{
	struct myx_softc	*sc = (struct myx_softc *)ifp->if_softc;
	bus_dmamap_t		 map = sc->sc_sts_dma.mxm_map;
	u_int32_t		 sts;

	imr->ifm_active = IFM_ETHER | IFM_AUTO;
	if (!ISSET(ifp->if_flags, IFF_RUNNING)) {
		imr->ifm_status = 0;
		return;
	}

	bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
	    BUS_DMASYNC_POSTREAD|BUS_DMASYNC_POSTWRITE);
	sts = sc->sc_sts->ms_linkstate;
	bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
	    BUS_DMASYNC_PREREAD|BUS_DMASYNC_PREWRITE);

	myx_link_state(sc, sts);

	imr->ifm_status = IFM_AVALID;
	if (!LINK_STATE_IS_UP(ifp->if_link_state))
		return;

	imr->ifm_active |= IFM_FDX | IFM_FLOW |
	    IFM_ETH_RXPAUSE | IFM_ETH_TXPAUSE;
	imr->ifm_status |= IFM_ACTIVE;
}

void
myx_link_state(struct myx_softc *sc, u_int32_t sts)
{
	struct ifnet		*ifp = &sc->sc_ac.ac_if;
	int			 link_state = LINK_STATE_DOWN;

	if (betoh32(sts) == MYXSTS_LINKUP)
		link_state = LINK_STATE_FULL_DUPLEX;
	if (ifp->if_link_state != link_state) {
		ifp->if_link_state = link_state;
		if_link_state_change(ifp);
		ifp->if_baudrate = LINK_STATE_IS_UP(ifp->if_link_state) ?
		    IF_Gbps(10) : 0;
	}
}

void
myx_watchdog(struct ifnet *ifp)
{
	return;
}

int
myx_ioctl(struct ifnet *ifp, u_long cmd, caddr_t data)
{
	struct myx_softc	*sc = (struct myx_softc *)ifp->if_softc;
	struct ifreq		*ifr = (struct ifreq *)data;
	int			 s, error = 0;

	s = splnet();

	switch (cmd) {
	case SIOCSIFADDR:
		ifp->if_flags |= IFF_UP;
		/* FALLTHROUGH */

	case SIOCSIFFLAGS:
		if (ISSET(ifp->if_flags, IFF_UP)) {
			if (ISSET(ifp->if_flags, IFF_RUNNING))
				error = ENETRESET;
			else
				myx_up(sc);
		} else {
			if (ISSET(ifp->if_flags, IFF_RUNNING))
				myx_down(sc);
		}
		break;

	case SIOCGIFMEDIA:
	case SIOCSIFMEDIA:
		error = ifmedia_ioctl(ifp, ifr, &sc->sc_media, cmd);
		break;

	case SIOCGIFRXR:
		error = myx_rxrinfo(sc, (struct if_rxrinfo *)ifr->ifr_data);
		break;

	default:
		error = ether_ioctl(ifp, &sc->sc_ac, cmd, data);
	}

	if (error == ENETRESET) {
		if ((ifp->if_flags & (IFF_UP | IFF_RUNNING)) ==
		    (IFF_UP | IFF_RUNNING))
			myx_iff(sc);
		error = 0;
	}

	splx(s);
	return (error);
}

int
myx_rxrinfo(struct myx_softc *sc, struct if_rxrinfo *ifri)
{
	struct if_rxring_info ifr[2];

	memset(ifr, 0, sizeof(ifr));

	ifr[0].ifr_size = MYX_RXSMALL_SIZE;
	ifr[0].ifr_info = sc->sc_rx_ring[0].mrr_rxr;

	ifr[1].ifr_size = MYX_RXBIG_SIZE;
	ifr[1].ifr_info = sc->sc_rx_ring[1].mrr_rxr;

	return (if_rxr_info_ioctl(ifri, nitems(ifr), ifr));
}

void
myx_up(struct myx_softc *sc)
{
	struct ifnet		*ifp = &sc->sc_ac.ac_if;
	struct myx_cmd		mc;
	bus_dmamap_t		map;
	size_t			size;
	u_int			maxpkt;
	u_int32_t		r;

	memset(&mc, 0, sizeof(mc));
	if (myx_cmd(sc, MYXCMD_RESET, &mc, NULL) != 0) {
		printf("%s: failed to reset the device\n", DEVNAME(sc));
		return;
	}

	if (myx_dmamem_alloc(sc, &sc->sc_zerodma,
	    64, MYXALIGN_CMD) != 0) {
		printf("%s: failed to allocate zero pad memory\n",
		    DEVNAME(sc));
		return;
	}
	memset(sc->sc_zerodma.mxm_kva, 0, 64);
	bus_dmamap_sync(sc->sc_dmat, sc->sc_zerodma.mxm_map, 0,
	    sc->sc_zerodma.mxm_map->dm_mapsize, BUS_DMASYNC_PREREAD);

	if (myx_dmamem_alloc(sc, &sc->sc_paddma,
	    MYXALIGN_CMD, MYXALIGN_CMD) != 0) {
		printf("%s: failed to allocate pad DMA memory\n",
		    DEVNAME(sc));
		goto free_zero;
	}
	bus_dmamap_sync(sc->sc_dmat, sc->sc_paddma.mxm_map, 0,
	    sc->sc_paddma.mxm_map->dm_mapsize,
	    BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);

	if (myx_rdma(sc, MYXRDMA_ON) != 0) {
		printf("%s: failed to enable dummy RDMA\n", DEVNAME(sc));
		goto free_pad;
	}

	if (myx_cmd(sc, MYXCMD_GET_RXRINGSZ, &mc, &r) != 0) {
		printf("%s: unable to get rx ring size\n", DEVNAME(sc));
		goto free_pad;
	}
	sc->sc_rx_ring_count = r / sizeof(struct myx_rx_desc);

	memset(&mc, 0, sizeof(mc));
	if (myx_cmd(sc, MYXCMD_GET_TXRINGSZ, &mc, &r) != 0) {
		printf("%s: unable to get tx ring size\n", DEVNAME(sc));
		goto free_pad;
	}
	sc->sc_tx_ring_prod = 0;
	sc->sc_tx_ring_cons = 0;
	sc->sc_tx_ring_count = r / sizeof(struct myx_tx_desc);
	sc->sc_tx_nsegs = min(16, sc->sc_tx_ring_count / 4); /* magic */
	sc->sc_tx_count = 0;
	IFQ_SET_MAXLEN(&ifp->if_snd, sc->sc_tx_ring_count - 1);

	/* Allocate Interrupt Queue */

	sc->sc_intrq_count = sc->sc_rx_ring_count * 2;
	sc->sc_intrq_idx = 0;

	size = sc->sc_intrq_count * sizeof(struct myx_intrq_desc);
	if (myx_dmamem_alloc(sc, &sc->sc_intrq_dma,
	    size, MYXALIGN_DATA) != 0) {
		goto free_pad;
	}
	sc->sc_intrq = (struct myx_intrq_desc *)sc->sc_intrq_dma.mxm_kva;
	map = sc->sc_intrq_dma.mxm_map;
	memset(sc->sc_intrq, 0, size);
	bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
	    BUS_DMASYNC_PREREAD);

	memset(&mc, 0, sizeof(mc));
	mc.mc_data0 = htobe32(size);
	if (myx_cmd(sc, MYXCMD_SET_INTRQSZ, &mc, NULL) != 0) {
		printf("%s: failed to set intrq size\n", DEVNAME(sc));
		goto free_intrq;
	}

	memset(&mc, 0, sizeof(mc));
	mc.mc_data0 = htobe32(MYX_ADDRLOW(map->dm_segs[0].ds_addr));
	mc.mc_data1 = htobe32(MYX_ADDRHIGH(map->dm_segs[0].ds_addr));
	if (myx_cmd(sc, MYXCMD_SET_INTRQDMA, &mc, NULL) != 0) {
		printf("%s: failed to set intrq address\n", DEVNAME(sc));
		goto free_intrq;
	}

	/*
	 * get interrupt offsets
	 */

	memset(&mc, 0, sizeof(mc));
	if (myx_cmd(sc, MYXCMD_GET_INTRACKOFF, &mc,
	    &sc->sc_irqclaimoff) != 0) {
		printf("%s: failed to get IRQ ack offset\n", DEVNAME(sc));
		goto free_intrq;
	}

	memset(&mc, 0, sizeof(mc));
	if (myx_cmd(sc, MYXCMD_GET_INTRDEASSERTOFF, &mc,
	    &sc->sc_irqdeassertoff) != 0) {
		printf("%s: failed to get IRQ deassert offset\n", DEVNAME(sc));
		goto free_intrq;
	}

	memset(&mc, 0, sizeof(mc));
	if (myx_cmd(sc, MYXCMD_GET_INTRCOALDELAYOFF, &mc,
	    &sc->sc_irqcoaloff) != 0) {
		printf("%s: failed to get IRQ coal offset\n", DEVNAME(sc));
		goto free_intrq;
	}

	/* Set an appropriate interrupt coalescing period */
	r = htobe32(MYX_IRQCOALDELAY);
	myx_write(sc, sc->sc_irqcoaloff, &r, sizeof(r));

	if (myx_setlladdr(sc, MYXCMD_SET_LLADDR, LLADDR(ifp->if_sadl)) != 0) {
		printf("%s: failed to configure lladdr\n", DEVNAME(sc));
		goto free_intrq;
	}

	memset(&mc, 0, sizeof(mc));
	if (myx_cmd(sc, MYXCMD_UNSET_PROMISC, &mc, NULL) != 0) {
		printf("%s: failed to disable promisc mode\n", DEVNAME(sc));
		goto free_intrq;
	}

	memset(&mc, 0, sizeof(mc));
	if (myx_cmd(sc, MYXCMD_FC_DEFAULT, &mc, NULL) != 0) {
		printf("%s: failed to configure flow control\n", DEVNAME(sc));
		goto free_intrq;
	}

	memset(&mc, 0, sizeof(mc));
	if (myx_cmd(sc, MYXCMD_GET_TXRINGOFF, &mc,
	    &sc->sc_tx_ring_offset) != 0) {
		printf("%s: unable to get tx ring offset\n", DEVNAME(sc));
		goto free_intrq;
	}

	memset(&mc, 0, sizeof(mc));
	if (myx_cmd(sc, MYXCMD_GET_RXSMALLRINGOFF, &mc,
	    &sc->sc_rx_ring[MYX_RXSMALL].mrr_offset) != 0) {
		printf("%s: unable to get small rx ring offset\n", DEVNAME(sc));
		goto free_intrq;
	}

	memset(&mc, 0, sizeof(mc));
	if (myx_cmd(sc, MYXCMD_GET_RXBIGRINGOFF, &mc,
	    &sc->sc_rx_ring[MYX_RXBIG].mrr_offset) != 0) {
		printf("%s: unable to get big rx ring offset\n", DEVNAME(sc));
		goto free_intrq;
	}

	/* Allocate Interrupt Data */
	if (myx_dmamem_alloc(sc, &sc->sc_sts_dma,
	    sizeof(struct myx_status), MYXALIGN_DATA) != 0) {
		printf("%s: failed to allocate status DMA memory\n",
		    DEVNAME(sc));
		goto free_intrq;
	}
	sc->sc_sts = (struct myx_status *)sc->sc_sts_dma.mxm_kva;
	map = sc->sc_sts_dma.mxm_map;
	bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
	    BUS_DMASYNC_PREREAD);

	memset(&mc, 0, sizeof(mc));
	mc.mc_data0 = htobe32(MYX_ADDRLOW(map->dm_segs[0].ds_addr));
	mc.mc_data1 = htobe32(MYX_ADDRHIGH(map->dm_segs[0].ds_addr));
	mc.mc_data2 = htobe32(sizeof(struct myx_status));
	if (myx_cmd(sc, MYXCMD_SET_STATSDMA, &mc, NULL) != 0) {
		printf("%s: failed to set status DMA offset\n", DEVNAME(sc));
		goto free_sts;
	}

	maxpkt = ifp->if_hardmtu + ETHER_HDR_LEN + ETHER_VLAN_ENCAP_LEN;

	memset(&mc, 0, sizeof(mc));
	mc.mc_data0 = htobe32(maxpkt);
	if (myx_cmd(sc, MYXCMD_SET_MTU, &mc, NULL) != 0) {
		printf("%s: failed to set MTU size %d\n", DEVNAME(sc), maxpkt);
		goto free_sts;
	}

	if (myx_tx_init(sc, maxpkt) != 0)
		goto free_sts;

	if (myx_rx_init(sc, MYX_RXSMALL, MCLBYTES) != 0)
		goto free_tx_ring;

	if (myx_rx_fill(sc, &sc->sc_rx_ring[MYX_RXSMALL]) != 0)
		goto free_rx_ring_small;

	if (myx_rx_init(sc, MYX_RXBIG, MYX_RXBIG_SIZE) != 0)
		goto empty_rx_ring_small;

	if (myx_rx_fill(sc, &sc->sc_rx_ring[MYX_RXBIG]) != 0)
		goto free_rx_ring_big;

	memset(&mc, 0, sizeof(mc));
	mc.mc_data0 = htobe32(MYX_RXSMALL_SIZE - ETHER_ALIGN);
	if (myx_cmd(sc, MYXCMD_SET_SMALLBUFSZ, &mc, NULL) != 0) {
		printf("%s: failed to set small buf size\n", DEVNAME(sc));
		goto empty_rx_ring_big;
	}

	memset(&mc, 0, sizeof(mc));
	mc.mc_data0 = htobe32(16384);
	if (myx_cmd(sc, MYXCMD_SET_BIGBUFSZ, &mc, NULL) != 0) {
		printf("%s: failed to set big buf size\n", DEVNAME(sc));
		goto empty_rx_ring_big;
	}

	sc->sc_state = MYX_S_RUNNING;

	if (myx_cmd(sc, MYXCMD_SET_IFUP, &mc, NULL) != 0) {
		printf("%s: failed to start the device\n", DEVNAME(sc));
		goto empty_rx_ring_big;
	}

	myx_iff(sc);
	SET(ifp->if_flags, IFF_RUNNING);
	ifq_restart(&ifp->if_snd);

	return;

empty_rx_ring_big:
	myx_rx_empty(sc, &sc->sc_rx_ring[MYX_RXBIG]);
free_rx_ring_big:
	myx_rx_free(sc, &sc->sc_rx_ring[MYX_RXBIG]);
empty_rx_ring_small:
	myx_rx_empty(sc, &sc->sc_rx_ring[MYX_RXSMALL]);
free_rx_ring_small:
	myx_rx_free(sc, &sc->sc_rx_ring[MYX_RXSMALL]);
free_tx_ring:
	myx_tx_free(sc);
free_sts:
	bus_dmamap_sync(sc->sc_dmat, sc->sc_sts_dma.mxm_map, 0,
	    sc->sc_sts_dma.mxm_map->dm_mapsize, BUS_DMASYNC_POSTREAD);
	myx_dmamem_free(sc, &sc->sc_sts_dma);
free_intrq:
	bus_dmamap_sync(sc->sc_dmat, sc->sc_intrq_dma.mxm_map, 0,
	    sc->sc_intrq_dma.mxm_map->dm_mapsize, BUS_DMASYNC_POSTREAD);
	myx_dmamem_free(sc, &sc->sc_intrq_dma);
free_pad:
	bus_dmamap_sync(sc->sc_dmat, sc->sc_paddma.mxm_map, 0,
	    sc->sc_paddma.mxm_map->dm_mapsize,
	    BUS_DMASYNC_POSTREAD | BUS_DMASYNC_POSTWRITE);
	myx_dmamem_free(sc, &sc->sc_paddma);

	memset(&mc, 0, sizeof(mc));
	if (myx_cmd(sc, MYXCMD_RESET, &mc, NULL) != 0) {
		printf("%s: failed to reset the device\n", DEVNAME(sc));
	}
free_zero:
	bus_dmamap_sync(sc->sc_dmat, sc->sc_zerodma.mxm_map, 0,
	    sc->sc_zerodma.mxm_map->dm_mapsize, BUS_DMASYNC_POSTREAD);
	myx_dmamem_free(sc, &sc->sc_zerodma);
}

int
myx_setlladdr(struct myx_softc *sc, u_int32_t cmd, u_int8_t *addr)
{
	struct myx_cmd		 mc;

	memset(&mc, 0, sizeof(mc));
	mc.mc_data0 = htobe32(addr[0] << 24 | addr[1] << 16 |
	    addr[2] << 8 | addr[3]);
	mc.mc_data1 = htobe32(addr[4] << 8 | addr[5]);

	if (myx_cmd(sc, cmd, &mc, NULL) != 0) {
		printf("%s: failed to set the lladdr\n", DEVNAME(sc));
		return (-1);
	}
	return (0);
}

void
myx_iff(struct myx_softc *sc)
{
	struct myx_cmd		mc;
	struct ifnet		*ifp = &sc->sc_ac.ac_if;
	struct ether_multi	*enm;
	struct ether_multistep	step;
	u_int8_t *addr;

	CLR(ifp->if_flags, IFF_ALLMULTI);

	if (myx_cmd(sc, ISSET(ifp->if_flags, IFF_PROMISC) ?
	    MYXCMD_SET_PROMISC : MYXCMD_UNSET_PROMISC, &mc, NULL) != 0) {
		printf("%s: failed to configure promisc mode\n", DEVNAME(sc));
		return;
	}

	if (myx_cmd(sc, MYXCMD_SET_ALLMULTI, &mc, NULL) != 0) {
		printf("%s: failed to enable ALLMULTI\n", DEVNAME(sc));
		return;
	}

	if (myx_cmd(sc, MYXCMD_UNSET_MCAST, &mc, NULL) != 0) {
		printf("%s: failed to leave all mcast groups \n", DEVNAME(sc));
		return;
	}

	if (ISSET(ifp->if_flags, IFF_PROMISC) ||
	    sc->sc_ac.ac_multirangecnt > 0) {
		SET(ifp->if_flags, IFF_ALLMULTI);
		return;
	}

	ETHER_FIRST_MULTI(step, &sc->sc_ac, enm);
	while (enm != NULL) {
		addr = enm->enm_addrlo;

		memset(&mc, 0, sizeof(mc));
		mc.mc_data0 = htobe32(addr[0] << 24 | addr[1] << 16 |
		    addr[2] << 8 | addr[3]);
		mc.mc_data1 = htobe32(addr[4] << 24 | addr[5] << 16);
		if (myx_cmd(sc, MYXCMD_SET_MCASTGROUP, &mc, NULL) != 0) {
			printf("%s: failed to join mcast group\n", DEVNAME(sc));
			return;
		}

		ETHER_NEXT_MULTI(step, enm);
	}

	memset(&mc, 0, sizeof(mc));
	if (myx_cmd(sc, MYXCMD_UNSET_ALLMULTI, &mc, NULL) != 0) {
		printf("%s: failed to disable ALLMULTI\n", DEVNAME(sc));
		return;
	}
}

void
myx_down(struct myx_softc *sc)
{
	struct ifnet		*ifp = &sc->sc_ac.ac_if;
	volatile struct myx_status *sts = sc->sc_sts;
	bus_dmamap_t		 map = sc->sc_sts_dma.mxm_map;
	struct sleep_state	 sls;
	struct myx_cmd		 mc;
	int			 s;
	int			 ring;

	CLR(ifp->if_flags, IFF_RUNNING);

	bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
	    BUS_DMASYNC_POSTREAD|BUS_DMASYNC_POSTWRITE);
	sc->sc_linkdown = sts->ms_linkdown;
	bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
	    BUS_DMASYNC_PREREAD|BUS_DMASYNC_PREWRITE);

	sc->sc_state = MYX_S_DOWN;
	membar_producer();

	memset(&mc, 0, sizeof(mc));
	(void)myx_cmd(sc, MYXCMD_SET_IFDOWN, &mc, NULL);

	while (sc->sc_state != MYX_S_OFF) {
		sleep_setup(&sls, sts, PWAIT, "myxdown");
		membar_consumer();
		sleep_finish(&sls, sc->sc_state != MYX_S_OFF);
	}

	s = splnet();
	if (ifp->if_link_state != LINK_STATE_UNKNOWN) {
		ifp->if_link_state = LINK_STATE_UNKNOWN;
		ifp->if_baudrate = 0;
		if_link_state_change(ifp);
	}
	splx(s);

	memset(&mc, 0, sizeof(mc));
	if (myx_cmd(sc, MYXCMD_RESET, &mc, NULL) != 0) {
		printf("%s: failed to reset the device\n", DEVNAME(sc));
	}

	ifq_clr_oactive(&ifp->if_snd);
	ifq_barrier(&ifp->if_snd);

	for (ring = 0; ring < 2; ring++) {
		struct myx_rx_ring *mrr = &sc->sc_rx_ring[ring];

		timeout_del(&mrr->mrr_refill);
		myx_rx_empty(sc, mrr);
		myx_rx_free(sc, mrr);
	}

	myx_tx_empty(sc);
	myx_tx_free(sc);

	/* the sleep shizz above already synced this dmamem */
	myx_dmamem_free(sc, &sc->sc_sts_dma);

	bus_dmamap_sync(sc->sc_dmat, sc->sc_intrq_dma.mxm_map, 0,
	    sc->sc_intrq_dma.mxm_map->dm_mapsize, BUS_DMASYNC_POSTREAD);
	myx_dmamem_free(sc, &sc->sc_intrq_dma);

	bus_dmamap_sync(sc->sc_dmat, sc->sc_paddma.mxm_map, 0,
	    sc->sc_paddma.mxm_map->dm_mapsize, BUS_DMASYNC_POSTREAD);
	myx_dmamem_free(sc, &sc->sc_paddma);

	bus_dmamap_sync(sc->sc_dmat, sc->sc_zerodma.mxm_map, 0,
	    sc->sc_zerodma.mxm_map->dm_mapsize, BUS_DMASYNC_POSTREAD);
	myx_dmamem_free(sc, &sc->sc_zerodma);
}

void
myx_write_txd_tail(struct myx_softc *sc, struct myx_slot *ms, u_int8_t flags,
    u_int32_t offset, u_int idx)
{
	struct myx_tx_desc		txd;
	bus_dmamap_t			zmap = sc->sc_zerodma.mxm_map;
	bus_dmamap_t			map = ms->ms_map;
	int				i;

	for (i = 1; i < map->dm_nsegs; i++) {
		memset(&txd, 0, sizeof(txd));
		txd.tx_addr = htobe64(map->dm_segs[i].ds_addr);
		txd.tx_length = htobe16(map->dm_segs[i].ds_len);
		txd.tx_flags = flags;

		myx_bus_space_write(sc,
		    offset + sizeof(txd) * ((idx + i) % sc->sc_tx_ring_count),
		    &txd, sizeof(txd));
	}

	/* pad runt frames */
	if (map->dm_mapsize < 60) {
		memset(&txd, 0, sizeof(txd));
		txd.tx_addr = htobe64(zmap->dm_segs[0].ds_addr);
		txd.tx_length = htobe16(60 - map->dm_mapsize);
		txd.tx_flags = flags;

		myx_bus_space_write(sc,
		    offset + sizeof(txd) * ((idx + i) % sc->sc_tx_ring_count),
		    &txd, sizeof(txd));
	}
}

void
myx_start(struct ifqueue *ifq)
{
	struct ifnet			*ifp = ifq->ifq_if;
	struct myx_tx_desc		txd;
	struct myx_softc		*sc = ifp->if_softc;
	struct myx_slot			*ms;
	bus_dmamap_t			map;
	struct mbuf			*m;
	u_int32_t			offset = sc->sc_tx_ring_offset;
	u_int				idx, cons, prod;
	u_int				free, used;
	u_int8_t			flags;

	idx = sc->sc_tx_ring_prod;

	/* figure out space */
	free = sc->sc_tx_ring_cons;
	if (free <= idx)
		free += sc->sc_tx_ring_count;
	free -= idx;

	cons = prod = sc->sc_tx_prod;

	used = 0;

	for (;;) {
		if (used + sc->sc_tx_nsegs + 1 > free) {
			ifq_set_oactive(ifq);
			break;
		}

		m = ifq_dequeue(ifq);
		if (m == NULL)
			break;

		ms = &sc->sc_tx_slots[prod];

		if (myx_load_mbuf(sc, ms, m) != 0) {
			m_freem(m);
			ifp->if_oerrors++;
			continue;
		}

#if NBPFILTER > 0
		if (ifp->if_bpf)
			bpf_mtap(ifp->if_bpf, m, BPF_DIRECTION_OUT);
#endif

		map = ms->ms_map;
		bus_dmamap_sync(sc->sc_dmat, map, 0,
		    map->dm_mapsize, BUS_DMASYNC_PREWRITE);

		used += map->dm_nsegs + (map->dm_mapsize < 60 ? 1 : 0);

		if (++prod >= sc->sc_tx_ring_count)
			prod = 0;
	}

	if (cons == prod)
		return;

	ms = &sc->sc_tx_slots[cons];

	for (;;) {
		idx += ms->ms_map->dm_nsegs +
		    (ms->ms_map->dm_mapsize < 60 ? 1 : 0);
		if (idx >= sc->sc_tx_ring_count)
			idx -= sc->sc_tx_ring_count;

		if (++cons >= sc->sc_tx_ring_count)
			cons = 0;

		if (cons == prod)
			break;

		ms = &sc->sc_tx_slots[cons];
		map = ms->ms_map;

		flags = MYXTXD_FLAGS_NO_TSO;
		if (map->dm_mapsize < 1520)
			flags |= MYXTXD_FLAGS_SMALL;

		memset(&txd, 0, sizeof(txd));
		txd.tx_addr = htobe64(map->dm_segs[0].ds_addr);
		txd.tx_length = htobe16(map->dm_segs[0].ds_len);
		txd.tx_nsegs = map->dm_nsegs + (map->dm_mapsize < 60 ? 1 : 0);
		txd.tx_flags = flags | MYXTXD_FLAGS_FIRST;
		myx_bus_space_write(sc,
		    offset + sizeof(txd) * idx, &txd, sizeof(txd));

		myx_write_txd_tail(sc, ms, flags, offset, idx);
	}

	/* go back and post first packet */
	ms = &sc->sc_tx_slots[sc->sc_tx_prod];
	map = ms->ms_map;

	flags = MYXTXD_FLAGS_NO_TSO;
	if (map->dm_mapsize < 1520)
		flags |= MYXTXD_FLAGS_SMALL;

	memset(&txd, 0, sizeof(txd));
	txd.tx_addr = htobe64(map->dm_segs[0].ds_addr);
	txd.tx_length = htobe16(map->dm_segs[0].ds_len);
	txd.tx_nsegs = map->dm_nsegs + (map->dm_mapsize < 60 ? 1 : 0);
	txd.tx_flags = flags | MYXTXD_FLAGS_FIRST;

	/* make sure the first descriptor is seen after the others */
	myx_write_txd_tail(sc, ms, flags, offset, sc->sc_tx_ring_prod);

	myx_bus_space_write(sc,
	    offset + sizeof(txd) * sc->sc_tx_ring_prod, &txd,
	    sizeof(txd) - sizeof(myx_bus_t));

	bus_space_barrier(sc->sc_memt, sc->sc_memh, offset,
	    sizeof(txd) * sc->sc_tx_ring_count, BUS_SPACE_BARRIER_WRITE);

	myx_bus_space_write(sc,
	    offset + sizeof(txd) * (sc->sc_tx_ring_prod + 1) -
	    sizeof(myx_bus_t),
	    (u_int8_t *)&txd + sizeof(txd) - sizeof(myx_bus_t),
	    sizeof(myx_bus_t));

	bus_space_barrier(sc->sc_memt, sc->sc_memh,
	    offset + sizeof(txd) * sc->sc_tx_ring_prod, sizeof(txd),
	    BUS_SPACE_BARRIER_WRITE);

	/* commit */
	sc->sc_tx_ring_prod = idx;
	sc->sc_tx_prod = prod;
}

int
myx_load_mbuf(struct myx_softc *sc, struct myx_slot *ms, struct mbuf *m)
{
	bus_dma_tag_t			dmat = sc->sc_dmat;
	bus_dmamap_t			dmap = ms->ms_map;

	switch (bus_dmamap_load_mbuf(dmat, dmap, m,
	    BUS_DMA_STREAMING | BUS_DMA_NOWAIT)) {
	case 0:
		break;

	case EFBIG: /* mbuf chain is too fragmented */
		if (m_defrag(m, M_DONTWAIT) == 0 &&
		    bus_dmamap_load_mbuf(dmat, dmap, m,
		    BUS_DMA_STREAMING | BUS_DMA_NOWAIT) == 0)
			break;
	default:
		return (1);
	}

	ms->ms_m = m;
	return (0);
}

int
myx_intr(void *arg)
{
	struct myx_softc	*sc = (struct myx_softc *)arg;
	volatile struct myx_status *sts = sc->sc_sts;
	enum myx_state		 state;
	bus_dmamap_t		 map = sc->sc_sts_dma.mxm_map;
	u_int32_t		 data;
	u_int8_t		 valid = 0;

	state = sc->sc_state;
	if (state == MYX_S_OFF)
		return (0);

	bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
	    BUS_DMASYNC_POSTREAD|BUS_DMASYNC_POSTWRITE);

	valid = sts->ms_isvalid;
	if (valid == 0x0) {
		bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
		    BUS_DMASYNC_PREREAD|BUS_DMASYNC_PREWRITE);
		return (0);
	}

	if (sc->sc_intx) {
		data = htobe32(0);
		bus_space_write_raw_region_4(sc->sc_memt, sc->sc_memh,
		    sc->sc_irqdeassertoff, &data, sizeof(data));
	}
	sts->ms_isvalid = 0;

	do {
		data = sts->ms_txdonecnt;

		bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
		    BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE |
		    BUS_DMASYNC_POSTREAD | BUS_DMASYNC_POSTWRITE);
	} while (sts->ms_isvalid);

	data = betoh32(data);
	if (data != sc->sc_tx_count)
		myx_txeof(sc, data);

	data = htobe32(3);
	if (valid & 0x1) {
		myx_rxeof(sc);

		bus_space_write_raw_region_4(sc->sc_memt, sc->sc_memh,
		    sc->sc_irqclaimoff, &data, sizeof(data));
	}
	bus_space_write_raw_region_4(sc->sc_memt, sc->sc_memh,
	    sc->sc_irqclaimoff + sizeof(data), &data, sizeof(data));

	if (sts->ms_statusupdated) {
		if (state == MYX_S_DOWN &&
		    sc->sc_linkdown != sts->ms_linkdown) {
			sc->sc_state = MYX_S_OFF;
			membar_producer();
			wakeup(sts);
		} else {
			data = sts->ms_linkstate;
			if (data != 0xffffffff) {
				KERNEL_LOCK();
				myx_link_state(sc, data);
				KERNEL_UNLOCK();
			}
		}
	}

	bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
	    BUS_DMASYNC_PREREAD|BUS_DMASYNC_PREWRITE);

	return (1);
}

void
myx_refill(void *xmrr)
{
	struct myx_rx_ring *mrr = xmrr;
	struct myx_softc *sc = mrr->mrr_softc;

	myx_rx_fill(sc, mrr);

	if (mrr->mrr_prod == mrr->mrr_cons)
		timeout_add(&mrr->mrr_refill, 1);
}

void
myx_txeof(struct myx_softc *sc, u_int32_t done_count)
{
	struct ifnet *ifp = &sc->sc_ac.ac_if;
	struct myx_slot *ms;
	bus_dmamap_t map;
	u_int idx, cons;

	idx = sc->sc_tx_ring_cons;
	cons = sc->sc_tx_cons;

	do {
		ms = &sc->sc_tx_slots[cons];
		map = ms->ms_map;

		idx += map->dm_nsegs + (map->dm_mapsize < 60 ? 1 : 0);

		bus_dmamap_sync(sc->sc_dmat, map, 0,
		    map->dm_mapsize, BUS_DMASYNC_POSTWRITE);
		bus_dmamap_unload(sc->sc_dmat, map);
		m_freem(ms->ms_m);

		if (++cons >= sc->sc_tx_ring_count)
			cons = 0;
	} while (++sc->sc_tx_count != done_count);

	if (idx >= sc->sc_tx_ring_count)
		idx -= sc->sc_tx_ring_count;

	sc->sc_tx_ring_cons = idx;
	sc->sc_tx_cons = cons;

	if (ifq_is_oactive(&ifp->if_snd))
		ifq_restart(&ifp->if_snd);
}

void
myx_rxeof(struct myx_softc *sc)
{
	static const struct myx_intrq_desc zerodesc = { 0, 0 };
	struct ifnet *ifp = &sc->sc_ac.ac_if;
	struct mbuf_list ml = MBUF_LIST_INITIALIZER();
	struct myx_rx_ring *mrr;
	struct myx_slot *ms;
	struct mbuf *m;
	int ring;
	u_int rxfree[2] = { 0 , 0 };
	u_int len;

	bus_dmamap_sync(sc->sc_dmat, sc->sc_intrq_dma.mxm_map, 0,
	    sc->sc_intrq_dma.mxm_map->dm_mapsize, BUS_DMASYNC_POSTREAD);

	while ((len = betoh16(sc->sc_intrq[sc->sc_intrq_idx].iq_length)) != 0) {
		sc->sc_intrq[sc->sc_intrq_idx] = zerodesc;

		if (++sc->sc_intrq_idx >= sc->sc_intrq_count)
			sc->sc_intrq_idx = 0;

		ring = (len <= (MYX_RXSMALL_SIZE - ETHER_ALIGN)) ?
		    MYX_RXSMALL : MYX_RXBIG;

		mrr = &sc->sc_rx_ring[ring];
		ms = &mrr->mrr_slots[mrr->mrr_cons];

		if (++mrr->mrr_cons >= sc->sc_rx_ring_count)
			mrr->mrr_cons = 0;

		bus_dmamap_sync(sc->sc_dmat, ms->ms_map, 0,
		    ms->ms_map->dm_mapsize, BUS_DMASYNC_POSTREAD);
		bus_dmamap_unload(sc->sc_dmat, ms->ms_map);

		m = ms->ms_m;
		m->m_data += ETHER_ALIGN;
		m->m_pkthdr.len = m->m_len = len;

		ml_enqueue(&ml, m);

		rxfree[ring]++;
	}

	bus_dmamap_sync(sc->sc_dmat, sc->sc_intrq_dma.mxm_map, 0,
	    sc->sc_intrq_dma.mxm_map->dm_mapsize, BUS_DMASYNC_PREREAD);

	for (ring = MYX_RXSMALL; ring <= MYX_RXBIG; ring++) {
		if (rxfree[ring] == 0)
			continue;

		mrr = &sc->sc_rx_ring[ring];

		if_rxr_put(&mrr->mrr_rxr, rxfree[ring]);
		myx_rx_fill(sc, mrr);
		if (mrr->mrr_prod == mrr->mrr_cons)
			timeout_add(&mrr->mrr_refill, 0);
	}

	if_input(ifp, &ml);
}

static int
myx_rx_fill_slots(struct myx_softc *sc, struct myx_rx_ring *mrr, u_int slots)
{
	struct myx_rx_desc rxd;
	struct myx_slot *ms;
	u_int32_t offset = mrr->mrr_offset;
	u_int p, first, fills;

	first = p = mrr->mrr_prod;
	if (myx_buf_fill(sc, &mrr->mrr_slots[first], mrr->mrr_mclget) != 0)
		return (slots);

	if (++p >= sc->sc_rx_ring_count)
		p = 0;

	for (fills = 1; fills < slots; fills++) {
		ms = &mrr->mrr_slots[p];

		if (myx_buf_fill(sc, ms, mrr->mrr_mclget) != 0)
			break;

		rxd.rx_addr = htobe64(ms->ms_map->dm_segs[0].ds_addr);
		myx_bus_space_write(sc, offset + p * sizeof(rxd),
		    &rxd, sizeof(rxd));

		if (++p >= sc->sc_rx_ring_count)
			p = 0;
	}

	mrr->mrr_prod = p;

	/* make sure the first descriptor is seen after the others */
	if (fills > 1) {
		bus_space_barrier(sc->sc_memt, sc->sc_memh,
		    offset, sizeof(rxd) * sc->sc_rx_ring_count,
		    BUS_SPACE_BARRIER_WRITE);
	}

	ms = &mrr->mrr_slots[first];
	rxd.rx_addr = htobe64(ms->ms_map->dm_segs[0].ds_addr);
	myx_bus_space_write(sc, offset + first * sizeof(rxd),
	    &rxd, sizeof(rxd));

	return (slots - fills);
}

int
myx_rx_init(struct myx_softc *sc, int ring, bus_size_t size)
{
	struct myx_rx_desc rxd;
	struct myx_rx_ring *mrr = &sc->sc_rx_ring[ring];
	struct myx_slot *ms;
	u_int32_t offset = mrr->mrr_offset;
	int rv;
	int i;

	mrr->mrr_slots = mallocarray(sizeof(*ms), sc->sc_rx_ring_count,
	    M_DEVBUF, M_WAITOK);
	if (mrr->mrr_slots == NULL)
		return (ENOMEM);

	memset(&rxd, 0xff, sizeof(rxd));
	for (i = 0; i < sc->sc_rx_ring_count; i++) {
		ms = &mrr->mrr_slots[i];
		rv = bus_dmamap_create(sc->sc_dmat, size, 1, size, 0,
		    BUS_DMA_WAITOK | BUS_DMA_ALLOCNOW, &ms->ms_map);
		if (rv != 0)
			goto destroy;

		myx_bus_space_write(sc, offset + i * sizeof(rxd),
		    &rxd, sizeof(rxd));
	}

	if_rxr_init(&mrr->mrr_rxr, 2, sc->sc_rx_ring_count - 2);
	mrr->mrr_prod = mrr->mrr_cons = 0;

	return (0);

destroy:
	while (i-- > 0) {
		ms = &mrr->mrr_slots[i];
		bus_dmamap_destroy(sc->sc_dmat, ms->ms_map);
	}
	free(mrr->mrr_slots, M_DEVBUF, sizeof(*ms) * sc->sc_rx_ring_count);
	return (rv);
}

int
myx_rx_fill(struct myx_softc *sc, struct myx_rx_ring *mrr)
{
	u_int slots;

	slots = if_rxr_get(&mrr->mrr_rxr, sc->sc_rx_ring_count);
	if (slots == 0)
		return (1);

	slots = myx_rx_fill_slots(sc, mrr, slots);
	if (slots > 0)
		if_rxr_put(&mrr->mrr_rxr, slots);

	return (0);
}

void
myx_rx_empty(struct myx_softc *sc, struct myx_rx_ring *mrr)
{
	struct myx_slot *ms;

	while (mrr->mrr_cons != mrr->mrr_prod) {
		ms = &mrr->mrr_slots[mrr->mrr_cons];

		if (++mrr->mrr_cons >= sc->sc_rx_ring_count)
			mrr->mrr_cons = 0;

		bus_dmamap_sync(sc->sc_dmat, ms->ms_map, 0,
		    ms->ms_map->dm_mapsize, BUS_DMASYNC_POSTREAD);
		bus_dmamap_unload(sc->sc_dmat, ms->ms_map);
		m_freem(ms->ms_m);
	}

	if_rxr_init(&mrr->mrr_rxr, 2, sc->sc_rx_ring_count - 2);
}

void
myx_rx_free(struct myx_softc *sc, struct myx_rx_ring *mrr)
{
	struct myx_slot *ms;
	int i;

	for (i = 0; i < sc->sc_rx_ring_count; i++) {
		ms = &mrr->mrr_slots[i];
		bus_dmamap_destroy(sc->sc_dmat, ms->ms_map);
	}

	free(mrr->mrr_slots, M_DEVBUF, sizeof(*ms) * sc->sc_rx_ring_count);
}

struct mbuf *
myx_mcl_small(void)
{
	struct mbuf *m;

	m = MCLGETI(NULL, M_DONTWAIT, NULL, MYX_RXSMALL_SIZE);
	if (m == NULL)
		return (NULL);

	m->m_len = m->m_pkthdr.len = MYX_RXSMALL_SIZE;

	return (m);
}

struct mbuf *
myx_mcl_big(void)
{
	struct mbuf *m;
	void *mcl;

	MGETHDR(m, M_DONTWAIT, MT_DATA);
	if (m == NULL)
		return (NULL);

	mcl = pool_get(myx_mcl_pool, PR_NOWAIT);
	if (mcl == NULL) {
		m_free(m);
		return (NULL);
	}

	MEXTADD(m, mcl, MYX_RXBIG_SIZE, M_EXTWR, MEXTFREE_POOL, myx_mcl_pool);
	m->m_len = m->m_pkthdr.len = MYX_RXBIG_SIZE;

	return (m);
}

int
myx_buf_fill(struct myx_softc *sc, struct myx_slot *ms,
    struct mbuf *(*mclget)(void))
{
	struct mbuf *m;
	int rv;

	m = (*mclget)();
	if (m == NULL)
		return (ENOMEM);

	rv = bus_dmamap_load_mbuf(sc->sc_dmat, ms->ms_map, m, BUS_DMA_NOWAIT);
	if (rv != 0) {
		m_freem(m);
		return (rv);
	}

	bus_dmamap_sync(sc->sc_dmat, ms->ms_map, 0,
	    ms->ms_map->dm_mapsize, BUS_DMASYNC_PREREAD);

	ms->ms_m = m;

	return (0);
}

int
myx_tx_init(struct myx_softc *sc, bus_size_t size)
{
	struct myx_slot *ms;
	int rv;
	int i;

	sc->sc_tx_slots = mallocarray(sizeof(*ms), sc->sc_tx_ring_count,
	    M_DEVBUF, M_WAITOK);
	if (sc->sc_tx_slots == NULL)
		return (ENOMEM);

	for (i = 0; i < sc->sc_tx_ring_count; i++) {
		ms = &sc->sc_tx_slots[i];
		rv = bus_dmamap_create(sc->sc_dmat, size, sc->sc_tx_nsegs,
		    sc->sc_tx_boundary, sc->sc_tx_boundary,
		    BUS_DMA_WAITOK | BUS_DMA_ALLOCNOW, &ms->ms_map);
		if (rv != 0)
			goto destroy;
	}

	sc->sc_tx_prod = sc->sc_tx_cons = 0;

	return (0);

destroy:
	while (i-- > 0) {
		ms = &sc->sc_tx_slots[i];
		bus_dmamap_destroy(sc->sc_dmat, ms->ms_map);
	}
	free(sc->sc_tx_slots, M_DEVBUF, sizeof(*ms) * sc->sc_tx_ring_count);
	return (rv);
}

void
myx_tx_empty(struct myx_softc *sc)
{
	struct myx_slot *ms;
	u_int cons = sc->sc_tx_cons;
	u_int prod = sc->sc_tx_prod;

	while (cons != prod) {
		ms = &sc->sc_tx_slots[cons];
		
		bus_dmamap_sync(sc->sc_dmat, ms->ms_map, 0,
		    ms->ms_map->dm_mapsize, BUS_DMASYNC_POSTWRITE);
		bus_dmamap_unload(sc->sc_dmat, ms->ms_map);
		m_freem(ms->ms_m);

		if (++cons >= sc->sc_tx_ring_count)
			cons = 0;
	}

	sc->sc_tx_cons = cons;
}

void
myx_tx_free(struct myx_softc *sc)
{
	struct myx_slot *ms;
	int i;

	for (i = 0; i < sc->sc_tx_ring_count; i++) {
		ms = &sc->sc_tx_slots[i];
		bus_dmamap_destroy(sc->sc_dmat, ms->ms_map);
	}

	free(sc->sc_tx_slots, M_DEVBUF, sizeof(*ms) * sc->sc_tx_ring_count);
}
@


1.101
log
@add support for multiple transmit ifqueues per network interface.

an ifq to transmit a packet is picked by the current traffic
conditioner (ie, priq or hfsc) by providing an index into an array
of ifqs. by default interfaces get a single ifq but can ask for
more using if_attach_queues().

the vast majority of our drivers still think there's a 1:1 mapping
between interfaces and transmit queues, so their if_start routines
take an ifnet pointer instead of a pointer to the ifqueue struct.
instead of changing all the drivers in the tree, drivers can opt
into using an if_qstart routine and setting the IFXF_MPSAFE flag.
the stack provides a compatability wrapper from the new if_qstart
handler to the previous if_start handlers if IFXF_MPSAFE isnt set.

enabling hfsc on an interface configures it to transmit everything
through the first ifq. any other ifqs are left configured as priq,
but unused, when hfsc is enabled.

getting this in now so everyone can kick the tyres.

ok mpi@@ visa@@ (who provided some tweaks for cnmac).
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.100 2017/01/22 10:17:38 dlg Exp $	*/
a296 2
		extern struct kmem_pa_mode kp_dma_contig;

d304 3
a306 3
		pool_init(myx_mcl_pool, MYX_RXBIG_SIZE, MYX_BOUNDARY, IPL_NET,
		    0, "myxmcl", NULL);
		pool_set_constraints(myx_mcl_pool, &kp_dma_contig);
@


1.100
log
@move counting if_opackets next to counting if_obytes in if_enqueue.

this means packets are consistently counted in one place, unlike the
many and various ways that drivers thought they should do it.

ok mpi@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.99 2016/10/31 01:38:57 dlg Exp $	*/
d204 1
a204 1
void	 myx_start(struct ifnet *);
d513 1
a513 1
	ifp->if_start = myx_start;
d1203 1
a1203 1
	ifq_clr_oactive(&ifp->if_snd);
d1205 1
a1205 2
	myx_iff(sc);
	if_start(ifp);
d1424 1
a1424 1
myx_start(struct ifnet *ifp)
d1426 1
d1451 1
a1451 1
			ifq_set_oactive(&ifp->if_snd);
d1455 1
a1455 1
		IFQ_DEQUEUE(&ifp->if_snd, m);
@


1.99
log
@turns out these chips can handle buffers up to 9400 bytes in length.

raise the mtu to 9380 bytes so we can take advantage of the extra space.

i need to revisit the macro names at some point.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.98 2016/10/31 01:23:46 dlg Exp $	*/
a1687 2

		ifp->if_opackets++;
@


1.98
log
@revert 1.97 where i moved myx to using the system pools

my early revision board doesnt like it at all
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.96 2016/09/15 02:00:17 dlg Exp $	*/
d162 2
a163 1
#define MYX_RXBIG_SIZE		(9 * 1024)
d515 1
a515 1
	ifp->if_hardmtu = 9000;
@


1.97
log
@get rid of the custom pool in myx for jumbo frames.

now it asks the mbuf layer for the 9k from its pools.

a question from chris@@ made me go look at the chip doco again and i
realised that the chip only requires 4 byte alignment for rx buffers,
no 4k alignment for jumbo buffers.

i also found that the chip is supposed to be able to rx up to 9400
bytes instead of 9000. ill fix that later though.
@
text
@d32 1
d82 2
d98 1
a98 1
	u_int			 mrr_size;
d213 3
a215 1
			    u_int);
d259 1
a259 1
	sc->sc_rx_ring[MYX_RXSMALL].mrr_size = MYX_RXSMALL_SIZE;
d263 1
a263 1
	sc->sc_rx_ring[MYX_RXBIG].mrr_size = MYX_RXBIG_SIZE;
d294 16
d1775 1
a1775 1
	if (myx_buf_fill(sc, &mrr->mrr_slots[first], mrr->mrr_size) != 0)
d1784 1
a1784 1
		if (myx_buf_fill(sc, ms, mrr->mrr_size) != 0)
d1903 36
d1940 2
a1941 1
myx_buf_fill(struct myx_softc *sc, struct myx_slot *ms, u_int size)
d1946 1
a1946 2

	m = MCLGETI(NULL, M_DONTWAIT, NULL, size);
a1948 2

	m->m_pkthdr.len = m->m_len = size;
@


1.96
log
@all pools have their ipl set via pool_setipl, so fold it into pool_init.

the ioff argument to pool_init() is unused and has been for many
years, so this replaces it with an ipl argument. because the ipl
will be set on init we no longer need pool_setipl.

most of these changes have been done with coccinelle using the spatch
below. cocci sucks at formatting code though, so i fixed that by hand.

the manpage and subr_pool.c bits i did myself.

ok tedu@@ jmatthew@@

@@ipl@@
expression pp;
expression ipl;
expression s, a, o, f, m, p;
@@@@
-pool_init(pp, s, a, o, f, m, p);
-pool_setipl(pp, ipl);
+pool_init(pp, s, a, ipl, f, m, p);
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.95 2016/05/23 15:22:44 tedu Exp $	*/
a31 1
#include <sys/pool.h>
a80 2
struct pool *myx_mcl_pool;

d95 1
a95 1
	struct mbuf		*(*mrr_mclget)(void);
d210 1
a210 3
			    struct mbuf *(*)(void));
struct mbuf *		myx_mcl_small(void);
struct mbuf *		myx_mcl_big(void);
d254 1
a254 1
	sc->sc_rx_ring[MYX_RXSMALL].mrr_mclget = myx_mcl_small;
d258 1
a258 1
	sc->sc_rx_ring[MYX_RXBIG].mrr_mclget = myx_mcl_big;
a288 16
	/* this is sort of racy */
	if (myx_mcl_pool == NULL) {
		extern struct kmem_pa_mode kp_dma_contig;

		myx_mcl_pool = malloc(sizeof(*myx_mcl_pool), M_DEVBUF,
		    M_WAITOK);
		if (myx_mcl_pool == NULL) {
			printf("%s: unable to allocate mcl pool\n",
			    DEVNAME(sc));
			goto unmap;
		}
		pool_init(myx_mcl_pool, MYX_RXBIG_SIZE, MYX_BOUNDARY, IPL_NET,
		    0, "myxmcl", NULL);
		pool_set_constraints(myx_mcl_pool, &kp_dma_contig);
	}

d1754 1
a1754 1
	if (myx_buf_fill(sc, &mrr->mrr_slots[first], mrr->mrr_mclget) != 0)
d1763 1
a1763 1
		if (myx_buf_fill(sc, ms, mrr->mrr_mclget) != 0)
a1881 36
struct mbuf *
myx_mcl_small(void)
{
	struct mbuf *m;

	m = MCLGETI(NULL, M_DONTWAIT, NULL, MYX_RXSMALL_SIZE);
	if (m == NULL)
		return (NULL);

	m->m_len = m->m_pkthdr.len = MYX_RXSMALL_SIZE;

	return (m);
}

struct mbuf *
myx_mcl_big(void)
{
	struct mbuf *m;
	void *mcl;

	MGETHDR(m, M_DONTWAIT, MT_DATA);
	if (m == NULL)
		return (NULL);

	mcl = pool_get(myx_mcl_pool, PR_NOWAIT);
	if (mcl == NULL) {
		m_free(m);
		return (NULL);
	}

	MEXTADD(m, mcl, MYX_RXBIG_SIZE, M_EXTWR, MEXTFREE_POOL, myx_mcl_pool);
	m->m_len = m->m_pkthdr.len = MYX_RXBIG_SIZE;

	return (m);
}

d1883 1
a1883 2
myx_buf_fill(struct myx_softc *sc, struct myx_slot *ms,
    struct mbuf *(*mclget)(void))
d1888 2
a1889 1
	m = (*mclget)();
d1892 2
@


1.95
log
@remove the function pointer from mbufs. this memory is shared with data
via unions, and we don't want to make it easy to control the target.
instead an integer index into an array of acceptable functions is used.
drivers using custom functions must register them to receive an index.
ok deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.94 2016/04/13 11:36:00 mpi Exp $	*/
d305 1
a305 1
		pool_init(myx_mcl_pool, MYX_RXBIG_SIZE, MYX_BOUNDARY, 0,
a306 1
		pool_setipl(myx_mcl_pool, IPL_NET);
@


1.94
log
@G/C IFQ_SET_READY().
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.93 2016/04/13 10:34:32 mpi Exp $	*/
d1934 1
a1934 1
	MEXTADD(m, mcl, MYX_RXBIG_SIZE, M_EXTWR, m_extfree_pool, myx_mcl_pool);
@


1.93
log
@G/C IFQ_SET_READY().
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.92 2015/12/11 16:07:02 mpi Exp $	*/
a1037 1
	IFQ_SET_READY(&ifp->if_snd);
@


1.92
log
@Replace mountroothook_establish(9) by config_mountroot(9) a narrower API
similar to config_defer(9).

ok mikeb@@, deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.91 2015/12/09 03:22:39 dlg Exp $	*/
a517 1
	IFQ_SET_READY(&ifp->if_snd);
@


1.91
log
@rework the if_start mpsafe serialisation so it can serialise arbitrary work

work is represented by struct task.

the start routine is now wrapped by a task which is serialised by the
infrastructure. if_start_barrier has been renamed to ifq_barrier and
is now implemented as a task that gets serialised with the start
routine.

this also adds an ifq_restart() function. it serialises a call to
ifq_clr_oactive and calls the start routine again. it exists to
avoid a race that kettenis@@ identified in between when a start
routine discovers theres no space left on a ring, and when it calls
ifq_set_oactive. if the txeof side of the driver empties the ring
and calls ifq_clr_oactive in between the above calls in start, the
queue will be marked oactive and the stack will never call the start
routine again.

by serialising the ifq_set_oactive call in the start routine and
ifq_clr_oactive calls we avoid that race.

tested on various nics
ok mpi@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.90 2015/12/03 12:45:56 dlg Exp $	*/
d169 1
a169 1
void	 myx_attachhook(void *);
d314 1
a314 4
	if (mountroothook_establish(myx_attachhook, sc) == NULL) {
		printf("%s: unable to establish mountroot hook\n", DEVNAME(sc));
		goto unmap;
	}
d468 1
a468 1
myx_attachhook(void *arg)
d470 1
a470 1
	struct myx_softc	*sc = (struct myx_softc *)arg;
@


1.90
log
@tell the stack myx_start is mpsafe.

as per the stack commit, the driver changes are:

1. setting ifp->if_xflags = IFXF_MPSAFE
2. only calling if_start() instead of its own start routine
3. clearing IFF_RUNNING before calling if_start_barrier() on its way down
4. only using IFQ_DEQUEUE (not ifq_deq_begin/commit/rollback)
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.89 2015/12/01 12:37:12 dlg Exp $	*/
d1211 1
a1211 1
	myx_start(ifp);
d1333 2
d1367 1
a1367 2
	CLR(ifp->if_flags, IFF_RUNNING);
	if_start_barrier(ifp);
d1706 2
a1707 3
	ifq_clr_oactive(&ifp->if_snd);
	if (!ifq_empty(&ifp->if_snd))
		if_start(ifp);
@


1.89
log
@myx doesnt use atomic.h anymore.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.88 2015/11/25 03:09:59 dlg Exp $	*/
d514 1
d1364 1
d1366 1
a1366 1
	ifq_clr_oactive(&ifp->if_snd);
a1440 5
	if (!ISSET(ifp->if_flags, IFF_RUNNING) ||
	    ifq_is_oactive(&ifp->if_snd) ||
	    IFQ_IS_EMPTY(&ifp->if_snd))
		return;

a1587 1
	struct ifnet		*ifp = &sc->sc_ac.ac_if;
d1591 1
a1591 1
	u_int32_t		 data, start;
a1636 2
	start = ifq_is_oactive(&ifp->if_snd);

a1642 1
			start = 0;
a1655 7
	if (start) {
		KERNEL_LOCK();
		ifq_clr_oactive(&ifp->if_snd);
		myx_start(ifp);
		KERNEL_UNLOCK();
	}

d1704 4
@


1.88
log
@replace IFF_OACTIVE manipulation with mpsafe operations.

there are two things shared between the network stack and drivers
in the send path: the send queue and the IFF_OACTIVE flag. the send
queue is now protected by a mutex. this diff makes the oactive
functionality mpsafe too.

IFF_OACTIVE is part of if_flags. there are two problems with that.
firstly, if_flags is a short and we dont have any MI atomic operations
to manipulate a short. secondly, while we could make the IFF_OACTIVE
operates mpsafe, all changes to other flags would have to be made
safe at the same time, otherwise a read-modify-write cycle on their
updates could clobber the oactive change.

instead, this moves the oactive mark into struct ifqueue and provides
an API for changing it. there's ifq_set_oactive, ifq_clr_oactive,
and ifq_is_oactive. these are modelled on ifsq_set_oactive,
ifsq_clr_oactive, and ifsq_is_oactive in dragonflybsd.

this diff includes changes to all the drivers manipulating IFF_OACTIVE
to now use the ifsq_{set,clr_is}_oactive API too.

ok kettenis@@ mpi@@ jmatthew@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.87 2015/11/24 10:04:34 dlg Exp $	*/
a36 1
#include <sys/atomic.h>
a1866 17
}

static inline int
myx_rx_ring_enter(struct myx_rx_ring *mrr)
{
	return (atomic_inc_int_nv(&mrr->mrr_running) == 1);
}

static inline int
myx_rx_ring_leave(struct myx_rx_ring *mrr)
{
	if (atomic_cas_uint(&mrr->mrr_running, 1, 0) == 1)
		return (1);

	mrr->mrr_running = 1;

	return (0);
@


1.87
log
@fix tx ring accounting in myx_start.

turns out i was calculating the number of packets (not descriptors)
on the tx ring, and then using that as the free space for descriptors.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.86 2015/11/19 12:46:08 dlg Exp $	*/
d1208 1
a1208 1
	CLR(ifp->if_flags, IFF_OACTIVE);
d1364 2
a1365 1
	CLR(ifp->if_flags, IFF_RUNNING | IFF_OACTIVE);
d1441 1
a1441 1
	    ISSET(ifp->if_flags, IFF_OACTIVE) ||
d1459 1
a1459 1
			SET(ifp->if_flags, IFF_OACTIVE);
d1642 1
a1642 1
	start = ISSET(ifp->if_flags, IFF_OACTIVE);
d1666 1
a1666 1
		CLR(ifp->if_flags, IFF_OACTIVE);
@


1.86
log
@get rid of sc_tx_free and the atomic ops on it in myx_start and myx_txeof.

myx_start calculates the free space by reading the consumer index
and doing some maths, which lets us avoid the interlocked cpu ops.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.85 2015/10/25 13:04:28 mpi Exp $	*/
d149 2
a150 1
	u_int			 sc_tx_ring_idx;
d1036 2
a1037 1
	sc->sc_tx_ring_idx = 0;
d1444 1
a1444 2
	prod = sc->sc_tx_prod;
	cons = sc->sc_tx_cons;
d1447 2
a1448 2
	free = prod;
	if (cons >= prod)
d1450 1
a1450 1
	free -= cons;
d1452 1
a1452 2
	/* keep track of our usage */
	cons = prod;
d1481 1
a1481 1
		    map->dm_mapsize, BUS_DMASYNC_POSTWRITE);
a1492 1
	idx = sc->sc_tx_ring_idx;
d1539 1
a1539 1
	myx_write_txd_tail(sc, ms, flags, offset, sc->sc_tx_ring_idx);
d1542 1
a1542 1
	    offset + sizeof(txd) * sc->sc_tx_ring_idx, &txd,
d1549 2
a1550 1
	    offset + sizeof(txd) * (sc->sc_tx_ring_idx + 1) - sizeof(myx_bus_t),
d1555 1
a1555 1
	    offset + sizeof(txd) * sc->sc_tx_ring_idx, sizeof(txd),
d1559 1
a1559 1
	sc->sc_tx_ring_idx = idx;
d1691 1
a1691 2
	u_int free = 0;
	u_int cons;
d1693 1
d1700 1
a1700 1
		free += map->dm_nsegs + (map->dm_mapsize < 60 ? 1 : 0);
d1713 4
@


1.85
log
@arp_ifinit() is no longer needed.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.84 2015/09/29 10:52:22 dlg Exp $	*/
a150 1
	u_int			 sc_tx_free;
a1036 1
	sc->sc_tx_free = sc->sc_tx_ring_count - 1;
d1442 12
a1453 2
	cons = prod = sc->sc_tx_prod;
	free = sc->sc_tx_free;
d1457 1
a1457 1
		if (used + sc->sc_tx_nsegs > free) {
a1491 2
	atomic_sub_int(&sc->sc_tx_free, used);

a1713 1
	atomic_add_int(&sc->sc_tx_free, free);
@


1.84
log
@get rid of the mutex between access to the status block and myx_down

myx is unusual in that it has an explicit command to shut down the
chip that gets an interrupt when it's done. so myx_down sends the
command and has to sleep until it gets that interrupt. this moves
to using a single int to represent that state (so loads and stores
are atomic), and sleep_setup/sleep_finish in myx_down to wait for
it to change.

this has been running in production at work for a few months now
tested by chris@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.83 2015/09/01 06:08:57 deraadt Exp $	*/
a921 1
	struct ifaddr		*ifa = (struct ifaddr *)data;
a929 2
		if (ifa->ifa_addr->sa_family == AF_INET)
			arp_ifinit(&sc->sc_ac, ifa);
@


1.83
log
@free() firmware with right len; ok dlg
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.82 2015/08/15 01:17:01 dlg Exp $	*/
d35 1
a126 1
	struct mutex		 sc_sts_mtx;
a228 20
static inline void
myx_sts_enter(struct myx_softc *sc)
{
	bus_dmamap_t		 map = sc->sc_sts_dma.mxm_map;

	mtx_enter(&sc->sc_sts_mtx);
	bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
	    BUS_DMASYNC_POSTREAD|BUS_DMASYNC_POSTWRITE);
}

static inline void
myx_sts_leave(struct myx_softc *sc)
{
	bus_dmamap_t		 map = sc->sc_sts_dma.mxm_map;

	bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
	    BUS_DMASYNC_PREREAD|BUS_DMASYNC_PREWRITE);
	mtx_leave(&sc->sc_sts_mtx);
}

a267 2
	mtx_init(&sc->sc_sts_mtx, IPL_NET);

d870 1
d879 2
a880 1
	myx_sts_enter(sc);
d882 2
a883 1
	myx_sts_leave(sc);
a1203 1
	mtx_enter(&sc->sc_sts_mtx);
a1204 1
	mtx_leave(&sc->sc_sts_mtx);
d1331 1
d1336 2
a1337 1
	myx_sts_enter(sc);
d1339 3
d1343 1
d1348 5
a1352 7
	bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
	    BUS_DMASYNC_PREREAD|BUS_DMASYNC_PREWRITE);
	while (sc->sc_state != MYX_S_OFF)
		msleep(sts, &sc->sc_sts_mtx, 0, "myxdown", 0);
	bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
	    BUS_DMASYNC_POSTREAD|BUS_DMASYNC_POSTWRITE);
	mtx_leave(&sc->sc_sts_mtx);
d1590 1
a1590 1
	enum myx_state		 state = MYX_S_RUNNING;
d1592 1
a1592 1
	u_int32_t		 data, link = 0xffffffff;
d1595 2
a1596 3
	mtx_enter(&sc->sc_sts_mtx);
	if (sc->sc_state == MYX_S_OFF) {
		mtx_leave(&sc->sc_sts_mtx);
a1597 1
	}
d1604 2
a1605 1
		myx_sts_leave(sc);
a1623 9
	if (sts->ms_statusupdated) {
		link = sts->ms_linkstate;

		if (sc->sc_state == MYX_S_DOWN &&
		    sc->sc_linkdown != sts->ms_linkdown)
			state = MYX_S_DOWN;
	}
	myx_sts_leave(sc);

d1638 1
a1638 6
	if (state == MYX_S_DOWN) {
		/* myx_down is waiting for us */
		mtx_enter(&sc->sc_sts_mtx);
		sc->sc_state = MYX_S_OFF;
		wakeup(sts);
		mtx_leave(&sc->sc_sts_mtx);
d1640 15
a1654 1
		return (1);
d1657 2
a1658 5
	if (link != 0xffffffff) {
		KERNEL_LOCK();
		myx_link_state(sc, link);
		KERNEL_UNLOCK();
	}
d1660 1
a1660 1
	if (ISSET(ifp->if_flags, IFF_OACTIVE)) {
@


1.82
log
@do the global tx free accounting in myx_start with a single atomic op
instead of one per packet.

seems to let me send packets a little faster.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.81 2015/08/15 00:49:15 dlg Exp $	*/
d489 1
a489 1
	free(fw, M_DEVBUF, 0);
@


1.81
log
@rework the tx path to use a ring to keep track of dmamaps/mbufs.

this removes the myx_buf structure and uses myx_slot instead. theyre
the same expcet slots dont have list entry structures, so theyre
smaller.

this cuts out four mutex ops per packet out of the tx handling.
just have to get rid of the atomic op per packet in myx_start now.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.80 2015/08/14 10:42:25 dlg Exp $	*/
d1456 1
d1465 2
d1469 1
a1469 1
		if (sc->sc_tx_free <= sc->sc_tx_nsegs) {
d1495 1
a1495 2
		atomic_sub_int(&sc->sc_tx_free, map->dm_nsegs +
		    (map->dm_mapsize < 60 ? 1 : 0));
d1503 2
@


1.80
log
@move to a per rx ring timeout for refilling empty rings.

this lets me get rid of the locking around the refilling of the rx ring.

the timeout only runs refill if the rx ring is empty. we know rxeof
wont try and refill it in that situation because there's no packets
on the ring so we wont get interrupts for it. therefore we dont
need to lock between the timeout and rxeof cos they cant run at the
same time.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.79 2015/08/14 07:24:18 dlg Exp $	*/
a81 12
struct myx_buf {
	SIMPLEQ_ENTRY(myx_buf)	 mb_entry;
	bus_dmamap_t		 mb_map;
	struct mbuf		*mb_m;
};

struct myx_buf_list {
	SIMPLEQ_HEAD(, myx_buf)	mbl_q;
	struct mutex		mbl_mtx;
};

struct pool *myx_buf_pool;
d84 3
a86 3
struct myx_rx_slot {
	bus_dmamap_t		 mrs_map;
	struct mbuf		*mrs_m;
d93 1
a93 1
	struct myx_rx_slot	*mrr_slots;
d149 2
d152 3
a154 3
	struct myx_buf_list	 sc_tx_buf_free;
	struct myx_buf_list	 sc_tx_buf_list;
	u_int			 sc_tx_ring_idx;
d205 1
a205 1
void	 myx_write_txd_tail(struct myx_softc *, struct myx_buf *, u_int8_t,
d207 1
a207 1
int	 myx_load_buf(struct myx_softc *, struct myx_buf *, struct mbuf *);
d213 1
a213 8
struct myx_buf *	myx_buf_alloc(struct myx_softc *, bus_size_t, int,
			    bus_size_t, bus_size_t);
void			myx_buf_free(struct myx_softc *, struct myx_buf *);
void			myx_bufs_init(struct myx_buf_list *);
int			myx_bufs_empty(struct myx_buf_list *);
struct myx_buf *	myx_buf_get(struct myx_buf_list *);
void			myx_buf_put(struct myx_buf_list *, struct myx_buf *);
int			myx_buf_fill(struct myx_softc *, struct myx_rx_slot *,
d223 4
a287 3
	myx_bufs_init(&sc->sc_tx_buf_free);
	myx_bufs_init(&sc->sc_tx_buf_list);

d318 1
a318 1
	if (myx_buf_pool == NULL) {
a320 11
		myx_buf_pool = malloc(sizeof(*myx_buf_pool), M_DEVBUF,
		    M_WAITOK);
		if (myx_buf_pool == NULL) {
			printf("%s: unable to allocate buf pool\n",
			    DEVNAME(sc));
			goto unmap;
		}
		pool_init(myx_buf_pool, sizeof(struct myx_buf),
		    0, 0, 0, "myxbufs", &pool_allocator_nointr);
		pool_setipl(myx_buf_pool, IPL_NONE);

a1009 1
	struct myx_buf		*mb;
a1014 1
	int			i;
d1194 2
a1195 8
	for (i = 0; i < sc->sc_tx_ring_count; i++) {
		mb = myx_buf_alloc(sc, maxpkt, sc->sc_tx_nsegs,
		    sc->sc_tx_boundary, sc->sc_tx_boundary);
		if (mb == NULL)
			goto free_tx_bufs;

		myx_buf_put(&sc->sc_tx_buf_free, mb);
	}
d1198 1
a1198 1
		goto free_tx_bufs;
d1247 2
a1248 3
free_tx_bufs:
	while ((mb = myx_buf_get(&sc->sc_tx_buf_free)) != NULL)
		myx_buf_free(sc, mb);
a1351 1
	struct myx_buf		*mb;
d1394 2
a1395 10
	while ((mb = myx_buf_get(&sc->sc_tx_buf_list)) != NULL) {
		bus_dmamap_sync(sc->sc_dmat, mb->mb_map, 0,
		    mb->mb_map->dm_mapsize, BUS_DMASYNC_POSTWRITE);
		bus_dmamap_unload(sc->sc_dmat, mb->mb_map);
		m_freem(mb->mb_m);
		myx_buf_free(sc, mb);
	}

	while ((mb = myx_buf_get(&sc->sc_tx_buf_free)) != NULL)
		myx_buf_free(sc, mb);
d1414 1
a1414 1
myx_write_txd_tail(struct myx_softc *sc, struct myx_buf *mb, u_int8_t flags,
d1419 1
a1419 1
	bus_dmamap_t			map = mb->mb_map;
a1449 1
	SIMPLEQ_HEAD(, myx_buf)		list = SIMPLEQ_HEAD_INITIALIZER(list);
d1451 1
a1452 1
	struct myx_buf			*mb, *firstmb;
d1455 1
a1455 1
	u_int				idx, firstidx;
d1463 2
d1466 1
a1466 2
		if (sc->sc_tx_free <= sc->sc_tx_nsegs ||
		    (mb = myx_buf_get(&sc->sc_tx_buf_free)) == NULL) {
d1472 1
a1472 2
		if (m == NULL) {
			myx_buf_put(&sc->sc_tx_buf_free, mb);
a1473 1
		}
d1475 3
a1477 1
		if (myx_load_buf(sc, mb, m) != 0) {
a1478 1
			myx_buf_put(&sc->sc_tx_buf_free, mb);
d1488 1
a1488 3
		mb->mb_m = m;

		map = mb->mb_map;
a1491 2
		SIMPLEQ_INSERT_TAIL(&list, mb, mb_entry);

d1494 3
d1499 1
a1499 3
	/* post the first descriptor last */
	firstmb = SIMPLEQ_FIRST(&list);
	if (firstmb == NULL)
a1500 12
	
	SIMPLEQ_REMOVE_HEAD(&list, mb_entry);
	myx_buf_put(&sc->sc_tx_buf_list, firstmb);

	idx = firstidx = sc->sc_tx_ring_idx;
	idx += firstmb->mb_map->dm_nsegs +
	    (firstmb->mb_map->dm_mapsize < 60 ? 1 : 0);
	idx %= sc->sc_tx_ring_count;

	while ((mb = SIMPLEQ_FIRST(&list)) != NULL) {
		SIMPLEQ_REMOVE_HEAD(&list, mb_entry);
		myx_buf_put(&sc->sc_tx_buf_list, mb);
d1502 17
a1518 1
		map = mb->mb_map;
d1532 1
a1532 4
		myx_write_txd_tail(sc, mb, flags, offset, idx);

		idx += map->dm_nsegs + (map->dm_mapsize < 60 ? 1 : 0);
		idx %= sc->sc_tx_ring_count;
a1533 1
	sc->sc_tx_ring_idx = idx;
d1535 3
a1537 2
	/* go back and post first mb */
	map = firstmb->mb_map;
d1543 1
d1550 1
a1550 1
	myx_write_txd_tail(sc, firstmb, flags, offset, firstidx);
d1553 1
a1553 1
	    offset + sizeof(txd) * firstidx, &txd,
d1560 1
a1560 1
	    offset + sizeof(txd) * (firstidx + 1) - sizeof(myx_bus_t),
d1565 1
a1565 1
	    offset + sizeof(txd) * firstidx, sizeof(txd),
d1567 4
d1574 1
a1574 1
myx_load_buf(struct myx_softc *sc, struct myx_buf *mb, struct mbuf *m)
d1577 1
a1577 1
	bus_dmamap_t			dmap = mb->mb_map;
d1593 1
a1593 1
	mb->mb_m = m;
d1703 1
a1703 2
	struct myx_buf *mb;
	struct mbuf *m;
d1706 3
d1711 2
a1712 8
		mb = myx_buf_get(&sc->sc_tx_buf_list);
		if (mb == NULL) {
			printf("oh noes, no mb!\n");
			break;
		}

		m = mb->mb_m;
		map = mb->mb_map;
d1718 2
a1720 1
		bus_dmamap_unload(sc->sc_dmat, map);
d1723 2
a1724 2
		m_freem(m);
		myx_buf_put(&sc->sc_tx_buf_free, mb);
d1727 2
a1728 2
	if (free)
		atomic_add_int(&sc->sc_tx_free, free);
d1738 1
a1738 1
	struct myx_rx_slot *mrs;
d1757 1
a1757 1
		mrs = &mrr->mrr_slots[mrr->mrr_cons];
d1762 3
a1764 3
		bus_dmamap_sync(sc->sc_dmat, mrs->mrs_map, 0,
		    mrs->mrs_map->dm_mapsize, BUS_DMASYNC_POSTREAD);
		bus_dmamap_unload(sc->sc_dmat, mrs->mrs_map);
d1766 1
a1766 1
		m = mrs->mrs_m;
d1797 1
a1797 1
	struct myx_rx_slot *mrs;
d1809 1
a1809 1
		mrs = &mrr->mrr_slots[p];
d1811 1
a1811 1
		if (myx_buf_fill(sc, mrs, mrr->mrr_mclget) != 0)
d1814 1
a1814 1
		rxd.rx_addr = htobe64(mrs->mrs_map->dm_segs[0].ds_addr);
d1831 2
a1832 2
	mrs = &mrr->mrr_slots[first];
	rxd.rx_addr = htobe64(mrs->mrs_map->dm_segs[0].ds_addr);
d1844 1
a1844 1
	struct myx_rx_slot *mrs;
d1849 1
a1849 1
	mrr->mrr_slots = mallocarray(sizeof(*mrs), sc->sc_rx_ring_count,
d1856 1
a1856 1
		mrs = &mrr->mrr_slots[i];
d1858 1
a1858 1
		    BUS_DMA_WAITOK | BUS_DMA_ALLOCNOW, &mrs->mrs_map);
d1873 2
a1874 2
		mrs = &mrr->mrr_slots[i];
		bus_dmamap_destroy(sc->sc_dmat, mrs->mrs_map);
d1876 1
a1876 1
	free(mrr->mrr_slots, M_DEVBUF, sizeof(*mrs) * sc->sc_rx_ring_count);
d1916 1
a1916 1
	struct myx_rx_slot *mrs;
d1919 1
a1919 1
		mrs = &mrr->mrr_slots[mrr->mrr_cons];
d1924 4
a1927 4
		bus_dmamap_sync(sc->sc_dmat, mrs->mrs_map, 0,
		    mrs->mrs_map->dm_mapsize, BUS_DMASYNC_POSTREAD);
		bus_dmamap_unload(sc->sc_dmat, mrs->mrs_map);
		m_freem(mrs->mrs_m);
d1936 1
a1936 1
	struct myx_rx_slot *mrs;
d1940 2
a1941 2
		mrs = &mrr->mrr_slots[i];
		bus_dmamap_destroy(sc->sc_dmat, mrs->mrs_map);
d1944 1
a1944 1
	free(mrr->mrr_slots, M_DEVBUF, sizeof(*mrs) * sc->sc_rx_ring_count);
d1984 1
a1984 1
myx_buf_fill(struct myx_softc *sc, struct myx_rx_slot *mrs,
d1994 1
a1994 1
	rv = bus_dmamap_load_mbuf(sc->sc_dmat, mrs->mrs_map, m, BUS_DMA_NOWAIT);
d2000 2
a2001 2
	bus_dmamap_sync(sc->sc_dmat, mrs->mrs_map, 0,
	    mrs->mrs_map->dm_mapsize, BUS_DMASYNC_PREREAD);
d2003 1
a2003 1
	mrs->mrs_m = m;
d2008 2
a2009 3
struct myx_buf *
myx_buf_alloc(struct myx_softc *sc, bus_size_t size, int nsegs,
    bus_size_t maxsegsz, bus_size_t boundary)
d2011 3
a2013 1
	struct myx_buf *mb;
d2015 4
a2018 3
	mb = pool_get(myx_buf_pool, PR_WAITOK);
	if (mb == NULL)
		return (NULL);
d2020 7
a2026 4
	if (bus_dmamap_create(sc->sc_dmat, size, nsegs, maxsegsz, boundary,
	    BUS_DMA_WAITOK | BUS_DMA_ALLOCNOW, &mb->mb_map) != 0) {
		pool_put(myx_buf_pool, mb);
		return (NULL);
d2029 11
a2039 1
	return (mb);
d2043 1
a2043 1
myx_buf_free(struct myx_softc *sc, struct myx_buf *mb)
d2045 3
a2047 3
	bus_dmamap_destroy(sc->sc_dmat, mb->mb_map);
	pool_put(myx_buf_pool, mb);
}
d2049 7
a2055 4
struct myx_buf *
myx_buf_get(struct myx_buf_list *mbl)
{
	struct myx_buf *mb;
d2057 3
a2059 5
	mtx_enter(&mbl->mbl_mtx);
	mb = SIMPLEQ_FIRST(&mbl->mbl_q);
	if (mb != NULL)
		SIMPLEQ_REMOVE_HEAD(&mbl->mbl_q, mb_entry);
	mtx_leave(&mbl->mbl_mtx);
d2061 1
a2061 1
	return (mb);
d2064 2
a2065 2
int
myx_bufs_empty(struct myx_buf_list *mbl)
d2067 2
a2068 1
	int rv;
d2070 4
a2073 3
	mtx_enter(&mbl->mbl_mtx);
	rv = SIMPLEQ_EMPTY(&mbl->mbl_q);
	mtx_leave(&mbl->mbl_mtx);
d2075 1
a2075 16
	return (rv);
}

void
myx_buf_put(struct myx_buf_list *mbl, struct myx_buf *mb)
{
	mtx_enter(&mbl->mbl_mtx);
	SIMPLEQ_INSERT_TAIL(&mbl->mbl_q, mb, mb_entry);
	mtx_leave(&mbl->mbl_mtx);
}

void
myx_bufs_init(struct myx_buf_list *mbl)
{
	SIMPLEQ_INIT(&mbl->mbl_q);
	mtx_init(&mbl->mbl_mtx, IPL_NET);
@


1.79
log
@rework how we track the packets on the rx rings.

originally there were two mutex protected lists for rx packets, a
list of free packets, and a list of packets that were on the ring.
filling the ring popped packets off the free list, attached an mbuf
and dmamapped it, and pushed it onto the list of active packets.
the hw fills packets in order, so on rx completion we'd pop packets
the active list, unmap the mbuf and shove it up the stack before
putting the packet on the free list.

the problem with the lists is that every rx ring operation resulted
in two mutex ops. so 4 mutex ops per packet after you do both fill
and rxeof.

this replaces the mutexed lists with rings that shadow the hardware
rings. filling the rx ring pushes a producer index along, while
rxeof chases it with a consumer. because we know only one thing can
do either of those tasks at a time, we can get away with not using
atomic ops for them.

there's more to be done, but this is a good first step.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.78 2015/06/24 09:40:54 mpi Exp $	*/
a95 3
struct myx_ring_lock {
};

d102 2
a103 1
	struct mutex		 mrr_rxr_mtx;
d105 1
d110 1
a110 1
	struct myx_rx_slot	*mrr_slots;
a154 1
	struct timeout		 sc_refill;
d230 2
a231 2
int			myx_buf_fill(struct myx_softc *, int,
			    struct myx_rx_slot *);
d236 3
a238 3
int			myx_rx_fill(struct myx_softc *, int);
void			myx_rx_empty(struct myx_softc *, int);
void			myx_rx_free(struct myx_softc *, int);
d292 8
a299 2
	mtx_init(&sc->sc_rx_ring[MYX_RXSMALL].mrr_rxr_mtx, IPL_NET);
	mtx_init(&sc->sc_rx_ring[MYX_RXBIG].mrr_rxr_mtx, IPL_NET);
a303 2
	timeout_set(&sc->sc_refill, myx_refill, sc);

a1024 1
	mtx_enter(&sc->sc_rx_ring[MYX_RXSMALL].mrr_rxr_mtx);
a1025 1
	mtx_leave(&sc->sc_rx_ring[MYX_RXSMALL].mrr_rxr_mtx);
a1027 1
	mtx_enter(&sc->sc_rx_ring[MYX_RXBIG].mrr_rxr_mtx);
a1028 1
	mtx_leave(&sc->sc_rx_ring[MYX_RXBIG].mrr_rxr_mtx);
d1235 1
a1235 1
	if (myx_rx_fill(sc, MYX_RXSMALL) != 0)
d1241 1
a1241 1
	if (myx_rx_fill(sc, MYX_RXBIG) != 0)
d1275 1
a1275 1
	myx_rx_empty(sc, MYX_RXBIG);
d1277 1
a1277 1
	myx_rx_free(sc, MYX_RXBIG);
d1279 1
a1279 1
	myx_rx_empty(sc, MYX_RXSMALL);
d1281 1
a1281 1
	myx_rx_free(sc, MYX_RXSMALL);
a1407 2
	timeout_del(&sc->sc_refill);

d1424 5
a1428 2
		myx_rx_empty(sc, ring);
		myx_rx_free(sc, ring);
d1731 1
a1731 1
myx_refill(void *xsc)
d1733 2
a1734 3
	struct myx_softc *sc = xsc;
	struct myx_rx_ring *mrr;
	int ring;
d1736 1
a1736 2
	for (ring = 0; ring < 2; ring++) {
		mrr = &sc->sc_rx_ring[ring];
d1738 2
a1739 4
		if (myx_rx_fill(sc, ring) >= 0 &&
		    mrr->mrr_prod == mrr->mrr_cons)
			timeout_add(&sc->sc_refill, 1);
	}
a1829 1
		mtx_enter(&mrr->mrr_rxr_mtx);
d1831 3
a1833 5
		mtx_leave(&mrr->mrr_rxr_mtx);

		if (myx_rx_fill(sc, ring) >= 0 &&
		    mrr->mrr_prod == mrr->mrr_cons)
			timeout_add(&sc->sc_refill, 0);
d1840 1
a1840 1
myx_rx_fill_slots(struct myx_softc *sc, int ring, u_int slots)
a1842 1
	struct myx_rx_ring *mrr = &sc->sc_rx_ring[ring];
d1848 1
a1848 1
	if (myx_buf_fill(sc, ring, &mrr->mrr_slots[first]) != 0)
d1857 1
a1857 1
		if (myx_buf_fill(sc, ring, mrs) != 0)
d1944 1
a1944 1
myx_rx_fill(struct myx_softc *sc, int ring)
a1945 1
	struct myx_rx_ring *mrr = &sc->sc_rx_ring[ring];
a1946 1
	int rv = 1;
d1948 3
a1950 2
	if (!myx_rx_ring_enter(mrr))
		return (-1);
d1952 3
a1954 5
	do {
		mtx_enter(&sc->sc_rx_ring[ring].mrr_rxr_mtx);
		slots = if_rxr_get(&sc->sc_rx_ring[ring].mrr_rxr,
		    sc->sc_rx_ring_count);
		mtx_leave(&sc->sc_rx_ring[ring].mrr_rxr_mtx);
d1956 1
a1956 14
		if (slots == 0)
			continue;

		slots = myx_rx_fill_slots(sc, ring, slots);
		rv = 0;

		if (slots > 0) {
			mtx_enter(&sc->sc_rx_ring[ring].mrr_rxr_mtx);
			if_rxr_put(&sc->sc_rx_ring[ring].mrr_rxr, slots);
			mtx_leave(&sc->sc_rx_ring[ring].mrr_rxr_mtx);
		}
	} while (!myx_rx_ring_leave(mrr));

	return (rv);
d1960 1
a1960 1
myx_rx_empty(struct myx_softc *sc, int ring)
a1961 1
	struct myx_rx_ring *mrr = &sc->sc_rx_ring[ring];
d1980 1
a1980 1
myx_rx_free(struct myx_softc *sc, int ring)
a1981 1
	struct myx_rx_ring *mrr = &sc->sc_rx_ring[ring];
d2030 2
a2031 1
myx_buf_fill(struct myx_softc *sc, int ring, struct myx_rx_slot *mrs)
a2032 1
	struct mbuf *(*mclget[2])(void) = { myx_mcl_small, myx_mcl_big };
d2036 1
a2036 1
	m = (*mclget[ring])();
@


1.78
log
@Increment if_ipackets in if_input().

Note that pseudo-drivers not using if_input() are not affected by this
conversion.

ok mikeb@@, kettenis@@, claudio@@, dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.77 2015/05/17 02:33:09 chris Exp $	*/
d97 15
a111 2
	struct mutex		mrl_mtx;
	u_int			mrl_running;
a152 6
	struct myx_ring_lock	 sc_rx_ring_lock[2];
	u_int32_t		 sc_rx_ring_offset[2];
	struct myx_buf_list	 sc_rx_buf_free[2];
	struct myx_buf_list	 sc_rx_buf_list[2];
	u_int			 sc_rx_ring_idx[2];
	struct if_rxring	 sc_rx_ring[2];
d155 1
a159 1
	struct myx_ring_lock	 sc_tx_ring_lock;
d190 1
a190 1
#define myx_bus_space_write bus_space_write_raw_region_8
d193 1
a193 1
#define myx_bus_space_write bus_space_write_raw_region_4
d196 2
d232 2
a233 1
struct myx_buf *	myx_buf_fill(struct myx_softc *, int);
d237 1
a237 1
void			myx_rx_zero(struct myx_softc *, int);
d239 3
a243 4
void			myx_ring_lock_init(struct myx_ring_lock *);
int			myx_ring_enter(struct myx_ring_lock *);
int			myx_ring_leave(struct myx_ring_lock *);

d294 2
a295 6
	myx_ring_lock_init(&sc->sc_rx_ring_lock[MYX_RXSMALL]);
	myx_bufs_init(&sc->sc_rx_buf_free[MYX_RXSMALL]);
	myx_bufs_init(&sc->sc_rx_buf_list[MYX_RXSMALL]);
	myx_ring_lock_init(&sc->sc_rx_ring_lock[MYX_RXBIG]);
	myx_bufs_init(&sc->sc_rx_buf_free[MYX_RXBIG]);
	myx_bufs_init(&sc->sc_rx_buf_list[MYX_RXBIG]);
a296 1
	myx_ring_lock_init(&sc->sc_tx_ring_lock);
a303 1

d1023 3
a1025 3
	mtx_enter(&sc->sc_rx_ring_lock[0].mrl_mtx);
	ifr[0].ifr_info = sc->sc_rx_ring[0];
	mtx_leave(&sc->sc_rx_ring_lock[0].mrl_mtx);
d1028 3
a1030 3
	mtx_enter(&sc->sc_rx_ring_lock[1].mrl_mtx);
	ifr[1].ifr_info = sc->sc_rx_ring[1];
	mtx_leave(&sc->sc_rx_ring_lock[1].mrl_mtx);
d1183 1
a1183 1
	    &sc->sc_rx_ring_offset[MYX_RXSMALL]) != 0) {
d1190 1
a1190 1
	    &sc->sc_rx_ring_offset[MYX_RXBIG]) != 0) {
d1234 2
a1235 15
	for (i = 0; i < sc->sc_rx_ring_count; i++) {
		mb = myx_buf_alloc(sc, MYX_RXSMALL_SIZE, 1, 4096, 4096);
		if (mb == NULL)
			goto free_rxsmall_bufs;

		myx_buf_put(&sc->sc_rx_buf_free[MYX_RXSMALL], mb);
	}

	for (i = 0; i < sc->sc_rx_ring_count; i++) {
		mb = myx_buf_alloc(sc, 12 * 1024, 1, 12 * 1024, 0);
		if (mb == NULL)
			goto free_rxbig_bufs;

		myx_buf_put(&sc->sc_rx_buf_free[MYX_RXBIG], mb);
	}
d1237 2
a1238 2
	if_rxr_init(&sc->sc_rx_ring[MYX_RXBIG], 2, sc->sc_rx_ring_count - 2);
	if_rxr_init(&sc->sc_rx_ring[MYX_RXSMALL], 2, sc->sc_rx_ring_count - 2);
d1240 2
a1241 5
	myx_rx_zero(sc, MYX_RXSMALL);
	if (myx_rx_fill(sc, MYX_RXSMALL) != 0) {
		printf("%s: failed to fill small rx ring\n", DEVNAME(sc));
		goto free_rxbig_bufs;
	}
d1243 2
a1244 5
	myx_rx_zero(sc, MYX_RXBIG);
	if (myx_rx_fill(sc, MYX_RXBIG) != 0) {
		printf("%s: failed to fill big rx ring\n", DEVNAME(sc));
		goto free_rxsmall;
	}
d1250 1
a1250 1
		goto free_rxbig;
d1257 1
a1257 1
		goto free_rxbig;
d1266 1
a1266 1
		goto free_rxbig;
d1276 8
a1283 22
free_rxbig:
	while ((mb = myx_buf_get(&sc->sc_rx_buf_list[MYX_RXBIG])) != NULL) {
		bus_dmamap_sync(sc->sc_dmat, mb->mb_map, 0,
		    mb->mb_map->dm_mapsize, BUS_DMASYNC_POSTREAD);
		bus_dmamap_unload(sc->sc_dmat, mb->mb_map);
		m_freem(mb->mb_m);
		myx_buf_free(sc, mb);
	}
free_rxsmall:
	while ((mb = myx_buf_get(&sc->sc_rx_buf_list[MYX_RXSMALL])) != NULL) {
		bus_dmamap_sync(sc->sc_dmat, mb->mb_map, 0,
		    mb->mb_map->dm_mapsize, BUS_DMASYNC_POSTREAD);
		bus_dmamap_unload(sc->sc_dmat, mb->mb_map);
		m_freem(mb->mb_m);
		myx_buf_free(sc, mb);
	}
free_rxbig_bufs:
	while ((mb = myx_buf_get(&sc->sc_rx_buf_free[MYX_RXBIG])) != NULL)
		myx_buf_free(sc, mb);
free_rxsmall_bufs:
	while ((mb = myx_buf_get(&sc->sc_rx_buf_free[MYX_RXSMALL])) != NULL)
		myx_buf_free(sc, mb);
d1393 1
d1427 3
a1429 14
	while ((mb = myx_buf_get(&sc->sc_rx_buf_list[MYX_RXBIG])) != NULL) {
		bus_dmamap_sync(sc->sc_dmat, mb->mb_map, 0,
		    mb->mb_map->dm_mapsize, BUS_DMASYNC_POSTREAD);
		bus_dmamap_unload(sc->sc_dmat, mb->mb_map);
		m_freem(mb->mb_m);
		myx_buf_free(sc, mb);
	}

	while ((mb = myx_buf_get(&sc->sc_rx_buf_list[MYX_RXSMALL])) != NULL) {
		bus_dmamap_sync(sc->sc_dmat, mb->mb_map, 0,
		    mb->mb_map->dm_mapsize, BUS_DMASYNC_POSTREAD);
		bus_dmamap_unload(sc->sc_dmat, mb->mb_map);
		m_freem(mb->mb_m);
		myx_buf_free(sc, mb);
a1431 6
	while ((mb = myx_buf_get(&sc->sc_rx_buf_free[MYX_RXBIG])) != NULL)
		myx_buf_free(sc, mb);

	while ((mb = myx_buf_get(&sc->sc_rx_buf_free[MYX_RXSMALL])) != NULL)
		myx_buf_free(sc, mb);

d1474 1
a1474 1
		myx_bus_space_write(sc->sc_memt, sc->sc_memh,
d1486 1
a1486 1
		myx_bus_space_write(sc->sc_memt, sc->sc_memh,
d1543 2
a1544 2
		sc->sc_tx_free -= map->dm_nsegs +
		    (map->dm_mapsize < 60 ? 1 : 0);
d1575 1
a1575 1
		myx_bus_space_write(sc->sc_memt, sc->sc_memh,
d1600 1
a1600 1
	myx_bus_space_write(sc->sc_memt, sc->sc_memh,
d1607 1
a1607 1
	myx_bus_space_write(sc->sc_memt, sc->sc_memh,
d1735 5
a1739 1
	int i;
d1741 2
a1742 3
	for (i = 0; i < 2; i++) {
		if (myx_rx_fill(sc, i) >= 0 &&
		    myx_bufs_empty(&sc->sc_rx_buf_list[i]))
d1778 2
a1779 5
	if (free) {
		KERNEL_LOCK();
		sc->sc_tx_free += free;
		KERNEL_UNLOCK();
	}
d1788 2
a1789 1
	struct myx_buf *mb;
d1807 5
a1811 5
		mb = myx_buf_get(&sc->sc_rx_buf_list[ring]);
		if (mb == NULL) {
			printf("oh noes, no mb!\n");
			break;
		}
d1813 3
a1815 3
		bus_dmamap_sync(sc->sc_dmat, mb->mb_map, 0,
		    mb->mb_map->dm_mapsize, BUS_DMASYNC_POSTREAD);
		bus_dmamap_unload(sc->sc_dmat, mb->mb_map);
d1817 1
a1817 1
		m = mb->mb_m;
a1822 2
		myx_buf_put(&sc->sc_rx_buf_free[ring], mb);

d1833 5
a1837 3
		mtx_enter(&sc->sc_rx_ring_lock[ring].mrl_mtx);
		if_rxr_put(&sc->sc_rx_ring[ring], rxfree[ring]);
		mtx_leave(&sc->sc_rx_ring_lock[ring].mrl_mtx);
d1840 1
a1840 1
		    myx_bufs_empty(&sc->sc_rx_buf_list[ring]))
d1847 2
a1848 2
void
myx_rx_zero(struct myx_softc *sc, int ring)
d1851 11
a1861 2
	u_int32_t offset = sc->sc_rx_ring_offset[ring];
	int idx;
d1863 2
a1864 1
	sc->sc_rx_ring_idx[ring] = 0;
d1866 5
a1870 3
	memset(&rxd, 0xff, sizeof(rxd));
	for (idx = 0; idx < sc->sc_rx_ring_count; idx++) {
		myx_write(sc, offset + idx * sizeof(rxd),
d1872 3
d1876 16
d1894 2
a1895 2
static inline int
myx_rx_fill_slots(struct myx_softc *sc, int ring, u_int slots)
d1898 5
a1902 3
	struct myx_buf *mb, *firstmb;
	u_int32_t offset = sc->sc_rx_ring_offset[ring];
	u_int idx, firstidx;
d1904 4
a1907 3
	firstmb = myx_buf_fill(sc, ring);
	if (firstmb == NULL)
		return (slots);
d1909 7
a1915 1
	myx_buf_put(&sc->sc_rx_buf_list[ring], firstmb);
d1917 2
a1918 15
	firstidx = sc->sc_rx_ring_idx[ring];
	idx = firstidx + 1;
	idx %= sc->sc_rx_ring_count;
	slots--;

	while (slots > 0 && (mb = myx_buf_fill(sc, ring)) != NULL) {
		myx_buf_put(&sc->sc_rx_buf_list[ring], mb);

		rxd.rx_addr = htobe64(mb->mb_map->dm_segs[0].ds_addr);
		myx_bus_space_write(sc->sc_memt, sc->sc_memh,
		    offset + idx * sizeof(rxd), &rxd, sizeof(rxd));

		idx++;
		idx %= sc->sc_rx_ring_count;
		slots--;
d1921 9
a1929 5
	/* make sure the first descriptor is seen after the others */
	if (idx != firstidx + 1) {
		bus_space_barrier(sc->sc_memt, sc->sc_memh,
		    offset, sizeof(rxd) * sc->sc_rx_ring_count,
		    BUS_SPACE_BARRIER_WRITE);
d1931 9
d1941 5
a1945 3
	rxd.rx_addr = htobe64(firstmb->mb_map->dm_segs[0].ds_addr);
	myx_write(sc, offset + firstidx * sizeof(rxd),
	    &rxd, sizeof(rxd));
d1947 1
a1947 1
	sc->sc_rx_ring_idx[ring] = idx;
d1949 1
a1949 1
	return (slots);
d1955 1
d1959 1
a1959 1
	if (!myx_ring_enter(&sc->sc_rx_ring_lock[ring]))
d1963 4
a1966 3
		mtx_enter(&sc->sc_rx_ring_lock[ring].mrl_mtx);
		slots = if_rxr_get(&sc->sc_rx_ring[ring], sc->sc_rx_ring_count);
		mtx_leave(&sc->sc_rx_ring_lock[ring].mrl_mtx);
d1974 6
a1979 4
		mtx_enter(&sc->sc_rx_ring_lock[ring].mrl_mtx);
		if_rxr_put(&sc->sc_rx_ring[ring], slots);
		mtx_leave(&sc->sc_rx_ring_lock[ring].mrl_mtx);
	} while (!myx_ring_leave(&sc->sc_rx_ring_lock[ring]));
d1984 36
d2056 2
a2057 2
struct myx_buf *
myx_buf_fill(struct myx_softc *sc, int ring)
a2059 1
	struct myx_buf *mb;
d2065 1
a2065 1
		return (NULL);
d2067 5
a2071 3
	mb = myx_buf_get(&sc->sc_rx_buf_free[ring]);
	if (mb == NULL)
		goto mfree;
d2073 2
a2074 3
	rv = bus_dmamap_load_mbuf(sc->sc_dmat, mb->mb_map, m, BUS_DMA_NOWAIT);
	if (rv != 0)
		goto put;
d2076 1
a2076 3
	mb->mb_m = m;
	bus_dmamap_sync(sc->sc_dmat, mb->mb_map, 0, mb->mb_map->dm_mapsize,
	    BUS_DMASYNC_PREREAD);
d2078 1
a2078 8
	return (mb);

put:
	myx_buf_put(&sc->sc_rx_buf_free[ring], mb);
mfree:
	m_freem(m);

	return (NULL);
a2145 24
}

void
myx_ring_lock_init(struct myx_ring_lock *mrl)
{
	mtx_init(&mrl->mrl_mtx, IPL_NET);
	mrl->mrl_running = 0;
}

int
myx_ring_enter(struct myx_ring_lock *mrl)
{
	return (atomic_inc_int_nv(&mrl->mrl_running) == 1);
}

int
myx_ring_leave(struct myx_ring_lock *mrl)
{
	if (atomic_cas_uint(&mrl->mrl_running, 1, 0) == 1)
		return (1);

	mrl->mrl_running = 1;

	return (0);
@


1.77
log
@We don't need KERNEL_LOCK() around if_input() anymore, as if_input() has
appropriate locking around bpf now.

ok dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.76 2015/03/14 03:38:48 jsg Exp $	*/
a1887 2

	ifp->if_ipackets += ml_len(&ml);
@


1.76
log
@Remove some includes include-what-you-use claims don't
have any direct symbols used.  Tested for indirect use by compiling
amd64/i386/sparc64 kernels.

ok tedu@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.75 2015/02/20 23:24:30 chris Exp $	*/
a1890 1
	KERNEL_LOCK();
a1891 1
	KERNEL_UNLOCK();
@


1.75
log
@Now that if_input() is a thing, use it

ok dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.74 2015/02/18 23:58:34 dlg Exp $	*/
a43 1
#include <net/if_types.h>
@


1.74
log
@myri employees and their drivers for linux and solaris have repeatedly
told me that if you're going to rx into buffers greater than 4k in
size, they have to be aligned to a 4k boundary.

the mru of this chip is 9k, but ive been using the 12k mcl pool to
provide the alignment. however, if we move to putting 8 items on a
pool page there'll be enough slack space in the mcl12k pool pages
to allow item colouring, which in turn will break the chip requirement
above. in practice the chips i have seem to work fine with unaligned
buffers, but i dont want to risk breaking early revision chips.

this moves myx to using a private pool for allocating clusters for
the big rx ring. the item size is 9k, but we specify a 4k alignment
so every item we get out of it will be correct for the chip.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.73 2015/02/18 09:57:33 dlg Exp $	*/
a1864 1
		m->m_pkthdr.rcvif = ifp;
d1893 1
a1893 9
#if NBPFILTER > 0
	if (ifp->if_bpf) {
		MBUF_LIST_FOREACH(&ml, m)
			bpf_mtap(ifp->if_bpf, m, BPF_DIRECTION_IN);
	}
#endif

	while ((m = ml_dequeue(&ml)) != NULL)
		ether_input_mbuf(ifp, m);
@


1.73
log
@enable pcie relaxed transaction ordering and bump the max payload
size up to 4k.

found while reading someone elses driver.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.72 2014/12/22 02:28:52 tedu Exp $	*/
d95 1
d168 3
d225 2
d331 2
d342 13
d1020 1
a1020 1
	ifr[0].ifr_size = MCLBYTES;
d1025 1
a1025 1
	ifr[1].ifr_size = 12 * 1024;
d1233 1
a1233 1
		mb = myx_buf_alloc(sc, MCLBYTES, 1, 4096, 4096);
d1264 1
a1264 1
	mc.mc_data0 = htobe32(MCLBYTES - ETHER_ALIGN);
d1850 1
a1850 1
		ring = (len <= (MCLBYTES - ETHER_ALIGN)) ?
d1997 36
d2036 1
a2036 1
	static size_t sizes[2] = { MCLBYTES, 12 * 1024 };
d2041 1
a2041 1
	m = MCLGETI(NULL, M_DONTWAIT, NULL, sizes[ring]);
a2043 1
	m->m_len = m->m_pkthdr.len = sizes[ring];
@


1.72
log
@unifdef INET
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.71 2014/10/28 00:36:06 dlg Exp $	*/
d169 1
d336 3
d349 23
@


1.71
log
@the if_rxring accounting would get screwed up if the first mbuf to
be put on the ring couldnt be allocated.

this pulls the code that puts the mbufs on the ring out of myx_rx_fill
so it can return early if firstmb cant be allocated, which puts it
in the right place to return unused slots to the if_rxring.

this means myx rx wont lock up if you're DoSsed to the point where
you exhaust your mbuf pools and cant allocate mbufs for the ring.

ok jmatthew@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.70 2014/10/04 11:42:27 dlg Exp $	*/
a49 1
#ifdef INET
a51 1
#endif
a924 1
#ifdef INET
a926 1
#endif
@


1.70
log
@replace mutexes to serialise the operations on the flag that restricts
the number of contexts that are refilling the rx rings with atomic
ops.

this is borrowed from code i wrote for the scsi midlayer but cant
put in yet because i havent got atomic.h up to scrach on all archs
yet. the archs myx runs on do have enough atomic.h to be fine though.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.69 2014/10/03 13:41:55 dlg Exp $	*/
d1878 2
a1879 2
int
myx_rx_fill(struct myx_softc *sc, int ring)
d1884 45
a1928 1
	u_int idx, firstidx, slots;
d1939 1
a1939 5
		if (slots-- == 0)
			continue;

		firstmb = myx_buf_fill(sc, ring);
		if (firstmb == NULL)
d1942 1
a1943 28
		myx_buf_put(&sc->sc_rx_buf_list[ring], firstmb);

		firstidx = sc->sc_rx_ring_idx[ring];
		idx = firstidx + 1;
		idx %= sc->sc_rx_ring_count;

		while (slots > 0 && (mb = myx_buf_fill(sc, ring)) != NULL) {
			myx_buf_put(&sc->sc_rx_buf_list[ring], mb);

			rxd.rx_addr = htobe64(mb->mb_map->dm_segs[0].ds_addr);
			myx_bus_space_write(sc->sc_memt, sc->sc_memh,
			    offset + idx * sizeof(rxd), &rxd, sizeof(rxd));

			idx++;
			idx %= sc->sc_rx_ring_count;
			slots--;
		}

		/* make sure the first descriptor is seen after the others */
		if (idx != firstidx + 1) {
			bus_space_barrier(sc->sc_memt, sc->sc_memh,
			    offset, sizeof(rxd) * sc->sc_rx_ring_count,
			    BUS_SPACE_BARRIER_WRITE);
		}

		rxd.rx_addr = htobe64(firstmb->mb_map->dm_segs[0].ds_addr);
		myx_write(sc, offset + firstidx * sizeof(rxd),
		    &rxd, sizeof(rxd));
a1944 1
		sc->sc_rx_ring_idx[ring] = idx;
@


1.69
log
@refill the rx ring in myx_rxeof, not much later at the end of myx_intr.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.68 2014/10/03 13:10:15 dlg Exp $	*/
d36 1
d2053 1
a2053 8
	int rv = 1;

	mtx_enter(&mrl->mrl_mtx);
	if (++mrl->mrl_running > 1)
		rv = 0;
	mtx_leave(&mrl->mrl_mtx);

	return (rv);
d2059 2
a2060 1
	int rv = 1;
d2062 1
a2062 6
	mtx_enter(&mrl->mrl_mtx);
	if (--mrl->mrl_running > 0) {
		mrl->mrl_running = 1;
		rv = 0;
	}
	mtx_leave(&mrl->mrl_mtx);
d2064 1
a2064 1
	return (rv);
@


1.68
log
@in rxeof, instead of taking the biglock on every packet to call bpf
and ether_input, queue all the mbufs onto an mbuf_list on the stack
and then take the biglock once outside the loop.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.67 2014/10/03 09:52:01 dlg Exp $	*/
d210 1
a210 1
int	 myx_rxeof(struct myx_softc *);
a1651 1
	int			 refill = 0;
a1652 1
	int			 i;
d1699 1
a1699 1
		refill |= myx_rxeof(sc);
a1729 8
	for (i = 0; i < 2; i++) {
		if (ISSET(refill, 1 << i)) {
			if (myx_rx_fill(sc, i) >= 0 &&
			    myx_bufs_empty(&sc->sc_rx_buf_list[i]))
				timeout_add(&sc->sc_refill, 0);
		}
	}

d1784 1
a1784 1
int
a1792 1
	int rings = 0;
d1841 3
a1843 1
		SET(rings, 1 << ring);
a1858 2

	return (rings);
@


1.67
log
@we dont need the kernel lock to call bus_dmamap_load and unload thanks
to ketenis.

move the if_ipacket and if_opacket increments out of biglock too.
theyre only updated from the interrupt handler, which is only run
on a single cpu so there's no chance of the update racing. everywhere
else only reads them.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.66 2014/10/03 09:25:21 dlg Exp $	*/
d1799 1
d1834 1
a1834 9
		KERNEL_LOCK();
#if NBPFILTER > 0
		if (ifp->if_bpf)
			bpf_mtap(ifp->if_bpf, m, BPF_DIRECTION_IN);
#endif

		ether_input_mbuf(ifp, m);
		KERNEL_UNLOCK();
		ifp->if_ipackets++;
d1854 14
@


1.66
log
@dont need to hold the kernel lock to call MCLGETI and m_freem now.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.65 2014/10/03 06:36:10 dlg Exp $	*/
a1779 1
		KERNEL_LOCK();
a1781 1
		KERNEL_UNLOCK();
d1826 1
a1833 1
		bus_dmamap_unload(sc->sc_dmat, mb->mb_map);
d1840 1
a1841 1
		KERNEL_UNLOCK();
a1960 1
	KERNEL_LOCK();
a1961 1
	KERNEL_UNLOCK();
@


1.65
log
@dont take the kernel lock on every interrupt in case we might change
the link state or to clear OACTIVE, just take it when we know we
really are going to do those things.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.64 2014/09/14 14:17:25 jsg Exp $	*/
a1781 1
		m_freem(m);
d1785 1
a1953 1
	KERNEL_LOCK();
a1954 1
	KERNEL_UNLOCK();
a1977 1
	KERNEL_LOCK();
a1978 1
	KERNEL_UNLOCK();
@


1.64
log
@remove uneeded proc.h includes
ok mpi@@ kspillner@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.63 2014/08/19 11:13:16 dlg Exp $	*/
d1719 2
a1720 2
	KERNEL_LOCK();
	if (link != 0xffffffff)
d1722 2
d1726 1
d1729 1
a1730 1
	KERNEL_UNLOCK();
@


1.63
log
@in myx_start, replace

while (space) {
	IFQ_POLL;
	myx_dequeue(free descr);
	IFQ_DEQUEUE;
	etc;
}

with

while (space && myx_dequeue(free descr)) {
	IFQ_DEQUEUE;
	etc;
}
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.62 2014/08/18 05:11:03 dlg Exp $	*/
a33 1
#include <sys/proc.h>
@


1.62
log
@dont rely on mbuf.h to provide pool.h.

ok miod@@, who has offerred to help with any MD fallout
ok guenther@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.61 2014/07/12 18:48:51 tedu Exp $	*/
d1514 2
a1515 1
		if (sc->sc_tx_free <= sc->sc_tx_nsegs) {
d1520 3
a1522 7
		IFQ_POLL(&ifp->if_snd, m);
		if (m == NULL)
			break;

		mb = myx_buf_get(&sc->sc_tx_buf_free);
		if (mb == NULL) {
			SET(ifp->if_flags, IFF_OACTIVE);
a1525 1
		IFQ_DEQUEUE(&ifp->if_snd, m);
d1530 1
a1530 1
			break;
@


1.61
log
@add a size argument to free. will be used soon, but for now default to 0.
after discussions with beck deraadt kettenis.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.60 2014/07/10 07:02:50 dlg Exp $	*/
d32 1
@


1.60
log
@rings that dont rx packets dont need to be refilled.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.59 2014/07/08 05:35:18 dlg Exp $	*/
d465 1
a465 1
	free(fw, M_DEVBUF);
@


1.59
log
@cut things that relied on mclgeti for rx ring accounting/restriction over
to using if_rxr.

cut the reporting systat did over to the rxr ioctl.

tested as much as i can on alpha, amd64, and sparc64.
mpi@@ has run it on macppc.
ok mpi@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.57 2014/03/24 01:00:58 dlg Exp $	*/
d1855 3
@


1.58
log
@whitespace fix.

im sick of fixing this by hand on all my boxes while hacking on
other stuff and having it pollute my diffs.

no functional change.
@
text
@d146 1
d199 1
d949 4
d968 20
a1036 3
	m_clsetwms(ifp, MCLBYTES, 2, sc->sc_rx_ring_count - 2);
	m_clsetwms(ifp, 12 * 1024, 2, sc->sc_rx_ring_count - 2);

d1203 3
d1806 1
d1848 1
a1848 1
		SET(rings, 1 << ring);
d1854 8
d1887 1
a1887 1
	u_int idx, firstidx;
d1894 7
d1912 1
a1912 1
		while ((mb = myx_buf_fill(sc, ring)) != NULL) {
d1921 1
d1936 3
d1953 1
a1953 1
	m = MCLGETI(NULL, M_DONTWAIT, &sc->sc_ac.ac_if, sizes[ring]);
@


1.57
log
@nothing after the irq ack posting relies on it being ordered.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.56 2014/02/10 05:21:41 dlg Exp $	*/
d233 3
a235 3
        mtx_enter(&sc->sc_sts_mtx);
        bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
            BUS_DMASYNC_POSTREAD|BUS_DMASYNC_POSTWRITE);
d243 3
a245 3
        bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
            BUS_DMASYNC_PREREAD|BUS_DMASYNC_PREWRITE);
        mtx_leave(&sc->sc_sts_mtx);
@


1.56
log
@the mac addresses you program with MYXCMD_SET_MCASTGROUP are in a different
format to the one used for MYXCMD_SET_LLADDR. for reasons.

this lets ospf work if you dont happen to have PROMISC enabled on your
interface like my production firewalls happen to have, which is why i
never noticed this before.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.55 2014/02/05 08:17:30 dlg Exp $	*/
a1685 2
	bus_space_barrier(sc->sc_memt, sc->sc_memh,
	    sc->sc_irqclaimoff, sizeof(data) * 2, BUS_SPACE_BARRIER_WRITE);
@


1.55
log
@after running myx(4) without biglock in production for a few days
i discovered that there's a race between the interrupt code and
myx_start which causes the count of free tx descriptors to get
distorted, which eventually leads to a permanent setting of
IFF_OACTIVE, which in turn prevents the driver from transmitting
packets.

fixing that went horribly wrong when i then discovered that there's
a race between the interrupt handler and myx_down, where the interrupt
can tell myx_down to wake up and free all the rings while the
interrupt handler is still looking at them. free panics for all.

this moves the handling of the tx free count under the biglock (for
now), and moves myx_up and myx_down to managing a "driver state"
variable independantly of the IFF_UP and IFF_RUNNING flags, and
very very careful reordering of the checks of that state variable
and the hardware state.

as a bonus we get to avoid excessive calls to myx_txeof and myx_rxeof
in the isr, and less stuff checked unconditionally. on the other
hand, the sc_state handling added some more checks so it might not
be a win overall.

tested on smp sparc64 with msi and nonmsi interrupts, and on amd64 smp
in production again.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.54 2014/01/31 00:52:20 dlg Exp $	*/
d1277 2
a1278 1
	mc.mc_data0 = htobe32(addr[0] << 24 | addr[1] << 16 | addr[2] << 8 | addr[3]);
d1295 1
d1315 2
a1316 1
	if (ISSET(ifp->if_flags, IFF_PROMISC) || sc->sc_ac.ac_multirangecnt > 0) {
d1323 7
a1329 2
		if (myx_setlladdr(sc, MYXCMD_SET_MCASTGROUP,
		    enm->enm_addrlo) != 0) {
@


1.54
log
@sc_function is set, but never used for anything useful. clean it up...
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.53 2014/01/31 00:50:45 dlg Exp $	*/
d102 6
d163 1
d1206 4
a1216 1

d1218 1
d1340 1
d1347 2
a1348 2
	sc->sc_linkdown = sc->sc_sts->ms_linkdown;
	myx_sts_leave(sc);
d1353 6
a1358 11
	myx_sts_enter(sc);
	/* we play with the guts of sc_sts by hand here */
	while (sc->sc_linkdown == sc->sc_sts->ms_linkdown) {
		bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
		    BUS_DMASYNC_PREREAD|BUS_DMASYNC_PREWRITE);

		msleep(sc->sc_sts, &sc->sc_sts_mtx, 0, "myxdown", 0);

		bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
		    BUS_DMASYNC_POSTREAD|BUS_DMASYNC_POSTWRITE);
	}
a1363 2
	CLR(ifp->if_flags, IFF_RUNNING);

d1619 3
a1621 1
	u_int32_t		 data, link;
a1623 1
	u_int			 if_flags;
d1626 3
a1628 2
	if_flags = ifp->if_flags;
	if (!ISSET(if_flags, IFF_RUNNING))
d1630 4
a1634 1
	myx_sts_enter(sc);
a1639 1
	sts->ms_isvalid = 0;
d1646 1
a1646 8

	if (!ISSET(if_flags, IFF_UP) &&
	    sc->sc_linkdown != sts->ms_linkdown) {
		/* myx_down is waiting for us */
		wakeup_one(sc->sc_sts);
	}

	link = sts->ms_statusupdated ? sts->ms_linkstate : 0xffffffff;
d1649 1
a1649 2
		data = betoh32(sts->ms_txdonecnt);
		myx_sts_leave(sc);
d1651 4
a1654 2
		if (data != sc->sc_tx_count)
			myx_txeof(sc, data);
d1656 2
a1657 1
		refill |= myx_rxeof(sc);
d1659 4
a1662 2
		myx_sts_enter(sc);
	} while (sts->ms_isvalid);
d1665 3
a1667 5
	if (link != 0xffffffff) {
		KERNEL_LOCK();
		myx_link_state(sc, link);
		KERNEL_UNLOCK();
	}
d1671 2
d1681 15
a1695 2
	if (ISSET(if_flags, IFF_OACTIVE)) {
		KERNEL_LOCK();
a1697 1
		KERNEL_UNLOCK();
d1699 1
d1732 1
d1744 1
a1744 3
		sc->sc_tx_free += map->dm_nsegs;
		if (map->dm_mapsize < 60)
			sc->sc_tx_free += 1;
d1757 6
@


1.53
log
@sc_lladdr is never used, so we can get the space in the sc back.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.52 2014/01/23 01:54:02 dlg Exp $	*/
a108 1
	u_int			 sc_function;
a269 1
	sc->sc_function = pa->pa_function;
@


1.52
log
@a lot of people have pointed out to me that taking a lock just to read an
int isnt necessary.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.51 2014/01/23 01:51:53 dlg Exp $	*/
a155 1
	u_int8_t		 sc_lladdr[ETHER_ADDR_LEN];
@


1.51
log
@factor the mutex/bus_space handling of the sts block out.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.50 2014/01/21 23:26:50 dlg Exp $	*/
a1622 1
	KERNEL_LOCK();	
a1623 2
	KERNEL_UNLOCK();

@


1.50
log
@introduce fine grained locking.

this doesnt give up the big lock coming from process context, only from
the interrupt side. it is excessively careful about when it takes
the big lock again. notably it goes to a lot of effort to not hold
a mutex while calling into other subsystems or before taking the
big lock.

ive been hitting it as hard as i can without problems.

intensly read by mpi@@
ok claudio@@ kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.49 2014/01/19 21:43:36 dlg Exp $	*/
d223 20
a861 1
	bus_dmamap_t		 map = sc->sc_sts_dma.mxm_map;
d870 1
a870 3
	mtx_enter(&sc->sc_sts_mtx);
	bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
	    BUS_DMASYNC_POSTREAD);
d872 1
a872 3
	bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
	    BUS_DMASYNC_PREREAD);
	mtx_leave(&sc->sc_sts_mtx);
d1337 1
a1337 3
	mtx_enter(&sc->sc_sts_mtx);
	bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
	    BUS_DMASYNC_POSTREAD);
d1339 1
a1339 3
	bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
	    BUS_DMASYNC_PREREAD);
	mtx_leave(&sc->sc_sts_mtx);
d1344 2
a1345 3
	mtx_enter(&sc->sc_sts_mtx);
	bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
	    BUS_DMASYNC_POSTREAD);
d1348 1
a1348 1
		    BUS_DMASYNC_PREREAD);
d1353 1
a1353 1
		    BUS_DMASYNC_POSTREAD);
a1616 1
	bus_dmamap_t		 map = sc->sc_sts_dma.mxm_map;
d1630 1
a1630 4
	mtx_enter(&sc->sc_sts_mtx);
	bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
	    BUS_DMASYNC_POSTREAD);

d1633 1
a1633 3
		bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
		    BUS_DMASYNC_PREREAD);
		mtx_leave(&sc->sc_sts_mtx);
d1654 1
a1654 3
		bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
		    BUS_DMASYNC_PREREAD);
		mtx_leave(&sc->sc_sts_mtx);
d1661 1
a1661 3
		mtx_enter(&sc->sc_sts_mtx);
		bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
		    BUS_DMASYNC_POSTREAD);
d1663 1
a1663 4

	bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
	    BUS_DMASYNC_PREREAD);
	mtx_leave(&sc->sc_sts_mtx);
@


1.49
log
@white space fix
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.48 2014/01/19 09:04:37 dlg Exp $	*/
d97 5
d122 1
d136 1
d147 1
d190 1
a190 1
void	 myx_link_state(struct myx_softc *);
d219 4
d254 1
d257 1
d261 1
d267 3
d478 2
a479 2
	sc->sc_irqh = pci_intr_establish(sc->sc_pc, sc->sc_ih, IPL_NET,
	    myx_intr, sc, DEVNAME(sc));
d842 2
d851 9
a859 1
	myx_link_state(sc);
d871 1
a871 1
myx_link_state(struct myx_softc *sc)
d876 1
a876 1
	if (betoh32(sc->sc_sts->ms_linkstate) == MYXSTS_LINKUP)
d1322 1
a1322 1
	s = splnet();
d1328 1
d1333 1
d1340 1
a1340 1
		tsleep(sc->sc_sts, 0, "myxdown", 0);
d1345 1
d1349 1
d1608 1
a1608 1
	u_int32_t		 data;
d1611 1
d1614 5
a1618 1
	if (!ISSET(ifp->if_flags, IFF_RUNNING))
d1621 1
d1629 1
d1640 1
a1640 1
	if (!ISSET(ifp->if_flags, IFF_UP) &&
d1646 1
a1646 2
	if (sts->ms_statusupdated)
		myx_link_state(sc);
d1652 1
d1659 1
d1666 7
d1684 2
a1685 1
	if (ISSET(ifp->if_flags, IFF_OACTIVE)) {
d1688 1
d1693 2
a1694 2
			myx_rx_fill(sc, i);
			if (myx_bufs_empty(&sc->sc_rx_buf_list[i]))
a1706 1
	int s;
a1707 1
	s = splnet();
d1709 2
a1710 2
		myx_rx_fill(sc, i);
		if (myx_bufs_empty(&sc->sc_rx_buf_list[i]))
a1712 1
	splx(s);
d1739 2
d1743 2
a1746 2

		ifp->if_opackets++;
a1780 1
		bus_dmamap_unload(sc->sc_dmat, mb->mb_map);
d1787 2
d1795 2
a1800 1
		ifp->if_ipackets++;
d1832 1
d1834 2
a1835 3
	firstmb = myx_buf_fill(sc, ring);
	if (firstmb == NULL)
		return (1);
d1837 4
a1840 1
	myx_buf_put(&sc->sc_rx_buf_list[ring], firstmb);
d1842 2
a1843 3
	firstidx = sc->sc_rx_ring_idx[ring];
	idx = firstidx + 1;
	idx %= sc->sc_rx_ring_count;
d1845 3
a1847 2
	while ((mb = myx_buf_fill(sc, ring)) != NULL) {
		myx_buf_put(&sc->sc_rx_buf_list[ring], mb);
d1849 6
a1854 3
		rxd.rx_addr = htobe64(mb->mb_map->dm_segs[0].ds_addr);
		myx_bus_space_write(sc->sc_memt, sc->sc_memh,
		    offset + idx * sizeof(rxd), &rxd, sizeof(rxd));
d1856 3
a1858 3
		idx++;
		idx %= sc->sc_rx_ring_count;
	}
d1860 6
a1865 6
	/* make sure the first descriptor is seen after the others */
	if (idx != firstidx + 1) {
		bus_space_barrier(sc->sc_memt, sc->sc_memh,
		    offset, sizeof(rxd) * sc->sc_rx_ring_count,
		    BUS_SPACE_BARRIER_WRITE);
	}
d1867 3
a1869 3
	rxd.rx_addr = htobe64(firstmb->mb_map->dm_segs[0].ds_addr);
	myx_write(sc, offset + firstidx * sizeof(rxd),
	    &rxd, sizeof(rxd));
d1871 2
a1872 1
	sc->sc_rx_ring_idx[ring] = idx;
d1874 1
a1874 1
	return (0);
d1883 1
d1885 1
d1887 1
d1896 4
a1899 2
	if (bus_dmamap_load_mbuf(sc->sc_dmat, mb->mb_map, m,
	    BUS_DMA_NOWAIT) != 0)
d1911 1
d1913 1
d1983 35
@


1.48
log
@introduce fine grained locking around the lists of packet handlers
myx maintains. this moves it away from relying on splnet to protect
them.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.46 2014/01/19 03:08:56 dlg Exp $	*/
d514 1
a514 1
                        /*
@


1.47
log
@hwflags is never used, so clean it up
@
text
@d89 6
a94 1
SIMPLEQ_HEAD(myx_buf_list, myx_buf);
d201 2
d242 4
a245 4
	SIMPLEQ_INIT(&sc->sc_rx_buf_free[MYX_RXSMALL]);
	SIMPLEQ_INIT(&sc->sc_rx_buf_list[MYX_RXSMALL]);
	SIMPLEQ_INIT(&sc->sc_rx_buf_free[MYX_RXBIG]);
	SIMPLEQ_INIT(&sc->sc_rx_buf_list[MYX_RXBIG]);
d247 2
a248 2
	SIMPLEQ_INIT(&sc->sc_tx_buf_free);
	SIMPLEQ_INIT(&sc->sc_tx_buf_list);
d1420 1
a1420 1
	struct myx_buf_list		list = SIMPLEQ_HEAD_INITIALIZER(list);
d1469 1
a1469 1
		myx_buf_put(&list, mb);
d1476 1
a1476 1
	firstmb = myx_buf_get(&list);
d1479 2
d1488 2
a1489 1
	while ((mb = myx_buf_get(&list)) != NULL) {
d1645 1
a1645 1
			if (SIMPLEQ_EMPTY(&sc->sc_rx_buf_list[i]))
d1663 1
a1663 1
		if (SIMPLEQ_EMPTY(&sc->sc_rx_buf_list[i]))
d1885 13
a1897 3
	mb = SIMPLEQ_FIRST(mbl);
	if (mb == NULL)
		return (NULL);
d1899 3
a1901 1
	SIMPLEQ_REMOVE_HEAD(mbl, mb_entry);
d1903 1
a1903 1
	return (mb);
d1909 10
a1918 1
	SIMPLEQ_INSERT_TAIL(mbl, mb, mb_entry);
@


1.46
log
@replace bcmp with memcmp
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.45 2014/01/19 03:05:46 dlg Exp $	*/
a145 2
	u_int			 sc_hwflags;
#define  MYXFLAG_FLOW_CONTROL	 (1<<0)		/* Rx/Tx pause is enabled */
@


1.45
log
@bcopy to memcpy
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.44 2014/01/19 03:03:50 dlg Exp $	*/
d348 1
a348 1
		if (maxlen > 4 && bcmp("MAC=", &strings[i], 4) == 0) {
d352 1
a352 1
		} else if (maxlen > 3 && bcmp("PC=", &strings[i], 3) == 0) {
d398 1
a398 1
	    bcmp(MYXFW_VER, hdr.fw_version, strlen(MYXFW_VER)) != 0) {
@


1.44
log
@replace bzero with memset.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.43 2014/01/19 02:55:43 dlg Exp $	*/
d384 1
a384 1
	bcopy(fw + MYX_HEADER_POS, &offset, sizeof(offset));
d391 1
a391 1
	bcopy(fw + offset, &hdr, sizeof(hdr));
@


1.43
log
@all 64bit archs myx runs on support bus_space 8 things because of work i
did at n2k13.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.42 2013/01/29 07:17:45 brad Exp $	*/
d256 1
a256 1
	bzero(part, sizeof(part));
d305 1
a305 1
	bzero(lladdr, ETHER_ADDR_LEN);
d441 1
a441 1
	bzero(&mc, sizeof(mc));
d524 1
a524 1
	bzero(&mc, sizeof(mc));
d533 1
a533 1
	bzero(&mc, sizeof(mc));
d542 1
a542 1
	bzero(&mc, sizeof(mc));
d721 1
a721 1
	bzero(&bc, sizeof(bc));
d922 1
a922 1
	bzero(&mc, sizeof(mc));
d934 1
a934 1
	bzero(sc->sc_zerodma.mxm_kva, 64);
d962 1
a962 1
	bzero(&mc, sizeof(mc));
d987 1
a987 1
	bzero(sc->sc_intrq, size);
d991 1
a991 1
	bzero(&mc, sizeof(mc));
d998 1
a998 1
	bzero(&mc, sizeof(mc));
d1010 1
a1010 1
	bzero(&mc, sizeof(mc));
d1017 1
a1017 1
	bzero(&mc, sizeof(mc));
d1024 1
a1024 1
	bzero(&mc, sizeof(mc));
d1040 1
a1040 1
	bzero(&mc, sizeof(mc));
d1046 1
a1046 1
	bzero(&mc, sizeof(mc));
d1052 1
a1052 1
	bzero(&mc, sizeof(mc));
d1059 1
a1059 1
	bzero(&mc, sizeof(mc));
d1066 1
a1066 1
	bzero(&mc, sizeof(mc));
d1085 1
a1085 1
	bzero(&mc, sizeof(mc));
d1096 1
a1096 1
	bzero(&mc, sizeof(mc));
d1140 1
a1140 1
	bzero(&mc, sizeof(mc));
d1147 1
a1147 1
	bzero(&mc, sizeof(mc));
d1205 1
a1205 1
	bzero(&mc, sizeof(mc));
d1220 1
a1220 1
	bzero(&mc, sizeof(mc));
d1273 1
a1273 1
	bzero(&mc, sizeof(mc));
d1296 1
a1296 1
	bzero(&mc, sizeof(mc));
d1322 1
a1322 1
	bzero(&mc, sizeof(mc));
d1388 1
a1388 1
		bzero(&txd, sizeof(txd));
d1400 1
a1400 1
		bzero(&txd, sizeof(txd));
d1490 1
a1490 1
		bzero(&txd, sizeof(txd));
@


1.42
log
@- Set ENETRESET within myx_ioctl() instead of calling myx_iff() directly, to be
  consistent with other drivers.
- Clear IFF_ALLMULTI flag early and at the top of myx_iff().
- Set IFF_ALLMULTI when in promisc mode.

ok dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.41 2013/01/25 02:56:41 dlg Exp $	*/
d162 1
a162 1
#if 0 && defined(__LP64__)
@


1.41
log
@we go to a lot of effort to post the first tx descriptor last, but we
really should be trying to post everything except the flags field in the
first tx descriptor. this shuffles things around so the rest of that first
txd is posted as part of the "everything else" before its flags field.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.39 2013/01/21 00:41:42 dlg Exp $	*/
d881 1
a881 1
				myx_iff(sc);
d1239 2
a1246 2
	CLR(ifp->if_flags, IFF_ALLMULTI);

d1257 1
a1257 1
	if (sc->sc_ac.ac_multirangecnt > 0) {
@


1.40
log
@the myx_dmamem struct doesnt need a name.
@
text
@d164 1
d167 1
a186 2
void	 myx_write_txd_head(struct myx_softc *, struct myx_buf *, u_int8_t,
	    u_int32_t, u_int);
a1378 16
myx_write_txd_head(struct myx_softc *sc, struct myx_buf *mb, u_int8_t flags,
    u_int32_t offset, u_int idx)
{
	struct myx_tx_desc		txd;
	bus_dmamap_t			map = mb->mb_map;

	bzero(&txd, sizeof(txd));
	txd.tx_addr = htobe64(map->dm_segs[0].ds_addr);
	txd.tx_length = htobe16(map->dm_segs[0].ds_len);
	txd.tx_nsegs = map->dm_nsegs + (map->dm_mapsize < 60 ? 1 : 0);
	txd.tx_flags = flags | MYXTXD_FLAGS_FIRST;

	myx_bus_space_write(sc->sc_memt, sc->sc_memh,
	    offset + sizeof(txd) * idx, &txd, sizeof(txd));
}
void
d1414 1
d1490 8
a1497 1
		myx_write_txd_head(sc, mb, flags, offset, idx);
d1506 2
d1509 1
a1509 1
	if (firstmb->mb_map->dm_mapsize < 1520)
d1512 6
d1520 11
a1530 6
	/* make sure the first descriptor is seen after the others */
	if (idx != firstidx + 1) {
		bus_space_barrier(sc->sc_memt, sc->sc_memh, offset,
		    sizeof(struct myx_tx_desc) * sc->sc_tx_ring_count,
		    BUS_SPACE_BARRIER_WRITE);
	}
a1531 1
	myx_write_txd_head(sc, firstmb, flags, offset, firstidx);
d1533 2
a1534 2
	    offset + sizeof(struct myx_tx_desc) * firstidx,
	    sizeof(struct myx_tx_desc), BUS_SPACE_BARRIER_WRITE);
@


1.39
log
@myx does reads and writes in one direction to packet buffers. lets try
STREAMING them.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.38 2013/01/15 03:48:20 dlg Exp $	*/
a81 1
	const char		*mxm_name;
d173 1
a173 1
	    bus_size_t, u_int align, const char *);
d429 1
a429 1
	    MYXALIGN_CMD, "cmd") != 0) {
d517 1
a517 1
	if (myx_dmamem_alloc(sc, &test, 4096, 4096, "test") != 0)
d591 1
a591 1
    bus_size_t size, u_int align, const char *mname)
a609 2
	mxm->mxm_name = mname;

d929 1
a929 1
	    64, MYXALIGN_CMD, "zero") != 0) {
d939 1
a939 1
	    MYXALIGN_CMD, MYXALIGN_CMD, "pad") != 0) {
d982 1
a982 1
	    size, MYXALIGN_DATA, "intrq") != 0) {
d1075 1
a1075 1
	    sizeof(struct myx_status), MYXALIGN_DATA, "status") != 0) {
@


1.38
log
@dont use amd64 is currently broken cos it has no
bus_space_write_raw_region_8. disabling it for now.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.37 2013/01/15 00:22:32 dlg Exp $	*/
d1542 2
a1543 1
	switch (bus_dmamap_load_mbuf(dmat, dmap, m, BUS_DMA_NOWAIT)) {
d1549 2
a1550 1
		    bus_dmamap_load_mbuf(dmat, dmap, m, BUS_DMA_NOWAIT) == 0)
@


1.37
log
@use bus_space_write_raw_region_8 on 64bit archs when writing to the rings
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.36 2013/01/14 23:58:34 dlg Exp $	*/
d163 1
a163 1
#if defined(__LP64__)
@


1.36
log
@map the registers PREFETCHABLE so things that can do write combining can
try and do write combining like the myx doco likes.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.34 2013/01/14 06:00:48 dlg Exp $	*/
d163 6
d1394 1
a1394 1
	bus_space_write_raw_region_4(sc->sc_memt, sc->sc_memh,
d1412 1
a1412 1
		bus_space_write_raw_region_4(sc->sc_memt, sc->sc_memh,
d1424 1
a1424 1
		bus_space_write_raw_region_4(sc->sc_memt, sc->sc_memh,
d1786 1
a1786 1
		bus_space_write_raw_region_4(sc->sc_memt, sc->sc_memh,
@


1.35
log
@avoid extra bus_space barriers in the interrupt handler.
@
text
@d244 2
a245 2
	if (pci_mapreg_map(pa, MYXBAR0, memtype, 0, &sc->sc_memt,
	    &sc->sc_memh, NULL, &sc->sc_mems, 0)) {
@


1.34
log
@when posting descriptors to the chips rings, avoid going write barrier
write barrier write barrier when using myx_write to post descriptors.

instead let its go write write write barrier by using the appropriate
bus_space write directly followed by a single bus_space barrier.

the story above is mostly true, except that myx wants use to write all the
descriptors except the first, barrier, and then write the first one out to
signale that the chip can proceed.

it is also worth noting that the barriers cover more address space than
what we actually wrote to. this makes the code much simpler, and avoids
generating extra fence operations (which is what barrier functions end up
as on most of our archs) when we wrap around the end of the ring. the
bus_space doco encourages this.

bus_space use was discussed with krw@@ kettenis@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.33 2013/01/14 04:02:02 dlg Exp $	*/
d1580 2
a1581 1
		myx_write(sc, sc->sc_irqdeassertoff, &data, sizeof(data));
d1611 8
a1618 4
	if (valid & 0x1)
		myx_write(sc, sc->sc_irqclaimoff, &data, sizeof(data));
	myx_write(sc, sc->sc_irqclaimoff + sizeof(u_int32_t),
	    &data, sizeof(data));
@


1.33
log
@the myri doco suggests its nice to post stuff by filling in everything
in the rings except the first descriptor. once you've written as
much as you can out, then you go back and post the first descriptor
to signal that the chip should go ahead and work.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.32 2013/01/14 00:47:53 dlg Exp $	*/
d1388 2
a1389 1
	myx_write(sc, offset + sizeof(txd) * idx, &txd, sizeof(txd));
d1406 2
a1407 2
		myx_write(sc, offset +
		    sizeof(txd) * ((idx + i) % sc->sc_tx_ring_count),
d1418 2
a1419 2
		myx_write(sc, offset +
		    sizeof(txd) * ((idx + i) % sc->sc_tx_ring_count),
d1516 8
d1525 3
d1775 2
a1776 2
		myx_write(sc, offset + idx * sizeof(rxd),
		    &rxd, sizeof(rxd));
d1782 7
d1791 1
a1791 1
		    &rxd, sizeof(rxd));
@


1.32
log
@;; is a long way of saying ;
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.31 2012/11/29 21:10:32 brad Exp $	*/
d180 4
d1373 14
d1388 33
d1426 1
a1426 1
	struct myx_tx_desc		txd;
d1429 1
a1429 2
	bus_dmamap_t			zmap = sc->sc_zerodma.mxm_map;
	struct myx_buf			*mb;
d1432 1
a1432 2
	u_int				idx;
	u_int				i;
a1439 2
	idx = sc->sc_tx_ring_idx;

d1470 1
a1471 1

d1475 5
a1479 1
		myx_buf_put(&sc->sc_tx_buf_list, mb);
d1481 5
a1485 3
		flags = MYXTXD_FLAGS_NO_TSO;
		if (m->m_pkthdr.len < 1520)
			flags |= MYXTXD_FLAGS_SMALL;
d1487 4
a1490 11
		for (i = 1; i < map->dm_nsegs; i++) {
			bzero(&txd, sizeof(txd));
			txd.tx_addr = htobe64(map->dm_segs[i].ds_addr);
			txd.tx_length = htobe16(map->dm_segs[i].ds_len);
			txd.tx_flags = flags;

			/* complicated maths is cool */
			myx_write(sc, offset + sizeof(txd) *
			    ((idx + i) % sc->sc_tx_ring_count),
			    &txd, sizeof(txd));
		}
d1492 2
a1493 10
		/* pad runt frames */
		if (map->dm_mapsize < 60) {
			bzero(&txd, sizeof(txd));
			txd.tx_addr = htobe64(zmap->dm_segs[0].ds_addr);
			txd.tx_length = htobe16(60 - map->dm_mapsize);
			txd.tx_flags = flags;

			myx_write(sc, offset + sizeof(txd) *
			    ((idx + i) % sc->sc_tx_ring_count),
			    &txd, sizeof(txd));
d1495 1
a1495 2
			i++;
		}
d1497 3
a1499 6
		/* commit by posting the first descriptor */
		bzero(&txd, sizeof(txd));
		txd.tx_addr = htobe64(map->dm_segs[0].ds_addr);
		txd.tx_length = htobe16(map->dm_segs[0].ds_len);
		txd.tx_nsegs = i;
		txd.tx_flags = flags | MYXTXD_FLAGS_FIRST;
d1501 2
a1502 2
		myx_write(sc, offset + idx * sizeof(txd),
		    &txd, sizeof(txd));
d1504 1
a1504 2
		sc->sc_tx_free -= i;
		idx += i;
d1507 1
d1509 7
a1515 1
	sc->sc_tx_ring_idx = idx;
d1745 1
a1745 1
	struct myx_buf *mb;
d1747 11
a1757 2
	u_int idx;
	int ret = 1;
a1758 1
	idx = sc->sc_rx_ring_idx[ring];
d1760 2
a1762 2

		myx_buf_put(&sc->sc_rx_buf_list[ring], mb);
d1766 7
a1772 2
		if (++idx >= sc->sc_rx_ring_count)
			idx = 0;
a1773 2
		ret = 0;
	}
d1776 1
a1776 1
	return (ret);
@


1.31
log
@Remove setting an initial assumed baudrate upon driver attach which is not
necessarily correct, there might not even be a link when attaching.

ok mikeb@@ reyk@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.30 2011/11/28 10:25:22 blambert Exp $	*/
d1378 1
a1378 1
	bus_dmamap_t			zmap = sc->sc_zerodma.mxm_map;;
@


1.30
log
@Fix reversed error-handling gotos in myx_buf_fill(), which would lead to
either an mbuf leak or a NULL pointer dereference.

ok sthen@@ claudio@@ dlg@@
testing claudio@@ dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.29 2011/08/08 01:30:25 dlg Exp $	*/
a468 1
	ifp->if_baudrate = 0;
@


1.29
log
@myx requires the driver pad short ethernet frames to 60 bytes by
adding a descriptor pointing at zeroed bytes onto the end of transmit
chains. i was accounting for this extra descriptor when i was
completing the chain, but not when i was setting this up.  this
meant the number of free descriptors kept growing until it overflowed.
at this point the check for space in the ring failed and packets
no longer flowed.

this counts the pad descriptor in the tx chain setup too.

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.28 2011/06/23 04:09:08 dlg Exp $	*/
d1755 2
a1758 2
put:
	myx_buf_put(&sc->sc_rx_buf_free[ring], mb);
@


1.28
log
@cope with empty rx rings by scheduling a timeout to keep trying until it
gets some packets onto the rings.

also annoying, but the hardware doesnt report empty rings, we have to
handle it ourselves.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.27 2011/06/23 03:36:06 dlg Exp $	*/
a1428 2
		sc->sc_tx_free -= map->dm_nsegs;

d1471 1
@


1.27
log
@this chip has an annoying "feature" where it cannot report the link
state unless the chip is up and handling packets. while its down
it does not report the link state, so it is unknown.

this tweaks the link state handling, in particular it adds code to
myx_down so it moves the link state to unknown, ie, it correctly
reflects reality.

stupidity pointed out by deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.26 2011/06/22 21:04:31 deraadt Exp $	*/
d132 1
d195 1
d236 2
d1305 2
d1571 1
a1571 1
		if (ISSET(refill, 1 << i))
d1573 3
d1579 16
@


1.26
log
@reset the tx_count on UP, since it may have been advanced from non-zero
by a previous use
ok claudio
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.25 2011/06/22 10:34:15 dlg Exp $	*/
a148 2

	struct timeout		 sc_tick;
a172 1
void	 myx_tick(void *);
a473 2
	timeout_set(&sc->sc_tick, myx_tick, sc);

d811 4
a814 1
	imr->ifm_status = IFM_AVALID;
d818 1
d822 2
a823 1
	imr->ifm_active |= IFM_FDX;
a824 4

	/* Flow control */
	if (sc->sc_hwflags & MYXFLAG_FLOW_CONTROL)
		imr->ifm_active |= IFM_FLOW | IFM_ETH_RXPAUSE | IFM_ETH_TXPAUSE;
a832 3
	if (!ISSET(ifp->if_flags, IFF_RUNNING))
		return;

a848 13
void
myx_tick(void *arg)
{
	struct myx_softc	*sc = (struct myx_softc *)arg;
	struct ifnet		*ifp = &sc->sc_ac.ac_if;

	if (!ISSET(ifp->if_flags, IFF_RUNNING))
		return;

	myx_link_state(sc);
	timeout_add_sec(&sc->sc_tick, 1);
}

d1302 6
@


1.25
log
@msi support. this is a complicated one...

ok kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.24 2011/06/22 08:38:45 jsg Exp $	*/
d981 1
@


1.24
log
@another myri10ge device matched by freebsd/linux drivers
ok dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.23 2011/06/22 04:09:54 dlg Exp $	*/
d114 1
d251 6
a256 3
	if (pci_intr_map(pa, &sc->sc_ih) != 0) {
		printf(": unable to map interrupt\n");
		goto unmap;
d1535 4
a1538 2
	data = htobe32(0);
	myx_write(sc, sc->sc_irqdeassertoff, &data, sizeof(data));
@


1.23
log
@oops, handle refill like i said i was going to two revisions ago.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.22 2011/06/22 04:03:01 deraadt Exp $	*/
d205 2
a206 1
	{ PCI_VENDOR_MYRICOM, PCI_PRODUCT_MYRICOM_Z8E }
@


1.22
log
@set the mac address on the chip correctly (repair the byte order)
it now works on sparc64, too
ok dlg
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.21 2011/06/22 03:54:31 dlg Exp $	*/
d1550 1
a1550 1
		refill = myx_rxeof(sc);
@


1.21
log
@deraadt plugged his myx into a sparc64 and discovered 3 problems:

1. we want to write raw values to registers all the time, so promote the
myx_raw{read,write} to myx_{read,write} and use them everywhere. get rid
of the raw funcs.
2. i was setting the watermarks on the rx ring before knowhing how big
they were.
3. rxfill in the interrupt handler could lose data if you loop on
sts_isvalid.

almost working now...

"please commit your diff" deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.20 2011/06/21 21:56:28 dlg Exp $	*/
d1225 3
a1227 2
	mc.mc_data0 = addr[0] | addr[1] << 8 | addr[2] << 16 | addr[3] << 24;
	mc.mc_data1 = addr[4] << 16 | addr[5] << 24;
@


1.20
log
@do the unaligned dma tests so we can figure out if we need to fall
back to the unaligned firmware. apparently this is only an issue
on the "A" controllers which have been supersceded, but those are
the chips we (openbsd devs) have.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.19 2011/06/21 11:57:20 dlg Exp $	*/
a160 1
void	 myx_rawread(struct myx_softc *, bus_size_t, void *, bus_size_t);
a161 1
void	 myx_rawwrite(struct myx_softc *, bus_size_t, void *, bus_size_t);
d323 1
a323 1
	myx_rawread(sc, offset, &hdr, sizeof(hdr));
d391 1
a391 1
		myx_rawwrite(sc, i + MYX_FW, fw + i, min(256, fwlen - i));
a456 3
	m_clsetwms(ifp, MCLBYTES, 2, sc->sc_rx_ring_count - 2);
	m_clsetwms(ifp, 12 * 1024, 2, sc->sc_rx_ring_count - 2);

a565 9
	bus_space_read_region_4(sc->sc_memt, sc->sc_memh, off, ptr, len / 4);
}

void
myx_rawread(struct myx_softc *sc, bus_size_t off, void *ptr,
    bus_size_t len)
{
	bus_space_barrier(sc->sc_memt, sc->sc_memh, off, len,
	    BUS_SPACE_BARRIER_READ);
a571 9
	bus_space_write_region_4(sc->sc_memt, sc->sc_memh, off, ptr, len / 4);
	bus_space_barrier(sc->sc_memt, sc->sc_memh, off, len,
	    BUS_SPACE_BARRIER_WRITE);
}

void
myx_rawwrite(struct myx_softc *sc, bus_size_t off, void *ptr,
    bus_size_t len)
{
d963 3
@


1.19
log
@report the controllers part number. eg, i now know i have a
10G-PCIE-8A-R. dmesg looks like this:

myx0 at pci4 dev 0 function 0 "Myricom Z8E" rev 0x00: apic 1 int 8, model 10G-PCIE-8A-R, address 00:60:dd:47:c6:74
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.18 2011/06/21 10:31:28 dlg Exp $	*/
d132 1
d158 1
a412 1
	u_int32_t		 r;
d435 4
a438 2
	if (myx_cmd(sc, MYXCMD_GET_RXRINGSZ, &mc, &r) != 0) {
		printf("%s: unable to get rx ring size\n", DEVNAME(sc));
a440 1
	sc->sc_rx_ring_count = r / sizeof(struct myx_rx_desc);
d485 81
d981 6
d990 1
a990 1
		return;
d1128 2
a1129 1
		mb = myx_buf_alloc(sc, maxpkt, sc->sc_tx_nsegs, 4096, 4096);
@


1.18
log
@wire up jumbos properly. the hardware supports up to 9018 bytes off
the wire (9000 + ether header + vlan tag), but has some cool alignment
requirements. if you want to use a single rx ring desc to point at
a jumbo it needs to start on a 4k boundary and be physically
contiguous. to ensure this im pulling frames from the 12k pool and
waiting for arianes diff to ensure mbufs are contig.

direction from andrew gallatin. tested locally.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.17 2011/06/21 06:55:44 deraadt Exp $	*/
d153 1
a153 1
int	 myx_query(struct myx_softc *sc);
d219 1
d243 3
a245 2
	/* Get the mac address */
	if (myx_query(sc) != 0)
d254 3
a256 1
	printf(": %s, address %s\n", pci_intr_string(pa->pa_pc, sc->sc_ih),
d309 1
a309 1
myx_query(struct myx_softc *sc)
d337 3
@


1.17
log
@minor cleanups; ok dlg
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.16 2011/06/20 13:02:49 dlg Exp $	*/
d187 2
a188 1
struct myx_buf *	myx_buf_alloc(struct myx_softc *, bus_size_t, int);
d451 1
a451 1
	m_clsetwms(ifp, 4096, 2, sc->sc_rx_ring_count - 2);
d856 1
d1022 2
d1025 1
a1025 1
	mc.mc_data0 = htobe32(ifp->if_mtu + ETHER_HDR_LEN + 4 + 4);
d1027 1
a1027 2
		printf("%s: failed to set MTU size %d\n",
		    DEVNAME(sc), ifp->if_mtu + ETHER_HDR_LEN + 4 + 4);
d1032 1
a1032 1
		mb = myx_buf_alloc(sc, 4096, sc->sc_tx_nsegs);
d1040 1
a1040 1
		mb = myx_buf_alloc(sc, MCLBYTES, 1);
d1048 1
a1048 1
		mb = myx_buf_alloc(sc, 4096, 1);
d1068 1
a1068 1
	mc.mc_data0 = htobe32(MCLBYTES - 2);
d1075 1
a1075 1
	mc.mc_data0 = htobe32(4096);
d1553 2
a1554 1
		ring = (len <= (MCLBYTES - 2)) ? MYX_RXSMALL : MYX_RXBIG;
d1636 1
a1636 1
	static size_t sizes[2] = { MCLBYTES, 4096 };
d1668 2
a1669 1
myx_buf_alloc(struct myx_softc *sc, bus_size_t size, int nsegs)
d1677 1
a1677 1
	if (bus_dmamap_create(sc->sc_dmat, size, nsegs, 4096, 4096,
@


1.16
log
@make the interrupt handler look more like what the doco suggests. seems to
fix a bad lockup i kept getting.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.15 2011/06/20 06:56:06 dlg Exp $	*/
d74 1
a74 1
#define DEVNAME(_s)	((_s)->_s##_dev.dv_xname)
d444 1
a444 1
        ifp->if_hardmtu = 9000;
d456 1
a456 1
		    IFCAP_CSUM_UDPv4;
d1159 2
a1160 2
        struct ether_multi	*enm;
        struct ether_multistep	step;
d1302 1
a1302 1
        struct mbuf			*m;
d1310 1
a1310 1
	    IFQ_IS_EMPTY(&ifp->if_snd)) 
d1521 1
a1521 1
                bus_dmamap_unload(sc->sc_dmat, map);
d1560 1
a1560 1
                bus_dmamap_unload(sc->sc_dmat, mb->mb_map);
a1706 1

@


1.15
log
@dont need debug, the myx_cmd stuff works fine.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.14 2011/06/20 05:19:20 dlg Exp $	*/
d112 1
a112 1
	struct myx_status	*sc_sts;
d1428 1
a1428 1
	struct myx_status	*sts = sc->sc_sts;
a1432 1
	int			 ret = 0;
d1442 6
a1447 3
	if (valid) {
		data = htobe32(0);
		myx_write(sc, sc->sc_irqdeassertoff, &data, sizeof(data));
d1449 13
d1463 4
a1466 1
		if (data != sc->sc_tx_count) {
a1467 5
			if (ISSET(ifp->if_flags, IFF_OACTIVE)) {
				CLR(ifp->if_flags, IFF_OACTIVE);
				myx_start(ifp);
			}
		}
a1469 4
		for (i = 0; i < 2; i++) {
			if (ISSET(refill, 1 << i))
				myx_rx_fill(sc, i);
		}
d1471 3
a1473 2
		if (sts->ms_statusupdated)
			myx_link_state(sc);
d1475 2
a1476 5
		data = htobe32(3);
		if (valid & 0x1)
			myx_write(sc, sc->sc_irqclaimoff, &data, sizeof(data));
		myx_write(sc, sc->sc_irqclaimoff + sizeof(u_int32_t),
		    &data, sizeof(data));
d1478 9
a1486 1
		ret = 1;
d1489 3
a1491 5
	if (!ISSET(ifp->if_flags, IFF_UP) &&
	    sc->sc_linkdown != sts->ms_linkdown) {
		/* myx_down is waiting for us */
		wakeup_one(sc->sc_sts);
		ret = 1;
d1494 1
a1494 4
	bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
	    BUS_DMASYNC_PREREAD);

	return (ret);
@


1.14
log
@i got myx working!
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.13 2011/05/02 22:13:27 chl Exp $	*/
a59 1
#define MYX_DEBUG
@


1.13
log
@Do not check malloc return value against NULL, as M_WAITOK is used.

ok dlg@@ krw@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.12 2010/05/19 15:27:35 oga Exp $	*/
d35 1
a35 1
#include <sys/sensors.h>
d87 2
a88 1
	bus_dmamap_t		 mb_dmamap;
d91 2
d99 1
d108 1
d112 1
a112 1
	struct myx_dmamem	 sc_stsdma;
a114 9
	struct myx_dmamem	 sc_rxdma;
	struct myx_rxdesc	*sc_rxdesc;
	struct myx_rxbufdesc	*sc_rxbufdesc[2];
	struct myx_buf		*sc_rxbuf[2];
#define  MYX_RXSMALL		 0
#define  MYX_RXBIG		 1
	int			 sc_rxactive;
	int			 sc_rxidx;

d120 22
a144 12
	u_int32_t		 sc_rxringsize;
	u_int32_t		 sc_rxsmallringoff;
	u_int32_t		 sc_rxbigringoff;
	int			 sc_rxndesc;
	size_t			 sc_rxdescsize;
	size_t			 sc_rxbufsize;
	size_t			 sc_rxbufdescsize;
	u_int32_t		 sc_txringsize;
	u_int32_t		 sc_txringoff;
	int			 sc_txndesc;

	u_int			 sc_phy;	/* PHY type (CX4/SR/LR) */
d147 1
a147 3
#define  MYXFLAG_PROMISC	 (1<<1)		/* promisc mode is enabled */
#define  MYXFLAG_ALLMULTI	 (1<<2)		/* allmulti is set */
	u_int8_t		 sc_active;
a155 2
int	 myx_loadfirmware(struct myx_softc *, u_int8_t *, size_t,
	    u_int32_t, int);
d157 7
a163 4
void	 myx_read(struct myx_softc *, bus_size_t, u_int8_t *, bus_size_t);
void	 myx_rawread(struct myx_softc *, bus_size_t, u_int8_t *, bus_size_t);
void	 myx_write(struct myx_softc *, bus_size_t, u_int8_t *, bus_size_t);
void	 myx_rawwrite(struct myx_softc *, bus_size_t, u_int8_t *, bus_size_t);
d165 2
a166 1
int	 myx_boot(struct myx_softc *, u_int32_t, struct myx_bootcmd *);
a167 1
int	 myx_reset(struct myx_softc *);
d177 1
d179 2
a180 1
void	 myx_init(struct ifnet *);
d182 2
a183 2
void	 myx_stop(struct ifnet *);
int	 myx_setlladdr(struct myx_softc *, u_int8_t *);
d185 11
a195 3
int	 myx_init_rings(struct myx_softc *);
void	 myx_free_rings(struct myx_softc *);
struct mbuf *myx_getbuf(struct myx_softc *, bus_dmamap_t, int);
d211 1
a211 2
	return (pci_matchbyid((struct pci_attach_args *)aux,
	    myx_devices, sizeof(myx_devices) / sizeof(myx_devices[0])));
a218 1
	pci_intr_handle_t	 ih;
a219 2
	const char		*intrstr;
	struct ifnet		*ifp;
d226 8
d242 1
a242 1
	/* Get the board information and initialize the h/w */
d246 3
a248 6
	/*
	 * Allocate command DMA memory
	 */
	if (myx_dmamem_alloc(sc, &sc->sc_cmddma, MYXALIGN_CMD,
	    MYXALIGN_CMD, "cmd") != 0) {
		printf(": failed to allocate command DMA memory\n");
d252 2
a253 5
	if (myx_dmamem_alloc(sc, &sc->sc_paddma,
	    MYXALIGN_CMD, MYXALIGN_CMD, "pad") != 0) {
		printf(": failed to allocate pad DMA memory\n");
		goto err2;
	}
d255 11
a265 4
	if (myx_dmamem_alloc(sc, &sc->sc_stsdma,
	    sizeof(struct myx_status), MYXALIGN_DATA /* XXX */, "status") != 0) {
		printf(": failed to allocate status DMA memory\n");
		goto err1;
a266 1
	sc->sc_sts = (struct myx_status *)sc->sc_stsdma.mxm_kva;
d268 3
a270 13
	/*
	 * Map and establish the interrupt
	 */
	if (pci_intr_map(pa, &ih) != 0) {
		printf(": unable to map interrupt\n");
		goto err;
	}
	intrstr = pci_intr_string(pa->pa_pc, ih);
	sc->sc_irqh = pci_intr_establish(pa->pa_pc, ih, IPL_NET,
	    myx_intr, sc, DEVNAME(sc));
	if (sc->sc_irqh == NULL) {
		printf(": unable to establish interrupt %s\n", intrstr);
		goto err;
a271 33
	printf(": %s, address %s\n", intrstr,
	    ether_sprintf(sc->sc_ac.ac_enaddr));

	ifp = &sc->sc_ac.ac_if;
	ifp->if_softc = sc;
	ifp->if_flags = IFF_BROADCAST | IFF_SIMPLEX | IFF_MULTICAST;
	ifp->if_ioctl = myx_ioctl;
	ifp->if_start = myx_start;
	ifp->if_watchdog = myx_watchdog;
	strlcpy(ifp->if_xname, DEVNAME(sc), IFNAMSIZ);
	IFQ_SET_MAXLEN(&ifp->if_snd, MYX_NTXDESC_MIN - 1);
	IFQ_SET_READY(&ifp->if_snd);

	ifp->if_capabilities = IFCAP_VLAN_MTU;
#if 0
	ifp->if_capabilities |= IFCAP_VLAN_HWTAGGING;
	ifp->if_capabilities |= IFCAP_CSUM_IPv4 | IFCAP_CSUM_TCPv4 |
		    IFCAP_CSUM_UDPv4;
#endif
	ifp->if_baudrate = IF_Gbps(10);

	ifmedia_init(&sc->sc_media, 0,
	    myx_media_change, myx_media_status);
	ifmedia_add(&sc->sc_media, IFM_ETHER|sc->sc_phy, 0, NULL);
	ifmedia_set(&sc->sc_media, IFM_ETHER|sc->sc_phy);

	if_attach(ifp);
	ether_ifattach(ifp);

	timeout_set(&sc->sc_tick, myx_tick, sc);
	timeout_add_sec(&sc->sc_tick, 1);

	mountroothook_establish(myx_attachhook, sc);
a274 6
 err:
	myx_dmamem_free(sc, &sc->sc_stsdma);
 err1:
	myx_dmamem_free(sc, &sc->sc_paddma);
 err2:
	myx_dmamem_free(sc, &sc->sc_cmddma);
d307 11
a317 4
	u_int8_t	eeprom[MYX_EEPROM_SIZE];
	u_int		i, maxlen;

	myx_read(sc, MYX_EEPROM, eeprom, MYX_EEPROM_SIZE);
d319 9
a327 3
	for (i = 0; i < MYX_EEPROM_SIZE; i++) {
		maxlen = MYX_EEPROM_SIZE - i;
		if (eeprom[i] == '\0')
d329 1
a329 1
		if (maxlen > 4 && bcmp("MAC=", &eeprom[i], 4) == 0) {
d331 1
a331 1
			i += myx_ether_aton(&eeprom[i],
d334 2
a335 2
		for (; i < MYX_EEPROM_SIZE; i++)
			if (eeprom[i] == '\0')
d337 1
d344 1
a344 2
myx_loadfirmware(struct myx_softc *sc, u_int8_t *fw, size_t fwlen,
    u_int32_t fwhdroff, int reload)
d346 15
a360 2
	struct myx_firmware_hdr	*fwhdr;
	u_int			 i, len, ret = 0;
d362 5
a366 16
	fwhdr = (struct myx_firmware_hdr *)(fw + fwhdroff);
	DPRINTF(MYXDBG_INIT, "%s(%s): "
	    "fw hdr off %d, length %d, type 0x%x, version %s\n",
	    DEVNAME(sc), __func__,
	    fwhdroff, betoh32(fwhdr->fw_hdrlength),
	    betoh32(fwhdr->fw_type),
	    fwhdr->fw_version);

	if (betoh32(fwhdr->fw_type) != MYXFW_TYPE_ETH ||
	    bcmp(MYXFW_VER, fwhdr->fw_version, strlen(MYXFW_VER)) != 0) {
		if (reload)
			printf("%s: invalid firmware type 0x%x version %s\n",
			    DEVNAME(sc), betoh32(fwhdr->fw_type),
			    fwhdr->fw_version);
		ret = 1;
		goto done;
d369 12
a380 2
	if (!reload)
		goto done;
d383 1
a383 2
	for (i = 0; i < fwlen; i += 256) {
		len = min(256, fwlen - i);
d385 4
d391 3
a393 1
 done:
d402 3
a404 4
	size_t			 fwlen;
	u_int8_t		*fw = NULL;
	u_int32_t		 fwhdroff;
	struct myx_bootcmd	 bc;
d406 7
a412 8
	/*
	 * First try the firmware found in the SRAM
	 */
	myx_read(sc, MYX_HEADER_POS, (u_int8_t *)&fwhdroff, sizeof(fwhdroff));
	fwhdroff = betoh32(fwhdroff);
	fwlen = sizeof(struct myx_firmware_hdr);
	if ((fwhdroff + fwlen) > MYX_SRAM_SIZE)
		goto load;
d414 5
a418 2
	fw = malloc(fwlen, M_DEVBUF, M_WAIT);
	myx_rawread(sc, MYX_HEADER_POS, fw, fwlen);
d420 1
a420 2
	if (myx_loadfirmware(sc, fw, fwlen, fwhdroff, 0) == 0)
		goto boot;
d422 3
a424 7
 load:
	/*
	 * Now try the firmware stored on disk
	 */
	if (loadfirmware(MYXFW_ALIGNED /* XXX */, &fw, &fwlen) != 0) {
		printf("%s: could not load firmware\n", DEVNAME(sc));
		return;
d426 4
a429 3
	if (fwlen > MYX_SRAM_SIZE || fwlen < MYXFW_MIN_LEN) {
		printf("%s: invalid firmware image size\n", DEVNAME(sc));
		goto err;
d431 1
d433 5
a437 5
	bcopy(fw + MYX_HEADER_POS, &fwhdroff, sizeof(fwhdroff));
	fwhdroff = betoh32(fwhdroff);
	if ((fwhdroff + sizeof(struct myx_firmware_hdr)) > fwlen) {
		printf("%s: invalid firmware image\n", DEVNAME(sc));
		goto err;
d440 27
a466 5
	if (myx_loadfirmware(sc, fw, fwlen, fwhdroff, 1) != 0) {
		fw = NULL;
		goto err;
	}
	fw = NULL;
d468 1
a468 8
 boot:
	bzero(&bc, sizeof(bc));
	if (myx_boot(sc, fwlen, &bc) != 0) {
		printf("%s: failed to bootstrap the device\n", DEVNAME(sc));
		goto err;
	}
	if (myx_reset(sc) != 0)
		goto err;
a469 1
	sc->sc_active = 1;
d472 2
a473 3
 err:
	if (fw != NULL)
		free(fw, M_DEVBUF);
d477 1
a477 1
myx_read(struct myx_softc *sc, bus_size_t off, u_int8_t *ptr, bus_size_t len)
d485 1
a485 1
myx_rawread(struct myx_softc *sc, bus_size_t off, u_int8_t *ptr,
d494 1
a494 1
myx_write(struct myx_softc *sc, bus_size_t off, u_int8_t *ptr, bus_size_t len)
d502 1
a502 1
myx_rawwrite(struct myx_softc *sc, bus_size_t off, u_int8_t *ptr,
d607 2
d618 3
d637 1
a637 1
myx_boot(struct myx_softc *sc, u_int32_t length, struct myx_bootcmd *bc)
d639 1
d642 1
a642 1
	u_int			 i;
d644 8
a651 7
	bc->bc_addr_high = htobe32(MYX_ADDRHIGH(map->dm_segs[0].ds_addr));
	bc->bc_addr_low = htobe32(MYX_ADDRLOW(map->dm_segs[0].ds_addr));
	bc->bc_result = 0xffffffff;
	bc->bc_offset = htobe32(MYX_FW_BOOT);
	bc->bc_length = htobe32(length);
	bc->bc_copyto = htobe32(8);
	bc->bc_jumpto = htobe32(0);
d657 3
a659 1
	myx_write(sc, MYX_BOOT, (u_int8_t *)bc, sizeof(struct myx_bootcmd));
d664 2
a665 1
		if (*status == 0xffffffff)
d667 4
d674 2
a675 2
	DPRINTF(MYXDBG_CMD, "%s(%s): boot completed, i %d, result 0x%x\n",
	    DEVNAME(sc), __func__, i, betoh32(*status));
d677 1
a677 4
	if (*status != 0xffffffff)
		return (-1);

	return (0);
d687 1
d704 3
d708 1
a708 1
	myx_write(sc, MYX_RDMA, (u_int8_t *)&rc, sizeof(struct myx_rdmacmd));
d713 3
a715 1
		if (*status == 0xffffffff)
d717 4
d728 1
a728 4
	if (*status != 0xffffffff)
		return (-1);

	return (0);
d732 1
a732 1
myx_reset(struct myx_softc *sc)
d734 1
a734 48
	struct myx_cmd		 mc;
	u_int32_t		 data;
	struct ifnet		*ifp = &sc->sc_ac.ac_if;

	bzero(&mc, sizeof(mc));
	if (myx_cmd(sc, MYXCMD_RESET, &mc, NULL) != 0) {
		printf("%s: failed to reset the device\n", DEVNAME(sc));
		return (-1);
	}

	if (myx_rdma(sc, MYXRDMA_ON) != 0) {
		printf("%s: failed to enable dummy RDMA\n", DEVNAME(sc));
		return (-1);
	}

	if (myx_cmd(sc, MYXCMD_GET_INTRCOALDELAYOFF, &mc,
	    &sc->sc_irqcoaloff) != 0) {
		printf("%s: failed to get IRQ coal offset\n", DEVNAME(sc));
		return (-1);
	}
	data = htobe32(MYX_IRQCOALDELAY);
	myx_write(sc, sc->sc_irqcoaloff, (u_int8_t *)&data, sizeof(data));

	if (myx_cmd(sc, MYXCMD_GET_INTRACKOFF, &mc,
	    &sc->sc_irqclaimoff) != 0) {
		printf("%s: failed to get IRQ ack offset\n", DEVNAME(sc));
		return (-1);
	}

	if (myx_cmd(sc, MYXCMD_GET_INTRDEASSERTOFF, &mc,
	    &sc->sc_irqdeassertoff) != 0) {
		printf("%s: failed to get IRQ deassert offset\n", DEVNAME(sc));
		return (-1);
	}

	if (myx_cmd(sc, MYXCMD_UNSET_PROMISC, &mc, NULL) != 0) {
		printf("%s: failed to disable promisc mode\n", DEVNAME(sc));
		return (-1);
	}

	if (myx_cmd(sc, MYXCMD_FC_DEFAULT, &mc, NULL) != 0) {
		printf("%s: failed to configure flow control\n", DEVNAME(sc));
		return (-1);
	}

	if (myx_setlladdr(sc, LLADDR(ifp->if_sadl)) != 0)
		return (-1);

a737 7

int
myx_media_change(struct ifnet *ifp)
{
	return (EINVAL);
}

d743 1
a743 1
	imr->ifm_active = IFM_ETHER|sc->sc_phy;
d745 1
d747 1
d750 1
d756 1
a756 1
		imr->ifm_active |= IFM_FLOW|IFM_ETH_RXPAUSE|IFM_ETH_TXPAUSE;
d765 1
a765 1
	if (sc->sc_sts == NULL)
d767 2
a768 1
	if (sc->sc_sts->ms_linkstate == MYXSTS_LINKUP)
d773 2
d788 1
d790 1
a790 1
	if (!sc->sc_active)
d817 2
a818 2
		if (ifp->if_flags & IFF_UP) {
			if (ifp->if_flags & IFF_RUNNING)
d821 1
a821 1
				myx_init(ifp);
d823 2
a824 2
			if (ifp->if_flags & IFF_RUNNING)
				myx_stop(ifp);
d849 1
a849 1
myx_iff(struct myx_softc *sc)
d851 7
a857 3
	/* XXX set multicast filters etc. */
	return;
}
d859 5
a863 5
void
myx_init(struct ifnet *ifp)
{
	struct myx_softc	*sc = (struct myx_softc *)ifp->if_softc;
	struct myx_cmd		 mc;
d865 4
a868 1
	if (myx_reset(sc) != 0)
d870 14
d885 4
a888 2
	if (myx_init_rings(sc) != 0)
		return;
d890 3
a892 3
	if (myx_cmd(sc, MYXCMD_SET_IFUP, &mc, NULL) != 0) {
		printf("%s: failed to start the device\n", DEVNAME(sc));
		myx_free_rings(sc);
d895 6
d902 1
a902 3
	ifp->if_flags |= IFF_RUNNING;
	ifp->if_flags &= ~IFF_OACTIVE;
}
d904 2
a905 4
void
myx_start(struct ifnet *ifp)
{
}
d907 10
a916 5
void
myx_stop(struct ifnet *ifp)
{
	struct myx_softc	*sc = (struct myx_softc *)ifp->if_softc;
	struct myx_cmd		 mc;
d919 5
a923 2
	(void)myx_cmd(sc, MYXCMD_SET_IFDOWN, &mc, NULL);
	myx_free_rings(sc);
d925 214
a1138 2
	ifp->if_flags &= ~(IFF_RUNNING | IFF_OACTIVE);
}
d1141 1
a1141 1
myx_setlladdr(struct myx_softc *sc, u_int8_t *addr)
d1146 3
a1148 3
	mc.mc_data0 = addr[3] | addr[2] << 8 | addr[1] << 16 | addr[0] << 24;
	mc.mc_data1 = addr[5] | addr[4] << 8;
	if (myx_cmd(sc, MYXCMD_SET_LLADDR, &mc, NULL) != 0) {
d1155 2
a1156 2
int
myx_intr(void *arg)
d1158 4
a1161 4
	struct myx_softc	*sc = (struct myx_softc *)arg;
	u_int32_t		 data, valid;
	struct myx_status	*sts = sc->sc_sts;
	bus_dmamap_t		 map = sc->sc_stsdma.mxm_map;
d1163 5
a1167 2
	if (!sc->sc_active)
		return (0);
d1169 1
a1169 2
	bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
	    BUS_DMASYNC_POSTWRITE);
d1171 4
a1174 7
	/*
	 * XXX The 'valid' flags should be set by the NIC, but it doesn't
	 * XXX work yet.
	 */
	valid = sts->ms_isvalid;
	if (!valid)
		return (0);
d1176 4
a1179 2
	data = 0;
	myx_write(sc, sc->sc_irqdeassertoff, (u_int8_t *)&data, sizeof(data));
d1181 4
a1184 2
	DPRINTF(MYXDBG_INTR, "%s(%s): interrupt, valid 0x%x\n",
	    DEVNAME(sc), __func__, valid);
d1186 7
a1192 25
#ifdef MYX_DEBUG
#define DPRINT_STATUS(_n)						\
	DPRINTF(MYXDBG_INTR, "%s(%s): %s: %u, 0x%x\n", DEVNAME(sc), __func__,\
	    #_n, sts->_n, sts->_n)

	DPRINT_STATUS(ms_reserved);
	DPRINT_STATUS(ms_dropped_pause);
	DPRINT_STATUS(ms_dropped_unicast);
	DPRINT_STATUS(ms_dropped_crc32err);
	DPRINT_STATUS(ms_dropped_phyerr);
	DPRINT_STATUS(ms_dropped_mcast);
	DPRINT_STATUS(ms_txdonecnt);
	DPRINT_STATUS(ms_linkstate);
	DPRINT_STATUS(ms_dropped_linkoverflow);
	DPRINT_STATUS(ms_dropped_linkerror);
	DPRINT_STATUS(ms_dropped_runt);
	DPRINT_STATUS(ms_dropped_overrun);
	DPRINT_STATUS(ms_dropped_smallbufunderrun);
	DPRINT_STATUS(ms_dropped_bigbufunderrun);
	DPRINT_STATUS(ms_rdmatags_available);
	DPRINT_STATUS(ms_txstopped);
	DPRINT_STATUS(ms_linkdowncnt);
	DPRINT_STATUS(ms_statusupdated);
	DPRINT_STATUS(ms_isvalid);
#endif
d1194 2
a1195 6
	data = htobe32(3);
	if (sts->ms_isvalid)
		myx_write(sc, sc->sc_irqclaimoff, (u_int8_t *)&data,
		    sizeof(data));
	myx_write(sc, sc->sc_irqclaimoff + sizeof(u_int32_t),
	    (u_int8_t *)&data, sizeof(data));
d1197 5
a1201 1
	return (1);
d1204 2
a1205 2
int
myx_init_rings(struct myx_softc *sc)
a1206 1
	struct myx_cmd		 mc;
d1208 1
a1208 2
	bus_dmamap_t		 map;
	int			 i;
d1210 9
a1218 2
	struct myx_rxbufdesc	*rxb;
	u_int32_t		 data;
d1221 12
a1232 13
	if (!(myx_cmd(sc, MYXCMD_GET_RXRINGSZ, &mc,
	    &sc->sc_rxringsize) == 0 && sc->sc_rxringsize &&
	    myx_cmd(sc, MYXCMD_GET_RXSMALLRINGOFF, &mc,
	    &sc->sc_rxsmallringoff) == 0 && sc->sc_rxsmallringoff &&
	    myx_cmd(sc, MYXCMD_GET_RXBIGRINGOFF, &mc,
	    &sc->sc_rxbigringoff) == 0 && sc->sc_rxbigringoff &&
	    myx_cmd(sc, MYXCMD_GET_TXRINGSZ, &mc,
	    &sc->sc_txringsize) == 0 && sc->sc_txringsize &&
	    myx_cmd(sc, MYXCMD_GET_TXRINGOFF, &mc,
	    &sc->sc_txringoff) == 0 && sc->sc_txringoff)) {
		printf("%s: failed to get ring sizes and offsets\n",
		    DEVNAME(sc));
		return (-1);
a1233 7
	sc->sc_rxndesc = sc->sc_rxringsize / sizeof(struct myx_rxbufdesc);
	sc->sc_txndesc = sc->sc_txringsize / sizeof(struct myx_txdesc);
	sc->sc_rxdescsize = sc->sc_rxndesc * 2 * sizeof(struct myx_rxdesc);
	sc->sc_rxbufsize = sc->sc_rxndesc * sizeof(struct myx_buf);
	sc->sc_rxbufdescsize = sc->sc_rxndesc * sizeof(struct myx_rxbufdesc);
	IFQ_SET_MAXLEN(&ifp->if_snd, sc->sc_txndesc - 1);
	IFQ_SET_READY(&ifp->if_snd);
d1235 2
a1236 4
	DPRINTF(MYXDBG_INIT, "%s(%s): Rx ring ndesc %u size %u bufsize %u, "
	    "Tx ring ndesc %u size %u offset 0x%x\n", DEVNAME(sc), __func__,
	    sc->sc_rxndesc, sc->sc_rxdescsize, sc->sc_rxringsize,
	    sc->sc_txndesc, sc->sc_txringsize, sc->sc_txringoff);
d1238 3
a1240 7
	/*
	 * Setup Rx DMA descriptors
	 */
	if (myx_dmamem_alloc(sc, &sc->sc_rxdma,
	    sc->sc_rxdescsize, MYXALIGN_DATA, "rxring") != 0) {
		printf(": failed to allocate Rx DMA memory\n");
		return (-1);
a1241 1
	sc->sc_rxdesc = (struct myx_rxdesc *)sc->sc_rxdma.mxm_kva;
d1243 8
a1250 5
	bzero(&mc, sizeof(mc));
	mc.mc_data0 = htobe32(sc->sc_rxdescsize);
	if (myx_cmd(sc, MYXCMD_SET_INTRQSZ, &mc, NULL) != 0) {
		printf("%s: failed to set Rx DMA size\n", DEVNAME(sc));
		goto err;
d1253 6
a1258 6
	map = sc->sc_rxdma.mxm_map;
	mc.mc_data0 = MYX_ADDRLOW(map->dm_segs[0].ds_addr);
	mc.mc_data1 = MYX_ADDRHIGH(map->dm_segs[0].ds_addr);
	if (myx_cmd(sc, MYXCMD_SET_INTRQDMA, &mc, NULL) != 0) {
		printf("%s: failed to set Rx DMA address\n", DEVNAME(sc));
		goto err;
d1261 12
a1272 11
#ifdef notyet
	/*
	 * XXX It fails to set the MTU and it always returns
	 * XXX MYXCMD_ERR_RANGE.
	 */
	bzero(&mc, sizeof(mc));
	mc.mc_data0 = ifp->if_mtu + ETHER_HDR_LEN + 4;
	if (myx_cmd(sc, MYXCMD_SET_MTU, &mc, NULL) != 0) {
		printf("%s: failed to set MTU size %d\n",
		    DEVNAME(sc), ifp->if_mtu + ETHER_HDR_LEN + 4);
		goto err;
a1273 1
#endif
d1275 55
a1329 24
	/*
	 * Setup Rx buffer descriptors
	 */
	sc->sc_rxbuf[MYX_RXSMALL] = (struct myx_buf *)
	    malloc(sc->sc_rxbufsize, M_DEVBUF, M_WAITOK);
	sc->sc_rxbufdesc[MYX_RXSMALL] = (struct myx_rxbufdesc *)
	    malloc(sc->sc_rxbufdescsize, M_DEVBUF, M_WAITOK);
	sc->sc_rxbuf[MYX_RXBIG] = (struct myx_buf *)
	    malloc(sc->sc_rxbufsize, M_DEVBUF, M_WAITOK);
	sc->sc_rxbufdesc[MYX_RXBIG] = (struct myx_rxbufdesc *)
	    malloc(sc->sc_rxbufdescsize, M_DEVBUF, M_WAITOK);

	for (i = 0; i < sc->sc_rxndesc; i++) {
		/*
		 * Small Rx buffers and descriptors
		 */
		mb = sc->sc_rxbuf[MYX_RXSMALL] + i;
		rxb = sc->sc_rxbufdesc[MYX_RXSMALL] + i;

		if (bus_dmamap_create(sc->sc_dmat, MCLBYTES, 1,
		    MCLBYTES, 0, BUS_DMA_WAITOK, &mb->mb_dmamap) != 0) {
			printf("%s: unable to create dmamap for small rx %d\n",
			    DEVNAME(sc), i);
			goto err;
d1332 6
a1337 5
		map = mb->mb_dmamap;
		mb->mb_m = myx_getbuf(sc, map, 1);
		if (mb->mb_m == NULL) {
			bus_dmamap_destroy(sc->sc_dmat, map);
			goto err;
d1340 8
d1349 5
a1353 1
		    mb->mb_m->m_pkthdr.len, BUS_DMASYNC_PREREAD);
d1355 14
a1368 19
		rxb->rb_addr_high =
		    htobe32(MYX_ADDRHIGH(map->dm_segs[0].ds_addr));
		rxb->rb_addr_low =
		    htobe32(MYX_ADDRHIGH(map->dm_segs[0].ds_addr));

		data = sc->sc_rxsmallringoff + i * sizeof(*rxb);
		myx_write(sc, data, (u_int8_t *)rxb, sizeof(*rxb));

		/*
		 * Big Rx buffers and descriptors
		 */
		mb = sc->sc_rxbuf[MYX_RXBIG] + i;
		rxb = sc->sc_rxbufdesc[MYX_RXBIG] + i;

		if (bus_dmamap_create(sc->sc_dmat, MCLBYTES, 1,
		    MCLBYTES, 0, BUS_DMA_WAITOK, &mb->mb_dmamap) != 0) {
			printf("%s: unable to create dmamap for big rx %d\n",
			    DEVNAME(sc), i);
			goto err;
d1371 12
a1382 5
		map = mb->mb_dmamap;
		mb->mb_m = myx_getbuf(sc, map, 1);
		if (mb->mb_m == NULL) {
			bus_dmamap_destroy(sc->sc_dmat, map);
			goto err;
d1385 22
a1406 2
		bus_dmamap_sync(sc->sc_dmat, map, 0,
		    mb->mb_m->m_pkthdr.len, BUS_DMASYNC_PREREAD);
d1408 3
a1410 4
		rxb->rb_addr_high =
		    htobe32(MYX_ADDRHIGH(map->dm_segs[0].ds_addr));
		rxb->rb_addr_low =
		    htobe32(MYX_ADDRHIGH(map->dm_segs[0].ds_addr));
d1412 6
a1417 2
		data = sc->sc_rxbigringoff + i * sizeof(*rxb);
		myx_write(sc, data, (u_int8_t *)rxb, sizeof(*rxb));
d1420 53
a1472 5
	bzero(&mc, sizeof(mc));
	mc.mc_data0 = MYX_MAX_MTU_SMALL;
	if (myx_cmd(sc, MYXCMD_SET_SMALLBUFSZ, &mc, NULL) != 0) {
		printf("%s: failed to set small buf size\n", DEVNAME(sc));
		goto err;
d1475 5
a1479 5
	bzero(&mc, sizeof(mc));
	mc.mc_data0 = MCLBYTES;
	if (myx_cmd(sc, MYXCMD_SET_BIGBUFSZ, &mc, NULL) != 0) {
		printf("%s: failed to set big buf size\n", DEVNAME(sc));
		goto err;
d1482 84
a1565 4
	/*
	 * Setup status DMA
	 */
	map = sc->sc_stsdma.mxm_map;
d1567 2
a1568 7
	bzero(&mc, sizeof(mc));
	mc.mc_data0 = MYX_ADDRLOW(map->dm_segs[0].ds_addr);
	mc.mc_data1 = MYX_ADDRHIGH(map->dm_segs[0].ds_addr);
	mc.mc_data2 = sizeof(struct myx_status);
	if (myx_cmd(sc, MYXCMD_SET_STATSDMA, &mc, NULL) != 0) {
		printf("%s: failed to set status DMA offset\n", DEVNAME(sc));
		goto err;
d1571 2
a1572 2
	bus_dmamap_sync(sc->sc_dmat, map, 0,
	    map->dm_mapsize, BUS_DMASYNC_PREWRITE);
d1574 1
a1574 4
	return (0);
 err:
	myx_free_rings(sc);
	return (-1);
d1578 17
a1594 1
myx_free_rings(struct myx_softc *sc)
d1596 18
a1613 23
	if (sc->sc_rxbuf[MYX_RXSMALL] != NULL) {
		free(sc->sc_rxbuf[MYX_RXSMALL], M_DEVBUF);
		sc->sc_rxbuf[MYX_RXSMALL] = NULL;
	}
	if (sc->sc_rxbufdesc[MYX_RXSMALL] != NULL) {
		free(sc->sc_rxbufdesc[MYX_RXSMALL], M_DEVBUF);
		sc->sc_rxbufdesc[MYX_RXSMALL] = NULL;
	}
	if (sc->sc_rxbuf[MYX_RXBIG] != NULL) {
		free(sc->sc_rxbuf[MYX_RXBIG], M_DEVBUF);
		sc->sc_rxbuf[MYX_RXBIG] = NULL;
	}
	if (sc->sc_rxbufdesc[MYX_RXBIG] != NULL) {
		free(sc->sc_rxbufdesc[MYX_RXBIG], M_DEVBUF);
		sc->sc_rxbufdesc[MYX_RXBIG] = NULL;
	}
	if (sc->sc_rxdesc != NULL) {
		myx_dmamem_free(sc, &sc->sc_rxdma);
		sc->sc_rxdesc = NULL;
	}
	if (sc->sc_sts != NULL) {
		myx_dmamem_free(sc, &sc->sc_stsdma);
		sc->sc_sts = NULL;
d1615 3
a1617 1
	return;
d1620 2
a1621 2
struct mbuf *
myx_getbuf(struct myx_softc *sc, bus_dmamap_t map, int wait)
d1623 3
a1625 1
	struct mbuf		*m = NULL;
d1627 1
a1627 1
	MGETHDR(m, wait ? M_WAIT : M_DONTWAIT, MT_DATA);
d1629 29
a1657 1
		goto merr;
d1659 8
a1666 9
	MCLGET(m, wait ? M_WAIT : M_DONTWAIT);
	if ((m->m_flags & M_EXT) == 0)
		goto merr;
	m->m_len = m->m_pkthdr.len = MCLBYTES;

	if (bus_dmamap_load_mbuf(sc->sc_dmat, map, m,
	    wait ? BUS_DMA_WAITOK : BUS_DMA_NOWAIT) != 0) {
		printf("%s: could not load mbuf dma map\n", DEVNAME(sc));
		goto err;
d1669 28
a1696 7
	return (m);
 merr:
	printf("%s: unable to allocate mbuf\n", DEVNAME(sc));
 err:
	if (m != NULL)
		m_freem(m);
	return (NULL);
d1698 1
@


1.12
log
@BUS_DMA_ZERO instead of alloc, map, bzero.

ok krw@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.11 2009/08/13 14:24:47 jasper Exp $	*/
a1080 7
	if (sc->sc_rxbuf[MYX_RXSMALL] == NULL ||
	    sc->sc_rxbufdesc[MYX_RXSMALL] == NULL ||
	    sc->sc_rxbuf[MYX_RXBIG] == NULL ||
	    sc->sc_rxbufdesc[MYX_RXBIG] == NULL) {
		printf("%s: failed to allocate rx buffers\n", DEVNAME(sc));
		goto err;
	}
@


1.11
log
@- consistify cfdriver for the ethernet drivers (0 -> NULL)

ok dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.10 2008/11/28 02:44:18 brad Exp $	*/
d511 1
a511 1
	    BUS_DMA_WAITOK) != 0)
a519 1
	bzero(mxm->mxm_kva, mxm->mxm_size);
@


1.10
log
@Eliminate the redundant bits of code for MTU and multicast handling
from the individual drivers now that ether_ioctl() handles this.

Shrinks the i386 kernels by..
RAMDISK - 2176 bytes
RAMDISKB - 1504 bytes
RAMDISKC - 736 bytes

Tested by naddy@@/okan@@/sthen@@/brad@@/todd@@/jmc@@ and lots of users.
Build tested on almost all archs by todd@@/brad@@

ok naddy@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.9 2008/10/02 20:21:14 brad Exp $	*/
d183 1
a183 1
	0, "myx", DV_IFNET
@


1.9
log
@First step towards cleaning up the Ethernet driver ioctl handling.
Move calling ether_ioctl() from the top of the ioctl function, which
at the moment does absolutely nothing, to the default switch case.
Thus allowing drivers to define their own ioctl handlers and then
falling back on ether_ioctl(). The only functional change this results
in at the moment is having all Ethernet drivers returning the proper
errno of ENOTTY instead of EINVAL/ENXIO when encountering unknown
ioctl's.

Shrinks the i386 kernels by..
RAMDISK - 1024 bytes
RAMDISKB -  1120 bytes
RAMDISKC - 832 bytes

Tested by martin@@/jsing@@/todd@@/brad@@
Build tested on almost all archs by todd@@/brad@@

ok jsing@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.8 2008/09/10 14:01:22 blambert Exp $	*/
d834 1
a844 15
		break;

	case SIOCSIFMTU:
		if (ifr->ifr_mtu < ETHERMIN || ifr->ifr_mtu > ifp->if_hardmtu)
			error = EINVAL;
		else if (ifp->if_mtu != ifr->ifr_mtu)
			ifp->if_mtu = ifr->ifr_mtu;
		break;

	case SIOCADDMULTI:
		error = ether_addmulti(ifr, &sc->sc_ac);
		break;

	case SIOCDELMULTI:
		error = ether_delmulti(ifr, &sc->sc_ac);
@


1.8
log
@Convert timeout_add() calls using multiples of hz to timeout_add_sec()

Really just the low-hanging fruit of (hopefully) forthcoming timeout
conversions.

ok art@@, krw@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.7 2008/05/23 08:49:27 brad Exp $	*/
a824 4
	if ((error = ether_ioctl(ifp, &sc->sc_ac, cmd, data)) > 0) {
		splx(s);
		return (error);
	}
d867 1
a867 1
		error = ENOTTY;
a877 1

@


1.7
log
@Simplify the combination use of pci_mapreg_type()/pci_mapreg_map() as
suggested by dlg@@ awhile ago.

ok dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.6 2008/01/16 19:30:19 thib Exp $	*/
d293 1
a293 1
	timeout_add(&sc->sc_tick, hz);
d813 1
a813 1
	timeout_add(&sc->sc_tick, hz);
@


1.6
log
@Set the baudrate with IF_Gbps(10); and remove an
XXX comment now that if_baudrate is 64bits.

ok reyk@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.5 2007/06/01 18:07:08 reyk Exp $	*/
d215 1
a216 10
	switch (memtype) {
	case PCI_MAPREG_TYPE_MEM | PCI_MAPREG_MEM_TYPE_32BIT:
	case PCI_MAPREG_TYPE_MEM | PCI_MAPREG_MEM_TYPE_64BIT:
		break;
	default:
		printf(": invalid memory type: 0x%x\n", memtype);
		return;
	}

	/* Map the PCI memory space */
d218 1
a218 1
	    &sc->sc_memh, NULL, &sc->sc_mems, 0) != 0) {
@


1.5
log
@initialize the rings
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.4 2007/05/31 22:09:09 reyk Exp $	*/
d291 1
a291 1
	ifp->if_baudrate = ULONG_MAX;	/* XXX fix if_baudrate */
@


1.4
log
@further improvement of the bus space i/o. firmware loading, booting,
and card initalization works now.

thanks to dlg@@ who pointed me to the fact that
bus_space_write_region_N and bus_space_write_raw_region_N use count of
elements vs. size of buffer arguments.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.3 2007/05/31 19:14:05 reyk Exp $	*/
d60 1
d64 1
a64 1
#define MYXDBG_INTR	(2<<0)	/* interrupts */
d86 5
d112 4
d127 3
a129 3
	int			 sc_txringsize;
	int			 sc_rxringsize;
	int			 sc_txndesc;
d132 5
d178 3
d248 1
a248 1
		goto err3;
d252 1
a252 1
	    sizeof(struct myx_status), MYXALIGN_CMD, "status") != 0) {
d254 1
a254 1
		goto err2;
a257 8
	sc->sc_rxdescsize = MYX_NRXDESC * sizeof(struct myx_rxdesc);
	if (myx_dmamem_alloc(sc, &sc->sc_rxdma,
	    sc->sc_rxdescsize, MYXALIGN_DATA, "rxdesc") != 0) {
		printf(": failed to allocate Rx descriptor DMA memory\n");
		goto err1;
	}
	sc->sc_rxdesc = (struct myx_rxdesc *)sc->sc_rxdma.mxm_kva;

d282 1
a282 1
	IFQ_SET_MAXLEN(&ifp->if_snd, sc->sc_txndesc - 1);
d309 1
a309 1
	myx_dmamem_free(sc, &sc->sc_rxdma);
d311 1
a311 1
	myx_dmamem_free(sc, &sc->sc_stsdma);
a312 2
	myx_dmamem_free(sc, &sc->sc_paddma);
 err3:
d419 1
a419 2
	myx_read(sc, MYX_HEADER_POS,
	    (u_int8_t *)&fwhdroff, sizeof(fwhdroff));
d435 1
a435 1
	if (loadfirmware(MYXFW_UNALIGNED, &fw, &fwlen) != 0) {
d515 1
a515 1
	    mxm->mxm_size, 0, BUS_DMA_NOWAIT | BUS_DMA_ALLOCNOW,
d520 1
a520 1
	    BUS_DMA_NOWAIT) != 0)
d523 1
a523 1
	    mxm->mxm_size, &mxm->mxm_kva, BUS_DMA_NOWAIT) != 0)
d526 1
a526 1
	    mxm->mxm_size, NULL, BUS_DMA_NOWAIT) != 0)
d558 38
a595 3

	DPRINTF(MYXDBG_CMD, "%s(%s) command %d\n", DEVNAME(sc),
	    __func__, cmd);
d598 2
a599 2
	mc->mc_addr_high = MYX_ADDRHIGH(map->dm_segs[0].ds_addr);
	mc->mc_addr_low = MYX_ADDRLOW(map->dm_segs[0].ds_addr);
d618 3
a620 3
	DPRINTF(MYXDBG_CMD, "%s(%s): command %d completed, i %d, "
	    "result 0x%x, data 0x%x (%u)\n", DEVNAME(sc), __func__, cmd, i,
	    result, data, data);
d637 2
a638 2
	bc->bc_addr_high = MYX_ADDRHIGH(map->dm_segs[0].ds_addr);
	bc->bc_addr_low = MYX_ADDRLOW(map->dm_segs[0].ds_addr);
d681 2
a682 2
	rc.rc_addr_high = MYX_ADDRHIGH(map->dm_segs[0].ds_addr);
	rc.rc_addr_low = MYX_ADDRLOW(map->dm_segs[0].ds_addr);
d684 2
a685 2
	rc.rc_rdma_high = MYX_ADDRHIGH(pad->dm_segs[0].ds_addr);
	rc.rc_rdma_low = MYX_ADDRLOW(pad->dm_segs[0].ds_addr);
d716 1
a716 1
	u_int32_t		 result;
a717 1
	bus_dmamap_t		 map;
d730 3
a732 4
	bzero(&mc, sizeof(mc));
	mc.mc_data0 = htobe32(sc->sc_rxdescsize);
	if (myx_cmd(sc, MYXCMD_SET_INTRQSZ, &mc, NULL) != 0) {
		printf("%s: failed to set Rx DMA size\n", DEVNAME(sc));
d735 2
d738 3
a740 6
	bzero(&mc, sizeof(mc));
	map = sc->sc_rxdma.mxm_map;
	mc.mc_data0 = MYX_ADDRLOW(map->dm_segs[0].ds_addr);
	mc.mc_data1 = MYX_ADDRHIGH(map->dm_segs[0].ds_addr);
	if (myx_cmd(sc, MYXCMD_SET_INTRQSZ, &mc, NULL) != 0) {
		printf("%s: failed to set Rx DMA address\n", DEVNAME(sc));
d744 3
a746 3
	bzero(&mc, sizeof(mc));
	if (myx_cmd(sc, MYXCMD_GET_INTRCOALDELAYOFF, &mc, &result) != 0) {
		printf("%s: failed to get IRQ coal offset\n", DEVNAME(sc));
a748 1
	sc->sc_irqcoaloff = result;
d750 2
a751 3
	bzero(&mc, sizeof(mc));
	if (myx_cmd(sc, MYXCMD_GET_INTRACKOFF, &mc, &result) != 0) {
		printf("%s: failed to get IRQ ack offset\n", DEVNAME(sc));
a753 1
	sc->sc_irqclaimoff = result;
d755 2
a756 3
	bzero(&mc, sizeof(mc));
	if (myx_cmd(sc, MYXCMD_GET_INTRDEASSERTOFF, &mc, &result) != 0) {
		printf("%s: failed to get IRQ deassert offset\n", DEVNAME(sc));
a758 5
	sc->sc_irqdeassertoff = result;

	/* XXX */
	sc->sc_txndesc = 2;
	sc->sc_rxndesc = 2;
d797 2
d906 4
d911 1
a911 1
	if (myx_setlladdr(sc, LLADDR(ifp->if_sadl)) != 0)
d914 6
d932 7
d961 9
d971 6
a976 1
	if (!sc->sc_active || sc->sc_sts->ms_isvalid == 0)
d979 39
a1017 1
	DPRINTF(MYXDBG_INTR, "%s(%s): interrupt\n", DEVNAME(sc), __func__);
d1019 257
@


1.3
log
@enable all debugging messages by default if the driver is compiled with
MYX_DEBUG
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.2 2007/05/31 19:12:56 reyk Exp $	*/
d141 1
d143 1
d221 2
a222 2
	if (myx_dmamem_alloc(sc, &sc->sc_cmddma,
	    sizeof(struct myx_cmd), MYXALIGN_CMD, "cmd") != 0) {
d391 1
a391 1
		myx_write(sc, i + MYX_FW, fw + i, min(256, fwlen - i));
d419 1
a419 1
	myx_read(sc, MYX_HEADER_POS, fw, fwlen);
d472 10
a481 1
	bus_space_read_region_1(sc->sc_memt, sc->sc_memh, off, ptr, len);
d487 10
a496 1
	bus_space_write_region_1(sc->sc_memt, sc->sc_memh, off, ptr, len);
d550 1
d568 4
a571 1
		if (mr->mr_result != 0xffffffff)
d576 3
a578 3
	DPRINTF(MYXDBG_CMD, "%s(%s): command %d completed, "
	    "result %x, data %x\n", DEVNAME(sc), __func__, cmd,
	    betoh32(mr->mr_result), betoh32(mr->mr_data));
d580 1
a580 1
	if (betoh32(mr->mr_result) != 0)
d584 1
a584 1
		*r = betoh32(mr->mr_data);
d609 1
a609 1
	for (i = 0; i < 2000; i++) {
d614 1
a614 1
		delay(100);
d617 2
a618 2
	DPRINTF(MYXDBG_CMD, "%s(%s): boot completed, result %x\n",
	    DEVNAME(sc), __func__, betoh32(*status));
d652 1
a652 1
	for (i = 0; i < 200; i++) {
d660 1
a660 1
	DPRINTF(MYXDBG_CMD, "%s(%s): dummy RDMA %s, result %x\n",
d662 1
a662 1
	    do_enable ? "enabled" : "disabled", betoh32(*status));
@


1.2
log
@fix the myx_write function
@
text
@d1 1
a1 1
/*	$OpenBSD: if_myx.c,v 1.1 2007/05/31 18:23:42 reyk Exp $	*/
d65 1
a65 1
int myx_debug = 0;
@


1.1
log
@initial bits of a new driver for the Myricom Myri-10G Lanai-Z8E 10Gb
Ethernet chipset. not working yet.

ok dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d476 1
a476 1
	bus_space_write_region_4(sc->sc_memt, sc->sc_memh, off, ptr, len);
@

