head	1.98;
access;
symbols
	OPENBSD_6_2:1.98.0.4
	OPENBSD_6_2_BASE:1.98
	OPENBSD_6_1:1.97.0.4
	OPENBSD_6_1_BASE:1.97
	OPENBSD_6_0:1.96.0.4
	OPENBSD_6_0_BASE:1.96
	OPENBSD_5_9:1.95.0.2
	OPENBSD_5_9_BASE:1.95
	OPENBSD_5_8:1.91.0.4
	OPENBSD_5_8_BASE:1.91
	OPENBSD_5_7:1.85.0.4
	OPENBSD_5_7_BASE:1.85
	OPENBSD_5_6:1.81.0.4
	OPENBSD_5_6_BASE:1.81
	OPENBSD_5_5:1.77.0.12
	OPENBSD_5_5_BASE:1.77
	OPENBSD_5_4:1.77.0.8
	OPENBSD_5_4_BASE:1.77
	OPENBSD_5_3:1.77.0.6
	OPENBSD_5_3_BASE:1.77
	OPENBSD_5_2:1.77.0.4
	OPENBSD_5_2_BASE:1.77
	OPENBSD_5_1_BASE:1.77
	OPENBSD_5_1:1.77.0.2
	OPENBSD_5_0:1.76.0.6
	OPENBSD_5_0_BASE:1.76
	OPENBSD_4_9:1.76.0.4
	OPENBSD_4_9_BASE:1.76
	OPENBSD_4_8:1.76.0.2
	OPENBSD_4_8_BASE:1.76
	OPENBSD_4_7:1.75.0.2
	OPENBSD_4_7_BASE:1.75
	OPENBSD_4_6:1.71.0.4
	OPENBSD_4_6_BASE:1.71
	OPENBSD_4_5:1.70.0.2
	OPENBSD_4_5_BASE:1.70
	OPENBSD_4_4:1.53.0.2
	OPENBSD_4_4_BASE:1.53
	OPENBSD_4_3:1.52.0.2
	OPENBSD_4_3_BASE:1.52
	OPENBSD_4_2:1.49.0.2
	OPENBSD_4_2_BASE:1.49
	OPENBSD_4_1:1.39.0.2
	OPENBSD_4_1_BASE:1.39
	OPENBSD_4_0:1.9.0.2
	OPENBSD_4_0_BASE:1.9
	OPENBSD_3_9:1.4.0.2
	OPENBSD_3_9_BASE:1.4;
locks; strict;
comment	@ * @;


1.98
date	2017.07.12.14.25.36;	author mikeb;	state Exp;
branches;
next	1.97;
commitid	EQxnB2fCFUCj0qyZ;

1.97
date	2017.01.22.10.17.38;	author dlg;	state Exp;
branches;
next	1.96;
commitid	VyLWTsbepAOk7VQM;

1.96
date	2016.04.13.10.34.32;	author mpi;	state Exp;
branches;
next	1.95;
commitid	8YSL8ByWzGeIGBiJ;

1.95
date	2015.11.25.03.09.59;	author dlg;	state Exp;
branches;
next	1.94;
commitid	B0kwmVGiD5DVx4kv;

1.94
date	2015.11.24.13.33.17;	author mpi;	state Exp;
branches;
next	1.93;
commitid	5DvsamK0GblTp8ww;

1.93
date	2015.11.20.03.35.23;	author dlg;	state Exp;
branches;
next	1.92;
commitid	eYnPulzvLjDImPCa;

1.92
date	2015.10.25.13.04.28;	author mpi;	state Exp;
branches;
next	1.91;
commitid	hPF95ClMUQfeqQDX;

1.91
date	2015.06.24.09.40.54;	author mpi;	state Exp;
branches;
next	1.90;
commitid	MVWrtktB46JRxFWT;

1.90
date	2015.05.29.00.37.10;	author uebayasi;	state Exp;
branches;
next	1.89;
commitid	fK1KUxmxCh2v4tEt;

1.89
date	2015.05.29.00.33.37;	author uebayasi;	state Exp;
branches;
next	1.88;
commitid	k9pN2wgTn5cUwDek;

1.88
date	2015.04.30.07.52.00;	author mpi;	state Exp;
branches;
next	1.87;
commitid	pTRq8Jb3T5WeNn6X;

1.87
date	2015.04.01.16.09.21;	author uebayasi;	state Exp;
branches;
next	1.86;
commitid	yZOBwQ3w4yXme153;

1.86
date	2015.03.14.03.38.48;	author jsg;	state Exp;
branches;
next	1.85;
commitid	p4LJxGKbi0BU2cG6;

1.85
date	2015.02.10.23.22.39;	author brad;	state Exp;
branches;
next	1.84;
commitid	TLO34Kp2tTdJqKJt;

1.84
date	2015.02.10.02.57.32;	author pelikan;	state Exp;
branches;
next	1.83;
commitid	CsGpnijgOcAILIF6;

1.83
date	2014.12.22.02.28.52;	author tedu;	state Exp;
branches;
next	1.82;
commitid	yM2VFFhpDTeFQlve;

1.82
date	2014.12.01.01.59.45;	author brad;	state Exp;
branches;
next	1.81;
commitid	EQg9jRWkayVpNA1w;

1.81
date	2014.07.13.23.10.23;	author deraadt;	state Exp;
branches;
next	1.80;
commitid	JtO5uXxVcnZfhUkR;

1.80
date	2014.07.12.18.48.52;	author tedu;	state Exp;
branches;
next	1.79;
commitid	OBNa5kfxQ2UXoiIw;

1.79
date	2014.07.10.11.15.52;	author dlg;	state Exp;
branches;
next	1.78;
commitid	CeBmYQKA1t5MODym;

1.78
date	2014.07.08.05.35.19;	author dlg;	state Exp;
branches;
next	1.77;
commitid	0QJleeeWqZmC5anF;

1.77
date	2011.11.29.11.53.25;	author jsing;	state Exp;
branches;
next	1.76;

1.76
date	2010.05.19.15.27.35;	author oga;	state Exp;
branches;
next	1.75;

1.75
date	2009.11.17.03.21.36;	author sthen;	state Exp;
branches;
next	1.74;

1.74
date	2009.08.13.14.24.47;	author jasper;	state Exp;
branches;
next	1.73;

1.73
date	2009.08.10.17.25.07;	author deraadt;	state Exp;
branches;
next	1.72;

1.72
date	2009.08.09.11.40.56;	author deraadt;	state Exp;
branches;
next	1.71;

1.71
date	2009.06.02.12.32.06;	author deraadt;	state Exp;
branches;
next	1.70;

1.70
date	2009.02.01.14.05.52;	author dlg;	state Exp;
branches;
next	1.69;

1.69
date	2008.12.30.12.27.57;	author reyk;	state Exp;
branches;
next	1.68;

1.68
date	2008.12.12.06.12.34;	author dlg;	state Exp;
branches;
next	1.67;

1.67
date	2008.12.05.01.10.25;	author dlg;	state Exp;
branches;
next	1.66;

1.66
date	2008.12.03.05.00.22;	author dlg;	state Exp;
branches;
next	1.65;

1.65
date	2008.12.03.04.07.20;	author dlg;	state Exp;
branches;
next	1.64;

1.64
date	2008.11.28.02.44.18;	author brad;	state Exp;
branches;
next	1.63;

1.63
date	2008.11.25.17.01.14;	author dlg;	state Exp;
branches;
next	1.62;

1.62
date	2008.11.25.16.02.06;	author dlg;	state Exp;
branches;
next	1.61;

1.61
date	2008.11.24.19.18.19;	author dlg;	state Exp;
branches;
next	1.60;

1.60
date	2008.11.24.18.36.01;	author dlg;	state Exp;
branches;
next	1.59;

1.59
date	2008.11.24.16.13.47;	author dlg;	state Exp;
branches;
next	1.58;

1.58
date	2008.11.24.13.10.16;	author dlg;	state Exp;
branches;
next	1.57;

1.57
date	2008.11.24.12.34.29;	author dlg;	state Exp;
branches;
next	1.56;

1.56
date	2008.10.29.01.14.47;	author deraadt;	state Exp;
branches;
next	1.55;

1.55
date	2008.10.02.20.21.14;	author brad;	state Exp;
branches;
next	1.54;

1.54
date	2008.09.10.14.01.23;	author blambert;	state Exp;
branches;
next	1.53;

1.53
date	2008.07.07.00.42.34;	author dlg;	state Exp;
branches;
next	1.52;

1.52
date	2007.11.28.11.13.47;	author reyk;	state Exp;
branches;
next	1.51;

1.51
date	2007.10.28.12.38.43;	author dlg;	state Exp;
branches;
next	1.50;

1.50
date	2007.10.23.07.15.18;	author dlg;	state Exp;
branches;
next	1.49;

1.49
date	2007.06.15.02.29.50;	author dlg;	state Exp;
branches;
next	1.48;

1.48
date	2007.05.26.17.13.30;	author jason;	state Exp;
branches;
next	1.47;

1.47
date	2007.05.04.05.08.55;	author deraadt;	state Exp;
branches;
next	1.46;

1.46
date	2007.05.04.01.52.51;	author reyk;	state Exp;
branches;
next	1.45;

1.45
date	2007.04.22.13.17.55;	author dlg;	state Exp;
branches;
next	1.44;

1.44
date	2007.04.21.19.24.59;	author deraadt;	state Exp;
branches;
next	1.43;

1.43
date	2007.04.21.12.52.46;	author dlg;	state Exp;
branches;
next	1.42;

1.42
date	2007.04.17.03.55.07;	author dlg;	state Exp;
branches;
next	1.41;

1.41
date	2007.04.17.02.07.05;	author dlg;	state Exp;
branches;
next	1.40;

1.40
date	2007.04.14.23.35.35;	author reyk;	state Exp;
branches;
next	1.39;

1.39
date	2007.01.30.09.54.24;	author reyk;	state Exp;
branches;
next	1.38;

1.38
date	2006.12.14.10.10.20;	author dlg;	state Exp;
branches;
next	1.37;

1.37
date	2006.12.03.14.52.45;	author reyk;	state Exp;
branches;
next	1.36;

1.36
date	2006.12.03.13.58.58;	author reyk;	state Exp;
branches;
next	1.35;

1.35
date	2006.11.09.18.50.30;	author reyk;	state Exp;
branches;
next	1.34;

1.34
date	2006.11.09.18.31.25;	author reyk;	state Exp;
branches;
next	1.33;

1.33
date	2006.11.09.18.29.19;	author reyk;	state Exp;
branches;
next	1.32;

1.32
date	2006.11.06.07.31.54;	author reyk;	state Exp;
branches;
next	1.31;

1.31
date	2006.11.02.23.43.35;	author dlg;	state Exp;
branches;
next	1.30;

1.30
date	2006.11.02.23.39.22;	author dlg;	state Exp;
branches;
next	1.29;

1.29
date	2006.11.02.23.35.16;	author dlg;	state Exp;
branches;
next	1.28;

1.28
date	2006.11.02.23.32.16;	author dlg;	state Exp;
branches;
next	1.27;

1.27
date	2006.11.02.23.29.04;	author dlg;	state Exp;
branches;
next	1.26;

1.26
date	2006.11.02.23.28.04;	author dlg;	state Exp;
branches;
next	1.25;

1.25
date	2006.11.02.05.10.10;	author dlg;	state Exp;
branches;
next	1.24;

1.24
date	2006.11.02.04.56.04;	author dlg;	state Exp;
branches;
next	1.23;

1.23
date	2006.11.02.04.32.59;	author dlg;	state Exp;
branches;
next	1.22;

1.22
date	2006.11.02.02.17.22;	author brad;	state Exp;
branches;
next	1.21;

1.21
date	2006.11.02.02.10.12;	author dlg;	state Exp;
branches;
next	1.20;

1.20
date	2006.11.02.02.08.18;	author dlg;	state Exp;
branches;
next	1.19;

1.19
date	2006.11.02.02.01.36;	author dlg;	state Exp;
branches;
next	1.18;

1.18
date	2006.11.02.01.54.13;	author dlg;	state Exp;
branches;
next	1.17;

1.17
date	2006.11.02.00.38.34;	author fkr;	state Exp;
branches;
next	1.16;

1.16
date	2006.11.01.13.23.06;	author claudio;	state Exp;
branches;
next	1.15;

1.15
date	2006.11.01.10.21.57;	author dlg;	state Exp;
branches;
next	1.14;

1.14
date	2006.11.01.05.45.15;	author dlg;	state Exp;
branches;
next	1.13;

1.13
date	2006.11.01.05.06.26;	author dlg;	state Exp;
branches;
next	1.12;

1.12
date	2006.11.01.04.34.23;	author dlg;	state Exp;
branches;
next	1.11;

1.11
date	2006.10.31.07.01.08;	author dlg;	state Exp;
branches;
next	1.10;

1.10
date	2006.10.31.06.04.15;	author dlg;	state Exp;
branches;
next	1.9;

1.9
date	2006.05.31.06.46.12;	author brad;	state Exp;
branches;
next	1.8;

1.8
date	2006.05.28.00.20.21;	author brad;	state Exp;
branches;
next	1.7;

1.7
date	2006.05.28.00.04.24;	author jason;	state Exp;
branches;
next	1.6;

1.6
date	2006.03.25.22.41.46;	author djm;	state Exp;
branches;
next	1.5;

1.5
date	2006.03.04.03.33.05;	author brad;	state Exp;
branches;
next	1.4;

1.4
date	2006.02.26.04.30.08;	author brad;	state Exp;
branches;
next	1.3;

1.3
date	2006.02.26.02.21.31;	author brad;	state Exp;
branches;
next	1.2;

1.2
date	2006.02.26.02.13.54;	author brad;	state Exp;
branches;
next	1.1;

1.1
date	2006.02.25.23.49.04;	author reyk;	state Exp;
branches;
next	;


desc
@@


1.98
log
@Reshuffle vic_start and get rid of the dequeue begin/rollback/commit dance

Tested on ESXi 5.5.0, OK reyk
@
text
@/*	$OpenBSD: if_vic.c,v 1.97 2017/01/22 10:17:38 dlg Exp $	*/

/*
 * Copyright (c) 2006 Reyk Floeter <reyk@@openbsd.org>
 * Copyright (c) 2006 David Gwynne <dlg@@openbsd.org>
 *
 * Permission to use, copy, modify, and distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 */

/*
 * Driver for the VMware Virtual NIC ("vmxnet")
 */

#include "bpfilter.h"

#include <sys/param.h>
#include <sys/systm.h>
#include <sys/sockio.h>
#include <sys/mbuf.h>
#include <sys/kernel.h>
#include <sys/socket.h>
#include <sys/malloc.h>
#include <sys/timeout.h>
#include <sys/device.h>

#include <machine/bus.h>
#include <machine/intr.h>

#include <net/if.h>
#include <net/if_media.h>

#if NBPFILTER > 0
#include <net/bpf.h>
#endif

#include <netinet/in.h>
#include <netinet/if_ether.h>

#include <dev/pci/pcireg.h>
#include <dev/pci/pcivar.h>
#include <dev/pci/pcidevs.h>

#define VIC_PCI_BAR		PCI_MAPREG_START /* Base Address Register */

#define VIC_LANCE_SIZE		0x20
#define VIC_MORPH_SIZE		0x04
#define  VIC_MORPH_MASK			0xffff
#define  VIC_MORPH_LANCE		0x2934
#define  VIC_MORPH_VMXNET		0x4392
#define VIC_VMXNET_SIZE		0x40
#define VIC_LANCE_MINLEN	(VIC_LANCE_SIZE + VIC_MORPH_SIZE + \
				    VIC_VMXNET_SIZE)

#define VIC_MAGIC		0xbabe864f

/* Register address offsets */
#define VIC_DATA_ADDR		0x0000		/* Shared data address */
#define VIC_DATA_LENGTH		0x0004		/* Shared data length */
#define VIC_Tx_ADDR		0x0008		/* Tx pointer address */

/* Command register */
#define VIC_CMD			0x000c		/* Command register */
#define  VIC_CMD_INTR_ACK	0x0001	/* Acknowledge interrupt */
#define  VIC_CMD_MCASTFIL	0x0002	/* Multicast address filter */
#define   VIC_CMD_MCASTFIL_LENGTH	2
#define  VIC_CMD_IFF		0x0004	/* Interface flags */
#define   VIC_CMD_IFF_PROMISC	0x0001		/* Promiscous enabled */
#define   VIC_CMD_IFF_BROADCAST	0x0002		/* Broadcast enabled */
#define   VIC_CMD_IFF_MULTICAST	0x0004		/* Multicast enabled */
#define  VIC_CMD_INTR_DISABLE	0x0020	/* Disable interrupts */
#define  VIC_CMD_INTR_ENABLE	0x0040	/* Enable interrupts */
#define  VIC_CMD_Tx_DONE	0x0100	/* Tx done register */
#define  VIC_CMD_NUM_Rx_BUF	0x0200	/* Number of Rx buffers */
#define  VIC_CMD_NUM_Tx_BUF	0x0400	/* Number of Tx buffers */
#define  VIC_CMD_NUM_PINNED_BUF	0x0800	/* Number of pinned buffers */
#define  VIC_CMD_HWCAP		0x1000	/* Capability register */
#define   VIC_CMD_HWCAP_SG		(1<<0) /* Scatter-gather transmits */
#define   VIC_CMD_HWCAP_CSUM_IPv4	(1<<1) /* TCP/UDP cksum */
#define   VIC_CMD_HWCAP_CSUM_ALL	(1<<3) /* Hardware cksum */
#define   VIC_CMD_HWCAP_CSUM \
	(VIC_CMD_HWCAP_CSUM_IPv4 | VIC_CMD_HWCAP_CSUM_ALL)
#define   VIC_CMD_HWCAP_DMA_HIGH		(1<<4) /* High DMA mapping */
#define   VIC_CMD_HWCAP_TOE		(1<<5) /* TCP offload engine */
#define   VIC_CMD_HWCAP_TSO		(1<<6) /* TCP segmentation offload */
#define   VIC_CMD_HWCAP_TSO_SW		(1<<7) /* Software TCP segmentation */
#define   VIC_CMD_HWCAP_VPROM		(1<<8) /* Virtual PROM available */
#define   VIC_CMD_HWCAP_VLAN_Tx		(1<<9) /* Hardware VLAN MTU Rx */
#define   VIC_CMD_HWCAP_VLAN_Rx		(1<<10) /* Hardware VLAN MTU Tx */
#define   VIC_CMD_HWCAP_VLAN_SW		(1<<11)	/* Software VLAN MTU */
#define   VIC_CMD_HWCAP_VLAN \
	(VIC_CMD_HWCAP_VLAN_Tx | VIC_CMD_HWCAP_VLAN_Rx | \
	VIC_CMD_HWCAP_VLAN_SW)
#define  VIC_CMD_HWCAP_BITS \
	"\20\01SG\02CSUM4\03CSUM\04HDMA\05TOE\06TSO" \
	"\07TSOSW\10VPROM\13VLANTx\14VLANRx\15VLANSW"
#define  VIC_CMD_FEATURE	0x2000	/* Additional feature register */
#define   VIC_CMD_FEATURE_0_Tx		(1<<0)
#define   VIC_CMD_FEATURE_TSO		(1<<1)

#define VIC_LLADDR		0x0010		/* MAC address register */
#define VIC_VERSION_MINOR	0x0018		/* Minor version register */
#define VIC_VERSION_MAJOR	0x001c		/* Major version register */
#define VIC_VERSION_MAJOR_M	0xffff0000

/* Status register */
#define VIC_STATUS		0x0020
#define  VIC_STATUS_CONNECTED		(1<<0)
#define  VIC_STATUS_ENABLED		(1<<1)

#define VIC_TOE_ADDR		0x0024		/* TCP offload address */

/* Virtual PROM address */
#define VIC_VPROM		0x0028
#define VIC_VPROM_LENGTH	6

/* Shared DMA data structures */

struct vic_sg {
	u_int32_t	sg_addr_low;
	u_int16_t	sg_addr_high;
	u_int16_t	sg_length;
} __packed;

#define VIC_SG_MAX		6
#define VIC_SG_ADDR_MACH	0
#define VIC_SG_ADDR_PHYS	1
#define VIC_SG_ADDR_VIRT	3

struct vic_sgarray {
	u_int16_t	sa_addr_type;
	u_int16_t	sa_length;
	struct vic_sg	sa_sg[VIC_SG_MAX];
} __packed;

struct vic_rxdesc {
	u_int64_t	rx_physaddr;
	u_int32_t	rx_buflength;
	u_int32_t	rx_length;
	u_int16_t	rx_owner;
	u_int16_t	rx_flags;
	u_int32_t	rx_priv;
} __packed;

#define VIC_RX_FLAGS_CSUMHW_OK	0x0001

struct vic_txdesc {
	u_int16_t		tx_flags;
	u_int16_t		tx_owner;
	u_int32_t		tx_priv;
	u_int32_t		tx_tsomss;
	struct vic_sgarray	tx_sa;
} __packed;

#define VIC_TX_FLAGS_KEEP	0x0001
#define VIC_TX_FLAGS_TXURN	0x0002
#define VIC_TX_FLAGS_CSUMHW	0x0004
#define VIC_TX_FLAGS_TSO	0x0008
#define VIC_TX_FLAGS_PINNED	0x0010
#define VIC_TX_FLAGS_QRETRY	0x1000

struct vic_stats {
	u_int32_t		vs_tx_count;
	u_int32_t		vs_tx_packets;
	u_int32_t		vs_tx_0copy;
	u_int32_t		vs_tx_copy;
	u_int32_t		vs_tx_maxpending;
	u_int32_t		vs_tx_stopped;
	u_int32_t		vs_tx_overrun;
	u_int32_t		vs_intr;
	u_int32_t		vs_rx_packets;
	u_int32_t		vs_rx_underrun;
} __packed;

#define VIC_NRXRINGS		2

struct vic_data {
	u_int32_t		vd_magic;

	struct {
		u_int32_t		length;
		u_int32_t		nextidx;
	}			vd_rx[VIC_NRXRINGS];

	u_int32_t		vd_irq;
	u_int32_t		vd_iff;

	u_int32_t		vd_mcastfil[VIC_CMD_MCASTFIL_LENGTH];

	u_int32_t		vd_reserved1[1];

	u_int32_t		vd_tx_length;
	u_int32_t		vd_tx_curidx;
	u_int32_t		vd_tx_nextidx;
	u_int32_t		vd_tx_stopped;
	u_int32_t		vd_tx_triggerlvl;
	u_int32_t		vd_tx_queued;
	u_int32_t		vd_tx_minlength;

	u_int32_t		vd_reserved2[6];

	u_int32_t		vd_rx_saved_nextidx[VIC_NRXRINGS];
	u_int32_t		vd_tx_saved_nextidx;

	u_int32_t		vd_length;
	u_int32_t		vd_rx_offset[VIC_NRXRINGS];
	u_int32_t		vd_tx_offset;
	u_int32_t		vd_debug;
	u_int32_t		vd_tx_physaddr;
	u_int32_t		vd_tx_physaddr_length;
	u_int32_t		vd_tx_maxlength;

	struct vic_stats	vd_stats;
} __packed;

#define VIC_OWNER_DRIVER	0
#define VIC_OWNER_DRIVER_PEND	1
#define VIC_OWNER_NIC		2
#define VIC_OWNER_NIC_PEND	3

#define VIC_JUMBO_FRAMELEN	9018
#define VIC_JUMBO_MTU		(VIC_JUMBO_FRAMELEN - ETHER_HDR_LEN - ETHER_CRC_LEN)

#define VIC_NBUF		100
#define VIC_NBUF_MAX		128
#define VIC_MAX_SCATTER		1	/* 8? */
#define VIC_QUEUE_SIZE		VIC_NBUF_MAX
#define VIC_INC(_x, _y)		(_x) = ((_x) + 1) % (_y)
#define VIC_TX_TIMEOUT		5

#define VIC_MIN_FRAMELEN	(ETHER_MIN_LEN - ETHER_CRC_LEN)

#define VIC_TXURN_WARN(_sc)	((_sc)->sc_txpending >= ((_sc)->sc_ntxbuf - 5))
#define VIC_TXURN(_sc)		((_sc)->sc_txpending >= (_sc)->sc_ntxbuf)

struct vic_rxbuf {
	bus_dmamap_t		rxb_dmamap;
	struct mbuf		*rxb_m;
};

struct vic_txbuf {
	bus_dmamap_t		txb_dmamap;
	struct mbuf		*txb_m;
};

struct vic_softc {
	struct device		sc_dev;

	pci_chipset_tag_t	sc_pc;
	pcitag_t		sc_tag;

	bus_space_tag_t		sc_iot;
	bus_space_handle_t	sc_ioh;
	bus_size_t		sc_ios;
	bus_dma_tag_t		sc_dmat;

	void			*sc_ih;

	struct timeout		sc_tick;

	struct arpcom		sc_ac;
	struct ifmedia		sc_media;

	u_int32_t		sc_nrxbuf;
	u_int32_t		sc_ntxbuf;
	u_int32_t		sc_cap;
	u_int32_t		sc_feature;
	u_int8_t		sc_lladdr[ETHER_ADDR_LEN];

	bus_dmamap_t		sc_dma_map;
	bus_dma_segment_t	sc_dma_seg;
	size_t			sc_dma_size;
	caddr_t			sc_dma_kva;
#define VIC_DMA_DVA(_sc)	((_sc)->sc_dma_map->dm_segs[0].ds_addr)
#define VIC_DMA_KVA(_sc)	((void *)(_sc)->sc_dma_kva)

	struct vic_data		*sc_data;

	struct {
		struct if_rxring	ring;
		struct vic_rxbuf	*bufs;
		struct vic_rxdesc	*slots;
		int			end;
		u_int			pktlen;
	}			sc_rxq[VIC_NRXRINGS];

	struct vic_txbuf	*sc_txbuf;
	struct vic_txdesc	*sc_txq;
	volatile u_int		sc_txpending;
};

struct cfdriver vic_cd = {
	NULL, "vic", DV_IFNET
};

int		vic_match(struct device *, void *, void *);
void		vic_attach(struct device *, struct device *, void *);

struct cfattach vic_ca = {
	sizeof(struct vic_softc), vic_match, vic_attach
};

int		vic_intr(void *);

int		vic_query(struct vic_softc *);
int		vic_alloc_data(struct vic_softc *);
int		vic_init_data(struct vic_softc *sc);
int		vic_uninit_data(struct vic_softc *sc);

u_int32_t	vic_read(struct vic_softc *, bus_size_t);
void		vic_write(struct vic_softc *, bus_size_t, u_int32_t);

u_int32_t	vic_read_cmd(struct vic_softc *, u_int32_t);

int		vic_alloc_dmamem(struct vic_softc *);
void		vic_free_dmamem(struct vic_softc *);

void		vic_link_state(struct vic_softc *);
void		vic_rx_fill(struct vic_softc *, int);
void		vic_rx_proc(struct vic_softc *, int);
void		vic_tx_proc(struct vic_softc *);
void		vic_iff(struct vic_softc *);
void		vic_getlladdr(struct vic_softc *);
void		vic_setlladdr(struct vic_softc *);
int		vic_media_change(struct ifnet *);
void		vic_media_status(struct ifnet *, struct ifmediareq *);
void		vic_start(struct ifnet *);
int		vic_load_txb(struct vic_softc *, struct vic_txbuf *,
		    struct mbuf *);
void		vic_watchdog(struct ifnet *);
int		vic_ioctl(struct ifnet *, u_long, caddr_t);
int		vic_rxrinfo(struct vic_softc *, struct if_rxrinfo *);
void		vic_init(struct ifnet *);
void		vic_stop(struct ifnet *);
void		vic_tick(void *);

#define DEVNAME(_s)	((_s)->sc_dev.dv_xname)

struct mbuf *vic_alloc_mbuf(struct vic_softc *, bus_dmamap_t, u_int);

const struct pci_matchid vic_devices[] = {
	{ PCI_VENDOR_VMWARE, PCI_PRODUCT_VMWARE_NET }
};

int
vic_match(struct device *parent, void *match, void *aux)
{
	struct pci_attach_args		*pa = aux;
	pcireg_t			memtype;
	bus_size_t			pcisize;
	bus_addr_t			pciaddr;

	switch (pa->pa_id) {
	case PCI_ID_CODE(PCI_VENDOR_VMWARE, PCI_PRODUCT_VMWARE_NET):
		return (1);

	case PCI_ID_CODE(PCI_VENDOR_AMD, PCI_PRODUCT_AMD_PCNET_PCI):
		memtype = pci_mapreg_type(pa->pa_pc, pa->pa_tag, VIC_PCI_BAR);
		if (pci_mapreg_info(pa->pa_pc, pa->pa_tag, VIC_PCI_BAR,
		    memtype, &pciaddr, &pcisize, NULL) != 0)
			break;

		if (pcisize > VIC_LANCE_MINLEN)
			return (2);

		break;
	}

	return (0);
}

void
vic_attach(struct device *parent, struct device *self, void *aux)
{
	struct vic_softc		*sc = (struct vic_softc *)self;
	struct pci_attach_args		*pa = aux;
	bus_space_handle_t		ioh;
	pcireg_t			r;
	pci_intr_handle_t		ih;
	struct ifnet			*ifp;

	sc->sc_pc = pa->pa_pc;
	sc->sc_tag = pa->pa_tag;
	sc->sc_dmat = pa->pa_dmat;

	r = pci_mapreg_type(sc->sc_pc, sc->sc_tag, VIC_PCI_BAR);
	if (pci_mapreg_map(pa, VIC_PCI_BAR, r, 0, &sc->sc_iot,
	    &ioh, NULL, &sc->sc_ios, 0) != 0) {
		printf(": unable to map system interface register\n");
		return;
	}

	switch (pa->pa_id) {
	case PCI_ID_CODE(PCI_VENDOR_VMWARE, PCI_PRODUCT_VMWARE_NET):
		if (bus_space_subregion(sc->sc_iot, ioh, 0, sc->sc_ios,
		    &sc->sc_ioh) != 0) {
			printf(": unable to map register window\n");
			goto unmap;
		}
		break;

	case PCI_ID_CODE(PCI_VENDOR_AMD, PCI_PRODUCT_AMD_PCNET_PCI):
		if (bus_space_subregion(sc->sc_iot, ioh, 
		    VIC_LANCE_SIZE + VIC_MORPH_SIZE, VIC_VMXNET_SIZE,
		    &sc->sc_ioh) != 0) {
			printf(": unable to map register window\n");
			goto unmap;
		}

		bus_space_barrier(sc->sc_iot, ioh, VIC_LANCE_SIZE, 4,
		    BUS_SPACE_BARRIER_READ);
		r = bus_space_read_4(sc->sc_iot, ioh, VIC_LANCE_SIZE);

		if ((r & VIC_MORPH_MASK) == VIC_MORPH_VMXNET)
			break;
		if ((r & VIC_MORPH_MASK) != VIC_MORPH_LANCE) {
			printf(": unexpect morph value (0x%08x)\n", r);
			goto unmap;
		}

		r &= ~VIC_MORPH_MASK;
		r |= VIC_MORPH_VMXNET;

		bus_space_write_4(sc->sc_iot, ioh, VIC_LANCE_SIZE, r);
		bus_space_barrier(sc->sc_iot, ioh, VIC_LANCE_SIZE, 4,
		    BUS_SPACE_BARRIER_WRITE);

		bus_space_barrier(sc->sc_iot, ioh, VIC_LANCE_SIZE, 4,
		    BUS_SPACE_BARRIER_READ);
		r = bus_space_read_4(sc->sc_iot, ioh, VIC_LANCE_SIZE);

		if ((r & VIC_MORPH_MASK) != VIC_MORPH_VMXNET) {
			printf(": unable to morph vlance chip\n");
			goto unmap;
		}

		break;
	}

	if (pci_intr_map(pa, &ih) != 0) {
		printf(": unable to map interrupt\n");
		goto unmap;
	}

	sc->sc_ih = pci_intr_establish(pa->pa_pc, ih, IPL_NET,
	    vic_intr, sc, DEVNAME(sc));
	if (sc->sc_ih == NULL) {
		printf(": unable to establish interrupt\n");
		goto unmap;
	}

	if (vic_query(sc) != 0) {
		/* error printed by vic_query */
		goto unmap;
	}

	if (vic_alloc_data(sc) != 0) {
		/* error printed by vic_alloc */
		goto unmap;
	}

	timeout_set(&sc->sc_tick, vic_tick, sc);

	bcopy(sc->sc_lladdr, sc->sc_ac.ac_enaddr, ETHER_ADDR_LEN);

	ifp = &sc->sc_ac.ac_if;
	ifp->if_softc = sc;
	ifp->if_flags = IFF_BROADCAST | IFF_SIMPLEX | IFF_MULTICAST;
	ifp->if_ioctl = vic_ioctl;
	ifp->if_start = vic_start;
	ifp->if_watchdog = vic_watchdog;
	ifp->if_hardmtu = VIC_JUMBO_MTU;
	strlcpy(ifp->if_xname, DEVNAME(sc), IFNAMSIZ);
	IFQ_SET_MAXLEN(&ifp->if_snd, sc->sc_ntxbuf - 1);

	ifp->if_capabilities = IFCAP_VLAN_MTU;

#if 0
	/* XXX interface capabilities */
	if (sc->sc_cap & VIC_CMD_HWCAP_VLAN)
		ifp->if_capabilities |= IFCAP_VLAN_HWTAGGING;
	if (sc->sc_cap & VIC_CMD_HWCAP_CSUM)
		ifp->if_capabilities |= IFCAP_CSUM_IPv4 | IFCAP_CSUM_TCPv4 |
		    IFCAP_CSUM_UDPv4;
#endif

	ifmedia_init(&sc->sc_media, 0, vic_media_change, vic_media_status);
	ifmedia_add(&sc->sc_media, IFM_ETHER | IFM_AUTO, 0, NULL);
	ifmedia_set(&sc->sc_media, IFM_ETHER | IFM_AUTO);

	if_attach(ifp);
	ether_ifattach(ifp);

	printf(": %s, address %s\n", pci_intr_string(pa->pa_pc, ih),
	    ether_sprintf(sc->sc_lladdr));

#ifdef VIC_DEBUG
	printf("%s: feature 0x%8x, cap 0x%8x, rx/txbuf %d/%d\n", DEVNAME(sc),
	    sc->sc_feature, sc->sc_cap, sc->sc_nrxbuf, sc->sc_ntxbuf);
#endif

	return;

unmap:
	bus_space_unmap(sc->sc_iot, ioh, sc->sc_ios);
	sc->sc_ios = 0;
}

int
vic_query(struct vic_softc *sc)
{
	u_int32_t			major, minor;

	major = vic_read(sc, VIC_VERSION_MAJOR);
	minor = vic_read(sc, VIC_VERSION_MINOR);

	/* Check for a supported version */
	if ((major & VIC_VERSION_MAJOR_M) !=
	    (VIC_MAGIC & VIC_VERSION_MAJOR_M)) {
		printf(": magic mismatch\n");
		return (1);
	}

	if (VIC_MAGIC > major || VIC_MAGIC < minor) {
		printf(": unsupported version (%X)\n",
		    major & ~VIC_VERSION_MAJOR_M);
		return (1);
	}

	sc->sc_nrxbuf = vic_read_cmd(sc, VIC_CMD_NUM_Rx_BUF);
	sc->sc_ntxbuf = vic_read_cmd(sc, VIC_CMD_NUM_Tx_BUF);
	sc->sc_feature = vic_read_cmd(sc, VIC_CMD_FEATURE);
	sc->sc_cap = vic_read_cmd(sc, VIC_CMD_HWCAP);

	vic_getlladdr(sc);

	if (sc->sc_nrxbuf > VIC_NBUF_MAX || sc->sc_nrxbuf == 0)
		sc->sc_nrxbuf = VIC_NBUF;
	if (sc->sc_ntxbuf > VIC_NBUF_MAX || sc->sc_ntxbuf == 0)
		sc->sc_ntxbuf = VIC_NBUF;

	return (0);
}

int
vic_alloc_data(struct vic_softc *sc)
{
	u_int8_t			*kva;
	u_int				offset;
	struct vic_rxdesc		*rxd;
	int				i, q;

	sc->sc_rxq[0].pktlen = MCLBYTES;
	sc->sc_rxq[1].pktlen = 4096;

	for (q = 0; q < VIC_NRXRINGS; q++) {
		sc->sc_rxq[q].bufs = mallocarray(sc->sc_nrxbuf,
		    sizeof(struct vic_rxbuf), M_DEVBUF, M_NOWAIT | M_ZERO);
		if (sc->sc_rxq[q].bufs == NULL) {
			printf(": unable to allocate rxbuf for ring %d\n", q);
			goto freerx;
		}
	}

	sc->sc_txbuf = mallocarray(sc->sc_ntxbuf, sizeof(struct vic_txbuf),
	    M_DEVBUF, M_NOWAIT);
	if (sc->sc_txbuf == NULL) {
		printf(": unable to allocate txbuf\n");
		goto freerx;
	}

	sc->sc_dma_size = sizeof(struct vic_data) +
	    (sc->sc_nrxbuf * VIC_NRXRINGS) * sizeof(struct vic_rxdesc) +
	    sc->sc_ntxbuf * sizeof(struct vic_txdesc);

	if (vic_alloc_dmamem(sc) != 0) {
		printf(": unable to allocate dma region\n");
		goto freetx;
	}
	kva = VIC_DMA_KVA(sc);

	/* set up basic vic data */
	sc->sc_data = VIC_DMA_KVA(sc);

	sc->sc_data->vd_magic = VIC_MAGIC;
	sc->sc_data->vd_length = sc->sc_dma_size;

	offset = sizeof(struct vic_data);

	/* set up the rx rings */

	for (q = 0; q < VIC_NRXRINGS; q++) {
		sc->sc_rxq[q].slots = (struct vic_rxdesc *)&kva[offset];
		sc->sc_data->vd_rx_offset[q] = offset;
		sc->sc_data->vd_rx[q].length = sc->sc_nrxbuf;

		for (i = 0; i < sc->sc_nrxbuf; i++) {
			rxd = &sc->sc_rxq[q].slots[i];

			rxd->rx_physaddr = 0;
			rxd->rx_buflength = 0;
			rxd->rx_length = 0;
			rxd->rx_owner = VIC_OWNER_DRIVER;

			offset += sizeof(struct vic_rxdesc);
		}
	}

	/* set up the tx ring */
	sc->sc_txq = (struct vic_txdesc *)&kva[offset];

	sc->sc_data->vd_tx_offset = offset;
	sc->sc_data->vd_tx_length = sc->sc_ntxbuf;

	return (0);
freetx:
	free(sc->sc_txbuf, M_DEVBUF, 0);
	q = VIC_NRXRINGS;
freerx:
	while (q--)
		free(sc->sc_rxq[q].bufs, M_DEVBUF, 0);

	return (1);
}

void
vic_rx_fill(struct vic_softc *sc, int q)
{
	struct vic_rxbuf		*rxb;
	struct vic_rxdesc		*rxd;
	u_int				slots;

	for (slots = if_rxr_get(&sc->sc_rxq[q].ring, sc->sc_nrxbuf);
	    slots > 0; slots--) {
		rxb = &sc->sc_rxq[q].bufs[sc->sc_rxq[q].end];
		rxd = &sc->sc_rxq[q].slots[sc->sc_rxq[q].end];

		rxb->rxb_m = vic_alloc_mbuf(sc, rxb->rxb_dmamap,
		    sc->sc_rxq[q].pktlen);
		if (rxb->rxb_m == NULL)
			break;

		bus_dmamap_sync(sc->sc_dmat, rxb->rxb_dmamap, 0,
		    rxb->rxb_m->m_pkthdr.len, BUS_DMASYNC_PREREAD);

		rxd->rx_physaddr = rxb->rxb_dmamap->dm_segs[0].ds_addr;
		rxd->rx_buflength = rxb->rxb_m->m_pkthdr.len;
		rxd->rx_length = 0;
		rxd->rx_owner = VIC_OWNER_NIC;

		VIC_INC(sc->sc_rxq[q].end, sc->sc_data->vd_rx[q].length);
	}
	if_rxr_put(&sc->sc_rxq[q].ring, slots);
}

int
vic_init_data(struct vic_softc *sc)
{
	struct vic_rxbuf		*rxb;
	struct vic_rxdesc		*rxd;
	struct vic_txbuf		*txb;

	int				q, i;

	for (q = 0; q < VIC_NRXRINGS; q++) {
		for (i = 0; i < sc->sc_nrxbuf; i++) {
			rxb = &sc->sc_rxq[q].bufs[i];
			rxd = &sc->sc_rxq[q].slots[i];

			if (bus_dmamap_create(sc->sc_dmat,
			    sc->sc_rxq[q].pktlen, 1, sc->sc_rxq[q].pktlen, 0,
			    BUS_DMA_NOWAIT, &rxb->rxb_dmamap) != 0) {
				printf("%s: unable to create dmamap for "
				    "ring %d slot %d\n", DEVNAME(sc), q, i);
				goto freerxbs;
			}

			/* scrub the ring */
			rxd->rx_physaddr = 0;
			rxd->rx_buflength = 0;
			rxd->rx_length = 0;
			rxd->rx_owner = VIC_OWNER_DRIVER;
		}
		sc->sc_rxq[q].end = 0;

		if_rxr_init(&sc->sc_rxq[q].ring, 2, sc->sc_nrxbuf - 1);
		vic_rx_fill(sc, q);
	}

	for (i = 0; i < sc->sc_ntxbuf; i++) {
		txb = &sc->sc_txbuf[i];
		if (bus_dmamap_create(sc->sc_dmat, VIC_JUMBO_FRAMELEN,
		    (sc->sc_cap & VIC_CMD_HWCAP_SG) ? VIC_SG_MAX : 1,
		    VIC_JUMBO_FRAMELEN, 0, BUS_DMA_NOWAIT,
		    &txb->txb_dmamap) != 0) {
			printf("%s: unable to create dmamap for tx %d\n",
			    DEVNAME(sc), i);
			goto freetxbs;
		}
		txb->txb_m = NULL;
	}

	return (0);

freetxbs:
	while (i--) {
		txb = &sc->sc_txbuf[i];
		bus_dmamap_destroy(sc->sc_dmat, txb->txb_dmamap);
	}

	i = sc->sc_nrxbuf;
	q = VIC_NRXRINGS - 1;
freerxbs:
	while (q >= 0) {
		while (i--) {
			rxb = &sc->sc_rxq[q].bufs[i];

			if (rxb->rxb_m != NULL) {
				bus_dmamap_sync(sc->sc_dmat, rxb->rxb_dmamap,
				    0, rxb->rxb_m->m_pkthdr.len,
				    BUS_DMASYNC_POSTREAD);
				bus_dmamap_unload(sc->sc_dmat, rxb->rxb_dmamap);
				m_freem(rxb->rxb_m);
				rxb->rxb_m = NULL;
			}
			bus_dmamap_destroy(sc->sc_dmat, rxb->rxb_dmamap);
		}
		q--;
	}

	return (1);
}

int
vic_uninit_data(struct vic_softc *sc)
{
	struct vic_rxbuf		*rxb;
	struct vic_rxdesc		*rxd;
	struct vic_txbuf		*txb;

	int				i, q;

	for (q = 0; q < VIC_NRXRINGS; q++) {
		for (i = 0; i < sc->sc_nrxbuf; i++) {
			rxb = &sc->sc_rxq[q].bufs[i];
			rxd = &sc->sc_rxq[q].slots[i];

			if (rxb->rxb_m != NULL) {
				bus_dmamap_sync(sc->sc_dmat, rxb->rxb_dmamap,
				    0, rxb->rxb_m->m_pkthdr.len,
				    BUS_DMASYNC_POSTREAD);
				bus_dmamap_unload(sc->sc_dmat, rxb->rxb_dmamap);
				m_freem(rxb->rxb_m);
				rxb->rxb_m = NULL;
			}
			bus_dmamap_destroy(sc->sc_dmat, rxb->rxb_dmamap);
		}
	}

	for (i = 0; i < sc->sc_ntxbuf; i++) {
		txb = &sc->sc_txbuf[i];
		bus_dmamap_destroy(sc->sc_dmat, txb->txb_dmamap);
	}

	return (0);
}

void
vic_link_state(struct vic_softc *sc)
{
	struct ifnet *ifp = &sc->sc_ac.ac_if;
	u_int32_t status;
	int link_state = LINK_STATE_DOWN;

	status = vic_read(sc, VIC_STATUS);
	if (status & VIC_STATUS_CONNECTED)
		link_state = LINK_STATE_FULL_DUPLEX;
	if (ifp->if_link_state != link_state) {
		ifp->if_link_state = link_state;
		if_link_state_change(ifp);
	}
}

int
vic_intr(void *arg)
{
	struct vic_softc *sc = (struct vic_softc *)arg;
	int q;

	for (q = 0; q < VIC_NRXRINGS; q++)
		vic_rx_proc(sc, q);
	vic_tx_proc(sc);

	vic_write(sc, VIC_CMD, VIC_CMD_INTR_ACK);

	return (-1);
}

void
vic_rx_proc(struct vic_softc *sc, int q)
{
	struct ifnet			*ifp = &sc->sc_ac.ac_if;
	struct vic_rxdesc		*rxd;
	struct vic_rxbuf		*rxb;
	struct mbuf_list		 ml = MBUF_LIST_INITIALIZER();
	struct mbuf			*m;
	int				len, idx;

	if ((ifp->if_flags & IFF_RUNNING) == 0)
		return;

	bus_dmamap_sync(sc->sc_dmat, sc->sc_dma_map, 0, sc->sc_dma_size,
	    BUS_DMASYNC_POSTREAD | BUS_DMASYNC_POSTWRITE);

	while (if_rxr_inuse(&sc->sc_rxq[q].ring) > 0) {
		idx = sc->sc_data->vd_rx[q].nextidx;
		if (idx >= sc->sc_data->vd_rx[q].length) {
			ifp->if_ierrors++;
			if (ifp->if_flags & IFF_DEBUG)
				printf("%s: receive index error\n",
				    sc->sc_dev.dv_xname);
			break;
		}

		rxd = &sc->sc_rxq[q].slots[idx];
		if (rxd->rx_owner != VIC_OWNER_DRIVER)
			break;

		rxb = &sc->sc_rxq[q].bufs[idx];

		if (rxb->rxb_m == NULL) {
			ifp->if_ierrors++;
			printf("%s: rxb %d has no mbuf\n", DEVNAME(sc), idx);
			break;
		}

		bus_dmamap_sync(sc->sc_dmat, rxb->rxb_dmamap, 0,
		    rxb->rxb_m->m_pkthdr.len, BUS_DMASYNC_POSTREAD);
		bus_dmamap_unload(sc->sc_dmat, rxb->rxb_dmamap);

		m = rxb->rxb_m;
		rxb->rxb_m = NULL;
		len = rxd->rx_length;

		if (len < VIC_MIN_FRAMELEN) {
			m_freem(m);

			ifp->if_iqdrops++;
			goto nextp;
		}

		m->m_pkthdr.len = m->m_len = len;

		ml_enqueue(&ml, m);

 nextp:
		if_rxr_put(&sc->sc_rxq[q].ring, 1);
		VIC_INC(sc->sc_data->vd_rx[q].nextidx, sc->sc_nrxbuf);
	}

	if_input(ifp, &ml);
	vic_rx_fill(sc, q);

	bus_dmamap_sync(sc->sc_dmat, sc->sc_dma_map, 0, sc->sc_dma_size,
	    BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);
}

void
vic_tx_proc(struct vic_softc *sc)
{
	struct ifnet			*ifp = &sc->sc_ac.ac_if;
	struct vic_txdesc		*txd;
	struct vic_txbuf		*txb;
	int				idx;

	bus_dmamap_sync(sc->sc_dmat, sc->sc_dma_map, 0, sc->sc_dma_size,
	    BUS_DMASYNC_POSTREAD | BUS_DMASYNC_POSTWRITE);

	while (sc->sc_txpending > 0) {
		idx = sc->sc_data->vd_tx_curidx;
		if (idx >= sc->sc_data->vd_tx_length) {
			ifp->if_oerrors++;
			break;
		}

		txd = &sc->sc_txq[idx];
		if (txd->tx_owner != VIC_OWNER_DRIVER)
			break;

		txb = &sc->sc_txbuf[idx];
		if (txb->txb_m == NULL) {
			printf("%s: tx ring is corrupt\n", DEVNAME(sc));
			ifp->if_oerrors++;
			break;
		}

		bus_dmamap_sync(sc->sc_dmat, txb->txb_dmamap, 0,
		    txb->txb_dmamap->dm_mapsize, BUS_DMASYNC_POSTWRITE);
		bus_dmamap_unload(sc->sc_dmat, txb->txb_dmamap);

		m_freem(txb->txb_m);
		txb->txb_m = NULL;
		ifq_clr_oactive(&ifp->if_snd);

		sc->sc_txpending--;
		sc->sc_data->vd_tx_stopped = 0;

		VIC_INC(sc->sc_data->vd_tx_curidx, sc->sc_data->vd_tx_length);
	}

	bus_dmamap_sync(sc->sc_dmat, sc->sc_dma_map, 0, sc->sc_dma_size,
	    BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);

	vic_start(ifp);
}

void
vic_iff(struct vic_softc *sc)
{
	struct arpcom *ac = &sc->sc_ac;
	struct ifnet *ifp = &sc->sc_ac.ac_if;
	struct ether_multi *enm;
	struct ether_multistep step;
	u_int32_t crc;
	u_int16_t *mcastfil = (u_int16_t *)sc->sc_data->vd_mcastfil;
	u_int flags;

	ifp->if_flags &= ~IFF_ALLMULTI;

	/* Always accept broadcast frames. */
	flags = VIC_CMD_IFF_BROADCAST;

	if (ifp->if_flags & IFF_PROMISC || ac->ac_multirangecnt > 0) {
		ifp->if_flags |= IFF_ALLMULTI;
		if (ifp->if_flags & IFF_PROMISC)
			flags |= VIC_CMD_IFF_PROMISC;
		else
			flags |= VIC_CMD_IFF_MULTICAST;
		memset(&sc->sc_data->vd_mcastfil, 0xff,
		    sizeof(sc->sc_data->vd_mcastfil));
	} else {
		flags |= VIC_CMD_IFF_MULTICAST;

		bzero(&sc->sc_data->vd_mcastfil,
		    sizeof(sc->sc_data->vd_mcastfil));

		ETHER_FIRST_MULTI(step, ac, enm);
		while (enm != NULL) {
			crc = ether_crc32_le(enm->enm_addrlo, ETHER_ADDR_LEN);

			crc >>= 26;

			mcastfil[crc >> 4] |= htole16(1 << (crc & 0xf));

			ETHER_NEXT_MULTI(step, enm);
		}
	}

	vic_write(sc, VIC_CMD, VIC_CMD_MCASTFIL);
	sc->sc_data->vd_iff = flags;
	vic_write(sc, VIC_CMD, VIC_CMD_IFF);
}

void
vic_getlladdr(struct vic_softc *sc)
{
	u_int32_t reg;

	/* Get MAC address */
	reg = (sc->sc_cap & VIC_CMD_HWCAP_VPROM) ? VIC_VPROM : VIC_LLADDR;

	bus_space_barrier(sc->sc_iot, sc->sc_ioh, reg, ETHER_ADDR_LEN,
	    BUS_SPACE_BARRIER_READ);
	bus_space_read_region_1(sc->sc_iot, sc->sc_ioh, reg, sc->sc_lladdr,
	    ETHER_ADDR_LEN);

	/* Update the MAC address register */
	if (reg == VIC_VPROM)
		vic_setlladdr(sc);
}

void
vic_setlladdr(struct vic_softc *sc)
{
	bus_space_write_region_1(sc->sc_iot, sc->sc_ioh, VIC_LLADDR,
	    sc->sc_lladdr, ETHER_ADDR_LEN);
	bus_space_barrier(sc->sc_iot, sc->sc_ioh, VIC_LLADDR, ETHER_ADDR_LEN,
	    BUS_SPACE_BARRIER_WRITE);
}

int
vic_media_change(struct ifnet *ifp)
{
	/* Ignore */
	return (0);
}

void
vic_media_status(struct ifnet *ifp, struct ifmediareq *imr)
{
	struct vic_softc *sc = (struct vic_softc *)ifp->if_softc;

	imr->ifm_active = IFM_ETHER | IFM_AUTO;
	imr->ifm_status = IFM_AVALID;

	vic_link_state(sc);

	if (LINK_STATE_IS_UP(ifp->if_link_state) &&
	    ifp->if_flags & IFF_UP)
		imr->ifm_status |= IFM_ACTIVE;
}

void
vic_start(struct ifnet *ifp)
{
	struct vic_softc		*sc;
	struct mbuf			*m;
	struct vic_txbuf		*txb;
	struct vic_txdesc		*txd;
	struct vic_sg			*sge;
	bus_dmamap_t			dmap;
	int				i, idx;
	int				tx = 0;

	if (!(ifp->if_flags & IFF_RUNNING))
		return;

	if (ifq_is_oactive(&ifp->if_snd))
		return;

	if (IFQ_IS_EMPTY(&ifp->if_snd))
		return;

	sc = (struct vic_softc *)ifp->if_softc;

	bus_dmamap_sync(sc->sc_dmat, sc->sc_dma_map, 0, sc->sc_dma_size,
	    BUS_DMASYNC_POSTREAD | BUS_DMASYNC_POSTWRITE);

	for (;;) {
		if (VIC_TXURN(sc)) {
			ifq_set_oactive(&ifp->if_snd);
			break;
		}

		idx = sc->sc_data->vd_tx_nextidx;
		if (idx >= sc->sc_data->vd_tx_length) {
			printf("%s: tx idx is corrupt\n", DEVNAME(sc));
			ifp->if_oerrors++;
			break;
		}

		txd = &sc->sc_txq[idx];
		txb = &sc->sc_txbuf[idx];

		if (txb->txb_m != NULL) {
			printf("%s: tx ring is corrupt\n", DEVNAME(sc));
			sc->sc_data->vd_tx_stopped = 1;
			ifp->if_oerrors++;
			break;
		}

		m = ifq_dequeue(&ifp->if_snd);
		if (m == NULL)
			break;

		if (vic_load_txb(sc, txb, m) != 0) {
			m_freem(m);
			ifp->if_oerrors++;
			continue;
		}

#if NBPFILTER > 0
		if (ifp->if_bpf)
			bpf_mtap(ifp->if_bpf, txb->txb_m, BPF_DIRECTION_OUT);
#endif

		dmap = txb->txb_dmamap;
		txd->tx_flags = VIC_TX_FLAGS_KEEP;
		txd->tx_owner = VIC_OWNER_NIC;
		txd->tx_sa.sa_addr_type = VIC_SG_ADDR_PHYS;
		txd->tx_sa.sa_length = dmap->dm_nsegs;
		for (i = 0; i < dmap->dm_nsegs; i++) {
			sge = &txd->tx_sa.sa_sg[i];
			sge->sg_length = dmap->dm_segs[i].ds_len;
			sge->sg_addr_low = dmap->dm_segs[i].ds_addr;
		}

		if (VIC_TXURN_WARN(sc)) {
			txd->tx_flags |= VIC_TX_FLAGS_TXURN;
		}

		bus_dmamap_sync(sc->sc_dmat, dmap, 0, dmap->dm_mapsize,
		    BUS_DMASYNC_PREWRITE);

		sc->sc_txpending++;

		VIC_INC(sc->sc_data->vd_tx_nextidx, sc->sc_data->vd_tx_length);

		tx = 1;
	}

	bus_dmamap_sync(sc->sc_dmat, sc->sc_dma_map, 0, sc->sc_dma_size,
	    BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);

	if (tx)
		vic_read(sc, VIC_Tx_ADDR);
}

int
vic_load_txb(struct vic_softc *sc, struct vic_txbuf *txb, struct mbuf *m)
{
	bus_dmamap_t			dmap = txb->txb_dmamap;
	int				error;

	error = bus_dmamap_load_mbuf(sc->sc_dmat, dmap, m, BUS_DMA_NOWAIT);
	switch (error) {
	case 0:
		txb->txb_m = m;
		break;

	case EFBIG:
		if (m_defrag(m, M_DONTWAIT) == 0 &&
		    bus_dmamap_load_mbuf(sc->sc_dmat, dmap, m,
		    BUS_DMA_NOWAIT) == 0) {
			txb->txb_m = m;
			break;
		}

		/* FALLTHROUGH */
	default:
		return (ENOBUFS);
	}

	return (0);
}

void
vic_watchdog(struct ifnet *ifp)
{
#if 0
	struct vic_softc *sc = (struct vic_softc *)ifp->if_softc;

	if (sc->sc_txpending && sc->sc_txtimeout > 0) {
		if (--sc->sc_txtimeout == 0) {
			printf("%s: device timeout\n", sc->sc_dev.dv_xname);
			ifp->if_flags &= ~IFF_RUNNING;
			vic_init(ifp);
			ifp->if_oerrors++;
			return;
		}
	}

	if (!IFQ_IS_EMPTY(&ifp->if_snd))
		vic_start(ifp);
#endif
}

int
vic_ioctl(struct ifnet *ifp, u_long cmd, caddr_t data)
{
	struct vic_softc *sc = (struct vic_softc *)ifp->if_softc;
	struct ifreq *ifr = (struct ifreq *)data;
	int s, error = 0;

	s = splnet();

	switch (cmd) {
	case SIOCSIFADDR:
		ifp->if_flags |= IFF_UP;
		/* FALLTHROUGH */
	case SIOCSIFFLAGS:
		if (ifp->if_flags & IFF_UP) {
			if (ifp->if_flags & IFF_RUNNING)
				error = ENETRESET;
			else
				vic_init(ifp);
		} else {
			if (ifp->if_flags & IFF_RUNNING)
				vic_stop(ifp);
		}
		break;

	case SIOCGIFMEDIA:
	case SIOCSIFMEDIA:
		error = ifmedia_ioctl(ifp, ifr, &sc->sc_media, cmd);
		break;

	case SIOCGIFRXR:
		error = vic_rxrinfo(sc, (struct if_rxrinfo *)ifr->ifr_data);
		break;

	default:
		error = ether_ioctl(ifp, &sc->sc_ac, cmd, data);
	}

	if (error == ENETRESET) {
		if (ifp->if_flags & IFF_RUNNING)
			vic_iff(sc);
		error = 0;
	}

	splx(s);
	return (error);
}

int
vic_rxrinfo(struct vic_softc *sc, struct if_rxrinfo *ifri)
{
	struct if_rxring_info ifr[2];

	memset(ifr, 0, sizeof(ifr));

	ifr[0].ifr_size = MCLBYTES;
	ifr[0].ifr_info = sc->sc_rxq[0].ring;

	ifr[1].ifr_size = 4096;
	ifr[1].ifr_info = sc->sc_rxq[1].ring;

	return (if_rxr_info_ioctl(ifri, nitems(ifr), ifr));
}

void
vic_init(struct ifnet *ifp)
{
	struct vic_softc	*sc = (struct vic_softc *)ifp->if_softc;
	int			q;
	int			s;

	sc->sc_data->vd_tx_curidx = 0;
	sc->sc_data->vd_tx_nextidx = 0;
	sc->sc_data->vd_tx_stopped = sc->sc_data->vd_tx_queued = 0;
	sc->sc_data->vd_tx_saved_nextidx = 0;

	for (q = 0; q < VIC_NRXRINGS; q++) {
		sc->sc_data->vd_rx[q].nextidx = 0;
		sc->sc_data->vd_rx_saved_nextidx[q] = 0;
	}

	if (vic_init_data(sc) != 0)
		return;

	bus_dmamap_sync(sc->sc_dmat, sc->sc_dma_map, 0, sc->sc_dma_size,
	    BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);

	s = splnet();

	vic_write(sc, VIC_DATA_ADDR, VIC_DMA_DVA(sc));
	vic_write(sc, VIC_DATA_LENGTH, sc->sc_dma_size);

	ifp->if_flags |= IFF_RUNNING;
	ifq_clr_oactive(&ifp->if_snd);

	vic_iff(sc);
	vic_write(sc, VIC_CMD, VIC_CMD_INTR_ENABLE);

	splx(s);

	timeout_add_sec(&sc->sc_tick, 1);
}

void
vic_stop(struct ifnet *ifp)
{
	struct vic_softc *sc = (struct vic_softc *)ifp->if_softc;
	int s;

	s = splnet();

	timeout_del(&sc->sc_tick);

	ifp->if_flags &= ~IFF_RUNNING;
	ifq_clr_oactive(&ifp->if_snd);

	bus_dmamap_sync(sc->sc_dmat, sc->sc_dma_map, 0, sc->sc_dma_size,
	    BUS_DMASYNC_POSTREAD | BUS_DMASYNC_POSTWRITE);

	/* XXX wait for tx to complete */
	while (sc->sc_txpending > 0) {
		splx(s);
		delay(1000);
		s = splnet();
	}

	sc->sc_data->vd_tx_stopped = 1;

	vic_write(sc, VIC_CMD, VIC_CMD_INTR_DISABLE);

	sc->sc_data->vd_iff = 0;
	vic_write(sc, VIC_CMD, VIC_CMD_IFF);

	vic_write(sc, VIC_DATA_ADDR, 0);

	vic_uninit_data(sc);

	splx(s);
}

struct mbuf *
vic_alloc_mbuf(struct vic_softc *sc, bus_dmamap_t map, u_int pktlen)
{
	struct mbuf *m = NULL;

	m = MCLGETI(NULL, M_DONTWAIT, NULL, pktlen);
	if (!m)
		return (NULL);
	m->m_data += ETHER_ALIGN;
	m->m_len = m->m_pkthdr.len = pktlen - ETHER_ALIGN;

	if (bus_dmamap_load_mbuf(sc->sc_dmat, map, m, BUS_DMA_NOWAIT) != 0) {
		printf("%s: could not load mbuf DMA map\n", DEVNAME(sc));
		m_freem(m);
		return (NULL);
	}

	return (m);
}

void
vic_tick(void *arg)
{
	struct vic_softc		*sc = (struct vic_softc *)arg;

	vic_link_state(sc);

	timeout_add_sec(&sc->sc_tick, 1);
}

u_int32_t
vic_read(struct vic_softc *sc, bus_size_t r)
{
	bus_space_barrier(sc->sc_iot, sc->sc_ioh, r, 4,
	    BUS_SPACE_BARRIER_READ);
	return (bus_space_read_4(sc->sc_iot, sc->sc_ioh, r));
}

void
vic_write(struct vic_softc *sc, bus_size_t r, u_int32_t v)
{
	bus_space_write_4(sc->sc_iot, sc->sc_ioh, r, v);
	bus_space_barrier(sc->sc_iot, sc->sc_ioh, r, 4,
	    BUS_SPACE_BARRIER_WRITE);
}

u_int32_t
vic_read_cmd(struct vic_softc *sc, u_int32_t cmd)
{
	vic_write(sc, VIC_CMD, cmd);
	return (vic_read(sc, VIC_CMD));
}

int
vic_alloc_dmamem(struct vic_softc *sc)
{
	int nsegs;

	if (bus_dmamap_create(sc->sc_dmat, sc->sc_dma_size, 1,
	    sc->sc_dma_size, 0, BUS_DMA_NOWAIT | BUS_DMA_ALLOCNOW,
	    &sc->sc_dma_map) != 0)
		goto err;

	if (bus_dmamem_alloc(sc->sc_dmat, sc->sc_dma_size, 16, 0,
	    &sc->sc_dma_seg, 1, &nsegs, BUS_DMA_NOWAIT | BUS_DMA_ZERO) != 0)
		goto destroy;

	if (bus_dmamem_map(sc->sc_dmat, &sc->sc_dma_seg, nsegs,
	    sc->sc_dma_size, &sc->sc_dma_kva, BUS_DMA_NOWAIT) != 0)
		goto free;

	if (bus_dmamap_load(sc->sc_dmat, sc->sc_dma_map, sc->sc_dma_kva,
	    sc->sc_dma_size, NULL, BUS_DMA_NOWAIT) != 0)
		goto unmap;

	return (0);

unmap:
	bus_dmamem_unmap(sc->sc_dmat, sc->sc_dma_kva, sc->sc_dma_size);
free:
	bus_dmamem_free(sc->sc_dmat, &sc->sc_dma_seg, 1);
destroy:
	bus_dmamap_destroy(sc->sc_dmat, sc->sc_dma_map);
err:
	return (1);
}

void
vic_free_dmamem(struct vic_softc *sc)
{
	bus_dmamap_unload(sc->sc_dmat, sc->sc_dma_map);
	bus_dmamem_unmap(sc->sc_dmat, sc->sc_dma_kva, sc->sc_dma_size);
	bus_dmamem_free(sc->sc_dmat, &sc->sc_dma_seg, 1);
	bus_dmamap_destroy(sc->sc_dmat, sc->sc_dma_map);
}
@


1.97
log
@move counting if_opackets next to counting if_obytes in if_enqueue.

this means packets are consistently counted in one place, unlike the
many and various ways that drivers thought they should do it.

ok mpi@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.96 2016/04/13 10:34:32 mpi Exp $	*/
a1053 4
		m = ifq_deq_begin(&ifp->if_snd);
		if (m == NULL)
			break;

a1055 1
			ifq_deq_rollback(&ifp->if_snd, m);
a1064 1
			ifq_deq_rollback(&ifp->if_snd, m);
d1071 4
a1074 5
		/*
		 * we're committed to sending it now. if we cant map it into
		 * dma memory then we drop it.
		 */
		ifq_deq_commit(&ifp->if_snd, m);
d1078 1
a1078 2
			/* continue? */
			break;
@


1.96
log
@G/C IFQ_SET_READY().
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.95 2015/11/25 03:09:59 dlg Exp $	*/
a1111 1
		ifp->if_opackets++;
@


1.95
log
@replace IFF_OACTIVE manipulation with mpsafe operations.

there are two things shared between the network stack and drivers
in the send path: the send queue and the IFF_OACTIVE flag. the send
queue is now protected by a mutex. this diff makes the oactive
functionality mpsafe too.

IFF_OACTIVE is part of if_flags. there are two problems with that.
firstly, if_flags is a short and we dont have any MI atomic operations
to manipulate a short. secondly, while we could make the IFF_OACTIVE
operates mpsafe, all changes to other flags would have to be made
safe at the same time, otherwise a read-modify-write cycle on their
updates could clobber the oactive change.

instead, this moves the oactive mark into struct ifqueue and provides
an API for changing it. there's ifq_set_oactive, ifq_clr_oactive,
and ifq_is_oactive. these are modelled on ifsq_set_oactive,
ifsq_clr_oactive, and ifsq_is_oactive in dragonflybsd.

this diff includes changes to all the drivers manipulating IFF_OACTIVE
to now use the ifsq_{set,clr_is}_oactive API too.

ok kettenis@@ mpi@@ jmatthew@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.94 2015/11/24 13:33:17 mpi Exp $	*/
a483 1
	IFQ_SET_READY(&ifp->if_snd);
@


1.94
log
@The only network driver needing <net/if_types.h> is upl(4) for IFT_OTHER.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.93 2015/11/20 03:35:23 dlg Exp $	*/
d913 1
a913 1
		ifp->if_flags &= ~IFF_OACTIVE;
d1038 1
a1038 1
	if (ifp->if_flags & IFF_OACTIVE)
d1051 1
a1051 1
			ifp->if_flags |= IFF_OACTIVE;
d1270 1
a1270 1
	ifp->if_flags &= ~IFF_OACTIVE;
d1290 2
a1291 1
	ifp->if_flags &= ~(IFF_RUNNING | IFF_OACTIVE);
@


1.93
log
@shuffle struct ifqueue so in flight mbufs are protected by a mutex.

the code is refactored so the IFQ macros call newly implemented ifq
functions. the ifq code is split so each discipline (priq and hfsc
in our case) is an opaque set of operations that the common ifq
code can call. the common code does the locking, accounting (ifq_len
manipulation), and freeing of the mbuf if the disciplines enqueue
function rejects it. theyre kind of like bufqs in the block layer
with their fifo and nscan disciplines.

the new api also supports atomic switching of disciplines at runtime.
the hfsc setup in pf_ioctl.c has been tweaked to build a complete
hfsc_if structure which it attaches to the send queue in a single
operation, rather than attaching to the interface up front and
building up a list of queues.

the send queue is now mutexed, which raises the expectation that
packets can be enqueued or purged on one cpu while another cpu is
dequeueing them in a driver for transmission. a lot of drivers use
IFQ_POLL to peek at an mbuf and attempt to fit it on the ring before
committing to it with a later IFQ_DEQUEUE operation. if the mbuf
gets freed in between the POLL and DEQUEUE operations, fireworks
will ensue.

to avoid this, the ifq api introduces ifq_deq_begin, ifq_deq_rollback,
and ifq_deq_commit. ifq_deq_begin allows a driver to take the ifq
mutex and get a reference to the mbuf they wish to try and tx. if
there's space, they can ifq_deq_commit it to remove the mbuf and
release the mutex. if there's no space, ifq_deq_rollback simply
releases the mutex. this api was developed to make updating the
drivers using IFQ_POLL easy, instead of having to do significant
semantic changes to avoid POLL that we cannot test on all the
hardware.

the common code has been tested pretty hard, and all the driver
modifications are straightforward except for de(4). if that breaks
it can be dealt with later.

ok mpi@@ jmatthew@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.92 2015/10/25 13:04:28 mpi Exp $	*/
a40 1
#include <net/if_types.h>
@


1.92
log
@arp_ifinit() is no longer needed.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.91 2015/06/24 09:40:54 mpi Exp $	*/
d1056 1
a1056 1
		IFQ_POLL(&ifp->if_snd, m);
d1062 1
d1072 1
d1083 1
a1083 1
		IFQ_DEQUEUE(&ifp->if_snd, m);
@


1.91
log
@Increment if_ipackets in if_input().

Note that pseudo-drivers not using if_input() are not affected by this
conversion.

ok mikeb@@, kettenis@@, claudio@@, dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.90 2015/05/29 00:37:10 uebayasi Exp $	*/
a1179 1
	struct ifaddr *ifa = (struct ifaddr *)data;
a1187 2
		if (ifa->ifa_addr->sa_family == AF_INET)
			arp_ifinit(&sc->sc_ac, ifa);
@


1.90
log
@Revert unrelated changes in previous.
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
a863 2

		ifp->if_ipackets++;
@


1.89
log
@Initial addition of ``Patrol Read'' support in bio(4), biocto(8), and
mfi(4).  Based on FreeBSD, but done without mfiutil(8).

OK deraadt@@
@
text
@a1343 10
	int				s, q;

	/*
	 * XXX Poll Rx interrupt and process existing packets to work-around
	 * XXX occasional Rx interrupt lossage.
	 */
	s = splnet();
	for (q = 0; q < VIC_NRXRINGS; q++)
		vic_rx_proc(sc, q);
	splx(s);
@


1.88
log
@No need to set `rcvif', if_input() does it for you!
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.87 2015/04/01 16:09:21 uebayasi Exp $	*/
d1344 10
@


1.87
log
@Correct comments.
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
a862 1
		m->m_pkthdr.rcvif = ifp;
@


1.86
log
@Remove some includes include-what-you-use claims don't
have any direct symbols used.  Tested for indirect use by compiling
amd64/i386/sparc64 kernels.

ok tedu@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.85 2015/02/10 23:22:39 brad Exp $	*/
d81 2
a82 2
#define  VIC_CMD_INTR_DISABLE	0x0020	/* Enable interrupts */
#define  VIC_CMD_INTR_ENABLE	0x0040	/* Disable interrupts */
@


1.85
log
@Replace hand rolled code with m_defrag().

ok pelikan@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.84 2015/02/10 02:57:32 pelikan Exp $	*/
a39 1
#include <net/if_dl.h>
@


1.84
log
@convert VMXNET drivers to ml_enqueue + if_input

ok dlg reyk
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.83 2014/12/22 02:28:52 tedu Exp $	*/
a1134 1
	struct mbuf			*m0 = NULL;
d1143 6
a1148 10
	case EFBIG: /* mbuf chain is too fragmented */
		MGETHDR(m0, M_DONTWAIT, MT_DATA);
		if (m0 == NULL)
			return (ENOBUFS);
		if (m->m_pkthdr.len > MHLEN) {
			MCLGETI(m0, M_DONTWAIT, NULL, m->m_pkthdr.len);
			if (!(m0->m_flags & M_EXT)) {
				m_freem(m0);
				return (ENOBUFS);
			}
a1149 13
		m_copydata(m, 0, m->m_pkthdr.len, mtod(m0, caddr_t));
		m0->m_pkthdr.len = m0->m_len = m->m_pkthdr.len;
		error = bus_dmamap_load_mbuf(sc->sc_dmat, dmap, m0,
		    BUS_DMA_NOWAIT);
		if (error != 0) {
			m_freem(m0);
			printf("%s: tx dmamap load error %d\n", DEVNAME(sc),
			    error);
			return (ENOBUFS);
		}
		m_freem(m);
		txb->txb_m = m0;
		break;
d1151 1
a1152 1
		printf("%s: tx dmamap load error %d\n", DEVNAME(sc), error);
@


1.83
log
@unifdef INET
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.82 2014/12/01 01:59:45 brad Exp $	*/
d817 1
d869 1
a869 6
#if NBPFILTER > 0
		if (ifp->if_bpf)
			bpf_mtap(ifp->if_bpf, m, BPF_DIRECTION_IN);
#endif

		ether_input_mbuf(ifp, m);
d871 1
a871 1
nextp:
d876 1
@


1.82
log
@rxr ioctl handling.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.81 2014/07/13 23:10:23 deraadt Exp $	*/
a47 1
#ifdef INET
a49 1
#endif
a1213 1
#ifdef INET
a1215 1
#endif
@


1.81
log
@Some reallocarray() use; review Jean-Philippe Ouellet, patrick keshishian
ok tedu
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.80 2014/07/12 18:48:52 tedu Exp $	*/
d345 1
d1238 4
d1254 16
@


1.80
log
@add a size argument to free. will be used soon, but for now default to 0.
after discussions with beck deraadt kettenis.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.79 2014/07/10 11:15:52 dlg Exp $	*/
d570 2
a571 2
		sc->sc_rxq[q].bufs = malloc(sizeof(struct vic_rxbuf) *
		    sc->sc_nrxbuf, M_DEVBUF, M_NOWAIT | M_ZERO);
d578 1
a578 1
	sc->sc_txbuf = malloc(sizeof(struct vic_txbuf) * sc->sc_ntxbuf,
@


1.79
log
@record the size of the rx rings so we can wrap around them correctly.

fixes a panic, reported by paul de weerd.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.78 2014/07/08 05:35:19 dlg Exp $	*/
d630 1
a630 1
	free(sc->sc_txbuf, M_DEVBUF);
d634 1
a634 1
		free(sc->sc_rxq[q].bufs, M_DEVBUF);
@


1.78
log
@cut things that relied on mclgeti for rx ring accounting/restriction over
to using if_rxr.

cut the reporting systat did over to the rxr ioctl.

tested as much as i can on alpha, amd64, and sparc64.
mpi@@ has run it on macppc.
ok mpi@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.77 2011/11/29 11:53:25 jsing Exp $	*/
d608 1
@


1.77
log
@Do not blindly return 1 from the interrupt handler since we do not know
if we actually did any work. Otherwise devices sharing this interrupt will
not have their interrupt handler run, possibly leading to the kernel
spinning in the vic(4) interrupt handler.

ok dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.75 2009/11/17 03:21:36 sthen Exp $	*/
d293 1
a296 1
		int			len;
a488 3
	m_clsetwms(ifp, MCLBYTES, 2, sc->sc_nrxbuf - 1);
	m_clsetwms(ifp, 4096, 2, sc->sc_nrxbuf - 1);

a607 1
		sc->sc_data->vd_rx[q].length = sc->sc_nrxbuf;
d643 1
d645 2
a646 1
	while (sc->sc_rxq[q].len < sc->sc_data->vd_rx[q].length) {
a663 1
		sc->sc_rxq[q].len++;
d665 1
d696 1
d698 1
a698 2
		sc->sc_rxq[q].len = 0;
		sc->sc_rxq[q].end = 0;
d826 1
a826 1
	while (sc->sc_rxq[q].len > 0) {
d876 2
a877 3
		sc->sc_rxq[q].len--;
		VIC_INC(sc->sc_data->vd_rx[q].nextidx,
		    sc->sc_data->vd_rx[q].length);
d1330 1
a1330 1
	m = MCLGETI(NULL, M_DONTWAIT, &sc->sc_ac.ac_if, pktlen);
@


1.76
log
@BUS_DMA_ZERO instead of alloc, map, bzero.

ok krw@@
@
text
@d810 1
a810 1
	return (1);
@


1.75
log
@Tidy up promisc/multicast handling. Tested by myself (and earlier
versions by some others who didn't test with both multicast and
promiscuous at the same time). From Brad.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.74 2009/08/13 14:24:47 jasper Exp $	*/
d1392 1
a1392 1
	    &sc->sc_dma_seg, 1, &nsegs, BUS_DMA_NOWAIT) != 0)
a1401 2

	bzero(sc->sc_dma_kva, sc->sc_dma_size);
@


1.74
log
@- consistify cfdriver for the ethernet drivers (0 -> NULL)

ok dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.73 2009/08/10 17:25:07 deraadt Exp $	*/
d947 1
a947 1
	u_int flags = 0;
a948 1
	bzero(&sc->sc_data->vd_mcastfil, sizeof(sc->sc_data->vd_mcastfil));
d951 20
a970 4
	if ((ifp->if_flags & IFF_RUNNING) == 0)
		goto domulti;
	if (ifp->if_flags & IFF_PROMISC)
		goto allmulti;
d972 1
a972 4
	ETHER_FIRST_MULTI(step, ac, enm);
	while (enm != NULL) {
		if (bcmp(enm->enm_addrlo, enm->enm_addrhi, ETHER_ADDR_LEN))
			goto allmulti;
d974 1
a974 3
		crc = ether_crc32_le(enm->enm_addrlo, ETHER_ADDR_LEN);
		crc >>= 26;
		mcastfil[crc >> 4] |= htole16(1 << (crc & 0xf));
d976 2
a977 1
		ETHER_NEXT_MULTI(step, enm);
a979 8
	goto domulti;

 allmulti:
	ifp->if_flags |= IFF_ALLMULTI;
	memset(&sc->sc_data->vd_mcastfil, 0xff,
	    sizeof(sc->sc_data->vd_mcastfil));

 domulti:
a980 6

	if (ifp->if_flags & IFF_RUNNING) {
		flags = (ifp->if_flags & IFF_PROMISC) ?
		    VIC_CMD_IFF_PROMISC :
		    (VIC_CMD_IFF_BROADCAST | VIC_CMD_IFF_MULTICAST);
	}
d1225 1
a1225 1
				vic_iff(sc);
d1318 3
a1320 1
	vic_iff(sc);
@


1.73
log
@delete xxshutdown handlers that are never even hooked up
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.72 2009/08/09 11:40:56 deraadt Exp $	*/
d306 1
a306 1
	0, "vic", DV_IFNET
@


1.72
log
@MCLGETI() will now allocate a mbuf header if it is not provided, thus
reducing the amount of splnet/splx dancing required.. especially in the
worst case (of m_cldrop)
ok dlg kettenis damien
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.71 2009/06/02 12:32:06 deraadt Exp $	*/
a316 1
void		vic_shutdown(void *);
a795 8
}

void
vic_shutdown(void *self)
{
	struct vic_softc *sc = (struct vic_softc *)self;

	vic_stop(&sc->sc_ac.ac_if);
@


1.71
log
@Fix some minor format string problems found in a maze of false positives
provided by Parfait
ok oga
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.70 2009/02/01 14:05:52 dlg Exp $	*/
d1343 2
a1344 2
	MGETHDR(m, M_DONTWAIT, MT_DATA);
	if (m == NULL)
a1345 6

	MCLGETI(m, M_DONTWAIT, &sc->sc_ac.ac_if, pktlen);
	if ((m->m_flags & M_EXT) == 0) {
		m_freem(m);
		return (NULL);
	}
@


1.70
log
@use m_clsetwms to tell the allocator how big the rings are.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.69 2008/12/30 12:27:57 reyk Exp $	*/
d446 1
a446 1
			printf(": unable to morph vlance chip\n", r);
@


1.69
log
@Add missing newline to error message printf.

Thanks to Alexey Suslikov
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.68 2008/12/12 06:12:34 dlg Exp $	*/
d489 3
@


1.68
log
@matthieu and reyk say that using 9k frames for rx breaks vic on esx. i can
sometimes reproduce this, but i cannot see why it would be a problem. tres
weird.

only put 4k frames on the jumbo ring to cope. i'll try to figure this out
again later.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.67 2008/12/05 01:10:25 dlg Exp $	*/
d1353 1
a1353 1
		printf("%s: could not load mbuf DMA map", DEVNAME(sc));
@


1.67
log
@enable 9k frames on the "jumbo" ring
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.66 2008/12/03 05:00:22 dlg Exp $	*/
d568 1
a568 1
	sc->sc_rxq[1].pktlen = VIC_JUMBO_FRAMELEN;
@


1.66
log
@allocate the right number of entries in the "jumbo" rx ring now that it is
actually used. this fixes vic on esx3.

problem found by matthieu@@

also includes misc tweaks to comments and some cleanup code.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.65 2008/12/03 04:07:20 dlg Exp $	*/
d568 1
a568 1
	sc->sc_rxq[1].pktlen = 4096;
@


1.65
log
@use the right variable when looping over rxqs.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.63 2008/11/25 17:01:14 dlg Exp $	*/
a240 1
#define VIC_QUEUE2_SIZE		1
d587 1
a587 1
	    (sc->sc_nrxbuf + VIC_QUEUE2_SIZE) * sizeof(struct vic_rxdesc) +
d604 1
a604 1
	/* set up the rx ring */
d724 1
a724 1
	q = VIC_NRXRINGS;
d726 1
a726 1
	do {
d740 2
a741 1
	} while (--q);
@


1.64
log
@Eliminate the redundant bits of code for MTU and multicast handling
from the individual drivers now that ether_ioctl() handles this.

Shrinks the i386 kernels by..
RAMDISK - 2176 bytes
RAMDISKB - 1504 bytes
RAMDISKC - 736 bytes

Tested by naddy@@/okan@@/sthen@@/brad@@/todd@@/jmc@@ and lots of users.
Build tested on almost all archs by todd@@/brad@@

ok naddy@@
@
text
@d574 1
a574 1
		if (sc->sc_rxq[i].bufs == NULL) {
@


1.63
log
@backout large cluster allocators.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.62 2008/11/25 16:02:06 dlg Exp $	*/
d1217 1
a1218 1
	struct ifaddr *ifa;
a1224 1
		ifa = (struct ifaddr *)data;
a1242 21
	case SIOCSIFMTU:
		if (ifr->ifr_mtu < ETHERMIN || ifr->ifr_mtu > ifp->if_hardmtu)
			error = EINVAL;
		else if (ifp->if_mtu != ifr->ifr_mtu)
			ifp->if_mtu = ifr->ifr_mtu;
		break;

	case SIOCADDMULTI:
	case SIOCDELMULTI:
		ifr = (struct ifreq *)data;
		error = (cmd == SIOCADDMULTI) ?
		    ether_addmulti(ifr, &sc->sc_ac) :
		    ether_delmulti(ifr, &sc->sc_ac);

		if (error == ENETRESET) {
			if (ifp->if_flags & IFF_RUNNING)
				vic_iff(sc);
			error = 0;
		}
		break;

d1253 2
a1254 3
		if ((ifp->if_flags & (IFF_UP | IFF_RUNNING)) ==
		    (IFF_UP | IFF_RUNNING))
			vic_iff(ifp->if_softc);
@


1.62
log
@put 9k frames on the jumbo ring
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.61 2008/11/24 19:18:19 dlg Exp $	*/
d569 1
a569 1
	sc->sc_rxq[1].pktlen = VIC_JUMBO_FRAMELEN;
@


1.61
log
@no 9k cluster allocator yet, switch back to 4k.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.60 2008/11/24 18:36:01 dlg Exp $	*/
d569 1
a569 1
	sc->sc_rxq[1].pktlen = 4096;
@


1.60
log
@switch from 4k to 9k frames on the jumbo ring now the cluster allocator is
able to give them to me.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.59 2008/11/24 16:13:47 dlg Exp $	*/
d569 1
a569 1
	sc->sc_rxq[1].pktlen = VIC_JUMBO_FRAMELEN;
@


1.59
log
@enable the use of the second rx ring. populate it with 4k frames until the
9k backend allocator is available.

vic is the first driver to properly support "jumbo" frames. this is the
model every other driver should follow.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.58 2008/11/24 13:10:16 dlg Exp $	*/
d569 1
a569 1
	sc->sc_rxq[1].pktlen = 4096; /* XXX VIC_JUMBO_FRAMELEN; */
@


1.58
log
@switch from using MCLGET to MCLGETI for clusters going onto the rx ring.
this causes vic to start up with 4 mbufs on the ring, and the allocator
will let it increase the number of rx mbufs as usage demands.

testing shows that i need only 20 to 30 mbufs on the rx ring to
cope with full speed io. we used to always put 100 on the ring, so
we're now saving 140k of kernerl virtual address space (70 *
MCLBYTES).

this relies on the previous commit that copes with failures of mbuf
allocation in the rx path.

similar changes must be made to all the other drivers. i'll happily review
diffs people send in. SUBTLE HINTS ARE COMING YOUR WAY.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.57 2008/11/24 12:34:29 dlg Exp $	*/
d188 2
d193 4
a196 4
	u_int32_t		vd_rx_length;
	u_int32_t		vd_rx_nextidx;
	u_int32_t		vd_rx_length2;
	u_int32_t		vd_rx_nextidx2;
d215 1
a215 2
	u_int32_t		vd_rx_saved_nextidx;
	u_int32_t		vd_rx_saved_nextidx2;
d219 1
a219 2
	u_int32_t		vd_rx_offset;
	u_int32_t		vd_rx_offset2;
d293 7
a299 7
	struct vic_rxbuf	*sc_rxbuf;
	struct vic_rxdesc	*sc_rxq;
	int			sc_rxq_end;
	int			sc_rxq_len;
	struct vic_rxdesc	*sc_rxq2;
	int			sc_rxq_end2;
	int			sc_rxq_len2;
d334 2
a335 2
void		vic_rx_fill(struct vic_softc *);
void		vic_rx_proc(struct vic_softc *);
d353 1
a353 1
struct mbuf *vic_alloc_mbuf(struct vic_softc *, bus_dmamap_t);
d566 4
a569 1
	int				i;
d571 7
a577 5
	sc->sc_rxbuf = malloc(sizeof(struct vic_rxbuf) * sc->sc_nrxbuf,
	    M_DEVBUF, M_NOWAIT);
	if (sc->sc_rxbuf == NULL) {
		printf(": unable to allocate rxbuf\n");
		goto err;
a605 1
	sc->sc_rxq = (struct vic_rxdesc *)&kva[offset];
d607 4
a610 2
	sc->sc_data->vd_rx_offset = offset;
	sc->sc_data->vd_rx_length = sc->sc_nrxbuf;
d612 2
a613 2
	for (i = 0; i < sc->sc_nrxbuf; i++) {
		rxd = &sc->sc_rxq[i];
d615 4
a618 4
		rxd->rx_physaddr = 0;
		rxd->rx_buflength = 0;
		rxd->rx_length = 0;
		rxd->rx_owner = VIC_OWNER_DRIVER;
d620 2
a621 18
		offset += sizeof(struct vic_rxdesc);
	}

	/* set up the dummy rx ring 2 with an unusable entry */
	sc->sc_rxq2 = (struct vic_rxdesc *)&kva[offset];

	sc->sc_data->vd_rx_offset2 = offset;
	sc->sc_data->vd_rx_length2 = VIC_QUEUE2_SIZE;

	for (i = 0; i < VIC_QUEUE2_SIZE; i++) {
		rxd = &sc->sc_rxq2[i];

		rxd->rx_physaddr = 0;
		rxd->rx_buflength = 0;
		rxd->rx_length = 0;
		rxd->rx_owner = VIC_OWNER_DRIVER;

		offset += sizeof(struct vic_rxdesc);
d633 1
d635 3
a637 2
	free(sc->sc_rxbuf, M_DEVBUF);
err:
d642 1
a642 1
vic_rx_fill(struct vic_softc *sc)
d647 3
a649 3
	while (sc->sc_rxq_len < sc->sc_data->vd_rx_length) {
		rxb = &sc->sc_rxbuf[sc->sc_rxq_end];
		rxd = &sc->sc_rxq[sc->sc_rxq_end];
d651 2
a652 1
		rxb->rxb_m = vic_alloc_mbuf(sc, rxb->rxb_dmamap);
d664 2
a665 2
		VIC_INC(sc->sc_rxq_end, sc->sc_data->vd_rx_length);
		sc->sc_rxq_len++;
d676 1
a676 1
	int				i;
d678 18
a695 9
	for (i = 0; i < sc->sc_nrxbuf; i++) {
		rxb = &sc->sc_rxbuf[i];
		rxd = &sc->sc_rxq[i];

		if (bus_dmamap_create(sc->sc_dmat, MCLBYTES, 1,
		    MCLBYTES, 0, BUS_DMA_NOWAIT, &rxb->rxb_dmamap) != 0) {
			printf("%s: unable to create dmamap for rxb %d\n",
			    DEVNAME(sc), i);
			goto freerxbs;
d698 3
a700 5
		/* scrub the ring */
		rxd->rx_physaddr = 0;
		rxd->rx_buflength = 0;
		rxd->rx_length = 0;
		rxd->rx_owner = VIC_OWNER_DRIVER;
a702 4
	sc->sc_rxq_len = 0;
	sc->sc_rxq_end = 0;
	vic_rx_fill(sc);

d705 1
a705 1
		if (bus_dmamap_create(sc->sc_dmat, MCLBYTES,
d707 2
a708 1
		    MCLBYTES, 0, BUS_DMA_NOWAIT, &txb->txb_dmamap) != 0) {
d725 1
d727 13
a739 9
	while (i--) {
		rxb = &sc->sc_rxbuf[i];

		if (rxb->rxb_m != NULL) {
			bus_dmamap_sync(sc->sc_dmat, rxb->rxb_dmamap, 0,
			    rxb->rxb_m->m_pkthdr.len, BUS_DMASYNC_POSTREAD);
			bus_dmamap_unload(sc->sc_dmat, rxb->rxb_dmamap);
			m_freem(rxb->rxb_m);
			rxb->rxb_m = NULL;
d741 1
a741 2
		bus_dmamap_destroy(sc->sc_dmat, rxb->rxb_dmamap);
	}
d753 1
a753 1
	int				i;
d755 14
a768 10
	for (i = 0; i < sc->sc_nrxbuf; i++) {
		rxb = &sc->sc_rxbuf[i];
		rxd = &sc->sc_rxq[i];

		if (rxb->rxb_m != NULL) {
			bus_dmamap_sync(sc->sc_dmat, rxb->rxb_dmamap, 0,
			    rxb->rxb_m->m_pkthdr.len, BUS_DMASYNC_POSTREAD);
			bus_dmamap_unload(sc->sc_dmat, rxb->rxb_dmamap);
			m_freem(rxb->rxb_m);
			rxb->rxb_m = NULL;
a769 1
		bus_dmamap_destroy(sc->sc_dmat, rxb->rxb_dmamap);
d808 1
d810 2
a811 1
	vic_rx_proc(sc);
d820 1
a820 1
vic_rx_proc(struct vic_softc *sc)
d834 3
a836 3
	while (sc->sc_rxq_len > 0) {
		idx = sc->sc_data->vd_rx_nextidx;
		if (idx >= sc->sc_data->vd_rx_length) {
d844 1
a844 1
		rxd = &sc->sc_rxq[idx];
d848 1
a848 1
		rxb = &sc->sc_rxbuf[idx];
d860 2
d863 1
a864 1
			m = rxb->rxb_m;
a866 5
			rxd->rx_owner = VIC_OWNER_DRIVER;
			rxd->rx_length = 0;

			rxb->rxb_m = NULL;

a870 2
		m = rxb->rxb_m;
		rxb->rxb_m = NULL;
d884 3
a886 2
		sc->sc_rxq_len--;
		VIC_INC(sc->sc_data->vd_rx_nextidx, sc->sc_data->vd_rx_length);
d889 1
a889 1
	vic_rx_fill(sc);
d1164 1
a1164 1
			MCLGET(m0, M_DONTWAIT);
d1289 1
d1295 1
d1297 4
a1300 6
	sc->sc_data->vd_rx_nextidx = 0;
	sc->sc_data->vd_rx_nextidx2 = 0;

	sc->sc_data->vd_rx_saved_nextidx = 0;
	sc->sc_data->vd_rx_saved_nextidx2 = 0;
	sc->sc_data->vd_tx_saved_nextidx = 0;
d1359 1
a1359 1
vic_alloc_mbuf(struct vic_softc *sc, bus_dmamap_t map)
d1367 1
a1367 1
	MCLGETI(m, M_DONTWAIT, &sc->sc_ac.ac_if, MCLBYTES);
d1373 1
a1373 1
	m->m_len = m->m_pkthdr.len = MCLBYTES - ETHER_ALIGN;
@


1.57
log
@drop the requirement that the rx ring has to be filled with mbufs. we only
fill a slot when the mbuf allocator gives us an mbuf cluster.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.56 2008/10/29 01:14:47 deraadt Exp $	*/
d1365 1
a1365 1
	MCLGET(m, M_DONTWAIT);
@


1.56
log
@dlg says "well, that is embarassing"
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.55 2008/10/02 20:21:14 brad Exp $	*/
d295 2
d298 2
d334 1
d606 10
a615 1
	offset += sizeof(struct vic_rxdesc) * sc->sc_nrxbuf;
d649 27
d696 3
a698 12
		rxb->rxb_m = vic_alloc_mbuf(sc, rxb->rxb_dmamap);
		if (rxb->rxb_m == NULL) {
			/* error already printed */
			bus_dmamap_destroy(sc->sc_dmat, rxb->rxb_dmamap);
			goto freerxbs;
		}

		bus_dmamap_sync(sc->sc_dmat, rxb->rxb_dmamap, 0,
		    rxb->rxb_m->m_pkthdr.len, BUS_DMASYNC_PREREAD);

		rxd->rx_physaddr = rxb->rxb_dmamap->dm_segs[0].ds_addr;
		rxd->rx_buflength = rxb->rxb_m->m_pkthdr.len; /* XXX? */
d700 1
a700 1
		rxd->rx_owner = VIC_OWNER_NIC;
d703 4
d731 8
a738 3
		bus_dmamap_sync(sc->sc_dmat, rxb->rxb_dmamap, 0,
		    rxb->rxb_m->m_pkthdr.len, BUS_DMASYNC_POSTREAD);
		bus_dmamap_unload(sc->sc_dmat, rxb->rxb_dmamap);
d758 7
a764 3
		bus_dmamap_sync(sc->sc_dmat, rxb->rxb_dmamap, 0,
		    rxb->rxb_m->m_pkthdr.len, BUS_DMASYNC_POSTREAD);
		bus_dmamap_unload(sc->sc_dmat, rxb->rxb_dmamap);
a765 3

		m_freem(rxb->rxb_m);
		rxb->rxb_m = NULL;
d828 1
a828 1
	for (;;) {
a843 6
		len = rxd->rx_length;
		if (len < VIC_MIN_FRAMELEN) {
			ifp->if_iqdrops++;
			goto nextp;
		}

d854 14
a872 15
		/* Get new mbuf for the Rx queue */
		rxb->rxb_m = vic_alloc_mbuf(sc, rxb->rxb_dmamap);
		if (rxb->rxb_m == NULL) {
			ifp->if_ierrors++;
			printf("%s: mbuf alloc failed\n", DEVNAME(sc));
			break;
		}
		bus_dmamap_sync(sc->sc_dmat, rxb->rxb_dmamap, 0,
		    rxb->rxb_m->m_pkthdr.len, BUS_DMASYNC_PREREAD);

		rxd->rx_physaddr = rxb->rxb_dmamap->dm_segs[0].ds_addr;
		rxd->rx_buflength = rxb->rxb_m->m_pkthdr.len;
		rxd->rx_length = 0;
		rxd->rx_owner = VIC_OWNER_DRIVER;

d883 1
a883 1
		rxd->rx_owner = VIC_OWNER_NIC;
d887 2
a1288 3
	if (vic_init_data(sc) != 0)
		return;

d1299 3
@


1.55
log
@First step towards cleaning up the Ethernet driver ioctl handling.
Move calling ether_ioctl() from the top of the ioctl function, which
at the moment does absolutely nothing, to the default switch case.
Thus allowing drivers to define their own ioctl handlers and then
falling back on ether_ioctl(). The only functional change this results
in at the moment is having all Ethernet drivers returning the proper
errno of ENOTTY instead of EINVAL/ENXIO when encountering unknown
ioctl's.

Shrinks the i386 kernels by..
RAMDISK - 1024 bytes
RAMDISKB -  1120 bytes
RAMDISKC - 832 bytes

Tested by martin@@/jsing@@/todd@@/brad@@
Build tested on almost all archs by todd@@/brad@@

ok jsing@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.54 2008/09/10 14:01:23 blambert Exp $	*/
d564 1
a564 1
	    M_NOWAIT, M_DEVBUF);
d571 1
a571 1
	    M_NOWAIT, M_DEVBUF);
@


1.54
log
@Convert timeout_add() calls using multiples of hz to timeout_add_sec()

Really just the low-hanging fruit of (hopefully) forthcoming timeout
conversions.

ok art@@, krw@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.53 2008/07/07 00:42:34 dlg Exp $	*/
a1183 5
	if ((error = ether_ioctl(ifp, &sc->sc_ac, cmd, data)) > 0) {
		splx(s);
		return (error);
	}

d1232 1
a1232 2
		error = ENOTTY;
		break;
a1242 1

@


1.53
log
@tweak the alignment of the rx buffers so the headers in the frame are
better aligned for fast access. i didnt bench, so maybe this does nothing.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.51 2007/10/28 12:38:43 dlg Exp $	*/
d1289 1
a1289 1
	timeout_add(&sc->sc_tick, hz);
d1359 1
a1359 1
	timeout_add(&sc->sc_tick, hz);
@


1.52
log
@use correct data type for the pci address (bus_addr_t)

From mickey
@
text
@d1340 2
a1341 1
	m->m_len = m->m_pkthdr.len = MCLBYTES;
@


1.51
log
@let vic attach to the virtual pcnet hardware in vmware.

tested on real hardware by jsing@@ to ensure pcn(4) isnt affected in the
real world.

ok jsing@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.50 2007/10/23 07:15:18 dlg Exp $	*/
d360 1
a360 1
	paddr_t				pciaddr;
@


1.50
log
@shrink dmesg output to one line that shows irq and the ethernet address.
the vmxnet id never changes.

ok reyk@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.47 2007/05/04 05:08:55 deraadt Exp $	*/
d59 9
d357 22
a378 2
	return (pci_matchbyid((struct pci_attach_args *)aux,
	    vic_devices, sizeof(vic_devices)/sizeof(vic_devices[0])));
d386 2
a387 1
	pcireg_t			memtype;
d395 3
a397 3
	memtype = pci_mapreg_type(sc->sc_pc, sc->sc_tag, VIC_PCI_BAR);
	if (pci_mapreg_map(pa, VIC_PCI_BAR, memtype, 0, &sc->sc_iot,
	    &sc->sc_ioh, NULL, &sc->sc_ios, 0) != 0) {
d402 47
d515 1
a515 1
	bus_space_unmap(sc->sc_iot, sc->sc_ioh, sc->sc_ios);
@


1.49
log
@the multicast filter is operated on as an array of u_int16_t's, not the
u_int32_t's like its described as in the chip descriptors. fixing this
stops the driver from overwriting the field next to the multicast filter
that specifies the number of tx descriptors we give the nic.

we were accidentally telling the chip we had 32 thousand tx descriptors
when we only have 100. trying to complete the 101th tx descriptor causes
panics.
@
text
@a306 1
int		vic_map_pci(struct vic_softc *, struct pci_attach_args *);
d357 2
d361 8
a368 2
	if (vic_map_pci(sc, pa) != 0) {
		/* error printed by vic_map_pci */
d372 12
d386 1
a386 1
		return;
d391 1
a391 1
		return;
d427 2
a428 2
	return;
}
d430 4
a433 6
int
vic_map_pci(struct vic_softc *sc, struct pci_attach_args *pa)
{
	pcireg_t			memtype;
	pci_intr_handle_t		ih;
	const char			*intrstr;
d435 1
a435 28
	sc->sc_pc = pa->pa_pc;
	sc->sc_tag = pa->pa_tag;
	sc->sc_dmat = pa->pa_dmat;

	memtype = pci_mapreg_type(sc->sc_pc, sc->sc_tag, VIC_PCI_BAR);
	if (pci_mapreg_map(pa, VIC_PCI_BAR, memtype, 0, &sc->sc_iot,
	    &sc->sc_ioh, NULL, &sc->sc_ios, 0) != 0) {
		printf(": unable to map system interface register\n");
		return (1);
	}

	if (pci_intr_map(pa, &ih) != 0) {
		printf(": unable to map interrupt\n");
		goto unmap;
	}

	intrstr = pci_intr_string(pa->pa_pc, ih);
	sc->sc_ih = pci_intr_establish(pa->pa_pc, ih, IPL_NET,
	    vic_intr, sc, DEVNAME(sc));
	if (sc->sc_ih == NULL) {
		printf(": unable to map interrupt%s%s\n",
		    intrstr == NULL ? "" : " at ",
		    intrstr == NULL ? "" : intrstr);
		goto unmap;
	}
	printf(": %s\n", intrstr);

	return (0);
a439 1
	return (1);
d453 1
a453 1
		printf("%s: magic mismatch\n", DEVNAME(sc));
d458 1
a458 1
		printf("%s: unsupported version (%X)\n", DEVNAME(sc),
a469 8
	printf("%s: VMXnet %04X, address %s\n", DEVNAME(sc),
	    major & ~VIC_VERSION_MAJOR_M, ether_sprintf(sc->sc_lladdr));

#ifdef VIC_DEBUG
	printf("%s: feature 0x%8x, cap 0x%8x, rx/txbuf %d/%d\n", DEVNAME(sc),
	    sc->sc_feature, sc->sc_cap, sc->sc_nrxbuf, sc->sc_ntxbuf);
#endif

d489 1
a489 1
		printf("%s: unable to allocate rxbuf\n", DEVNAME(sc));
d496 1
a496 1
		printf("%s: unable to allocate txbuf\n", DEVNAME(sc));
d505 1
a505 1
		printf("%s: unable to allocate dma region\n", DEVNAME(sc));
@


1.48
log
@one extern seems to be better than 20 for ifqmaxlen; ok krw
@
text
@d855 1
d873 1
a873 1
		sc->sc_data->vd_mcastfil[crc >> 4] |= htole16(1 << (crc & 0xf));
@


1.47
log
@when it does not compile we KNOW it was not tested.  come on
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.46 2007/05/04 01:52:51 reyk Exp $	*/
a344 2

extern int ifqmaxlen;
@


1.46
log
@do not call vic_init() on ENETRESET in the ioctl handler, use
vic_iff() instead. vic_init() calls vic_init_data() which sets up the
rings and allocates the dma maps. it could happen that vic_init() was
called for multiple times without releasing them first by calling
vic_uninit_data(). ouch! this may have caused some problems related to
dmamap corruption but we'll do further investigation.

ok dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.45 2007/04/22 13:17:55 dlg Exp $	*/
d1187 1
a1187 1
			vic_iff(ifp);
@


1.45
log
@this is my previous commit again, but this time it was tested.

dma sync the rx mbuf before we push it to the hardware.

technically this isnt necessary cos bus_dmamap_sync is a nop on i386 and
amd64. but i like to be correct, and someone might read this as an example
of how to write a driver.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.44 2007/04/21 19:24:59 deraadt Exp $	*/
d1187 1
a1187 1
			vic_init(ifp);
@


1.44
log
@backout: compile before you commit, please
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.42 2007/04/17 03:55:07 dlg Exp $	*/
d774 3
d780 1
@


1.43
log
@when allocating a new mbuf for rx, do a dmamap_sync before handing it to
the hardware. oops.
@
text
@a773 3
		bus_dmamap_sync(sc->sc_dmat, rxb->rxb_dmamap, 0,
		    rxb->rxb_m->m_pkthdr.len, BUS_DMAMAP_PREREAD);

a776 1
		rxd->rx_owner = VIC_OWNER_DRIVER;
@


1.42
log
@a break in the default case, while unnecessary, is still nice.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.41 2007/04/17 02:07:05 dlg Exp $	*/
d774 3
d780 1
@


1.41
log
@point ifreq in the ioctl path at something, so we can void dereferencing
random memory.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.40 2007/04/14 23:35:35 reyk Exp $	*/
d1177 1
@


1.40
log
@replace IPL_BIO with IPL_NET. vic(4) is a networking driver, not block
I/O... ;)

ok dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.39 2007/01/30 09:54:24 reyk Exp $	*/
d1117 1
a1118 1
	struct ifreq *ifr;
@


1.39
log
@update vic(4) to use the LINK_STATE_IS_UP() macro
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.38 2006/12/14 10:10:20 dlg Exp $	*/
d437 2
a438 2
	sc->sc_ih = pci_intr_establish(pa->pa_pc, ih, IPL_BIO,
	vic_intr, sc, DEVNAME(sc));
@


1.38
log
@remove an ugly macro that made claudio sad. luckily it wasnt being used.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.37 2006/12/03 14:52:45 reyk Exp $	*/
d938 1
a938 1
	if (ifp->if_link_state == LINK_STATE_UP &&
@


1.37
log
@always assume full duplex state if the interface is up... what does
full duplex mean for a virtual interface?
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.36 2006/12/03 13:58:58 reyk Exp $	*/
a233 1
#define VIC_INC_POS(_x, _y)	(_x) = (++(_x)) % (_y) ? (_x) : 1
@


1.36
log
@re-add a tiny little #ifdef VIC_DEBUG, used to compare the vic(4)
features and capabilities on different vmware platforms.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.35 2006/11/09 18:50:30 reyk Exp $	*/
d688 1
a688 1
		link_state = LINK_STATE_UP;
@


1.35
log
@no need to check for IFF_ALLMULTI when we just removed the flag...
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.34 2006/11/09 18:31:25 reyk Exp $	*/
a477 3
	if (sc->sc_nrxbuf > VIC_NBUF_MAX || sc->sc_nrxbuf == 0)
		sc->sc_nrxbuf = VIC_NBUF;

a478 3
	if (sc->sc_ntxbuf > VIC_NBUF_MAX || sc->sc_ntxbuf == 0)
		sc->sc_ntxbuf = VIC_NBUF;

d486 10
@


1.34
log
@knf
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.33 2006/11/09 18:29:19 reyk Exp $	*/
d857 1
a857 1
	if (ifp->if_flags & (IFF_ALLMULTI | IFF_PROMISC))
@


1.33
log
@add multicast filter support instead of using ALLMULTI all the time
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.32 2006/11/06 07:31:54 reyk Exp $	*/
d319 1
a319 1
int 		vic_alloc_dmamem(struct vic_softc *);
d429 1
a429 1
		return(1);
d1204 3
a1206 3
        sc->sc_data->vd_rx_saved_nextidx = 0;
        sc->sc_data->vd_rx_saved_nextidx2 = 0;
        sc->sc_data->vd_tx_saved_nextidx = 0;
@


1.32
log
@set the rx filters after setting the shared data address.

this fixes a crash of old vmware versions (like workstation 4.5.2)
when bringing the interface up. it didn't crash the openbsd kernel
running as a guest system, it did crash the complete vmware host
application. that's why i dislike VMs, they're so buggy and
insecure...

ok dlg@@ fkr@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.31 2006/11/02 23:43:35 dlg Exp $	*/
d325 1
a325 1
void		vic_iff(struct vic_softc *, u_int);
d843 1
a843 1
vic_iff(struct vic_softc *sc, u_int flags)
d845 31
a875 1
	/* XXX ALLMULTI */
a877 1
	sc->sc_data->vd_iff = flags;
d879 2
a880 4
/*
	bus_dmamap_sync(sc->sc_dmat, sc->sc_map, 0,
	    sizeof(struct vic_data), BUS_DMASYNC_POSTWRITE);
*/
d882 6
a887 1
	vic_write(sc, VIC_CMD, VIC_CMD_MCASTFIL);
d1136 3
a1138 1
			if ((ifp->if_flags & IFF_RUNNING) == 0)
d1160 3
a1162 1
		if (error == ENETRESET)
d1164 1
a1215 5
	if (ifp->if_flags & IFF_PROMISC)
		vic_iff(sc, VIC_CMD_IFF_PROMISC);
	else
		vic_iff(sc, VIC_CMD_IFF_BROADCAST | VIC_CMD_IFF_MULTICAST);

d1219 1
d1253 1
a1253 1
	vic_iff(sc, 0);
@


1.31
log
@if the hardware doesnt say it can do scatter gather lists for tx, then
limit it to one dma segment so it only fills one scatter gather entry.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.30 2006/11/02 23:39:22 dlg Exp $	*/
d1176 3
a1182 3

	vic_write(sc, VIC_DATA_ADDR, VIC_DMA_DVA(sc));
	vic_write(sc, VIC_DATA_LENGTH, sc->sc_dma_size);
@


1.30
log
@comments like "schedule timeout" before going timeout_add are dumb. learn
to read the code.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.29 2006/11/02 23:35:16 dlg Exp $	*/
d614 2
a615 1
		if (bus_dmamap_create(sc->sc_dmat, MCLBYTES, VIC_SG_MAX,
@


1.29
log
@dont set tx_stopped when we actually want to do tx.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.28 2006/11/02 23:32:16 dlg Exp $	*/
a403 1
	/* Initialise pseudo media types */
a407 1
	/* Attach the device structures */
a1256 1
	/* Update link state (if changed) */
a1258 1
	/* Re-schedule another timeout. */
@


1.28
log
@pointers in hardware structures are stupid. shame on you vmware.

this should have a chance at running on amd64 now. can anyone test?
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.27 2006/11/02 23:29:04 dlg Exp $	*/
a999 1
		sc->sc_data->vd_tx_stopped = 1;
@


1.27
log
@reyk said i can put my copyright on this file too.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.26 2006/11/02 23:28:04 dlg Exp $	*/
d146 1
a146 1
	void 		*rx_priv;
d154 1
a154 1
	void			*tx_priv;
@


1.26
log
@merge the register description into the c file. nothing else will ever
use the reg descriptions, so why pollute the tree with it?
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.25 2006/11/02 05:10:10 dlg Exp $	*/
d5 1
@


1.25
log
@set up a tick to check the link state every second.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.24 2006/11/02 04:56:04 dlg Exp $	*/
d56 3
a58 1
#include <dev/pci/if_vicreg.h>
d60 166
a225 1
#define VIC_PCI_BAR		PCI_MAPREG_START /* Base Address Register */
@


1.24
log
@remove cruft
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.23 2006/11/02 04:32:59 dlg Exp $	*/
a67 2
#define VIC_TIMER_DELAY		2
#define VIC_TIMER_MS(_ms)	(_ms * hz / 1000)
d97 2
d169 1
a169 1
void		vic_timer(void *);
d210 2
d507 1
d1024 2
d1036 2
d1088 1
a1088 1
vic_timer(void *arg)
a1090 1
//	struct ifnet			*ifp = &sc->sc_ac.ac_if;
d1096 1
a1096 1
//	timeout_add(&sc->sc_timer, hz * VIC_TIMER_DELAY);
@


1.23
log
@split the initialisation of the dma area up between the attach path and the
interface init path. the init path now does the allocation of the dmamaps
for both tx and rx, and allocates the mbufs for the rx ring.

the interface stop is now uncommented. it waits for the hardware to stop
working, and cleans up the bits allocated in the init path.

ifconfig vic0 up and ifconfig vic0 down both work now.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.22 2006/11/02 02:17:22 brad Exp $	*/
a173 3
int	vic_alloc_data(struct vic_softc *);
void	vic_reset_data(struct vic_softc *);
void	vic_free_data(struct vic_softc *);
a1077 83
}

void
vic_reset_data(struct vic_softc *sc)
{

#if 0
	struct vic_rxbuf *rxb;
	struct vic_txbuf *txb;
	int i;

	for (i = 0; i < sc->sc_nrxbuf; i++) {
		rxb = &sc->sc_rxbuf[i];

		bzero(&sc->sc_rxq[i], sizeof(struct vic_rxdesc));
		sc->sc_rxq[i].rx_physaddr =
		    rxb->rxb_map->dm_segs->ds_addr;
		sc->sc_rxq[i].rx_buflength = htole32(MCLBYTES);
		sc->sc_rxq[i].rx_owner = VIC_OWNER_NIC;
		sc->sc_rxq[i].rx_priv = rxb;

		bus_dmamap_sync(sc->sc_dmat, rxb->rxb_map, 0,
		    rxb->rxb_map->dm_mapsize, BUS_DMASYNC_PREWRITE);
	}

	for (i = 0; i < sc->sc_ntxbuf; i++) {
		txb = &sc->sc_txbuf[i];

		bzero(&sc->sc_txq[i], sizeof(struct vic_txdesc));
		sc->sc_txq[i].tx_owner = VIC_OWNER_DRIVER;
		sc->sc_txq[i].tx_priv = txb;

		if (sc->sc_txbuf[i].txb_m != NULL) {
			bus_dmamap_sync(sc->sc_dmat, txb->txb_map, 0,
			    txb->txb_map->dm_mapsize, BUS_DMASYNC_POSTWRITE);
			bus_dmamap_unload(sc->sc_dmat, txb->txb_map);
			m_freem(sc->sc_txbuf[i].txb_m);
			sc->sc_txbuf[i].txb_m = NULL;
		}
	}

	bus_dmamap_sync(sc->sc_dmat, sc->sc_map, 0,
	    sc->sc_map->dm_mapsize, BUS_DMASYNC_PREWRITE);
#endif
}

void
vic_free_data(struct vic_softc *sc)
{
#if 0

	bus_dmamap_t map;
	int i;

	if (sc->sc_data == NULL)
		return;

	/* Free Rx queue */
	for (i = 0; i < sc->sc_nrxbuf; i++) {
		if ((map = sc->sc_rxbuf[i].rxb_map) == NULL)
			continue;
		if (sc->sc_rxbuf[i].rxb_m != NULL) {
			bus_dmamap_sync(sc->sc_dmat, map, 0,
			    map->dm_mapsize, BUS_DMASYNC_POSTWRITE);
			bus_dmamap_unload(sc->sc_dmat, map);
			m_freem(sc->sc_rxbuf[i].rxb_m);
		}
		bus_dmamap_destroy(sc->sc_dmat, map);
	}

	/* Free Tx queue */
	for (i = 0; i < sc->sc_ntxbuf; i++) {
		if ((map = sc->sc_txbuf[i].txb_map) == NULL)
			continue;
		if (sc->sc_txbuf[i].txb_m != NULL) {
			bus_dmamap_sync(sc->sc_dmat, map, 0,
			    map->dm_mapsize, BUS_DMASYNC_POSTWRITE);
			bus_dmamap_unload(sc->sc_dmat, map);
			m_freem(sc->sc_txbuf[i].txb_m);
		}
		bus_dmamap_destroy(sc->sc_dmat, map);
	}
#endif
@


1.22
log
@set the proper maximum queue length.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.21 2006/11/02 02:10:12 dlg Exp $	*/
d144 1
a212 5
	if (vic_init_data(sc) != 0) {
		/* error printed by vic_alloc */
		return;
	}

d334 5
d361 40
a413 3
	u_int8_t			*kva = VIC_DMA_KVA(sc);
	u_int				offset;

a419 14
	/* set up basic vic data */
	sc->sc_data = VIC_DMA_KVA(sc);

	sc->sc_data->vd_magic = VIC_MAGIC;
	sc->sc_data->vd_length = sc->sc_dma_size;

	offset = sizeof(struct vic_data);

	/* set up the rx ring */
	sc->sc_rxq = (struct vic_rxdesc *)&kva[offset];

	sc->sc_data->vd_rx_offset = offset;
	sc->sc_data->vd_rx_length = sc->sc_nrxbuf;

a444 19

		offset += sizeof(struct vic_rxdesc);
	}

	/* set up the dummy rx ring 2 with an unusable entry */
	sc->sc_rxq2 = (struct vic_rxdesc *)&kva[offset];

	sc->sc_data->vd_rx_offset2 = offset;
	sc->sc_data->vd_rx_length2 = VIC_QUEUE2_SIZE;

	for (i = 0; i < VIC_QUEUE2_SIZE; i++) {
		rxd = &sc->sc_rxq2[i];

		rxd->rx_physaddr = 0;
		rxd->rx_buflength = 0;
		rxd->rx_length = 0;
		rxd->rx_owner = VIC_OWNER_DRIVER;

		offset += sizeof(struct vic_rxdesc);
a446 6
	/* set up the tx ring */
	sc->sc_txq = (struct vic_txdesc *)&kva[offset];

	sc->sc_data->vd_tx_offset = offset;
	sc->sc_data->vd_tx_length = sc->sc_ntxbuf;

d479 29
d554 3
d753 3
d991 14
a1009 2
	vic_write(sc, VIC_DATA_ADDR, VIC_DMA_DVA(sc));
	vic_write(sc, VIC_DATA_LENGTH, sc->sc_dma_size);
d1015 2
a1016 3
	sc->sc_data->vd_tx_curidx = 0;
	sc->sc_data->vd_tx_nextidx = 0;
	sc->sc_data->vd_tx_stopped = sc->sc_data->vd_tx_queued = 0;
a1028 1
#if 0
a1033 1
	sc->sc_txtimeout = 0;
d1036 12
a1047 1
#ifdef notyet
a1048 1
#endif
d1050 1
a1051 1
	vic_iff(sc, 0);
d1053 1
a1053 2
	sc->sc_data->vd_tx_stopped = 1;
	timeout_del(&sc->sc_timer);
a1055 1
#endif
@


1.21
log
@we sync regions in the dma area anymore, we just sync the whole thing. this
means the insane macro used to calculate the offset for syncing can go
away.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.20 2006/11/02 02:08:18 dlg Exp $	*/
d227 1
a227 1
	IFQ_SET_MAXLEN(&ifp->if_snd, ifqmaxlen);
@


1.20
log
@VIC_DEBUG is useless, so it goes away
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.19 2006/11/02 02:01:36 dlg Exp $	*/
a74 4
#define VIC_OFF_TXDESC(_n) \
	(sizeof(struct vic_data) + \
	((sc->sc_nrxbuf + VIC_QUEUE2_SIZE) * sizeof(struct vic_rxdesc)) + \
	((_n) * sizeof(struct vic_txdesc)))
@


1.19
log
@more whitespace fixes
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.18 2006/11/02 01:54:13 dlg Exp $	*/
a56 7

#ifdef VIC_DEBUG
int vic_debug = 0;
#define DPRINTF(x...)		do { if (vic_debug) printf(x); } while (0)
#else
#define DPRINTF(x...)
#endif
@


1.18
log
@rewrite the tx path so it doesnt feel so lopsided.

now i can have coffee!
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.17 2006/11/02 00:38:34 fkr Exp $	*/
d286 1
a286 1
	
d292 2
a293 2
		       intrstr == NULL ? "" : " at ",
		       intrstr == NULL ? "" : intrstr);
d493 1
a493 1
{       
d886 1
a886 1
#endif 
d1150 3
a1152 3
        bus_space_write_4(sc->sc_iot, sc->sc_ioh, r, v);
        bus_space_barrier(sc->sc_iot, sc->sc_ioh, r, 4,
            BUS_SPACE_BARRIER_WRITE);
@


1.17
log
@whitespaces cleanup, no functional change
ok dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.16 2006/11/01 13:23:06 claudio Exp $	*/
d173 2
a174 1
int		vic_encap(struct vic_softc *, struct mbuf *);
a519 2
	vic_write(sc, VIC_CMD, VIC_CMD_INTR_ACK);

d523 2
a620 3
			if (ifp->if_flags & IFF_DEBUG)
				printf("%s: transmit index error\n",
				    sc->sc_dev.dv_xname);
a628 1

d630 1
a631 3
			if (ifp->if_flags & IFF_DEBUG)
				printf("%s: transmit buffer error\n",
				    DEVNAME(sc));
d652 1
a652 2
	if (!IFQ_IS_EMPTY(&ifp->if_snd))
		vic_start(ifp);
d724 8
a731 2
	struct vic_softc	*sc = (struct vic_softc *)ifp->if_softc;
	struct mbuf		*m;
d736 8
d745 5
d754 4
a757 2
		if (vic_encap(sc, m) != 0) {
			printf("%s: encap err\n", DEVNAME(sc));
d760 53
d814 6
d823 1
a823 1
vic_encap(struct vic_softc *sc, struct mbuf *m)
d825 1
a825 4
	struct ifnet			*ifp = &sc->sc_ac.ac_if;
	struct vic_txbuf		*txb;
	struct vic_txdesc		*txd;
	struct vic_sg			*sge;
a826 1
	bus_dmamap_t			dmap;
a827 4
	int				i, idx;

	bus_dmamap_sync(sc->sc_dmat, sc->sc_dma_map, 0, sc->sc_dma_size,
	    BUS_DMASYNC_POSTREAD | BUS_DMASYNC_POSTWRITE);
a828 21
	idx = sc->sc_data->vd_tx_nextidx;
	if (idx >= sc->sc_data->vd_tx_length) {
		ifp->if_oerrors++;
		if (ifp->if_flags & IFF_DEBUG)
			printf("%s: transmit index error\n", DEVNAME(sc));
		return (EINVAL);
	}

	txd = &sc->sc_txq[idx];
	txb = &sc->sc_txbuf[idx];

	if (VIC_TXURN(sc)) {
		ifp->if_flags |= IFF_OACTIVE;
		return (ENOBUFS);
	} else if (txb->txb_m != NULL) {
		sc->sc_data->vd_tx_stopped = 1;
		ifp->if_oerrors++;
		return (ENOMEM);
	}

	dmap = txb->txb_dmamap;
d832 1
d834 2
a835 2
	case EFBIG:
		/* XXX this is bollocks */
d848 3
a850 2
		if (bus_dmamap_load_mbuf(sc->sc_dmat, dmap, m0,
		    BUS_DMA_NOWAIT) != 0) {
d852 2
d856 2
d859 1
a863 40

#if NBPFILTER > 0
	if (ifp->if_bpf)
		bpf_mtap(ifp->if_bpf, m, BPF_DIRECTION_OUT);
#endif

	IFQ_DEQUEUE(&ifp->if_snd, m);
	if (m0 != NULL) {
		m_freem(m);
		m = m0;
		m0 = NULL;
	}
	txb->txb_m = m;

	txd->tx_flags = VIC_TX_FLAGS_KEEP;
	txd->tx_owner = VIC_OWNER_NIC;
	txd->tx_sa.sa_addr_type = VIC_SG_ADDR_PHYS;
	txd->tx_sa.sa_length = dmap->dm_nsegs;
	for (i = 0; i < dmap->dm_nsegs; i++) {
		sge = &txd->tx_sa.sa_sg[i];
		sge->sg_length = dmap->dm_segs[i].ds_len;
		sge->sg_addr_low = dmap->dm_segs[i].ds_addr;
	}

	if (VIC_TXURN_WARN(sc))
		txd->tx_flags |= VIC_TX_FLAGS_TXURN;

	ifp->if_opackets++;
	sc->sc_txpending++;

	bus_dmamap_sync(sc->sc_dmat, dmap, 0, dmap->dm_mapsize,
	    BUS_DMASYNC_PREWRITE);

	sc->sc_data->vd_tx_stopped = 1;
	VIC_INC(sc->sc_data->vd_tx_nextidx, sc->sc_data->vd_tx_length);

	bus_dmamap_sync(sc->sc_dmat, sc->sc_dma_map, 0, sc->sc_dma_size,
	    BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);

	vic_read(sc, VIC_Tx_ADDR);
@


1.16
log
@Use correct error message as return value. OK dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.15 2006/11/01 10:21:57 dlg Exp $	*/
d274 1
a274 1
        memtype = pci_mapreg_type(sc->sc_pc, sc->sc_tag, VIC_PCI_BAR);
d279 1
a279 1
        }
d281 15
a295 14
        if (pci_intr_map(pa, &ih) != 0) {
                printf(": unable to map interrupt\n");
                goto unmap;
        }
        intrstr = pci_intr_string(pa->pa_pc, ih);
        sc->sc_ih = pci_intr_establish(pa->pa_pc, ih, IPL_BIO,
            vic_intr, sc, DEVNAME(sc));
        if (sc->sc_ih == NULL) {
                printf(": unable to map interrupt%s%s\n",
                    intrstr == NULL ? "" : " at ",
                    intrstr == NULL ? "" : intrstr);
                goto unmap;
        }
        printf(": %s\n", intrstr);
d297 1
a297 1
        return (0);
d300 3
a302 3
        bus_space_unmap(sc->sc_iot, sc->sc_ioh, sc->sc_ios);
        sc->sc_ios = 0;
        return (1);
@


1.15
log
@fix the tx path so it can use more than one scatter gather entry when
sending the packet. this makes it less likely that we'll have to repack
fragmented packets for transmission.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.14 2006/11/01 05:45:15 dlg Exp $	*/
d796 1
a796 1
				return (E2BIG);
@


1.14
log
@let the tx completion path clean up by recording which mbuf we're
sending in the tx forward path. gotta love one line fixes...

committed over vic
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.13 2006/11/01 05:06:26 dlg Exp $	*/
d459 1
a459 1
		if (bus_dmamap_create(sc->sc_dmat, MCLBYTES, 1 /* XXX 6 */,
d639 2
a640 1
		/* XXX bus dma sync */
d753 1
d755 3
a757 1
	int				idx;
d782 6
a787 2
	if (bus_dmamap_load_mbuf(sc->sc_dmat, txb->txb_dmamap,
	    m, BUS_DMA_NOWAIT) != 0) {
d801 2
a802 2
		if (bus_dmamap_load_mbuf(sc->sc_dmat, txb->txb_dmamap,
		    m0, BUS_DMA_NOWAIT) != 0) {
d806 4
a816 1
	/* m0 means this has to be done here, more bollocks */
d823 1
a824 1
	/* XXX nsegs are cool */
d826 1
d828 6
a833 5
	txd->tx_sa.sa_length = 1;
	txd->tx_sa.sa_sg[0].sg_length = m->m_len;
	txd->tx_sa.sa_sg[0].sg_addr_low = 0;
	txd->tx_sa.sa_sg[0].sg_addr_low = txb->txb_dmamap->dm_segs[0].ds_addr;
	txd->tx_owner = VIC_OWNER_NIC;
d835 1
a835 7
	/* XXX bus dma sync */
	txb->txb_m = m;

	if (VIC_TXURN_WARN(sc)) {
		if (ifp->if_flags & IFF_DEBUG)
			printf("%s: running out of tx descriptors\n",
			    DEVNAME(sc));
a836 1
	}
d840 3
@


1.13
log
@vmware frames are slightly short, but that is ok. done with clues from
brad@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.12 2006/11/01 04:34:23 dlg Exp $	*/
d823 1
d958 2
@


1.12
log
@fix the barriers in setlladdr.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.10 2006/10/31 06:04:15 dlg Exp $	*/
d78 2
d555 1
a555 1
		if (len < ETHER_MIN_LEN) {
@


1.11
log
@we're passing physical addresses to the adapter, so say so. add some magic
that lets me see packets coming out of the box.
@
text
@a694 2
	bus_space_barrier(sc->sc_iot, sc->sc_ioh, VIC_LLADDR, ETHER_ADDR_LEN,
	    BUS_SPACE_BARRIER_READ);
d697 2
@


1.10
log
@absolutely huge reworking on this driver (sorry reyk). so far attach,
resource mapping, mem allocation, init, and rx is working. the tx path
needs work, but that can happen in tree. overall it's closer to working
than the old code. if_vicvar.h goes away since nothing else uses it.

im getting this in so other people can play with it too.

ok brad@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.8 2006/05/28 00:20:21 brad Exp $	*/
d813 1
d816 1
d832 1
d837 2
@


1.9
log
@- stop counting input/output bytes in the driver as this is taken care of
in ether_input/ether_output.
- only count input packets when sure the packet can be received as opposed
to counting it unconditionally, then potentially running into an error
and then dropping the packet.

ok reyk@@
@
text
@d26 1
a30 1
#include <sys/systm.h>
a56 1
#include <dev/pci/if_vicvar.h>
d58 39
a96 21
int	vic_match(struct device *, void *, void *);
void	vic_attach(struct device *, struct device *, void *);
void	vic_link_state(struct vic_softc *);
void	vic_shutdown(void *);
int	vic_intr(void *);
void	vic_rx_proc(struct vic_softc *);
void	vic_tx_proc(struct vic_softc *);
void	vic_iff(struct vic_softc *, u_int);
void	vic_getlladdr(struct vic_softc *);
void	vic_setlladdr(struct vic_softc *);
int	vic_media_change(struct ifnet *);
void	vic_media_status(struct ifnet *, struct ifmediareq *);
void	vic_start(struct ifnet *);
int	vic_tx_start(struct vic_softc *, struct mbuf *);
void	vic_watchdog(struct ifnet *);
int	vic_ioctl(struct ifnet *, u_long, caddr_t);
void	vic_init(struct ifnet *);
void	vic_stop(struct ifnet *);
void	vic_printb(unsigned short, char *);
void	vic_timer(void *);
void	vic_poll(void *); /* XXX poll */
d98 2
a99 4
struct mbuf *vic_alloc_mbuf(struct vic_softc *, bus_dmamap_t);
int	vic_alloc_data(struct vic_softc *);
void	vic_reset_data(struct vic_softc *);
void	vic_free_data(struct vic_softc *);
d101 32
a132 2
struct cfattach vic_ca = {
	sizeof(struct vic_softc), vic_match, vic_attach
d139 46
d201 6
a206 12
	struct vic_softc *sc = (struct vic_softc *)self;
	struct pci_attach_args *pa = aux;
	pci_chipset_tag_t pc = pa->pa_pc;
	pci_intr_handle_t ih;
	const char *intrstr = NULL;
	bus_size_t size;
	struct ifnet *ifp;

	/* Enable I/O mapping */
	if (pci_mapreg_map(pa, VIC_BAR0, PCI_MAPREG_TYPE_IO, 0,
	    &sc->sc_st, &sc->sc_sh, NULL, &size, 0)) {
		printf(": I/O mapping of register space failed\n");
d210 3
a212 4
	/* Map and enable the interrupt line */
	if (pci_intr_map(pa, &ih)) {
		printf(": interrupt mapping failed\n");
		goto fail_1;
d215 3
a217 10
	intrstr = pci_intr_string(pc, ih);

	sc->sc_ih = pci_intr_establish(pc, ih, IPL_NET, vic_intr, sc,
	    sc->sc_dev.dv_xname);
	if (sc->sc_ih == NULL) {
		printf(": couldn't establish interrupt");
		if (intrstr != NULL)
			printf(" at %s", intrstr);
		printf("\n");
		goto fail_1;
d220 3
a222 17
	printf(": %s\n", intrstr);

	sc->sc_dmat = pa->pa_dmat;

	sc->sc_ver_major = VIC_READ(VIC_VERSION_MAJOR);
	sc->sc_ver_minor = VIC_READ(VIC_VERSION_MINOR);

	printf("%s: vmxnet %X", sc->sc_dev.dv_xname,
	    sc->sc_ver_major & ~VIC_VERSION_MAJOR_M);

	/* Check for a supported version */
	if (((sc->sc_ver_major & VIC_VERSION_MAJOR_M) !=
	    (VIC_MAGIC & VIC_VERSION_MAJOR_M)) ||
	    VIC_MAGIC > sc->sc_ver_major ||
	    VIC_MAGIC < sc->sc_ver_minor) {
		printf(" unsupported device\n");
		goto fail_2;
a224 24
	VIC_WRITE(VIC_CMD, VIC_CMD_NUM_Rx_BUF);
	sc->sc_nrxbuf = VIC_READ(VIC_CMD);
	if (sc->sc_nrxbuf > VIC_NBUF_MAX || sc->sc_nrxbuf == 0)
		sc->sc_nrxbuf = VIC_NBUF;

	VIC_WRITE(VIC_CMD, VIC_CMD_NUM_Tx_BUF);
	sc->sc_ntxbuf = VIC_READ(VIC_CMD);
	if (sc->sc_ntxbuf > VIC_NBUF_MAX || sc->sc_ntxbuf == 0)
		sc->sc_ntxbuf = VIC_NBUF;

	VIC_WRITE(VIC_CMD, VIC_CMD_FEATURE);
	sc->sc_feature = VIC_READ(VIC_CMD);

	VIC_WRITE(VIC_CMD, VIC_CMD_HWCAP);
	sc->sc_cap = VIC_READ(VIC_CMD);
	if (sc->sc_cap) {
		printf(", ");
		vic_printb(sc->sc_cap, VIC_CMD_HWCAP_BITS);
	}

	printf("\n");

	vic_getlladdr(sc);

d234 1
a234 1
	strlcpy(ifp->if_xname, sc->sc_dev.dv_xname, IFNAMSIZ);
a248 8
	/* Allocate Rx and Tx queues */
	if (vic_alloc_data(sc) != 0) {
		printf(": could not allocate queues\n");
		goto fail_2;
	}

	printf(", address %s\n", ether_sprintf(sc->sc_lladdr));

d258 9
a266 1
	sc->sc_sdhook = shutdownhook_establish(vic_shutdown, sc);
d268 33
a300 2
	/* Initialize timeout for link state update. */
	timeout_set(&sc->sc_timer, vic_timer, sc);
d302 165
a466 3
	/* XXX poll */
	timeout_set(&sc->sc_poll, vic_poll, sc);
	return;
d468 5
a472 2
fail_2:
	pci_intr_disestablish(pc, sc->sc_ih);
d474 11
a484 2
fail_1:
	bus_space_unmap(sc->sc_st, sc->sc_sh, size);
d494 1
a494 1
	status = VIC_READ(VIC_STATUS);
a514 1
	struct ifnet *ifp = &sc->sc_ac.ac_if;
d516 1
a516 6
	VIC_WRITE(VIC_CMD, VIC_CMD_INTR_ACK);

#ifdef VIC_DEBUG
	if (ifp->if_flags & IFF_DEBUG)
		printf("%s: %s\n", sc->sc_dev.dv_xname, __func__);
#endif
d527 8
a534 5
	struct ifnet *ifp = &sc->sc_ac.ac_if;
	struct vic_rxdesc *desc;
	struct vic_rxbuf *rxb;
	struct mbuf *m;
	int len, idx;
d537 1
a537 5
		bus_dmamap_sync(sc->sc_dmat, sc->sc_map, 0,
		    sizeof(struct vic_data),
		    BUS_DMASYNC_POSTREAD | BUS_DMASYNC_POSTWRITE);

		idx = letoh32(sc->sc_data->vd_rx_nextidx);
d546 3
a548 4
		bus_dmamap_sync(sc->sc_dmat, sc->sc_map,
		    VIC_OFF_RXDESC(idx), sizeof(struct vic_rxdesc),
		    BUS_DMASYNC_POSTREAD | BUS_DMASYNC_POSTWRITE);
		desc = &sc->sc_rxq[idx];
d550 1
a550 2
		if (desc->rx_owner != VIC_OWNER_DRIVER)
			break;
d552 1
a552 1
		len = letoh32(desc->rx_length);
d558 1
a558 2
		if ((rxb = (struct vic_rxbuf *)desc->rx_priv) == NULL ||
		    rxb->rxb_m == NULL) {
d560 1
a560 3
			if (ifp->if_flags & IFF_DEBUG)
				printf("%s: receive buffer error\n",
				    sc->sc_dev.dv_xname);
d564 4
a567 3
		bus_dmamap_sync(sc->sc_dmat, rxb->rxb_map, 0,
		    rxb->rxb_map->dm_mapsize, BUS_DMASYNC_POSTREAD);
		bus_dmamap_unload(sc->sc_dmat, rxb->rxb_map);
d574 2
a575 1
		if ((rxb->rxb_m = vic_alloc_mbuf(sc, rxb->rxb_map)) == NULL) {
d577 1
a577 3
			if (ifp->if_flags & IFF_DEBUG)
				printf("%s: receive buffer failed\n",
				    sc->sc_dev.dv_xname);
d580 3
a582 1
		desc->rx_physaddr = rxb->rxb_map->dm_segs->ds_addr;
d593 2
a594 2
 nextp:
		desc->rx_owner = VIC_OWNER_NIC;
d597 3
d605 4
a608 4
	struct ifnet *ifp = &sc->sc_ac.ac_if;
	struct vic_txdesc *desc;
	struct vic_txbuf *txb;
	int idx;
d610 2
a611 4
	for (; sc->sc_txpending;) {
		bus_dmamap_sync(sc->sc_dmat, sc->sc_map, 0,
		    sizeof(struct vic_data),
		    BUS_DMASYNC_POSTREAD | BUS_DMASYNC_POSTWRITE);
d613 2
a614 1
		idx = letoh32(sc->sc_data->vd_tx_curidx);
d623 3
a625 4
		bus_dmamap_sync(sc->sc_dmat, sc->sc_map,
		    VIC_OFF_TXDESC(idx), sizeof(struct vic_rxdesc),
		    BUS_DMASYNC_POSTREAD | BUS_DMASYNC_POSTWRITE);
		desc = &sc->sc_txq[idx];
d627 1
a627 2
		if (desc->tx_owner != VIC_OWNER_DRIVER)
			break;
d629 1
a629 2
		if ((txb = (struct vic_txbuf *)desc->tx_priv) == NULL ||
		    txb->txb_m == NULL) {
d633 1
a633 1
				    sc->sc_dev.dv_xname);
d637 6
a642 8
		bus_dmamap_sync(sc->sc_dmat, txb->txb_map, 0,
		    txb->txb_map->dm_mapsize, BUS_DMASYNC_POSTREAD);
		bus_dmamap_unload(sc->sc_dmat, txb->txb_map);
		if (txb->txb_m != NULL) {
			m_freem(txb->txb_m);
			txb->txb_m = NULL;
			ifp->if_flags &= ~IFF_OACTIVE;
		}
d650 2
a651 2
	sc->sc_txtimeout = 0;
	ifp->if_flags &= ~IFF_OACTIVE;
d665 1
d668 1
d670 2
a671 2
	VIC_WRITE(VIC_CMD, VIC_CMD_MCASTFIL);
	VIC_WRITE(VIC_CMD, VIC_CMD_IFF);
a677 1
	int i;
d680 6
a685 3
	reg = sc->sc_cap & VIC_CMD_HWCAP_VPROM ? VIC_VPROM : VIC_LLADDR;
	for (i = 0; i < ETHER_ADDR_LEN; i++)
		sc->sc_lladdr[i] = VIC_READ8(reg + i);
d695 4
a698 4
	int i;

	for (i = 0; i < ETHER_ADDR_LEN; i++)
		VIC_WRITE8(VIC_LLADDR + i, sc->sc_lladdr[i]);
d726 2
a727 3
	struct vic_softc *sc = (struct vic_softc *)ifp->if_softc;
	struct mbuf *m;
	int error;
d732 1
a732 1
	for (;; error = 0) {
d737 4
a740 7
#if NBPFILTER > 0
		if (ifp->if_bpf)
			bpf_mtap(ifp->if_bpf, m, BPF_DIRECTION_OUT);
#endif

		if ((error = vic_tx_start(sc, m)) != 0)
			ifp->if_oerrors++;
d745 1
a745 1
vic_tx_start(struct vic_softc *sc, struct mbuf *m)
d747 5
a751 5
	struct ifnet *ifp = &sc->sc_ac.ac_if;
	struct vic_txbuf *txb;
	struct vic_txdesc *desc;
	struct mbuf *m0 = NULL;
	int idx;
d753 1
a753 2
	bus_dmamap_sync(sc->sc_dmat, sc->sc_map, 0,
	    sizeof(struct vic_data),
d756 1
a756 1
	idx = letoh32(sc->sc_data->vd_tx_nextidx);
d760 1
a760 2
			printf("%s: transmit index error\n",
			    sc->sc_dev.dv_xname);
d764 2
a765 6
	bus_dmamap_sync(sc->sc_dmat, sc->sc_map,
	    VIC_OFF_TXDESC(idx), sizeof(struct vic_txdesc),
	    BUS_DMASYNC_POSTREAD | BUS_DMASYNC_POSTWRITE);

	desc = &sc->sc_txq[idx];
	txb = (struct vic_txbuf *)desc->tx_priv;
a769 6
	} else if (txb == NULL) {
		ifp->if_oerrors++;
		if (ifp->if_flags & IFF_DEBUG)
			printf("%s: transmit buffer error\n",
			    sc->sc_dev.dv_xname);
		return (ENOBUFS);
d776 1
a776 1
	if (bus_dmamap_load_mbuf(sc->sc_dmat, txb->txb_map,
d778 1
d791 1
a791 1
		if (bus_dmamap_load_mbuf(sc->sc_dmat, txb->txb_map,
d798 6
d811 8
a818 5
	desc->tx_flags = VIC_TX_FLAGS_KEEP;
	desc->tx_sa.sa_length = 1;
	desc->tx_sa.sa_sg[0].sg_length = htole16(m->m_len);
	desc->tx_sa.sa_sg[0].sg_addr_low = txb->txb_map->dm_segs->ds_addr;
	desc->tx_owner = VIC_OWNER_NIC;
d823 2
a824 2
			    sc->sc_dev.dv_xname);
		desc->tx_flags |= VIC_TX_FLAGS_TXURN;
a827 1

a828 2
	sc->sc_txtimeout = VIC_TX_TIMEOUT;
	ifp->if_timer = 1;
d832 3
d841 1
a843 2
	ifp->if_timer = 0;

a851 1
		ifp->if_timer = 1;
d856 1
d935 5
a939 2
	struct vic_softc *sc = (struct vic_softc *)ifp->if_softc;
	int s;
d943 2
a944 10
	timeout_add(&sc->sc_timer, hz * VIC_TIMER_DELAY);

	vic_reset_data(sc);

#ifdef notyet
	VIC_WRITE(VIC_CMD, VIC_CMD_INTR_ENABLE);
#endif

	VIC_WRITE(VIC_DATA_ADDR, sc->sc_physaddr);
	VIC_WRITE(VIC_DATA_LENGTH, htole32(sc->sc_size));
a949 6
#ifdef VIC_DEBUG
	if (ifp->if_flags & IFF_DEBUG)
		printf("%s: physaddr 0x%08x length 0x%08x\n",
		    sc->sc_dev.dv_xname, sc->sc_physaddr, sc->sc_size);
#endif

d955 1
a955 6
	/* XXX poll */
	if (ifp->if_flags & IFF_LINK0) {
		sc->sc_polling = 1;
		timeout_add(&sc->sc_poll, VIC_TIMER_MS(100));
	} else
		sc->sc_polling = 0;
d963 1
a969 1
	ifp->if_timer = 0;
d973 1
a973 1
	VIC_WRITE(VIC_CMD, VIC_CMD_INTR_DISABLE);
d976 1
a976 1
	VIC_WRITE(VIC_DATA_ADDR, 0);
a981 6
	/* XXX poll */
	if (sc->sc_polling) {
		sc->sc_polling = 0;
		timeout_del(&sc->sc_poll);
	}

d983 1
a983 25
}

void
vic_printb(unsigned short v, char *bits)
{
	int i, any = 0;
	char c;

	/*
	 * Used to print capability bits on startup
	 */
	bits++;
	if (bits) {
		while ((i = *bits++)) {
			if (v & (1 << (i-1))) {
				if (any)
					printf(" ");
				any = 1;
				for (; (c = *bits) > 32; bits++)
					printf("%c", c);
			} else
				for (; *bits > 32; bits++)
					;
		}
	}
d994 1
d1000 2
d1003 1
a1003 2
		printf("%s: could not load mbuf DMA map",
		    sc->sc_dev.dv_xname);
a1010 109
int
vic_alloc_data(struct vic_softc *sc)
{
	struct vic_rxbuf *rxb;
	struct vic_txbuf *txb;
	u_int32_t offset;
	int i, error;

	sc->sc_size = sizeof(struct vic_data) +
	    (sc->sc_nrxbuf + VIC_QUEUE2_SIZE) * sizeof(struct vic_rxdesc) +
	    sc->sc_ntxbuf * sizeof(struct vic_txdesc);

	if ((error = bus_dmamap_create(sc->sc_dmat, sc->sc_size, 1,
	    sc->sc_size, 0, BUS_DMA_NOWAIT, &sc->sc_map)) != 0) {
		printf("%s: could not create DMA material\n",
		    sc->sc_dev.dv_xname);
		goto fail;
	}

	if ((error = bus_dmamem_alloc(sc->sc_dmat, sc->sc_size, PAGE_SIZE, 0,
	    &sc->sc_seg, 1, &sc->sc_nsegs, BUS_DMA_NOWAIT)) != 0) {
		printf("%s: could not allocate DMA memory\n",
		    sc->sc_dev.dv_xname);
		goto fail;
	}

	if ((error = bus_dmamem_map(sc->sc_dmat, &sc->sc_seg,
	    sc->sc_nsegs, sc->sc_size, (caddr_t *)&sc->sc_data,
	    BUS_DMA_NOWAIT | BUS_DMA_COHERENT)) != 0) {
		printf("%s: could not map DMA memory\n",
		    sc->sc_dev.dv_xname);
		goto fail;
	}

	if ((error = bus_dmamap_load(sc->sc_dmat, sc->sc_map,
	    sc->sc_data, sc->sc_size, NULL, BUS_DMA_NOWAIT)) != 0) {
		printf("%s: could not load DMA map\n",
		    sc->sc_dev.dv_xname);
		goto fail;
	}

	bzero(sc->sc_data, sc->sc_size);
	sc->sc_physaddr = sc->sc_map->dm_segs->ds_addr;
	sc->sc_data->vd_magic = VIC_MAGIC;
	sc->sc_data->vd_length = htole32(sc->sc_size);
	offset = (u_int32_t)sc->sc_data + sizeof(struct vic_data);

#ifdef VIC_DEBUG
	printf("%s: (rxbuf %d * %d) (txbuf %d * %d) (size %d)\n",
	    sc->sc_dev.dv_xname,
	    sc->sc_nrxbuf, sizeof(struct vic_rxdesc),
	    sc->sc_ntxbuf, sizeof(struct vic_txdesc),
	    sc->sc_size);
#endif

	/* Setup the Rx queue */
	sc->sc_rxq = (struct vic_rxdesc *)offset;
	sc->sc_data->vd_rx_offset = htole32(offset);
	sc->sc_data->vd_rx_length = htole32(sc->sc_nrxbuf);
	offset += sc->sc_nrxbuf + sizeof(struct vic_rxdesc);
	for (i = 0; i < sc->sc_nrxbuf; i++) {
		rxb = &sc->sc_rxbuf[i];
		if ((error = bus_dmamap_create(sc->sc_dmat, MCLBYTES,
		    VIC_MAX_SCATTER, MCLBYTES, 0, BUS_DMA_NOWAIT,
		    &rxb->rxb_map)) != 0) {
			printf("%s: could not create rx DMA map\n",
			    sc->sc_dev.dv_xname);
			goto fail;
		}

		/* Preallocate the Rx mbuf */
		if ((rxb->rxb_m = vic_alloc_mbuf(sc, rxb->rxb_map)) == NULL) {
			error = ENOMEM;
			goto fail;
		}
		sc->sc_rxq[i].rx_physaddr = rxb->rxb_map->dm_segs->ds_addr;
	}

	/* Setup Rx queue 2 (unused gap) */
	sc->sc_rxq2 = (struct vic_rxdesc *)offset;
	sc->sc_data->vd_rx_offset = htole32(offset);
	sc->sc_data->vd_rx_length = htole32(1);
	sc->sc_rxq2[0].rx_owner = VIC_OWNER_DRIVER;
	offset += sizeof(struct vic_rxdesc);

	/* Setup the Tx queue */
	sc->sc_txq = (struct vic_txdesc *)offset;
	sc->sc_data->vd_tx_offset = htole32(offset);
	sc->sc_data->vd_tx_length = htole32(sc->sc_ntxbuf);
	offset += sc->sc_ntxbuf + sizeof(struct vic_txdesc);
	for (i = 0; i < sc->sc_ntxbuf; i++) {
		txb = &sc->sc_txbuf[i];
		if ((error = bus_dmamap_create(sc->sc_dmat, MCLBYTES,
		    VIC_MAX_SCATTER, MCLBYTES, 0, BUS_DMA_NOWAIT,
		    &txb->txb_map)) != 0) {
			printf("%s: could not create tx DMA map\n",
			    sc->sc_dev.dv_xname);
			goto fail;
		}
	}

	return (0);

 fail:
	vic_free_data(sc);

	return (error);
}

d1014 2
d1052 1
d1058 2
d1091 1
a1091 6

	bus_dmamap_sync(sc->sc_dmat, sc->sc_map, 0,
	    sc->sc_map->dm_mapsize, BUS_DMASYNC_POSTWRITE);
	bus_dmamap_unload(sc->sc_dmat, sc->sc_map);
	bus_dmamem_unmap(sc->sc_dmat, (caddr_t)sc->sc_data, sc->sc_size);
	bus_dmamem_free(sc->sc_dmat, &sc->sc_seg, sc->sc_nsegs);
d1097 2
a1098 13
	struct vic_softc *sc = (struct vic_softc *)arg;
	struct ifnet *ifp = &sc->sc_ac.ac_if;

#ifdef VIC_DEBUG
	if (ifp->if_flags & IFF_DEBUG) {
		if (sc->sc_polling)
			printf("%s: %s (polling #%u)\n",
			    ifp->if_xname, __func__, sc->sc_polling);
		else
			printf("%s: %s\n",
			    ifp->if_xname, __func__);
	}
#endif
d1104 9
a1112 1
	timeout_add(&sc->sc_timer, hz * VIC_TIMER_DELAY);
a1114 1
 /* XXX poll */
d1116 16
a1131 1
vic_poll(void *arg)
d1133 14
a1146 2
	struct vic_softc *sc = (struct vic_softc *)arg;
	int s;
d1148 3
a1150 1
	s = splnet();
d1152 1
a1152 2
	vic_rx_proc(sc);
	vic_tx_proc(sc);
d1154 1
a1154 1
	VIC_INC_POS(sc->sc_polling, UINT_MAX);
d1156 9
a1164 1
	timeout_add(&sc->sc_poll, VIC_TIMER_MS(100));
d1166 7
a1172 1
	splx(s);
@


1.8
log
@- remove ETHER_MAX_LEN_JUMBO and ETHERMTU_JUMBO.
- use if_hardmtu for MTU ioctl handlers.

ok reyk@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.7 2006/05/28 00:04:24 jason Exp $	*/
a317 3
		ifp->if_ibytes += len;
		ifp->if_ipackets++;

d350 2
a598 1
	ifp->if_obytes += m->m_len;
@


1.7
log
@unknown ioctl is ENOTTY not EINVAL
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.6 2006/03/25 22:41:46 djm Exp $	*/
d194 1
d668 1
a668 1
		if (ifr->ifr_mtu < ETHERMIN || ifr->ifr_mtu > ETHERMTU_JUMBO)
@


1.6
log
@allow bpf(4) to ignore packets based on their direction (inbound or
outbound), using a new BIOCSDIRFILT ioctl;
guidance, feedback and ok canacar@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.5 2006/03/04 03:33:05 brad Exp $	*/
d690 1
a690 1
		error = EINVAL;
@


1.5
log
@- Use sc->sc_dev.dv_xname everywhere.
- Always set IFCAP_VLAN_MTU.
- Remove some printf's from the error paths in vic_alloc_mbuf().
- Move the device struct up to the top of the softc struct
  so the driver will actually attach.. sometimes, still issues to resolve.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.4 2006/02/26 04:30:08 brad Exp $	*/
d354 1
a354 1
			bpf_mtap(ifp->if_bpf, m);
d505 1
a505 1
			bpf_mtap(ifp->if_bpf, m);
@


1.4
log
@clean up if there is a failure to attach.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.3 2006/02/26 02:21:31 brad Exp $	*/
d86 4
a93 4
struct cfattach vic_ca = {
	sizeof(struct vic_softc), vic_match, vic_attach
};

d104 1
a104 1
	    vic_devices, sizeof(vic_devices) / sizeof(vic_devices[0])));
d158 1
a158 1
		printf("unsupported device\n");
d166 1
a176 1

d182 2
d186 1
a186 4
	/* Initialise pseudo media types */
	ifmedia_init(&sc->sc_media, 0, vic_media_change, vic_media_status);
	ifmedia_add(&sc->sc_media, IFM_ETHER | IFM_AUTO, 0, NULL);
	ifmedia_set(&sc->sc_media, IFM_ETHER | IFM_AUTO);
a188 2
	ifp->if_carp = NULL;
	ifp->if_type = IFT_ETHER;
d190 2
d194 5
a198 3
	ifp->if_ioctl = vic_ioctl;
	ifp->if_output = ether_output;
	ifp->if_flags = IFF_SIMPLEX | IFF_BROADCAST | IFF_MULTICAST;
a199 1
	ifp->if_capabilities = 0;
d203 1
a203 1
		ifp->if_capabilities |= IFCAP_VLAN_HWTAGGING | IFCAP_VLAN_MTU;
a208 6
	IFQ_SET_MAXLEN(&ifp->if_snd, ifqmaxlen);
	IFQ_SET_READY(&ifp->if_snd);

	strlcpy(ifp->if_xname, sc->sc_dev.dv_xname, sizeof(ifp->if_xname));
	bcopy(sc->sc_lladdr, sc->sc_ac.ac_enaddr, ETHER_ADDR_LEN);

d211 1
a211 1
		printf(": could not allocate queues\n", ifp->if_xname);
d215 6
a220 1
	printf(", address: %s\n", ether_sprintf(sc->sc_lladdr));
d276 1
a276 1
		printf("%s: %s\n", ifp->if_xname, __func__);
d304 1
a304 1
				    ifp->if_xname);
d330 1
a330 1
				    ifp->if_xname);
d347 1
a347 1
				    ifp->if_xname);
d383 1
a383 1
				    ifp->if_xname);
d400 1
a400 1
				    ifp->if_xname);
d531 1
a531 1
			    ifp->if_xname);
d549 1
a549 1
			    ifp->if_xname);
d594 1
a594 1
			    ifp->if_xname);
d619 1
a619 1
			printf("%s: device timeout\n", ifp->if_xname);
d731 1
a731 1
		    ifp->if_xname, sc->sc_physaddr, sc->sc_size);
d808 1
a808 1
	struct mbuf *m;
d811 1
a811 3
	if (m == NULL) {
		printf("%s: could not allocate mbuf\n",
		    sc->sc_dev.dv_xname);
a812 1
	}
d815 1
a815 2
		printf("%s: could not allocate mbuf cluster\n",
		    sc->sc_dev.dv_xname);
d821 1
d916 1
a916 1
	sc->sc_data->vd_tx_length = htole32(sc->sc_nrxbuf);
@


1.3
log
@store the shutdown hook pointer in the softc struct.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.2 2006/02/26 02:13:54 brad Exp $	*/
d115 1
d118 1
a118 1
	/* Enable memory mapping */
d120 1
a120 1
	    &sc->sc_st, &sc->sc_sh, NULL, NULL, 0)) {
d128 1
a128 1
		return;
d140 1
a140 1
		return;
d159 1
a159 1
		return;
d218 1
a218 1
		return;
d234 7
@


1.2
log
@vic(4) is PCI only so make it look like a typical PCI only driver.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_vic.c,v 1.1 2006/02/25 23:49:04 reyk Exp $	*/
a115 1
	void *hook;
a145 5
	if ((hook = shutdownhook_establish(vic_shutdown, sc)) == NULL) {
		printf(": failed to establish the shutdown hook\n");
		return;
	}

d184 1
a184 2
	ifmedia_init(&sc->sc_media, 0, vic_media_change,
	    vic_media_status);
d226 2
a232 2

	return;
@


1.1
log
@Add vic(4), a driver for the VMware vmxnet network interface. This is
an alternative approach to the much slower pcn(4) emulation of VMware.

The driver is not yet working and work in progress.

ok brad@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d59 21
a79 24
int	 vic_pci_match(struct device *, void *, void *);
void	 vic_pci_attach(struct device *, struct device *, void *);
void	 vic_pci_shutdown(void *);

int	 vic_attach(struct vic_softc *);
void	 vic_link_state(struct vic_softc *);
void	 vic_shutdown(void *);
int	 vic_intr(void *);
void	 vic_rx_proc(struct vic_softc *);
void	 vic_tx_proc(struct vic_softc *);
void	 vic_iff(struct vic_softc *, u_int);
void	 vic_getlladdr(struct vic_softc *);
void	 vic_setlladdr(struct vic_softc *);
int	 vic_media_change(struct ifnet *);
void	 vic_media_status(struct ifnet *, struct ifmediareq *);
void	 vic_start(struct ifnet *);
int	 vic_tx_start(struct vic_softc *, struct mbuf *);
void	 vic_watchdog(struct ifnet *);
int	 vic_ioctl(struct ifnet *, u_long, caddr_t);
void	 vic_init(struct ifnet *);
void	 vic_stop(struct ifnet *);
void	 vic_printb(unsigned short, char *);
void	 vic_timer(void *);
void	 vic_poll(void *); /* XXX poll */
d82 3
a84 11
int	 vic_alloc_data(struct vic_softc *);
void	 vic_reset_data(struct vic_softc *);
void	 vic_free_data(struct vic_softc *);

struct vic_pci_softc {
	struct vic_softc	sc_sc;
	pci_chipset_tag_t	sc_pc;
	pcitag_t		sc_pcitag;
	pci_intr_handle_t	sc_iht;
	void			*sc_ih;
};
d91 1
a91 3
	sizeof(struct vic_pci_softc),
	vic_pci_match,
	vic_pci_attach
d94 1
a94 1
const struct pci_matchid vic_pci_devices[] = {
d101 1
a101 1
vic_pci_match(struct device *parent, void *match, void *aux)
d104 1
a104 2
	    vic_pci_devices, sizeof(vic_pci_devices) /
	    sizeof(vic_pci_devices[0])));
d108 1
a108 1
vic_pci_attach(struct device *parent, struct device *self, void *aux)
d110 1
a110 1
	struct vic_pci_softc *psc = (struct vic_pci_softc *)self;
a111 1
	struct vic_softc *sc = &psc->sc_sc;
d113 1
a113 1
	pcitag_t pt = pa->pa_tag;
d115 1
a116 12
	pcireg_t res;

	psc->sc_pc = pc;
	psc->sc_pcitag = pt;
	sc->sc_psc = psc;

	/* Validate PCI configuration */
	res = pci_conf_read(pc, pt, PCI_COMMAND_STATUS_REG);
	if ((res & PCI_COMMAND_MEM_ENABLE) == 0) {
		printf(": memory mapping is not available\n");
		return;
	}
d121 1
a121 1
		printf(": memory mapping of register space failed\n");
d126 1
a126 1
	if (pci_intr_map(pa, &psc->sc_iht)) {
d130 10
a139 4
	intrstr = pci_intr_string(pc, psc->sc_iht);
	if ((psc->sc_ih = pci_intr_establish(pc,
	    psc->sc_iht, IPL_NET, vic_intr, sc, sc->sc_dev.dv_xname)) == NULL) {
		printf(": failed to establish the interrupt\n");
d147 1
a147 1
	if ((hook = shutdownhook_establish(vic_pci_shutdown, psc)) == NULL) {
a151 21
	/* Finally, attach the device */
	if (vic_attach(sc) == 0)
		return;

	shutdownhook_disestablish(hook);

	return;
}

void
vic_pci_shutdown(void *self)
{
	struct vic_pci_softc *psc = (struct vic_pci_softc *)self;
	vic_shutdown(&psc->sc_sc);
}

int
vic_attach(struct vic_softc *sc)
{
	struct ifnet *ifp;

d164 1
a164 1
		return (1);
a188 2
	printf(", address: %s\n", ether_sprintf(sc->sc_lladdr));

d223 2
a224 2
		printf("%s: could not allocate queues\n", ifp->if_xname);
		return (1);
d227 2
d239 1
a239 1
	return (0);
d259 1
a259 1
vic_shutdown(void *arg)
d261 2
a262 1
	struct vic_softc *sc = (struct vic_softc *)arg;
@

