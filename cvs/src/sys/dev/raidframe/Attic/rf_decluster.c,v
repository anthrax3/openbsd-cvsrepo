head	1.6;
access;
symbols
	OPENBSD_5_1_BASE:1.5
	OPENBSD_5_1:1.5.0.38
	OPENBSD_5_0:1.5.0.36
	OPENBSD_5_0_BASE:1.5
	OPENBSD_4_9:1.5.0.34
	OPENBSD_4_9_BASE:1.5
	OPENBSD_4_8:1.5.0.32
	OPENBSD_4_8_BASE:1.5
	OPENBSD_4_7:1.5.0.28
	OPENBSD_4_7_BASE:1.5
	OPENBSD_4_6:1.5.0.30
	OPENBSD_4_6_BASE:1.5
	OPENBSD_4_5:1.5.0.26
	OPENBSD_4_5_BASE:1.5
	OPENBSD_4_4:1.5.0.24
	OPENBSD_4_4_BASE:1.5
	OPENBSD_4_3:1.5.0.22
	OPENBSD_4_3_BASE:1.5
	OPENBSD_4_2:1.5.0.20
	OPENBSD_4_2_BASE:1.5
	OPENBSD_4_1:1.5.0.18
	OPENBSD_4_1_BASE:1.5
	OPENBSD_4_0:1.5.0.16
	OPENBSD_4_0_BASE:1.5
	OPENBSD_3_9:1.5.0.14
	OPENBSD_3_9_BASE:1.5
	OPENBSD_3_8:1.5.0.12
	OPENBSD_3_8_BASE:1.5
	OPENBSD_3_7:1.5.0.10
	OPENBSD_3_7_BASE:1.5
	OPENBSD_3_6:1.5.0.8
	OPENBSD_3_6_BASE:1.5
	SMP_SYNC_A:1.5
	SMP_SYNC_B:1.5
	OPENBSD_3_5:1.5.0.6
	OPENBSD_3_5_BASE:1.5
	OPENBSD_3_4:1.5.0.4
	OPENBSD_3_4_BASE:1.5
	UBC_SYNC_A:1.5
	OPENBSD_3_3:1.5.0.2
	OPENBSD_3_3_BASE:1.5
	OPENBSD_3_2:1.4.0.12
	OPENBSD_3_2_BASE:1.4
	OPENBSD_3_1:1.4.0.10
	OPENBSD_3_1_BASE:1.4
	UBC_SYNC_B:1.4
	UBC:1.4.0.8
	UBC_BASE:1.4
	OPENBSD_3_0:1.4.0.6
	OPENBSD_3_0_BASE:1.4
	OPENBSD_2_9_BASE:1.4
	OPENBSD_2_9:1.4.0.4
	OPENBSD_2_8:1.4.0.2
	OPENBSD_2_8_BASE:1.4
	OPENBSD_2_7:1.3.0.4
	OPENBSD_2_7_BASE:1.3
	SMP:1.3.0.2
	SMP_BASE:1.3
	kame_19991208:1.2
	OPENBSD_2_6:1.2.0.4
	OPENBSD_2_6_BASE:1.2
	OPENBSD_2_5:1.2.0.2
	OPENBSD_2_5_BASE:1.2;
locks; strict;
comment	@ * @;


1.6
date	2012.04.06.15.53.58;	author jsing;	state dead;
branches;
next	1.5;

1.5
date	2002.12.16.07.01.03;	author tdeval;	state Exp;
branches;
next	1.4;

1.4
date	2000.08.08.16.07.40;	author peter;	state Exp;
branches
	1.4.8.1;
next	1.3;

1.3
date	2000.01.07.14.50.21;	author peter;	state Exp;
branches
	1.3.2.1;
next	1.2;

1.2
date	99.02.16.00.02.34;	author niklas;	state Exp;
branches;
next	1.1;

1.1
date	99.01.11.14.29.14;	author niklas;	state Exp;
branches;
next	;

1.3.2.1
date	2001.05.14.22.26.10;	author niklas;	state Exp;
branches;
next	1.3.2.2;

1.3.2.2
date	2003.03.28.00.38.27;	author niklas;	state Exp;
branches;
next	;

1.4.8.1
date	2003.05.19.22.21.51;	author tedu;	state Exp;
branches;
next	;


desc
@@


1.6
log
@Put raidframe in the attic.
@
text
@/*	$OpenBSD: rf_decluster.c,v 1.5 2002/12/16 07:01:03 tdeval Exp $	*/
/*	$NetBSD: rf_decluster.c,v 1.5 2000/03/07 01:54:29 oster Exp $	*/

/*
 * Copyright (c) 1995 Carnegie-Mellon University.
 * All rights reserved.
 *
 * Author: Mark Holland
 *
 * Permission to use, copy, modify and distribute this software and
 * its documentation is hereby granted, provided that both the copyright
 * notice and this permission notice appear in all copies of the
 * software, derivative works or modified versions, and any portions
 * thereof, and that both notices appear in supporting documentation.
 *
 * CARNEGIE MELLON ALLOWS FREE USE OF THIS SOFTWARE IN ITS "AS IS"
 * CONDITION.  CARNEGIE MELLON DISCLAIMS ANY LIABILITY OF ANY KIND
 * FOR ANY DAMAGES WHATSOEVER RESULTING FROM THE USE OF THIS SOFTWARE.
 *
 * Carnegie Mellon requests users of this software to return to
 *
 *  Software Distribution Coordinator  or  Software.Distribution@@CS.CMU.EDU
 *  School of Computer Science
 *  Carnegie Mellon University
 *  Pittsburgh PA 15213-3890
 *
 * any improvements or extensions that they make and grant Carnegie the
 * rights to redistribute these changes.
 */

/*****************************************************************************
 *
 * rf_decluster.c -- Code related to the declustered layout.
 *
 * Created 10-21-92 (MCH)
 *
 * Nov 93:	Adding support for distributed sparing. This code is a little
 *		complex; the basic layout used is as follows:
 *		Let F = (v-1)/GCD(r,v-1). The spare space for each set of
 *		F consecutive fulltables is grouped together and placed after
 *		that set of tables.
 *			+-------------------------------+
 *			|	  F fulltables		|
 *			|	  Spare Space		|
 *			|	  F fulltables		|
 *			|	  Spare Space		|
 *			|	      ...		|
 *			+-------------------------------+
 *
 *****************************************************************************/

#include "rf_types.h"
#include "rf_raid.h"
#include "rf_raidframe.h"
#include "rf_configure.h"
#include "rf_decluster.h"
#include "rf_debugMem.h"
#include "rf_utils.h"
#include "rf_alloclist.h"
#include "rf_general.h"
#include "rf_shutdown.h"

extern int rf_copyback_in_progress;	/* Debug only. */

/* Found in rf_kintf.c */
int  rf_GetSpareTableFromDaemon(RF_SparetWait_t *);

/* Configuration code. */

int
rf_ConfigureDeclustered(RF_ShutdownList_t **listp, RF_Raid_t *raidPtr,
    RF_Config_t *cfgPtr)
{
	RF_RaidLayout_t *layoutPtr = &(raidPtr->Layout);
	int b, v, k, r, lambda;	/* block design params */
	int i, j;
	RF_RowCol_t *first_avail_slot;
	RF_StripeCount_t complete_FT_count, numCompleteFullTablesPerDisk;
	RF_DeclusteredConfigInfo_t *info;
	RF_StripeCount_t PUsPerDisk, spareRegionDepthInPUs,
	    numCompleteSpareRegionsPerDisk, extraPUsPerDisk;
	RF_StripeCount_t totSparePUsPerDisk;
	RF_SectorNum_t diskOffsetOfLastFullTableInSUs;
	RF_SectorCount_t SpareSpaceInSUs;
	char *cfgBuf = (char *) (cfgPtr->layoutSpecific);
	RF_StripeNum_t l, SUID;

	SUID = l = 0;
	numCompleteSpareRegionsPerDisk = 0;

	/* 1. Create layout specific structure. */
	RF_MallocAndAdd(info, sizeof(RF_DeclusteredConfigInfo_t),
	    (RF_DeclusteredConfigInfo_t *), raidPtr->cleanupList);
	if (info == NULL)
		return (ENOMEM);
	layoutPtr->layoutSpecificInfo = (void *) info;
	info->SpareTable = NULL;

	/* 2. Extract parameters from the config structure. */
	if (layoutPtr->map->flags & RF_DISTRIBUTE_SPARE) {
		bcopy(cfgBuf, info->sparemap_fname, RF_SPAREMAP_NAME_LEN);
	}
	cfgBuf += RF_SPAREMAP_NAME_LEN;

	b = *((int *) cfgBuf);
	cfgBuf += sizeof(int);
	v = *((int *) cfgBuf);
	cfgBuf += sizeof(int);
	k = *((int *) cfgBuf);
	cfgBuf += sizeof(int);
	r = *((int *) cfgBuf);
	cfgBuf += sizeof(int);
	lambda = *((int *) cfgBuf);
	cfgBuf += sizeof(int);
	raidPtr->noRotate = *((int *) cfgBuf);
	cfgBuf += sizeof(int);

	/*
	 * The sparemaps are generated assuming that parity is rotated, so we
	 * issue a warning if both distributed sparing and no-rotate are on at
	 * the same time.
	 */
	if ((layoutPtr->map->flags & RF_DISTRIBUTE_SPARE) &&
	    raidPtr->noRotate) {
		RF_ERRORMSG("Warning:  distributed sparing specified without"
		    " parity rotation.\n");
	}
	if (raidPtr->numCol != v) {
		RF_ERRORMSG2("RAID: config error: table element count (%d)"
		    " not equal to no. of cols (%d).\n", v, raidPtr->numCol);
		return (EINVAL);
	}
	/* 3. Set up the values used in the mapping code. */
	info->BlocksPerTable = b;
	info->Lambda = lambda;
	info->NumParityReps = info->groupSize = k;
	/* b blks, k-1 SUs each. */
	info->SUsPerTable = b * (k - 1) * layoutPtr->SUsPerPU;
	info->SUsPerFullTable = k * info->SUsPerTable;	/* rot k times */
	info->PUsPerBlock = k - 1;
	info->SUsPerBlock = info->PUsPerBlock * layoutPtr->SUsPerPU;
	info->TableDepthInPUs = (b * k) / v;
	/* k repetitions. */
	info->FullTableDepthInPUs = info->TableDepthInPUs * k;

	/* Used only in distributed sparing case. */
	/* (v-1)/gcd fulltables. */
	info->FullTablesPerSpareRegion = (v - 1) / rf_gcd(r, v - 1);
	info->TablesPerSpareRegion = k * info->FullTablesPerSpareRegion;
	info->SpareSpaceDepthPerRegionInSUs = (r * info->TablesPerSpareRegion /
	    (v - 1)) * layoutPtr->SUsPerPU;

	/* Check to make sure the block design is sufficiently small. */
	if ((raidPtr->Layout.map->flags & RF_DISTRIBUTE_SPARE)) {
		if (info->FullTableDepthInPUs * layoutPtr->SUsPerPU +
		    info->SpareSpaceDepthPerRegionInSUs >
		    layoutPtr->stripeUnitsPerDisk) {
			RF_ERRORMSG3("RAID: config error: Full Table depth"
			    " (%d) + Spare Space (%d) larger than disk size"
			    " (%d) (BD too big).\n",
			    (int) info->FullTableDepthInPUs,
			    (int) info->SpareSpaceDepthPerRegionInSUs,
			    (int) layoutPtr->stripeUnitsPerDisk);
			return (EINVAL);
		}
	} else {
		if (info->TableDepthInPUs * layoutPtr->SUsPerPU >
		    layoutPtr->stripeUnitsPerDisk) {
			RF_ERRORMSG2("RAID: config error: Table depth (%d)"
			    " larger than disk size (%d) (BD too big).\n",
			    (int) (info->TableDepthInPUs * layoutPtr->SUsPerPU),
			    (int) layoutPtr->stripeUnitsPerDisk);
			return (EINVAL);
		}
	}


	/*
	 * Compute the size of each disk, and the number of tables in the last
	 * fulltable (which need not be complete).
	 */
	if (raidPtr->Layout.map->flags & RF_DISTRIBUTE_SPARE) {

		PUsPerDisk = layoutPtr->stripeUnitsPerDisk /
		    layoutPtr->SUsPerPU;
		spareRegionDepthInPUs =
		    (info->TablesPerSpareRegion * info->TableDepthInPUs +
		    (info->TablesPerSpareRegion * info->TableDepthInPUs) /
		    (v - 1));
		info->SpareRegionDepthInSUs =
		    spareRegionDepthInPUs * layoutPtr->SUsPerPU;

		numCompleteSpareRegionsPerDisk =
		    PUsPerDisk / spareRegionDepthInPUs;
		info->NumCompleteSRs = numCompleteSpareRegionsPerDisk;
		extraPUsPerDisk = PUsPerDisk % spareRegionDepthInPUs;

		/*
		 * Assume conservatively that we need the full amount of spare
		 * space in one region in order to provide spares for the
		 * partial spare region at the end of the array. We set "i"
		 * to the number of tables in the partial spare region. This
		 * may actually include some fulltables.
		 */
		extraPUsPerDisk -= (info->SpareSpaceDepthPerRegionInSUs /
		    layoutPtr->SUsPerPU);
		if (extraPUsPerDisk <= 0)
			i = 0;
		else
			i = extraPUsPerDisk / info->TableDepthInPUs;

		complete_FT_count = raidPtr->numRow *
		    (numCompleteSpareRegionsPerDisk *
		    (info->TablesPerSpareRegion / k) + i / k);
		info->FullTableLimitSUID =
		    complete_FT_count * info->SUsPerFullTable;
		info->ExtraTablesPerDisk = i % k;

		/*
		 * Note that in the last spare region, the spare space is
		 * complete even though data/parity space is not.
		 */
		totSparePUsPerDisk = (numCompleteSpareRegionsPerDisk + 1) *
		    (info->SpareSpaceDepthPerRegionInSUs / layoutPtr->SUsPerPU);
		info->TotSparePUsPerDisk = totSparePUsPerDisk;

		layoutPtr->stripeUnitsPerDisk =
		    ((complete_FT_count / raidPtr->numRow) *
		    info->FullTableDepthInPUs +	/* data & parity space */
		    info->ExtraTablesPerDisk * info->TableDepthInPUs +
		    totSparePUsPerDisk		/* spare space */
		    ) * layoutPtr->SUsPerPU;
		layoutPtr->dataStripeUnitsPerDisk =
		    (complete_FT_count * info->FullTableDepthInPUs +
		    info->ExtraTablesPerDisk * info->TableDepthInPUs) *
		    layoutPtr->SUsPerPU * (k - 1) / k;

	} else {
		/*
		 * Non-dist spare case:  force each disk to contain an
		 * integral number of tables.
		 */
		layoutPtr->stripeUnitsPerDisk /=
		    (info->TableDepthInPUs * layoutPtr->SUsPerPU);
		layoutPtr->stripeUnitsPerDisk *=
		    (info->TableDepthInPUs * layoutPtr->SUsPerPU);

		/*
		 * Compute the number of tables in the last fulltable, which
		 * need not be complete.
		 */
		complete_FT_count =
		    ((layoutPtr->stripeUnitsPerDisk / layoutPtr->SUsPerPU) /
		    info->FullTableDepthInPUs) * raidPtr->numRow;

		info->FullTableLimitSUID =
		    complete_FT_count * info->SUsPerFullTable;
		info->ExtraTablesPerDisk =
		    ((layoutPtr->stripeUnitsPerDisk / layoutPtr->SUsPerPU) /
		    info->TableDepthInPUs) % k;
	}

	raidPtr->sectorsPerDisk = layoutPtr->stripeUnitsPerDisk *
		    layoutPtr->sectorsPerStripeUnit;

	/*
	 * Find the disk offset of the stripe unit where the last fulltable
	 * starts.
	 */
	numCompleteFullTablesPerDisk = complete_FT_count / raidPtr->numRow;
	diskOffsetOfLastFullTableInSUs = numCompleteFullTablesPerDisk *
	    info->FullTableDepthInPUs * layoutPtr->SUsPerPU;
	if (raidPtr->Layout.map->flags & RF_DISTRIBUTE_SPARE) {
		SpareSpaceInSUs = numCompleteSpareRegionsPerDisk *
		    info->SpareSpaceDepthPerRegionInSUs;
		diskOffsetOfLastFullTableInSUs += SpareSpaceInSUs;
		info->DiskOffsetOfLastSpareSpaceChunkInSUs =
		    diskOffsetOfLastFullTableInSUs + info->ExtraTablesPerDisk *
		    info->TableDepthInPUs * layoutPtr->SUsPerPU;
	}
	info->DiskOffsetOfLastFullTableInSUs = diskOffsetOfLastFullTableInSUs;
	info->numCompleteFullTablesPerDisk = numCompleteFullTablesPerDisk;

	/* 4. Create and initialize the lookup tables. */
	info->LayoutTable = rf_make_2d_array(b, k, raidPtr->cleanupList);
	if (info->LayoutTable == NULL)
		return (ENOMEM);
	info->OffsetTable = rf_make_2d_array(b, k, raidPtr->cleanupList);
	if (info->OffsetTable == NULL)
		return (ENOMEM);
	info->BlockTable = rf_make_2d_array(info->TableDepthInPUs *
	    layoutPtr->SUsPerPU, raidPtr->numCol, raidPtr->cleanupList);
	if (info->BlockTable == NULL)
		return (ENOMEM);

	first_avail_slot = rf_make_1d_array(v, NULL);
	if (first_avail_slot == NULL)
		return (ENOMEM);

	for (i = 0; i < b; i++)
		for (j = 0; j < k; j++)
			info->LayoutTable[i][j] = *cfgBuf++;

	/* Initialize the offset table. */
	for (i = 0; i < b; i++)
		for (j = 0; j < k; j++) {
			info->OffsetTable[i][j] =
			    first_avail_slot[info->LayoutTable[i][j]];
			first_avail_slot[info->LayoutTable[i][j]]++;
		}

	/* Initialize the block table. */
	for (SUID = l = 0; l < layoutPtr->SUsPerPU; l++) {
		for (i = 0; i < b; i++) {
			for (j = 0; j < k; j++) {
				info->BlockTable[(info->OffsetTable[i][j] *
				    layoutPtr->SUsPerPU) + l]
				    [info->LayoutTable[i][j]] = SUID;
			}
			SUID++;
		}
	}

	rf_free_1d_array(first_avail_slot, v);

	/* 5. Set up the remaining redundant-but-useful parameters. */

	raidPtr->totalSectors = (k * complete_FT_count + raidPtr->numRow *
	    info->ExtraTablesPerDisk) * info->SUsPerTable *
	    layoutPtr->sectorsPerStripeUnit;
	layoutPtr->numStripe = (raidPtr->totalSectors /
	    layoutPtr->sectorsPerStripeUnit) / (k - 1);

	/*
	 * Strange evaluation order below to try and minimize overflow
	 * problems.
	 */

	layoutPtr->dataSectorsPerStripe =
	    (k - 1) * layoutPtr->sectorsPerStripeUnit;
	layoutPtr->bytesPerStripeUnit = layoutPtr->sectorsPerStripeUnit <<
	    raidPtr->logBytesPerSector;
	layoutPtr->numDataCol = k - 1;
	layoutPtr->numParityCol = 1;

	return (0);
}

/* Declustering with distributed sparing. */
void rf_ShutdownDeclusteredDS(RF_ThreadArg_t);
void
rf_ShutdownDeclusteredDS(RF_ThreadArg_t arg)
{
	RF_DeclusteredConfigInfo_t *info;
	RF_Raid_t *raidPtr;

	raidPtr = (RF_Raid_t *) arg;
	info =
	    (RF_DeclusteredConfigInfo_t *) raidPtr->Layout.layoutSpecificInfo;
	if (info->SpareTable)
		rf_FreeSpareTable(raidPtr);
}

int
rf_ConfigureDeclusteredDS(RF_ShutdownList_t **listp, RF_Raid_t *raidPtr,
    RF_Config_t *cfgPtr)
{
	int rc;

	rc = rf_ConfigureDeclustered(listp, raidPtr, cfgPtr);
	if (rc)
		return (rc);

	rc = rf_ShutdownCreate(listp, rf_ShutdownDeclusteredDS, raidPtr);
	if (rc) {
		RF_ERRORMSG1("Got %d adding shutdown event for"
		    " DeclusteredDS.\n", rc);
		rf_ShutdownDeclusteredDS(raidPtr);
		return (rc);
	}

	return (0);
}

void
rf_MapSectorDeclustered(RF_Raid_t *raidPtr, RF_RaidAddr_t raidSector,
    RF_RowCol_t *row, RF_RowCol_t *col, RF_SectorNum_t *diskSector, int remap)
{
	RF_RaidLayout_t *layoutPtr = &(raidPtr->Layout);
	RF_DeclusteredConfigInfo_t *info =
	    (RF_DeclusteredConfigInfo_t *) layoutPtr->layoutSpecificInfo;
	RF_StripeNum_t SUID = raidSector / layoutPtr->sectorsPerStripeUnit;
	RF_StripeNum_t FullTableID, FullTableOffset, TableID, TableOffset;
	RF_StripeNum_t BlockID, BlockOffset, RepIndex;
	RF_StripeCount_t sus_per_fulltable = info->SUsPerFullTable;
	RF_StripeCount_t fulltable_depth =
	    info->FullTableDepthInPUs * layoutPtr->SUsPerPU;
	RF_StripeNum_t base_suid = 0, outSU, SpareRegion = 0, SpareSpace = 0;

	rf_decluster_adjust_params(layoutPtr, &SUID, &sus_per_fulltable,
	    &fulltable_depth, &base_suid);

	/* Fulltable ID within array (across rows). */
	FullTableID = SUID / sus_per_fulltable;
	if (raidPtr->numRow == 1)
		*row = 0;	/* Avoid a mod and a div in the common case. */
	else {
		*row = FullTableID % raidPtr->numRow;
		/* Convert to fulltable ID on this disk. */
		FullTableID /= raidPtr->numRow;
	}
	if (raidPtr->Layout.map->flags & RF_DISTRIBUTE_SPARE) {
		SpareRegion = FullTableID / info->FullTablesPerSpareRegion;
		SpareSpace = SpareRegion * info->SpareSpaceDepthPerRegionInSUs;
	}
	FullTableOffset = SUID % sus_per_fulltable;
	TableID = FullTableOffset / info->SUsPerTable;
	TableOffset = FullTableOffset - TableID * info->SUsPerTable;
	BlockID = TableOffset / info->PUsPerBlock;
	BlockOffset = TableOffset - BlockID * info->PUsPerBlock;
	BlockID %= info->BlocksPerTable;
	RepIndex = info->PUsPerBlock - TableID;
	if (!raidPtr->noRotate)
		BlockOffset += ((BlockOffset >= RepIndex) ? 1 : 0);
	*col = info->LayoutTable[BlockID][BlockOffset];

	/* Remap to distributed spare space if indicated. */
	if (remap) {
		RF_ASSERT(raidPtr->Disks[*row][*col].status ==
		    rf_ds_reconstructing ||
		    raidPtr->Disks[*row][*col].status == rf_ds_dist_spared ||
		    (rf_copyback_in_progress &&
		    raidPtr->Disks[*row][*col].status == rf_ds_optimal));
		rf_remap_to_spare_space(layoutPtr, info, *row, FullTableID,
		    TableID, BlockID, (base_suid) ? 1 : 0, SpareRegion, col,
		    &outSU);
	} else {

		outSU = base_suid;
		outSU += FullTableID * fulltable_depth;
			/* Offset to start of FT. */
		outSU += SpareSpace;
			/* Skip rsvd spare space. */
		outSU += TableID * info->TableDepthInPUs * layoutPtr->SUsPerPU;
			/* Offset to start of table. */
		outSU += info->OffsetTable[BlockID][BlockOffset] *
		    layoutPtr->SUsPerPU;
			/* Offset to the PU. */
	}
	outSU += TableOffset / (info->BlocksPerTable * info->PUsPerBlock);
		/* offs to the SU within a PU */

	/*
	 * Convert SUs to sectors, and, if not aligned to SU boundary, add in
	 * offset to sector.
	 */
	*diskSector = outSU * layoutPtr->sectorsPerStripeUnit +
	    (raidSector % layoutPtr->sectorsPerStripeUnit);

	RF_ASSERT(*col != -1);
}

/*
 * Prototyping this inexplicably causes the compile of the layout table
 * (rf_layout.c) to fail.
 */
void
rf_MapParityDeclustered(RF_Raid_t *raidPtr, RF_RaidAddr_t raidSector,
    RF_RowCol_t *row, RF_RowCol_t *col, RF_SectorNum_t *diskSector, int remap)
{
	RF_RaidLayout_t *layoutPtr = &(raidPtr->Layout);
	RF_DeclusteredConfigInfo_t *info =
	    (RF_DeclusteredConfigInfo_t *) layoutPtr->layoutSpecificInfo;
	RF_StripeNum_t SUID = raidSector / layoutPtr->sectorsPerStripeUnit;
	RF_StripeNum_t FullTableID, FullTableOffset, TableID, TableOffset;
	RF_StripeNum_t BlockID, BlockOffset, RepIndex;
	RF_StripeCount_t sus_per_fulltable = info->SUsPerFullTable;
	RF_StripeCount_t fulltable_depth =
	    info->FullTableDepthInPUs * layoutPtr->SUsPerPU;
	RF_StripeNum_t base_suid = 0, outSU, SpareRegion = 0, SpareSpace = 0;

	rf_decluster_adjust_params(layoutPtr, &SUID, &sus_per_fulltable,
	    &fulltable_depth, &base_suid);

	/* Compute row & (possibly) spare space exactly as before. */
	FullTableID = SUID / sus_per_fulltable;
	if (raidPtr->numRow == 1)
		*row = 0;	/* Avoid a mod and a div in the common case. */
	else {
		*row = FullTableID % raidPtr->numRow;
		/* Convert to fulltable ID on this disk. */
		FullTableID /= raidPtr->numRow;
	}
	if ((raidPtr->Layout.map->flags & RF_DISTRIBUTE_SPARE)) {
		SpareRegion = FullTableID / info->FullTablesPerSpareRegion;
		SpareSpace = SpareRegion * info->SpareSpaceDepthPerRegionInSUs;
	}
	/* Compute BlockID and RepIndex exactly as before. */
	FullTableOffset = SUID % sus_per_fulltable;
	TableID = FullTableOffset / info->SUsPerTable;
	TableOffset = FullTableOffset - TableID * info->SUsPerTable;
	/*TableOffset	= FullTableOffset % info->SUsPerTable;*/
	/*BlockID	= (TableOffset / info->PUsPerBlock) %
	 *info->BlocksPerTable;*/
	BlockID = TableOffset / info->PUsPerBlock;
	/*BlockOffset	= TableOffset % info->PUsPerBlock;*/
	BlockOffset = TableOffset - BlockID * info->PUsPerBlock;
	BlockID %= info->BlocksPerTable;

	/* The parity block is in the position indicated by RepIndex. */
	RepIndex = (raidPtr->noRotate) ?
	    info->PUsPerBlock : info->PUsPerBlock - TableID;
	*col = info->LayoutTable[BlockID][RepIndex];

	if (remap) {
		RF_ASSERT(raidPtr->Disks[*row][*col].status ==
		    rf_ds_reconstructing ||
		    raidPtr->Disks[*row][*col].status == rf_ds_dist_spared ||
		    (rf_copyback_in_progress &&
		    raidPtr->Disks[*row][*col].status == rf_ds_optimal));
		rf_remap_to_spare_space(layoutPtr, info, *row, FullTableID,
		    TableID, BlockID, (base_suid) ? 1 : 0, SpareRegion, col,
		    &outSU);
	} else {

		/*
		 * Compute sector as before, except use RepIndex instead of
		 * BlockOffset.
		 */
		outSU = base_suid;
		outSU += FullTableID * fulltable_depth;
		outSU += SpareSpace;	/* skip rsvd spare space */
		outSU += TableID * info->TableDepthInPUs * layoutPtr->SUsPerPU;
		outSU += info->OffsetTable[BlockID][RepIndex] *
		    layoutPtr->SUsPerPU;
	}

	outSU += TableOffset / (info->BlocksPerTable * info->PUsPerBlock);
	*diskSector = outSU * layoutPtr->sectorsPerStripeUnit +
	    (raidSector % layoutPtr->sectorsPerStripeUnit);

	RF_ASSERT(*col != -1);
}

/*
 * Return an array of ints identifying the disks that comprise the stripe
 * containing the indicated address.
 * The caller must _never_ attempt to modify this array.
 */
void
rf_IdentifyStripeDeclustered(RF_Raid_t *raidPtr, RF_RaidAddr_t addr,
    RF_RowCol_t **diskids, RF_RowCol_t *outRow)
{
	RF_RaidLayout_t *layoutPtr = &(raidPtr->Layout);
	RF_DeclusteredConfigInfo_t *info =
	    (RF_DeclusteredConfigInfo_t *) layoutPtr->layoutSpecificInfo;
	RF_StripeCount_t sus_per_fulltable = info->SUsPerFullTable;
	RF_StripeCount_t fulltable_depth =
	    info->FullTableDepthInPUs * layoutPtr->SUsPerPU;
	RF_StripeNum_t base_suid = 0;
	RF_StripeNum_t SUID = rf_RaidAddressToStripeUnitID(layoutPtr, addr);
	RF_StripeNum_t stripeID, FullTableID;
	int tableOffset;

	rf_decluster_adjust_params(layoutPtr, &SUID, &sus_per_fulltable,
	    &fulltable_depth, &base_suid);
	/* Fulltable ID within array (across rows). */
	FullTableID = SUID / sus_per_fulltable;
	*outRow = FullTableID % raidPtr->numRow;
	/* Find stripe offset into array. */
	stripeID = rf_StripeUnitIDToStripeID(layoutPtr, SUID);
	/* Find offset into block design table. */
	tableOffset = (stripeID % info->BlocksPerTable);
	*diskids = info->LayoutTable[tableOffset];
}

/*
 * This returns the default head-separation limit, measured in
 * "required units for reconstruction". Each time a disk fetches
 * a unit, it bumps a counter. The head-sep code prohibits any disk
 * from getting more than headSepLimit counter values ahead of any
 * other.
 *
 * We assume here that the number of floating recon buffers is already
 * set. There are r stripes to be reconstructed in each table, and so
 * if we have a total of B buffers, we can have at most B/r tables
 * under recon at any one time. In each table, lambda units are required
 * from each disk, so given B buffers, the head sep limit has to be
 * (lambda*B)/r units. We subtract one to avoid weird boundary cases.
 *
 * For example, suppose we are given 50 buffers, r=19, and lambda=4 as in
 * the 20.5 design. There are 19 stripes/table to be reconstructed, so
 * we can have 50/19 tables concurrently under reconstruction, which means
 * we can allow the fastest disk to get 50/19 tables ahead of the slower
 * disk. There are lambda "required units" for each disk, so the fastest
 * disk can get 4*50/19 = 10 counter values ahead of the slowest.
 *
 * If numBufsToAccumulate is not 1, we need to limit the head sep further
 * because multiple bufs will be required for each stripe under recon.
 */
RF_HeadSepLimit_t
rf_GetDefaultHeadSepLimitDeclustered(RF_Raid_t *raidPtr)
{
	RF_DeclusteredConfigInfo_t *info =
	    (RF_DeclusteredConfigInfo_t *) raidPtr->Layout.layoutSpecificInfo;

	return (info->Lambda * raidPtr->numFloatingReconBufs /
	    info->TableDepthInPUs / rf_numBufsToAccumulate);
}

/*
 * Return the default number of recon buffers to use. The value
 * is somewhat arbitrary...  It's intended to be large enough to
 * allow for a reasonably large head-sep limit, but small enough
 * that you don't use up all your system memory with buffers.
 */
int
rf_GetDefaultNumFloatingReconBuffersDeclustered(RF_Raid_t *raidPtr)
{
	return (100 * rf_numBufsToAccumulate);
}

/*
 * Sectors in the last fulltable of the array need to be handled
 * specially since this fulltable can be incomplete. This function
 * changes the values of certain params to handle this.
 *
 * The idea here is that MapSector et. al. figure out which disk the
 * addressed unit lives on by computing the modulos of the unit number
 * with the number of units per fulltable, table, etc.  In the last
 * fulltable, there are fewer units per fulltable, so we need to adjust
 * the number of user data units per fulltable to reflect this.
 *
 * So, we (1) convert the fulltable size and depth parameters to
 * the size of the partial fulltable at the end, (2) compute the
 * disk sector offset where this fulltable starts, and (3) convert
 * the users stripe unit number from an offset into the array to
 * an offset into the last fulltable.
 */
void
rf_decluster_adjust_params(RF_RaidLayout_t *layoutPtr, RF_StripeNum_t *SUID,
    RF_StripeCount_t *sus_per_fulltable, RF_StripeCount_t *fulltable_depth,
    RF_StripeNum_t *base_suid)
{
	RF_DeclusteredConfigInfo_t *info =
	    (RF_DeclusteredConfigInfo_t *) layoutPtr->layoutSpecificInfo;

	if (*SUID >= info->FullTableLimitSUID) {
		/* New full table size is size of last full table on disk. */
		*sus_per_fulltable =
		    info->ExtraTablesPerDisk * info->SUsPerTable;

		/* New full table depth is corresponding depth. */
		*fulltable_depth =
		    info->ExtraTablesPerDisk * info->TableDepthInPUs *
		    layoutPtr->SUsPerPU;

		/* Set up the new base offset. */
		*base_suid = info->DiskOffsetOfLastFullTableInSUs;

		/*
		 * Convert user's array address to an offset into the last
		 * fulltable.
		 */
		*SUID -= info->FullTableLimitSUID;
	}
}

/*
 * Map a stripe ID to a parity stripe ID.
 * See comment above RaidAddressToParityStripeID in layout.c.
 */
void
rf_MapSIDToPSIDDeclustered(RF_RaidLayout_t *layoutPtr, RF_StripeNum_t stripeID,
    RF_StripeNum_t *psID, RF_ReconUnitNum_t *which_ru)
{
	RF_DeclusteredConfigInfo_t *info;

	info = (RF_DeclusteredConfigInfo_t *) layoutPtr->layoutSpecificInfo;

	*psID = (stripeID / (layoutPtr->SUsPerPU * info->BlocksPerTable)) *
	    info->BlocksPerTable + (stripeID % info->BlocksPerTable);
	*which_ru = (stripeID % (info->BlocksPerTable * layoutPtr->SUsPerPU)) /
	    info->BlocksPerTable;
	RF_ASSERT((*which_ru) < layoutPtr->SUsPerPU / layoutPtr->SUsPerRU);
}

/*
 * Called from MapSector and MapParity to retarget an access at the spare unit.
 * Modifies the "col" and "outSU" parameters only.
 */
void
rf_remap_to_spare_space(RF_RaidLayout_t *layoutPtr,
    RF_DeclusteredConfigInfo_t *info, RF_RowCol_t row,
    RF_StripeNum_t FullTableID, RF_StripeNum_t TableID, RF_SectorNum_t BlockID,
    RF_StripeNum_t base_suid, RF_StripeNum_t SpareRegion, RF_RowCol_t *outCol,
    RF_StripeNum_t *outSU)
{
	RF_StripeNum_t ftID, spareTableStartSU, TableInSpareRegion,
	    lastSROffset, which_ft;

	/*
	 * Note that FullTableID and hence SpareRegion may have gotten
	 * tweaked by rf_decluster_adjust_params. We detect this by
	 * noticing that base_suid is not 0.
	 */
	if (base_suid == 0) {
		ftID = FullTableID;
	} else {
		/*
		 * There may be > 1.0 full tables in the last (i.e. partial)
		 * spare region. Find out which of these we are in.
		 */
		lastSROffset = info->NumCompleteSRs *
		    info->SpareRegionDepthInSUs;
		which_ft =
		    (info->DiskOffsetOfLastFullTableInSUs - lastSROffset) /
		    (info->FullTableDepthInPUs * layoutPtr->SUsPerPU);

		/* Compute the actual full table ID. */
		ftID = info->DiskOffsetOfLastFullTableInSUs /
		    (info->FullTableDepthInPUs * layoutPtr->SUsPerPU) +
		    which_ft;
		SpareRegion = info->NumCompleteSRs;
	}
	TableInSpareRegion = (ftID * info->NumParityReps + TableID) %
	    info->TablesPerSpareRegion;

	*outCol = info->SpareTable[TableInSpareRegion][BlockID].spareDisk;
	RF_ASSERT(*outCol != -1);

	spareTableStartSU = (SpareRegion == info->NumCompleteSRs) ?
	    info->DiskOffsetOfLastFullTableInSUs + info->ExtraTablesPerDisk *
	    info->TableDepthInPUs * layoutPtr->SUsPerPU :
	    (SpareRegion + 1) * info->SpareRegionDepthInSUs -
	    info->SpareSpaceDepthPerRegionInSUs;
	*outSU = spareTableStartSU +
	    info->SpareTable[TableInSpareRegion][BlockID].spareBlockOffsetInSUs;
	if (*outSU >= layoutPtr->stripeUnitsPerDisk) {
		printf("rf_remap_to_spare_space: invalid remapped disk SU"
		    " offset %ld.\n", (long) *outSU);
	}
}

int
rf_InstallSpareTable(RF_Raid_t *raidPtr, RF_RowCol_t frow, RF_RowCol_t fcol)
{
	RF_DeclusteredConfigInfo_t *info =
	    (RF_DeclusteredConfigInfo_t *) raidPtr->Layout.layoutSpecificInfo;
	RF_SparetWait_t *req;
	int retcode;

	RF_Malloc(req, sizeof(*req), (RF_SparetWait_t *));
	req->C = raidPtr->numCol;
	req->G = raidPtr->Layout.numDataCol + raidPtr->Layout.numParityCol;
	req->fcol = fcol;
	req->SUsPerPU = raidPtr->Layout.SUsPerPU;
	req->TablesPerSpareRegion = info->TablesPerSpareRegion;
	req->BlocksPerTable = info->BlocksPerTable;
	req->TableDepthInPUs = info->TableDepthInPUs;
	req->SpareSpaceDepthPerRegionInSUs =
	    info->SpareSpaceDepthPerRegionInSUs;

	retcode = rf_GetSpareTableFromDaemon(req);
	RF_ASSERT(!retcode);
	/* XXX -- Fix this to recover gracefully. -- XXX */

	return (retcode);
}

/*
 * Invoked via ioctl to install a spare table in the kernel.
 */
int
rf_SetSpareTable(RF_Raid_t *raidPtr, void *data)
{
	RF_DeclusteredConfigInfo_t *info =
	    (RF_DeclusteredConfigInfo_t *) raidPtr->Layout.layoutSpecificInfo;
	RF_SpareTableEntry_t **ptrs;
	int i, retcode;

	/*
	 * What we need to copyin is a 2-d array, so first copyin the user
	 * pointers to the rows in the table.
	 */
	RF_Malloc(ptrs, info->TablesPerSpareRegion *
	    sizeof(RF_SpareTableEntry_t *), (RF_SpareTableEntry_t **));
	retcode = copyin((caddr_t) data, (caddr_t) ptrs,
	    info->TablesPerSpareRegion * sizeof(RF_SpareTableEntry_t *));

	if (retcode)
		return (retcode);

	/* Now allocate kernel space for the row pointers. */
	RF_Malloc(info->SpareTable, info->TablesPerSpareRegion *
	    sizeof(RF_SpareTableEntry_t *), (RF_SpareTableEntry_t **));

	/*
	 * Now allocate kernel space for each row in the table, and copy it in
	 * from user space. */
	for (i = 0; i < info->TablesPerSpareRegion; i++) {
		RF_Malloc(info->SpareTable[i], info->BlocksPerTable *
		    sizeof(RF_SpareTableEntry_t), (RF_SpareTableEntry_t *));
		retcode = copyin(ptrs[i], info->SpareTable[i],
		    info->BlocksPerTable * sizeof(RF_SpareTableEntry_t));
		if (retcode) {
			/* Blow off the memory we have allocated. */
			info->SpareTable = NULL;
			return (retcode);
		}
	}

	/* Free up the temporary array we used. */
	RF_Free(ptrs, info->TablesPerSpareRegion *
	    sizeof(RF_SpareTableEntry_t *));

	return (0);
}

RF_ReconUnitCount_t
rf_GetNumSpareRUsDeclustered(RF_Raid_t *raidPtr)
{
	RF_RaidLayout_t *layoutPtr = &raidPtr->Layout;

	return (((RF_DeclusteredConfigInfo_t *)
	    layoutPtr->layoutSpecificInfo)->TotSparePUsPerDisk);
}


void
rf_FreeSpareTable(RF_Raid_t *raidPtr)
{
	long i;
	RF_RaidLayout_t *layoutPtr = &raidPtr->Layout;
	RF_DeclusteredConfigInfo_t *info =
	    (RF_DeclusteredConfigInfo_t *) layoutPtr->layoutSpecificInfo;
	RF_SpareTableEntry_t **table = info->SpareTable;

	for (i = 0; i < info->TablesPerSpareRegion; i++) {
		RF_Free(table[i], info->BlocksPerTable *
		    sizeof(RF_SpareTableEntry_t));
	}
	RF_Free(table, info->TablesPerSpareRegion *
	    sizeof(RF_SpareTableEntry_t *));
	info->SpareTable = (RF_SpareTableEntry_t **) NULL;
}
@


1.5
log
@Major KNF.  Incentive from Tedu
@
text
@d1 1
a1 1
/*	$OpenBSD: rf_decluster.c,v 1.4 2000/08/08 16:07:40 peter Exp $	*/
@


1.4
log
@sync RAIDframe with Gre Oster's work for NetBSD.

This update incorporates changes since January 2000.

RAID1 and RAID5 tested for functionality matching the 2.7 code. A
number of bug fixes (including stopping a parity rebuild when
unconfiguring) have been included. See Greg's RAIDframe info page:

	http://www.cs.usask.ca/staff/oster/raid.html

The RAID_AUTOCONFIG feature set does *NOT* yet work. These features
require more work throughout the boot system and as such are a big
task.

IMPORTANT: As with anything that is this near live data on your
systems, please test carefully with existing configurations before
deploying in a live system.  Feedback via sendbug or mail direct
to peter@@wonderland.org is appreciated.
@
text
@d1 1
a1 1
/*	$OpenBSD: rf_decluster.c,v 1.3 2000/01/07 14:50:21 peter Exp $	*/
d3 1
d31 1
a31 1
/*----------------------------------------------------------------------
d33 1
a33 1
 * rf_decluster.c -- code related to the declustered layout
d37 12
a48 12
 * Nov 93:  adding support for distributed sparing.  This code is a little
 *          complex:  the basic layout used is as follows:
 *          let F = (v-1)/GCD(r,v-1).  The spare space for each set of
 *          F consecutive fulltables is grouped together and placed after
 *          that set of tables.
 *                   +------------------------------+
 *                   |        F fulltables          |
 *                   |        Spare Space           |
 *                   |        F fulltables          |
 *                   |        Spare Space           |
 *                   |            ...               |
 *                   +------------------------------+
d50 1
a50 1
 *--------------------------------------------------------------------*/
d63 1
a63 1
extern int rf_copyback_in_progress;	/* debug only */
d65 2
a66 2
/* found in rf_kintf.c */
int     rf_GetSpareTableFromDaemon(RF_SparetWait_t * req);
d68 1
a68 1
/* configuration code */
d70 3
a72 5
int 
rf_ConfigureDeclustered(
    RF_ShutdownList_t ** listp,
    RF_Raid_t * raidPtr,
    RF_Config_t * cfgPtr)
d75 2
a76 2
	int     b, v, k, r, lambda;	/* block design params */
	int     i, j;
d80 2
a81 2
	RF_StripeCount_t PUsPerDisk, spareRegionDepthInPUs, numCompleteSpareRegionsPerDisk,
	        extraPUsPerDisk;
d85 1
a85 1
	char   *cfgBuf = (char *) (cfgPtr->layoutSpecific);
d91 3
a93 2
	/* 1. create layout specific structure */
	RF_MallocAndAdd(info, sizeof(RF_DeclusteredConfigInfo_t), (RF_DeclusteredConfigInfo_t *), raidPtr->cleanupList);
d99 1
a99 1
	/* 2. extract parameters from the config structure */
d101 1
a101 1
		(void) bcopy(cfgBuf, info->sparemap_fname, RF_SPAREMAP_NAME_LEN);
d118 2
a119 1
	/* the sparemaps are generated assuming that parity is rotated, so we
d121 6
a126 3
	 * the same time */
	if ((layoutPtr->map->flags & RF_DISTRIBUTE_SPARE) && raidPtr->noRotate) {
		RF_ERRORMSG("Warning:  distributed sparing specified without parity rotation.\n");
d129 2
a130 1
		RF_ERRORMSG2("RAID: config error: table element count (%d) not equal to no. of cols (%d)\n", v, raidPtr->numCol);
d133 1
a133 1
	/* 3.  set up the values used in the mapping code */
d137 2
a138 1
	info->SUsPerTable = b * (k - 1) * layoutPtr->SUsPerPU;	/* b blks, k-1 SUs each */
d143 2
a144 1
	info->FullTableDepthInPUs = info->TableDepthInPUs * k;	/* k repetitions */
d146 3
a148 2
	/* used only in distributed sparing case */
	info->FullTablesPerSpareRegion = (v - 1) / rf_gcd(r, v - 1);	/* (v-1)/gcd fulltables */
d150 2
a151 1
	info->SpareSpaceDepthPerRegionInSUs = (r * info->TablesPerSpareRegion / (v - 1)) * layoutPtr->SUsPerPU;
d153 1
a153 1
	/* check to make sure the block design is sufficiently small */
d155 6
a160 2
		if (info->FullTableDepthInPUs * layoutPtr->SUsPerPU + info->SpareSpaceDepthPerRegionInSUs > layoutPtr->stripeUnitsPerDisk) {
			RF_ERRORMSG3("RAID: config error: Full Table depth (%d) + Spare Space (%d) larger than disk size (%d) (BD too big)\n",
d167 5
a171 3
		if (info->TableDepthInPUs * layoutPtr->SUsPerPU > layoutPtr->stripeUnitsPerDisk) {
			RF_ERRORMSG2("RAID: config error: Table depth (%d) larger than disk size (%d) (BD too big)\n",
			    (int) (info->TableDepthInPUs * layoutPtr->SUsPerPU), \
d178 4
a181 2
	/* compute the size of each disk, and the number of tables in the last
	 * fulltable (which need not be complete) */
d184 8
a191 4
		PUsPerDisk = layoutPtr->stripeUnitsPerDisk / layoutPtr->SUsPerPU;
		spareRegionDepthInPUs = (info->TablesPerSpareRegion * info->TableDepthInPUs +
		    (info->TablesPerSpareRegion * info->TableDepthInPUs) / (v - 1));
		info->SpareRegionDepthInSUs = spareRegionDepthInPUs * layoutPtr->SUsPerPU;
d193 2
a194 1
		numCompleteSpareRegionsPerDisk = PUsPerDisk / spareRegionDepthInPUs;
d198 2
a199 1
		/* assume conservatively that we need the full amount of spare
d201 6
a206 4
		 * partial spare region at the end of the array.  We set "i"
		 * to the number of tables in the partial spare region.  This
		 * may actually include some fulltables. */
		extraPUsPerDisk -= (info->SpareSpaceDepthPerRegionInSUs / layoutPtr->SUsPerPU);
d212 5
a216 2
		complete_FT_count = raidPtr->numRow * (numCompleteSpareRegionsPerDisk * (info->TablesPerSpareRegion / k) + i / k);
		info->FullTableLimitSUID = complete_FT_count * info->SUsPerFullTable;
d219 6
a224 3
		/* note that in the last spare region, the spare space is
		 * complete even though data/parity space is not */
		totSparePUsPerDisk = (numCompleteSpareRegionsPerDisk + 1) * (info->SpareSpaceDepthPerRegionInSUs / layoutPtr->SUsPerPU);
d228 2
a229 1
		    ((complete_FT_count / raidPtr->numRow) * info->FullTableDepthInPUs +	/* data & parity space */
d231 1
a231 1
		    totSparePUsPerDisk	/* spare space */
d234 3
a236 2
		    (complete_FT_count * info->FullTableDepthInPUs + info->ExtraTablesPerDisk * info->TableDepthInPUs)
		    * layoutPtr->SUsPerPU * (k - 1) / k;
d239 8
a246 4
		/* non-dist spare case:  force each disk to contain an
		 * integral number of tables */
		layoutPtr->stripeUnitsPerDisk /= (info->TableDepthInPUs * layoutPtr->SUsPerPU);
		layoutPtr->stripeUnitsPerDisk *= (info->TableDepthInPUs * layoutPtr->SUsPerPU);
d248 4
a251 2
		/* compute the number of tables in the last fulltable, which
		 * need not be complete */
d253 2
a254 1
		    ((layoutPtr->stripeUnitsPerDisk / layoutPtr->SUsPerPU) / info->FullTableDepthInPUs) * raidPtr->numRow;
d256 2
a257 1
		info->FullTableLimitSUID = complete_FT_count * info->SUsPerFullTable;
d259 2
a260 1
		    ((layoutPtr->stripeUnitsPerDisk / layoutPtr->SUsPerPU) / info->TableDepthInPUs) % k;
d263 2
a264 1
	raidPtr->sectorsPerDisk = layoutPtr->stripeUnitsPerDisk * layoutPtr->sectorsPerStripeUnit;
d266 4
a269 2
	/* find the disk offset of the stripe unit where the last fulltable
	 * starts */
d271 2
a272 1
	diskOffsetOfLastFullTableInSUs = numCompleteFullTablesPerDisk * info->FullTableDepthInPUs * layoutPtr->SUsPerPU;
d274 2
a275 1
		SpareSpaceInSUs = numCompleteSpareRegionsPerDisk * info->SpareSpaceDepthPerRegionInSUs;
d278 2
a279 1
		    diskOffsetOfLastFullTableInSUs + info->ExtraTablesPerDisk * info->TableDepthInPUs * layoutPtr->SUsPerPU;
d284 1
a284 1
	/* 4.  create and initialize the lookup tables */
d291 2
a292 1
	info->BlockTable = rf_make_2d_array(info->TableDepthInPUs * layoutPtr->SUsPerPU, raidPtr->numCol, raidPtr->cleanupList);
d304 1
a304 1
	/* initialize offset table */
d307 2
a308 1
			info->OffsetTable[i][j] = first_avail_slot[info->LayoutTable[i][j]];
d312 1
a312 1
	/* initialize block table */
d316 2
a317 1
				info->BlockTable[(info->OffsetTable[i][j] * layoutPtr->SUsPerPU) + l]
d326 1
a326 1
	/* 5.  set up the remaining redundant-but-useful parameters */
d328 5
a332 3
	raidPtr->totalSectors = (k * complete_FT_count + raidPtr->numRow * info->ExtraTablesPerDisk) *
	    info->SUsPerTable * layoutPtr->sectorsPerStripeUnit;
	layoutPtr->numStripe = (raidPtr->totalSectors / layoutPtr->sectorsPerStripeUnit) / (k - 1);
d334 9
a342 5
	/* strange evaluation order below to try and minimize overflow
	 * problems */

	layoutPtr->dataSectorsPerStripe = (k - 1) * layoutPtr->sectorsPerStripeUnit;
	layoutPtr->bytesPerStripeUnit = layoutPtr->sectorsPerStripeUnit << raidPtr->logBytesPerSector;
d348 5
a352 5
/* declustering with distributed sparing */
static void rf_ShutdownDeclusteredDS(RF_ThreadArg_t);
static void 
rf_ShutdownDeclusteredDS(arg)
	RF_ThreadArg_t arg;
d358 2
a359 1
	info = (RF_DeclusteredConfigInfo_t *) raidPtr->Layout.layoutSpecificInfo;
d364 3
a366 5
int 
rf_ConfigureDeclusteredDS(
    RF_ShutdownList_t ** listp,
    RF_Raid_t * raidPtr,
    RF_Config_t * cfgPtr)
d368 1
a368 1
	int     rc;
d373 1
d376 2
a377 1
		RF_ERRORMSG1("Got %d adding shutdown event for DeclusteredDS\n", rc);
d381 1
d385 3
a387 8
void 
rf_MapSectorDeclustered(raidPtr, raidSector, row, col, diskSector, remap)
	RF_Raid_t *raidPtr;
	RF_RaidAddr_t raidSector;
	RF_RowCol_t *row;
	RF_RowCol_t *col;
	RF_SectorNum_t *diskSector;
	int     remap;
d390 2
a391 1
	RF_DeclusteredConfigInfo_t *info = (RF_DeclusteredConfigInfo_t *) layoutPtr->layoutSpecificInfo;
d396 2
a397 1
	RF_StripeCount_t fulltable_depth = info->FullTableDepthInPUs * layoutPtr->SUsPerPU;
d400 2
a401 1
	rf_decluster_adjust_params(layoutPtr, &SUID, &sus_per_fulltable, &fulltable_depth, &base_suid);
d403 2
a404 2
	FullTableID = SUID / sus_per_fulltable;	/* fulltable ID within array
						 * (across rows) */
d406 1
a406 1
		*row = 0;	/* avoid a mod and a div in the common case */
d409 2
a410 2
		FullTableID /= raidPtr->numRow;	/* convert to fulltable ID on
						 * this disk */
d427 1
a427 1
	/* remap to distributed spare space if indicated */
d429 8
a436 3
		RF_ASSERT(raidPtr->Disks[*row][*col].status == rf_ds_reconstructing || raidPtr->Disks[*row][*col].status == rf_ds_dist_spared ||
		    (rf_copyback_in_progress && raidPtr->Disks[*row][*col].status == rf_ds_optimal));
		rf_remap_to_spare_space(layoutPtr, info, *row, FullTableID, TableID, BlockID, (base_suid) ? 1 : 0, SpareRegion, col, &outSU);
d440 9
a448 4
		outSU += FullTableID * fulltable_depth;	/* offs to strt of FT */
		outSU += SpareSpace;	/* skip rsvd spare space */
		outSU += TableID * info->TableDepthInPUs * layoutPtr->SUsPerPU;	/* offs to strt of tble */
		outSU += info->OffsetTable[BlockID][BlockOffset] * layoutPtr->SUsPerPU;	/* offs to the PU */
d450 2
a451 2
	outSU += TableOffset / (info->BlocksPerTable * info->PUsPerBlock);	/* offs to the SU within
										 * a PU */
d453 6
a458 3
	/* convert SUs to sectors, and, if not aligned to SU boundary, add in
	 * offset to sector.  */
	*diskSector = outSU * layoutPtr->sectorsPerStripeUnit + (raidSector % layoutPtr->sectorsPerStripeUnit);
d463 7
a469 10

/* prototyping this inexplicably causes the compile of the layout table (rf_layout.c) to fail */
void 
rf_MapParityDeclustered(
    RF_Raid_t * raidPtr,
    RF_RaidAddr_t raidSector,
    RF_RowCol_t * row,
    RF_RowCol_t * col,
    RF_SectorNum_t * diskSector,
    int remap)
d472 2
a473 1
	RF_DeclusteredConfigInfo_t *info = (RF_DeclusteredConfigInfo_t *) layoutPtr->layoutSpecificInfo;
d478 2
a479 1
	RF_StripeCount_t fulltable_depth = info->FullTableDepthInPUs * layoutPtr->SUsPerPU;
d482 2
a483 1
	rf_decluster_adjust_params(layoutPtr, &SUID, &sus_per_fulltable, &fulltable_depth, &base_suid);
d485 1
a485 1
	/* compute row & (possibly) spare space exactly as before */
d488 1
a488 1
		*row = 0;	/* avoid a mod and a div in the common case */
d491 2
a492 2
		FullTableID /= raidPtr->numRow;	/* convert to fulltable ID on
						 * this disk */
d498 1
a498 1
	/* compute BlockID and RepIndex exactly as before */
d502 3
a504 3
	/* TableOffset     = FullTableOffset % info->SUsPerTable; */
	/* BlockID         = (TableOffset / info->PUsPerBlock) %
	 * info->BlocksPerTable; */
d506 1
a506 1
	/* BlockOffset     = TableOffset % info->PUsPerBlock; */
d510 3
a512 2
	/* the parity block is in the position indicated by RepIndex */
	RepIndex = (raidPtr->noRotate) ? info->PUsPerBlock : info->PUsPerBlock - TableID;
d516 8
a523 3
		RF_ASSERT(raidPtr->Disks[*row][*col].status == rf_ds_reconstructing || raidPtr->Disks[*row][*col].status == rf_ds_dist_spared ||
		    (rf_copyback_in_progress && raidPtr->Disks[*row][*col].status == rf_ds_optimal));
		rf_remap_to_spare_space(layoutPtr, info, *row, FullTableID, TableID, BlockID, (base_suid) ? 1 : 0, SpareRegion, col, &outSU);
d526 4
a529 2
		/* compute sector as before, except use RepIndex instead of
		 * BlockOffset */
d534 2
a535 1
		outSU += info->OffsetTable[BlockID][RepIndex] * layoutPtr->SUsPerPU;
d539 2
a540 1
	*diskSector = outSU * layoutPtr->sectorsPerStripeUnit + (raidSector % layoutPtr->sectorsPerStripeUnit);
d544 5
a548 2
/* returns an array of ints identifying the disks that comprise the stripe containing the indicated address.
 * the caller must _never_ attempt to modify this array.
d550 3
a552 6
void 
rf_IdentifyStripeDeclustered(
    RF_Raid_t * raidPtr,
    RF_RaidAddr_t addr,
    RF_RowCol_t ** diskids,
    RF_RowCol_t * outRow)
d555 2
a556 1
	RF_DeclusteredConfigInfo_t *info = (RF_DeclusteredConfigInfo_t *) layoutPtr->layoutSpecificInfo;
d558 2
a559 1
	RF_StripeCount_t fulltable_depth = info->FullTableDepthInPUs * layoutPtr->SUsPerPU;
d563 1
a563 1
	int     tableOffset;
d565 4
a568 3
	rf_decluster_adjust_params(layoutPtr, &SUID, &sus_per_fulltable, &fulltable_depth, &base_suid);
	FullTableID = SUID / sus_per_fulltable;	/* fulltable ID within array
						 * (across rows) */
d570 4
a573 4
	stripeID = rf_StripeUnitIDToStripeID(layoutPtr, SUID);	/* find stripe offset
								 * into array */
	tableOffset = (stripeID % info->BlocksPerTable);	/* find offset into
								 * block design table */
d576 5
a580 3
/* This returns the default head-separation limit, which is measured
 * in "required units for reconstruction".  Each time a disk fetches
 * a unit, it bumps a counter.  The head-sep code prohibits any disk
d585 1
a585 1
 * set.  There are r stripes to be reconstructed in each table, and so
d587 1
a587 1
 * under recon at any one time.  In each table, lambda units are required
d589 1
a589 1
 * (lambda*B)/r units.  We subtract one to avoid weird boundary cases.
d591 2
a592 2
 * for example, suppose were given 50 buffers, r=19, and lambda=4 as in
 * the 20.5 design.  There are 19 stripes/table to be reconstructed, so
d595 1
a595 1
 * disk.  There are lambda "required units" for each disk, so the fastest
d601 15
a615 12
RF_HeadSepLimit_t 
rf_GetDefaultHeadSepLimitDeclustered(
    RF_Raid_t * raidPtr)
{
	RF_DeclusteredConfigInfo_t *info = (RF_DeclusteredConfigInfo_t *) raidPtr->Layout.layoutSpecificInfo;

	return (info->Lambda * raidPtr->numFloatingReconBufs / info->TableDepthInPUs / rf_numBufsToAccumulate);
}
/* returns the default number of recon buffers to use.  The value
 * is somewhat arbitrary...it's intended to be large enough to allow
 * for a reasonably large head-sep limit, but small enough that you
 * don't use up all your system memory with buffers.
d617 2
a618 2
int 
rf_GetDefaultNumFloatingReconBuffersDeclustered(RF_Raid_t * raidPtr)
d622 4
a625 2
/* sectors in the last fulltable of the array need to be handled
 * specially since this fulltable can be incomplete.  this function
d628 1
a628 1
 * the idea here is that MapSector et. al. figure out which disk the
d634 1
a634 1
 * so, we (1) convert the fulltable size and depth parameters to
d640 4
a643 7
void 
rf_decluster_adjust_params(
    RF_RaidLayout_t * layoutPtr,
    RF_StripeNum_t * SUID,
    RF_StripeCount_t * sus_per_fulltable,
    RF_StripeCount_t * fulltable_depth,
    RF_StripeNum_t * base_suid)
d645 2
a646 1
	RF_DeclusteredConfigInfo_t *info = (RF_DeclusteredConfigInfo_t *) layoutPtr->layoutSpecificInfo;
d649 8
a656 2
		/* new full table size is size of last full table on disk */
		*sus_per_fulltable = info->ExtraTablesPerDisk * info->SUsPerTable;
d658 1
a658 4
		/* new full table depth is corresponding depth */
		*fulltable_depth = info->ExtraTablesPerDisk * info->TableDepthInPUs * layoutPtr->SUsPerPU;

		/* set up the new base offset */
d661 4
a664 2
		/* convert users array address to an offset into the last
		 * fulltable */
d668 1
d670 1
a670 1
 * map a stripe ID to a parity stripe ID.
d673 3
a675 6
void 
rf_MapSIDToPSIDDeclustered(
    RF_RaidLayout_t * layoutPtr,
    RF_StripeNum_t stripeID,
    RF_StripeNum_t * psID,
    RF_ReconUnitNum_t * which_ru)
d681 4
a684 4
	*psID = (stripeID / (layoutPtr->SUsPerPU * info->BlocksPerTable))
	    * info->BlocksPerTable + (stripeID % info->BlocksPerTable);
	*which_ru = (stripeID % (info->BlocksPerTable * layoutPtr->SUsPerPU))
	    / info->BlocksPerTable;
d687 1
d692 6
a697 12
void 
rf_remap_to_spare_space(
    RF_RaidLayout_t * layoutPtr,
    RF_DeclusteredConfigInfo_t * info,
    RF_RowCol_t row,
    RF_StripeNum_t FullTableID,
    RF_StripeNum_t TableID,
    RF_SectorNum_t BlockID,
    RF_StripeNum_t base_suid,
    RF_StripeNum_t SpareRegion,
    RF_RowCol_t * outCol,
    RF_StripeNum_t * outSU)
d699 2
a700 2
	RF_StripeNum_t ftID, spareTableStartSU, TableInSpareRegion, lastSROffset,
	        which_ft;
d703 4
a706 4
         * note that FullTableID and hence SpareRegion may have gotten
         * tweaked by rf_decluster_adjust_params. We detect this by
         * noticing that base_suid is not 0.
         */
d711 13
a723 8
	         * There may be > 1.0 full tables in the last (i.e. partial)
	         * spare region.  find out which of these we're in.
	         */
		lastSROffset = info->NumCompleteSRs * info->SpareRegionDepthInSUs;
		which_ft = (info->DiskOffsetOfLastFullTableInSUs - lastSROffset) / (info->FullTableDepthInPUs * layoutPtr->SUsPerPU);

		/* compute the actual full table ID */
		ftID = info->DiskOffsetOfLastFullTableInSUs / (info->FullTableDepthInPUs * layoutPtr->SUsPerPU) + which_ft;
d726 2
a727 1
	TableInSpareRegion = (ftID * info->NumParityReps + TableID) % info->TablesPerSpareRegion;
d733 6
a738 3
	    info->DiskOffsetOfLastFullTableInSUs + info->ExtraTablesPerDisk * info->TableDepthInPUs * layoutPtr->SUsPerPU :
	    (SpareRegion + 1) * info->SpareRegionDepthInSUs - info->SpareSpaceDepthPerRegionInSUs;
	*outSU = spareTableStartSU + info->SpareTable[TableInSpareRegion][BlockID].spareBlockOffsetInSUs;
d740 2
a741 1
		printf("rf_remap_to_spare_space: invalid remapped disk SU offset %ld\n", (long) *outSU);
d745 2
a746 5
int 
rf_InstallSpareTable(
    RF_Raid_t * raidPtr,
    RF_RowCol_t frow,
    RF_RowCol_t fcol)
d748 2
a749 1
	RF_DeclusteredConfigInfo_t *info = (RF_DeclusteredConfigInfo_t *) raidPtr->Layout.layoutSpecificInfo;
d751 1
a751 1
	int     retcode;
d761 2
a762 1
	req->SpareSpaceDepthPerRegionInSUs = info->SpareSpaceDepthPerRegionInSUs;
d765 3
a767 2
	RF_ASSERT(!retcode);	/* XXX -- fix this to recover gracefully --
				 * XXX */
d770 1
d774 2
a775 4
int 
rf_SetSpareTable(raidPtr, data)
	RF_Raid_t *raidPtr;
	void   *data;
d777 2
a778 1
	RF_DeclusteredConfigInfo_t *info = (RF_DeclusteredConfigInfo_t *) raidPtr->Layout.layoutSpecificInfo;
d780 1
a780 1
	int     i, retcode;
d782 8
a789 4
	/* what we need to copyin is a 2-d array, so first copyin the user
	 * pointers to the rows in the table */
	RF_Malloc(ptrs, info->TablesPerSpareRegion * sizeof(RF_SpareTableEntry_t *), (RF_SpareTableEntry_t **));
	retcode = copyin((caddr_t) data, (caddr_t) ptrs, info->TablesPerSpareRegion * sizeof(RF_SpareTableEntry_t *));
d794 3
a796 2
	/* now allocate kernel space for the row pointers */
	RF_Malloc(info->SpareTable, info->TablesPerSpareRegion * sizeof(RF_SpareTableEntry_t *), (RF_SpareTableEntry_t **));
d798 3
a800 2
	/* now allocate kernel space for each row in the table, and copy it in
	 * from user space */
d802 4
a805 2
		RF_Malloc(info->SpareTable[i], info->BlocksPerTable * sizeof(RF_SpareTableEntry_t), (RF_SpareTableEntry_t *));
		retcode = copyin(ptrs[i], info->SpareTable[i], info->BlocksPerTable * sizeof(RF_SpareTableEntry_t));
d807 2
a808 2
			info->SpareTable = NULL;	/* blow off the memory
							 * we've allocated */
d813 3
a815 2
	/* free up the temporary array we used */
	RF_Free(ptrs, info->TablesPerSpareRegion * sizeof(RF_SpareTableEntry_t *));
d820 2
a821 3
RF_ReconUnitCount_t 
rf_GetNumSpareRUsDeclustered(raidPtr)
	RF_Raid_t *raidPtr;
d825 2
a826 1
	return (((RF_DeclusteredConfigInfo_t *) layoutPtr->layoutSpecificInfo)->TotSparePUsPerDisk);
d830 2
a831 3
void 
rf_FreeSpareTable(raidPtr)
	RF_Raid_t *raidPtr;
d833 1
a833 1
	long    i;
d835 2
a836 1
	RF_DeclusteredConfigInfo_t *info = (RF_DeclusteredConfigInfo_t *) layoutPtr->layoutSpecificInfo;
d840 2
a841 1
		RF_Free(table[i], info->BlocksPerTable * sizeof(RF_SpareTableEntry_t));
d843 2
a844 1
	RF_Free(table, info->TablesPerSpareRegion * sizeof(RF_SpareTableEntry_t *));
@


1.4.8.1
log
@sync
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
a2 1

d30 1
a30 1
/*****************************************************************************
d32 1
a32 1
 * rf_decluster.c -- Code related to the declustered layout.
d36 12
a47 12
 * Nov 93:	Adding support for distributed sparing. This code is a little
 *		complex; the basic layout used is as follows:
 *		Let F = (v-1)/GCD(r,v-1). The spare space for each set of
 *		F consecutive fulltables is grouped together and placed after
 *		that set of tables.
 *			+-------------------------------+
 *			|	  F fulltables		|
 *			|	  Spare Space		|
 *			|	  F fulltables		|
 *			|	  Spare Space		|
 *			|	      ...		|
 *			+-------------------------------+
d49 1
a49 1
 *****************************************************************************/
d62 1
a62 1
extern int rf_copyback_in_progress;	/* Debug only. */
d64 2
a65 2
/* Found in rf_kintf.c */
int  rf_GetSpareTableFromDaemon(RF_SparetWait_t *);
d67 1
a67 1
/* Configuration code. */
d69 5
a73 3
int
rf_ConfigureDeclustered(RF_ShutdownList_t **listp, RF_Raid_t *raidPtr,
    RF_Config_t *cfgPtr)
d76 2
a77 2
	int b, v, k, r, lambda;	/* block design params */
	int i, j;
d81 2
a82 2
	RF_StripeCount_t PUsPerDisk, spareRegionDepthInPUs,
	    numCompleteSpareRegionsPerDisk, extraPUsPerDisk;
d86 1
a86 1
	char *cfgBuf = (char *) (cfgPtr->layoutSpecific);
d92 2
a93 3
	/* 1. Create layout specific structure. */
	RF_MallocAndAdd(info, sizeof(RF_DeclusteredConfigInfo_t),
	    (RF_DeclusteredConfigInfo_t *), raidPtr->cleanupList);
d99 1
a99 1
	/* 2. Extract parameters from the config structure. */
d101 1
a101 1
		bcopy(cfgBuf, info->sparemap_fname, RF_SPAREMAP_NAME_LEN);
d118 1
a118 2
	/*
	 * The sparemaps are generated assuming that parity is rotated, so we
d120 3
a122 6
	 * the same time.
	 */
	if ((layoutPtr->map->flags & RF_DISTRIBUTE_SPARE) &&
	    raidPtr->noRotate) {
		RF_ERRORMSG("Warning:  distributed sparing specified without"
		    " parity rotation.\n");
d125 1
a125 2
		RF_ERRORMSG2("RAID: config error: table element count (%d)"
		    " not equal to no. of cols (%d).\n", v, raidPtr->numCol);
d128 1
a128 1
	/* 3. Set up the values used in the mapping code. */
d132 1
a132 2
	/* b blks, k-1 SUs each. */
	info->SUsPerTable = b * (k - 1) * layoutPtr->SUsPerPU;
d137 1
a137 2
	/* k repetitions. */
	info->FullTableDepthInPUs = info->TableDepthInPUs * k;
d139 2
a140 3
	/* Used only in distributed sparing case. */
	/* (v-1)/gcd fulltables. */
	info->FullTablesPerSpareRegion = (v - 1) / rf_gcd(r, v - 1);
d142 1
a142 2
	info->SpareSpaceDepthPerRegionInSUs = (r * info->TablesPerSpareRegion /
	    (v - 1)) * layoutPtr->SUsPerPU;
d144 1
a144 1
	/* Check to make sure the block design is sufficiently small. */
d146 2
a147 6
		if (info->FullTableDepthInPUs * layoutPtr->SUsPerPU +
		    info->SpareSpaceDepthPerRegionInSUs >
		    layoutPtr->stripeUnitsPerDisk) {
			RF_ERRORMSG3("RAID: config error: Full Table depth"
			    " (%d) + Spare Space (%d) larger than disk size"
			    " (%d) (BD too big).\n",
d154 3
a156 5
		if (info->TableDepthInPUs * layoutPtr->SUsPerPU >
		    layoutPtr->stripeUnitsPerDisk) {
			RF_ERRORMSG2("RAID: config error: Table depth (%d)"
			    " larger than disk size (%d) (BD too big).\n",
			    (int) (info->TableDepthInPUs * layoutPtr->SUsPerPU),
d163 2
a164 4
	/*
	 * Compute the size of each disk, and the number of tables in the last
	 * fulltable (which need not be complete).
	 */
d167 4
a170 8
		PUsPerDisk = layoutPtr->stripeUnitsPerDisk /
		    layoutPtr->SUsPerPU;
		spareRegionDepthInPUs =
		    (info->TablesPerSpareRegion * info->TableDepthInPUs +
		    (info->TablesPerSpareRegion * info->TableDepthInPUs) /
		    (v - 1));
		info->SpareRegionDepthInSUs =
		    spareRegionDepthInPUs * layoutPtr->SUsPerPU;
d172 1
a172 2
		numCompleteSpareRegionsPerDisk =
		    PUsPerDisk / spareRegionDepthInPUs;
d176 1
a176 2
		/*
		 * Assume conservatively that we need the full amount of spare
d178 4
a181 6
		 * partial spare region at the end of the array. We set "i"
		 * to the number of tables in the partial spare region. This
		 * may actually include some fulltables.
		 */
		extraPUsPerDisk -= (info->SpareSpaceDepthPerRegionInSUs /
		    layoutPtr->SUsPerPU);
d187 2
a188 5
		complete_FT_count = raidPtr->numRow *
		    (numCompleteSpareRegionsPerDisk *
		    (info->TablesPerSpareRegion / k) + i / k);
		info->FullTableLimitSUID =
		    complete_FT_count * info->SUsPerFullTable;
d191 3
a193 6
		/*
		 * Note that in the last spare region, the spare space is
		 * complete even though data/parity space is not.
		 */
		totSparePUsPerDisk = (numCompleteSpareRegionsPerDisk + 1) *
		    (info->SpareSpaceDepthPerRegionInSUs / layoutPtr->SUsPerPU);
d197 1
a197 2
		    ((complete_FT_count / raidPtr->numRow) *
		    info->FullTableDepthInPUs +	/* data & parity space */
d199 1
a199 1
		    totSparePUsPerDisk		/* spare space */
d202 2
a203 3
		    (complete_FT_count * info->FullTableDepthInPUs +
		    info->ExtraTablesPerDisk * info->TableDepthInPUs) *
		    layoutPtr->SUsPerPU * (k - 1) / k;
d206 4
a209 8
		/*
		 * Non-dist spare case:  force each disk to contain an
		 * integral number of tables.
		 */
		layoutPtr->stripeUnitsPerDisk /=
		    (info->TableDepthInPUs * layoutPtr->SUsPerPU);
		layoutPtr->stripeUnitsPerDisk *=
		    (info->TableDepthInPUs * layoutPtr->SUsPerPU);
d211 2
a212 4
		/*
		 * Compute the number of tables in the last fulltable, which
		 * need not be complete.
		 */
d214 1
a214 2
		    ((layoutPtr->stripeUnitsPerDisk / layoutPtr->SUsPerPU) /
		    info->FullTableDepthInPUs) * raidPtr->numRow;
d216 1
a216 2
		info->FullTableLimitSUID =
		    complete_FT_count * info->SUsPerFullTable;
d218 1
a218 2
		    ((layoutPtr->stripeUnitsPerDisk / layoutPtr->SUsPerPU) /
		    info->TableDepthInPUs) % k;
d221 1
a221 2
	raidPtr->sectorsPerDisk = layoutPtr->stripeUnitsPerDisk *
		    layoutPtr->sectorsPerStripeUnit;
d223 2
a224 4
	/*
	 * Find the disk offset of the stripe unit where the last fulltable
	 * starts.
	 */
d226 1
a226 2
	diskOffsetOfLastFullTableInSUs = numCompleteFullTablesPerDisk *
	    info->FullTableDepthInPUs * layoutPtr->SUsPerPU;
d228 1
a228 2
		SpareSpaceInSUs = numCompleteSpareRegionsPerDisk *
		    info->SpareSpaceDepthPerRegionInSUs;
d231 1
a231 2
		    diskOffsetOfLastFullTableInSUs + info->ExtraTablesPerDisk *
		    info->TableDepthInPUs * layoutPtr->SUsPerPU;
d236 1
a236 1
	/* 4. Create and initialize the lookup tables. */
d243 1
a243 2
	info->BlockTable = rf_make_2d_array(info->TableDepthInPUs *
	    layoutPtr->SUsPerPU, raidPtr->numCol, raidPtr->cleanupList);
d255 1
a255 1
	/* Initialize the offset table. */
d258 1
a258 2
			info->OffsetTable[i][j] =
			    first_avail_slot[info->LayoutTable[i][j]];
d262 1
a262 1
	/* Initialize the block table. */
d266 1
a266 2
				info->BlockTable[(info->OffsetTable[i][j] *
				    layoutPtr->SUsPerPU) + l]
d275 5
a279 1
	/* 5. Set up the remaining redundant-but-useful parameters. */
d281 2
a282 5
	raidPtr->totalSectors = (k * complete_FT_count + raidPtr->numRow *
	    info->ExtraTablesPerDisk) * info->SUsPerTable *
	    layoutPtr->sectorsPerStripeUnit;
	layoutPtr->numStripe = (raidPtr->totalSectors /
	    layoutPtr->sectorsPerStripeUnit) / (k - 1);
d284 2
a285 9
	/*
	 * Strange evaluation order below to try and minimize overflow
	 * problems.
	 */

	layoutPtr->dataSectorsPerStripe =
	    (k - 1) * layoutPtr->sectorsPerStripeUnit;
	layoutPtr->bytesPerStripeUnit = layoutPtr->sectorsPerStripeUnit <<
	    raidPtr->logBytesPerSector;
d291 5
a295 5

/* Declustering with distributed sparing. */
void rf_ShutdownDeclusteredDS(RF_ThreadArg_t);
void
rf_ShutdownDeclusteredDS(RF_ThreadArg_t arg)
d301 1
a301 2
	info =
	    (RF_DeclusteredConfigInfo_t *) raidPtr->Layout.layoutSpecificInfo;
d306 5
a310 3
int
rf_ConfigureDeclusteredDS(RF_ShutdownList_t **listp, RF_Raid_t *raidPtr,
    RF_Config_t *cfgPtr)
d312 1
a312 1
	int rc;
a316 1

d319 1
a319 2
		RF_ERRORMSG1("Got %d adding shutdown event for"
		    " DeclusteredDS.\n", rc);
a322 1

d326 8
a333 3
void
rf_MapSectorDeclustered(RF_Raid_t *raidPtr, RF_RaidAddr_t raidSector,
    RF_RowCol_t *row, RF_RowCol_t *col, RF_SectorNum_t *diskSector, int remap)
d336 1
a336 2
	RF_DeclusteredConfigInfo_t *info =
	    (RF_DeclusteredConfigInfo_t *) layoutPtr->layoutSpecificInfo;
d341 1
a341 2
	RF_StripeCount_t fulltable_depth =
	    info->FullTableDepthInPUs * layoutPtr->SUsPerPU;
d344 1
a344 2
	rf_decluster_adjust_params(layoutPtr, &SUID, &sus_per_fulltable,
	    &fulltable_depth, &base_suid);
d346 2
a347 2
	/* Fulltable ID within array (across rows). */
	FullTableID = SUID / sus_per_fulltable;
d349 1
a349 1
		*row = 0;	/* Avoid a mod and a div in the common case. */
d352 2
a353 2
		/* Convert to fulltable ID on this disk. */
		FullTableID /= raidPtr->numRow;
d370 1
a370 1
	/* Remap to distributed spare space if indicated. */
d372 3
a374 8
		RF_ASSERT(raidPtr->Disks[*row][*col].status ==
		    rf_ds_reconstructing ||
		    raidPtr->Disks[*row][*col].status == rf_ds_dist_spared ||
		    (rf_copyback_in_progress &&
		    raidPtr->Disks[*row][*col].status == rf_ds_optimal));
		rf_remap_to_spare_space(layoutPtr, info, *row, FullTableID,
		    TableID, BlockID, (base_suid) ? 1 : 0, SpareRegion, col,
		    &outSU);
d378 4
a381 9
		outSU += FullTableID * fulltable_depth;
			/* Offset to start of FT. */
		outSU += SpareSpace;
			/* Skip rsvd spare space. */
		outSU += TableID * info->TableDepthInPUs * layoutPtr->SUsPerPU;
			/* Offset to start of table. */
		outSU += info->OffsetTable[BlockID][BlockOffset] *
		    layoutPtr->SUsPerPU;
			/* Offset to the PU. */
d383 2
a384 2
	outSU += TableOffset / (info->BlocksPerTable * info->PUsPerBlock);
		/* offs to the SU within a PU */
d386 3
a388 6
	/*
	 * Convert SUs to sectors, and, if not aligned to SU boundary, add in
	 * offset to sector.
	 */
	*diskSector = outSU * layoutPtr->sectorsPerStripeUnit +
	    (raidSector % layoutPtr->sectorsPerStripeUnit);
d393 10
a402 7
/*
 * Prototyping this inexplicably causes the compile of the layout table
 * (rf_layout.c) to fail.
 */
void
rf_MapParityDeclustered(RF_Raid_t *raidPtr, RF_RaidAddr_t raidSector,
    RF_RowCol_t *row, RF_RowCol_t *col, RF_SectorNum_t *diskSector, int remap)
d405 1
a405 2
	RF_DeclusteredConfigInfo_t *info =
	    (RF_DeclusteredConfigInfo_t *) layoutPtr->layoutSpecificInfo;
d410 1
a410 2
	RF_StripeCount_t fulltable_depth =
	    info->FullTableDepthInPUs * layoutPtr->SUsPerPU;
d413 1
a413 2
	rf_decluster_adjust_params(layoutPtr, &SUID, &sus_per_fulltable,
	    &fulltable_depth, &base_suid);
d415 1
a415 1
	/* Compute row & (possibly) spare space exactly as before. */
d418 1
a418 1
		*row = 0;	/* Avoid a mod and a div in the common case. */
d421 2
a422 2
		/* Convert to fulltable ID on this disk. */
		FullTableID /= raidPtr->numRow;
d428 1
a428 1
	/* Compute BlockID and RepIndex exactly as before. */
d432 3
a434 3
	/*TableOffset	= FullTableOffset % info->SUsPerTable;*/
	/*BlockID	= (TableOffset / info->PUsPerBlock) %
	 *info->BlocksPerTable;*/
d436 1
a436 1
	/*BlockOffset	= TableOffset % info->PUsPerBlock;*/
d440 2
a441 3
	/* The parity block is in the position indicated by RepIndex. */
	RepIndex = (raidPtr->noRotate) ?
	    info->PUsPerBlock : info->PUsPerBlock - TableID;
d445 3
a447 8
		RF_ASSERT(raidPtr->Disks[*row][*col].status ==
		    rf_ds_reconstructing ||
		    raidPtr->Disks[*row][*col].status == rf_ds_dist_spared ||
		    (rf_copyback_in_progress &&
		    raidPtr->Disks[*row][*col].status == rf_ds_optimal));
		rf_remap_to_spare_space(layoutPtr, info, *row, FullTableID,
		    TableID, BlockID, (base_suid) ? 1 : 0, SpareRegion, col,
		    &outSU);
d450 2
a451 4
		/*
		 * Compute sector as before, except use RepIndex instead of
		 * BlockOffset.
		 */
d456 1
a456 2
		outSU += info->OffsetTable[BlockID][RepIndex] *
		    layoutPtr->SUsPerPU;
d460 1
a460 2
	*diskSector = outSU * layoutPtr->sectorsPerStripeUnit +
	    (raidSector % layoutPtr->sectorsPerStripeUnit);
d464 2
a465 5

/*
 * Return an array of ints identifying the disks that comprise the stripe
 * containing the indicated address.
 * The caller must _never_ attempt to modify this array.
d467 6
a472 3
void
rf_IdentifyStripeDeclustered(RF_Raid_t *raidPtr, RF_RaidAddr_t addr,
    RF_RowCol_t **diskids, RF_RowCol_t *outRow)
d475 1
a475 2
	RF_DeclusteredConfigInfo_t *info =
	    (RF_DeclusteredConfigInfo_t *) layoutPtr->layoutSpecificInfo;
d477 1
a477 2
	RF_StripeCount_t fulltable_depth =
	    info->FullTableDepthInPUs * layoutPtr->SUsPerPU;
d481 1
a481 1
	int tableOffset;
d483 3
a485 4
	rf_decluster_adjust_params(layoutPtr, &SUID, &sus_per_fulltable,
	    &fulltable_depth, &base_suid);
	/* Fulltable ID within array (across rows). */
	FullTableID = SUID / sus_per_fulltable;
d487 4
a490 4
	/* Find stripe offset into array. */
	stripeID = rf_StripeUnitIDToStripeID(layoutPtr, SUID);
	/* Find offset into block design table. */
	tableOffset = (stripeID % info->BlocksPerTable);
d493 3
a495 5

/*
 * This returns the default head-separation limit, measured in
 * "required units for reconstruction". Each time a disk fetches
 * a unit, it bumps a counter. The head-sep code prohibits any disk
d500 1
a500 1
 * set. There are r stripes to be reconstructed in each table, and so
d502 1
a502 1
 * under recon at any one time. In each table, lambda units are required
d504 1
a504 1
 * (lambda*B)/r units. We subtract one to avoid weird boundary cases.
d506 2
a507 2
 * For example, suppose we are given 50 buffers, r=19, and lambda=4 as in
 * the 20.5 design. There are 19 stripes/table to be reconstructed, so
d510 1
a510 1
 * disk. There are lambda "required units" for each disk, so the fastest
d516 12
a527 15
RF_HeadSepLimit_t
rf_GetDefaultHeadSepLimitDeclustered(RF_Raid_t *raidPtr)
{
	RF_DeclusteredConfigInfo_t *info =
	    (RF_DeclusteredConfigInfo_t *) raidPtr->Layout.layoutSpecificInfo;

	return (info->Lambda * raidPtr->numFloatingReconBufs /
	    info->TableDepthInPUs / rf_numBufsToAccumulate);
}

/*
 * Return the default number of recon buffers to use. The value
 * is somewhat arbitrary...  It's intended to be large enough to
 * allow for a reasonably large head-sep limit, but small enough
 * that you don't use up all your system memory with buffers.
d529 2
a530 2
int
rf_GetDefaultNumFloatingReconBuffersDeclustered(RF_Raid_t *raidPtr)
d534 2
a535 4

/*
 * Sectors in the last fulltable of the array need to be handled
 * specially since this fulltable can be incomplete. This function
d538 1
a538 1
 * The idea here is that MapSector et. al. figure out which disk the
d544 1
a544 1
 * So, we (1) convert the fulltable size and depth parameters to
d550 7
a556 4
void
rf_decluster_adjust_params(RF_RaidLayout_t *layoutPtr, RF_StripeNum_t *SUID,
    RF_StripeCount_t *sus_per_fulltable, RF_StripeCount_t *fulltable_depth,
    RF_StripeNum_t *base_suid)
d558 1
a558 2
	RF_DeclusteredConfigInfo_t *info =
	    (RF_DeclusteredConfigInfo_t *) layoutPtr->layoutSpecificInfo;
d561 2
a562 8
		/* New full table size is size of last full table on disk. */
		*sus_per_fulltable =
		    info->ExtraTablesPerDisk * info->SUsPerTable;

		/* New full table depth is corresponding depth. */
		*fulltable_depth =
		    info->ExtraTablesPerDisk * info->TableDepthInPUs *
		    layoutPtr->SUsPerPU;
d564 4
a567 1
		/* Set up the new base offset. */
d570 2
a571 4
		/*
		 * Convert user's array address to an offset into the last
		 * fulltable.
		 */
a574 1

d576 1
a576 1
 * Map a stripe ID to a parity stripe ID.
d579 6
a584 3
void
rf_MapSIDToPSIDDeclustered(RF_RaidLayout_t *layoutPtr, RF_StripeNum_t stripeID,
    RF_StripeNum_t *psID, RF_ReconUnitNum_t *which_ru)
d590 4
a593 4
	*psID = (stripeID / (layoutPtr->SUsPerPU * info->BlocksPerTable)) *
	    info->BlocksPerTable + (stripeID % info->BlocksPerTable);
	*which_ru = (stripeID % (info->BlocksPerTable * layoutPtr->SUsPerPU)) /
	    info->BlocksPerTable;
a595 1

d600 12
a611 6
void
rf_remap_to_spare_space(RF_RaidLayout_t *layoutPtr,
    RF_DeclusteredConfigInfo_t *info, RF_RowCol_t row,
    RF_StripeNum_t FullTableID, RF_StripeNum_t TableID, RF_SectorNum_t BlockID,
    RF_StripeNum_t base_suid, RF_StripeNum_t SpareRegion, RF_RowCol_t *outCol,
    RF_StripeNum_t *outSU)
d613 2
a614 2
	RF_StripeNum_t ftID, spareTableStartSU, TableInSpareRegion,
	    lastSROffset, which_ft;
d617 4
a620 4
	 * Note that FullTableID and hence SpareRegion may have gotten
	 * tweaked by rf_decluster_adjust_params. We detect this by
	 * noticing that base_suid is not 0.
	 */
d625 8
a632 13
		 * There may be > 1.0 full tables in the last (i.e. partial)
		 * spare region. Find out which of these we are in.
		 */
		lastSROffset = info->NumCompleteSRs *
		    info->SpareRegionDepthInSUs;
		which_ft =
		    (info->DiskOffsetOfLastFullTableInSUs - lastSROffset) /
		    (info->FullTableDepthInPUs * layoutPtr->SUsPerPU);

		/* Compute the actual full table ID. */
		ftID = info->DiskOffsetOfLastFullTableInSUs /
		    (info->FullTableDepthInPUs * layoutPtr->SUsPerPU) +
		    which_ft;
d635 1
a635 2
	TableInSpareRegion = (ftID * info->NumParityReps + TableID) %
	    info->TablesPerSpareRegion;
d641 3
a643 6
	    info->DiskOffsetOfLastFullTableInSUs + info->ExtraTablesPerDisk *
	    info->TableDepthInPUs * layoutPtr->SUsPerPU :
	    (SpareRegion + 1) * info->SpareRegionDepthInSUs -
	    info->SpareSpaceDepthPerRegionInSUs;
	*outSU = spareTableStartSU +
	    info->SpareTable[TableInSpareRegion][BlockID].spareBlockOffsetInSUs;
d645 1
a645 2
		printf("rf_remap_to_spare_space: invalid remapped disk SU"
		    " offset %ld.\n", (long) *outSU);
d649 5
a653 2
int
rf_InstallSpareTable(RF_Raid_t *raidPtr, RF_RowCol_t frow, RF_RowCol_t fcol)
d655 1
a655 2
	RF_DeclusteredConfigInfo_t *info =
	    (RF_DeclusteredConfigInfo_t *) raidPtr->Layout.layoutSpecificInfo;
d657 1
a657 1
	int retcode;
d667 1
a667 2
	req->SpareSpaceDepthPerRegionInSUs =
	    info->SpareSpaceDepthPerRegionInSUs;
d670 2
a671 3
	RF_ASSERT(!retcode);
	/* XXX -- Fix this to recover gracefully. -- XXX */

a673 1

d677 4
a680 2
int
rf_SetSpareTable(RF_Raid_t *raidPtr, void *data)
d682 1
a682 2
	RF_DeclusteredConfigInfo_t *info =
	    (RF_DeclusteredConfigInfo_t *) raidPtr->Layout.layoutSpecificInfo;
d684 1
a684 1
	int i, retcode;
d686 4
a689 8
	/*
	 * What we need to copyin is a 2-d array, so first copyin the user
	 * pointers to the rows in the table.
	 */
	RF_Malloc(ptrs, info->TablesPerSpareRegion *
	    sizeof(RF_SpareTableEntry_t *), (RF_SpareTableEntry_t **));
	retcode = copyin((caddr_t) data, (caddr_t) ptrs,
	    info->TablesPerSpareRegion * sizeof(RF_SpareTableEntry_t *));
d694 2
a695 3
	/* Now allocate kernel space for the row pointers. */
	RF_Malloc(info->SpareTable, info->TablesPerSpareRegion *
	    sizeof(RF_SpareTableEntry_t *), (RF_SpareTableEntry_t **));
d697 2
a698 3
	/*
	 * Now allocate kernel space for each row in the table, and copy it in
	 * from user space. */
d700 2
a701 4
		RF_Malloc(info->SpareTable[i], info->BlocksPerTable *
		    sizeof(RF_SpareTableEntry_t), (RF_SpareTableEntry_t *));
		retcode = copyin(ptrs[i], info->SpareTable[i],
		    info->BlocksPerTable * sizeof(RF_SpareTableEntry_t));
d703 2
a704 2
			/* Blow off the memory we have allocated. */
			info->SpareTable = NULL;
d709 2
a710 3
	/* Free up the temporary array we used. */
	RF_Free(ptrs, info->TablesPerSpareRegion *
	    sizeof(RF_SpareTableEntry_t *));
d715 3
a717 2
RF_ReconUnitCount_t
rf_GetNumSpareRUsDeclustered(RF_Raid_t *raidPtr)
d721 1
a721 2
	return (((RF_DeclusteredConfigInfo_t *)
	    layoutPtr->layoutSpecificInfo)->TotSparePUsPerDisk);
d725 3
a727 2
void
rf_FreeSpareTable(RF_Raid_t *raidPtr)
d729 1
a729 1
	long i;
d731 1
a731 2
	RF_DeclusteredConfigInfo_t *info =
	    (RF_DeclusteredConfigInfo_t *) layoutPtr->layoutSpecificInfo;
d735 1
a735 2
		RF_Free(table[i], info->BlocksPerTable *
		    sizeof(RF_SpareTableEntry_t));
d737 1
a737 2
	RF_Free(table, info->TablesPerSpareRegion *
	    sizeof(RF_SpareTableEntry_t *));
@


1.3
log
@sync with work by Greg Oster on NetBSD

Please note: This update has *only* been tested on i386 with IDE
disks. Could someone with a spare box please make sure all is OK with
SCSI and maybe other arches ? sparc testing will follow locally.

* remove rf_sys.h
* many changes to make it more stable
* some performance increases
* All raid threads now get their own kernel process and the calling
  raidctl(8) program will show status progress through a meter.
* In theory FFS_SOFTUPDATES and RAIDframe will now work together - NOT
  TESTED YET

See http://www.cs.usask.ca/staff/oster/raid.html

This updates include Greg's changes to Jan 4th 2000.

TODO:
* some odd behaviour when running raictl -c on an already config'ed
  raid set - problem founf, fix being done
* progress meter is in raidctl(8) - seperate commit, but could do with
  sync'ing with OpenBSD ftp version
@
text
@d1 2
a2 2
/*	$OpenBSD: rf_decluster.c,v 1.2 1999/02/16 00:02:34 niklas Exp $	*/
/*	$NetBSD: rf_decluster.c,v 1.4 1999/08/13 03:41:56 oster Exp $	*/
a558 5
#if (defined(__NetBSD__) || defined (__OpenBSD__)) && defined(_KERNEL)
	/* Nothing! */
#else
	char    pc = layoutPtr->map->parityConfig;
#endif
@


1.3.2.1
log
@merge in approximately 2.9 into SMP branch
@
text
@d1 2
a2 2
/*	$OpenBSD: rf_decluster.c,v 1.4 2000/08/08 16:07:40 peter Exp $	*/
/*	$NetBSD: rf_decluster.c,v 1.5 2000/03/07 01:54:29 oster Exp $	*/
d559 5
@


1.3.2.2
log
@Sync the SMP branch with 3.3
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
a2 1

d30 1
a30 1
/*****************************************************************************
d32 1
a32 1
 * rf_decluster.c -- Code related to the declustered layout.
d36 12
a47 12
 * Nov 93:	Adding support for distributed sparing. This code is a little
 *		complex; the basic layout used is as follows:
 *		Let F = (v-1)/GCD(r,v-1). The spare space for each set of
 *		F consecutive fulltables is grouped together and placed after
 *		that set of tables.
 *			+-------------------------------+
 *			|	  F fulltables		|
 *			|	  Spare Space		|
 *			|	  F fulltables		|
 *			|	  Spare Space		|
 *			|	      ...		|
 *			+-------------------------------+
d49 1
a49 1
 *****************************************************************************/
d62 1
a62 1
extern int rf_copyback_in_progress;	/* Debug only. */
d64 2
a65 2
/* Found in rf_kintf.c */
int  rf_GetSpareTableFromDaemon(RF_SparetWait_t *);
d67 1
a67 1
/* Configuration code. */
d69 5
a73 3
int
rf_ConfigureDeclustered(RF_ShutdownList_t **listp, RF_Raid_t *raidPtr,
    RF_Config_t *cfgPtr)
d76 2
a77 2
	int b, v, k, r, lambda;	/* block design params */
	int i, j;
d81 2
a82 2
	RF_StripeCount_t PUsPerDisk, spareRegionDepthInPUs,
	    numCompleteSpareRegionsPerDisk, extraPUsPerDisk;
d86 1
a86 1
	char *cfgBuf = (char *) (cfgPtr->layoutSpecific);
d92 2
a93 3
	/* 1. Create layout specific structure. */
	RF_MallocAndAdd(info, sizeof(RF_DeclusteredConfigInfo_t),
	    (RF_DeclusteredConfigInfo_t *), raidPtr->cleanupList);
d99 1
a99 1
	/* 2. Extract parameters from the config structure. */
d101 1
a101 1
		bcopy(cfgBuf, info->sparemap_fname, RF_SPAREMAP_NAME_LEN);
d118 1
a118 2
	/*
	 * The sparemaps are generated assuming that parity is rotated, so we
d120 3
a122 6
	 * the same time.
	 */
	if ((layoutPtr->map->flags & RF_DISTRIBUTE_SPARE) &&
	    raidPtr->noRotate) {
		RF_ERRORMSG("Warning:  distributed sparing specified without"
		    " parity rotation.\n");
d125 1
a125 2
		RF_ERRORMSG2("RAID: config error: table element count (%d)"
		    " not equal to no. of cols (%d).\n", v, raidPtr->numCol);
d128 1
a128 1
	/* 3. Set up the values used in the mapping code. */
d132 1
a132 2
	/* b blks, k-1 SUs each. */
	info->SUsPerTable = b * (k - 1) * layoutPtr->SUsPerPU;
d137 1
a137 2
	/* k repetitions. */
	info->FullTableDepthInPUs = info->TableDepthInPUs * k;
d139 2
a140 3
	/* Used only in distributed sparing case. */
	/* (v-1)/gcd fulltables. */
	info->FullTablesPerSpareRegion = (v - 1) / rf_gcd(r, v - 1);
d142 1
a142 2
	info->SpareSpaceDepthPerRegionInSUs = (r * info->TablesPerSpareRegion /
	    (v - 1)) * layoutPtr->SUsPerPU;
d144 1
a144 1
	/* Check to make sure the block design is sufficiently small. */
d146 2
a147 6
		if (info->FullTableDepthInPUs * layoutPtr->SUsPerPU +
		    info->SpareSpaceDepthPerRegionInSUs >
		    layoutPtr->stripeUnitsPerDisk) {
			RF_ERRORMSG3("RAID: config error: Full Table depth"
			    " (%d) + Spare Space (%d) larger than disk size"
			    " (%d) (BD too big).\n",
d154 3
a156 5
		if (info->TableDepthInPUs * layoutPtr->SUsPerPU >
		    layoutPtr->stripeUnitsPerDisk) {
			RF_ERRORMSG2("RAID: config error: Table depth (%d)"
			    " larger than disk size (%d) (BD too big).\n",
			    (int) (info->TableDepthInPUs * layoutPtr->SUsPerPU),
d163 2
a164 4
	/*
	 * Compute the size of each disk, and the number of tables in the last
	 * fulltable (which need not be complete).
	 */
d167 4
a170 8
		PUsPerDisk = layoutPtr->stripeUnitsPerDisk /
		    layoutPtr->SUsPerPU;
		spareRegionDepthInPUs =
		    (info->TablesPerSpareRegion * info->TableDepthInPUs +
		    (info->TablesPerSpareRegion * info->TableDepthInPUs) /
		    (v - 1));
		info->SpareRegionDepthInSUs =
		    spareRegionDepthInPUs * layoutPtr->SUsPerPU;
d172 1
a172 2
		numCompleteSpareRegionsPerDisk =
		    PUsPerDisk / spareRegionDepthInPUs;
d176 1
a176 2
		/*
		 * Assume conservatively that we need the full amount of spare
d178 4
a181 6
		 * partial spare region at the end of the array. We set "i"
		 * to the number of tables in the partial spare region. This
		 * may actually include some fulltables.
		 */
		extraPUsPerDisk -= (info->SpareSpaceDepthPerRegionInSUs /
		    layoutPtr->SUsPerPU);
d187 2
a188 5
		complete_FT_count = raidPtr->numRow *
		    (numCompleteSpareRegionsPerDisk *
		    (info->TablesPerSpareRegion / k) + i / k);
		info->FullTableLimitSUID =
		    complete_FT_count * info->SUsPerFullTable;
d191 3
a193 6
		/*
		 * Note that in the last spare region, the spare space is
		 * complete even though data/parity space is not.
		 */
		totSparePUsPerDisk = (numCompleteSpareRegionsPerDisk + 1) *
		    (info->SpareSpaceDepthPerRegionInSUs / layoutPtr->SUsPerPU);
d197 1
a197 2
		    ((complete_FT_count / raidPtr->numRow) *
		    info->FullTableDepthInPUs +	/* data & parity space */
d199 1
a199 1
		    totSparePUsPerDisk		/* spare space */
d202 2
a203 3
		    (complete_FT_count * info->FullTableDepthInPUs +
		    info->ExtraTablesPerDisk * info->TableDepthInPUs) *
		    layoutPtr->SUsPerPU * (k - 1) / k;
d206 4
a209 8
		/*
		 * Non-dist spare case:  force each disk to contain an
		 * integral number of tables.
		 */
		layoutPtr->stripeUnitsPerDisk /=
		    (info->TableDepthInPUs * layoutPtr->SUsPerPU);
		layoutPtr->stripeUnitsPerDisk *=
		    (info->TableDepthInPUs * layoutPtr->SUsPerPU);
d211 2
a212 4
		/*
		 * Compute the number of tables in the last fulltable, which
		 * need not be complete.
		 */
d214 1
a214 2
		    ((layoutPtr->stripeUnitsPerDisk / layoutPtr->SUsPerPU) /
		    info->FullTableDepthInPUs) * raidPtr->numRow;
d216 1
a216 2
		info->FullTableLimitSUID =
		    complete_FT_count * info->SUsPerFullTable;
d218 1
a218 2
		    ((layoutPtr->stripeUnitsPerDisk / layoutPtr->SUsPerPU) /
		    info->TableDepthInPUs) % k;
d221 1
a221 2
	raidPtr->sectorsPerDisk = layoutPtr->stripeUnitsPerDisk *
		    layoutPtr->sectorsPerStripeUnit;
d223 2
a224 4
	/*
	 * Find the disk offset of the stripe unit where the last fulltable
	 * starts.
	 */
d226 1
a226 2
	diskOffsetOfLastFullTableInSUs = numCompleteFullTablesPerDisk *
	    info->FullTableDepthInPUs * layoutPtr->SUsPerPU;
d228 1
a228 2
		SpareSpaceInSUs = numCompleteSpareRegionsPerDisk *
		    info->SpareSpaceDepthPerRegionInSUs;
d231 1
a231 2
		    diskOffsetOfLastFullTableInSUs + info->ExtraTablesPerDisk *
		    info->TableDepthInPUs * layoutPtr->SUsPerPU;
d236 1
a236 1
	/* 4. Create and initialize the lookup tables. */
d243 1
a243 2
	info->BlockTable = rf_make_2d_array(info->TableDepthInPUs *
	    layoutPtr->SUsPerPU, raidPtr->numCol, raidPtr->cleanupList);
d255 1
a255 1
	/* Initialize the offset table. */
d258 1
a258 2
			info->OffsetTable[i][j] =
			    first_avail_slot[info->LayoutTable[i][j]];
d262 1
a262 1
	/* Initialize the block table. */
d266 1
a266 2
				info->BlockTable[(info->OffsetTable[i][j] *
				    layoutPtr->SUsPerPU) + l]
d275 5
a279 1
	/* 5. Set up the remaining redundant-but-useful parameters. */
d281 2
a282 5
	raidPtr->totalSectors = (k * complete_FT_count + raidPtr->numRow *
	    info->ExtraTablesPerDisk) * info->SUsPerTable *
	    layoutPtr->sectorsPerStripeUnit;
	layoutPtr->numStripe = (raidPtr->totalSectors /
	    layoutPtr->sectorsPerStripeUnit) / (k - 1);
d284 2
a285 9
	/*
	 * Strange evaluation order below to try and minimize overflow
	 * problems.
	 */

	layoutPtr->dataSectorsPerStripe =
	    (k - 1) * layoutPtr->sectorsPerStripeUnit;
	layoutPtr->bytesPerStripeUnit = layoutPtr->sectorsPerStripeUnit <<
	    raidPtr->logBytesPerSector;
d291 5
a295 5

/* Declustering with distributed sparing. */
void rf_ShutdownDeclusteredDS(RF_ThreadArg_t);
void
rf_ShutdownDeclusteredDS(RF_ThreadArg_t arg)
d301 1
a301 2
	info =
	    (RF_DeclusteredConfigInfo_t *) raidPtr->Layout.layoutSpecificInfo;
d306 5
a310 3
int
rf_ConfigureDeclusteredDS(RF_ShutdownList_t **listp, RF_Raid_t *raidPtr,
    RF_Config_t *cfgPtr)
d312 1
a312 1
	int rc;
a316 1

d319 1
a319 2
		RF_ERRORMSG1("Got %d adding shutdown event for"
		    " DeclusteredDS.\n", rc);
a322 1

d326 8
a333 3
void
rf_MapSectorDeclustered(RF_Raid_t *raidPtr, RF_RaidAddr_t raidSector,
    RF_RowCol_t *row, RF_RowCol_t *col, RF_SectorNum_t *diskSector, int remap)
d336 1
a336 2
	RF_DeclusteredConfigInfo_t *info =
	    (RF_DeclusteredConfigInfo_t *) layoutPtr->layoutSpecificInfo;
d341 1
a341 2
	RF_StripeCount_t fulltable_depth =
	    info->FullTableDepthInPUs * layoutPtr->SUsPerPU;
d344 1
a344 2
	rf_decluster_adjust_params(layoutPtr, &SUID, &sus_per_fulltable,
	    &fulltable_depth, &base_suid);
d346 2
a347 2
	/* Fulltable ID within array (across rows). */
	FullTableID = SUID / sus_per_fulltable;
d349 1
a349 1
		*row = 0;	/* Avoid a mod and a div in the common case. */
d352 2
a353 2
		/* Convert to fulltable ID on this disk. */
		FullTableID /= raidPtr->numRow;
d370 1
a370 1
	/* Remap to distributed spare space if indicated. */
d372 3
a374 8
		RF_ASSERT(raidPtr->Disks[*row][*col].status ==
		    rf_ds_reconstructing ||
		    raidPtr->Disks[*row][*col].status == rf_ds_dist_spared ||
		    (rf_copyback_in_progress &&
		    raidPtr->Disks[*row][*col].status == rf_ds_optimal));
		rf_remap_to_spare_space(layoutPtr, info, *row, FullTableID,
		    TableID, BlockID, (base_suid) ? 1 : 0, SpareRegion, col,
		    &outSU);
d378 4
a381 9
		outSU += FullTableID * fulltable_depth;
			/* Offset to start of FT. */
		outSU += SpareSpace;
			/* Skip rsvd spare space. */
		outSU += TableID * info->TableDepthInPUs * layoutPtr->SUsPerPU;
			/* Offset to start of table. */
		outSU += info->OffsetTable[BlockID][BlockOffset] *
		    layoutPtr->SUsPerPU;
			/* Offset to the PU. */
d383 2
a384 2
	outSU += TableOffset / (info->BlocksPerTable * info->PUsPerBlock);
		/* offs to the SU within a PU */
d386 3
a388 6
	/*
	 * Convert SUs to sectors, and, if not aligned to SU boundary, add in
	 * offset to sector.
	 */
	*diskSector = outSU * layoutPtr->sectorsPerStripeUnit +
	    (raidSector % layoutPtr->sectorsPerStripeUnit);
d393 10
a402 7
/*
 * Prototyping this inexplicably causes the compile of the layout table
 * (rf_layout.c) to fail.
 */
void
rf_MapParityDeclustered(RF_Raid_t *raidPtr, RF_RaidAddr_t raidSector,
    RF_RowCol_t *row, RF_RowCol_t *col, RF_SectorNum_t *diskSector, int remap)
d405 1
a405 2
	RF_DeclusteredConfigInfo_t *info =
	    (RF_DeclusteredConfigInfo_t *) layoutPtr->layoutSpecificInfo;
d410 1
a410 2
	RF_StripeCount_t fulltable_depth =
	    info->FullTableDepthInPUs * layoutPtr->SUsPerPU;
d413 1
a413 2
	rf_decluster_adjust_params(layoutPtr, &SUID, &sus_per_fulltable,
	    &fulltable_depth, &base_suid);
d415 1
a415 1
	/* Compute row & (possibly) spare space exactly as before. */
d418 1
a418 1
		*row = 0;	/* Avoid a mod and a div in the common case. */
d421 2
a422 2
		/* Convert to fulltable ID on this disk. */
		FullTableID /= raidPtr->numRow;
d428 1
a428 1
	/* Compute BlockID and RepIndex exactly as before. */
d432 3
a434 3
	/*TableOffset	= FullTableOffset % info->SUsPerTable;*/
	/*BlockID	= (TableOffset / info->PUsPerBlock) %
	 *info->BlocksPerTable;*/
d436 1
a436 1
	/*BlockOffset	= TableOffset % info->PUsPerBlock;*/
d440 2
a441 3
	/* The parity block is in the position indicated by RepIndex. */
	RepIndex = (raidPtr->noRotate) ?
	    info->PUsPerBlock : info->PUsPerBlock - TableID;
d445 3
a447 8
		RF_ASSERT(raidPtr->Disks[*row][*col].status ==
		    rf_ds_reconstructing ||
		    raidPtr->Disks[*row][*col].status == rf_ds_dist_spared ||
		    (rf_copyback_in_progress &&
		    raidPtr->Disks[*row][*col].status == rf_ds_optimal));
		rf_remap_to_spare_space(layoutPtr, info, *row, FullTableID,
		    TableID, BlockID, (base_suid) ? 1 : 0, SpareRegion, col,
		    &outSU);
d450 2
a451 4
		/*
		 * Compute sector as before, except use RepIndex instead of
		 * BlockOffset.
		 */
d456 1
a456 2
		outSU += info->OffsetTable[BlockID][RepIndex] *
		    layoutPtr->SUsPerPU;
d460 1
a460 2
	*diskSector = outSU * layoutPtr->sectorsPerStripeUnit +
	    (raidSector % layoutPtr->sectorsPerStripeUnit);
d464 2
a465 5

/*
 * Return an array of ints identifying the disks that comprise the stripe
 * containing the indicated address.
 * The caller must _never_ attempt to modify this array.
d467 6
a472 3
void
rf_IdentifyStripeDeclustered(RF_Raid_t *raidPtr, RF_RaidAddr_t addr,
    RF_RowCol_t **diskids, RF_RowCol_t *outRow)
d475 1
a475 2
	RF_DeclusteredConfigInfo_t *info =
	    (RF_DeclusteredConfigInfo_t *) layoutPtr->layoutSpecificInfo;
d477 1
a477 2
	RF_StripeCount_t fulltable_depth =
	    info->FullTableDepthInPUs * layoutPtr->SUsPerPU;
d481 1
a481 1
	int tableOffset;
d483 3
a485 4
	rf_decluster_adjust_params(layoutPtr, &SUID, &sus_per_fulltable,
	    &fulltable_depth, &base_suid);
	/* Fulltable ID within array (across rows). */
	FullTableID = SUID / sus_per_fulltable;
d487 4
a490 4
	/* Find stripe offset into array. */
	stripeID = rf_StripeUnitIDToStripeID(layoutPtr, SUID);
	/* Find offset into block design table. */
	tableOffset = (stripeID % info->BlocksPerTable);
d493 3
a495 5

/*
 * This returns the default head-separation limit, measured in
 * "required units for reconstruction". Each time a disk fetches
 * a unit, it bumps a counter. The head-sep code prohibits any disk
d500 1
a500 1
 * set. There are r stripes to be reconstructed in each table, and so
d502 1
a502 1
 * under recon at any one time. In each table, lambda units are required
d504 1
a504 1
 * (lambda*B)/r units. We subtract one to avoid weird boundary cases.
d506 2
a507 2
 * For example, suppose we are given 50 buffers, r=19, and lambda=4 as in
 * the 20.5 design. There are 19 stripes/table to be reconstructed, so
d510 1
a510 1
 * disk. There are lambda "required units" for each disk, so the fastest
d516 12
a527 15
RF_HeadSepLimit_t
rf_GetDefaultHeadSepLimitDeclustered(RF_Raid_t *raidPtr)
{
	RF_DeclusteredConfigInfo_t *info =
	    (RF_DeclusteredConfigInfo_t *) raidPtr->Layout.layoutSpecificInfo;

	return (info->Lambda * raidPtr->numFloatingReconBufs /
	    info->TableDepthInPUs / rf_numBufsToAccumulate);
}

/*
 * Return the default number of recon buffers to use. The value
 * is somewhat arbitrary...  It's intended to be large enough to
 * allow for a reasonably large head-sep limit, but small enough
 * that you don't use up all your system memory with buffers.
d529 2
a530 2
int
rf_GetDefaultNumFloatingReconBuffersDeclustered(RF_Raid_t *raidPtr)
d534 2
a535 4

/*
 * Sectors in the last fulltable of the array need to be handled
 * specially since this fulltable can be incomplete. This function
d538 1
a538 1
 * The idea here is that MapSector et. al. figure out which disk the
d544 1
a544 1
 * So, we (1) convert the fulltable size and depth parameters to
d550 7
a556 4
void
rf_decluster_adjust_params(RF_RaidLayout_t *layoutPtr, RF_StripeNum_t *SUID,
    RF_StripeCount_t *sus_per_fulltable, RF_StripeCount_t *fulltable_depth,
    RF_StripeNum_t *base_suid)
d558 1
a558 2
	RF_DeclusteredConfigInfo_t *info =
	    (RF_DeclusteredConfigInfo_t *) layoutPtr->layoutSpecificInfo;
d561 2
a562 8
		/* New full table size is size of last full table on disk. */
		*sus_per_fulltable =
		    info->ExtraTablesPerDisk * info->SUsPerTable;

		/* New full table depth is corresponding depth. */
		*fulltable_depth =
		    info->ExtraTablesPerDisk * info->TableDepthInPUs *
		    layoutPtr->SUsPerPU;
d564 4
a567 1
		/* Set up the new base offset. */
d570 2
a571 4
		/*
		 * Convert user's array address to an offset into the last
		 * fulltable.
		 */
a574 1

d576 1
a576 1
 * Map a stripe ID to a parity stripe ID.
d579 6
a584 3
void
rf_MapSIDToPSIDDeclustered(RF_RaidLayout_t *layoutPtr, RF_StripeNum_t stripeID,
    RF_StripeNum_t *psID, RF_ReconUnitNum_t *which_ru)
d590 4
a593 4
	*psID = (stripeID / (layoutPtr->SUsPerPU * info->BlocksPerTable)) *
	    info->BlocksPerTable + (stripeID % info->BlocksPerTable);
	*which_ru = (stripeID % (info->BlocksPerTable * layoutPtr->SUsPerPU)) /
	    info->BlocksPerTable;
a595 1

d600 12
a611 6
void
rf_remap_to_spare_space(RF_RaidLayout_t *layoutPtr,
    RF_DeclusteredConfigInfo_t *info, RF_RowCol_t row,
    RF_StripeNum_t FullTableID, RF_StripeNum_t TableID, RF_SectorNum_t BlockID,
    RF_StripeNum_t base_suid, RF_StripeNum_t SpareRegion, RF_RowCol_t *outCol,
    RF_StripeNum_t *outSU)
d613 2
a614 2
	RF_StripeNum_t ftID, spareTableStartSU, TableInSpareRegion,
	    lastSROffset, which_ft;
d617 4
a620 4
	 * Note that FullTableID and hence SpareRegion may have gotten
	 * tweaked by rf_decluster_adjust_params. We detect this by
	 * noticing that base_suid is not 0.
	 */
d625 8
a632 13
		 * There may be > 1.0 full tables in the last (i.e. partial)
		 * spare region. Find out which of these we are in.
		 */
		lastSROffset = info->NumCompleteSRs *
		    info->SpareRegionDepthInSUs;
		which_ft =
		    (info->DiskOffsetOfLastFullTableInSUs - lastSROffset) /
		    (info->FullTableDepthInPUs * layoutPtr->SUsPerPU);

		/* Compute the actual full table ID. */
		ftID = info->DiskOffsetOfLastFullTableInSUs /
		    (info->FullTableDepthInPUs * layoutPtr->SUsPerPU) +
		    which_ft;
d635 1
a635 2
	TableInSpareRegion = (ftID * info->NumParityReps + TableID) %
	    info->TablesPerSpareRegion;
d641 3
a643 6
	    info->DiskOffsetOfLastFullTableInSUs + info->ExtraTablesPerDisk *
	    info->TableDepthInPUs * layoutPtr->SUsPerPU :
	    (SpareRegion + 1) * info->SpareRegionDepthInSUs -
	    info->SpareSpaceDepthPerRegionInSUs;
	*outSU = spareTableStartSU +
	    info->SpareTable[TableInSpareRegion][BlockID].spareBlockOffsetInSUs;
d645 1
a645 2
		printf("rf_remap_to_spare_space: invalid remapped disk SU"
		    " offset %ld.\n", (long) *outSU);
d649 5
a653 2
int
rf_InstallSpareTable(RF_Raid_t *raidPtr, RF_RowCol_t frow, RF_RowCol_t fcol)
d655 1
a655 2
	RF_DeclusteredConfigInfo_t *info =
	    (RF_DeclusteredConfigInfo_t *) raidPtr->Layout.layoutSpecificInfo;
d657 1
a657 1
	int retcode;
d667 1
a667 2
	req->SpareSpaceDepthPerRegionInSUs =
	    info->SpareSpaceDepthPerRegionInSUs;
d670 2
a671 3
	RF_ASSERT(!retcode);
	/* XXX -- Fix this to recover gracefully. -- XXX */

a673 1

d677 4
a680 2
int
rf_SetSpareTable(RF_Raid_t *raidPtr, void *data)
d682 1
a682 2
	RF_DeclusteredConfigInfo_t *info =
	    (RF_DeclusteredConfigInfo_t *) raidPtr->Layout.layoutSpecificInfo;
d684 1
a684 1
	int i, retcode;
d686 4
a689 8
	/*
	 * What we need to copyin is a 2-d array, so first copyin the user
	 * pointers to the rows in the table.
	 */
	RF_Malloc(ptrs, info->TablesPerSpareRegion *
	    sizeof(RF_SpareTableEntry_t *), (RF_SpareTableEntry_t **));
	retcode = copyin((caddr_t) data, (caddr_t) ptrs,
	    info->TablesPerSpareRegion * sizeof(RF_SpareTableEntry_t *));
d694 2
a695 3
	/* Now allocate kernel space for the row pointers. */
	RF_Malloc(info->SpareTable, info->TablesPerSpareRegion *
	    sizeof(RF_SpareTableEntry_t *), (RF_SpareTableEntry_t **));
d697 2
a698 3
	/*
	 * Now allocate kernel space for each row in the table, and copy it in
	 * from user space. */
d700 2
a701 4
		RF_Malloc(info->SpareTable[i], info->BlocksPerTable *
		    sizeof(RF_SpareTableEntry_t), (RF_SpareTableEntry_t *));
		retcode = copyin(ptrs[i], info->SpareTable[i],
		    info->BlocksPerTable * sizeof(RF_SpareTableEntry_t));
d703 2
a704 2
			/* Blow off the memory we have allocated. */
			info->SpareTable = NULL;
d709 2
a710 3
	/* Free up the temporary array we used. */
	RF_Free(ptrs, info->TablesPerSpareRegion *
	    sizeof(RF_SpareTableEntry_t *));
d715 3
a717 2
RF_ReconUnitCount_t
rf_GetNumSpareRUsDeclustered(RF_Raid_t *raidPtr)
d721 1
a721 2
	return (((RF_DeclusteredConfigInfo_t *)
	    layoutPtr->layoutSpecificInfo)->TotSparePUsPerDisk);
d725 3
a727 2
void
rf_FreeSpareTable(RF_Raid_t *raidPtr)
d729 1
a729 1
	long i;
d731 1
a731 2
	RF_DeclusteredConfigInfo_t *info =
	    (RF_DeclusteredConfigInfo_t *) layoutPtr->layoutSpecificInfo;
d735 1
a735 2
		RF_Free(table[i], info->BlocksPerTable *
		    sizeof(RF_SpareTableEntry_t));
d737 1
a737 2
	RF_Free(table, info->TablesPerSpareRegion *
	    sizeof(RF_SpareTableEntry_t *));
@


1.2
log
@Merge from NetBSD, mostly indentation
@
text
@d1 2
a2 2
/*	$OpenBSD: rf_decluster.c,v 1.1 1999/01/11 14:29:14 niklas Exp $	*/
/*	$NetBSD: rf_decluster.c,v 1.3 1999/02/05 00:06:08 oster Exp $	*/
a60 1
#include "rf_sys.h"
@


1.1
log
@Import of CMU's RAIDframe via NetBSD.
@
text
@d1 2
a2 2
/*	$OpenBSD: rf_decluster.c,v 1.1 1998/11/13 04:20:28 oster Exp $	*/
/*	$NetBSD: rf_decluster.c,v 1.1 1998/11/13 04:20:28 oster Exp $	*/
a50 133
/*
 * :  
 * Log: rf_decluster.c,v 
 * Revision 1.51  1996/08/21 19:47:10  jimz
 * fix bogus return values from config
 *
 * Revision 1.50  1996/08/20  22:41:42  jimz
 * better diagnostics for bad blockdesigns
 *
 * Revision 1.49  1996/07/31  16:56:18  jimz
 * dataBytesPerStripe, sectorsPerDisk init arch-indep.
 *
 * Revision 1.48  1996/07/29  14:05:12  jimz
 * fix numPUs/numRUs confusion (everything is now numRUs)
 * clean up some commenting, return values
 *
 * Revision 1.47  1996/07/27  23:36:08  jimz
 * Solaris port of simulator
 *
 * Revision 1.46  1996/07/27  18:40:11  jimz
 * cleanup sweep
 *
 * Revision 1.45  1996/07/18  22:57:14  jimz
 * port simulator to AIX
 *
 * Revision 1.44  1996/07/13  00:00:59  jimz
 * sanitized generalized reconstruction architecture
 * cleaned up head sep, rbuf problems
 *
 * Revision 1.43  1996/06/19  17:53:48  jimz
 * move GetNumSparePUs, InstallSpareTable ops into layout switch
 *
 * Revision 1.42  1996/06/17  03:23:48  jimz
 * switch DeclusteredDS typing
 *
 * Revision 1.41  1996/06/11  08:55:15  jimz
 * improved error-checking at configuration time
 *
 * Revision 1.40  1996/06/10  11:55:47  jimz
 * Straightened out some per-array/not-per-array distinctions, fixed
 * a couple bugs related to confusion. Added shutdown lists. Removed
 * layout shutdown function (now subsumed by shutdown lists).
 *
 * Revision 1.39  1996/06/09  02:36:46  jimz
 * lots of little crufty cleanup- fixup whitespace
 * issues, comment #ifdefs, improve typing in some
 * places (esp size-related)
 *
 * Revision 1.38  1996/06/07  22:26:27  jimz
 * type-ify which_ru (RF_ReconUnitNum_t)
 *
 * Revision 1.37  1996/06/07  21:33:04  jimz
 * begin using consistent types for sector numbers,
 * stripe numbers, row+col numbers, recon unit numbers
 *
 * Revision 1.36  1996/06/03  23:28:26  jimz
 * more bugfixes
 * check in tree to sync for IPDS runs with current bugfixes
 * there still may be a problem with threads in the script test
 * getting I/Os stuck- not trivially reproducible (runs ~50 times
 * in a row without getting stuck)
 *
 * Revision 1.35  1996/06/02  17:31:48  jimz
 * Moved a lot of global stuff into array structure, where it belongs.
 * Fixed up paritylogging, pss modules in this manner. Some general
 * code cleanup. Removed lots of dead code, some dead files.
 *
 * Revision 1.34  1996/05/30  23:22:16  jimz
 * bugfixes of serialization, timing problems
 * more cleanup
 *
 * Revision 1.33  1996/05/30  11:29:41  jimz
 * Numerous bug fixes. Stripe lock release code disagreed with the taking code
 * about when stripes should be locked (I made it consistent: no parity, no lock)
 * There was a lot of extra serialization of I/Os which I've removed- a lot of
 * it was to calculate values for the cache code, which is no longer with us.
 * More types, function, macro cleanup. Added code to properly quiesce the array
 * on shutdown. Made a lot of stuff array-specific which was (bogusly) general
 * before. Fixed memory allocation, freeing bugs.
 *
 * Revision 1.32  1996/05/27  18:56:37  jimz
 * more code cleanup
 * better typing
 * compiles in all 3 environments
 *
 * Revision 1.31  1996/05/24  01:59:45  jimz
 * another checkpoint in code cleanup for release
 * time to sync kernel tree
 *
 * Revision 1.30  1996/05/23  00:33:23  jimz
 * code cleanup: move all debug decls to rf_options.c, all extern
 * debug decls to rf_options.h, all debug vars preceded by rf_
 *
 * Revision 1.29  1996/05/18  19:51:34  jimz
 * major code cleanup- fix syntax, make some types consistent,
 * add prototypes, clean out dead code, et cetera
 *
 * Revision 1.28  1995/12/12  18:10:06  jimz
 * MIN -> RF_MIN, MAX -> RF_MAX, ASSERT -> RF_ASSERT
 * fix 80-column brain damage in comments
 *
 * Revision 1.27  1995/12/01  16:00:08  root
 * added copyright info
 *
 * Revision 1.26  1995/11/28  21:35:12  amiri
 * set the RF_BD_DECLUSTERED flag
 *
 * Revision 1.25  1995/11/17  18:56:00  wvcii
 * added prototyping to MapParity
 *
 * Revision 1.24  1995/07/04  22:25:33  holland
 * increased default num bufs
 *
 * Revision 1.23  1995/07/03  20:23:51  holland
 * changed floating recon bufs & head sep yet again
 *
 * Revision 1.22  1995/07/03  18:12:14  holland
 * changed the way the number of floating recon bufs & the head sep
 * limit are set
 *
 * Revision 1.21  1995/07/02  15:07:42  holland
 * bug fixes related to getting distributed sparing numbers
 *
 * Revision 1.20  1995/06/23  13:41:28  robby
 * updeated to prototypes in rf_layout.h
 *
 */

#ifdef _KERNEL
#define KERNEL
#endif


d63 1
a63 1
extern int rf_copyback_in_progress;                /* debug only */
d66 1
a66 1
int rf_GetSpareTableFromDaemon(RF_SparetWait_t  *req);
d70 93
a162 205
int rf_ConfigureDeclustered(
  RF_ShutdownList_t  **listp,
  RF_Raid_t           *raidPtr,
  RF_Config_t         *cfgPtr)
{
    RF_RaidLayout_t *layoutPtr = &(raidPtr->Layout);
    int b, v, k, r, lambda;				/* block design params */
    int i, j;
    RF_RowCol_t *first_avail_slot;
    RF_StripeCount_t complete_FT_count, numCompleteFullTablesPerDisk;
    RF_DeclusteredConfigInfo_t *info;
    RF_StripeCount_t PUsPerDisk, spareRegionDepthInPUs, numCompleteSpareRegionsPerDisk, extraPUsPerDisk;
    RF_StripeCount_t totSparePUsPerDisk;
    RF_SectorNum_t diskOffsetOfLastFullTableInSUs;
    RF_SectorCount_t SpareSpaceInSUs;
    char *cfgBuf = (char *) (cfgPtr->layoutSpecific);
    RF_StripeNum_t l, SUID;

    SUID = l = 0;
    numCompleteSpareRegionsPerDisk = 0;

    /* 1. create layout specific structure */
    RF_MallocAndAdd(info, sizeof(RF_DeclusteredConfigInfo_t), (RF_DeclusteredConfigInfo_t *), raidPtr->cleanupList);
    if (info == NULL)
      return(ENOMEM);
    layoutPtr->layoutSpecificInfo = (void *) info;
    info->SpareTable = NULL;

    /* 2. extract parameters from the config structure */
    if (layoutPtr->map->flags & RF_DISTRIBUTE_SPARE) {
      (void) bcopy(cfgBuf, info->sparemap_fname, RF_SPAREMAP_NAME_LEN);
    }
    cfgBuf += RF_SPAREMAP_NAME_LEN;
    
    b        = *( (int *) cfgBuf);   cfgBuf += sizeof(int);
    v        = *( (int *) cfgBuf);   cfgBuf += sizeof(int);
    k        = *( (int *) cfgBuf);   cfgBuf += sizeof(int);
    r        = *( (int *) cfgBuf);   cfgBuf += sizeof(int);
    lambda   = *( (int *) cfgBuf);   cfgBuf += sizeof(int);
    raidPtr->noRotate = *( (int *) cfgBuf);   cfgBuf += sizeof(int);

    /* the sparemaps are generated assuming that parity is rotated, so we issue
     * a warning if both distributed sparing and no-rotate are on at the same time
     */
    if ((layoutPtr->map->flags & RF_DISTRIBUTE_SPARE) && raidPtr->noRotate) {
	RF_ERRORMSG("Warning:  distributed sparing specified without parity rotation.\n");
    }

    if (raidPtr->numCol != v) {
        RF_ERRORMSG2("RAID: config error: table element count (%d) not equal to no. of cols (%d)\n", v, raidPtr->numCol);
        return(EINVAL);
    }

    /* 3.  set up the values used in the mapping code */
    info->BlocksPerTable = b;
    info->Lambda = lambda;
    info->NumParityReps = info->groupSize = k;
    info->SUsPerTable = b * (k-1) * layoutPtr->SUsPerPU;/* b blks, k-1 SUs each */
    info->SUsPerFullTable = k * info->SUsPerTable;	/* rot k times */
    info->PUsPerBlock = k-1;
    info->SUsPerBlock = info->PUsPerBlock * layoutPtr->SUsPerPU;
    info->TableDepthInPUs = (b*k) / v;
    info->FullTableDepthInPUs = info->TableDepthInPUs * k;		/* k repetitions */

    /* used only in distributed sparing case */
    info->FullTablesPerSpareRegion = (v-1) / rf_gcd(r, v-1);		/* (v-1)/gcd fulltables */
    info->TablesPerSpareRegion = k * info->FullTablesPerSpareRegion;
    info->SpareSpaceDepthPerRegionInSUs = (r * info->TablesPerSpareRegion / (v-1)) * layoutPtr->SUsPerPU;

    /* check to make sure the block design is sufficiently small */
    if ((raidPtr->Layout.map->flags & RF_DISTRIBUTE_SPARE)) {
        if (info->FullTableDepthInPUs * layoutPtr->SUsPerPU + info->SpareSpaceDepthPerRegionInSUs > layoutPtr->stripeUnitsPerDisk) {
	    RF_ERRORMSG3("RAID: config error: Full Table depth (%d) + Spare Space (%d) larger than disk size (%d) (BD too big)\n",
			 (int)info->FullTableDepthInPUs, 
			 (int)info->SpareSpaceDepthPerRegionInSUs, 
			 (int)layoutPtr->stripeUnitsPerDisk);
	    return(EINVAL);
	}
    } else {
	if (info->TableDepthInPUs * layoutPtr->SUsPerPU > layoutPtr->stripeUnitsPerDisk) {
	    RF_ERRORMSG2("RAID: config error: Table depth (%d) larger than disk size (%d) (BD too big)\n",
			 (int)(info->TableDepthInPUs * layoutPtr->SUsPerPU), \
			 (int)layoutPtr->stripeUnitsPerDisk);
	    return(EINVAL);
	}
    }

	
    /* compute the size of each disk, and the number of tables in the last fulltable (which
     * need not be complete)
     */
    if (raidPtr->Layout.map->flags & RF_DISTRIBUTE_SPARE) {
	
	PUsPerDisk = layoutPtr->stripeUnitsPerDisk / layoutPtr->SUsPerPU;
	spareRegionDepthInPUs = (info->TablesPerSpareRegion * info->TableDepthInPUs +
				 (info->TablesPerSpareRegion * info->TableDepthInPUs) / (v-1));
	info->SpareRegionDepthInSUs = spareRegionDepthInPUs * layoutPtr->SUsPerPU;
	
	numCompleteSpareRegionsPerDisk = PUsPerDisk / spareRegionDepthInPUs;
	info->NumCompleteSRs = numCompleteSpareRegionsPerDisk;
	extraPUsPerDisk = PUsPerDisk % spareRegionDepthInPUs;

	/* assume conservatively that we need the full amount of spare space in one region in order
	 * to provide spares for the partial spare region at the end of the array.  We set "i" to
	 * the number of tables in the partial spare region.  This may actually include some fulltables.
	 */
	extraPUsPerDisk -= (info->SpareSpaceDepthPerRegionInSUs / layoutPtr->SUsPerPU);
	if (extraPUsPerDisk <= 0) i = 0;
	else i = extraPUsPerDisk/info->TableDepthInPUs;

	complete_FT_count = raidPtr->numRow * (numCompleteSpareRegionsPerDisk * (info->TablesPerSpareRegion/k) + i/k);
        info->FullTableLimitSUID = complete_FT_count * info->SUsPerFullTable;
	info->ExtraTablesPerDisk = i % k;

	/* note that in the last spare region, the spare space is complete even though data/parity space is not */
	totSparePUsPerDisk = (numCompleteSpareRegionsPerDisk+1) * (info->SpareSpaceDepthPerRegionInSUs / layoutPtr->SUsPerPU);
	info->TotSparePUsPerDisk = totSparePUsPerDisk;
	
	layoutPtr->stripeUnitsPerDisk =
	    ((complete_FT_count/raidPtr->numRow) * info->FullTableDepthInPUs +	 	/* data & parity space */
	     info->ExtraTablesPerDisk * info->TableDepthInPUs +
	     totSparePUsPerDisk								/* spare space */
	    ) * layoutPtr->SUsPerPU;
	layoutPtr->dataStripeUnitsPerDisk = 
	    (complete_FT_count * info->FullTableDepthInPUs + info->ExtraTablesPerDisk * info->TableDepthInPUs)
	    * layoutPtr->SUsPerPU * (k-1) / k;

    } else {
        /* non-dist spare case:  force each disk to contain an integral number of tables */
        layoutPtr->stripeUnitsPerDisk /= (info->TableDepthInPUs * layoutPtr->SUsPerPU);
        layoutPtr->stripeUnitsPerDisk *= (info->TableDepthInPUs * layoutPtr->SUsPerPU);

	/* compute the number of tables in the last fulltable, which need not be complete */
        complete_FT_count =
            ((layoutPtr->stripeUnitsPerDisk/layoutPtr->SUsPerPU) / info->FullTableDepthInPUs) * raidPtr->numRow;
	    
        info->FullTableLimitSUID = complete_FT_count * info->SUsPerFullTable;
        info->ExtraTablesPerDisk =
		((layoutPtr->stripeUnitsPerDisk/layoutPtr->SUsPerPU) / info->TableDepthInPUs) % k;
    }

    raidPtr->sectorsPerDisk = layoutPtr->stripeUnitsPerDisk * layoutPtr->sectorsPerStripeUnit;

    /* find the disk offset of the stripe unit where the last fulltable starts */
    numCompleteFullTablesPerDisk = complete_FT_count / raidPtr->numRow;
    diskOffsetOfLastFullTableInSUs = numCompleteFullTablesPerDisk * info->FullTableDepthInPUs * layoutPtr->SUsPerPU;
    if (raidPtr->Layout.map->flags & RF_DISTRIBUTE_SPARE) {
        SpareSpaceInSUs  = numCompleteSpareRegionsPerDisk * info->SpareSpaceDepthPerRegionInSUs;
        diskOffsetOfLastFullTableInSUs += SpareSpaceInSUs;
        info->DiskOffsetOfLastSpareSpaceChunkInSUs =
	    diskOffsetOfLastFullTableInSUs + info->ExtraTablesPerDisk * info->TableDepthInPUs * layoutPtr->SUsPerPU;
    }
    info->DiskOffsetOfLastFullTableInSUs = diskOffsetOfLastFullTableInSUs;
    info->numCompleteFullTablesPerDisk = numCompleteFullTablesPerDisk;
	
    /* 4.  create and initialize the lookup tables */
    info->LayoutTable = rf_make_2d_array(b, k, raidPtr->cleanupList);
    if (info->LayoutTable == NULL)
      return(ENOMEM);
    info->OffsetTable = rf_make_2d_array(b, k, raidPtr->cleanupList);
    if (info->OffsetTable == NULL)
      return(ENOMEM);
    info->BlockTable  =	rf_make_2d_array(info->TableDepthInPUs*layoutPtr->SUsPerPU, raidPtr->numCol, raidPtr->cleanupList);
    if (info->BlockTable == NULL)
      return(ENOMEM);

    first_avail_slot = rf_make_1d_array(v, NULL);
    if (first_avail_slot == NULL)
      return(ENOMEM);

    for (i=0; i<b; i++)
      for (j=0; j<k; j++)
        info->LayoutTable[i][j] = *cfgBuf++;

    /* initialize offset table */
    for (i=0; i<b; i++) for (j=0; j<k; j++) {
        info->OffsetTable[i][j] = first_avail_slot[ info->LayoutTable[i][j] ];
        first_avail_slot[ info->LayoutTable[i][j] ]++;
    }

    /* initialize block table */
    for (SUID=l=0; l<layoutPtr->SUsPerPU; l++) {
        for (i=0; i<b; i++) {
            for (j=0; j<k; j++) {
                info->BlockTable[ (info->OffsetTable[i][j] * layoutPtr->SUsPerPU) + l ]
		                [ info->LayoutTable[i][j] ] = SUID;
            }
            SUID++;
        }
    }

    rf_free_1d_array(first_avail_slot, v);

    /* 5.  set up the remaining redundant-but-useful parameters */

    raidPtr->totalSectors = (k*complete_FT_count + raidPtr->numRow*info->ExtraTablesPerDisk) *
    			  info->SUsPerTable * layoutPtr->sectorsPerStripeUnit;
    layoutPtr->numStripe = (raidPtr->totalSectors / layoutPtr->sectorsPerStripeUnit) / (k-1);

    /* strange evaluation order below to try and minimize overflow problems */
    
    layoutPtr->dataSectorsPerStripe = (k-1) * layoutPtr->sectorsPerStripeUnit;
    layoutPtr->bytesPerStripeUnit = layoutPtr->sectorsPerStripeUnit << raidPtr->logBytesPerSector;
    layoutPtr->numDataCol = k-1;
    layoutPtr->numParityCol = 1;
d164 127
a290 1
    return(0);
a291 1

d294 92
a385 5
static void rf_ShutdownDeclusteredDS(arg)
  RF_ThreadArg_t  arg;
{
  RF_DeclusteredConfigInfo_t *info;
  RF_Raid_t *raidPtr;
d387 3
a389 81
  raidPtr = (RF_Raid_t *)arg;
  info = (RF_DeclusteredConfigInfo_t *) raidPtr->Layout.layoutSpecificInfo;
  if (info->SpareTable)
    rf_FreeSpareTable(raidPtr);
}

int rf_ConfigureDeclusteredDS(
  RF_ShutdownList_t  **listp,
  RF_Raid_t           *raidPtr,
  RF_Config_t         *cfgPtr)
{
  int rc;

  rc = rf_ConfigureDeclustered(listp, raidPtr, cfgPtr);
  if (rc)
    return(rc);
  rc = rf_ShutdownCreate(listp, rf_ShutdownDeclusteredDS, raidPtr);
  if (rc) {
    RF_ERRORMSG1("Got %d adding shutdown event for DeclusteredDS\n", rc);
    rf_ShutdownDeclusteredDS(raidPtr);
    return(rc);
  }
  return(0);
}

void rf_MapSectorDeclustered(raidPtr, raidSector, row, col, diskSector, remap)
  RF_Raid_t       *raidPtr;
  RF_RaidAddr_t    raidSector;
  RF_RowCol_t     *row;
  RF_RowCol_t     *col;
  RF_SectorNum_t  *diskSector;
  int              remap;
{
    RF_RaidLayout_t *layoutPtr = &(raidPtr->Layout);
    RF_DeclusteredConfigInfo_t *info = (RF_DeclusteredConfigInfo_t *) layoutPtr->layoutSpecificInfo;
    RF_StripeNum_t SUID = raidSector / layoutPtr->sectorsPerStripeUnit;
    RF_StripeNum_t FullTableID, FullTableOffset, TableID, TableOffset; 
    RF_StripeNum_t BlockID, BlockOffset, RepIndex;
    RF_StripeCount_t sus_per_fulltable = info->SUsPerFullTable;
    RF_StripeCount_t fulltable_depth  = info->FullTableDepthInPUs * layoutPtr->SUsPerPU;
    RF_StripeNum_t base_suid = 0, outSU, SpareRegion=0, SpareSpace=0;

    rf_decluster_adjust_params(layoutPtr, &SUID, &sus_per_fulltable, &fulltable_depth, &base_suid);
	    
    FullTableID     = SUID / sus_per_fulltable;		/* fulltable ID within array (across rows) */
    if (raidPtr->numRow == 1) *row = 0;                 /* avoid a mod and a div in the common case */
    else {
      *row            = FullTableID % raidPtr->numRow;
      FullTableID    /= raidPtr->numRow;			/* convert to fulltable ID on this disk */
    }
    if (raidPtr->Layout.map->flags & RF_DISTRIBUTE_SPARE) {
	SpareRegion = FullTableID / info->FullTablesPerSpareRegion;
        SpareSpace  = SpareRegion * info->SpareSpaceDepthPerRegionInSUs;
    }
    FullTableOffset = SUID % sus_per_fulltable;
    TableID         = FullTableOffset / info->SUsPerTable;
    TableOffset     = FullTableOffset - TableID * info->SUsPerTable;
    BlockID         = TableOffset / info->PUsPerBlock;
    BlockOffset     = TableOffset - BlockID * info->PUsPerBlock;
    BlockID        %= info->BlocksPerTable;
    RepIndex        = info->PUsPerBlock - TableID;
    if (!raidPtr->noRotate) BlockOffset    += ((BlockOffset >= RepIndex) ? 1 : 0);
    *col            = info->LayoutTable[BlockID][BlockOffset];

    /* remap to distributed spare space if indicated */
    if (remap) {
      RF_ASSERT( raidPtr->Disks[*row][*col].status == rf_ds_reconstructing || raidPtr->Disks[*row][*col].status == rf_ds_dist_spared ||
	     (rf_copyback_in_progress && raidPtr->Disks[*row][*col].status == rf_ds_optimal));
      rf_remap_to_spare_space(layoutPtr, info, *row, FullTableID, TableID, BlockID, (base_suid) ? 1 : 0, SpareRegion, col, &outSU);
    } else {
    
        outSU	    = base_suid;
        outSU      += FullTableID * fulltable_depth;  				        /* offs to strt of FT */
        outSU	   += SpareSpace;						        /* skip rsvd spare space */
        outSU      += TableID * info->TableDepthInPUs * layoutPtr->SUsPerPU;   	        /* offs to strt of tble */
        outSU      += info->OffsetTable[BlockID][BlockOffset] * layoutPtr->SUsPerPU;	/* offs to the PU */
    }
    outSU          += TableOffset / (info->BlocksPerTable * info->PUsPerBlock);	        /* offs to the SU within a PU */
    
    /* convert SUs to sectors, and, if not aligned to SU boundary, add in offset to sector.  */
    *diskSector     = outSU*layoutPtr->sectorsPerStripeUnit + (raidSector % layoutPtr->sectorsPerStripeUnit);
d391 1
a391 1
    RF_ASSERT( *col != -1 );
d396 68
a463 64
void rf_MapParityDeclustered(
  RF_Raid_t       *raidPtr,
  RF_RaidAddr_t    raidSector,
  RF_RowCol_t     *row,
  RF_RowCol_t     *col,
  RF_SectorNum_t  *diskSector,
  int              remap)
{
    RF_RaidLayout_t *layoutPtr = &(raidPtr->Layout);
    RF_DeclusteredConfigInfo_t *info = (RF_DeclusteredConfigInfo_t *) layoutPtr->layoutSpecificInfo;
    RF_StripeNum_t SUID = raidSector / layoutPtr->sectorsPerStripeUnit;
    RF_StripeNum_t FullTableID, FullTableOffset, TableID, TableOffset; 
    RF_StripeNum_t BlockID, BlockOffset, RepIndex;
    RF_StripeCount_t sus_per_fulltable = info->SUsPerFullTable;
    RF_StripeCount_t fulltable_depth  = info->FullTableDepthInPUs * layoutPtr->SUsPerPU;
    RF_StripeNum_t base_suid = 0, outSU, SpareRegion=0, SpareSpace=0;

    rf_decluster_adjust_params(layoutPtr, &SUID, &sus_per_fulltable, &fulltable_depth, &base_suid);
    
    /* compute row & (possibly) spare space exactly as before */
    FullTableID     = SUID / sus_per_fulltable;
    if (raidPtr->numRow == 1) *row = 0;                         /* avoid a mod and a div in the common case */
    else {
      *row            = FullTableID % raidPtr->numRow;
      FullTableID    /= raidPtr->numRow;			/* convert to fulltable ID on this disk */
    }
    if ((raidPtr->Layout.map->flags & RF_DISTRIBUTE_SPARE)) {
	SpareRegion = FullTableID / info->FullTablesPerSpareRegion;
        SpareSpace  = SpareRegion * info->SpareSpaceDepthPerRegionInSUs;
    }

    /* compute BlockID and RepIndex exactly as before */
    FullTableOffset = SUID % sus_per_fulltable;
    TableID         = FullTableOffset / info->SUsPerTable;
    TableOffset     = FullTableOffset - TableID * info->SUsPerTable;
    /*TableOffset     = FullTableOffset % info->SUsPerTable;*/
    /*BlockID         = (TableOffset / info->PUsPerBlock) % info->BlocksPerTable;*/
    BlockID         = TableOffset / info->PUsPerBlock;
    /*BlockOffset     = TableOffset % info->PUsPerBlock;*/
    BlockOffset     = TableOffset - BlockID * info->PUsPerBlock;
    BlockID        %= info->BlocksPerTable;

    /* the parity block is in the position indicated by RepIndex */
    RepIndex        = (raidPtr->noRotate) ? info->PUsPerBlock : info->PUsPerBlock - TableID;
    *col	    = info->LayoutTable[BlockID][RepIndex];
    
    if (remap) {
      RF_ASSERT( raidPtr->Disks[*row][*col].status == rf_ds_reconstructing || raidPtr->Disks[*row][*col].status == rf_ds_dist_spared ||
	     (rf_copyback_in_progress && raidPtr->Disks[*row][*col].status == rf_ds_optimal));
      rf_remap_to_spare_space(layoutPtr, info, *row, FullTableID, TableID, BlockID, (base_suid) ? 1 : 0, SpareRegion, col, &outSU);
    } else {

        /* compute sector as before, except use RepIndex instead of BlockOffset */
        outSU        = base_suid;
        outSU       += FullTableID * fulltable_depth;
        outSU	    += SpareSpace;						/* skip rsvd spare space */
        outSU       += TableID * info->TableDepthInPUs * layoutPtr->SUsPerPU;
        outSU       += info->OffsetTable[BlockID][RepIndex] * layoutPtr->SUsPerPU;
    }
    
    outSU       += TableOffset / (info->BlocksPerTable * info->PUsPerBlock);
    *diskSector  = outSU*layoutPtr->sectorsPerStripeUnit + (raidSector % layoutPtr->sectorsPerStripeUnit);
    
    RF_ASSERT( *col != -1 );
a464 1

d468 25
a492 21
void rf_IdentifyStripeDeclustered(
  RF_Raid_t        *raidPtr,
  RF_RaidAddr_t     addr,
  RF_RowCol_t     **diskids,
  RF_RowCol_t      *outRow)
{
  RF_RaidLayout_t *layoutPtr           = &(raidPtr->Layout);
  RF_DeclusteredConfigInfo_t *info     = (RF_DeclusteredConfigInfo_t *) layoutPtr->layoutSpecificInfo;
  RF_StripeCount_t sus_per_fulltable   = info->SUsPerFullTable;
  RF_StripeCount_t fulltable_depth     = info->FullTableDepthInPUs * layoutPtr->SUsPerPU;
  RF_StripeNum_t  base_suid            = 0;
  RF_StripeNum_t SUID                  = rf_RaidAddressToStripeUnitID(layoutPtr, addr);
  RF_StripeNum_t stripeID, FullTableID;
  int tableOffset;

  rf_decluster_adjust_params(layoutPtr, &SUID, &sus_per_fulltable, &fulltable_depth, &base_suid);
  FullTableID     = SUID / sus_per_fulltable;		/* fulltable ID within array (across rows) */
  *outRow         = FullTableID % raidPtr->numRow;
  stripeID        = rf_StripeUnitIDToStripeID(layoutPtr, SUID);                     /* find stripe offset into array */
  tableOffset     = (stripeID % info->BlocksPerTable);                        /* find offset into block design table */
  *diskids        = info->LayoutTable[tableOffset];
a493 1

d497 1
a497 1
 * from getting more than headSepLimit counter values ahead of any 
d506 1
a506 1
 * 
d517 3
a519 2
RF_HeadSepLimit_t rf_GetDefaultHeadSepLimitDeclustered(
  RF_Raid_t  *raidPtr)
d521 1
a521 1
  RF_DeclusteredConfigInfo_t *info = (RF_DeclusteredConfigInfo_t *) raidPtr->Layout.layoutSpecificInfo;
d523 1
a523 1
  return(info->Lambda * raidPtr->numFloatingReconBufs / info->TableDepthInPUs / rf_numBufsToAccumulate);
a524 1

d530 2
a531 1
int rf_GetDefaultNumFloatingReconBuffersDeclustered(RF_Raid_t *raidPtr)
d533 1
a533 1
  return(100 * rf_numBufsToAccumulate);
a534 1

d551 11
a561 10
void rf_decluster_adjust_params(
  RF_RaidLayout_t   *layoutPtr,
  RF_StripeNum_t    *SUID,
  RF_StripeCount_t  *sus_per_fulltable,
  RF_StripeCount_t  *fulltable_depth,
  RF_StripeNum_t    *base_suid)
{
    RF_DeclusteredConfigInfo_t *info = (RF_DeclusteredConfigInfo_t *) layoutPtr->layoutSpecificInfo;
#if (defined(__NetBSD__) || defined(__OpenBSD__)) && defined(_KERNEL)
    /* Nothing! */
d563 1
a563 1
    char pc = layoutPtr->map->parityConfig;
d566 14
a579 13
    if (*SUID >= info->FullTableLimitSUID) {
	/* new full table size is size of last full table on disk */
	*sus_per_fulltable = info->ExtraTablesPerDisk * info->SUsPerTable;

	/* new full table depth is corresponding depth */
	*fulltable_depth = info->ExtraTablesPerDisk * info->TableDepthInPUs * layoutPtr->SUsPerPU;

	/* set up the new base offset */
	*base_suid = info->DiskOffsetOfLastFullTableInSUs;

	/* convert users array address to an offset into the last fulltable */
	*SUID -= info->FullTableLimitSUID;
    }
a580 1

d585 16
a600 15
void rf_MapSIDToPSIDDeclustered(
  RF_RaidLayout_t    *layoutPtr,
  RF_StripeNum_t      stripeID,
  RF_StripeNum_t     *psID,
  RF_ReconUnitNum_t  *which_ru)
{
    RF_DeclusteredConfigInfo_t *info;

    info = (RF_DeclusteredConfigInfo_t *) layoutPtr->layoutSpecificInfo;
    
    *psID = (stripeID / (layoutPtr->SUsPerPU * info->BlocksPerTable))
        * info->BlocksPerTable + (stripeID % info->BlocksPerTable);
    *which_ru = (stripeID % (info->BlocksPerTable * layoutPtr->SUsPerPU))
        / info->BlocksPerTable;
    RF_ASSERT( (*which_ru) < layoutPtr->SUsPerPU/layoutPtr->SUsPerRU);
a601 1

d606 41
a646 40
void rf_remap_to_spare_space(
  RF_RaidLayout_t             *layoutPtr,
  RF_DeclusteredConfigInfo_t  *info,
  RF_RowCol_t                  row,
  RF_StripeNum_t               FullTableID,
  RF_StripeNum_t               TableID,
  RF_SectorNum_t               BlockID,
  RF_StripeNum_t               base_suid,
  RF_StripeNum_t               SpareRegion,
  RF_RowCol_t                 *outCol,
  RF_StripeNum_t              *outSU)
{
    RF_StripeNum_t ftID, spareTableStartSU, TableInSpareRegion, lastSROffset, which_ft;

    /*
     * note that FullTableID and hence SpareRegion may have gotten
     * tweaked by rf_decluster_adjust_params. We detect this by
     * noticing that base_suid is not 0.
     */
    if (base_suid == 0) {
      ftID = FullTableID;
    }
    else {
      /*
       * There may be > 1.0 full tables in the last (i.e. partial)
       * spare region.  find out which of these we're in.
       */
      lastSROffset = info->NumCompleteSRs * info->SpareRegionDepthInSUs;
      which_ft = (info->DiskOffsetOfLastFullTableInSUs - lastSROffset) / (info->FullTableDepthInPUs * layoutPtr->SUsPerPU);

      /* compute the actual full table ID */
      ftID = info->DiskOffsetOfLastFullTableInSUs / (info->FullTableDepthInPUs * layoutPtr->SUsPerPU) + which_ft;
      SpareRegion = info->NumCompleteSRs;
    }
    TableInSpareRegion = (ftID * info->NumParityReps + TableID) % info->TablesPerSpareRegion;
	
    *outCol = info->SpareTable[TableInSpareRegion][BlockID].spareDisk;
    RF_ASSERT( *outCol != -1);
	
    spareTableStartSU = (SpareRegion == info->NumCompleteSRs) ?
d648 6
a653 34
	    (SpareRegion+1) * info->SpareRegionDepthInSUs - info->SpareSpaceDepthPerRegionInSUs;
    *outSU = spareTableStartSU + info->SpareTable[TableInSpareRegion][BlockID].spareBlockOffsetInSUs;
    if (*outSU >= layoutPtr->stripeUnitsPerDisk) {
	printf("rf_remap_to_spare_space: invalid remapped disk SU offset %ld\n",(long)*outSU);
    }
}

int rf_InstallSpareTable(
  RF_Raid_t    *raidPtr,
  RF_RowCol_t   frow,
  RF_RowCol_t   fcol)
{
  RF_DeclusteredConfigInfo_t *info = (RF_DeclusteredConfigInfo_t *) raidPtr->Layout.layoutSpecificInfo;
  RF_SparetWait_t *req;
  int retcode;

  RF_Malloc(req, sizeof(*req), (RF_SparetWait_t *));
  req->C                             = raidPtr->numCol;
  req->G                             = raidPtr->Layout.numDataCol + raidPtr->Layout.numParityCol;
  req->fcol                          = fcol;
  req->SUsPerPU                      = raidPtr->Layout.SUsPerPU;
  req->TablesPerSpareRegion          = info->TablesPerSpareRegion;
  req->BlocksPerTable                = info->BlocksPerTable;
  req->TableDepthInPUs               = info->TableDepthInPUs;
  req->SpareSpaceDepthPerRegionInSUs = info->SpareSpaceDepthPerRegionInSUs;

#ifndef KERNEL
  info->SpareTable = rf_ReadSpareTable(req, info->sparemap_fname);
  RF_Free(req, sizeof(*req));
  retcode = (info->SpareTable) ? 0 : 1;
#else /* !KERNEL */
  retcode = rf_GetSpareTableFromDaemon(req);
  RF_ASSERT(!retcode);                                     /* XXX -- fix this to recover gracefully -- XXX */
#endif /* !KERNEL */
d655 24
a678 1
  return(retcode);
a679 2

#ifdef KERNEL
d683 31
a713 13
int rf_SetSpareTable(raidPtr, data)
  RF_Raid_t  *raidPtr;
  void       *data;
{
  RF_DeclusteredConfigInfo_t *info = (RF_DeclusteredConfigInfo_t *) raidPtr->Layout.layoutSpecificInfo;
  RF_SpareTableEntry_t **ptrs;
  int i, retcode;

  /* what we need to copyin is a 2-d array, so first copyin the user pointers to the rows in the table */
  RF_Malloc(ptrs, info->TablesPerSpareRegion * sizeof(RF_SpareTableEntry_t *), (RF_SpareTableEntry_t **));
  retcode = copyin((caddr_t) data, (caddr_t) ptrs, info->TablesPerSpareRegion * sizeof(RF_SpareTableEntry_t *));

  if (retcode) return(retcode);
d715 2
a716 2
  /* now allocate kernel space for the row pointers */
  RF_Malloc(info->SpareTable, info->TablesPerSpareRegion * sizeof(RF_SpareTableEntry_t *), (RF_SpareTableEntry_t **));
d718 1
a718 14
  /* now allocate kernel space for each row in the table, and copy it in from user space */
  for (i=0; i<info->TablesPerSpareRegion; i++) {
    RF_Malloc(info->SpareTable[i], info->BlocksPerTable * sizeof(RF_SpareTableEntry_t), (RF_SpareTableEntry_t *));
    retcode = copyin(ptrs[i], info->SpareTable[i], info->BlocksPerTable * sizeof(RF_SpareTableEntry_t));
    if (retcode) {
      info->SpareTable = NULL;             /* blow off the memory we've allocated */
      return(retcode);
    }
  }

  /* free up the temporary array we used */
  RF_Free(ptrs, info->TablesPerSpareRegion * sizeof(RF_SpareTableEntry_t *));

  return(0);
a719 1
#endif /* KERNEL */
d721 3
a723 2
RF_ReconUnitCount_t rf_GetNumSpareRUsDeclustered(raidPtr)
  RF_Raid_t *raidPtr;
d725 1
a725 1
  RF_RaidLayout_t *layoutPtr = &raidPtr->Layout;
d727 1
a727 1
  return( ((RF_DeclusteredConfigInfo_t *) layoutPtr->layoutSpecificInfo)->TotSparePUsPerDisk );
d731 3
a733 2
void rf_FreeSpareTable(raidPtr)
  RF_Raid_t  *raidPtr;
d735 4
a738 4
  long i;
  RF_RaidLayout_t *layoutPtr = &raidPtr->Layout;
  RF_DeclusteredConfigInfo_t *info = (RF_DeclusteredConfigInfo_t *) layoutPtr->layoutSpecificInfo;
  RF_SpareTableEntry_t **table = info->SpareTable;
d740 5
a744 3
  for (i=0; i<info->TablesPerSpareRegion; i++) {RF_Free(table[i], info->BlocksPerTable * sizeof(RF_SpareTableEntry_t));}
  RF_Free(table, info->TablesPerSpareRegion * sizeof(RF_SpareTableEntry_t *));
  info->SpareTable = (RF_SpareTableEntry_t **) NULL;
@

