head	1.4;
access;
symbols
	OPENBSD_5_1_BASE:1.3
	OPENBSD_5_1:1.3.0.38
	OPENBSD_5_0:1.3.0.36
	OPENBSD_5_0_BASE:1.3
	OPENBSD_4_9:1.3.0.34
	OPENBSD_4_9_BASE:1.3
	OPENBSD_4_8:1.3.0.32
	OPENBSD_4_8_BASE:1.3
	OPENBSD_4_7:1.3.0.28
	OPENBSD_4_7_BASE:1.3
	OPENBSD_4_6:1.3.0.30
	OPENBSD_4_6_BASE:1.3
	OPENBSD_4_5:1.3.0.26
	OPENBSD_4_5_BASE:1.3
	OPENBSD_4_4:1.3.0.24
	OPENBSD_4_4_BASE:1.3
	OPENBSD_4_3:1.3.0.22
	OPENBSD_4_3_BASE:1.3
	OPENBSD_4_2:1.3.0.20
	OPENBSD_4_2_BASE:1.3
	OPENBSD_4_1:1.3.0.18
	OPENBSD_4_1_BASE:1.3
	OPENBSD_4_0:1.3.0.16
	OPENBSD_4_0_BASE:1.3
	OPENBSD_3_9:1.3.0.14
	OPENBSD_3_9_BASE:1.3
	OPENBSD_3_8:1.3.0.12
	OPENBSD_3_8_BASE:1.3
	OPENBSD_3_7:1.3.0.10
	OPENBSD_3_7_BASE:1.3
	OPENBSD_3_6:1.3.0.8
	OPENBSD_3_6_BASE:1.3
	SMP_SYNC_A:1.3
	SMP_SYNC_B:1.3
	OPENBSD_3_5:1.3.0.6
	OPENBSD_3_5_BASE:1.3
	OPENBSD_3_4:1.3.0.4
	OPENBSD_3_4_BASE:1.3
	UBC_SYNC_A:1.3
	OPENBSD_3_3:1.3.0.2
	OPENBSD_3_3_BASE:1.3
	OPENBSD_3_2:1.2.0.20
	OPENBSD_3_2_BASE:1.2
	OPENBSD_3_1:1.2.0.18
	OPENBSD_3_1_BASE:1.2
	UBC_SYNC_B:1.2
	UBC:1.2.0.16
	UBC_BASE:1.2
	OPENBSD_3_0:1.2.0.14
	OPENBSD_3_0_BASE:1.2
	OPENBSD_2_9_BASE:1.2
	OPENBSD_2_9:1.2.0.12
	OPENBSD_2_8:1.2.0.10
	OPENBSD_2_8_BASE:1.2
	OPENBSD_2_7:1.2.0.8
	OPENBSD_2_7_BASE:1.2
	SMP:1.2.0.6
	SMP_BASE:1.2
	kame_19991208:1.2
	OPENBSD_2_6:1.2.0.4
	OPENBSD_2_6_BASE:1.2
	OPENBSD_2_5:1.2.0.2
	OPENBSD_2_5_BASE:1.2;
locks; strict;
comment	@ * @;


1.4
date	2012.04.06.15.53.59;	author jsing;	state dead;
branches;
next	1.3;

1.3
date	2002.12.16.07.01.05;	author tdeval;	state Exp;
branches;
next	1.2;

1.2
date	99.02.16.00.03.23;	author niklas;	state Exp;
branches
	1.2.6.1
	1.2.16.1;
next	1.1;

1.1
date	99.01.11.14.29.47;	author niklas;	state Exp;
branches;
next	;

1.2.6.1
date	2003.03.28.00.38.29;	author niklas;	state Exp;
branches;
next	;

1.2.16.1
date	2003.05.19.22.21.53;	author tedu;	state Exp;
branches;
next	;


desc
@@


1.4
log
@Put raidframe in the attic.
@
text
@/*	$OpenBSD: rf_reconutil.c,v 1.3 2002/12/16 07:01:05 tdeval Exp $	*/
/*	$NetBSD: rf_reconutil.c,v 1.3 1999/02/05 00:06:17 oster Exp $	*/

/*
 * Copyright (c) 1995 Carnegie-Mellon University.
 * All rights reserved.
 *
 * Author: Mark Holland
 *
 * Permission to use, copy, modify and distribute this software and
 * its documentation is hereby granted, provided that both the copyright
 * notice and this permission notice appear in all copies of the
 * software, derivative works or modified versions, and any portions
 * thereof, and that both notices appear in supporting documentation.
 *
 * CARNEGIE MELLON ALLOWS FREE USE OF THIS SOFTWARE IN ITS "AS IS"
 * CONDITION.  CARNEGIE MELLON DISCLAIMS ANY LIABILITY OF ANY KIND
 * FOR ANY DAMAGES WHATSOEVER RESULTING FROM THE USE OF THIS SOFTWARE.
 *
 * Carnegie Mellon requests users of this software to return to
 *
 *  Software Distribution Coordinator  or  Software.Distribution@@CS.CMU.EDU
 *  School of Computer Science
 *  Carnegie Mellon University
 *  Pittsburgh PA 15213-3890
 *
 * any improvements or extensions that they make and grant Carnegie the
 * rights to redistribute these changes.
 */

/**********************************************
 * rf_reconutil.c -- Reconstruction utilities.
 **********************************************/

#include "rf_types.h"
#include "rf_raid.h"
#include "rf_desc.h"
#include "rf_reconutil.h"
#include "rf_reconbuffer.h"
#include "rf_general.h"
#include "rf_decluster.h"
#include "rf_raid5_rotatedspare.h"
#include "rf_interdecluster.h"
#include "rf_chaindecluster.h"


/*********************************************************************
 * Allocates/frees the reconstruction control information structures.
 *********************************************************************/
RF_ReconCtrl_t *
rf_MakeReconControl(
    RF_RaidReconDesc_t	*reconDesc,
    RF_RowCol_t		 frow,	/* Failed row and column. */
    RF_RowCol_t		 fcol,
    RF_RowCol_t		 srow,	/* Identifies which spare we're using. */
    RF_RowCol_t		 scol
)
{
	RF_Raid_t *raidPtr = reconDesc->raidPtr;
	RF_RaidLayout_t *layoutPtr = &raidPtr->Layout;
	RF_ReconUnitCount_t RUsPerPU = layoutPtr->SUsPerPU /
	    layoutPtr->SUsPerRU;
	RF_ReconUnitCount_t numSpareRUs;
	RF_ReconCtrl_t *reconCtrlPtr;
	RF_ReconBuffer_t *rbuf;
	RF_LayoutSW_t *lp;
	int retcode, rc;
	RF_RowCol_t i;

	lp = raidPtr->Layout.map;

	/*
	 * Make and zero the global reconstruction structure and the per-disk
	 * structure.
	 */
	RF_Calloc(reconCtrlPtr, 1, sizeof(RF_ReconCtrl_t), (RF_ReconCtrl_t *));
	/* This zeros it. */
	RF_Calloc(reconCtrlPtr->perDiskInfo, raidPtr->numCol,
	    sizeof(RF_PerDiskReconCtrl_t), (RF_PerDiskReconCtrl_t *));
	reconCtrlPtr->reconDesc = reconDesc;
	reconCtrlPtr->fcol = fcol;
	reconCtrlPtr->spareRow = srow;
	reconCtrlPtr->spareCol = scol;
	reconCtrlPtr->lastPSID = layoutPtr->numStripe / layoutPtr->SUsPerPU;
	reconCtrlPtr->percentComplete = 0;

	/* Initialize each per-disk recon information structure. */
	for (i = 0; i < raidPtr->numCol; i++) {
		reconCtrlPtr->perDiskInfo[i].reconCtrl = reconCtrlPtr;
		reconCtrlPtr->perDiskInfo[i].row = frow;
		reconCtrlPtr->perDiskInfo[i].col = i;
		/* Make it appear as if we just finished an RU. */
		reconCtrlPtr->perDiskInfo[i].curPSID = -1;
		reconCtrlPtr->perDiskInfo[i].ru_count = RUsPerPU - 1;
	}

	/*
	 * Get the number of spare units per disk and the sparemap in case
	 * spare is distributed.
	 */

	if (lp->GetNumSpareRUs) {
		numSpareRUs = lp->GetNumSpareRUs(raidPtr);
	} else {
		numSpareRUs = 0;
	}

	/*
	 * Not all distributed sparing archs need dynamic mappings.
	 */
	if (lp->InstallSpareTable) {
		retcode = rf_InstallSpareTable(raidPtr, frow, fcol);
		if (retcode) {
			RF_PANIC();	/* XXX Fix this. */
		}
	}
	/* Make the reconstruction map. */
	reconCtrlPtr->reconMap = rf_MakeReconMap(raidPtr,
	    (int) (layoutPtr->SUsPerRU * layoutPtr->sectorsPerStripeUnit),
	    raidPtr->sectorsPerDisk, numSpareRUs);

	/* Make the per-disk reconstruction buffers. */
	for (i = 0; i < raidPtr->numCol; i++) {
		reconCtrlPtr->perDiskInfo[i].rbuf = (i == fcol) ? NULL :
		    rf_MakeReconBuffer(raidPtr, frow, i,
		     RF_RBUF_TYPE_EXCLUSIVE);
	}

	/* Initialize the event queue. */
	rc = rf_mutex_init(&reconCtrlPtr->eq_mutex);
	if (rc) {
		/* XXX Deallocate, cleanup. */
		RF_ERRORMSG3("Unable to init mutex file %s line %d rc=%d.\n",
		    __FILE__, __LINE__, rc);
		return (NULL);
	}
	rc = rf_cond_init(&reconCtrlPtr->eq_cond);
	if (rc) {
		/* XXX Deallocate, cleanup. */
		RF_ERRORMSG3("Unable to init cond file %s line %d rc=%d.\n",
		    __FILE__, __LINE__, rc);
		return (NULL);
	}
	reconCtrlPtr->eventQueue = NULL;
	reconCtrlPtr->eq_count = 0;

	/* Make the floating recon buffers and append them to the free list. */
	rc = rf_mutex_init(&reconCtrlPtr->rb_mutex);
	if (rc) {
		/* XXX Deallocate, cleanup. */
		RF_ERRORMSG3("Unable to init mutex file %s line %d rc=%d.\n",
		    __FILE__, __LINE__, rc);
		return (NULL);
	}
	reconCtrlPtr->fullBufferList = NULL;
	reconCtrlPtr->priorityList = NULL;
	reconCtrlPtr->floatingRbufs = NULL;
	reconCtrlPtr->committedRbufs = NULL;
	for (i = 0; i < raidPtr->numFloatingReconBufs; i++) {
		rbuf = rf_MakeReconBuffer(raidPtr, frow, fcol,
		    RF_RBUF_TYPE_FLOATING);
		rbuf->next = reconCtrlPtr->floatingRbufs;
		reconCtrlPtr->floatingRbufs = rbuf;
	}

	/* Create the parity stripe status table. */
	reconCtrlPtr->pssTable = rf_MakeParityStripeStatusTable(raidPtr);

	/* Set the initial min head sep counter val. */
	reconCtrlPtr->minHeadSepCounter = 0;

	return (reconCtrlPtr);
}

void
rf_FreeReconControl(RF_Raid_t *raidPtr, RF_RowCol_t row)
{
	RF_ReconCtrl_t *reconCtrlPtr = raidPtr->reconControl[row];
	RF_ReconBuffer_t *t;
	RF_ReconUnitNum_t i;

	RF_ASSERT(reconCtrlPtr);
	for (i = 0; i < raidPtr->numCol; i++)
		if (reconCtrlPtr->perDiskInfo[i].rbuf)
			rf_FreeReconBuffer(reconCtrlPtr->perDiskInfo[i].rbuf);
	for (i = 0; i < raidPtr->numFloatingReconBufs; i++) {
		t = reconCtrlPtr->floatingRbufs;
		RF_ASSERT(t);
		reconCtrlPtr->floatingRbufs = t->next;
		rf_FreeReconBuffer(t);
	}
	rf_mutex_destroy(&reconCtrlPtr->rb_mutex);
	rf_mutex_destroy(&reconCtrlPtr->eq_mutex);
	rf_cond_destroy(&reconCtrlPtr->eq_cond);
	rf_FreeReconMap(reconCtrlPtr->reconMap);
	rf_FreeParityStripeStatusTable(raidPtr, reconCtrlPtr->pssTable);
	RF_Free(reconCtrlPtr->perDiskInfo, raidPtr->numCol *
	    sizeof(RF_PerDiskReconCtrl_t));
	RF_Free(reconCtrlPtr, sizeof(*reconCtrlPtr));
}


/*****************************************************************************
 * Computes the default head separation limit.
 *****************************************************************************/
RF_HeadSepLimit_t
rf_GetDefaultHeadSepLimit(RF_Raid_t *raidPtr)
{
	RF_HeadSepLimit_t hsl;
	RF_LayoutSW_t *lp;

	lp = raidPtr->Layout.map;
	if (lp->GetDefaultHeadSepLimit == NULL)
		return (-1);
	hsl = lp->GetDefaultHeadSepLimit(raidPtr);
	return (hsl);
}


/*****************************************************************************
 * Computes the default number of floating recon buffers.
 *****************************************************************************/
int
rf_GetDefaultNumFloatingReconBuffers(RF_Raid_t *raidPtr)
{
	RF_LayoutSW_t *lp;
	int nrb;

	lp = raidPtr->Layout.map;
	if (lp->GetDefaultNumFloatingReconBuffers == NULL)
		return (3 * raidPtr->numCol);
	nrb = lp->GetDefaultNumFloatingReconBuffers(raidPtr);
	return (nrb);
}


/*****************************************************************************
 * Creates and initializes a reconstruction buffer.
 *****************************************************************************/
RF_ReconBuffer_t *
rf_MakeReconBuffer(RF_Raid_t *raidPtr, RF_RowCol_t row, RF_RowCol_t col,
    RF_RbufType_t type)
{
	RF_RaidLayout_t *layoutPtr = &raidPtr->Layout;
	RF_ReconBuffer_t *t;
	u_int recon_buffer_size = rf_RaidAddressToByte(raidPtr,
	    layoutPtr->SUsPerRU * layoutPtr->sectorsPerStripeUnit);

	RF_Malloc(t, sizeof(RF_ReconBuffer_t), (RF_ReconBuffer_t *));
	RF_Malloc(t->buffer, recon_buffer_size, (caddr_t));
	RF_Malloc(t->arrived, raidPtr->numCol * sizeof(char), (char *));
	t->raidPtr = raidPtr;
	t->row = row;
	t->col = col;
	t->priority = RF_IO_RECON_PRIORITY;
	t->type = type;
	t->pssPtr = NULL;
	t->next = NULL;
	return (t);
}


/*****************************************************************************
 * Frees a reconstruction buffer.
 *****************************************************************************/
void
rf_FreeReconBuffer(RF_ReconBuffer_t *rbuf)
{
	RF_Raid_t *raidPtr = rbuf->raidPtr;
	u_int recon_buffer_size = rf_RaidAddressToByte(raidPtr,
	    raidPtr->Layout.SUsPerRU * raidPtr->Layout.sectorsPerStripeUnit);

	RF_Free(rbuf->arrived, raidPtr->numCol * sizeof(char));
	RF_Free(rbuf->buffer, recon_buffer_size);
	RF_Free(rbuf, sizeof(*rbuf));
}


/*****************************************************************************
 * Debug only:  Sanity check the number of floating recon bufs in use.
 *****************************************************************************/
void
rf_CheckFloatingRbufCount(RF_Raid_t *raidPtr, int dolock)
{
	RF_ReconParityStripeStatus_t *p;
	RF_PSStatusHeader_t *pssTable;
	RF_ReconBuffer_t *rbuf;
	int i, j, sum = 0;
	RF_RowCol_t frow = 0;

	for (i = 0; i < raidPtr->numRow; i++)
		if (raidPtr->reconControl[i]) {
			frow = i;
			break;
		}
	RF_ASSERT(frow >= 0);

	if (dolock)
		RF_LOCK_MUTEX(raidPtr->reconControl[frow]->rb_mutex);
	pssTable = raidPtr->reconControl[frow]->pssTable;

	for (i = 0; i < raidPtr->pssTableSize; i++) {
		RF_LOCK_MUTEX(pssTable[i].mutex);
		for (p = pssTable[i].chain; p; p = p->next) {
			rbuf = (RF_ReconBuffer_t *) p->rbuf;
			if (rbuf && rbuf->type == RF_RBUF_TYPE_FLOATING)
				sum++;

			rbuf = (RF_ReconBuffer_t *) p->writeRbuf;
			if (rbuf && rbuf->type == RF_RBUF_TYPE_FLOATING)
				sum++;

			for (j = 0; j < p->xorBufCount; j++) {
				rbuf = (RF_ReconBuffer_t *) p->rbufsForXor[j];
				RF_ASSERT(rbuf);
				if (rbuf->type == RF_RBUF_TYPE_FLOATING)
					sum++;
			}
		}
		RF_UNLOCK_MUTEX(pssTable[i].mutex);
	}

	for (rbuf = raidPtr->reconControl[frow]->floatingRbufs; rbuf;
	     rbuf = rbuf->next) {
		if (rbuf->type == RF_RBUF_TYPE_FLOATING)
			sum++;
	}
	for (rbuf = raidPtr->reconControl[frow]->committedRbufs; rbuf;
	     rbuf = rbuf->next) {
		if (rbuf->type == RF_RBUF_TYPE_FLOATING)
			sum++;
	}
	for (rbuf = raidPtr->reconControl[frow]->fullBufferList; rbuf;
	     rbuf = rbuf->next) {
		if (rbuf->type == RF_RBUF_TYPE_FLOATING)
			sum++;
	}
	for (rbuf = raidPtr->reconControl[frow]->priorityList; rbuf;
	     rbuf = rbuf->next) {
		if (rbuf->type == RF_RBUF_TYPE_FLOATING)
			sum++;
	}

	RF_ASSERT(sum == raidPtr->numFloatingReconBufs);

	if (dolock)
		RF_UNLOCK_MUTEX(raidPtr->reconControl[frow]->rb_mutex);
}
@


1.3
log
@Major KNF.  Incentive from Tedu
@
text
@d1 1
a1 1
/*	$OpenBSD: rf_reconutil.c,v 1.2 1999/02/16 00:03:23 niklas Exp $	*/
@


1.2
log
@Merge from NetBSD, mostly indentation
@
text
@d1 1
a1 1
/*	$OpenBSD: rf_reconutil.c,v 1.1 1999/01/11 14:29:47 niklas Exp $	*/
d3 1
d31 3
a33 3
/********************************************
 * rf_reconutil.c -- reconstruction utilities
 ********************************************/
d46 4
a49 3
/*******************************************************************
 * allocates/frees the reconstruction control information structures
 *******************************************************************/
d51 7
a57 6
rf_MakeReconControl(reconDesc, frow, fcol, srow, scol)
	RF_RaidReconDesc_t *reconDesc;
	RF_RowCol_t frow;	/* failed row and column */
	RF_RowCol_t fcol;
	RF_RowCol_t srow;	/* identifies which spare we're using */
	RF_RowCol_t scol;
d61 2
a62 1
	RF_ReconUnitCount_t RUsPerPU = layoutPtr->SUsPerPU / layoutPtr->SUsPerRU;
d67 1
a67 1
	int     retcode, rc;
d72 4
a75 2
	/* make and zero the global reconstruction structure and the per-disk
	 * structure */
d77 3
a79 1
	RF_Calloc(reconCtrlPtr->perDiskInfo, raidPtr->numCol, sizeof(RF_PerDiskReconCtrl_t), (RF_PerDiskReconCtrl_t *));	/* this zeros it */
d87 1
a87 1
	/* initialize each per-disk recon information structure */
d92 2
a93 3
		reconCtrlPtr->perDiskInfo[i].curPSID = -1;	/* make it appear as if
								 * we just finished an
								 * RU */
d97 4
a100 2
	/* Get the number of spare units per disk and the sparemap in case
	 * spare is distributed  */
d109 2
a110 2
         * Not all distributed sparing archs need dynamic mappings
         */
d114 1
a114 1
			RF_PANIC();	/* XXX fix this */
d117 3
a119 2
	/* make the reconstruction map */
	reconCtrlPtr->reconMap = rf_MakeReconMap(raidPtr, (int) (layoutPtr->SUsPerRU * layoutPtr->sectorsPerStripeUnit),
d122 1
a122 1
	/* make the per-disk reconstruction buffers */
d124 3
a126 1
		reconCtrlPtr->perDiskInfo[i].rbuf = (i == fcol) ? NULL : rf_MakeReconBuffer(raidPtr, frow, i, RF_RBUF_TYPE_EXCLUSIVE);
d129 1
a129 1
	/* initialize the event queue */
d132 3
a134 3
		/* XXX deallocate, cleanup */
		RF_ERRORMSG3("Unable to init mutex file %s line %d rc=%d\n", __FILE__,
		    __LINE__, rc);
d139 3
a141 3
		/* XXX deallocate, cleanup */
		RF_ERRORMSG3("Unable to init cond file %s line %d rc=%d\n", __FILE__,
		    __LINE__, rc);
d147 1
a147 1
	/* make the floating recon buffers and append them to the free list */
d150 3
a152 3
		/* XXX deallocate, cleanup */
		RF_ERRORMSG3("Unable to init mutex file %s line %d rc=%d\n", __FILE__,
		    __LINE__, rc);
d160 2
a161 1
		rbuf = rf_MakeReconBuffer(raidPtr, frow, fcol, RF_RBUF_TYPE_FLOATING);
d166 1
a166 1
	/* create the parity stripe status table */
d169 1
a169 1
	/* set the initial min head sep counter val */
d175 2
a176 4
void 
rf_FreeReconControl(raidPtr, row)
	RF_Raid_t *raidPtr;
	RF_RowCol_t row;
d197 2
a198 1
	RF_Free(reconCtrlPtr->perDiskInfo, raidPtr->numCol * sizeof(RF_PerDiskReconCtrl_t));
d203 2
a204 2
/******************************************************************************
 * computes the default head separation limit
d206 2
a207 3
RF_HeadSepLimit_t 
rf_GetDefaultHeadSepLimit(raidPtr)
	RF_Raid_t *raidPtr;
d220 2
a221 2
/******************************************************************************
 * computes the default number of floating recon buffers
d223 2
a224 3
int 
rf_GetDefaultNumFloatingReconBuffers(raidPtr)
	RF_Raid_t *raidPtr;
d227 1
a227 1
	int     nrb;
d237 2
a238 2
/******************************************************************************
 * creates and initializes a reconstruction buffer
d241 1
a241 4
rf_MakeReconBuffer(
    RF_Raid_t * raidPtr,
    RF_RowCol_t row,
    RF_RowCol_t col,
d246 2
a247 1
	u_int   recon_buffer_size = rf_RaidAddressToByte(raidPtr, layoutPtr->SUsPerRU * layoutPtr->sectorsPerStripeUnit);
d261 4
a264 2
/******************************************************************************
 * frees a reconstruction buffer
d266 2
a267 3
void 
rf_FreeReconBuffer(rbuf)
	RF_ReconBuffer_t *rbuf;
d270 2
a271 1
	u_int   recon_buffer_size = rf_RaidAddressToByte(raidPtr, raidPtr->Layout.SUsPerRU * raidPtr->Layout.sectorsPerStripeUnit);
d279 2
a280 2
/******************************************************************************
 * debug only:  sanity check the number of floating recon bufs in use
d282 2
a283 4
void 
rf_CheckFloatingRbufCount(raidPtr, dolock)
	RF_Raid_t *raidPtr;
	int     dolock;
d288 1
a288 1
	int     i, j, sum = 0;
d323 2
a324 1
	for (rbuf = raidPtr->reconControl[frow]->floatingRbufs; rbuf; rbuf = rbuf->next) {
d328 2
a329 1
	for (rbuf = raidPtr->reconControl[frow]->committedRbufs; rbuf; rbuf = rbuf->next) {
d333 2
a334 1
	for (rbuf = raidPtr->reconControl[frow]->fullBufferList; rbuf; rbuf = rbuf->next) {
d338 2
a339 1
	for (rbuf = raidPtr->reconControl[frow]->priorityList; rbuf; rbuf = rbuf->next) {
@


1.2.16.1
log
@sync
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
a2 1

d30 3
a32 3
/**********************************************
 * rf_reconutil.c -- Reconstruction utilities.
 **********************************************/
d45 3
a47 4

/*********************************************************************
 * Allocates/frees the reconstruction control information structures.
 *********************************************************************/
d49 6
a54 7
rf_MakeReconControl(
    RF_RaidReconDesc_t	*reconDesc,
    RF_RowCol_t		 frow,	/* Failed row and column. */
    RF_RowCol_t		 fcol,
    RF_RowCol_t		 srow,	/* Identifies which spare we're using. */
    RF_RowCol_t		 scol
)
d58 1
a58 2
	RF_ReconUnitCount_t RUsPerPU = layoutPtr->SUsPerPU /
	    layoutPtr->SUsPerRU;
d63 1
a63 1
	int retcode, rc;
d68 2
a69 4
	/*
	 * Make and zero the global reconstruction structure and the per-disk
	 * structure.
	 */
d71 1
a71 3
	/* This zeros it. */
	RF_Calloc(reconCtrlPtr->perDiskInfo, raidPtr->numCol,
	    sizeof(RF_PerDiskReconCtrl_t), (RF_PerDiskReconCtrl_t *));
d79 1
a79 1
	/* Initialize each per-disk recon information structure. */
d84 3
a86 2
		/* Make it appear as if we just finished an RU. */
		reconCtrlPtr->perDiskInfo[i].curPSID = -1;
d90 2
a91 4
	/*
	 * Get the number of spare units per disk and the sparemap in case
	 * spare is distributed.
	 */
d100 2
a101 2
	 * Not all distributed sparing archs need dynamic mappings.
	 */
d105 1
a105 1
			RF_PANIC();	/* XXX Fix this. */
d108 2
a109 3
	/* Make the reconstruction map. */
	reconCtrlPtr->reconMap = rf_MakeReconMap(raidPtr,
	    (int) (layoutPtr->SUsPerRU * layoutPtr->sectorsPerStripeUnit),
d112 1
a112 1
	/* Make the per-disk reconstruction buffers. */
d114 1
a114 3
		reconCtrlPtr->perDiskInfo[i].rbuf = (i == fcol) ? NULL :
		    rf_MakeReconBuffer(raidPtr, frow, i,
		     RF_RBUF_TYPE_EXCLUSIVE);
d117 1
a117 1
	/* Initialize the event queue. */
d120 3
a122 3
		/* XXX Deallocate, cleanup. */
		RF_ERRORMSG3("Unable to init mutex file %s line %d rc=%d.\n",
		    __FILE__, __LINE__, rc);
d127 3
a129 3
		/* XXX Deallocate, cleanup. */
		RF_ERRORMSG3("Unable to init cond file %s line %d rc=%d.\n",
		    __FILE__, __LINE__, rc);
d135 1
a135 1
	/* Make the floating recon buffers and append them to the free list. */
d138 3
a140 3
		/* XXX Deallocate, cleanup. */
		RF_ERRORMSG3("Unable to init mutex file %s line %d rc=%d.\n",
		    __FILE__, __LINE__, rc);
d148 1
a148 2
		rbuf = rf_MakeReconBuffer(raidPtr, frow, fcol,
		    RF_RBUF_TYPE_FLOATING);
d153 1
a153 1
	/* Create the parity stripe status table. */
d156 1
a156 1
	/* Set the initial min head sep counter val. */
d162 4
a165 2
void
rf_FreeReconControl(RF_Raid_t *raidPtr, RF_RowCol_t row)
d186 1
a186 2
	RF_Free(reconCtrlPtr->perDiskInfo, raidPtr->numCol *
	    sizeof(RF_PerDiskReconCtrl_t));
d191 2
a192 2
/*****************************************************************************
 * Computes the default head separation limit.
d194 3
a196 2
RF_HeadSepLimit_t
rf_GetDefaultHeadSepLimit(RF_Raid_t *raidPtr)
d209 2
a210 2
/*****************************************************************************
 * Computes the default number of floating recon buffers.
d212 3
a214 2
int
rf_GetDefaultNumFloatingReconBuffers(RF_Raid_t *raidPtr)
d217 1
a217 1
	int nrb;
d227 2
a228 2
/*****************************************************************************
 * Creates and initializes a reconstruction buffer.
d231 4
a234 1
rf_MakeReconBuffer(RF_Raid_t *raidPtr, RF_RowCol_t row, RF_RowCol_t col,
d239 1
a239 2
	u_int recon_buffer_size = rf_RaidAddressToByte(raidPtr,
	    layoutPtr->SUsPerRU * layoutPtr->sectorsPerStripeUnit);
d253 2
a254 4


/*****************************************************************************
 * Frees a reconstruction buffer.
d256 3
a258 2
void
rf_FreeReconBuffer(RF_ReconBuffer_t *rbuf)
d261 1
a261 2
	u_int recon_buffer_size = rf_RaidAddressToByte(raidPtr,
	    raidPtr->Layout.SUsPerRU * raidPtr->Layout.sectorsPerStripeUnit);
d269 2
a270 2
/*****************************************************************************
 * Debug only:  Sanity check the number of floating recon bufs in use.
d272 4
a275 2
void
rf_CheckFloatingRbufCount(RF_Raid_t *raidPtr, int dolock)
d280 1
a280 1
	int i, j, sum = 0;
d315 1
a315 2
	for (rbuf = raidPtr->reconControl[frow]->floatingRbufs; rbuf;
	     rbuf = rbuf->next) {
d319 1
a319 2
	for (rbuf = raidPtr->reconControl[frow]->committedRbufs; rbuf;
	     rbuf = rbuf->next) {
d323 1
a323 2
	for (rbuf = raidPtr->reconControl[frow]->fullBufferList; rbuf;
	     rbuf = rbuf->next) {
d327 1
a327 2
	for (rbuf = raidPtr->reconControl[frow]->priorityList; rbuf;
	     rbuf = rbuf->next) {
@


1.2.6.1
log
@Sync the SMP branch with 3.3
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
a2 1

d30 3
a32 3
/**********************************************
 * rf_reconutil.c -- Reconstruction utilities.
 **********************************************/
d45 3
a47 4

/*********************************************************************
 * Allocates/frees the reconstruction control information structures.
 *********************************************************************/
d49 6
a54 7
rf_MakeReconControl(
    RF_RaidReconDesc_t	*reconDesc,
    RF_RowCol_t		 frow,	/* Failed row and column. */
    RF_RowCol_t		 fcol,
    RF_RowCol_t		 srow,	/* Identifies which spare we're using. */
    RF_RowCol_t		 scol
)
d58 1
a58 2
	RF_ReconUnitCount_t RUsPerPU = layoutPtr->SUsPerPU /
	    layoutPtr->SUsPerRU;
d63 1
a63 1
	int retcode, rc;
d68 2
a69 4
	/*
	 * Make and zero the global reconstruction structure and the per-disk
	 * structure.
	 */
d71 1
a71 3
	/* This zeros it. */
	RF_Calloc(reconCtrlPtr->perDiskInfo, raidPtr->numCol,
	    sizeof(RF_PerDiskReconCtrl_t), (RF_PerDiskReconCtrl_t *));
d79 1
a79 1
	/* Initialize each per-disk recon information structure. */
d84 3
a86 2
		/* Make it appear as if we just finished an RU. */
		reconCtrlPtr->perDiskInfo[i].curPSID = -1;
d90 2
a91 4
	/*
	 * Get the number of spare units per disk and the sparemap in case
	 * spare is distributed.
	 */
d100 2
a101 2
	 * Not all distributed sparing archs need dynamic mappings.
	 */
d105 1
a105 1
			RF_PANIC();	/* XXX Fix this. */
d108 2
a109 3
	/* Make the reconstruction map. */
	reconCtrlPtr->reconMap = rf_MakeReconMap(raidPtr,
	    (int) (layoutPtr->SUsPerRU * layoutPtr->sectorsPerStripeUnit),
d112 1
a112 1
	/* Make the per-disk reconstruction buffers. */
d114 1
a114 3
		reconCtrlPtr->perDiskInfo[i].rbuf = (i == fcol) ? NULL :
		    rf_MakeReconBuffer(raidPtr, frow, i,
		     RF_RBUF_TYPE_EXCLUSIVE);
d117 1
a117 1
	/* Initialize the event queue. */
d120 3
a122 3
		/* XXX Deallocate, cleanup. */
		RF_ERRORMSG3("Unable to init mutex file %s line %d rc=%d.\n",
		    __FILE__, __LINE__, rc);
d127 3
a129 3
		/* XXX Deallocate, cleanup. */
		RF_ERRORMSG3("Unable to init cond file %s line %d rc=%d.\n",
		    __FILE__, __LINE__, rc);
d135 1
a135 1
	/* Make the floating recon buffers and append them to the free list. */
d138 3
a140 3
		/* XXX Deallocate, cleanup. */
		RF_ERRORMSG3("Unable to init mutex file %s line %d rc=%d.\n",
		    __FILE__, __LINE__, rc);
d148 1
a148 2
		rbuf = rf_MakeReconBuffer(raidPtr, frow, fcol,
		    RF_RBUF_TYPE_FLOATING);
d153 1
a153 1
	/* Create the parity stripe status table. */
d156 1
a156 1
	/* Set the initial min head sep counter val. */
d162 4
a165 2
void
rf_FreeReconControl(RF_Raid_t *raidPtr, RF_RowCol_t row)
d186 1
a186 2
	RF_Free(reconCtrlPtr->perDiskInfo, raidPtr->numCol *
	    sizeof(RF_PerDiskReconCtrl_t));
d191 2
a192 2
/*****************************************************************************
 * Computes the default head separation limit.
d194 3
a196 2
RF_HeadSepLimit_t
rf_GetDefaultHeadSepLimit(RF_Raid_t *raidPtr)
d209 2
a210 2
/*****************************************************************************
 * Computes the default number of floating recon buffers.
d212 3
a214 2
int
rf_GetDefaultNumFloatingReconBuffers(RF_Raid_t *raidPtr)
d217 1
a217 1
	int nrb;
d227 2
a228 2
/*****************************************************************************
 * Creates and initializes a reconstruction buffer.
d231 4
a234 1
rf_MakeReconBuffer(RF_Raid_t *raidPtr, RF_RowCol_t row, RF_RowCol_t col,
d239 1
a239 2
	u_int recon_buffer_size = rf_RaidAddressToByte(raidPtr,
	    layoutPtr->SUsPerRU * layoutPtr->sectorsPerStripeUnit);
d253 2
a254 4


/*****************************************************************************
 * Frees a reconstruction buffer.
d256 3
a258 2
void
rf_FreeReconBuffer(RF_ReconBuffer_t *rbuf)
d261 1
a261 2
	u_int recon_buffer_size = rf_RaidAddressToByte(raidPtr,
	    raidPtr->Layout.SUsPerRU * raidPtr->Layout.sectorsPerStripeUnit);
d269 2
a270 2
/*****************************************************************************
 * Debug only:  Sanity check the number of floating recon bufs in use.
d272 4
a275 2
void
rf_CheckFloatingRbufCount(RF_Raid_t *raidPtr, int dolock)
d280 1
a280 1
	int i, j, sum = 0;
d315 1
a315 2
	for (rbuf = raidPtr->reconControl[frow]->floatingRbufs; rbuf;
	     rbuf = rbuf->next) {
d319 1
a319 2
	for (rbuf = raidPtr->reconControl[frow]->committedRbufs; rbuf;
	     rbuf = rbuf->next) {
d323 1
a323 2
	for (rbuf = raidPtr->reconControl[frow]->fullBufferList; rbuf;
	     rbuf = rbuf->next) {
d327 1
a327 2
	for (rbuf = raidPtr->reconControl[frow]->priorityList; rbuf;
	     rbuf = rbuf->next) {
@


1.1
log
@Import of CMU's RAIDframe via NetBSD.
@
text
@d1 2
a2 2
/*	$OpenBSD: rf_reconutil.c,v 1.1 1998/11/13 04:20:34 oster Exp $	*/
/*	$NetBSD: rf_reconutil.c,v 1.1 1998/11/13 04:20:34 oster Exp $	*/
a33 83
/* :  
 * Log: rf_reconutil.c,v 
 * Revision 1.32  1996/07/29 14:05:12  jimz
 * fix numPUs/numRUs confusion (everything is now numRUs)
 * clean up some commenting, return values
 *
 * Revision 1.31  1996/07/15  05:40:41  jimz
 * some recon datastructure cleanup
 * better handling of multiple failures
 * added undocumented double-recon test
 *
 * Revision 1.30  1996/07/13  00:00:59  jimz
 * sanitized generalized reconstruction architecture
 * cleaned up head sep, rbuf problems
 *
 * Revision 1.29  1996/06/19  17:53:48  jimz
 * move GetNumSparePUs, InstallSpareTable ops into layout switch
 *
 * Revision 1.28  1996/06/07  21:33:04  jimz
 * begin using consistent types for sector numbers,
 * stripe numbers, row+col numbers, recon unit numbers
 *
 * Revision 1.27  1996/06/05  18:06:02  jimz
 * Major code cleanup. The Great Renaming is now done.
 * Better modularity. Better typing. Fixed a bunch of
 * synchronization bugs. Made a lot of global stuff
 * per-desc or per-array. Removed dead code.
 *
 * Revision 1.26  1996/06/03  23:28:26  jimz
 * more bugfixes
 * check in tree to sync for IPDS runs with current bugfixes
 * there still may be a problem with threads in the script test
 * getting I/Os stuck- not trivially reproducible (runs ~50 times
 * in a row without getting stuck)
 *
 * Revision 1.25  1996/06/02  17:31:48  jimz
 * Moved a lot of global stuff into array structure, where it belongs.
 * Fixed up paritylogging, pss modules in this manner. Some general
 * code cleanup. Removed lots of dead code, some dead files.
 *
 * Revision 1.24  1996/05/31  22:26:54  jimz
 * fix a lot of mapping problems, memory allocation problems
 * found some weird lock issues, fixed 'em
 * more code cleanup
 *
 * Revision 1.23  1996/05/30  23:22:16  jimz
 * bugfixes of serialization, timing problems
 * more cleanup
 *
 * Revision 1.22  1996/05/30  11:29:41  jimz
 * Numerous bug fixes. Stripe lock release code disagreed with the taking code
 * about when stripes should be locked (I made it consistent: no parity, no lock)
 * There was a lot of extra serialization of I/Os which I've removed- a lot of
 * it was to calculate values for the cache code, which is no longer with us.
 * More types, function, macro cleanup. Added code to properly quiesce the array
 * on shutdown. Made a lot of stuff array-specific which was (bogusly) general
 * before. Fixed memory allocation, freeing bugs.
 *
 * Revision 1.21  1996/05/27  18:56:37  jimz
 * more code cleanup
 * better typing
 * compiles in all 3 environments
 *
 * Revision 1.20  1996/05/23  00:33:23  jimz
 * code cleanup: move all debug decls to rf_options.c, all extern
 * debug decls to rf_options.h, all debug vars preceded by rf_
 *
 * Revision 1.19  1996/05/20  16:14:55  jimz
 * switch to rf_{mutex,cond}_{init,destroy}
 *
 * Revision 1.18  1996/05/18  19:51:34  jimz
 * major code cleanup- fix syntax, make some types consistent,
 * add prototypes, clean out dead code, et cetera
 *
 * Revision 1.17  1995/12/12  18:10:06  jimz
 * MIN -> RF_MIN, MAX -> RF_MAX, ASSERT -> RF_ASSERT
 * fix 80-column brain damage in comments
 *
 * Revision 1.16  1995/12/06  15:05:31  root
 * added copyright info
 *
 */

d48 7
a54 6
RF_ReconCtrl_t *rf_MakeReconControl(reconDesc, frow, fcol, srow, scol)
  RF_RaidReconDesc_t  *reconDesc;
  RF_RowCol_t          frow;    /* failed row and column */
  RF_RowCol_t          fcol;
  RF_RowCol_t          srow;    /* identifies which spare we're using */
  RF_RowCol_t          scol;
d56 104
a159 102
  RF_Raid_t *raidPtr = reconDesc->raidPtr;
  RF_RaidLayout_t  *layoutPtr = &raidPtr->Layout;
  RF_ReconUnitCount_t RUsPerPU = layoutPtr->SUsPerPU / layoutPtr->SUsPerRU;
  RF_ReconUnitCount_t numSpareRUs;
  RF_ReconCtrl_t *reconCtrlPtr;
  RF_ReconBuffer_t *rbuf;
  RF_LayoutSW_t *lp;
  int retcode, rc;
  RF_RowCol_t i;

  lp = raidPtr->Layout.map;

  /* make and zero the global reconstruction structure and the per-disk structure */
  RF_Calloc(reconCtrlPtr, 1, sizeof(RF_ReconCtrl_t), (RF_ReconCtrl_t *));
  RF_Calloc(reconCtrlPtr->perDiskInfo, raidPtr->numCol, sizeof(RF_PerDiskReconCtrl_t), (RF_PerDiskReconCtrl_t *));  /* this zeros it */
  reconCtrlPtr->reconDesc = reconDesc;
  reconCtrlPtr->fcol = fcol;
  reconCtrlPtr->spareRow = srow;
  reconCtrlPtr->spareCol = scol;
  reconCtrlPtr->lastPSID = layoutPtr->numStripe/layoutPtr->SUsPerPU;
  reconCtrlPtr->percentComplete = 0;
  
  /* initialize each per-disk recon information structure */
  for (i=0; i<raidPtr->numCol; i++) {
    reconCtrlPtr->perDiskInfo[i].reconCtrl = reconCtrlPtr;
    reconCtrlPtr->perDiskInfo[i].row      = frow;
    reconCtrlPtr->perDiskInfo[i].col      = i;
    reconCtrlPtr->perDiskInfo[i].curPSID  = -1;          /* make it appear as if we just finished an RU */
    reconCtrlPtr->perDiskInfo[i].ru_count = RUsPerPU-1;
  }

 /* Get the number of spare units per disk and the sparemap in case spare is distributed  */

  if (lp->GetNumSpareRUs) {
    numSpareRUs = lp->GetNumSpareRUs(raidPtr);
  }
  else {
    numSpareRUs = 0;
  }

  /*
   * Not all distributed sparing archs need dynamic mappings
   */
  if (lp->InstallSpareTable) {
    retcode = rf_InstallSpareTable(raidPtr, frow, fcol);
    if (retcode) {
      RF_PANIC(); /* XXX fix this*/
    }
  }

  /* make the reconstruction map */
  reconCtrlPtr->reconMap = rf_MakeReconMap(raidPtr, (int) (layoutPtr->SUsPerRU * layoutPtr->sectorsPerStripeUnit),
					raidPtr->sectorsPerDisk, numSpareRUs);

  /* make the per-disk reconstruction buffers */
  for (i=0; i<raidPtr->numCol; i++) {
    reconCtrlPtr->perDiskInfo[i].rbuf = (i==fcol) ? NULL : rf_MakeReconBuffer(raidPtr, frow, i, RF_RBUF_TYPE_EXCLUSIVE);
  }

  /* initialize the event queue */
  rc = rf_mutex_init(&reconCtrlPtr->eq_mutex);
  if (rc) {
    /* XXX deallocate, cleanup */
    RF_ERRORMSG3("Unable to init mutex file %s line %d rc=%d\n", __FILE__,
      __LINE__, rc);
    return(NULL);
  }
  rc = rf_cond_init(&reconCtrlPtr->eq_cond);
  if (rc) {
    /* XXX deallocate, cleanup */
    RF_ERRORMSG3("Unable to init cond file %s line %d rc=%d\n", __FILE__,
      __LINE__, rc);
    return(NULL);
  }
  reconCtrlPtr->eventQueue = NULL;
  reconCtrlPtr->eq_count = 0;

  /* make the floating recon buffers and append them to the free list */
  rc = rf_mutex_init(&reconCtrlPtr->rb_mutex);
  if (rc) {
    /* XXX deallocate, cleanup */
    RF_ERRORMSG3("Unable to init mutex file %s line %d rc=%d\n", __FILE__,
      __LINE__, rc);
    return(NULL);
  }
  reconCtrlPtr->fullBufferList= NULL;
  reconCtrlPtr->priorityList  = NULL;
  reconCtrlPtr->floatingRbufs = NULL;
  reconCtrlPtr->committedRbufs= NULL;
  for (i=0; i<raidPtr->numFloatingReconBufs; i++) {
    rbuf = rf_MakeReconBuffer(raidPtr, frow, fcol, RF_RBUF_TYPE_FLOATING);
    rbuf->next = reconCtrlPtr->floatingRbufs;
    reconCtrlPtr->floatingRbufs = rbuf;
  }

  /* create the parity stripe status table */
  reconCtrlPtr->pssTable = rf_MakeParityStripeStatusTable(raidPtr);

  /* set the initial min head sep counter val */
  reconCtrlPtr->minHeadSepCounter = 0;
  
  return(reconCtrlPtr);
d162 4
a165 3
void rf_FreeReconControl(raidPtr, row)
  RF_Raid_t    *raidPtr;
  RF_RowCol_t   row;
d167 21
a187 19
  RF_ReconCtrl_t *reconCtrlPtr = raidPtr->reconControl[row];
  RF_ReconBuffer_t *t;
  RF_ReconUnitNum_t i;
  
  RF_ASSERT(reconCtrlPtr);
  for (i=0; i<raidPtr->numCol; i++) if (reconCtrlPtr->perDiskInfo[i].rbuf) rf_FreeReconBuffer(reconCtrlPtr->perDiskInfo[i].rbuf);
  for (i=0; i<raidPtr->numFloatingReconBufs; i++) {
    t = reconCtrlPtr->floatingRbufs;
    RF_ASSERT(t);
    reconCtrlPtr->floatingRbufs = t->next;
    rf_FreeReconBuffer(t);
  }
  rf_mutex_destroy(&reconCtrlPtr->rb_mutex);
  rf_mutex_destroy(&reconCtrlPtr->eq_mutex);
  rf_cond_destroy(&reconCtrlPtr->eq_cond);
  rf_FreeReconMap(reconCtrlPtr->reconMap);
  rf_FreeParityStripeStatusTable(raidPtr, reconCtrlPtr->pssTable);
  RF_Free(reconCtrlPtr->perDiskInfo, raidPtr->numCol * sizeof(RF_PerDiskReconCtrl_t));
  RF_Free(reconCtrlPtr, sizeof(*reconCtrlPtr));
d194 3
a196 2
RF_HeadSepLimit_t rf_GetDefaultHeadSepLimit(raidPtr)
  RF_Raid_t  *raidPtr;
d198 2
a199 2
  RF_HeadSepLimit_t hsl;
  RF_LayoutSW_t *lp;
d201 5
a205 5
  lp = raidPtr->Layout.map;
  if (lp->GetDefaultHeadSepLimit == NULL)
    return(-1);
  hsl = lp->GetDefaultHeadSepLimit(raidPtr);
  return(hsl);
d212 3
a214 2
int rf_GetDefaultNumFloatingReconBuffers(raidPtr)
  RF_Raid_t  *raidPtr;
d216 2
a217 2
  RF_LayoutSW_t *lp;
  int nrb;
d219 5
a223 5
  lp = raidPtr->Layout.map;
  if (lp->GetDefaultNumFloatingReconBuffers == NULL)
    return(3 * raidPtr->numCol);
  nrb = lp->GetDefaultNumFloatingReconBuffers(raidPtr);
  return(nrb);
d230 6
a235 5
RF_ReconBuffer_t *rf_MakeReconBuffer(
  RF_Raid_t      *raidPtr,
  RF_RowCol_t     row,
  RF_RowCol_t     col,
  RF_RbufType_t   type)
d237 15
a251 14
  RF_RaidLayout_t *layoutPtr = &raidPtr->Layout;
  RF_ReconBuffer_t *t;
  u_int recon_buffer_size = rf_RaidAddressToByte(raidPtr, layoutPtr->SUsPerRU * layoutPtr->sectorsPerStripeUnit);

  RF_Malloc(t, sizeof(RF_ReconBuffer_t), (RF_ReconBuffer_t *));
  RF_Malloc(t->buffer, recon_buffer_size, (caddr_t));
  RF_Malloc(t->arrived, raidPtr->numCol * sizeof(char), (char *));
  t->raidPtr = raidPtr;
  t->row = row; t->col = col;
  t->priority = RF_IO_RECON_PRIORITY;
  t->type = type;
  t->pssPtr = NULL;
  t->next = NULL;
  return(t);
a252 1

d256 3
a258 2
void rf_FreeReconBuffer(rbuf)
  RF_ReconBuffer_t  *rbuf;
d260 6
a265 6
  RF_Raid_t *raidPtr = rbuf->raidPtr;
  u_int recon_buffer_size = rf_RaidAddressToByte(raidPtr, raidPtr->Layout.SUsPerRU * raidPtr->Layout.sectorsPerStripeUnit);
  
  RF_Free(rbuf->arrived, raidPtr->numCol * sizeof(char));
  RF_Free(rbuf->buffer, recon_buffer_size);
  RF_Free(rbuf, sizeof(*rbuf));
d272 4
a275 3
void rf_CheckFloatingRbufCount(raidPtr, dolock)
  RF_Raid_t  *raidPtr;
  int         dolock;
d277 54
a330 54
  RF_ReconParityStripeStatus_t *p;
  RF_PSStatusHeader_t *pssTable;
  RF_ReconBuffer_t *rbuf;
  int i, j, sum = 0;
  RF_RowCol_t frow=0;

  for (i=0; i<raidPtr->numRow; i++)
    if (raidPtr->reconControl[i]) {
      frow = i;
      break;
     }
  RF_ASSERT(frow >= 0);

  if (dolock)
    RF_LOCK_MUTEX(raidPtr->reconControl[frow]->rb_mutex);
  pssTable = raidPtr->reconControl[frow]->pssTable;

  for (i=0; i<raidPtr->pssTableSize; i++) {
    RF_LOCK_MUTEX(pssTable[i].mutex);
    for (p = pssTable[i].chain; p; p=p->next) {
      rbuf = (RF_ReconBuffer_t *) p->rbuf;
      if (rbuf && rbuf->type == RF_RBUF_TYPE_FLOATING)
        sum++;

      rbuf = (RF_ReconBuffer_t *) p->writeRbuf;
      if (rbuf && rbuf->type == RF_RBUF_TYPE_FLOATING)
        sum++;

      for (j=0; j<p->xorBufCount; j++) {
        rbuf = (RF_ReconBuffer_t *) p->rbufsForXor[j];
        RF_ASSERT(rbuf);
        if (rbuf->type == RF_RBUF_TYPE_FLOATING)
          sum++;
      }
    }
    RF_UNLOCK_MUTEX(pssTable[i].mutex);
  }

  for (rbuf = raidPtr->reconControl[frow]->floatingRbufs;  rbuf; rbuf = rbuf->next) {
    if (rbuf->type == RF_RBUF_TYPE_FLOATING)
      sum++;
  }
  for (rbuf = raidPtr->reconControl[frow]->committedRbufs; rbuf; rbuf = rbuf->next) {
    if (rbuf->type == RF_RBUF_TYPE_FLOATING)
      sum++;
  }
  for (rbuf = raidPtr->reconControl[frow]->fullBufferList; rbuf; rbuf = rbuf->next) {
    if (rbuf->type == RF_RBUF_TYPE_FLOATING)
      sum++;
  }
  for (rbuf = raidPtr->reconControl[frow]->priorityList;   rbuf; rbuf = rbuf->next) {
    if (rbuf->type == RF_RBUF_TYPE_FLOATING)
      sum++;
  }
d332 1
a332 1
  RF_ASSERT(sum == raidPtr->numFloatingReconBufs);
d334 2
a335 2
  if (dolock)
    RF_UNLOCK_MUTEX(raidPtr->reconControl[frow]->rb_mutex);
@

