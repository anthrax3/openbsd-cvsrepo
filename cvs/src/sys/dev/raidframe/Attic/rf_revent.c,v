head	1.11;
access;
symbols
	OPENBSD_5_1_BASE:1.10
	OPENBSD_5_1:1.10.0.38
	OPENBSD_5_0:1.10.0.36
	OPENBSD_5_0_BASE:1.10
	OPENBSD_4_9:1.10.0.34
	OPENBSD_4_9_BASE:1.10
	OPENBSD_4_8:1.10.0.32
	OPENBSD_4_8_BASE:1.10
	OPENBSD_4_7:1.10.0.28
	OPENBSD_4_7_BASE:1.10
	OPENBSD_4_6:1.10.0.30
	OPENBSD_4_6_BASE:1.10
	OPENBSD_4_5:1.10.0.26
	OPENBSD_4_5_BASE:1.10
	OPENBSD_4_4:1.10.0.24
	OPENBSD_4_4_BASE:1.10
	OPENBSD_4_3:1.10.0.22
	OPENBSD_4_3_BASE:1.10
	OPENBSD_4_2:1.10.0.20
	OPENBSD_4_2_BASE:1.10
	OPENBSD_4_1:1.10.0.18
	OPENBSD_4_1_BASE:1.10
	OPENBSD_4_0:1.10.0.16
	OPENBSD_4_0_BASE:1.10
	OPENBSD_3_9:1.10.0.14
	OPENBSD_3_9_BASE:1.10
	OPENBSD_3_8:1.10.0.12
	OPENBSD_3_8_BASE:1.10
	OPENBSD_3_7:1.10.0.10
	OPENBSD_3_7_BASE:1.10
	OPENBSD_3_6:1.10.0.8
	OPENBSD_3_6_BASE:1.10
	SMP_SYNC_A:1.10
	SMP_SYNC_B:1.10
	OPENBSD_3_5:1.10.0.6
	OPENBSD_3_5_BASE:1.10
	OPENBSD_3_4:1.10.0.4
	OPENBSD_3_4_BASE:1.10
	UBC_SYNC_A:1.10
	OPENBSD_3_3:1.10.0.2
	OPENBSD_3_3_BASE:1.10
	OPENBSD_3_2:1.9.0.12
	OPENBSD_3_2_BASE:1.9
	OPENBSD_3_1:1.9.0.10
	OPENBSD_3_1_BASE:1.9
	UBC_SYNC_B:1.9
	UBC:1.9.0.8
	UBC_BASE:1.9
	OPENBSD_3_0:1.9.0.6
	OPENBSD_3_0_BASE:1.9
	OPENBSD_2_9_BASE:1.9
	OPENBSD_2_9:1.9.0.4
	OPENBSD_2_8:1.9.0.2
	OPENBSD_2_8_BASE:1.9
	OPENBSD_2_7:1.8.0.4
	OPENBSD_2_7_BASE:1.8
	SMP:1.8.0.2
	SMP_BASE:1.8
	kame_19991208:1.6
	OPENBSD_2_6:1.6.0.2
	OPENBSD_2_6_BASE:1.6
	OPENBSD_2_5:1.2.0.2
	OPENBSD_2_5_BASE:1.2;
locks; strict;
comment	@ * @;


1.11
date	2012.04.06.15.53.59;	author jsing;	state dead;
branches;
next	1.10;

1.10
date	2002.12.16.07.01.05;	author tdeval;	state Exp;
branches;
next	1.9;

1.9
date	2000.08.08.16.07.45;	author peter;	state Exp;
branches
	1.9.8.1;
next	1.8;

1.8
date	2000.01.11.14.38.59;	author peter;	state Exp;
branches
	1.8.2.1;
next	1.7;

1.7
date	2000.01.07.14.50.23;	author peter;	state Exp;
branches;
next	1.6;

1.6
date	99.08.03.13.56.38;	author peter;	state Exp;
branches;
next	1.5;

1.5
date	99.08.02.15.42.48;	author peter;	state Exp;
branches;
next	1.4;

1.4
date	99.08.02.12.35.33;	author peter;	state Exp;
branches;
next	1.3;

1.3
date	99.07.30.14.45.33;	author peter;	state Exp;
branches;
next	1.2;

1.2
date	99.02.16.00.03.24;	author niklas;	state Exp;
branches;
next	1.1;

1.1
date	99.01.11.14.29.48;	author niklas;	state Exp;
branches;
next	;

1.8.2.1
date	2001.05.14.22.26.14;	author niklas;	state Exp;
branches;
next	1.8.2.2;

1.8.2.2
date	2003.03.28.00.38.29;	author niklas;	state Exp;
branches;
next	;

1.9.8.1
date	2003.05.19.22.21.53;	author tedu;	state Exp;
branches;
next	;


desc
@@


1.11
log
@Put raidframe in the attic.
@
text
@/*	$OpenBSD: rf_revent.c,v 1.10 2002/12/16 07:01:05 tdeval Exp $	*/
/*	$NetBSD: rf_revent.c,v 1.7 2000/05/30 02:04:29 oster Exp $	*/

/*
 * Copyright (c) 1995 Carnegie-Mellon University.
 * All rights reserved.
 *
 * Author:
 *
 * Permission to use, copy, modify and distribute this software and
 * its documentation is hereby granted, provided that both the copyright
 * notice and this permission notice appear in all copies of the
 * software, derivative works or modified versions, and any portions
 * thereof, and that both notices appear in supporting documentation.
 *
 * CARNEGIE MELLON ALLOWS FREE USE OF THIS SOFTWARE IN ITS "AS IS"
 * CONDITION.  CARNEGIE MELLON DISCLAIMS ANY LIABILITY OF ANY KIND
 * FOR ANY DAMAGES WHATSOEVER RESULTING FROM THE USE OF THIS SOFTWARE.
 *
 * Carnegie Mellon requests users of this software to return to
 *
 *  Software Distribution Coordinator  or  Software.Distribution@@CS.CMU.EDU
 *  School of Computer Science
 *  Carnegie Mellon University
 *  Pittsburgh PA 15213-3890
 *
 * any improvements or extensions that they make and grant Carnegie the
 * rights to redistribute these changes.
 */

/*
 * revent.c -- Reconstruction event handling code.
 */

#include <sys/errno.h>

#include "rf_raid.h"
#include "rf_revent.h"
#include "rf_etimer.h"
#include "rf_general.h"
#include "rf_freelist.h"
#include "rf_desc.h"
#include "rf_shutdown.h"

static RF_FreeList_t *rf_revent_freelist;
#define	RF_MAX_FREE_REVENT	128
#define	RF_REVENT_INC		  8
#define	RF_REVENT_INITIAL	  8



#include <sys/proc.h>
#include <sys/kernel.h>

#define	DO_WAIT(_rc)							\
	tsleep(&(_rc)->eventQueue, PRIBIO, "RAIDframe eventq", 0)

#define	DO_SIGNAL(_rc)	wakeup(&(_rc)->eventQueue)


void rf_ShutdownReconEvent(void *);

RF_ReconEvent_t *GetReconEventDesc(RF_RowCol_t, RF_RowCol_t, void *,
	RF_Revent_t);

void
rf_ShutdownReconEvent(void *ignored)
{
	RF_FREELIST_DESTROY(rf_revent_freelist, next, (RF_ReconEvent_t *));
}

int
rf_ConfigureReconEvent(RF_ShutdownList_t **listp)
{
	int rc;

	RF_FREELIST_CREATE(rf_revent_freelist, RF_MAX_FREE_REVENT,
	    RF_REVENT_INC, sizeof(RF_ReconEvent_t));
	if (rf_revent_freelist == NULL)
		return (ENOMEM);
	rc = rf_ShutdownCreate(listp, rf_ShutdownReconEvent, NULL);
	if (rc) {
		RF_ERRORMSG3("Unable to add to shutdown list file %s line %d"
		    " rc=%d\n", __FILE__, __LINE__, rc);
		rf_ShutdownReconEvent(NULL);
		return (rc);
	}
	RF_FREELIST_PRIME(rf_revent_freelist, RF_REVENT_INITIAL, next,
	    (RF_ReconEvent_t *));
	return (0);
}

/*
 * Returns the next reconstruction event, blocking the calling thread
 * until one becomes available. Will now return null if it is blocked
 * or will return an event if it is not.
 */

RF_ReconEvent_t *
rf_GetNextReconEvent(RF_RaidReconDesc_t *reconDesc, RF_RowCol_t row,
    void (*continueFunc) (void *), void *continueArg)
{
	RF_Raid_t *raidPtr = reconDesc->raidPtr;
	RF_ReconCtrl_t *rctrl = raidPtr->reconControl[row];
	RF_ReconEvent_t *event;

	RF_ASSERT(row >= 0 && row <= raidPtr->numRow);
	RF_LOCK_MUTEX(rctrl->eq_mutex);
	/* q NULL and count==0 must be equivalent conditions. */
	RF_ASSERT((rctrl->eventQueue == NULL) == (rctrl->eq_count == 0));

	rctrl->continueFunc = continueFunc;
	rctrl->continueArg = continueArg;

	/*
	 * mpsleep timeout value: secs = timo_val/hz. 'ticks' here is
	 * defined as cycle-counter ticks, not softclock ticks.
	 */

#define	MAX_RECON_EXEC_USECS		(100 * 1000)	/* 100 ms */
#define	RECON_DELAY_MS			25
#define	RECON_TIMO			((RECON_DELAY_MS * hz) / 1000)

	/*
	 * We are not pre-emptible in the kernel, but we don't want to run
	 * forever. If we run w/o blocking for more than MAX_RECON_EXEC_USECS
	 * delay for RECON_DELAY_MS before continuing. This may murder us with
	 * context switches, so we may need to increase both the
	 * MAX...TICKS and the RECON_DELAY_MS.
	 */
	if (reconDesc->reconExecTimerRunning) {
		int status;

		RF_ETIMER_STOP(reconDesc->recon_exec_timer);
		RF_ETIMER_EVAL(reconDesc->recon_exec_timer);
		reconDesc->reconExecTicks +=
		    RF_ETIMER_VAL_US(reconDesc->recon_exec_timer);
		if (reconDesc->reconExecTicks > reconDesc->maxReconExecTicks)
			reconDesc->maxReconExecTicks =
			    reconDesc->reconExecTicks;
		if (reconDesc->reconExecTicks >= MAX_RECON_EXEC_USECS) {
			/* We've been running too long - sleep. */
#if RF_RECON_STATS > 0
			reconDesc->numReconExecDelays++;
#endif /* RF_RECON_STATS > 0 */
			status = tsleep(&reconDesc->reconExecTicks,
			    PRIBIO, "recon delay", RECON_TIMO);
			RF_ASSERT(status == EWOULDBLOCK);
			reconDesc->reconExecTicks = 0;
		}
	}
	while (!rctrl->eventQueue) {
#if RF_RECON_STATS > 0
		reconDesc->numReconEventWaits++;
#endif				/* RF_RECON_STATS > 0 */
		DO_WAIT(rctrl);
		reconDesc->reconExecTicks = 0;	/* We've just waited. */
	}

	RF_ETIMER_START(reconDesc->recon_exec_timer);
	reconDesc->reconExecTimerRunning = 1;

	event = rctrl->eventQueue;
	rctrl->eventQueue = event->next;
	event->next = NULL;
	rctrl->eq_count--;

	/* q NULL and count==0 must be equivalent conditions. */
	RF_ASSERT((rctrl->eventQueue == NULL) == (rctrl->eq_count == 0));
	RF_UNLOCK_MUTEX(rctrl->eq_mutex);
	return (event);
}

/* Enqueues a reconstruction event on the indicated queue. */
void
rf_CauseReconEvent(RF_Raid_t *raidPtr, RF_RowCol_t row, RF_RowCol_t col,
    void *arg, RF_Revent_t type)
{
	RF_ReconCtrl_t *rctrl = raidPtr->reconControl[row];
	RF_ReconEvent_t *event = GetReconEventDesc(row, col, arg, type);

	if (type == RF_REVENT_BUFCLEAR) {
		RF_ASSERT(col != rctrl->fcol);
	}
	RF_ASSERT(row >= 0 && row <= raidPtr->numRow && col >= 0 &&
	    col <= raidPtr->numCol);
	RF_LOCK_MUTEX(rctrl->eq_mutex);
	/* q NULL and count==0 must be equivalent conditions. */
	RF_ASSERT((rctrl->eventQueue == NULL) == (rctrl->eq_count == 0));
	event->next = rctrl->eventQueue;
	rctrl->eventQueue = event;
	rctrl->eq_count++;
	RF_UNLOCK_MUTEX(rctrl->eq_mutex);

	DO_SIGNAL(rctrl);
}

/* Allocates and initializes a recon event descriptor. */
RF_ReconEvent_t *
GetReconEventDesc(RF_RowCol_t row, RF_RowCol_t col, void *arg, RF_Revent_t type)
{
	RF_ReconEvent_t *t;

	RF_FREELIST_GET(rf_revent_freelist, t, next, (RF_ReconEvent_t *));
	if (t == NULL)
		return (NULL);
	t->col = col;
	t->arg = arg;
	t->type = type;
	return (t);
}

void
rf_FreeReconEventDesc(RF_ReconEvent_t *event)
{
	RF_FREELIST_FREE(rf_revent_freelist, event, next);
}
@


1.10
log
@Major KNF.  Incentive from Tedu
@
text
@d1 1
a1 1
/*	$OpenBSD: rf_revent.c,v 1.9 2000/08/08 16:07:45 peter Exp $	*/
@


1.9
log
@sync RAIDframe with Gre Oster's work for NetBSD.

This update incorporates changes since January 2000.

RAID1 and RAID5 tested for functionality matching the 2.7 code. A
number of bug fixes (including stopping a parity rebuild when
unconfiguring) have been included. See Greg's RAIDframe info page:

	http://www.cs.usask.ca/staff/oster/raid.html

The RAID_AUTOCONFIG feature set does *NOT* yet work. These features
require more work throughout the boot system and as such are a big
task.

IMPORTANT: As with anything that is this near live data on your
systems, please test carefully with existing configurations before
deploying in a live system.  Feedback via sendbug or mail direct
to peter@@wonderland.org is appreciated.
@
text
@d1 1
a1 1
/*	$OpenBSD: rf_revent.c,v 1.8 2000/01/11 14:38:59 peter Exp $	*/
d3 1
d30 1
d32 1
a32 1
 * revent.c -- reconstruction event handling code
d46 3
a48 3
#define RF_MAX_FREE_REVENT 128
#define RF_REVENT_INC        8
#define RF_REVENT_INITIAL    8
d55 2
a56 2
#define DO_WAIT(_rc)  \
	tsleep(&(_rc)->eventQueue, PRIBIO,  "raidframe eventq", 0)
d58 1
a58 1
#define DO_SIGNAL(_rc)     wakeup(&(_rc)->eventQueue)
d61 1
a61 1
static void rf_ShutdownReconEvent(void *);
d63 2
a64 3
static RF_ReconEvent_t *
GetReconEventDesc(RF_RowCol_t row, RF_RowCol_t col,
    void *arg, RF_Revent_t type);
d66 2
a67 3
static void
rf_ShutdownReconEvent(ignored)
	void   *ignored;
d72 2
a73 3
int 
rf_ConfigureReconEvent(listp)
	RF_ShutdownList_t **listp;
d75 1
a75 1
	int     rc;
d83 2
a84 2
		RF_ERRORMSG3("Unable to add to shutdown list file %s line %d rc=%d\n", __FILE__,
		    __LINE__, rc);
d93 5
a97 3
/* returns the next reconstruction event, blocking the calling thread
 * until one becomes available.  will now return null if it is blocked
 * or will return an event if it is not */
d100 2
a101 5
rf_GetNextReconEvent(reconDesc, row, continueFunc, continueArg)
	RF_RaidReconDesc_t *reconDesc;
	RF_RowCol_t row;
	void    (*continueFunc) (void *);
	void   *continueArg;
d109 1
a109 1
	/* q null and count==0 must be equivalent conditions */
d115 8
a122 6
	/* mpsleep timeout value: secs = timo_val/hz.  'ticks' here is
	   defined as cycle-counter ticks, not softclock ticks */

#define MAX_RECON_EXEC_USECS		(100 * 1000)	/* 100 ms */
#define RECON_DELAY_MS			25
#define RECON_TIMO    			((RECON_DELAY_MS * hz) / 1000)
d124 2
a125 1
	/* we are not pre-emptible in the kernel, but we don't want to run
d127 1
a127 1
	 * delay for RECON_DELAY_MS before continuing. this may murder us with
d129 2
a130 1
	 * MAX...TICKS and the RECON_DELAY_MS. */
d132 1
a132 1
		int	status;
d136 2
a137 2
		reconDesc->reconExecTicks += 
			RF_ETIMER_VAL_US(reconDesc->recon_exec_timer);
d139 2
a140 2
			reconDesc->maxReconExecTicks = 
				reconDesc->reconExecTicks;
d142 1
a142 1
			/* we've been running too long - sleep */
d146 2
a147 2
			status = tsleep(&reconDesc->reconExecTicks, 
					PRIBIO, "recon delay", RECON_TIMO);
d157 1
a157 1
		reconDesc->reconExecTicks = 0;	/* we've just waited */
d168 1
a168 1
	/* q null and count==0 must be equivalent conditions */
d173 5
a177 8
/* enqueues a reconstruction event on the indicated queue */
void 
rf_CauseReconEvent(raidPtr, row, col, arg, type)
	RF_Raid_t *raidPtr;
	RF_RowCol_t row;
	RF_RowCol_t col;
	void   *arg;
	RF_Revent_t type;
d185 2
a186 1
	RF_ASSERT(row >= 0 && row <= raidPtr->numRow && col >= 0 && col <= raidPtr->numCol);
d188 1
a188 1
	/* q null and count==0 must be equivalent conditions */
d197 4
a200 7
/* allocates and initializes a recon event descriptor */
static RF_ReconEvent_t *
GetReconEventDesc(row, col, arg, type)
	RF_RowCol_t row;
	RF_RowCol_t col;
	void   *arg;
	RF_Revent_t type;
d213 2
a214 3
void 
rf_FreeReconEventDesc(event)
	RF_ReconEvent_t *event;
@


1.9.8.1
log
@sync
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
a2 1

a28 1

d30 1
a30 1
 * revent.c -- Reconstruction event handling code.
d44 3
a46 3
#define	RF_MAX_FREE_REVENT	128
#define	RF_REVENT_INC		  8
#define	RF_REVENT_INITIAL	  8
d53 2
a54 2
#define	DO_WAIT(_rc)							\
	tsleep(&(_rc)->eventQueue, PRIBIO, "RAIDframe eventq", 0)
d56 1
a56 1
#define	DO_SIGNAL(_rc)	wakeup(&(_rc)->eventQueue)
d59 1
a59 1
void rf_ShutdownReconEvent(void *);
d61 3
a63 2
RF_ReconEvent_t *GetReconEventDesc(RF_RowCol_t, RF_RowCol_t, void *,
	RF_Revent_t);
d65 3
a67 2
void
rf_ShutdownReconEvent(void *ignored)
d72 3
a74 2
int
rf_ConfigureReconEvent(RF_ShutdownList_t **listp)
d76 1
a76 1
	int rc;
d84 2
a85 2
		RF_ERRORMSG3("Unable to add to shutdown list file %s line %d"
		    " rc=%d\n", __FILE__, __LINE__, rc);
d94 3
a96 5
/*
 * Returns the next reconstruction event, blocking the calling thread
 * until one becomes available. Will now return null if it is blocked
 * or will return an event if it is not.
 */
d99 5
a103 2
rf_GetNextReconEvent(RF_RaidReconDesc_t *reconDesc, RF_RowCol_t row,
    void (*continueFunc) (void *), void *continueArg)
d111 1
a111 1
	/* q NULL and count==0 must be equivalent conditions. */
d117 6
a122 8
	/*
	 * mpsleep timeout value: secs = timo_val/hz. 'ticks' here is
	 * defined as cycle-counter ticks, not softclock ticks.
	 */

#define	MAX_RECON_EXEC_USECS		(100 * 1000)	/* 100 ms */
#define	RECON_DELAY_MS			25
#define	RECON_TIMO			((RECON_DELAY_MS * hz) / 1000)
d124 1
a124 2
	/*
	 * We are not pre-emptible in the kernel, but we don't want to run
d126 1
a126 1
	 * delay for RECON_DELAY_MS before continuing. This may murder us with
d128 1
a128 2
	 * MAX...TICKS and the RECON_DELAY_MS.
	 */
d130 1
a130 1
		int status;
d134 2
a135 2
		reconDesc->reconExecTicks +=
		    RF_ETIMER_VAL_US(reconDesc->recon_exec_timer);
d137 2
a138 2
			reconDesc->maxReconExecTicks =
			    reconDesc->reconExecTicks;
d140 1
a140 1
			/* We've been running too long - sleep. */
d144 2
a145 2
			status = tsleep(&reconDesc->reconExecTicks,
			    PRIBIO, "recon delay", RECON_TIMO);
d155 1
a155 1
		reconDesc->reconExecTicks = 0;	/* We've just waited. */
d166 1
a166 1
	/* q NULL and count==0 must be equivalent conditions. */
d171 8
a178 5

/* Enqueues a reconstruction event on the indicated queue. */
void
rf_CauseReconEvent(RF_Raid_t *raidPtr, RF_RowCol_t row, RF_RowCol_t col,
    void *arg, RF_Revent_t type)
d186 1
a186 2
	RF_ASSERT(row >= 0 && row <= raidPtr->numRow && col >= 0 &&
	    col <= raidPtr->numCol);
d188 1
a188 1
	/* q NULL and count==0 must be equivalent conditions. */
d197 7
a203 4

/* Allocates and initializes a recon event descriptor. */
RF_ReconEvent_t *
GetReconEventDesc(RF_RowCol_t row, RF_RowCol_t col, void *arg, RF_Revent_t type)
d216 3
a218 2
void
rf_FreeReconEventDesc(RF_ReconEvent_t *event)
@


1.8
log
@sync with NetBSD - remove an unused prototype.
@
text
@d1 2
a2 2
/*	$OpenBSD: rf_revent.c,v 1.7 2000/01/07 14:50:23 peter Exp $	*/
/*	$NetBSD: rf_revent.c,v 1.6 2000/01/07 03:56:14 oster Exp $	*/
d51 1
d53 2
a54 3
extern int hz;

#define DO_WAIT(_rc)   tsleep(&(_rc)->eventQueue, PRIBIO, "raidframe eventq", 0)
a92 3
/* returns the next reconstruction event, blocking the calling thread until
 * one becomes available
 */
d94 3
a96 1
/* will now return null if it is blocked or will return an event if it is not */
d111 2
a112 3
	RF_ASSERT((rctrl->eventQueue == NULL) == (rctrl->eq_count == 0));	/* q null and count==0
										 * must be equivalent
										 * conditions */
d117 2
d134 2
a135 1
		reconDesc->reconExecTicks += RF_ETIMER_VAL_US(reconDesc->recon_exec_timer);
d137 2
a138 1
			reconDesc->maxReconExecTicks = reconDesc->reconExecTicks;
d144 2
a145 1
			status = tsleep(&reconDesc->reconExecTicks, PRIBIO, "recon delay", RECON_TIMO);
d165 3
a167 3
	RF_ASSERT((rctrl->eventQueue == NULL) == (rctrl->eq_count == 0));	/* q null and count==0
										 * must be equivalent
										 * conditions */
d188 2
a189 3
	RF_ASSERT((rctrl->eventQueue == NULL) == (rctrl->eq_count == 0));	/* q null and count==0
										 * must be equivalent
										 * conditions */
@


1.8.2.1
log
@merge in approximately 2.9 into SMP branch
@
text
@d1 2
a2 2
/*	$OpenBSD: rf_revent.c,v 1.9 2000/08/08 16:07:45 peter Exp $	*/
/*	$NetBSD: rf_revent.c,v 1.7 2000/05/30 02:04:29 oster Exp $	*/
a50 1
#include <sys/kernel.h>
d52 3
a54 2
#define DO_WAIT(_rc)  \
	tsleep(&(_rc)->eventQueue, PRIBIO,  "raidframe eventq", 0)
d93 3
d97 1
a97 3
/* returns the next reconstruction event, blocking the calling thread
 * until one becomes available.  will now return null if it is blocked
 * or will return an event if it is not */
d112 3
a114 2
	/* q null and count==0 must be equivalent conditions */
	RF_ASSERT((rctrl->eventQueue == NULL) == (rctrl->eq_count == 0));
a118 2
	/* mpsleep timeout value: secs = timo_val/hz.  'ticks' here is
	   defined as cycle-counter ticks, not softclock ticks */
d134 1
a134 2
		reconDesc->reconExecTicks += 
			RF_ETIMER_VAL_US(reconDesc->recon_exec_timer);
d136 1
a136 2
			reconDesc->maxReconExecTicks = 
				reconDesc->reconExecTicks;
d142 1
a142 2
			status = tsleep(&reconDesc->reconExecTicks, 
					PRIBIO, "recon delay", RECON_TIMO);
d162 3
a164 3

	/* q null and count==0 must be equivalent conditions */
	RF_ASSERT((rctrl->eventQueue == NULL) == (rctrl->eq_count == 0));
d185 3
a187 2
	/* q null and count==0 must be equivalent conditions */
	RF_ASSERT((rctrl->eventQueue == NULL) == (rctrl->eq_count == 0));
@


1.8.2.2
log
@Sync the SMP branch with 3.3
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
a2 1

a28 1

d30 1
a30 1
 * revent.c -- Reconstruction event handling code.
d44 3
a46 3
#define	RF_MAX_FREE_REVENT	128
#define	RF_REVENT_INC		  8
#define	RF_REVENT_INITIAL	  8
d53 2
a54 2
#define	DO_WAIT(_rc)							\
	tsleep(&(_rc)->eventQueue, PRIBIO, "RAIDframe eventq", 0)
d56 1
a56 1
#define	DO_SIGNAL(_rc)	wakeup(&(_rc)->eventQueue)
d59 1
a59 1
void rf_ShutdownReconEvent(void *);
d61 3
a63 2
RF_ReconEvent_t *GetReconEventDesc(RF_RowCol_t, RF_RowCol_t, void *,
	RF_Revent_t);
d65 3
a67 2
void
rf_ShutdownReconEvent(void *ignored)
d72 3
a74 2
int
rf_ConfigureReconEvent(RF_ShutdownList_t **listp)
d76 1
a76 1
	int rc;
d84 2
a85 2
		RF_ERRORMSG3("Unable to add to shutdown list file %s line %d"
		    " rc=%d\n", __FILE__, __LINE__, rc);
d94 3
a96 5
/*
 * Returns the next reconstruction event, blocking the calling thread
 * until one becomes available. Will now return null if it is blocked
 * or will return an event if it is not.
 */
d99 5
a103 2
rf_GetNextReconEvent(RF_RaidReconDesc_t *reconDesc, RF_RowCol_t row,
    void (*continueFunc) (void *), void *continueArg)
d111 1
a111 1
	/* q NULL and count==0 must be equivalent conditions. */
d117 6
a122 8
	/*
	 * mpsleep timeout value: secs = timo_val/hz. 'ticks' here is
	 * defined as cycle-counter ticks, not softclock ticks.
	 */

#define	MAX_RECON_EXEC_USECS		(100 * 1000)	/* 100 ms */
#define	RECON_DELAY_MS			25
#define	RECON_TIMO			((RECON_DELAY_MS * hz) / 1000)
d124 1
a124 2
	/*
	 * We are not pre-emptible in the kernel, but we don't want to run
d126 1
a126 1
	 * delay for RECON_DELAY_MS before continuing. This may murder us with
d128 1
a128 2
	 * MAX...TICKS and the RECON_DELAY_MS.
	 */
d130 1
a130 1
		int status;
d134 2
a135 2
		reconDesc->reconExecTicks +=
		    RF_ETIMER_VAL_US(reconDesc->recon_exec_timer);
d137 2
a138 2
			reconDesc->maxReconExecTicks =
			    reconDesc->reconExecTicks;
d140 1
a140 1
			/* We've been running too long - sleep. */
d144 2
a145 2
			status = tsleep(&reconDesc->reconExecTicks,
			    PRIBIO, "recon delay", RECON_TIMO);
d155 1
a155 1
		reconDesc->reconExecTicks = 0;	/* We've just waited. */
d166 1
a166 1
	/* q NULL and count==0 must be equivalent conditions. */
d171 8
a178 5

/* Enqueues a reconstruction event on the indicated queue. */
void
rf_CauseReconEvent(RF_Raid_t *raidPtr, RF_RowCol_t row, RF_RowCol_t col,
    void *arg, RF_Revent_t type)
d186 1
a186 2
	RF_ASSERT(row >= 0 && row <= raidPtr->numRow && col >= 0 &&
	    col <= raidPtr->numCol);
d188 1
a188 1
	/* q NULL and count==0 must be equivalent conditions. */
d197 7
a203 4

/* Allocates and initializes a recon event descriptor. */
RF_ReconEvent_t *
GetReconEventDesc(RF_RowCol_t row, RF_RowCol_t col, void *arg, RF_Revent_t type)
d216 3
a218 2
void
rf_FreeReconEventDesc(RF_ReconEvent_t *event)
@


1.7
log
@sync with work by Greg Oster on NetBSD

Please note: This update has *only* been tested on i386 with IDE
disks. Could someone with a spare box please make sure all is OK with
SCSI and maybe other arches ? sparc testing will follow locally.

* remove rf_sys.h
* many changes to make it more stable
* some performance increases
* All raid threads now get their own kernel process and the calling
  raidctl(8) program will show status progress through a meter.
* In theory FFS_SOFTUPDATES and RAIDframe will now work together - NOT
  TESTED YET

See http://www.cs.usask.ca/staff/oster/raid.html

This updates include Greg's changes to Jan 4th 2000.

TODO:
* some odd behaviour when running raictl -c on an already config'ed
  raid set - problem founf, fix being done
* progress meter is in raidctl(8) - seperate commit, but could do with
  sync'ing with OpenBSD ftp version
@
text
@d1 2
a2 2
/*	$OpenBSD: rf_revent.c,v 1.6 1999/08/03 13:56:38 peter Exp $	*/
/*	$NetBSD: rf_revent.c,v 1.5 1999/08/13 03:26:55 oster Exp $	*/
a63 4
RF_ReconEvent_t *
rf_GetNextReconEvent(RF_RaidReconDesc_t *,
    RF_RowCol_t, void (*continueFunc) (void *),
    void *);
d67 1
a67 1
void   *ignored;
@


1.6
log
@* rf_reconstruct.c: adopt nilkas' suggestion regard statics and
__inline__ - this is a proof of concept and will cover the raidframe
source as a whole over coming updates. Update namespace of function to
prefix with rf_ - comments again welcome.

* overall: rework the macros in rf_etimer.h and the resultant changes
to their use to count microseconds and not clock ticks. Restore the code
in rf_revent.c to a similar strcuture to before the previous commit,
and use the system timers to govern resource usage.

Tested with local i386/IDE and the reconstruction of a disk in my
array - performance has improved for reconstruction at no noticable
CPU cost.
@
text
@d1 2
a2 2
/*	$OpenBSD: rf_revent.c,v 1.4 1999/08/02 12:35:33 peter Exp $	*/
/*	$NetBSD: rf_revent.c,v 1.4 1999/03/14 21:53:31 oster Exp $	*/
d138 4
a141 4
		reconDesc->reconExecuSecs += RF_ETIMER_VAL_US(reconDesc->recon_exec_timer);
		if (reconDesc->reconExecuSecs > reconDesc->maxReconExecuSecs)
			reconDesc->maxReconExecuSecs = reconDesc->reconExecuSecs;
		if (reconDesc->reconExecuSecs >= MAX_RECON_EXEC_USECS) {
d146 1
a146 1
			status = tsleep(&reconDesc->reconExecuSecs, PRIBIO, "recon delay", RECON_TIMO);
d148 1
a148 1
			reconDesc->reconExecuSecs = 0;
d156 1
a156 1
		reconDesc->reconExecuSecs = 0;	/* we've just waited */
@


1.5
log
@fix reconstruction performance. the old code used home-grown timers
based upon hardcoded CPU speed values and an assumtion that the number
of clock cycles was available. This is/was silly.

redone rf_GetNextReconEvent so that is now runs for 1/10th second
before sleeping for a short time (1/50th sec). Locally, this is using
about 25% of the CPU while rebuilding a disk in a four disk IDE RAID5
array. It was 22% of the way through when I last looked... much much
faster.

An even better way is sought - suggestions welcome. Lots of code that
the old routines relied on canm be harvested later.

Patches also being sent to Greg Oster @@ NetBSD group.
@
text
@a42 2
#include <sys/kernel.h>

a109 2
	int	s;

a119 1

a122 5
/* start with a simple premise. Allow 100 ms for recon, and then
 * sleep for the 2 ms to allow use of the CPU. This resulted in a CPU
 * utilisation of about 25% locally, and a very responsive system - PMG
 */
#define	RECON_TIME	((100 * hz) / 1000)
d124 9
d134 1
a134 2
		int     status;
		RF_int64 ticks;
d136 7
a142 7
		s = splclock();
		ticks = (mono_time.tv_sec * 1000000 + mono_time.tv_usec) -
			reconDesc->reconExecTimerRunning;
		splx(s);

		if (ticks >= (1000000 / RECON_TIME)) {
			/* we've been running too long.  delay for RECON_TIME */
d146 1
a146 1
			status = tsleep(&reconDesc->reconExecTicks, PRIBIO, "recon delay", RECON_TIME / 5);
d148 1
a150 1

d156 1
d158 3
a160 5
	s = splclock();
	/* set time to now */
	reconDesc->reconExecTimerRunning = mono_time.tv_sec * 1000000 +
					   mono_time.tv_usec;
	splx(s);
@


1.4
log
@minor style nit
@
text
@d1 1
a1 1
/*	$OpenBSD: rf_revent.c,v 1.3 1999/07/30 14:45:33 peter Exp $	*/
d43 2
d112 2
d128 5
a133 11
/* mpsleep timeout value: secs = timo_val/hz.  'ticks' here is defined as cycle-counter ticks, not softclock ticks */
#define MAX_RECON_EXEC_TICKS 15000000	/* 150 Mhz => this many ticks in 100
					 * ms */
#define RECON_DELAY_MS 25
#define RECON_TIMO     ((RECON_DELAY_MS * hz) / 1000)

	/* we are not pre-emptible in the kernel, but we don't want to run
	 * forever.  If we run w/o blocking for more than MAX_RECON_EXEC_TICKS
	 * ticks of the cycle counter, delay for RECON_DELAY before
	 * continuing. this may murder us with context switches, so we may
	 * need to increase both the MAX...TICKS and the RECON_DELAY_MS. */
d136 6
d143 2
a144 8
		RF_ETIMER_STOP(reconDesc->recon_exec_timer);
		RF_ETIMER_EVAL(reconDesc->recon_exec_timer);
		reconDesc->reconExecTicks += RF_ETIMER_VAL_TICKS(reconDesc->recon_exec_timer);
		if (reconDesc->reconExecTicks > reconDesc->maxReconExecTicks)
			reconDesc->maxReconExecTicks = reconDesc->reconExecTicks;
		if (reconDesc->reconExecTicks >= MAX_RECON_EXEC_TICKS) {
			/* we've been running too long.  delay for
			 * RECON_DELAY_MS */
d147 2
a148 2
#endif				/* RF_RECON_STATS > 0 */
			status = tsleep(&reconDesc->reconExecTicks, PRIBIO, "recon delay", RECON_TIMO);
a149 1
			reconDesc->reconExecTicks = 0;
d152 1
a157 1
		reconDesc->reconExecTicks = 0;	/* we've just waited */
d159 5
a163 3

	reconDesc->reconExecTimerRunning = 1;
	RF_ETIMER_START(reconDesc->recon_exec_timer);
@


1.3
log
@Update RAIDframe from NetBSD-current as of 1999/07/26.

Please note that you *must* follow the upgrade instructions at

	http://www.cs.usask.ca/staff/oster/clabel_upgrade.html

before installing the new raidctl and new kernel using this code.
@
text
@d1 1
a1 1
/*	$OpenBSD: rf_revent.c,v 1.2 1999/02/16 00:03:24 niklas Exp $	*/
d69 3
a71 2
	static void rf_ShutdownReconEvent(ignored)
	void   *ignored;
@


1.2
log
@Merge from NetBSD, mostly indentation
@
text
@d1 2
a2 2
/*	$OpenBSD: rf_revent.c,v 1.1 1999/01/11 14:29:48 niklas Exp $	*/
/*	$NetBSD: rf_revent.c,v 1.3 1999/02/05 00:06:17 oster Exp $	*/
d54 1
a54 1
#define DO_WAIT(_rc)   tsleep(&(_rc)->eventQueue, PRIBIO | PCATCH, "raidframe eventq", 0)
d149 1
a149 1
			status = tsleep(&reconDesc->reconExecTicks, PRIBIO | PCATCH, "recon delay", RECON_TIMO);
@


1.1
log
@Import of CMU's RAIDframe via NetBSD.
@
text
@d1 2
a2 2
/*	$OpenBSD: rf_revent.c,v 1.1 1998/11/13 04:20:34 oster Exp $	*/
/*	$NetBSD: rf_revent.c,v 1.1 1998/11/13 04:20:34 oster Exp $	*/
a31 55
/*
 * :  
 * Log: rf_revent.c,v 
 * Revision 1.22  1996/08/11 00:41:11  jimz
 * extern hz only for kernel
 *
 * Revision 1.21  1996/07/15  05:40:41  jimz
 * some recon datastructure cleanup
 * better handling of multiple failures
 * added undocumented double-recon test
 *
 * Revision 1.20  1996/06/17  03:18:04  jimz
 * include shutdown.h for macroized ShutdownCreate
 *
 * Revision 1.19  1996/06/10  11:55:47  jimz
 * Straightened out some per-array/not-per-array distinctions, fixed
 * a couple bugs related to confusion. Added shutdown lists. Removed
 * layout shutdown function (now subsumed by shutdown lists).
 *
 * Revision 1.18  1996/06/07  21:33:04  jimz
 * begin using consistent types for sector numbers,
 * stripe numbers, row+col numbers, recon unit numbers
 *
 * Revision 1.17  1996/06/05  18:06:02  jimz
 * Major code cleanup. The Great Renaming is now done.
 * Better modularity. Better typing. Fixed a bunch of
 * synchronization bugs. Made a lot of global stuff
 * per-desc or per-array. Removed dead code.
 *
 * Revision 1.16  1996/06/03  23:28:26  jimz
 * more bugfixes
 * check in tree to sync for IPDS runs with current bugfixes
 * there still may be a problem with threads in the script test
 * getting I/Os stuck- not trivially reproducible (runs ~50 times
 * in a row without getting stuck)
 *
 * Revision 1.15  1996/05/30  12:59:18  jimz
 * make etimer happier, more portable
 *
 * Revision 1.14  1996/05/20  16:13:40  jimz
 * switch to rf_{mutex,cond}_{init,destroy}
 * use RF_FREELIST for revents
 *
 * Revision 1.13  1996/05/18  20:09:47  jimz
 * bit of cleanup to compile cleanly in kernel, once again
 *
 * Revision 1.12  1996/05/18  19:51:34  jimz
 * major code cleanup- fix syntax, make some types consistent,
 * add prototypes, clean out dead code, et cetera
 *
 */

#ifdef _KERNEL
#define KERNEL
#endif
a48 1
#ifdef KERNEL
a53 4
#if !defined(__NetBSD__) && !defined(__OpenBSD__)
#define DO_WAIT(_rc)       mpsleep(&(_rc)->eventQueue, PZERO, "raidframe eventq", 0, \
			      (void *) simple_lock_addr((_rc)->eq_mutex), MS_LOCK_SIMPLE)
#else
a54 1
#endif
a57 6
#else      /* KERNEL */

#define DO_WAIT(_rc)       RF_WAIT_COND((_rc)->eq_cond, (_rc)->eq_mutex)
#define DO_SIGNAL(_rc)     RF_SIGNAL_COND((_rc)->eq_cond)

#endif     /* KERNEL */
d61 7
a67 5
static RF_ReconEvent_t *GetReconEventDesc(RF_RowCol_t row, RF_RowCol_t col,
	void *arg, RF_Revent_t type);
RF_ReconEvent_t *rf_GetNextReconEvent(RF_RaidReconDesc_t   *,
				      RF_RowCol_t, void (*continueFunc)(void *),
				      void *);     
d69 2
a70 2
static void rf_ShutdownReconEvent(ignored)
  void  *ignored;
d72 1
a72 1
	RF_FREELIST_DESTROY(rf_revent_freelist,next,(RF_ReconEvent_t *));
d75 20
a94 19
int rf_ConfigureReconEvent(listp)
  RF_ShutdownList_t  **listp;
{
  int rc;

  RF_FREELIST_CREATE(rf_revent_freelist, RF_MAX_FREE_REVENT,
    RF_REVENT_INC, sizeof(RF_ReconEvent_t));
  if (rf_revent_freelist == NULL)
    return(ENOMEM);
  rc = rf_ShutdownCreate(listp, rf_ShutdownReconEvent, NULL);
  if (rc) {
    RF_ERRORMSG3("Unable to add to shutdown list file %s line %d rc=%d\n", __FILE__,
      __LINE__, rc);
    rf_ShutdownReconEvent(NULL);
    return(rc);
  }
  RF_FREELIST_PRIME(rf_revent_freelist, RF_REVENT_INITIAL,next,
    (RF_ReconEvent_t *));
  return(0);
a95 1

d102 20
a121 24
RF_ReconEvent_t *rf_GetNextReconEvent(reconDesc, row, continueFunc, continueArg)
  RF_RaidReconDesc_t   *reconDesc;
  RF_RowCol_t           row;
  void                (*continueFunc)(void *);
  void                 *continueArg;     
{
  RF_Raid_t *raidPtr = reconDesc->raidPtr;
  RF_ReconCtrl_t *rctrl = raidPtr->reconControl[row];
  RF_ReconEvent_t *event;
  
  RF_ASSERT( row >= 0 && row <= raidPtr->numRow );
  RF_LOCK_MUTEX(rctrl->eq_mutex);
  RF_ASSERT( (rctrl->eventQueue==NULL) == (rctrl->eq_count == 0));  /* q null and count==0 must be equivalent conditions */


  rctrl->continueFunc=continueFunc;
  rctrl->continueArg=continueArg;

#ifdef SIMULATE
  if (!rctrl->eventQueue) {
    RF_UNLOCK_MUTEX(rctrl->eq_mutex);
    return (NULL);
  }
#else /* SIMULATE */
a122 1
#ifdef KERNEL
d125 2
a126 1
#define MAX_RECON_EXEC_TICKS 15000000  /* 150 Mhz => this many ticks in 100 ms */
d130 16
a145 14
  /* we are not pre-emptible in the kernel, but we don't want to run forever.  If we run w/o blocking
   * for more than MAX_RECON_EXEC_TICKS ticks of the cycle counter, delay for RECON_DELAY before continuing.
   * this may murder us with context switches, so we may need to increase both the MAX...TICKS and the RECON_DELAY_MS.
   */
  if (reconDesc->reconExecTimerRunning) {
    int status;
    
    RF_ETIMER_STOP(reconDesc->recon_exec_timer);
    RF_ETIMER_EVAL(reconDesc->recon_exec_timer);
    reconDesc->reconExecTicks += RF_ETIMER_VAL_TICKS(reconDesc->recon_exec_timer);
    if (reconDesc->reconExecTicks > reconDesc->maxReconExecTicks)
      reconDesc->maxReconExecTicks = reconDesc->reconExecTicks;
    if (reconDesc->reconExecTicks >= MAX_RECON_EXEC_TICKS) {
      /* we've been running too long.  delay for RECON_DELAY_MS */
d147 8
a154 15
      reconDesc->numReconExecDelays++;
#endif /* RF_RECON_STATS > 0 */
#if !defined(__NetBSD__) && !defined(__OpenBSD__)
      status = mpsleep(&reconDesc->reconExecTicks, PZERO, "recon delay", RECON_TIMO, (void *) simple_lock_addr(rctrl->eq_mutex), MS_LOCK_SIMPLE);
#else
      status = tsleep(&reconDesc->reconExecTicks, PRIBIO | PCATCH, "recon delay", RECON_TIMO );
#endif
      RF_ASSERT(status == EWOULDBLOCK);
      reconDesc->reconExecTicks = 0;
    }
  }

#endif /* KERNEL */

  while (!rctrl->eventQueue) {
d156 18
a173 22
    reconDesc->numReconEventWaits++;
#endif /* RF_RECON_STATS > 0 */
    DO_WAIT(rctrl);
#ifdef KERNEL
    reconDesc->reconExecTicks = 0; /* we've just waited */
#endif /* KERNEL */
  }

#endif /* SIMULATE */

#ifdef KERNEL
  reconDesc->reconExecTimerRunning = 1;
  RF_ETIMER_START(reconDesc->recon_exec_timer);
#endif /* KERNEL */

  event = rctrl->eventQueue;
  rctrl->eventQueue = event->next;
  event->next = NULL;
  rctrl->eq_count--;
  RF_ASSERT( (rctrl->eventQueue==NULL) == (rctrl->eq_count == 0));  /* q null and count==0 must be equivalent conditions */
  RF_UNLOCK_MUTEX(rctrl->eq_mutex);
  return(event);
a174 1

d176 23
a198 9
void rf_CauseReconEvent(raidPtr, row, col, arg, type)
  RF_Raid_t    *raidPtr;
  RF_RowCol_t   row;
  RF_RowCol_t   col;
  void         *arg;
  RF_Revent_t   type;
{
  RF_ReconCtrl_t *rctrl = raidPtr->reconControl[row];
  RF_ReconEvent_t *event = GetReconEventDesc(row, col, arg, type);
d200 1
a200 17
  if (type == RF_REVENT_BUFCLEAR) {
    RF_ASSERT(col != rctrl->fcol);
  }
  
  RF_ASSERT( row >= 0 && row <= raidPtr->numRow && col >=0 && col <= raidPtr->numCol );
  RF_LOCK_MUTEX(rctrl->eq_mutex);
  RF_ASSERT( (rctrl->eventQueue==NULL) == (rctrl->eq_count == 0));  /* q null and count==0 must be equivalent conditions */
  event->next = rctrl->eventQueue;
  rctrl->eventQueue = event;
  rctrl->eq_count++;
  RF_UNLOCK_MUTEX(rctrl->eq_mutex);

#ifndef SIMULATE
  DO_SIGNAL(rctrl);
#else /* !SIMULATE */
  (rctrl->continueFunc)(rctrl->continueArg);
#endif /* !SIMULATE */
a201 1

d203 6
a208 5
static RF_ReconEvent_t *GetReconEventDesc(row, col, arg, type)
  RF_RowCol_t   row;
  RF_RowCol_t   col;
  void         *arg;
  RF_Revent_t   type;
d212 1
a212 1
	RF_FREELIST_GET(rf_revent_freelist,t,next,(RF_ReconEvent_t *));
d214 1
a214 1
		return(NULL);
d218 1
a218 1
	return(t);
d221 3
a223 2
void rf_FreeReconEventDesc(event)
  RF_ReconEvent_t  *event;
d225 1
a225 1
	RF_FREELIST_FREE(rf_revent_freelist,event,next);
@

