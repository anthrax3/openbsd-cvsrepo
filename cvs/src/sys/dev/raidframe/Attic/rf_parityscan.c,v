head	1.9;
access;
symbols
	OPENBSD_5_1_BASE:1.8
	OPENBSD_5_1:1.8.0.4
	OPENBSD_5_0:1.8.0.2
	OPENBSD_5_0_BASE:1.8
	OPENBSD_4_9:1.7.0.34
	OPENBSD_4_9_BASE:1.7
	OPENBSD_4_8:1.7.0.32
	OPENBSD_4_8_BASE:1.7
	OPENBSD_4_7:1.7.0.28
	OPENBSD_4_7_BASE:1.7
	OPENBSD_4_6:1.7.0.30
	OPENBSD_4_6_BASE:1.7
	OPENBSD_4_5:1.7.0.26
	OPENBSD_4_5_BASE:1.7
	OPENBSD_4_4:1.7.0.24
	OPENBSD_4_4_BASE:1.7
	OPENBSD_4_3:1.7.0.22
	OPENBSD_4_3_BASE:1.7
	OPENBSD_4_2:1.7.0.20
	OPENBSD_4_2_BASE:1.7
	OPENBSD_4_1:1.7.0.18
	OPENBSD_4_1_BASE:1.7
	OPENBSD_4_0:1.7.0.16
	OPENBSD_4_0_BASE:1.7
	OPENBSD_3_9:1.7.0.14
	OPENBSD_3_9_BASE:1.7
	OPENBSD_3_8:1.7.0.12
	OPENBSD_3_8_BASE:1.7
	OPENBSD_3_7:1.7.0.10
	OPENBSD_3_7_BASE:1.7
	OPENBSD_3_6:1.7.0.8
	OPENBSD_3_6_BASE:1.7
	SMP_SYNC_A:1.7
	SMP_SYNC_B:1.7
	OPENBSD_3_5:1.7.0.6
	OPENBSD_3_5_BASE:1.7
	OPENBSD_3_4:1.7.0.4
	OPENBSD_3_4_BASE:1.7
	UBC_SYNC_A:1.7
	OPENBSD_3_3:1.7.0.2
	OPENBSD_3_3_BASE:1.7
	OPENBSD_3_2:1.6.0.12
	OPENBSD_3_2_BASE:1.6
	OPENBSD_3_1:1.6.0.10
	OPENBSD_3_1_BASE:1.6
	UBC_SYNC_B:1.6
	UBC:1.6.0.8
	UBC_BASE:1.6
	OPENBSD_3_0:1.6.0.6
	OPENBSD_3_0_BASE:1.6
	OPENBSD_2_9_BASE:1.6
	OPENBSD_2_9:1.6.0.4
	OPENBSD_2_8:1.6.0.2
	OPENBSD_2_8_BASE:1.6
	OPENBSD_2_7:1.5.0.4
	OPENBSD_2_7_BASE:1.5
	SMP:1.5.0.2
	SMP_BASE:1.5
	kame_19991208:1.4
	OPENBSD_2_6:1.4.0.2
	OPENBSD_2_6_BASE:1.4
	OPENBSD_2_5:1.3.0.2
	OPENBSD_2_5_BASE:1.3;
locks; strict;
comment	@ * @;


1.9
date	2012.04.06.15.53.59;	author jsing;	state dead;
branches;
next	1.8;

1.8
date	2011.06.21.16.46.00;	author tedu;	state Exp;
branches;
next	1.7;

1.7
date	2002.12.16.07.01.04;	author tdeval;	state Exp;
branches;
next	1.6;

1.6
date	2000.08.08.16.07.44;	author peter;	state Exp;
branches
	1.6.8.1;
next	1.5;

1.5
date	2000.01.07.14.50.22;	author peter;	state Exp;
branches
	1.5.2.1;
next	1.4;

1.4
date	99.07.30.14.45.33;	author peter;	state Exp;
branches;
next	1.3;

1.3
date	99.03.02.21.53.50;	author niklas;	state Exp;
branches;
next	1.2;

1.2
date	99.02.16.00.03.09;	author niklas;	state Exp;
branches;
next	1.1;

1.1
date	99.01.11.14.29.37;	author niklas;	state Exp;
branches;
next	;

1.5.2.1
date	2001.05.14.22.26.13;	author niklas;	state Exp;
branches;
next	1.5.2.2;

1.5.2.2
date	2003.03.28.00.38.28;	author niklas;	state Exp;
branches;
next	;

1.6.8.1
date	2003.05.19.22.21.52;	author tedu;	state Exp;
branches;
next	;


desc
@@


1.9
log
@Put raidframe in the attic.
@
text
@/*	$OpenBSD: rf_parityscan.c,v 1.8 2011/06/21 16:46:00 tedu Exp $	*/
/*	$NetBSD: rf_parityscan.c,v 1.9 2000/05/28 03:00:31 oster Exp $	*/

/*
 * Copyright (c) 1995 Carnegie-Mellon University.
 * All rights reserved.
 *
 * Author: Mark Holland
 *
 * Permission to use, copy, modify and distribute this software and
 * its documentation is hereby granted, provided that both the copyright
 * notice and this permission notice appear in all copies of the
 * software, derivative works or modified versions, and any portions
 * thereof, and that both notices appear in supporting documentation.
 *
 * CARNEGIE MELLON ALLOWS FREE USE OF THIS SOFTWARE IN ITS "AS IS"
 * CONDITION.  CARNEGIE MELLON DISCLAIMS ANY LIABILITY OF ANY KIND
 * FOR ANY DAMAGES WHATSOEVER RESULTING FROM THE USE OF THIS SOFTWARE.
 *
 * Carnegie Mellon requests users of this software to return to
 *
 *  Software Distribution Coordinator  or  Software.Distribution@@CS.CMU.EDU
 *  School of Computer Science
 *  Carnegie Mellon University
 *  Pittsburgh PA 15213-3890
 *
 * any improvements or extensions that they make and grant Carnegie the
 * rights to redistribute these changes.
 */

/*****************************************************************************
 *
 * rf_parityscan.c -- Misc utilities related to parity verification.
 *
 *****************************************************************************/

#include "rf_types.h"
#include "rf_raid.h"
#include "rf_dag.h"
#include "rf_dagfuncs.h"
#include "rf_dagutils.h"
#include "rf_mcpair.h"
#include "rf_general.h"
#include "rf_engine.h"
#include "rf_parityscan.h"
#include "rf_map.h"


/*****************************************************************************
 *
 * Walk through the entire arry and write new parity.
 * This works by creating two DAGs, one to read a stripe of data and one to
 * write new parity. The first is executed, the data is xored together, and
 * then the second is executed. To avoid constantly building and tearing down
 * the DAGs, we create them a priori and fill them in with the mapping
 * information as we go along.
 *
 * There should never be more than one thread running this.
 *
 *****************************************************************************/
int
rf_RewriteParity(RF_Raid_t *raidPtr)
{
	RF_RaidLayout_t *layoutPtr = &raidPtr->Layout;
	RF_AccessStripeMapHeader_t *asm_h;
	int ret_val;
	int rc;
	RF_PhysDiskAddr_t pda;
	RF_SectorNum_t i;

	if (raidPtr->Layout.map->faultsTolerated == 0) {
		/* There isn't any parity. Call it "okay." */
		return (RF_PARITY_OKAY);
	}
	if (raidPtr->status[0] != rf_rs_optimal) {
		/*
		 * We're in degraded mode. Don't try to verify parity now !
		 * XXX: This should be a "we don't want to", not a
		 * "we can't" error.
		 */
		return (RF_PARITY_COULD_NOT_VERIFY);
	}

	ret_val = 0;

	pda.startSector = 0;
	pda.numSector = raidPtr->Layout.sectorsPerStripeUnit;
	rc = RF_PARITY_OKAY;

	for (i = 0; i < raidPtr->totalSectors && rc <= RF_PARITY_CORRECTED;
	     i += layoutPtr->dataSectorsPerStripe) {
		if (raidPtr->waitShutdown) {
			/*
			 * Someone is pulling the plug on this set...
			 * Abort the re-write.
			 */
			return (1);
		}
		asm_h = rf_MapAccess(raidPtr, i,
		    layoutPtr->dataSectorsPerStripe, NULL, RF_DONT_REMAP);
		raidPtr->parity_rewrite_stripes_done =
			i / layoutPtr->dataSectorsPerStripe ;
		rc = rf_VerifyParity(raidPtr, asm_h->stripeMap, 1, 0);
		switch (rc) {
		case RF_PARITY_OKAY:
		case RF_PARITY_CORRECTED:
			break;
		case RF_PARITY_BAD:
			printf("Parity bad during correction.\n");
			ret_val = 1;
			break;
		case RF_PARITY_COULD_NOT_CORRECT:
			printf("Could not correct bad parity.\n");
			ret_val = 1;
			break;
		case RF_PARITY_COULD_NOT_VERIFY:
			printf("Could not verify parity.\n");
			ret_val = 1;
			break;
		default:
			printf("Bad rc=%d from VerifyParity in"
			    " RewriteParity.\n", rc);
			ret_val = 1;
		}
		rf_FreeAccessStripeMap(asm_h);
	}
	return (ret_val);
}


/*****************************************************************************
 *
 * Verify that the parity in a particular stripe is correct.
 * We validate only the range of parity defined by parityPDA, since
 * this is all we have locked. The way we do this is to create an asm
 * that maps the whole stripe and then range-restrict it to the parity
 * region defined by the parityPDA.
 *
 *****************************************************************************/
int
rf_VerifyParity(RF_Raid_t *raidPtr, RF_AccessStripeMap_t *aasm, int correct_it,
    RF_RaidAccessFlags_t flags)
{
	RF_PhysDiskAddr_t *parityPDA;
	RF_AccessStripeMap_t *doasm;
	RF_LayoutSW_t *lp;
	int lrc, rc;

	lp = raidPtr->Layout.map;
	if (lp->faultsTolerated == 0) {
		/*
		 * There isn't any parity. Call it "okay."
		 */
		return (RF_PARITY_OKAY);
	}
	rc = RF_PARITY_OKAY;
	if (lp->VerifyParity) {
		for (doasm = aasm; doasm; doasm = doasm->next) {
			for (parityPDA = doasm->parityInfo; parityPDA;
			     parityPDA = parityPDA->next) {
				lrc = lp->VerifyParity(raidPtr,
				    doasm->raidAddress, parityPDA, correct_it,
				    flags);
				if (lrc > rc) {
					/*
					 * see rf_parityscan.h for why this
					 * works.
					 */
					rc = lrc;
				}
			}
		}
	} else {
		rc = RF_PARITY_COULD_NOT_VERIFY;
	}
	return (rc);
}

int
rf_VerifyParityBasic(RF_Raid_t *raidPtr, RF_RaidAddr_t raidAddr,
    RF_PhysDiskAddr_t *parityPDA, int correct_it, RF_RaidAccessFlags_t flags)
{
	RF_RaidLayout_t *layoutPtr = &(raidPtr->Layout);
	RF_RaidAddr_t startAddr = rf_RaidAddressOfPrevStripeBoundary(layoutPtr,
	    raidAddr);
	RF_SectorCount_t numsector = parityPDA->numSector;
	int numbytes = rf_RaidAddressToByte(raidPtr, numsector);
	int bytesPerStripe = numbytes * layoutPtr->numDataCol;
	RF_DagHeader_t *rd_dag_h, *wr_dag_h;	/* Read, write dag. */
	RF_DagNode_t *blockNode, *unblockNode, *wrBlock, *wrUnblock;
	RF_AccessStripeMapHeader_t *asm_h;
	RF_AccessStripeMap_t *asmap;
	RF_AllocListElem_t *alloclist;
	RF_PhysDiskAddr_t *pda;
	char *pbuf, *buf, *end_p, *p;
	int i, retcode;
	RF_ReconUnitNum_t which_ru;
	RF_StripeNum_t psID = rf_RaidAddressToParityStripeID(layoutPtr,
	    raidAddr, &which_ru);
	int stripeWidth = layoutPtr->numDataCol + layoutPtr->numParityCol;
	RF_AccTraceEntry_t tracerec;
	RF_MCPair_t *mcpair;

	retcode = RF_PARITY_OKAY;

	mcpair = rf_AllocMCPair();
	rf_MakeAllocList(alloclist);
	RF_MallocAndAdd(buf, numbytes * (layoutPtr->numDataCol +
	    layoutPtr->numParityCol), (char *), alloclist);
	/* Use calloc to make sure buffer is zeroed. */
	RF_CallocAndAdd(pbuf, 1, numbytes, (char *), alloclist);
	end_p = buf + bytesPerStripe;

	rd_dag_h = rf_MakeSimpleDAG(raidPtr, stripeWidth, numbytes, buf,
	    rf_DiskReadFunc, rf_DiskReadUndoFunc,
	    "Rod", alloclist, flags, RF_IO_NORMAL_PRIORITY);
	blockNode = rd_dag_h->succedents[0];
	unblockNode = blockNode->succedents[0]->succedents[0];

	/* Map the stripe and fill in the PDAs in the dag. */
	asm_h = rf_MapAccess(raidPtr, startAddr,
	    layoutPtr->dataSectorsPerStripe, buf, RF_DONT_REMAP);
	asmap = asm_h->stripeMap;

	for (pda = asmap->physInfo, i = 0; i < layoutPtr->numDataCol;
	     i++, pda = pda->next) {
		RF_ASSERT(pda);
		rf_RangeRestrictPDA(raidPtr, parityPDA, pda, 0, 1);
		RF_ASSERT(pda->numSector != 0);
		if (rf_TryToRedirectPDA(raidPtr, pda, 0))
			goto out;	/*
					 * No way to verify parity if disk is
					 * dead. Return w/ good status.
					 */
		blockNode->succedents[i]->params[0].p = pda;
		blockNode->succedents[i]->params[2].v = psID;
		blockNode->succedents[i]->params[3].v =
		    RF_CREATE_PARAM3(RF_IO_NORMAL_PRIORITY, 0, 0, which_ru);
	}

	RF_ASSERT(!asmap->parityInfo->next);
	rf_RangeRestrictPDA(raidPtr, parityPDA, asmap->parityInfo, 0, 1);
	RF_ASSERT(asmap->parityInfo->numSector != 0);
	if (rf_TryToRedirectPDA(raidPtr, asmap->parityInfo, 1))
		goto out;
	blockNode->succedents[layoutPtr->numDataCol]->params[0].p =
	    asmap->parityInfo;

	/* Fire off the DAG. */
	bzero(&tracerec, sizeof(tracerec));
	rd_dag_h->tracerec = &tracerec;

	if (rf_verifyParityDebug) {
		printf("Parity verify read dag:\n");
		rf_PrintDAGList(rd_dag_h);
	}
	RF_LOCK_MUTEX(mcpair->mutex);
	mcpair->flag = 0;
	rf_DispatchDAG(rd_dag_h, (void (*) (void *)) rf_MCPairWakeupFunc,
	    (void *) mcpair);
	while (!mcpair->flag)
		RF_WAIT_COND(mcpair->cond, mcpair->mutex);
	RF_UNLOCK_MUTEX(mcpair->mutex);
	if (rd_dag_h->status != rf_enable) {
		RF_ERRORMSG("Unable to verify parity:  can't read the"
		            " stripe.\n");
		retcode = RF_PARITY_COULD_NOT_VERIFY;
		goto out;
	}
	for (p = buf; p < end_p; p += numbytes) {
		rf_bxor(p, pbuf, numbytes, NULL);
	}
	for (i = 0; i < numbytes; i++) {
#if 0
		if (pbuf[i] != 0 || buf[bytesPerStripe + i] != 0) {
			printf("Bytes: %d %d %d\n", i, pbuf[i],
			    buf[bytesPerStripe + i]);
		}
#endif
		if (pbuf[i] != buf[bytesPerStripe + i]) {
			if (!correct_it)
				RF_ERRORMSG3("Parity verify error: byte %d of"
				    " parity is 0x%x should be 0x%x.\n", i,
				    (u_char) buf[bytesPerStripe + i],
				    (u_char) pbuf[i]);
			retcode = RF_PARITY_BAD;
			break;
		}
	}

	if (retcode && correct_it) {
		wr_dag_h = rf_MakeSimpleDAG(raidPtr, 1, numbytes, pbuf,
		    rf_DiskWriteFunc, rf_DiskWriteUndoFunc,
		    "Wnp", alloclist, flags, RF_IO_NORMAL_PRIORITY);
		wrBlock = wr_dag_h->succedents[0];
		wrUnblock = wrBlock->succedents[0]->succedents[0];
		wrBlock->succedents[0]->params[0].p = asmap->parityInfo;
		wrBlock->succedents[0]->params[2].v = psID;
		wrBlock->succedents[0]->params[3].v =
		    RF_CREATE_PARAM3(RF_IO_NORMAL_PRIORITY, 0, 0, which_ru);
		bzero(&tracerec, sizeof(tracerec));
		wr_dag_h->tracerec = &tracerec;
		if (rf_verifyParityDebug) {
			printf("Parity verify write dag:\n");
			rf_PrintDAGList(wr_dag_h);
		}
		RF_LOCK_MUTEX(mcpair->mutex);
		mcpair->flag = 0;
		rf_DispatchDAG(wr_dag_h, (void (*) (void *))
		    rf_MCPairWakeupFunc, (void *) mcpair);
		while (!mcpair->flag)
			RF_WAIT_COND(mcpair->cond, mcpair->mutex);
		RF_UNLOCK_MUTEX(mcpair->mutex);
		if (wr_dag_h->status != rf_enable) {
			RF_ERRORMSG("Unable to correct parity in VerifyParity:"
			    "  can't write the stripe.\n");
			retcode = RF_PARITY_COULD_NOT_CORRECT;
		}
		rf_FreeDAG(wr_dag_h);
		if (retcode == RF_PARITY_BAD)
			retcode = RF_PARITY_CORRECTED;
	}
out:
	rf_FreeAccessStripeMap(asm_h);
	rf_FreeAllocList(alloclist);
	rf_FreeDAG(rd_dag_h);
	rf_FreeMCPair(mcpair);
	return (retcode);
}

int
rf_TryToRedirectPDA(RF_Raid_t *raidPtr, RF_PhysDiskAddr_t *pda, int parity)
{
	if (raidPtr->Disks[pda->row][pda->col].status == rf_ds_reconstructing) {
		if (rf_CheckRUReconstructed(raidPtr->reconControl[pda->row]
		     ->reconMap, pda->startSector)) {
			if (raidPtr->Layout.map->flags & RF_DISTRIBUTE_SPARE) {
				RF_RowCol_t or = pda->row, oc = pda->col;
				RF_SectorNum_t os = pda->startSector;
				if (parity) {
					(raidPtr->Layout.map->MapParity)
					    (raidPtr, pda->raidAddress,
					     &pda->row, &pda->col,
					     &pda->startSector, RF_REMAP);
					if (rf_verifyParityDebug)
						printf("VerifyParity: Redir P"
						    " r %d c %d sect %ld ->"
						    " r %d c %d sect %ld.\n",
						    or, oc, (long) os,
						    pda->row, pda->col,
						    (long) pda->startSector);
				} else {
					(raidPtr->Layout.map->MapSector)
					    (raidPtr, pda->raidAddress,
					     &pda->row, &pda->col,
					     &pda->startSector, RF_REMAP);
					if (rf_verifyParityDebug)
						printf("VerifyParity: Redir D"
						    " r %d c %d sect %ld ->"
						    " r %d c %d sect %ld.\n",
						    or, oc, (long) os,
						    pda->row, pda->col,
						    (long) pda->startSector);
				}
			} else {
				RF_RowCol_t spRow =
				    raidPtr->Disks[pda->row][pda->col].spareRow;
				RF_RowCol_t spCol =
				    raidPtr->Disks[pda->row][pda->col].spareCol;
				pda->row = spRow;
				pda->col = spCol;
			}
		}
	}
	if (RF_DEAD_DISK(raidPtr->Disks[pda->row][pda->col].status))
		return (1);
	return (0);
}


/*****************************************************************************
 *
 * Currently a stub.
 *
 * Takes as input an ASM describing a write operation and containing one
 * failure, and verifies that the parity was correctly updated to reflect the
 * write.
 *
 * If it's a data unit that has failed, we read the other data units in the
 * stripe and the parity unit, XOR them together, and verify that we get the
 * data intended for the failed disk. Since it's easy, we also validate that
 * the right data got written to the surviving data disks.
 *
 * If it's the parity that failed, there's really no validation we can do
 * except the above verification that the right data got written to all disks.
 * This is because the new data intended for the failed disk is supplied in
 * the ASM, but this is of course not the case for the new parity.
 *
 *****************************************************************************/
int
rf_VerifyDegrModeWrite(RF_Raid_t *raidPtr, RF_AccessStripeMapHeader_t *asmh)
{
	return (0);
}


/*
 * Creates a simple DAG with a header, a block-recon node at level 1,
 * nNodes nodes at level 2, an unblock-recon node at level 3, and
 * a terminator node at level 4. The stripe address field in
 * the block and unblock nodes are not touched, nor are the pda
 * fields in the second-level nodes, so they must be filled in later.
 *
 * Commit point is established at unblock node - this means that any
 * failure during dag execution causes the dag to fail.
 */
RF_DagHeader_t *
rf_MakeSimpleDAG(RF_Raid_t *raidPtr, int nNodes, int bytesPerSU, char *databuf,
    int (*doFunc) (RF_DagNode_t * node), int (*undoFunc) (RF_DagNode_t * node),
    char *name	/* Node names at the second level. */,
    RF_AllocListElem_t *alloclist, RF_RaidAccessFlags_t flags, int priority)
{
	RF_DagHeader_t *dag_h;
	RF_DagNode_t *nodes, *termNode, *blockNode, *unblockNode;
	int i;

	/*
	 * Create the nodes, the block & unblock nodes, and the terminator
	 * node.
	 */
	RF_CallocAndAdd(nodes, nNodes + 3, sizeof(RF_DagNode_t),
	    (RF_DagNode_t *), alloclist);
	blockNode = &nodes[nNodes];
	unblockNode = blockNode + 1;
	termNode = unblockNode + 1;

	dag_h = rf_AllocDAGHeader();
	dag_h->raidPtr = (void *) raidPtr;
	dag_h->allocList = NULL;	/* We won't use this alloc list. */
	dag_h->status = rf_enable;
	dag_h->numSuccedents = 1;
	dag_h->creator = "SimpleDAG";

	/*
	 * This dag can not commit until the unblock node is reached.
	 * Errors prior to the commit point imply the dag has failed.
	 */
	dag_h->numCommitNodes = 1;
	dag_h->numCommits = 0;

	dag_h->succedents[0] = blockNode;
	rf_InitNode(blockNode, rf_wait, RF_FALSE, rf_NullNodeFunc,
	    rf_NullNodeUndoFunc, NULL, nNodes, 0, 0, 0, dag_h,
	    "Nil", alloclist);
	rf_InitNode(unblockNode, rf_wait, RF_TRUE, rf_NullNodeFunc,
	    rf_NullNodeUndoFunc, NULL, 1, nNodes, 0, 0, dag_h,
	    "Nil", alloclist);
	unblockNode->succedents[0] = termNode;
	for (i = 0; i < nNodes; i++) {
		blockNode->succedents[i] = unblockNode->antecedents[i]
					 = &nodes[i];
		unblockNode->antType[i] = rf_control;
		rf_InitNode(&nodes[i], rf_wait, RF_FALSE, doFunc, undoFunc,
		    rf_GenericWakeupFunc, 1, 1, 4, 0, dag_h, name, alloclist);
		nodes[i].succedents[0] = unblockNode;
		nodes[i].antecedents[0] = blockNode;
		nodes[i].antType[0] = rf_control;
		nodes[i].params[1].p = (databuf + (i * bytesPerSU));
	}
	rf_InitNode(termNode, rf_wait, RF_FALSE, rf_TerminateFunc,
	    rf_TerminateUndoFunc, NULL, 0, 1, 0, 0, dag_h, "Trm", alloclist);
	termNode->antecedents[0] = unblockNode;
	termNode->antType[0] = rf_control;
	return (dag_h);
}
@


1.8
log
@remove stupid casts, ok deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: rf_parityscan.c,v 1.7 2002/12/16 07:01:04 tdeval Exp $	*/
@


1.7
log
@Major KNF.  Incentive from Tedu
@
text
@d1 1
a1 1
/*	$OpenBSD: rf_parityscan.c,v 1.6 2000/08/08 16:07:44 peter Exp $	*/
d250 1
a250 1
	bzero((char *) &tracerec, sizeof(tracerec));
d301 1
a301 1
		bzero((char *) &tracerec, sizeof(tracerec));
@


1.6
log
@sync RAIDframe with Gre Oster's work for NetBSD.

This update incorporates changes since January 2000.

RAID1 and RAID5 tested for functionality matching the 2.7 code. A
number of bug fixes (including stopping a parity rebuild when
unconfiguring) have been included. See Greg's RAIDframe info page:

	http://www.cs.usask.ca/staff/oster/raid.html

The RAID_AUTOCONFIG feature set does *NOT* yet work. These features
require more work throughout the boot system and as such are a big
task.

IMPORTANT: As with anything that is this near live data on your
systems, please test carefully with existing configurations before
deploying in a live system.  Feedback via sendbug or mail direct
to peter@@wonderland.org is appreciated.
@
text
@d1 1
a1 1
/*	$OpenBSD: rf_parityscan.c,v 1.5 2000/01/07 14:50:22 peter Exp $	*/
d3 1
d33 1
a33 1
 * rf_parityscan.c -- misc utilities related to parity verification
d48 2
a49 1
/*****************************************************************************************
d51 1
a51 1
 * walk through the entire arry and write new parity.
d53 2
a54 2
 * write new parity.  The first is executed, the data is xored together, and
 * then the second is executed.  To avoid constantly building and tearing down
d58 1
a58 1
 * there should never be more than one thread running this.
d60 3
a62 5
 ****************************************************************************************/

int 
rf_RewriteParity(raidPtr)
	RF_Raid_t *raidPtr;
d77 3
a79 3
		 * We're in degraded mode.  Don't try to verify parity now! 
		 * XXX: this should be a "we don't want to", not a 
		 * "we can't" error. 
d90 1
a90 2
	for (i = 0; i < raidPtr->totalSectors && 
		     rc <= RF_PARITY_CORRECTED; 
d93 4
a96 2
			/* Someone is pulling the plug on this set...
			   abort the re-write */
d99 3
a101 4
		asm_h = rf_MapAccess(raidPtr, i, 
				     layoutPtr->dataSectorsPerStripe, 
				     NULL, RF_DONT_REMAP);
		raidPtr->parity_rewrite_stripes_done = 
d109 1
a109 1
			printf("Parity bad during correction\n");
d113 1
a113 1
			printf("Could not correct bad parity\n");
d117 1
a117 1
			printf("Could not verify parity\n");
d121 2
a122 1
			printf("Bad rc=%d from VerifyParity in RewriteParity\n", rc);
d129 3
a131 1
/*****************************************************************************************
d133 3
a135 3
 * verify that the parity in a particular stripe is correct.
 * we validate only the range of parity defined by parityPDA, since
 * this is all we have locked.  The way we do this is to create an asm
d139 4
a142 7
 ****************************************************************************************/
int 
rf_VerifyParity(raidPtr, aasm, correct_it, flags)
	RF_Raid_t *raidPtr;
	RF_AccessStripeMap_t *aasm;
	int     correct_it;
	RF_RaidAccessFlags_t flags;
d147 1
a147 1
	int     lrc, rc;
d152 2
a153 2
	         * There isn't any parity. Call it "okay."
	         */
d159 1
a159 1
			for (parityPDA = doasm->parityInfo; parityPDA; 
d161 3
a163 4
				lrc = lp->VerifyParity(raidPtr, 
						       doasm->raidAddress, 
						       parityPDA,
						       correct_it, flags);
d165 4
a168 2
					/* see rf_parityscan.h for why this
					 * works */
d179 3
a181 7
int 
rf_VerifyParityBasic(raidPtr, raidAddr, parityPDA, correct_it, flags)
	RF_Raid_t *raidPtr;
	RF_RaidAddr_t raidAddr;
	RF_PhysDiskAddr_t *parityPDA;
	int     correct_it;
	RF_RaidAccessFlags_t flags;
d185 1
a185 1
								     raidAddr);
d187 3
a189 3
	int     numbytes = rf_RaidAddressToByte(raidPtr, numsector);
	int     bytesPerStripe = numbytes * layoutPtr->numDataCol;
	RF_DagHeader_t *rd_dag_h, *wr_dag_h;	/* read, write dag */
d195 2
a196 2
	char   *pbuf, *buf, *end_p, *p;
	int     i, retcode;
d199 2
a200 3
							     raidAddr,
							     &which_ru);
	int     stripeWidth = layoutPtr->numDataCol + layoutPtr->numParityCol;
d208 4
a211 3
	RF_MallocAndAdd(buf, numbytes * (layoutPtr->numDataCol + layoutPtr->numParityCol), (char *), alloclist);
	RF_CallocAndAdd(pbuf, 1, numbytes, (char *), alloclist);	/* use calloc to make
									 * sure buffer is zeroed */
d214 2
a215 1
	rd_dag_h = rf_MakeSimpleDAG(raidPtr, stripeWidth, numbytes, buf, rf_DiskReadFunc, rf_DiskReadUndoFunc,
d220 3
a222 2
	/* map the stripe and fill in the PDAs in the dag */
	asm_h = rf_MapAccess(raidPtr, startAddr, layoutPtr->dataSectorsPerStripe, buf, RF_DONT_REMAP);
d225 2
a226 1
	for (pda = asmap->physInfo, i = 0; i < layoutPtr->numDataCol; i++, pda = pda->next) {
d231 4
a234 2
			goto out;	/* no way to verify parity if disk is
					 * dead.  return w/ good status */
d237 2
a238 1
		blockNode->succedents[i]->params[3].v = RF_CREATE_PARAM3(RF_IO_NORMAL_PRIORITY, 0, 0, which_ru);
d246 2
a247 1
	blockNode->succedents[layoutPtr->numDataCol]->params[0].p = asmap->parityInfo;
d249 1
a249 1
	/* fire off the DAG */
d265 2
a266 1
		RF_ERRORMSG("Unable to verify parity:  can't read the stripe\n");
d276 2
a277 1
			printf("Bytes: %d %d %d\n", i, pbuf[i], buf[bytesPerStripe + i]);
d282 4
a285 2
				RF_ERRORMSG3("Parity verify error: byte %d of parity is 0x%x should be 0x%x\n",
				    i, (u_char) buf[bytesPerStripe + i], (u_char) pbuf[i]);
d292 2
a293 1
		wr_dag_h = rf_MakeSimpleDAG(raidPtr, 1, numbytes, pbuf, rf_DiskWriteFunc, rf_DiskWriteUndoFunc,
d299 2
a300 1
		wrBlock->succedents[0]->params[3].v = RF_CREATE_PARAM3(RF_IO_NORMAL_PRIORITY, 0, 0, which_ru);
d309 2
a310 2
		rf_DispatchDAG(wr_dag_h, (void (*) (void *)) rf_MCPairWakeupFunc,
		    (void *) mcpair);
d315 2
a316 1
			RF_ERRORMSG("Unable to correct parity in VerifyParity:  can't write the stripe\n");
d331 2
a332 5
int 
rf_TryToRedirectPDA(raidPtr, pda, parity)
	RF_Raid_t *raidPtr;
	RF_PhysDiskAddr_t *pda;
	int     parity;
d335 2
a336 1
		if (rf_CheckRUReconstructed(raidPtr->reconControl[pda->row]->reconMap, pda->startSector)) {
d341 4
a344 1
					(raidPtr->Layout.map->MapParity) (raidPtr, pda->raidAddress, &pda->row, &pda->col, &pda->startSector, RF_REMAP);
d346 6
a351 2
						printf("VerifyParity: Redir P r %d c %d sect %ld -> r %d c %d sect %ld\n",
						    or, oc, (long) os, pda->row, pda->col, (long) pda->startSector);
d353 4
a356 1
					(raidPtr->Layout.map->MapSector) (raidPtr, pda->raidAddress, &pda->row, &pda->col, &pda->startSector, RF_REMAP);
d358 6
a363 2
						printf("VerifyParity: Redir D r %d c %d sect %ld -> r %d c %d sect %ld\n",
						    or, oc, (long) os, pda->row, pda->col, (long) pda->startSector);
d366 4
a369 2
				RF_RowCol_t spRow = raidPtr->Disks[pda->row][pda->col].spareRow;
				RF_RowCol_t spCol = raidPtr->Disks[pda->row][pda->col].spareCol;
d379 3
a381 1
/*****************************************************************************************
d383 1
a383 1
 * currently a stub.
d385 13
a397 2
 * takes as input an ASM describing a write operation and containing one failure, and
 * verifies that the parity was correctly updated to reflect the write.
d399 3
a401 15
 * if it's a data unit that's failed, we read the other data units in the stripe and
 * the parity unit, XOR them together, and verify that we get the data intended for
 * the failed disk.  Since it's easy, we also validate that the right data got written
 * to the surviving data disks.
 *
 * If it's the parity that failed, there's really no validation we can do except the
 * above verification that the right data got written to all disks.  This is because
 * the new data intended for the failed disk is supplied in the ASM, but this is of
 * course not the case for the new parity.
 *
 ****************************************************************************************/
int 
rf_VerifyDegrModeWrite(raidPtr, asmh)
	RF_Raid_t *raidPtr;
	RF_AccessStripeMapHeader_t *asmh;
d405 4
a408 1
/* creates a simple DAG with a header, a block-recon node at level 1,
d410 1
a410 1
 * a terminator node at level 4.  The stripe address field in
d414 2
a415 2
 * commit point is established at unblock node - this means that any
 * failure during dag execution causes the dag to fail
d418 4
a421 11
rf_MakeSimpleDAG(raidPtr, nNodes, bytesPerSU, databuf, doFunc, undoFunc, name, alloclist, flags, priority)
	RF_Raid_t *raidPtr;
	int     nNodes;
	int     bytesPerSU;
	char   *databuf;
	int     (*doFunc) (RF_DagNode_t * node);
	int     (*undoFunc) (RF_DagNode_t * node);
	char   *name;		/* node names at the second level */
	RF_AllocListElem_t *alloclist;
	RF_RaidAccessFlags_t flags;
	int     priority;
d425 1
a425 1
	int     i;
d427 6
a432 3
	/* create the nodes, the block & unblock nodes, and the terminator
	 * node */
	RF_CallocAndAdd(nodes, nNodes + 3, sizeof(RF_DagNode_t), (RF_DagNode_t *), alloclist);
d439 1
a439 1
	dag_h->allocList = NULL;/* we won't use this alloc list */
d444 4
a447 2
	/* this dag can not commit until the unblock node is reached errors
	 * prior to the commit point imply the dag has failed */
d452 6
a457 2
	rf_InitNode(blockNode, rf_wait, RF_FALSE, rf_NullNodeFunc, rf_NullNodeUndoFunc, NULL, nNodes, 0, 0, 0, dag_h, "Nil", alloclist);
	rf_InitNode(unblockNode, rf_wait, RF_TRUE, rf_NullNodeFunc, rf_NullNodeUndoFunc, NULL, 1, nNodes, 0, 0, dag_h, "Nil", alloclist);
d460 2
a461 1
		blockNode->succedents[i] = unblockNode->antecedents[i] = &nodes[i];
d463 2
a464 1
		rf_InitNode(&nodes[i], rf_wait, RF_FALSE, doFunc, undoFunc, rf_GenericWakeupFunc, 1, 1, 4, 0, dag_h, name, alloclist);
d470 2
a471 1
	rf_InitNode(termNode, rf_wait, RF_FALSE, rf_TerminateFunc, rf_TerminateUndoFunc, NULL, 0, 1, 0, 0, dag_h, "Trm", alloclist);
@


1.6.8.1
log
@sync
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
a2 1

d32 1
a32 1
 * rf_parityscan.c -- Misc utilities related to parity verification.
d47 1
a47 2

/*****************************************************************************
d49 1
a49 1
 * Walk through the entire arry and write new parity.
d51 2
a52 2
 * write new parity. The first is executed, the data is xored together, and
 * then the second is executed. To avoid constantly building and tearing down
d56 1
a56 1
 * There should never be more than one thread running this.
d58 5
a62 3
 *****************************************************************************/
int
rf_RewriteParity(RF_Raid_t *raidPtr)
d77 3
a79 3
		 * We're in degraded mode. Don't try to verify parity now !
		 * XXX: This should be a "we don't want to", not a
		 * "we can't" error.
d90 2
a91 1
	for (i = 0; i < raidPtr->totalSectors && rc <= RF_PARITY_CORRECTED;
d94 2
a95 4
			/*
			 * Someone is pulling the plug on this set...
			 * Abort the re-write.
			 */
d98 4
a101 3
		asm_h = rf_MapAccess(raidPtr, i,
		    layoutPtr->dataSectorsPerStripe, NULL, RF_DONT_REMAP);
		raidPtr->parity_rewrite_stripes_done =
d109 1
a109 1
			printf("Parity bad during correction.\n");
d113 1
a113 1
			printf("Could not correct bad parity.\n");
d117 1
a117 1
			printf("Could not verify parity.\n");
d121 1
a121 2
			printf("Bad rc=%d from VerifyParity in"
			    " RewriteParity.\n", rc);
d128 1
a128 3


/*****************************************************************************
d130 3
a132 3
 * Verify that the parity in a particular stripe is correct.
 * We validate only the range of parity defined by parityPDA, since
 * this is all we have locked. The way we do this is to create an asm
d136 7
a142 4
 *****************************************************************************/
int
rf_VerifyParity(RF_Raid_t *raidPtr, RF_AccessStripeMap_t *aasm, int correct_it,
    RF_RaidAccessFlags_t flags)
d147 1
a147 1
	int lrc, rc;
d152 2
a153 2
		 * There isn't any parity. Call it "okay."
		 */
d159 1
a159 1
			for (parityPDA = doasm->parityInfo; parityPDA;
d161 4
a164 3
				lrc = lp->VerifyParity(raidPtr,
				    doasm->raidAddress, parityPDA, correct_it,
				    flags);
d166 2
a167 4
					/*
					 * see rf_parityscan.h for why this
					 * works.
					 */
d178 7
a184 3
int
rf_VerifyParityBasic(RF_Raid_t *raidPtr, RF_RaidAddr_t raidAddr,
    RF_PhysDiskAddr_t *parityPDA, int correct_it, RF_RaidAccessFlags_t flags)
d188 1
a188 1
	    raidAddr);
d190 3
a192 3
	int numbytes = rf_RaidAddressToByte(raidPtr, numsector);
	int bytesPerStripe = numbytes * layoutPtr->numDataCol;
	RF_DagHeader_t *rd_dag_h, *wr_dag_h;	/* Read, write dag. */
d198 2
a199 2
	char *pbuf, *buf, *end_p, *p;
	int i, retcode;
d202 3
a204 2
	    raidAddr, &which_ru);
	int stripeWidth = layoutPtr->numDataCol + layoutPtr->numParityCol;
d212 3
a214 4
	RF_MallocAndAdd(buf, numbytes * (layoutPtr->numDataCol +
	    layoutPtr->numParityCol), (char *), alloclist);
	/* Use calloc to make sure buffer is zeroed. */
	RF_CallocAndAdd(pbuf, 1, numbytes, (char *), alloclist);
d217 1
a217 2
	rd_dag_h = rf_MakeSimpleDAG(raidPtr, stripeWidth, numbytes, buf,
	    rf_DiskReadFunc, rf_DiskReadUndoFunc,
d222 2
a223 3
	/* Map the stripe and fill in the PDAs in the dag. */
	asm_h = rf_MapAccess(raidPtr, startAddr,
	    layoutPtr->dataSectorsPerStripe, buf, RF_DONT_REMAP);
d226 1
a226 2
	for (pda = asmap->physInfo, i = 0; i < layoutPtr->numDataCol;
	     i++, pda = pda->next) {
d231 2
a232 4
			goto out;	/*
					 * No way to verify parity if disk is
					 * dead. Return w/ good status.
					 */
d235 1
a235 2
		blockNode->succedents[i]->params[3].v =
		    RF_CREATE_PARAM3(RF_IO_NORMAL_PRIORITY, 0, 0, which_ru);
d243 1
a243 2
	blockNode->succedents[layoutPtr->numDataCol]->params[0].p =
	    asmap->parityInfo;
d245 1
a245 1
	/* Fire off the DAG. */
d261 1
a261 2
		RF_ERRORMSG("Unable to verify parity:  can't read the"
		            " stripe.\n");
d271 1
a271 2
			printf("Bytes: %d %d %d\n", i, pbuf[i],
			    buf[bytesPerStripe + i]);
d276 2
a277 4
				RF_ERRORMSG3("Parity verify error: byte %d of"
				    " parity is 0x%x should be 0x%x.\n", i,
				    (u_char) buf[bytesPerStripe + i],
				    (u_char) pbuf[i]);
d284 1
a284 2
		wr_dag_h = rf_MakeSimpleDAG(raidPtr, 1, numbytes, pbuf,
		    rf_DiskWriteFunc, rf_DiskWriteUndoFunc,
d290 1
a290 2
		wrBlock->succedents[0]->params[3].v =
		    RF_CREATE_PARAM3(RF_IO_NORMAL_PRIORITY, 0, 0, which_ru);
d299 2
a300 2
		rf_DispatchDAG(wr_dag_h, (void (*) (void *))
		    rf_MCPairWakeupFunc, (void *) mcpair);
d305 1
a305 2
			RF_ERRORMSG("Unable to correct parity in VerifyParity:"
			    "  can't write the stripe.\n");
d320 5
a324 2
int
rf_TryToRedirectPDA(RF_Raid_t *raidPtr, RF_PhysDiskAddr_t *pda, int parity)
d327 1
a327 2
		if (rf_CheckRUReconstructed(raidPtr->reconControl[pda->row]
		     ->reconMap, pda->startSector)) {
d332 1
a332 4
					(raidPtr->Layout.map->MapParity)
					    (raidPtr, pda->raidAddress,
					     &pda->row, &pda->col,
					     &pda->startSector, RF_REMAP);
d334 2
a335 6
						printf("VerifyParity: Redir P"
						    " r %d c %d sect %ld ->"
						    " r %d c %d sect %ld.\n",
						    or, oc, (long) os,
						    pda->row, pda->col,
						    (long) pda->startSector);
d337 1
a337 4
					(raidPtr->Layout.map->MapSector)
					    (raidPtr, pda->raidAddress,
					     &pda->row, &pda->col,
					     &pda->startSector, RF_REMAP);
d339 2
a340 6
						printf("VerifyParity: Redir D"
						    " r %d c %d sect %ld ->"
						    " r %d c %d sect %ld.\n",
						    or, oc, (long) os,
						    pda->row, pda->col,
						    (long) pda->startSector);
d343 2
a344 4
				RF_RowCol_t spRow =
				    raidPtr->Disks[pda->row][pda->col].spareRow;
				RF_RowCol_t spCol =
				    raidPtr->Disks[pda->row][pda->col].spareCol;
d354 1
a354 3


/*****************************************************************************
d356 1
a356 1
 * Currently a stub.
d358 2
a359 13
 * Takes as input an ASM describing a write operation and containing one
 * failure, and verifies that the parity was correctly updated to reflect the
 * write.
 *
 * If it's a data unit that has failed, we read the other data units in the
 * stripe and the parity unit, XOR them together, and verify that we get the
 * data intended for the failed disk. Since it's easy, we also validate that
 * the right data got written to the surviving data disks.
 *
 * If it's the parity that failed, there's really no validation we can do
 * except the above verification that the right data got written to all disks.
 * This is because the new data intended for the failed disk is supplied in
 * the ASM, but this is of course not the case for the new parity.
d361 15
a375 3
 *****************************************************************************/
int
rf_VerifyDegrModeWrite(RF_Raid_t *raidPtr, RF_AccessStripeMapHeader_t *asmh)
d379 1
a379 4


/*
 * Creates a simple DAG with a header, a block-recon node at level 1,
d381 1
a381 1
 * a terminator node at level 4. The stripe address field in
d385 2
a386 2
 * Commit point is established at unblock node - this means that any
 * failure during dag execution causes the dag to fail.
d389 11
a399 4
rf_MakeSimpleDAG(RF_Raid_t *raidPtr, int nNodes, int bytesPerSU, char *databuf,
    int (*doFunc) (RF_DagNode_t * node), int (*undoFunc) (RF_DagNode_t * node),
    char *name	/* Node names at the second level. */,
    RF_AllocListElem_t *alloclist, RF_RaidAccessFlags_t flags, int priority)
d403 1
a403 1
	int i;
d405 3
a407 6
	/*
	 * Create the nodes, the block & unblock nodes, and the terminator
	 * node.
	 */
	RF_CallocAndAdd(nodes, nNodes + 3, sizeof(RF_DagNode_t),
	    (RF_DagNode_t *), alloclist);
d414 1
a414 1
	dag_h->allocList = NULL;	/* We won't use this alloc list. */
d419 2
a420 4
	/*
	 * This dag can not commit until the unblock node is reached.
	 * Errors prior to the commit point imply the dag has failed.
	 */
d425 2
a426 6
	rf_InitNode(blockNode, rf_wait, RF_FALSE, rf_NullNodeFunc,
	    rf_NullNodeUndoFunc, NULL, nNodes, 0, 0, 0, dag_h,
	    "Nil", alloclist);
	rf_InitNode(unblockNode, rf_wait, RF_TRUE, rf_NullNodeFunc,
	    rf_NullNodeUndoFunc, NULL, 1, nNodes, 0, 0, dag_h,
	    "Nil", alloclist);
d429 1
a429 2
		blockNode->succedents[i] = unblockNode->antecedents[i]
					 = &nodes[i];
d431 1
a431 2
		rf_InitNode(&nodes[i], rf_wait, RF_FALSE, doFunc, undoFunc,
		    rf_GenericWakeupFunc, 1, 1, 4, 0, dag_h, name, alloclist);
d437 1
a437 2
	rf_InitNode(termNode, rf_wait, RF_FALSE, rf_TerminateFunc,
	    rf_TerminateUndoFunc, NULL, 0, 1, 0, 0, dag_h, "Trm", alloclist);
@


1.5
log
@sync with work by Greg Oster on NetBSD

Please note: This update has *only* been tested on i386 with IDE
disks. Could someone with a spare box please make sure all is OK with
SCSI and maybe other arches ? sparc testing will follow locally.

* remove rf_sys.h
* many changes to make it more stable
* some performance increases
* All raid threads now get their own kernel process and the calling
  raidctl(8) program will show status progress through a meter.
* In theory FFS_SOFTUPDATES and RAIDframe will now work together - NOT
  TESTED YET

See http://www.cs.usask.ca/staff/oster/raid.html

This updates include Greg's changes to Jan 4th 2000.

TODO:
* some odd behaviour when running raictl -c on an already config'ed
  raid set - problem founf, fix being done
* progress meter is in raidctl(8) - seperate commit, but could do with
  sync'ing with OpenBSD ftp version
@
text
@d1 2
a2 2
/*	$OpenBSD: rf_parityscan.c,v 1.4 1999/07/30 14:45:33 peter Exp $	*/
/*	$NetBSD: rf_parityscan.c,v 1.8 2000/01/05 02:57:28 oster Exp $	*/
d93 5
@


1.5.2.1
log
@merge in approximately 2.9 into SMP branch
@
text
@d1 2
a2 2
/*	$OpenBSD: rf_parityscan.c,v 1.6 2000/08/08 16:07:44 peter Exp $	*/
/*	$NetBSD: rf_parityscan.c,v 1.9 2000/05/28 03:00:31 oster Exp $	*/
a92 5
		if (raidPtr->waitShutdown) {
			/* Someone is pulling the plug on this set...
			   abort the re-write */
			return (1);
		}
@


1.5.2.2
log
@Sync the SMP branch with 3.3
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
a2 1

d32 1
a32 1
 * rf_parityscan.c -- Misc utilities related to parity verification.
d47 1
a47 2

/*****************************************************************************
d49 1
a49 1
 * Walk through the entire arry and write new parity.
d51 2
a52 2
 * write new parity. The first is executed, the data is xored together, and
 * then the second is executed. To avoid constantly building and tearing down
d56 1
a56 1
 * There should never be more than one thread running this.
d58 5
a62 3
 *****************************************************************************/
int
rf_RewriteParity(RF_Raid_t *raidPtr)
d77 3
a79 3
		 * We're in degraded mode. Don't try to verify parity now !
		 * XXX: This should be a "we don't want to", not a
		 * "we can't" error.
d90 2
a91 1
	for (i = 0; i < raidPtr->totalSectors && rc <= RF_PARITY_CORRECTED;
d94 2
a95 4
			/*
			 * Someone is pulling the plug on this set...
			 * Abort the re-write.
			 */
d98 4
a101 3
		asm_h = rf_MapAccess(raidPtr, i,
		    layoutPtr->dataSectorsPerStripe, NULL, RF_DONT_REMAP);
		raidPtr->parity_rewrite_stripes_done =
d109 1
a109 1
			printf("Parity bad during correction.\n");
d113 1
a113 1
			printf("Could not correct bad parity.\n");
d117 1
a117 1
			printf("Could not verify parity.\n");
d121 1
a121 2
			printf("Bad rc=%d from VerifyParity in"
			    " RewriteParity.\n", rc);
d128 1
a128 3


/*****************************************************************************
d130 3
a132 3
 * Verify that the parity in a particular stripe is correct.
 * We validate only the range of parity defined by parityPDA, since
 * this is all we have locked. The way we do this is to create an asm
d136 7
a142 4
 *****************************************************************************/
int
rf_VerifyParity(RF_Raid_t *raidPtr, RF_AccessStripeMap_t *aasm, int correct_it,
    RF_RaidAccessFlags_t flags)
d147 1
a147 1
	int lrc, rc;
d152 2
a153 2
		 * There isn't any parity. Call it "okay."
		 */
d159 1
a159 1
			for (parityPDA = doasm->parityInfo; parityPDA;
d161 4
a164 3
				lrc = lp->VerifyParity(raidPtr,
				    doasm->raidAddress, parityPDA, correct_it,
				    flags);
d166 2
a167 4
					/*
					 * see rf_parityscan.h for why this
					 * works.
					 */
d178 7
a184 3
int
rf_VerifyParityBasic(RF_Raid_t *raidPtr, RF_RaidAddr_t raidAddr,
    RF_PhysDiskAddr_t *parityPDA, int correct_it, RF_RaidAccessFlags_t flags)
d188 1
a188 1
	    raidAddr);
d190 3
a192 3
	int numbytes = rf_RaidAddressToByte(raidPtr, numsector);
	int bytesPerStripe = numbytes * layoutPtr->numDataCol;
	RF_DagHeader_t *rd_dag_h, *wr_dag_h;	/* Read, write dag. */
d198 2
a199 2
	char *pbuf, *buf, *end_p, *p;
	int i, retcode;
d202 3
a204 2
	    raidAddr, &which_ru);
	int stripeWidth = layoutPtr->numDataCol + layoutPtr->numParityCol;
d212 3
a214 4
	RF_MallocAndAdd(buf, numbytes * (layoutPtr->numDataCol +
	    layoutPtr->numParityCol), (char *), alloclist);
	/* Use calloc to make sure buffer is zeroed. */
	RF_CallocAndAdd(pbuf, 1, numbytes, (char *), alloclist);
d217 1
a217 2
	rd_dag_h = rf_MakeSimpleDAG(raidPtr, stripeWidth, numbytes, buf,
	    rf_DiskReadFunc, rf_DiskReadUndoFunc,
d222 2
a223 3
	/* Map the stripe and fill in the PDAs in the dag. */
	asm_h = rf_MapAccess(raidPtr, startAddr,
	    layoutPtr->dataSectorsPerStripe, buf, RF_DONT_REMAP);
d226 1
a226 2
	for (pda = asmap->physInfo, i = 0; i < layoutPtr->numDataCol;
	     i++, pda = pda->next) {
d231 2
a232 4
			goto out;	/*
					 * No way to verify parity if disk is
					 * dead. Return w/ good status.
					 */
d235 1
a235 2
		blockNode->succedents[i]->params[3].v =
		    RF_CREATE_PARAM3(RF_IO_NORMAL_PRIORITY, 0, 0, which_ru);
d243 1
a243 2
	blockNode->succedents[layoutPtr->numDataCol]->params[0].p =
	    asmap->parityInfo;
d245 1
a245 1
	/* Fire off the DAG. */
d261 1
a261 2
		RF_ERRORMSG("Unable to verify parity:  can't read the"
		            " stripe.\n");
d271 1
a271 2
			printf("Bytes: %d %d %d\n", i, pbuf[i],
			    buf[bytesPerStripe + i]);
d276 2
a277 4
				RF_ERRORMSG3("Parity verify error: byte %d of"
				    " parity is 0x%x should be 0x%x.\n", i,
				    (u_char) buf[bytesPerStripe + i],
				    (u_char) pbuf[i]);
d284 1
a284 2
		wr_dag_h = rf_MakeSimpleDAG(raidPtr, 1, numbytes, pbuf,
		    rf_DiskWriteFunc, rf_DiskWriteUndoFunc,
d290 1
a290 2
		wrBlock->succedents[0]->params[3].v =
		    RF_CREATE_PARAM3(RF_IO_NORMAL_PRIORITY, 0, 0, which_ru);
d299 2
a300 2
		rf_DispatchDAG(wr_dag_h, (void (*) (void *))
		    rf_MCPairWakeupFunc, (void *) mcpair);
d305 1
a305 2
			RF_ERRORMSG("Unable to correct parity in VerifyParity:"
			    "  can't write the stripe.\n");
d320 5
a324 2
int
rf_TryToRedirectPDA(RF_Raid_t *raidPtr, RF_PhysDiskAddr_t *pda, int parity)
d327 1
a327 2
		if (rf_CheckRUReconstructed(raidPtr->reconControl[pda->row]
		     ->reconMap, pda->startSector)) {
d332 1
a332 4
					(raidPtr->Layout.map->MapParity)
					    (raidPtr, pda->raidAddress,
					     &pda->row, &pda->col,
					     &pda->startSector, RF_REMAP);
d334 2
a335 6
						printf("VerifyParity: Redir P"
						    " r %d c %d sect %ld ->"
						    " r %d c %d sect %ld.\n",
						    or, oc, (long) os,
						    pda->row, pda->col,
						    (long) pda->startSector);
d337 1
a337 4
					(raidPtr->Layout.map->MapSector)
					    (raidPtr, pda->raidAddress,
					     &pda->row, &pda->col,
					     &pda->startSector, RF_REMAP);
d339 2
a340 6
						printf("VerifyParity: Redir D"
						    " r %d c %d sect %ld ->"
						    " r %d c %d sect %ld.\n",
						    or, oc, (long) os,
						    pda->row, pda->col,
						    (long) pda->startSector);
d343 2
a344 4
				RF_RowCol_t spRow =
				    raidPtr->Disks[pda->row][pda->col].spareRow;
				RF_RowCol_t spCol =
				    raidPtr->Disks[pda->row][pda->col].spareCol;
d354 1
a354 3


/*****************************************************************************
d356 1
a356 1
 * Currently a stub.
d358 2
a359 13
 * Takes as input an ASM describing a write operation and containing one
 * failure, and verifies that the parity was correctly updated to reflect the
 * write.
 *
 * If it's a data unit that has failed, we read the other data units in the
 * stripe and the parity unit, XOR them together, and verify that we get the
 * data intended for the failed disk. Since it's easy, we also validate that
 * the right data got written to the surviving data disks.
 *
 * If it's the parity that failed, there's really no validation we can do
 * except the above verification that the right data got written to all disks.
 * This is because the new data intended for the failed disk is supplied in
 * the ASM, but this is of course not the case for the new parity.
d361 15
a375 3
 *****************************************************************************/
int
rf_VerifyDegrModeWrite(RF_Raid_t *raidPtr, RF_AccessStripeMapHeader_t *asmh)
d379 1
a379 4


/*
 * Creates a simple DAG with a header, a block-recon node at level 1,
d381 1
a381 1
 * a terminator node at level 4. The stripe address field in
d385 2
a386 2
 * Commit point is established at unblock node - this means that any
 * failure during dag execution causes the dag to fail.
d389 11
a399 4
rf_MakeSimpleDAG(RF_Raid_t *raidPtr, int nNodes, int bytesPerSU, char *databuf,
    int (*doFunc) (RF_DagNode_t * node), int (*undoFunc) (RF_DagNode_t * node),
    char *name	/* Node names at the second level. */,
    RF_AllocListElem_t *alloclist, RF_RaidAccessFlags_t flags, int priority)
d403 1
a403 1
	int i;
d405 3
a407 6
	/*
	 * Create the nodes, the block & unblock nodes, and the terminator
	 * node.
	 */
	RF_CallocAndAdd(nodes, nNodes + 3, sizeof(RF_DagNode_t),
	    (RF_DagNode_t *), alloclist);
d414 1
a414 1
	dag_h->allocList = NULL;	/* We won't use this alloc list. */
d419 2
a420 4
	/*
	 * This dag can not commit until the unblock node is reached.
	 * Errors prior to the commit point imply the dag has failed.
	 */
d425 2
a426 6
	rf_InitNode(blockNode, rf_wait, RF_FALSE, rf_NullNodeFunc,
	    rf_NullNodeUndoFunc, NULL, nNodes, 0, 0, 0, dag_h,
	    "Nil", alloclist);
	rf_InitNode(unblockNode, rf_wait, RF_TRUE, rf_NullNodeFunc,
	    rf_NullNodeUndoFunc, NULL, 1, nNodes, 0, 0, dag_h,
	    "Nil", alloclist);
d429 1
a429 2
		blockNode->succedents[i] = unblockNode->antecedents[i]
					 = &nodes[i];
d431 1
a431 2
		rf_InitNode(&nodes[i], rf_wait, RF_FALSE, doFunc, undoFunc,
		    rf_GenericWakeupFunc, 1, 1, 4, 0, dag_h, name, alloclist);
d437 1
a437 2
	rf_InitNode(termNode, rf_wait, RF_FALSE, rf_TerminateFunc,
	    rf_TerminateUndoFunc, NULL, 0, 1, 0, 0, dag_h, "Trm", alloclist);
@


1.4
log
@Update RAIDframe from NetBSD-current as of 1999/07/26.

Please note that you *must* follow the upgrade instructions at

	http://www.cs.usask.ca/staff/oster/clabel_upgrade.html

before installing the new raidctl and new kernel using this code.
@
text
@d1 2
a2 2
/*	$OpenBSD: rf_parityscan.c,v 1.3 1999/03/02 21:53:50 niklas Exp $	*/
/*	$NetBSD: rf_parityscan.c,v 1.4 1999/03/14 22:10:46 oster Exp $	*/
a45 1
#include "rf_sys.h"
d66 1
d71 15
d88 1
d90 2
a91 1
	for (i = 0; i < raidPtr->totalSectors; 
d96 2
d105 1
a105 1
			RF_PANIC();
d109 1
a109 1
			RF_PANIC();
d113 1
a113 1
			RF_PANIC();
d117 1
a117 1
			RF_PANIC();
d121 1
a121 1
	return (0);
@


1.3
log
@Remove 3 bad panic cases, which should just report an error up
to the caller.  This fixes some cases of panics due to SCSI errors.
@
text
@d1 2
a2 2
/*	$OpenBSD: rf_parityscan.c,v 1.2 1999/02/16 00:03:09 niklas Exp $	*/
/*	$NetBSD: rf_parityscan.c,v 1.3 1999/02/05 00:06:14 oster Exp $	*/
d67 1
a67 1
	int     old_pctg, new_pctg, rc;
a72 1
	old_pctg = -1;
d74 5
a78 3
/* rf_verifyParityDebug=1; */
	for (i = 0; i < raidPtr->totalSectors; i += layoutPtr->dataSectorsPerStripe) {
		asm_h = rf_MapAccess(raidPtr, i, layoutPtr->dataSectorsPerStripe, NULL, RF_DONT_REMAP);
a79 1
		/* printf("Parity verified: rc=%d\n",rc); */
d86 1
a86 1
			return (1);
d90 1
a90 1
			return (1);
d94 1
a94 1
			return (1);
a100 4
		new_pctg = i * 1000 / raidPtr->totalSectors;
		if (new_pctg != old_pctg) {
		}
		old_pctg = new_pctg;
d102 1
a102 3
#if 1
	return (0);		/* XXX nothing was here.. GO */
#endif
d135 6
a140 3
			for (parityPDA = doasm->parityInfo; parityPDA; parityPDA = parityPDA->next) {
				lrc = lp->VerifyParity(raidPtr, doasm->raidAddress, parityPDA,
				    correct_it, flags);
d163 2
a164 1
	RF_RaidAddr_t startAddr = rf_RaidAddressOfPrevStripeBoundary(layoutPtr, raidAddr);
d177 3
a179 1
	RF_StripeNum_t psID = rf_RaidAddressToParityStripeID(layoutPtr, raidAddr, &which_ru);
@


1.2
log
@Merge from NetBSD, mostly indentation
@
text
@d1 1
a1 1
/*	$OpenBSD: rf_parityscan.c,v 1.1 1999/01/11 14:29:37 niklas Exp $	*/
d86 1
a86 1
			RF_PANIC();
d90 1
a90 1
			RF_PANIC();
d94 1
a94 1
			RF_PANIC();
@


1.1
log
@Import of CMU's RAIDframe via NetBSD.
@
text
@d1 2
a2 2
/*	$OpenBSD: rf_parityscan.c,v 1.1 1998/11/13 04:20:32 oster Exp $	*/
/*	$NetBSD: rf_parityscan.c,v 1.1 1998/11/13 04:20:32 oster Exp $	*/
a35 135
/*
 * :  
 * Log: rf_parityscan.c,v 
 * Revision 1.47  1996/08/20 20:35:01  jimz
 * change diagnostic string in rewrite
 *
 * Revision 1.46  1996/08/20  20:03:19  jimz
 * fixed parity rewrite to actually use arch-specific parity stuff
 * (this ever worked... how?)
 *
 * Revision 1.45  1996/08/16  17:41:25  jimz
 * allow rewrite parity on any fault-tolerant arch
 *
 * Revision 1.44  1996/07/28  20:31:39  jimz
 * i386netbsd port
 * true/false fixup
 *
 * Revision 1.43  1996/07/27  23:36:08  jimz
 * Solaris port of simulator
 *
 * Revision 1.42  1996/07/22  21:12:01  jimz
 * clean up parity scan status printing
 *
 * Revision 1.41  1996/07/22  19:52:16  jimz
 * switched node params to RF_DagParam_t, a union of
 * a 64-bit int and a void *, for better portability
 * attempted hpux port, but failed partway through for
 * lack of a single C compiler capable of compiling all
 * source files
 *
 * Revision 1.40  1996/07/13  00:00:59  jimz
 * sanitized generalized reconstruction architecture
 * cleaned up head sep, rbuf problems
 *
 * Revision 1.39  1996/07/09  21:44:26  jimz
 * fix bogus return code in VerifyParityBasic when a stripe can't be corrected
 *
 * Revision 1.38  1996/06/20  17:56:57  jimz
 * update VerifyParity to check complete AccessStripeMaps
 *
 * Revision 1.37  1996/06/19  22:23:01  jimz
 * parity verification is now a layout-configurable thing
 * not all layouts currently support it (correctly, anyway)
 *
 * Revision 1.36  1996/06/09  02:36:46  jimz
 * lots of little crufty cleanup- fixup whitespace
 * issues, comment #ifdefs, improve typing in some
 * places (esp size-related)
 *
 * Revision 1.35  1996/06/07  22:26:27  jimz
 * type-ify which_ru (RF_ReconUnitNum_t)
 *
 * Revision 1.34  1996/06/07  21:33:04  jimz
 * begin using consistent types for sector numbers,
 * stripe numbers, row+col numbers, recon unit numbers
 *
 * Revision 1.33  1996/06/05  18:06:02  jimz
 * Major code cleanup. The Great Renaming is now done.
 * Better modularity. Better typing. Fixed a bunch of
 * synchronization bugs. Made a lot of global stuff
 * per-desc or per-array. Removed dead code.
 *
 * Revision 1.32  1996/06/02  17:31:48  jimz
 * Moved a lot of global stuff into array structure, where it belongs.
 * Fixed up paritylogging, pss modules in this manner. Some general
 * code cleanup. Removed lots of dead code, some dead files.
 *
 * Revision 1.31  1996/05/31  22:26:54  jimz
 * fix a lot of mapping problems, memory allocation problems
 * found some weird lock issues, fixed 'em
 * more code cleanup
 *
 * Revision 1.30  1996/05/30  23:22:16  jimz
 * bugfixes of serialization, timing problems
 * more cleanup
 *
 * Revision 1.29  1996/05/30  12:59:18  jimz
 * make etimer happier, more portable
 *
 * Revision 1.28  1996/05/30  11:29:41  jimz
 * Numerous bug fixes. Stripe lock release code disagreed with the taking code
 * about when stripes should be locked (I made it consistent: no parity, no lock)
 * There was a lot of extra serialization of I/Os which I've removed- a lot of
 * it was to calculate values for the cache code, which is no longer with us.
 * More types, function, macro cleanup. Added code to properly quiesce the array
 * on shutdown. Made a lot of stuff array-specific which was (bogusly) general
 * before. Fixed memory allocation, freeing bugs.
 *
 * Revision 1.27  1996/05/27  18:56:37  jimz
 * more code cleanup
 * better typing
 * compiles in all 3 environments
 *
 * Revision 1.26  1996/05/24  22:17:04  jimz
 * continue code + namespace cleanup
 * typed a bunch of flags
 *
 * Revision 1.25  1996/05/24  04:28:55  jimz
 * release cleanup ckpt
 *
 * Revision 1.24  1996/05/23  21:46:35  jimz
 * checkpoint in code cleanup (release prep)
 * lots of types, function names have been fixed
 *
 * Revision 1.23  1996/05/23  00:33:23  jimz
 * code cleanup: move all debug decls to rf_options.c, all extern
 * debug decls to rf_options.h, all debug vars preceded by rf_
 *
 * Revision 1.22  1996/05/18  19:51:34  jimz
 * major code cleanup- fix syntax, make some types consistent,
 * add prototypes, clean out dead code, et cetera
 *
 * Revision 1.21  1996/05/08  21:01:24  jimz
 * fixed up enum type names that were conflicting with other
 * enums and function names (ie, "panic")
 * future naming trends will be towards RF_ and rf_ for
 * everything raidframe-related
 *
 * Revision 1.20  1995/12/12  18:10:06  jimz
 * MIN -> RF_MIN, MAX -> RF_MAX, ASSERT -> RF_ASSERT
 * fix 80-column brain damage in comments
 *
 * Revision 1.19  1995/11/30  16:16:49  wvcii
 * added copyright info
 *
 * Revision 1.18  1995/11/19  16:32:19  wvcii
 * eliminated initialization of dag header fields which no longer exist
 * (numDags, numDagsDone, firstHdr)
 *
 * Revision 1.17  1995/11/07  16:23:36  wvcii
 * added comments, asserts, and prototypes
 * encoded commit point nodes, barrier, and antecedents types into dags
 *
 */

d61 3
a63 2
int rf_RewriteParity(raidPtr)
  RF_Raid_t  *raidPtr;
d65 9
a73 9
  RF_RaidLayout_t *layoutPtr = &raidPtr->Layout;
  RF_AccessStripeMapHeader_t *asm_h;
  int old_pctg, new_pctg, rc;
  RF_PhysDiskAddr_t pda;
  RF_SectorNum_t i;

  pda.startSector = 0;
  pda.numSector   = raidPtr->Layout.sectorsPerStripeUnit;
  old_pctg = -1;
d76 30
a105 38
  for (i=0; i<raidPtr->totalSectors; i+=layoutPtr->dataSectorsPerStripe) {
    asm_h = rf_MapAccess(raidPtr, i, layoutPtr->dataSectorsPerStripe, NULL, RF_DONT_REMAP);
    rc = rf_VerifyParity(raidPtr, asm_h->stripeMap, 1, 0);
    /*     printf("Parity verified: rc=%d\n",rc); */
    switch (rc) {
      case RF_PARITY_OKAY:
      case RF_PARITY_CORRECTED:
        break;
      case RF_PARITY_BAD:
        printf("Parity bad during correction\n");
        RF_PANIC();
        break;
      case RF_PARITY_COULD_NOT_CORRECT:
        printf("Could not correct bad parity\n");
        RF_PANIC();
        break;
      case RF_PARITY_COULD_NOT_VERIFY:
        printf("Could not verify parity\n");
        RF_PANIC();
        break;
      default:
        printf("Bad rc=%d from VerifyParity in RewriteParity\n", rc);
        RF_PANIC();
    }
    rf_FreeAccessStripeMap(asm_h);
    new_pctg = i*1000/raidPtr->totalSectors;
    if (new_pctg != old_pctg) {
#ifndef KERNEL
      fprintf(stderr,"\rParity rewrite: %d.%d%% complete",
        new_pctg/10, new_pctg%10);
      fflush(stderr);
#endif /* !KERNEL */
    }
    old_pctg = new_pctg;
  }
#ifndef KERNEL
  fprintf(stderr,"\rParity rewrite: 100.0%% complete\n");
#endif /* !KERNEL */
d107 1
a107 1
  return(0); /* XXX nothing was here.. GO */
a109 1

d119 6
a124 5
int rf_VerifyParity(raidPtr, aasm, correct_it, flags)
  RF_Raid_t             *raidPtr;
  RF_AccessStripeMap_t  *aasm;
  int                    correct_it;
  RF_RaidAccessFlags_t   flags;
d126 29
a154 29
  RF_PhysDiskAddr_t *parityPDA;
  RF_AccessStripeMap_t *doasm;
  RF_LayoutSW_t *lp;
  int lrc, rc;

  lp = raidPtr->Layout.map;
  if (lp->faultsTolerated == 0) {
    /*
     * There isn't any parity. Call it "okay."
     */
    return(RF_PARITY_OKAY);
  }
  rc = RF_PARITY_OKAY;
  if (lp->VerifyParity) {
    for(doasm=aasm;doasm;doasm=doasm->next) {
      for(parityPDA=doasm->parityInfo;parityPDA;parityPDA=parityPDA->next) {
        lrc = lp->VerifyParity(raidPtr, doasm->raidAddress, parityPDA,
          correct_it, flags);
        if (lrc > rc) {
          /* see rf_parityscan.h for why this works */
          rc = lrc;
        }
      }
    }
  }
  else {
    rc = RF_PARITY_COULD_NOT_VERIFY;
  }
  return(rc);
d157 7
a163 6
int rf_VerifyParityBasic(raidPtr, raidAddr, parityPDA, correct_it, flags)
  RF_Raid_t             *raidPtr;
  RF_RaidAddr_t          raidAddr;
  RF_PhysDiskAddr_t     *parityPDA;
  int                    correct_it;
  RF_RaidAccessFlags_t   flags;
d165 80
a244 79
  RF_RaidLayout_t *layoutPtr = &(raidPtr->Layout);
  RF_RaidAddr_t startAddr = rf_RaidAddressOfPrevStripeBoundary(layoutPtr, raidAddr);
  RF_SectorCount_t numsector = parityPDA->numSector;
  int numbytes  = rf_RaidAddressToByte(raidPtr, numsector);
  int bytesPerStripe = numbytes * layoutPtr->numDataCol;
  RF_DagHeader_t *rd_dag_h, *wr_dag_h;          /* read, write dag */
  RF_DagNode_t *blockNode, *unblockNode, *wrBlock, *wrUnblock;
  RF_AccessStripeMapHeader_t *asm_h;
  RF_AccessStripeMap_t *asmap;
  RF_AllocListElem_t *alloclist;
  RF_PhysDiskAddr_t *pda;
  char *pbuf, *buf, *end_p, *p;
  int i, retcode;
  RF_ReconUnitNum_t which_ru;
  RF_StripeNum_t psID = rf_RaidAddressToParityStripeID(layoutPtr, raidAddr, &which_ru);
  int stripeWidth = layoutPtr->numDataCol + layoutPtr->numParityCol;
  RF_AccTraceEntry_t tracerec;
  RF_MCPair_t *mcpair;

  retcode = RF_PARITY_OKAY;

  mcpair = rf_AllocMCPair();
  rf_MakeAllocList(alloclist);
  RF_MallocAndAdd(buf, numbytes * (layoutPtr->numDataCol + layoutPtr->numParityCol), (char *), alloclist);
  RF_CallocAndAdd(pbuf, 1, numbytes, (char *), alloclist);     /* use calloc to make sure buffer is zeroed */
  end_p = buf + bytesPerStripe;

  rd_dag_h = rf_MakeSimpleDAG(raidPtr, stripeWidth, numbytes, buf, rf_DiskReadFunc, rf_DiskReadUndoFunc,
			   "Rod", alloclist, flags, RF_IO_NORMAL_PRIORITY);
  blockNode = rd_dag_h->succedents[0];
  unblockNode = blockNode->succedents[0]->succedents[0];

  /* map the stripe and fill in the PDAs in the dag */
  asm_h = rf_MapAccess(raidPtr, startAddr, layoutPtr->dataSectorsPerStripe, buf, RF_DONT_REMAP);
  asmap = asm_h->stripeMap;
  
  for (pda=asmap->physInfo,i=0; i<layoutPtr->numDataCol; i++,pda=pda->next) {
    RF_ASSERT(pda);
    rf_RangeRestrictPDA(raidPtr, parityPDA, pda, 0, 1);
    RF_ASSERT(pda->numSector != 0);
    if (rf_TryToRedirectPDA(raidPtr, pda, 0)) goto out;   /* no way to verify parity if disk is dead.  return w/ good status */
    blockNode->succedents[i]->params[0].p = pda;
    blockNode->succedents[i]->params[2].v = psID;
    blockNode->succedents[i]->params[3].v = RF_CREATE_PARAM3(RF_IO_NORMAL_PRIORITY, 0, 0, which_ru);
  }

  RF_ASSERT(!asmap->parityInfo->next);
  rf_RangeRestrictPDA(raidPtr, parityPDA, asmap->parityInfo, 0, 1);
  RF_ASSERT(asmap->parityInfo->numSector != 0);
  if (rf_TryToRedirectPDA(raidPtr, asmap->parityInfo, 1))
    goto out;
  blockNode->succedents[layoutPtr->numDataCol]->params[0].p = asmap->parityInfo;

  /* fire off the DAG */
  bzero((char *)&tracerec,sizeof(tracerec));
  rd_dag_h->tracerec = &tracerec;

  if (rf_verifyParityDebug) {
    printf("Parity verify read dag:\n");
    rf_PrintDAGList(rd_dag_h);
  }

  RF_LOCK_MUTEX(mcpair->mutex);
  mcpair->flag = 0;
  rf_DispatchDAG(rd_dag_h, (void (*)(void *))rf_MCPairWakeupFunc, 
		 (void *) mcpair);
  while (!mcpair->flag) 
	  RF_WAIT_COND(mcpair->cond, mcpair->mutex);
  RF_UNLOCK_MUTEX(mcpair->mutex);
  if (rd_dag_h->status != rf_enable) {
    RF_ERRORMSG("Unable to verify parity:  can't read the stripe\n");
    retcode = RF_PARITY_COULD_NOT_VERIFY;
    goto out;
  }

  for (p=buf; p<end_p; p+=numbytes) {
    rf_bxor(p, pbuf, numbytes, NULL);
  }
  for (i=0; i<numbytes; i++) {
d246 3
a248 3
	  if (pbuf[i]!=0 || buf[bytesPerStripe+i]!=0) {
	  printf("Bytes: %d %d %d\n",i,pbuf[i],buf[bytesPerStripe+i]);
	  }
d250 8
a257 37
	  if (pbuf[i] != buf[bytesPerStripe+i]) {
		  if (!correct_it) 
			  RF_ERRORMSG3("Parity verify error: byte %d of parity is 0x%x should be 0x%x\n",
			       i,(u_char) buf[bytesPerStripe+i],(u_char) pbuf[i]);
		  retcode = RF_PARITY_BAD;
		  break;
	  }
  }

  if (retcode && correct_it) {
    wr_dag_h = rf_MakeSimpleDAG(raidPtr, 1, numbytes, pbuf, rf_DiskWriteFunc, rf_DiskWriteUndoFunc,
			     "Wnp", alloclist, flags, RF_IO_NORMAL_PRIORITY);
    wrBlock = wr_dag_h->succedents[0]; wrUnblock = wrBlock->succedents[0]->succedents[0];
    wrBlock->succedents[0]->params[0].p = asmap->parityInfo;
    wrBlock->succedents[0]->params[2].v = psID;
    wrBlock->succedents[0]->params[3].v = RF_CREATE_PARAM3(RF_IO_NORMAL_PRIORITY, 0, 0, which_ru);
    bzero((char *)&tracerec,sizeof(tracerec));
    wr_dag_h->tracerec = &tracerec;
    if (rf_verifyParityDebug) {
      printf("Parity verify write dag:\n");
      rf_PrintDAGList(wr_dag_h);
    }
    RF_LOCK_MUTEX(mcpair->mutex);
    mcpair->flag = 0;
    rf_DispatchDAG(wr_dag_h, (void (*)(void *))rf_MCPairWakeupFunc, 
		   (void *) mcpair);
    while (!mcpair->flag)
      RF_WAIT_COND(mcpair->cond, mcpair->mutex);
    RF_UNLOCK_MUTEX(mcpair->mutex);
    if (wr_dag_h->status != rf_enable) {
      RF_ERRORMSG("Unable to correct parity in VerifyParity:  can't write the stripe\n");
      retcode = RF_PARITY_COULD_NOT_CORRECT;
    }
    rf_FreeDAG(wr_dag_h);
    if (retcode == RF_PARITY_BAD)
      retcode = RF_PARITY_CORRECTED;
  }
d259 29
d289 5
a293 5
  rf_FreeAccessStripeMap(asm_h);
  rf_FreeAllocList(alloclist);
  rf_FreeDAG(rd_dag_h);
  rf_FreeMCPair(mcpair);
  return(retcode);
d296 5
a300 4
int rf_TryToRedirectPDA(raidPtr, pda, parity)
  RF_Raid_t          *raidPtr;
  RF_PhysDiskAddr_t  *pda;
  int                 parity;
d302 27
a328 24
  if (raidPtr->Disks[pda->row][pda->col].status == rf_ds_reconstructing) {
    if (rf_CheckRUReconstructed(raidPtr->reconControl[pda->row]->reconMap, pda->startSector)) {
      if (raidPtr->Layout.map->flags & RF_DISTRIBUTE_SPARE) {
	RF_RowCol_t or = pda->row, oc = pda->col;
	RF_SectorNum_t os = pda->startSector;
	if (parity) {
	  (raidPtr->Layout.map->MapParity)(raidPtr, pda->raidAddress, &pda->row, &pda->col, &pda->startSector, RF_REMAP);
	  if (rf_verifyParityDebug) printf("VerifyParity: Redir P r %d c %d sect %ld -> r %d c %d sect %ld\n",
					or,oc,(long)os,pda->row,pda->col,(long)pda->startSector);
	} else {
	  (raidPtr->Layout.map->MapSector)(raidPtr, pda->raidAddress, &pda->row, &pda->col, &pda->startSector, RF_REMAP);
	  if (rf_verifyParityDebug) printf("VerifyParity: Redir D r %d c %d sect %ld -> r %d c %d sect %ld\n",
					or,oc,(long)os,pda->row,pda->col,(long)pda->startSector);
	}
      } else {
	RF_RowCol_t spRow = raidPtr->Disks[pda->row][pda->col].spareRow;
	RF_RowCol_t spCol = raidPtr->Disks[pda->row][pda->col].spareCol;
	pda->row = spRow;
	pda->col = spCol;
      }
    }
  }
  if (RF_DEAD_DISK(raidPtr->Disks[pda->row][pda->col].status)) return(1);
  return(0);
a329 1

d348 4
a351 3
int rf_VerifyDegrModeWrite(raidPtr, asmh)
  RF_Raid_t                   *raidPtr;
  RF_AccessStripeMapHeader_t  *asmh;
d353 1
a353 1
  return(0);
a354 1

d364 12
a375 11
RF_DagHeader_t *rf_MakeSimpleDAG(raidPtr, nNodes, bytesPerSU, databuf, doFunc, undoFunc, name, alloclist, flags, priority)
  RF_Raid_t              *raidPtr;
  int                     nNodes;
  int                     bytesPerSU;
  char                   *databuf;
  int                   (*doFunc)(RF_DagNode_t *node);
  int                   (*undoFunc)(RF_DagNode_t *node);
  char                   *name;        /* node names at the second level */
  RF_AllocListElem_t     *alloclist;
  RF_RaidAccessFlags_t    flags;
  int                     priority;
d377 40
a416 40
  RF_DagHeader_t *dag_h;
  RF_DagNode_t *nodes, *termNode, *blockNode, *unblockNode;
  int i;
  
  /* create the nodes, the block & unblock nodes, and the terminator node */
  RF_CallocAndAdd(nodes, nNodes+3, sizeof(RF_DagNode_t), (RF_DagNode_t *), alloclist);
  blockNode   = &nodes[nNodes];
  unblockNode = blockNode+1;
  termNode   = unblockNode+1;

  dag_h = rf_AllocDAGHeader();
  dag_h->raidPtr = (void *) raidPtr;
  dag_h->allocList = NULL;                               /* we won't use this alloc list */
  dag_h->status = rf_enable;
  dag_h->numSuccedents = 1;
  dag_h->creator = "SimpleDAG";

  /* this dag can not commit until the unblock node is reached
   * errors prior to the commit point imply the dag has failed
   */
  dag_h->numCommitNodes = 1;
  dag_h->numCommits = 0;

  dag_h->succedents[0] = blockNode;
  rf_InitNode(blockNode,   rf_wait, RF_FALSE, rf_NullNodeFunc, rf_NullNodeUndoFunc, NULL, nNodes, 0, 0, 0, dag_h, "Nil", alloclist);
  rf_InitNode(unblockNode, rf_wait, RF_TRUE, rf_NullNodeFunc, rf_NullNodeUndoFunc, NULL, 1, nNodes, 0, 0, dag_h, "Nil", alloclist);
  unblockNode->succedents[0] = termNode;
  for (i=0; i<nNodes; i++) {
    blockNode->succedents[i] = unblockNode->antecedents[i] = &nodes[i];
    unblockNode->antType[i] = rf_control;
    rf_InitNode(&nodes[i], rf_wait, RF_FALSE, doFunc, undoFunc, rf_GenericWakeupFunc, 1, 1, 4, 0, dag_h, name, alloclist);
    nodes[i].succedents[0] =  unblockNode;
    nodes[i].antecedents[0] = blockNode;
    nodes[i].antType[0] = rf_control;
    nodes[i].params[1].p = (databuf + (i*bytesPerSU));
  }
  rf_InitNode(termNode, rf_wait, RF_FALSE, rf_TerminateFunc, rf_TerminateUndoFunc, NULL, 0, 1, 0, 0, dag_h, "Trm", alloclist);
  termNode->antecedents[0] = unblockNode;
  termNode->antType[0] = rf_control;
  return(dag_h);
@

