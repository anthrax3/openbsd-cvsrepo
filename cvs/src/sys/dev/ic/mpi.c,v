head	1.205;
access;
symbols
	OPENBSD_6_1:1.205.0.4
	OPENBSD_6_1_BASE:1.205
	OPENBSD_6_0:1.203.0.6
	OPENBSD_6_0_BASE:1.203
	OPENBSD_5_9:1.203.0.2
	OPENBSD_5_9_BASE:1.203
	OPENBSD_5_8:1.201.0.4
	OPENBSD_5_8_BASE:1.201
	OPENBSD_5_7:1.199.0.2
	OPENBSD_5_7_BASE:1.199
	OPENBSD_5_6:1.193.0.4
	OPENBSD_5_6_BASE:1.193
	OPENBSD_5_5:1.185.0.4
	OPENBSD_5_5_BASE:1.185
	OPENBSD_5_4:1.183.0.4
	OPENBSD_5_4_BASE:1.183
	OPENBSD_5_3:1.183.0.2
	OPENBSD_5_3_BASE:1.183
	OPENBSD_5_2:1.175.0.2
	OPENBSD_5_2_BASE:1.175
	OPENBSD_5_1_BASE:1.175
	OPENBSD_5_1:1.175.0.4
	OPENBSD_5_0:1.174.0.2
	OPENBSD_5_0_BASE:1.174
	OPENBSD_4_9:1.166.0.2
	OPENBSD_4_9_BASE:1.166
	OPENBSD_4_8:1.156.0.2
	OPENBSD_4_8_BASE:1.156
	OPENBSD_4_7:1.134.0.2
	OPENBSD_4_7_BASE:1.134
	OPENBSD_4_6:1.110.0.4
	OPENBSD_4_6_BASE:1.110
	OPENBSD_4_5:1.109.0.2
	OPENBSD_4_5_BASE:1.109
	OPENBSD_4_4:1.93.0.2
	OPENBSD_4_4_BASE:1.93
	OPENBSD_4_3:1.92.0.2
	OPENBSD_4_3_BASE:1.92
	OPENBSD_4_2:1.86.0.2
	OPENBSD_4_2_BASE:1.86
	OPENBSD_4_1:1.82.0.2
	OPENBSD_4_1_BASE:1.82
	OPENBSD_4_0:1.66.0.2
	OPENBSD_4_0_BASE:1.66;
locks; strict;
comment	@ * @;


1.205
date	2016.08.17.01.02.31;	author krw;	state Exp;
branches;
next	1.204;
commitid	NQJzcPS2mgd0AEvc;

1.204
date	2016.08.14.04.08.03;	author dlg;	state Exp;
branches;
next	1.203;
commitid	7Sh26Zh99sH8viYr;

1.203
date	2015.10.23.00.08.57;	author jsg;	state Exp;
branches;
next	1.202;
commitid	BOb1zSqGV9WLf4re;

1.202
date	2015.09.09.18.23.55;	author deraadt;	state Exp;
branches;
next	1.201;
commitid	pxEWup0rbECbQnbF;

1.201
date	2015.05.04.03.59.42;	author jsg;	state Exp;
branches;
next	1.200;
commitid	a8MWvErr5z5NNDlo;

1.200
date	2015.03.14.03.38.47;	author jsg;	state Exp;
branches;
next	1.199;
commitid	p4LJxGKbi0BU2cG6;

1.199
date	2015.01.27.03.17.36;	author dlg;	state Exp;
branches;
next	1.198;
commitid	MyKPm9Q3dQu92BiX;

1.198
date	2014.09.17.10.11.33;	author dlg;	state Exp;
branches;
next	1.197;
commitid	s2a91p0wHz4OY5PF;

1.197
date	2014.09.15.12.00.04;	author dlg;	state Exp;
branches;
next	1.196;
commitid	mAlNepn7ILap73ON;

1.196
date	2014.09.14.14.17.24;	author jsg;	state Exp;
branches;
next	1.195;
commitid	uzzBR7hz9ncd4O6G;

1.195
date	2014.09.03.00.46.04;	author dlg;	state Exp;
branches;
next	1.194;
commitid	z6K8FSAT3J9gg3C0;

1.194
date	2014.09.01.07.52.30;	author blambert;	state Exp;
branches;
next	1.193;
commitid	pRnd0qMNwQQn0ntn;

1.193
date	2014.07.13.23.10.23;	author deraadt;	state Exp;
branches;
next	1.192;
commitid	JtO5uXxVcnZfhUkR;

1.192
date	2014.07.12.18.48.17;	author tedu;	state Exp;
branches;
next	1.191;
commitid	I19imNlAX05zJOED;

1.191
date	2014.04.16.01.19.28;	author dlg;	state Exp;
branches;
next	1.190;

1.190
date	2014.03.25.09.36.37;	author dlg;	state Exp;
branches;
next	1.189;

1.189
date	2014.03.25.07.26.50;	author dlg;	state Exp;
branches;
next	1.188;

1.188
date	2014.03.24.04.26.58;	author dlg;	state Exp;
branches;
next	1.187;

1.187
date	2014.03.24.04.05.11;	author dlg;	state Exp;
branches;
next	1.186;

1.186
date	2014.03.24.02.59.11;	author dlg;	state Exp;
branches;
next	1.185;

1.185
date	2014.01.20.02.22.10;	author dlg;	state Exp;
branches;
next	1.184;

1.184
date	2014.01.20.02.20.27;	author dlg;	state Exp;
branches;
next	1.183;

1.183
date	2013.01.18.05.49.52;	author dlg;	state Exp;
branches;
next	1.182;

1.182
date	2013.01.17.03.05.11;	author dlg;	state Exp;
branches;
next	1.181;

1.181
date	2013.01.17.02.44.42;	author dlg;	state Exp;
branches;
next	1.180;

1.180
date	2013.01.17.02.39.05;	author dlg;	state Exp;
branches;
next	1.179;

1.179
date	2012.09.18.23.54.29;	author dlg;	state Exp;
branches;
next	1.178;

1.178
date	2012.09.12.06.58.20;	author haesbaert;	state Exp;
branches;
next	1.177;

1.177
date	2012.09.12.06.53.05;	author haesbaert;	state Exp;
branches;
next	1.176;

1.176
date	2012.08.26.11.33.44;	author dlg;	state Exp;
branches;
next	1.175;

1.175
date	2012.01.16.10.55.46;	author dlg;	state Exp;
branches;
next	1.174;

1.174
date	2011.07.17.22.46.48;	author matthew;	state Exp;
branches;
next	1.173;

1.173
date	2011.07.08.22.09.27;	author matthew;	state Exp;
branches;
next	1.172;

1.172
date	2011.06.17.07.06.46;	author mk;	state Exp;
branches;
next	1.171;

1.171
date	2011.04.27.06.06.30;	author dlg;	state Exp;
branches;
next	1.170;

1.170
date	2011.04.27.06.04.48;	author dlg;	state Exp;
branches;
next	1.169;

1.169
date	2011.04.27.05.11.09;	author dlg;	state Exp;
branches;
next	1.168;

1.168
date	2011.04.27.04.03.11;	author dlg;	state Exp;
branches;
next	1.167;

1.167
date	2011.03.04.15.44.39;	author mikeb;	state Exp;
branches;
next	1.166;

1.166
date	2011.03.01.23.48.33;	author dlg;	state Exp;
branches;
next	1.165;

1.165
date	2010.09.24.01.27.11;	author dlg;	state Exp;
branches;
next	1.164;

1.164
date	2010.09.21.06.25.48;	author dlg;	state Exp;
branches;
next	1.163;

1.163
date	2010.09.20.06.17.49;	author krw;	state Exp;
branches;
next	1.162;

1.162
date	2010.09.14.00.03.04;	author dlg;	state Exp;
branches;
next	1.161;

1.161
date	2010.09.13.07.48.12;	author dlg;	state Exp;
branches;
next	1.160;

1.160
date	2010.09.13.07.11.47;	author dlg;	state Exp;
branches;
next	1.159;

1.159
date	2010.09.13.06.53.21;	author dlg;	state Exp;
branches;
next	1.158;

1.158
date	2010.09.10.07.00.56;	author dlg;	state Exp;
branches;
next	1.157;

1.157
date	2010.08.27.05.30.59;	author dlg;	state Exp;
branches;
next	1.156;

1.156
date	2010.08.07.03.50.01;	author krw;	state Exp;
branches;
next	1.155;

1.155
date	2010.07.06.07.18.18;	author dlg;	state Exp;
branches;
next	1.154;

1.154
date	2010.07.06.06.50.42;	author dlg;	state Exp;
branches;
next	1.153;

1.153
date	2010.07.01.03.20.38;	author matthew;	state Exp;
branches;
next	1.152;

1.152
date	2010.06.28.18.31.02;	author krw;	state Exp;
branches;
next	1.151;

1.151
date	2010.06.15.04.30.26;	author dlg;	state Exp;
branches;
next	1.150;

1.150
date	2010.06.15.04.11.34;	author dlg;	state Exp;
branches;
next	1.149;

1.149
date	2010.05.19.07.26.01;	author dlg;	state Exp;
branches;
next	1.148;

1.148
date	2010.05.16.20.33.59;	author nicm;	state Exp;
branches;
next	1.147;

1.147
date	2010.05.09.22.03.56;	author dlg;	state Exp;
branches;
next	1.146;

1.146
date	2010.04.28.11.46.23;	author marco;	state Exp;
branches;
next	1.145;

1.145
date	2010.04.22.12.33.30;	author oga;	state Exp;
branches;
next	1.144;

1.144
date	2010.04.22.03.14.35;	author marco;	state Exp;
branches;
next	1.143;

1.143
date	2010.04.19.09.51.09;	author dlg;	state Exp;
branches;
next	1.142;

1.142
date	2010.04.16.12.19.07;	author dlg;	state Exp;
branches;
next	1.141;

1.141
date	2010.04.16.01.10.19;	author deraadt;	state Exp;
branches;
next	1.140;

1.140
date	2010.04.12.09.53.46;	author dlg;	state Exp;
branches;
next	1.139;

1.139
date	2010.04.09.14.06.01;	author dlg;	state Exp;
branches;
next	1.138;

1.138
date	2010.04.06.01.24.43;	author dlg;	state Exp;
branches;
next	1.137;

1.137
date	2010.04.06.01.04.22;	author dlg;	state Exp;
branches;
next	1.136;

1.136
date	2010.04.03.08.00.42;	author dlg;	state Exp;
branches;
next	1.135;

1.135
date	2010.03.23.01.57.19;	author krw;	state Exp;
branches;
next	1.134;

1.134
date	2010.01.11.03.51.57;	author dlg;	state Exp;
branches
	1.134.2.1;
next	1.133;

1.133
date	2010.01.09.23.15.06;	author krw;	state Exp;
branches;
next	1.132;

1.132
date	2010.01.03.07.47.20;	author dlg;	state Exp;
branches;
next	1.131;

1.131
date	2010.01.03.07.28.46;	author dlg;	state Exp;
branches;
next	1.130;

1.130
date	2010.01.03.07.26.44;	author dlg;	state Exp;
branches;
next	1.129;

1.129
date	2010.01.03.07.05.43;	author dlg;	state Exp;
branches;
next	1.128;

1.128
date	2010.01.03.06.47.58;	author dlg;	state Exp;
branches;
next	1.127;

1.127
date	2010.01.03.06.41.22;	author dlg;	state Exp;
branches;
next	1.126;

1.126
date	2010.01.03.06.36.50;	author dlg;	state Exp;
branches;
next	1.125;

1.125
date	2010.01.03.06.15.30;	author dlg;	state Exp;
branches;
next	1.124;

1.124
date	2009.12.10.00.20.38;	author chl;	state Exp;
branches;
next	1.123;

1.123
date	2009.12.09.04.59.41;	author marco;	state Exp;
branches;
next	1.122;

1.122
date	2009.12.01.01.40.02;	author dlg;	state Exp;
branches;
next	1.121;

1.121
date	2009.11.12.06.20.27;	author dlg;	state Exp;
branches;
next	1.120;

1.120
date	2009.11.10.10.13.08;	author dlg;	state Exp;
branches;
next	1.119;

1.119
date	2009.11.05.03.55.59;	author marco;	state Exp;
branches;
next	1.118;

1.118
date	2009.11.05.03.33.52;	author marco;	state Exp;
branches;
next	1.117;

1.117
date	2009.11.02.23.20.41;	author marco;	state Exp;
branches;
next	1.116;

1.116
date	2009.10.23.13.30.54;	author dlg;	state Exp;
branches;
next	1.115;

1.115
date	2009.10.23.01.02.29;	author dlg;	state Exp;
branches;
next	1.114;

1.114
date	2009.10.15.12.38.49;	author dlg;	state Exp;
branches;
next	1.113;

1.113
date	2009.10.11.02.11.34;	author dlg;	state Exp;
branches;
next	1.112;

1.112
date	2009.08.12.14.28.02;	author dlg;	state Exp;
branches;
next	1.111;

1.111
date	2009.08.08.09.35.22;	author dlg;	state Exp;
branches;
next	1.110;

1.110
date	2009.03.06.01.28.44;	author krw;	state Exp;
branches
	1.110.4.1;
next	1.109;

1.109
date	2009.02.16.21.19.07;	author miod;	state Exp;
branches
	1.109.2.1;
next	1.108;

1.108
date	2009.02.13.23.16.22;	author sthen;	state Exp;
branches;
next	1.107;

1.107
date	2008.11.23.16.20.06;	author marco;	state Exp;
branches;
next	1.106;

1.106
date	2008.11.23.12.45.11;	author dlg;	state Exp;
branches;
next	1.105;

1.105
date	2008.11.18.21.52.39;	author marco;	state Exp;
branches;
next	1.104;

1.104
date	2008.11.03.01.42.15;	author marco;	state Exp;
branches;
next	1.103;

1.103
date	2008.11.01.23.09.29;	author marco;	state Exp;
branches;
next	1.102;

1.102
date	2008.11.01.21.25.34;	author marco;	state Exp;
branches;
next	1.101;

1.101
date	2008.11.01.18.18.16;	author marco;	state Exp;
branches;
next	1.100;

1.100
date	2008.10.28.11.27.53;	author marco;	state Exp;
branches;
next	1.99;

1.99
date	2008.10.28.11.00.40;	author marco;	state Exp;
branches;
next	1.98;

1.98
date	2008.10.07.12.34.30;	author dlg;	state Exp;
branches;
next	1.97;

1.97
date	2008.09.30.23.58.40;	author dlg;	state Exp;
branches;
next	1.96;

1.96
date	2008.09.30.23.40.16;	author dlg;	state Exp;
branches;
next	1.95;

1.95
date	2008.09.30.23.36.19;	author dlg;	state Exp;
branches;
next	1.94;

1.94
date	2008.09.30.01.50.48;	author dlg;	state Exp;
branches;
next	1.93;

1.93
date	2008.05.25.23.45.53;	author dlg;	state Exp;
branches;
next	1.92;

1.92
date	2007.12.27.02.29.00;	author dlg;	state Exp;
branches;
next	1.91;

1.91
date	2007.12.27.02.27.09;	author dlg;	state Exp;
branches;
next	1.90;

1.90
date	2007.12.27.02.24.33;	author dlg;	state Exp;
branches;
next	1.89;

1.89
date	2007.09.12.13.42.49;	author dlg;	state Exp;
branches;
next	1.88;

1.88
date	2007.09.11.13.39.33;	author gilles;	state Exp;
branches;
next	1.87;

1.87
date	2007.09.07.12.11.11;	author dlg;	state Exp;
branches;
next	1.86;

1.86
date	2007.06.12.19.29.23;	author thib;	state Exp;
branches;
next	1.85;

1.85
date	2007.05.31.18.21.44;	author dlg;	state Exp;
branches;
next	1.84;

1.84
date	2007.04.03.04.15.50;	author dlg;	state Exp;
branches;
next	1.83;

1.83
date	2007.03.17.10.25.39;	author dlg;	state Exp;
branches;
next	1.82;

1.82
date	2006.11.28.23.59.45;	author dlg;	state Exp;
branches;
next	1.81;

1.81
date	2006.11.28.13.22.56;	author dlg;	state Exp;
branches;
next	1.80;

1.80
date	2006.11.28.12.54.12;	author dlg;	state Exp;
branches;
next	1.79;

1.79
date	2006.11.26.09.30.08;	author dlg;	state Exp;
branches;
next	1.78;

1.78
date	2006.11.25.17.18.46;	author dlg;	state Exp;
branches;
next	1.77;

1.77
date	2006.10.22.06.59.00;	author dlg;	state Exp;
branches;
next	1.76;

1.76
date	2006.10.21.07.36.15;	author dlg;	state Exp;
branches;
next	1.75;

1.75
date	2006.09.22.00.43.18;	author dlg;	state Exp;
branches;
next	1.74;

1.74
date	2006.09.21.10.57.52;	author dlg;	state Exp;
branches;
next	1.73;

1.73
date	2006.09.21.10.52.30;	author dlg;	state Exp;
branches;
next	1.72;

1.72
date	2006.09.21.10.00.40;	author dlg;	state Exp;
branches;
next	1.71;

1.71
date	2006.09.21.09.44.05;	author dlg;	state Exp;
branches;
next	1.70;

1.70
date	2006.09.21.09.42.27;	author dlg;	state Exp;
branches;
next	1.69;

1.69
date	2006.09.21.09.05.28;	author dlg;	state Exp;
branches;
next	1.68;

1.68
date	2006.09.18.13.01.26;	author dlg;	state Exp;
branches;
next	1.67;

1.67
date	2006.09.18.03.13.25;	author pedro;	state Exp;
branches;
next	1.66;

1.66
date	2006.09.16.07.50.46;	author dlg;	state Exp;
branches;
next	1.65;

1.65
date	2006.08.24.14.08.43;	author dlg;	state Exp;
branches;
next	1.64;

1.64
date	2006.08.03.08.48.44;	author dlg;	state Exp;
branches;
next	1.63;

1.63
date	2006.07.15.04.09.57;	author dlg;	state Exp;
branches;
next	1.62;

1.62
date	2006.07.15.03.59.50;	author dlg;	state Exp;
branches;
next	1.61;

1.61
date	2006.07.09.14.10.57;	author dlg;	state Exp;
branches;
next	1.60;

1.60
date	2006.07.09.13.45.36;	author dlg;	state Exp;
branches;
next	1.59;

1.59
date	2006.07.09.13.35.10;	author dlg;	state Exp;
branches;
next	1.58;

1.58
date	2006.07.06.09.59.42;	author dlg;	state Exp;
branches;
next	1.57;

1.57
date	2006.07.06.09.21.59;	author dlg;	state Exp;
branches;
next	1.56;

1.56
date	2006.07.06.09.04.45;	author dlg;	state Exp;
branches;
next	1.55;

1.55
date	2006.07.06.00.55.03;	author dlg;	state Exp;
branches;
next	1.54;

1.54
date	2006.07.05.23.50.49;	author dlg;	state Exp;
branches;
next	1.53;

1.53
date	2006.06.30.17.42.28;	author kettenis;	state Exp;
branches;
next	1.52;

1.52
date	2006.06.30.12.32.53;	author dlg;	state Exp;
branches;
next	1.51;

1.51
date	2006.06.30.08.29.42;	author dlg;	state Exp;
branches;
next	1.50;

1.50
date	2006.06.29.10.43.21;	author dlg;	state Exp;
branches;
next	1.49;

1.49
date	2006.06.29.08.35.08;	author dlg;	state Exp;
branches;
next	1.48;

1.48
date	2006.06.19.21.06.22;	author miod;	state Exp;
branches;
next	1.47;

1.47
date	2006.06.18.22.31.06;	author marco;	state Exp;
branches;
next	1.46;

1.46
date	2006.06.18.00.10.24;	author marco;	state Exp;
branches;
next	1.45;

1.45
date	2006.06.18.00.08.00;	author marco;	state Exp;
branches;
next	1.44;

1.44
date	2006.06.16.05.36.46;	author dlg;	state Exp;
branches;
next	1.43;

1.43
date	2006.06.15.07.35.44;	author marco;	state Exp;
branches;
next	1.42;

1.42
date	2006.06.15.06.45.53;	author marco;	state Exp;
branches;
next	1.41;

1.41
date	2006.06.15.05.22.08;	author marco;	state Exp;
branches;
next	1.40;

1.40
date	2006.06.15.04.59.21;	author marco;	state Exp;
branches;
next	1.39;

1.39
date	2006.06.15.04.44.59;	author marco;	state Exp;
branches;
next	1.38;

1.38
date	2006.06.15.02.56.51;	author marco;	state Exp;
branches;
next	1.37;

1.37
date	2006.06.13.02.07.19;	author dlg;	state Exp;
branches;
next	1.36;

1.36
date	2006.06.12.23.25.57;	author dlg;	state Exp;
branches;
next	1.35;

1.35
date	2006.06.12.14.06.05;	author dlg;	state Exp;
branches;
next	1.34;

1.34
date	2006.06.12.12.31.58;	author dlg;	state Exp;
branches;
next	1.33;

1.33
date	2006.06.12.03.55.39;	author dlg;	state Exp;
branches;
next	1.32;

1.32
date	2006.06.12.03.46.12;	author marco;	state Exp;
branches;
next	1.31;

1.31
date	2006.06.10.17.50.33;	author marco;	state Exp;
branches;
next	1.30;

1.30
date	2006.06.10.14.05.29;	author dlg;	state Exp;
branches;
next	1.29;

1.29
date	2006.06.10.13.45.48;	author marco;	state Exp;
branches;
next	1.28;

1.28
date	2006.06.08.22.09.03;	author dlg;	state Exp;
branches;
next	1.27;

1.27
date	2006.06.08.12.27.59;	author dlg;	state Exp;
branches;
next	1.26;

1.26
date	2006.06.06.14.51.29;	author dlg;	state Exp;
branches;
next	1.25;

1.25
date	2006.06.06.14.47.45;	author dlg;	state Exp;
branches;
next	1.24;

1.24
date	2006.06.01.21.32.15;	author dlg;	state Exp;
branches;
next	1.23;

1.23
date	2006.06.01.04.36.19;	author dlg;	state Exp;
branches;
next	1.22;

1.22
date	2006.06.01.00.53.15;	author deraadt;	state Exp;
branches;
next	1.21;

1.21
date	2006.05.31.21.28.08;	author dlg;	state Exp;
branches;
next	1.20;

1.20
date	2006.05.31.06.17.00;	author dlg;	state Exp;
branches;
next	1.19;

1.19
date	2006.05.31.03.06.39;	author dlg;	state Exp;
branches;
next	1.18;

1.18
date	2006.05.31.02.39.29;	author dlg;	state Exp;
branches;
next	1.17;

1.17
date	2006.05.31.02.38.36;	author dlg;	state Exp;
branches;
next	1.16;

1.16
date	2006.05.31.00.52.05;	author deraadt;	state Exp;
branches;
next	1.15;

1.15
date	2006.05.31.00.32.51;	author dlg;	state Exp;
branches;
next	1.14;

1.14
date	2006.05.30.05.03.28;	author dlg;	state Exp;
branches;
next	1.13;

1.13
date	2006.05.30.03.25.13;	author jason;	state Exp;
branches;
next	1.12;

1.12
date	2006.05.29.21.30.24;	author dlg;	state Exp;
branches;
next	1.11;

1.11
date	2006.05.29.19.55.37;	author dlg;	state Exp;
branches;
next	1.10;

1.10
date	2006.05.29.08.33.36;	author dlg;	state Exp;
branches;
next	1.9;

1.9
date	2006.05.29.08.18.57;	author dlg;	state Exp;
branches;
next	1.8;

1.8
date	2006.05.29.06.32.09;	author dlg;	state Exp;
branches;
next	1.7;

1.7
date	2006.05.29.05.43.55;	author dlg;	state Exp;
branches;
next	1.6;

1.6
date	2006.05.28.21.59.23;	author dlg;	state Exp;
branches;
next	1.5;

1.5
date	2006.05.28.02.32.55;	author dlg;	state Exp;
branches;
next	1.4;

1.4
date	2006.05.28.01.29.21;	author dlg;	state Exp;
branches;
next	1.3;

1.3
date	2006.05.27.20.53.56;	author dlg;	state Exp;
branches;
next	1.2;

1.2
date	2006.05.27.19.37.38;	author dlg;	state Exp;
branches;
next	1.1;

1.1
date	2006.05.27.19.03.55;	author dlg;	state Exp;
branches;
next	;

1.109.2.1
date	2010.04.04.11.37.23;	author dlg;	state Exp;
branches;
next	;

1.110.4.1
date	2010.04.04.11.37.56;	author dlg;	state Exp;
branches;
next	;

1.134.2.1
date	2010.04.04.11.38.29;	author dlg;	state Exp;
branches;
next	;


desc
@@


1.205
log
@Make error handling (esp. DATA_UNDERRUN) clearer and avoid losing resid
value.

Specs from mikeb@@, ok dlg@@
@
text
@/*	$OpenBSD: mpi.c,v 1.204 2016/08/14 04:08:03 dlg Exp $ */

/*
 * Copyright (c) 2005, 2006, 2009 David Gwynne <dlg@@openbsd.org>
 * Copyright (c) 2005, 2008, 2009 Marco Peereboom <marco@@openbsd.org>
 *
 * Permission to use, copy, modify, and distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 */

#include "bio.h"

#include <sys/param.h>
#include <sys/systm.h>
#include <sys/buf.h>
#include <sys/device.h>
#include <sys/malloc.h>
#include <sys/kernel.h>
#include <sys/mutex.h>
#include <sys/rwlock.h>
#include <sys/sensors.h>
#include <sys/dkio.h>
#include <sys/task.h>

#include <machine/bus.h>

#include <scsi/scsi_all.h>
#include <scsi/scsiconf.h>

#include <dev/biovar.h>
#include <dev/ic/mpireg.h>
#include <dev/ic/mpivar.h>

#ifdef MPI_DEBUG
uint32_t	mpi_debug = 0
/*		    | MPI_D_CMD */
/*		    | MPI_D_INTR */
/*		    | MPI_D_MISC */
/*		    | MPI_D_DMA */
/*		    | MPI_D_IOCTL */
/*		    | MPI_D_RW */
/*		    | MPI_D_MEM */
/*		    | MPI_D_CCB */
/*		    | MPI_D_PPR */
/*		    | MPI_D_RAID */
/*		    | MPI_D_EVT */
		;
#endif

struct cfdriver mpi_cd = {
	NULL,
	"mpi",
	DV_DULL
};

void			mpi_scsi_cmd(struct scsi_xfer *);
void			mpi_scsi_cmd_done(struct mpi_ccb *);
void			mpi_minphys(struct buf *bp, struct scsi_link *sl);
int			mpi_scsi_probe(struct scsi_link *);
int			mpi_scsi_ioctl(struct scsi_link *, u_long, caddr_t,
			    int);

struct scsi_adapter mpi_switch = {
	mpi_scsi_cmd,
	mpi_minphys,
	mpi_scsi_probe,
	NULL,
	mpi_scsi_ioctl
};

struct mpi_dmamem	*mpi_dmamem_alloc(struct mpi_softc *, size_t);
void			mpi_dmamem_free(struct mpi_softc *,
			    struct mpi_dmamem *);
int			mpi_alloc_ccbs(struct mpi_softc *);
void			*mpi_get_ccb(void *);
void			mpi_put_ccb(void *, void *);
int			mpi_alloc_replies(struct mpi_softc *);
void			mpi_push_replies(struct mpi_softc *);
void			mpi_push_reply(struct mpi_softc *, struct mpi_rcb *);

void			mpi_start(struct mpi_softc *, struct mpi_ccb *);
int			mpi_poll(struct mpi_softc *, struct mpi_ccb *, int);
void			mpi_poll_done(struct mpi_ccb *);
void			mpi_reply(struct mpi_softc *, u_int32_t);

void			mpi_wait(struct mpi_softc *sc, struct mpi_ccb *);
void			mpi_wait_done(struct mpi_ccb *);

int			mpi_cfg_spi_port(struct mpi_softc *);
void			mpi_squash_ppr(struct mpi_softc *);
void			mpi_run_ppr(struct mpi_softc *);
int			mpi_ppr(struct mpi_softc *, struct scsi_link *,
			    struct mpi_cfg_raid_physdisk *, int, int, int);
int			mpi_inq(struct mpi_softc *, u_int16_t, int);

int			mpi_cfg_sas(struct mpi_softc *);
int			mpi_cfg_fc(struct mpi_softc *);

void			mpi_timeout_xs(void *);
int			mpi_load_xs(struct mpi_ccb *);

u_int32_t		mpi_read(struct mpi_softc *, bus_size_t);
void			mpi_write(struct mpi_softc *, bus_size_t, u_int32_t);
int			mpi_wait_eq(struct mpi_softc *, bus_size_t, u_int32_t,
			    u_int32_t);
int			mpi_wait_ne(struct mpi_softc *, bus_size_t, u_int32_t,
			    u_int32_t);

int			mpi_init(struct mpi_softc *);
int			mpi_reset_soft(struct mpi_softc *);
int			mpi_reset_hard(struct mpi_softc *);

int			mpi_handshake_send(struct mpi_softc *, void *, size_t);
int			mpi_handshake_recv_dword(struct mpi_softc *,
			    u_int32_t *);
int			mpi_handshake_recv(struct mpi_softc *, void *, size_t);

void			mpi_empty_done(struct mpi_ccb *);

int			mpi_iocinit(struct mpi_softc *);
int			mpi_iocfacts(struct mpi_softc *);
int			mpi_portfacts(struct mpi_softc *);
int			mpi_portenable(struct mpi_softc *);
int			mpi_cfg_coalescing(struct mpi_softc *);
void			mpi_get_raid(struct mpi_softc *);
int			mpi_fwupload(struct mpi_softc *);
int			mpi_manufacturing(struct mpi_softc *);
int			mpi_scsi_probe_virtual(struct scsi_link *);

int			mpi_eventnotify(struct mpi_softc *);
void			mpi_eventnotify_done(struct mpi_ccb *);
void			mpi_eventnotify_free(struct mpi_softc *,
			    struct mpi_rcb *);
void			mpi_eventack(void *, void *);
void			mpi_eventack_done(struct mpi_ccb *);
int			mpi_evt_sas(struct mpi_softc *, struct mpi_rcb *);
void			mpi_evt_sas_detach(void *, void *);
void			mpi_evt_sas_detach_done(struct mpi_ccb *);
void			mpi_fc_rescan(void *);

int			mpi_req_cfg_header(struct mpi_softc *, u_int8_t,
			    u_int8_t, u_int32_t, int, void *);
int			mpi_req_cfg_page(struct mpi_softc *, u_int32_t, int,
			    void *, int, void *, size_t);

int			mpi_ioctl_cache(struct scsi_link *, u_long,
			    struct dk_cache *);

#if NBIO > 0
int		mpi_bio_get_pg0_raid(struct mpi_softc *, int);
int		mpi_ioctl(struct device *, u_long, caddr_t);
int		mpi_ioctl_inq(struct mpi_softc *, struct bioc_inq *);
int		mpi_ioctl_vol(struct mpi_softc *, struct bioc_vol *);
int		mpi_ioctl_disk(struct mpi_softc *, struct bioc_disk *);
int		mpi_ioctl_setstate(struct mpi_softc *, struct bioc_setstate *);
#ifndef SMALL_KERNEL
int		mpi_create_sensors(struct mpi_softc *);
void		mpi_refresh_sensors(void *);
#endif /* SMALL_KERNEL */
#endif /* NBIO > 0 */

#define DEVNAME(s)		((s)->sc_dev.dv_xname)

#define	dwordsof(s)		(sizeof(s) / sizeof(u_int32_t))

#define mpi_read_db(s)		mpi_read((s), MPI_DOORBELL)
#define mpi_write_db(s, v)	mpi_write((s), MPI_DOORBELL, (v))
#define mpi_read_intr(s)	bus_space_read_4((s)->sc_iot, (s)->sc_ioh, \
				    MPI_INTR_STATUS)
#define mpi_write_intr(s, v)	mpi_write((s), MPI_INTR_STATUS, (v))
#define mpi_pop_reply(s)	bus_space_read_4((s)->sc_iot, (s)->sc_ioh, \
				    MPI_REPLY_QUEUE)
#define mpi_push_reply_db(s, v) bus_space_write_4((s)->sc_iot, (s)->sc_ioh, \
				    MPI_REPLY_QUEUE, (v))	

#define mpi_wait_db_int(s)	mpi_wait_ne((s), MPI_INTR_STATUS, \
				    MPI_INTR_STATUS_DOORBELL, 0)
#define mpi_wait_db_ack(s)	mpi_wait_eq((s), MPI_INTR_STATUS, \
				    MPI_INTR_STATUS_IOCDOORBELL, 0)

#define MPI_PG_EXTENDED		(1<<0)
#define MPI_PG_POLL		(1<<1)
#define MPI_PG_FMT		"\020" "\002POLL" "\001EXTENDED"

#define mpi_cfg_header(_s, _t, _n, _a, _h) \
	mpi_req_cfg_header((_s), (_t), (_n), (_a), \
	    MPI_PG_POLL, (_h))
#define mpi_ecfg_header(_s, _t, _n, _a, _h) \
	mpi_req_cfg_header((_s), (_t), (_n), (_a), \
	    MPI_PG_POLL|MPI_PG_EXTENDED, (_h))

#define mpi_cfg_page(_s, _a, _h, _r, _p, _l) \
	mpi_req_cfg_page((_s), (_a), MPI_PG_POLL, \
	    (_h), (_r), (_p), (_l))
#define mpi_ecfg_page(_s, _a, _h, _r, _p, _l) \
	mpi_req_cfg_page((_s), (_a), MPI_PG_POLL|MPI_PG_EXTENDED, \
	    (_h), (_r), (_p), (_l))

static inline void
mpi_dvatosge(struct mpi_sge *sge, u_int64_t dva)
{
	htolem32(&sge->sg_addr_lo, dva);
	htolem32(&sge->sg_addr_hi, dva >> 32);
}

int
mpi_attach(struct mpi_softc *sc)
{
	struct scsibus_attach_args	saa;
	struct mpi_ccb			*ccb;

	printf("\n");

	rw_init(&sc->sc_lock, "mpi_lock");
	task_set(&sc->sc_evt_rescan, mpi_fc_rescan, sc);

	/* disable interrupts */
	mpi_write(sc, MPI_INTR_MASK,
	    MPI_INTR_MASK_REPLY | MPI_INTR_MASK_DOORBELL);

	if (mpi_init(sc) != 0) {
		printf("%s: unable to initialise\n", DEVNAME(sc));
		return (1);
	}

	if (mpi_iocfacts(sc) != 0) {
		printf("%s: unable to get iocfacts\n", DEVNAME(sc));
		return (1);
	}

	if (mpi_alloc_ccbs(sc) != 0) {
		/* error already printed */
		return (1);
	}

	if (mpi_alloc_replies(sc) != 0) {
		printf("%s: unable to allocate reply space\n", DEVNAME(sc));
		goto free_ccbs;
	}

	if (mpi_iocinit(sc) != 0) {
		printf("%s: unable to send iocinit\n", DEVNAME(sc));
		goto free_ccbs;
	}

	/* spin until we're operational */
	if (mpi_wait_eq(sc, MPI_DOORBELL, MPI_DOORBELL_STATE,
	    MPI_DOORBELL_STATE_OPER) != 0) {
		printf("%s: state: 0x%08x\n", DEVNAME(sc),
		    mpi_read_db(sc) & MPI_DOORBELL_STATE);
		printf("%s: operational state timeout\n", DEVNAME(sc));
		goto free_ccbs;
	}

	mpi_push_replies(sc);

	if (mpi_portfacts(sc) != 0) {
		printf("%s: unable to get portfacts\n", DEVNAME(sc));
		goto free_replies;
	}

	if (mpi_cfg_coalescing(sc) != 0) {
		printf("%s: unable to configure coalescing\n", DEVNAME(sc));
		goto free_replies;
	}

	switch (sc->sc_porttype) {
	case MPI_PORTFACTS_PORTTYPE_SAS:
		SIMPLEQ_INIT(&sc->sc_evt_scan_queue);
		mtx_init(&sc->sc_evt_scan_mtx, IPL_BIO);
		scsi_ioh_set(&sc->sc_evt_scan_handler, &sc->sc_iopool,
		    mpi_evt_sas_detach, sc);
		/* FALLTHROUGH */
	case MPI_PORTFACTS_PORTTYPE_FC:
		if (mpi_eventnotify(sc) != 0) {
			printf("%s: unable to enable events\n", DEVNAME(sc));
			goto free_replies;
		}
		break;
	}

	if (mpi_portenable(sc) != 0) {
		printf("%s: unable to enable port\n", DEVNAME(sc));
		goto free_replies;
	}

	if (mpi_fwupload(sc) != 0) {
		printf("%s: unable to upload firmware\n", DEVNAME(sc));
		goto free_replies;
	}

	if (mpi_manufacturing(sc) != 0) {
		printf("%s: unable to fetch manufacturing info\n", DEVNAME(sc));		goto free_replies;
	}

	switch (sc->sc_porttype) {
	case MPI_PORTFACTS_PORTTYPE_SCSI:
		if (mpi_cfg_spi_port(sc) != 0) {
			printf("%s: unable to configure spi\n", DEVNAME(sc));
			goto free_replies;
		}
		mpi_squash_ppr(sc);
		break;
	case MPI_PORTFACTS_PORTTYPE_SAS:
		if (mpi_cfg_sas(sc) != 0) {
			printf("%s: unable to configure sas\n", DEVNAME(sc));
			goto free_replies;
		}
		break;
	case MPI_PORTFACTS_PORTTYPE_FC:
		if (mpi_cfg_fc(sc) != 0) {
			printf("%s: unable to configure fc\n", DEVNAME(sc));
			goto free_replies;
		}
		break;
	}

	/* get raid pages */
	mpi_get_raid(sc);
#if NBIO > 0
	if (sc->sc_flags & MPI_F_RAID) {
		if (bio_register(&sc->sc_dev, mpi_ioctl) != 0)
			panic("%s: controller registration failed",
			    DEVNAME(sc));
		else {
			if (mpi_cfg_header(sc, MPI_CONFIG_REQ_PAGE_TYPE_IOC,
			    2, 0, &sc->sc_cfg_hdr) != 0) {
				panic("%s: can't get IOC page 2 hdr",
				    DEVNAME(sc));
			}

			sc->sc_vol_page = mallocarray(sc->sc_cfg_hdr.page_length,
			    4, M_TEMP, M_WAITOK | M_CANFAIL);
			if (sc->sc_vol_page == NULL) {
				panic("%s: can't get memory for IOC page 2, "
				    "bio disabled", DEVNAME(sc));
			}

			if (mpi_cfg_page(sc, 0, &sc->sc_cfg_hdr, 1,
			    sc->sc_vol_page,
			    sc->sc_cfg_hdr.page_length * 4) != 0) {
				panic("%s: can't get IOC page 2", DEVNAME(sc));
			}

			sc->sc_vol_list = (struct mpi_cfg_raid_vol *)
			    (sc->sc_vol_page + 1);
 
			sc->sc_ioctl = mpi_ioctl;
		}
	}
#endif /* NBIO > 0 */

	/* we should be good to go now, attach scsibus */
	sc->sc_link.adapter = &mpi_switch;
	sc->sc_link.adapter_softc = sc;
	sc->sc_link.adapter_target = sc->sc_target;
	sc->sc_link.adapter_buswidth = sc->sc_buswidth;
	sc->sc_link.openings = MAX(sc->sc_maxcmds / sc->sc_buswidth, 16);
	sc->sc_link.pool = &sc->sc_iopool;

	memset(&saa, 0, sizeof(saa));
	saa.saa_sc_link = &sc->sc_link;

	/* config_found() returns the scsibus attached to us */
	sc->sc_scsibus = (struct scsibus_softc *) config_found(&sc->sc_dev,
	    &saa, scsiprint);

	/* do domain validation */
	if (sc->sc_porttype == MPI_PORTFACTS_PORTTYPE_SCSI)
		mpi_run_ppr(sc);

	/* enable interrupts */
	mpi_write(sc, MPI_INTR_MASK, MPI_INTR_MASK_DOORBELL);

#if NBIO > 0
#ifndef SMALL_KERNEL
	mpi_create_sensors(sc);
#endif /* SMALL_KERNEL */
#endif /* NBIO > 0 */

	return (0);

free_replies:
	bus_dmamap_sync(sc->sc_dmat, MPI_DMA_MAP(sc->sc_replies), 0,
	    sc->sc_repq * MPI_REPLY_SIZE, BUS_DMASYNC_POSTREAD);
	mpi_dmamem_free(sc, sc->sc_replies);
free_ccbs:
	while ((ccb = mpi_get_ccb(sc)) != NULL)
		bus_dmamap_destroy(sc->sc_dmat, ccb->ccb_dmamap);
	mpi_dmamem_free(sc, sc->sc_requests);
	free(sc->sc_ccbs, M_DEVBUF, 0);

	return(1);
}

int
mpi_cfg_spi_port(struct mpi_softc *sc)
{
	struct mpi_cfg_hdr		hdr;
	struct mpi_cfg_spi_port_pg1	port;

	if (mpi_cfg_header(sc, MPI_CONFIG_REQ_PAGE_TYPE_SCSI_SPI_PORT, 1, 0x0,
	    &hdr) != 0)
		return (1);

	if (mpi_cfg_page(sc, 0x0, &hdr, 1, &port, sizeof(port)) != 0)
		return (1);

	DNPRINTF(MPI_D_MISC, "%s: mpi_cfg_spi_port_pg1\n", DEVNAME(sc));
	DNPRINTF(MPI_D_MISC, "%s:  port_scsi_id: %d port_resp_ids 0x%04x\n",
	    DEVNAME(sc), port.port_scsi_id, letoh16(port.port_resp_ids));
	DNPRINTF(MPI_D_MISC, "%s:  on_bus_timer_value: 0x%08x\n", DEVNAME(sc),
	    letoh32(port.port_scsi_id));
	DNPRINTF(MPI_D_MISC, "%s:  target_config: 0x%02x id_config: 0x%04x\n",
	    DEVNAME(sc), port.target_config, letoh16(port.id_config));

	if (port.port_scsi_id == sc->sc_target &&
	    port.port_resp_ids == htole16(1 << sc->sc_target) &&
	    port.on_bus_timer_value != htole32(0x0))
		return (0);

	DNPRINTF(MPI_D_MISC, "%s: setting port scsi id to %d\n", DEVNAME(sc),
	    sc->sc_target);
	port.port_scsi_id = sc->sc_target;
	port.port_resp_ids = htole16(1 << sc->sc_target);
	port.on_bus_timer_value = htole32(0x07000000); /* XXX magic */

	if (mpi_cfg_page(sc, 0x0, &hdr, 0, &port, sizeof(port)) != 0) {
		printf("%s: unable to configure port scsi id\n", DEVNAME(sc));
		return (1);
	}

	return (0);
}

void
mpi_squash_ppr(struct mpi_softc *sc)
{
	struct mpi_cfg_hdr		hdr;
	struct mpi_cfg_spi_dev_pg1	page;
	int				i;

	DNPRINTF(MPI_D_PPR, "%s: mpi_squash_ppr\n", DEVNAME(sc));

	for (i = 0; i < sc->sc_buswidth; i++) {
		if (mpi_cfg_header(sc, MPI_CONFIG_REQ_PAGE_TYPE_SCSI_SPI_DEV,
		    1, i, &hdr) != 0)
			return;

		if (mpi_cfg_page(sc, i, &hdr, 1, &page, sizeof(page)) != 0)
			return;

		DNPRINTF(MPI_D_PPR, "%s:  target: %d req_params1: 0x%02x "
		    "req_offset: 0x%02x req_period: 0x%02x "
		    "req_params2: 0x%02x conf: 0x%08x\n", DEVNAME(sc), i,
		    page.req_params1, page.req_offset, page.req_period,
		    page.req_params2, letoh32(page.configuration));

		page.req_params1 = 0x0;
		page.req_offset = 0x0;
		page.req_period = 0x0;
		page.req_params2 = 0x0;
		page.configuration = htole32(0x0);

		if (mpi_cfg_page(sc, i, &hdr, 0, &page, sizeof(page)) != 0)
			return;
	}
}

void
mpi_run_ppr(struct mpi_softc *sc)
{
	struct mpi_cfg_hdr		hdr;
	struct mpi_cfg_spi_port_pg0	port_pg;
	struct mpi_cfg_ioc_pg3		*physdisk_pg;
	struct mpi_cfg_raid_physdisk	*physdisk_list, *physdisk;
	size_t				pagelen;
	struct scsi_link		*link;
	int				i, tries;

	if (mpi_cfg_header(sc, MPI_CONFIG_REQ_PAGE_TYPE_SCSI_SPI_PORT, 0, 0x0,
	    &hdr) != 0) {
		DNPRINTF(MPI_D_PPR, "%s: mpi_run_ppr unable to fetch header\n",
		    DEVNAME(sc));
		return;
	}

	if (mpi_cfg_page(sc, 0x0, &hdr, 1, &port_pg, sizeof(port_pg)) != 0) {
		DNPRINTF(MPI_D_PPR, "%s: mpi_run_ppr unable to fetch page\n",
		    DEVNAME(sc));
		return;
	}

	for (i = 0; i < sc->sc_buswidth; i++) {
		link = scsi_get_link(sc->sc_scsibus, i, 0);
		if (link == NULL)
			continue;

		/* do not ppr volumes */
		if (link->flags & SDEV_VIRTUAL)
			continue;

		tries = 0;
		while (mpi_ppr(sc, link, NULL, port_pg.min_period,
		    port_pg.max_offset, tries) == EAGAIN)
			tries++;
	}

	if ((sc->sc_flags & MPI_F_RAID) == 0)
		return;

	if (mpi_cfg_header(sc, MPI_CONFIG_REQ_PAGE_TYPE_IOC, 3, 0x0,
	    &hdr) != 0) {
		DNPRINTF(MPI_D_RAID|MPI_D_PPR, "%s: mpi_run_ppr unable to "
		    "fetch ioc pg 3 header\n", DEVNAME(sc));
		return;
	}

	pagelen = hdr.page_length * 4; /* dwords to bytes */
	physdisk_pg = malloc(pagelen, M_TEMP, M_WAITOK|M_CANFAIL);
	if (physdisk_pg == NULL) {
		DNPRINTF(MPI_D_RAID|MPI_D_PPR, "%s: mpi_run_ppr unable to "
		    "allocate ioc pg 3\n", DEVNAME(sc));
		return;
	}
	physdisk_list = (struct mpi_cfg_raid_physdisk *)(physdisk_pg + 1);

	if (mpi_cfg_page(sc, 0, &hdr, 1, physdisk_pg, pagelen) != 0) {
		DNPRINTF(MPI_D_PPR|MPI_D_PPR, "%s: mpi_run_ppr unable to "
		    "fetch ioc page 3\n", DEVNAME(sc));
		goto out;
	}

	DNPRINTF(MPI_D_PPR|MPI_D_PPR, "%s:  no_phys_disks: %d\n", DEVNAME(sc),
	    physdisk_pg->no_phys_disks);

	for (i = 0; i < physdisk_pg->no_phys_disks; i++) {
		physdisk = &physdisk_list[i];

		DNPRINTF(MPI_D_PPR|MPI_D_PPR, "%s:  id: %d bus: %d ioc: %d "
		    "num: %d\n", DEVNAME(sc), physdisk->phys_disk_id,
		    physdisk->phys_disk_bus, physdisk->phys_disk_ioc,
		    physdisk->phys_disk_num);

		if (physdisk->phys_disk_ioc != sc->sc_ioc_number)
			continue;

		tries = 0;
		while (mpi_ppr(sc, NULL, physdisk, port_pg.min_period,
		    port_pg.max_offset, tries) == EAGAIN)
			tries++;
	}

out:
	free(physdisk_pg, M_TEMP, pagelen);
}

int
mpi_ppr(struct mpi_softc *sc, struct scsi_link *link,
    struct mpi_cfg_raid_physdisk *physdisk, int period, int offset, int try)
{
	struct mpi_cfg_hdr		hdr0, hdr1;
	struct mpi_cfg_spi_dev_pg0	pg0;
	struct mpi_cfg_spi_dev_pg1	pg1;
	u_int32_t			address;
	int				id;
	int				raid = 0;

	DNPRINTF(MPI_D_PPR, "%s: mpi_ppr period: %d offset: %d try: %d "
	    "link quirks: 0x%x\n", DEVNAME(sc), period, offset, try,
	    link->quirks);

	if (try >= 3)
		return (EIO);

	if (physdisk == NULL) {
		if ((link->inqdata.device & SID_TYPE) == T_PROCESSOR)
			return (EIO);

		address = link->target;
		id = link->target;
	} else {
		raid = 1;
		address = (physdisk->phys_disk_bus << 8) |
		    (physdisk->phys_disk_id);
		id = physdisk->phys_disk_num;
	}

	if (mpi_cfg_header(sc, MPI_CONFIG_REQ_PAGE_TYPE_SCSI_SPI_DEV, 0,
	    address, &hdr0) != 0) {
		DNPRINTF(MPI_D_PPR, "%s: mpi_ppr unable to fetch header 0\n",
		    DEVNAME(sc));
		return (EIO);
	}

	if (mpi_cfg_header(sc, MPI_CONFIG_REQ_PAGE_TYPE_SCSI_SPI_DEV, 1,
	    address, &hdr1) != 0) {
		DNPRINTF(MPI_D_PPR, "%s: mpi_ppr unable to fetch header 1\n",
		    DEVNAME(sc));
		return (EIO);
	}

#ifdef MPI_DEBUG
	if (mpi_cfg_page(sc, address, &hdr0, 1, &pg0, sizeof(pg0)) != 0) {
		DNPRINTF(MPI_D_PPR, "%s: mpi_ppr unable to fetch page 0\n",
		    DEVNAME(sc));
		return (EIO);
	}

	DNPRINTF(MPI_D_PPR, "%s: mpi_ppr dev pg 0 neg_params1: 0x%02x "
	    "neg_offset: %d neg_period: 0x%02x neg_params2: 0x%02x "
	    "info: 0x%08x\n", DEVNAME(sc), pg0.neg_params1, pg0.neg_offset,
	    pg0.neg_period, pg0.neg_params2, letoh32(pg0.information));
#endif

	if (mpi_cfg_page(sc, address, &hdr1, 1, &pg1, sizeof(pg1)) != 0) {
		DNPRINTF(MPI_D_PPR, "%s: mpi_ppr unable to fetch page 1\n",
		    DEVNAME(sc));
		return (EIO);
	}

	DNPRINTF(MPI_D_PPR, "%s: mpi_ppr dev pg 1 req_params1: 0x%02x "
	    "req_offset: 0x%02x req_period: 0x%02x req_params2: 0x%02x "
	    "conf: 0x%08x\n", DEVNAME(sc), pg1.req_params1, pg1.req_offset,
	    pg1.req_period, pg1.req_params2, letoh32(pg1.configuration));

	pg1.req_params1 = 0;
	pg1.req_offset = offset;
	pg1.req_period = period;
	pg1.req_params2 &= ~MPI_CFG_SPI_DEV_1_REQPARAMS_WIDTH;

	if (raid || !(link->quirks & SDEV_NOSYNC)) {
		pg1.req_params2 |= MPI_CFG_SPI_DEV_1_REQPARAMS_WIDTH_WIDE;

		switch (try) {
		case 0: /* U320 */
			break;
		case 1: /* U160 */
			pg1.req_period = 0x09;
			break;
		case 2: /* U80 */
			pg1.req_period = 0x0a;
			break;
		}

		if (pg1.req_period < 0x09) {
			/* Ultra320: enable QAS & PACKETIZED */
			pg1.req_params1 |= MPI_CFG_SPI_DEV_1_REQPARAMS_QAS |
			    MPI_CFG_SPI_DEV_1_REQPARAMS_PACKETIZED;
		}
		if (pg1.req_period < 0xa) {
			/* >= Ultra160: enable dual xfers */
			pg1.req_params1 |=
			    MPI_CFG_SPI_DEV_1_REQPARAMS_DUALXFERS;
		}
	}

	DNPRINTF(MPI_D_PPR, "%s: mpi_ppr dev pg 1 req_params1: 0x%02x "
	    "req_offset: 0x%02x req_period: 0x%02x req_params2: 0x%02x "
	    "conf: 0x%08x\n", DEVNAME(sc), pg1.req_params1, pg1.req_offset,
	    pg1.req_period, pg1.req_params2, letoh32(pg1.configuration));

	if (mpi_cfg_page(sc, address, &hdr1, 0, &pg1, sizeof(pg1)) != 0) {
		DNPRINTF(MPI_D_PPR, "%s: mpi_ppr unable to write page 1\n",
		    DEVNAME(sc));
		return (EIO);
	}

	if (mpi_cfg_page(sc, address, &hdr1, 1, &pg1, sizeof(pg1)) != 0) {
		DNPRINTF(MPI_D_PPR, "%s: mpi_ppr unable to read page 1\n",
		    DEVNAME(sc));
		return (EIO);
	}

	DNPRINTF(MPI_D_PPR, "%s: mpi_ppr dev pg 1 req_params1: 0x%02x "
	    "req_offset: 0x%02x req_period: 0x%02x req_params2: 0x%02x "
	    "conf: 0x%08x\n", DEVNAME(sc), pg1.req_params1, pg1.req_offset,
	    pg1.req_period, pg1.req_params2, letoh32(pg1.configuration));

	if (mpi_inq(sc, id, raid) != 0) {
		DNPRINTF(MPI_D_PPR, "%s: mpi_ppr unable to do inquiry against "
		    "target %d\n", DEVNAME(sc), link->target);
		return (EIO);
	}

	if (mpi_cfg_page(sc, address, &hdr0, 1, &pg0, sizeof(pg0)) != 0) {
		DNPRINTF(MPI_D_PPR, "%s: mpi_ppr unable to read page 0 after "
		    "inquiry\n", DEVNAME(sc));
		return (EIO);
	}

	DNPRINTF(MPI_D_PPR, "%s: mpi_ppr dev pg 0 neg_params1: 0x%02x "
	    "neg_offset: %d neg_period: 0x%02x neg_params2: 0x%02x "
	    "info: 0x%08x\n", DEVNAME(sc), pg0.neg_params1, pg0.neg_offset,
	    pg0.neg_period, pg0.neg_params2, letoh32(pg0.information));

	if (!(lemtoh32(&pg0.information) & 0x07) && (try == 0)) {
		DNPRINTF(MPI_D_PPR, "%s: mpi_ppr U320 ppr rejected\n",
		    DEVNAME(sc));
		return (EAGAIN);
	}

	if ((((lemtoh32(&pg0.information) >> 8) & 0xff) > 0x09) && (try == 1)) {
		DNPRINTF(MPI_D_PPR, "%s: mpi_ppr U160 ppr rejected\n",
		    DEVNAME(sc));
		return (EAGAIN);
	}

	if (lemtoh32(&pg0.information) & 0x0e) {
		DNPRINTF(MPI_D_PPR, "%s: mpi_ppr ppr rejected: %0x\n",
		    DEVNAME(sc), lemtoh32(&pg0.information));
		return (EAGAIN);
	}

	switch(pg0.neg_period) {
	case 0x08:
		period = 160;
		break;
	case 0x09:
		period = 80;
		break;
	case 0x0a:
		period = 40;
		break;
	case 0x0b:
		period = 20;
		break;
	case 0x0c:
		period = 10;
		break;
	default:
		period = 0;
		break;
	}

	printf("%s: %s %d %s at %dMHz width %dbit offset %d "
	    "QAS %d DT %d IU %d\n", DEVNAME(sc), raid ? "phys disk" : "target",
	    id, period ? "Sync" : "Async", period,
	    (pg0.neg_params2 & MPI_CFG_SPI_DEV_0_NEGPARAMS_WIDTH_WIDE) ? 16 : 8,
	    pg0.neg_offset,
	    (pg0.neg_params1 & MPI_CFG_SPI_DEV_0_NEGPARAMS_QAS) ? 1 : 0,
	    (pg0.neg_params1 & MPI_CFG_SPI_DEV_0_NEGPARAMS_DUALXFERS) ? 1 : 0,
	    (pg0.neg_params1 & MPI_CFG_SPI_DEV_0_NEGPARAMS_PACKETIZED) ? 1 : 0);

	return (0);
}

int
mpi_inq(struct mpi_softc *sc, u_int16_t target, int physdisk)
{
	struct mpi_ccb			*ccb;
	struct scsi_inquiry		inq;
	struct inq_bundle {
		struct mpi_msg_scsi_io		io;
		struct mpi_sge			sge;
		struct scsi_inquiry_data	inqbuf;
		struct scsi_sense_data		sense;
	} __packed			*bundle;
	struct mpi_msg_scsi_io		*io;
	struct mpi_sge			*sge;

	DNPRINTF(MPI_D_PPR, "%s: mpi_inq\n", DEVNAME(sc));

	memset(&inq, 0, sizeof(inq));
	inq.opcode = INQUIRY;
	_lto2b(sizeof(struct scsi_inquiry_data), inq.length);

	ccb = scsi_io_get(&sc->sc_iopool, SCSI_NOSLEEP);
	if (ccb == NULL)
		return (1);

	ccb->ccb_done = mpi_empty_done;

	bundle = ccb->ccb_cmd;
	io = &bundle->io;
	sge = &bundle->sge;

	io->function = physdisk ? MPI_FUNCTION_RAID_SCSI_IO_PASSTHROUGH :
	    MPI_FUNCTION_SCSI_IO_REQUEST;
	/*
	 * bus is always 0
	 * io->bus = htole16(sc->sc_bus);
	 */
	io->target_id = target;

	io->cdb_length = sizeof(inq);
	io->sense_buf_len = sizeof(struct scsi_sense_data);
	io->msg_flags = MPI_SCSIIO_SENSE_BUF_ADDR_WIDTH_64;

	/*
	 * always lun 0
	 * io->lun[0] = htobe16(link->lun);
	 */

	io->direction = MPI_SCSIIO_DIR_READ;
	io->tagging = MPI_SCSIIO_ATTR_NO_DISCONNECT;

	memcpy(io->cdb, &inq, sizeof(inq));

	htolem32(&io->data_length, sizeof(struct scsi_inquiry_data));

	htolem32(&io->sense_buf_low_addr, ccb->ccb_cmd_dva +
	    offsetof(struct inq_bundle, sense));

	htolem32(&sge->sg_hdr, MPI_SGE_FL_TYPE_SIMPLE | MPI_SGE_FL_SIZE_64 |
	    MPI_SGE_FL_LAST | MPI_SGE_FL_EOB | MPI_SGE_FL_EOL |
	    (u_int32_t)sizeof(inq));

	mpi_dvatosge(sge, ccb->ccb_cmd_dva +
	    offsetof(struct inq_bundle, inqbuf));

	if (mpi_poll(sc, ccb, 5000) != 0)
		return (1);

	if (ccb->ccb_rcb != NULL)
		mpi_push_reply(sc, ccb->ccb_rcb);

	scsi_io_put(&sc->sc_iopool, ccb);

	return (0);
}

int
mpi_cfg_sas(struct mpi_softc *sc)
{
	struct mpi_ecfg_hdr		ehdr;
	struct mpi_cfg_sas_iou_pg1	*pg;
	size_t				pagelen;
	int				rv = 0;

	if (mpi_ecfg_header(sc, MPI_CONFIG_REQ_EXTPAGE_TYPE_SAS_IO_UNIT, 1, 0,
	    &ehdr) != 0)
		return (0);

	pagelen = lemtoh16(&ehdr.ext_page_length) * 4;
	pg = malloc(pagelen, M_TEMP, M_NOWAIT | M_ZERO);
	if (pg == NULL)
		return (ENOMEM);

	if (mpi_ecfg_page(sc, 0, &ehdr, 1, pg, pagelen) != 0)
		goto out;

	if (pg->max_sata_q_depth != 32) {
		pg->max_sata_q_depth = 32;

		if (mpi_ecfg_page(sc, 0, &ehdr, 0, pg, pagelen) != 0)
			goto out;
	}

out:
	free(pg, M_TEMP, pagelen);
	return (rv);
}

int
mpi_cfg_fc(struct mpi_softc *sc)
{
	struct mpi_cfg_hdr		hdr;
	struct mpi_cfg_fc_port_pg0	pg0;
	struct mpi_cfg_fc_port_pg1	pg1;

	if (mpi_cfg_header(sc, MPI_CONFIG_REQ_PAGE_TYPE_FC_PORT, 0, 0,
	    &hdr) != 0) {
		printf("%s: unable to fetch FC port header 0\n", DEVNAME(sc));
		return (1);
	}

	if (mpi_cfg_page(sc, 0, &hdr, 1, &pg0, sizeof(pg0)) != 0) {
		printf("%s: unable to fetch FC port page 0\n", DEVNAME(sc));
		return (1);
	}

	sc->sc_link.port_wwn = letoh64(pg0.wwpn);
	sc->sc_link.node_wwn = letoh64(pg0.wwnn);

	/* configure port config more to our liking */
	if (mpi_cfg_header(sc, MPI_CONFIG_REQ_PAGE_TYPE_FC_PORT, 1, 0,
	    &hdr) != 0) {
		printf("%s: unable to fetch FC port header 1\n", DEVNAME(sc));
		return (1);
	}

	if (mpi_cfg_page(sc, 0, &hdr, 1, &pg1, sizeof(pg1)) != 0) {
		printf("%s: unable to fetch FC port page 1\n", DEVNAME(sc));
		return (1);
	}

	SET(pg1.flags, htole32(MPI_CFG_FC_PORT_0_FLAGS_IMMEDIATE_ERROR |
	    MPI_CFG_FC_PORT_0_FLAGS_VERBOSE_RESCAN));

	if (mpi_cfg_page(sc, 0, &hdr, 0, &pg1, sizeof(pg1)) != 0) {
		printf("%s: unable to set FC port page 1\n", DEVNAME(sc));
		return (1);
	}

	return (0);
}

void
mpi_detach(struct mpi_softc *sc)
{

}

int
mpi_intr(void *arg)
{
	struct mpi_softc		*sc = arg;
	u_int32_t			reg;
	int				rv = 0;

	if ((mpi_read_intr(sc) & MPI_INTR_STATUS_REPLY) == 0)
		return (rv);

	while ((reg = mpi_pop_reply(sc)) != 0xffffffff) {
		mpi_reply(sc, reg);
		rv = 1;
	}

	return (rv);
}

void
mpi_reply(struct mpi_softc *sc, u_int32_t reg)
{
	struct mpi_ccb			*ccb;
	struct mpi_rcb			*rcb = NULL;
	struct mpi_msg_reply		*reply = NULL;
	u_int32_t			reply_dva;
	int				id;
	int				i;

	DNPRINTF(MPI_D_INTR, "%s: mpi_reply reg: 0x%08x\n", DEVNAME(sc), reg);

	if (reg & MPI_REPLY_QUEUE_ADDRESS) {
		reply_dva = (reg & MPI_REPLY_QUEUE_ADDRESS_MASK) << 1;
		i = (reply_dva - (u_int32_t)MPI_DMA_DVA(sc->sc_replies)) /
		    MPI_REPLY_SIZE;
		rcb = &sc->sc_rcbs[i];

		bus_dmamap_sync(sc->sc_dmat,
		    MPI_DMA_MAP(sc->sc_replies), rcb->rcb_offset,
		    MPI_REPLY_SIZE, BUS_DMASYNC_POSTREAD);

		reply = rcb->rcb_reply;

		id = lemtoh32(&reply->msg_context);
	} else {
		switch (reg & MPI_REPLY_QUEUE_TYPE_MASK) {
		case MPI_REPLY_QUEUE_TYPE_INIT:
			id = reg & MPI_REPLY_QUEUE_CONTEXT;
			break;

		default:
			panic("%s: unsupported context reply",
			    DEVNAME(sc));
		}
	}

	DNPRINTF(MPI_D_INTR, "%s: mpi_reply id: %d reply: %p\n",
	    DEVNAME(sc), id, reply);

	ccb = &sc->sc_ccbs[id];

	bus_dmamap_sync(sc->sc_dmat, MPI_DMA_MAP(sc->sc_requests),
	    ccb->ccb_offset, MPI_REQUEST_SIZE,
	    BUS_DMASYNC_POSTREAD | BUS_DMASYNC_POSTWRITE);
	ccb->ccb_state = MPI_CCB_READY;
	ccb->ccb_rcb = rcb;

	ccb->ccb_done(ccb);
}

struct mpi_dmamem *
mpi_dmamem_alloc(struct mpi_softc *sc, size_t size)
{
	struct mpi_dmamem		*mdm;
	int				nsegs;

	mdm = malloc(sizeof(struct mpi_dmamem), M_DEVBUF, M_NOWAIT | M_ZERO);
	if (mdm == NULL)
		return (NULL);

	mdm->mdm_size = size;

	if (bus_dmamap_create(sc->sc_dmat, size, 1, size, 0,
	    BUS_DMA_NOWAIT | BUS_DMA_ALLOCNOW, &mdm->mdm_map) != 0)
		goto mdmfree;

	if (bus_dmamem_alloc(sc->sc_dmat, size, PAGE_SIZE, 0, &mdm->mdm_seg,
	    1, &nsegs, BUS_DMA_NOWAIT | BUS_DMA_ZERO) != 0)
		goto destroy;

	if (bus_dmamem_map(sc->sc_dmat, &mdm->mdm_seg, nsegs, size,
	    &mdm->mdm_kva, BUS_DMA_NOWAIT) != 0)
		goto free;

	if (bus_dmamap_load(sc->sc_dmat, mdm->mdm_map, mdm->mdm_kva, size,
	    NULL, BUS_DMA_NOWAIT) != 0)
		goto unmap;

	DNPRINTF(MPI_D_MEM, "%s: mpi_dmamem_alloc size: %d mdm: %#x "
	    "map: %#x nsegs: %d segs: %#x kva: %x\n",
	    DEVNAME(sc), size, mdm->mdm_map, nsegs, mdm->mdm_seg, mdm->mdm_kva);

	return (mdm);

unmap:
	bus_dmamem_unmap(sc->sc_dmat, mdm->mdm_kva, size);
free:
	bus_dmamem_free(sc->sc_dmat, &mdm->mdm_seg, 1);
destroy:
	bus_dmamap_destroy(sc->sc_dmat, mdm->mdm_map);
mdmfree:
	free(mdm, M_DEVBUF, sizeof *mdm);

	return (NULL);
}

void
mpi_dmamem_free(struct mpi_softc *sc, struct mpi_dmamem *mdm)
{
	DNPRINTF(MPI_D_MEM, "%s: mpi_dmamem_free %#x\n", DEVNAME(sc), mdm);

	bus_dmamap_unload(sc->sc_dmat, mdm->mdm_map);
	bus_dmamem_unmap(sc->sc_dmat, mdm->mdm_kva, mdm->mdm_size);
	bus_dmamem_free(sc->sc_dmat, &mdm->mdm_seg, 1);
	bus_dmamap_destroy(sc->sc_dmat, mdm->mdm_map);
	free(mdm, M_DEVBUF, sizeof *mdm);
}

int
mpi_alloc_ccbs(struct mpi_softc *sc)
{
	struct mpi_ccb			*ccb;
	u_int8_t			*cmd;
	int				i;

	SLIST_INIT(&sc->sc_ccb_free);
	mtx_init(&sc->sc_ccb_mtx, IPL_BIO);

	sc->sc_ccbs = mallocarray(sc->sc_maxcmds, sizeof(struct mpi_ccb),
	    M_DEVBUF, M_WAITOK | M_CANFAIL | M_ZERO);
	if (sc->sc_ccbs == NULL) {
		printf("%s: unable to allocate ccbs\n", DEVNAME(sc));
		return (1);
	}

	sc->sc_requests = mpi_dmamem_alloc(sc,
	    MPI_REQUEST_SIZE * sc->sc_maxcmds);
	if (sc->sc_requests == NULL) {
		printf("%s: unable to allocate ccb dmamem\n", DEVNAME(sc));
		goto free_ccbs;
	}
	cmd = MPI_DMA_KVA(sc->sc_requests);
	memset(cmd, 0, MPI_REQUEST_SIZE * sc->sc_maxcmds);

	for (i = 0; i < sc->sc_maxcmds; i++) {
		ccb = &sc->sc_ccbs[i];

		if (bus_dmamap_create(sc->sc_dmat, MAXPHYS,
		    sc->sc_max_sgl_len, MAXPHYS, 0,
		    BUS_DMA_NOWAIT | BUS_DMA_ALLOCNOW,
		    &ccb->ccb_dmamap) != 0) {
			printf("%s: unable to create dma map\n", DEVNAME(sc));
			goto free_maps;
		}

		ccb->ccb_sc = sc;
		ccb->ccb_id = i;
		ccb->ccb_offset = MPI_REQUEST_SIZE * i;
		ccb->ccb_state = MPI_CCB_READY;

		ccb->ccb_cmd = &cmd[ccb->ccb_offset];
		ccb->ccb_cmd_dva = (u_int32_t)MPI_DMA_DVA(sc->sc_requests) +
		    ccb->ccb_offset;

		DNPRINTF(MPI_D_CCB, "%s: mpi_alloc_ccbs(%d) ccb: %#x map: %#x "
		    "sc: %#x id: %#x offs: %#x cmd: %#x dva: %#x\n",
		    DEVNAME(sc), i, ccb, ccb->ccb_dmamap, ccb->ccb_sc,
		    ccb->ccb_id, ccb->ccb_offset, ccb->ccb_cmd,
		    ccb->ccb_cmd_dva);

		mpi_put_ccb(sc, ccb);
	}

	scsi_iopool_init(&sc->sc_iopool, sc, mpi_get_ccb, mpi_put_ccb);

	return (0);

free_maps:
	while ((ccb = mpi_get_ccb(sc)) != NULL)
		bus_dmamap_destroy(sc->sc_dmat, ccb->ccb_dmamap);

	mpi_dmamem_free(sc, sc->sc_requests);
free_ccbs:
	free(sc->sc_ccbs, M_DEVBUF, 0);

	return (1);
}

void *
mpi_get_ccb(void *xsc)
{
	struct mpi_softc		*sc = xsc;
	struct mpi_ccb			*ccb;

	mtx_enter(&sc->sc_ccb_mtx);
	ccb = SLIST_FIRST(&sc->sc_ccb_free);
	if (ccb != NULL) {
		SLIST_REMOVE_HEAD(&sc->sc_ccb_free, ccb_link);
		ccb->ccb_state = MPI_CCB_READY;
	}
	mtx_leave(&sc->sc_ccb_mtx);

	DNPRINTF(MPI_D_CCB, "%s: mpi_get_ccb %p\n", DEVNAME(sc), ccb);

	return (ccb);
}

void
mpi_put_ccb(void *xsc, void *io)
{
	struct mpi_softc		*sc = xsc;
	struct mpi_ccb			*ccb = io;

	DNPRINTF(MPI_D_CCB, "%s: mpi_put_ccb %p\n", DEVNAME(sc), ccb);

#ifdef DIAGNOSTIC
	if (ccb->ccb_state == MPI_CCB_FREE)
		panic("mpi_put_ccb: double free");
#endif

	ccb->ccb_state = MPI_CCB_FREE;
	ccb->ccb_cookie = NULL;
	ccb->ccb_done = NULL;
	memset(ccb->ccb_cmd, 0, MPI_REQUEST_SIZE);
	mtx_enter(&sc->sc_ccb_mtx);
	SLIST_INSERT_HEAD(&sc->sc_ccb_free, ccb, ccb_link);
	mtx_leave(&sc->sc_ccb_mtx);
}

int
mpi_alloc_replies(struct mpi_softc *sc)
{
	DNPRINTF(MPI_D_MISC, "%s: mpi_alloc_replies\n", DEVNAME(sc));

	sc->sc_rcbs = mallocarray(sc->sc_repq, sizeof(struct mpi_rcb), M_DEVBUF,
	    M_WAITOK|M_CANFAIL);
	if (sc->sc_rcbs == NULL)
		return (1);

	sc->sc_replies = mpi_dmamem_alloc(sc, sc->sc_repq * MPI_REPLY_SIZE);
	if (sc->sc_replies == NULL) {
		free(sc->sc_rcbs, M_DEVBUF, 0);
		return (1);
	}

	return (0);
}

void
mpi_push_reply(struct mpi_softc *sc, struct mpi_rcb *rcb)
{
	bus_dmamap_sync(sc->sc_dmat, MPI_DMA_MAP(sc->sc_replies),
	    rcb->rcb_offset, MPI_REPLY_SIZE, BUS_DMASYNC_PREREAD);
	mpi_push_reply_db(sc, rcb->rcb_reply_dva);
}

void
mpi_push_replies(struct mpi_softc *sc)
{
	struct mpi_rcb			*rcb;
	char				*kva = MPI_DMA_KVA(sc->sc_replies);
	int				i;

	bus_dmamap_sync(sc->sc_dmat, MPI_DMA_MAP(sc->sc_replies), 0,
	    sc->sc_repq * MPI_REPLY_SIZE, BUS_DMASYNC_PREREAD);

	for (i = 0; i < sc->sc_repq; i++) {
		rcb = &sc->sc_rcbs[i];

		rcb->rcb_reply = kva + MPI_REPLY_SIZE * i;
		rcb->rcb_offset = MPI_REPLY_SIZE * i;
		rcb->rcb_reply_dva = (u_int32_t)MPI_DMA_DVA(sc->sc_replies) +
		    MPI_REPLY_SIZE * i;
		mpi_push_reply_db(sc, rcb->rcb_reply_dva);
	}
}

void
mpi_start(struct mpi_softc *sc, struct mpi_ccb *ccb)
{
	struct mpi_msg_request *msg;

	DNPRINTF(MPI_D_RW, "%s: mpi_start %#x\n", DEVNAME(sc),
	    ccb->ccb_cmd_dva);

	msg = ccb->ccb_cmd;
	htolem32(&msg->msg_context, ccb->ccb_id);

	bus_dmamap_sync(sc->sc_dmat, MPI_DMA_MAP(sc->sc_requests),
	    ccb->ccb_offset, MPI_REQUEST_SIZE,
	    BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);

	ccb->ccb_state = MPI_CCB_QUEUED;
	bus_space_write_4(sc->sc_iot, sc->sc_ioh,
	    MPI_REQ_QUEUE, ccb->ccb_cmd_dva);
}

int
mpi_poll(struct mpi_softc *sc, struct mpi_ccb *ccb, int timeout)
{
	void				(*done)(struct mpi_ccb *);
	void				*cookie;
	int				rv = 1;
	u_int32_t			reg;

	DNPRINTF(MPI_D_INTR, "%s: mpi_poll timeout %d\n", DEVNAME(sc),
	    timeout);

	done = ccb->ccb_done;
	cookie = ccb->ccb_cookie;

	ccb->ccb_done = mpi_poll_done;
	ccb->ccb_cookie = &rv;

	mpi_start(sc, ccb);
	while (rv == 1) {
		reg = mpi_pop_reply(sc);
		if (reg == 0xffffffff) {
			if (timeout-- == 0) {
				printf("%s: timeout\n", DEVNAME(sc));
				goto timeout;
			}

			delay(1000);
			continue;
		}

		mpi_reply(sc, reg);
	}

	ccb->ccb_cookie = cookie;
	done(ccb);

timeout:
	return (rv);
}

void
mpi_poll_done(struct mpi_ccb *ccb)
{
	int				*rv = ccb->ccb_cookie;

	*rv = 0;
}

void
mpi_wait(struct mpi_softc *sc, struct mpi_ccb *ccb)
{
	struct mutex			cookie = MUTEX_INITIALIZER(IPL_BIO);
	void				(*done)(struct mpi_ccb *);

	done = ccb->ccb_done;
	ccb->ccb_done = mpi_wait_done;
	ccb->ccb_cookie = &cookie;

	/* XXX this will wait forever for the ccb to complete */

	mpi_start(sc, ccb);

	mtx_enter(&cookie);
	while (ccb->ccb_cookie != NULL)
		msleep(ccb, &cookie, PRIBIO, "mpiwait", 0);
	mtx_leave(&cookie);

	done(ccb);
}

void
mpi_wait_done(struct mpi_ccb *ccb)
{
	struct mutex			*cookie = ccb->ccb_cookie;

	mtx_enter(cookie);
	ccb->ccb_cookie = NULL;
	wakeup_one(ccb);
	mtx_leave(cookie);
}

void
mpi_scsi_cmd(struct scsi_xfer *xs)
{
	struct scsi_link		*link = xs->sc_link;
	struct mpi_softc		*sc = link->adapter_softc;
	struct mpi_ccb			*ccb;
	struct mpi_ccb_bundle		*mcb;
	struct mpi_msg_scsi_io		*io;

	DNPRINTF(MPI_D_CMD, "%s: mpi_scsi_cmd\n", DEVNAME(sc));

	KERNEL_UNLOCK();

	if (xs->cmdlen > MPI_CDB_LEN) {
		DNPRINTF(MPI_D_CMD, "%s: CBD too big %d\n",
		    DEVNAME(sc), xs->cmdlen);
		memset(&xs->sense, 0, sizeof(xs->sense));
		xs->sense.error_code = SSD_ERRCODE_VALID | SSD_ERRCODE_CURRENT;
		xs->sense.flags = SKEY_ILLEGAL_REQUEST;
		xs->sense.add_sense_code = 0x20;
		xs->error = XS_SENSE;
		goto done;
	}

	ccb = xs->io;

	DNPRINTF(MPI_D_CMD, "%s: ccb_id: %d xs->flags: 0x%x\n",
	    DEVNAME(sc), ccb->ccb_id, xs->flags);

	ccb->ccb_cookie = xs;
	ccb->ccb_done = mpi_scsi_cmd_done;

	mcb = ccb->ccb_cmd;
	io = &mcb->mcb_io;

	io->function = MPI_FUNCTION_SCSI_IO_REQUEST;
	/*
	 * bus is always 0
	 * io->bus = htole16(sc->sc_bus);
	 */
	io->target_id = link->target;

	io->cdb_length = xs->cmdlen;
	io->sense_buf_len = sizeof(xs->sense);
	io->msg_flags = MPI_SCSIIO_SENSE_BUF_ADDR_WIDTH_64;

	htobem16(&io->lun[0], link->lun);

	switch (xs->flags & (SCSI_DATA_IN | SCSI_DATA_OUT)) {
	case SCSI_DATA_IN:
		io->direction = MPI_SCSIIO_DIR_READ;
		break;
	case SCSI_DATA_OUT:
		io->direction = MPI_SCSIIO_DIR_WRITE;
		break;
	default:
		io->direction = MPI_SCSIIO_DIR_NONE;
		break;
	}

	if (sc->sc_porttype != MPI_PORTFACTS_PORTTYPE_SCSI &&
	    (link->quirks & SDEV_NOTAGS))
		io->tagging = MPI_SCSIIO_ATTR_UNTAGGED;
	else 
		io->tagging = MPI_SCSIIO_ATTR_SIMPLE_Q;

	memcpy(io->cdb, xs->cmd, xs->cmdlen);

	htolem32(&io->data_length, xs->datalen);

	htolem32(&io->sense_buf_low_addr, ccb->ccb_cmd_dva +
	    offsetof(struct mpi_ccb_bundle, mcb_sense));

	if (mpi_load_xs(ccb) != 0)
		goto stuffup;

	timeout_set(&xs->stimeout, mpi_timeout_xs, ccb);

	if (xs->flags & SCSI_POLL) {
		if (mpi_poll(sc, ccb, xs->timeout) != 0)
			goto stuffup;
	} else
		mpi_start(sc, ccb);

	KERNEL_LOCK();
	return;

stuffup:
	xs->error = XS_DRIVER_STUFFUP;
done:
	KERNEL_LOCK();
	scsi_done(xs);
}

void
mpi_scsi_cmd_done(struct mpi_ccb *ccb)
{
	struct mpi_softc		*sc = ccb->ccb_sc;
	struct scsi_xfer		*xs = ccb->ccb_cookie;
	struct mpi_ccb_bundle		*mcb = ccb->ccb_cmd;
	bus_dmamap_t			dmap = ccb->ccb_dmamap;
	struct mpi_msg_scsi_io_error	*sie;

	if (xs->datalen != 0) {
		bus_dmamap_sync(sc->sc_dmat, dmap, 0, dmap->dm_mapsize,
		    (xs->flags & SCSI_DATA_IN) ? BUS_DMASYNC_POSTREAD :
		    BUS_DMASYNC_POSTWRITE);

		bus_dmamap_unload(sc->sc_dmat, dmap);
	}

	/* timeout_del */
	xs->error = XS_NOERROR;
	xs->resid = 0;

	if (ccb->ccb_rcb == NULL) {
		/* no scsi error, we're ok so drop out early */
		xs->status = SCSI_OK;
		KERNEL_LOCK();
		scsi_done(xs);
		KERNEL_UNLOCK();
		return;
	}

	sie = ccb->ccb_rcb->rcb_reply;

	DNPRINTF(MPI_D_CMD, "%s: mpi_scsi_cmd_done xs cmd: 0x%02x len: %d "
	    "flags 0x%x\n", DEVNAME(sc), xs->cmd->opcode, xs->datalen,
	    xs->flags);
	DNPRINTF(MPI_D_CMD, "%s:  target_id: %d bus: %d msg_length: %d "
	    "function: 0x%02x\n", DEVNAME(sc), sie->target_id, sie->bus,
	    sie->msg_length, sie->function);
	DNPRINTF(MPI_D_CMD, "%s:  cdb_length: %d sense_buf_length: %d "
	    "msg_flags: 0x%02x\n", DEVNAME(sc), sie->cdb_length,
	    sie->sense_buf_len, sie->msg_flags);
	DNPRINTF(MPI_D_CMD, "%s:  msg_context: 0x%08x\n", DEVNAME(sc),
	    letoh32(sie->msg_context));
	DNPRINTF(MPI_D_CMD, "%s:  scsi_status: 0x%02x scsi_state: 0x%02x "
	    "ioc_status: 0x%04x\n", DEVNAME(sc), sie->scsi_status,
	    sie->scsi_state, letoh16(sie->ioc_status));
	DNPRINTF(MPI_D_CMD, "%s:  ioc_loginfo: 0x%08x\n", DEVNAME(sc),
	    letoh32(sie->ioc_loginfo));
	DNPRINTF(MPI_D_CMD, "%s:  transfer_count: %d\n", DEVNAME(sc),
	    letoh32(sie->transfer_count));
	DNPRINTF(MPI_D_CMD, "%s:  sense_count: %d\n", DEVNAME(sc),
	    letoh32(sie->sense_count));
	DNPRINTF(MPI_D_CMD, "%s:  response_info: 0x%08x\n", DEVNAME(sc),
	    letoh32(sie->response_info));
	DNPRINTF(MPI_D_CMD, "%s:  tag: 0x%04x\n", DEVNAME(sc),
	    letoh16(sie->tag));

	if (sie->scsi_state & MPI_SCSIIO_ERR_STATE_NO_SCSI_STATUS)
		xs->status = SCSI_TERMINATED;
	else
		xs->status = sie->scsi_status;
	xs->resid = 0;

	switch (lemtoh16(&sie->ioc_status)) {
	case MPI_IOCSTATUS_SCSI_DATA_UNDERRUN:
		xs->resid = xs->datalen - lemtoh32(&sie->transfer_count);
		/* FALLTHROUGH */
	case MPI_IOCSTATUS_SUCCESS:
	case MPI_IOCSTATUS_SCSI_RECOVERED_ERROR:
		switch (xs->status) {
		case SCSI_OK:
			xs->error = XS_NOERROR;
			break;

		case SCSI_CHECK:
			xs->error = XS_SENSE;
			break;

		case SCSI_BUSY:
		case SCSI_QUEUE_FULL:
			xs->error = XS_BUSY;
			break;

		default:
			xs->error = XS_DRIVER_STUFFUP;
			break;
		}
		break;

	case MPI_IOCSTATUS_BUSY:
	case MPI_IOCSTATUS_INSUFFICIENT_RESOURCES:
		xs->error = XS_BUSY;
		break;

	case MPI_IOCSTATUS_SCSI_INVALID_BUS:
	case MPI_IOCSTATUS_SCSI_INVALID_TARGETID:
	case MPI_IOCSTATUS_SCSI_DEVICE_NOT_THERE:
		xs->error = XS_SELTIMEOUT;
		break;

	case MPI_IOCSTATUS_SCSI_IOC_TERMINATED:
	case MPI_IOCSTATUS_SCSI_EXT_TERMINATED:
		xs->error = XS_RESET;
		break;

	default:
		xs->error = XS_DRIVER_STUFFUP;
		break;
	}

	if (sie->scsi_state & MPI_SCSIIO_ERR_STATE_AUTOSENSE_VALID)
		memcpy(&xs->sense, &mcb->mcb_sense, sizeof(xs->sense));

	DNPRINTF(MPI_D_CMD, "%s:  xs err: 0x%02x status: %d\n", DEVNAME(sc),
	    xs->error, xs->status);

	mpi_push_reply(sc, ccb->ccb_rcb);
	KERNEL_LOCK();
	scsi_done(xs);
	KERNEL_UNLOCK();
}

void
mpi_timeout_xs(void *arg)
{
	/* XXX */
}

int
mpi_load_xs(struct mpi_ccb *ccb)
{
	struct mpi_softc		*sc = ccb->ccb_sc;
	struct scsi_xfer		*xs = ccb->ccb_cookie;
	struct mpi_ccb_bundle		*mcb = ccb->ccb_cmd;
	struct mpi_msg_scsi_io		*io = &mcb->mcb_io;
	struct mpi_sge			*sge = NULL;
	struct mpi_sge			*nsge = &mcb->mcb_sgl[0];
	struct mpi_sge			*ce = NULL, *nce;
	bus_dmamap_t			dmap = ccb->ccb_dmamap;
	u_int32_t			addr, flags;
	int				i, error;

	if (xs->datalen == 0) {
		htolem32(&nsge->sg_hdr, MPI_SGE_FL_TYPE_SIMPLE |
		    MPI_SGE_FL_LAST | MPI_SGE_FL_EOB | MPI_SGE_FL_EOL);
		return (0);
	}

	error = bus_dmamap_load(sc->sc_dmat, dmap,
	    xs->data, xs->datalen, NULL, BUS_DMA_STREAMING |
	    ((xs->flags & SCSI_NOSLEEP) ? BUS_DMA_NOWAIT : BUS_DMA_WAITOK));
	if (error) {
		printf("%s: error %d loading dmamap\n", DEVNAME(sc), error);
		return (1);
	}

	flags = MPI_SGE_FL_TYPE_SIMPLE | MPI_SGE_FL_SIZE_64;
	if (xs->flags & SCSI_DATA_OUT)
		flags |= MPI_SGE_FL_DIR_OUT;

	if (dmap->dm_nsegs > sc->sc_first_sgl_len) {
		ce = &mcb->mcb_sgl[sc->sc_first_sgl_len - 1];
		io->chain_offset = (u_int32_t *)ce - (u_int32_t *)io;
	}

	for (i = 0; i < dmap->dm_nsegs; i++) {

		if (nsge == ce) {
			nsge++;
			sge->sg_hdr |= htole32(MPI_SGE_FL_LAST);

			if ((dmap->dm_nsegs - i) > sc->sc_chain_len) {
				nce = &nsge[sc->sc_chain_len - 1];
				addr = (u_int32_t *)nce - (u_int32_t *)nsge;
				addr = addr << 16 |
				    sizeof(struct mpi_sge) * sc->sc_chain_len;
			} else {
				nce = NULL;
				addr = sizeof(struct mpi_sge) *
				    (dmap->dm_nsegs - i);
			}

			ce->sg_hdr = htole32(MPI_SGE_FL_TYPE_CHAIN |
			    MPI_SGE_FL_SIZE_64 | addr);

			mpi_dvatosge(ce, ccb->ccb_cmd_dva +
			    ((u_int8_t *)nsge - (u_int8_t *)mcb));

			ce = nce;
		}

		DNPRINTF(MPI_D_DMA, "%s:  %d: %d 0x%016llx\n", DEVNAME(sc),
		    i, dmap->dm_segs[i].ds_len,
		    (u_int64_t)dmap->dm_segs[i].ds_addr);

		sge = nsge++;

		sge->sg_hdr = htole32(flags | dmap->dm_segs[i].ds_len);
		mpi_dvatosge(sge, dmap->dm_segs[i].ds_addr);
	}

	/* terminate list */
	sge->sg_hdr |= htole32(MPI_SGE_FL_LAST | MPI_SGE_FL_EOB |
	    MPI_SGE_FL_EOL);

	bus_dmamap_sync(sc->sc_dmat, dmap, 0, dmap->dm_mapsize,
	    (xs->flags & SCSI_DATA_IN) ? BUS_DMASYNC_PREREAD :
	    BUS_DMASYNC_PREWRITE);

	return (0);
}

void
mpi_minphys(struct buf *bp, struct scsi_link *sl)
{
	/* XXX */
	if (bp->b_bcount > MAXPHYS)
		bp->b_bcount = MAXPHYS;
	minphys(bp);
}

int
mpi_scsi_probe_virtual(struct scsi_link *link)
{
	struct mpi_softc		*sc = link->adapter_softc;
	struct mpi_cfg_hdr		hdr;
	struct mpi_cfg_raid_vol_pg0	*rp0;
	int				len;
	int				rv;

	if (!ISSET(sc->sc_flags, MPI_F_RAID))
		return (0);

	if (link->lun > 0)
		return (0);

	rv = mpi_req_cfg_header(sc, MPI_CONFIG_REQ_PAGE_TYPE_RAID_VOL,
	    0, link->target, MPI_PG_POLL, &hdr);
	if (rv != 0)
		return (0);

	len = hdr.page_length * 4;
	rp0 = malloc(len, M_TEMP, M_NOWAIT);
	if (rp0 == NULL)
		return (ENOMEM);

	rv = mpi_req_cfg_page(sc, link->target, MPI_PG_POLL, &hdr, 1, rp0, len);
	if (rv == 0)
		SET(link->flags, SDEV_VIRTUAL);

	free(rp0, M_TEMP, len);
	return (0);
}

int
mpi_scsi_probe(struct scsi_link *link)
{
	struct mpi_softc		*sc = link->adapter_softc;
	struct mpi_ecfg_hdr		ehdr;
	struct mpi_cfg_sas_dev_pg0	pg0;
	u_int32_t			address;
	int				rv;

	rv = mpi_scsi_probe_virtual(link);
	if (rv != 0)
		return (rv);

	if (ISSET(link->flags, SDEV_VIRTUAL))
		return (0);

	if (sc->sc_porttype != MPI_PORTFACTS_PORTTYPE_SAS)
		return (0);

	address = MPI_CFG_SAS_DEV_ADDR_BUS | link->target;

	if (mpi_ecfg_header(sc, MPI_CONFIG_REQ_EXTPAGE_TYPE_SAS_DEVICE, 0,
	    address, &ehdr) != 0)
		return (EIO);

	if (mpi_ecfg_page(sc, address, &ehdr, 1, &pg0, sizeof(pg0)) != 0)
		return (0);

	DNPRINTF(MPI_D_MISC, "%s: mpi_scsi_probe sas dev pg 0 for target %d:\n",
	    DEVNAME(sc), link->target);
	DNPRINTF(MPI_D_MISC, "%s:  slot: 0x%04x enc_handle: 0x%04x\n",
	    DEVNAME(sc), letoh16(pg0.slot), letoh16(pg0.enc_handle));
	DNPRINTF(MPI_D_MISC, "%s:  sas_addr: 0x%016llx\n", DEVNAME(sc),
	    letoh64(pg0.sas_addr));
	DNPRINTF(MPI_D_MISC, "%s:  parent_dev_handle: 0x%04x phy_num: 0x%02x "
	    "access_status: 0x%02x\n", DEVNAME(sc),
	    letoh16(pg0.parent_dev_handle), pg0.phy_num, pg0.access_status);
	DNPRINTF(MPI_D_MISC, "%s:  dev_handle: 0x%04x "
	    "bus: 0x%02x target: 0x%02x\n", DEVNAME(sc),
	    letoh16(pg0.dev_handle), pg0.bus, pg0.target);
	DNPRINTF(MPI_D_MISC, "%s:  device_info: 0x%08x\n", DEVNAME(sc),
	    letoh32(pg0.device_info));
	DNPRINTF(MPI_D_MISC, "%s:  flags: 0x%04x physical_port: 0x%02x\n",
	    DEVNAME(sc), letoh16(pg0.flags), pg0.physical_port);

	if (ISSET(lemtoh32(&pg0.device_info),
	    MPI_CFG_SAS_DEV_0_DEVINFO_ATAPI_DEVICE)) {
		DNPRINTF(MPI_D_MISC, "%s: target %d is an ATAPI device\n",
		    DEVNAME(sc), link->target);
		link->flags |= SDEV_ATAPI;
		link->quirks |= SDEV_ONLYBIG;
	}

	return (0);
}

u_int32_t
mpi_read(struct mpi_softc *sc, bus_size_t r)
{
	u_int32_t			rv;

	bus_space_barrier(sc->sc_iot, sc->sc_ioh, r, 4,
	    BUS_SPACE_BARRIER_READ);
	rv = bus_space_read_4(sc->sc_iot, sc->sc_ioh, r);

	DNPRINTF(MPI_D_RW, "%s: mpi_read %#x %#x\n", DEVNAME(sc), r, rv);

	return (rv);
}

void
mpi_write(struct mpi_softc *sc, bus_size_t r, u_int32_t v)
{
	DNPRINTF(MPI_D_RW, "%s: mpi_write %#x %#x\n", DEVNAME(sc), r, v);

	bus_space_write_4(sc->sc_iot, sc->sc_ioh, r, v);
	bus_space_barrier(sc->sc_iot, sc->sc_ioh, r, 4,
	    BUS_SPACE_BARRIER_WRITE);
}

int
mpi_wait_eq(struct mpi_softc *sc, bus_size_t r, u_int32_t mask,
    u_int32_t target)
{
	int				i;

	DNPRINTF(MPI_D_RW, "%s: mpi_wait_eq %#x %#x %#x\n", DEVNAME(sc), r,
	    mask, target);

	for (i = 0; i < 10000; i++) {
		if ((mpi_read(sc, r) & mask) == target)
			return (0);
		delay(1000);
	}

	return (1);
}

int
mpi_wait_ne(struct mpi_softc *sc, bus_size_t r, u_int32_t mask,
    u_int32_t target)
{
	int				i;

	DNPRINTF(MPI_D_RW, "%s: mpi_wait_ne %#x %#x %#x\n", DEVNAME(sc), r,
	    mask, target);

	for (i = 0; i < 10000; i++) {
		if ((mpi_read(sc, r) & mask) != target)
			return (0);
		delay(1000);
	}

	return (1);
}

int
mpi_init(struct mpi_softc *sc)
{
	u_int32_t			db;
	int				i;

	/* spin until the IOC leaves the RESET state */
	if (mpi_wait_ne(sc, MPI_DOORBELL, MPI_DOORBELL_STATE,
	    MPI_DOORBELL_STATE_RESET) != 0) {
		DNPRINTF(MPI_D_MISC, "%s: mpi_init timeout waiting to leave "
		    "reset state\n", DEVNAME(sc));
		return (1);
	}

	/* check current ownership */
	db = mpi_read_db(sc);
	if ((db & MPI_DOORBELL_WHOINIT) == MPI_DOORBELL_WHOINIT_PCIPEER) {
		DNPRINTF(MPI_D_MISC, "%s: mpi_init initialised by pci peer\n",
		    DEVNAME(sc));
		return (0);
	}

	for (i = 0; i < 5; i++) {
		switch (db & MPI_DOORBELL_STATE) {
		case MPI_DOORBELL_STATE_READY:
			DNPRINTF(MPI_D_MISC, "%s: mpi_init ioc is ready\n",
			    DEVNAME(sc));
			return (0);

		case MPI_DOORBELL_STATE_OPER:
		case MPI_DOORBELL_STATE_FAULT:
			DNPRINTF(MPI_D_MISC, "%s: mpi_init ioc is being "
			    "reset\n" , DEVNAME(sc));
			if (mpi_reset_soft(sc) != 0)
				mpi_reset_hard(sc);
			break;

		case MPI_DOORBELL_STATE_RESET:
			DNPRINTF(MPI_D_MISC, "%s: mpi_init waiting to come "
			    "out of reset\n", DEVNAME(sc));
			if (mpi_wait_ne(sc, MPI_DOORBELL, MPI_DOORBELL_STATE,
			    MPI_DOORBELL_STATE_RESET) != 0)
				return (1);
			break;
		}
		db = mpi_read_db(sc);
	}

	return (1);
}

int
mpi_reset_soft(struct mpi_softc *sc)
{
	DNPRINTF(MPI_D_MISC, "%s: mpi_reset_soft\n", DEVNAME(sc));

	if (mpi_read_db(sc) & MPI_DOORBELL_INUSE)
		return (1);

	mpi_write_db(sc,
	    MPI_DOORBELL_FUNCTION(MPI_FUNCTION_IOC_MESSAGE_UNIT_RESET));
	if (mpi_wait_eq(sc, MPI_INTR_STATUS,
	    MPI_INTR_STATUS_IOCDOORBELL, 0) != 0)
		return (1);

	if (mpi_wait_eq(sc, MPI_DOORBELL, MPI_DOORBELL_STATE,
	    MPI_DOORBELL_STATE_READY) != 0)
		return (1);

	return (0);
}

int
mpi_reset_hard(struct mpi_softc *sc)
{
	DNPRINTF(MPI_D_MISC, "%s: mpi_reset_hard\n", DEVNAME(sc));

	/* enable diagnostic register */
	mpi_write(sc, MPI_WRITESEQ, 0xff);
	mpi_write(sc, MPI_WRITESEQ, MPI_WRITESEQ_1);
	mpi_write(sc, MPI_WRITESEQ, MPI_WRITESEQ_2);
	mpi_write(sc, MPI_WRITESEQ, MPI_WRITESEQ_3);
	mpi_write(sc, MPI_WRITESEQ, MPI_WRITESEQ_4);
	mpi_write(sc, MPI_WRITESEQ, MPI_WRITESEQ_5);

	/* reset ioc */
	mpi_write(sc, MPI_HOSTDIAG, MPI_HOSTDIAG_RESET_ADAPTER);

	delay(10000);

	/* disable diagnostic register */
	mpi_write(sc, MPI_WRITESEQ, 0xff);

	/* restore pci bits? */

	/* firmware bits? */
	return (0);
}

int
mpi_handshake_send(struct mpi_softc *sc, void *buf, size_t dwords)
{
	u_int32_t				*query = buf;
	int					i;

	/* make sure the doorbell is not in use. */
	if (mpi_read_db(sc) & MPI_DOORBELL_INUSE)
		return (1);

	/* clear pending doorbell interrupts */
	if (mpi_read_intr(sc) & MPI_INTR_STATUS_DOORBELL)
		mpi_write_intr(sc, 0);

	/*
	 * first write the doorbell with the handshake function and the
	 * dword count.
	 */
	mpi_write_db(sc, MPI_DOORBELL_FUNCTION(MPI_FUNCTION_HANDSHAKE) |
	    MPI_DOORBELL_DWORDS(dwords));

	/*
	 * the doorbell used bit will be set because a doorbell function has
	 * started. Wait for the interrupt and then ack it.
	 */
	if (mpi_wait_db_int(sc) != 0)
		return (1);
	mpi_write_intr(sc, 0);

	/* poll for the acknowledgement. */
	if (mpi_wait_db_ack(sc) != 0)
		return (1);

	/* write the query through the doorbell. */
	for (i = 0; i < dwords; i++) {
		mpi_write_db(sc, htole32(query[i]));
		if (mpi_wait_db_ack(sc) != 0)
			return (1);
	}

	return (0);
}

int
mpi_handshake_recv_dword(struct mpi_softc *sc, u_int32_t *dword)
{
	u_int16_t				*words = (u_int16_t *)dword;
	int					i;

	for (i = 0; i < 2; i++) {
		if (mpi_wait_db_int(sc) != 0)
			return (1);
		words[i] = letoh16(mpi_read_db(sc) & MPI_DOORBELL_DATA_MASK);
		mpi_write_intr(sc, 0);
	}

	return (0);
}

int
mpi_handshake_recv(struct mpi_softc *sc, void *buf, size_t dwords)
{
	struct mpi_msg_reply			*reply = buf;
	u_int32_t				*dbuf = buf, dummy;
	int					i;

	/* get the first dword so we can read the length out of the header. */
	if (mpi_handshake_recv_dword(sc, &dbuf[0]) != 0)
		return (1);

	DNPRINTF(MPI_D_CMD, "%s: mpi_handshake_recv dwords: %d reply: %d\n",
	    DEVNAME(sc), dwords, reply->msg_length);

	/*
	 * the total length, in dwords, is in the message length field of the
	 * reply header.
	 */
	for (i = 1; i < MIN(dwords, reply->msg_length); i++) {
		if (mpi_handshake_recv_dword(sc, &dbuf[i]) != 0)
			return (1);
	}

	/* if there's extra stuff to come off the ioc, discard it */
	while (i++ < reply->msg_length) {
		if (mpi_handshake_recv_dword(sc, &dummy) != 0)
			return (1);
		DNPRINTF(MPI_D_CMD, "%s: mpi_handshake_recv dummy read: "
		    "0x%08x\n", DEVNAME(sc), dummy);
	}

	/* wait for the doorbell used bit to be reset and clear the intr */
	if (mpi_wait_db_int(sc) != 0)
		return (1);
	mpi_write_intr(sc, 0);

	return (0);
}

void
mpi_empty_done(struct mpi_ccb *ccb)
{
	/* nothing to do */
}

int
mpi_iocfacts(struct mpi_softc *sc)
{
	struct mpi_msg_iocfacts_request		ifq;
	struct mpi_msg_iocfacts_reply		ifp;

	DNPRINTF(MPI_D_MISC, "%s: mpi_iocfacts\n", DEVNAME(sc));

	memset(&ifq, 0, sizeof(ifq));
	memset(&ifp, 0, sizeof(ifp));

	ifq.function = MPI_FUNCTION_IOC_FACTS;
	ifq.chain_offset = 0;
	ifq.msg_flags = 0;
	ifq.msg_context = htole32(0xdeadbeef);

	if (mpi_handshake_send(sc, &ifq, dwordsof(ifq)) != 0) {
		DNPRINTF(MPI_D_MISC, "%s: mpi_iocfacts send failed\n",
		    DEVNAME(sc));
		return (1);
	}

	if (mpi_handshake_recv(sc, &ifp, dwordsof(ifp)) != 0) {
		DNPRINTF(MPI_D_MISC, "%s: mpi_iocfacts recv failed\n",
		    DEVNAME(sc));
		return (1);
	}

	DNPRINTF(MPI_D_MISC, "%s:  func: 0x%02x len: %d msgver: %d.%d\n",
	    DEVNAME(sc), ifp.function, ifp.msg_length,
	    ifp.msg_version_maj, ifp.msg_version_min);
	DNPRINTF(MPI_D_MISC, "%s:  msgflags: 0x%02x iocnumber: 0x%02x "
	    "hdrver: %d.%d\n", DEVNAME(sc), ifp.msg_flags,
	    ifp.ioc_number, ifp.header_version_maj,
	    ifp.header_version_min);
	DNPRINTF(MPI_D_MISC, "%s:  message context: 0x%08x\n", DEVNAME(sc),
	    letoh32(ifp.msg_context));
	DNPRINTF(MPI_D_MISC, "%s:  iocstatus: 0x%04x ioexcept: 0x%04x\n",
	    DEVNAME(sc), letoh16(ifp.ioc_status),
	    letoh16(ifp.ioc_exceptions));
	DNPRINTF(MPI_D_MISC, "%s:  iocloginfo: 0x%08x\n", DEVNAME(sc),
	    letoh32(ifp.ioc_loginfo));
	DNPRINTF(MPI_D_MISC, "%s:  flags: 0x%02x blocksize: %d whoinit: 0x%02x "
	    "maxchdepth: %d\n", DEVNAME(sc), ifp.flags,
	    ifp.block_size, ifp.whoinit, ifp.max_chain_depth);
	DNPRINTF(MPI_D_MISC, "%s:  reqfrsize: %d replyqdepth: %d\n",
	    DEVNAME(sc), letoh16(ifp.request_frame_size),
	    letoh16(ifp.reply_queue_depth));
	DNPRINTF(MPI_D_MISC, "%s:  productid: 0x%04x\n", DEVNAME(sc),
	    letoh16(ifp.product_id));
	DNPRINTF(MPI_D_MISC, "%s:  hostmfahiaddr: 0x%08x\n", DEVNAME(sc),
	    letoh32(ifp.current_host_mfa_hi_addr));
	DNPRINTF(MPI_D_MISC, "%s:  event_state: 0x%02x number_of_ports: %d "
	    "global_credits: %d\n",
	    DEVNAME(sc), ifp.event_state, ifp.number_of_ports,
	    letoh16(ifp.global_credits));
	DNPRINTF(MPI_D_MISC, "%s:  sensebufhiaddr: 0x%08x\n", DEVNAME(sc),
	    letoh32(ifp.current_sense_buffer_hi_addr));
	DNPRINTF(MPI_D_MISC, "%s:  maxbus: %d maxdev: %d replyfrsize: %d\n",
	    DEVNAME(sc), ifp.max_buses, ifp.max_devices,
	    letoh16(ifp.current_reply_frame_size));
	DNPRINTF(MPI_D_MISC, "%s:  fw_image_size: %d\n", DEVNAME(sc),
	    letoh32(ifp.fw_image_size));
	DNPRINTF(MPI_D_MISC, "%s:  ioc_capabilities: 0x%08x\n", DEVNAME(sc),
	    letoh32(ifp.ioc_capabilities));
	DNPRINTF(MPI_D_MISC, "%s:  fw_version: %d.%d fw_version_unit: 0x%02x "
	    "fw_version_dev: 0x%02x\n", DEVNAME(sc),
	    ifp.fw_version_maj, ifp.fw_version_min,
	    ifp.fw_version_unit, ifp.fw_version_dev);
	DNPRINTF(MPI_D_MISC, "%s:  hi_priority_queue_depth: 0x%04x\n",
	    DEVNAME(sc), letoh16(ifp.hi_priority_queue_depth));
	DNPRINTF(MPI_D_MISC, "%s:  host_page_buffer_sge: hdr: 0x%08x "
	    "addr 0x%08lx%08lx\n", DEVNAME(sc),
	    letoh32(ifp.host_page_buffer_sge.sg_hdr),
	    letoh32(ifp.host_page_buffer_sge.sg_addr_hi),
	    letoh32(ifp.host_page_buffer_sge.sg_addr_lo));

	sc->sc_fw_maj = ifp.fw_version_maj;
	sc->sc_fw_min = ifp.fw_version_min;
	sc->sc_fw_unit = ifp.fw_version_unit;
	sc->sc_fw_dev = ifp.fw_version_dev;

	sc->sc_maxcmds = lemtoh16(&ifp.global_credits);
	sc->sc_maxchdepth = ifp.max_chain_depth;
	sc->sc_ioc_number = ifp.ioc_number;
	if (sc->sc_flags & MPI_F_SPI)
		sc->sc_buswidth = 16;
	else
		sc->sc_buswidth =
		    (ifp.max_devices == 0) ? 256 : ifp.max_devices;
	if (ifp.flags & MPI_IOCFACTS_FLAGS_FW_DOWNLOAD_BOOT)
		sc->sc_fw_len = lemtoh32(&ifp.fw_image_size);

	sc->sc_repq = MIN(MPI_REPLYQ_DEPTH, lemtoh16(&ifp.reply_queue_depth));

	/*
	 * you can fit sg elements on the end of the io cmd if they fit in the
	 * request frame size.
	 */
	sc->sc_first_sgl_len = ((lemtoh16(&ifp.request_frame_size) * 4) -
	    sizeof(struct mpi_msg_scsi_io)) / sizeof(struct mpi_sge);
	DNPRINTF(MPI_D_MISC, "%s:   first sgl len: %d\n", DEVNAME(sc),
	    sc->sc_first_sgl_len);

	sc->sc_chain_len = (lemtoh16(&ifp.request_frame_size) * 4) /
	    sizeof(struct mpi_sge);
	DNPRINTF(MPI_D_MISC, "%s:   chain len: %d\n", DEVNAME(sc),
	    sc->sc_chain_len);

	/* the sgl tailing the io cmd loses an entry to the chain element. */
	sc->sc_max_sgl_len = MPI_MAX_SGL - 1;
	/* the sgl chains lose an entry for each chain element */
	sc->sc_max_sgl_len -= (MPI_MAX_SGL - sc->sc_first_sgl_len) /
	    sc->sc_chain_len;
	DNPRINTF(MPI_D_MISC, "%s:   max sgl len: %d\n", DEVNAME(sc),
	    sc->sc_max_sgl_len);

	/* XXX we're ignoring the max chain depth */

	return (0);
}

int
mpi_iocinit(struct mpi_softc *sc)
{
	struct mpi_msg_iocinit_request		iiq;
	struct mpi_msg_iocinit_reply		iip;
	u_int32_t				hi_addr;

	DNPRINTF(MPI_D_MISC, "%s: mpi_iocinit\n", DEVNAME(sc));

	memset(&iiq, 0, sizeof(iiq));
	memset(&iip, 0, sizeof(iip));

	iiq.function = MPI_FUNCTION_IOC_INIT;
	iiq.whoinit = MPI_WHOINIT_HOST_DRIVER;

	iiq.max_devices = (sc->sc_buswidth == 256) ? 0 : sc->sc_buswidth;
	iiq.max_buses = 1;

	iiq.msg_context = htole32(0xd00fd00f);

	iiq.reply_frame_size = htole16(MPI_REPLY_SIZE);

	hi_addr = (u_int32_t)(MPI_DMA_DVA(sc->sc_requests) >> 32);
	htolem32(&iiq.host_mfa_hi_addr, hi_addr);
	htolem32(&iiq.sense_buffer_hi_addr, hi_addr);

	iiq.msg_version_maj = 0x01;
	iiq.msg_version_min = 0x02;

	iiq.hdr_version_unit = 0x0d;
	iiq.hdr_version_dev = 0x00;

	if (mpi_handshake_send(sc, &iiq, dwordsof(iiq)) != 0) {
		DNPRINTF(MPI_D_MISC, "%s: mpi_iocinit send failed\n",
		    DEVNAME(sc));
		return (1);
	}

	if (mpi_handshake_recv(sc, &iip, dwordsof(iip)) != 0) {
		DNPRINTF(MPI_D_MISC, "%s: mpi_iocinit recv failed\n",
		    DEVNAME(sc));
		return (1);
	}

	DNPRINTF(MPI_D_MISC, "%s:  function: 0x%02x msg_length: %d "
	    "whoinit: 0x%02x\n", DEVNAME(sc), iip.function,
	    iip.msg_length, iip.whoinit);
	DNPRINTF(MPI_D_MISC, "%s:  msg_flags: 0x%02x max_buses: %d "
	    "max_devices: %d flags: 0x%02x\n", DEVNAME(sc), iip.msg_flags,
	    iip.max_buses, iip.max_devices, iip.flags);
	DNPRINTF(MPI_D_MISC, "%s:  msg_context: 0x%08x\n", DEVNAME(sc),
	    letoh32(iip.msg_context));
	DNPRINTF(MPI_D_MISC, "%s:  ioc_status: 0x%04x\n", DEVNAME(sc),
	    letoh16(iip.ioc_status));
	DNPRINTF(MPI_D_MISC, "%s:  ioc_loginfo: 0x%08x\n", DEVNAME(sc),
	    letoh32(iip.ioc_loginfo));

	return (0);
}

int
mpi_portfacts(struct mpi_softc *sc)
{
	struct mpi_ccb				*ccb;
	struct mpi_msg_portfacts_request	*pfq;
	volatile struct mpi_msg_portfacts_reply	*pfp;
	int					rv = 1;

	DNPRINTF(MPI_D_MISC, "%s: mpi_portfacts\n", DEVNAME(sc));

	ccb = scsi_io_get(&sc->sc_iopool, SCSI_NOSLEEP);
	if (ccb == NULL) {
		DNPRINTF(MPI_D_MISC, "%s: mpi_portfacts ccb_get\n",
		    DEVNAME(sc));
		return (rv);
	}

	ccb->ccb_done = mpi_empty_done;
	pfq = ccb->ccb_cmd;

	pfq->function = MPI_FUNCTION_PORT_FACTS;
	pfq->chain_offset = 0;
	pfq->msg_flags = 0;
	pfq->port_number = 0;

	if (mpi_poll(sc, ccb, 50000) != 0) {
		DNPRINTF(MPI_D_MISC, "%s: mpi_portfacts poll\n", DEVNAME(sc));
		goto err;
	}

	if (ccb->ccb_rcb == NULL) {
		DNPRINTF(MPI_D_MISC, "%s: empty portfacts reply\n",
		    DEVNAME(sc));
		goto err;
	}
	pfp = ccb->ccb_rcb->rcb_reply;

	DNPRINTF(MPI_D_MISC, "%s:  function: 0x%02x msg_length: %d\n",
	    DEVNAME(sc), pfp->function, pfp->msg_length);
	DNPRINTF(MPI_D_MISC, "%s:  msg_flags: 0x%02x port_number: %d\n",
	    DEVNAME(sc), pfp->msg_flags, pfp->port_number);
	DNPRINTF(MPI_D_MISC, "%s:  msg_context: 0x%08x\n", DEVNAME(sc),
	    letoh32(pfp->msg_context));
	DNPRINTF(MPI_D_MISC, "%s:  ioc_status: 0x%04x\n", DEVNAME(sc),
	    letoh16(pfp->ioc_status));
	DNPRINTF(MPI_D_MISC, "%s:  ioc_loginfo: 0x%08x\n", DEVNAME(sc),
	    letoh32(pfp->ioc_loginfo));
	DNPRINTF(MPI_D_MISC, "%s:  max_devices: %d port_type: 0x%02x\n",
	    DEVNAME(sc), letoh16(pfp->max_devices), pfp->port_type);
	DNPRINTF(MPI_D_MISC, "%s:  protocol_flags: 0x%04x port_scsi_id: %d\n",
	    DEVNAME(sc), letoh16(pfp->protocol_flags),
	    letoh16(pfp->port_scsi_id));
	DNPRINTF(MPI_D_MISC, "%s:  max_persistent_ids: %d "
	    "max_posted_cmd_buffers: %d\n", DEVNAME(sc),
	    letoh16(pfp->max_persistent_ids),
	    letoh16(pfp->max_posted_cmd_buffers));
	DNPRINTF(MPI_D_MISC, "%s:  max_lan_buckets: %d\n", DEVNAME(sc),
	    letoh16(pfp->max_lan_buckets));

	sc->sc_porttype = pfp->port_type;
	if (sc->sc_target == -1)
		sc->sc_target = lemtoh16(&pfp->port_scsi_id);

	mpi_push_reply(sc, ccb->ccb_rcb);
	rv = 0;
err:
	scsi_io_put(&sc->sc_iopool, ccb);

	return (rv);
}

int
mpi_cfg_coalescing(struct mpi_softc *sc)
{
	struct mpi_cfg_hdr		hdr;
	struct mpi_cfg_ioc_pg1		pg;
	u_int32_t			flags;

	if (mpi_cfg_header(sc, MPI_CONFIG_REQ_PAGE_TYPE_IOC, 1, 0, &hdr) != 0) {
		DNPRINTF(MPI_D_MISC, "%s: unable to fetch IOC page 1 header\n",
		    DEVNAME(sc));
		return (1);
	}

	if (mpi_cfg_page(sc, 0, &hdr, 1, &pg, sizeof(pg)) != 0) {
		DNPRINTF(MPI_D_MISC, "%s: unable to fetch IOC page 1\n",
		    DEVNAME(sc));
		return (1);
	}

	DNPRINTF(MPI_D_MISC, "%s: IOC page 1\n", DEVNAME(sc));
	DNPRINTF(MPI_D_MISC, "%s:  flags: 0x%08x\n", DEVNAME(sc),
	    letoh32(pg.flags));
	DNPRINTF(MPI_D_MISC, "%s:  coalescing_timeout: %d\n", DEVNAME(sc),
	    letoh32(pg.coalescing_timeout));
	DNPRINTF(MPI_D_MISC, "%s:  coalescing_depth: %d pci_slot_num: %d\n",
	    DEVNAME(sc), pg.coalescing_depth, pg.pci_slot_num);

	flags = lemtoh32(&pg.flags);
	if (!ISSET(flags, MPI_CFG_IOC_1_REPLY_COALESCING))
		return (0);

	CLR(pg.flags, htole32(MPI_CFG_IOC_1_REPLY_COALESCING));
	if (mpi_cfg_page(sc, 0, &hdr, 0, &pg, sizeof(pg)) != 0) {
		DNPRINTF(MPI_D_MISC, "%s: unable to clear coalescing\n",
		    DEVNAME(sc));
		return (1);
	}

	return (0);
}

int
mpi_eventnotify(struct mpi_softc *sc)
{
	struct mpi_ccb				*ccb;
	struct mpi_msg_event_request		*enq;

	ccb = scsi_io_get(&sc->sc_iopool, SCSI_NOSLEEP);
	if (ccb == NULL) {
		DNPRINTF(MPI_D_MISC, "%s: mpi_eventnotify ccb_get\n",
		    DEVNAME(sc));
		return (1);
	}

	sc->sc_evt_ccb = ccb;
	SIMPLEQ_INIT(&sc->sc_evt_ack_queue);
	mtx_init(&sc->sc_evt_ack_mtx, IPL_BIO);
	scsi_ioh_set(&sc->sc_evt_ack_handler, &sc->sc_iopool,
	    mpi_eventack, sc);

	ccb->ccb_done = mpi_eventnotify_done;
	enq = ccb->ccb_cmd;

	enq->function = MPI_FUNCTION_EVENT_NOTIFICATION;
	enq->chain_offset = 0;
	enq->event_switch = MPI_EVENT_SWITCH_ON;

	mpi_start(sc, ccb);
	return (0);
}

void
mpi_eventnotify_done(struct mpi_ccb *ccb)
{
	struct mpi_softc			*sc = ccb->ccb_sc;
	struct mpi_rcb				*rcb = ccb->ccb_rcb;
	struct mpi_msg_event_reply		*enp = rcb->rcb_reply;

	DNPRINTF(MPI_D_EVT, "%s: mpi_eventnotify_done\n", DEVNAME(sc));

	DNPRINTF(MPI_D_EVT, "%s:  function: 0x%02x msg_length: %d "
	    "data_length: %d\n", DEVNAME(sc), enp->function, enp->msg_length,
	    letoh16(enp->data_length));
	DNPRINTF(MPI_D_EVT, "%s:  ack_required: %d msg_flags 0x%02x\n",
	    DEVNAME(sc), enp->ack_required, enp->msg_flags);
	DNPRINTF(MPI_D_EVT, "%s:  msg_context: 0x%08x\n", DEVNAME(sc),
	    letoh32(enp->msg_context));
	DNPRINTF(MPI_D_EVT, "%s:  ioc_status: 0x%04x\n", DEVNAME(sc),
	    letoh16(enp->ioc_status));
	DNPRINTF(MPI_D_EVT, "%s:  ioc_loginfo: 0x%08x\n", DEVNAME(sc),
	    letoh32(enp->ioc_loginfo));
	DNPRINTF(MPI_D_EVT, "%s:  event: 0x%08x\n", DEVNAME(sc),
	    letoh32(enp->event));
	DNPRINTF(MPI_D_EVT, "%s:  event_context: 0x%08x\n", DEVNAME(sc),
	    letoh32(enp->event_context));

	switch (lemtoh32(&enp->event)) {
	/* ignore these */
	case MPI_EVENT_EVENT_CHANGE:
	case MPI_EVENT_SAS_PHY_LINK_STATUS:
		break;

	case MPI_EVENT_SAS_DEVICE_STATUS_CHANGE:
		if (sc->sc_scsibus == NULL)
			break;

		if (mpi_evt_sas(sc, rcb) != 0) {
			/* reply is freed later on */
			return;
		}
		break;

	case MPI_EVENT_RESCAN:
		if (sc->sc_scsibus != NULL &&
		    sc->sc_porttype == MPI_PORTFACTS_PORTTYPE_FC)
			task_add(systq, &sc->sc_evt_rescan);
		break;

	default:
		DNPRINTF(MPI_D_EVT, "%s:  unhandled event 0x%02x\n",
		    DEVNAME(sc), lemtoh32(&enp->event));
		break;
	}

	mpi_eventnotify_free(sc, rcb);
}

void
mpi_eventnotify_free(struct mpi_softc *sc, struct mpi_rcb *rcb)
{
	struct mpi_msg_event_reply		*enp = rcb->rcb_reply;

	if (enp->ack_required) {
		mtx_enter(&sc->sc_evt_ack_mtx);
		SIMPLEQ_INSERT_TAIL(&sc->sc_evt_ack_queue, rcb, rcb_link);
		mtx_leave(&sc->sc_evt_ack_mtx);
		scsi_ioh_add(&sc->sc_evt_ack_handler);
	} else
		mpi_push_reply(sc, rcb);
}

int
mpi_evt_sas(struct mpi_softc *sc, struct mpi_rcb *rcb)
{
	struct mpi_evt_sas_change		*ch;
	u_int8_t				*data;

	data = rcb->rcb_reply;
	data += sizeof(struct mpi_msg_event_reply);
	ch = (struct mpi_evt_sas_change *)data;

	if (ch->bus != 0)
		return (0);

	switch (ch->reason) {
	case MPI_EVT_SASCH_REASON_ADDED:
	case MPI_EVT_SASCH_REASON_NO_PERSIST_ADDED:
		KERNEL_LOCK();
		if (scsi_req_probe(sc->sc_scsibus, ch->target, -1) != 0) {
			printf("%s: unable to request attach of %d\n",
			    DEVNAME(sc), ch->target);
		}
		KERNEL_UNLOCK();
		break;

	case MPI_EVT_SASCH_REASON_NOT_RESPONDING:
		KERNEL_LOCK();
		scsi_activate(sc->sc_scsibus, ch->target, -1, DVACT_DEACTIVATE);
		KERNEL_UNLOCK();

		mtx_enter(&sc->sc_evt_scan_mtx);
		SIMPLEQ_INSERT_TAIL(&sc->sc_evt_scan_queue, rcb, rcb_link);
		mtx_leave(&sc->sc_evt_scan_mtx);
		scsi_ioh_add(&sc->sc_evt_scan_handler);

		/* we'll handle event ack later on */
		return (1);

	case MPI_EVT_SASCH_REASON_SMART_DATA:
	case MPI_EVT_SASCH_REASON_UNSUPPORTED:
	case MPI_EVT_SASCH_REASON_INTERNAL_RESET:
		break;
	default:
		printf("%s: unknown reason for SAS device status change: "
		    "0x%02x\n", DEVNAME(sc), ch->reason);
		break;
	}

	return (0);
}

void
mpi_evt_sas_detach(void *cookie, void *io)
{
	struct mpi_softc			*sc = cookie;
	struct mpi_ccb				*ccb = io;
	struct mpi_rcb				*rcb, *next;
	struct mpi_msg_event_reply		*enp;
	struct mpi_evt_sas_change		*ch;
	struct mpi_msg_scsi_task_request	*str;

	DNPRINTF(MPI_D_EVT, "%s: event sas detach handler\n", DEVNAME(sc));

	mtx_enter(&sc->sc_evt_scan_mtx);
	rcb = SIMPLEQ_FIRST(&sc->sc_evt_scan_queue);
	if (rcb != NULL) {
		next = SIMPLEQ_NEXT(rcb, rcb_link);
		SIMPLEQ_REMOVE_HEAD(&sc->sc_evt_scan_queue, rcb_link);
	}
	mtx_leave(&sc->sc_evt_scan_mtx);

	if (rcb == NULL) {
		scsi_io_put(&sc->sc_iopool, ccb);
		return;
	}

	enp = rcb->rcb_reply;
	ch = (struct mpi_evt_sas_change *)(enp + 1);

	ccb->ccb_done = mpi_evt_sas_detach_done;
	str = ccb->ccb_cmd;

	str->target_id = ch->target;
	str->bus = 0;
	str->function = MPI_FUNCTION_SCSI_TASK_MGMT;

	str->task_type = MPI_MSG_SCSI_TASK_TYPE_TARGET_RESET;

	mpi_eventnotify_free(sc, rcb);

	mpi_start(sc, ccb);

	if (next != NULL)
		scsi_ioh_add(&sc->sc_evt_scan_handler);
}

void
mpi_evt_sas_detach_done(struct mpi_ccb *ccb)
{
	struct mpi_softc			*sc = ccb->ccb_sc;
	struct mpi_msg_scsi_task_reply		*r = ccb->ccb_rcb->rcb_reply;

	KERNEL_LOCK();
	if (scsi_req_detach(sc->sc_scsibus, r->target_id, -1,
	    DETACH_FORCE) != 0) {
		printf("%s: unable to request detach of %d\n",
		    DEVNAME(sc), r->target_id);
	}
	KERNEL_UNLOCK();

	mpi_push_reply(sc, ccb->ccb_rcb);
	scsi_io_put(&sc->sc_iopool, ccb);
}

void
mpi_fc_rescan(void *xsc)
{
	struct mpi_softc			*sc = xsc;
	struct mpi_cfg_hdr			hdr;
	struct mpi_cfg_fc_device_pg0		pg;
	struct scsi_link			*link;
	u_int8_t				devmap[256 / NBBY];
	u_int32_t				id = 0xffffff;
	int					i;

	memset(devmap, 0, sizeof(devmap));

	do {
		if (mpi_req_cfg_header(sc, MPI_CONFIG_REQ_PAGE_TYPE_FC_DEV, 0,
		    id, 0, &hdr) != 0) {
			printf("%s: header get for rescan of 0x%08x failed\n",
			    DEVNAME(sc), id);
			return;
		}

		memset(&pg, 0, sizeof(pg));
		if (mpi_req_cfg_page(sc, id, 0, &hdr, 1, &pg, sizeof(pg)) != 0)
			break;

		if (ISSET(pg.flags, MPI_CFG_FC_DEV_0_FLAGS_BUSADDR_VALID) &&
		    pg.current_bus == 0)
			setbit(devmap, pg.current_target_id);

		id = lemtoh32(&pg.port_id);
	} while (id <= 0xff0000);

	for (i = 0; i < sc->sc_buswidth; i++) {
		link = scsi_get_link(sc->sc_scsibus, i, 0);

		if (isset(devmap, i)) {
			if (link == NULL)
				scsi_probe_target(sc->sc_scsibus, i);
		} else {
			if (link != NULL) {
				scsi_activate(sc->sc_scsibus, i, -1,
				    DVACT_DEACTIVATE);
				scsi_detach_target(sc->sc_scsibus, i,
				    DETACH_FORCE);
			}
		}
	}
}

void
mpi_eventack(void *cookie, void *io)
{
	struct mpi_softc			*sc = cookie;
	struct mpi_ccb				*ccb = io;
	struct mpi_rcb				*rcb, *next;
	struct mpi_msg_event_reply		*enp;
	struct mpi_msg_eventack_request		*eaq;

	DNPRINTF(MPI_D_EVT, "%s: event ack\n", DEVNAME(sc));

	mtx_enter(&sc->sc_evt_ack_mtx);
	rcb = SIMPLEQ_FIRST(&sc->sc_evt_ack_queue);
	if (rcb != NULL) {
		next = SIMPLEQ_NEXT(rcb, rcb_link);
		SIMPLEQ_REMOVE_HEAD(&sc->sc_evt_ack_queue, rcb_link);
	}
	mtx_leave(&sc->sc_evt_ack_mtx);

	if (rcb == NULL) {
		scsi_io_put(&sc->sc_iopool, ccb);
		return;
	}

	enp = rcb->rcb_reply;

	ccb->ccb_done = mpi_eventack_done;
	eaq = ccb->ccb_cmd;

	eaq->function = MPI_FUNCTION_EVENT_ACK;

	eaq->event = enp->event;
	eaq->event_context = enp->event_context;

	mpi_push_reply(sc, rcb);
	mpi_start(sc, ccb);

	if (next != NULL)
		scsi_ioh_add(&sc->sc_evt_ack_handler);
}

void
mpi_eventack_done(struct mpi_ccb *ccb)
{
	struct mpi_softc			*sc = ccb->ccb_sc;

	DNPRINTF(MPI_D_EVT, "%s: event ack done\n", DEVNAME(sc));

	mpi_push_reply(sc, ccb->ccb_rcb);
	scsi_io_put(&sc->sc_iopool, ccb);
}

int
mpi_portenable(struct mpi_softc *sc)
{
	struct mpi_ccb				*ccb;
	struct mpi_msg_portenable_request	*peq;
	int					rv = 0;

	DNPRINTF(MPI_D_MISC, "%s: mpi_portenable\n", DEVNAME(sc));

	ccb = scsi_io_get(&sc->sc_iopool, SCSI_NOSLEEP);
	if (ccb == NULL) {
		DNPRINTF(MPI_D_MISC, "%s: mpi_portenable ccb_get\n",
		    DEVNAME(sc));
		return (1);
	}

	ccb->ccb_done = mpi_empty_done;
	peq = ccb->ccb_cmd;

	peq->function = MPI_FUNCTION_PORT_ENABLE;
	peq->port_number = 0;

	if (mpi_poll(sc, ccb, 50000) != 0) {
		DNPRINTF(MPI_D_MISC, "%s: mpi_portenable poll\n", DEVNAME(sc));
		return (1);
	}

	if (ccb->ccb_rcb == NULL) {
		DNPRINTF(MPI_D_MISC, "%s: empty portenable reply\n",
		    DEVNAME(sc));
		rv = 1;
	} else
		mpi_push_reply(sc, ccb->ccb_rcb);

	scsi_io_put(&sc->sc_iopool, ccb);

	return (rv);
}

int
mpi_fwupload(struct mpi_softc *sc)
{
	struct mpi_ccb				*ccb;
	struct {
		struct mpi_msg_fwupload_request		req;
		struct mpi_sge				sge;
	} __packed				*bundle;
	struct mpi_msg_fwupload_reply		*upp;
	int					rv = 0;

	if (sc->sc_fw_len == 0)
		return (0);

	DNPRINTF(MPI_D_MISC, "%s: mpi_fwupload\n", DEVNAME(sc));

	sc->sc_fw = mpi_dmamem_alloc(sc, sc->sc_fw_len);
	if (sc->sc_fw == NULL) {
		DNPRINTF(MPI_D_MISC, "%s: mpi_fwupload unable to allocate %d\n",
		    DEVNAME(sc), sc->sc_fw_len);
		return (1);
	}

	ccb = scsi_io_get(&sc->sc_iopool, SCSI_NOSLEEP);
	if (ccb == NULL) {
		DNPRINTF(MPI_D_MISC, "%s: mpi_fwupload ccb_get\n",
		    DEVNAME(sc));
		goto err;
	}

	ccb->ccb_done = mpi_empty_done;
	bundle = ccb->ccb_cmd;

	bundle->req.function = MPI_FUNCTION_FW_UPLOAD;

	bundle->req.image_type = MPI_FWUPLOAD_IMAGETYPE_IOC_FW;

	bundle->req.tce.details_length = 12;
	htolem32(&bundle->req.tce.image_size, sc->sc_fw_len);

	htolem32(&bundle->sge.sg_hdr, MPI_SGE_FL_TYPE_SIMPLE |
	    MPI_SGE_FL_SIZE_64 | MPI_SGE_FL_LAST | MPI_SGE_FL_EOB |
	    MPI_SGE_FL_EOL | (u_int32_t)sc->sc_fw_len);
	mpi_dvatosge(&bundle->sge, MPI_DMA_DVA(sc->sc_fw));

	if (mpi_poll(sc, ccb, 50000) != 0) {
		DNPRINTF(MPI_D_MISC, "%s: mpi_cfg_header poll\n", DEVNAME(sc));
		goto err;
	}

	if (ccb->ccb_rcb == NULL)
		panic("%s: unable to do fw upload", DEVNAME(sc));
	upp = ccb->ccb_rcb->rcb_reply;

	if (lemtoh16(&upp->ioc_status) != MPI_IOCSTATUS_SUCCESS)
		rv = 1;

	mpi_push_reply(sc, ccb->ccb_rcb);
	scsi_io_put(&sc->sc_iopool, ccb);

	return (rv);

err:
	mpi_dmamem_free(sc, sc->sc_fw);
	return (1);
}

int
mpi_manufacturing(struct mpi_softc *sc)
{
	char board_name[33];
	struct mpi_cfg_hdr hdr;
	struct mpi_cfg_manufacturing_pg0 *pg;
	size_t pagelen;
	int rv = 1;

	if (mpi_cfg_header(sc, MPI_CONFIG_REQ_PAGE_TYPE_MANUFACTURING,
	    0, 0, &hdr) != 0)
		return (1);

	pagelen = hdr.page_length * 4; /* dwords to bytes */
	if (pagelen < sizeof(*pg))
		return (1);

	pg = malloc(pagelen, M_TEMP, M_WAITOK|M_CANFAIL);
	if (pg == NULL)
		return (1);

	if (mpi_cfg_page(sc, 0, &hdr, 1, pg, pagelen) != 0)
		goto out;

	scsi_strvis(board_name, pg->board_name, sizeof(pg->board_name));

	printf("%s: %s, firmware %d.%d.%d.%d\n", DEVNAME(sc), board_name,
	    sc->sc_fw_maj, sc->sc_fw_min, sc->sc_fw_unit, sc->sc_fw_dev);

	rv = 0;

out:
	free(pg, M_TEMP, pagelen);
	return (rv);
}

void
mpi_get_raid(struct mpi_softc *sc)
{
	struct mpi_cfg_hdr		hdr;
	struct mpi_cfg_ioc_pg2		*vol_page;
	size_t				pagelen;
	u_int32_t			capabilities;

	DNPRINTF(MPI_D_RAID, "%s: mpi_get_raid\n", DEVNAME(sc));

	if (mpi_cfg_header(sc, MPI_CONFIG_REQ_PAGE_TYPE_IOC, 2, 0, &hdr) != 0) {
		DNPRINTF(MPI_D_RAID, "%s: mpi_get_raid unable to fetch header"
		    "for IOC page 2\n", DEVNAME(sc));
		return;
	}

	pagelen = hdr.page_length * 4; /* dwords to bytes */
	vol_page = malloc(pagelen, M_TEMP, M_WAITOK|M_CANFAIL);
	if (vol_page == NULL) {
		DNPRINTF(MPI_D_RAID, "%s: mpi_get_raid unable to allocate "
		    "space for ioc config page 2\n", DEVNAME(sc));
		return;
	}

	if (mpi_cfg_page(sc, 0, &hdr, 1, vol_page, pagelen) != 0) {
		DNPRINTF(MPI_D_RAID, "%s: mpi_get_raid unable to fetch IOC "
		    "page 2\n", DEVNAME(sc));
		goto out;
	}

	capabilities = lemtoh32(&vol_page->capabilities);

	DNPRINTF(MPI_D_RAID, "%s:  capabilities: 0x08%x\n", DEVNAME(sc),
	    letoh32(vol_page->capabilities));
	DNPRINTF(MPI_D_RAID, "%s:  active_vols: %d max_vols: %d "
	    "active_physdisks: %d max_physdisks: %d\n", DEVNAME(sc),
	    vol_page->active_vols, vol_page->max_vols,
	    vol_page->active_physdisks, vol_page->max_physdisks);

	/* don't walk list if there are no RAID capability */
	if (capabilities == 0xdeadbeef) {
		printf("%s: deadbeef in raid configuration\n", DEVNAME(sc));
		goto out;
	}

	if (ISSET(capabilities, MPI_CFG_IOC_2_CAPABILITIES_RAID))
		sc->sc_flags |= MPI_F_RAID;

out:
	free(vol_page, M_TEMP, pagelen);
}

int
mpi_req_cfg_header(struct mpi_softc *sc, u_int8_t type, u_int8_t number,
    u_int32_t address, int flags, void *p)
{
	struct mpi_ccb				*ccb;
	struct mpi_msg_config_request		*cq;
	struct mpi_msg_config_reply		*cp;
	struct mpi_cfg_hdr			*hdr = p;
	struct mpi_ecfg_hdr			*ehdr = p;
	int					etype = 0;
	int					rv = 0;

	DNPRINTF(MPI_D_MISC, "%s: mpi_req_cfg_header type: %#x number: %x "
	    "address: 0x%08x flags: 0x%b\n", DEVNAME(sc), type, number,
	    address, flags, MPI_PG_FMT);

	ccb = scsi_io_get(&sc->sc_iopool,
	    ISSET(flags, MPI_PG_POLL) ? SCSI_NOSLEEP : 0);
	if (ccb == NULL) {
		DNPRINTF(MPI_D_MISC, "%s: mpi_cfg_header ccb_get\n",
		    DEVNAME(sc));
		return (1);
	}

	if (ISSET(flags, MPI_PG_EXTENDED)) {
		etype = type;
		type = MPI_CONFIG_REQ_PAGE_TYPE_EXTENDED;
	}

	cq = ccb->ccb_cmd;

	cq->function = MPI_FUNCTION_CONFIG;

	cq->action = MPI_CONFIG_REQ_ACTION_PAGE_HEADER;

	cq->config_header.page_number = number;
	cq->config_header.page_type = type;
	cq->ext_page_type = etype;
	htolem32(&cq->page_address, address);
	htolem32(&cq->page_buffer.sg_hdr, MPI_SGE_FL_TYPE_SIMPLE |
	    MPI_SGE_FL_LAST | MPI_SGE_FL_EOB | MPI_SGE_FL_EOL);

	ccb->ccb_done = mpi_empty_done;
	if (ISSET(flags, MPI_PG_POLL)) {
		if (mpi_poll(sc, ccb, 50000) != 0) {
			DNPRINTF(MPI_D_MISC, "%s: mpi_cfg_header poll\n",
			    DEVNAME(sc));
			return (1);
		}
	} else
		mpi_wait(sc, ccb);

	if (ccb->ccb_rcb == NULL)
		panic("%s: unable to fetch config header", DEVNAME(sc));
	cp = ccb->ccb_rcb->rcb_reply;

	DNPRINTF(MPI_D_MISC, "%s:  action: 0x%02x msg_length: %d function: "
	    "0x%02x\n", DEVNAME(sc), cp->action, cp->msg_length, cp->function);
	DNPRINTF(MPI_D_MISC, "%s:  ext_page_length: %d ext_page_type: 0x%02x "
	    "msg_flags: 0x%02x\n", DEVNAME(sc),
	    letoh16(cp->ext_page_length), cp->ext_page_type,
	    cp->msg_flags);
	DNPRINTF(MPI_D_MISC, "%s:  msg_context: 0x%08x\n", DEVNAME(sc),
	    letoh32(cp->msg_context));
	DNPRINTF(MPI_D_MISC, "%s:  ioc_status: 0x%04x\n", DEVNAME(sc),
	    letoh16(cp->ioc_status));
	DNPRINTF(MPI_D_MISC, "%s:  ioc_loginfo: 0x%08x\n", DEVNAME(sc),
	    letoh32(cp->ioc_loginfo));
	DNPRINTF(MPI_D_MISC, "%s:  page_version: 0x%02x page_length: %d "
	    "page_number: 0x%02x page_type: 0x%02x\n", DEVNAME(sc),
	    cp->config_header.page_version,
	    cp->config_header.page_length,
	    cp->config_header.page_number,
	    cp->config_header.page_type);

	if (lemtoh16(&cp->ioc_status) != MPI_IOCSTATUS_SUCCESS)
		rv = 1;
	else if (ISSET(flags, MPI_PG_EXTENDED)) {
		memset(ehdr, 0, sizeof(*ehdr));
		ehdr->page_version = cp->config_header.page_version;
		ehdr->page_number = cp->config_header.page_number;
		ehdr->page_type = cp->config_header.page_type;
		ehdr->ext_page_length = cp->ext_page_length;
		ehdr->ext_page_type = cp->ext_page_type;
	} else
		*hdr = cp->config_header;

	mpi_push_reply(sc, ccb->ccb_rcb);
	scsi_io_put(&sc->sc_iopool, ccb);

	return (rv);
}

int
mpi_req_cfg_page(struct mpi_softc *sc, u_int32_t address, int flags,
    void *p, int read, void *page, size_t len)
{
	struct mpi_ccb				*ccb;
	struct mpi_msg_config_request		*cq;
	struct mpi_msg_config_reply		*cp;
	struct mpi_cfg_hdr			*hdr = p;
	struct mpi_ecfg_hdr			*ehdr = p;
	char					*kva;
	int					page_length;
	int					rv = 0;

	DNPRINTF(MPI_D_MISC, "%s: mpi_cfg_page address: %d read: %d type: %x\n",
	    DEVNAME(sc), address, read, hdr->page_type);

	page_length = ISSET(flags, MPI_PG_EXTENDED) ?
	    lemtoh16(&ehdr->ext_page_length) : hdr->page_length;

	if (len > MPI_REQUEST_SIZE - sizeof(struct mpi_msg_config_request) ||
	    len < page_length * 4)
		return (1);

	ccb = scsi_io_get(&sc->sc_iopool,
	    ISSET(flags, MPI_PG_POLL) ? SCSI_NOSLEEP : 0);
	if (ccb == NULL) {
		DNPRINTF(MPI_D_MISC, "%s: mpi_cfg_page ccb_get\n", DEVNAME(sc));
		return (1);
	}

	cq = ccb->ccb_cmd;

	cq->function = MPI_FUNCTION_CONFIG;

	cq->action = (read ? MPI_CONFIG_REQ_ACTION_PAGE_READ_CURRENT :
	    MPI_CONFIG_REQ_ACTION_PAGE_WRITE_CURRENT);

	if (ISSET(flags, MPI_PG_EXTENDED)) {
		cq->config_header.page_version = ehdr->page_version;
		cq->config_header.page_number = ehdr->page_number;
		cq->config_header.page_type = ehdr->page_type;
		cq->ext_page_len = ehdr->ext_page_length;
		cq->ext_page_type = ehdr->ext_page_type;
	} else
		cq->config_header = *hdr;
	cq->config_header.page_type &= MPI_CONFIG_REQ_PAGE_TYPE_MASK;
	htolem32(&cq->page_address, address);
	htolem32(&cq->page_buffer.sg_hdr, MPI_SGE_FL_TYPE_SIMPLE |
	    MPI_SGE_FL_LAST | MPI_SGE_FL_EOB | MPI_SGE_FL_EOL |
	    (page_length * 4) |
	    (read ? MPI_SGE_FL_DIR_IN : MPI_SGE_FL_DIR_OUT));

	/* bounce the page via the request space to avoid more bus_dma games */
	mpi_dvatosge(&cq->page_buffer, ccb->ccb_cmd_dva +
	    sizeof(struct mpi_msg_config_request));

	kva = ccb->ccb_cmd;
	kva += sizeof(struct mpi_msg_config_request);
	if (!read)
		memcpy(kva, page, len);

	ccb->ccb_done = mpi_empty_done;
	if (ISSET(flags, MPI_PG_POLL)) {
		if (mpi_poll(sc, ccb, 50000) != 0) {
			DNPRINTF(MPI_D_MISC, "%s: mpi_cfg_header poll\n",
			    DEVNAME(sc));
			return (1);
		}
	} else
		mpi_wait(sc, ccb);

	if (ccb->ccb_rcb == NULL) {
		scsi_io_put(&sc->sc_iopool, ccb);
		return (1);
	}
	cp = ccb->ccb_rcb->rcb_reply;

	DNPRINTF(MPI_D_MISC, "%s:  action: 0x%02x msg_length: %d function: "
	    "0x%02x\n", DEVNAME(sc), cp->action, cp->msg_length, cp->function);
	DNPRINTF(MPI_D_MISC, "%s:  ext_page_length: %d ext_page_type: 0x%02x "
	    "msg_flags: 0x%02x\n", DEVNAME(sc),
	    letoh16(cp->ext_page_length), cp->ext_page_type,
	    cp->msg_flags);
	DNPRINTF(MPI_D_MISC, "%s:  msg_context: 0x%08x\n", DEVNAME(sc),
	    letoh32(cp->msg_context));
	DNPRINTF(MPI_D_MISC, "%s:  ioc_status: 0x%04x\n", DEVNAME(sc),
	    letoh16(cp->ioc_status));
	DNPRINTF(MPI_D_MISC, "%s:  ioc_loginfo: 0x%08x\n", DEVNAME(sc),
	    letoh32(cp->ioc_loginfo));
	DNPRINTF(MPI_D_MISC, "%s:  page_version: 0x%02x page_length: %d "
	    "page_number: 0x%02x page_type: 0x%02x\n", DEVNAME(sc),
	    cp->config_header.page_version,
	    cp->config_header.page_length,
	    cp->config_header.page_number,
	    cp->config_header.page_type);

	if (lemtoh16(&cp->ioc_status) != MPI_IOCSTATUS_SUCCESS)
		rv = 1;
	else if (read)
		memcpy(page, kva, len);

	mpi_push_reply(sc, ccb->ccb_rcb);
	scsi_io_put(&sc->sc_iopool, ccb);

	return (rv);
}

int
mpi_scsi_ioctl(struct scsi_link *link, u_long cmd, caddr_t addr, int flag)
{
	struct mpi_softc	*sc = (struct mpi_softc *)link->adapter_softc;

	DNPRINTF(MPI_D_IOCTL, "%s: mpi_scsi_ioctl\n", DEVNAME(sc));

	switch (cmd) {
	case DIOCGCACHE:
	case DIOCSCACHE:
		if (ISSET(link->flags, SDEV_VIRTUAL)) {
			return (mpi_ioctl_cache(link, cmd,
			    (struct dk_cache *)addr));
		}
		break;

	default:
		if (sc->sc_ioctl)
			return (sc->sc_ioctl(link->adapter_softc, cmd, addr));

		break;
	}

	return (ENOTTY);
}

int
mpi_ioctl_cache(struct scsi_link *link, u_long cmd, struct dk_cache *dc)
{
	struct mpi_softc	*sc = (struct mpi_softc *)link->adapter_softc;
	struct mpi_ccb		*ccb;
	int			len, rv;
	struct mpi_cfg_hdr	hdr;
	struct mpi_cfg_raid_vol_pg0 *rpg0;
	int			enabled;
	struct mpi_msg_raid_action_request *req;
	struct mpi_msg_raid_action_reply *rep;
	struct mpi_raid_settings settings;

	rv = mpi_req_cfg_header(sc, MPI_CONFIG_REQ_PAGE_TYPE_RAID_VOL, 0,
	    link->target, MPI_PG_POLL, &hdr);
	if (rv != 0)
		return (EIO);

	len = sizeof(*rpg0) + sc->sc_vol_page->max_physdisks *
	    sizeof(struct mpi_cfg_raid_vol_pg0_physdisk);
	rpg0 = malloc(len, M_TEMP, M_NOWAIT);
	if (rpg0 == NULL)
		return (ENOMEM);

	if (mpi_req_cfg_page(sc, link->target, MPI_PG_POLL, &hdr, 1,
	    rpg0, len) != 0) {
		DNPRINTF(MPI_D_RAID, "%s: can't get RAID vol cfg page 0\n",
		    DEVNAME(sc));
		rv = EIO;
		goto done;
	}

	enabled = ISSET(lemtoh16(&rpg0->settings.volume_settings),
	    MPI_CFG_RAID_VOL_0_SETTINGS_WRITE_CACHE_EN) ? 1 : 0;

	if (cmd == DIOCGCACHE) {
		dc->wrcache = enabled;
		dc->rdcache = 0;
		goto done;
	} /* else DIOCSCACHE */

	if (dc->rdcache) {
		rv = EOPNOTSUPP;
		goto done;
	}

	if (((dc->wrcache) ? 1 : 0) == enabled)
		goto done;

	settings = rpg0->settings;
	if (dc->wrcache) {
		SET(settings.volume_settings,
		    htole16(MPI_CFG_RAID_VOL_0_SETTINGS_WRITE_CACHE_EN));
	} else {
		CLR(settings.volume_settings,
		    htole16(MPI_CFG_RAID_VOL_0_SETTINGS_WRITE_CACHE_EN));
	}

	ccb = scsi_io_get(&sc->sc_iopool, SCSI_NOSLEEP);
	if (ccb == NULL) {
		rv = ENOMEM;
		goto done;
	}

	req = ccb->ccb_cmd;
	req->function = MPI_FUNCTION_RAID_ACTION;
	req->action = MPI_MSG_RAID_ACTION_CH_VOL_SETTINGS;
	req->vol_id = rpg0->volume_id;
	req->vol_bus = rpg0->volume_bus;

	memcpy(&req->data_word, &settings, sizeof(req->data_word));
	ccb->ccb_done = mpi_empty_done;
	if (mpi_poll(sc, ccb, 50000) != 0) {
		rv = EIO;
		goto done;
	}

	rep = (struct mpi_msg_raid_action_reply *)ccb->ccb_rcb;
	if (rep == NULL)
		panic("%s: raid volume settings change failed", DEVNAME(sc));

	switch (lemtoh16(&rep->action_status)) {
	case MPI_RAID_ACTION_STATUS_OK:
		rv = 0;
		break;
	default:
		rv = EIO;
		break;
	}

	mpi_push_reply(sc, ccb->ccb_rcb);
	scsi_io_put(&sc->sc_iopool, ccb);

done:
	free(rpg0, M_TEMP, len);
	return (rv);
}

#if NBIO > 0
int
mpi_bio_get_pg0_raid(struct mpi_softc *sc, int id)
{
	int			len, rv = EINVAL;
	u_int32_t		address;
	struct mpi_cfg_hdr	hdr;
	struct mpi_cfg_raid_vol_pg0 *rpg0;

	/* get IOC page 2 */
	if (mpi_req_cfg_page(sc, 0, 0, &sc->sc_cfg_hdr, 1, sc->sc_vol_page,
	    sc->sc_cfg_hdr.page_length * 4) != 0) {
		DNPRINTF(MPI_D_IOCTL, "%s: mpi_bio_get_pg0_raid unable to "
		    "fetch IOC page 2\n", DEVNAME(sc));
		goto done;
	}

	/* XXX return something else than EINVAL to indicate within hs range */
	if (id > sc->sc_vol_page->active_vols) {
		DNPRINTF(MPI_D_IOCTL, "%s: mpi_bio_get_pg0_raid invalid vol "
		    "id: %d\n", DEVNAME(sc), id);
		goto done;
	}

	/* replace current buffer with new one */
	len = sizeof *rpg0 + sc->sc_vol_page->max_physdisks *
	    sizeof(struct mpi_cfg_raid_vol_pg0_physdisk);
	rpg0 = malloc(len, M_DEVBUF, M_WAITOK | M_CANFAIL);
	if (rpg0 == NULL) {
		printf("%s: can't get memory for RAID page 0, "
		    "bio disabled\n", DEVNAME(sc));
		goto done;
	}
	if (sc->sc_rpg0)
		free(sc->sc_rpg0, M_DEVBUF, 0);
	sc->sc_rpg0 = rpg0;

	/* get raid vol page 0 */
	address = sc->sc_vol_list[id].vol_id |
	    (sc->sc_vol_list[id].vol_bus << 8);
	if (mpi_req_cfg_header(sc, MPI_CONFIG_REQ_PAGE_TYPE_RAID_VOL, 0,
	    address, 0, &hdr) != 0)
		goto done;
	if (mpi_req_cfg_page(sc, address, 0, &hdr, 1, rpg0, len)) {
		DNPRINTF(MPI_D_RAID, "%s: can't get RAID vol cfg page 0\n",
		    DEVNAME(sc));
		goto done;
	}

	rv = 0;
done:
	return (rv);
}

int
mpi_ioctl(struct device *dev, u_long cmd, caddr_t addr)
{
	struct mpi_softc	*sc = (struct mpi_softc *)dev;
	int error = 0;

	DNPRINTF(MPI_D_IOCTL, "%s: mpi_ioctl ", DEVNAME(sc));

	/* make sure we have bio enabled */
	if (sc->sc_ioctl != mpi_ioctl)
		return (EINVAL);

	rw_enter_write(&sc->sc_lock);

	switch (cmd) {
	case BIOCINQ:
		DNPRINTF(MPI_D_IOCTL, "inq\n");
		error = mpi_ioctl_inq(sc, (struct bioc_inq *)addr);
		break;

	case BIOCVOL:
		DNPRINTF(MPI_D_IOCTL, "vol\n");
		error = mpi_ioctl_vol(sc, (struct bioc_vol *)addr);
		break;

	case BIOCDISK:
		DNPRINTF(MPI_D_IOCTL, "disk\n");
		error = mpi_ioctl_disk(sc, (struct bioc_disk *)addr);
		break;

	case BIOCALARM:
		DNPRINTF(MPI_D_IOCTL, "alarm\n");
		break;

	case BIOCBLINK:
		DNPRINTF(MPI_D_IOCTL, "blink\n");
		break;

	case BIOCSETSTATE:
		DNPRINTF(MPI_D_IOCTL, "setstate\n");
		error = mpi_ioctl_setstate(sc, (struct bioc_setstate *)addr);
		break;

	default:
		DNPRINTF(MPI_D_IOCTL, " invalid ioctl\n");
		error = EINVAL;
	}

	rw_exit_write(&sc->sc_lock);

	return (error);
}

int
mpi_ioctl_inq(struct mpi_softc *sc, struct bioc_inq *bi)
{
	if (!(sc->sc_flags & MPI_F_RAID)) {
		bi->bi_novol = 0;
		bi->bi_nodisk = 0;
	}

	if (mpi_cfg_page(sc, 0, &sc->sc_cfg_hdr, 1, sc->sc_vol_page,
	    sc->sc_cfg_hdr.page_length * 4) != 0) {
		DNPRINTF(MPI_D_IOCTL, "%s: mpi_get_raid unable to fetch IOC "
		    "page 2\n", DEVNAME(sc));
		return (EINVAL);
	}

	DNPRINTF(MPI_D_IOCTL, "%s:  active_vols: %d max_vols: %d "
	    "active_physdisks: %d max_physdisks: %d\n", DEVNAME(sc),
	    sc->sc_vol_page->active_vols, sc->sc_vol_page->max_vols,
	    sc->sc_vol_page->active_physdisks, sc->sc_vol_page->max_physdisks);

	bi->bi_novol = sc->sc_vol_page->active_vols;
	bi->bi_nodisk = sc->sc_vol_page->active_physdisks;
	strlcpy(bi->bi_dev, DEVNAME(sc), sizeof(bi->bi_dev));

	return (0);
}

int
mpi_ioctl_vol(struct mpi_softc *sc, struct bioc_vol *bv)
{
	int			i, vol, id, rv = EINVAL;
	struct device		*dev;
	struct scsi_link	*link;
	struct mpi_cfg_raid_vol_pg0 *rpg0;
	char			*vendp;

	id = bv->bv_volid;
	if (mpi_bio_get_pg0_raid(sc, id))
		goto done;

	if (id > sc->sc_vol_page->active_vols)
		return (EINVAL); /* XXX deal with hot spares */

	rpg0 = sc->sc_rpg0;
	if (rpg0 == NULL)
		goto done;

	/* determine status */
	switch (rpg0->volume_state) {
	case MPI_CFG_RAID_VOL_0_STATE_OPTIMAL:
		bv->bv_status = BIOC_SVONLINE;
		break;
	case MPI_CFG_RAID_VOL_0_STATE_DEGRADED:
		bv->bv_status = BIOC_SVDEGRADED;
		break;
	case MPI_CFG_RAID_VOL_0_STATE_FAILED:
	case MPI_CFG_RAID_VOL_0_STATE_MISSING:
		bv->bv_status = BIOC_SVOFFLINE;
		break;
	default:
		bv->bv_status = BIOC_SVINVALID;
	}

	/* override status if scrubbing or something */
	if (rpg0->volume_status & MPI_CFG_RAID_VOL_0_STATUS_RESYNCING)
		bv->bv_status = BIOC_SVREBUILD;

	bv->bv_size = (uint64_t)lemtoh32(&rpg0->max_lba) * 512;

	switch (sc->sc_vol_list[id].vol_type) {
	case MPI_CFG_RAID_TYPE_RAID_IS:
		bv->bv_level = 0;
		break;
	case MPI_CFG_RAID_TYPE_RAID_IME:
	case MPI_CFG_RAID_TYPE_RAID_IM:
		bv->bv_level = 1;
		break;
	case MPI_CFG_RAID_TYPE_RAID_5:
		bv->bv_level = 5;
		break;
	case MPI_CFG_RAID_TYPE_RAID_6:
		bv->bv_level = 6;
		break;
	case MPI_CFG_RAID_TYPE_RAID_10:
		bv->bv_level = 10;
		break;
	case MPI_CFG_RAID_TYPE_RAID_50:
		bv->bv_level = 50;
		break;
	default:
		bv->bv_level = -1;
	}

	bv->bv_nodisk = rpg0->num_phys_disks;

	for (i = 0, vol = -1; i < sc->sc_buswidth; i++) {
		link = scsi_get_link(sc->sc_scsibus, i, 0);
		if (link == NULL)
			continue;

		/* skip if not a virtual disk */
		if (!(link->flags & SDEV_VIRTUAL))
			continue;

		vol++;
		/* are we it? */
		if (vol == bv->bv_volid) {
			dev = link->device_softc;
			vendp = link->inqdata.vendor;
			memcpy(bv->bv_vendor, vendp, sizeof bv->bv_vendor);
			bv->bv_vendor[sizeof(bv->bv_vendor) - 1] = '\0';
			strlcpy(bv->bv_dev, dev->dv_xname, sizeof bv->bv_dev);
			break;
		}
	}
	rv = 0;
done:
	return (rv);
}

int
mpi_ioctl_disk(struct mpi_softc *sc, struct bioc_disk *bd)
{
	int			pdid, id, rv = EINVAL;
	u_int32_t		address;
	struct mpi_cfg_hdr	hdr;
	struct mpi_cfg_raid_vol_pg0 *rpg0;
	struct mpi_cfg_raid_vol_pg0_physdisk *physdisk;
	struct mpi_cfg_raid_physdisk_pg0 pdpg0;

	id = bd->bd_volid;
	if (mpi_bio_get_pg0_raid(sc, id))
		goto done;

	if (id > sc->sc_vol_page->active_vols)
		return (EINVAL); /* XXX deal with hot spares */

	rpg0 = sc->sc_rpg0;
	if (rpg0 == NULL)
		goto done;

	pdid = bd->bd_diskid;
	if (pdid > rpg0->num_phys_disks)
		goto done;
	physdisk = (struct mpi_cfg_raid_vol_pg0_physdisk *)(rpg0 + 1);
	physdisk += pdid;

	/* get raid phys disk page 0 */
	address = physdisk->phys_disk_num;
	if (mpi_cfg_header(sc, MPI_CONFIG_REQ_PAGE_TYPE_RAID_PD, 0, address,
	    &hdr) != 0)
		goto done;
	if (mpi_cfg_page(sc, address, &hdr, 1, &pdpg0, sizeof pdpg0)) {
		bd->bd_status = BIOC_SDFAILED;
		return (0);
	}
	bd->bd_channel = pdpg0.phys_disk_bus;
	bd->bd_target = pdpg0.phys_disk_id;
	bd->bd_lun = 0;
	bd->bd_size = (uint64_t)lemtoh32(&pdpg0.max_lba) * 512;
	strlcpy(bd->bd_vendor, (char *)pdpg0.vendor_id, sizeof(bd->bd_vendor));

	switch (pdpg0.phys_disk_state) {
	case MPI_CFG_RAID_PHYDISK_0_STATE_ONLINE:
		bd->bd_status = BIOC_SDONLINE;
		break;
	case MPI_CFG_RAID_PHYDISK_0_STATE_MISSING:
	case MPI_CFG_RAID_PHYDISK_0_STATE_FAILED:
		bd->bd_status = BIOC_SDFAILED;
		break;
	case MPI_CFG_RAID_PHYDISK_0_STATE_HOSTFAIL:
	case MPI_CFG_RAID_PHYDISK_0_STATE_OTHER:
	case MPI_CFG_RAID_PHYDISK_0_STATE_OFFLINE:
		bd->bd_status = BIOC_SDOFFLINE;
		break;
	case MPI_CFG_RAID_PHYDISK_0_STATE_INIT:
		bd->bd_status = BIOC_SDSCRUB;
		break;
	case MPI_CFG_RAID_PHYDISK_0_STATE_INCOMPAT:
	default:
		bd->bd_status = BIOC_SDINVALID;
		break;
	}

	/* XXX figure this out */
	/* bd_serial[32]; */
	/* bd_procdev[16]; */

	rv = 0;
done:
	return (rv);
}

int
mpi_ioctl_setstate(struct mpi_softc *sc, struct bioc_setstate *bs)
{
	return (ENOTTY);
}

#ifndef SMALL_KERNEL
int
mpi_create_sensors(struct mpi_softc *sc)
{
	struct device		*dev;
	struct scsi_link	*link;
	int			i, vol, nsensors;

	/* count volumes */
	for (i = 0, vol = 0; i < sc->sc_buswidth; i++) {
		link = scsi_get_link(sc->sc_scsibus, i, 0);
		if (link == NULL)
			continue;
		/* skip if not a virtual disk */
		if (!(link->flags & SDEV_VIRTUAL))
			continue;
		
		vol++;
	}
	if (vol == 0)
		return (0);

	sc->sc_sensors = mallocarray(vol, sizeof(struct ksensor),
	    M_DEVBUF, M_NOWAIT | M_ZERO);
	if (sc->sc_sensors == NULL)
		return (1);
	nsensors = vol;

	strlcpy(sc->sc_sensordev.xname, DEVNAME(sc),
	    sizeof(sc->sc_sensordev.xname));

	for (i = 0, vol= 0; i < sc->sc_buswidth; i++) {
		link = scsi_get_link(sc->sc_scsibus, i, 0);
		if (link == NULL)
			continue;
		/* skip if not a virtual disk */
		if (!(link->flags & SDEV_VIRTUAL))
			continue;

		dev = link->device_softc;
		strlcpy(sc->sc_sensors[vol].desc, dev->dv_xname,
		    sizeof(sc->sc_sensors[vol].desc));
		sc->sc_sensors[vol].type = SENSOR_DRIVE;
		sc->sc_sensors[vol].status = SENSOR_S_UNKNOWN;
		sensor_attach(&sc->sc_sensordev, &sc->sc_sensors[vol]);

		vol++;
	}

	if (sensor_task_register(sc, mpi_refresh_sensors, 10) == NULL)
		goto bad;

	sensordev_install(&sc->sc_sensordev);

	return (0);

bad:
	free(sc->sc_sensors, M_DEVBUF, nsensors * sizeof(struct ksensor));
	return (1);
}

void
mpi_refresh_sensors(void *arg)
{
	int			i, vol;
	struct scsi_link	*link;
	struct mpi_softc	*sc = arg;
	struct mpi_cfg_raid_vol_pg0 *rpg0;

	rw_enter_write(&sc->sc_lock);

	for (i = 0, vol = 0; i < sc->sc_buswidth; i++) {
		link = scsi_get_link(sc->sc_scsibus, i, 0);
		if (link == NULL)
			continue;
		/* skip if not a virtual disk */
		if (!(link->flags & SDEV_VIRTUAL))
			continue;

		if (mpi_bio_get_pg0_raid(sc, vol))
			continue;

		rpg0 = sc->sc_rpg0;
		if (rpg0 == NULL)
			goto done;

		/* determine status */
		switch (rpg0->volume_state) {
		case MPI_CFG_RAID_VOL_0_STATE_OPTIMAL:
			sc->sc_sensors[vol].value = SENSOR_DRIVE_ONLINE;
			sc->sc_sensors[vol].status = SENSOR_S_OK;
			break;
		case MPI_CFG_RAID_VOL_0_STATE_DEGRADED:
			sc->sc_sensors[vol].value = SENSOR_DRIVE_PFAIL;
			sc->sc_sensors[vol].status = SENSOR_S_WARN;
			break;
		case MPI_CFG_RAID_VOL_0_STATE_FAILED:
		case MPI_CFG_RAID_VOL_0_STATE_MISSING:
			sc->sc_sensors[vol].value = SENSOR_DRIVE_FAIL;
			sc->sc_sensors[vol].status = SENSOR_S_CRIT;
			break;
		default:
			sc->sc_sensors[vol].value = 0; /* unknown */
			sc->sc_sensors[vol].status = SENSOR_S_UNKNOWN;
		}

		/* override status if scrubbing or something */
		if (rpg0->volume_status & MPI_CFG_RAID_VOL_0_STATUS_RESYNCING) {
			sc->sc_sensors[vol].value = SENSOR_DRIVE_REBUILD;
			sc->sc_sensors[vol].status = SENSOR_S_WARN;
		}

		vol++;
	}
done:
	rw_exit_write(&sc->sc_lock);
}
#endif /* SMALL_KERNEL */
#endif /* NBIO > 0 */
@


1.204
log
@change some types in bio from u_quad_t to uint64_t, and fix casts in
drivers that fill that field in too.

quad types are going away.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.203 2015/10/23 00:08:57 jsg Exp $ */
d1452 6
a1457 1
	xs->status = sie->scsi_status;
a1460 4
		if (sie->scsi_state & MPI_SCSIIO_ERR_STATE_NO_SCSI_STATUS) {
			xs->error = XS_DRIVER_STUFFUP;
			break;
		}
d1466 1
a1466 1
			xs->resid = 0;
@


1.203
log
@replace pointer arithmetic and casts with offsetof
ok dlg@@ krw@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.202 2015/09/09 18:23:55 deraadt Exp $ */
d3267 1
a3267 1
	bv->bv_size = (u_quad_t)lemtoh32(&rpg0->max_lba) * 512;
d3359 1
a3359 1
	bd->bd_size = (u_quad_t)lemtoh32(&pdpg0.max_lba) * 512;
@


1.202
log
@sizes for free(); ok sthen
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.201 2015/05/04 03:59:42 jsg Exp $ */
d762 1
a762 1
	struct {
d812 1
a812 1
	    ((u_int8_t *)&bundle->sense - (u_int8_t *)bundle));
d819 1
a819 1
	    ((u_int8_t *)&bundle->inqbuf - (u_int8_t *)bundle));
d1372 1
a1372 1
	    ((u_int8_t *)&mcb->mcb_sense - (u_int8_t *)mcb));
@


1.201
log
@Fix some misuse of the | operator.  In particular | has higher
precedence than ?:
ok guenther@@ krw@@ miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.200 2015/03/14 03:38:47 jsg Exp $ */
d564 1
a564 1
	free(physdisk_pg, M_TEMP, 0);
d860 1
a860 1
	free(pg, M_TEMP, 0);
d1024 1
a1024 1
	free(mdm, M_DEVBUF, 0);
d1038 1
a1038 1
	free(mdm, M_DEVBUF, 0);
d1644 1
a1644 1
	free(rp0, M_TEMP, 0);
d2713 1
a2713 1
	free(pg, M_TEMP, 0);
d2766 1
a2766 1
	free(vol_page, M_TEMP, 0);
d3089 1
a3089 1
	free(rpg0, M_TEMP, 0);
d3405 1
a3405 1
	int			i, vol;
d3425 1
d3456 1
a3456 1
	free(sc->sc_sensors, M_DEVBUF, 0);
@


1.200
log
@Remove some includes include-what-you-use claims don't
have any direct symbols used.  Tested for indirect use by compiling
amd64/i386/sparc64 kernels.

ok tedu@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.199 2015/01/27 03:17:36 dlg Exp $ */
d1544 1
a1544 1
	    (xs->flags & SCSI_NOSLEEP) ? BUS_DMA_NOWAIT : BUS_DMA_WAITOK);
@


1.199
log
@remove the second void * argument on tasks.

when workqs were introduced, we provided a second argument so you
could pass a thing and some context to work on it in. there were
very few things that took advantage of the second argument, so when
i introduced pools i suggested removing it. since tasks were meant
to replace workqs, it was requested that we keep the second argument
to make porting from workqs to tasks easier.

now that workqs are gone, i had a look at the use of the second
argument again and found only one good use of it (vdsp(4) on sparc64
if you're interested) and a tiny handful of questionable uses. the
vast majority of tasks only used a single argument. i have since
modified all tasks that used two args to only use one, so now we
can remove the second argument.

so this is a mechanical change. all tasks only passed NULL as their
second argument, so we can just remove it.

ok krw@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.198 2014/09/17 10:11:33 dlg Exp $ */
a25 1
#include <sys/ioctl.h>
@


1.198
log
@be less confusing to the compiler when setting up the sge.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.197 2014/09/15 12:00:04 dlg Exp $ */
d149 1
a149 1
void			mpi_fc_rescan(void *, void *);
d225 1
a225 1
	task_set(&sc->sc_evt_rescan, mpi_fc_rescan, sc, NULL);
d2476 1
a2476 1
mpi_fc_rescan(void *xsc, void *null)
@


1.197
log
@mark the interrupt handler mpsafe, and drop the kernel lock in the scs_cmd
paths. take it again when going back to other parts of the kernel.

tested by and ok kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.196 2014/09/14 14:17:24 jsg Exp $ */
d1530 2
a1531 1
	struct mpi_sge			*sge, *nsge = &mcb->mcb_sgl[0];
@


1.196
log
@remove uneeded proc.h includes
ok mpi@@ kspillner@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.195 2014/09/03 00:46:04 dlg Exp $ */
d1313 2
d1323 1
a1323 2
		scsi_done(xs);
		return;
d1375 2
a1376 5
	if (mpi_load_xs(ccb) != 0) {
		xs->error = XS_DRIVER_STUFFUP;
		scsi_done(xs);
		return;
	}
d1381 7
a1387 6
		if (mpi_poll(sc, ccb, xs->timeout) != 0) {
			xs->error = XS_DRIVER_STUFFUP;
			scsi_done(xs);
		}
		return;
	}
d1389 5
a1393 1
	mpi_start(sc, ccb);
d1420 1
d1422 1
d2377 1
d2382 1
d2386 1
d2388 1
d2462 1
d2468 1
@


1.195
log
@tasks dont need a mutex and a semaphore to protect against multiple uses
of the task structure like workq tasks did.

tested on an fc929
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.194 2014/09/01 07:52:30 blambert Exp $ */
a26 1
#include <sys/proc.h>
@


1.194
log
@move mpi(4) from workq to taskq

ok dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.193 2014/07/13 23:10:23 deraadt Exp $ */
a149 1
void			mpi_evt_fc_rescan(struct mpi_softc *);
a225 2
	mtx_init(&sc->sc_evt_rescan_mtx, IPL_BIO);

d2331 1
a2331 1
			mpi_evt_fc_rescan(sc);
d2465 1
a2465 18
mpi_evt_fc_rescan(struct mpi_softc *sc)
{
	int					queue = 1;

	mtx_enter(&sc->sc_evt_rescan_mtx);
	if (sc->sc_evt_rescan_sem)
		queue = 0;
	else
		sc->sc_evt_rescan_sem = 1;
	mtx_leave(&sc->sc_evt_rescan_mtx);

	if (queue) {
		task_add(systq, &sc->sc_evt_rescan);
	}
}

void
mpi_fc_rescan(void *xsc, void *xarg)
a2473 4

	mtx_enter(&sc->sc_evt_rescan_mtx);
	sc->sc_evt_rescan_sem = 0;
	mtx_leave(&sc->sc_evt_rescan_mtx);
@


1.193
log
@Some reallocarray() use; review Jean-Philippe Ouellet, patrick keshishian
ok tedu
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.192 2014/07/12 18:48:17 tedu Exp $ */
d34 1
d229 2
d2480 1
a2480 2
		workq_queue_task(NULL, &sc->sc_evt_rescan, 0,
		    mpi_fc_rescan, sc, NULL);
@


1.192
log
@add a size argument to free. will be used soon, but for now default to 0.
after discussions with beck deraadt kettenis.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.191 2014/04/16 01:19:28 dlg Exp $ */
d343 2
a344 2
			sc->sc_vol_page = malloc(sc->sc_cfg_hdr.page_length * 4,
			    M_TEMP, M_WAITOK | M_CANFAIL);
d1053 1
a1053 1
	sc->sc_ccbs = malloc(sizeof(struct mpi_ccb) * sc->sc_maxcmds,
d1159 1
a1159 1
	sc->sc_rcbs = malloc(sc->sc_repq * sizeof(struct mpi_rcb), M_DEVBUF,
d3433 1
a3433 1
	sc->sc_sensors = malloc(sizeof(struct ksensor) * vol,
@


1.191
log
@print the board name and firmware revision like we do on mpii and
nvme and other stuff.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.190 2014/03/25 09:36:37 dlg Exp $ */
d402 1
a402 1
	free(sc->sc_ccbs, M_DEVBUF);
d566 1
a566 1
	free(physdisk_pg, M_TEMP);
d862 1
a862 1
	free(pg, M_TEMP);
d1026 1
a1026 1
	free(mdm, M_DEVBUF);
d1040 1
a1040 1
	free(mdm, M_DEVBUF);
d1108 1
a1108 1
	free(sc->sc_ccbs, M_DEVBUF);
d1166 1
a1166 1
		free(sc->sc_rcbs, M_DEVBUF);
d1640 1
a1640 1
	free(rp0, M_TEMP);
d2725 1
a2725 1
	free(pg, M_TEMP);
d2778 1
a2778 1
	free(vol_page, M_TEMP);
d3101 1
a3101 1
	free(rpg0, M_TEMP);
d3139 1
a3139 1
		free(sc->sc_rpg0, M_DEVBUF);
d3467 1
a3467 1
	free(sc->sc_sensors, M_DEVBUF);
@


1.190
log
@use lemtohXX and htolemXX as much as possible
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.188 2014/03/24 04:26:58 dlg Exp $ */
d137 1
d303 4
d2039 6
d2691 36
@


1.189
log
@when reading from the chip you use letoh32, not htole32.

jmatthew@@ agrees with me
@
text
@d703 1
a703 1
	if (!(letoh32(pg0.information) & 0x07) && (try == 0)) {
d709 1
a709 1
	if ((((letoh32(pg0.information) >> 8) & 0xff) > 0x09) && (try == 1)) {
d715 1
a715 1
	if (letoh32(pg0.information) & 0x0e) {
d717 1
a717 1
		    DEVNAME(sc), letoh32(pg0.information));
d806 1
a806 1
	io->data_length = htole32(sizeof(struct scsi_inquiry_data));
d808 1
a808 1
	io->sense_buf_low_addr = htole32(ccb->ccb_cmd_dva +
d811 1
a811 1
	sge->sg_hdr = htole32(MPI_SGE_FL_TYPE_SIMPLE | MPI_SGE_FL_SIZE_64 |
d841 1
a841 1
	pagelen = letoh16(ehdr.ext_page_length) * 4;
d1528 1
a1528 1
		nsge->sg_hdr = htole32(MPI_SGE_FL_TYPE_SIMPLE |
d1580 1
a1580 1
		sge = nsge;
a1583 2

		nsge = sge + 1;
d1684 1
a1684 1
	if (ISSET(letoh32(pg0.device_info),
d2034 1
a2034 1
	sc->sc_maxcmds = letoh16(ifp.global_credits);
d2043 1
a2043 1
		sc->sc_fw_len = letoh32(ifp.fw_image_size);
d2045 1
a2045 1
	sc->sc_repq = MIN(MPI_REPLYQ_DEPTH, letoh16(ifp.reply_queue_depth));
d2051 1
a2051 1
	sc->sc_first_sgl_len = ((letoh16(ifp.request_frame_size) * 4) -
d2056 1
a2056 1
	sc->sc_chain_len = (letoh16(ifp.request_frame_size) * 4) /
d2097 2
a2098 2
	iiq.host_mfa_hi_addr = htole32(hi_addr);
	iiq.sense_buffer_hi_addr = htole32(hi_addr);
d2195 1
a2195 1
		sc->sc_target = letoh16(pfp->port_scsi_id);
d2232 1
a2232 1
	flags = letoh32(pg.flags);
d2301 1
a2301 1
	switch (letoh32(enp->event)) {
d2325 1
a2325 1
		    DEVNAME(sc), letoh32(enp->event));
d2504 1
a2504 1
		id = letoh32(pg.port_id);
d2653 1
a2653 1
	bundle->req.tce.image_size = htole32(sc->sc_fw_len);
d2655 1
a2655 1
	bundle->sge.sg_hdr = htole32(MPI_SGE_FL_TYPE_SIMPLE |
d2669 1
a2669 1
	if (letoh16(upp->ioc_status) != MPI_IOCSTATUS_SUCCESS)
d2712 1
a2712 1
	capabilities = letoh32(vol_page->capabilities);
d2772 2
a2773 2
	cq->page_address = htole32(address);
	cq->page_buffer.sg_hdr = htole32(MPI_SGE_FL_TYPE_SIMPLE |
d2809 1
a2809 1
	if (letoh16(cp->ioc_status) != MPI_IOCSTATUS_SUCCESS)
d2844 1
a2844 1
	    letoh16(ehdr->ext_page_length) : hdr->page_length;
d2873 2
a2874 2
	cq->page_address = htole32(address);
	cq->page_buffer.sg_hdr = htole32(MPI_SGE_FL_TYPE_SIMPLE |
d2923 1
a2923 1
	if (letoh16(cp->ioc_status) != MPI_IOCSTATUS_SUCCESS)
d2992 1
a2992 1
	enabled = ISSET(letoh16(rpg0->settings.volume_settings),
d3041 1
a3041 1
	switch (letoh16(rep->action_status)) {
d3232 1
a3232 1
	bv->bv_size = (u_quad_t)letoh32(rpg0->max_lba) * 512;
d3324 1
a3324 1
	bd->bd_size = (u_quad_t)letoh32(pdpg0.max_lba) * 512;
@


1.188
log
@use htolemXX and lemtohXX in the scsi_cmd paths.

apart from the flags handling in sgls, this shrinks the io hot path
on sparc64 and powerpc a lot. its pretty much the same on
i386/amd64/alpha.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.187 2014/03/24 04:05:11 dlg Exp $ */
d2506 1
a2506 1
		id = htole32(pg.port_id);
@


1.187
log
@mpi scatter gather lists are 24 bytes long and next to each other in
memory. that means you cant do 8 byte loads and stores on the sg_addr
member cos it wont be 8 byte aligned half the time which makes
strict alignment archs (ie, the fun ones ones) upset.

annotate the sge as being 4 byte aligned. replace the sg_addr member
with sg_addr_lo and sg_addr_hi.

replace htole64 assignment of the sg addr with a wrapper that does
the right thing with a couple of htolem32 calls.

generated code shrinks again.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.186 2014/03/24 02:59:11 dlg Exp $ */
d1343 1
a1343 1
	io->lun[0] = htobe16(link->lun);
d1365 1
a1365 1
	io->data_length = htole32(xs->datalen);
d1367 1
a1367 1
	io->sense_buf_low_addr = htole32(ccb->ccb_cmd_dva +
d1445 1
a1445 1
	switch (letoh16(sie->ioc_status)) {
d1447 1
a1447 1
		xs->resid = xs->datalen - letoh32(sie->transfer_count);
@


1.186
log
@factor out the setting of the request context field so mpi_start does it
on behalf of all its callers.

use htolem32 and lemtoh32 to handle the message context.

both save bytes.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.185 2014/01/20 02:22:10 dlg Exp $ */
d209 7
a766 1
	u_int64_t			addr;
d815 2
a816 3
	addr = ccb->ccb_cmd_dva +
	    ((u_int8_t *)&bundle->inqbuf - (u_int8_t *)bundle);
	sge->sg_addr = htole64(addr);
a1522 1
	u_int64_t			ce_dva;
d1547 1
a1547 1
		io->chain_offset = ((u_int8_t *)ce - (u_int8_t *)io) / 4;
a1555 4
			DNPRINTF(MPI_D_DMA, "%s:   - 0x%08x 0x%016llx\n",
			    DEVNAME(sc), sge->sg_hdr,
			    sge->sg_addr);

d1558 1
a1558 1
				addr = ((u_int8_t *)nce - (u_int8_t *)nsge) / 4;
d1570 2
a1571 7
			ce_dva = ccb->ccb_cmd_dva +
			    ((u_int8_t *)nsge - (u_int8_t *)mcb);

			ce->sg_addr = htole64(ce_dva);

			DNPRINTF(MPI_D_DMA, "%s:  ce: 0x%08x 0x%016llx\n",
			    DEVNAME(sc), ce->sg_hdr, ce->sg_addr);
d1583 1
a1583 4
		sge->sg_addr = htole64(dmap->dm_segs[i].ds_addr);

		DNPRINTF(MPI_D_DMA, "%s:  %d: 0x%08x 0x%016llx\n",
		    DEVNAME(sc), i, sge->sg_hdr, sge->sg_addr);
d2032 1
a2032 1
	    "addr 0x%016llx\n", DEVNAME(sc),
d2034 2
a2035 1
	    letoh64(ifp.host_page_buffer_sge.sg_addr));
d2660 1
a2660 1
	bundle->sge.sg_addr = htole64(MPI_DMA_DVA(sc->sc_fw));
d2882 1
a2882 1
	cq->page_buffer.sg_addr = htole64(ccb->ccb_cmd_dva +
@


1.185
log
@bzero to memset
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.184 2014/01/20 02:20:27 dlg Exp $ */
a789 2
	io->msg_context = htole32(ccb->ccb_id);

d948 1
a948 1
		id = letoh32(reply->msg_context);
d1195 2
d1200 3
a1337 2
	io->msg_context = htole32(ccb->ccb_id);

a2166 1
	pfq->msg_context = htole32(ccb->ccb_id);
a2279 1
	enq->msg_context = htole32(ccb->ccb_id);
a2437 2
	str->msg_context = htole32(ccb->ccb_id);

a2562 1
	eaq->msg_context = htole32(ccb->ccb_id);
a2605 1
	peq->msg_context = htole32(ccb->ccb_id);
a2657 1
	bundle->req.msg_context = htole32(ccb->ccb_id);
a2774 1
	cq->msg_context = htole32(ccb->ccb_id);
a2868 1
	cq->msg_context = htole32(ccb->ccb_id);
a3037 1
	req->msg_context = htole32(ccb->ccb_id);
@


1.184
log
@bcopy to memcpy
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.183 2013/01/18 05:49:52 dlg Exp $ */
d360 1
a360 1
	bzero(&saa, sizeof(saa));
d764 1
a764 1
	bzero(&inq, sizeof(inq));
d1059 1
a1059 1
	bzero(cmd, MPI_REQUEST_SIZE * sc->sc_maxcmds);
d1140 1
a1140 1
	bzero(ccb->ccb_cmd, MPI_REQUEST_SIZE);
d1304 1
a1304 1
		bzero(&xs->sense, sizeof(xs->sense));
d1975 2
a1976 2
	bzero(&ifq, sizeof(ifq));
	bzero(&ifp, sizeof(ifp));
d2091 2
a2092 2
	bzero(&iiq, sizeof(iiq));
	bzero(&iip, sizeof(iip));
d2498 1
a2498 1
	bzero(devmap, sizeof(devmap));
d2508 1
a2508 1
		bzero(&pg, sizeof(pg));
d2828 1
a2828 1
		bzero(ehdr, sizeof(*ehdr));
@


1.183
log
@data transfers suit STREAMING dma maps.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.182 2013/01/17 03:05:11 dlg Exp $ */
d800 1
a800 1
	bcopy(&inq, io->cdb, sizeof(inq));
d1357 1
a1357 1
	bcopy(xs->cmd, io->cdb, xs->cmdlen);
d1491 1
a1491 1
		bcopy(&mcb->mcb_sense, &xs->sense, sizeof(xs->sense));
d1497 1
d1499 1
d2903 1
a2903 1
		bcopy(page, kva, len);
d2943 1
a2943 1
		bcopy(kva, page, len);
@


1.182
log
@mikeb pointed at that the interrupt status register read in mpi_intr was
important, as per r1.167.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.181 2013/01/17 02:44:42 dlg Exp $ */
d1527 1
a1527 1
	    xs->data, xs->datalen, NULL,
@


1.181
log
@we dont need to read the interrupt status register to know if we have
any work to do in the interrupt handler, or to clear it. the relevant bits
indicate whether there's work on the doorbell and clear when there isnt.
we need to read the doorbell if there is work to do, so lets just go that
straight away anyway.

get rid of bus_space_barriers in the io path. barriers are for enforcing
ordering. the doorbell reads and writes dont depend on any other register
values so ordering isnt applicable here.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.180 2013/01/17 02:39:05 dlg Exp $ */
d178 2
a179 1
#define mpi_read_intr(s)	mpi_read((s), MPI_INTR_STATUS)
d914 3
@


1.180
log
@treat DVAs as 64bits all the time so we can avoid ugly casts and shifts in
the code.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.179 2012/09/18 23:54:29 dlg Exp $ */
d180 4
a183 2
#define mpi_pop_reply(s)	mpi_read((s), MPI_REPLY_QUEUE)
#define mpi_push_reply_db(s, v)	mpi_write((s), MPI_REPLY_QUEUE, (v))
a913 3
	if ((mpi_read_intr(sc) & MPI_INTR_STATUS_REPLY) == 0)
		return (rv);

d1201 2
a1202 1
	mpi_write(sc, MPI_REQ_QUEUE, ccb->ccb_cmd_dva);
@


1.179
log
@several tweaks to make mpi(4) work for vmware emulated sas adapters.

1. vmware advertises more scsi targets than command slots, so the maths
we did for openings gave each target 0 openings. always advertise at least
16 openings.

2. if we cant configure the ATA queue depth, dont fail to attach the
controller whole.

finally, improve the error reporting during attach so its more obvious
where things fail.

mostly figured out by jmatthew@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.178 2012/09/12 06:58:20 haesbaert Exp $ */
d2098 1
a2098 1
	hi_addr = (u_int32_t)((u_int64_t)MPI_DMA_DVA(sc->sc_requests) >> 32);
@


1.178
log
@Use sg_addr instead of sg_lo_addr, leftovers from last commit.

ok dlg
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.177 2012/09/12 06:53:05 haesbaert Exp $ */
d294 2
a295 1
		if (mpi_cfg_spi_port(sc) != 0)
d297 1
d301 2
a302 1
		if (mpi_cfg_sas(sc) != 0)
d304 1
d307 2
a308 1
		if (mpi_cfg_fc(sc) != 0)
d310 1
d354 1
a354 1
	sc->sc_link.openings = sc->sc_maxcmds / sc->sc_buswidth;
d833 1
a833 1
		return (EIO);
d840 1
a840 2
	if (mpi_ecfg_page(sc, 0, &ehdr, 1, pg, pagelen) != 0) {
		rv = EIO;
a841 1
	}
d846 1
a846 2
		if (mpi_ecfg_page(sc, 0, &ehdr, 0, pg, pagelen) != 0) {
			rv = EIO;
a847 1
		}
@


1.177
log
@Make sure we don't sleep on autoconf.

ok mikeb
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.176 2012/08/26 11:33:44 dlg Exp $ */
d1543 1
a1543 1
			DNPRINTF(MPI_D_DMA, "%s:   - 0x%08x 0x%08x 0x%08x\n",
d1545 1
a1545 1
			    sge->sg_hi_addr, sge->sg_lo_addr);
d1566 2
a1567 3
			DNPRINTF(MPI_D_DMA, "%s:  ce: 0x%08x 0x%08x 0x%08x\n",
			    DEVNAME(sc), ce->sg_hdr, ce->sg_hi_addr,
			    ce->sg_lo_addr);
d1581 2
a1582 3
		DNPRINTF(MPI_D_DMA, "%s:  %d: 0x%08x 0x%08x 0x%08x\n",
		    DEVNAME(sc), i, sge->sg_hdr, sge->sg_hi_addr,
		    sge->sg_lo_addr);
d2031 1
a2031 1
	    "addr 0x%08x %08x\n", DEVNAME(sc),
d2033 1
a2033 3
	    letoh32(ifp.host_page_buffer_sge.sg_hi_addr),
	    letoh32(ifp.host_page_buffer_sge.sg_lo_addr));

@


1.176
log
@htole64 works as good as htole32 twice for dma virtual addresses.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.175 2012/01/16 10:55:46 dlg Exp $ */
d3401 1
a3401 1
	    M_DEVBUF, M_WAITOK|M_CANFAIL|M_ZERO);
@


1.175
log
@mpi_get_ccb and mpi_put_ccb are only called via iopools now, so change
their types to fit the iopools api rather than doing awful typecasts to
shove them into iopool_init.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.174 2011/07/17 22:46:48 matthew Exp $ */
d804 1
a804 2
	sge->sg_hi_addr = htole32((u_int32_t)(addr >> 32));
	sge->sg_lo_addr = htole32((u_int32_t)addr);
d1564 1
a1564 4
			addr = (u_int32_t)(ce_dva >> 32);
			ce->sg_hi_addr = htole32(addr);
			addr = (u_int32_t)ce_dva;
			ce->sg_lo_addr = htole32(addr);
d1580 1
a1580 4
		addr = (u_int32_t)((u_int64_t)dmap->dm_segs[i].ds_addr >> 32);
		sge->sg_hi_addr = htole32(addr);
		addr = (u_int32_t)dmap->dm_segs[i].ds_addr;
		sge->sg_lo_addr = htole32(addr);
a2633 1
	u_int64_t				addr;
d2669 1
a2669 3
	addr = MPI_DMA_DVA(sc->sc_fw);
	bundle->sge.sg_hi_addr = htole32((u_int32_t)(addr >> 32));
	bundle->sge.sg_lo_addr = htole32((u_int32_t)addr);
a2847 1
	u_int64_t				dva;
d2893 2
a2894 4
	dva = ccb->ccb_cmd_dva + sizeof(struct mpi_msg_config_request);

	cq->page_buffer.sg_hi_addr = htole32((u_int32_t)(dva >> 32));
	cq->page_buffer.sg_lo_addr = htole32((u_int32_t)dva);
@


1.174
log
@Backout a bunch of my SCSI commits from c2k11.  At least one of these
is causing problems when trying to boot sparc64 from an isp(4).

Verified to fix the sparc64/isp(4) regression by krw@@; ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.173 2011/07/08 22:09:27 matthew Exp $ */
d85 2
a86 2
struct mpi_ccb		*mpi_get_ccb(struct mpi_softc *);
void			mpi_put_ccb(struct mpi_softc *, struct mpi_ccb *);
d1086 1
a1086 3
	scsi_iopool_init(&sc->sc_iopool, sc,
	    (void *(*)(void *))mpi_get_ccb,
	    (void (*)(void *, void *))mpi_put_ccb);
d1101 2
a1102 2
struct mpi_ccb *
mpi_get_ccb(struct mpi_softc *sc)
d1104 1
d1121 1
a1121 1
mpi_put_ccb(struct mpi_softc *sc, struct mpi_ccb *ccb)
d1123 3
@


1.173
log
@First batch of converting SCSI HBAs from setting saa_targets and
saa_luns instead of adapter_buswidth and luns in the prototype link.

ok dlg@@, miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.172 2011/06/17 07:06:46 mk Exp $ */
d347 1
a352 1
	saa.saa_targets = sc->sc_buswidth;
@


1.172
log
@M_WAITOK cleanup of two cases:

1) Allocating with M_WAITOK, checking for NULL, and calling panic() is
pointless (malloc() will panic if it can't allocate) so remove the check
and the call.

2) Allocating with M_WAITOK, checking for NULL, and then gracefully
handling failure to allocate is pointless.  Instead also pass M_CANFAIL
so malloc() doesn't panic so we can actually handle it gracefully.

1) was done using Coccinelle.

Input from oga.

ok miod.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.171 2011/04/27 06:06:30 dlg Exp $ */
a346 1
	sc->sc_link.adapter_buswidth = sc->sc_buswidth;
d352 1
@


1.171
log
@if getting the RAID header fails, dont stop the midlayer from trying to
issues scsi commands against that target. it might be a normal device and
the firmware is just being picky about which headers you can fetch.

tested by and ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.170 2011/04/27 06:04:48 dlg Exp $ */
d3412 1
a3412 1
	    M_DEVBUF, M_WAITOK|M_ZERO);
@


1.170
log
@configure fc controllers to fail io as fast as possible when cables are
yanked. we want to reschedule them down active paths rather than wait for
a minute while mpi decides that a path isnt coming back.

discussed with and tested by deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.169 2011/04/27 05:11:09 dlg Exp $ */
d1632 1
a1632 1
		return (rv);
@


1.169
log
@return XS_RESET to the midlayer if the command was killed for some reason
rather than the default of XS_DRIVER_STUFFUP. mpath(4) likes this better
when you unplug paths.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.168 2011/04/27 04:03:11 dlg Exp $ */
d107 1
a107 1
void			mpi_fc_info(struct mpi_softc *);
d303 2
a304 1
		mpi_fc_info(sc);
d854 2
a855 2
void
mpi_fc_info(struct mpi_softc *sc)
d858 2
a859 1
	struct mpi_cfg_fc_port_pg0	pg;
d863 22
a884 3
		DNPRINTF(MPI_D_MISC, "%s: mpi_fc_print unable to fetch "
		    "FC port header 0\n", DEVNAME(sc));
		return;
d887 6
a892 5
	if (mpi_cfg_page(sc, 0, &hdr, 1, &pg, sizeof(pg)) != 0) {
		DNPRINTF(MPI_D_MISC, "%s: mpi_fc_print unable to fetch "
		    "FC port page 0\n",
		    DEVNAME(sc));
		return;
d895 1
a895 2
	sc->sc_link.port_wwn = letoh64(pg.wwpn);
	sc->sc_link.node_wwn = letoh64(pg.wwnn);
@


1.168
log
@rework the scanning of fibre channel ports to match how linux does it.
some fc parts dont like the header requests against missing devices with
bus addressing, so now we do the magic iteration over active ports.

the original problem was reported by deraadt@@
lots of testing and debugging by deraadt@@
tested on fc929 and fc949 adapters
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.167 2011/03/04 15:44:39 mikeb Exp $ */
d1450 5
@


1.167
log
@Peek at the interrupt status register before poking with the reply post
queue.  In some situations this prevents us from reading a garbled reply.
If this commit breaks your mpi, please report ASAP.

The issue was reported and the fix was verified by Emeric Boit.  Thanks!
Ok dlg, kettenis, marco (who warned us and wanted to test more)
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.166 2011/03/01 23:48:33 dlg Exp $ */
d2465 2
a2466 1
	u_int32_t				id;
d2473 1
a2473 2
	for (i = 0; i < sc->sc_buswidth; i++) {
		id = MPI_PAGE_ADDRESS_FC_BTID | i;
d2475 1
d2478 2
a2479 2
			printf("%s: header get for rescan of %d failed\n",
			    DEVNAME(sc), i);
d2483 12
d2497 1
a2497 3
		memset(&pg, 0, sizeof(pg));
		if (mpi_req_cfg_page(sc, id, 0, &hdr, 1,
		    &pg, sizeof(pg)) == 0) {
@


1.166
log
@back out r1.162, the one that bumps openings up on sas and fc
devices.

my theory is that some devices report queue full conditions in ways
the firmware doesnt understand, or some firmwares default to NOT
doing the queue full handling internally. either way it reports
queue full conditions as faulted io which gets passed up to the
block layer as errors.

this makes us conservative again and safe.

this fixes panics from ajacout

ok sthen@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.161 2010/09/13 07:48:12 dlg Exp $ */
d889 3
@


1.165
log
@vol_list in mpi_get_raid is never used.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.164 2010/09/21 06:25:48 dlg Exp $ */
d347 1
a347 4
	if (sc->sc_porttype == MPI_PORTFACTS_PORTTYPE_SCSI)
		sc->sc_link.openings = sc->sc_maxcmds / sc->sc_buswidth;
	else
		sc->sc_link.openings = sc->sc_maxcmds;
@


1.164
log
@tweak the sas io unit to use 32 openings when talking to sata disks if the
firmware has it configured lower.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.163 2010/09/20 06:17:49 krw Exp $ */
a2668 1
	struct mpi_cfg_raid_vol		*vol_list;
a2686 1
	vol_list = (struct mpi_cfg_raid_vol *)(vol_page + 1);
@


1.163
log
@Use SSD_ERRCODE_CURRENT instead of magic 0x70.

ok dlg@@ matthew@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.162 2010/09/14 00:03:04 dlg Exp $ */
d106 1
d298 4
d818 36
@


1.162
log
@allow devices on fc and sas adapters to use all the openings the chip can
provide. spi parts are still limited.

ok krw@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.161 2010/09/13 07:48:12 dlg Exp $ */
d1236 1
a1236 1
		xs->sense.error_code = SSD_ERRCODE_VALID | 0x70;
@


1.161
log
@if a busy sas device is unplugged, the pending io on that device will
never complete.

when we get a detach event from the firmware, we currently deactivate the
device and then request the scsi midlayer attempt to detach the device.
this diff now deactivates the device and then resets the target, forcing
the ioc to complete the pending operations. once the reset has completed
we then request a detach of the kernel device.

this lets me hotplug busy sas disks without leaking scsi_xfers or bufs or
anything.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.159 2010/09/13 06:53:21 dlg Exp $ */
d342 4
a345 1
	sc->sc_link.openings = sc->sc_maxcmds / sc->sc_buswidth;
@


1.160
log
@dont reuse the event notifications ccbs id for the acknowledgement.
@
text
@d140 2
d144 3
a146 1
void			mpi_evt_sas(struct mpi_softc *, struct mpi_rcb *);
d267 6
a273 1
	case MPI_PORTFACTS_PORTTYPE_SAS:
d2252 4
a2255 1
		mpi_evt_sas(sc, rcb);
d2270 8
d2284 1
a2284 1
		mpi_push_reply(sc, ccb->ccb_rcb);
d2287 1
a2287 1
void
d2298 1
a2298 1
		return;
d2311 8
a2318 6
		if (scsi_req_detach(sc->sc_scsibus, ch->target, -1,
		    DETACH_FORCE) != 0) {
			printf("%s: unable to request detach of %d\n",
			    DEVNAME(sc), ch->target);
		}
		break;
d2329 65
@


1.159
log
@im not convinced we only have one outstanding event to ack at a time. this
steals^Wleverages the code used in mpii for handling a list of events to
acknowlede.

tested by hotplugging sas disks.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.158 2010/09/10 07:00:56 dlg Exp $ */
d2399 1
a2399 1
	eaq->msg_context = enp->msg_context;
@


1.158
log
@implement handling of rescan events on fc controllers. allows "hotplug" of
fc devices.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.157 2010/08/27 05:30:59 dlg Exp $ */
d2190 6
a2203 2
	sc->sc_evt_ccb = ccb;
	scsi_ioh_set(&sc->sc_evt_ack, &sc->sc_iopool, mpi_eventack, sc);
d2212 2
a2213 1
	struct mpi_msg_event_reply		*enp = ccb->ccb_rcb->rcb_reply;
d2243 1
a2243 1
		mpi_evt_sas(sc, ccb->ccb_rcb);
d2258 6
a2263 3
	if (enp->ack_required)
		scsi_ioh_add(&sc->sc_evt_ack);
	else
d2374 2
a2375 2
	struct mpi_ccb				*eccb = sc->sc_evt_ccb;
	struct mpi_msg_event_reply		*enp = eccb->ccb_rcb->rcb_reply;
d2380 15
d2399 1
a2399 1
	eaq->msg_context = htole32(ccb->ccb_id);
d2404 1
a2404 1
	mpi_push_reply(sc, eccb->ccb_rcb);
d2406 3
@


1.157
log
@get some format strings and variables right in debug output
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.156 2010/08/07 03:50:01 krw Exp $ */
d143 2
d209 3
d262 3
a264 1
	if (sc->sc_porttype == MPI_PORTFACTS_PORTTYPE_SAS) {
d269 1
a292 2
	rw_init(&sc->sc_lock, "mpi_lock");

d2241 6
d2298 60
@


1.156
log
@No "\n" needed at the end of panic() strings.

Bogus chunks pointed out by matthew@@ and miod@@. No cookies for
marco@@ and jasper@@.

ok deraadt@@ miod@@ matthew@@ jasper@@ macro@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.155 2010/07/06 07:18:18 dlg Exp $ */
d2150 1
a2150 1
	DNPRINTF(MPI_D_MISC, "%s:  flags: 0x08%x\n", DEVNAME(sc),
d2155 1
a2155 1
	    DEVNAME(sc), pg.coalescing_timeout, pg.pci_slot_num);
@


1.155
log
@if we get an event notification that requires acknowledgement while
we're busy, we might not be able to allocate a ccb via scsi_ioh_get
if the pool is empty. this means we wont ack the event, which in
turn means we wont receive further event notifications.

this cuts the event ack code over to using a scsi_iohandler. the
eventack iohandler will be called as soon as a ccb becomes available
for it to use. this guarantees reliable event handling and
acknowledgement, despite how busy the controller might be.

this has bugging me ever since i wrote the event handling code.
tested by hotplugging sata disks.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.154 2010/07/06 06:50:42 dlg Exp $ */
d874 1
a874 1
			panic("%s: unsupported context reply\n",
d2419 1
a2419 1
		panic("%s: unable to do fw upload\n", DEVNAME(sc));
d2543 1
a2543 1
		panic("%s: unable to fetch config header\n", DEVNAME(sc));
@


1.154
log
@move the last direct users of mpi_{get,put}_ccb over to using the scsi
ioh wrappers.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.153 2010/07/01 03:20:38 matthew Exp $ */
d140 1
a140 2
void			mpi_eventack(struct mpi_softc *,
			    struct mpi_msg_event_reply *);
d2193 1
d2242 3
a2244 9
		mpi_eventack(sc, enp);
	mpi_push_reply(sc, ccb->ccb_rcb);

#if 0
	/* fc hbas have a bad habit of setting this without meaning it. */
	if ((enp->msg_flags & MPI_EVENT_FLAGS_REPLY_KEPT) == 0) {
		scsi_io_put(&sc->sc_iopool, ccb);
	}
#endif
d2290 1
a2290 1
mpi_eventack(struct mpi_softc *sc, struct mpi_msg_event_reply *enp)
d2292 4
a2295 1
	struct mpi_ccb				*ccb;
d2298 1
a2298 5
	ccb = scsi_io_get(&sc->sc_iopool, SCSI_NOSLEEP);
	if (ccb == NULL) {
		DNPRINTF(MPI_D_EVT, "%s: mpi_eventack ccb_get\n", DEVNAME(sc));
		return;
	}
d2309 1
a2310 1
	return;
@


1.153
log
@Change scsibus(4)'s scsi_link array to an SLIST to save memory on
sparsely populated buses.

ok dlg@@, krw@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.152 2010/06/28 18:31:02 krw Exp $ */
d739 1
a739 1
	ccb = mpi_get_ccb(sc);
d793 1
a793 1
	mpi_put_ccb(sc, ccb);
d2069 1
a2069 1
	ccb = mpi_get_ccb(sc);
d2126 1
a2126 1
	mpi_put_ccb(sc, ccb);
d2178 1
a2178 1
	ccb = mpi_get_ccb(sc);
d2248 1
a2248 1
		mpi_put_ccb(sc, ccb);
d2301 1
a2301 1
	ccb = mpi_get_ccb(sc);
d2328 1
a2328 1
	mpi_put_ccb(sc, ccb);
d2340 1
a2340 1
	ccb = mpi_get_ccb(sc);
d2366 1
a2366 1
	mpi_put_ccb(sc, ccb);
d2395 1
a2395 1
	ccb = mpi_get_ccb(sc);
d2433 1
a2433 1
	mpi_put_ccb(sc, ccb);
d2666 1
a2666 1
		mpi_put_ccb(sc, ccb);
@


1.152
log
@Remove all adapter-specific 'struct scsi_device's. They are never used. First
step in elminating 'struct scsi_device' entirely.

Spotted and initial diff from matthew@@.

ok matthew@@ dlg@@ deraadt@@ marco@@ miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.151 2010/06/15 04:30:26 dlg Exp $ */
d465 1
a465 1
		link = sc->sc_scsibus->sc_link[i][0];
d3029 1
a3029 1
		link = sc->sc_scsibus->sc_link[i][0];
d3142 1
a3142 1
		link = sc->sc_scsibus->sc_link[i][0];
d3163 1
a3163 1
		link = sc->sc_scsibus->sc_link[i][0];
d3203 1
a3203 1
		link = sc->sc_scsibus->sc_link[i][0];
@


1.151
log
@rearrange attach so that the SDEV_VIRTUAL flag is set during scsi_probe,
rather than as a scan of all attached devices after scsibus is attached.

this will allow the cache enabling on virtual disks to run as part of the
disks attach routine.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.149 2010/05/19 07:26:01 dlg Exp $ */
a80 7
struct scsi_device mpi_dev = {
	NULL,
	NULL,
	NULL,
	NULL
};

a323 1
	sc->sc_link.device = &mpi_dev;
@


1.150
log
@dont pass the dev_t from the scsi device drivers into the midlayer for
ioctl requests, and dont pass the proc pointers around for any ioctl
requests in scsi land at all. neither were used, so trim the fat.

ok krw@@ marco@@
@
text
@d143 1
d295 35
a345 3
	/* get raid pages */
	mpi_get_raid(sc);

a353 24
	if (sc->sc_flags & MPI_F_RAID) {
		if (bio_register(&sc->sc_dev, mpi_ioctl) != 0)
			panic("%s: controller registration failed",
			    DEVNAME(sc));
		else {
			if (mpi_cfg_header(sc, MPI_CONFIG_REQ_PAGE_TYPE_IOC,
			    2, 0, &sc->sc_cfg_hdr) != 0) {
				printf("%s: can't get IOC page 2 hdr, bio "
				    "disabled\n", DEVNAME(sc));
				goto done;
			}
			sc->sc_vol_page = malloc(sc->sc_cfg_hdr.page_length * 4,
			    M_TEMP, M_WAITOK | M_CANFAIL);
			if (sc->sc_vol_page == NULL) {
				printf("%s: can't get memory for IOC page 2, "
				    "bio disabled\n", DEVNAME(sc));
				goto done;
			}
			sc->sc_vol_list = (struct mpi_cfg_raid_vol *)
			    (sc->sc_vol_page + 1);

			sc->sc_ioctl = mpi_ioctl;
		}
	}
a356 1
done:
d1539 33
d1578 8
d2455 1
a2455 1
	struct mpi_cfg_raid_vol		*vol_list, *vol;
a2457 2
	struct scsi_link		*link;
	int				i;
d2497 2
a2498 24
	if ((capabilities & MPI_CFG_IOC_2_CAPABILITIES_RAID) == 0 ||
	    (vol_page->active_vols == 0))
		goto out;

	sc->sc_flags |= MPI_F_RAID;

	for (i = 0; i < vol_page->active_vols; i++) {
		vol = &vol_list[i];

		DNPRINTF(MPI_D_RAID, "%s:   id: %d bus: %d ioc: %d pg: %d\n",
		    DEVNAME(sc), vol->vol_id, vol->vol_bus, vol->vol_ioc,
		    vol->vol_page);
		DNPRINTF(MPI_D_RAID, "%s:   type: 0x%02x flags: 0x%02x\n",
		    DEVNAME(sc), vol->vol_type, vol->flags);

		if (vol->vol_ioc != sc->sc_ioc_number || vol->vol_bus != 0)
			continue;

		link = sc->sc_scsibus->sc_link[vol->vol_id][0];
		if (link == NULL)
			continue;

		link->flags |= SDEV_VIRTUAL;
	}
a2740 1
	u_int32_t		address;
a2747 2
	address = link->target;

d2749 1
a2749 1
	    address, 0, &hdr);
d2753 1
a2753 1
	len = sizeof *rpg0 + sc->sc_vol_page->max_physdisks *
d2755 3
a2757 1
	rpg0 = malloc(len, M_TEMP, M_WAITOK);
d2759 2
a2760 1
	if (mpi_req_cfg_page(sc, address, 0, &hdr, 1, rpg0, len) != 0) {
d2793 1
a2793 1
	ccb = scsi_io_get(&sc->sc_iopool, 0);
a2806 1

d2808 4
a2811 1
	mpi_wait(sc, ccb);
@


1.149
log
@the virtual scsi disks that mpi(4) presents dont grok modifications to the
mode pages that control the caches. this adds code that talks to the mpi
chip directly on behalf of those disks so you can enable write caching on
them.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.148 2010/05/16 20:33:59 nicm Exp $ */
d71 1
a71 1
			    int, struct proc *);
d2685 1
a2685 2
mpi_scsi_ioctl(struct scsi_link *link, u_long cmd, caddr_t addr, int flag,
    struct proc *p)
@


1.148
log
@Use a temporary variable for now to sidestep -Wbounded checking when
copying vendor[8]/product[16]/revision[4] out of struct scsi_inquiry_data
together with one memcopy.

ok krw
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.147 2010/05/09 22:03:56 dlg Exp $ */
d33 1
d156 3
d2692 114
a2805 4
	if (sc->sc_ioctl)
		return (sc->sc_ioctl(link->adapter_softc, cmd, addr));
	else
		return (ENOTTY);
@


1.147
log
@back out 1.143, it causes data corruption on the mpis in sun v20z boxes,
but i suspect it is common to all SPI mpi parts.

problem found and problem diff verified by landry.

ok krw@@ landry@@ jasper@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.143 2010/04/19 09:51:09 dlg Exp $ */
d2835 1
d2909 2
a2910 2
			memcpy(bv->bv_vendor, link->inqdata.vendor,
			    sizeof bv->bv_vendor);
@


1.146
log
@Fix gcc4 warning
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.145 2010/04/22 12:33:30 oga Exp $ */
d296 1
a296 1
	sc->sc_link.openings = sc->sc_maxcmds;
@


1.145
log
@use BUS_DMA_ZERO on alloc instead of bzeroing after.

ok dlg@@, marco@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.144 2010/04/22 03:14:35 marco Exp $ */
d2960 1
a2960 1
	strlcpy(bd->bd_vendor, pdpg0.vendor_id, sizeof(bd->bd_vendor));
@


1.144
log
@Fix cut 'n paste typo
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.143 2010/04/19 09:51:09 dlg Exp $ */
d907 1
a907 1
	    1, &nsegs, BUS_DMA_NOWAIT) != 0)
a916 2

	bzero(mdm->mdm_kva, size);
@


1.143
log
@i thought mpi gave each device all the openings on the bus, which was a
big motivation to implementing iopools. while looking at another issue i
noticed that openings were cut up for each disk.

this cranks openings to maxcmds.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.142 2010/04/16 12:19:07 dlg Exp $ */
d2102 2
a2103 2
		DNPRINTF(MPI_D_MISC, "%s: mpi_get_raid unable to fetch IOC "
		    "page 1\n", DEVNAME(sc));
@


1.142
log
@byteswap the number of blocks on physical disks for bioctl correctly.
makes output sane on sparc64 and other BE archs.

found by jason george
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.141 2010/04/16 01:10:19 deraadt Exp $ */
d296 1
a296 1
	sc->sc_link.openings = sc->sc_maxcmds / sc->sc_buswidth;
@


1.141
log
@if there is no raid, do not allocate a 0-sized structure for sensors
and then start attaching it with 0 sensors attached
ok dlg
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.140 2010/04/12 09:53:46 dlg Exp $ */
d2961 1
a2961 1
	bd->bd_size = (u_quad_t)pdpg0.max_lba * 512;
@


1.140
log
@dont need to call scsi_done with splbio. the midlayer protects
itself now, its not the adapters responsibility anymore.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.139 2010/04/09 14:06:01 dlg Exp $ */
d3020 2
@


1.139
log
@fix double free in an error path. the midlayer gets the ccb for scsi io
now, so it not our job to free it.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.138 2010/04/06 01:24:43 dlg Exp $ */
a1209 1
	int				s;
a1220 1
		s = splbio();
a1221 1
		splx(s);
a1277 1
		s = splbio();
a1278 1
		splx(s);
a1286 1
			s = splbio();
a1287 1
			splx(s);
a1302 1
	int				s;
a1318 1
		s = splbio();
a1319 1
		splx(s);
a1403 1
	s = splbio();
a1404 1
	splx(s);
@


1.138
log
@use SLISTs for managing the ccb free list rather than TAILQs.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.137 2010/04/06 01:04:22 dlg Exp $ */
a1280 1
		mpi_put_ccb(sc, ccb);
@


1.137
log
@modify mpi to provide an iopool as a way for the midlayer to manage access
to its free ccbs.

this allows the midlayer to schedule access to the bus in a roundrobin
fashion for all consumers on the bus, including io from devices and even
the internal mpi management commands used to poll the state of raid
devices. the result is fairer sharing between disks on the bus and more
reliable sensor updates.

ok krw@@ beck@@ marco@@
tested by beck@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.136 2010/04/03 08:00:42 dlg Exp $ */
d957 1
a957 1
	TAILQ_INIT(&sc->sc_ccb_free);
d1028 1
a1028 1
	ccb = TAILQ_FIRST(&sc->sc_ccb_free);
d1030 1
a1030 1
		TAILQ_REMOVE(&sc->sc_ccb_free, ccb, ccb_link);
d1055 1
a1055 1
	TAILQ_INSERT_TAIL(&sc->sc_ccb_free, ccb, ccb_link);
@


1.136
log
@dont allocate with M_TEMP and then free with M_DEVBUF. made even worse that
this was done for every sensor update, which really screwed up the memory
stats.

noticed by deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.135 2010/03/23 01:57:19 krw Exp $ */
d297 1
d990 1
d1005 4
d1045 5
d1228 1
a1228 8
	ccb = mpi_get_ccb(sc);
	if (ccb == NULL) {
		xs->error = XS_NO_CCB;
		s = splbio();
		scsi_done(xs);
		splx(s);
		return;
	}
a1326 1
		mpi_put_ccb(sc, ccb);
a1414 1
	mpi_put_ccb(sc, ccb);
d2506 2
a2507 1
	ccb = mpi_get_ccb(sc);
d2579 1
a2579 1
	mpi_put_ccb(sc, ccb);
d2608 2
a2609 1
	ccb = mpi_get_ccb(sc);
d2690 1
a2690 1
	mpi_put_ccb(sc, ccb);
@


1.135
log
@Change the scsi_cmd function member of scsi_adapter from int to
void. Use XS_NO_CCB error in the scsi command (xs) to report the
NO_CCB condition. Eliminates all SUCCESSFULLY_QUEUED and COMPLETE
confusion and untangles the midlayer from the adapter a bit more.

Eyes and some fixes by miod@@

There may be some compile issues on little used (i.e. I don't have
any) drivers but the change is mechanical and thus easy to remedy.

ok dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.134 2010/01/11 03:51:57 dlg Exp $ */
d2732 1
a2732 1
	rpg0 = malloc(len, M_TEMP, M_WAITOK | M_CANFAIL);
@


1.134
log
@rework the polling code to use the semantic krw@@ proposed.

intercept the ccb_done handling so polled commands set a flag that mpi_poll
tests on. when ccb_done sets the variable, the poll loop breaks and
mpi_poll runs the original ccb_done handler for the ccb completion.

this is a lot simpler than the previous implementation and removes a
mutex.

ok beck@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.133 2010/01/09 23:15:06 krw Exp $ */
d65 1
a65 1
int			mpi_scsi_cmd(struct scsi_xfer *);
d1191 1
a1191 1
int
d1214 1
a1214 1
		return (COMPLETE);
d1218 7
a1224 2
	if (ccb == NULL)
		return (NO_CCB);
d1281 1
a1281 1
		return (COMPLETE);
d1293 1
a1293 1
		return (COMPLETE);
a1296 1
	return (SUCCESSFULLY_QUEUED);
@


1.134.2.1
log
@mfc r1.136. requested by deraadt@@

dont allocate with M_TEMP and then free with M_DEVBUF. made even worse that
this was done for every sensor update, which really screwed up the memory
stats.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.136 2010/04/03 08:00:42 dlg Exp $ */
d2728 1
a2728 1
	rpg0 = malloc(len, M_DEVBUF, M_WAITOK | M_CANFAIL);
@


1.133
log
@Zap all setting of ITSDONE in drivers that don't look at it. Nobody
else cares so it's just noise. Drivers that actually look at ITSDONE
are unchanged.

ok marco@@ (for his files) dlg@@ beck@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.132 2010/01/03 07:47:20 dlg Exp $ */
a94 1
u_int32_t		mpi_pop_reply(struct mpi_softc *);
d99 2
a100 1
struct mpi_ccb		*mpi_reply(struct mpi_softc *, u_int32_t);
d176 1
a176 1
#define mpi_pop_reply_db(s)	mpi_read((s), MPI_REPLY_QUEUE)
a207 2
	mtx_init(&sc->sc_reply_mtx, IPL_BIO);

a822 12
u_int32_t
mpi_pop_reply(struct mpi_softc *sc)
{
	u_int32_t			reg;

	mtx_enter(&sc->sc_reply_mtx);
	reg = mpi_pop_reply_db(sc);
	mtx_leave(&sc->sc_reply_mtx);

	return (reg);
}

a826 1
	struct mpi_ccb			*ccb = NULL;
d828 1
d831 2
a832 2
		ccb = mpi_reply(sc, reg);
		ccb->ccb_done(ccb);
d835 1
a835 1
	return ((ccb == NULL) ? 0 : 1);
d838 1
a838 1
struct mpi_ccb *
d886 1
a886 1
	return (ccb);
d1113 3
a1115 3
	struct mpi_ccb_list		completed =
					    TAILQ_HEAD_INITIALIZER(completed);
	struct mpi_ccb			*nccb = NULL;
a1116 1
	int				rv = 0;
d1121 6
a1126 1
	mtx_enter(&sc->sc_reply_mtx);
d1128 2
a1129 2
	do {
		reg = mpi_pop_reply_db(sc);
a1132 1
				rv = 1;
d1140 2
a1141 1
		nccb = mpi_reply(sc, reg);
d1143 2
a1144 11
		/* 
		 * The ccb used for event notification can come out of the
		 * reply doorbell multiple times. Avoid enqueuing it here for
		 * completion outside the reply mutex since that can screw the
		 * completed TAILQ up. We know it will not cause new ccbs to be
		 * generated and issued, so it is safe to complete here.
		 */
		if (nccb == sc->sc_evt_ccb)
			nccb->ccb_done(nccb);
		else
			TAILQ_INSERT_TAIL(&completed, nccb, ccb_link);
d1146 3
a1148 2
	} while (ccb != nccb);
	mtx_leave(&sc->sc_reply_mtx);
d1150 4
a1153 5
timeout:
	while ((nccb = TAILQ_FIRST(&completed)) != NULL) {
		TAILQ_REMOVE(&completed, nccb, ccb_link);
		nccb->ccb_done(nccb);
	}
d1155 1
a1155 1
	return (rv);
@


1.132
log
@oops, get the order of args right for the header request in
mpi_bio_get_pg0_raid. the sensor updates dont poll at all now.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.131 2010/01/03 07:28:46 dlg Exp $ */
a1229 1
		xs->flags |= ITSDONE;
a1290 1
		xs->flags |= ITSDONE;
a1302 1
			xs->flags |= ITSDONE;
a1334 1
	xs->flags |= ITSDONE;
@


1.131
log
@mpi_bio_get_pg0_raid is only called from a process context. let the cfg
requests sleep rather than poll for completion.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.129 2010/01/03 07:05:43 dlg Exp $ */
d2764 2
a2765 2
	if (mpi_req_cfg_header(sc, MPI_CONFIG_REQ_PAGE_TYPE_RAID_VOL, 0, 0,
	    address, &hdr) != 0)
@


1.130
log
@oops, forgot to set the ccb_cookie in mpi_wait. mpi_wait_done would fault
when it used the uninitialized cookie.
@
text
@d2734 1
a2734 1
	if (mpi_cfg_page(sc, 0, &sc->sc_cfg_hdr, 1, sc->sc_vol_page,
d2764 1
a2764 1
	if (mpi_cfg_header(sc, MPI_CONFIG_REQ_PAGE_TYPE_RAID_VOL, 0,
d2767 1
a2767 1
	if (mpi_cfg_page(sc, address, &hdr, 1, rpg0, len)) {
@


1.129
log
@get rid of the last internal user of splbio. waiting for the completion of
a ccb can now be done with mpi_wait. this switches the cfg page handlers
over from their own tsleep stuff to mpi_wait.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.128 2010/01/03 06:47:58 dlg Exp $ */
d1185 1
@


1.128
log
@rename ccb_xs to ccb_cookie, and switch it from a struct scsi_xfer * to a
void *. this will let me stash things other than scsi xfers in the ccb for
ccb_done handlers to use.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.127 2010/01/03 06:41:22 dlg Exp $ */
d102 3
d1177 32
a2516 1
	int					s;
d2548 1
a2549 1
		ccb->ccb_done = mpi_empty_done;
d2555 2
a2556 8
	} else {
		ccb->ccb_done = (void (*)(struct mpi_ccb *))wakeup;
		s = splbio();
		mpi_start(sc, ccb);
		while (ccb->ccb_state != MPI_CCB_READY)
			tsleep(ccb, PRIBIO, "mpipghdr", 0);
		splx(s);
	}
a2611 1
	int					s;
d2663 1
a2664 1
		ccb->ccb_done = mpi_empty_done;
d2670 2
a2671 8
	} else {
		ccb->ccb_done = (void (*)(struct mpi_ccb *))wakeup;
		s = splbio();
		mpi_start(sc, ccb);
		while (ccb->ccb_state != MPI_CCB_READY)
			tsleep(ccb, PRIBIO, "mpipghdr", 0);
		splx(s);
	}
@


1.127
log
@dont leak a ccb if we fail to get a reply in portenable
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.126 2010/01/03 06:36:50 dlg Exp $ */
d1051 1
a1051 1
	ccb->ccb_xs = NULL;
d1208 1
a1208 1
	ccb->ccb_xs = xs;
d1285 1
a1285 1
	struct scsi_xfer		*xs = ccb->ccb_xs;
d1411 1
a1411 1
	struct scsi_xfer		*xs = ccb->ccb_xs;
@


1.126
log
@when getting a reply from the hw, only sync the dmamem for that one reply
rather than all the replies.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.125 2010/01/03 06:15:30 dlg Exp $ */
d2287 1
d2313 3
a2315 2
		return (1);
	}
a2316 1
	mpi_push_reply(sc, ccb->ccb_rcb);
d2319 1
a2319 1
	return (0);
@


1.125
log
@switch mpi from using splbio to protect itself over to mutexes.

mpi only needs two mutexes, one for the list of free ccbs, and another to
protect the reply doorbell. the latter is necessary to allow polling for
command completion to work in smp systems.

tested on sas and fc hbas. this diff was written over 2 years ago now with
surprisingly few tweaks to handle changes that have occurred since then.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.124 2009/12/10 00:20:38 chl Exp $ */
d95 2
a99 1
u_int32_t		mpi_pop_mtx_reply(struct mpi_softc *);
d173 2
a174 2
#define mpi_pop_reply(s)	mpi_read((s), MPI_REPLY_QUEUE)
#define mpi_push_reply(s, v)	mpi_write((s), MPI_REPLY_QUEUE, (v))
d785 1
a785 1
		mpi_push_reply(sc, ccb->ccb_rcb->rcb_reply_dva);
d823 1
a823 1
mpi_pop_mtx_reply(struct mpi_softc *sc)
d828 1
a828 1
	reg = mpi_pop_reply(sc);
d841 1
a841 1
	while ((reg = mpi_pop_mtx_reply(sc)) != 0xffffffff) {
a861 4
		bus_dmamap_sync(sc->sc_dmat,
		    MPI_DMA_MAP(sc->sc_replies), 0, sc->sc_repq *
		    MPI_REPLY_SIZE, BUS_DMASYNC_POSTREAD);

a862 1

d866 5
a873 4

		bus_dmamap_sync(sc->sc_dmat,
		    MPI_DMA_MAP(sc->sc_replies), 0, sc->sc_repq *
		    MPI_REPLY_SIZE, BUS_DMASYNC_PREREAD);
d1079 8
d1100 1
d1103 1
a1103 1
		mpi_push_reply(sc, rcb->rcb_reply_dva);
d1136 1
a1136 1
		reg = mpi_pop_reply(sc);
d1394 1
a1394 1
	mpi_push_reply(sc, ccb->ccb_rcb->rcb_reply_dva);
d2074 1
a2074 1
	mpi_push_reply(sc, ccb->ccb_rcb->rcb_reply_dva);
d2194 1
a2194 1
	mpi_push_reply(sc, ccb->ccb_rcb->rcb_reply_dva);
d2278 1
a2278 1
	mpi_push_reply(sc, ccb->ccb_rcb->rcb_reply_dva);
d2315 1
a2315 1
	mpi_push_reply(sc, ccb->ccb_rcb->rcb_reply_dva);
d2382 1
a2382 1
	mpi_push_reply(sc, ccb->ccb_rcb->rcb_reply_dva);
d2564 1
a2564 1
	mpi_push_reply(sc, ccb->ccb_rcb->rcb_reply_dva);
d2681 1
a2681 1
	mpi_push_reply(sc, ccb->ccb_rcb->rcb_reply_dva);
@


1.124
log
@remove dead assignment and newly created unused variable.

Found by LLVM/Clang Static Analyzer.

ok dlg@@ marco@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.123 2009/12/09 04:59:41 marco Exp $ */
d30 1
a96 1
int			mpi_complete(struct mpi_softc *, struct mpi_ccb *, int);
d98 2
a99 1
int			mpi_reply(struct mpi_softc *, u_int32_t);
d204 2
d821 12
d837 1
a838 1
	int				rv = 0;
d840 3
a842 3
	while ((reg = mpi_pop_reply(sc)) != 0xffffffff) {
		mpi_reply(sc, reg);
		rv = 1;
d845 1
a845 1
	return (rv);
d848 1
a848 1
int
d900 1
a900 3
	ccb->ccb_done(ccb);

	return (id);
d971 1
d1035 1
d1037 3
a1039 3
	if (ccb == NULL) {
		DNPRINTF(MPI_D_CCB, "%s: mpi_get_ccb == NULL\n", DEVNAME(sc));
		return (NULL);
d1041 1
d1043 1
a1043 5
	TAILQ_REMOVE(&sc->sc_ccb_free, ccb, ccb_link);

	ccb->ccb_state = MPI_CCB_READY;

	DNPRINTF(MPI_D_CCB, "%s: mpi_get_ccb %#x\n", DEVNAME(sc), ccb);
d1051 1
a1051 1
	DNPRINTF(MPI_D_CCB, "%s: mpi_put_ccb %#x\n", DEVNAME(sc), ccb);
d1057 1
d1059 1
d1116 1
a1116 1
mpi_complete(struct mpi_softc *sc, struct mpi_ccb *ccb, int timeout)
d1118 3
d1122 1
a1122 1
	int				id = -1;
d1124 1
a1124 1
	DNPRINTF(MPI_D_INTR, "%s: mpi_complete timeout %d\n", DEVNAME(sc),
d1127 2
d1132 5
a1136 2
			if (timeout-- == 0)
				return (1);
d1142 1
a1142 1
		id = mpi_reply(sc, reg);
d1144 20
a1163 1
	} while (ccb->ccb_id != id);
d1165 1
a1165 17
	return (0);
}

int
mpi_poll(struct mpi_softc *sc, struct mpi_ccb *ccb, int timeout)
{
	int				error;
	int				s;

	DNPRINTF(MPI_D_CMD, "%s: mpi_poll\n", DEVNAME(sc));

	s = splbio();
	mpi_start(sc, ccb);
	error = mpi_complete(sc, ccb, timeout);
	splx(s);

	return (error);
a1194 1
	s = splbio();
a1195 1
	splx(s);
d1251 1
a1252 1
		mpi_put_ccb(sc, ccb);
a1270 1
	s = splbio();
a1271 1
	splx(s);
d1283 1
d1300 1
d1302 1
a1302 1
		mpi_put_ccb(sc, ccb);
d1304 1
d1390 1
d1392 1
d2010 1
a2010 1
	int					s, rv = 1;
a2013 1
	s = splbio();
a2014 1
	splx(s);
a2121 1
	int					s;
a2122 1
	s = splbio();
a2123 1
	splx(s);
d2138 1
a2280 1
	int					s;
a2283 1
	s = splbio();
a2284 1
	splx(s);
a2324 1
	int					s;
a2338 1
	s = splbio();
a2339 1
	splx(s);
a2480 1
	s = splbio();
a2481 1
	splx(s);
a2588 1
	s = splbio();
a2589 1
	splx(s);
@


1.123
log
@Stop spamming dmesg when raid isn't available.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.122 2009/12/01 01:40:02 dlg Exp $ */
a2258 1
	struct mpi_msg_portenable_repy		*pep;
a2288 1
	pep = ccb->ccb_rcb->rcb_reply;
@


1.122
log
@put the midlayer changes back in.

the two issues affecting it last time are gone. the first, mishandling of
TRY_AGAIN_LATER is not relevant now that krw got rid of TRY_AGAIN_LATER.
the second, the misbehaving IBM disk was found to be a problem with siop
using ordered tags on most ops combined with the speed of the new code.

putting this in so we can move forward.

ok krw@@ "commit please" marco@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.120 2009/11/10 10:13:08 dlg Exp $ */
d2729 2
a2730 1
		printf("%s: can't get RAID vol cfg page 0\n", DEVNAME(sc));
@


1.121
log
@revert midlayer back to it was before i put my big rewrite in. this is
causing a weird problems on an alpha and also appears responsible for
isp(4) weirdness i havent had a chance to examine yet.

sigh, this makes me sad.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.119 2009/11/05 03:55:59 marco Exp $ */
a2178 1
#if 0
a2215 1
#endif
@


1.120
log
@backout the backout marco did of my code because of the NO_CCB breakage.
the fix for the NO_CCB breakage will follow shortly.

tested by krw@@ marco@@ johan@@
ok krw@@ marco@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.118 2009/11/05 03:33:52 marco Exp $ */
d2179 1
d2217 1
@


1.119
log
@bump copyrights
@
text
@a2178 1
#if 0
a2215 1
#endif
@


1.118
log
@The big diff dlg committed to the midlayer breaks NO_CCB and
TRY_AGAIN_LATER.  NO_CCB is a timer based mechanism that can trivially
be made to fail by running IO to two or more disks simultaneously.  The
TRY_AGAIN_LATER thing is more subtle because it now is a permanent
failure instead of transient however this is much harder to hit because
something must have gone wrong before it hits.

ok deraadt krw miod
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.117 2009/11/02 23:20:41 marco Exp $ */
d4 2
a5 2
 * Copyright (c) 2005, 2006 David Gwynne <dlg@@openbsd.org>
 * Copyright (c) 2005 Marco Peereboom <marco@@openbsd.org>
@


1.117
log
@Don't write bogus values to reply_fifo_host_signalling_addr.  This register
should remain untouched because it is only for interruptless drivers.

Honor reply queue depth per the spec instead of clipping it at 32.

ok dlg
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.116 2009/10/23 13:30:54 dlg Exp $ */
d2179 1
d2217 1
@


1.116
log
@enable event handling on sas hbas and ignore unhandled events. this turns
on sas hotplug. you can add and remove drives and the kernel will handle it
now.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.115 2009/10/23 01:02:29 dlg Exp $ */
d344 2
a345 2
	bus_dmamap_sync(sc->sc_dmat, MPI_DMA_MAP(sc->sc_replies),
	    0, PAGE_SIZE, BUS_DMASYNC_POSTREAD);
d847 2
a848 2
		    MPI_DMA_MAP(sc->sc_replies), 0, PAGE_SIZE,
		    BUS_DMASYNC_POSTREAD);
d860 2
a861 2
		    MPI_DMA_MAP(sc->sc_replies), 0, PAGE_SIZE,
		    BUS_DMASYNC_PREREAD);
d1053 2
a1054 2
	sc->sc_rcbs = malloc(MPI_REPLY_COUNT * sizeof(struct mpi_rcb),
	    M_DEVBUF, M_WAITOK|M_CANFAIL);
d1058 1
a1058 1
	sc->sc_replies = mpi_dmamem_alloc(sc, PAGE_SIZE);
d1074 2
a1075 2
	bus_dmamap_sync(sc->sc_dmat, MPI_DMA_MAP(sc->sc_replies),
	    0, PAGE_SIZE, BUS_DMASYNC_PREREAD);
d1077 1
a1077 1
	for (i = 0; i < MPI_REPLY_COUNT; i++) {
d1889 2
a1942 3

	hi_addr = (u_int32_t)((u_int64_t)MPI_DMA_DVA(sc->sc_replies) >> 32);
	iiq.reply_fifo_host_signalling_addr = htole32(hi_addr);
@


1.115
log
@if you're attempting to detach multiple devices (eg, many targets,
many luns, or the entire bus), dont report ENXIO as an error to the
caller. this broke autoconf when it tried to forcefully remove a
bus such as umass and it thought there was a failure.

this introduces a way for scsi hbas to call activate/deactivate on
a device based on its target/lun address via a call to scsi_activate().
they can then schedule the actual detach/attach in a thread later via
scsi_req_probe/detach.

the mpi changes tweak the sas event handling code to use these apis
to properly handle attaches and detaches of disks. event handling
is still disabled till i can make it less chatty.

umass breakage reported by form@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.114 2009/10/15 12:38:49 dlg Exp $ */
d255 5
a259 4
#ifdef notyet
	if (mpi_eventnotify(sc) != 0) {
		printf("%s: unable to get portfacts\n", DEVNAME(sc));
		goto free_replies;
a260 1
#endif
d2160 2
a2161 2
		printf("%s: unhandled event 0x%02x\n", DEVNAME(sc),
		    letoh32(enp->event));
@


1.114
log
@disable interrupt coalescing (aka mitigation) if the chip comes up with it
turned on. mitigation on io only slows us down.

developed on hardware donated by fox-it.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.111 2009/08/08 09:35:22 dlg Exp $ */
d143 1
a143 1
void			mpi_evt_sas(void *, void *);
a2126 1
	int					deferred = 0;
d2156 1
a2156 6
		if (scsi_task(mpi_evt_sas, sc, ccb->ccb_rcb, 0) != 0) {
			printf("%s: unable to run SAS device status change\n",
			    DEVNAME(sc));
			break;
		}
		deferred = 1;
d2165 3
a2167 5
	if (!deferred) {
		if (enp->ack_required)
			mpi_eventack(sc, enp);
		mpi_push_reply(sc, ccb->ccb_rcb->rcb_reply_dva);
	}
d2169 2
a2171 1
		/* XXX this shouldnt happen till shutdown */
d2174 1
d2178 1
a2178 1
mpi_evt_sas(void *xsc, void *arg)
a2179 3
	struct mpi_softc			*sc = xsc;
	struct mpi_rcb				*rcb = arg;
	struct mpi_msg_event_reply		*enp = rcb->rcb_reply;
a2181 1
	int					s;
d2193 4
a2196 1
		scsi_probe_target(sc->sc_scsibus, ch->target);
d2200 6
a2205 1
		scsi_detach_target(sc->sc_scsibus, ch->target, DETACH_FORCE);
a2216 6

	s = splbio();
	mpi_push_reply(sc, rcb->rcb_reply_dva);
	if (enp->ack_required)
		mpi_eventack(sc, enp);
	splx(s);
@


1.113
log
@let page requests sleep instead of polling for completion. not used just
yet...
@
text
@d134 1
d250 5
d2051 41
@


1.112
log
@always mark an xs complete if we're about to return COMPLETE to the
midlayer. always call scsi_done on the xs too.
@
text
@d178 4
d183 2
a184 1
	mpi_req_cfg_header((_s), (_t), (_n), (_a), 0, (_h))
d186 2
a187 1
	mpi_req_cfg_header((_s), (_t), (_n), (_a), 1, (_h))
d190 2
a191 1
	mpi_req_cfg_page((_s), (_a), 0, (_h), (_r), (_p), (_l))
d193 2
a194 1
	mpi_req_cfg_page((_s), (_a), 1, (_h), (_r), (_p), (_l))
d2414 1
a2414 1
    u_int32_t address, int extended, void *p)
d2426 2
a2427 2
	    "address: 0x%08x extended: %d\n", DEVNAME(sc), type, number,
	    address, extended);
d2438 1
a2438 1
	if (extended) {
a2442 1
	ccb->ccb_done = mpi_empty_done;
d2457 14
a2470 3
	if (mpi_poll(sc, ccb, 50000) != 0) {
		DNPRINTF(MPI_D_MISC, "%s: mpi_cfg_header poll\n", DEVNAME(sc));
		return (1);
d2498 1
a2498 1
	else if (extended) {
d2515 1
a2515 1
mpi_req_cfg_page(struct mpi_softc *sc, u_int32_t address, int extended,
d2532 1
a2532 1
	page_length = extended ?
a2546 1
	ccb->ccb_done = mpi_empty_done;
d2555 1
a2555 1
	if (extended) {
d2581 14
a2594 3
	if (mpi_poll(sc, ccb, 50000) != 0) {
		DNPRINTF(MPI_D_MISC, "%s: mpi_cfg_page poll\n", DEVNAME(sc));
		return (1);
@


1.111
log
@if the port is fc, populate the adapters scsi_link structure with the wwpn
and wwnn so scsibus can use it.

requested by and ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.109 2009/02/16 21:19:07 miod Exp $ */
d1149 1
d1213 1
d1224 1
a1224 1
		if (mpi_poll(sc, ccb, xs->timeout) != 0)
d1226 5
@


1.110
log
@Bring NO_CCB to mpi.

ok marco@@
@
text
@d107 2
d258 2
a259 1
	if (sc->sc_porttype == MPI_PORTFACTS_PORTTYPE_SCSI) {
d263 4
d772 24
@


1.110.4.1
log
@mfc r1.136. requested by deraadt@@

dont allocate with M_TEMP and then free with M_DEVBUF. made even worse that
this was done for every sensor update, which really screwed up the memory
stats.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.136 2010/04/03 08:00:42 dlg Exp $ */
d2608 1
a2608 1
	rpg0 = malloc(len, M_DEVBUF, M_WAITOK | M_CANFAIL);
@


1.109
log
@Extend the scsi_adapter minphys() callback to take a struct scsi_link *
as additional argument. This will allow intermediate layers between
scsi devices such as sd and scsi host adapters to take appropriate
action if necessary.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.108 2009/02/13 23:16:22 sthen Exp $ */
d1127 3
a1129 7
	if (ccb == NULL) {
		xs->error = XS_DRIVER_STUFFUP;
		s = splbio();
		scsi_done(xs);
		splx(s);
		return (COMPLETE);
	}
@


1.109.2.1
log
@mfc r1.136. requested by deraadt@@

dont allocate with M_TEMP and then free with M_DEVBUF. made even worse that
this was done for every sensor update, which really screwed up the memory
stats.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.136 2010/04/03 08:00:42 dlg Exp $ */
d2612 1
a2612 1
	rpg0 = malloc(len, M_DEVBUF, M_WAITOK | M_CANFAIL);
@


1.108
log
@missing braces; ok marco
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.107 2008/11/23 16:20:06 marco Exp $ */
d66 1
a66 1
void			mpi_minphys(struct buf *bp);
d1434 1
a1434 1
mpi_minphys(struct buf *bp)
@


1.107
log
@enable bio

ok dlg
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.106 2008/11/23 12:45:11 dlg Exp $ */
d2993 1
a2993 1
		if (rpg0->volume_status & MPI_CFG_RAID_VOL_0_STATUS_RESYNCING)
d2996 1
@


1.106
log
@sizeofa is now nitems in param.h, so dont declare my own in mpi.c it was
unused there anyway. use nitems in mpi_pci_match.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.105 2008/11/18 21:52:39 marco Exp $ */
a288 1
#ifdef notyet
a318 1
#endif /* notyet */
@


1.105
log
@Remove dup proto from <alexey.suslikov@@gmail.com>
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.104 2008/11/03 01:42:15 marco Exp $ */
a162 1
#define	sizeofa(s)		(sizeof(s) / sizeof((s)[0]))
@


1.104
log
@Don't attach bio unless we do RAID.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.103 2008/11/01 23:09:29 marco Exp $ */
a155 1
void		mpi_refresh_sensors(void *);
@


1.103
log
@Add sensors
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.102 2008/11/01 21:25:34 marco Exp $ */
d293 3
a295 6
	if (bio_register(&sc->sc_dev, mpi_ioctl) != 0)
		panic("%s: controller registration failed", DEVNAME(sc));
	else {
		if (mpi_cfg_header(sc, MPI_CONFIG_REQ_PAGE_TYPE_IOC, 2, 0,
		    &sc->sc_cfg_hdr) != 0) {
			printf("%s: can't get IOC page 2 hdr, bio disabled\n",
d297 18
a314 1
			goto done;
a315 11
		sc->sc_vol_page = malloc(sc->sc_cfg_hdr.page_length * 4, M_TEMP,
		    M_WAITOK | M_CANFAIL);
		if (sc->sc_vol_page == NULL) {
			printf("%s: can't get memory for IOC page 2, "
			    "bio disabled\n", DEVNAME(sc));
			goto done;
		}
		sc->sc_vol_list = (struct mpi_cfg_raid_vol *)
		    (sc->sc_vol_page + 1);

		sc->sc_ioctl = mpi_ioctl;
d318 1
a318 2
	if (mpi_create_sensors(sc) != 0)
		printf("%s: unable to create sensors\n", DEVNAME(sc));
a2649 3
	if (!(sc->sc_flags & MPI_F_RAID))
		return (EINVAL);

d2698 5
@


1.102
log
@Fix bogus shift.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.101 2008/11/01 18:18:16 marco Exp $ */
d157 1
d2893 51
d2945 56
@


1.101
log
@Add disk.  This makes bio mostly done however to make it pretty we need
to implement RAID_ACTION.  Remains disabled for now.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.100 2008/10/28 11:27:53 marco Exp $ */
d2837 1
a2837 1
	address = physdisk->phys_disk_num << 24;
@


1.100
log
@Pointer sizeof oops
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.99 2008/10/28 11:00:40 marco Exp $ */
d148 1
d2588 52
d2720 1
a2720 2
	int			i, vol, id, len, rv = EINVAL;
	u_int32_t		address;
a2722 1
	struct mpi_cfg_hdr	hdr;;
a2723 1
	struct mpi_cfg_raid_vol_pg0_physdisk *physdisk;
d2725 3
a2727 6
	if (mpi_cfg_page(sc, 0, &sc->sc_cfg_hdr, 1, sc->sc_vol_page,
	    sc->sc_cfg_hdr.page_length * 4) != 0) {
		DNPRINTF(MPI_D_IOCTL, "%s: mpi_get_raid unable to fetch IOC "
		    "page 2\n", DEVNAME(sc));
		return (EINVAL);
	}
a2728 1
	id = bv->bv_volid;
d2732 2
a2733 5
	len = sizeof *rpg0 + sc->sc_vol_page->max_physdisks * sizeof *physdisk;
	rpg0 = malloc(len, M_TEMP, M_WAITOK | M_CANFAIL);
	if (rpg0 == NULL) {
		printf("%s: can't get memory for RAID page 0, "
		    "bio disabled\n", DEVNAME(sc));
a2734 13
	}
	physdisk = (struct mpi_cfg_raid_vol_pg0_physdisk *)(rpg0 + 1);

	/* get raid vol page 0 */
	address = sc->sc_vol_list[id].vol_id |
	    (sc->sc_vol_list[id].vol_bus << 8);
	if (mpi_cfg_header(sc, MPI_CONFIG_REQ_PAGE_TYPE_RAID_VOL, 0,
	    address, &hdr) != 0)
		goto done;
	if (mpi_cfg_page(sc, address, &hdr, 1, rpg0, len)) {
		printf("%s: can't get RAID vol cfg page 0\n", DEVNAME(sc));
		goto done;
	}
d2753 1
a2753 1
	if (rpg0->volume_status == MPI_CFG_RAID_VOL_0_STATUS_RESYNCING)
d2756 1
a2756 1
	bv->bv_size = (u_quad_t)letoh32(rpg0->max_lba);
a2805 1
	free(rpg0, M_DEVBUF);
d2812 68
a2879 1
	return (ENOTTY);
@


1.99
log
@Add beginings of bio.  Disabled for now.

dlg "go go go"
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.98 2008/10/07 12:34:30 dlg Exp $ */
d2686 1
a2686 1
	len = sizeof(rpg0) + sc->sc_vol_page->max_physdisks * sizeof(physdisk);
@


1.98
log
@if fetching a config page for a sas target doesnt work then let the scsi
midlayer try to probe it anyway. this lets raid devices configured on an
mpi to work again.

reported by djm@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.96 2008/09/30 23:40:16 dlg Exp $ */
d20 2
d26 1
d30 2
d38 1
d147 12
d262 2
d289 31
d1462 1
a1462 1
	DPRINTF(MPI_D_MISC, "%s: mpi_scsi_probe sas dev pg 0 for target %d:\n",
d1464 1
a1464 1
	DPRINTF(MPI_D_MISC, "%s:  slot: 0x%04x enc_handle: 0x%04x\n",
d1466 1
a1466 1
	DPRINTF(MPI_D_MISC, "%s:  sas_addr: 0x%016llx\n", DEVNAME(sc),
d1468 1
a1468 1
	DPRINTF(MPI_D_MISC, "%s:  parent_dev_handle: 0x%04x phy_num: 0x%02x "
d1471 1
a1471 1
	DPRINTF(MPI_D_MISC, "%s:  dev_handle: 0x%04x "
d1474 1
a1474 1
	DPRINTF(MPI_D_MISC, "%s:  device_info: 0x%08x\n", DEVNAME(sc),
d1476 1
a1476 1
	DPRINTF(MPI_D_MISC, "%s:  flags: 0x%04x physical_port: 0x%02x\n",
d1481 1
a1481 1
		DPRINTF(MPI_D_MISC, "%s: target %d is an ATAPI device\n",
a1489 6
int
mpi_scsi_ioctl(struct scsi_link *a, u_long b, caddr_t c, int d, struct proc *e)
{
	return (ENOTTY);
}

d2570 230
@


1.97
log
@check all luns on sas boards to see if the device is atapi instead of just
the first one.
@
text
@d1408 2
a1409 4
	if (mpi_ecfg_page(sc, address, &ehdr, 1, &pg0, sizeof(pg0)) != 0) {
		/* the device probably doesnt exist if the page fetch fails */
		return (ENXIO);
	}
@


1.96
log
@provide a scsi probe hook that checks if an atapi device is plugged into
sas mpi variants. this lets the midlayer know it should send the right
sized commands to the device.

this will make the cd drive work on the sun enterprise m4000 and related
machines.

reported by James Hsieh at sun.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.94 2008/09/30 01:50:48 dlg Exp $ */
d1399 1
a1399 1
	if (sc->sc_porttype != MPI_PORTFACTS_PORTTYPE_SAS || link->lun != 0)
@


1.95
log
@add support for handling extended configuration page requests. the sas
pages are all extended, which is annoying.
@
text
@d61 1
d68 1
a68 1
	NULL,
d1389 50
@


1.94
log
@straighten the deck chairs slightly
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.92 2007/12/27 02:29:00 dlg Exp $ */
d135 4
a138 4
int			mpi_cfg_header(struct mpi_softc *, u_int8_t, u_int8_t,
			    u_int32_t, struct mpi_cfg_hdr *);
int			mpi_cfg_page(struct mpi_softc *, u_int32_t,
			    struct mpi_cfg_hdr *, int, void *, size_t);
d157 10
d2277 2
a2278 2
mpi_cfg_header(struct mpi_softc *sc, u_int8_t type, u_int8_t number,
    u_int32_t address, struct mpi_cfg_hdr *hdr)
d2283 3
d2289 3
a2291 2
	DNPRINTF(MPI_D_MISC, "%s: mpi_cfg_header type: %#x number: %x "
	    "address: %d\n", DEVNAME(sc), type, number, address);
d2302 5
d2317 1
d2352 8
a2359 1
	else
d2369 2
a2370 2
mpi_cfg_page(struct mpi_softc *sc, u_int32_t address, struct mpi_cfg_hdr *hdr,
    int read, void *page, size_t len)
d2375 2
d2379 1
d2386 3
d2390 1
a2390 1
	    len < hdr->page_length * 4)
d2410 8
a2417 1
	cq->config_header = *hdr;
d2422 1
a2422 1
	    (hdr->page_length * 4) |
@


1.93
log
@tweak the SPI port configuration if we figure out that it is not quite
right, in particular the adapters scsi id on the bus.

requested by kettenis@@ who is having trouble with the scsi controller on
the primepower 250.
@
text
@d53 3
a55 1
	NULL, "mpi", DV_DULL
d65 5
a69 1
	mpi_scsi_cmd, mpi_minphys, NULL, NULL, mpi_scsi_ioctl
d73 4
a76 1
	NULL, NULL, NULL, NULL
@


1.92
log
@1.90 again. use the right flags when creating a dmamap for use during
interrupts.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.91 2007/12/27 02:27:09 dlg Exp $ */
d84 1
d218 3
a220 1
	if (sc->sc_porttype == MPI_PORTFACTS_PORTTYPE_SCSI)
d222 1
d264 40
d1881 2
a1882 1
	sc->sc_target = letoh16(pfp->port_scsi_id);
@


1.91
log
@oops, there was other code in the previous commit that shouldnt have gone
in. this reverts 1.90.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.89 2007/09/12 13:42:49 dlg Exp $ */
d819 2
a820 1
		    sc->sc_max_sgl_len, MAXPHYS, 0, 0,
@


1.90
log
@use the right flags when creating dmamaps for use in interrupt handlers.
@
text
@a60 1
int			mpi_scsi_dev_probe(struct scsi_link *);
d63 1
a63 7
	mpi_scsi_cmd,
	mpi_minphys,
	NULL,
	NULL,
	mpi_scsi_ioctl,
	mpi_scsi_dev_probe,
	NULL /* mpi_scsi_dev_free */
d819 1
a819 2
		    sc->sc_max_sgl_len, MAXPHYS, 0,
		    BUS_DMA_NOWAIT | BUS_DMA_ALLOCNOW,
a1329 40
}

int
mpi_scsi_dev_probe(struct scsi_link *link)
{
	struct mpi_softc		*sc = link->adapter_softc;
	struct mpi_cfg_hdr		hdr;
	struct mpi_cfg_fc_device_pg0	page;
	u_int32_t			addr;

	if (sc->sc_porttype != MPI_PORTFACTS_PORTTYPE_FC)
		return (0);

	addr = link->target | MPI_PAGE_ADDRESS_FC_BTID;

	if (mpi_cfg_header(sc, MPI_CONFIG_REQ_PAGE_TYPE_FC_DEV, 0, addr,
	    &hdr) != 0) {
		DNPRINTF(MPI_D_MISC, "%s: mpi_get_raid unable to fetch header"
		    "for IOC page 2\n", DEVNAME(sc));
		return (EIO);
	}

#if 0
	if (hdr.page_length * 4 != sizeof(page)) {
		return (EIO);
	}
#endif

	if (mpi_cfg_page(sc, addr, &hdr, 1, &page, sizeof(page)) != 0) {
		DNPRINTF(MPI_D_MISC, "%s: mpi_bio_fc_device: unable to fetch "
		    "config page\n", DEVNAME(sc));
		return (EIO);
	}

	/* DPRINTFs for page */

	link->node_wwn = letoh64(page.wwnn);
	link->port_wwn = letoh64(page.wwpn);

	return (0);
@


1.89
log
@always tag fibre channel commands.

ok marco@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.88 2007/09/11 13:39:33 gilles Exp $ */
d61 1
d64 7
a70 1
	mpi_scsi_cmd, mpi_minphys, NULL, NULL, mpi_scsi_ioctl
d826 2
a827 1
		    sc->sc_max_sgl_len, MAXPHYS, 0, 0,
d1338 40
@


1.88
log
@KNF

prompted and "much better" by marco@@, ok pyr@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.87 2007/09/07 12:11:11 dlg Exp $ */
d1054 2
a1055 1
	if (link->quirks & SDEV_NOTAGS)
@


1.87
log
@take advantage of the new M_ZERO malloc flag.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.86 2007/06/12 19:29:23 thib Exp $ */
d736 1
a736 1
	mdm = malloc(sizeof(struct mpi_dmamem), M_DEVBUF, M_NOWAIT|M_ZERO);
d800 1
a800 1
	    M_DEVBUF, M_WAITOK|M_CANFAIL|M_ZERO);
@


1.86
log
@add M_CANFAIL to malloc() flags, requested by
marco after I showed him a diff to remove the
malloc retun values since they are all called
with M_WAITOK.

ok marco@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.85 2007/05/31 18:21:44 dlg Exp $ */
d736 1
a736 1
	mdm = malloc(sizeof(struct mpi_dmamem), M_DEVBUF, M_NOWAIT);
a739 1
	bzero(mdm, sizeof(struct mpi_dmamem));
d800 1
a800 1
	    M_DEVBUF, M_WAITOK|M_CANFAIL);
a804 1
	bzero(sc->sc_ccbs, sizeof(struct mpi_ccb) * sc->sc_maxcmds);
@


1.85
log
@remove the scsi task thread, and replace it with the system workq.

"just :wq and do it" tedu@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.84 2007/04/03 04:15:50 dlg Exp $ */
d344 1
a344 1
	physdisk_pg = malloc(pagelen, M_TEMP, M_WAITOK);
d801 1
a801 1
	    M_DEVBUF, M_WAITOK);
d895 1
a895 1
	    M_DEVBUF, M_WAITOK);
d2154 1
a2154 1
	vol_page = malloc(pagelen, M_TEMP, M_WAITOK);
@


1.84
log
@modernise scsi_inquiry. the length field has grown and now theres pages to
query.

ok krw@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.83 2007/03/17 10:25:39 dlg Exp $ */
d1910 1
a1910 1
		if (scsi_task(mpi_evt_sas, sc, ccb->ccb_rcb, 1) != 0) {
@


1.83
log
@replace the VMWARE quirk that restricts the bus width to 16 targets with
one for all SPI controllers. krw has a sun machine with a 1030 that gets
the bus width wrong too, so since vmware emulates that type of hardware
too, we can just limit the lot of them and forget about it.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.82 2006/11/28 23:59:45 dlg Exp $ */
d591 1
@


1.82
log
@give scsi controllers a real attach args to fill in when attaching scsibus.

ok miod@@ marco@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.81 2006/11/28 13:22:56 dlg Exp $ */
d1675 1
a1675 1
	if (sc->sc_flags & MPI_F_VMWARE)
@


1.81
log
@unhandled ioctls return ENOTTY, not 0
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.80 2006/11/28 12:54:12 dlg Exp $ */
d150 1
d228 2
d231 1
a231 1
	/* config_found() returns the scsibus we should attach to */
d233 1
a233 1
	    &sc->sc_link, scsiprint);
@


1.80
log
@remove dead code
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.79 2006/11/26 09:30:08 dlg Exp $ */
d1326 1
a1326 1
	return (0);
@


1.79
log
@use scsi_detach_target when a device dissapears, rather than using
config_detach and cleaning the midlayer up ourselves.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.78 2006/11/25 17:18:46 dlg Exp $ */
a83 1
void			mpi_fc_print(struct mpi_softc *);
d227 1
a237 2
	if (sc->sc_porttype == MPI_PORTFACTS_PORTTYPE_FC)
		mpi_fc_print(sc);
a254 71
}

void
mpi_fc_print(struct mpi_softc *sc)
{
	struct mpi_cfg_hdr		hdr;
	struct mpi_cfg_fc_port_pg0	pg;
	struct mpi_cfg_fc_device_pg0	dpg;
	struct device			*dev;
	struct scsibus_softc		*ssc;
	struct scsi_link		*link;
	int				i;
	u_int32_t			btid;

	if (mpi_cfg_header(sc, MPI_CONFIG_REQ_PAGE_TYPE_FC_PORT, 0, 0,
	    &hdr) != 0) {
		DNPRINTF(MPI_D_MISC, "%s: mpi_fc_print unable to fetch "
		    "FC port header 0\n", DEVNAME(sc));
		return;
	}

	if (mpi_cfg_page(sc, 0, &hdr, 1, &pg, sizeof(pg)) != 0) {
		DNPRINTF(MPI_D_MISC, "%s: mpi_fc_print unable to fetch "
		    "FC port page 0\n",
		    DEVNAME(sc));
		return;
	}

	DNPRINTF(MPI_D_MISC, "%s: at: %dGHz WWNN: %016llx WWPN: %016llx\n",
	    DEVNAME(sc), letoh32(pg.current_speed), letoh64(pg.wwnn),
	    letoh64(pg.wwpn));

	TAILQ_FOREACH(dev, &alldevs, dv_list) {
		if (dev->dv_parent == &sc->sc_dev)
			break;
	}

	/* im too nice to punish idiots who don't configure scsibus */
	if (dev == NULL)
		return;

	ssc = (struct scsibus_softc *)dev;
	for (i = 0; i < sc->sc_link.adapter_buswidth; i++) {

		link = ssc->sc_link[i][0];

		if (link == NULL)
			continue;

		btid = i | MPI_PAGE_ADDRESS_FC_BTID;
		if (mpi_cfg_header(sc, MPI_CONFIG_REQ_PAGE_TYPE_FC_DEV, 0,
		    btid, &hdr) != 0) {
			DNPRINTF(MPI_D_MISC, "%s: mpi_fc_print unable to fetch "
			    "device header 0\n", DEVNAME(sc));
			return;
		}

		bzero(&dpg, sizeof(dpg));
		if (mpi_cfg_page(sc, btid, &hdr, 1, &dpg, sizeof(dpg)) != 0) {
			DNPRINTF(MPI_D_MISC, "%s: mpi_fc_print unable to fetch "
			    "device page 0\n", DEVNAME(sc));
			continue;
		}

		link->port_wwn = letoh64(dpg.wwpn);
		link->node_wwn = letoh64(dpg.wwnn);

		DNPRINTF(MPI_D_MISC, "%s: target %d WWNN: %016llx "
		    "WWPN: %016llx\n", DEVNAME(sc), i,
		    letoh64(dpg.wwnn), letoh64(dpg.wwpn));
	}
@


1.78
log
@remove a comment which is now untrue after i fixed it
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.77 2006/10/22 06:59:00 dlg Exp $ */
a2011 1
	struct scsi_link			*link;
a2012 1
	int					i;
d2029 1
a2029 9
		for (i = 0; i < sc->sc_link.luns; i++) {
			link = sc->sc_scsibus->sc_link[ch->target][i];
			if (link == NULL)
				continue;

			config_detach(link->device_softc, 0x0);
			free(link, M_DEVBUF); /* XXX bogus */
			sc->sc_scsibus->sc_link[ch->target][i] = NULL;
		}
@


1.77
log
@oops, the eventnotify stuff was accidentally enabled with the scsiconf
changes. its not ready yet, so disable it again.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.76 2006/10/21 07:36:15 dlg Exp $ */
a2026 1
		/* XXX what an awful interface */
@


1.76
log
@rework the bus scanning code by splitting it out into separate functions
for walking the bus and targets, and probing the luns. this removes the
need to use magic numbers to wildcard each of these, which in turn makes
the code a lot easier to read. as a bonus we get some more space to work in
(80 chars isnt that much somtimes).

note that this code wont probe high luns if lun 0 doesnt exist.

ok krw@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.75 2006/09/22 00:43:18 dlg Exp $ */
d200 1
d205 1
@


1.75
log
@add support for hotplugging devices on sas controllers. this is disabled
for now until we deal more appropriately with events generated by other
variants of mpi controllers.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.74 2006/09/21 10:57:52 dlg Exp $ */
a199 1
#ifdef notyet
a203 1
#endif
d2026 1
a2026 2
		scsi_probe_busses(sc->sc_scsibus->sc_dev.dv_unit,
		    ch->target, -1);
@


1.74
log
@code for acking event notifications that require acks.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.73 2006/09/21 10:52:30 dlg Exp $ */
d124 1
d200 1
a200 1
#if notyet
d1949 1
d1969 29
a1997 2
	if (enp->ack_required)
		mpi_eventack(sc, enp);
a1998 1
	mpi_push_reply(sc, ccb->ccb_rcb->rcb_reply_dva);
d2003 56
@


1.73
log
@deref the right rcb by using i as the index, not 1 all the time.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.72 2006/09/21 10:00:40 dlg Exp $ */
a114 2
int			mpi_eventnotify(struct mpi_softc *);
void			mpi_eventnotify_done(struct mpi_ccb *);
d119 6
d747 1
a747 1
	u_int32_t			reply_dva = 0x0;
d1967 2
a1968 1
	/* XXX ack required? */
d1975 36
@


1.72
log
@start cleaning up the completion path for event notifications.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.71 2006/09/21 09:44:05 dlg Exp $ */
d758 1
a758 1
		rcb = &sc->sc_rcbs[1];
@


1.71
log
@add a debug flag type thing for event handling
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.70 2006/09/21 09:42:27 dlg Exp $ */
a1943 2
	u_int32_t				*data;
	int					i;
d1945 1
a1945 1
	printf("%s: %s\n", DEVNAME(sc), __func__);
d1947 2
a1948 2
	printf("%s:  function: 0x%02x msg_length: %d data_length: %d\n",
	    DEVNAME(sc), enp->function, enp->msg_length,
d1950 3
a1952 5

	printf("%s:  ack_required: %d msg_flags 0x%02x\n", DEVNAME(sc),
	    enp->msg_flags, enp->msg_flags);

	printf("%s:  msg_context: 0x%08x\n", DEVNAME(sc),
d1954 1
a1954 2

	printf("%s:  ioc_status: 0x%04x\n", DEVNAME(sc),
d1956 6
d1963 1
a1963 2
	printf("%s:  ioc_loginfo: 0x%08x\n", DEVNAME(sc),
	    letoh32(enp->ioc_loginfo));
d1965 4
a1968 4
	data = ccb->ccb_rcb->rcb_reply;
	data += dwordsof(struct mpi_msg_event_reply);
	for (i = 0; i < letoh16(enp->data_length); i++) {
		printf("%s:  data[%d]: 0x%08x\n", DEVNAME(sc), i, data[i]);
@


1.70
log
@wrap the hardware replies up in a structure called mpi_rcb which is
similair to the one used for requests. take the reply bits out of the ccb,
but point it at the rcb instead.

this lets us defer processing of the reply some time after we reuse or
free the ccb.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.69 2006/09/21 09:05:28 dlg Exp $ */
d48 1
@


1.69
log
@factor the common code out of mpi_intr and mpi_complete. they were
basically identical apart from the conditions they looped on.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.68 2006/09/18 13:01:26 dlg Exp $ */
d707 2
a708 2
	if (ccb->ccb_reply != NULL)
		mpi_push_reply(sc, ccb->ccb_reply_dva);
d740 1
a742 1
	char				*reply_addr;
d744 1
d755 4
a758 4
		reply_addr = MPI_DMA_KVA(sc->sc_replies);
		reply_addr += reply_dva -
		    (u_int32_t)MPI_DMA_DVA(sc->sc_replies);
		reply = (struct mpi_msg_reply *)reply_addr;
d786 1
a786 2
	ccb->ccb_reply = reply;
	ccb->ccb_reply_dva = reply_dva;
d957 5
d963 2
a964 1
	if (sc->sc_replies == NULL)
d966 1
d974 2
a975 1
	paddr_t				reply;
d981 5
a985 2
	for (i = 0; i < PAGE_SIZE / MPI_REPLY_SIZE; i++) {
		reply = (u_int32_t)MPI_DMA_DVA(sc->sc_replies) +
d987 1
a987 3
		DNPRINTF(MPI_D_MEM, "%s: mpi_push_replies %#x\n", DEVNAME(sc),
		    reply);
		mpi_push_reply(sc, reply);
d1161 1
a1161 1
	struct mpi_msg_scsi_io_error	*sie = ccb->ccb_reply;
d1176 1
a1176 1
	if (sie == NULL) {
d1184 2
d1264 1
a1264 1
	mpi_push_reply(sc, ccb->ccb_reply_dva);
d1870 1
a1870 2
	pfp = ccb->ccb_reply;
	if (pfp == NULL) {
d1875 1
d1902 1
a1902 1
	mpi_push_reply(sc, ccb->ccb_reply_dva);
d1942 1
a1942 1
	struct mpi_msg_event_reply		*enp = ccb->ccb_reply;
d1964 1
a1964 1
	data = ccb->ccb_reply;
d2002 1
a2002 2
	pep = ccb->ccb_reply;
	if (pep == NULL) {
d2007 1
d2009 1
a2009 1
	mpi_push_reply(sc, ccb->ccb_reply_dva);
d2072 1
a2072 2
	upp = ccb->ccb_reply;
	if (upp == NULL)
d2074 1
d2079 1
a2079 1
	mpi_push_reply(sc, ccb->ccb_reply_dva);
d2208 1
a2208 2
	cp = ccb->ccb_reply;
	if (cp == NULL)
d2210 1
d2236 1
a2236 1
	mpi_push_reply(sc, ccb->ccb_reply_dva);
d2302 1
a2302 2
	cp = ccb->ccb_reply;
	if (cp == NULL) {
d2306 1
d2332 1
a2332 1
	mpi_push_reply(sc, ccb->ccb_reply_dva);
@


1.68
log
@macros and types for event notifications from the hardware.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.67 2006/09/18 03:13:25 pedro Exp $ */
d81 1
d725 14
d740 2
a741 2
	struct mpi_msg_reply		*reply;
	u_int32_t			reply_dva;
d743 8
a750 2
	u_int32_t			reg, id;
	int				rv = 0;
d752 1
a752 1
	while ((reg = mpi_pop_reply(sc)) != 0xffffffff) {
d754 4
a757 2
		DNPRINTF(MPI_D_INTR, "%s: mpi_intr reply_queue: 0x%08x\n",
		    DEVNAME(sc), reg);
d759 1
a759 27
		if (reg & MPI_REPLY_QUEUE_ADDRESS) {
			bus_dmamap_sync(sc->sc_dmat,
			    MPI_DMA_MAP(sc->sc_replies), 0, PAGE_SIZE,
			    BUS_DMASYNC_POSTREAD);

			reply_dva = (reg & MPI_REPLY_QUEUE_ADDRESS_MASK) << 1;

			reply_addr = MPI_DMA_KVA(sc->sc_replies);
			reply_addr += reply_dva -
			    (u_int32_t)MPI_DMA_DVA(sc->sc_replies);
			reply = (struct mpi_msg_reply *)reply_addr;

			id = letoh32(reply->msg_context);

			bus_dmamap_sync(sc->sc_dmat,
			    MPI_DMA_MAP(sc->sc_replies), 0, PAGE_SIZE,
			    BUS_DMASYNC_PREREAD);
		} else {
			switch (reg & MPI_REPLY_QUEUE_TYPE_MASK) {
			case MPI_REPLY_QUEUE_TYPE_INIT:
				id = reg & MPI_REPLY_QUEUE_CONTEXT;
				break;

			default:
				panic("%s: unsupported context reply\n",
				    DEVNAME(sc));
			}
d761 12
a772 1
			reply = NULL;
d774 1
d776 2
a777 2
		DNPRINTF(MPI_D_INTR, "%s: mpi_intr id: %d reply: %p\n",
		    DEVNAME(sc), id, reply);
d779 1
a779 1
		ccb = &sc->sc_ccbs[id];
d781 6
a786 6
		bus_dmamap_sync(sc->sc_dmat, MPI_DMA_MAP(sc->sc_requests),
		    ccb->ccb_offset, MPI_REQUEST_SIZE,
		    BUS_DMASYNC_POSTREAD | BUS_DMASYNC_POSTWRITE);
		ccb->ccb_state = MPI_CCB_READY;
		ccb->ccb_reply = reply;
		ccb->ccb_reply_dva = reply_dva;
d788 1
a788 3
		ccb->ccb_done(ccb);
		rv = 1;
	}
d790 1
a790 1
	return (rv);
d997 1
a997 1
mpi_complete(struct mpi_softc *sc, struct mpi_ccb *nccb, int timeout)
d999 2
a1000 5
	struct mpi_ccb			*ccb;
	struct mpi_msg_reply		*reply;
	u_int32_t			reply_dva;
	char				*reply_addr;
	u_int32_t			reg, id = 0xffffffff;
d1015 1
a1015 47
		DNPRINTF(MPI_D_INTR, "%s: mpi_complete reply_queue: 0x%08x\n",
		    DEVNAME(sc), reg);

		if (reg & MPI_REPLY_QUEUE_ADDRESS) {
			bus_dmamap_sync(sc->sc_dmat,
			    MPI_DMA_MAP(sc->sc_replies), 0, PAGE_SIZE,
			    BUS_DMASYNC_POSTREAD);

			reply_dva = (reg & MPI_REPLY_QUEUE_ADDRESS_MASK) << 1;

			reply_addr = MPI_DMA_KVA(sc->sc_replies);
			reply_addr += reply_dva -
			    (u_int32_t)MPI_DMA_DVA(sc->sc_replies);
			reply = (struct mpi_msg_reply *)reply_addr;

			id = letoh32(reply->msg_context);

			bus_dmamap_sync(sc->sc_dmat,
			    MPI_DMA_MAP(sc->sc_replies), 0, PAGE_SIZE,
			    BUS_DMASYNC_PREREAD);
		} else {
			switch (reg & MPI_REPLY_QUEUE_TYPE_MASK) {
			case MPI_REPLY_QUEUE_TYPE_INIT:
				id = reg & MPI_REPLY_QUEUE_CONTEXT;
				break;

			default:
				panic("%s: unsupported context reply\n",
				    DEVNAME(sc));
			}

			reply = NULL;
		}

		DNPRINTF(MPI_D_INTR, "%s: mpi_complete id: %d\n",
		    DEVNAME(sc), id);

		ccb = &sc->sc_ccbs[id];

		bus_dmamap_sync(sc->sc_dmat, MPI_DMA_MAP(sc->sc_requests),
		    ccb->ccb_offset, MPI_REQUEST_SIZE,
		    BUS_DMASYNC_POSTREAD | BUS_DMASYNC_POSTWRITE);
		ccb->ccb_state = MPI_CCB_READY;
		ccb->ccb_reply = reply;
		ccb->ccb_reply_dva = reply_dva;

		ccb->ccb_done(ccb);
d1017 1
a1017 1
	} while (nccb->ccb_id != id);
@


1.67
log
@There's no need to walk the list of devices to find the SCSI bus we
should attach to, since config_found() already returns a pointer to it.
Pointed out by Quentin Garnier, okay dlg@@.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.66 2006/09/16 07:50:46 dlg Exp $ */
d1962 1
a1962 1
	enq->ev_switch = 1;
@


1.66
log
@rework the handling of the errors coming off the hardware at the bottom of
mpi_scsi_cmd_done. this makes it more appropriate for our midlayer.

ok beck@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.65 2006/08/24 14:08:43 dlg Exp $ */
a143 1
	struct device			*dev;
d221 3
a223 8
	config_found(&sc->sc_dev, &sc->sc_link, scsiprint);

	/* find our scsibus */
	TAILQ_FOREACH(dev, &alldevs, dv_list) {
		if (dev->dv_parent == &sc->sc_dev)
			break;
	}
	sc->sc_scsibus = (struct scsibus_softc *)dev;
@


1.65
log
@dont print debug output when the scsi completion path returns with
something other than SCSI_OK. for example, SCSI_SENSE is returned when the
device has sense data. this code was left in to help debug problems in the
field, but noones had any problems with mpi apart from it being too chatty
when a device returns sense data...
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.64 2006/08/03 08:48:44 dlg Exp $ */
a1249 4
	case MPI_IOCSTATUS_SCSI_DATA_OVERRUN:
		xs->error = XS_DRIVER_STUFFUP;
		break;

a1250 7
		/*
		 * Yikes!  Tagged queue full comes through this path!
		 *
		 * So we'll change it to a status error and anything
		 * that returns status should probably be a status
		 * error as well.
		 */
d1269 1
a1272 4
		case SCSI_QUEUE_FULL:
			xs->error = XS_TIMEOUT;
			xs->retries++;
			break;
a1273 2
			printf("%s: invalid status code %d\n",
			    DEVNAME(sc), xs->status);
a1289 23
	case MPI_IOCSTATUS_SCSI_RESIDUAL_MISMATCH:
		xs->error = XS_DRIVER_STUFFUP;
		break;

	case MPI_IOCSTATUS_SCSI_TASK_TERMINATED:
		xs->error = XS_DRIVER_STUFFUP;
		break;

	case MPI_IOCSTATUS_SCSI_TASK_MGMT_FAILED:
		/* XXX */
		xs->error = XS_DRIVER_STUFFUP;
		break;

	case MPI_IOCSTATUS_SCSI_IOC_TERMINATED:
		/* XXX */
		xs->error = XS_DRIVER_STUFFUP;
		break;

	case MPI_IOCSTATUS_SCSI_EXT_TERMINATED:
		/* XXX This is a bus-reset */
		xs->error = XS_DRIVER_STUFFUP;
		break;

a1290 1
		/* XXX unrecognized HBA error */
a1296 5
	else if (sie->scsi_state & MPI_SCSIIO_ERR_STATE_AUTOSENSE_FAILED) {
		/* This will cause the scsi layer to issue a REQUEST SENSE */
		if (xs->status == SCSI_CHECK)
			xs->error = XS_BUSY;
	}
@


1.64
log
@always call scsi_done at splbio. issue found by pedro@@
while here protect submission of the scsi command with splbio as well.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.63 2006/07/15 04:09:57 dlg Exp $ */
d1223 25
d1343 2
a1344 28
	if (xs->error != XS_NOERROR && !cold) {
		printf("%s:  xs cmd: 0x%02x len: %d error: 0x%02x "
		    "flags 0x%x\n", DEVNAME(sc), xs->cmd->opcode, xs->datalen,
		    xs->error, xs->flags);
		printf("%s:  target_id: %d bus: %d msg_length: %d "
		    "function: 0x%02x\n", DEVNAME(sc), sie->target_id,
		    sie->bus, sie->msg_length, sie->function);
		printf("%s:  cdb_length: %d sense_buf_length: %d "
		    "msg_flags: 0x%02x\n", DEVNAME(sc), sie->cdb_length,
		    sie->bus, sie->msg_flags);
		printf("%s:  msg_context: 0x%08x\n", DEVNAME(sc),
		    letoh32(sie->msg_context));
		printf("%s:  scsi_status: 0x%02x scsi_state: 0x%02x "
		    "ioc_status: 0x%04x\n", DEVNAME(sc), sie->scsi_status,
		    sie->scsi_state, letoh16(sie->ioc_status));
		printf("%s:  ioc_loginfo: 0x%08x\n", DEVNAME(sc),
		    letoh32(sie->ioc_loginfo));
		printf("%s:  transfer_count: %d\n", DEVNAME(sc),
		    letoh32(sie->transfer_count));
		printf("%s:  sense_count: %d\n", DEVNAME(sc),
		    letoh32(sie->sense_count));
		printf("%s:  response_info: 0x%08x\n", DEVNAME(sc),
		    letoh32(sie->response_info));
		printf("%s:  tag: 0x%04x\n", DEVNAME(sc),
		    letoh16(sie->tag));
		printf("%s:  xs error: 0x%02x xs status: %d\n", DEVNAME(sc),
		    xs->error, xs->status);
	}
@


1.63
log
@set the tags on the scsi command according to what the midlayer says they
should be.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.62 2006/07/15 03:59:50 dlg Exp $ */
d1106 1
d1108 1
d1117 1
d1119 1
d1171 1
d1174 1
a1175 2
		xs->error = XS_DRIVER_STUFFUP;
		scsi_done(xs);
d1187 1
d1189 1
a2017 1

@


1.62
log
@have a go at configuring spi variants to only talk to the devices at the
lowest possible speeds during inquiry and attach. some devices, like tapes
and enclosures, dont like being probed at high speeds and can attach as
weird things. this seems to help those devices.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.61 2006/07/09 14:10:57 dlg Exp $ */
d1153 5
@


1.61
log
@spacing
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.60 2006/07/09 13:45:36 dlg Exp $ */
d83 1
d211 3
d330 34
d387 1
a387 1
	for (i = 0; i < sc->sc_link.adapter_buswidth; i++) {
@


1.60
log
@enabling interrupts doesnt deserve an XXX. i think we want to do that.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.59 2006/07/09 13:35:10 dlg Exp $ */
d133 1
a133 1
#define mpi_push_reply(s, v)	mpi_write((s), MPI_REPLY_QUEUE, (v)) 
d402 2
a403 2
 
                tries = 0;
d666 1
a666 1
	addr = ccb->ccb_cmd_dva + 
a1723 1

a1727 1

a1729 1

a1732 1

a1734 1

a1737 1

a1740 1

a1742 1

a1744 1

a1748 1

a1750 1

a1753 1

a1755 1

a1757 1

a1761 1

a1763 1

d1785 1
a1785 1
	sc->sc_first_sgl_len = ((letoh16(ifp.request_frame_size) * 4) - 
a1857 1

a1860 1

a1862 1

a1864 1

a1912 1

a1914 1

a1916 1

a1918 1

a1920 1

a1922 1

a1925 1

a1929 1

d2261 3
a2263 3
	    cp->config_header.page_version, 
	    cp->config_header.page_length, 
	    cp->config_header.page_number, 
d2357 3
a2359 3
	    cp->config_header.page_version, 
	    cp->config_header.page_length, 
	    cp->config_header.page_number, 
@


1.59
log
@implement firmware upload. this frees up memory on some controllers so they
can do more io at a time. tested on the onboard controllers of a dell 2850
(which can do it) and a pci controller on my home box (which doesnt). this
was the last feature mpt had that mpi was behind on.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.58 2006/07/06 09:59:42 dlg Exp $ */
d236 1
a236 1
	/* XXX enable interrupts */
@


1.58
log
@fix debugging stuff
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.57 2006/07/06 09:21:59 dlg Exp $ */
d116 1
d205 5
d1794 2
d2076 74
@


1.57
log
@after walking the attached devices and running ppr against them, then fetch
the ioc page 3 for a list of all the physical disks behind any configured
volumes and run ppr against them too.

raid volumes on scsi mpi is fast now.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.56 2006/07/06 09:04:45 dlg Exp $ */
d2111 1
a2111 1
	    vol_page->active_physdisks, vol->max_physdisks);
@


1.56
log
@do not stash pages 2 and 3 (the volume and physdisk pages respectively)
of the ioc config in the softc. instead, we only walk page 2 when we get
the raid config and mark each disks scsi_link structure with the
SDEV_LOGICAL flag when we find volumes. while there we mark this instance
of the driver as being capable of doing raid so later on we can
conditionally hook up bio.

when we walk the devices attached to mpi to do ppr, we now skip the logical
disks.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.55 2006/07/06 00:55:03 dlg Exp $ */
d85 1
a85 1
			    int, int, int);
d323 4
a326 1
	struct mpi_cfg_spi_port_pg0	pg;
d337 1
a337 1
	if (mpi_cfg_page(sc, 0x0, &hdr, 1, &pg, sizeof(pg)) != 0) {
d353 2
a354 2
		while (mpi_ppr(sc, link, pg.min_period, pg.max_offset,
		    tries) == EAGAIN)
d357 48
d408 2
a409 2
mpi_ppr(struct mpi_softc *sc, struct scsi_link *link, int period, int offset,
    int try)
d415 2
d425 12
a436 4
	if ((link->inqdata.device & SID_TYPE) == T_PROCESSOR)
		return (EIO);

	address = link->target;
d481 1
a481 1
	if (!(link->quirks & SDEV_NOSYNC)) {
d529 1
a529 1
	if (mpi_inq(sc, link->target, 0) != 0) {
d585 3
a587 3
	printf("%s: target %d %s at %dMHz width %dbit offset %d "
	    "QAS %d DT %d IU %d\n", DEVNAME(sc), link->target,
	    period ? "Sync" : "Async", period,
@


1.55
log
@stash a pointer to the scsibus attached to us so we dont have to walk the
device tree all the time.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.54 2006/07/05 23:50:49 dlg Exp $ */
d325 1
a325 1
	int				i, r, tries;
d345 4
a348 1
		/* is this a RAID device? */
a349 8
		for (r = 0; r < sc->sc_ioc_pg2->max_vols; r++)
			if (i == sc->sc_ioc_pg2->raid_vol[r].vol_id) {
				DNPRINTF(MPI_D_PPR, "%s: mpi_run_ppr scsibus "
				    "%d ioc %d target %d RAID\n", DEVNAME(sc),
				    sc->sc_link.scsibus, sc->sc_ioc_number, i);
				/* XXX fan out ppr */
			}

d2013 5
a2017 1
	struct mpi_cfg_raid_vol		*raidvol;
d2023 1
a2023 1
		DNPRINTF(MPI_D_PPR, "%s: mpi_get_raid unable to fetch header"
d2028 10
a2037 4
	/* make page length bytes instead of dwords */
	sc->sc_ioc_pg2 = malloc(hdr.page_length * 4, M_DEVBUF, M_WAITOK);
	if (mpi_cfg_page(sc, 0, &hdr, 1, sc->sc_ioc_pg2,
	    hdr.page_length * 4) != 0) {
d2040 1
a2040 1
		return;
d2043 8
a2050 7
	DNPRINTF(MPI_D_RAID, "%s:  capabilities: %x active vols %d "
	    "max vols: %d\n", DEVNAME(sc),
	    letoh32(sc->sc_ioc_pg2->capabilities),
	    sc->sc_ioc_pg2->no_active_vols, sc->sc_ioc_pg2->max_vols);
	DNPRINTF(MPI_D_RAID, "%s:  active phys disks: %d max disks: %d\n",
	    DEVNAME(sc), sc->sc_ioc_pg2->no_active_phys_disks,
	    sc->sc_ioc_pg2->max_phys_disks);
d2053 13
a2065 2
	if (letoh32(sc->sc_ioc_pg2->capabilities) == 0xdeadbeef)
		return;
d2067 5
a2071 6
	for (i = 0; i < sc->sc_ioc_pg2->max_vols; i++) {
		raidvol = &sc->sc_ioc_pg2->raid_vol[i];
		DNPRINTF(MPI_D_RAID, "%s:   id: %#02x bus: %d ioc: %d page: %d "
		    "type: %#02x flags: %#02x\n", DEVNAME(sc), raidvol->vol_id,
		    raidvol->vol_bus, raidvol->vol_ioc, raidvol->vol_page,
		    raidvol->vol_type, raidvol->flags);
d2073 2
a2074 1
	}
d2076 3
a2078 6
	/* reuse hdr */
	if (mpi_cfg_header(sc, MPI_CONFIG_REQ_PAGE_TYPE_IOC, 3, 0, &hdr) != 0) {
		DNPRINTF(MPI_D_PPR, "%s: mpi_get_raid unable to fetch header"
		    "for IOC page 3\n", DEVNAME(sc));
		return;
	}
d2080 1
a2080 7
	/* make page length bytes instead of dwords */
	sc->sc_ioc_pg3 = malloc(hdr.page_length * 4, M_DEVBUF, M_WAITOK);
	if (mpi_cfg_page(sc, 0, &hdr, 1, sc->sc_ioc_pg3,
	    hdr.page_length * 4) != 0) {
		DNPRINTF(MPI_D_RAID, "%s: mpi_get_raid unable to fetch IOC "
		    "page 3\n", DEVNAME(sc));
		return;
d2083 2
a2084 8
	for (i = 0; i < sc->sc_ioc_pg3->no_phys_disks; i++) {
		DNPRINTF(MPI_D_RAID, "%s:    id: %#02x bus: %d ioc: %d "
		    "num: %#02x\n", DEVNAME(sc),
		    sc->sc_ioc_pg3->phys_disks[i].phys_disk_id,
		    sc->sc_ioc_pg3->phys_disks[i].phys_disk_bus,
		    sc->sc_ioc_pg3->phys_disks[i].phys_disk_ioc,
		    sc->sc_ioc_pg3->phys_disks[i].phys_disk_num);
	}
@


1.54
log
@check if the requests for the config pages were completed successful,
rather than just completed.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.53 2006/06/30 17:42:28 kettenis Exp $ */
d142 1
d214 7
a323 3

	struct device			*dev;
	struct scsibus_softc		*ssc;
a339 10
	TAILQ_FOREACH(dev, &alldevs, dv_list) {
		if (dev->dv_parent == &sc->sc_dev)
			break;
	}

	/* im too nice to punish idiots who don't configure scsibus */
	if (dev == NULL)
		return;

	ssc = (struct scsibus_softc *)dev;
d341 1
a341 3
		link = ssc->sc_link[i][0];
		tries = 0;

a344 1

d346 1
@


1.53
log
@Unbreak the tree; cast the result of sizeof() to u_int32_t before passing it
to htole32().
"go for it" miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.52 2006/06/30 12:32:53 dlg Exp $ */
d2099 1
a2138 1

a2142 1

a2144 1

a2146 1

a2148 1

d2156 4
a2159 1
	*hdr = cp->config_header;
d2164 1
a2164 1
	return (0);
d2176 1
a2234 1

a2238 1

a2240 1

a2242 1

a2244 1

d2252 3
a2254 1
	if (read)
d2260 1
a2260 1
	return (0);
@


1.52
log
@tabs, not spaces
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.51 2006/06/30 08:29:42 dlg Exp $ */
d609 1
a609 1
	    sizeof(inq));
@


1.51
log
@add mpi_inq. this is a custom io function that does an inquiry against
either a normal target, or against a physical disk using the raid passthru
command. it is necessary since the normal io path can only be used by the
midlayer, and only against normal targets. this will be used for ppr
against the disks in raid volumes on scsi controllers.

tested by marco@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.50 2006/06/29 10:43:21 dlg Exp $ */
d565 2
a566 2
        bzero(&inq, sizeof(inq));
        inq.opcode = INQUIRY;
@


1.50
log
@split some fields up in the spi port and dev config pages. makes the ppr
code easier since we dont have to byteswap and shift stuff around so much.
no functional change though.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.49 2006/06/29 08:35:08 dlg Exp $ */
d86 1
a374 1
	struct scsi_inquiry_data	inqbuf;
d480 1
a480 1
	if (scsi_inquire(link, &inqbuf, SCSI_POLL) != 0) {
d544 79
@


1.49
log
@theres a ton of 32bit fields in mpi messages that have subfields that lie
on byte boundaries. so rather than byteswappping and bitshifting the
values in these subfields around we can break them up into byte fields and
access them directly.

this breaks up the control field in the scsi io command.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.48 2006/06/19 21:06:22 miod Exp $ */
a314 1
	int				period, offset;
a333 5
	period = MPI_CFG_SPI_PORT_0_CAPABILITIES_MIN_PERIOD(
	    letoh32(pg.capabilities));
	offset = MPI_CFG_SPI_PORT_0_CAPABILITIES_MAX_OFFSET(
	    letoh32(pg.capabilities));

d361 2
a362 1
		while (mpi_ppr(sc, link, period, offset, tries) == EAGAIN)
a375 1
	u_int32_t			params;
d377 3
a379 2
	DNPRINTF(MPI_D_PPR, "%s: mpi_ppr sc: %p link: %p period: %d "
	    "offset: %d try: %d\n", DEVNAME(sc), sc, link, period, offset, try);
d403 1
d410 5
a414 2
	DNPRINTF(MPI_D_PPR, "%s: mpi_ppr neg_params: 0x%08x info: 0x%08x\n",
	    DEVNAME(sc), letoh32(pg0.neg_params), letoh32(pg0.information));
d422 9
a430 11
	DNPRINTF(MPI_D_PPR, "%s: mpi_ppr pg 1 req_params: 0x%08x conf: "
	    "0x%08x\n", DEVNAME(sc), letoh32(pg1.req_params),
	    letoh32(pg1.configuration));

	params = letoh32(pg1.req_params);
	params &= ~(MPI_CFG_SPI_DEV_1_REQPARAMS_WIDTH |
	    MPI_CFG_SPI_DEV_1_REQPARAMS_XFER_PERIOD_MASK |
	    MPI_CFG_SPI_DEV_1_REQPARAMS_XFER_OFFSET_MASK |
	    MPI_CFG_SPI_DEV_1_REQPARAMS_DUALXFERS |
	    MPI_CFG_SPI_DEV_1_REQPARAMS_QAS |
	    MPI_CFG_SPI_DEV_1_REQPARAMS_PACKETIZED);
d433 1
a433 1
		params |= MPI_CFG_SPI_DEV_1_REQPARAMS_WIDTH_WIDE;
d439 1
a439 1
			period = 0x09;
d442 1
a442 1
			period = 0x0a;
d446 1
a446 1
		if (period < 0x09) {
d448 1
a448 1
			params |= MPI_CFG_SPI_DEV_1_REQPARAMS_QAS |
d451 1
a451 1
		if (period < 0xa) {
d453 2
a454 1
			params |= MPI_CFG_SPI_DEV_1_REQPARAMS_DUALXFERS;
a455 3
		pg1.req_params = htole32(params |
		    MPI_CFG_SPI_DEV_1_REQPARAMS_XFER_PERIOD(period) |
		    MPI_CFG_SPI_DEV_1_REQPARAMS_XFER_OFFSET(offset));
d458 4
a461 4
	DNPRINTF(MPI_D_PPR, "%s: mpi_ppr pg 1 req_params: 0x%08x conf: "
	    "0x%08x period: %0x address: %d\n", DEVNAME(sc),
	    letoh32(pg1.req_params), letoh32(pg1.configuration), period,
	    address);
d475 4
a478 3
	DNPRINTF(MPI_D_PPR, "%s: mpi_ppr pg 1 readback req_params: 0x%08x "
	    "conf: 0x%08x\n", DEVNAME(sc), letoh32(pg1.req_params),
	    letoh32(pg1.configuration));
d492 4
a495 4
	DNPRINTF(MPI_D_PPR, "%s: mpi_ppr neg_params: 0x%08x info: 0x%08x "
	    "try: %d\n",
	    DEVNAME(sc), letoh32(pg0.neg_params), letoh32(pg0.information),
	    try);
d515 1
a515 4
	params = letoh32(pg0.neg_params);
	DNPRINTF(MPI_D_PPR, "%s: mpi_ppr params %08x\n", DEVNAME(sc), params);

	switch(MPI_CFG_SPI_DEV_0_NEGPARAMS_XFER_PERIOD(params)) {
d539 5
a543 5
	    (params & MPI_CFG_SPI_DEV_0_NEGPARAMS_WIDTH_WIDE) ? 16 : 8,
	    MPI_CFG_SPI_DEV_0_NEGPARAMS_XFER_OFFSET(params),
	    (params & MPI_CFG_SPI_DEV_0_NEGPARAMS_QAS) ? 1 : 0,
	    (params & MPI_CFG_SPI_DEV_0_NEGPARAMS_DUALXFERS) ? 1 : 0,
	    (params & MPI_CFG_SPI_DEV_0_NEGPARAMS_PACKETIZED) ? 1 : 0);
@


1.48
log
@Everytime one forgets an argument in a printf-like function call, God kills
a kitten. Commiters, please think of the kittens when working on code.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.47 2006/06/18 22:31:06 marco Exp $ */
d979 1
a979 1
		io->control = htole32(MPI_SCSIIO_DATA_DIR_READ);
d982 1
a982 1
		io->control = htole32(MPI_SCSIIO_DATA_DIR_WRITE);
d985 1
a985 1
		io->control = htole32(MPI_SCSIIO_DATA_DIR_NONE);
@


1.47
log
@Make mpi not spit out WWNN and WWPN as requested by deraadt and dlg.  Do
store these values in the scsi_link structure for each device.

ok dlg.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.46 2006/06/18 00:10:24 marco Exp $ */
d1087 2
a1088 1
			printf("%s: invalid status code %d\n", xs->status);
@


1.46
log
@Don't walk memory whenever there is nothing there.  I ran into this while
debugging FC stuff.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.45 2006/06/18 00:08:00 marco Exp $ */
d253 2
a254 2
		DNPRINTF(MPI_D_PPR, "%s: mpi_fc_print unable to fetch header\n",
		    DEVNAME(sc));
d259 2
a260 1
		DNPRINTF(MPI_D_PPR, "%s: mpi_fc_print unable to fetch page\n",
d265 3
a267 2
	printf("%s: at: %dGHz WWNN: %016llx WWPN: %016llx\n", DEVNAME(sc),
	    letoh32(pg.current_speed), letoh64(pg.wwnn), letoh64(pg.wwpn));
d289 1
a289 1
			DNPRINTF(MPI_D_PPR, "%s: mpi_fc_print unable to fetch "
d296 1
a296 1
			DNPRINTF(MPI_D_PPR, "%s: mpi_fc_print unable to fetch "
d301 6
a306 3
		printf("%s: target %d WWNN: %016llx WWPN: %016llx\n",
		    DEVNAME(sc), i, letoh64(dpg.wwnn),
		    letoh64(dpg.wwpn));
@


1.45
log
@Print World Wide Node Name and World Wide Port Name during dmesg so that
we can actually find the drives on the fabric.  Requested by kettenis krw
and brad.

ok dlg
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.44 2006/06/16 05:36:46 dlg Exp $ */
d1974 4
@


1.44
log
@vmware emulates mpi, but it does a half arsed job of it. half the fields
we read off the hardware and use to configure the driver with are set to
zero, so things dont really work like we want them to.

one of these fields is the pci subsystem id which is something we can fetch
really early in the attach process. so if the subsys is 0 then we go on and
fix up some of the values we get off the "hardware". now we can attach
disks on vmware.

"sneaky" and ok marco@@ tested by and ok brad@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.43 2006/06/15 07:35:44 marco Exp $ */
d47 1
a47 1
		    | MPI_D_RAID
d82 1
d218 2
d240 66
a365 1

@


1.43
log
@Add detection of RAID volume during PPR.  Doesn't fan out the ppr to individual
devices yet.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.42 2006/06/15 06:45:53 marco Exp $ */
a1585 1
	sc->sc_buswidth = (ifp.max_devices == 0) ? 256 : ifp.max_devices;
d1588 5
@


1.42
log
@Add IOC page 3 support.  Needed for RAID and bio.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.41 2006/06/15 05:22:08 marco Exp $ */
d246 1
a246 1
	int				i, tries;
d283 10
d1588 1
@


1.41
log
@Print volume details in debug.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.40 2006/06/15 04:59:21 marco Exp $ */
d1884 6
a1889 5
	DNPRINTF(MPI_D_RAID, "%s:  capabilities: %x active vols %d max vols: %d"
	    " active phys disks: %d max disks: %d\n",
	    DEVNAME(sc), letoh32(sc->sc_ioc_pg2->capabilities),
	    sc->sc_ioc_pg2->no_active_vols, sc->sc_ioc_pg2->max_vols,
	    sc->sc_ioc_pg2->no_active_phys_disks,
d1894 1
a1894 1
		DNPRINTF(MPI_D_RAID, "%s:  id: %#02x bus: %d ioc: %d page: %d "
d1899 25
@


1.40
log
@And now without a buffer overflow.  Pointed out by dlg.  No cookie for me.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.39 2006/06/15 04:44:59 marco Exp $ */
d1864 2
d1890 9
@


1.39
log
@Add structures and initial code to retrieve IOC page 2.  We need this for
RAID support and bio.  "go at it" dlg
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.38 2006/06/15 02:56:51 marco Exp $ */
a1863 1
	struct mpi_cfg_ioc_pg2		pg;
d1874 3
a1876 1
	if (mpi_cfg_page(sc, 0, &hdr, 1, &pg, hdr.page_length * 4) != 0) {
d1884 4
a1887 2
	    DEVNAME(sc), letoh32(pg.capabilities), pg.no_active_vols,
	    pg.max_vols, pg.no_active_phys_disks, pg.max_phys_disks);
@


1.38
log
@Print some useful error information during failure.  We need this to be able
to diagnose field issues.  Talked through with dlg.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.37 2006/06/13 02:07:19 dlg Exp $ */
d41 1
a41 1
		    | MPI_D_DMA
d47 1
d113 1
d211 3
d1858 27
@


1.37
log
@we sometimes bundle chunks that the ioc will write to in the request space
as well as the request itself, so we need to sync the memory in both
directions for dma.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.36 2006/06/12 23:25:57 dlg Exp $ */
d40 2
a41 2
		    | MPI_D_MISC
/*		    | MPI_D_DMA */
d46 1
a46 1
		    | MPI_D_PPR
a949 3
	DNPRINTF(MPI_D_CMD, "%s:  xs cmd: 0x%02x len: %d error: 0x%02x "
	    "flags 0x%x\n", DEVNAME(sc), xs->cmd->opcode, xs->datalen,
	    xs->error, xs->flags);
a958 30
	DNPRINTF(MPI_D_CMD, "%s:  target_id: %d bus: %d msg_length: %d "
	    "function: 0x%02x\n", DEVNAME(sc), sie->target_id,
	    sie->bus, sie->msg_length, sie->function);

	DNPRINTF(MPI_D_CMD, "%s:  cdb_length: %d sense_buf_length: %d "
	    "msg_flags: 0x%02x\n", DEVNAME(sc), sie->cdb_length,
	    sie->bus, sie->msg_flags);

	DNPRINTF(MPI_D_CMD, "%s:  msg_context: 0x%08x\n", DEVNAME(sc),
	    letoh32(sie->msg_context));

	DNPRINTF(MPI_D_CMD, "%s:  scsi_status: 0x%02x scsi_state: 0x%02x "
	    "ioc_status: 0x%04x\n", DEVNAME(sc), sie->scsi_status,
	    sie->scsi_state, letoh16(sie->ioc_status));

	DNPRINTF(MPI_D_CMD, "%s:  ioc_loginfo: 0x%08x\n", DEVNAME(sc),
	    letoh32(sie->ioc_loginfo));

	DNPRINTF(MPI_D_CMD, "%s:  transfer_count: %d\n", DEVNAME(sc),
	    letoh32(sie->transfer_count));

	DNPRINTF(MPI_D_CMD, "%s:  sense_count: %d\n", DEVNAME(sc),
	    letoh32(sie->sense_count));

	DNPRINTF(MPI_D_CMD, "%s:  response_info: 0x%08x\n", DEVNAME(sc),
	    letoh32(sie->response_info));

	DNPRINTF(MPI_D_CMD, "%s:  tag: 0x%04x\n", DEVNAME(sc),
	    letoh16(sie->tag));

d1053 29
a1081 2
	DNPRINTF(MPI_D_CMD, "%s:  xs error: 0x%02x len: %d\n", DEVNAME(sc),
	    xs->error, xs->status);
@


1.36
log
@i stashed the dva and kva of each request space in its ccb, so why am i
recalculating them whenever i want to use them? shorten code a bit by using
the stored values.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.35 2006/06/12 14:06:05 dlg Exp $ */
d526 2
a527 1
		    ccb->ccb_offset, MPI_REQUEST_SIZE, BUS_DMASYNC_POSTWRITE);
d735 2
a736 1
	    ccb->ccb_offset, MPI_REQUEST_SIZE, BUS_DMASYNC_PREWRITE);
d804 2
a805 1
		    ccb->ccb_offset, MPI_REQUEST_SIZE, BUS_DMASYNC_POSTWRITE);
@


1.35
log
@fix sgl loading. there were a few issues, the main ones being:
- when the sgl grew too large it became bigger than the maximum frame size
that the ioc would deal with, and then it would just stop doing io. i was
using the wrong field from iocfacts to figure out how large an sgl should
be.
- chained sgls were broken cos i was including the current chain element in
the calculation of the offset to the next chain element.

big ok from marco@@
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.34 2006/06/12 12:31:58 dlg Exp $ */
d1157 2
a1158 2
			ce_dva = MPI_DMA_DVA(sc->sc_requests) + ccb->ccb_offset;
			ce_dva += (u_int8_t *)nsge - (u_int8_t *)mcb;
d1978 2
a1979 2
	dva = MPI_DMA_DVA(sc->sc_requests) + ccb->ccb_offset +
	    sizeof(struct mpi_msg_config_request);
d1983 2
a1984 2
	kva = MPI_DMA_KVA(sc->sc_requests);
	kva += ccb->ccb_offset + sizeof(struct mpi_msg_config_request);
@


1.34
log
@reset the reply pointer to NULL every time we get a context reply in
mpi_interrupt and mpi_completion. if we got an address reply followed by a
context reply we used to pass that same reply to both completion routines.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.33 2006/06/12 03:55:39 dlg Exp $ */
d520 2
a521 1
		DNPRINTF(MPI_D_INTR, "%s: mpi_intr id: %d\n", DEVNAME(sc), id);
d1143 3
a1145 3
			if ((dmap->dm_nsegs - i) > sc->sc_maxchdepth) {
				nce = &nsge[sc->sc_maxchdepth - 1];
				addr = ((u_int8_t *)nce - (u_int8_t *)ce) / 4;
d1147 1
a1147 1
				    sizeof(struct mpi_sge) * sc->sc_maxchdepth;
d1586 5
d1595 5
a1599 3
	    sc->sc_maxchdepth;
	DNPRINTF(MPI_D_MISC, "%s:   max sgl len: %d\n",
	    DEVNAME(sc), sc->sc_max_sgl_len);
@


1.33
log
@white space fixes
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.32 2006/06/12 03:46:12 marco Exp $ */
d478 1
a478 1
	struct mpi_msg_reply		*reply = NULL;
d516 2
d743 1
a743 1
	struct mpi_msg_reply		*reply = NULL;
d791 2
@


1.32
log
@Initial version of dv for scsi.  Work based on dlg's code.
ok dlg
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.30 2006/06/10 14:05:29 dlg Exp $ */
d238 1
a238 1
        struct device			*dev;
d240 1
a240 1
        struct scsi_link		*link;
d291 1
a291 1
        struct scsi_inquiry_data	inqbuf;
d337 1
a337 1
	     letoh32(pg1.configuration));
d990 8
a997 8
        case MPI_IOCSTATUS_SCSI_DATA_UNDERRUN:
                /*
                 * Yikes!  Tagged queue full comes through this path!
                 *
                 * So we'll change it to a status error and anything
                 * that returns status should probably be a status
                 * error as well.
                 */
d999 1
a999 1
                if (sie->scsi_state & MPI_SCSIIO_ERR_STATE_NO_SCSI_STATUS) {
d1003 1
a1003 1
                /* FALLTHROUGH */
d1037 1
a1037 1
        case MPI_IOCSTATUS_SCSI_DEVICE_NOT_THERE:
d1070 1
a1070 1
	if (sie->scsi_state & MPI_SCSIIO_ERR_STATE_AUTOSENSE_VALID) {
d1072 5
a1076 5
        } else if (sie->scsi_state & MPI_SCSIIO_ERR_STATE_AUTOSENSE_FAILED) {
                /* This will cause the scsi layer to issue a REQUEST SENSE */
                if (xs->status == SCSI_CHECK)
                        xs->error = XS_BUSY;
        }
d1217 1
a1217 1
        bus_space_barrier(sc->sc_iot, sc->sc_ioh, r, 4,
d1219 1
a1219 1
        rv = bus_space_read_4(sc->sc_iot, sc->sc_ioh, r);
d1231 3
a1233 3
        bus_space_write_4(sc->sc_iot, sc->sc_ioh, r, v);
        bus_space_barrier(sc->sc_iot, sc->sc_ioh, r, 4,
            BUS_SPACE_BARRIER_WRITE);
d1851 2
a1852 2
	struct mpi_msg_config_request           *cq;
	struct mpi_msg_config_reply             *cp;
@


1.31
log
@Make id in mpi_complete an unused value instead of random stack garbage.
This was causing the "empty portfacts" issue since the IOC wasn't complete
yet with the request however since the id would match the requested id the
timeout was a terminal condition.
@
text
@d46 1
d81 4
d113 1
a113 1
int			mpi_cfg_hdr(struct mpi_softc *, u_int8_t, u_int8_t,
d209 4
d232 236
d565 5
d587 2
d640 6
d668 2
a669 1
	if (ccb == NULL)
d671 1
d677 2
d685 2
d697 2
d718 2
d727 3
d746 2
a747 1
	DNPRINTF(MPI_D_INTR, "%s: mpi_complete\n", DEVNAME(sc));
d1215 2
d1219 5
a1223 1
        return (bus_space_read_4(sc->sc_iot, sc->sc_ioh, r));
d1229 2
d1242 3
d1260 3
d1664 2
a1665 2
	struct mpi_msg_portfacts_reply		*pfp;
	int					s;
d1675 1
a1675 1
		return (1);
d1689 1
a1689 1
		return (1);
d1696 1
a1696 1
		return (1);
d1733 2
d1737 1
a1737 1
	return (0);
d1847 1
a1847 1
mpi_cfg_hdr(struct mpi_softc *sc, u_int8_t type, u_int8_t number,
d1855 2
a1856 1
	DNPRINTF(MPI_D_MISC, "%s: mpi_cfg_hdr\n", DEVNAME(sc));
d1862 2
a1863 1
		DNPRINTF(MPI_D_MISC, "%s: mpi_cfg_hdr ccb_get\n", DEVNAME(sc));
d1882 1
a1882 1
		DNPRINTF(MPI_D_MISC, "%s: mpi_cfg_hdr poll\n", DEVNAME(sc));
d1933 2
a1934 1
	DNPRINTF(MPI_D_MISC, "%s: mpi_cfg_page\n", DEVNAME(sc));
d1961 3
a1963 1
	    MPI_SGE_FL_LAST | MPI_SGE_FL_EOB | MPI_SGE_FL_EOL | len);
@


1.30
log
@if we're not reading a page then we're writing a page. stupid braino from
me pointed out by marco.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.29 2006/06/10 13:45:48 marco Exp $ */
d473 1
a473 1
	u_int32_t			reg, id;
@


1.29
log
@Redo debug prints to make it less loud and more granular.

ok dlg
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.28 2006/06/08 22:09:03 dlg Exp $ */
d1664 1
a1664 1
	    MPI_CONFIG_REQ_ACTION_PAGE_READ_CURRENT);
@


1.28
log
@unsigned long long -> u_int64_t
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.27 2006/06/08 12:27:59 dlg Exp $ */
d37 10
a46 6
#define DPRINTF(x...)		do { if (mpidebug) printf(x); } while (0)
#define DPRINTFN(n, x...)	do { if (mpidebug > (n)) printf(x); } while (0)
int mpidebug = 11; 
#else
#define DPRINTF(x...)		/* x */
#define DPRINTFN(n, x...)	/* n, x */
d241 2
a242 2
		DPRINTF("%s: %s reply_queue: 0x%08x\n", DEVNAME(sc), __func__,
		    reg);
d273 1
a273 1
		DPRINTF("%s: %s id: %d\n", DEVNAME(sc), __func__, id);
d475 1
a475 1
	DPRINTF("%s: %s\n", DEVNAME(sc), __func__);
d487 2
a488 2
		DPRINTF("%s: %s reply_queue: 0x%08x\n", DEVNAME(sc), __func__,
		    reg);
d519 2
a520 1
		DPRINTF("%s: %s id: %d\n", DEVNAME(sc), __func__, id);
d543 1
a543 1
	DPRINTF("%s: %s\n", DEVNAME(sc), __func__);
d563 1
a563 1
	DPRINTF("%s: %s\n", DEVNAME(sc), __func__);
d566 2
a567 1
		DPRINTF("%s: CBD too big %d", DEVNAME(sc), xs->cmdlen);
d585 2
a586 2
	DPRINTF("%s: ccb_id: %d xs->flags: 0x%x\n", DEVNAME(sc), ccb->ccb_id,
	    xs->flags);
d670 3
a672 2
	DPRINTFN(10, "%s:  xs cmd: 0x%02x len: %d error: 0x%02x flags 0x%x\n",
	    DEVNAME(sc), xs->cmd->opcode, xs->datalen, xs->error, xs->flags);
d682 3
a684 5
#ifdef MPI_DEBUG
	if (mpidebug > 10) {
		printf("%s:  target_id: %d bus: %d msg_length: %d "
		    "function: 0x%02x\n", DEVNAME(sc), sie->target_id,
		    sie->bus, sie->msg_length, sie->function);
d686 3
a688 3
		printf("%s:  cdb_length: %d sense_buf_length: %d "
		    "msg_flags: 0x%02x\n", DEVNAME(sc), sie->cdb_length,
		    sie->bus, sie->msg_flags);
d690 2
a691 2
		printf("%s:  msg_context: 0x%08x\n", DEVNAME(sc),
		    letoh32(sie->msg_context));
d693 3
a695 3
		printf("%s:  scsi_status: 0x%02x scsi_state: 0x%02x "
		    "ioc_status: 0x%04x\n", DEVNAME(sc), sie->scsi_status,
		    sie->scsi_state, letoh16(sie->ioc_status));
d697 2
a698 2
		printf("%s:  ioc_loginfo: 0x%08x\n", DEVNAME(sc),
		    letoh32(sie->ioc_loginfo));
d700 2
a701 2
		printf("%s:  transfer_count: %d\n", DEVNAME(sc),
		    letoh32(sie->transfer_count));
d703 2
a704 2
		printf("%s:  sense_count: %d\n", DEVNAME(sc),
		    letoh32(sie->sense_count));
d706 2
a707 2
		printf("%s:  response_info: 0x%08x\n", DEVNAME(sc),
		    letoh32(sie->response_info));
d709 2
a710 3
		printf("%s:  tag: 0x%04x\n", DEVNAME(sc), letoh16(sie->tag));
	}
#endif /* MPI_DEBUG */
d806 1
a806 1
	DPRINTFN(10, "%s:  xs error: 0x%02x len: %d\n", DEVNAME(sc),
d862 1
a862 1
			DPRINTFN(5, "%s:   - 0x%08x 0x%08x 0x%08x\n",
d888 1
a888 1
			DPRINTFN(5, "%s:  ce: 0x%08x 0x%08x 0x%08x\n",
d895 1
a895 1
		DPRINTFN(5, "%s:  %d: %d 0x%016llx\n", DEVNAME(sc),
d907 3
a909 2
		DPRINTFN(5, "%s:  %d: 0x%08x 0x%08x 0x%08x\n", DEVNAME(sc),
		    i, sge->sg_hdr, sge->sg_hi_addr, sge->sg_lo_addr);
d995 2
a996 2
		DPRINTF("%s: %s timeout waiting to leave reset state\n",
		    DEVNAME(sc), __func__);
d1003 2
a1004 2
		DPRINTF("%s: %s initialised by pci peer\n", DEVNAME(sc),
		    __func__);
d1011 2
a1012 2
			DPRINTF("%s: %s ioc is ready\n", DEVNAME(sc),
			    __func__);
d1017 2
a1018 2
			DPRINTF("%s: %s ioc is being reset\n", DEVNAME(sc),
			    __func__);
d1024 2
a1025 2
			DPRINTF("%s: %s waiting to come out of reset\n",
			    DEVNAME(sc), __func__);
d1040 1
a1040 1
	DPRINTF("%s: %s\n", DEVNAME(sc), __func__);
d1061 1
a1061 1
	DPRINTF("%s: %s\n", DEVNAME(sc), __func__);
d1155 2
a1156 2
	DPRINTFN(10, "%s: %s dwords: %d reply: %d\n", DEVNAME(sc), __func__,
	    dwords, reply->msg_length);
d1171 2
a1172 2
		DPRINTFN(10, "%s: %s dummy read: 0x%08x\n", DEVNAME(sc),
		    __func__, dummy);
d1195 1
a1195 1
	DPRINTF("%s: %s\n", DEVNAME(sc), __func__);
d1206 2
a1207 1
		DPRINTF("%s: %s send failed\n", DEVNAME(sc), __func__);
d1212 2
a1213 1
		DPRINTF("%s: %s recv failed\n", DEVNAME(sc), __func__);
d1217 3
a1219 5
#ifdef MPI_DEBUG
	if (mpidebug) {
		printf("%s:  func: 0x%02x len: %d msgver: %d.%d\n",
		    DEVNAME(sc), ifp.function, ifp.msg_length,
		    ifp.msg_version_maj, ifp.msg_version_min);
d1221 4
a1224 4
		printf("%s:  msgflags: 0x%02x iocnumber: 0x%02x "
		    "hdrver: %d.%d\n", DEVNAME(sc), ifp.msg_flags,
		    ifp.ioc_number, ifp.header_version_maj,
		    ifp.header_version_min);
d1226 2
a1227 2
		printf("%s:  message context: 0x%08x\n", DEVNAME(sc),
		    letoh32(ifp.msg_context));
d1229 3
a1231 3
		printf("%s:  iocstatus: 0x%04x ioexcept: 0x%04x\n",
		    DEVNAME(sc), letoh16(ifp.ioc_status),
		    letoh16(ifp.ioc_exceptions));
d1233 2
a1234 2
		printf("%s:  iocloginfo: 0x%08x\n", DEVNAME(sc),
		    letoh32(ifp.ioc_loginfo));
d1236 3
a1238 3
		printf("%s:  flags: 0x%02x blocksize: %d whoinit: 0x%02x "
		    "maxchdepth: %d\n", DEVNAME(sc), ifp.flags,
		    ifp.block_size, ifp.whoinit, ifp.max_chain_depth);
d1240 3
a1242 3
		printf("%s:  reqfrsize: %d replyqdepth: %d\n", DEVNAME(sc),
		    letoh16(ifp.request_frame_size),
		    letoh16(ifp.reply_queue_depth));
d1244 2
a1245 2
		printf("%s:  productid: 0x%04x\n", DEVNAME(sc),
		    letoh16(ifp.product_id));
d1247 2
a1248 2
		printf("%s:  hostmfahiaddr: 0x%08x\n", DEVNAME(sc),
		    letoh32(ifp.current_host_mfa_hi_addr));
d1250 4
a1253 4
		printf("%s:  event_state: 0x%02x number_of_ports: %d "
		    "global_credits: %d\n",
		    DEVNAME(sc), ifp.event_state, ifp.number_of_ports,
		    letoh16(ifp.global_credits));
d1255 2
a1256 2
		printf("%s:  sensebufhiaddr: 0x%08x\n", DEVNAME(sc),
		    letoh32(ifp.current_sense_buffer_hi_addr));
d1258 3
a1260 3
		printf("%s:  maxbus: %d maxdev: %d replyfrsize: %d\n",
		    DEVNAME(sc), ifp.max_buses, ifp.max_devices,
		    letoh16(ifp.current_reply_frame_size));
d1262 2
a1263 2
		printf("%s:  fw_image_size: %d\n", DEVNAME(sc),
		    letoh32(ifp.fw_image_size));
d1265 2
a1266 2
		printf("%s:  ioc_capabilities: 0x%08x\n", DEVNAME(sc),
		    letoh32(ifp.ioc_capabilities));
d1268 4
a1271 4
		printf("%s:  fw_version: %d.%d fw_version_unit: 0x%02x "
		    "fw_version_dev: 0x%02x\n", DEVNAME(sc),
		    ifp.fw_version_maj, ifp.fw_version_min,
		    ifp.fw_version_unit, ifp.fw_version_dev);
d1273 2
a1274 2
		printf("%s:  hi_priority_queue_depth: 0x%04x\n", DEVNAME(sc),
		    letoh16(ifp.hi_priority_queue_depth));
d1276 5
a1280 7
		printf("%s:  host_page_buffer_sge: hdr: 0x%08x "
		    "addr 0x%08x %08x\n", DEVNAME(sc),
		    letoh32(ifp.host_page_buffer_sge.sg_hdr),
		    letoh32(ifp.host_page_buffer_sge.sg_hi_addr),
		    letoh32(ifp.host_page_buffer_sge.sg_lo_addr));
	}
#endif /* MPI_DEBUG */
d1292 1
a1292 1
	DPRINTF("%s:   first sgl len: %d\n", DEVNAME(sc),
d1300 2
a1301 1
	DPRINTF("%s:   max sgl len: %d\n", DEVNAME(sc), sc->sc_max_sgl_len);
d1313 1
a1313 1
	DPRINTF("%s: %s\n", DEVNAME(sc), __func__);
d1342 2
a1343 1
		DPRINTF("%s: %s send failed\n", DEVNAME(sc), __func__);
d1348 2
a1349 1
		DPRINTF("%s: %s recv failed\n", DEVNAME(sc), __func__);
d1353 3
a1355 5
#ifdef MPI_DEBUG
	if (mpidebug) {
		printf("%s:  function: 0x%02x msg_length: %d "
		    "whoinit: 0x%02x\n", DEVNAME(sc), iip.function,
		    iip.msg_length, iip.whoinit);
d1357 3
a1359 3
		printf("%s:  msg_flags: 0x%02x max_buses: %d max_devices: %d "
		    "flags: 0x%02x\n", DEVNAME(sc), iip.msg_flags,
		    iip.max_buses, iip.max_devices, iip.flags);
d1361 2
a1362 2
		printf("%s:  msg_context: 0x%08x\n", DEVNAME(sc),
		    letoh32(iip.msg_context));
d1364 2
a1365 2
		printf("%s:  ioc_status: 0x%04x\n", DEVNAME(sc),
		    letoh16(iip.ioc_status));
d1367 2
a1368 4
		printf("%s:  ioc_loginfo: 0x%08x\n", DEVNAME(sc),
		    letoh32(iip.ioc_loginfo));
	}
#endif /* MPI_DEBUG */
d1381 1
a1381 1
	DPRINTF("%s: %s\n", DEVNAME(sc), __func__);
d1387 2
a1388 1
		DPRINTF("%s: %s ccb_get\n", DEVNAME(sc), __func__);
d1402 1
a1402 1
		DPRINTF("%s: %s poll\n", DEVNAME(sc), __func__);
d1408 2
a1409 1
		DPRINTF("%s: empty portfacts reply\n", DEVNAME(sc));
d1413 2
a1414 4
#ifdef MPI_DEBUG
	if (mpidebug) {
		printf("%s:  function: 0x%02x msg_length: %d\n", DEVNAME(sc),
		    pfp->function, pfp->msg_length);
d1416 2
a1417 2
		printf("%s:  msg_flags: 0x%02x port_number: %d\n", DEVNAME(sc),
		    pfp->msg_flags, pfp->port_number);
d1419 2
a1420 2
		printf("%s:  msg_context: 0x%08x\n", DEVNAME(sc),
		    letoh32(pfp->msg_context));
d1422 2
a1423 2
		printf("%s:  ioc_status: 0x%04x\n", DEVNAME(sc),
		    letoh16(pfp->ioc_status));
d1425 2
a1426 2
		printf("%s:  ioc_loginfo: 0x%08x\n", DEVNAME(sc),
		    letoh32(pfp->ioc_loginfo));
d1428 2
a1429 2
		printf("%s:  max_devices: %d port_type: 0x%02x\n", DEVNAME(sc),
		    letoh16(pfp->max_devices), pfp->port_type);
d1431 3
a1433 3
		printf("%s:  protocol_flags: 0x%04x port_scsi_id: %d\n",
		    DEVNAME(sc), letoh16(pfp->protocol_flags),
		    letoh16(pfp->port_scsi_id));
d1435 4
a1438 4
		printf("%s:  max_persistent_ids: %d "
		    "max_posted_cmd_buffers: %d\n", DEVNAME(sc),
	 	    letoh16(pfp->max_persistent_ids),
		    letoh16(pfp->max_posted_cmd_buffers));
d1440 2
a1441 4
		printf("%s:  max_lan_buckets: %d\n", DEVNAME(sc),
		    letoh16(pfp->max_lan_buckets));
	}
#endif /* MPI_DEBUG */
d1463 2
a1464 1
		DPRINTF("%s: %s ccb_get\n", DEVNAME(sc), __func__);
d1522 1
a1522 1
	DPRINTF("%s: %s\n", DEVNAME(sc), __func__);
d1528 2
a1529 1
		DPRINTF("%s: %s ccb_get\n", DEVNAME(sc), __func__);
d1541 1
a1541 1
		DPRINTF("%s: %s poll\n", DEVNAME(sc), __func__);
d1547 2
a1548 1
		DPRINTF("%s: empty portenable reply\n", DEVNAME(sc));
d1567 1
a1567 1
	DPRINTF("%s: %s\n", DEVNAME(sc), __func__);
d1573 1
a1573 1
		DPRINTF("%s: %s ccb_get\n", DEVNAME(sc), __func__);
d1592 1
a1592 1
		DPRINTF("%s: %s poll\n", DEVNAME(sc), __func__);
d1600 23
a1622 27
#ifdef MPI_DEBUG
	if (mpidebug) {
		printf("%s:  action: 0x%02x msg_length: %d function: 0x%02x\n",
		    DEVNAME(sc), cp->action, cp->msg_length, cp->function);

		printf("%s:  ext_page_length: %d ext_page_type: 0x%02x "
		    "msg_flags: 0x%02x\n", DEVNAME(sc),
		    letoh16(cp->ext_page_length), cp->ext_page_type,
		    cp->msg_flags);

		printf("%s:  msg_context: 0x%08x\n", DEVNAME(sc),
		    letoh32(cp->msg_context));

		printf("%s:  ioc_status: 0x%04x\n", DEVNAME(sc),
		    letoh16(cp->ioc_status));

		printf("%s:  ioc_loginfo: 0x%08x\n", DEVNAME(sc),
		    letoh32(cp->ioc_loginfo));

		printf("%s:  page_version: 0x%02x page_length: %d "
		    "page_number: 0x%02x page_type: 0x%02x\n", DEVNAME(sc),
		    cp->config_header.page_version, 
		    cp->config_header.page_length, 
		    cp->config_header.page_number, 
		    cp->config_header.page_type);
	}
#endif /* MPI_DEBUG */ 
d1643 1
a1643 1
	DPRINTF("%s: %s\n", DEVNAME(sc), __func__);
d1653 1
a1653 1
		DPRINTF("%s: %s ccb_get\n", DEVNAME(sc), __func__);
d1684 1
a1684 1
		DPRINTF("%s: %s poll\n", DEVNAME(sc), __func__);
d1694 23
a1716 27
#ifdef MPI_DEBUG
	if (mpidebug) {
		printf("%s:  action: 0x%02x msg_length: %d function: 0x%02x\n",
		    DEVNAME(sc), cp->action, cp->msg_length, cp->function);

		printf("%s:  ext_page_length: %d ext_page_type: 0x%02x "
		    "msg_flags: 0x%02x\n", DEVNAME(sc),
		    letoh16(cp->ext_page_length), cp->ext_page_type,
		    cp->msg_flags);

		printf("%s:  msg_context: 0x%08x\n", DEVNAME(sc),
		    letoh32(cp->msg_context));

		printf("%s:  ioc_status: 0x%04x\n", DEVNAME(sc),
		    letoh16(cp->ioc_status));

		printf("%s:  ioc_loginfo: 0x%08x\n", DEVNAME(sc),
		    letoh32(cp->ioc_loginfo));

		printf("%s:  page_version: 0x%02x page_length: %d "
		    "page_number: 0x%02x page_type: 0x%02x\n", DEVNAME(sc),
		    cp->config_header.page_version, 
		    cp->config_header.page_length, 
		    cp->config_header.page_number, 
		    cp->config_header.page_type);
	}
#endif /* MPI_DEBUG */ 
@


1.27
log
@dont panic on empty portfacts or portenable replies. we should probably
retry the init sequence if this happens.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.26 2006/06/06 14:51:29 dlg Exp $ */
d893 1
a893 1
		    (unsigned long long)dmap->dm_segs[i].ds_addr);
d898 1
a898 1
		addr = (u_int32_t)((unsigned long long)dmap->dm_segs[i].ds_addr >> 32);
@


1.26
log
@set the ccb state when it comes off the free list. this isnt used anywhere
yet, but i like to be ready when the time comes.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.25 2006/06/06 14:47:45 dlg Exp $ */
d1404 4
a1407 2
	if (pfp == NULL)
		panic("%s: empty portfacts reply\n", DEVNAME(sc));
d1544 4
a1547 2
	if (pep == NULL)
		panic("%s: empty portenable reply\n", DEVNAME(sc));
@


1.25
log
@fix a panic string to mention the corrent place its freaking out in.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.24 2006/06/01 21:32:15 dlg Exp $ */
d410 2
@


1.24
log
@leave the reply_dva address alone so we can post it back to the ioc rather
than posting back the offset of the reply frame to the start of the reply
space.

nobody likes panics, even if theyre free.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.23 2006/06/01 04:36:19 dlg Exp $ */
d1541 1
a1541 1
		panic("%s: empty portfacts reply\n", DEVNAME(sc));
@


1.23
log
@fix the reply handling on crazy machines that give me bits in the high part
of the address.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.22 2006/06/01 00:53:15 deraadt Exp $ */
a245 1
			reply_dva -= (u_int32_t)MPI_DMA_DVA(sc->sc_replies);
d247 3
a249 1
			reply_addr = MPI_DMA_KVA(sc->sc_replies) + reply_dva;
a489 1
			reply_dva -= (u_int32_t)MPI_DMA_DVA(sc->sc_replies);
d491 3
a493 1
			reply_addr = MPI_DMA_KVA(sc->sc_replies) + reply_dva;
@


1.22
log
@64 bit dva addresses so we can >> 32 later; ok dlg
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.21 2006/05/31 21:28:08 dlg Exp $ */
d230 1
a230 1
	paddr_t				reply_dva;
d246 1
d248 1
a248 2
			reply_addr = MPI_DMA_KVA(sc->sc_replies) +
			    (reply_dva - MPI_DMA_DVA(sc->sc_replies));
d380 1
a380 1
		ccb->ccb_cmd_dva = MPI_DMA_DVA(sc->sc_requests) +
d443 2
a444 1
		reply = MPI_DMA_DVA(sc->sc_replies) + MPI_REPLY_SIZE * i;
d464 1
a464 1
	paddr_t				reply_dva;
d489 1
d491 1
a491 2
			reply_addr = MPI_DMA_KVA(sc->sc_replies) +
			    (reply_dva - MPI_DMA_DVA(sc->sc_replies));
d1320 1
a1320 1
	hi_addr = (u_int32_t)((unsigned long long)MPI_DMA_DVA(sc->sc_requests) >> 32);
d1324 1
a1324 1
	hi_addr = (u_int32_t)((unsigned long long)MPI_DMA_DVA(sc->sc_replies) >> 32);
@


1.21
log
@byteswap the ioc_status field so we can respond to scsi things properly on
bigendian archs. this lets ses attach now.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.20 2006/05/31 06:17:00 dlg Exp $ */
d819 1
a819 1
	paddr_t				ce_dva;
d1631 1
a1631 1
	paddr_t					dva;
@


1.20
log
@remove the fetching of the manufacturing page. it was just there to see if
i got the page fetching right, its not really useful for anything in the
real world.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.19 2006/05/31 03:06:39 dlg Exp $ */
d704 1
a704 1
	switch (sie->ioc_status) {
@


1.19
log
@mpi hardware uses an 8 bit field to describe the number of devices it has
on a port. since 256 wont fit into 8 bits they say 0 means 256. this diff
does the appropriate interpretation. it also avoids a divide by zero when
we figure the openings out by dividing the number of commands the
controller can support by the number of devices it supports.

panic found while testing the fc controller at home.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.18 2006/05/31 02:39:29 dlg Exp $ */
a108 2
int			mpi_cfg_manufacturer0(struct mpi_softc *);

a1541 25

	return (0);
}

int
mpi_cfg_manufacturer0(struct mpi_softc *sc)
{
	struct mpi_cfg_hdr			hdr;
	struct mpi_cfg_manufacturing_pg0	pg0;

	DPRINTF("%s: %s\n", DEVNAME(sc), __func__);

	if (mpi_cfg_hdr(sc, MPI_CONFIG_REQ_PAGE_TYPE_MANUFACTURING, 0, 0x0,
	    &hdr) != 0)
		return (1);

	if (mpi_cfg_page(sc, 0x0, &hdr, 1, &pg0, sizeof(pg0)) != 0)
		return (1);

	printf("%s:  chip_name: %s\n", DEVNAME(sc), pg0.chip_name);
	printf("%s:  chip_revision: %s\n", DEVNAME(sc), pg0.chip_revision);
	printf("%s:  board_name: %s\n", DEVNAME(sc), pg0.board_name);
	printf("%s:  board_assembly: %s\n", DEVNAME(sc), pg0.board_assembly);
	printf("%s:  board_tracer_numer: %s\n", DEVNAME(sc),
	    pg0.board_tracer_number);
@


1.18
log
@dont display the first manufacturing page
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.17 2006/05/31 02:38:36 dlg Exp $ */
d1277 1
a1277 1
	sc->sc_buswidth = ifp.max_devices;
d1314 1
a1314 1
	iiq.max_devices = sc->sc_buswidth;
@


1.17
log
@c++ style comments shouldnt be in the tree
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.16 2006/05/31 00:52:05 deraadt Exp $ */
a188 5
		goto free_replies;
	}

	if (mpi_cfg_manufacturer0(sc) != 0) {
		printf("%s: unable to read config pages\n", DEVNAME(sc));
@


1.16
log
@int32 i >> 32 is undefined, so cast to unsigned long long first, ok dlg
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.15 2006/05/31 00:32:51 dlg Exp $ */
d591 4
a594 2
//	io->chain_offset = dwordsof(mcb->mcb_io);
//	io->bus = htole16(sc->sc_bus);
@


1.15
log
@implement chained scatter gather lists.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.14 2006/05/30 05:03:28 dlg Exp $ */
d898 1
a898 1
		addr = (u_int32_t)(dmap->dm_segs[i].ds_addr >> 32);
d1324 1
a1324 1
	hi_addr = (u_int32_t)(MPI_DMA_DVA(sc->sc_requests) >> 32);
d1328 1
a1328 1
	hi_addr = (u_int32_t)(MPI_DMA_DVA(sc->sc_replies) >> 32);
@


1.14
log
@raise the timeout on the init commands (especially port enable) to give
the sas controller currently being used in jasons blade 2000 a chance to
respond.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.13 2006/05/30 03:25:13 jason Exp $ */
d39 1
a39 1
int mpidebug = 10;
d376 1
a376 1
		    sc->sc_first_sgl_len, MAXPHYS, 0, 0,
d821 4
a824 1
	struct mpi_sge			*sge;
d830 1
a830 2
		sge = &mcb->mcb_sgl[0];
		sge->sg_hdr = htole32(MPI_SGE_FL_TYPE_SIMPLE |
d847 5
d853 44
a896 1
		sge = &mcb->mcb_sgl[i];
d902 5
a912 14
#ifdef MPI_DEBUG
	if (mpidebug > 5) {
		for (i = 0; i < dmap->dm_nsegs; i++) {
			printf("%s:  %d: %d 0x%016llx\n", DEVNAME(sc),
			    i, dmap->dm_segs[i].ds_len,
			    (unsigned long long)dmap->dm_segs[i].ds_addr);
			printf("%s:  %d: 0x%08x 0x%08x 0x%08x\n", DEVNAME(sc),
			    i, mcb->mcb_sgl[i].sg_hdr,
			    mcb->mcb_sgl[i].sg_hi_addr,
			    mcb->mcb_sgl[i].sg_lo_addr);
		}
	}
#endif

d1280 7
d1291 7
a1297 2
	sc->sc_maxchdepth = ifp.max_chain_depth;
	sc->sc_buswidth = ifp.max_devices;
@


1.13
log
@hush; ok dlg
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.12 2006/05/29 21:30:24 dlg Exp $ */
a35 2
#undef MPI_DEBUG

d1345 1
a1345 1
	if (mpi_poll(sc, ccb, 10000) != 0) {
d1483 1
a1483 1
	if (mpi_poll(sc, ccb, 10000) != 0) {
d1556 1
a1556 1
	if (mpi_poll(sc, ccb, 10000) != 0) {
d1652 1
a1652 1
	if (mpi_poll(sc, ccb, 10000) != 0) {
@


1.12
log
@increase the timeout on the enabling commands during attach so that sas
controllers have a chance to respond.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.11 2006/05/29 19:55:37 dlg Exp $ */
d36 1
a36 1
#define MPI_DEBUG
@


1.11
log
@limit the number of scatter gather entries sent with the scsi_io commands
so it fits in the maximum request frame size. this will do until i can
write sgl chaining in a nice way.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.10 2006/05/29 08:33:36 dlg Exp $ */
d1347 1
a1347 1
	if (mpi_poll(sc, ccb, 1000) != 0) {
d1485 1
a1485 1
	if (mpi_poll(sc, ccb, 1000) != 0) {
d1558 1
a1558 1
	if (mpi_poll(sc, ccb, 1000) != 0) {
d1654 1
a1654 1
	if (mpi_poll(sc, ccb, 1000) != 0) {
@


1.10
log
@put the 64bit flag in the right place on the scatter gather list.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.9 2006/05/29 08:18:57 dlg Exp $ */
d377 3
a379 2
		if (bus_dmamap_create(sc->sc_dmat, MAXPHYS, MPI_MAX_SGL,
		    MAXPHYS, 0, 0, &ccb->ccb_dmamap) != 0) {
d1241 4
@


1.9
log
@split mpi_poll out into mpi_complete, and rewrite poll to use start and
complete to do its job. enforce the use of a timeout on polled commands
and make the callers check if the timeout happened.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.8 2006/05/29 06:32:09 dlg Exp $ */
d830 1
a830 2
		    MPI_SGE_FL_LAST | MPI_SGE_FL_EOB | MPI_SGE_FL_EOL |
		    MPI_SGE_FL_SIZE_64);
d842 1
a842 1
	flags = MPI_SGE_FL_TYPE_SIMPLE;
@


1.8
log
@remove some if 0 code
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.7 2006/05/29 05:43:55 dlg Exp $ */
d75 1
d77 1
d467 1
a467 1
mpi_poll(struct mpi_softc *sc, struct mpi_ccb *nccb, int timeout)
a473 1
	int				s;
a476 4
	s = splbio();

	mpi_start(sc, nccb);

d480 1
a480 2
			if (timeout == 0) {
				splx(s);
a481 4
			}

			if (timeout > 0)
				--timeout;
d532 14
d548 1
a548 1
	return (0);
d1343 4
a1346 1
	mpi_poll(sc, ccb, -1);
d1481 4
a1484 1
	mpi_poll(sc, ccb, -1);
d1554 4
a1557 1
	mpi_poll(sc, ccb, -1);
d1650 4
a1653 1
	mpi_poll(sc, ccb, -1);
@


1.7
log
@bump mpi up to using 64bit for all dva
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.6 2006/05/28 21:59:23 dlg Exp $ */
a828 6
#if 0
	error = bus_dmamap_load(sc->sc_dmat, dmap,
	    xs->data, xs->datalen, NULL, BUS_DMA_STREAMING |
	    (xs->flags & SCSI_NOSLEEP) ? BUS_DMA_NOWAIT : BUS_DMA_WAITOK |
	    (xs->flags & SCSI_DATA_IN) ? BUS_DMA_READ : BUS_DMA_WRITE);
#endif
@


1.6
log
@junk to read and write configuration pages.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.5 2006/05/28 02:32:55 dlg Exp $ */
d41 1
a41 1
int mpidebug = 0;
d72 1
d75 1
a75 1
void			mpi_poll(struct mpi_softc *, struct mpi_ccb *);
d154 5
d173 1
a173 4
	if (mpi_alloc_replies(sc) != 0) {
		/* error already printed */
		goto free_ccbs;
	}
a415 3
	DPRINTFN(10, "%s: %s: ccb_id: %d\n", DEVNAME(sc), __func__,
	    ccb->ccb_id);

a421 3
	DPRINTFN(10, "%s: %s: ccb_id: %d\n", DEVNAME(sc), __func__,
	    ccb->ccb_id);

d432 10
a444 6
	sc->sc_replies = mpi_dmamem_alloc(sc, PAGE_SIZE);
	if (sc->sc_replies == NULL) {
		printf("%s: unable to allocate replies\n", DEVNAME(sc));
		return (1);
	}

a451 2

	return (0);
d464 2
a465 2
void
mpi_poll(struct mpi_softc *sc, struct mpi_ccb *nccb)
d483 8
d541 2
d592 1
d596 1
a596 2
	/* XXX */
	io->lun[0] = htole16(link->lun);
d629 2
a630 1
		mpi_poll(sc, ccb);
d816 1
a816 1
	struct mpi_sge32		*sge;
d818 1
a818 1
	u_int32_t			flags;
d824 2
a825 1
		    MPI_SGE_FL_LAST | MPI_SGE_FL_EOB | MPI_SGE_FL_EOL);
d850 4
a853 1
		sge->sg_addr = htole32(dmap->dm_segs[i].ds_addr);
d861 1
a861 1
	if (mpidebug > 11) {
d863 7
a869 2
			printf("%s:  %d: 0x%08x 0x%08x\n", DEVNAME(sc), i,
			    mcb->mcb_sgl[i].sg_hdr, mcb->mcb_sgl[i].sg_addr);
d1235 2
a1236 2
		    letoh32(ifp.host_page_buffer_sge.sg_hiaddr),
		    letoh32(ifp.host_page_buffer_sge.sg_loaddr));
d1252 1
d1269 7
d1343 1
a1343 1
	mpi_poll(sc, ccb);
d1478 1
a1478 1
	mpi_poll(sc, ccb);
d1548 1
a1548 1
	mpi_poll(sc, ccb);
d1597 1
d1631 5
a1635 2
	cq->page_buffer.sg_addr = htole32(MPI_DMA_DVA(sc->sc_requests) +
	    ccb->ccb_offset + sizeof(struct mpi_msg_config_request));
d1641 1
a1641 1
	mpi_poll(sc, ccb);
@


1.5
log
@pass the reply from the hardware via the ccb rather than on the stack to
the function handling the completion. this means that the completion
function can do nothing with the reply, instead leaving it up to the
requester to deal with.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.4 2006/05/28 01:29:21 dlg Exp $ */
d103 7
d189 5
d1456 192
@


1.4
log
@rename mpi_complete to mpi_poll and make it call mpi_start itself.
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.3 2006/05/27 20:53:56 dlg Exp $ */
d52 1
a52 1
void			mpi_scsi_cmd_done(struct mpi_ccb *, void *, paddr_t);
d94 2
a98 1
void			mpi_portfacts_done(struct mpi_ccb *, void *, paddr_t);
d100 1
a100 1
void			mpi_eventnotify_done(struct mpi_ccb *, void *, paddr_t);
a101 1
void			mpi_portenable_done(struct mpi_ccb *, void *, paddr_t);
d266 3
d270 1
a270 1
		ccb->ccb_done(ccb, reply, reply_dva);
a338 1
	TAILQ_INIT(&sc->sc_ccb_runq);
a449 1
	TAILQ_INSERT_TAIL(&sc->sc_ccb_runq, ccb, ccb_link);
d513 3
d517 1
a517 1
		ccb->ccb_done(ccb, reply, reply_dva);
d617 1
a617 1
mpi_scsi_cmd_done(struct mpi_ccb *ccb, void *reply, paddr_t reply_dva)
d623 1
a623 1
	struct mpi_msg_scsi_io_error	*sie = reply;
a680 1

d777 1
a777 1
	mpi_push_reply(sc, reply_dva);
d1108 6
d1282 1
d1295 1
a1295 1
	ccb->ccb_done = mpi_portfacts_done;
d1306 1
a1306 11
	return (0);
}

void
mpi_portfacts_done(struct mpi_ccb *ccb, void *reply, paddr_t reply_dva)
{
	struct mpi_softc			*sc = ccb->ccb_sc;
	struct mpi_msg_portfacts_reply		*pfp = reply;

	DPRINTF("%s: %s\n", DEVNAME(sc), __func__);

d1347 1
a1347 1
	mpi_push_reply(sc, reply_dva);
d1349 2
d1382 1
a1382 1
mpi_eventnotify_done(struct mpi_ccb *ccb, void *reply, paddr_t reply_dva)
d1385 1
a1385 1
	struct mpi_msg_event_reply		*enp = reply;
d1407 1
a1407 1
	data = reply;
d1419 1
d1432 1
a1432 1
	ccb->ccb_done = mpi_portenable_done;
d1441 1
a1441 11
	return (0);
}

void
mpi_portenable_done(struct mpi_ccb *ccb, void *reply, paddr_t reply_dva)
{
	struct mpi_softc			*sc = ccb->ccb_sc;
	struct mpi_msg_portenable_reply		*pep = reply;

	DPRINTF("%s: %s\n", DEVNAME(sc), __func__);

d1445 1
a1445 1
	mpi_push_reply(sc, reply_dva);
d1447 2
@


1.3
log
@make debug output during attach quiet unless you want it by raising
mpidebug
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.2 2006/05/27 19:37:38 dlg Exp $ */
d74 1
a74 1
void			mpi_complete(struct mpi_softc *, struct mpi_ccb *);
d453 1
a453 1
mpi_complete(struct mpi_softc *sc, struct mpi_ccb *nccb)
d460 1
d464 4
d516 2
d604 1
a604 5
		s = splbio();
		mpi_start(sc, ccb);
		mpi_complete(sc, ccb);
		splx(s);

d1294 1
a1294 4
	s = splbio();
	mpi_start(sc, ccb);
	mpi_complete(sc, ccb);
	splx(s);
d1436 1
a1436 4
	s = splbio();
	mpi_start(sc, ccb);
	mpi_complete(sc, ccb);
	splx(s);
a1454 1

@


1.2
log
@remove dead code
@
text
@d1 1
a1 1
/*	$OpenBSD: mpi.c,v 1.1 2006/05/27 19:03:55 dlg Exp $ */
a119 2


d1129 66
a1194 59
	printf("%s:  func: 0x%02x len: %d msgver: %d.%d\n",
	    DEVNAME(sc), ifp.function, ifp.msg_length,
	    ifp.msg_version_maj, ifp.msg_version_min);

	printf("%s:  msgflags: 0x%02x iocnumber: 0x%02x hdrver: %d.%d\n",
            DEVNAME(sc), ifp.msg_flags, ifp.ioc_number,
            ifp.header_version_maj, ifp.header_version_min);

	printf("%s:  message context: 0x%08x\n", DEVNAME(sc),
	    letoh32(ifp.msg_context));

	printf("%s:  iocstatus: 0x%04x ioexcept: 0x%04x\n", DEVNAME(sc),
	    letoh16(ifp.ioc_status), letoh16(ifp.ioc_exceptions));

	printf("%s:  iocloginfo: 0x%08x\n", DEVNAME(sc),
	    letoh32(ifp.ioc_loginfo));

	printf("%s:  flags: 0x%02x blocksize: %d whoinit: 0x%02x "
	    "maxchdepth: %d\n", DEVNAME(sc), ifp.flags, ifp.block_size,
	    ifp.whoinit, ifp.max_chain_depth);

	printf("%s:  reqfrsize: %d replyqdepth: %d\n", DEVNAME(sc),
	    letoh16(ifp.request_frame_size), letoh16(ifp.reply_queue_depth));

	printf("%s:  productid: 0x%04x\n", DEVNAME(sc),
	    letoh16(ifp.product_id));

	printf("%s:  hostmfahiaddr: 0x%08x\n", DEVNAME(sc),
	    letoh32(ifp.current_host_mfa_hi_addr));

	printf("%s:  event_state: 0x%02x number_of_ports: %d "
	    "global_credits: %d\n",
	    DEVNAME(sc), ifp.event_state, ifp.number_of_ports,
	    letoh16(ifp.global_credits));

	printf("%s:  sensebufhiaddr: 0x%08x\n", DEVNAME(sc),
	    letoh32(ifp.current_sense_buffer_hi_addr));

	printf("%s:  maxbus: %d maxdev: %d replyfrsize: %d\n", DEVNAME(sc),
	    ifp.max_buses, ifp.max_devices,
	    letoh16(ifp.current_reply_frame_size));

	printf("%s:  fw_image_size: %d\n", DEVNAME(sc),
	    letoh32(ifp.fw_image_size));

	printf("%s:  ioc_capabilities: 0x%08x\n", DEVNAME(sc),
	    letoh32(ifp.ioc_capabilities));

	printf("%s:  fw_version: %d.%d fw_version_unit: 0x%02x "
	    "fw_version_dev: 0x%02x\n", DEVNAME(sc), ifp.fw_version_maj,
	    ifp.fw_version_min, ifp.fw_version_unit, ifp.fw_version_dev);

	printf("%s:  hi_priority_queue_depth: 0x%04x\n", DEVNAME(sc),
	    letoh16(ifp.hi_priority_queue_depth));

	printf("%s:  host_page_buffer_sge: hdr: 0x%08x addr 0x%08x %08x\n",
	    DEVNAME(sc), letoh32(ifp.host_page_buffer_sge.sg_hdr),
	    letoh32(ifp.host_page_buffer_sge.sg_hiaddr),
	    letoh32(ifp.host_page_buffer_sge.sg_loaddr));
d1242 8
a1249 2
	printf("%s:  function: 0x%02x msg_length: %d whoinit: 0x%02x\n",
	    DEVNAME(sc), iip.function, iip.msg_length, iip.whoinit);
d1251 2
a1252 3
	printf("%s:  msg_flags: 0x%02x max_buses: %d max_devices: %d "
	    "flags: 0x%02x\n", DEVNAME(sc), iip.msg_flags, iip.max_buses,
	    iip.max_devices, iip.flags);
d1254 2
a1255 2
	printf("%s:  msg_context: 0x%08x\n", DEVNAME(sc),
	    letoh32(iip.msg_context));
d1257 3
a1259 5
	printf("%s:  ioc_status: 0x%04x\n", DEVNAME(sc),
	    letoh16(iip.ioc_status));

	printf("%s:  ioc_loginfo: 0x%08x\n", DEVNAME(sc),
	    letoh32(iip.ioc_loginfo));
d1311 3
a1313 2
	printf("%s:  function: 0x%02x msg_length: %d\n", DEVNAME(sc),
	    pfp->function, pfp->msg_length);
d1315 2
a1316 2
	printf("%s:  msg_flags: 0x%02x port_number: %d\n", DEVNAME(sc),
	    pfp->msg_flags, pfp->port_number);
d1318 2
a1319 2
	printf("%s:  msg_context: 0x%08x\n", DEVNAME(sc),
	    letoh32(pfp->msg_context));
d1321 2
a1322 2
	printf("%s:  ioc_status: 0x%04x\n", DEVNAME(sc),
	    letoh16(pfp->ioc_status));
d1324 2
a1325 2
	printf("%s:  ioc_loginfo: 0x%08x\n", DEVNAME(sc),
	    letoh32(pfp->ioc_loginfo));
d1327 2
a1328 2
	printf("%s:  max_devices: %d port_type: 0x%02x\n", DEVNAME(sc),
	    letoh16(pfp->max_devices), pfp->port_type);
d1330 8
a1337 3
	printf("%s:  protocol_flags: 0x%04x port_scsi_id: %d\n",
	    DEVNAME(sc), letoh16(pfp->protocol_flags),
	    letoh16(pfp->port_scsi_id));
d1339 3
a1341 6
	printf("%s:  max_persistent_ids: %d max_posted_cmd_buffers: %d\n",
	    DEVNAME(sc), letoh16(pfp->max_persistent_ids),
	    letoh16(pfp->max_posted_cmd_buffers));

	printf("%s:  max_lan_buckets: %d\n", DEVNAME(sc),
	    letoh16(pfp->max_lan_buckets));
@


1.1
log
@add mpi(4), an alternative (replacement) driver for lsi logic fusion mpt
controllers currently supported by mpt(4).

ok marco@@
@
text
@d1 1
a1 1
/*	$OpenBSD$ */
a97 1
int			mpi_oportfacts(struct mpi_softc *);
a1447 61
int
mpi_oportfacts(struct mpi_softc *sc)
{
	struct mpi_msg_portfacts_request	pfq;
	struct mpi_msg_portfacts_reply		pfp;

	bzero(&pfq, sizeof(pfq));
	bzero(&pfp, sizeof(pfp));

	pfq.function = MPI_FUNCTION_PORT_FACTS;
	pfq.chain_offset = 0;
	pfq.msg_flags = 0;
	pfq.port_number = 0;
	pfq.msg_context = htole32(0xdeadbeef);

	if (mpi_handshake_send(sc, &pfq, dwordsof(pfq)) != 0) {
		DPRINTF("%s: %s send failed\n", DEVNAME(sc), __func__);
		return (1);
	}

	if (mpi_handshake_recv(sc, &pfp, dwordsof(pfp)) != 0) {
		DPRINTF("%s: %s recv failed\n", DEVNAME(sc), __func__);
		return (1);
	}

#ifdef MPI_DEBUG
	printf("%s:  function: 0x%02x msg_length: %d\n", DEVNAME(sc),
	    pfp.function, pfp.msg_length);

	printf("%s:  msg_flags: 0x%02x port_number: %d\n", DEVNAME(sc),
	    pfp.msg_flags, pfp.port_number);

	printf("%s:  msg_context: 0x%08x\n", DEVNAME(sc),
	    letoh32(pfp.msg_context));

	printf("%s:  ioc_status: 0x%04x\n", DEVNAME(sc),
	    letoh16(pfp.ioc_status));

	printf("%s:  ioc_loginfo: 0x%08x\n", DEVNAME(sc),
	    letoh32(pfp.ioc_loginfo));

	printf("%s:  max_devices: %d port_type: 0x%02x\n", DEVNAME(sc),
	    letoh16(pfp.max_devices), pfp.port_type);

	printf("%s:  protocol_flags: 0x%04x port_scsi_id: %d\n",
	    DEVNAME(sc), letoh16(pfp.protocol_flags),
	    letoh16(pfp.port_scsi_id));

	printf("%s:  max_persistent_ids: %d max_posted_cmd_buffers: %d\n",
	    DEVNAME(sc), letoh16(pfp.max_persistent_ids),
	    letoh16(pfp.max_posted_cmd_buffers));

	printf("%s:  max_lan_buckets: %d\n", DEVNAME(sc),
	    letoh16(pfp.max_lan_buckets));
#endif /* MPI_DEBUG */

	sc->sc_porttype = pfp.port_type;
	sc->sc_target = letoh16(pfp.port_scsi_id);

	return (0);
}
@

