head	1.27;
access;
symbols
	OPENBSD_6_0:1.26.0.2
	OPENBSD_6_0_BASE:1.26
	OPENBSD_5_9:1.23.0.2
	OPENBSD_5_9_BASE:1.23
	OPENBSD_5_8:1.23.0.4
	OPENBSD_5_8_BASE:1.23
	OPENBSD_5_7:1.17.0.4
	OPENBSD_5_7_BASE:1.17
	OPENBSD_5_6:1.15.0.6
	OPENBSD_5_6_BASE:1.15
	OPENBSD_5_5:1.15.0.4
	OPENBSD_5_5_BASE:1.15;
locks; strict;
comment	@ * @;


1.27
date	2016.10.07.19.17.50;	author krw;	state Exp;
branches;
next	1.26;
commitid	8ox2k2SmVxJEvtG3;

1.26
date	2016.05.31.15.19.12;	author jsing;	state Exp;
branches;
next	1.25;
commitid	cwFTIUrXuiupYWGN;

1.25
date	2016.04.12.16.26.54;	author krw;	state Exp;
branches;
next	1.24;
commitid	ATfj2h1H9b585gss;

1.24
date	2016.04.04.18.48.39;	author krw;	state Exp;
branches;
next	1.23;
commitid	1ISokwrtQ24zRrhW;

1.23
date	2015.07.21.03.30.51;	author krw;	state Exp;
branches;
next	1.22;
commitid	TJiPw62Nfq0KhqBx;

1.22
date	2015.07.19.21.06.04;	author krw;	state Exp;
branches;
next	1.21;
commitid	DQBduvhX3UJc1lbB;

1.21
date	2015.07.19.18.24.16;	author krw;	state Exp;
branches;
next	1.20;
commitid	soWovNPxU9gU33mQ;

1.20
date	2015.07.19.17.04.31;	author krw;	state Exp;
branches;
next	1.19;
commitid	WthDQr0yYlXab4V8;

1.19
date	2015.05.29.13.48.45;	author krw;	state Exp;
branches;
next	1.18;
commitid	4T685JZ45NUupSv2;

1.18
date	2015.04.11.16.23.34;	author jsing;	state Exp;
branches;
next	1.17;
commitid	xOhjxDypA8NH6aeR;

1.17
date	2014.11.18.02.37.30;	author tedu;	state Exp;
branches;
next	1.16;
commitid	Z1vcFtHO8wRH0yRt;

1.16
date	2014.09.14.14.17.24;	author jsg;	state Exp;
branches;
next	1.15;
commitid	uzzBR7hz9ncd4O6G;

1.15
date	2014.01.23.00.22.35;	author jsing;	state Exp;
branches;
next	1.14;

1.14
date	2014.01.22.23.50.52;	author jsing;	state Exp;
branches;
next	1.13;

1.13
date	2014.01.22.12.31.09;	author jsing;	state Exp;
branches;
next	1.12;

1.12
date	2014.01.22.09.37.11;	author jsing;	state Exp;
branches;
next	1.11;

1.11
date	2014.01.22.05.11.36;	author jsing;	state Exp;
branches;
next	1.10;

1.10
date	2014.01.22.04.47.15;	author jsing;	state Exp;
branches;
next	1.9;

1.9
date	2014.01.22.04.24.29;	author jsing;	state Exp;
branches;
next	1.8;

1.8
date	2014.01.21.10.25.25;	author jsing;	state Exp;
branches;
next	1.7;

1.7
date	2014.01.21.10.21.05;	author jsing;	state Exp;
branches;
next	1.6;

1.6
date	2014.01.21.03.15.55;	author jsing;	state Exp;
branches;
next	1.5;

1.5
date	2014.01.19.11.48.42;	author jsing;	state Exp;
branches;
next	1.4;

1.4
date	2014.01.19.11.43.05;	author jsing;	state Exp;
branches;
next	1.3;

1.3
date	2014.01.19.11.24.37;	author jsing;	state Exp;
branches;
next	1.2;

1.2
date	2014.01.18.09.33.53;	author jsing;	state Exp;
branches;
next	1.1;

1.1
date	2014.01.18.09.23.26;	author jsing;	state Exp;
branches;
next	;


desc
@@


1.27
log
@Using '4' as the max # of ccb's in a work unit doesn't work so well
when the number of chunks in your RAID5 is significantly more than
4.  Each work unit needs to use at least a ccb per chunk to do the
i/o.

Set the max to the number of chunks, which all the other RAID types
do in one varient or other. Note that it's not really a max, just
the number used when allocating the entire collection of ccb's for the
volume.

Fixes doing largeish i/o's (e.g. dd bs=1m count=128) to RAID5 volumes
with many chunks.

Problem reported by Alex McWhirter.

ok jsing@@
@
text
@/* $OpenBSD: softraid_raid5.c,v 1.26 2016/05/31 15:19:12 jsing Exp $ */
/*
 * Copyright (c) 2014 Joel Sing <jsing@@openbsd.org>
 * Copyright (c) 2009 Marco Peereboom <marco@@peereboom.us>
 * Copyright (c) 2009 Jordan Hargrave <jordan@@openbsd.org>
 *
 * Permission to use, copy, modify, and distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 */

#include "bio.h"

#include <sys/param.h>
#include <sys/systm.h>
#include <sys/buf.h>
#include <sys/device.h>
#include <sys/ioctl.h>
#include <sys/malloc.h>
#include <sys/kernel.h>
#include <sys/disk.h>
#include <sys/rwlock.h>
#include <sys/queue.h>
#include <sys/fcntl.h>
#include <sys/mount.h>
#include <sys/sensors.h>
#include <sys/stat.h>
#include <sys/task.h>
#include <sys/pool.h>
#include <sys/conf.h>
#include <sys/uio.h>

#include <scsi/scsi_all.h>
#include <scsi/scsiconf.h>
#include <scsi/scsi_disk.h>

#include <dev/softraidvar.h>

/* RAID 5 functions. */
int	sr_raid5_create(struct sr_discipline *, struct bioc_createraid *,
	    int, int64_t);
int	sr_raid5_assemble(struct sr_discipline *, struct bioc_createraid *,
	    int, void *);
int	sr_raid5_init(struct sr_discipline *);
int	sr_raid5_rw(struct sr_workunit *);
int	sr_raid5_openings(struct sr_discipline *);
void	sr_raid5_intr(struct buf *);
int	sr_raid5_wu_done(struct sr_workunit *);
void	sr_raid5_set_chunk_state(struct sr_discipline *, int, int);
void	sr_raid5_set_vol_state(struct sr_discipline *);

int	sr_raid5_addio(struct sr_workunit *wu, int, daddr_t, long,
	    void *, int, int, void *);
int	sr_raid5_regenerate(struct sr_workunit *, int, daddr_t, long,
	    void *);
int	sr_raid5_write(struct sr_workunit *, struct sr_workunit *, int, int,
	    daddr_t, long, void *, int, int);
void	sr_raid5_xor(void *, void *, int);

void	sr_raid5_rebuild(struct sr_discipline *);
void	sr_raid5_scrub(struct sr_discipline *);

/* discipline initialisation. */
void
sr_raid5_discipline_init(struct sr_discipline *sd)
{
	/* Fill out discipline members. */
	sd->sd_type = SR_MD_RAID5;
	strlcpy(sd->sd_name, "RAID 5", sizeof(sd->sd_name));
	sd->sd_capabilities = SR_CAP_SYSTEM_DISK | SR_CAP_AUTO_ASSEMBLE |
	    SR_CAP_REBUILD | SR_CAP_REDUNDANT;
	sd->sd_max_wu = SR_RAID5_NOWU + 2;	/* Two for scrub/rebuild. */

	/* Setup discipline specific function pointers. */
	sd->sd_assemble = sr_raid5_assemble;
	sd->sd_create = sr_raid5_create;
	sd->sd_openings = sr_raid5_openings;
	sd->sd_rebuild = sr_raid5_rebuild;
	sd->sd_scsi_rw = sr_raid5_rw;
	sd->sd_scsi_intr = sr_raid5_intr;
	sd->sd_scsi_wu_done = sr_raid5_wu_done;
	sd->sd_set_chunk_state = sr_raid5_set_chunk_state;
	sd->sd_set_vol_state = sr_raid5_set_vol_state;
}

int
sr_raid5_create(struct sr_discipline *sd, struct bioc_createraid *bc,
    int no_chunk, int64_t coerced_size)
{
	if (no_chunk < 3) {
		sr_error(sd->sd_sc, "%s requires three or more chunks",
		    sd->sd_name);
		return EINVAL;
	}

	/*
	 * XXX add variable strip size later even though MAXPHYS is really
	 * the clever value, users like to tinker with that type of stuff.
	 */
	sd->sd_meta->ssdi.ssd_strip_size = MAXPHYS;
	sd->sd_meta->ssdi.ssd_size = (coerced_size &
	    ~(((u_int64_t)sd->sd_meta->ssdi.ssd_strip_size >>
	    DEV_BSHIFT) - 1)) * (no_chunk - 1);

	return sr_raid5_init(sd);
}

int
sr_raid5_assemble(struct sr_discipline *sd, struct bioc_createraid *bc,
    int no_chunk, void *data)
{
	return sr_raid5_init(sd);
}

int
sr_raid5_init(struct sr_discipline *sd)
{
	/* Initialise runtime values. */
	sd->mds.mdd_raid5.sr5_strip_bits =
	    sr_validate_stripsize(sd->sd_meta->ssdi.ssd_strip_size);
	if (sd->mds.mdd_raid5.sr5_strip_bits == -1) {
		sr_error(sd->sd_sc, "invalid strip size");
		return EINVAL;
	}

	sd->sd_max_ccb_per_wu = sd->sd_meta->ssdi.ssd_chunk_no;

	return 0;
}

int
sr_raid5_openings(struct sr_discipline *sd)
{
	/* Two work units per I/O, two for rebuild/scrub. */
	return ((sd->sd_max_wu - 2) >> 1);
}

void
sr_raid5_set_chunk_state(struct sr_discipline *sd, int c, int new_state)
{
	int			old_state, s;

	DNPRINTF(SR_D_STATE, "%s: %s: %s: sr_raid_set_chunk_state %d -> %d\n",
	    DEVNAME(sd->sd_sc), sd->sd_meta->ssd_devname,
	    sd->sd_vol.sv_chunks[c]->src_meta.scmi.scm_devname, c, new_state);

	/* ok to go to splbio since this only happens in error path */
	s = splbio();
	old_state = sd->sd_vol.sv_chunks[c]->src_meta.scm_status;

	/* multiple IOs to the same chunk that fail will come through here */
	if (old_state == new_state)
		goto done;

	switch (old_state) {
	case BIOC_SDONLINE:
		switch (new_state) {
		case BIOC_SDOFFLINE:
		case BIOC_SDSCRUB:
			break;
		default:
			goto die;
		}
		break;

	case BIOC_SDOFFLINE:
		if (new_state == BIOC_SDREBUILD) {
			;
		} else
			goto die;
		break;

	case BIOC_SDSCRUB:
		switch (new_state) {
		case BIOC_SDONLINE:
		case BIOC_SDOFFLINE:
			break;
		default:
			goto die;
		}
		break;

	case BIOC_SDREBUILD:
		switch (new_state) {
		case BIOC_SDONLINE:
		case BIOC_SDOFFLINE:
			break;
		default:
			goto die;
		}
		break;

	default:
die:
		splx(s); /* XXX */
		panic("%s: %s: %s: invalid chunk state transition "
		    "%d -> %d", DEVNAME(sd->sd_sc),
		    sd->sd_meta->ssd_devname,
		    sd->sd_vol.sv_chunks[c]->src_meta.scmi.scm_devname,
		    old_state, new_state);
		/* NOTREACHED */
	}

	sd->sd_vol.sv_chunks[c]->src_meta.scm_status = new_state;
	sd->sd_set_vol_state(sd);

	sd->sd_must_flush = 1;
	task_add(systq, &sd->sd_meta_save_task);
done:
	splx(s);
}

void
sr_raid5_set_vol_state(struct sr_discipline *sd)
{
	int			states[SR_MAX_STATES];
	int			new_state, i, s, nd;
	int			old_state = sd->sd_vol_status;

	DNPRINTF(SR_D_STATE, "%s: %s: sr_raid_set_vol_state\n",
	    DEVNAME(sd->sd_sc), sd->sd_meta->ssd_devname);

	nd = sd->sd_meta->ssdi.ssd_chunk_no;

	for (i = 0; i < SR_MAX_STATES; i++)
		states[i] = 0;

	for (i = 0; i < nd; i++) {
		s = sd->sd_vol.sv_chunks[i]->src_meta.scm_status;
		if (s >= SR_MAX_STATES)
			panic("%s: %s: %s: invalid chunk state",
			    DEVNAME(sd->sd_sc),
			    sd->sd_meta->ssd_devname,
			    sd->sd_vol.sv_chunks[i]->src_meta.scmi.scm_devname);
		states[s]++;
	}

	if (states[BIOC_SDONLINE] == nd)
		new_state = BIOC_SVONLINE;
	else if (states[BIOC_SDONLINE] < nd - 1)
		new_state = BIOC_SVOFFLINE;
	else if (states[BIOC_SDSCRUB] != 0)
		new_state = BIOC_SVSCRUB;
	else if (states[BIOC_SDREBUILD] != 0)
		new_state = BIOC_SVREBUILD;
	else if (states[BIOC_SDONLINE] == nd - 1)
		new_state = BIOC_SVDEGRADED;
	else {
#ifdef SR_DEBUG
		DNPRINTF(SR_D_STATE, "%s: invalid volume state, old state "
		    "was %d\n", DEVNAME(sd->sd_sc), old_state);
		for (i = 0; i < nd; i++)
			DNPRINTF(SR_D_STATE, "%s: chunk %d status = %d\n",
			    DEVNAME(sd->sd_sc), i,
			    sd->sd_vol.sv_chunks[i]->src_meta.scm_status);
#endif
		panic("invalid volume state");
	}

	DNPRINTF(SR_D_STATE, "%s: %s: sr_raid5_set_vol_state %d -> %d\n",
	    DEVNAME(sd->sd_sc), sd->sd_meta->ssd_devname,
	    old_state, new_state);

	switch (old_state) {
	case BIOC_SVONLINE:
		switch (new_state) {
		case BIOC_SVONLINE: /* can go to same state */
		case BIOC_SVOFFLINE:
		case BIOC_SVDEGRADED:
		case BIOC_SVREBUILD: /* happens on boot */
			break;
		default:
			goto die;
		}
		break;

	case BIOC_SVOFFLINE:
		/* XXX this might be a little too much */
		goto die;

	case BIOC_SVDEGRADED:
		switch (new_state) {
		case BIOC_SVOFFLINE:
		case BIOC_SVREBUILD:
		case BIOC_SVDEGRADED: /* can go to the same state */
			break;
		default:
			goto die;
		}
		break;

	case BIOC_SVBUILDING:
		switch (new_state) {
		case BIOC_SVONLINE:
		case BIOC_SVOFFLINE:
		case BIOC_SVBUILDING: /* can go to the same state */
			break;
		default:
			goto die;
		}
		break;

	case BIOC_SVSCRUB:
		switch (new_state) {
		case BIOC_SVONLINE:
		case BIOC_SVOFFLINE:
		case BIOC_SVDEGRADED:
		case BIOC_SVSCRUB: /* can go to same state */
			break;
		default:
			goto die;
		}
		break;

	case BIOC_SVREBUILD:
		switch (new_state) {
		case BIOC_SVONLINE:
		case BIOC_SVOFFLINE:
		case BIOC_SVDEGRADED:
		case BIOC_SVREBUILD: /* can go to the same state */
			break;
		default:
			goto die;
		}
		break;

	default:
die:
		panic("%s: %s: invalid volume state transition %d -> %d",
		    DEVNAME(sd->sd_sc), sd->sd_meta->ssd_devname,
		    old_state, new_state);
		/* NOTREACHED */
	}

	sd->sd_vol_status = new_state;
}

static inline int
sr_raid5_chunk_online(struct sr_discipline *sd, int chunk)
{
	switch (sd->sd_vol.sv_chunks[chunk]->src_meta.scm_status) {
	case BIOC_SDONLINE:
	case BIOC_SDSCRUB:
		return 1;
	default:
		return 0;
	}
}

static inline int
sr_raid5_chunk_rebuild(struct sr_discipline *sd, int chunk)
{
	switch (sd->sd_vol.sv_chunks[chunk]->src_meta.scm_status) {
	case BIOC_SDREBUILD:
		return 1;
	default:
		return 0;
	}
}

int
sr_raid5_rw(struct sr_workunit *wu)
{
	struct sr_workunit	*wu_r = NULL;
	struct sr_discipline	*sd = wu->swu_dis;
	struct scsi_xfer	*xs = wu->swu_xs;
	struct sr_chunk		*scp;
	daddr_t			blkno, lba;
	int64_t			chunk_offs, lbaoffs, offset, strip_offs;
	int64_t			strip_bits, strip_no, strip_size;
	int64_t			chunk, no_chunk;
	int64_t			parity, row_size;
	long			length, datalen;
	void			*data;
	int			s;

	/* blkno and scsi error will be handled by sr_validate_io */
	if (sr_validate_io(wu, &blkno, "sr_raid5_rw"))
		goto bad;

	DNPRINTF(SR_D_DIS, "%s: %s sr_raid5_rw %s: blkno %lld size %d\n",
	    DEVNAME(sd->sd_sc), sd->sd_meta->ssd_devname,
	    (xs->flags & SCSI_DATA_IN) ? "read" : "write",
	    (long long)blkno, xs->datalen);

	strip_size = sd->sd_meta->ssdi.ssd_strip_size;
	strip_bits = sd->mds.mdd_raid5.sr5_strip_bits;
	no_chunk = sd->sd_meta->ssdi.ssd_chunk_no - 1;
	row_size = (no_chunk << strip_bits) >> DEV_BSHIFT;

	data = xs->data;
	datalen = xs->datalen;
	lbaoffs	= blkno << DEV_BSHIFT;

	if (xs->flags & SCSI_DATA_OUT) {
		if ((wu_r = sr_scsi_wu_get(sd, SCSI_NOSLEEP)) == NULL){
			printf("%s: %s failed to get read work unit",
			    DEVNAME(sd->sd_sc), sd->sd_meta->ssd_devname);
			goto bad;
		}
		wu_r->swu_state = SR_WU_INPROGRESS;
		wu_r->swu_flags |= SR_WUF_DISCIPLINE;
	}

	wu->swu_blk_start = 0;
	while (datalen != 0) {
		strip_no = lbaoffs >> strip_bits;
		strip_offs = lbaoffs & (strip_size - 1);
		chunk_offs = (strip_no / no_chunk) << strip_bits;
		offset = chunk_offs + strip_offs;

		/* get size remaining in this stripe */
		length = MIN(strip_size - strip_offs, datalen);

		/*
		 * Map disk offset to data and parity chunks, using a left
		 * asymmetric algorithm for the parity assignment.
		 */
		chunk = strip_no % no_chunk;
		parity = no_chunk - ((strip_no / no_chunk) % (no_chunk + 1));
		if (chunk >= parity)
			chunk++;

		lba = offset >> DEV_BSHIFT;

		/* XXX big hammer.. exclude I/O from entire stripe */
		if (wu->swu_blk_start == 0)
			wu->swu_blk_start = (strip_no / no_chunk) * row_size;
		wu->swu_blk_end = (strip_no / no_chunk) * row_size +
		    (row_size - 1);

		scp = sd->sd_vol.sv_chunks[chunk];
		if (xs->flags & SCSI_DATA_IN) {
			switch (scp->src_meta.scm_status) {
			case BIOC_SDONLINE:
			case BIOC_SDSCRUB:
				/*
				 * Chunk is online, issue a single read
				 * request.
				 */
				if (sr_raid5_addio(wu, chunk, lba, length,
				    data, xs->flags, 0, NULL))
					goto bad;
				break;
			case BIOC_SDOFFLINE:
			case BIOC_SDREBUILD:
			case BIOC_SDHOTSPARE:
				if (sr_raid5_regenerate(wu, chunk, lba,
				    length, data))
					goto bad;
				break;
			default:
				printf("%s: is offline, can't read\n",
				    DEVNAME(sd->sd_sc));
				goto bad;
			}
		} else {
			if (sr_raid5_write(wu, wu_r, chunk, parity, lba,
			    length, data, xs->flags, 0))
				goto bad;
		}

		/* advance to next block */
		lbaoffs += length;
		datalen -= length;
		data += length;
	}

	s = splbio();
	if (wu_r) {
		if (wu_r->swu_io_count > 0) {
			/* collide write request with reads */
			wu_r->swu_blk_start = wu->swu_blk_start;
			wu_r->swu_blk_end = wu->swu_blk_end;

			wu->swu_state = SR_WU_DEFERRED;
			wu_r->swu_collider = wu;
			TAILQ_INSERT_TAIL(&sd->sd_wu_defq, wu, swu_link);

			wu = wu_r;
		} else {
			sr_scsi_wu_put(sd, wu_r);
		}
	}
	splx(s);

	sr_schedule_wu(wu);

	return (0);

bad:
	/* wu is unwound by sr_wu_put */
	if (wu_r)
		sr_scsi_wu_put(sd, wu_r);
	return (1);
}

int
sr_raid5_regenerate(struct sr_workunit *wu, int chunk, daddr_t blkno,
    long len, void *data)
{
	struct sr_discipline	*sd = wu->swu_dis;
	int			i;

	/*
	 * Regenerate a block on a RAID 5 volume by xoring the data and parity
	 * from all of the remaining online chunks. This requires the parity
	 * to already be correct.
	 */

	DNPRINTF(SR_D_DIS, "%s: %s sr_raid5_regenerate chunk %d offline, "
	    "regenerating block %llu\n",
	    DEVNAME(sd->sd_sc), sd->sd_meta->ssd_devname, chunk, blkno);

	memset(data, 0, len);
	for (i = 0; i < sd->sd_meta->ssdi.ssd_chunk_no; i++) {
		if (i == chunk)
			continue;
		if (!sr_raid5_chunk_online(sd, i))
			goto bad;
		if (sr_raid5_addio(wu, i, blkno, len, NULL, SCSI_DATA_IN,
		    0, data))
			goto bad;
	}
	return (0);

bad:
	return (1);
}

int
sr_raid5_write(struct sr_workunit *wu, struct sr_workunit *wu_r, int chunk,
    int parity, daddr_t blkno, long len, void *data, int xsflags,
    int ccbflags)
{
	struct sr_discipline	*sd = wu->swu_dis;
	struct scsi_xfer	*xs = wu->swu_xs;
	void			*xorbuf;
	int			chunk_online, chunk_rebuild;
	int			parity_online, parity_rebuild;
	int			other_offline = 0, other_rebuild = 0;
	int			i;

	/*
	 * Perform a write to a RAID 5 volume. This write routine does not
	 * require the parity to already be correct and will operate on a
	 * uninitialised volume.
	 *
	 * There are four possible cases:
	 *
	 * 1) All data chunks and parity are online. In this case we read the
	 *    data from all data chunks, except the one we are writing to, in
	 *    order to calculate and write the new parity.
	 *
	 * 2) The parity chunk is offline. In this case we only need to write
	 *    to the data chunk. No parity calculation is required.
	 *
	 * 3) The data chunk is offline. In this case we read the data from all
	 *    online chunks in order to calculate and write the new parity.
	 *    This is the same as (1) except we do not write the data chunk.
	 *
	 * 4) A different data chunk is offline. The new parity is calculated
	 *    by taking the existing parity, xoring the original data and
	 *    xoring in the new data. This requires that the parity already be
	 *    correct, which it will be if any of the data chunks has
	 *    previously been written.
	 *
	 * There is an additional complication introduced by a chunk that is
	 * being rebuilt. If this is the data or parity chunk, then we want
	 * to write to it as per normal. If it is another data chunk then we
	 * need to presume that it has not yet been regenerated and use the
	 * same method as detailed in (4) above.
	 */

	DNPRINTF(SR_D_DIS, "%s: %s sr_raid5_write chunk %i parity %i "
	    "blkno %llu\n", DEVNAME(sd->sd_sc), sd->sd_meta->ssd_devname,
	    chunk, parity, (unsigned long long)blkno);

	chunk_online = sr_raid5_chunk_online(sd, chunk);
	chunk_rebuild = sr_raid5_chunk_rebuild(sd, chunk);
	parity_online = sr_raid5_chunk_online(sd, parity);
	parity_rebuild = sr_raid5_chunk_rebuild(sd, parity);

	for (i = 0; i < sd->sd_meta->ssdi.ssd_chunk_no; i++) {
		if (i == chunk || i == parity)
			continue;
		if (sr_raid5_chunk_rebuild(sd, i))
			other_rebuild = 1;
		else if (!sr_raid5_chunk_online(sd, i))
			other_offline = 1;
	}

	DNPRINTF(SR_D_DIS, "%s: %s chunk online %d, parity online %d, "
	    "other offline %d\n", DEVNAME(sd->sd_sc), sd->sd_meta->ssd_devname,
	    chunk_online, parity_online, other_offline);

	if (!parity_online && !parity_rebuild)
		goto data_write;

	xorbuf = sr_block_get(sd, len);
	if (xorbuf == NULL)
		goto bad;
	memcpy(xorbuf, data, len);

	if (other_offline || other_rebuild) {

		/*
		 * XXX - If we can guarantee that this LBA has been scrubbed
		 * then we can also take this faster path.
		 */

		/* Read in existing data and existing parity. */
		if (sr_raid5_addio(wu_r, chunk, blkno, len, NULL,
		    SCSI_DATA_IN, 0, xorbuf))
			goto bad;
		if (sr_raid5_addio(wu_r, parity, blkno, len, NULL,
		    SCSI_DATA_IN, 0, xorbuf))
			goto bad;

	} else {

		/* Read in existing data from all other chunks. */
		for (i = 0; i < sd->sd_meta->ssdi.ssd_chunk_no; i++) {
			if (i == chunk || i == parity)
				continue;
			if (sr_raid5_addio(wu_r, i, blkno, len, NULL,
			    SCSI_DATA_IN, 0, xorbuf))
				goto bad;
		}

	}

	/* Write new parity. */
	if (sr_raid5_addio(wu, parity, blkno, len, xorbuf, xs->flags,
	    SR_CCBF_FREEBUF, NULL))
		goto bad;

data_write:
	/* Write new data. */
	if (chunk_online || chunk_rebuild)
		if (sr_raid5_addio(wu, chunk, blkno, len, data, xs->flags,
		    0, NULL))
			goto bad;

	return (0);

bad:
	return (1);
}

void
sr_raid5_intr(struct buf *bp)
{
	struct sr_ccb		*ccb = (struct sr_ccb *)bp;
	struct sr_workunit	*wu = ccb->ccb_wu;
	struct sr_discipline	*sd = wu->swu_dis;
	int			s;

	DNPRINTF(SR_D_INTR, "%s: sr_raid5_intr bp %p xs %p\n",
	    DEVNAME(sd->sd_sc), bp, wu->swu_xs);

	s = splbio();
	sr_ccb_done(ccb);

	/* XXX - Should this be done via the taskq? */

	/* XOR data to result. */
	if (ccb->ccb_state == SR_CCB_OK && ccb->ccb_opaque)
		sr_raid5_xor(ccb->ccb_opaque, ccb->ccb_buf.b_data,
		    ccb->ccb_buf.b_bcount);

	/* Free allocated data buffer. */
	if (ccb->ccb_flags & SR_CCBF_FREEBUF) {
		sr_block_put(sd, ccb->ccb_buf.b_data, ccb->ccb_buf.b_bcount);
		ccb->ccb_buf.b_data = NULL;
	}

	sr_wu_done(wu);
	splx(s);
}

int
sr_raid5_wu_done(struct sr_workunit *wu)
{
	struct sr_discipline	*sd = wu->swu_dis;
	struct scsi_xfer	*xs = wu->swu_xs;

	/* XXX - we have no way of propagating errors... */
	if (wu->swu_flags & (SR_WUF_DISCIPLINE | SR_WUF_REBUILD))
		return SR_WU_OK;

	/* XXX - This is insufficient for RAID 5. */
	if (wu->swu_ios_succeeded > 0) {
		xs->error = XS_NOERROR;
		return SR_WU_OK;
	}

	if (xs->flags & SCSI_DATA_IN) {
		printf("%s: retrying read on block %lld\n",
		    sd->sd_meta->ssd_devname, (long long)wu->swu_blk_start);
		sr_wu_release_ccbs(wu);
		wu->swu_state = SR_WU_RESTART;
		if (sd->sd_scsi_rw(wu) == 0)
			return SR_WU_RESTART;
	} else {
		/* XXX - retry write if we just went from online to degraded. */
		printf("%s: permanently fail write on block %lld\n",
		    sd->sd_meta->ssd_devname, (long long)wu->swu_blk_start);
	}

	wu->swu_state = SR_WU_FAILED;
	xs->error = XS_DRIVER_STUFFUP;

	return SR_WU_FAILED;
}

int
sr_raid5_addio(struct sr_workunit *wu, int chunk, daddr_t blkno,
    long len, void *data, int xsflags, int ccbflags, void *xorbuf)
{
	struct sr_discipline	*sd = wu->swu_dis;
	struct sr_ccb		*ccb;

	DNPRINTF(SR_D_DIS, "sr_raid5_addio: %s chunk %d block %lld "
	    "length %ld %s\n", (xsflags & SCSI_DATA_IN) ? "read" : "write",
	    chunk, (long long)blkno, len, xorbuf ? "X0R" : "-");

	/* Allocate temporary buffer. */
	if (data == NULL) {
		data = sr_block_get(sd, len);
		if (data == NULL)
			return (-1);
		ccbflags |= SR_CCBF_FREEBUF;
	}

	ccb = sr_ccb_rw(sd, chunk, blkno, len, data, xsflags, ccbflags);
	if (ccb == NULL) {
		if (ccbflags & SR_CCBF_FREEBUF)
			sr_block_put(sd, data, len);
		return (-1);
	}
	ccb->ccb_opaque = xorbuf;
	sr_wu_enqueue_ccb(wu, ccb);

	return (0);
}

void
sr_raid5_xor(void *a, void *b, int len)
{
	uint32_t		*xa = a, *xb = b;

	len >>= 2;
	while (len--)
		*xa++ ^= *xb++;
}

void
sr_raid5_rebuild(struct sr_discipline *sd)
{
	int64_t strip_no, strip_size, strip_bits, i, restart;
	int64_t chunk_count, chunk_strips, chunk_lba, chunk_size, row_size;
	struct sr_workunit *wu_r, *wu_w;
	int s, slept, percent = 0, old_percent = -1;
	int rebuild_chunk = -1;
	void *xorbuf;

	/* Find the rebuild chunk. */
	for (i = 0; i < sd->sd_meta->ssdi.ssd_chunk_no; i++) {
		if (sr_raid5_chunk_rebuild(sd, i)) {
			rebuild_chunk = i;
			break;
		}
	}
	if (rebuild_chunk == -1)
		goto bad;

	strip_size = sd->sd_meta->ssdi.ssd_strip_size;
	strip_bits = sd->mds.mdd_raid5.sr5_strip_bits;
	chunk_count = sd->sd_meta->ssdi.ssd_chunk_no - 1;
	chunk_size = sd->sd_meta->ssdi.ssd_size / chunk_count;
	chunk_strips = (chunk_size << DEV_BSHIFT) >> strip_bits;
	row_size = (chunk_count << strip_bits) >> DEV_BSHIFT;

	DNPRINTF(SR_D_REBUILD, "%s: %s sr_raid5_rebuild volume size = %lld, "
	    "chunk count = %lld, chunk size = %lld, chunk strips = %lld, "
	    "row size = %lld\n", DEVNAME(sd->sd_sc), sd->sd_meta->ssd_devname,
	    sd->sd_meta->ssdi.ssd_size, chunk_count, chunk_size, chunk_strips,
	    row_size);

	restart = sd->sd_meta->ssd_rebuild / row_size;
	if (restart > chunk_strips) {
		printf("%s: bogus rebuild restart offset, starting from 0\n",
		    DEVNAME(sd->sd_sc));
		restart = 0;
	}
	if (restart != 0) {
		percent = sr_rebuild_percent(sd);
		printf("%s: resuming rebuild on %s at %d%%\n",
		    DEVNAME(sd->sd_sc), sd->sd_meta->ssd_devname, percent);
	}

	for (strip_no = restart; strip_no < chunk_strips; strip_no++) {
		chunk_lba = (strip_size >> DEV_BSHIFT) * strip_no;

		DNPRINTF(SR_D_REBUILD, "%s: %s rebuild strip %lld, "
		    "chunk lba = %lld\n", DEVNAME(sd->sd_sc),
		    sd->sd_meta->ssd_devname, strip_no, chunk_lba);

		wu_w = sr_scsi_wu_get(sd, 0);
		wu_r = sr_scsi_wu_get(sd, 0);

		xorbuf = sr_block_get(sd, strip_size);
		if (sr_raid5_regenerate(wu_r, rebuild_chunk, chunk_lba,
		    strip_size, xorbuf))
			goto bad;
		if (sr_raid5_addio(wu_w, rebuild_chunk, chunk_lba, strip_size,
		    xorbuf, SCSI_DATA_OUT, SR_CCBF_FREEBUF, NULL))
			goto bad;

		/* Collide write work unit with read work unit. */
		wu_r->swu_state = SR_WU_INPROGRESS;
		wu_r->swu_flags |= SR_WUF_REBUILD;
		wu_w->swu_state = SR_WU_DEFERRED;
		wu_w->swu_flags |= SR_WUF_REBUILD | SR_WUF_WAKEUP;
		wu_r->swu_collider = wu_w;

		/* Block I/O to this strip while we rebuild it. */
		wu_r->swu_blk_start = (strip_no / chunk_count) * row_size;
		wu_r->swu_blk_end = wu_r->swu_blk_start + row_size - 1;
		wu_w->swu_blk_start = wu_r->swu_blk_start;
		wu_w->swu_blk_end = wu_r->swu_blk_end;

		DNPRINTF(SR_D_REBUILD, "%s: %s rebuild swu_blk_start = %lld, "
		    "swu_blk_end = %lld\n", DEVNAME(sd->sd_sc),
		    sd->sd_meta->ssd_devname,
		    wu_r->swu_blk_start, wu_r->swu_blk_end);

		s = splbio();
		TAILQ_INSERT_TAIL(&sd->sd_wu_defq, wu_w, swu_link);
		splx(s);

		sr_schedule_wu(wu_r);

		slept = 0;
		while ((wu_w->swu_flags & SR_WUF_REBUILDIOCOMP) == 0) {
			tsleep(wu_w, PRIBIO, "sr_rebuild", 0);
			slept = 1;
		}
		if (!slept)
			tsleep(sd->sd_sc, PWAIT, "sr_yield", 1);

		sr_scsi_wu_put(sd, wu_r);
		sr_scsi_wu_put(sd, wu_w);

		sd->sd_meta->ssd_rebuild = chunk_lba * chunk_count;

		percent = sr_rebuild_percent(sd);
		if (percent != old_percent && strip_no != chunk_strips - 1) {
			if (sr_meta_save(sd, SR_META_DIRTY))
				printf("%s: could not save metadata to %s\n",
				    DEVNAME(sd->sd_sc),
				    sd->sd_meta->ssd_devname);
			old_percent = percent;
		}

		if (sd->sd_reb_abort)
			goto abort;
	}

	DNPRINTF(SR_D_REBUILD, "%s: %s rebuild complete\n", DEVNAME(sd->sd_sc),
	    sd->sd_meta->ssd_devname);

	/* all done */
	sd->sd_meta->ssd_rebuild = 0;
	for (i = 0; i < sd->sd_meta->ssdi.ssd_chunk_no; i++) {
		if (sd->sd_vol.sv_chunks[i]->src_meta.scm_status ==
		    BIOC_SDREBUILD) {
			sd->sd_set_chunk_state(sd, i, BIOC_SDONLINE);
			break;
		}
	}

	return;

abort:
	if (sr_meta_save(sd, SR_META_DIRTY))
		printf("%s: could not save metadata to %s\n",
		    DEVNAME(sd->sd_sc), sd->sd_meta->ssd_devname);
bad:
	return;
}

#if 0
void
sr_raid5_scrub(struct sr_discipline *sd)
{
	int64_t strip_no, strip_size, no_chunk, parity, max_strip, strip_bits;
	int64_t i;
	struct sr_workunit *wu_r, *wu_w;
	int s, slept;
	void *xorbuf;

	wu_w = sr_scsi_wu_get(sd, 0);
	wu_r = sr_scsi_wu_get(sd, 0);

	no_chunk = sd->sd_meta->ssdi.ssd_chunk_no - 1;
	strip_size = sd->sd_meta->ssdi.ssd_strip_size;
	strip_bits = sd->mds.mdd_raid5.sr5_strip_bits;
	max_strip = sd->sd_meta->ssdi.ssd_size >> strip_bits;

	for (strip_no = 0; strip_no < max_strip; strip_no++) {
		parity = no_chunk - ((strip_no / no_chunk) % (no_chunk + 1));

		xorbuf = sr_block_get(sd, strip_size);
		for (i = 0; i <= no_chunk; i++) {
			if (i != parity)
				sr_raid5_addio(wu_r, i, 0xBADCAFE, strip_size,
				    NULL, SCSI_DATA_IN, 0, xorbuf);
		}
		sr_raid5_addio(wu_w, parity, 0xBADCAFE, strip_size, xorbuf,
		    SCSI_DATA_OUT, SR_CCBF_FREEBUF, NULL);

		wu_r->swu_flags |= SR_WUF_REBUILD;

		/* Collide wu_w with wu_r */
		wu_w->swu_state = SR_WU_DEFERRED;
		wu_w->swu_flags |= SR_WUF_REBUILD | SR_WUF_WAKEUP;
		wu_r->swu_collider = wu_w;

		s = splbio();
		TAILQ_INSERT_TAIL(&sd->sd_wu_defq, wu_w, swu_link);
		splx(s);

		wu_r->swu_state = SR_WU_INPROGRESS;
		sr_schedule_wu(wu_r);

		slept = 0;
		while ((wu_w->swu_flags & SR_WUF_REBUILDIOCOMP) == 0) {
			tsleep(wu_w, PRIBIO, "sr_scrub", 0);
			slept = 1;
		}
		if (!slept)
			tsleep(sd->sd_sc, PWAIT, "sr_yield", 1);
	}
done:
	return;
}
#endif
@


1.26
log
@Provide a function for calculting the rebuild percentage, rather than
having five copies of the same code.

ok krw@@
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid5.c,v 1.25 2016/04/12 16:26:54 krw Exp $ */
a79 1
	sd->sd_max_ccb_per_wu = 4; /* only if stripsize <= MAXPHYS */
d133 2
@


1.25
log
@No need to rescan chunks in each discipline to find appropriate
volume sector size.  Determine volume sector size in sr_meta_init().

Pointed out, tweaked and ok jsing@@
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid5.c,v 1.24 2016/04/04 18:48:39 krw Exp $ */
d768 1
a768 1
	int64_t strip_no, strip_size, strip_bits, i, psz, rb, restart;
d805 1
a805 6
		psz = sd->sd_meta->ssdi.ssd_size;
		rb = sd->sd_meta->ssd_rebuild;
		if (rb > 0)
			percent = 100 - ((psz * 100 - rb * 100) / psz) - 1;
		else
			percent = 0;
d865 1
a865 6
		psz = sd->sd_meta->ssdi.ssd_size;
		rb = sd->sd_meta->ssd_rebuild;
		if (rb > 0)
			percent = 100 - ((psz * 100 - rb * 100) / psz) - 1;
		else
			percent = 0;
@


1.24
log
@Enable creation of softraid volumes using disks with non-512 byte
sectors. Volumes created will present a sector size equal to the
largest sector size of the constituent disks.

Softraid Metadata version cranks to 6 due to new field.

ok jsing@@ with tweaks that will follow soon.
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid5.c,v 1.23 2015/07/21 03:30:51 krw Exp $ */
a98 3
	int i;
	u_int32_t secsize;

a103 7

	secsize = sd->sd_vol.sv_chunks[0]->src_secsize;
	for (i = 0; i < no_chunk; i++) {
		if (sd->sd_vol.sv_chunks[i]->src_secsize > secsize)
			secsize = sd->sd_vol.sv_chunks[i]->src_secsize;
	}
	sd->sd_meta->ssdi.ssd_secsize = secsize;
@


1.23
log
@A few more daddr_t fixes. Rename 'phys_off' variables to 'offset'
since they are now relative to chunks. Use 'blkno' as normal variable
name for daddr_t items rather than mix of 'blkno, blk, offset.
Change field name ssd_data_offset to ssd_data_blkno since it is a
block and not byte quantity.

No intentional functional change.
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid5.c,v 1.22 2015/07/19 21:06:04 krw Exp $ */
d99 3
d107 7
@


1.22
log
@Remove unneeded #include <disklabel.h>.

ok jsing@@
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid5.c,v 1.21 2015/07/19 18:24:16 krw Exp $ */
d375 2
a376 2
	daddr_t			blk, lba;
	int64_t			chunk_offs, lbaoffs, phys_offs, strip_offs;
d384 2
a385 2
	/* blk and scsi error will be handled by sr_validate_io */
	if (sr_validate_io(wu, &blk, "sr_raid5_rw"))
d388 1
a388 1
	DNPRINTF(SR_D_DIS, "%s: %s sr_raid5_rw %s: lba %lld size %d\n",
d391 1
a391 1
	    (long long)blk, xs->datalen);
d400 1
a400 1
	lbaoffs	= blk << DEV_BSHIFT;
d417 1
a417 1
		phys_offs = chunk_offs + strip_offs;
d431 1
a431 1
		lba = phys_offs >> DEV_BSHIFT;
d583 1
a583 1
	    "blk %llu\n", DEVNAME(sd->sd_sc), sd->sd_meta->ssd_devname,
@


1.21
log
@Stop passing daddr_t parameters for lengths. Use long since that's the type
of the destination fields.

ok jsing@@
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid5.c,v 1.20 2015/07/19 17:04:31 krw Exp $ */
a32 1
#include <sys/disklabel.h>
@


1.20
log
@Stop adding and subtracting data offset. Just keep to chunk relative
block offsets until actual i/o is constructed and needs the physical
offset. Eliminate a number of <<DEV_BSIZE shifts as a bonus.

No intentional functional change.

Fixed and ok jsing@@
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid5.c,v 1.19 2015/05/29 13:48:45 krw Exp $ */
d61 1
a61 1
int	sr_raid5_addio(struct sr_workunit *wu, int, daddr_t, daddr_t,
d63 1
a63 1
int	sr_raid5_regenerate(struct sr_workunit *, int, daddr_t, daddr_t,
d66 1
a66 1
	    daddr_t, daddr_t, void *, int, int);
d380 2
a381 1
	int64_t			length, parity, datalen, row_size;
d508 1
a508 1
    daddr_t len, void *data)
d541 1
a541 1
    int parity, daddr_t blkno, daddr_t len, void *data, int xsflags,
d727 1
a727 1
    daddr_t len, void *data, int xsflags, int ccbflags, void *xorbuf)
d733 2
a734 2
	    "length %lld %s\n", (xsflags & SCSI_DATA_IN) ? "read" : "write",
	    chunk, (long long)blkno, (long long)len, xorbuf ? "X0R" : "-");
@


1.19
log
@Nuke annoying whitespace nits to shrink some future diffs.
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid5.c,v 1.18 2015/04/11 16:23:34 jsing Exp $ */
d417 1
a417 2
		phys_offs = chunk_offs + strip_offs +
		    (sd->sd_meta->ssd_data_offset << DEV_BSHIFT);
d816 1
a816 2
		chunk_lba = (strip_size >> DEV_BSHIFT) * strip_no +
		    sd->sd_meta->ssd_data_offset;
d868 1
a868 2
		sd->sd_meta->ssd_rebuild =
		    (chunk_lba - sd->sd_meta->ssd_data_offset) * chunk_count;
@


1.18
log
@Add support for restarting rebuilds on RAID 5.

ok krw@@
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid5.c,v 1.17 2014/11/18 02:37:30 tedu Exp $ */
d517 1
a517 1
 	 */
@


1.17
log
@move arc4random prototype to systm.h. more appropriate for most code
to include that than rdnvar.h. ok deraadt dlg
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid5.c,v 1.16 2014/09/14 14:17:24 jsg Exp $ */
d769 1
a769 1
	int64_t strip_no, strip_size, strip_bits, i, psz, rb;
a792 1
	/* XXX - handle restarts. */
d799 18
a816 1
	for (strip_no = 0; strip_no < chunk_strips; strip_no++) {
@


1.16
log
@remove uneeded proc.h includes
ok mpi@@ kspillner@@
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid5.c,v 1.15 2014/01/23 00:22:35 jsing Exp $ */
a46 1
#include <dev/rndvar.h>
@


1.15
log
@Add support for rebuilding a RAID5 volume. Lots of testing is still
required and there is missing functionality, such as the ability to resume
a partially completed rebuild.

ok krw@@
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid5.c,v 1.14 2014/01/22 23:50:52 jsing Exp $ */
a26 1
#include <sys/proc.h>
@


1.14
log
@Assert copyright.
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid5.c,v 1.13 2014/01/22 12:31:09 jsing Exp $ */
d71 1
d82 1
a82 1
	    SR_CAP_REDUNDANT;
d90 1
d766 132
@


1.13
log
@Do not attempt to handle rebuild work units in the RAID5 work unit
completion code. Add a comment about retrying on write failures.
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid5.c,v 1.12 2014/01/22 09:37:11 jsing Exp $ */
d3 1
@


1.12
log
@Allocate two work units for use by rebuild/scrub.
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid5.c,v 1.11 2014/01/22 05:11:36 jsing Exp $ */
d696 1
a696 1
	if (wu->swu_flags & SR_WUF_DISCIPLINE)
d713 1
@


1.11
log
@Move sr_dump from the RAID5 code into shared code. Rename it to
sr_dump_block and place it under the debug define in the process.
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid5.c,v 1.10 2014/01/22 04:47:15 jsing Exp $ */
d82 1
a82 1
	sd->sd_max_wu = SR_RAID5_NOWU;
d141 2
a142 1
	return (sd->sd_max_wu >> 1); /* 2 wu's per IO */
d403 2
a404 1
			printf("%s: can't get wu_r", DEVNAME(sd->sd_sc));
@


1.10
log
@Handle the case where a chunk is in a rebuild state during writes.

ok krw@@
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid5.c,v 1.9 2014/01/22 04:24:29 jsing Exp $ */
a69 1
void	sr_dump(void *, int);
a749 20
}

void
sr_dump(void *blk, int len)
{
	uint8_t			*b = blk;
	int			i, j, c;

	for (i = 0; i < len; i += 16) {
		for (j = 0; j < 16; j++)
			printf("%.2x ", b[i + j]);
		printf("  ");
		for (j = 0; j < 16; j++) {
			c = b[i + j];
			if (c < ' ' || c > 'z' || i + j > len)
				c = '.';
			printf("%c", c);
		}
		printf("\n");
	}
@


1.9
log
@Switch metadata saves from the system workq to the system taskq.

ok dlg@@
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid5.c,v 1.8 2014/01/21 10:25:25 jsing Exp $ */
d357 11
d545 3
a547 1
	int			chunk_online, parity_online, other_offline = 0;
d573 6
d586 1
d588 1
d593 3
a595 1
		if (!sr_raid5_chunk_online(sd, i))
d603 1
a603 1
	if (!parity_online)
d611 1
a611 1
	if (other_offline) {
d646 1
a646 1
	if (chunk_online)
@


1.8
log
@Order the volume state transitions by state value.
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid5.c,v 1.6 2014/01/21 03:15:55 jsing Exp $ */
d37 1
d215 1
a215 1
	workq_add_task(NULL, 0, sr_meta_save_callback, sd, NULL);
d648 1
a648 1
	/* XXX - Should this be done via the workq? */
@


1.7
log
@Add missing states to the RAID 5 volume transitions.
@
text
@d287 11
a326 11
			break;
		default:
			goto die;
		}
		break;

	case BIOC_SVDEGRADED:
		switch (new_state) {
		case BIOC_SVOFFLINE:
		case BIOC_SVREBUILD:
		case BIOC_SVDEGRADED: /* can go to the same state */
@


1.6
log
@Factor out and fix the RAID5 write functionality.

In particular, change the parity calculation algorithm so that we do not
need to scrub the volume. Also handle the different cases that we can
encounter when operating in online and degraded mode. This allows writes
to continue to function correctly even when a chunk is lost.

ok krw@@
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid5.c,v 1.5 2014/01/19 11:48:42 jsing Exp $ */
d274 1
d286 11
@


1.5
log
@Improve some comments and wrap a long line.
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid5.c,v 1.4 2014/01/19 11:43:05 jsing Exp $ */
d65 2
d356 1
a356 1
	void			*xorbuf, *data;
d363 5
d440 2
a441 33
			/* XXX handle writes to failed/offline disk? */
			if (scp->src_meta.scm_status == BIOC_SDOFFLINE)
				goto bad;

			/*
			 * initialize XORBUF with contents of new data to be
			 * written. This will be XORed with old data and old
			 * parity in the intr routine. The result in xorbuf
			 * is the new parity data.
			 */
			xorbuf = sr_block_get(sd, length);
			if (xorbuf == NULL)
				goto bad;
			memcpy(xorbuf, data, length);

			/* xor old data */
			if (sr_raid5_addio(wu_r, chunk, lba, length, NULL,
			    SCSI_DATA_IN, 0, xorbuf))
				goto bad;

			/* xor old parity */
			if (sr_raid5_addio(wu_r, parity, lba, length, NULL,
			    SCSI_DATA_IN, 0, xorbuf))
				goto bad;

			/* write new data */
			if (sr_raid5_addio(wu, chunk, lba, length, data,
			    xs->flags, 0, NULL))
				goto bad;

			/* write new parity */
			if (sr_raid5_addio(wu, parity, lba, length, xorbuf,
			    xs->flags, SR_CCBF_FREEBUF, NULL))
a473 1
	/* XXX - can leak xorbuf on error. */
d507 108
@


1.4
log
@Only schedule the read workunit if there are actually I/O ccbs enqueued
on it.

ok krw@@
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid5.c,v 1.3 2014/01/19 11:24:37 jsing Exp $ */
d390 4
a393 1
		/* map disk offset to parity/data drive */
a394 2

		/* RAID5 - left asymmetric algorithm */
d404 2
a405 1
		wu->swu_blk_end = (strip_no / no_chunk) * row_size + (row_size - 1);
d412 4
a415 1
				/* drive is good. issue single read request */
@


1.3
log
@Factor out and improve the block regeneration code.

ok krw@@
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid5.c,v 1.2 2014/01/18 09:33:53 jsing Exp $ */
d472 8
a479 7
		/* collide write request with reads */
		wu_r->swu_blk_start = wu->swu_blk_start;
		wu_r->swu_blk_end = wu->swu_blk_end;

		wu->swu_state = SR_WU_DEFERRED;
		wu_r->swu_collider = wu;
		TAILQ_INSERT_TAIL(&sd->sd_wu_defq, wu, swu_link);
d481 4
a484 1
		wu = wu_r;
@


1.2
log
@Move the block get/put routines into the common code, instead of having
RAID 6 borrow them from RAID 5.
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid5.c,v 1.1 2014/01/18 09:23:26 jsing Exp $ */
a60 1
void	sr_raid5_xor(void *, void *, int);
d63 4
d330 12
a348 1
	int			s, i;
d355 1
d418 3
a420 19
				/*
				 * XXX only works if this LBA has already
				 * been scrubbed
				 */
				printf("Disk %llx offline, "
				    "regenerating buffer\n", chunk);
				memset(data, 0, length);
				for (i = 0; i <= no_chunk; i++) {
					/*
					 * read all other drives: xor result
					 * into databuffer.
					 */
					if (i != chunk) {
						if (sr_raid5_addio(wu, i, lba,
						    length, NULL, SCSI_DATA_IN,
						    0, data))
							goto bad;
					}
				}
d496 33
d570 1
a570 1
	/* XXX - This is insufficient for RAID 4/5. */
d601 3
a603 3
	DNPRINTF(SR_D_DIS, "sr_raid5_addio: %s %d.%llx %llx %s\n",
	    (xsflags & SCSI_DATA_IN) ? "read" : "write", chunk, 
	    (long long)blkno, (long long)len, xorbuf ? "X0R" : "-");
@


1.1
log
@Rename softraid RAIDP to softraid RAID5.

Discussed with krw@@
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid5.c,v 1.56 2014/01/18 09:01:01 jsing Exp $ */
a66 3
void	*sr_get_block(struct sr_discipline *, int);
void	sr_put_block(struct sr_discipline *, void *, int);

d439 1
a439 1
			xorbuf = sr_get_block(sd, length);
d520 1
a520 1
		sr_put_block(sd, ccb->ccb_buf.b_data, ccb->ccb_buf.b_bcount);
d575 1
a575 1
		data = sr_get_block(sd, len);
d584 1
a584 1
			sr_put_block(sd, data, len);
d644 1
a644 1
		xorbuf = sr_get_block(sd, strip_size);
a678 13

void *
sr_get_block(struct sr_discipline *sd, int length)
{
	return dma_alloc(length, PR_NOWAIT | PR_ZERO);
}

void
sr_put_block(struct sr_discipline *sd, void *ptr, int length)
{
	dma_free(ptr, length);
}

@

